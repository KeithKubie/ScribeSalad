WEBVTT
Kind: captions
Language: en

00:00:03.380 --> 00:00:07.820
the mathematician IJ good back in the

00:00:07.820 --> 00:00:07.830
the mathematician IJ good back in the
 

00:00:07.830 --> 00:00:11.270
the mathematician IJ good back in the
mid-1960s introduced what he called the

00:00:11.270 --> 00:00:11.280
mid-1960s introduced what he called the
 

00:00:11.280 --> 00:00:15.079
mid-1960s introduced what he called the
intelligence explosion which in essence

00:00:15.079 --> 00:00:15.089
intelligence explosion which in essence
 

00:00:15.089 --> 00:00:17.269
intelligence explosion which in essence
was the same as the concept that Vernor

00:00:17.269 --> 00:00:17.279
was the same as the concept that Vernor
 

00:00:17.279 --> 00:00:17.930
was the same as the concept that Vernor
Vinge

00:00:17.930 --> 00:00:17.940
Vinge
 

00:00:17.940 --> 00:00:20.359
Vinge
later introduced and Ray Kurzweil

00:00:20.359 --> 00:00:20.369
later introduced and Ray Kurzweil
 

00:00:20.369 --> 00:00:22.279
later introduced and Ray Kurzweil
adopted and called the technological

00:00:22.279 --> 00:00:22.289
adopted and called the technological
 

00:00:22.289 --> 00:00:26.120
adopted and called the technological
singularity what IJ good said was the

00:00:26.120 --> 00:00:26.130
singularity what IJ good said was the
 

00:00:26.130 --> 00:00:30.080
singularity what IJ good said was the
first intelligent machine will be the

00:00:30.080 --> 00:00:30.090
first intelligent machine will be the
 

00:00:30.090 --> 00:00:32.540
first intelligent machine will be the
last invention that humanity needs to

00:00:32.540 --> 00:00:32.550
last invention that humanity needs to
 

00:00:32.550 --> 00:00:35.660
last invention that humanity needs to
make now in the 1960s the difference

00:00:35.660 --> 00:00:35.670
make now in the 1960s the difference
 

00:00:35.670 --> 00:00:39.049
make now in the 1960s the difference
between narrow AI and AGI wasn't that

00:00:39.049 --> 00:00:39.059
between narrow AI and AGI wasn't that
 

00:00:39.059 --> 00:00:41.780
between narrow AI and AGI wasn't that
clear and RJ good wasn't thinking about

00:00:41.780 --> 00:00:41.790
clear and RJ good wasn't thinking about
 

00:00:41.790 --> 00:00:44.810
clear and RJ good wasn't thinking about
a system like alphago that could beat go

00:00:44.810 --> 00:00:44.820
a system like alphago that could beat go
 

00:00:44.820 --> 00:00:47.600
a system like alphago that could beat go
but couldn't walk down the street or add

00:00:47.600 --> 00:00:47.610
but couldn't walk down the street or add
 

00:00:47.610 --> 00:00:51.350
but couldn't walk down the street or add
five plus five in the modern vernacular

00:00:51.350 --> 00:00:51.360
five plus five in the modern vernacular
 

00:00:51.360 --> 00:00:54.500
five plus five in the modern vernacular
what we can say is the first human level

00:00:54.500 --> 00:00:54.510
what we can say is the first human level
 

00:00:54.510 --> 00:00:57.889
what we can say is the first human level
AGI the first human level artificial

00:00:57.889 --> 00:00:57.899
AGI the first human level artificial
 

00:00:57.899 --> 00:01:00.650
AGI the first human level artificial
general intelligence will be the last

00:01:00.650 --> 00:01:00.660
general intelligence will be the last
 

00:01:00.660 --> 00:01:03.650
general intelligence will be the last
invention that humanity needs to make

00:01:03.650 --> 00:01:03.660
invention that humanity needs to make
 

00:01:03.660 --> 00:01:06.679
invention that humanity needs to make
and the reason for that is once you get

00:01:06.679 --> 00:01:06.689
and the reason for that is once you get
 

00:01:06.689 --> 00:01:09.440
and the reason for that is once you get
a human level AGI you can teach this

00:01:09.440 --> 00:01:09.450
a human level AGI you can teach this
 

00:01:09.450 --> 00:01:11.899
a human level AGI you can teach this
human level AGI math and programming and

00:01:11.899 --> 00:01:11.909
human level AGI math and programming and
 

00:01:11.909 --> 00:01:14.030
human level AGI math and programming and
AI theory in cognitive science and

00:01:14.030 --> 00:01:14.040
AI theory in cognitive science and
 

00:01:14.040 --> 00:01:17.960
AI theory in cognitive science and
neuroscience this human level AGI can

00:01:17.960 --> 00:01:17.970
neuroscience this human level AGI can
 

00:01:17.970 --> 00:01:20.929
neuroscience this human level AGI can
then reprogram itself and it can modify

00:01:20.929 --> 00:01:20.939
then reprogram itself and it can modify
 

00:01:20.939 --> 00:01:24.289
then reprogram itself and it can modify
its own mind and it can make itself into

00:01:24.289 --> 00:01:24.299
its own mind and it can make itself into
 

00:01:24.299 --> 00:01:26.539
its own mind and it can make itself into
a yet smarter machine it can make 10,000

00:01:26.539 --> 00:01:26.549
a yet smarter machine it can make 10,000
 

00:01:26.549 --> 00:01:28.999
a yet smarter machine it can make 10,000
copies of itself some of which are much

00:01:28.999 --> 00:01:29.009
copies of itself some of which are much
 

00:01:29.009 --> 00:01:31.149
copies of itself some of which are much
more intelligent than the original and

00:01:31.149 --> 00:01:31.159
more intelligent than the original and
 

00:01:31.159 --> 00:01:35.300
more intelligent than the original and
once the first human level AGI has

00:01:35.300 --> 00:01:35.310
once the first human level AGI has
 

00:01:35.310 --> 00:01:37.399
once the first human level AGI has
created the second one which is smarter

00:01:37.399 --> 00:01:37.409
created the second one which is smarter
 

00:01:37.409 --> 00:01:38.120
created the second one which is smarter
than itself

00:01:38.120 --> 00:01:38.130
than itself
 

00:01:38.130 --> 00:01:40.550
than itself
well that second one will be even better

00:01:40.550 --> 00:01:40.560
well that second one will be even better
 

00:01:40.560 --> 00:01:42.980
well that second one will be even better
at AI programming and hardware design

00:01:42.980 --> 00:01:42.990
at AI programming and hardware design
 

00:01:42.990 --> 00:01:45.350
at AI programming and hardware design
and cognitive science and so forth and

00:01:45.350 --> 00:01:45.360
and cognitive science and so forth and
 

00:01:45.360 --> 00:01:48.020
and cognitive science and so forth and
we'll be able to create the third human

00:01:48.020 --> 00:01:48.030
we'll be able to create the third human
 

00:01:48.030 --> 00:01:50.120
we'll be able to create the third human
level AGI which by now will be well

00:01:50.120 --> 00:01:50.130
level AGI which by now will be well
 

00:01:50.130 --> 00:01:54.380
level AGI which by now will be well
beyond human level so it seems that it's

00:01:54.380 --> 00:01:54.390
beyond human level so it seems that it's
 

00:01:54.390 --> 00:01:57.499
beyond human level so it seems that it's
going to be a laborious path to get to

00:01:57.499 --> 00:01:57.509
going to be a laborious path to get to
 

00:01:57.509 --> 00:02:00.590
going to be a laborious path to get to
the first human level AGI I don't think

00:02:00.590 --> 00:02:00.600
the first human level AGI I don't think
 

00:02:00.600 --> 00:02:02.420
the first human level AGI I don't think
it will take centuries from now but it

00:02:02.420 --> 00:02:02.430
it will take centuries from now but it
 

00:02:02.430 --> 00:02:06.050
it will take centuries from now but it
may be decades rather than years on the

00:02:06.050 --> 00:02:06.060
may be decades rather than years on the
 

00:02:06.060 --> 00:02:08.630
may be decades rather than years on the
other hand once you get to a human level

00:02:08.630 --> 00:02:08.640
other hand once you get to a human level
 

00:02:08.640 --> 00:02:11.940
other hand once you get to a human level
AGI I think you may see what some

00:02:11.940 --> 00:02:11.950
AGI I think you may see what some
 

00:02:11.950 --> 00:02:13.619
AGI I think you may see what some
futures have called the hard takeoff

00:02:13.619 --> 00:02:13.629
futures have called the hard takeoff
 

00:02:13.629 --> 00:02:16.650
futures have called the hard takeoff
where you see the intelligence increase

00:02:16.650 --> 00:02:16.660
where you see the intelligence increase
 

00:02:16.660 --> 00:02:20.210
where you see the intelligence increase
literally day by day as the AI system

00:02:20.210 --> 00:02:20.220
literally day by day as the AI system
 

00:02:20.220 --> 00:02:24.869
literally day by day as the AI system
rewrites its own mind and this it's a

00:02:24.869 --> 00:02:24.879
rewrites its own mind and this it's a
 

00:02:24.879 --> 00:02:28.280
rewrites its own mind and this it's a
bit frightening but it's also incredibly

00:02:28.280 --> 00:02:28.290
bit frightening but it's also incredibly
 

00:02:28.290 --> 00:02:31.830
bit frightening but it's also incredibly
exciting does that mean humans will not

00:02:31.830 --> 00:02:31.840
exciting does that mean humans will not
 

00:02:31.840 --> 00:02:35.220
exciting does that mean humans will not
ever make any more inventions of course

00:02:35.220 --> 00:02:35.230
ever make any more inventions of course
 

00:02:35.230 --> 00:02:39.030
ever make any more inventions of course
it doesn't but what it means is if we do

00:02:39.030 --> 00:02:39.040
it doesn't but what it means is if we do
 

00:02:39.040 --> 00:02:41.820
it doesn't but what it means is if we do
things right we won't need to if things

00:02:41.820 --> 00:02:41.830
things right we won't need to if things
 

00:02:41.830 --> 00:02:43.740
things right we won't need to if things
come out the way that I hope they will

00:02:43.740 --> 00:02:43.750
come out the way that I hope they will
 

00:02:43.750 --> 00:02:46.160
come out the way that I hope they will
what will happen is we'll have these

00:02:46.160 --> 00:02:46.170
what will happen is we'll have these
 

00:02:46.170 --> 00:02:48.630
what will happen is we'll have these
superhuman minds and largely they'll be

00:02:48.630 --> 00:02:48.640
superhuman minds and largely they'll be
 

00:02:48.640 --> 00:02:51.210
superhuman minds and largely they'll be
doing their own things they will also

00:02:51.210 --> 00:02:51.220
doing their own things they will also
 

00:02:51.220 --> 00:02:54.630
doing their own things they will also
offer to us the possibility to upload or

00:02:54.630 --> 00:02:54.640
offer to us the possibility to upload or
 

00:02:54.640 --> 00:02:57.600
offer to us the possibility to upload or
upgrade ourselves and join them in

00:02:57.600 --> 00:02:57.610
upgrade ourselves and join them in
 

00:02:57.610 --> 00:03:00.569
upgrade ourselves and join them in
realms of experience that we cannot now

00:03:00.569 --> 00:03:00.579
realms of experience that we cannot now
 

00:03:00.579 --> 00:03:04.410
realms of experience that we cannot now
conceive no current human forms or these

00:03:04.410 --> 00:03:04.420
conceive no current human forms or these
 

00:03:04.420 --> 00:03:08.699
conceive no current human forms or these
superhuman Agis may help humans to

00:03:08.699 --> 00:03:08.709
superhuman Agis may help humans to
 

00:03:08.709 --> 00:03:11.220
superhuman Agis may help humans to
maintain that traditional human-like

00:03:11.220 --> 00:03:11.230
maintain that traditional human-like
 

00:03:11.230 --> 00:03:13.620
maintain that traditional human-like
existence I mean if if you have a

00:03:13.620 --> 00:03:13.630
existence I mean if if you have a
 

00:03:13.630 --> 00:03:16.080
existence I mean if if you have a
million times human IQ and you can

00:03:16.080 --> 00:03:16.090
million times human IQ and you can
 

00:03:16.090 --> 00:03:18.360
million times human IQ and you can
reconfigure elementary particles into

00:03:18.360 --> 00:03:18.370
reconfigure elementary particles into
 

00:03:18.370 --> 00:03:20.660
reconfigure elementary particles into
new forms of matter and will then

00:03:20.660 --> 00:03:20.670
new forms of matter and will then
 

00:03:20.670 --> 00:03:24.180
new forms of matter and will then
supplying a few billion humans with you

00:03:24.180 --> 00:03:24.190
supplying a few billion humans with you
 

00:03:24.190 --> 00:03:26.789
supplying a few billion humans with you
know food and water and video games

00:03:26.789 --> 00:03:26.799
know food and water and video games
 

00:03:26.799 --> 00:03:29.160
know food and water and video games
virtual reality headsets and national

00:03:29.160 --> 00:03:29.170
virtual reality headsets and national
 

00:03:29.170 --> 00:03:32.460
virtual reality headsets and national
parks and flying cars and whatnot this

00:03:32.460 --> 00:03:32.470
parks and flying cars and whatnot this
 

00:03:32.470 --> 00:03:35.039
parks and flying cars and whatnot this
would be trivial for these super human

00:03:35.039 --> 00:03:35.049
would be trivial for these super human
 

00:03:35.049 --> 00:03:38.009
would be trivial for these super human
minds so if if they are well disposed

00:03:38.009 --> 00:03:38.019
minds so if if they are well disposed
 

00:03:38.019 --> 00:03:38.759
minds so if if they are well disposed
toward us

00:03:38.759 --> 00:03:38.769
toward us
 

00:03:38.769 --> 00:03:42.360
toward us
people who chose to remain in human form

00:03:42.360 --> 00:03:42.370
people who chose to remain in human form
 

00:03:42.370 --> 00:03:45.930
people who chose to remain in human form
could have a simply much better quality

00:03:45.930 --> 00:03:45.940
could have a simply much better quality
 

00:03:45.940 --> 00:03:47.849
could have a simply much better quality
of life than we have now you don't have

00:03:47.849 --> 00:03:47.859
of life than we have now you don't have
 

00:03:47.859 --> 00:03:50.009
of life than we have now you don't have
to work for a living you can devote your

00:03:50.009 --> 00:03:50.019
to work for a living you can devote your
 

00:03:50.019 --> 00:03:53.190
to work for a living you can devote your
time to social emotional spiritual

00:03:53.190 --> 00:03:53.200
time to social emotional spiritual
 

00:03:53.200 --> 00:03:55.819
time to social emotional spiritual
intellectual and creative pursuits

00:03:55.819 --> 00:03:55.829
intellectual and creative pursuits
 

00:03:55.829 --> 00:03:59.160
intellectual and creative pursuits
rather than laborious ly doing things

00:03:59.160 --> 00:03:59.170
rather than laborious ly doing things
 

00:03:59.170 --> 00:04:01.920
rather than laborious ly doing things
you might rather not do just in order to

00:04:01.920 --> 00:04:01.930
you might rather not do just in order to
 

00:04:01.930 --> 00:04:04.680
you might rather not do just in order to
get food and shelter and an internet

00:04:04.680 --> 00:04:04.690
get food and shelter and an internet
 

00:04:04.690 --> 00:04:07.050
get food and shelter and an internet
connection so I think that there is

00:04:07.050 --> 00:04:07.060
connection so I think that there is
 

00:04:07.060 --> 00:04:10.800
connection so I think that there is
tremendous positive possibilities here

00:04:10.800 --> 00:04:10.810
tremendous positive possibilities here
 

00:04:10.810 --> 00:04:14.280
tremendous positive possibilities here
and there's also a lot a lot of

00:04:14.280 --> 00:04:14.290
and there's also a lot a lot of
 

00:04:14.290 --> 00:04:17.129
and there's also a lot a lot of
uncertainty and there's a lot of work to

00:04:17.129 --> 00:04:17.139
uncertainty and there's a lot of work to
 

00:04:17.139 --> 00:04:20.000
uncertainty and there's a lot of work to
get to the point where intelligence

00:04:20.000 --> 00:04:20.010
get to the point where intelligence
 

00:04:20.010 --> 00:04:22.589
get to the point where intelligence
explodes in the sense of a hard takeoff

00:04:22.589 --> 00:04:22.599
explodes in the sense of a hard takeoff
 

00:04:22.599 --> 00:04:25.670
explodes in the sense of a hard takeoff
but I do think it's reasonably from

00:04:25.670 --> 00:04:25.680
but I do think it's reasonably from
 

00:04:25.680 --> 00:04:28.249
but I do think it's reasonably from
but we can get there in my lifetime

00:04:28.249 --> 00:04:28.259
but we can get there in my lifetime
 

00:04:28.259 --> 00:04:35.070
but we can get there in my lifetime
which is which is rather exciting

00:04:35.070 --> 00:04:35.080
 

00:04:35.080 --> 00:04:38.430
[Music]

