WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.600 align:start position:0%
 
bachelor<00:00:00.570><c> on</c><00:00:00.659><c> processes</c><00:00:01.260><c> or</c><00:00:01.410><c> data</c><00:00:01.620><c> one</c><00:00:02.310><c> me</c><00:00:02.550><c> me</c>

00:00:02.600 --> 00:00:02.610 align:start position:0%
bachelor on processes or data one me me
 

00:00:02.610 --> 00:00:04.999 align:start position:0%
bachelor on processes or data one me me
batch<00:00:02.879><c> at</c><00:00:03.090><c> the</c><00:00:03.179><c> time</c><00:00:03.419><c> but</c><00:00:03.990><c> at</c><00:00:04.140><c> times</c><00:00:04.710><c> you</c><00:00:04.890><c> might</c>

00:00:04.999 --> 00:00:05.009 align:start position:0%
batch at the time but at times you might
 

00:00:05.009 --> 00:00:07.010 align:start position:0%
batch at the time but at times you might
need<00:00:05.160><c> to</c><00:00:05.310><c> process</c><00:00:05.549><c> the</c><00:00:05.850><c> examples</c><00:00:06.299><c> one</c><00:00:06.810><c> at</c><00:00:06.990><c> a</c>

00:00:07.010 --> 00:00:07.020 align:start position:0%
need to process the examples one at a
 

00:00:07.020 --> 00:00:08.960 align:start position:0%
need to process the examples one at a
time<00:00:07.259><c> let's</c><00:00:07.919><c> see</c><00:00:08.069><c> how</c><00:00:08.250><c> you</c><00:00:08.309><c> can</c><00:00:08.519><c> adapt</c><00:00:08.880><c> your</c>

00:00:08.960 --> 00:00:08.970 align:start position:0%
time let's see how you can adapt your
 

00:00:08.970 --> 00:00:11.270 align:start position:0%
time let's see how you can adapt your
network<00:00:09.360><c> to</c><00:00:09.510><c> do</c><00:00:09.660><c> that</c><00:00:09.920><c> recall</c><00:00:10.920><c> that</c><00:00:11.070><c> during</c>

00:00:11.270 --> 00:00:11.280 align:start position:0%
network to do that recall that during
 

00:00:11.280 --> 00:00:13.879 align:start position:0%
network to do that recall that during
training<00:00:11.969><c> here</c><00:00:12.389><c> are</c><00:00:12.599><c> the</c><00:00:12.780><c> equations</c><00:00:13.049><c> you</c><00:00:13.530><c> just</c>

00:00:13.879 --> 00:00:13.889 align:start position:0%
training here are the equations you just
 

00:00:13.889 --> 00:00:16.129 align:start position:0%
training here are the equations you just
implement<00:00:14.250><c> national</c><00:00:14.839><c> within</c><00:00:15.839><c> a</c><00:00:15.870><c> single</c>

00:00:16.129 --> 00:00:16.139 align:start position:0%
implement national within a single
 

00:00:16.139 --> 00:00:19.640 align:start position:0%
implement national within a single
mini-batches<00:00:16.740><c> sum</c><00:00:17.279><c> over</c><00:00:17.550><c> that</c><00:00:17.670><c> mini</c><00:00:17.880><c> batch</c><00:00:18.650><c> of</c>

00:00:19.640 --> 00:00:19.650 align:start position:0%
mini-batches sum over that mini batch of
 

00:00:19.650 --> 00:00:22.730 align:start position:0%
mini-batches sum over that mini batch of
the<00:00:20.070><c> zi</c><00:00:20.400><c> values</c><00:00:20.970><c> to</c><00:00:21.449><c> compute</c><00:00:21.779><c> the</c><00:00:21.840><c> mean</c><00:00:22.080><c> so</c>

00:00:22.730 --> 00:00:22.740 align:start position:0%
the zi values to compute the mean so
 

00:00:22.740 --> 00:00:24.320 align:start position:0%
the zi values to compute the mean so
here<00:00:22.980><c> you're</c><00:00:23.430><c> just</c><00:00:23.460><c> summing</c><00:00:23.939><c> over</c><00:00:24.029><c> the</c>

00:00:24.320 --> 00:00:24.330 align:start position:0%
here you're just summing over the
 

00:00:24.330 --> 00:00:26.480 align:start position:0%
here you're just summing over the
examples<00:00:24.869><c> in</c><00:00:25.050><c> one</c><00:00:25.260><c> mini</c><00:00:25.500><c> batch</c><00:00:25.740><c> I'm</c><00:00:25.980><c> using</c><00:00:26.189><c> M</c>

00:00:26.480 --> 00:00:26.490 align:start position:0%
examples in one mini batch I'm using M
 

00:00:26.490 --> 00:00:28.580 align:start position:0%
examples in one mini batch I'm using M
to<00:00:26.699><c> denote</c><00:00:27.000><c> the</c><00:00:27.510><c> number</c><00:00:27.539><c> of</c><00:00:27.869><c> examples</c><00:00:28.109><c> in</c><00:00:28.500><c> the</c>

00:00:28.580 --> 00:00:28.590 align:start position:0%
to denote the number of examples in the
 

00:00:28.590 --> 00:00:30.620 align:start position:0%
to denote the number of examples in the
mini<00:00:28.800><c> batch</c><00:00:29.010><c> not</c><00:00:29.310><c> not</c><00:00:29.670><c> in</c><00:00:29.939><c> the</c><00:00:30.060><c> whole</c><00:00:30.240><c> training</c>

00:00:30.620 --> 00:00:30.630 align:start position:0%
mini batch not not in the whole training
 

00:00:30.630 --> 00:00:33.410 align:start position:0%
mini batch not not in the whole training
set<00:00:30.810><c> then</c><00:00:31.080><c> you</c><00:00:32.040><c> compute</c><00:00:32.550><c> the</c><00:00:32.640><c> variance</c><00:00:33.090><c> and</c>

00:00:33.410 --> 00:00:33.420 align:start position:0%
set then you compute the variance and
 

00:00:33.420 --> 00:00:36.680 align:start position:0%
set then you compute the variance and
then<00:00:33.660><c> you</c><00:00:33.780><c> compute</c><00:00:34.200><c> the</c><00:00:34.290><c> norm</c><00:00:35.040><c> by</c><00:00:35.670><c> scaling</c><00:00:36.360><c> by</c>

00:00:36.680 --> 00:00:36.690 align:start position:0%
then you compute the norm by scaling by
 

00:00:36.690 --> 00:00:38.840 align:start position:0%
then you compute the norm by scaling by
the<00:00:36.750><c> mean</c><00:00:37.020><c> and</c><00:00:37.260><c> standard</c><00:00:37.410><c> deviation</c><00:00:37.850><c> what</c>

00:00:38.840 --> 00:00:38.850 align:start position:0%
the mean and standard deviation what
 

00:00:38.850 --> 00:00:40.490 align:start position:0%
the mean and standard deviation what
that's<00:00:39.059><c> on</c><00:00:39.270><c> added</c><00:00:39.660><c> for</c><00:00:39.840><c> numerical</c><00:00:40.290><c> stability</c>

00:00:40.490 --> 00:00:40.500 align:start position:0%
that's on added for numerical stability
 

00:00:40.500 --> 00:00:44.270 align:start position:0%
that's on added for numerical stability
and<00:00:41.070><c> then</c><00:00:41.700><c> V</c><00:00:41.910><c> tilde</c><00:00:42.360><c> is</c><00:00:42.629><c> taking</c><00:00:43.020><c> Z</c><00:00:43.350><c> norm</c><00:00:43.920><c> and</c>

00:00:44.270 --> 00:00:44.280 align:start position:0%
and then V tilde is taking Z norm and
 

00:00:44.280 --> 00:00:48.229 align:start position:0%
and then V tilde is taking Z norm and
rescaling<00:00:44.789><c> by</c><00:00:44.969><c> gamma</c><00:00:45.450><c> and</c><00:00:45.750><c> beta</c><00:00:46.489><c> so</c><00:00:47.489><c> notice</c>

00:00:48.229 --> 00:00:48.239 align:start position:0%
rescaling by gamma and beta so notice
 

00:00:48.239 --> 00:00:52.189 align:start position:0%
rescaling by gamma and beta so notice
that<00:00:48.559><c> mu</c><00:00:49.559><c> and</c><00:00:49.920><c> Sigma</c><00:00:50.489><c> squared</c><00:00:50.820><c> which</c><00:00:51.780><c> you</c><00:00:51.960><c> need</c>

00:00:52.189 --> 00:00:52.199 align:start position:0%
that mu and Sigma squared which you need
 

00:00:52.199 --> 00:00:54.619 align:start position:0%
that mu and Sigma squared which you need
for<00:00:52.739><c> this</c><00:00:52.860><c> scaling</c><00:00:53.340><c> calculation</c><00:00:54.239><c> are</c>

00:00:54.619 --> 00:00:54.629 align:start position:0%
for this scaling calculation are
 

00:00:54.629 --> 00:00:57.920 align:start position:0%
for this scaling calculation are
computed<00:00:55.350><c> on</c><00:00:55.559><c> the</c><00:00:55.739><c> entire</c><00:00:56.129><c> mini</c><00:00:56.760><c> value</c><00:00:57.149><c> but</c><00:00:57.809><c> at</c>

00:00:57.920 --> 00:00:57.930 align:start position:0%
computed on the entire mini value but at
 

00:00:57.930 --> 00:01:00.250 align:start position:0%
computed on the entire mini value but at
times<00:00:58.440><c> you</c><00:00:58.590><c> might</c><00:00:58.800><c> not</c><00:00:59.010><c> have</c><00:00:59.190><c> a</c><00:00:59.250><c> mini</c><00:00:59.550><c> batch</c><00:00:59.820><c> of</c>

00:01:00.250 --> 00:01:00.260 align:start position:0%
times you might not have a mini batch of
 

00:01:00.260 --> 00:01:03.740 align:start position:0%
times you might not have a mini batch of
64<00:01:01.260><c> 128</c><00:01:01.980><c> alternative</c><00:01:02.550><c> Pacific</c><00:01:02.910><c> examples</c><00:01:03.510><c> to</c>

00:01:03.740 --> 00:01:03.750 align:start position:0%
64 128 alternative Pacific examples to
 

00:01:03.750 --> 00:01:05.750 align:start position:0%
64 128 alternative Pacific examples to
process<00:01:04.199><c> at</c><00:01:04.379><c> the</c><00:01:04.470><c> same</c><00:01:04.650><c> time</c><00:01:04.920><c> so</c><00:01:05.400><c> you</c><00:01:05.460><c> need</c>

00:01:05.750 --> 00:01:05.760 align:start position:0%
process at the same time so you need
 

00:01:05.760 --> 00:01:07.640 align:start position:0%
process at the same time so you need
some<00:01:06.000><c> different</c><00:01:06.390><c> way</c><00:01:06.510><c> of</c><00:01:06.540><c> coming</c><00:01:07.080><c> up</c><00:01:07.200><c> with</c><00:01:07.229><c> mu</c>

00:01:07.640 --> 00:01:07.650 align:start position:0%
some different way of coming up with mu
 

00:01:07.650 --> 00:01:09.679 align:start position:0%
some different way of coming up with mu
and<00:01:07.920><c> Sigma</c><00:01:08.310><c> squared</c><00:01:08.670><c> and</c><00:01:08.909><c> if</c><00:01:09.060><c> just</c><00:01:09.450><c> one</c>

00:01:09.679 --> 00:01:09.689 align:start position:0%
and Sigma squared and if just one
 

00:01:09.689 --> 00:01:11.570 align:start position:0%
and Sigma squared and if just one
example<00:01:09.810><c> taking</c><00:01:10.560><c> the</c><00:01:10.650><c> mean</c><00:01:10.799><c> and</c><00:01:11.010><c> variance</c><00:01:11.070><c> of</c>

00:01:11.570 --> 00:01:11.580 align:start position:0%
example taking the mean and variance of
 

00:01:11.580 --> 00:01:15.200 align:start position:0%
example taking the mean and variance of
that<00:01:11.729><c> one</c><00:01:12.000><c> example</c><00:01:12.360><c> doesn't</c><00:01:13.320><c> make</c><00:01:13.439><c> sense</c><00:01:14.210><c> so</c>

00:01:15.200 --> 00:01:15.210 align:start position:0%
that one example doesn't make sense so
 

00:01:15.210 --> 00:01:18.469 align:start position:0%
that one example doesn't make sense so
what's<00:01:15.450><c> actually</c><00:01:15.600><c> done</c><00:01:16.280><c> in</c><00:01:17.280><c> order</c><00:01:17.700><c> to</c><00:01:17.939><c> apply</c>

00:01:18.469 --> 00:01:18.479 align:start position:0%
what's actually done in order to apply
 

00:01:18.479 --> 00:01:21.200 align:start position:0%
what's actually done in order to apply
your<00:01:18.810><c> neural</c><00:01:18.990><c> network</c><00:01:19.409><c> at</c><00:01:19.650><c> test</c><00:01:19.950><c> time</c><00:01:20.070><c> is</c><00:01:20.490><c> to</c>

00:01:21.200 --> 00:01:21.210 align:start position:0%
your neural network at test time is to
 

00:01:21.210 --> 00:01:23.179 align:start position:0%
your neural network at test time is to
come<00:01:21.479><c> up</c><00:01:21.630><c> with</c><00:01:21.750><c> some</c><00:01:22.049><c> separate</c><00:01:22.500><c> estimate</c><00:01:23.040><c> of</c>

00:01:23.179 --> 00:01:23.189 align:start position:0%
come up with some separate estimate of
 

00:01:23.189 --> 00:01:26.570 align:start position:0%
come up with some separate estimate of
mu<00:01:24.000><c> and</c><00:01:24.030><c> Sigma</c><00:01:24.750><c> squared</c><00:01:25.140><c> and</c><00:01:25.560><c> in</c><00:01:26.100><c> typical</c>

00:01:26.570 --> 00:01:26.580 align:start position:0%
mu and Sigma squared and in typical
 

00:01:26.580 --> 00:01:28.609 align:start position:0%
mu and Sigma squared and in typical
implementations<00:01:26.759><c> of</c><00:01:27.630><c> national</c><00:01:28.080><c> what</c><00:01:28.320><c> you</c><00:01:28.439><c> do</c>

00:01:28.609 --> 00:01:28.619 align:start position:0%
implementations of national what you do
 

00:01:28.619 --> 00:01:33.620 align:start position:0%
implementations of national what you do
is<00:01:29.240><c> estimate</c><00:01:30.240><c> this</c><00:01:30.979><c> using</c><00:01:31.979><c> a</c><00:01:32.630><c> exponentially</c>

00:01:33.620 --> 00:01:33.630 align:start position:0%
is estimate this using a exponentially
 

00:01:33.630 --> 00:01:36.830 align:start position:0%
is estimate this using a exponentially
weighted<00:01:33.979><c> average</c><00:01:34.979><c> where</c><00:01:35.310><c> the</c><00:01:36.060><c> average</c><00:01:36.509><c> is</c>

00:01:36.830 --> 00:01:36.840 align:start position:0%
weighted average where the average is
 

00:01:36.840 --> 00:01:44.120 align:start position:0%
weighted average where the average is
across<00:01:37.409><c> the</c><00:01:38.479><c> mini</c><00:01:39.479><c> batches</c><00:01:39.810><c> so</c><00:01:42.710><c> to</c><00:01:43.710><c> be</c><00:01:43.860><c> very</c>

00:01:44.120 --> 00:01:44.130 align:start position:0%
across the mini batches so to be very
 

00:01:44.130 --> 00:01:45.679 align:start position:0%
across the mini batches so to be very
concrete<00:01:44.430><c> here's</c><00:01:44.970><c> what</c><00:01:45.180><c> I</c><00:01:45.210><c> mean</c>

00:01:45.679 --> 00:01:45.689 align:start position:0%
concrete here's what I mean
 

00:01:45.689 --> 00:01:48.530 align:start position:0%
concrete here's what I mean
let's<00:01:46.140><c> pick</c><00:01:46.619><c> some</c><00:01:46.860><c> layer</c><00:01:47.100><c> L</c><00:01:47.399><c> and</c><00:01:47.700><c> let's</c><00:01:48.390><c> say</c>

00:01:48.530 --> 00:01:48.540 align:start position:0%
let's pick some layer L and let's say
 

00:01:48.540 --> 00:01:52.399 align:start position:0%
let's pick some layer L and let's say
you're<00:01:48.720><c> going</c><00:01:48.930><c> through</c><00:01:49.229><c> mini</c><00:01:49.470><c> batches</c><00:01:50.090><c> x1</c><00:01:51.409><c> x2</c>

00:01:52.399 --> 00:01:52.409 align:start position:0%
you're going through mini batches x1 x2
 

00:01:52.409 --> 00:01:54.679 align:start position:0%
you're going through mini batches x1 x2
together<00:01:53.399><c> with</c><00:01:53.670><c> the</c><00:01:53.790><c> corresponding</c><00:01:54.360><c> values</c>

00:01:54.679 --> 00:01:54.689 align:start position:0%
together with the corresponding values
 

00:01:54.689 --> 00:01:56.929 align:start position:0%
together with the corresponding values
of<00:01:54.840><c> Y</c><00:01:55.020><c> and</c><00:01:55.490><c> so</c><00:01:56.490><c> on</c>

00:01:56.929 --> 00:01:56.939 align:start position:0%
of Y and so on
 

00:01:56.939 --> 00:02:01.850 align:start position:0%
of Y and so on
so<00:01:57.899><c> when</c><00:01:58.380><c> training</c><00:01:59.130><c> on</c><00:01:59.340><c> x1</c><00:02:00.000><c> for</c><00:02:00.869><c> that</c><00:02:01.049><c> layer</c><00:02:01.530><c> L</c>

00:02:01.850 --> 00:02:01.860 align:start position:0%
so when training on x1 for that layer L
 

00:02:01.860 --> 00:02:06.649 align:start position:0%
so when training on x1 for that layer L
you<00:02:02.399><c> get</c><00:02:02.729><c> some</c><00:02:03.119><c> new</c><00:02:03.990><c> L</c><00:02:04.799><c> and</c><00:02:05.310><c> in</c><00:02:05.909><c> fact</c><00:02:06.119><c> I'm</c><00:02:06.390><c> going</c>

00:02:06.649 --> 00:02:06.659 align:start position:0%
you get some new L and in fact I'm going
 

00:02:06.659 --> 00:02:10.070 align:start position:0%
you get some new L and in fact I'm going
to<00:02:06.719><c> write</c><00:02:06.990><c> this</c><00:02:07.200><c> as</c><00:02:07.670><c> new</c><00:02:08.670><c> for</c><00:02:09.390><c> the</c><00:02:09.479><c> first</c><00:02:09.810><c> mini</c>

00:02:10.070 --> 00:02:10.080 align:start position:0%
to write this as new for the first mini
 

00:02:10.080 --> 00:02:11.860 align:start position:0%
to write this as new for the first mini
batch<00:02:10.379><c> and</c><00:02:10.770><c> that</c><00:02:11.459><c> lane</c>

00:02:11.860 --> 00:02:11.870 align:start position:0%
batch and that lane
 

00:02:11.870 --> 00:02:13.780 align:start position:0%
batch and that lane
and<00:02:12.290><c> then</c><00:02:12.770><c> when</c><00:02:12.920><c> you</c><00:02:13.010><c> train</c><00:02:13.220><c> on</c><00:02:13.370><c> the</c><00:02:13.459><c> second</c>

00:02:13.780 --> 00:02:13.790 align:start position:0%
and then when you train on the second
 

00:02:13.790 --> 00:02:16.360 align:start position:0%
and then when you train on the second
mini<00:02:13.940><c> batch</c><00:02:14.209><c> for</c><00:02:15.080><c> that</c><00:02:15.230><c> layer</c><00:02:15.470><c> and</c><00:02:15.770><c> that</c><00:02:16.190><c> mean</c>

00:02:16.360 --> 00:02:16.370 align:start position:0%
mini batch for that layer and that mean
 

00:02:16.370 --> 00:02:17.890 align:start position:0%
mini batch for that layer and that mean
about<00:02:16.610><c> you</c><00:02:16.910><c> and</c><00:02:17.030><c> there</c><00:02:17.150><c> was</c><00:02:17.300><c> some</c><00:02:17.510><c> second</c>

00:02:17.890 --> 00:02:17.900 align:start position:0%
about you and there was some second
 

00:02:17.900 --> 00:02:20.500 align:start position:0%
about you and there was some second
value<00:02:18.230><c> of</c><00:02:18.349><c> you</c><00:02:18.590><c> and</c><00:02:19.010><c> then</c><00:02:19.340><c> for</c><00:02:19.580><c> the</c><00:02:19.940><c> third</c><00:02:20.180><c> mini</c>

00:02:20.500 --> 00:02:20.510 align:start position:0%
value of you and then for the third mini
 

00:02:20.510 --> 00:02:24.070 align:start position:0%
value of you and then for the third mini
batch<00:02:20.750><c> in</c><00:02:21.560><c> this</c><00:02:21.860><c> hidden</c><00:02:22.160><c> layer</c><00:02:22.660><c> you</c><00:02:23.660><c> end</c><00:02:23.900><c> up</c>

00:02:24.070 --> 00:02:24.080 align:start position:0%
batch in this hidden layer you end up
 

00:02:24.080 --> 00:02:30.250 align:start position:0%
batch in this hidden layer you end up
with<00:02:24.290><c> some</c><00:02:24.650><c> third</c><00:02:25.520><c> value</c><00:02:26.500><c> for</c><00:02:27.500><c> MU</c><00:02:28.690><c> so</c><00:02:29.690><c> just</c><00:02:30.080><c> as</c>

00:02:30.250 --> 00:02:30.260 align:start position:0%
with some third value for MU so just as
 

00:02:30.260 --> 00:02:32.620 align:start position:0%
with some third value for MU so just as
means<00:02:30.530><c> for</c><00:02:30.650><c> how</c><00:02:31.220><c> to</c><00:02:31.280><c> use</c><00:02:31.670><c> the</c><00:02:31.880><c> exponentially</c>

00:02:32.620 --> 00:02:32.630 align:start position:0%
means for how to use the exponentially
 

00:02:32.630 --> 00:02:35.550 align:start position:0%
means for how to use the exponentially
weighted<00:02:32.780><c> average</c><00:02:33.349><c> to</c><00:02:34.310><c> compute</c><00:02:34.730><c> the</c><00:02:34.849><c> mean</c><00:02:35.060><c> of</c>

00:02:35.550 --> 00:02:35.560 align:start position:0%
weighted average to compute the mean of
 

00:02:35.560 --> 00:02:39.370 align:start position:0%
weighted average to compute the mean of
theta1<00:02:36.560><c> theta2</c><00:02:36.830><c> theta3</c><00:02:37.870><c> when</c><00:02:38.870><c> you</c><00:02:38.989><c> are</c><00:02:39.140><c> trying</c>

00:02:39.370 --> 00:02:39.380 align:start position:0%
theta1 theta2 theta3 when you are trying
 

00:02:39.380 --> 00:02:41.770 align:start position:0%
theta1 theta2 theta3 when you are trying
to<00:02:39.470><c> compute</c><00:02:39.680><c> a</c><00:02:40.660><c> exponentially</c><00:02:41.660><c> weighted</c>

00:02:41.770 --> 00:02:41.780 align:start position:0%
to compute a exponentially weighted
 

00:02:41.780 --> 00:02:44.259 align:start position:0%
to compute a exponentially weighted
average<00:02:42.290><c> of</c><00:02:42.500><c> the</c><00:02:42.800><c> current</c><00:02:43.160><c> temperature</c><00:02:43.610><c> you</c>

00:02:44.259 --> 00:02:44.269 align:start position:0%
average of the current temperature you
 

00:02:44.269 --> 00:02:47.110 align:start position:0%
average of the current temperature you
will<00:02:44.420><c> do</c><00:02:44.569><c> that</c><00:02:44.780><c> to</c><00:02:45.200><c> keep</c><00:02:45.440><c> track</c><00:02:45.799><c> of</c><00:02:46.130><c> so</c><00:02:46.790><c> what's</c>

00:02:47.110 --> 00:02:47.120 align:start position:0%
will do that to keep track of so what's
 

00:02:47.120 --> 00:02:49.630 align:start position:0%
will do that to keep track of so what's
the<00:02:47.330><c> latest</c><00:02:47.510><c> average</c><00:02:48.200><c> value</c><00:02:48.709><c> of</c><00:02:48.739><c> this</c><00:02:49.400><c> mean</c>

00:02:49.630 --> 00:02:49.640 align:start position:0%
the latest average value of this mean
 

00:02:49.640 --> 00:02:52.870 align:start position:0%
the latest average value of this mean
vector<00:02:49.880><c> your</c><00:02:50.269><c> seat</c><00:02:50.510><c> so</c><00:02:51.140><c> that</c><00:02:51.880><c> exponentially</c>

00:02:52.870 --> 00:02:52.880 align:start position:0%
vector your seat so that exponentially
 

00:02:52.880 --> 00:02:55.210 align:start position:0%
vector your seat so that exponentially
weighted<00:02:53.030><c> average</c><00:02:53.540><c> becomes</c><00:02:54.019><c> your</c><00:02:54.290><c> estimate</c>

00:02:55.210 --> 00:02:55.220 align:start position:0%
weighted average becomes your estimate
 

00:02:55.220 --> 00:02:58.449 align:start position:0%
weighted average becomes your estimate
for<00:02:55.819><c> what</c><00:02:55.850><c> the</c><00:02:56.120><c> mean</c><00:02:56.390><c> of</c><00:02:56.750><c> the</c><00:02:57.230><c> B's</c><00:02:57.560><c> is</c><00:02:57.980><c> for</c><00:02:58.340><c> that</c>

00:02:58.449 --> 00:02:58.459 align:start position:0%
for what the mean of the B's is for that
 

00:02:58.459 --> 00:03:01.539 align:start position:0%
for what the mean of the B's is for that
hidden<00:02:58.640><c> layer</c><00:02:58.910><c> and</c><00:02:59.230><c> similarly</c><00:03:00.250><c> you'd</c><00:03:01.250><c> use</c><00:03:01.430><c> an</c>

00:03:01.539 --> 00:03:01.549 align:start position:0%
hidden layer and similarly you'd use an
 

00:03:01.549 --> 00:03:03.100 align:start position:0%
hidden layer and similarly you'd use an
exponentially<00:03:02.060><c> weighted</c><00:03:02.180><c> average</c><00:03:02.750><c> to</c><00:03:02.900><c> keep</c>

00:03:03.100 --> 00:03:03.110 align:start position:0%
exponentially weighted average to keep
 

00:03:03.110 --> 00:03:06.789 align:start position:0%
exponentially weighted average to keep
track<00:03:03.410><c> of</c><00:03:03.739><c> these</c><00:03:04.090><c> values</c><00:03:05.090><c> of</c><00:03:05.450><c> Sigma</c><00:03:06.230><c> squared</c>

00:03:06.789 --> 00:03:06.799 align:start position:0%
track of these values of Sigma squared
 

00:03:06.799 --> 00:03:09.130 align:start position:0%
track of these values of Sigma squared
that<00:03:07.069><c> you</c><00:03:07.190><c> see</c><00:03:07.489><c> on</c><00:03:07.970><c> the</c><00:03:08.120><c> first</c><00:03:08.330><c> mini</c><00:03:08.660><c> batch</c><00:03:08.900><c> in</c>

00:03:09.130 --> 00:03:09.140 align:start position:0%
that you see on the first mini batch in
 

00:03:09.140 --> 00:03:11.770 align:start position:0%
that you see on the first mini batch in
that<00:03:09.319><c> layer</c><00:03:09.610><c> Sigma</c><00:03:10.610><c> squared</c><00:03:10.970><c> then</c><00:03:11.299><c> you</c><00:03:11.330><c> see</c><00:03:11.660><c> on</c>

00:03:11.770 --> 00:03:11.780 align:start position:0%
that layer Sigma squared then you see on
 

00:03:11.780 --> 00:03:13.960 align:start position:0%
that layer Sigma squared then you see on
a<00:03:11.810><c> second</c><00:03:12.260><c> mini</c><00:03:12.410><c> batch</c><00:03:12.650><c> and</c><00:03:12.980><c> so</c><00:03:13.459><c> on</c><00:03:13.640><c> so</c><00:03:13.880><c> you</c>

00:03:13.960 --> 00:03:13.970 align:start position:0%
a second mini batch and so on so you
 

00:03:13.970 --> 00:03:17.860 align:start position:0%
a second mini batch and so on so you
keep<00:03:14.150><c> a</c><00:03:14.330><c> running</c><00:03:15.230><c> average</c><00:03:15.440><c> of</c><00:03:16.250><c> the</c><00:03:17.209><c> MU</c><00:03:17.510><c> and</c><00:03:17.540><c> the</c>

00:03:17.860 --> 00:03:17.870 align:start position:0%
keep a running average of the MU and the
 

00:03:17.870 --> 00:03:20.140 align:start position:0%
keep a running average of the MU and the
Sigma<00:03:18.200><c> square</c><00:03:18.500><c> that</c><00:03:18.530><c> you're</c><00:03:18.769><c> seeing</c><00:03:19.010><c> for</c><00:03:19.880><c> each</c>

00:03:20.140 --> 00:03:20.150 align:start position:0%
Sigma square that you're seeing for each
 

00:03:20.150 --> 00:03:22.420 align:start position:0%
Sigma square that you're seeing for each
layer<00:03:20.510><c> as</c><00:03:20.870><c> you</c><00:03:21.290><c> train</c><00:03:21.590><c> the</c><00:03:21.769><c> neural</c><00:03:21.950><c> network</c>

00:03:22.420 --> 00:03:22.430 align:start position:0%
layer as you train the neural network
 

00:03:22.430 --> 00:03:24.640 align:start position:0%
layer as you train the neural network
across<00:03:22.790><c> different</c><00:03:23.299><c> mini</c><00:03:23.450><c> batches</c><00:03:23.750><c> then</c>

00:03:24.640 --> 00:03:24.650 align:start position:0%
across different mini batches then
 

00:03:24.650 --> 00:03:28.030 align:start position:0%
across different mini batches then
finally<00:03:25.250><c> at</c><00:03:25.459><c> test</c><00:03:25.910><c> time</c><00:03:26.030><c> what</c><00:03:26.930><c> you</c><00:03:27.049><c> do</c><00:03:27.290><c> is</c><00:03:27.650><c> in</c>

00:03:28.030 --> 00:03:28.040 align:start position:0%
finally at test time what you do is in
 

00:03:28.040 --> 00:03:31.030 align:start position:0%
finally at test time what you do is in
place<00:03:28.640><c> of</c><00:03:28.880><c> this</c><00:03:29.180><c> equation</c><00:03:29.810><c> you</c><00:03:30.680><c> would</c><00:03:30.799><c> just</c>

00:03:31.030 --> 00:03:31.040 align:start position:0%
place of this equation you would just
 

00:03:31.040 --> 00:03:34.599 align:start position:0%
place of this equation you would just
compute<00:03:31.489><c> Z</c><00:03:32.000><c> norm</c><00:03:32.650><c> using</c><00:03:33.650><c> whatever</c><00:03:34.069><c> value</c><00:03:34.579><c> you</c>

00:03:34.599 --> 00:03:34.609 align:start position:0%
compute Z norm using whatever value you
 

00:03:34.609 --> 00:03:37.259 align:start position:0%
compute Z norm using whatever value you
see<00:03:35.000><c> you</c><00:03:35.180><c> have</c><00:03:35.390><c> and</c><00:03:35.690><c> using</c><00:03:36.680><c> your</c>

00:03:37.259 --> 00:03:37.269 align:start position:0%
see you have and using your
 

00:03:37.269 --> 00:03:40.539 align:start position:0%
see you have and using your
exponentially<00:03:38.269><c> weighted</c><00:03:38.420><c> average</c><00:03:39.019><c> of</c><00:03:39.230><c> the</c><00:03:39.890><c> MU</c>

00:03:40.539 --> 00:03:40.549 align:start position:0%
exponentially weighted average of the MU
 

00:03:40.549 --> 00:03:41.949 align:start position:0%
exponentially weighted average of the MU
and<00:03:40.700><c> Sigma</c><00:03:40.790><c> squared</c><00:03:41.359><c> whatever</c><00:03:41.569><c> was</c><00:03:41.840><c> the</c>

00:03:41.949 --> 00:03:41.959 align:start position:0%
and Sigma squared whatever was the
 

00:03:41.959 --> 00:03:44.710 align:start position:0%
and Sigma squared whatever was the
latest<00:03:42.350><c> value</c><00:03:42.680><c> you</c><00:03:42.829><c> have</c><00:03:42.880><c> to</c><00:03:43.880><c> do</c><00:03:44.060><c> the</c><00:03:44.209><c> scaling</c>

00:03:44.710 --> 00:03:44.720 align:start position:0%
latest value you have to do the scaling
 

00:03:44.720 --> 00:03:48.430 align:start position:0%
latest value you have to do the scaling
here<00:03:45.019><c> and</c><00:03:45.230><c> then</c><00:03:45.709><c> you</c><00:03:45.920><c> would</c><00:03:47.170><c> compute</c><00:03:48.170><c> each</c>

00:03:48.430 --> 00:03:48.440 align:start position:0%
here and then you would compute each
 

00:03:48.440 --> 00:03:51.759 align:start position:0%
here and then you would compute each
other<00:03:48.739><c> on</c><00:03:49.130><c> your</c><00:03:49.700><c> one</c><00:03:49.880><c> test</c><00:03:50.150><c> example</c><00:03:50.769><c> using</c>

00:03:51.759 --> 00:03:51.769 align:start position:0%
other on your one test example using
 

00:03:51.769 --> 00:03:53.620 align:start position:0%
other on your one test example using
that<00:03:51.980><c> Z</c><00:03:52.280><c> norm</c><00:03:52.579><c> that</c><00:03:52.790><c> we</c><00:03:52.880><c> just</c><00:03:53.060><c> computed</c><00:03:53.480><c> on</c><00:03:53.600><c> the</c>

00:03:53.620 --> 00:03:53.630 align:start position:0%
that Z norm that we just computed on the
 

00:03:53.630 --> 00:03:57.490 align:start position:0%
that Z norm that we just computed on the
left<00:03:53.959><c> and</c><00:03:54.280><c> using</c><00:03:55.280><c> the</c><00:03:55.519><c> beta</c><00:03:56.180><c> and</c><00:03:56.660><c> gamma</c>

00:03:57.490 --> 00:03:57.500 align:start position:0%
left and using the beta and gamma
 

00:03:57.500 --> 00:04:00.190 align:start position:0%
left and using the beta and gamma
parameters<00:03:58.310><c> then</c><00:03:58.760><c> you'll</c><00:03:59.329><c> you</c><00:03:59.810><c> have</c><00:03:59.959><c> learned</c>

00:04:00.190 --> 00:04:00.200 align:start position:0%
parameters then you'll you have learned
 

00:04:00.200 --> 00:04:01.449 align:start position:0%
parameters then you'll you have learned
during<00:04:00.470><c> your</c><00:04:00.560><c> neural</c><00:04:00.889><c> network</c><00:04:01.220><c> training</c>

00:04:01.449 --> 00:04:01.459 align:start position:0%
during your neural network training
 

00:04:01.459 --> 00:04:04.330 align:start position:0%
during your neural network training
process<00:04:02.000><c> so</c><00:04:02.900><c> the</c><00:04:03.260><c> takeaway</c><00:04:03.680><c> from</c><00:04:03.739><c> this</c><00:04:04.100><c> is</c>

00:04:04.330 --> 00:04:04.340 align:start position:0%
process so the takeaway from this is
 

00:04:04.340 --> 00:04:07.360 align:start position:0%
process so the takeaway from this is
that<00:04:04.400><c> during</c><00:04:05.120><c> training</c><00:04:05.690><c> time</c><00:04:05.930><c> mu</c><00:04:06.739><c> and</c><00:04:06.980><c> Sigma</c>

00:04:07.360 --> 00:04:07.370 align:start position:0%
that during training time mu and Sigma
 

00:04:07.370 --> 00:04:09.400 align:start position:0%
that during training time mu and Sigma
squared<00:04:07.670><c> are</c><00:04:07.880><c> computed</c><00:04:08.420><c> on</c><00:04:08.630><c> an</c><00:04:08.780><c> entire</c><00:04:09.139><c> mini</c>

00:04:09.400 --> 00:04:09.410 align:start position:0%
squared are computed on an entire mini
 

00:04:09.410 --> 00:04:12.129 align:start position:0%
squared are computed on an entire mini
batch<00:04:09.680><c> of</c><00:04:10.010><c> you</c><00:04:10.250><c> know</c><00:04:10.340><c> say</c><00:04:10.639><c> 64</c><00:04:11.209><c> and</c><00:04:11.420><c> June</c><00:04:11.569><c> 28</c><00:04:11.989><c> or</c>

00:04:12.129 --> 00:04:12.139 align:start position:0%
batch of you know say 64 and June 28 or
 

00:04:12.139 --> 00:04:15.220 align:start position:0%
batch of you know say 64 and June 28 or
some<00:04:12.769><c> number</c><00:04:13.100><c> of</c><00:04:13.130><c> examples</c><00:04:13.780><c> but</c><00:04:14.780><c> at</c><00:04:14.900><c> test</c><00:04:15.139><c> time</c>

00:04:15.220 --> 00:04:15.230 align:start position:0%
some number of examples but at test time
 

00:04:15.230 --> 00:04:16.690 align:start position:0%
some number of examples but at test time
you<00:04:15.590><c> might</c><00:04:15.769><c> need</c><00:04:15.889><c> to</c><00:04:16.039><c> process</c><00:04:16.250><c> a</c><00:04:16.430><c> single</c>

00:04:16.690 --> 00:04:16.700 align:start position:0%
you might need to process a single
 

00:04:16.700 --> 00:04:19.509 align:start position:0%
you might need to process a single
example<00:04:17.299><c> at</c><00:04:17.359><c> a</c><00:04:17.450><c> time</c><00:04:17.530><c> so</c><00:04:18.530><c> the</c><00:04:18.919><c> way</c><00:04:19.070><c> to</c><00:04:19.100><c> do</c><00:04:19.370><c> that</c>

00:04:19.509 --> 00:04:19.519 align:start position:0%
example at a time so the way to do that
 

00:04:19.519 --> 00:04:21.759 align:start position:0%
example at a time so the way to do that
is<00:04:19.849><c> to</c><00:04:20.030><c> estimate</c><00:04:20.239><c> mu</c><00:04:20.539><c> and</c><00:04:20.959><c> Sigma</c><00:04:21.289><c> squared</c><00:04:21.590><c> from</c>

00:04:21.759 --> 00:04:21.769 align:start position:0%
is to estimate mu and Sigma squared from
 

00:04:21.769 --> 00:04:22.430 align:start position:0%
is to estimate mu and Sigma squared from
your<00:04:21.890><c> training</c>

00:04:22.430 --> 00:04:22.440 align:start position:0%
your training
 

00:04:22.440 --> 00:04:25.490 align:start position:0%
your training
and<00:04:22.850><c> there</c><00:04:23.850><c> many</c><00:04:24.060><c> ways</c><00:04:24.270><c> to</c><00:04:24.420><c> do</c><00:04:24.570><c> that</c><00:04:25.050><c> you</c>

00:04:25.490 --> 00:04:25.500 align:start position:0%
and there many ways to do that you
 

00:04:25.500 --> 00:04:27.410 align:start position:0%
and there many ways to do that you
couldn't<00:04:25.980><c> clearly</c><00:04:26.370><c> run</c><00:04:26.640><c> your</c><00:04:26.790><c> whole</c><00:04:26.970><c> training</c>

00:04:27.410 --> 00:04:27.420 align:start position:0%
couldn't clearly run your whole training
 

00:04:27.420 --> 00:04:29.720 align:start position:0%
couldn't clearly run your whole training
set<00:04:27.660><c> through</c><00:04:28.260><c> your</c><00:04:28.410><c> final</c><00:04:28.650><c> network</c><00:04:29.160><c> to</c><00:04:29.370><c> get</c><00:04:29.520><c> mu</c>

00:04:29.720 --> 00:04:29.730 align:start position:0%
set through your final network to get mu
 

00:04:29.730 --> 00:04:31.760 align:start position:0%
set through your final network to get mu
and<00:04:29.910><c> Sigma</c><00:04:30.180><c> squared</c><00:04:30.510><c> but</c><00:04:31.080><c> in</c><00:04:31.200><c> practice</c><00:04:31.590><c> what</c>

00:04:31.760 --> 00:04:31.770 align:start position:0%
and Sigma squared but in practice what
 

00:04:31.770 --> 00:04:33.500 align:start position:0%
and Sigma squared but in practice what
people<00:04:32.100><c> usually</c><00:04:32.280><c> do</c><00:04:32.670><c> is</c><00:04:32.820><c> implement</c><00:04:33.150><c> an</c>

00:04:33.500 --> 00:04:33.510 align:start position:0%
people usually do is implement an
 

00:04:33.510 --> 00:04:35.480 align:start position:0%
people usually do is implement an
exponentially<00:04:34.020><c> weighted</c><00:04:34.140><c> average</c><00:04:34.740><c> where</c><00:04:34.950><c> you</c>

00:04:35.480 --> 00:04:35.490 align:start position:0%
exponentially weighted average where you
 

00:04:35.490 --> 00:04:37.730 align:start position:0%
exponentially weighted average where you
just<00:04:35.790><c> keep</c><00:04:36.270><c> track</c><00:04:36.510><c> of</c><00:04:36.780><c> the</c><00:04:36.930><c> new</c><00:04:37.140><c> and</c><00:04:37.380><c> Sigma</c>

00:04:37.730 --> 00:04:37.740 align:start position:0%
just keep track of the new and Sigma
 

00:04:37.740 --> 00:04:39.140 align:start position:0%
just keep track of the new and Sigma
squared<00:04:38.040><c> values</c><00:04:38.460><c> you've</c><00:04:38.640><c> seen</c><00:04:38.880><c> during</c>

00:04:39.140 --> 00:04:39.150 align:start position:0%
squared values you've seen during
 

00:04:39.150 --> 00:04:41.210 align:start position:0%
squared values you've seen during
training<00:04:39.720><c> and</c><00:04:39.900><c> use</c><00:04:40.560><c> an</c><00:04:40.740><c> exponentially</c>

00:04:41.210 --> 00:04:41.220 align:start position:0%
training and use an exponentially
 

00:04:41.220 --> 00:04:43.040 align:start position:0%
training and use an exponentially
weighted<00:04:41.340><c> average</c><00:04:41.820><c> also</c><00:04:42.300><c> sometimes</c><00:04:42.720><c> called</c><00:04:42.990><c> a</c>

00:04:43.040 --> 00:04:43.050 align:start position:0%
weighted average also sometimes called a
 

00:04:43.050 --> 00:04:45.170 align:start position:0%
weighted average also sometimes called a
running<00:04:43.410><c> average</c><00:04:43.560><c> to</c><00:04:44.430><c> just</c><00:04:44.640><c> get</c><00:04:44.850><c> a</c><00:04:44.880><c> rough</c>

00:04:45.170 --> 00:04:45.180 align:start position:0%
running average to just get a rough
 

00:04:45.180 --> 00:04:47.030 align:start position:0%
running average to just get a rough
estimate<00:04:45.630><c> of</c><00:04:45.810><c> mu</c><00:04:46.020><c> and</c><00:04:46.050><c> Sigma</c><00:04:46.470><c> squared</c><00:04:46.770><c> and</c>

00:04:47.030 --> 00:04:47.040 align:start position:0%
estimate of mu and Sigma squared and
 

00:04:47.040 --> 00:04:48.950 align:start position:0%
estimate of mu and Sigma squared and
then<00:04:47.520><c> you</c><00:04:47.550><c> use</c><00:04:47.880><c> those</c><00:04:48.120><c> values</c><00:04:48.570><c> of</c><00:04:48.690><c> MU</c><00:04:48.810><c> and</c>

00:04:48.950 --> 00:04:48.960 align:start position:0%
then you use those values of MU and
 

00:04:48.960 --> 00:04:51.830 align:start position:0%
then you use those values of MU and
Sigma<00:04:49.020><c> square</c><00:04:49.800><c> that</c><00:04:49.830><c> test</c><00:04:50.220><c> time</c><00:04:50.510><c> to</c><00:04:51.510><c> do</c><00:04:51.690><c> the</c>

00:04:51.830 --> 00:04:51.840 align:start position:0%
Sigma square that test time to do the
 

00:04:51.840 --> 00:04:54.530 align:start position:0%
Sigma square that test time to do the
scaling<00:04:52.350><c> you</c><00:04:52.500><c> need</c><00:04:52.710><c> of</c><00:04:52.980><c> the</c><00:04:53.280><c> hidden</c><00:04:54.210><c> unit</c>

00:04:54.530 --> 00:04:54.540 align:start position:0%
scaling you need of the hidden unit
 

00:04:54.540 --> 00:04:57.650 align:start position:0%
scaling you need of the hidden unit
values<00:04:54.960><c> z</c><00:04:55.410><c> in</c><00:04:55.680><c> practice</c><00:04:56.550><c> this</c><00:04:56.910><c> process</c><00:04:57.450><c> is</c>

00:04:57.650 --> 00:04:57.660 align:start position:0%
values z in practice this process is
 

00:04:57.660 --> 00:05:00.560 align:start position:0%
values z in practice this process is
pretty<00:04:58.170><c> robust</c><00:04:58.740><c> to</c><00:04:59.100><c> the</c><00:04:59.340><c> exact</c><00:04:59.760><c> way</c><00:05:00.060><c> you</c><00:05:00.120><c> use</c>

00:05:00.560 --> 00:05:00.570 align:start position:0%
pretty robust to the exact way you use
 

00:05:00.570 --> 00:05:03.560 align:start position:0%
pretty robust to the exact way you use
to<00:05:00.840><c> estimate</c><00:05:01.020><c> mu</c><00:05:01.500><c> and</c><00:05:01.680><c> Sigma</c><00:05:01.980><c> squared</c><00:05:02.540><c> so</c><00:05:03.540><c> I</c>

00:05:03.560 --> 00:05:03.570 align:start position:0%
to estimate mu and Sigma squared so I
 

00:05:03.570 --> 00:05:05.750 align:start position:0%
to estimate mu and Sigma squared so I
wouldn't<00:05:03.960><c> worry</c><00:05:04.260><c> too</c><00:05:04.380><c> much</c><00:05:04.680><c> about</c><00:05:04.890><c> exactly</c>

00:05:05.750 --> 00:05:05.760 align:start position:0%
wouldn't worry too much about exactly
 

00:05:05.760 --> 00:05:08.270 align:start position:0%
wouldn't worry too much about exactly
how<00:05:05.940><c> you</c><00:05:06.000><c> do</c><00:05:06.360><c> this</c><00:05:06.570><c> and</c><00:05:06.870><c> if</c><00:05:07.740><c> you're</c><00:05:07.890><c> using</c><00:05:08.100><c> a</c>

00:05:08.270 --> 00:05:08.280 align:start position:0%
how you do this and if you're using a
 

00:05:08.280 --> 00:05:10.130 align:start position:0%
how you do this and if you're using a
deep<00:05:08.460><c> learning</c><00:05:08.640><c> framework</c><00:05:09.270><c> they'll</c><00:05:09.810><c> usually</c>

00:05:10.130 --> 00:05:10.140 align:start position:0%
deep learning framework they'll usually
 

00:05:10.140 --> 00:05:14.600 align:start position:0%
deep learning framework they'll usually
have<00:05:10.380><c> some</c><00:05:10.830><c> default</c><00:05:11.310><c> way</c><00:05:11.520><c> to</c><00:05:12.330><c> estimate</c><00:05:13.430><c> mu</c><00:05:14.430><c> and</c>

00:05:14.600 --> 00:05:14.610 align:start position:0%
have some default way to estimate mu and
 

00:05:14.610 --> 00:05:16.580 align:start position:0%
have some default way to estimate mu and
Sigma<00:05:14.970><c> squared</c><00:05:15.300><c> tension</c><00:05:15.780><c> work</c><00:05:15.960><c> reasonably</c>

00:05:16.580 --> 00:05:16.590 align:start position:0%
Sigma squared tension work reasonably
 

00:05:16.590 --> 00:05:18.940 align:start position:0%
Sigma squared tension work reasonably
well<00:05:16.710><c> as</c><00:05:17.040><c> well</c><00:05:17.280><c> but</c><00:05:17.970><c> in</c><00:05:18.120><c> practice</c><00:05:18.540><c> any</c>

00:05:18.940 --> 00:05:18.950 align:start position:0%
well as well but in practice any
 

00:05:18.950 --> 00:05:21.560 align:start position:0%
well as well but in practice any
reasonable<00:05:19.950><c> way</c><00:05:20.100><c> to</c><00:05:20.130><c> estimate</c><00:05:20.850><c> the</c><00:05:21.030><c> mean</c><00:05:21.240><c> and</c>

00:05:21.560 --> 00:05:21.570 align:start position:0%
reasonable way to estimate the mean and
 

00:05:21.570 --> 00:05:26.270 align:start position:0%
reasonable way to estimate the mean and
variance<00:05:21.990><c> of</c><00:05:22.710><c> your</c><00:05:23.670><c> hidden</c><00:05:24.660><c> unit</c><00:05:25.140><c> values</c><00:05:25.830><c> of</c><00:05:26.040><c> Z</c>

00:05:26.270 --> 00:05:26.280 align:start position:0%
variance of your hidden unit values of Z
 

00:05:26.280 --> 00:05:29.840 align:start position:0%
variance of your hidden unit values of Z
should<00:05:27.030><c> work</c><00:05:27.270><c> fine</c><00:05:27.570><c> and</c><00:05:27.960><c> test</c><00:05:28.170><c> so</c><00:05:28.740><c> that's</c><00:05:28.980><c> it</c><00:05:29.310><c> -</c>

00:05:29.840 --> 00:05:29.850 align:start position:0%
should work fine and test so that's it -
 

00:05:29.850 --> 00:05:32.000 align:start position:0%
should work fine and test so that's it -
dome<00:05:30.180><c> and</c><00:05:30.450><c> using</c><00:05:30.960><c> it</c><00:05:31.080><c> I</c><00:05:31.260><c> think</c><00:05:31.650><c> you'll</c><00:05:31.830><c> be</c><00:05:31.950><c> able</c>

00:05:32.000 --> 00:05:32.010 align:start position:0%
dome and using it I think you'll be able
 

00:05:32.010 --> 00:05:34.430 align:start position:0%
dome and using it I think you'll be able
to<00:05:32.160><c> train</c><00:05:32.430><c> much</c><00:05:32.940><c> deeper</c><00:05:33.360><c> networks</c><00:05:33.810><c> and</c><00:05:34.170><c> get</c>

00:05:34.430 --> 00:05:34.440 align:start position:0%
to train much deeper networks and get
 

00:05:34.440 --> 00:05:36.320 align:start position:0%
to train much deeper networks and get
your<00:05:34.590><c> learning</c><00:05:34.890><c> album</c><00:05:35.160><c> to</c><00:05:35.340><c> run</c><00:05:35.550><c> much</c><00:05:36.120><c> more</c>

00:05:36.320 --> 00:05:36.330 align:start position:0%
your learning album to run much more
 

00:05:36.330 --> 00:05:38.630 align:start position:0%
your learning album to run much more
quickly<00:05:36.770><c> before</c><00:05:37.770><c> we</c><00:05:37.830><c> wrap</c><00:05:38.040><c> up</c><00:05:38.220><c> for</c><00:05:38.250><c> this</c><00:05:38.430><c> video</c>

00:05:38.630 --> 00:05:38.640 align:start position:0%
quickly before we wrap up for this video
 

00:05:38.640 --> 00:05:40.430 align:start position:0%
quickly before we wrap up for this video
I<00:05:38.910><c> want</c><00:05:39.120><c> to</c><00:05:39.180><c> share</c><00:05:39.390><c> you</c><00:05:39.660><c> some</c><00:05:39.900><c> thoughts</c><00:05:40.140><c> on</c>

00:05:40.430 --> 00:05:40.440 align:start position:0%
I want to share you some thoughts on
 

00:05:40.440 --> 00:05:43.190 align:start position:0%
I want to share you some thoughts on
deep<00:05:41.190><c> learning</c><00:05:41.220><c> frameworks</c><00:05:42.210><c> as</c><00:05:42.450><c> well</c><00:05:42.660><c> let's</c>

00:05:43.190 --> 00:05:43.200 align:start position:0%
deep learning frameworks as well let's
 

00:05:43.200 --> 00:05:44.690 align:start position:0%
deep learning frameworks as well let's
start<00:05:43.410><c> to</c><00:05:43.470><c> talk</c><00:05:43.560><c> about</c><00:05:43.980><c> that</c><00:05:44.190><c> in</c><00:05:44.460><c> the</c><00:05:44.550><c> next</c>

00:05:44.690 --> 00:05:44.700 align:start position:0%
start to talk about that in the next
 

00:05:44.700 --> 00:05:47.060 align:start position:0%
start to talk about that in the next
video

