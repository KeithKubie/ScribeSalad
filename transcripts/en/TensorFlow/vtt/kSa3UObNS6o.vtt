WEBVTT
Kind: captions
Language: en

00:00:04.969 --> 00:00:06.649
Good morning, everybody.

00:00:07.429 --> 00:00:08.539
I'm Anitha Vijayakumar,

00:00:08.539 --> 00:00:11.319
Technical Program Manager for TensorFlow.

00:00:11.319 --> 00:00:13.839
Welcome. Good morning to all of you.

00:00:14.399 --> 00:00:18.959
It's really exciting to be here
with all of you today,

00:00:18.959 --> 00:00:23.429
and welcome to the 2018 
TensorFlow Developer Summit.

00:00:23.429 --> 00:00:26.835
We have a packed day 
filled with lots of interesting talks,

00:00:26.835 --> 00:00:28.846
and some really cool demos.

00:00:28.846 --> 00:00:31.406
We hope you enjoy it as much as we do.

00:00:32.796 --> 00:00:36.702
As you know, we are together embarking 
on a transformative journey

00:00:36.702 --> 00:00:39.969
in the field of machine learning 
and artificial intelligence.

00:00:39.969 --> 00:00:44.589
Problems that were impossible 
or too complex are now possible

00:00:44.589 --> 00:00:46.799
to solve using this technology.

00:00:47.039 --> 00:00:49.379
This field is unleashing new frontiers

00:00:49.379 --> 00:00:54.439
and substantially changing many aspects 
of our lives in a meaningful way.

00:00:55.015 --> 00:00:58.897
We’ve already seen great 
advantages in many different areas

00:00:58.897 --> 00:01:00.760
with machine learning.

00:01:00.760 --> 00:01:04.590
Some examples are: 
In the field of astronomy,

00:01:04.590 --> 00:01:08.029
hunting for new planets is no easy task.

00:01:08.029 --> 00:01:13.550
These planets are small, cold, 
dark objects compared to their host star.

00:01:13.550 --> 00:01:17.684
Researchers and astrophysicists
have analyzed large amounts

00:01:17.684 --> 00:01:21.604
of data from the Kepler mission,
and by using machine learning

00:01:21.604 --> 00:01:25.844
have discovered a brand new planet 
called the Kepler-90i,

00:01:26.682 --> 00:01:32.739
making it the only 8-planet solar system 
that we know of in our universe

00:01:32.739 --> 00:01:34.518
other than our own.

00:01:35.529 --> 00:01:39.357
In healthcare, we have discovered 
that looking at scans

00:01:39.357 --> 00:01:42.558
of the human eye, 
machine learning can assess

00:01:42.558 --> 00:01:45.598
a person’s risk 
for cardiovascular diseases.

00:01:46.137 --> 00:01:49.237
Just imagine if the screening 
can be done with a mobile device,

00:01:49.237 --> 00:01:51.238
how profound the effect will be.

00:01:51.896 --> 00:01:56.357
Suddenly the whole world 
will have access to rapid, easy,

00:01:56.357 --> 00:02:00.848
affordable non-invasive 
screening for heart diseases,

00:02:00.848 --> 00:02:03.019
saving lots of lives.

00:02:03.517 --> 00:02:08.338
In aviation, trajectory prediction 
is a critical component

00:02:08.338 --> 00:02:11.669
to ensuring that aircrafts can fly safely

00:02:11.669 --> 00:02:14.448
and efficiently in crowded spaces.

00:02:14.807 --> 00:02:17.910
Engineers and air traffic 
controllers in Europe are using

00:02:17.910 --> 00:02:20.944
machine learning to predict 
the trajectory of a flight

00:02:20.944 --> 00:02:26.056
through the air spaces of Belgium, 
Luxembourg, Germany, and the Netherlands.

00:02:26.821 --> 00:02:30.898
This has more than 1.8 million 
flights per year and is one of the most

00:02:30.898 --> 00:02:33.916
dense and complex air spaces 
in the world.

00:02:34.828 --> 00:02:39.316
In dairy farming, we know 
that a cow’s health is vital

00:02:39.316 --> 00:02:41.928
to the survival of the dairy industry.

00:02:41.928 --> 00:02:45.027
And folks at [inaudible], our company
in the Netherlands wondered

00:02:45.027 --> 00:02:49.077
if they can use machine learning 
to track the health of cows

00:02:49.077 --> 00:02:53.747
and be able to provide insight 
to farmers and veterinarians on actions

00:02:53.747 --> 00:02:57.958
to be taken to ensure 
we have happy, healthy cows

00:02:57.958 --> 00:03:00.868
that are high-yielding. 
So we now have happy cows

00:03:00.868 --> 00:03:03.657
not only from California 
but also the Netherlands.

00:03:06.508 --> 00:03:09.146
Fighting climate change: 
Fighting climate change

00:03:09.146 --> 00:03:12.927
and protecting our forests, 
we believe the technology

00:03:12.936 --> 00:03:16.128
has a huge role to play. 
A group of engineers

00:03:16.128 --> 00:03:19.928
and scientists have built 
real-time detection and alerting

00:03:19.937 --> 00:03:25.318
mechanisms to detect logging of trees. 
They listen to real-time data

00:03:25.318 --> 00:03:28.357
from chainsaw sounds, 
from trucking sounds,

00:03:28.357 --> 00:03:30.967
from logging sounds, 
and machine learning is fighting

00:03:30.967 --> 00:03:34.338
deforestation and protecting 
our precious rainforests.

00:03:35.658 --> 00:03:40.557
In music: There are many machine learning 
algorithms using deep neural networks

00:03:40.557 --> 00:03:45.999
that can learn the characteristics 
of sounds and create completely new music

00:03:45.999 --> 00:03:48.159
based on these characteristics.

00:03:49.326 --> 00:03:53.077
In arts and culture: 
You can even search

00:03:53.077 --> 00:03:57.847
if you have a long-lost twin 
from the past by looking at oil paintings

00:03:59.237 --> 00:04:04.555
using apps that are based on machine 
learning. How cool is that?

00:04:05.484 --> 00:04:11.164
At Google, we are an AI first company 
and every product is being fundamentally

00:04:11.164 --> 00:04:16.014
impacted and changed by machine learning,
be it the popular Google Home,

00:04:16.014 --> 00:04:20.014
or the Pixel, or Search, or Youtube, 
or even Maps.

00:04:20.819 --> 00:04:23.852
Do you know what is fascinating 
in all of these examples?

00:04:25.011 --> 00:04:30.400
TensorFlow is at the forefront of them, 
making it all possible,

00:04:30.901 --> 00:04:32.311
a machine learning platform

00:04:32.311 --> 00:04:35.992
that can solve challenging problems
for all of us.

00:04:35.992 --> 00:04:40.971
Join us on this incredible 
journey to make TensorFlow powerful,

00:04:40.971 --> 00:04:44.912
scalable, and the best machine learning 
platform for everybody.

00:04:46.029 --> 00:04:49.764
I now invite Rajat, Director 
of Engineering of TensorFlow,

00:04:49.764 --> 00:04:52.899
to tell us more about this. Thank you.

00:04:52.899 --> 00:04:54.749
(applause)

00:04:57.906 --> 00:04:59.896
Hello everyone. Good morning.

00:05:00.997 --> 00:05:02.265
Thanks, Anita.

00:05:02.595 --> 00:05:04.505
So let’s a look 
at what we’ve been doing

00:05:04.505 --> 00:05:07.316
over the last two years. 
It’s been really amazing,

00:05:07.316 --> 00:05:10.286
with lots of new releases. 
We’ve seen the popularity

00:05:10.286 --> 00:05:13.776
of TensorFlow really grow 
over the last two years.

00:05:13.776 --> 00:05:16.462
Especially over the last year, 
we’ve focused on making

00:05:16.462 --> 00:05:21.572
TensorFlow easy to use, 
and with the release of high-level APIs

00:05:21.572 --> 00:05:25.872
like tf.data and tf.keras, 
and new programming paradigms

00:05:25.872 --> 00:05:29.542
like Eager Execution, 
really continue to make that easier.

00:05:30.533 --> 00:05:34.293
Earlier this year, we hit the milestone 
of 11 million downloads.

00:05:34.293 --> 00:05:37.223
We are really excited to see 
how much users are using this

00:05:37.223 --> 00:05:39.513
and how much impact 
it’s having in the world.

00:05:42.116 --> 00:05:46.546
So here’s a map showing self-identified 
locations of folks on GitHub

00:05:46.546 --> 00:05:49.333
that have started TensorFlow. 
And you can see that it goes

00:05:49.333 --> 00:05:53.173
all the way up to the Arctic Circle 
of [inaudible] Norway

00:05:53.173 --> 00:05:57.103
and all the way down to Deception Island, 
which is part of Antarctica.

00:05:57.103 --> 00:06:00.633
In fact, TensorFlow is used in every 
single time zone in the world.

00:06:03.565 --> 00:06:07.235
An important part of any open-source 
project are the contributors themselves.

00:06:07.325 --> 00:06:09.475
You know, the community is 
made of the people

00:06:09.475 --> 00:06:11.555
who make this project successful.

00:06:11.555 --> 00:06:16.495
I’m excited to see over a thousand 
contributors from outside Google

00:06:16.495 --> 00:06:19.735
who are making contributions 
not just by improving code

00:06:19.735 --> 00:06:23.405
but also by helping the rest 
of the community by answering questions,

00:06:23.405 --> 00:06:25.485
responding to queries, and so on.

00:06:28.525 --> 00:06:34.215
Our commitment to this community
is by sharing our direction in a roadmap,

00:06:34.215 --> 00:06:39.625
inviting public participation on design
direction, and by creating SIGs that help

00:06:39.625 --> 00:06:45.445
focus collaboration on the key needs,
like built-in packaging of TensorBoard.

00:06:45.445 --> 00:06:49.445
And we’ll be talking more about this 
in detail later this afternoon.

00:06:51.521 --> 00:06:53.941
Today we are launching 
a new TensorFlow blog.

00:06:55.211 --> 00:06:56.931
They’ll be sharing work by the team

00:06:56.931 --> 00:06:59.911
and the community on this blog,
and we would like to invite you

00:06:59.911 --> 00:07:01.441
to participate in this as well.

00:07:01.941 --> 00:07:03.971
We’re also launching 
a new YouTube channel

00:07:03.971 --> 00:07:07.971
for TensorFlow that brings 
together all the great content

00:07:07.971 --> 00:07:12.841
that’s been created for TensorFlow. 
Again, all of these are for the community

00:07:12.841 --> 00:07:17.111
to really help build and communicate. 
All day today, we’ll be sharing a number

00:07:17.111 --> 00:07:20.841
of posts from the blog 
and videos on the channel.

00:07:20.841 --> 00:07:24.201
The talks you’re hearing here will be 
made available there as well,

00:07:24.201 --> 00:07:26.271
along with lots of conversations

00:07:26.271 --> 00:07:31.961
and interviews with the speakers. 
To make reuse and sharing easier,

00:07:31.961 --> 00:07:37.251
today we are launching TensorFlow Hub. 
This library of model components

00:07:37.251 --> 00:07:40.811
is easily integrated into your models 
with just a single line of code.

00:07:40.811 --> 00:07:44.201
Now again, it goes back to really 
making things easy for you.

00:07:47.244 --> 00:07:49.964
Machine learning is important 
and powerful, as you saw.

00:07:49.964 --> 00:07:52.344
We care about bringing it 
to more and more people.

00:07:52.344 --> 00:07:54.474
As part of this effort, 
we recently released

00:07:54.474 --> 00:07:56.164
the Machine Learning Crash Course,

00:07:56.164 --> 00:07:59.454
focused on introducing this 
to a much broader audience.

00:07:59.454 --> 00:08:01.744
The same course that’s trained thousands

00:08:01.744 --> 00:08:05.184
of Googlers in machine learning
and allows us to integrate them now

00:08:05.184 --> 00:08:08.484
into everything we build,
is now available to everyone.

00:08:11.064 --> 00:08:15.194
TensorFlow started as a library 
for numerical computation,

00:08:15.194 --> 00:08:18.714
with a focus on deep learning 
and neural networks.

00:08:18.714 --> 00:08:21.214
Since the early release, 
it’s grown to include

00:08:21.214 --> 00:08:24.324
a very rich collection 
of machine learning algorithms.

00:08:24.324 --> 00:08:28.964
It includes popular algorithms 
like linear regressions and decision trees

00:08:28.964 --> 00:08:32.614
commonly used for many 
structured data classification problems.

00:08:32.614 --> 00:08:36.184
There’s also a very broad collection 
of state-of-the-art tools

00:08:36.184 --> 00:08:40.194
for stats and basic analysis
in the TF public library,

00:08:40.194 --> 00:08:43.574
and several new additions 
are being released today.

00:08:43.574 --> 00:08:46.664
You can check out the blog post 
and website for more details.

00:08:49.902 --> 00:08:53.823
As I mentioned earlier, one of the big 
key focus points for us is to make

00:08:53.823 --> 00:08:57.903
TensorFlow easy to use, and towards 
that we’ve been pushing on simpler APIs,

00:08:57.903 --> 00:09:00.473
easier to use and making them 
more intuitive.

00:09:01.333 --> 00:09:06.073
At the lowest level, our focus is 
to consolidate a lot of the APIs we have

00:09:06.073 --> 00:09:08.803
and make it easier to build 
these models and train them.

00:09:09.223 --> 00:09:11.162
At the lowest level, the TensorFlow APIs

00:09:11.162 --> 00:09:15.213
are really, really flexible, and they let 
users build anything they want to.

00:09:15.213 --> 00:09:18.823
With Eager Execution, these same APIs
are now easier to use.

00:09:20.083 --> 00:09:23.872
TensorFlow also contains 
a full implementation of Keras.

00:09:23.872 --> 00:09:26.462
TF Keras contains 
building blocks like layers

00:09:26.462 --> 00:09:30.101
to build models to make it easier 
to do that and offers

00:09:30.101 --> 00:09:32.500
lots of utilities to train them as well.

00:09:32.900 --> 00:09:36.500
Keras works with both Graph 
and Eager Execution as well.

00:09:38.110 --> 00:09:40.853
For Distributed Execution, 
we provide Estimators,

00:09:40.853 --> 00:09:43.725
so you can take your models 
and combine them with estimators

00:09:43.725 --> 00:09:45.415
to distribute them across machines.

00:09:46.135 --> 00:09:49.675
You can also build estimators 
from the Keras layers or models.

00:09:49.675 --> 00:09:53.684
And finally, we provide 
premade estimators, a library

00:09:53.684 --> 00:09:58.035
of ready-to-go implementations 
of common machine learning algorithms.

00:09:59.175 --> 00:10:01.094
So let’s take a look at how this works.

00:10:01.244 --> 00:10:04.694
So first you would often define 
your model, and this is a nice easy way

00:10:04.694 --> 00:10:08.000
to define your model. 
It shows a convolution model here,

00:10:08.000 --> 00:10:09.910
with just a few lines here.

00:10:09.910 --> 00:10:12.581
Now, once you have defined that, 
often you’d want to do

00:10:12.581 --> 00:10:16.124
some input processing, so in this case,
you load your data set from files.

00:10:16.124 --> 00:10:20.234
And we have a great API <i>tf.data</i>
that was introduced in 1.4 that makes

00:10:20.234 --> 00:10:24.864
it easy for you to process inputs 
while still allowing us to do lots

00:10:24.864 --> 00:10:27.283
of optimizations behind the scenes.

00:10:27.283 --> 00:10:30.876
And you’ll see a lot more detail 
on this later today as well.

00:10:33.746 --> 00:10:36.725
Once you have the model
and the input data,

00:10:36.725 --> 00:10:39.518
you can put them together
by iterating all the datasets,

00:10:39.518 --> 00:10:42.518
computing gradients, 
and updating the parameters themselves.

00:10:42.518 --> 00:10:45.718
As you can see here, you really just 
need a few lines of Python

00:10:45.718 --> 00:10:47.058
to put these together.

00:10:47.058 --> 00:10:49.937
And in fact, it runs just 
as Python does, and you can use

00:10:49.937 --> 00:10:53.457
your Python debugger to debug that 
and solve problems as well.

00:10:54.384 --> 00:10:57.428
Of course, you can do it
in even fewer lines by just using

00:10:57.428 --> 00:10:59.947
the pre-defined utilities 
that we have with Keras.

00:11:01.957 --> 00:11:04.819
In this case, it executes the model 
as a graph with all

00:11:04.819 --> 00:11:07.368
the additional optimizations 
that come with it.

00:11:09.008 --> 00:11:12.768
Now, this is great for a single
machine or a single device.

00:11:12.828 --> 00:11:16.279
Now, often, given the high 
heavy computation needs

00:11:16.279 --> 00:11:20.170
for deep learning and machine learning, 
we want to use more than one accelerator

00:11:20.170 --> 00:11:22.548
or GPU or machines themselves.

00:11:22.968 --> 00:11:24.828
So for that we have estimators.

00:11:24.948 --> 00:11:27.557
Taking the same model 
that you’ve defined, the same data sets

00:11:27.557 --> 00:11:31.876
that you have, you can build 
an estimator and really use that to train

00:11:31.876 --> 00:11:35.526
across this cluster or across 
the multiple devices on a single machine.

00:11:35.976 --> 00:11:37.097
That’s great.

00:11:38.387 --> 00:11:40.077
Why not use a cluster?

00:11:40.077 --> 00:11:43.865
Why just use a single box if you can
actually train faster with that?

00:11:44.005 --> 00:11:47.345
This picture shows a TPU part used
for training ML models at scale.

00:11:48.105 --> 00:11:50.165
And again, the focus is to really take

00:11:50.165 --> 00:11:54.165
everything you’ve been doing 
and just build a TPU estimator

00:11:54.165 --> 00:11:58.165
that allows you to scale that same model 
across this entire super computer.

00:11:58.833 --> 00:12:01.213
And then, finally, 
once you’ve trained that model,

00:12:01.213 --> 00:12:03.913
you can use that one line
at the bottom to export that

00:12:03.913 --> 00:12:05.353
for deployment itself.

00:12:08.150 --> 00:12:09.970
So, you know,
deployment is important.

00:12:09.970 --> 00:12:12.490
You often do that in data centers. 
But more and more,

00:12:12.490 --> 00:12:17.030
we are seeing the need to deploy this 
on phones and other devices as well.

00:12:19.508 --> 00:12:21.518
And so for that, 
we have TensorFlow Lite.

00:12:21.718 --> 00:12:25.438
The model we just exported,
we have a script to convert that

00:12:25.438 --> 00:12:28.858
to a custom format 
that’s designed for devices,

00:12:28.858 --> 00:12:32.858
that’s lightweight, and it’s really 
faster to get started with.

00:12:32.858 --> 00:12:37.408
And then once you have that format, 
you can include that in your application,

00:12:38.358 --> 00:12:41.468
integrate TensorFlow Lite 
with a few lines here, and get going.

00:12:41.468 --> 00:12:43.328
You basically have an application

00:12:43.328 --> 00:12:47.428
that can do ML predictions 
and include ML in whatever task

00:12:47.428 --> 00:12:48.788
you want to perform.

00:12:51.328 --> 00:12:54.958
So TensorFlow runs not just on many 
platforms but in many languages as well.

00:12:56.318 --> 00:12:58.568
Today I’m excited to add 
Swift to the mix.

00:12:59.158 --> 00:13:01.958
And it brings with it a fresh
approach to machine learning.

00:13:02.628 --> 00:13:05.188
Don’t miss the talk 
by Chris Lattner this afternoon

00:13:05.188 --> 00:13:08.988
that covers exciting details 
of how we are enriching this platform.

00:13:12.008 --> 00:13:14.688
JavaScript is a language 
that’s synonymous with the web

00:13:14.688 --> 00:13:16.242
development community.

00:13:16.328 --> 00:13:18.868
I’m excited to announce TensorFlow.JS.

00:13:19.318 --> 00:13:22.048
It’s bringing machine learning 
to this growing community

00:13:22.048 --> 00:13:23.808
of exciting web developers.

00:13:24.658 --> 00:13:28.658
So let’s take a brief look at this. 
It brings the same TensorFlow operations

00:13:28.658 --> 00:13:32.198
that you’re used to into JavaScript 
for you-- you can call them just as plain

00:13:32.198 --> 00:13:36.018
JavaScript code-- along with full fledged
layers API on top.

00:13:36.018 --> 00:13:39.628
It also includes full support 
for TensorFlow and Keras models,

00:13:39.628 --> 00:13:42.458
so you can pick 
the most appropriate development

00:13:42.458 --> 00:13:44.699
and deployment environment
that works for you.

00:13:44.699 --> 00:13:46.459
So you can start in one place
and go to the other,

00:13:46.459 --> 00:13:47.829
whichever way you want.

00:13:47.829 --> 00:13:53.628
And under the covers, these APIs 
are accelerated in the browser via WebGL,

00:13:53.628 --> 00:13:55.769
and then the Node.js support 
is coming soon,

00:13:55.769 --> 00:13:57.704
which will give you the power
of all of TensorFlow

00:13:57.704 --> 00:14:00.124
to accelerate on CPUs
and GPUs as well.

00:14:01.414 --> 00:14:05.074
And with that, I would like to invite 
Megan Kacholia, Engineering Director

00:14:05.074 --> 00:14:08.434
of Google Brain, who leads our 
performance efforts, to talk a bit more

00:14:08.434 --> 00:14:10.544
about how TensorFlow does performance.

00:14:12.298 --> 00:14:13.608
Thank you.

00:14:16.068 --> 00:14:17.638
All right. Thanks, Rajat.

00:14:19.814 --> 00:14:23.271
So performance across all platforms
is critical to TensorFlow’s success.

00:14:23.481 --> 00:14:25.348
First, I want to take 
a quick step back

00:14:25.348 --> 00:14:27.928
and just talk about some 
of the things we think about

00:14:27.928 --> 00:14:30.768
when we’re measuring
and assessing TensorFlow’s performance.

00:14:30.768 --> 00:14:34.603
One of the things we try to do is focus
on real-world data and time-to-accuracy.

00:14:34.603 --> 00:14:37.208
It’s really important to have
reproducible benchmarks.

00:14:37.208 --> 00:14:38.738
We want to make sure 
those benchmarks

00:14:38.738 --> 00:14:39.978
are actually realistic

00:14:39.978 --> 00:14:41.458
of the workloads and types of things

00:14:41.458 --> 00:14:43.428
that users like you
are actually doing

00:14:43.428 --> 00:14:44.618
on a day-to-day basis.

00:14:44.938 --> 00:14:47.518
Another thing like Rajat 
talked about is that we want

00:14:47.518 --> 00:14:51.178
to make sure we have clean APIs. 
And we don’t want to have a fast version

00:14:51.178 --> 00:14:54.808
and a pretty version of something; 
the fast version is the pretty version.

00:14:54.808 --> 00:14:57.138
And so all of these APIs
that we’re talking about

00:14:57.138 --> 00:14:59.898
that we’re going to be talking 
about through various talks

00:14:59.898 --> 00:15:01.108
throughout the day today.

00:15:01.318 --> 00:15:02.318
These are the things you can use

00:15:02.318 --> 00:15:04.398
to get the best performance
out of TensorFlow

00:15:04.398 --> 00:15:07.455
so that you don’t have to worry about 
which one is fast, which one is pretty.

00:15:07.455 --> 00:15:09.658
Use the pretty one; it is fast!

00:15:09.658 --> 00:15:11.038
You’ll hear about <i>tf.data</i>

00:15:11.038 --> 00:15:13.058
from Derrick right after the keynote,

00:15:13.058 --> 00:15:16.038
as well as distribution strategy 
from Igor later today.

00:15:16.038 --> 00:15:18.208
And these are just some 
great examples of things we’ve been

00:15:18.208 --> 00:15:21.258
pushing on to ensure 
good performance and clean APIs.

00:15:21.518 --> 00:15:23.318
So in general we want to ensure

00:15:23.318 --> 00:15:25.298
that you have great performance, 
regardless of what type

00:15:25.298 --> 00:15:27.378
of platform you might 
be making use of.

00:15:27.378 --> 00:15:28.978
Whether it’s a large data center,

00:15:28.978 --> 00:15:30.908
like what’s shown here, or maybe 
you’re using something

00:15:30.908 --> 00:15:32.923
like what’s shown on the image here.

00:15:32.923 --> 00:15:35.963
You have a GPU or CPU box under
your desk, maybe you’re making

00:15:35.963 --> 00:15:39.243
use of a cloud platform, or mobile 
or an embedded device.

00:15:39.243 --> 00:15:41.803
Regardless of the type of hardware 
you’re making use of,

00:15:41.803 --> 00:15:42.673
we want to make sure

00:15:42.673 --> 00:15:45.433
that TensorFlow performs well 
across all of them.

00:15:45.783 --> 00:15:47.053
So now getting into some numbers,

00:15:47.053 --> 00:15:49.123
because what is a performance
talk if I don’t show you slides

00:15:49.123 --> 00:15:50.393
of numbers?

00:15:50.393 --> 00:15:53.103
So first let’s look at things 
on the mobile side.

00:15:53.103 --> 00:15:55.593
So this is highlighting 
TensorFlow Lite performance.

00:15:55.593 --> 00:15:58.323
So TensorFlow Lite
we initially released last fall.

00:15:58.323 --> 00:15:59.823
And there’s going to be a talk giving

00:15:59.823 --> 00:16:01.768
a lot more detail just about how it works

00:16:01.768 --> 00:16:03.258
and the things we were thinking of when

00:16:03.258 --> 00:16:05.158
making it later today by Sarah.

00:16:05.608 --> 00:16:07.538
But I wanted to call out just here

00:16:07.538 --> 00:16:09.108
the speedups we see in inference.

00:16:09.108 --> 00:16:10.948
So a 3x inference speedup when using

00:16:10.948 --> 00:16:15.248
TensorFlow Lite Quantized versus standard 
TensorFlow Lite for some

00:16:15.248 --> 00:16:16.958
of the models called out here.

00:16:16.958 --> 00:16:18.968
And again, it’s critical 
to have strong performance

00:16:18.968 --> 00:16:21.028
regardless of what platform 
you’re working on,

00:16:21.028 --> 00:16:22.578
and we’re really excited to be able to see

00:16:22.578 --> 00:16:24.118
these gains in mobile.

00:16:25.168 --> 00:16:28.178
Looking past mobile, just beyond, 
there are a number

00:16:28.178 --> 00:16:31.368
of companies in the hardware space 
which continues to expand.

00:16:31.368 --> 00:16:34.448
The contributions that come out 
of the collaborations that we have

00:16:34.448 --> 00:16:35.548
with these companies,

00:16:35.548 --> 00:16:37.488
the contributions they give back 
to TensorFlow and back

00:16:37.488 --> 00:16:39.168
to the community at large,

00:16:39.168 --> 00:16:41.678
are critical to making sure 
that TensorFlow performs well

00:16:41.678 --> 00:16:45.548
on these specific platforms for the
users that each group really cares about.

00:16:46.378 --> 00:16:49.448
One of the first ones I want 
to highlight is Intel.

00:16:50.488 --> 00:16:53.908
The Intel MKL-DNN library
which is open-sourced,

00:16:53.908 --> 00:16:56.208
and it’s highly optimized for TensorFlow.

00:16:56.208 --> 00:16:59.738
So by making use of this open-source
library, we’re able to achieve a 3x

00:16:59.738 --> 00:17:02.228
interference speedup 
on various Intel platforms.

00:17:02.228 --> 00:17:04.438
I’ve called out Broadwell 
and Skylake here

00:17:04.438 --> 00:17:07.288
as well as see great scaling 
efficiency on training.

00:17:07.718 --> 00:17:09.558
And again, 
this is one of those things

00:17:09.558 --> 00:17:11.108
that really highlights
how important it is

00:17:11.108 --> 00:17:13.158
to have strong collaborations
with different folks

00:17:13.158 --> 00:17:14.498
in the community.

00:17:14.498 --> 00:17:15.598
And we’re really excited

00:17:15.598 --> 00:17:18.718
to be able to see things like this
that can go back to all the users.

00:17:19.258 --> 00:17:21.781
I wanted to call out a few 
of the collaborations we’ve had

00:17:21.781 --> 00:17:23.174
with NVIDIA as well.

00:17:23.174 --> 00:17:24.438
So one of the first things

00:17:24.438 --> 00:17:28.758
that we’re excited about is TensorRT. 
TensorRT is an inference optimizer

00:17:28.758 --> 00:17:32.758
and a runtime for GPU platforms. 
We’ve been collaborating very closely

00:17:32.758 --> 00:17:34.638
with NVIDIA on TensorRT.

00:17:34.638 --> 00:17:36.758
TensorRT has been around
for a little while,

00:17:36.758 --> 00:17:40.138
but with the TensorFlow 1.7 release 
we now have native support

00:17:40.138 --> 00:17:41.498
for TensorRT built in.

00:17:41.498 --> 00:17:44.808
That means you can get low 
latency, high throughput inference.

00:17:44.808 --> 00:17:50.318
So here you can see an 8x inference 
speedup when making use of TensorRT

00:17:50.318 --> 00:17:54.318
versus just using Native FP32 
with standard TensorFlow.

00:17:54.318 --> 00:17:57.608
So it’s great, again, to see these types 
of collaborations that can be done

00:17:57.608 --> 00:17:58.908
and the contributions come back

00:17:58.908 --> 00:18:01.348
and the great numbers that can
be delivered by it.

00:18:02.188 --> 00:18:04.823
Looking past inference 
and going on to some

00:18:04.823 --> 00:18:06.043
of the training things.

00:18:06.043 --> 00:18:08.853
So mixed precision training 
is really important.

00:18:08.853 --> 00:18:10.443
As faster and more 
powerful hardware comes out,

00:18:10.443 --> 00:18:12.453
some of it is optimized such that if you

00:18:12.453 --> 00:18:16.206
use mixed-precision or FP16 support, 
that’s how you’ll get the best out

00:18:16.206 --> 00:18:17.316
of that hardware.

00:18:17.316 --> 00:18:20.646
One example of this 
is the Tesla V100 that NVIDIA has.

00:18:20.646 --> 00:18:23.906
So we’ve been working closely 
to make sure that we have this strong

00:18:23.906 --> 00:18:27.778
mixed-precision training support, 
so that way you can get the best

00:18:27.778 --> 00:18:29.118
performance out of that hardware.

00:18:29.118 --> 00:18:32.198
So here you can see 
a 3.5x training speedup;

00:18:32.198 --> 00:18:37.038
this is on an 8xTesla V100 box. 
And you can see 
just the performance improvements

00:18:37.038 --> 00:18:39.808
when you move 
to mixed-precision training versus

00:18:39.808 --> 00:18:41.878
just using standard TensorFlow.

00:18:44.198 --> 00:18:46.408
Scaling efficiency is really
important as well.

00:18:46.408 --> 00:18:49.088
Obviously we want to make sure 
TensorFlow performs well.

00:18:49.088 --> 00:18:50.558
Maybe you have a single GPU,

00:18:50.558 --> 00:18:51.558
but it should keep going

00:18:51.558 --> 00:18:53.568
regardless of how many things
that you throw at it.

00:18:53.808 --> 00:18:56.678
So we want to make sure 
that, again, looking at examples

00:18:56.678 --> 00:19:00.098
for real-world data as well as 
synthetic data, it’s great to benchmark

00:19:00.098 --> 00:19:03.738
on synthetic data, but it’s very important 
to make sure real-world use cases

00:19:03.738 --> 00:19:07.968
actually perform as we expect as well. 
Here we’re showing 90% scaling efficiency

00:19:07.968 --> 00:19:12.168
with real data, 95% 
with synthetic data, and this is again

00:19:12.168 --> 00:19:18.408
on DGX-1, so an NVIDIA, V100 box 
that has between one and eight GPUs.

00:19:18.408 --> 00:19:20.048
And you can see the scaling here.

00:19:20.048 --> 00:19:21.678
But this is something 
that we care a lot about

00:19:21.678 --> 00:19:24.308
and you’re actually going
to hear more about how to get easier

00:19:24.308 --> 00:19:29.068
scaling efficiency by making use of some 
of our internal APIs later today as well.

00:19:31.074 --> 00:19:33.704
Moving on to cloud frameworks.

00:19:33.704 --> 00:19:35.654
I want to talk a little about cloud TPUs.

00:19:36.094 --> 00:19:39.054
Cloud TPU was launched 
in beta in February,

00:19:39.054 --> 00:19:40.754
just a month and a half ago.

00:19:41.214 --> 00:19:45.314
This is Google’s V2 TPU, so it’s designed 
from the ground up for machine learning

00:19:45.314 --> 00:19:48.334
workloads, and it’s available 
via Google’s cloud platform

00:19:48.334 --> 00:19:49.554
like I mentioned.

00:19:49.554 --> 00:19:51.894
It’s really exciting to look 
at some of the numbers here.

00:19:51.894 --> 00:19:53.944
This picture is actually showing a device,

00:19:53.944 --> 00:19:57.554
and on a single device you’re able to get
180 teraflops of computation.

00:19:58.904 --> 00:20:00.634
But it’s not just about the compute power,

00:20:00.634 --> 00:20:03.114
it’s about what you can
actually do on this.

00:20:03.114 --> 00:20:05.144
It doesn’t really matter if you have
amazing compute power,

00:20:05.144 --> 00:20:07.314
but you can’t run the types
of models that you want.

00:20:07.314 --> 00:20:10.174
So I want to highlight 
the types of reference models

00:20:10.174 --> 00:20:12.874
that we’ve already open-sourced 
that are available today,

00:20:12.874 --> 00:20:14.604
as well as a bunch more types of models

00:20:14.604 --> 00:20:16.014
that are coming soon.

00:20:16.014 --> 00:20:16.984
Again, just to highlight

00:20:16.984 --> 00:20:19.874
the breadth of things that you 
can run on this type of hardware

00:20:19.874 --> 00:20:22.494
and get great performance,
as well as great accuracy.

00:20:22.494 --> 00:20:23.404
We actually have

00:20:23.404 --> 00:20:27.054
an internal team that is continually 
making sure that these models

00:20:27.054 --> 00:20:30.854
perform well, they perform fast,
and that they also are training

00:20:30.854 --> 00:20:32.984
to accuracy in the expected 
amount of time.

00:20:32.984 --> 00:20:35.324
So it’s not just about putting
the model out there

00:20:35.324 --> 00:20:37.124
and open-sourcing it 
and saying “here go with it,”

00:20:37.124 --> 00:20:41.084
it’s about making sure it actually works 
as the community would expect it to work.

00:20:42.515 --> 00:20:45.535
Again, some numbers because what good 
is it if I don’t show any numbers

00:20:45.535 --> 00:20:48.645
in the performance talk? 
One of the numbers here I want

00:20:48.645 --> 00:20:53.695
to call out on this slide is just that 
for cloud TPUs the cost to train ImageNet

00:20:53.695 --> 00:20:59.055
to 76% accuracy is under $85. 
And we think it’s really exciting to be able

00:20:59.055 --> 00:21:02.525
to see what you can achieve 
by making use of this platform.

00:21:04.175 --> 00:21:05.965
If you want more numbers 
than what’s shown here,

00:21:05.965 --> 00:21:08.595
you can definitely take a look
at the DAWNBench entry

00:21:08.595 --> 00:21:11.396
that cloud TPU submitted 
for the ImageNet training.

00:21:13.659 --> 00:21:16.499
One final exciting thing I want 
to call out about cloud TPUs

00:21:16.499 --> 00:21:17.879
is availability of pods,

00:21:17.879 --> 00:21:20.529
which will be coming later this year. 
So what’s a pod?

00:21:20.529 --> 00:21:24.469
A pod is actually 64 of the devices 
like I showed earlier

00:21:24.469 --> 00:21:28.469
all wired up together 
and you get about 11.5 petaflops

00:21:28.469 --> 00:21:32.007
of computation in a pod.
So that’s a lot of compute power

00:21:32.007 --> 00:21:34.567
that is going to be available in this.

00:21:34.567 --> 00:21:36.657
And what can you do 
with that compute power?

00:21:36.657 --> 00:21:40.477
One of the things that the team 
has been pushing on is training ResNet-50

00:21:40.477 --> 00:21:43.847
on a cloud TPU pod to accuracy
in less than 15 minutes.

00:21:43.847 --> 00:21:44.917
So we’re very excited

00:21:44.917 --> 00:21:48.917
to be able to see what can be done 
with this type of hardware,

00:21:48.917 --> 00:21:53.417
and just the amazing speed that you 
can get that wasn’t possible before.

00:21:53.417 --> 00:21:56.757
So Rajat’s talked about the APIs 
and the ease of use and things

00:21:56.757 --> 00:21:59.697
we’re focusing on, I’ve given 
you some fun numbers.

00:21:59.697 --> 00:22:01.717
But what happens when 
you put it together?

00:22:01.717 --> 00:22:03.307
What can TensorFlow actually do?

00:22:03.647 --> 00:22:06.917
So I want to invite Jeff Dean, 
who’s the leader of the Brain team,

00:22:06.917 --> 00:22:11.447
to come up and talk a bit more about 
how TensorFlow addresses real problems.

00:22:12.697 --> 00:22:14.147
- All you!
- Thanks!

00:22:16.467 --> 00:22:17.467
Thanks, Megan.

00:22:18.297 --> 00:22:20.467
So I think one
of the really remarkable things

00:22:20.467 --> 00:22:25.407
about machine learning is its capacity 
to solve real problems in the world.

00:22:25.407 --> 00:22:29.837
And we’ve seen tremendous 
progress in the last few years.

00:22:29.837 --> 00:22:31.127
In 2008, though,

00:22:31.127 --> 00:22:34.947
the U.S. National Academy of Engineering 
put out this list of Grand Engineering

00:22:34.947 --> 00:22:38.947
Challenges that they were hoping would 
be solved by the end of the 21st century.

00:22:38.947 --> 00:22:40.527
It’s 14 different challenges.

00:22:40.637 --> 00:22:43.917
And I think it’s a really 
nice list of things

00:22:43.917 --> 00:22:46.157
we should be aspiring 
to work on as a society.

00:22:46.157 --> 00:22:47.927
If we solved all these problems,

00:22:47.927 --> 00:22:50.667
our planet would be healthier, 
people would live longer,

00:22:50.667 --> 00:22:54.667
they would be happier, 
and generally things would be better.

00:22:54.667 --> 00:22:58.397
I think machine learning is actually 
going to help us in all of these things,

00:22:58.397 --> 00:23:02.397
some in small ways where you see 
machine learning influencing

00:23:02.397 --> 00:23:05.957
our understanding of chemical molecules
and so on, some in very major ways.

00:23:06.207 --> 00:23:07.817
So I’m going to talk about
two of these today,

00:23:07.817 --> 00:23:08.997
but I think machine learning

00:23:08.997 --> 00:23:13.237
will actually be a key to helping us 
attack all of these different areas.

00:23:13.237 --> 00:23:14.507
The two I’m going to talk about

00:23:14.507 --> 00:23:16.117
are engineering the tools 
of scientific discovery

00:23:16.117 --> 00:23:17.977
and advancing health informatics.

00:23:17.977 --> 00:23:21.377
So first, engineering the tools
for scientific discovery.

00:23:21.377 --> 00:23:22.747
You know, clearly machine learning

00:23:22.747 --> 00:23:26.947
is going to be a big component of what 
we do to solve some of these challenges

00:23:26.947 --> 00:23:30.517
and TensorFlow itself you can think 
of as a tool for helping us engineer

00:23:30.517 --> 00:23:32.673
some of these discoveries.

00:23:32.673 --> 00:23:35.753
But one of the things 
that I think is really important

00:23:35.753 --> 00:23:39.253
is that there’s a lot more 
opportunity for machine learning

00:23:39.253 --> 00:23:42.063
than there is machine learning 
expertise in the world.

00:23:42.063 --> 00:23:45.853
The way you solve a machine learning
problem today is:

00:23:45.853 --> 00:23:48.173
you have some data, 
you have some computation,

00:23:48.173 --> 00:23:50.863
maybe GPUs or TPUs or CPUs or whatever,

00:23:50.863 --> 00:23:53.223
and then you have
a machine learning expert.

00:23:53.223 --> 00:23:55.993
Someone who’s taken a graduate 
class in machine learning,

00:23:55.993 --> 00:23:59.313
someone who’s downloaded 
TensorFlow and is familiar enough

00:23:59.313 --> 00:24:00.463
to play around with it.

00:24:00.633 --> 00:24:02.853
But that’s a pretty small set 
of people in the world.

00:24:02.853 --> 00:24:06.523
And then you stir all of this together, 
and you get a solution hopefully.

00:24:07.763 --> 00:24:10.613
So the unfortunate thing about that

00:24:10.613 --> 00:24:13.223
is there’s probably tens 
of thousands of organizations

00:24:13.223 --> 00:24:16.693
in the world today that are actually 
effectively using machine learning

00:24:16.693 --> 00:24:20.373
in production environments and really 
making use of it to solve problems.

00:24:20.373 --> 00:24:24.243
But there’s probably tens of millions 
of organizations in the world that have

00:24:24.243 --> 00:24:27.543
data in electronic form that could
be used for machine learning

00:24:27.543 --> 00:24:30.343
but don’t really have the internal 
expertise and skills.

00:24:30.343 --> 00:24:33.593
So one of the things we’re excited 
about is how can we make machine

00:24:33.593 --> 00:24:37.213
learning much easier to use so that you 
don’t need nearly as much expertise

00:24:37.213 --> 00:24:38.553
to apply it.

00:24:38.953 --> 00:24:41.943
So can we use computation 
to replace a lot of the need

00:24:41.943 --> 00:24:44.083
for that machine learning expertise.

00:24:44.623 --> 00:24:49.183
So we’ve been working on a suite
of techniques that we call Auto ML.

00:24:49.183 --> 00:24:52.323
Neural Architecture Search is one
example of this.

00:24:52.323 --> 00:24:54.743
One of the things that 
a machine learning expert does

00:24:54.743 --> 00:24:58.103
is they sit down and they decide 
for a particular problem what kind

00:24:58.103 --> 00:25:00.763
of model structure they’re going 
to use for this problem.

00:25:00.763 --> 00:25:03.143
Is it going to be 
a ResNet 50 architecture,

00:25:03.143 --> 00:25:06.533
is it going to be a 9-layer CMN
with these kinds of filter sizes,

00:25:06.533 --> 00:25:08.053
and so on.

00:25:08.823 --> 00:25:12.773
It turns out that you can
use machine learning to optimize

00:25:12.773 --> 00:25:15.493
a controller that proposes machine
learning models.

00:25:15.493 --> 00:25:17.953
And so you can actually 
have the controller propose

00:25:17.953 --> 00:25:20.773
machine learning models, 
train those models on the problem

00:25:20.773 --> 00:25:24.163
you care about, see which ones
work well and which ones don’t,

00:25:24.163 --> 00:25:27.603
and use that feedback signal 
as a reinforcement learning signal

00:25:27.603 --> 00:25:31.263
for the model-generating model. 
It can sort of steer it towards models

00:25:31.263 --> 00:25:34.283
that are working well for particular 
kinds of problems, and away from

00:25:34.283 --> 00:25:37.353
the part of space where those models 
don’t seem to work very well.

00:25:37.353 --> 00:25:40.693
And if you repeat this a lot of times, 
you can actually get really powerful

00:25:40.693 --> 00:25:42.183
high-quality models.

00:25:43.503 --> 00:25:44.923
And they look a little weird.

00:25:45.343 --> 00:25:46.503
So this is not something

00:25:46.503 --> 00:25:50.503
a human machine learning expert 
would sit down and construct,

00:25:50.503 --> 00:25:54.103
but it has characteristics of things 
we know that human machine learning

00:25:54.103 --> 00:25:57.243
experts have discovered are helpful. 
So if you think of the ResNet

00:25:57.243 --> 00:25:59.123
architecture, it has skip connections;

00:25:59.123 --> 00:26:01.153
it’ll allow you to skip every other layer.

00:26:02.313 --> 00:26:05.883
So these more organic looking 
connections are the same

00:26:05.883 --> 00:26:09.073
fundamental idea, which is you 
want to allow input data to flow

00:26:09.073 --> 00:26:11.413
more directly to the output 
without necessarily going through

00:26:11.413 --> 00:26:13.263
as much computational layers.

00:26:14.933 --> 00:26:18.233
The interesting thing is AutoML
actually does quite well here.

00:26:19.393 --> 00:26:24.073
This is a graph showing computational
cost versus accuracy for ImageNet.

00:26:24.073 --> 00:26:27.963
Every dot here shows you different
kinds of tradeoffs there.

00:26:27.963 --> 00:26:31.293
And generally as you extend 
more computation,

00:26:31.293 --> 00:26:32.463
you get higher accuracy.

00:26:34.433 --> 00:26:38.803
Every dot here is the work 
of years of cumulative effort

00:26:38.803 --> 00:26:41.123
by top machine learning 
researchers and computer

00:26:41.123 --> 00:26:42.573
vision experts in the world.

00:26:44.063 --> 00:26:47.453
And if you look at AutoML,
you actually get better

00:26:47.453 --> 00:26:50.483
accuracy and better 
computational tradeoffs

00:26:50.483 --> 00:26:52.813
than all of those kinds of models.

00:26:52.813 --> 00:26:55.753
That’s true both at the high 
end where you care about upmost

00:26:55.753 --> 00:26:58.713
accuracy and don’t care that much 
about computational budget,

00:26:58.713 --> 00:27:01.893
but it’s also true at the low end
where you have very lightweight models

00:27:01.893 --> 00:27:05.773
where you care about very low 
computational costs and high accuracy.

00:27:06.573 --> 00:27:09.153
So that’s pretty exciting and I think 
this is a real opportunity

00:27:09.153 --> 00:27:12.873
to use more computation to solve real 
machine learning problems in a much

00:27:12.873 --> 00:27:17.233
more automated way so that we can solve 
more problems more quickly.

00:27:17.233 --> 00:27:19.833
And we’ve actually released this
in collaboration with a cloud group

00:27:19.833 --> 00:27:25.103
at Google as a product that customers 
can use for solving their own computer

00:27:25.103 --> 00:27:28.403
vision problems and obviously we want 
to broaden it out from beyond

00:27:28.403 --> 00:27:31.573
just computer vision to lots 
of other kinds of categories of problems.

00:27:32.563 --> 00:27:34.313
Okay, Advance Health Informatics.

00:27:34.913 --> 00:27:36.563
So machine learning and healthcare

00:27:36.563 --> 00:27:38.943
is going to be a really impactful
combination.

00:27:40.143 --> 00:27:41.443
One of the lay areas

00:27:41.443 --> 00:27:44.193
that we’ve been working on 
is a variety of different

00:27:44.193 --> 00:27:48.193
medical imaging problems, including one
problem in ophthalmology where you’re

00:27:48.193 --> 00:27:51.723
trying to look at an image like this 
and diagnose whether that image

00:27:51.723 --> 00:27:53.563
shows signs of diabetic retinopathy.

00:27:53.933 --> 00:27:56.563
This is a serious 
degenerative eye disease;

00:27:56.563 --> 00:27:59.203
400 million people are at risk
of this around the world,

00:27:59.203 --> 00:28:02.063
and it’s very treatable 
if it’s caught in time.

00:28:02.063 --> 00:28:03.383
But if it’s not caught in time,

00:28:03.383 --> 00:28:05.473
you can actually suffer vision loss.

00:28:06.443 --> 00:28:07.753
In many parts of the world,

00:28:07.753 --> 00:28:09.043
there just aren’t enough 
ophthalmologists

00:28:09.043 --> 00:28:10.933
to inspect these images.

00:28:11.793 --> 00:28:15.363
So we’ve done work, 
and with the work that we published

00:28:15.363 --> 00:28:19.793
at the very end of 2016, we showed 
that we had a model that was on par

00:28:19.793 --> 00:28:22.403
with board-certified ophthalmologists.

00:28:23.353 --> 00:28:24.973
And since then we’ve been continuing

00:28:24.973 --> 00:28:28.463
to work on this and we’ve changed 
how we label our training data;

00:28:28.463 --> 00:28:31.843
we’ve gotten a retinal specialist
to label the training data rather than

00:28:31.843 --> 00:28:35.353
general ophthalmologists, and now 
we actually have a model that is on par

00:28:35.353 --> 00:28:36.683
with retinal specialists.

00:28:36.683 --> 00:28:40.003
This is a much higher standard of care, 
and we’re pretty excited about this

00:28:40.003 --> 00:28:41.783
because this means
you can bring this and deliver this

00:28:41.783 --> 00:28:44.583
to lots of places around the world.

00:28:45.253 --> 00:28:46.433
But more interestingly,

00:28:46.433 --> 00:28:49.073
I’m going to tell you a little tale
of scientific discovery.

00:28:49.073 --> 00:28:51.913
So we had a new person 
join the retinopathy team.

00:28:51.913 --> 00:28:57.223
And as a warm-up exercise, Lily Pang,
who leads some of this work,

00:28:57.223 --> 00:29:00.303
said to the new person, “Hey, 
why don’t you go off and see if you

00:29:00.303 --> 00:29:02.633
can predict age and gender
from these images?”

00:29:02.633 --> 00:29:05.963
And she thought maybe you can predict
age within a couple of decades,

00:29:05.963 --> 00:29:08.053
and you definitely shouldn’t 
be able to predict gender,

00:29:08.053 --> 00:29:09.953
so your AUC should be 0.5.

00:29:09.953 --> 00:29:11.763
So the person went off and came back

00:29:11.763 --> 00:29:14.283
a little while later and they said, 
“I can predict gender

00:29:14.283 --> 00:29:15.833
with an AUC of 0.7."

00:29:16.053 --> 00:29:19.993
And Lily was like, “Hmm…
that’s weird. That must be wrong.

00:29:19.993 --> 00:29:22.023
Why don’t you go off 
and come back later,

00:29:22.023 --> 00:29:23.653
and just double-check everything."

00:29:23.653 --> 00:29:26.833
So they come back, 
and they said, “My AUC is now 0.85.”

00:29:28.413 --> 00:29:31.763
And so that got us thinking, 
and we investigated what other

00:29:31.763 --> 00:29:34.463
kinds of things we could predict 
from these retinal images.

00:29:34.463 --> 00:29:37.243
And it turns out that you can predict
a variety of different things

00:29:37.243 --> 00:29:40.023
that are indicative
of cardiovascular health.

00:29:41.553 --> 00:29:45.573
Your age and gender are signs 
of cardiovascular health,

00:29:45.573 --> 00:29:48.773
as are things like your hemoglobin
levels, lots of things like this.

00:29:48.773 --> 00:29:53.033
We now actually have a new non-invasive
test for cardiovascular health.

00:29:53.033 --> 00:29:55.863
Normally you have to draw 
blood and do lab tests for this,

00:29:55.863 --> 00:29:58.973
but now we can do this just 
from an image, which is pretty cool.

00:30:00.743 --> 00:30:03.973
We’re also doing a bunch of work
on predictive tasks for healthcare.

00:30:03.973 --> 00:30:07.683
So given a patient’s medical record,
can we predict the future?

00:30:07.683 --> 00:30:10.923
This is something doctors want to do;
you want to understand how your

00:30:10.923 --> 00:30:14.243
patient’s going to progress 
and you want to be able to answer

00:30:14.243 --> 00:30:18.243
lots of questions: "Will the patient 
be readmitted if I release them

00:30:18.243 --> 00:30:20.713
from the hospital now?
What are the most likely diagnoses

00:30:20.713 --> 00:30:23.183
I should be thinking about?
What tests should be considered

00:30:23.183 --> 00:30:26.033
for this patient right now?"
Lots of questions like that.

00:30:26.033 --> 00:30:28.743
And we’ve been collaborating 
with several healthcare organizations

00:30:28.743 --> 00:30:31.933
to work on de-identified medical records 
to see if we can predict

00:30:31.933 --> 00:30:33.223
these kinds of things.

00:30:33.223 --> 00:30:37.873
And in January, we posted 
a mini author archives paper,

00:30:37.873 --> 00:30:41.563
and we looked at a lot of these 
different types of tasks.

00:30:41.563 --> 00:30:44.998
I'll highlight just one of them here, 
which is predicting which patients

00:30:44.998 --> 00:30:46.888
are most at risk for mortality.

00:30:48.288 --> 00:30:50.278
And using this, we’re able to actually

00:30:50.278 --> 00:30:54.468
predict which patients are most 
seriously at risk 24 hours earlier

00:30:54.468 --> 00:30:57.708
than the clinical base lines
that are currently in use.

00:30:57.708 --> 00:31:01.248
And so that really means the doctors 
get 24 hours of advance notice

00:31:01.248 --> 00:31:04.408
to really pay attention to those 
patients that are critically ill

00:31:04.408 --> 00:31:06.948
and really need their close attention 
and close watching.

00:31:06.948 --> 00:31:10.318
So this is indicative of what machine 
learning can do for this kind of field.

00:31:11.948 --> 00:31:15.048
In general, the Google Brain team’s 
mission is to make machines intelligent

00:31:15.048 --> 00:31:17.908
and then use that ability to improve 
people’s lives.

00:31:17.908 --> 00:31:21.308
I think these are good examples of where
there’s real opportunity for this.

00:31:22.288 --> 00:31:24.568
I’m going to close with a bit of a story.

00:31:25.388 --> 00:31:28.568
So when I was five years old, 
I lived in northwestern Uganda

00:31:28.568 --> 00:31:33.618
for a year, and the local crop there 
is a root called cassava.

00:31:33.618 --> 00:31:38.398
And I was five, so I’d like to go out 
and help people pick cassava.

00:31:38.738 --> 00:31:43.608
But it turns out that machine learning and
cassava have a cool twist together.

00:31:44.418 --> 00:31:45.708
Please roll the video.

00:31:46.984 --> 00:31:48.714
♪ (music) ♪

00:31:53.650 --> 00:31:55.770
<i>(David Hughes) Cassava’s a really 
important crop.</i>

00:31:55.770 --> 00:31:58.570
It provides for over 500 million
Africans every day.

00:31:59.540 --> 00:32:01.470
<i>(Amanda Ramcharan) When all 
other crops fail,</i>

00:32:01.470 --> 00:32:05.590
farmers know that they can rely on their
cassava plants to provide them food.

00:32:10.320 --> 00:32:13.920
<i>(Latifa Mrisho) There are several diseases 
that affect cassava, and these diseases</i>

00:32:13.920 --> 00:32:15.540
<i>make the root inedible.</i>

00:32:16.110 --> 00:32:18.190
It is very crucial to actually control

00:32:18.190 --> 00:32:20.070
<i>and manage these diseases.</i>

00:32:20.310 --> 00:32:24.270
(David) So we’re trying to use machine 
learning to respond to those diseases.

00:32:24.270 --> 00:32:27.590
<i>(Amanda) And TensorFlow is the best 
foundation for our solutions.</i>

00:32:27.590 --> 00:32:30.530
The app that we’ve designed 
can diagnose multiple diseases.

00:32:30.530 --> 00:32:32.360
<i>It’s called nuru, 
Swahili for light,</i>

00:32:32.830 --> 00:32:35.620
<i>the light that farmers 
can use to see their problems</i>

00:32:35.620 --> 00:32:36.860
<i>and find solutions.</i>

00:32:37.200 --> 00:32:40.280
<i>You wave your phone over 
a specific leaf, look at it,</i>

00:32:40.280 --> 00:32:44.170
<i>and if it has a symptom, the box will 
pop up saying you have this problem.</i>

00:32:44.170 --> 00:32:45.630
<i>When you get a diagnosis,</i>

00:32:45.630 --> 00:32:47.610
<i>we have an option for you
to get advice and learn </i>

00:32:47.610 --> 00:32:49.740
<i>about the best management practices.</i>

00:32:49.740 --> 00:32:51.250
The object detection that we use

00:32:51.250 --> 00:32:54.900
<i>through TensorFlow relies 
upon our team annotating images.</i>

00:32:54.900 --> 00:32:58.610
<i>(Amanda) We’ve collected over 5,000 
high-quality images of different cassava</i>

00:32:58.610 --> 00:33:00.520
<i>diseases for this project.</i>

00:33:00.520 --> 00:33:04.310
<i>We use a single shot detector model 
on the mobile net architecture.</i>

00:33:04.310 --> 00:33:07.620
<i>It’s able to make predictions
in less than one second.</i>

00:33:07.620 --> 00:33:10.620
<i>(Pete McCloskey) Instead of having 
to implement thousands of lines of code,</i>

00:33:10.620 --> 00:33:13.090
TensorFlow provides a library 
of functions that allow us

00:33:13.090 --> 00:33:16.350
<i>to build architectures in much less time.</i>

00:33:16.930 --> 00:33:18.220
<i>(Amanda) We need something</i>

00:33:18.220 --> 00:33:21.680
<i>that can be deployed on a phone 
without any connection.</i>

00:33:21.680 --> 00:33:25.260
<i>TensorFlow is able to shrink 
these neural networks to be able to fit</i>

00:33:25.260 --> 00:33:26.880
<i>on your mobile device.</i>

00:33:26.880 --> 00:33:28.910
<i>(Pete) The human input 
is absolutely critical.</i>

00:33:28.910 --> 00:33:31.630
<i>We’re really building something
that augments your experience</i>

00:33:31.630 --> 00:33:33.900
and makes you better at your job.

00:33:33.900 --> 00:33:38.530
<i>(Amanda) So with AI tools and machine 
learning, you can improve the yields,</i>

00:33:38.530 --> 00:33:43.094
<i>you can protect your crops, and you can 
have a much more reliable source of food.</i>

00:33:43.704 --> 00:33:47.894
<i>(David) AI offers the prospect
to fundamentally transform the life</i>

00:33:47.894 --> 00:33:51.574
<i>of hundreds of millions of farms 
around the world.</i>

00:33:55.187 --> 00:33:58.877
<i>(Latifa) You can see a product that can 
actually make someone’s life better.</i>

00:33:59.877 --> 00:34:01.827
<i>This is kind of revolutionary.</i>

00:34:13.087 --> 00:34:15.677
Pretty cool! I think we have some 
members of the Penn State

00:34:15.677 --> 00:34:20.147
and IITA teams from Tanzania here today, 
so if you could all stand up or wave.

00:34:20.557 --> 00:34:22.657
And I’m sure they’d be happy
to chat with you.

00:34:22.657 --> 00:34:23.697
Fantastic!

00:34:24.417 --> 00:34:25.487
[applause]

00:34:25.877 --> 00:34:27.537
I'm sure they’ll be happy 
to chat with you at the break

00:34:27.537 --> 00:34:28.907
about that work.

00:34:28.907 --> 00:34:31.747
♪ (music) ♪

