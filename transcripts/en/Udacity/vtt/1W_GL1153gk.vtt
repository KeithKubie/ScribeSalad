WEBVTT
Kind: captions
Language: en

00:00:00.270 --> 00:00:05.446
So far it's really pretty much been
the tracking like we saw before.

00:00:05.446 --> 00:00:08.890
But now the part of filter tracking,
we've got a model tracking it.

00:00:08.890 --> 00:00:10.960
But the thing that we're going to do
now that's a little bit different,

00:00:10.960 --> 00:00:12.540
this is sort of the cool part is.

00:00:12.540 --> 00:00:16.490
We're not going to assume
that our appearance and

00:00:16.490 --> 00:00:19.270
observation model remain constant.

00:00:19.270 --> 00:00:23.880
Basically the idea is we're going to,
sort of, update our,

00:00:23.880 --> 00:00:28.150
the model as we get
new images coming in.

00:00:28.150 --> 00:00:30.820
Now a sort of a standard way of
doing this, and, by the way,

00:00:30.820 --> 00:00:33.410
this works really poorly so
don't do it is.

00:00:33.410 --> 00:00:37.260
I have a model, appearance, I look
around, I say that's my best one, and

00:00:37.260 --> 00:00:39.110
I say, okay,
I guess it's changed a little bit,

00:00:39.110 --> 00:00:42.150
let me pull out that model and
I'll find that in the next image.

00:00:42.150 --> 00:00:44.320
And, eventually,
what happens is you get drift.

00:00:44.320 --> 00:00:45.750
And the model lands on that.

00:00:45.750 --> 00:00:48.130
There's this really, really cool thing.

00:00:48.130 --> 00:00:49.410
Oh, you can't see.

00:00:49.410 --> 00:00:51.060
Okay.
I'm going to pretend like there's this

00:00:51.060 --> 00:00:53.810
really great car.

00:00:53.810 --> 00:00:56.610
Sitting right over here and
you know, eventually and

00:00:56.610 --> 00:00:58.080
it just gets stuck on there.

00:00:58.080 --> 00:01:00.660
And the thing that I was tracking
would go, it would go away.

00:01:01.740 --> 00:01:05.970
But if I don't update my
model then as things change,

00:01:05.970 --> 00:01:07.770
I can't find it so well anymore.

00:01:07.770 --> 00:01:11.950
So what we do here instead is
with every new appearance,

00:01:11.950 --> 00:01:14.090
we're going to change our eigenbasis.

00:01:14.090 --> 00:01:14.760
Right?
This is a,

00:01:14.760 --> 00:01:18.405
this is the set of eigen vectors
that let's our It says reconstruct.

00:01:18.405 --> 00:01:20.445
We're going to change that a little bit.

00:01:20.445 --> 00:01:23.505
And that allows for
a small variation in appearance, but

00:01:23.505 --> 00:01:27.435
it still going to try to do things
like track the general class.

00:01:27.435 --> 00:01:29.385
And so
the trick is just as it is written here.

00:01:29.385 --> 00:01:32.745
Given the basis set, B of t minus one,

00:01:32.745 --> 00:01:39.520
that we use to find the loc,
the observation at time t minus one.

00:01:39.520 --> 00:01:44.060
We, that allows us to compute
a new eigenbasis, B of t,

00:01:44.060 --> 00:01:48.760
that we're going to use now
to evaluate our measurements.

00:01:48.760 --> 00:01:50.550
All right?
So the idea is we're updating

00:01:50.550 --> 00:01:55.550
this eigenbasis, but it's adding sort
of it's a small variation each time, so

00:01:55.550 --> 00:01:57.840
we can't radically change
what things look like.

00:01:57.840 --> 00:01:59.700
We can change them a little bit.

00:01:59.700 --> 00:02:03.010
And this referred to as
an incremental subspace update.

00:02:03.010 --> 00:02:06.240
As you remember from PCA we said
the whole reason that we're doing this

00:02:06.240 --> 00:02:09.680
dimensionality reduction is
the idea that we believe our images

00:02:09.680 --> 00:02:11.660
lie in some subspace.

00:02:11.660 --> 00:02:14.570
But we have to find that subspace
within the bigger feature space.

00:02:14.570 --> 00:02:18.710
So that's why this is referred to
as an Incremental Subspace Update.

00:02:18.710 --> 00:02:19.950
And why are we doing this?

00:02:19.950 --> 00:02:22.930
Basically, we are accounting for
appearance change.

00:02:22.930 --> 00:02:25.670
So we might be tracking the,
the object in the image.

00:02:25.670 --> 00:02:28.550
It's translating, it's rotating,
it's maybe shearing, but

00:02:28.550 --> 00:02:32.600
if I rotate out of the plane,
as far as the camera is concerned,

00:02:32.600 --> 00:02:35.410
my face is changing its appearance.

00:02:35.410 --> 00:02:38.450
As I go sideways,
it usually goes worse, but that's okay.

00:02:38.450 --> 00:02:40.580
The idea is that I want to
model that change.

00:02:40.580 --> 00:02:43.950
So we're learning a new
appearance representation as,

00:02:43.950 --> 00:02:45.700
as the image area changes.

00:02:45.700 --> 00:02:47.110
In the papers that I've
been telling you about,

00:02:47.110 --> 00:02:50.390
they base it upon, on this recursive
SVD algorithm, which is kind of nice.

00:02:50.390 --> 00:02:54.350
So you don't have to do the whole
eigendecomposition, decomposition again.

00:02:54.350 --> 00:02:56.450
So you can do this quickly in real time.

00:02:56.450 --> 00:02:58.070
That part doesn't matter so much.

00:02:58.070 --> 00:03:02.260
Essentially what you have is
an algorithm, that allows you,

00:03:02.260 --> 00:03:05.040
it's kind of like a running
mean algorithm, where you're

00:03:05.040 --> 00:03:09.740
using the most recent examples more
strongly than the older examples.

