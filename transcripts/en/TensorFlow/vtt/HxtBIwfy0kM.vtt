WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.209
[MUSIC PLAYING]

00:00:04.209 --> 00:00:05.750
MAGNUS HYTTSTEN: Hi
there, everybody.

00:00:05.750 --> 00:00:06.610
What's up?

00:00:06.610 --> 00:00:10.150
My name is Magnus, and you're
watching Cording TensorFlow--

00:00:10.150 --> 00:00:13.862
the show where you learn
how to code in TensorFlow.

00:00:13.862 --> 00:00:15.550
[MUSIC PLAYING]

00:00:15.550 --> 00:00:16.340
All right.

00:00:16.340 --> 00:00:19.250
In this episode, we'll talk
about saving and loading

00:00:19.250 --> 00:00:20.150
models.

00:00:20.150 --> 00:00:22.100
So why do we want
to talk about this?

00:00:22.100 --> 00:00:24.200
Well, first of all,
whenever you train

00:00:24.200 --> 00:00:26.930
a model of any
significant complexity,

00:00:26.930 --> 00:00:30.770
the training can
take a long time.

00:00:30.770 --> 00:00:33.430
Most of the models in this
Getting Started series

00:00:33.430 --> 00:00:35.690
will just take a
minute or so to train,

00:00:35.690 --> 00:00:40.880
where real-life models can take
days or even weeks to train.

00:00:40.880 --> 00:00:44.480
So if you were to hit
Control-C on your training job

00:00:44.480 --> 00:00:46.790
after it's been running
for a day or so,

00:00:46.790 --> 00:00:50.570
all your model weights
and values will be lost,

00:00:50.570 --> 00:00:53.120
and you would have to restart
training from the beginning

00:00:53.120 --> 00:00:56.000
and be a very sad camper.

00:00:56.000 --> 00:00:58.670
But if you saved your
model every so often,

00:00:58.670 --> 00:01:01.640
you can always resume
training from that point,

00:01:01.640 --> 00:01:04.760
making you a happy camper.

00:01:04.760 --> 00:01:07.250
Another benefit is that
you can take your model

00:01:07.250 --> 00:01:09.590
and transfer to
another computer, where

00:01:09.590 --> 00:01:11.630
you can continue training.

00:01:11.630 --> 00:01:13.640
But I'm pretty sure you
already guessed that I

00:01:13.640 --> 00:01:15.170
was going to bring that up.

00:01:15.170 --> 00:01:16.860
That's enough talking for now.

00:01:16.860 --> 00:01:19.290
Check out the links
below to locate the code,

00:01:19.290 --> 00:01:21.170
because that's what
we're going to do now.

00:01:21.170 --> 00:01:22.350
Check out the code!

00:01:22.350 --> 00:01:23.190
Oh, finally!

00:01:23.190 --> 00:01:24.480
We get to check out the code!

00:01:24.480 --> 00:01:25.105
That's awesome!

00:01:25.105 --> 00:01:28.530
Let's go and check out the code!

00:01:28.530 --> 00:01:29.130
All right.

00:01:29.130 --> 00:01:31.980
Let's start by checking out
the awesome licenses here

00:01:31.980 --> 00:01:33.330
at the top.

00:01:33.330 --> 00:01:38.080
Then install packages for
HDF5 and JAML support.

00:01:38.080 --> 00:01:41.170
And here we do some imports, and
print the TensorFlow version.

00:01:41.170 --> 00:01:45.640
It's totally OK if you have
a later version than me here.

00:01:45.640 --> 00:01:47.650
We use the MNIST data
set to demonstrate

00:01:47.650 --> 00:01:49.990
model loading and saving.

00:01:49.990 --> 00:01:52.930
Then reshape the
images to batches of 28

00:01:52.930 --> 00:01:58.060
by 28 arrays, which is the
pixel size of MNIST images,

00:01:58.060 --> 00:02:03.050
and normalize all pixel
values to be between 0 and 1.

00:02:03.050 --> 00:02:05.060
Next is the model
definition, which

00:02:05.060 --> 00:02:08.389
is defined in the
create_model function.

00:02:08.389 --> 00:02:10.520
This is a very
basic model, which

00:02:10.520 --> 00:02:13.070
is totally OK, because
in this screencast

00:02:13.070 --> 00:02:16.700
we're interested in learning
how to load and save models,

00:02:16.700 --> 00:02:21.400
not creating the best model
for the MNIST dataset.

00:02:21.400 --> 00:02:25.120
And here, we finally get to
see how a model can be saved.

00:02:25.120 --> 00:02:30.250
checkpoint_path will be the
path of the saved model.

00:02:30.250 --> 00:02:32.230
A model checkpoint
callback object

00:02:32.230 --> 00:02:35.090
is created with this path.

00:02:35.090 --> 00:02:37.510
We also specify that only
the weights of the model

00:02:37.510 --> 00:02:40.180
should be saved, and
that we want debug output

00:02:40.180 --> 00:02:43.040
when the saving is performed.

00:02:43.040 --> 00:02:44.940
Finally, we perform
the model training

00:02:44.940 --> 00:02:48.420
by calling the fit method
and providing this callback.

00:02:48.420 --> 00:02:50.700
As you can see, this
will cause a model

00:02:50.700 --> 00:02:55.150
to be saved once every
epoch has been completed.

00:02:55.150 --> 00:02:56.990
And if we look at the
checkpoints directory,

00:02:56.990 --> 00:02:59.030
we can now see three files.

00:02:59.030 --> 00:03:04.400
The cp.ckpt.data file contains
all the weight values.

00:03:04.400 --> 00:03:07.850
This file has a range sequence,
because multiple partitions

00:03:07.850 --> 00:03:11.980
could potentially be used
if we have a lot of weights.

00:03:11.980 --> 00:03:16.910
The cp.ckpt.index file
specifies which partition file

00:03:16.910 --> 00:03:19.210
contains which weights.

00:03:19.210 --> 00:03:22.080
And finally, the checkpoint
file is a text file that

00:03:22.080 --> 00:03:24.210
points to the latest model.

00:03:24.210 --> 00:03:26.640
In our case, we only
have one data file,

00:03:26.640 --> 00:03:28.770
but shortly, we'll
see an example

00:03:28.770 --> 00:03:33.090
where we have saved multiple
versions of the model.

00:03:33.090 --> 00:03:33.800
All right.

00:03:33.800 --> 00:03:35.630
So now when we have
our saved model,

00:03:35.630 --> 00:03:39.160
let's try out loading it.

00:03:39.160 --> 00:03:43.360
First, let's just create a model
from scratch and try it out.

00:03:43.360 --> 00:03:44.920
Since it hasn't
been trained, you

00:03:44.920 --> 00:03:49.220
can see that the
accuracy really sucks.

00:03:49.220 --> 00:03:51.200
And now for the magic.

00:03:51.200 --> 00:03:54.050
If we call the
method load_weights

00:03:54.050 --> 00:03:55.970
with our checkpoint
path, our model

00:03:55.970 --> 00:03:58.730
gets initialized with the
previous training state,

00:03:58.730 --> 00:04:02.450
and has much better accuracy.

00:04:02.450 --> 00:04:03.260
OK.

00:04:03.260 --> 00:04:06.480
That's the basics to
save and load models.

00:04:06.480 --> 00:04:09.980
Let's look at some
more options we have.

00:04:09.980 --> 00:04:12.530
One option is to provide
the period parameter

00:04:12.530 --> 00:04:15.910
when creating the model
checkpoint object.

00:04:15.910 --> 00:04:20.019
In this case we use the
value 5, which as you can see

00:04:20.019 --> 00:04:23.940
saves a new model
every five epochs.

00:04:23.940 --> 00:04:27.880
Observe in this case, we also
use a parameterized filing

00:04:27.880 --> 00:04:30.280
based on the epoch.

00:04:30.280 --> 00:04:33.060
This means a unique file
is saved every time.

00:04:35.820 --> 00:04:38.670
That's also why we can see
multiple files when looking

00:04:38.670 --> 00:04:41.590
at the checkpoint directory.

00:04:41.590 --> 00:04:43.210
We can also use
a function called

00:04:43.210 --> 00:04:48.970
tf.train.latest_checkpoint that
will return the latest model,

00:04:48.970 --> 00:04:50.860
which was saved--

00:04:50.860 --> 00:04:54.850
in our case, the
one with index 50.

00:04:54.850 --> 00:04:58.450
This function looks into the
file with the name checkpoint

00:04:58.450 --> 00:05:01.410
to find the latest checkpoint.

00:05:01.410 --> 00:05:04.390
Remember that the checkpoint
file is a text file,

00:05:04.390 --> 00:05:08.770
so you can actually check
the file content yourself.

00:05:08.770 --> 00:05:12.920
And now we can load the model
using the load_weights function

00:05:12.920 --> 00:05:15.770
like we did before,
providing the value returned

00:05:15.770 --> 00:05:17.900
by tf.train.latest_checkpoint.

00:05:21.220 --> 00:05:24.280
Another way of saving models
is to call the save method

00:05:24.280 --> 00:05:25.750
on the model.

00:05:25.750 --> 00:05:30.530
This will create an
HDF5-formatted file.

00:05:30.530 --> 00:05:34.670
Remember that we specified
save_weights_only

00:05:34.670 --> 00:05:37.860
to true last time
we saved a model.

00:05:37.860 --> 00:05:40.190
In addition to only
saving variables,

00:05:40.190 --> 00:05:42.680
the save method saves
additional data,

00:05:42.680 --> 00:05:45.500
like the model's configuration
and even the state

00:05:45.500 --> 00:05:47.740
of the optimizer.

00:05:47.740 --> 00:05:51.400
A model that was saved using the
save method can be loaded with

00:05:51.400 --> 00:05:54.040
the function
keras.models.load_model.

00:05:57.700 --> 00:06:02.840
And as you can see, we have the
accuracy of a trained model.

00:06:02.840 --> 00:06:04.960
In addition to everything
we've looked at,

00:06:04.960 --> 00:06:07.630
TensorFlow also has a very
important file format,

00:06:07.630 --> 00:06:10.530
called SavedModel.

00:06:10.530 --> 00:06:12.390
This is a file
format that allows

00:06:12.390 --> 00:06:16.280
to exchange models between many
different parts of TensorFlow,

00:06:16.280 --> 00:06:19.200
like TensorFlow
Python, TensorFlow.js,.

00:06:19.200 --> 00:06:21.810
And also TensorFlow Lite.

00:06:21.810 --> 00:06:24.060
We are currently building
out first-hand support

00:06:24.060 --> 00:06:27.660
for SavedModel in Keras, and you
can check out the links below

00:06:27.660 --> 00:06:29.560
to read more about it.

00:06:29.560 --> 00:06:32.380
And that's it for this
episode of Coding TensorFlow.

00:06:32.380 --> 00:06:34.320
Make sure to subscribe
to the channel

00:06:34.320 --> 00:06:36.490
to get more videos like this.

00:06:36.490 --> 00:06:38.820
Now it's your turn to
go out there and create

00:06:38.820 --> 00:06:42.690
some great models.

00:06:42.690 --> 00:06:45.270
And don't forget to
tell us all about it.

00:06:45.270 --> 00:06:48.320
[MUSIC PLAYING]

