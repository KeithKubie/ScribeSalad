WEBVTT
Kind: captions
Language: en

00:00:01.680 --> 00:00:04.590
- [Announcer] This program
is a presentation of UCTV

00:00:04.590 --> 00:00:07.733
for educational and
noncommercial use only.

00:00:10.563 --> 00:00:14.480
(electronic synthesizer music)

00:00:43.890 --> 00:00:47.703
- So first an update from yesterday.

00:00:49.376 --> 00:00:54.376
I paraphrased a quote
that science marches on,

00:00:54.730 --> 00:00:56.840
funeral by funeral.

00:00:56.840 --> 00:01:00.453
Here's the exact quote as
emailed to me this afternoon.

00:01:02.250 --> 00:01:04.357
It comes from Max Plank.

00:01:04.357 --> 00:01:07.007
"A new scientific truth does not triumph

00:01:07.007 --> 00:01:10.887
"by convincing its opponents
and making them see the light,

00:01:10.887 --> 00:01:14.487
"but rather because its
opponents eventually die,

00:01:14.487 --> 00:01:18.050
"and a new generation grows
up that is familiar with it."

00:01:18.050 --> 00:01:22.617
And paraphrasing, "Truth never triumphs,

00:01:22.617 --> 00:01:26.450
"its opponents just die
out," or the version I gave.

00:01:26.450 --> 00:01:29.363
Thanks to Paul Sas for sending me that.

00:01:35.980 --> 00:01:38.280
Much of what I'm gonna talk about today

00:01:39.450 --> 00:01:42.380
comes from my book, "Nudge,"

00:01:42.380 --> 00:01:44.300
which we'll get to in a little while

00:01:45.450 --> 00:01:47.443
that was written with Cass Sunstein.

00:01:49.670 --> 00:01:54.220
Cass and I tried to make
the distinction between

00:01:54.220 --> 00:01:59.220
the people that economists
model and the rest of us,

00:02:00.290 --> 00:02:05.290
and to shorten it, we call
the agents of economic models,

00:02:06.420 --> 00:02:10.510
econs, and real people, humans.

00:02:10.510 --> 00:02:14.430
Now, how do they differ?

00:02:14.430 --> 00:02:19.430
Well economists really
assume that economists

00:02:20.839 --> 00:02:24.840
are as smart as they are

00:02:24.840 --> 00:02:28.800
or really as smart as they think they are.

00:02:28.800 --> 00:02:33.800
And the norm in economics has become

00:02:34.120 --> 00:02:39.120
that suppose some old guy
like me writes down some model

00:02:39.380 --> 00:02:41.820
of rational behavior and then,

00:02:41.820 --> 00:02:44.443
a younger guy, like Matthew, comes along,

00:02:45.600 --> 00:02:48.613
but a rational version of
Matthew in every sense,

00:02:50.550 --> 00:02:55.280
and thinks of way in which
the agents in my model

00:02:55.280 --> 00:02:57.410
could be smarter.

00:02:57.410 --> 00:02:59.850
Then the norm has become

00:02:59.850 --> 00:03:03.410
that his model is better than my model.

00:03:03.410 --> 00:03:07.420
And as a result, the
agents in economic models

00:03:07.420 --> 00:03:12.160
have gotten smarter and
smarter over the last 60 years,

00:03:12.160 --> 00:03:13.243
and we haven't.

00:03:14.635 --> 00:03:18.780
So as a result, there's
been this growing divide

00:03:18.780 --> 00:03:22.320
that probably peaked in the 1980s

00:03:22.320 --> 00:03:27.320
of when hyper-rational models
were very much in fashion,

00:03:28.570 --> 00:03:31.900
and so the agents are
really, really smart,

00:03:31.900 --> 00:03:35.020
and we're just sort of plodding along.

00:03:35.020 --> 00:03:39.470
Now thanks to neuro-economics,

00:03:39.470 --> 00:03:43.573
we've been able to
establish the actual truth.

00:03:45.218 --> 00:03:48.218
(audience laughing)

00:03:51.670 --> 00:03:52.720
So, there you go.

00:03:52.720 --> 00:03:56.610
That's a visual image
of bounded rationality.

00:03:56.610 --> 00:03:58.853
I was trying to get this.

00:04:00.120 --> 00:04:01.680
That's the last thing I'm going to say

00:04:01.680 --> 00:04:03.683
about neuro-economics.

00:04:08.240 --> 00:04:12.620
The second way in which economists differ,

00:04:12.620 --> 00:04:16.160
econs differ from humans is,

00:04:16.160 --> 00:04:18.660
humans have self-control problems.

00:04:18.660 --> 00:04:21.810
Homer, when told by a gun shop owner

00:04:21.810 --> 00:04:23.610
that there's a five-day waiting period

00:04:23.610 --> 00:04:26.270
for a gun he wants to
buy to kill somebody,

00:04:26.270 --> 00:04:27.937
says, "Five days?

00:04:27.937 --> 00:04:29.777
"But I'm mad now!"

00:04:31.400 --> 00:04:36.400
Now Matthew and his colleagues
have called this combination

00:04:38.120 --> 00:04:41.920
of no self-control and no self-insight

00:04:41.920 --> 00:04:44.973
about one's self-control, naivete.

00:04:46.998 --> 00:04:51.437
So this is like the
pathologically uncontrolled person

00:04:53.340 --> 00:04:55.440
who has no clue,

00:04:55.440 --> 00:04:59.780
and actual humans are slightly
more with it than that,

00:04:59.780 --> 00:05:04.780
and they lie somewhere
between this pathetic creature

00:05:04.830 --> 00:05:07.870
and a very smart version of this

00:05:07.870 --> 00:05:12.870
that David Laibson has
suggested of sophistication.

00:05:13.430 --> 00:05:15.520
The people I'm going to talk about today

00:05:15.520 --> 00:05:18.200
are neither as dumb as Homer Simpson

00:05:18.200 --> 00:05:19.944
or as smart as David Laibson,

00:05:19.944 --> 00:05:23.203
but there's a big gap between those two.

00:05:25.480 --> 00:05:29.130
The third way in which
humans differ from econs

00:05:31.130 --> 00:05:33.563
is that humans are nicer.

00:05:35.390 --> 00:05:39.843
So econs are unboundedly unscrupulous.

00:05:43.764 --> 00:05:47.300
Any interaction between
a human and an econ

00:05:47.300 --> 00:05:49.873
is an opportunity for strategy,

00:05:50.760 --> 00:05:53.100
and they will take advantage of it

00:05:53.100 --> 00:05:55.873
if they think it's in
their long-run interest.

00:05:57.626 --> 00:06:00.640
Now, in Matthew's honor,

00:06:00.640 --> 00:06:04.000
I'm bringing my empirical
evidence of this.

00:06:04.000 --> 00:06:06.123
This is the fruit stand in Ithica.

00:06:06.990 --> 00:06:09.030
It's selling rhubarb.

00:06:09.030 --> 00:06:11.310
You can't quite see the rhubarb,
but you can see the sign,

00:06:11.310 --> 00:06:13.990
and you can see the box with the lock.

00:06:13.990 --> 00:06:17.240
This is really my model of human nature,

00:06:17.240 --> 00:06:21.846
which is that there are enough
people who will put money in

00:06:21.846 --> 00:06:25.800
that it's worthwhile for the
farmer to put the rhubarb out,

00:06:25.800 --> 00:06:28.820
but there's also enough econs around

00:06:28.820 --> 00:06:32.123
who will take the money if
you just leave it lying there.

00:06:34.024 --> 00:06:37.810
So finally, we get to markets.

00:06:37.810 --> 00:06:41.840
And behavioral economics
is a branch of economics,

00:06:41.840 --> 00:06:46.030
a way of doing economics,
not a branch of psychology,

00:06:46.030 --> 00:06:49.660
precisely because what we think about

00:06:49.660 --> 00:06:54.210
is what happens when you
put humans into markets,

00:06:54.210 --> 00:06:57.930
and especially if
there's some econs around

00:06:57.930 --> 00:07:01.340
trying to take advantage of them.

00:07:01.340 --> 00:07:06.340
Now, the standard assumption about markets

00:07:11.860 --> 00:07:14.590
is that they are efficient.

00:07:14.590 --> 00:07:18.133
And here's my proof that they're not.

00:07:18.133 --> 00:07:21.133
(audience laughing)

00:07:25.070 --> 00:07:29.810
Now, this is a picture that
was taken in Buenos Aires.

00:07:29.810 --> 00:07:34.290
And now, there are some
of my finance colleagues,

00:07:34.290 --> 00:07:36.070
like Mark Rubenstein,

00:07:36.070 --> 00:07:38.170
who's sitting up in the front of the room,

00:07:38.170 --> 00:07:39.067
who will probably say,

00:07:39.067 --> 00:07:43.130
"No, this is not a violation
of the law of one price,"

00:07:43.130 --> 00:07:48.130
which is the fundamental
driver of finance theory.

00:07:48.527 --> 00:07:53.527
"No, this is price discrimination
against stupid Americans

00:07:55.587 --> 00:07:59.520
"who don't know the Spanish for oranges."

00:07:59.520 --> 00:08:03.300
Now, notice they have to be so stupid

00:08:03.300 --> 00:08:06.741
that they don't see that the
two pictures are identical.

00:08:06.741 --> 00:08:07.860
(audience laughing)

00:08:07.860 --> 00:08:12.860
Which kind of violates the
unlimited rationality hypothesis.

00:08:12.980 --> 00:08:15.692
So you have to give up one or the other.

00:08:15.692 --> 00:08:16.960
(audience laughing)

00:08:16.960 --> 00:08:20.790
Now, Matthew would
prefer that I would stop

00:08:20.790 --> 00:08:23.113
my discussion of finance at this point,

00:08:24.400 --> 00:08:29.400
but some think this isn't
completely convincing.

00:08:30.560 --> 00:08:35.560
So let me spend five minutes
on something more convincing.

00:08:41.040 --> 00:08:43.080
The most efficient place,

00:08:43.080 --> 00:08:46.080
where we would expect
markets to work best,

00:08:46.080 --> 00:08:50.847
is financial markets because
the transactions costs are low,

00:08:51.780 --> 00:08:55.590
essentially zero in most cases,

00:08:55.590 --> 00:08:58.940
and the stakes are very large.

00:08:58.940 --> 00:09:03.440
So if anything is gonna
work like a textbook model,

00:09:03.440 --> 00:09:05.490
it should be the New York Stock Exchange.

00:09:06.480 --> 00:09:11.480
So I got interested in finance
precisely because of this,

00:09:11.960 --> 00:09:16.960
and it's sort of the New
York, New York model.

00:09:19.780 --> 00:09:23.430
If you can make it there,
you can make it anywhere.

00:09:23.430 --> 00:09:28.430
My feeling was if we could
make some inroads in finance,

00:09:28.480 --> 00:09:32.810
then it would sort of diffuse this idea

00:09:32.810 --> 00:09:36.793
that we're only about toy
problems in laboratories.

00:09:38.680 --> 00:09:42.060
I was helped with one
of my first students,

00:09:42.060 --> 00:09:44.323
I think in fact my first student,

00:09:45.595 --> 00:09:47.193
a Belgian named Werner DeBondt.

00:09:48.390 --> 00:09:52.927
And he wanted to do finance,
so I said, "Okay, why not?"

00:09:55.200 --> 00:09:59.720
So we wanted to test one
principle of financial economics,

00:09:59.720 --> 00:10:04.288
which is that you can't predict
the future from the past.

00:10:04.288 --> 00:10:09.288
So markets can't be efficient
if this is violated,

00:10:09.320 --> 00:10:11.670
because otherwise you
could make tons of money.

00:10:12.720 --> 00:10:17.480
Now, at one point, Michael Jensen,

00:10:17.480 --> 00:10:20.630
a leading proponent of market
efficiency at this time,

00:10:20.630 --> 00:10:23.763
he's now become a
born-again, something else,

00:10:25.960 --> 00:10:30.610
Jensen said famously that the
efficient market hypothesis

00:10:30.610 --> 00:10:33.810
is the best established
fact in social science.

00:10:33.810 --> 00:10:36.360
Now, it helped he hadn't
read much social science

00:10:36.360 --> 00:10:39.593
at that time, but anyway,
that was his claim.

00:10:42.122 --> 00:10:44.130
So here's what Werner and I did.

00:10:44.130 --> 00:10:45.723
I mean, this is lazy finances.

00:10:48.436 --> 00:10:50.760
Especially since Werner did all
the programming. (chuckling)

00:10:50.760 --> 00:10:55.760
We formed portfolios of
the 50 biggest losers

00:10:58.530 --> 00:11:03.280
over a five-year period and
then the 50 biggest winners.

00:11:03.280 --> 00:11:07.830
And then we tracked those
portfolios for the next 5 years,

00:11:07.830 --> 00:11:08.733
how would they do?

00:11:09.810 --> 00:11:12.850
Now, the efficient market hypothesis

00:11:12.850 --> 00:11:16.830
says they should do the
same, because remember,

00:11:16.830 --> 00:11:19.630
you can't predict the
future from the past.

00:11:19.630 --> 00:11:24.253
So we should just see, they
should be indistinguishable.

00:11:25.570 --> 00:11:26.970
So here's what we find.

00:11:26.970 --> 00:11:31.113
This is averaging over many years of data.

00:11:32.490 --> 00:11:36.640
We see that losers do very well.

00:11:36.640 --> 00:11:41.640
They outperform the market by about 30%.

00:11:41.930 --> 00:11:44.520
The winners do poorly.

00:11:44.520 --> 00:11:47.180
They underperform by about 10%.

00:11:47.180 --> 00:11:50.713
And after five years, the
difference is about 40%.

00:11:52.720 --> 00:11:55.240
Now, there's some funny
things in this chart.

00:11:55.240 --> 00:11:56.860
You'll notice that the losers

00:11:56.860 --> 00:11:59.133
are doing all their winning in January.

00:12:00.100 --> 00:12:02.433
We have no idea why that was.

00:12:03.282 --> 00:12:04.250
It happened to be true.

00:12:04.250 --> 00:12:09.070
There are other funny things
that happened in January.

00:12:09.070 --> 00:12:12.460
That seems to have sort
of died out over time

00:12:12.460 --> 00:12:15.400
after academics started writing about it.

00:12:15.400 --> 00:12:16.883
It kind of shifted around,

00:12:18.030 --> 00:12:23.030
but this loser effect or
more general versions of it

00:12:23.500 --> 00:12:24.590
is still quite robust.

00:12:24.590 --> 00:12:26.233
It's called the value effect.

00:12:27.610 --> 00:12:30.820
Now there was an army--

00:12:30.820 --> 00:12:32.560
I was at Cornell when this was written.

00:12:32.560 --> 00:12:34.550
There was an army of University of Chicago

00:12:34.550 --> 00:12:37.920
finance graduates students put to work

00:12:37.920 --> 00:12:40.920
to find our programming error.

00:12:40.920 --> 00:12:45.920
Because it was known this
cannot possibly be true.

00:12:47.810 --> 00:12:49.780
So what mistake did we make?

00:12:49.780 --> 00:12:53.743
Well, it turns out
DeBondt, bless his heart,

00:12:55.350 --> 00:12:57.023
doesn't make programming errors.

00:12:58.010 --> 00:13:03.010
He didn't trust CAM regression programs

00:13:03.870 --> 00:13:07.060
so he would write them
himself to check to make sure

00:13:07.060 --> 00:13:10.340
that the CAM programs were working.

00:13:10.340 --> 00:13:12.740
So here are the complaints.

00:13:12.740 --> 00:13:14.670
The first is that these losers

00:13:14.670 --> 00:13:18.370
must somehow be riskier than the winners

00:13:19.310 --> 00:13:21.733
because otherwise, why
are they outperforming?

00:13:23.230 --> 00:13:27.560
Now the standard measure
of risk at this time

00:13:27.560 --> 00:13:28.930
was something called beta.

00:13:28.930 --> 00:13:30.723
I won't go into what that is.

00:13:31.640 --> 00:13:34.393
It's co-variants with
the market essentially.

00:13:35.540 --> 00:13:38.150
The losers actually had
lower betas than the winners

00:13:38.150 --> 00:13:39.763
so that couldn't have been it.

00:13:40.840 --> 00:13:43.080
But then people started getting creative

00:13:43.080 --> 00:13:44.410
in how they measured beta

00:13:44.410 --> 00:13:46.690
and if you measured beta afterwards.

00:13:46.690 --> 00:13:49.720
Well, a big argument ensued.

00:13:49.720 --> 00:13:53.170
All I can say is no one
has ever found a way

00:13:53.170 --> 00:13:57.750
in which these losers are
actually riskier than the winners.

00:13:57.750 --> 00:14:01.010
But in some metaphysical sense,

00:14:01.010 --> 00:14:03.610
if you want to call them
riskier, you're welcome to.

00:14:06.100 --> 00:14:09.860
Then they pointed out that
the losers were smaller,

00:14:09.860 --> 00:14:13.080
and there's a well-known phenomena

00:14:13.080 --> 00:14:15.820
that smaller stocks
outperform bigger stocks.

00:14:15.820 --> 00:14:18.690
Now what's true is they
had become smaller.

00:14:18.690 --> 00:14:20.680
They didn't start out that small,

00:14:20.680 --> 00:14:23.920
but if you're the 50
worst-performing stocks

00:14:23.920 --> 00:14:27.250
over a five year period,
you've really shrunk,

00:14:27.250 --> 00:14:30.570
and in any case, finance
has absolutely no theory

00:14:30.570 --> 00:14:35.090
about why portfolios of
small firms should do worse

00:14:35.090 --> 00:14:37.000
than big firms.

00:14:37.000 --> 00:14:39.980
So this is really just
shifting the anomaly

00:14:39.980 --> 00:14:41.383
from one place to another.

00:14:43.410 --> 00:14:44.960
So I'm gonna spare you

00:14:44.960 --> 00:14:48.140
the thirty years of arguing about this

00:14:49.640 --> 00:14:54.640
and move on to the other
dimension of market efficiency,

00:14:57.340 --> 00:14:58.833
the price is right.

00:15:02.840 --> 00:15:07.840
The idea here is that
in an efficient market

00:15:08.780 --> 00:15:13.780
prices are equal to the
intrinsic value of the asset.

00:15:14.420 --> 00:15:19.010
So that's the second pillar
of efficient market theory,

00:15:19.010 --> 00:15:24.010
and in some ways, it's
an easier one to defend

00:15:24.100 --> 00:15:28.790
than the first one
because most of the time,

00:15:28.790 --> 00:15:29.893
it's not testable.

00:15:30.760 --> 00:15:33.590
And that's handy if you
want to defend a theory

00:15:33.590 --> 00:15:35.540
is to make it untestable,

00:15:36.620 --> 00:15:39.240
and it's untestable because
you don't know intrinsic value.

00:15:39.240 --> 00:15:42.287
Stocks don't come with labels saying,

00:15:42.287 --> 00:15:44.610
"Here's my intrinsic value."

00:15:44.610 --> 00:15:49.313
So you need to be clever to
figure out how to test this.

00:15:51.810 --> 00:15:53.763
I have a colleague who's clever,

00:15:55.001 --> 00:15:58.900
a guy called Owen Lamont, one
of my colleagues at Chicago,

00:15:58.900 --> 00:16:01.443
and here's the story we investigated.

00:16:02.690 --> 00:16:06.823
There was a company in
Silicon Valley in the 1990s,

00:16:07.700 --> 00:16:10.987
and if you will remember
back to the 1990s,

00:16:10.987 --> 00:16:14.370
the stock market was going up very fast,

00:16:14.370 --> 00:16:19.020
tech companies were
doubling every few weeks,

00:16:19.020 --> 00:16:24.020
and it was an exciting time
to be a stock on the NASDAQ.

00:16:25.590 --> 00:16:29.840
But 3Com which owned Palm Pilots,

00:16:29.840 --> 00:16:34.158
which you can think of as a
very clunky version of an iPhone

00:16:34.158 --> 00:16:36.540
that doesn't make calls,

00:16:36.540 --> 00:16:39.263
but it was thought to be
quite sexy at the time,

00:16:40.819 --> 00:16:42.433
3Com is being ignored.

00:16:44.200 --> 00:16:48.600
So here's a plot of 3Com's
stock price during this period.

00:16:48.600 --> 00:16:53.600
Here's the summer of 1999
which was a very exciting time

00:16:53.720 --> 00:16:56.823
for NASDAQ stocks but not for 3Com.

00:16:59.426 --> 00:17:00.460
So 3Com decides, "We
need to unleash value,

00:17:06.277 --> 00:17:10.013
"and how we're gonna do that,
we're gonna spin off Palm"

00:17:11.287 --> 00:17:13.830
"and make it its own company."

00:17:13.830 --> 00:17:16.990
Now of course, in an efficient market,

00:17:16.990 --> 00:17:18.510
it would make no difference

00:17:18.510 --> 00:17:22.660
whether Palm is inside of 3Com or outside.

00:17:22.660 --> 00:17:26.920
However, you can see the
market really liked this idea.

00:17:26.920 --> 00:17:31.920
So they announce here that
they're gonna spin off Palm,

00:17:32.170 --> 00:17:37.170
and their stock price
jumps from about 42 to 100.

00:17:37.490 --> 00:17:41.710
And as the IPO of Palm
gets nearer and nearer,

00:17:41.710 --> 00:17:44.323
3Com is racing up.

00:17:45.750 --> 00:17:48.910
So here are the details of the spin off.

00:17:48.910 --> 00:17:50.553
The details are important.

00:17:52.930 --> 00:17:55.540
This second bullet is the crucial number.

00:17:55.540 --> 00:18:00.540
Each 3Com shareholder
gets 1.5 shares of Palm.

00:18:02.530 --> 00:18:05.910
Now with my high-powered mathematics,

00:18:05.910 --> 00:18:08.970
I'm able to derive the
following inequality

00:18:08.970 --> 00:18:12.910
that that means that 3Com's share price

00:18:12.910 --> 00:18:17.910
must be equal or greater
than 1.5 Palm because

00:18:17.950 --> 00:18:21.650
every 3Com shareholder got
one and half shares of Palm.

00:18:21.650 --> 00:18:22.483
Okay?

00:18:23.415 --> 00:18:25.503
On the first day of trading,

00:18:26.950 --> 00:18:30.380
the market goes crazy over Palm.

00:18:30.380 --> 00:18:33.993
At one point the price is as high as $165,

00:18:35.110 --> 00:18:38.770
and ends up settling
the day at $95 a share.

00:18:38.770 --> 00:18:43.600
Now if you multiply $95
by 1.5, you get $142.

00:18:43.600 --> 00:18:46.620
Remember, 3Com was selling for $100.

00:18:46.620 --> 00:18:51.033
So that means it should go up by 42%.

00:18:52.830 --> 00:18:53.730
Actually, it fell.

00:18:55.278 --> 00:18:57.290
It fell by 20%.

00:18:57.290 --> 00:19:00.090
And at the close of the market,

00:19:00.090 --> 00:19:04.150
the market was valuing 3Com, the stub,

00:19:04.150 --> 00:19:08.130
meaning its value less
its interest in Palm,

00:19:08.130 --> 00:19:09.993
at minus $23 billion.

00:19:11.540 --> 00:19:15.260
Now there's a really
basic principle of finance

00:19:15.260 --> 00:19:19.363
which is asset prices cannot be negative.

00:19:19.363 --> 00:19:20.960
(audience laughing)

00:19:20.960 --> 00:19:21.793
Right?

00:19:21.793 --> 00:19:22.993
Because you can throw them away.

00:19:24.550 --> 00:19:29.270
But here we go, minus $23
billion, that's fairly negative.

00:19:29.270 --> 00:19:31.090
Here's a plot.

00:19:31.090 --> 00:19:35.140
So 3Com's stub was worth minus $60 a share

00:19:35.140 --> 00:19:37.180
at the end of that day.

00:19:37.180 --> 00:19:39.590
Some sanity came in the next day.

00:19:39.590 --> 00:19:42.780
It was only worth minus $38 a share,

00:19:42.780 --> 00:19:46.453
and then it lasted for several months.

00:19:47.930 --> 00:19:51.900
Finally, at the IPO
when Palm was released,

00:19:51.900 --> 00:19:54.400
3Com was worth some positive amount,

00:19:54.400 --> 00:19:55.890
which of course it had to be.

00:19:55.890 --> 00:19:58.370
It couldn't be worth a negative amount

00:19:58.370 --> 00:19:59.583
once it started trading.

00:20:00.710 --> 00:20:03.763
Okay, so where does this leave us?

00:20:05.950 --> 00:20:10.760
We're more like homer
economicus than homo economicus,

00:20:10.760 --> 00:20:14.113
and markets are not perfect.

00:20:15.440 --> 00:20:18.470
So what does that mean for government?

00:20:18.470 --> 00:20:21.860
Does that mean that we should
have governments come in

00:20:21.860 --> 00:20:23.340
and run everything?

00:20:23.340 --> 00:20:28.340
Should we abandon markets and
adopt Soviet-style systems?

00:20:32.680 --> 00:20:35.470
Well, you can guess my
answer to that is no,

00:20:35.470 --> 00:20:38.130
and in part because of the realization

00:20:38.130 --> 00:20:40.283
that governments are run by humans too,

00:20:41.770 --> 00:20:43.730
and in fact, running an economy

00:20:43.730 --> 00:20:46.023
is an impossibly complicated task.

00:20:47.000 --> 00:20:49.960
So what the role of government should be

00:20:49.960 --> 00:20:54.750
is an interesting problem
with not an obvious answer,

00:20:54.750 --> 00:20:59.707
and that of course is what Cass and I

00:20:59.707 --> 00:21:02.210
try to address in our book.

00:21:02.210 --> 00:21:06.910
I should say Cass is probably
the most distinguished

00:21:06.910 --> 00:21:11.337
constitutional law professor
of his era, a great friend,

00:21:12.620 --> 00:21:15.730
and now is, well in the media,

00:21:15.730 --> 00:21:18.087
they call him "the regulation czar."

00:21:19.390 --> 00:21:23.350
His official title is he's
the Director of the Office

00:21:23.350 --> 00:21:26.640
of Information and Regulatory Affairs.

00:21:26.640 --> 00:21:30.133
And so, I call him the nudger-in-chief.

00:21:32.200 --> 00:21:35.760
So when we set out to write this book,

00:21:35.760 --> 00:21:37.320
Cass likes to write books.

00:21:37.320 --> 00:21:38.700
I had never really written a book.

00:21:38.700 --> 00:21:43.700
I had stapled a couple,
collections of papers.

00:21:44.686 --> 00:21:46.460
Have we mentioned my laziness?

00:21:46.460 --> 00:21:47.920
Yeah, I think that's come up.

00:21:47.920 --> 00:21:52.920
So when we wrote this
book, we had two goals.

00:21:53.270 --> 00:21:56.810
We called them, when we were
talking among ourselves,

00:21:56.810 --> 00:22:00.210
the ambitious goal and the
ridiculously ambitious goal.

00:22:00.210 --> 00:22:03.770
So the ambitious goal was to take

00:22:06.060 --> 00:22:11.060
the work I and my corrupted young friends

00:22:11.100 --> 00:22:14.070
have been doing for 30 years or so

00:22:14.070 --> 00:22:16.920
and bring it to a lay audience

00:22:16.920 --> 00:22:20.033
and see what it might have
to say about public policy.

00:22:21.520 --> 00:22:23.020
So that was the ambitious goal.

00:22:23.020 --> 00:22:26.250
The ridiculously ambitious goal

00:22:26.250 --> 00:22:30.680
was to try to create a political framework

00:22:30.680 --> 00:22:32.723
that was neither left nor right.

00:22:33.610 --> 00:22:38.610
And now, in the US, that
is a ridiculous goal,

00:22:41.370 --> 00:22:44.150
and Glen Beck has decided

00:22:44.150 --> 00:22:47.423
that Cass Sunstein is the
most dangerous man in America.

00:22:49.270 --> 00:22:52.765
Quite an honor, I think, for Cass but--

00:22:52.765 --> 00:22:55.765
(audience laughing)

00:22:57.350 --> 00:23:00.350
Glen Beck doesn't know much about me.

00:23:00.350 --> 00:23:03.770
If he knew, he would realize
I'm more dangerous inherently,

00:23:03.770 --> 00:23:06.280
but Cass has a more dangerous job.

00:23:06.280 --> 00:23:11.150
But in other countries there's some hope

00:23:11.150 --> 00:23:15.540
that this approach that I'm
going to talk to you about

00:23:16.740 --> 00:23:19.340
isn't really ideological.

00:23:19.340 --> 00:23:24.340
So the conservative party in the UK has,

00:23:26.600 --> 00:23:28.380
David Cameron read the book

00:23:28.380 --> 00:23:33.017
and one summer, assigned
it to all the Tory MPs,

00:23:34.490 --> 00:23:39.030
and they recently created
what is known in number 10

00:23:39.030 --> 00:23:40.573
as the nudge unit.

00:23:41.566 --> 00:23:44.990
The official name is the
behavioral insight team,

00:23:44.990 --> 00:23:48.490
and I'm an advisor to that group.

00:23:48.490 --> 00:23:51.740
And our charge is to think of ways

00:23:51.740 --> 00:23:54.550
of using behavioral science to improve

00:23:54.550 --> 00:23:56.143
whatever government is doing.

00:23:57.200 --> 00:24:02.200
Now, it is fair to say that the
conservative party in the UK

00:24:02.650 --> 00:24:06.720
is not very different from the
Democratic party in the US,

00:24:06.720 --> 00:24:11.720
but I'm just back from Korea
where the prime minister there

00:24:12.720 --> 00:24:15.610
is a conservative by any definition.

00:24:15.610 --> 00:24:18.350
He also assigned the book to his cabinet,

00:24:18.350 --> 00:24:22.260
and so there is some hope, we think,

00:24:22.260 --> 00:24:24.780
that what I'm about to tell you about

00:24:24.780 --> 00:24:29.780
could be an idea that
either party could take on.

00:24:30.400 --> 00:24:32.380
So what is that idea?

00:24:32.380 --> 00:24:36.993
It comes with a really snappy
name: libertarian paternalism.

00:24:38.530 --> 00:24:40.650
Now as you know, both of those words

00:24:40.650 --> 00:24:42.723
are unpopular in this country.

00:24:43.820 --> 00:24:46.020
Libertarians are thought to be

00:24:46.020 --> 00:24:49.823
crazy people who live in
Montana and Hyde Park,

00:24:51.966 --> 00:24:53.490
a neighborhood in Chicago,

00:24:53.490 --> 00:24:56.770
but they're loved compared to paternalists

00:24:56.770 --> 00:25:01.120
who are reviled everywhere,
possibly even in Berkeley.

00:25:01.120 --> 00:25:06.120
So our idea was to take these
two hated, contradictory words

00:25:08.130 --> 00:25:09.113
and combine them.

00:25:10.270 --> 00:25:11.420
Right, that's a winner.

00:25:16.376 --> 00:25:19.050
Here's the way we do that.

00:25:19.050 --> 00:25:24.050
By libertarian, what we mean
simply is choice preserving.

00:25:25.360 --> 00:25:29.033
So we never want to tell
anybody what they have to do.

00:25:30.090 --> 00:25:33.350
By paternalism, we simply mean

00:25:35.340 --> 00:25:39.490
that we care about people's outcomes

00:25:39.490 --> 00:25:41.823
as defined by themselves.

00:25:43.440 --> 00:25:48.440
So that's what we want to do,
and how do we achieve this?

00:25:49.530 --> 00:25:53.720
We achieve it with something
we call choice architecture.

00:25:53.720 --> 00:25:56.850
So who is a choice architect?

00:25:56.850 --> 00:26:00.160
A choice architect is anyone
who designs the environment

00:26:00.160 --> 00:26:01.603
in which we choose.

00:26:04.110 --> 00:26:07.490
Consider if you go to a restaurant,

00:26:07.490 --> 00:26:12.490
the chef has decided what food
items he or she will prepare,

00:26:13.830 --> 00:26:18.830
but there's someone who gets
to put that on a piece of paper

00:26:20.485 --> 00:26:24.140
and in some order.

00:26:24.140 --> 00:26:28.560
So the place we went to lunch today,

00:26:28.560 --> 00:26:31.343
what's it called, Gather,
a very nice restaurant,

00:26:32.490 --> 00:26:34.920
there were three categories of things.

00:26:34.920 --> 00:26:38.420
There were salads, there were pizzas,

00:26:38.420 --> 00:26:41.420
and there were sandwiches, and
maybe there was a fourth one.

00:26:43.080 --> 00:26:46.090
Now it needn't be grouped
in that way, but they were.

00:26:46.090 --> 00:26:50.200
And then within each
category, there's some order.

00:26:50.200 --> 00:26:52.360
Somebody's deciding that.

00:26:52.360 --> 00:26:54.453
Well that person is the choice architect.

00:26:55.560 --> 00:26:58.960
Now, so what?

00:26:58.960 --> 00:27:02.740
Well here's the most important
point I'm gonna make today.

00:27:02.740 --> 00:27:05.920
There's no alternative
to choice architecture.

00:27:05.920 --> 00:27:09.283
Sometimes people accuse
Cass and I of meddling.

00:27:10.440 --> 00:27:12.030
The point I want you to leave with today

00:27:12.030 --> 00:27:13.823
is it's impossible not to meddle.

00:27:15.100 --> 00:27:18.093
So here's the example we
used to start the book.

00:27:19.020 --> 00:27:23.210
Suppose that the director of
school cafeterias in Berkeley

00:27:24.134 --> 00:27:27.500
discovers through experimentation

00:27:27.500 --> 00:27:31.550
that the order in which
the food is displayed

00:27:31.550 --> 00:27:33.653
influences what the kids eat.

00:27:34.500 --> 00:27:39.240
So if the tofu is in front of the yogurt,

00:27:39.240 --> 00:27:42.560
then more people will take
it than the other way around.

00:27:42.560 --> 00:27:46.315
I assume those are the only
two things that are served.

00:27:46.315 --> 00:27:48.280
(audience laughing)

00:27:48.280 --> 00:27:50.860
At the Berkeley school cafeteria.

00:27:50.860 --> 00:27:55.547
Now, armed with that
information, what should she do?

00:28:01.820 --> 00:28:03.890
How should she arrange the food?

00:28:03.890 --> 00:28:08.890
Well, one choice would be to
arrange the food in such a way

00:28:09.170 --> 00:28:12.243
as to make the kids healthy and happy.

00:28:13.320 --> 00:28:16.793
So somehow defined,
make the kids best off.

00:28:17.990 --> 00:28:20.020
Okay, that's one option.

00:28:20.020 --> 00:28:21.943
She could try to make the kids fatter.

00:28:23.180 --> 00:28:27.240
She could fool herself into thinking

00:28:27.240 --> 00:28:29.400
she can avoid choice architecture

00:28:29.400 --> 00:28:31.800
by arranging the food at random,

00:28:31.800 --> 00:28:34.800
but of course that's
just gonna create havoc.

00:28:34.800 --> 00:28:37.600
Imagine if all the
ingredients in the salad bar

00:28:37.600 --> 00:28:40.060
are scattered all around the room.

00:28:40.060 --> 00:28:43.050
So the lettuce is over there,
and the tomato's over here

00:28:43.050 --> 00:28:45.670
and the dressings are back there.

00:28:45.670 --> 00:28:48.523
Right, the line will
come to a complete stop.

00:28:50.450 --> 00:28:52.780
Or she could follow the Illinois,

00:28:52.780 --> 00:28:55.860
state of Illinois model
and feature the items

00:28:55.860 --> 00:28:58.520
for which it gets the largest bribes.

00:28:58.520 --> 00:29:02.540
But again, the point I want to make is

00:29:02.540 --> 00:29:04.220
she must choose something.

00:29:04.220 --> 00:29:07.790
It's impossible not to meddle.

00:29:07.790 --> 00:29:12.473
So given that, we argue,
why not pick something good?

00:29:14.140 --> 00:29:19.140
Now, this was a hypothetical example.

00:29:19.410 --> 00:29:23.020
Right, this came out of my
head this school cafeteria.

00:29:23.020 --> 00:29:25.200
There's no study that I knew of.

00:29:25.200 --> 00:29:29.210
It just made sense to me
that that would be true.

00:29:29.210 --> 00:29:31.360
Thanks to Brian Wansink,

00:29:31.360 --> 00:29:34.730
the author of a brilliant
book called "Mindless Eating"

00:29:34.730 --> 00:29:37.613
this hypothetical example is now true.

00:29:39.793 --> 00:29:44.793
So he's doing experiments
in school cafeterias.

00:29:45.120 --> 00:29:47.260
He's actually rearranging the food.

00:29:47.260 --> 00:29:52.260
So in one school, they've
increased the salad uptake

00:29:53.380 --> 00:29:55.570
just by moving the salad bar.

00:29:55.570 --> 00:29:59.230
In another school, they've
increased the fruit consumption

00:29:59.230 --> 00:30:02.470
by putting the fruit in a nicer display.

00:30:02.470 --> 00:30:04.630
And if you're interested in this,

00:30:04.630 --> 00:30:09.490
look at Brian Wansink's website

00:30:09.490 --> 00:30:11.793
or go to smarterlunchrooms.org.

00:30:13.080 --> 00:30:16.520
They just got a million dollar
grant from the government

00:30:16.520 --> 00:30:18.883
to continue this work.

00:30:20.520 --> 00:30:25.520
Now so that's one sort of high-brow nudge.

00:30:25.980 --> 00:30:27.713
Here's a more famous one.

00:30:30.230 --> 00:30:34.620
This is a picture of the urinal

00:30:34.620 --> 00:30:37.970
in Schiphol Airport in Amsterdam.

00:30:37.970 --> 00:30:42.313
You can see if you just squint,
there's something in there.

00:30:44.650 --> 00:30:48.370
So I have a blow up of
that. (audience laughing)

00:30:48.370 --> 00:30:52.810
So some genius (audience laughing)

00:30:52.810 --> 00:30:57.810
decided that if you etch
the image of a housefly

00:31:00.890 --> 00:31:05.890
in the urinals then-- (audience laughing)

00:31:09.070 --> 00:31:13.610
Now, I have to explain this that men,

00:31:13.610 --> 00:31:15.733
we have a lot on our minds, you know?

00:31:15.733 --> 00:31:18.733
(audience laughing)

00:31:20.047 --> 00:31:22.877
"The Giants have a big game tonight,"

00:31:24.090 --> 00:31:25.210
who are we going to start

00:31:25.210 --> 00:31:28.240
in our fantasy football league team?

00:31:28.240 --> 00:31:32.162
So while we're taking
care of our business,

00:31:32.162 --> 00:31:35.070
we're thinking about other things.

00:31:35.070 --> 00:31:38.180
And I'm sure there's an
evolutionary explanation

00:31:38.180 --> 00:31:40.040
for what I'm about to say.

00:31:40.040 --> 00:31:43.614
If you give us a target, we will aim.

00:31:43.614 --> 00:31:47.000
(audience laughing)

00:31:47.000 --> 00:31:50.873
So, and here's hard data.

00:31:52.741 --> 00:31:55.280
(audience laughing)

00:31:55.280 --> 00:31:58.880
Spillage has been reduced by--

00:31:58.880 --> 00:32:02.153
I don't know the
empirical methods on this.

00:32:02.153 --> 00:32:03.670
(audience laughing)

00:32:03.670 --> 00:32:06.173
But we're just gonna take that as a given.

00:32:08.490 --> 00:32:10.230
Now this is like a paragraph in our book,

00:32:10.230 --> 00:32:14.380
but it's probably had
thousands of newspaper articles

00:32:14.380 --> 00:32:15.230
written about it.

00:32:17.120 --> 00:32:20.710
We have a chapter on choice architecture

00:32:20.710 --> 00:32:22.800
that I don't have time to go into.

00:32:22.800 --> 00:32:27.800
And we detail six principles
of good choice architecture.

00:32:29.310 --> 00:32:31.813
Today I'm gonna just talk about defaults.

00:32:35.620 --> 00:32:39.400
Here's one example that
we're working on in the UK.

00:32:40.566 --> 00:32:45.566
In the US in most states, if
you want to donate your organs,

00:32:47.110 --> 00:32:50.273
should you have a sudden accident,

00:32:52.560 --> 00:32:54.490
you have to take some action.

00:32:54.490 --> 00:32:57.250
You have to fill out some
form or do something.

00:32:57.250 --> 00:32:59.023
So it's an opt-in system.

00:32:59.890 --> 00:33:04.890
In some countries in
Europe, most notably Spain,

00:33:06.820 --> 00:33:11.060
they have an opt-out system
that they call presumed consent.

00:33:11.060 --> 00:33:13.070
And the way that works is you

00:33:13.070 --> 00:33:16.630
are presumed to give your
consent unless you do something.

00:33:16.630 --> 00:33:21.070
Now the Labor government
in the UK wanted to switch

00:33:21.070 --> 00:33:25.570
from the opt-in system
to presumed consent,

00:33:25.570 --> 00:33:27.653
but there was a big fuss made.

00:33:29.300 --> 00:33:31.830
Some people objected to someone else

00:33:31.830 --> 00:33:35.580
presuming something
about their body parts.

00:33:35.580 --> 00:33:40.580
And so, what I'm urging
their government to do

00:33:41.470 --> 00:33:43.810
and I think what they may do

00:33:43.810 --> 00:33:46.830
is adopt what I call prompted choice.

00:33:46.830 --> 00:33:50.430
Now in the book we refer
to this as mandated choice.

00:33:50.430 --> 00:33:54.163
I've learned a lot about
politics in the last two years.

00:33:55.040 --> 00:33:59.560
Prompted choice is exactly the
same policy but sounds better

00:33:59.560 --> 00:34:01.890
so we call it prompted choice.

00:34:01.890 --> 00:34:05.130
This is actually something the
state of Illinois does right.

00:34:05.130 --> 00:34:07.860
When you go to get your
driver's license renewed,

00:34:07.860 --> 00:34:12.217
the last question the clerk
at the DMV asks you is,

00:34:12.217 --> 00:34:15.380
"Would you like to be an
organ donor, yes or no?"

00:34:15.380 --> 00:34:17.340
Now, I called it mandated choice.

00:34:17.340 --> 00:34:19.197
Somebody wrote a newspaper
article about this,

00:34:19.197 --> 00:34:22.727
and the secretary of
state in Illinois said,

00:34:22.727 --> 00:34:24.147
"No, we don't have that."

00:34:24.990 --> 00:34:26.993
So I got a call from the reporter,

00:34:28.037 --> 00:34:29.937
"The state claims they don't have it."

00:34:31.050 --> 00:34:32.480
I don't know what he's talking about.

00:34:32.480 --> 00:34:34.760
I've been there, I know.

00:34:34.760 --> 00:34:38.530
It turns out he just
didn't like "mandated."

00:34:38.530 --> 00:34:41.260
He says, "We don't enforce
anybody to do anything."

00:34:41.260 --> 00:34:42.770
So technically he's right.

00:34:42.770 --> 00:34:46.377
If you get up to the front
of the line, and they say,

00:34:46.377 --> 00:34:48.080
"Do you want to be a donor or not?"

00:34:48.080 --> 00:34:52.300
and you stand there
mum, (audience laughing)

00:34:52.300 --> 00:34:55.930
they will check "No" and give
you your driver's license.

00:34:55.930 --> 00:34:58.938
So that's why we now
call it prompted choice.

00:34:58.938 --> 00:35:03.938
And that's the model I think
will probably adopt in the UK.

00:35:05.010 --> 00:35:08.530
I wrote an article about
this in the New York Times

00:35:08.530 --> 00:35:10.483
where I have an occasional column,

00:35:12.140 --> 00:35:15.980
and I said that Steve Jobs,

00:35:15.980 --> 00:35:19.070
who had just recently
gotten a liver transplant,

00:35:19.070 --> 00:35:20.950
should take it upon himself

00:35:20.950 --> 00:35:24.360
to make it as easy to donate your organs

00:35:24.360 --> 00:35:28.370
as it is to download an app on an iPhone.

00:35:28.370 --> 00:35:31.070
Two weeks later, there was an app.

00:35:31.070 --> 00:35:33.150
Steve Jobs had nothing to do with it.

00:35:33.150 --> 00:35:36.060
Somebody read the article,
thought it was a good idea.

00:35:36.060 --> 00:35:40.120
If you have an iPhone, you
can download Donate Lives

00:35:40.120 --> 00:35:42.560
and sign up to be an organ donor

00:35:42.560 --> 00:35:45.083
and maybe we can save a few lives today.

00:35:46.490 --> 00:35:51.190
Now, another domain in
which default options has

00:35:51.190 --> 00:35:54.923
proven to be very powerful
is in 401(k) plans.

00:35:56.560 --> 00:35:58.570
Many 401(k) plans,

00:35:58.570 --> 00:36:02.660
participants never get
around to signing up.

00:36:02.660 --> 00:36:04.070
They procrastinate.

00:36:04.070 --> 00:36:09.070
So in a normal plan, if
you want to join the plan,

00:36:09.500 --> 00:36:12.190
you've got a big pile
of forms to fill out,

00:36:12.190 --> 00:36:13.310
you have to fill those out.

00:36:13.310 --> 00:36:14.710
If you don't, you're not in.

00:36:15.570 --> 00:36:20.370
Under the alternative, which
is called automatic enrollment,

00:36:20.370 --> 00:36:23.257
you get that big pile of
forms and the first page says,

00:36:23.257 --> 00:36:25.477
"If you don't fill out these forms,

00:36:25.477 --> 00:36:27.897
"we're gonna enroll
you at this saving rate

00:36:27.897 --> 00:36:29.507
"and in this investment plan."

00:36:30.350 --> 00:36:34.776
Well that jumps enrollment
immediately to over 90%

00:36:34.776 --> 00:36:36.670
in every firm that's tried it.

00:36:36.670 --> 00:36:41.380
And importantly, very few
people wake up a few years later

00:36:41.380 --> 00:36:44.187
and say, "Oh my God, I'm saving!

00:36:44.187 --> 00:36:46.458
"What a stupid idea," and drop out.

00:36:46.458 --> 00:36:49.810
(audience laughing)

00:36:49.810 --> 00:36:54.160
Now the downside of
automatic enrollment is

00:36:54.160 --> 00:36:57.050
that whatever you make as the default,

00:36:57.050 --> 00:36:59.050
many people will take.

00:36:59.050 --> 00:37:04.050
And so many companies make the
default saving rate quite low

00:37:04.180 --> 00:37:08.630
and the deferred investment
very conservative,

00:37:08.630 --> 00:37:13.630
so we advise now firms to have
a more sensible default plan

00:37:16.010 --> 00:37:21.010
like something that re-balances
the portfolio automatically

00:37:21.120 --> 00:37:23.460
and adjusts it over time.

00:37:23.460 --> 00:37:27.450
And Shlomo Benartzi, another
one of my students, and I

00:37:27.450 --> 00:37:31.970
have created a program that
we call Save More Tomorrow

00:37:31.970 --> 00:37:34.400
to solve the saving rate problem,

00:37:34.400 --> 00:37:38.612
and what we do is we invite
participants to sign up

00:37:38.612 --> 00:37:42.730
for a program where they save more later.

00:37:42.730 --> 00:37:44.840
And the reason for that is

00:37:44.840 --> 00:37:49.840
that we all have more self-control
in the future than now.

00:37:51.060 --> 00:37:55.523
So many of us are planning
diets starting next month,

00:37:57.790 --> 00:37:58.653
including me.

00:38:00.550 --> 00:38:05.490
So we give them the option of
saving more in a few months,

00:38:05.490 --> 00:38:08.000
when they get their next raise

00:38:08.000 --> 00:38:10.530
because we want to mitigate
against loss aversion.

00:38:10.530 --> 00:38:12.740
So they never see their pay go down.

00:38:12.740 --> 00:38:15.260
In the first company that adopted this,

00:38:15.260 --> 00:38:18.163
we tripled saving rates
in less than three years.

00:38:20.000 --> 00:38:23.470
That was a special case
where we went around

00:38:23.470 --> 00:38:26.290
to each employee with a laptop

00:38:26.290 --> 00:38:29.030
and sort of led them by the hand.

00:38:29.030 --> 00:38:32.070
Sign up rates have never been that high

00:38:32.070 --> 00:38:35.730
in other less costly implementations.

00:38:35.730 --> 00:38:40.723
But everywhere, it's now available
in thousands of companies

00:38:42.360 --> 00:38:44.420
serving millions of employees,

00:38:44.420 --> 00:38:48.490
and wherever it works, the
people who get into it stick,

00:38:48.490 --> 00:38:49.990
and their savings rates go up.

00:38:51.570 --> 00:38:56.570
Now, I'm gonna switch to
an idea that's less sexy

00:38:59.050 --> 00:39:01.590
but I think is getting some traction

00:39:01.590 --> 00:39:04.720
in Washington and elsewhere.

00:39:04.720 --> 00:39:06.173
It's a very geeky idea.

00:39:08.330 --> 00:39:10.220
And the idea is a simple one.

00:39:10.220 --> 00:39:15.220
Wherever the government has
a required disclosure rule,

00:39:15.920 --> 00:39:19.683
they would supplement that
with an electronic disclosure.

00:39:22.600 --> 00:39:25.450
And the disclosure where applicable

00:39:25.450 --> 00:39:27.137
would have two kinds of information,

00:39:27.137 --> 00:39:29.990
one about prices and one about uses.

00:39:29.990 --> 00:39:32.334
So let me explain how this might work

00:39:32.334 --> 00:39:36.580
for wireless calling plans
which is very relevant

00:39:36.580 --> 00:39:40.130
because the FCC is
seriously thinking about

00:39:40.130 --> 00:39:42.780
adopting some version of this idea.

00:39:42.780 --> 00:39:45.270
So the idea would be once a year,

00:39:45.270 --> 00:39:50.270
you would get an email from
your mobile calling plan

00:39:51.180 --> 00:39:54.653
that would have essentially
a spreadsheet attached to it,

00:39:55.490 --> 00:40:00.490
and it would have data on every way

00:40:02.180 --> 00:40:06.460
in which you used your phone
that incurred a charge.

00:40:06.460 --> 00:40:11.130
So how many text messages,
how many mega-whatevers

00:40:11.130 --> 00:40:14.340
of things you've downloaded,

00:40:14.340 --> 00:40:19.340
and how many Simpsons
episodes you've downloaded.

00:40:21.130 --> 00:40:25.580
And then, the second would be a list of

00:40:25.580 --> 00:40:27.780
all the ways they can
charge you for things.

00:40:28.770 --> 00:40:31.120
Now it's not that we think anyone

00:40:31.120 --> 00:40:32.963
would ever look at that file.

00:40:34.270 --> 00:40:38.030
What we think is, what we know is,

00:40:38.030 --> 00:40:40.064
because these websites already exist,

00:40:40.064 --> 00:40:45.064
is that with one click, you
would be able to upload that

00:40:45.490 --> 00:40:49.333
to a website that would
then turn you into an econ.

00:40:50.350 --> 00:40:51.777
And it would tell you,

00:40:51.777 --> 00:40:56.777
"Well, based on the way
you use your smartphone,

00:40:57.007 --> 00:41:00.220
"we suggest that you switch
to the following plan,"

00:41:00.220 --> 00:41:03.070
or the following provider or so forth.

00:41:03.070 --> 00:41:06.550
We think we should do
this with credit cards,

00:41:06.550 --> 00:41:08.050
with mortgages.

00:41:08.050 --> 00:41:12.550
You know those 30 pages of
forms you have to fill out

00:41:12.550 --> 00:41:16.020
when you get a mortgage
that no one ever reads?

00:41:16.020 --> 00:41:17.830
Including, we now know,

00:41:17.830 --> 00:41:20.520
the people foreclosing on those mortgages?

00:41:20.520 --> 00:41:23.870
Again, we think that
you ought to get a file

00:41:23.870 --> 00:41:25.760
when you apply for a mortgage

00:41:25.760 --> 00:41:30.550
that you could upload
to mortgagesearcher.com

00:41:30.550 --> 00:41:31.827
and it would tell you,

00:41:31.827 --> 00:41:34.007
"Well, do you notice
that this mortgage rate

00:41:34.007 --> 00:41:35.740
"doubles in two years?"

00:41:35.740 --> 00:41:39.760
Or, "There's a $25,000
pre-payment penalty."

00:41:39.760 --> 00:41:41.720
Or all the other stuff in the fine print

00:41:41.720 --> 00:41:43.420
that nobody every bothers to read.

00:41:48.320 --> 00:41:52.380
What we think is that in many cases,

00:41:52.380 --> 00:41:57.330
this kind of disclosure
can be an alternative

00:41:57.330 --> 00:42:00.190
to heavy-handed regulation.

00:42:00.190 --> 00:42:03.530
And the reason is you
just are trying to make

00:42:03.530 --> 00:42:07.163
the consumer smarter and
the markets work better.

00:42:09.210 --> 00:42:13.890
And it eliminates the fruitless game

00:42:13.890 --> 00:42:17.670
of constantly thinking up new regulations

00:42:17.670 --> 00:42:21.313
that the firms are thinking
up ways to getting around.

00:42:22.330 --> 00:42:26.010
And so I would urge Elizabeth Warren

00:42:26.010 --> 00:42:29.870
to think very hard about this approach

00:42:29.870 --> 00:42:33.723
to dealing with the new consumer
finance protection agency.

00:42:37.060 --> 00:42:40.573
It also should allow for innovation,

00:42:41.440 --> 00:42:43.990
because if you want to
introduce a new product,

00:42:43.990 --> 00:42:46.810
you just need a new line
on this electronic form

00:42:46.810 --> 00:42:48.313
which is easy to accommodate.

00:42:50.690 --> 00:42:52.770
Now, the last thing I want to talk about

00:42:54.160 --> 00:42:59.160
is the financial crisis and
some interesting parallels

00:42:59.420 --> 00:43:02.060
I've drawn between the financial crisis

00:43:02.060 --> 00:43:06.143
and the oil spill we had
in the Gulf of Mexico.

00:43:07.640 --> 00:43:12.640
And I want to suggest
that three ingredients

00:43:13.740 --> 00:43:15.433
create a toxic recipe.

00:43:16.650 --> 00:43:20.873
The three ingredients are
statistically rare events,

00:43:22.660 --> 00:43:25.580
in Taleb's language, "black swans,"

00:43:25.580 --> 00:43:29.310
complex technologies that
I'll call "black boxes,"

00:43:29.310 --> 00:43:31.760
and counterparty risk

00:43:31.760 --> 00:43:35.310
meaning you have to do
business with somebody else

00:43:35.310 --> 00:43:37.560
and you're not quite
sure what they're doing.

00:43:39.000 --> 00:43:41.563
So about black swans,

00:43:42.990 --> 00:43:46.160
in financial markets we
keep observing things

00:43:46.160 --> 00:43:48.253
that the theory tells us can't happen.

00:43:49.360 --> 00:43:54.287
So behavioral finance got a
big boost on October 19th, 1987

00:43:55.420 --> 00:44:00.230
when stock prices fell
20 to 30% in a single day

00:44:00.230 --> 00:44:05.113
all around the world on a
day with absolutely no news.

00:44:06.380 --> 00:44:08.290
The only news was that stock prices

00:44:08.290 --> 00:44:10.430
were falling all around the world,

00:44:10.430 --> 00:44:13.623
one country after another
as the stock markets opened.

00:44:15.712 --> 00:44:20.712
It wasn't that ten heads of
state died in a bomb at the UN

00:44:21.780 --> 00:44:26.380
or that a war was breaking
out in the Middle East.

00:44:26.380 --> 00:44:27.253
Nothing happened.

00:44:28.260 --> 00:44:33.210
The rest of that week had
two of the biggest up days

00:44:33.210 --> 00:44:35.563
and another of the biggest down days.

00:44:36.550 --> 00:44:39.420
Again, in a week, the only news was

00:44:39.420 --> 00:44:41.223
that the market was going crazy.

00:44:44.010 --> 00:44:48.833
We've had more of those
happening every few years.

00:44:49.860 --> 00:44:52.840
The internet bubble, where
we created and destroyed

00:44:52.840 --> 00:44:56.113
seven trillion dollars of wealth,

00:44:57.186 --> 00:45:00.323
and most recently, the financial crisis.

00:45:03.610 --> 00:45:07.530
People will tell you
these are 10 sigma events

00:45:07.530 --> 00:45:10.210
or 15 sigma events.

00:45:10.210 --> 00:45:12.423
We know we can't get those.

00:45:13.950 --> 00:45:16.730
Maybe once every hundred
million lifetimes.

00:45:16.730 --> 00:45:21.310
So what's going on, at some point,

00:45:21.310 --> 00:45:24.690
when a lot of these events keep happening,

00:45:24.690 --> 00:45:27.053
you have to decide you
have the wrong model.

00:45:29.720 --> 00:45:33.913
Now there's a wonderful book
I wish you could all read.

00:45:34.920 --> 00:45:38.140
I just recently gave a
lecture about this at Yale.

00:45:38.140 --> 00:45:40.410
The author of this book
was a law professor

00:45:40.410 --> 00:45:42.100
called Arthur Leff.

00:45:42.100 --> 00:45:43.860
The book's called "Swindling and Selling."

00:45:43.860 --> 00:45:45.880
It's been out of print for 30 years,

00:45:45.880 --> 00:45:47.913
although you can find it on Amazon.

00:45:49.170 --> 00:45:54.170
He talks about all the great
cons and about Ponzi schemes,

00:45:56.480 --> 00:46:01.480
and he introduces the
notion of the gray box.

00:46:02.810 --> 00:46:07.810
And so the theme of the
book is for every con

00:46:08.740 --> 00:46:12.800
the conman has to explain
the answers to two questions:

00:46:12.800 --> 00:46:14.930
where is the wealth coming from,

00:46:14.930 --> 00:46:17.343
and why are you willing
to share it with me?

00:46:18.830 --> 00:46:23.140
And as this passage
says, in a Ponzi scheme,

00:46:23.140 --> 00:46:26.560
the original Ponzi had
an arbitrage opportunity.

00:46:26.560 --> 00:46:30.150
He claimed he had figured out a way

00:46:30.150 --> 00:46:35.150
of investing depreciated
European currencies

00:46:35.320 --> 00:46:39.923
in international postage
coupons and making a killing.

00:46:41.630 --> 00:46:46.630
So all Ponzi-ers since

00:46:46.650 --> 00:46:51.650
have some mechanism that they
describe, and as Leff says,

00:46:51.820 --> 00:46:56.599
the mechanism need not be
very plausible upon reflection

00:46:56.599 --> 00:47:01.599
but it most be possible,
publicizable, and complicated.

00:47:01.690 --> 00:47:05.930
It cannot be a black box,
but it cannot be transparent.

00:47:05.930 --> 00:47:08.200
It needs to be a gray box,

00:47:08.200 --> 00:47:11.230
somewhat understandable but not so much

00:47:11.230 --> 00:47:13.360
that it can be seen through.

00:47:13.360 --> 00:47:15.040
Now why is that?

00:47:15.040 --> 00:47:18.100
Gray box must be
believable and unbelievable

00:47:18.100 --> 00:47:19.830
at the same time.

00:47:19.830 --> 00:47:24.830
It has to be understandable
that some people won't want it.

00:47:25.060 --> 00:47:27.123
That's why you're getting the deal.

00:47:29.100 --> 00:47:33.943
Now, think about Wall Street.

00:47:35.240 --> 00:47:37.233
First, the financial crisis.

00:47:38.720 --> 00:47:43.520
The most perceptive article
in all that's been written

00:47:43.520 --> 00:47:45.420
about the Financial Crisis

00:47:45.420 --> 00:47:49.900
was written by a New Yorker food writer

00:47:49.900 --> 00:47:51.323
called Calvin Trillin,

00:47:52.970 --> 00:47:57.970
and Trillin describes an
imaginary scene at an Eastside bar

00:47:59.770 --> 00:48:01.690
where he goes into the bar

00:48:01.690 --> 00:48:06.090
and meets an elderly
gentleman, well-dressed,

00:48:06.090 --> 00:48:10.065
who offers to explain the
Financial Crisis to him.

00:48:10.065 --> 00:48:12.887
He says he can do it in one sentence.

00:48:12.887 --> 00:48:13.980
"Okay, what's that?"

00:48:13.980 --> 00:48:18.237
He says, "Smart people started
working on Wall Street."

00:48:20.137 --> 00:48:23.660
Says, "Okay, well I'm
not sure I get that."

00:48:23.660 --> 00:48:26.740
So he says, "Well, back
when I was in school

00:48:27.857 --> 00:48:30.873
"only the C students went to Wall Street.

00:48:31.767 --> 00:48:35.647
"The A and B students
wouldn't touch Wall Street.

00:48:35.647 --> 00:48:40.647
"They went into good careers
like law or medicine.

00:48:43.827 --> 00:48:46.387
"But then in the '80s,

00:48:46.387 --> 00:48:48.707
"people started making a
lot of money on Wall Street,

00:48:48.707 --> 00:48:52.867
"and all of a sudden, the
brightest, smartest kids

00:48:52.867 --> 00:48:56.507
"from all the best colleges
flocked to Wall Street

00:48:56.507 --> 00:48:58.257
"where they were making millions."

00:48:59.190 --> 00:49:04.190
So Mr. Trillin says,
"Okay, so far, so good.

00:49:04.417 --> 00:49:06.180
"I don't see what the problem is."

00:49:06.180 --> 00:49:10.933
He says, "Yes, but who are all
those smart kids working for?

00:49:11.927 --> 00:49:15.397
"The guys from my
generation, the C students."

00:49:16.520 --> 00:49:20.920
Now, I think that story
is so perceptive because

00:49:22.100 --> 00:49:27.100
we've seen after the fact that many CEOs

00:49:27.170 --> 00:49:29.940
just didn't understand what was going on.

00:49:29.940 --> 00:49:34.276
Even Bob Rubin, the most respected,

00:49:34.276 --> 00:49:36.490
one of the most respected
men on Wall Street,

00:49:36.490 --> 00:49:39.280
former secretary of the treasury,

00:49:39.280 --> 00:49:43.360
admitted that he had never
heard the phrase "liquidity put"

00:49:43.360 --> 00:49:47.923
until Citicorp had lost $50
billion selling liquidity puts.

00:49:49.830 --> 00:49:54.830
And Bernie Madoff, who sold $65
billion worth of gray boxes,

00:49:58.400 --> 00:49:59.410
how did he sell them?

00:49:59.410 --> 00:50:04.410
He had some story, a story
that any finance professor

00:50:04.420 --> 00:50:06.287
with after five minutes would say,

00:50:06.287 --> 00:50:09.787
"This is not possible for you
to make money doing this."

00:50:11.620 --> 00:50:13.850
Why did people put their money in?

00:50:13.850 --> 00:50:15.563
They thought he was frontrunning.

00:50:17.120 --> 00:50:20.640
Now frontrunning means,
he had a trading company,

00:50:20.640 --> 00:50:24.090
a legitimate, presumably
legitimate trading company.

00:50:24.090 --> 00:50:28.930
What frontrunning means is
suppose Matthew calls his broker

00:50:28.930 --> 00:50:32.503
and decides to buy 100,000 shares of IBM,

00:50:33.620 --> 00:50:36.640
and the broker quickly

00:50:36.640 --> 00:50:40.480
buys a 100,000 shares for himself first.

00:50:40.480 --> 00:50:43.080
That drives up the price,
he sells those to Matthew.

00:50:44.500 --> 00:50:48.260
So that's a pretty sure way
of making a little money

00:50:48.260 --> 00:50:49.680
each time you trade.

00:50:49.680 --> 00:50:51.410
It's illegal, but--

00:50:51.410 --> 00:50:55.820
That's what many of the
investors in the feeder funds

00:50:55.820 --> 00:50:58.620
thought Madoff was doing.

00:50:58.620 --> 00:50:59.947
And they thought, "This is fine,

00:50:59.947 --> 00:51:03.137
"because he's stealing from someone else

00:51:03.137 --> 00:51:05.120
"and giving the money to me."

00:51:05.120 --> 00:51:07.950
(audience laughing)

00:51:07.950 --> 00:51:12.950
Which constitutes ethics these
days. (audience laughing)

00:51:14.150 --> 00:51:16.167
Here's some facts about the SEC.

00:51:18.210 --> 00:51:22.670
They have 1400 lawyers, 25 economists,

00:51:22.670 --> 00:51:24.923
and I don't know how many hackers.

00:51:27.726 --> 00:51:32.057
I am pretty sure that if
they could clone Salander

00:51:33.240 --> 00:51:35.157
and put her in the SEC,

00:51:37.362 --> 00:51:41.153
that could replace several hundred lawyers

00:51:41.153 --> 00:51:43.513
and probably most of the economists,

00:51:44.470 --> 00:51:48.820
but the SEC was a job
that used to be suitable

00:51:48.820 --> 00:51:51.330
for an agency of lawyers,

00:51:51.330 --> 00:51:55.070
but the SEC investigated
Madoff many times,

00:51:55.070 --> 00:51:56.920
couldn't find anything wrong with it.

00:51:59.480 --> 00:52:01.030
Finally, counterparty risk,

00:52:01.030 --> 00:52:04.120
I'll just quote Mr. Greenspan.

00:52:04.120 --> 00:52:07.463
In fact, I'll let you read that
while I get a sip of water.

00:52:13.650 --> 00:52:18.103
Okay, now the oil spill.

00:52:19.680 --> 00:52:22.430
Tony Hayward said this oil spill

00:52:22.430 --> 00:52:24.760
was a one-in-a-million chance.

00:52:24.760 --> 00:52:26.900
Now whenever somebody says that,

00:52:26.900 --> 00:52:28.350
you have a pretty good idea,

00:52:28.350 --> 00:52:30.591
that was not a precise calculation.

00:52:30.591 --> 00:52:34.000
(audience laughing)

00:52:34.000 --> 00:52:36.560
But if you look at the numbers,

00:52:36.560 --> 00:52:41.423
there are 15,000 wells
in the Gulf of Mexico.

00:52:43.220 --> 00:52:46.960
In 11 cases, there was an accident

00:52:46.960 --> 00:52:51.960
in which they had to use
the blowout preventer.

00:52:53.810 --> 00:52:57.180
The blowout preventer
worked 45% of the time.

00:52:57.180 --> 00:52:59.340
That was their fail safe mechanism,

00:52:59.340 --> 00:53:00.840
works less than half the time.

00:53:02.810 --> 00:53:05.960
And if what he meant by one-in-a-million

00:53:05.960 --> 00:53:08.530
was one-in-a-million per year per well,

00:53:08.530 --> 00:53:11.370
you can see over a period of time,

00:53:11.370 --> 00:53:12.903
we're gonna get some spills.

00:53:16.330 --> 00:53:20.140
Again, the regulators
are not used to dealing

00:53:20.140 --> 00:53:22.800
with oil wells that are a mile down.

00:53:22.800 --> 00:53:25.550
So one of the inspectors said,

00:53:25.550 --> 00:53:28.963
you know, we don't really have
the capability of doing this.

00:53:29.990 --> 00:53:34.440
And counterparty risks, on
the day of the accident,

00:53:34.440 --> 00:53:39.440
of the 126 people on the rig,
only eight worked for BP.

00:53:42.420 --> 00:53:45.970
So what are we gonna do about this?

00:53:45.970 --> 00:53:49.230
Well one trap is to conclude

00:53:49.230 --> 00:53:52.940
that we should give lots
of power to regulators.

00:53:52.940 --> 00:53:57.790
But remember, regulators are human too,

00:53:57.790 --> 00:54:01.410
and it's unlikely that if
the CEOs didn't understand

00:54:01.410 --> 00:54:03.290
what was going on in a company

00:54:03.290 --> 00:54:05.320
that some bureaucrat will be able to

00:54:06.420 --> 00:54:08.270
no matter how good the bureaucrat is.

00:54:10.300 --> 00:54:15.300
So one goal, I think, should
be to increase transparency

00:54:16.210 --> 00:54:19.570
which will allow more
people to get involved.

00:54:19.570 --> 00:54:22.873
So the rating agencies let us down.

00:54:24.090 --> 00:54:25.640
I think with more disclosure,

00:54:25.640 --> 00:54:27.760
we wouldn't have needed
the rating agencies.

00:54:27.760 --> 00:54:29.840
If every mortgage-backed security

00:54:29.840 --> 00:54:34.370
had all the data on every
mortgage, which was known to them

00:54:34.370 --> 00:54:36.980
and was possible to get
if you paid enough money,

00:54:36.980 --> 00:54:38.240
if that was all available

00:54:38.240 --> 00:54:41.200
just like in our electronic disclosure,

00:54:41.200 --> 00:54:44.143
then any geek could have
become a rating agency.

00:54:45.990 --> 00:54:50.090
And in some cases, disclosure
will regulate risks

00:54:50.090 --> 00:54:51.273
to the own firm.

00:54:54.670 --> 00:54:57.400
Another possibility is to impose taxes

00:54:57.400 --> 00:55:00.060
on those who impose risk.

00:55:00.060 --> 00:55:04.860
So this is a topic of much
discussion, bank regulation.

00:55:04.860 --> 00:55:08.440
It could also be for oil drillers.

00:55:08.440 --> 00:55:13.440
The problem with this is A,
knowing how to measure the risk.

00:55:14.050 --> 00:55:15.530
Is it one-in-a-million?

00:55:15.530 --> 00:55:16.780
What is it?

00:55:16.780 --> 00:55:19.790
Bankers would have told
us there was no chance

00:55:19.790 --> 00:55:21.543
of this sort of break down.

00:55:23.530 --> 00:55:27.610
Another approach could be to
require them to have insurance

00:55:27.610 --> 00:55:29.640
which shifts some of the risk

00:55:29.640 --> 00:55:31.660
from the government to the insurer,

00:55:31.660 --> 00:55:33.340
but of course we can't be sure

00:55:33.340 --> 00:55:37.113
whether the insurance companies
are fully up to the job.

00:55:38.420 --> 00:55:41.233
So let me conclude.

00:55:42.360 --> 00:55:46.280
Our world is getting increasingly complex,

00:55:46.280 --> 00:55:49.170
but we're not getting any smarter.

00:55:49.170 --> 00:55:52.780
Neither the private sector
nor the public sector

00:55:52.780 --> 00:55:57.143
seems to up to the job of
dealing with this complexity.

00:55:58.430 --> 00:56:03.210
To paraphrase something Larry Summers said

00:56:03.210 --> 00:56:05.620
about financial regulation,

00:56:05.620 --> 00:56:09.350
we need regulations that
don't require anybody

00:56:09.350 --> 00:56:11.280
to get any smarter.

00:56:11.280 --> 00:56:13.910
And by that, what he meant was

00:56:13.910 --> 00:56:16.960
neither the consumers nor the regulators.

00:56:16.960 --> 00:56:20.280
Because we can't hope that
the next round of regulators

00:56:20.280 --> 00:56:22.240
will be smarter than the last round.

00:56:22.240 --> 00:56:23.690
They're gonna be humans, too.

00:56:25.060 --> 00:56:27.700
So I'll offer two rules.

00:56:27.700 --> 00:56:30.520
Start with electronic disclosure,

00:56:30.520 --> 00:56:32.760
and don't ban and mandate.

00:56:32.760 --> 00:56:34.500
Just nudge.

00:56:34.500 --> 00:56:37.173
Thank you very much.
(applauding)

00:56:41.121 --> 00:56:45.038
(electronic synthesizer music)

