WEBVTT
Kind: captions
Language: en

00:00:00.680 --> 00:00:02.310
SAMEER AJMANI: Hello.

00:00:02.310 --> 00:00:06.760
My name is Sameer Ajmani, and
my job at Google is to help

00:00:06.760 --> 00:00:09.840
make Go programs work
well in production.

00:00:09.840 --> 00:00:13.060
And I'm going to talk to you
today about some of the code

00:00:13.060 --> 00:00:14.840
structures that we've developed
to make our code

00:00:14.840 --> 00:00:18.520
more responsive, to make it
clean up after itself properly

00:00:18.520 --> 00:00:21.050
and respect its resources,
and to make it

00:00:21.050 --> 00:00:22.960
easier to read and maintain.

00:00:22.960 --> 00:00:26.225
And I'm one of the members of
the team driving adoption of

00:00:26.225 --> 00:00:27.475
Go within Google.

00:00:30.230 --> 00:00:32.130
So this is an advanced talk.

00:00:32.130 --> 00:00:35.700
What this means, I'm going to
throw a lot of code at you.

00:00:35.700 --> 00:00:36.750
It's very dense.

00:00:36.750 --> 00:00:41.210
And it shows you a lot of the
different ways you can put

00:00:41.210 --> 00:00:44.220
Go's concurrency primitives
together to build interesting

00:00:44.220 --> 00:00:48.550
structures and get your code
to respond well to a lot of

00:00:48.550 --> 00:00:50.870
things happening at once.

00:00:50.870 --> 00:00:52.120
So get ready.

00:00:54.690 --> 00:00:59.410
One of the critical things to
notice is that Go supports

00:00:59.410 --> 00:01:01.510
concurrency in the language,
not as a library.

00:01:01.510 --> 00:01:04.690
That means you have great
syntax for dealing with

00:01:04.690 --> 00:01:08.320
starting concurrent events,
communicating with them, and

00:01:08.320 --> 00:01:10.400
then reacting to that
communication.

00:01:10.400 --> 00:01:12.720
And that syntax is going to come
out in the code samples

00:01:12.720 --> 00:01:13.810
in this talk.

00:01:13.810 --> 00:01:17.020
And I hope to make the point
that it really helps you read

00:01:17.020 --> 00:01:19.340
and understand these programs
that are dealing

00:01:19.340 --> 00:01:20.590
with a lot of events.

00:01:23.100 --> 00:01:26.050
By means of quick review, the
main primitives are Goroutines

00:01:26.050 --> 00:01:27.240
and Channels.

00:01:27.240 --> 00:01:32.070
Goroutines allow you to start
functions executing in the

00:01:32.070 --> 00:01:35.590
same address space alongside
the existing one.

00:01:35.590 --> 00:01:38.540
So this first called go f
starts the function f

00:01:38.540 --> 00:01:40.970
executing with no arguments
in a new Goroutine.

00:01:40.970 --> 00:01:44.200
The second one starts function
g with parameters 1 and 2.

00:01:44.200 --> 00:01:47.940
And the Goroutine that
called these two--

00:01:47.940 --> 00:01:50.070
made these two statements, these
Go statements, continues

00:01:50.070 --> 00:01:52.200
executing, continues running.

00:01:52.200 --> 00:01:55.680
Now, Goroutines need to
communicate and synchronize so

00:01:55.680 --> 00:01:57.790
that they can understand what
each other's doing and you can

00:01:57.790 --> 00:02:00.050
gather results from other
Goroutines that are executing.

00:02:00.050 --> 00:02:01.940
And for that, we use Channels.

00:02:01.940 --> 00:02:06.060
Channels are typed conduits
that provide--

00:02:06.060 --> 00:02:09.169
they both provide a way to pass
data between Goroutines

00:02:09.169 --> 00:02:12.270
and a way for the Goroutines to
find out what state they're

00:02:12.270 --> 00:02:15.540
in in terms of what point in
their execution they are.

00:02:15.540 --> 00:02:17.160
That synchronization is critical
to a lot of the

00:02:17.160 --> 00:02:19.040
structures we will
get into today.

00:02:19.040 --> 00:02:21.690
So in this example, I've created
a channel of integers,

00:02:21.690 --> 00:02:23.035
assigned it to variable c.

00:02:23.035 --> 00:02:24.070
And I started a Goroutine.

00:02:24.070 --> 00:02:27.290
Here I'm using an anonymous
function closure that's going

00:02:27.290 --> 00:02:31.000
to send the value 3 on that
channel of integers.

00:02:31.000 --> 00:02:33.980
And that Send operation is
going to block until some

00:02:33.980 --> 00:02:36.450
other Goroutine is ready to
receive from that channel.

00:02:36.450 --> 00:02:38.905
And then the final statement
is going to receive off

00:02:38.905 --> 00:02:39.980
of the channel c.

00:02:39.980 --> 00:02:42.905
It's going to block until some
Goroutine sends its value, and

00:02:42.905 --> 00:02:45.600
then store that value in
the new variable n.

00:02:45.600 --> 00:02:47.860
So n is going to be 3
after end of this.

00:02:47.860 --> 00:02:49.985
For a lot more on these basics,
see Rob Pike's talk

00:02:49.985 --> 00:02:54.200
from last year at I/O. I'll
provide a link at the end.

00:02:54.200 --> 00:02:57.330
Here's an example that puts
these primitives together.

00:02:57.330 --> 00:02:59.810
What it's going to do is print
out ping and pong on

00:02:59.810 --> 00:03:01.330
alternating lines and
an incrementing

00:03:01.330 --> 00:03:03.100
count on each line.

00:03:03.100 --> 00:03:06.510
The way this works is we have
a data type, ball, that's

00:03:06.510 --> 00:03:08.900
going to keep track of how
many times it's been hit.

00:03:08.900 --> 00:03:10.490
And in our main function,
we're going to create a

00:03:10.490 --> 00:03:12.240
channel of pointers to ball.

00:03:12.240 --> 00:03:15.480
So we're going to pass a pointer
to the same ball

00:03:15.480 --> 00:03:18.380
instance, back and forth,
between Goroutines.

00:03:18.380 --> 00:03:22.360
We're going to start two
Goroutines that each run the

00:03:22.360 --> 00:03:23.550
function player.

00:03:23.550 --> 00:03:25.400
We'll pass one with the name
ping, the other pong, and both

00:03:25.400 --> 00:03:27.610
references to the
same channel.

00:03:27.610 --> 00:03:30.680
We'll start the game by sending
a ball on that channel

00:03:30.680 --> 00:03:32.790
and allow the players
to pick it up.

00:03:32.790 --> 00:03:35.260
One player will receive
the ball and then send

00:03:35.260 --> 00:03:36.300
it back to the other.

00:03:36.300 --> 00:03:39.350
We'll sleep for a second, and
then snatch the ball off the

00:03:39.350 --> 00:03:40.830
table to end the game.

00:03:40.830 --> 00:03:43.600
The player function
here is in a loop.

00:03:43.600 --> 00:03:45.450
It's receiving the ball,
incrementing the number of

00:03:45.450 --> 00:03:48.400
hits, printing that out,
sleeping briefly, and then

00:03:48.400 --> 00:03:49.340
sending the ball back.

00:03:49.340 --> 00:03:54.100
So again here's that
ping-pong exchange.

00:03:54.100 --> 00:03:57.410
Now, one of big benefits of
having this concurrency

00:03:57.410 --> 00:04:00.420
managed by the GoRun time is we
can do things like detect

00:04:00.420 --> 00:04:01.970
when the system is deadlocked.

00:04:01.970 --> 00:04:04.600
So if we never send the ball on
the channel, we'll do that

00:04:04.600 --> 00:04:07.080
one-second sleep, and then
we'll get a fatal error.

00:04:07.080 --> 00:04:10.540
It says all Goroutines
are sleep deadlock.

00:04:10.540 --> 00:04:13.747
And it'll print out the stack
traces of the Goroutines that

00:04:13.747 --> 00:04:15.350
are sitting in the system.

00:04:15.350 --> 00:04:17.490
We have our main that's blocked
on channel receive,

00:04:17.490 --> 00:04:19.070
that's received out
of the table here.

00:04:19.070 --> 00:04:22.850
And we have our two players,
main.player, that are these

00:04:22.850 --> 00:04:24.930
two Goroutines, and you can see
they're also each stuck on

00:04:24.930 --> 00:04:26.150
a channel receive.

00:04:26.150 --> 00:04:27.910
This is very useful to
understand when your system

00:04:27.910 --> 00:04:30.640
gets deadlocked.

00:04:30.640 --> 00:04:35.340
And that set of stack traces
can be useful for

00:04:35.340 --> 00:04:37.020
other things as well.

00:04:37.020 --> 00:04:39.570
So a Panic in Goroutine is
going to dump the stacks.

00:04:39.570 --> 00:04:41.050
It's at the top of
your program.

00:04:41.050 --> 00:04:42.070
And there are a number
of other ways to

00:04:42.070 --> 00:04:42.950
get those stack traces.

00:04:42.950 --> 00:04:45.390
The runtime package provides
ways to get at it.

00:04:45.390 --> 00:04:47.850
And there's even ways
to export it

00:04:47.850 --> 00:04:48.780
through HTTP handlers.

00:04:48.780 --> 00:04:51.590
So you can look at, say, a
running server, and see where

00:04:51.590 --> 00:04:53.140
its Goroutine stacks are.

00:04:53.140 --> 00:04:56.630
So if I run that Panic, right at
the end of our program, we

00:04:56.630 --> 00:04:57.960
get a dump of the
stacks again.

00:04:57.960 --> 00:04:59.970
And we see our main Goroutine,
which we expect.

00:04:59.970 --> 00:05:02.120
But we also see these two
players are hanging around.

00:05:02.120 --> 00:05:04.550
Those Goroutines are still
existing in the system.

00:05:04.550 --> 00:05:05.710
They haven't exited.

00:05:05.710 --> 00:05:07.080
And it's kind of obvious
from the code.

00:05:07.080 --> 00:05:08.250
They are in an infinite loop.

00:05:08.250 --> 00:05:10.730
Why would they exit?

00:05:10.730 --> 00:05:12.290
That's a leak.

00:05:12.290 --> 00:05:14.860
These Goroutines are
going to continue

00:05:14.860 --> 00:05:16.770
sitting in the system.

00:05:16.770 --> 00:05:19.200
And we want them to exit when
they're no longer needed.

00:05:19.200 --> 00:05:21.340
And that's really what
this talk is about.

00:05:21.340 --> 00:05:22.960
When you're building long-lived
systems, like the

00:05:22.960 --> 00:05:27.480
one in Google, you need to be
careful to make sure that you

00:05:27.480 --> 00:05:28.800
get rid of the things
you no longer need.

00:05:28.800 --> 00:05:30.570
And Goroutines are one
of those things.

00:05:30.570 --> 00:05:31.880
They need to clean
up properly.

00:05:31.880 --> 00:05:33.940
So we're going to look at
programs that handle

00:05:33.940 --> 00:05:36.680
communication, but also various
periodic events in

00:05:36.680 --> 00:05:40.330
time, and then cancellation,
deciding when things are done

00:05:40.330 --> 00:05:42.570
and making sure that we
clean up properly.

00:05:42.570 --> 00:05:45.440
The key mechanism that's going
to let us do this is Go's

00:05:45.440 --> 00:05:46.310
Select statement.

00:05:46.310 --> 00:05:47.540
And this is sort of
the third leg of

00:05:47.540 --> 00:05:49.090
its concurrency support.

00:05:49.090 --> 00:05:51.580
A Select statement looks a
little like a switch, but it's

00:05:51.580 --> 00:05:52.240
fundamentally different.

00:05:52.240 --> 00:05:55.290
A Select blocks until one of
its cases can proceed, and

00:05:55.290 --> 00:05:57.940
each case is a communication.

00:05:57.940 --> 00:06:01.490
So in this example, the first
case in the select attempts to

00:06:01.490 --> 00:06:03.760
send the value x on
the channel xc.

00:06:03.760 --> 00:06:05.855
And the second attempts to
receive a value from the

00:06:05.855 --> 00:06:08.510
channel yc and store it
in the new variable y.

00:06:08.510 --> 00:06:11.140
And the select will block until
exactly one of these

00:06:11.140 --> 00:06:13.810
cases can proceed, which means
that communication happened.

00:06:13.810 --> 00:06:17.010
Then the body of each
Select case can take

00:06:17.010 --> 00:06:19.240
action on that event.

00:06:19.240 --> 00:06:22.450
In particular, the receive off
the y-case can use the new

00:06:22.450 --> 00:06:23.640
value received from y.

00:06:23.640 --> 00:06:27.780
And we know that that send
on x didn't happen.

00:06:27.780 --> 00:06:29.560
So the motivating
example here--

00:06:29.560 --> 00:06:31.640
to put this all together--
is a feed reader.

00:06:31.640 --> 00:06:33.445
Recently my favorite feed
reader disappeared.

00:06:33.445 --> 00:06:35.860
So I said, well, I
need a new one.

00:06:35.860 --> 00:06:36.690
Well, we know Go.

00:06:36.690 --> 00:06:38.930
So why not just write one?

00:06:38.930 --> 00:06:40.180
But where do we start?

00:06:40.180 --> 00:06:42.090
I don't know much about
feed readers.

00:06:42.090 --> 00:06:44.390
I know they have something
to do with RSS.

00:06:44.390 --> 00:06:47.130
So we can open up this website,
godoc.org, which is

00:06:47.130 --> 00:06:48.380
pretty fantastic.

00:06:50.230 --> 00:06:54.600
It provides automatically
generated documentation for

00:06:54.600 --> 00:06:55.520
the various Go projects--

00:06:55.520 --> 00:06:59.400
BitBucket, GetHub, Google
Hosting, and LaunchPad.

00:06:59.400 --> 00:07:03.060
And so if you search for RSS
here, you will get a number of

00:07:03.060 --> 00:07:03.860
Go packages.

00:07:03.860 --> 00:07:07.320
We get their tag lines
here that says what

00:07:07.320 --> 00:07:09.580
the package is about.

00:07:09.580 --> 00:07:12.010
A number of these are just
providing Go data structures

00:07:12.010 --> 00:07:14.410
that correspond to the
RSS data types.

00:07:14.410 --> 00:07:16.080
But some of them actually
provide clients.

00:07:16.080 --> 00:07:17.330
And that's what I really want.

00:07:17.330 --> 00:07:20.110
So we can click through on a
given package and get more

00:07:20.110 --> 00:07:22.660
information on what the package
owner has described.

00:07:22.660 --> 00:07:25.740
And this is all powered
by godoc.org.

00:07:25.740 --> 00:07:28.080
So I chose a package
and started

00:07:28.080 --> 00:07:29.980
looking at its interface.

00:07:29.980 --> 00:07:33.380
What it provides is a fetch
function, something like this.

00:07:33.380 --> 00:07:36.640
It takes a URI from which to
fetch the feed, and it returns

00:07:36.640 --> 00:07:40.435
to me a slice of items and a
time, which is the next time I

00:07:40.435 --> 00:07:42.940
should try a fetch on this
particular feed.

00:07:42.940 --> 00:07:45.380
Or if there's a failure, it'll
return the error value.

00:07:45.380 --> 00:07:46.050
The errors are returned.

00:07:46.050 --> 00:07:48.700
And I don't get the
items or the time.

00:07:48.700 --> 00:07:50.950
And in this example, I'm
going to strip down.

00:07:50.950 --> 00:07:53.120
And I've just given us some
basic elements like the title,

00:07:53.120 --> 00:07:55.020
the name of the channel,
and the unique ID.

00:07:55.020 --> 00:07:58.530
But, of course, the real RSS
items have a lot more data.

00:07:58.530 --> 00:07:59.950
But this isn't what I want.

00:07:59.950 --> 00:08:02.590
I want a stream of items
that I can then

00:08:02.590 --> 00:08:04.670
build, say, UI on top.

00:08:04.670 --> 00:08:06.830
So what I really want is
a channel of items.

00:08:06.830 --> 00:08:08.880
And here, this little arrow
hanging off the channel type

00:08:08.880 --> 00:08:10.380
says that it's a receive
only channel.

00:08:10.380 --> 00:08:12.790
I just want to suck on that
channel and do interesting

00:08:12.790 --> 00:08:14.420
things with the items I get.

00:08:14.420 --> 00:08:17.150
Also multiple subscriptions,
not just one.

00:08:17.150 --> 00:08:20.120
So let's take a look in more
detail about what we want.

00:08:20.120 --> 00:08:22.050
Here's what we have.

00:08:22.050 --> 00:08:23.580
We have this thing that
we can call fetch on

00:08:23.580 --> 00:08:25.310
periodically to get items.

00:08:25.310 --> 00:08:27.360
And we're going to put in an
interface so it makes it easy

00:08:27.360 --> 00:08:29.790
to provide a fake implementation
for this talk.

00:08:29.790 --> 00:08:33.049
And you can imagine using
it for testing.

00:08:33.049 --> 00:08:35.990
We have our function, which
given our domain, a blogger

00:08:35.990 --> 00:08:37.990
domain, is going to give us
a fetcher implementation.

00:08:37.990 --> 00:08:40.039
And that's where
we're starting.

00:08:40.039 --> 00:08:41.610
What we want to build is
something more like a

00:08:41.610 --> 00:08:45.520
subscription that gives us
a channel on which we can

00:08:45.520 --> 00:08:47.990
receive these items and gives
us a way to say we're no

00:08:47.990 --> 00:08:49.350
longer interested--
unsubscribe.

00:08:49.350 --> 00:08:50.680
So we're going to close
that subscription.

00:08:50.680 --> 00:08:53.040
It's going to give us an error
if there was any problems

00:08:53.040 --> 00:08:54.110
fetching that stream.

00:08:54.110 --> 00:08:55.770
And this gets to that whole
cancellation point.

00:08:55.770 --> 00:08:57.260
We want to be able to clean
up when we're no longer

00:08:57.260 --> 00:08:58.780
interested in something.

00:08:58.780 --> 00:09:01.210
We have a subscribe function,
which given a fetcher,

00:09:01.210 --> 00:09:02.520
transforms it into
a subscription.

00:09:02.520 --> 00:09:05.180
It takes this idea of
periodically fetching and

00:09:05.180 --> 00:09:06.110
gives us this stream.

00:09:06.110 --> 00:09:09.240
And then we have a merge, which
takes a variadic list of

00:09:09.240 --> 00:09:11.750
subscriptions, any number of
subscriptions, and gives us a

00:09:11.750 --> 00:09:15.400
merged one, one whose series of
items are merged from the

00:09:15.400 --> 00:09:19.050
various domains.

00:09:19.050 --> 00:09:20.930
Here's an example that
puts it together.

00:09:20.930 --> 00:09:22.510
This is using a fake fetcher.

00:09:22.510 --> 00:09:25.750
So we're just getting which =gs
we're fetching from and

00:09:25.750 --> 00:09:26.320
some item number.

00:09:26.320 --> 00:09:28.150
Then the panic at the
end is the same

00:09:28.150 --> 00:09:28.970
technique we used before.

00:09:28.970 --> 00:09:30.890
It just shows us that all that's
hanging around is the

00:09:30.890 --> 00:09:32.390
main Goroutine and a
syscall Goroutine

00:09:32.390 --> 00:09:33.530
managed by the runtime.

00:09:33.530 --> 00:09:35.630
There's nothing with regards to
subscription that's still

00:09:35.630 --> 00:09:36.400
handing around.

00:09:36.400 --> 00:09:39.500
So we've cleaned up
is the point.

00:09:39.500 --> 00:09:42.110
The code here, we are making
a call to merge, and we're

00:09:42.110 --> 00:09:43.650
passing it three
subscriptions.

00:09:43.650 --> 00:09:46.010
Each subscription is fetching
a different domain.

00:09:46.010 --> 00:09:48.510
And that's our merged
subscription.

00:09:48.510 --> 00:09:50.730
We're going to start a timer,
which is after 3 seconds close

00:09:50.730 --> 00:09:52.874
the subscription, because
otherwise, we're going to sit

00:09:52.874 --> 00:09:54.380
here, reading these all day.

00:09:54.380 --> 00:09:56.410
And then we're going to iterate
over this channel.

00:09:56.410 --> 00:10:01.210
Now, here I'm using Go's range
function, range built-in,

00:10:01.210 --> 00:10:02.720
which allows you to iterate
over things

00:10:02.720 --> 00:10:04.450
like slices and maps.

00:10:04.450 --> 00:10:06.970
And on a channel, it means
continue receiving over that

00:10:06.970 --> 00:10:09.270
channel until the channel
is closed.

00:10:09.270 --> 00:10:11.120
And closed is a built-in
operation you can do on a

00:10:11.120 --> 00:10:12.865
channel to indicate to receivers
that no more items

00:10:12.865 --> 00:10:13.870
are coming.

00:10:13.870 --> 00:10:16.280
So really, the main reason to
use close, in my opinion, is

00:10:16.280 --> 00:10:19.370
to make these four loops
really nice.

00:10:19.370 --> 00:10:22.850
It makes it very easy then to
write things that are easy to

00:10:22.850 --> 00:10:25.890
reason about.

00:10:25.890 --> 00:10:28.170
And then we're going to
print each item and

00:10:28.170 --> 00:10:29.640
then dump the stack.

00:10:29.640 --> 00:10:31.980
So again, this is a
randomized thing.

00:10:31.980 --> 00:10:33.710
We're getting different items
from different blogs at

00:10:33.710 --> 00:10:35.380
different times, different
next-fetch times.

00:10:38.550 --> 00:10:40.320
Most of this talk is going
to focus on subscribe.

00:10:40.320 --> 00:10:41.855
That's all we have
time to go into.

00:10:41.855 --> 00:10:43.010
We'll provide the code
for things like

00:10:43.010 --> 00:10:45.330
merge online later.

00:10:45.330 --> 00:10:47.850
The idea behind subscribe is
to translate this periodic

00:10:47.850 --> 00:10:50.540
fetch into a continuous
stream of items.

00:10:50.540 --> 00:10:52.410
The way that's going to work
is we're going to have an

00:10:52.410 --> 00:10:54.240
un-exporting data type that
implements subscription.

00:10:54.240 --> 00:10:55.440
And that's sub.

00:10:55.440 --> 00:10:57.060
Sub is going to contain
a fetcher.

00:10:57.060 --> 00:11:00.100
And it's going to have this
channel of items it exposes to

00:11:00.100 --> 00:11:01.280
the client.

00:11:01.280 --> 00:11:04.200
And when we create a new
subscription, we're going to

00:11:04.200 --> 00:11:05.840
initialize our subtype.

00:11:05.840 --> 00:11:08.080
And we're going to start a
Goroutine called loop.

00:11:08.080 --> 00:11:09.260
And this is the key bit.

00:11:09.260 --> 00:11:11.590
This is going to implement that
periodic fetching, but

00:11:11.590 --> 00:11:14.440
also handle events like closing
and delivering items

00:11:14.440 --> 00:11:14.980
to the user.

00:11:14.980 --> 00:11:16.280
We will see how we put
that all together.

00:11:20.230 --> 00:11:21.670
Again, subscription
is an interface.

00:11:21.670 --> 00:11:23.560
And what that means in Go is we
need to implement all the

00:11:23.560 --> 00:11:25.530
methods in that method set.

00:11:25.530 --> 00:11:26.840
So we have two to implement.

00:11:26.840 --> 00:11:27.610
One is updates.

00:11:27.610 --> 00:11:28.570
And that's easy.

00:11:28.570 --> 00:11:30.660
We have our update channel in
sub, and we are just going to

00:11:30.660 --> 00:11:31.970
return that to the user.

00:11:31.970 --> 00:11:35.020
Note that we're returning the
receive-only view on that

00:11:35.020 --> 00:11:36.240
channel here.

00:11:36.240 --> 00:11:38.370
So the client of the
subscription is only going to

00:11:38.370 --> 00:11:39.030
be able to receive.

00:11:39.030 --> 00:11:41.100
They won't be able to try
to send on that channel.

00:11:41.100 --> 00:11:42.590
And Close has two jobs.

00:11:42.590 --> 00:11:43.850
It's got to make that
loop Goroutine exit.

00:11:43.850 --> 00:11:47.790
It has to find out about any
fetch error that happened

00:11:47.790 --> 00:11:51.220
while we're trying to get
that subscription.

00:11:51.220 --> 00:11:53.510
So what does this loop
Goroutine do?

00:11:53.510 --> 00:11:54.970
It's got three jobs--

00:11:54.970 --> 00:11:57.990
call fetch periodically, deliver
items on that updates

00:11:57.990 --> 00:11:59.800
channel, and then when
Close is called, exit

00:11:59.800 --> 00:12:02.290
and report the error.

00:12:02.290 --> 00:12:03.680
This doesn't sound too hard.

00:12:03.680 --> 00:12:07.230
So here's the implementation
that you might just try first.

00:12:07.230 --> 00:12:08.240
Let's have a loop.

00:12:08.240 --> 00:12:10.050
And if we're closed,
let's close and

00:12:10.050 --> 00:12:11.650
update channel on return.

00:12:11.650 --> 00:12:15.350
Otherwise, we run our fetch,
we get some items.

00:12:15.350 --> 00:12:17.670
If we get an error, sleep for
a little while, and loop

00:12:17.670 --> 00:12:19.240
around again.

00:12:19.240 --> 00:12:22.480
If we succeeded, deliver each
item on the updates channel

00:12:22.480 --> 00:12:24.830
and then calculate what's the
next time we're supposed to

00:12:24.830 --> 00:12:28.930
fetch, sleep for that long,
loop around again.

00:12:28.930 --> 00:12:32.900
And close simply sets this
Boolean to make the loop exit.

00:12:32.900 --> 00:12:34.670
And then reads the error off.

00:12:34.670 --> 00:12:37.290
If we run that, it seems
to kind of work.

00:12:37.290 --> 00:12:39.210
We seem to be getting items.

00:12:39.210 --> 00:12:43.000
And it looks like it even
might have exited

00:12:43.000 --> 00:12:44.740
cleanly in this case.

00:12:44.740 --> 00:12:47.210
But it turns out this
code is very buggy.

00:12:47.210 --> 00:12:49.930
And I'll go into exactly why.

00:12:49.930 --> 00:12:54.460
The first bug is that this
closed a bit, and this error

00:12:54.460 --> 00:12:56.620
value are being accessed by
two Goroutines with no

00:12:56.620 --> 00:12:58.140
synchronization.

00:12:58.140 --> 00:12:59.670
And this is bad.

00:12:59.670 --> 00:13:01.940
This means that this
is a data race.

00:13:01.940 --> 00:13:03.160
You can see--

00:13:03.160 --> 00:13:04.790
particularly in the case of
the error, which is an

00:13:04.790 --> 00:13:07.300
interface value, you can see
partially written types, if

00:13:07.300 --> 00:13:12.730
there really are because these
are executing in a shared

00:13:12.730 --> 00:13:15.400
address space.

00:13:15.400 --> 00:13:16.800
So we have to resolve
that race.

00:13:16.800 --> 00:13:18.810
And you notice this race is sort
of by inspection, which

00:13:18.810 --> 00:13:21.250
isn't a very satisfying way
to find data races.

00:13:21.250 --> 00:13:23.220
Luckily with Go 1.1, we have
a new race detector.

00:13:25.770 --> 00:13:28.700
When you go run your program,
you can pass this hyphen race

00:13:28.700 --> 00:13:33.450
flag on your Goroutine. and
you can get a nice report.

00:13:33.450 --> 00:13:36.720
So we're going to run this
with a race detector--

00:13:36.720 --> 00:13:37.190
hopefully.

00:13:37.190 --> 00:13:38.440
There it is.

00:13:40.800 --> 00:13:44.830
And we get an error that says
there's a data race.

00:13:44.830 --> 00:13:49.170
There's a read in the Goroutine
called loop.

00:13:49.170 --> 00:13:52.610
And it was a previous write to
that value from the Goroutine

00:13:52.610 --> 00:13:54.630
that ran Close.

00:13:54.630 --> 00:13:57.170
And it even tells us where these
respective Goroutine

00:13:57.170 --> 00:13:58.610
were created.

00:13:58.610 --> 00:14:02.030
And then we see in our stacked
race it came below.

00:14:02.030 --> 00:14:05.080
So the race detector is a really
great way in a program

00:14:05.080 --> 00:14:06.610
that is doing a lot of
concurrency, that's dealing

00:14:06.610 --> 00:14:10.210
with a lot of Goroutines and a
lot of data, to discover when

00:14:10.210 --> 00:14:12.805
you're not synchronizing
improperly.

00:14:12.805 --> 00:14:16.610
I'm going to talk about how
you fix these data races.

00:14:16.610 --> 00:14:18.210
The second bug is a little
more subtle.

00:14:18.210 --> 00:14:21.520
This is really a resource leak
of an insidious sort, which is

00:14:21.520 --> 00:14:27.490
our loop is just sleeping when
it has nothing else to do.

00:14:27.490 --> 00:14:30.000
And what that means is it's not
responsive when it's time

00:14:30.000 --> 00:14:30.990
to close a subscription.

00:14:30.990 --> 00:14:32.290
Now, this might not
be a big deal.

00:14:32.290 --> 00:14:33.960
I mean, it's just one Goroutine
hanging around.

00:14:33.960 --> 00:14:35.040
We know it's going to
exit eventually.

00:14:35.040 --> 00:14:36.360
It'll see Closed.

00:14:36.360 --> 00:14:38.710
But what if this next
time is tomorrow?

00:14:38.710 --> 00:14:40.880
Some feeds are updated
fairly rarely.

00:14:40.880 --> 00:14:42.870
So this could be hanging around
for quite a long time.

00:14:42.870 --> 00:14:44.670
We want to be in the case that
as soon as the user calls

00:14:44.670 --> 00:14:46.840
Close, we clean up, because
there's no reason for this to

00:14:46.840 --> 00:14:49.330
hang around.

00:14:49.330 --> 00:14:54.230
The third bug is, in a sense,
the hardest to catch.

00:14:54.230 --> 00:14:57.750
As I said, sends will block
until there's a Goroutine

00:14:57.750 --> 00:14:59.650
ready to receive the value.

00:14:59.650 --> 00:15:02.080
So what happens when the client
of the subscription

00:15:02.080 --> 00:15:05.170
calls Close and then stops
using the subscription?

00:15:05.170 --> 00:15:07.630
There's no reason they should
keep receiving off of it.

00:15:07.630 --> 00:15:10.720
Well, this send will
block indefinitely.

00:15:10.720 --> 00:15:11.980
There's no one to receive it.

00:15:11.980 --> 00:15:13.360
Nothing's going to happen.

00:15:13.360 --> 00:15:15.960
This loop Goroutine is going to
stay hanging around in the

00:15:15.960 --> 00:15:19.010
system forever.

00:15:19.010 --> 00:15:23.600
So luckily, we have a way to fix
all of these problems by

00:15:23.600 --> 00:15:25.710
refactoring the way
our loop works.

00:15:25.710 --> 00:15:27.670
And what's interesting--

00:15:27.670 --> 00:15:32.690
so it's going to be built on
this select statement in Go.

00:15:32.690 --> 00:15:36.730
And the point I want to make
here is that in this case, we

00:15:36.730 --> 00:15:39.220
have a type that wants to
consider any of these three

00:15:39.220 --> 00:15:39.990
things could happen--

00:15:39.990 --> 00:15:42.600
Close was called, or it's time
to call Fetch, or it's time to

00:15:42.600 --> 00:15:43.760
deliver an item on updates.

00:15:43.760 --> 00:15:45.150
Select is what lets
you do that.

00:15:45.150 --> 00:15:47.980
To consider multiple things that
could happen at the same

00:15:47.980 --> 00:15:51.330
time, when one happens, take
action on it, then consider

00:15:51.330 --> 00:15:52.580
them all again.

00:15:54.590 --> 00:15:57.580
The basic structure is what
I call for-select loop.

00:15:57.580 --> 00:15:59.890
So loop is going to run
in its own Goroutine.

00:15:59.890 --> 00:16:01.670
And at the top of it, we're
going to declare a mutable

00:16:01.670 --> 00:16:05.320
state, and that mutable state
is owned by that Goroutine.

00:16:05.320 --> 00:16:08.230
And in our loop, at the top of
the loop, we're going to set

00:16:08.230 --> 00:16:11.280
up the channels to
use in our select

00:16:11.280 --> 00:16:12.650
And then our select is
going to consider

00:16:12.650 --> 00:16:13.740
these the various cases.

00:16:13.740 --> 00:16:16.510
And then they are going to
manipulate that state that's

00:16:16.510 --> 00:16:17.330
owned by the loop.

00:16:17.330 --> 00:16:20.660
Then we're going to run
around the loop again.

00:16:20.660 --> 00:16:22.580
And the key here is that there's
no data races because

00:16:22.580 --> 00:16:23.610
this is a single Goroutine.

00:16:23.610 --> 00:16:24.610
It's a straight-line code.

00:16:24.610 --> 00:16:28.110
It's much more algorithmic than
you might be used to in

00:16:28.110 --> 00:16:30.300
dealing with threads and
event-driven style.

00:16:30.300 --> 00:16:32.890
I'll show you how powerful this
is and the way we resolve

00:16:32.890 --> 00:16:35.485
these errors and then build
on this structure.

00:16:38.140 --> 00:16:39.980
So we're going to
go case by case.

00:16:39.980 --> 00:16:41.220
We have three cases.

00:16:41.220 --> 00:16:42.760
The first one is Close.

00:16:42.760 --> 00:16:46.620
We need to transform that closed
Boolean and that error

00:16:46.620 --> 00:16:48.860
value into communication.

00:16:48.860 --> 00:16:53.590
And we're going to do this by
introducing a channel in our

00:16:53.590 --> 00:16:56.440
subscriber implementation
called closing.

00:16:56.440 --> 00:16:57.590
And this is a funny signature.

00:16:57.590 --> 00:16:59.180
It's a chan of chan of error.

00:16:59.180 --> 00:17:01.310
It's a channel on which
you pass a channel.

00:17:01.310 --> 00:17:02.860
So what's going on here?

00:17:02.860 --> 00:17:05.349
This is a request response
structure.

00:17:05.349 --> 00:17:07.800
So the loop you can think of
as a little server that's

00:17:07.800 --> 00:17:09.790
listening for requests on
this closing channel, in

00:17:09.790 --> 00:17:11.790
particular, requests to close.

00:17:11.790 --> 00:17:14.700
And when we call Close, we're
going to say, hey, loop,

00:17:14.700 --> 00:17:15.319
please close.

00:17:15.319 --> 00:17:18.395
And we're going to wait until
the loop acknowledges that by

00:17:18.395 --> 00:17:22.075
sending us back the error if
there's been an error on

00:17:22.075 --> 00:17:24.390
fetch, or nil if there's
been no error.

00:17:24.390 --> 00:17:27.060
And this request response
structure can be built up

00:17:27.060 --> 00:17:27.880
quite a bit.

00:17:27.880 --> 00:17:30.420
There's some material I'll point
out later that talks

00:17:30.420 --> 00:17:33.630
about this in more detail.

00:17:33.630 --> 00:17:36.725
So the code here is that Close
now creates the channel which

00:17:36.725 --> 00:17:39.780
it wants to receive an errors,
sends that to the loop, and

00:17:39.780 --> 00:17:41.720
then waits for the error
to come back.

00:17:41.720 --> 00:17:43.010
In loop, we have--

00:17:43.010 --> 00:17:44.710
this is just a snippet of it--

00:17:44.710 --> 00:17:47.850
our first select case, which
is if we receive a value on

00:17:47.850 --> 00:17:53.520
closing, deliver the error to
the listener, close the

00:17:53.520 --> 00:17:56.450
updates channel, and
then return.

00:17:56.450 --> 00:17:59.040
And this error is the one that
fetch is going to write to.

00:17:59.040 --> 00:18:01.420
And fetch is next.

00:18:01.420 --> 00:18:02.500
So this is a big case.

00:18:02.500 --> 00:18:04.870
And I'll go into this
in some detail.

00:18:04.870 --> 00:18:08.910
The state here is what's
returned by fetch and shared

00:18:08.910 --> 00:18:10.550
with the other cases.

00:18:10.550 --> 00:18:13.250
In particular, we have a set
of items that we fetched

00:18:13.250 --> 00:18:16.790
previously and that we want
to deliver to the client.

00:18:16.790 --> 00:18:19.560
We have this next time that we
need to run our next fetch.

00:18:19.560 --> 00:18:21.950
And we have the error
from a failed fetch.

00:18:21.950 --> 00:18:24.800
At the top of our loop, we have
to calculate when is our

00:18:24.800 --> 00:18:25.900
next fetch?

00:18:25.900 --> 00:18:28.480
And so that's this
fetch delay.

00:18:28.480 --> 00:18:29.580
Initially, it's going to be 0.

00:18:29.580 --> 00:18:31.970
So our first fetch is going
to be immediately.

00:18:31.970 --> 00:18:33.900
This start fetch is a channel.

00:18:33.900 --> 00:18:38.200
We use the time.after function
in the time package to create

00:18:38.200 --> 00:18:40.865
a channel that will deliver a
value exactly after fetch

00:18:40.865 --> 00:18:43.480
delay elapses.

00:18:43.480 --> 00:18:50.640
And this second select case is
going to be able to proceed

00:18:50.640 --> 00:18:51.890
after that time has elapsed.

00:18:54.220 --> 00:18:56.150
In this case, we're going to go
ahead and fetch our items.

00:18:56.150 --> 00:18:57.420
We'll run fetch.

00:18:57.420 --> 00:18:59.710
If there's an error, we'll
schedule our next fetch to be

00:18:59.710 --> 00:19:00.950
10 seconds from now.

00:19:00.950 --> 00:19:03.560
You can imagine backing
off there.

00:19:03.560 --> 00:19:06.115
And if we succeeded, we'll
append the fetched items to

00:19:06.115 --> 00:19:07.860
our pending queue.

00:19:07.860 --> 00:19:10.550
Our last case is going to then
deliver the items in those

00:19:10.550 --> 00:19:16.110
pending queue to the
client of the type.

00:19:16.110 --> 00:19:17.870
And this seems pretty easy.

00:19:17.870 --> 00:19:20.255
We should be able to just take
the first item off pending and

00:19:20.255 --> 00:19:23.670
deliver it on the updates
channel and then advance the

00:19:23.670 --> 00:19:28.640
slice, reslice it to
be one forward.

00:19:28.640 --> 00:19:31.320
Unfortunately, this crashes
exactly when pending is empty.

00:19:31.320 --> 00:19:33.700
And this is because the way
select is evaluated, it

00:19:33.700 --> 00:19:36.570
evaluates the expressions in
the communication and it

00:19:36.570 --> 00:19:39.840
evaluates pending sub 0
when it runs a select.

00:19:39.840 --> 00:19:42.540
And if it's empty, that's
going to be a panic.

00:19:42.540 --> 00:19:45.660
We're going to fix this using
another technique.

00:19:45.660 --> 00:19:47.870
And it's going to combine two
properties of the Go language

00:19:47.870 --> 00:19:48.920
that are somewhat interesting.

00:19:48.920 --> 00:19:52.840
First is that nil channels, if
you send or receive on an nil

00:19:52.840 --> 00:19:54.080
channel, it blocks.

00:19:54.080 --> 00:19:54.710
It doesn't panic.

00:19:54.710 --> 00:19:56.250
It just blocks.

00:19:56.250 --> 00:19:59.840
And we know that selects will
never select a blocking case.

00:19:59.840 --> 00:20:01.440
It will only select cases
that proceed.

00:20:01.440 --> 00:20:04.090
If you put this together, we can
use the fact that we can

00:20:04.090 --> 00:20:07.010
set a channel to nil to disable
a case that we don't

00:20:07.010 --> 00:20:08.570
need this time around.

00:20:08.570 --> 00:20:11.870
And this replaces a lot more
complicated logic where you

00:20:11.870 --> 00:20:13.280
have multiple different selects

00:20:13.280 --> 00:20:14.530
depending on what can happen.

00:20:17.530 --> 00:20:19.250
We have one select where you
can turn certain cases off

00:20:19.250 --> 00:20:20.630
that you don't need.

00:20:20.630 --> 00:20:22.680
So our example here, just
a simple example

00:20:22.680 --> 00:20:23.470
to demonstrate this.

00:20:23.470 --> 00:20:26.310
We're going to create two
channels of strings, a and b.

00:20:26.310 --> 00:20:29.680
Start two Goroutines that
deliver a to a and b to b.

00:20:29.680 --> 00:20:31.960
We're going to flip a coin and
set one of them to nil.

00:20:31.960 --> 00:20:34.630
And then select to see which
one delivers a value.

00:20:34.630 --> 00:20:37.390
And what you'll see is that each
time we run it, we get a

00:20:37.390 --> 00:20:39.640
value exactly from the one
that wasn't set to nil.

00:20:45.170 --> 00:20:45.980
It did show up there.

00:20:45.980 --> 00:20:47.230
Yeah, there's a.

00:20:49.860 --> 00:20:53.420
The way we are going to fix
this now is in our select

00:20:53.420 --> 00:20:57.050
case, we're only going to
attempt to send if we've got a

00:20:57.050 --> 00:20:58.270
value to send.

00:20:58.270 --> 00:21:01.130
So we're going to create an
updates channel that's nil.

00:21:01.130 --> 00:21:02.880
And we're going to set it to
non-nil exactly when you have

00:21:02.880 --> 00:21:03.330
something to send.

00:21:03.330 --> 00:21:04.690
And then we're going to
set our first item to

00:21:04.690 --> 00:21:06.270
be pending sub 0.

00:21:06.270 --> 00:21:07.840
So that fixes this issue.

00:21:07.840 --> 00:21:10.300
And now we can put all
three cases together.

00:21:10.300 --> 00:21:12.280
So we have a case
that's closing.

00:21:12.280 --> 00:21:13.600
And in that case, we're going
to send the error to

00:21:13.600 --> 00:21:15.340
the user and exit.

00:21:15.340 --> 00:21:17.400
We have start fetch, which means
it's time to run the

00:21:17.400 --> 00:21:20.580
fetch and append the
pending queue.

00:21:20.580 --> 00:21:21.740
And then we have the updates.

00:21:21.740 --> 00:21:23.430
And we advance our queue.

00:21:23.430 --> 00:21:25.550
And the key thing here is that
these three cases are

00:21:25.550 --> 00:21:27.490
interacting with the local
state and loop.

00:21:27.490 --> 00:21:29.030
There's no races.

00:21:29.030 --> 00:21:31.340
This is all straight-line
code looking around.

00:21:31.340 --> 00:21:36.240
But you're doing some fairly
complex updates to your state

00:21:36.240 --> 00:21:38.200
because you're dealing with
a lot of things going on.

00:21:38.200 --> 00:21:39.990
And yet, this is still
responsive.

00:21:39.990 --> 00:21:42.970
When it's time to send something
to the user or the

00:21:42.970 --> 00:21:45.060
user's no longer interested,
we clean up very rapidly.

00:21:45.060 --> 00:21:48.160
And this is key to building
responsive systems.

00:21:48.160 --> 00:21:50.380
In all of this code, there's
no locks, no conditioned

00:21:50.380 --> 00:21:53.790
variables, no callbacks, none of
the typical stuff you deal

00:21:53.790 --> 00:21:55.210
with in current programming.

00:21:55.210 --> 00:21:57.870
It's really the syntax and the
structure that Go gives you

00:21:57.870 --> 00:22:01.090
that makes this possible.

00:22:01.090 --> 00:22:02.470
We fixed our three bugs.

00:22:02.470 --> 00:22:04.680
We no longer have the data
race on closed and error.

00:22:04.680 --> 00:22:07.030
Because now we're using
communication instead.

00:22:07.030 --> 00:22:09.370
We're no longer blocking for a
run sleep because it's just

00:22:09.370 --> 00:22:11.560
one of the cases
on our select.

00:22:11.560 --> 00:22:13.380
And we're no longer blocking
forever an update, again,

00:22:13.380 --> 00:22:15.580
because it's just one of the
cases in our select.

00:22:15.580 --> 00:22:20.040
We're always responsive to any
of these events happening.

00:22:20.040 --> 00:22:22.370
Now that we have this structure,
we can make a

00:22:22.370 --> 00:22:23.270
number of improvements.

00:22:23.270 --> 00:22:28.040
It's much easier to see what's
going on in this data type.

00:22:28.040 --> 00:22:31.770
The first issue we noticed is
that this fetch call can

00:22:31.770 --> 00:22:32.510
return duplicates.

00:22:32.510 --> 00:22:36.410
When you fetch an RSS feed and
you re-fetch it, you may get

00:22:36.410 --> 00:22:37.900
many of the items that
got last time as well

00:22:37.900 --> 00:22:40.390
as a few new ones.

00:22:40.390 --> 00:22:43.180
We can fix this trivially now
inside loop by just keeping

00:22:43.180 --> 00:22:45.180
track of the ones we've already
seen because we don't

00:22:45.180 --> 00:22:47.070
want to deliver duplicate
items on our stream.

00:22:47.070 --> 00:22:48.950
We want to have a
deduped stream.

00:22:48.950 --> 00:22:52.560
So we have a set of the items
we've seen represented as a

00:22:52.560 --> 00:22:54.280
map of strings to bool.

00:22:54.280 --> 00:22:55.940
And then instead of just
appending all the items we've

00:22:55.940 --> 00:22:58.500
fetched, we iterate over those
items, check whether we've

00:22:58.500 --> 00:23:00.710
seen it, and only append
the ones we need.

00:23:00.710 --> 00:23:04.060
That's all we need
to do to dedupe.

00:23:04.060 --> 00:23:06.860
A second issue is that the set
of pending items can grow

00:23:06.860 --> 00:23:09.850
without bound, because our
downstream receiver may be

00:23:09.850 --> 00:23:12.060
distracted, may not
be keeping up with

00:23:12.060 --> 00:23:13.620
the items were offering.

00:23:13.620 --> 00:23:17.590
And you can think of this
as back pressure, right?

00:23:17.590 --> 00:23:19.980
If the receiver is doing
something else, we don't want

00:23:19.980 --> 00:23:24.390
to keep acquiring more and
more pending items and

00:23:24.390 --> 00:23:27.100
allocating an arbitrary
amount of memory.

00:23:27.100 --> 00:23:30.100
So what we want to
do here is bound.

00:23:30.100 --> 00:23:32.000
When the receiver is slow,
we want to stop

00:23:32.000 --> 00:23:34.150
fetching new items.

00:23:34.150 --> 00:23:36.540
And we can use that nil
channel trick again.

00:23:36.540 --> 00:23:39.840
So remember that start fetch
schedule told us when the next

00:23:39.840 --> 00:23:41.330
time we should fetch is.

00:23:41.330 --> 00:23:44.160
If we leave that to nil, we
won't run another fetch.

00:23:44.160 --> 00:23:47.080
So we're going to decide, in
this case, that the maximum

00:23:47.080 --> 00:23:48.320
number of pending items
we have is 10.

00:23:48.320 --> 00:23:51.050
And we're only going to schedule
the next fetch if we

00:23:51.050 --> 00:23:52.660
have room in our
pending queue.

00:23:52.660 --> 00:23:53.980
It's a very simplistic policy.

00:23:53.980 --> 00:23:57.096
You can imagine doing a variety
of things here.

00:23:57.096 --> 00:23:59.430
You might care only about having
the most recent items

00:23:59.430 --> 00:24:00.330
since you could drop
stuff from the

00:24:00.330 --> 00:24:01.910
head of pending instead.

00:24:01.910 --> 00:24:04.990
So you can think of this as a
node in a data stream where

00:24:04.990 --> 00:24:07.930
you can implement policies on
how you want to deal with a

00:24:07.930 --> 00:24:08.550
queue overflow.

00:24:08.550 --> 00:24:14.740
Finally, we have this issue
that fetches are doing IO.

00:24:14.740 --> 00:24:16.410
They're talking to remote
servers, and they could take a

00:24:16.410 --> 00:24:19.930
long time, and so this
particular call may block.

00:24:19.930 --> 00:24:23.770
And we may not want to block
our loop on these fetches.

00:24:23.770 --> 00:24:25.040
We want to remain responsive.

00:24:25.040 --> 00:24:27.850
If the server is taking 10
seconds to respond and the

00:24:27.850 --> 00:24:31.890
user calls Close, we want to be
able to ditch and move on.

00:24:31.890 --> 00:24:33.630
And the way we're going to do
is we're going to move fetch

00:24:33.630 --> 00:24:34.570
to its own Goroutine.

00:24:34.570 --> 00:24:37.580
But now we have to figure out
when that fetch finishes.

00:24:37.580 --> 00:24:40.670
We need to then resynchronize
back with what loop is doing.

00:24:40.670 --> 00:24:43.815
We'll do this by introducing
another case into our select

00:24:43.815 --> 00:24:45.990
and another channel for
running fetches to

00:24:45.990 --> 00:24:47.930
communicate with us.

00:24:47.930 --> 00:24:49.210
Here's how that works.

00:24:49.210 --> 00:24:50.790
First, we need a channel
on which select

00:24:50.790 --> 00:24:51.700
can send its results.

00:24:51.700 --> 00:24:53.780
We're going to define a fetch
result data type, which is a

00:24:53.780 --> 00:24:55.460
struct containing the
fetched items the

00:24:55.460 --> 00:24:57.320
next time that error.

00:24:57.320 --> 00:25:00.030
We have this fetchDone channel,
which is channel

00:25:00.030 --> 00:25:01.020
fetchResults.

00:25:01.020 --> 00:25:03.930
And our invariant. this
is non-nil exactly

00:25:03.930 --> 00:25:06.160
when fetch is running.

00:25:06.160 --> 00:25:09.330
So we want to start a fetch
when fetchDone is nil.

00:25:09.330 --> 00:25:10.360
That's our initial state.

00:25:10.360 --> 00:25:12.310
So we'll go ahead and
start a fetch.

00:25:12.310 --> 00:25:15.930
And the startFetch case is going
to set our fetchDone

00:25:15.930 --> 00:25:18.780
channel and start a Goroutine
that runs our fetch.

00:25:18.780 --> 00:25:21.380
And that Goroutine is going to
run a fetch and send the

00:25:21.380 --> 00:25:22.690
results on that channel.

00:25:22.690 --> 00:25:23.630
And then the case exists.

00:25:23.630 --> 00:25:24.900
And so we loop back around.

00:25:24.900 --> 00:25:27.320
And we are considering closing
and delivering items on our

00:25:27.320 --> 00:25:28.540
updates channel.

00:25:28.540 --> 00:25:30.700
When the fetch finishes, it's
going to deliver its result on

00:25:30.700 --> 00:25:31.400
this channel.

00:25:31.400 --> 00:25:32.900
And that's just the
rest of the fetch

00:25:32.900 --> 00:25:34.580
case that we saw before.

00:25:34.580 --> 00:25:36.750
And this is a fairly small
transformation

00:25:36.750 --> 00:25:37.840
to what we had before.

00:25:37.840 --> 00:25:41.240
And we made our loop not block
on the IO that's going on.

00:25:41.240 --> 00:25:43.020
And we still synchronize
properly with all the other

00:25:43.020 --> 00:25:44.580
events that can happen
in this subscription.

00:25:47.300 --> 00:25:48.800
So we've implemented
subscribe.

00:25:48.800 --> 00:25:51.050
This code is responsive to
various events in the

00:25:51.050 --> 00:25:51.980
environment.

00:25:51.980 --> 00:25:55.490
It cleans up everything and
handles cancellation properly.

00:25:55.490 --> 00:25:58.290
And the structure that we
introduced made it relatively

00:25:58.290 --> 00:26:03.070
easy to read and change
the code.

00:26:03.070 --> 00:26:05.810
The key techniques were this
for-select loop, which allows

00:26:05.810 --> 00:26:07.500
you to consider all the things
that could be happening to

00:26:07.500 --> 00:26:09.480
your type in time.

00:26:09.480 --> 00:26:11.870
And this idea of a
request-response channel.

00:26:11.870 --> 00:26:15.820
And you can really build quite
a lot on that, where I think

00:26:15.820 --> 00:26:18.610
of Goroutines in Go, you can
have them acting as servers

00:26:18.610 --> 00:26:19.790
and clients on a little
distributed

00:26:19.790 --> 00:26:21.120
system that you own.

00:26:21.120 --> 00:26:24.890
And you can use these channels
to exchange data.

00:26:24.890 --> 00:26:26.610
And you build a lot of the same
structures you'll see in

00:26:26.610 --> 00:26:29.640
distributed systems within
your program.

00:26:29.640 --> 00:26:32.570
And finally, we have this
technique of setting channel

00:26:32.570 --> 00:26:34.840
to nil and select cases to
turn cases on and off.

00:26:34.840 --> 00:26:37.180
That really just helps you
simplify some of the logic

00:26:37.180 --> 00:26:40.880
when you're dealing with a
staple type like this.

00:26:40.880 --> 00:26:42.140
There are going to be a lot
more details online.

00:26:42.140 --> 00:26:44.430
All the code will be online,
including merge, which is also

00:26:44.430 --> 00:26:46.460
interesting because it's
dealing with multiple

00:26:46.460 --> 00:26:48.140
subscriptions merged onto
a single channel.

00:26:51.460 --> 00:26:53.850
Concurrent programming can be
very tricky, and clearly the

00:26:53.850 --> 00:26:56.460
code that I presented here
is relatively complex.

00:26:56.460 --> 00:26:59.710
But the point is that Go really
makes this easier by

00:26:59.710 --> 00:27:02.480
giving you good building
blocks and good syntax.

00:27:02.480 --> 00:27:04.210
Channels are pretty versatile.

00:27:04.210 --> 00:27:07.160
They're not just for conveying
data, but also for events in

00:27:07.160 --> 00:27:10.780
time and things like
cancellation signals.

00:27:10.780 --> 00:27:13.270
And you can use Goroutine to
serialize access to a mutable

00:27:13.270 --> 00:27:16.090
state in a way that's much
easier to understand than

00:27:16.090 --> 00:27:18.260
traditional synchronization
primitives.

00:27:18.260 --> 00:27:19.890
We also have great new tools.

00:27:19.890 --> 00:27:21.890
We have the stack traces and the
deadlock detector I showed

00:27:21.890 --> 00:27:22.760
you earlier.

00:27:22.760 --> 00:27:24.350
The deadlock detector is
particularly handy when you're

00:27:24.350 --> 00:27:25.490
running unit tests.

00:27:25.490 --> 00:27:28.670
When you're testing a data
type in isolation, and

00:27:28.670 --> 00:27:31.440
everything sort of seizes up,
you can see what goes wrong.

00:27:31.440 --> 00:27:33.550
And we have the race detector
which is great for larger

00:27:33.550 --> 00:27:36.140
tests and integration tests
and larger programs to see

00:27:36.140 --> 00:27:39.820
whether things are working right
at scale when you've got

00:27:39.820 --> 00:27:44.170
lots of Goroutine exchanging
data and accessing state.

00:27:44.170 --> 00:27:47.130
There's a lot more information
about this online.

00:27:47.130 --> 00:27:49.790
Last year's talk, Go Concurrency
Patterns, goes

00:27:49.790 --> 00:27:51.550
over the basics and a lot of the
basic structures you can

00:27:51.550 --> 00:27:54.610
build with Go's concurrency
primitives.

00:27:54.610 --> 00:27:59.290
And Concurrency is not
parallelism talk, considering

00:27:59.290 --> 00:28:02.140
the difference between how you
structure your code to deal

00:28:02.140 --> 00:28:04.960
with a lot of events and what
it means for things to

00:28:04.960 --> 00:28:07.630
actually run in parallel
at the same time.

00:28:07.630 --> 00:28:09.270
And that distinction can
be a little subtle.

00:28:09.270 --> 00:28:11.630
And it's interesting because Go
really lets you write your

00:28:11.630 --> 00:28:12.170
code differently.

00:28:12.170 --> 00:28:14.220
You structure your code
differently when you want to

00:28:14.220 --> 00:28:15.780
be responsive and deal
with a lot of things

00:28:15.780 --> 00:28:17.210
happening at once.

00:28:17.210 --> 00:28:19.280
There's also a code walk
that goes over some of

00:28:19.280 --> 00:28:20.560
these basics as well.

00:28:20.560 --> 00:28:24.010
The Go tour gets into this.

00:28:24.010 --> 00:28:25.930
It starts you from the basics
and works all the way through

00:28:25.930 --> 00:28:27.560
the concurrency primitives.

00:28:27.560 --> 00:28:30.750
And I also plug the Go Team
Fireside Chat, which is

00:28:30.750 --> 00:28:32.260
next, in Room 2.

00:28:32.260 --> 00:28:35.090
And that'll have the whole Go
Team answer your questions

00:28:35.090 --> 00:28:37.050
about the language.

00:28:37.050 --> 00:28:38.300
Thank you.

00:28:50.120 --> 00:28:51.370
Questions?

00:28:58.550 --> 00:28:58.945
AUDIENCE: Hi.

00:28:58.945 --> 00:29:01.160
In one of your early
examples, you were

00:29:01.160 --> 00:29:03.240
leaking Goroutines, right?

00:29:03.240 --> 00:29:03.750
SAMEER AJMANI: Yes.

00:29:03.750 --> 00:29:06.120
AUDIENCE: I'm wondering
what the best way to--

00:29:06.120 --> 00:29:08.650
if there's tooling or
the best way to

00:29:08.650 --> 00:29:10.065
detect when that's happening?

00:29:12.870 --> 00:29:14.120
SAMEER AJMANI: It's a
very good question.

00:29:17.570 --> 00:29:19.470
I think there is some tooling
to be built here to try and

00:29:19.470 --> 00:29:20.050
figure that out.

00:29:20.050 --> 00:29:23.340
For now, I'm using relatively
primitive techniques by

00:29:23.340 --> 00:29:26.140
actually inspecting the set of
stack races that are available

00:29:26.140 --> 00:29:28.300
and frankly that can be very
effective, particularly in

00:29:28.300 --> 00:29:29.810
tests and in isolation.

00:29:29.810 --> 00:29:31.870
I think it would be interesting
to see if we can

00:29:31.870 --> 00:29:32.780
automate this a little more.

00:29:32.780 --> 00:29:36.430
It's a little bit hard to
really detect when--

00:29:36.430 --> 00:29:38.400
well, we know it's hard to
detect when code is done

00:29:38.400 --> 00:29:39.283
executing, right?

00:29:39.283 --> 00:29:40.010
AUDIENCE: Yeah.

00:29:40.010 --> 00:29:41.870
SAMEER AJMANI: So--

00:29:41.870 --> 00:29:42.360
sorry?

00:29:42.360 --> 00:29:45.120
AUDIENCE: Blocking profiles
are in 1.1.

00:29:45.120 --> 00:29:45.815
SAMEER AJMANI: Blocking
profiles?

00:29:45.815 --> 00:29:48.535
AUDIENCE: Yes, so you can
actually get a graph of what

00:29:48.535 --> 00:29:51.870
makes them block.

00:29:51.870 --> 00:29:53.500
SAMEER AJMANI: Blocking
profiles are in 1.1.

00:29:53.500 --> 00:29:55.845
So you can get a graph
of what's blocked.

00:29:58.570 --> 00:29:59.630
This is apparently--

00:29:59.630 --> 00:30:02.600
we should have put
that in the talk.

00:30:02.600 --> 00:30:03.370
AUDIENCE: Thank you.

00:30:03.370 --> 00:30:04.337
SAMEER AJMANI: Thank you.

00:30:04.337 --> 00:30:05.530
Yes?

00:30:05.530 --> 00:30:07.380
AUDIENCE: I guess I have a
very similar question.

00:30:07.380 --> 00:30:11.030
About halfway through the talk
here, one of the things you

00:30:11.030 --> 00:30:13.010
did was surprise us all
with three errors

00:30:13.010 --> 00:30:15.130
that we didn't expect.

00:30:15.130 --> 00:30:19.270
So there are lots of languages
out there that can do

00:30:19.270 --> 00:30:21.060
concurrent programming.

00:30:21.060 --> 00:30:24.900
What I want to know is how Go
helps me find those bugs which

00:30:24.900 --> 00:30:26.150
I'm guaranteed to write?

00:30:29.600 --> 00:30:30.660
SAMEER AJMANI: The race detector
and the unlock

00:30:30.660 --> 00:30:32.690
detectors are good
basic things.

00:30:32.690 --> 00:30:35.290
But I think, again, there's a
lot of things we can do moving

00:30:35.290 --> 00:30:37.890
forward to help detect these
more automatically.

00:30:37.890 --> 00:30:40.380
Our static analysis tools are
getting better and better as

00:30:40.380 --> 00:30:45.420
well as our runtime is
also developing.

00:30:45.420 --> 00:30:48.750
Part of it also is experience
with the language.

00:30:48.750 --> 00:30:54.450
Because when I wrote this, I had
to convince myself that--

00:30:54.450 --> 00:30:56.190
once you've written code that's
dealing with multiple

00:30:56.190 --> 00:31:00.780
Goroutines, this kind of race,
I think, between closed and

00:31:00.780 --> 00:31:02.500
error is apparent.

00:31:02.500 --> 00:31:05.420
But you're right that it's not
obvious to new programmers.

00:31:05.420 --> 00:31:07.300
And part of it's having
the proper tools.

00:31:07.300 --> 00:31:11.700
Part of it is changing the way
you think about how these

00:31:11.700 --> 00:31:13.090
Goroutines work together.

00:31:13.090 --> 00:31:13.990
It's key--

00:31:13.990 --> 00:31:17.070
the tag line I remember is share
memory by communicating,

00:31:17.070 --> 00:31:18.440
not communicate by
sharing memory.

00:31:18.440 --> 00:31:20.320
And here, we're mutating shared
memory without any

00:31:20.320 --> 00:31:21.420
synchronization.

00:31:21.420 --> 00:31:24.220
We fix that by converting
it to communication.

00:31:24.220 --> 00:31:25.370
And that's key.

00:31:25.370 --> 00:31:28.800
AUDIENCE: You're convinced that
over time, this language

00:31:28.800 --> 00:31:30.020
will allow those static

00:31:30.020 --> 00:31:32.300
analysis tools to be developed?

00:31:32.300 --> 00:31:33.650
SAMEER AJMANI: I'm convinced
that our tools will get better

00:31:33.650 --> 00:31:35.140
and better, yes.

00:31:35.140 --> 00:31:37.360
That doesn't mean that we
can detect every race.

00:31:37.360 --> 00:31:40.450
But I think data races are
certainly one of the most

00:31:40.450 --> 00:31:42.420
insidious and hardest
things to debug.

00:31:42.420 --> 00:31:46.140
The race detector is a really
great tool for helping us

00:31:46.140 --> 00:31:47.140
detect that.

00:31:47.140 --> 00:31:52.230
And I think clearly we have to
build our collective ability

00:31:52.230 --> 00:31:55.910
to write programs that take
advantage of our hardware and

00:31:55.910 --> 00:31:58.080
be very responsive to the
events and types.

00:31:58.080 --> 00:31:59.610
And concurrent programming
is important.

00:31:59.610 --> 00:32:00.470
We need to build the tools up.

00:32:00.470 --> 00:32:03.010
And I think Go is a great base
on which to build that because

00:32:03.010 --> 00:32:05.200
I believe the syntax really
helps you read and

00:32:05.200 --> 00:32:06.530
understand the code.

00:32:06.530 --> 00:32:07.780
And we can build
up from there.

00:32:10.290 --> 00:32:11.200
AUDIENCE: Thank you.

00:32:11.200 --> 00:32:12.390
I was at the previous talk.

00:32:12.390 --> 00:32:14.540
And it was about App
Engine and Go.

00:32:14.540 --> 00:32:18.085
And it highly recommended
using Go and App Engine.

00:32:18.085 --> 00:32:22.180
Now, all these debugging tools,
will they work in App

00:32:22.180 --> 00:32:24.290
Engine, meaning the
local development

00:32:24.290 --> 00:32:25.540
environment of App Engine?

00:32:25.540 --> 00:32:28.320
Or how do we debug App
Engine Go apps?

00:32:28.320 --> 00:32:31.810
SAMEER AJMANI: How do we
debug App Engine in Go?

00:32:31.810 --> 00:32:32.720
Next session.

00:32:32.720 --> 00:32:34.410
That's a great question
for the Fireside Chat.

00:32:34.410 --> 00:32:36.666
Thank you.

00:32:36.666 --> 00:32:38.975
AUDIENCE: Hi, there.

00:32:38.975 --> 00:32:40.730
I'm very new to Go.

00:32:40.730 --> 00:32:43.070
But I've been studying some
concurrency structures and

00:32:43.070 --> 00:32:43.780
other languages.

00:32:43.780 --> 00:32:46.330
And it seems like one of
the popular approaches,

00:32:46.330 --> 00:32:48.680
specifically on the
JVM especially

00:32:48.680 --> 00:32:50.840
now, is to use actors.

00:32:50.840 --> 00:32:53.400
And the way those approach
concurrency is by kind of

00:32:53.400 --> 00:32:54.630
holding their hands
up and saying, no.

00:32:54.630 --> 00:32:57.225
No one can touch this message
queue except the object that

00:32:57.225 --> 00:32:58.440
it's assigned to.

00:32:58.440 --> 00:33:02.710
And it seems like Goroutine and
Channels are similar to

00:33:02.710 --> 00:33:05.180
the approach, except that the
channels can be touched by

00:33:05.180 --> 00:33:07.170
external sources.

00:33:07.170 --> 00:33:08.100
SAMEER AJMANI: It's
a great question.

00:33:08.100 --> 00:33:12.330
It's really interesting because
I think the difference

00:33:12.330 --> 00:33:15.440
here is that you can use
Goroutines and channels to

00:33:15.440 --> 00:33:18.250
build something actor-like,
which is sort of what I did

00:33:18.250 --> 00:33:21.280
here with the four select
group if you squint.

00:33:21.280 --> 00:33:23.390
But you can also use them to do
a variety of other things.

00:33:23.390 --> 00:33:25.310
If you look at Rob's earlier
talk, you'll see there's a

00:33:25.310 --> 00:33:26.880
number of ways you can use it.

00:33:26.880 --> 00:33:29.340
And there's certainly value in
the approaches these other

00:33:29.340 --> 00:33:30.890
concurrent languages
have done.

00:33:30.890 --> 00:33:36.450
And the fact that you can, in a
fairly straightforward way,

00:33:36.450 --> 00:33:40.780
convert those good approaches
in Go is a

00:33:40.780 --> 00:33:42.000
strength of the language.

00:33:42.000 --> 00:33:45.355
So yeah, certainly it's the case
that serializing access

00:33:45.355 --> 00:33:46.700
to mutable state, which
is what actors

00:33:46.700 --> 00:33:49.340
do as well, is great.

00:33:49.340 --> 00:33:51.090
So do critical sections.

00:33:51.090 --> 00:33:53.760
And so the question is, what's
the way that allows you to

00:33:53.760 --> 00:33:56.360
structure code in a way that is
easy to reason about, easy

00:33:56.360 --> 00:33:57.610
to maintain?

00:33:59.560 --> 00:34:00.920
I presented one here.

00:34:00.920 --> 00:34:02.290
And there's a number
in the other talks

00:34:02.290 --> 00:34:03.363
and links I've provided.

00:34:03.363 --> 00:34:03.786
AUDIENCE: OK.

00:34:03.786 --> 00:34:04.210
Great.

00:34:04.210 --> 00:34:05.460
Thank you.

00:34:07.760 --> 00:34:09.010
SAMEER AJMANI: Thank
you all very much.

