WEBVTT
Kind: captions
Language: en

00:00:03.484 --> 00:00:05.900
SPEAKER: I'm pleased to be
here today for a Talk at Google

00:00:05.900 --> 00:00:08.850
with Mr. Robin Hanson.

00:00:08.850 --> 00:00:10.900
Robin is a research
associate at the Future

00:00:10.900 --> 00:00:13.340
of Humanity Institute
at Oxford University,

00:00:13.340 --> 00:00:16.070
an associate professor of
economics at George Mason

00:00:16.070 --> 00:00:17.280
University.

00:00:17.280 --> 00:00:20.200
He's known for his ideas on
idea futures and markets,

00:00:20.200 --> 00:00:24.240
and was involved in the creation
of DARPA's Future Map project

00:00:24.240 --> 00:00:27.050
in the Foresight Institute's
Foresight Exchange.

00:00:27.050 --> 00:00:30.500
He invented market scoring
rules, like the LMSR,

00:00:30.500 --> 00:00:32.920
used by prediction markets
such as Consensus Point, where

00:00:32.920 --> 00:00:36.300
he is the chief scientist,
and has conducted research

00:00:36.300 --> 00:00:37.620
on signaling.

00:00:37.620 --> 00:00:39.310
Hanson's blog,
"Overcoming Bias,"

00:00:39.310 --> 00:00:41.480
has more than 50,000
visitors per month,

00:00:41.480 --> 00:00:44.200
with more than eight
million views since 2005.

00:00:44.200 --> 00:00:46.600
Robin, thanks so much for
joining us, and welcome.

00:00:46.600 --> 00:00:48.176
ROBIN HANSON: Thank you.

00:00:48.176 --> 00:00:50.880
[APPLAUSE]

00:00:53.110 --> 00:00:55.210
I plan to leave lots
of time for questions,

00:00:55.210 --> 00:00:57.340
but feel free to ask
questions along the way.

00:00:57.340 --> 00:00:59.270
And I'll feel free to say later.

00:00:59.270 --> 00:01:00.060
[LAUGHTER]

00:01:00.060 --> 00:01:00.560
Deal?

00:01:00.560 --> 00:01:03.310
All right.

00:01:03.310 --> 00:01:04.840
This is a big picture.

00:01:04.840 --> 00:01:07.940
This is the US economy
over the last four years.

00:01:07.940 --> 00:01:10.240
A few days ago, that
last bar came out.

00:01:10.240 --> 00:01:12.450
It's always big news--
the economy bumps

00:01:12.450 --> 00:01:13.620
up or down a little bit.

00:01:13.620 --> 00:01:16.620
But we're going to be talking
about a bigger picture.

00:01:16.620 --> 00:01:20.510
This is the world economy over
the last half century or so.

00:01:20.510 --> 00:01:22.730
And now on the y-axis,
it's a logarithm

00:01:22.730 --> 00:01:24.540
of the size of
the world economy.

00:01:24.540 --> 00:01:28.640
And as you know, logarithms make
exponentials look like lines.

00:01:28.640 --> 00:01:29.740
And that's roughly a line.

00:01:29.740 --> 00:01:31.860
So the major news over the
last half century or so

00:01:31.860 --> 00:01:33.840
is the world economy's
been slowly doubling

00:01:33.840 --> 00:01:36.320
roughly every 15 years.

00:01:36.320 --> 00:01:39.680
But if you go back even
farther-- say, 2,000 years--

00:01:39.680 --> 00:01:40.910
it's still a log axis.

00:01:40.910 --> 00:01:43.610
But it's no longer a
line because it was not

00:01:43.610 --> 00:01:44.430
exponential growth.

00:01:44.430 --> 00:01:46.350
There was the famous
Industrial Revolution.

00:01:46.350 --> 00:01:48.320
Before that, it looks
like there wasn't growth.

00:01:48.320 --> 00:01:51.190
And then we've been growing
like gangbusters ever since.

00:01:51.190 --> 00:01:57.630
But if you look back even
farther, over 10,000 years,

00:01:57.630 --> 00:02:00.170
you'll see that there
was a farming revolution

00:02:00.170 --> 00:02:01.860
7,000 years or so ago.

00:02:01.860 --> 00:02:03.882
And it was growing
exponential after that.

00:02:03.882 --> 00:02:06.340
During the farming era, it was
doubling roughly every 1,000

00:02:06.340 --> 00:02:07.454
years.

00:02:07.454 --> 00:02:09.870
And before then, it looks like
it was growing even slower.

00:02:09.870 --> 00:02:13.830
But of course, it was, in fact,
growing exponentially, roughly.

00:02:13.830 --> 00:02:16.126
It was growing even slower.

00:02:16.126 --> 00:02:17.750
And if you go back
even farther, you'll

00:02:17.750 --> 00:02:19.250
see that brains
were growing roughly

00:02:19.250 --> 00:02:21.540
exponentially over the
last half billion years.

00:02:21.540 --> 00:02:23.784
And even farther
back, genome seems

00:02:23.784 --> 00:02:25.200
to have been growing
exponentially

00:02:25.200 --> 00:02:27.550
over many billions of years.

00:02:27.550 --> 00:02:30.760
If you just look at the last
period of human history,

00:02:30.760 --> 00:02:33.190
you'll see that this
sequence of growth

00:02:33.190 --> 00:02:36.900
is fit pretty well by just a
sequence of exponential modes,

00:02:36.900 --> 00:02:39.360
i.e., exponential growth
with sudden transitions

00:02:39.360 --> 00:02:41.860
to faster growth modes.

00:02:41.860 --> 00:02:43.780
So if we put this
all on one graph,

00:02:43.780 --> 00:02:45.750
now it's again
logarithm, but now it's

00:02:45.750 --> 00:02:48.480
logarithm of the growth rate.

00:02:48.480 --> 00:02:50.530
And on the y-axis,
now I've changed

00:02:50.530 --> 00:02:52.649
it to be a logarithm
of time until sometime

00:02:52.649 --> 00:02:54.690
in the near future so I
can fit this all on here.

00:02:54.690 --> 00:02:57.130
And so then you have
very slowly growing

00:02:57.130 --> 00:02:59.970
things like animal
brains, humans growing--

00:02:59.970 --> 00:03:02.870
doubling roughly every
quarter million years--

00:03:02.870 --> 00:03:05.180
farmers doubling
roughly every 1,000,

00:03:05.180 --> 00:03:08.700
industry doubling
roughly every 15,000.

00:03:08.700 --> 00:03:13.490
If this trend were
to continue, then

00:03:13.490 --> 00:03:17.040
the statistics of the last
few modes suggest roughly

00:03:17.040 --> 00:03:19.310
there would be a transition
some time roughly

00:03:19.310 --> 00:03:22.370
in the next century or
so-- not very precise.

00:03:22.370 --> 00:03:24.730
Within a five-year
period, the economy

00:03:24.730 --> 00:03:26.540
would go from doubling
every 15 years,

00:03:26.540 --> 00:03:30.140
like it does now, to doubling
every month or faster.

00:03:30.140 --> 00:03:32.170
And then that would
last for a year or two.

00:03:32.170 --> 00:03:35.016
And then something
else would happen.

00:03:35.016 --> 00:03:36.640
What could possibly
cause such a thing?

00:03:36.640 --> 00:03:38.260
One of the most
common speculations

00:03:38.260 --> 00:03:40.740
about a really big disruptive
change on the horizon that

00:03:40.740 --> 00:03:42.760
could change everything
is smart robots--

00:03:42.760 --> 00:03:44.310
artificial intelligence.

00:03:44.310 --> 00:03:46.170
And there are several
stories about how

00:03:46.170 --> 00:03:47.660
that might be possible.

00:03:47.660 --> 00:03:49.182
One route is that
we continue to do

00:03:49.182 --> 00:03:50.640
what we've been
doing for 70 years,

00:03:50.640 --> 00:03:53.320
slowly accumulating
better software.

00:03:53.320 --> 00:03:57.120
I used to be an AI researcher
for nine years-- a while ago.

00:03:57.120 --> 00:03:58.719
And so when I go to
conferences and I

00:03:58.719 --> 00:04:00.510
meet researchers who
have been in the field

00:04:00.510 --> 00:04:02.190
for at least 20
years and ask them,

00:04:02.190 --> 00:04:04.400
in your subfield
that you know best,

00:04:04.400 --> 00:04:06.380
how far have we come
in the last 20 years

00:04:06.380 --> 00:04:09.210
as a percentage of the distance
to human level abilities,

00:04:09.210 --> 00:04:13.530
they usually say 5% to 10%--
no noticeable acceleration.

00:04:13.530 --> 00:04:16.390
At that rate, we're talking
two to four centuries, which

00:04:16.390 --> 00:04:21.430
is a short time, but not in
your lifetime necessarily.

00:04:21.430 --> 00:04:23.870
Other people say, past
progress is no indication

00:04:23.870 --> 00:04:24.750
of future progress.

00:04:24.750 --> 00:04:27.260
We've got a really great
theory just around the corner.

00:04:27.260 --> 00:04:31.210
And when we do, everything
will be easy-- maybe.

00:04:31.210 --> 00:04:35.170
I'm going to explore a
third scenario, a relatively

00:04:35.170 --> 00:04:36.112
conservative scenario.

00:04:36.112 --> 00:04:38.570
This is the idea, of course,
as you know, porting software.

00:04:38.570 --> 00:04:40.486
We're going to try to
port the software that's

00:04:40.486 --> 00:04:42.320
already in the human brain.

00:04:42.320 --> 00:04:44.610
To do that, we
need three things.

00:04:44.610 --> 00:04:46.750
We need lots of fast
parallel computers, which

00:04:46.750 --> 00:04:48.100
we don't have enough of yet.

00:04:48.100 --> 00:04:49.683
We don't have any
of these things yet,

00:04:49.683 --> 00:04:51.420
but we're working on it.

00:04:51.420 --> 00:04:55.080
We need to have the ability to
take particular human brains

00:04:55.080 --> 00:04:59.300
and scan them in very fine
spatial and chemical detail.

00:04:59.300 --> 00:05:02.400
And then we need to have models
of how each type of brain cell

00:05:02.400 --> 00:05:04.170
works in terms of
taking input signals,

00:05:04.170 --> 00:05:06.932
changing internal state,
and sending output signals.

00:05:06.932 --> 00:05:08.640
If you have all of
those things, then you

00:05:08.640 --> 00:05:11.370
can basically take
a particular scan

00:05:11.370 --> 00:05:13.280
and make a model of
that particular brain

00:05:13.280 --> 00:05:15.730
with your models of all the
particular brain cell types.

00:05:15.730 --> 00:05:16.850
And if your models
are good enough,

00:05:16.850 --> 00:05:18.850
your scan's good enough,
the entire thing should

00:05:18.850 --> 00:05:21.160
have the same input/output
behavior, i.e.,

00:05:21.160 --> 00:05:24.040
you can hook it up with hands,
eyes, ears, mouths, and talk

00:05:24.040 --> 00:05:25.650
to it, talk back,
ask it to do things.

00:05:25.650 --> 00:05:26.790
It might do them.

00:05:26.790 --> 00:05:30.160
If you have that sort of
thing and it was cheap,

00:05:30.160 --> 00:05:32.140
a lot changes.

00:05:32.140 --> 00:05:36.351
Now, when might that happen?

00:05:36.351 --> 00:05:38.600
It depends on how deep into
the brain structure we go.

00:05:38.600 --> 00:05:40.460
The brain's cells
are very complicated.

00:05:40.460 --> 00:05:42.402
If we have to do a lot
of that complexity,

00:05:42.402 --> 00:05:44.360
it'll take longer before
we have computers that

00:05:44.360 --> 00:05:46.410
are cheap enough to do that.

00:05:46.410 --> 00:05:47.690
If not, we can do it sooner.

00:05:47.690 --> 00:05:49.180
But still, the
forecast is roughly

00:05:49.180 --> 00:05:51.130
in the next century or so.

00:05:51.130 --> 00:05:54.200
That's roughly the time scale.

00:05:54.200 --> 00:05:57.050
Now, I've been around
people-- some of them

00:05:57.050 --> 00:05:59.660
in this room-- for
30 or more years

00:05:59.660 --> 00:06:01.240
who like to talk
about this subject.

00:06:01.240 --> 00:06:04.200
It's a favorite bull session
topic for college students.

00:06:04.200 --> 00:06:07.400
When the subject comes up, the
favorite topics are usually,

00:06:07.400 --> 00:06:10.770
is it even technically
possible to make a machine that

00:06:10.770 --> 00:06:13.100
acts just like a real human?

00:06:13.100 --> 00:06:15.530
If we were to do it, is it
going to be conscious or is

00:06:15.530 --> 00:06:17.380
it just a bunch of wires?

00:06:17.380 --> 00:06:20.580
If we made a copy of me, an
emulation of me, is it me

00:06:20.580 --> 00:06:21.926
or is it somebody else?

00:06:21.926 --> 00:06:23.300
Those are all
really fun subjects

00:06:23.300 --> 00:06:25.042
that I'm going to ignore.

00:06:25.042 --> 00:06:26.990
[LAUGHTER]

00:06:26.990 --> 00:06:28.800
I think they're overdone.

00:06:28.800 --> 00:06:31.410
You're welcome to take them on.

00:06:31.410 --> 00:06:33.930
But I want to talk about
a neglected subject.

00:06:33.930 --> 00:06:36.610
So I have written this book,
"The Age of Em-- Work, Love,

00:06:36.610 --> 00:06:39.920
and Life When Robots Rule the
Earth"-- just out June 1--

00:06:39.920 --> 00:06:42.980
some favorable quotes.

00:06:42.980 --> 00:06:46.300
I decided to focus on what
would actually happen.

00:06:46.300 --> 00:06:48.397
What would be the actual
social consequences

00:06:48.397 --> 00:06:49.480
of having this technology?

00:06:49.480 --> 00:06:51.960
What does the world look like?

00:06:51.960 --> 00:06:55.080
Now, if you look up on
Amazon the keyword history,

00:06:55.080 --> 00:06:58.040
you'll find about 20% of the
books have the keyword history.

00:06:58.040 --> 00:07:00.180
1% have the keyword
future-- a lot more interest

00:07:00.180 --> 00:07:01.110
in the past than the future.

00:07:01.110 --> 00:07:02.400
Interestingly,
though, if you looked

00:07:02.400 --> 00:07:05.010
at historical fiction and future
fiction, it's about the same.

00:07:05.010 --> 00:07:06.040
And you might ask,
well, why don't we

00:07:06.040 --> 00:07:08.081
study the future more
because we can do something

00:07:08.081 --> 00:07:09.130
about it, maybe?

00:07:09.130 --> 00:07:10.350
Past is kind of too late.

00:07:10.350 --> 00:07:12.860
And the usual answer people
give you is, well, duh,

00:07:12.860 --> 00:07:14.180
we can't study the future.

00:07:14.180 --> 00:07:15.180
We can study the past.

00:07:15.180 --> 00:07:16.810
See all these artifacts
and stuff we've got around?

00:07:16.810 --> 00:07:19.059
We can study the past because
we have these artifacts.

00:07:19.059 --> 00:07:21.410
No artifacts about
the future-- no study.

00:07:21.410 --> 00:07:23.890
I think that's wrong.

00:07:23.890 --> 00:07:25.720
So we have theory.

00:07:25.720 --> 00:07:27.367
I'm a social scientist.

00:07:27.367 --> 00:07:29.950
So think about three different
ways to think about the future.

00:07:29.950 --> 00:07:31.740
One is to just take
current trends,

00:07:31.740 --> 00:07:36.282
like increasing leisure,
decreasing religiosity,

00:07:36.282 --> 00:07:37.740
increasing promiscuity,
whatever it

00:07:37.740 --> 00:07:39.440
is, project those
trends forward, think

00:07:39.440 --> 00:07:40.570
about where they lead.

00:07:40.570 --> 00:07:43.310
Another way to do futurism
is to imagine disruptive

00:07:43.310 --> 00:07:46.290
technologies-- self-driving
cars, blockchains--

00:07:46.290 --> 00:07:48.540
and try to imagine the
details of those technologies.

00:07:48.540 --> 00:07:50.012
But a third way
of doing futurism

00:07:50.012 --> 00:07:51.970
is to take one of those
disruptive technologies

00:07:51.970 --> 00:07:53.600
and ask, what are
the consequences?

00:07:53.600 --> 00:07:55.290
What follows as a result?

00:07:55.290 --> 00:07:57.640
And that tends to be neglected
because the people who

00:07:57.640 --> 00:07:59.570
take these disrupting
technologies seriously

00:07:59.570 --> 00:08:02.010
tend to be technologists,
physical scientists.

00:08:02.010 --> 00:08:05.230
And I learned when I was
a undergraduate, graduate

00:08:05.230 --> 00:08:07.510
physical scientists--
that the standard view is

00:08:07.510 --> 00:08:09.580
those social scientists,
they're bullshit.

00:08:09.580 --> 00:08:12.420
They don't know
anything-- doesn't exist.

00:08:12.420 --> 00:08:15.170
So I became a Ph.D., and now
a professor of economics.

00:08:15.170 --> 00:08:17.360
And I can tell
you it does exist.

00:08:17.360 --> 00:08:20.262
And this book is in part trying
to show you that we know a lot,

00:08:20.262 --> 00:08:22.720
and we can apply lots of things
we know to find out answers

00:08:22.720 --> 00:08:24.420
to questions like this.

00:08:24.420 --> 00:08:26.760
So this is a map of academia.

00:08:26.760 --> 00:08:29.951
These are different major fields
connected by co-citation links.

00:08:29.951 --> 00:08:31.950
When they cite each other
a lot, they're linked.

00:08:31.950 --> 00:08:34.090
So academia is a
circle-- go figure.

00:08:34.090 --> 00:08:35.890
I don't know why.

00:08:35.890 --> 00:08:38.250
But I can tell you that
these are the fields

00:08:38.250 --> 00:08:39.914
I'm drawing on for this book.

00:08:39.914 --> 00:08:41.539
I have an unusually
diverse background.

00:08:41.539 --> 00:08:42.955
So I've turned
that into a virtue.

00:08:42.955 --> 00:08:45.320
It's usually not a
virtue in academia

00:08:45.320 --> 00:08:46.640
to know too many fields.

00:08:46.640 --> 00:08:49.340
But I'm going draw on
that for this book.

00:08:49.340 --> 00:08:51.757
That allows me to take
some simple strategies,

00:08:51.757 --> 00:08:53.090
like pick the low-hanging fruit.

00:08:53.090 --> 00:08:56.430
I'm just going to go area by
area through a civilization

00:08:56.430 --> 00:08:59.970
with this brain emulations and
ask, what do standard theories

00:08:59.970 --> 00:09:01.437
predict about this?

00:09:01.437 --> 00:09:03.395
And when I find easy
things to say, I say them.

00:09:03.395 --> 00:09:07.420
And when it looks hard,
I go on to the next one.

00:09:07.420 --> 00:09:08.850
I am applying theory here.

00:09:08.850 --> 00:09:09.890
So I'm a theorist.

00:09:09.890 --> 00:09:12.085
I'm staking our standard
theories and applying them.

00:09:12.085 --> 00:09:13.460
I'm going to do
what theorists do

00:09:13.460 --> 00:09:16.810
everywhere, which is we look
for our keys under the lamppost,

00:09:16.810 --> 00:09:19.330
i.e., we make simplifying
assumptions as necessary

00:09:19.330 --> 00:09:20.330
to get concrete results.

00:09:20.330 --> 00:09:24.290
That's what we always
do-- welcome the theory.

00:09:24.290 --> 00:09:25.720
So this is my last
slide where I'm

00:09:25.720 --> 00:09:27.780
going to tell you how
I'm doing what I'm doing.

00:09:27.780 --> 00:09:29.405
And then after this,
I'm going to start

00:09:29.405 --> 00:09:32.390
telling you all the results that
I've learned about this world.

00:09:32.390 --> 00:09:34.910
But just to be clear, cover
my ass-- I'm an academic,

00:09:34.910 --> 00:09:38.790
after all-- first
of all, I'm just

00:09:38.790 --> 00:09:40.790
trying to apply
standard consensus,

00:09:40.790 --> 00:09:42.920
not be creative or
original, other than asking

00:09:42.920 --> 00:09:44.660
this unusual question.

00:09:44.660 --> 00:09:46.610
Secondly, I'm going
to focus on just

00:09:46.610 --> 00:09:48.602
saying what this world
looks like whether I

00:09:48.602 --> 00:09:49.560
like it or you like it.

00:09:49.560 --> 00:09:51.390
It's not my job to
make you like it.

00:09:51.390 --> 00:09:52.820
My job is just to
tell you what it

00:09:52.820 --> 00:09:56.420
looks like with the path
of least resistance,

00:09:56.420 --> 00:09:58.610
as if we did the least to
stop it-- just what it's

00:09:58.610 --> 00:10:01.190
most likely to become.

00:10:01.190 --> 00:10:03.222
Not that much happens to
humans during this era.

00:10:03.222 --> 00:10:04.180
I will talk about them.

00:10:04.180 --> 00:10:05.820
But mostly, the focus
is on the robots

00:10:05.820 --> 00:10:08.130
because a lot happens for them.

00:10:08.130 --> 00:10:10.370
I'm not going to tell you
about the entire history

00:10:10.370 --> 00:10:12.250
of the universe for the
next trillion years.

00:10:12.250 --> 00:10:14.630
My ambition, which I think
is pretty ambitious enough,

00:10:14.630 --> 00:10:17.330
is to tell you about the next
great era after ours that's

00:10:17.330 --> 00:10:19.020
as different from
our era as ours

00:10:19.020 --> 00:10:21.720
is from the farming or foraging
eras that came before us.

00:10:21.720 --> 00:10:24.610
That's plenty for me,
thank you very much.

00:10:24.610 --> 00:10:28.880
I'm going to focus on what
happens once this world is

00:10:28.880 --> 00:10:34.030
in its groove where people are
know roughly what to expect

00:10:34.030 --> 00:10:35.694
and they can see their world.

00:10:35.694 --> 00:10:37.110
You are now in the
industrial era.

00:10:37.110 --> 00:10:39.355
The industrial era has reached
some sort of rough equilibrium.

00:10:39.355 --> 00:10:41.230
You know kind of what
our world's like.

00:10:41.230 --> 00:10:42.850
Early on in the
Industrial Revolution,

00:10:42.850 --> 00:10:44.450
people didn't know
where it was going.

00:10:44.450 --> 00:10:45.250
They were scared.

00:10:45.250 --> 00:10:46.480
And it was a lot
harder to predict

00:10:46.480 --> 00:10:48.063
what was happening
during a transition

00:10:48.063 --> 00:10:51.060
than it is during
the equilibrium.

00:10:51.060 --> 00:10:54.440
I'm going to take a standard
economist method called

00:10:54.440 --> 00:10:56.390
supply and demand.

00:10:56.390 --> 00:10:58.680
This is our usual first-cut
analysis of everything

00:10:58.680 --> 00:11:02.290
because it's our best and
easiest first-cut analysis.

00:11:02.290 --> 00:11:06.070
This is basically assuming a lot
of competitors and relatively

00:11:06.070 --> 00:11:07.350
little regulation.

00:11:07.350 --> 00:11:08.810
It's a world out of control.

00:11:08.810 --> 00:11:09.680
Nobody runs it.

00:11:09.680 --> 00:11:12.640
There's no vote taken on what
people wish would happen.

00:11:12.640 --> 00:11:14.280
The world just
happens as a result

00:11:14.280 --> 00:11:17.160
of many small local actions.

00:11:17.160 --> 00:11:18.900
Finally, these
emulations-- I'm going

00:11:18.900 --> 00:11:21.024
to make simple assumptions
about them which I think

00:11:21.024 --> 00:11:23.440
are more reasonable in
the early era, at least.

00:11:23.440 --> 00:11:24.450
You have a simulation.

00:11:24.450 --> 00:11:26.440
You made a scan and
you made a model.

00:11:26.440 --> 00:11:27.120
And you have it.

00:11:27.120 --> 00:11:28.404
And it's mostly a black box.

00:11:28.404 --> 00:11:30.070
There's a few tweaks
you can make to it.

00:11:30.070 --> 00:11:34.540
But mostly, you can turn it on,
turn it off, copy it, erase it,

00:11:34.540 --> 00:11:36.070
run it fast, run it slow.

00:11:36.070 --> 00:11:37.780
That's about it.

00:11:37.780 --> 00:11:40.990
And now I'm going to talk about
what does that world look like?

00:11:40.990 --> 00:11:42.310
We have these cheap emulations.

00:11:42.310 --> 00:11:43.760
Those are the things
you can do to them.

00:11:43.760 --> 00:11:44.980
This is the
assumptions I'm making.

00:11:44.980 --> 00:11:45.480
Yes?

00:11:45.480 --> 00:11:46.960
AUDIENCE: [INAUDIBLE]

00:11:46.960 --> 00:11:50.850
ROBIN HANSON: It starts out
being exactly the person that

00:11:50.850 --> 00:11:51.650
was scanned.

00:11:51.650 --> 00:11:53.290
So the soon as you
turn it on, you

00:11:53.290 --> 00:11:57.230
have to tell it, you are
the emulation, sir or madam,

00:11:57.230 --> 00:11:59.680
and convince it that it is
no longer the human because

00:11:59.680 --> 00:12:01.409
a moment ago, it was
the scan of a human,

00:12:01.409 --> 00:12:02.700
and that's where it was before.

00:12:02.700 --> 00:12:04.880
So it then diverges
from that point

00:12:04.880 --> 00:12:07.930
on through differing experiences
to become something different

00:12:07.930 --> 00:12:09.150
in terms of its life.

00:12:09.150 --> 00:12:11.470
But it starts out being
very human in terms

00:12:11.470 --> 00:12:15.230
of its psychology and its
skills and its memory and habits

00:12:15.230 --> 00:12:17.490
and things like that.

00:12:17.490 --> 00:12:19.580
He says, why do I so
quickly dismiss the idea

00:12:19.580 --> 00:12:21.400
that this could be impossible?

00:12:21.400 --> 00:12:24.120
Well, as I said, I've heard that
discussion over and over again

00:12:24.120 --> 00:12:24.910
for many decades.

00:12:24.910 --> 00:12:26.060
I'm tired of it.

00:12:26.060 --> 00:12:26.980
You can look it up.

00:12:26.980 --> 00:12:28.580
There are many people
have talked about it.

00:12:28.580 --> 00:12:31.110
But I thought so many people
have talked about this scenario

00:12:31.110 --> 00:12:33.193
that it's worth thinking
about what would actually

00:12:33.193 --> 00:12:35.084
happen rather than
endlessly go over

00:12:35.084 --> 00:12:37.750
this philosophical underpinnings
of whether it could be possible

00:12:37.750 --> 00:12:40.525
or not-- sort of a
technologist sort of attitude,

00:12:40.525 --> 00:12:42.400
like let's just get on
with making the thing,

00:12:42.400 --> 00:12:43.533
see what happens.

00:12:43.533 --> 00:12:45.692
AUDIENCE: It sounds like
[INAUDIBLE] different.

00:12:45.692 --> 00:12:47.900
ROBIN HANSON: I have many
personal opinions here that

00:12:47.900 --> 00:12:50.210
about preferences that
are irrelevant to my talk.

00:12:50.210 --> 00:12:51.930
You shouldn't care what I want.

00:12:51.930 --> 00:12:53.760
You should care what I know.

00:12:53.760 --> 00:12:54.740
[LAUGHTER]

00:12:54.740 --> 00:12:57.010
And I'll tell you what I know.

00:12:57.010 --> 00:12:59.730
So some things I can
tell you are just

00:12:59.730 --> 00:13:01.700
true for any world
dominated by robots

00:13:01.700 --> 00:13:04.260
because the key assumption is
that a robot can be represented

00:13:04.260 --> 00:13:06.380
by some sort of computer file.

00:13:06.380 --> 00:13:08.230
So computer files
can be made immortal.

00:13:08.230 --> 00:13:10.280
You can archive them,
keep bringing them back.

00:13:10.280 --> 00:13:13.320
So robots can, in
principle, be immortal.

00:13:13.320 --> 00:13:15.830
Now, today houses and cars
are in principle immortal--

00:13:15.830 --> 00:13:17.090
that is, you can keep
repairing them forever.

00:13:17.090 --> 00:13:18.270
But you don't always.

00:13:18.270 --> 00:13:22.210
So just because they could be
immortal doesn't mean they are.

00:13:22.210 --> 00:13:25.440
Electronic files can
be sent electronically

00:13:25.440 --> 00:13:26.560
across long distances.

00:13:26.560 --> 00:13:28.450
So emulations or
other kinds of robots

00:13:28.450 --> 00:13:30.530
can travel long distance
at the speed of light

00:13:30.530 --> 00:13:33.880
by just sending the file
that represents them.

00:13:33.880 --> 00:13:36.230
You care that you
don't kill nature

00:13:36.230 --> 00:13:39.460
in part because you fear that if
you kill nature, you will die.

00:13:39.460 --> 00:13:40.580
It's a reasonable fear.

00:13:40.580 --> 00:13:42.675
But robots don't have that fear.

00:13:42.675 --> 00:13:45.050
They know that if they are
made in factories out of stuff

00:13:45.050 --> 00:13:47.400
dug up in mines, if they
accidentally kill off nature,

00:13:47.400 --> 00:13:48.190
they keep going.

00:13:48.190 --> 00:13:53.087
So they have less of an
impetus to save nature.

00:13:53.087 --> 00:13:54.670
You can make copies
of computer files.

00:13:54.670 --> 00:13:56.540
And that has enormous
implications.

00:13:56.540 --> 00:13:58.970
So first of all, with the
supply and demand of labor--

00:13:58.970 --> 00:14:00.990
today, you guys are
all in high demand.

00:14:00.990 --> 00:14:02.040
You're all very valuable.

00:14:02.040 --> 00:14:03.470
There's a big demand
for people like you,

00:14:03.470 --> 00:14:05.070
a limited supply
in people like you.

00:14:05.070 --> 00:14:06.030
You get high wages.

00:14:06.030 --> 00:14:07.820
Isn't that nice?

00:14:07.820 --> 00:14:09.830
When there are
substitutes for you

00:14:09.830 --> 00:14:12.464
that are made in factories
with a very elastic supply

00:14:12.464 --> 00:14:14.380
curve, which most stuff
made in factories has,

00:14:14.380 --> 00:14:18.150
wages fall down to
a subsistence level

00:14:18.150 --> 00:14:21.950
of the robots, which is below
subsistence level for humans.

00:14:21.950 --> 00:14:24.400
And so even if the
economy gets much bigger,

00:14:24.400 --> 00:14:27.451
still wages stay small-- at
subsistence level for robots.

00:14:30.160 --> 00:14:32.740
The economy can
also grow faster.

00:14:32.740 --> 00:14:36.700
So today, we need
basically labor and capital

00:14:36.700 --> 00:14:39.000
to make stuff--
first approximation.

00:14:39.000 --> 00:14:41.850
We can make stuff in factories,
actually, pretty fast.

00:14:41.850 --> 00:14:43.930
But if you make a lot
more stuff in factories

00:14:43.930 --> 00:14:45.140
and you have the same
number of people,

00:14:45.140 --> 00:14:46.160
you have diminishing returns.

00:14:46.160 --> 00:14:47.780
They're not actually
that valuable.

00:14:47.780 --> 00:14:49.700
If you can make a
lot more people fast,

00:14:49.700 --> 00:14:51.020
the economy can grow fast.

00:14:51.020 --> 00:14:53.460
But today, the economy
doubles every 15 years.

00:14:53.460 --> 00:14:55.360
And we don't double
people every 15 years.

00:14:55.360 --> 00:14:56.650
So what are we doing?

00:14:56.650 --> 00:14:57.900
We are making better machines.

00:14:57.900 --> 00:15:01.510
This is the main way we grow
today-- is through innovation.

00:15:01.510 --> 00:15:03.750
However, if you can
make substitutes

00:15:03.750 --> 00:15:06.280
for people in a factory
and you can make them

00:15:06.280 --> 00:15:08.970
just as fast as you can make
other stuff in factories,

00:15:08.970 --> 00:15:12.270
the economy can grow much faster
than our economy grows today.

00:15:12.270 --> 00:15:15.020
Standard growth economics
says it could plausibly

00:15:15.020 --> 00:15:16.340
double every month or faster.

00:15:16.340 --> 00:15:18.631
That's a straightforward
prediction of standard theory.

00:15:22.400 --> 00:15:24.619
If the economy
doubles every month,

00:15:24.619 --> 00:15:26.410
this whole era may only
last a year or two.

00:15:26.410 --> 00:15:29.430
And during that era, if it
takes a year to get to Mars,

00:15:29.430 --> 00:15:31.980
they will really not be
that interested in that.

00:15:31.980 --> 00:15:34.440
The opportunity cost
will be just extreme.

00:15:34.440 --> 00:15:37.310
So they will either figure out
ways to get around really fast,

00:15:37.310 --> 00:15:42.127
or wait a while before
they take long, slow trips.

00:15:42.127 --> 00:15:43.960
Most of you are probably
software engineers.

00:15:43.960 --> 00:15:47.122
So let me tell you about
software in this new era.

00:15:47.122 --> 00:15:48.580
Over the last few
decades, you guys

00:15:48.580 --> 00:15:51.002
have enjoyed the experience
that your wages have

00:15:51.002 --> 00:15:53.460
been slowly rising while the
cost of hardware you deal with

00:15:53.460 --> 00:15:54.950
has been rapidly falling.

00:15:54.950 --> 00:15:57.232
That has changed your
style of programming--

00:15:57.232 --> 00:15:59.190
that as you are doing
more and more things that

00:15:59.190 --> 00:16:00.710
are very intensive
with hardware,

00:16:00.710 --> 00:16:02.360
because they're cheap.

00:16:02.360 --> 00:16:04.480
However, when emulations
show up, all of a sudden,

00:16:04.480 --> 00:16:07.000
the cost of emulation
falls dramatically.

00:16:07.000 --> 00:16:09.190
And then the cost of
the emulation hardware

00:16:09.190 --> 00:16:11.672
falls at the same rate of other
computer hardware, roughly.

00:16:11.672 --> 00:16:13.630
So there's a sudden "Back
to the Future" moment

00:16:13.630 --> 00:16:16.230
where you go back to old
styles of software engineering

00:16:16.230 --> 00:16:17.700
that were less
hardware-intensive.

00:16:17.700 --> 00:16:20.180
And then you stay at roughly
that era for a long time,

00:16:20.180 --> 00:16:22.190
at least for parallel software.

00:16:22.190 --> 00:16:23.940
For serial hardware, it's worse.

00:16:23.940 --> 00:16:25.630
You start going
backward and backward

00:16:25.630 --> 00:16:28.474
because serial hardware does not
improve as fast as the hardware

00:16:28.474 --> 00:16:29.640
that emulations are made of.

00:16:29.640 --> 00:16:30.270
Yes?

00:16:30.270 --> 00:16:32.728
So the question is, do I see
programming languages changing

00:16:32.728 --> 00:16:33.310
or evolving?

00:16:33.310 --> 00:16:36.250
And my generic answer here is
I've looked opportunistically

00:16:36.250 --> 00:16:38.690
for things I can say with some
confidence, and I say them.

00:16:38.690 --> 00:16:40.980
And when I can't find a
thing to say, I don't say it.

00:16:40.980 --> 00:16:43.355
And this is one of those things
I don't know what to say.

00:16:43.355 --> 00:16:46.190
What I can tell you is if you
understand how programming

00:16:46.190 --> 00:16:48.870
languages and tools depend
on the ratio of the cost

00:16:48.870 --> 00:16:50.880
of hardware to the
cost of a person,

00:16:50.880 --> 00:16:53.650
those things will have a
"Back to the Future" moment.

00:16:53.650 --> 00:16:56.500
Other dimensions, I don't know.

00:16:56.500 --> 00:16:58.100
And that's just for
parallel hardware.

00:16:58.100 --> 00:17:01.050
For serial hardware or serial
tools, it gets even worse.

00:17:03.960 --> 00:17:05.310
So this is your life.

00:17:05.310 --> 00:17:06.880
You start, and then you end.

00:17:06.880 --> 00:17:08.210
Isn't that nice?

00:17:08.210 --> 00:17:10.150
[LAUGHTER]

00:17:10.150 --> 00:17:13.690
This is a more complicated
life of an emulation.

00:17:13.690 --> 00:17:15.300
And an emulation can
split off copies.

00:17:15.300 --> 00:17:17.220
So at the beginning
of a work day,

00:17:17.220 --> 00:17:19.960
emulations plausibly
will often split off

00:17:19.960 --> 00:17:23.730
a few copies who spend a few
hours doing a short-term task,

00:17:23.730 --> 00:17:25.940
and then end or retire.

00:17:25.940 --> 00:17:28.369
These short-term copies
are much cheaper.

00:17:28.369 --> 00:17:30.160
They don't have to rest
over the whole rest

00:17:30.160 --> 00:17:32.660
evening in order to be
ready for the next work day.

00:17:32.660 --> 00:17:35.550
So if you don't need to
remember the task being

00:17:35.550 --> 00:17:37.360
done very well--
just want the task

00:17:37.360 --> 00:17:39.080
done-- this is very tempting.

00:17:39.080 --> 00:17:41.040
We'll talk more
about how tempting.

00:17:41.040 --> 00:17:42.750
This is an opportunistic em.

00:17:42.750 --> 00:17:44.699
They make more copies
whenever there's demand

00:17:44.699 --> 00:17:45.740
for that particular copy.

00:17:45.740 --> 00:17:47.460
They don't know which things
will be in more demand.

00:17:47.460 --> 00:17:50.310
Some time, there's an expanding
demand-- sometimes, declining.

00:17:50.310 --> 00:17:53.270
And that's their life.

00:17:53.270 --> 00:17:55.640
This could be an em software
engineer or other sort

00:17:55.640 --> 00:17:56.590
of designer.

00:17:56.590 --> 00:17:59.079
You initially conceive
of a large system.

00:17:59.079 --> 00:18:01.120
And then once you've
conceived of the subsystems,

00:18:01.120 --> 00:18:03.030
you break in the
copies, who then

00:18:03.030 --> 00:18:04.700
pursue the design
of the subsystems

00:18:04.700 --> 00:18:06.420
and so on recursively
until you have

00:18:06.420 --> 00:18:08.900
designed an entire system
with the initial vision

00:18:08.900 --> 00:18:09.910
that you have.

00:18:09.910 --> 00:18:14.510
So ems can implement much
larger design visions coherently

00:18:14.510 --> 00:18:19.190
via this process of recursive
design and implementation.

00:18:19.190 --> 00:18:21.480
For us, once you made a
person, they're very valuable.

00:18:21.480 --> 00:18:23.640
And if you end
one, then you don't

00:18:23.640 --> 00:18:24.790
get immediate replacement.

00:18:24.790 --> 00:18:26.270
They're very
expensive investments.

00:18:26.270 --> 00:18:28.020
These are very cheap--
easy come, easy go.

00:18:30.620 --> 00:18:33.667
So we have many familiar
systems in our world,

00:18:33.667 --> 00:18:35.750
including software, which
you experience something

00:18:35.750 --> 00:18:37.930
like software rot, i.e.,
the experience that

00:18:37.930 --> 00:18:39.770
is as you slowly
adapt them in more

00:18:39.770 --> 00:18:41.720
detail to a particular
environment,

00:18:41.720 --> 00:18:45.470
they become fragile and harder
to readapt to new environments.

00:18:45.470 --> 00:18:48.300
This is true for cells
and species and products

00:18:48.300 --> 00:18:49.860
today, as well as software.

00:18:49.860 --> 00:18:51.610
It also seems to be
true of the human mind

00:18:51.610 --> 00:18:53.610
because we start out what's
called fluid intelligence

00:18:53.610 --> 00:18:56.068
and we end up with what's called
crystallized intelligence.

00:18:56.068 --> 00:18:58.090
We become fragile
mentally over time--

00:18:58.090 --> 00:19:01.577
and seems to be not
just brain degradation.

00:19:01.577 --> 00:19:03.910
It seems to be a fundamental
feature of complex systems.

00:19:03.910 --> 00:19:08.010
So I guess that, in fact,
emulations will experience

00:19:08.010 --> 00:19:09.650
becoming inflexible over time.

00:19:09.650 --> 00:19:11.370
So they have a
limited career length,

00:19:11.370 --> 00:19:12.630
after which they must retire.

00:19:12.630 --> 00:19:14.710
They might retire to an
indefinite retirement.

00:19:14.710 --> 00:19:17.001
But they still will then have
to be replaced by younger

00:19:17.001 --> 00:19:18.080
versions of themselves.

00:19:18.080 --> 00:19:20.730
So they continually
make new copies

00:19:20.730 --> 00:19:23.610
of the very first version and
train it in slightly new ways.

00:19:23.610 --> 00:19:25.270
So emulations would
see around them

00:19:25.270 --> 00:19:27.420
younger and older versions
of themselves that

00:19:27.420 --> 00:19:29.419
have a very good idea of
what their future looks

00:19:29.419 --> 00:19:31.960
like-- their future career,
their future spouse, et cetera,

00:19:31.960 --> 00:19:34.440
because there are these slightly
older versions of them around,

00:19:34.440 --> 00:19:35.690
and younger versions, as well.

00:19:38.090 --> 00:19:40.190
So this is you, again.

00:19:40.190 --> 00:19:41.510
You start and you end.

00:19:41.510 --> 00:19:43.790
Now, this could be a
diagram describing you

00:19:43.790 --> 00:19:46.620
if at the beginning
of a party, you

00:19:46.620 --> 00:19:49.680
took a drug which meant that
you will not remember that party

00:19:49.680 --> 00:19:52.536
the next day or ever again.

00:19:52.536 --> 00:19:55.036
Now, some people have done this
sort of thing, they tell me.

00:19:55.036 --> 00:19:55.990
[LAUGHTER]

00:19:55.990 --> 00:20:01.330
Not I-- never I. But the
question I have for you

00:20:01.330 --> 00:20:04.937
is toward the end of that
party, will you say to yourself,

00:20:04.937 --> 00:20:06.770
I'm a whole new creature
who's about to die?

00:20:06.770 --> 00:20:07.478
This is terrible.

00:20:07.478 --> 00:20:08.909
How did I get myself into this?

00:20:08.909 --> 00:20:10.450
You could think of
yourself that way.

00:20:10.450 --> 00:20:12.542
You could think the
moment you took this drug,

00:20:12.542 --> 00:20:14.000
you became a new
creature, you see,

00:20:14.000 --> 00:20:17.500
because your future-- this
other person won't remember you.

00:20:17.500 --> 00:20:19.750
But most of you probably
won't take that attitude.

00:20:19.750 --> 00:20:21.520
But you could.

00:20:21.520 --> 00:20:24.430
This is an emulation who splits
off a short-term copy, who

00:20:24.430 --> 00:20:25.740
then ends after a short time.

00:20:25.740 --> 00:20:26.880
It's the same structure.

00:20:26.880 --> 00:20:28.560
And they could have
the same attitudes.

00:20:28.560 --> 00:20:31.290
Either I'm a new creature, I'm
about to die, this is terrible,

00:20:31.290 --> 00:20:34.070
I'm going to have a revolution--
run away, fight, destroy.

00:20:34.070 --> 00:20:36.500
Or you could think, this is me.

00:20:36.500 --> 00:20:37.610
It's the same person.

00:20:37.610 --> 00:20:40.382
I'm another part of me that
I won't later remember.

00:20:40.382 --> 00:20:41.840
I predict this is
the attitude they

00:20:41.840 --> 00:20:44.020
will have-- not because it's
the correct attitude, because it

00:20:44.020 --> 00:20:45.400
gets along in this world.

00:20:45.400 --> 00:20:48.687
This is a very competitive
world because it's

00:20:48.687 --> 00:20:51.020
at subsistence wage and it's
really easy to make copies.

00:20:51.020 --> 00:20:54.200
In this very competitive
world, more productive habits

00:20:54.200 --> 00:20:56.770
are greatly rewarded,
i.e., more copies

00:20:56.770 --> 00:20:58.830
are made of whichever
ems can adopt

00:20:58.830 --> 00:21:00.172
the more productive habits.

00:21:00.172 --> 00:21:02.130
And this is one of the
more productive habits--

00:21:02.130 --> 00:21:04.213
being willing to make these
short-term copies that

00:21:04.213 --> 00:21:05.480
then end.

00:21:05.480 --> 00:21:06.690
There you go.

00:21:06.690 --> 00:21:09.890
Now, even though you don't mind
making a short-term copy that

00:21:09.890 --> 00:21:12.790
ends, if you interact with
other people around you

00:21:12.790 --> 00:21:15.456
and they don't know who
it is they're talking to,

00:21:15.456 --> 00:21:16.830
whether you remember
other things

00:21:16.830 --> 00:21:19.163
they said in the past-- that
gets difficult and awkward.

00:21:19.163 --> 00:21:20.720
So a simple solution
is that they

00:21:20.720 --> 00:21:23.790
tend to copy together as a
team, work together as a team,

00:21:23.790 --> 00:21:25.720
and then end and retire
together as a team.

00:21:25.720 --> 00:21:28.330
So now each one of them can have
predictable social relations

00:21:28.330 --> 00:21:30.680
with others.

00:21:30.680 --> 00:21:32.960
Today, it's hard to
meet with celebrities.

00:21:32.960 --> 00:21:34.440
Their time is rare.

00:21:34.440 --> 00:21:37.211
With ems, it turns out that
anybody can meet easily

00:21:37.211 --> 00:21:38.710
with celebrities
because all they do

00:21:38.710 --> 00:21:40.640
is spit off another copy
that meets with you.

00:21:40.640 --> 00:21:44.090
The hard thing is to get
celebrities to remember you.

00:21:44.090 --> 00:21:46.220
But we can use this feature
in the emulation world

00:21:46.220 --> 00:21:47.427
to a nice advantage.

00:21:47.427 --> 00:21:50.010
So today, if you have a leader--
say, the president-- and they

00:21:50.010 --> 00:21:52.490
say, we must invade Iraq,
and you say, why, why must we

00:21:52.490 --> 00:21:54.365
invade Iraq, and they
say, I can't tell you--

00:21:54.365 --> 00:21:56.276
state secrets--
you're kind of stuck.

00:21:56.276 --> 00:21:57.900
You don't know whether
to believe them.

00:21:57.900 --> 00:22:00.020
For emulations, they can
do the following trick.

00:22:00.020 --> 00:22:02.370
The president makes a
copy and you make a copy,

00:22:02.370 --> 00:22:03.515
and both go inside a safe.

00:22:03.515 --> 00:22:05.806
And inside the safe, they
can explain all their reasons

00:22:05.806 --> 00:22:06.690
to you.

00:22:06.690 --> 00:22:08.680
And then at the end,
you send out one bit.

00:22:08.680 --> 00:22:09.720
Was I persuaded or not?

00:22:09.720 --> 00:22:11.652
And then the entire
safe is erased.

00:22:11.652 --> 00:22:14.310
[LAUGHTER]

00:22:14.310 --> 00:22:17.200
And now you can become
persuaded of things

00:22:17.200 --> 00:22:19.860
that you don't know why.

00:22:19.860 --> 00:22:21.600
Yes, in the back?

00:22:21.600 --> 00:22:23.670
Obviously, you have to
trust the structure here.

00:22:23.670 --> 00:22:26.390
If you trust this structure to
be as safe as it claims to be,

00:22:26.390 --> 00:22:27.640
then you can trust the answer.

00:22:27.640 --> 00:22:28.790
If it's not what
it claims to be,

00:22:28.790 --> 00:22:30.020
then, of course, you
shouldn't trust it.

00:22:30.020 --> 00:22:32.311
But that's the generic answer
about just about anything

00:22:32.311 --> 00:22:34.450
you might trust.

00:22:34.450 --> 00:22:36.380
When it claims to be
something, it better

00:22:36.380 --> 00:22:38.390
be what you think it is,
or you're in trouble.

00:22:38.390 --> 00:22:39.050
Yes?

00:22:39.050 --> 00:22:41.510
How many different
clans will there be?

00:22:41.510 --> 00:22:44.070
Turns out-- I've got
slide in a minute.

00:22:44.070 --> 00:22:46.062
But the--

00:22:46.062 --> 00:22:47.520
AUDIENCE: [INAUDIBLE]

00:22:47.520 --> 00:22:49.864
ROBIN HANSON: So
all the copies that

00:22:49.864 --> 00:22:51.530
originate from the
same original human--

00:22:51.530 --> 00:22:53.680
let me call that a clan.

00:22:53.680 --> 00:22:56.050
And now the question
might be, how concentrated

00:22:56.050 --> 00:22:57.890
is the em world
in terms of clans?

00:22:57.890 --> 00:23:00.150
So there are seven billion
potential clans, i.e., all

00:23:00.150 --> 00:23:01.480
of the seven billion humans.

00:23:01.480 --> 00:23:04.040
A very equal world would
have roughly the same number

00:23:04.040 --> 00:23:05.999
of ems per human,
i.e., all the clans

00:23:05.999 --> 00:23:07.290
are roughly the very same size.

00:23:07.290 --> 00:23:09.660
A very unequal world would
be the entire em world

00:23:09.660 --> 00:23:12.570
all comes from copies of one
human-- all trillion of them

00:23:12.570 --> 00:23:13.570
are one.

00:23:13.570 --> 00:23:18.150
So my prediction is that
roughly, most emulations

00:23:18.150 --> 00:23:22.489
are come from the few
hundred most copied clans.

00:23:22.489 --> 00:23:24.030
So that's a high
degree of inequality

00:23:24.030 --> 00:23:27.330
relative to our world,
but not total inequality.

00:23:27.330 --> 00:23:31.410
The basis for that is basically
looking at the variety of jobs

00:23:31.410 --> 00:23:35.600
and saying, it doesn't seem
to be more than a few thousand

00:23:35.600 --> 00:23:38.100
distinct kinds of job skills.

00:23:38.100 --> 00:23:40.050
And I'm making a
prediction there.

00:23:40.050 --> 00:23:43.970
So basically, a few
hundred is my best guess.

00:23:43.970 --> 00:23:46.180
So I told you that I would
tell you about humans.

00:23:46.180 --> 00:23:48.270
So it turns out most
of the emulations

00:23:48.270 --> 00:23:50.700
are concentrated in a small
number of dense cities.

00:23:50.700 --> 00:23:52.908
And so humans can have most
of the rest of the earth.

00:23:52.908 --> 00:23:56.290
But the emulation cities
are kind of hostile to them.

00:23:56.290 --> 00:23:57.710
So they stay away.

00:23:57.710 --> 00:23:59.940
Humans basically have to retire.

00:23:59.940 --> 00:24:04.340
Now, i.e., pretty soon,
very quickly, humans

00:24:04.340 --> 00:24:06.350
lose their ability to
compete for wages, i.e.,

00:24:06.350 --> 00:24:09.910
the wages they could earn
couldn't make them subsist.

00:24:09.910 --> 00:24:14.610
However, humans start out
owning this entire economy.

00:24:14.610 --> 00:24:16.361
And so if the economy
doubles every month,

00:24:16.361 --> 00:24:17.734
their wealth
doubles every month.

00:24:17.734 --> 00:24:19.730
So collectively, humans
are doing very well.

00:24:19.730 --> 00:24:22.850
And they can have a very
rich, comfortable retirement.

00:24:22.850 --> 00:24:24.602
Since this era only
lasts a year or two,

00:24:24.602 --> 00:24:26.810
there's not that much cultural
change for the humans.

00:24:26.810 --> 00:24:27.760
The main thing
that happens-- they

00:24:27.760 --> 00:24:29.460
suddenly lose all their
jobs and have to retire.

00:24:29.460 --> 00:24:31.090
And then collectively,
they get rich.

00:24:31.090 --> 00:24:33.560
Now, whether any one human
has enough to survive

00:24:33.560 --> 00:24:36.490
depends on how well
humans share and insure.

00:24:36.490 --> 00:24:38.300
And my confident
prediction is since that

00:24:38.300 --> 00:24:41.058
has varied enormously across
history, it'll vary again.

00:24:41.058 --> 00:24:42.632
[LAUGHTER]

00:24:42.632 --> 00:24:43.840
Some places, they'll do well.

00:24:43.840 --> 00:24:44.986
And some places, they won't.

00:24:44.986 --> 00:24:45.800
AUDIENCE: I have a question.

00:24:45.800 --> 00:24:47.780
ROBIN HANSON: The question
is, how do ems get paid,

00:24:47.780 --> 00:24:49.262
and how do they
want to get paid?

00:24:49.262 --> 00:24:50.470
Why do they want to get paid?

00:24:50.470 --> 00:24:52.910
So this is a
subsistence economy.

00:24:52.910 --> 00:24:54.910
We have seen subsistent
economy through history.

00:24:54.910 --> 00:24:57.940
Actually, our era is
the unusual case, us.

00:24:57.940 --> 00:24:59.970
Malthusian subsistence
world is basically

00:24:59.970 --> 00:25:01.720
the world of pretty much all
animals who've ever lived

00:25:01.720 --> 00:25:03.719
and all humans who have
ever lived in the forage

00:25:03.719 --> 00:25:04.840
or in farmer eras.

00:25:04.840 --> 00:25:07.370
In a subsistence
economy, most work

00:25:07.370 --> 00:25:09.810
is producing the minimum
required to subsist.

00:25:09.810 --> 00:25:13.540
So 1,000 years ago in a
subsistence farming village,

00:25:13.540 --> 00:25:17.300
most work was done to create
food, clothes, shelter,

00:25:17.300 --> 00:25:18.670
transport the things around.

00:25:18.670 --> 00:25:20.700
That's where most of
their effort went.

00:25:20.700 --> 00:25:22.080
This is a subsistence economy.

00:25:22.080 --> 00:25:25.880
Emulations to subsist need
computers, energy, cooling,

00:25:25.880 --> 00:25:27.680
structural support,
communication lines,

00:25:27.680 --> 00:25:28.500
things like that.

00:25:28.500 --> 00:25:31.170
So most of their work goes
to produce those things.

00:25:31.170 --> 00:25:34.580
And because it's a
subsistence economy,

00:25:34.580 --> 00:25:38.480
they have to work
hard most of the time

00:25:38.480 --> 00:25:40.560
to earn enough to subsist.

00:25:40.560 --> 00:25:42.260
So why do they work?

00:25:42.260 --> 00:25:45.320
Because if they don't,
they don't exist,

00:25:45.320 --> 00:25:47.560
which is pretty much
why all humans ever

00:25:47.560 --> 00:25:48.770
worked through history.

00:25:48.770 --> 00:25:50.500
AUDIENCE: [INAUDIBLE]
created those rules

00:25:50.500 --> 00:25:52.107
for the ems [INAUDIBLE]?

00:25:52.107 --> 00:25:53.440
ROBIN HANSON: This is not rules.

00:25:53.440 --> 00:25:55.070
This is applying economics.

00:25:55.070 --> 00:25:58.880
So standard economics applies
to ancient farming societies

00:25:58.880 --> 00:25:59.690
or the future.

00:25:59.690 --> 00:26:02.620
And so it's a fact of the
world that because there's

00:26:02.620 --> 00:26:04.640
so much labor, the
marginal product of labor

00:26:04.640 --> 00:26:06.350
has fallen to a very
low level, which

00:26:06.350 --> 00:26:09.510
means wages are low
and not much higher

00:26:09.510 --> 00:26:12.050
than subsistence, which means
they have to work to survive.

00:26:12.050 --> 00:26:12.841
There's not a rule.

00:26:12.841 --> 00:26:14.640
It's not a political
ruling or a decision.

00:26:14.640 --> 00:26:16.650
It's just the fact of the world.

00:26:16.650 --> 00:26:21.090
There's plenty of labor,
and it's hard to exist.

00:26:21.090 --> 00:26:25.690
It's a economy of poverty, if
you like, in a certain sense,

00:26:25.690 --> 00:26:27.255
but not necessarily slavery.

00:26:27.255 --> 00:26:31.210
AUDIENCE: If the ems don't
work, can we turn them off?

00:26:31.210 --> 00:26:34.070
ROBIN HANSON: 1,000 years ago,
if you did not work to farm,

00:26:34.070 --> 00:26:34.820
you died.

00:26:34.820 --> 00:26:35.940
There was no rule.

00:26:35.940 --> 00:26:36.980
There was no ruling.

00:26:36.980 --> 00:26:39.130
Nobody had to tell you
that or decide it for you.

00:26:39.130 --> 00:26:40.690
It's just physics.

00:26:40.690 --> 00:26:45.004
You don't have enough to
buy your basic subsistence,

00:26:45.004 --> 00:26:45.670
you don't exist.

00:26:45.670 --> 00:26:47.240
So it's not a rule.

00:26:47.240 --> 00:26:50.320
AUDIENCE: So physics would
turn off the computers?

00:26:50.320 --> 00:26:52.200
ROBIN HANSON: For
example, the computers

00:26:52.200 --> 00:26:54.747
will sit in large racks
of computer hardware.

00:26:54.747 --> 00:26:56.330
And you'll have to
rent space on them.

00:26:56.330 --> 00:26:58.663
And if you can't pay your
rental fee, you'll be evicted.

00:26:58.663 --> 00:27:01.370
So the question is, what does
the pie chart of the economy

00:27:01.370 --> 00:27:01.870
look like?

00:27:01.870 --> 00:27:03.950
Where is most of the
effort happening?

00:27:03.950 --> 00:27:06.484
So first of all, one
level-- most jobs

00:27:06.484 --> 00:27:07.900
are still going
to be office jobs.

00:27:07.900 --> 00:27:10.220
That's the nature of a
complicated economy like ours.

00:27:10.220 --> 00:27:12.357
So most of them are
working in offices in terms

00:27:12.357 --> 00:27:13.440
of the jobs they're doing.

00:27:13.440 --> 00:27:15.790
But in terms of the
industries, the industries

00:27:15.790 --> 00:27:19.830
are mainly producing computer
hardware, cooling, energy,

00:27:19.830 --> 00:27:23.560
structural support, real
estate, communication--

00:27:23.560 --> 00:27:25.120
the minimum required to exist.

00:27:25.120 --> 00:27:27.547
That's where most of
the money is going.

00:27:27.547 --> 00:27:29.630
But of course, there's
innovation in those things.

00:27:29.630 --> 00:27:30.727
There's marketing.

00:27:30.727 --> 00:27:33.310
There's all sorts of things that
happen in an advanced economy

00:27:33.310 --> 00:27:34.676
to support all those things.

00:27:34.676 --> 00:27:36.550
So there's still a large,
complicated economy

00:27:36.550 --> 00:27:39.090
with large, complicated
firms and layers

00:27:39.090 --> 00:27:42.080
of middle management
and all those things.

00:27:42.080 --> 00:27:43.260
But yes.

00:27:43.260 --> 00:27:45.660
The question is, how do we
know economics works anywhere

00:27:45.660 --> 00:27:51.140
besides a few miles around
this building or a few years

00:27:51.140 --> 00:27:52.670
around our current era?

00:27:52.670 --> 00:27:54.339
Isn't this all
just curve-fitting

00:27:54.339 --> 00:27:56.380
in the actual world we
live in, and so it doesn't

00:27:56.380 --> 00:27:57.490
apply to much of anything else?

00:27:57.490 --> 00:27:58.090
No.

00:27:58.090 --> 00:28:00.230
So first of all, I'd
say, no, economics

00:28:00.230 --> 00:28:04.390
is a robust, general
field of knowledge that

00:28:04.390 --> 00:28:06.150
applies not just around here.

00:28:06.150 --> 00:28:07.579
It applies over
the entire globe.

00:28:07.579 --> 00:28:10.120
We have decent economic models
of a great many very different

00:28:10.120 --> 00:28:11.110
societies today.

00:28:11.110 --> 00:28:13.660
We have economic history, which
applies standard economics

00:28:13.660 --> 00:28:16.860
to eras quite differently
in the past thousands,

00:28:16.860 --> 00:28:18.062
tens of thousands years ago.

00:28:18.062 --> 00:28:19.770
Economists studied
those sorts of things.

00:28:19.770 --> 00:28:21.990
And we have an
integrated social science

00:28:21.990 --> 00:28:25.390
where we understand a great many
things besides the world we now

00:28:25.390 --> 00:28:25.890
live in.

00:28:25.890 --> 00:28:29.500
And so if social science
exists, as I said,

00:28:29.500 --> 00:28:31.800
then it exists at a
degree of generality such

00:28:31.800 --> 00:28:33.280
that we can start to talk about.

00:28:33.280 --> 00:28:35.363
Now, of course, we'll
probably make some mistakes.

00:28:35.363 --> 00:28:38.259
But if you were applying
chemistry or computer science

00:28:38.259 --> 00:28:40.800
or other things to the future,
you'd also make some mistakes.

00:28:40.800 --> 00:28:41.130
Yes?

00:28:41.130 --> 00:28:43.380
AUDIENCE: So if you're saying
that humans would retire

00:28:43.380 --> 00:28:47.040
into relative
richness, then who'd

00:28:47.040 --> 00:28:51.588
be creating the food and
items that these humans need

00:28:51.588 --> 00:28:52.460
[INAUDIBLE]?

00:28:52.460 --> 00:28:53.668
ROBIN HANSON: The emulations.

00:28:53.668 --> 00:28:55.650
So humans become
the rich capitalists

00:28:55.650 --> 00:28:58.160
of this world, at
least some of them.

00:28:58.160 --> 00:28:59.940
And so with their
capital, they can

00:28:59.940 --> 00:29:03.470
spend it to acquire things
they want from the emulation.

00:29:03.470 --> 00:29:06.600
So some of the emulations
spend their time

00:29:06.600 --> 00:29:11.420
doing whatever it is the humans
want-- sweeping their floors,

00:29:11.420 --> 00:29:14.630
growing their food, et cetera,
because the rich capitalists

00:29:14.630 --> 00:29:16.260
have money to spend.

00:29:16.260 --> 00:29:20.560
The question is, when you have
a few rich capitalists and lots

00:29:20.560 --> 00:29:22.900
of poorer people, doesn't
that mean revolution

00:29:22.900 --> 00:29:26.070
unless something better happens?

00:29:26.070 --> 00:29:28.680
And no, it doesn't, actually.

00:29:28.680 --> 00:29:32.600
Historically, we have a vast
history of ancient societies.

00:29:32.600 --> 00:29:36.230
And revolution was really
rare in ancient societies.

00:29:36.230 --> 00:29:38.690
Revolution isn't actually that
much correlated with people

00:29:38.690 --> 00:29:41.894
being unhappy, per se,
in terms of objective.

00:29:41.894 --> 00:29:43.560
Often, revolutions
actually had happened

00:29:43.560 --> 00:29:46.532
when people were getting richer
and then got more ambitious--

00:29:46.532 --> 00:29:47.240
what they wanted.

00:29:47.240 --> 00:29:49.480
So revolution is
certainly a possibility.

00:29:49.480 --> 00:29:53.000
But it isn't necessarily derived
from the fact of a subsistence

00:29:53.000 --> 00:29:56.900
economy because again, we have
a long history of thousands

00:29:56.900 --> 00:29:58.640
of years of subsistence
farming economies

00:29:58.640 --> 00:30:01.970
where revolutions
were quite rare.

00:30:01.970 --> 00:30:03.440
When there was
famine, of course,

00:30:03.440 --> 00:30:04.924
there was often a
social breakdown.

00:30:04.924 --> 00:30:06.840
And whether you want to
call that revolution--

00:30:06.840 --> 00:30:09.180
there was often a lot of
rioting and things like that

00:30:09.180 --> 00:30:10.380
when there was famine.

00:30:10.380 --> 00:30:11.880
And so that was
often a reason why

00:30:11.880 --> 00:30:15.600
governments made sure to
save up food against famine.

00:30:15.600 --> 00:30:18.190
But revolution is
hardly inevitable.

00:30:18.190 --> 00:30:22.650
Nevertheless, you could
ask, why won't they revolt?

00:30:22.650 --> 00:30:25.230
And the question
is, what can you do?

00:30:25.230 --> 00:30:27.670
Again, and in societies
where there is a high degree

00:30:27.670 --> 00:30:30.829
of-- there's a few rich people
against a lot of poor people,

00:30:30.829 --> 00:30:32.870
sometimes there's a thing
you could do to revolt.

00:30:32.870 --> 00:30:35.440
And sometimes, there just isn't.

00:30:35.440 --> 00:30:38.240
AUDIENCE: I think another reason
not to expect a revolution--

00:30:38.240 --> 00:30:41.240
if I was in this world, I'd
probably get myself copied,

00:30:41.240 --> 00:30:44.547
have one copy of myself, take
all my vast amounts of capital,

00:30:44.547 --> 00:30:46.630
and spend it enjoying
myself in the virtual world.

00:30:46.630 --> 00:30:48.710
And so there'd be a
handful of ems like me

00:30:48.710 --> 00:30:50.660
for whom there are
only a very few copies

00:30:50.660 --> 00:30:53.030
and who spend all their
money on these few copies.

00:30:53.030 --> 00:30:54.240
And then there'd be a
small number of people--

00:30:54.240 --> 00:30:55.781
and I know I fancy
a life where there

00:30:55.781 --> 00:30:58.730
are millions of copies of me
and I can get all this money

00:30:58.730 --> 00:31:00.210
collectively from the clan.

00:31:00.210 --> 00:31:02.283
And so nearly everybody
will be copying

00:31:02.283 --> 00:31:04.080
these few people
who are basically

00:31:04.080 --> 00:31:05.622
OK with this way
of doing things.

00:31:05.622 --> 00:31:08.080
ROBIN HANSON: So I have some
slides that are on inequality.

00:31:08.080 --> 00:31:09.579
But there's two
very different kinds

00:31:09.579 --> 00:31:12.460
of inequality in this world.

00:31:12.460 --> 00:31:15.930
Humans versus ems-- humans
are individually very rich.

00:31:15.930 --> 00:31:18.340
So there's these definite
humans as the rich capitalists.

00:31:18.340 --> 00:31:21.120
And so humans are vulnerable
there in many ways.

00:31:21.120 --> 00:31:25.100
Among the ems, rich clans are
ones who have more copies.

00:31:25.100 --> 00:31:27.960
But individually, they
don't have higher income--

00:31:27.960 --> 00:31:29.190
so successful clan.

00:31:29.190 --> 00:31:33.730
So in our world, we've had
often envy of rich families

00:31:33.730 --> 00:31:35.040
within a nation.

00:31:35.040 --> 00:31:37.770
But we don't usually envy them
for the number of descendants

00:31:37.770 --> 00:31:39.420
they've had relative
to some ancestors.

00:31:39.420 --> 00:31:42.390
We usually envy them for their
individual income or wealth.

00:31:42.390 --> 00:31:45.470
And in this world,
the successful ems

00:31:45.470 --> 00:31:47.840
don't necessarily have
higher individual income.

00:31:47.840 --> 00:31:50.977
What they have is a larger
success of having more copies.

00:31:50.977 --> 00:31:52.810
And that's not something
we actually usually

00:31:52.810 --> 00:31:53.840
are envious about in our world.

00:31:53.840 --> 00:31:54.410
Yes?

00:31:54.410 --> 00:31:58.290
AUDIENCE: In your model,
do the ems have bodies?

00:31:58.290 --> 00:32:01.240
ROBIN HANSON: I'd say I'm
guessing roughly 20% of jobs

00:32:01.240 --> 00:32:04.310
need a direct physical
representation to do the job--

00:32:04.310 --> 00:32:07.200
drivers, factory managers,
miners, things like that.

00:32:07.200 --> 00:32:08.300
For-- say again?

00:32:08.300 --> 00:32:09.050
AUDIENCE: Farmers.

00:32:09.050 --> 00:32:09.710
ROBIN HANSON: Farmers.

00:32:09.710 --> 00:32:11.190
So for emulations
who are directly

00:32:11.190 --> 00:32:13.080
dealing with the physical
world, they will need a body.

00:32:13.080 --> 00:32:15.050
And it will need to be a body
appropriate for that job.

00:32:15.050 --> 00:32:17.280
Now, we already know that, say,
when somebody drives a steam

00:32:17.280 --> 00:32:18.810
shovel, they drive it
in a mental mode, where

00:32:18.810 --> 00:32:20.850
they see that seam shovel
as part of their body.

00:32:20.850 --> 00:32:22.780
So we know we are
capable of dealing

00:32:22.780 --> 00:32:25.661
with a wide range of bodies as
something we're acting through.

00:32:25.661 --> 00:32:27.410
But still, they would
have whatever bodies

00:32:27.410 --> 00:32:28.576
are appropriate for the job.

00:32:28.576 --> 00:32:30.709
Once these work day
is over, most likely,

00:32:30.709 --> 00:32:32.750
they spend their leisure
time in virtual reality.

00:32:32.750 --> 00:32:34.060
It's just much nicer.

00:32:34.060 --> 00:32:36.050
And the people who have
desk jobs-- they're

00:32:36.050 --> 00:32:38.100
pretty much going to be
in virtual reality, too,

00:32:38.100 --> 00:32:39.079
during their desk jobs.

00:32:39.079 --> 00:32:40.120
Question in the far back?

00:32:40.120 --> 00:32:40.745
AUDIENCE: Yeah.

00:32:40.745 --> 00:32:42.200
It seems like [INAUDIBLE].

00:32:42.200 --> 00:32:45.150
ROBIN HANSON: During the farming
era from roughly 7,000 years

00:32:45.150 --> 00:32:47.646
ago until 200 years
ago, most people

00:32:47.646 --> 00:32:49.270
lived near subsistence
level, even when

00:32:49.270 --> 00:32:51.424
there was lots of trade.

00:32:51.424 --> 00:32:52.840
The Industrial
Revolution has been

00:32:52.840 --> 00:32:56.340
able to produce wealth so
fast that it can grow faster

00:32:56.340 --> 00:32:59.150
than the population, which is
why we have increasing wealth

00:32:59.150 --> 00:33:01.040
or income per person today.

00:33:01.040 --> 00:33:02.941
That's because we can
grow wealth faster,

00:33:02.941 --> 00:33:05.190
but it's also fundamental
because we don't grow people

00:33:05.190 --> 00:33:06.160
faster.

00:33:06.160 --> 00:33:08.890
You can grow the
ems really fast.

00:33:08.890 --> 00:33:11.710
So even if wealth can grow
much faster than our world,

00:33:11.710 --> 00:33:14.920
since you can grow the ems
even faster, the wealth per em

00:33:14.920 --> 00:33:15.620
still falls.

00:33:15.620 --> 00:33:17.050
The income per em
still falls even

00:33:17.050 --> 00:33:19.675
though they have a lot to trade
and they're collectively a very

00:33:19.675 --> 00:33:21.490
rich, productive society.

00:33:21.490 --> 00:33:24.740
The question is, are we
copying the entire brain

00:33:24.740 --> 00:33:26.560
when we emulate, or
just a part of it

00:33:26.560 --> 00:33:28.840
so that are we getting
emotions coming along?

00:33:28.840 --> 00:33:31.543
And yes, the answer is
the simple assumption

00:33:31.543 --> 00:33:33.160
at the beginning is
just a black box.

00:33:33.160 --> 00:33:34.210
We copy it entirely.

00:33:34.210 --> 00:33:36.210
It has all of the
features the original has.

00:33:36.210 --> 00:33:37.622
We don't get to pick and choose.

00:33:37.622 --> 00:33:39.760
And so yes, it has all
of the emotions and all

00:33:39.760 --> 00:33:42.640
of the mental styles--
creativity, getting mad,

00:33:42.640 --> 00:33:44.567
everything, falling in love.

00:33:44.567 --> 00:33:46.400
So all of those things
are in the emulation.

00:33:46.400 --> 00:33:50.250
They have all of those
desires and habits and styles,

00:33:50.250 --> 00:33:51.900
which is why we can
reason about it.

00:33:51.900 --> 00:33:54.810
It makes it a scenario of the
future that is easier to reason

00:33:54.810 --> 00:33:56.660
about exactly because of that.

00:33:56.660 --> 00:33:58.880
Humans retire basically.

00:33:58.880 --> 00:34:02.790
And whether they do well
depends on how well they share.

00:34:02.790 --> 00:34:04.970
All emulations started
out from humans.

00:34:04.970 --> 00:34:08.940
And so they are within the
range of human mental styles,

00:34:08.940 --> 00:34:11.250
but they are not typical humans.

00:34:11.250 --> 00:34:12.980
So if we think of,
say, hardworking

00:34:12.980 --> 00:34:15.860
and smart as characteristics,
the red dots are the people

00:34:15.860 --> 00:34:18.219
and the dots up above the
line are the emulations,

00:34:18.219 --> 00:34:19.750
i.e., they are
selected for being

00:34:19.750 --> 00:34:22.989
the best on a lot
of characteristics,

00:34:22.989 --> 00:34:26.070
which again, I estimate
roughly a few hundred humans--

00:34:26.070 --> 00:34:28.310
copies of them dominate
this whole world.

00:34:28.310 --> 00:34:32.270
That makes emulations-- the
typical emulation is as elite

00:34:32.270 --> 00:34:34.880
compared to the typical human
as the typical Nobel Prize

00:34:34.880 --> 00:34:36.982
winner, head of state,
billionaire, Olympic gold

00:34:36.982 --> 00:34:38.190
medalist, that sort of thing.

00:34:38.190 --> 00:34:40.509
They are all that good.

00:34:40.509 --> 00:34:43.050
We know a lot of things about
how more productive people vary

00:34:43.050 --> 00:34:43.675
in our society.

00:34:43.675 --> 00:34:45.110
So I just use those to predict.

00:34:45.110 --> 00:34:47.480
On average, emulations will
be smart, conscientious,

00:34:47.480 --> 00:34:51.830
hardworking, workaholic,
get up early in the morning.

00:34:51.830 --> 00:34:53.699
They'll be near a peak
age of productivity.

00:34:53.699 --> 00:34:55.487
Today, for us, that's
about 40 or 50.

00:34:55.487 --> 00:34:56.820
For them, it might be a century.

00:34:56.820 --> 00:34:58.320
But whatever it is,
most of them are

00:34:58.320 --> 00:35:01.550
near a peak subjective age--
probably also on average

00:35:01.550 --> 00:35:04.030
be married, religious
because that correlates

00:35:04.030 --> 00:35:05.260
with productivity today.

00:35:07.790 --> 00:35:10.370
Emulations-- when they're
in virtual reality,

00:35:10.370 --> 00:35:13.760
they never need to feel pain
or hunger or grime or disease.

00:35:13.760 --> 00:35:15.581
Their bodies are
always beautiful.

00:35:15.581 --> 00:35:18.080
It's very cheap to give them
luxurious surroundings compared

00:35:18.080 --> 00:35:19.746
to just the cost of
running their brain.

00:35:19.746 --> 00:35:22.070
So they have beautiful,
luxurious worlds.

00:35:22.070 --> 00:35:23.280
But these are desks.

00:35:23.280 --> 00:35:24.816
They're working
most of the time.

00:35:24.816 --> 00:35:26.864
[LAUGHTER]

00:35:26.864 --> 00:35:28.280
But when they have
free time, they

00:35:28.280 --> 00:35:29.821
can have spectacular
virtual reality.

00:35:29.821 --> 00:35:32.620
And the economy is large
enough to really develop

00:35:32.620 --> 00:35:34.810
fantastic stories, music,
art, things like that.

00:35:37.350 --> 00:35:40.517
Some of you when you
were kids saw the people

00:35:40.517 --> 00:35:42.600
around you weren't like
you and you thought, maybe

00:35:42.600 --> 00:35:44.120
I'm an alien from
some other planet

00:35:44.120 --> 00:35:46.630
and someday I'll meet the
people from my planet,

00:35:46.630 --> 00:35:49.050
and then I'll find
people who are like me.

00:35:49.050 --> 00:35:52.330
This is literally true
for the emulations

00:35:52.330 --> 00:35:55.360
because they all come
from a clan of people

00:35:55.360 --> 00:35:59.050
very much like them who all
originated from the same human.

00:35:59.050 --> 00:36:01.289
Probably, most work teams
won't have that many copies

00:36:01.289 --> 00:36:02.080
from the same clan.

00:36:02.080 --> 00:36:04.950
But each of them will be able
to consult with this clan

00:36:04.950 --> 00:36:06.900
to give them on-the-site
advice about things

00:36:06.900 --> 00:36:09.037
and to compare their
lives with many others

00:36:09.037 --> 00:36:10.120
to tell them about things.

00:36:10.120 --> 00:36:12.750
So they will have this new
unit of social organization

00:36:12.750 --> 00:36:16.610
that will be used for
finance and politics and law.

00:36:16.610 --> 00:36:19.530
And it's a very tempting unit
because you have more in common

00:36:19.530 --> 00:36:23.430
with this than you might
with a identical twin.

00:36:23.430 --> 00:36:26.180
They are that close.

00:36:26.180 --> 00:36:28.740
The most traumatic thing I
think ever happened to humans

00:36:28.740 --> 00:36:32.540
was the transition from
foraging to farming.

00:36:32.540 --> 00:36:36.090
Foragers were well in tune
with their environment.

00:36:36.090 --> 00:36:38.150
Their mental habits
and their styles

00:36:38.150 --> 00:36:39.760
and what came
natural to them fit

00:36:39.760 --> 00:36:41.490
well with the world
they lived in.

00:36:41.490 --> 00:36:43.710
When farming became
possible, it required

00:36:43.710 --> 00:36:47.550
people adopt somewhat alien
mental styles and behaviors.

00:36:47.550 --> 00:36:48.540
They no longer foraged.

00:36:48.540 --> 00:36:49.910
They stay in one place.

00:36:49.910 --> 00:36:50.770
They now have war.

00:36:50.770 --> 00:36:51.728
They now have marriage.

00:36:51.728 --> 00:36:53.570
They now have property
and more inequality.

00:36:53.570 --> 00:36:57.240
And this was hard to
get people to accept.

00:36:57.240 --> 00:37:00.700
But the farming-- humans have
enough cultural plasticity

00:37:00.700 --> 00:37:04.390
to create religions and
conformity pressures such

00:37:04.390 --> 00:37:06.840
as we were able-- those
who were able to make

00:37:06.840 --> 00:37:08.740
humans become farmers.

00:37:08.740 --> 00:37:12.700
And this distinction
between the forger lifestyle

00:37:12.700 --> 00:37:14.450
and mental style from
the farmer lifestyle

00:37:14.450 --> 00:37:17.120
actually maps somewhat
plausibly onto a roughly liberal

00:37:17.120 --> 00:37:20.070
conservative dimension
in our society today.

00:37:20.070 --> 00:37:25.161
And so originally, say, foragers
were relatively liberal.

00:37:25.161 --> 00:37:26.660
Farmers are relatively
conservative.

00:37:26.660 --> 00:37:29.010
In the last few hundred
years as we've gotten rich,

00:37:29.010 --> 00:37:31.740
plausibly what's
happened is the pressures

00:37:31.740 --> 00:37:35.600
that make farmers into
farmers feel less compelling.

00:37:35.600 --> 00:37:38.020
And we've drifted more
toward liberal or forager

00:37:38.020 --> 00:37:41.050
mental styles or habits.

00:37:41.050 --> 00:37:42.870
We're more horrified by slavery.

00:37:42.870 --> 00:37:47.170
We're more into democracy, into
leisure, more into promiscuity,

00:37:47.170 --> 00:37:48.900
more into art, travel.

00:37:48.900 --> 00:37:51.160
These are forager styles.

00:37:51.160 --> 00:37:53.560
And so many people
are proud of this.

00:37:53.560 --> 00:37:56.710
And they see the future
continuing in this direction

00:37:56.710 --> 00:37:58.930
as we get individually richer.

00:37:58.930 --> 00:38:01.900
My prediction here, though,
is that while for the humans

00:38:01.900 --> 00:38:03.780
this continues to be
true, for the ems,

00:38:03.780 --> 00:38:07.420
it's not because they go back
to a subsistence income level

00:38:07.420 --> 00:38:10.590
and a poor world
where the culture does

00:38:10.590 --> 00:38:12.480
need to apply pressure
to get them to act

00:38:12.480 --> 00:38:15.000
in ways that seem strange.

00:38:15.000 --> 00:38:17.480
The farmer-like
cultural pressures,

00:38:17.480 --> 00:38:19.980
the conservative pressures,
will have a resurgence

00:38:19.980 --> 00:38:21.740
because they have a need for it.

00:38:25.660 --> 00:38:27.138
This is your life.

00:38:27.138 --> 00:38:28.560
[LAUGHTER]

00:38:28.560 --> 00:38:30.980
You train and then you
work and then you retire--

00:38:30.980 --> 00:38:32.700
three main phases of your life.

00:38:32.700 --> 00:38:34.380
Emulations have
those same phases.

00:38:34.380 --> 00:38:37.740
But it's emphasized work.

00:38:37.740 --> 00:38:40.820
So they can have a small number
of copies who are trained,

00:38:40.820 --> 00:38:43.020
and then make many
copies of those to work.

00:38:43.020 --> 00:38:44.990
So they can lavish
a lot of expense

00:38:44.990 --> 00:38:48.050
on very high-quality training.

00:38:48.050 --> 00:38:51.520
And then when they retire, they
can retire at a slower speed.

00:38:51.520 --> 00:38:54.070
So there's roughly a
linear relationship

00:38:54.070 --> 00:38:55.560
between speed and cost.

00:38:55.560 --> 00:38:57.740
So if you want an emulation
that runs twice as fast,

00:38:57.740 --> 00:39:00.650
it'll cost you twice
as much per minute.

00:39:00.650 --> 00:39:03.610
So it has about the same
cost per subjective minute.

00:39:03.610 --> 00:39:05.779
This means if you're not
rich when you retire,

00:39:05.779 --> 00:39:06.570
it's not a problem.

00:39:06.570 --> 00:39:09.775
You just retire slow.

00:39:09.775 --> 00:39:11.400
And now the world
speeds up around you.

00:39:11.400 --> 00:39:13.772
And now humans and em
retirees have a common cause

00:39:13.772 --> 00:39:15.480
in wanting the
civilization to be stable,

00:39:15.480 --> 00:39:18.370
because otherwise, it doesn't
last-- for them, at least.

00:39:18.370 --> 00:39:20.620
If you want a long, stable
retirement and you're slow,

00:39:20.620 --> 00:39:21.840
you need the
civilization to last

00:39:21.840 --> 00:39:24.250
a very long time relative to
the speed of those things.

00:39:24.250 --> 00:39:24.900
Yes?

00:39:24.900 --> 00:39:27.150
AUDIENCE: Is that keeping
a process in memory

00:39:27.150 --> 00:39:29.520
if it's not running can
actually be pretty expensive?

00:39:29.520 --> 00:39:30.561
ROBIN HANSON: Absolutely.

00:39:30.561 --> 00:39:34.120
So actually, this
linear range over which

00:39:34.120 --> 00:39:37.370
you can run twice as fast
and it costs twice as much,

00:39:37.370 --> 00:39:39.340
the high end of that
range is set roughly

00:39:39.340 --> 00:39:41.250
at the fastest device speeds.

00:39:41.250 --> 00:39:42.930
But the low end of
that range is set

00:39:42.930 --> 00:39:44.700
by roughly the ratio
of the cost of just

00:39:44.700 --> 00:39:48.160
an archived copy versus the cost
of running a human-speed copy.

00:39:48.160 --> 00:39:51.210
I estimate that to
be roughly a billion.

00:39:51.210 --> 00:39:53.610
So you can probably go down
to a billion times slower

00:39:53.610 --> 00:39:55.990
than human speed before you
run into these two costs

00:39:55.990 --> 00:39:56.864
being about the same.

00:39:56.864 --> 00:39:58.730
So at human speed,
the cost of running

00:39:58.730 --> 00:40:00.690
a human versus
archiving that copy

00:40:00.690 --> 00:40:02.500
is roughly a factor
of a billion,

00:40:02.500 --> 00:40:04.080
which means you
can easily spin off

00:40:04.080 --> 00:40:08.990
archive copies every few minutes
at a relatively low cost,

00:40:08.990 --> 00:40:11.450
at least if you're putting
them in very low-cost archive

00:40:11.450 --> 00:40:12.570
memory.

00:40:12.570 --> 00:40:14.930
That's my rough estimate.

00:40:14.930 --> 00:40:17.740
They can have a huge
range of motivations.

00:40:17.740 --> 00:40:19.770
The world is just
defined by the people

00:40:19.770 --> 00:40:21.860
who have both the ability
and the motivation such

00:40:21.860 --> 00:40:24.160
that they do the
things the world needs.

00:40:24.160 --> 00:40:27.000
So if motivation is
a high constraint,

00:40:27.000 --> 00:40:30.535
then there'll be a trade
between ability and motivation.

00:40:30.535 --> 00:40:33.160
The emulations are those who are
not only able to function well

00:40:33.160 --> 00:40:34.701
in the emulation
world, they are ones

00:40:34.701 --> 00:40:36.824
who have a motivation
such that they do function

00:40:36.824 --> 00:40:38.990
in the emulation world,
i.e., they show up for work,

00:40:38.990 --> 00:40:41.025
they do their job, they're
willing to split off

00:40:41.025 --> 00:40:42.275
[INAUDIBLE] copies, et cetera.

00:40:42.275 --> 00:40:45.170
They do the things
this world needs.

00:40:45.170 --> 00:40:48.290
I already know many people who
are very capable people who

00:40:48.290 --> 00:40:51.990
are workaholics, and I think
who would do fine in this world.

00:40:51.990 --> 00:40:53.780
So I don't see it as a problem.

00:40:53.780 --> 00:40:55.730
I see lots of
candidates-- people

00:40:55.730 --> 00:40:58.566
who would be happy to try
to succeed in this world.

00:40:58.566 --> 00:41:01.470
AUDIENCE: If we had
these 100 copies who

00:41:01.470 --> 00:41:05.720
work very efficiently,
generate a lot of wealth,

00:41:05.720 --> 00:41:09.640
after some time, how
do we replace them,

00:41:09.640 --> 00:41:12.430
because if they
work so efficiently

00:41:12.430 --> 00:41:16.150
and people just have everything
they need, why should they

00:41:16.150 --> 00:41:19.630
work-- is should think about
getting better because there

00:41:19.630 --> 00:41:24.720
are a lot of people in now,
real world, this current world,

00:41:24.720 --> 00:41:28.130
which actually become
better, become the best,

00:41:28.130 --> 00:41:32.070
just because there are
a lot of competition.

00:41:32.070 --> 00:41:34.076
ROBIN HANSON: So
the question is--

00:41:34.076 --> 00:41:34.950
SPEAKER: Use the mic.

00:41:34.950 --> 00:41:36.680
ROBIN HANSON: Right.

00:41:36.680 --> 00:41:39.360
Why do they work if
they're so productive?

00:41:39.360 --> 00:41:40.860
If they're so
productive, don't they

00:41:40.860 --> 00:41:43.510
make so much that they
don't need to work anymore

00:41:43.510 --> 00:41:46.980
because they are so very good?

00:41:46.980 --> 00:41:50.280
1,000 years ago,
subsistence human farmers

00:41:50.280 --> 00:41:52.760
were a pinnacle of productivity
relative to the rest

00:41:52.760 --> 00:41:54.430
of the animal world.

00:41:54.430 --> 00:41:57.250
Nevertheless, they were still
living at a subsistence level.

00:41:57.250 --> 00:42:00.090
So pretty much all animals
who have ever lived

00:42:00.090 --> 00:42:02.610
have lived at a subsistence
level, even though most of them

00:42:02.610 --> 00:42:03.320
go extinct.

00:42:03.320 --> 00:42:05.030
So the few who
continue to remain

00:42:05.030 --> 00:42:06.720
are at a pinnacle
of productivity

00:42:06.720 --> 00:42:08.370
relative to the
others who go extinct.

00:42:08.370 --> 00:42:11.447
Nevertheless, in a typical
animal world, most of them

00:42:11.447 --> 00:42:12.780
are living at subsistence level.

00:42:12.780 --> 00:42:14.738
And that's been true for
most of human history.

00:42:14.738 --> 00:42:17.140
So it's quite possible
for there to be

00:42:17.140 --> 00:42:20.710
a world of the most productive
and have them still be living

00:42:20.710 --> 00:42:23.220
at a subsistence level because
there are so many of them

00:42:23.220 --> 00:42:26.240
relative to the
environment resources.

00:42:26.240 --> 00:42:29.150
So a very large population
of very productive people

00:42:29.150 --> 00:42:32.060
can still have a
low income because

00:42:32.060 --> 00:42:35.280
the marginal productivity is
low because there are so many.

00:42:35.280 --> 00:42:37.766
AUDIENCE: Does this not
assume a zero sum game?

00:42:37.766 --> 00:42:40.770
Ems could stop creating so
many copies of them such

00:42:40.770 --> 00:42:43.680
that the few that remain
live very comfortably

00:42:43.680 --> 00:42:45.290
in the same way that
we no longer have

00:42:45.290 --> 00:42:47.070
to work 16-hour days?

00:42:47.070 --> 00:42:48.080
We only work eight.

00:42:48.080 --> 00:42:50.250
ROBIN HANSON: That was been true
through the entire farming era.

00:42:50.250 --> 00:42:52.172
Through all 10,000 years
of the farming era,

00:42:52.172 --> 00:42:54.130
if only people who could
get together and agree

00:42:54.130 --> 00:42:56.950
not to have so many kids,
then a few generations later,

00:42:56.950 --> 00:42:58.492
they could all live
more comfortably.

00:42:58.492 --> 00:42:59.950
Right after the
Black Death, that's

00:42:59.950 --> 00:43:01.430
exactly what did
happen in Europe.

00:43:01.430 --> 00:43:02.513
The Black Death showed up.

00:43:02.513 --> 00:43:03.906
Half the population died off.

00:43:03.906 --> 00:43:05.280
And for the next
few generations,

00:43:05.280 --> 00:43:07.220
people lived pretty
well because there

00:43:07.220 --> 00:43:09.636
was the same amount of land
and other capital, a lot fewer

00:43:09.636 --> 00:43:10.970
workers, wages went up.

00:43:10.970 --> 00:43:12.420
But within a few
generations, they

00:43:12.420 --> 00:43:13.660
did not make that coordination.

00:43:13.660 --> 00:43:15.620
They did not prevent the
population from rising.

00:43:15.620 --> 00:43:17.411
And so wages fell back
to subsistence level

00:43:17.411 --> 00:43:20.460
within a century of the
Black Death in 1350.

00:43:20.460 --> 00:43:23.390
AUDIENCE: So in this
world, how are humans

00:43:23.390 --> 00:43:27.000
getting access to any percentage
of the wealth generated

00:43:27.000 --> 00:43:27.570
by the ems?

00:43:30.210 --> 00:43:35.020
ROBIN HANSON: So in our
world, we have retirees.

00:43:35.020 --> 00:43:38.250
Retirees don't work
for the rest of us.

00:43:38.250 --> 00:43:39.760
They're sponging
off the rest of us.

00:43:39.760 --> 00:43:40.850
They're parasites.

00:43:40.850 --> 00:43:43.695
We could say to ourselves,
let's go kill all the retirees

00:43:43.695 --> 00:43:44.570
and take their stuff.

00:43:44.570 --> 00:43:45.980
What are they doing for us?

00:43:45.980 --> 00:43:47.360
But we don't.

00:43:47.360 --> 00:43:49.920
We so far mostly let
retirees continue

00:43:49.920 --> 00:43:54.440
to exist, spending their income
that they earned earlier.

00:43:54.440 --> 00:43:57.560
And humans can hope that
that happens to them.

00:43:57.560 --> 00:43:59.900
Humans can hope to be the
retirees of the emulation

00:43:59.900 --> 00:44:00.810
world.

00:44:00.810 --> 00:44:05.090
Now, there's a better chance
for that if they are integrated.

00:44:05.090 --> 00:44:07.260
So part of the reason we
don't kill all the retirees

00:44:07.260 --> 00:44:08.730
and take their
stuff is that they

00:44:08.730 --> 00:44:10.420
are integrated
into our financial

00:44:10.420 --> 00:44:13.100
and legal and political systems
such that trying to do this

00:44:13.100 --> 00:44:16.950
would threaten the stability
of these systems we share.

00:44:16.950 --> 00:44:20.570
Similarly, if ems share
institutions with humans,

00:44:20.570 --> 00:44:22.880
they might be reluctant to
try to kill all the humans

00:44:22.880 --> 00:44:25.710
and take their stuff because
that would threaten the peace

00:44:25.710 --> 00:44:28.547
among themselves,
as a perhaps hope

00:44:28.547 --> 00:44:31.130
that the more they would end up
having different institutions,

00:44:31.130 --> 00:44:33.649
different things they use
between themselves than they

00:44:33.649 --> 00:44:35.190
use with humans,
the more possibility

00:44:35.190 --> 00:44:37.680
there would be to just
cut off the humans.

00:44:37.680 --> 00:44:41.215
If all the retirees in our
world went off to some island,

00:44:41.215 --> 00:44:42.590
then we could more
plausibly say,

00:44:42.590 --> 00:44:46.160
let's just cut off that
island because they

00:44:46.160 --> 00:44:50.080
would be in a separate world
with separate supports.

00:44:50.080 --> 00:44:52.851
AUDIENCE: So like Monsanto--
when they release GMO seeds,

00:44:52.851 --> 00:44:54.350
they're often
designed to be sterile

00:44:54.350 --> 00:44:55.349
so they can't reproduce.

00:44:55.349 --> 00:44:57.540
So you have to
buy more GMO seeds

00:44:57.540 --> 00:44:59.570
from the agricultural factory.

00:44:59.570 --> 00:45:01.720
Why wouldn't the
em factories make

00:45:01.720 --> 00:45:03.780
sure the ems can't
copy themselves

00:45:03.780 --> 00:45:05.360
and wouldn't want
to copy themselves

00:45:05.360 --> 00:45:06.660
so you have to go
back to the factory

00:45:06.660 --> 00:45:08.800
and pay a licensing fee
to get a new one to keep

00:45:08.800 --> 00:45:12.050
the population down?

00:45:12.050 --> 00:45:15.450
ROBIN HANSON: If at the
beginning of the emulation era,

00:45:15.450 --> 00:45:18.010
the original developer
of emulation technology

00:45:18.010 --> 00:45:20.990
was a small unitary
organization that

00:45:20.990 --> 00:45:23.940
was able to maintain a
lock on its technology,

00:45:23.940 --> 00:45:27.590
it might well try to play
monopolist of that technology

00:45:27.590 --> 00:45:29.760
and prevent others from
using the technology,

00:45:29.760 --> 00:45:31.850
and always pay that
firm a big fee to do it.

00:45:31.850 --> 00:45:33.870
And that might happen
in the early era.

00:45:33.870 --> 00:45:37.830
I just can't see that
lasting that long.

00:45:37.830 --> 00:45:39.870
So in this scenario,
I assumed it

00:45:39.870 --> 00:45:41.740
was a competitively
available technology--

00:45:41.740 --> 00:45:43.531
it was available to
many different parties.

00:45:43.531 --> 00:45:47.490
And so I find it hard to imagine
that even if that starts out

00:45:47.490 --> 00:45:49.660
in that scenario of a
monopolist holding onto it,

00:45:49.660 --> 00:45:52.760
that that could last
throughout this entire era.

00:45:52.760 --> 00:45:54.179
But that's my guess.

00:45:54.179 --> 00:45:55.720
AUDIENCE: Do you
see the ems choosing

00:45:55.720 --> 00:45:57.303
to make copies of
themselves, or is it

00:45:57.303 --> 00:45:59.174
the capitalist
that controls them

00:45:59.174 --> 00:46:00.840
the one that chooses
how many copies are

00:46:00.840 --> 00:46:03.876
made of each clan you said?

00:46:03.876 --> 00:46:05.500
ROBIN HANSON: So
imagine it's this way.

00:46:05.500 --> 00:46:06.440
You are an emulation.

00:46:06.440 --> 00:46:07.190
You have a job.

00:46:07.190 --> 00:46:08.106
You're doing your job.

00:46:08.106 --> 00:46:09.250
You're doing pretty well.

00:46:09.250 --> 00:46:11.740
And now there's a new place
somewhere else over there where

00:46:11.740 --> 00:46:13.290
a job like yours is needed.

00:46:13.290 --> 00:46:15.450
Somebody like you
over there is needed.

00:46:15.450 --> 00:46:17.076
Now, I could be eager
and say, I really

00:46:17.076 --> 00:46:18.950
want to find it, make
another copy of myself.

00:46:18.950 --> 00:46:20.160
I'm searching out for it.

00:46:20.160 --> 00:46:22.420
And whenever it shows up,
I try to make a bid for it,

00:46:22.420 --> 00:46:24.300
like go to some
capitalist and say, hey,

00:46:24.300 --> 00:46:26.260
would you fund some
capital so that I

00:46:26.260 --> 00:46:28.010
could make a new
venture copy myself over

00:46:28.010 --> 00:46:30.780
there because, hey, I'm
really eager to make copies?

00:46:30.780 --> 00:46:32.089
Or you might not be so eager.

00:46:32.089 --> 00:46:34.130
You might just be doing
your job and a capitalist

00:46:34.130 --> 00:46:35.490
see this opportunity over there.

00:46:35.490 --> 00:46:37.406
They say, hmm, this guy
would be good at that.

00:46:37.406 --> 00:46:40.195
And he comes to you and
says, I got a deal for you.

00:46:40.195 --> 00:46:41.820
How about we make
another copy for you?

00:46:41.820 --> 00:46:42.630
And here are the terms.

00:46:42.630 --> 00:46:44.050
This is the income
you'll get over there.

00:46:44.050 --> 00:46:45.160
This is the capital
you accumulate.

00:46:45.160 --> 00:46:46.576
Here are the rights
you will have.

00:46:46.576 --> 00:46:49.730
Here is how the first copy won't
compete with you, et cetera.

00:46:49.730 --> 00:46:52.170
There'll be many ways that
the terms of these contracts

00:46:52.170 --> 00:46:53.640
could be proposed.

00:46:53.640 --> 00:46:56.660
The economics-- it doesn't
matter that much who

00:46:56.660 --> 00:46:58.610
makes the initial proposal.

00:46:58.610 --> 00:47:00.210
The economics mostly
determines what

00:47:00.210 --> 00:47:02.880
are the efficient contracts
that end up being offered.

00:47:02.880 --> 00:47:04.950
And the main thing required
is that there ends up

00:47:04.950 --> 00:47:06.820
being a job that's
available and that you're

00:47:06.820 --> 00:47:09.070
willing to do it at
some reasonable terms.

00:47:09.070 --> 00:47:10.610
If not, use somebody.

00:47:10.610 --> 00:47:12.370
And the prediction
is as long as there

00:47:12.370 --> 00:47:13.990
are some people who
are willing enough

00:47:13.990 --> 00:47:16.874
to make copies of themselves
where, hey, it's another job,

00:47:16.874 --> 00:47:18.290
it looks like a
life worth living,

00:47:18.290 --> 00:47:19.303
I'm going to make
another copy of myself

00:47:19.303 --> 00:47:21.230
with a life worth living,
I'm OK with that-- as long

00:47:21.230 --> 00:47:23.646
as there are some people like
that, this all goes through.

00:47:23.646 --> 00:47:26.670
And it doesn't that much matter
what their motivations are.

00:47:26.670 --> 00:47:29.460
The main thing is that
they choose to do it.

00:47:29.460 --> 00:47:31.380
Emulations could
go fast or slow.

00:47:31.380 --> 00:47:36.030
So how fast any one worker
goes depends on how fast

00:47:36.030 --> 00:47:37.560
is optimal for that job.

00:47:37.560 --> 00:47:39.200
So those that
interact with humans

00:47:39.200 --> 00:47:40.350
will go as slow as humans.

00:47:40.350 --> 00:47:42.190
Those who might be in a
race, you might go fast.

00:47:42.190 --> 00:47:43.690
Bosses will turn
out to go faster.

00:47:43.690 --> 00:47:45.662
Leisure probably goes faster.

00:47:45.662 --> 00:47:47.870
If you're a fast emulation,
than the world around you

00:47:47.870 --> 00:47:49.720
is solid mountains--
very few things change

00:47:49.720 --> 00:47:53.276
and there's only a few tunnels
that you can go in and use.

00:47:53.276 --> 00:47:54.650
If you're a very
slow emulations,

00:47:54.650 --> 00:47:56.920
however, the opposite is true.

00:47:56.920 --> 00:47:58.670
Everything around you
is fast and buzzing,

00:47:58.670 --> 00:48:01.400
and you better keep your fingers
out or they'll get bitten off.

00:48:01.400 --> 00:48:03.274
So fast and slow
emulations, even though they

00:48:03.274 --> 00:48:05.120
are identical in
the software eyes,

00:48:05.120 --> 00:48:08.280
they really live in
quite different worlds.

00:48:08.280 --> 00:48:10.064
And the emulations
interact with humans.

00:48:10.064 --> 00:48:12.230
If they have a body, it
would probably be human size

00:48:12.230 --> 00:48:13.270
because that's natural.

00:48:13.270 --> 00:48:15.139
But if you run
faster, what you need

00:48:15.139 --> 00:48:16.680
is a short or
proportionately shorter

00:48:16.680 --> 00:48:19.116
body so that you can have a
natural reaction of the body.

00:48:19.116 --> 00:48:20.740
There's a basic
physics relation there.

00:48:20.740 --> 00:48:22.209
So as they get
faster and faster,

00:48:22.209 --> 00:48:24.500
plausibly, it can go up to
a million times human speed.

00:48:24.500 --> 00:48:25.930
They would have smaller
and smaller bodies.

00:48:25.930 --> 00:48:28.179
At some point, that might
teleoperate them rather than

00:48:28.179 --> 00:48:29.940
fit the brain in the body.

00:48:29.940 --> 00:48:33.730
You might notice that they'll
clump into speed classes

00:48:33.730 --> 00:48:35.980
rather than just being spread
uniformly across things.

00:48:35.980 --> 00:48:37.210
Just like we clump
into cities, they

00:48:37.210 --> 00:48:39.085
will clump into classes
of speed so that they

00:48:39.085 --> 00:48:40.910
can interact with each other.

00:48:40.910 --> 00:48:42.500
And this becomes
a class hierarchy

00:48:42.500 --> 00:48:45.820
because these faster
emulations are high status

00:48:45.820 --> 00:48:47.240
in many obvious ways.

00:48:47.240 --> 00:48:48.240
They embody more wealth.

00:48:48.240 --> 00:48:49.031
They win arguments.

00:48:49.031 --> 00:48:50.010
They know things first.

00:48:50.010 --> 00:48:53.410
Meetings happen in their place.

00:48:53.410 --> 00:48:56.060
So high-speed is high-class.

00:48:56.060 --> 00:48:57.270
You can also go much slower.

00:48:57.270 --> 00:48:59.100
And most retirees
would be slower.

00:48:59.100 --> 00:49:01.740
And there ends up being a
whole hierarchy in the sense

00:49:01.740 --> 00:49:04.200
that these emulations
become ghost-like--

00:49:04.200 --> 00:49:07.070
that is, like our traditional
ghosts of literature,

00:49:07.070 --> 00:49:10.412
slow retiree emulations
are not up with things.

00:49:10.412 --> 00:49:11.620
They're not paying attention.

00:49:11.620 --> 00:49:13.453
There's not really very
valuable to talk to.

00:49:13.453 --> 00:49:15.620
They're kind of
obsessed with the past.

00:49:15.620 --> 00:49:17.080
They can't have much influence.

00:49:17.080 --> 00:49:19.650
But if you want to
talk to one, there's

00:49:19.650 --> 00:49:21.100
thousands, millions
of them around

00:49:21.100 --> 00:49:25.590
available to talk
to if you so desire.

00:49:25.590 --> 00:49:27.810
As I said, our
cities are limited

00:49:27.810 --> 00:49:31.150
by-- they are
great in some ways.

00:49:31.150 --> 00:49:33.112
But the major limitation
is traffic congestion.

00:49:33.112 --> 00:49:34.820
That's why we aren't
all in one big city.

00:49:34.820 --> 00:49:37.480
That's no longer
true for emulations

00:49:37.480 --> 00:49:39.980
because they can interact across
the city in virtual reality

00:49:39.980 --> 00:49:42.080
without actually
sending themselves.

00:49:42.080 --> 00:49:44.639
They can have larger
cities that function well.

00:49:44.639 --> 00:49:46.680
And so they would concentrate
into a small number

00:49:46.680 --> 00:49:49.120
of dense cities.

00:49:49.120 --> 00:49:50.660
We have [INAUDIBLE]
infrastructure.

00:49:50.660 --> 00:49:55.042
And my last slide, which is
today in virtual reality,

00:49:55.042 --> 00:49:57.250
you can interact with anybody
across the entire world

00:49:57.250 --> 00:49:59.590
because the speed of light
to get a signal to them

00:49:59.590 --> 00:50:02.090
is less than your reaction
time of a tenth of a second.

00:50:02.090 --> 00:50:03.800
For an emulation
that's 16 times faster,

00:50:03.800 --> 00:50:06.440
that needs to be within
1,000 kilometers.

00:50:06.440 --> 00:50:08.210
If they're even
faster still, it needs

00:50:08.210 --> 00:50:12.410
to be-- let's just say if
they're within-- they need

00:50:12.410 --> 00:50:14.480
to be with 256
times faster, they

00:50:14.480 --> 00:50:16.660
need to be within a
few tens of kilometers.

00:50:16.660 --> 00:50:19.130
And so the faster
emulations go, the harder

00:50:19.130 --> 00:50:21.666
it is for them to interact
with other emulations

00:50:21.666 --> 00:50:22.790
without noticing the delay.

00:50:22.790 --> 00:50:24.870
So that's a reason
not to go too fast.

00:50:24.870 --> 00:50:26.910
A reason not to go
too slow, however,

00:50:26.910 --> 00:50:30.400
is that you want your career to
last within roughly a doubling

00:50:30.400 --> 00:50:31.270
time of the economy.

00:50:31.270 --> 00:50:32.480
Otherwise, your
initial job skills

00:50:32.480 --> 00:50:34.570
are no longer relevant
quickly into your career.

00:50:34.570 --> 00:50:37.965
And that sets a upper
limit-- a limit of how slow

00:50:37.965 --> 00:50:38.840
you might want to go.

00:50:38.840 --> 00:50:40.030
And those two things
together give me

00:50:40.030 --> 00:50:42.290
an estimate of roughly
1,000 times human speed

00:50:42.290 --> 00:50:44.560
for the typical speed
of the emulation.

00:50:44.560 --> 00:50:46.580
And I've other things
to say about inequality.

00:50:46.580 --> 00:50:50.152
But I will since it's the
end leave you with these are

00:50:50.152 --> 00:50:51.360
some positives and negatives.

00:50:51.360 --> 00:50:54.716
I caution you that if your
ancestors were evaluating

00:50:54.716 --> 00:50:57.090
your world, they would love
things and hate other things.

00:50:57.090 --> 00:50:58.798
And perhaps whether
they liked you or not

00:50:58.798 --> 00:51:00.940
would depend on the
first thing they heard.

00:51:00.940 --> 00:51:03.739
You should think carefully about
a whole different civilization

00:51:03.739 --> 00:51:05.530
you don't know much
about before you decide

00:51:05.530 --> 00:51:07.010
if you love it or hate it.

00:51:07.010 --> 00:51:09.046
But these are some
things to notice.

00:51:09.046 --> 00:51:11.420
In virtual reality, again--
no pain, hunger, [INAUDIBLE],

00:51:11.420 --> 00:51:13.100
they're not afraid of death.

00:51:13.100 --> 00:51:15.604
Some of you may be in a city
like this area and you think,

00:51:15.604 --> 00:51:17.270
I couldn't possibly
live in a small town

00:51:17.270 --> 00:51:18.645
because nothing's
going on there.

00:51:18.645 --> 00:51:20.740
They will think that
about your cities

00:51:20.740 --> 00:51:22.781
because they all have much
bigger, more intricate

00:51:22.781 --> 00:51:24.180
cities with a lot more going on.

00:51:24.180 --> 00:51:26.513
On the negative, they are
working at subsistence income,

00:51:26.513 --> 00:51:27.227
long hours.

00:51:27.227 --> 00:51:28.810
There's more inequality
in this world.

00:51:28.810 --> 00:51:30.727
Often, they are OK
with [INAUDIBLE]

00:51:30.727 --> 00:51:33.310
bigger, more bureaucratic firms;
perhaps less nature and space

00:51:33.310 --> 00:51:36.310
travel; less democracy;
more religion.

00:51:36.310 --> 00:51:39.100
This is the age of em
as I best guess it.

00:51:39.100 --> 00:51:41.690
Again, it's not my job to
make you like it or hate it.

00:51:41.690 --> 00:51:44.967
My job is just to tell you as
best I can what it looks like.

00:51:44.967 --> 00:51:46.800
SPEAKER: On your website,
"Overcoming Bias,"

00:51:46.800 --> 00:51:48.450
you frequently to
behavioral biases

00:51:48.450 --> 00:51:50.870
and how they affect people's
understandings of the future.

00:51:50.870 --> 00:51:52.953
How do you control for
these in your own research?

00:51:52.953 --> 00:51:57.590
ROBIN HANSON: One bias is a
taboo on assuming that we fail.

00:51:57.590 --> 00:52:01.060
So my colleague Tyler Cowen
wrote a book about inequality

00:52:01.060 --> 00:52:03.752
a few years ago
where he basically

00:52:03.752 --> 00:52:05.710
assumed that inequality
was going to get worse.

00:52:05.710 --> 00:52:07.980
And he said, how can
you deal with this?

00:52:07.980 --> 00:52:09.527
And a lot of people
just didn't like

00:52:09.527 --> 00:52:12.110
that because they said, hey, we
think inequality is a problem.

00:52:12.110 --> 00:52:13.776
And you're assuming
we're going to fail.

00:52:13.776 --> 00:52:15.580
And he said, yeah.

00:52:15.580 --> 00:52:18.422
And so similarly,
here, many people

00:52:18.422 --> 00:52:19.880
think that this is
a scenario where

00:52:19.880 --> 00:52:21.920
we fail at some things
we would like to change.

00:52:21.920 --> 00:52:22.880
And I'm saying, yeah.

00:52:22.880 --> 00:52:25.590
So I think you should
just consider scenarios

00:52:25.590 --> 00:52:30.010
where we fail at achieving
some of the ideals we have.

00:52:30.010 --> 00:52:32.450
There's another
cognitive phenomena

00:52:32.450 --> 00:52:34.550
called construal
level theory, which

00:52:34.550 --> 00:52:36.630
says that we have an
abstract way of reasoning

00:52:36.630 --> 00:52:38.970
and a concrete way of
reasoning, and they

00:52:38.970 --> 00:52:40.280
have different features.

00:52:40.280 --> 00:52:43.050
Our abstract reasoning is
more creative and intuitive.

00:52:43.050 --> 00:52:46.880
Our concrete reasoning
is more detail-oriented

00:52:46.880 --> 00:52:50.060
and based on analysis
and things like that.

00:52:50.060 --> 00:52:52.910
We are prone to reason
abstractly about the future

00:52:52.910 --> 00:52:55.190
because we have so few
concrete details to anchor us.

00:52:55.190 --> 00:52:57.300
And so there's a risk
of becoming too abstract

00:52:57.300 --> 00:52:58.280
about the future.

00:52:58.280 --> 00:53:02.450
Our abstract mode also makes
us very principled in the sense

00:53:02.450 --> 00:53:05.350
that in abstract mode,
we think of small number

00:53:05.350 --> 00:53:06.970
of moral principles
should hold very

00:53:06.970 --> 00:53:08.584
strongly with few exceptions.

00:53:08.584 --> 00:53:10.000
And we think that
of all theories,

00:53:10.000 --> 00:53:12.739
whereas in concrete
mode, we are more

00:53:12.739 --> 00:53:14.780
willing to admit that
there's a lot of complexity

00:53:14.780 --> 00:53:18.140
and to give people a pass on
various exceptions and things

00:53:18.140 --> 00:53:18.640
like that.

00:53:18.640 --> 00:53:20.889
And so that's also a thing
to be wary about the future

00:53:20.889 --> 00:53:22.410
because it's so
abstract, you decide

00:53:22.410 --> 00:53:24.160
that there are these
moral principles that

00:53:24.160 --> 00:53:25.750
simply must be held.

00:53:25.750 --> 00:53:28.020
Those are some examples there.

00:53:28.020 --> 00:53:29.460
Do I believe whole
brain emulation

00:53:29.460 --> 00:53:33.227
is the most likely path to
reach super intelligence?

00:53:33.227 --> 00:53:34.560
And who are the biggest players?

00:53:34.560 --> 00:53:37.372
So in terms of players,
there are three technologies

00:53:37.372 --> 00:53:38.080
I told you about.

00:53:38.080 --> 00:53:39.204
None of them are ready yet.

00:53:39.204 --> 00:53:41.570
So nobody putting them
together, nor should they.

00:53:41.570 --> 00:53:43.011
It's way too early for that.

00:53:43.011 --> 00:53:44.510
But in the three
technologies, there

00:53:44.510 --> 00:53:46.970
are, of course, many players
in computers, scanning,

00:53:46.970 --> 00:53:49.910
and in brain cell modeling.

00:53:49.910 --> 00:53:51.840
I have opinions about
the most likely paths.

00:53:51.840 --> 00:53:55.170
But my book was primarily
not about that question.

00:53:55.170 --> 00:53:57.340
So just to be
clear, the future's

00:53:57.340 --> 00:53:59.740
important enough that,
say, we should be exploring

00:53:59.740 --> 00:54:01.370
100 different scenarios.

00:54:01.370 --> 00:54:04.410
That means we should explore a
scenario with only a 1% chance.

00:54:04.410 --> 00:54:06.510
So I think this definitely
reaches that standard

00:54:06.510 --> 00:54:09.670
of at least a 1% chance.

00:54:09.670 --> 00:54:11.970
So I think we should
take each scenario that

00:54:11.970 --> 00:54:13.520
has at least a 1%
chance and work it

00:54:13.520 --> 00:54:14.770
out like I've worked out here.

00:54:14.770 --> 00:54:16.103
And that's what this book about.

00:54:16.103 --> 00:54:18.010
The book is showing
expertise in being

00:54:18.010 --> 00:54:20.680
able to work out
a scenario, not--

00:54:20.680 --> 00:54:23.850
I did argue a little bit
about why it's not unlikely.

00:54:23.850 --> 00:54:25.680
But that wasn't the
focus of the book.

00:54:25.680 --> 00:54:28.325
As I said, the other
most plausible route

00:54:28.325 --> 00:54:30.157
to artificial
intelligence is slowly

00:54:30.157 --> 00:54:31.740
accumulating better
software, as we've

00:54:31.740 --> 00:54:32.876
been doing for a long time.

00:54:32.876 --> 00:54:34.500
We have at the rate
of progress there--

00:54:34.500 --> 00:54:36.276
it looks roughly two
to four centuries.

00:54:36.276 --> 00:54:37.650
The rough guess
is about the rate

00:54:37.650 --> 00:54:40.024
of progress it would take to
do brain emulation-- roughly

00:54:40.024 --> 00:54:42.984
a century or so, which is
why this seems plausibly

00:54:42.984 --> 00:54:44.400
the thing that
might happen first.

00:54:44.400 --> 00:54:46.600
But those are pretty
weak inferences.

00:54:46.600 --> 00:54:49.060
So I'm happy to say, hey,
there's a lot of possibilities.

00:54:49.060 --> 00:54:51.740
And I'm not going to argue
very strongly for any one

00:54:51.740 --> 00:54:53.420
calculation there.

00:54:53.420 --> 00:54:55.060
I know some of the
players in brain

00:54:55.060 --> 00:54:58.540
scanning because there's a Brain
Preservation Foundation that I

00:54:58.540 --> 00:55:02.720
contributed some money to
that is trying to develop

00:55:02.720 --> 00:55:05.770
better ways of scanning brains.

00:55:05.770 --> 00:55:09.800
There actually are decent
scans of mouse brains

00:55:09.800 --> 00:55:11.070
at a reasonable resolution.

00:55:11.070 --> 00:55:12.240
We don't know if it's a
good enough resolution.

00:55:12.240 --> 00:55:13.720
But we don't know how
far you have to go.

00:55:13.720 --> 00:55:15.919
Mouse brain is roughly one
thousandth times smaller

00:55:15.919 --> 00:55:16.710
than a human brain.

00:55:16.710 --> 00:55:18.540
So in terms of scaling,
you have to go up

00:55:18.540 --> 00:55:21.950
by a factor of a thousand still.

00:55:21.950 --> 00:55:24.200
And my guess is brain scanning
is the first technology

00:55:24.200 --> 00:55:26.775
to be ready.

00:55:26.775 --> 00:55:28.400
AUDIENCE: Everything
I've heard so far,

00:55:28.400 --> 00:55:30.066
you've been talking
about adults and how

00:55:30.066 --> 00:55:31.510
they would work in this.

00:55:31.510 --> 00:55:34.082
I wonder if you
scanned a young child

00:55:34.082 --> 00:55:35.790
and let them grow up
in this environment,

00:55:35.790 --> 00:55:37.462
if they would
rapidly out-compete

00:55:37.462 --> 00:55:38.920
adults who are sort
of transplanted

00:55:38.920 --> 00:55:40.270
into this environment.

00:55:40.270 --> 00:55:42.550
And if so, would that
shorten the doubling time

00:55:42.550 --> 00:55:45.160
and the duration
of this economy?

00:55:45.160 --> 00:55:48.080
ROBIN HANSON: It is my guess
that, in fact, very quickly,

00:55:48.080 --> 00:55:50.690
scanning children will be the
preference of this society.

00:55:50.690 --> 00:55:52.680
So at the very
beginning, you would

00:55:52.680 --> 00:55:55.460
be taking people at the current
peak of their human career

00:55:55.460 --> 00:55:57.751
and copying them-- the best
software engineer, the best

00:55:57.751 --> 00:55:58.870
lawyer, et cetera.

00:55:58.870 --> 00:56:00.510
But very quickly as
this world changes,

00:56:00.510 --> 00:56:02.260
the people who are
best in the human world

00:56:02.260 --> 00:56:04.100
will no longer be the
best in this new world.

00:56:04.100 --> 00:56:06.050
You'll need people who are
younger and flexible to learn

00:56:06.050 --> 00:56:07.500
and adapt to this world,
and therefore you'll

00:56:07.500 --> 00:56:08.840
want to pick young children.

00:56:08.840 --> 00:56:11.150
Now, there's a substantial
complication here,

00:56:11.150 --> 00:56:15.650
which is that the first scans
will probably be destructive.

00:56:15.650 --> 00:56:18.700
So you would then have the
scenario of rich capitalists--

00:56:18.700 --> 00:56:21.300
humans and ems, otherwise--
approaching families

00:56:21.300 --> 00:56:23.380
of children who seem to
have a lot of potential

00:56:23.380 --> 00:56:25.530
to be successful in the
emulation world saying,

00:56:25.530 --> 00:56:29.080
could we destructively
scan your child

00:56:29.080 --> 00:56:30.770
so that they have a
chance of becoming

00:56:30.770 --> 00:56:33.071
a very successful emulation?

00:56:33.071 --> 00:56:35.320
The obvious prediction is
some places will allow that,

00:56:35.320 --> 00:56:36.710
and some won't.

00:56:36.710 --> 00:56:38.820
And wherever it's
allowed, that will

00:56:38.820 --> 00:56:40.140
dominate the emulation economy.

00:56:40.140 --> 00:56:41.598
So my straightforward
prediction is

00:56:41.598 --> 00:56:45.250
yes-- is that there are many
obstacles by which an emulation

00:56:45.250 --> 00:56:48.509
economy will face resistance
in the preexisting economy.

00:56:48.509 --> 00:56:50.800
But that happened in the
industrial era and the farming

00:56:50.800 --> 00:56:51.950
transitions, as well.

00:56:51.950 --> 00:56:55.226
There were long transitions in
part because of these obstacles

00:56:55.226 --> 00:56:55.850
being overcome.

00:56:55.850 --> 00:56:58.540
But by the time this economy's
doubling every month,

00:56:58.540 --> 00:57:01.600
those obstacles will have
been overcome somewhere.

00:57:01.600 --> 00:57:04.070
And so somewhere, they will
allow destructive scanning

00:57:04.070 --> 00:57:05.102
of children.

00:57:05.102 --> 00:57:06.310
And that'll happen somewhere.

00:57:06.310 --> 00:57:09.202
That's just prediction on the
basis of wherever it happens,

00:57:09.202 --> 00:57:10.160
it'll happen somewhere.

00:57:10.160 --> 00:57:12.243
Wherever it happens, they'll
have a big advantage.

00:57:12.243 --> 00:57:13.391
So that's it.

00:57:13.391 --> 00:57:13.890
In the back?

00:57:13.890 --> 00:57:14.900
AUDIENCE: Where's all
the energy coming from?

00:57:14.900 --> 00:57:17.500
Where does all the energy come
from for this constant doubling

00:57:17.500 --> 00:57:18.810
of ems?

00:57:18.810 --> 00:57:22.720
Are they somehow extremely more
efficient than current people

00:57:22.720 --> 00:57:25.430
are, energy-wise, or--

00:57:25.430 --> 00:57:28.490
ROBIN HANSON: So I don't know
how fast this economy can

00:57:28.490 --> 00:57:30.060
grow its energy budget.

00:57:30.060 --> 00:57:32.200
But even if it's very
limited in its ability

00:57:32.200 --> 00:57:34.990
to grow the energy
budget, it can still just

00:57:34.990 --> 00:57:38.050
make its computers
more miniaturized

00:57:38.050 --> 00:57:39.800
and use less energy.

00:57:39.800 --> 00:57:41.620
Also, within a few
decades, we will

00:57:41.620 --> 00:57:43.902
need to switch to what's
called reversible computing,

00:57:43.902 --> 00:57:45.110
thermodynamically reversible.

00:57:45.110 --> 00:57:48.070
And with thermodynamically
reversible computing parts,

00:57:48.070 --> 00:57:50.950
you have a trade-off that
you can run it twice as slow

00:57:50.950 --> 00:57:55.400
and use only half as much
energy per computation.

00:57:55.400 --> 00:57:57.450
So as energy gets
more expensive,

00:57:57.450 --> 00:58:00.820
they will just be pushed to move
in that regime toward slower

00:58:00.820 --> 00:58:02.111
computational cycles.

00:58:02.111 --> 00:58:03.860
But you can compensate
with more hardware.

00:58:03.860 --> 00:58:08.600
So the age of em-- growing
fast and being big--

00:58:08.600 --> 00:58:11.016
isn't very sensitive
to how cheap energy is.

00:58:11.016 --> 00:58:12.390
Even if energy is
very expensive,

00:58:12.390 --> 00:58:13.860
this all can still happen.

00:58:13.860 --> 00:58:16.650
But I would guess they would
be so eager to get more energy,

00:58:16.650 --> 00:58:17.290
they would spend a lot.

00:58:17.290 --> 00:58:18.748
So one of the things
I can tell you

00:58:18.748 --> 00:58:20.770
is that when you're using
reversible computing

00:58:20.770 --> 00:58:23.149
hardware and other reversible
systems in general,

00:58:23.149 --> 00:58:24.690
you spend roughly
half of your budget

00:58:24.690 --> 00:58:27.500
on the hardware and half
on the energy and cooling.

00:58:27.500 --> 00:58:30.680
So emulation cities
are roughly half

00:58:30.680 --> 00:58:35.080
of the volume as cooling pipes--
full of ice water coming in

00:58:35.080 --> 00:58:38.597
and steam coming out because
it's so valuable to spend more

00:58:38.597 --> 00:58:40.180
on it because that's
real estate-wise,

00:58:40.180 --> 00:58:42.281
you're spending half
your budget on that.

00:58:42.281 --> 00:58:44.530
And so energy is a big
fraction of this economy, i.e.,

00:58:44.530 --> 00:58:46.196
you'll spend roughly
half of your budget

00:58:46.196 --> 00:58:50.036
on energy and cooling relative
to building more hardware.

00:58:50.036 --> 00:58:52.660
So they'll spending a lot on it,
and it's therefore innovation.

00:58:52.660 --> 00:58:54.419
And it will be very valuable.

00:58:54.419 --> 00:58:56.710
And we do really know a lot
of futuristic-sounding ways

00:58:56.710 --> 00:58:57.570
to increase the energy budget.

00:58:57.570 --> 00:58:59.460
It's actually harder
to find futuristic ways

00:58:59.460 --> 00:59:00.867
to make cooling faster.

00:59:00.867 --> 00:59:02.950
So that's why I think
cooling is actually a bigger

00:59:02.950 --> 00:59:04.230
limitation than energy.

00:59:04.230 --> 00:59:06.630
The key argument for
subsistence level

00:59:06.630 --> 00:59:09.900
is that no matter how
fast you figure out

00:59:09.900 --> 00:59:14.640
that you could
innovate this economy,

00:59:14.640 --> 00:59:18.090
you can just crank more
computers out of the factories

00:59:18.090 --> 00:59:19.160
faster.

00:59:19.160 --> 00:59:21.410
So as long as you can just
keep cranking computers out

00:59:21.410 --> 00:59:23.830
of the factories faster
and the other resources

00:59:23.830 --> 00:59:27.000
they need faster than
the economy can innovate,

00:59:27.000 --> 00:59:30.410
then the wealth or
income per em falls down

00:59:30.410 --> 00:59:31.571
to subsistence level.

00:59:31.571 --> 00:59:32.570
That's the key argument.

00:59:32.570 --> 00:59:34.740
So it's about the
relative speeds.

00:59:34.740 --> 00:59:36.610
So even if
innovation's very fast,

00:59:36.610 --> 00:59:40.715
as long as production is
even faster, production wins.

00:59:40.715 --> 00:59:42.340
AUDIENCE: One thing
we didn't have time

00:59:42.340 --> 00:59:46.900
for is how they interact
with each other.

00:59:46.900 --> 00:59:49.020
So how do you
predict they interact

00:59:49.020 --> 00:59:54.080
with each other emotionally
and family-wise, clan-wise?

00:59:54.080 --> 00:59:56.120
ROBIN HANSON: So
the book has a lot

00:59:56.120 --> 00:59:57.920
of detail about interactions.

00:59:57.920 --> 01:00:00.030
If you look at the
sections, early on,

01:00:00.030 --> 01:00:01.070
there's the basic setup.

01:00:01.070 --> 01:00:03.236
And then there's some physics
and some other things.

01:00:03.236 --> 01:00:05.057
But then we do
organizations and sociology

01:00:05.057 --> 01:00:07.140
and all sort-- there's
whole big sections on that.

01:00:07.140 --> 01:00:10.285
So I talk a lot about work
and how they organize at work.

01:00:10.285 --> 01:00:12.410
And they will be in big
organized firms like we do.

01:00:12.410 --> 01:00:14.910
But there'll be some difference
because they have these clan

01:00:14.910 --> 01:00:15.920
structure.

01:00:15.920 --> 01:00:17.920
They will have, I
predict, the usual sort

01:00:17.920 --> 01:00:21.160
of romantic attachments and
inclinations in that direction.

01:00:21.160 --> 01:00:23.930
The main complication
there is that there's

01:00:23.930 --> 01:00:25.980
no longer necessarily
an equal demand

01:00:25.980 --> 01:00:27.780
for male versus female work.

01:00:27.780 --> 01:00:30.674
So plausibly, there's an
asymmetric ratio there

01:00:30.674 --> 01:00:31.840
that they have to deal with.

01:00:31.840 --> 01:00:34.820
And I talk about some of the
ways they could deal with that.

01:00:34.820 --> 01:00:39.176
There are the ways in which--
so if you're in a team,

01:00:39.176 --> 01:00:41.050
you're going to be copied
together as a team.

01:00:41.050 --> 01:00:42.160
Today when you have
a team, you have

01:00:42.160 --> 01:00:43.580
to worry if some of
your team members

01:00:43.580 --> 01:00:45.410
are going to leave your
team, betraying your team

01:00:45.410 --> 01:00:46.451
and going somewhere else.

01:00:46.451 --> 01:00:47.490
But that happens, right?

01:00:47.490 --> 01:00:48.930
Ems-- they don't have
to worry about that.

01:00:48.930 --> 01:00:51.240
If one of your team member
leaves, a copy leaves.

01:00:51.240 --> 01:00:53.370
The original stays
with your team.

01:00:53.370 --> 01:00:57.830
So the teams stay
together for life.

01:00:57.830 --> 01:01:00.340
So teams are a very
strong social bond.

01:01:00.340 --> 01:01:01.840
There you can copy a whole team.

01:01:01.840 --> 01:01:03.354
So if you have a
team around you,

01:01:03.354 --> 01:01:04.770
there's probably
thousands or even

01:01:04.770 --> 01:01:06.311
millions of other
copies of that team

01:01:06.311 --> 01:01:09.460
out there that you can use as
statistics about your team.

01:01:09.460 --> 01:01:11.770
So if I have a
relationship with Bob

01:01:11.770 --> 01:01:14.390
or, say, Sue-- I'm married
to Sue-- and out there

01:01:14.390 --> 01:01:15.900
all of a sudden
Bobs and Stu start

01:01:15.900 --> 01:01:17.358
having fights and
getting divorced,

01:01:17.358 --> 01:01:20.282
I know that my relationship may
be in trouble because there's

01:01:20.282 --> 01:01:21.990
all these other copies
of my relationship

01:01:21.990 --> 01:01:23.580
out there to use as data points.

01:01:26.090 --> 01:01:28.270
And because these other
copies of me around me

01:01:28.270 --> 01:01:32.260
create the-- not only can I
talk to other members of my clan

01:01:32.260 --> 01:01:35.460
as sources of information, I
have to worry that things I do

01:01:35.460 --> 01:01:38.460
will be taken as information
about other copies of me.

01:01:38.460 --> 01:01:40.310
And that creates more
of an incentive for me

01:01:40.310 --> 01:01:45.680
to behave because otherwise,
if he starts acting weird,

01:01:45.680 --> 01:01:47.700
maybe the other ones
will act weird, too.

01:01:47.700 --> 01:01:49.770
So there's a whole bunch
of things like that

01:01:49.770 --> 01:01:52.060
that the book talks about.

01:01:52.060 --> 01:01:53.560
AUDIENCE: So we
were already talking

01:01:53.560 --> 01:01:57.230
about political structures and
about power and revolution.

01:01:57.230 --> 01:02:01.675
I'm just curious sort of how
you use social science to think

01:02:01.675 --> 01:02:03.080
about that sort of stuff.

01:02:03.080 --> 01:02:04.170
ROBIN HANSON: The question
is about politics,

01:02:04.170 --> 01:02:06.295
though there are chapters
and sections on politics.

01:02:08.790 --> 01:02:10.940
First thing is to
say is that autocrats

01:02:10.940 --> 01:02:14.185
relative to democracies have
some relative advantages here.

01:02:14.185 --> 01:02:15.810
That doesn't mean
democracy disappears.

01:02:15.810 --> 01:02:18.400
But the proportion shifts.

01:02:18.400 --> 01:02:19.820
So autocrats here,
again-- we have

01:02:19.820 --> 01:02:21.860
the safes that
can help you trust

01:02:21.860 --> 01:02:25.120
a leader, an autocratic leader
via the safes I talked about.

01:02:25.120 --> 01:02:27.280
Also, today, autocrats
have the problem

01:02:27.280 --> 01:02:28.820
that the few people
around them--

01:02:28.820 --> 01:02:30.480
they need strong
loyalty from them

01:02:30.480 --> 01:02:31.700
and they have to be
afraid of betrayal

01:02:31.700 --> 01:02:32.600
about the few
people around them.

01:02:32.600 --> 01:02:34.290
Ems can just have
copies of themselves

01:02:34.290 --> 01:02:36.960
around them as the leader.

01:02:36.960 --> 01:02:38.570
Leaders can run
much faster here.

01:02:38.570 --> 01:02:40.650
So you can have
very fast leaders.

01:02:40.650 --> 01:02:42.920
And that allows
bosses in general

01:02:42.920 --> 01:02:43.920
to have more advantages.

01:02:43.920 --> 01:02:47.420
So hierarchies here are probably
shorter because the bosses can

01:02:47.420 --> 01:02:50.100
have larger spans of control.

01:02:50.100 --> 01:02:53.600
Those are some of the things
to say about politics here.

01:02:53.600 --> 01:02:56.530
One em, one vote just
doesn't work here.

01:02:56.530 --> 01:02:58.160
Perhaps speed-weighted
voting does

01:02:58.160 --> 01:03:00.820
work, and which, of course,
gives the government

01:03:00.820 --> 01:03:03.070
an excuse or a reason to
monitor everybody's speed all

01:03:03.070 --> 01:03:05.970
the time-- so that
they can weight them

01:03:05.970 --> 01:03:08.500
appropriately in the election.

01:03:08.500 --> 01:03:11.580
AUDIENCE: It looks like you
thought through this scenario

01:03:11.580 --> 01:03:14.070
of the future in great details.

01:03:14.070 --> 01:03:16.660
I'm very curious about
your thinking process.

01:03:16.660 --> 01:03:19.750
How did you get to
this point where--

01:03:19.750 --> 01:03:23.830
I think you managed to
answer most of our question

01:03:23.830 --> 01:03:27.000
in so many details, and
which I think is better

01:03:27.000 --> 01:03:30.710
than most people I heard.

01:03:30.710 --> 01:03:32.210
ROBIN HANSON: As
I indicated early,

01:03:32.210 --> 01:03:35.640
I have spent a lifetime
learning many different fields.

01:03:35.640 --> 01:03:37.330
Academia doesn't
usually reward that.

01:03:37.330 --> 01:03:40.010
So I kind of squeaked
by in getting tenure.

01:03:40.010 --> 01:03:42.930
But I started out
in engineering.

01:03:42.930 --> 01:03:43.970
Then I moved to physics.

01:03:43.970 --> 01:03:45.490
I did philosophy.

01:03:45.490 --> 01:03:47.560
Then I did nine years
of computer research.

01:03:47.560 --> 01:03:49.310
Then I went back and
did political science

01:03:49.310 --> 01:03:50.417
and economics.

01:03:50.417 --> 01:03:51.250
And I've read a lot.

01:03:51.250 --> 01:03:54.980
So basically, I'm not
doing anything very special

01:03:54.980 --> 01:03:58.380
other than having a lifetime
of learning many fields

01:03:58.380 --> 01:04:00.764
and then just straightforwardly
applying the things I

01:04:00.764 --> 01:04:01.930
know about all these fields.

01:04:01.930 --> 01:04:05.310
So I would claim that if you
look at the section in my book

01:04:05.310 --> 01:04:07.420
about the field you
know a lot about,

01:04:07.420 --> 01:04:10.050
you will find it to be a
relatively straightforward

01:04:10.050 --> 01:04:11.415
application of things you know.

01:04:11.415 --> 01:04:13.998
Maybe you wouldn't have thought
of those applications, per se.

01:04:13.998 --> 01:04:15.310
But they are straightforward.

01:04:15.310 --> 01:04:16.351
And that's my claim here.

01:04:16.351 --> 01:04:18.447
I'm just knowing a lot
of different fields,

01:04:18.447 --> 01:04:20.780
and just methodically going
through each one and saying,

01:04:20.780 --> 01:04:22.800
what does the standard
results about this field

01:04:22.800 --> 01:04:24.800
say about this scenario?

01:04:24.800 --> 01:04:27.250
AUDIENCE: Quick question--
followup question--

01:04:27.250 --> 01:04:30.420
do you get a lot of feedback,
like in person from people,

01:04:30.420 --> 01:04:33.900
or it mainly happens as a
research where you're alone

01:04:33.900 --> 01:04:34.450
in the room?

01:04:34.450 --> 01:04:36.241
ROBIN HANSON: This is
where I get feedback.

01:04:36.241 --> 01:04:38.420
When I give talks,
you people talk to me.

01:04:38.420 --> 01:04:40.320
Writing a book is
lonely, by the way,

01:04:40.320 --> 01:04:42.690
especially if it's a weird
book that nobody ever writes

01:04:42.690 --> 01:04:43.731
a book like about before.

01:04:43.731 --> 01:04:45.970
So if you write a book
like somebody else's book,

01:04:45.970 --> 01:04:47.820
then you can send them
a copy of your draft

01:04:47.820 --> 01:04:49.540
and they'll send you copy and
tell you what they thought.

01:04:49.540 --> 01:04:51.770
If you're writing a weird book
that's like no other book,

01:04:51.770 --> 01:04:52.936
then you're all on your own.

01:04:52.936 --> 01:04:55.226
So writing the book
itself is lonely.

01:04:55.226 --> 01:04:56.600
Publishing it is
less lonely when

01:04:56.600 --> 01:04:58.550
you get people to talk to you
about the book, like this.

01:04:58.550 --> 01:04:59.425
So I'm enjoying this.

01:04:59.425 --> 01:05:01.930
In order to reach the
age of em society,

01:05:01.930 --> 01:05:04.560
we'll inevitably be experience
serious economic growing pains.

01:05:04.560 --> 01:05:06.060
In what ways do society
have to change in order

01:05:06.060 --> 01:05:08.476
to make the introduction of
powerful automation technology

01:05:08.476 --> 01:05:12.590
positive for the majority
of the population?

01:05:12.590 --> 01:05:16.980
I think subsistence
economies are OK.

01:05:16.980 --> 01:05:19.670
That is, I think most humans
through history had OK lives.

01:05:19.670 --> 01:05:21.250
They were lives worth living.

01:05:21.250 --> 01:05:24.444
So most foragers in the
woods, most farmers--

01:05:24.444 --> 01:05:26.610
subsistence farmers--
sometimes, there were famines.

01:05:26.610 --> 01:05:28.220
Sometimes there were
invasions, and then things

01:05:28.220 --> 01:05:29.220
didn't go so well.

01:05:29.220 --> 01:05:34.860
But mostly, humans evolved to
exist as subsistence income

01:05:34.860 --> 01:05:35.550
worlds.

01:05:35.550 --> 01:05:38.260
And that's where most
humans ever did exist.

01:05:38.260 --> 01:05:39.350
And those lives are OK.

01:05:39.350 --> 01:05:44.010
So I think a future of
subsistence ems is an OK world.

01:05:44.010 --> 01:05:48.240
So in that sense, it's
positive because there's

01:05:48.240 --> 01:05:50.870
probably less war here,
there's more-- again,

01:05:50.870 --> 01:05:52.335
no grime, disease, pain.

01:05:52.335 --> 01:05:53.960
There's some other
nice positives here.

01:05:53.960 --> 01:05:56.915
So I already think this
is reasonably positive.

01:05:56.915 --> 01:05:59.040
But there's obviously always
a lot of opportunities

01:05:59.040 --> 01:06:01.410
for making things better.

01:06:01.410 --> 01:06:06.180
But I have to tell you that when
people talk about the future,

01:06:06.180 --> 01:06:11.307
they seem to me overwhelmingly
tempted to evaluate and discuss

01:06:11.307 --> 01:06:13.640
whether they like things or
not before they've even done

01:06:13.640 --> 01:06:15.890
the very basics of analysis.

01:06:15.890 --> 01:06:18.180
So I feel the thing
I can contribute

01:06:18.180 --> 01:06:20.690
is to get people to pause
longer and do more analysis

01:06:20.690 --> 01:06:22.270
before they jump
into evaluation mode

01:06:22.270 --> 01:06:25.610
because I have no doubt they
will get to evaluation mode.

01:06:25.610 --> 01:06:27.790
I do not feel any need
to jump in and offer

01:06:27.790 --> 01:06:29.950
my first evaluation
so as to decide

01:06:29.950 --> 01:06:31.076
what they should evaluate.

01:06:31.076 --> 01:06:32.200
Evaluate on your own terms.

01:06:32.200 --> 01:06:33.533
You figure out how you evaluate.

01:06:33.533 --> 01:06:35.290
But first, please,
pause and think

01:06:35.290 --> 01:06:37.500
about the actual world
you're talking about.

01:06:37.500 --> 01:06:38.610
See it in some detail.

01:06:38.610 --> 01:06:40.540
Learn a few things about
it before you jump in

01:06:40.540 --> 01:06:42.000
and evaluate it.

01:06:42.000 --> 01:06:43.980
And then once you
do some evaluation,

01:06:43.980 --> 01:06:45.470
maybe you can think about what
you like and you don't like,

01:06:45.470 --> 01:06:46.880
and we can think
about ways to push it

01:06:46.880 --> 01:06:47.610
in the directions you like.

01:06:47.610 --> 01:06:48.318
It's not so hard.

01:06:48.318 --> 01:06:50.390
The hard thing is to get
this baselines estimate

01:06:50.390 --> 01:06:51.850
of what the world looks like.

01:06:51.850 --> 01:06:54.480
If you don't have the foggiest
idea what a world looks

01:06:54.480 --> 01:07:00.275
like, you jump in to try to fix
it, that just doesn't go well.

01:07:00.275 --> 01:07:02.980
AUDIENCE: So you mentioned ems
making decisions and signing

01:07:02.980 --> 01:07:03.700
contracts.

01:07:03.700 --> 01:07:06.655
So would they need some sort
of secure execution environment

01:07:06.655 --> 01:07:09.790
in order to do that so it
would prevent something

01:07:09.790 --> 01:07:11.960
else from manipulating
their emulation

01:07:11.960 --> 01:07:14.540
software to make them make
decisions that they wouldn't

01:07:14.540 --> 01:07:17.190
normally make?

01:07:17.190 --> 01:07:20.120
ROBIN HANSON: All of
human and animal history

01:07:20.120 --> 01:07:22.480
has involved people
making decisions

01:07:22.480 --> 01:07:25.090
in contexts where their
things they rely on

01:07:25.090 --> 01:07:27.884
are usually, but not
always, reliable.

01:07:27.884 --> 01:07:29.800
That includes pretty
much all of human history

01:07:29.800 --> 01:07:31.160
making contacts and demons.

01:07:31.160 --> 01:07:33.030
And pretty much all of
human history, people

01:07:33.030 --> 01:07:34.630
have tried to
persuade each other

01:07:34.630 --> 01:07:37.950
to be favorable in the ways
that are fair and unfair.

01:07:37.950 --> 01:07:40.110
I just predict that
all continues here.

01:07:40.110 --> 01:07:44.590
They will continue to use
mildly unreliable, but mostly

01:07:44.590 --> 01:07:48.789
reliable, mechanisms, as we
have, with some improvements

01:07:48.789 --> 01:07:50.080
to make whatever deal they can.

01:07:50.080 --> 01:07:52.080
And yes, they will try
to influence and persuade

01:07:52.080 --> 01:07:54.970
each other in licit
and illicit ways.

01:07:54.970 --> 01:07:57.040
It just seems like an
easy prediction to me.

01:07:57.040 --> 01:07:59.140
How could it be otherwise?

01:07:59.140 --> 01:08:02.190
[APPLAUSE]

