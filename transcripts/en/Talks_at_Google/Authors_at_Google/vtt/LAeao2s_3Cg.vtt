WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.796
[MUSIC PLAYING]

00:00:05.462 --> 00:00:07.170
SPEAKER: Thanks,
everyone, for joining us

00:00:07.170 --> 00:00:09.150
for this Talks at Google event.

00:00:09.150 --> 00:00:11.430
We have two fantastic
authors here

00:00:11.430 --> 00:00:14.940
for you today, Cory
Doctorow and John Scalzi.

00:00:14.940 --> 00:00:16.713
So we're graced
with their presence.

00:00:16.713 --> 00:00:20.580
[APPLAUSE]

00:00:20.580 --> 00:00:24.210
Cory Doctorow,
author of "Walkaway,"

00:00:24.210 --> 00:00:28.140
so Cory is a science fiction
author, activist, journalist,

00:00:28.140 --> 00:00:29.640
and blogger.

00:00:29.640 --> 00:00:34.080
He's the co-editor of Boing
Boing, that's boingboing.net,

00:00:34.080 --> 00:00:36.720
and the author of the
best-selling "Little Brother,"

00:00:36.720 --> 00:00:39.720
which is actually just
recently optioned by Paramount,

00:00:39.720 --> 00:00:43.410
so it's going to be a movie,
with Don Murphy producing--

00:00:43.410 --> 00:00:44.790
pretty cool stuff.

00:00:44.790 --> 00:00:47.700
He's also the former European
director of the Electronic

00:00:47.700 --> 00:00:49.770
Frontier Foundation.

00:00:49.770 --> 00:00:53.110
And he co-founded the
UK Open Rights Group.

00:00:53.110 --> 00:00:56.410
He was born in Toronto, Canada
and now lives in Burbank.

00:00:56.410 --> 00:00:57.910
[CHEER]

00:00:57.910 --> 00:00:59.289
That's for Toronto or for Bur--?

00:00:59.289 --> 00:01:00.080
That's for Toronto.

00:01:00.080 --> 00:01:00.760
[LAUGHTER]

00:01:00.760 --> 00:01:02.176
CORY DOCTOROW:
That's for Toronto.

00:01:02.176 --> 00:01:03.540
SPEAKER: No Burbank love.

00:01:03.540 --> 00:01:06.430
OK, and then we have
John Scalzi, author

00:01:06.430 --> 00:01:08.830
of "The Collapsing Empire."

00:01:08.830 --> 00:01:11.860
He's one of the most
popular and acclaimed SF

00:01:11.860 --> 00:01:15.250
to emerge in the last decade.

00:01:15.250 --> 00:01:17.290
His massively successful
debut, "Old Man's

00:01:17.290 --> 00:01:22.910
War--" SF as in science
fiction, not San Francisco--

00:01:22.910 --> 00:01:25.480
his massively successful
debut, "Old Man's War"

00:01:25.480 --> 00:01:28.150
won him the Science
Fiction's John W. Campbell

00:01:28.150 --> 00:01:30.580
Award for Best New Writer.

00:01:30.580 --> 00:01:32.230
His "New York
Times" best sellers

00:01:32.230 --> 00:01:35.110
include "The Last
Colony," "Fuzzy Nation,"

00:01:35.110 --> 00:01:38.170
and "Red Shirts," which
won 2013's Hugo Award

00:01:38.170 --> 00:01:41.770
for Best Novel and "Lock In."

00:01:41.770 --> 00:01:43.560
Material from his
widely read blog,

00:01:43.560 --> 00:01:47.530
"Whatever" has also earned
him two other Hugo Awards.

00:01:47.530 --> 00:01:50.462
He lives in Ohio with
his wife and daughter.

00:01:50.462 --> 00:01:52.878
And let's put our hands together
for them to welcome them.

00:01:52.878 --> 00:01:57.429
[APPLAUSE]

00:01:57.429 --> 00:01:58.470
JOHN SCALZI: Hello, Cory.

00:01:58.470 --> 00:01:59.130
CORY DOCTOROW: Hello, John.

00:01:59.130 --> 00:02:00.070
It's nice to see you again.

00:02:00.070 --> 00:02:01.430
JOHN SCALZI: I know, it's been
so long since I've seen you.

00:02:01.430 --> 00:02:02.460
CORY DOCTOROW: It has.

00:02:02.460 --> 00:02:04.170
So John is at the
very end of his tour,

00:02:04.170 --> 00:02:05.680
and I'm at the
very start of mine.

00:02:05.680 --> 00:02:08.009
John has come from
my future to warn me

00:02:08.009 --> 00:02:10.470
about the terrible catastrophes
in the coming week.

00:02:10.470 --> 00:02:12.990
JOHN SCALZI: Right, it's
hydrate and hand sanitizer--

00:02:12.990 --> 00:02:16.020
these are the two things that
will get you through most

00:02:16.020 --> 00:02:17.400
of these particular events.

00:02:17.400 --> 00:02:18.390
CORY DOCTOROW: Well,
hydration will get you

00:02:18.390 --> 00:02:19.950
through times of
no hand sanitizer

00:02:19.950 --> 00:02:22.050
better than hand
sanitizer would get you

00:02:22.050 --> 00:02:23.430
through times of no hydration.

00:02:23.430 --> 00:02:24.840
JOHN SCALZI: There's so much
truth in that statement.

00:02:24.840 --> 00:02:24.940
I can't--

00:02:24.940 --> 00:02:25.320
CORY DOCTOROW: There really is.

00:02:25.320 --> 00:02:26.400
JOHN SCALZI: I don't
even know where to start.

00:02:26.400 --> 00:02:27.170
CORY DOCTOROW: I
didn't even realize it

00:02:27.170 --> 00:02:28.900
till I was halfway through
that it's actually true.

00:02:28.900 --> 00:02:29.690
JOHN SCALZI: It
is actually true.

00:02:29.690 --> 00:02:32.010
You were trying to be
arch, and yet you've

00:02:32.010 --> 00:02:33.270
actually spoken a home truth.

00:02:33.270 --> 00:02:35.590
That is really useful to
people who are on the--

00:02:35.590 --> 00:02:36.210
CORY DOCTOROW: Don't
drink hand sanitizer.

00:02:36.210 --> 00:02:37.876
JOHN SCALZI: Don't
drink hand sanitizer.

00:02:37.876 --> 00:02:40.170
I mean, no matter
how fruity it smells,

00:02:40.170 --> 00:02:41.564
it's just going to end in pain.

00:02:41.564 --> 00:02:42.730
CORY DOCTOROW: That's right.

00:02:42.730 --> 00:02:43.771
JOHN SCALZI: But you do--

00:02:43.771 --> 00:02:45.282
I mean, you do see
a lot of people,

00:02:45.282 --> 00:02:46.490
and you shake a lot of hands.

00:02:46.490 --> 00:02:48.060
And the very first time
that I ever went on tour,

00:02:48.060 --> 00:02:49.980
I shook somebody's
hand in San Diego.

00:02:49.980 --> 00:02:53.130
And the next thing I knew, I
was in Minneapolis and Phoenix

00:02:53.130 --> 00:02:54.870
was somewhere in between that.

00:02:54.870 --> 00:02:56.952
And it's like, I
can't do that again.

00:02:56.952 --> 00:02:58.410
I don't know what
I did in Phoenix,

00:02:58.410 --> 00:03:01.860
but I can't ever go
back to that city now.

00:03:01.860 --> 00:03:05.400
CORY DOCTOROW: So John,
you wrote this book,

00:03:05.400 --> 00:03:06.480
"The Collapsing Empire."

00:03:06.480 --> 00:03:07.479
JOHN SCALZI: Yes, I did.

00:03:07.479 --> 00:03:09.420
CORY DOCTOROW: A kind
of eco-catastrophe

00:03:09.420 --> 00:03:11.400
that you didn't realize
was an eco-catastrophe

00:03:11.400 --> 00:03:12.990
until the reviews
started coming in.

00:03:12.990 --> 00:03:14.531
JOHN SCALZI: Yeah,
what happened was,

00:03:14.531 --> 00:03:18.240
this is the classic idea
of the author so fixated

00:03:18.240 --> 00:03:22.680
on their own specific idea that
they don't really think about,

00:03:22.680 --> 00:03:25.830
necessarily, about the obvious
wider implications that

00:03:25.830 --> 00:03:27.049
are clear to everyone else.

00:03:27.049 --> 00:03:29.340
In my specific case, when I
was writing "The Collapsing

00:03:29.340 --> 00:03:33.300
Empire," I was thinking
about the age of sail

00:03:33.300 --> 00:03:38.250
and the age of empires,
basically between the 15th

00:03:38.250 --> 00:03:41.740
through 18th
centuries in Europe.

00:03:41.740 --> 00:03:44.370
And what I was
thinking about, what

00:03:44.370 --> 00:03:47.580
would happen to all
those empires in Europe--

00:03:47.580 --> 00:03:50.520
Portugal, the UK, Spain--

00:03:50.520 --> 00:03:54.810
if all of a sudden, the jet
stream and the ocean currents

00:03:54.810 --> 00:03:57.697
just suddenly went away,
or shifted so significantly

00:03:57.697 --> 00:03:59.280
that all the things
that they took for

00:03:59.280 --> 00:04:01.654
granted about how they were
going to get around the world

00:04:01.654 --> 00:04:05.160
to get to the New World
or to get to Japan,

00:04:05.160 --> 00:04:07.200
just suddenly disappeared.

00:04:07.200 --> 00:04:09.240
And this is relevant to
me because I created--

00:04:09.240 --> 00:04:12.390
because I strongly believe
that the speed of light

00:04:12.390 --> 00:04:14.990
is not only a good idea,
but actually the law,

00:04:14.990 --> 00:04:17.490
and that you wouldn't want to
go close to the speed of light

00:04:17.490 --> 00:04:19.380
anyway, because anytime
you hit something,

00:04:19.380 --> 00:04:21.700
space is only mostly empty.

00:04:21.700 --> 00:04:23.700
So that when you hit
something, of course, boom,

00:04:23.700 --> 00:04:26.110
that all turns into
energy, and you're doomed.

00:04:26.110 --> 00:04:30.150
So I created this thing
called the "flow," which

00:04:30.150 --> 00:04:32.762
is a sort of
extra-dimensional conduit

00:04:32.762 --> 00:04:35.220
that gets you from one place
to another, because it doesn't

00:04:35.220 --> 00:04:37.350
have to obey the rules of
this particular universe,

00:04:37.350 --> 00:04:39.210
because it sort of
sits on top of it.

00:04:39.210 --> 00:04:41.910
It's basically a cheat, but
a very interesting cheat.

00:04:41.910 --> 00:04:43.980
But it works like
ocean currents,

00:04:43.980 --> 00:04:46.830
or it works like the jet stream.

00:04:46.830 --> 00:04:49.890
And it's a feature
of the universe

00:04:49.890 --> 00:04:51.820
that we have no control over.

00:04:51.820 --> 00:04:56.269
And so they built this
entire empire using the flow,

00:04:56.269 --> 00:04:57.810
just assuming that
the flow is always

00:04:57.810 --> 00:05:00.150
going to be there, because
as far as they know,

00:05:00.150 --> 00:05:01.410
it always has been.

00:05:01.410 --> 00:05:04.920
But the universe doesn't care
what you think about permanence

00:05:04.920 --> 00:05:06.271
or what you need.

00:05:06.271 --> 00:05:08.520
It's basically just going
to do what it's going to do.

00:05:08.520 --> 00:05:10.150
And eventually the
flow goes away.

00:05:10.150 --> 00:05:12.300
So I'm busy thinking
about these parallels

00:05:12.300 --> 00:05:14.250
to ocean currents and the flow.

00:05:14.250 --> 00:05:18.570
And people are coming up
to me at these events,

00:05:18.570 --> 00:05:20.940
and they're going, "It's
about oil, isn't it?"

00:05:20.940 --> 00:05:25.800
And I'm, like, I guess it is,
because it's the thing that

00:05:25.800 --> 00:05:27.820
happens where you have--

00:05:27.820 --> 00:05:30.810
you write something, and
you put it out in the world.

00:05:30.810 --> 00:05:33.420
And it's no longer just
exclusively in your brain.

00:05:33.420 --> 00:05:35.160
It is now in
dialogue with what's

00:05:35.160 --> 00:05:36.759
in the brain of somebody else.

00:05:36.759 --> 00:05:38.550
So the person who's
looking at it is going,

00:05:38.550 --> 00:05:40.060
this is obviously about oil.

00:05:40.060 --> 00:05:42.180
This is obviously
about climate change.

00:05:42.180 --> 00:05:44.100
This is obviously
about such and such.

00:05:44.100 --> 00:05:46.540
Sometimes they can get
really wacky about it.

00:05:46.540 --> 00:05:48.360
But other times, it's like, yep.

00:05:48.360 --> 00:05:51.210
Because I also live in the now.

00:05:51.210 --> 00:05:54.660
And I do actually think
about oil and climate change.

00:05:54.660 --> 00:05:57.000
And even if I'm not thinking
about them directly,

00:05:57.000 --> 00:06:00.660
obviously, that sort of stuff
is going to seep into what I do.

00:06:00.660 --> 00:06:02.910
CORY DOCTOROW: I also wonder
if there isn't a parallel

00:06:02.910 --> 00:06:07.140
to be drawn, though, with some
sort of theory-free knowledge.

00:06:07.140 --> 00:06:10.710
The thing that brings all
these people into catastrophe

00:06:10.710 --> 00:06:14.460
is that they don't really
know how the flow works.

00:06:14.460 --> 00:06:16.140
But it's worked so
well for so long

00:06:16.140 --> 00:06:17.970
that they assume
it'll be stable.

00:06:17.970 --> 00:06:19.560
And we have a lot
of things that we

00:06:19.560 --> 00:06:22.380
do that are kind of folk
ways rather than reality.

00:06:22.380 --> 00:06:25.860
We'll A/B split our way
into some optimal pattern,

00:06:25.860 --> 00:06:27.720
that we don't really
know why it works.

00:06:27.720 --> 00:06:30.210
But it's stable for a long
time, and so we build up

00:06:30.210 --> 00:06:31.380
big edifices on it.

00:06:31.380 --> 00:06:33.900
And then all of a sudden,
it changes or turns out

00:06:33.900 --> 00:06:34.680
that it's fragile.

00:06:34.680 --> 00:06:37.140
JOHN SCALZI: What happens
is, like an example,

00:06:37.140 --> 00:06:38.190
science fiction fandom--

00:06:38.190 --> 00:06:40.440
there's this saying
that if you do something

00:06:40.440 --> 00:06:42.190
once it's a tradition,
if you do it twice,

00:06:42.190 --> 00:06:43.500
It's a hallowed tradition.

00:06:43.500 --> 00:06:45.852
And what that means is
that people get so used

00:06:45.852 --> 00:06:47.310
to doing things
heuristically, they

00:06:47.310 --> 00:06:50.940
don't even question whether
that process makes sense outside

00:06:50.940 --> 00:06:53.820
of that specific thing.

00:06:53.820 --> 00:06:54.390
And we do.

00:06:54.390 --> 00:06:56.160
As humans, we do things
so heuristically.

00:06:56.160 --> 00:06:57.000
It's like, why do you do this?

00:06:57.000 --> 00:06:58.125
Because it's always worked.

00:06:58.125 --> 00:06:59.520
Why do you do it this way?

00:06:59.520 --> 00:07:01.500
Because when I did it the other
way, it didn't work the way

00:07:01.500 --> 00:07:03.458
I wanted it to, so I'm
always going to do this.

00:07:03.458 --> 00:07:05.441
Can you explain why this
works the way it does?

00:07:05.441 --> 00:07:06.690
It just works the way it does.

00:07:06.690 --> 00:07:07.981
Stop asking me these questions.

00:07:07.981 --> 00:07:09.450
I have things to do.

00:07:09.450 --> 00:07:13.260
We do things so heuristically
that what we end up doing is,

00:07:13.260 --> 00:07:17.384
we become trapped to a
process without understanding

00:07:17.384 --> 00:07:18.300
how the process works.

00:07:18.300 --> 00:07:22.560
And that's of course,
how we fall down.

00:07:22.560 --> 00:07:25.267
Now, let's segue a little
bit into "Walkaway."

00:07:25.267 --> 00:07:26.100
CORY DOCTOROW: Sure.

00:07:26.100 --> 00:07:28.980
JOHN SCALZI: And we're talking
about one of the things

00:07:28.980 --> 00:07:33.630
that you do in "Walkaway"
is that you actually

00:07:33.630 --> 00:07:37.350
posit that a lot of
people are actually

00:07:37.350 --> 00:07:42.330
going to cooperate in trying
times, rather than go,

00:07:42.330 --> 00:07:44.550
oh, no, it's every
person for themselves.

00:07:44.550 --> 00:07:47.060
And let's get at it.

00:07:47.060 --> 00:07:50.220
Now there are some people
who would say, heuristically,

00:07:50.220 --> 00:07:54.070
that when you go
and have a crisis,

00:07:54.070 --> 00:07:55.634
the thing that you
should do is just

00:07:55.634 --> 00:07:57.300
sort of look out for
yourself and assume

00:07:57.300 --> 00:07:59.430
everybody else is going to
take care of themselves.

00:07:59.430 --> 00:07:59.940
Do you--

00:07:59.940 --> 00:08:00.773
[INTERPOSING VOICES]

00:08:00.773 --> 00:08:04.980
CORY DOCTOROW: Yeah, so I mean,
the theory that 99.9% of people

00:08:04.980 --> 00:08:11.149
are total bastards has a really
significant statistical problem

00:08:11.149 --> 00:08:12.690
with it, which is
that the people who

00:08:12.690 --> 00:08:14.790
evince this theory
almost always also say,

00:08:14.790 --> 00:08:17.100
"but not you, me, and
all the people we know."

00:08:17.100 --> 00:08:20.182
So the likelihood, in a
world where 99.9% of people

00:08:20.182 --> 00:08:22.140
are total bastards, that
everyone that you know

00:08:22.140 --> 00:08:24.460
isn't is really low.

00:08:24.460 --> 00:08:26.585
It's much more likely that
the people that you know

00:08:26.585 --> 00:08:30.330
are a representative selection
of the people around them,

00:08:30.330 --> 00:08:32.940
and that they have
the dual nature

00:08:32.940 --> 00:08:34.919
of all fragile and
imperfect humans, which

00:08:34.919 --> 00:08:39.030
is to say that on a good day,
they rise to the occasion.

00:08:39.030 --> 00:08:41.130
And on a bad day, they
do things that haunt them

00:08:41.130 --> 00:08:42.659
forever as their regrets.

00:08:42.659 --> 00:08:47.370
And what really matters
in terms of society

00:08:47.370 --> 00:08:50.100
is not how it works
when it's working well,

00:08:50.100 --> 00:08:53.730
but what lessons it teaches
us that come to mind

00:08:53.730 --> 00:08:55.920
easily when things go wrong.

00:08:55.920 --> 00:08:59.310
The liquidation preference
for a civilization

00:08:59.310 --> 00:09:02.490
that's based on every
person for themselves,

00:09:02.490 --> 00:09:06.090
my gain is your loss,
let's all be rational,

00:09:06.090 --> 00:09:08.280
self-interested actors, and
through that will emerge

00:09:08.280 --> 00:09:11.880
some kind of competitive
but optimized world,

00:09:11.880 --> 00:09:14.520
is that when things go
wrong, you see your neighbors

00:09:14.520 --> 00:09:16.920
as your competitors and not
as your potential saviors,

00:09:16.920 --> 00:09:20.190
or people with whom you have
some kind of mutual destiny

00:09:20.190 --> 00:09:22.710
or mutual responsibility to.

00:09:22.710 --> 00:09:24.990
And all of these
stories that we have

00:09:24.990 --> 00:09:27.990
through our history, of
civilizations falling in ways

00:09:27.990 --> 00:09:30.630
large and small, whether that's
just the lights going out

00:09:30.630 --> 00:09:32.292
because the power
plant collapsed,

00:09:32.292 --> 00:09:33.750
or because we had
a horrible quake,

00:09:33.750 --> 00:09:37.740
or whatever, or all the way
up to the fall of the empire,

00:09:37.740 --> 00:09:39.420
every one of those
situations was not

00:09:39.420 --> 00:09:41.880
resolved by the people
who ran to the hills.

00:09:41.880 --> 00:09:43.830
By definition, when
you run to the hills,

00:09:43.830 --> 00:09:45.430
you do not solve those problems.

00:09:45.430 --> 00:09:48.410
It's all solved by the
people who run to the middle

00:09:48.410 --> 00:09:49.950
to see how they can help.

00:09:49.950 --> 00:09:52.410
And coordinating
that help is hard.

00:09:52.410 --> 00:09:54.810
And I always feel
like there's a lot

00:09:54.810 --> 00:09:57.930
of drama latent in
the story of people

00:09:57.930 --> 00:10:00.690
who agree with each other
on what should be done,

00:10:00.690 --> 00:10:03.900
but disagree about
how it should be done,

00:10:03.900 --> 00:10:06.990
and that it's actually a
much more compelling drama

00:10:06.990 --> 00:10:10.710
in the end then the easy drama
of people who actually disagree

00:10:10.710 --> 00:10:11.940
about what should be done.

00:10:11.940 --> 00:10:15.000
The man versus man story
is a lot less interesting

00:10:15.000 --> 00:10:17.010
than, we're all on the
same side but I hate you

00:10:17.010 --> 00:10:18.870
and I want to kill
you story, which

00:10:18.870 --> 00:10:20.850
is something that is
much harder to resolve,

00:10:20.850 --> 00:10:22.725
as anyone who's ever
gone to Christmas dinner

00:10:22.725 --> 00:10:25.230
with their family can tell you.

00:10:25.230 --> 00:10:28.050
And so "Walkaway" is
a story about people

00:10:28.050 --> 00:10:31.320
who are consciously
trying to form

00:10:31.320 --> 00:10:34.080
societies that fail gracefully,
instead of societies

00:10:34.080 --> 00:10:35.100
that work well.

00:10:35.100 --> 00:10:39.210
And that they're trying to use
the coordinative, latent power

00:10:39.210 --> 00:10:41.189
of technology to get there.

00:10:41.189 --> 00:10:42.730
Rather than thinking
about technology

00:10:42.730 --> 00:10:45.600
as the thing that helps us
manufacture or communicate,

00:10:45.600 --> 00:10:47.308
they're thinking about
it as a thing that

00:10:47.308 --> 00:10:49.870
lets us add our labor
one to the other,

00:10:49.870 --> 00:10:52.480
even if we don't all agree
on what's to be done.

00:10:52.480 --> 00:10:55.230
And if it turns out that I
throw some code or some work

00:10:55.230 --> 00:10:58.050
into a project that turns
out to be superfluous to it,

00:10:58.050 --> 00:10:58.560
that's OK.

00:10:58.560 --> 00:11:00.490
We can just leave
it by the wayside,

00:11:00.490 --> 00:11:04.522
or factor it out in
future revisions.

00:11:04.522 --> 00:11:06.480
Rather than having someone
sit down and tell us

00:11:06.480 --> 00:11:08.910
all what to do, we all do what
we think needs to be done.

00:11:08.910 --> 00:11:11.340
And we have a tool that
lets the parts of it that

00:11:11.340 --> 00:11:13.140
are useful glom together.

00:11:13.140 --> 00:11:15.690
So today, we can build
an encyclopedia the way

00:11:15.690 --> 00:11:17.730
that we used to
apply bureaucracy

00:11:17.730 --> 00:11:20.430
to the problem of
building a bake sale.

00:11:20.430 --> 00:11:22.710
And tomorrow, maybe we
could build skyscrapers

00:11:22.710 --> 00:11:24.990
and space programs that
way, without the kind

00:11:24.990 --> 00:11:27.090
of coercive
hierarchical control.

00:11:27.090 --> 00:11:29.644
Maybe we can use
additive labor to do it.

00:11:29.644 --> 00:11:30.810
I see you shaking your head.

00:11:30.810 --> 00:11:33.543
Perhaps you should
read the book.

00:11:33.543 --> 00:11:36.259
AUDIENCE: [INAUDIBLE] build
a Wikipedia skyscraper.

00:11:36.259 --> 00:11:37.800
CORY DOCTOROW: But
I think there were

00:11:37.800 --> 00:11:40.008
a lot of people who said
they didn't want a Wikipedia

00:11:40.008 --> 00:11:41.730
encyclopedia for about 10 years.

00:11:41.730 --> 00:11:42.660
And there were a
lot of people who

00:11:42.660 --> 00:11:44.410
said that they didn't
want a GNU operating

00:11:44.410 --> 00:11:45.900
system for about 10 years.

00:11:45.900 --> 00:11:48.900
And they were really right
for the first 10 years.

00:11:48.900 --> 00:11:50.280
That's the amazing thing.

00:11:50.280 --> 00:11:54.360
It's as Jimmy Wales says, "It is
a complete disaster in theory.

00:11:54.360 --> 00:11:57.320
It only works in practice."

00:11:57.320 --> 00:11:59.930
JOHN SCALZI: Here's a question.

00:11:59.930 --> 00:12:01.910
And one of the things
that you can say

00:12:01.910 --> 00:12:05.000
is, all right, so the
idea that cooperation

00:12:05.000 --> 00:12:07.790
is kind of a wonderful
thing not to be disputed,

00:12:07.790 --> 00:12:10.340
but how do you keep
a wonderful thing,

00:12:10.340 --> 00:12:12.380
a wonderful communal
thing, from basically

00:12:12.380 --> 00:12:13.702
being swamped by the bastards?

00:12:13.702 --> 00:12:15.410
CORY DOCTOROW: Well,
and that's a problem

00:12:15.410 --> 00:12:19.250
that the people in this
story really contend with.

00:12:19.250 --> 00:12:23.390
We have a new move
in the 21st century

00:12:23.390 --> 00:12:26.270
for resolving disputes,
which is forking.

00:12:26.270 --> 00:12:27.720
I mean, it's not entirely new.

00:12:27.720 --> 00:12:29.610
It's just lower cost
than it's ever been.

00:12:29.610 --> 00:12:31.760
There's this thing
in Canada where

00:12:31.760 --> 00:12:34.280
the further west you go,
the weirder the Mennonites

00:12:34.280 --> 00:12:39.560
get, because Mennonitism
is a schematic faith,

00:12:39.560 --> 00:12:43.640
because it has this article
that you shouldn't be worldly.

00:12:43.640 --> 00:12:46.820
But worldly is not a
crisply defined idea.

00:12:46.820 --> 00:12:48.770
And so what's one
person's worldliness

00:12:48.770 --> 00:12:50.360
is someone else's
non-worldliness.

00:12:50.360 --> 00:12:52.910
I have a friend who grew up
in a Mennonite community that

00:12:52.910 --> 00:12:55.370
was founded by people who
disagreed about whether or not

00:12:55.370 --> 00:12:57.260
vertical blinds were cool.

00:12:57.260 --> 00:12:58.279
They thought they were.

00:12:58.279 --> 00:13:00.570
The people who are old order
thought they shouldn't be.

00:13:00.570 --> 00:13:02.117
And so they moved west.

00:13:02.117 --> 00:13:03.950
So you get all the way
west to Saskatchewan,

00:13:03.950 --> 00:13:06.241
and there's that wonderful
science fiction writer named

00:13:06.241 --> 00:13:09.350
Karl Schroeder, who is a second,
multigenerational Mennonite.

00:13:09.350 --> 00:13:12.320
His father was a
Mennonite TV repairman.

00:13:12.320 --> 00:13:18.740
And so this was like somehow
reconcilable with this faith.

00:13:18.740 --> 00:13:21.980
So that's a very expensive
way of schisming,

00:13:21.980 --> 00:13:24.420
but we have a much cheaper
way of schisming now,

00:13:24.420 --> 00:13:26.530
which is that we
can fork the code.

00:13:26.530 --> 00:13:29.090
We can keep the code
bases reconciled,

00:13:29.090 --> 00:13:32.120
but we can add
stuff on top of it.

00:13:32.120 --> 00:13:37.700
And so the kind of Debian
into Ubuntu model of schisming

00:13:37.700 --> 00:13:39.800
is a much more interesting
one, because it

00:13:39.800 --> 00:13:42.120
allows for a lot of
experimentation at the margin.

00:13:42.120 --> 00:13:44.990
You can do a lot of parallel
universe stuff, where

00:13:44.990 --> 00:13:47.390
it's like, what if
we reran Debian,

00:13:47.390 --> 00:13:49.340
but we gave up on
this principle,

00:13:49.340 --> 00:13:51.115
or we included some
non-free repositories,

00:13:51.115 --> 00:13:55.070
or we did something else
that was key core to Debian.

00:13:55.070 --> 00:13:57.260
And then you get to
find out how's it work?

00:13:57.260 --> 00:13:59.794
Instead of having a kind
of abstract argument,

00:13:59.794 --> 00:14:01.710
you can actually try it,
and see what happens.

00:14:01.710 --> 00:14:04.350
JOHN SCALZI: So it's like a
choose-your-own adventure.

00:14:04.350 --> 00:14:07.060
CORY DOCTOROW: Or like
multiple parallel universes,

00:14:07.060 --> 00:14:10.870
and so the walkways, for
better and for worse--

00:14:10.870 --> 00:14:12.470
the thing about
walkaway, it's a sort

00:14:12.470 --> 00:14:15.230
of Burning Man-ish subculture.

00:14:15.230 --> 00:14:17.690
But what it is, is they
walk away from the world.

00:14:17.690 --> 00:14:19.370
They find brownfield
sites that have

00:14:19.370 --> 00:14:23.150
been left behind by the collapse
of industrial civilization.

00:14:23.150 --> 00:14:24.890
They harvest the
waste stream that's

00:14:24.890 --> 00:14:28.490
exhausted off what's left of
post-industrial civilization.

00:14:28.490 --> 00:14:30.560
And using cool tools,
they build fully

00:14:30.560 --> 00:14:32.390
automated leisure communism.

00:14:32.390 --> 00:14:35.180
And if someone comes along
and says, that patch of dirt

00:14:35.180 --> 00:14:36.980
is mine, and that
garbage that you're using

00:14:36.980 --> 00:14:38.990
doesn't belong to you,
rather than argue about it,

00:14:38.990 --> 00:14:40.156
they just go somewhere else.

00:14:40.156 --> 00:14:44.720
Because all garbage and patches
of blighted land are fungible.

00:14:44.720 --> 00:14:46.470
And so they just go
find somewhere else

00:14:46.470 --> 00:14:48.584
to try out their experiment.

00:14:48.584 --> 00:14:50.750
And they're able to do this
for better or for worse.

00:14:50.750 --> 00:14:53.930
And the worse is
that there are times

00:14:53.930 --> 00:14:56.330
when doing that actually
does cost them something.

00:14:56.330 --> 00:14:58.880
And they can't
always reconcile it.

00:14:58.880 --> 00:15:02.090
And then the people
who have kicked them

00:15:02.090 --> 00:15:04.796
off plot of land A
sometimes aren't happy

00:15:04.796 --> 00:15:06.170
with them walking
to plot of land

00:15:06.170 --> 00:15:08.420
B. Sometimes they're mortally
offended that they've

00:15:08.420 --> 00:15:09.020
walked off.

00:15:09.020 --> 00:15:12.270
And in particular, when the
walkaways who are walking away

00:15:12.270 --> 00:15:16.640
are scientists who've taken the
practical cure for death out

00:15:16.640 --> 00:15:20.420
of the default world, and kind
of stolen fire from the gods,

00:15:20.420 --> 00:15:24.100
and brought it to everyone
else, in a kind of Aaron Swartz

00:15:24.100 --> 00:15:28.640
Sci-Hub kind of exfiltration
of the technology

00:15:28.640 --> 00:15:30.704
necessary for immortality,
the super-rich

00:15:30.704 --> 00:15:32.120
realize that they're
going to have

00:15:32.120 --> 00:15:34.850
to spend the rest
of eternity with us,

00:15:34.850 --> 00:15:38.000
and become really,
really upset about it.

00:15:38.000 --> 00:15:40.610
And walking away ceases
to be a viable strategy.

00:15:40.610 --> 00:15:42.910
Now they have to
start running away.

00:15:42.910 --> 00:15:45.680
JOHN SCALZI: I like
watching you talk.

00:15:45.680 --> 00:15:48.290
Because the funny thing
about Cory is, you're like,

00:15:48.290 --> 00:15:50.300
Cory, here's a thought.

00:15:50.300 --> 00:15:52.420
And he goes, so, thwoomp.

00:15:52.420 --> 00:15:59.990
And it comes out, 10,000 ideas
in this stream of-- like you're

00:15:59.990 --> 00:16:01.047
the firehose of ideas.

00:16:01.047 --> 00:16:02.630
CORY DOCTOROW: Oh,
that's kind of you.

00:16:02.630 --> 00:16:03.340
JOHN SCALZI: But
it's true though.

00:16:03.340 --> 00:16:06.210
And so when we were first
talking, and they were, like,

00:16:06.210 --> 00:16:07.600
we want to pair
you up with Cory.

00:16:07.600 --> 00:16:08.766
I'm, like, yeah, sign me up.

00:16:08.766 --> 00:16:12.557
I am the carbon fuel or the
carbon rod to his nuclear fuel.

00:16:12.557 --> 00:16:14.390
Because he's going to
go all over the place,

00:16:14.390 --> 00:16:16.651
and I'm going to be, OK.

00:16:16.651 --> 00:16:17.150
Here we go.

00:16:17.150 --> 00:16:19.010
CORY DOCTOROW: I
love this analogy.

00:16:19.010 --> 00:16:20.990
I love that you're
the inert carbon rod.

00:16:27.120 --> 00:16:30.750
JOHN SCALZI: But,
actually, here's

00:16:30.750 --> 00:16:33.540
the thing that we had talked
about in previous things.

00:16:33.540 --> 00:16:37.040
And I'm going to approach
it to you a little bit.

00:16:37.040 --> 00:16:39.000
One of the things that
we were talking about

00:16:39.000 --> 00:16:43.230
is one of the issues
of way back when,

00:16:43.230 --> 00:16:46.500
with primogeniture, and how
that related to colonialism.

00:16:46.500 --> 00:16:49.050
Primogeniture means
only one person,

00:16:49.050 --> 00:16:50.760
usually the son, inherits.

00:16:50.760 --> 00:16:54.060
And then colonialism to an
extent solved that problem,

00:16:54.060 --> 00:16:56.565
because you could go from--

00:16:56.565 --> 00:16:59.550
you could take those second
and third sons or whatever,

00:16:59.550 --> 00:17:03.870
and have them find their own
fortunes out in the world.

00:17:03.870 --> 00:17:06.119
And eventually, it
exhausts itself,

00:17:06.119 --> 00:17:08.520
because there's only so
much world out there.

00:17:08.520 --> 00:17:11.030
And that leads to
a kind of collapse

00:17:11.030 --> 00:17:13.650
that caused, for example,
World War I and then

00:17:13.650 --> 00:17:16.140
as a consequence, World War II.

00:17:16.140 --> 00:17:19.290
But let me apply that to
the world of the walkaways.

00:17:19.290 --> 00:17:21.869
One of the posits here
is that when you fork,

00:17:21.869 --> 00:17:23.640
you can just go somewhere else.

00:17:23.640 --> 00:17:27.150
Sooner or later, you'll
run out of somewhere else.

00:17:27.150 --> 00:17:32.010
CORY DOCTOROW: Yes,
so in that regard--

00:17:32.010 --> 00:17:35.370
so to kind of reiterate this
earlier part, Thomas Piketty,

00:17:35.370 --> 00:17:36.810
in "Capital of
the 21st Century,"

00:17:36.810 --> 00:17:40.170
he hypothesizes that
the age of colonialism

00:17:40.170 --> 00:17:42.690
allowed every family to create
as many dynastic fortunes

00:17:42.690 --> 00:17:44.580
as they had sons, and
that eventually, you

00:17:44.580 --> 00:17:48.530
run out of colonies that you can
get dynastic fortunes out of.

00:17:48.530 --> 00:17:52.140
But the dynastic fortunes had
a character of rivalrousness.

00:17:52.140 --> 00:17:54.610
The fortune that I have is
a fortune you can't have.

00:17:54.610 --> 00:17:59.130
What the walkways get is like
a kind of federated universe

00:17:59.130 --> 00:18:02.820
of slightly different
variations on their ethics,

00:18:02.820 --> 00:18:06.730
and on their design aesthetics,
and on their practices,

00:18:06.730 --> 00:18:09.090
their engineering practices,
their social practices.

00:18:09.090 --> 00:18:12.870
And so you're right,
there may be some element

00:18:12.870 --> 00:18:16.140
that is optimal for you
that isn't perfectly suited

00:18:16.140 --> 00:18:17.520
in any of the places.

00:18:17.520 --> 00:18:21.150
But they're also not
super intensely specified.

00:18:21.150 --> 00:18:23.790
So the likelihood
that there's something

00:18:23.790 --> 00:18:27.150
that's really important to
you that no one will tolerate,

00:18:27.150 --> 00:18:28.710
and you can't find
anywhere to do it,

00:18:28.710 --> 00:18:31.920
that's a pretty low likelihood.

00:18:31.920 --> 00:18:34.780
And this coordination, it's
a really remarkable thing.

00:18:34.780 --> 00:18:37.890
In fact, one of the
impetuses for this book

00:18:37.890 --> 00:18:40.710
was, I think Google did.

00:18:40.710 --> 00:18:43.470
You guys built a data
center in Belgium

00:18:43.470 --> 00:18:46.710
in a valley where
two-thirds of the time, you

00:18:46.710 --> 00:18:47.760
don't need chillers.

00:18:47.760 --> 00:18:49.432
The ambient temperature
is low enough

00:18:49.432 --> 00:18:50.640
that you don't need chillers.

00:18:50.640 --> 00:18:53.014
And the rest of the time, they
just shut off the servers,

00:18:53.014 --> 00:18:54.870
because the file
system is distributed,

00:18:54.870 --> 00:18:56.970
and you can
coordinate the labor.

00:18:56.970 --> 00:18:59.910
And this was a remarkable
realization for me,

00:18:59.910 --> 00:19:06.060
that we could use coordination
to simply shunt around

00:19:06.060 --> 00:19:10.200
resources to wherever
they're least environmentally

00:19:10.200 --> 00:19:13.246
catastrophic, wherever they're
kind of most harmonious

00:19:13.246 --> 00:19:14.370
with the rest of the world.

00:19:14.370 --> 00:19:16.740
And we could realize
these new efficiencies

00:19:16.740 --> 00:19:20.160
that really challenge
the notion that you

00:19:20.160 --> 00:19:23.340
can't have infinite
growth in a finite world.

00:19:23.340 --> 00:19:27.325
Infinite growth implies that you
don't have any kind of process

00:19:27.325 --> 00:19:29.700
automation, and you don't have
any changes in what people

00:19:29.700 --> 00:19:33.720
want, and that will
just keep growing.

00:19:33.720 --> 00:19:36.491
We'll keep making cars that
have x tons of steel in them,

00:19:36.491 --> 00:19:37.740
and we can do that infinitely.

00:19:37.740 --> 00:19:39.161
That's obviously not true.

00:19:39.161 --> 00:19:41.160
But there doesn't seem
to be any bottom in sight

00:19:41.160 --> 00:19:44.130
as to how few tons of
steel you can put in a car.

00:19:44.130 --> 00:19:48.000
And so in that regard, we can
get some extremely flexible

00:19:48.000 --> 00:19:49.090
growth out of there.

00:19:49.090 --> 00:19:51.090
And then when you add to
that using coordination

00:19:51.090 --> 00:19:53.880
to move cars and people close to
each other when they need them,

00:19:53.880 --> 00:19:55.830
and then apart when
they don't, you

00:19:55.830 --> 00:19:59.250
can sure get a lot of cars,
peoples, miles, seats,

00:19:59.250 --> 00:20:02.370
without having to necessarily
multiply the number of tons

00:20:02.370 --> 00:20:05.925
of steel by the number of people
to get the number of cars.

00:20:05.925 --> 00:20:08.440
JOHN SCALZI: It's the effective
use of the cars as opposed

00:20:08.440 --> 00:20:09.720
to the sheer number of cars.

00:20:09.720 --> 00:20:12.300
CORY DOCTOROW:
Right, I mean, it's

00:20:12.300 --> 00:20:16.470
better than the mere
despotic dominion over a car

00:20:16.470 --> 00:20:18.870
that, after all, you then
have to take care of,

00:20:18.870 --> 00:20:22.770
and find a place to put, and
all the rest of it, which

00:20:22.770 --> 00:20:25.770
is inevitably the third best
car, or the fifth best car,

00:20:25.770 --> 00:20:27.960
as opposed to the very
best car for your needs,

00:20:27.960 --> 00:20:29.720
because you can't afford that.

00:20:29.720 --> 00:20:32.372
The interesting move
of science fiction,

00:20:32.372 --> 00:20:34.080
one of the best moves
of science fiction,

00:20:34.080 --> 00:20:36.480
is to take a
technological phenomenon

00:20:36.480 --> 00:20:39.570
and see if it can be extracted
from its social and economic

00:20:39.570 --> 00:20:41.400
context, and whether
it still works.

00:20:41.400 --> 00:20:44.010
This is steampunk,
like what does it

00:20:44.010 --> 00:20:46.880
mean if you could have the
machines with the factory?

00:20:46.880 --> 00:20:49.710
Mad scientists could
do productivity

00:20:49.710 --> 00:20:52.290
that are characteristic
of an assembly line,

00:20:52.290 --> 00:20:56.070
but they can do it all
alone in their labs.

00:20:56.070 --> 00:20:59.100
To imagine something
like fleet vehicles

00:20:59.100 --> 00:21:02.250
without market
capitalism, without even

00:21:02.250 --> 00:21:04.410
communal ownership,
that we're just

00:21:04.410 --> 00:21:07.320
a kind of epic phenomenon
of cooperative work

00:21:07.320 --> 00:21:09.210
without any
formalized structures,

00:21:09.210 --> 00:21:11.700
that's a really provocative
thought experiment,

00:21:11.700 --> 00:21:13.380
to imagine what
kind of arrangements

00:21:13.380 --> 00:21:14.280
we'd get out of that.

00:21:14.280 --> 00:21:16.680
JOHN SCALZI: I wish I had
a car, and a car drives up,

00:21:16.680 --> 00:21:18.540
and you go into your car, and
then you say, goodbye car.

00:21:18.540 --> 00:21:19.680
Thanks for driving me.

00:21:19.680 --> 00:21:22.180
CORY DOCTOROW: Right, and if
it turns out there are no cars,

00:21:22.180 --> 00:21:24.210
then some other thing
that you might want to do

00:21:24.210 --> 00:21:27.060
is brought to your attention
that doesn't require a car.

00:21:27.060 --> 00:21:29.700
There's a whole group of
people in "Walkaway" that

00:21:29.700 --> 00:21:35.820
are the remnants of an
investment bubble in zeppelins.

00:21:35.820 --> 00:21:39.030
And they, just
like 20 years ago,

00:21:39.030 --> 00:21:41.180
we had this
investment bubble that

00:21:41.180 --> 00:21:43.020
used pension funds
to teach humanities

00:21:43.020 --> 00:21:48.660
majors how to write
JavaScript, this bubble turns

00:21:48.660 --> 00:21:51.240
a whole ton of disaffected
post-millennials

00:21:51.240 --> 00:21:53.340
into airship
builders and pilots,

00:21:53.340 --> 00:21:56.760
but doesn't actually produce
a functional airship economy.

00:21:56.760 --> 00:21:59.970
And so a bunch of them just
start building airships.

00:21:59.970 --> 00:22:02.920
But they are
non-propelled airships.

00:22:02.920 --> 00:22:04.740
They have minimal impellers.

00:22:04.740 --> 00:22:06.840
And so they just go where
the winds are blowing.

00:22:06.840 --> 00:22:09.960
But because they were all part
of this global phenomenon,

00:22:09.960 --> 00:22:11.640
they kind of know
somewhere wherever

00:22:11.640 --> 00:22:13.020
the winds might blow them.

00:22:13.020 --> 00:22:14.790
And so it's a kind
of movable party.

00:22:14.790 --> 00:22:17.024
You sort of check to see
who's on the next airship

00:22:17.024 --> 00:22:18.690
through town, and
whether you know them.

00:22:18.690 --> 00:22:19.860
And when you get
on the airship, you

00:22:19.860 --> 00:22:22.230
check to see whether the next
town that the wind is blowing

00:22:22.230 --> 00:22:24.146
you to is a place where
there might be someone

00:22:24.146 --> 00:22:25.260
you want to hang out with.

00:22:25.260 --> 00:22:30.250
And the automation
marries the two.

00:22:30.250 --> 00:22:32.560
JOHN SCALZI: Fascinating.

00:22:32.560 --> 00:22:35.230
Now, do you think
there are antecedents?

00:22:35.230 --> 00:22:39.850
I mean not antecedents
in the human experience,

00:22:39.850 --> 00:22:43.990
but antecedents to what you're
doing in science fiction?

00:22:43.990 --> 00:22:45.970
I mean, one of the
things that I kind of see

00:22:45.970 --> 00:22:48.760
"Walkaway" being is almost
like the seed culture

00:22:48.760 --> 00:22:51.007
for in Banks' culture series.

00:22:51.007 --> 00:22:52.090
CORY DOCTOROW: Yeah, sure.

00:22:52.090 --> 00:22:55.120
Yeah, I think Banks
definitely was

00:22:55.120 --> 00:22:57.760
writing about what a
post-scarcity world would

00:22:57.760 --> 00:22:58.990
look like.

00:22:58.990 --> 00:23:01.600
But if there's a
difference in our angle,

00:23:01.600 --> 00:23:04.480
he's got this fait accompli.

00:23:04.480 --> 00:23:06.700
And I'm thinking about
the transitional state,

00:23:06.700 --> 00:23:09.220
which is a really interesting
moment to think about it.

00:23:09.220 --> 00:23:13.960
And his emphasis is
really on manufacture

00:23:13.960 --> 00:23:15.490
as opposed to coordination.

00:23:15.490 --> 00:23:20.400
So his magical
technology is the,

00:23:20.400 --> 00:23:23.110
to date still
rather fanciful idea

00:23:23.110 --> 00:23:25.330
that matter can be conjured.

00:23:25.330 --> 00:23:26.800
Organized matter
can be conjured up

00:23:26.800 --> 00:23:29.260
out of code, which
notwithstanding

00:23:29.260 --> 00:23:30.970
a few 3-D printers
around the margin

00:23:30.970 --> 00:23:35.890
is not a thing that we do very
reliably at mass scale yet.

00:23:35.890 --> 00:23:38.200
But for me, it doesn't
really matter if you've

00:23:38.200 --> 00:23:39.770
got 3-D printers in Walkaway.

00:23:39.770 --> 00:23:42.370
Walkaway works pretty good
even if all you've got

00:23:42.370 --> 00:23:44.890
is just people who
are assembling stuff.

00:23:44.890 --> 00:23:47.420
Because they're still able
to do process improvement.

00:23:47.420 --> 00:23:49.670
They're still able to
feedback to one another.

00:23:49.670 --> 00:23:52.120
They're still using
software and networks

00:23:52.120 --> 00:23:54.370
to take whatever it is
they can make and make it

00:23:54.370 --> 00:23:58.320
better on demand, continuously,
all around the world.

00:23:58.320 --> 00:24:02.050
So it's hardware that acts
like a software object.

00:24:02.050 --> 00:24:05.470
JOHN SCALZI: So basically
one of the things

00:24:05.470 --> 00:24:10.030
that we talked about earlier
is like the triangle, you said.

00:24:10.030 --> 00:24:11.559
You have process.

00:24:11.559 --> 00:24:12.350
Tell me, remind me.

00:24:12.350 --> 00:24:15.700
CORY DOCTOROW: Yeah, so the
triangle of post-scarcity,

00:24:15.700 --> 00:24:17.470
up here you have what we want.

00:24:17.470 --> 00:24:19.740
So Keynes wrote
this essay in 1930

00:24:19.740 --> 00:24:21.490
about how his grandchildren
would struggle

00:24:21.490 --> 00:24:24.010
to fill their lives after
the 15-hour work week was

00:24:24.010 --> 00:24:26.230
introduced, because
there would be no reason

00:24:26.230 --> 00:24:28.870
to work beyond that because
we could fill all our material

00:24:28.870 --> 00:24:29.680
wants.

00:24:29.680 --> 00:24:32.980
And the resolution to
Keynes's paradox today

00:24:32.980 --> 00:24:35.470
is that Keynes
dramatically underestimated

00:24:35.470 --> 00:24:37.060
how much people would want--

00:24:37.060 --> 00:24:40.300
that people's
desires were elastic,

00:24:40.300 --> 00:24:43.180
and responsive to
new material goods.

00:24:43.180 --> 00:24:44.702
Or a cynic might
say that people are

00:24:44.702 --> 00:24:46.660
amenable to marketing
messages, and want things

00:24:46.660 --> 00:24:47.440
that they don't really want.

00:24:47.440 --> 00:24:48.898
They can be convinced
in the moment

00:24:48.898 --> 00:24:51.214
that they want something that
actually and objectively,

00:24:51.214 --> 00:24:51.880
they don't want.

00:24:51.880 --> 00:24:55.030
But whatever your explanation
is, that's up in this corner.

00:24:55.030 --> 00:24:58.660
Down here, you have you
have the production.

00:24:58.660 --> 00:25:01.900
But over here, you
have the ability

00:25:01.900 --> 00:25:04.760
to coordinate what we want
with what we can make.

00:25:04.760 --> 00:25:07.990
And the thing that allows
the Port of Guangzhou

00:25:07.990 --> 00:25:10.240
to fire a shipping
container full of Happy Meal

00:25:10.240 --> 00:25:15.310
toys at the Port of Los Angeles,
one a second, 365 days a year,

00:25:15.310 --> 00:25:18.190
like a rail gun
firing tchotchkes,

00:25:18.190 --> 00:25:19.850
is that's coordination.

00:25:19.850 --> 00:25:22.870
These long supply chains
are all built up out

00:25:22.870 --> 00:25:24.300
of coordination technology.

00:25:24.300 --> 00:25:26.350
It's a marvel to behold.

00:25:26.350 --> 00:25:29.700
And it's such an everyday marvel
that we don't even notice it.

00:25:29.700 --> 00:25:32.222
And we think about 3-D
printers as being miraculous.

00:25:32.222 --> 00:25:34.180
What's really miraculous
is that McDonald's can

00:25:34.180 --> 00:25:38.610
sell you a burger with the
beef of 1,000 cows in it,

00:25:38.610 --> 00:25:42.490
that we can do these
incredible, complex, seemingly

00:25:42.490 --> 00:25:44.800
fragile supply chains that
nevertheless are really

00:25:44.800 --> 00:25:47.770
robust against even
the burgeoning climate

00:25:47.770 --> 00:25:50.220
problems of long-distance
shipping, and so on.

00:25:50.220 --> 00:25:51.327
JOHN SCALZI: Sure.

00:25:51.327 --> 00:25:53.410
And the reason I bring
that up is because you when

00:25:53.410 --> 00:25:54.670
you were talking
about the triangle,

00:25:54.670 --> 00:25:55.950
"Walkaway" is over
here, where you're

00:25:55.950 --> 00:25:57.075
talking about coordination.

00:25:57.075 --> 00:26:00.550
And someone like
Banks is over here.

00:26:00.550 --> 00:26:02.110
Who's up at the top, then?

00:26:02.110 --> 00:26:04.660
CORY DOCTOROW: Well,
that's the Huxley, that's

00:26:04.660 --> 00:26:07.215
changing what we want, or
Marie Kondo, the cottage

00:26:07.215 --> 00:26:09.340
industry of convincing you
that all you really want

00:26:09.340 --> 00:26:12.760
is a smooth river rock that
reminds you of your mother,

00:26:12.760 --> 00:26:14.150
as [INAUDIBLE] said.

00:26:17.470 --> 00:26:19.440
It's the project
of Zen Buddhism,

00:26:19.440 --> 00:26:22.840
the minimalist project.

00:26:22.840 --> 00:26:25.870
The biggest enemy of
minimalism is precarity.

00:26:25.870 --> 00:26:28.835
One of the major reasons
that people hold on to stuff

00:26:28.835 --> 00:26:31.210
is because they're worried
that their circumstances might

00:26:31.210 --> 00:26:33.751
change, and they might not be
able to afford to get it again,

00:26:33.751 --> 00:26:35.380
even if they don't need it now.

00:26:35.380 --> 00:26:37.960
That's why people
save their clothes

00:26:37.960 --> 00:26:39.994
from before they lost
weight, or gained

00:26:39.994 --> 00:26:42.160
weight, or whatever, because
they know that it would

00:26:42.160 --> 00:26:44.050
cost them more to
replace it in the future

00:26:44.050 --> 00:26:45.010
than they might have.

00:26:45.010 --> 00:26:46.900
And so it's worth
the opportunity cost

00:26:46.900 --> 00:26:48.490
of leaving it in their closet.

00:26:48.490 --> 00:26:49.870
JOHN SCALZI: Well, no,
it's the whole idea

00:26:49.870 --> 00:26:52.244
that everybody had a grandmother
or great-grandmother who

00:26:52.244 --> 00:26:54.805
lived through the Depression,
who had a big ball of string.

00:26:54.805 --> 00:26:56.680
And that big ball-- what
are you going to use

00:26:56.680 --> 00:26:57.806
the big ball of string for?

00:26:57.806 --> 00:26:59.638
You never know what you
might be able to use

00:26:59.638 --> 00:27:00.850
that big ball of string for.

00:27:00.850 --> 00:27:02.260
CORY DOCTOROW: I have
a homecoming ritual,

00:27:02.260 --> 00:27:04.176
which is throwing out
all the non-working pens

00:27:04.176 --> 00:27:07.979
in my parents' kitchen
whenever I visit Toronto.

00:27:07.979 --> 00:27:09.520
JOHN SCALZI: Because
they do pile up.

00:27:09.520 --> 00:27:10.895
CORY DOCTOROW:
Oh, yeah, they do.

00:27:10.895 --> 00:27:13.032
And it's Gresham's
Law, the bad pens

00:27:13.032 --> 00:27:14.740
drive out the good,
because the good pens

00:27:14.740 --> 00:27:17.040
are the ones you take with
you in your bag and lose.

00:27:17.040 --> 00:27:18.998
And the bad pens are the
ones that stay behind.

00:27:18.998 --> 00:27:20.710
It's just broken pencils and--

00:27:20.710 --> 00:27:23.450
JOHN SCALZI: You know that
in this bag right now,

00:27:23.450 --> 00:27:25.840
I have got, like, six
working pens that I've

00:27:25.840 --> 00:27:29.307
stolen from bookstores that
I've been on tour with.

00:27:29.307 --> 00:27:29.890
I'm going to--

00:27:29.890 --> 00:27:30.640
CORY DOCTOROW: Good
drives out the bad.

00:27:30.640 --> 00:27:32.000
JOHN SCALZI: Right, because
then, they'll be like,

00:27:32.000 --> 00:27:32.950
oh, we don't have any good pens.

00:27:32.950 --> 00:27:33.866
I'm, like, I have one.

00:27:33.866 --> 00:27:34.660
It's like, cool.

00:27:34.660 --> 00:27:36.410
CORY DOCTOROW: So John,
you are incredibly

00:27:36.410 --> 00:27:40.520
generous being at
the end of your tour,

00:27:40.520 --> 00:27:42.975
with putting the
emphasis on my book here.

00:27:42.975 --> 00:27:45.350
But I really want to talk more
about "Collapsing Empire,"

00:27:45.350 --> 00:27:47.800
because it's a fascinating
and cracking read.

00:27:47.800 --> 00:27:51.460
And you say that you're
a cheerful, quippy guy,

00:27:51.460 --> 00:27:53.170
and so people mistake
you for an optimist

00:27:53.170 --> 00:27:54.910
even though you
write about bastards.

00:27:54.910 --> 00:28:01.350
But what I'm interested in is
why the interest in bastards?

00:28:01.350 --> 00:28:02.590
Are they just fun to write?

00:28:02.590 --> 00:28:04.048
JOHN SCALZI: They
are fun to write.

00:28:04.048 --> 00:28:05.620
I mean, bastards are great fun.

00:28:05.620 --> 00:28:09.020
You don't want
them in your life.

00:28:09.020 --> 00:28:12.280
And in this particular
book, I have a character

00:28:12.280 --> 00:28:14.440
who I love, who is one
of my favorite characters

00:28:14.440 --> 00:28:15.820
that I've ever written.

00:28:15.820 --> 00:28:17.530
And her name is Kiva Lagos.

00:28:17.530 --> 00:28:20.050
And she is amazing
to read, and she's

00:28:20.050 --> 00:28:21.490
amazing to watch in action.

00:28:21.490 --> 00:28:23.510
And you know that if
she were your friend

00:28:23.510 --> 00:28:29.040
and she was calling you,
you'd would be like, [SIGHS]

00:28:29.040 --> 00:28:30.490
do I want to answer the phone?

00:28:30.490 --> 00:28:32.531
Do I want to answer the
phone, because whatever's

00:28:32.531 --> 00:28:35.470
going to happen, it's
going to be a thing,

00:28:35.470 --> 00:28:37.000
and then I've got
to deal with it.

00:28:37.000 --> 00:28:38.120
And I don't want to
deal with it right now.

00:28:38.120 --> 00:28:39.220
I don't have time for this.

00:28:39.220 --> 00:28:40.053
And you put it down.

00:28:40.053 --> 00:28:42.490
And immediately afterwards,
there's a text that says,

00:28:42.490 --> 00:28:44.200
"I know you're there.

00:28:44.200 --> 00:28:45.610
Pick up the phone, you bastard."

00:28:45.610 --> 00:28:46.960
CORY DOCTOROW: But
with more swearing.

00:28:46.960 --> 00:28:47.850
JOHN SCALZI: With
much more swearing.

00:28:47.850 --> 00:28:49.020
CORY DOCTOROW: She
is an epic swearer.

00:28:49.020 --> 00:28:50.519
JOHN SCALZI: She
is an epic swearer.

00:28:50.519 --> 00:28:52.660
And last night, we were on tour.

00:28:52.660 --> 00:28:54.757
And he's, like, you
don't swear very much.

00:28:54.757 --> 00:28:55.840
Where does that come from?

00:28:55.840 --> 00:28:57.880
And I just stared at him.

00:28:57.880 --> 00:28:59.710
Because I am-- you don't know.

00:28:59.710 --> 00:29:00.680
CORY DOCTOROW: I
never hear you swear.

00:29:00.680 --> 00:29:00.840
JOHN SCALZI: You never--

00:29:00.840 --> 00:29:02.339
CORY DOCTOROW: I
must only catch you

00:29:02.339 --> 00:29:04.140
in moments of
great cheerfulness.

00:29:04.140 --> 00:29:07.220
JOHN SCALZI: Of being very
well-behaved, it must be.

00:29:07.220 --> 00:29:10.060
But in fact, I am
an epic swearer.

00:29:10.060 --> 00:29:13.780
And I come from a grand
line of epic swearers.

00:29:13.780 --> 00:29:19.300
And if you get us all together,
about 60% of our discourse

00:29:19.300 --> 00:29:21.860
is swearing in one
way or another.

00:29:21.860 --> 00:29:24.500
But she's a great character.

00:29:24.500 --> 00:29:26.560
But she's also a
bit of a bastard.

00:29:26.560 --> 00:29:29.740
She's our bastard,
so we like her.

00:29:29.740 --> 00:29:32.350
But you still have
to deal with what

00:29:32.350 --> 00:29:34.510
does that mean in terms
of character and story.

00:29:34.510 --> 00:29:36.996
And the other thing is,
as we were talking about,

00:29:36.996 --> 00:29:39.370
how our books, even though
they were completely unrelated

00:29:39.370 --> 00:29:41.800
in the writing are
strangely complementary.

00:29:41.800 --> 00:29:47.470
He is looking at the world
of a kind of a post-collapse

00:29:47.470 --> 00:29:51.220
and the middle class and
lower classes dealing

00:29:51.220 --> 00:29:54.070
with that, whereas in
"The Collapsing Empire,"

00:29:54.070 --> 00:29:57.955
it is all focused on the
people who are up at the top.

00:29:57.955 --> 00:29:59.580
CORY DOCTOROW: The
literal aristocracy.

00:29:59.580 --> 00:30:01.121
JOHN SCALZI: The
literal aristocracy,

00:30:01.121 --> 00:30:06.130
and their motivations are, in
some ways, very, very, very

00:30:06.130 --> 00:30:09.010
different, because they
are the main beneficiaries

00:30:09.010 --> 00:30:10.902
of this entire
interdependent system.

00:30:10.902 --> 00:30:12.360
The whole point of
this system-- it

00:30:12.360 --> 00:30:19.330
was built so that the 1%, or
actually, the 1/10 of the 1/10

00:30:19.330 --> 00:30:21.336
of the 1%, would
benefit, basically,

00:30:21.336 --> 00:30:23.710
from every exchange and every
transaction that would ever

00:30:23.710 --> 00:30:27.410
happen in trade through space.

00:30:27.410 --> 00:30:32.020
And so when they have evidence
that it's very likely to fail--

00:30:32.020 --> 00:30:35.530
some of it's debatable evidence,
but it is very strong evidence,

00:30:35.530 --> 00:30:36.700
nonetheless--

00:30:36.700 --> 00:30:39.380
they kind of break up
into three general areas.

00:30:39.380 --> 00:30:42.307
There's going to be
the people who say,

00:30:42.307 --> 00:30:43.390
get everybody on the boat.

00:30:43.390 --> 00:30:45.610
We're going to see how
many people we can save.

00:30:45.610 --> 00:30:47.440
There are going to be
other people who are,

00:30:47.440 --> 00:30:49.523
there's not enough room
in the boat for everybody.

00:30:49.523 --> 00:30:50.800
Kick, kick, kick.

00:30:50.800 --> 00:30:52.575
Just make sure my
family is on the boat.

00:30:52.575 --> 00:30:53.950
And then there
are the people who

00:30:53.950 --> 00:30:56.684
are, like, I don't know
whether or not things

00:30:56.684 --> 00:30:57.850
are coming to an end or not.

00:30:57.850 --> 00:31:00.850
All I know is I need
to own that boat,

00:31:00.850 --> 00:31:03.640
because they're going to be
the person who is in control.

00:31:03.640 --> 00:31:05.020
So their motivations
are actually

00:31:05.020 --> 00:31:07.720
materially different
than hoi polloi

00:31:07.720 --> 00:31:10.120
trying to get through
their day or trying

00:31:10.120 --> 00:31:11.630
to adjust to this world.

00:31:11.630 --> 00:31:17.407
Their focus is going
to be on preservation,

00:31:17.407 --> 00:31:19.990
whether it's preservation on a
large scale with as many people

00:31:19.990 --> 00:31:22.240
as possible, preservation
on a small scale with fewer

00:31:22.240 --> 00:31:24.520
people, or preservation
of wealth and capital,

00:31:24.520 --> 00:31:26.020
or whatever.

00:31:26.020 --> 00:31:29.710
And because of
that, in many ways,

00:31:29.710 --> 00:31:34.150
the impulses that
can be valorized

00:31:34.150 --> 00:31:36.250
in those particular
situations seem

00:31:36.250 --> 00:31:39.340
to be the ones that
also include bastardy.

00:31:39.340 --> 00:31:41.410
CORY DOCTOROW: Right,
I mean, it's so--

00:31:41.410 --> 00:31:45.110
I love the cynicism of
the political system,

00:31:45.110 --> 00:31:47.440
where there's this hub that--

00:31:47.440 --> 00:31:48.400
it's called Hub, right?

00:31:48.400 --> 00:31:49.608
JOHN SCALZI: It's called Hub.

00:31:49.608 --> 00:31:52.090
CORY DOCTOROW: That all of
the lay lines converge on,

00:31:52.090 --> 00:31:57.520
and the power-brokers
have granted monopolies

00:31:57.520 --> 00:32:01.390
on different technologies to
different spokes, the termini

00:32:01.390 --> 00:32:03.400
of different spokes
of the Hub, such

00:32:03.400 --> 00:32:06.460
that no one world
is self-sufficient.

00:32:06.460 --> 00:32:10.700
And therefore, goods always
have to transit Hub to get to--

00:32:10.700 --> 00:32:12.400
keep each of the
colonies running.

00:32:12.400 --> 00:32:15.790
And if the Hub ever
breaks down, civilization

00:32:15.790 --> 00:32:19.720
collapses across space.

00:32:19.720 --> 00:32:22.255
So first of all, this is
a lovely bit of cynicism.

00:32:22.255 --> 00:32:24.160
But what I found
really great was,

00:32:24.160 --> 00:32:26.437
there's this kind of latent
thing, which I didn't even

00:32:26.437 --> 00:32:29.020
realize until the book was over,
because as they're scrambling

00:32:29.020 --> 00:32:31.430
to make plans, even the
best of them is not saying,

00:32:31.430 --> 00:32:34.960
wait a second, how do we create
resilient independent colonies

00:32:34.960 --> 00:32:40.480
before the hyperspace
loopholes disappear?

00:32:40.480 --> 00:32:43.690
Because they're
going to be literally

00:32:43.690 --> 00:32:46.330
unreachable for the
next million years,

00:32:46.330 --> 00:32:48.179
and they can't make
their own food.

00:32:48.179 --> 00:32:48.970
JOHN SCALZI: Right.

00:32:48.970 --> 00:32:49.720
CORY DOCTOROW: And
no one's, like, how

00:32:49.720 --> 00:32:52.360
do we make sure that that
distant world has food?

00:32:52.360 --> 00:32:53.560
I love that.

00:32:53.560 --> 00:32:57.100
We're getting a time
signal, here, for Q and A.

00:32:57.100 --> 00:32:59.170
JOHN SCALZI: Yeah, so
what that means is,

00:32:59.170 --> 00:33:01.720
very briefly, there is,
in fact, one character who

00:33:01.720 --> 00:33:04.870
is leaning in that direction.

00:33:04.870 --> 00:33:07.104
And the next book, I
believe, is actually

00:33:07.104 --> 00:33:08.770
going to be about how
she tries to solve

00:33:08.770 --> 00:33:09.190
that particular problem.

00:33:09.190 --> 00:33:10.606
CORY DOCTOROW: I
kind of wondered.

00:33:10.606 --> 00:33:11.837
Yeah, I kind of wondered.

00:33:11.837 --> 00:33:13.420
JOHN SCALZI: It ends
on a cliffhanger,

00:33:13.420 --> 00:33:15.660
which enraged a lot of
people, who were, like, what?

00:33:15.660 --> 00:33:16.810
There's got to be more.

00:33:16.810 --> 00:33:20.960
And I'm like, look,
it's a whole universe.

00:33:20.960 --> 00:33:22.150
It needs a couple of books.

00:33:22.150 --> 00:33:22.850
So that--

00:33:22.850 --> 00:33:24.933
CORY DOCTOROW: My book has
a surprise ending, too.

00:33:24.933 --> 00:33:27.490
The last 40% is just the same
word over and over again.

00:33:27.490 --> 00:33:28.390
Don't tell anyone.

00:33:28.390 --> 00:33:29.097
It's a spoiler.

00:33:29.097 --> 00:33:31.180
JOHN SCALZI: But the
punctuation and the spacing--

00:33:31.180 --> 00:33:32.080
CORY DOCTOROW: Is
very different.

00:33:32.080 --> 00:33:32.920
JOHN SCALZI: It's
very, very different.

00:33:32.920 --> 00:33:34.732
CORY DOCTOROW: It's,
yeah, steganography.

00:33:34.732 --> 00:33:36.940
JOHN SCALZI: So we're going
to go into questions now,

00:33:36.940 --> 00:33:41.920
and we actually have a thing
that we like to do, where--

00:33:41.920 --> 00:33:42.760
Cory suggested it.

00:33:42.760 --> 00:33:44.020
I agree with it--

00:33:44.020 --> 00:33:46.900
that one question
comes from someone

00:33:46.900 --> 00:33:49.080
who identifies as female.

00:33:49.080 --> 00:33:50.322
CORY DOCTOROW: Or not binary.

00:33:50.322 --> 00:33:52.780
JOHN SCALZI: The next one comes
from someone who identifies

00:33:52.780 --> 00:33:54.314
as male and non binary.

00:33:54.314 --> 00:33:55.480
And why do we do that, Cory?

00:33:55.480 --> 00:33:56.740
CORY DOCTOROW: We do that
because otherwise, it's

00:33:56.740 --> 00:33:57.540
a sausage fest.

00:33:57.540 --> 00:33:58.040
Sorry, guys.

00:33:58.040 --> 00:33:59.248
JOHN SCALZI: That is correct.

00:33:59.248 --> 00:34:01.000
So we'll start with--

00:34:01.000 --> 00:34:02.750
CORY DOCTOROW: Are any
people who identify

00:34:02.750 --> 00:34:04.720
as female or non-binary who'd
like to ask the first question?

00:34:04.720 --> 00:34:06.160
And there's a mic runner
who will come over

00:34:06.160 --> 00:34:07.618
for the benefit of
the live stream.

00:34:07.618 --> 00:34:10.279
JOHN SCALZI: Right, so
anyone raise your hands.

00:34:10.279 --> 00:34:11.320
Otherwise, we'll move on.

00:34:11.320 --> 00:34:11.920
There we go.

00:34:11.920 --> 00:34:13.110
In back, in purple.

00:34:13.110 --> 00:34:15.449
AUDIENCE: I'm not going
to ask the same question.

00:34:15.449 --> 00:34:17.170
CORY DOCTOROW: I recognize
you from our event last night

00:34:17.170 --> 00:34:17.753
in Santa Cruz.

00:34:17.753 --> 00:34:19.900
Nice to see you again.

00:34:19.900 --> 00:34:22.989
AUDIENCE: So is the
retention of wealth immoral?

00:34:22.989 --> 00:34:25.020
JOHN SCALZI: Is the
retention of wealth immoral?

00:34:25.020 --> 00:34:26.920
No, I don't think the
retention of wealth

00:34:26.920 --> 00:34:28.810
is inherently immoral.

00:34:28.810 --> 00:34:32.830
I think there becomes
a point where,

00:34:32.830 --> 00:34:35.500
if your retention
of wealth leads

00:34:35.500 --> 00:34:40.144
to the overall reduction of
well-being of other people

00:34:40.144 --> 00:34:41.560
I personally think
that's immoral,

00:34:41.560 --> 00:34:47.440
because my moral system says,
do as well for everybody

00:34:47.440 --> 00:34:51.620
as much as you can, in a very,
very general sort of way.

00:34:51.620 --> 00:34:54.489
And so when the
concentration of wealth

00:34:54.489 --> 00:34:58.150
means, for example,
that we valorize

00:34:58.150 --> 00:35:02.680
the accumulation of wealth over,
say, the well-being of people

00:35:02.680 --> 00:35:07.210
in realms of health, or
education, or housing,

00:35:07.210 --> 00:35:09.490
or any of those sorts of
things, and it eventually

00:35:09.490 --> 00:35:13.660
becomes that you really
create such a huge disparity

00:35:13.660 --> 00:35:18.100
between the uppermost one-tenth
of one-tenth of one-tenth of 1%

00:35:18.100 --> 00:35:21.340
and literally everybody
else in the world, yes, then

00:35:21.340 --> 00:35:22.480
it becomes immoral.

00:35:22.480 --> 00:35:24.080
But in the sense of--

00:35:24.080 --> 00:35:28.360
in a very real sense, wealth
is an abstract concept

00:35:28.360 --> 00:35:31.250
that we all agree to go along.

00:35:31.250 --> 00:35:33.800
And so to some
extent, we all agree

00:35:33.800 --> 00:35:35.400
to that particular delusion.

00:35:35.400 --> 00:35:37.780
The problem, the
fall down, is when

00:35:37.780 --> 00:35:41.830
that all-agreed-upon delusion
means that the majority suffer.

00:35:41.830 --> 00:35:44.260
CORY DOCTOROW: Yeah, I
would take a more Piketty

00:35:44.260 --> 00:35:48.610
version of this, where Piketty
basically says, why do we

00:35:48.610 --> 00:35:51.130
tolerate imbalances in wealth?

00:35:51.130 --> 00:35:52.360
Why do we not go and take?

00:35:52.360 --> 00:35:54.910
If we want and someone else
has, why do we not go and take?

00:35:54.910 --> 00:35:58.540
And why do we erect systems just
to establish stable property

00:35:58.540 --> 00:35:59.200
relationships?

00:35:59.200 --> 00:36:03.580
And his answer is that because
when we allocate wealth--

00:36:03.580 --> 00:36:06.007
when people can have
wealth as a result of being

00:36:06.007 --> 00:36:08.590
good allocators of wealth, when
being a good locator of wealth

00:36:08.590 --> 00:36:10.840
gets you more wealth, so
when you allocate wealth

00:36:10.840 --> 00:36:13.660
in a way that is beneficial
to the world, you get richer,

00:36:13.660 --> 00:36:16.100
then you get more
wealth to allocate.

00:36:16.100 --> 00:36:19.210
And the problem is that
intergenerational wealth

00:36:19.210 --> 00:36:23.950
transfer doesn't create
efficient capital allocations.

00:36:23.950 --> 00:36:26.770
And his example is to compare
Liliane Bettencourt, who's

00:36:26.770 --> 00:36:29.200
the heiress of the L'Oreal
fortune, who has literally

00:36:29.200 --> 00:36:32.097
never worked a day of her
life, and Bill Gates, who

00:36:32.097 --> 00:36:34.180
founded the most successful
company in the history

00:36:34.180 --> 00:36:36.380
of the world in his lifetime.

00:36:36.380 --> 00:36:38.170
And Liliane Bettencourt
and Bill Gates,

00:36:38.170 --> 00:36:41.920
starting from the same
place at the same time,

00:36:41.920 --> 00:36:45.160
Liliane Bettencourt's fortune
grew more than Bill Gates' did,

00:36:45.160 --> 00:36:47.890
even though she didn't
even allocate capital.

00:36:47.890 --> 00:36:51.820
She just gave capital to
other people to allocate.

00:36:51.820 --> 00:36:53.830
And then Bill Gates,
after he retired,

00:36:53.830 --> 00:36:57.025
made more money still
in total than he

00:36:57.025 --> 00:36:59.150
had while running the
largest company in the world.

00:36:59.150 --> 00:37:01.360
So Bill Gates,
doing nothing apart

00:37:01.360 --> 00:37:03.520
from being a financial
plumber, as opposed

00:37:03.520 --> 00:37:06.680
to doing the non-commodity
thing of starting a business

00:37:06.680 --> 00:37:09.266
that capital can
flow into, Bill Gates

00:37:09.266 --> 00:37:10.390
doesn't make as much money.

00:37:10.390 --> 00:37:13.450
And so there's this
kind of utilitarian,

00:37:13.450 --> 00:37:16.550
but market-oriented reason
to do redistribution,

00:37:16.550 --> 00:37:19.480
to care about intergenerational
wealth transfer.

00:37:19.480 --> 00:37:22.070
But there's a simpler kind
of left-right version.

00:37:22.070 --> 00:37:24.217
So there's a wonderful
left-wing fantasy

00:37:24.217 --> 00:37:25.300
writer named Steven Brust.

00:37:25.300 --> 00:37:28.270
He's a no-fooling
Trotskyist fantasy writer.

00:37:28.270 --> 00:37:29.360
JOHN SCALZI: Yes, he is.

00:37:29.360 --> 00:37:32.210
CORY DOCTOROW: And you can
tell he's a Marxist fantasy

00:37:32.210 --> 00:37:35.750
writer, because he has the
right ratio of vassals to lords.

00:37:35.750 --> 00:37:40.340
Normal fantasy writers
have way too few vassals.

00:37:40.340 --> 00:37:44.175
But I was having drinks
with him once, and I said,

00:37:44.175 --> 00:37:46.300
I don't even know what left
and right mean anymore.

00:37:46.300 --> 00:37:48.600
And he said, it means
exactly the same thing

00:37:48.600 --> 00:37:50.450
it's meant since the
French Revolution.

00:37:50.450 --> 00:37:52.940
You ask, what is more
important, a property right

00:37:52.940 --> 00:37:53.730
or a human right?

00:37:53.730 --> 00:37:57.014
And if the person
you're asking says

00:37:57.014 --> 00:37:58.430
property rights
are a human right,

00:37:58.430 --> 00:38:00.120
they're on the political right.

00:38:00.120 --> 00:38:03.800
And that is the question that
divides the two philosophies.

00:38:03.800 --> 00:38:06.545
And so once you come
to the conclusion

00:38:06.545 --> 00:38:08.420
that it's not a human
right, that it's merely

00:38:08.420 --> 00:38:11.110
like a utilitarian thing,
then yes, of course,

00:38:11.110 --> 00:38:13.400
there's real problems with
intergenerational wealth

00:38:13.400 --> 00:38:13.930
transfer.

00:38:13.930 --> 00:38:16.388
JOHN SCALZI: And the other
thing about it, and particularly

00:38:16.388 --> 00:38:20.150
in the United States, is people
have a tendency in the United

00:38:20.150 --> 00:38:22.610
States to believe that there
are two types of people.

00:38:22.610 --> 00:38:24.710
There are the millionaires,
and the people who

00:38:24.710 --> 00:38:26.120
are not the millionaires yet.

00:38:26.120 --> 00:38:27.470
CORY DOCTOROW: Temporary
embarrassed millionaires,

00:38:27.470 --> 00:38:28.370
as Steinbeck called them.

00:38:28.370 --> 00:38:29.536
JOHN SCALZI: Right, exactly.

00:38:29.536 --> 00:38:32.030
And if that is your
fundamental view of the world,

00:38:32.030 --> 00:38:38.090
then ultimately, the question of
wealth accretion does, I think,

00:38:38.090 --> 00:38:40.000
tend towards immorality.

00:38:40.000 --> 00:38:42.580
So next question.

00:38:42.580 --> 00:38:43.630
AUDIENCE: So hi.

00:38:43.630 --> 00:38:45.654
And I hate to say this,
because I know you

00:38:45.654 --> 00:38:46.820
make your living doing this.

00:38:46.820 --> 00:38:50.360
But would you-- what do
you think about the fact

00:38:50.360 --> 00:38:53.930
that, to be successful
in a post-scarcity world,

00:38:53.930 --> 00:38:58.180
you have to completely ignore
all intellectual property law?

00:38:58.180 --> 00:39:01.160
And I would argue that open
source is successful because it

00:39:01.160 --> 00:39:03.760
found a way to do just that.

00:39:03.760 --> 00:39:05.390
CORY DOCTOROW: Yeah,
Cory, so I think

00:39:05.390 --> 00:39:07.723
you've got it wrong about
free and open source software.

00:39:07.723 --> 00:39:10.490
I actually think-- so
I think you're right,

00:39:10.490 --> 00:39:12.830
that the Free Software
movement's origins are

00:39:12.830 --> 00:39:18.260
in opposition to the idea
of copyright and patent,

00:39:18.260 --> 00:39:21.950
actually, against intellectual
monopoly more widely.

00:39:21.950 --> 00:39:26.810
But it's a brilliant hack,
because what Stallman

00:39:26.810 --> 00:39:31.190
did with the GPL was he created
a regime where the more you

00:39:31.190 --> 00:39:35.220
strengthen copyright, the
more enforceable his license

00:39:35.220 --> 00:39:37.910
that abjured copyright became.

00:39:37.910 --> 00:39:39.410
And the weaker you
made copyright,

00:39:39.410 --> 00:39:42.230
the less his license was
needed to accomplish its goals.

00:39:42.230 --> 00:39:46.790
And so he created a
heads I win, tails

00:39:46.790 --> 00:39:51.020
you lose situation
in the license.

00:39:51.020 --> 00:39:58.940
I think that the idea of
exclusive rights over one's

00:39:58.940 --> 00:40:02.150
intellectual
creations has always

00:40:02.150 --> 00:40:09.530
been a battleground between
the utilitarian considerations,

00:40:09.530 --> 00:40:15.110
self-deception, and emotional
feelings, animal sentiments.

00:40:15.110 --> 00:40:16.880
So we have this
Lockean intuition

00:40:16.880 --> 00:40:19.880
that when we infuse something
with our labor, it's ours.

00:40:19.880 --> 00:40:22.040
And that leads to
the self-delusion

00:40:22.040 --> 00:40:23.900
that when we infused
it with our labor,

00:40:23.900 --> 00:40:26.900
we did not take anything from
anyone else that was theirs.

00:40:26.900 --> 00:40:29.660
So when Edgar Allan Poe
invents the detective story,

00:40:29.660 --> 00:40:30.800
he's just making plumbing.

00:40:30.800 --> 00:40:32.450
When I write a
detective story, I'm

00:40:32.450 --> 00:40:36.020
making something
special and unique to me

00:40:36.020 --> 00:40:40.320
that no one can take without
doing me some irreparable harm.

00:40:40.320 --> 00:40:42.956
And then from a utilitarian
perspective, we ask ourselves,

00:40:42.956 --> 00:40:44.330
would the world
be a better place

00:40:44.330 --> 00:40:46.880
if you could only
write detective stories

00:40:46.880 --> 00:40:48.802
if Edgar Allan Poe's
estate said you could?

00:40:48.802 --> 00:40:51.260
And it seems pretty clear that
there are, like, detectives.

00:40:51.260 --> 00:40:53.570
Poe is-- I named my
daughter after Poe.

00:40:53.570 --> 00:40:54.590
I'm not a--

00:40:54.590 --> 00:40:56.270
I will brief for Poe.

00:40:56.270 --> 00:40:58.440
But Poe had eccentric ideas.

00:40:58.440 --> 00:41:01.340
And if we said to Poe, "You are
the arbiter of all detective

00:41:01.340 --> 00:41:04.070
stories because of "Murders
in the Rue morgue,"

00:41:04.070 --> 00:41:06.990
we would be a
poorer world for it.

00:41:06.990 --> 00:41:11.960
And so I am a believer
in evidence-led copyright

00:41:11.960 --> 00:41:14.750
and patent, where if we can
show that at the margin,

00:41:14.750 --> 00:41:18.170
you produce more creativity,
more of whatever the underlying

00:41:18.170 --> 00:41:21.530
purpose is by enacting some
temporary monopoly as specified

00:41:21.530 --> 00:41:24.020
in the Constitution for the
promotion of the useful arts

00:41:24.020 --> 00:41:26.360
and sciences, then let us do so.

00:41:26.360 --> 00:41:30.290
But if the only
thing we're doing

00:41:30.290 --> 00:41:34.950
is pandering to the
self-deception and the animal

00:41:34.950 --> 00:41:40.550
sentiment, then I think
we do so at the cost

00:41:40.550 --> 00:41:42.975
of our intellectual enrichment.

00:41:42.975 --> 00:41:44.600
JOHN SCALZI: And also
there's the issue

00:41:44.600 --> 00:41:49.100
of, it is the individual
versus the society thing, where

00:41:49.100 --> 00:41:52.700
the individual creates
something that is basically

00:41:52.700 --> 00:41:55.250
Hegelian in nature, because
we don't just pop things out

00:41:55.250 --> 00:41:56.510
of the air.

00:41:56.510 --> 00:41:59.334
The information exists
before that is your thesis.

00:41:59.334 --> 00:42:00.500
You add something new to it.

00:42:00.500 --> 00:42:02.034
That's your antithesis.

00:42:02.034 --> 00:42:03.200
You get something out of it.

00:42:03.200 --> 00:42:03.920
That's synthesis.

00:42:03.920 --> 00:42:06.306
That synthesis is your creation.

00:42:06.306 --> 00:42:07.430
Should you benefit from it?

00:42:07.430 --> 00:42:09.170
Sure, because you
have done something

00:42:09.170 --> 00:42:11.390
that no one else
has done before.

00:42:11.390 --> 00:42:14.660
But you also didn't do it
independent of the rest

00:42:14.660 --> 00:42:16.310
of the community
in which you live.

00:42:16.310 --> 00:42:20.960
We do grant, as they say,
exclusive right to profit

00:42:20.960 --> 00:42:23.337
from it for a certain
amount of time.

00:42:23.337 --> 00:42:24.920
But what's really
important about that

00:42:24.920 --> 00:42:26.540
is that it is the
individual that

00:42:26.540 --> 00:42:29.300
has the right to profit from
it, and so on, and so forth.

00:42:29.300 --> 00:42:31.633
So when you have-- and the
great thing about individuals

00:42:31.633 --> 00:42:34.070
is that they die in
this particular setup,

00:42:34.070 --> 00:42:37.580
because eventually, everything
about what the individual does

00:42:37.580 --> 00:42:40.130
stops being of importance
to that individual,

00:42:40.130 --> 00:42:41.910
because they're dead.

00:42:41.910 --> 00:42:45.170
And then it becomes of the
use to the society in general,

00:42:45.170 --> 00:42:49.190
unless they previously licensed
it, or do whatever else

00:42:49.190 --> 00:42:51.110
to let it happen.

00:42:51.110 --> 00:42:54.870
When you have a situation
where, for example,

00:42:54.870 --> 00:42:57.950
the individual dies,
and then their children

00:42:57.950 --> 00:43:00.380
and grandchildren, and
so on and so forth,

00:43:00.380 --> 00:43:04.370
then become rent seekers on that
particular piece of property,

00:43:04.370 --> 00:43:08.420
then to go back to the question,
is wealth immoral, then

00:43:08.420 --> 00:43:11.660
you start having a real
question of the morality of it

00:43:11.660 --> 00:43:14.830
relative to the benefit
of the society in general.

00:43:14.830 --> 00:43:16.580
My personal feeling
about stuff like this,

00:43:16.580 --> 00:43:19.400
and I think it may be
slightly different from yours,

00:43:19.400 --> 00:43:23.060
is, I'm a big fan of
copyright for individuals

00:43:23.060 --> 00:43:27.300
being life plus 20, or 75
years, whichever is longer

00:43:27.300 --> 00:43:28.550
in the case of the individual.

00:43:28.550 --> 00:43:35.060
Because the 20 then allows
the person's spouse and family

00:43:35.060 --> 00:43:37.410
to get some limited
benefit after that.

00:43:37.410 --> 00:43:40.610
But after that, it goes
into the community,

00:43:40.610 --> 00:43:42.350
because quite honestly,
my grandchildren

00:43:42.350 --> 00:43:44.360
should go either
get their own jobs,

00:43:44.360 --> 00:43:48.370
or walk away, one
of those two things.

00:43:48.370 --> 00:43:50.040
For corporations, I think 75.

00:43:50.040 --> 00:43:52.790
And then the problem is, that
you have folks like Disney.

00:43:52.790 --> 00:43:56.000
As much as I admire
Disney in many other ways,

00:43:56.000 --> 00:43:58.670
but the fact that every time
Steamboat Willie comes up

00:43:58.670 --> 00:44:00.890
to being put in
the public domain,

00:44:00.890 --> 00:44:04.685
they somehow magically get to
extend the life of copyright.

00:44:04.685 --> 00:44:07.310
CORY DOCTOROW: Although they've
got only one year to do it now,

00:44:07.310 --> 00:44:08.976
because we're starting--
we're coming up

00:44:08.976 --> 00:44:11.480
against the limits of the
20-year renewal in 1998.

00:44:11.480 --> 00:44:13.170
So we're pretty close to it.

00:44:13.170 --> 00:44:15.378
JOHN SCALZI: Don't worry,
we live in Trump's America.

00:44:15.378 --> 00:44:19.930
CORY DOCTOROW: I hear you, where
legislation passes with ease.

00:44:19.930 --> 00:44:23.090
JOHN SCALZI: But so, as
far as that goes, I mean,

00:44:23.090 --> 00:44:26.250
there is that thing
that at a certain point,

00:44:26.250 --> 00:44:27.650
the individual ceases to exist.

00:44:27.650 --> 00:44:31.250
The benefit that the individual
accrues from it goes away,

00:44:31.250 --> 00:44:33.260
and it has to go
back to the society,

00:44:33.260 --> 00:44:37.100
because the society needs that
Hegelian process to create

00:44:37.100 --> 00:44:38.496
new and compelling stuff.

00:44:38.496 --> 00:44:41.120
CORY DOCTOROW: I want to suggest
a gloss, a friendly amendment.

00:44:41.120 --> 00:44:41.700
JOHN SCALZI: Please do.

00:44:41.700 --> 00:44:44.070
CORY DOCTOROW: Which is
that in addition to this,

00:44:44.070 --> 00:44:48.980
you need an expansive safety
valve for free expression

00:44:48.980 --> 00:44:54.410
that doesn't allow the
author to enjoin people

00:44:54.410 --> 00:44:56.810
from using their work
to criticize their work.

00:44:56.810 --> 00:45:01.880
And so I think that we
worry too much about things

00:45:01.880 --> 00:45:04.910
like open licenses, and
too little about things

00:45:04.910 --> 00:45:08.480
like limitations to
copyright, like fair use.

00:45:08.480 --> 00:45:11.540
Our pole star shouldn't be,
I can write "The Wind Done

00:45:11.540 --> 00:45:13.382
Gone," which was a
retelling of "Gone

00:45:13.382 --> 00:45:14.840
with the Wind" from
the perspective

00:45:14.840 --> 00:45:17.600
of the enslaved people, if
Margaret Mitchell tells me

00:45:17.600 --> 00:45:18.710
I can.

00:45:18.710 --> 00:45:20.270
And therefore, what
we should do is

00:45:20.270 --> 00:45:22.520
kind of work on Margaret
Mitchell's estate

00:45:22.520 --> 00:45:25.700
to get her to let
us tell that story.

00:45:25.700 --> 00:45:28.100
What we should be saying is,
Margaret Mitchell's estate--

00:45:28.100 --> 00:45:29.974
and this is what the
Supreme Court affirmed--

00:45:29.974 --> 00:45:32.760
Margaret Mitchell's estate
doesn't get to decide.

00:45:32.760 --> 00:45:33.950
And so we don't have to--

00:45:33.950 --> 00:45:36.080
and in that regard, the
duration of copyright

00:45:36.080 --> 00:45:37.820
becomes a lot less important.

00:45:37.820 --> 00:45:40.730
Because one of the greatest
problems of the copyright

00:45:40.730 --> 00:45:44.750
term is that it is accompanied
by a very narrow view

00:45:44.750 --> 00:45:46.460
of limitations to copyright.

00:45:46.460 --> 00:45:48.650
And so we not only have
a very long-lived thing,

00:45:48.650 --> 00:45:49.970
but a very wide thing.

00:45:49.970 --> 00:45:50.761
JOHN SCALZI: Right.

00:45:50.761 --> 00:45:54.350
Now, I accept this gloss and
endorse it wholeheartedly.

00:45:54.350 --> 00:45:56.184
CORY DOCTOROW: How
we doing for time?

00:45:56.184 --> 00:45:57.100
JOHN SCALZI: Timewise?

00:45:57.100 --> 00:45:58.400
CORY DOCTOROW: Do we
have time for more?

00:45:58.400 --> 00:45:59.817
JOHN SCALZI: OK,
so next question.

00:45:59.817 --> 00:46:01.691
CORY DOCTOROW: From
someone who identifies as

00:46:01.691 --> 00:46:02.930
female or non-binary, please.

00:46:02.930 --> 00:46:03.720
Right here.

00:46:03.720 --> 00:46:05.537
AUDIENCE: This one's
for Mr. Scalzi.

00:46:05.537 --> 00:46:07.370
Really curious how you
came up with the ship

00:46:07.370 --> 00:46:09.036
names for "Collapsing
Empire," because I

00:46:09.036 --> 00:46:10.192
enjoyed them very much.

00:46:10.192 --> 00:46:11.150
JOHN SCALZI: Thank you.

00:46:11.150 --> 00:46:11.983
AUDIENCE: Thank you.

00:46:14.650 --> 00:46:19.670
JOHN SCALZI: Specifically
it's a sort of a sub rosa--

00:46:19.670 --> 00:46:24.560
not really sub rosa-- it's a
kind of an explicit testimonial

00:46:24.560 --> 00:46:29.660
to Iain M. Banks, whose Culture
series I absolutely love,

00:46:29.660 --> 00:46:36.170
creates the idea of a huge,
galaxy-spanning civilization.

00:46:36.170 --> 00:46:40.940
Now, he writes with a sort of
verve and complexity that I

00:46:40.940 --> 00:46:42.370
don't.

00:46:42.370 --> 00:46:44.930
And in the sense of even
just in the sentences.

00:46:44.930 --> 00:46:47.062
I mean, we all have
complicated universes.

00:46:47.062 --> 00:46:48.020
That's why you love us.

00:46:48.020 --> 00:46:50.965
But just the fact
of his Culture,

00:46:50.965 --> 00:46:52.340
and the way that
he's built that,

00:46:52.340 --> 00:46:56.900
and that there's so much there,
and even so much more implied,

00:46:56.900 --> 00:46:58.680
I absolutely love.

00:46:58.680 --> 00:47:01.970
And he and I were
up for a Locus Award

00:47:01.970 --> 00:47:04.880
together, when I
did "Redshirts."

00:47:04.880 --> 00:47:07.650
And he had just passed,
or was about to pass away.

00:47:07.650 --> 00:47:09.710
And I remember explicitly
saying to people,

00:47:09.710 --> 00:47:14.720
I'm absolutely happy that I'm
a finalist for this award.

00:47:14.720 --> 00:47:18.140
If you were planning to vote for
me, please vote for Iain Banks.

00:47:18.140 --> 00:47:20.120
Because not only was
"The Hydrogen Sonata"

00:47:20.120 --> 00:47:21.650
a wonderful book
in and of itself,

00:47:21.650 --> 00:47:26.660
but just as a proxy for the
entire series, I was like,

00:47:26.660 --> 00:47:31.830
this would be a great time
and place to honor him.

00:47:31.830 --> 00:47:33.260
I won.

00:47:33.260 --> 00:47:35.029
My wife gave my
acceptance speech,

00:47:35.029 --> 00:47:36.320
in which I dedicated it to him.

00:47:36.320 --> 00:47:39.470
Because again, I feel like
I won, but he should have,

00:47:39.470 --> 00:47:41.270
so this is his.

00:47:41.270 --> 00:47:43.550
And this is my way,
and in my creating

00:47:43.550 --> 00:47:46.550
this galaxy-spanning
thing, to acknowledge

00:47:46.550 --> 00:47:51.645
that Iain Banks is a master
of this particular form.

00:47:51.645 --> 00:47:53.520
And so every time someone
sees that and goes,

00:47:53.520 --> 00:47:55.430
huh, it's like Iain
Banks, it's almost

00:47:55.430 --> 00:47:57.486
like spending a prayer wheel.

00:47:57.486 --> 00:48:00.140
In my book, Iain
Banks is remembered.

00:48:00.140 --> 00:48:01.731
And that actually
makes me happy.

00:48:01.731 --> 00:48:03.980
CORY DOCTOROW: I sneak my
favorite William Gibson line

00:48:03.980 --> 00:48:04.857
into-- oh, yeah.

00:48:04.857 --> 00:48:06.317
[APPLAUSE]

00:48:06.317 --> 00:48:07.900
I take my favorite
William Gibson line

00:48:07.900 --> 00:48:10.130
into about three-quarters
of my books, which is,

00:48:10.130 --> 00:48:12.640
"Don't let the little
fuckers generation gap you."

00:48:12.640 --> 00:48:15.830
And it's in-- it appears
in half a dozen of them.

00:48:15.830 --> 00:48:17.960
I wanted to ask about
that, because Earth

00:48:17.960 --> 00:48:19.970
is 1,000 years gone.

00:48:19.970 --> 00:48:22.370
Earth has lost to
this civilization.

00:48:22.370 --> 00:48:24.470
But they're all cool,
old, Tin Pan Alley songs.

00:48:24.470 --> 00:48:25.845
Do you have a
continuity in mind?

00:48:25.845 --> 00:48:28.330
Is that going to emerge,
why Tin Pan Alley survives?

00:48:28.330 --> 00:48:30.830
JOHN SCALZI: I think it's just
basically the classical music

00:48:30.830 --> 00:48:32.780
of its time.

00:48:32.780 --> 00:48:34.470
So they'll pull it off.

00:48:34.470 --> 00:48:36.860
And I think it's also, there
may be some sort of thing

00:48:36.860 --> 00:48:39.500
where you want-- your ship names
have to be distinctive enough

00:48:39.500 --> 00:48:44.210
that they're not going to
repeat, but at the same time,

00:48:44.210 --> 00:48:46.850
have to be easy enough to
remember that you can say them.

00:48:46.850 --> 00:48:49.920
And song lyrics do a
really good job of that.

00:48:49.920 --> 00:48:52.580
I think there's
that thing that--

00:48:52.580 --> 00:48:55.360
you shouldn't do
this for passwords.

00:48:55.360 --> 00:48:56.990
But a long time ago,
people were, like,

00:48:56.990 --> 00:49:00.576
if you have a hard time
remembering a thing, just use--

00:49:00.576 --> 00:49:01.700
CORY DOCTOROW: Initialisms.

00:49:01.700 --> 00:49:04.580
JOHN SCALZI: Yeah, or a
line of lyrics from a song,

00:49:04.580 --> 00:49:06.020
or something like that.

00:49:06.020 --> 00:49:07.400
You shouldn't do
it, because once

00:49:07.400 --> 00:49:09.733
you actually see the pattern,
then it gives it all away.

00:49:09.733 --> 00:49:11.490
And even a machine
can figure that out.

00:49:11.490 --> 00:49:16.759
But just the idea that you can
remember a sequence of words

00:49:16.759 --> 00:49:18.800
better than you might
remember just a single word

00:49:18.800 --> 00:49:19.770
is kind of interesting to me.

00:49:19.770 --> 00:49:22.311
CORY DOCTOROW: There's a thing
called Zooko's Triangle, which

00:49:22.311 --> 00:49:24.830
says that identifiers can
be human readable, unique,

00:49:24.830 --> 00:49:25.950
or collision resistant.

00:49:25.950 --> 00:49:26.960
I forget what the third one is.

00:49:26.960 --> 00:49:28.709
Does anyone remember
what the third corner

00:49:28.709 --> 00:49:30.050
of Zooko's triangle was?

00:49:30.050 --> 00:49:32.202
But it is this problem.

00:49:32.202 --> 00:49:34.160
When you have independent
people coming up with

00:49:34.160 --> 00:49:36.375
identifiers without being
able to talk to each other,

00:49:36.375 --> 00:49:38.000
that you have this
really hard problem.

00:49:38.000 --> 00:49:38.958
And you can use hashes.

00:49:38.958 --> 00:49:42.420
But like calling your
spaceship the 80-character hash

00:49:42.420 --> 00:49:44.690
of something is--

00:49:44.690 --> 00:49:47.117
it's not the kind of thing
that people write songs about.

00:49:47.117 --> 00:49:48.950
JOHN SCALZI: And it
really is the difference

00:49:48.950 --> 00:49:52.250
between having a
personalized license plate

00:49:52.250 --> 00:49:54.440
and having a VIN number.

00:49:54.440 --> 00:49:55.490
OK, one last question.

00:49:58.186 --> 00:49:59.310
You had your hand up first.

00:49:59.310 --> 00:49:59.960
I'm sorry.

00:49:59.960 --> 00:50:02.000
AUDIENCE: So John, I
was curious about--

00:50:02.000 --> 00:50:05.345
you mentioned in your
book that society kind of

00:50:05.345 --> 00:50:07.470
has this infrastructure
that they take for granted.

00:50:07.470 --> 00:50:10.250
And there's also been
this loss of knowledge

00:50:10.250 --> 00:50:13.160
as to why existing principles,
why it kind of existed.

00:50:13.160 --> 00:50:14.870
And you mentioned that someone--

00:50:14.870 --> 00:50:17.260
people draw the conclusion
that you may be referring,

00:50:17.260 --> 00:50:19.530
or it's an allegory about oil.

00:50:19.530 --> 00:50:21.800
But I actually think
of it as an allegory

00:50:21.800 --> 00:50:24.470
for another modern-day
infrastructure

00:50:24.470 --> 00:50:28.700
that we're a little bit famous
for working with, that people

00:50:28.700 --> 00:50:31.240
potentially take for granted.

00:50:31.240 --> 00:50:34.490
And I'm curious, especially
with one of the groups

00:50:34.490 --> 00:50:37.880
that's currently tasked
with protecting it, also

00:50:37.880 --> 00:50:41.180
recently publishing
rules to kind of erode

00:50:41.180 --> 00:50:44.750
key parts of why it exists,
and why it's important.

00:50:44.750 --> 00:50:46.880
And just this thought
that every death

00:50:46.880 --> 00:50:51.080
is kind of its own destruction
of a library of Alexandria is--

00:50:51.080 --> 00:50:52.627
you lose a family
member, maybe I

00:50:52.627 --> 00:50:54.710
should have asked them
something before they left.

00:50:54.710 --> 00:50:59.609
Or I lost a team member, and
now suddenly, for a code,

00:50:59.609 --> 00:51:01.900
like I should have called
this function holding a lock,

00:51:01.900 --> 00:51:03.733
and now I have race
condition kind of thing.

00:51:03.733 --> 00:51:06.860
It's like this information,
it's not quite codified,

00:51:06.860 --> 00:51:08.230
but it's important.

00:51:08.230 --> 00:51:11.450
And because it wasn't
distilled, and because others

00:51:11.450 --> 00:51:14.690
weren't educated about it,
it's kind of lost in time.

00:51:14.690 --> 00:51:16.280
Do either of you
have thoughts on how

00:51:16.280 --> 00:51:19.610
we can better kind
of codify and educate

00:51:19.610 --> 00:51:21.950
others about these things?

00:51:21.950 --> 00:51:24.410
JOHN SCALZI: OK,
you danced around

00:51:24.410 --> 00:51:26.660
what it was that you were
actually trying to describe.

00:51:26.660 --> 00:51:28.940
I thought at first you
were going towards Google

00:51:28.940 --> 00:51:31.400
Books or something.

00:51:31.400 --> 00:51:32.000
But what is--

00:51:32.000 --> 00:51:32.600
CORY DOCTOROW: What
group are you--

00:51:32.600 --> 00:51:34.480
JOHN SCALZI: What were you
referring to explicitly?

00:51:34.480 --> 00:51:36.354
AUDIENCE: I was curious
about net neutrality.

00:51:36.354 --> 00:51:38.030
CORY DOCTOROW: Oh,
net neutrality.

00:51:38.030 --> 00:51:41.332
JOHN SCALZI: I'm going
to let Cory talk first.

00:51:41.332 --> 00:51:43.790
CORY DOCTOROW: Well, look, the
network neutrality question,

00:51:43.790 --> 00:51:45.890
on its face, should be
really easy to square up.

00:51:45.890 --> 00:51:50.980
Even if you believe in markets
as the solution to everything,

00:51:50.980 --> 00:51:52.700
and you think
regulation is a problem,

00:51:52.700 --> 00:51:54.770
phone companies don't
exist without regulation.

00:51:54.770 --> 00:51:56.270
Like arguing about
whether or not

00:51:56.270 --> 00:51:58.850
phone companies should or
shouldn't be regulated,

00:51:58.850 --> 00:52:02.650
it's like arguing
about whether or not

00:52:02.650 --> 00:52:06.850
ice cream should be cold.

00:52:06.850 --> 00:52:11.390
The going Galt fiber
network involves

00:52:11.390 --> 00:52:13.370
going to every
basement in New York,

00:52:13.370 --> 00:52:15.290
and paying the clearing
price of digging it up

00:52:15.290 --> 00:52:17.030
to put a piece of
fiber in it, that

00:52:17.030 --> 00:52:19.280
is like umpteen
trillion dollars,

00:52:19.280 --> 00:52:20.870
and you will never,
ever recoup it.

00:52:20.870 --> 00:52:22.730
So without some
regulatory intervention

00:52:22.730 --> 00:52:25.390
that gives you these literally
priceless rights of way--

00:52:25.390 --> 00:52:27.890
priceless because you would get
this deadlock where when you

00:52:27.890 --> 00:52:30.160
got down the last two
basements that controlled

00:52:30.160 --> 00:52:32.050
the closing of the
loop, those people

00:52:32.050 --> 00:52:34.870
would just price it at
the entire expected return

00:52:34.870 --> 00:52:36.100
minus $1.

00:52:36.100 --> 00:52:38.620
And so there's no
viable way to build

00:52:38.620 --> 00:52:42.160
a telecom without
state intervention

00:52:42.160 --> 00:52:43.099
into property rights.

00:52:43.099 --> 00:52:45.640
And so if you're going to take
the King's Shilling, if you're

00:52:45.640 --> 00:52:47.770
going to put your
copper in our dirt

00:52:47.770 --> 00:52:49.330
that we clear the
way for for you,

00:52:49.330 --> 00:52:53.890
than you have an
obligation to operate

00:52:53.890 --> 00:52:55.660
that copper in the
public interest.

00:52:55.660 --> 00:52:57.730
And you are welcome
to run your network

00:52:57.730 --> 00:53:00.250
any way you want if you're
going to pay all the clearing

00:53:00.250 --> 00:53:01.840
costs associated with it.

00:53:01.840 --> 00:53:03.841
But when you're going
to use our largesse,

00:53:03.841 --> 00:53:05.590
when you're going to
take a giant subsidy,

00:53:05.590 --> 00:53:07.480
that subsidy comes
with a quid pro quo.

00:53:07.480 --> 00:53:08.980
And that quid pro
quo is you give me

00:53:08.980 --> 00:53:12.040
the bits I ask for when I ask
for them as quickly as you can,

00:53:12.040 --> 00:53:14.560
not trading me to another
prisoner for a pack

00:53:14.560 --> 00:53:19.240
of cigarettes, going to one
company or another, and saying,

00:53:19.240 --> 00:53:23.420
how much will you pay me to
get your bits to Mr. Doctorow

00:53:23.420 --> 00:53:26.950
faster than the guys
down the road will?

00:53:26.950 --> 00:53:29.440
And the fact that
you have people

00:53:29.440 --> 00:53:33.100
who claim to be
market supporters who

00:53:33.100 --> 00:53:38.140
are unable to understand
this tells you that--

00:53:38.140 --> 00:53:39.909
I think it's Mencken's
Aphorism that it's

00:53:39.909 --> 00:53:41.950
impossible to get someone
to understand something

00:53:41.950 --> 00:53:44.470
when his paycheck depends on
him not understanding it--

00:53:44.470 --> 00:53:49.180
that the arguments are
so crummy for allowing

00:53:49.180 --> 00:53:51.010
network discrimination.

00:53:51.010 --> 00:53:54.250
And Susan Crawford had a
great op-ed about it today.

00:53:54.250 --> 00:53:57.310
I think that we are
almost at the point

00:53:57.310 --> 00:54:01.480
where maybe network neutrality
will be very hard to take away,

00:54:01.480 --> 00:54:04.570
because we are
almost at the point

00:54:04.570 --> 00:54:08.770
where we have pretty good
networks for enough people that

00:54:08.770 --> 00:54:11.140
taking that away will
cause them to rise up.

00:54:11.140 --> 00:54:13.090
Because it's very hard
to get people exercised

00:54:13.090 --> 00:54:15.423
about a thing they've never
had, that we're telling them

00:54:15.423 --> 00:54:17.140
their future has been
stolen from them.

00:54:17.140 --> 00:54:18.681
This is one of the
problems with DRM,

00:54:18.681 --> 00:54:22.210
is that we say there are
all these devices that

00:54:22.210 --> 00:54:24.070
should exist now but
don't, because it's

00:54:24.070 --> 00:54:26.630
against the law to break DRM
even for a legal purpose.

00:54:26.630 --> 00:54:29.260
And so you stick a
CD in your computer,

00:54:29.260 --> 00:54:30.730
and it wakes up
some software that

00:54:30.730 --> 00:54:31.930
came from the
manufacturer that says,

00:54:31.930 --> 00:54:33.888
I see you're visiting us
from the 20th century.

00:54:33.888 --> 00:54:35.950
Would you like to move
your music into the 21st?

00:54:35.950 --> 00:54:38.397
And handily puts it
on your mobile device,

00:54:38.397 --> 00:54:40.480
and lets you turn it into
a ring tone, alarm tone,

00:54:40.480 --> 00:54:41.324
and everything else.

00:54:41.324 --> 00:54:42.740
Stick a DVD in,
and all it will do

00:54:42.740 --> 00:54:45.540
was what it could do in
1996, which is play it.

00:54:45.540 --> 00:54:48.430
20 years, not one new
feature added to DVD.

00:54:48.430 --> 00:54:51.690
And people don't notice.

00:54:51.690 --> 00:54:53.650
They don't even
notice that there

00:54:53.650 --> 00:54:57.940
is nothing that happens when
you put a DVD in apart from what

00:54:57.940 --> 00:54:59.890
it did 20 years ago.

00:54:59.890 --> 00:55:03.370
But if they could do
all the things with DVDs

00:55:03.370 --> 00:55:05.470
that they can do with
CDs, and then we told them

00:55:05.470 --> 00:55:07.660
they couldn't do
it anymore, there

00:55:07.660 --> 00:55:09.610
would be blood in the streets.

00:55:09.610 --> 00:55:13.090
And what Obama was very
canny about was creating

00:55:13.090 --> 00:55:16.330
an unsustainable health care
system that nevertheless

00:55:16.330 --> 00:55:19.360
insured 22 million uninsured
people, who would then,

00:55:19.360 --> 00:55:22.180
when that system ran up against
the limits of the compromises

00:55:22.180 --> 00:55:24.922
he had to make with the insurers
to get it through, would,

00:55:24.922 --> 00:55:26.380
instead of saying,
all right, then,

00:55:26.380 --> 00:55:28.130
I guess we'll go back
to the old bad ways,

00:55:28.130 --> 00:55:30.276
would then plump
for single payer.

00:55:30.276 --> 00:55:31.650
JOHN SCALZI: I
was wondering when

00:55:31.650 --> 00:55:33.900
we would get to health care
on that, because that is--

00:55:33.900 --> 00:55:35.920
[LAUGHTER]

00:55:35.920 --> 00:55:40.720
--because boy, that is the
one that really does point

00:55:40.720 --> 00:55:42.430
to what he is saying there.

00:55:42.430 --> 00:55:45.460
I mean, the fact is
that, if all of a sudden,

00:55:45.460 --> 00:55:48.490
I have to pay an extra $20 for
the tier that allows me to get

00:55:48.490 --> 00:55:52.840
Netflix, which I already get
for free minus the Netflix

00:55:52.840 --> 00:55:56.260
subscription cost,
or that it basically

00:55:56.260 --> 00:55:59.380
goes into the cable
model, then people are

00:55:59.380 --> 00:56:01.840
going to freak out about it.

00:56:01.840 --> 00:56:06.430
Because they already have it.

00:56:06.430 --> 00:56:09.080
That's their already
ground-level expectation.

00:56:09.080 --> 00:56:12.700
Once you give people something,
and you give it sufficient time

00:56:12.700 --> 00:56:14.770
to take root as that
is the expectation,

00:56:14.770 --> 00:56:17.950
that is always going to be
part of that expectation.

00:56:17.950 --> 00:56:22.690
And you do have basically
what are, I would say,

00:56:22.690 --> 00:56:25.060
Randian acolytes going,
no, we should actually

00:56:25.060 --> 00:56:28.360
do it this particular way,
and pare away everything

00:56:28.360 --> 00:56:31.552
that doesn't allow
you to, or that

00:56:31.552 --> 00:56:33.760
has anything to do with the
government doing anything

00:56:33.760 --> 00:56:36.519
other than shooting
people, and saying,

00:56:36.519 --> 00:56:37.810
oh, no, this is more efficient.

00:56:37.810 --> 00:56:41.080
And of course, we can trust
other people to do that.

00:56:41.080 --> 00:56:42.740
And it just doesn't work.

00:56:42.740 --> 00:56:45.910
I mean, implicit in a lot
of the philosophies that

00:56:45.910 --> 00:56:49.060
lead to something like
breaking net neutrality

00:56:49.060 --> 00:56:52.510
or taking away the health
care that other people have

00:56:52.510 --> 00:56:56.170
is the assumption that
the only things that exist

00:56:56.170 --> 00:57:00.520
are you and the ground no
more than six feet under you.

00:57:00.520 --> 00:57:03.707
And so everything else will just
sort of take care of itself.

00:57:03.707 --> 00:57:04.790
And of course, it doesn't.

00:57:04.790 --> 00:57:07.030
And that's the aspect, I
think, in both of our books.

00:57:07.030 --> 00:57:08.560
Everything is interconnected.

00:57:08.560 --> 00:57:11.530
Everything works together or
it doesn't, but there's always

00:57:11.530 --> 00:57:14.900
going to be factors that
you have to deal with.

00:57:14.900 --> 00:57:17.500
I, obviously, and
I think this is

00:57:17.500 --> 00:57:19.000
a non-controversial
statement, think

00:57:19.000 --> 00:57:24.040
that trying to reverse net
neutrality is purely stupid.

00:57:24.040 --> 00:57:27.590
It doesn't benefit anyone but a
certain number of small people,

00:57:27.590 --> 00:57:29.430
again, up at the top.

00:57:29.430 --> 00:57:33.850
It is going to present real
issues for the vast majority

00:57:33.850 --> 00:57:35.710
of people at the bottom.

00:57:35.710 --> 00:57:38.830
And the potential
for the internet,

00:57:38.830 --> 00:57:41.200
and the potentials for
these networks, which

00:57:41.200 --> 00:57:47.440
is to have the potential to
raise up and then flatten out

00:57:47.440 --> 00:57:49.910
things like access,
things like education,

00:57:49.910 --> 00:57:55.270
things like communication,
goes away simply

00:57:55.270 --> 00:57:59.680
for the benefit of three
or four or five companies

00:57:59.680 --> 00:58:02.307
and the attendant CEOs and
executive class of those.

00:58:02.307 --> 00:58:03.640
CORY DOCTOROW: And shareholders.

00:58:03.640 --> 00:58:04.930
JOHN SCALZI: And bluntly--

00:58:04.930 --> 00:58:06.388
and I'm sorry that
I'm going to use

00:58:06.388 --> 00:58:08.980
a bad word here on the Google
streaming thing-- fuck that.

00:58:08.980 --> 00:58:11.150
I'm not here for the top 10.

00:58:11.150 --> 00:58:13.600
I'm speaking as someone
who's in the 1% myself.

00:58:13.600 --> 00:58:15.430
I'm not here for those people.

00:58:15.430 --> 00:58:18.070
I want the benefit
of this for everyone,

00:58:18.070 --> 00:58:22.510
because I also have come down
from the very bottom of our US

00:58:22.510 --> 00:58:25.450
society, and I know how
crappy and how awful it is,

00:58:25.450 --> 00:58:31.150
and how trivial it is to
improve the lives of people

00:58:31.150 --> 00:58:33.730
at the bottom through
things like access

00:58:33.730 --> 00:58:36.250
to computers, to
things like networks,

00:58:36.250 --> 00:58:38.590
to things like education.

00:58:38.590 --> 00:58:43.210
And so every time you
have an administration

00:58:43.210 --> 00:58:46.930
like this administration,
which is just full-scale,

00:58:46.930 --> 00:58:51.310
let's sprint as
fast as we possibly

00:58:51.310 --> 00:58:56.060
can towards oligarchy,
because to the rest of you,

00:58:56.060 --> 00:58:58.450
then, yeah you get my back up.

00:58:58.450 --> 00:59:01.769
So the current
head of the FCC can

00:59:01.769 --> 00:59:04.060
go dunk his head in the toilet
and flush several times,

00:59:04.060 --> 00:59:05.510
as far as I'm concerned.

00:59:05.510 --> 00:59:07.087
We need net neutrality.

00:59:07.087 --> 00:59:08.001
[APPLAUSE]

00:59:08.001 --> 00:59:09.829
CORY DOCTOROW: Awesome.

00:59:09.829 --> 00:59:11.660
Fight the power.

00:59:11.660 --> 00:59:13.330
JOHN SCALZI: Exactly.

00:59:13.330 --> 00:59:15.290
SPEAKER: Let's hear it
again for John and Cory.

00:59:15.290 --> 00:59:15.990
That was awesome.

00:59:15.990 --> 00:59:16.290
JOHN SCALZI: Thank you guys.

00:59:16.290 --> 00:59:17.498
CORY DOCTOROW: Thank you all.

00:59:17.498 --> 00:59:20.540
[APPLAUSE]

