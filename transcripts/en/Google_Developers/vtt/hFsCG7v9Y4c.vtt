WEBVTT
Kind: captions
Language: en

00:00:04.820 --> 00:00:07.460
CHRIS WILSON: Good afternoon
and welcome to Turning

00:00:07.460 --> 00:00:08.580
the Web Up to 11.

00:00:08.580 --> 00:00:09.800
I'm Chris Wilson.

00:00:09.800 --> 00:00:12.300
I'm a Developer Advocate
on the Chrome team.

00:00:12.300 --> 00:00:13.790
And I'm here to take you
on a journey through

00:00:13.790 --> 00:00:15.200
the Web Audio API.

00:00:15.200 --> 00:00:17.190
So if you didn't know what
I was going to talk

00:00:17.190 --> 00:00:19.950
about, now you do.

00:00:19.950 --> 00:00:22.780
I wanted to start by showing why
I'm so excited about the

00:00:22.780 --> 00:00:24.370
Web Audio API.

00:00:24.370 --> 00:00:28.300
When I first ran across the Web
Audio work, I got really

00:00:28.300 --> 00:00:30.400
excited because for the last
couple years, I've gotten

00:00:30.400 --> 00:00:33.070
really interested in building
and using software

00:00:33.070 --> 00:00:36.740
synthesizers, drum machines, all
kinds of production stuff,

00:00:36.740 --> 00:00:40.040
on desktop and also
on tablets.

00:00:40.040 --> 00:00:42.510
And I'd gotten really
excited about this.

00:00:42.510 --> 00:00:43.940
I wanted to start
building my own.

00:00:43.940 --> 00:00:46.900
And as I looked at the Web Audio
API, it looked super

00:00:46.900 --> 00:00:49.160
easy to do, super interesting.

00:00:49.160 --> 00:00:52.480
And I actually very quickly
realized that most of building

00:00:52.480 --> 00:00:55.860
a software synthesizer with
web audio ends up being a

00:00:55.860 --> 00:00:58.210
really big user interface
chore.

00:00:58.210 --> 00:01:00.810
And I'm not a great
UI designer.

00:01:00.810 --> 00:01:04.209
You'll probably notice
that during my deck.

00:01:04.209 --> 00:01:06.880
So I set my sights on a
different challenge.

00:01:06.880 --> 00:01:09.130
Because I wanted to do something
that was really

00:01:09.130 --> 00:01:11.790
pretty heavy duty with
audio processing.

00:01:11.790 --> 00:01:15.240
So I decided I would set my
sights on making robot voices.

00:01:15.240 --> 00:01:20.640
Or more particularly, building
a vocoder and trying to

00:01:20.640 --> 00:01:25.540
replicate Styx's seminal
1983 hit "Mr. Roboto."

00:01:25.540 --> 00:01:27.850
And I'm actually happy
to report that I've

00:01:27.850 --> 00:01:29.650
managed to do this.

00:01:29.650 --> 00:01:31.960
This is actually a vocoder
that I built.

00:01:31.960 --> 00:01:33.620
It's up on GitHub right now.

00:01:33.620 --> 00:01:35.210
There's a link to it at
the end of the deck.

00:01:35.210 --> 00:01:38.640
So you can go play with it
yourself, or fork it and do

00:01:38.640 --> 00:01:40.710
all kinds of interesting
things with it.

00:01:40.710 --> 00:01:45.225
So how many people know what a
vocoder is or how it works?

00:01:45.225 --> 00:01:48.730
Yeah, the guy on the Web Audio
team doesn't actually get to

00:01:48.730 --> 00:01:49.290
raise his hand.

00:01:49.290 --> 00:01:50.610
But I kind of figured.

00:01:50.610 --> 00:01:52.980
So I don't want to get
really deeply to

00:01:52.980 --> 00:01:54.770
vocoder theory or anything.

00:01:54.770 --> 00:01:59.090
Basically, what a vocoder does
is it takes one signal,

00:01:59.090 --> 00:02:01.260
generally called the modulator,
it's usually a

00:02:01.260 --> 00:02:02.030
vocal sample.

00:02:02.030 --> 00:02:04.290
Something like this--

00:02:04.290 --> 00:02:07.650
PLAYBACK: Four score and seven
years ago, our fathers brought

00:02:07.650 --> 00:02:09.830
forth on this continent.

00:02:09.830 --> 00:02:12.770
CHRIS WILSON: And it maps the
frequency characteristics of

00:02:12.770 --> 00:02:14.050
that sound over time.

00:02:14.050 --> 00:02:16.190
It chops it up into
frequency bands.

00:02:16.190 --> 00:02:18.570
And then it watches how
much energy is in

00:02:18.570 --> 00:02:20.040
each frequency band.

00:02:20.040 --> 00:02:22.890
And it maps it onto a different
signal, the carrier

00:02:22.890 --> 00:02:25.670
signal, which is usually
a synthesized sound.

00:02:25.670 --> 00:02:26.868
Something like this--

00:02:26.868 --> 00:02:28.540
[BUZZING NOISE]

00:02:28.540 --> 00:02:30.840
CHRIS WILSON: And I had
to tell the audio guys

00:02:30.840 --> 00:02:33.550
beforehand, No, that's not
something going wrong.

00:02:33.550 --> 00:02:34.720
That is actually what
it's supposed to

00:02:34.720 --> 00:02:36.630
sound like right now.

00:02:36.630 --> 00:02:37.900
It sounds really awful, right?

00:02:37.900 --> 00:02:40.580
But when you actually map the
frequency characteristics onto

00:02:40.580 --> 00:02:43.406
that sound, it ends up sounding
kind of like this--

00:02:43.406 --> 00:02:43.638
PLAYBACK: [ROBOT VOICE]

00:02:43.638 --> 00:02:46.150
Four score and seven years ago,
our fathers brought forth

00:02:46.150 --> 00:02:47.426
on this continent.

00:02:47.426 --> 00:02:47.910
[CONTINUES PLAYING
IN BACKGROUND]

00:02:47.910 --> 00:02:48.500
CHRIS WILSON: It's
kind of cool.

00:02:48.500 --> 00:02:51.550
It's actually somewhat
recognizable.

00:02:51.550 --> 00:02:56.030
Now the interesting thing about
this code, to me after

00:02:56.030 --> 00:02:59.810
having written it, is that this
is not being precomputed.

00:02:59.810 --> 00:03:02.030
This is actually
happening live.

00:03:02.030 --> 00:03:03.890
In fact, I can change
characteristics.

00:03:03.890 --> 00:03:06.040
Like I can detune the
voices being used.

00:03:06.040 --> 00:03:07.300
[VOICE SPEEDS UP]

00:03:07.300 --> 00:03:09.186
CHRIS WILSON: And change
how it sounds.

00:03:09.186 --> 00:03:14.240
[VOICE SLOWS DOWN]

00:03:14.240 --> 00:03:16.920
CHRIS WILSON: Or I can also
change what voices are being

00:03:16.920 --> 00:03:18.310
used to produce it.

00:03:18.310 --> 00:03:20.110
So if I grab and--

00:03:20.110 --> 00:03:25.351
[VOICE DEEPENS]

00:03:25.351 --> 00:03:26.630
CHRIS WILSON: I'm probably using
a different sample or

00:03:26.630 --> 00:03:28.780
something like that.

00:03:28.780 --> 00:03:31.260
So I have a lot of control
over what's going on.

00:03:31.260 --> 00:03:35.120
In fact, the only bit of my
JavaScript code that's running

00:03:35.120 --> 00:03:37.870
while this is going, is the
stuff used to animate the

00:03:37.870 --> 00:03:40.360
vocoder bands, how the frequency
bands are jumping

00:03:40.360 --> 00:03:44.180
around, and the input
and output signals.

00:03:44.180 --> 00:03:48.160
So the ability to build rich
audio applications like this.

00:03:48.160 --> 00:03:50.380
Because by the way, I'm
not an audio engineer.

00:03:50.380 --> 00:03:53.930
I'm not a digital signal
processing expert or anything.

00:03:53.930 --> 00:03:57.940
It did take me a lot of trial
and error to build this.

00:03:57.940 --> 00:04:01.950
But the ability to build rich
audio apps like this, without

00:04:01.950 --> 00:04:04.400
having a degree in audio
engineering, is why I'm so

00:04:04.400 --> 00:04:06.650
excited about the processing
capabilities here.

00:04:10.580 --> 00:04:11.310
And I will stop that.

00:04:11.310 --> 00:04:12.560
Because you can go play
with it yourself.

00:04:15.230 --> 00:04:17.079
Oops.

00:04:17.079 --> 00:04:19.890
Click on my slides here.

00:04:19.890 --> 00:04:22.940
So you might start out by
asking, why do we even need

00:04:22.940 --> 00:04:24.260
another API?

00:04:24.260 --> 00:04:27.510
We already have the HTML5
audio element.

00:04:27.510 --> 00:04:29.790
And I love the HTML5
audio element.

00:04:29.790 --> 00:04:32.220
Because it wraps everything
about audio--

00:04:32.220 --> 00:04:35.490
loading, decoding, and playing
audio-- all up into one easy,

00:04:35.490 --> 00:04:36.770
declarative step.

00:04:36.770 --> 00:04:36.970
Right?

00:04:36.970 --> 00:04:38.770
You stick an audio tag in.

00:04:38.770 --> 00:04:40.730
You tell it whether you want to
show the controls or not,

00:04:40.730 --> 00:04:43.620
whether you want to pre-load
it, give it the source, and

00:04:43.620 --> 00:04:44.380
you're good to go.

00:04:44.380 --> 00:04:45.455
Like I can--

00:04:45.455 --> 00:04:47.520
gonna turn my sound down
just a little here.

00:04:50.610 --> 00:04:51.400
I click the button.

00:04:51.400 --> 00:04:52.360
[LASER SOUND]

00:04:52.360 --> 00:04:53.800
CHRIS WILSON: I probably
can turn it back up.

00:04:53.800 --> 00:04:54.760
[LASER SOUND]

00:04:54.760 --> 00:04:55.300
CHRIS WILSON: Click
the button.

00:04:55.300 --> 00:04:56.250
And it plays the sound.

00:04:56.250 --> 00:04:58.660
In fact, I even get built-in
scrubbing of the sound.

00:04:58.660 --> 00:05:00.132
So I can--

00:05:00.132 --> 00:05:02.460
if I stop hitting my
right button--

00:05:02.460 --> 00:05:03.300
[PLAYS END OF LASER SOUND]

00:05:03.300 --> 00:05:04.330
CHRIS WILSON: I can scrub
it to part of the

00:05:04.330 --> 00:05:06.230
sound and hit play.

00:05:06.230 --> 00:05:07.390
Now this is great.

00:05:07.390 --> 00:05:10.170
But the thing that you don't
get from the HTML5 audio

00:05:10.170 --> 00:05:14.220
element is you don't get
sample-accurate control over

00:05:14.220 --> 00:05:16.310
when the sound is going
to be played.

00:05:16.310 --> 00:05:19.120
And it really struggles with
scalability, when you have a

00:05:19.120 --> 00:05:21.760
whole bunch of sounds what you
want to play all at the same

00:05:21.760 --> 00:05:23.960
time or very close
to each other.

00:05:23.960 --> 00:05:27.290
It's kind of a challenge to
get it to scale to that.

00:05:27.290 --> 00:05:29.340
Now the Web Audio API is
designed a little bit

00:05:29.340 --> 00:05:29.750
differently.

00:05:29.750 --> 00:05:32.560
It's really designed around
this idea of having very

00:05:32.560 --> 00:05:35.330
precise timing of
lots of sounds.

00:05:35.330 --> 00:05:39.534
So I can play the same
sound sample.

00:05:39.534 --> 00:05:40.490
[LASER SOUND]

00:05:40.490 --> 00:05:42.460
CHRIS WILSON: But I can also
play it a lot of times.

00:05:42.460 --> 00:05:44.260
[MULTIPLE SIMULTANEOUS
LASER SOUNDS]

00:05:44.260 --> 00:05:48.050
CHRIS WILSON: And it's very
precise in timing as to when

00:05:48.050 --> 00:05:53.140
it's playing, exactly when
I hit the button.

00:05:53.140 --> 00:05:56.300
The Web Audio API also provides
a really rich audio

00:05:56.300 --> 00:06:00.640
pipeline for building effects
and filters and routing audio

00:06:00.640 --> 00:06:02.680
around in different
powerful ways.

00:06:02.680 --> 00:06:05.210
So adding an effect
to that same sound

00:06:05.210 --> 00:06:06.150
file is really easy.

00:06:06.150 --> 00:06:09.110
[LASER SOUND ECHOING]

00:06:09.110 --> 00:06:11.960
CHRIS WILSON: And then finally,
the Web Audio API

00:06:11.960 --> 00:06:15.240
builds in a bunch of hooks
so you can analyze, and

00:06:15.240 --> 00:06:18.090
visualize, and kind of
manipulate the data on the

00:06:18.090 --> 00:06:19.150
fly, as well.

00:06:19.150 --> 00:06:22.790
So it's really pretty easy
to build something like--

00:06:22.790 --> 00:06:24.470
[MUSIC PLAYING WITH
VISUAL ANALYZER]

00:06:24.470 --> 00:06:27.040
CHRIS WILSON: A visual
analyzer.

00:06:27.040 --> 00:06:28.640
I actually built this
visual analyzer

00:06:28.640 --> 00:06:30.280
special for this talk.

00:06:30.280 --> 00:06:31.210
And it didn't take very long.

00:06:31.210 --> 00:06:34.560
We're going to walk through the
code a little bit later.

00:06:34.560 --> 00:06:38.680
So looking at the API from the
top down, it's kind of

00:06:38.680 --> 00:06:41.820
surprising that it's actually
designed to be a relatively

00:06:41.820 --> 00:06:43.060
high-level API.

00:06:43.060 --> 00:06:47.820
It's really pretty easy to do
basic tasks in the API, like--

00:06:47.820 --> 00:06:49.150
PLAYBACK: Play sound now.

00:06:49.150 --> 00:06:50.430
CHRIS WILSON: Playing a sound.

00:06:50.430 --> 00:06:51.810
That's the code for
it right there.

00:06:51.810 --> 00:06:54.840
That's all that I needed to
do to play that sound.

00:06:54.840 --> 00:06:56.770
Because I'd already had the
buffer loaded and we'll talk

00:06:56.770 --> 00:06:58.390
about that.

00:06:58.390 --> 00:07:02.800
But even better than that, the
effects and filters engine

00:07:02.800 --> 00:07:06.210
doesn't require you to
be a DSP engineer.

00:07:06.210 --> 00:07:09.490
If you told me that in order to
build that vocoder I had to

00:07:09.490 --> 00:07:14.160
go build my own FFT algorithm
implementation, and come up

00:07:14.160 --> 00:07:16.450
with a bunch of matrices
and transforms, and

00:07:16.450 --> 00:07:18.810
stick it all together.

00:07:18.810 --> 00:07:21.200
I would have walked away and
done something else, frankly.

00:07:21.200 --> 00:07:24.700
Math is not my favorite thing
to do on a sunny afternoon.

00:07:24.700 --> 00:07:29.030
So I probably would have figured
out something else.

00:07:29.030 --> 00:07:32.290
But if you want to do that, if
you want to get right down

00:07:32.290 --> 00:07:35.980
into the guts and do your own
processing in JavaScript, on

00:07:35.980 --> 00:07:38.300
the fly, you absolutely
can do that with the

00:07:38.300 --> 00:07:40.950
Web Audio API, too.

00:07:40.950 --> 00:07:43.090
But most of the effects engine,
and certainly the

00:07:43.090 --> 00:07:48.150
routing engine that we provide
in the implementation, it uses

00:07:48.150 --> 00:07:49.630
a separate high-priority
thread.

00:07:49.630 --> 00:07:53.750
It uses native implementation of
FFTs and things like that.

00:07:53.750 --> 00:07:57.950
And that way we can resist
problems like glitching.

00:07:57.950 --> 00:08:02.980
So if you have an application
that has pretty rich visuals

00:08:02.980 --> 00:08:05.373
and nice animation, here.

00:08:05.373 --> 00:08:11.050
[PLAYS POOL GAME]

00:08:11.050 --> 00:08:13.810
CHRIS WILSON: I never sink
anywhere when I do this.

00:08:13.810 --> 00:08:15.710
But this actually has
really rich sound.

00:08:15.710 --> 00:08:16.690
It's in 3D.

00:08:16.690 --> 00:08:19.910
So you actually hear the balls
clicking together in the

00:08:19.910 --> 00:08:21.380
appropriate place
and everything.

00:08:21.380 --> 00:08:22.970
It works better with headphones

00:08:22.970 --> 00:08:25.730
obviously than in the room.

00:08:25.730 --> 00:08:27.670
But you could tell
the sound wasn't

00:08:27.670 --> 00:08:28.870
interfering with the audio.

00:08:28.870 --> 00:08:30.830
And the audio wasn't interfering
with the sound.

00:08:30.830 --> 00:08:35.380
And this is really critical,
to not have these things

00:08:35.380 --> 00:08:39.299
interact with each other
accidentally.

00:08:39.299 --> 00:08:42.520
Now when you look at what you
need to build gaming.

00:08:42.520 --> 00:08:45.610
Because there are really two
major scenarios that we're

00:08:45.610 --> 00:08:47.020
super interested in--

00:08:47.020 --> 00:08:50.220
music applications and gaming.

00:08:50.220 --> 00:08:54.450
Gaming has a lot of features
that are expected for high-end

00:08:54.450 --> 00:08:56.140
console games.

00:08:56.140 --> 00:08:58.720
You expect to see things like
I talked before about very

00:08:58.720 --> 00:09:01.100
precise timing of audio
elements and

00:09:01.100 --> 00:09:02.680
simultaneous sounds.

00:09:02.680 --> 00:09:05.460
But you also expect to be able
to do things like position

00:09:05.460 --> 00:09:09.400
sound in 3D, have automatic
effects happen, like Doppler

00:09:09.400 --> 00:09:12.890
shift when the siren races past
you and the pitch seems

00:09:12.890 --> 00:09:17.270
to change because of
the physics of it.

00:09:17.270 --> 00:09:19.820
You also want to be able to do
things like filtering effects.

00:09:19.820 --> 00:09:22.890
So that, if you're doing a
live chat, you want it to

00:09:22.890 --> 00:09:25.920
sound like it's coming over the
radio or over a telephone.

00:09:25.920 --> 00:09:28.400
So I can take that same
sample I did earlier--

00:09:28.400 --> 00:09:29.770
PLAYBACK: Play sound now.

00:09:29.770 --> 00:09:31.550
CHRIS WILSON: And filter it so
it sounds like it's coming

00:09:31.550 --> 00:09:35.080
over a really kind of
crappy-quality telephone.

00:09:35.080 --> 00:09:38.860
And, of course, replicating
acoustic environments.

00:09:38.860 --> 00:09:42.260
Like if you fire your BFG 9,000
in a huge hall, you

00:09:42.260 --> 00:09:44.740
expect it to sound a little
different than if you fire it

00:09:44.740 --> 00:09:47.570
in a small room.

00:09:47.570 --> 00:09:50.420
And, of course, you need the
ability to create rhythms and

00:09:50.420 --> 00:09:51.920
sequences and things
like that.

00:09:51.920 --> 00:09:53.510
But also do automation.

00:09:53.510 --> 00:09:58.140
Do automated fade ins, fade
outs, that sort of thing.

00:09:58.140 --> 00:10:01.730
On top of that, for music
applications you also need to

00:10:01.730 --> 00:10:03.080
be able to generate sound.

00:10:03.080 --> 00:10:04.570
You need oscillators.

00:10:04.570 --> 00:10:07.760
You need things like dynamics
processing, and distortion,

00:10:07.760 --> 00:10:09.020
and things like that.

00:10:09.020 --> 00:10:11.360
And, of course, this is where
frequency and waveform

00:10:11.360 --> 00:10:15.110
analysis gets really
interesting.

00:10:15.110 --> 00:10:18.250
So I want to start diving in
to how we make this happen

00:10:18.250 --> 00:10:21.340
with the Web Audio API.

00:10:21.340 --> 00:10:22.790
This is an application
that I wrote.

00:10:22.790 --> 00:10:25.190
I'm going to use this multiple
times during the talk.

00:10:25.190 --> 00:10:26.620
It's also posted on GitHub.

00:10:26.620 --> 00:10:28.070
It's also posted publicly.

00:10:28.070 --> 00:10:29.960
So you can just go run it.

00:10:29.960 --> 00:10:32.620
It basically is something that
I built to let me kind of

00:10:32.620 --> 00:10:36.060
explore, visually, the
Web Audio API.

00:10:36.060 --> 00:10:37.950
So the first thing to understand
is that the Web

00:10:37.950 --> 00:10:43.980
Audio API works on the concept
of a node graph.

00:10:43.980 --> 00:10:45.070
You create nodes.

00:10:45.070 --> 00:10:47.810
So I just created an audio
buffer source node.

00:10:47.810 --> 00:10:49.580
And you connect them.

00:10:49.580 --> 00:10:52.170
And in this case I'm going to
connect it to the speakers.

00:10:52.170 --> 00:10:54.160
Because you need to connect
everything to the speakers if

00:10:54.160 --> 00:10:56.110
you want to hear a sound.

00:10:56.110 --> 00:10:58.576
And I'll hit play.

00:10:58.576 --> 00:11:00.570
[BELL DINGS]

00:11:00.570 --> 00:11:01.220
CHRIS WILSON: Yay.

00:11:01.220 --> 00:11:03.330
So you get the basic idea.

00:11:03.330 --> 00:11:06.500
Create nodes, connect them
together, hit play.

00:11:06.500 --> 00:11:13.970
Now these node graphs can
be varying complexity.

00:11:13.970 --> 00:11:18.160
What I just had here, that just
went away, was actually

00:11:18.160 --> 00:11:18.800
really simple.

00:11:18.800 --> 00:11:20.260
It just had two nodes--

00:11:20.260 --> 00:11:22.500
the source code and the speaker

00:11:22.500 --> 00:11:24.310
destination node that I played.

00:11:24.310 --> 00:11:26.600
This is a little bit more
complex node graph.

00:11:26.600 --> 00:11:29.310
But if you work through it one
piece at a time, it's pretty

00:11:29.310 --> 00:11:30.030
straightforward.

00:11:30.030 --> 00:11:31.060
There's a few sources.

00:11:31.060 --> 00:11:32.500
There's a few effects.

00:11:32.500 --> 00:11:35.276
They're mixed together in
sub-mixes and then it goes

00:11:35.276 --> 00:11:38.175
through a compressor
and gets played.

00:11:38.175 --> 00:11:41.840
That vocoder app that I ran in
the beginning, by the way, is

00:11:41.840 --> 00:11:43.510
a really complex node graph.

00:11:43.510 --> 00:11:48.980
It has somewhere around 420
nodes, I think, active while

00:11:48.980 --> 00:11:50.660
it's playing, the whole time.

00:11:50.660 --> 00:11:52.410
So you can tell how
scalable it is.

00:11:52.410 --> 00:11:56.060
Because that's running on my
two-year-old MacBook Pro.

00:11:56.060 --> 00:12:00.360
And really doesn't make the
system sweat even that much.

00:12:00.360 --> 00:12:03.020
For a while I was accidentally
running two copies at the same

00:12:03.020 --> 00:12:05.810
time, I was wondering why I
got a weird effect, but--

00:12:08.310 --> 00:12:14.320
So I want to start by walking
through how to build all of

00:12:14.320 --> 00:12:15.350
this audio code.

00:12:15.350 --> 00:12:18.290
I'm not going to dig into the
code of the vocoder app.

00:12:18.290 --> 00:12:20.360
I started trying to do that and
realized it's kind of hard

00:12:20.360 --> 00:12:23.280
to explain in an hour.

00:12:23.280 --> 00:12:26.530
But, at the same time, I do want
to walk through each of

00:12:26.530 --> 00:12:28.360
these building blocks
and help you

00:12:28.360 --> 00:12:30.120
understand how to use them.

00:12:30.120 --> 00:12:32.500
Now you're going to have
to bear with me.

00:12:32.500 --> 00:12:35.240
We have to get through five
types before I can start

00:12:35.240 --> 00:12:37.570
playing with the fun stuff.

00:12:37.570 --> 00:12:40.300
The first of those is
the AudioContext.

00:12:40.300 --> 00:12:45.400
The AudioContext is kind of the
root of all things audio.

00:12:45.400 --> 00:12:48.500
This is kind of similar to
a 2D canvas context.

00:12:48.500 --> 00:12:51.410
So you create one of these.

00:12:51.410 --> 00:12:53.180
And this is where you
get access to all

00:12:53.180 --> 00:12:54.630
the other fun stuff.

00:12:54.630 --> 00:12:57.000
First and foremost, of course,
this is where you get access

00:12:57.000 --> 00:12:58.560
to the speakers.

00:12:58.560 --> 00:13:00.710
And you have to route
everything to this

00:13:00.710 --> 00:13:03.110
destination, to the speakers,
in order to

00:13:03.110 --> 00:13:04.630
have it make sound.

00:13:04.630 --> 00:13:06.560
Otherwise you're not plugging
the cable into

00:13:06.560 --> 00:13:08.190
anything, in effect.

00:13:08.190 --> 00:13:11.960
But we also have methods here
to create audio buffers, to

00:13:11.960 --> 00:13:16.200
decode audio buffers from common
file formats like mp3,

00:13:16.200 --> 00:13:19.210
or wav, or ogg, or that
sort of thing.

00:13:19.210 --> 00:13:21.890
And this is also down at the
bottom where we create all

00:13:21.890 --> 00:13:23.035
kinds of different
audio nodes.

00:13:23.035 --> 00:13:24.610
And we're going to walk through
each one of those

00:13:24.610 --> 00:13:26.240
audio nodes.

00:13:26.240 --> 00:13:28.080
This is a good time to mention,
by the way, I show

00:13:28.080 --> 00:13:31.940
you a lot of interfaces
in this talk.

00:13:31.940 --> 00:13:35.220
These are not the precise
interface declarations.

00:13:35.220 --> 00:13:37.310
I tried to simplify them to
make them a little more

00:13:37.310 --> 00:13:39.240
understandable.

00:13:39.240 --> 00:13:41.140
And, obviously, like I've
cropped a bunch the audio

00:13:41.140 --> 00:13:42.790
nodes out of the bottom here.

00:13:42.790 --> 00:13:44.430
So look in the spec
if you want the

00:13:44.430 --> 00:13:47.750
full, complete version.

00:13:47.750 --> 00:13:52.580
So this is the first line of Web
Audio applications, or a

00:13:52.580 --> 00:13:54.460
very early line, I should say.

00:13:54.460 --> 00:13:57.390
You need to create a
new AudioContext.

00:13:57.390 --> 00:14:01.110
Right now, obviously, we're a
WebKit prefix, vendor prefix.

00:14:01.110 --> 00:14:03.540
Sooner or later, that will go
away as we move the spec

00:14:03.540 --> 00:14:04.790
through the standards process.

00:14:07.760 --> 00:14:10.930
Now the second type
is AudioNode.

00:14:10.930 --> 00:14:14.330
And I already said Web Audio API
is based on the concept of

00:14:14.330 --> 00:14:15.480
a node graph.

00:14:15.480 --> 00:14:18.810
AudioNode is basically the super
class for all nodes in

00:14:18.810 --> 00:14:19.890
that graph.

00:14:19.890 --> 00:14:22.300
In fact, it really only has
two things that are super

00:14:22.300 --> 00:14:23.050
interesting.

00:14:23.050 --> 00:14:24.020
It has a connect.

00:14:24.020 --> 00:14:25.330
It has a disconnect.

00:14:25.330 --> 00:14:28.380
You want to connect a source
node to a destination node,

00:14:28.380 --> 00:14:31.410
you just call source.connect
and pass it the destination

00:14:31.410 --> 00:14:34.230
you want to connect it to.

00:14:34.230 --> 00:14:36.560
I will point out, here, there's
a second connect

00:14:36.560 --> 00:14:39.920
method that takes
an AudioParam.

00:14:39.920 --> 00:14:42.110
I don't want to get into the
implications of that, yet.

00:14:42.110 --> 00:14:43.190
But I did want to call it out.

00:14:43.190 --> 00:14:46.110
Because it's going to be
important later on.

00:14:46.110 --> 00:14:49.970
And that leads me to the third
type, which is AudioParam.

00:14:49.970 --> 00:14:53.680
The AudioParam is a really
kind of complex type to

00:14:53.680 --> 00:14:55.210
understand at first.

00:14:55.210 --> 00:14:57.990
But it ends up being super,
super important.

00:14:57.990 --> 00:15:00.840
So most of the values, the
things you would think of as

00:15:00.840 --> 00:15:04.470
values in the Web Audio API,
like the volume on a

00:15:04.470 --> 00:15:06.890
gain-controlling node,
for example.

00:15:06.890 --> 00:15:09.280
They're actually represented
as AudioParams.

00:15:09.280 --> 00:15:12.370
Now you can still get and set
the values, the first thing in

00:15:12.370 --> 00:15:13.910
the interface declaration.

00:15:13.910 --> 00:15:15.800
You can go in and grab the
value out of there.

00:15:15.800 --> 00:15:18.020
You can manipulate
it, set it to

00:15:18.020 --> 00:15:19.750
something different, whatever.

00:15:19.750 --> 00:15:21.010
And that's an easy
way to use it.

00:15:21.010 --> 00:15:23.040
And I do use it that
way a lot.

00:15:23.040 --> 00:15:25.090
But at the same time you
can also do things

00:15:25.090 --> 00:15:26.600
that schedule it.

00:15:26.600 --> 00:15:29.220
So you can say, I want to set
the value at a particular time

00:15:29.220 --> 00:15:30.200
in the future.

00:15:30.200 --> 00:15:34.290
Or, my personal favorite, I want
to ramp this over time.

00:15:34.290 --> 00:15:36.520
I want to set the value to zero
now, but I want to ramp

00:15:36.520 --> 00:15:39.940
it up to one over the course
of the next couple seconds.

00:15:39.940 --> 00:15:41.950
And we handle that for you
under the covers in

00:15:41.950 --> 00:15:43.010
the Web Audio API.

00:15:43.010 --> 00:15:45.240
So you get really, really
smooth automation.

00:15:45.240 --> 00:15:47.950
Because of course we can
do that very fast.

00:15:47.950 --> 00:15:51.810
And I will show several examples
of how to do that.

00:15:51.810 --> 00:15:55.050
So we covered the three
infrastructure bits of

00:15:55.050 --> 00:15:57.510
context, nodes, and params.

00:15:57.510 --> 00:15:59.710
Now I want to talk
about sounds.

00:15:59.710 --> 00:16:02.610
And AudioBuffer is the
first thing to talk

00:16:02.610 --> 00:16:03.690
about, audio buffers.

00:16:03.690 --> 00:16:09.110
It represents a decoded
buffer of sound.

00:16:09.110 --> 00:16:11.470
So that means it's actually
in memory.

00:16:11.470 --> 00:16:15.170
And the bits are right there,
lined up in a row for you.

00:16:15.170 --> 00:16:19.210
You can actually access them
in here as a float32array.

00:16:19.210 --> 00:16:22.430
You can go directly twiddle,
get, set, whatever you want to

00:16:22.430 --> 00:16:24.400
do with those bits.

00:16:24.400 --> 00:16:27.740
You can, of course, also see the
sample rate and how long

00:16:27.740 --> 00:16:30.480
the buffer is and that sort
of thing, if you want.

00:16:30.480 --> 00:16:34.350
But if you want to, you can
access the data directly.

00:16:34.350 --> 00:16:39.380
In fact, this set of code
creates an audio buffer and

00:16:39.380 --> 00:16:43.550
gets the data, gets a pointer
to the data, and then just

00:16:43.550 --> 00:16:46.560
sets it to random numbers.

00:16:46.560 --> 00:16:49.340
This sounds like a goofy
thing to do, but

00:16:49.340 --> 00:16:50.326
actually this is how--

00:16:50.326 --> 00:16:52.310
[STATIC]

00:16:52.310 --> 00:16:54.290
CHRIS WILSON: This is how
you get white noise.

00:16:54.290 --> 00:16:56.790
You know, white noise is
actually musically useful in a

00:16:56.790 --> 00:16:57.660
number of cases.

00:16:57.660 --> 00:17:03.050
Like the vocoder app uses white
noise in one place.

00:17:03.050 --> 00:17:05.720
So it's something that
you may want to do.

00:17:05.720 --> 00:17:10.339
Now, of course, you typically
aren't really going to want to

00:17:10.339 --> 00:17:12.319
directly set these values.

00:17:12.319 --> 00:17:15.460
You're going to want to load
them from somewhere.

00:17:15.460 --> 00:17:18.460
So usually, you'll do
something like this.

00:17:18.460 --> 00:17:22.960
This is using pretty standard
XMLHttpRequest code.

00:17:22.960 --> 00:17:27.579
I set up a new XHR request.

00:17:27.579 --> 00:17:28.670
I open it with a get.

00:17:28.670 --> 00:17:31.270
I point it to an mp3
file, in this case.

00:17:31.270 --> 00:17:34.720
The only interesting bits here
are I set the response type to

00:17:34.720 --> 00:17:36.260
arraybuffer.

00:17:36.260 --> 00:17:39.000
Because I want to get this back
as an array, not as a

00:17:39.000 --> 00:17:39.930
bunch of plain text.

00:17:39.930 --> 00:17:40.860
It's an audio file.

00:17:40.860 --> 00:17:41.950
It's probably not--

00:17:41.950 --> 00:17:44.410
plain text is not going to
be super interesting.

00:17:44.410 --> 00:17:48.090
And then when it loads, I
call the AudioContext's

00:17:48.090 --> 00:17:50.520
decodeAudioData method.

00:17:50.520 --> 00:17:55.410
And I give it that buffer that
I just got back from XHR.

00:17:55.410 --> 00:18:00.170
And when it asynchronously
completes, it passes me back a

00:18:00.170 --> 00:18:02.920
buffer, an audio buffer,
that I can then do

00:18:02.920 --> 00:18:05.430
whatever I want with.

00:18:05.430 --> 00:18:08.730
Now what, you might ask, do
I do with an audio buffer?

00:18:08.730 --> 00:18:11.990
It's not a node, you might
notice if you go back to the

00:18:11.990 --> 00:18:13.740
interface that we had
a minute ago.

00:18:13.740 --> 00:18:16.070
It doesn't derive from node.

00:18:16.070 --> 00:18:18.630
It's an object in
its own right.

00:18:18.630 --> 00:18:23.010
So what you do is you use an
AudioBufferSourceNode.

00:18:23.010 --> 00:18:26.480
An AudioBufferSourceNode is a
node that we wrap around--

00:18:26.480 --> 00:18:30.390
or actually, we point
to an audio buffer.

00:18:30.390 --> 00:18:33.890
And it's really important to
understand this is a one shot

00:18:33.890 --> 00:18:35.320
playback node.

00:18:35.320 --> 00:18:38.120
AudioBufferSourceNode can
only be played once.

00:18:38.120 --> 00:18:40.460
This is really, really super
important, which is why I say

00:18:40.460 --> 00:18:42.700
it multiple times during
this slide.

00:18:42.700 --> 00:18:45.670
Once you've played the
AudioBufferSourceNode once,

00:18:45.670 --> 00:18:47.510
you have to throw it away.

00:18:47.510 --> 00:18:49.500
You don't have to throw
away the buffer.

00:18:49.500 --> 00:18:51.610
The buffer you can keep
around and use as many

00:18:51.610 --> 00:18:52.920
times as you want.

00:18:52.920 --> 00:18:54.960
In fact, you can share
it with multiple

00:18:54.960 --> 00:18:56.340
AudioBufferSourceNodes Buffer
Source that are

00:18:56.340 --> 00:18:58.050
playing at the same time.

00:18:58.050 --> 00:19:00.940
When I hit the fire button
repeatedly earlier, I only had

00:19:00.940 --> 00:19:03.100
one copy of that sound buffer.

00:19:03.100 --> 00:19:05.540
I just had multiple buffer
source nodes that pointed to

00:19:05.540 --> 00:19:08.490
it and were playing
at the same time.

00:19:08.490 --> 00:19:12.085
So buffer source node, the type
points to the buffer that

00:19:12.085 --> 00:19:13.840
it's playing.

00:19:13.840 --> 00:19:15.720
It also lets you change
the playback rate.

00:19:15.720 --> 00:19:18.540
So you can make it playback
faster or slower.

00:19:18.540 --> 00:19:21.620
Meaning you can increase
or decrease the pitch.

00:19:21.620 --> 00:19:22.390
You can loop it.

00:19:22.390 --> 00:19:24.090
You can tell it when
to start playing.

00:19:24.090 --> 00:19:27.380
And you can tell when
to stop playing.

00:19:27.380 --> 00:19:29.960
So let's look at how we use
these two together.

00:19:32.690 --> 00:19:35.840
So the top part of this code
sample is the code you just

00:19:35.840 --> 00:19:40.810
saw to do an XMLHttpRequest,
get the data back, call the

00:19:40.810 --> 00:19:43.100
code audio data, and
get a buffer.

00:19:43.100 --> 00:19:45.980
And the only difference is once
I've gotten the buffer, I

00:19:45.980 --> 00:19:47.950
call this method bark().

00:19:47.950 --> 00:19:51.980
And bark() creates a buffer
source node, points the buffer

00:19:51.980 --> 00:19:55.300
for the buffer source node to
what we just loaded, connects

00:19:55.300 --> 00:19:56.300
it to the speaker--

00:19:56.300 --> 00:19:58.230
because remember, we have to
connect everything to the

00:19:58.230 --> 00:20:00.540
speakers or we don't
hear anything--

00:20:00.540 --> 00:20:02.810
and then calls noteOn
to start it.

00:20:02.810 --> 00:20:04.140
And I can--

00:20:04.140 --> 00:20:05.120
[BARK]

00:20:05.120 --> 00:20:06.150
CHRIS WILSON: --make it bark.

00:20:06.150 --> 00:20:08.500
There's "Hello, World,"
right there.

00:20:08.500 --> 00:20:10.400
"Hello, dog," I don't
know, whatever.

00:20:10.400 --> 00:20:12.170
Now if this were my
dog, on the other

00:20:12.170 --> 00:20:14.650
hand, it would be loop.

00:20:14.650 --> 00:20:15.490
Because she barks--

00:20:15.490 --> 00:20:17.990
[REPEATED BARKING]

00:20:17.990 --> 00:20:18.910
CHRIS WILSON: A lot.

00:20:18.910 --> 00:20:21.100
I didn't actually want to
run this for 10 minutes.

00:20:21.100 --> 00:20:24.480
But she does back about that
long, most of the time.

00:20:24.480 --> 00:20:27.980
Now, there are a couple things
that I want to point out here.

00:20:27.980 --> 00:20:30.030
One thing that I should have
mentioned before, when I was

00:20:30.030 --> 00:20:33.590
talking about writing values
in, is the sound values are

00:20:33.590 --> 00:20:35.620
actually floating-point
numbers.

00:20:35.620 --> 00:20:40.010
It's negative one to one is
the range that we have.

00:20:40.010 --> 00:20:41.100
But it's floating point.

00:20:41.100 --> 00:20:45.690
It's not 16-bit integers, it's
not 24-bit integers, or 32-bit

00:20:45.690 --> 00:20:49.310
integers, which if you were
heavy into digital sound in

00:20:49.310 --> 00:20:51.470
the past, you might
have expected.

00:20:51.470 --> 00:20:55.620
The reason is that gives us
a lot of play in where the

00:20:55.620 --> 00:20:57.310
dynamic range gets applied.

00:20:57.310 --> 00:20:59.550
So we still have a lot
of dynamic range.

00:20:59.550 --> 00:21:01.320
We're not wasting the
dynamic range.

00:21:01.320 --> 00:21:04.630
But it helps us to
avoid clipping.

00:21:04.630 --> 00:21:07.370
The second thing here
is I've been passing

00:21:07.370 --> 00:21:09.180
these time values around.

00:21:09.180 --> 00:21:09.990
Like here I call

00:21:09.990 --> 00:21:15.240
audioContext.currentTime plus 600.

00:21:15.240 --> 00:21:20.520
So time, in the Web Audio API,
is an interesting beast

00:21:20.520 --> 00:21:22.550
because it's in seconds.

00:21:22.550 --> 00:21:24.480
It's not in milliseconds.

00:21:24.480 --> 00:21:26.090
But it's a floating-point
number.

00:21:26.090 --> 00:21:29.590
And this is really why we used
milliseconds for a long time.

00:21:29.590 --> 00:21:33.330
I imagine that very few of you
in the room have not used

00:21:33.330 --> 00:21:37.340
setTimeout at one point or
another in web programming.

00:21:37.340 --> 00:21:39.740
SetTimeout takes values
in milliseconds.

00:21:39.740 --> 00:21:42.650
The problem with this is a
millisecond is actually a

00:21:42.650 --> 00:21:44.680
really long time when
you're looking at

00:21:44.680 --> 00:21:46.250
each sample of audio.

00:21:46.250 --> 00:21:46.440
Right?

00:21:46.440 --> 00:21:51.460
In one millisecond, on a
CD-quality audio, that's 44

00:21:51.460 --> 00:21:53.810
and a tenth samples.

00:21:53.810 --> 00:21:55.870
You're not very precise
in that case.

00:21:55.870 --> 00:21:58.710
So we needed something more
precise and went with seconds

00:21:58.710 --> 00:22:00.970
not milliseconds.

00:22:00.970 --> 00:22:04.680
Secondly, you want to
grab this from the

00:22:04.680 --> 00:22:05.930
audioContext.currentTime.

00:22:07.550 --> 00:22:09.460
You don't grab it
from time.now or

00:22:09.460 --> 00:22:10.190
something like that.

00:22:10.190 --> 00:22:12.730
It's not the Unix Epoch clock.

00:22:12.730 --> 00:22:15.830
It actually starts at zero when
the context is created.

00:22:15.830 --> 00:22:19.690
That's not a super useful point
in time, it's more a

00:22:19.690 --> 00:22:23.830
relative unit than an absolute
unit, in that sense.

00:22:23.830 --> 00:22:27.900
But finally, and also critically
important, you kind

00:22:27.900 --> 00:22:28.680
of have to be careful.

00:22:28.680 --> 00:22:31.330
Because this is a
different clock.

00:22:31.330 --> 00:22:34.610
It literally may have a
different clock crystal that

00:22:34.610 --> 00:22:35.690
it's running off of.

00:22:35.690 --> 00:22:38.960
Because audio hardware systems
frequently have a separate

00:22:38.960 --> 00:22:42.090
crystal that keeps the
audio very stable.

00:22:42.090 --> 00:22:44.870
And the CPU may spin its
crystal up or down or

00:22:44.870 --> 00:22:49.890
something like that for power
management reasons.

00:22:49.890 --> 00:22:54.870
So by now, we're, I don't know,
a little under halfway

00:22:54.870 --> 00:22:57.760
through, and you're thinking,
that's great.

00:22:57.760 --> 00:23:00.740
You dumped a bunch of types on
me, a whole bunch of code, and

00:23:00.740 --> 00:23:03.280
fundamentally all you did
was make a dog bark.

00:23:03.280 --> 00:23:06.750
And I can loop that in the
HTML5 audio tag, too.

00:23:06.750 --> 00:23:09.820
So what have you shown me that's
really interesting?

00:23:09.820 --> 00:23:13.230
Well, first and foremost, you
don't usually do code the way

00:23:13.230 --> 00:23:14.970
that I did it there.

00:23:14.970 --> 00:23:18.450
Most particularly, you don't
usually immediately play the

00:23:18.450 --> 00:23:21.190
sound buffer when you've loaded
it with web audio.

00:23:21.190 --> 00:23:22.770
It's called a buffer
for a reason.

00:23:22.770 --> 00:23:24.800
You want to keep it around
for a while.

00:23:24.800 --> 00:23:28.740
In fact, I use about a dozen
sound samples during the

00:23:28.740 --> 00:23:30.080
course of this talk.

00:23:30.080 --> 00:23:31.330
And I've loaded all of them.

00:23:31.330 --> 00:23:33.970
I loaded them all when the page
loaded the first time.

00:23:33.970 --> 00:23:35.340
And I just hang on
to the buffer.

00:23:35.340 --> 00:23:36.980
And I use them whenever
I want.

00:23:36.980 --> 00:23:40.980
So there are a couple samples
that I use repeatedly.

00:23:40.980 --> 00:23:42.010
They're already in memory.

00:23:42.010 --> 00:23:44.150
I don't need to worry about,
Are they still there?

00:23:44.150 --> 00:23:45.170
Do I load them again?

00:23:45.170 --> 00:23:48.620
Are they going to get
cached or not?

00:23:48.620 --> 00:23:52.020
Now, there is, of course,
one other

00:23:52.020 --> 00:23:54.560
critical difference here.

00:23:54.560 --> 00:23:57.660
Which is the Web Audio API has
a lot of audio nodes for

00:23:57.660 --> 00:23:58.720
processing.

00:23:58.720 --> 00:24:02.380
We can do a lot of interesting
things with the audio, once

00:24:02.380 --> 00:24:03.500
we've started playing.

00:24:03.500 --> 00:24:06.110
I just wanted to get
out of the way,

00:24:06.110 --> 00:24:07.760
how do you play something.

00:24:07.760 --> 00:24:09.950
Because it's actually
relatively easy.

00:24:09.950 --> 00:24:13.800
And by the way, if you want to
use the HTML5 audio, as I did

00:24:13.800 --> 00:24:17.420
mention before, HTML5 audio
supports streaming.

00:24:17.420 --> 00:24:20.190
And streaming is a critically
important thing to do for some

00:24:20.190 --> 00:24:21.370
types of audio.

00:24:21.370 --> 00:24:24.630
If you want to play background
music for a game, for example,

00:24:24.630 --> 00:24:26.270
you may not want to load
all of that into

00:24:26.270 --> 00:24:27.820
an in-memory buffer.

00:24:27.820 --> 00:24:32.250
So here, you can take an HTML5
audio element and grab its

00:24:32.250 --> 00:24:34.355
audio output by calling
audioContext.cre

00:24:34.355 --> 00:24:39.670
ateMediaElementSource, handing
it the HTML5 audio or video

00:24:39.670 --> 00:24:43.290
element, and it grabs the sound
output from that tag,

00:24:43.290 --> 00:24:44.710
from that element.

00:24:44.710 --> 00:24:46.930
And then you can connect it
to wherever you want.

00:24:46.930 --> 00:24:48.610
You can connect it to the
effects pipeline.

00:24:48.610 --> 00:24:49.410
You can route it.

00:24:49.410 --> 00:24:52.010
You can change its gain,
all kinds of things.

00:24:52.010 --> 00:24:54.410
So it does integrate very
well into the Web

00:24:54.410 --> 00:24:55.660
Audio API as well.

00:24:58.360 --> 00:25:01.380
So I want to walk through each
of the types of processing

00:25:01.380 --> 00:25:04.460
nodes, and what they can do,
and how to use them.

00:25:04.460 --> 00:25:08.430
The first one, and kind of the
easiest one to knock out

00:25:08.430 --> 00:25:10.720
first, I guess, is
the gain node.

00:25:10.720 --> 00:25:12.170
And gain node is pretty
straightforward.

00:25:12.170 --> 00:25:15.140
It lets you control the
gain, AKA volume.

00:25:15.140 --> 00:25:23.470
And I'll just drop a sound file
in, drop a gain node in,

00:25:23.470 --> 00:25:28.880
connect the sound file to the
gain node, the speakers.

00:25:28.880 --> 00:25:32.610
Let's choose a different
sound here.

00:25:32.610 --> 00:25:34.410
[MUSIC PLAYING]

00:25:34.410 --> 00:25:34.700
CHRIS WILSON: OK.

00:25:34.700 --> 00:25:37.350
So I've done my sound playing.

00:25:37.350 --> 00:25:38.685
And now I can change
the gain value.

00:25:38.685 --> 00:25:40.470
[MUSIC FADES OUT]

00:25:40.470 --> 00:25:41.560
CHRIS WILSON: And it
makes it quieter.

00:25:41.560 --> 00:25:43.280
[MUSIC FADES IN]

00:25:43.280 --> 00:25:46.510
CHRIS WILSON: Or makes
it a lot louder.

00:25:46.510 --> 00:25:50.160
Pretty straightforward,
pretty easy.

00:25:50.160 --> 00:25:53.280
However, it's important to
understand gain nodes are

00:25:53.280 --> 00:25:56.450
fantastically useful and really,
really important.

00:25:56.450 --> 00:25:59.550
Because this is how you create
a lot of the points in the

00:25:59.550 --> 00:26:00.290
routing graph.

00:26:00.290 --> 00:26:03.120
This is how you create things
like sub-mixes.

00:26:03.120 --> 00:26:06.600
If you are implementing a game
sound manager, for example,

00:26:06.600 --> 00:26:10.210
and you're creating a bunch of
effect sounds, like guns

00:26:10.210 --> 00:26:13.340
firing, or whatever, that
probably all gets connected to

00:26:13.340 --> 00:26:15.100
a single gain node
that lets you

00:26:15.100 --> 00:26:16.750
control the effects volume.

00:26:16.750 --> 00:26:18.250
And then you have a different
gain node that lets you

00:26:18.250 --> 00:26:19.620
control the music volume.

00:26:19.620 --> 00:26:21.220
And maybe you have a master
volume that they

00:26:21.220 --> 00:26:22.380
both connect to.

00:26:22.380 --> 00:26:24.480
But all of these
routing points,

00:26:24.480 --> 00:26:25.860
frequently, are gain nodes.

00:26:25.860 --> 00:26:28.161
Because they're an easy
thing to hang off of.

00:26:30.930 --> 00:26:34.420
I should also mention, by the
way, implicitly you can make

00:26:34.420 --> 00:26:37.770
more than one connection at
any node connection point.

00:26:37.770 --> 00:26:41.420
If you connect multiple nodes to
one destination, they just

00:26:41.420 --> 00:26:43.010
automatically mix together.

00:26:43.010 --> 00:26:45.330
So if I have my dog barking--

00:26:45.330 --> 00:26:46.226
[BARK]

00:26:46.226 --> 00:26:46.338
CHRIS

00:26:46.338 --> 00:26:48.020
WILSON: --my cat [MEOW]

00:26:48.020 --> 00:26:50.400
CHRIS WILSON: --and I just
connect them both to the same

00:26:50.400 --> 00:26:52.530
destination down below,
and call noteOn

00:26:52.530 --> 00:26:53.570
on at the same time--

00:26:53.570 --> 00:26:54.950
[SIMULTANEOUS BARK AND MEOW]

00:26:54.950 --> 00:26:55.830
CHRIS WILSON: You get
them both together.

00:26:55.830 --> 00:26:57.620
It just mixes them together.

00:26:57.620 --> 00:27:01.120
And, of course, if I connected
one node to multiple

00:27:01.120 --> 00:27:03.740
destination nodes,
that also works.

00:27:03.740 --> 00:27:05.730
It just automatically
fans out.

00:27:05.730 --> 00:27:08.890
In fact, my vocoder app in the
beginning, I mentioned at one

00:27:08.890 --> 00:27:11.610
point it's a 28-band vocoder.

00:27:11.610 --> 00:27:16.170
That means one of the nodes fans
out to 28 other nodes.

00:27:16.170 --> 00:27:20.180
And then at the other end, 28
nodes all have to mix back

00:27:20.180 --> 00:27:22.020
down together into one node.

00:27:22.020 --> 00:27:23.670
And I just do that by
connecting them.

00:27:23.670 --> 00:27:25.760
I didn't have to do anything
special or come up with a

00:27:25.760 --> 00:27:28.970
special node to do that.

00:27:28.970 --> 00:27:35.370
Now, I also want to point out--
remember I said that all

00:27:35.370 --> 00:27:38.330
the things that you would think
of like parameters, like

00:27:38.330 --> 00:27:41.960
gain on a gain node, are
actually AudioParams.

00:27:41.960 --> 00:27:44.050
This lets you do automation.

00:27:44.050 --> 00:27:46.740
So I can do things like
this automated fade

00:27:46.740 --> 00:27:47.550
that I played earlier.

00:27:47.550 --> 00:27:49.800
[MUSIC FADES IN AND OUT]

00:27:49.800 --> 00:27:51.750
CHRIS WILSON: I should
have played earlier.

00:27:51.750 --> 00:27:53.630
And it fades it in,
and fades it out.

00:27:53.630 --> 00:27:57.140
And I did this simply by saying,
I want to start by

00:27:57.140 --> 00:28:00.080
creating a gain node, inserting
it into the path,

00:28:00.080 --> 00:28:03.510
and then, right now, set
the value to zero.

00:28:03.510 --> 00:28:07.970
In two seconds, I want you
to have ramped up to 1.0.

00:28:07.970 --> 00:28:11.655
And four seconds from now, I
want you to have ramped back

00:28:11.655 --> 00:28:13.300
down to zero.

00:28:13.300 --> 00:28:15.140
These are really
easy to set up.

00:28:15.140 --> 00:28:18.070
And as I said, they happen
very, very smoothly.

00:28:18.070 --> 00:28:21.190
Because we handle them under
the covers a very high time

00:28:21.190 --> 00:28:22.440
resolution.

00:28:25.890 --> 00:28:27.870
Now my next node type--

00:28:27.870 --> 00:28:29.520
it's also relatively basic--

00:28:29.520 --> 00:28:30.770
is a delay node.

00:28:32.870 --> 00:28:36.130
Now, it's pretty obvious
what a delay node does.

00:28:36.130 --> 00:28:39.610
It delays the audio
sent through it.

00:28:39.610 --> 00:28:46.225
So I'm going to create a delay
node and hook it up.

00:28:49.440 --> 00:28:50.700
And I'll hit play--

00:28:50.700 --> 00:28:52.330
[BELL DINGS]

00:28:52.330 --> 00:28:54.090
CHRIS WILSON: --and the
interesting thing is you

00:28:54.090 --> 00:28:55.870
probably didn't notice
anything different.

00:28:55.870 --> 00:28:57.900
Well, it's because what
goes through the

00:28:57.900 --> 00:29:00.620
node is entirely delayed.

00:29:00.620 --> 00:29:02.940
So it's not mixing it
back together with

00:29:02.940 --> 00:29:04.260
the original sound.

00:29:04.260 --> 00:29:06.560
It's only delaying all the
audio going through it.

00:29:06.560 --> 00:29:09.690
So there was an extra 0.2
seconds from when I hit the

00:29:09.690 --> 00:29:11.220
button to when it played.

00:29:11.220 --> 00:29:13.380
But of course that's not
really noticeable.

00:29:13.380 --> 00:29:17.970
Now, if I wanted to, to sound
like an echo, then I can

00:29:17.970 --> 00:29:20.450
connect the original source
straight to the speaker

00:29:20.450 --> 00:29:24.980
destination, too, and
play it again.

00:29:24.980 --> 00:29:27.130
And now you get the
echo effect.

00:29:27.130 --> 00:29:30.260
Now if you really want what you
classically think of as a

00:29:30.260 --> 00:29:34.060
fading feedback echo digital
delay, you want to

00:29:34.060 --> 00:29:35.310
add a gain node in.

00:29:39.410 --> 00:29:40.800
Let's move it where we
can actually see

00:29:40.800 --> 00:29:42.510
where the routing goes.

00:29:42.510 --> 00:29:44.870
And you want to put a cycle
through this delay.

00:29:44.870 --> 00:29:48.170
So the output of the delay
goes into the gain node.

00:29:48.170 --> 00:29:51.420
And the gain node goes
back into the delay.

00:29:51.420 --> 00:29:53.390
And a critically important
piece is set the

00:29:53.390 --> 00:29:55.760
gain less than one.

00:29:55.760 --> 00:29:58.400
And now when I play it, it's
gonna cycle through this

00:29:58.400 --> 00:30:01.150
delay-gain, delay-gain,
delay-gain, until the sound

00:30:01.150 --> 00:30:04.598
just dies back down to zero.

00:30:04.598 --> 00:30:08.420
So you can hear how I can
build a digital delay.

00:30:08.420 --> 00:30:12.200
In fact, for any studio
engineer types in the

00:30:12.200 --> 00:30:15.230
audience, if you want to build
multi-tap delays, you just

00:30:15.230 --> 00:30:17.830
stack a few delay nodes
in parallel.

00:30:17.830 --> 00:30:20.490
If you want to do things like
multi-channel effects like

00:30:20.490 --> 00:30:23.620
ping-pong delay, I'll actually
get into that later.

00:30:23.620 --> 00:30:24.770
They're really easy to do.

00:30:24.770 --> 00:30:28.350
Because you have the basic
tool kit for doing delay.

00:30:28.350 --> 00:30:30.060
And all you have to
do is route it in

00:30:30.060 --> 00:30:31.310
an interesting way.

00:30:35.410 --> 00:30:40.050
Now another amazing thing is
that delay time is actually an

00:30:40.050 --> 00:30:41.390
audio param.

00:30:41.390 --> 00:30:43.170
That means you can schedule
changes to it.

00:30:43.170 --> 00:30:47.270
You can make changes to it live
and things will happen.

00:30:47.270 --> 00:30:51.630
So if I wanted to do code like
this, I can actually increase

00:30:51.630 --> 00:30:53.750
the delay time over time.

00:30:53.750 --> 00:30:56.310
And it automatically
makes it happen.

00:30:56.310 --> 00:30:57.293
So--

00:30:57.293 --> 00:30:57.615
PLAYBACK: [ECHOING]

00:30:57.615 --> 00:30:58.865
Hello.

00:31:02.123 --> 00:31:02.610
CHRIS WILSON: OK.

00:31:02.610 --> 00:31:04.115
That one didn't sound right.

00:31:04.115 --> 00:31:07.250
I'm gonna restart this.

00:31:07.250 --> 00:31:09.960
For some reason, this
demo occasionally

00:31:09.960 --> 00:31:12.680
decides to be finicky.

00:31:12.680 --> 00:31:17.325
So I'm gonna try
that one again.

00:31:17.325 --> 00:31:17.635
PLAYBACK: [ECHOING]

00:31:17.635 --> 00:31:18.885
Hello.

00:31:21.980 --> 00:31:23.170
CHRIS WILSON: There we go.

00:31:23.170 --> 00:31:24.140
Kind of a subtle effect.

00:31:24.140 --> 00:31:27.190
But it's basically increasing
the delay time over time.

00:31:29.720 --> 00:31:33.120
I mentioned before, you can also
connect audio nodes into

00:31:33.120 --> 00:31:38.060
AudioParams, like take the
output of an audio feed and

00:31:38.060 --> 00:31:40.960
pump it straight in as a
parameter controller.

00:31:40.960 --> 00:31:43.880
This is how you do effects like
flanging and chorusing,

00:31:43.880 --> 00:31:46.340
which basically just have an
oscillator modulating the

00:31:46.340 --> 00:31:48.210
display time.

00:31:48.210 --> 00:31:51.980
I'll have a demo about that
up on the net later.

00:31:51.980 --> 00:31:53.820
I didn't put it in here because
it's kind of hard to

00:31:53.820 --> 00:31:55.070
walk through the code for it.

00:31:58.110 --> 00:32:01.170
Now is the time, actually, in
this talk, to introduce a

00:32:01.170 --> 00:32:03.470
really, really good
friend of mine--

00:32:03.470 --> 00:32:05.290
the RealtimeAnalyserNode.

00:32:05.290 --> 00:32:07.920
And I say a really, really good
friend of mine because I

00:32:07.920 --> 00:32:11.960
used these constantly while
I was debugging my vocoder

00:32:11.960 --> 00:32:14.940
application to figure out
what was going on

00:32:14.940 --> 00:32:16.480
in the sound feed.

00:32:16.480 --> 00:32:19.240
Because it turns out, you really
cannot debug an audio

00:32:19.240 --> 00:32:21.930
application by using
console.log to

00:32:21.930 --> 00:32:23.400
spit out sound values.

00:32:23.400 --> 00:32:24.710
It just doesn't work.

00:32:24.710 --> 00:32:29.370
Like you have 44,000 values blow
past in a second, you're

00:32:29.370 --> 00:32:31.560
not going to recognize the
pattern and say, Oh yeah,

00:32:31.560 --> 00:32:33.500
that's a sine wave.

00:32:33.500 --> 00:32:37.090
So the RealtimeAnalyserNode
is what lets

00:32:37.090 --> 00:32:39.410
you visualize things.

00:32:39.410 --> 00:32:40.760
Like this.

00:32:40.760 --> 00:32:42.290
So all that this does--

00:32:42.290 --> 00:32:47.260
you can set this up and tell
it, I want to get an array

00:32:47.260 --> 00:32:49.860
that represents the frequency
band energy.

00:32:49.860 --> 00:32:51.970
And you can tell it how
detailed you want

00:32:51.970 --> 00:32:53.660
that array to be.

00:32:53.660 --> 00:32:56.480
Or you can say, I want kind
of a chunk of the

00:32:56.480 --> 00:32:57.880
waveform, as well.

00:32:57.880 --> 00:33:01.040
We use the same node to give
you both of those features.

00:33:01.040 --> 00:33:03.970
The frequency data you can ask
for as a Unit8 or as a float.

00:33:03.970 --> 00:33:06.660
It's kind of totally up to
you in your coding how

00:33:06.660 --> 00:33:08.730
you want to do it.

00:33:08.730 --> 00:33:13.050
So let's see how we
actually do this.

00:33:13.050 --> 00:33:14.340
So here's how you use it.

00:33:14.340 --> 00:33:17.720
The frequency buckets, by the
way, are split up linearly

00:33:17.720 --> 00:33:21.860
across zero to the NyQuist
frequency, which is half of

00:33:21.860 --> 00:33:24.210
the AudioContext's
sample rate.

00:33:24.210 --> 00:33:28.430
So if you say you want 1,024
buckets, then it's going to

00:33:28.430 --> 00:33:31.470
chop that up evenly
across zero to

00:33:31.470 --> 00:33:35.220
probably 22.05 kilohertz.

00:33:35.220 --> 00:33:39.960
And then, at some point in time,
what you do is you go to

00:33:39.960 --> 00:33:40.730
your analyser.

00:33:40.730 --> 00:33:42.540
And you pass it an array
that you've created.

00:33:42.540 --> 00:33:46.020
And you say, Give me the bite
frequency count data here.

00:33:46.020 --> 00:33:49.730
And it performs the frequency
analysis of the current sound

00:33:49.730 --> 00:33:52.320
and passes it back to you.

00:33:52.320 --> 00:33:55.530
And then of course you just go
in a loop through that array.

00:33:55.530 --> 00:33:58.800
Do whatever you want to make
something interesting

00:33:58.800 --> 00:34:01.630
visually, or do interesting
analysis, or

00:34:01.630 --> 00:34:03.330
whatever you want.

00:34:03.330 --> 00:34:07.060
In the case of this visualizer,
all I did was I

00:34:07.060 --> 00:34:08.760
walked through that array
and drew little

00:34:08.760 --> 00:34:11.120
boxes on the screen.

00:34:11.120 --> 00:34:14.310
But, of course, if you do that
on a RequestAnimationFrame

00:34:14.310 --> 00:34:17.820
timer, then it happens at the
refresh rate of your monitor

00:34:17.820 --> 00:34:18.820
or whatever.

00:34:18.820 --> 00:34:21.479
And you can do something
that looks very live.

00:34:21.479 --> 00:34:21.820
Right.

00:34:21.820 --> 00:34:23.409
You're doing it constantly.

00:34:23.409 --> 00:34:25.170
You're getting lots
of analysis.

00:34:25.170 --> 00:34:27.840
Please, by the way, don't use
setTimeout to do this.

00:34:27.840 --> 00:34:30.460
SetTimeout's not a great way
to do animation anyways.

00:34:30.460 --> 00:34:34.929
But it gets even worse
in sound sometimes.

00:34:34.929 --> 00:34:40.889
So now that we've looked
at frequency analysers.

00:34:40.889 --> 00:34:43.960
Now we can talk about
filter nodes.

00:34:43.960 --> 00:34:46.989
So filtering is a process
that happens in

00:34:46.989 --> 00:34:48.270
the frequency domain.

00:34:48.270 --> 00:34:51.440
It changes the response
across frequencies.

00:34:51.440 --> 00:34:52.909
So we have a bunch of
different types.

00:34:52.909 --> 00:34:56.170
We have LOWPASS, HIGHPASS,
BANDPASS, LOW and HIGH

00:34:56.170 --> 00:34:58.580
shelving filters, PEAKING
filter, NOTCH filter, and

00:34:58.580 --> 00:34:59.760
ALLPASS filter.

00:34:59.760 --> 00:35:01.440
I don't expect to magically
know what all

00:35:01.440 --> 00:35:03.270
those do, or care.

00:35:03.270 --> 00:35:06.590
This actually let you play with
the parameters and see

00:35:06.590 --> 00:35:09.080
what happens when you change
the frequency.

00:35:09.080 --> 00:35:11.730
When you change from a LOWPASS
filter, which lets all the low

00:35:11.730 --> 00:35:15.040
frequencies through but cuts
off the high ones, to a

00:35:15.040 --> 00:35:18.370
HIGHPASS filter, you can
see how it shifts.

00:35:18.370 --> 00:35:21.090
It's a neat little graph to play
with and gives you some

00:35:21.090 --> 00:35:23.530
idea of how things work.

00:35:23.530 --> 00:35:25.810
And, by the way, the parameters
in this are

00:35:25.810 --> 00:35:29.070
frequency and Q, or occasionally
what's referred

00:35:29.070 --> 00:35:32.230
to as quality, or sometimes
resonance.

00:35:32.230 --> 00:35:34.450
Because it's sort of
a related concept.

00:35:34.450 --> 00:35:38.890
So like here, if I pump up the
Q, you can see how it sort of

00:35:38.890 --> 00:35:41.010
accentuates whatever
the frequency is.

00:35:41.010 --> 00:35:44.730
It's causing a resonance
right at that spot.

00:35:44.730 --> 00:35:46.260
Now this is great.

00:35:46.260 --> 00:35:47.910
I'm showing you some
neat graphs.

00:35:47.910 --> 00:35:51.610
You can actually hear and see
how it sounds, by using my

00:35:51.610 --> 00:35:53.880
neat little demo app here.

00:35:53.880 --> 00:35:56.560
And don't worry, this is the
most complex graph I'm going

00:35:56.560 --> 00:35:59.700
to draw in this thing on my
little track-pad here.

00:35:59.700 --> 00:36:03.140
So let's create an
AudioBufferSource, grab an

00:36:03.140 --> 00:36:08.300
analyser, a filter, and
another analyser.

00:36:08.300 --> 00:36:10.630
And let's see if I can get these
all to fit on the screen

00:36:10.630 --> 00:36:11.880
at the same time.

00:36:14.960 --> 00:36:17.540
There we go.

00:36:17.540 --> 00:36:19.366
Connect.

00:36:19.366 --> 00:36:23.060
You know, If I had had time I
would have figured out how to

00:36:23.060 --> 00:36:27.340
pre-load these in
my app, but--

00:36:27.340 --> 00:36:27.830
all right.

00:36:27.830 --> 00:36:30.010
Let's use our same drum
sample and loop it.

00:36:30.010 --> 00:36:31.720
[MUTED DRUMS]

00:36:31.720 --> 00:36:33.820
CHRIS WILSON: And you can hear
how all the high frequencies

00:36:33.820 --> 00:36:35.940
are getting cut off on
this sound sample.

00:36:35.940 --> 00:36:38.860
You can actually see it in the
difference between the before

00:36:38.860 --> 00:36:40.910
and after analyser here.

00:36:40.910 --> 00:36:43.040
And if I play with
the frequency--

00:36:43.040 --> 00:36:46.040
[MUSIC FADES IN]

00:36:46.040 --> 00:36:46.890
CHRIS WILSON: --you can
hear it open up.

00:36:46.890 --> 00:36:49.766
And now I'm pretty much passing
through all of the

00:36:49.766 --> 00:36:50.740
frequencies.

00:36:50.740 --> 00:36:53.216
But just for kicks, let's
crank up the resonance.

00:36:56.204 --> 00:37:02.710
[MUSIC WARPS]

00:37:02.710 --> 00:37:03.030
CHRIS WILSON: OK.

00:37:03.030 --> 00:37:05.930
So I'm not Paul Oakenfold.

00:37:05.930 --> 00:37:07.920
But you get how this
stuff works.

00:37:07.920 --> 00:37:10.870
And you get the application
of these kinds of things.

00:37:10.870 --> 00:37:13.600
Now it's turning into
a UI problem--

00:37:13.600 --> 00:37:16.570
to build some really cool DJ
tools, which I'm kind of

00:37:16.570 --> 00:37:19.360
excited about building next.

00:37:19.360 --> 00:37:23.110
That'll be my next
little fun game.

00:37:23.110 --> 00:37:28.250
Now, I also wanted to point out,
again, frequency and Q?

00:37:28.250 --> 00:37:31.260
They're both AudioParams, so
you can automate them.

00:37:31.260 --> 00:37:34.150
You can change these
automatically over time.

00:37:34.150 --> 00:37:38.720
And so I took this, and I took
the output of a standard, I

00:37:38.720 --> 00:37:41.510
think it's a triangle wave, and
just pumped it straight

00:37:41.510 --> 00:37:43.580
into a filter.

00:37:43.580 --> 00:37:47.090
So the original sound is
an unchanging wave.

00:37:47.090 --> 00:37:50.390
And I just changed the filter
and told it, hey, sweep the

00:37:50.390 --> 00:37:54.720
filter from zero to 2,000 hertz
over the course of two

00:37:54.720 --> 00:37:56.820
seconds, and then back
down to zero.

00:37:56.820 --> 00:37:58.655
I think I automated
the Q, too.

00:37:58.655 --> 00:38:03.110
[SOUND EFFECT]

00:38:03.110 --> 00:38:04.670
CHRIS WILSON: So you can do
these neat little filter

00:38:04.670 --> 00:38:06.890
sweeps really, really easily.

00:38:06.890 --> 00:38:08.980
That actually is the
code snippet pasted

00:38:08.980 --> 00:38:11.720
out of my js file.

00:38:11.720 --> 00:38:14.560
And you can take that same
filter, and you can use it to

00:38:14.560 --> 00:38:16.110
process other things.

00:38:16.110 --> 00:38:18.060
You don't have to have an
unchanging sound that you

00:38:18.060 --> 00:38:18.390
start with.

00:38:18.390 --> 00:38:24.410
[MUSIC PLAYS]

00:38:24.410 --> 00:38:26.436
CHRIS WILSON: Sorry, I should
have cranked that up a little.

00:38:26.436 --> 00:38:31.150
[MUSIC PLAYS LOUDER]

00:38:31.150 --> 00:38:33.710
CHRIS WILSON: So you can do
all kinds of fun things by

00:38:33.710 --> 00:38:36.120
automating those filters, as
well as just twiddling the

00:38:36.120 --> 00:38:37.630
values yourself.

00:38:37.630 --> 00:38:41.130
In fact, filters are also how
you get effects like, I'm

00:38:41.130 --> 00:38:43.940
talking on a telephone, or I'm
talking on an am radio, or

00:38:43.940 --> 00:38:45.490
something like that.

00:38:45.490 --> 00:38:47.660
You can take the original
sound, here--

00:38:47.660 --> 00:38:49.390
PLAYBACK: Play sound now.

00:38:49.390 --> 00:38:50.800
CHRIS WILSON: Which
you heard earlier.

00:38:50.800 --> 00:38:53.550
And all that I do in this other
sample is I pump it

00:38:53.550 --> 00:38:57.140
through a couple of filters to
mask off the low and the high

00:38:57.140 --> 00:38:57.850
frequencies.

00:38:57.850 --> 00:39:01.130
It turns out a telephone sound
is really just-- the old

00:39:01.130 --> 00:39:04.140
telephone system chopped off
all of the upper and lower

00:39:04.140 --> 00:39:04.790
frequencies.

00:39:04.790 --> 00:39:06.810
Because of the way that
they transferred the

00:39:06.810 --> 00:39:08.150
data across the lines.

00:39:08.150 --> 00:39:09.770
PLAYBACK: Play sound now.

00:39:09.770 --> 00:39:12.800
CHRIS WILSON: And you get
something like that, just by

00:39:12.800 --> 00:39:16.130
filtering off those
frequencies.

00:39:16.130 --> 00:39:19.780
CHRIS WILSON: So now we've got
all these really cool sounds,

00:39:19.780 --> 00:39:23.940
or the tools to build all of
them, we need to position them

00:39:23.940 --> 00:39:25.110
in 3D space.

00:39:25.110 --> 00:39:28.210
There's a great tutorial on
HTML5Rocks about this.

00:39:28.210 --> 00:39:30.940
I basically decided I couldn't
improve on that a whole lot,

00:39:30.940 --> 00:39:32.760
so I was just going to show
the demo for it--

00:39:32.760 --> 00:39:34.250
[MUSIC PLAYS]

00:39:34.250 --> 00:39:35.600
CHRIS WILSON: And talk through
it a little bit.

00:39:35.600 --> 00:39:39.420
And you'll see as we
move around here--

00:39:39.420 --> 00:39:46.320
hopefully, you're hearing
the audio move around.

00:39:46.320 --> 00:39:48.580
I wanna thank the sound guys
again for getting the room set

00:39:48.580 --> 00:39:49.040
up for stereo.

00:39:49.040 --> 00:39:51.400
Because it definitely
would not been

00:39:51.400 --> 00:39:52.650
as impressive otherwise.

00:39:55.280 --> 00:39:58.810
So the way that you do this is
you create an AudioPannerNode.

00:39:58.810 --> 00:40:01.690
You just pump your sound into
an AudioPannerNode.

00:40:01.690 --> 00:40:04.770
And you set its position, its
orientation if you want to

00:40:04.770 --> 00:40:08.720
sound to be directional,
and its velocity.

00:40:08.720 --> 00:40:11.330
And this sounds really
complex to do.

00:40:11.330 --> 00:40:13.580
Obviously, it makes sense for
the demo that I just showed

00:40:13.580 --> 00:40:15.470
you where it's really
a 3D space.

00:40:15.470 --> 00:40:18.690
But maybe you just want to take
a normal sound and pan it

00:40:18.690 --> 00:40:20.390
to the left or the right.

00:40:20.390 --> 00:40:22.220
Well that's actually
really easy to do.

00:40:22.220 --> 00:40:24.870
You just create a panner node,
you set the position to

00:40:24.870 --> 00:40:29.910
straight ahead, and then you can
animate the x position to

00:40:29.910 --> 00:40:31.980
change where it is,
left or right.

00:40:31.980 --> 00:40:33.435
And you end up with something
like this--

00:40:33.435 --> 00:40:34.685
[MUSIC PLAYS, PANNING
LEFT AND RIGHT]

00:40:44.340 --> 00:40:46.400
CHRIS WILSON: So it's actually
really easy to do simple

00:40:46.400 --> 00:40:47.130
things, as well.

00:40:47.130 --> 00:40:51.010
You don't have to do super
complex 3D math to figure out

00:40:51.010 --> 00:40:53.720
where to position things.

00:40:53.720 --> 00:40:56.450
This is also, by the way, how
you get Doppler effects.

00:40:56.450 --> 00:40:59.650
That whole setVelocity
method is to set the

00:40:59.650 --> 00:41:01.480
velocity of an object.

00:41:01.480 --> 00:41:03.175
So that you get these
sounds where--

00:41:05.730 --> 00:41:08.170
[SIREN]

00:41:08.170 --> 00:41:10.430
CHRIS WILSON: You can hear the
pitch change as something

00:41:10.430 --> 00:41:11.870
races past you.

00:41:11.870 --> 00:41:18.120
So given the number of
ambulances or policemen that

00:41:18.120 --> 00:41:21.250
I've heard going around on the
streets of San Francisco the

00:41:21.250 --> 00:41:23.650
last couple days, you
hear this a lot.

00:41:23.650 --> 00:41:25.550
But you expect that
sound to change.

00:41:25.550 --> 00:41:28.700
If you were playing a game and
you raced past the police

00:41:28.700 --> 00:41:31.340
officer in the game and the
pitch of the siren didn't

00:41:31.340 --> 00:41:33.230
change, you would
actually notice.

00:41:33.230 --> 00:41:34.250
It would be kind of weird.

00:41:34.250 --> 00:41:34.850
It would be jarring.

00:41:34.850 --> 00:41:38.990
Because that's not the way that
it works in real life.

00:41:38.990 --> 00:41:40.210
And this just magically
happened.

00:41:40.210 --> 00:41:43.640
All you had to do was set the
velocity of the object and we

00:41:43.640 --> 00:41:47.990
knew to change the pitch
of the object.

00:41:47.990 --> 00:41:52.910
Now, all of these things.

00:41:52.910 --> 00:41:55.690
All of these AudioPannerNodes
that may be in play, they're

00:41:55.690 --> 00:41:58.380
all relative to a listener
somewhere.

00:41:58.380 --> 00:42:00.980
You have to position
the person hearing

00:42:00.980 --> 00:42:02.380
all of these things.

00:42:02.380 --> 00:42:06.910
And the person hearing all these
things is an attribute

00:42:06.910 --> 00:42:08.510
of the speakers, in effect.

00:42:08.510 --> 00:42:10.800
It's an attribute of
the entire context.

00:42:10.800 --> 00:42:13.960
So the AudioListener hangs
directly off the AudioContext.

00:42:13.960 --> 00:42:15.260
There's only one of them.

00:42:15.260 --> 00:42:16.350
You don't create these.

00:42:16.350 --> 00:42:17.760
It's always there.

00:42:17.760 --> 00:42:20.770
And you just set your position,
or your orientation

00:42:20.770 --> 00:42:21.410
or velocity.

00:42:21.410 --> 00:42:24.740
When I moved around in that
sound field during the demo a

00:42:24.740 --> 00:42:27.540
couple seconds ago, I was
changing the AudioListener

00:42:27.540 --> 00:42:30.420
properties, as well as the
visual representation of that.

00:42:33.220 --> 00:42:38.040
So with that, I want to jump
to another fun node--

00:42:38.040 --> 00:42:39.290
the ConvolverNode.

00:42:41.600 --> 00:42:48.560
So convolution is a process to
digitally simulate a space, or

00:42:48.560 --> 00:42:50.330
a process actually.

00:42:50.330 --> 00:42:53.910
Because you can use this to
simulate room ambiance, like

00:42:53.910 --> 00:42:56.210
the way sound bounces
around in this room.

00:42:56.210 --> 00:42:58.250
This room has kind of a
nice response to it.

00:42:58.250 --> 00:43:02.560
I can hear my voice bouncing
off the back wall.

00:43:02.560 --> 00:43:06.660
But you can also use it to
simulate an analog processor.

00:43:06.660 --> 00:43:12.230
Something that you use to plug
an audio signal through.

00:43:12.230 --> 00:43:14.140
The way that this works is you
use these things called

00:43:14.140 --> 00:43:15.740
Impulse Response files.

00:43:15.740 --> 00:43:18.480
And Impulse Response files
can be recorded.

00:43:18.480 --> 00:43:21.270
You can literally go into a room
like this with a couple

00:43:21.270 --> 00:43:25.230
microphones and a speaker, play
a set of sounds, and then

00:43:25.230 --> 00:43:27.420
run that through this
convolution processing

00:43:27.420 --> 00:43:30.900
software, and it creates
a sound file that is

00:43:30.900 --> 00:43:33.000
representative of how this room

00:43:33.000 --> 00:43:36.030
responds to a sound impulse.

00:43:36.030 --> 00:43:39.090
Or you can have been generated
algorithmically.

00:43:39.090 --> 00:43:41.550
Or you can just come up with
really wacky ones, which

00:43:41.550 --> 00:43:44.250
usually has very unpredictable
results, of course.

00:43:44.250 --> 00:43:50.150
But fundamentally, in order to
simulate different responses,

00:43:50.150 --> 00:43:52.410
you have to use this
file, a sound file.

00:43:52.410 --> 00:43:55.980
There are tons of these
available on the net, freely.

00:43:55.980 --> 00:43:58.940
You can just go search for
Impulse Response files.

00:43:58.940 --> 00:44:00.000
Tons of them are out there.

00:44:00.000 --> 00:44:03.020
Lots of hall reverbs, room
reverbs, and things like that,

00:44:03.020 --> 00:44:05.740
as well as some really
crazy ones.

00:44:05.740 --> 00:44:08.520
Again, I do want to point out
the output of this node is

00:44:08.520 --> 00:44:10.900
just the processed signal.

00:44:10.900 --> 00:44:13.630
And typically, you don't
just hear the echos.

00:44:13.630 --> 00:44:15.350
You hear the original
sound too.

00:44:15.350 --> 00:44:17.170
So you probably want to mix
these together when you

00:44:17.170 --> 00:44:19.270
actually use it.

00:44:19.270 --> 00:44:21.790
But ConvolverNode is pretty
straightforward because it

00:44:21.790 --> 00:44:24.860
basically has one property that
you really care about.

00:44:24.860 --> 00:44:26.240
It's a buffer.

00:44:26.240 --> 00:44:28.760
Remember I said these are
Impulse Response files.

00:44:28.760 --> 00:44:29.700
They're sound files.

00:44:29.700 --> 00:44:33.130
You load them the same way you
load any other sound sample.

00:44:33.130 --> 00:44:35.370
You just set it here, rather
than setting it in

00:44:35.370 --> 00:44:38.070
AudioBufferSource node.

00:44:38.070 --> 00:44:42.040
So to do this, I'm going to use
my favorite drum sample

00:44:42.040 --> 00:44:43.710
that I keep using.

00:44:43.710 --> 00:44:45.141
[MUSIC PLAYS]

00:44:45.141 --> 00:44:47.050
CHRIS WILSON: Turn that
down a little bit.

00:44:47.050 --> 00:44:51.440
And so I took my drum sound, I
created a ConvolverNode, I

00:44:51.440 --> 00:44:54.210
pumped the drum sound into that
ConvolverNode, but also

00:44:54.210 --> 00:44:55.700
connected it to the speakers--

00:44:55.700 --> 00:44:56.920
to the destination.

00:44:56.920 --> 00:44:58.550
So I hear both of them.

00:44:58.550 --> 00:45:01.030
And then all that I'm going to
do now, is I'm gonna switch

00:45:01.030 --> 00:45:03.780
what the ImpulseResponseBuffer
is.

00:45:03.780 --> 00:45:05.120
So I can change it to a hall--

00:45:05.120 --> 00:45:08.410
[MUSIC ALTERS]

00:45:08.410 --> 00:45:10.770
CHRIS WILSON: Which I
hope you can hear.

00:45:10.770 --> 00:45:12.702
I can change it to
a spring reverb.

00:45:12.702 --> 00:45:14.090
[MUSIC ALTERS]

00:45:14.090 --> 00:45:17.500
CHRIS WILSON: Spring reverb is
an old analog processor that

00:45:17.500 --> 00:45:19.490
literally used springs.

00:45:19.490 --> 00:45:22.010
And you can kind of hear this
weird slapping noise going

00:45:22.010 --> 00:45:22.920
back and forth as a

00:45:22.920 --> 00:45:25.470
characteristic of spring reverb.

00:45:25.470 --> 00:45:27.098
You can do a comb filter.

00:45:27.098 --> 00:45:28.412
[MUSIC ALTERS]

00:45:28.412 --> 00:45:30.396
CHRIS WILSON: Which has a
really, really awful sound.

00:45:30.396 --> 00:45:32.570
I'm not gonna stay
on that one.

00:45:32.570 --> 00:45:36.650
Or, my personal favorite with
drums, is a backwards reverb.

00:45:36.650 --> 00:45:36.950
[MUSIC ALTERS]

00:45:36.950 --> 00:45:39.530
CHRIS WILSON: Because you can
do any Impulse Response.

00:45:39.530 --> 00:45:42.680
This Impulse Response may be
completely the opposite in

00:45:42.680 --> 00:45:45.040
time of what you would
actually hear

00:45:45.040 --> 00:45:47.000
in the reverb space.

00:45:47.000 --> 00:45:48.353
So if I stop it.

00:45:48.353 --> 00:45:50.325
[MUSIC FADES]

00:45:50.325 --> 00:45:53.380
CHRIS WILSON: You can actually
hear the reversed

00:45:53.380 --> 00:45:54.750
reverb sound of that.

00:45:57.390 --> 00:45:58.170
OK.

00:45:58.170 --> 00:46:02.790
So we've talked a lot
about how to build

00:46:02.790 --> 00:46:07.310
these processing systems.

00:46:07.310 --> 00:46:10.310
I want to talk for a minute
about how to synthesize sound.

00:46:10.310 --> 00:46:13.970
How to do musical applications
with sound, not just provide

00:46:13.970 --> 00:46:16.840
ambient environments
for sound.

00:46:16.840 --> 00:46:18.330
First and foremost,
it's actually

00:46:18.330 --> 00:46:20.160
really easy to do this.

00:46:20.160 --> 00:46:23.840
If you go and just do a search
for Web Audio API demos,

00:46:23.840 --> 00:46:27.290
there's a whole bunch of demos
out there that are different

00:46:27.290 --> 00:46:28.050
synthesizers.

00:46:28.050 --> 00:46:29.030
This is only one of them.

00:46:29.030 --> 00:46:30.630
It's actually a fairly
simplistic one,

00:46:30.630 --> 00:46:31.980
which is why use it.

00:46:31.980 --> 00:46:32.460
But--

00:46:32.460 --> 00:46:32.940
[PLAYS SYNTHESIZER]

00:46:32.940 --> 00:46:35.730
CHRIS WILSON: It has controls
for all of these different

00:46:35.730 --> 00:46:39.390
things that I'm playing
around with.

00:46:39.390 --> 00:46:40.180
It's actually--

00:46:40.180 --> 00:46:42.690
the hardest part about building
something like this

00:46:42.690 --> 00:46:45.570
is providing the user
experience for it.

00:46:45.570 --> 00:46:49.530
I've actually built a test-bed
synthesizer out that

00:46:49.530 --> 00:46:52.060
has no UI at all.

00:46:52.060 --> 00:46:55.250
And it's really easy-- like the
actual sound production.

00:46:55.250 --> 00:46:57.670
I want to build an envelope, I
want to stick a filter in, I

00:46:57.670 --> 00:47:00.740
want to control some other
properties of it, is like a

00:47:00.740 --> 00:47:02.220
dozen lines of code.

00:47:02.220 --> 00:47:05.310
The rest of it, the shell for
drawing knobs and everything

00:47:05.310 --> 00:47:09.420
else is actually a lot
more troublesome.

00:47:09.420 --> 00:47:12.640
And remember when I mentioned
before, you can actually

00:47:12.640 --> 00:47:17.820
connect AudioNodes to
AudioParams, as well.

00:47:17.820 --> 00:47:20.840
For those of you who are synth
geeks, like me-- because I've

00:47:20.840 --> 00:47:24.960
loved synthesizers since
I was about 12--

00:47:24.960 --> 00:47:27.060
this is how you get things
like low-frequency

00:47:27.060 --> 00:47:27.710
oscillators.

00:47:27.710 --> 00:47:30.050
It's how you do things
like FM synthesis.

00:47:30.050 --> 00:47:31.950
They're actually just
intersecting two different

00:47:31.950 --> 00:47:36.470
audio signals or multiplying
them together.

00:47:36.470 --> 00:47:39.590
So the first and most
fundamental piece of

00:47:39.590 --> 00:47:42.910
generating sound is
an oscillator.

00:47:42.910 --> 00:47:46.120
Oscillators provide a periodic
waveform source.

00:47:46.120 --> 00:47:50.190
It's going to draw for you, or
create for you, things like a

00:47:50.190 --> 00:47:50.570
sine

00:47:50.570 --> 00:47:52.519
wave, [BEEP]

00:47:52.519 --> 00:47:53.485
CHRIS WILSON: Square wave.

00:47:53.485 --> 00:47:54.934
[BEEP]

00:47:54.934 --> 00:47:55.417
CHRIS WILSON: Sawtooth wave.

00:47:55.417 --> 00:47:57.350
[BEEP]

00:47:57.350 --> 00:47:58.897
CHRIS WILSON: And
a triangle wave.

00:47:58.897 --> 00:48:00.270
[BEEP]

00:48:00.270 --> 00:48:02.400
CHRIS WILSON: Those all sound
kind of vaguely similar.

00:48:02.400 --> 00:48:03.930
It's because I didn't
alter the pitch.

00:48:03.930 --> 00:48:05.360
I haven't filtered them.

00:48:05.360 --> 00:48:07.690
They're not super complex
waveforms.

00:48:07.690 --> 00:48:08.600
But they are different.

00:48:08.600 --> 00:48:10.840
And they have very different
harmonic characteristics,

00:48:10.840 --> 00:48:13.640
which give you some interesting
properties.

00:48:13.640 --> 00:48:16.120
So an oscillator is an
AudioSourceNode.

00:48:16.120 --> 00:48:18.490
It's an audio node that you
can connect up to a

00:48:18.490 --> 00:48:19.610
destination.

00:48:19.610 --> 00:48:24.280
It lets you control the
frequency in hertz, it

00:48:24.280 --> 00:48:26.000
actually also lets you
control the frequency

00:48:26.000 --> 00:48:28.740
with the detune parameter.

00:48:28.740 --> 00:48:31.730
Detuning basically lets you
control using a different unit

00:48:31.730 --> 00:48:32.840
known as cents.

00:48:32.840 --> 00:48:36.040
Cents are great for musical
applications because in an

00:48:36.040 --> 00:48:39.240
equal-tempered scale there's
100 cents per note.

00:48:39.240 --> 00:48:42.840
So it's super easy to say,
I want three octaves up.

00:48:42.840 --> 00:48:47.380
It's three times 12 times 100.

00:48:47.380 --> 00:48:49.230
And just like
AudioBufferSourceNode you have

00:48:49.230 --> 00:48:51.890
noteOn, noteOff, and that
sort of things.

00:48:51.890 --> 00:48:54.470
Now, I did skip that we
have another type up

00:48:54.470 --> 00:48:57.320
there, called custom.

00:48:57.320 --> 00:49:01.260
Custom lets us use this really
interesting oscillator called

00:49:01.260 --> 00:49:03.020
a wavetable oscillator.

00:49:03.020 --> 00:49:05.910
Wavetables are not a sample
playback buffer.

00:49:05.910 --> 00:49:08.730
The term got misused in
the late '80s and

00:49:08.730 --> 00:49:10.910
early '90s for a while.

00:49:10.910 --> 00:49:16.530
It's actually a way to produce
sound that uses--

00:49:16.530 --> 00:49:18.311
looks like my page didn't
load, hang on.

00:49:21.400 --> 00:49:24.070
Let's try this again.

00:49:24.070 --> 00:49:25.320
There we go.

00:49:27.370 --> 00:49:33.040
It creates wave forms by adding
different coefficients

00:49:33.040 --> 00:49:35.520
onto harmonic partials.

00:49:35.520 --> 00:49:39.660
So it basically stacks up
harmonics of the same tone.

00:49:39.660 --> 00:49:42.850
And then lets you control how
much of each harmonic to draw,

00:49:42.850 --> 00:49:45.010
or to play, to add
to the waveform.

00:49:45.010 --> 00:49:46.520
So here, we start out
with a fairly

00:49:46.520 --> 00:49:47.600
simple set of harmonics.

00:49:47.600 --> 00:49:48.040
[DEEP BUZZING NOISE]

00:49:48.040 --> 00:49:49.866
CHRIS WILSON: There's three
harmonics playing.

00:49:49.866 --> 00:49:51.500
And it sounds pretty basic.

00:49:51.500 --> 00:49:53.756
It's not a very rich
sound or anything.

00:49:53.756 --> 00:49:55.930
But I can draw in more--

00:49:55.930 --> 00:49:59.080
[SOUND ALTERS]

00:49:59.080 --> 00:50:00.926
CHRIS WILSON: And you can get a
lot more interesting sound.

00:50:04.050 --> 00:50:05.510
So this is kind of weird.

00:50:05.510 --> 00:50:09.940
It's a very deep area to build
complex waveforms.

00:50:09.940 --> 00:50:11.140
Because you can sit there
and tweak the

00:50:11.140 --> 00:50:12.390
partials all you want.

00:50:14.850 --> 00:50:16.800
But I don't want to go
too deeply into it.

00:50:16.800 --> 00:50:19.340
Because we could just sit
here and play with

00:50:19.340 --> 00:50:20.380
partials all day.

00:50:20.380 --> 00:50:22.210
It's a different way
of creating sounds.

00:50:22.210 --> 00:50:23.990
It's a different generation
system.

00:50:23.990 --> 00:50:26.480
It actually was very popular
in the early '80s.

00:50:26.480 --> 00:50:29.460
There was a PPG wave synthesizer
that kind of

00:50:29.460 --> 00:50:31.390
kicked off the usage of this.

00:50:31.390 --> 00:50:35.020
The great thing, to me,
is this creates a very

00:50:35.020 --> 00:50:38.970
spectrum-rich sound, creates a
lot of harmonics, which was

00:50:38.970 --> 00:50:42.080
super useful in building
the vocoder.

00:50:42.080 --> 00:50:43.880
The sound that I used
for that vocoder

00:50:43.880 --> 00:50:45.130
is actually a wavetable.

00:50:51.620 --> 00:50:52.190
OK.

00:50:52.190 --> 00:50:54.010
So we've created sound.

00:50:54.010 --> 00:50:55.850
Now we need to process
it a little bit more.

00:50:55.850 --> 00:50:59.330
And there a couple of node
types that are really

00:50:59.330 --> 00:51:00.400
musically interesting.

00:51:00.400 --> 00:51:03.290
The first of these is
Compressor node.

00:51:03.290 --> 00:51:06.200
Now compressors are a very
common musical tool.

00:51:06.200 --> 00:51:09.830
In fact, that picture of a
rack of music equipment?

00:51:09.830 --> 00:51:12.080
That's actually from
my basement studio.

00:51:12.080 --> 00:51:15.190
One of the units in that is
a hardware compressor.

00:51:15.190 --> 00:51:18.520
And compression basically
controls the volume peaks of a

00:51:18.520 --> 00:51:21.990
sound, but tries to increase
the overall volume.

00:51:21.990 --> 00:51:25.860
So this is a before-and-after
picture of the same sound

00:51:25.860 --> 00:51:28.320
sample, of me playing
my bass guitar.

00:51:28.320 --> 00:51:29.800
The first one is uncompressed.

00:51:29.800 --> 00:51:31.160
The second one is compressed.

00:51:31.160 --> 00:51:34.190
I've actually increased the
average volume, but I've had

00:51:34.190 --> 00:51:38.360
to turn it down in a couple of
places to make sure that I

00:51:38.360 --> 00:51:41.550
don't spike past the
clipping range.

00:51:44.480 --> 00:51:47.180
So this is kind of like having
an engineer who sits there

00:51:47.180 --> 00:51:50.680
with his hand on the volume knob
with an extremely fast

00:51:50.680 --> 00:51:51.740
reaction time.

00:51:51.740 --> 00:51:55.718
You can actually see
how this works--

00:51:55.718 --> 00:51:57.150
[MUSIC PLAYS]

00:51:57.150 --> 00:51:57.380
CHRIS WILSON: Here.

00:51:57.380 --> 00:52:01.000
These are really standardized
controls, by the way.

00:52:01.000 --> 00:52:04.440
The AudioParams that give you
controls on Compressor node

00:52:04.440 --> 00:52:07.030
for threshold, knee, ratio,
attack, and release.

00:52:07.030 --> 00:52:10.400
These are the five standard
things that you get on a

00:52:10.400 --> 00:52:11.130
compressor.

00:52:11.130 --> 00:52:13.720
There's actually knobs that say
threshold, knee, ratio,

00:52:13.720 --> 00:52:15.840
attack, and release
on that hardware

00:52:15.840 --> 00:52:16.776
compressor that I have.

00:52:16.776 --> 00:52:18.650
[MUSIC VOLUME INCREASES]

00:52:18.650 --> 00:52:20.890
CHRIS WILSON: Now the little
bouncing red bar shows you how

00:52:20.890 --> 00:52:23.340
much compression is being
applied at any

00:52:23.340 --> 00:52:24.920
given point in time.

00:52:24.920 --> 00:52:31.800
So I can crank the threshold
down, crank the knee up, crank

00:52:31.800 --> 00:52:33.016
the ratio up.

00:52:33.016 --> 00:52:33.890
[MUSIC ALTERS]

00:52:33.890 --> 00:52:35.380
CHRIS WILSON: And you can
probably tell in the back.

00:52:35.380 --> 00:52:37.470
It sounds a little
muddled, for me.

00:52:37.470 --> 00:52:39.060
But you can probably
tell in the back.

00:52:39.060 --> 00:52:45.350
Suddenly, the peaks aren't so
loud, but the whole sound is a

00:52:45.350 --> 00:52:48.140
little bit muddled right
now, actually.

00:52:48.140 --> 00:52:50.445
Because you don't generally
over-compress like this.

00:52:50.445 --> 00:52:53.210
If you want to, you can change
the attack time, and you'll

00:52:53.210 --> 00:52:54.715
start hearing some of the--

00:52:54.715 --> 00:52:56.110
[MUSIC ALTERS]

00:52:56.110 --> 00:52:57.520
CHRIS WILSON: Some of the
poppiness of the attack is

00:52:57.520 --> 00:53:01.658
back, which is why you have all
these different controls.

00:53:01.658 --> 00:53:02.600
[MUSIC STOPS]

00:53:02.600 --> 00:53:04.690
CHRIS WILSON: So I'm not going
to do a class in how to use

00:53:04.690 --> 00:53:05.660
compressors.

00:53:05.660 --> 00:53:09.560
I just wanted to say, this
is a tool that we have.

00:53:09.560 --> 00:53:13.130
The last processing node
tool in our toolbox is

00:53:13.130 --> 00:53:14.980
a WaveShaper node.

00:53:14.980 --> 00:53:17.630
WaveShapers are a little
bit complex to explain.

00:53:17.630 --> 00:53:21.630
Basically, what they do is they
let you create a curve, a

00:53:21.630 --> 00:53:25.070
response curve, that's like
a sample look-up table.

00:53:25.070 --> 00:53:27.550
And it happens on every
sound sample.

00:53:27.550 --> 00:53:30.210
So for every sample it
says, I'm actually

00:53:30.210 --> 00:53:31.140
going to return this.

00:53:31.140 --> 00:53:36.690
If I set a curve that was
actually just a flat line on a

00:53:36.690 --> 00:53:39.700
45 degree angle down here, then
it would actually just

00:53:39.700 --> 00:53:42.780
have the output be exactly
the same as the input.

00:53:42.780 --> 00:53:46.270
Otherwise it's going to change
the waveforms that go through.

00:53:46.270 --> 00:53:49.630
Not control the volume over
time, like a Compressor node.

00:53:49.630 --> 00:53:52.000
But actually change the
waveforms and kind of squish

00:53:52.000 --> 00:53:53.770
the peaks down a little bit.

00:53:53.770 --> 00:53:57.670
So I can use this to create like
distortion and overdrive.

00:53:57.670 --> 00:53:58.130
[GUITAR]

00:53:58.130 --> 00:54:02.238
CHRIS WILSON: So here, you have
me playing the guitar.

00:54:02.238 --> 00:54:06.625
And if I just drive the gain a
little bit more to push up

00:54:06.625 --> 00:54:09.300
into the areas that
get clipped off--

00:54:09.300 --> 00:54:11.505
[GUITAR DISTORTS]

00:54:11.505 --> 00:54:13.170
CHRIS WILSON: You can hear
it sounds like a guitar

00:54:13.170 --> 00:54:17.160
distortion pedal, or
over-driving an amplifier.

00:54:17.160 --> 00:54:18.440
And this is just a--

00:54:18.440 --> 00:54:19.060
[GUITAR STOPS]

00:54:19.060 --> 00:54:21.200
CHRIS WILSON: A single sound
curve that I created and

00:54:21.200 --> 00:54:22.300
shoved into there.

00:54:22.300 --> 00:54:25.080
You can actually change these
curves infinitely.

00:54:25.080 --> 00:54:29.130
You can give it any size of
array curve that you want.

00:54:29.130 --> 00:54:31.860
And you can change what the
response looks like and get

00:54:31.860 --> 00:54:33.350
very, very different
distortion effects.

00:54:36.620 --> 00:54:37.930
OK.

00:54:37.930 --> 00:54:40.060
Almost there.

00:54:40.060 --> 00:54:43.800
So I haven't mentioned mono
sound versus stereo sound,

00:54:43.800 --> 00:54:47.550
versus 5.1 surround sound,
or anything like that.

00:54:47.550 --> 00:54:50.570
Mostly because the Web Audio
API, for the most part, just

00:54:50.570 --> 00:54:52.380
kind of handles it for you.

00:54:52.380 --> 00:54:54.500
You don't have to deal
with channels.

00:54:54.500 --> 00:54:57.380
It just sort of magically
upgrades whenever it needs to

00:54:57.380 --> 00:55:01.150
go to stereo, or if you have a
mono signal, or upgrades all

00:55:01.150 --> 00:55:04.440
the way to 5.1 surround sound
if it has to, whatever.

00:55:04.440 --> 00:55:06.950
If you really do want
to poke into channel

00:55:06.950 --> 00:55:08.870
control, you can do that.

00:55:08.870 --> 00:55:12.790
Most of those connections may
be more than one channel.

00:55:12.790 --> 00:55:15.990
And you just don't have to worry
about whether it's a

00:55:15.990 --> 00:55:17.790
mono or stereo signal.

00:55:17.790 --> 00:55:20.540
If you want to, use an audio
channel splitter and an audio

00:55:20.540 --> 00:55:22.570
channel merger.

00:55:22.570 --> 00:55:25.090
So for example, I mentioned
a ping-pong delay.

00:55:25.090 --> 00:55:28.050
Ping-pong delay bounces the
delay back and forth between

00:55:28.050 --> 00:55:29.070
the left and the
right channels.

00:55:29.070 --> 00:55:31.853
So it sounds kind
of like this--

00:55:31.853 --> 00:55:34.110
[BELL DINGS]

00:55:34.110 --> 00:55:36.220
CHRIS WILSON: Hopefully you hear
that bouncing between the

00:55:36.220 --> 00:55:37.920
channels back there.

00:55:37.920 --> 00:55:38.485
[BELL DINGS]

00:55:38.485 --> 00:55:41.000
CHRIS WILSON: You'd accomplish
this just by taking two

00:55:41.000 --> 00:55:43.745
delays, feeding the original
signal into one side,

00:55:43.745 --> 00:55:44.090
[BELL DINGS]

00:55:44.090 --> 00:55:45.890
CHRIS WILSON: And then crossing
the feedback loop.

00:55:45.890 --> 00:55:48.480
So it goes from the left channel
output into the right

00:55:48.480 --> 00:55:51.190
channel's delay node and
then back the same

00:55:51.190 --> 00:55:54.210
way the other direction.

00:55:54.210 --> 00:55:57.460
And, of course, you can
individually control in here

00:55:57.460 --> 00:56:02.580
how long the delay is for each
side, and that kind of stuff.

00:56:02.580 --> 00:56:06.340
So I mentioned at the very
beginning you can actually

00:56:06.340 --> 00:56:09.760
plug in and do any kind of
custom JavaScript you want to,

00:56:09.760 --> 00:56:11.400
on a sound node.

00:56:11.400 --> 00:56:13.410
JavaScriptAudioNode is
how you do that.

00:56:13.410 --> 00:56:16.260
You plug in, you set up an event
listener, and then you

00:56:16.260 --> 00:56:20.650
process buffers of audio
in that event listener.

00:56:20.650 --> 00:56:22.060
I'm not going to go into
the demo of this.

00:56:22.060 --> 00:56:24.770
It's really subtle and it takes
a lot of explaining.

00:56:24.770 --> 00:56:28.570
And we are at about three
minutes left, I think.

00:56:28.570 --> 00:56:31.080
So but this is how you do it.

00:56:31.080 --> 00:56:34.200
There's some pretty good
examples of how to do it on

00:56:34.200 --> 00:56:36.770
the Chromium sight.

00:56:36.770 --> 00:56:39.840
And I want to jump to where
we are with Web Audio.

00:56:39.840 --> 00:56:41.490
One of the first questions
is always, So

00:56:41.490 --> 00:56:43.400
is this Chrome only?

00:56:43.400 --> 00:56:47.010
And it is supported in Chrome,
Windows, Mac OS, and Linux.

00:56:47.010 --> 00:56:49.200
ChromeOS actually just
enabled it, as well.

00:56:49.200 --> 00:56:51.650
So we have it on Chrome OS.

00:56:51.650 --> 00:56:55.000
But even more interestingly,
Safari has now enabled in

00:56:55.000 --> 00:56:56.350
nightly builds and
it's shipping in

00:56:56.350 --> 00:56:58.570
the Safari 5.2 beta.

00:56:58.570 --> 00:57:00.650
And, my personal favorite,
it's now on the

00:57:00.650 --> 00:57:02.510
iOS 6 betas, also.

00:57:02.510 --> 00:57:07.430
So you can get the Web Audio
API on your iPhone or iPad.

00:57:07.430 --> 00:57:10.900
Apple actually covered the Web
Audio API in one of their

00:57:10.900 --> 00:57:13.520
sessions in WWDC earlier
this month, which

00:57:13.520 --> 00:57:15.580
I thought was great.

00:57:15.580 --> 00:57:20.300
And we have some really active
discussion going on on the Web

00:57:20.300 --> 00:57:22.510
Audio working group, of
which I'm a member.

00:57:22.510 --> 00:57:25.570
We have a bunch of active
participants from Mozilla,

00:57:25.570 --> 00:57:28.880
Opera, the Internet Explorer
team, a bunch of other

00:57:28.880 --> 00:57:31.230
industry people, as well,
helping to get the

00:57:31.230 --> 00:57:34.500
specification to the point where
we can get rid of vendor

00:57:34.500 --> 00:57:38.290
prefix and turn it into
a solid standard.

00:57:38.290 --> 00:57:40.600
And, of course, if you need
it today though in other

00:57:40.600 --> 00:57:43.580
browsers, use ChromeFrame.

00:57:43.580 --> 00:57:46.570
I promised I would plug
for ChromeFrame, so.

00:57:46.570 --> 00:57:49.610
So we are just about
out of time.

00:57:49.610 --> 00:57:52.520
But I did want to call out two
features that I'm actually

00:57:52.520 --> 00:57:55.090
really excited about coming
up in the future.

00:57:55.090 --> 00:57:58.520
They're not quite there yet, so
I can't demo them, really.

00:57:58.520 --> 00:58:00.460
But they are exciting.

00:58:00.460 --> 00:58:03.880
And I also want to kind of
paint a picture of what I

00:58:03.880 --> 00:58:06.010
really hope people build
and what I'm really

00:58:06.010 --> 00:58:08.300
excited about building.

00:58:08.300 --> 00:58:13.610
First and foremost, I'm super
pumped to have audio input.

00:58:13.610 --> 00:58:16.166
Jan can tell you I keep pinging
the team like, When am

00:58:16.166 --> 00:58:17.410
I gonna get my audio input?

00:58:17.410 --> 00:58:19.700
When am I going to get
my audio input?

00:58:19.700 --> 00:58:21.510
Mostly because I want
to plug a live

00:58:21.510 --> 00:58:23.800
microphone into my vocoder.

00:58:23.800 --> 00:58:27.830
And do stuff like that, like
plug my guitar in and create

00:58:27.830 --> 00:58:30.350
my own guitar amp simulators,
and stuff like that.

00:58:30.350 --> 00:58:34.190
Because they're pretty easy to
do using the Web Audio API.

00:58:34.190 --> 00:58:38.850
Not quite there yet, hopefully
will be in the near future.

00:58:38.850 --> 00:58:41.830
The second one is one that is
a little bit further out.

00:58:41.830 --> 00:58:46.520
But I'm actually the co-editor
of a proposal in the W3C to do

00:58:46.520 --> 00:58:47.660
MIDI input.

00:58:47.660 --> 00:58:50.210
Some of you up front may notice
that I've actually

00:58:50.210 --> 00:58:53.450
driven some of these demos off
a little keyboard here.

00:58:53.450 --> 00:58:56.760
I'm cheating because
that uses a plugin.

00:58:56.760 --> 00:58:58.960
And I've just hard-wired the
plug-in in to do the

00:58:58.960 --> 00:59:00.400
appropriate thing.

00:59:00.400 --> 00:59:04.860
But the specification that I'm
co-editing will eventually

00:59:04.860 --> 00:59:08.180
allow us to have that as part
of the web platform.

00:59:08.180 --> 00:59:10.530
And we can natively just
handle MIDI input.

00:59:10.530 --> 00:59:13.040
So you can do controllers,
you can access external

00:59:13.040 --> 00:59:15.730
synthesizers, you can do all
kinds of cool stuff.

00:59:15.730 --> 00:59:18.620
Light shows are generally driven
by MIDI, as well, like

00:59:18.620 --> 00:59:21.730
all the controllers for the
fancy lights last night are

00:59:21.730 --> 00:59:22.980
driven through that.

00:59:25.280 --> 00:59:27.470
Now for awesome apps
that I really want

00:59:27.470 --> 00:59:28.980
to see people build?

00:59:28.980 --> 00:59:29.850
There's tons of them.

00:59:29.850 --> 00:59:32.750
First and foremost, great game
audio, like really richly

00:59:32.750 --> 00:59:33.800
interactive.

00:59:33.800 --> 00:59:35.030
Don't just make it beep.

00:59:35.030 --> 00:59:39.170
Make it beep differently
depending on some parameter I

00:59:39.170 --> 00:59:40.150
can't even think of.

00:59:40.150 --> 00:59:42.330
Like how fast someone's
running, or whatever.

00:59:42.330 --> 00:59:45.190
But we have the tools to build
shared music composition

00:59:45.190 --> 00:59:47.460
tools, and digital audio
workstations, and all this

00:59:47.460 --> 00:59:48.710
kind of stuff today.

00:59:50.910 --> 00:59:54.210
So with that, no deck is
complete without tons of

00:59:54.210 --> 00:59:55.670
references.

00:59:55.670 --> 00:59:57.280
You don't have to
memorize these

00:59:57.280 --> 00:59:59.080
because the deck's posted.

00:59:59.080 --> 01:00:01.110
You don't even have to memorize
the thing at the top,

01:00:01.110 --> 01:00:04.680
because it's on my last slide in
a shortened form and it'll

01:00:04.680 --> 01:00:06.080
be easier to read.

01:00:06.080 --> 01:00:09.700
If you don't already follow
Chrome developers on Google+,

01:00:09.700 --> 01:00:11.270
please add us to a circle.

01:00:11.270 --> 01:00:12.770
We do lots of communication
there.

01:00:12.770 --> 01:00:15.420
But we do try to keep it nice
and concise and useful and

01:00:15.420 --> 01:00:17.790
interesting.

01:00:17.790 --> 01:00:20.610
And with that, thank you.

01:00:20.610 --> 01:00:22.050
We're basically out of time.

01:00:22.050 --> 01:00:23.510
But I'm going to
be around now.

01:00:23.510 --> 01:00:26.500
I'll be outside once we've
packed up here.

01:00:26.500 --> 01:00:29.220
And I'll be doing office hours
for the next hour or two, too,

01:00:29.220 --> 01:00:30.850
if you have other questions.

01:00:30.850 --> 01:00:31.150
Thanks.

01:00:31.150 --> 01:00:35.435
[APPLAUSE]

