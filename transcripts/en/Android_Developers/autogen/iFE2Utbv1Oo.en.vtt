WEBVTT
Kind: captions
Language: en

00:00:01.500 --> 00:00:05.380
[Music]

00:00:05.380 --> 00:00:05.390
[Music]
 

00:00:05.390 --> 00:00:08.089
[Music]
hello everyone I'm David Cyr I'm the

00:00:08.089 --> 00:00:08.099
hello everyone I'm David Cyr I'm the
 

00:00:08.099 --> 00:00:09.290
hello everyone I'm David Cyr I'm the
lead of the Mountain View Android

00:00:09.290 --> 00:00:09.300
lead of the Mountain View Android
 

00:00:09.300 --> 00:00:11.990
lead of the Mountain View Android
runtime team we're the folks that build

00:00:11.990 --> 00:00:12.000
runtime team we're the folks that build
 

00:00:12.000 --> 00:00:13.570
runtime team we're the folks that build
the code that runs on your phone and

00:00:13.570 --> 00:00:13.580
the code that runs on your phone and
 

00:00:13.580 --> 00:00:16.220
the code that runs on your phone and
loads your applications runs them and

00:00:16.220 --> 00:00:16.230
loads your applications runs them and
 

00:00:16.230 --> 00:00:24.380
loads your applications runs them and
manages their memory so so last year our

00:00:24.380 --> 00:00:24.390
manages their memory so so last year our
 

00:00:24.390 --> 00:00:26.540
manages their memory so so last year our
team presented the evolution of art and

00:00:26.540 --> 00:00:26.550
team presented the evolution of art and
 

00:00:26.550 --> 00:00:28.580
team presented the evolution of art and
we describe some of the techniques we're

00:00:28.580 --> 00:00:28.590
we describe some of the techniques we're
 

00:00:28.590 --> 00:00:30.050
we describe some of the techniques we're
using at the runtime and how you can

00:00:30.050 --> 00:00:30.060
using at the runtime and how you can
 

00:00:30.060 --> 00:00:31.630
using at the runtime and how you can
really see the goodness that we bring

00:00:31.630 --> 00:00:31.640
really see the goodness that we bring
 

00:00:31.640 --> 00:00:34.370
really see the goodness that we bring
this year so last year we talked about

00:00:34.370 --> 00:00:34.380
this year so last year we talked about
 

00:00:34.380 --> 00:00:36.190
this year so last year we talked about
the profile got it up compilation

00:00:36.190 --> 00:00:36.200
the profile got it up compilation
 

00:00:36.200 --> 00:00:38.690
the profile got it up compilation
how you can make your experience better

00:00:38.690 --> 00:00:38.700
how you can make your experience better
 

00:00:38.700 --> 00:00:40.130
how you can make your experience better
by understanding how programs run on

00:00:40.130 --> 00:00:40.140
by understanding how programs run on
 

00:00:40.140 --> 00:00:42.350
by understanding how programs run on
your phone we talked about how important

00:00:42.350 --> 00:00:42.360
your phone we talked about how important
 

00:00:42.360 --> 00:00:45.740
your phone we talked about how important
it is to keep memory usage down and to

00:00:45.740 --> 00:00:45.750
it is to keep memory usage down and to
 

00:00:45.750 --> 00:00:48.940
it is to keep memory usage down and to
make memory allocation blindingly fast

00:00:48.940 --> 00:00:48.950
make memory allocation blindingly fast
 

00:00:48.950 --> 00:00:52.369
make memory allocation blindingly fast
and we talked about just-in-time

00:00:52.369 --> 00:00:52.379
and we talked about just-in-time
 

00:00:52.379 --> 00:00:54.350
and we talked about just-in-time
compilation and how we can get great

00:00:54.350 --> 00:00:54.360
compilation and how we can get great
 

00:00:54.360 --> 00:00:55.850
compilation and how we can get great
performance from your applications

00:00:55.850 --> 00:00:55.860
performance from your applications
 

00:00:55.860 --> 00:00:58.479
performance from your applications
without the annoying optimizing dialogue

00:00:58.479 --> 00:00:58.489
without the annoying optimizing dialogue
 

00:00:58.489 --> 00:01:00.770
without the annoying optimizing dialogue
so you heard last year about how great

00:01:00.770 --> 00:01:00.780
so you heard last year about how great
 

00:01:00.780 --> 00:01:04.270
so you heard last year about how great
things are but it was just the beginning

00:01:04.270 --> 00:01:04.280
things are but it was just the beginning
 

00:01:04.280 --> 00:01:06.560
things are but it was just the beginning
now that your phone knows more about how

00:01:06.560 --> 00:01:06.570
now that your phone knows more about how
 

00:01:06.570 --> 00:01:08.840
now that your phone knows more about how
your applications execute we can focus

00:01:08.840 --> 00:01:08.850
your applications execute we can focus
 

00:01:08.850 --> 00:01:10.580
your applications execute we can focus
on loading only the parts that are

00:01:10.580 --> 00:01:10.590
on loading only the parts that are
 

00:01:10.590 --> 00:01:13.219
on loading only the parts that are
important to you so apps load faster and

00:01:13.219 --> 00:01:13.229
important to you so apps load faster and
 

00:01:13.229 --> 00:01:17.330
important to you so apps load faster and
use less memory and speaking of less

00:01:17.330 --> 00:01:17.340
use less memory and speaking of less
 

00:01:17.340 --> 00:01:19.160
use less memory and speaking of less
memory we've made your applications

00:01:19.160 --> 00:01:19.170
memory we've made your applications
 

00:01:19.170 --> 00:01:21.679
memory we've made your applications
spent less time reclaiming and even less

00:01:21.679 --> 00:01:21.689
spent less time reclaiming and even less
 

00:01:21.689 --> 00:01:25.039
spent less time reclaiming and even less
time allocating memory and of course

00:01:25.039 --> 00:01:25.049
time allocating memory and of course
 

00:01:25.049 --> 00:01:26.929
time allocating memory and of course
with a just-in-time compiler we can

00:01:26.929 --> 00:01:26.939
with a just-in-time compiler we can
 

00:01:26.939 --> 00:01:28.219
with a just-in-time compiler we can
focus on making your applications run

00:01:28.219 --> 00:01:28.229
focus on making your applications run
 

00:01:28.229 --> 00:01:29.109
focus on making your applications run
even faster

00:01:29.109 --> 00:01:29.119
even faster
 

00:01:29.119 --> 00:01:31.460
even faster
nicolas and art will be talking to you

00:01:31.460 --> 00:01:31.470
nicolas and art will be talking to you
 

00:01:31.470 --> 00:01:36.920
nicolas and art will be talking to you
in just a moment about that you'll

00:01:36.920 --> 00:01:36.930
in just a moment about that you'll
 

00:01:36.930 --> 00:01:38.690
in just a moment about that you'll
notice I mentioned using less memory

00:01:38.690 --> 00:01:38.700
notice I mentioned using less memory
 

00:01:38.700 --> 00:01:40.999
notice I mentioned using less memory
twice so let's start by talking about

00:01:40.999 --> 00:01:41.009
twice so let's start by talking about
 

00:01:41.009 --> 00:01:43.639
twice so let's start by talking about
that I'm going to begin by talking a

00:01:43.639 --> 00:01:43.649
that I'm going to begin by talking a
 

00:01:43.649 --> 00:01:44.749
that I'm going to begin by talking a
little bit about how we rearranged your

00:01:44.749 --> 00:01:44.759
little bit about how we rearranged your
 

00:01:44.759 --> 00:01:47.060
little bit about how we rearranged your
application to use less memory and then

00:01:47.060 --> 00:01:47.070
application to use less memory and then
 

00:01:47.070 --> 00:01:48.620
application to use less memory and then
matthew is going to tell tell you about

00:01:48.620 --> 00:01:48.630
matthew is going to tell tell you about
 

00:01:48.630 --> 00:01:52.429
matthew is going to tell tell you about
how we improve our heap sizes reduce the

00:01:52.429 --> 00:01:52.439
how we improve our heap sizes reduce the
 

00:01:52.439 --> 00:01:55.760
how we improve our heap sizes reduce the
jank reduce the pause times and have

00:01:55.760 --> 00:01:55.770
jank reduce the pause times and have
 

00:01:55.770 --> 00:02:00.230
jank reduce the pause times and have
even better allocation types first a

00:02:00.230 --> 00:02:00.240
even better allocation types first a
 

00:02:00.240 --> 00:02:01.700
even better allocation types first a
little review of how Android

00:02:01.700 --> 00:02:01.710
little review of how Android
 

00:02:01.710 --> 00:02:03.530
little review of how Android
applications work on your Android phone

00:02:03.530 --> 00:02:03.540
applications work on your Android phone
 

00:02:03.540 --> 00:02:06.410
applications work on your Android phone
an application comes in an apk file

00:02:06.410 --> 00:02:06.420
an application comes in an apk file
 

00:02:06.420 --> 00:02:08.570
an application comes in an apk file
which contains one or more Dex files

00:02:08.570 --> 00:02:08.580
which contains one or more Dex files
 

00:02:08.580 --> 00:02:11.100
which contains one or more Dex files
these contain the instructions for

00:02:11.100 --> 00:02:11.110
these contain the instructions for
 

00:02:11.110 --> 00:02:14.550
these contain the instructions for
executing your application art uses the

00:02:14.550 --> 00:02:14.560
executing your application art uses the
 

00:02:14.560 --> 00:02:15.860
executing your application art uses the
Dex file to get information about

00:02:15.860 --> 00:02:15.870
Dex file to get information about
 

00:02:15.870 --> 00:02:19.440
Dex file to get information about
instructions to run strings class

00:02:19.440 --> 00:02:19.450
instructions to run strings class
 

00:02:19.450 --> 00:02:21.200
instructions to run strings class
relationships and lots of other things

00:02:21.200 --> 00:02:21.210
relationships and lots of other things
 

00:02:21.210 --> 00:02:23.400
relationships and lots of other things
and the Dex files are loaded into memory

00:02:23.400 --> 00:02:23.410
and the Dex files are loaded into memory
 

00:02:23.410 --> 00:02:26.760
and the Dex files are loaded into memory
by art loading these files has both a

00:02:26.760 --> 00:02:26.770
by art loading these files has both a
 

00:02:26.770 --> 00:02:32.070
by art loading these files has both a
ram and a startup time cost so when you

00:02:32.070 --> 00:02:32.080
ram and a startup time cost so when you
 

00:02:32.080 --> 00:02:34.200
ram and a startup time cost so when you
run for instance naps one of our

00:02:34.200 --> 00:02:34.210
run for instance naps one of our
 

00:02:34.210 --> 00:02:36.210
run for instance naps one of our
favorite application your phone reads

00:02:36.210 --> 00:02:36.220
favorite application your phone reads
 

00:02:36.220 --> 00:02:38.190
favorite application your phone reads
the Dex files into memory and you can

00:02:38.190 --> 00:02:38.200
the Dex files into memory and you can
 

00:02:38.200 --> 00:02:40.130
the Dex files into memory and you can
see amounts of thousands of pages

00:02:40.130 --> 00:02:40.140
see amounts of thousands of pages
 

00:02:40.140 --> 00:02:42.330
see amounts of thousands of pages
multiple megabytes worth of information

00:02:42.330 --> 00:02:42.340
multiple megabytes worth of information
 

00:02:42.340 --> 00:02:43.460
multiple megabytes worth of information
are loaded into memory

00:02:43.460 --> 00:02:43.470
are loaded into memory
 

00:02:43.470 --> 00:02:45.630
are loaded into memory
now the Dex files were produced by a

00:02:45.630 --> 00:02:45.640
now the Dex files were produced by a
 

00:02:45.640 --> 00:02:47.370
now the Dex files were produced by a
developer and the typical developer

00:02:47.370 --> 00:02:47.380
developer and the typical developer
 

00:02:47.380 --> 00:02:49.800
developer and the typical developer
tools don't really know about the use

00:02:49.800 --> 00:02:49.810
tools don't really know about the use
 

00:02:49.810 --> 00:02:51.840
tools don't really know about the use
cases that are going to be important to

00:02:51.840 --> 00:02:51.850
cases that are going to be important to
 

00:02:51.850 --> 00:02:54.240
cases that are going to be important to
you on your phone so the Dex files may

00:02:54.240 --> 00:02:54.250
you on your phone so the Dex files may
 

00:02:54.250 --> 00:02:56.250
you on your phone so the Dex files may
have unimportant things on the same

00:02:56.250 --> 00:02:56.260
have unimportant things on the same
 

00:02:56.260 --> 00:03:00.960
have unimportant things on the same
pages as important things like for

00:03:00.960 --> 00:03:00.970
pages as important things like for
 

00:03:00.970 --> 00:03:04.170
pages as important things like for
example the way you use Maps you may

00:03:04.170 --> 00:03:04.180
example the way you use Maps you may
 

00:03:04.180 --> 00:03:05.910
example the way you use Maps you may
only use some of the methods that were

00:03:05.910 --> 00:03:05.920
only use some of the methods that were
 

00:03:05.920 --> 00:03:10.230
only use some of the methods that were
in the Dex files or some of the strings

00:03:10.230 --> 00:03:10.240
in the Dex files or some of the strings
 

00:03:10.240 --> 00:03:13.350
in the Dex files or some of the strings
that are there are not seen in your use

00:03:13.350 --> 00:03:13.360
that are there are not seen in your use
 

00:03:13.360 --> 00:03:18.560
that are there are not seen in your use
case as I told you before in Android an

00:03:18.560 --> 00:03:18.570
case as I told you before in Android an
 

00:03:18.570 --> 00:03:21.090
case as I told you before in Android an
art introduced profile based compilation

00:03:21.090 --> 00:03:21.100
art introduced profile based compilation
 

00:03:21.100 --> 00:03:24.360
art introduced profile based compilation
in Android oh we have clever new uses

00:03:24.360 --> 00:03:24.370
in Android oh we have clever new uses
 

00:03:24.370 --> 00:03:26.850
in Android oh we have clever new uses
for this several clever new uses in fact

00:03:26.850 --> 00:03:26.860
for this several clever new uses in fact
 

00:03:26.860 --> 00:03:28.590
for this several clever new uses in fact
but one of the ones I'm here to talk

00:03:28.590 --> 00:03:28.600
but one of the ones I'm here to talk
 

00:03:28.600 --> 00:03:30.750
but one of the ones I'm here to talk
about is improving the Dex file locality

00:03:30.750 --> 00:03:30.760
about is improving the Dex file locality
 

00:03:30.760 --> 00:03:34.320
about is improving the Dex file locality
the idea is simple use the gyp profile

00:03:34.320 --> 00:03:34.330
the idea is simple use the gyp profile
 

00:03:34.330 --> 00:03:35.970
the idea is simple use the gyp profile
information to move the important things

00:03:35.970 --> 00:03:35.980
information to move the important things
 

00:03:35.980 --> 00:03:37.229
information to move the important things
the things that have been used by you

00:03:37.229 --> 00:03:37.239
the things that have been used by you
 

00:03:37.239 --> 00:03:38.790
the things that have been used by you
and your usage of the applications

00:03:38.790 --> 00:03:38.800
and your usage of the applications
 

00:03:38.800 --> 00:03:42.770
and your usage of the applications
closer together and this is all done

00:03:42.770 --> 00:03:42.780
closer together and this is all done
 

00:03:42.780 --> 00:03:45.210
closer together and this is all done
seamlessly and transparently to the user

00:03:45.210 --> 00:03:45.220
seamlessly and transparently to the user
 

00:03:45.220 --> 00:03:49.430
seamlessly and transparently to the user
as we compile applications on the device

00:03:49.430 --> 00:03:49.440
 

00:03:49.440 --> 00:03:52.020
so after we run your application once at

00:03:52.020 --> 00:03:52.030
so after we run your application once at
 

00:03:52.030 --> 00:03:53.520
so after we run your application once at
least to collect the profile information

00:03:53.520 --> 00:03:53.530
least to collect the profile information
 

00:03:53.530 --> 00:03:55.199
least to collect the profile information
we use information about what parts of

00:03:55.199 --> 00:03:55.209
we use information about what parts of
 

00:03:55.209 --> 00:03:56.370
we use information about what parts of
the application we're important to you

00:03:56.370 --> 00:03:56.380
the application we're important to you
 

00:03:56.380 --> 00:03:58.410
the application we're important to you
we gather the important methods together

00:03:58.410 --> 00:03:58.420
we gather the important methods together
 

00:03:58.420 --> 00:04:00.300
we gather the important methods together
and leave the unimportant methods

00:04:00.300 --> 00:04:00.310
and leave the unimportant methods
 

00:04:00.310 --> 00:04:02.970
and leave the unimportant methods
together as you can see on the right

00:04:02.970 --> 00:04:02.980
together as you can see on the right
 

00:04:02.980 --> 00:04:06.650
together as you can see on the right
they're a lot fewer pages are accessed

00:04:06.650 --> 00:04:06.660
they're a lot fewer pages are accessed
 

00:04:06.660 --> 00:04:09.449
they're a lot fewer pages are accessed
especially the methods of when we use

00:04:09.449 --> 00:04:09.459
especially the methods of when we use
 

00:04:09.459 --> 00:04:13.199
especially the methods of when we use
profiling information now let's take a

00:04:13.199 --> 00:04:13.209
profiling information now let's take a
 

00:04:13.209 --> 00:04:15.300
profiling information now let's take a
look at what type of RAM improvements we

00:04:15.300 --> 00:04:15.310
look at what type of RAM improvements we
 

00:04:15.310 --> 00:04:17.250
look at what type of RAM improvements we
see after launching a few apps a few of

00:04:17.250 --> 00:04:17.260
see after launching a few apps a few of
 

00:04:17.260 --> 00:04:18.900
see after launching a few apps a few of
our favorites again as you can see

00:04:18.900 --> 00:04:18.910
our favorites again as you can see
 

00:04:18.910 --> 00:04:19.770
our favorites again as you can see
there's a significant reduction

00:04:19.770 --> 00:04:19.780
there's a significant reduction
 

00:04:19.780 --> 00:04:21.870
there's a significant reduction
typically around a third in these

00:04:21.870 --> 00:04:21.880
typically around a third in these
 

00:04:21.880 --> 00:04:23.280
typically around a third in these
applications

00:04:23.280 --> 00:04:23.290
applications
 

00:04:23.290 --> 00:04:27.990
applications
it's less member used by decks after

00:04:27.990 --> 00:04:28.000
it's less member used by decks after
 

00:04:28.000 --> 00:04:30.630
it's less member used by decks after
layout this Ram production also improved

00:04:30.630 --> 00:04:30.640
layout this Ram production also improved
 

00:04:30.640 --> 00:04:32.190
layout this Ram production also improved
launch time on devices that have slower

00:04:32.190 --> 00:04:32.200
launch time on devices that have slower
 

00:04:32.200 --> 00:04:33.960
launch time on devices that have slower
flash because you're pulling in fewer

00:04:33.960 --> 00:04:33.970
flash because you're pulling in fewer
 

00:04:33.970 --> 00:04:36.000
flash because you're pulling in fewer
pages and have spending less time paging

00:04:36.000 --> 00:04:36.010
pages and have spending less time paging
 

00:04:36.010 --> 00:04:39.750
pages and have spending less time paging
applications off of the flesh so that's

00:04:39.750 --> 00:04:39.760
applications off of the flesh so that's
 

00:04:39.760 --> 00:04:41.010
applications off of the flesh so that's
it for my partner over to Matthew who's

00:04:41.010 --> 00:04:41.020
it for my partner over to Matthew who's
 

00:04:41.020 --> 00:04:42.210
it for my partner over to Matthew who's
going to tell you about our new garbage

00:04:42.210 --> 00:04:42.220
going to tell you about our new garbage
 

00:04:42.220 --> 00:04:45.680
going to tell you about our new garbage
collector thank you David

00:04:45.680 --> 00:04:45.690
collector thank you David
 

00:04:45.690 --> 00:04:48.510
collector thank you David
another thing that saves RAM is the new

00:04:48.510 --> 00:04:48.520
another thing that saves RAM is the new
 

00:04:48.520 --> 00:04:52.260
another thing that saves RAM is the new
concurrent okay you could current a

00:04:52.260 --> 00:04:52.270
concurrent okay you could current a
 

00:04:52.270 --> 00:04:55.470
concurrent okay you could current a
coffee and garbage collector now Android

00:04:55.470 --> 00:04:55.480
coffee and garbage collector now Android
 

00:04:55.480 --> 00:04:57.360
coffee and garbage collector now Android
has had a compacting garbage collector

00:04:57.360 --> 00:04:57.370
has had a compacting garbage collector
 

00:04:57.370 --> 00:04:59.160
has had a compacting garbage collector
that runs for background apps since

00:04:59.160 --> 00:04:59.170
that runs for background apps since
 

00:04:59.170 --> 00:05:02.100
that runs for background apps since
Android L but unfortunately since this

00:05:02.100 --> 00:05:02.110
Android L but unfortunately since this
 

00:05:02.110 --> 00:05:04.020
Android L but unfortunately since this
collector is non concurrent I meant that

00:05:04.020 --> 00:05:04.030
collector is non concurrent I meant that
 

00:05:04.030 --> 00:05:05.520
collector is non concurrent I meant that
there was a GC pause for the entire

00:05:05.520 --> 00:05:05.530
there was a GC pause for the entire
 

00:05:05.530 --> 00:05:11.400
there was a GC pause for the entire
duration so basically the problem with

00:05:11.400 --> 00:05:11.410
duration so basically the problem with
 

00:05:11.410 --> 00:05:12.780
duration so basically the problem with
having a GC pause for the entire

00:05:12.780 --> 00:05:12.790
having a GC pause for the entire
 

00:05:12.790 --> 00:05:15.540
having a GC pause for the entire
duration of the GC is that it can last

00:05:15.540 --> 00:05:15.550
duration of the GC is that it can last
 

00:05:15.550 --> 00:05:17.280
duration of the GC is that it can last
hundreds of milliseconds and this would

00:05:17.280 --> 00:05:17.290
hundreds of milliseconds and this would
 

00:05:17.290 --> 00:05:19.350
hundreds of milliseconds and this would
very likely cause jank for foreground

00:05:19.350 --> 00:05:19.360
very likely cause jank for foreground
 

00:05:19.360 --> 00:05:24.270
very likely cause jank for foreground
applications in Android Oh art now could

00:05:24.270 --> 00:05:24.280
applications in Android Oh art now could
 

00:05:24.280 --> 00:05:26.520
applications in Android Oh art now could
currently compact the heap of background

00:05:26.520 --> 00:05:26.530
currently compact the heap of background
 

00:05:26.530 --> 00:05:30.210
currently compact the heap of background
and foreground applications this enables

00:05:30.210 --> 00:05:30.220
and foreground applications this enables
 

00:05:30.220 --> 00:05:31.890
and foreground applications this enables
compaction of many long-lived

00:05:31.890 --> 00:05:31.900
compaction of many long-lived
 

00:05:31.900 --> 00:05:33.810
compaction of many long-lived
applications such as the Android system

00:05:33.810 --> 00:05:33.820
applications such as the Android system
 

00:05:33.820 --> 00:05:37.470
applications such as the Android system
process and Google Play services since

00:05:37.470 --> 00:05:37.480
process and Google Play services since
 

00:05:37.480 --> 00:05:38.940
process and Google Play services since
these processes were long-lived

00:05:38.940 --> 00:05:38.950
these processes were long-lived
 

00:05:38.950 --> 00:05:40.860
these processes were long-lived
they tended to have a high fragmentation

00:05:40.860 --> 00:05:40.870
they tended to have a high fragmentation
 

00:05:40.870 --> 00:05:43.850
they tended to have a high fragmentation
over the time that they were executing

00:05:43.850 --> 00:05:43.860
over the time that they were executing
 

00:05:43.860 --> 00:05:48.660
over the time that they were executing
let's take a look at a GC process unlike

00:05:48.660 --> 00:05:48.670
let's take a look at a GC process unlike
 

00:05:48.670 --> 00:05:50.790
let's take a look at a GC process unlike
its predecessor the new GC is region

00:05:50.790 --> 00:05:50.800
its predecessor the new GC is region
 

00:05:50.800 --> 00:05:54.390
its predecessor the new GC is region
based starting out the GC does a brief

00:05:54.390 --> 00:05:54.400
based starting out the GC does a brief
 

00:05:54.400 --> 00:05:56.670
based starting out the GC does a brief
pause to identify which regions we are

00:05:56.670 --> 00:05:56.680
pause to identify which regions we are
 

00:05:56.680 --> 00:05:59.550
pause to identify which regions we are
going to evacuate these regions are also

00:05:59.550 --> 00:05:59.560
going to evacuate these regions are also
 

00:05:59.560 --> 00:06:03.180
going to evacuate these regions are also
known as the source region threads then

00:06:03.180 --> 00:06:03.190
known as the source region threads then
 

00:06:03.190 --> 00:06:06.210
known as the source region threads then
resume from the pause after having walk

00:06:06.210 --> 00:06:06.220
resume from the pause after having walk
 

00:06:06.220 --> 00:06:09.690
resume from the pause after having walk
their stacks next up is the largest

00:06:09.690 --> 00:06:09.700
their stacks next up is the largest
 

00:06:09.700 --> 00:06:13.590
their stacks next up is the largest
phase of the GC the copying phase in the

00:06:13.590 --> 00:06:13.600
phase of the GC the copying phase in the
 

00:06:13.600 --> 00:06:15.570
phase of the GC the copying phase in the
copying phase reachable objects are

00:06:15.570 --> 00:06:15.580
copying phase reachable objects are
 

00:06:15.580 --> 00:06:17.070
copying phase reachable objects are
copied from the source region the

00:06:17.070 --> 00:06:17.080
copied from the source region the
 

00:06:17.080 --> 00:06:20.310
copied from the source region the
destination regions finally in the

00:06:20.310 --> 00:06:20.320
destination regions finally in the
 

00:06:20.320 --> 00:06:22.980
destination regions finally in the
reclaim phase the GC frees the ram for

00:06:22.980 --> 00:06:22.990
reclaim phase the GC frees the ram for
 

00:06:22.990 --> 00:06:26.490
reclaim phase the GC frees the ram for
the source regions

00:06:26.490 --> 00:06:26.500
 

00:06:26.500 --> 00:06:30.480
starting with the pause phase the pauses

00:06:30.480 --> 00:06:30.490
starting with the pause phase the pauses
 

00:06:30.490 --> 00:06:32.670
starting with the pause phase the pauses
are pretty small during the pause one of

00:06:32.670 --> 00:06:32.680
are pretty small during the pause one of
 

00:06:32.680 --> 00:06:34.560
are pretty small during the pause one of
the key steps is identifying which

00:06:34.560 --> 00:06:34.570
the key steps is identifying which
 

00:06:34.570 --> 00:06:37.800
the key steps is identifying which
regions to evacuate the goal of

00:06:37.800 --> 00:06:37.810
regions to evacuate the goal of
 

00:06:37.810 --> 00:06:39.990
regions to evacuate the goal of
evacuation is to copy all of the

00:06:39.990 --> 00:06:40.000
evacuation is to copy all of the
 

00:06:40.000 --> 00:06:41.970
evacuation is to copy all of the
reachable objects out of regions with

00:06:41.970 --> 00:06:41.980
reachable objects out of regions with
 

00:06:41.980 --> 00:06:45.060
reachable objects out of regions with
high fragmentation after this is

00:06:45.060 --> 00:06:45.070
high fragmentation after this is
 

00:06:45.070 --> 00:06:47.460
high fragmentation after this is
accomplished UC can release the RAM for

00:06:47.460 --> 00:06:47.470
accomplished UC can release the RAM for
 

00:06:47.470 --> 00:06:51.330
accomplished UC can release the RAM for
these regions in this example the GC

00:06:51.330 --> 00:06:51.340
these regions in this example the GC
 

00:06:51.340 --> 00:06:52.950
these regions in this example the GC
picks the middle two regions as the

00:06:52.950 --> 00:06:52.960
picks the middle two regions as the
 

00:06:52.960 --> 00:06:54.570
picks the middle two regions as the
source regions because these both have

00:06:54.570 --> 00:06:54.580
source regions because these both have
 

00:06:54.580 --> 00:07:00.270
source regions because these both have
more than 20% fragmentation next up is

00:07:00.270 --> 00:07:00.280
more than 20% fragmentation next up is
 

00:07:00.280 --> 00:07:03.870
more than 20% fragmentation next up is
the copying phase in the copying phase

00:07:03.870 --> 00:07:03.880
the copying phase in the copying phase
 

00:07:03.880 --> 00:07:05.940
the copying phase in the copying phase
the GC copies all reachable objects from

00:07:05.940 --> 00:07:05.950
the GC copies all reachable objects from
 

00:07:05.950 --> 00:07:07.620
the GC copies all reachable objects from
resource regions to the destination

00:07:07.620 --> 00:07:07.630
resource regions to the destination
 

00:07:07.630 --> 00:07:09.780
resource regions to the destination
regions with the goal that no objects

00:07:09.780 --> 00:07:09.790
regions with the goal that no objects
 

00:07:09.790 --> 00:07:11.690
regions with the goal that no objects
will reference the source regions after

00:07:11.690 --> 00:07:11.700
will reference the source regions after
 

00:07:11.700 --> 00:07:16.200
will reference the source regions after
collection is completed the GC also

00:07:16.200 --> 00:07:16.210
collection is completed the GC also
 

00:07:16.210 --> 00:07:17.880
collection is completed the GC also
updates the references to these regions

00:07:17.880 --> 00:07:17.890
updates the references to these regions
 

00:07:17.890 --> 00:07:19.350
updates the references to these regions
to point to the new addresses of the

00:07:19.350 --> 00:07:19.360
to point to the new addresses of the
 

00:07:19.360 --> 00:07:24.659
to point to the new addresses of the
object now this application threads are

00:07:24.659 --> 00:07:24.669
object now this application threads are
 

00:07:24.669 --> 00:07:26.340
object now this application threads are
running concurrently during the garbage

00:07:26.340 --> 00:07:26.350
running concurrently during the garbage
 

00:07:26.350 --> 00:07:28.409
running concurrently during the garbage
collector the GC needs a way to make

00:07:28.409 --> 00:07:28.419
collector the GC needs a way to make
 

00:07:28.419 --> 00:07:29.610
collector the GC needs a way to make
sure that these stores don't end up

00:07:29.610 --> 00:07:29.620
sure that these stores don't end up
 

00:07:29.620 --> 00:07:31.350
sure that these stores don't end up
reading a field that points to a source

00:07:31.350 --> 00:07:31.360
reading a field that points to a source
 

00:07:31.360 --> 00:07:35.130
reading a field that points to a source
region to accomplish this the GC uses

00:07:35.130 --> 00:07:35.140
region to accomplish this the GC uses
 

00:07:35.140 --> 00:07:40.020
region to accomplish this the GC uses
technique called a read barrier a read

00:07:40.020 --> 00:07:40.030
technique called a read barrier a read
 

00:07:40.030 --> 00:07:41.760
technique called a read barrier a read
barrier is a small amount of work done

00:07:41.760 --> 00:07:41.770
barrier is a small amount of work done
 

00:07:41.770 --> 00:07:44.400
barrier is a small amount of work done
for every field read the read barrier

00:07:44.400 --> 00:07:44.410
for every field read the read barrier
 

00:07:44.410 --> 00:07:46.170
for every field read the read barrier
prevents the threads from ever seeing

00:07:46.170 --> 00:07:46.180
prevents the threads from ever seeing
 

00:07:46.180 --> 00:07:47.850
prevents the threads from ever seeing
references to the source regions by

00:07:47.850 --> 00:07:47.860
references to the source regions by
 

00:07:47.860 --> 00:07:49.440
references to the source regions by
intercepting the reads and then copying

00:07:49.440 --> 00:07:49.450
intercepting the reads and then copying
 

00:07:49.450 --> 00:07:52.310
intercepting the reads and then copying
the objects of destination regions in

00:07:52.310 --> 00:07:52.320
the objects of destination regions in
 

00:07:52.320 --> 00:07:54.750
the objects of destination regions in
this example there's a thread attempting

00:07:54.750 --> 00:07:54.760
this example there's a thread attempting
 

00:07:54.760 --> 00:07:57.600
this example there's a thread attempting
to read foo X this is a reference to a

00:07:57.600 --> 00:07:57.610
to read foo X this is a reference to a
 

00:07:57.610 --> 00:08:00.659
to read foo X this is a reference to a
bar object in the source region the read

00:08:00.659 --> 00:08:00.669
bar object in the source region the read
 

00:08:00.669 --> 00:08:02.670
bar object in the source region the read
barrier intercepts this read copies the

00:08:02.670 --> 00:08:02.680
barrier intercepts this read copies the
 

00:08:02.680 --> 00:08:04.770
barrier intercepts this read copies the
object the destination region and also

00:08:04.770 --> 00:08:04.780
object the destination region and also
 

00:08:04.780 --> 00:08:11.070
object the destination region and also
returns the new address copying process

00:08:11.070 --> 00:08:11.080
returns the new address copying process
 

00:08:11.080 --> 00:08:13.500
returns the new address copying process
continues copying moving objects as well

00:08:13.500 --> 00:08:13.510
continues copying moving objects as well
 

00:08:13.510 --> 00:08:15.480
continues copying moving objects as well
as doing repairs if necessary until

00:08:15.480 --> 00:08:15.490
as doing repairs if necessary until
 

00:08:15.490 --> 00:08:16.890
as doing repairs if necessary until
there are no longer any references to

00:08:16.890 --> 00:08:16.900
there are no longer any references to
 

00:08:16.900 --> 00:08:20.460
there are no longer any references to
the from reach to the source region at

00:08:20.460 --> 00:08:20.470
the from reach to the source region at
 

00:08:20.470 --> 00:08:22.740
the from reach to the source region at
this point the GC begins the reclaimed

00:08:22.740 --> 00:08:22.750
this point the GC begins the reclaimed
 

00:08:22.750 --> 00:08:28.200
this point the GC begins the reclaimed
phase as you can see here there are no

00:08:28.200 --> 00:08:28.210
phase as you can see here there are no
 

00:08:28.210 --> 00:08:29.670
phase as you can see here there are no
longer any references to the source

00:08:29.670 --> 00:08:29.680
longer any references to the source
 

00:08:29.680 --> 00:08:31.620
longer any references to the source
regions so the garbage collector can

00:08:31.620 --> 00:08:31.630
regions so the garbage collector can
 

00:08:31.630 --> 00:08:33.899
regions so the garbage collector can
free all the ram for these regions and

00:08:33.899 --> 00:08:33.909
free all the ram for these regions and
 

00:08:33.909 --> 00:08:36.719
free all the ram for these regions and
while we are left with is a heap that

00:08:36.719 --> 00:08:36.729
while we are left with is a heap that
 

00:08:36.729 --> 00:08:38.340
while we are left with is a heap that
has much less wasted RAM

00:08:38.340 --> 00:08:38.350
has much less wasted RAM
 

00:08:38.350 --> 00:08:43.530
has much less wasted RAM
- when the collection begins now you

00:08:43.530 --> 00:08:43.540
- when the collection begins now you
 

00:08:43.540 --> 00:08:45.090
- when the collection begins now you
might be wondering how much RAM can we

00:08:45.090 --> 00:08:45.100
might be wondering how much RAM can we
 

00:08:45.100 --> 00:08:46.620
might be wondering how much RAM can we
save by compacting foreground

00:08:46.620 --> 00:08:46.630
save by compacting foreground
 

00:08:46.630 --> 00:08:48.240
save by compacting foreground
applications as well as background

00:08:48.240 --> 00:08:48.250
applications as well as background
 

00:08:48.250 --> 00:08:51.030
applications as well as background
applications well the average heap size

00:08:51.030 --> 00:08:51.040
applications well the average heap size
 

00:08:51.040 --> 00:08:53.490
applications well the average heap size
is 32 percent smaller occured to the

00:08:53.490 --> 00:08:53.500
is 32 percent smaller occured to the
 

00:08:53.500 --> 00:08:55.500
is 32 percent smaller occured to the
Android n concurrent mark-sweep garbage

00:08:55.500 --> 00:08:55.510
Android n concurrent mark-sweep garbage
 

00:08:55.510 --> 00:08:58.920
Android n concurrent mark-sweep garbage
collector and RAM lost the GC overhead

00:08:58.920 --> 00:08:58.930
collector and RAM lost the GC overhead
 

00:08:58.930 --> 00:09:03.840
collector and RAM lost the GC overhead
is also a little bit smaller one

00:09:03.840 --> 00:09:03.850
is also a little bit smaller one
 

00:09:03.850 --> 00:09:05.460
is also a little bit smaller one
important factor about concurrent

00:09:05.460 --> 00:09:05.470
important factor about concurrent
 

00:09:05.470 --> 00:09:06.870
important factor about concurrent
garbage collectors is how long

00:09:06.870 --> 00:09:06.880
garbage collectors is how long
 

00:09:06.880 --> 00:09:10.200
garbage collectors is how long
application threads are suspended every

00:09:10.200 --> 00:09:10.210
application threads are suspended every
 

00:09:10.210 --> 00:09:11.880
application threads are suspended every
millisecond that the threads are paused

00:09:11.880 --> 00:09:11.890
millisecond that the threads are paused
 

00:09:11.890 --> 00:09:14.370
millisecond that the threads are paused
or suspended is one less millisecond to

00:09:14.370 --> 00:09:14.380
or suspended is one less millisecond to
 

00:09:14.380 --> 00:09:18.150
or suspended is one less millisecond to
prepare the next frame for the UI with

00:09:18.150 --> 00:09:18.160
prepare the next frame for the UI with
 

00:09:18.160 --> 00:09:20.940
prepare the next frame for the UI with
the new GC the average pause times 0.4

00:09:20.940 --> 00:09:20.950
the new GC the average pause times 0.4
 

00:09:20.950 --> 00:09:23.040
the new GC the average pause times 0.4
milliseconds compared to 2.5

00:09:23.040 --> 00:09:23.050
milliseconds compared to 2.5
 

00:09:23.050 --> 00:09:26.640
milliseconds compared to 2.5
milliseconds in Android N and a 99%

00:09:26.640 --> 00:09:26.650
milliseconds in Android N and a 99%
 

00:09:26.650 --> 00:09:29.850
milliseconds in Android N and a 99%
worst case for large heap is a 2.6

00:09:29.850 --> 00:09:29.860
worst case for large heap is a 2.6
 

00:09:29.860 --> 00:09:31.980
worst case for large heap is a 2.6
milliseconds instead of 11 milliseconds

00:09:31.980 --> 00:09:31.990
milliseconds instead of 11 milliseconds
 

00:09:31.990 --> 00:09:37.650
milliseconds instead of 11 milliseconds
in under 10 finally always compacting

00:09:37.650 --> 00:09:37.660
in under 10 finally always compacting
 

00:09:37.660 --> 00:09:39.720
in under 10 finally always compacting
the heap has enabled Hart to switch to a

00:09:39.720 --> 00:09:39.730
the heap has enabled Hart to switch to a
 

00:09:39.730 --> 00:09:42.350
the heap has enabled Hart to switch to a
new thread local bump pointer allocator

00:09:42.350 --> 00:09:42.360
new thread local bump pointer allocator
 

00:09:42.360 --> 00:09:45.090
new thread local bump pointer allocator
this is simple this alligator is simpler

00:09:45.090 --> 00:09:45.100
this is simple this alligator is simpler
 

00:09:45.100 --> 00:09:47.220
this is simple this alligator is simpler
and faster than the free list alligator

00:09:47.220 --> 00:09:47.230
and faster than the free list alligator
 

00:09:47.230 --> 00:09:50.520
and faster than the free list alligator
it replaces overall this means the

00:09:50.520 --> 00:09:50.530
it replaces overall this means the
 

00:09:50.530 --> 00:09:52.950
it replaces overall this means the
allocation is around 70% faster compared

00:09:52.950 --> 00:09:52.960
allocation is around 70% faster compared
 

00:09:52.960 --> 00:09:54.660
allocation is around 70% faster compared
to Android n and if you go further back

00:09:54.660 --> 00:09:54.670
to Android n and if you go further back
 

00:09:54.670 --> 00:09:57.330
to Android n and if you go further back
allocations are 18 times faster than

00:09:57.330 --> 00:09:57.340
allocations are 18 times faster than
 

00:09:57.340 --> 00:10:00.510
allocations are 18 times faster than
KitKat on a device adjusted basis and

00:10:00.510 --> 00:10:00.520
KitKat on a device adjusted basis and
 

00:10:00.520 --> 00:10:02.400
KitKat on a device adjusted basis and
now off the Nicolas for other

00:10:02.400 --> 00:10:02.410
now off the Nicolas for other
 

00:10:02.410 --> 00:10:09.810
now off the Nicolas for other
optimizations

00:10:09.810 --> 00:10:09.820
 

00:10:09.820 --> 00:10:13.480
Thank You Matthew so besides managing

00:10:13.480 --> 00:10:13.490
Thank You Matthew so besides managing
 

00:10:13.490 --> 00:10:15.640
Thank You Matthew so besides managing
application memory are is also

00:10:15.640 --> 00:10:15.650
application memory are is also
 

00:10:15.650 --> 00:10:17.800
application memory are is also
responsible for encoding executing

00:10:17.800 --> 00:10:17.810
responsible for encoding executing
 

00:10:17.810 --> 00:10:20.800
responsible for encoding executing
application code and for every hundred

00:10:20.800 --> 00:10:20.810
application code and for every hundred
 

00:10:20.810 --> 00:10:23.020
application code and for every hundred
release our team spent a significant

00:10:23.020 --> 00:10:23.030
release our team spent a significant
 

00:10:23.030 --> 00:10:27.010
release our team spent a significant
time optimizing wherever we can so in

00:10:27.010 --> 00:10:27.020
time optimizing wherever we can so in
 

00:10:27.020 --> 00:10:29.470
time optimizing wherever we can so in
this talk we want to share with you two

00:10:29.470 --> 00:10:29.480
this talk we want to share with you two
 

00:10:29.480 --> 00:10:30.880
this talk we want to share with you two
major accomplishments we've made for

00:10:30.880 --> 00:10:30.890
major accomplishments we've made for
 

00:10:30.890 --> 00:10:33.490
major accomplishments we've made for
this release the first is a performance

00:10:33.490 --> 00:10:33.500
this release the first is a performance
 

00:10:33.500 --> 00:10:35.410
this release the first is a performance
if city and the second is about you a

00:10:35.410 --> 00:10:35.420
if city and the second is about you a
 

00:10:35.420 --> 00:10:40.660
if city and the second is about you a
new optimization framework for loops let

00:10:40.660 --> 00:10:40.670
new optimization framework for loops let
 

00:10:40.670 --> 00:10:42.520
new optimization framework for loops let
me start with the performance city and

00:10:42.520 --> 00:10:42.530
me start with the performance city and
 

00:10:42.530 --> 00:10:43.810
me start with the performance city and
an r2 let me talk about loop

00:10:43.810 --> 00:10:43.820
an r2 let me talk about loop
 

00:10:43.820 --> 00:10:47.620
an r2 let me talk about loop
optimizations so to validate all the

00:10:47.620 --> 00:10:47.630
optimizations so to validate all the
 

00:10:47.630 --> 00:10:49.690
optimizations so to validate all the
optimizations we do we have our own

00:10:49.690 --> 00:10:49.700
optimizations we do we have our own
 

00:10:49.700 --> 00:10:52.780
optimizations we do we have our own
benchmarks where we look for regressions

00:10:52.780 --> 00:10:52.790
benchmarks where we look for regressions
 

00:10:52.790 --> 00:10:54.670
benchmarks where we look for regressions
and improvements but we also want to

00:10:54.670 --> 00:10:54.680
and improvements but we also want to
 

00:10:54.680 --> 00:10:56.890
and improvements but we also want to
make sure that optimizations do matter

00:10:56.890 --> 00:10:56.900
make sure that optimizations do matter
 

00:10:56.900 --> 00:11:00.580
make sure that optimizations do matter
for real Android apps so for the old

00:11:00.580 --> 00:11:00.590
for real Android apps so for the old
 

00:11:00.590 --> 00:11:02.530
for real Android apps so for the old
release we have invested our

00:11:02.530 --> 00:11:02.540
release we have invested our
 

00:11:02.540 --> 00:11:04.120
release we have invested our
optimizations on one of our Android

00:11:04.120 --> 00:11:04.130
optimizations on one of our Android
 

00:11:04.130 --> 00:11:09.370
optimizations on one of our Android
applications sheet over the years the

00:11:09.370 --> 00:11:09.380
applications sheet over the years the
 

00:11:09.380 --> 00:11:11.530
applications sheet over the years the
our team and the sheets team I've worked

00:11:11.530 --> 00:11:11.540
our team and the sheets team I've worked
 

00:11:11.540 --> 00:11:13.600
our team and the sheets team I've worked
on benchmarking the core computational

00:11:13.600 --> 00:11:13.610
on benchmarking the core computational
 

00:11:13.610 --> 00:11:17.410
on benchmarking the core computational
logic in the cheats app or sheets

00:11:17.410 --> 00:11:17.420
logic in the cheats app or sheets
 

00:11:17.420 --> 00:11:19.120
logic in the cheats app or sheets
benchmark suite is composed of three

00:11:19.120 --> 00:11:19.130
benchmark suite is composed of three
 

00:11:19.130 --> 00:11:22.120
benchmark suite is composed of three
kinds of benchmarks benchmarking

00:11:22.120 --> 00:11:22.130
kinds of benchmarks benchmarking
 

00:11:22.130 --> 00:11:25.060
kinds of benchmarks benchmarking
low-level runtime capabilities Corsi's

00:11:25.060 --> 00:11:25.070
low-level runtime capabilities Corsi's
 

00:11:25.070 --> 00:11:27.730
low-level runtime capabilities Corsi's
formal evaluation and benchmarks that

00:11:27.730 --> 00:11:27.740
formal evaluation and benchmarks that
 

00:11:27.740 --> 00:11:32.770
formal evaluation and benchmarks that
shuffle ran themselves and we're very

00:11:32.770 --> 00:11:32.780
shuffle ran themselves and we're very
 

00:11:32.780 --> 00:11:34.120
shuffle ran themselves and we're very
excited to share with you that in

00:11:34.120 --> 00:11:34.130
excited to share with you that in
 

00:11:34.130 --> 00:11:36.460
excited to share with you that in
android do we make significant

00:11:36.460 --> 00:11:36.470
android do we make significant
 

00:11:36.470 --> 00:11:39.300
android do we make significant
improvements to our runtime and compiler

00:11:39.300 --> 00:11:39.310
improvements to our runtime and compiler
 

00:11:39.310 --> 00:11:42.310
improvements to our runtime and compiler
up to the point that we are now running

00:11:42.310 --> 00:11:42.320
up to the point that we are now running
 

00:11:42.320 --> 00:11:44.260
up to the point that we are now running
eight of eight out of the nine

00:11:44.260 --> 00:11:44.270
eight of eight out of the nine
 

00:11:44.270 --> 00:11:47.110
eight of eight out of the nine
benchmarking sheets from two times -

00:11:47.110 --> 00:11:47.120
benchmarking sheets from two times -
 

00:11:47.120 --> 00:11:49.240
benchmarking sheets from two times -
three times faster compared to our

00:11:49.240 --> 00:11:49.250
three times faster compared to our
 

00:11:49.250 --> 00:11:55.480
three times faster compared to our
previous release Naga

00:11:55.480 --> 00:11:55.490
 

00:11:55.490 --> 00:11:58.640
you may remember a similar graph and

00:11:58.640 --> 00:11:58.650
you may remember a similar graph and
 

00:11:58.650 --> 00:12:00.080
you may remember a similar graph and
this one that we presently the keynote

00:12:00.080 --> 00:12:00.090
this one that we presently the keynote
 

00:12:00.090 --> 00:12:03.740
this one that we presently the keynote
years ago this is actually a snapshot of

00:12:03.740 --> 00:12:03.750
years ago this is actually a snapshot of
 

00:12:03.750 --> 00:12:07.250
years ago this is actually a snapshot of
our benchmark monitoring tool where we

00:12:07.250 --> 00:12:07.260
our benchmark monitoring tool where we
 

00:12:07.260 --> 00:12:09.980
our benchmark monitoring tool where we
track over time the impact of each evil

00:12:09.980 --> 00:12:09.990
track over time the impact of each evil
 

00:12:09.990 --> 00:12:13.510
track over time the impact of each evil
change we do in art on our benchmarks

00:12:13.510 --> 00:12:13.520
change we do in art on our benchmarks
 

00:12:13.520 --> 00:12:16.070
change we do in art on our benchmarks
for this graph where we see that the

00:12:16.070 --> 00:12:16.080
for this graph where we see that the
 

00:12:16.080 --> 00:12:18.140
for this graph where we see that the
sheets aggregate score keeps on

00:12:18.140 --> 00:12:18.150
sheets aggregate score keeps on
 

00:12:18.150 --> 00:12:20.360
sheets aggregate score keeps on
improving month after month between the

00:12:20.360 --> 00:12:20.370
improving month after month between the
 

00:12:20.370 --> 00:12:24.680
improving month after month between the
two Android and ad with all release so

00:12:24.680 --> 00:12:24.690
two Android and ad with all release so
 

00:12:24.690 --> 00:12:26.030
two Android and ad with all release so
let me pick al explain to you the major

00:12:26.030 --> 00:12:26.040
let me pick al explain to you the major
 

00:12:26.040 --> 00:12:31.460
let me pick al explain to you the major
improvements we made for o so one major

00:12:31.460 --> 00:12:31.470
improvements we made for o so one major
 

00:12:31.470 --> 00:12:32.900
improvements we made for o so one major
change is of course on your garbage

00:12:32.900 --> 00:12:32.910
change is of course on your garbage
 

00:12:32.910 --> 00:12:35.620
change is of course on your garbage
collector that Matthew just introduced

00:12:35.620 --> 00:12:35.630
collector that Matthew just introduced
 

00:12:35.630 --> 00:12:37.970
collector that Matthew just introduced
overall and improve the performance of

00:12:37.970 --> 00:12:37.980
overall and improve the performance of
 

00:12:37.980 --> 00:12:39.370
overall and improve the performance of
sheets by 40%

00:12:39.370 --> 00:12:39.380
sheets by 40%
 

00:12:39.380 --> 00:12:41.660
sheets by 40%
thanks to thread-local allocation buffer

00:12:41.660 --> 00:12:41.670
thanks to thread-local allocation buffer
 

00:12:41.670 --> 00:12:46.630
thanks to thread-local allocation buffer
and faster collections

00:12:46.630 --> 00:12:46.640
 

00:12:46.640 --> 00:12:49.580
the next major influence we made is our

00:12:49.580 --> 00:12:49.590
the next major influence we made is our
 

00:12:49.590 --> 00:12:52.460
the next major influence we made is our
in liner which gave us another 20% boost

00:12:52.460 --> 00:12:52.470
in liner which gave us another 20% boost
 

00:12:52.470 --> 00:12:56.840
in liner which gave us another 20% boost
and this was what this optimization was

00:12:56.840 --> 00:12:56.850
and this was what this optimization was
 

00:12:56.850 --> 00:12:58.400
and this was what this optimization was
only the easiest optimizations we've

00:12:58.400 --> 00:12:58.410
only the easiest optimizations we've
 

00:12:58.410 --> 00:13:00.410
only the easiest optimizations we've
made because we already had it in liner

00:13:00.410 --> 00:13:00.420
made because we already had it in liner
 

00:13:00.420 --> 00:13:03.140
made because we already had it in liner
in EM but what happened in the end is

00:13:03.140 --> 00:13:03.150
in EM but what happened in the end is
 

00:13:03.150 --> 00:13:04.580
in EM but what happened in the end is
that now we're doing all the computation

00:13:04.580 --> 00:13:04.590
that now we're doing all the computation
 

00:13:04.590 --> 00:13:06.740
that now we're doing all the computation
in the background and we only compiled

00:13:06.740 --> 00:13:06.750
in the background and we only compiled
 

00:13:06.750 --> 00:13:09.230
in the background and we only compiled
important things I mean we can avoid the

00:13:09.230 --> 00:13:09.240
important things I mean we can avoid the
 

00:13:09.240 --> 00:13:13.370
important things I mean we can avoid the
code bloating when we in line with those

00:13:13.370 --> 00:13:13.380
code bloating when we in line with those
 

00:13:13.380 --> 00:13:14.810
code bloating when we in line with those
two improvements implemented in the end

00:13:14.810 --> 00:13:14.820
two improvements implemented in the end
 

00:13:14.820 --> 00:13:18.830
two improvements implemented in the end
it was a lot easy for us to do a more

00:13:18.830 --> 00:13:18.840
it was a lot easy for us to do a more
 

00:13:18.840 --> 00:13:21.890
it was a lot easy for us to do a more
aggressive aligning for oh so for

00:13:21.890 --> 00:13:21.900
aggressive aligning for oh so for
 

00:13:21.900 --> 00:13:24.350
aggressive aligning for oh so for
example we now in line across textiles

00:13:24.350 --> 00:13:24.360
example we now in line across textiles
 

00:13:24.360 --> 00:13:26.510
example we now in line across textiles
we in line methods which could end up

00:13:26.510 --> 00:13:26.520
we in line methods which could end up
 

00:13:26.520 --> 00:13:28.640
we in line methods which could end up
throwing and we give a much larger

00:13:28.640 --> 00:13:28.650
throwing and we give a much larger
 

00:13:28.650 --> 00:13:30.860
throwing and we give a much larger
aligning budget so more methods get in

00:13:30.860 --> 00:13:30.870
aligning budget so more methods get in
 

00:13:30.870 --> 00:13:36.050
aligning budget so more methods get in
line now let's move to an optimization

00:13:36.050 --> 00:13:36.060
line now let's move to an optimization
 

00:13:36.060 --> 00:13:38.870
line now let's move to an optimization
that did require some work and helps us

00:13:38.870 --> 00:13:38.880
that did require some work and helps us
 

00:13:38.880 --> 00:13:42.440
that did require some work and helps us
increase the sheets code like 15% this

00:13:42.440 --> 00:13:42.450
increase the sheets code like 15% this
 

00:13:42.450 --> 00:13:43.910
increase the sheets code like 15% this
is called that optimization is called

00:13:43.910 --> 00:13:43.920
is called that optimization is called
 

00:13:43.920 --> 00:13:49.610
is called that optimization is called
code thinking it's an optimization that

00:13:49.610 --> 00:13:49.620
code thinking it's an optimization that
 

00:13:49.620 --> 00:13:52.550
code thinking it's an optimization that
it essentially moves instructions next

00:13:52.550 --> 00:13:52.560
it essentially moves instructions next
 

00:13:52.560 --> 00:13:54.470
it essentially moves instructions next
that to instructions that actually use

00:13:54.470 --> 00:13:54.480
that to instructions that actually use
 

00:13:54.480 --> 00:13:57.350
that to instructions that actually use
them so typically what you want to do is

00:13:57.350 --> 00:13:57.360
them so typically what you want to do is
 

00:13:57.360 --> 00:14:00.770
them so typically what you want to do is
the instructions are that are really

00:14:00.770 --> 00:14:00.780
the instructions are that are really
 

00:14:00.780 --> 00:14:03.140
the instructions are that are really
being used you want to move them closer

00:14:03.140 --> 00:14:03.150
being used you want to move them closer
 

00:14:03.150 --> 00:14:05.480
being used you want to move them closer
to where they are used so the

00:14:05.480 --> 00:14:05.490
to where they are used so the
 

00:14:05.490 --> 00:14:07.160
to where they are used so the
instructions are not in a regular flow

00:14:07.160 --> 00:14:07.170
instructions are not in a regular flow
 

00:14:07.170 --> 00:14:08.190
instructions are not in a regular flow
of your

00:14:08.190 --> 00:14:08.200
of your
 

00:14:08.200 --> 00:14:10.740
of your
want to move them to the intestinal

00:14:10.740 --> 00:14:10.750
want to move them to the intestinal
 

00:14:10.750 --> 00:14:14.850
want to move them to the intestinal
cases that's fairly abstract so let me

00:14:14.850 --> 00:14:14.860
cases that's fairly abstract so let me
 

00:14:14.860 --> 00:14:15.930
cases that's fairly abstract so let me
give you an example to make it more

00:14:15.930 --> 00:14:15.940
give you an example to make it more
 

00:14:15.940 --> 00:14:22.700
give you an example to make it more
concrete here's an accept of sheets code

00:14:22.700 --> 00:14:22.710
concrete here's an accept of sheets code
 

00:14:22.710 --> 00:14:25.430
concrete here's an accept of sheets code
there's a method called who ate range

00:14:25.430 --> 00:14:25.440
there's a method called who ate range
 

00:14:25.440 --> 00:14:28.170
there's a method called who ate range
takes two integers and returns a new

00:14:28.170 --> 00:14:28.180
takes two integers and returns a new
 

00:14:28.180 --> 00:14:33.090
takes two integers and returns a new
range the query range method shows a

00:14:33.090 --> 00:14:33.100
range the query range method shows a
 

00:14:33.100 --> 00:14:36.590
range the query range method shows a
helper method called check condition

00:14:36.590 --> 00:14:36.600
helper method called check condition
 

00:14:36.600 --> 00:14:38.850
helper method called check condition
that will check the required conditions

00:14:38.850 --> 00:14:38.860
that will check the required conditions
 

00:14:38.860 --> 00:14:41.970
that will check the required conditions
for creating a range if those conditions

00:14:41.970 --> 00:14:41.980
for creating a range if those conditions
 

00:14:41.980 --> 00:14:45.740
for creating a range if those conditions
are not met we'll throw an error

00:14:45.740 --> 00:14:45.750
are not met we'll throw an error
 

00:14:45.750 --> 00:14:49.920
are not met we'll throw an error
notice how the check condition is a very

00:14:49.920 --> 00:14:49.930
notice how the check condition is a very
 

00:14:49.930 --> 00:14:53.520
notice how the check condition is a very
first method and this is important to

00:14:53.520 --> 00:14:53.530
first method and this is important to
 

00:14:53.530 --> 00:14:56.190
first method and this is important to
notice because it will affect the code

00:14:56.190 --> 00:14:56.200
notice because it will affect the code
 

00:14:56.200 --> 00:15:00.540
notice because it will affect the code
that is being sent to our runtime here's

00:15:00.540 --> 00:15:00.550
that is being sent to our runtime here's
 

00:15:00.550 --> 00:15:05.300
that is being sent to our runtime here's
how so you start with a simple method

00:15:05.300 --> 00:15:05.310
how so you start with a simple method
 

00:15:05.310 --> 00:15:08.010
how so you start with a simple method
the Java compiler actually did sugars

00:15:08.010 --> 00:15:08.020
the Java compiler actually did sugars
 

00:15:08.020 --> 00:15:12.210
the Java compiler actually did sugars
the varargs call to allocating a new

00:15:12.210 --> 00:15:12.220
the varargs call to allocating a new
 

00:15:12.220 --> 00:15:15.210
the varargs call to allocating a new
object putting that allocating a new

00:15:15.210 --> 00:15:15.220
object putting that allocating a new
 

00:15:15.220 --> 00:15:19.230
object putting that allocating a new
array putting in an array boxed versions

00:15:19.230 --> 00:15:19.240
array putting in an array boxed versions
 

00:15:19.240 --> 00:15:22.470
array putting in an array boxed versions
of start and end and then passing this

00:15:22.470 --> 00:15:22.480
of start and end and then passing this
 

00:15:22.480 --> 00:15:25.380
of start and end and then passing this
array to check condition and this is an

00:15:25.380 --> 00:15:25.390
array to check condition and this is an
 

00:15:25.390 --> 00:15:27.300
array to check condition and this is an
Android specific this is what the Java

00:15:27.300 --> 00:15:27.310
Android specific this is what the Java
 

00:15:27.310 --> 00:15:28.710
Android specific this is what the Java
compiler does when compiled to bytecode

00:15:28.710 --> 00:15:28.720
compiler does when compiled to bytecode
 

00:15:28.720 --> 00:15:32.940
compiler does when compiled to bytecode
and these instructions are not

00:15:32.940 --> 00:15:32.950
and these instructions are not
 

00:15:32.950 --> 00:15:35.760
and these instructions are not
completely free yes we made allocations

00:15:35.760 --> 00:15:35.770
completely free yes we made allocations
 

00:15:35.770 --> 00:15:37.170
completely free yes we made allocations
extremely fast with the new garbage

00:15:37.170 --> 00:15:37.180
extremely fast with the new garbage
 

00:15:37.180 --> 00:15:39.180
extremely fast with the new garbage
collector but having to create this

00:15:39.180 --> 00:15:39.190
collector but having to create this
 

00:15:39.190 --> 00:15:41.250
collector but having to create this
array the boxed versions of storing and

00:15:41.250 --> 00:15:41.260
array the boxed versions of storing and
 

00:15:41.260 --> 00:15:44.040
array the boxed versions of storing and
all the time the method is executed is

00:15:44.040 --> 00:15:44.050
all the time the method is executed is
 

00:15:44.050 --> 00:15:47.720
all the time the method is executed is
not really ideal so here's how we avoid

00:15:47.720 --> 00:15:47.730
not really ideal so here's how we avoid
 

00:15:47.730 --> 00:15:52.950
not really ideal so here's how we avoid
executed completely first we can easily

00:15:52.950 --> 00:15:52.960
executed completely first we can easily
 

00:15:52.960 --> 00:15:55.650
executed completely first we can easily
inline the call to check condition so

00:15:55.650 --> 00:15:55.660
inline the call to check condition so
 

00:15:55.660 --> 00:15:57.510
inline the call to check condition so
int only this is how the code is

00:15:57.510 --> 00:15:57.520
int only this is how the code is
 

00:15:57.520 --> 00:16:02.220
int only this is how the code is
transformed in art

00:16:02.220 --> 00:16:02.230
 

00:16:02.230 --> 00:16:06.820
notice how arcs now is only used in the

00:16:06.820 --> 00:16:06.830
notice how arcs now is only used in the
 

00:16:06.830 --> 00:16:11.860
notice how arcs now is only used in the
in French so where the compiler can do

00:16:11.860 --> 00:16:11.870
in French so where the compiler can do
 

00:16:11.870 --> 00:16:14.890
in French so where the compiler can do
is move the allocation and the boxing

00:16:14.890 --> 00:16:14.900
is move the allocation and the boxing
 

00:16:14.900 --> 00:16:17.710
is move the allocation and the boxing
closer to where arcs is being used in

00:16:17.710 --> 00:16:17.720
closer to where arcs is being used in
 

00:16:17.720 --> 00:16:21.610
closer to where arcs is being used in
the exceptional flow so at the end of

00:16:21.610 --> 00:16:21.620
the exceptional flow so at the end of
 

00:16:21.620 --> 00:16:23.710
the exceptional flow so at the end of
this optimization what the compilers

00:16:23.710 --> 00:16:23.720
this optimization what the compilers
 

00:16:23.720 --> 00:16:26.200
this optimization what the compilers
made sure of is that only the require

00:16:26.200 --> 00:16:26.210
made sure of is that only the require
 

00:16:26.210 --> 00:16:28.090
made sure of is that only the require
instructions will be executed in the

00:16:28.090 --> 00:16:28.100
instructions will be executed in the
 

00:16:28.100 --> 00:16:34.960
instructions will be executed in the
normal flow the last optimization I want

00:16:34.960 --> 00:16:34.970
normal flow the last optimization I want
 

00:16:34.970 --> 00:16:37.150
normal flow the last optimization I want
to mention here is class your key

00:16:37.150 --> 00:16:37.160
to mention here is class your key
 

00:16:37.160 --> 00:16:42.640
to mention here is class your key
analysis class search analysis is a

00:16:42.640 --> 00:16:42.650
analysis class search analysis is a
 

00:16:42.650 --> 00:16:44.470
analysis class search analysis is a
pretty common technique in object

00:16:44.470 --> 00:16:44.480
pretty common technique in object
 

00:16:44.480 --> 00:16:47.080
pretty common technique in object
oriented language what a runtime will

00:16:47.080 --> 00:16:47.090
oriented language what a runtime will
 

00:16:47.090 --> 00:16:50.590
oriented language what a runtime will
try to infer classes or methods that can

00:16:50.590 --> 00:16:50.600
try to infer classes or methods that can
 

00:16:50.600 --> 00:16:53.530
try to infer classes or methods that can
be made final even though they aren't

00:16:53.530 --> 00:16:53.540
be made final even though they aren't
 

00:16:53.540 --> 00:16:57.400
be made final even though they aren't
markets final having this information

00:16:57.400 --> 00:16:57.410
markets final having this information
 

00:16:57.410 --> 00:17:01.450
markets final having this information
internally gives a lot of room for the

00:17:01.450 --> 00:17:01.460
internally gives a lot of room for the
 

00:17:01.460 --> 00:17:04.030
internally gives a lot of room for the
compiler for more optimizations for

00:17:04.030 --> 00:17:04.040
compiler for more optimizations for
 

00:17:04.040 --> 00:17:09.120
compiler for more optimizations for
example you can do more inlining and

00:17:09.120 --> 00:17:09.130
example you can do more inlining and
 

00:17:09.130 --> 00:17:13.090
example you can do more inlining and
because Java has dynamic clustering we

00:17:13.090 --> 00:17:13.100
because Java has dynamic clustering we
 

00:17:13.100 --> 00:17:14.890
because Java has dynamic clustering we
will bail out of this optimizations

00:17:14.890 --> 00:17:14.900
will bail out of this optimizations
 

00:17:14.900 --> 00:17:17.470
will bail out of this optimizations
if sudden you would suddenly a new a new

00:17:17.470 --> 00:17:17.480
if sudden you would suddenly a new a new
 

00:17:17.480 --> 00:17:19.810
if sudden you would suddenly a new a new
class gets loaded and all the

00:17:19.810 --> 00:17:19.820
class gets loaded and all the
 

00:17:19.820 --> 00:17:22.210
class gets loaded and all the
optimizations we did by inferring final

00:17:22.210 --> 00:17:22.220
optimizations we did by inferring final
 

00:17:22.220 --> 00:17:29.030
optimizations we did by inferring final
classes and methods become invalid

00:17:29.030 --> 00:17:29.040
 

00:17:29.040 --> 00:17:31.350
so this sums up the optimizations I will

00:17:31.350 --> 00:17:31.360
so this sums up the optimizations I will
 

00:17:31.360 --> 00:17:34.200
so this sums up the optimizations I will
instruct you about for the record we'll

00:17:34.200 --> 00:17:34.210
instruct you about for the record we'll
 

00:17:34.210 --> 00:17:36.570
instruct you about for the record we'll
also did a bunch of other improvements

00:17:36.570 --> 00:17:36.580
also did a bunch of other improvements
 

00:17:36.580 --> 00:17:39.960
also did a bunch of other improvements
for this release such as faster type

00:17:39.960 --> 00:17:39.970
for this release such as faster type
 

00:17:39.970 --> 00:17:42.660
for this release such as faster type
checks faster access is pop-out code for

00:17:42.660 --> 00:17:42.670
checks faster access is pop-out code for
 

00:17:42.670 --> 00:17:46.010
checks faster access is pop-out code for
class of strings faster gni transitions

00:17:46.010 --> 00:17:46.020
class of strings faster gni transitions
 

00:17:46.020 --> 00:17:49.790
class of strings faster gni transitions
more compiler instances and a lot more

00:17:49.790 --> 00:17:49.800
more compiler instances and a lot more
 

00:17:49.800 --> 00:17:53.360
more compiler instances and a lot more
well did not have the space to list here

00:17:53.360 --> 00:17:53.370
well did not have the space to list here
 

00:17:53.370 --> 00:17:55.620
well did not have the space to list here
so for the interest of time I'm not

00:17:55.620 --> 00:17:55.630
so for the interest of time I'm not
 

00:17:55.630 --> 00:17:57.060
so for the interest of time I'm not
going to go into details on these

00:17:57.060 --> 00:17:57.070
going to go into details on these
 

00:17:57.070 --> 00:17:59.910
going to go into details on these
optimizations instead I'm going to head

00:17:59.910 --> 00:17:59.920
optimizations instead I'm going to head
 

00:17:59.920 --> 00:18:02.430
optimizations instead I'm going to head
over to art we're going to tell you

00:18:02.430 --> 00:18:02.440
over to art we're going to tell you
 

00:18:02.440 --> 00:18:04.890
over to art we're going to tell you
about the whole new set of loop

00:18:04.890 --> 00:18:04.900
about the whole new set of loop
 

00:18:04.900 --> 00:18:16.110
about the whole new set of loop
optimizations Thank You Nicholas so if

00:18:16.110 --> 00:18:16.120
optimizations Thank You Nicholas so if
 

00:18:16.120 --> 00:18:19.200
optimizations Thank You Nicholas so if
you don't look at virtual method

00:18:19.200 --> 00:18:19.210
you don't look at virtual method
 

00:18:19.210 --> 00:18:21.170
you don't look at virtual method
overhead or general runtime overhead

00:18:21.170 --> 00:18:21.180
overhead or general runtime overhead
 

00:18:21.180 --> 00:18:23.550
overhead or general runtime overhead
programs tend to spend most of the time

00:18:23.550 --> 00:18:23.560
programs tend to spend most of the time
 

00:18:23.560 --> 00:18:27.060
programs tend to spend most of the time
in loops so besides all the good stuff

00:18:27.060 --> 00:18:27.070
in loops so besides all the good stuff
 

00:18:27.070 --> 00:18:28.620
in loops so besides all the good stuff
that Nicholas already talked about it

00:18:28.620 --> 00:18:28.630
that Nicholas already talked about it
 

00:18:28.630 --> 00:18:31.140
that Nicholas already talked about it
can really pay off by optimizing loops

00:18:31.140 --> 00:18:31.150
can really pay off by optimizing loops
 

00:18:31.150 --> 00:18:34.290
can really pay off by optimizing loops
specifically and I will discuss some of

00:18:34.290 --> 00:18:34.300
specifically and I will discuss some of
 

00:18:34.300 --> 00:18:37.800
specifically and I will discuss some of
these in this part optimizations really

00:18:37.800 --> 00:18:37.810
these in this part optimizations really
 

00:18:37.810 --> 00:18:39.990
these in this part optimizations really
always consist of an analysis part where

00:18:39.990 --> 00:18:40.000
always consist of an analysis part where
 

00:18:40.000 --> 00:18:41.520
always consist of an analysis part where
you look at the program and an

00:18:41.520 --> 00:18:41.530
you look at the program and an
 

00:18:41.530 --> 00:18:43.140
you look at the program and an
optimization part where you actually

00:18:43.140 --> 00:18:43.150
optimization part where you actually
 

00:18:43.150 --> 00:18:45.420
optimization part where you actually
perform the transformations and you can

00:18:45.420 --> 00:18:45.430
perform the transformations and you can
 

00:18:45.430 --> 00:18:47.430
perform the transformations and you can
see here like a list of all the work we

00:18:47.430 --> 00:18:47.440
see here like a list of all the work we
 

00:18:47.440 --> 00:18:50.160
see here like a list of all the work we
did for all but I'll only touch on a few

00:18:50.160 --> 00:18:50.170
did for all but I'll only touch on a few
 

00:18:50.170 --> 00:18:54.060
did for all but I'll only touch on a few
of those in the interest of time but

00:18:54.060 --> 00:18:54.070
of those in the interest of time but
 

00:18:54.070 --> 00:18:55.980
of those in the interest of time but
before I do that let's first look at

00:18:55.980 --> 00:18:55.990
before I do that let's first look at
 

00:18:55.990 --> 00:18:57.780
before I do that let's first look at
what loop optimizations can do for you

00:18:57.780 --> 00:18:57.790
what loop optimizations can do for you
 

00:18:57.790 --> 00:19:00.380
what loop optimizations can do for you
so here you see a graph that quotes

00:19:00.380 --> 00:19:00.390
so here you see a graph that quotes
 

00:19:00.390 --> 00:19:02.610
so here you see a graph that quotes
Android all versus Android end

00:19:02.610 --> 00:19:02.620
Android all versus Android end
 

00:19:02.620 --> 00:19:05.070
Android all versus Android end
performance so higher is better and the

00:19:05.070 --> 00:19:05.080
performance so higher is better and the
 

00:19:05.080 --> 00:19:07.050
performance so higher is better and the
color encoding shows you specifically

00:19:07.050 --> 00:19:07.060
color encoding shows you specifically
 

00:19:07.060 --> 00:19:10.560
color encoding shows you specifically
where loop optimizations in general the

00:19:10.560 --> 00:19:10.570
where loop optimizations in general the
 

00:19:10.570 --> 00:19:13.110
where loop optimizations in general the
blue stuff has helped and the red stuff

00:19:13.110 --> 00:19:13.120
blue stuff has helped and the red stuff
 

00:19:13.120 --> 00:19:14.940
blue stuff has helped and the red stuff
where factorization which I'll talk

00:19:14.940 --> 00:19:14.950
where factorization which I'll talk
 

00:19:14.950 --> 00:19:17.370
where factorization which I'll talk
about briefly has helped and you see

00:19:17.370 --> 00:19:17.380
about briefly has helped and you see
 

00:19:17.380 --> 00:19:19.710
about briefly has helped and you see
that benchmarks on the left like loop

00:19:19.710 --> 00:19:19.720
that benchmarks on the left like loop
 

00:19:19.720 --> 00:19:22.350
that benchmarks on the left like loop
and some really get unrealistic highs

00:19:22.350 --> 00:19:22.360
and some really get unrealistic highs
 

00:19:22.360 --> 00:19:25.050
and some really get unrealistic highs
speed ups and it is really as a result

00:19:25.050 --> 00:19:25.060
speed ups and it is really as a result
 

00:19:25.060 --> 00:19:27.330
speed ups and it is really as a result
of that we broke the benchmark so we

00:19:27.330 --> 00:19:27.340
of that we broke the benchmark so we
 

00:19:27.340 --> 00:19:29.010
of that we broke the benchmark so we
were able to transform loops into

00:19:29.010 --> 00:19:29.020
were able to transform loops into
 

00:19:29.020 --> 00:19:30.990
were able to transform loops into
closed-form expressions that execute

00:19:30.990 --> 00:19:31.000
closed-form expressions that execute
 

00:19:31.000 --> 00:19:33.540
closed-form expressions that execute
really fast and although that's always

00:19:33.540 --> 00:19:33.550
really fast and although that's always
 

00:19:33.550 --> 00:19:35.220
really fast and although that's always
nice to have the ability in your

00:19:35.220 --> 00:19:35.230
nice to have the ability in your
 

00:19:35.230 --> 00:19:38.070
nice to have the ability in your
compiler it's not very realistic but as

00:19:38.070 --> 00:19:38.080
compiler it's not very realistic but as
 

00:19:38.080 --> 00:19:40.350
compiler it's not very realistic but as
you go to the right of the graph you see

00:19:40.350 --> 00:19:40.360
you go to the right of the graph you see
 

00:19:40.360 --> 00:19:42.200
you go to the right of the graph you see
more realistic speed ups

00:19:42.200 --> 00:19:42.210
more realistic speed ups
 

00:19:42.210 --> 00:19:45.160
more realistic speed ups
like LUN Linpack obtained like 10%

00:19:45.160 --> 00:19:45.170
like LUN Linpack obtained like 10%
 

00:19:45.170 --> 00:19:51.620
like LUN Linpack obtained like 10%
improvements by factorizations so

00:19:51.620 --> 00:19:51.630
improvements by factorizations so
 

00:19:51.630 --> 00:19:53.900
improvements by factorizations so
central to all loop optimizations

00:19:53.900 --> 00:19:53.910
central to all loop optimizations
 

00:19:53.910 --> 00:19:55.490
central to all loop optimizations
is always induction variable

00:19:55.490 --> 00:19:55.500
is always induction variable
 

00:19:55.500 --> 00:19:57.590
is always induction variable
recognitions and that consists of

00:19:57.590 --> 00:19:57.600
recognitions and that consists of
 

00:19:57.600 --> 00:20:00.440
recognitions and that consists of
finding expressions that progress in a

00:20:00.440 --> 00:20:00.450
finding expressions that progress in a
 

00:20:00.450 --> 00:20:02.750
finding expressions that progress in a
regular and predictable way in your loop

00:20:02.750 --> 00:20:02.760
regular and predictable way in your loop
 

00:20:02.760 --> 00:20:05.720
regular and predictable way in your loop
and the most common example is a linear

00:20:05.720 --> 00:20:05.730
and the most common example is a linear
 

00:20:05.730 --> 00:20:08.660
and the most common example is a linear
induction so here in this example the

00:20:08.660 --> 00:20:08.670
induction so here in this example the
 

00:20:08.670 --> 00:20:10.520
induction so here in this example the
basic loop counter I is a linear

00:20:10.520 --> 00:20:10.530
basic loop counter I is a linear
 

00:20:10.530 --> 00:20:12.890
basic loop counter I is a linear
induction but also the expression J

00:20:12.890 --> 00:20:12.900
induction but also the expression J
 

00:20:12.900 --> 00:20:14.630
induction but also the expression J
shown in blue is a linear induction

00:20:14.630 --> 00:20:14.640
shown in blue is a linear induction
 

00:20:14.640 --> 00:20:17.240
shown in blue is a linear induction
every time around the iteration its

00:20:17.240 --> 00:20:17.250
every time around the iteration its
 

00:20:17.250 --> 00:20:21.280
every time around the iteration its
increments by a loop invariant constants

00:20:21.280 --> 00:20:21.290
increments by a loop invariant constants
 

00:20:21.290 --> 00:20:24.260
increments by a loop invariant constants
there's many more induction variables

00:20:24.260 --> 00:20:24.270
there's many more induction variables
 

00:20:24.270 --> 00:20:26.510
there's many more induction variables
and you see some of them depicted here

00:20:26.510 --> 00:20:26.520
and you see some of them depicted here
 

00:20:26.520 --> 00:20:28.700
and you see some of them depicted here
on the graph and detecting as many of

00:20:28.700 --> 00:20:28.710
on the graph and detecting as many of
 

00:20:28.710 --> 00:20:31.310
on the graph and detecting as many of
them as possible is always good for the

00:20:31.310 --> 00:20:31.320
them as possible is always good for the
 

00:20:31.320 --> 00:20:36.110
them as possible is always good for the
next phase the actual optimizations so

00:20:36.110 --> 00:20:36.120
next phase the actual optimizations so
 

00:20:36.120 --> 00:20:38.390
next phase the actual optimizations so
let's look at what loop optimizations

00:20:38.390 --> 00:20:38.400
let's look at what loop optimizations
 

00:20:38.400 --> 00:20:41.810
let's look at what loop optimizations
can benefit from induction variables so

00:20:41.810 --> 00:20:41.820
can benefit from induction variables so
 

00:20:41.820 --> 00:20:43.970
can benefit from induction variables so
here you see a somewhat synthetic

00:20:43.970 --> 00:20:43.980
here you see a somewhat synthetic
 

00:20:43.980 --> 00:20:46.880
here you see a somewhat synthetic
example where the compiler can easily

00:20:46.880 --> 00:20:46.890
example where the compiler can easily
 

00:20:46.890 --> 00:20:48.950
example where the compiler can easily
see that in the innermost loop the

00:20:48.950 --> 00:20:48.960
see that in the innermost loop the
 

00:20:48.960 --> 00:20:51.170
see that in the innermost loop the
increment to sum actually is very

00:20:51.170 --> 00:20:51.180
increment to sum actually is very
 

00:20:51.180 --> 00:20:53.930
increment to sum actually is very
predictable since the loop only iterates

00:20:53.930 --> 00:20:53.940
predictable since the loop only iterates
 

00:20:53.940 --> 00:20:56.410
predictable since the loop only iterates
hundred times it can actually replace

00:20:56.410 --> 00:20:56.420
hundred times it can actually replace
 

00:20:56.420 --> 00:20:59.870
hundred times it can actually replace
the sum hoisted out with a closed form

00:20:59.870 --> 00:20:59.880
the sum hoisted out with a closed form
 

00:20:59.880 --> 00:21:02.150
the sum hoisted out with a closed form
expression that just adds hundreds at a

00:21:02.150 --> 00:21:02.160
expression that just adds hundreds at a
 

00:21:02.160 --> 00:21:02.860
expression that just adds hundreds at a
time

00:21:02.860 --> 00:21:02.870
time
 

00:21:02.870 --> 00:21:05.210
time
after you've done that you can actually

00:21:05.210 --> 00:21:05.220
after you've done that you can actually
 

00:21:05.220 --> 00:21:07.220
after you've done that you can actually
hoist it again out of the next loop if

00:21:07.220 --> 00:21:07.230
hoist it again out of the next loop if
 

00:21:07.230 --> 00:21:09.620
hoist it again out of the next loop if
you take a little bit care of the fact

00:21:09.620 --> 00:21:09.630
you take a little bit care of the fact
 

00:21:09.630 --> 00:21:11.300
you take a little bit care of the fact
that the loop may not be taken when n is

00:21:11.300 --> 00:21:11.310
that the loop may not be taken when n is
 

00:21:11.310 --> 00:21:13.910
that the loop may not be taken when n is
negative so after that the whole

00:21:13.910 --> 00:21:13.920
negative so after that the whole
 

00:21:13.920 --> 00:21:15.770
negative so after that the whole
computation has been hoisted out of the

00:21:15.770 --> 00:21:15.780
computation has been hoisted out of the
 

00:21:15.780 --> 00:21:17.720
computation has been hoisted out of the
loop and the whole double loop can be

00:21:17.720 --> 00:21:17.730
loop and the whole double loop can be
 

00:21:17.730 --> 00:21:20.600
loop and the whole double loop can be
eliminated so in this case the whole

00:21:20.600 --> 00:21:20.610
eliminated so in this case the whole
 

00:21:20.610 --> 00:21:22.940
eliminated so in this case the whole
loop is replaced by closed form and

00:21:22.940 --> 00:21:22.950
loop is replaced by closed form and
 

00:21:22.950 --> 00:21:24.830
loop is replaced by closed form and
that's one of the examples that I showed

00:21:24.830 --> 00:21:24.840
that's one of the examples that I showed
 

00:21:24.840 --> 00:21:26.240
that's one of the examples that I showed
in the beginning very broke the

00:21:26.240 --> 00:21:26.250
in the beginning very broke the
 

00:21:26.250 --> 00:21:30.170
in the beginning very broke the
benchmark obviously your code you'll

00:21:30.170 --> 00:21:30.180
benchmark obviously your code you'll
 

00:21:30.180 --> 00:21:32.210
benchmark obviously your code you'll
probably not benefit this greatly from

00:21:32.210 --> 00:21:32.220
probably not benefit this greatly from
 

00:21:32.220 --> 00:21:34.340
probably not benefit this greatly from
optimizations but having this ability

00:21:34.340 --> 00:21:34.350
optimizations but having this ability
 

00:21:34.350 --> 00:21:38.360
optimizations but having this ability
can really kick in like after you inline

00:21:38.360 --> 00:21:38.370
can really kick in like after you inline
 

00:21:38.370 --> 00:21:41.540
can really kick in like after you inline
library code not to the same degree but

00:21:41.540 --> 00:21:41.550
library code not to the same degree but
 

00:21:41.550 --> 00:21:44.090
library code not to the same degree but
still nice to be able to to optimize

00:21:44.090 --> 00:21:44.100
still nice to be able to to optimize
 

00:21:44.100 --> 00:21:48.790
still nice to be able to to optimize
your induction variables

00:21:48.790 --> 00:21:48.800
 

00:21:48.800 --> 00:21:50.890
another example where induction

00:21:50.890 --> 00:21:50.900
another example where induction
 

00:21:50.900 --> 00:21:52.660
another example where induction
variables can help you is it bounced

00:21:52.660 --> 00:21:52.670
variables can help you is it bounced
 

00:21:52.670 --> 00:21:55.270
variables can help you is it bounced
check eliminations so when you access an

00:21:55.270 --> 00:21:55.280
check eliminations so when you access an
 

00:21:55.280 --> 00:21:57.490
check eliminations so when you access an
array you always need to test to see

00:21:57.490 --> 00:21:57.500
array you always need to test to see
 

00:21:57.500 --> 00:21:59.110
array you always need to test to see
whether the subscripts can go out of

00:21:59.110 --> 00:21:59.120
whether the subscripts can go out of
 

00:21:59.120 --> 00:22:00.520
whether the subscripts can go out of
bounds and if they do you throw an

00:22:00.520 --> 00:22:00.530
bounds and if they do you throw an
 

00:22:00.530 --> 00:22:02.980
bounds and if they do you throw an
exception but if you know the exact

00:22:02.980 --> 00:22:02.990
exception but if you know the exact
 

00:22:02.990 --> 00:22:04.660
exception but if you know the exact
range that induction variables will take

00:22:04.660 --> 00:22:04.670
range that induction variables will take
 

00:22:04.670 --> 00:22:07.510
range that induction variables will take
you can often eliminate those tests

00:22:07.510 --> 00:22:07.520
you can often eliminate those tests
 

00:22:07.520 --> 00:22:09.520
you can often eliminate those tests
completely so here you seen an example

00:22:09.520 --> 00:22:09.530
completely so here you seen an example
 

00:22:09.530 --> 00:22:13.330
completely so here you seen an example
that both the XS - a and B will never go

00:22:13.330 --> 00:22:13.340
that both the XS - a and B will never go
 

00:22:13.340 --> 00:22:15.340
that both the XS - a and B will never go
out of bounds so the compiler can

00:22:15.340 --> 00:22:15.350
out of bounds so the compiler can
 

00:22:15.350 --> 00:22:17.560
out of bounds so the compiler can
statically remove those tests and the

00:22:17.560 --> 00:22:17.570
statically remove those tests and the
 

00:22:17.570 --> 00:22:19.750
statically remove those tests and the
program as a result will execute a lot

00:22:19.750 --> 00:22:19.760
program as a result will execute a lot
 

00:22:19.760 --> 00:22:26.740
program as a result will execute a lot
faster induction variables also tell how

00:22:26.740 --> 00:22:26.750
faster induction variables also tell how
 

00:22:26.750 --> 00:22:29.620
faster induction variables also tell how
often looks iterate so if you know that

00:22:29.620 --> 00:22:29.630
often looks iterate so if you know that
 

00:22:29.630 --> 00:22:31.720
often looks iterate so if you know that
it's only a few times you can actually

00:22:31.720 --> 00:22:31.730
it's only a few times you can actually
 

00:22:31.730 --> 00:22:35.110
it's only a few times you can actually
completely unroll the loop and the

00:22:35.110 --> 00:22:35.120
completely unroll the loop and the
 

00:22:35.120 --> 00:22:36.520
completely unroll the loop and the
advantage of enrolling is that you

00:22:36.520 --> 00:22:36.530
advantage of enrolling is that you
 

00:22:36.530 --> 00:22:38.230
advantage of enrolling is that you
completely removed the loop control

00:22:38.230 --> 00:22:38.240
completely removed the loop control
 

00:22:38.240 --> 00:22:40.480
completely removed the loop control
overhead it reduces the code size

00:22:40.480 --> 00:22:40.490
overhead it reduces the code size
 

00:22:40.490 --> 00:22:42.850
overhead it reduces the code size
because you don't have to control to

00:22:42.850 --> 00:22:42.860
because you don't have to control to
 

00:22:42.860 --> 00:22:45.790
because you don't have to control to
iterate and it often enables like

00:22:45.790 --> 00:22:45.800
iterate and it often enables like
 

00:22:45.800 --> 00:22:47.800
iterate and it often enables like
constant folding so you see an example

00:22:47.800 --> 00:22:47.810
constant folding so you see an example
 

00:22:47.810 --> 00:22:50.050
constant folding so you see an example
here where the blue part shows that the

00:22:50.050 --> 00:22:50.060
here where the blue part shows that the
 

00:22:50.060 --> 00:22:52.120
here where the blue part shows that the
loop only iterate from 10 to 10 so it

00:22:52.120 --> 00:22:52.130
loop only iterate from 10 to 10 so it
 

00:22:52.130 --> 00:22:54.370
loop only iterate from 10 to 10 so it
actually only iterates once so you can

00:22:54.370 --> 00:22:54.380
actually only iterates once so you can
 

00:22:54.380 --> 00:22:55.870
actually only iterates once so you can
replace the whole loop with a single

00:22:55.870 --> 00:22:55.880
replace the whole loop with a single
 

00:22:55.880 --> 00:22:57.910
replace the whole loop with a single
statement and as a result you can also

00:22:57.910 --> 00:22:57.920
statement and as a result you can also
 

00:22:57.920 --> 00:23:00.010
statement and as a result you can also
constant fold to multiplication and

00:23:00.010 --> 00:23:00.020
constant fold to multiplication and
 

00:23:00.020 --> 00:23:02.650
constant fold to multiplication and
already do that at compile time so the

00:23:02.650 --> 00:23:02.660
already do that at compile time so the
 

00:23:02.660 --> 00:23:05.350
already do that at compile time so the
program will run a lot faster again

00:23:05.350 --> 00:23:05.360
program will run a lot faster again
 

00:23:05.360 --> 00:23:08.080
program will run a lot faster again
typical code Volt's optimized right away

00:23:08.080 --> 00:23:08.090
typical code Volt's optimized right away
 

00:23:08.090 --> 00:23:10.330
typical code Volt's optimized right away
but of the inlining or other forms of

00:23:10.330 --> 00:23:10.340
but of the inlining or other forms of
 

00:23:10.340 --> 00:23:12.550
but of the inlining or other forms of
specializations these situations are

00:23:12.550 --> 00:23:12.560
specializations these situations are
 

00:23:12.560 --> 00:23:15.120
specializations these situations are
cure and they can help improve your

00:23:15.120 --> 00:23:15.130
cure and they can help improve your
 

00:23:15.130 --> 00:23:21.610
cure and they can help improve your
performance so the last loop

00:23:21.610 --> 00:23:21.620
performance so the last loop
 

00:23:21.620 --> 00:23:23.920
performance so the last loop
optimization I want to talk about is the

00:23:23.920 --> 00:23:23.930
optimization I want to talk about is the
 

00:23:23.930 --> 00:23:27.220
optimization I want to talk about is the
ability of Android all to act to take

00:23:27.220 --> 00:23:27.230
ability of Android all to act to take
 

00:23:27.230 --> 00:23:30.190
ability of Android all to act to take
advantage of Cindy instructions so Cindy

00:23:30.190 --> 00:23:30.200
advantage of Cindy instructions so Cindy
 

00:23:30.200 --> 00:23:31.810
advantage of Cindy instructions so Cindy
instructions are instructions that

00:23:31.810 --> 00:23:31.820
instructions are instructions that
 

00:23:31.820 --> 00:23:33.660
instructions are instructions that
perform a single operation

00:23:33.660 --> 00:23:33.670
perform a single operation
 

00:23:33.670 --> 00:23:36.400
perform a single operation
simultaneously to multiple data operands

00:23:36.400 --> 00:23:36.410
simultaneously to multiple data operands
 

00:23:36.410 --> 00:23:39.000
simultaneously to multiple data operands
so you see an example here where one

00:23:39.000 --> 00:23:39.010
so you see an example here where one
 

00:23:39.010 --> 00:23:41.410
so you see an example here where one
instruction actually does four additions

00:23:41.410 --> 00:23:41.420
instruction actually does four additions
 

00:23:41.420 --> 00:23:44.110
instruction actually does four additions
at the same time and all our target

00:23:44.110 --> 00:23:44.120
at the same time and all our target
 

00:23:44.120 --> 00:23:48.880
at the same time and all our target
platforms are Intel mitts they have such

00:23:48.880 --> 00:23:48.890
platforms are Intel mitts they have such
 

00:23:48.890 --> 00:23:51.130
platforms are Intel mitts they have such
instructions and if you take advantage

00:23:51.130 --> 00:23:51.140
instructions and if you take advantage
 

00:23:51.140 --> 00:23:52.780
instructions and if you take advantage
of them it can greatly improve the

00:23:52.780 --> 00:23:52.790
of them it can greatly improve the
 

00:23:52.790 --> 00:23:54.610
of them it can greatly improve the
performance of certain classes of

00:23:54.610 --> 00:23:54.620
performance of certain classes of
 

00:23:54.620 --> 00:23:58.539
performance of certain classes of
programs

00:23:58.539 --> 00:23:58.549
 

00:23:58.549 --> 00:24:01.669
so converting sequential code and we

00:24:01.669 --> 00:24:01.679
so converting sequential code and we
 

00:24:01.679 --> 00:24:03.530
so converting sequential code and we
typically focus on loops but it doesn't

00:24:03.530 --> 00:24:03.540
typically focus on loops but it doesn't
 

00:24:03.540 --> 00:24:05.630
typically focus on loops but it doesn't
have to be restricted to that into code

00:24:05.630 --> 00:24:05.640
have to be restricted to that into code
 

00:24:05.640 --> 00:24:06.980
have to be restricted to that into code
it exploits to send the instructions

00:24:06.980 --> 00:24:06.990
it exploits to send the instructions
 

00:24:06.990 --> 00:24:10.630
it exploits to send the instructions
that process is called factorization and

00:24:10.630 --> 00:24:10.640
that process is called factorization and
 

00:24:10.640 --> 00:24:13.280
that process is called factorization and
it's illustrated here where on the left

00:24:13.280 --> 00:24:13.290
it's illustrated here where on the left
 

00:24:13.290 --> 00:24:14.500
it's illustrated here where on the left
you see a loop that iterates

00:24:14.500 --> 00:24:14.510
you see a loop that iterates
 

00:24:14.510 --> 00:24:16.700
you see a loop that iterates
sequentially and on the right you see

00:24:16.700 --> 00:24:16.710
sequentially and on the right you see
 

00:24:16.710 --> 00:24:18.380
sequentially and on the right you see
the vector loop that actually goes by

00:24:18.380 --> 00:24:18.390
the vector loop that actually goes by
 

00:24:18.390 --> 00:24:21.470
the vector loop that actually goes by
for and in order to do this

00:24:21.470 --> 00:24:21.480
for and in order to do this
 

00:24:21.480 --> 00:24:23.900
for and in order to do this
transformation this vectorization you

00:24:23.900 --> 00:24:23.910
transformation this vectorization you
 

00:24:23.910 --> 00:24:26.390
transformation this vectorization you
need somes very specific analysis you

00:24:26.390 --> 00:24:26.400
need somes very specific analysis you
 

00:24:26.400 --> 00:24:28.070
need somes very specific analysis you
have to detect and resolve memory

00:24:28.070 --> 00:24:28.080
have to detect and resolve memory
 

00:24:28.080 --> 00:24:30.230
have to detect and resolve memory
conflicts between the loop iterations to

00:24:30.230 --> 00:24:30.240
conflicts between the loop iterations to
 

00:24:30.240 --> 00:24:32.180
conflicts between the loop iterations to
see if you can actually execute them in

00:24:32.180 --> 00:24:32.190
see if you can actually execute them in
 

00:24:32.190 --> 00:24:34.280
see if you can actually execute them in
parallel you may want to be a little bit

00:24:34.280 --> 00:24:34.290
parallel you may want to be a little bit
 

00:24:34.290 --> 00:24:35.990
parallel you may want to be a little bit
more strict about alignments because

00:24:35.990 --> 00:24:36.000
more strict about alignments because
 

00:24:36.000 --> 00:24:37.640
more strict about alignments because
seen the instructions often require

00:24:37.640 --> 00:24:37.650
seen the instructions often require
 

00:24:37.650 --> 00:24:41.990
seen the instructions often require
stricter alignments on the memory and

00:24:41.990 --> 00:24:42.000
stricter alignments on the memory and
 

00:24:42.000 --> 00:24:45.230
stricter alignments on the memory and
you want to detect idiomatic construct

00:24:45.230 --> 00:24:45.240
you want to detect idiomatic construct
 

00:24:45.240 --> 00:24:46.700
you want to detect idiomatic construct
you'll see an example of that shortly

00:24:46.700 --> 00:24:46.710
you'll see an example of that shortly
 

00:24:46.710 --> 00:24:48.860
you'll see an example of that shortly
stuff that you cannot really express

00:24:48.860 --> 00:24:48.870
stuff that you cannot really express
 

00:24:48.870 --> 00:24:50.930
stuff that you cannot really express
with single operators in your sequential

00:24:50.930 --> 00:24:50.940
with single operators in your sequential
 

00:24:50.940 --> 00:24:53.210
with single operators in your sequential
codes but if you detect them you can map

00:24:53.210 --> 00:24:53.220
codes but if you detect them you can map
 

00:24:53.220 --> 00:24:54.980
codes but if you detect them you can map
them onto very efficient sim the

00:24:54.980 --> 00:24:54.990
them onto very efficient sim the
 

00:24:54.990 --> 00:25:00.919
them onto very efficient sim the
instructions so let's just explore this

00:25:00.919 --> 00:25:00.929
instructions so let's just explore this
 

00:25:00.929 --> 00:25:02.770
instructions so let's just explore this
whole factorization with a case study

00:25:02.770 --> 00:25:02.780
whole factorization with a case study
 

00:25:02.780 --> 00:25:05.810
whole factorization with a case study
suppose they keep on a like display a

00:25:05.810 --> 00:25:05.820
suppose they keep on a like display a
 

00:25:05.820 --> 00:25:07.549
suppose they keep on a like display a
string of pictures like these paintings

00:25:07.549 --> 00:25:07.559
string of pictures like these paintings
 

00:25:07.559 --> 00:25:10.100
string of pictures like these paintings
here on the graph on your display and

00:25:10.100 --> 00:25:10.110
here on the graph on your display and
 

00:25:10.110 --> 00:25:12.799
here on the graph on your display and
you want to transition smoothly from one

00:25:12.799 --> 00:25:12.809
you want to transition smoothly from one
 

00:25:12.809 --> 00:25:14.600
you want to transition smoothly from one
picture to the other you don't want to

00:25:14.600 --> 00:25:14.610
picture to the other you don't want to
 

00:25:14.610 --> 00:25:16.640
picture to the other you don't want to
just show one and on the other you want

00:25:16.640 --> 00:25:16.650
just show one and on the other you want
 

00:25:16.650 --> 00:25:18.169
just show one and on the other you want
to sort of have a transition in the tree

00:25:18.169 --> 00:25:18.179
to sort of have a transition in the tree
 

00:25:18.179 --> 00:25:20.390
to sort of have a transition in the tree
and you want to do that real time you

00:25:20.390 --> 00:25:20.400
and you want to do that real time you
 

00:25:20.400 --> 00:25:22.340
and you want to do that real time you
don't know the stream in advance and of

00:25:22.340 --> 00:25:22.350
don't know the stream in advance and of
 

00:25:22.350 --> 00:25:23.900
don't know the stream in advance and of
course you want to do it in an efficient

00:25:23.900 --> 00:25:23.910
course you want to do it in an efficient
 

00:25:23.910 --> 00:25:28.760
course you want to do it in an efficient
way so one way to get a smooth

00:25:28.760 --> 00:25:28.770
way so one way to get a smooth
 

00:25:28.770 --> 00:25:30.530
way so one way to get a smooth
transition is actually performing a

00:25:30.530 --> 00:25:30.540
transition is actually performing a
 

00:25:30.540 --> 00:25:33.110
transition is actually performing a
crossfade so what you do is it's called

00:25:33.110 --> 00:25:33.120
crossfade so what you do is it's called
 

00:25:33.120 --> 00:25:35.539
crossfade so what you do is it's called
rounding housing act so basically you

00:25:35.539 --> 00:25:35.549
rounding housing act so basically you
 

00:25:35.549 --> 00:25:38.000
rounding housing act so basically you
take the average of two pictures and you

00:25:38.000 --> 00:25:38.010
take the average of two pictures and you
 

00:25:38.010 --> 00:25:40.310
take the average of two pictures and you
showed it in between the two pictures so

00:25:40.310 --> 00:25:40.320
showed it in between the two pictures so
 

00:25:40.320 --> 00:25:43.130
showed it in between the two pictures so
the example here you see the shipwreck

00:25:43.130 --> 00:25:43.140
the example here you see the shipwreck
 

00:25:43.140 --> 00:25:46.370
the example here you see the shipwreck
on the bar on the top and the quiet fire

00:25:46.370 --> 00:25:46.380
on the bar on the top and the quiet fire
 

00:25:46.380 --> 00:25:48.530
on the bar on the top and the quiet fire
on the bottom and the picture that you

00:25:48.530 --> 00:25:48.540
on the bottom and the picture that you
 

00:25:48.540 --> 00:25:50.840
on the bottom and the picture that you
show in-between will sort of be an

00:25:50.840 --> 00:25:50.850
show in-between will sort of be an
 

00:25:50.850 --> 00:25:52.760
show in-between will sort of be an
average of the two pictures showing them

00:25:52.760 --> 00:25:52.770
average of the two pictures showing them
 

00:25:52.770 --> 00:25:55.430
average of the two pictures showing them
at the same time it forms a nice smooth

00:25:55.430 --> 00:25:55.440
at the same time it forms a nice smooth
 

00:25:55.440 --> 00:25:58.159
at the same time it forms a nice smooth
transition so how do you code it and you

00:25:58.159 --> 00:25:58.169
transition so how do you code it and you
 

00:25:58.169 --> 00:25:59.930
transition so how do you code it and you
don't want to go to a native solution

00:25:59.930 --> 00:25:59.940
don't want to go to a native solution
 

00:25:59.940 --> 00:26:01.640
don't want to go to a native solution
you want to don't want to use the NDK

00:26:01.640 --> 00:26:01.650
you want to don't want to use the NDK
 

00:26:01.650 --> 00:26:03.770
you want to don't want to use the NDK
you don't want to use GPU code you just

00:26:03.770 --> 00:26:03.780
you don't want to use GPU code you just
 

00:26:03.780 --> 00:26:08.529
you don't want to use GPU code you just
want to stay at source level

00:26:08.529 --> 00:26:08.539
 

00:26:08.539 --> 00:26:11.199
so here you see a method that could do

00:26:11.199 --> 00:26:11.209
so here you see a method that could do
 

00:26:11.209 --> 00:26:13.419
so here you see a method that could do
such a crossfade so you have two

00:26:13.419 --> 00:26:13.429
such a crossfade so you have two
 

00:26:13.429 --> 00:26:15.849
such a crossfade so you have two
incoming byte arrays which represented

00:26:15.849 --> 00:26:15.859
incoming byte arrays which represented
 

00:26:15.859 --> 00:26:19.569
incoming byte arrays which represented
pictures X 1 and X 2 and you go for like

00:26:19.569 --> 00:26:19.579
pictures X 1 and X 2 and you go for like
 

00:26:19.579 --> 00:26:22.269
pictures X 1 and X 2 and you go for like
an 0 extension and an averaging

00:26:22.269 --> 00:26:22.279
an 0 extension and an averaging
 

00:26:22.279 --> 00:26:24.699
an 0 extension and an averaging
operation and then you computes the X

00:26:24.699 --> 00:26:24.709
operation and then you computes the X
 

00:26:24.709 --> 00:26:28.569
operation and then you computes the X
out so keeping this at source level is

00:26:28.569 --> 00:26:28.579
out so keeping this at source level is
 

00:26:28.579 --> 00:26:30.909
out so keeping this at source level is
of course a much easier way of

00:26:30.909 --> 00:26:30.919
of course a much easier way of
 

00:26:30.919 --> 00:26:33.159
of course a much easier way of
expressing such an algorithm it's easy

00:26:33.159 --> 00:26:33.169
expressing such an algorithm it's easy
 

00:26:33.169 --> 00:26:35.589
expressing such an algorithm it's easy
to write as debug maintain etc you don't

00:26:35.589 --> 00:26:35.599
to write as debug maintain etc you don't
 

00:26:35.599 --> 00:26:38.139
to write as debug maintain etc you don't
have to use the the NDK you don't have

00:26:38.139 --> 00:26:38.149
have to use the the NDK you don't have
 

00:26:38.149 --> 00:26:45.430
have to use the the NDK you don't have
to use GPU counts so Android n will

00:26:45.430 --> 00:26:45.440
to use GPU counts so Android n will
 

00:26:45.440 --> 00:26:47.829
to use GPU counts so Android n will
actually translate the loop that I just

00:26:47.829 --> 00:26:47.839
actually translate the loop that I just
 

00:26:47.839 --> 00:26:49.449
actually translate the loop that I just
showed to the sequential code on the

00:26:49.449 --> 00:26:49.459
showed to the sequential code on the
 

00:26:49.459 --> 00:26:52.869
showed to the sequential code on the
left and Android all will now generate

00:26:52.869 --> 00:26:52.879
left and Android all will now generate
 

00:26:52.879 --> 00:26:55.059
left and Android all will now generate
the simply called shown on the right and

00:26:55.059 --> 00:26:55.069
the simply called shown on the right and
 

00:26:55.069 --> 00:26:57.249
the simply called shown on the right and
I don't expect you to dress this whole

00:26:57.249 --> 00:26:57.259
I don't expect you to dress this whole
 

00:26:57.259 --> 00:26:59.229
I don't expect you to dress this whole
assembly right away but just focus on

00:26:59.229 --> 00:26:59.239
assembly right away but just focus on
 

00:26:59.239 --> 00:27:01.869
assembly right away but just focus on
the parts that have been highlighted so

00:27:01.869 --> 00:27:01.879
the parts that have been highlighted so
 

00:27:01.879 --> 00:27:04.239
the parts that have been highlighted so
first of all in orange you see that the

00:27:04.239 --> 00:27:04.249
first of all in orange you see that the
 

00:27:04.249 --> 00:27:07.779
first of all in orange you see that the
sequential loop goes by one it does one

00:27:07.779 --> 00:27:07.789
sequential loop goes by one it does one
 

00:27:07.789 --> 00:27:09.969
sequential loop goes by one it does one
byte at a time before it goes to the

00:27:09.969 --> 00:27:09.979
byte at a time before it goes to the
 

00:27:09.979 --> 00:27:10.599
byte at a time before it goes to the
other one

00:27:10.599 --> 00:27:10.609
other one
 

00:27:10.609 --> 00:27:14.709
other one
in contrast the same decode goes by 16

00:27:14.709 --> 00:27:14.719
in contrast the same decode goes by 16
 

00:27:14.719 --> 00:27:18.639
in contrast the same decode goes by 16
it does 16 bytes at the same time the

00:27:18.639 --> 00:27:18.649
it does 16 bytes at the same time the
 

00:27:18.649 --> 00:27:19.930
it does 16 bytes at the same time the
other thing that you notice is that the

00:27:19.930 --> 00:27:19.940
other thing that you notice is that the
 

00:27:19.940 --> 00:27:22.959
other thing that you notice is that the
loop body is a lot shorter for the same

00:27:22.959 --> 00:27:22.969
loop body is a lot shorter for the same
 

00:27:22.969 --> 00:27:25.959
loop body is a lot shorter for the same
decode and that's a result of the yellow

00:27:25.959 --> 00:27:25.969
decode and that's a result of the yellow
 

00:27:25.969 --> 00:27:28.479
decode and that's a result of the yellow
highlighted instructions on the left

00:27:28.479 --> 00:27:28.489
highlighted instructions on the left
 

00:27:28.489 --> 00:27:30.489
highlighted instructions on the left
there's a lot of instructions required

00:27:30.489 --> 00:27:30.499
there's a lot of instructions required
 

00:27:30.499 --> 00:27:32.379
there's a lot of instructions required
to do the zero extension and the

00:27:32.379 --> 00:27:32.389
to do the zero extension and the
 

00:27:32.389 --> 00:27:35.199
to do the zero extension and the
rounding housing and on the right

00:27:35.199 --> 00:27:35.209
rounding housing and on the right
 

00:27:35.209 --> 00:27:37.479
rounding housing and on the right
there's a singles idiomatic instruction

00:27:37.479 --> 00:27:37.489
there's a singles idiomatic instruction
 

00:27:37.489 --> 00:27:40.629
there's a singles idiomatic instruction
that can takes care of that so all this

00:27:40.629 --> 00:27:40.639
that can takes care of that so all this
 

00:27:40.639 --> 00:27:44.769
that can takes care of that so all this
combined makes sure that the loop runs

00:27:44.769 --> 00:27:44.779
combined makes sure that the loop runs
 

00:27:44.779 --> 00:27:47.889
combined makes sure that the loop runs
about 10 times faster if you just look

00:27:47.889 --> 00:27:47.899
about 10 times faster if you just look
 

00:27:47.899 --> 00:27:53.859
about 10 times faster if you just look
at the loop however if you look at the

00:27:53.859 --> 00:27:53.869
at the loop however if you look at the
 

00:27:53.869 --> 00:27:55.869
at the loop however if you look at the
real application where this loop is

00:27:55.869 --> 00:27:55.879
real application where this loop is
 

00:27:55.879 --> 00:27:58.029
real application where this loop is
actually part of a larger thing where

00:27:58.029 --> 00:27:58.039
actually part of a larger thing where
 

00:27:58.039 --> 00:27:59.859
actually part of a larger thing where
there's a like a handler requesting new

00:27:59.859 --> 00:27:59.869
there's a like a handler requesting new
 

00:27:59.869 --> 00:28:01.989
there's a like a handler requesting new
pictures etc you can see that

00:28:01.989 --> 00:28:01.999
pictures etc you can see that
 

00:28:01.999 --> 00:28:03.639
pictures etc you can see that
vectorization made the difference

00:28:03.639 --> 00:28:03.649
vectorization made the difference
 

00:28:03.649 --> 00:28:06.279
vectorization made the difference
between rendering at a slow 20 frames

00:28:06.279 --> 00:28:06.289
between rendering at a slow 20 frames
 

00:28:06.289 --> 00:28:09.729
between rendering at a slow 20 frames
per seconds and the fact of the

00:28:09.729 --> 00:28:09.739
per seconds and the fact of the
 

00:28:09.739 --> 00:28:11.709
per seconds and the fact of the
factorization we vendor at 60 frames per

00:28:11.709 --> 00:28:11.719
factorization we vendor at 60 frames per
 

00:28:11.719 --> 00:28:13.839
factorization we vendor at 60 frames per
second and that's actually as fast as

00:28:13.839 --> 00:28:13.849
second and that's actually as fast as
 

00:28:13.849 --> 00:28:16.059
second and that's actually as fast as
you can go like you cannot render much

00:28:16.059 --> 00:28:16.069
you can go like you cannot render much
 

00:28:16.069 --> 00:28:18.249
you can go like you cannot render much
faster so that really shows that

00:28:18.249 --> 00:28:18.259
faster so that really shows that
 

00:28:18.259 --> 00:28:20.589
faster so that really shows that
factorization has given you the power to

00:28:20.589 --> 00:28:20.599
factorization has given you the power to
 

00:28:20.599 --> 00:28:22.280
factorization has given you the power to
render at a very acceptable

00:28:22.280 --> 00:28:22.290
render at a very acceptable
 

00:28:22.290 --> 00:28:24.650
render at a very acceptable
and you actually have CPU cycles to

00:28:24.650 --> 00:28:24.660
and you actually have CPU cycles to
 

00:28:24.660 --> 00:28:26.630
and you actually have CPU cycles to
spare because it doesn't need the full

00:28:26.630 --> 00:28:26.640
spare because it doesn't need the full
 

00:28:26.640 --> 00:28:28.940
spare because it doesn't need the full
power to go to the 60 frames per second

00:28:28.940 --> 00:28:28.950
power to go to the 60 frames per second
 

00:28:28.950 --> 00:28:32.300
power to go to the 60 frames per second
and all this was made possible by the

00:28:32.300 --> 00:28:32.310
and all this was made possible by the
 

00:28:32.310 --> 00:28:34.970
and all this was made possible by the
vectorization you don't need to write

00:28:34.970 --> 00:28:34.980
vectorization you don't need to write
 

00:28:34.980 --> 00:28:38.600
vectorization you don't need to write
like T DS NDK code anymore you can just

00:28:38.600 --> 00:28:38.610
like T DS NDK code anymore you can just
 

00:28:38.610 --> 00:28:43.490
like T DS NDK code anymore you can just
Express the loop at source platform

00:28:43.490 --> 00:28:43.500
 

00:28:43.500 --> 00:28:57.429
[Music]

