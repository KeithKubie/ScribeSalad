WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.389
in the previous video you saw how you

00:00:02.389 --> 00:00:02.399
in the previous video you saw how you
 

00:00:02.399 --> 00:00:04.730
in the previous video you saw how you
can get a neural network to output for

00:00:04.730 --> 00:00:04.740
can get a neural network to output for
 

00:00:04.740 --> 00:00:08.780
can get a neural network to output for
numbers P X py BH + BW to specify the

00:00:08.780 --> 00:00:08.790
numbers P X py BH + BW to specify the
 

00:00:08.790 --> 00:00:11.089
numbers P X py BH + BW to specify the
bounding box of an object you want in

00:00:11.089 --> 00:00:11.099
bounding box of an object you want in
 

00:00:11.099 --> 00:00:14.089
bounding box of an object you want in
your network to localize in more general

00:00:14.089 --> 00:00:14.099
your network to localize in more general
 

00:00:14.099 --> 00:00:16.039
your network to localize in more general
cases you can have a neural network just

00:00:16.039 --> 00:00:16.049
cases you can have a neural network just
 

00:00:16.049 --> 00:00:19.490
cases you can have a neural network just
output X and y coordinates of important

00:00:19.490 --> 00:00:19.500
output X and y coordinates of important
 

00:00:19.500 --> 00:00:21.500
output X and y coordinates of important
points in image sometimes called

00:00:21.500 --> 00:00:21.510
points in image sometimes called
 

00:00:21.510 --> 00:00:23.660
points in image sometimes called
landmarks they want the neural network

00:00:23.660 --> 00:00:23.670
landmarks they want the neural network
 

00:00:23.670 --> 00:00:25.670
landmarks they want the neural network
to recognize let me show you a few

00:00:25.670 --> 00:00:25.680
to recognize let me show you a few
 

00:00:25.680 --> 00:00:27.830
to recognize let me show you a few
examples let's say you're building a

00:00:27.830 --> 00:00:27.840
examples let's say you're building a
 

00:00:27.840 --> 00:00:30.470
examples let's say you're building a
face recognition application and for

00:00:30.470 --> 00:00:30.480
face recognition application and for
 

00:00:30.480 --> 00:00:32.209
face recognition application and for
some reason you want the algorithm to

00:00:32.209 --> 00:00:32.219
some reason you want the algorithm to
 

00:00:32.219 --> 00:00:35.120
some reason you want the algorithm to
tell you where is the corner of

00:00:35.120 --> 00:00:35.130
tell you where is the corner of
 

00:00:35.130 --> 00:00:39.290
tell you where is the corner of
someone's eye so that point has an x and

00:00:39.290 --> 00:00:39.300
someone's eye so that point has an x and
 

00:00:39.300 --> 00:00:41.959
someone's eye so that point has an x and
y coordinate so you can just have a

00:00:41.959 --> 00:00:41.969
y coordinate so you can just have a
 

00:00:41.969 --> 00:00:44.180
y coordinate so you can just have a
neural network have is you know final

00:00:44.180 --> 00:00:44.190
neural network have is you know final
 

00:00:44.190 --> 00:00:47.360
neural network have is you know final
layer and have it just output two more

00:00:47.360 --> 00:00:47.370
layer and have it just output two more
 

00:00:47.370 --> 00:00:50.150
layer and have it just output two more
numbers which I'm gonna call our X and

00:00:50.150 --> 00:00:50.160
numbers which I'm gonna call our X and
 

00:00:50.160 --> 00:00:53.330
numbers which I'm gonna call our X and
our Y to just tell you the coordinates

00:00:53.330 --> 00:00:53.340
our Y to just tell you the coordinates
 

00:00:53.340 --> 00:00:56.840
our Y to just tell you the coordinates
of that corner of the person's eye now

00:00:56.840 --> 00:00:56.850
of that corner of the person's eye now
 

00:00:56.850 --> 00:00:59.299
of that corner of the person's eye now
what if you wanted to tell you you know

00:00:59.299 --> 00:00:59.309
what if you wanted to tell you you know
 

00:00:59.309 --> 00:01:02.150
what if you wanted to tell you you know
all four corners of the eye are really

00:01:02.150 --> 00:01:02.160
all four corners of the eye are really
 

00:01:02.160 --> 00:01:05.329
all four corners of the eye are really
of both eyes so if we call the points

00:01:05.329 --> 00:01:05.339
of both eyes so if we call the points
 

00:01:05.339 --> 00:01:07.370
of both eyes so if we call the points
the first second third and four points

00:01:07.370 --> 00:01:07.380
the first second third and four points
 

00:01:07.380 --> 00:01:09.200
the first second third and four points
going from left to right then you can

00:01:09.200 --> 00:01:09.210
going from left to right then you can
 

00:01:09.210 --> 00:01:12.010
going from left to right then you can
modify the neural network now to output

00:01:12.010 --> 00:01:12.020
modify the neural network now to output
 

00:01:12.020 --> 00:01:17.109
modify the neural network now to output
l1 X 1 Y for the first point and l2 X

00:01:17.109 --> 00:01:17.119
l1 X 1 Y for the first point and l2 X
 

00:01:17.119 --> 00:01:22.399
l1 X 1 Y for the first point and l2 X
two Y for the second point and so on so

00:01:22.399 --> 00:01:22.409
two Y for the second point and so on so
 

00:01:22.409 --> 00:01:25.399
two Y for the second point and so on so
that the neural network can output the

00:01:25.399 --> 00:01:25.409
that the neural network can output the
 

00:01:25.409 --> 00:01:27.109
that the neural network can output the
estimated position of all those four

00:01:27.109 --> 00:01:27.119
estimated position of all those four
 

00:01:27.119 --> 00:01:30.020
estimated position of all those four
points of the person's face but what if

00:01:30.020 --> 00:01:30.030
points of the person's face but what if
 

00:01:30.030 --> 00:01:31.490
points of the person's face but what if
you don't want just those four points

00:01:31.490 --> 00:01:31.500
you don't want just those four points
 

00:01:31.500 --> 00:01:33.080
you don't want just those four points
what do you want to output at this point

00:01:33.080 --> 00:01:33.090
what do you want to output at this point
 

00:01:33.090 --> 00:01:34.789
what do you want to output at this point
at this point at this point at this

00:01:34.789 --> 00:01:34.799
at this point at this point at this
 

00:01:34.799 --> 00:01:37.310
at this point at this point at this
point you know along the eye maybe

00:01:37.310 --> 00:01:37.320
point you know along the eye maybe
 

00:01:37.320 --> 00:01:39.770
point you know along the eye maybe
output some key points along the mouth

00:01:39.770 --> 00:01:39.780
output some key points along the mouth
 

00:01:39.780 --> 00:01:41.960
output some key points along the mouth
so you can extract the mouth shape and

00:01:41.960 --> 00:01:41.970
so you can extract the mouth shape and
 

00:01:41.970 --> 00:01:43.969
so you can extract the mouth shape and
tell the person is smiling or frowning

00:01:43.969 --> 00:01:43.979
tell the person is smiling or frowning
 

00:01:43.979 --> 00:01:46.880
tell the person is smiling or frowning
maybe extract a few key points along the

00:01:46.880 --> 00:01:46.890
maybe extract a few key points along the
 

00:01:46.890 --> 00:01:49.190
maybe extract a few key points along the
edges of the nose but you could define

00:01:49.190 --> 00:01:49.200
edges of the nose but you could define
 

00:01:49.200 --> 00:01:51.020
edges of the nose but you could define
some number for the sake of argument

00:01:51.020 --> 00:01:51.030
some number for the sake of argument
 

00:01:51.030 --> 00:01:55.670
some number for the sake of argument
let's say 64 points or 64 landmarks on

00:01:55.670 --> 00:01:55.680
let's say 64 points or 64 landmarks on
 

00:01:55.680 --> 00:01:59.120
let's say 64 points or 64 landmarks on
the face maybe even some points you know

00:01:59.120 --> 00:01:59.130
the face maybe even some points you know
 

00:01:59.130 --> 00:02:01.370
the face maybe even some points you know
that helps you define the edge of the

00:02:01.370 --> 00:02:01.380
that helps you define the edge of the
 

00:02:01.380 --> 00:02:04.310
that helps you define the edge of the
face it defines the jawline but by

00:02:04.310 --> 00:02:04.320
face it defines the jawline but by
 

00:02:04.320 --> 00:02:06.520
face it defines the jawline but by
selecting a number of landmarks and

00:02:06.520 --> 00:02:06.530
selecting a number of landmarks and
 

00:02:06.530 --> 00:02:09.350
selecting a number of landmarks and
generating a label training set that

00:02:09.350 --> 00:02:09.360
generating a label training set that
 

00:02:09.360 --> 00:02:11.869
generating a label training set that
contains all of these landmarks you can

00:02:11.869 --> 00:02:11.879
contains all of these landmarks you can
 

00:02:11.879 --> 00:02:12.510
contains all of these landmarks you can
then have the

00:02:12.510 --> 00:02:12.520
then have the
 

00:02:12.520 --> 00:02:14.790
then have the
network will tell you where are all the

00:02:14.790 --> 00:02:14.800
network will tell you where are all the
 

00:02:14.800 --> 00:02:17.910
network will tell you where are all the
key positions or the key landmarks on a

00:02:17.910 --> 00:02:17.920
key positions or the key landmarks on a
 

00:02:17.920 --> 00:02:20.490
key positions or the key landmarks on a
face so what you do is you have this

00:02:20.490 --> 00:02:20.500
face so what you do is you have this
 

00:02:20.500 --> 00:02:24.390
face so what you do is you have this
image person's face as input have it go

00:02:24.390 --> 00:02:24.400
image person's face as input have it go
 

00:02:24.400 --> 00:02:28.110
image person's face as input have it go
through a confident and have a confident

00:02:28.110 --> 00:02:28.120
through a confident and have a confident
 

00:02:28.120 --> 00:02:32.550
through a confident and have a confident
then have some set of features maybe

00:02:32.550 --> 00:02:32.560
then have some set of features maybe
 

00:02:32.560 --> 00:02:34.890
then have some set of features maybe
have it output zero or one like is there

00:02:34.890 --> 00:02:34.900
have it output zero or one like is there
 

00:02:34.900 --> 00:02:36.720
have it output zero or one like is there
a face in this or not and then have it

00:02:36.720 --> 00:02:36.730
a face in this or not and then have it
 

00:02:36.730 --> 00:02:45.890
a face in this or not and then have it
also output o1x l1y and so on down to no

00:02:45.890 --> 00:02:45.900
also output o1x l1y and so on down to no
 

00:02:45.900 --> 00:02:50.430
also output o1x l1y and so on down to no
64x64 why and here I'm using L to stand

00:02:50.430 --> 00:02:50.440
64x64 why and here I'm using L to stand
 

00:02:50.440 --> 00:02:53.490
64x64 why and here I'm using L to stand
for a landmark so this example would

00:02:53.490 --> 00:02:53.500
for a landmark so this example would
 

00:02:53.500 --> 00:03:01.020
for a landmark so this example would
have 129 output units 1 4 is where a

00:03:01.020 --> 00:03:01.030
have 129 output units 1 4 is where a
 

00:03:01.030 --> 00:03:03.150
have 129 output units 1 4 is where a
face or not and then if you have 64

00:03:03.150 --> 00:03:03.160
face or not and then if you have 64
 

00:03:03.160 --> 00:03:07.680
face or not and then if you have 64
landmark stats 64 times 2 so 128 plus 1

00:03:07.680 --> 00:03:07.690
landmark stats 64 times 2 so 128 plus 1
 

00:03:07.690 --> 00:03:10.830
landmark stats 64 times 2 so 128 plus 1
output units and this can tell you if

00:03:10.830 --> 00:03:10.840
output units and this can tell you if
 

00:03:10.840 --> 00:03:12.450
output units and this can tell you if
there's a face as well as where all the

00:03:12.450 --> 00:03:12.460
there's a face as well as where all the
 

00:03:12.460 --> 00:03:15.270
there's a face as well as where all the
key landmarks on the face so you know

00:03:15.270 --> 00:03:15.280
key landmarks on the face so you know
 

00:03:15.280 --> 00:03:18.230
key landmarks on the face so you know
this is a basic building block for

00:03:18.230 --> 00:03:18.240
this is a basic building block for
 

00:03:18.240 --> 00:03:21.390
this is a basic building block for
recognizing emotions from faces and if

00:03:21.390 --> 00:03:21.400
recognizing emotions from faces and if
 

00:03:21.400 --> 00:03:23.760
recognizing emotions from faces and if
you played with the snapchat and the

00:03:23.760 --> 00:03:23.770
you played with the snapchat and the
 

00:03:23.770 --> 00:03:26.010
you played with the snapchat and the
other entertainment you know self AR

00:03:26.010 --> 00:03:26.020
other entertainment you know self AR
 

00:03:26.020 --> 00:03:28.680
other entertainment you know self AR
augmented reality filter so if the

00:03:28.680 --> 00:03:28.690
augmented reality filter so if the
 

00:03:28.690 --> 00:03:31.320
augmented reality filter so if the
snapchat filters can only draw a crown

00:03:31.320 --> 00:03:31.330
snapchat filters can only draw a crown
 

00:03:31.330 --> 00:03:32.880
snapchat filters can only draw a crown
on the face and have other special

00:03:32.880 --> 00:03:32.890
on the face and have other special
 

00:03:32.890 --> 00:03:35.130
on the face and have other special
effects being able to detect these

00:03:35.130 --> 00:03:35.140
effects being able to detect these
 

00:03:35.140 --> 00:03:38.190
effects being able to detect these
landmarks on the face is also a key

00:03:38.190 --> 00:03:38.200
landmarks on the face is also a key
 

00:03:38.200 --> 00:03:40.290
landmarks on the face is also a key
building block for the computer graphics

00:03:40.290 --> 00:03:40.300
building block for the computer graphics
 

00:03:40.300 --> 00:03:42.900
building block for the computer graphics
effects that warp the face or draw on

00:03:42.900 --> 00:03:42.910
effects that warp the face or draw on
 

00:03:42.910 --> 00:03:44.880
effects that warp the face or draw on
various special effects like for the

00:03:44.880 --> 00:03:44.890
various special effects like for the
 

00:03:44.890 --> 00:03:48.540
various special effects like for the
crown of our hats on a person of course

00:03:48.540 --> 00:03:48.550
crown of our hats on a person of course
 

00:03:48.550 --> 00:03:50.220
crown of our hats on a person of course
in order to trade a network like this

00:03:50.220 --> 00:03:50.230
in order to trade a network like this
 

00:03:50.230 --> 00:03:53.100
in order to trade a network like this
you will need a label training set we

00:03:53.100 --> 00:03:53.110
you will need a label training set we
 

00:03:53.110 --> 00:03:56.070
you will need a label training set we
have a set of images as well as labels Y

00:03:56.070 --> 00:03:56.080
have a set of images as well as labels Y
 

00:03:56.080 --> 00:03:58.980
have a set of images as well as labels Y
where people where someone would have

00:03:58.980 --> 00:03:58.990
where people where someone would have
 

00:03:58.990 --> 00:04:01.020
where people where someone would have
had to go through and laborious ly

00:04:01.020 --> 00:04:01.030
had to go through and laborious ly
 

00:04:01.030 --> 00:04:06.360
had to go through and laborious ly
annotate all of these landmarks one last

00:04:06.360 --> 00:04:06.370
annotate all of these landmarks one last
 

00:04:06.370 --> 00:04:10.440
annotate all of these landmarks one last
example if you are interested in people

00:04:10.440 --> 00:04:10.450
example if you are interested in people
 

00:04:10.450 --> 00:04:13.140
example if you are interested in people
post-detection you could also define a

00:04:13.140 --> 00:04:13.150
post-detection you could also define a
 

00:04:13.150 --> 00:04:16.650
post-detection you could also define a
few key positions like the midpoint of

00:04:16.650 --> 00:04:16.660
few key positions like the midpoint of
 

00:04:16.660 --> 00:04:18.900
few key positions like the midpoint of
the chest that should the left shoulder

00:04:18.900 --> 00:04:18.910
the chest that should the left shoulder
 

00:04:18.910 --> 00:04:22.890
the chest that should the left shoulder
left elbow the wrist and so on and just

00:04:22.890 --> 00:04:22.900
left elbow the wrist and so on and just
 

00:04:22.900 --> 00:04:25.159
left elbow the wrist and so on and just
have a neural network you know

00:04:25.159 --> 00:04:25.169
have a neural network you know
 

00:04:25.169 --> 00:04:30.260
have a neural network you know
annotate key positions in the person's

00:04:30.260 --> 00:04:30.270
annotate key positions in the person's
 

00:04:30.270 --> 00:04:32.659
annotate key positions in the person's
pose as well and by having a neural

00:04:32.659 --> 00:04:32.669
pose as well and by having a neural
 

00:04:32.669 --> 00:04:35.659
pose as well and by having a neural
network output all of those points down

00:04:35.659 --> 00:04:35.669
network output all of those points down
 

00:04:35.669 --> 00:04:38.540
network output all of those points down
annotating you could also have the

00:04:38.540 --> 00:04:38.550
annotating you could also have the
 

00:04:38.550 --> 00:04:41.480
annotating you could also have the
neural network output the pose of the

00:04:41.480 --> 00:04:41.490
neural network output the pose of the
 

00:04:41.490 --> 00:04:44.809
neural network output the pose of the
person and of course to do that you also

00:04:44.809 --> 00:04:44.819
person and of course to do that you also
 

00:04:44.819 --> 00:04:48.589
person and of course to do that you also
need to specify on these key landmarks

00:04:48.589 --> 00:04:48.599
need to specify on these key landmarks
 

00:04:48.599 --> 00:04:51.230
need to specify on these key landmarks
which may be l1 X and l1 Y is the

00:04:51.230 --> 00:04:51.240
which may be l1 X and l1 Y is the
 

00:04:51.240 --> 00:04:53.739
which may be l1 X and l1 Y is the
midpoint of the chest down to maybe oh

00:04:53.739 --> 00:04:53.749
midpoint of the chest down to maybe oh
 

00:04:53.749 --> 00:04:55.670
midpoint of the chest down to maybe oh
32 X Oh

00:04:55.670 --> 00:04:55.680
32 X Oh
 

00:04:55.680 --> 00:04:59.209
32 X Oh
32 Y if you study two coordinates to

00:04:59.209 --> 00:04:59.219
32 Y if you study two coordinates to
 

00:04:59.219 --> 00:05:02.360
32 Y if you study two coordinates to
specify the pose of the person so this

00:05:02.360 --> 00:05:02.370
specify the pose of the person so this
 

00:05:02.370 --> 00:05:04.580
specify the pose of the person so this
idea it might seem quite simple of just

00:05:04.580 --> 00:05:04.590
idea it might seem quite simple of just
 

00:05:04.590 --> 00:05:07.399
idea it might seem quite simple of just
adding a bunch of output units to output

00:05:07.399 --> 00:05:07.409
adding a bunch of output units to output
 

00:05:07.409 --> 00:05:09.619
adding a bunch of output units to output
the XY coordinates of different

00:05:09.619 --> 00:05:09.629
the XY coordinates of different
 

00:05:09.629 --> 00:05:12.980
the XY coordinates of different
landmarks you want to recognize to be

00:05:12.980 --> 00:05:12.990
landmarks you want to recognize to be
 

00:05:12.990 --> 00:05:16.100
landmarks you want to recognize to be
clear the identity of landmark one must

00:05:16.100 --> 00:05:16.110
clear the identity of landmark one must
 

00:05:16.110 --> 00:05:18.019
clear the identity of landmark one must
be consistent across different images

00:05:18.019 --> 00:05:18.029
be consistent across different images
 

00:05:18.029 --> 00:05:19.999
be consistent across different images
like maybe landmark one is always this

00:05:19.999 --> 00:05:20.009
like maybe landmark one is always this
 

00:05:20.009 --> 00:05:20.749
like maybe landmark one is always this
corner of the eye

00:05:20.749 --> 00:05:20.759
corner of the eye
 

00:05:20.759 --> 00:05:22.820
corner of the eye
Lima 2 is always this corner of the eye

00:05:22.820 --> 00:05:22.830
Lima 2 is always this corner of the eye
 

00:05:22.830 --> 00:05:26.059
Lima 2 is always this corner of the eye
lamech 3 landmark 4 and so on so the

00:05:26.059 --> 00:05:26.069
lamech 3 landmark 4 and so on so the
 

00:05:26.069 --> 00:05:28.040
lamech 3 landmark 4 and so on so the
labels have to be consistent across

00:05:28.040 --> 00:05:28.050
labels have to be consistent across
 

00:05:28.050 --> 00:05:30.829
labels have to be consistent across
different images but if you can hire

00:05:30.829 --> 00:05:30.839
different images but if you can hire
 

00:05:30.839 --> 00:05:32.779
different images but if you can hire
laborers or laborer yourself a big

00:05:32.779 --> 00:05:32.789
laborers or laborer yourself a big
 

00:05:32.789 --> 00:05:35.149
laborers or laborer yourself a big
enough data set to do this then a neural

00:05:35.149 --> 00:05:35.159
enough data set to do this then a neural
 

00:05:35.159 --> 00:05:37.279
enough data set to do this then a neural
network can output you know all of these

00:05:37.279 --> 00:05:37.289
network can output you know all of these
 

00:05:37.289 --> 00:05:40.339
network can output you know all of these
landmarks you shouldn't use to carry out

00:05:40.339 --> 00:05:40.349
landmarks you shouldn't use to carry out
 

00:05:40.349 --> 00:05:41.929
landmarks you shouldn't use to carry out
other interesting effects I just

00:05:41.929 --> 00:05:41.939
other interesting effects I just
 

00:05:41.939 --> 00:05:44.029
other interesting effects I just
estimate the posing person maybe try to

00:05:44.029 --> 00:05:44.039
estimate the posing person maybe try to
 

00:05:44.039 --> 00:05:46.219
estimate the posing person maybe try to
recognize someone's emotion from a

00:05:46.219 --> 00:05:46.229
recognize someone's emotion from a
 

00:05:46.229 --> 00:05:48.860
recognize someone's emotion from a
picture and so on so that's it for

00:05:48.860 --> 00:05:48.870
picture and so on so that's it for
 

00:05:48.870 --> 00:05:51.950
picture and so on so that's it for
landmark detection next let's take these

00:05:51.950 --> 00:05:51.960
landmark detection next let's take these
 

00:05:51.960 --> 00:05:53.839
landmark detection next let's take these
building blocks and use it to start

00:05:53.839 --> 00:05:53.849
building blocks and use it to start
 

00:05:53.849 --> 00:05:58.039
building blocks and use it to start
building up towards object detection

