WEBVTT
Kind: captions
Language: en

00:00:03.060 --> 00:00:06.440
Hi, I’m Adriene Hill, and Welcome back to
Crash Course, Statistics.

00:00:06.440 --> 00:00:10.530
To recap from last time, P-values tell us
how “rare” something is.

00:00:10.530 --> 00:00:15.719
So far, we’ve been using that information
to decide whether or not our hypotheses are

00:00:15.719 --> 00:00:20.230
reasonable, and using P-values to reject or
fail to reject an idea.

00:00:20.230 --> 00:00:24.740
Today, we’re going to explore p-values a
little more and talk about the logic of p-values

00:00:24.740 --> 00:00:26.420
and some of the problems that come up.

00:00:26.420 --> 00:00:35.480
INTRO

00:00:35.480 --> 00:00:40.480
Remember, to calculate a p-value, we first
assume that the null distribution is the true

00:00:40.480 --> 00:00:42.929
distribution our sample was taken from.

00:00:42.929 --> 00:00:49.000
Then we calculate how often we’d see a value that is at least as extreme as our observed value.

00:00:49.000 --> 00:00:54.840
So in probability terms, the p-value is the
probability of getting a sample as or more

00:00:54.850 --> 00:00:58.640
extreme than ours, given that the null hypothesis is true:

00:00:58.640 --> 00:01:03.109
So all the values that we see in the sampling distribution are means we could actually get

00:01:03.109 --> 00:01:04.830
if the null hypothesis was true.

00:01:04.830 --> 00:01:09.299
For example, let’s say the average cat weigh 10lbs (or 4.5 kg).

00:01:09.299 --> 00:01:13.360
We might want to calculate the probability
of getting a group of 30 randomly selected

00:01:13.360 --> 00:01:19.659
calico cats who have an average weight of
11 lbs (or 5 kg) if calico cats have the same

00:01:19.660 --> 00:01:22.260
average weight as the whole population of
cats.

00:01:22.260 --> 00:01:26.240
The first issue is if, in real life, there
is no connection between two things like fur

00:01:26.240 --> 00:01:30.880
color and weight --we still might get samples of calicos, mackerel tabbies, or tortoise

00:01:30.899 --> 00:01:35.930
shells that are different enough to cause
us to “reject” the null hypothesis that

00:01:35.930 --> 00:01:37.659
there is no difference.

00:01:37.659 --> 00:01:40.240
Our alpha tells us how often this will happen.

00:01:40.240 --> 00:01:44.770
Let’s say our hypothesis is that the reaction
time of older professional chess players is

00:01:44.770 --> 00:01:49.800
different from the reaction time of the general population of professional chess players.

00:01:49.800 --> 00:01:54.160
Even if older chess players are the same as
their colleagues, if we ran this study over

00:01:54.160 --> 00:02:00.960
and over, we’d expect that 5% of the time,
we’d mistakenly reject the null if it were true.

00:02:00.960 --> 00:02:05.900
This is one reason why p-values are pretty
controversial in the statistical community right now.

00:02:05.900 --> 00:02:12.280
Not everyone agrees that a p-value less than 0.05 is sufficient evidence to reject the

00:02:12.280 --> 00:02:13.320
null hypothesis.

00:02:13.320 --> 00:02:17.900
In fact, some studies that look at incredibly
important things like new medications, have

00:02:17.900 --> 00:02:22.200
already decided that an alpha of 0.05 isn’t
low enough.

00:02:22.200 --> 00:02:28.260
They want p-values lower than 0.01 so that
if the null hypothesis is true, they’ll

00:02:28.260 --> 00:02:31.500
only mistakenly reject it 1% of the time.

00:02:31.500 --> 00:02:35.450
Still others argue that 0.005 is the better
cutoff.

00:02:35.450 --> 00:02:38.819
As you can see, the standard cutoff is arbitrary.

00:02:38.819 --> 00:02:44.170
Null Hypothesis Significance Testing requires that we draw a line in the sand somewhere,

00:02:44.170 --> 00:02:45.480
but it isn’t clear where.

00:02:45.480 --> 00:02:50.020
Arguments have been made that we can have different p-value cutoffs--our alphas--depending

00:02:50.020 --> 00:02:54.049
on the situation, and that scientists should
be allowed to justify their reasons for picking

00:02:54.049 --> 00:02:55.410
a certain cutoff.

00:02:55.410 --> 00:03:00.450
But on the whole, many fields that regularly
use p-values have some sort of “official”

00:03:00.450 --> 00:03:01.450
cutoff that they use.

00:03:01.450 --> 00:03:06.159
The second, related issue is that a p-value
tells you how “extreme” your data would

00:03:06.159 --> 00:03:09.630
be if you assume the null hypothesis is true.

00:03:09.630 --> 00:03:12.760
But when you really think about it...that’s
not what we want to know.

00:03:12.760 --> 00:03:17.379
We want to know whether the null is correct, or at least probably correct.

00:03:17.379 --> 00:03:21.390
In other words, the probability of the null,
given that we’ve seen our data.

00:03:21.390 --> 00:03:27.290
A p-value of 0.02 in a study on cancer rates
in mice tells you that if your new drug didn’t

00:03:27.290 --> 00:03:31.579
work and there was no difference between the cancer rates of mice on and off the drug,

00:03:31.579 --> 00:03:37.250
then you’d only expect 2% of identically
run studies to produce a difference in cancer

00:03:37.250 --> 00:03:41.120
rates that’s as or more extreme than the
one you just observed.

00:03:41.120 --> 00:03:45.920
But we can’t use these p-values alone to
tell us about the probability of the null

00:03:45.920 --> 00:03:50.640
being true or false, even though it can be
tempting to think we can.

00:03:50.640 --> 00:03:54.880
One common misinterpretation of a p-value
is that it can tell you the probability that

00:03:54.890 --> 00:03:57.190
the null hypothesis is true.

00:03:57.190 --> 00:04:02.890
For example, if a random sample of tuna has a 10% higher mercury content than a random

00:04:02.890 --> 00:04:09.090
sample of mahi-mahi, it would be incorrect
to say that a p-value of 0.02 in this case

00:04:09.090 --> 00:04:13.060
means there’s only a 2% chance that the
null hypothesis is true.

00:04:13.060 --> 00:04:18.340
This is an especially tempting misinterpretation because it feels like it maybe should be true,

00:04:18.340 --> 00:04:22.180
but again, when we calculate our p-value,
we’ve already assumed for a moment that

00:04:22.180 --> 00:04:28.900
the null hypothesis is true and that any sample differences we see are actually due to just

00:04:28.910 --> 00:04:30.430
random sampling variation.

00:04:30.430 --> 00:04:36.470
If our p-value for the chess study was 0.01,
that means that we already assumed older chess

00:04:36.470 --> 00:04:42.410
players were the same as the general population of chess players, so 0.01 can’t tell us

00:04:42.410 --> 00:04:46.960
much about the probability that older chess
players are the same as their colleagues.

00:04:46.960 --> 00:04:50.800
That would be like saying “assuming that
grass is green, what’s the probability that

00:04:50.810 --> 00:04:51.980
grass is green?”

00:04:51.980 --> 00:04:53.620
It just doesn’t make much sense.

00:04:53.620 --> 00:04:58.460
Similarly, p-values can’t tell you the probability that you’ve made an error, given that you

00:04:58.470 --> 00:04:59.660
rejected the null.

00:04:59.670 --> 00:05:04.720
Again, this is because p-values don’t tell
you about the probability of the null being

00:05:04.720 --> 00:05:05.860
true or false.

00:05:05.860 --> 00:05:10.240
If you’ve rejected the null hypothesis--like
that drinking orange juice is not associated

00:05:10.250 --> 00:05:15.100
with higher levels of cavities than drinking
coffee--either you did so correctly, because

00:05:15.100 --> 00:05:20.610
there really is a difference between cavities
in OJ and coffee drinkers, or you did so mistakenly

00:05:20.610 --> 00:05:23.830
because there really is no discernible difference.

00:05:23.830 --> 00:05:29.420
But p-values--since they assume the null is
true--don’t tell you how likely either of

00:05:29.420 --> 00:05:30.490
these options is.

00:05:30.490 --> 00:05:35.550
Ronald Fisher--one of the first proponents
of Null Hypothesis Significance Testing wrote

00:05:35.550 --> 00:05:42.300
that: “ In general tests of significance
are based on hypothetical probabilities calculated

00:05:42.300 --> 00:05:44.330
from their null hypotheses.

00:05:44.330 --> 00:05:49.030
They do not generally lead to any probability statements about the real world, but to a

00:05:49.030 --> 00:05:55.150
rational and well-defined measure of reluctance to the acceptance of the hypotheses they test."

00:05:55.150 --> 00:06:00.060
In other words, getting a p-value of 0.04
doesn’t mean that there’s a 4% chance

00:06:00.060 --> 00:06:01.910
that the null hypothesis is true.

00:06:01.910 --> 00:06:07.071
The probability we want to know is the opposite conditional probability from what a p-value

00:06:07.080 --> 00:06:08.230
gives you.

00:06:08.230 --> 00:06:13.980
We want to know the probability of the null
hypothesis given that we got this data.

00:06:13.980 --> 00:06:15.780
But that’s not what we get.

00:06:15.780 --> 00:06:20.540
From the p-value we get the Probability of
the data given the null.

00:06:20.540 --> 00:06:23.460
For example, we calculate P(data

00:06:23.460 --> 00:06:29.320
|older chess players are the same as population of chess players ) but we wish we could calculate

00:06:29.320 --> 00:06:34.730
P(older chess players are the same as population of chess players | data).

00:06:34.730 --> 00:06:38.010
And while all the same pieces are there, they’re not the same.

00:06:38.010 --> 00:06:41.870
This is made even more clear when you realize the probability of being a child, given that

00:06:41.870 --> 00:06:46.620
you’re at Chuck E Cheese is NOT the same
as the probability of being at Chuck E Cheese,

00:06:46.620 --> 00:06:48.060
given that you’re a child.

00:06:48.060 --> 00:06:50.340
This is one reason why p-values are so perplexing.

00:06:50.340 --> 00:06:53.880
They don’t give us the probability that
we truly want.

00:06:53.880 --> 00:06:58.550
There are some statistical methods that will give you the probability of a hypothesis given

00:06:58.550 --> 00:07:00.900
the data, and we’ll talk about those later.

00:07:00.900 --> 00:07:04.820
A third issue is that if you reject the null,
you still don’t have much information about

00:07:04.830 --> 00:07:06.030
the alternative.

00:07:06.030 --> 00:07:11.540
When the data is pretty improbable under the null hypothesis, we reject the null and accept

00:07:11.540 --> 00:07:17.380
the hypothesis that the data came from another distribution that is not the null distribution.

00:07:17.380 --> 00:07:21.351
We call this the alternative distribution,
and the hypothesis that goes with it, the

00:07:21.351 --> 00:07:23.320
alternative hypothesis.

00:07:23.320 --> 00:07:27.300
If we reject the null that Mrs. Smith and Mr. Kennedy give the same amount of homework

00:07:27.300 --> 00:07:31.790
each week, then the alternative is that they don’t give the same amount each week.

00:07:31.790 --> 00:07:36.060
But, we don’t know whether the difference
is by 30 minutes, 25 minutes...45 minutes.

00:07:36.060 --> 00:07:41.170
Or, for example,we might want to know whether people who were primed with the words “Elderly,

00:07:41.170 --> 00:07:46.171
Florida, and Retired” walked more slowly
than the average person who takes 10 minutes

00:07:46.171 --> 00:07:49.920
to go around our office building, with a standard deviation of 1 minute.

00:07:49.920 --> 00:07:52.390
We think they will.

00:07:52.390 --> 00:07:55.700
We take a sample of 50 people, primed them, and set them off.

00:07:55.700 --> 00:08:03.390
Their mean time is 10.5 minutes, which corresponds to a p-value of 0.00036.

00:08:03.390 --> 00:08:09.070
We already decided beforehand to make our alpha (or predetermined cutoff) 0.005.

00:08:09.070 --> 00:08:14.850
So our p-value which is less than 0.005 allows us to reject the null hypothesis...in this

00:08:14.850 --> 00:08:19.330
case that the people primed with words about being old take a mean of 10 minutes to walk

00:08:19.330 --> 00:08:20.400
around the building.

00:08:20.400 --> 00:08:21.380
But what now?

00:08:21.380 --> 00:08:26.300
While we’ve rejected the null hypothesis
that the primed subjects take a mean of 10 minutes.

00:08:26.300 --> 00:08:30.520
The alternative hypothesis is just that their mean isn’t 10.

00:08:30.520 --> 00:08:32.520
Our p-values can’t tell us anything else.

00:08:32.529 --> 00:08:38.130
A fourth common issue for p-values is more about how we interpret “non-significant”

00:08:38.130 --> 00:08:39.279
p-values.

00:08:39.279 --> 00:08:44.800
If our p-value isn’t lower than our predetermined cutoff, our alpha, we “fail to reject”

00:08:44.800 --> 00:08:46.080
the null hypothesis.

00:08:46.080 --> 00:08:48.600
Notice that we say fail to reject, not accept.

00:08:48.600 --> 00:08:53.339
Null hypothesis testing doesn’t allow us
to “accept” or provide evidence that the

00:08:53.339 --> 00:08:58.420
null is true, instead we’ve only failed
to provide evidence that it’s false.

00:08:58.420 --> 00:09:02.780
Consider this: Your best friend makes the
statement, “there are no black swans in China".

00:09:02.780 --> 00:09:06.780
You think she’s wrong, so you go to China
and you look at a bunch of swans, and none

00:09:06.790 --> 00:09:07.780
of them are black.

00:09:07.790 --> 00:09:12.839
You may, at a certain point, decide that you’ve seen SO many swans that if there were black

00:09:12.839 --> 00:09:16.830
swans in China, it’s unlikely that you wouldn’t have seen one yet.

00:09:16.830 --> 00:09:22.800
But you can’t PROVE there are no black swans until you’ve seen EVERY.SINGLE.SWAN.

00:09:22.800 --> 00:09:26.839
Just like you can’t prove the null is true--that there’s no relationship between two variables,

00:09:26.839 --> 00:09:31.300
you can only show that you didn’t find any
evidence it’s false.

00:09:31.300 --> 00:09:35.319
The absence of evidence is not the evidence of absence.

00:09:35.319 --> 00:09:39.250
“failing to reject” the null hypothesis
doesn’t mean that there isn’t an effect

00:09:39.250 --> 00:09:44.440
or relationship, it just means we didn’t
get enough evidence to say there definitely is one.

00:09:44.440 --> 00:09:48.760
If we looked whether bees produce more honey when it’s warm than when it’s cold, we

00:09:48.760 --> 00:09:52.520
could look at some data and calculate a p-value of 0.25.

00:09:52.520 --> 00:09:57.550
Since we decided beforehand that our alpha would be 0.01, we fail to reject the null

00:09:57.550 --> 00:10:02.240
hypothesis that bees produce the same amount of honey in hot and cold seasons.

00:10:02.240 --> 00:10:07.520
But we can’t conclude that there is no difference or even that it’s unlikely that there’s a difference.

00:10:07.520 --> 00:10:11.420
We can only conclude that we didn’t find
any evidence of one.

00:10:11.420 --> 00:10:16.360
Since null hypothesis significance testing
is often the first type of statistical inference

00:10:16.360 --> 00:10:21.160
that people learn, it can seem pretty limiting to know that you can’t provide good evidence

00:10:21.160 --> 00:10:23.670
for the null hypothesis being true.

00:10:23.670 --> 00:10:27.879
In some cases the null hypothesis might be
what you actually want to demonstrate.

00:10:27.879 --> 00:10:31.829
For example, say there are two groups: people who play a souped up, bells and whistles version

00:10:31.829 --> 00:10:36.060
of a cognitive training game and those who
plan a less fancy version of the game.

00:10:36.060 --> 00:10:39.680
If these two groups have the same amount of improvement in cognitive abilities (which

00:10:39.680 --> 00:10:42.510
is our null hypothesis says) that’s really
interesting.

00:10:42.510 --> 00:10:47.180
It means that researchers could feel comfortable using whichever version of the game that they want.

00:10:47.180 --> 00:10:50.700
If playing the fancier, more aesthetically
pleasing game made people with strokes, or

00:10:50.710 --> 00:10:56.860
children with learning differences more likely to play it, researchers would know that’s fine.

00:10:56.860 --> 00:11:00.660
They wouldn’t have any concerns that the
bells and whistles would detract from the

00:11:00.660 --> 00:11:02.000
cognitive benefits.

00:11:02.000 --> 00:11:03.840
P-values can be perplexing.

00:11:03.850 --> 00:11:06.480
But they give us insight into how to make
decisions about data.

00:11:06.490 --> 00:11:10.740
They also remind us that people’s perception of evidence can be arbitrary.

00:11:10.740 --> 00:11:15.000
What you consider sufficient evidence might not be enough to convince someone else.

00:11:15.000 --> 00:11:19.459
When you read about the results of scientific studies, you can see the alpha they used and

00:11:19.459 --> 00:11:22.930
decide if you think it’s a stringent enough
criteria.

00:11:22.930 --> 00:11:26.970
More than that, though, we now know what p-values are and how to interpret them.

00:11:26.970 --> 00:11:32.189
This helps us compare the logic of null hypothesis significance testing with how we normally

00:11:32.189 --> 00:11:33.880
reason about the world.

00:11:33.880 --> 00:11:35.920
Thanks for watching, I’ll see 
you next time.

