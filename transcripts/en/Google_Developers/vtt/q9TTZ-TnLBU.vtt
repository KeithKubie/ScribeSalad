WEBVTT
Kind: captions
Language: en

00:00:04.033 --> 00:00:05.767
&gt;&gt; Barrett:
Hi, my name is Ryan Barrett.

00:00:05.767 --> 00:00:08.467
I'll be speaking at I/O.

00:00:08.467 --> 00:00:11.133
So imagine
you're starting a startup

00:00:11.133 --> 00:00:12.133
or an open source project,

00:00:12.133 --> 00:00:13.667
and you're working with people

00:00:13.667 --> 00:00:15.234
who live in
a bunch of different places.

00:00:15.234 --> 00:00:16.701
Everyone lives
in a different place.

00:00:16.701 --> 00:00:18.868
But say you couldn't
email with them

00:00:18.868 --> 00:00:21.334
or IM or talk on the phone.

00:00:21.334 --> 00:00:23.367
Say the only way you could
communicate with them

00:00:23.367 --> 00:00:25.734
was flying to one of them,

00:00:25.734 --> 00:00:27.367
you know,
and meet one on one.

00:00:27.367 --> 00:00:28.934
You could never
get more than two of you

00:00:28.934 --> 00:00:29.934
in the same place at a time.

00:00:29.934 --> 00:00:32.734
So this is how
we have to think

00:00:32.734 --> 00:00:36.767
when we design protocols
for managing data

00:00:36.767 --> 00:00:39.667
and building products
that run across data centers.

00:00:39.667 --> 00:00:42.067
It's no fun,
but we still need to do it,

00:00:42.067 --> 00:00:44.400
because we need
our products to run

00:00:44.400 --> 00:00:45.634
even if any data center

00:00:45.634 --> 00:00:47.167
at any time
falls into the ocean,

00:00:47.167 --> 00:00:49.501
or, more likely,
has a power outage

00:00:49.501 --> 00:00:50.501
or has a fire.

00:00:50.501 --> 00:00:52.934
So this is what my talk
is about.

00:00:52.934 --> 00:00:56.234
How can you write a product

00:00:56.234 --> 00:00:57.367
or develop a system

00:00:57.367 --> 00:00:59.834
that runs in the face of

00:00:59.834 --> 00:01:02.100
not only a single server
or a few servers,

00:01:02.100 --> 00:01:04.534
but an entire data center
going down at any time?

00:01:04.534 --> 00:01:06.267
We don't have any magic.

00:01:06.267 --> 00:01:07.934
We do have a few people

00:01:07.934 --> 00:01:09.901
who have invented protocols

00:01:09.901 --> 00:01:12.968
that deal with
this kind of thing, though.

00:01:12.968 --> 00:01:16.834
One of the most interesting
is Paxos.

00:01:16.834 --> 00:01:17.868
It's what we call

00:01:17.868 --> 00:01:19.300
a distributed
consensus protocol,

00:01:19.300 --> 00:01:22.100
where without any single master,

00:01:22.100 --> 00:01:26.000
you can have a bunch
of different entities--

00:01:26.000 --> 00:01:28.467
data centers,
servers inside data centers,

00:01:28.467 --> 00:01:29.634
agree on something.

00:01:29.634 --> 00:01:31.267
So most people know

00:01:31.267 --> 00:01:33.133
that you need
to replicate your data.

00:01:33.133 --> 00:01:34.601
At a minimum for safety,

00:01:34.601 --> 00:01:35.734
you need backups.

00:01:35.734 --> 00:01:37.734
If you do
a write to one data center,

00:01:37.734 --> 00:01:39.100
and it comes back,

00:01:39.100 --> 00:01:40.200
and you immediately do a read

00:01:40.200 --> 00:01:41.801
that gets routed
to another data center,

00:01:41.801 --> 00:01:43.667
if that data hasn't replicated

00:01:43.667 --> 00:01:45.133
from the original data center

00:01:45.133 --> 00:01:46.133
to the other one,

00:01:46.133 --> 00:01:48.000
you're kinda screwed, right?

00:01:48.000 --> 00:01:49.300
So you either need
to block on it,

00:01:49.300 --> 00:01:51.467
but you don't
wanna block too much

00:01:51.467 --> 00:01:52.601
on too much replication,

00:01:52.601 --> 00:01:54.834
because then every action
your user takes

00:01:54.834 --> 00:01:55.834
takes forever.

00:01:55.834 --> 00:01:58.033
So these kinds of trade-offs,

00:01:58.033 --> 00:01:59.501
these kinds of tensions

00:01:59.501 --> 00:02:01.501
are what makes this kind
of problem interesting.

00:02:01.501 --> 00:02:03.667
I can't wait
to talk more about that

00:02:03.667 --> 00:02:04.667
and share that with people

00:02:04.667 --> 00:02:06.133
both inside and outside
the company,

00:02:06.133 --> 00:02:07.534
so I look forward
to seeing you at I/O.

