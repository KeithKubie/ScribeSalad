WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.970
[MUSIC PLAYING]

00:00:08.112 --> 00:00:09.570
CLEMENS MEWALD: My
name is Clemens.

00:00:09.570 --> 00:00:11.430
I'm the product lead
for TensorFlow Extended,

00:00:11.430 --> 00:00:13.097
the end-to-end machine
learning platform

00:00:13.097 --> 00:00:14.350
that we built for TensorFlow.

00:00:14.350 --> 00:00:16.183
And we have a lot of
exciting announcements,

00:00:16.183 --> 00:00:18.065
so let's jump right in.

00:00:18.065 --> 00:00:19.940
A lot of you may be
familiar with this graph.

00:00:19.940 --> 00:00:22.813
We published this
in a paper in 2017.

00:00:22.813 --> 00:00:24.980
And the main point that I
usually make on this graph

00:00:24.980 --> 00:00:28.040
is that there's more to machine
learning than just the training

00:00:28.040 --> 00:00:28.785
part.

00:00:28.785 --> 00:00:30.160
In the middle,
the trainer piece,

00:00:30.160 --> 00:00:32.653
that's where you train
your machinery model.

00:00:32.653 --> 00:00:34.820
But if you want to do machine
learning in production

00:00:34.820 --> 00:00:37.453
reliably and in a
robust way, you actually

00:00:37.453 --> 00:00:38.870
need all of these
other components

00:00:38.870 --> 00:00:41.390
before and after, and in
parallel, to the training

00:00:41.390 --> 00:00:42.470
algorithm.

00:00:42.470 --> 00:00:45.510
And often I hear, sometimes
from researchers, well,

00:00:45.510 --> 00:00:46.640
I really only do research.

00:00:46.640 --> 00:00:49.150
I only care about training
the machine learning model

00:00:49.150 --> 00:00:51.650
and I don't really need all of
these upstream and downstream

00:00:51.650 --> 00:00:52.160
things.

00:00:52.160 --> 00:00:54.260
But what I would argue
is that research often

00:00:54.260 --> 00:00:55.790
leads to production.

00:00:55.790 --> 00:00:58.070
And what we want to
avoid is researchers

00:00:58.070 --> 00:01:00.290
having to re-implement
their hard work,

00:01:00.290 --> 00:01:02.570
in a model that they've
built, when they want to put

00:01:02.570 --> 00:01:03.860
the model into production.

00:01:03.860 --> 00:01:05.060
That's actually one
of the main reasons

00:01:05.060 --> 00:01:07.250
why we open sourced
TensorFlow because we really

00:01:07.250 --> 00:01:11.420
wanted the research community to
build the models in a framework

00:01:11.420 --> 00:01:15.050
that we can then use and
actually move into production.

00:01:15.050 --> 00:01:16.820
A second comment
that I hear often

00:01:16.820 --> 00:01:19.220
is, well, I only have
a very small data set

00:01:19.220 --> 00:01:20.597
that fits in a single machine.

00:01:20.597 --> 00:01:22.430
And all of these tools
are built to scale up

00:01:22.430 --> 00:01:24.080
to hundreds of machines.

00:01:24.080 --> 00:01:26.210
And I don't really need
all of these heavy tools.

00:01:26.210 --> 00:01:28.400
But what we've seen time
and time again at Google

00:01:28.400 --> 00:01:32.300
is that small data today
becomes large data tomorrow.

00:01:32.300 --> 00:01:33.800
And there's really
no reason why you

00:01:33.800 --> 00:01:36.560
would have to re-implement
your entire stack just

00:01:36.560 --> 00:01:38.325
because your data set grew.

00:01:38.325 --> 00:01:39.950
So we really want to
make sure that you

00:01:39.950 --> 00:01:42.860
can use the same tools
early on in your journey

00:01:42.860 --> 00:01:46.370
so that the tools can actually
grow with you and your product,

00:01:46.370 --> 00:01:49.190
with the data, so that you
can scale the exact same code

00:01:49.190 --> 00:01:50.930
to hundreds of machines.

00:01:50.930 --> 00:01:53.360
So we've built TensorFlow
Extended as a platform

00:01:53.360 --> 00:01:57.050
at Google, and it has
had a profound impact

00:01:57.050 --> 00:01:59.030
to how we do machine
learning and production

00:01:59.030 --> 00:02:01.770
and into becoming
an AI-first company.

00:02:01.770 --> 00:02:04.740
So TFX really powers some of
our most important Alphabet

00:02:04.740 --> 00:02:05.240
companies.

00:02:05.240 --> 00:02:08.610
Of course, Google is just one
of the Alphabet companies.

00:02:08.610 --> 00:02:11.960
So TFX is used at six
different Alphabet companies.

00:02:11.960 --> 00:02:14.000
And within Google,
it's really used

00:02:14.000 --> 00:02:15.493
with all of the major products.

00:02:15.493 --> 00:02:16.910
And also, all of
the products that

00:02:16.910 --> 00:02:19.970
don't have billions of users
[INAUDIBLE] this slide.

00:02:19.970 --> 00:02:21.880
And I've said before
that we really

00:02:21.880 --> 00:02:24.342
want to make TFX
available to all of you

00:02:24.342 --> 00:02:26.050
because we've seen
the profound impact it

00:02:26.050 --> 00:02:27.310
has had on our business.

00:02:27.310 --> 00:02:28.810
And we're really
excited to see what

00:02:28.810 --> 00:02:32.836
you can do with the same
tools in your companies.

00:02:32.836 --> 00:02:35.800
So a year ago we talked
about the libraries

00:02:35.800 --> 00:02:38.180
that we had open sourced
at that point in time.

00:02:38.180 --> 00:02:40.420
So we talked about TensorFlow
Transform, the training

00:02:40.420 --> 00:02:43.540
libraries, Estimators and Keras,
TensorFlow Model Analysis,

00:02:43.540 --> 00:02:45.290
and TensorFlow Serving.

00:02:45.290 --> 00:02:49.210
And I made the point that, back
then, as today, all of these

00:02:49.210 --> 00:02:50.190
are just libraries.

00:02:50.190 --> 00:02:52.065
So they're low-level
libraries that you still

00:02:52.065 --> 00:02:53.980
have to use independently
and stitch together

00:02:53.980 --> 00:02:57.280
to actually make work and
train for your own use cases.

00:02:57.280 --> 00:03:00.670
Later that year, we added
TensorFlow Data Validation.

00:03:00.670 --> 00:03:03.760
So that made the picture
a little more complete.

00:03:03.760 --> 00:03:06.730
But we're still far away
from actually being done yet.

00:03:06.730 --> 00:03:09.570
However, it was extremely
valuable to release

00:03:09.570 --> 00:03:11.418
these libraries at
that point in time

00:03:11.418 --> 00:03:13.210
because some of our
most important partners

00:03:13.210 --> 00:03:16.000
externally has also had a
profound impact with some

00:03:16.000 --> 00:03:17.360
of these libraries.

00:03:17.360 --> 00:03:19.330
So we've just heard from
our friends at Airbnb.

00:03:19.330 --> 00:03:21.247
They use TensorFlow
Serving in that case study

00:03:21.247 --> 00:03:23.160
that they mentioned.

00:03:23.160 --> 00:03:25.690
Our friends at Twitter just
published this fascinating blog

00:03:25.690 --> 00:03:29.080
post of how they used
TensorFlow to rank tweets

00:03:29.080 --> 00:03:30.440
on their home timeline.

00:03:30.440 --> 00:03:33.370
And they've used TensorFlow
Model Analysis to analyze

00:03:33.370 --> 00:03:35.860
that model on different
segments of the data

00:03:35.860 --> 00:03:38.600
and used TensorFlow Hub to share
some of the word embeddings

00:03:38.600 --> 00:03:41.050
that they've used
for these models.

00:03:41.050 --> 00:03:44.060
So coming back to this picture.

00:03:44.060 --> 00:03:46.310
For those of you who've
seen my talk last year,

00:03:46.310 --> 00:03:48.590
I promised everyone
that there will be more.

00:03:48.590 --> 00:03:51.350
Because, again, this is
only the partial platform.

00:03:51.350 --> 00:03:53.790
It's far away from actually
being an end-to-end platform.

00:03:53.790 --> 00:03:56.000
It's just a set of libraries.

00:03:56.000 --> 00:03:57.930
So today, for the
very first time,

00:03:57.930 --> 00:03:59.970
we're actually sharing
the horizontal layers

00:03:59.970 --> 00:04:01.530
that integrate all
of these libraries

00:04:01.530 --> 00:04:04.770
into one end-to-end platform,
into one end-to-end product,

00:04:04.770 --> 00:04:08.500
which is called
TensorFlow Extended.

00:04:08.500 --> 00:04:10.250
But first, we have to
build components out

00:04:10.250 --> 00:04:11.610
of these libraries.

00:04:11.610 --> 00:04:14.390
So at the top of this slide,
you see in orange, the libraries

00:04:14.390 --> 00:04:15.753
that we've shared in the past.

00:04:15.753 --> 00:04:17.420
And then in blue, you
see the components

00:04:17.420 --> 00:04:19.459
that we've built
from these libraries.

00:04:19.459 --> 00:04:22.130
So one observation to be
made here is that, of course,

00:04:22.130 --> 00:04:25.500
libraries are very low
level and very flexible.

00:04:25.500 --> 00:04:28.460
So with a single library, we can
build many different components

00:04:28.460 --> 00:04:30.510
that are part of machine
learning pipeline.

00:04:30.510 --> 00:04:32.665
So in the example of
TensorFlow Data Validation,

00:04:32.665 --> 00:04:34.040
we used the same
library to build

00:04:34.040 --> 00:04:35.165
three different components.

00:04:35.165 --> 00:04:37.580
And I will go into detail on
each one of these components

00:04:37.580 --> 00:04:39.300
later.

00:04:39.300 --> 00:04:40.820
So what makes a component?

00:04:40.820 --> 00:04:43.170
A component is no
longer just a library.

00:04:43.170 --> 00:04:46.330
It's a packaged
binary or container

00:04:46.330 --> 00:04:48.280
that can be run as
part of a pipeline.

00:04:48.280 --> 00:04:50.410
It has well-defined
inputs and outputs.

00:04:50.410 --> 00:04:52.270
In the case of Model
Validation, it's

00:04:52.270 --> 00:04:55.660
the last validated model,
a new candidate model,

00:04:55.660 --> 00:04:57.542
and the validation outcome.

00:04:57.542 --> 00:04:59.000
And that's a
well-defined interface

00:04:59.000 --> 00:05:01.320
of each one of these components.

00:05:01.320 --> 00:05:03.080
It has a well-defined
configuration.

00:05:03.080 --> 00:05:05.450
And, most importantly, it's
one configuration model

00:05:05.450 --> 00:05:06.690
for the entire pipeline.

00:05:06.690 --> 00:05:10.860
So you configure a TFX
pipeline end to end.

00:05:10.860 --> 00:05:12.240
And some of you
may have noticed,

00:05:12.240 --> 00:05:14.940
because Model Validation needs
the last validated model,

00:05:14.940 --> 00:05:16.500
it actually needs some context.

00:05:16.500 --> 00:05:19.740
It needs to know what was the
last model that was validated.

00:05:19.740 --> 00:05:22.500
So we need to add a metadata
store that actually provides

00:05:22.500 --> 00:05:24.690
this context, that
keeps a record of all

00:05:24.690 --> 00:05:27.450
of the previous runs so that
some of these more advanced

00:05:27.450 --> 00:05:30.840
capabilities can be enabled.

00:05:30.840 --> 00:05:32.460
So how does this
context get created?

00:05:32.460 --> 00:05:35.790
Of course, in this case, the
trainer produces new models.

00:05:35.790 --> 00:05:38.730
Model Validator knows about
the last validated model

00:05:38.730 --> 00:05:40.260
and the new candidate model.

00:05:40.260 --> 00:05:42.210
And then downstream
from the Validator,

00:05:42.210 --> 00:05:45.340
we take that new candidate model
and the validation outcome.

00:05:45.340 --> 00:05:47.280
And if the validation
outcome is positive,

00:05:47.280 --> 00:05:49.230
we push the model to
the serving system.

00:05:49.230 --> 00:05:50.580
If it's negative, we don't.

00:05:50.580 --> 00:05:52.260
Because usually we
don't want to push

00:05:52.260 --> 00:05:54.093
a model that's worse
than our previous model

00:05:54.093 --> 00:05:56.590
into our serving system.

00:05:56.590 --> 00:05:58.160
So the Metadata Store is new.

00:05:58.160 --> 00:05:59.890
So let's discuss
why we need this

00:05:59.890 --> 00:06:02.085
and what the
Metadata Store does.

00:06:02.085 --> 00:06:04.210
First, when most people
talk about machine learning

00:06:04.210 --> 00:06:06.220
workflows and
pipelines, they really

00:06:06.220 --> 00:06:08.340
think about task dependency.

00:06:08.340 --> 00:06:11.080
They think there's one component
and when that's finished,

00:06:11.080 --> 00:06:12.850
there's another
component that runs.

00:06:12.850 --> 00:06:15.040
However, all of you who
actually do machine learning

00:06:15.040 --> 00:06:19.270
in production know that we
actually need data dependency,

00:06:19.270 --> 00:06:22.030
because all of these components
consume artifacts and create

00:06:22.030 --> 00:06:23.110
artifacts.

00:06:23.110 --> 00:06:27.220
And as the example of Model
Validation has showed,

00:06:27.220 --> 00:06:29.710
it's incredibly important
to actually know

00:06:29.710 --> 00:06:31.250
these dependencies.

00:06:31.250 --> 00:06:34.390
So we need a system that's
both task and data aware so

00:06:34.390 --> 00:06:36.700
that each component
has a history of all

00:06:36.700 --> 00:06:41.000
of the previous runs and knows
about all of the artifacts.

00:06:41.000 --> 00:06:42.710
So what's in this
Metadata Store?

00:06:42.710 --> 00:06:44.690
Most importantly,
type definitions

00:06:44.690 --> 00:06:46.860
of artifacts and the properties.

00:06:46.860 --> 00:06:49.310
So in our case, for TFX,
it contains the definition

00:06:49.310 --> 00:06:52.490
of all of the artifacts that
are being consumed and produced

00:06:52.490 --> 00:06:55.340
by our components and
all of their properties.

00:06:55.340 --> 00:06:57.200
And it's an extensible
type system,

00:06:57.200 --> 00:06:59.150
so you can add new
types of artifacts,

00:06:59.150 --> 00:07:00.547
if you add new components.

00:07:00.547 --> 00:07:02.630
And you can add new
properties to these artifacts,

00:07:02.630 --> 00:07:06.270
if you need to track
more properties of those.

00:07:06.270 --> 00:07:11.310
Secondly, we keep a record
of all of the execution

00:07:11.310 --> 00:07:13.150
of the components.

00:07:13.150 --> 00:07:15.100
And with that
execution, we store

00:07:15.100 --> 00:07:17.560
all of the input artifacts
that went into the execution,

00:07:17.560 --> 00:07:20.500
all of the output artifacts
that were produced,

00:07:20.500 --> 00:07:22.450
and all of the
runtime configuration

00:07:22.450 --> 00:07:24.590
of this component.

00:07:24.590 --> 00:07:26.063
And, again, this is extensible.

00:07:26.063 --> 00:07:28.480
So if you want to track things
like the code snapshot that

00:07:28.480 --> 00:07:30.880
was used to produce
that component,

00:07:30.880 --> 00:07:34.660
you can store it in the
Metadata Store, as well.

00:07:34.660 --> 00:07:36.580
So, putting these
things together

00:07:36.580 --> 00:07:39.730
allows us to do something
we call lineage tracking

00:07:39.730 --> 00:07:41.068
across all executions.

00:07:41.068 --> 00:07:42.610
Because if you think
about it, if you

00:07:42.610 --> 00:07:45.970
know every execution, all of its
inputs and all of its outputs,

00:07:45.970 --> 00:07:49.693
you can piece together a story
of how an artifact was created.

00:07:49.693 --> 00:07:51.610
So we can actually, by
looking at an artifact,

00:07:51.610 --> 00:07:54.250
say what were all of
the upstream executions

00:07:54.250 --> 00:07:57.130
and artifacts that went into
producing this artifact,

00:07:57.130 --> 00:07:59.080
and what were all of
the downstream runs

00:07:59.080 --> 00:08:01.180
and downstream artifacts
that were produced using

00:08:01.180 --> 00:08:03.330
that artifact as an input?

00:08:03.330 --> 00:08:05.930
Now, that's an extremely
powerful capability,

00:08:05.930 --> 00:08:08.730
so let me talk you through
some of the examples of what

00:08:08.730 --> 00:08:10.470
this enables.

00:08:10.470 --> 00:08:12.387
The first one is a pretty
straightforward one.

00:08:12.387 --> 00:08:14.220
Let's say I want to
list all of the training

00:08:14.220 --> 00:08:15.820
runs that I've done in the past.

00:08:15.820 --> 00:08:18.690
So in this case, I am
interested in the trainer

00:08:18.690 --> 00:08:20.598
and I want to see all
of the training runs

00:08:20.598 --> 00:08:21.390
that were recorded.

00:08:21.390 --> 00:08:23.330
In this case, I had
two training runs.

00:08:23.330 --> 00:08:25.920
And I see all of the properties
of these training runs.

00:08:25.920 --> 00:08:31.160
This is pretty straightforward,
yet nothing new to see here.

00:08:31.160 --> 00:08:33.669
However, I just
spoke about lineage.

00:08:33.669 --> 00:08:35.919
We can visualize that lineage
and all this information

00:08:35.919 --> 00:08:36.461
that we have.

00:08:36.461 --> 00:08:38.530
The first comment on
this slide to make

00:08:38.530 --> 00:08:40.130
is we're working on a better UI.

00:08:40.130 --> 00:08:42.760
This is really just for
demonstration purposes.

00:08:42.760 --> 00:08:45.800
But if you look at the end of
this graph to the right side,

00:08:45.800 --> 00:08:47.630
you see the model expert path.

00:08:47.630 --> 00:08:51.530
This is the specific instance
of a model that was created.

00:08:51.530 --> 00:08:53.350
And as you can see,
we see that the model

00:08:53.350 --> 00:08:54.603
was created by the trainer.

00:08:54.603 --> 00:08:56.020
And the trainer
created this model

00:08:56.020 --> 00:08:59.480
by consuming a Schema,
Transform and Examples.

00:08:59.480 --> 00:09:01.350
And, again, these are
specific instances.

00:09:01.350 --> 00:09:03.820
So the IDs there are
not just numbering,

00:09:03.820 --> 00:09:06.130
they're Schema of ID
number four and Transform

00:09:06.130 --> 00:09:07.690
of ID number five.

00:09:07.690 --> 00:09:09.280
And for each one
of those artifacts,

00:09:09.280 --> 00:09:11.800
we also see how they
were created upstream.

00:09:11.800 --> 00:09:14.560
And this allows us to do this
lineage tracking and going

00:09:14.560 --> 00:09:18.640
forward and backward
in our artifacts.

00:09:18.640 --> 00:09:21.520
The narrative I used was
walking back from the model but,

00:09:21.520 --> 00:09:23.620
similarly, you could look
at your training data

00:09:23.620 --> 00:09:25.810
and say, what were all of the
artifacts that were produced

00:09:25.810 --> 00:09:26.852
using that training data?

00:09:29.600 --> 00:09:32.290
This slide shows a visualization
of the data distribution

00:09:32.290 --> 00:09:33.513
that went into our model.

00:09:33.513 --> 00:09:34.930
Now, at first
glance, this may not

00:09:34.930 --> 00:09:40.130
be something earth shattering
because we've done this before.

00:09:40.130 --> 00:09:42.350
We can compute statistics
and we can visualize them.

00:09:42.350 --> 00:09:44.050
But if we look at
the code snippet,

00:09:44.050 --> 00:09:46.480
we're not referring
data or statistics.

00:09:46.480 --> 00:09:48.280
We're referring to a model.

00:09:48.280 --> 00:09:50.650
So we say for this
specific model,

00:09:50.650 --> 00:09:53.550
show me the distribution of data
that the model was trained on.

00:09:53.550 --> 00:09:55.300
And we can do this
because we have a track

00:09:55.300 --> 00:09:57.342
record of all of the data
and the statistics that

00:09:57.342 --> 00:09:59.710
went into this model.

00:09:59.710 --> 00:10:01.900
We can do a similar thing
in the other direction

00:10:01.900 --> 00:10:05.680
of saying for a specific model,
show me the sliced metrics that

00:10:05.680 --> 00:10:09.490
were produced downstream by
TensorFlow Model Analysis,

00:10:09.490 --> 00:10:11.360
and we can get
this visualization.

00:10:11.360 --> 00:10:13.060
Again, just by
looking at a model

00:10:13.060 --> 00:10:16.310
and not specifically pointing to
the output of TensorFlow Model

00:10:16.310 --> 00:10:19.080
Analysis.

00:10:19.080 --> 00:10:21.330
Of course, we know all of
the models that were trained

00:10:21.330 --> 00:10:23.070
and where all of
the checkpoints lie

00:10:23.070 --> 00:10:26.100
so we can start TensorBoard
and point to some

00:10:26.100 --> 00:10:27.030
of our historic runs.

00:10:27.030 --> 00:10:29.160
So you can actually
look at the TensorBoard

00:10:29.160 --> 00:10:31.715
for all of the models that
you've trained in the past.

00:10:31.715 --> 00:10:33.840
Because we have a track
record of all of the models

00:10:33.840 --> 00:10:36.298
that you've trained, we can
launch TensorBoard and point it

00:10:36.298 --> 00:10:38.610
to two different directories.

00:10:38.610 --> 00:10:41.790
So you can actually compare two
models in the same TensorBoard

00:10:41.790 --> 00:10:42.730
instance.

00:10:42.730 --> 00:10:46.120
So this is really model tracking
and experiment comparison

00:10:46.120 --> 00:10:46.930
after the fact.

00:10:46.930 --> 00:10:51.600
And we enable this by keeping
a track record of all of this.

00:10:51.600 --> 00:10:53.157
And, if we have
multiple models, you

00:10:53.157 --> 00:10:54.740
can also look at the
data distribution

00:10:54.740 --> 00:10:56.250
for multiple models.

00:10:56.250 --> 00:10:58.820
So this usually helps
with debugging a model.

00:10:58.820 --> 00:11:01.760
If you train the same model
twice, or on different data,

00:11:01.760 --> 00:11:03.950
and it behaves
differently, sometimes it

00:11:03.950 --> 00:11:06.650
can pay off to look at whether
the data distribution has

00:11:06.650 --> 00:11:08.275
changed between the
two different ones.

00:11:08.275 --> 00:11:09.733
And it's hard to
see in this graph,

00:11:09.733 --> 00:11:11.330
but here we're
actually overlaying

00:11:11.330 --> 00:11:12.860
two distributions
of the statistics

00:11:12.860 --> 00:11:14.480
for one model and the other.

00:11:14.480 --> 00:11:16.970
And you would see if
there's a considerable drift

00:11:16.970 --> 00:11:17.720
between those two.

00:11:20.340 --> 00:11:22.520
So all of these are enabled
by this lineage tracking

00:11:22.520 --> 00:11:24.110
that I just mentioned.

00:11:24.110 --> 00:11:28.340
Another set of use cases is
visualizing previous runs

00:11:28.340 --> 00:11:29.580
over time.

00:11:29.580 --> 00:11:32.210
So if you train the same model
over time, over new data,

00:11:32.210 --> 00:11:34.970
we can give you a time series
graph of all of the evaluation

00:11:34.970 --> 00:11:36.500
metrics over time,
and you can see

00:11:36.500 --> 00:11:39.320
if your model improves
or gets worse over time

00:11:39.320 --> 00:11:41.510
as you retrain them.

00:11:41.510 --> 00:11:44.050
Another very powerful use
case is carrying over state

00:11:44.050 --> 00:11:46.030
from previous models.

00:11:46.030 --> 00:11:48.610
Because we know that you've
trained the model in the past,

00:11:48.610 --> 00:11:50.500
we can do something
we call warm starting.

00:11:50.500 --> 00:11:52.540
So we can
re-initialize the model

00:11:52.540 --> 00:11:54.868
with weights from
a previous run.

00:11:54.868 --> 00:11:57.160
And sometimes we want to
re-initialize the entire model

00:11:57.160 --> 00:11:58.900
or maybe just an embedding.

00:11:58.900 --> 00:12:01.210
And in this way, we
can continue training

00:12:01.210 --> 00:12:05.345
from where we left off
with a new data set.

00:12:05.345 --> 00:12:07.220
And another very powerful
application of this

00:12:07.220 --> 00:12:10.610
is being able to reuse
previously computed outputs.

00:12:10.610 --> 00:12:14.090
A very common workflow is
to iterate on the model

00:12:14.090 --> 00:12:16.980
and basically iterate on
your model architecture.

00:12:16.980 --> 00:12:19.448
Now, if you have a
pipeline that ingests data,

00:12:19.448 --> 00:12:20.990
applies transformations
to your data,

00:12:20.990 --> 00:12:23.548
and then you train a model--

00:12:23.548 --> 00:12:25.590
every time you make a
small change to your model,

00:12:25.590 --> 00:12:27.720
you don't want to recompute
everything upstream.

00:12:27.720 --> 00:12:30.000
There's no reason why you would
have to re-ingest your data,

00:12:30.000 --> 00:12:32.458
re-compute the transform just
because you changed something

00:12:32.458 --> 00:12:33.300
in your model.

00:12:33.300 --> 00:12:37.210
Because we have a track record
of all of the previous steps,

00:12:37.210 --> 00:12:39.860
we can make a decision of
saying your data hasn't changed,

00:12:39.860 --> 00:12:41.318
your transform code
hasn't changed,

00:12:41.318 --> 00:12:44.220
so we will reuse the artifacts
that were produced upstream.

00:12:44.220 --> 00:12:47.190
And you can just iterate much,
much faster on your model.

00:12:47.190 --> 00:12:49.560
So this improves
iteration speeds,

00:12:49.560 --> 00:12:51.470
and it also saves compute
because you're not

00:12:51.470 --> 00:12:54.012
re-computing things that you've
already computed in the past.

00:12:56.290 --> 00:12:58.630
So now, we've talked about
components quite a bit.

00:12:58.630 --> 00:13:02.630
Now how do we actually
orchestrate TFX pipelines?

00:13:02.630 --> 00:13:04.490
First, every component
has something we

00:13:04.490 --> 00:13:06.920
call a driver and a publisher.

00:13:06.920 --> 00:13:11.390
The driver's responsibility
is to basically retrieve state

00:13:11.390 --> 00:13:13.400
from the Metadata
Store to inform

00:13:13.400 --> 00:13:15.060
what work needs to be done.

00:13:15.060 --> 00:13:16.790
So in the example
of Model Validation,

00:13:16.790 --> 00:13:18.530
the driver looks into
the Metadata Store

00:13:18.530 --> 00:13:20.520
to find the last
validated model,

00:13:20.520 --> 00:13:22.160
because that's the
model that we need

00:13:22.160 --> 00:13:24.640
to compare with the new model.

00:13:24.640 --> 00:13:28.400
The publisher then basically
keeps the record of everything

00:13:28.400 --> 00:13:30.900
that went into this component,
everything that was produced,

00:13:30.900 --> 00:13:32.467
and all of the
runtime configuration,

00:13:32.467 --> 00:13:34.050
so that we can do
that linear tracking

00:13:34.050 --> 00:13:36.570
that I mentioned earlier.

00:13:36.570 --> 00:13:38.610
And in between
sits the executor.

00:13:38.610 --> 00:13:42.360
And the executor is blissfully
unaware of all of this metadata

00:13:42.360 --> 00:13:44.760
stuff because it's
extremely important for us

00:13:44.760 --> 00:13:48.105
both to make that piece
relatively simple.

00:13:48.105 --> 00:13:49.980
Because if you want to
change the code in one

00:13:49.980 --> 00:13:52.410
of these components, if you want
to change the training code,

00:13:52.410 --> 00:13:54.785
you shouldn't have to worry
about drivers and publishers.

00:13:54.785 --> 00:13:57.000
You should just have to
worry about the executor.

00:13:57.000 --> 00:13:58.583
And it also makes
it much, much easier

00:13:58.583 --> 00:14:00.560
to write new components
for the system.

00:14:02.852 --> 00:14:04.810
And then we have one
shared configuration model

00:14:04.810 --> 00:14:08.440
that sits on top that configures
end-to-end TFX pipelines.

00:14:08.440 --> 00:14:11.320
And let's just take a look
at what that looks like.

00:14:11.320 --> 00:14:13.530
As you can see, this
is a Python DSL.

00:14:13.530 --> 00:14:16.470
And, from top to
bottom, you see that it

00:14:16.470 --> 00:14:19.020
has an object for each
one of these components.

00:14:19.020 --> 00:14:22.940
From ExampleGen,
StatisticsGen, and so on.

00:14:22.940 --> 00:14:25.338
The trainer component,
you can see, basically

00:14:25.338 --> 00:14:27.380
receives its configuration,
says that your inputs

00:14:27.380 --> 00:14:31.460
come from the transferred
output and the schema that

00:14:31.460 --> 00:14:32.900
was inferred.

00:14:32.900 --> 00:14:36.820
And let's just see what's
inside of that trainer.

00:14:36.820 --> 00:14:39.090
And that's really
just TensorFlow code.

00:14:39.090 --> 00:14:41.570
So in this case, as you can
see, we just use an estimator.

00:14:41.570 --> 00:14:44.510
And we use to estimator
train and evaluate method

00:14:44.510 --> 00:14:46.290
to actually train this model.

00:14:46.290 --> 00:14:48.450
And it takes an estimator.

00:14:48.450 --> 00:14:51.880
And we just use one of our peak
end estimators, in this case.

00:14:51.880 --> 00:14:54.000
So this is a wide and deep
model that you can just

00:14:54.000 --> 00:14:56.017
instantiate and return.

00:14:56.017 --> 00:14:57.600
But what's important
to highlight here

00:14:57.600 --> 00:15:01.050
is that we don't have an
opinion on what this code looks

00:15:01.050 --> 00:15:02.610
like, it's just TensorFlow.

00:15:02.610 --> 00:15:05.070
So anything that produces
a safe model as an output

00:15:05.070 --> 00:15:06.130
is fair game.

00:15:06.130 --> 00:15:10.650
You can use a Keras model that
produces the inference graph

00:15:10.650 --> 00:15:12.600
or, if you choose to,
you can go lower level

00:15:12.600 --> 00:15:14.880
and use some of the
lower-level APIs in TensorFlow.

00:15:14.880 --> 00:15:17.520
As long as it produces a safe
model in the right format

00:15:17.520 --> 00:15:19.590
that it can be used
TensorFlow Serving,

00:15:19.590 --> 00:15:22.090
or the [? eval graph ?] that
can be used in TensorFlow Model

00:15:22.090 --> 00:15:26.780
Analysis, you can read any type
of TensorFlow code you want.

00:15:26.780 --> 00:15:28.670
So, if you've noticed,
we still haven't

00:15:28.670 --> 00:15:30.110
talked about orchestration.

00:15:30.110 --> 00:15:33.200
So we now have a configuration
system, we have components,

00:15:33.200 --> 00:15:35.660
and we have a metadata store.

00:15:35.660 --> 00:15:38.400
And I know what some of you
may be thinking right now.

00:15:38.400 --> 00:15:41.180
Is he going to announce a
new orchestration system?

00:15:41.180 --> 00:15:43.130
And the good news is no--

00:15:43.130 --> 00:15:44.570
at least not today.

00:15:44.570 --> 00:15:47.930
Instead, we talked to a lot
of our users, to a lot of you,

00:15:47.930 --> 00:15:50.010
and unsurprisingly found out--

00:15:50.010 --> 00:15:51.020
whoops.

00:15:51.020 --> 00:15:52.320
Can we go back one slide?

00:15:52.320 --> 00:15:52.820
Yup.

00:15:52.820 --> 00:15:55.280
Unsurprisingly found
out that there's

00:15:55.280 --> 00:15:57.860
a significant installed
base of orchestration

00:15:57.860 --> 00:16:00.190
systems in your companies.

00:16:00.190 --> 00:16:02.110
We just heard from Airbnb.

00:16:02.110 --> 00:16:03.780
Of course, they
developed Airflow.

00:16:03.780 --> 00:16:06.310
And there's a lot of
companies that use Kubeflow

00:16:06.310 --> 00:16:08.770
And there's a number of
other orchestration systems.

00:16:08.770 --> 00:16:11.500
So we made a deliberate
choice to support

00:16:11.500 --> 00:16:13.270
any number of
orchestration systems

00:16:13.270 --> 00:16:15.430
because we don't want
to make you adopt

00:16:15.430 --> 00:16:17.150
a different
orchestration system just

00:16:17.150 --> 00:16:19.800
to orchestrate TFX pipelines.

00:16:19.800 --> 00:16:21.770
So the installed base
was reason number one.

00:16:21.770 --> 00:16:23.720
Reason number two
is we really want

00:16:23.720 --> 00:16:26.300
you to extend TFX pipelines.

00:16:26.300 --> 00:16:28.790
What we publish is really
just our opinionated version

00:16:28.790 --> 00:16:31.100
of what a TFX
pipeline looks like

00:16:31.100 --> 00:16:33.008
and the components
that we use at Google.

00:16:33.008 --> 00:16:34.550
But we want to make
it easier for you

00:16:34.550 --> 00:16:37.640
to add new components before
and after and in parallel

00:16:37.640 --> 00:16:40.017
to customize the pipeline
to your own use cases.

00:16:40.017 --> 00:16:41.600
And all of these
orchestration systems

00:16:41.600 --> 00:16:46.607
are really made to be able to
express arbitrary workflows.

00:16:46.607 --> 00:16:49.190
And if you're already familiar
with one of those orchestration

00:16:49.190 --> 00:16:53.010
systems, you should be able
to use them for your use case.

00:16:53.010 --> 00:16:54.870
So here we show you
two examples of what

00:16:54.870 --> 00:16:57.850
that looks like with Airflow
and Kubeflow pipelines.

00:16:57.850 --> 00:17:03.740
So on the left you see that
same TFX pipeline configured

00:17:03.740 --> 00:17:05.680
that is executed on Airflow.

00:17:05.680 --> 00:17:08.000
And there on my example we
use this for a small data

00:17:08.000 --> 00:17:10.460
set so we can iterate on
it fast on a local machine.

00:17:10.460 --> 00:17:14.560
So in the Chicago taxicab
example we use 10,000 records.

00:17:14.560 --> 00:17:17.510
And on the right side, you
see the exact same pipeline

00:17:17.510 --> 00:17:20.510
executed on Kubeflow
pipelines, on Google Cloud

00:17:20.510 --> 00:17:23.420
so that you can take advantage
of Cloud Dataflow and Cloud ML

00:17:23.420 --> 00:17:25.940
Engine and scale it up to
the 100 million [INAUDIBLE]

00:17:25.940 --> 00:17:27.470
in that data set.

00:17:27.470 --> 00:17:30.230
What's important here is
it's the same configuration,

00:17:30.230 --> 00:17:32.690
it's the same components, so
we run the same components

00:17:32.690 --> 00:17:35.390
in both environments,
and you can

00:17:35.390 --> 00:17:37.940
choose how you want
to orchestrate them

00:17:37.940 --> 00:17:40.740
in your own favorite
orchestration system.

00:17:40.740 --> 00:17:43.760
So this is what this looks
like if it's put together.

00:17:43.760 --> 00:17:45.890
TFX goes all the way
from your raw data

00:17:45.890 --> 00:17:47.930
to your deployment environment.

00:17:47.930 --> 00:17:49.760
We discussed a shared
configuration model

00:17:49.760 --> 00:17:53.490
at the top, the metadata system
that keeps track of all the

00:17:53.490 --> 00:17:55.160
runs no matter how
you orchestrate

00:17:55.160 --> 00:17:57.080
those components,
and then two ways

00:17:57.080 --> 00:17:59.030
that we published of
how to orchestrate them

00:17:59.030 --> 00:18:01.170
with Airflow and with
Kubeflow pipelines.

00:18:01.170 --> 00:18:04.570
But, as mentioned, you can
choose to orchestrate a TFX

00:18:04.570 --> 00:18:07.570
pipeline in any way you want.

00:18:07.570 --> 00:18:08.940
All of this is available now.

00:18:08.940 --> 00:18:12.450
So you can go on GitHub, on
github.com/tensorflow/tfx

00:18:12.450 --> 00:18:15.400
to check out our code and
see our new user guide

00:18:15.400 --> 00:18:17.845
on tensorflow.org/tfx.

00:18:17.845 --> 00:18:19.720
And I also want to point
out that tomorrow we

00:18:19.720 --> 00:18:21.130
have a workshop
where you can get

00:18:21.130 --> 00:18:24.010
hands-on experience with
TensorFlow Extended,

00:18:24.010 --> 00:18:25.750
from 12:00 to 2:00 PM.

00:18:25.750 --> 00:18:26.960
And there's no prerequisites.

00:18:26.960 --> 00:18:29.890
You don't even have to
bring your own laptop.

00:18:29.890 --> 00:18:32.640
So with this, we're going to
jump into an end-to-end example

00:18:32.640 --> 00:18:34.920
of how to actually go
through the entire workflow

00:18:34.920 --> 00:18:38.770
with the Chicago taxicab
data set And just

00:18:38.770 --> 00:18:39.930
to set some context.

00:18:39.930 --> 00:18:43.240
So the Chicago taxi
data set is a record

00:18:43.240 --> 00:18:48.098
of cab rides in Chicago
for some period of time.

00:18:48.098 --> 00:18:50.140
And it contains everything
that you would expect.

00:18:50.140 --> 00:18:52.810
It contains when the trip
started, when they ended,

00:18:52.810 --> 00:18:54.520
where they started
and where they ended,

00:18:54.520 --> 00:18:57.762
how much was paid for
it, and how it was paid.

00:18:57.762 --> 00:18:59.970
Now, some of these features
need some transformation,

00:18:59.970 --> 00:19:04.103
so latitude and longitude
features need to be bucketized.

00:19:04.103 --> 00:19:05.520
Usually it's a bad
idea to do math

00:19:05.520 --> 00:19:07.780
with geographical coordinates.

00:19:07.780 --> 00:19:10.810
So we bucketize them and treat
them as categorical features.

00:19:10.810 --> 00:19:13.710
Vocab features, which are
strings, need to be integerized

00:19:13.710 --> 00:19:17.040
and some of the Dense Float
features need to be normalized.

00:19:17.040 --> 00:19:19.297
We feed them into a
wide and deep model.

00:19:19.297 --> 00:19:21.880
So, the Dense features we feed
into the deep part of the model

00:19:21.880 --> 00:19:25.900
and all of the others
we use in the wide part.

00:19:25.900 --> 00:19:27.880
And then the label that
we're trying to predict

00:19:27.880 --> 00:19:31.300
is a Boolean, which
is if the tip is

00:19:31.300 --> 00:19:34.312
larger than 20% of the fare.

00:19:34.312 --> 00:19:35.770
So really what
we're doing is we're

00:19:35.770 --> 00:19:37.973
building a high tip predictor.

00:19:37.973 --> 00:19:40.390
So just in case if there's any
cab drivers in the audience

00:19:40.390 --> 00:19:42.310
or listening online,
come find me later

00:19:42.310 --> 00:19:45.097
and I can help you
set this up for you.

00:19:45.097 --> 00:19:46.930
I think it would be
really beneficial to you

00:19:46.930 --> 00:19:52.311
if you could predict if a cab
ride gives a high tip or not.

00:19:52.311 --> 00:19:53.400
So let's jump right in.

00:19:53.400 --> 00:19:56.610
And we start with data
validation and transformation.

00:19:56.610 --> 00:19:59.600
So the first part of the TFX
pipeline is ingesting data,

00:19:59.600 --> 00:20:02.182
validating that
data-- if it's OK--

00:20:02.182 --> 00:20:03.890
and then transforming
it such that it can

00:20:03.890 --> 00:20:06.720
be fed into a TensorFlow graph.

00:20:06.720 --> 00:20:09.770
So we start with ExampleGen. And
the ExampleGen component really

00:20:09.770 --> 00:20:12.300
just ingests data into
it a TFX pipeline.

00:20:12.300 --> 00:20:14.150
So it takes this
input, your raw data.

00:20:14.150 --> 00:20:17.948
We ship by default capabilities
for CSV and TF Records.

00:20:17.948 --> 00:20:19.490
But that's of course
extensible as we

00:20:19.490 --> 00:20:23.060
can ingest any type of
data into these pipelines.

00:20:23.060 --> 00:20:25.070
What's important is
that, after this step,

00:20:25.070 --> 00:20:28.580
the data is in a well-defined
place where we can find it--

00:20:28.580 --> 00:20:30.080
in a well-defined
format because all

00:20:30.080 --> 00:20:32.840
of our downstream components
standardize on that format.

00:20:32.840 --> 00:20:35.662
And it's split between
training and eval.

00:20:35.662 --> 00:20:38.120
So you've seen the configuration
of all of these components

00:20:38.120 --> 00:20:38.890
before.

00:20:38.890 --> 00:20:44.350
It's very minimal configuration
in most of the cases.

00:20:44.350 --> 00:20:46.607
Next, to move onto data
analysis and validation.

00:20:46.607 --> 00:20:48.690
And I think a lot of you
have a good intuition why

00:20:48.690 --> 00:20:49.720
that is important.

00:20:49.720 --> 00:20:51.553
Because, of course,
machine learning is just

00:20:51.553 --> 00:20:53.920
the process of taking
data and learning models

00:20:53.920 --> 00:20:56.637
that predict some
field in your data.

00:20:56.637 --> 00:20:58.720
And you're also aware that
if you feed garbage in,

00:20:58.720 --> 00:20:59.960
you get garbage out.

00:20:59.960 --> 00:21:02.200
This will be no hope in a
good machine learning model

00:21:02.200 --> 00:21:05.550
if the data wrong, or if the
data have errors in them.

00:21:05.550 --> 00:21:08.260
And this is even reinforced if
you have continuous pipelines

00:21:08.260 --> 00:21:11.290
that train on data that
was produced by a bad model

00:21:11.290 --> 00:21:14.910
and you're just reinforcing
the same problem.

00:21:14.910 --> 00:21:17.930
So first, what I would argue
is that data understanding

00:21:17.930 --> 00:21:20.285
is absolutely critical
for model understanding.

00:21:20.285 --> 00:21:21.785
There's no hope in
understanding why

00:21:21.785 --> 00:21:24.080
a model is mis-predicting
something if you don't

00:21:24.080 --> 00:21:25.640
understand what the
data looked like

00:21:25.640 --> 00:21:28.510
and if the data was OK that was
actually fed into the model.

00:21:28.510 --> 00:21:30.410
And the question you
might ask as a cab

00:21:30.410 --> 00:21:34.760
driver is why are my trip
predictions bad in the morning

00:21:34.760 --> 00:21:35.653
hours?

00:21:35.653 --> 00:21:38.070
And for all of these questions
that I'm highlighting here,

00:21:38.070 --> 00:21:40.190
I'm going to try to
answer them with the tools

00:21:40.190 --> 00:21:41.880
that we have available
in TFX later.

00:21:41.880 --> 00:21:44.700
So I will come back
to these questions.

00:21:44.700 --> 00:21:46.830
Next, we really would like
you to treat your data

00:21:46.830 --> 00:21:48.180
as your treat code.

00:21:48.180 --> 00:21:50.400
There's a lot of care
taken with code these days.

00:21:50.400 --> 00:21:53.250
It's peer reviewed, it's checked
into shared repositories,

00:21:53.250 --> 00:21:55.952
it's version
controlled, and so on.

00:21:55.952 --> 00:21:57.660
And data really needs
to be a first class

00:21:57.660 --> 00:21:59.850
citizens in these systems.

00:21:59.850 --> 00:22:01.770
And with this question,
what are our expected

00:22:01.770 --> 00:22:03.660
values from our
payment types, that's

00:22:03.660 --> 00:22:06.560
really a question about
the schema of your data.

00:22:06.560 --> 00:22:08.640
And what we would argue
is that the schema

00:22:08.640 --> 00:22:10.382
needs to be treated
with the same care

00:22:10.382 --> 00:22:11.340
as you treat your code.

00:22:14.370 --> 00:22:16.600
And catching errors early
is absolutely critical.

00:22:16.600 --> 00:22:18.610
Because I'm sure,
as all of you know,

00:22:18.610 --> 00:22:20.110
errors propagate
through the system.

00:22:20.110 --> 00:22:22.990
If your data are not OK, then
everything else downstream

00:22:22.990 --> 00:22:24.310
goes wrong as well.

00:22:24.310 --> 00:22:28.060
And these errors are extremely
hard to correct for or fix

00:22:28.060 --> 00:22:30.530
if you catch them relatively
late in the process.

00:22:30.530 --> 00:22:32.950
So really catching those
problems as early as possible

00:22:32.950 --> 00:22:35.510
is absolutely critical.

00:22:35.510 --> 00:22:38.020
So in the taxicab example,
you would ask a question

00:22:38.020 --> 00:22:41.110
like is this new company that
I have in my data set a typo

00:22:41.110 --> 00:22:43.150
or is it actually a
real company which

00:22:43.150 --> 00:22:46.252
is a natural evolution
of my data set?

00:22:46.252 --> 00:22:48.460
So let's see if we can answer
some of these questions

00:22:48.460 --> 00:22:50.050
with the tools we
have available,

00:22:50.050 --> 00:22:52.240
starting with Statistics.

00:22:52.240 --> 00:22:55.250
So the StatisticsGen
component takes in your data,

00:22:55.250 --> 00:22:56.560
computes statistics.

00:22:56.560 --> 00:22:58.630
The data can be
training, eval data,

00:22:58.630 --> 00:23:00.108
it can also be serving logs--

00:23:00.108 --> 00:23:02.650
in which case, you can look at
the skew between your training

00:23:02.650 --> 00:23:05.090
and your serving data.

00:23:05.090 --> 00:23:07.970
And the statistics really
capture the shape of your data.

00:23:07.970 --> 00:23:09.440
And the visualization
components we

00:23:09.440 --> 00:23:11.390
have draw your
attention to things

00:23:11.390 --> 00:23:14.293
that need your attention, such
as if a feature is missing

00:23:14.293 --> 00:23:16.460
most of the times, it's
actually highlighted in red.

00:23:19.120 --> 00:23:22.060
The configuration for this
component is minimal, as well.

00:23:22.060 --> 00:23:25.075
And let me zoom into some
of these visualizations.

00:23:25.075 --> 00:23:26.950
And one of the questions
that I posed earlier

00:23:26.950 --> 00:23:30.830
was why are my tip predictions
bad in the morning hours?

00:23:30.830 --> 00:23:32.920
So one thing you could do
is look at your data set

00:23:32.920 --> 00:23:36.910
and see that for trip
start hour, in the morning

00:23:36.910 --> 00:23:39.308
hours between 2:00
AM and 6:00 AM,

00:23:39.308 --> 00:23:41.350
you just don't have much
data because there's not

00:23:41.350 --> 00:23:45.010
that many taxi
trips at that time.

00:23:45.010 --> 00:23:49.060
And not having a lot of data
in a specific area of your data

00:23:49.060 --> 00:23:52.310
can mean that your model is not
robust, or has higher variance.

00:23:52.310 --> 00:23:56.910
And this could lead
to worse predictions.

00:23:56.910 --> 00:23:58.710
Next, you move on the
SchemaGen. SchemaGen

00:23:58.710 --> 00:24:01.620
takes this input, the
output of StatisticsGen,

00:24:01.620 --> 00:24:03.940
and it infers schema for you.

00:24:03.940 --> 00:24:06.160
In the case of the
chicago taxicab example,

00:24:06.160 --> 00:24:07.535
there's very few
features, so you

00:24:07.535 --> 00:24:08.790
could handwrite that schema.

00:24:08.790 --> 00:24:11.220
Although, it would be hard
to handwrite what you expect

00:24:11.220 --> 00:24:12.760
the string values to look like.

00:24:12.760 --> 00:24:14.670
But if you have
thousands of features,

00:24:14.670 --> 00:24:17.340
it's hard to actually
handwrite that expectation.

00:24:17.340 --> 00:24:20.115
So we infer that schema for
you the first time we run.

00:24:20.115 --> 00:24:23.700
And the schema really represent
what you expect from your data,

00:24:23.700 --> 00:24:25.800
and what good data
looks like, and what

00:24:25.800 --> 00:24:29.840
values your string features
can take on, and so on.

00:24:29.840 --> 00:24:32.000
Again, very minimal
configuration.

00:24:32.000 --> 00:24:34.130
And the question
that we can answer,

00:24:34.130 --> 00:24:37.020
now, is what are expected
values for payment types?

00:24:37.020 --> 00:24:38.730
And if you look here
at the very bottom,

00:24:38.730 --> 00:24:40.160
you see the field
payment type can

00:24:40.160 --> 00:24:43.280
take on cash, credit, card
dispute, no charge, key card,

00:24:43.280 --> 00:24:44.940
and unknown.

00:24:44.940 --> 00:24:46.440
So that's the
expectation of my data

00:24:46.440 --> 00:24:47.815
that's expressed in my schema.

00:24:47.815 --> 00:24:49.190
And now the next
time I run this,

00:24:49.190 --> 00:24:51.350
and this field takes
on a different value,

00:24:51.350 --> 00:24:52.713
I will get an anomaly--

00:24:55.820 --> 00:24:58.220
which comes from the
ExampleValidator.

00:24:58.220 --> 00:25:00.770
The ExampleValidator takes
the statistics and the schema

00:25:00.770 --> 00:25:03.960
as an input and produces
an anomaly report.

00:25:03.960 --> 00:25:05.420
Now, that anomaly
report basically

00:25:05.420 --> 00:25:08.600
tells you if your data
are missing features,

00:25:08.600 --> 00:25:11.630
if they have the wrong valency,
if your distributions have

00:25:11.630 --> 00:25:13.957
shifted for some
of these features.

00:25:13.957 --> 00:25:16.040
And it's important to
highlight that the anomalies

00:25:16.040 --> 00:25:18.000
report is human readable.

00:25:18.000 --> 00:25:20.760
So you can look at it and
understand what's going on.

00:25:20.760 --> 00:25:22.785
But it's also machine readable.

00:25:22.785 --> 00:25:24.410
So you can automatically
make decisions

00:25:24.410 --> 00:25:25.785
based on the
anomalies and decide

00:25:25.785 --> 00:25:29.940
not to train a model if you
have anomalies in your data.

00:25:29.940 --> 00:25:32.410
So the ExampleValidator just
takes this input, statistics,

00:25:32.410 --> 00:25:34.300
and the schema.

00:25:34.300 --> 00:25:36.730
And let me zoom into one
of these anomaly reports.

00:25:36.730 --> 00:25:39.400
Here you can see that the
field company has taken

00:25:39.400 --> 00:25:41.590
on unexpected string values.

00:25:41.590 --> 00:25:43.810
That just means that these
string values weren't

00:25:43.810 --> 00:25:46.040
there in your schema before.

00:25:46.040 --> 00:25:48.490
And that can be a natural
evolution of your data.

00:25:48.490 --> 00:25:49.960
The first time you
run this, maybe

00:25:49.960 --> 00:25:53.410
you just didn't see any trips
from those taxi companies.

00:25:53.410 --> 00:25:56.080
And by looking at it, you can
say, well, all of these look

00:25:56.080 --> 00:25:59.120
like they're normal
taxicab companies.

00:25:59.120 --> 00:26:02.230
So you can update your
schema with this expectation.

00:26:02.230 --> 00:26:04.287
Or if you saw a lot of
scrambled text in here,

00:26:04.287 --> 00:26:06.370
you would know that there's
a problem in your data

00:26:06.370 --> 00:26:07.787
that you would
have to go and fix.

00:26:10.550 --> 00:26:13.117
Moving on, we actually
get to Transform.

00:26:13.117 --> 00:26:15.200
And let me just recap the
types of transformations

00:26:15.200 --> 00:26:16.040
that we want to do.

00:26:16.040 --> 00:26:17.660
I've led them here in red--

00:26:17.660 --> 00:26:20.110
in blue, sorry.

00:26:20.110 --> 00:26:22.490
So we want to bucketize
the longitude and latitude

00:26:22.490 --> 00:26:23.780
features.

00:26:23.780 --> 00:26:27.560
We want to convert the
strings to ints, which

00:26:27.560 --> 00:26:29.240
is also calling integerizing.

00:26:29.240 --> 00:26:32.240
And for the Dense features, we
want to actually normalize them

00:26:32.240 --> 00:26:34.640
to a mean of zero and a
standard deviation of one.

00:26:34.640 --> 00:26:36.050
Now, all of these
transformations

00:26:36.050 --> 00:26:38.810
require you to do a
full pass of your data

00:26:38.810 --> 00:26:40.400
to compute some statistics.

00:26:40.400 --> 00:26:42.140
To bucketize, you
need to figure out

00:26:42.140 --> 00:26:44.080
the boundaries of the buckets.

00:26:44.080 --> 00:26:46.370
To do a string to
integer, you need

00:26:46.370 --> 00:26:49.352
to see all of the string values
that show up in your data.

00:26:49.352 --> 00:26:50.810
And to scale to a
Z-score, you need

00:26:50.810 --> 00:26:53.280
to compute the mean and
the standard deviation.

00:26:53.280 --> 00:26:55.970
Now, this is exactly what we
built TensorFlow Transform for.

00:26:55.970 --> 00:26:58.460
TensorFlow Transform
allows you to express

00:26:58.460 --> 00:27:00.980
a pre-processing
function of your data

00:27:00.980 --> 00:27:03.740
that contains some of these
transformations that require

00:27:03.740 --> 00:27:05.530
a full pass of your data.

00:27:05.530 --> 00:27:08.870
And it will then automatically
run a data processing graph

00:27:08.870 --> 00:27:10.660
to compute those statistics.

00:27:10.660 --> 00:27:13.280
So in this case, you
can see the orange boxes

00:27:13.280 --> 00:27:14.860
are statistics that we require.

00:27:14.860 --> 00:27:16.540
So for minimalization,
we require a mean

00:27:16.540 --> 00:27:18.283
and the standard deviation.

00:27:18.283 --> 00:27:19.700
And what TensorFlow
Transform does

00:27:19.700 --> 00:27:23.100
is it has a utility function
that says scale to Z-score.

00:27:23.100 --> 00:27:25.458
And it will then create a
data processing graph for you

00:27:25.458 --> 00:27:27.500
that computes the mean
and the standard deviation

00:27:27.500 --> 00:27:30.800
of your data,
return the results,

00:27:30.800 --> 00:27:34.170
and inject them as constants
into your transformation graph.

00:27:34.170 --> 00:27:36.290
So now that graph
is a hermetic graph

00:27:36.290 --> 00:27:37.790
that contains all
of the information

00:27:37.790 --> 00:27:41.370
that you need to actually
apply your transformations.

00:27:41.370 --> 00:27:43.620
And that graph can then
be used in training

00:27:43.620 --> 00:27:45.810
and in serving,
guaranteeing that there's

00:27:45.810 --> 00:27:47.538
no drift between them.

00:27:47.538 --> 00:27:49.080
This basically
eliminates the chances

00:27:49.080 --> 00:27:51.390
of training serving
skew by applying

00:27:51.390 --> 00:27:53.080
the same transformations.

00:27:53.080 --> 00:27:55.490
And at serving time, we just
need to fit in the raw data,

00:27:55.490 --> 00:27:58.073
and all the transformations are
done as part of the TensorFlow

00:27:58.073 --> 00:27:59.820
graph.

00:27:59.820 --> 00:28:02.190
So how does that look
like in the TFX Pipeline?

00:28:02.190 --> 00:28:04.800
The Transform component
takes in data, schema--

00:28:04.800 --> 00:28:07.740
the schema allows us to
parse the data more easily--

00:28:07.740 --> 00:28:08.380
and code.

00:28:08.380 --> 00:28:10.680
In this case, this is the
user-provided pre-processing

00:28:10.680 --> 00:28:12.170
function.

00:28:12.170 --> 00:28:14.850
And it produces the Transform
graph, which I just mentioned,

00:28:14.850 --> 00:28:16.460
which is a hermetic
graph that applies

00:28:16.460 --> 00:28:18.350
the transformations,
that gets attached

00:28:18.350 --> 00:28:20.840
to your training and
your serving graph.

00:28:20.840 --> 00:28:23.367
And it optionally can
materialize the Transform data.

00:28:23.367 --> 00:28:25.700
And that's a performance
optimization that sometimes you

00:28:25.700 --> 00:28:28.040
need when you want to feed
hardware accelerators really

00:28:28.040 --> 00:28:30.410
fast, it can sometimes
pay off to materialize

00:28:30.410 --> 00:28:34.445
some transformations
before your training step.

00:28:34.445 --> 00:28:36.570
So in this case, the
configuration of the component

00:28:36.570 --> 00:28:38.440
takes in a module file.

00:28:38.440 --> 00:28:40.380
That's just the file
where you configure

00:28:40.380 --> 00:28:42.410
your pre-processing function.

00:28:42.410 --> 00:28:44.520
And in this code
snippet, the actual code

00:28:44.520 --> 00:28:45.460
is not that important.

00:28:45.460 --> 00:28:47.573
But what I want
to highlight is--

00:28:47.573 --> 00:28:48.990
the last line in
this code snippet

00:28:48.990 --> 00:28:51.510
is how we transform our label.

00:28:51.510 --> 00:28:54.300
Because, of course, the label
is a logic expression of saying,

00:28:54.300 --> 00:28:56.768
is the tip greater
than 20% of my fare?

00:28:56.768 --> 00:28:58.560
And the reason why I
want to highlight this

00:28:58.560 --> 00:29:02.310
is because you don't need
analyze phases for all

00:29:02.310 --> 00:29:03.710
of your transformations.

00:29:03.710 --> 00:29:06.270
So in cases where you
don't need analysis phases,

00:29:06.270 --> 00:29:08.640
the transformation is just
a regular TensorFlow graph

00:29:08.640 --> 00:29:10.450
that transforms the features.

00:29:10.450 --> 00:29:14.580
However, to scale something to
Z-score, to integerize strings,

00:29:14.580 --> 00:29:16.740
and to bucketize a
feature, you definitely

00:29:16.740 --> 00:29:19.490
need analysis phases, and that's
what Transform helps you with.

00:29:19.490 --> 00:29:22.070
So this is the user code
that you would write.

00:29:22.070 --> 00:29:24.540
And TF Transform would create
a data processing graph

00:29:24.540 --> 00:29:27.380
and return the results
and the transform graph

00:29:27.380 --> 00:29:31.310
that you need to apply
these transformations.

00:29:31.310 --> 00:29:33.200
So now that we've
done with all of this,

00:29:33.200 --> 00:29:34.750
we still haven't trained our
machine learning model yet,

00:29:34.750 --> 00:29:35.410
right?

00:29:35.410 --> 00:29:38.350
But we've made sure that
we know that our data is

00:29:38.350 --> 00:29:40.190
in a place where we can find it.

00:29:40.190 --> 00:29:42.190
We know it's in a format
that we can understand.

00:29:42.190 --> 00:29:44.560
We know it's split
between training and eval.

00:29:44.560 --> 00:29:48.040
We know that our data are good
because we validated them.

00:29:48.040 --> 00:29:50.530
And we know that we're applying
transforms consistently

00:29:50.530 --> 00:29:53.990
between training and serving.

00:29:53.990 --> 00:29:56.390
Which brings us to
the training step.

00:29:56.390 --> 00:29:59.510
And this is where the magic
happens, or so they say.

00:29:59.510 --> 00:30:02.270
But, actually, it's not because
the training step in TFX

00:30:02.270 --> 00:30:05.030
is really just the TensorFlow
graph and the TensorFlow

00:30:05.030 --> 00:30:07.480
training step.

00:30:07.480 --> 00:30:11.080
And the training component takes
in the output of Transform,

00:30:11.080 --> 00:30:12.580
as mentioned, which
is the Transform

00:30:12.580 --> 00:30:16.390
graph and, optionally, the
materialized data, a schema,

00:30:16.390 --> 00:30:19.130
and the training code
that you provide.

00:30:19.130 --> 00:30:22.180
And it creates, as
output, TensorFlow models.

00:30:22.180 --> 00:30:24.430
And those models are in
the safe model format,

00:30:24.430 --> 00:30:26.290
which is the standard
serialized model

00:30:26.290 --> 00:30:28.930
format in TensorFlow, which
you've heard quite a bit

00:30:28.930 --> 00:30:30.290
about this morning.

00:30:30.290 --> 00:30:32.420
And in this case, actually,
we produce two of them.

00:30:32.420 --> 00:30:33.820
One is the inference
graph, which

00:30:33.820 --> 00:30:36.070
is used by TensorFlow
Serving, and another one

00:30:36.070 --> 00:30:38.590
is the eval graph,
which contains

00:30:38.590 --> 00:30:41.530
the metrics and the
necessary annotations

00:30:41.530 --> 00:30:45.753
to perform TensorFlow
Model Analysis.

00:30:45.753 --> 00:30:48.170
And so this is the configuration
that you've seen earlier.

00:30:48.170 --> 00:30:50.830
And, again, that the trainer
takes in a module file.

00:30:50.830 --> 00:30:54.022
And the code that's actually
in that module file, again,

00:30:54.022 --> 00:30:55.730
I'm just going to show
you the same slide

00:30:55.730 --> 00:30:58.513
again just to reiterate the
point, is just TensorFlow.

00:30:58.513 --> 00:31:00.680
So, in this case, it's the
train and evaluate method

00:31:00.680 --> 00:31:04.370
from estimators and a
[? canned ?] estimator

00:31:04.370 --> 00:31:05.810
that has been returned here.

00:31:05.810 --> 00:31:09.050
But again, just to
make sure you're

00:31:09.050 --> 00:31:10.790
aware of this, any
TensorFlow quote here

00:31:10.790 --> 00:31:14.420
that produces the safe model in
the right format is fair game.

00:31:14.420 --> 00:31:17.212
So all of this
works really well.

00:31:17.212 --> 00:31:19.420
So with this, we've now
trained the TensorFlow model.

00:31:19.420 --> 00:31:21.280
And now I'm going to hand
it off to my colleague,

00:31:21.280 --> 00:31:23.630
Christina, who's going to
talk about model evaluation

00:31:23.630 --> 00:31:24.310
and analysis.

00:31:24.310 --> 00:31:27.360
[MUSIC PLAYING]

