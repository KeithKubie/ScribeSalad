WEBVTT
Kind: captions
Language: en

00:00:12.580 --> 00:00:12.930
ILYA GRIGORIK: Hello.

00:00:12.930 --> 00:00:16.260
Welcome to our episode here
on structural and sampling

00:00:16.260 --> 00:00:18.590
JavaScript profiling,
which, to be honest,

00:00:18.590 --> 00:00:20.120
is a bit of a mouthful.

00:00:20.120 --> 00:00:23.060
So thankfully, today, we have
John McCutchan, who's going to

00:00:23.060 --> 00:00:24.770
help us make sense of it all.

00:00:24.770 --> 00:00:25.600
So welcome, John.

00:00:25.600 --> 00:00:26.680
JOHN MCCUTCHAN: Thank you.

00:00:26.680 --> 00:00:28.200
ILYA GRIGORIK: A couple
questions before we get into

00:00:28.200 --> 00:00:30.030
the meat of the conversation.

00:00:30.030 --> 00:00:32.530
First is, what kind of stuff
do you do at Google?

00:00:32.530 --> 00:00:34.930
And why are you the
person to tell us

00:00:34.930 --> 00:00:36.110
about all of this work?

00:00:36.110 --> 00:00:39.240
JOHN MCCUTCHAN: All right, so
I work on Native Client and

00:00:39.240 --> 00:00:43.750
Dart in DevRel at Google,
focusing on mainly

00:00:43.750 --> 00:00:44.440
performance.

00:00:44.440 --> 00:00:47.580
And this is my background coming
from PlayStation, where

00:00:47.580 --> 00:00:50.760
I spent five years doing
performance analysis and

00:00:50.760 --> 00:00:53.750
optimization for games on the
PlayStation 3 and the

00:00:53.750 --> 00:00:55.610
PlayStation Vita.

00:00:55.610 --> 00:00:56.530
ILYA GRIGORIK: That
sounds awesome.

00:00:56.530 --> 00:00:59.960
So I think you've already
partially answered my next

00:00:59.960 --> 00:01:04.260
question, but what would
somebody take

00:01:04.260 --> 00:01:05.379
away from these tools?

00:01:05.379 --> 00:01:07.780
Why should they care about and
know about the difference

00:01:07.780 --> 00:01:09.950
between a structural and
a sampling profiler?

00:01:09.950 --> 00:01:12.660
JOHN MCCUTCHAN: So both tools
give you insight into what's

00:01:12.660 --> 00:01:15.800
happening inside your program,
where the time is being spent,

00:01:15.800 --> 00:01:18.450
and that's crucially important
when you're making an

00:01:18.450 --> 00:01:21.480
interactive application that
you want to run and render

00:01:21.480 --> 00:01:24.470
smoothly inside of Chrome.

00:01:24.470 --> 00:01:25.420
ILYA GRIGORIK: All right,
fair enough.

00:01:25.420 --> 00:01:29.360
So I think I'll kick off with
a quick overview, and I'll

00:01:29.360 --> 00:01:33.190
just point out that, chances
are, you are familiar with

00:01:33.190 --> 00:01:34.910
sampling and structural
profiling.

00:01:34.910 --> 00:01:37.090
So structural is also
often called

00:01:37.090 --> 00:01:38.320
instrumenting profiling.

00:01:38.320 --> 00:01:41.390
And chances are, if you've ever
put in a manual timer--

00:01:41.390 --> 00:01:44.760
like, here's my code, and I
want to time how much time

00:01:44.760 --> 00:01:47.310
passes between these two
function calls or anything--

00:01:47.310 --> 00:01:48.920
that is, in fact, structural
profiling.

00:01:48.920 --> 00:01:49.310
JOHN MCCUTCHAN: Yes.

00:01:49.310 --> 00:01:51.240
ILYA GRIGORIK: Right, so that
is what we're talking about.

00:01:51.240 --> 00:01:53.470
But there's also this other
approach, which is sampling,

00:01:53.470 --> 00:01:55.510
which is something that
you guys have probably

00:01:55.510 --> 00:01:57.860
used in our dev tools.

00:01:57.860 --> 00:01:59.660
But there's a slight difference
between the two.

00:01:59.660 --> 00:02:01.180
JOHN MCCUTCHAN: Yes, there is.

00:02:01.180 --> 00:02:04.980
I mean, the first difference
is just in their names.

00:02:04.980 --> 00:02:09.740
Sampling is taking samples at
a fixed frequency, whereas

00:02:09.740 --> 00:02:12.460
instrumenting, or structural
profiling, is measuring the

00:02:12.460 --> 00:02:14.240
execution flow across time.

00:02:14.240 --> 00:02:14.970
ILYA GRIGORIK: And
there's some good

00:02:14.970 --> 00:02:16.680
pros and cons to both.

00:02:16.680 --> 00:02:18.320
JOHN MCCUTCHAN: Yes,
you need both.

00:02:18.320 --> 00:02:19.810
You don't use one
or the other.

00:02:19.810 --> 00:02:22.440
ILYA GRIGORIK: And I guess the
other takeaway for the

00:02:22.440 --> 00:02:25.370
structural profiling is, as I
said earlier, chances are

00:02:25.370 --> 00:02:26.480
you've done it yourself.

00:02:26.480 --> 00:02:29.015
But chances are, you've logged
something to your console,

00:02:29.015 --> 00:02:31.650
like a timer or something
else, whereas with

00:02:31.650 --> 00:02:35.280
Chrome://tracing, we actually
have a tool that will allow

00:02:35.280 --> 00:02:38.390
you to kind of introspect
and do better analysis.

00:02:38.390 --> 00:02:41.350
JOHN MCCUTCHAN: So instead of
just doing this structural or

00:02:41.350 --> 00:02:44.290
instrumenting profiling, where
you're logging something to

00:02:44.290 --> 00:02:48.970
the console, you can actually
do many nested structural or

00:02:48.970 --> 00:02:52.240
instrumenting profiling runs and
have it outputted onto a

00:02:52.240 --> 00:02:54.490
timeline track inside Chrome.

00:02:54.490 --> 00:02:55.560
ILYA GRIGORIK: Yep, awesome.

00:02:55.560 --> 00:02:58.320
So let's get right into
it and talk about--

00:02:58.320 --> 00:03:00.860
I guess we'll start with the
differences, or explain what

00:03:00.860 --> 00:03:01.760
the two approaches are.

00:03:01.760 --> 00:03:03.860
JOHN MCCUTCHAN: So with anything
that you're trying to

00:03:03.860 --> 00:03:07.090
measure, it's important that
you understand exactly what

00:03:07.090 --> 00:03:11.070
you're measuring and how that
is related to the bigger

00:03:11.070 --> 00:03:12.800
problem that you're
trying to solve.

00:03:12.800 --> 00:03:15.450
So a sampling profiler
works like this.

00:03:15.450 --> 00:03:18.690
At a fixed frequency, your
JavaScript program is

00:03:18.690 --> 00:03:22.340
instantaneously paused, and
the call stack is sampled.

00:03:22.340 --> 00:03:24.450
So if we look at the code
snippet on the left of the

00:03:24.450 --> 00:03:28.250
slide, you can see that the
program is calling foo, and

00:03:28.250 --> 00:03:29.670
foo calls bar.

00:03:29.670 --> 00:03:34.420
So the instant that the sample
comes in is maybe when the

00:03:34.420 --> 00:03:36.430
program is inside bar.

00:03:36.430 --> 00:03:38.905
As you can see here, the data
that comes out of the sample

00:03:38.905 --> 00:03:40.340
is on the right side.

00:03:40.340 --> 00:03:43.660
It's the call stack, which is
the hierarchy of function

00:03:43.660 --> 00:03:47.230
calls at the moment that
the sample was taken.

00:03:47.230 --> 00:03:50.770
ILYA GRIGORIK: So this is the
VM being paused right inside

00:03:50.770 --> 00:03:51.510
of this function.

00:03:51.510 --> 00:03:52.920
JOHN MCCUTCHAN: Exactly, yes.

00:03:52.920 --> 00:03:56.550
So the VM pauses your program,
looks at which functions are

00:03:56.550 --> 00:03:58.900
on the stack, and captures
this and

00:03:58.900 --> 00:04:00.240
saves it into a buffer.

00:04:00.240 --> 00:04:03.450
So you can see, exactly as you
can read from the code,

00:04:03.450 --> 00:04:05.640
program calls foo and
foo calls bar.

00:04:05.640 --> 00:04:08.220
And then that's when the sample
is taken, and so this

00:04:08.220 --> 00:04:09.640
gets logged.

00:04:09.640 --> 00:04:12.930
Another perspective that you
can look at a sampling CPU

00:04:12.930 --> 00:04:15.130
profiler is that over time.

00:04:15.130 --> 00:04:18.300
So here we have a timeline,
time running across the

00:04:18.300 --> 00:04:22.040
x-axis, and a sample is taken.

00:04:22.040 --> 00:04:24.110
And the call stack there
is represented with

00:04:24.110 --> 00:04:25.620
a rainbow of colors.

00:04:25.620 --> 00:04:29.930
And a millisecond ticks by, and
another sample is taken.

00:04:29.930 --> 00:04:31.990
And again, another millisecond
goes by,

00:04:31.990 --> 00:04:33.360
and a sample is taken.

00:04:33.360 --> 00:04:34.410
A millisecond goes by.

00:04:34.410 --> 00:04:36.990
Your program is paused
for an instant.

00:04:36.990 --> 00:04:40.230
The call stack is captured,
and it's logged.

00:04:40.230 --> 00:04:41.500
ILYA GRIGORIK: And the
millisecond is just a

00:04:41.500 --> 00:04:43.960
hard-wired value within
the V8, right?

00:04:43.960 --> 00:04:46.740
JOHN MCCUTCHAN: Yes, sampling
profilers can work on any

00:04:46.740 --> 00:04:49.860
frequency, some at a very,
very high frequency.

00:04:49.860 --> 00:04:55.230
Chrome's is at a reasonably high
frequency of 1,000 hertz,

00:04:55.230 --> 00:04:58.990
or once per millisecond.

00:04:58.990 --> 00:05:01.360
The issue with a sampling
profiler that I think a lot of

00:05:01.360 --> 00:05:05.160
people don't appreciate is that
in between these samples,

00:05:05.160 --> 00:05:08.170
you have no idea of what is
actually happening inside of

00:05:08.170 --> 00:05:09.240
your program.

00:05:09.240 --> 00:05:15.230
So you could very easily miss
or misreport a hot code path

00:05:15.230 --> 00:05:17.580
that just happens
to be executing

00:05:17.580 --> 00:05:18.790
off the sample interval.

00:05:18.790 --> 00:05:20.830
You can kind of go
out of phase.

00:05:20.830 --> 00:05:23.830
Your code can go out of phase
with how it's been sampled.

00:05:23.830 --> 00:05:25.330
ILYA GRIGORIK: Of course, I
guess one of the assumptions

00:05:25.330 --> 00:05:28.480
is if you sample long enough, or
if you make sure that your

00:05:28.480 --> 00:05:30.900
workload is representative,
you should be

00:05:30.900 --> 00:05:31.870
able to cache it.

00:05:31.870 --> 00:05:34.390
JOHN MCCUTCHAN: Yes,
absolutely.

00:05:34.390 --> 00:05:37.980
So long as your workload is
uniform and representative of

00:05:37.980 --> 00:05:41.930
what you're trying to measure,
if you sample over a long

00:05:41.930 --> 00:05:45.850
enough period of time, the
timing data that you get out

00:05:45.850 --> 00:05:49.920
of the sampling-based profiler
will approach that of reality.

00:05:49.920 --> 00:05:52.640
What you miss, though, with the
sampling-based profiler is

00:05:52.640 --> 00:05:54.400
that there's no sense of flow.

00:05:54.400 --> 00:05:56.865
There's no sense of I was here,
and now I'm here, and

00:05:56.865 --> 00:05:58.970
now I'm here because these
gaps are huge.

00:06:03.090 --> 00:06:06.400
So once the samples are
collected, and the data has

00:06:06.400 --> 00:06:10.430
been processed, what you get out
of it is two data points

00:06:10.430 --> 00:06:14.860
per function that was observed
executing in your program

00:06:14.860 --> 00:06:16.410
during the capture.

00:06:16.410 --> 00:06:20.060
The first is what is called a
leaf of a call stack, and this

00:06:20.060 --> 00:06:22.070
is the function that was at
the top of the stack.

00:06:22.070 --> 00:06:24.840
It's marked in blue here, which
is bar, exactly like the

00:06:24.840 --> 00:06:27.470
code snippet that we're
showing on the left.

00:06:27.470 --> 00:06:30.790
Underneath of bar are
two other functions.

00:06:30.790 --> 00:06:33.220
One is program, which is just
the main entry into the

00:06:33.220 --> 00:06:36.940
JavaScript code, and the
one above that is foo.

00:06:36.940 --> 00:06:39.830
These are what we call
inclusive functions.

00:06:39.830 --> 00:06:41.810
So they're not leafs,
but they're

00:06:41.810 --> 00:06:42.950
part of the call stack.

00:06:42.950 --> 00:06:46.290
And so they're, in a sense,
executing, but they're not

00:06:46.290 --> 00:06:47.410
doing the work.

00:06:47.410 --> 00:06:49.560
The function that's doing the
work is the leaf, or the blue

00:06:49.560 --> 00:06:50.520
function, in this case.

00:06:50.520 --> 00:06:52.370
ILYA GRIGORIK: So this is a
nested call in here, so foo is

00:06:52.370 --> 00:06:52.890
on the outside.

00:06:52.890 --> 00:06:56.100
So when we pause it outside of
bar, that's my exclusive time?

00:06:56.100 --> 00:06:57.960
JOHN MCCUTCHAN: Yes.

00:06:57.960 --> 00:07:00.970
You're doing work in bar, but
foo is responsible for

00:07:00.970 --> 00:07:01.640
triggering that.

00:07:01.640 --> 00:07:02.890
ILYA GRIGORIK: Yeah,
makes sense.

00:07:06.570 --> 00:07:08.990
JOHN MCCUTCHAN: So on the other
hand, we have structural

00:07:08.990 --> 00:07:13.510
CPU profilers, and what these
do is they record the entry

00:07:13.510 --> 00:07:16.940
and exit times of every function
in your program.

00:07:16.940 --> 00:07:20.150
So if we have the same program
here again, where foo gets

00:07:20.150 --> 00:07:23.980
called and then foo makes a
nested call to bar, we have

00:07:23.980 --> 00:07:27.070
our buffer, and we see, OK,
we've entered foo, so we're

00:07:27.070 --> 00:07:30.380
going to record the timestamp
which we've entered foo.

00:07:30.380 --> 00:07:33.470
We enter bar, so we record
that timestamp.

00:07:33.470 --> 00:07:35.870
We leave bar, and so
we record the time

00:07:35.870 --> 00:07:37.850
stamp of when we left.

00:07:37.850 --> 00:07:39.980
And now, we've left foo, and
we're back at the program.

00:07:43.460 --> 00:07:46.740
When this buffer is processed,
it gives us three data points

00:07:46.740 --> 00:07:47.860
per function.

00:07:47.860 --> 00:07:49.310
The first is inclusive time.

00:07:49.310 --> 00:07:53.040
This is the actual amount of
time a function was executing

00:07:53.040 --> 00:07:57.810
for, including time spent
inside if its children.

00:07:57.810 --> 00:07:59.900
And then there's exclusive time,
and again, these are

00:07:59.900 --> 00:08:02.980
analogous to exclusive and
inclusive samples.

00:08:02.980 --> 00:08:06.420
But samples, again, don't
represent time.

00:08:06.420 --> 00:08:09.960
So exclusive time is just the
time that the function was

00:08:09.960 --> 00:08:14.730
executing, so it's the amount
of time it's executing minus

00:08:14.730 --> 00:08:16.980
the amount of time that its
children were executing for.

00:08:16.980 --> 00:08:17.390
ILYA GRIGORIK: Right.

00:08:17.390 --> 00:08:20.120
So in this case, when you talk
about structural, the example

00:08:20.120 --> 00:08:22.980
that you showed, you were
recording the entry and exit

00:08:22.980 --> 00:08:25.870
points, which we'll just assume
that that somehow

00:08:25.870 --> 00:08:27.020
magically happens.

00:08:27.020 --> 00:08:29.955
So something has instrumented
our code to record this.

00:08:29.955 --> 00:08:30.790
JOHN MCCUTCHAN: Yes,
and we will get to

00:08:30.790 --> 00:08:31.940
how that magic works.

00:08:31.940 --> 00:08:34.700
ILYA GRIGORIK: Right, but I
guess the point here, before

00:08:34.700 --> 00:08:37.429
we even get into how we
instrument our code to gather

00:08:37.429 --> 00:08:40.740
the data, is that unlike the
sampling, here we are

00:08:40.740 --> 00:08:42.720
recording every instance
of every call.

00:08:42.720 --> 00:08:47.250
JOHN MCCUTCHAN: Yes, you're
logging every call and return,

00:08:47.250 --> 00:08:50.205
which happens at a much higher
frequency than 1,000 hertz.

00:08:50.205 --> 00:08:52.510
ILYA GRIGORIK: Right, so I would
have the exact count of

00:08:52.510 --> 00:08:55.510
how many times I've called foo
and bar, and I could even have

00:08:55.510 --> 00:08:57.090
the time deltas for each one.

00:08:57.090 --> 00:08:58.390
JOHN MCCUTCHAN: You could
have the time deltas.

00:08:58.390 --> 00:09:00.315
You could have the min, the max,
the standard deviation.

00:09:00.315 --> 00:09:03.590
I mean, you could gather a lot
of statistics about what's

00:09:03.590 --> 00:09:04.830
happening inside your program.

00:09:04.830 --> 00:09:06.550
ILYA GRIGORIK: Which I think
also kind of hints at

00:09:06.550 --> 00:09:08.570
something that we're going to
cover a little bit further,

00:09:08.570 --> 00:09:10.660
which is there are different
costs to doing

00:09:10.660 --> 00:09:11.271
this sort of profiling.

00:09:11.271 --> 00:09:13.980
JOHN MCCUTCHAN: Yes, because
the structural CP profiling

00:09:13.980 --> 00:09:16.660
occurs at a much higher
frequency, there's just

00:09:16.660 --> 00:09:18.550
naturally higher costs
associated with that.

00:09:18.550 --> 00:09:19.060
ILYA GRIGORIK: Right.

00:09:19.060 --> 00:09:20.555
OK, interesting.

00:09:20.555 --> 00:09:22.460
JOHN MCCUTCHAN: So yeah, just
in summary, we get the

00:09:22.460 --> 00:09:25.240
inclusive time, which is time
spent inside of the function

00:09:25.240 --> 00:09:26.210
and its children.

00:09:26.210 --> 00:09:29.070
Exclusive is discounting
the time spent

00:09:29.070 --> 00:09:30.550
inside of the children.

00:09:30.550 --> 00:09:32.600
And then the call count,
which is exact.

00:09:35.690 --> 00:09:38.850
So once you've found an area
of your program that is the

00:09:38.850 --> 00:09:41.520
bottleneck, and you want to
improve it, the goal of

00:09:41.520 --> 00:09:44.180
optimization is to minimize the

00:09:44.180 --> 00:09:45.550
inclusive time of a function.

00:09:45.550 --> 00:09:47.700
So that includes time spent
inside the children of the

00:09:47.700 --> 00:09:51.140
function, which is just
intuitively what we all

00:09:51.140 --> 00:09:52.470
understand optimization to be.

00:09:52.470 --> 00:09:53.900
ILYA GRIGORIK: Although
something that you said at the

00:09:53.900 --> 00:09:56.300
beginning, which is
once you've found

00:09:56.300 --> 00:09:57.080
the function, right?

00:09:57.080 --> 00:09:57.920
JOHN MCCUTCHAN: Once
you've found, yes.

00:09:57.920 --> 00:10:00.100
ILYA GRIGORIK: Right,
so how do we find?

00:10:00.100 --> 00:10:01.545
JOHN MCCUTCHAN: Well, we're
going to get into that.

00:10:01.545 --> 00:10:04.580
We're going to discuss how
we can figure that out.

00:10:04.580 --> 00:10:06.850
But of course, it involves
using a sampling and a

00:10:06.850 --> 00:10:07.860
structural profiler.

00:10:07.860 --> 00:10:09.110
ILYA GRIGORIK: Right.

00:10:11.860 --> 00:10:12.480
JOHN MCCUTCHAN: So the question

00:10:12.480 --> 00:10:14.640
becomes, what do you use?

00:10:14.640 --> 00:10:16.900
And the answer to that question
is you use both.

00:10:16.900 --> 00:10:20.370
They're both very valuable tools
to have in your toolbox.

00:10:20.370 --> 00:10:23.110
Of course, they both come with
their own pros and cons.

00:10:23.110 --> 00:10:26.400
So as I've already touched on,
sampling doesn't actually give

00:10:26.400 --> 00:10:28.060
you any measurement of time.

00:10:28.060 --> 00:10:31.550
It's giving you a measurement
at an instant, whereas

00:10:31.550 --> 00:10:35.400
structural or instrumenting
profiling, it's built around

00:10:35.400 --> 00:10:37.650
the idea of measuring
slices of time.

00:10:37.650 --> 00:10:39.850
So you get an exact measurement
of time.

00:10:39.850 --> 00:10:40.280
[INAUDIBLE]

00:10:40.280 --> 00:10:43.370
you can get an approximate
[INAUDIBLE], kind of attribute

00:10:43.370 --> 00:10:49.400
a weight to every sample and
extrapolate to time.

00:10:49.400 --> 00:10:53.220
Invocation can-- again, it's
approximate with sampling,

00:10:53.220 --> 00:10:54.490
because it's only once every

00:10:54.490 --> 00:10:56.530
millisecond that we're sampling.

00:10:56.530 --> 00:10:59.820
So you could be called 1,000
times between those two points

00:10:59.820 --> 00:11:01.290
in time and miss them.

00:11:01.290 --> 00:11:03.930
With structural,
you get exact.

00:11:03.930 --> 00:11:05.110
Something that you
were hinting at,

00:11:05.110 --> 00:11:06.790
which is the overhead.

00:11:06.790 --> 00:11:09.080
Sampling has a very,
very low overhead.

00:11:09.080 --> 00:11:10.130
It's guaranteed.

00:11:10.130 --> 00:11:12.300
Because it's at a fixed
frequency, your program is

00:11:12.300 --> 00:11:15.800
paused, the call stack is
captured, and it's resumed.

00:11:15.800 --> 00:11:16.210
ILYA GRIGORIK: Right,
so this is

00:11:16.210 --> 00:11:18.850
specifically for a CPU overhead.

00:11:18.850 --> 00:11:21.310
JOHN MCCUTCHAN: Yes,
CPU overhead.

00:11:21.310 --> 00:11:23.600
Whereas structural, because
it's at such a higher

00:11:23.600 --> 00:11:26.440
frequency, the data being
collected in structural

00:11:26.440 --> 00:11:28.140
profiling is cheaper
to compute.

00:11:28.140 --> 00:11:30.050
It's cheaper to compute
the time than to

00:11:30.050 --> 00:11:31.590
extract the call stack.

00:11:31.590 --> 00:11:33.900
But the rate at which you're
doing that work is so much

00:11:33.900 --> 00:11:35.160
higher with the structural
profiling.

00:11:35.160 --> 00:11:37.410
ILYA GRIGORIK: Although even
that depends, because--

00:11:37.410 --> 00:11:39.370
so in the example that you
showed earlier, we were

00:11:39.370 --> 00:11:42.060
recording every entry to every
function, or every entry and

00:11:42.060 --> 00:11:42.940
every exit.

00:11:42.940 --> 00:11:46.840
But if I only care about one
specific piece of code, and I

00:11:46.840 --> 00:11:51.410
just need an entry and exit
point, then if that's the only

00:11:51.410 --> 00:11:53.332
thing I'm instrumenting, then
maybe that's not that bad to

00:11:53.332 --> 00:11:53.730
begin with.

00:11:53.730 --> 00:11:55.030
JOHN MCCUTCHAN: Yeah,
absolutely.

00:11:55.030 --> 00:11:58.570
In a manually instrumented
system, you can reduce and

00:11:58.570 --> 00:12:00.470
minimize the overhead of
structural profiling

00:12:00.470 --> 00:12:02.150
by moving it around.

00:12:02.150 --> 00:12:04.710
ILYA GRIGORIK: And depending
on which mechanism you use,

00:12:04.710 --> 00:12:07.910
you could end up in a scenario
where it could be, in fact,

00:12:07.910 --> 00:12:10.130
incredibly expensive.

00:12:10.130 --> 00:12:11.440
Then your code may
actually suffer

00:12:11.440 --> 00:12:13.580
from an observer effect.

00:12:13.580 --> 00:12:15.290
Just because you're looking
at it, when this--

00:12:15.290 --> 00:12:16.420
JOHN MCCUTCHAN: It's
running slower.

00:12:16.420 --> 00:12:18.660
ILYA GRIGORIK: Right, it's
exhibiting completely

00:12:18.660 --> 00:12:20.290
different behaviors than
from what you're

00:12:20.290 --> 00:12:21.910
seeing in the wild.

00:12:21.910 --> 00:12:24.100
JOHN MCCUTCHAN: Yeah, I mean
that's something that, just in

00:12:24.100 --> 00:12:27.710
general with all optimization
and kind of measurement

00:12:27.710 --> 00:12:30.740
techniques with programs, is
sometimes the very act of

00:12:30.740 --> 00:12:33.700
measuring and observing the
state of your program impacts

00:12:33.700 --> 00:12:36.750
not only the behavior
but the performance.

00:12:36.750 --> 00:12:38.710
ILYA GRIGORIK: Those are always
fun ones to try out.

00:12:38.710 --> 00:12:40.970
JOHN MCCUTCHAN: Yeah,
how can you subtract

00:12:40.970 --> 00:12:42.150
that from the data?

00:12:42.150 --> 00:12:44.140
I don't know.

00:12:44.140 --> 00:12:50.020
So overhead, very low sampling,
high to low with

00:12:50.020 --> 00:12:52.380
structural, but you're in
control with structural

00:12:52.380 --> 00:12:55.650
profiling, how high
that overhead is.

00:12:55.650 --> 00:12:59.920
In terms of accuracy, it's
marked with asterisks.

00:12:59.920 --> 00:13:01.780
It's a bit of a gray area.

00:13:01.780 --> 00:13:03.780
It's hard to say which
one is more accurate.

00:13:03.780 --> 00:13:05.260
I mean, sampling--

00:13:05.260 --> 00:13:08.410
it's just measuring samples, so
it's incredibly accurate at

00:13:08.410 --> 00:13:09.940
measuring samples.

00:13:09.940 --> 00:13:12.950
But a lot of people have a
tendency to extract from

00:13:12.950 --> 00:13:18.010
samples time, and that's where
it becomes very inaccurate.

00:13:18.010 --> 00:13:20.560
ILYA GRIGORIK: And for
structural, if you're not

00:13:20.560 --> 00:13:22.685
instrumenting the right thing,
then you may have missed the

00:13:22.685 --> 00:13:23.320
actual picture.

00:13:23.320 --> 00:13:24.490
JOHN MCCUTCHAN: Yes, exactly.

00:13:24.490 --> 00:13:26.290
ILYA GRIGORIK: And if you
instrument everything, then

00:13:26.290 --> 00:13:29.410
you may actually suffer from
this observer effect, so it

00:13:29.410 --> 00:13:31.250
really depends.

00:13:31.250 --> 00:13:34.090
The answer is it always
depends for accuracy.

00:13:34.090 --> 00:13:35.610
JOHN MCCUTCHAN: And use both.

00:13:35.610 --> 00:13:36.170
ILYA GRIGORIK: And use both.

00:13:36.170 --> 00:13:39.630
JOHN MCCUTCHAN: And iterate
and play with it.

00:13:39.630 --> 00:13:42.990
So sampling has one added
benefit, which is that it

00:13:42.990 --> 00:13:45.400
requires no modification
to your program.

00:13:45.400 --> 00:13:47.440
You don't have to know anything
about the structure

00:13:47.440 --> 00:13:47.720
of your program.

00:13:47.720 --> 00:13:52.240
You don't have to know where a
good place to lay markers are,

00:13:52.240 --> 00:13:52.880
and it just works.

00:13:52.880 --> 00:13:54.990
You could go to any website,
run the sampling profiling,

00:13:54.990 --> 00:13:56.290
and see where they're
spending their time.

00:13:56.290 --> 00:13:58.580
ILYA GRIGORIK: So that's just a
service provider by the VM?

00:13:58.580 --> 00:13:59.060
JOHN MCCUTCHAN: Yes.

00:13:59.060 --> 00:13:59.730
ILYA GRIGORIK: We'll
pause you.

00:13:59.730 --> 00:14:01.100
We'll take a snapshot.

00:14:01.100 --> 00:14:02.040
We'll move on.

00:14:02.040 --> 00:14:04.810
JOHN MCCUTCHAN: While it is
possible for a VM to also

00:14:04.810 --> 00:14:08.400
offer a structural and
instrumenting profiling as a

00:14:08.400 --> 00:14:10.290
service, V8 does not.

00:14:10.290 --> 00:14:11.840
ILYA GRIGORIK: Right,
right, so the

00:14:11.840 --> 00:14:13.410
specifics of V8, actually.

00:14:13.410 --> 00:14:15.820
JOHN MCCUTCHAN: Yes.

00:14:15.820 --> 00:14:20.510
So in summary, instrumenting
profilers give you very fine

00:14:20.510 --> 00:14:23.910
control over like where and what
you're measuring, but it

00:14:23.910 --> 00:14:25.710
requires that you have implicit

00:14:25.710 --> 00:14:26.890
knowledge of the code base.

00:14:26.890 --> 00:14:31.550
And you also have trouble
instrumenting things that you

00:14:31.550 --> 00:14:32.380
haven't written.

00:14:32.380 --> 00:14:34.330
If you have a library or a
system call that you're

00:14:34.330 --> 00:14:36.760
making, you don't want to start
going in and laying

00:14:36.760 --> 00:14:37.150
markers across it.

00:14:37.150 --> 00:14:38.830
ILYA GRIGORIK: If I'm debugging
somebody's site, if

00:14:38.830 --> 00:14:40.630
I just pulled that up, and it's
running kind of slow, and

00:14:40.630 --> 00:14:43.020
I'm curious, I don't
have the ability to

00:14:43.020 --> 00:14:43.760
instrument the code.

00:14:43.760 --> 00:14:44.880
JOHN MCCUTCHAN: Correct.

00:14:44.880 --> 00:14:47.320
It's kind of a non-starter.

00:14:47.320 --> 00:14:48.440
ILYA GRIGORIK: So speaking
of which--

00:14:48.440 --> 00:14:52.090
so I guess we should cover
very quickly the sampling

00:14:52.090 --> 00:14:53.370
profiler first.

00:14:53.370 --> 00:14:55.920
And the sampling profiler is
built into the Chrome dev

00:14:55.920 --> 00:14:59.260
tools, so if you open up your
dev tools, head into Profiles,

00:14:59.260 --> 00:15:02.610
you can click Start and
record a sample.

00:15:02.610 --> 00:15:03.990
So actually, let's
do just that.

00:15:03.990 --> 00:15:07.720
So we have the V8 Benchmark
Suite here, and I'm going to

00:15:07.720 --> 00:15:08.840
refresh the page.

00:15:08.840 --> 00:15:13.480
And it's actually running the
suite here, and I'm going to

00:15:13.480 --> 00:15:14.640
start sampling.

00:15:14.640 --> 00:15:18.150
So we'll let it run for
a couple of seconds.

00:15:18.150 --> 00:15:22.130
We'll stop, and here is
the actual view of

00:15:22.130 --> 00:15:23.280
the sampling profiler.

00:15:23.280 --> 00:15:27.350
So Chrome was pausing the VM
once every millisecond,

00:15:27.350 --> 00:15:29.070
capturing the stack trace,
and this is what

00:15:29.070 --> 00:15:30.200
we're seeing here.

00:15:30.200 --> 00:15:30.720
JOHN MCCUTCHAN: Absolutely.

00:15:30.720 --> 00:15:35.190
ILYA GRIGORIK: And there's
no time sequence here.

00:15:35.190 --> 00:15:37.100
You can't really see what
was executing when.

00:15:37.100 --> 00:15:41.390
It's just showing you that, hey,
35% of the total time was

00:15:41.390 --> 00:15:42.485
in this function called--

00:15:42.485 --> 00:15:44.700
JOHN MCCUTCHAN: That's a leaf
function, too, actually.

00:15:44.700 --> 00:15:47.090
ILYA GRIGORIK: Right, and you
don't really get that sense.

00:15:47.090 --> 00:15:49.500
So you're familiar with some
of this code, and you can

00:15:49.500 --> 00:15:50.350
figure that out.

00:15:50.350 --> 00:15:51.790
JOHN MCCUTCHAN: Yes.

00:15:51.790 --> 00:15:55.130
Yeah, it's giving you, like,
35%, but what's really missing

00:15:55.130 --> 00:15:56.390
from this is flow.

00:15:56.390 --> 00:15:57.040
That's exactly it.

00:15:57.040 --> 00:15:59.510
You don't know what led
to that computation.

00:15:59.510 --> 00:16:00.010
ILYA GRIGORIK: Right.

00:16:00.010 --> 00:16:03.110
So we do provide a little bit
of help in that regard.

00:16:03.110 --> 00:16:06.200
So we can actually flip here
and look at the tree view,

00:16:06.200 --> 00:16:09.190
which is going to reorganize
all the data in here.

00:16:09.190 --> 00:16:12.900
And you can see that there's
some kind of

00:16:12.900 --> 00:16:15.300
V8-specific stuff in here.

00:16:15.300 --> 00:16:18.330
And then we can go to Run Step,
and we can navigate

00:16:18.330 --> 00:16:22.240
basically down into this tree
and see what's being called,

00:16:22.240 --> 00:16:24.060
kind of the call stack,
if you will.

00:16:24.060 --> 00:16:26.150
But now, it's kind of hard to
figure out where is the actual

00:16:26.150 --> 00:16:27.670
time being spent, really.

00:16:27.670 --> 00:16:29.330
JOHN MCCUTCHAN: Yeah, I mean,
you kind of have to fan and

00:16:29.330 --> 00:16:32.310
drill into this large tree,
and then you find your hot

00:16:32.310 --> 00:16:33.110
spot, maybe.

00:16:33.110 --> 00:16:35.700
ILYA GRIGORIK: So the
tool is there.

00:16:35.700 --> 00:16:38.100
It is useful, so another
tip that I'll

00:16:38.100 --> 00:16:39.390
show is you can actually--

00:16:39.390 --> 00:16:42.870
these trees can be very deep and
very hard to work with, so

00:16:42.870 --> 00:16:45.250
you can actually focus on a
specific one and kind of

00:16:45.250 --> 00:16:46.280
continue drilling down.

00:16:46.280 --> 00:16:47.530
You can go back.

00:16:47.530 --> 00:16:50.010
So this functionality's here.

00:16:50.010 --> 00:16:52.960
The one thing that I really
like is you can load and

00:16:52.960 --> 00:16:54.385
export these profiles,
as well.

00:16:54.385 --> 00:16:55.650
JOHN MCCUTCHAN: Yeah,
that's so important.

00:16:55.650 --> 00:16:58.230
If you want to report a
performance problem to

00:16:58.230 --> 00:17:01.660
someone, it's best to show up
with a capture in some way.

00:17:01.660 --> 00:17:03.640
ILYA GRIGORIK: That's right,
don't just take a screenshot

00:17:03.640 --> 00:17:04.800
and point an arrow.

00:17:04.800 --> 00:17:05.359
I know I've done that.

00:17:05.359 --> 00:17:07.869
JOHN MCCUTCHAN: With the
screenshot, you end up giving

00:17:07.869 --> 00:17:08.560
it to the developer.

00:17:08.560 --> 00:17:10.319
And the developer's like, oh,
I really wish I could see

00:17:10.319 --> 00:17:13.109
what's under that leaf, which
you didn't expand, and the

00:17:13.109 --> 00:17:13.579
data's gone.

00:17:13.579 --> 00:17:15.920
ILYA GRIGORIK: Exactly, so
export it, attach it to your

00:17:15.920 --> 00:17:19.290
bug report, attach it to
your email, load it

00:17:19.290 --> 00:17:21.300
later into dev tools.

00:17:21.300 --> 00:17:23.300
Even if you just don't have the
time right now to analyze

00:17:23.300 --> 00:17:25.990
it, you can save it and
come back to it later.

00:17:25.990 --> 00:17:30.180
So that's a very brief
overview of--

00:17:30.180 --> 00:17:31.560
JOHN MCCUTCHAN: Yeah, we're
going to go into a little bit

00:17:31.560 --> 00:17:34.000
more detail about the
differences between these two

00:17:34.000 --> 00:17:35.010
as the talk goes on.

00:17:35.010 --> 00:17:35.340
ILYA GRIGORIK: Right.

00:17:35.340 --> 00:17:38.470
So I mentioned some of these,
and I encourage you guys to

00:17:38.470 --> 00:17:40.640
play with the V8 Benchmark
Suite.

00:17:40.640 --> 00:17:43.310
It's a great place to kind of
get a really nice workload,

00:17:43.310 --> 00:17:46.320
where you can see and figure
out what's going on.

00:17:46.320 --> 00:17:48.600
Definitely play with the options
at the bottom, the

00:17:48.600 --> 00:17:49.620
tools there.

00:17:49.620 --> 00:17:51.120
It's good stuff.

00:17:51.120 --> 00:17:55.000
And now, let's look at
Chrome://tracing.

00:17:55.000 --> 00:17:57.430
I don't think many people
actually, first, know about

00:17:57.430 --> 00:18:00.980
Chrome://tracing and ever
connected debugging, or

00:18:00.980 --> 00:18:02.650
profiling, with
Chrome://tracing.

00:18:02.650 --> 00:18:05.800
JOHN MCCUTCHAN: Yeah, so
Chrome://tracing is a--

00:18:05.800 --> 00:18:09.590
it's a hidden site built into
Chrome, like Chrome://memory

00:18:09.590 --> 00:18:12.030
or about:GPU or something
like that.

00:18:12.030 --> 00:18:16.030
When you navigate to Chrome
colon slash slash tracing, you

00:18:16.030 --> 00:18:19.050
are presented with this
incredibly deep and detailed

00:18:19.050 --> 00:18:21.520
view into the guts of what
Chrome is doing.

00:18:21.520 --> 00:18:23.320
So it's kind of overwhelming
at first, you look at it,

00:18:23.320 --> 00:18:23.970
you're like, holy--

00:18:23.970 --> 00:18:27.310
I can't make heads or tails
of what this is.

00:18:27.310 --> 00:18:30.140
And in sense, that's partially
because it's not really

00:18:30.140 --> 00:18:33.440
designed for the end user
to be poking around.

00:18:33.440 --> 00:18:38.770
But what you can do is you can
actually inject structural or

00:18:38.770 --> 00:18:42.030
instrumenting profiling data
from your own JavaScript code

00:18:42.030 --> 00:18:44.020
into the Chrome://tracing
view.

00:18:44.020 --> 00:18:46.690
And so that gives you a really
interesting timeline view of

00:18:46.690 --> 00:18:50.180
what your program is doing,
showing the flow across time.

00:18:50.180 --> 00:18:53.840
But the added benefit is that it
actually frames it into the

00:18:53.840 --> 00:18:57.710
larger Chrome context, which is
completely missing from the

00:18:57.710 --> 00:18:58.610
sample-based profile.

00:18:58.610 --> 00:19:00.450
ILYA GRIGORIK: The history
is also interesting, So

00:19:00.450 --> 00:19:03.400
Chrome://tracing was built by
Chrome developers for Chrome

00:19:03.400 --> 00:19:04.170
developers.

00:19:04.170 --> 00:19:06.900
JOHN MCCUTCHAN: Yes,
specifically for the GPU

00:19:06.900 --> 00:19:09.420
developers who want to optimize
the low-level GPU

00:19:09.420 --> 00:19:09.810
performance.

00:19:09.810 --> 00:19:11.660
ILYA GRIGORIK: Right, so if
you're building a game, you're

00:19:11.660 --> 00:19:13.920
trying to figure out what's
going on in my render stack

00:19:13.920 --> 00:19:15.970
and all the rest, that's
definitely a tool that you

00:19:15.970 --> 00:19:17.220
should be familiar with.

00:19:17.220 --> 00:19:20.040
But I think in the process of
just using this tool, we've

00:19:20.040 --> 00:19:22.550
kind of realized that there's
these accidental discoveries

00:19:22.550 --> 00:19:24.350
of, like, well, if we instrument
our JavaScript

00:19:24.350 --> 00:19:28.270
code, and we provide a way to
show that here, it allows some

00:19:28.270 --> 00:19:31.820
very powerful debugging
capabilities.

00:19:31.820 --> 00:19:32.510
JOHN MCCUTCHAN: Absolutely.

00:19:32.510 --> 00:19:34.950
I mean, you can go in and
really have a deep

00:19:34.950 --> 00:19:37.200
understanding of why your game's
running at 30 frames

00:19:37.200 --> 00:19:39.670
per second rather than six.

00:19:39.670 --> 00:19:40.910
ILYA GRIGORIK: Right.

00:19:40.910 --> 00:19:44.510
JOHN MCCUTCHAN: But so let's
step through this, but before

00:19:44.510 --> 00:19:46.330
I do that, I just want to point
out that, while it is

00:19:46.330 --> 00:19:48.980
very overwhelming, you can
really narrow this view down.

00:19:48.980 --> 00:19:51.920
You can strip away all of
the cruft data that

00:19:51.920 --> 00:19:54.080
isn't relevant to you.

00:19:54.080 --> 00:19:56.700
So keep that in mind when you're
looking at it in the

00:19:56.700 --> 00:19:57.500
first place.

00:19:57.500 --> 00:19:58.820
ILYA GRIGORIK: We'll show
you some tips, actually,

00:19:58.820 --> 00:19:59.490
a little bit later.

00:19:59.490 --> 00:20:00.740
JOHN MCCUTCHAN: Yeah.

00:20:02.720 --> 00:20:04.550
So how do you use
Chrome://tracing?

00:20:04.550 --> 00:20:06.170
The first thing you have to
do, which we've kind of

00:20:06.170 --> 00:20:09.350
touched upon, is that you have
to instrument your code.

00:20:09.350 --> 00:20:12.410
And the way you instrument
your code in order to

00:20:12.410 --> 00:20:14.470
interface with Chrome://tracing
is by making

00:20:14.470 --> 00:20:18.310
calls to console.time
and console.timeEnd.

00:20:18.310 --> 00:20:22.420
You pass in a string parameter
representing the name of the

00:20:22.420 --> 00:20:25.640
time period that you
want to measure.

00:20:25.640 --> 00:20:29.580
So you can see here, we have
our trusty, simple example,

00:20:29.580 --> 00:20:32.480
where foo gets called,
foo calls bar,

00:20:32.480 --> 00:20:34.110
and bar does nothing.

00:20:34.110 --> 00:20:37.350
And you can see that it's been
instrumented both at the entry

00:20:37.350 --> 00:20:40.400
and exit points of
foo and bar.

00:20:40.400 --> 00:20:43.570
This will allow us to understand
when foo begins

00:20:43.570 --> 00:20:45.320
executing and when
it finishes, and

00:20:45.320 --> 00:20:46.260
you can nest them.

00:20:46.260 --> 00:20:48.440
This is a very important
concept, is that

00:20:48.440 --> 00:20:49.190
it's not just one.

00:20:49.190 --> 00:20:51.560
You could have as many nested
as you want, and

00:20:51.560 --> 00:20:53.710
Chrome://tracing will make sense
of it and display it to

00:20:53.710 --> 00:20:56.200
you in that hierarchy.

00:20:56.200 --> 00:20:58.110
So there's lots of different
types of instrumentation.

00:20:58.110 --> 00:21:00.480
We've kind of touched upon the
fact that you have to manually

00:21:00.480 --> 00:21:03.830
instrument your code with V8
in order to interact with

00:21:03.830 --> 00:21:05.020
Chrome://tracing.

00:21:05.020 --> 00:21:06.210
But some systems--

00:21:06.210 --> 00:21:09.710
I think Firefox's profiler
does automatic

00:21:09.710 --> 00:21:12.420
instrumentation, so it's just
something to keep in mind,

00:21:12.420 --> 00:21:15.770
that some tools will do this
automatically for you, both at

00:21:15.770 --> 00:21:17.100
compile time and run time.

00:21:17.100 --> 00:21:18.990
ILYA GRIGORIK: Yeah, so
actually, just before this, we

00:21:18.990 --> 00:21:21.480
actually looked at Firefox,
at Firebug specifically.

00:21:21.480 --> 00:21:24.550
And when you run Profile, when
you look at the output, it'll

00:21:24.550 --> 00:21:27.410
actually tell you the exact
call count, which is

00:21:27.410 --> 00:21:29.220
immediately a tip off that's
saying that it's

00:21:29.220 --> 00:21:30.980
a structural profiler.

00:21:30.980 --> 00:21:33.740
So it's much heavier, but it's
giving you a little bit of a

00:21:33.740 --> 00:21:34.650
different view.

00:21:34.650 --> 00:21:38.600
So keep in mind that these, the
way the profiling is done

00:21:38.600 --> 00:21:41.750
in different browsers
is also different.

00:21:41.750 --> 00:21:43.790
JOHN MCCUTCHAN: Oh, totally.

00:21:43.790 --> 00:21:46.590
Yeah, I mean, they couldn't
be more different.

00:21:46.590 --> 00:21:50.570
The Chrome Developer Tools
profiler is a sample-based

00:21:50.570 --> 00:21:52.650
profiler, and the Firebug
profiler is

00:21:52.650 --> 00:21:53.700
a structural profiler.

00:21:53.700 --> 00:21:55.270
And it does automatic
instrumentation.

00:21:55.270 --> 00:21:57.640
ILYA GRIGORIK: And it's not
a case of either one.

00:21:57.640 --> 00:22:00.550
You really need both, which is
what I like about having

00:22:00.550 --> 00:22:01.610
access to both here.

00:22:01.610 --> 00:22:02.530
JOHN MCCUTCHAN: Yeah,
it's great.

00:22:02.530 --> 00:22:04.840
It's all on one hood here.

00:22:04.840 --> 00:22:09.380
So you might wonder about what
are the costs of all of these

00:22:09.380 --> 00:22:10.880
markers and instrumentation,
then?

00:22:10.880 --> 00:22:13.400
We keep hinting that there
is a cost to it.

00:22:13.400 --> 00:22:15.960
It's important to note that
when Chrome://tracing is

00:22:15.960 --> 00:22:17.820
disabled and the developer
console is

00:22:17.820 --> 00:22:20.090
closed, the cost is almost--

00:22:20.090 --> 00:22:21.140
it's negligible.

00:22:21.140 --> 00:22:22.450
You won't be able
to measure it.

00:22:22.450 --> 00:22:24.280
It's OK to leave
them in there.

00:22:24.280 --> 00:22:29.050
But when Chrome://tracing is on,
a cost starts to show up,

00:22:29.050 --> 00:22:31.740
and it's about 0.01
milliseconds

00:22:31.740 --> 00:22:32.720
measured on my machine.

00:22:32.720 --> 00:22:35.070
So everyone's machine is going
to be slightly different.

00:22:35.070 --> 00:22:42.187
But that allows me to do about
100 markers per millisecond.

00:22:42.187 --> 00:22:42.941
ILYA GRIGORIK: Right.

00:22:42.941 --> 00:22:44.380
Yeah, that makes sense.

00:22:44.380 --> 00:22:48.470
Although, I'll still say that as
a best practice, you should

00:22:48.470 --> 00:22:50.990
probably remove the
console.times from your

00:22:50.990 --> 00:22:52.720
production code, anyway.

00:22:52.720 --> 00:22:57.340
Even though it's basically inert
code, maybe on IE6 or

00:22:57.340 --> 00:22:59.880
what have you, that may actually
throw an error

00:22:59.880 --> 00:23:01.660
because it has no idea
what this is.

00:23:01.660 --> 00:23:02.500
JOHN MCCUTCHAN: Absolutely.

00:23:02.500 --> 00:23:04.300
ILYA GRIGORIK: So you should
probably strip it out, and

00:23:04.300 --> 00:23:05.610
there's a couple of different
ways you could do that.

00:23:05.610 --> 00:23:07.720
I mean, you could
try and do a--

00:23:07.720 --> 00:23:09.770
JOHN MCCUTCHAN: What I do is I
have something called Push and

00:23:09.770 --> 00:23:14.030
Pop, and you can just replace
the body of those functions

00:23:14.030 --> 00:23:16.520
for your production
code with nothing.

00:23:16.520 --> 00:23:18.470
ILYA GRIGORIK: Right, right, so
just wrap your own function

00:23:18.470 --> 00:23:18.700
around the--

00:23:18.700 --> 00:23:20.610
JOHN MCCUTCHAN: Yeah, wrap
console.time and

00:23:20.610 --> 00:23:21.310
console.timeEnd.

00:23:21.310 --> 00:23:22.640
Don't call them directly.

00:23:22.640 --> 00:23:23.480
ILYA GRIGORIK: Sure, sure.

00:23:23.480 --> 00:23:26.640
JOHN MCCUTCHAN: So you have a
very simple one place to short

00:23:26.640 --> 00:23:28.380
circuit all of that logic
and clear it out.

00:23:28.380 --> 00:23:29.780
ILYA GRIGORIK: Alternatively,
if you're using something

00:23:29.780 --> 00:23:33.150
like, let's say, Closure you
could actually build a filter

00:23:33.150 --> 00:23:35.280
in there, so you could go in
and kind of strip it out.

00:23:35.280 --> 00:23:38.010
Or it can be even more advanced,
something like a

00:23:38.010 --> 00:23:38.680
[INAUDIBLE]

00:23:38.680 --> 00:23:42.190
with a JavaScript parser could
actually get the AST, just

00:23:42.190 --> 00:23:44.170
extract it, and rebuild it.

00:23:44.170 --> 00:23:46.140
I mean, this is kind of going
into the crazy land, but--

00:23:46.140 --> 00:23:49.000
JOHN MCCUTCHAN: Well, yeah but
I mean, I think as JavaScript

00:23:49.000 --> 00:23:53.310
applications become like that
big and that complex, these

00:23:53.310 --> 00:23:55.870
sorts of tools will just
employed regularly.

00:23:55.870 --> 00:23:57.760
So why not just apply
to this [INAUDIBLE]?

00:23:57.760 --> 00:23:59.670
ILYA GRIGORIK: And I think it's
important to invest into

00:23:59.670 --> 00:24:03.050
these kinds of tools for your
team, because you should have

00:24:03.050 --> 00:24:05.150
this code in there, because it
makes everything so much

00:24:05.150 --> 00:24:07.440
simpler to debug, monitor
over time, [INAUDIBLE].

00:24:07.440 --> 00:24:10.380
JOHN MCCUTCHAN: Yeah, I mean if
you can find a way to leave

00:24:10.380 --> 00:24:14.250
the code in there, like maybe
wrapped in some way so that,

00:24:14.250 --> 00:24:16.620
hey, I've noticed something
going slow, why don't I just

00:24:16.620 --> 00:24:19.540
click a button and get a really
good capture without

00:24:19.540 --> 00:24:21.250
having to worry about going
in and laying out the

00:24:21.250 --> 00:24:22.685
instrumentation again.

00:24:22.685 --> 00:24:26.160
Yeah, I think best practice,
find a way to make sure that

00:24:26.160 --> 00:24:29.940
that doesn't get called
in production.

00:24:29.940 --> 00:24:32.526
ILYA GRIGORIK: Having your debug
data in production is

00:24:32.526 --> 00:24:33.040
never a good thing.

00:24:33.040 --> 00:24:34.340
JOHN MCCUTCHAN: Yes.

00:24:34.340 --> 00:24:36.370
So we've instrumented
the code.

00:24:36.370 --> 00:24:38.920
We've added the calls to
console.time and timeEnd, and

00:24:38.920 --> 00:24:41.060
now, we want to go over to
Chrome://tracing and start

00:24:41.060 --> 00:24:42.600
recording a trace.

00:24:42.600 --> 00:24:44.950
When you go there, it's going to
be essentially a blank page

00:24:44.950 --> 00:24:47.440
except there'll be a toolbar
along the top with the Record

00:24:47.440 --> 00:24:50.720
button there, indicated
with the red arrow.

00:24:50.720 --> 00:24:53.860
Immediately after pressing
Record, you switch over to

00:24:53.860 --> 00:24:54.640
your application.

00:24:54.640 --> 00:24:56.360
It's important that you actually
interact with your

00:24:56.360 --> 00:24:58.860
application while capturing
it, because Chrome will

00:24:58.860 --> 00:25:01.280
throttle down your page
if it's not present.

00:25:01.280 --> 00:25:01.980
ILYA GRIGORIK: Right,
background

00:25:01.980 --> 00:25:03.250
pages get a lower priority.

00:25:03.250 --> 00:25:05.580
JOHN MCCUTCHAN: Yes, so you
want to be playing with it

00:25:05.580 --> 00:25:07.690
exactly as a user would be.

00:25:07.690 --> 00:25:11.030
After a while, you'll switch
back to the Chrome://tracing

00:25:11.030 --> 00:25:14.020
tab and click the Stop
Tracing button there.

00:25:14.020 --> 00:25:17.010
And as you can see, it indicates
how much of the

00:25:17.010 --> 00:25:17.990
buffer you've used.

00:25:17.990 --> 00:25:21.080
I don't know what the absolute
size of the buffer is, but

00:25:21.080 --> 00:25:22.430
it's quite large.

00:25:22.430 --> 00:25:24.420
ILYA GRIGORIK: It's quite large,
but the amount of data

00:25:24.420 --> 00:25:27.140
that this actually collects
is ginormous.

00:25:27.140 --> 00:25:29.300
JOHN MCCUTCHAN: Yes,
it really is.

00:25:29.300 --> 00:25:30.620
ILYA GRIGORIK: So don't be--

00:25:30.620 --> 00:25:34.150
I've run most of my traces for
on the order of maybe 10

00:25:34.150 --> 00:25:35.960
seconds, 20 seconds at most.

00:25:35.960 --> 00:25:36.870
Right?

00:25:36.870 --> 00:25:38.490
JOHN MCCUTCHAN: That's about
it, because the nice thing

00:25:38.490 --> 00:25:41.930
about a structural profiling
is you only need one frame.

00:25:41.930 --> 00:25:44.390
Assuming the frame is
representative of the average

00:25:44.390 --> 00:25:46.790
frame, that's all the
data you need.

00:25:46.790 --> 00:25:49.090
Where on the other side, a
sample-based profiler, the

00:25:49.090 --> 00:25:52.980
longer you let it run, the more
it's going to approach

00:25:52.980 --> 00:25:54.300
the reality of timings.

00:25:54.300 --> 00:25:56.830
ILYA GRIGORIK: Right, so when
Chrome is actually tracing

00:25:56.830 --> 00:25:58.850
this, it's actually storing all
this data in memory just

00:25:58.850 --> 00:26:00.800
because it's so much data.

00:26:00.800 --> 00:26:03.720
And I think we'll talk about it
later, but-- actually, we

00:26:03.720 --> 00:26:06.390
have it in the screenshot here--
you can also export

00:26:06.390 --> 00:26:08.770
this trace and then
load it up later.

00:26:08.770 --> 00:26:11.810
So same story, you can
attach it to a bug

00:26:11.810 --> 00:26:12.690
report, which is great.

00:26:12.690 --> 00:26:13.090
JOHN MCCUTCHAN: Please do.

00:26:13.090 --> 00:26:15.580
If you're going to file a
performance bug [? report, ?]

00:26:15.580 --> 00:26:20.520
provide more data, because it
gives the developers the input

00:26:20.520 --> 00:26:22.020
they need to solve
the problem.

00:26:22.020 --> 00:26:24.280
If you just send a screenshot,
it's like, it's slow.

00:26:24.280 --> 00:26:28.110
Well, you're probably right,
but how does that help the

00:26:28.110 --> 00:26:29.470
developer solve the problem?

00:26:29.470 --> 00:26:32.070
ILYA GRIGORIK: Right, perfect.

00:26:32.070 --> 00:26:36.900
JOHN MCCUTCHAN: All right, so
we've done a capture now, and

00:26:36.900 --> 00:26:37.520
we see this.

00:26:37.520 --> 00:26:38.610
Again, it's intimidating.

00:26:38.610 --> 00:26:41.040
It's wild.

00:26:41.040 --> 00:26:44.280
I don't know what half of this
stuff is, but that's great

00:26:44.280 --> 00:26:46.160
because you can just
strip it away.

00:26:46.160 --> 00:26:47.390
ILYA GRIGORIK: Right, so the
important thing to note here

00:26:47.390 --> 00:26:48.930
is that this--

00:26:48.930 --> 00:26:51.970
so Chrome://tracing does not
capture just your tab or the

00:26:51.970 --> 00:26:54.310
page that you're on, which is
what the sampling profiler

00:26:54.310 --> 00:26:56.820
does when you pull
up in dev tools.

00:26:56.820 --> 00:27:00.180
This profiler will actually
record activity across every

00:27:00.180 --> 00:27:03.350
single tab, every single
process, that Chrome is

00:27:03.350 --> 00:27:07.720
managing, so this also means
things like I/O threads,

00:27:07.720 --> 00:27:11.210
renderer threads, so each tab
has an instance of those.

00:27:11.210 --> 00:27:13.620
JOHN MCCUTCHAN: So within a
tab, you have the renderer

00:27:13.620 --> 00:27:15.920
thread, which is where your
JavaScript code runs, and then

00:27:15.920 --> 00:27:18.890
you have a compositor thread,
which does the interactions

00:27:18.890 --> 00:27:19.650
with the GPU.

00:27:19.650 --> 00:27:22.690
I mean, a given tab could have
multiple threads off of it.

00:27:22.690 --> 00:27:24.320
ILYA GRIGORIK: Right, and so
for each tab that you have

00:27:24.320 --> 00:27:27.110
open, you'll have each one of
these in here, which is what

00:27:27.110 --> 00:27:28.430
the rows stand for.

00:27:28.430 --> 00:27:32.200
So the first question is, well,
if I have a couple of

00:27:32.200 --> 00:27:32.910
tabs open--

00:27:32.910 --> 00:27:35.380
I guess first tip is
close all the tabs.

00:27:35.380 --> 00:27:37.000
That'll make your
life simpler.

00:27:37.000 --> 00:27:37.990
JOHN MCCUTCHAN: Well, actually,
that's a really

00:27:37.990 --> 00:27:40.260
important thing to note for
any types of performance

00:27:40.260 --> 00:27:40.850
measurement--

00:27:40.850 --> 00:27:43.670
on a PC or Mac or any
type of computer--

00:27:43.670 --> 00:27:46.370
is that if you have some other
applications, say you're

00:27:46.370 --> 00:27:48.670
watching a YouTube video in
another tab or something like

00:27:48.670 --> 00:27:52.310
that, that has an impact on the
execution of your program

00:27:52.310 --> 00:27:54.220
and will kind of muddy
the waters

00:27:54.220 --> 00:27:55.020
of what you're measuring.

00:27:55.020 --> 00:27:58.080
So you want to close everything
down, keep it

00:27:58.080 --> 00:28:01.370
really simple, not just within
Chrome but your entire OS.

00:28:01.370 --> 00:28:02.480
ILYA GRIGORIK: It's your
lab environment.

00:28:02.480 --> 00:28:04.240
JOHN MCCUTCHAN: Exactly, yeah,
you've got to keep it clean.

00:28:04.240 --> 00:28:05.074
ILYA GRIGORIK: That's right.

00:28:05.074 --> 00:28:07.650
OK, so how do I--

00:28:07.650 --> 00:28:08.140
JOHN MCCUTCHAN: Yes.

00:28:08.140 --> 00:28:09.490
ILYA GRIGORIK: filter some
of those [? noise? ?]

00:28:09.490 --> 00:28:10.840
JOHN MCCUTCHAN: The first thing
that you want to do is

00:28:10.840 --> 00:28:14.230
you want to figure out the
process ID for your page, and

00:28:14.230 --> 00:28:17.016
the easiest way to do that is to
go to Chrome, colon, slash,

00:28:17.016 --> 00:28:18.340
slash, memory.

00:28:18.340 --> 00:28:22.690
And there'll be a table of
process IDs with tab names,

00:28:22.690 --> 00:28:24.830
and you find the tab of
your application.

00:28:24.830 --> 00:28:26.480
ILYA GRIGORIK: So you search
for your tab name there?

00:28:26.480 --> 00:28:28.790
JOHN MCCUTCHAN: Yes, and then
right next to it is going to

00:28:28.790 --> 00:28:33.340
be the process ID, and this is
going to allow you to filter

00:28:33.340 --> 00:28:35.400
for the data that you're
interested in.

00:28:35.400 --> 00:28:40.710
So we've already said the main
rows inside Chrome://tracing

00:28:40.710 --> 00:28:43.970
are keyed off of the process IDs
that they're coming from.

00:28:43.970 --> 00:28:47.470
So once you've gotten your
process ID, kill all of the

00:28:47.470 --> 00:28:47.870
other rows.

00:28:47.870 --> 00:28:50.450
ILYA GRIGORIK: So it's maybe a
little bit hard to see on the

00:28:50.450 --> 00:28:53.490
presentation, but there's the
little X icon beside each of

00:28:53.490 --> 00:28:54.910
the rows, so you can
just kill them.

00:28:54.910 --> 00:28:58.170
So you know the process IDs, or
the PIDs, of the ones that

00:28:58.170 --> 00:29:00.690
you're interested in, just
close all the rest.

00:29:00.690 --> 00:29:01.430
JOHN MCCUTCHAN: Yeah,
absolutely.

00:29:01.430 --> 00:29:04.585
If it doesn't have your
process ID next to

00:29:04.585 --> 00:29:05.440
it, get rid of it.

00:29:05.440 --> 00:29:06.840
It's fine.

00:29:06.840 --> 00:29:09.480
And then on top of that, after
having done that, you can

00:29:09.480 --> 00:29:10.630
filter even further.

00:29:10.630 --> 00:29:13.270
And since we're talking about
just profiling JavaScript

00:29:13.270 --> 00:29:16.860
code, there's a Categories box
in the upper right corner of

00:29:16.860 --> 00:29:19.790
Chrome://tracing, and by
clicking on that, you can

00:29:19.790 --> 00:29:22.770
deselect all of the categories
of data that were captured

00:29:22.770 --> 00:29:25.610
that is not relevant to what
you're trying to look at.

00:29:25.610 --> 00:29:27.350
ILYA GRIGORIK: Right, so
if we're interested in

00:29:27.350 --> 00:29:30.810
JavaScript, and we don't care
about the compositor thread,

00:29:30.810 --> 00:29:32.380
you can just unclick
the renderer

00:29:32.380 --> 00:29:33.600
and a few other things.

00:29:33.600 --> 00:29:35.480
JOHN MCCUTCHAN: So if you're
doing just JavaScript

00:29:35.480 --> 00:29:37.870
profiling, you just want
to V8 and Webkit.

00:29:37.870 --> 00:29:39.660
Everything else, turn it off.

00:29:39.660 --> 00:29:42.820
So immediately, we've kind of
come down from that craziness

00:29:42.820 --> 00:29:46.510
to something that's far more
reasonable, and you can reason

00:29:46.510 --> 00:29:49.310
about what's being displayed
in front of you now.

00:29:49.310 --> 00:29:50.890
ILYA GRIGORIK: Right.

00:29:50.890 --> 00:29:52.780
JOHN MCCUTCHAN: And then this
brings us to the awkwardness

00:29:52.780 --> 00:29:54.640
of your first initial
interactions with

00:29:54.640 --> 00:29:57.930
Chrome://tracing, which it
doesn't work as you'd expect,

00:29:57.930 --> 00:30:00.750
where you can use the mouse and
drag around and scroll.

00:30:00.750 --> 00:30:05.050
It operates based on the Quake
keys, so W and S zoom in and

00:30:05.050 --> 00:30:08.935
zoom out, and A and D pan to
the left or to the right.

00:30:08.935 --> 00:30:11.660
You can press a question key or
click the question mark box

00:30:11.660 --> 00:30:13.690
in the upper right-hand corner,
which gives you all of

00:30:13.690 --> 00:30:15.060
the other keyboard shortcuts.

00:30:15.060 --> 00:30:17.550
But it's important to just keep
in mind that most of your

00:30:17.550 --> 00:30:19.120
interactions are going to
be through the keyboard.

00:30:19.120 --> 00:30:19.800
ILYA GRIGORIK: That's right.

00:30:19.800 --> 00:30:24.030
You can, I guess, select
segments with your mouse, and

00:30:24.030 --> 00:30:26.120
it'll show you a little summary
at the bottom as to

00:30:26.120 --> 00:30:27.610
which functions are
being called.

00:30:27.610 --> 00:30:29.660
JOHN MCCUTCHAN: Yeah, it's kind
of like a lasso, and then

00:30:29.660 --> 00:30:32.320
you get a lot of information
about what you've lassoed.

00:30:32.320 --> 00:30:35.770
ILYA GRIGORIK: Right, but unless
you're panning left and

00:30:35.770 --> 00:30:37.990
right and zooming in and out,
you're not really going to get

00:30:37.990 --> 00:30:40.140
the high fidelity information
that's available.

00:30:40.140 --> 00:30:43.520
JOHN MCCUTCHAN: Yeah, I mean
you look at that initial

00:30:43.520 --> 00:30:46.800
screenshot where it's just
craziness, you can just drill

00:30:46.800 --> 00:30:48.670
in until each one of
those tiny little

00:30:48.670 --> 00:30:50.720
bars fills the screen.

00:30:50.720 --> 00:30:52.980
It kind of has an infinite
resolution there.

00:30:52.980 --> 00:30:54.070
You just keep drilling.

00:30:54.070 --> 00:30:56.120
ILYA GRIGORIK: Yeah, I think
you're literally looking at

00:30:56.120 --> 00:30:58.390
nanosecond granularity
at certain points.

00:30:58.390 --> 00:30:59.620
JOHN MCCUTCHAN: Yeah,
it's really,

00:30:59.620 --> 00:31:01.310
really, really precise.

00:31:04.300 --> 00:31:08.850
So why don't we do a walkthrough
and do a profile

00:31:08.850 --> 00:31:12.560
of some code with the
sample-based profiler and then

00:31:12.560 --> 00:31:15.240
with the structural profiler,
so we can kind of compare

00:31:15.240 --> 00:31:17.500
apples to oranges and see the
different types of data that

00:31:17.500 --> 00:31:20.730
you can get from both.

00:31:20.730 --> 00:31:24.010
So what we're looking at here is
a subset of the code that's

00:31:24.010 --> 00:31:25.750
being executed.

00:31:25.750 --> 00:31:27.760
We have a RequestAnimationFrame
function

00:31:27.760 --> 00:31:32.220
called gameloop, and gameloop
calls A. A loops for two

00:31:32.220 --> 00:31:34.780
milliseconds and then calls B.

00:31:34.780 --> 00:31:37.740
And the body of B and C are not
shown here, but you can

00:31:37.740 --> 00:31:40.990
see on the table on the
right how much time

00:31:40.990 --> 00:31:42.420
they execute for.

00:31:42.420 --> 00:31:45.800
So A calls B, and B executes
for eight milliseconds.

00:31:45.800 --> 00:31:49.370
And then B calls C, and C
executes for one millisecond.

00:31:49.370 --> 00:31:53.070
And then C calls D, which
executes for two milliseconds,

00:31:53.070 --> 00:31:55.400
and you can see the body
of D on the slide.

00:31:55.400 --> 00:31:57.800
It does nothing but that, and
then it just returns, and they

00:31:57.800 --> 00:31:59.000
all return back up.

00:31:59.000 --> 00:32:00.902
ILYA GRIGORIK: So it's just a
sequence of functions, A, B,

00:32:00.902 --> 00:32:03.200
C, D, and each one does a little
bit of work and then

00:32:03.200 --> 00:32:03.860
calls the next.

00:32:03.860 --> 00:32:05.260
JOHN MCCUTCHAN: Yeah, and
they're all nested.

00:32:05.260 --> 00:32:07.970
ILYA GRIGORIK: Right, so the
total, one pass when we invoke

00:32:07.970 --> 00:32:10.500
A, the total time would
be 13 milliseconds

00:32:10.500 --> 00:32:11.590
once everything completes.

00:32:11.590 --> 00:32:13.340
JOHN MCCUTCHAN: Yeah, and so
looking at this table, you

00:32:13.340 --> 00:32:16.720
would expect that B is the
dominant function.

00:32:16.720 --> 00:32:22.772
B is taking 8 out of the 13,
so that's about 66% or so.

00:32:22.772 --> 00:32:24.540
Yeah, so you would expect it.

00:32:24.540 --> 00:32:26.600
ILYA GRIGORIK: Right, and we're
firing this, hopefully,

00:32:26.600 --> 00:32:28.850
every 16 milliseconds,
which is why 13

00:32:28.850 --> 00:32:29.970
milliseconds is important.

00:32:29.970 --> 00:32:32.060
JOHN MCCUTCHAN: Yes, if you
want to do an interactive

00:32:32.060 --> 00:32:34.460
application using
RequestAnimationFrame, it's

00:32:34.460 --> 00:32:39.550
important that you are operating
at 60 hertz, which

00:32:39.550 --> 00:32:41.010
inverted, is 16 milliseconds.

00:32:41.010 --> 00:32:44.640
ILYA GRIGORIK: Right, so to
render each of the frames, you

00:32:44.640 --> 00:32:47.490
have about 16 milliseconds
in which you're

00:32:47.490 --> 00:32:48.850
allowed to do your work.

00:32:48.850 --> 00:32:50.570
JOHN MCCUTCHAN: Yeah, and
we'll get into the real

00:32:50.570 --> 00:32:54.360
details of that 16 milliseconds
later on, but

00:32:54.360 --> 00:32:58.310
ballpark is 16 milliseconds.

00:32:58.310 --> 00:33:02.900
So we'll switch open the Chrome
Developer's Tool and go

00:33:02.900 --> 00:33:06.780
to the sample-based profiler and
run a sample of this loop

00:33:06.780 --> 00:33:09.170
running endlessly for
a little while.

00:33:09.170 --> 00:33:11.080
And then you'll see again,
here, a screenshot on the

00:33:11.080 --> 00:33:13.330
right showing you that tree of
information, which we've

00:33:13.330 --> 00:33:15.420
touched upon already.

00:33:15.420 --> 00:33:17.840
But what's really interesting,
if you start to dig into it,

00:33:17.840 --> 00:33:21.790
is you notice that the functions
A, B, and C are

00:33:21.790 --> 00:33:22.510
actually gone.

00:33:22.510 --> 00:33:23.820
They're nowhere in
this capture,

00:33:23.820 --> 00:33:25.600
which is very unusual.

00:33:25.600 --> 00:33:28.320
Doesn't make a lot of sense,
considering that B, for

00:33:28.320 --> 00:33:32.530
example, is taking 66%
of our frame time.

00:33:32.530 --> 00:33:34.980
It's not present in the
sample-based capture.

00:33:34.980 --> 00:33:37.430
And also spinFor, which is that
leaf function which is

00:33:37.430 --> 00:33:40.080
just doing all that spinning,
is actually showing up as a

00:33:40.080 --> 00:33:45.680
very small contributor to the
overall execution time.

00:33:45.680 --> 00:33:48.320
ILYA GRIGORIK: Right, so maybe
just to highlight, because I

00:33:48.320 --> 00:33:50.810
think what you mentioned is very
important, so B is the

00:33:50.810 --> 00:33:53.740
longest function, so 8
milliseconds here.

00:33:53.740 --> 00:33:56.130
But as you're pointing out,
you just don't see it.

00:33:56.130 --> 00:33:59.120
So for some reason, we see D,
which is supposedly two

00:33:59.120 --> 00:33:59.650
milliseconds.

00:33:59.650 --> 00:34:01.830
JOHN MCCUTCHAN: Yeah, and D is
showing up, but B isn't.

00:34:01.830 --> 00:34:04.370
That doesn't intuitively make
sense as to what you would

00:34:04.370 --> 00:34:07.960
expect the execution flow of
your program to look like.

00:34:07.960 --> 00:34:09.170
ILYA GRIGORIK: Right.

00:34:09.170 --> 00:34:11.460
JOHN MCCUTCHAN: So what has
happened here is through a

00:34:11.460 --> 00:34:13.590
variety of optimizations--

00:34:13.590 --> 00:34:16.260
in this case, specifically
inlining--

00:34:16.260 --> 00:34:20.370
the functions A, B, and C and
spinFor have all been inlined

00:34:20.370 --> 00:34:22.880
into gameloop.

00:34:22.880 --> 00:34:25.130
So let me explain what
inlining is.

00:34:25.130 --> 00:34:27.800
So inlining is a very common
compiler optimization.

00:34:27.800 --> 00:34:30.730
And if you take a look at the
code on the left here, you can

00:34:30.730 --> 00:34:34.510
see we have our variable x, and
we loop 10 times, and we

00:34:34.510 --> 00:34:37.960
call A passing in x and passing
the result back out.

00:34:37.960 --> 00:34:40.150
And all A does is double
the value of x.

00:34:40.150 --> 00:34:42.710
It returns 2x out of it.

00:34:42.710 --> 00:34:45.335
So a compiler will see this and
say, hey, you know what, A

00:34:45.335 --> 00:34:49.810
is so short that I can just put
the body of A where the

00:34:49.810 --> 00:34:51.690
call to A takes place.

00:34:51.690 --> 00:34:54.120
And what this effectively does
is it erases A from the

00:34:54.120 --> 00:34:56.929
program, because it no longer
exists by name.

00:34:56.929 --> 00:34:59.630
The execution and the side
effects of its execution are

00:34:59.630 --> 00:35:01.650
still present in your program.

00:35:01.650 --> 00:35:03.960
The name of A is gone.

00:35:03.960 --> 00:35:06.880
So the rule of thumb is that
the code at run time in V8

00:35:06.880 --> 00:35:09.600
does not represent the
code that you wrote

00:35:09.600 --> 00:35:11.180
in source code form.

00:35:11.180 --> 00:35:14.870
So the side effect of this
is the call stacks won't

00:35:14.870 --> 00:35:17.500
necessarily look like the ones
that you've analyzed.

00:35:17.500 --> 00:35:20.400
ILYA GRIGORIK: And this is just
one optimization out of

00:35:20.400 --> 00:35:24.010
dozens and dozens
that V8 does.

00:35:24.010 --> 00:35:26.390
JOHN MCCUTCHAN: And not only
that, V8 is constantly

00:35:26.390 --> 00:35:29.020
analyzing your program and
looking for new optimizations

00:35:29.020 --> 00:35:30.390
to test out and employ.

00:35:30.390 --> 00:35:31.880
ILYA GRIGORIK: Right, so even
between runs, you might

00:35:31.880 --> 00:35:35.930
actually have, basically, a
different representation of

00:35:35.930 --> 00:35:36.770
the code in V8.

00:35:36.770 --> 00:35:39.560
Functionally, it'll do the same
thing, or it ought to be

00:35:39.560 --> 00:35:41.100
doing the same thing.

00:35:41.100 --> 00:35:44.970
But what's actually living
inside of V8 may be very

00:35:44.970 --> 00:35:47.090
different from what you have
in your mind when you're

00:35:47.090 --> 00:35:49.550
thinking about that code,
because I am thinking of B

00:35:49.550 --> 00:35:50.800
with eight milliseconds.

00:35:50.800 --> 00:35:51.830
I'm trying to map it here.

00:35:51.830 --> 00:35:53.740
I'm like, what is going on?

00:35:53.740 --> 00:35:54.700
JOHN MCCUTCHAN: Where
did it go, right?

00:35:54.700 --> 00:35:57.580
And so in this specific case,
it was inlined and erased.

00:35:57.580 --> 00:36:01.380
But I mean, yeah, V8 is
constantly testing out

00:36:01.380 --> 00:36:02.410
optimizations.

00:36:02.410 --> 00:36:04.130
It might take a look at a
function and be like, OK,

00:36:04.130 --> 00:36:06.380
well, it's running at
this rate, now.

00:36:06.380 --> 00:36:08.220
Let me try out this
optimization.

00:36:08.220 --> 00:36:10.420
In a second, I'll see if
the new optimization

00:36:10.420 --> 00:36:11.770
is better or not.

00:36:11.770 --> 00:36:13.250
So it's just constantly
changing.

00:36:13.250 --> 00:36:16.030
Eventually, it hits a steady
state, but especially at the

00:36:16.030 --> 00:36:17.700
beginning, it's very volatile.

00:36:17.700 --> 00:36:20.510
ILYA GRIGORIK: And not only
that, but this is Chrome.

00:36:20.510 --> 00:36:22.770
These optimizations may be
different in other browsers,

00:36:22.770 --> 00:36:24.760
or in other JavaScript
[? run times. ?]

00:36:24.760 --> 00:36:27.830
JOHN MCCUTCHAN: Yes, Firefox's
optimizations will be

00:36:27.830 --> 00:36:31.030
different than Safari's
optimizations, and they'll be

00:36:31.030 --> 00:36:33.260
different than Chrome's
optimizations.

00:36:33.260 --> 00:36:35.880
So there's no guarantee that
this type of optimization will

00:36:35.880 --> 00:36:37.370
be employed in another
browser.

00:36:37.370 --> 00:36:38.620
ILYA GRIGORIK: Yeah,
makes sense.

00:36:41.390 --> 00:36:44.880
JOHN MCCUTCHAN: So bottom line
here is that this trace just

00:36:44.880 --> 00:36:47.590
doesn't really resemble the
application's real execution

00:36:47.590 --> 00:36:49.250
flow or execution time.

00:36:52.430 --> 00:36:56.540
Now, let's look at
the same program.

00:36:56.540 --> 00:37:00.500
So again, it's A calling B
calling C calling D, but this

00:37:00.500 --> 00:37:02.850
time, with a structural
profiler.

00:37:02.850 --> 00:37:06.170
So we've instrumented our
functions with calls to

00:37:06.170 --> 00:37:09.220
console.time and
console.timeEnd.

00:37:09.220 --> 00:37:12.090
And keep in mind that these
functions, these calls to time

00:37:12.090 --> 00:37:15.190
and timeEnd and the functions
A, B, C, and D,

00:37:15.190 --> 00:37:16.280
can still be optimized.

00:37:16.280 --> 00:37:20.190
They can be optimized however
the VM that you're running in

00:37:20.190 --> 00:37:24.130
feels like optimizing them,
but the marking of time

00:37:24.130 --> 00:37:26.130
regions will not be
optimized away.

00:37:26.130 --> 00:37:29.410
ILYA GRIGORIK: Right, so we can
take the body of D, inline

00:37:29.410 --> 00:37:32.990
it into the function above
it, and it'll take the

00:37:32.990 --> 00:37:34.070
console.time.

00:37:34.070 --> 00:37:34.530
Right?

00:37:34.530 --> 00:37:35.080
JOHN MCCUTCHAN: Exactly.

00:37:35.080 --> 00:37:36.170
ILYA GRIGORIK: So even
though the code--

00:37:36.170 --> 00:37:37.500
the shape changes--

00:37:37.500 --> 00:37:40.090
JOHN MCCUTCHAN: We could be the
best compiler ever and the

00:37:40.090 --> 00:37:43.580
best optimizer ever and inline
it all, but so long as we keep

00:37:43.580 --> 00:37:46.240
the console.time and timeEnds
marking the regions of time

00:37:46.240 --> 00:37:49.860
that we're interested in, the
structural profiler present in

00:37:49.860 --> 00:37:52.580
Chrome://tracing will still
show us the flow of time.

00:37:52.580 --> 00:37:54.490
ILYA GRIGORIK: Maybe one more
comment about this.

00:37:54.490 --> 00:37:58.810
In the example so far, we've
always shown time and timeEnd

00:37:58.810 --> 00:37:59.740
within the same function.

00:37:59.740 --> 00:38:01.300
That doesn't have
to be the case.

00:38:01.300 --> 00:38:02.290
JOHN MCCUTCHAN: Absolutely
not.

00:38:02.290 --> 00:38:04.060
ILYA GRIGORIK: So I think this
is important to highlight.

00:38:04.060 --> 00:38:06.520
JOHN MCCUTCHAN: You can nest
them, and you can cross

00:38:06.520 --> 00:38:07.740
function boundaries.

00:38:07.740 --> 00:38:11.250
So what I like to do when I
first start off profiling and

00:38:11.250 --> 00:38:15.280
optimizing code is start with
a huge ball of code.

00:38:15.280 --> 00:38:17.730
Go from the beginning of your
frame to the end and just

00:38:17.730 --> 00:38:18.790
measure that.

00:38:18.790 --> 00:38:20.350
And then binary search
your way down.

00:38:25.020 --> 00:38:30.490
So up above, you can see that
there is a timeline view here,

00:38:30.490 --> 00:38:33.470
and it looks like an
inverted pyramid.

00:38:33.470 --> 00:38:37.040
We have A along the top, and
then for less time, we have B,

00:38:37.040 --> 00:38:39.560
and then for less time,
C, and furthermore.

00:38:39.560 --> 00:38:41.780
If you were to actually get
out and measure this, you

00:38:41.780 --> 00:38:46.100
could see that A is executing
exclusively for two

00:38:46.100 --> 00:38:48.680
milliseconds, exactly as
we've instructed it.

00:38:48.680 --> 00:38:51.730
It then calls B, which
executes for eight

00:38:51.730 --> 00:38:52.580
milliseconds.

00:38:52.580 --> 00:38:55.960
And then it calls C, which
executes for one exclusively.

00:38:55.960 --> 00:38:58.670
Then it calls D, which executes
for two exclusively,

00:38:58.670 --> 00:38:59.600
and then they all return up.

00:38:59.600 --> 00:39:03.290
ILYA GRIGORIK: So this is a very
direct visual mapping of

00:39:03.290 --> 00:39:04.360
that function [INAUDIBLE].

00:39:04.360 --> 00:39:05.510
JOHN MCCUTCHAN: It matches
our intuition.

00:39:05.510 --> 00:39:07.460
It's exactly what you'd
expect to be going--

00:39:07.460 --> 00:39:10.370
ILYA GRIGORIK: And this is, in
fact, what you would see in

00:39:10.370 --> 00:39:12.590
your Chrome://tracing if you
zoom in on this specific

00:39:12.590 --> 00:39:15.630
execution of this trace, once
you're instrumented this.

00:39:15.630 --> 00:39:16.850
JOHN MCCUTCHAN: This is
a screenshot from

00:39:16.850 --> 00:39:19.260
Chrome://tracing with
these exact

00:39:19.260 --> 00:39:21.340
instrumentations in place.

00:39:21.340 --> 00:39:23.770
What I find really interesting
is, it's hard to see in the

00:39:23.770 --> 00:39:26.360
screenshot on the right-hand
side here, but you can see

00:39:26.360 --> 00:39:29.230
that there's a little bit of
time from when D returns from

00:39:29.230 --> 00:39:30.120
when C returns.

00:39:30.120 --> 00:39:32.270
ILYA GRIGORIK: Yeah,
it's almost like a

00:39:32.270 --> 00:39:33.180
pixel to the right.

00:39:33.180 --> 00:39:35.340
JOHN MCCUTCHAN: Yeah, yeah, but
that's exactly what you

00:39:35.340 --> 00:39:39.030
would expect it to be, because
once D's returned, C is going

00:39:39.030 --> 00:39:41.810
to execute for a few more
instructions and execute its

00:39:41.810 --> 00:39:44.370
return statement, and
so on and so on.

00:39:44.370 --> 00:39:46.850
The important thing here is
that the exclusive runtime

00:39:46.850 --> 00:39:49.920
column matches exactly
what we've written

00:39:49.920 --> 00:39:52.660
the code to run for.

00:39:52.660 --> 00:39:54.590
And that was not the case with
sample-based profiling.

00:39:57.730 --> 00:40:01.070
So in conclusion with this demo,
in this specific case--

00:40:01.070 --> 00:40:03.960
and we've definitely picked
a worst-case scenario for

00:40:03.960 --> 00:40:05.500
sample-based profiling--

00:40:05.500 --> 00:40:07.950
it didn't present a very clear
picture of the program

00:40:07.950 --> 00:40:12.030
execution flow or the time spent
inside a given function.

00:40:12.030 --> 00:40:14.520
Contrast that with the
structural profiler, which

00:40:14.520 --> 00:40:17.500
mirrored exactly what you'd
expect and the true flow and

00:40:17.500 --> 00:40:19.960
time of the program's
execution.

00:40:19.960 --> 00:40:23.880
But structural profiling
required that we, first,

00:40:23.880 --> 00:40:27.420
instrument our code and then,
second, master the beast that

00:40:27.420 --> 00:40:30.960
is Chrome://tracing to even be
able to look at this data.

00:40:30.960 --> 00:40:32.570
ILYA GRIGORIK: Right, which kind
of leads me to believe

00:40:32.570 --> 00:40:34.450
that you should probably
be using both.

00:40:34.450 --> 00:40:37.450
JOHN MCCUTCHAN: Of
course, yeah.

00:40:37.450 --> 00:40:40.050
Always start with sample-based
profiling.

00:40:40.050 --> 00:40:42.050
So here's a walkthrough
of a real-world

00:40:42.050 --> 00:40:43.830
workflow for profiling.

00:40:43.830 --> 00:40:45.950
First step, of course, is you
just realized something's

00:40:45.950 --> 00:40:48.760
running slow, or you're just a
very inquisitive person, which

00:40:48.760 --> 00:40:50.090
is always good.

00:40:50.090 --> 00:40:52.090
And then you run the
sample-based profiler, which

00:40:52.090 --> 00:40:56.110
is going to highlight
the big target.

00:40:56.110 --> 00:40:59.080
It's not going to provide the
precision and detail that we

00:40:59.080 --> 00:41:01.460
saw with the structural-based
profiling, but it is going to

00:41:01.460 --> 00:41:03.550
give you a landmark in
your code to start

00:41:03.550 --> 00:41:04.390
instrumenting from.

00:41:04.390 --> 00:41:06.150
ILYA GRIGORIK: And it's three
clicks, open dev tools,

00:41:06.150 --> 00:41:08.310
Profiling, Start.

00:41:08.310 --> 00:41:08.840
JOHN MCCUTCHAN: Couldn't
be easier.

00:41:08.840 --> 00:41:10.280
ILYA GRIGORIK: Right,
and I'm there.

00:41:10.280 --> 00:41:12.810
JOHN MCCUTCHAN: Yeah, so once
you have that landmark, then

00:41:12.810 --> 00:41:17.000
start laying out some of these
console.time and timeEnds to

00:41:17.000 --> 00:41:19.580
kind of mark out regions
of execution.

00:41:19.580 --> 00:41:22.450
ILYA GRIGORIK: Right, so it
could, in fact-- so I think

00:41:22.450 --> 00:41:23.760
this is actually important
to highlight.

00:41:23.760 --> 00:41:29.550
So with sampling, let's say
I'm calling a DOM API.

00:41:29.550 --> 00:41:34.600
I can't really instrument the
DOM API in my structural code.

00:41:34.600 --> 00:41:36.140
JOHN MCCUTCHAN: Yes, although
you could actually

00:41:36.140 --> 00:41:37.030
instrument around it.

00:41:37.030 --> 00:41:38.690
ILYA GRIGORIK: Around it
and record it, right?

00:41:38.690 --> 00:41:42.200
But the sampling profiler will
actually tell me immediately.

00:41:42.200 --> 00:41:44.160
Like if I'm calling some
function which is blocking all

00:41:44.160 --> 00:41:47.620
the time for whatever reason,
that'll show up there.

00:41:47.620 --> 00:41:49.840
And then you can actually ask a
question like, OK, so maybe

00:41:49.840 --> 00:41:53.340
I'm calling some expensive
function for CSS or for

00:41:53.340 --> 00:41:54.710
JavaScript or what have you.

00:41:54.710 --> 00:41:56.010
What is calling that?

00:41:56.010 --> 00:41:58.280
What is causing that?

00:41:58.280 --> 00:42:00.180
JOHN MCCUTCHAN: That's where the
sample starts to kind of

00:42:00.180 --> 00:42:02.300
get a little like
Swiss cheese.

00:42:02.300 --> 00:42:04.270
You can kind of see these holes
in it, and you're not

00:42:04.270 --> 00:42:06.580
getting the clear picture.

00:42:06.580 --> 00:42:08.890
And then you start instrumenting
around that

00:42:08.890 --> 00:42:09.820
chunk of code.

00:42:09.820 --> 00:42:10.760
You narrow it in.

00:42:10.760 --> 00:42:11.500
But that's a great point.

00:42:11.500 --> 00:42:13.540
The sample-based profiler
does show you system

00:42:13.540 --> 00:42:14.670
calls that you make.

00:42:14.670 --> 00:42:18.860
So if you call a canvas fill or
a canvas stroke method, or

00:42:18.860 --> 00:42:23.700
you're modifying some property
of a DOM element which

00:42:23.700 --> 00:42:25.910
requires a reflow, that's
going to show up in the

00:42:25.910 --> 00:42:28.770
sample-based profiler.

00:42:28.770 --> 00:42:30.940
So the key takeaway here is
that you start with the

00:42:30.940 --> 00:42:33.320
sample-based profiler,
you then dig in with

00:42:33.320 --> 00:42:36.260
instrumentation, and
you iterate.

00:42:36.260 --> 00:42:38.640
This is not a one-pass.

00:42:38.640 --> 00:42:40.940
You repeatedly go over this.

00:42:40.940 --> 00:42:44.370
You're slowly building this
really detailed map of what

00:42:44.370 --> 00:42:45.620
your program is doing.

00:42:49.280 --> 00:42:51.620
So some closing tips.

00:42:51.620 --> 00:42:54.210
Again, you start with the
sampling profiler.

00:42:54.210 --> 00:42:58.010
You have to learn how to deal
with Chrome://tracing.

00:42:58.010 --> 00:43:02.140
After maybe one or two attempts
at it, it's easy, but

00:43:02.140 --> 00:43:04.300
the first time, it's
intimidating.

00:43:04.300 --> 00:43:07.240
ILYA GRIGORIK: Yeah, I think
what I found very useful is

00:43:07.240 --> 00:43:11.100
just finding a couple of good
traces and just kind of

00:43:11.100 --> 00:43:12.190
wrapping your head around it.

00:43:12.190 --> 00:43:14.440
So I think you'll show us a
quick demo at the end, which

00:43:14.440 --> 00:43:16.160
will be very good to see.

00:43:16.160 --> 00:43:20.170
But also just go into your
page, capture something,

00:43:20.170 --> 00:43:23.010
scroll around, interact with
it, record a couple of

00:43:23.010 --> 00:43:25.190
different ones, and just kind of
compare them side by side.

00:43:25.190 --> 00:43:28.860
JOHN MCCUTCHAN: Yeah, so some
interesting flow there if you

00:43:28.860 --> 00:43:31.630
just want to figure out
what's going on,

00:43:31.630 --> 00:43:33.540
is you want to find--

00:43:33.540 --> 00:43:38.650
you could have a keyboard input
that will show up inside

00:43:38.650 --> 00:43:40.680
Chrome://tracing when
a key was pressed.

00:43:40.680 --> 00:43:44.500
And so if you go from there, you
can start following this

00:43:44.500 --> 00:43:46.230
thread through Chrome://tracing.

00:43:46.230 --> 00:43:49.210
It's like, OK, well, a key was
pressed, and the browser

00:43:49.210 --> 00:43:50.560
noticed a key was pressed.

00:43:50.560 --> 00:43:53.490
And then it notified my page,
and then my page ran my

00:43:53.490 --> 00:43:54.885
OnKeyDown handler.

00:43:54.885 --> 00:43:56.610
ILYA GRIGORIK: So there's
definitely a case of just

00:43:56.610 --> 00:43:59.160
information overload
initially there.

00:43:59.160 --> 00:44:00.940
And I guess the other thing that
I'll mention is-- and I

00:44:00.940 --> 00:44:02.920
find this incredibly useful--

00:44:02.920 --> 00:44:06.490
when you narrow in on that one,
let's say, input handler,

00:44:06.490 --> 00:44:08.820
it'll actually give you
the Chrome name

00:44:08.820 --> 00:44:09.780
from the source code.

00:44:09.780 --> 00:44:11.170
So you can actually--

00:44:11.170 --> 00:44:13.420
most of the time, you can just
copy that if you're really

00:44:13.420 --> 00:44:15.460
curious about it, paste it
into your favorite search

00:44:15.460 --> 00:44:18.430
engine, and you'll end up
looking at the Chrome source.

00:44:18.430 --> 00:44:20.770
And I just find reading through
the comments very

00:44:20.770 --> 00:44:21.830
enlightening sometimes.

00:44:21.830 --> 00:44:23.970
JOHN MCCUTCHAN: Yeah, I think
that's a great idea,

00:44:23.970 --> 00:44:25.770
absolutely.

00:44:25.770 --> 00:44:29.160
So part of this learning how
to deal with it is, again,

00:44:29.160 --> 00:44:29.840
filtering down.

00:44:29.840 --> 00:44:32.390
And remember, go to
Chrome://memory to get the

00:44:32.390 --> 00:44:35.110
PID, and then just kill all the
rows that have nothing to

00:44:35.110 --> 00:44:38.180
do with your page, because
they're just noise for what

00:44:38.180 --> 00:44:40.176
we're looking at right now.

00:44:40.176 --> 00:44:43.630
And we've kind of touched on a
lot of this here, but remember

00:44:43.630 --> 00:44:46.500
that the time and timeEnd
pairs can cross function

00:44:46.500 --> 00:44:47.510
boundaries.

00:44:47.510 --> 00:44:50.470
They don't have to be within
a single function.

00:44:50.470 --> 00:44:54.340
You could do huge reams of code
with just one time and

00:44:54.340 --> 00:44:57.230
timeEnd and narrow in.

00:44:57.230 --> 00:45:02.670
And the V8 optimizer and the
optimizers in Safari and

00:45:02.670 --> 00:45:07.040
Firefox employ a variety of
optimization techniques, which

00:45:07.040 --> 00:45:10.980
ultimately, to you, means that
the runtime representation of

00:45:10.980 --> 00:45:14.190
your code will not necessarily
match your source code.

00:45:14.190 --> 00:45:16.220
ILYA GRIGORIK: Yeah,
yeah, makes sense.

00:45:16.220 --> 00:45:18.400
JOHN MCCUTCHAN: And remember,
if you want to, you can

00:45:18.400 --> 00:45:21.490
exchange these captures both
from Chrome://tracing and from

00:45:21.490 --> 00:45:23.800
Chrome dev tools sample-based
profiler.

00:45:23.800 --> 00:45:25.770
And it's a really great idea,
when you're interacting with

00:45:25.770 --> 00:45:27.430
developers, to provide
them with a capture.

00:45:27.430 --> 00:45:29.780
ILYA GRIGORIK: Yeah, so if
you're on the receiving end of

00:45:29.780 --> 00:45:31.920
these things, start asking.

00:45:31.920 --> 00:45:33.290
If you're currently
not getting these,

00:45:33.290 --> 00:45:34.420
start asking for them.

00:45:34.420 --> 00:45:37.710
And if you're the one filing the
bug, please include this.

00:45:37.710 --> 00:45:39.570
JOHN MCCUTCHAN: And just think,
if you go through your

00:45:39.570 --> 00:45:43.990
library, and you add in an
optional instrumentation pass,

00:45:43.990 --> 00:45:47.240
which someone who is running
into a performance problem,

00:45:47.240 --> 00:45:50.880
you could just write back to
them set this flag, run it,

00:45:50.880 --> 00:45:53.230
give me a capture, and
email it back to me.

00:45:53.230 --> 00:45:57.000
So it reduces this back and
forth time between you and the

00:45:57.000 --> 00:46:00.160
developer reporting the issue
to just one pass.

00:46:00.160 --> 00:46:03.220
ILYA GRIGORIK: Yeah, yeah,
incredibly useful.

00:46:03.220 --> 00:46:03.880
JOHN MCCUTCHAN: Yes.

00:46:03.880 --> 00:46:07.100
So another little tip that I
have here is think about the

00:46:07.100 --> 00:46:08.920
data that's being processed.

00:46:08.920 --> 00:46:11.690
Let's imagine a scenario where
you're iterating over elements

00:46:11.690 --> 00:46:15.430
in a list, and you're doing
some computation on them.

00:46:15.430 --> 00:46:18.830
Your intuition and your
expectation is that the cost

00:46:18.830 --> 00:46:20.770
per element is uniform.

00:46:20.770 --> 00:46:24.110
So cost for element one is the
same for two, same for three,

00:46:24.110 --> 00:46:25.180
same for four.

00:46:25.180 --> 00:46:27.420
So you'll lay out an
instrumentation marker that

00:46:27.420 --> 00:46:30.610
says, well, I'm processing
my list.

00:46:30.610 --> 00:46:32.470
ILYA GRIGORIK: So be creative
with your names.

00:46:32.470 --> 00:46:34.670
JOHN MCCUTCHAN: Yes, be very
creative with your names and

00:46:34.670 --> 00:46:35.700
include them.

00:46:35.700 --> 00:46:40.230
Because the instrumentation just
takes a string, you could

00:46:40.230 --> 00:46:43.350
name all of your objects and
pass that string in.

00:46:43.350 --> 00:46:46.670
So I'm doing work on data
item 1, 2, 3, 4, 5.

00:46:46.670 --> 00:46:51.180
Oh, 6 is huge, as you can see in
the screenshot, which tells

00:46:51.180 --> 00:46:54.910
you that maybe the data in 6
is maybe malformed, or it's

00:46:54.910 --> 00:46:55.810
triggering a slow path.

00:46:55.810 --> 00:46:57.620
ILYA GRIGORIK: So maybe I'm
processing a list of users.

00:46:57.620 --> 00:47:00.200
I can just include the username
in here, and be like,

00:47:00.200 --> 00:47:04.610
hey, it's data item 6, or data
John, it's taking a long--

00:47:04.610 --> 00:47:06.200
like, why is John
taking so long?

00:47:06.200 --> 00:47:06.990
JOHN MCCUTCHAN: And then you're
going to dig in, and

00:47:06.990 --> 00:47:08.600
you're going to find
some really

00:47:08.600 --> 00:47:09.950
obscure bug in your code.

00:47:09.950 --> 00:47:13.250
ILYA GRIGORIK: Sure, sure,
or a megabyte of

00:47:13.250 --> 00:47:14.240
extra text or something.

00:47:14.240 --> 00:47:17.110
JOHN MCCUTCHAN: Yeah, exactly,
or like maybe I've been

00:47:17.110 --> 00:47:19.920
chatting a lot, and the log
has gotten huge, and your

00:47:19.920 --> 00:47:23.860
algorithm that processes the log
is algorithmically slow.

00:47:23.860 --> 00:47:26.250
ILYA GRIGORIK: So this is
important, I think, because

00:47:26.250 --> 00:47:28.390
most of the time, your code
could be running just fine.

00:47:28.390 --> 00:47:28.880
JOHN MCCUTCHAN: Yeah,
it's that outlier.

00:47:28.880 --> 00:47:30.900
ILYA GRIGORIK: It's
staying within--

00:47:30.900 --> 00:47:32.440
but then every once in a while,
you get a dropped

00:47:32.440 --> 00:47:33.980
frame, and you're just
scratching your head trying to

00:47:33.980 --> 00:47:37.190
figure out what's going on.

00:47:37.190 --> 00:47:39.210
That could be the problem, and
that's one way to help you

00:47:39.210 --> 00:47:40.438
track it down.

00:47:40.438 --> 00:47:41.688
JOHN MCCUTCHAN: Yeah.

00:47:44.030 --> 00:47:46.050
So budgeting--

00:47:46.050 --> 00:47:48.150
like any good household,
you've got

00:47:48.150 --> 00:47:48.840
to budget for money.

00:47:48.840 --> 00:47:53.000
You need to budget for
performance as well, which in

00:47:53.000 --> 00:47:55.810
terms of a game or an
interactive, very, very

00:47:55.810 --> 00:47:59.970
responsive application, means
less than 16 milliseconds per

00:47:59.970 --> 00:48:00.500
RequestAnimationFrame.

00:48:00.500 --> 00:48:02.020
ILYA GRIGORIK: So let's,
yes, step back.

00:48:02.020 --> 00:48:04.940
So we have 1,000 milliseconds
in a second.

00:48:04.940 --> 00:48:07.550
We want 60 frames per second.

00:48:07.550 --> 00:48:10.330
If you just divide those
numbers, we get roughly 16.6

00:48:10.330 --> 00:48:14.960
repeated, so 16 milliseconds
to get 60 frames.

00:48:14.960 --> 00:48:15.630
JOHN MCCUTCHAN: Right.

00:48:15.630 --> 00:48:18.420
ILYA GRIGORIK: So that is my
budget to render each frame.

00:48:18.420 --> 00:48:21.080
JOHN MCCUTCHAN: Exactly, you
have 16 milliseconds to do

00:48:21.080 --> 00:48:24.600
everything, which includes
taking keyboard input, taking

00:48:24.600 --> 00:48:27.250
mouse input, which actually
brings me to a

00:48:27.250 --> 00:48:28.830
little side note here.

00:48:28.830 --> 00:48:33.230
In your input process-- in your
OnKeyDown handlers, just

00:48:33.230 --> 00:48:37.410
cue that up and process it in
your RequestAnimationFrame.

00:48:37.410 --> 00:48:39.250
That's a much more
efficient way of

00:48:39.250 --> 00:48:41.630
allowing Chrome to execute.

00:48:41.630 --> 00:48:45.650
So that aside, you have 16
milliseconds, and you have to

00:48:45.650 --> 00:48:49.780
do everything in it in order to
give Chrome enough time to

00:48:49.780 --> 00:48:51.810
render your page at 60 hertz.

00:48:51.810 --> 00:48:54.015
ILYA GRIGORIK: Right, and I
guess there's some overhead

00:48:54.015 --> 00:48:55.190
for Chrome itself.

00:48:55.190 --> 00:48:56.180
It's not just instant.

00:48:56.180 --> 00:48:56.970
Right?

00:48:56.970 --> 00:48:59.310
JOHN MCCUTCHAN: Yes, and we'll
highlight that in more detail

00:48:59.310 --> 00:49:00.310
momentarily, actually.

00:49:00.310 --> 00:49:02.180
But, yeah, it's really not 16.

00:49:02.180 --> 00:49:06.050
It's actually, like, let's
round down to 14, maybe.

00:49:06.050 --> 00:49:08.540
Depending on what you're doing,
it could be 13 and 12.

00:49:08.540 --> 00:49:11.130
ILYA GRIGORIK: And actually,
not only that, but 16

00:49:11.130 --> 00:49:13.700
milliseconds is also-- it's
not an absolute time.

00:49:13.700 --> 00:49:16.880
I'm going to claim that it's
a relative time, because 16

00:49:16.880 --> 00:49:20.280
milliseconds on this computer
that I have here is probably

00:49:20.280 --> 00:49:23.530
very different from 16
milliseconds on my phone.

00:49:23.530 --> 00:49:25.870
JOHN MCCUTCHAN: Absolutely
right, and then the same but

00:49:25.870 --> 00:49:28.180
in the other direction with
your desktop machine.

00:49:28.180 --> 00:49:30.750
16 milliseconds on this
might be 10 on a

00:49:30.750 --> 00:49:33.590
desktop and 28 on a phone.

00:49:33.590 --> 00:49:36.690
ILYA GRIGORIK: So if you're
optimizing your page, and

00:49:36.690 --> 00:49:40.010
let's say you're taking 20
milliseconds to do the work,

00:49:40.010 --> 00:49:41.920
and you've just managed
to get it under

00:49:41.920 --> 00:49:43.520
14, and you're happy--

00:49:43.520 --> 00:49:45.450
I mean, that's a great
one to begin with--

00:49:45.450 --> 00:49:47.770
but I'm sorry, you should
probably get it down even

00:49:47.770 --> 00:49:51.650
further to make sure that it's
silky smooth on mobile phones.

00:49:51.650 --> 00:49:52.690
JOHN MCCUTCHAN: We're all
developers, right?

00:49:52.690 --> 00:49:56.020
So we've got these beefy
workstations with gigs and

00:49:56.020 --> 00:49:58.960
gigs of RAM and 16 cores.

00:49:58.960 --> 00:50:00.390
And you're like, oh, it's 16.

00:50:00.390 --> 00:50:01.430
Awesome.

00:50:01.430 --> 00:50:03.240
You get that on a MacBook
Air, it's not

00:50:03.240 --> 00:50:05.150
going to run that well.

00:50:05.150 --> 00:50:09.380
So the rule of thumb here is
always optimize for the lowest

00:50:09.380 --> 00:50:12.020
common denominator of hardware
that your application is

00:50:12.020 --> 00:50:13.010
expected to run on.

00:50:13.010 --> 00:50:15.900
ILYA GRIGORIK: Right, so I'll
wave my hands and kind of

00:50:15.900 --> 00:50:19.010
claim a rule of thumb, which is
to say if you're targeting

00:50:19.010 --> 00:50:22.060
mobile phones as well, try and
stay under 10 milliseconds.

00:50:22.060 --> 00:50:22.780
JOHN MCCUTCHAN: Yeah, I think
that's probably fair.

00:50:22.780 --> 00:50:24.900
ILYA GRIGORIK: I think that's
probably a safe-ish bound.

00:50:24.900 --> 00:50:28.840
It's not a scientific measure,
but that's a good target.

00:50:28.840 --> 00:50:30.600
JOHN MCCUTCHAN: Yeah, I
would agree with that.

00:50:30.600 --> 00:50:35.010
The lower you can go, the
better, but then the

00:50:35.010 --> 00:50:36.810
expressiveness of
your application

00:50:36.810 --> 00:50:37.890
goes down with that.

00:50:37.890 --> 00:50:41.270
So you have to find that sweet
spot, and I would say 8 to 10

00:50:41.270 --> 00:50:43.440
is a good rule of thumb.

00:50:43.440 --> 00:50:45.690
But of course, with everything
when it comes to performance,

00:50:45.690 --> 00:50:48.940
you have to measure, and you
have to prove that you're

00:50:48.940 --> 00:50:50.880
still running at 60 hertz.

00:50:50.880 --> 00:50:53.215
ILYA GRIGORIK: Perfect, so how
do we measure our hertz?

00:50:53.215 --> 00:50:55.290
JOHN MCCUTCHAN: OK, so
that's going to bring

00:50:55.290 --> 00:50:56.130
us to the next one.

00:50:56.130 --> 00:51:00.880
So just summary here, budget and
then track the performance

00:51:00.880 --> 00:51:03.550
across the project's lifespan.

00:51:03.550 --> 00:51:06.560
Don't just measure one day and
then, the week before release,

00:51:06.560 --> 00:51:08.640
measure again and be like,
oh, whoops, we're

00:51:08.640 --> 00:51:11.150
completely out of budget.

00:51:11.150 --> 00:51:11.910
Really break it down.

00:51:11.910 --> 00:51:17.130
ILYA GRIGORIK: So I guess for
frames, we do have the

00:51:17.130 --> 00:51:19.110
timeline view in dev tools.

00:51:19.110 --> 00:51:22.160
We can hit Record, and it'll
actually tell you how long it

00:51:22.160 --> 00:51:23.450
took to render each
frame, which is

00:51:23.450 --> 00:51:24.540
actually very, very useful.

00:51:24.540 --> 00:51:25.640
If you guys haven't
tried that, I

00:51:25.640 --> 00:51:27.640
encourage you to try it.

00:51:27.640 --> 00:51:30.590
But I guess you can also kind
of get a glimpse into that

00:51:30.590 --> 00:51:32.650
through Chrome://tracing,
which is a

00:51:32.650 --> 00:51:34.350
much lower level view.

00:51:34.350 --> 00:51:36.490
JOHN MCCUTCHAN: Yes, it's very
low level, but it's really

00:51:36.490 --> 00:51:38.230
useful when you really want
to get down into the

00:51:38.230 --> 00:51:39.330
nitty-gritty.

00:51:39.330 --> 00:51:42.340
And by using the
instrumentation, you can

00:51:42.340 --> 00:51:46.360
actually overlay your program's
real execution flow

00:51:46.360 --> 00:51:49.590
with the larger Chrome context,
which allows you to

00:51:49.590 --> 00:51:52.920
really see how you're fitting
into Chrome's frame, because

00:51:52.920 --> 00:51:55.730
you're running within Chrome,
and you need to understand the

00:51:55.730 --> 00:51:57.070
bigger picture.

00:51:57.070 --> 00:52:01.830
So with that, why don't we try
out a little experiment here.

00:52:01.830 --> 00:52:02.690
ILYA GRIGORIK: So I
think you want to

00:52:02.690 --> 00:52:05.030
actually go to the Canary.

00:52:05.030 --> 00:52:06.520
JOHN MCCUTCHAN: Here,
I'll let you--

00:52:06.520 --> 00:52:07.300
ILYA GRIGORIK: Here we go, so
we just have a different

00:52:07.300 --> 00:52:08.020
instance here.

00:52:08.020 --> 00:52:10.460
JOHN MCCUTCHAN: OK, just
a different instance.

00:52:10.460 --> 00:52:14.250
So what we have here is a very
simple demo and some buttons

00:52:14.250 --> 00:52:14.850
alongside here.

00:52:14.850 --> 00:52:18.090
It's just a sphere that grows,
and then it shrinks.

00:52:18.090 --> 00:52:19.160
ILYA GRIGORIK: OK.

00:52:19.160 --> 00:52:20.590
JOHN MCCUTCHAN: So when I press
this button here, it

00:52:20.590 --> 00:52:22.390
runs at 60 hertz.

00:52:22.390 --> 00:52:25.360
If I switch to 30, it's
hard to really see.

00:52:25.360 --> 00:52:27.420
ILYA GRIGORIK: Yeah, I don't
really notice much difference.

00:52:27.420 --> 00:52:30.010
JOHN MCCUTCHAN: Yes, but I will
prove to you that it is,

00:52:30.010 --> 00:52:32.240
in fact, running at 30 hertz.

00:52:32.240 --> 00:52:35.630
But film runs at 24, so the
human eye is kind of

00:52:35.630 --> 00:52:37.010
conditioned.

00:52:37.010 --> 00:52:40.610
Anyways, when you drop to 15,
you really start to see it.

00:52:40.610 --> 00:52:40.960
It's jerky.

00:52:40.960 --> 00:52:42.440
ILYA GRIGORIK: Yeah, there's
definitely a drop there.

00:52:42.440 --> 00:52:42.920
JOHN MCCUTCHAN: And then
when you go to

00:52:42.920 --> 00:52:43.950
eight, it's even worse.

00:52:43.950 --> 00:52:45.690
ILYA GRIGORIK: Right.

00:52:45.690 --> 00:52:47.470
JOHN MCCUTCHAN: So why don't we
start at eight, and we'll

00:52:47.470 --> 00:52:49.420
just run a Chrome trace?

00:52:49.420 --> 00:52:56.590
So first thing is to figure out
our process ID, which in

00:52:56.590 --> 00:52:59.950
this case, is 68139.

00:52:59.950 --> 00:53:00.730
Then we go over to

00:53:00.730 --> 00:53:04.530
Chrome://tracing, and we record.

00:53:04.530 --> 00:53:07.930
We pop over here, and we just
let it run for a little while.

00:53:07.930 --> 00:53:09.500
We come back.

00:53:09.500 --> 00:53:12.250
We stop the trace.

00:53:12.250 --> 00:53:15.300
So now, we want to find 68139.

00:53:15.300 --> 00:53:17.630
I'm not going to collapse down
everything else just for--

00:53:17.630 --> 00:53:19.210
ILYA GRIGORIK: So as we were
saying, there's a lot of stuff

00:53:19.210 --> 00:53:19.660
on the screen.

00:53:19.660 --> 00:53:21.580
JOHN MCCUTCHAN: Yeah, I mean
just look at this.

00:53:21.580 --> 00:53:25.340
Chrome DB thread, Chrome file
thread, lots of stuff.

00:53:25.340 --> 00:53:29.710
But let's find where we live,
which is right here.

00:53:29.710 --> 00:53:33.150
68139 CD render main, this
is the thread where your

00:53:33.150 --> 00:53:35.775
JavaScript executes in.

00:53:35.775 --> 00:53:39.200
68139 compositor, this is where
Chrome interacts with

00:53:39.200 --> 00:53:41.570
the GPU on your behalf.

00:53:41.570 --> 00:53:43.970
So you can see here, when we--

00:53:43.970 --> 00:53:47.120
I'll select this region
right here.

00:53:47.120 --> 00:53:49.750
I'm pressing the F key,
which zooms into

00:53:49.750 --> 00:53:52.100
what you have selected.

00:53:52.100 --> 00:53:55.630
And you can see that I've
instrumented the code, and

00:53:55.630 --> 00:54:00.150
I've added a frame update
marker, and we're spending 132

00:54:00.150 --> 00:54:02.010
milliseconds per frame.

00:54:02.010 --> 00:54:04.860
ILYA GRIGORIK: So this is
console.time, timeEnd for the

00:54:04.860 --> 00:54:05.400
frame update.

00:54:05.400 --> 00:54:07.470
So that's you instrumenting
it.

00:54:07.470 --> 00:54:08.940
JOHN MCCUTCHAN: That is
me instrumenting it.

00:54:08.940 --> 00:54:13.440
And you can see here that
WebView implementation colon

00:54:13.440 --> 00:54:18.210
colon update animations, this
is where WebKit says, I'm

00:54:18.210 --> 00:54:19.060
ready to call your

00:54:19.060 --> 00:54:20.490
RequestAnimationFrame callback.

00:54:20.490 --> 00:54:23.200
ILYA GRIGORIK: Interesting,
OK.

00:54:23.200 --> 00:54:25.520
JOHN MCCUTCHAN: So it's
kind of strange.

00:54:25.520 --> 00:54:27.480
We actually have two different
pyramids here.

00:54:27.480 --> 00:54:29.990
We have the first one here,
which is Run Task, Begin

00:54:29.990 --> 00:54:33.940
Frame, Update Animations, V8
Call Function, and then

00:54:33.940 --> 00:54:38.200
sitting on top but still within
the same thread, is our

00:54:38.200 --> 00:54:41.800
own hierarchy of markers.

00:54:41.800 --> 00:54:46.780
So it goes from Message Loop
down to V8 Call Function, and

00:54:46.780 --> 00:54:48.670
then we start overlaying
our own.

00:54:48.670 --> 00:54:52.060
So we have Frame Update here,
and I've added in AI Update,

00:54:52.060 --> 00:54:55.800
which takes two milliseconds,
a Physics Update which takes

00:54:55.800 --> 00:54:58.950
two, and then a Draw Scene which
is just artificially

00:54:58.950 --> 00:55:01.160
taking a ridiculous
amount of time.

00:55:01.160 --> 00:55:03.450
ILYA GRIGORIK: So this is a very
good visual way to get--

00:55:03.450 --> 00:55:07.640
this allows me to very quickly
see which functions

00:55:07.640 --> 00:55:09.110
are taking the most.

00:55:09.110 --> 00:55:10.460
Without even analyzing
the numbers,

00:55:10.460 --> 00:55:12.080
it's just very obvious.

00:55:12.080 --> 00:55:13.370
JOHN MCCUTCHAN: Yeah,
it's immediately

00:55:13.370 --> 00:55:14.160
obvious in this case.

00:55:14.160 --> 00:55:16.170
Draw Scene is our bottleneck.

00:55:16.170 --> 00:55:17.860
ILYA GRIGORIK: So this is
for a frame, right?

00:55:17.860 --> 00:55:19.050
JOHN MCCUTCHAN: Yes,
it's for a frame.

00:55:19.050 --> 00:55:23.424
We're zoomed in, and
so next to--

00:55:23.424 --> 00:55:27.460
oops, let me zoom out here.

00:55:27.460 --> 00:55:30.347
I've lost my keyboard focus.

00:55:30.347 --> 00:55:31.597
What happened there?

00:55:34.330 --> 00:55:37.760
Sorry technical difficulties,
of course.

00:55:37.760 --> 00:55:39.760
ILYA GRIGORIK: Probably easier
just to re-record it.

00:55:39.760 --> 00:55:41.420
JOHN MCCUTCHAN: Yes, I agree.

00:55:41.420 --> 00:55:42.100
So here we go.

00:55:42.100 --> 00:55:43.540
Here's another frame.

00:55:43.540 --> 00:55:44.630
ILYA GRIGORIK: So stop, yeah.

00:55:44.630 --> 00:55:45.720
JOHN MCCUTCHAN: OK,
there we go.

00:55:45.720 --> 00:55:49.210
Now, let's go down to 68139,
press that, zoom in.

00:55:49.210 --> 00:55:51.810
So this is a frame update.

00:55:51.810 --> 00:55:56.800
Next to it, we have
this right here.

00:55:56.800 --> 00:56:00.650
And I know this just because I
spent enough time that when

00:56:00.650 --> 00:56:05.810
I've lassoed that very tall
tower there, you can see here

00:56:05.810 --> 00:56:08.650
that there is a call
to draw layers.

00:56:08.650 --> 00:56:10.680
This is your clue that
this is where the

00:56:10.680 --> 00:56:13.430
actual drawing occurs.

00:56:13.430 --> 00:56:15.840
So the first thing is you find
your RequestAnimationFrame

00:56:15.840 --> 00:56:19.620
frame, and then you find
this shape next to it.

00:56:19.620 --> 00:56:24.040
And from there you can press
G. And what G does is it,

00:56:24.040 --> 00:56:30.770
starting at the slice that you
have selected, lays out grids

00:56:30.770 --> 00:56:33.920
at 16 millisecond intervals.

00:56:33.920 --> 00:56:37.280
So you can see here that this is
the start of our frame, so

00:56:37.280 --> 00:56:41.320
this is-- at this point,
we would be running 60.

00:56:41.320 --> 00:56:42.300
At this point, it would be--

00:56:42.300 --> 00:56:43.780
ILYA GRIGORIK: So ideally, we
should be seeing all of our

00:56:43.780 --> 00:56:46.370
work fit into each one of
these small intervals.

00:56:46.370 --> 00:56:47.680
That's your 60 FPS.

00:56:47.680 --> 00:56:48.600
JOHN MCCUTCHAN: Exactly,
yeah, so--

00:56:48.600 --> 00:56:50.430
[INTERPOSING VOICES]

00:56:50.430 --> 00:56:52.060
JOHN MCCUTCHAN: We've completely
blown our budget.

00:56:52.060 --> 00:56:53.590
ILYA GRIGORIK: So how
many do we have?

00:56:53.590 --> 00:57:00.438
JOHN MCCUTCHAN: Let's see,
60, 30, and then--

00:57:00.438 --> 00:57:02.010
15 or something, I don't know.

00:57:02.010 --> 00:57:04.970
One, two, three, four, five--

00:57:04.970 --> 00:57:06.865
ILYA GRIGORIK: So when we
recorded it, I think it was 15

00:57:06.865 --> 00:57:09.020
frames per second.

00:57:09.020 --> 00:57:11.810
JOHN MCCUTCHAN: Yeah, maybe
8 or something like that.

00:57:11.810 --> 00:57:16.900
We have about 8 times 16, and
we can see here that this

00:57:16.900 --> 00:57:20.960
whole thing is taking
133 milliseconds.

00:57:20.960 --> 00:57:24.290
ILYA GRIGORIK: OK, so we're just
getting less than 10 FPS.

00:57:24.290 --> 00:57:25.370
So this is your eight frames.

00:57:25.370 --> 00:57:28.140
JOHN MCCUTCHAN: Yeah, because
you have 1,000 milliseconds,

00:57:28.140 --> 00:57:30.820
and we're spending 133.

00:57:30.820 --> 00:57:33.210
But I want to point out here
that, by clicking on the

00:57:33.210 --> 00:57:36.910
message loop run task, it will
actually tell you the duration

00:57:36.910 --> 00:57:39.700
of that slice, which
is very helpful.

00:57:39.700 --> 00:57:40.980
You don't have to like--

00:57:40.980 --> 00:57:44.070
we're sitting here counting grid
lines when we could have

00:57:44.070 --> 00:57:44.820
just clicked.

00:57:44.820 --> 00:57:46.580
ILYA GRIGORIK: Right,
but you know what?

00:57:46.580 --> 00:57:48.040
So here's a question.

00:57:48.040 --> 00:57:51.990
It seems we're taking all of
this time to just draw a

00:57:51.990 --> 00:57:54.190
scene, but it seems
like it's not even

00:57:54.190 --> 00:57:55.950
painting immediately either.

00:57:55.950 --> 00:57:57.450
It's waiting a little bit,
and then it's painting.

00:57:57.450 --> 00:57:59.340
JOHN MCCUTCHAN: So let me take
another capture, which will

00:57:59.340 --> 00:58:01.120
even better illustrate this.

00:58:01.120 --> 00:58:03.880
So if we switch over to 30,
which looks pretty much

00:58:03.880 --> 00:58:08.580
exactly like 60, but it's not.

00:58:08.580 --> 00:58:13.220
Let me take a recording here, so
I'll just let it to do its

00:58:13.220 --> 00:58:17.400
thing, and then I'll
stop the trace.

00:58:17.400 --> 00:58:22.810
And again, the first thing you
do you find 68139, which is

00:58:22.810 --> 00:58:26.580
down here, and then
you zoom in.

00:58:26.580 --> 00:58:32.360
And you find that shape,
that same shape as--

00:58:32.360 --> 00:58:34.150
ILYA GRIGORIK: So it's like
compositor thread, just

00:58:34.150 --> 00:58:35.330
working with GPU.

00:58:35.330 --> 00:58:39.310
JOHN MCCUTCHAN: Here we are at
our RequestAnimationFrame, and

00:58:39.310 --> 00:58:42.940
if we click on that, we can see,
well, now our total frame

00:58:42.940 --> 00:58:44.810
update time is about 15.3.

00:58:44.810 --> 00:58:45.480
ILYA GRIGORIK: So
we're actually

00:58:45.480 --> 00:58:46.920
just right under budget.

00:58:46.920 --> 00:58:49.080
JOHN MCCUTCHAN: Yes, and with
that, you would expect to be

00:58:49.080 --> 00:58:49.710
running at 60.

00:58:49.710 --> 00:58:50.630
ILYA GRIGORIK: Yeah, I am.

00:58:50.630 --> 00:58:51.880
It's happening.

00:58:51.880 --> 00:58:52.910
JOHN MCCUTCHAN: Let's see.

00:58:52.910 --> 00:58:56.845
So I've gone ahead and I've
selected our tower of drawing,

00:58:56.845 --> 00:58:58.590
and we lay down the
grid lines.

00:58:58.590 --> 00:59:04.540
And you can see that, while
here's the previous draw here,

00:59:04.540 --> 00:59:09.690
and if we measure it out from
one draw to the next draw on

00:59:09.690 --> 00:59:10.230
the timeline--

00:59:10.230 --> 00:59:11.360
ILYA GRIGORIK: It's taking
32 milliseconds.

00:59:11.360 --> 00:59:12.430
JOHN MCCUTCHAN: It's taking
32 milliseconds.

00:59:12.430 --> 00:59:13.900
ILYA GRIGORIK: So that's
a dropped frame.

00:59:13.900 --> 00:59:15.860
JOHN MCCUTCHAN: Exactly, and
when you really drill into it,

00:59:15.860 --> 00:59:20.780
you can see that, while our code
executed well within the

00:59:20.780 --> 00:59:24.670
16 millisecond boundary,
Chrome's entire machinery

00:59:24.670 --> 00:59:26.470
takes a little bit of time
to get it set up

00:59:26.470 --> 00:59:27.400
to execute our code.

00:59:27.400 --> 00:59:31.080
And then afterwards, in this
specific case, what it's doing

00:59:31.080 --> 00:59:34.130
here is we've painted under
the canvas, and now it's

00:59:34.130 --> 00:59:35.760
actually flushing the canvas.

00:59:35.760 --> 00:59:37.950
So all of our paint
operations are now

00:59:37.950 --> 00:59:40.060
being realized in memory.

00:59:40.060 --> 00:59:42.460
Following that, we have
something called the commit

00:59:42.460 --> 00:59:46.740
stage, and this is where Chrome
is signaling to the

00:59:46.740 --> 00:59:50.920
compositor thread, take the
canvas pixels and upload them

00:59:50.920 --> 00:59:52.270
to the GPU.

00:59:52.270 --> 00:59:58.860
When commit is finished, it's
only at the next v-sync that

00:59:58.860 --> 01:00:00.190
the draw will occur.

01:00:00.190 --> 01:00:02.320
ILYA GRIGORIK: Right, so we
already passed our 16

01:00:02.320 --> 01:00:05.090
millisecond boundary, so at this
point Chrome just says,

01:00:05.090 --> 01:00:07.350
look, I'm just going to wait
until the end of next frame.

01:00:07.350 --> 01:00:08.530
JOHN MCCUTCHAN: Yeah, and that's
really what it is.

01:00:08.530 --> 01:00:12.910
You are idle for, like, 14
milliseconds, doing nothing,

01:00:12.910 --> 01:00:14.730
while Chrome is like,
I'm ready to paint.

01:00:14.730 --> 01:00:19.140
Just tell me when the v-sync
hits, and I'll go.

01:00:19.140 --> 01:00:24.170
So if we go back here, and we
click on 60, again my eyes

01:00:24.170 --> 01:00:26.980
can't tell the difference,
but Chrome can.

01:00:26.980 --> 01:00:29.660
So I've switched it to 60, and
I'll do a recording here.

01:00:29.660 --> 01:00:31.120
I'll let it run.

01:00:31.120 --> 01:00:38.350
I'll stop, and here we are down
at the render thread.

01:00:38.350 --> 01:00:41.960
You start to get to know the
colors, so I've got my

01:00:41.960 --> 01:00:44.380
message loop here.

01:00:44.380 --> 01:00:51.815
So I find my draw call,
and it's not that one.

01:00:51.815 --> 01:00:53.490
It's over here.

01:00:53.490 --> 01:00:54.160
Here's a draw.

01:00:54.160 --> 01:00:55.720
You can see Draw Layers.

01:00:55.720 --> 01:01:00.340
So I pick that here, and I press
G, and I lay down my 16

01:01:00.340 --> 01:01:01.510
millisecond grid.

01:01:01.510 --> 01:01:04.780
So because my frame time
in total was only six

01:01:04.780 --> 01:01:08.390
milliseconds this time, Chrome
was able to run my frame

01:01:08.390 --> 01:01:11.010
update, do all of its
extra processing,

01:01:11.010 --> 01:01:14.340
upload it to the GPU.

01:01:14.340 --> 01:01:17.860
This is that commit phase again,
where it's realizing

01:01:17.860 --> 01:01:20.440
the requested changes
I want the canvas,

01:01:20.440 --> 01:01:21.990
uploading it to the GPU.

01:01:21.990 --> 01:01:24.710
But that is all finished in--

01:01:24.710 --> 01:01:26.910
well, we can click on
this right here.

01:01:26.910 --> 01:01:28.200
ILYA GRIGORIK: About
seven milliseconds.

01:01:28.200 --> 01:01:29.330
JOHN MCCUTCHAN: Yeah,
seven milliseconds.

01:01:29.330 --> 01:01:31.770
ILYA GRIGORIK: So we're well
within our budget and, in

01:01:31.770 --> 01:01:35.210
fact, coming back to your
earlier point about mobile and

01:01:35.210 --> 01:01:39.660
different CPU and everything,
this is probably what you want

01:01:39.660 --> 01:01:41.290
to see on your app if
you're targeting--

01:01:41.290 --> 01:01:44.610
JOHN MCCUTCHAN: You've got
this nice space here.

01:01:44.610 --> 01:01:47.270
That's great, because that means
that if you happen to be

01:01:47.270 --> 01:01:50.070
running on a slower machine or
a machine that happens to be

01:01:50.070 --> 01:01:52.000
bogged down, you've got room.

01:01:52.000 --> 01:01:52.850
ILYA GRIGORIK: Right.

01:01:52.850 --> 01:01:54.290
JOHN MCCUTCHAN: What's
interesting here is this guy

01:01:54.290 --> 01:01:58.100
right here is actually
a input handle.

01:01:58.100 --> 01:02:00.500
It's a HandleMouseMove event.

01:02:00.500 --> 01:02:04.190
So after the frame update,
Chrome noticed that I moved my

01:02:04.190 --> 01:02:07.220
mouse and notified the thread
and said, hey, do any mouse

01:02:07.220 --> 01:02:08.390
move processing you
have to do.

01:02:08.390 --> 01:02:12.000
I have none, so it
just bubbles out.

01:02:12.000 --> 01:02:15.910
ILYA GRIGORIK: So I think this
is a great highlight of--

01:02:15.910 --> 01:02:17.645
this is a very low-level view.

01:02:17.645 --> 01:02:20.525
You could correlate, I
press the keyboard--

01:02:20.525 --> 01:02:21.850
JOHN MCCUTCHAN: And
this happens.

01:02:21.850 --> 01:02:23.500
ILYA GRIGORIK: Right, or press a
key on my keyboard, and this

01:02:23.500 --> 01:02:26.400
happened that kicked off this V8
function, which did a draw

01:02:26.400 --> 01:02:28.840
call, and you can see
a pyramid, and

01:02:28.840 --> 01:02:29.505
now I'm over budget.

01:02:29.505 --> 01:02:30.200
JOHN MCCUTCHAN: Exactly, yeah.

01:02:30.200 --> 01:02:32.160
ILYA GRIGORIK: Or
hopefully not.

01:02:32.160 --> 01:02:34.220
JOHN MCCUTCHAN: And you'll see
things like we saw with the 38

01:02:34.220 --> 01:02:37.540
frames per second capture, which
even visually-- like, if

01:02:37.540 --> 01:02:39.130
you asked me, is that running
at 60, I'd be

01:02:39.130 --> 01:02:40.880
like, yeah, of course.

01:02:40.880 --> 01:02:43.030
I know I'm under 60
milliseconds.

01:02:43.030 --> 01:02:43.920
It looks as smooth.

01:02:43.920 --> 01:02:46.600
I can't tell the difference, but
when you really drill in,

01:02:46.600 --> 01:02:49.910
you can tell that you're,
in fact, not.

01:02:49.910 --> 01:02:53.630
Your game update is at 60 hertz,
but the rendering is

01:02:53.630 --> 01:02:56.650
delayed because you just
tip over that boundary.

01:02:56.650 --> 01:02:58.920
ILYA GRIGORIK: So I think this
tool deserves at least several

01:02:58.920 --> 01:03:01.070
more episodes down the road,
because I think it's very

01:03:01.070 --> 01:03:04.020
interesting to look at
different tools.

01:03:04.020 --> 01:03:05.560
So with that, let's
see if we have any

01:03:05.560 --> 01:03:08.330
questions that we can answer.

01:03:08.330 --> 01:03:11.440
And we have a few.

01:03:11.440 --> 01:03:15.480
So the first one is, is it
possible to capture and export

01:03:15.480 --> 01:03:18.390
this tracing data from outside
of Chrome, so if I want to

01:03:18.390 --> 01:03:21.800
have it as part of Build Script
or something similar?

01:03:21.800 --> 01:03:24.240
JOHN MCCUTCHAN: Yes, so
Chrome://tracing actually, as

01:03:24.240 --> 01:03:27.460
its file format, uses
a JSON text file.

01:03:27.460 --> 01:03:32.030
So you can synthesize your own
traces and upload them through

01:03:32.030 --> 01:03:35.730
the Load button inside
Chrome://tracing from any

01:03:35.730 --> 01:03:36.460
program, actually.

01:03:36.460 --> 01:03:40.180
I've used it instrumenting my
Direct3D 11 game engine.

01:03:40.180 --> 01:03:42.630
I've written out a stream
of JSON and then

01:03:42.630 --> 01:03:43.670
just loaded it in.

01:03:43.670 --> 01:03:44.400
ILYA GRIGORIK: This
reminds me.

01:03:44.400 --> 01:03:48.070
We actually had an awesome
talk at Google I/O about

01:03:48.070 --> 01:03:52.350
Android generating a trace,
which you can import, and it's

01:03:52.350 --> 01:03:53.190
a Chrome://tracing--

01:03:53.190 --> 01:03:56.780
so you export your debugging
your profiling data from your

01:03:56.780 --> 01:03:58.790
Android device, import it
into Chrome, and use

01:03:58.790 --> 01:03:59.750
Chrome://tracing
to analyze it.

01:03:59.750 --> 01:04:01.680
JOHN MCCUTCHAN: I think
Project Butter used it

01:04:01.680 --> 01:04:02.430
extensively.

01:04:02.430 --> 01:04:03.260
ILYA GRIGORIK: Yeah.

01:04:03.260 --> 01:04:06.920
JOHN MCCUTCHAN: So this,
I think, is the Android

01:04:06.920 --> 01:04:07.930
profiler, as well.

01:04:07.930 --> 01:04:09.050
ILYA GRIGORIK: Right,
very cool.

01:04:09.050 --> 01:04:10.370
JOHN MCCUTCHAN: And furthermore
to this point,

01:04:10.370 --> 01:04:11.760
I've actually enabled--

01:04:11.760 --> 01:04:15.550
so Chrome://tracing has an
open-source side project

01:04:15.550 --> 01:04:18.210
called Trace-Viewer, and you
can just Google for Trace

01:04:18.210 --> 01:04:20.100
hyphen Viewer and go there.

01:04:20.100 --> 01:04:24.090
And what I've added to
Trace-Viewer is a support for

01:04:24.090 --> 01:04:26.080
streaming over WebSockets.

01:04:26.080 --> 01:04:29.520
So you could have a web
application hosting the

01:04:29.520 --> 01:04:33.460
Chrome://tracing UI, connect
over WebSockets to some

01:04:33.460 --> 01:04:36.740
server, and have the server
be streaming live.

01:04:36.740 --> 01:04:38.560
ILYA GRIGORIK: So we're going
to have you back and talk

01:04:38.560 --> 01:04:40.460
about just that, because I
think that's an awesome

01:04:40.460 --> 01:04:40.920
application.

01:04:40.920 --> 01:04:43.490
But I guess that one of the
highlights there is you can

01:04:43.490 --> 01:04:45.610
actually take the
Chrome://tracing

01:04:45.610 --> 01:04:46.910
stuff out of Chrome.

01:04:46.910 --> 01:04:48.110
It's just a web app.

01:04:48.110 --> 01:04:50.760
You just feed it data, so you
can embed it in your own

01:04:50.760 --> 01:04:51.860
application, if you want.

01:04:51.860 --> 01:04:52.340
JOHN MCCUTCHAN: Of course.

01:04:52.340 --> 01:04:56.220
ILYA GRIGORIK: Yeah, awesome, So
next we have, "So sometimes

01:04:56.220 --> 01:04:59.850
we made real time service
with long-polling.

01:04:59.850 --> 01:05:01.560
It's very hard for me
to get a profile

01:05:01.560 --> 01:05:02.680
result of loading time.

01:05:02.680 --> 01:05:05.390
Do you have any suggestions
for these situations?"

01:05:05.390 --> 01:05:09.150
So maybe I can take this one.

01:05:09.150 --> 01:05:11.280
So Chrome://tracing may
not be the exact tool.

01:05:11.280 --> 01:05:15.110
It may show you some network
data, but what you probably

01:05:15.110 --> 01:05:19.450
want there is actually to use
navigation timing data, or

01:05:19.450 --> 01:05:21.930
what's coming soon is
resource timing.

01:05:21.930 --> 01:05:22.790
So I think--

01:05:22.790 --> 01:05:26.430
I hope, fingers crossed-- this
will be in Chrome 25.

01:05:26.430 --> 01:05:31.380
The idea there, that you'll be
able to extract all of the TCP

01:05:31.380 --> 01:05:34.450
connection times, DNS times, and
all the other metadata--

01:05:34.450 --> 01:05:37.560
as you can today for your main
page, the main resource page--

01:05:37.560 --> 01:05:40.870
for every resource that you're
making a request against.

01:05:40.870 --> 01:05:43.800
So you'll know exactly how long
that page is taking, why

01:05:43.800 --> 01:05:46.860
it's taking so long,
et cetera.

01:05:46.860 --> 01:05:48.976
So Chrome://tracing may not be
the exact tool that you're

01:05:48.976 --> 01:05:50.903
looking for, but there are the
ways to get at that data.

01:05:50.903 --> 01:05:51.690
JOHN MCCUTCHAN: Interesting.

01:05:51.690 --> 01:05:52.940
ILYA GRIGORIK: Yeah.

01:05:55.755 --> 01:05:57.610
"Can I use sampling to
benchmark my Chrome

01:05:57.610 --> 01:05:57.980
extensions?"

01:05:57.980 --> 01:06:00.970
JOHN MCCUTCHAN: Yeah, I think
you can, because from within a

01:06:00.970 --> 01:06:03.540
Chrome extension, there's some
element associated with it.

01:06:03.540 --> 01:06:03.800
Right?

01:06:03.800 --> 01:06:04.470
ILYA GRIGORIK: Yeah.

01:06:04.470 --> 01:06:06.500
JOHN MCCUTCHAN: And then from
that element, you can bring up

01:06:06.500 --> 01:06:07.270
the Chrome dev tools.

01:06:07.270 --> 01:06:09.100
ILYA GRIGORIK: Yeah, so I
believe Chrome Extension just

01:06:09.100 --> 01:06:12.330
basically runs in a background
tab, so you can open your

01:06:12.330 --> 01:06:16.070
about:memory, find a PID,
and do the same thing.

01:06:16.070 --> 01:06:18.550
So console.time, timeEnd,
and you should be--

01:06:18.550 --> 01:06:20.240
JOHN MCCUTCHAN: Yeah, yeah,
you just put that in your

01:06:20.240 --> 01:06:21.050
extension code.

01:06:21.050 --> 01:06:22.300
ILYA GRIGORIK: Yeah, OK.

01:06:24.500 --> 01:06:27.260
"Wouldn't it be interesting
if I not only used this to

01:06:27.260 --> 01:06:31.400
improve my web app but also
to do a sort of regression

01:06:31.400 --> 01:06:34.570
testing on my server?"
Yes, absolutely.

01:06:34.570 --> 01:06:38.220
So I think this hints at
the automation piece.

01:06:38.220 --> 01:06:42.190
So let's say we have this
profiling code, in--

01:06:42.190 --> 01:06:43.660
well, it's there.

01:06:43.660 --> 01:06:46.700
And as part of our build, we
actually log out some of this

01:06:46.700 --> 01:06:49.960
data and somehow monitor it
and trigger alerts on it.

01:06:49.960 --> 01:06:51.230
JOHN MCCUTCHAN: Of
course, right?

01:06:51.230 --> 01:06:54.310
I mean, from within
Chrome://tracing, you can

01:06:54.310 --> 01:06:55.160
export the data.

01:06:55.160 --> 01:06:57.870
And when you export the data,
it's just a JSON file.

01:06:57.870 --> 01:07:00.930
So you could write any set of
tools that you want that will

01:07:00.930 --> 01:07:04.330
process this and put it into a
database and graph it for you.

01:07:04.330 --> 01:07:06.410
ILYA GRIGORIK: So we were
talking about this just before

01:07:06.410 --> 01:07:10.090
the show, but I don't think
there's a way to do that in a

01:07:10.090 --> 01:07:12.980
completely automated manner,
like you can just tell Chrome,

01:07:12.980 --> 01:07:14.280
dump into this file.

01:07:14.280 --> 01:07:17.100
JOHN MCCUTCHAN: Yeah, I mean,
it may be, but I'm not aware

01:07:17.100 --> 01:07:19.090
of a way to do it, either,
although that's something I

01:07:19.090 --> 01:07:20.190
would love to have.

01:07:20.190 --> 01:07:22.657
ILYA GRIGORIK: So maybe that's
a future request, I guess.

01:07:22.657 --> 01:07:24.020
JOHN MCCUTCHAN: Yeah.

01:07:24.020 --> 01:07:26.000
ILYA GRIGORIK: Do the time
and timeEnd have the

01:07:26.000 --> 01:07:27.070
same matching name--

01:07:27.070 --> 01:07:29.180
or do they have to have the
same matching name?

01:07:29.180 --> 01:07:30.630
JOHN MCCUTCHAN: Yes.

01:07:30.630 --> 01:07:35.320
So if you pass in time with foo,
you pass in timeEnd with

01:07:35.320 --> 01:07:38.180
foo to mark the end of the
time region, although you

01:07:38.180 --> 01:07:41.430
could have many nested
and kind of

01:07:41.430 --> 01:07:44.090
overlapping time slices.

01:07:44.090 --> 01:07:45.090
ILYA GRIGORIK: OK, perfect.

01:07:45.090 --> 01:07:46.190
I think that's it.

01:07:46.190 --> 01:07:49.030
So we're actually going to post
the slides, as well, on

01:07:49.030 --> 01:07:51.540
the Google+ event page,
so take a look there.

01:07:51.540 --> 01:07:53.810
And if you guys have any
follow-up questions, feel free

01:07:53.810 --> 01:07:56.000
to ping either one
of us on Google+.

01:07:56.000 --> 01:07:57.990
We'll be happy to answer
your questions.

01:07:57.990 --> 01:07:58.790
Thanks.

01:07:58.790 --> 01:08:00.040
JOHN MCCUTCHAN: Thank you.

01:08:06.525 --> 01:10:37.633
[MUSIC PLAYING]

