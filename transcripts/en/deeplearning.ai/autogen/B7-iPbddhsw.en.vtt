WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.389
in the earlier videos from this week as

00:00:02.389 --> 00:00:02.399
in the earlier videos from this week as
 

00:00:02.399 --> 00:00:04.820
in the earlier videos from this week as
well as from the videos from the past

00:00:04.820 --> 00:00:04.830
well as from the videos from the past
 

00:00:04.830 --> 00:00:06.800
well as from the videos from the past
several weeks you've already seen the

00:00:06.800 --> 00:00:06.810
several weeks you've already seen the
 

00:00:06.810 --> 00:00:08.480
several weeks you've already seen the
basic building blocks of board

00:00:08.480 --> 00:00:08.490
basic building blocks of board
 

00:00:08.490 --> 00:00:10.700
basic building blocks of board
propagation and back propagation the key

00:00:10.700 --> 00:00:10.710
propagation and back propagation the key
 

00:00:10.710 --> 00:00:12.919
propagation and back propagation the key
components you need to implement a deep

00:00:12.919 --> 00:00:12.929
components you need to implement a deep
 

00:00:12.929 --> 00:00:15.079
components you need to implement a deep
neural network let's see how you can put

00:00:15.079 --> 00:00:15.089
neural network let's see how you can put
 

00:00:15.089 --> 00:00:17.120
neural network let's see how you can put
these components together to build your

00:00:17.120 --> 00:00:17.130
these components together to build your
 

00:00:17.130 --> 00:00:19.730
these components together to build your
deep net use the network with a few

00:00:19.730 --> 00:00:19.740
deep net use the network with a few
 

00:00:19.740 --> 00:00:23.359
deep net use the network with a few
layers let's pick one layer and look at

00:00:23.359 --> 00:00:23.369
layers let's pick one layer and look at
 

00:00:23.369 --> 00:00:26.240
layers let's pick one layer and look at
the computations focusing on just that

00:00:26.240 --> 00:00:26.250
the computations focusing on just that
 

00:00:26.250 --> 00:00:29.900
the computations focusing on just that
layer for now so for layer L you have

00:00:29.900 --> 00:00:29.910
layer for now so for layer L you have
 

00:00:29.910 --> 00:00:34.069
layer for now so for layer L you have
some parameters WL and Bo and for the

00:00:34.069 --> 00:00:34.079
some parameters WL and Bo and for the
 

00:00:34.079 --> 00:00:39.220
some parameters WL and Bo and for the
forward prop you will input the

00:00:39.220 --> 00:00:39.230
forward prop you will input the
 

00:00:39.230 --> 00:00:42.440
forward prop you will input the
activations a L minus 1 from the

00:00:42.440 --> 00:00:42.450
activations a L minus 1 from the
 

00:00:42.450 --> 00:00:49.279
activations a L minus 1 from the
previous layer and output Al so the way

00:00:49.279 --> 00:00:49.289
previous layer and output Al so the way
 

00:00:49.289 --> 00:00:52.670
previous layer and output Al so the way
we did this previously was you compute Z

00:00:52.670 --> 00:00:52.680
we did this previously was you compute Z
 

00:00:52.680 --> 00:01:00.590
we did this previously was you compute Z
l equals WL x al minus 1 plus BL um and

00:01:00.590 --> 00:01:00.600
l equals WL x al minus 1 plus BL um and
 

00:01:00.600 --> 00:01:08.420
l equals WL x al minus 1 plus BL um and
then al equals G of ZL right so that's

00:01:08.420 --> 00:01:08.430
then al equals G of ZL right so that's
 

00:01:08.430 --> 00:01:11.450
then al equals G of ZL right so that's
how you go from the input al minus 1 to

00:01:11.450 --> 00:01:11.460
how you go from the input al minus 1 to
 

00:01:11.460 --> 00:01:14.510
how you go from the input al minus 1 to
the output al and it turns out that for

00:01:14.510 --> 00:01:14.520
the output al and it turns out that for
 

00:01:14.520 --> 00:01:17.510
the output al and it turns out that for
later use will be useful to also cache

00:01:17.510 --> 00:01:17.520
later use will be useful to also cache
 

00:01:17.520 --> 00:01:22.280
later use will be useful to also cache
the value ZL so let me include this on

00:01:22.280 --> 00:01:22.290
the value ZL so let me include this on
 

00:01:22.290 --> 00:01:25.100
the value ZL so let me include this on
cache as well because storing the value

00:01:25.100 --> 00:01:25.110
cache as well because storing the value
 

00:01:25.110 --> 00:01:28.670
cache as well because storing the value
ZL will be useful for backward for the

00:01:28.670 --> 00:01:28.680
ZL will be useful for backward for the
 

00:01:28.680 --> 00:01:31.460
ZL will be useful for backward for the
back propagation step later and then for

00:01:31.460 --> 00:01:31.470
back propagation step later and then for
 

00:01:31.470 --> 00:01:33.289
back propagation step later and then for
the backward step or 3 for the back

00:01:33.289 --> 00:01:33.299
the backward step or 3 for the back
 

00:01:33.299 --> 00:01:35.270
the backward step or 3 for the back
propagation step again focusing on

00:01:35.270 --> 00:01:35.280
propagation step again focusing on
 

00:01:35.280 --> 00:01:37.969
propagation step again focusing on
computation for this layer L you're

00:01:37.969 --> 00:01:37.979
computation for this layer L you're
 

00:01:37.979 --> 00:01:39.890
computation for this layer L you're
going to implement a function that

00:01:39.890 --> 00:01:39.900
going to implement a function that
 

00:01:39.900 --> 00:01:51.160
going to implement a function that
inputs da of L and output da L minus 1

00:01:51.160 --> 00:01:51.170
inputs da of L and output da L minus 1
 

00:01:51.170 --> 00:01:53.719
inputs da of L and output da L minus 1
and just the special the details the

00:01:53.719 --> 00:01:53.729
and just the special the details the
 

00:01:53.729 --> 00:01:58.069
and just the special the details the
input is actually da FL as well as the

00:01:58.069 --> 00:01:58.079
input is actually da FL as well as the
 

00:01:58.079 --> 00:02:01.219
input is actually da FL as well as the
cache so you have available to you the

00:02:01.219 --> 00:02:01.229
cache so you have available to you the
 

00:02:01.229 --> 00:02:04.510
cache so you have available to you the
value of ZL that you compute it and

00:02:04.510 --> 00:02:04.520
value of ZL that you compute it and
 

00:02:04.520 --> 00:02:07.090
value of ZL that you compute it and
in addition to outputting GL minus 1 you

00:02:07.090 --> 00:02:07.100
in addition to outputting GL minus 1 you
 

00:02:07.100 --> 00:02:10.419
in addition to outputting GL minus 1 you
will output the gradients you want in

00:02:10.419 --> 00:02:10.429
will output the gradients you want in
 

00:02:10.429 --> 00:02:12.820
will output the gradients you want in
order to implement gradient descent for

00:02:12.820 --> 00:02:12.830
order to implement gradient descent for
 

00:02:12.830 --> 00:02:15.720
order to implement gradient descent for
learning okay so this is the basic

00:02:15.720 --> 00:02:15.730
learning okay so this is the basic
 

00:02:15.730 --> 00:02:18.820
learning okay so this is the basic
structure of how you implement this

00:02:18.820 --> 00:02:18.830
structure of how you implement this
 

00:02:18.830 --> 00:02:20.619
structure of how you implement this
forward step I'm going to call the

00:02:20.619 --> 00:02:20.629
forward step I'm going to call the
 

00:02:20.629 --> 00:02:21.789
forward step I'm going to call the
forward function as well as this

00:02:21.789 --> 00:02:21.799
forward function as well as this
 

00:02:21.799 --> 00:02:23.710
forward function as well as this
backward step using a callback wave

00:02:23.710 --> 00:02:23.720
backward step using a callback wave
 

00:02:23.720 --> 00:02:27.150
backward step using a callback wave
function so just to summarize in layer L

00:02:27.150 --> 00:02:27.160
function so just to summarize in layer L
 

00:02:27.160 --> 00:02:29.979
function so just to summarize in layer L
you're going to have you know the

00:02:29.979 --> 00:02:29.989
you're going to have you know the
 

00:02:29.989 --> 00:02:31.509
you're going to have you know the
forward step or the forward property'

00:02:31.509 --> 00:02:31.519
forward step or the forward property'
 

00:02:31.519 --> 00:02:35.460
forward step or the forward property'
forward function input 800 minus 1 and

00:02:35.460 --> 00:02:35.470
forward function input 800 minus 1 and
 

00:02:35.470 --> 00:02:41.319
forward function input 800 minus 1 and
output Al and in order to make this

00:02:41.319 --> 00:02:41.329
output Al and in order to make this
 

00:02:41.329 --> 00:02:43.990
output Al and in order to make this
computation you need to use wo and BL um

00:02:43.990 --> 00:02:44.000
computation you need to use wo and BL um
 

00:02:44.000 --> 00:02:49.440
computation you need to use wo and BL um
and also output a cache which contains

00:02:49.440 --> 00:02:49.450
and also output a cache which contains
 

00:02:49.450 --> 00:02:53.949
and also output a cache which contains
ZL and then on the backward function

00:02:53.949 --> 00:02:53.959
ZL and then on the backward function
 

00:02:53.959 --> 00:02:58.630
ZL and then on the backward function
using the back prop step will be another

00:02:58.630 --> 00:02:58.640
using the back prop step will be another
 

00:02:58.640 --> 00:03:04.589
using the back prop step will be another
function then now inputs the AFL and

00:03:04.589 --> 00:03:04.599
function then now inputs the AFL and
 

00:03:04.599 --> 00:03:09.840
function then now inputs the AFL and
outputs da l minus 1 so it tells you

00:03:09.840 --> 00:03:09.850
outputs da l minus 1 so it tells you
 

00:03:09.850 --> 00:03:12.670
outputs da l minus 1 so it tells you
given the derivatives respect to these

00:03:12.670 --> 00:03:12.680
given the derivatives respect to these
 

00:03:12.680 --> 00:03:16.150
given the derivatives respect to these
activations that's da FL how what are

00:03:16.150 --> 00:03:16.160
activations that's da FL how what are
 

00:03:16.160 --> 00:03:17.800
activations that's da FL how what are
the derivatives or how much do I wish

00:03:17.800 --> 00:03:17.810
the derivatives or how much do I wish
 

00:03:17.810 --> 00:03:21.009
the derivatives or how much do I wish
you know al minus 1 changes to compute

00:03:21.009 --> 00:03:21.019
you know al minus 1 changes to compute
 

00:03:21.019 --> 00:03:22.629
you know al minus 1 changes to compute
the derivatives respect to the

00:03:22.629 --> 00:03:22.639
the derivatives respect to the
 

00:03:22.639 --> 00:03:24.720
the derivatives respect to the
activations from the previous layer

00:03:24.720 --> 00:03:24.730
activations from the previous layer
 

00:03:24.730 --> 00:03:28.090
activations from the previous layer
within this box ready need to use WL and

00:03:28.090 --> 00:03:28.100
within this box ready need to use WL and
 

00:03:28.100 --> 00:03:31.150
within this box ready need to use WL and
BL and it turns out along the way you

00:03:31.150 --> 00:03:31.160
BL and it turns out along the way you
 

00:03:31.160 --> 00:03:36.129
BL and it turns out along the way you
end up computing VL and then this false

00:03:36.129 --> 00:03:36.139
end up computing VL and then this false
 

00:03:36.139 --> 00:03:39.509
end up computing VL and then this false
this backward function can also output

00:03:39.509 --> 00:03:39.519
this backward function can also output
 

00:03:39.519 --> 00:03:45.250
this backward function can also output
dwl and DB l but now sometimes using red

00:03:45.250 --> 00:03:45.260
dwl and DB l but now sometimes using red
 

00:03:45.260 --> 00:03:47.349
dwl and DB l but now sometimes using red
arrows to denote the backward elevation

00:03:47.349 --> 00:03:47.359
arrows to denote the backward elevation
 

00:03:47.359 --> 00:03:49.780
arrows to denote the backward elevation
so if you prefer we could draw these

00:03:49.780 --> 00:03:49.790
so if you prefer we could draw these
 

00:03:49.790 --> 00:03:53.129
so if you prefer we could draw these
arrows in red so if you can implement

00:03:53.129 --> 00:03:53.139
arrows in red so if you can implement
 

00:03:53.139 --> 00:03:56.140
arrows in red so if you can implement
these two functions then the basic

00:03:56.140 --> 00:03:56.150
these two functions then the basic
 

00:03:56.150 --> 00:03:57.970
these two functions then the basic
computation of the neural network will

00:03:57.970 --> 00:03:57.980
computation of the neural network will
 

00:03:57.980 --> 00:04:00.970
computation of the neural network will
be as follows you're going to take the

00:04:00.970 --> 00:04:00.980
be as follows you're going to take the
 

00:04:00.980 --> 00:04:04.289
be as follows you're going to take the
input features a zero see that in and

00:04:04.289 --> 00:04:04.299
input features a zero see that in and
 

00:04:04.299 --> 00:04:06.759
input features a zero see that in and
that will compute the activations of the

00:04:06.759 --> 00:04:06.769
that will compute the activations of the
 

00:04:06.769 --> 00:04:10.330
that will compute the activations of the
first layer let's call that a 1 and to

00:04:10.330 --> 00:04:10.340
first layer let's call that a 1 and to
 

00:04:10.340 --> 00:04:15.430
first layer let's call that a 1 and to
do that you needed W 1 and B 1 and then

00:04:15.430 --> 00:04:15.440
do that you needed W 1 and B 1 and then
 

00:04:15.440 --> 00:04:17.860
do that you needed W 1 and B 1 and then
we'll also you know cache

00:04:17.860 --> 00:04:17.870
we'll also you know cache
 

00:04:17.870 --> 00:04:22.780
we'll also you know cache
away v1 now having done that you feed

00:04:22.780 --> 00:04:22.790
away v1 now having done that you feed
 

00:04:22.790 --> 00:04:25.629
away v1 now having done that you feed
that this is the second layer and then

00:04:25.629 --> 00:04:25.639
that this is the second layer and then
 

00:04:25.639 --> 00:04:28.810
that this is the second layer and then
using W 2 and B 2 you're going to

00:04:28.810 --> 00:04:28.820
using W 2 and B 2 you're going to
 

00:04:28.820 --> 00:04:31.300
using W 2 and B 2 you're going to
compute the activations our next layer a

00:04:31.300 --> 00:04:31.310
compute the activations our next layer a
 

00:04:31.310 --> 00:04:37.270
compute the activations our next layer a
2 and so on until eventually you end up

00:04:37.270 --> 00:04:37.280
2 and so on until eventually you end up
 

00:04:37.280 --> 00:04:41.050
2 and so on until eventually you end up
outputting a capital L which is equal to

00:04:41.050 --> 00:04:41.060
outputting a capital L which is equal to
 

00:04:41.060 --> 00:04:47.080
outputting a capital L which is equal to
Y hat and along the way we cashed all of

00:04:47.080 --> 00:04:47.090
Y hat and along the way we cashed all of
 

00:04:47.090 --> 00:04:53.409
Y hat and along the way we cashed all of
these on values Z so that's the forward

00:04:53.409 --> 00:04:53.419
these on values Z so that's the forward
 

00:04:53.419 --> 00:04:56.200
these on values Z so that's the forward
propagation step now for the back

00:04:56.200 --> 00:04:56.210
propagation step now for the back
 

00:04:56.210 --> 00:04:58.780
propagation step now for the back
propagation step what we're going to do

00:04:58.780 --> 00:04:58.790
propagation step what we're going to do
 

00:04:58.790 --> 00:05:03.159
propagation step what we're going to do
will be a backward sequence of

00:05:03.159 --> 00:05:03.169
will be a backward sequence of
 

00:05:03.169 --> 00:05:06.550
will be a backward sequence of
iterations in which you're going

00:05:06.550 --> 00:05:06.560
iterations in which you're going
 

00:05:06.560 --> 00:05:09.070
iterations in which you're going
backwards and computing gradients like

00:05:09.070 --> 00:05:09.080
backwards and computing gradients like
 

00:05:09.080 --> 00:05:15.540
backwards and computing gradients like
so so as you're going to feed in here da

00:05:15.540 --> 00:05:15.550
so so as you're going to feed in here da
 

00:05:15.550 --> 00:05:21.340
so so as you're going to feed in here da
L and then this box will give us da L

00:05:21.340 --> 00:05:21.350
L and then this box will give us da L
 

00:05:21.350 --> 00:05:31.230
L and then this box will give us da L
minus 1 and so on until we get da - da 1

00:05:31.230 --> 00:05:31.240
minus 1 and so on until we get da - da 1
 

00:05:31.240 --> 00:05:33.760
minus 1 and so on until we get da - da 1
you could actually get one more output

00:05:33.760 --> 00:05:33.770
you could actually get one more output
 

00:05:33.770 --> 00:05:37.540
you could actually get one more output
to compute da 0 but this is derivative

00:05:37.540 --> 00:05:37.550
to compute da 0 but this is derivative
 

00:05:37.550 --> 00:05:39.640
to compute da 0 but this is derivative
respect your input features which is not

00:05:39.640 --> 00:05:39.650
respect your input features which is not
 

00:05:39.650 --> 00:05:42.279
respect your input features which is not
useful at least for training the weights

00:05:42.279 --> 00:05:42.289
useful at least for training the weights
 

00:05:42.289 --> 00:05:45.450
useful at least for training the weights
of these are supervised neural networks

00:05:45.450 --> 00:05:45.460
of these are supervised neural networks
 

00:05:45.460 --> 00:05:48.670
of these are supervised neural networks
so you could just stop it there belong

00:05:48.670 --> 00:05:48.680
so you could just stop it there belong
 

00:05:48.680 --> 00:05:50.469
so you could just stop it there belong
the way back prop also ends up

00:05:50.469 --> 00:05:50.479
the way back prop also ends up
 

00:05:50.479 --> 00:05:56.200
the way back prop also ends up
outputting PWL DB l right this used

00:05:56.200 --> 00:05:56.210
outputting PWL DB l right this used
 

00:05:56.210 --> 00:06:01.600
outputting PWL DB l right this used
times with wo and BL this would output d

00:06:01.600 --> 00:06:01.610
times with wo and BL this would output d
 

00:06:01.610 --> 00:06:11.469
times with wo and BL this would output d
w3 t p3 and so on so you end up

00:06:11.469 --> 00:06:11.479
w3 t p3 and so on so you end up
 

00:06:11.479 --> 00:06:15.960
w3 t p3 and so on so you end up
computing all the derivatives you need

00:06:15.960 --> 00:06:15.970
 

00:06:15.970 --> 00:06:19.779
and so just a maybe so in the structure

00:06:19.779 --> 00:06:19.789
and so just a maybe so in the structure
 

00:06:19.789 --> 00:06:22.270
and so just a maybe so in the structure
of this a little bit more right these

00:06:22.270 --> 00:06:22.280
of this a little bit more right these
 

00:06:22.280 --> 00:06:27.320
of this a little bit more right these
boxes will use those parameters as well

00:06:27.320 --> 00:06:27.330
 

00:06:27.330 --> 00:06:32.330
wo PL and it turns out that we'll see

00:06:32.330 --> 00:06:32.340
wo PL and it turns out that we'll see
 

00:06:32.340 --> 00:06:34.730
wo PL and it turns out that we'll see
later that inside these boxes we'll end

00:06:34.730 --> 00:06:34.740
later that inside these boxes we'll end
 

00:06:34.740 --> 00:06:37.939
later that inside these boxes we'll end
up computing disease as well so one

00:06:37.939 --> 00:06:37.949
up computing disease as well so one
 

00:06:37.949 --> 00:06:39.710
up computing disease as well so one
iteration of training for a new network

00:06:39.710 --> 00:06:39.720
iteration of training for a new network
 

00:06:39.720 --> 00:06:43.010
iteration of training for a new network
involves starting with a zero which is X

00:06:43.010 --> 00:06:43.020
involves starting with a zero which is X
 

00:06:43.020 --> 00:06:46.749
involves starting with a zero which is X
and going through for profit as follows

00:06:46.749 --> 00:06:46.759
and going through for profit as follows
 

00:06:46.759 --> 00:06:49.369
and going through for profit as follows
computing y hats and then using that to

00:06:49.369 --> 00:06:49.379
computing y hats and then using that to
 

00:06:49.379 --> 00:06:53.570
computing y hats and then using that to
compute this and then back prop right

00:06:53.570 --> 00:06:53.580
compute this and then back prop right
 

00:06:53.580 --> 00:06:57.529
compute this and then back prop right
doing that and now you have all these

00:06:57.529 --> 00:06:57.539
doing that and now you have all these
 

00:06:57.539 --> 00:07:01.790
doing that and now you have all these
derivative terms and so you know W will

00:07:01.790 --> 00:07:01.800
derivative terms and so you know W will
 

00:07:01.800 --> 00:07:04.369
derivative terms and so you know W will
get updated as some W minus the learning

00:07:04.369 --> 00:07:04.379
get updated as some W minus the learning
 

00:07:04.379 --> 00:07:07.879
get updated as some W minus the learning
rate times DW right for each of the

00:07:07.879 --> 00:07:07.889
rate times DW right for each of the
 

00:07:07.889 --> 00:07:13.999
rate times DW right for each of the
layers and similarly for B right now

00:07:13.999 --> 00:07:14.009
layers and similarly for B right now
 

00:07:14.009 --> 00:07:16.369
layers and similarly for B right now
we've compute the back prop and have all

00:07:16.369 --> 00:07:16.379
we've compute the back prop and have all
 

00:07:16.379 --> 00:07:18.379
we've compute the back prop and have all
these derivatives so that's one

00:07:18.379 --> 00:07:18.389
these derivatives so that's one
 

00:07:18.389 --> 00:07:20.540
these derivatives so that's one
iteration of gradient descent for your

00:07:20.540 --> 00:07:20.550
iteration of gradient descent for your
 

00:07:20.550 --> 00:07:23.089
iteration of gradient descent for your
neural network now before moving on just

00:07:23.089 --> 00:07:23.099
neural network now before moving on just
 

00:07:23.099 --> 00:07:25.089
neural network now before moving on just
one more implementational detail

00:07:25.089 --> 00:07:25.099
one more implementational detail
 

00:07:25.099 --> 00:07:27.350
one more implementational detail
conceptually will be useful to think of

00:07:27.350 --> 00:07:27.360
conceptually will be useful to think of
 

00:07:27.360 --> 00:07:32.110
conceptually will be useful to think of
the cashier as storing the value of Z

00:07:32.110 --> 00:07:32.120
the cashier as storing the value of Z
 

00:07:32.120 --> 00:07:34.730
the cashier as storing the value of Z
for the backward functions but when you

00:07:34.730 --> 00:07:34.740
for the backward functions but when you
 

00:07:34.740 --> 00:07:36.469
for the backward functions but when you
implement this you see this in the

00:07:36.469 --> 00:07:36.479
implement this you see this in the
 

00:07:36.479 --> 00:07:37.730
implement this you see this in the
programming exercise when you implement

00:07:37.730 --> 00:07:37.740
programming exercise when you implement
 

00:07:37.740 --> 00:07:39.830
programming exercise when you implement
it you find that the cash may be a

00:07:39.830 --> 00:07:39.840
it you find that the cash may be a
 

00:07:39.840 --> 00:07:42.019
it you find that the cash may be a
convenient way to get this value of the

00:07:42.019 --> 00:07:42.029
convenient way to get this value of the
 

00:07:42.029 --> 00:07:45.409
convenient way to get this value of the
parameters at W 1 V 1 into the backward

00:07:45.409 --> 00:07:45.419
parameters at W 1 V 1 into the backward
 

00:07:45.419 --> 00:07:46.909
parameters at W 1 V 1 into the backward
function as well so the program exercise

00:07:46.909 --> 00:07:46.919
function as well so the program exercise
 

00:07:46.919 --> 00:07:49.760
function as well so the program exercise
you actually spawn the cash is Z as well

00:07:49.760 --> 00:07:49.770
you actually spawn the cash is Z as well
 

00:07:49.770 --> 00:07:55.659
you actually spawn the cash is Z as well
as W and B all right so to store z2w to

00:07:55.659 --> 00:07:55.669
as W and B all right so to store z2w to
 

00:07:55.669 --> 00:07:58.939
as W and B all right so to store z2w to
be 2 but from an implementational

00:07:58.939 --> 00:07:58.949
be 2 but from an implementational
 

00:07:58.949 --> 00:08:01.070
be 2 but from an implementational
standpoint i just find this a convenient

00:08:01.070 --> 00:08:01.080
standpoint i just find this a convenient
 

00:08:01.080 --> 00:08:04.309
standpoint i just find this a convenient
way to just get the parameters copied to

00:08:04.309 --> 00:08:04.319
way to just get the parameters copied to
 

00:08:04.319 --> 00:08:06.649
way to just get the parameters copied to
where you need to need to use them later

00:08:06.649 --> 00:08:06.659
where you need to need to use them later
 

00:08:06.659 --> 00:08:08.390
where you need to need to use them later
when you're computing back propagation

00:08:08.390 --> 00:08:08.400
when you're computing back propagation
 

00:08:08.400 --> 00:08:10.339
when you're computing back propagation
so that's just an implementational

00:08:10.339 --> 00:08:10.349
so that's just an implementational
 

00:08:10.349 --> 00:08:13.279
so that's just an implementational
detail that you see when you do the

00:08:13.279 --> 00:08:13.289
detail that you see when you do the
 

00:08:13.289 --> 00:08:16.339
detail that you see when you do the
programming exercise so you've now seen

00:08:16.339 --> 00:08:16.349
programming exercise so you've now seen
 

00:08:16.349 --> 00:08:18.170
programming exercise so you've now seen
one of the basic building blocks for

00:08:18.170 --> 00:08:18.180
one of the basic building blocks for
 

00:08:18.180 --> 00:08:20.029
one of the basic building blocks for
implementing the deep neural network in

00:08:20.029 --> 00:08:20.039
implementing the deep neural network in
 

00:08:20.039 --> 00:08:21.350
implementing the deep neural network in
each layer there's a for propagation

00:08:21.350 --> 00:08:21.360
each layer there's a for propagation
 

00:08:21.360 --> 00:08:22.850
each layer there's a for propagation
step and there's a corresponding

00:08:22.850 --> 00:08:22.860
step and there's a corresponding
 

00:08:22.860 --> 00:08:24.709
step and there's a corresponding
backward propagation step and there's a

00:08:24.709 --> 00:08:24.719
backward propagation step and there's a
 

00:08:24.719 --> 00:08:26.959
backward propagation step and there's a
cash deposit information from one to the

00:08:26.959 --> 00:08:26.969
cash deposit information from one to the
 

00:08:26.969 --> 00:08:27.529
cash deposit information from one to the
other

00:08:27.529 --> 00:08:27.539
other
 

00:08:27.539 --> 00:08:29.689
other
in the next video we'll talk about how

00:08:29.689 --> 00:08:29.699
in the next video we'll talk about how
 

00:08:29.699 --> 00:08:31.070
in the next video we'll talk about how
you can actually implement these

00:08:31.070 --> 00:08:31.080
you can actually implement these
 

00:08:31.080 --> 00:08:33.050
you can actually implement these
building blocks let's go on to the next

00:08:33.050 --> 00:08:33.060
building blocks let's go on to the next
 

00:08:33.060 --> 00:08:35.329
building blocks let's go on to the next
video

