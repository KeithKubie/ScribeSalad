WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:05.879
We talked a little bit about how images, particularly RGB Images are stored in memory, but one interesting question is how

00:00:05.880 --> 00:00:07.200
do we obtain those images to begin with.

00:00:07.200 --> 00:00:13.460
Obviously, we used to use Photographic film. Now we've got a huge amount of consumer cameras on every device that we have, and they almost all

00:00:13.690 --> 00:00:17.039
use the same technique to obtain their RGB images.

00:00:19.119 --> 00:00:21.688
All the cameras that we own will have some kind of CCD

00:00:21.689 --> 00:00:27.269
or some kind of CMOS sensor on [it], which is essentially a photosensitive layer which will tell the camera how

00:00:27.269 --> 00:00:31.739
much light has hit a certain position. And that will be arranged in a grid form so that each position

00:00:31.869 --> 00:00:37.078
represents a pixel in our image. And so from the top we might have something like this. We have some CCD or

00:00:37.420 --> 00:00:42.750
CMOS elements and then light from our scene is going to come in like this. Now if we just leave it at that, then we're

00:00:42.750 --> 00:00:44.680
going to get a grayscale image out, because

00:00:44.680 --> 00:00:46.120
there's no way of knowing

00:00:46.120 --> 00:00:51.599
what proportion of this light is red and what proportion is blue and what proportion is green. Because that's not how these sensors work.

00:00:51.699 --> 00:00:55.709
So what we instead do is we put a sort of filter over each of these

00:00:56.020 --> 00:00:59.520
but [it] filters a different colour. So this one will filter red, this

00:00:59.520 --> 00:01:03.839
one will filter green, and this one will filter blue. And then if we do that over a whole image

00:01:03.840 --> 00:01:05.400
we can start to recompute our

00:01:05.400 --> 00:01:09.240
actual pixel values and we can work out what colour we were actually supposed to be looking at.

00:01:09.240 --> 00:01:12.300
Sean: That filter in the camera - it's a physical thing, right?

00:01:12.400 --> 00:01:15.740
Mike: Yes, it's a physical set of small elements

00:01:16.060 --> 00:01:22.400
that intercept certain wavelengths. It's like a pair of those 3D glasses that you use where one side's red and one side's blue.

00:01:22.460 --> 00:01:27.220
But you've also got green ones, and you've got them in a grid arrangement in front of your camera's eye.

00:01:27.380 --> 00:01:30.580
Sean: If I've bought a 10 Megapixel camera, does that mean

00:01:30.580 --> 00:01:33.940
only three of the Megapixels are doing green, and three of them are different?

00:01:33.940 --> 00:01:37.360
Mike: It does. So different camera manufacturers may have different ways of doing this, but in general

00:01:37.360 --> 00:01:44.720
what they do is they split the amount of Megapixels that they've got available on their sensor into green, red, and blue as appropriate,

00:01:44.720 --> 00:01:49.720
and then they interpolate the values that they're missing. The Technique used for this is called the Bayer Filter.

00:01:49.960 --> 00:01:53.020
There are other filters but the Bayer Filter is by far the most common.

00:01:53.420 --> 00:01:56.500
So, from the top, your CCD sensor will look a little bit like this.

00:01:56.760 --> 00:02:03.220
So each of these represents our photosensitive element and a part of our filter. So we start off with green and then blue

00:02:03.460 --> 00:02:08.740
Each is a group of four. So green, blue, and then a green in this corner and a red in this corner.

00:02:08.840 --> 00:02:12.720
So you can immediately see already that there's two greens for every blue and red.

00:02:12.740 --> 00:02:16.000
And that's because our eyes are more sensitive to green than they are to blue and red,

00:02:16.080 --> 00:02:22.620
and we also distinguish Luminance, i.e. Brightness with much more intensity - sort of in the green channel.

00:02:22.900 --> 00:02:28.760
So if you have an image that's captured using two green elements rather than, say, two blue elements, it will look sharper to us.

00:02:28.820 --> 00:02:32.740
And of course, this is all about how it looks to us. So this pattern is repeated, but the problem here

00:02:32.900 --> 00:02:36.660
is that you've got, say, 10 Megapixels of this available, but you've only captured half

00:02:36.660 --> 00:02:39.320
of them as green and the other half as either blue or red.

00:02:39.320 --> 00:02:41.920
So the amount of red you've got is not 10 Megapixels.

00:02:41.920 --> 00:02:46.100
But they exploit a nice quality of our eyes,

00:02:46.100 --> 00:02:48.800
which is that we don't really see colour that well.

00:02:48.800 --> 00:02:52.540
We see it okay, but we see Grayscale and Luminance much much better.

00:02:52.560 --> 00:02:57.380
So if we can use the green, and to an extent the red and the blue to create a nice, sharp Luminance

00:02:57.380 --> 00:03:02.180
the fact that the colour's a little bit less high-resolution won't matter to us, and it'll still look nice and sharp in the image.

00:03:02.770 --> 00:03:05.399
So all we need to do is to look by the nearby

00:03:06.000 --> 00:03:12.140
pixels that have the colour we're looking for and interpolate that value. So in this case, we don't have a green value here,

00:03:12.140 --> 00:03:16.540
but we know what this green value is, and we know what this green value is. So on a very simple level

00:03:16.560 --> 00:03:21.460
we could just pick a green value which was halfway between the two, and assume that there's nothing complicated going on

00:03:21.460 --> 00:03:25.200
and it's a nice clean slope. And it's the same for blue and the same for red.

00:03:25.200 --> 00:03:31.840
The process of turning a CCD or CMOS image that's been used with a Bayer Filter

00:03:31.840 --> 00:03:36.660
into an RGB image where red, green and blue appear at every pixel is called Demosaicing.

00:03:36.660 --> 00:03:41.820
So this is a mosaic, and we'll say we've got some samples of green, some samples of blue, and some samples of red

00:03:41.820 --> 00:03:43.940
And we want all the samples of green and blue and red.

00:03:43.940 --> 00:03:46.660
And we're going to make some assumptions about what happens in the image.

00:03:46.660 --> 00:03:49.080
So, we're going to make the assumption that

00:03:49.080 --> 00:03:53.800
nothing particularly complex is going on at the moment between these two pixels because they're very close together,

00:03:53.800 --> 00:04:00.580
and so this green is probably halfway between these ones, and this red here in this pixel is probably halfway between these two red ones.

00:04:00.580 --> 00:04:03.020
And you've also got other red ones nearby that you could use.

00:04:03.220 --> 00:04:06.760
Now modern consumer cameras will do more complicated demosaicing,

00:04:06.760 --> 00:04:13.200
and in fact if you shoot in the Raw format, you can control the demosaicing algorithms in some of these software packages yourself.

00:04:13.200 --> 00:04:15.040
It will literally be the raw output of the sensor,

00:04:15.040 --> 00:04:20.240
including any weird colour effects based on the fact that you've got a Bayer Filter in front of your sensor.

00:04:20.240 --> 00:04:23.380
So you can do more complicated demosaicing algorithms.

00:04:23.380 --> 00:04:28.600
So if we're trying to capture our blue channel and we've got a value of 200, and a value of 200,

00:04:28.860 --> 00:04:35.820
and a value of 200 in our neighbouring pixels and we don't know what this one is, and we've got a value of 50 here.

00:04:35.820 --> 00:04:39.840
We could assume that it's somewhere averaged between these four values,

00:04:39.840 --> 00:04:42.460
but we could also assume that perhaps this represents an edge,

00:04:42.460 --> 00:04:47.320
and this should be 200, because there's a lot of consensus in this direction that we've got an edge.

00:04:47.420 --> 00:04:52.260
So more complicated demosaicing algorithms will try and preserve edge detail,

00:04:52.260 --> 00:04:55.520
Which is something you will classically lose in a normal demosaicing approach.

00:04:55.520 --> 00:04:59.080
It will go a little bit fuzzy, and it may not matter because you've got, let's say,

00:04:59.080 --> 00:05:04.319
16 or 20 Megapixels at your disposal and, this is when you zoom right in that you're going to see these kinds of problems.

00:05:04.539 --> 00:05:08.940
But for people who are really interested in image quality, they spend a lot of time looking into this.

00:05:08.940 --> 00:05:13.240
The downside of the Bayer filter approach, or any filter that you're putting in front of your your camera

00:05:13.240 --> 00:05:20.580
is if you get decreased Chrominance resolutions. The Chrominance is what we call our red and blue channels,

00:05:20.580 --> 00:05:23.700
Luminance is green, generally speaking. Although obviously they all represent colours.

00:05:24.069 --> 00:05:28.049
Some types of images like with fast, repeating stripy patterns will look

00:05:28.049 --> 00:05:32.960
extremely bad after you try and sort of apply a demosaicing algorithm that hasn't been tailored to that.

00:05:32.960 --> 00:05:37.800
And that's just because we're making assumptions about the smoothness between nearby blue pixels

00:05:37.800 --> 00:05:40.840
and they don't hold - those assumptions don't hold for certain types of images.

00:05:40.840 --> 00:05:43.199
So that's a sort of way of taking videos

00:05:44.260 --> 00:05:49.080
You might find that certain textures look particularly bad, and it's these kinds of things that are causing that problem.

00:05:51.460 --> 00:05:54.060
We've got a lot of investment in 8-bit code.

00:05:54.060 --> 00:05:59.800
How can, we exploit that investment whilst getting into the 16-bit market?

00:05:59.800 --> 00:06:05.520
And so what we had sketched on the table, it was effectively a dual processor system.

