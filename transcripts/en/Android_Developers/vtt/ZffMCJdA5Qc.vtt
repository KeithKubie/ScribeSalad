WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.952
[MUSIC PLAYING]

00:00:04.283 --> 00:00:05.450
CHRIS CRAIK: Hey, everybody.

00:00:05.450 --> 00:00:07.575
We're here to talk to you
about benchmarking today.

00:00:07.575 --> 00:00:08.315
I'm Chris.

00:00:08.315 --> 00:00:09.440
DUSTIN LAM: And I'm Dustin.

00:00:09.440 --> 00:00:12.260
And we're engineers who work
on Android Toolkit stuff.

00:00:12.260 --> 00:00:14.270
So first, I'd like to
start off with a note.

00:00:14.270 --> 00:00:16.660
We're not here to talk
about benchmarking devices.

00:00:16.660 --> 00:00:19.160
I know a lot of people out there
are probably really excited

00:00:19.160 --> 00:00:21.470
compare phone A to
phone B, but that's

00:00:21.470 --> 00:00:22.730
not what this talk is about.

00:00:22.730 --> 00:00:26.390
This talk is about benchmarking
Android app code, specifically,

00:00:26.390 --> 00:00:30.800
Kotlin and Java-based app code,
and a little bit of NDK code,

00:00:30.800 --> 00:00:32.720
too.

00:00:32.720 --> 00:00:34.265
So what is benchmarking?

00:00:34.265 --> 00:00:36.390
There's probably a couple
of definitions out there.

00:00:36.390 --> 00:00:38.430
But for all intents and
purposes of this talk,

00:00:38.430 --> 00:00:40.890
we're talking about
measuring code performance.

00:00:40.890 --> 00:00:41.390
Right?

00:00:41.390 --> 00:00:42.973
We want to know how
much time it takes

00:00:42.973 --> 00:00:44.470
to run some chunk of code.

00:00:44.470 --> 00:00:46.100
And we want to
measure this in a way

00:00:46.100 --> 00:00:47.892
where we can see our
improvements reflected

00:00:47.892 --> 00:00:50.210
in those measurements.

00:00:50.210 --> 00:00:52.040
And of course, unlike
profiling, we're

00:00:52.040 --> 00:00:54.110
not running the full
application in here.

00:00:54.110 --> 00:00:56.510
We're looking for a tool
for rapid feedback loops.

00:00:56.510 --> 00:00:59.600
We want to iterate and quickly.

00:00:59.600 --> 00:01:01.970
So you publish an app.

00:01:01.970 --> 00:01:03.110
Very exciting, right?

00:01:03.110 --> 00:01:06.650
We're going to be
rich and famous.

00:01:06.650 --> 00:01:10.270
And then your users
start writing reviews.

00:01:10.270 --> 00:01:12.070
It's the first of five
out of five stars.

00:01:12.070 --> 00:01:14.080
We're doing great,
hearts in the eyes.

00:01:14.080 --> 00:01:15.310
Was this review helpful?

00:01:15.310 --> 00:01:17.590
Yes, for my self-esteem.

00:01:17.590 --> 00:01:19.280
Five out of five again.

00:01:19.280 --> 00:01:20.110
Awesome.

00:01:20.110 --> 00:01:22.480
Little hesitation
space, exclamation mark.

00:01:22.480 --> 00:01:23.930
We're doing great.

00:01:23.930 --> 00:01:28.330
And then the inevitable
one star review, "laggg".

00:01:28.330 --> 00:01:29.113
Oh.

00:01:29.113 --> 00:01:31.030
You're so upset you can't
even spell it right.

00:01:33.900 --> 00:01:36.570
Well, we've been there too.

00:01:36.570 --> 00:01:40.110
And we'd like to share
what we've learned.

00:01:40.110 --> 00:01:44.550
So let's go on a benchmarking
adventure, very exciting.

00:01:44.550 --> 00:01:45.860
We'll start off with a test.

00:01:45.860 --> 00:01:49.040
We'll call it, myFirstBenchmark.

00:01:49.040 --> 00:01:51.170
And here's an
object that we might

00:01:51.170 --> 00:01:52.850
be interested in benchmarking.

00:01:52.850 --> 00:01:55.520
If you haven't seen this before,
this is the Jetpack WorkManager

00:01:55.520 --> 00:01:56.060
library.

00:01:56.060 --> 00:01:59.970
And it's basically an
abstraction over async tasks.

00:01:59.970 --> 00:02:03.437
And here's a synchronous test
API we can use to measure.

00:02:03.437 --> 00:02:05.020
So what's the first
thing we might do?

00:02:05.020 --> 00:02:08.169
Well, we could get
the system time,

00:02:08.169 --> 00:02:10.750
and then get the system time
after we've done the work,

00:02:10.750 --> 00:02:13.342
subtract that out, output
that as a result, and great,

00:02:13.342 --> 00:02:14.800
we have our first
benchmark, right?

00:02:14.800 --> 00:02:15.970
We're done.

00:02:15.970 --> 00:02:18.010
Well, not quite.

00:02:18.010 --> 00:02:20.210
We'll find that as we run
this over and over again,

00:02:20.210 --> 00:02:22.330
we'll get vastly
varying results.

00:02:22.330 --> 00:02:24.550
And that's no good
for measurements.

00:02:24.550 --> 00:02:27.865
But what if we ran it in a loop?

00:02:27.865 --> 00:02:30.830
And maybe we'll run
this loop five times,

00:02:30.830 --> 00:02:33.500
and then we'll
report the average.

00:02:33.500 --> 00:02:35.600
So great, problem solved, right?

00:02:35.600 --> 00:02:37.460
There's still a few issues here.

00:02:37.460 --> 00:02:41.030
Well, first, five is kind
of a random magic number.

00:02:41.030 --> 00:02:43.040
And ideally we'd like
to dynamically compute

00:02:43.040 --> 00:02:44.155
this number.

00:02:44.155 --> 00:02:45.530
We want to report
the result when

00:02:45.530 --> 00:02:47.530
we're ready and confident
that this number won't

00:02:47.530 --> 00:02:49.510
change too much.

00:02:49.510 --> 00:02:51.310
We're also measuring
immediately.

00:02:51.310 --> 00:02:53.710
And the issue here is
that the first couple

00:02:53.710 --> 00:02:55.690
runs of some piece
of code might not

00:02:55.690 --> 00:02:58.450
be indicative of what the
real user will experience.

00:02:58.450 --> 00:03:00.700
And this can be due
to code paging memory

00:03:00.700 --> 00:03:04.260
or just-in-time
compilization optimizations.

00:03:04.260 --> 00:03:06.360
And we're also
including outliers.

00:03:06.360 --> 00:03:10.460
So everything on device
is a shared resource.

00:03:10.460 --> 00:03:11.953
And this can cause
complications,

00:03:11.953 --> 00:03:13.370
background
interference that might

00:03:13.370 --> 00:03:15.350
cause certain runs to
be much, much slower

00:03:15.350 --> 00:03:16.250
than they should be.

00:03:16.250 --> 00:03:17.780
And if we include those
results, our measurements

00:03:17.780 --> 00:03:18.738
will be completely off.

00:03:21.105 --> 00:03:23.730
And make sure we're not running
an emulator, because while it's

00:03:23.730 --> 00:03:26.100
very tempting to run
tests on emulator,

00:03:26.100 --> 00:03:30.580
emulators don't emulate
real world performance.

00:03:30.580 --> 00:03:34.090
So the lesson here is that
benchmarking is tricky.

00:03:34.090 --> 00:03:35.050
It's often inaccurate.

00:03:35.050 --> 00:03:38.190
We're measuring the wrong
things at the wrong time, right?

00:03:38.190 --> 00:03:39.970
And it's unstable.

00:03:39.970 --> 00:03:41.080
There's tons of variance.

00:03:41.080 --> 00:03:43.480
How many loops should we run?

00:03:43.480 --> 00:03:44.920
And it's hard to
set up correctly.

00:03:44.920 --> 00:03:46.628
That's worst of all,
because benchmarking

00:03:46.628 --> 00:03:50.020
is a tool to help us
focus developer efforts.

00:03:50.020 --> 00:03:53.290
So it's hard to set up how much
time we're really saving here.

00:03:53.290 --> 00:03:55.830
So I'd like to introduce the
Jetpack Benchmark library.

00:03:55.830 --> 00:03:59.153
It's out now, and
it's in alpha one.

00:03:59.153 --> 00:04:00.570
This is a previously
internal tool

00:04:00.570 --> 00:04:02.380
I've been working on for years.

00:04:02.380 --> 00:04:04.980
We've been working hard to get
it available to the public now.

00:04:04.980 --> 00:04:06.410
So we hope you
guys will enjoy it.

00:04:06.410 --> 00:04:08.910
First, I'm going to go over a
little bit about what it looks

00:04:08.910 --> 00:04:11.485
like and how might how you
might use it in your code,

00:04:11.485 --> 00:04:13.110
and then we'll talk
about the internals

00:04:13.110 --> 00:04:16.829
and how we solve a
lot of these issues.

00:04:16.829 --> 00:04:18.310
So Jetpack Benchmark--
it's a tool

00:04:18.310 --> 00:04:20.350
for measuring code
performance, of course.

00:04:20.350 --> 00:04:22.730
Thank you.

00:04:22.730 --> 00:04:24.968
We like to prevent common
measuring mistakes.

00:04:24.968 --> 00:04:27.510
There's a lot of common pitfalls
that we've seen in the past,

00:04:27.510 --> 00:04:30.242
and we want to pass
those lessons on to you.

00:04:30.242 --> 00:04:32.450
And best of all, it's
integrated with Android Studio.

00:04:32.450 --> 00:04:35.900
Who doesn't love Android
Studio integration, right?

00:04:35.900 --> 00:04:38.620
Let's jump back to
our previous example.

00:04:38.620 --> 00:04:40.090
Here's our previous benchmark.

00:04:40.090 --> 00:04:42.443
It's verbose, and
it's full of errors.

00:04:42.443 --> 00:04:44.110
But this is really
only the code that we

00:04:44.110 --> 00:04:47.240
care about-- the highlighted
code here, about three lines.

00:04:47.240 --> 00:04:49.020
So let's fix that.

00:04:49.020 --> 00:04:52.390
First, we apply the benchmark
rule, and then all of this code

00:04:52.390 --> 00:04:56.740
becomes one simple API
call, measureRepeated.

00:04:56.740 --> 00:04:59.770
And we can focus on the code
that we really care about.

00:04:59.770 --> 00:05:01.270
Let's check on
another example here.

00:05:01.270 --> 00:05:02.870
This is a database benchmark.

00:05:02.870 --> 00:05:05.420
So first, let's initialize
our database with Room.

00:05:05.420 --> 00:05:06.920
And if you haven't
seen Room before,

00:05:06.920 --> 00:05:08.240
it's another Jetpack library.

00:05:08.240 --> 00:05:09.988
It's just an abstraction
over databases.

00:05:09.988 --> 00:05:11.530
All that matters
really here is we're

00:05:11.530 --> 00:05:13.596
initializing some
object that allows

00:05:13.596 --> 00:05:16.140
us to make database queries.

00:05:16.140 --> 00:05:18.060
So first let's
clear all the tables

00:05:18.060 --> 00:05:21.873
and install some test data,
create our measuring loop,

00:05:21.873 --> 00:05:24.040
and then we can measure the
code that we care about.

00:05:24.040 --> 00:05:25.720
In this case, some
kind of complex

00:05:25.720 --> 00:05:26.950
query, not sure what it is.

00:05:26.950 --> 00:05:29.780
Doesn't really matter.

00:05:29.780 --> 00:05:31.000
But there's an issue here.

00:05:31.000 --> 00:05:33.160
Depending on your
database implementation,

00:05:33.160 --> 00:05:34.610
your query could
be cached, right?

00:05:34.610 --> 00:05:36.680
If we know that the query
results won't be changed,

00:05:36.680 --> 00:05:37.840
shouldn't we just
save that result

00:05:37.840 --> 00:05:39.257
and use that in
the future instead

00:05:39.257 --> 00:05:42.235
of having to use complex
query all over again?

00:05:42.235 --> 00:05:43.610
So what we're
going have to do is

00:05:43.610 --> 00:05:45.860
we have to take this
clearAndInsertTestData method

00:05:45.860 --> 00:05:47.330
and do it inside
the loop, right?

00:05:47.330 --> 00:05:49.160
Every single time,
bust the cache,

00:05:49.160 --> 00:05:52.140
so we can measure what
we actually care about.

00:05:52.140 --> 00:05:53.530
But there's another
problem here.

00:05:53.530 --> 00:05:56.270
We're now measuring more
than we actually care.

00:05:56.270 --> 00:05:57.830
So what are we going to do?

00:05:57.830 --> 00:05:59.470
Well, we could do
the previous thing

00:05:59.470 --> 00:06:02.770
where we take the system
time before and after, maybe

00:06:02.770 --> 00:06:05.200
save that to some variable,
output the result,

00:06:05.200 --> 00:06:07.210
then subtract that
from our final result.

00:06:07.210 --> 00:06:09.010
And then we'll have
our actual result

00:06:09.010 --> 00:06:10.210
that we care about, right?

00:06:10.210 --> 00:06:11.950
Well, this is,
again, very verbose.

00:06:11.950 --> 00:06:13.700
And fortunately, this
is a common use case

00:06:13.700 --> 00:06:14.710
that we run into too.

00:06:14.710 --> 00:06:17.558
So we created an API
for this as well.

00:06:17.558 --> 00:06:19.350
And that's the
runWithTimingDisabled block.

00:06:22.300 --> 00:06:24.280
So I know a lot
of Java developers

00:06:24.280 --> 00:06:26.830
out there are probably
wondering, well, what about us?

00:06:26.830 --> 00:06:29.393
Well, of course, we
have Java APIs as well.

00:06:29.393 --> 00:06:30.560
And it's slightly different.

00:06:30.560 --> 00:06:32.393
So I'd like to go through
this line by line.

00:06:32.393 --> 00:06:33.820
A lot of code has changed here.

00:06:33.820 --> 00:06:38.053
So we have to create this
BenchmarkState variable.

00:06:38.053 --> 00:06:40.470
And this is how the library's
going to commit to your code

00:06:40.470 --> 00:06:41.520
when it's done.

00:06:41.520 --> 00:06:44.163
We create a while loop and
call state.keepRunning.

00:06:44.163 --> 00:06:46.080
And inside that block,
we can run all the code

00:06:46.080 --> 00:06:47.370
that we want to measure.

00:06:47.370 --> 00:06:49.470
If we ever need to do
any setup initialization,

00:06:49.470 --> 00:06:51.420
we can just call this
pauseTiming method,

00:06:51.420 --> 00:06:53.790
do our initialization,
and then resume when

00:06:53.790 --> 00:06:56.190
we're ready to measure again.

00:06:56.190 --> 00:06:58.355
So that's great.

00:06:58.355 --> 00:06:59.980
I've got one more
example for you guys,

00:06:59.980 --> 00:07:01.290
and it's a UI example.

00:07:01.290 --> 00:07:04.255
A very compelling case for
benchmarking might be UI.

00:07:04.255 --> 00:07:06.880
And we've designed this library
to integrate on top of existing

00:07:06.880 --> 00:07:07.900
test infrastructure.

00:07:07.900 --> 00:07:09.900
And that's because we
want you to be able to use

00:07:09.900 --> 00:07:11.650
all your favorite tools.

00:07:11.650 --> 00:07:13.613
For example, the
ActivityTestRule,

00:07:13.613 --> 00:07:15.280
which is an abstraction
that'll help you

00:07:15.280 --> 00:07:16.988
with activity lifecycle
and all the setup

00:07:16.988 --> 00:07:18.790
you need in order
to make a UI test.

00:07:18.790 --> 00:07:21.190
So we simply mark this
test as an @UIThreadTest

00:07:21.190 --> 00:07:22.930
to run it on the main thread.

00:07:22.930 --> 00:07:25.750
And then we get a reference
to a recyclerView.

00:07:25.750 --> 00:07:28.570
Then, as before, we just
create a measureRepeated loop

00:07:28.570 --> 00:07:30.347
and measure the code
that we care about.

00:07:30.347 --> 00:07:32.680
In this case, we're scrolling
by the height of one item.

00:07:35.350 --> 00:07:38.040
Let's talk about
studio integration.

00:07:38.040 --> 00:07:43.340
With Studio 3.5, we're releasing
a new benchmark Module Template

00:07:43.340 --> 00:07:45.720
to help you get up and
running with your benchmarks.

00:07:45.720 --> 00:07:47.887
So let's walk through what
adding a benchmark module

00:07:47.887 --> 00:07:49.240
looks like.

00:07:49.240 --> 00:07:51.930
So here's a typical
Android project.

00:07:51.930 --> 00:07:53.940
We've got an app module
and a library module,

00:07:53.940 --> 00:07:57.190
because we love modulization
and we're great developers.

00:07:57.190 --> 00:07:59.880
We right click the
project, click New, Module.

00:08:03.960 --> 00:08:07.260
And we'll get this Create
New Module wizard that you've

00:08:07.260 --> 00:08:08.430
probably seen before.

00:08:08.430 --> 00:08:09.480
And if you scroll all
the way to the bottom,

00:08:09.480 --> 00:08:11.680
you'll see this new
Benchmark Module icon.

00:08:11.680 --> 00:08:14.190
Click Next, and it gives
a little configuration

00:08:14.190 --> 00:08:16.590
dialog you can use to
choose your module name,

00:08:16.590 --> 00:08:17.770
change the package name.

00:08:17.770 --> 00:08:21.330
And we've got templates in both
Kotlin and Java-based code.

00:08:21.330 --> 00:08:23.800
So click Finish, come
back to the project.

00:08:23.800 --> 00:08:25.280
Now we have our
benchmark module.

00:08:25.280 --> 00:08:28.440
Let's take a look inside.

00:08:28.440 --> 00:08:31.590
We've got a benchmark here
that you can just run, up

00:08:31.590 --> 00:08:32.940
and running.

00:08:32.940 --> 00:08:35.970
Similar as before,
set BenchmarkRule,

00:08:35.970 --> 00:08:38.888
measureRepeated loop, and
it works out of the box.

00:08:38.888 --> 00:08:40.430
You can just run
it, and your results

00:08:40.430 --> 00:08:42.370
will appear directly
in Studio in case

00:08:42.370 --> 00:08:46.370
you're developing locally and
you want to iterate quickly.

00:08:46.370 --> 00:08:48.550
We've also got JSON
and XML output data.

00:08:48.550 --> 00:08:51.280
We'll pull off from connected
instrument to tests from device

00:08:51.280 --> 00:08:52.267
onto your host machine.

00:08:52.267 --> 00:08:53.850
And we've done this
with the intention

00:08:53.850 --> 00:08:56.027
of being ingested by
continuous integration tools.

00:08:56.027 --> 00:08:57.610
So if you want to
look for regressions

00:08:57.610 --> 00:08:59.610
and look for improvements
you've made over time,

00:08:59.610 --> 00:09:02.422
this is a great way to do that.

00:09:02.422 --> 00:09:04.630
As with any module, there's
also a build.gradle file.

00:09:04.630 --> 00:09:07.047
And there's a couple of things
here I'd like to point out.

00:09:07.047 --> 00:09:09.840
So first, there's a bench
there's a benchmark plugin

00:09:09.840 --> 00:09:12.180
that we're going to be shipping
along with the library.

00:09:12.180 --> 00:09:14.460
There's a custom runner that
extends off the Andrew JUnit

00:09:14.460 --> 00:09:15.000
runner.

00:09:15.000 --> 00:09:16.417
And it's also open
to be extended,

00:09:16.417 --> 00:09:18.550
in case you need to do that.

00:09:18.550 --> 00:09:22.200
We've also pre-built it with
some pre-built proguard rules

00:09:22.200 --> 00:09:24.850
that'll work out of the box with
the Jetpack Benchmark library.

00:09:24.850 --> 00:09:26.308
And of course, the
library itself--

00:09:26.308 --> 00:09:28.440
can't forget that,
very important.

00:09:28.440 --> 00:09:30.300
Let's talk about
the Gradle plugin.

00:09:30.300 --> 00:09:33.348
So that's this line you saw
before, the apply plugin line.

00:09:33.348 --> 00:09:35.640
It's going to help you pull
your benchmark reports when

00:09:35.640 --> 00:09:38.070
you run gradlew,
connect an Android test,

00:09:38.070 --> 00:09:41.660
or connected check for CI.

00:09:41.660 --> 00:09:44.160
And we've also got some gradle
tasks for CPU clock stability

00:09:44.160 --> 00:09:46.190
in there as well.

00:09:46.190 --> 00:09:49.383
The test runner, that's
the AndroidBenchmarkRunner.

00:09:49.383 --> 00:09:51.050
It's kind of an
in-depth topic, so we'll

00:09:51.050 --> 00:09:52.460
talk more about that later.

00:09:52.460 --> 00:09:55.070
But suffice to say it's got
a lot of baked in tricks

00:09:55.070 --> 00:09:58.440
to stabilize your benchmarks.

00:09:58.440 --> 00:10:01.080
We've also got proguard rules.

00:10:01.080 --> 00:10:03.220
And that's in this file here.

00:10:03.220 --> 00:10:05.610
Our template supplies
pre-configured proguard rules.

00:10:05.610 --> 00:10:08.040
And that's important because
proguard optimizes your code.

00:10:08.040 --> 00:10:10.290
So you want to make sure
you're running your benchmark

00:10:10.290 --> 00:10:12.570
in a configuration that
represents real user

00:10:12.570 --> 00:10:13.380
performance, right?

00:10:13.380 --> 00:10:14.880
So we want to do this
in a release production

00:10:14.880 --> 00:10:16.030
environment if possible.

00:10:16.030 --> 00:10:18.332
So that's why we bundle
these rules for you.

00:10:18.332 --> 00:10:19.790
And we realize that
tests generally

00:10:19.790 --> 00:10:22.310
don't use proguard
or R8, but this

00:10:22.310 --> 00:10:23.920
is important for benchmarks.

00:10:23.920 --> 00:10:27.282
And it's probably why we set
it up as a separate module.

00:10:27.282 --> 00:10:29.240
So we've also included
an Android manifest here

00:10:29.240 --> 00:10:31.410
that's going to run
with your Android tests.

00:10:31.410 --> 00:10:34.275
And if you notice here, we've
set debuggable to be false.

00:10:36.950 --> 00:10:39.650
And while this is normally
enabled by default for tests,

00:10:39.650 --> 00:10:41.683
it's great because it
allows us to use things

00:10:41.683 --> 00:10:43.100
like connecting a
debugger and use

00:10:43.100 --> 00:10:44.600
all of our favorite
debugging tools.

00:10:44.600 --> 00:10:47.950
And it's great when you're
testing for correctness.

00:10:47.950 --> 00:10:50.260
But it's not so
great for benchmarks.

00:10:50.260 --> 00:10:54.190
We've seen before that runs have
been between 0% to 80% slower.

00:10:54.190 --> 00:10:57.490
And 80% is not the number
that should be worrying you.

00:10:57.490 --> 00:10:58.270
It's the hyphen.

00:10:58.270 --> 00:11:00.520
It's the range, the
variability here.

00:11:00.520 --> 00:11:02.780
It's hard to account for.

00:11:02.780 --> 00:11:04.795
Let's take a look at an example.

00:11:04.795 --> 00:11:06.670
Here are some benchmarks
that we have in AOSP

00:11:06.670 --> 00:11:09.497
that we use in the Jetpack team.

00:11:09.497 --> 00:11:11.830
And along the x-axis, you'll
see several different types

00:11:11.830 --> 00:11:13.730
of benchmarks that we do.

00:11:13.730 --> 00:11:16.500
And along the y-axis is
normalized duration, how long

00:11:16.500 --> 00:11:17.950
the benchmark took to run.

00:11:17.950 --> 00:11:21.570
Blue is with debuggable false
and red is with debuggable on.

00:11:21.570 --> 00:11:24.070
And we've normalized
each benchmark,

00:11:24.070 --> 00:11:28.390
benchmark by benchmark,
not across the board.

00:11:28.390 --> 00:11:31.122
So you'll see here in the
deserialization example

00:11:31.122 --> 00:11:32.580
that there's hardly
any difference.

00:11:32.580 --> 00:11:35.340
If you look really closely,
it's like one pixel off.

00:11:35.340 --> 00:11:37.550
1% difference, right?

00:11:37.550 --> 00:11:41.460
But over here in the
inflateSimple benchmark,

00:11:41.460 --> 00:11:43.168
there's a huge difference here.

00:11:43.168 --> 00:11:45.210
And again, the hard part
here is the variability.

00:11:45.210 --> 00:11:46.780
It's really hard to account for.

00:11:46.780 --> 00:11:49.380
So we want to make sure that
the optimizations and the code

00:11:49.380 --> 00:11:50.460
change we're making
are actually going

00:11:50.460 --> 00:11:51.870
to have an impact on our users.

00:11:51.870 --> 00:11:55.130
We need to make sure
debuggable is off.

00:11:55.130 --> 00:11:59.750
So that leaves me at about
benchmark configuration.

00:11:59.750 --> 00:12:02.960
And here I'd just like to
give some tips that we also

00:12:02.960 --> 00:12:04.520
bundled with the template.

00:12:04.520 --> 00:12:06.268
But you should
definitely be setting up

00:12:06.268 --> 00:12:07.310
your benchmarks this way.

00:12:07.310 --> 00:12:11.208
So first, as before, we'd like
to turn off debuggability.

00:12:11.208 --> 00:12:13.250
We also want to make sure
code coverage is false.

00:12:13.250 --> 00:12:14.792
If you're using
something like JCoCo,

00:12:14.792 --> 00:12:16.640
this actually modifies
the dex in order

00:12:16.640 --> 00:12:18.540
to support what it needs to do.

00:12:18.540 --> 00:12:22.010
And that's great if you're
trying to get code coverage,

00:12:22.010 --> 00:12:25.580
but when you're running a
benchmark, that's not so great.

00:12:25.580 --> 00:12:28.560
Of course, as before, you
like to enable proguard.

00:12:28.560 --> 00:12:31.440
And we currently support
library modules for alpha one.

00:12:31.440 --> 00:12:33.930
We're really pushing developers
to modulize their app

00:12:33.930 --> 00:12:34.620
this year.

00:12:34.620 --> 00:12:36.247
And I'd like to do
a little shout out.

00:12:36.247 --> 00:12:38.580
Please check out the How to
Create a Modular Android App

00:12:38.580 --> 00:12:39.330
Architecture talk.

00:12:39.330 --> 00:12:40.747
That was on Tuesday,
so you should

00:12:40.747 --> 00:12:42.040
be able to find it on YouTube.

00:12:42.040 --> 00:12:44.840
It's by Florina and Yigit.

00:12:44.840 --> 00:12:46.590
But what if you forget?

00:12:46.590 --> 00:12:50.252
As a library, we can do a lot,
but we can't do everything.

00:12:50.252 --> 00:12:51.960
We can't just print
out a device and have

00:12:51.960 --> 00:12:53.370
you run on that, right?

00:12:53.370 --> 00:12:55.760
But that would be great.

00:12:55.760 --> 00:12:58.310
Fortunately, we've got warnings.

00:12:58.310 --> 00:13:00.320
So we're going to
corrupt your output

00:13:00.320 --> 00:13:01.730
and make it very visible to you.

00:13:01.730 --> 00:13:03.397
And hopefully this
is something that you

00:13:03.397 --> 00:13:05.858
can catch in your continuous
integration tests.

00:13:05.858 --> 00:13:07.650
So here's an example,
a couple of warnings,

00:13:07.650 --> 00:13:08.735
debuggable as before.

00:13:08.735 --> 00:13:10.110
If you're running
on an emulator,

00:13:10.110 --> 00:13:11.162
that's also pretty bad.

00:13:11.162 --> 00:13:12.870
If you're missing the
runner, then you're

00:13:12.870 --> 00:13:15.630
not using any of our tricks to
help stabilize your benchmarks.

00:13:15.630 --> 00:13:17.200
And if you're low on battery--

00:13:17.200 --> 00:13:19.710
now, a surprising thing
about being low in battery

00:13:19.710 --> 00:13:22.650
is that while you might expect
the device will throttle

00:13:22.650 --> 00:13:24.990
itself, it'll try
and save power.

00:13:24.990 --> 00:13:27.160
However, we've found
that on many devices

00:13:27.160 --> 00:13:29.290
it still does this even
while it's charging.

00:13:29.290 --> 00:13:32.380
So this is definitely something
you want to watch out for.

00:13:32.380 --> 00:13:34.260
So that's a bit about
what the lab looks like

00:13:34.260 --> 00:13:35.710
and how you would use it.

00:13:35.710 --> 00:13:37.793
And now Chris is going to
talk about how it works.

00:13:42.757 --> 00:13:45.090
CHRIS CRAIK: All right, so
that was a lot of information

00:13:45.090 --> 00:13:47.370
about what it looks
like to use the library,

00:13:47.370 --> 00:13:51.180
but there's a lot of
implementation behind it

00:13:51.180 --> 00:13:53.570
to implement all
of these behaviors

00:13:53.570 --> 00:13:54.820
that Dustin was talking about.

00:13:54.820 --> 00:13:57.090
So first of all, let's
talk about CPU clock,

00:13:57.090 --> 00:13:59.610
specifically
frequency and how it's

00:13:59.610 --> 00:14:01.050
kind of the enemy of stability.

00:14:01.050 --> 00:14:04.500
Because when you go up and down
massively, you change results,

00:14:04.500 --> 00:14:06.630
and you make it very
hard to discover

00:14:06.630 --> 00:14:08.880
regressions and improvements.

00:14:08.880 --> 00:14:10.920
So from the perspective
of benchmarking,

00:14:10.920 --> 00:14:12.630
there are really two
problems that CPU

00:14:12.630 --> 00:14:14.010
clocks introduce to us.

00:14:14.010 --> 00:14:16.380
And the first is ramping.

00:14:16.380 --> 00:14:18.540
Clocks generally start
out low when the device

00:14:18.540 --> 00:14:19.560
isn't doing anything.

00:14:19.560 --> 00:14:23.520
And then once work
is scheduled, they

00:14:23.520 --> 00:14:25.710
will ramp slowly
over time in order

00:14:25.710 --> 00:14:28.253
to get to a
high-performance mode.

00:14:28.253 --> 00:14:29.670
On the other side
of this, though,

00:14:29.670 --> 00:14:31.212
when the device gets
hot because it's

00:14:31.212 --> 00:14:34.710
been running for a long time,
the clocks will dive quickly,

00:14:34.710 --> 00:14:36.610
and you'll get
terrible performance.

00:14:36.610 --> 00:14:37.860
So both of these are problems.

00:14:37.860 --> 00:14:39.460
Let's talk about
them one at a time.

00:14:39.460 --> 00:14:45.060
So first, ramping-- clocks will
generally increase under load.

00:14:45.060 --> 00:14:49.930
And what we've seen is that it
takes about 100 milliseconds.

00:14:49.930 --> 00:14:52.388
So here we have a clip of
a little systrace here.

00:14:52.388 --> 00:14:54.180
And the only thing
that's important to note

00:14:54.180 --> 00:14:56.520
is the clock frequency
at the bottom versus when

00:14:56.520 --> 00:14:59.070
the work started on the top.

00:14:59.070 --> 00:15:00.780
At the very beginning
of the trace,

00:15:00.780 --> 00:15:02.550
you see time equals
0 milliseconds.

00:15:02.550 --> 00:15:05.660
The frequency is 300
megahertz-- incredibly slow.

00:15:05.660 --> 00:15:08.860
A frequency that most of your
app code is never going to see.

00:15:08.860 --> 00:15:11.760
However, after about
75 milliseconds,

00:15:11.760 --> 00:15:14.760
you see that we go all the
way up to 2.56 gigahertz.

00:15:14.760 --> 00:15:17.550
If we were measuring in
between these two times,

00:15:17.550 --> 00:15:18.835
that would be bad.

00:15:18.835 --> 00:15:21.210
However, the solution for this
is actually pretty simple.

00:15:21.210 --> 00:15:24.730
Benchmark just runs warmup
in order to account for this.

00:15:24.730 --> 00:15:28.260
So we spin the measurement
loop for 250 milliseconds

00:15:28.260 --> 00:15:30.390
before we ever start measuring.

00:15:30.390 --> 00:15:35.290
And then we only start measuring
once timing stabilizes.

00:15:35.290 --> 00:15:37.000
This also has the
nice side effect

00:15:37.000 --> 00:15:38.550
of handling the
Android runtime's

00:15:38.550 --> 00:15:40.065
just-in-time compilation.

00:15:40.065 --> 00:15:41.440
By the time that
your performance

00:15:41.440 --> 00:15:44.210
numbers are stabilizing,
JIT has stabilized as well.

00:15:44.210 --> 00:15:47.020
You're seeing performance
that's corresponding to what

00:15:47.020 --> 00:15:52.660
your user would see in a
frequently hot code path.

00:15:52.660 --> 00:15:56.050
So that was ramping, but diving
is a much bigger problem.

00:15:56.050 --> 00:15:58.210
When the device gets hot,
the clocks dive quickly.

00:15:58.210 --> 00:16:01.390
And this is called
thermal throttling.

00:16:01.390 --> 00:16:03.460
Generally, the CPU will
lower its frequency

00:16:03.460 --> 00:16:05.127
once it gets to
a very high level

00:16:05.127 --> 00:16:07.210
because it wants to avoid
overheating and damaging

00:16:07.210 --> 00:16:07.710
the chip.

00:16:10.200 --> 00:16:13.105
This can happen
unexpectedly, though,

00:16:13.105 --> 00:16:14.980
and massively affects
performance while we're

00:16:14.980 --> 00:16:16.610
running our benchmarks.

00:16:16.610 --> 00:16:19.330
So take a look at this
sample where I'm just taking

00:16:19.330 --> 00:16:21.520
a pretty simple benchmark.

00:16:21.520 --> 00:16:25.780
It's just doing a tiny bit
of matrix math in a loop.

00:16:25.780 --> 00:16:28.040
And at the beginning, I'm
getting a relatively stable

00:16:28.040 --> 00:16:28.540
performance.

00:16:28.540 --> 00:16:31.240
Over the first minute or so,
it looks pretty stable at 2

00:16:31.240 --> 00:16:33.280
milliseconds, all is well.

00:16:33.280 --> 00:16:37.930
But less than a minute in,
performance becomes terrible.

00:16:37.930 --> 00:16:39.640
Look at that.

00:16:39.640 --> 00:16:43.600
Less than two minutes in, we
are up to three and a half times

00:16:43.600 --> 00:16:46.550
the performance that we expect.

00:16:46.550 --> 00:16:49.220
However, the device runs at this
low clock for a little while.

00:16:49.220 --> 00:16:50.078
It cools down.

00:16:50.078 --> 00:16:50.870
And it's back down.

00:16:50.870 --> 00:16:51.140
OK.

00:16:51.140 --> 00:16:52.440
Well, we're good now, right?

00:16:52.440 --> 00:16:52.940
No.

00:16:52.940 --> 00:16:54.840
We're still doing the work.

00:16:54.840 --> 00:16:57.350
So over the result of
this five minute test,

00:16:57.350 --> 00:17:00.470
we have thermal throttling
taking us up and down

00:17:00.470 --> 00:17:03.440
and making these results
pretty terrible, right?

00:17:03.440 --> 00:17:05.420
We can't extract a
whole lot of information

00:17:05.420 --> 00:17:07.339
from these because we
are dynamically going

00:17:07.339 --> 00:17:09.650
between 2 and 7 milliseconds.

00:17:09.650 --> 00:17:13.300
We can't trust
these measurements.

00:17:13.300 --> 00:17:16.079
So our solution to
throttling, we found,

00:17:16.079 --> 00:17:18.660
is different per
device because we

00:17:18.660 --> 00:17:20.160
have different tools
that we can use

00:17:20.160 --> 00:17:22.630
in different configurations.

00:17:22.630 --> 00:17:28.310
So the first solution to thermal
throttling is the simplest--

00:17:28.310 --> 00:17:29.130
lock clocks.

00:17:29.130 --> 00:17:31.320
What if we could just
set the clock frequency?

00:17:31.320 --> 00:17:36.250
Well, unfortunately, this is
ideal, but this requires root.

00:17:36.250 --> 00:17:39.660
This is not a great solution
for the average person.

00:17:39.660 --> 00:17:43.142
Because although we can set
it to a medium frequency,

00:17:43.142 --> 00:17:44.850
this will keep it from
thermal throttling

00:17:44.850 --> 00:17:48.480
because the device handles
medium frequency just fine.

00:17:48.480 --> 00:17:50.820
We do provide a gradle
plug-in for you,

00:17:50.820 --> 00:17:53.190
though, if you do
have a device that

00:17:53.190 --> 00:17:55.860
is rooted-- simply
gradlew lockClocks

00:17:55.860 --> 00:17:58.260
and your device is locked.

00:17:58.260 --> 00:18:01.273
But requiring root, though, is
really not a general solution.

00:18:01.273 --> 00:18:02.190
We don't recommend it.

00:18:02.190 --> 00:18:04.750
So what else do we have?

00:18:04.750 --> 00:18:08.745
Well, there is this API added
in Android N, Window.setSustai

00:18:08.745 --> 00:18:10.860
nedPerformanceMode.

00:18:10.860 --> 00:18:14.190
And this was originally
designed for VR and for games,

00:18:14.190 --> 00:18:16.930
but it's incredibly
appealing for benchmarks.

00:18:16.930 --> 00:18:19.530
This is because it lowers
the max clocks specifically

00:18:19.530 --> 00:18:21.570
to solve this problem,
prevent throttling.

00:18:21.570 --> 00:18:23.700
Perfect, right?

00:18:23.700 --> 00:18:26.028
And it also works on
GPUs as well as CPUs,

00:18:26.028 --> 00:18:27.570
so it's even useful
if you're wanting

00:18:27.570 --> 00:18:31.040
to do rendering benchmarking,
say if you're a game.

00:18:31.040 --> 00:18:33.230
However, it comes along
with a lot of difficulties.

00:18:33.230 --> 00:18:37.260
It's designed for VR, not
for headless benchmarks.

00:18:37.260 --> 00:18:39.350
So first of all, it
requires an activity

00:18:39.350 --> 00:18:41.850
running with a flag set.

00:18:41.850 --> 00:18:43.393
It also has two
separate modes if it

00:18:43.393 --> 00:18:44.810
thinks that you're
single-threaded

00:18:44.810 --> 00:18:46.610
versus multi-threaded.

00:18:46.610 --> 00:18:50.090
And it's also only supported
on some N+ devices.

00:18:50.090 --> 00:18:51.590
So let's talk through
each of these.

00:18:51.590 --> 00:18:53.370
Maybe we can solve some of this.

00:18:53.370 --> 00:18:56.120
So the first is
the activity flag.

00:18:56.120 --> 00:18:58.440
And in order to
solve this problem,

00:18:58.440 --> 00:19:00.980
we actually just launch
an activity for you

00:19:00.980 --> 00:19:02.300
around any headless test.

00:19:02.300 --> 00:19:05.073
We inject an activity that
launches any time that we might

00:19:05.073 --> 00:19:06.990
need to use the
setSustainedPerformanceMode so

00:19:06.990 --> 00:19:09.380
that it's up at all times.

00:19:09.380 --> 00:19:12.040
We set this flag, also, on any
activities that you launch.

00:19:12.040 --> 00:19:14.540
So if you're doing a UI test,
like Dustin was showing before

00:19:14.540 --> 00:19:18.180
with the Recycler view, that
gets this property as well.

00:19:18.180 --> 00:19:20.900
And it works together with
ActivityTestRule and Activity

00:19:20.900 --> 00:19:23.810
Scenario, so you don't have
to worry about adapting

00:19:23.810 --> 00:19:26.230
to this new model.

00:19:26.230 --> 00:19:29.530
And in addition, it also calls
it out in the UI of the test

00:19:29.530 --> 00:19:30.430
while it's running.

00:19:30.430 --> 00:19:31.888
It pops up there
and says, hey, I'm

00:19:31.888 --> 00:19:35.680
in setSustainedPerformanceMode.

00:19:35.680 --> 00:19:37.930
Now, OK, so we've
got a way to solve

00:19:37.930 --> 00:19:39.640
the problem of needing
the flag, but how

00:19:39.640 --> 00:19:41.290
do we handle the
two different modes?

00:19:41.290 --> 00:19:43.540
So first, let's
describe what these are.

00:19:43.540 --> 00:19:45.820
The setSustainedPerformanceMode
can either

00:19:45.820 --> 00:19:47.830
operate in a single or
a multi-threaded mode.

00:19:47.830 --> 00:19:52.070
Either that means you have your
single threaded application--

00:19:52.070 --> 00:19:55.420
so we could probably use
one core at max frequency--

00:19:55.420 --> 00:19:57.280
or you're multi-threaded,
in which case

00:19:57.280 --> 00:20:00.560
it will set all of the
cores to a lower frequency

00:20:00.560 --> 00:20:02.080
to prevent throttling.

00:20:02.080 --> 00:20:03.760
That's fine for
a game, but we're

00:20:03.760 --> 00:20:06.130
trying to run potentially
different benchmarks

00:20:06.130 --> 00:20:08.500
with different threading
models, and switching

00:20:08.500 --> 00:20:12.500
between these modes will
create inconsistency.

00:20:12.500 --> 00:20:14.170
So what do we do
about this problem?

00:20:14.170 --> 00:20:15.100
How do we make--

00:20:15.100 --> 00:20:17.350
we'd really like to just
pick the multi-threaded mode.

00:20:17.350 --> 00:20:18.610
That's the lower of both.

00:20:18.610 --> 00:20:21.380
That sounds good, but
how do we force that?

00:20:21.380 --> 00:20:24.250
Well, the way that we do this
is in our Android benchmark

00:20:24.250 --> 00:20:25.900
runner.

00:20:25.900 --> 00:20:28.820
When sustained performance
mode is in use,

00:20:28.820 --> 00:20:31.310
we create a new thread.

00:20:31.310 --> 00:20:35.340
And this thread spins.

00:20:35.340 --> 00:20:37.310
And this is a really
strange way to do this,

00:20:37.310 --> 00:20:40.000
but it turns out that this is
actually a pretty efficient way

00:20:40.000 --> 00:20:43.660
to force us into a
multi-threaded mode.

00:20:43.660 --> 00:20:45.898
And it gives us that incredibly
sustained performance

00:20:45.898 --> 00:20:46.940
that we were looking for.

00:20:46.940 --> 00:20:48.977
We also set a
thread name for it.

00:20:48.977 --> 00:20:51.560
So if you see this in a trace,
you understand what's going on.

00:20:51.560 --> 00:20:52.820
And we do the best we can.

00:20:52.820 --> 00:20:55.120
We set thread priority to
be the lowest possible so

00:20:55.120 --> 00:20:57.970
that it interferes with
your test minimally.

00:20:57.970 --> 00:21:00.310
But here's a look of what
that looks like in systrace.

00:21:00.310 --> 00:21:02.560
So on the top there, you
can see clock frequency.

00:21:02.560 --> 00:21:05.530
And over the time of
the benchmark running,

00:21:05.530 --> 00:21:07.990
when the test starts, the
activity launches-- bam,

00:21:07.990 --> 00:21:10.630
we're suddenly locked
to half clocks.

00:21:10.630 --> 00:21:11.140
Perfect.

00:21:11.140 --> 00:21:13.910
We're not going to thermal
throttle in that configuration.

00:21:13.910 --> 00:21:16.840
Once the test is done,
the activity finishes,

00:21:16.840 --> 00:21:21.580
and then the clocks are free to
ramp back up slowly over time.

00:21:21.580 --> 00:21:23.880
So we talked about
how we solve the issue

00:21:23.880 --> 00:21:26.250
with having an activity
running with a flag set.

00:21:26.250 --> 00:21:27.953
We talked about the
two different modes.

00:21:27.953 --> 00:21:29.370
But we still have
this last issue.

00:21:29.370 --> 00:21:32.170
This is only on some N+ devices.

00:21:32.170 --> 00:21:35.640
So you can check whether this is
supported on a specific device

00:21:35.640 --> 00:21:38.080
by calling PowerManager.isS
ustainedPerforma

00:21:38.080 --> 00:21:39.170
nceModeSupported.

00:21:39.170 --> 00:21:40.920
By the way, this is
supported for anything

00:21:40.920 --> 00:21:42.480
that is VR certified.

00:21:42.480 --> 00:21:43.972
So you have that.

00:21:43.972 --> 00:21:45.930
However, in the Firebase
Test Lab, for example,

00:21:45.930 --> 00:21:51.380
11 out of the 17 Nougat+ OS
device combos have support

00:21:51.380 --> 00:21:51.880
for it.

00:21:51.880 --> 00:21:54.047
So it's not terribly hard
to find something that you

00:21:54.047 --> 00:21:56.240
can use like this for CI.

00:21:56.240 --> 00:21:58.700
But again, this is still
not a general solution.

00:21:58.700 --> 00:22:00.530
This requires
platform support that

00:22:00.530 --> 00:22:02.850
isn't available on every phone.

00:22:02.850 --> 00:22:06.210
So our final solution to
this problem at the very end

00:22:06.210 --> 00:22:10.600
here is Thread.sleep.

00:22:10.600 --> 00:22:14.050
The simplest solution--
many devices aren't rooted.

00:22:14.050 --> 00:22:17.470
Many devices don't have
setSustainedPerformanceMode,

00:22:17.470 --> 00:22:19.730
so we use Thread.sleep.

00:22:19.730 --> 00:22:22.990
So what we do here is
we detect a slowdown

00:22:22.990 --> 00:22:25.630
in between every benchmark
by running a little tiny mini

00:22:25.630 --> 00:22:29.995
benchmark to see if the device
has started thermal throttling.

00:22:29.995 --> 00:22:32.620
If it does, we throw away
the current benchmark data,

00:22:32.620 --> 00:22:36.310
and we sleep to let
the device cool down.

00:22:36.310 --> 00:22:39.100
So we saw this
previous slide how

00:22:39.100 --> 00:22:41.500
performance was oscillating
all over the place

00:22:41.500 --> 00:22:44.020
and we couldn't get stable
numbers out of this.

00:22:44.020 --> 00:22:46.660
Well, in this particular
case, our device

00:22:46.660 --> 00:22:50.710
doesn't have root, so we
can't use lock clocks.

00:22:50.710 --> 00:22:52.480
It can't use
setSustainedPerformanceMode.

00:22:52.480 --> 00:22:53.620
Not available, OK.

00:22:53.620 --> 00:22:54.860
Can't use that.

00:22:54.860 --> 00:22:57.610
So we have to fall
back on Thread.sleep.

00:22:57.610 --> 00:23:02.080
So let's see how that actually
performs in this graph.

00:23:02.080 --> 00:23:04.000
That is a lot better.

00:23:04.000 --> 00:23:06.252
It is just completely flat.

00:23:06.252 --> 00:23:08.710
And if you see here, we have
standard deviation for the two

00:23:08.710 --> 00:23:10.060
different approaches.

00:23:10.060 --> 00:23:13.060
For the default, we've
got 2.25 milliseconds.

00:23:13.060 --> 00:23:16.950
And for Thread.sleep,
you've got to look closely,

00:23:16.950 --> 00:23:19.990
0.02 milliseconds-- massively
more stable, much more

00:23:19.990 --> 00:23:21.970
consistent performance.

00:23:21.970 --> 00:23:23.897
But there was a
sacrifice with this.

00:23:23.897 --> 00:23:25.480
So because we were
sleeping every time

00:23:25.480 --> 00:23:26.680
that we detected
thermal throttling,

00:23:26.680 --> 00:23:27.638
it takes longer to run.

00:23:27.638 --> 00:23:29.230
This one takes
about eight minutes.

00:23:29.230 --> 00:23:33.280
The original takes
about four and a half.

00:23:33.280 --> 00:23:36.220
So in summary, our solution
for thermal strategy

00:23:36.220 --> 00:23:37.900
does have three
different steps, and we

00:23:37.900 --> 00:23:40.150
use the best solution
for your device

00:23:40.150 --> 00:23:43.300
that's available for
your particular phone.

00:23:43.300 --> 00:23:45.440
So clocks are one
thing, but what

00:23:45.440 --> 00:23:46.690
about background interference?

00:23:46.690 --> 00:23:50.180
What about other things
running on your device?

00:23:50.180 --> 00:23:56.150
So first of all, you have to
ask, am I in the foreground?

00:23:56.150 --> 00:23:58.425
So if you're not,
something else is.

00:23:58.425 --> 00:24:00.550
And this is important to
think about in the context

00:24:00.550 --> 00:24:03.430
of performance.

00:24:03.430 --> 00:24:07.780
Tests generally run,
if they don't have UI,

00:24:07.780 --> 00:24:09.880
on top of the launcher,
because there's nothing

00:24:09.880 --> 00:24:11.680
to launch, nothing to display.

00:24:11.680 --> 00:24:15.010
However, this means that the OS
thinks the launcher, right now,

00:24:15.010 --> 00:24:17.367
is the important app.

00:24:17.367 --> 00:24:18.950
When you're running
in the background,

00:24:18.950 --> 00:24:20.552
say for instance,
behind the launcher,

00:24:20.552 --> 00:24:22.010
that means you get
a lot of sources

00:24:22.010 --> 00:24:23.930
of potential performance
interference.

00:24:23.930 --> 00:24:26.510
You might have a live
wallpaper rendering.

00:24:26.510 --> 00:24:28.705
You might have home
screen widgets updating.

00:24:28.705 --> 00:24:30.080
You could have
the launcher doing

00:24:30.080 --> 00:24:32.150
hotword detection or
other miscellaneous work

00:24:32.150 --> 00:24:33.980
that you don't know about.

00:24:33.980 --> 00:24:37.070
The status bar is probably
repainting every now and then

00:24:37.070 --> 00:24:38.600
with a notification coming up.

00:24:38.600 --> 00:24:41.390
The clock's changing,
Wi-Fi, whatever.

00:24:41.390 --> 00:24:44.030
And starting at Nougat,
it's possible for devices

00:24:44.030 --> 00:24:46.220
to have a foreground-exclusive
core, a core that

00:24:46.220 --> 00:24:49.910
is only available to be used
by the foreground application.

00:24:49.910 --> 00:24:53.070
You just can't touch that
if you're in the background.

00:24:53.070 --> 00:24:55.220
So we want to come
to the foreground.

00:24:55.220 --> 00:24:57.800
And we actually have a solution
for this already, right?

00:24:57.800 --> 00:24:59.170
We have our old activity.

00:24:59.170 --> 00:25:00.330
Remember this guy?

00:25:00.330 --> 00:25:02.730
So this also solves
this particular problem.

00:25:02.730 --> 00:25:06.020
And that's why we use this in
all benchmark configurations,

00:25:06.020 --> 00:25:08.690
regardless of whatever
your clocks are.

00:25:08.690 --> 00:25:10.460
The benchmark
keeps this activity

00:25:10.460 --> 00:25:14.090
in the foreground at all times,
unless you have your own,

00:25:14.090 --> 00:25:16.010
in order to guarantee
that you can

00:25:16.010 --> 00:25:18.800
use all cores with minimum
rendering interference

00:25:18.800 --> 00:25:22.710
from whatever is going
on underneath you.

00:25:22.710 --> 00:25:24.290
But there's another
important source

00:25:24.290 --> 00:25:25.880
of background interference.

00:25:25.880 --> 00:25:28.050
And that is contention.

00:25:28.050 --> 00:25:32.150
So everything on the
device from CPU to disk

00:25:32.150 --> 00:25:33.900
is a shared resource.

00:25:33.900 --> 00:25:35.810
And if your benchmark
is being, let's say,

00:25:35.810 --> 00:25:38.840
kicked off of a CPU
because of some conflict

00:25:38.840 --> 00:25:42.710
with another task, if you're
accessing disk and system

00:25:42.710 --> 00:25:46.140
services at the same time
that someone else is,

00:25:46.140 --> 00:25:48.880
or if somebody has random
background work happening,

00:25:48.880 --> 00:25:51.420
for instance, the
system doing something,

00:25:51.420 --> 00:25:54.460
an app background job,
something along those lines.

00:25:54.460 --> 00:25:57.370
Those can create contention.

00:25:57.370 --> 00:25:59.870
So for example, if we
were running our benchmark

00:25:59.870 --> 00:26:02.670
and warmup just finished,
so we're just right

00:26:02.670 --> 00:26:05.380
about to start
taking measurements.

00:26:05.380 --> 00:26:07.680
However, we have this
other process here that's

00:26:07.680 --> 00:26:09.720
about to start doing some work.

00:26:09.720 --> 00:26:12.750
Our first few loops are fine,
but then the other process

00:26:12.750 --> 00:26:15.220
kicks in and starts
running as well.

00:26:15.220 --> 00:26:17.220
All of a sudden, we see,
oh, well, actually some

00:26:17.220 --> 00:26:20.040
of these loops are just giving
me flat out bad numbers.

00:26:20.040 --> 00:26:22.920
Not very useful numbers that
overlap with this background

00:26:22.920 --> 00:26:24.360
work.

00:26:24.360 --> 00:26:26.490
Some of these runs are
still totally fine,

00:26:26.490 --> 00:26:28.560
but some of them aren't.

00:26:28.560 --> 00:26:32.100
So that's why we have this idea
of measure twice, report once.

00:26:32.100 --> 00:26:36.692
And by twice I, of
course, mean many times.

00:26:36.692 --> 00:26:37.650
We will measure every--

00:26:37.650 --> 00:26:39.210
we will measure several loops.

00:26:39.210 --> 00:26:41.580
And understanding
that most contention

00:26:41.580 --> 00:26:46.410
is for a short
duration, we can ignore

00:26:46.410 --> 00:26:50.080
those loops that are most
likely to have hit contention.

00:26:50.080 --> 00:26:52.380
So what we do, in fact, is
that we report and track

00:26:52.380 --> 00:26:55.080
the minimum number
observed, not the average,

00:26:55.080 --> 00:26:59.218
because the average is
susceptible to contention.

00:26:59.218 --> 00:27:01.510
This way, the number that we
report by the benchmarking

00:27:01.510 --> 00:27:03.610
library is immune to
tiny little hiccups that

00:27:03.610 --> 00:27:05.860
happen every now and
then and might otherwise

00:27:05.860 --> 00:27:08.853
interfere with your numbers.

00:27:08.853 --> 00:27:10.270
All right, so let's
talk about how

00:27:10.270 --> 00:27:13.467
to go about using this library.

00:27:13.467 --> 00:27:15.300
So the first thing that
we want to recommend

00:27:15.300 --> 00:27:18.000
is-- don't benchmark everything.

00:27:18.000 --> 00:27:19.110
Start with tracing.

00:27:19.110 --> 00:27:20.700
Start with profiling tools.

00:27:20.700 --> 00:27:25.590
Maybe you have measurement
going on on real user devices

00:27:25.590 --> 00:27:27.990
that tell you some
particular part is slow.

00:27:27.990 --> 00:27:30.970
Well, that's a good
place to start.

00:27:30.970 --> 00:27:33.960
Benchmark what you know is slow
so that you can iterate on it

00:27:33.960 --> 00:27:36.510
and improve it.

00:27:36.510 --> 00:27:38.220
We generally
recommend benchmarking

00:27:38.220 --> 00:27:40.350
synchronous blocks, because
these are the easiest

00:27:40.350 --> 00:27:44.170
to measure and these are the
easiest to improve over time.

00:27:44.170 --> 00:27:47.050
So if you're measuring something
that's single-threaded,

00:27:47.050 --> 00:27:49.350
it is much more likely
to be stable and isolated

00:27:49.350 --> 00:27:50.440
from other tasks.

00:27:50.440 --> 00:27:51.720
There's no thread hopping.

00:27:51.720 --> 00:27:54.750
That means you're taking
the scheduler entirely out

00:27:54.750 --> 00:27:57.000
of the mix.

00:27:57.000 --> 00:27:59.640
And that way, for instance,
you might measure UI separately

00:27:59.640 --> 00:28:03.930
from network separately
from database and rendering.

00:28:03.930 --> 00:28:07.020
We also generally recommend
fairly small blocks.

00:28:07.020 --> 00:28:08.710
These are faster to run.

00:28:08.710 --> 00:28:13.390
And here we've been probably
less than 50 milliseconds.

00:28:13.390 --> 00:28:17.250
However, the loop itself
only has around 6 nanoseconds

00:28:17.250 --> 00:28:18.330
overhead.

00:28:18.330 --> 00:28:21.922
And this is running on a fairly
old device at half clocks.

00:28:21.922 --> 00:28:23.880
So you can measure really
small amounts of work

00:28:23.880 --> 00:28:26.262
with a benchmarking library.

00:28:26.262 --> 00:28:27.720
Another important
thing to remember

00:28:27.720 --> 00:28:30.870
is that the benchmarking library
is primarily for hot code.

00:28:30.870 --> 00:28:35.020
Because we run all of
your code with warmup

00:28:35.020 --> 00:28:36.930
and we run it in a
loop, that probably

00:28:36.930 --> 00:28:39.850
means that the code inside
is going to be JIT-ed.

00:28:39.850 --> 00:28:42.220
Now, that's great if it's
something like work that's

00:28:42.220 --> 00:28:44.410
done by your Recycler
view, but if it's only

00:28:44.410 --> 00:28:46.180
run once in a while
by your app, it's

00:28:46.180 --> 00:28:48.440
not as likely to get JIT-ed.

00:28:48.440 --> 00:28:51.070
So be very careful when
you're benchmarking startup.

00:28:51.070 --> 00:28:54.070
We generally recommend
to only benchmark

00:28:54.070 --> 00:28:56.350
the code that is inside
of a loop during startup

00:28:56.350 --> 00:29:01.800
so that is more likely
to be measured correctly.

00:29:01.800 --> 00:29:04.380
Another thing to
keep in mind is to be

00:29:04.380 --> 00:29:08.890
aware of caches that might
be anywhere in your code,

00:29:08.890 --> 00:29:10.390
or even in someone else's code.

00:29:10.390 --> 00:29:15.040
So here's a simple
example of a benchmark

00:29:15.040 --> 00:29:18.850
where we access a file and
check whether it exists.

00:29:18.850 --> 00:29:21.640
Maybe we observed that this
took a couple of milliseconds

00:29:21.640 --> 00:29:22.600
during startup.

00:29:22.600 --> 00:29:25.990
The problem is that the
OS is going to take this

00:29:25.990 --> 00:29:27.610
and it's going to
know that nothing

00:29:27.610 --> 00:29:30.690
has changed and just served
you a cached value every time.

00:29:30.690 --> 00:29:32.890
The benchmark is going
to be very different

00:29:32.890 --> 00:29:34.580
than the behavior at startup.

00:29:34.580 --> 00:29:35.440
So be aware of this.

00:29:35.440 --> 00:29:40.820
You can sometimes take measures
to create things differently,

00:29:40.820 --> 00:29:42.820
for example, like Dustin
showed at the beginning

00:29:42.820 --> 00:29:45.520
with the database.

00:29:45.520 --> 00:29:48.630
Another thing to consider
is potentially avoid

00:29:48.630 --> 00:29:50.410
overparameterizing.

00:29:50.410 --> 00:29:53.160
So correctness tests, it's
really easy to, say, sweep

00:29:53.160 --> 00:29:56.340
over five different
variables, recognize that, OK,

00:29:56.340 --> 00:29:59.850
over all 4,000 of these
tests, none of them failed.

00:29:59.850 --> 00:30:00.540
Great.

00:30:00.540 --> 00:30:02.070
You get a pass.

00:30:02.070 --> 00:30:04.590
That is a much harder
task for benchmarking,

00:30:04.590 --> 00:30:07.590
because we're getting something
that isn't a simple pass/fail.

00:30:07.590 --> 00:30:10.870
More data can be more
difficult to deal with.

00:30:10.870 --> 00:30:13.800
We recommend to start targeting
benchmarks at real world

00:30:13.800 --> 00:30:17.580
parameters instead of maybe
going as enthusiastically

00:30:17.580 --> 00:30:20.320
towards parameterization as
you might during a unit test.

00:30:22.970 --> 00:30:24.970
One thing I really want
to re-emphasize, though,

00:30:24.970 --> 00:30:27.010
that Dustin mentioned
before, is, please,

00:30:27.010 --> 00:30:30.560
do not compare devices.

00:30:30.560 --> 00:30:33.850
This library is not designed
to compare the performance

00:30:33.850 --> 00:30:36.310
of one device versus another.

00:30:36.310 --> 00:30:39.325
We're really focused
on comparing code,

00:30:39.325 --> 00:30:41.200
whether that's framework
code, whether that's

00:30:41.200 --> 00:30:45.850
app code, on the same device,
same operating system version.

00:30:45.850 --> 00:30:48.250
The library optimizes
for stability.

00:30:48.250 --> 00:30:50.470
It will have some
factor of difference,

00:30:50.470 --> 00:30:53.320
that can vary from device
to device, over what

00:30:53.320 --> 00:30:55.810
you see on a benchmark versus
what you see in reality.

00:30:55.810 --> 00:30:59.860
And that's because we do not
account for real-world clocks.

00:30:59.860 --> 00:31:03.070
For example, if the user
touches down on their device,

00:31:03.070 --> 00:31:06.250
starts scrolling, generally
the clocks will ramp.

00:31:06.250 --> 00:31:08.500
If a user uses their
device for a while

00:31:08.500 --> 00:31:12.070
and it gets hot and thermal
throttles, it performs poorly,

00:31:12.070 --> 00:31:13.610
the clocks go down.

00:31:13.610 --> 00:31:16.060
None of that is accounted for
in the benchmarking library.

00:31:16.060 --> 00:31:18.577
And that's why we don't
recommend comparing devices

00:31:18.577 --> 00:31:19.285
with our library.

00:31:21.843 --> 00:31:23.260
So you might be
wondering, OK, how

00:31:23.260 --> 00:31:26.540
do I go about in
integrating this into my CI?

00:31:26.540 --> 00:31:28.910
So there are different
tiers of adoption

00:31:28.910 --> 00:31:32.840
that you can start with to
look at exactly how deeply you

00:31:32.840 --> 00:31:34.580
want to get into benchmarking.

00:31:34.580 --> 00:31:36.820
The first is quick and local.

00:31:36.820 --> 00:31:41.420
It's very reasonable to do
a trace, write a benchmark,

00:31:41.420 --> 00:31:44.350
and measure the
performance, make a change,

00:31:44.350 --> 00:31:45.890
check in that change
without having

00:31:45.890 --> 00:31:49.370
to monitor the performance over
time and detect regressions.

00:31:49.370 --> 00:31:52.370
And in general, this is because,
unlike correctness tests,

00:31:52.370 --> 00:31:57.140
benchmarks usually get better
because you're deleting code.

00:31:57.140 --> 00:31:59.120
Now, that said, if
you can monitor them

00:31:59.120 --> 00:32:02.350
over time, potentially manually,
that's a totally reasonable way

00:32:02.350 --> 00:32:02.850
to go.

00:32:02.850 --> 00:32:05.370
And that's even better.

00:32:05.370 --> 00:32:07.670
But we want to recognize
that there's still

00:32:07.670 --> 00:32:10.070
value in manual
monitoring of benchmarks,

00:32:10.070 --> 00:32:14.300
even if you don't have
automatic regression detection.

00:32:14.300 --> 00:32:19.230
Because automatic regression
detection is a complex problem.

00:32:19.230 --> 00:32:22.170
However, if you do want to go
all the way to that point--

00:32:22.170 --> 00:32:25.430
and we recommend it--

00:32:25.430 --> 00:32:28.040
it is something to
recognize that it's not

00:32:28.040 --> 00:32:30.290
as simple as detecting, when
does my benchmark go down

00:32:30.290 --> 00:32:31.490
by, say, 1%?

00:32:31.490 --> 00:32:34.143
Because there's going to be all
sorts of times where it flakes

00:32:34.143 --> 00:32:35.810
a little bit, it goes
down a little bit,

00:32:35.810 --> 00:32:39.230
and make a trade for one
benchmark versus another,

00:32:39.230 --> 00:32:41.510
or you check in a feature
that just absolutely needs

00:32:41.510 --> 00:32:44.518
to make this one code
path slightly slower.

00:32:44.518 --> 00:32:47.060
So if you're prepared to receive
emails for all those things,

00:32:47.060 --> 00:32:49.010
by all means, just
something to keep in mind.

00:32:51.560 --> 00:32:53.630
And so let's go through
a few closing notes.

00:32:53.630 --> 00:32:56.180
We do have, as Dustin
mentioned earlier,

00:32:56.180 --> 00:32:59.930
an NDK sample that shows how to
use some of our infrastructure

00:32:59.930 --> 00:33:02.090
together with C++ code.

00:33:02.090 --> 00:33:04.460
That's available on our
android-performance GitHub

00:33:04.460 --> 00:33:06.370
repository.

00:33:06.370 --> 00:33:09.640
And it actually wraps the
existing Google benchmark C++

00:33:09.640 --> 00:33:13.630
library to get numbers directly
from infrastructure that you

00:33:13.630 --> 00:33:16.420
might already be using
for C++ benchmarking.

00:33:16.420 --> 00:33:20.250
It captures the results together
with Java and Kotlin benchmarks

00:33:20.250 --> 00:33:21.800
in our final output.

00:33:21.800 --> 00:33:24.280
And it applies all of our
Android-specific tricks

00:33:24.280 --> 00:33:25.960
regarding stabilizing clocks.

00:33:29.030 --> 00:33:31.797
So Dustin mentioned that this is
actually a fairly old library.

00:33:31.797 --> 00:33:33.380
So why haven't you
heard of it before?

00:33:33.380 --> 00:33:35.360
Well, this library
has been around

00:33:35.360 --> 00:33:40.580
since about 2016, used inside
of the Android platform.

00:33:40.580 --> 00:33:43.130
And we use it all
over the place.

00:33:43.130 --> 00:33:45.710
We use it for text, for
graphics, for views,

00:33:45.710 --> 00:33:48.710
for resources, for
SQLite, for optimizing all

00:33:48.710 --> 00:33:50.143
of these different components.

00:33:50.143 --> 00:33:51.560
But for a long
time it's been very

00:33:51.560 --> 00:33:55.280
difficult to use externally
because we kind of needed

00:33:55.280 --> 00:33:58.400
you to have a rooted
device to run this on.

00:33:58.400 --> 00:34:00.050
That's easy for a
platform developer,

00:34:00.050 --> 00:34:01.730
much harder for
an app developer.

00:34:01.730 --> 00:34:03.860
But more recently,
we have overhauled it

00:34:03.860 --> 00:34:05.630
for non-rooted devices.

00:34:05.630 --> 00:34:07.760
We've switched over to
Kotlin, which gave us

00:34:07.760 --> 00:34:10.580
some really nice benefits in
terms of function inlining

00:34:10.580 --> 00:34:13.190
for that measurement
loop and allowed

00:34:13.190 --> 00:34:14.370
us to minimize overhead.

00:34:14.370 --> 00:34:17.630
So now libraries such as
Room, Navigation, and Slices

00:34:17.630 --> 00:34:23.389
all use our benchmarking
library to make improvements.

00:34:23.389 --> 00:34:26.155
So here's an example
from the platform

00:34:26.155 --> 00:34:27.280
from a couple of years ago.

00:34:27.280 --> 00:34:28.822
I think this was in
O when we noticed

00:34:28.822 --> 00:34:31.540
that, hey, toggling the
visibility of a relatively

00:34:31.540 --> 00:34:34.070
large tree of views
was kind of expensive.

00:34:34.070 --> 00:34:36.820
So this was our CI
over the process

00:34:36.820 --> 00:34:38.889
of checking in a few changes.

00:34:38.889 --> 00:34:41.530
So at the beginning,
modifying these views

00:34:41.530 --> 00:34:43.780
took 350 microseconds.

00:34:43.780 --> 00:34:45.550
And we checked in
an optimization

00:34:45.550 --> 00:34:49.489
for how outlines were changed
when views were stored.

00:34:49.489 --> 00:34:51.460
And so it went
down a little bit.

00:34:51.460 --> 00:34:53.739
And we actually realized,
OK, most of the work

00:34:53.739 --> 00:34:56.153
here is actually
in View.invalidate.

00:34:56.153 --> 00:34:57.820
It's doing a lot of
work that it doesn't

00:34:57.820 --> 00:35:00.410
need to anymore in a modern
hardware-accelerated pipeline.

00:35:00.410 --> 00:35:03.910
So we checked in a
complete overhaul of that.

00:35:03.910 --> 00:35:05.620
And of course, we
quickly reverted it

00:35:05.620 --> 00:35:07.240
because it broke the world.

00:35:07.240 --> 00:35:10.480
But we didn't learn
a lot of things

00:35:10.480 --> 00:35:12.200
that we needed to
change along that path.

00:35:12.200 --> 00:35:14.920
And after we were able
to check that back in,

00:35:14.920 --> 00:35:17.570
we were able to get a
total improvement of 100%--

00:35:17.570 --> 00:35:22.240
of 50% of taking that view
toggling from 0.35 milliseconds

00:35:22.240 --> 00:35:25.030
per, say, 64 views or
whatever, down to half

00:35:25.030 --> 00:35:27.200
of that, which is
a huge improvement.

00:35:27.200 --> 00:35:29.560
And we did this all before
we had automatic regression

00:35:29.560 --> 00:35:31.920
testing.

00:35:31.920 --> 00:35:34.518
So in summary here, we've seen
through all of these tricks

00:35:34.518 --> 00:35:36.060
that we've talked
about, benchmarking

00:35:36.060 --> 00:35:37.840
is a really complex problem.

00:35:37.840 --> 00:35:39.960
It's really hard to
measure accurately.

00:35:39.960 --> 00:35:44.950
It's completely foiled
by clock instability.

00:35:44.950 --> 00:35:48.160
And background interference
can be a real source of pain

00:35:48.160 --> 00:35:51.220
when you're trying
to detect changes.

00:35:51.220 --> 00:35:52.720
That's why with
Jetpack Benchmarking

00:35:52.720 --> 00:35:54.970
we've provided a simple API.

00:35:54.970 --> 00:35:56.590
We bundled in all
the lessons we've

00:35:56.590 --> 00:35:59.890
learned about getting stable
numbers out of a device.

00:35:59.890 --> 00:36:03.130
And the alpha is available now.

00:36:03.130 --> 00:36:05.500
Thank you so much for coming.

00:36:05.500 --> 00:36:10.060
If you remember only one
thing, d.android.com/benchmark.

00:36:10.060 --> 00:36:11.200
Thank you all so much.

00:36:11.200 --> 00:36:15.150
[MUSIC PLAYING]

