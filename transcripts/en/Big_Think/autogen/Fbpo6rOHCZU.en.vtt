WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.880
 
as machines become increasingly

00:00:01.880 --> 00:00:01.890
as machines become increasingly
 

00:00:01.890 --> 00:00:04.610
as machines become increasingly
autonomous by which I mean that they can

00:00:04.610 --> 00:00:04.620
autonomous by which I mean that they can
 

00:00:04.620 --> 00:00:05.660
autonomous by which I mean that they can
sense their environment and they can

00:00:05.660 --> 00:00:05.670
sense their environment and they can
 

00:00:05.670 --> 00:00:07.970
sense their environment and they can
make decisions about what to do or what

00:00:07.970 --> 00:00:07.980
make decisions about what to do or what
 

00:00:07.980 --> 00:00:09.500
make decisions about what to do or what
not to do of course it's based on their

00:00:09.500 --> 00:00:09.510
not to do of course it's based on their
 

00:00:09.510 --> 00:00:12.020
not to do of course it's based on their
programming and their experience but we

00:00:12.020 --> 00:00:12.030
programming and their experience but we
 

00:00:12.030 --> 00:00:14.240
programming and their experience but we
don't have this direct control over what

00:00:14.240 --> 00:00:14.250
don't have this direct control over what
 

00:00:14.250 --> 00:00:17.090
don't have this direct control over what
they do as we do today with the kinds of

00:00:17.090 --> 00:00:17.100
they do as we do today with the kinds of
 

00:00:17.100 --> 00:00:20.750
they do as we do today with the kinds of
technology that we have now there's a

00:00:20.750 --> 00:00:20.760
technology that we have now there's a
 

00:00:20.760 --> 00:00:22.700
technology that we have now there's a
couple of very interesting consequences

00:00:22.700 --> 00:00:22.710
couple of very interesting consequences
 

00:00:22.710 --> 00:00:25.340
couple of very interesting consequences
of that one of them is that they're

00:00:25.340 --> 00:00:25.350
of that one of them is that they're
 

00:00:25.350 --> 00:00:26.570
of that one of them is that they're
going to be faced with having to make

00:00:26.570 --> 00:00:26.580
going to be faced with having to make
 

00:00:26.580 --> 00:00:30.050
going to be faced with having to make
ethical decisions I'll call it ethics

00:00:30.050 --> 00:00:30.060
ethical decisions I'll call it ethics
 

00:00:30.060 --> 00:00:32.089
ethical decisions I'll call it ethics
jr. is just making socially appropriate

00:00:32.089 --> 00:00:32.099
jr. is just making socially appropriate
 

00:00:32.099 --> 00:00:34.639
jr. is just making socially appropriate
decisions so we're taking machines and

00:00:34.639 --> 00:00:34.649
decisions so we're taking machines and
 

00:00:34.649 --> 00:00:35.930
decisions so we're taking machines and
we're putting them in situations where

00:00:35.930 --> 00:00:35.940
we're putting them in situations where
 

00:00:35.940 --> 00:00:37.400
we're putting them in situations where
they're around people and something that

00:00:37.400 --> 00:00:37.410
they're around people and something that
 

00:00:37.410 --> 00:00:38.900
they're around people and something that
we take for granted and it seems so

00:00:38.900 --> 00:00:38.910
we take for granted and it seems so
 

00:00:38.910 --> 00:00:41.660
we take for granted and it seems so
natural that machines do not take for

00:00:41.660 --> 00:00:41.670
natural that machines do not take for
 

00:00:41.670 --> 00:00:43.490
natural that machines do not take for
granted and do not find natural is the

00:00:43.490 --> 00:00:43.500
granted and do not find natural is the
 

00:00:43.500 --> 00:00:44.990
granted and do not find natural is the
normal kinds of social courtesies and

00:00:44.990 --> 00:00:45.000
normal kinds of social courtesies and
 

00:00:45.000 --> 00:00:48.799
normal kinds of social courtesies and
conventions that we operate by in

00:00:48.799 --> 00:00:48.809
conventions that we operate by in
 

00:00:48.809 --> 00:00:51.110
conventions that we operate by in
dealing with other people you don't want

00:00:51.110 --> 00:00:51.120
dealing with other people you don't want
 

00:00:51.120 --> 00:00:52.700
dealing with other people you don't want
to have a robot that's making a delivery

00:00:52.700 --> 00:00:52.710
to have a robot that's making a delivery
 

00:00:52.710 --> 00:00:54.889
to have a robot that's making a delivery
or run down the sidewalk and you know

00:00:54.889 --> 00:00:54.899
or run down the sidewalk and you know
 

00:00:54.899 --> 00:00:57.080
or run down the sidewalk and you know
everybody's got to get out of the way it

00:00:57.080 --> 00:00:57.090
everybody's got to get out of the way it
 

00:00:57.090 --> 00:00:58.819
everybody's got to get out of the way it
has to be able to walk in a crowd in a

00:00:58.819 --> 00:00:58.829
has to be able to walk in a crowd in a
 

00:00:58.829 --> 00:01:01.490
has to be able to walk in a crowd in a
socially appropriate way your autonomous

00:01:01.490 --> 00:01:01.500
socially appropriate way your autonomous
 

00:01:01.500 --> 00:01:03.080
socially appropriate way your autonomous
car there are lots of very interesting

00:01:03.080 --> 00:01:03.090
car there are lots of very interesting
 

00:01:03.090 --> 00:01:06.260
car there are lots of very interesting
ethical conundrums that come up but a

00:01:06.260 --> 00:01:06.270
ethical conundrums that come up but a
 

00:01:06.270 --> 00:01:07.940
ethical conundrums that come up but a
lot of them are just social ok it pulls

00:01:07.940 --> 00:01:07.950
lot of them are just social ok it pulls
 

00:01:07.950 --> 00:01:11.000
lot of them are just social ok it pulls
up to discuss the crosswalk should you

00:01:11.000 --> 00:01:11.010
up to discuss the crosswalk should you
 

00:01:11.010 --> 00:01:12.530
up to discuss the crosswalk should you
cross should you wait how's it going to

00:01:12.530 --> 00:01:12.540
cross should you wait how's it going to
 

00:01:12.540 --> 00:01:15.800
cross should you wait how's it going to
signal you it's right now the social

00:01:15.800 --> 00:01:15.810
signal you it's right now the social
 

00:01:15.810 --> 00:01:17.120
signal you it's right now the social
dimensions you make eye contact with the

00:01:17.120 --> 00:01:17.130
dimensions you make eye contact with the
 

00:01:17.130 --> 00:01:18.590
dimensions you make eye contact with the
driver and they tell you whether to

00:01:18.590 --> 00:01:18.600
driver and they tell you whether to
 

00:01:18.600 --> 00:01:21.890
driver and they tell you whether to
cross you know now I can't make eye

00:01:21.890 --> 00:01:21.900
cross you know now I can't make eye
 

00:01:21.900 --> 00:01:25.010
cross you know now I can't make eye
contact with an autonomous car so there

00:01:25.010 --> 00:01:25.020
contact with an autonomous car so there
 

00:01:25.020 --> 00:01:26.420
contact with an autonomous car so there
are lots of these sort of rough edges

00:01:26.420 --> 00:01:26.430
are lots of these sort of rough edges
 

00:01:26.430 --> 00:01:29.960
are lots of these sort of rough edges
around how machines ought to be able to

00:01:29.960 --> 00:01:29.970
around how machines ought to be able to
 

00:01:29.970 --> 00:01:32.870
around how machines ought to be able to
behave and the situation's are highly

00:01:32.870 --> 00:01:32.880
behave and the situation's are highly
 

00:01:32.880 --> 00:01:34.700
behave and the situation's are highly
variable you can't just make a list of

00:01:34.700 --> 00:01:34.710
variable you can't just make a list of
 

00:01:34.710 --> 00:01:36.590
variable you can't just make a list of
them and say do this and do that we need

00:01:36.590 --> 00:01:36.600
them and say do this and do that we need
 

00:01:36.600 --> 00:01:38.780
them and say do this and do that we need
to program into these devices some

00:01:38.780 --> 00:01:38.790
to program into these devices some
 

00:01:38.790 --> 00:01:40.730
to program into these devices some
fairly general principles you can call

00:01:40.730 --> 00:01:40.740
fairly general principles you can call
 

00:01:40.740 --> 00:01:43.460
fairly general principles you can call
them ethical if you like which will

00:01:43.460 --> 00:01:43.470
them ethical if you like which will
 

00:01:43.470 --> 00:01:45.170
them ethical if you like which will
allow them to guide their own behavior

00:01:45.170 --> 00:01:45.180
allow them to guide their own behavior
 

00:01:45.180 --> 00:01:47.389
allow them to guide their own behavior
in ways and interactions that are

00:01:47.389 --> 00:01:47.399
in ways and interactions that are
 

00:01:47.399 --> 00:01:49.190
in ways and interactions that are
consistent with the expectations that we

00:01:49.190 --> 00:01:49.200
consistent with the expectations that we
 

00:01:49.200 --> 00:01:53.569
consistent with the expectations that we
have in society now I'm I'm teaching at

00:01:53.569 --> 00:01:53.579
have in society now I'm I'm teaching at
 

00:01:53.579 --> 00:01:56.719
have in society now I'm I'm teaching at
Stanford and I can tell you I haven't

00:01:56.719 --> 00:01:56.729
Stanford and I can tell you I haven't
 

00:01:56.729 --> 00:01:59.510
Stanford and I can tell you I haven't
seen anything about this in the

00:01:59.510 --> 00:01:59.520
seen anything about this in the
 

00:01:59.520 --> 00:02:02.300
seen anything about this in the
engineering curriculum there's how to be

00:02:02.300 --> 00:02:02.310
engineering curriculum there's how to be
 

00:02:02.310 --> 00:02:04.459
engineering curriculum there's how to be
an ethical engineer but there isn't how

00:02:04.459 --> 00:02:04.469
an ethical engineer but there isn't how
 

00:02:04.469 --> 00:02:06.709
an ethical engineer but there isn't how
do you build a device to be ethical this

00:02:06.709 --> 00:02:06.719
do you build a device to be ethical this
 

00:02:06.719 --> 00:02:08.660
do you build a device to be ethical this
is a completely new area that's

00:02:08.660 --> 00:02:08.670
is a completely new area that's
 

00:02:08.670 --> 00:02:10.609
is a completely new area that's
sometimes got some name moral

00:02:10.609 --> 00:02:10.619
sometimes got some name moral
 

00:02:10.619 --> 00:02:13.640
sometimes got some name moral
programming computational ethics

00:02:13.640 --> 00:02:13.650
programming computational ethics
 

00:02:13.650 --> 00:02:14.930
programming computational ethics
there's some excellent books on this

00:02:14.930 --> 00:02:14.940
there's some excellent books on this
 

00:02:14.940 --> 00:02:17.449
there's some excellent books on this
subject but unfortunately if you read

00:02:17.449 --> 00:02:17.459
subject but unfortunately if you read
 

00:02:17.459 --> 00:02:19.699
subject but unfortunately if you read
those books which I I have to do because

00:02:19.699 --> 00:02:19.709
those books which I I have to do because
 

00:02:19.709 --> 00:02:23.330
those books which I I have to do because
that's my my job they're mostly pointing

00:02:23.330 --> 00:02:23.340
that's my my job they're mostly pointing
 

00:02:23.340 --> 00:02:25.490
that's my my job they're mostly pointing
out the problems nobody has a really

00:02:25.490 --> 00:02:25.500
out the problems nobody has a really
 

00:02:25.500 --> 00:02:27.470
out the problems nobody has a really
good scheme for how to go about doing

00:02:27.470 --> 00:02:27.480
good scheme for how to go about doing
 

00:02:27.480 --> 00:02:28.039
good scheme for how to go about doing
this

00:02:28.039 --> 00:02:28.049
this
 

00:02:28.049 --> 00:02:30.410
this
so we need to develop an engineering

00:02:30.410 --> 00:02:30.420
so we need to develop an engineering
 

00:02:30.420 --> 00:02:33.619
so we need to develop an engineering
discipline of computational ethics and

00:02:33.619 --> 00:02:33.629
discipline of computational ethics and
 

00:02:33.629 --> 00:02:36.289
discipline of computational ethics and
we need to have course sequences in our

00:02:36.289 --> 00:02:36.299
we need to have course sequences in our
 

00:02:36.299 --> 00:02:39.140
we need to have course sequences in our
engineering schools that teach how to

00:02:39.140 --> 00:02:39.150
engineering schools that teach how to
 

00:02:39.150 --> 00:02:41.630
engineering schools that teach how to
get machines to behave appropriately in

00:02:41.630 --> 00:02:41.640
get machines to behave appropriately in
 

00:02:41.640 --> 00:02:43.940
get machines to behave appropriately in
a wide variety of new circumstances

00:02:43.940 --> 00:02:43.950
a wide variety of new circumstances
 

00:02:43.950 --> 00:02:45.319
a wide variety of new circumstances
let me point out some of the more

00:02:45.319 --> 00:02:45.329
let me point out some of the more
 

00:02:45.329 --> 00:02:47.210
let me point out some of the more
serious kinds of conundrums just to give

00:02:47.210 --> 00:02:47.220
serious kinds of conundrums just to give
 

00:02:47.220 --> 00:02:48.770
serious kinds of conundrums just to give
you a feel for it and then others that

00:02:48.770 --> 00:02:48.780
you a feel for it and then others that
 

00:02:48.780 --> 00:02:52.130
you a feel for it and then others that
are just inconveniences okay on the very

00:02:52.130 --> 00:02:52.140
are just inconveniences okay on the very
 

00:02:52.140 --> 00:02:53.630
are just inconveniences okay on the very
serious side there's a classic

00:02:53.630 --> 00:02:53.640
serious side there's a classic
 

00:02:53.640 --> 00:02:56.479
serious side there's a classic
philosophical debate that goes on over

00:02:56.479 --> 00:02:56.489
philosophical debate that goes on over
 

00:02:56.489 --> 00:02:58.729
philosophical debate that goes on over
what's called the trolley problem and

00:02:58.729 --> 00:02:58.739
what's called the trolley problem and
 

00:02:58.739 --> 00:03:01.759
what's called the trolley problem and
the trolley problem is basically you're

00:03:01.759 --> 00:03:01.769
the trolley problem is basically you're
 

00:03:01.769 --> 00:03:04.970
the trolley problem is basically you're
you're in a trolley and there's track

00:03:04.970 --> 00:03:04.980
you're in a trolley and there's track
 

00:03:04.980 --> 00:03:07.399
you're in a trolley and there's track
splits if you take no action the trolley

00:03:07.399 --> 00:03:07.409
splits if you take no action the trolley
 

00:03:07.409 --> 00:03:08.390
splits if you take no action the trolley
is going to go to the right and there

00:03:08.390 --> 00:03:08.400
is going to go to the right and there
 

00:03:08.400 --> 00:03:09.770
is going to go to the right and there
are four people on the track and it's

00:03:09.770 --> 00:03:09.780
are four people on the track and it's
 

00:03:09.780 --> 00:03:12.380
are four people on the track and it's
going to kill those people you can flip

00:03:12.380 --> 00:03:12.390
going to kill those people you can flip
 

00:03:12.390 --> 00:03:14.259
going to kill those people you can flip
a switch and it'll go down the left

00:03:14.259 --> 00:03:14.269
a switch and it'll go down the left
 

00:03:14.269 --> 00:03:17.330
a switch and it'll go down the left
track and there's only one person on

00:03:17.330 --> 00:03:17.340
track and there's only one person on
 

00:03:17.340 --> 00:03:20.180
track and there's only one person on
that track the ethical question is is it

00:03:20.180 --> 00:03:20.190
that track the ethical question is is it
 

00:03:20.190 --> 00:03:24.050
that track the ethical question is is it
ethical to flip that switch it is true

00:03:24.050 --> 00:03:24.060
ethical to flip that switch it is true
 

00:03:24.060 --> 00:03:26.050
ethical to flip that switch it is true
that the loss of life would be minimized

00:03:26.050 --> 00:03:26.060
that the loss of life would be minimized
 

00:03:26.060 --> 00:03:29.270
that the loss of life would be minimized
but is also true that you've now taken

00:03:29.270 --> 00:03:29.280
but is also true that you've now taken
 

00:03:29.280 --> 00:03:31.280
but is also true that you've now taken
an action to kill somebody and if you're

00:03:31.280 --> 00:03:31.290
an action to kill somebody and if you're
 

00:03:31.290 --> 00:03:33.319
an action to kill somebody and if you're
that person you may not think that's the

00:03:33.319 --> 00:03:33.329
that person you may not think that's the
 

00:03:33.329 --> 00:03:35.240
that person you may not think that's the
right the right thing to do so

00:03:35.240 --> 00:03:35.250
right the right thing to do so
 

00:03:35.250 --> 00:03:36.860
right the right thing to do so
philosophers have been studying this and

00:03:36.860 --> 00:03:36.870
philosophers have been studying this and
 

00:03:36.870 --> 00:03:38.479
philosophers have been studying this and
many variations and there's a lot of

00:03:38.479 --> 00:03:38.489
many variations and there's a lot of
 

00:03:38.489 --> 00:03:40.909
many variations and there's a lot of
very subtle and interesting work that

00:03:40.909 --> 00:03:40.919
very subtle and interesting work that
 

00:03:40.919 --> 00:03:43.250
very subtle and interesting work that
goes on in this but this is about to

00:03:43.250 --> 00:03:43.260
goes on in this but this is about to
 

00:03:43.260 --> 00:03:45.650
goes on in this but this is about to
become very real because autonomous cars

00:03:45.650 --> 00:03:45.660
become very real because autonomous cars
 

00:03:45.660 --> 00:03:47.150
become very real because autonomous cars
will face exactly these kinds of

00:03:47.150 --> 00:03:47.160
will face exactly these kinds of
 

00:03:47.160 --> 00:03:49.909
will face exactly these kinds of
decisions so I'm gonna buy an autonomous

00:03:49.909 --> 00:03:49.919
decisions so I'm gonna buy an autonomous
 

00:03:49.919 --> 00:03:53.839
decisions so I'm gonna buy an autonomous
car and I'm in the car I'm the one guy

00:03:53.839 --> 00:03:53.849
car and I'm in the car I'm the one guy
 

00:03:53.849 --> 00:03:56.990
car and I'm in the car I'm the one guy
and there may be circumstances in which

00:03:56.990 --> 00:03:57.000
and there may be circumstances in which
 

00:03:57.000 --> 00:04:00.500
and there may be circumstances in which
there are four lives four people in

00:04:00.500 --> 00:04:00.510
there are four lives four people in
 

00:04:00.510 --> 00:04:02.809
there are four lives four people in
front of the car in some way and to save

00:04:02.809 --> 00:04:02.819
front of the car in some way and to save
 

00:04:02.819 --> 00:04:05.659
front of the car in some way and to save
their lives my car has to drive off the

00:04:05.659 --> 00:04:05.669
their lives my car has to drive off the
 

00:04:05.669 --> 00:04:07.430
their lives my car has to drive off the
edge of the bridge there's a

00:04:07.430 --> 00:04:07.440
edge of the bridge there's a
 

00:04:07.440 --> 00:04:08.809
edge of the bridge there's a
philosophical Theory called

00:04:08.809 --> 00:04:08.819
philosophical Theory called
 

00:04:08.819 --> 00:04:11.119
philosophical Theory called
utilitarianism which has been around for

00:04:11.119 --> 00:04:11.129
utilitarianism which has been around for
 

00:04:11.129 --> 00:04:13.069
utilitarianism which has been around for
a couple of centuries at least that

00:04:13.069 --> 00:04:13.079
a couple of centuries at least that
 

00:04:13.079 --> 00:04:15.050
a couple of centuries at least that
would say that maximizing the good for

00:04:15.050 --> 00:04:15.060
would say that maximizing the good for
 

00:04:15.060 --> 00:04:17.839
would say that maximizing the good for
society is my car should kill me if I'm

00:04:17.839 --> 00:04:17.849
society is my car should kill me if I'm
 

00:04:17.849 --> 00:04:21.469
society is my car should kill me if I'm
not buying that car and so we have a

00:04:21.469 --> 00:04:21.479
not buying that car and so we have a
 

00:04:21.479 --> 00:04:23.480
not buying that car and so we have a
conundrum here I don't want to see

00:04:23.480 --> 00:04:23.490
conundrum here I don't want to see
 

00:04:23.490 --> 00:04:27.740
conundrum here I don't want to see
people buying a Ford instead of a Chevy

00:04:27.740 --> 00:04:27.750
people buying a Ford instead of a Chevy
 

00:04:27.750 --> 00:04:31.880
people buying a Ford instead of a Chevy
because des Ford's more likely to save

00:04:31.880 --> 00:04:31.890
because des Ford's more likely to save
 

00:04:31.890 --> 00:04:34.340
because des Ford's more likely to save
my life no matter what and the Chevy is

00:04:34.340 --> 00:04:34.350
my life no matter what and the Chevy is
 

00:04:34.350 --> 00:04:36.140
my life no matter what and the Chevy is
going to be a little more forgiving of

00:04:36.140 --> 00:04:36.150
going to be a little more forgiving of
 

00:04:36.150 --> 00:04:40.160
going to be a little more forgiving of
of that and and might kill me too to

00:04:40.160 --> 00:04:40.170
of that and and might kill me too to
 

00:04:40.170 --> 00:04:41.660
of that and and might kill me too to
save the lives of other people I don't

00:04:41.660 --> 00:04:41.670
save the lives of other people I don't
 

00:04:41.670 --> 00:04:43.430
save the lives of other people I don't
want that to be a selling point in cars

00:04:43.430 --> 00:04:43.440
want that to be a selling point in cars
 

00:04:43.440 --> 00:04:45.650
want that to be a selling point in cars
so we need to have a societal discussion

00:04:45.650 --> 00:04:45.660
so we need to have a societal discussion
 

00:04:45.660 --> 00:04:47.030
so we need to have a societal discussion
over how does this work

00:04:47.030 --> 00:04:47.040
over how does this work
 

00:04:47.040 --> 00:04:49.130
over how does this work
to demonstrate why that is so

00:04:49.130 --> 00:04:49.140
to demonstrate why that is so
 

00:04:49.140 --> 00:04:50.720
to demonstrate why that is so
interesting I'll just give it a twist on

00:04:50.720 --> 00:04:50.730
interesting I'll just give it a twist on
 

00:04:50.730 --> 00:04:51.380
interesting I'll just give it a twist on
what I said

00:04:51.380 --> 00:04:51.390
what I said
 

00:04:51.390 --> 00:04:52.820
what I said
right now we're talking about me buying

00:04:52.820 --> 00:04:52.830
right now we're talking about me buying
 

00:04:52.830 --> 00:04:55.520
right now we're talking about me buying
an autonomous car but let's suppose I'm

00:04:55.520 --> 00:04:55.530
an autonomous car but let's suppose I'm
 

00:04:55.530 --> 00:04:58.940
an autonomous car but let's suppose I'm
signed up for the great uber network in

00:04:58.940 --> 00:04:58.950
signed up for the great uber network in
 

00:04:58.950 --> 00:05:01.460
signed up for the great uber network in
the sky of the future and cars are

00:05:01.460 --> 00:05:01.470
the sky of the future and cars are
 

00:05:01.470 --> 00:05:04.070
the sky of the future and cars are
coming and whatever and it I don't own

00:05:04.070 --> 00:05:04.080
coming and whatever and it I don't own
 

00:05:04.080 --> 00:05:06.409
coming and whatever and it I don't own
that car now I feel a little bit

00:05:06.409 --> 00:05:06.419
that car now I feel a little bit
 

00:05:06.419 --> 00:05:09.260
that car now I feel a little bit
differently about it because it's not my

00:05:09.260 --> 00:05:09.270
differently about it because it's not my
 

00:05:09.270 --> 00:05:11.960
differently about it because it's not my
car I'm just like I'm getting on a train

00:05:11.960 --> 00:05:11.970
car I'm just like I'm getting on a train
 

00:05:11.970 --> 00:05:16.070
car I'm just like I'm getting on a train
we would never allow a train to the

00:05:16.070 --> 00:05:16.080
we would never allow a train to the
 

00:05:16.080 --> 00:05:17.930
we would never allow a train to the
people on the train to vote you know

00:05:17.930 --> 00:05:17.940
people on the train to vote you know
 

00:05:17.940 --> 00:05:19.640
people on the train to vote you know
like you know okay I love my car killed

00:05:19.640 --> 00:05:19.650
like you know okay I love my car killed
 

00:05:19.650 --> 00:05:21.740
like you know okay I love my car killed
and not you know to kill me and not that

00:05:21.740 --> 00:05:21.750
and not you know to kill me and not that
 

00:05:21.750 --> 00:05:24.350
and not you know to kill me and not that
one they're certain then it makes more

00:05:24.350 --> 00:05:24.360
one they're certain then it makes more
 

00:05:24.360 --> 00:05:27.500
one they're certain then it makes more
sense for the societal average interests

00:05:27.500 --> 00:05:27.510
sense for the societal average interests
 

00:05:27.510 --> 00:05:33.260
sense for the societal average interests
to to be operational so when I think

00:05:33.260 --> 00:05:33.270
to to be operational so when I think
 

00:05:33.270 --> 00:05:36.050
to to be operational so when I think
about this issue even the fact of who

00:05:36.050 --> 00:05:36.060
about this issue even the fact of who
 

00:05:36.060 --> 00:05:38.960
about this issue even the fact of who
owns the car changes my own moral

00:05:38.960 --> 00:05:38.970
owns the car changes my own moral
 

00:05:38.970 --> 00:05:41.240
owns the car changes my own moral
judgement about this particular kind of

00:05:41.240 --> 00:05:41.250
judgement about this particular kind of
 

00:05:41.250 --> 00:05:44.180
judgement about this particular kind of
an issue well we need to be able to take

00:05:44.180 --> 00:05:44.190
an issue well we need to be able to take
 

00:05:44.190 --> 00:05:45.980
an issue well we need to be able to take
these kinds of principles talk about

00:05:45.980 --> 00:05:45.990
these kinds of principles talk about
 

00:05:45.990 --> 00:05:49.360
these kinds of principles talk about
them vet them and put them into cars so

00:05:49.360 --> 00:05:49.370
them vet them and put them into cars so
 

00:05:49.370 --> 00:05:51.469
them vet them and put them into cars so
autonomous driving cars it's got I've

00:05:51.469 --> 00:05:51.479
autonomous driving cars it's got I've
 

00:05:51.479 --> 00:05:52.670
autonomous driving cars it's got I've
got a number of different issues that

00:05:52.670 --> 00:05:52.680
got a number of different issues that
 

00:05:52.680 --> 00:05:54.920
got a number of different issues that
are very very important now I've so far

00:05:54.920 --> 00:05:54.930
are very very important now I've so far
 

00:05:54.930 --> 00:05:56.500
are very very important now I've so far
I've just talked about life and death

00:05:56.500 --> 00:05:56.510
I've just talked about life and death
 

00:05:56.510 --> 00:05:59.570
I've just talked about life and death
but there's lots of shades of grey in

00:05:59.570 --> 00:05:59.580
but there's lots of shades of grey in
 

00:05:59.580 --> 00:06:01.340
but there's lots of shades of grey in
between that are really quite quite

00:06:01.340 --> 00:06:01.350
between that are really quite quite
 

00:06:01.350 --> 00:06:03.260
between that are really quite quite
different in fact I'm gonna make an

00:06:03.260 --> 00:06:03.270
different in fact I'm gonna make an
 

00:06:03.270 --> 00:06:05.330
different in fact I'm gonna make an
argument to you today that we're already

00:06:05.330 --> 00:06:05.340
argument to you today that we're already
 

00:06:05.340 --> 00:06:06.710
argument to you today that we're already
down this path and we haven't even

00:06:06.710 --> 00:06:06.720
down this path and we haven't even
 

00:06:06.720 --> 00:06:08.510
down this path and we haven't even
recognized yet for a very interesting

00:06:08.510 --> 00:06:08.520
recognized yet for a very interesting
 

00:06:08.520 --> 00:06:10.640
recognized yet for a very interesting
reason because in order to avoid

00:06:10.640 --> 00:06:10.650
reason because in order to avoid
 

00:06:10.650 --> 00:06:12.590
reason because in order to avoid
pointing out this problem the car

00:06:12.590 --> 00:06:12.600
pointing out this problem the car
 

00:06:12.600 --> 00:06:14.330
pointing out this problem the car
manufacturers do not talk about this as

00:06:14.330 --> 00:06:14.340
manufacturers do not talk about this as
 

00:06:14.340 --> 00:06:16.820
manufacturers do not talk about this as
artificial intelligence let me give you

00:06:16.820 --> 00:06:16.830
artificial intelligence let me give you
 

00:06:16.830 --> 00:06:21.370
artificial intelligence let me give you
an example a common function cars is ABS

00:06:21.370 --> 00:06:21.380
an example a common function cars is ABS
 

00:06:21.380 --> 00:06:24.620
an example a common function cars is ABS
DAC adaptive braking systems I think

00:06:24.620 --> 00:06:24.630
DAC adaptive braking systems I think
 

00:06:24.630 --> 00:06:27.050
DAC adaptive braking systems I think
it's what that stands for and what that

00:06:27.050 --> 00:06:27.060
it's what that stands for and what that
 

00:06:27.060 --> 00:06:28.730
it's what that stands for and what that
will do is if it can detect which it can

00:06:28.730 --> 00:06:28.740
will do is if it can detect which it can
 

00:06:28.740 --> 00:06:31.700
will do is if it can detect which it can
that you're about to skid it's going to

00:06:31.700 --> 00:06:31.710
that you're about to skid it's going to
 

00:06:31.710 --> 00:06:33.770
that you're about to skid it's going to
pump the brakes and to various things to

00:06:33.770 --> 00:06:33.780
pump the brakes and to various things to
 

00:06:33.780 --> 00:06:36.050
pump the brakes and to various things to
maintain control of the car and keep it

00:06:36.050 --> 00:06:36.060
maintain control of the car and keep it
 

00:06:36.060 --> 00:06:38.800
maintain control of the car and keep it
going in a particular direction okay now

00:06:38.800 --> 00:06:38.810
going in a particular direction okay now
 

00:06:38.810 --> 00:06:41.180
going in a particular direction okay now
what you might not know

00:06:41.180 --> 00:06:41.190
what you might not know
 

00:06:41.190 --> 00:06:45.320
what you might not know
is that abs in many cases on certain

00:06:45.320 --> 00:06:45.330
is that abs in many cases on certain
 

00:06:45.330 --> 00:06:47.230
is that abs in many cases on certain
surfaces has a longer stopping distance

00:06:47.230 --> 00:06:47.240
surfaces has a longer stopping distance
 

00:06:47.240 --> 00:06:49.730
surfaces has a longer stopping distance
then if you just jammed on the brakes

00:06:49.730 --> 00:06:49.740
then if you just jammed on the brakes
 

00:06:49.740 --> 00:06:52.700
then if you just jammed on the brakes
locked them in the car spun around so

00:06:52.700 --> 00:06:52.710
locked them in the car spun around so
 

00:06:52.710 --> 00:06:54.680
locked them in the car spun around so
imagine you're driving your car and oh

00:06:54.680 --> 00:06:54.690
imagine you're driving your car and oh
 

00:06:54.690 --> 00:06:56.000
imagine you're driving your car and oh
my god there's a kid in the middle of

00:06:56.000 --> 00:06:56.010
my god there's a kid in the middle of
 

00:06:56.010 --> 00:06:58.610
my god there's a kid in the middle of
the road and you you just want that car

00:06:58.610 --> 00:06:58.620
the road and you you just want that car
 

00:06:58.620 --> 00:07:00.890
the road and you you just want that car
to stop as quickly as it possible as you

00:07:00.890 --> 00:07:00.900
to stop as quickly as it possible as you
 

00:07:00.900 --> 00:07:03.620
to stop as quickly as it possible as you
can and you you slam on the brakes well

00:07:03.620 --> 00:07:03.630
can and you you slam on the brakes well
 

00:07:03.630 --> 00:07:05.870
can and you you slam on the brakes well
the car is going to prioritize keeping

00:07:05.870 --> 00:07:05.880
the car is going to prioritize keeping
 

00:07:05.880 --> 00:07:08.900
the car is going to prioritize keeping
going straight over running over that

00:07:08.900 --> 00:07:08.910
going straight over running over that
 

00:07:08.910 --> 00:07:12.020
going straight over running over that
kid in today's technology there are

00:07:12.020 --> 00:07:12.030
kid in today's technology there are
 

00:07:12.030 --> 00:07:14.090
kid in today's technology there are
circumstances in which that decision

00:07:14.090 --> 00:07:14.100
circumstances in which that decision
 

00:07:14.100 --> 00:07:16.070
circumstances in which that decision
which an engineer made a while back in

00:07:16.070 --> 00:07:16.080
which an engineer made a while back in
 

00:07:16.080 --> 00:07:17.600
which an engineer made a while back in
designing that system what I want to

00:07:17.600 --> 00:07:17.610
designing that system what I want to
 

00:07:17.610 --> 00:07:20.750
designing that system what I want to
keep the car stable you no longer have

00:07:20.750 --> 00:07:20.760
keep the car stable you no longer have
 

00:07:20.760 --> 00:07:22.820
keep the car stable you no longer have
the freedom to make the decision I don't

00:07:22.820 --> 00:07:22.830
the freedom to make the decision I don't
 

00:07:22.830 --> 00:07:24.590
the freedom to make the decision I don't
mind if the car spins out of control as

00:07:24.590 --> 00:07:24.600
mind if the car spins out of control as
 

00:07:24.600 --> 00:07:27.620
mind if the car spins out of control as
long as I miss that kid so now imagine

00:07:27.620 --> 00:07:27.630
long as I miss that kid so now imagine
 

00:07:27.630 --> 00:07:30.290
long as I miss that kid so now imagine
that the ABS function had been described

00:07:30.290 --> 00:07:30.300
that the ABS function had been described
 

00:07:30.300 --> 00:07:34.540
that the ABS function had been described
as we're simulating the actions of a

00:07:34.540 --> 00:07:34.550
as we're simulating the actions of a
 

00:07:34.550 --> 00:07:36.770
as we're simulating the actions of a
professional driver and we're taking

00:07:36.770 --> 00:07:36.780
professional driver and we're taking
 

00:07:36.780 --> 00:07:38.930
professional driver and we're taking
that judgment and we're programming it

00:07:38.930 --> 00:07:38.940
that judgment and we're programming it
 

00:07:38.940 --> 00:07:40.850
that judgment and we're programming it
to a machine using these advanced

00:07:40.850 --> 00:07:40.860
to a machine using these advanced
 

00:07:40.860 --> 00:07:42.950
to a machine using these advanced
artificial intelligence techniques so

00:07:42.950 --> 00:07:42.960
artificial intelligence techniques so
 

00:07:42.960 --> 00:07:45.290
artificial intelligence techniques so
that the car can keep under control the

00:07:45.290 --> 00:07:45.300
that the car can keep under control the
 

00:07:45.300 --> 00:07:47.870
that the car can keep under control the
same way a professional driver might

00:07:47.870 --> 00:07:47.880
same way a professional driver might
 

00:07:47.880 --> 00:07:49.520
same way a professional driver might
well we might have fell a little bit

00:07:49.520 --> 00:07:49.530
well we might have fell a little bit
 

00:07:49.530 --> 00:07:51.170
well we might have fell a little bit
differently about that if I presented

00:07:51.170 --> 00:07:51.180
differently about that if I presented
 

00:07:51.180 --> 00:07:52.940
differently about that if I presented
you with that example and we were

00:07:52.940 --> 00:07:52.950
you with that example and we were
 

00:07:52.950 --> 00:07:54.380
you with that example and we were
talking about this as an AI technology

00:07:54.380 --> 00:07:54.390
talking about this as an AI technology
 

00:07:54.390 --> 00:07:57.409
talking about this as an AI technology
but by saying it's simply a function of

00:07:57.409 --> 00:07:57.419
but by saying it's simply a function of
 

00:07:57.419 --> 00:08:00.500
but by saying it's simply a function of
the car and it's just like it's like

00:08:00.500 --> 00:08:00.510
the car and it's just like it's like
 

00:08:00.510 --> 00:08:01.640
the car and it's just like it's like
every other phone you know it's like the

00:08:01.640 --> 00:08:01.650
every other phone you know it's like the
 

00:08:01.650 --> 00:08:03.860
every other phone you know it's like the
turn signals and everything else this

00:08:03.860 --> 00:08:03.870
turn signals and everything else this
 

00:08:03.870 --> 00:08:05.990
turn signals and everything else this
issue never really got raised and never

00:08:05.990 --> 00:08:06.000
issue never really got raised and never
 

00:08:06.000 --> 00:08:08.300
issue never really got raised and never
really got vetted but as we look to the

00:08:08.300 --> 00:08:08.310
really got vetted but as we look to the
 

00:08:08.310 --> 00:08:09.770
really got vetted but as we look to the
future of autonomous driving it's going

00:08:09.770 --> 00:08:09.780
future of autonomous driving it's going
 

00:08:09.780 --> 00:08:12.980
future of autonomous driving it's going
to be a problem let me move on there too

00:08:12.980 --> 00:08:12.990
to be a problem let me move on there too
 

00:08:12.990 --> 00:08:18.470
to be a problem let me move on there too
less less severe situations you're in

00:08:18.470 --> 00:08:18.480
less less severe situations you're in
 

00:08:18.480 --> 00:08:20.810
less less severe situations you're in
your autonomous car and it pulls you're

00:08:20.810 --> 00:08:20.820
your autonomous car and it pulls you're
 

00:08:20.820 --> 00:08:22.430
your autonomous car and it pulls you're
on a two-lane Street this happens all

00:08:22.430 --> 00:08:22.440
on a two-lane Street this happens all
 

00:08:22.440 --> 00:08:24.800
on a two-lane Street this happens all
the time there's a UPS truck right in

00:08:24.800 --> 00:08:24.810
the time there's a UPS truck right in
 

00:08:24.810 --> 00:08:26.420
the time there's a UPS truck right in
front of you see if it's come to a stop

00:08:26.420 --> 00:08:26.430
front of you see if it's come to a stop
 

00:08:26.430 --> 00:08:28.340
front of you see if it's come to a stop
the guy jumps out he opens up the back

00:08:28.340 --> 00:08:28.350
the guy jumps out he opens up the back
 

00:08:28.350 --> 00:08:29.840
the guy jumps out he opens up the back
he grabs a package that starts hitting

00:08:29.840 --> 00:08:29.850
he grabs a package that starts hitting
 

00:08:29.850 --> 00:08:33.709
he grabs a package that starts hitting
off now you as a driver are permitted a

00:08:33.709 --> 00:08:33.719
off now you as a driver are permitted a
 

00:08:33.719 --> 00:08:35.600
off now you as a driver are permitted a
certain amount of latitude in how you

00:08:35.600 --> 00:08:35.610
certain amount of latitude in how you
 

00:08:35.610 --> 00:08:38.149
certain amount of latitude in how you
behave and what we what would you do you

00:08:38.149 --> 00:08:38.159
behave and what we what would you do you
 

00:08:38.159 --> 00:08:38.899
behave and what we what would you do you
look around it

00:08:38.899 --> 00:08:38.909
look around it
 

00:08:38.909 --> 00:08:40.850
look around it
you'd go across the double yellow line

00:08:40.850 --> 00:08:40.860
you'd go across the double yellow line
 

00:08:40.860 --> 00:08:43.610
you'd go across the double yellow line
and you pass that UPS truck it's

00:08:43.610 --> 00:08:43.620
and you pass that UPS truck it's
 

00:08:43.620 --> 00:08:46.040
and you pass that UPS truck it's
perfectly acceptable behavior may I

00:08:46.040 --> 00:08:46.050
perfectly acceptable behavior may I
 

00:08:46.050 --> 00:08:47.960
perfectly acceptable behavior may I
point out you're breaking a rule you're

00:08:47.960 --> 00:08:47.970
point out you're breaking a rule you're
 

00:08:47.970 --> 00:08:50.329
point out you're breaking a rule you're
crossing a double yellow line if we were

00:08:50.329 --> 00:08:50.339
crossing a double yellow line if we were
 

00:08:50.339 --> 00:08:53.400
crossing a double yellow line if we were
to program our cars simply to say

00:08:53.400 --> 00:08:53.410
to program our cars simply to say
 

00:08:53.410 --> 00:08:55.080
to program our cars simply to say
you're never supposed to cross the

00:08:55.080 --> 00:08:55.090
you're never supposed to cross the
 

00:08:55.090 --> 00:08:57.000
you're never supposed to cross the
double yellow line that cars gonna sit

00:08:57.000 --> 00:08:57.010
double yellow line that cars gonna sit
 

00:08:57.010 --> 00:08:58.950
double yellow line that cars gonna sit
there until the guy's done which might

00:08:58.950 --> 00:08:58.960
there until the guy's done which might
 

00:08:58.960 --> 00:09:00.570
there until the guy's done which might
be a very long time if he's gone to his

00:09:00.570 --> 00:09:00.580
be a very long time if he's gone to his
 

00:09:00.580 --> 00:09:05.040
be a very long time if he's gone to his
lunch so the kinds of latitude that we

00:09:05.040 --> 00:09:05.050
lunch so the kinds of latitude that we
 

00:09:05.050 --> 00:09:08.280
lunch so the kinds of latitude that we
permit people in their behavior in a lot

00:09:08.280 --> 00:09:08.290
permit people in their behavior in a lot
 

00:09:08.290 --> 00:09:09.660
permit people in their behavior in a lot
of these circumstances to be able to

00:09:09.660 --> 00:09:09.670
of these circumstances to be able to
 

00:09:09.670 --> 00:09:11.760
of these circumstances to be able to
break rules or bend rules in a very

00:09:11.760 --> 00:09:11.770
break rules or bend rules in a very
 

00:09:11.770 --> 00:09:15.480
break rules or bend rules in a very
appropriate way we need to talk about

00:09:15.480 --> 00:09:15.490
appropriate way we need to talk about
 

00:09:15.490 --> 00:09:17.970
appropriate way we need to talk about
whether or not it's okay for a car to

00:09:17.970 --> 00:09:17.980
whether or not it's okay for a car to
 

00:09:17.980 --> 00:09:21.000
whether or not it's okay for a car to
engage in that kind of behavior let me

00:09:21.000 --> 00:09:21.010
engage in that kind of behavior let me
 

00:09:21.010 --> 00:09:23.520
engage in that kind of behavior let me
give you another one what would you feel

00:09:23.520 --> 00:09:23.530
give you another one what would you feel
 

00:09:23.530 --> 00:09:24.900
give you another one what would you feel
if you went down the movie theater and

00:09:24.900 --> 00:09:24.910
if you went down the movie theater and
 

00:09:24.910 --> 00:09:27.180
if you went down the movie theater and
you're the scarcity it's available all

00:09:27.180 --> 00:09:27.190
you're the scarcity it's available all
 

00:09:27.190 --> 00:09:28.710
you're the scarcity it's available all
of a sudden you find this sixteen robots

00:09:28.710 --> 00:09:28.720
of a sudden you find this sixteen robots
 

00:09:28.720 --> 00:09:31.050
of a sudden you find this sixteen robots
in line in front of you and you're at

00:09:31.050 --> 00:09:31.060
in line in front of you and you're at
 

00:09:31.060 --> 00:09:31.800
in line in front of you and you're at
the back of the line

00:09:31.800 --> 00:09:31.810
the back of the line
 

00:09:31.810 --> 00:09:33.420
the back of the line
my reaction be hey wait a minute that's

00:09:33.420 --> 00:09:33.430
my reaction be hey wait a minute that's
 

00:09:33.430 --> 00:09:35.820
my reaction be hey wait a minute that's
not fair why do we have sixteen robots

00:09:35.820 --> 00:09:35.830
not fair why do we have sixteen robots
 

00:09:35.830 --> 00:09:37.170
not fair why do we have sixteen robots
that are gonna pick up tickets for

00:09:37.170 --> 00:09:37.180
that are gonna pick up tickets for
 

00:09:37.180 --> 00:09:39.720
that are gonna pick up tickets for
whoever owns the robots I'm here you

00:09:39.720 --> 00:09:39.730
whoever owns the robots I'm here you
 

00:09:39.730 --> 00:09:41.370
whoever owns the robots I'm here you
know we should prioritize me over those

00:09:41.370 --> 00:09:41.380
know we should prioritize me over those
 

00:09:41.380 --> 00:09:43.830
know we should prioritize me over those
robots I think when that begins to

00:09:43.830 --> 00:09:43.840
robots I think when that begins to
 

00:09:43.840 --> 00:09:46.860
robots I think when that begins to
happen in practice people will be up in

00:09:46.860 --> 00:09:46.870
happen in practice people will be up in
 

00:09:46.870 --> 00:09:49.470
happen in practice people will be up in
arms because they can see what is

00:09:49.470 --> 00:09:49.480
arms because they can see what is
 

00:09:49.480 --> 00:09:51.300
arms because they can see what is
actually happening but that same

00:09:51.300 --> 00:09:51.310
actually happening but that same
 

00:09:51.310 --> 00:09:54.000
actually happening but that same
situation is already happening today if

00:09:54.000 --> 00:09:54.010
situation is already happening today if
 

00:09:54.010 --> 00:09:57.090
situation is already happening today if
you try to get a ticket to Billy Joel at

00:09:57.090 --> 00:09:57.100
you try to get a ticket to Billy Joel at
 

00:09:57.100 --> 00:10:01.800
you try to get a ticket to Billy Joel at
Madison Square Garden scalpers run

00:10:01.800 --> 00:10:01.810
Madison Square Garden scalpers run
 

00:10:01.810 --> 00:10:04.680
Madison Square Garden scalpers run
programs that can snap up all of those

00:10:04.680 --> 00:10:04.690
programs that can snap up all of those
 

00:10:04.690 --> 00:10:07.500
programs that can snap up all of those
tickets in a matter of seconds leaving

00:10:07.500 --> 00:10:07.510
tickets in a matter of seconds leaving
 

00:10:07.510 --> 00:10:08.670
tickets in a matter of seconds leaving
all the humans who are sitting there

00:10:08.670 --> 00:10:08.680
all the humans who are sitting there
 

00:10:08.680 --> 00:10:11.490
all the humans who are sitting there
trying to press the The Return button or

00:10:11.490 --> 00:10:11.500
trying to press the The Return button or
 

00:10:11.500 --> 00:10:14.300
trying to press the The Return button or
god forbid fill out the little CAPTCHA

00:10:14.300 --> 00:10:14.310
god forbid fill out the little CAPTCHA
 

00:10:14.310 --> 00:10:17.880
god forbid fill out the little CAPTCHA
there they don't get the stuff so it's

00:10:17.880 --> 00:10:17.890
there they don't get the stuff so it's
 

00:10:17.890 --> 00:10:19.320
there they don't get the stuff so it's
exactly the same situation

00:10:19.320 --> 00:10:19.330
exactly the same situation
 

00:10:19.330 --> 00:10:22.830
exactly the same situation
the robots are who are owned and working

00:10:22.830 --> 00:10:22.840
the robots are who are owned and working
 

00:10:22.840 --> 00:10:25.530
the robots are who are owned and working
for somebody else are grabbing an asset

00:10:25.530 --> 00:10:25.540
for somebody else are grabbing an asset
 

00:10:25.540 --> 00:10:27.840
for somebody else are grabbing an asset
before you have an opportunity or a fair

00:10:27.840 --> 00:10:27.850
before you have an opportunity or a fair
 

00:10:27.850 --> 00:10:30.510
before you have an opportunity or a fair
chance to acquire that asset to get that

00:10:30.510 --> 00:10:30.520
chance to acquire that asset to get that
 

00:10:30.520 --> 00:10:33.030
chance to acquire that asset to get that
particular ticket you know and if you

00:10:33.030 --> 00:10:33.040
particular ticket you know and if you
 

00:10:33.040 --> 00:10:34.650
particular ticket you know and if you
could see that people be really mad

00:10:34.650 --> 00:10:34.660
could see that people be really mad
 

00:10:34.660 --> 00:10:37.110
could see that people be really mad
today but it's invisible because all

00:10:37.110 --> 00:10:37.120
today but it's invisible because all
 

00:10:37.120 --> 00:10:39.750
today but it's invisible because all
this stuff is in the cloud so we're

00:10:39.750 --> 00:10:39.760
this stuff is in the cloud so we're
 

00:10:39.760 --> 00:10:41.160
this stuff is in the cloud so we're
already facing a lot of these same

00:10:41.160 --> 00:10:41.170
already facing a lot of these same
 

00:10:41.170 --> 00:10:43.860
already facing a lot of these same
ethical and social issues but they're

00:10:43.860 --> 00:10:43.870
ethical and social issues but they're
 

00:10:43.870 --> 00:10:45.660
ethical and social issues but they're
they're not as visible as they need to

00:10:45.660 --> 00:10:45.670
they're not as visible as they need to
 

00:10:45.670 --> 00:10:47.670
they're not as visible as they need to
be for us to have a meaningful public

00:10:47.670 --> 00:10:47.680
be for us to have a meaningful public
 

00:10:47.680 --> 00:10:52.080
be for us to have a meaningful public
discussion about these particular topics

