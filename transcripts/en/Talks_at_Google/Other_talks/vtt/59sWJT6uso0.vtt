WEBVTT
Kind: captions
Language: en

00:00:01.700 --> 00:00:03.120
SPEAKER 1: Hello, everyone.

00:00:03.120 --> 00:00:07.650
Thanks for coming here and for
your interest in this talk.

00:00:07.650 --> 00:00:10.300
As announced via
e-mail, today we

00:00:10.300 --> 00:00:15.920
have as guest at Google Mr. Phil
Zimmermann, the creator of PGP

00:00:15.920 --> 00:00:20.720
and co-creator of Silent
Circle and Silent Phone.

00:00:20.720 --> 00:00:21.220
Hi, Phil.

00:00:21.220 --> 00:00:21.990
Welcome to Google.

00:00:21.990 --> 00:00:23.630
How are you?

00:00:23.630 --> 00:00:24.720
PHIL ZIMMERMANN: I'm good.

00:00:24.720 --> 00:00:25.219
Yeah.

00:00:28.121 --> 00:00:29.620
SPEAKER 1: How we
got Phil to Google

00:00:29.620 --> 00:00:34.430
was that Google gave him an
award for his contribution

00:00:34.430 --> 00:00:37.550
to security, and
recently, as he's involved

00:00:37.550 --> 00:00:42.670
with researching
communication security.

00:00:42.670 --> 00:00:44.810
And we have the end to
end encryption of WhatsApp

00:00:44.810 --> 00:00:49.350
and the recently announced
Google products in this area.

00:00:49.350 --> 00:00:51.500
He was very kind
to accept an offer

00:00:51.500 --> 00:00:55.910
to have a talk about his
recent research in this area.

00:00:55.910 --> 00:01:00.300
And I'll let him present
more of his talk.

00:01:00.300 --> 00:01:03.350
Just so you know, there
are people in this room.

00:01:03.350 --> 00:01:06.680
There are people watching
the transmission live.

00:01:06.680 --> 00:01:09.550
And we'll have
questions from the room

00:01:09.550 --> 00:01:11.342
as well as in [INAUDIBLE]
and are prepared.

00:01:11.342 --> 00:01:12.175
PHIL ZIMMERMANN: OK.

00:01:12.175 --> 00:01:14.010
SPEAKER 1: And ask at
the end of the talk.

00:01:14.010 --> 00:01:14.470
PHIL ZIMMERMANN:
Well, I would assume

00:01:14.470 --> 00:01:16.010
there's not too
many in California

00:01:16.010 --> 00:01:17.779
because it's too early.

00:01:17.779 --> 00:01:19.195
SPEAKER 1: You
would be surprised.

00:01:23.630 --> 00:01:29.230
PHIL ZIMMERMANN: Well, you know,
normally, for most audiences,

00:01:29.230 --> 00:01:33.040
I ask for a show of hands
for people who are engineers.

00:01:33.040 --> 00:01:34.360
[LAUGHTER]

00:01:35.280 --> 00:01:37.300
When I look at
this audience here,

00:01:37.300 --> 00:01:41.860
I absolutely do not
have to ask this.

00:01:41.860 --> 00:01:44.746
The visual signature
is so distinct that--

00:01:44.746 --> 00:01:47.126
[LAUGHTER]

00:01:48.080 --> 00:01:50.330
--that there is
absolutely no ambiguity.

00:01:50.330 --> 00:01:53.900
In fact, I'm not sure that
there is a single non-engineer

00:01:53.900 --> 00:01:56.820
in the room.

00:01:56.820 --> 00:01:59.140
In fact, actually it's
even at this level

00:01:59.140 --> 00:02:04.790
of pharmaceutical purity
of engineer density,

00:02:04.790 --> 00:02:07.080
it's to the point where
I can sort of gauge

00:02:07.080 --> 00:02:13.030
the skill level of software
engineers by appearance.

00:02:13.030 --> 00:02:14.980
You know?

00:02:14.980 --> 00:02:22.670
So all right, so this is the
most pure sample of engineers

00:02:22.670 --> 00:02:24.450
I've spoken to in
many, many years.

00:02:24.450 --> 00:02:28.200
So I guess I can be as
geeky as I want to be.

00:02:31.920 --> 00:02:39.640
So well, I guess I'm best known
for my work thousands of years

00:02:39.640 --> 00:02:41.960
ago for developing the PGP.

00:02:41.960 --> 00:02:45.473
But that was a
very long time ago.

00:02:45.473 --> 00:02:48.440
For the past more
than a decade, I've

00:02:48.440 --> 00:02:52.860
been focusing all on Secure
VoIP, and more recently

00:02:52.860 --> 00:02:55.710
on secure instant messaging.

00:02:55.710 --> 00:02:59.050
But secure VoIP is far more
interesting than secure e-mail.

00:02:59.050 --> 00:03:01.440
I had to do secure e-mail first.

00:03:01.440 --> 00:03:06.520
Because in the 1990s,
nobody had broadband.

00:03:06.520 --> 00:03:10.064
And without
broadband, there's not

00:03:10.064 --> 00:03:12.230
much of a market for secure
VoIP because there's not

00:03:12.230 --> 00:03:15.390
much of a market for VoIP.

00:03:15.390 --> 00:03:16.470
So I had to wait.

00:03:16.470 --> 00:03:19.400
And I had to do
secure e-mail first.

00:03:19.400 --> 00:03:21.250
So even though I
got better known

00:03:21.250 --> 00:03:24.770
for my work in secure e-mail,
what I actually wanted to do

00:03:24.770 --> 00:03:26.070
was secure VoIP.

00:03:26.070 --> 00:03:29.810
So I just had to wait for
the enabling technologies

00:03:29.810 --> 00:03:30.560
to come into play.

00:03:39.410 --> 00:03:41.540
So for the past decade--
for more than a decade--

00:03:41.540 --> 00:03:44.180
I've been working
100% on secure VoIP.

00:03:44.180 --> 00:03:48.880
The first time I did this
was 1995 with PGP Phone.

00:03:48.880 --> 00:03:50.830
But at that time, I
was just using a modem

00:03:50.830 --> 00:03:51.940
to talk to another modem.

00:03:51.940 --> 00:03:56.550
So it was two PCs talking
through dial up modems.

00:03:56.550 --> 00:03:58.660
And it wasn't even
internet protocol.

00:03:58.660 --> 00:03:59.875
It was just modem to modem.

00:04:02.610 --> 00:04:07.920
It was kind of like the STU-III
or the other secure telephone

00:04:07.920 --> 00:04:12.590
devices that existed at the type
that used only the phone lines.

00:04:12.590 --> 00:04:18.180
But anyway, so now that we have
these enabling technologies

00:04:18.180 --> 00:04:21.180
of broadband and also VoIP
standards like the SIP

00:04:21.180 --> 00:04:27.510
standard in and RTP,
I've been doing that.

00:04:27.510 --> 00:04:33.920
I started out with Zfone
about 10 years ago.

00:04:33.920 --> 00:04:38.420
And today, I have a
product called Silent Phone

00:04:38.420 --> 00:04:39.860
from Silent Circle.

00:04:39.860 --> 00:04:43.140
That's the company that I
started about four and a half

00:04:43.140 --> 00:04:43.700
years ago.

00:04:47.250 --> 00:04:52.046
But we didn't get a
huge network effect.

00:04:52.046 --> 00:04:53.670
Because we pursued
a different business

00:04:53.670 --> 00:04:58.690
model where we charged
for our product.

00:04:58.690 --> 00:05:00.440
And I kind of regret that now.

00:05:00.440 --> 00:05:05.320
Because I can see
that just recently,

00:05:05.320 --> 00:05:07.440
WhatsApp got a
billion users with end

00:05:07.440 --> 00:05:10.630
to end encryption immediately.

00:05:10.630 --> 00:05:13.880
Because I mean, they ramped
up the network effect.

00:05:13.880 --> 00:05:17.050
And then suddenly,
turned on encryption

00:05:17.050 --> 00:05:18.740
when they reached
a billion users.

00:05:18.740 --> 00:05:22.950
So I thought that was
a pretty effective way

00:05:22.950 --> 00:05:27.860
to bring a billion users
into secure communications.

00:05:27.860 --> 00:05:31.340
But anyway, what
I'd like to talk

00:05:31.340 --> 00:05:36.480
with you about today
is how do you protect

00:05:36.480 --> 00:05:39.390
your users from yourself?

00:05:39.390 --> 00:05:42.030
If you're a company
like Apple and you

00:05:42.030 --> 00:05:46.120
have products that encrypt
things like the encryption

00:05:46.120 --> 00:05:49.020
that iPhones have,
and the FBI comes in

00:05:49.020 --> 00:05:55.140
asks you to defeat
your own encryption,

00:05:55.140 --> 00:05:57.610
what can you do to be
able to say to them,

00:05:57.610 --> 00:05:59.620
well sorry, I can't do that?

00:05:59.620 --> 00:06:04.020
Well, Tim Cook had to
fight them in court.

00:06:04.020 --> 00:06:05.900
But wouldn't it be
easier if he could just

00:06:05.900 --> 00:06:09.700
say, well, we just don't
have the means of doing that.

00:06:09.700 --> 00:06:12.560
And that would be easier
if he could do that.

00:06:12.560 --> 00:06:15.220
And I suspect that
Apple is now working

00:06:15.220 --> 00:06:19.130
on trying to improve their
security to the point

00:06:19.130 --> 00:06:22.410
where the next time someone asks
them to do that, they can say,

00:06:22.410 --> 00:06:26.220
sorry, no can do.

00:06:26.220 --> 00:06:28.620
And I think that
it would be helpful

00:06:28.620 --> 00:06:32.680
if all the big companies
that make products that

00:06:32.680 --> 00:06:38.740
do encryption could do that
also like Google, like Facebook,

00:06:38.740 --> 00:06:43.980
like any other large
scale company that

00:06:43.980 --> 00:06:45.070
has a billion users.

00:06:48.200 --> 00:06:54.610
We have a society of
pervasive surveillance.

00:06:54.610 --> 00:06:55.840
We always knew that.

00:06:55.840 --> 00:06:58.890
I mean, security
people knew that.

00:06:58.890 --> 00:07:02.780
But we didn't know it was
quite as breathtakingly

00:07:02.780 --> 00:07:07.400
sweeping in its scope until
the Snowden revelations.

00:07:07.400 --> 00:07:11.980
And now, since the
Snowden revelations,

00:07:11.980 --> 00:07:14.820
everybody's been trying
to up their game.

00:07:14.820 --> 00:07:17.360
Standards bodies are
trying to up their game.

00:07:17.360 --> 00:07:22.480
The IETF is trying to
deprecate old security, all

00:07:22.480 --> 00:07:29.690
the old crypto suites,
trying to make standards

00:07:29.690 --> 00:07:32.510
for a world of
pervasive surveillance,

00:07:32.510 --> 00:07:35.090
how to defend
yourself against that.

00:07:35.090 --> 00:07:43.310
NIST is trying to recover
from the humiliation they

00:07:43.310 --> 00:07:48.540
had to endure because of the
random number generator that

00:07:48.540 --> 00:07:52.985
was handed to them by NSA-- the
not-so-random number generator.

00:07:55.870 --> 00:08:01.930
And you know, I mean NIST crypto
standards are really very good.

00:08:01.930 --> 00:08:07.630
If you sit down and read their
SP 800 series of publications,

00:08:07.630 --> 00:08:09.880
they're just
absolutely excellent.

00:08:09.880 --> 00:08:12.940
You just had that one
embarrassing problem.

00:08:12.940 --> 00:08:14.930
And they've gotten rid of it.

00:08:14.930 --> 00:08:17.910
But everybody's trying
to make improvements.

00:08:17.910 --> 00:08:20.190
And Apple's been
making improvements.

00:08:20.190 --> 00:08:23.590
Google started
encrypting their links

00:08:23.590 --> 00:08:24.960
between their data centers.

00:08:24.960 --> 00:08:28.000
I'm absolutely horrified that
you guys weren't doing that

00:08:28.000 --> 00:08:30.430
already.

00:08:30.430 --> 00:08:33.190
What were you thinking
that you didn't do that?

00:08:33.190 --> 00:08:35.440
So you should be embarrassed
along with everyone else,

00:08:35.440 --> 00:08:35.939
right?

00:08:39.220 --> 00:08:44.690
But you know, when I first
started working on secure VoIP,

00:08:44.690 --> 00:08:47.970
I just assumed that you cannot
trust the phone company.

00:08:47.970 --> 00:08:54.000
And so I did this protocol that
negotiates its keys end to end

00:08:54.000 --> 00:08:57.040
and absolutely does not
trust the phone company.

00:08:57.040 --> 00:08:58.420
And when I say
the phone company,

00:08:58.420 --> 00:09:04.087
I mean the servers, the
service provider, the servers.

00:09:04.087 --> 00:09:06.670
The servers are not involved in
the cryptographic negotiation.

00:09:10.020 --> 00:09:15.110
Now, the way I do it is I do
an ephemeral Diffie Hellman

00:09:15.110 --> 00:09:17.270
exchange.

00:09:17.270 --> 00:09:25.850
And then I derive something to
display on the screen that's

00:09:25.850 --> 00:09:27.880
derived from the session key.

00:09:27.880 --> 00:09:29.670
And then I have the
two parties compare

00:09:29.670 --> 00:09:32.260
what they see on the screen
to see if it matches.

00:09:32.260 --> 00:09:34.760
If it matches, the
session keys are the same.

00:09:34.760 --> 00:09:36.140
If the session
keys are the same,

00:09:36.140 --> 00:09:39.200
then that means there
is no man in the middle.

00:09:39.200 --> 00:09:41.070
That's a good thing.

00:09:41.070 --> 00:09:50.600
All the complexities of PKI, all
that work that we put into PKI

00:09:50.600 --> 00:09:52.760
is to prevent a man
in the middle attack.

00:09:52.760 --> 00:09:55.710
And yet, PKI has
done very poorly

00:09:55.710 --> 00:10:01.950
at this over the
past like 20 years.

00:10:01.950 --> 00:10:07.580
PKI has just had a
bad track record.

00:10:07.580 --> 00:10:11.450
The most spectacular
failure was--

00:10:11.450 --> 00:10:13.470
there's been a number of
spectacular failures--

00:10:13.470 --> 00:10:15.230
but the most
spectacular of them was

00:10:15.230 --> 00:10:19.260
the one with the
Iranian hackers hacking

00:10:19.260 --> 00:10:22.160
into a Dutch
certificate authority

00:10:22.160 --> 00:10:27.110
and stealing their
signing key that could

00:10:27.110 --> 00:10:30.050
create credentials for anyone.

00:10:30.050 --> 00:10:35.280
And the public key for
that certificate authority

00:10:35.280 --> 00:10:39.080
was baked into
everyone's browsers.

00:10:39.080 --> 00:10:43.180
And the hacker that did that
forged hundreds of certificates

00:10:43.180 --> 00:10:46.330
for Gmail, for Yahoo!

00:10:46.330 --> 00:10:54.190
Mail, for Facebook, for
government agencies,

00:10:54.190 --> 00:10:56.560
and handed off all
these credentials

00:10:56.560 --> 00:11:00.330
to the Iranian government who
then used them to perform man

00:11:00.330 --> 00:11:04.950
in the middle attacks
on Iranian dissidents

00:11:04.950 --> 00:11:09.380
and arrested so many of
them and put them in prison.

00:11:09.380 --> 00:11:14.120
So if you wanted to try to
write just a fictional novel

00:11:14.120 --> 00:11:20.460
of the absolute worst case
of what is the theoretically

00:11:20.460 --> 00:11:24.100
worst possible failure of a
public key infrastructure,

00:11:24.100 --> 00:11:27.650
that would have to be it.

00:11:27.650 --> 00:11:37.660
So there's been a lot of effort
to try to reform PKI, centrally

00:11:37.660 --> 00:11:39.370
manage PKI.

00:11:39.370 --> 00:11:40.480
For example, certificate.

00:11:40.480 --> 00:11:44.960
Transparency seems to
be a big improvement.

00:11:44.960 --> 00:11:49.840
But it still depends on
the certificate authority

00:11:49.840 --> 00:11:52.310
not becoming evil.

00:11:52.310 --> 00:11:55.130
It does protect against
someone stealing the keys

00:11:55.130 --> 00:11:57.519
and making unauthorized
certificates.

00:11:57.519 --> 00:11:59.310
But what if they're
authorized certificates

00:11:59.310 --> 00:12:01.690
that are just lying?

00:12:01.690 --> 00:12:06.650
What if governments could compel
certificate authorities to lie?

00:12:06.650 --> 00:12:09.510
What can you do to
reduce the dependency

00:12:09.510 --> 00:12:11.200
on certificate authorities?

00:12:11.200 --> 00:12:15.760
Well, what I did with
my protocol, ZRTP,

00:12:15.760 --> 00:12:18.310
was to make it so it just
doesn't use a PKI at all.

00:12:18.310 --> 00:12:21.780
And this thing about displaying
a hash of the session key

00:12:21.780 --> 00:12:24.190
will work for a
VoIP application.

00:12:24.190 --> 00:12:28.820
Because you're already
speaking-- it's a human speech

00:12:28.820 --> 00:12:31.420
encryption product, right?

00:12:31.420 --> 00:12:34.340
So you're talking to
another human being.

00:12:34.340 --> 00:12:37.680
So why not use the humans,
drag the human brain

00:12:37.680 --> 00:12:43.840
into the protocol,
100 trillion synapses

00:12:43.840 --> 00:12:46.480
dragged into the protocol.

00:12:46.480 --> 00:12:48.750
Instead of relying on just
a little ARM processor,

00:12:48.750 --> 00:12:51.250
you've got 100 trillion
synapses on each end

00:12:51.250 --> 00:12:53.750
that participate
in a calculation

00:12:53.750 --> 00:12:56.224
by listening to the
other person tell you

00:12:56.224 --> 00:12:57.515
what's displayed on the screen.

00:13:00.730 --> 00:13:04.760
We don't have to do
a fingerprint compare

00:13:04.760 --> 00:13:08.720
like I'm sure that many of
you have seen PGP key signing

00:13:08.720 --> 00:13:11.340
parties.

00:13:11.340 --> 00:13:13.490
Remember what I said
about theoretical limits

00:13:13.490 --> 00:13:16.140
of geekiness?

00:13:16.140 --> 00:13:22.620
The frontier of geekiness can
be found at PGP key signing

00:13:22.620 --> 00:13:23.210
parties.

00:13:23.210 --> 00:13:25.160
It's kind of right
up there, you know?

00:13:30.190 --> 00:13:35.860
But you can't get people to
compare full size fingerprints

00:13:35.860 --> 00:13:37.360
on a phone call.

00:13:37.360 --> 00:13:39.380
Nobody would ever do it.

00:13:39.380 --> 00:13:44.490
So I made it so that the amount
of material you have to compare

00:13:44.490 --> 00:13:46.360
is just two bytes.

00:13:46.360 --> 00:13:48.940
And I use the PGP word list.

00:13:48.940 --> 00:13:53.650
The PGP fingerprints can
be displayed in hexadecimal

00:13:53.650 --> 00:13:55.310
or using the word list.

00:13:55.310 --> 00:14:00.540
And I used that same word
list for displaying on Zfone

00:14:00.540 --> 00:14:04.730
originally, and now-- actually,
PGP Phone did it, and then

00:14:04.730 --> 00:14:07.280
Zfone, and now Silent Phone.

00:14:07.280 --> 00:14:11.360
And it's part of
the ZRTP standard.

00:14:11.360 --> 00:14:13.140
So you compare two words.

00:14:13.140 --> 00:14:15.150
And if they match, you're good.

00:14:15.150 --> 00:14:17.530
And the protocol makes
it possible to do this

00:14:17.530 --> 00:14:23.110
by allowing you to use a short
truncated hash because it

00:14:23.110 --> 00:14:26.400
does hash commitment
in the protocol.

00:14:26.400 --> 00:14:29.130
Instead of just truncating
the hash of the session keys,

00:14:29.130 --> 00:14:32.340
it makes it so that
it's possible to use

00:14:32.340 --> 00:14:35.560
a truncated hash without
a birthday attack

00:14:35.560 --> 00:14:38.830
by a highly resourceful
attacker that

00:14:38.830 --> 00:14:42.620
could sit there and perform a
lot of parallel calculations

00:14:42.620 --> 00:14:46.820
to try to force a match of
the first 16 bits of the hash.

00:14:46.820 --> 00:14:49.640
You put him in a position
where he only gets one guess.

00:14:49.640 --> 00:14:51.180
He can only do one.

00:14:51.180 --> 00:14:53.530
He cant' do trial calculations.

00:14:53.530 --> 00:14:56.440
You make it so that when you
send the public component

00:14:56.440 --> 00:14:58.432
of the Diffie
Hellman calculation,

00:14:58.432 --> 00:14:59.640
you don't send it right away.

00:14:59.640 --> 00:15:01.680
You send a hash of it first.

00:15:01.680 --> 00:15:03.350
And then you get the
other party to send

00:15:03.350 --> 00:15:07.280
his public component of the
Diffie Hellman calculation

00:15:07.280 --> 00:15:08.250
after you get that.

00:15:08.250 --> 00:15:11.370
Then you finally reveal your
public component, the one

00:15:11.370 --> 00:15:12.980
that you hashed first.

00:15:12.980 --> 00:15:16.075
He gets it, compares it with
the hash, and caches it again.

00:15:16.075 --> 00:15:19.140
If it matches, then he uses it.

00:15:19.140 --> 00:15:21.910
And by doing it that
way, you put the guy

00:15:21.910 --> 00:15:24.720
in the middle in a
position where he can't

00:15:24.720 --> 00:15:26.880
do a whole lot of guesses.

00:15:26.880 --> 00:15:30.670
He can't do a bunch of trial
Diffie Hellman calculations.

00:15:30.670 --> 00:15:32.530
He only gets one guess.

00:15:32.530 --> 00:15:36.990
And so because of that, if
you display a 16-bit hash,

00:15:36.990 --> 00:15:41.010
he has only one chance in
65,000 of getting it right.

00:15:41.010 --> 00:15:45.312
He has only one chance of
65,000 of not being detected.

00:15:45.312 --> 00:15:46.770
And that's a powerful
disincentive.

00:15:46.770 --> 00:15:49.440
He's never going to
even try the attack

00:15:49.440 --> 00:15:55.200
if his odds of getting it
undetected are so pessimistic.

00:15:55.200 --> 00:16:01.640
So that's the foundation
on which ZRTP rests.

00:16:01.640 --> 00:16:05.210
That plus, we make
it so that you don't

00:16:05.210 --> 00:16:06.520
have to compare every time.

00:16:06.520 --> 00:16:09.260
Because we have this
other component.

00:16:09.260 --> 00:16:12.490
We have key continuity.

00:16:12.490 --> 00:16:18.540
At the end of every session, you
destroy all the key material,

00:16:18.540 --> 00:16:22.090
which is great for
forward secrecy.

00:16:22.090 --> 00:16:25.730
But before we destroy it,
we take the session key

00:16:25.730 --> 00:16:28.680
and hash it one more time.

00:16:28.680 --> 00:16:31.610
We run it through a key
derivation function.

00:16:31.610 --> 00:16:35.620
And we store that in
a cache for next time.

00:16:35.620 --> 00:16:39.560
And the next time you call
the same person again,

00:16:39.560 --> 00:16:41.130
it does a fresh
Diffie Hellman just

00:16:41.130 --> 00:16:46.370
like you did on the first call
with fresh random key material.

00:16:46.370 --> 00:16:49.290
And when you derive
the new session key,

00:16:49.290 --> 00:16:52.250
you are mixing together
the Diffie Hellman result

00:16:52.250 --> 00:16:56.380
with the previous cache material
from the previous call that you

00:16:56.380 --> 00:16:58.710
made to the same person.

00:16:58.710 --> 00:17:02.570
And that way, if there was no
man in the middle on the first

00:17:02.570 --> 00:17:05.980
call, there cannot be a man in
the middle on the second call

00:17:05.980 --> 00:17:09.109
or the third because
you do this every time.

00:17:09.109 --> 00:17:13.010
At the end of every
call, you hash it again,

00:17:13.010 --> 00:17:15.520
your destroy all the
original material,

00:17:15.520 --> 00:17:19.339
but you hash it and
store the hash-- which

00:17:19.339 --> 00:17:21.490
because these hashes
are not invertible,

00:17:21.490 --> 00:17:25.920
it's OK to do that-- and then
you use it the next time.

00:17:25.920 --> 00:17:28.250
So this is a form
of key continuity.

00:17:28.250 --> 00:17:31.050
That means you only have to do
this little ritual of comparing

00:17:31.050 --> 00:17:34.236
the fingerprint--
not the fingerprint,

00:17:34.236 --> 00:17:36.290
the short authentication
string-- you only

00:17:36.290 --> 00:17:40.070
have to do that one time
for each person you talk to.

00:17:40.070 --> 00:17:44.460
After you've done that, you
have this key continuity going.

00:17:44.460 --> 00:17:48.910
So in most cases where
an attacker wants

00:17:48.910 --> 00:17:50.580
to do a man in
the middle attack,

00:17:50.580 --> 00:17:53.270
he's not going to do it
on the first session.

00:17:53.270 --> 00:17:55.310
He probably doesn't
take an interest

00:17:55.310 --> 00:17:57.260
in wiretapping you until later.

00:17:57.260 --> 00:17:58.230
By then, it's too late.

00:17:58.230 --> 00:18:01.640
You've already got this
key continuity chain going.

00:18:01.640 --> 00:18:04.420
Every call, you refresh
the material in the cache.

00:18:04.420 --> 00:18:07.770
And you do it again
on the next one.

00:18:07.770 --> 00:18:11.704
So the key continuity and the
short authentication string

00:18:11.704 --> 00:18:13.370
which is enabled by
this hash commitment

00:18:13.370 --> 00:18:16.880
during the Diffie Hellman
is a good combination

00:18:16.880 --> 00:18:20.420
to make it possible
to do ephemeral Diffie

00:18:20.420 --> 00:18:24.240
Hellman without relying on
a public key infrastructure

00:18:24.240 --> 00:18:26.120
with certificate authorities.

00:18:26.120 --> 00:18:30.600
You don't need
persistent key material.

00:18:30.600 --> 00:18:33.220
It's not even persistent
even in the cache

00:18:33.220 --> 00:18:35.560
because it's changed every time.

00:18:35.560 --> 00:18:39.380
Now, everybody in this
room has used SSH.

00:18:39.380 --> 00:18:42.210
I don't have to ask
for a show of hands

00:18:42.210 --> 00:18:44.882
for the aforementioned visual
signature of what engineers

00:18:44.882 --> 00:18:45.590
look like, right?

00:18:49.210 --> 00:18:53.730
And so SSH also
has key continuity.

00:18:53.730 --> 00:18:58.660
Because when you talk to a
server, you get a public key.

00:18:58.660 --> 00:19:00.734
You store it in
your local cache.

00:19:00.734 --> 00:19:03.150
And you use it next time when
you talk to the same server.

00:19:03.150 --> 00:19:04.608
It tells you again
this public key.

00:19:04.608 --> 00:19:06.970
You compare, see if
it's the same one.

00:19:06.970 --> 00:19:08.280
That's key continuity.

00:19:08.280 --> 00:19:10.480
But that's a different
kind of key continuity.

00:19:10.480 --> 00:19:15.730
That's for a persistent
public key that never changes.

00:19:15.730 --> 00:19:18.470
That means that you have
to protect your private key

00:19:18.470 --> 00:19:20.520
over a long term.

00:19:20.520 --> 00:19:24.040
And if anybody ever
steals your private key,

00:19:24.040 --> 00:19:28.610
they can impersonate
you forever.

00:19:28.610 --> 00:19:30.770
Or if anybody steals the
private key of the server,

00:19:30.770 --> 00:19:33.120
they can impersonate the server.

00:19:33.120 --> 00:19:35.350
And it's not that easy to
protect the private key

00:19:35.350 --> 00:19:35.870
on a server.

00:19:35.870 --> 00:19:40.120
Because the server is up 24/7.

00:19:40.120 --> 00:19:42.410
And there's no human there.

00:19:42.410 --> 00:19:45.710
And so the private key has to
be accessible all the time.

00:19:45.710 --> 00:19:49.210
And that means that anybody
can get into the server

00:19:49.210 --> 00:19:51.580
and escalate their privileges.

00:19:51.580 --> 00:19:54.870
They can get to
that private key.

00:19:54.870 --> 00:19:59.360
So the way I do key
continuity is a bit different

00:19:59.360 --> 00:20:03.440
in that it's always ephemeral.

00:20:03.440 --> 00:20:05.460
It's less brittle.

00:20:05.460 --> 00:20:07.900
And it also has
another property,

00:20:07.900 --> 00:20:11.770
which I didn't think was so
important when I designed it.

00:20:11.770 --> 00:20:13.920
But it's starting to
look more important.

00:20:13.920 --> 00:20:16.310
And that is people are
starting to get concerned

00:20:16.310 --> 00:20:19.301
about the post-quantum
environment for cryptography.

00:20:22.190 --> 00:20:24.820
Now, I think it's going to
be a long time before we

00:20:24.820 --> 00:20:27.160
have to worry about
quantum computers.

00:20:27.160 --> 00:20:31.140
But you know, NSA is
saying that maybe we

00:20:31.140 --> 00:20:33.090
should start worrying now.

00:20:33.090 --> 00:20:37.660
And so NIST has put out a
document saying everybody--

00:20:37.660 --> 00:20:39.540
they're trying to
solicit suggestions

00:20:39.540 --> 00:20:45.480
for public key algorithms that
can resist quantum computers.

00:20:45.480 --> 00:20:50.160
And so it just so
happens that ZRTP already

00:20:50.160 --> 00:20:53.510
had resisted quantum
computers in most scenarios.

00:20:53.510 --> 00:20:55.350
Because even though
I'm not using

00:20:55.350 --> 00:20:57.610
any new exotic public
key algorithms, I'm just

00:20:57.610 --> 00:20:59.140
using elliptic curve
Diffie Hellman,

00:20:59.140 --> 00:21:02.640
which is not resistant
to Shor's algorithm that

00:21:02.640 --> 00:21:07.230
would be available to
a quantum computer,

00:21:07.230 --> 00:21:15.550
it's still difficult for-- see,
the only reason to worry today

00:21:15.550 --> 00:21:19.480
about quantum computers
is because if you have

00:21:19.480 --> 00:21:23.190
a very powerful opponent who
records your traffic today

00:21:23.190 --> 00:21:28.410
and archives it for 50 years,
and then 50 years in the future

00:21:28.410 --> 00:21:32.740
uses quantum computers to
retroactively figure out--

00:21:32.740 --> 00:21:36.340
breaks the traffic by
using Shor's algorithm

00:21:36.340 --> 00:21:41.960
to break your public
key calculations,

00:21:41.960 --> 00:21:45.230
I mean, that is something that
if you think that someday there

00:21:45.230 --> 00:21:47.790
will be quantum computers,
then you've got to think,

00:21:47.790 --> 00:21:49.630
if I want to protect
the traffic today

00:21:49.630 --> 00:21:55.260
from a future retroactive
examination of my traffic,

00:21:55.260 --> 00:22:00.480
then what I've done
with ZRTP is actually

00:22:00.480 --> 00:22:02.620
resistant to that
kind of attack.

00:22:02.620 --> 00:22:08.850
Because if your opponent misses
a single session of a ZRTP

00:22:08.850 --> 00:22:11.750
exchange, then
he's going to miss

00:22:11.750 --> 00:22:15.970
that cache key material that's
resulted from that session.

00:22:15.970 --> 00:22:18.730
And then every
session after that

00:22:18.730 --> 00:22:22.160
will be unable to break
even with quantum computers.

00:22:22.160 --> 00:22:25.530
Because quantum
computers, if we are

00:22:25.530 --> 00:22:27.890
assuming that it's
Shor's algorithm

00:22:27.890 --> 00:22:36.550
which can break public key
algorithms in polynomial time,

00:22:36.550 --> 00:22:40.790
then they can't break
symmetric algorithms.

00:22:40.790 --> 00:22:46.570
They can't break the AES for
example or hash functions.

00:22:46.570 --> 00:22:51.910
And so the cache key material
is symmetric key material.

00:22:51.910 --> 00:22:53.400
So you mix it in and use it.

00:22:53.400 --> 00:22:55.130
And you get to key continuity.

00:22:55.130 --> 00:22:56.950
So it would be immune
if your opponent

00:22:56.950 --> 00:22:58.780
misses a single session.

00:22:58.780 --> 00:23:00.870
So even those ZRTP
doesn't use any

00:23:00.870 --> 00:23:02.540
of these advanced
public key algorithms

00:23:02.540 --> 00:23:07.420
like algorithms based on
lattices or coding theory,

00:23:07.420 --> 00:23:12.000
it's still good because
of the key continuity,

00:23:12.000 --> 00:23:14.144
assuming that your opponent
misses one session.

00:23:14.144 --> 00:23:15.019
AUDIENCE: [INAUDIBLE]

00:23:17.874 --> 00:23:18.790
PHIL ZIMMERMANN: Sure.

00:23:18.790 --> 00:23:20.414
But they can't do it
50 years from now.

00:23:20.414 --> 00:23:22.460
Because the computer
doesn't exist anymore.

00:23:22.460 --> 00:23:24.790
And you might be dead by then.

00:23:24.790 --> 00:23:26.427
AUDIENCE: [INAUDIBLE]

00:23:26.427 --> 00:23:28.010
PHIL ZIMMERMANN:
They could do it now.

00:23:28.010 --> 00:23:32.690
But they don't have
quantum computers now.

00:23:32.690 --> 00:23:34.400
AUDIENCE: You said
that you, I mean,

00:23:34.400 --> 00:23:38.120
[INAUDIBLE] identify check
the hash the first time.

00:23:38.120 --> 00:23:40.136
I was under the assumption
that the key is--

00:23:40.136 --> 00:23:41.760
PHIL ZIMMERMANN:
Yeah, but even if they

00:23:41.760 --> 00:23:43.650
extract-- if they break
into your computer

00:23:43.650 --> 00:23:49.600
and extract the material,
even if they break in today

00:23:49.600 --> 00:23:51.850
and extract the
cached material, it's

00:23:51.850 --> 00:23:54.550
only good for the next session.

00:23:54.550 --> 00:23:57.540
And it gets
replenished every time.

00:23:57.540 --> 00:24:02.480
So if they're going to exploit
the material that they stole,

00:24:02.480 --> 00:24:04.690
they have to exploit
it on the next session.

00:24:04.690 --> 00:24:07.570
If they miss that one
opportunity, too bad.

00:24:07.570 --> 00:24:10.420
They're going to have
to steal it again.

00:24:10.420 --> 00:24:12.980
So it's always getting changed.

00:24:12.980 --> 00:24:15.740
It's operationally quite
a challenge for them.

00:24:18.760 --> 00:24:24.270
So all in all, ZRTP covers a
lot of the attack scenarios.

00:24:24.270 --> 00:24:28.470
And it does it without relying
on public key infrastructure

00:24:28.470 --> 00:24:31.460
or centrally managed
certificate authorities.

00:24:31.460 --> 00:24:38.840
And so if you're worried
about building-- like you

00:24:38.840 --> 00:24:44.470
guys recently announced a couple
of new products-- Allo and Duo,

00:24:44.470 --> 00:24:48.720
which do end to end encryption
both for text messages

00:24:48.720 --> 00:24:51.620
and for voice and video.

00:24:51.620 --> 00:24:53.410
And that's great.

00:24:53.410 --> 00:25:01.340
But if they rely on a protocol
to negotiate the session key,

00:25:01.340 --> 00:25:05.680
that might be subject
to attack at the server.

00:25:05.680 --> 00:25:11.690
For example, if you were using
WebRTC which relies on DTLS,

00:25:11.690 --> 00:25:15.580
that relies on long term
persistent public keys

00:25:15.580 --> 00:25:17.870
that the server provides.

00:25:17.870 --> 00:25:23.110
If that could be compromised,
possibly with the cooperation

00:25:23.110 --> 00:25:26.610
of the server, which could
be coerced-- remember,

00:25:26.610 --> 00:25:29.580
we're talking about
the coercion scenario

00:25:29.580 --> 00:25:33.450
where Google or
Apple or whoever's

00:25:33.450 --> 00:25:36.470
running the service
could be coerced--

00:25:36.470 --> 00:25:40.730
you have to consider your own
company as part of the threat

00:25:40.730 --> 00:25:42.440
model.

00:25:42.440 --> 00:25:45.560
But if you use protocol
that's designed to not trust

00:25:45.560 --> 00:25:49.660
the service provider
like ZRTP, then you're

00:25:49.660 --> 00:25:55.190
immune to the service
becoming evil.

00:25:55.190 --> 00:25:57.640
I mean, the service
promised not to be evil

00:25:57.640 --> 00:26:00.770
when this company
was founded, right?

00:26:00.770 --> 00:26:03.030
But it's a tough
promise to live up

00:26:03.030 --> 00:26:06.450
to when somebody comes in
with a national security

00:26:06.450 --> 00:26:09.310
letter or a court order.

00:26:09.310 --> 00:26:12.980
So you have to take into account
that even if the service does

00:26:12.980 --> 00:26:16.900
something bad, it
would be helpful

00:26:16.900 --> 00:26:24.040
if you had a protocol that is
immune to that kind of a threat

00:26:24.040 --> 00:26:26.940
model that includes
your own company.

00:26:29.652 --> 00:26:31.860
SPEAKER 1: Phil, can you
already take some questions?

00:26:31.860 --> 00:26:33.235
PHIL ZIMMERMANN:
Yeah, yeah sure.

00:26:33.235 --> 00:26:34.040
Let's do that.

00:26:34.040 --> 00:26:37.540
SPEAKER 1: So let's take
one from the room first.

00:26:37.540 --> 00:26:40.760
And I have one related
to exactly your latest

00:26:40.760 --> 00:26:42.464
point from online.

00:26:42.464 --> 00:26:43.380
PHIL ZIMMERMANN: Yeah.

00:26:47.970 --> 00:26:49.167
SPEAKER 1: Should be on.

00:26:49.167 --> 00:26:50.000
AUDIENCE: Thank you.

00:26:50.000 --> 00:26:53.290
So you mentioned that the
ZRTP protocol prevents

00:26:53.290 --> 00:26:54.520
the man in the middle attack.

00:26:54.520 --> 00:26:59.560
But if you don't have any
permanent key material

00:26:59.560 --> 00:27:05.260
on the end points, how can--
so if I call you on ZRTP,

00:27:05.260 --> 00:27:10.100
how do I know that I'm talking
to you and not to a look-alike?

00:27:10.100 --> 00:27:13.664
So this is mostly a problem
from e-mail and text protocol.

00:27:13.664 --> 00:27:15.330
PHIL ZIMMERMANN: This
is not for e-mail.

00:27:15.330 --> 00:27:16.445
This is just for voice.

00:27:16.445 --> 00:27:17.070
AUDIENCE: Yeah.

00:27:17.070 --> 00:27:18.820
PHIL ZIMMERMANN: It's
designed for a voice

00:27:18.820 --> 00:27:21.587
product like voice telephony.

00:27:21.587 --> 00:27:23.170
AUDIENCE: So you're
assuming that they

00:27:23.170 --> 00:27:25.200
would recognize your voice
on the phone, for instance?

00:27:25.200 --> 00:27:26.230
PHIL ZIMMERMANN: Yeah.

00:27:26.230 --> 00:27:27.650
AUDIENCE: OK.

00:27:27.650 --> 00:27:30.310
PHIL ZIMMERMANN: I mean,
I thought about somebody

00:27:30.310 --> 00:27:32.210
imitating your voice.

00:27:32.210 --> 00:27:35.500
I call it the Rich Little
attack because there

00:27:35.500 --> 00:27:38.880
was a famous voice impressionist
named Rich Little back

00:27:38.880 --> 00:27:40.500
in the 1970s.

00:27:40.500 --> 00:27:43.930
And the man of
1,000 voices, right?

00:27:43.930 --> 00:27:48.860
But it's not enough to
simply imitate your voice.

00:27:48.860 --> 00:27:53.360
See, if you see the short
authentication stream,

00:27:53.360 --> 00:27:57.320
it says ski lift Capricorn.

00:27:57.320 --> 00:27:59.604
And so you could talk
to the other person.

00:27:59.604 --> 00:28:01.270
You'd say, oh, you
remember that time we

00:28:01.270 --> 00:28:03.970
went skiing in Colorado,
and we rode on a ski lift?

00:28:03.970 --> 00:28:04.860
Remember that?

00:28:04.860 --> 00:28:05.360
You know?

00:28:05.360 --> 00:28:08.370
And you can work it
into the conversation

00:28:08.370 --> 00:28:11.250
if it becomes part
of the threat model.

00:28:11.250 --> 00:28:18.890
Like if somebody finds that
there's an attack like this,

00:28:18.890 --> 00:28:21.600
they're going to
post it on Slashdot.

00:28:21.600 --> 00:28:22.620
You know?

00:28:22.620 --> 00:28:25.320
Everybody's going to
know that, OK, somebody's

00:28:25.320 --> 00:28:27.650
trying to screw around.

00:28:27.650 --> 00:28:30.290
They're trying to imitate
voices to break this.

00:28:30.290 --> 00:28:32.120
And so everybody
would be more careful.

00:28:32.120 --> 00:28:33.590
AUDIENCE: Yeah, there's
also the scenario

00:28:33.590 --> 00:28:35.548
where you'd talk to
someone you don't know yet,

00:28:35.548 --> 00:28:38.430
like they're calling for
the first time to Google

00:28:38.430 --> 00:28:39.684
to request their tech support.

00:28:39.684 --> 00:28:40.600
PHIL ZIMMERMANN: Sure.

00:28:40.600 --> 00:28:43.590
AUDIENCE: Then how do you
know you actually reach them?

00:28:43.590 --> 00:28:45.260
PHIL ZIMMERMANN:
Yeah, well, I guess

00:28:45.260 --> 00:28:46.750
it could be done in that case.

00:28:46.750 --> 00:28:51.170
But still, even
there, they would

00:28:51.170 --> 00:28:54.280
have to imitate the voice
of the entire session.

00:28:54.280 --> 00:28:56.710
Because the voice
that's used to recite

00:28:56.710 --> 00:28:59.954
the words has got to be the same
voice that you're talking to

00:28:59.954 --> 00:29:01.120
for the rest of the session.

00:29:01.120 --> 00:29:02.170
AUDIENCE: But assuming
that you don't

00:29:02.170 --> 00:29:03.544
no the voice of
the person you're

00:29:03.544 --> 00:29:04.810
calling for the first time.

00:29:04.810 --> 00:29:08.090
PHIL ZIMMERMANN: Yeah,
they can do that.

00:29:08.090 --> 00:29:09.260
AUDIENCE: [INAUDIBLE]

00:29:09.260 --> 00:29:10.218
PHIL ZIMMERMANN: Right.

00:29:10.218 --> 00:29:12.730
But if you want to use it
in other scenarios, where

00:29:12.730 --> 00:29:15.660
for most people, they want
to talk to somebody that they

00:29:15.660 --> 00:29:18.570
know, they want to talk to--
I mean, look, if you're going

00:29:18.570 --> 00:29:21.580
to have a confidential
conversation, in most cases,

00:29:21.580 --> 00:29:22.510
you'd know the person.

00:29:22.510 --> 00:29:24.093
Because if you don't
know them, you're

00:29:24.093 --> 00:29:27.412
less likely to be talking
about something confidential.

00:29:32.710 --> 00:29:35.180
SPEAKER 1: I think-- can
you pass it behind you?

00:29:35.180 --> 00:29:37.160
I'll first ask the
question that I got online.

00:29:37.160 --> 00:29:38.280
And then it's you.

00:29:38.280 --> 00:29:40.460
So I'm just going
to read it out.

00:29:40.460 --> 00:29:42.180
PHIL ZIMMERMANN: Yeah.

00:29:42.180 --> 00:29:44.040
SPEAKER 1: The
question is as follows.

00:29:44.040 --> 00:29:45.640
What are the main
security issues

00:29:45.640 --> 00:29:49.020
of replacing centralized
call set up in user database

00:29:49.020 --> 00:29:51.160
like currently in
Duo with [INAUDIBLE]

00:29:51.160 --> 00:29:53.030
decentralized
system, for example,

00:29:53.030 --> 00:29:57.730
the machinery used by ring.cx?

00:29:57.730 --> 00:29:59.130
PHIL ZIMMERMANN: Used by what?

00:29:59.130 --> 00:30:01.820
SPEAKER 1: It's ring.cx.

00:30:01.820 --> 00:30:03.820
It's a company that
provides a framework

00:30:03.820 --> 00:30:09.630
for doing decentralized call
setup and user database.

00:30:12.160 --> 00:30:14.660
PHIL ZIMMERMANN: Well, you need
to have a centralized server

00:30:14.660 --> 00:30:16.270
for routing the calls.

00:30:16.270 --> 00:30:18.640
You have to have
something running

00:30:18.640 --> 00:30:21.560
SIP or some other protocol
to setup the call,

00:30:21.560 --> 00:30:24.160
do the signaling
part of the call.

00:30:24.160 --> 00:30:26.610
But it doesn't
have to be part of

00:30:26.610 --> 00:30:28.740
the cryptographic negotiation.

00:30:28.740 --> 00:30:33.010
It could route the messages
that are used to negotiate

00:30:33.010 --> 00:30:34.860
the crypto part of it.

00:30:34.860 --> 00:30:39.380
But it doesn't have to be a
participant getting access

00:30:39.380 --> 00:30:42.040
to key material.

00:30:42.040 --> 00:30:43.640
And that's the difference.

00:30:43.640 --> 00:30:47.140
I mean, you want to make it
so that the servers are not

00:30:47.140 --> 00:30:51.612
in possession of
private key material.

00:30:51.612 --> 00:30:53.740
If you can just achieve
that one objective,

00:30:53.740 --> 00:30:56.490
then it doesn't matter that
the servers are setting up

00:30:56.490 --> 00:30:56.990
the call.

00:31:01.930 --> 00:31:05.490
AUDIENCE: So a lot of research
into security protocol

00:31:05.490 --> 00:31:09.670
and application shows that
usually the weakest link is

00:31:09.670 --> 00:31:13.590
the end user not understanding
the security guarantees

00:31:13.590 --> 00:31:15.290
and not using the
software properly.

00:31:15.290 --> 00:31:17.490
So you know, with
a secure phone,

00:31:17.490 --> 00:31:21.210
they won't bother reading the
words or they'll flub it up.

00:31:21.210 --> 00:31:23.530
Or even more importantly,
you said that we

00:31:23.530 --> 00:31:25.380
don't rely on a central server.

00:31:25.380 --> 00:31:28.590
But even if your product
is completely secure,

00:31:28.590 --> 00:31:30.909
there is still automatic
updates and stuff like that.

00:31:30.909 --> 00:31:31.950
PHIL ZIMMERMANN: Oh sure.

00:31:31.950 --> 00:31:33.408
AUDIENCE: So say
Google implemented

00:31:33.408 --> 00:31:34.990
a completely secure NGN server.

00:31:34.990 --> 00:31:36.461
Hey can just push--

00:31:36.461 --> 00:31:37.710
PHIL ZIMMERMANN: That's right.

00:31:37.710 --> 00:31:40.296
AUDIENCE: --an update that
bypasses it on the [INAUDIBLE].

00:31:40.296 --> 00:31:44.160
PHIL ZIMMERMANN: Well, yeah.

00:31:44.160 --> 00:31:50.710
Pushing updates, that's a major
part of the attack surface.

00:31:50.710 --> 00:31:54.770
In fact, actually,
Apple is even worse.

00:31:54.770 --> 00:32:00.240
Because Apple only allows
the Apple Store to be the one

00:32:00.240 --> 00:32:02.160
that gives you these updates.

00:32:02.160 --> 00:32:05.432
Most Apple users don't have
the ability to load an app.

00:32:05.432 --> 00:32:07.640
Unless they're developers,
they could do it that way.

00:32:07.640 --> 00:32:10.000
But if they're not, then
the only game in town

00:32:10.000 --> 00:32:12.580
is the App Store.

00:32:12.580 --> 00:32:20.290
Google Play is not the only
way to get an app on Android.

00:32:20.290 --> 00:32:22.830
But it's the one
that most people use.

00:32:22.830 --> 00:32:25.740
So at least you've got some
other way to get it on there.

00:32:25.740 --> 00:32:30.900
But that's only for
the dedicated fanatics.

00:32:30.900 --> 00:32:34.620
So if the App Store or
the Google Play Store

00:32:34.620 --> 00:32:37.880
can be attacked, perhaps even
without the knowledge of Google

00:32:37.880 --> 00:32:41.150
or Apple, then
they could somehow

00:32:41.150 --> 00:32:46.540
make it deliver updates
that are specially

00:32:46.540 --> 00:32:48.526
designed for the attacker.

00:32:52.400 --> 00:32:54.150
But you have to
put a lot of work

00:32:54.150 --> 00:32:57.570
into the Google Play Store and
the App Store to prevent that.

00:32:57.570 --> 00:33:04.490
It's also getting worse in
that we're now seeing efforts

00:33:04.490 --> 00:33:16.040
to have just-in-time resolution
of the binaries, which

00:33:16.040 --> 00:33:20.810
makes it hard to sign
the binaries in advance

00:33:20.810 --> 00:33:25.430
because there's different
versions of the execution

00:33:25.430 --> 00:33:30.290
environment that the
binaries can be configured

00:33:30.290 --> 00:33:35.470
for on a phone by phone basis,
a customer by customer basis.

00:33:35.470 --> 00:33:39.940
And that makes it even harder
to do digital signatures on it.

00:33:39.940 --> 00:33:42.919
So that's something that
needs a lot more work.

00:33:42.919 --> 00:33:44.960
AUDIENCE: Obviously, there
is a double bind here.

00:33:44.960 --> 00:33:47.830
Because if we don't
do any updates,

00:33:47.830 --> 00:33:51.620
then users are running outdated
software, which will eventually

00:33:51.620 --> 00:33:53.730
have discovered security holes.

00:33:53.730 --> 00:33:58.490
And you're back to the same end
user exploitability problem.

00:33:58.490 --> 00:34:02.860
If you look in real life,
almost always the compromises

00:34:02.860 --> 00:34:06.430
are based on exploits on
the end user software.

00:34:06.430 --> 00:34:09.409
Even with the iPhone case, the
FBI ended up not needing it

00:34:09.409 --> 00:34:12.090
because they found a
company that will exploit

00:34:12.090 --> 00:34:14.719
some kind of end user security.

00:34:14.719 --> 00:34:19.270
PHIL ZIMMERMANN: The fact is
that the highly resourceful

00:34:19.270 --> 00:34:22.760
intel agencies around
the world-- the NSA

00:34:22.760 --> 00:34:25.199
being the most powerful--
have ways of getting

00:34:25.199 --> 00:34:26.630
into individual phones.

00:34:26.630 --> 00:34:28.830
If they really, really want
to get into your phone,

00:34:28.830 --> 00:34:30.310
they will get in.

00:34:30.310 --> 00:34:33.100
When you put 30,000
engineers and scientists

00:34:33.100 --> 00:34:35.889
and mathematicians coming
to work every single day,

00:34:35.889 --> 00:34:38.270
spending all day
long, day in and day

00:34:38.270 --> 00:34:40.857
out for years and years
talking to their very

00:34:40.857 --> 00:34:42.440
intelligent colleagues
about how we're

00:34:42.440 --> 00:34:47.070
going to make this better,
they'll find a way in.

00:34:47.070 --> 00:34:50.080
I mean, the FBI did not
ask for any help from NSA

00:34:50.080 --> 00:34:52.280
because they wanted to
make a point in court.

00:34:52.280 --> 00:34:55.440
They wanted to set
a legal precedent.

00:34:55.440 --> 00:34:58.100
They could have gotten in
with help from the NSA.

00:34:58.100 --> 00:35:03.130
As it stands, they went
out to a private vendor.

00:35:03.130 --> 00:35:06.870
But you know, you've got to at
least get a start somewhere.

00:35:06.870 --> 00:35:08.620
You've got to start
with protocols

00:35:08.620 --> 00:35:13.540
that are immune to bad
behavior from the server that's

00:35:13.540 --> 00:35:15.650
providing the service.

00:35:15.650 --> 00:35:18.690
And we also have to work on
the distribution of updates.

00:35:21.970 --> 00:35:28.310
But one of the obstacles
to making this kind of push

00:35:28.310 --> 00:35:33.900
to reduce the dependency
on the server being good

00:35:33.900 --> 00:35:36.830
is that you have to have the
attitude that the server will

00:35:36.830 --> 00:35:38.300
not always be good.

00:35:38.300 --> 00:35:40.630
Just because it's
your company's server,

00:35:40.630 --> 00:35:44.050
you've got to stop
trusting your company.

00:35:44.050 --> 00:35:48.820
I mean, if the government
came into my company

00:35:48.820 --> 00:35:52.420
with a court order
and said, give us

00:35:52.420 --> 00:35:54.720
everything you
have on this user,

00:35:54.720 --> 00:35:56.350
we don't want to go to jail.

00:35:56.350 --> 00:35:58.800
We would have to do
whatever we can to give them

00:35:58.800 --> 00:36:01.090
something for that user.

00:36:01.090 --> 00:36:02.980
But we've architected
things so that we

00:36:02.980 --> 00:36:08.190
don't have much to give them
just cybertext, maybe credit

00:36:08.190 --> 00:36:12.420
card information, except we
use an external processor.

00:36:12.420 --> 00:36:14.210
So they'd have to go there.

00:36:18.250 --> 00:36:22.610
So you've got to have
the attitude that-- Apple

00:36:22.610 --> 00:36:24.820
failed to have that attitude.

00:36:24.820 --> 00:36:29.000
They did not take themselves
as part of the threat model.

00:36:29.000 --> 00:36:30.560
But now they do.

00:36:30.560 --> 00:36:32.529
Now they understand.

00:36:32.529 --> 00:36:34.070
They've been through
that experience.

00:36:34.070 --> 00:36:36.550
Now they understand
that they themselves

00:36:36.550 --> 00:36:37.950
are part of the threat model.

00:36:37.950 --> 00:36:40.690
And so their
engineers, I am sure,

00:36:40.690 --> 00:36:45.150
are working now to include
themselves in the threat model

00:36:45.150 --> 00:36:49.710
and to try to make it so that
the next time after they make

00:36:49.710 --> 00:36:54.480
these improvements,
they'll cut themselves out

00:36:54.480 --> 00:36:56.206
of the threat model.

00:36:56.206 --> 00:36:57.580
And you guys have
to do the same.

00:37:01.860 --> 00:37:04.204
Yeah?

00:37:04.204 --> 00:37:05.120
AUDIENCE: Now it's on.

00:37:05.120 --> 00:37:05.730
OK.

00:37:05.730 --> 00:37:10.440
So if each session key derives
from the previous session key,

00:37:10.440 --> 00:37:14.700
that kind of requires every end
user to use a single device.

00:37:14.700 --> 00:37:15.990
Otherwise--

00:37:15.990 --> 00:37:16.400
PHIL ZIMMERMANN:
No, every device--

00:37:16.400 --> 00:37:18.525
AUDIENCE: --they'll have
to synchronize the session

00:37:18.525 --> 00:37:20.310
keys between their smartphones.

00:37:20.310 --> 00:37:22.020
PHIL ZIMMERMANN:
No, each device--

00:37:22.020 --> 00:37:24.680
it's a device to
device protocol.

00:37:24.680 --> 00:37:26.520
It doesn't care how
many devices you have.

00:37:29.460 --> 00:37:33.430
If I call from my
device to your device,

00:37:33.430 --> 00:37:36.770
and then tomorrow I'm
talking to your other device,

00:37:36.770 --> 00:37:38.250
then we'll do it again.

00:37:38.250 --> 00:37:42.370
You will have to do the
verbal comparison twice.

00:37:42.370 --> 00:37:46.880
AUDIENCE: So that means
that one way to attack

00:37:46.880 --> 00:37:53.160
would be to physically
steal somebody's phone

00:37:53.160 --> 00:37:57.110
so that they would
have to re-authenticate

00:37:57.110 --> 00:38:00.170
with the other user
with a new smartphone.

00:38:00.170 --> 00:38:01.420
PHIL ZIMMERMANN: That's right.

00:38:01.420 --> 00:38:05.532
But you know, you could tell
them that you lost your phone.

00:38:05.532 --> 00:38:06.740
And now you have another one.

00:38:21.427 --> 00:38:22.260
AUDIENCE: Excellent.

00:38:22.260 --> 00:38:23.450
Can you hear me?

00:38:23.450 --> 00:38:23.790
PHIL ZIMMERMANN: Yeah.

00:38:23.790 --> 00:38:24.956
AUDIENCE: I can hear myself.

00:38:24.956 --> 00:38:27.700
So that's probably good.

00:38:27.700 --> 00:38:29.700
So for that thing,
there's OMEMO.

00:38:29.700 --> 00:38:32.540
It lets you sync
keys across devices.

00:38:32.540 --> 00:38:35.072
And basically, one device can
say, yes, this other device

00:38:35.072 --> 00:38:36.030
is trustworthy as well.

00:38:36.030 --> 00:38:37.430
It's a really good protocol.

00:38:37.430 --> 00:38:39.270
Maybe ZRTP should
incorporate that.

00:38:39.270 --> 00:38:41.460
Anyway, thank you
for being here.

00:38:41.460 --> 00:38:42.970
I'm a customer of yours.

00:38:42.970 --> 00:38:47.220
I dropped the phone already
as you can probably tell.

00:38:47.220 --> 00:38:52.080
And I wanted to ask, why
the change in strategy?

00:38:52.080 --> 00:38:55.550
Silent Phone 1 did not
come with Google Play.

00:38:55.550 --> 00:38:57.590
And Silent Phone 2
came with Google Play.

00:38:57.590 --> 00:39:01.850
I actually had to return
that phone for that reason.

00:39:01.850 --> 00:39:04.960
And what changed about
the whole product strategy

00:39:04.960 --> 00:39:06.890
that had happened at the time?

00:39:06.890 --> 00:39:08.510
If you know, maybe you don't.

00:39:08.510 --> 00:39:10.422
I don't know.

00:39:10.422 --> 00:39:13.800
PHIL ZIMMERMANN: Well,
a lot of these decisions

00:39:13.800 --> 00:39:15.225
were made by non-engineers.

00:39:15.225 --> 00:39:17.045
[LAUGHTER]

00:39:19.320 --> 00:39:21.320
AUDIENCE: We're also
familiar with this problem.

00:39:21.320 --> 00:39:22.170
PHIL ZIMMERMANN: Yeah.

00:39:22.170 --> 00:39:22.780
AUDIENCE: Anyway, thanks.

00:39:22.780 --> 00:39:24.070
PHIL ZIMMERMANN: If they'd
listen to the engineers

00:39:24.070 --> 00:39:26.236
from the start, we'd been
in better shape with that.

00:39:32.920 --> 00:39:35.410
Just a little bit of advice
when you start a company,

00:39:35.410 --> 00:39:39.410
it's a good idea to try to get
as many engineers as possible

00:39:39.410 --> 00:39:41.364
involved in the decision making.

00:39:41.364 --> 00:39:43.260
[LAUGHTER]

00:39:43.260 --> 00:39:46.130
Or as few-- let me rephrase
it-- as few non-engineers as

00:39:46.130 --> 00:39:47.503
possible with decision making.

00:39:47.503 --> 00:39:49.768
[LAUGHTER]

00:39:51.547 --> 00:39:53.130
AUDIENCE: Thanks for
being here today.

00:39:53.130 --> 00:39:56.200
If I may, I'd like to
widen the scope a little.

00:39:56.200 --> 00:39:58.260
So we talked a lot about
protecting the content

00:39:58.260 --> 00:39:59.970
of your communication.

00:39:59.970 --> 00:40:02.390
We talked a lot about
protecting the content

00:40:02.390 --> 00:40:05.650
of your communication to
cope with mass surveillance.

00:40:05.650 --> 00:40:06.890
Another thing is--

00:40:06.890 --> 00:40:08.190
PHIL ZIMMERMANN: The metadata.

00:40:08.190 --> 00:40:08.820
AUDIENCE: Exactly.

00:40:08.820 --> 00:40:10.160
PHIL ZIMMERMANN: Yeah,
and traffic analysis.

00:40:10.160 --> 00:40:10.920
AUDIENCE: Exactly.

00:40:10.920 --> 00:40:12.330
Discovering your social network.

00:40:12.330 --> 00:40:12.580
PHIL ZIMMERMANN: Sure

00:40:12.580 --> 00:40:14.100
AUDIENCE: Now, into the
future, into the past.

00:40:14.100 --> 00:40:15.025
What are you [INAUDIBLE]

00:40:15.025 --> 00:40:15.590
PHIL ZIMMERMANN: Well, yeah.

00:40:15.590 --> 00:40:17.881
I didn't talk about that
because it's kind of hopeless.

00:40:17.881 --> 00:40:20.560
[LAUGHTER]

00:40:20.560 --> 00:40:21.362
AUDIENCE: Thanks.

00:40:21.362 --> 00:40:23.320
PHIL ZIMMERMANN: Traffic
analysis is very, very

00:40:23.320 --> 00:40:25.210
difficult to defend against.

00:40:25.210 --> 00:40:26.950
It's so difficult
to defend against it

00:40:26.950 --> 00:40:31.340
that I usually don't even try.

00:40:31.340 --> 00:40:33.270
I mean, look,
there's some things

00:40:33.270 --> 00:40:38.470
that I'm doing in Silent Phone
that defend against slightly

00:40:38.470 --> 00:40:40.310
less capable opponents.

00:40:40.310 --> 00:40:44.040
For example, if you're trying
to protect against traffic

00:40:44.040 --> 00:40:48.160
analysis from an intel agency in
a particular country you happen

00:40:48.160 --> 00:40:51.420
to be standing in
holding your device,

00:40:51.420 --> 00:40:56.010
I mean, I do protect
against the traffic analysis

00:40:56.010 --> 00:40:58.630
that he's doing by observing
the traffic between your phone

00:40:58.630 --> 00:41:00.470
and our servers.

00:41:00.470 --> 00:41:06.060
But if it's a worldwide
intelligency with global reach,

00:41:06.060 --> 00:41:08.850
and they can see all
the traffic everywhere,

00:41:08.850 --> 00:41:12.080
then it's nearly impossible
to protect against traffic

00:41:12.080 --> 00:41:15.030
analysis in practical terms.

00:41:15.030 --> 00:41:18.990
I mean, theoretically,
you could just

00:41:18.990 --> 00:41:22.560
flood the entire internet
with dummy traffic

00:41:22.560 --> 00:41:25.640
and try to use the needle
in a haystack approach.

00:41:25.640 --> 00:41:31.110
But that's like draining the
oceans to find the submarine.

00:41:31.110 --> 00:41:33.740
That's just not practical.

00:41:33.740 --> 00:41:37.170
So traffic analysis--
you would be

00:41:37.170 --> 00:41:40.250
surprised at what
traffic analysis can do.

00:41:40.250 --> 00:41:43.680
I mean, for example,
most people don't even

00:41:43.680 --> 00:41:46.680
consider some aspects
of traffic analysis.

00:41:46.680 --> 00:41:51.350
For example, if you use a codec
that is variable bit rate,

00:41:51.350 --> 00:41:54.570
you know, that some phonemes
produce different numbers

00:41:54.570 --> 00:41:58.430
of bits than other
phonemes, that could

00:41:58.430 --> 00:42:00.580
be used in traffic analysis.

00:42:00.580 --> 00:42:03.410
Because even though the
payloads of the RTP packets

00:42:03.410 --> 00:42:06.210
are encrypted, the
number of bits,

00:42:06.210 --> 00:42:08.540
if you are using a
variable bit rate codec,

00:42:08.540 --> 00:42:12.010
which I never use for this
reason, the number of bits

00:42:12.010 --> 00:42:14.510
for each packet-- and it's
50 packets per second--

00:42:14.510 --> 00:42:18.750
you could construct a
histogram of packet lengths

00:42:18.750 --> 00:42:25.360
and match it to phrases,
words, phrases, and figure

00:42:25.360 --> 00:42:28.480
out what people are
saying without actually

00:42:28.480 --> 00:42:32.130
being able to break
the encryption just

00:42:32.130 --> 00:42:33.380
from the packet.

00:42:33.380 --> 00:42:36.020
So never use variable
bit rate codecs.

00:42:36.020 --> 00:42:38.150
But that is a form
of traffic analysis.

00:42:38.150 --> 00:42:40.860
So it's not just looking at
where the packets are going.

00:42:40.860 --> 00:42:43.982
It's even studying
things like that.

00:42:43.982 --> 00:42:45.190
There's all kinds of traffic.

00:42:45.190 --> 00:42:48.650
And traffic analysis is an
extremely powerful field

00:42:48.650 --> 00:42:51.820
of study and very difficult
to protect against.

00:42:51.820 --> 00:42:57.320
So you know, I do
what I'm able to do.

00:42:57.320 --> 00:43:01.236
I mean, it's like the guy
looking for his contact lens.

00:43:01.236 --> 00:43:03.610
You see him searching on the
ground for his contact lens.

00:43:03.610 --> 00:43:05.940
And you say, what
are you looking for?

00:43:05.940 --> 00:43:07.030
I dropped my contact lens.

00:43:07.030 --> 00:43:08.196
Well, where did you drop it?

00:43:08.196 --> 00:43:09.590
Oh, across the
street over there.

00:43:09.590 --> 00:43:11.089
Well, why are you
looking over here?

00:43:11.089 --> 00:43:14.050
Well, because the
light's better.

00:43:14.050 --> 00:43:16.970
I know how to do certain things.

00:43:16.970 --> 00:43:20.670
So I'm just doing
what I know how to do.

00:43:20.670 --> 00:43:23.230
But we need more than that.

00:43:23.230 --> 00:43:27.640
But just being able to
protect the content,

00:43:27.640 --> 00:43:30.220
even there, you
just have to protect

00:43:30.220 --> 00:43:34.462
against your own servers
being compromised.

00:43:40.743 --> 00:43:41.550
Go ahead.

00:43:41.550 --> 00:43:45.120
AUDIENCE: All right, I'd
like to get a bit of context.

00:43:45.120 --> 00:43:47.530
So the whole problem
of session set up

00:43:47.530 --> 00:43:50.250
and key exchange is basically
a problem of short identifiers

00:43:50.250 --> 00:43:51.720
versus longer identifiers.

00:43:51.720 --> 00:43:53.970
Short, because we
remember facebook.com,

00:43:53.970 --> 00:43:56.330
but we don't remember
the public key.

00:43:56.330 --> 00:43:59.340
Personally, coming from a
bit of a bitcoin background,

00:43:59.340 --> 00:44:01.830
I found it very practical to
exchange long identifiers,

00:44:01.830 --> 00:44:04.720
especially with elliptic curves
having very short key material.

00:44:04.720 --> 00:44:06.470
Just hold the [INAUDIBLE]
code and be done

00:44:06.470 --> 00:44:09.050
and don't have to worry
about any of that problem.

00:44:09.050 --> 00:44:11.270
Can you talk a
little bit about how

00:44:11.270 --> 00:44:13.040
Silent Phone deals
with the problem,

00:44:13.040 --> 00:44:15.030
to call a lengthy phone
number, and then I

00:44:15.030 --> 00:44:17.710
have to do the exchange?

00:44:17.710 --> 00:44:20.060
Or is there a way for
me to directly give you

00:44:20.060 --> 00:44:22.760
a long identifier and
completely sidestep the problem?

00:44:22.760 --> 00:44:25.190
Of course, then, that
probably doesn't change.

00:44:25.190 --> 00:44:27.219
Because you [INAUDIBLE]

00:44:27.219 --> 00:44:28.760
PHIL ZIMMERMANN:
Yeah, I can tell you

00:44:28.760 --> 00:44:32.050
that the human readable
identifier-- first,

00:44:32.050 --> 00:44:34.290
it's provided in the
signaling, which is not

00:44:34.290 --> 00:44:35.840
protected cryptographically.

00:44:35.840 --> 00:44:37.549
Well, it is protected
cryptographically

00:44:37.549 --> 00:44:39.090
in that it goes
through a TLS tunnel.

00:44:39.090 --> 00:44:43.300
But if the server
is evil, then it's

00:44:43.300 --> 00:44:47.890
only [INAUDIBLE] safe there.

00:44:47.890 --> 00:44:52.530
But you have the ability to
edit the human readable name.

00:44:52.530 --> 00:44:56.630
So if somebody calls you and
says that they're Barack Obama,

00:44:56.630 --> 00:44:58.440
and you know they're
not Barack Obama,

00:44:58.440 --> 00:45:01.540
you could edit that
and say, no he isn't.

00:45:01.540 --> 00:45:05.400
It pre-fills the
string saying this call

00:45:05.400 --> 00:45:07.019
appears to be from Barack Obama.

00:45:07.019 --> 00:45:08.060
You can say, no it's not.

00:45:08.060 --> 00:45:10.120
It's whatever the
name of the person

00:45:10.120 --> 00:45:11.762
is who you're talking to.

00:45:11.762 --> 00:45:13.970
Or you can say I'm not even
going to authenticate it.

00:45:17.340 --> 00:45:20.960
Another thing that I do--
we do text messaging.

00:45:20.960 --> 00:45:29.010
And we use the double ratchet
construct that Axolotl uses.

00:45:29.010 --> 00:45:33.642
But I don't like the fact that
the double ratchet-- and this

00:45:33.642 --> 00:45:36.050
is what they used in WhatsApp.

00:45:36.050 --> 00:45:40.260
I don't like the fact that that
relies on long term identity

00:45:40.260 --> 00:45:42.830
thieves.

00:45:42.830 --> 00:45:46.020
And so what I do-- if
a product has both text

00:45:46.020 --> 00:45:50.220
messaging and secure
VoIP, so I've got ZRTP.

00:45:50.220 --> 00:45:50.780
GP

00:45:50.780 --> 00:45:53.960
And because the ZRTP
security association

00:45:53.960 --> 00:45:57.650
is established by this
voice authentication

00:45:57.650 --> 00:45:59.440
of the short
authentication string,

00:45:59.440 --> 00:46:06.870
I use that to reinforce the text
messaging security association

00:46:06.870 --> 00:46:08.370
by sending the
long term identity

00:46:08.370 --> 00:46:13.370
key under the protection
of the ZRTP exchange.

00:46:13.370 --> 00:46:16.460
And that way, if you do
the verbal comparison

00:46:16.460 --> 00:46:19.060
of the authentication
string, you now

00:46:19.060 --> 00:46:21.070
have verified that
the text messaging

00:46:21.070 --> 00:46:24.620
protocol is end to end secure
with no man in the middle.

00:46:24.620 --> 00:46:27.490
So in other words, you bound
the long term identity key

00:46:27.490 --> 00:46:32.790
to the same identity that you
did the ZRTP exchange with.

00:46:32.790 --> 00:46:36.040
So if you have a
protocol that you like,

00:46:36.040 --> 00:46:40.600
that you trust-- because
the ZRTP exchange

00:46:40.600 --> 00:46:44.480
is very well optimized
just for voice.

00:46:44.480 --> 00:46:47.324
Don't ever try to
use it for e-mail.

00:46:47.324 --> 00:46:51.430
Back when I first got into
secure VoIP, some people said,

00:46:51.430 --> 00:46:54.050
well can you use PGP
to do secure VoIP?

00:46:54.050 --> 00:46:54.990
No, you can't.

00:46:54.990 --> 00:46:58.789
PGP is for e-mail
and file encryption.

00:46:58.789 --> 00:47:00.330
You've got to use
different protocols

00:47:00.330 --> 00:47:03.580
for different problems
you're trying to solve.

00:47:03.580 --> 00:47:06.380
And ZRTP is just to solve
the one problem of how do you

00:47:06.380 --> 00:47:08.440
get to people to talk
to each other securely

00:47:08.440 --> 00:47:11.250
with their voices
and with video?

00:47:11.250 --> 00:47:15.770
Well, if you can do that, and
you get a really good security

00:47:15.770 --> 00:47:19.190
association, you can
leverage that to reinforce

00:47:19.190 --> 00:47:22.770
another security association
under another protocol

00:47:22.770 --> 00:47:24.860
like Axolotl.

00:47:24.860 --> 00:47:28.780
And that's what we
did in Silent Phone.

00:47:28.780 --> 00:47:32.530
And so we don't have to
worry about the server

00:47:32.530 --> 00:47:37.090
giving out fake long term
identity keys for the text

00:47:37.090 --> 00:47:38.410
messaging protocol.

00:47:38.410 --> 00:47:39.780
Because we protect it with ZRTP.

00:47:43.600 --> 00:47:45.590
So anyway, yes?

00:47:45.590 --> 00:47:48.150
SPEAKER 1: So we have time for
maybe one or two questions.

00:47:48.150 --> 00:47:49.570
PHIL ZIMMERMANN: Do we
really have to cut this off?

00:47:49.570 --> 00:47:50.986
It's at the end
of the day, right?

00:47:50.986 --> 00:47:52.930
Have people started
moving toward the exits?

00:47:52.930 --> 00:47:56.340
SPEAKER 1: If you'd like to
join us for the TGIF drinks,

00:47:56.340 --> 00:47:58.410
then maybe people can
approach you then.

00:47:58.410 --> 00:47:59.910
PHIL ZIMMERMANN: OK, all right.

00:47:59.910 --> 00:48:01.990
Go ahead.

00:48:01.990 --> 00:48:04.820
AUDIENCE: My question
is addressed to you

00:48:04.820 --> 00:48:06.167
as a political activist.

00:48:06.167 --> 00:48:07.250
I put it also on the Dory.

00:48:07.250 --> 00:48:09.910
Maybe I'm playing here a
bit of devil's advocate.

00:48:09.910 --> 00:48:13.380
But clearly, you strive
for better security,

00:48:13.380 --> 00:48:14.370
better privacy.

00:48:14.370 --> 00:48:17.610
And as you said, if the
server is compromised,

00:48:17.610 --> 00:48:19.670
it's by some evil power.

00:48:19.670 --> 00:48:21.800
But as a society,
after all, we have

00:48:21.800 --> 00:48:23.100
these democratic societies.

00:48:23.100 --> 00:48:27.684
We have entrusted the government
with power to survey after all.

00:48:27.684 --> 00:48:28.600
PHIL ZIMMERMANN: Sure.

00:48:28.600 --> 00:48:30.360
AUDIENCE: So how do
we strike the balance?

00:48:30.360 --> 00:48:32.410
I mean, this is mostly
legal concept, of course.

00:48:32.410 --> 00:48:33.970
But how do we strike
it technically?

00:48:33.970 --> 00:48:35.200
Maybe we do one after all.

00:48:35.200 --> 00:48:36.156
PHIL ZIMMERMANN: Yeah.

00:48:36.156 --> 00:48:37.030
AUDIENCE: [INAUDIBLE]

00:48:37.030 --> 00:48:39.320
PHIL ZIMMERMANN: Yeah, sure.

00:48:39.320 --> 00:48:42.430
It's the core question
that was at the center

00:48:42.430 --> 00:48:46.970
of the crypto wars of
the 1990s and the one

00:48:46.970 --> 00:48:49.230
that we keep on
running into today.

00:48:49.230 --> 00:48:52.575
I mean, we now see a resurgence
of the crypto wars of the '90s.

00:48:52.575 --> 00:48:53.450
It's come back again.

00:48:59.774 --> 00:49:03.090
If we had-- always
had a government

00:49:03.090 --> 00:49:09.440
that was wise and
true and fair and what

00:49:09.440 --> 00:49:13.560
we want in a government,
then maybe that

00:49:13.560 --> 00:49:14.830
would be a good trade to make.

00:49:14.830 --> 00:49:16.660
You know?

00:49:16.660 --> 00:49:24.180
But if all it takes is a court
order to use a back door,

00:49:24.180 --> 00:49:26.260
then the United
States government

00:49:26.260 --> 00:49:29.960
is not the only government
in the world that has courts,

00:49:29.960 --> 00:49:31.230
or the Swiss government.

00:49:31.230 --> 00:49:32.642
You know?

00:49:32.642 --> 00:49:33.850
What about the North Koreans?

00:49:33.850 --> 00:49:35.790
They have courts.

00:49:35.790 --> 00:49:36.530
The Iranians?

00:49:36.530 --> 00:49:38.740
They have courts.

00:49:38.740 --> 00:49:42.630
China, Russia, they have courts.

00:49:42.630 --> 00:49:46.830
I mean, just because
it's a court order,

00:49:46.830 --> 00:49:48.300
doesn't mean that you're safe.

00:49:48.300 --> 00:49:53.630
A few years ago, you guys-- I
don't know how many of you--

00:49:53.630 --> 00:49:55.040
everybody's so young.

00:49:55.040 --> 00:49:56.800
Maybe you didn't work here then.

00:49:56.800 --> 00:50:00.880
But Google had a big
confrontation with China

00:50:00.880 --> 00:50:03.820
because Google had
built back doors

00:50:03.820 --> 00:50:07.380
into their servers for
law enforcement purposes.

00:50:07.380 --> 00:50:09.880
And the Chinese hijacked
those back doors

00:50:09.880 --> 00:50:12.650
to spy on Chinese dissidents.

00:50:12.650 --> 00:50:15.060
And this resulted
in a confrontation

00:50:15.060 --> 00:50:17.190
between Google and China.

00:50:17.190 --> 00:50:22.700
And if you build in
back doors because you

00:50:22.700 --> 00:50:28.040
think it's only going to be used
for the aforementioned utopian

00:50:28.040 --> 00:50:33.062
wise, true philosopher
king government,

00:50:33.062 --> 00:50:35.270
then you're going to find
that the back door can also

00:50:35.270 --> 00:50:39.520
be used by not so nice people.

00:50:39.520 --> 00:50:45.080
So Silent Phone is
used by Navy SEALs.

00:50:45.080 --> 00:50:50.040
And they use it to go kill
Bin Laden or something,

00:50:50.040 --> 00:50:51.180
whatever they're doing.

00:50:51.180 --> 00:50:53.600
They're using it to
kill bad guys, right?

00:50:53.600 --> 00:50:58.370
And they're not going to use
it if it has a back door.

00:50:58.370 --> 00:51:04.950
So if you're worried
about Islamic extremism,

00:51:04.950 --> 00:51:06.460
and you think, OK
well, we've got

00:51:06.460 --> 00:51:08.580
to have some way to
get into this in case

00:51:08.580 --> 00:51:12.200
Islamic extremists use it,
well, if you put a back door

00:51:12.200 --> 00:51:14.590
in for that purpose, you're
also undermining the guys

00:51:14.590 --> 00:51:18.290
that kill Islamic extremists.

00:51:18.290 --> 00:51:23.060
So you've got to make the
best protections you can

00:51:23.060 --> 00:51:25.770
and try to find some other way
of dealing with the problem.

00:51:25.770 --> 00:51:31.700
Law enforcement is now in a
golden age of surveillance.

00:51:31.700 --> 00:51:33.770
When you compare
what they have now

00:51:33.770 --> 00:51:35.370
with what they had
20 years ago when

00:51:35.370 --> 00:51:38.970
we were fighting the
crypto wars in the 1990s,

00:51:38.970 --> 00:51:41.260
they have it so much better now.

00:51:41.260 --> 00:51:46.490
They have OCR to scan the
license plates of cars

00:51:46.490 --> 00:51:50.450
from traffic cameras so they
can see all the cars traveling

00:51:50.450 --> 00:51:50.950
everywhere.

00:51:50.950 --> 00:51:52.160
They know where
everybody is going

00:51:52.160 --> 00:51:53.909
with their cars because
of traffic cameras

00:51:53.909 --> 00:51:55.470
reading license plates.

00:51:55.470 --> 00:51:58.300
They have face
recognition software

00:51:58.300 --> 00:52:01.830
that can look through a
camera on a city street

00:52:01.830 --> 00:52:03.640
and see thousands
of people walking by

00:52:03.640 --> 00:52:07.560
and identify every one
of them, or most of them,

00:52:07.560 --> 00:52:10.120
depending on how far away
they are from the camera.

00:52:10.120 --> 00:52:15.220
And they can see where people
are walking even without cars.

00:52:15.220 --> 00:52:18.680
They have transactional data
from where you eat lunch

00:52:18.680 --> 00:52:20.234
with a credit card.

00:52:20.234 --> 00:52:22.150
Or they can see you
walking in the restaurant.

00:52:22.150 --> 00:52:24.990
They know who you
had lunch with.

00:52:24.990 --> 00:52:28.090
They can see a hotel
and see everybody

00:52:28.090 --> 00:52:29.480
going in and out of the hotel.

00:52:29.480 --> 00:52:34.470
So they know which mistresses
the politicians are sleeping

00:52:34.470 --> 00:52:37.210
with that they're
not married to so

00:52:37.210 --> 00:52:41.280
that those politicians,
opposition politicians,

00:52:41.280 --> 00:52:45.760
can be neutralized
by the incumbency.

00:52:45.760 --> 00:52:47.175
They actually do that in Russia.

00:52:50.490 --> 00:52:52.190
I mean, there was a
prosecutor in Russia

00:52:52.190 --> 00:52:54.260
that was investigating
corruption.

00:52:54.260 --> 00:52:58.700
And he was neutralized by
putting him in a sex scandal

00:52:58.700 --> 00:53:03.800
and getting him out of that.

00:53:03.800 --> 00:53:09.390
You have to recognize that
today's pervasive surveillance

00:53:09.390 --> 00:53:12.820
environment is so much
more powerful, so much more

00:53:12.820 --> 00:53:16.720
complete and sweeping and
breathtaking in its scope,

00:53:16.720 --> 00:53:20.820
that law enforcement has it like
they've never had it before.

00:53:20.820 --> 00:53:23.970
And they're complaining
about going dark.

00:53:23.970 --> 00:53:26.330
What that means,
really, is that there's

00:53:26.330 --> 00:53:31.850
a few black pixels in
this vast 4K display

00:53:31.850 --> 00:53:33.900
of a big picture they now have.

00:53:33.900 --> 00:53:36.960
And they've got a few
tiny little black pixels

00:53:36.960 --> 00:53:38.130
that are dark.

00:53:38.130 --> 00:53:40.650
They're not going dark.

00:53:40.650 --> 00:53:44.880
They have a couple
of missing pixels.

00:53:44.880 --> 00:53:47.150
And for them to
demand that we hand

00:53:47.150 --> 00:53:51.652
over those last few pixels,
it's going to hurt everybody.

00:53:51.652 --> 00:53:53.860
And it's going to make it
impossible to have any kind

00:53:53.860 --> 00:53:55.370
of political opposition.

00:53:55.370 --> 00:53:57.500
You think that it's
safe to set it up

00:53:57.500 --> 00:54:00.950
because maybe it's OK to have a
government to have surveillance

00:54:00.950 --> 00:54:01.590
capability.

00:54:01.590 --> 00:54:03.980
But what happens
in a democracy when

00:54:03.980 --> 00:54:10.720
you elect someone that is an
absolute nightmare to elect?

00:54:10.720 --> 00:54:13.150
[LAUGHTER]

00:54:15.150 --> 00:54:17.286
Then it's the end of
the American experiment.

00:54:19.890 --> 00:54:21.170
AUDIENCE: Point well made.

00:54:21.170 --> 00:54:21.450
PHIL ZIMMERMANN: Yeah.

00:54:21.450 --> 00:54:22.050
AUDIENCE: Thank you.

00:54:22.050 --> 00:54:22.925
SPEAKER 1: Thank you.

00:54:22.925 --> 00:54:24.430
Unfortunately, we
have to stop here,

00:54:24.430 --> 00:54:28.870
at least so that my colleagues
can close the meeting.

00:54:28.870 --> 00:54:31.015
PHIL ZIMMERMANN: Yeah.

00:54:31.015 --> 00:54:32.140
SPEAKER 1: We'll be around.

00:54:32.140 --> 00:54:32.700
PHIL ZIMMERMANN: OK, yeah.

00:54:32.700 --> 00:54:34.650
SPEAKER 1: And a lot of people
are more curious about it.

00:54:34.650 --> 00:54:35.483
Thank you very much.

00:54:35.483 --> 00:54:38.960
[APPLAUSE]

