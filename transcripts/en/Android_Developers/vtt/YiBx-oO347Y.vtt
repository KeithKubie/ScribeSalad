WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.125
HRISHIKESH ARADHYE: Hi
everyone, my name is Hrishi.

00:00:02.125 --> 00:00:05.020
I'm one of the engineering
directors in the Android

00:00:05.020 --> 00:00:06.960
and the Play teams.

00:00:06.960 --> 00:00:09.690
I honestly feel like I lucked
into one of the coolest jobs

00:00:09.690 --> 00:00:10.750
at Google.

00:00:10.750 --> 00:00:13.470
There's a lot of activity
going on in the space.

00:00:13.470 --> 00:00:16.470
I promised myself a beer
every time someone mentioned

00:00:16.470 --> 00:00:18.780
AI or machine
learning, and it seems

00:00:18.780 --> 00:00:20.280
like at the end of
the day I'm going

00:00:20.280 --> 00:00:25.470
to be very, very drunk at the
rate things are going today.

00:00:25.470 --> 00:00:29.960
So it's no secret that if you've
been following our narrative

00:00:29.960 --> 00:00:33.500
in the last couple of I/Os,
a few hardware announcements,

00:00:33.500 --> 00:00:37.050
that Google's
heavily banking on AI

00:00:37.050 --> 00:00:40.010
and machine learning as one of
the core pillars of our product

00:00:40.010 --> 00:00:42.770
development.

00:00:42.770 --> 00:00:44.510
And there is a reason for that.

00:00:44.510 --> 00:00:46.790
You have heard our
CEO mention before

00:00:46.790 --> 00:00:49.910
that we used to be a
mobile-first company,

00:00:49.910 --> 00:00:51.950
and now we at an
AI-first company.

00:00:51.950 --> 00:00:55.190
And I wanted to give you
some context into how

00:00:55.190 --> 00:00:58.230
we evolved into that vision.

00:00:58.230 --> 00:01:00.860
So come to think about
it, in retrospect,

00:01:00.860 --> 00:01:04.080
it is easy to
imagine what it meant

00:01:04.080 --> 00:01:06.130
to be a mobile-first product.

00:01:06.130 --> 00:01:09.470
A mobile-first product is a
product that is fundamentally

00:01:09.470 --> 00:01:11.840
designed for a small screen.

00:01:11.840 --> 00:01:15.110
It is fundamentally
designed for a product that

00:01:15.110 --> 00:01:17.120
has always-on connectivity.

00:01:17.120 --> 00:01:20.780
It is fundamentally designed
for low-power usage,

00:01:20.780 --> 00:01:23.700
and so on and so forth.

00:01:23.700 --> 00:01:27.320
So we believe that
products of tomorrow

00:01:27.320 --> 00:01:31.490
will take some of these
other things for granted.

00:01:31.490 --> 00:01:33.900
So products of
today, for example,

00:01:33.900 --> 00:01:36.500
it's hard to imagine
an app that is not

00:01:36.500 --> 00:01:39.440
designed with some of the
principles I mentioned

00:01:39.440 --> 00:01:41.150
in the mobile-first column.

00:01:41.150 --> 00:01:43.760
Five years down, I think
products of tomorrow

00:01:43.760 --> 00:01:47.270
will have to have some
of these other factors

00:01:47.270 --> 00:01:49.530
in the AI-first column.

00:01:49.530 --> 00:01:51.740
So products of
tomorrow, we believe,

00:01:51.740 --> 00:01:54.130
will be required
to learn and adapt,

00:01:54.130 --> 00:01:58.070
will be expected to learn
and adapt from user behavior.

00:01:58.070 --> 00:01:59.870
We believe the
products of tomorrow

00:01:59.870 --> 00:02:06.260
should assist the user in doing
that in a [INAUDIBLE] better.

00:02:06.260 --> 00:02:07.910
We believe the
products of tomorrow

00:02:07.910 --> 00:02:11.150
should be conversational
and assistant.

00:02:11.150 --> 00:02:12.830
So products of
tomorrow should be

00:02:12.830 --> 00:02:15.830
able to figure out if
they don't know anything

00:02:15.830 --> 00:02:17.780
and they should be
able to ask the user

00:02:17.780 --> 00:02:20.060
for the right information.

00:02:20.060 --> 00:02:23.240
Products of tomorrow should
also be context aware.

00:02:23.240 --> 00:02:25.490
They should be aware of the
state of the environment.

00:02:25.490 --> 00:02:27.680
They should be aware of
the state of the user.

00:02:27.680 --> 00:02:29.420
And they should be
using that information

00:02:29.420 --> 00:02:31.850
to make that product better.

00:02:31.850 --> 00:02:34.250
And last but not the
least, products of tomorrow

00:02:34.250 --> 00:02:36.890
should be trustworthy
in a fundamental way.

00:02:36.890 --> 00:02:40.560
And that's not just about
safety, security, and privacy,

00:02:40.560 --> 00:02:43.250
but also being able
to deliver performance

00:02:43.250 --> 00:02:48.410
that is reliable on day
one and on day hundred.

00:02:48.410 --> 00:02:50.420
So with that in mind,
machine learning

00:02:50.420 --> 00:02:52.490
is a fundamental
set of algorithms

00:02:52.490 --> 00:02:56.120
that help our products
and our platforms

00:02:56.120 --> 00:02:58.610
get closer to that vision.

00:02:58.610 --> 00:03:00.740
I say here on this slide
that machine learning

00:03:00.740 --> 00:03:04.580
is the science and the art
of making machines learn.

00:03:04.580 --> 00:03:07.430
Your products shouldn't
just be great on day one

00:03:07.430 --> 00:03:09.575
but should be even
better on day hundred.

00:03:09.575 --> 00:03:13.370
And machine learning
will help you get there.

00:03:13.370 --> 00:03:17.410
So as a learning
example, I picked an app,

00:03:17.410 --> 00:03:21.620
a hypothetical app, that will
take a picture of an animal

00:03:21.620 --> 00:03:26.100
and let you classify
it as a dog or a cat.

00:03:26.100 --> 00:03:28.190
And in the world
of yesterday, you

00:03:28.190 --> 00:03:32.480
would develop this system by
designing a bunch of heuristics

00:03:32.480 --> 00:03:35.900
based on human knowledge of
what separates a dog and a cat.

00:03:35.900 --> 00:03:41.320
And you would just encode that
knowledge in a bunch of rules.

00:03:41.320 --> 00:03:44.050
But real world is
much messier than that

00:03:44.050 --> 00:03:45.620
and very unpredictable.

00:03:45.620 --> 00:03:48.070
So your set of rules
might work for 10 images,

00:03:48.070 --> 00:03:49.990
20 images, 100 images.

00:03:49.990 --> 00:03:52.900
But as you start to gather
hundreds of thousands

00:03:52.900 --> 00:03:56.170
of images, all kinds of
corner cases pile up.

00:03:56.170 --> 00:03:58.570
And it becomes really
hard and intractable

00:03:58.570 --> 00:04:01.540
for a rule-based
system to evolve.

00:04:01.540 --> 00:04:04.050
So before I took
this new gig on,

00:04:04.050 --> 00:04:07.240
I ran search and discovery for
the Play Store for four years.

00:04:07.240 --> 00:04:11.500
And even our [INAUDIBLE] stack
started with a rule-based way.

00:04:11.500 --> 00:04:13.930
And as our product
started to grow,

00:04:13.930 --> 00:04:17.959
it became harder and harder
to evolve it over time.

00:04:17.959 --> 00:04:21.279
And so machine learning
comes to the rescue.

00:04:21.279 --> 00:04:23.020
So compared to
rule-based systems,

00:04:23.020 --> 00:04:26.290
machine-learning systems take
a completely different approach

00:04:26.290 --> 00:04:28.490
to solving some of
the same problems.

00:04:28.490 --> 00:04:31.060
So here is a simple
schematic of something

00:04:31.060 --> 00:04:32.560
called a neural network.

00:04:32.560 --> 00:04:34.330
It's called a neural
network because it

00:04:34.330 --> 00:04:37.240
mimics the processing
of our brain

00:04:37.240 --> 00:04:41.350
and tries to achieve it
with software systems.

00:04:41.350 --> 00:04:44.320
So the way this works
is given a picture,

00:04:44.320 --> 00:04:47.080
and given millions
of such pictures,

00:04:47.080 --> 00:04:49.240
it will take the
pixels of that picture

00:04:49.240 --> 00:04:53.770
and then follow through
with layers of computation

00:04:53.770 --> 00:04:55.570
to allow us to
predict at the end

00:04:55.570 --> 00:04:58.810
whether it was a cat or a dog.

00:04:58.810 --> 00:05:00.880
It doesn't start
with a hardcoded set

00:05:00.880 --> 00:05:04.030
of rules that embed our
knowledge about cats and dogs.

00:05:04.030 --> 00:05:08.890
Instead, it learns or relies on
millions of samples and data.

00:05:08.890 --> 00:05:12.280
And with every sample it gets
better and better and better

00:05:12.280 --> 00:05:15.520
at doing that job.

00:05:15.520 --> 00:05:21.330
So back in 2011 on some
of the standard data

00:05:21.330 --> 00:05:23.980
sets around computer
vision, around recognizing

00:05:23.980 --> 00:05:28.630
objects and images, we
had around 26% error rate.

00:05:28.630 --> 00:05:32.620
Compare that error rate
with humans, about 5%.

00:05:32.620 --> 00:05:35.710
So you could imagine
that at that time,

00:05:35.710 --> 00:05:38.860
we would be lucky if we could
classify a picture as indoor

00:05:38.860 --> 00:05:39.850
versus outdoor.

00:05:39.850 --> 00:05:43.000
But we weren't too good
at reliably recognizing

00:05:43.000 --> 00:05:45.220
what's in the picture.

00:05:45.220 --> 00:05:48.670
So today, these systems
based on deep neural networks

00:05:48.670 --> 00:05:51.310
are even better than
human-level performance.

00:05:51.310 --> 00:05:53.140
It's a 3% error rate.

00:05:53.140 --> 00:05:55.780
And perceptually it
feels like we are now

00:05:55.780 --> 00:05:58.870
able to see the world
through machines.

00:05:58.870 --> 00:06:01.630
And that enables a whole
lot of other things,

00:06:01.630 --> 00:06:05.155
other cool things we could
do with software systems.

00:06:05.155 --> 00:06:09.250
And it's not just about labeling
pictures as a cat or dog,

00:06:09.250 --> 00:06:11.620
but we can automatically
caption them

00:06:11.620 --> 00:06:14.590
with really
human-sounding captions.

00:06:14.590 --> 00:06:16.730
So I show some of
the examples here.

00:06:16.730 --> 00:06:19.600
The left hand side top
picture says a close up

00:06:19.600 --> 00:06:22.300
of a child holding
a stuffed animal.

00:06:22.300 --> 00:06:25.870
So if you think about it,
there are many parameters that

00:06:25.870 --> 00:06:27.520
goes into a label like that.

00:06:27.520 --> 00:06:31.270
We not only detect that
there is a young child

00:06:31.270 --> 00:06:33.030
and a stuffed animal
in the picture,

00:06:33.030 --> 00:06:36.810
we detect that the child
is holding the animal

00:06:36.810 --> 00:06:38.050
and that it's a close up.

00:06:38.050 --> 00:06:40.270
So there are multiple
layers of intelligence

00:06:40.270 --> 00:06:43.440
built into a caption like that.

00:06:43.440 --> 00:06:45.420
And there are many
cool examples here

00:06:45.420 --> 00:06:47.680
that really showcase
how the technology has

00:06:47.680 --> 00:06:49.600
evolved over time.

00:06:49.600 --> 00:06:51.520
The scientists in
me would cringe

00:06:51.520 --> 00:06:55.150
if I hadn't put even a
single example of a mislabel.

00:06:55.150 --> 00:06:57.940
You can see that
the bottom row says

00:06:57.940 --> 00:07:01.130
a man flying through the
air riding a snowboard,

00:07:01.130 --> 00:07:02.350
and it's clearly not that.

00:07:02.350 --> 00:07:05.164
So AI systems today
are much better

00:07:05.164 --> 00:07:06.580
compared to where
they used to be,

00:07:06.580 --> 00:07:08.260
but they're still not perfect.

00:07:08.260 --> 00:07:11.170
And any product you
design with AI in mind

00:07:11.170 --> 00:07:13.930
has to be aware of that.

00:07:13.930 --> 00:07:16.130
So the types of
problems ML can solve--

00:07:16.130 --> 00:07:17.940
I want to give
you a quick flavor

00:07:17.940 --> 00:07:20.730
for the types of use cases
you might be able to power

00:07:20.730 --> 00:07:23.540
with ML and AI.

00:07:23.540 --> 00:07:25.520
So the first example
is classification.

00:07:25.520 --> 00:07:27.440
And it's similar to
what I showed before.

00:07:27.440 --> 00:07:30.410
Take a picture, label
it as a cat or dog.

00:07:30.410 --> 00:07:34.100
Take a song, label it as
a pop song or a rock song.

00:07:34.100 --> 00:07:37.880
Or take an app and label
it as a harmful app or not.

00:07:37.880 --> 00:07:41.780
And these are some of the
examples of classification.

00:07:41.780 --> 00:07:47.290
Take an item and label
it within the namespace.

00:07:47.290 --> 00:07:48.870
Another example is prediction.

00:07:48.870 --> 00:07:53.950
So here I show YouTube
recommendations for videos

00:07:53.950 --> 00:07:56.110
to watch if you're
watching this video.

00:07:56.110 --> 00:07:59.530
So machine-learning systems
are getting really better

00:07:59.530 --> 00:08:01.630
at predicting user activity.

00:08:01.630 --> 00:08:05.290
If you watch this video, given
the knowledge of other users

00:08:05.290 --> 00:08:06.880
who watched the
same video before,

00:08:06.880 --> 00:08:10.840
are you able to reliably
predict which video they're

00:08:10.840 --> 00:08:13.440
going to use next?

00:08:13.440 --> 00:08:15.600
And the third example--

00:08:15.600 --> 00:08:19.220
sorry, how do I go back--

00:08:19.220 --> 00:08:21.420
is perception.

00:08:21.420 --> 00:08:23.880
Machine-learning systems
are getting better at not

00:08:23.880 --> 00:08:26.280
just labeling and
predicting but also

00:08:26.280 --> 00:08:29.460
being able to understand
the world through images,

00:08:29.460 --> 00:08:31.380
through sound, through
audio, and through

00:08:31.380 --> 00:08:33.090
natural-language processing.

00:08:33.090 --> 00:08:36.150
Here I show an example
of system integration,

00:08:36.150 --> 00:08:39.840
and I know you'll be hearing
about that through the day.

00:08:39.840 --> 00:08:41.490
So a few examples
of where Google's

00:08:41.490 --> 00:08:44.610
used ML technology over
the few years-- so Google

00:08:44.610 --> 00:08:46.590
has a wide array of products.

00:08:46.590 --> 00:08:50.790
Some of these products, seven
products, are used by a billion

00:08:50.790 --> 00:08:52.980
plus monthly active users a day.

00:08:52.980 --> 00:08:57.420
And many of them fundamentally
use machine learning.

00:08:57.420 --> 00:09:00.030
An example here is Google Lens.

00:09:00.030 --> 00:09:03.660
This is one of the recent
examples of machine learning

00:09:03.660 --> 00:09:07.540
has fundamentally changed the
way products behave today.

00:09:07.540 --> 00:09:10.680
So you are able to not
only detect landmarks

00:09:10.680 --> 00:09:13.050
but are able to do
that in real time

00:09:13.050 --> 00:09:17.490
in the viewfinder of
the camera, and perceive

00:09:17.490 --> 00:09:21.084
the real-time imagery
through machines.

00:09:21.084 --> 00:09:23.625
Next example is machine-learned
personalized recommendations.

00:09:23.625 --> 00:09:28.440
Coby mentioned that ML is used
heavily for recommendations

00:09:28.440 --> 00:09:29.610
on the app store.

00:09:29.610 --> 00:09:32.530
Here I show examples
from YouTube.

00:09:32.530 --> 00:09:34.380
So given your
video-watch history,

00:09:34.380 --> 00:09:39.030
what videos make the
most sense for you?

00:09:39.030 --> 00:09:41.650
Another example is
Google Translate

00:09:41.650 --> 00:09:44.100
where you can look at
the picture in real time,

00:09:44.100 --> 00:09:46.620
detect not only the
text in the picture,

00:09:46.620 --> 00:09:49.530
detect the language it's
in, and able to recognize

00:09:49.530 --> 00:09:52.990
that all in real time.

00:09:52.990 --> 00:09:56.730
Another example is smart
reply in Gmail and Inbox.

00:09:56.730 --> 00:09:58.950
We can process the
text of the message

00:09:58.950 --> 00:10:03.570
and are able to predict what the
likely response is going to be.

00:10:03.570 --> 00:10:06.270
So for someone like me running
from meeting to meeting trying

00:10:06.270 --> 00:10:11.280
to respond to messages on the
staircase, this sort of feature

00:10:11.280 --> 00:10:13.770
is super useful.

00:10:13.770 --> 00:10:16.380
And last but not the
least, this is an example

00:10:16.380 --> 00:10:19.650
where it's not a user-facing
application at all

00:10:19.650 --> 00:10:25.961
but our ability to optimize
back-end processing in data

00:10:25.961 --> 00:10:26.460
centers.

00:10:26.460 --> 00:10:30.150
So using DeepMind AI from
our office in London,

00:10:30.150 --> 00:10:33.570
we were able to reduce our power
usage in Google's data centers

00:10:33.570 --> 00:10:36.930
by up to 40%.

00:10:36.930 --> 00:10:41.040
So Google not only built
some of these products

00:10:41.040 --> 00:10:44.160
but we also have some of
the most-used platforms

00:10:44.160 --> 00:10:45.550
in the world today.

00:10:45.550 --> 00:10:48.030
And it's not sufficient
for our own products

00:10:48.030 --> 00:10:50.070
to get better with AI and ML.

00:10:50.070 --> 00:10:52.410
We also want to
empower all of you

00:10:52.410 --> 00:10:56.950
to use AI and ML in your
own products as well.

00:10:56.950 --> 00:10:59.310
So to do that, we
open sourced some

00:10:59.310 --> 00:11:01.490
of the fundamental
parts of our ML stack

00:11:01.490 --> 00:11:04.900
through TensorFlow
several years ago.

00:11:04.900 --> 00:11:07.830
And this is a repository in
GitHub that anyone of you

00:11:07.830 --> 00:11:10.950
can download and use.

00:11:10.950 --> 00:11:13.680
It's getting huge traction
in the developer community

00:11:13.680 --> 00:11:14.400
already.

00:11:14.400 --> 00:11:18.360
Just in two years this
graph shows the GitHub stars

00:11:18.360 --> 00:11:21.930
for TensorFlow compared to other
such repositories out there.

00:11:21.930 --> 00:11:25.710
And it has just been
exceedingly popular

00:11:25.710 --> 00:11:27.300
and getting used more and more.

00:11:31.220 --> 00:11:32.890
We are not going to
stop there though.

00:11:32.890 --> 00:11:36.530
So TensorFlow, when it was open
sourced a couple of years ago,

00:11:36.530 --> 00:11:39.710
it was fundamentally
designed for server use case.

00:11:39.710 --> 00:11:41.660
And at I/O this
year we announced

00:11:41.660 --> 00:11:43.415
that we are taking
it to work on device.

00:11:43.415 --> 00:11:45.440
So TensorFlow Lite,
which is going

00:11:45.440 --> 00:11:48.530
to be a fast and efficient
version of TensorFlow, going

00:11:48.530 --> 00:11:52.610
to be open sourced this quarter,
will be instance of TensorFlow

00:11:52.610 --> 00:11:56.200
that runs on Android devices.

00:11:56.200 --> 00:11:58.900
And last but not
least, we are not only

00:11:58.900 --> 00:12:02.530
making it possible for
you to use ML libraries

00:12:02.530 --> 00:12:04.750
but we are also
making it possible

00:12:04.750 --> 00:12:08.020
for you to directly access
Google's intelligent APIs.

00:12:08.020 --> 00:12:11.920
So example here is detecting
faces and emotions in faces

00:12:11.920 --> 00:12:15.020
through Google's Cloud ML
APIs and some of the same APIs

00:12:15.020 --> 00:12:19.140
that are available
on device as well.

00:12:19.140 --> 00:12:20.070
So that's it.

00:12:20.070 --> 00:12:22.219
I'll be available for
taking some other questions

00:12:22.219 --> 00:12:23.010
later down the day.

00:12:23.010 --> 00:12:27.270
And I know we have a deeper
dive on ML during the day.

00:12:27.270 --> 00:12:29.110
Thank you all.

