WEBVTT

1
00:00:00.450 --> 00:00:04.530
This is more perfect. I'm Jad Abumrad today a little bit of a departure.

2
00:00:05.100 --> 00:00:06.270
Maybe it's more of an addendum,

3
00:00:06.300 --> 00:00:09.510
so we just released an episode about citizens United,

4
00:00:10.560 --> 00:00:14.230
which is one of the most argued about cases in recent history and this,

5
00:00:14.231 --> 00:00:19.200
this was a case really about the first amendment and whether we should limit the

6
00:00:19.201 --> 00:00:23.550
first amendment in any way. Now, in that case, you had this tension.

7
00:00:23.880 --> 00:00:26.850
You had justice Kennedy who saying, don't touch it, don't touch it,

8
00:00:26.851 --> 00:00:30.510
don't touch it. I don't care if all this money comes into our political system.

9
00:00:31.170 --> 00:00:35.280
Don't touch the first amendment, but you had just a suitor saying,

10
00:00:35.490 --> 00:00:36.450
I don't know,

11
00:00:36.480 --> 00:00:41.480
maybe we should touch it because sometimes your freedom impinges on my equality

12
00:00:43.680 --> 00:00:45.660
and shouldn't those two things be in balance?

13
00:00:46.950 --> 00:00:51.950
It's a fascinating and important conversation and it was one that we were having

14
00:00:52.201 --> 00:00:56.700
internally at the team while we were making that episode and at a certain point

15
00:00:56.701 --> 00:01:01.701
we decided let's actually take that conversation and make a live event around

16
00:01:02.161 --> 00:01:06.120
it. This is something that we, we did a few times in the runup to season two.

17
00:01:06.480 --> 00:01:10.470
We would have these public debates in the WWE NYC green space.

18
00:01:10.830 --> 00:01:15.230
I don't want to play you, uh, some excerpts from that debate, um,

19
00:01:15.470 --> 00:01:19.530
that we had about free speech and we did it sort of classic debate format.

20
00:01:19.531 --> 00:01:22.860
One person took one side, one person took another, and our questions were,

21
00:01:22.890 --> 00:01:27.060
should the government do more in this day and age to limit free speech?

22
00:01:27.061 --> 00:01:30.750
Should Twitter do more? Should Facebook do more?

23
00:01:30.751 --> 00:01:34.890
Should all of us collectively be doing more to stop dangerous,

24
00:01:34.891 --> 00:01:35.820
hateful speech?

25
00:01:36.000 --> 00:01:40.080
Or is this precisely the moment when we have to stand up louder and prouder and

26
00:01:40.081 --> 00:01:44.010
protect that speech even if we hate it? So before we got into it,

27
00:01:44.610 --> 00:01:46.170
I took a poll of the audience.

28
00:01:48.110 --> 00:01:52.640
Everybody who thinks that your right to free speech, especially online,

29
00:01:52.641 --> 00:01:54.890
okay people say some bad things, fine,

30
00:01:55.370 --> 00:02:00.370
but your right to free speech should remain pretty much unlimited.

31
00:02:01.130 --> 00:02:03.560
Those of you who feel that way make some noise.

32
00:02:06.140 --> 00:02:06.850
<v 1>[inaudible]</v>

33
00:02:06.850 --> 00:02:09.230
<v 0>all right, you guys are, you guys are thunders over here. Let's do it one.</v>

34
00:02:09.270 --> 00:02:11.850
Let's just do one, one more time so I can just get a sort of more accurate.

35
00:02:11.950 --> 00:02:13.850
For those of you who don't think it should be limited, go.

36
00:02:14.190 --> 00:02:15.023
<v 1>Yeah.</v>

37
00:02:16.090 --> 00:02:18.490
<v 0>Okay. Now those of you on the flip side,</v>

38
00:02:18.491 --> 00:02:23.200
those of you think there should be some clear hard limits, easy,

39
00:02:23.380 --> 00:02:24.070
easy.

40
00:02:24.070 --> 00:02:28.450
Those of you think there should be some clear limits on what you can say online.

41
00:02:28.451 --> 00:02:29.350
Make some noise.

42
00:02:31.650 --> 00:02:32.000
<v 1>[inaudible]</v>

43
00:02:32.000 --> 00:02:35.370
<v 0>all right. Okay. That gives us a good sense of where we're starting. All right,</v>

44
00:02:35.371 --> 00:02:37.680
so let me introduce our debaters for round one. The question is,

45
00:02:37.681 --> 00:02:39.930
should the government limit online free speech?

46
00:02:39.931 --> 00:02:43.910
Taking one side of that question is Mr Ellie Mystil,

47
00:02:44.270 --> 00:02:45.210
our legal editor,

48
00:02:45.740 --> 00:02:50.270
<v 1>perfect. [inaudible] editor above La</v>

49
00:02:50.950 --> 00:02:51.591
<v 0>site for legal news.</v>

50
00:02:51.591 --> 00:02:55.280
He is on one side of the stage and have the question on the other.

51
00:02:55.580 --> 00:02:59.560
Mr Ken White, a First Amendment litigator criminal defense attorney Brown,

52
00:02:59.561 --> 00:03:04.270
white and Osborne in Los Angeles. He has joined us here from the left coast.

53
00:03:04.690 --> 00:03:06.340
He's a former federal prosecutor.

54
00:03:06.341 --> 00:03:08.740
He runs the free speech and criminal justice blog,

55
00:03:09.190 --> 00:03:10.360
[inaudible] dot com give it up for Ken.

56
00:03:13.330 --> 00:03:14.850
<v 1>All right,</v>

57
00:03:16.220 --> 00:03:19.190
<v 0>let us begin. We'll start with you, Ellie. Uh,</v>

58
00:03:19.280 --> 00:03:21.290
is there something wrong with the First Amendment, would you say?

59
00:03:21.380 --> 00:03:24.080
<v 2>Yeah. No, I don't have a problem with the first amendment.</v>

60
00:03:24.081 --> 00:03:26.750
It was a beautiful thing written for white people who wanted to overthrow the

61
00:03:26.751 --> 00:03:27.584
government. It's fine.

62
00:03:29.240 --> 00:03:33.230
I have a problem with absolute absoluteness who wants to elevate threats,

63
00:03:33.290 --> 00:03:37.490
harassment and calls for genocide to the level of a secret. Right.

64
00:03:37.970 --> 00:03:42.140
I do not think that the first amendment prohibits us from preventing a Nazi from

65
00:03:42.141 --> 00:03:46.430
getting a permit to rally any more than I would think that the second amendment

66
00:03:46.431 --> 00:03:50.810
prevents us from having a sociopath not get a gun permit. Okay.

67
00:03:51.230 --> 00:03:56.230
Absolutism is absolutely wrong on this.

68
00:03:57.760 --> 00:04:01.270
<v 1>Okay. Let me smell strong beginning. Ken, what do you think?</v>

69
00:04:01.690 --> 00:04:04.270
<v 3>Well, I don't know what Absolut is. Ellie is talking about,</v>

70
00:04:04.271 --> 00:04:09.271
the last one I know was Hugo black and he died in 1971 we have well established

71
00:04:09.790 --> 00:04:14.260
narrow exceptions to the First Amendment and they are narrow for a reason.

72
00:04:14.320 --> 00:04:19.180
We got them narrowed on the backs of the powerless being suppressed by the

73
00:04:19.181 --> 00:04:20.014
powerful.

74
00:04:20.050 --> 00:04:23.980
All of the types of restrictions that Ellie would like are ones that have

75
00:04:23.981 --> 00:04:28.570
historically been used against communists, against Labor protestors,

76
00:04:28.750 --> 00:04:32.560
against war protestors, against minorities, and everyone else.

77
00:04:32.890 --> 00:04:36.940
The Nazis aren't the ones in danger from the types of restrictions that Ellie is

78
00:04:36.941 --> 00:04:37.990
suggesting. He'd like,

79
00:04:38.160 --> 00:04:41.030
<v 0>okay, there are the two basic positions.</v>

80
00:04:43.200 --> 00:04:47.970
Let's get the debate started. All right, Ellie,

81
00:04:47.971 --> 00:04:51.840
start, start us off. Explain why you think that hateful speech,

82
00:04:51.870 --> 00:04:54.900
fake news shouldn't be protected by the first amendment.

83
00:04:55.480 --> 00:05:00.290
<v 2>Ken just admitted, just agreed that we already regulate speech at some level,</v>

84
00:05:00.500 --> 00:05:02.300
so really all we're debating about tonight.

85
00:05:02.301 --> 00:05:05.660
The only thing that's even up for debate is where we want to draw that line.

86
00:05:06.080 --> 00:05:09.860
Ken would draw that line so it protects Nazis.

87
00:05:10.310 --> 00:05:15.110
I would draw that line so it protects us from the Nazis.

88
00:05:16.100 --> 00:05:19.610
Let's start with a pretty simple example. Fire

89
00:05:21.430 --> 00:05:23.960
kidding. There's no actual fire. I'm sure you've all heard that.

90
00:05:23.961 --> 00:05:27.440
The thing that you can say is that you can't shout fire on the crowded theater,

91
00:05:27.680 --> 00:05:32.680
but actually under our current laws I probably can because our current standard

92
00:05:32.721 --> 00:05:37.721
is that what is unprotected are things that lead to direct incitement of

93
00:05:38.270 --> 00:05:41.540
imminent lawless action. That's a very high bar,

94
00:05:41.660 --> 00:05:43.340
so I can probably say fire.

95
00:05:43.341 --> 00:05:47.900
What I probably can say is fire kill who you must to survive.

96
00:05:49.340 --> 00:05:50.840
That would probably get me in trouble.

97
00:05:51.740 --> 00:05:56.090
But the fire analogy comes from an older standard older than the one that I just

98
00:05:56.091 --> 00:05:58.820
quoted. It comes Oliver Wendell Holmes,

99
00:05:58.821 --> 00:06:02.150
who some of you might've heard of and his standard when he used the,

100
00:06:02.151 --> 00:06:05.510
you can't falsely shout fire in a crowded theater analogy.

101
00:06:05.660 --> 00:06:10.660
His standard was false and dangerous speech that is false and dangerous is not

102
00:06:12.231 --> 00:06:15.200
protected by the constitution. I think that's where the line is.

103
00:06:15.290 --> 00:06:16.880
I think that's an eminently reasonable line.

104
00:06:16.910 --> 00:06:20.330
I think that we had 150 years of a free republic with that line.

105
00:06:20.840 --> 00:06:25.840
So I want the line where dangerous lies are not protected by the constitution.

106
00:06:27.250 --> 00:06:30.280
<v 3>I don't want the government deciding what's a line of what's true.</v>

107
00:06:30.281 --> 00:06:31.091
May I remind you,

108
00:06:31.091 --> 00:06:35.020
we are currently led by a president who thinks that global warming is a Chinese

109
00:06:35.021 --> 00:06:39.610
hoax to corner the tungsten market and that's why I don't want the government

110
00:06:39.611 --> 00:06:44.290
deciding what to suppress based on its decision about what is true or not.

111
00:06:45.070 --> 00:06:45.903
Now,

112
00:06:46.760 --> 00:06:51.100
Ellie refers to the fire in the crowded theater just as home's famous quote.

113
00:06:51.340 --> 00:06:54.460
Let's remember what he was talking about. He was using that quote,

114
00:06:54.461 --> 00:06:59.440
you can't shout fire in a crowded theater to justify jailing a man who is

115
00:06:59.441 --> 00:07:03.730
protesting World War II by handing out flyers suggesting that people resist the

116
00:07:03.731 --> 00:07:07.870
draft. That was the clear danger that the government saw. Now,

117
00:07:07.871 --> 00:07:12.040
if you don't think that it's plausible that the government would be suppressing

118
00:07:12.041 --> 00:07:14.710
the same type of speech. Now, if you gave it the power,

119
00:07:14.711 --> 00:07:17.530
if you handed it to them out of fear of Nazis,

120
00:07:17.890 --> 00:07:21.370
then just look at what happened after the protest this last year,

121
00:07:21.790 --> 00:07:24.220
the outright and neo-nazis rose.

122
00:07:24.221 --> 00:07:28.450
There were massive protests in response and are largely Republican dominated.

123
00:07:28.451 --> 00:07:33.451
State legislatures leaped into action and in 17 places they proposed heavily

124
00:07:34.390 --> 00:07:38.800
punitive anti protest bills, including for charming examples,

125
00:07:39.100 --> 00:07:42.820
making it easier for you to get off if you run over a protestor in your car.

126
00:07:43.420 --> 00:07:47.050
That's what the government does with the power to suppress speech.

127
00:07:47.260 --> 00:07:49.540
When you let the government decide what's true,

128
00:07:49.670 --> 00:07:53.630
<v 2>I think you just proved that our current first amendment standard doesn't do</v>

129
00:07:53.690 --> 00:07:58.130
bull to actually protect protesters. All it does is protect Nazis.

130
00:07:58.280 --> 00:08:00.080
You want to talk about the Oliver Wendell Holmes Skates?

131
00:08:00.230 --> 00:08:03.620
Let's talk about where our current standard comes from. It's relatively recent.

132
00:08:03.700 --> 00:08:07.280
In 1969 Brandenburg v Ohio. Now, what was that case?

133
00:08:07.310 --> 00:08:10.580
I said 1969 you probably thought, oh, it was probably like civil rights and,

134
00:08:10.910 --> 00:08:13.850
yeah, and they were making it. No, it was for clansmen.

135
00:08:14.000 --> 00:08:18.410
Brandenburg was a Klansman. He was all making clan statements.

136
00:08:18.560 --> 00:08:21.140
Somebody arrested his ass for being a Klansman.

137
00:08:21.230 --> 00:08:25.070
He got convicted for inciting violence and the court said, Eh,

138
00:08:25.580 --> 00:08:26.660
he's just the Klansman.

139
00:08:26.870 --> 00:08:31.520
We really need a new standard that protects the right of Klansmen to threatened

140
00:08:31.521 --> 00:08:33.890
black people in 1969

141
00:08:34.230 --> 00:08:37.080
<v 3>but you see Ellie, you know that that's not the right case.</v>

142
00:08:37.081 --> 00:08:40.680
That's the one that's best for your argument. The right case is 12 years.

143
00:08:41.000 --> 00:08:44.640
That means the right case is 12 years earlier,

144
00:08:44.700 --> 00:08:46.530
Yates versus United States.

145
00:08:46.920 --> 00:08:51.920
People convicted for becoming members of the Communist Party under the theory

146
00:08:52.200 --> 00:08:57.060
that some ideas can be punished as clear and danger even when there is no

147
00:08:57.061 --> 00:08:59.670
imminent advocacy of wrongdoing.

148
00:09:00.210 --> 00:09:03.090
Yates built the wall that eventually Brandon Burke completed.

149
00:09:04.200 --> 00:09:07.500
Brandenburgs the outlier Yates is the one that shows how the power is

150
00:09:07.501 --> 00:09:08.880
consistently used by the governor.

151
00:09:08.950 --> 00:09:11.830
<v 2>Can you explain to me a standard that allows me to stop plantsman cause that's</v>

152
00:09:11.831 --> 00:09:12.430
what I want.

153
00:09:12.430 --> 00:09:15.850
Like if you can explain to me how I could make Klansman not faint in a field,

154
00:09:15.880 --> 00:09:17.860
then I think we're going to agree more than we disagree.

155
00:09:18.040 --> 00:09:22.300
But it's a misnomer to suggest that the first amendment is here to protect

156
00:09:22.301 --> 00:09:23.890
minorities. Are you kidding me?

157
00:09:24.040 --> 00:09:27.790
The constitution to even think about black people until the 13th amendment.

158
00:09:27.791 --> 00:09:28.780
I think as we all know,

159
00:09:28.850 --> 00:09:32.420
<v 0>so, okay. You're saying that you would like to change the standards,</v>

160
00:09:32.421 --> 00:09:35.840
so that will help me understand. So what would you do? The standards. Okay, so,

161
00:09:35.841 --> 00:09:39.680
so what was your, for people, how would you, how, what would the standard be?

162
00:09:39.790 --> 00:09:43.840
<v 2>I can give you an example. The president is a Kenyan that's false,</v>

163
00:09:43.841 --> 00:09:47.560
but that's not particularly dangerous. And so we can let that kind of slide,

164
00:09:47.561 --> 00:09:51.930
right? Um, Hillary Clinton is running a pedophile ring out of a pizza shop.

165
00:09:52.660 --> 00:09:54.670
Do not pass. Go, do not collect $200.

166
00:09:54.671 --> 00:09:57.310
That is both false and demonstrably dangerous.

167
00:09:57.680 --> 00:10:00.490
<v 0>Wait, okay. But, but those, those are two very clear examples, but the,</v>

168
00:10:00.520 --> 00:10:04.240
the idea of falseness and danger can get pretty squishy.

169
00:10:04.750 --> 00:10:07.150
I'm going to sugar camp. Can I call up an example? If you get,

170
00:10:07.151 --> 00:10:11.080
if you guys don't mind. So, uh, the daily stormer, which is a,

171
00:10:11.081 --> 00:10:15.910
a very popular new Nazi site, there was a situation where they basically took a,

172
00:10:15.911 --> 00:10:20.200
a Jewish woman, a real estate agent. Uh, that's, that's the image right there.

173
00:10:20.201 --> 00:10:23.560
You can see it on, on the screens and they superimpose it on image of Auschwitz.

174
00:10:23.830 --> 00:10:26.950
They published her name, they published her kids. Uh,

175
00:10:26.951 --> 00:10:29.830
they said hateful things like we will drive you to suicide.

176
00:10:29.831 --> 00:10:32.530
They call the phrase sort of troll off on her.

177
00:10:33.310 --> 00:10:37.270
Does that qualify for you and does it qualify for you? Can, I mean,

178
00:10:37.271 --> 00:10:38.560
would you limit that kind of speech?

179
00:10:38.790 --> 00:10:42.540
<v 3>I think a lot of the comments sent to her were true threats.</v>

180
00:10:42.810 --> 00:10:46.590
That is a reasonable person would see them as statements of actual intent to do

181
00:10:46.591 --> 00:10:47.280
her harm.

182
00:10:47.280 --> 00:10:51.180
I think that some of the speech about her meets the incitement standard that

183
00:10:51.300 --> 00:10:55.320
it's intended to and likely cause imminent lawless action against her.

184
00:10:55.590 --> 00:10:57.270
But ideas,

185
00:10:57.480 --> 00:11:02.460
however hateful can't be true or false and it's not for the government to

186
00:11:02.461 --> 00:11:05.970
regulate whether ideas or opinions are true or false

187
00:11:06.570 --> 00:11:09.430
<v 2>ideas can be coupled. Nope. Nope, nope, nope. That is how we got here.</v>

188
00:11:09.460 --> 00:11:14.350
Ideas can be true or false. Climate Change, real slow idea. Climate Change,

189
00:11:14.351 --> 00:11:15.910
not real false idea.

190
00:11:15.911 --> 00:11:18.400
We can make these distinctions and I don't think that we need to.

191
00:11:18.700 --> 00:11:21.640
Your standard requires, and I, and I have, unfortunately,

192
00:11:21.641 --> 00:11:23.620
because I am black on the Internet,

193
00:11:23.800 --> 00:11:27.610
I haven't unfortunately had to deal with some true threats,

194
00:11:27.611 --> 00:11:31.750
some not true threats, some trying to wrestle with this issue.

195
00:11:31.751 --> 00:11:34.170
When I go to the cops to try to ask for protection,

196
00:11:34.370 --> 00:11:37.630
I'm trying to wrestle with this issue of what's actually protected speech and

197
00:11:37.631 --> 00:11:39.100
what's actually not protected speech.

198
00:11:39.310 --> 00:11:42.700
And my problem with the current standard is that it basically waits until they

199
00:11:42.701 --> 00:11:45.070
start shooting at me before they stop them.

200
00:11:45.550 --> 00:11:47.560
I want to stop them before they start shooting.

201
00:11:47.561 --> 00:11:51.340
I want to stop them before they start driving their cars into crowded protesters

202
00:11:51.430 --> 00:11:54.160
because by then it's too late. I want them to stop

203
00:11:54.160 --> 00:11:54.580
<v 3>too.</v>

204
00:11:54.580 --> 00:11:59.200
But here's the problem with the history of America being what it is with the

205
00:11:59.201 --> 00:12:01.570
power having been used in the past, being what it is.

206
00:12:01.870 --> 00:12:05.860
What possesses you to think that if you give this broader power to attack speech

207
00:12:05.940 --> 00:12:08.230
of the government, it's going to be used the way you want it to be.

208
00:12:13.480 --> 00:12:13.720
<v 1>[inaudible].</v>

209
00:12:13.720 --> 00:12:16.240
<v 3>I'd rather have this, the Bain 2020. Okay.</v>

210
00:12:18.960 --> 00:12:19.710
It's a date.

211
00:12:19.710 --> 00:12:23.270
<v 0>All right. Now you've heard, uh, Ellie and Ken's points. The question is,</v>

212
00:12:23.271 --> 00:12:25.520
did you change your mind?

213
00:12:25.760 --> 00:12:29.750
Who thinks the government should limit what we say online?

214
00:12:29.840 --> 00:12:30.673
Let's hear some noise.

215
00:12:33.040 --> 00:12:33.873
<v 1>Okay,</v>

216
00:12:34.810 --> 00:12:39.810
<v 0>let me get those of you who actually leaned farther in that direction over the</v>

217
00:12:39.851 --> 00:12:41.800
course of this argument. Let me hear from you guys.

218
00:12:45.660 --> 00:12:49.170
Golf claps. You've got a few. You've got a few tips. Uh,

219
00:12:49.171 --> 00:12:52.980
those of you who do not think there should be limits place from the group

220
00:12:53.490 --> 00:12:54.330
<v 1>by US online.</v>

221
00:12:59.660 --> 00:13:03.960
<v 0>Uh, I think we may have a winner for the first round. Uh,</v>

222
00:13:03.970 --> 00:13:06.540
I'm going to declare that you can. White are the winner

223
00:13:07.310 --> 00:13:11.340
<v 1>for the first round. Give it up for Ken White Person Amendment Attorney,</v>

224
00:13:11.940 --> 00:13:14.760
former federal prosecutor and founder of [inaudible] Dot Com.

225
00:13:15.270 --> 00:13:16.290
Thank you for joining us again.

226
00:13:24.120 --> 00:13:27.790
<v 4>Okay, so coming up, we're gonna shift the question a little bit.</v>

227
00:13:28.180 --> 00:13:32.440
Instead of asking, what should the government do about free speech?

228
00:13:32.441 --> 00:13:35.050
You don't limit it or not. We're going to ask what your Twitter do.

229
00:13:35.051 --> 00:13:39.340
What should Facebook do? You know with all the fake news that's happening,

230
00:13:39.341 --> 00:13:41.170
all the hate speech that's coalescing online,

231
00:13:41.950 --> 00:13:45.250
should they limit free speech more than they are?

232
00:13:46.360 --> 00:13:49.870
That is coming up after the break. This is more perfect. I'm chat out. Boom,

233
00:13:49.871 --> 00:13:50.704
rod, stay with us.

234
00:13:59.910 --> 00:14:00.743
<v 1>[inaudible]</v>

235
00:14:01.420 --> 00:14:02.253
<v 4>[inaudible]</v>

236
00:14:04.490 --> 00:14:05.323
<v 1>[inaudible]</v>

237
00:14:13.180 --> 00:14:15.310
<v 0>more perfect is supported by ZipRecruiter.</v>

238
00:14:15.340 --> 00:14:19.690
The smartest way to hire quality talent fast with ZipRecruiter,

239
00:14:19.691 --> 00:14:23.920
you can post your job to 100 plus job boards with just one click.

240
00:14:24.250 --> 00:14:28.090
Then let ZipRecruiter's powerful technology match your job to the right

241
00:14:28.091 --> 00:14:32.530
candidates and use their simple dashboard to find your perfect hire. In fact,

242
00:14:32.860 --> 00:14:37.240
80% of employers who post on ZipRecruiter get a quality candidate through the

243
00:14:37.241 --> 00:14:38.650
site within one day.

244
00:14:39.040 --> 00:14:43.210
Try It for free at ziprecruiter.com/more perfect. That zip

245
00:14:44.920 --> 00:14:45.753
recruiter.com/more perfect.

246
00:14:46.780 --> 00:14:50.430
<v 1>Hey, it's called Washington from snap, snap,</v>

247
00:14:50.431 --> 00:14:53.660
duck live walks Nashville Wyman theater Friday,

248
00:14:53.670 --> 00:14:58.070
March 16th and I'm bringing the best and cause in the world last Friday.

249
00:14:58.470 --> 00:15:02.360
Laugh some more amazing night out and yes, she's coming.

250
00:15:02.690 --> 00:15:04.850
The funniest woman in the world, Jen Kober.

251
00:15:05.600 --> 00:15:10.550
I do my hung in the lady forest, Jen POBA rocks a brand new story.

252
00:15:10.940 --> 00:15:13.460
Get tickets at snap judgment. That'll watch it.

253
00:15:13.910 --> 00:15:17.030
I've never gotten applause for it before. If you guys could call my mom,

254
00:15:17.031 --> 00:15:18.800
that'd be awesome. She's still pissed.

255
00:15:19.870 --> 00:15:24.770
<v 0>[inaudible] this is more perfect. I'm Chad, I boom, rod,</v>

256
00:15:25.040 --> 00:15:30.020
let's get back to our debate. Our free speech debate at the w NYC green space.

257
00:15:31.130 --> 00:15:33.170
Okay, so round two,

258
00:15:33.440 --> 00:15:36.260
we're going to take that same basic question that we asked in round one,

259
00:15:36.261 --> 00:15:37.460
but now we're going to transpose it.

260
00:15:37.880 --> 00:15:40.220
Whatever we think about the first amendment,

261
00:15:40.340 --> 00:15:42.950
it does place limits on the government,

262
00:15:43.310 --> 00:15:47.030
but not so much on Twitter or Facebook. So the question is,

263
00:15:47.780 --> 00:15:52.640
should Twitter and Facebook or other social media companies severely limit

264
00:15:52.641 --> 00:15:56.450
online speech or shouldn't they?

265
00:15:57.340 --> 00:15:59.960
I want to pull you guys for it just again, so we have a, a,

266
00:15:59.961 --> 00:16:03.710
a baseline to start from. Those of you people watching on Facebook,

267
00:16:04.580 --> 00:16:09.140
do you think the site of which you are on right now should aggressively limit

268
00:16:09.760 --> 00:16:14.240
this speech that you might type, uh, take, take the online poll,

269
00:16:14.720 --> 00:16:16.500
those of you in the audience, same question. Uh,

270
00:16:16.520 --> 00:16:20.330
should Facebook and Twitter be allowed to severely limit online speech?

271
00:16:20.331 --> 00:16:21.410
Define it as you will.

272
00:16:26.970 --> 00:16:27.140
<v 1>[inaudible].</v>

273
00:16:27.140 --> 00:16:28.940
<v 0>Okay. Those of you who think Hell No.</v>

274
00:16:29.570 --> 00:16:30.403
<v 1>Yeah.</v>

275
00:16:33.170 --> 00:16:34.090
<v 0>All right. That's,</v>

276
00:16:34.091 --> 00:16:38.110
I guess I get a kind of a sort of mixed sense of where we're at in the audience.

277
00:16:38.111 --> 00:16:38.411
Okay.

278
00:16:38.411 --> 00:16:43.090
So here to debate this topic with Elliot is Corrine McSherry legal director of

279
00:16:43.091 --> 00:16:44.680
the Electronic Frontier Foundation,

280
00:16:44.681 --> 00:16:47.440
which is committed to defending civil liberties in a digital world.

281
00:16:47.441 --> 00:16:48.274
Give it up for her.

282
00:16:51.290 --> 00:16:53.880
<v 1>All right. So</v>

283
00:16:54.980 --> 00:16:56.270
<v 0>Karen, let's start with you. What,</v>

284
00:16:56.330 --> 00:17:00.620
what do you think about the prospect of a Twitter or a Facebook stepping in to

285
00:17:00.621 --> 00:17:02.720
take down lies and take down hate speech?

286
00:17:03.390 --> 00:17:08.390
<v 5>So I think it's a very dangerous path that unfortunately we're already well</v>

287
00:17:08.731 --> 00:17:09.360
along.

288
00:17:09.360 --> 00:17:12.720
I think in moments of crisis and I think we're in a moment of crisis right now.

289
00:17:12.840 --> 00:17:17.840
We look to simple solutions for very complex problems and we are often sorry.

290
00:17:18.660 --> 00:17:21.420
And I think that is where we are right now.

291
00:17:21.570 --> 00:17:25.680
The Internet grew up the way it did for mostly good,

292
00:17:25.740 --> 00:17:30.740
I would argue because the platforms and the intermediaries mostly stayed

293
00:17:31.290 --> 00:17:36.000
neutral. If we have a world in which Facebook, Twitter, Google,

294
00:17:36.060 --> 00:17:37.080
Instagram,

295
00:17:37.140 --> 00:17:40.590
put themselves in the position of a court and decide what speech should be up,

296
00:17:40.770 --> 00:17:41.880
what speed shouldn't,

297
00:17:42.240 --> 00:17:45.510
we're going to walk down a dangerous path because of those decisions.

298
00:17:45.540 --> 00:17:50.540
Those tactics will inevitably be used against speech that we would support for

299
00:17:51.781 --> 00:17:55.530
one thing. They will be inevitably used eventually by governments.

300
00:17:55.531 --> 00:17:57.660
Private censorship does not stay private.

301
00:17:57.840 --> 00:18:01.410
It becomes public censorship almost inevitably,

302
00:18:01.560 --> 00:18:04.080
and the third reason is really practical.

303
00:18:04.290 --> 00:18:08.500
They're already doing it and they're doing it badly. All kinds of losses,

304
00:18:08.800 --> 00:18:10.860
<v 2>which is being taken down every day.</v>

305
00:18:11.130 --> 00:18:16.020
Google and Facebook can't save us from the Nazis. We have to do it. Okay,

306
00:18:16.050 --> 00:18:19.650
thank you Corrine. Ellie, what do you think? Yeah.

307
00:18:19.710 --> 00:18:22.910
The First Amendment does not apply to Twitter or Facebook.

308
00:18:22.970 --> 00:18:26.550
Anybody who tells you that they have a constitutional right to say what they

309
00:18:26.551 --> 00:18:30.960
want on Twitter is an idiot. The Twitter twirls want,

310
00:18:31.200 --> 00:18:36.120
they don't just want free speech, they want consequence free speech.

311
00:18:36.210 --> 00:18:40.440
They want to be able to say they're viral trash and still keep their jobs and

312
00:18:40.441 --> 00:18:45.150
still keep their homes. It's still get the girl, screw these people. All right,

313
00:18:45.330 --> 00:18:49.020
we should have Twitter at least at the level of a jets game.

314
00:18:51.250 --> 00:18:53.910
All right. Those are the basic sides.

315
00:18:54.270 --> 00:18:56.400
Let's start the debate.

316
00:18:59.200 --> 00:19:03.890
All right, Korean, kick us off. Okay, so the problems

317
00:19:04.160 --> 00:19:06.380
<v 5>you're are legion and almost start with the ones that I,</v>

318
00:19:06.381 --> 00:19:08.270
that I just touched on briefly before.

319
00:19:08.480 --> 00:19:12.680
The reality is that we can all target people that we hate right now,

320
00:19:12.860 --> 00:19:16.580
but if we think that the rules that Twitter and Facebook and all those guys are

321
00:19:16.581 --> 00:19:20.060
going to come up with aren't going to be used against speech that we support,

322
00:19:20.180 --> 00:19:23.420
we are foolish. It's already happening. Community standards,

323
00:19:23.421 --> 00:19:26.240
complaints are used against valuable speech all the time.

324
00:19:26.241 --> 00:19:29.690
I know because I hear about it everyday in my job.

325
00:19:30.290 --> 00:19:33.770
Then the related problem to that is when you get your lawful speech taken down,

326
00:19:33.920 --> 00:19:36.890
you don't have any options. You don't know how to get your stuff put back up.

327
00:19:36.920 --> 00:19:39.980
So we have courts, but we don't have a right of appeal.

328
00:19:40.130 --> 00:19:41.300
We don't have any challenge.

329
00:19:41.450 --> 00:19:44.090
These platforms have the right to host any speech they want.

330
00:19:44.150 --> 00:19:47.870
They actually have the First Amendment right to host any speech they want,

331
00:19:48.140 --> 00:19:52.490
but I think as users, we want them to use that right wisely.

332
00:19:52.550 --> 00:19:54.260
That's not happening, right?

333
00:19:54.800 --> 00:19:57.910
<v 2>No. As a user, I want them to stop Nazis. Okay.</v>

334
00:19:58.100 --> 00:19:59.550
That's really all I'm concerned about.

335
00:19:59.700 --> 00:20:02.880
I want them to find a Nazi and stop them from expressing,

336
00:20:03.120 --> 00:20:07.890
expressing their hate on Twitter. They can't. They can't. That's foolish.

337
00:20:07.950 --> 00:20:12.840
No, sorry. Yes. Goodbye.

338
00:20:12.900 --> 00:20:15.400
Here's one. You know what? I know the kid,

339
00:20:15.820 --> 00:20:18.430
<v 5>they're trying and they're failing over and over.</v>

340
00:20:18.431 --> 00:20:22.120
They cannot tell the difference between hate speech and reporting on hate speech

341
00:20:22.480 --> 00:20:26.110
until the counts get taken down and suspended when they're doing perfectly

342
00:20:26.200 --> 00:20:27.033
lawful.

343
00:20:27.410 --> 00:20:31.430
<v 2>One of the reasons why this is so important that we demand a better from</v>

344
00:20:31.431 --> 00:20:33.050
Facebook, from Twitter, from Reddit,

345
00:20:33.230 --> 00:20:37.520
is that the reason why we're seeing so many more Nazis now is because these

346
00:20:37.521 --> 00:20:39.680
platforms have allowed them to organize.

347
00:20:39.860 --> 00:20:44.860
There was a reason why the Klan was on the decline 20 years ago because you,

348
00:20:46.251 --> 00:20:49.960
because wearing hood and going out to meet your friends in the middle of a field

349
00:20:49.961 --> 00:20:53.560
like Brandenburg did wasn't really how the modern society was going.

350
00:20:53.680 --> 00:20:57.040
But then Twitter and Facebook and these fights and reddit came along and now

351
00:20:57.041 --> 00:21:00.880
they have a way to talk and talk to each other and realize that, no,

352
00:21:00.881 --> 00:21:04.240
I actually hate by people too. Oh, so do I? Yeah, let's hang out. No,

353
00:21:04.300 --> 00:21:05.830
screw these people. There's no,

354
00:21:05.860 --> 00:21:09.670
there's no constitutional reason why Twitter should allow them to exist or

355
00:21:09.671 --> 00:21:10.540
Facebook or whatever.

356
00:21:10.780 --> 00:21:13.900
There is no business reason why Twitter or Facebook or whatever should allow

357
00:21:13.901 --> 00:21:16.570
these people to exist. Get them the F out.

358
00:21:16.650 --> 00:21:19.460
<v 0>You know, one of the things I think about is one of the things we heard, uh,</v>

359
00:21:19.530 --> 00:21:22.110
in the wake of Charlottesville was that a lot of these folks got radicalized

360
00:21:22.111 --> 00:21:26.310
online. So why would the prospect of them getting radicalized online?

361
00:21:26.311 --> 00:21:30.150
What would balance that out in terms of the failure that these sites are doing?

362
00:21:30.151 --> 00:21:31.620
I'm curious to hear you talk more about that.

363
00:21:31.770 --> 00:21:34.500
<v 5>Okay. So a couple things I do just want to respond to this real question.</v>

364
00:21:34.620 --> 00:21:38.520
My view is if white supremacists and clansmen and Nazis are organizing,

365
00:21:38.550 --> 00:21:42.630
I way prefer they were doing it out in public where I can see them and I can

366
00:21:42.631 --> 00:21:44.190
challenge them and I can respond to them.

367
00:21:44.400 --> 00:21:47.610
And law enforcement will say the exact same thing.

368
00:21:47.640 --> 00:21:51.330
People who fight terrorism say it's much better for the, for the, you know,

369
00:21:51.331 --> 00:21:54.780
the people to speaking publicly for the radicals would be radicalizing where you

370
00:21:54.781 --> 00:21:58.590
can see them, they're going to organize anyway. Okay.

371
00:21:58.710 --> 00:22:01.300
So would you rather do what they stood in secret or in the open? Yeah,

372
00:22:01.320 --> 00:22:03.930
<v 2>I would rather, I would bet I would rather them do it in secret.</v>

373
00:22:04.020 --> 00:22:07.380
I would actually rather them go and find a, make their own Nazi website. Right.

374
00:22:07.470 --> 00:22:10.500
Make their own Nazi thing. Right. So that when I,

375
00:22:10.560 --> 00:22:12.390
whenever I get Ken to agree with me,

376
00:22:12.480 --> 00:22:15.120
whenever the government is ready to stop these people,

377
00:22:15.180 --> 00:22:18.510
they will have all preregistered, they would've all said, hey,

378
00:22:21.330 --> 00:22:22.700
look@usallnotseemean.com boom and we can go get them.

379
00:22:23.050 --> 00:22:23.501
<v 5>And so great.</v>

380
00:22:23.501 --> 00:22:26.410
So we can continue the silo conversations that we're having right now,

381
00:22:26.411 --> 00:22:29.770
which is a big part of where I ended up in this conversation from Nazis.

382
00:22:29.850 --> 00:22:33.700
I think that that sounds very nice and it's a good talking point,

383
00:22:33.701 --> 00:22:36.640
but in reality I think that's very, very dangerous for our society.

384
00:22:36.641 --> 00:22:39.990
We need people to be talking to each other when they only talk to people.

385
00:22:41.510 --> 00:22:44.500
<v 1>They never turned their minds. Now can you ask more</v>

386
00:22:45.140 --> 00:22:48.080
<v 2>proven time and time again to me not true and again I hate,</v>

387
00:22:48.130 --> 00:22:53.030
I feel like that is such a, a happy clappy white version of this story.

388
00:22:53.060 --> 00:22:55.160
Oh, if we just talked to these people,

389
00:22:55.250 --> 00:22:59.210
we can convince them that maybe black people shouldn't be sent off to prison

390
00:22:59.211 --> 00:23:03.800
camps once or twice and the rest of the time they're running cars and the people

391
00:23:04.130 --> 00:23:05.710
doesn't happen nearly not long.

392
00:23:05.930 --> 00:23:07.790
<v 5>Do you know why we have gay marriage equality now?</v>

393
00:23:07.940 --> 00:23:09.260
Because people talk to each other.

394
00:23:11.170 --> 00:23:12.850
<v 1>It's not the only reason, but it helped. I'll put,</v>

395
00:23:12.860 --> 00:23:15.740
<v 5>I want to answer John's question cause I think what you're asking is for an</v>

396
00:23:15.741 --> 00:23:20.300
example of why I'm worried about how the moderation happened against Ellie's

397
00:23:20.301 --> 00:23:21.500
worry. Yeah. Okay.

398
00:23:21.740 --> 00:23:26.240
So the way that it works now and the way that it's likely to continue to work is

399
00:23:26.430 --> 00:23:30.350
this. So the social media companies employ a combination of humans and mostly

400
00:23:30.351 --> 00:23:34.220
algorithms to try to figure out what's bad speech and what's good speech and

401
00:23:34.221 --> 00:23:38.630
they mess it up. So they'll end up taking down this statement.

402
00:23:38.631 --> 00:23:41.810
All white people are racist as an example of hate speech,

403
00:23:41.811 --> 00:23:46.811
but they won't take down if you might show the one this from a congressman who

404
00:23:47.781 --> 00:23:51.320
said not a single radicalized Islamic suspect should be granted enter measure of

405
00:23:51.321 --> 00:23:54.470
quarter, et Cetera, et cetera. Nasty stuff, right?

406
00:23:54.500 --> 00:23:57.320
They can't tell the difference. And that's what happens.

407
00:23:57.321 --> 00:23:59.360
And there is an a hat tip to propublica.

408
00:23:59.361 --> 00:24:02.090
I hope you guys are all propublica supporters and fans because they're great.

409
00:24:02.330 --> 00:24:06.860
They did a detailed study to look at Facebook's policies and they found out that

410
00:24:06.861 --> 00:24:07.700
among other things,

411
00:24:07.701 --> 00:24:12.560
they're training their moderators to in some instances protect white men over

412
00:24:12.561 --> 00:24:16.310
black children. Yes. That's where we are right now.

413
00:24:16.311 --> 00:24:18.710
That's what we want to endorse. That's what we want to encourage.

414
00:24:18.740 --> 00:24:19.580
I don't think so.

415
00:24:19.620 --> 00:24:23.700
<v 2>I will stipulate that there are many examples of, of them getting it wrong.</v>

416
00:24:23.760 --> 00:24:27.210
They get it wrong and they're not great at this job yet.

417
00:24:27.960 --> 00:24:30.330
But we live in a real world where the actual,

418
00:24:30.331 --> 00:24:31.500
now I'm talking about Twitter cops,

419
00:24:31.560 --> 00:24:36.180
but we live in a world where the actual cops get it wrong every fricking day.

420
00:24:36.300 --> 00:24:38.100
And in my most radical statements,

421
00:24:38.220 --> 00:24:41.490
I'm not saying let's get rid of the cops cause they don't know what they're

422
00:24:41.491 --> 00:24:42.450
doing. No,

423
00:24:42.480 --> 00:24:46.620
I'm saying let's get better cops and for Twitter I'm saying let's get better

424
00:24:46.710 --> 00:24:49.500
Twitter cops. So they don't get it wrong some so many times.

425
00:24:49.650 --> 00:24:52.440
But you want to talk about letting the perfect be the enemy of the good.

426
00:24:52.680 --> 00:24:56.660
Just because Twitter and Facebook have not gotten to the level yet where they're

427
00:24:56.670 --> 00:25:00.570
able to affectively police these people doesn't mean they should just stop

428
00:25:00.571 --> 00:25:01.404
trying.

429
00:25:02.240 --> 00:25:02.961
<v 5>Well, we have,</v>

430
00:25:02.961 --> 00:25:07.700
where we are right now is thousands of accounts are being suspended every day.

431
00:25:07.940 --> 00:25:11.840
Let's just say a relatively small percentage of those are for per perfectly

432
00:25:11.841 --> 00:25:14.540
lawful speech. That's a lot of lawful speech.

433
00:25:14.690 --> 00:25:19.130
That's a lot that we have authorized Twitter and Facebook and everyone else to

434
00:25:19.131 --> 00:25:21.290
take on and encourage them to. And keep in mind.

435
00:25:21.320 --> 00:25:23.000
I want to say one more thing that I said before,

436
00:25:23.001 --> 00:25:26.090
but I want to emphasize it once we start down this path.

437
00:25:26.210 --> 00:25:29.840
If you think that this is gonna stay within the decision makers at Silicon

438
00:25:29.840 --> 00:25:32.630
Valley, you are dreaming. I mean, that's bad enough. I'm not actually sure why.

439
00:25:32.631 --> 00:25:36.290
We all want silicon valley to make decisions about what speech is okay for all

440
00:25:36.291 --> 00:25:39.770
the rest of us. But even that aside, it's not gonna stop there.

441
00:25:39.950 --> 00:25:43.280
Governments are gonna come in when they see that Google, Facebook,

442
00:25:43.281 --> 00:25:46.550
Twitter can easily take down accounts. They're going to say, okay,

443
00:25:46.760 --> 00:25:50.240
could you do that for us? This doesn't stop.

444
00:25:50.330 --> 00:25:53.270
<v 2>Somebody needs to stop these people.</v>

445
00:25:53.271 --> 00:25:56.360
And I refuse to believe that we live in a country where that is impossible.

446
00:25:56.450 --> 00:25:59.600
Let's take a question. Take a question here in the back.

447
00:26:00.200 --> 00:26:00.220
<v 4>Ah,</v>

448
00:26:00.220 --> 00:26:05.220
if Facebook emailed you and said you can be in charge of what's considered,

449
00:26:05.530 --> 00:26:09.640
you know, a speech that is either left up or is taken down, you could build,

450
00:26:09.700 --> 00:26:12.940
you know, whatever team of people, would you accept that?

451
00:26:12.941 --> 00:26:17.140
Would you think that that could create something that you would be satisfied

452
00:26:17.141 --> 00:26:21.930
with or not satisfied with? Oh, if I was queen of the world, Huh?

453
00:26:22.330 --> 00:26:23.440
<v 5>Hard to turn that down.</v>

454
00:26:23.980 --> 00:26:28.690
But I think even I would have trouble in all instances being perfect about what

455
00:26:28.691 --> 00:26:30.940
was, um, lawful speech and what wasn't speech.

456
00:26:30.941 --> 00:26:34.900
But that actually isn't my main concern is that even I could then potentially be

457
00:26:34.901 --> 00:26:39.901
required by a government to then use that algorithm for other purposes.

458
00:26:40.481 --> 00:26:42.940
And that would be really dangerous. But here's the one thing that I would say,

459
00:26:43.110 --> 00:26:44.640
this is where I think we agree,

460
00:26:44.970 --> 00:26:49.970
is that if I was queen of the world and I was rule running any of these

461
00:26:50.581 --> 00:26:51.121
companies,

462
00:26:51.121 --> 00:26:55.920
one of the things I would absolutely do is put in much better processes for

463
00:26:55.921 --> 00:26:59.520
people to appeal, for people to challenge when things are taken down wrong.

464
00:26:59.670 --> 00:27:04.260
This isn't just a speech issue, it's a due process issue because let's face it,

465
00:27:04.740 --> 00:27:07.200
of course these aren't, you know, official government forums.

466
00:27:07.201 --> 00:27:10.380
We all understand that. But nonetheless, this is how we talk to each other.

467
00:27:10.650 --> 00:27:14.430
These are our public spaces. And in those public spaces,

468
00:27:14.431 --> 00:27:16.560
that's really important when your account gets suspended,

469
00:27:16.561 --> 00:27:20.100
when you get taken offline to be able to get back up,

470
00:27:20.101 --> 00:27:23.670
if what you're doing is perfectly legal. And right now the reality is,

471
00:27:23.671 --> 00:27:27.540
and I know this because I hear from people all the time, it's very confusing.

472
00:27:27.541 --> 00:27:29.640
You don't know who to appeal to. You don't know who to,

473
00:27:29.670 --> 00:27:33.030
you don't know why you're taking down half the time and you don't know what to

474
00:27:33.031 --> 00:27:33.864
do.

475
00:27:34.190 --> 00:27:38.970
<v 6>The question on the far right. Hi. Uh, I just wanted to get your opinions on,</v>

476
00:27:39.450 --> 00:27:44.220
um, money because I hear a lot of talk about this being a speech issue or not.

477
00:27:44.221 --> 00:27:46.740
But I think for platforms, the social media platforms,

478
00:27:46.741 --> 00:27:50.880
I think it's really all about money and it's about followers and young kids that

479
00:27:50.881 --> 00:27:53.000
are getting rape threats and um,

480
00:27:53.310 --> 00:27:56.850
threats and that they eventually end in suicide.

481
00:27:56.851 --> 00:27:58.290
I think that this has to do with money.

482
00:27:58.291 --> 00:28:02.460
I think there's a bigger issue here and I just don't hear anyone talking about

483
00:28:02.461 --> 00:28:04.310
it and I just wanted to know what you both thought about that.

484
00:28:04.410 --> 00:28:06.860
<v 5>So I mean I think that that's, that's really a,</v>

485
00:28:06.861 --> 00:28:09.420
a real pressure point cause I think a lot of these companies,

486
00:28:09.421 --> 00:28:13.530
and I think you actually genuinely so feel uncomfortable making money from,

487
00:28:13.980 --> 00:28:16.800
from hate. But unfortunately we still have a problem.

488
00:28:16.801 --> 00:28:20.220
And I'm going to give you an example from an article I just read yesterday. Um,

489
00:28:20.460 --> 00:28:21.480
that's a conversation.

490
00:28:21.481 --> 00:28:25.380
It's a solo piece about Google and how it runs advertising and search and so on

491
00:28:25.620 --> 00:28:28.890
from talking points, memo and talking points. Memo mentioned that you know,

492
00:28:28.891 --> 00:28:32.100
one of the problems that they have because these processes are so opaque,

493
00:28:32.250 --> 00:28:36.270
they survive because of Google advertising them to write and they're legitimate

494
00:28:36.271 --> 00:28:37.770
site trying to do good for the world.

495
00:28:37.771 --> 00:28:39.360
They survived because of Google advertising.

496
00:28:39.570 --> 00:28:43.740
They keep getting penalized for hate speech because they're reporting on hate

497
00:28:43.741 --> 00:28:47.220
speech, specifically Dylan, the Dylan roof situation.

498
00:28:47.490 --> 00:28:50.970
So we all easy to sort of disentangle,

499
00:28:51.280 --> 00:28:53.530
<v 2>but no, it is because we agree that the robots are bad,</v>

500
00:28:53.531 --> 00:28:57.510
but I think that we can all agree that talking points memo is a decent site.

501
00:28:58.090 --> 00:29:02.260
Info wars. On the other hand, if Google and Facebook and whatever,

502
00:29:02.900 --> 00:29:06.970
slam them, Woo hoo, why would that, why would that be so hard? Here's, here's,

503
00:29:06.971 --> 00:29:07.600
here's the other thing.

504
00:29:07.600 --> 00:29:12.490
If you really don't think that we yet have the technology and the resources

505
00:29:12.491 --> 00:29:17.020
necessary in order to police these sites better,

506
00:29:17.200 --> 00:29:19.870
how about we go the other direction? How about we just asked people,

507
00:29:20.350 --> 00:29:22.190
how about you? Just if you, if you're going to,

508
00:29:22.191 --> 00:29:26.560
if you Twitter are going to tell me you can't tell who's threatening to kill me,

509
00:29:26.800 --> 00:29:29.980
just tell me where it is. Just tell me who it is and I will handle it myself.

510
00:29:32.410 --> 00:29:33.610
What's wrong with that?

511
00:29:33.800 --> 00:29:36.170
<v 5>See, now he's just trying to Piss me off. Okay,</v>

512
00:29:38.800 --> 00:29:41.920
so we're talking about is now step further.

513
00:29:41.950 --> 00:29:45.160
It's social media companies and intermediaries. By the way,

514
00:29:45.161 --> 00:29:46.930
all the different people that you interact with,

515
00:29:46.960 --> 00:29:51.160
they take it upon themselves to out you right to pierce your anonymity.

516
00:29:51.400 --> 00:29:54.430
That is profoundly, profoundly dangerous. Anonymity.

517
00:29:54.431 --> 00:29:56.050
Anonymous speech is the most,

518
00:29:56.051 --> 00:29:59.200
probably the most important form of political speech that we have.

519
00:29:59.230 --> 00:30:04.230
The ability to speak specially online without fear of retaliation means that you

520
00:30:04.991 --> 00:30:08.110
have the ability to speak your truth. If we out people,

521
00:30:08.111 --> 00:30:12.640
if we accept that social media companies should be judge and jury over,

522
00:30:12.641 --> 00:30:16.180
that should just expose people to the world without any choice,

523
00:30:16.181 --> 00:30:18.670
without any recourse because once you're out [inaudible]

524
00:30:19.050 --> 00:30:19.350
<v 2>yes,</v>

525
00:30:19.350 --> 00:30:23.700
because they know that we used to have as a society to protect ourselves from

526
00:30:23.701 --> 00:30:25.950
these people, what's called shame.

527
00:30:26.460 --> 00:30:31.230
We could shame them into being part of the herd and if they didn't want to be

528
00:30:31.231 --> 00:30:34.230
part of the herd, we could know who they are and say, Hey, guess what?

529
00:30:34.320 --> 00:30:35.850
You're no longer part of the herd.

530
00:30:35.970 --> 00:30:40.110
Shame is a powerful weapon that we used to have and Twitter is taken away,

531
00:30:40.530 --> 00:30:44.460
taken away from us. And that is why these people are allowed to multiply.

532
00:30:44.650 --> 00:30:48.470
<v 5>That weapon was also used to persecute minorities all over the [inaudible]</v>

533
00:30:48.600 --> 00:30:52.910
<v 2>and everything was always used to persecute minorities. At some point in mind,</v>

534
00:30:53.080 --> 00:30:56.490
the fact that something has been used to persecute minorities doesn't mean that

535
00:30:56.491 --> 00:30:58.680
it can't also be used to stop Nazis.

536
00:30:58.681 --> 00:31:02.550
That's just the clocks were used to persecute minorities when they weren't paid

537
00:31:02.551 --> 00:31:06.420
by the hour we're calling me. Hello. Good thing. The one thing we have

538
00:31:06.560 --> 00:31:10.290
<v 5>always understood in this country, and this is before the first amendment,</v>

539
00:31:10.560 --> 00:31:13.080
is the importance of anonymous speech.

540
00:31:13.340 --> 00:31:14.840
<v 7>Right. Let me just jump in for a second. We have a,</v>

541
00:31:14.841 --> 00:31:18.180
we have a question here on the right. I just wanted to say that like, um,

542
00:31:18.980 --> 00:31:23.270
someone says something about is there a moral reason that Twitter or the

543
00:31:23.271 --> 00:31:26.060
government should, uh, lean towards free speech.

544
00:31:26.420 --> 00:31:31.420
And I personally am someone who used to have a port views and I was raised as

545
00:31:31.521 --> 00:31:33.110
fundamental Christian as you could get.

546
00:31:33.200 --> 00:31:37.260
And my views about gay people had I spoken them on the Internet probably would

547
00:31:37.580 --> 00:31:41.990
have put off some hate speech alarms and it was not shaming.

548
00:31:42.230 --> 00:31:46.280
That changed my mind. I encountered people who were engaging,

549
00:31:46.550 --> 00:31:50.540
who treated me like a person, even though I had back then there've been Twitter.

550
00:31:50.541 --> 00:31:54.230
I would have been a troll and it changed my mind and I don't know if you guys

551
00:31:54.231 --> 00:31:55.790
are familiar with the Westboro Baptist church.

552
00:31:55.791 --> 00:31:58.130
They fought a supreme court case in one.

553
00:31:58.670 --> 00:32:03.650
They have really the worst views of anyone I any group that considers himself

554
00:32:03.651 --> 00:32:07.700
Christian that I can think of and their person who ran their Twitter is a friend

555
00:32:07.701 --> 00:32:09.410
of mine, Megan Phelps Roper.

556
00:32:09.980 --> 00:32:14.660
She has this great story about how using Twitter to essentially like spread

557
00:32:14.661 --> 00:32:19.550
terrible hate speech saying things like thank God for aids for killing gay

558
00:32:19.551 --> 00:32:20.384
people,

559
00:32:20.540 --> 00:32:23.840
but it was through Twitter and through the arguments she got in and then through

560
00:32:23.841 --> 00:32:28.310
the relationships that she got in that she found a way out of that bubble she

561
00:32:28.311 --> 00:32:32.540
lived in and now is out in the world doing amazing work. If,

562
00:32:32.570 --> 00:32:33.740
if what you want,

563
00:32:34.190 --> 00:32:38.300
Ellie happens that troll that you want to shut up that Klansman,

564
00:32:38.301 --> 00:32:41.780
you want to get rid, he doesn't go away. The, the,

565
00:32:41.781 --> 00:32:46.370
the mold grows in the shadow and it's, it's only in the sunshine. You know,

566
00:32:46.371 --> 00:32:47.060
it's only,

567
00:32:47.060 --> 00:32:50.030
it's only when you get it out in the open and we have these conversations and

568
00:32:50.031 --> 00:32:54.380
like as a former believer in some of this stuff like don't lose heart.

569
00:32:54.381 --> 00:32:57.230
Like we can have our minds changed and like we can,

570
00:32:57.231 --> 00:33:00.740
we can be convinced of the truth.

571
00:33:05.310 --> 00:33:05.770
<v 1>[inaudible]</v>

572
00:33:05.770 --> 00:33:09.170
<v 2>[inaudible] story and I'm very glad that some that you were able to, to,</v>

573
00:33:09.220 --> 00:33:12.130
to get to where you are. Um, however,

574
00:33:14.770 --> 00:33:19.510
turns out that I believed what you want me to believe for good. Oh,

575
00:33:19.511 --> 00:33:22.210
I don't know, 28, 29 years of my life,

576
00:33:22.690 --> 00:33:24.520
I am a 40 year old black man.

577
00:33:24.550 --> 00:33:29.550
I am sick of being the educational PBS afterschool special for racist white

578
00:33:30.581 --> 00:33:31.120
people.

579
00:33:31.120 --> 00:33:35.020
Gay people are sick of being the ABC after school special for white people.

580
00:33:35.320 --> 00:33:38.230
Women are sick of being the afterschool special,

581
00:33:38.680 --> 00:33:41.530
trying to teach the white man why they also should have rights.

582
00:33:41.680 --> 00:33:46.480
It is simply no longer acceptable for you to expect other people just trying to

583
00:33:46.481 --> 00:33:49.960
go about posting their dinner recipes on Facebook.

584
00:33:50.110 --> 00:33:55.110
It's ridiculous for you to think that we sit still have the burden of educating

585
00:33:55.841 --> 00:33:56.620
you.

586
00:33:56.620 --> 00:34:01.620
You should go get educated somewhere that can't be on us all the time and I'm

587
00:34:01.931 --> 00:34:04.870
willing to do it. I'm willing to do it here. I'm willing to,

588
00:34:05.080 --> 00:34:07.810
I'm willing to do it in, in, in, in public. I am actually,

589
00:34:07.811 --> 00:34:11.800
I'm leaving to go to a bar and have a drink with people that I can't stand,

590
00:34:12.280 --> 00:34:16.180
but at some point when I just want to like get on Facebook and see the met

591
00:34:16.181 --> 00:34:20.490
score, I shouldn't have to hear your bullshit. Okay.

592
00:34:21.380 --> 00:34:26.200
I don't actually think that was what he was saying at all. Entirely positive.

593
00:34:26.201 --> 00:34:27.700
Someone should say that with a microphone.

594
00:34:30.280 --> 00:34:34.810
I think he was just saying silos bad, but that's what I'm saying.

595
00:34:35.610 --> 00:34:37.120
[inaudible] is what you're saying. Silos are bad.

596
00:34:37.240 --> 00:34:41.260
We should all be together and then then no, I think that, no, I think,

597
00:34:41.270 --> 00:34:45.670
I think we don't talk to each other. Nobody's mind ever changes.

598
00:34:48.220 --> 00:34:50.900
<v 4>All right. I'm going to jump in now. I think a, I think anyone,</v>

599
00:34:51.250 --> 00:34:54.850
currently you've done all they can to persuade you guys, uh,

600
00:34:55.090 --> 00:34:58.750
who thinks that Twitter and Facebook and such should take a strong hand in

601
00:34:58.751 --> 00:35:01.150
severely limiting online speech. Those are you think so.

602
00:35:04.750 --> 00:35:05.570
<v 1>[inaudible]</v>

603
00:35:05.570 --> 00:35:09.110
<v 4>those of you who disagree with the Asshole, clap into your left,</v>

604
00:35:10.040 --> 00:35:10.873
make some noise.

605
00:35:15.820 --> 00:35:16.010
<v 1>[inaudible]</v>

606
00:35:16.010 --> 00:35:17.980
<v 4>I believe that means that you are</v>

607
00:35:29.390 --> 00:35:29.510
<v 1>[inaudible]</v>

608
00:35:29.510 --> 00:35:31.440
<v 4>thank you to our debaters, Ellie [inaudible].</v>

609
00:35:31.450 --> 00:35:34.880
More perfect legal editor and executive editor at above the law.

610
00:35:35.360 --> 00:35:39.240
Thanks to Kerryn McSherry from the frontier foundation and Ken White from Pope

611
00:35:39.241 --> 00:35:40.110
pat.com.

612
00:35:40.530 --> 00:35:44.200
This episode was produced with Elaine Chin and the very excellent folks at wny

613
00:35:44.430 --> 00:35:48.360
C's green space. We had mixing help this week from Louie Mitchell Supreme Court.

614
00:35:48.361 --> 00:35:49.280
Audio is from OAA,

615
00:35:49.290 --> 00:35:52.650
a free law project in collaboration with the legal information institute at

616
00:35:52.651 --> 00:35:53.460
Cornell.

617
00:35:53.460 --> 00:35:56.370
Leadership support for more perfect is provided by the Joyce Foundation.

618
00:35:56.580 --> 00:36:00.000
Additional funding is provided by the Charles Evans Hughes Memorial Foundation.

619
00:36:01.380 --> 00:36:02.010
See you next week.

