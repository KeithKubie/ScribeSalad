WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.460
[Music]

00:00:06.460 --> 00:00:06.470
[Music]
 

00:00:06.470 --> 00:00:10.310
[Music]
hello everyone welcome to the talk my

00:00:10.310 --> 00:00:10.320
hello everyone welcome to the talk my
 

00:00:10.320 --> 00:00:12.770
hello everyone welcome to the talk my
name is dawn Chen I'm a tech lead of MLK

00:00:12.770 --> 00:00:12.780
name is dawn Chen I'm a tech lead of MLK
 

00:00:12.780 --> 00:00:14.030
name is dawn Chen I'm a tech lead of MLK
team at Google

00:00:14.030 --> 00:00:14.040
team at Google
 

00:00:14.040 --> 00:00:16.630
team at Google
I'm here today to talk about ml kit

00:00:16.630 --> 00:00:16.640
I'm here today to talk about ml kit
 

00:00:16.640 --> 00:00:20.390
I'm here today to talk about ml kit
Google's machine learning SDK for mobile

00:00:20.390 --> 00:00:20.400
Google's machine learning SDK for mobile
 

00:00:20.400 --> 00:00:23.720
Google's machine learning SDK for mobile
I would provide overview of what MLK

00:00:23.720 --> 00:00:23.730
I would provide overview of what MLK
 

00:00:23.730 --> 00:00:26.509
I would provide overview of what MLK
does and also what's new since its

00:00:26.509 --> 00:00:26.519
does and also what's new since its
 

00:00:26.519 --> 00:00:29.450
does and also what's new since its
inception six months ago I also share

00:00:29.450 --> 00:00:29.460
inception six months ago I also share
 

00:00:29.460 --> 00:00:31.990
inception six months ago I also share
some tips and the best practices to

00:00:31.990 --> 00:00:32.000
some tips and the best practices to
 

00:00:32.000 --> 00:00:35.900
some tips and the best practices to
improve performance accuracy reduce size

00:00:35.900 --> 00:00:35.910
improve performance accuracy reduce size
 

00:00:35.910 --> 00:00:39.440
improve performance accuracy reduce size
and few other things in the end I will

00:00:39.440 --> 00:00:39.450
and few other things in the end I will
 

00:00:39.450 --> 00:00:44.930
and few other things in the end I will
talk about what we're working on two

00:00:44.930 --> 00:00:44.940
talk about what we're working on two
 

00:00:44.940 --> 00:00:48.260
talk about what we're working on two
years ago Google CEO sundar Pichai said

00:00:48.260 --> 00:00:48.270
years ago Google CEO sundar Pichai said
 

00:00:48.270 --> 00:00:51.500
years ago Google CEO sundar Pichai said
we'll move from mobile first to AI first

00:00:51.500 --> 00:00:51.510
we'll move from mobile first to AI first
 

00:00:51.510 --> 00:00:55.130
we'll move from mobile first to AI first
world their intersection of these two

00:00:55.130 --> 00:00:55.140
world their intersection of these two
 

00:00:55.140 --> 00:00:58.479
world their intersection of these two
worlds means machine learning on mobile

00:00:58.479 --> 00:00:58.489
worlds means machine learning on mobile
 

00:00:58.489 --> 00:01:01.610
worlds means machine learning on mobile
in recent years more and more mobile

00:01:01.610 --> 00:01:01.620
in recent years more and more mobile
 

00:01:01.620 --> 00:01:03.260
in recent years more and more mobile
apps are using machine learning to

00:01:03.260 --> 00:01:03.270
apps are using machine learning to
 

00:01:03.270 --> 00:01:05.890
apps are using machine learning to
produce fascinating user experiences

00:01:05.890 --> 00:01:05.900
produce fascinating user experiences
 

00:01:05.900 --> 00:01:08.480
produce fascinating user experiences
with smartphones becoming increasingly

00:01:08.480 --> 00:01:08.490
with smartphones becoming increasingly
 

00:01:08.490 --> 00:01:11.090
with smartphones becoming increasingly
powerful and capable more and more

00:01:11.090 --> 00:01:11.100
powerful and capable more and more
 

00:01:11.100 --> 00:01:12.770
powerful and capable more and more
machine learning logic is shifting from

00:01:12.770 --> 00:01:12.780
machine learning logic is shifting from
 

00:01:12.780 --> 00:01:15.080
machine learning logic is shifting from
the server running the cloud to the

00:01:15.080 --> 00:01:15.090
the server running the cloud to the
 

00:01:15.090 --> 00:01:17.410
the server running the cloud to the
mobile device in your pocket

00:01:17.410 --> 00:01:17.420
mobile device in your pocket
 

00:01:17.420 --> 00:01:19.969
mobile device in your pocket
Randi own device mention learning has

00:01:19.969 --> 00:01:19.979
Randi own device mention learning has
 

00:01:19.979 --> 00:01:23.179
Randi own device mention learning has
many advantages its fast does not it'll

00:01:23.179 --> 00:01:23.189
many advantages its fast does not it'll
 

00:01:23.189 --> 00:01:25.460
many advantages its fast does not it'll
send very expensive RPC calls and in

00:01:25.460 --> 00:01:25.470
send very expensive RPC calls and in
 

00:01:25.470 --> 00:01:27.980
send very expensive RPC calls and in
carloon air or latency it also runs

00:01:27.980 --> 00:01:27.990
carloon air or latency it also runs
 

00:01:27.990 --> 00:01:30.730
carloon air or latency it also runs
anytime anywhere with and without

00:01:30.730 --> 00:01:30.740
anytime anywhere with and without
 

00:01:30.740 --> 00:01:34.609
anytime anywhere with and without
network connectivity it also provides

00:01:34.609 --> 00:01:34.619
network connectivity it also provides
 

00:01:34.619 --> 00:01:37.130
network connectivity it also provides
better protection for user privacy since

00:01:37.130 --> 00:01:37.140
better protection for user privacy since
 

00:01:37.140 --> 00:01:39.020
better protection for user privacy since
the data does not have to leave the

00:01:39.020 --> 00:01:39.030
the data does not have to leave the
 

00:01:39.030 --> 00:01:42.469
the data does not have to leave the
device let me take a quick poll here how

00:01:42.469 --> 00:01:42.479
device let me take a quick poll here how
 

00:01:42.479 --> 00:01:43.999
device let me take a quick poll here how
many of you traveled from outside

00:01:43.999 --> 00:01:44.009
many of you traveled from outside
 

00:01:44.009 --> 00:01:48.080
many of you traveled from outside
California to attend this dev summit Wow

00:01:48.080 --> 00:01:48.090
California to attend this dev summit Wow
 

00:01:48.090 --> 00:01:50.410
California to attend this dev summit Wow
welcome welcome to a Silicon Valley I

00:01:50.410 --> 00:01:50.420
welcome welcome to a Silicon Valley I
 

00:01:50.420 --> 00:01:53.120
welcome welcome to a Silicon Valley I
hope you get a chance to visit Conan

00:01:53.120 --> 00:01:53.130
hope you get a chance to visit Conan
 

00:01:53.130 --> 00:01:55.700
hope you get a chance to visit Conan
Gate Bridge Fisherman's Wharf and also

00:01:55.700 --> 00:01:55.710
Gate Bridge Fisherman's Wharf and also
 

00:01:55.710 --> 00:01:57.800
Gate Bridge Fisherman's Wharf and also
enjoy some good food at the local

00:01:57.800 --> 00:01:57.810
enjoy some good food at the local
 

00:01:57.810 --> 00:02:00.590
enjoy some good food at the local
restaurant around the Bay Area talking

00:02:00.590 --> 00:02:00.600
restaurant around the Bay Area talking
 

00:02:00.600 --> 00:02:04.760
restaurant around the Bay Area talking
about food my biological watch tells me

00:02:04.760 --> 00:02:04.770
about food my biological watch tells me
 

00:02:04.770 --> 00:02:08.109
about food my biological watch tells me
is time for dinner so where should I eat

00:02:08.109 --> 00:02:08.119
is time for dinner so where should I eat
 

00:02:08.119 --> 00:02:11.960
is time for dinner so where should I eat
well I'll pull out my phone ask Google

00:02:11.960 --> 00:02:11.970
well I'll pull out my phone ask Google
 

00:02:11.970 --> 00:02:13.040
well I'll pull out my phone ask Google
assistant

00:02:13.040 --> 00:02:13.050
assistant
 

00:02:13.050 --> 00:02:15.740
assistant
hi Google I'm hungry any good restaurant

00:02:15.740 --> 00:02:15.750
hi Google I'm hungry any good restaurant
 

00:02:15.750 --> 00:02:16.900
hi Google I'm hungry any good restaurant
around here

00:02:16.900 --> 00:02:16.910
around here
 

00:02:16.910 --> 00:02:19.460
around here
Google system uses machine learning to

00:02:19.460 --> 00:02:19.470
Google system uses machine learning to
 

00:02:19.470 --> 00:02:21.410
Google system uses machine learning to
understand my question and make

00:02:21.410 --> 00:02:21.420
understand my question and make
 

00:02:21.420 --> 00:02:23.810
understand my question and make
recommendation where to go for dinner

00:02:23.810 --> 00:02:23.820
recommendation where to go for dinner
 

00:02:23.820 --> 00:02:26.600
recommendation where to go for dinner
around area and location I'm currently

00:02:26.600 --> 00:02:26.610
around area and location I'm currently
 

00:02:26.610 --> 00:02:31.550
around area and location I'm currently
at when I travel to a new place I would

00:02:31.550 --> 00:02:31.560
at when I travel to a new place I would
 

00:02:31.560 --> 00:02:35.330
at when I travel to a new place I would
like to take a lot of photos and Google

00:02:35.330 --> 00:02:35.340
like to take a lot of photos and Google
 

00:02:35.340 --> 00:02:37.820
like to take a lot of photos and Google
photos use image recognition to

00:02:37.820 --> 00:02:37.830
photos use image recognition to
 

00:02:37.830 --> 00:02:39.980
photos use image recognition to
understand image content you can

00:02:39.980 --> 00:02:39.990
understand image content you can
 

00:02:39.990 --> 00:02:42.440
understand image content you can
classify photos quickly into a thousands

00:02:42.440 --> 00:02:42.450
classify photos quickly into a thousands
 

00:02:42.450 --> 00:02:45.290
classify photos quickly into a thousands
of categories you can also detect

00:02:45.290 --> 00:02:45.300
of categories you can also detect
 

00:02:45.300 --> 00:02:49.550
of categories you can also detect
individual faces pads objects text in

00:02:49.550 --> 00:02:49.560
individual faces pads objects text in
 

00:02:49.560 --> 00:02:51.740
individual faces pads objects text in
the photo and then make them searchable

00:02:51.740 --> 00:02:51.750
the photo and then make them searchable
 

00:02:51.750 --> 00:02:54.790
the photo and then make them searchable
by keywords or categories later on

00:02:54.790 --> 00:02:54.800
by keywords or categories later on
 

00:02:54.800 --> 00:02:58.940
by keywords or categories later on
mobile device can now run really

00:02:58.940 --> 00:02:58.950
mobile device can now run really
 

00:02:58.950 --> 00:03:00.470
mobile device can now run really
increasingly Suffolk's to machine

00:03:00.470 --> 00:03:00.480
increasingly Suffolk's to machine
 

00:03:00.480 --> 00:03:03.500
increasingly Suffolk's to machine
learning tasks last spring I took my

00:03:03.500 --> 00:03:03.510
learning tasks last spring I took my
 

00:03:03.510 --> 00:03:07.790
learning tasks last spring I took my
family to Tuscany in Italy we drove

00:03:07.790 --> 00:03:07.800
family to Tuscany in Italy we drove
 

00:03:07.800 --> 00:03:10.850
family to Tuscany in Italy we drove
around those beautiful hilltop towns in

00:03:10.850 --> 00:03:10.860
around those beautiful hilltop towns in
 

00:03:10.860 --> 00:03:12.910
around those beautiful hilltop towns in
each of the town there are many signs

00:03:12.910 --> 00:03:12.920
each of the town there are many signs
 

00:03:12.920 --> 00:03:15.920
each of the town there are many signs
but I don't speak Italian unfortunately

00:03:15.920 --> 00:03:15.930
but I don't speak Italian unfortunately
 

00:03:15.930 --> 00:03:20.360
but I don't speak Italian unfortunately
I wish said I do so how do I know what

00:03:20.360 --> 00:03:20.370
I wish said I do so how do I know what
 

00:03:20.370 --> 00:03:21.080
I wish said I do so how do I know what
this means

00:03:21.080 --> 00:03:21.090
this means
 

00:03:21.090 --> 00:03:24.140
this means
here's where the Google Translate came

00:03:24.140 --> 00:03:24.150
here's where the Google Translate came
 

00:03:24.150 --> 00:03:27.140
here's where the Google Translate came
to rescue Google Translate can perform

00:03:27.140 --> 00:03:27.150
to rescue Google Translate can perform
 

00:03:27.150 --> 00:03:28.729
to rescue Google Translate can perform
multiple machine learning tasks in a

00:03:28.729 --> 00:03:28.739
multiple machine learning tasks in a
 

00:03:28.739 --> 00:03:31.580
multiple machine learning tasks in a
single journey when I pull up my phone

00:03:31.580 --> 00:03:31.590
single journey when I pull up my phone
 

00:03:31.590 --> 00:03:34.490
single journey when I pull up my phone
pointing the camera at the sign it will

00:03:34.490 --> 00:03:34.500
pointing the camera at the sign it will
 

00:03:34.500 --> 00:03:36.920
pointing the camera at the sign it will
use optical character recognition to

00:03:36.920 --> 00:03:36.930
use optical character recognition to
 

00:03:36.930 --> 00:03:40.280
use optical character recognition to
detect us text in a sign it will also

00:03:40.280 --> 00:03:40.290
detect us text in a sign it will also
 

00:03:40.290 --> 00:03:42.199
detect us text in a sign it will also
use national and natural language

00:03:42.199 --> 00:03:42.209
use national and natural language
 

00:03:42.209 --> 00:03:44.510
use national and natural language
processing the transits attacks from one

00:03:44.510 --> 00:03:44.520
processing the transits attacks from one
 

00:03:44.520 --> 00:03:47.900
processing the transits attacks from one
language into another finally it will

00:03:47.900 --> 00:03:47.910
language into another finally it will
 

00:03:47.910 --> 00:03:50.390
language into another finally it will
use speech synthesis to convert text

00:03:50.390 --> 00:03:50.400
use speech synthesis to convert text
 

00:03:50.400 --> 00:03:53.180
use speech synthesis to convert text
into voice and using speaker tell me

00:03:53.180 --> 00:03:53.190
into voice and using speaker tell me
 

00:03:53.190 --> 00:03:56.810
into voice and using speaker tell me
what the sign is in my own language all

00:03:56.810 --> 00:03:56.820
what the sign is in my own language all
 

00:03:56.820 --> 00:03:58.840
what the sign is in my own language all
these tasks involve machine learning

00:03:58.840 --> 00:03:58.850
these tasks involve machine learning
 

00:03:58.850 --> 00:04:01.970
these tasks involve machine learning
combined they produce a seamless and a

00:04:01.970 --> 00:04:01.980
combined they produce a seamless and a
 

00:04:01.980 --> 00:04:05.210
combined they produce a seamless and a
powerful user experience this all look

00:04:05.210 --> 00:04:05.220
powerful user experience this all look
 

00:04:05.220 --> 00:04:08.330
powerful user experience this all look
great but as a developer how do I build

00:04:08.330 --> 00:04:08.340
great but as a developer how do I build
 

00:04:08.340 --> 00:04:12.080
great but as a developer how do I build
something like this well it's doable and

00:04:12.080 --> 00:04:12.090
something like this well it's doable and
 

00:04:12.090 --> 00:04:15.890
something like this well it's doable and
not easy machinery offer requires

00:04:15.890 --> 00:04:15.900
not easy machinery offer requires
 

00:04:15.900 --> 00:04:17.900
not easy machinery offer requires
specialized knowledge and the years of

00:04:17.900 --> 00:04:17.910
specialized knowledge and the years of
 

00:04:17.910 --> 00:04:20.570
specialized knowledge and the years of
experience in training and building ML

00:04:20.570 --> 00:04:20.580
experience in training and building ML
 

00:04:20.580 --> 00:04:23.659
experience in training and building ML
models the model training a lot of time

00:04:23.659 --> 00:04:23.669
models the model training a lot of time
 

00:04:23.669 --> 00:04:26.629
models the model training a lot of time
requires a large amount of good

00:04:26.629 --> 00:04:26.639
requires a large amount of good
 

00:04:26.639 --> 00:04:29.989
requires a large amount of good
high-quality data the mobile device hi

00:04:29.989 --> 00:04:29.999
high-quality data the mobile device hi
 

00:04:29.999 --> 00:04:32.330
high-quality data the mobile device hi
Ron Ellison aside it has very limited

00:04:32.330 --> 00:04:32.340
Ron Ellison aside it has very limited
 

00:04:32.340 --> 00:04:35.480
Ron Ellison aside it has very limited
computing power the models running on a

00:04:35.480 --> 00:04:35.490
computing power the models running on a
 

00:04:35.490 --> 00:04:37.640
computing power the models running on a
server in the cloud are often too large

00:04:37.640 --> 00:04:37.650
server in the cloud are often too large
 

00:04:37.650 --> 00:04:40.040
server in the cloud are often too large
or too complex to run directly on a

00:04:40.040 --> 00:04:40.050
or too complex to run directly on a
 

00:04:40.050 --> 00:04:42.409
or too complex to run directly on a
mobile device you need to spend a lot of

00:04:42.409 --> 00:04:42.419
mobile device you need to spend a lot of
 

00:04:42.419 --> 00:04:44.749
mobile device you need to spend a lot of
effort to optimize model for the mobile

00:04:44.749 --> 00:04:44.759
effort to optimize model for the mobile
 

00:04:44.759 --> 00:04:48.429
effort to optimize model for the mobile
usage after finally the app is built

00:04:48.429 --> 00:04:48.439
usage after finally the app is built
 

00:04:48.439 --> 00:04:51.409
usage after finally the app is built
Union worried about how do I deploy how

00:04:51.409 --> 00:04:51.419
Union worried about how do I deploy how
 

00:04:51.419 --> 00:04:53.689
Union worried about how do I deploy how
do I maintain ongoing instrumentation of

00:04:53.689 --> 00:04:53.699
do I maintain ongoing instrumentation of
 

00:04:53.699 --> 00:04:56.200
do I maintain ongoing instrumentation of
the models that becomes another headache

00:04:56.200 --> 00:04:56.210
the models that becomes another headache
 

00:04:56.210 --> 00:05:00.050
the models that becomes another headache
to tackle all this power problems we

00:05:00.050 --> 00:05:00.060
to tackle all this power problems we
 

00:05:00.060 --> 00:05:02.779
to tackle all this power problems we
launched ml kit Google's machine

00:05:02.779 --> 00:05:02.789
launched ml kit Google's machine
 

00:05:02.789 --> 00:05:05.839
launched ml kit Google's machine
learning SDK for mobile which helps the

00:05:05.839 --> 00:05:05.849
learning SDK for mobile which helps the
 

00:05:05.849 --> 00:05:09.409
learning SDK for mobile which helps the
mobile developers build Android and iOS

00:05:09.409 --> 00:05:09.419
mobile developers build Android and iOS
 

00:05:09.419 --> 00:05:12.939
mobile developers build Android and iOS
apps using machine learning technologies

00:05:12.939 --> 00:05:12.949
apps using machine learning technologies
 

00:05:12.949 --> 00:05:16.399
apps using machine learning technologies
ml cadiz aim at making machine learning

00:05:16.399 --> 00:05:16.409
ml cadiz aim at making machine learning
 

00:05:16.409 --> 00:05:19.969
ml cadiz aim at making machine learning
easy for mobile developers just because

00:05:19.969 --> 00:05:19.979
easy for mobile developers just because
 

00:05:19.979 --> 00:05:21.619
easy for mobile developers just because
you want to use machine learning on

00:05:21.619 --> 00:05:21.629
you want to use machine learning on
 

00:05:21.629 --> 00:05:24.379
you want to use machine learning on
mobile it does not mean you need to

00:05:24.379 --> 00:05:24.389
mobile it does not mean you need to
 

00:05:24.389 --> 00:05:26.600
mobile it does not mean you need to
worry about collecting data building

00:05:26.600 --> 00:05:26.610
worry about collecting data building
 

00:05:26.610 --> 00:05:29.350
worry about collecting data building
models training model compression

00:05:29.350 --> 00:05:29.360
models training model compression
 

00:05:29.360 --> 00:05:31.760
models training model compression
optimization hosting deployment

00:05:31.760 --> 00:05:31.770
optimization hosting deployment
 

00:05:31.770 --> 00:05:34.490
optimization hosting deployment
downloading model all this Haddock ml

00:05:34.490 --> 00:05:34.500
downloading model all this Haddock ml
 

00:05:34.500 --> 00:05:38.209
downloading model all this Haddock ml
kid will take care of this for you we

00:05:38.209 --> 00:05:38.219
kid will take care of this for you we
 

00:05:38.219 --> 00:05:41.269
kid will take care of this for you we
provide common turnkey models that work

00:05:41.269 --> 00:05:41.279
provide common turnkey models that work
 

00:05:41.279 --> 00:05:43.879
provide common turnkey models that work
just OtterBox all the models are

00:05:43.879 --> 00:05:43.889
just OtterBox all the models are
 

00:05:43.889 --> 00:05:47.059
just OtterBox all the models are
optimized for speed accuracy as well as

00:05:47.059 --> 00:05:47.069
optimized for speed accuracy as well as
 

00:05:47.069 --> 00:05:50.029
optimized for speed accuracy as well as
efficiency for the model for the mobile

00:05:50.029 --> 00:05:50.039
efficiency for the model for the mobile
 

00:05:50.039 --> 00:05:53.029
efficiency for the model for the mobile
device we provide a one consistent API

00:05:53.029 --> 00:05:53.039
device we provide a one consistent API
 

00:05:53.039 --> 00:05:56.689
device we provide a one consistent API
across both Android and iOS it's very

00:05:56.689 --> 00:05:56.699
across both Android and iOS it's very
 

00:05:56.699 --> 00:05:59.570
across both Android and iOS it's very
easy to integrate ml kit with firebase

00:05:59.570 --> 00:05:59.580
easy to integrate ml kit with firebase
 

00:05:59.580 --> 00:06:03.429
easy to integrate ml kit with firebase
tools like remote config or a be testing

00:06:03.429 --> 00:06:03.439
tools like remote config or a be testing
 

00:06:03.439 --> 00:06:06.050
tools like remote config or a be testing
for commonly needed machine learning

00:06:06.050 --> 00:06:06.060
for commonly needed machine learning
 

00:06:06.060 --> 00:06:09.409
for commonly needed machine learning
tasks we have base api's that come with

00:06:09.409 --> 00:06:09.419
tasks we have base api's that come with
 

00:06:09.419 --> 00:06:11.929
tasks we have base api's that come with
pre-trained google models that work

00:06:11.929 --> 00:06:11.939
pre-trained google models that work
 

00:06:11.939 --> 00:06:14.779
pre-trained google models that work
outer-box currently there are five api's

00:06:14.779 --> 00:06:14.789
outer-box currently there are five api's
 

00:06:14.789 --> 00:06:18.050
outer-box currently there are five api's
we are supporting the test recognition

00:06:18.050 --> 00:06:18.060
we are supporting the test recognition
 

00:06:18.060 --> 00:06:21.110
we are supporting the test recognition
API are supported on both on device and

00:06:21.110 --> 00:06:21.120
API are supported on both on device and
 

00:06:21.120 --> 00:06:23.839
API are supported on both on device and
the cloud the on device API can

00:06:23.839 --> 00:06:23.849
the cloud the on device API can
 

00:06:23.849 --> 00:06:26.809
the cloud the on device API can
recognize Latin characters and the cloud

00:06:26.809 --> 00:06:26.819
recognize Latin characters and the cloud
 

00:06:26.819 --> 00:06:30.529
recognize Latin characters and the cloud
API supports a wide range of languages

00:06:30.529 --> 00:06:30.539
API supports a wide range of languages
 

00:06:30.539 --> 00:06:34.249
API supports a wide range of languages
and special characters face detection is

00:06:34.249 --> 00:06:34.259
and special characters face detection is
 

00:06:34.259 --> 00:06:36.800
and special characters face detection is
another API we support which can be used

00:06:36.800 --> 00:06:36.810
another API we support which can be used
 

00:06:36.810 --> 00:06:39.050
another API we support which can be used
to detect faces in both static image as

00:06:39.050 --> 00:06:39.060
to detect faces in both static image as
 

00:06:39.060 --> 00:06:40.350
to detect faces in both static image as
well as live

00:06:40.350 --> 00:06:40.360
well as live
 

00:06:40.360 --> 00:06:43.170
well as live
video-streaming now we also launched

00:06:43.170 --> 00:06:43.180
video-streaming now we also launched
 

00:06:43.180 --> 00:06:45.990
video-streaming now we also launched
counter detection which can help you to

00:06:45.990 --> 00:06:46.000
counter detection which can help you to
 

00:06:46.000 --> 00:06:48.089
counter detection which can help you to
identify different parts of the face and

00:06:48.089 --> 00:06:48.099
identify different parts of the face and
 

00:06:48.099 --> 00:06:51.469
identify different parts of the face and
you can then apply face masks of users

00:06:51.469 --> 00:06:51.479
you can then apply face masks of users
 

00:06:51.479 --> 00:06:54.659
you can then apply face masks of users
the barcode scanning can be used to

00:06:54.659 --> 00:06:54.669
the barcode scanning can be used to
 

00:06:54.669 --> 00:06:56.550
the barcode scanning can be used to
detect post 1-dimensional in the

00:06:56.550 --> 00:06:56.560
detect post 1-dimensional in the
 

00:06:56.560 --> 00:06:59.219
detect post 1-dimensional in the
two-dimensional barcodes as well as a QR

00:06:59.219 --> 00:06:59.229
two-dimensional barcodes as well as a QR
 

00:06:59.229 --> 00:07:03.270
two-dimensional barcodes as well as a QR
code image labeling API can detect

00:07:03.270 --> 00:07:03.280
code image labeling API can detect
 

00:07:03.280 --> 00:07:05.610
code image labeling API can detect
objects of various entities inside the

00:07:05.610 --> 00:07:05.620
objects of various entities inside the
 

00:07:05.620 --> 00:07:08.879
objects of various entities inside the
photo and for which spore spawn some

00:07:08.879 --> 00:07:08.889
photo and for which spore spawn some
 

00:07:08.889 --> 00:07:11.219
photo and for which spore spawn some
device in the cloud the um device API

00:07:11.219 --> 00:07:11.229
device in the cloud the um device API
 

00:07:11.229 --> 00:07:13.050
device in the cloud the um device API
supports more than 400 labels which

00:07:13.050 --> 00:07:13.060
supports more than 400 labels which
 

00:07:13.060 --> 00:07:14.879
supports more than 400 labels which
covered most of common things you see in

00:07:14.879 --> 00:07:14.889
covered most of common things you see in
 

00:07:14.889 --> 00:07:18.959
covered most of common things you see in
photos well the cloud API can support

00:07:18.959 --> 00:07:18.969
photos well the cloud API can support
 

00:07:18.969 --> 00:07:22.309
photos well the cloud API can support
10,000 labels across many categories

00:07:22.309 --> 00:07:22.319
10,000 labels across many categories
 

00:07:22.319 --> 00:07:25.559
10,000 labels across many categories
finally our landmark API can recognize

00:07:25.559 --> 00:07:25.569
finally our landmark API can recognize
 

00:07:25.569 --> 00:07:27.899
finally our landmark API can recognize
well-known places in the photo like

00:07:27.899 --> 00:07:27.909
well-known places in the photo like
 

00:07:27.909 --> 00:07:32.040
well-known places in the photo like
White House our effort our if this

00:07:32.040 --> 00:07:32.050
White House our effort our if this
 

00:07:32.050 --> 00:07:34.170
White House our effort our if this
pre-trained model tunafish your need and

00:07:34.170 --> 00:07:34.180
pre-trained model tunafish your need and
 

00:07:34.180 --> 00:07:36.830
pre-trained model tunafish your need and
you are an experienced developer with

00:07:36.830 --> 00:07:36.840
you are an experienced developer with
 

00:07:36.840 --> 00:07:38.879
you are an experienced developer with
with that knowledge you know how to

00:07:38.879 --> 00:07:38.889
with that knowledge you know how to
 

00:07:38.889 --> 00:07:41.040
with that knowledge you know how to
build and train models you're more than

00:07:41.040 --> 00:07:41.050
build and train models you're more than
 

00:07:41.050 --> 00:07:43.080
build and train models you're more than
welcome to bring your own custom model

00:07:43.080 --> 00:07:43.090
welcome to bring your own custom model
 

00:07:43.090 --> 00:07:46.469
welcome to bring your own custom model
we rank us models intensive low light as

00:07:46.469 --> 00:07:46.479
we rank us models intensive low light as
 

00:07:46.479 --> 00:07:48.869
we rank us models intensive low light as
you might know tensorflow is an open

00:07:48.869 --> 00:07:48.879
you might know tensorflow is an open
 

00:07:48.879 --> 00:07:50.159
you might know tensorflow is an open
source framework for machine learning

00:07:50.159 --> 00:07:50.169
source framework for machine learning
 

00:07:50.169 --> 00:07:52.320
source framework for machine learning
and hence the flow light is a

00:07:52.320 --> 00:07:52.330
and hence the flow light is a
 

00:07:52.330 --> 00:07:53.839
and hence the flow light is a
lightweight version of tensorflow

00:07:53.839 --> 00:07:53.849
lightweight version of tensorflow
 

00:07:53.849 --> 00:07:57.180
lightweight version of tensorflow
optimized for mobile platforms for

00:07:57.180 --> 00:07:57.190
optimized for mobile platforms for
 

00:07:57.190 --> 00:07:59.040
optimized for mobile platforms for
models trained with tensorflow we

00:07:59.040 --> 00:07:59.050
models trained with tensorflow we
 

00:07:59.050 --> 00:08:01.350
models trained with tensorflow we
provide your tools to convert and

00:08:01.350 --> 00:08:01.360
provide your tools to convert and
 

00:08:01.360 --> 00:08:04.050
provide your tools to convert and
compress into a format compatible with

00:08:04.050 --> 00:08:04.060
compress into a format compatible with
 

00:08:04.060 --> 00:08:06.659
compress into a format compatible with
sensor for light when you're using

00:08:06.659 --> 00:08:06.669
sensor for light when you're using
 

00:08:06.669 --> 00:08:08.159
sensor for light when you're using
custom model you have two options either

00:08:08.159 --> 00:08:08.169
custom model you have two options either
 

00:08:08.169 --> 00:08:11.070
custom model you have two options either
bounded inside your app or hosted in the

00:08:11.070 --> 00:08:11.080
bounded inside your app or hosted in the
 

00:08:11.080 --> 00:08:13.110
bounded inside your app or hosted in the
cloud if you choose the latter option

00:08:13.110 --> 00:08:13.120
cloud if you choose the latter option
 

00:08:13.120 --> 00:08:15.360
cloud if you choose the latter option
the host in the cloud does not mean you

00:08:15.360 --> 00:08:15.370
the host in the cloud does not mean you
 

00:08:15.370 --> 00:08:17.850
the host in the cloud does not mean you
need to build your own cloud server ml

00:08:17.850 --> 00:08:17.860
need to build your own cloud server ml
 

00:08:17.860 --> 00:08:19.680
need to build your own cloud server ml
kit and firebase or provide a way for

00:08:19.680 --> 00:08:19.690
kit and firebase or provide a way for
 

00:08:19.690 --> 00:08:22.499
kit and firebase or provide a way for
for you for for you we will manage the

00:08:22.499 --> 00:08:22.509
for you for for you we will manage the
 

00:08:22.509 --> 00:08:25.019
for you for for you we will manage the
model hosting deployment downloading

00:08:25.019 --> 00:08:25.029
model hosting deployment downloading
 

00:08:25.029 --> 00:08:26.779
model hosting deployment downloading
upgrade as well as the ongoing

00:08:26.779 --> 00:08:26.789
upgrade as well as the ongoing
 

00:08:26.789 --> 00:08:31.260
upgrade as well as the ongoing
experimentations since ml kid was

00:08:31.260 --> 00:08:31.270
experimentations since ml kid was
 

00:08:31.270 --> 00:08:33.870
experimentations since ml kid was
launched six months ago at Google i/o we

00:08:33.870 --> 00:08:33.880
launched six months ago at Google i/o we
 

00:08:33.880 --> 00:08:37.589
launched six months ago at Google i/o we
have made several enhancements first

00:08:37.589 --> 00:08:37.599
have made several enhancements first
 

00:08:37.599 --> 00:08:40.439
have made several enhancements first
we greatly enhanced our face detection

00:08:40.439 --> 00:08:40.449
we greatly enhanced our face detection
 

00:08:40.449 --> 00:08:43.380
we greatly enhanced our face detection
models which is now eighteen times

00:08:43.380 --> 00:08:43.390
models which is now eighteen times
 

00:08:43.390 --> 00:08:46.740
models which is now eighteen times
faster and a 13 to 24 percent more

00:08:46.740 --> 00:08:46.750
faster and a 13 to 24 percent more
 

00:08:46.750 --> 00:08:50.490
faster and a 13 to 24 percent more
accurate we also polished our text

00:08:50.490 --> 00:08:50.500
accurate we also polished our text
 

00:08:50.500 --> 00:08:52.980
accurate we also polished our text
recognition API by making them more

00:08:52.980 --> 00:08:52.990
recognition API by making them more
 

00:08:52.990 --> 00:08:54.210
recognition API by making them more
streamlined

00:08:54.210 --> 00:08:54.220
streamlined
 

00:08:54.220 --> 00:08:56.369
streamlined
consistent across both sound device and

00:08:56.369 --> 00:08:56.379
consistent across both sound device and
 

00:08:56.379 --> 00:09:00.449
consistent across both sound device and
the cloud in addition we launched 133

00:09:00.449 --> 00:09:00.459
the cloud in addition we launched 133
 

00:09:00.459 --> 00:09:04.710
the cloud in addition we launched 133
point face contour detection as shown in

00:09:04.710 --> 00:09:04.720
point face contour detection as shown in
 

00:09:04.720 --> 00:09:07.800
point face contour detection as shown in
this image you can see now you can use

00:09:07.800 --> 00:09:07.810
this image you can see now you can use
 

00:09:07.810 --> 00:09:09.960
this image you can see now you can use
our face count or detection API it will

00:09:09.960 --> 00:09:09.970
our face count or detection API it will
 

00:09:09.970 --> 00:09:11.939
our face count or detection API it will
identify the contours of various parts

00:09:11.939 --> 00:09:11.949
identify the contours of various parts
 

00:09:11.949 --> 00:09:14.879
identify the contours of various parts
of your face or anyone's face in the

00:09:14.879 --> 00:09:14.889
of your face or anyone's face in the
 

00:09:14.889 --> 00:09:17.910
of your face or anyone's face in the
photo and includes the entire face both

00:09:17.910 --> 00:09:17.920
photo and includes the entire face both
 

00:09:17.920 --> 00:09:21.300
photo and includes the entire face both
eyebrows eyes nose and lips this is

00:09:21.300 --> 00:09:21.310
eyebrows eyes nose and lips this is
 

00:09:21.310 --> 00:09:23.999
eyebrows eyes nose and lips this is
where the real-time asks can put a

00:09:23.999 --> 00:09:24.009
where the real-time asks can put a
 

00:09:24.009 --> 00:09:26.850
where the real-time asks can put a
customer faces a customer face mask and

00:09:26.850 --> 00:09:26.860
customer faces a customer face mask and
 

00:09:26.860 --> 00:09:30.840
customer faces a customer face mask and
futures like a goggle or some funny nose

00:09:30.840 --> 00:09:30.850
futures like a goggle or some funny nose
 

00:09:30.850 --> 00:09:34.559
futures like a goggle or some funny nose
on the face and make the mask move waist

00:09:34.559 --> 00:09:34.569
on the face and make the mask move waist
 

00:09:34.569 --> 00:09:39.990
on the face and make the mask move waist
face in a live video streaming next I'm

00:09:39.990 --> 00:09:40.000
face in a live video streaming next I'm
 

00:09:40.000 --> 00:09:42.059
face in a live video streaming next I'm
going to share some tips and a best

00:09:42.059 --> 00:09:42.069
going to share some tips and a best
 

00:09:42.069 --> 00:09:45.300
going to share some tips and a best
practices for how to use ml kit so I can

00:09:45.300 --> 00:09:45.310
practices for how to use ml kit so I can
 

00:09:45.310 --> 00:09:47.490
practices for how to use ml kit so I can
build an impressive mobile apps using

00:09:47.490 --> 00:09:47.500
build an impressive mobile apps using
 

00:09:47.500 --> 00:09:50.100
build an impressive mobile apps using
own device machine-learning first of all

00:09:50.100 --> 00:09:50.110
own device machine-learning first of all
 

00:09:50.110 --> 00:09:51.780
own device machine-learning first of all
I will share a couple tips for achieving

00:09:51.780 --> 00:09:51.790
I will share a couple tips for achieving
 

00:09:51.790 --> 00:09:55.199
I will share a couple tips for achieving
best accuracy there are two things you

00:09:55.199 --> 00:09:55.209
best accuracy there are two things you
 

00:09:55.209 --> 00:09:57.809
best accuracy there are two things you
should make sure one you should take a

00:09:57.809 --> 00:09:57.819
should make sure one you should take a
 

00:09:57.819 --> 00:10:01.259
should make sure one you should take a
very sharp and a well focused image poor

00:10:01.259 --> 00:10:01.269
very sharp and a well focused image poor
 

00:10:01.269 --> 00:10:05.119
very sharp and a well focused image poor
image focus can really hurt the accuracy

00:10:05.119 --> 00:10:05.129
image focus can really hurt the accuracy
 

00:10:05.129 --> 00:10:08.069
image focus can really hurt the accuracy
second you should ensure the options you

00:10:08.069 --> 00:10:08.079
second you should ensure the options you
 

00:10:08.079 --> 00:10:09.660
second you should ensure the options you
want to detect in the image has

00:10:09.660 --> 00:10:09.670
want to detect in the image has
 

00:10:09.670 --> 00:10:12.420
want to detect in the image has
sufficient size for example for face

00:10:12.420 --> 00:10:12.430
sufficient size for example for face
 

00:10:12.430 --> 00:10:14.280
sufficient size for example for face
detection you should have at least 100

00:10:14.280 --> 00:10:14.290
detection you should have at least 100
 

00:10:14.290 --> 00:10:17.730
detection you should have at least 100
by 100 pixels for each face and if you

00:10:17.730 --> 00:10:17.740
by 100 pixels for each face and if you
 

00:10:17.740 --> 00:10:19.619
by 100 pixels for each face and if you
want a counter detection in their selfie

00:10:19.619 --> 00:10:19.629
want a counter detection in their selfie
 

00:10:19.629 --> 00:10:22.559
want a counter detection in their selfie
mode for example then the face should be

00:10:22.559 --> 00:10:22.569
mode for example then the face should be
 

00:10:22.569 --> 00:10:27.799
mode for example then the face should be
200 by 200 pixels for for the text API

00:10:27.799 --> 00:10:27.809
200 by 200 pixels for for the text API
 

00:10:27.809 --> 00:10:31.170
200 by 200 pixels for for the text API
for Latin languages each characters be

00:10:31.170 --> 00:10:31.180
for Latin languages each characters be
 

00:10:31.180 --> 00:10:34.650
for Latin languages each characters be
at least 16 by sitting in in size if you

00:10:34.650 --> 00:10:34.660
at least 16 by sitting in in size if you
 

00:10:34.660 --> 00:10:37.319
at least 16 by sitting in in size if you
use our cloud API to detect and

00:10:37.319 --> 00:10:37.329
use our cloud API to detect and
 

00:10:37.329 --> 00:10:40.319
use our cloud API to detect and
recognize Chinese Japanese and Korean

00:10:40.319 --> 00:10:40.329
recognize Chinese Japanese and Korean
 

00:10:40.329 --> 00:10:42.720
recognize Chinese Japanese and Korean
the each character in those oriental

00:10:42.720 --> 00:10:42.730
the each character in those oriental
 

00:10:42.730 --> 00:10:45.290
the each character in those oriental
language should be at least 24 by 24

00:10:45.290 --> 00:10:45.300
language should be at least 24 by 24
 

00:10:45.300 --> 00:10:47.819
language should be at least 24 by 24
similarly bar code also have the size

00:10:47.819 --> 00:10:47.829
similarly bar code also have the size
 

00:10:47.829 --> 00:10:50.280
similarly bar code also have the size
requirement please check out our online

00:10:50.280 --> 00:10:50.290
requirement please check out our online
 

00:10:50.290 --> 00:10:54.299
requirement please check out our online
documentation for more details machine

00:10:54.299 --> 00:10:54.309
documentation for more details machine
 

00:10:54.309 --> 00:10:56.309
documentation for more details machine
learning and the libraries can be large

00:10:56.309 --> 00:10:56.319
learning and the libraries can be large
 

00:10:56.319 --> 00:10:58.530
learning and the libraries can be large
which can slow down the app download

00:10:58.530 --> 00:10:58.540
which can slow down the app download
 

00:10:58.540 --> 00:11:01.920
which can slow down the app download
there are two ways to reduce the apk

00:11:01.920 --> 00:11:01.930
there are two ways to reduce the apk
 

00:11:01.930 --> 00:11:06.240
there are two ways to reduce the apk
size first you can build your app as a

00:11:06.240 --> 00:11:06.250
size first you can build your app as a
 

00:11:06.250 --> 00:11:07.920
size first you can build your app as a
Android app bundle

00:11:07.920 --> 00:11:07.930
Android app bundle
 

00:11:07.930 --> 00:11:11.700
Android app bundle
by doing that you enable Google Play to

00:11:11.700 --> 00:11:11.710
by doing that you enable Google Play to
 

00:11:11.710 --> 00:11:14.040
by doing that you enable Google Play to
automatically generate apks for specific

00:11:14.040 --> 00:11:14.050
automatically generate apks for specific
 

00:11:14.050 --> 00:11:16.710
automatically generate apks for specific
screen density CPU architecture as was

00:11:16.710 --> 00:11:16.720
screen density CPU architecture as was
 

00:11:16.720 --> 00:11:19.380
screen density CPU architecture as was
the languages then your user only have

00:11:19.380 --> 00:11:19.390
the languages then your user only have
 

00:11:19.390 --> 00:11:21.300
the languages then your user only have
to download the apk sand native code

00:11:21.300 --> 00:11:21.310
to download the apk sand native code
 

00:11:21.310 --> 00:11:22.800
to download the apk sand native code
libraries that match their device

00:11:22.800 --> 00:11:22.810
libraries that match their device
 

00:11:22.810 --> 00:11:26.250
libraries that match their device
configuration another way you can reduce

00:11:26.250 --> 00:11:26.260
configuration another way you can reduce
 

00:11:26.260 --> 00:11:29.730
configuration another way you can reduce
apk size is if you the machine learning

00:11:29.730 --> 00:11:29.740
apk size is if you the machine learning
 

00:11:29.740 --> 00:11:31.980
apk size is if you the machine learning
feature in your app is not a primary

00:11:31.980 --> 00:11:31.990
feature in your app is not a primary
 

00:11:31.990 --> 00:11:35.100
feature in your app is not a primary
purpose then you could move machine

00:11:35.100 --> 00:11:35.110
purpose then you could move machine
 

00:11:35.110 --> 00:11:37.050
purpose then you could move machine
learning features which require a make

00:11:37.050 --> 00:11:37.060
learning features which require a make
 

00:11:37.060 --> 00:11:40.680
learning features which require a make
it into a dynamic feature module in that

00:11:40.680 --> 00:11:40.690
it into a dynamic feature module in that
 

00:11:40.690 --> 00:11:42.930
it into a dynamic feature module in that
way you prevent users from unnecessary

00:11:42.930 --> 00:11:42.940
way you prevent users from unnecessary
 

00:11:42.940 --> 00:11:45.390
way you prevent users from unnecessary
downloading ml models which can

00:11:45.390 --> 00:11:45.400
downloading ml models which can
 

00:11:45.400 --> 00:11:49.410
downloading ml models which can
sometimes be large we all know machine

00:11:49.410 --> 00:11:49.420
sometimes be large we all know machine
 

00:11:49.420 --> 00:11:52.170
sometimes be large we all know machine
learning involves a lot of computation

00:11:52.170 --> 00:11:52.180
learning involves a lot of computation
 

00:11:52.180 --> 00:11:55.230
learning involves a lot of computation
so the speed becomes really important

00:11:55.230 --> 00:11:55.240
so the speed becomes really important
 

00:11:55.240 --> 00:11:57.720
so the speed becomes really important
here's some tips how you could improve

00:11:57.720 --> 00:11:57.730
here's some tips how you could improve
 

00:11:57.730 --> 00:12:00.090
here's some tips how you could improve
the performance for especially for

00:12:00.090 --> 00:12:00.100
the performance for especially for
 

00:12:00.100 --> 00:12:02.150
the performance for especially for
real-time inference on streaming video

00:12:02.150 --> 00:12:02.160
real-time inference on streaming video
 

00:12:02.160 --> 00:12:05.100
real-time inference on streaming video
you can reduce the image resolution as a

00:12:05.100 --> 00:12:05.110
you can reduce the image resolution as a
 

00:12:05.110 --> 00:12:08.220
you can reduce the image resolution as a
video frame rate to limit amount of

00:12:08.220 --> 00:12:08.230
video frame rate to limit amount of
 

00:12:08.230 --> 00:12:10.200
video frame rate to limit amount of
computation it involves to the inference

00:12:10.200 --> 00:12:10.210
computation it involves to the inference
 

00:12:10.210 --> 00:12:13.470
computation it involves to the inference
when the current frame speed process you

00:12:13.470 --> 00:12:13.480
when the current frame speed process you
 

00:12:13.480 --> 00:12:15.660
when the current frame speed process you
should also throttle incoming video

00:12:15.660 --> 00:12:15.670
should also throttle incoming video
 

00:12:15.670 --> 00:12:17.520
should also throttle incoming video
frames to avoid any backup which

00:12:17.520 --> 00:12:17.530
frames to avoid any backup which
 

00:12:17.530 --> 00:12:19.770
frames to avoid any backup which
increased memory as well slow down the

00:12:19.770 --> 00:12:19.780
increased memory as well slow down the
 

00:12:19.780 --> 00:12:22.800
increased memory as well slow down the
performance for real-time face detection

00:12:22.800 --> 00:12:22.810
performance for real-time face detection
 

00:12:22.810 --> 00:12:26.190
performance for real-time face detection
you should use face fast mode which

00:12:26.190 --> 00:12:26.200
you should use face fast mode which
 

00:12:26.200 --> 00:12:29.100
you should use face fast mode which
luckily is the default mode oftentime

00:12:29.100 --> 00:12:29.110
luckily is the default mode oftentime
 

00:12:29.110 --> 00:12:31.920
luckily is the default mode oftentime
480 by 360 resolution is sufficient for

00:12:31.920 --> 00:12:31.930
480 by 360 resolution is sufficient for
 

00:12:31.930 --> 00:12:34.980
480 by 360 resolution is sufficient for
face detection for real-time processing

00:12:34.980 --> 00:12:34.990
face detection for real-time processing
 

00:12:34.990 --> 00:12:38.070
face detection for real-time processing
you should also choose between counter

00:12:38.070 --> 00:12:38.080
you should also choose between counter
 

00:12:38.080 --> 00:12:40.380
you should also choose between counter
detection versus classification or

00:12:40.380 --> 00:12:40.390
detection versus classification or
 

00:12:40.390 --> 00:12:43.620
detection versus classification or
landmark detection but not both because

00:12:43.620 --> 00:12:43.630
landmark detection but not both because
 

00:12:43.630 --> 00:12:46.200
landmark detection but not both because
doing both could be expensive and may

00:12:46.200 --> 00:12:46.210
doing both could be expensive and may
 

00:12:46.210 --> 00:12:47.900
doing both could be expensive and may
not be fit for the real-time device

00:12:47.900 --> 00:12:47.910
not be fit for the real-time device
 

00:12:47.910 --> 00:12:51.410
not be fit for the real-time device
real-time processing in a slow device

00:12:51.410 --> 00:12:51.420
real-time processing in a slow device
 

00:12:51.420 --> 00:12:54.270
real-time processing in a slow device
another tip and trick you should even

00:12:54.270 --> 00:12:54.280
another tip and trick you should even
 

00:12:54.280 --> 00:12:56.550
another tip and trick you should even
use is you should wait for detection to

00:12:56.550 --> 00:12:56.560
use is you should wait for detection to
 

00:12:56.560 --> 00:12:59.070
use is you should wait for detection to
finish before render the face and

00:12:59.070 --> 00:12:59.080
finish before render the face and
 

00:12:59.080 --> 00:13:03.330
finish before render the face and
counter together you can check out our

00:13:03.330 --> 00:13:03.340
counter together you can check out our
 

00:13:03.340 --> 00:13:06.480
counter together you can check out our
online QuickStart sample app on github

00:13:06.480 --> 00:13:06.490
online QuickStart sample app on github
 

00:13:06.490 --> 00:13:09.930
online QuickStart sample app on github
for more details to illustrate what I

00:13:09.930 --> 00:13:09.940
for more details to illustrate what I
 

00:13:09.940 --> 00:13:14.100
for more details to illustrate what I
mean I will do a live demo let's switch

00:13:14.100 --> 00:13:14.110
mean I will do a live demo let's switch
 

00:13:14.110 --> 00:13:17.490
mean I will do a live demo let's switch
to the demo mode so for the purpose of

00:13:17.490 --> 00:13:17.500
to the demo mode so for the purpose of
 

00:13:17.500 --> 00:13:21.790
to the demo mode so for the purpose of
demo I'm using a slower Suite hi 3

00:13:21.790 --> 00:13:21.800
demo I'm using a slower Suite hi 3
 

00:13:21.800 --> 00:13:24.850
demo I'm using a slower Suite hi 3
year-old Nexus 5x phone because using

00:13:24.850 --> 00:13:24.860
year-old Nexus 5x phone because using
 

00:13:24.860 --> 00:13:26.920
year-old Nexus 5x phone because using
the latest pixel phone the difference

00:13:26.920 --> 00:13:26.930
the latest pixel phone the difference
 

00:13:26.930 --> 00:13:30.699
the latest pixel phone the difference
are not as prominent in the first video

00:13:30.699 --> 00:13:30.709
are not as prominent in the first video
 

00:13:30.709 --> 00:13:33.970
are not as prominent in the first video
I'm going to show you without any proofs

00:13:33.970 --> 00:13:33.980
I'm going to show you without any proofs
 

00:13:33.980 --> 00:13:37.870
I'm going to show you without any proofs
and we do not do videos throttling we do

00:13:37.870 --> 00:13:37.880
and we do not do videos throttling we do
 

00:13:37.880 --> 00:13:40.690
and we do not do videos throttling we do
not do any Lake drawing to make sure the

00:13:40.690 --> 00:13:40.700
not do any Lake drawing to make sure the
 

00:13:40.700 --> 00:13:43.420
not do any Lake drawing to make sure the
contour and the face are together so if

00:13:43.420 --> 00:13:43.430
contour and the face are together so if
 

00:13:43.430 --> 00:13:47.110
contour and the face are together so if
you just call the API without any

00:13:47.110 --> 00:13:47.120
you just call the API without any
 

00:13:47.120 --> 00:13:52.090
you just call the API without any
performance improvement you can see the

00:13:52.090 --> 00:13:52.100
performance improvement you can see the
 

00:13:52.100 --> 00:13:55.139
performance improvement you can see the
counters are not falling in the face and

00:13:55.139 --> 00:13:55.149
counters are not falling in the face and
 

00:13:55.149 --> 00:13:59.190
counters are not falling in the face and
there's a big gap between this two

00:13:59.190 --> 00:13:59.200
there's a big gap between this two
 

00:13:59.200 --> 00:14:02.050
there's a big gap between this two
alright so now I'm going to switch to

00:14:02.050 --> 00:14:02.060
alright so now I'm going to switch to
 

00:14:02.060 --> 00:14:05.910
alright so now I'm going to switch to
another version after applying

00:14:05.910 --> 00:14:05.920
another version after applying
 

00:14:05.920 --> 00:14:14.259
another version after applying
performance tips in this version it's

00:14:14.259 --> 00:14:14.269
performance tips in this version it's
 

00:14:14.269 --> 00:14:17.800
performance tips in this version it's
using the exact same Nexus 5x phone but

00:14:17.800 --> 00:14:17.810
using the exact same Nexus 5x phone but
 

00:14:17.810 --> 00:14:20.530
using the exact same Nexus 5x phone but
we throttle the video for incoming video

00:14:20.530 --> 00:14:20.540
we throttle the video for incoming video
 

00:14:20.540 --> 00:14:22.180
we throttle the video for incoming video
frame when we're still processing the

00:14:22.180 --> 00:14:22.190
frame when we're still processing the
 

00:14:22.190 --> 00:14:25.210
frame when we're still processing the
current frame and also we wait for the

00:14:25.210 --> 00:14:25.220
current frame and also we wait for the
 

00:14:25.220 --> 00:14:27.819
current frame and also we wait for the
detection of finish before render pose

00:14:27.819 --> 00:14:27.829
detection of finish before render pose
 

00:14:27.829 --> 00:14:31.150
detection of finish before render pose
the face and the counter as you can see

00:14:31.150 --> 00:14:31.160
the face and the counter as you can see
 

00:14:31.160 --> 00:14:34.000
the face and the counter as you can see
now the contours are following in the

00:14:34.000 --> 00:14:34.010
now the contours are following in the
 

00:14:34.010 --> 00:14:36.190
now the contours are following in the
face all the time they match each other

00:14:36.190 --> 00:14:36.200
face all the time they match each other
 

00:14:36.200 --> 00:14:41.410
face all the time they match each other
there's no more gap for so let's switch

00:14:41.410 --> 00:14:41.420
there's no more gap for so let's switch
 

00:14:41.420 --> 00:14:47.730
there's no more gap for so let's switch
back to the slides thank you

00:14:47.730 --> 00:14:47.740
 

00:14:47.740 --> 00:14:51.569
if you're using our custom auto API how

00:14:51.569 --> 00:14:51.579
if you're using our custom auto API how
 

00:14:51.579 --> 00:14:54.809
if you're using our custom auto API how
to include model becomes a something you

00:14:54.809 --> 00:14:54.819
to include model becomes a something you
 

00:14:54.819 --> 00:14:57.059
to include model becomes a something you
should consider there are two ways you

00:14:57.059 --> 00:14:57.069
should consider there are two ways you
 

00:14:57.069 --> 00:14:59.069
should consider there are two ways you
can either bundle the model inside your

00:14:59.069 --> 00:14:59.079
can either bundle the model inside your
 

00:14:59.079 --> 00:15:02.699
can either bundle the model inside your
app or host it on a cloud if you bundle

00:15:02.699 --> 00:15:02.709
app or host it on a cloud if you bundle
 

00:15:02.709 --> 00:15:05.400
app or host it on a cloud if you bundle
your model in your app it's available

00:15:05.400 --> 00:15:05.410
your model in your app it's available
 

00:15:05.410 --> 00:15:08.699
your model in your app it's available
immediately it also does not require any

00:15:08.699 --> 00:15:08.709
immediately it also does not require any
 

00:15:08.709 --> 00:15:10.679
immediately it also does not require any
model downloading so it works offline

00:15:10.679 --> 00:15:10.689
model downloading so it works offline
 

00:15:10.689 --> 00:15:13.859
model downloading so it works offline
but the downside is you get a bigger app

00:15:13.859 --> 00:15:13.869
but the downside is you get a bigger app
 

00:15:13.869 --> 00:15:16.410
but the downside is you get a bigger app
because app contains the model it may

00:15:16.410 --> 00:15:16.420
because app contains the model it may
 

00:15:16.420 --> 00:15:19.530
because app contains the model it may
slow down the app download also you

00:15:19.530 --> 00:15:19.540
slow down the app download also you
 

00:15:19.540 --> 00:15:21.569
slow down the app download also you
cannot change the model without a new

00:15:21.569 --> 00:15:21.579
cannot change the model without a new
 

00:15:21.579 --> 00:15:25.710
cannot change the model without a new
app release on the other hand if you

00:15:25.710 --> 00:15:25.720
app release on the other hand if you
 

00:15:25.720 --> 00:15:28.350
app release on the other hand if you
have some model in the cloud we provide

00:15:28.350 --> 00:15:28.360
have some model in the cloud we provide
 

00:15:28.360 --> 00:15:31.109
have some model in the cloud we provide
all the hosting support for you you get

00:15:31.109 --> 00:15:31.119
all the hosting support for you you get
 

00:15:31.119 --> 00:15:33.540
all the hosting support for you you get
a smaller app size because after itself

00:15:33.540 --> 00:15:33.550
a smaller app size because after itself
 

00:15:33.550 --> 00:15:35.309
a smaller app size because after itself
does not contain the model which

00:15:35.309 --> 00:15:35.319
does not contain the model which
 

00:15:35.319 --> 00:15:38.460
does not contain the model which
translate into a faster installation you

00:15:38.460 --> 00:15:38.470
translate into a faster installation you
 

00:15:38.470 --> 00:15:40.499
translate into a faster installation you
also can choose the download model only

00:15:40.499 --> 00:15:40.509
also can choose the download model only
 

00:15:40.509 --> 00:15:43.919
also can choose the download model only
if it's needed the model updates can

00:15:43.919 --> 00:15:43.929
if it's needed the model updates can
 

00:15:43.929 --> 00:15:46.679
if it's needed the model updates can
come over the air into the app without

00:15:46.679 --> 00:15:46.689
come over the air into the app without
 

00:15:46.689 --> 00:15:49.499
come over the air into the app without
any new app release you can also use

00:15:49.499 --> 00:15:49.509
any new app release you can also use
 

00:15:49.509 --> 00:15:52.049
any new app release you can also use
remote config and a be testing framework

00:15:52.049 --> 00:15:52.059
remote config and a be testing framework
 

00:15:52.059 --> 00:15:54.299
remote config and a be testing framework
provided by the firebase to do phase

00:15:54.299 --> 00:15:54.309
provided by the firebase to do phase
 

00:15:54.309 --> 00:15:57.689
provided by the firebase to do phase
rollout as much control to pilots the

00:15:57.689 --> 00:15:57.699
rollout as much control to pilots the
 

00:15:57.699 --> 00:16:00.660
rollout as much control to pilots the
drawback of hosting model on the cloud

00:16:00.660 --> 00:16:00.670
drawback of hosting model on the cloud
 

00:16:00.670 --> 00:16:04.199
drawback of hosting model on the cloud
is obviously it means connectivity when

00:16:04.199 --> 00:16:04.209
is obviously it means connectivity when
 

00:16:04.209 --> 00:16:05.669
is obviously it means connectivity when
there's no connectivity you don't get

00:16:05.669 --> 00:16:05.679
there's no connectivity you don't get
 

00:16:05.679 --> 00:16:07.169
there's no connectivity you don't get
that you don't you cannot download the

00:16:07.169 --> 00:16:07.179
that you don't you cannot download the
 

00:16:07.179 --> 00:16:09.299
that you don't you cannot download the
model also the model will not be

00:16:09.299 --> 00:16:09.309
model also the model will not be
 

00:16:09.309 --> 00:16:12.059
model also the model will not be
available and here they're downloaded so

00:16:12.059 --> 00:16:12.069
available and here they're downloaded so
 

00:16:12.069 --> 00:16:14.249
available and here they're downloaded so
a third option is using a hybrid

00:16:14.249 --> 00:16:14.259
a third option is using a hybrid
 

00:16:14.259 --> 00:16:17.100
a third option is using a hybrid
approach you can pound on the model the

00:16:17.100 --> 00:16:17.110
approach you can pound on the model the
 

00:16:17.110 --> 00:16:18.929
approach you can pound on the model the
initial version of model in the app so

00:16:18.929 --> 00:16:18.939
initial version of model in the app so
 

00:16:18.939 --> 00:16:21.299
initial version of model in the app so
make it usable right away after

00:16:21.299 --> 00:16:21.309
make it usable right away after
 

00:16:21.309 --> 00:16:23.460
make it usable right away after
installation now you can receive model

00:16:23.460 --> 00:16:23.470
installation now you can receive model
 

00:16:23.470 --> 00:16:28.710
installation now you can receive model
updates over the air from the cloud if

00:16:28.710 --> 00:16:28.720
updates over the air from the cloud if
 

00:16:28.720 --> 00:16:31.439
updates over the air from the cloud if
you are using our base API it's provided

00:16:31.439 --> 00:16:31.449
you are using our base API it's provided
 

00:16:31.449 --> 00:16:33.600
you are using our base API it's provided
in two different forms for the latter of

00:16:33.600 --> 00:16:33.610
in two different forms for the latter of
 

00:16:33.610 --> 00:16:34.439
in two different forms for the latter of
better terms

00:16:34.439 --> 00:16:34.449
better terms
 

00:16:34.449 --> 00:16:38.030
better terms
I call it thickened SDK and a thin SDK

00:16:38.030 --> 00:16:38.040
I call it thickened SDK and a thin SDK
 

00:16:38.040 --> 00:16:41.100
I call it thickened SDK and a thin SDK
in Athey SDK the models actually

00:16:41.100 --> 00:16:41.110
in Athey SDK the models actually
 

00:16:41.110 --> 00:16:42.689
in Athey SDK the models actually
provided by the Google Play service

00:16:42.689 --> 00:16:42.699
provided by the Google Play service
 

00:16:42.699 --> 00:16:44.309
provided by the Google Play service
which means they are shared across all

00:16:44.309 --> 00:16:44.319
which means they are shared across all
 

00:16:44.319 --> 00:16:46.289
which means they are shared across all
apps the apps itself does not have to

00:16:46.289 --> 00:16:46.299
apps the apps itself does not have to
 

00:16:46.299 --> 00:16:49.799
apps the apps itself does not have to
contain the model and which will make

00:16:49.799 --> 00:16:49.809
contain the model and which will make
 

00:16:49.809 --> 00:16:52.859
contain the model and which will make
your app smaller text recognition and

00:16:52.859 --> 00:16:52.869
your app smaller text recognition and
 

00:16:52.869 --> 00:16:55.289
your app smaller text recognition and
the barcode scanning api's are provided

00:16:55.289 --> 00:16:55.299
the barcode scanning api's are provided
 

00:16:55.299 --> 00:16:59.069
the barcode scanning api's are provided
through the thing sdk the second type is

00:16:59.069 --> 00:16:59.079
through the thing sdk the second type is
 

00:16:59.079 --> 00:17:01.350
through the thing sdk the second type is
called thick SDKs the

00:17:01.350 --> 00:17:01.360
called thick SDKs the
 

00:17:01.360 --> 00:17:04.829
called thick SDKs the
are bound on inside SDK each app will

00:17:04.829 --> 00:17:04.839
are bound on inside SDK each app will
 

00:17:04.839 --> 00:17:07.169
are bound on inside SDK each app will
have their own copy of the model which

00:17:07.169 --> 00:17:07.179
have their own copy of the model which
 

00:17:07.179 --> 00:17:09.750
have their own copy of the model which
will increase the app size face

00:17:09.750 --> 00:17:09.760
will increase the app size face
 

00:17:09.760 --> 00:17:11.699
will increase the app size face
detection and image labeling are

00:17:11.699 --> 00:17:11.709
detection and image labeling are
 

00:17:11.709 --> 00:17:15.780
detection and image labeling are
supported through the thickest case to

00:17:15.780 --> 00:17:15.790
supported through the thickest case to
 

00:17:15.790 --> 00:17:18.480
supported through the thickest case to
use this two type of SDK and use verse

00:17:18.480 --> 00:17:18.490
use this two type of SDK and use verse
 

00:17:18.490 --> 00:17:21.449
use this two type of SDK and use verse
API as provide by the ml kit you need to

00:17:21.449 --> 00:17:21.459
API as provide by the ml kit you need to
 

00:17:21.459 --> 00:17:24.059
API as provide by the ml kit you need to
include the appropriate MLK dependencies

00:17:24.059 --> 00:17:24.069
include the appropriate MLK dependencies
 

00:17:24.069 --> 00:17:26.090
include the appropriate MLK dependencies
in your app level build up Gradle file

00:17:26.090 --> 00:17:26.100
in your app level build up Gradle file
 

00:17:26.100 --> 00:17:29.040
in your app level build up Gradle file
inside the file inside this dependency

00:17:29.040 --> 00:17:29.050
inside the file inside this dependency
 

00:17:29.050 --> 00:17:31.830
inside the file inside this dependency
section if you want to use the API

00:17:31.830 --> 00:17:31.840
section if you want to use the API
 

00:17:31.840 --> 00:17:34.080
section if you want to use the API
support through the thing SDK you should

00:17:34.080 --> 00:17:34.090
support through the thing SDK you should
 

00:17:34.090 --> 00:17:35.490
support through the thing SDK you should
add the dependency called

00:17:35.490 --> 00:17:35.500
add the dependency called
 

00:17:35.500 --> 00:17:41.340
add the dependency called
firebase - mm - vision an in addition if

00:17:41.340 --> 00:17:41.350
firebase - mm - vision an in addition if
 

00:17:41.350 --> 00:17:43.560
firebase - mm - vision an in addition if
you want to use thick sdk you should

00:17:43.560 --> 00:17:43.570
you want to use thick sdk you should
 

00:17:43.570 --> 00:17:45.600
you want to use thick sdk you should
still keep this line because auto vision

00:17:45.600 --> 00:17:45.610
still keep this line because auto vision
 

00:17:45.610 --> 00:17:47.760
still keep this line because auto vision
API entry points are coming from this

00:17:47.760 --> 00:17:47.770
API entry points are coming from this
 

00:17:47.770 --> 00:17:51.030
API entry points are coming from this
thing SDK dependency but you also need

00:17:51.030 --> 00:17:51.040
thing SDK dependency but you also need
 

00:17:51.040 --> 00:17:53.370
thing SDK dependency but you also need
to add additional dependencies for

00:17:53.370 --> 00:17:53.380
to add additional dependencies for
 

00:17:53.380 --> 00:17:55.460
to add additional dependencies for
example if you want to use image

00:17:55.460 --> 00:17:55.470
example if you want to use image
 

00:17:55.470 --> 00:17:59.130
example if you want to use image
recognition image detection then you

00:17:59.130 --> 00:17:59.140
recognition image detection then you
 

00:17:59.140 --> 00:18:02.400
recognition image detection then you
need to add the FIR base ml vision face

00:18:02.400 --> 00:18:02.410
need to add the FIR base ml vision face
 

00:18:02.410 --> 00:18:05.220
need to add the FIR base ml vision face
model dependency because it's a thick

00:18:05.220 --> 00:18:05.230
model dependency because it's a thick
 

00:18:05.230 --> 00:18:06.290
model dependency because it's a thick
SDK

00:18:06.290 --> 00:18:06.300
SDK
 

00:18:06.300 --> 00:18:10.169
SDK
similarly for image labeling if used in

00:18:10.169 --> 00:18:10.179
similarly for image labeling if used in
 

00:18:10.179 --> 00:18:12.030
similarly for image labeling if used in
that feature they need to add image

00:18:12.030 --> 00:18:12.040
that feature they need to add image
 

00:18:12.040 --> 00:18:17.669
that feature they need to add image
label model dependency next I will talk

00:18:17.669 --> 00:18:17.679
label model dependency next I will talk
 

00:18:17.679 --> 00:18:19.590
label model dependency next I will talk
about a few new areas we are currently

00:18:19.590 --> 00:18:19.600
about a few new areas we are currently
 

00:18:19.600 --> 00:18:23.850
about a few new areas we are currently
working on a few new MLK features are

00:18:23.850 --> 00:18:23.860
working on a few new MLK features are
 

00:18:23.860 --> 00:18:25.980
working on a few new MLK features are
either under development or in early

00:18:25.980 --> 00:18:25.990
either under development or in early
 

00:18:25.990 --> 00:18:29.780
either under development or in early
testing phase we expanded beyond vision

00:18:29.780 --> 00:18:29.790
testing phase we expanded beyond vision
 

00:18:29.790 --> 00:18:31.650
testing phase we expanded beyond vision
starting natural language processing

00:18:31.650 --> 00:18:31.660
starting natural language processing
 

00:18:31.660 --> 00:18:35.130
starting natural language processing
with smart reply smart applies a feature

00:18:35.130 --> 00:18:35.140
with smart reply smart applies a feature
 

00:18:35.140 --> 00:18:37.470
with smart reply smart applies a feature
which can enable you to produce

00:18:37.470 --> 00:18:37.480
which can enable you to produce
 

00:18:37.480 --> 00:18:39.750
which can enable you to produce
meaningful response based on the current

00:18:39.750 --> 00:18:39.760
meaningful response based on the current
 

00:18:39.760 --> 00:18:42.270
meaningful response based on the current
conversation context we are also

00:18:42.270 --> 00:18:42.280
conversation context we are also
 

00:18:42.280 --> 00:18:44.010
conversation context we are also
planning to go into other areas like

00:18:44.010 --> 00:18:44.020
planning to go into other areas like
 

00:18:44.020 --> 00:18:47.790
planning to go into other areas like
speech at the same time we will continue

00:18:47.790 --> 00:18:47.800
speech at the same time we will continue
 

00:18:47.800 --> 00:18:50.159
speech at the same time we will continue
to enhance performance and accuracy of

00:18:50.159 --> 00:18:50.169
to enhance performance and accuracy of
 

00:18:50.169 --> 00:18:54.930
to enhance performance and accuracy of
base api's we launched model compression

00:18:54.930 --> 00:18:54.940
base api's we launched model compression
 

00:18:54.940 --> 00:18:56.820
base api's we launched model compression
and conversion service to our alpha

00:18:56.820 --> 00:18:56.830
and conversion service to our alpha
 

00:18:56.830 --> 00:19:00.659
and conversion service to our alpha
users which helped them to convert and

00:19:00.659 --> 00:19:00.669
users which helped them to convert and
 

00:19:00.669 --> 00:19:02.610
users which helped them to convert and
compress large model into a smaller and

00:19:02.610 --> 00:19:02.620
compress large model into a smaller and
 

00:19:02.620 --> 00:19:06.180
compress large model into a smaller and
faster versions for mobile usage the

00:19:06.180 --> 00:19:06.190
faster versions for mobile usage the
 

00:19:06.190 --> 00:19:08.840
faster versions for mobile usage the
conversion service contains in alpha

00:19:08.840 --> 00:19:08.850
conversion service contains in alpha
 

00:19:08.850 --> 00:19:12.900
conversion service contains in alpha
uses pruning quantization installation

00:19:12.900 --> 00:19:12.910
uses pruning quantization installation
 

00:19:12.910 --> 00:19:14.880
uses pruning quantization installation
as well as the transfer learning

00:19:14.880 --> 00:19:14.890
as well as the transfer learning
 

00:19:14.890 --> 00:19:17.700
as well as the transfer learning
to retrain the large models make them

00:19:17.700 --> 00:19:17.710
to retrain the large models make them
 

00:19:17.710 --> 00:19:19.980
to retrain the large models make them
smaller and faster without sacrificing

00:19:19.980 --> 00:19:19.990
smaller and faster without sacrificing
 

00:19:19.990 --> 00:19:23.250
smaller and faster without sacrificing
too much accuracy fish brain is a

00:19:23.250 --> 00:19:23.260
too much accuracy fish brain is a
 

00:19:23.260 --> 00:19:26.550
too much accuracy fish brain is a
community-based app it enables user to

00:19:26.550 --> 00:19:26.560
community-based app it enables user to
 

00:19:26.560 --> 00:19:28.470
community-based app it enables user to
share the photos of their cache and

00:19:28.470 --> 00:19:28.480
share the photos of their cache and
 

00:19:28.480 --> 00:19:31.560
share the photos of their cache and
within their social networks with a

00:19:31.560 --> 00:19:31.570
within their social networks with a
 

00:19:31.570 --> 00:19:33.660
within their social networks with a
machine learning model it can identify

00:19:33.660 --> 00:19:33.670
machine learning model it can identify
 

00:19:33.670 --> 00:19:37.080
machine learning model it can identify
any fish with just a photo when they

00:19:37.080 --> 00:19:37.090
any fish with just a photo when they
 

00:19:37.090 --> 00:19:40.080
any fish with just a photo when they
first came to us their model is more

00:19:40.080 --> 00:19:40.090
first came to us their model is more
 

00:19:40.090 --> 00:19:43.980
first came to us their model is more
than 480 Meg bytes by using our

00:19:43.980 --> 00:19:43.990
than 480 Meg bytes by using our
 

00:19:43.990 --> 00:19:46.380
than 480 Meg bytes by using our
conversion and compression service we

00:19:46.380 --> 00:19:46.390
conversion and compression service we
 

00:19:46.390 --> 00:19:49.050
conversion and compression service we
are able to trim down the model to ender

00:19:49.050 --> 00:19:49.060
are able to trim down the model to ender
 

00:19:49.060 --> 00:19:52.650
are able to trim down the model to ender
one Mac as you can see the not only

00:19:52.650 --> 00:19:52.660
one Mac as you can see the not only
 

00:19:52.660 --> 00:19:54.960
one Mac as you can see the not only
maintain same level accuracy that

00:19:54.960 --> 00:19:54.970
maintain same level accuracy that
 

00:19:54.970 --> 00:19:58.320
maintain same level accuracy that
actually is actually slightly better if

00:19:58.320 --> 00:19:58.330
actually is actually slightly better if
 

00:19:58.330 --> 00:20:00.210
actually is actually slightly better if
you are interested in trying out our

00:20:00.210 --> 00:20:00.220
you are interested in trying out our
 

00:20:00.220 --> 00:20:02.910
you are interested in trying out our
model compression service please join

00:20:02.910 --> 00:20:02.920
model compression service please join
 

00:20:02.920 --> 00:20:06.090
model compression service please join
our alpha program by sign up today at G

00:20:06.090 --> 00:20:06.100
our alpha program by sign up today at G
 

00:20:06.100 --> 00:20:11.640
our alpha program by sign up today at G
da Co / firebase / sign up no matter you

00:20:11.640 --> 00:20:11.650
da Co / firebase / sign up no matter you
 

00:20:11.650 --> 00:20:12.980
da Co / firebase / sign up no matter you
are new to machine learning or

00:20:12.980 --> 00:20:12.990
are new to machine learning or
 

00:20:12.990 --> 00:20:16.500
are new to machine learning or
experienced AI expert I hope you enjoyed

00:20:16.500 --> 00:20:16.510
experienced AI expert I hope you enjoyed
 

00:20:16.510 --> 00:20:18.090
experienced AI expert I hope you enjoyed
the talk today and they can take home

00:20:18.090 --> 00:20:18.100
the talk today and they can take home
 

00:20:18.100 --> 00:20:21.060
the talk today and they can take home
some tips and I can't wait to see what

00:20:21.060 --> 00:20:21.070
some tips and I can't wait to see what
 

00:20:21.070 --> 00:20:23.850
some tips and I can't wait to see what
you will build with ml kit if you have

00:20:23.850 --> 00:20:23.860
you will build with ml kit if you have
 

00:20:23.860 --> 00:20:25.680
you will build with ml kit if you have
any question are we outside in the Asha

00:20:25.680 --> 00:20:25.690
any question are we outside in the Asha
 

00:20:25.690 --> 00:20:28.110
any question are we outside in the Asha
and relaunch and we also have office

00:20:28.110 --> 00:20:28.120
and relaunch and we also have office
 

00:20:28.120 --> 00:20:30.060
and relaunch and we also have office
hour tomorrow thank you very much for

00:20:30.060 --> 00:20:30.070
hour tomorrow thank you very much for
 

00:20:30.070 --> 00:20:30.970
hour tomorrow thank you very much for
listening

00:20:30.970 --> 00:20:30.980
listening
 

00:20:30.980 --> 00:20:47.049
listening
[Music]

