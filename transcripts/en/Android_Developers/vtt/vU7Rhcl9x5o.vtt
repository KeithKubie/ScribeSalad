WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.964
[MUSIC PLAYING]

00:00:06.294 --> 00:00:08.210
NICOLAS GEOFFRAY: Well,
thanks for being here.

00:00:08.210 --> 00:00:10.480
I'm impressed you're--
there are people showing up.

00:00:10.480 --> 00:00:11.950
The Android Fireside
Chat was kind

00:00:11.950 --> 00:00:17.420
of scaring me that everyone
would just avoid the session.

00:00:17.420 --> 00:00:19.390
But no, it's great
to have you here,

00:00:19.390 --> 00:00:22.321
and this talk is about ART.

00:00:22.321 --> 00:00:25.090
So there's a part
of this talk, which

00:00:25.090 --> 00:00:27.740
was supposed to be on
garbage collection,

00:00:27.740 --> 00:00:31.360
and that my colleague David
was planning on giving,

00:00:31.360 --> 00:00:33.780
but we're not going to
rehash the same thing.

00:00:33.780 --> 00:00:40.870
So I'll put long pauses, awkward
ones I hope, during the talk,

00:00:40.870 --> 00:00:43.810
so I can fit the 40 minutes.

00:00:43.810 --> 00:00:46.690
So bear with me.

00:00:46.690 --> 00:00:50.819
So given we're celebrating
10 years of Android, David

00:00:50.819 --> 00:00:52.360
and I thought it
would be a good idea

00:00:52.360 --> 00:00:55.850
to think about what we've
done the last 10 years

00:00:55.850 --> 00:00:58.090
and how the Android
Runtime, which

00:00:58.090 --> 00:01:03.850
is the thing we worked on for
a couple of years now, evolved.

00:01:03.850 --> 00:01:04.670
So here we are.

00:01:09.526 --> 00:01:11.400
So some of you went to
the chat [INAUDIBLE],,

00:01:11.400 --> 00:01:14.250
so I guess you already know what
the-- what an Android Runtime

00:01:14.250 --> 00:01:15.900
is in the Android stack.

00:01:15.900 --> 00:01:19.380
But in case you don't,
it's that little layer,

00:01:19.380 --> 00:01:22.980
that yellow one here, between
the Android framework,

00:01:22.980 --> 00:01:24.600
like the Android
operating system,

00:01:24.600 --> 00:01:28.750
and the actual
underlying kernel.

00:01:28.750 --> 00:01:34.170
The Runtime runs both the
Android framework and all

00:01:34.170 --> 00:01:36.480
of the apps, so everything
written in Java,

00:01:36.480 --> 00:01:39.770
that's what we execute.

00:01:39.770 --> 00:01:42.650
And so being so core
in the platform,

00:01:42.650 --> 00:01:46.260
it becomes responsible
for a ton of things,

00:01:46.260 --> 00:01:50.740
like the user experience could
be very bad if the Android

00:01:50.740 --> 00:01:53.340
Runtime was not efficient,
and you saw that this morning

00:01:53.340 --> 00:01:59.040
with how the GC was sort
of poor in the dark days.

00:02:02.155 --> 00:02:04.680
So in this talk, I'll
show you over time

00:02:04.680 --> 00:02:08.759
how runtime versions that--

00:02:08.759 --> 00:02:11.719
the old iterations we've
made over the past--

00:02:11.719 --> 00:02:13.360
they've oscillated
between, OK, what

00:02:13.360 --> 00:02:16.776
do we need to improve
for this year?

00:02:16.776 --> 00:02:18.710
And like I said, it's--

00:02:18.710 --> 00:02:22.750
ART, the Android Runtime is
possible for a bunch of things,

00:02:22.750 --> 00:02:25.590
and raw performance
is one clear one,

00:02:25.590 --> 00:02:28.200
like how fast you
execute Java code.

00:02:28.200 --> 00:02:31.050
But clearly, it's also
responsible for jank,

00:02:31.050 --> 00:02:33.270
like the 16 milliseconds window.

00:02:33.270 --> 00:02:37.110
If the runtime is not able to
execute the Java code of that--

00:02:37.110 --> 00:02:39.240
of the app, well then,
we'll miss the frame

00:02:39.240 --> 00:02:41.780
and produce a lot of jank.

00:02:41.780 --> 00:02:45.450
Application startup--
there's a lot of Java code

00:02:45.450 --> 00:02:47.670
that needs to be executed
during application startup.

00:02:47.670 --> 00:02:52.080
Again, if the runtime is
slow, startup will be slow.

00:02:52.080 --> 00:02:55.410
Boot times-- the Android
OS is written in Java,

00:02:55.410 --> 00:02:58.580
so a lot of code, again,
executes during boot.

00:02:58.580 --> 00:03:02.190
Battery-- if we're slow, we're
going to tank your battery.

00:03:02.190 --> 00:03:05.100
And install time
is also something

00:03:05.100 --> 00:03:07.860
we care about because we are--

00:03:07.860 --> 00:03:12.095
when we get an APK, the
platform will optimize it,

00:03:12.095 --> 00:03:13.890
and that could take a
long time, depending

00:03:13.890 --> 00:03:16.290
on how we implement it.

00:03:16.290 --> 00:03:19.380
And we don't want that long
time to happen because we want

00:03:19.380 --> 00:03:22.420
you to use the app right away.

00:03:22.420 --> 00:03:25.170
And the other two,
which is memory related,

00:03:25.170 --> 00:03:28.470
is disk space, so
how much space is

00:03:28.470 --> 00:03:33.720
the runtime taking for its own
optimizations, and then RAM.

00:03:33.720 --> 00:03:37.520
So Java being Java,
there's allocation

00:03:37.520 --> 00:03:40.790
that the runtime
needs to handle,

00:03:40.790 --> 00:03:44.190
and if it doesn't do it well,
then it can take a lot of RAM.

00:03:49.600 --> 00:03:53.427
So essentially, there's
been three incarnations

00:03:53.427 --> 00:03:54.385
of the Android Runtime.

00:03:57.005 --> 00:04:00.180
The first one was Dalvik.

00:04:00.180 --> 00:04:04.820
It was the first implementation
that shipped with Android.

00:04:04.820 --> 00:04:09.260
And Dalvik's purpose,
or Dalvik's main focus,

00:04:09.260 --> 00:04:13.280
was how do we save RAM, and the
reason being, back in the day,

00:04:13.280 --> 00:04:16.279
like 10 years ago, the
RAM we had on the phones

00:04:16.279 --> 00:04:19.820
we were shipping was like
even less than 200 megabyte.

00:04:19.820 --> 00:04:21.320
And that was very
little if you want

00:04:21.320 --> 00:04:25.900
to execute the whole
event, the Android stack.

00:04:25.900 --> 00:04:28.140
So everything Dalvik
was doing was about, OK,

00:04:28.140 --> 00:04:29.630
how do we save on RAM?

00:04:29.630 --> 00:04:32.840
So it could not
generate any code.

00:04:32.840 --> 00:04:38.030
JIT or AOT is how
we generate code.

00:04:38.030 --> 00:04:40.287
It could just interpret
the dex code--

00:04:40.287 --> 00:04:41.870
the dex code being
the thing that gets

00:04:41.870 --> 00:04:46.040
sent to Android for
execution of your app.

00:04:46.040 --> 00:04:48.830
Eventually, it got a
just-in-time compiler,

00:04:48.830 --> 00:04:53.820
so that we could generate
native code of the dex code.

00:04:53.820 --> 00:04:56.430
But again, it was very
limited to what it could do,

00:04:56.430 --> 00:05:00.740
because RAM was the main focus.

00:05:00.740 --> 00:05:08.230
And its GC was tailored for
apps to not allocate objects.

00:05:08.230 --> 00:05:12.140
If you've been to the talk this
morning, things have changed.

00:05:12.140 --> 00:05:14.500
But back in the days,
the recommendation

00:05:14.500 --> 00:05:18.650
was like, please
avoid allocations.

00:05:18.650 --> 00:05:22.810
And this worked well
for, I think, five years,

00:05:22.810 --> 00:05:25.210
until KitKat.

00:05:25.210 --> 00:05:30.182
But there was a point where
Dalvik could not keep up.

00:05:30.182 --> 00:05:32.530
Phones were getting bigger.

00:05:32.530 --> 00:05:35.845
Phones were getting more
performance, more RAM.

00:05:39.390 --> 00:05:41.410
That was 2013, '14.

00:05:41.410 --> 00:05:43.240
I think it was 1
gig, 2 gigs of RAM.

00:05:46.000 --> 00:05:48.610
And apps were also
getting bigger.

00:05:48.610 --> 00:05:51.610
So initially, apps were supposed
to be like this small layer

00:05:51.610 --> 00:05:53.960
between UI and the framework.

00:05:53.960 --> 00:05:57.310
But apps started doing a
lot of more and more things.

00:05:57.310 --> 00:05:59.530
So that 60 millisecond
window I talked

00:05:59.530 --> 00:06:01.600
for rendering a frame--
well, more things

00:06:01.600 --> 00:06:05.310
started to be executed there.

00:06:05.310 --> 00:06:06.980
So we had to do
something about it.

00:06:06.980 --> 00:06:09.970
And the answer
happened in Lollipop,

00:06:09.970 --> 00:06:15.350
with ART, which introduced
ahead-of-time compilation.

00:06:15.350 --> 00:06:19.130
So no more interpretation,
or very, very little.

00:06:19.130 --> 00:06:21.730
And most of the things were
ahead-of-time compiled,

00:06:21.730 --> 00:06:24.520
meaning we were executing
native code for your app,

00:06:24.520 --> 00:06:31.360
and that is probably 20x
faster than interpretation.

00:06:31.360 --> 00:06:36.400
We also introduced like
a state of the art GC--

00:06:36.400 --> 00:06:40.010
what you find in regular
runtimes of being precise.

00:06:40.010 --> 00:06:43.520
That means we're not going to
be confused by an integer that

00:06:43.520 --> 00:06:46.390
looks like an object.

00:06:46.390 --> 00:06:49.510
But also generations,
so that the GC

00:06:49.510 --> 00:06:54.450
pauses we need to do in the
UI thread will be very short.

00:06:54.450 --> 00:06:58.180
So pauses don't actually
end up creating jank.

00:07:01.582 --> 00:07:05.950
The third incarnation is
like an evolution of ART.

00:07:05.950 --> 00:07:09.320
It happened in two
releases, Android Nougat

00:07:09.320 --> 00:07:10.050
and Android Oreo.

00:07:12.740 --> 00:07:16.950
In Android Nougat, we introduced
profile-guided compilation.

00:07:16.950 --> 00:07:21.600
I'll talk about this later, or
explain a bit later what it is.

00:07:21.600 --> 00:07:26.310
But it drastically
helped on scaling ART's

00:07:26.310 --> 00:07:29.960
ahead-of-time
technology to be more

00:07:29.960 --> 00:07:34.525
optimized for the platform.

00:07:34.525 --> 00:07:37.940
The profile-guided compilation
has underneath-- the way

00:07:37.940 --> 00:07:41.720
it works is like it's a hybrid
just-in-time, ahead-of-time

00:07:41.720 --> 00:07:42.760
compiler.

00:07:42.760 --> 00:07:46.370
So we're trying to use
the best of both worlds

00:07:46.370 --> 00:07:49.220
to optimize the platform.

00:07:49.220 --> 00:07:52.970
And in O, after we'd done
all the optimizations in N--

00:07:52.970 --> 00:07:56.540
in O, we focused on
the garbage collector,

00:07:56.540 --> 00:08:00.860
and implemented a brand new
one, which makes the pause even

00:08:00.860 --> 00:08:05.290
shorter on the UI thread.

00:08:05.290 --> 00:08:07.860
We call this concurrent GC.

00:08:07.860 --> 00:08:14.870
Now the GC happens on
a different thread,

00:08:14.870 --> 00:08:19.570
so it's not affecting
the execution of the app.

00:08:19.570 --> 00:08:20.780
All right.

00:08:20.780 --> 00:08:22.590
So before I dive
into ART details,

00:08:22.590 --> 00:08:23.840
I wanted to show this to you--

00:08:23.840 --> 00:08:27.670
the state of Android
distribution today.

00:08:27.670 --> 00:08:30.270
And in case you're still
optimizing for Dalvik,

00:08:30.270 --> 00:08:32.760
or if you need to care about
Dalvik, and this annoying

00:08:32.760 --> 00:08:33.395
GC_FOR_ALLOC.

00:08:33.395 --> 00:08:34.770
If you'd been at
Chad's talk, you

00:08:34.770 --> 00:08:36.700
know what I'm talking about--

00:08:36.700 --> 00:08:40.630
well, there's still
this 10% here.

00:08:40.630 --> 00:08:43.890
[INAUDIBLE] KitKat, Jelly
Bean and a few others.

00:08:43.890 --> 00:08:47.520
So around 10% of devices
are still running KitKat.

00:08:47.520 --> 00:08:51.450
So my recommendation
is, it still matters.

00:08:51.450 --> 00:08:54.780
10% is probably like
20 million users.

00:08:54.780 --> 00:08:57.160
It's quite a big number.

00:08:57.160 --> 00:08:58.710
So it still matters.

00:08:58.710 --> 00:09:02.130
But give it a couple
of years, and hopefully

00:09:02.130 --> 00:09:05.810
in two years, that will be gone.

00:09:05.810 --> 00:09:07.920
And Dalvik can be
part of this museum.

00:09:13.690 --> 00:09:18.330
So things ART matters for--

00:09:18.330 --> 00:09:20.670
I've put eight boxes.

00:09:20.670 --> 00:09:21.890
They look nice.

00:09:21.890 --> 00:09:23.580
And we do matter a lot for this.

00:09:23.580 --> 00:09:25.680
Like, if we do get
it wrong, things

00:09:25.680 --> 00:09:29.785
will go bad on your device.

00:09:29.785 --> 00:09:33.360
Raw performance, I talked about.

00:09:33.360 --> 00:09:35.550
That's Java execution.

00:09:35.550 --> 00:09:40.335
Jank, application startup,
battery, disk space, RAM,

00:09:40.335 --> 00:09:41.460
boot times, install times--

00:09:41.460 --> 00:09:44.120
I'm just repeating myself,
but this is really important.

00:09:44.120 --> 00:09:47.240
This is the thing that makes
your user experience kind of OK

00:09:47.240 --> 00:09:49.730
so that you can enjoy the apps.

00:09:52.440 --> 00:09:56.900
I'm going to go over the
releases I talked about-- what

00:09:56.900 --> 00:10:01.410
the different incarnations
of the Android Runtime,

00:10:01.410 --> 00:10:06.620
to show what makes ART today.

00:10:06.620 --> 00:10:11.070
Because ART, like I said,
has a lot of evolutions.

00:10:11.070 --> 00:10:15.050
But we also took good
things from Dalvik.

00:10:15.050 --> 00:10:17.220
I'm listing the major ones
here, because the list

00:10:17.220 --> 00:10:19.670
would be too long.

00:10:19.670 --> 00:10:23.610
And obviously, the major thing
that the Dalvik architecture

00:10:23.610 --> 00:10:26.830
brought was RAM savings.

00:10:26.830 --> 00:10:31.580
And for that, Dalvik,
or the Android platform,

00:10:31.580 --> 00:10:34.610
actually, introduced
the Zygote, which

00:10:34.610 --> 00:10:38.600
is the parent
process that creates

00:10:38.600 --> 00:10:40.990
all of the other processes.

00:10:40.990 --> 00:10:43.750
So because it's
the parent process,

00:10:43.750 --> 00:10:46.480
you have the option
of that parent process

00:10:46.480 --> 00:10:52.310
starting up, or
allocating, a lot of memory

00:10:52.310 --> 00:10:54.110
that apps can use.

00:10:54.110 --> 00:10:58.650
And that memory can be
shared with the other apps.

00:10:58.650 --> 00:10:59.970
And that's super important.

00:10:59.970 --> 00:11:02.360
That means that
every app now doesn't

00:11:02.360 --> 00:11:05.390
need to allocate this memory
that it would need, otherwise,

00:11:05.390 --> 00:11:10.520
to actually execute in ART.

00:11:10.520 --> 00:11:14.480
Today that's around a
couple of dozens of megabyte

00:11:14.480 --> 00:11:19.070
that we save per app, and
that the cycle just allocates

00:11:19.070 --> 00:11:21.200
and shares with the other apps.

00:11:24.992 --> 00:11:29.930
Then Lollipop-- that was the
major shift when we introduced

00:11:29.930 --> 00:11:32.590
ahead-of-time compilation.

00:11:32.590 --> 00:11:34.070
Ahead-of-time
compilation happens

00:11:34.070 --> 00:11:37.880
with what we call an SSA
compiler, Static Signal

00:11:37.880 --> 00:11:39.740
Assignment compiler.

00:11:39.740 --> 00:11:43.340
That's a compiler buzzword that
is like the state of the art

00:11:43.340 --> 00:11:45.470
compiler that does a
lot of optimizations

00:11:45.470 --> 00:11:50.260
and makes your code
up to 20x faster.

00:11:50.260 --> 00:11:52.670
So we introduced the
ahead-of-time compiler.

00:11:52.670 --> 00:11:56.180
That helped a lot
on reducing jank,

00:11:56.180 --> 00:11:59.120
because now the
code was compiled,

00:11:59.120 --> 00:12:02.300
not needing to be
interpreted, and very fast.

00:12:02.300 --> 00:12:05.880
Reducing application
startup-- same argument.

00:12:05.880 --> 00:12:08.180
But also saving battery.

00:12:08.180 --> 00:12:09.900
Now with the execution
being 20x faster,

00:12:09.900 --> 00:12:13.010
you can imagine that it's
not the point of saving

00:12:13.010 --> 00:12:16.550
20x times on a battery,
but things get faster

00:12:16.550 --> 00:12:21.590
and we don't need to execute
a lot on the CPU anymore.

00:12:21.590 --> 00:12:23.620
We also save on boot times.

00:12:23.620 --> 00:12:26.850
The whole Android OS is
ahead-of-time compiled,

00:12:26.850 --> 00:12:29.040
and doesn't need to be
interpreted at boot.

00:12:29.040 --> 00:12:30.370
So here we go.

00:12:30.370 --> 00:12:31.843
Things go faster at boot.

00:12:34.741 --> 00:12:40.210
We also introduced a
new GC, generational GC,

00:12:40.210 --> 00:12:44.260
which reduced the pauses
and removed the need

00:12:44.260 --> 00:12:46.150
for GC_FOR_ALLOC in Dalvik.

00:12:50.126 --> 00:12:54.370
Then the third incarnation,
Nougat and Oreo.

00:12:54.370 --> 00:12:56.650
I mentioned how
there, we introduced

00:12:56.650 --> 00:12:58.590
profile-guided compilation.

00:12:58.590 --> 00:12:59.830
And that thing helps--

00:12:59.830 --> 00:13:02.680
it's kind of the mother of
all the optimizations today

00:13:02.680 --> 00:13:03.580
that we do.

00:13:03.580 --> 00:13:06.610
It helps a lot of these metrics.

00:13:06.610 --> 00:13:12.680
It helps on jank, like
less code gets compiled.

00:13:12.680 --> 00:13:16.200
The things that we care
about gets optimized,

00:13:16.200 --> 00:13:21.600
so the UI thread needs
to run less code.

00:13:21.600 --> 00:13:23.810
It helps on application startup.

00:13:23.810 --> 00:13:26.210
Because we can profile
the application,

00:13:26.210 --> 00:13:29.270
we're able to know what
matters at startup,

00:13:29.270 --> 00:13:32.570
so that when we
recompile the app,

00:13:32.570 --> 00:13:34.460
we recompile it
with optimizations

00:13:34.460 --> 00:13:37.970
that optimize startup.

00:13:37.970 --> 00:13:40.030
It helps on battery--

00:13:40.030 --> 00:13:42.070
again, we're saving
on the amount

00:13:42.070 --> 00:13:45.440
of things we're interpreting.

00:13:45.440 --> 00:13:48.600
It helps on disk
space, because instead

00:13:48.600 --> 00:13:50.760
of compiling the
entire app, which

00:13:50.760 --> 00:13:54.540
was what Lollipop
was doing, now we're

00:13:54.540 --> 00:13:56.830
only compiling the
hard parts of an app,

00:13:56.830 --> 00:14:01.120
and that's probably like
10% to 20% of the dex code.

00:14:01.120 --> 00:14:03.150
So 80% just doesn't
get compiled.

00:14:03.150 --> 00:14:06.192
And that's a lot of savings.

00:14:06.192 --> 00:14:08.050
It saves on RAM--

00:14:08.050 --> 00:14:09.880
having a concurrent
GC means we can

00:14:09.880 --> 00:14:13.980
do a lot more defragmentation
of the heaps of every app,

00:14:13.980 --> 00:14:16.120
so we save that on
the fragmentation

00:14:16.120 --> 00:14:17.560
that we had in the previous GC.

00:14:20.647 --> 00:14:23.880
Profile-guided compilation also
helped a lot on boot times.

00:14:23.880 --> 00:14:26.360
Remember the optimizing
apps dialogue?

00:14:26.360 --> 00:14:28.950
Well, that's the reason
we were able to remove it.

00:14:28.950 --> 00:14:33.780
Now, we didn't need to AOT
compile at boot all of the apps

00:14:33.780 --> 00:14:37.090
to make sure the device was
reasonable in performance.

00:14:37.090 --> 00:14:39.410
We were able to just, OK--

00:14:39.410 --> 00:14:40.909
we take an OTA.

00:14:40.909 --> 00:14:42.450
We're going to JIT
all the apps so we

00:14:42.450 --> 00:14:44.460
don't need to compile at boot.

00:14:44.460 --> 00:14:46.680
We're going to JIT
when the user wants it,

00:14:46.680 --> 00:14:48.360
and then eventually,
we're going to do

00:14:48.360 --> 00:14:51.120
profile-guided
compilation of the apps

00:14:51.120 --> 00:14:55.330
when the user is
not using its phone.

00:14:55.330 --> 00:14:57.370
And then finally, it
helped on install times,

00:14:57.370 --> 00:14:59.890
because instead of
waiting for the compiler

00:14:59.890 --> 00:15:02.500
to compile the entire
app when you install,

00:15:02.500 --> 00:15:04.120
now we didn't compile at all.

00:15:04.120 --> 00:15:05.980
We just rely on the
JIT the first time

00:15:05.980 --> 00:15:06.940
the app was being used.

00:15:12.341 --> 00:15:17.390
And lastly, I want to mention
Pie, because the time we

00:15:17.390 --> 00:15:20.800
developed Pie was kind of at
the same time of Android Go.

00:15:20.800 --> 00:15:24.600
And Android Go was a great
effort in the Android platform.

00:15:24.600 --> 00:15:28.130
And for that, the
work we did was mostly

00:15:28.130 --> 00:15:31.640
to save on disk space and
RAM, because Android Go is

00:15:31.640 --> 00:15:37.870
like 512 to a gigabit of memory
and 4 or 8 gigs of disk space.

00:15:37.870 --> 00:15:39.560
So most of our
efforts were focused

00:15:39.560 --> 00:15:45.000
on improving RAM and also
improving disk space.

00:15:45.000 --> 00:15:47.900
So in that release, we
introduced compact DEX,

00:15:47.900 --> 00:15:53.240
which is a compact version
of the dex format, which

00:15:53.240 --> 00:15:56.330
saves on RAM because
then less you need

00:15:56.330 --> 00:15:59.690
to put into the memory
of the dex code,

00:15:59.690 --> 00:16:02.680
the more you're
saving, obviously.

00:16:02.680 --> 00:16:11.080
Also, when the APK has
uncompressed dex stored,

00:16:11.080 --> 00:16:15.370
we will not
uncompress it on disk.

00:16:15.370 --> 00:16:21.157
So before we used to uncompress
it to do optimizations

00:16:21.157 --> 00:16:23.740
on the dex file, which we cannot
do on the APK because the APK

00:16:23.740 --> 00:16:24.970
is signed.

00:16:24.970 --> 00:16:30.340
So before Pie, we uncompress
it, do some optimizations,

00:16:30.340 --> 00:16:33.190
and rely on the
first few iterations

00:16:33.190 --> 00:16:36.280
before we do
profile-guided compilation.

00:16:36.280 --> 00:16:39.730
Now we give the option
to the developer.

00:16:39.730 --> 00:16:42.760
If the developer wants
to save on disk space,

00:16:42.760 --> 00:16:44.550
then put the dex
file uncompressed

00:16:44.550 --> 00:16:46.810
in the APK, which
means we're not going

00:16:46.810 --> 00:16:48.650
to uncompress it on device.

00:16:48.650 --> 00:16:50.740
We'll have just one
version of the dex code

00:16:50.740 --> 00:16:53.330
and not a compressed
version in the APK

00:16:53.330 --> 00:16:55.770
and an uncompressed one on disk.

00:17:00.440 --> 00:17:03.010
That was a lot of optimizations.

00:17:03.010 --> 00:17:09.030
I wanted to focus on one, which
is raw execution performance,

00:17:09.030 --> 00:17:10.730
because what you
saw this morning was

00:17:10.730 --> 00:17:14.329
pretty cool with [INAUDIBLE],,
but this is even cooler.

00:17:14.329 --> 00:17:18.290
So obviously, the
faster ART runs,

00:17:18.290 --> 00:17:19.750
the more we're
saving on battery,

00:17:19.750 --> 00:17:22.819
on application startup,
and making the UI smooth.

00:17:22.819 --> 00:17:25.569
So it really matters, all
the optimizations we do.

00:17:28.527 --> 00:17:31.160
And over the
releases, we've kept

00:17:31.160 --> 00:17:34.700
on improving the performance by
looking at actual applications.

00:17:34.700 --> 00:17:37.680
In this case it's
the Google Sheets.

00:17:37.680 --> 00:17:39.380
And every release
we worked on, like,

00:17:39.380 --> 00:17:41.530
OK-- how do we improve
the Google Sheets app?

00:17:41.530 --> 00:17:44.090
And the Google
Sheets team helped

00:17:44.090 --> 00:17:47.720
us build benchmarks that
show how long it takes

00:17:47.720 --> 00:17:49.821
to do sheets manipulation.

00:17:52.527 --> 00:17:55.380
Here, higher is better.

00:17:55.380 --> 00:17:57.450
Blue is Dalvik.

00:17:57.450 --> 00:17:59.950
And that's a score of one.

00:17:59.950 --> 00:18:02.840
So we make it relative to
Dalvik, the performance.

00:18:02.840 --> 00:18:05.840
Red is Lollipop-- so that's
when we introduced ART.

00:18:05.840 --> 00:18:07.080
And then yellow is today.

00:18:09.644 --> 00:18:11.310
And you can see that
we went from around

00:18:11.310 --> 00:18:15.330
like a 4x improvement when
we moved to ART and Lollipop

00:18:15.330 --> 00:18:18.090
to like an average of
10x today, and even

00:18:18.090 --> 00:18:22.566
to 26x on one benchmark.

00:18:22.566 --> 00:18:26.590
So we're pretty happy
with those numbers.

00:18:26.590 --> 00:18:29.510
But we just didn't
look just at Sheets.

00:18:29.510 --> 00:18:35.320
We tried to also look at
what happened to other apps.

00:18:35.320 --> 00:18:38.120
So a couple of
years ago, we also

00:18:38.120 --> 00:18:41.840
worked with the Chrome
team and the YouTube team

00:18:41.840 --> 00:18:45.117
to look at what they
think we should optimize.

00:18:45.117 --> 00:18:47.450
And there again, after the
fact, even though we were not

00:18:47.450 --> 00:18:49.850
focused on optimizing
those benchmarks,

00:18:49.850 --> 00:18:55.790
we saw that we'd had this 4x
to 6x improvements with what

00:18:55.790 --> 00:18:58.480
we've done.

00:18:58.480 --> 00:18:59.710
There's two examples.

00:18:59.710 --> 00:19:01.420
There's the
[INAUDIBLE] benchmarks.

00:19:01.420 --> 00:19:03.237
That's the JavaScript
benchmark suite

00:19:03.237 --> 00:19:04.570
that we ported for our purposes.

00:19:07.230 --> 00:19:13.790
That's DeltaBlue and Richards,
and it's again, 2x to 4x, 3.5x,

00:19:13.790 --> 00:19:19.300
for those benchmarks,
up to 6x in Pie.

00:19:19.300 --> 00:19:23.710
And then ExoPlayer that's
the audio and video

00:19:23.710 --> 00:19:28.600
processor driving the
YouTube app on Android.

00:19:28.600 --> 00:19:32.170
Again, around 2x for
the introduction of ART

00:19:32.170 --> 00:19:34.270
and then 4x today in Pie.

00:19:37.672 --> 00:19:42.030
And while I have your
attention on performance,

00:19:42.030 --> 00:19:44.750
I have a shameless call to do.

00:19:44.750 --> 00:19:46.900
We are always super
interested in improving code

00:19:46.900 --> 00:19:48.860
that you think is important.

00:19:48.860 --> 00:19:54.190
So if on your side,
you'd like us to show off

00:19:54.190 --> 00:19:56.770
how we improve
performance of your app,

00:19:56.770 --> 00:19:58.030
please come talk to us.

00:19:58.030 --> 00:20:02.260
There's the office hours from
1:00 to 6:00 this afternoon.

00:20:02.260 --> 00:20:04.240
And we would be really
interested in knowing

00:20:04.240 --> 00:20:07.372
what you think we should
care about for performance.

00:20:07.372 --> 00:20:08.830
And then we can
show that off here.

00:20:14.450 --> 00:20:16.180
So the question
then is, how did we

00:20:16.180 --> 00:20:20.010
get this level of improvements?

00:20:20.010 --> 00:20:24.675
I mentioned our ART now has a
modern compiler implementation.

00:20:24.675 --> 00:20:26.990
I call that SSA.

00:20:26.990 --> 00:20:31.110
And thanks to that
modern SSA compilation,

00:20:31.110 --> 00:20:35.690
there's a bunch of optimizations
we're able to do now.

00:20:35.690 --> 00:20:39.400
If you know compiler,
things could look familiar--

00:20:39.400 --> 00:20:43.780
in-lining, dead
code elimination.

00:20:43.780 --> 00:20:45.880
I'm not going to go
over all of them.

00:20:45.880 --> 00:20:47.470
Lucky you.

00:20:47.470 --> 00:20:51.310
But instead, I'll focus
on an example that

00:20:51.310 --> 00:20:54.220
shows how the optimizations
matter, especially

00:20:54.220 --> 00:20:58.090
for a language like Kotlin,
that puts a lot more

00:20:58.090 --> 00:21:02.750
abstractions to help the
productivity of the user,

00:21:02.750 --> 00:21:06.803
but makes it more challenging
for the runtime to optimize.

00:21:10.510 --> 00:21:13.090
So let's take this
simple method.

00:21:13.090 --> 00:21:14.990
Very simple.

00:21:14.990 --> 00:21:18.174
It takes a function
that takes one argument

00:21:18.174 --> 00:21:19.340
and then returns the length.

00:21:22.581 --> 00:21:26.260
When we run that
through our dexer--

00:21:26.260 --> 00:21:30.760
R8, our awesome new dexer--

00:21:30.760 --> 00:21:33.280
here's the code you get.

00:21:33.280 --> 00:21:36.070
Again, pretty straightforward,
even if you're not

00:21:36.070 --> 00:21:37.660
familiar with dex code.

00:21:37.660 --> 00:21:40.170
You're creating a string--

00:21:40.170 --> 00:21:44.330
then, Kotlin having
[INAUDIBLE] types,

00:21:44.330 --> 00:21:48.040
it'll make sure that
the string is not null

00:21:48.040 --> 00:21:49.990
when you get it passed
to the function.

00:21:49.990 --> 00:21:51.790
So it adds this helper method.

00:21:51.790 --> 00:21:55.630
Hey, check that this
parameter is not null.

00:21:55.630 --> 00:21:59.980
Then invoke [INAUDIBLE]
all of the length

00:21:59.980 --> 00:22:02.140
method on the argument
and return that.

00:22:07.110 --> 00:22:09.591
Kotlin comes with
the built-in library.

00:22:09.591 --> 00:22:12.090
So that's where you can find
implementations of those helper

00:22:12.090 --> 00:22:13.130
methods.

00:22:13.130 --> 00:22:15.320
And for that case, it's
only like a simple method

00:22:15.320 --> 00:22:16.590
that will just, OK--

00:22:16.590 --> 00:22:18.390
is your argument null?

00:22:18.390 --> 00:22:19.260
Yes?

00:22:19.260 --> 00:22:22.930
Then I will throw,
call in another helper,

00:22:22.930 --> 00:22:25.550
or I will just return and
return back to the method.

00:22:30.050 --> 00:22:32.760
So method calls are
pretty expensive.

00:22:32.760 --> 00:22:35.690
So the first thing
that ART will do

00:22:35.690 --> 00:22:38.840
is that it will try to
inline that very small method

00:22:38.840 --> 00:22:40.890
within the caller.

00:22:40.890 --> 00:22:47.800
Here, the compiler is inlining
at the places being called.

00:22:47.800 --> 00:22:50.680
Just for simplicity reasons,
this looks like dex code.

00:22:50.680 --> 00:22:53.270
It's actually the intermediate
format of the compiler,

00:22:53.270 --> 00:22:57.110
but I'm not going
to show that to you.

00:22:57.110 --> 00:23:01.291
So compile code
is being inlined,

00:23:01.291 --> 00:23:06.820
which helps on performance,
but there's more we can do,

00:23:06.820 --> 00:23:09.300
because the compiler
sees, oh, wait--

00:23:09.300 --> 00:23:12.700
that throw parameter
is null exception call.

00:23:12.700 --> 00:23:15.988
It actually always throws.

00:23:15.988 --> 00:23:19.170
So there's a few things I
can do with that information.

00:23:23.870 --> 00:23:27.080
The first one is
called Code Layout,

00:23:27.080 --> 00:23:29.650
where we're trying
to put together

00:23:29.650 --> 00:23:33.120
the regular flow of the method.

00:23:33.120 --> 00:23:36.320
So things that rarely
happen, we put that

00:23:36.320 --> 00:23:38.630
at the very end of the
method, so it doesn't affect

00:23:38.630 --> 00:23:41.596
the flow of the execution.

00:23:41.596 --> 00:23:46.870
A nifty trick-- we just
switched the comparison from,

00:23:46.870 --> 00:23:49.115
hey, are you not
0, to are you 0,

00:23:49.115 --> 00:23:52.270
and then we jump to the end of
the method, which is like, hey,

00:23:52.270 --> 00:23:54.445
throw an exception.

00:23:54.445 --> 00:23:57.590
So the expensive jump is
out of the picture now.

00:24:01.339 --> 00:24:02.880
The second optimization
is that we're

00:24:02.880 --> 00:24:06.960
going to move things that,
hey, the regular flow doesn't

00:24:06.960 --> 00:24:08.740
care about.

00:24:08.740 --> 00:24:10.730
In this case, let
me just go back.

00:24:15.090 --> 00:24:19.140
In this case, the
construction of the string

00:24:19.140 --> 00:24:22.200
that is being
passed to the helper

00:24:22.200 --> 00:24:24.800
was the first thing you
execute in the method.

00:24:24.800 --> 00:24:28.608
But you only need that if you
end up calling the helper.

00:24:28.608 --> 00:24:32.340
So we move that construction
of that string right

00:24:32.340 --> 00:24:34.920
before the helper,
meaning we don't

00:24:34.920 --> 00:24:37.730
need to execute it anymore.

00:24:37.730 --> 00:24:40.570
So in the end, we started
from a method that

00:24:40.570 --> 00:24:44.240
was like creating a
string, calling a helper,

00:24:44.240 --> 00:24:47.212
then doing its thing, which
is returning the length,

00:24:47.212 --> 00:24:50.810
to a method that's just
like, check if it's null.

00:24:50.810 --> 00:24:53.940
If it is, jump to an
expensive jump somewhere.

00:24:53.940 --> 00:24:56.350
If it's not, just
continue the flow

00:24:56.350 --> 00:25:00.120
and return the
length of the string.

00:25:04.700 --> 00:25:06.140
All right.

00:25:06.140 --> 00:25:09.730
So that was raw performance.

00:25:09.730 --> 00:25:11.590
I have two other
things to talk about--

00:25:11.590 --> 00:25:13.645
actually, just
one, because I have

00:25:13.645 --> 00:25:15.790
to talk about application
startup and garbage

00:25:15.790 --> 00:25:18.490
collection, but I'm not going
to redo the garbage collection

00:25:18.490 --> 00:25:19.300
slide.

00:25:19.300 --> 00:25:24.190
Chad and Omar did a
great job this morning.

00:25:24.190 --> 00:25:27.560
So with application
startup, it's

00:25:27.560 --> 00:25:30.380
been a major focus
since we introduced

00:25:30.380 --> 00:25:34.350
profile-guided compilation.

00:25:34.350 --> 00:25:36.860
And that happened in Nougat.

00:25:36.860 --> 00:25:38.890
Profile-guided
compilation is when,

00:25:38.890 --> 00:25:43.700
when the app is
being installed, we

00:25:43.700 --> 00:25:46.330
compile it in a very quick way.

00:25:46.330 --> 00:25:50.580
Like, we're not going
to generate a full AOT

00:25:50.580 --> 00:25:51.610
compilation.

00:25:51.610 --> 00:25:54.170
We're going to do very
little optimizations that

00:25:54.170 --> 00:25:56.180
do not affect install time.

00:25:56.180 --> 00:25:57.700
So we're optimizing
install time.

00:25:57.700 --> 00:25:59.570
So the app is being installed.

00:25:59.570 --> 00:26:01.250
Then you run it.

00:26:01.250 --> 00:26:02.660
The app is being executed.

00:26:02.660 --> 00:26:05.720
Initially, it gets executed
with interpretation,

00:26:05.720 --> 00:26:08.560
and then method
gets hot, and then

00:26:08.560 --> 00:26:10.940
JIT kicks in and compiles
those hot methods.

00:26:13.670 --> 00:26:17.710
The JIT knows what
those hot methods are.

00:26:17.710 --> 00:26:20.140
So we are going to
dump to a profile

00:26:20.140 --> 00:26:27.476
file those hot methods so that
when your device is idle--

00:26:27.476 --> 00:26:29.340
the user's not using it.

00:26:29.340 --> 00:26:30.260
It's charging.

00:26:30.260 --> 00:26:31.870
100% charge.

00:26:31.870 --> 00:26:36.720
Then we have this what we call
profile-guided daemon that will

00:26:36.720 --> 00:26:37.740
just like, OK--

00:26:37.740 --> 00:26:42.680
let me work over all the
profiles and recompile the app,

00:26:42.680 --> 00:26:49.040
and compile only the things that
matter based on that profile.

00:26:49.040 --> 00:26:51.770
And you have like this
virtuous loop where,

00:26:51.770 --> 00:26:55.460
the next time you run the
app, we're going to use that

00:26:55.460 --> 00:26:58.920
optimized version of
the compiled code,

00:26:58.920 --> 00:27:02.510
and then run it
with what got AOT'd.

00:27:02.510 --> 00:27:06.890
Maybe some methods got missed,
so we'll interpret them.

00:27:06.890 --> 00:27:07.640
They'll get hot.

00:27:07.640 --> 00:27:08.630
We'll JIT them.

00:27:08.630 --> 00:27:12.380
We'll update the profile,
and then again, the daemon

00:27:12.380 --> 00:27:14.610
kicks in and says, oh,
the profile got updated.

00:27:14.610 --> 00:27:16.020
Let me recompile the app.

00:27:16.020 --> 00:27:18.860
So there's this virtuous
loop of trying to be

00:27:18.860 --> 00:27:20.750
better and better over time.

00:27:24.180 --> 00:27:28.144
And why is that helping
on application startup?

00:27:28.144 --> 00:27:29.560
Well, that's because
the things we

00:27:29.560 --> 00:27:32.110
do when we compile the
app based on the profile

00:27:32.110 --> 00:27:34.540
are really optimized
towards this.

00:27:34.540 --> 00:27:39.500
We are only going to
compile startup methods.

00:27:39.500 --> 00:27:41.440
So now, no need
to interpret them.

00:27:41.440 --> 00:27:44.685
Things that get executed at
startup will get compiled.

00:27:47.340 --> 00:27:51.480
We're going to lay out the
dex and the compile code,

00:27:51.480 --> 00:27:53.730
so things that
execute at startup

00:27:53.730 --> 00:27:55.542
will be next to each other.

00:27:55.542 --> 00:27:58.280
So now we don't need to
jump over the entire dex

00:27:58.280 --> 00:28:01.947
file to actually get
access to the method.

00:28:01.947 --> 00:28:03.030
And that's very important.

00:28:03.030 --> 00:28:05.820
Like I said, apps got bigger.

00:28:05.820 --> 00:28:09.170
So if you need to bring up
the entire dex file just

00:28:09.170 --> 00:28:12.840
for startup, that's a lot
of time waiting on IO.

00:28:12.840 --> 00:28:15.200
So we're trying to reduce
that by putting everything

00:28:15.200 --> 00:28:18.660
on startup at the beginning,
and then the rest at the end.

00:28:21.970 --> 00:28:27.970
Profile-guided compilation also
generates an application image.

00:28:27.970 --> 00:28:32.150
Other runtimes-- we'll
call this a snapshot.

00:28:32.150 --> 00:28:37.190
It's a representation
of Java classes

00:28:37.190 --> 00:28:39.650
that we put in that image.

00:28:39.650 --> 00:28:40.775
It's a file.

00:28:40.775 --> 00:28:44.390
And that avoids us to actually
load the classes at runtime

00:28:44.390 --> 00:28:45.830
again.

00:28:45.830 --> 00:28:49.040
So there's this
pre-formatted number

00:28:49.040 --> 00:28:53.820
of classes with a class
loader, and when we startup,

00:28:53.820 --> 00:28:55.070
we just take the class loader.

00:28:55.070 --> 00:28:57.836
All the classes are
already populated.

00:28:57.836 --> 00:29:03.330
And we're done-- we don't need
to do class loading anymore.

00:29:03.330 --> 00:29:06.370
We're also going to try
to pre-initialize classes.

00:29:06.370 --> 00:29:08.870
So Java has this
type of, oh, classes

00:29:08.870 --> 00:29:11.910
need to be initialized before
they need to be executed.

00:29:11.910 --> 00:29:14.299
So what we do during
profile-guided compilation

00:29:14.299 --> 00:29:16.340
is that we're going to
pre-initialize anything we

00:29:16.340 --> 00:29:22.872
can to avoid that being
executed when we start the app.

00:29:22.872 --> 00:29:25.170
And then finally,
I said we're not

00:29:25.170 --> 00:29:29.050
going to compile code
that doesn't get executed.

00:29:29.050 --> 00:29:36.600
That helps a lot, because
then your compile file

00:29:36.600 --> 00:29:39.420
is very small, so there's not
a lot you need to bring up

00:29:39.420 --> 00:29:41.896
in memory to actually execute.

00:29:46.560 --> 00:29:51.500
What do we gain from
all those optimizations?

00:29:51.500 --> 00:29:56.060
Well, we always gain
doing those optimizations.

00:29:56.060 --> 00:30:01.660
But depending on the app,
it can be up to 10% or 30%.

00:30:01.660 --> 00:30:06.090
And that's usually around how
many Java code do you have

00:30:06.090 --> 00:30:08.480
when you start your app.

00:30:08.480 --> 00:30:11.450
Typically, Camera has
lot of native code.

00:30:11.450 --> 00:30:15.520
So that's where it's on the low
end of like 10% improvement.

00:30:15.520 --> 00:30:18.260
But in this example, you
see Docs and Maps, which

00:30:18.260 --> 00:30:24.760
are very Java heavy,
go from around 30%

00:30:24.760 --> 00:30:26.680
of app startup improvement.

00:30:32.790 --> 00:30:37.940
And this is numbers that we
got from the Maps team, who

00:30:37.940 --> 00:30:39.430
got that from actual users.

00:30:39.430 --> 00:30:43.690
So actual data that
comes from the field.

00:30:43.690 --> 00:30:47.140
And when the Maps
team saw that graph,

00:30:47.140 --> 00:30:50.260
they were like,
what is going on?

00:30:50.260 --> 00:30:54.290
How come at install,
things are around

00:30:54.290 --> 00:31:00.300
like one second of app startup,
to over time things get faster?

00:31:00.300 --> 00:31:01.790
How does that happen?

00:31:01.790 --> 00:31:05.970
And every time they update
the app, it's the same trend.

00:31:05.970 --> 00:31:11.990
It starts pretty high,
and then goes low.

00:31:11.990 --> 00:31:14.540
And the answer is
profile-guided compilation.

00:31:14.540 --> 00:31:18.150
Here, you're clearly seeing that
over time, things get better.

00:31:22.870 --> 00:31:28.820
Today in Pie-- what we
talked about at I/O last year

00:31:28.820 --> 00:31:33.720
is the introduction of
profiles in the cloud.

00:31:33.720 --> 00:31:40.570
And that's how we're making
the entire ecosystem send us

00:31:40.570 --> 00:31:41.620
profiles--

00:31:41.620 --> 00:31:44.290
like, actual execution
profiles of users,

00:31:44.290 --> 00:31:48.340
so that we can
send those profiles

00:31:48.340 --> 00:31:50.440
to new users of the
app, so they don't

00:31:50.440 --> 00:31:57.040
get this starts at one second,
ends up at 750 milliseconds.

00:31:57.040 --> 00:32:00.400
They get the 750
milliseconds right away,

00:32:00.400 --> 00:32:03.090
because they get the profile
at the point they install.

00:32:08.270 --> 00:32:10.000
Garbage collection.

00:32:10.000 --> 00:32:13.870
Like I said, I'm
not going over it.

00:32:13.870 --> 00:32:18.960
Maybe I can just
put back a number

00:32:18.960 --> 00:32:20.330
that we're all very proud of.

00:32:26.078 --> 00:32:27.030
Here we are.

00:32:27.030 --> 00:32:30.030
Ah, that's the last.

00:32:30.030 --> 00:32:34.890
So this is resuming what Chad
talked about this morning.

00:32:34.890 --> 00:32:37.170
It's all the
technology we've used

00:32:37.170 --> 00:32:40.530
over time for building a GC.

00:32:40.530 --> 00:32:44.490
So you see in KitKat,
we had this, what we

00:32:44.490 --> 00:32:46.860
called concurrent mark sweep.

00:32:46.860 --> 00:32:50.180
There was one part of the
GC that was concurrent.

00:32:50.180 --> 00:32:54.160
And that stayed for
up until Nougat.

00:32:54.160 --> 00:32:55.980
In Oreo, that's
when we introduced

00:32:55.980 --> 00:32:59.500
a concurrent collector.

00:32:59.500 --> 00:33:02.320
Allocation in KitKat
was the main bottleneck.

00:33:02.320 --> 00:33:04.210
And it was single
threaded, so it

00:33:04.210 --> 00:33:08.460
needed to lock to actually
allocate something.

00:33:08.460 --> 00:33:11.410
The introduction of
a new GC in Lollipop

00:33:11.410 --> 00:33:14.170
meant that we could
allocate within the thread

00:33:14.170 --> 00:33:15.340
and not need to lock.

00:33:15.340 --> 00:33:17.760
So that improved
performance of allocation.

00:33:22.630 --> 00:33:26.360
When you allocate objects,
they are short-lived, right?

00:33:26.360 --> 00:33:29.206
And that's the motto
of Java is like,

00:33:29.206 --> 00:33:30.455
feel free to allocate objects.

00:33:30.455 --> 00:33:32.746
The ones that are short-lived
will be removed by the GC

00:33:32.746 --> 00:33:34.580
very quickly.

00:33:34.580 --> 00:33:38.440
But in KitKat, in Dalvik
days, that was not the case.

00:33:38.440 --> 00:33:43.015
You paid a very high cost by
allocating temporary objects.

00:33:46.460 --> 00:33:49.040
Lollipop is when we
introduced a new GC.

00:33:49.040 --> 00:33:53.210
And you didn't pay
that cost at all.

00:33:53.210 --> 00:33:55.070
Like, allocating a
short-lived object was--

00:33:55.070 --> 00:33:59.030
we had generations, so things
were removed pretty quickly.

00:33:59.030 --> 00:34:02.850
There's an asterisk for Oreo,
because when we introduced

00:34:02.850 --> 00:34:07.590
concurrent collector, we
removed the generations out

00:34:07.590 --> 00:34:09.889
of the collector.

00:34:09.889 --> 00:34:12.110
We're fixing that today.

00:34:12.110 --> 00:34:13.190
It's in the OSP--

00:34:13.190 --> 00:34:15.590
the improvement of the
GC with generations.

00:34:15.590 --> 00:34:17.780
So hopefully it will be
there in the device soon.

00:34:20.690 --> 00:34:23.370
And then fragmentation--
fragmentation

00:34:23.370 --> 00:34:27.510
is a big problem in Android,
because if you're not

00:34:27.510 --> 00:34:32.320
able to allocate memory,
your app will be killed.

00:34:32.320 --> 00:34:35.489
So doing compaction
of the memory,

00:34:35.489 --> 00:34:40.070
so that things are not
fragmented, is super important.

00:34:40.070 --> 00:34:43.131
KitKat did a bit,
but very little.

00:34:43.131 --> 00:34:46.013
In Lollipop over
Marshmallow, we were doing it

00:34:46.013 --> 00:34:47.429
when the app was
going background.

00:34:47.429 --> 00:34:49.940
So eventually, we're
reclaiming the memory.

00:34:49.940 --> 00:34:53.739
But Oreo is when we made it like
it's really important that we

00:34:53.739 --> 00:34:57.240
compact all the time, so that
the memory is there, available,

00:34:57.240 --> 00:35:00.264
all the time.

00:35:00.264 --> 00:35:03.850
And then the number
I was looking for--

00:35:03.850 --> 00:35:05.200
allocation speed.

00:35:05.200 --> 00:35:08.300
We went from a very
low number in Dalvik

00:35:08.300 --> 00:35:12.178
to an 18x improvement
in Oreo and Pie.

00:35:17.660 --> 00:35:22.970
And here's the reasons
it got improved.

00:35:22.970 --> 00:35:24.650
Lollipop added a
custom allocator

00:35:24.650 --> 00:35:27.500
that did not need to lock.

00:35:27.500 --> 00:35:32.180
Then in Marshmallow, we
had fewer CAS operations,

00:35:32.180 --> 00:35:35.090
automatic operations,
that have a cost,

00:35:35.090 --> 00:35:37.070
but we were able to
remove a bit of them.

00:35:37.070 --> 00:35:41.000
Then all of that implementation
of the allocation path

00:35:41.000 --> 00:35:44.090
was moved to Assembly
code in Nougat,

00:35:44.090 --> 00:35:45.710
which made things even faster.

00:35:45.710 --> 00:35:48.020
And then finally,
in Android Oreo,

00:35:48.020 --> 00:35:51.980
we implemented bump
pointer allocation, which

00:35:51.980 --> 00:35:53.900
meant the only thing
you do when you allocate

00:35:53.900 --> 00:35:55.580
is increment a pointer.

00:35:59.730 --> 00:36:00.390
All right.

00:36:00.390 --> 00:36:04.230
With that, this is the
recommendation that Chad has.

00:36:04.230 --> 00:36:05.970
And that comes from us.

00:36:05.970 --> 00:36:08.650
So I'll give the same.

00:36:08.650 --> 00:36:09.990
Creating garbage is OK today.

00:36:14.459 --> 00:36:16.500
You can use a type and
allocate objects you need.

00:36:19.392 --> 00:36:22.320
GC is still overhead.

00:36:22.320 --> 00:36:25.760
So be mindful that if you
allocate a lot of objects,

00:36:25.760 --> 00:36:27.890
then GC will need to run.

00:36:27.890 --> 00:36:31.690
But it's less a
problem since Dalvik.

00:36:36.470 --> 00:36:38.750
And with that, thank you.

00:36:38.750 --> 00:36:40.550
[APPLAUSE]

00:36:42.350 --> 00:36:45.100
[MUSIC PLAYING]

