WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.360
the job of the function D which you

00:00:02.360 --> 00:00:02.370
the job of the function D which you
 

00:00:02.370 --> 00:00:04.519
the job of the function D which you
learned about in the last video is to

00:00:04.519 --> 00:00:04.529
learned about in the last video is to
 

00:00:04.529 --> 00:00:07.070
learned about in the last video is to
input two faces and tell you how similar

00:00:07.070 --> 00:00:07.080
input two faces and tell you how similar
 

00:00:07.080 --> 00:00:09.290
input two faces and tell you how similar
or how different they are a good way to

00:00:09.290 --> 00:00:09.300
or how different they are a good way to
 

00:00:09.300 --> 00:00:12.290
or how different they are a good way to
do this is to use a Siamese Network

00:00:12.290 --> 00:00:12.300
do this is to use a Siamese Network
 

00:00:12.300 --> 00:00:15.919
do this is to use a Siamese Network
let's take a look you're used to seeing

00:00:15.919 --> 00:00:15.929
let's take a look you're used to seeing
 

00:00:15.929 --> 00:00:18.050
let's take a look you're used to seeing
pictures of confidence like these where

00:00:18.050 --> 00:00:18.060
pictures of confidence like these where
 

00:00:18.060 --> 00:00:20.510
pictures of confidence like these where
you input an image let's say X 1 and

00:00:20.510 --> 00:00:20.520
you input an image let's say X 1 and
 

00:00:20.520 --> 00:00:23.300
you input an image let's say X 1 and
through a sequence of convolutional and

00:00:23.300 --> 00:00:23.310
through a sequence of convolutional and
 

00:00:23.310 --> 00:00:25.250
through a sequence of convolutional and
pulling and fully connected layers and

00:00:25.250 --> 00:00:25.260
pulling and fully connected layers and
 

00:00:25.260 --> 00:00:29.890
pulling and fully connected layers and
with a feature vector like that and

00:00:29.890 --> 00:00:29.900
with a feature vector like that and
 

00:00:29.900 --> 00:00:33.650
with a feature vector like that and
sometimes this is fed to a softmax unit

00:00:33.650 --> 00:00:33.660
sometimes this is fed to a softmax unit
 

00:00:33.660 --> 00:00:36.080
sometimes this is fed to a softmax unit
to make a classification but we're gonna

00:00:36.080 --> 00:00:36.090
to make a classification but we're gonna
 

00:00:36.090 --> 00:00:38.290
to make a classification but we're gonna
not going to use that in this video

00:00:38.290 --> 00:00:38.300
not going to use that in this video
 

00:00:38.300 --> 00:00:41.270
not going to use that in this video
instead we're going to focus on this

00:00:41.270 --> 00:00:41.280
instead we're going to focus on this
 

00:00:41.280 --> 00:00:45.830
instead we're going to focus on this
vector of let's say 128 numbers computed

00:00:45.830 --> 00:00:45.840
vector of let's say 128 numbers computed
 

00:00:45.840 --> 00:00:48.260
vector of let's say 128 numbers computed
by some fully connected layer that is

00:00:48.260 --> 00:00:48.270
by some fully connected layer that is
 

00:00:48.270 --> 00:00:51.590
by some fully connected layer that is
deeper in the network and I'm going to

00:00:51.590 --> 00:00:51.600
deeper in the network and I'm going to
 

00:00:51.600 --> 00:00:56.240
deeper in the network and I'm going to
give this this of 128 numbers a name I'm

00:00:56.240 --> 00:00:56.250
give this this of 128 numbers a name I'm
 

00:00:56.250 --> 00:01:00.860
give this this of 128 numbers a name I'm
going to call this f of X 1 and you

00:01:00.860 --> 00:01:00.870
going to call this f of X 1 and you
 

00:01:00.870 --> 00:01:04.039
going to call this f of X 1 and you
should think of f of X 1 as an encoding

00:01:04.039 --> 00:01:04.049
should think of f of X 1 as an encoding
 

00:01:04.049 --> 00:01:09.080
should think of f of X 1 as an encoding
of the input image X 1 so it's taken the

00:01:09.080 --> 00:01:09.090
of the input image X 1 so it's taken the
 

00:01:09.090 --> 00:01:11.630
of the input image X 1 so it's taken the
input image here this picture of kion

00:01:11.630 --> 00:01:11.640
input image here this picture of kion
 

00:01:11.640 --> 00:01:15.010
input image here this picture of kion
and is re representing it as a vector of

00:01:15.010 --> 00:01:15.020
and is re representing it as a vector of
 

00:01:15.020 --> 00:01:18.710
and is re representing it as a vector of
128 numbers the way you can build a

00:01:18.710 --> 00:01:18.720
128 numbers the way you can build a
 

00:01:18.720 --> 00:01:21.410
128 numbers the way you can build a
face-recognition system is then that if

00:01:21.410 --> 00:01:21.420
face-recognition system is then that if
 

00:01:21.420 --> 00:01:23.899
face-recognition system is then that if
you want to compare two pictures let's

00:01:23.899 --> 00:01:23.909
you want to compare two pictures let's
 

00:01:23.909 --> 00:01:26.480
you want to compare two pictures let's
say this first picture with this second

00:01:26.480 --> 00:01:26.490
say this first picture with this second
 

00:01:26.490 --> 00:01:29.240
say this first picture with this second
picture here what you can do is feed the

00:01:29.240 --> 00:01:29.250
picture here what you can do is feed the
 

00:01:29.250 --> 00:01:31.190
picture here what you can do is feed the
second picture to the same neural

00:01:31.190 --> 00:01:31.200
second picture to the same neural
 

00:01:31.200 --> 00:01:33.740
second picture to the same neural
network with the same parameters and get

00:01:33.740 --> 00:01:33.750
network with the same parameters and get
 

00:01:33.750 --> 00:01:38.240
network with the same parameters and get
a different vector of 128 numbers which

00:01:38.240 --> 00:01:38.250
a different vector of 128 numbers which
 

00:01:38.250 --> 00:01:40.760
a different vector of 128 numbers which
represents or which encodes the second

00:01:40.760 --> 00:01:40.770
represents or which encodes the second
 

00:01:40.770 --> 00:01:43.039
represents or which encodes the second
picture so I'm going to call this second

00:01:43.039 --> 00:01:43.049
picture so I'm going to call this second
 

00:01:43.049 --> 00:01:45.350
picture so I'm going to call this second
picture so I'm going to call this

00:01:45.350 --> 00:01:45.360
picture so I'm going to call this
 

00:01:45.360 --> 00:01:50.359
picture so I'm going to call this
encoding of this second picture f of X 2

00:01:50.359 --> 00:01:50.369
encoding of this second picture f of X 2
 

00:01:50.369 --> 00:01:53.690
encoding of this second picture f of X 2
and here I'm using X 1 and X 2 just to

00:01:53.690 --> 00:01:53.700
and here I'm using X 1 and X 2 just to
 

00:01:53.700 --> 00:01:55.969
and here I'm using X 1 and X 2 just to
denote two input images they don't

00:01:55.969 --> 00:01:55.979
denote two input images they don't
 

00:01:55.979 --> 00:01:58.010
denote two input images they don't
necessarily have to be the first and

00:01:58.010 --> 00:01:58.020
necessarily have to be the first and
 

00:01:58.020 --> 00:02:00.020
necessarily have to be the first and
second examples in your training sets it

00:02:00.020 --> 00:02:00.030
second examples in your training sets it
 

00:02:00.030 --> 00:02:03.080
second examples in your training sets it
can be any two pictures finally if you

00:02:03.080 --> 00:02:03.090
can be any two pictures finally if you
 

00:02:03.090 --> 00:02:05.359
can be any two pictures finally if you
believe that these encoding x' are a

00:02:05.359 --> 00:02:05.369
believe that these encoding x' are a
 

00:02:05.369 --> 00:02:08.150
believe that these encoding x' are a
good representation of these two images

00:02:08.150 --> 00:02:08.160
good representation of these two images
 

00:02:08.160 --> 00:02:10.820
good representation of these two images
what you can do is then to find the

00:02:10.820 --> 00:02:10.830
what you can do is then to find the
 

00:02:10.830 --> 00:02:11.620
what you can do is then to find the
image

00:02:11.620 --> 00:02:11.630
image
 

00:02:11.630 --> 00:02:18.580
image
of distance between X 1 and X 2 has the

00:02:18.580 --> 00:02:18.590
of distance between X 1 and X 2 has the
 

00:02:18.590 --> 00:02:22.360
of distance between X 1 and X 2 has the
norm of the difference between the

00:02:22.360 --> 00:02:22.370
norm of the difference between the
 

00:02:22.370 --> 00:02:27.370
norm of the difference between the
encoding of these two images so this

00:02:27.370 --> 00:02:27.380
encoding of these two images so this
 

00:02:27.380 --> 00:02:29.860
encoding of these two images so this
idea of running two identical

00:02:29.860 --> 00:02:29.870
idea of running two identical
 

00:02:29.870 --> 00:02:32.110
idea of running two identical
convolutional neural networks on two

00:02:32.110 --> 00:02:32.120
convolutional neural networks on two
 

00:02:32.120 --> 00:02:34.480
convolutional neural networks on two
different inputs and then comparing them

00:02:34.480 --> 00:02:34.490
different inputs and then comparing them
 

00:02:34.490 --> 00:02:37.480
different inputs and then comparing them
sometimes that's called a Siamese neural

00:02:37.480 --> 00:02:37.490
sometimes that's called a Siamese neural
 

00:02:37.490 --> 00:02:40.210
sometimes that's called a Siamese neural
network architecture and a lot of the

00:02:40.210 --> 00:02:40.220
network architecture and a lot of the
 

00:02:40.220 --> 00:02:43.630
network architecture and a lot of the
ideas I'm presenting here came from this

00:02:43.630 --> 00:02:43.640
ideas I'm presenting here came from this
 

00:02:43.640 --> 00:02:46.600
ideas I'm presenting here came from this
paper due to yawn of Tackman Minyoung

00:02:46.600 --> 00:02:46.610
paper due to yawn of Tackman Minyoung
 

00:02:46.610 --> 00:02:49.630
paper due to yawn of Tackman Minyoung
marker really Renato and Leo wolf in a

00:02:49.630 --> 00:02:49.640
marker really Renato and Leo wolf in a
 

00:02:49.640 --> 00:02:51.880
marker really Renato and Leo wolf in a
research system that they developed

00:02:51.880 --> 00:02:51.890
research system that they developed
 

00:02:51.890 --> 00:02:55.720
research system that they developed
called deep face and many of the ideas

00:02:55.720 --> 00:02:55.730
called deep face and many of the ideas
 

00:02:55.730 --> 00:02:58.630
called deep face and many of the ideas
I'm presenting here came from a paper

00:02:58.630 --> 00:02:58.640
I'm presenting here came from a paper
 

00:02:58.640 --> 00:03:01.720
I'm presenting here came from a paper
due to yawn of Todman Minyoung marker

00:03:01.720 --> 00:03:01.730
due to yawn of Todman Minyoung marker
 

00:03:01.730 --> 00:03:04.420
due to yawn of Todman Minyoung marker
really Renato and Leo wolf in the system

00:03:04.420 --> 00:03:04.430
really Renato and Leo wolf in the system
 

00:03:04.430 --> 00:03:08.650
really Renato and Leo wolf in the system
that they developed called deep face so

00:03:08.650 --> 00:03:08.660
that they developed called deep face so
 

00:03:08.660 --> 00:03:10.930
that they developed called deep face so
how do you train this siamese neural

00:03:10.930 --> 00:03:10.940
how do you train this siamese neural
 

00:03:10.940 --> 00:03:13.360
how do you train this siamese neural
network remember that these two neural

00:03:13.360 --> 00:03:13.370
network remember that these two neural
 

00:03:13.370 --> 00:03:16.840
network remember that these two neural
networks have the same parameters so

00:03:16.840 --> 00:03:16.850
networks have the same parameters so
 

00:03:16.850 --> 00:03:18.550
networks have the same parameters so
what you want to do is really train a

00:03:18.550 --> 00:03:18.560
what you want to do is really train a
 

00:03:18.560 --> 00:03:21.040
what you want to do is really train a
neural network so that the encoding that

00:03:21.040 --> 00:03:21.050
neural network so that the encoding that
 

00:03:21.050 --> 00:03:24.340
neural network so that the encoding that
it computes results in a function D that

00:03:24.340 --> 00:03:24.350
it computes results in a function D that
 

00:03:24.350 --> 00:03:26.170
it computes results in a function D that
tells you when two pictures are of the

00:03:26.170 --> 00:03:26.180
tells you when two pictures are of the
 

00:03:26.180 --> 00:03:28.870
tells you when two pictures are of the
same person so more formally the

00:03:28.870 --> 00:03:28.880
same person so more formally the
 

00:03:28.880 --> 00:03:30.910
same person so more formally the
parameters of the neural network define

00:03:30.910 --> 00:03:30.920
parameters of the neural network define
 

00:03:30.920 --> 00:03:34.510
parameters of the neural network define
an encoding f of X I so given any input

00:03:34.510 --> 00:03:34.520
an encoding f of X I so given any input
 

00:03:34.520 --> 00:03:37.150
an encoding f of X I so given any input
image X I the neural network oprah's

00:03:37.150 --> 00:03:37.160
image X I the neural network oprah's
 

00:03:37.160 --> 00:03:40.690
image X I the neural network oprah's
this engine 28 dimensional encoding f of

00:03:40.690 --> 00:03:40.700
this engine 28 dimensional encoding f of
 

00:03:40.700 --> 00:03:43.990
this engine 28 dimensional encoding f of
X I so more formally what you want to do

00:03:43.990 --> 00:03:44.000
X I so more formally what you want to do
 

00:03:44.000 --> 00:03:46.510
X I so more formally what you want to do
is learn parameters so that if two

00:03:46.510 --> 00:03:46.520
is learn parameters so that if two
 

00:03:46.520 --> 00:03:50.170
is learn parameters so that if two
pictures X I and XJ are of the same

00:03:50.170 --> 00:03:50.180
pictures X I and XJ are of the same
 

00:03:50.180 --> 00:03:52.840
pictures X I and XJ are of the same
person then you want that distance

00:03:52.840 --> 00:03:52.850
person then you want that distance
 

00:03:52.850 --> 00:03:55.380
person then you want that distance
between their encodings to be small and

00:03:55.380 --> 00:03:55.390
between their encodings to be small and
 

00:03:55.390 --> 00:03:58.750
between their encodings to be small and
in the previous slide I was using x1 and

00:03:58.750 --> 00:03:58.760
in the previous slide I was using x1 and
 

00:03:58.760 --> 00:04:02.080
in the previous slide I was using x1 and
x2 but is really any pair X I and XJ

00:04:02.080 --> 00:04:02.090
x2 but is really any pair X I and XJ
 

00:04:02.090 --> 00:04:04.840
x2 but is really any pair X I and XJ
from your training set and in contrast

00:04:04.840 --> 00:04:04.850
from your training set and in contrast
 

00:04:04.850 --> 00:04:08.740
from your training set and in contrast
if X I XJ are of different persons then

00:04:08.740 --> 00:04:08.750
if X I XJ are of different persons then
 

00:04:08.750 --> 00:04:11.020
if X I XJ are of different persons then
you want that distance between their

00:04:11.020 --> 00:04:11.030
you want that distance between their
 

00:04:11.030 --> 00:04:14.410
you want that distance between their
encodings to be large so as you vary the

00:04:14.410 --> 00:04:14.420
encodings to be large so as you vary the
 

00:04:14.420 --> 00:04:16.630
encodings to be large so as you vary the
parameters and all of these layers of

00:04:16.630 --> 00:04:16.640
parameters and all of these layers of
 

00:04:16.640 --> 00:04:17.580
parameters and all of these layers of
the neural net

00:04:17.580 --> 00:04:17.590
the neural net
 

00:04:17.590 --> 00:04:19.740
the neural net
where you end up with different and

00:04:19.740 --> 00:04:19.750
where you end up with different and
 

00:04:19.750 --> 00:04:22.680
where you end up with different and
coatings and what you can do is use back

00:04:22.680 --> 00:04:22.690
coatings and what you can do is use back
 

00:04:22.690 --> 00:04:25.170
coatings and what you can do is use back
propagation to vary all those parameters

00:04:25.170 --> 00:04:25.180
propagation to vary all those parameters
 

00:04:25.180 --> 00:04:27.810
propagation to vary all those parameters
in order to make sure these conditions

00:04:27.810 --> 00:04:27.820
in order to make sure these conditions
 

00:04:27.820 --> 00:04:30.390
in order to make sure these conditions
are satisfied so you've learned about

00:04:30.390 --> 00:04:30.400
are satisfied so you've learned about
 

00:04:30.400 --> 00:04:33.090
are satisfied so you've learned about
the siamese network architecture and

00:04:33.090 --> 00:04:33.100
the siamese network architecture and
 

00:04:33.100 --> 00:04:35.640
the siamese network architecture and
have a sense of what you want the neural

00:04:35.640 --> 00:04:35.650
have a sense of what you want the neural
 

00:04:35.650 --> 00:04:37.650
have a sense of what you want the neural
network to output for you in terms of

00:04:37.650 --> 00:04:37.660
network to output for you in terms of
 

00:04:37.660 --> 00:04:40.140
network to output for you in terms of
what would make a good encoding but how

00:04:40.140 --> 00:04:40.150
what would make a good encoding but how
 

00:04:40.150 --> 00:04:41.969
what would make a good encoding but how
do you actually define an objective

00:04:41.969 --> 00:04:41.979
do you actually define an objective
 

00:04:41.979 --> 00:04:44.250
do you actually define an objective
function to make your new network learn

00:04:44.250 --> 00:04:44.260
function to make your new network learn
 

00:04:44.260 --> 00:04:46.830
function to make your new network learn
to do what we just discussed here let's

00:04:46.830 --> 00:04:46.840
to do what we just discussed here let's
 

00:04:46.840 --> 00:04:48.510
to do what we just discussed here let's
see how you can do that to the next

00:04:48.510 --> 00:04:48.520
see how you can do that to the next
 

00:04:48.520 --> 00:04:52.979
see how you can do that to the next
video using the triplet loss function

