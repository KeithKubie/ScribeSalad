WEBVTT
Kind: captions
Language: en

00:00:02.850 --> 00:00:05.389
 
hi Yin thanks a lot for joining us today

00:00:05.389 --> 00:00:05.399
hi Yin thanks a lot for joining us today
 

00:00:05.399 --> 00:00:07.280
hi Yin thanks a lot for joining us today
thank you for inviting me I drink I'm

00:00:07.280 --> 00:00:07.290
thank you for inviting me I drink I'm
 

00:00:07.290 --> 00:00:09.680
thank you for inviting me I drink I'm
glad to be here yeah one of the world's

00:00:09.680 --> 00:00:09.690
glad to be here yeah one of the world's
 

00:00:09.690 --> 00:00:11.540
glad to be here yeah one of the world's
most visible deep learning researchers

00:00:11.540 --> 00:00:11.550
most visible deep learning researchers
 

00:00:11.550 --> 00:00:13.940
most visible deep learning researchers
let us share bit about your personal

00:00:13.940 --> 00:00:13.950
let us share bit about your personal
 

00:00:13.950 --> 00:00:15.890
let us share bit about your personal
story so how do you end up doing this

00:00:15.890 --> 00:00:15.900
story so how do you end up doing this
 

00:00:15.900 --> 00:00:18.200
story so how do you end up doing this
work that you now do yeah that sounds

00:00:18.200 --> 00:00:18.210
work that you now do yeah that sounds
 

00:00:18.210 --> 00:00:20.359
work that you now do yeah that sounds
great I guess I first became interested

00:00:20.359 --> 00:00:20.369
great I guess I first became interested
 

00:00:20.369 --> 00:00:22.190
great I guess I first became interested
in machine learning

00:00:22.190 --> 00:00:22.200
in machine learning
 

00:00:22.200 --> 00:00:24.530
in machine learning
right before I met you actually I had

00:00:24.530 --> 00:00:24.540
right before I met you actually I had
 

00:00:24.540 --> 00:00:28.100
right before I met you actually I had
been working on neuroscience and my

00:00:28.100 --> 00:00:28.110
been working on neuroscience and my
 

00:00:28.110 --> 00:00:29.720
been working on neuroscience and my
undergraduate advisor

00:00:29.720 --> 00:00:29.730
undergraduate advisor
 

00:00:29.730 --> 00:00:31.850
undergraduate advisor
Jerry cane at Stanford encouraged me to

00:00:31.850 --> 00:00:31.860
Jerry cane at Stanford encouraged me to
 

00:00:31.860 --> 00:00:34.639
Jerry cane at Stanford encouraged me to
take your intro to AI class well I

00:00:34.639 --> 00:00:34.649
take your intro to AI class well I
 

00:00:34.649 --> 00:00:36.530
take your intro to AI class well I
didn't know that okay so I had always

00:00:36.530 --> 00:00:36.540
didn't know that okay so I had always
 

00:00:36.540 --> 00:00:40.190
didn't know that okay so I had always
thought that AI was a good idea but that

00:00:40.190 --> 00:00:40.200
thought that AI was a good idea but that
 

00:00:40.200 --> 00:00:42.590
thought that AI was a good idea but that
in practice the main thing I knew that

00:00:42.590 --> 00:00:42.600
in practice the main thing I knew that
 

00:00:42.600 --> 00:00:44.870
in practice the main thing I knew that
was happening was like game AI I said

00:00:44.870 --> 00:00:44.880
was happening was like game AI I said
 

00:00:44.880 --> 00:00:46.370
was happening was like game AI I said
where people have a lot of hard-coded

00:00:46.370 --> 00:00:46.380
where people have a lot of hard-coded
 

00:00:46.380 --> 00:00:48.650
where people have a lot of hard-coded
rules for non player characters and

00:00:48.650 --> 00:00:48.660
rules for non player characters and
 

00:00:48.660 --> 00:00:50.720
rules for non player characters and
games to say different scripted lines at

00:00:50.720 --> 00:00:50.730
games to say different scripted lines at
 

00:00:50.730 --> 00:00:52.910
games to say different scripted lines at
different points in time and then when I

00:00:52.910 --> 00:00:52.920
different points in time and then when I
 

00:00:52.920 --> 00:00:55.729
different points in time and then when I
took your intro to a high class and you

00:00:55.729 --> 00:00:55.739
took your intro to a high class and you
 

00:00:55.739 --> 00:00:57.530
took your intro to a high class and you
covered topics like linear regression

00:00:57.530 --> 00:00:57.540
covered topics like linear regression
 

00:00:57.540 --> 00:00:59.720
covered topics like linear regression
and the bias and various variance

00:00:59.720 --> 00:00:59.730
and the bias and various variance
 

00:00:59.730 --> 00:01:02.300
and the bias and various variance
decomposition of the error of linear

00:01:02.300 --> 00:01:02.310
decomposition of the error of linear
 

00:01:02.310 --> 00:01:03.620
decomposition of the error of linear
regression I started to realize that

00:01:03.620 --> 00:01:03.630
regression I started to realize that
 

00:01:03.630 --> 00:01:05.929
regression I started to realize that
this was a real science and I could

00:01:05.929 --> 00:01:05.939
this was a real science and I could
 

00:01:05.939 --> 00:01:07.910
this was a real science and I could
actually have a scientific career in a

00:01:07.910 --> 00:01:07.920
actually have a scientific career in a
 

00:01:07.920 --> 00:01:10.880
actually have a scientific career in a
guy rather than neuroscience see great

00:01:10.880 --> 00:01:10.890
guy rather than neuroscience see great
 

00:01:10.890 --> 00:01:13.940
guy rather than neuroscience see great
and then what happened well I came back

00:01:13.940 --> 00:01:13.950
and then what happened well I came back
 

00:01:13.950 --> 00:01:15.800
and then what happened well I came back
into ITA two-year course not later seen

00:01:15.800 --> 00:01:15.810
into ITA two-year course not later seen
 

00:01:15.810 --> 00:01:20.120
into ITA two-year course not later seen
right so the really big turning point

00:01:20.120 --> 00:01:20.130
right so the really big turning point
 

00:01:20.130 --> 00:01:21.830
right so the really big turning point
for me was while I was teeing that

00:01:21.830 --> 00:01:21.840
for me was while I was teeing that
 

00:01:21.840 --> 00:01:24.080
for me was while I was teeing that
course one of the students my friend

00:01:24.080 --> 00:01:24.090
course one of the students my friend
 

00:01:24.090 --> 00:01:26.539
course one of the students my friend
Ethan Dreyfus got interested in Jeff

00:01:26.539 --> 00:01:26.549
Ethan Dreyfus got interested in Jeff
 

00:01:26.549 --> 00:01:29.300
Ethan Dreyfus got interested in Jeff
Shannon's deep belief that paper and the

00:01:29.300 --> 00:01:29.310
Shannon's deep belief that paper and the
 

00:01:29.310 --> 00:01:32.090
Shannon's deep belief that paper and the
two of us ended up building one of the

00:01:32.090 --> 00:01:32.100
two of us ended up building one of the
 

00:01:32.100 --> 00:01:35.600
two of us ended up building one of the
first GPU CUDA based machines at

00:01:35.600 --> 00:01:35.610
first GPU CUDA based machines at
 

00:01:35.610 --> 00:01:38.149
first GPU CUDA based machines at
Stanford in order to run bolts and

00:01:38.149 --> 00:01:38.159
Stanford in order to run bolts and
 

00:01:38.159 --> 00:01:41.149
Stanford in order to run bolts and
machines in our spare time of her winter

00:01:41.149 --> 00:01:41.159
machines in our spare time of her winter
 

00:01:41.159 --> 00:01:45.469
machines in our spare time of her winter
break and at that point I started to

00:01:45.469 --> 00:01:45.479
break and at that point I started to
 

00:01:45.479 --> 00:01:48.170
break and at that point I started to
have a very strong intuition that deep

00:01:48.170 --> 00:01:48.180
have a very strong intuition that deep
 

00:01:48.180 --> 00:01:50.590
have a very strong intuition that deep
learning was the way to go in the future

00:01:50.590 --> 00:01:50.600
learning was the way to go in the future
 

00:01:50.600 --> 00:01:53.060
learning was the way to go in the future
that a lot of the other girls I was

00:01:53.060 --> 00:01:53.070
that a lot of the other girls I was
 

00:01:53.070 --> 00:01:55.190
that a lot of the other girls I was
working with like support vector

00:01:55.190 --> 00:01:55.200
working with like support vector
 

00:01:55.200 --> 00:01:57.590
working with like support vector
machines didn't seem to have the right

00:01:57.590 --> 00:01:57.600
machines didn't seem to have the right
 

00:01:57.600 --> 00:01:59.840
machines didn't seem to have the right
asymptotics that you add more training

00:01:59.840 --> 00:01:59.850
asymptotics that you add more training
 

00:01:59.850 --> 00:02:02.539
asymptotics that you add more training
data and they get slower or for the same

00:02:02.539 --> 00:02:02.549
data and they get slower or for the same
 

00:02:02.549 --> 00:02:03.950
data and they get slower or for the same
amount of training data it's hard to

00:02:03.950 --> 00:02:03.960
amount of training data it's hard to
 

00:02:03.960 --> 00:02:05.840
amount of training data it's hard to
make them perform a lot better by

00:02:05.840 --> 00:02:05.850
make them perform a lot better by
 

00:02:05.850 --> 00:02:08.960
make them perform a lot better by
changing other settings at that point I

00:02:08.960 --> 00:02:08.970
changing other settings at that point I
 

00:02:08.970 --> 00:02:11.300
changing other settings at that point I
I started to focus on deep learning as

00:02:11.300 --> 00:02:11.310
I started to focus on deep learning as
 

00:02:11.310 --> 00:02:15.140
I started to focus on deep learning as
much as possible in the and

00:02:15.140 --> 00:02:15.150
much as possible in the and
 

00:02:15.150 --> 00:02:18.080
much as possible in the and
remember Magette rayna's very odd GPU

00:02:18.080 --> 00:02:18.090
remember Magette rayna's very odd GPU
 

00:02:18.090 --> 00:02:20.300
remember Magette rayna's very odd GPU
paper right acknowledges you for having

00:02:20.300 --> 00:02:20.310
paper right acknowledges you for having
 

00:02:20.310 --> 00:02:23.330
paper right acknowledges you for having
done laudatory work yeah yeah that was

00:02:23.330 --> 00:02:23.340
done laudatory work yeah yeah that was
 

00:02:23.340 --> 00:02:25.190
done laudatory work yeah yeah that was
written using some of the machines that

00:02:25.190 --> 00:02:25.200
written using some of the machines that
 

00:02:25.200 --> 00:02:28.280
written using some of the machines that
we built the first machine I built was

00:02:28.280 --> 00:02:28.290
we built the first machine I built was
 

00:02:28.290 --> 00:02:29.720
we built the first machine I built was
just something that Ethan and I built

00:02:29.720 --> 00:02:29.730
just something that Ethan and I built
 

00:02:29.730 --> 00:02:34.399
just something that Ethan and I built
that Ethan's mom's house with I see wait

00:02:34.399 --> 00:02:34.409
that Ethan's mom's house with I see wait
 

00:02:34.409 --> 00:02:35.720
that Ethan's mom's house with I see wait
with our own money and then later we

00:02:35.720 --> 00:02:35.730
with our own money and then later we
 

00:02:35.730 --> 00:02:37.940
with our own money and then later we
have money to build the first to agree

00:02:37.940 --> 00:02:37.950
have money to build the first to agree
 

00:02:37.950 --> 00:02:40.550
have money to build the first to agree
for the Stanford lab wow that's great I

00:02:40.550 --> 00:02:40.560
for the Stanford lab wow that's great I
 

00:02:40.560 --> 00:02:42.339
for the Stanford lab wow that's great I
never knew that story that's great yeah

00:02:42.339 --> 00:02:42.349
never knew that story that's great yeah
 

00:02:42.349 --> 00:02:46.550
never knew that story that's great yeah
um and then today one of the you know

00:02:46.550 --> 00:02:46.560
um and then today one of the you know
 

00:02:46.560 --> 00:02:48.500
um and then today one of the you know
things that's really taken the deep

00:02:48.500 --> 00:02:48.510
things that's really taken the deep
 

00:02:48.510 --> 00:02:49.940
things that's really taken the deep
learning world by storm is your

00:02:49.940 --> 00:02:49.950
learning world by storm is your
 

00:02:49.950 --> 00:02:52.849
learning world by storm is your
invention of Gans so how did you come up

00:02:52.849 --> 00:02:52.859
invention of Gans so how did you come up
 

00:02:52.859 --> 00:02:55.640
invention of Gans so how did you come up
with that I'd been studying generative

00:02:55.640 --> 00:02:55.650
with that I'd been studying generative
 

00:02:55.650 --> 00:02:58.009
with that I'd been studying generative
models for a long time so it ganzar a

00:02:58.009 --> 00:02:58.019
models for a long time so it ganzar a
 

00:02:58.019 --> 00:03:00.020
models for a long time so it ganzar a
way of giving generative modeling where

00:03:00.020 --> 00:03:00.030
way of giving generative modeling where
 

00:03:00.030 --> 00:03:01.940
way of giving generative modeling where
you have a lot of training data and

00:03:01.940 --> 00:03:01.950
you have a lot of training data and
 

00:03:01.950 --> 00:03:04.610
you have a lot of training data and
you'd like to learn to produce more

00:03:04.610 --> 00:03:04.620
you'd like to learn to produce more
 

00:03:04.620 --> 00:03:06.440
you'd like to learn to produce more
examples that resemble the training data

00:03:06.440 --> 00:03:06.450
examples that resemble the training data
 

00:03:06.450 --> 00:03:09.679
examples that resemble the training data
but but they're imaginary they've never

00:03:09.679 --> 00:03:09.689
but but they're imaginary they've never
 

00:03:09.689 --> 00:03:12.520
but but they're imaginary they've never
been seen exactly in that form before

00:03:12.520 --> 00:03:12.530
been seen exactly in that form before
 

00:03:12.530 --> 00:03:14.720
been seen exactly in that form before
there were several other ways of doing

00:03:14.720 --> 00:03:14.730
there were several other ways of doing
 

00:03:14.730 --> 00:03:16.640
there were several other ways of doing
generative models that had been popular

00:03:16.640 --> 00:03:16.650
generative models that had been popular
 

00:03:16.650 --> 00:03:18.289
generative models that had been popular
for several years before I had the idea

00:03:18.289 --> 00:03:18.299
for several years before I had the idea
 

00:03:18.299 --> 00:03:22.099
for several years before I had the idea
for against and after I've been working

00:03:22.099 --> 00:03:22.109
for against and after I've been working
 

00:03:22.109 --> 00:03:23.479
for against and after I've been working
on all those other methods throughout

00:03:23.479 --> 00:03:23.489
on all those other methods throughout
 

00:03:23.489 --> 00:03:25.849
on all those other methods throughout
most of my PhD I knew a lot about the

00:03:25.849 --> 00:03:25.859
most of my PhD I knew a lot about the
 

00:03:25.859 --> 00:03:28.069
most of my PhD I knew a lot about the
advantages and disadvantages of all the

00:03:28.069 --> 00:03:28.079
advantages and disadvantages of all the
 

00:03:28.079 --> 00:03:29.780
advantages and disadvantages of all the
other frameworks like bulletin machines

00:03:29.780 --> 00:03:29.790
other frameworks like bulletin machines
 

00:03:29.790 --> 00:03:33.319
other frameworks like bulletin machines
and sparse coding and all the other

00:03:33.319 --> 00:03:33.329
and sparse coding and all the other
 

00:03:33.329 --> 00:03:34.699
and sparse coding and all the other
approaches that had been really popular

00:03:34.699 --> 00:03:34.709
approaches that had been really popular
 

00:03:34.709 --> 00:03:36.860
approaches that had been really popular
for years I was looking for something

00:03:36.860 --> 00:03:36.870
for years I was looking for something
 

00:03:36.870 --> 00:03:38.569
for years I was looking for something
how to avoid all of those disadvantages

00:03:38.569 --> 00:03:38.579
how to avoid all of those disadvantages
 

00:03:38.579 --> 00:03:41.180
how to avoid all of those disadvantages
at the same time and then finally when I

00:03:41.180 --> 00:03:41.190
at the same time and then finally when I
 

00:03:41.190 --> 00:03:43.309
at the same time and then finally when I
was arguing about derided models with my

00:03:43.309 --> 00:03:43.319
was arguing about derided models with my
 

00:03:43.319 --> 00:03:44.930
was arguing about derided models with my
friends in a bar something clicked into

00:03:44.930 --> 00:03:44.940
friends in a bar something clicked into
 

00:03:44.940 --> 00:03:47.149
friends in a bar something clicked into
place and I started telling them you

00:03:47.149 --> 00:03:47.159
place and I started telling them you
 

00:03:47.159 --> 00:03:48.710
place and I started telling them you
need to do this this and this and I

00:03:48.710 --> 00:03:48.720
need to do this this and this and I
 

00:03:48.720 --> 00:03:51.229
need to do this this and this and I
swear it'll work and my my friends

00:03:51.229 --> 00:03:51.239
swear it'll work and my my friends
 

00:03:51.239 --> 00:03:52.670
swear it'll work and my my friends
didn't believe me that it would work I

00:03:52.670 --> 00:03:52.680
didn't believe me that it would work I
 

00:03:52.680 --> 00:03:54.170
didn't believe me that it would work I
was supposed to be writing the deep

00:03:54.170 --> 00:03:54.180
was supposed to be writing the deep
 

00:03:54.180 --> 00:03:55.969
was supposed to be writing the deep
learning textbook at the time but I

00:03:55.969 --> 00:03:55.979
learning textbook at the time but I
 

00:03:55.979 --> 00:03:57.140
learning textbook at the time but I
believed strongly enough that it would

00:03:57.140 --> 00:03:57.150
believed strongly enough that it would
 

00:03:57.150 --> 00:03:58.640
believed strongly enough that it would
work that I went home and coded it up

00:03:58.640 --> 00:03:58.650
work that I went home and coded it up
 

00:03:58.650 --> 00:03:59.990
work that I went home and coded it up
the same night and it worked

00:03:59.990 --> 00:04:00.000
the same night and it worked
 

00:04:00.000 --> 00:04:02.149
the same night and it worked
so thank you one evening to implement

00:04:02.149 --> 00:04:02.159
so thank you one evening to implement
 

00:04:02.159 --> 00:04:04.699
so thank you one evening to implement
the first version as a if I implemented

00:04:04.699 --> 00:04:04.709
the first version as a if I implemented
 

00:04:04.709 --> 00:04:06.920
the first version as a if I implemented
it around midnight after going home from

00:04:06.920 --> 00:04:06.930
it around midnight after going home from
 

00:04:06.930 --> 00:04:08.509
it around midnight after going home from
the bar where my friend had his

00:04:08.509 --> 00:04:08.519
the bar where my friend had his
 

00:04:08.519 --> 00:04:10.759
the bar where my friend had his
going-away party I see and the first

00:04:10.759 --> 00:04:10.769
going-away party I see and the first
 

00:04:10.769 --> 00:04:12.740
going-away party I see and the first
version of it worked which is very very

00:04:12.740 --> 00:04:12.750
version of it worked which is very very
 

00:04:12.750 --> 00:04:14.360
version of it worked which is very very
fortunate I didn't have to search for

00:04:14.360 --> 00:04:14.370
fortunate I didn't have to search for
 

00:04:14.370 --> 00:04:16.039
fortunate I didn't have to search for
hyper parameters meaning there was a

00:04:16.039 --> 00:04:16.049
hyper parameters meaning there was a
 

00:04:16.049 --> 00:04:18.379
hyper parameters meaning there was a
story I read it somewhere where you had

00:04:18.379 --> 00:04:18.389
story I read it somewhere where you had
 

00:04:18.389 --> 00:04:20.659
story I read it somewhere where you had
a near-death experience and that

00:04:20.659 --> 00:04:20.669
a near-death experience and that
 

00:04:20.669 --> 00:04:23.870
a near-death experience and that
reaffirm your commitment to AI and tell

00:04:23.870 --> 00:04:23.880
reaffirm your commitment to AI and tell
 

00:04:23.880 --> 00:04:24.600
reaffirm your commitment to AI and tell
me that so

00:04:24.600 --> 00:04:24.610
me that so
 

00:04:24.610 --> 00:04:28.020
me that so
yeah I wasn't actually near death but I

00:04:28.020 --> 00:04:28.030
yeah I wasn't actually near death but I
 

00:04:28.030 --> 00:04:31.379
yeah I wasn't actually near death but I
briefly thought that I was I had a very

00:04:31.379 --> 00:04:31.389
briefly thought that I was I had a very
 

00:04:31.389 --> 00:04:33.680
briefly thought that I was I had a very
bad headache and some of the doctors

00:04:33.680 --> 00:04:33.690
bad headache and some of the doctors
 

00:04:33.690 --> 00:04:36.300
bad headache and some of the doctors
thought that I might have a burping

00:04:36.300 --> 00:04:36.310
thought that I might have a burping
 

00:04:36.310 --> 00:04:38.790
thought that I might have a burping
hemorrhage and during the time that I

00:04:38.790 --> 00:04:38.800
hemorrhage and during the time that I
 

00:04:38.800 --> 00:04:41.159
hemorrhage and during the time that I
was waiting for my MRI results to find

00:04:41.159 --> 00:04:41.169
was waiting for my MRI results to find
 

00:04:41.169 --> 00:04:42.629
was waiting for my MRI results to find
out whether I had a brain hemorrhage or

00:04:42.629 --> 00:04:42.639
out whether I had a brain hemorrhage or
 

00:04:42.639 --> 00:04:45.719
out whether I had a brain hemorrhage or
not I realized that most of the thoughts

00:04:45.719 --> 00:04:45.729
not I realized that most of the thoughts
 

00:04:45.729 --> 00:04:47.969
not I realized that most of the thoughts
I was having were about making sure that

00:04:47.969 --> 00:04:47.979
I was having were about making sure that
 

00:04:47.979 --> 00:04:50.309
I was having were about making sure that
other people would eventually try out

00:04:50.309 --> 00:04:50.319
other people would eventually try out
 

00:04:50.319 --> 00:04:52.110
other people would eventually try out
the research ideas that I had at the

00:04:52.110 --> 00:04:52.120
the research ideas that I had at the
 

00:04:52.120 --> 00:04:52.649
the research ideas that I had at the
time

00:04:52.649 --> 00:04:52.659
time
 

00:04:52.659 --> 00:04:54.659
time
in retrospect they're all pretty silly

00:04:54.659 --> 00:04:54.669
in retrospect they're all pretty silly
 

00:04:54.669 --> 00:04:58.649
in retrospect they're all pretty silly
research ideas but I at that point I

00:04:58.649 --> 00:04:58.659
research ideas but I at that point I
 

00:04:58.659 --> 00:05:00.959
research ideas but I at that point I
realized that this was actually one of

00:05:00.959 --> 00:05:00.969
realized that this was actually one of
 

00:05:00.969 --> 00:05:03.050
realized that this was actually one of
my highest priorities in life was

00:05:03.050 --> 00:05:03.060
my highest priorities in life was
 

00:05:03.060 --> 00:05:05.070
my highest priorities in life was
carrying out my machine learning

00:05:05.070 --> 00:05:05.080
carrying out my machine learning
 

00:05:05.080 --> 00:05:07.499
carrying out my machine learning
research work I see yeah that's great

00:05:07.499 --> 00:05:07.509
research work I see yeah that's great
 

00:05:07.509 --> 00:05:09.629
research work I see yeah that's great
that when you thought you might be dying

00:05:09.629 --> 00:05:09.639
that when you thought you might be dying
 

00:05:09.639 --> 00:05:11.279
that when you thought you might be dying
soon you're just thinking how do we get

00:05:11.279 --> 00:05:11.289
soon you're just thinking how do we get
 

00:05:11.289 --> 00:05:13.140
soon you're just thinking how do we get
the research done yeah yeah

00:05:13.140 --> 00:05:13.150
the research done yeah yeah
 

00:05:13.150 --> 00:05:18.659
the research done yeah yeah
that that does commitment yeah so today

00:05:18.659 --> 00:05:18.669
that that does commitment yeah so today
 

00:05:18.669 --> 00:05:20.459
that that does commitment yeah so today
you're still at the center of a lot of

00:05:20.459 --> 00:05:20.469
you're still at the center of a lot of
 

00:05:20.469 --> 00:05:22.020
you're still at the center of a lot of
the activities with Gans with

00:05:22.020 --> 00:05:22.030
the activities with Gans with
 

00:05:22.030 --> 00:05:24.719
the activities with Gans with
regenerative adversarial networks so

00:05:24.719 --> 00:05:24.729
regenerative adversarial networks so
 

00:05:24.729 --> 00:05:27.620
regenerative adversarial networks so
tell me how you see the future of guns

00:05:27.620 --> 00:05:27.630
tell me how you see the future of guns
 

00:05:27.630 --> 00:05:29.939
tell me how you see the future of guns
right now guns are used for a lot of

00:05:29.939 --> 00:05:29.949
right now guns are used for a lot of
 

00:05:29.949 --> 00:05:31.980
right now guns are used for a lot of
different things like so my supervised

00:05:31.980 --> 00:05:31.990
different things like so my supervised
 

00:05:31.990 --> 00:05:34.499
different things like so my supervised
learning generating training data for

00:05:34.499 --> 00:05:34.509
learning generating training data for
 

00:05:34.509 --> 00:05:37.260
learning generating training data for
other models and even simulating

00:05:37.260 --> 00:05:37.270
other models and even simulating
 

00:05:37.270 --> 00:05:40.080
other models and even simulating
scientific experiments in principle all

00:05:40.080 --> 00:05:40.090
scientific experiments in principle all
 

00:05:40.090 --> 00:05:41.879
scientific experiments in principle all
of these things could be done by other

00:05:41.879 --> 00:05:41.889
of these things could be done by other
 

00:05:41.889 --> 00:05:44.070
of these things could be done by other
kinds of generative models so I think

00:05:44.070 --> 00:05:44.080
kinds of generative models so I think
 

00:05:44.080 --> 00:05:46.080
kinds of generative models so I think
that games are at an important

00:05:46.080 --> 00:05:46.090
that games are at an important
 

00:05:46.090 --> 00:05:48.809
that games are at an important
crossroads right now right now they work

00:05:48.809 --> 00:05:48.819
crossroads right now right now they work
 

00:05:48.819 --> 00:05:51.059
crossroads right now right now they work
well some of the time but it can be more

00:05:51.059 --> 00:05:51.069
well some of the time but it can be more
 

00:05:51.069 --> 00:05:54.089
well some of the time but it can be more
of an art than a science to really bring

00:05:54.089 --> 00:05:54.099
of an art than a science to really bring
 

00:05:54.099 --> 00:05:56.339
of an art than a science to really bring
that performance out of them that's more

00:05:56.339 --> 00:05:56.349
that performance out of them that's more
 

00:05:56.349 --> 00:05:57.779
that performance out of them that's more
or less how people felt about deep

00:05:57.779 --> 00:05:57.789
or less how people felt about deep
 

00:05:57.789 --> 00:05:59.670
or less how people felt about deep
learning in general ten years ago and

00:05:59.670 --> 00:05:59.680
learning in general ten years ago and
 

00:05:59.680 --> 00:06:01.890
learning in general ten years ago and
back then we were using deep belief

00:06:01.890 --> 00:06:01.900
back then we were using deep belief
 

00:06:01.900 --> 00:06:04.260
back then we were using deep belief
networks with bullets and machines as

00:06:04.260 --> 00:06:04.270
networks with bullets and machines as
 

00:06:04.270 --> 00:06:06.209
networks with bullets and machines as
the building blocks they were very very

00:06:06.209 --> 00:06:06.219
the building blocks they were very very
 

00:06:06.219 --> 00:06:08.610
the building blocks they were very very
finicky over time we switched to things

00:06:08.610 --> 00:06:08.620
finicky over time we switched to things
 

00:06:08.620 --> 00:06:10.769
finicky over time we switched to things
like rectified linear units and batch

00:06:10.769 --> 00:06:10.779
like rectified linear units and batch
 

00:06:10.779 --> 00:06:13.200
like rectified linear units and batch
normalization and deep learning became a

00:06:13.200 --> 00:06:13.210
normalization and deep learning became a
 

00:06:13.210 --> 00:06:15.600
normalization and deep learning became a
lot more reliable if we can make guns

00:06:15.600 --> 00:06:15.610
lot more reliable if we can make guns
 

00:06:15.610 --> 00:06:17.939
lot more reliable if we can make guns
become as reliable as deep learning has

00:06:17.939 --> 00:06:17.949
become as reliable as deep learning has
 

00:06:17.949 --> 00:06:19.980
become as reliable as deep learning has
become but I think we'll keep seeing

00:06:19.980 --> 00:06:19.990
become but I think we'll keep seeing
 

00:06:19.990 --> 00:06:21.719
become but I think we'll keep seeing
guns used in all the places are used

00:06:21.719 --> 00:06:21.729
guns used in all the places are used
 

00:06:21.729 --> 00:06:24.570
guns used in all the places are used
today with much greater success if we

00:06:24.570 --> 00:06:24.580
today with much greater success if we
 

00:06:24.580 --> 00:06:27.570
today with much greater success if we
aren't able to figure out how to

00:06:27.570 --> 00:06:27.580
aren't able to figure out how to
 

00:06:27.580 --> 00:06:29.939
aren't able to figure out how to
stabilize guns that I think their main

00:06:29.939 --> 00:06:29.949
stabilize guns that I think their main
 

00:06:29.949 --> 00:06:32.309
stabilize guns that I think their main
contribution to the history of deep

00:06:32.309 --> 00:06:32.319
contribution to the history of deep
 

00:06:32.319 --> 00:06:34.290
contribution to the history of deep
learning is that they will have shown

00:06:34.290 --> 00:06:34.300
learning is that they will have shown
 

00:06:34.300 --> 00:06:36.149
learning is that they will have shown
people how to do all these tasks that

00:06:36.149 --> 00:06:36.159
people how to do all these tasks that
 

00:06:36.159 --> 00:06:37.250
people how to do all these tasks that
involve generative model

00:06:37.250 --> 00:06:37.260
involve generative model
 

00:06:37.260 --> 00:06:39.440
involve generative model
and eventually we will replace them with

00:06:39.440 --> 00:06:39.450
and eventually we will replace them with
 

00:06:39.450 --> 00:06:41.870
and eventually we will replace them with
other forms of generative models so I

00:06:41.870 --> 00:06:41.880
other forms of generative models so I
 

00:06:41.880 --> 00:06:44.270
other forms of generative models so I
spend maybe about 40% of my time right

00:06:44.270 --> 00:06:44.280
spend maybe about 40% of my time right
 

00:06:44.280 --> 00:06:46.040
spend maybe about 40% of my time right
now working on stabilizing kids

00:06:46.040 --> 00:06:46.050
now working on stabilizing kids
 

00:06:46.050 --> 00:06:50.360
now working on stabilizing kids
I see cool oh and some so just as a lot

00:06:50.360 --> 00:06:50.370
I see cool oh and some so just as a lot
 

00:06:50.370 --> 00:06:51.770
I see cool oh and some so just as a lot
of people they joined deep learning

00:06:51.770 --> 00:06:51.780
of people they joined deep learning
 

00:06:51.780 --> 00:06:53.510
of people they joined deep learning
about 10 years ago such as yourself

00:06:53.510 --> 00:06:53.520
about 10 years ago such as yourself
 

00:06:53.520 --> 00:06:55.850
about 10 years ago such as yourself
ended up being pioneers maybe the people

00:06:55.850 --> 00:06:55.860
ended up being pioneers maybe the people
 

00:06:55.860 --> 00:06:58.100
ended up being pioneers maybe the people
they joined Gans today if it works out

00:06:58.100 --> 00:06:58.110
they joined Gans today if it works out
 

00:06:58.110 --> 00:07:00.650
they joined Gans today if it works out
could end up the early pioneers yeah a

00:07:00.650 --> 00:07:00.660
could end up the early pioneers yeah a
 

00:07:00.660 --> 00:07:03.380
could end up the early pioneers yeah a
lot of people already are early pioneers

00:07:03.380 --> 00:07:03.390
lot of people already are early pioneers
 

00:07:03.390 --> 00:07:04.010
lot of people already are early pioneers
of Gans

00:07:04.010 --> 00:07:04.020
of Gans
 

00:07:04.020 --> 00:07:06.650
of Gans
and I think if you wanted to give any

00:07:06.650 --> 00:07:06.660
and I think if you wanted to give any
 

00:07:06.660 --> 00:07:09.230
and I think if you wanted to give any
kind of history of again so far you'd

00:07:09.230 --> 00:07:09.240
kind of history of again so far you'd
 

00:07:09.240 --> 00:07:11.750
kind of history of again so far you'd
really need to mention other groups like

00:07:11.750 --> 00:07:11.760
really need to mention other groups like
 

00:07:11.760 --> 00:07:15.500
really need to mention other groups like
indigo and Facebook and Berkeley for all

00:07:15.500 --> 00:07:15.510
indigo and Facebook and Berkeley for all
 

00:07:15.510 --> 00:07:16.520
indigo and Facebook and Berkeley for all
the different things that they've done

00:07:16.520 --> 00:07:16.530
the different things that they've done
 

00:07:16.530 --> 00:07:19.910
the different things that they've done
so in addition to all your research you

00:07:19.910 --> 00:07:19.920
so in addition to all your research you
 

00:07:19.920 --> 00:07:23.150
so in addition to all your research you
also co-authored a book on deep learning

00:07:23.150 --> 00:07:23.160
also co-authored a book on deep learning
 

00:07:23.160 --> 00:07:26.030
also co-authored a book on deep learning
oh is that good that's right with Joshua

00:07:26.030 --> 00:07:26.040
oh is that good that's right with Joshua
 

00:07:26.040 --> 00:07:28.060
oh is that good that's right with Joshua
Benji oh and Aaron kohrville who were my

00:07:28.060 --> 00:07:28.070
Benji oh and Aaron kohrville who were my
 

00:07:28.070 --> 00:07:31.490
Benji oh and Aaron kohrville who were my
PhD co advisors we wrote the first

00:07:31.490 --> 00:07:31.500
PhD co advisors we wrote the first
 

00:07:31.500 --> 00:07:34.370
PhD co advisors we wrote the first
textbook on the modern version of deep

00:07:34.370 --> 00:07:34.380
textbook on the modern version of deep
 

00:07:34.380 --> 00:07:37.940
textbook on the modern version of deep
learning and that has been very popular

00:07:37.940 --> 00:07:37.950
learning and that has been very popular
 

00:07:37.950 --> 00:07:40.730
learning and that has been very popular
both in the English edition of the

00:07:40.730 --> 00:07:40.740
both in the English edition of the
 

00:07:40.740 --> 00:07:44.690
both in the English edition of the
Chinese edition we've sold about I think

00:07:44.690 --> 00:07:44.700
Chinese edition we've sold about I think
 

00:07:44.700 --> 00:07:47.360
Chinese edition we've sold about I think
around 70,000 copies total between those

00:07:47.360 --> 00:07:47.370
around 70,000 copies total between those
 

00:07:47.370 --> 00:07:51.140
around 70,000 copies total between those
two languages and I've had a lot of

00:07:51.140 --> 00:07:51.150
two languages and I've had a lot of
 

00:07:51.150 --> 00:07:52.760
two languages and I've had a lot of
feedback from students who say that

00:07:52.760 --> 00:07:52.770
feedback from students who say that
 

00:07:52.770 --> 00:07:55.100
feedback from students who say that
they've learned a lot from it one thing

00:07:55.100 --> 00:07:55.110
they've learned a lot from it one thing
 

00:07:55.110 --> 00:07:56.270
they've learned a lot from it one thing
that we did a little bit differently

00:07:56.270 --> 00:07:56.280
that we did a little bit differently
 

00:07:56.280 --> 00:07:58.940
that we did a little bit differently
than some other books is we start with a

00:07:58.940 --> 00:07:58.950
than some other books is we start with a
 

00:07:58.950 --> 00:08:01.100
than some other books is we start with a
very focused introduction to the kind of

00:08:01.100 --> 00:08:01.110
very focused introduction to the kind of
 

00:08:01.110 --> 00:08:03.500
very focused introduction to the kind of
math that you need to do deep learning I

00:08:03.500 --> 00:08:03.510
math that you need to do deep learning I
 

00:08:03.510 --> 00:08:06.320
math that you need to do deep learning I
think one thing that I got from your

00:08:06.320 --> 00:08:06.330
think one thing that I got from your
 

00:08:06.330 --> 00:08:08.930
think one thing that I got from your
courses at Stanford is the linear

00:08:08.930 --> 00:08:08.940
courses at Stanford is the linear
 

00:08:08.940 --> 00:08:10.670
courses at Stanford is the linear
algebra and probability are very

00:08:10.670 --> 00:08:10.680
algebra and probability are very
 

00:08:10.680 --> 00:08:13.610
algebra and probability are very
important that people get excited about

00:08:13.610 --> 00:08:13.620
important that people get excited about
 

00:08:13.620 --> 00:08:15.770
important that people get excited about
the machine learning algorithms but if

00:08:15.770 --> 00:08:15.780
the machine learning algorithms but if
 

00:08:15.780 --> 00:08:17.690
the machine learning algorithms but if
you want to be a really excellent

00:08:17.690 --> 00:08:17.700
you want to be a really excellent
 

00:08:17.700 --> 00:08:20.330
you want to be a really excellent
practitioner you've got to master the

00:08:20.330 --> 00:08:20.340
practitioner you've got to master the
 

00:08:20.340 --> 00:08:23.080
practitioner you've got to master the
basic math of underlies the whole

00:08:23.080 --> 00:08:23.090
basic math of underlies the whole
 

00:08:23.090 --> 00:08:26.840
basic math of underlies the whole
approach in the first place so we make

00:08:26.840 --> 00:08:26.850
approach in the first place so we make
 

00:08:26.850 --> 00:08:28.730
approach in the first place so we make
sure to give a very focused presentation

00:08:28.730 --> 00:08:28.740
sure to give a very focused presentation
 

00:08:28.740 --> 00:08:30.830
sure to give a very focused presentation
of the math basics at the start of the

00:08:30.830 --> 00:08:30.840
of the math basics at the start of the
 

00:08:30.840 --> 00:08:32.690
of the math basics at the start of the
book that way you don't need to go ahead

00:08:32.690 --> 00:08:32.700
book that way you don't need to go ahead
 

00:08:32.700 --> 00:08:34.820
book that way you don't need to go ahead
and learn all of linear algebra but you

00:08:34.820 --> 00:08:34.830
and learn all of linear algebra but you
 

00:08:34.830 --> 00:08:37.339
and learn all of linear algebra but you
can get a very quick crash course in the

00:08:37.339 --> 00:08:37.349
can get a very quick crash course in the
 

00:08:37.349 --> 00:08:38.750
can get a very quick crash course in the
pieces of linear algebra that are the

00:08:38.750 --> 00:08:38.760
pieces of linear algebra that are the
 

00:08:38.760 --> 00:08:40.940
pieces of linear algebra that are the
most useful for deep learning so you

00:08:40.940 --> 00:08:40.950
most useful for deep learning so you
 

00:08:40.950 --> 00:08:42.740
most useful for deep learning so you
even someone who's math you know is a

00:08:42.740 --> 00:08:42.750
even someone who's math you know is a
 

00:08:42.750 --> 00:08:44.850
even someone who's math you know is a
little shaky you haven't seen an app for

00:08:44.850 --> 00:08:44.860
little shaky you haven't seen an app for
 

00:08:44.860 --> 00:08:46.769
little shaky you haven't seen an app for
yes we're gonna start from the beginning

00:08:46.769 --> 00:08:46.779
yes we're gonna start from the beginning
 

00:08:46.779 --> 00:08:48.420
yes we're gonna start from the beginning
of your book and get that background and

00:08:48.420 --> 00:08:48.430
of your book and get that background and
 

00:08:48.430 --> 00:08:50.759
of your book and get that background and
get into designing all of the facts that

00:08:50.759 --> 00:08:50.769
get into designing all of the facts that
 

00:08:50.769 --> 00:08:52.230
get into designing all of the facts that
you would need to know are there it

00:08:52.230 --> 00:08:52.240
you would need to know are there it
 

00:08:52.240 --> 00:08:54.720
you would need to know are there it
would definitely take some focused

00:08:54.720 --> 00:08:54.730
would definitely take some focused
 

00:08:54.730 --> 00:08:57.030
would definitely take some focused
effort and practice at making use of

00:08:57.030 --> 00:08:57.040
effort and practice at making use of
 

00:08:57.040 --> 00:09:00.780
effort and practice at making use of
them if someone's really afraid of

00:09:00.780 --> 00:09:00.790
them if someone's really afraid of
 

00:09:00.790 --> 00:09:02.850
them if someone's really afraid of
method it might be a bit of a painful

00:09:02.850 --> 00:09:02.860
method it might be a bit of a painful
 

00:09:02.860 --> 00:09:05.280
method it might be a bit of a painful
experience but but if you're ready for

00:09:05.280 --> 00:09:05.290
experience but but if you're ready for
 

00:09:05.290 --> 00:09:07.530
experience but but if you're ready for
the learning experience and you believe

00:09:07.530 --> 00:09:07.540
the learning experience and you believe
 

00:09:07.540 --> 00:09:10.079
the learning experience and you believe
you can master it I think all the all

00:09:10.079 --> 00:09:10.089
you can master it I think all the all
 

00:09:10.089 --> 00:09:12.480
you can master it I think all the all
the tools that you need are there as

00:09:12.480 --> 00:09:12.490
the tools that you need are there as
 

00:09:12.490 --> 00:09:14.639
the tools that you need are there as
someone this worked in deep learning for

00:09:14.639 --> 00:09:14.649
someone this worked in deep learning for
 

00:09:14.649 --> 00:09:17.550
someone this worked in deep learning for
a long time I'd be curious if you look

00:09:17.550 --> 00:09:17.560
a long time I'd be curious if you look
 

00:09:17.560 --> 00:09:19.440
a long time I'd be curious if you look
back over the years tell me about how

00:09:19.440 --> 00:09:19.450
back over the years tell me about how
 

00:09:19.450 --> 00:09:21.900
back over the years tell me about how
about how you're thinking of AI and of

00:09:21.900 --> 00:09:21.910
about how you're thinking of AI and of
 

00:09:21.910 --> 00:09:23.870
about how you're thinking of AI and of
deep learning has evolved over the years

00:09:23.870 --> 00:09:23.880
deep learning has evolved over the years
 

00:09:23.880 --> 00:09:28.050
deep learning has evolved over the years
ten years ago I felt like as a community

00:09:28.050 --> 00:09:28.060
ten years ago I felt like as a community
 

00:09:28.060 --> 00:09:30.060
ten years ago I felt like as a community
the biggest challenge in machine

00:09:30.060 --> 00:09:30.070
the biggest challenge in machine
 

00:09:30.070 --> 00:09:32.190
the biggest challenge in machine
learning was just how to get it working

00:09:32.190 --> 00:09:32.200
learning was just how to get it working
 

00:09:32.200 --> 00:09:35.370
learning was just how to get it working
for AI related tasks at all we had

00:09:35.370 --> 00:09:35.380
for AI related tasks at all we had
 

00:09:35.380 --> 00:09:37.949
for AI related tasks at all we had
really good tools that we can use for

00:09:37.949 --> 00:09:37.959
really good tools that we can use for
 

00:09:37.959 --> 00:09:39.990
really good tools that we can use for
simpler tasks where we wanted to

00:09:39.990 --> 00:09:40.000
simpler tasks where we wanted to
 

00:09:40.000 --> 00:09:43.500
simpler tasks where we wanted to
recognize patterns in hand extracted

00:09:43.500 --> 00:09:43.510
recognize patterns in hand extracted
 

00:09:43.510 --> 00:09:46.620
recognize patterns in hand extracted
features where a human designer could do

00:09:46.620 --> 00:09:46.630
features where a human designer could do
 

00:09:46.630 --> 00:09:49.050
features where a human designer could do
a lot of the work by creating those

00:09:49.050 --> 00:09:49.060
a lot of the work by creating those
 

00:09:49.060 --> 00:09:50.759
a lot of the work by creating those
features and then hand it off to the

00:09:50.759 --> 00:09:50.769
features and then hand it off to the
 

00:09:50.769 --> 00:09:53.340
features and then hand it off to the
computer and that was really good for

00:09:53.340 --> 00:09:53.350
computer and that was really good for
 

00:09:53.350 --> 00:09:55.439
computer and that was really good for
different things like predicting which

00:09:55.439 --> 00:09:55.449
different things like predicting which
 

00:09:55.449 --> 00:09:59.189
different things like predicting which
adds a user would click on or different

00:09:59.189 --> 00:09:59.199
adds a user would click on or different
 

00:09:59.199 --> 00:10:02.040
adds a user would click on or different
kinds of basic scientific analysis but

00:10:02.040 --> 00:10:02.050
kinds of basic scientific analysis but
 

00:10:02.050 --> 00:10:03.480
kinds of basic scientific analysis but
we really struggled to do anything

00:10:03.480 --> 00:10:03.490
we really struggled to do anything
 

00:10:03.490 --> 00:10:05.970
we really struggled to do anything
involving millions of pixels in an image

00:10:05.970 --> 00:10:05.980
involving millions of pixels in an image
 

00:10:05.980 --> 00:10:10.800
involving millions of pixels in an image
or a raw audio waveform where the system

00:10:10.800 --> 00:10:10.810
or a raw audio waveform where the system
 

00:10:10.810 --> 00:10:12.660
or a raw audio waveform where the system
had to build all of its understanding

00:10:12.660 --> 00:10:12.670
had to build all of its understanding
 

00:10:12.670 --> 00:10:15.540
had to build all of its understanding
from scratch we finally got over the

00:10:15.540 --> 00:10:15.550
from scratch we finally got over the
 

00:10:15.550 --> 00:10:17.850
from scratch we finally got over the
hurdle really thoroughly maybe five

00:10:17.850 --> 00:10:17.860
hurdle really thoroughly maybe five
 

00:10:17.860 --> 00:10:21.720
hurdle really thoroughly maybe five
years ago and now we're at a point where

00:10:21.720 --> 00:10:21.730
years ago and now we're at a point where
 

00:10:21.730 --> 00:10:23.519
years ago and now we're at a point where
there are so many different paths open

00:10:23.519 --> 00:10:23.529
there are so many different paths open
 

00:10:23.529 --> 00:10:25.500
there are so many different paths open
that someone who wants to get involved

00:10:25.500 --> 00:10:25.510
that someone who wants to get involved
 

00:10:25.510 --> 00:10:28.170
that someone who wants to get involved
in AI maybe the hardest problem they

00:10:28.170 --> 00:10:28.180
in AI maybe the hardest problem they
 

00:10:28.180 --> 00:10:30.060
in AI maybe the hardest problem they
faced is choosing which path they want

00:10:30.060 --> 00:10:30.070
faced is choosing which path they want
 

00:10:30.070 --> 00:10:31.829
faced is choosing which path they want
to go down do you want to make

00:10:31.829 --> 00:10:31.839
to go down do you want to make
 

00:10:31.839 --> 00:10:33.800
to go down do you want to make
reinforcement learning work as well as

00:10:33.800 --> 00:10:33.810
reinforcement learning work as well as
 

00:10:33.810 --> 00:10:36.000
reinforcement learning work as well as
supervised learning works do you want to

00:10:36.000 --> 00:10:36.010
supervised learning works do you want to
 

00:10:36.010 --> 00:10:38.340
supervised learning works do you want to
make unsupervised learning work as well

00:10:38.340 --> 00:10:38.350
make unsupervised learning work as well
 

00:10:38.350 --> 00:10:40.889
make unsupervised learning work as well
as supervised learning works do you want

00:10:40.889 --> 00:10:40.899
as supervised learning works do you want
 

00:10:40.899 --> 00:10:43.110
as supervised learning works do you want
to make sure that machine learning

00:10:43.110 --> 00:10:43.120
to make sure that machine learning
 

00:10:43.120 --> 00:10:46.319
to make sure that machine learning
algorithms are fair and reflect biases

00:10:46.319 --> 00:10:46.329
algorithms are fair and reflect biases
 

00:10:46.329 --> 00:10:46.900
algorithms are fair and reflect biases
that we

00:10:46.900 --> 00:10:46.910
that we
 

00:10:46.910 --> 00:10:49.390
that we
fer to avoid do you want to make sure

00:10:49.390 --> 00:10:49.400
fer to avoid do you want to make sure
 

00:10:49.400 --> 00:10:53.560
fer to avoid do you want to make sure
that the societal issues surrounding AI

00:10:53.560 --> 00:10:53.570
that the societal issues surrounding AI
 

00:10:53.570 --> 00:10:56.530
that the societal issues surrounding AI
work out well that we are able to make

00:10:56.530 --> 00:10:56.540
work out well that we are able to make
 

00:10:56.540 --> 00:10:58.930
work out well that we are able to make
sure that nei benefits everyone rather

00:10:58.930 --> 00:10:58.940
sure that nei benefits everyone rather
 

00:10:58.940 --> 00:11:01.660
sure that nei benefits everyone rather
than causing social upheaval and and

00:11:01.660 --> 00:11:01.670
than causing social upheaval and and
 

00:11:01.670 --> 00:11:04.450
than causing social upheaval and and
trouble with loss of jobs I think right

00:11:04.450 --> 00:11:04.460
trouble with loss of jobs I think right
 

00:11:04.460 --> 00:11:05.380
trouble with loss of jobs I think right
now there's just really an amazing

00:11:05.380 --> 00:11:05.390
now there's just really an amazing
 

00:11:05.390 --> 00:11:07.180
now there's just really an amazing
amount of different things that can be

00:11:07.180 --> 00:11:07.190
amount of different things that can be
 

00:11:07.190 --> 00:11:10.150
amount of different things that can be
done both to prevent downsides from AI

00:11:10.150 --> 00:11:10.160
done both to prevent downsides from AI
 

00:11:10.160 --> 00:11:12.610
done both to prevent downsides from AI
but also to make sure that we leverage

00:11:12.610 --> 00:11:12.620
but also to make sure that we leverage
 

00:11:12.620 --> 00:11:14.920
but also to make sure that we leverage
all of the upsides that it offers us and

00:11:14.920 --> 00:11:14.930
all of the upsides that it offers us and
 

00:11:14.930 --> 00:11:17.290
all of the upsides that it offers us and
so today there are a lot of people

00:11:17.290 --> 00:11:17.300
so today there are a lot of people
 

00:11:17.300 --> 00:11:21.070
so today there are a lot of people
wanting to get into AI so what advice

00:11:21.070 --> 00:11:21.080
wanting to get into AI so what advice
 

00:11:21.080 --> 00:11:23.140
wanting to get into AI so what advice
would you have for someone like that I

00:11:23.140 --> 00:11:23.150
would you have for someone like that I
 

00:11:23.150 --> 00:11:25.060
would you have for someone like that I
think a lot of people that want to get

00:11:25.060 --> 00:11:25.070
think a lot of people that want to get
 

00:11:25.070 --> 00:11:27.100
think a lot of people that want to get
into AI start thinking that they

00:11:27.100 --> 00:11:27.110
into AI start thinking that they
 

00:11:27.110 --> 00:11:29.980
into AI start thinking that they
absolutely need to get a PhD or some

00:11:29.980 --> 00:11:29.990
absolutely need to get a PhD or some
 

00:11:29.990 --> 00:11:31.630
absolutely need to get a PhD or some
other kind of credential like that I

00:11:31.630 --> 00:11:31.640
other kind of credential like that I
 

00:11:31.640 --> 00:11:33.460
other kind of credential like that I
don't think that's actually a

00:11:33.460 --> 00:11:33.470
don't think that's actually a
 

00:11:33.470 --> 00:11:36.370
don't think that's actually a
requirement anymore one way that you

00:11:36.370 --> 00:11:36.380
requirement anymore one way that you
 

00:11:36.380 --> 00:11:38.260
requirement anymore one way that you
could get a lot of attention is to write

00:11:38.260 --> 00:11:38.270
could get a lot of attention is to write
 

00:11:38.270 --> 00:11:40.720
could get a lot of attention is to write
good code and put it on github if you

00:11:40.720 --> 00:11:40.730
good code and put it on github if you
 

00:11:40.730 --> 00:11:43.330
good code and put it on github if you
have an interesting project that solves

00:11:43.330 --> 00:11:43.340
have an interesting project that solves
 

00:11:43.340 --> 00:11:45.820
have an interesting project that solves
a problem that someone working at a top

00:11:45.820 --> 00:11:45.830
a problem that someone working at a top
 

00:11:45.830 --> 00:11:48.700
a problem that someone working at a top
lab wanted to solve once they find your

00:11:48.700 --> 00:11:48.710
lab wanted to solve once they find your
 

00:11:48.710 --> 00:11:50.710
lab wanted to solve once they find your
github repository they'll come find you

00:11:50.710 --> 00:11:50.720
github repository they'll come find you
 

00:11:50.720 --> 00:11:54.610
github repository they'll come find you
and ask you to come work there a lot of

00:11:54.610 --> 00:11:54.620
and ask you to come work there a lot of
 

00:11:54.620 --> 00:11:56.200
and ask you to come work there a lot of
the people that I've I've hired or

00:11:56.200 --> 00:11:56.210
the people that I've I've hired or
 

00:11:56.210 --> 00:11:58.570
the people that I've I've hired or
recruited at opening I last year or at

00:11:58.570 --> 00:11:58.580
recruited at opening I last year or at
 

00:11:58.580 --> 00:12:00.640
recruited at opening I last year or at
Google this year I first became

00:12:00.640 --> 00:12:00.650
Google this year I first became
 

00:12:00.650 --> 00:12:02.290
Google this year I first became
interested in working with them because

00:12:02.290 --> 00:12:02.300
interested in working with them because
 

00:12:02.300 --> 00:12:03.970
interested in working with them because
of something that I saw that they

00:12:03.970 --> 00:12:03.980
of something that I saw that they
 

00:12:03.980 --> 00:12:05.830
of something that I saw that they
released in open-source form on the

00:12:05.830 --> 00:12:05.840
released in open-source form on the
 

00:12:05.840 --> 00:12:08.800
released in open-source form on the
internet writing papers and putting them

00:12:08.800 --> 00:12:08.810
internet writing papers and putting them
 

00:12:08.810 --> 00:12:11.740
internet writing papers and putting them
on archive can also be good a lot of the

00:12:11.740 --> 00:12:11.750
on archive can also be good a lot of the
 

00:12:11.750 --> 00:12:14.260
on archive can also be good a lot of the
time it's harder to reach the point

00:12:14.260 --> 00:12:14.270
time it's harder to reach the point
 

00:12:14.270 --> 00:12:16.000
time it's harder to reach the point
where you have something polished enough

00:12:16.000 --> 00:12:16.010
where you have something polished enough
 

00:12:16.010 --> 00:12:19.180
where you have something polished enough
to really be a new academic contribution

00:12:19.180 --> 00:12:19.190
to really be a new academic contribution
 

00:12:19.190 --> 00:12:22.930
to really be a new academic contribution
to the scientific literature but you can

00:12:22.930 --> 00:12:22.940
to the scientific literature but you can
 

00:12:22.940 --> 00:12:24.700
to the scientific literature but you can
often get to the point of having a

00:12:24.700 --> 00:12:24.710
often get to the point of having a
 

00:12:24.710 --> 00:12:28.120
often get to the point of having a
useful software product much earlier so

00:12:28.120 --> 00:12:28.130
useful software product much earlier so
 

00:12:28.130 --> 00:12:30.520
useful software product much earlier so
sort of you know meet your book practice

00:12:30.520 --> 00:12:30.530
sort of you know meet your book practice
 

00:12:30.530 --> 00:12:32.470
sort of you know meet your book practice
and materials and pulls on github and

00:12:32.470 --> 00:12:32.480
and materials and pulls on github and
 

00:12:32.480 --> 00:12:35.140
and materials and pulls on github and
maybe on archive I think if you if you

00:12:35.140 --> 00:12:35.150
maybe on archive I think if you if you
 

00:12:35.150 --> 00:12:36.430
maybe on archive I think if you if you
learn by reading the book it's really

00:12:36.430 --> 00:12:36.440
learn by reading the book it's really
 

00:12:36.440 --> 00:12:38.680
learn by reading the book it's really
important to also work on a project at

00:12:38.680 --> 00:12:38.690
important to also work on a project at
 

00:12:38.690 --> 00:12:42.610
important to also work on a project at
the same time to either choose some way

00:12:42.610 --> 00:12:42.620
the same time to either choose some way
 

00:12:42.620 --> 00:12:44.470
the same time to either choose some way
of applying machine learning to an area

00:12:44.470 --> 00:12:44.480
of applying machine learning to an area
 

00:12:44.480 --> 00:12:46.930
of applying machine learning to an area
that you're already interested in like

00:12:46.930 --> 00:12:46.940
that you're already interested in like
 

00:12:46.940 --> 00:12:49.570
that you're already interested in like
if you're a field biologist and you want

00:12:49.570 --> 00:12:49.580
if you're a field biologist and you want
 

00:12:49.580 --> 00:12:50.950
if you're a field biologist and you want
to get into deep learning maybe you

00:12:50.950 --> 00:12:50.960
to get into deep learning maybe you
 

00:12:50.960 --> 00:12:54.250
to get into deep learning maybe you
use it to identify birds or if you don't

00:12:54.250 --> 00:12:54.260
use it to identify birds or if you don't
 

00:12:54.260 --> 00:12:55.660
use it to identify birds or if you don't
have an idea for how you'd like to use

00:12:55.660 --> 00:12:55.670
have an idea for how you'd like to use
 

00:12:55.670 --> 00:12:56.980
have an idea for how you'd like to use
machine learning in your own life you

00:12:56.980 --> 00:12:56.990
machine learning in your own life you
 

00:12:56.990 --> 00:12:59.170
machine learning in your own life you
could pick something like making a

00:12:59.170 --> 00:12:59.180
could pick something like making a
 

00:12:59.180 --> 00:13:01.060
could pick something like making a
Street View house numbers classifier

00:13:01.060 --> 00:13:01.070
Street View house numbers classifier
 

00:13:01.070 --> 00:13:03.670
Street View house numbers classifier
where all the data sets are set up to

00:13:03.670 --> 00:13:03.680
where all the data sets are set up to
 

00:13:03.680 --> 00:13:04.990
where all the data sets are set up to
make it very straightforward for you

00:13:04.990 --> 00:13:05.000
make it very straightforward for you
 

00:13:05.000 --> 00:13:07.420
make it very straightforward for you
that way you get to exercise all of the

00:13:07.420 --> 00:13:07.430
that way you get to exercise all of the
 

00:13:07.430 --> 00:13:09.370
that way you get to exercise all of the
basic skills while you read the book or

00:13:09.370 --> 00:13:09.380
basic skills while you read the book or
 

00:13:09.380 --> 00:13:11.920
basic skills while you read the book or
while you watch Coursera videos that

00:13:11.920 --> 00:13:11.930
while you watch Coursera videos that
 

00:13:11.930 --> 00:13:14.860
while you watch Coursera videos that
explain the concepts to you so over the

00:13:14.860 --> 00:13:14.870
explain the concepts to you so over the
 

00:13:14.870 --> 00:13:16.690
explain the concepts to you so over the
last couple years have also seen you do

00:13:16.690 --> 00:13:16.700
last couple years have also seen you do
 

00:13:16.700 --> 00:13:19.260
last couple years have also seen you do
one more work on abbis arrow examples

00:13:19.260 --> 00:13:19.270
one more work on abbis arrow examples
 

00:13:19.270 --> 00:13:22.120
one more work on abbis arrow examples
tell us a bit about that yeah I think

00:13:22.120 --> 00:13:22.130
tell us a bit about that yeah I think
 

00:13:22.130 --> 00:13:25.120
tell us a bit about that yeah I think
adversarial examples are the beginning

00:13:25.120 --> 00:13:25.130
adversarial examples are the beginning
 

00:13:25.130 --> 00:13:28.240
adversarial examples are the beginning
of a new field that I called machine

00:13:28.240 --> 00:13:28.250
of a new field that I called machine
 

00:13:28.250 --> 00:13:31.020
of a new field that I called machine
learning security in the past we've seen

00:13:31.020 --> 00:13:31.030
learning security in the past we've seen
 

00:13:31.030 --> 00:13:35.260
learning security in the past we've seen
computer security issues where attackers

00:13:35.260 --> 00:13:35.270
computer security issues where attackers
 

00:13:35.270 --> 00:13:37.090
computer security issues where attackers
could fool a computer into running the

00:13:37.090 --> 00:13:37.100
could fool a computer into running the
 

00:13:37.100 --> 00:13:38.950
could fool a computer into running the
wrong code that's called application

00:13:38.950 --> 00:13:38.960
wrong code that's called application
 

00:13:38.960 --> 00:13:41.800
wrong code that's called application
level security and there's been attacks

00:13:41.800 --> 00:13:41.810
level security and there's been attacks
 

00:13:41.810 --> 00:13:45.160
level security and there's been attacks
where people can fool a computer into

00:13:45.160 --> 00:13:45.170
where people can fool a computer into
 

00:13:45.170 --> 00:13:47.380
where people can fool a computer into
believing that messages on a network

00:13:47.380 --> 00:13:47.390
believing that messages on a network
 

00:13:47.390 --> 00:13:50.470
believing that messages on a network
come from somebody that is not actually

00:13:50.470 --> 00:13:50.480
come from somebody that is not actually
 

00:13:50.480 --> 00:13:52.630
come from somebody that is not actually
who they says they say they are and

00:13:52.630 --> 00:13:52.640
who they says they say they are and
 

00:13:52.640 --> 00:13:55.180
who they says they say they are and
that's called Network level security now

00:13:55.180 --> 00:13:55.190
that's called Network level security now
 

00:13:55.190 --> 00:13:56.650
that's called Network level security now
we're starting to see that you can also

00:13:56.650 --> 00:13:56.660
we're starting to see that you can also
 

00:13:56.660 --> 00:13:58.630
we're starting to see that you can also
fool machine learning algorithms into

00:13:58.630 --> 00:13:58.640
fool machine learning algorithms into
 

00:13:58.640 --> 00:14:01.570
fool machine learning algorithms into
doing things they shouldn't even if the

00:14:01.570 --> 00:14:01.580
doing things they shouldn't even if the
 

00:14:01.580 --> 00:14:03.160
doing things they shouldn't even if the
program running the machine learning

00:14:03.160 --> 00:14:03.170
program running the machine learning
 

00:14:03.170 --> 00:14:05.490
program running the machine learning
algorithm is running the correct code

00:14:05.490 --> 00:14:05.500
algorithm is running the correct code
 

00:14:05.500 --> 00:14:08.260
algorithm is running the correct code
even if the program running the machine

00:14:08.260 --> 00:14:08.270
even if the program running the machine
 

00:14:08.270 --> 00:14:10.450
even if the program running the machine
learning algorithm and those who all the

00:14:10.450 --> 00:14:10.460
learning algorithm and those who all the
 

00:14:10.460 --> 00:14:12.750
learning algorithm and those who all the
messages on the network really came from

00:14:12.750 --> 00:14:12.760
messages on the network really came from
 

00:14:12.760 --> 00:14:16.300
messages on the network really came from
and I think it's important to build

00:14:16.300 --> 00:14:16.310
and I think it's important to build
 

00:14:16.310 --> 00:14:19.450
and I think it's important to build
security into any new technology near

00:14:19.450 --> 00:14:19.460
security into any new technology near
 

00:14:19.460 --> 00:14:21.220
security into any new technology near
the start of its development we've found

00:14:21.220 --> 00:14:21.230
the start of its development we've found
 

00:14:21.230 --> 00:14:23.320
the start of its development we've found
that it's very hard to build a working

00:14:23.320 --> 00:14:23.330
that it's very hard to build a working
 

00:14:23.330 --> 00:14:26.230
that it's very hard to build a working
system first and then add security later

00:14:26.230 --> 00:14:26.240
system first and then add security later
 

00:14:26.240 --> 00:14:29.380
system first and then add security later
so I am really excited about the idea

00:14:29.380 --> 00:14:29.390
so I am really excited about the idea
 

00:14:29.390 --> 00:14:31.680
so I am really excited about the idea
that if we dive in and start

00:14:31.680 --> 00:14:31.690
that if we dive in and start
 

00:14:31.690 --> 00:14:33.520
that if we dive in and start
anticipating security problems with

00:14:33.520 --> 00:14:33.530
anticipating security problems with
 

00:14:33.530 --> 00:14:35.590
anticipating security problems with
machine learning now we can make sure

00:14:35.590 --> 00:14:35.600
machine learning now we can make sure
 

00:14:35.600 --> 00:14:37.540
machine learning now we can make sure
that these algorithms are secure from

00:14:37.540 --> 00:14:37.550
that these algorithms are secure from
 

00:14:37.550 --> 00:14:39.970
that these algorithms are secure from
the start instead of trying to patch it

00:14:39.970 --> 00:14:39.980
the start instead of trying to patch it
 

00:14:39.980 --> 00:14:42.460
the start instead of trying to patch it
and richer actively years later thank

00:14:42.460 --> 00:14:42.470
and richer actively years later thank
 

00:14:42.470 --> 00:14:43.780
and richer actively years later thank
you that was great there's a lot about

00:14:43.780 --> 00:14:43.790
you that was great there's a lot about
 

00:14:43.790 --> 00:14:45.160
you that was great there's a lot about
your story that I thought was

00:14:45.160 --> 00:14:45.170
your story that I thought was
 

00:14:45.170 --> 00:14:46.870
your story that I thought was
fascinating in that despite having known

00:14:46.870 --> 00:14:46.880
fascinating in that despite having known
 

00:14:46.880 --> 00:14:48.520
fascinating in that despite having known
you for years I didn't actually know so

00:14:48.520 --> 00:14:48.530
you for years I didn't actually know so
 

00:14:48.530 --> 00:14:50.320
you for years I didn't actually know so
thank you for sharing all that oh very

00:14:50.320 --> 00:14:50.330
thank you for sharing all that oh very
 

00:14:50.330 --> 00:14:51.760
thank you for sharing all that oh very
welcome thank you for inviting me

00:14:51.760 --> 00:14:51.770
welcome thank you for inviting me
 

00:14:51.770 --> 00:14:55.510
welcome thank you for inviting me
there was a great chat Thanks

