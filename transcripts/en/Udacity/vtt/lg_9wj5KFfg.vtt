WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:01.833
All right.
&gt;&gt; Okay, so here's the idea.

00:00:01.833 --> 00:00:03.328
So just close your eyes in a minute,
well don't close your eyes,

00:00:03.328 --> 00:00:04.400
because I'm going to show you this but
imagine,

00:00:04.400 --> 00:00:05.062
&gt;&gt; [LAUGH]

00:00:05.062 --> 00:00:06.002
&gt;&gt; Imagine you have cloud of data.

00:00:06.002 --> 00:00:06.763
&gt;&gt; All right.

00:00:06.763 --> 00:00:07.599
&gt;&gt; Got it?

00:00:07.599 --> 00:00:08.217
&gt;&gt; I do.
&gt;&gt; And

00:00:08.217 --> 00:00:09.903
let's say some of it's labeled minus.

00:00:09.903 --> 00:00:10.420
&gt;&gt; Mm-hm.

00:00:10.420 --> 00:00:14.310
&gt;&gt; In fact the vast majority is labeled
minus, and just a few are labeled plus.

00:00:14.310 --> 00:00:16.640
Well if we do it as we've done before
as requiring learning algorithms do,

00:00:16.640 --> 00:00:18.750
we were basically going to say all of

00:00:18.750 --> 00:00:20.250
them were negative
&gt;&gt; Okay, as you've said.

00:00:20.250 --> 00:00:21.742
&gt;&gt; So,
here's what were going to do instead.

00:00:21.742 --> 00:00:23.430
We're going to build a learner,

00:00:23.430 --> 00:00:27.250
that's going to label about half of
them negative and half of them positive.

00:00:27.250 --> 00:00:28.070
&gt;&gt; I can make one of those.

00:00:28.070 --> 00:00:30.190
&gt;&gt; But,
it's going to have another property.

00:00:30.190 --> 00:00:31.960
&gt;&gt; Doh!
&gt;&gt; So you take that cloud that I had.

00:00:31.960 --> 00:00:33.090
&gt;&gt; Okay.
&gt;&gt; And half of them are negative,

00:00:33.090 --> 00:00:36.630
let's say the negative ones come down
here, and the positive ones go this way.

00:00:36.630 --> 00:00:37.880
Now, here's the thing.

00:00:37.880 --> 00:00:41.350
All the negative ones are actually
true negatives, okay?

00:00:42.710 --> 00:00:43.820
&gt;&gt; I see.

00:00:43.820 --> 00:00:45.990
&gt;&gt; The problem was we'll
include all the positives, but

00:00:45.990 --> 00:00:47.390
also some of the negatives.

00:00:47.390 --> 00:00:49.657
So I'll have no false negatives,
and I'll have many false positives.

00:00:49.657 --> 00:00:52.983
&gt;&gt; So in the causing trouble in
the airport example, you would.

00:00:52.983 --> 00:00:56.028
Like half the people you would say
these people are not a threat, and

00:00:56.028 --> 00:00:57.425
you'd just be right on those.

00:00:57.425 --> 00:00:59.095
&gt;&gt; Yes.
&gt;&gt; But the other half you might say

00:00:59.095 --> 00:01:00.328
these could be a threat-
&gt;&gt; Or

00:01:00.328 --> 00:01:03.655
even say that they are a threat and
you'll be wrong for most of them, but

00:01:03.655 --> 00:01:06.280
all the ones who are threats
will survive that filter.

00:01:06.280 --> 00:01:07.200
&gt;&gt; I see.

00:01:07.200 --> 00:01:09.370
&gt;&gt; So now, that I've got the cloud,
and it's over here, and

00:01:09.370 --> 00:01:11.240
I've got mostly negatives,
and a few positives.

00:01:11.240 --> 00:01:12.315
I keep doing the same thing.

00:01:12.315 --> 00:01:13.750
&gt;&gt; Mm-hm.
&gt;&gt; So I shove the negatives off, and

00:01:13.750 --> 00:01:16.650
I'm never wrong, and shove the
positives, and it goes on and on and on.

00:01:16.650 --> 00:01:18.770
&gt;&gt; It sort of vaguely
reminds me of boosting.

00:01:18.770 --> 00:01:21.790
&gt;&gt; It does, and in fact, the way that
they did this in the original paper is

00:01:22.980 --> 00:01:25.520
they did boosting over
very simple learners.

00:01:27.710 --> 00:01:29.890
But what's interesting here,
there's a couple of points.

00:01:29.890 --> 00:01:32.440
One is, I started out with this
big cloud, mostly negatives and

00:01:32.440 --> 00:01:33.390
a few positives.

00:01:33.390 --> 00:01:34.770
I kept cutting in half, and

00:01:34.770 --> 00:01:38.429
by the time I got over here, I have a
much smaller set, and now it's balanced.

00:01:39.680 --> 00:01:42.435
So now half of them are negative,
and half of them are positive.

00:01:42.435 --> 00:01:45.410
&gt;&gt; because we keep separating
the chaff from the wheat.

00:01:45.410 --> 00:01:47.270
&gt;&gt; Right, yeah, let's go with that.

00:01:47.270 --> 00:01:48.740
And so
the year with the sort of small set, and

00:01:48.740 --> 00:01:52.820
now I can apply my learner here, with
the sort of 50/50 split let's say, and

00:01:52.820 --> 00:01:54.560
I actually do a pretty good job.

00:01:54.560 --> 00:01:56.320
Now there's two things that
are worth pointing out here.

00:01:56.320 --> 00:01:58.290
&gt;&gt; Okay.
&gt;&gt; Well, there's a zero thing, which is-

00:01:58.290 --> 00:01:59.200
&gt;&gt; It's like you haven't pointed out

00:01:59.200 --> 00:01:59.960
anything so far.

00:01:59.960 --> 00:02:00.790
&gt;&gt; I'm pointing everywhere.

00:02:00.790 --> 00:02:01.560
&gt;&gt; Yeah.

00:02:01.560 --> 00:02:03.340
&gt;&gt; Now, here's the other thing,
here's the cool thing.

00:02:03.340 --> 00:02:09.180
Notice that, as I go from this data
over here to this smaller, and smaller.

00:02:09.180 --> 00:02:09.979
If I'm right, and

00:02:09.979 --> 00:02:13.730
I get about half the data surviving
the filter, then I can actually put.

00:02:15.560 --> 00:02:19.180
Twice as much learning
energy in each level.

00:02:19.180 --> 00:02:20.680
&gt;&gt; I'm pretty sure we didn't
study learning energy.

00:02:20.680 --> 00:02:21.940
&gt;&gt; Well I'm thinking
computational effort, right?

00:02:21.940 --> 00:02:22.850
&gt;&gt; All right.

00:02:22.850 --> 00:02:25.140
I see, to make it faster.

00:02:25.140 --> 00:02:26.400
&gt;&gt; Right.
So, if I keep going down my hill-

00:02:26.400 --> 00:02:27.550
&gt;&gt; Because the expected amount

00:02:27.550 --> 00:02:30.590
of computation is going to be quite
small, because most people come in and

00:02:30.590 --> 00:02:31.780
they get filtered in the first level.

00:02:31.780 --> 00:02:33.150
&gt;&gt; Right.
&gt;&gt; It's like a log thing.

00:02:33.150 --> 00:02:36.528
&gt;&gt; Yeah, so the size of the data that
I'm looking at is going down [CROSSTALK]

00:02:36.528 --> 00:02:38.094
&gt;&gt; But that means is that if I, or

00:02:38.094 --> 00:02:39.105
by a factor of two.

00:02:39.105 --> 00:02:40.404
Which means that,

00:02:40.404 --> 00:02:44.600
if I can put in a factor of two
more of computational effort.

00:02:44.600 --> 00:02:45.480
&gt;&gt; I see.

00:02:45.480 --> 00:02:48.230
&gt;&gt; And big O, it's going to be the same.

00:02:48.230 --> 00:02:49.960
&gt;&gt; Neat.
&gt;&gt; So.

00:02:49.960 --> 00:02:53.320
I can basically do something stupid,
less stupid, and

00:02:53.320 --> 00:02:55.920
by the time it gets in I can do
something actually rather sophisticated.

00:02:55.920 --> 00:02:57.190
Which I couldn't apply over here,

00:02:57.190 --> 00:02:58.920
because it would take too
much computational effort.

00:02:58.920 --> 00:03:01.380
&gt;&gt; I see, again, the expected
cost would be tremendous, but

00:03:01.380 --> 00:03:05.210
here the change in expected cost is very
small, because very little of the data

00:03:05.210 --> 00:03:06.710
actually makes it all the way
through that pipeline.

00:03:06.710 --> 00:03:08.200
&gt;&gt; Right, so that's point one.

00:03:08.200 --> 00:03:10.179
Point two is,
I now have this series of learner.

00:03:11.810 --> 00:03:13.150
And over here I've got a nice learner,

00:03:13.150 --> 00:03:15.370
that does a nice job of
separating everything out.

00:03:15.370 --> 00:03:17.240
But you'll notice that
if I took that learner.

00:03:17.240 --> 00:03:19.060
You might say,
well let's just take this learner, and

00:03:19.060 --> 00:03:20.450
I can just apply it from
the very beginning.

00:03:20.450 --> 00:03:22.042
I mean, after all,
now that I've learned the learner,

00:03:22.042 --> 00:03:23.983
it's not computationally painful,
I can, usually I can [CROSSTALK]

00:03:23.983 --> 00:03:25.149
&gt;&gt; I see because the classifier is fast,

00:03:25.149 --> 00:03:26.741
[CROSSTALK] the learning process was,
okay?

00:03:26.741 --> 00:03:31.390
And that's really good,
except it will do terribly, because why?

00:03:31.390 --> 00:03:32.780
&gt;&gt; It has a different distribution data.

00:03:32.780 --> 00:03:33.830
&gt;&gt; It has a different distribution.

00:03:33.830 --> 00:03:36.590
It learned on this distribution,
not this distribution.

00:03:36.590 --> 00:03:38.100
&gt;&gt; Got it.
&gt;&gt; So you still have to do this

00:03:38.100 --> 00:03:39.470
cascade of learners.

00:03:39.470 --> 00:03:41.500
That's why it's called cascade learners.

00:03:41.500 --> 00:03:43.720
&gt;&gt; I thought it was
because like detergent.

00:03:43.720 --> 00:03:46.030
&gt;&gt; It is like detergent, it scrubs out.

00:03:46.030 --> 00:03:49.640
I don't know enough about the Cascade
commercials to make a terrible

00:03:49.640 --> 00:03:50.490
pun here, but.

00:03:50.490 --> 00:03:53.380
&gt;&gt; All right,,
let's substitute the terrible pun here.

00:03:53.380 --> 00:03:54.163
&gt;&gt; Leaves drops the spot, right,

00:03:54.163 --> 00:03:55.206
that's the whole [CROSSTALK]
&gt;&gt; Yeah.

00:03:55.206 --> 00:03:57.429
&gt;&gt; So all the spotting
stuff comes over here, and

00:03:57.429 --> 00:04:00.812
you think of those that drops the spot
and you get spotting [INAUDIBLE].

00:04:00.812 --> 00:04:02.430
&gt;&gt; [LAUGH]
&gt;&gt; I'm glad we went through that effort.

00:04:02.430 --> 00:04:05.160
Anyway, so this sort of casting
learning thing works really well, and

00:04:05.160 --> 00:04:07.700
it gets you to this nice little place
where you've got this [INAUDIBLE].

00:04:07.700 --> 00:04:08.260
&gt;&gt; Good.

00:04:08.260 --> 00:04:08.950
&gt;&gt; And there's all

00:04:08.950 --> 00:04:11.350
kinds of things out there like that
in the supervised learning world.

00:04:11.350 --> 00:04:14.210
&gt;&gt; Can you name something that's
had an impact on I don't know,

00:04:14.210 --> 00:04:15.980
things that people have experience with?

00:04:15.980 --> 00:04:16.480
&gt;&gt; What do you mean?

00:04:17.709 --> 00:04:19.950
&gt;&gt; My understanding is that
they use some version of this,

00:04:19.950 --> 00:04:24.710
in hand held cameras, when they actually
put a little box around your face.

00:04:24.710 --> 00:04:26.090
&gt;&gt; I didn't realize that.

00:04:26.090 --> 00:04:27.141
Although it makes sense,

00:04:27.141 --> 00:04:29.592
because the original work in
fact was in exactly that space.

00:04:29.592 --> 00:04:30.434
&gt;&gt; Yeah.
&gt;&gt; It was sort of doing face

00:04:30.434 --> 00:04:31.113
finding-
&gt;&gt; Finding a face.

00:04:31.113 --> 00:04:32.053
Yeah.

00:04:32.053 --> 00:04:34.578
&gt;&gt; Where they used very
simple kind of pixel based-

00:04:34.578 --> 00:04:35.537
&gt;&gt; because most regions of an image

00:04:35.537 --> 00:04:36.501
don't have a face in them.

00:04:36.501 --> 00:04:37.244
&gt;&gt; Right.
&gt;&gt; Yeah.

00:04:37.244 --> 00:04:38.265
Finding a face.

00:04:38.265 --> 00:04:38.776
&gt;&gt; Yeah.

00:04:38.776 --> 00:04:39.729
&gt;&gt; Well it depends on
the image that you have.

00:04:39.729 --> 00:04:40.886
I'm with you.

00:04:40.886 --> 00:04:43.469
Okay, so any way there are tons of
things like that you should explore, and

00:04:43.469 --> 00:04:45.562
hopefully you are now prepared
to not just explore them, but

00:04:45.562 --> 00:04:46.479
to even understand them.

00:04:46.479 --> 00:04:47.164
&gt;&gt; Cool.

00:04:47.164 --> 00:04:48.354
&gt;&gt; So that's.

00:04:48.354 --> 00:04:49.230
&gt;&gt; Nice.

