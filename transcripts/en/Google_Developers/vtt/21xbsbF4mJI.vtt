WEBVTT
Kind: captions
Language: en

00:00:00.734 --> 00:00:02.150
ROSS KUKULINSKI:
Thank you, Chris.

00:00:02.150 --> 00:00:04.660
So again, my name
is Ross Kukulinski.

00:00:04.660 --> 00:00:08.380
I'm working with a newly
formed group called SpeakIt.io.

00:00:08.380 --> 00:00:10.380
We're actually a
spinoff out of a company

00:00:10.380 --> 00:00:13.110
that's been doing real-time
sound and communication

00:00:13.110 --> 00:00:16.350
systems for flight simulators
and military training

00:00:16.350 --> 00:00:17.710
and gaming applications.

00:00:17.710 --> 00:00:19.370
So we're sort of
coming at WebRTC

00:00:19.370 --> 00:00:20.703
from a slightly different angle.

00:00:20.703 --> 00:00:22.730
We're not
telecommunication people.

00:00:22.730 --> 00:00:24.210
We're not web developers.

00:00:24.210 --> 00:00:27.420
I mean, we are, but we're coming
at a very different angle.

00:00:27.420 --> 00:00:29.710
And basically the
previous presentation

00:00:29.710 --> 00:00:31.210
was a perfect
warm-up, because we're

00:00:31.210 --> 00:00:33.950
going to go more in-depth
into how you can potentially

00:00:33.950 --> 00:00:37.530
scale your WebRTC applications
from beyond 10 to 20 people

00:00:37.530 --> 00:00:42.170
in a conference to 200 or 2,000.

00:00:42.170 --> 00:00:45.330
So far today, we've heard
WebRTC is fundamentally

00:00:45.330 --> 00:00:48.270
a peer-to-peer application.

00:00:48.270 --> 00:00:49.290
Peer-to-peer is awesome.

00:00:49.290 --> 00:00:51.010
It gets back to the
decentralized nature

00:00:51.010 --> 00:00:51.740
of the internet.

00:00:51.740 --> 00:00:55.770
It takes control and puts it
back into us as web developers.

00:00:55.770 --> 00:00:58.350
It puts the control
back into the endpoints.

00:00:58.350 --> 00:01:03.230
And that's awesome, until
you need to get big.

00:01:03.230 --> 00:01:05.030
So before we get
into that, I want

00:01:05.030 --> 00:01:07.910
to cover a couple of
audio vocabulary terms

00:01:07.910 --> 00:01:09.849
that I'm going to
throw out there.

00:01:09.849 --> 00:01:11.640
Most web developers
maybe won't necessarily

00:01:11.640 --> 00:01:12.730
need to deal with
this, but if you're

00:01:12.730 --> 00:01:14.430
going to build a
scalable application,

00:01:14.430 --> 00:01:16.170
these words are
going to come up.

00:01:16.170 --> 00:01:17.940
So first of all, transcoding.

00:01:17.940 --> 00:01:21.350
So the idea of transcoding,
if you have an audio stream,

00:01:21.350 --> 00:01:22.860
it's going to have
a certain codec.

00:01:22.860 --> 00:01:23.880
It might be Opus.

00:01:23.880 --> 00:01:24.720
It might be VP8.

00:01:24.720 --> 00:01:27.540
It might have a signal rate.

00:01:27.540 --> 00:01:29.650
Transcoding is the
transfer of that data

00:01:29.650 --> 00:01:32.970
from one interpretation
to another.

00:01:32.970 --> 00:01:35.060
And the reason you need
to do that is in order

00:01:35.060 --> 00:01:37.010
to mix two audio
streams, they need

00:01:37.010 --> 00:01:39.080
to be in fundamentally
the same format.

00:01:39.080 --> 00:01:41.360
So in terms of
audio scalability,

00:01:41.360 --> 00:01:43.050
we end up mixing audio.

00:01:43.050 --> 00:01:45.920
Now, Chrome and Firefox
or browser limitations

00:01:45.920 --> 00:01:48.750
that's underneath in the
WebRTC implementation,

00:01:48.750 --> 00:01:50.502
they are doing this for you.

00:01:50.502 --> 00:01:52.710
But if you're going to build
a scalable architecture,

00:01:52.710 --> 00:01:55.585
you probably need some other
larger system to handle that.

00:01:55.585 --> 00:01:56.960
The other item
that I may mention

00:01:56.960 --> 00:02:00.432
is Acoustic Echo
Cancellation, or AEC.

00:02:00.432 --> 00:02:02.640
Chrome and Firefox have them
built in to some degree.

00:02:02.640 --> 00:02:04.280
They're now in the getUserMedia.

00:02:04.280 --> 00:02:06.780
When we first started building
this, none of that was there.

00:02:06.780 --> 00:02:09.030
So we've actually
built our own version.

00:02:09.030 --> 00:02:10.699
And we're doing some
parallel testing

00:02:10.699 --> 00:02:14.370
of doing AEC in the
browser in our own code

00:02:14.370 --> 00:02:16.840
in addition to comparing
it against the reference

00:02:16.840 --> 00:02:20.150
implementation specs.

00:02:20.150 --> 00:02:22.374
So this is a fully
meshed architecture.

00:02:22.374 --> 00:02:24.040
When we are seeing
these demonstrations,

00:02:24.040 --> 00:02:26.590
this is usually what's
happening in terms of the media

00:02:26.590 --> 00:02:28.420
stream that's going
between the nodes.

00:02:28.420 --> 00:02:31.200
We've got three nodes
here-- A, B, and C.

00:02:31.200 --> 00:02:33.440
And each one is sending
its own media stream

00:02:33.440 --> 00:02:35.617
to the other peers.

00:02:35.617 --> 00:02:38.200
If you only have three people,
this is pretty straightforward.

00:02:38.200 --> 00:02:42.171
Chrome browser and Firefox are
really, really good at this.

00:02:42.171 --> 00:02:44.890
This is six nodes.

00:02:44.890 --> 00:02:47.040
It's still going to
work just fine in most

00:02:47.040 --> 00:02:48.650
of the current browsers today.

00:02:48.650 --> 00:02:51.940
But if you make this 60 nodes,
all of those interconnection

00:02:51.940 --> 00:02:56.160
things means increased bandwidth
and increased CPU usage

00:02:56.160 --> 00:02:59.575
at each of those nodes.

00:02:59.575 --> 00:03:01.750
The kind folks at
Google and Mozilla,

00:03:01.750 --> 00:03:03.650
they're working
really, really hard

00:03:03.650 --> 00:03:05.600
to get their
browsers to be better

00:03:05.600 --> 00:03:08.330
at handling large
number of connections.

00:03:08.330 --> 00:03:13.909
But at some point,
the browsers aren't

00:03:13.909 --> 00:03:15.950
going to be able to keep
up, especially if you're

00:03:15.950 --> 00:03:17.684
doing applications like gaming.

00:03:17.684 --> 00:03:19.100
The browser is
going to be focused

00:03:19.100 --> 00:03:23.880
on doing the video rendering and
other actions on the platform,

00:03:23.880 --> 00:03:26.090
and so audio is
going to get dropped

00:03:26.090 --> 00:03:29.860
towards the bottom of the
implementation details.

00:03:29.860 --> 00:03:32.240
So what are some ways
we can get around this?

00:03:32.240 --> 00:03:33.890
One, we could change
our architecture

00:03:33.890 --> 00:03:37.456
and go to a star mesh, where
we are able to locate-- maybe

00:03:37.456 --> 00:03:38.580
we've got a node somewhere.

00:03:38.580 --> 00:03:41.610
Someone's desktop computer has
got massive processing power,

00:03:41.610 --> 00:03:43.440
and we can take
advantage of that.

00:03:43.440 --> 00:03:47.540
So maybe B and C and E and D
are clients that-- maybe they're

00:03:47.540 --> 00:03:48.310
mobile clients.

00:03:48.310 --> 00:03:50.490
Or maybe they are
less powerful laptops.

00:03:50.490 --> 00:03:53.710
They can offload some of that
mixing and transcoding work

00:03:53.710 --> 00:03:56.224
to A.

00:03:56.224 --> 00:03:57.390
We'll make this bigger.

00:03:57.390 --> 00:03:58.848
We actually could
even do something

00:03:58.848 --> 00:04:00.970
where we've got multiple stars.

00:04:00.970 --> 00:04:04.730
And some of the early versions
of the Skype platform, this

00:04:04.730 --> 00:04:07.740
is actually what they used for
their signaling and always-on

00:04:07.740 --> 00:04:09.210
peer-to-peer network.

00:04:09.210 --> 00:04:13.140
Here we could use this and do
this with the data platform.

00:04:13.140 --> 00:04:15.190
One of the problems
with this, though,

00:04:15.190 --> 00:04:19.190
is that it's hard to determine,
at least with current APIs

00:04:19.190 --> 00:04:21.329
available in the
browser, which platforms

00:04:21.329 --> 00:04:24.010
are going to be powerful
enough to do this.

00:04:24.010 --> 00:04:25.626
It hits at that noisy neighbor.

00:04:25.626 --> 00:04:27.500
What other things are
running on that browser

00:04:27.500 --> 00:04:28.680
or running on that box?

00:04:28.680 --> 00:04:32.790
How do you know which ones
are going to the best nodes

00:04:32.790 --> 00:04:34.696
to do that processing?

00:04:34.696 --> 00:04:36.820
So the other alternative,
which we've been hearing,

00:04:36.820 --> 00:04:40.560
is this thing of MCU,
Multipoint Control Unit.

00:04:40.560 --> 00:04:43.780
These are actually new words
to my group over the last six

00:04:43.780 --> 00:04:46.840
months, because we're not coming
from the telecommunications.

00:04:46.840 --> 00:04:49.290
But it's a more traditional
client server architecture,

00:04:49.290 --> 00:04:51.770
where A, B, and C
are generic nodes.

00:04:51.770 --> 00:04:54.790
So they might be a mobile
browser or a web browser.

00:04:54.790 --> 00:04:58.360
They might be a native
app running on a device.

00:04:58.360 --> 00:05:01.415
Here, the MCU is going to do
all of the transcoding, all

00:05:01.415 --> 00:05:04.280
of the mixing of that
audio, potentially video.

00:05:04.280 --> 00:05:07.550
There's a number of
different MCU options

00:05:07.550 --> 00:05:11.150
that you can choose as
an application developer.

00:05:11.150 --> 00:05:14.090
There are open source
ones that you can take.

00:05:14.090 --> 00:05:15.830
A lot of them work pretty well.

00:05:15.830 --> 00:05:17.760
They're self-contained.

00:05:17.760 --> 00:05:20.310
There's a couple of providers
that are providing that as

00:05:20.310 --> 00:05:22.317
one-off, like you rent a server.

00:05:22.317 --> 00:05:24.400
And then there's a couple
of platform-as-a-service

00:05:24.400 --> 00:05:25.760
providers.

00:05:25.760 --> 00:05:27.632
I'm not going to do
any naming names.

00:05:27.632 --> 00:05:29.090
But this is what
it looks like when

00:05:29.090 --> 00:05:30.940
you get to a larger conference.

00:05:30.940 --> 00:05:33.400
Here we're back to
our six clients.

00:05:33.400 --> 00:05:35.600
And you'll notice
that A through F,

00:05:35.600 --> 00:05:37.200
even though there's
six nodes now,

00:05:37.200 --> 00:05:39.840
they still only have
one stream going out

00:05:39.840 --> 00:05:41.470
and one stream coming in.

00:05:41.470 --> 00:05:43.490
The MCU is taking care
of all of the processing

00:05:43.490 --> 00:05:46.010
and transcoding, with
the exception of the one

00:05:46.010 --> 00:05:49.210
transcoding for node A
to go from whatever's

00:05:49.210 --> 00:05:51.230
on the network stream
to translating out

00:05:51.230 --> 00:05:52.100
the audio device.

00:05:52.100 --> 00:05:53.190
And that's going to
be in the browser.

00:05:53.190 --> 00:05:55.315
And you're going to have
to do that no matter what.

00:05:55.315 --> 00:05:59.220
But the idea is to offload
some of that extra work.

00:05:59.220 --> 00:06:02.280
So what are the advantages
of having an MCU

00:06:02.280 --> 00:06:03.870
as part of your
WebRTC application?

00:06:03.870 --> 00:06:06.810
Well, number one, it offloads
processing from your endpoints.

00:06:06.810 --> 00:06:09.190
It also allows you to
do more things with it.

00:06:09.190 --> 00:06:11.790
You can do things like
recording or transcription.

00:06:11.790 --> 00:06:13.760
Maybe you have a
conference or game,

00:06:13.760 --> 00:06:15.580
you can store that
data for later,

00:06:15.580 --> 00:06:17.235
do live, real-time
speech recognition,

00:06:17.235 --> 00:06:19.690
and translate that data.

00:06:19.690 --> 00:06:21.160
You also can rebroadcast that.

00:06:21.160 --> 00:06:23.910
So if you have a participant
list, if you're building,

00:06:23.910 --> 00:06:25.560
let's say, a podcast platform.

00:06:25.560 --> 00:06:27.372
And you've got one
or two co-hosts,

00:06:27.372 --> 00:06:29.080
and maybe they've got
four or five people

00:06:29.080 --> 00:06:30.390
they're going to call in.

00:06:30.390 --> 00:06:32.820
But maybe you've got
10,000 subscribers

00:06:32.820 --> 00:06:35.390
that want to listen
to this podcast live.

00:06:35.390 --> 00:06:37.090
Taking advantage
of an MCU allows

00:06:37.090 --> 00:06:39.574
you to rebroadcast that out.

00:06:39.574 --> 00:06:41.240
And then finally, you
can do cool things

00:06:41.240 --> 00:06:44.280
like having sound effects
and text to speech and music

00:06:44.280 --> 00:06:48.080
to keep yourselves occupied.

00:06:48.080 --> 00:06:48.580
All right.

00:06:48.580 --> 00:06:49.955
So I'm going to
talk a little bit

00:06:49.955 --> 00:06:53.720
about how we've built
out our application.

00:06:53.720 --> 00:06:57.630
So let's start at
the very bottom here.

00:06:57.630 --> 00:06:59.840
So we have our browser objects.

00:06:59.840 --> 00:07:01.755
So the little B squares
at the bottom, those

00:07:01.755 --> 00:07:02.504
are your browsers.

00:07:02.504 --> 00:07:04.710
So they might be
a desktop browser.

00:07:04.710 --> 00:07:07.320
They may be a mobile device.

00:07:07.320 --> 00:07:09.950
And the first version
of this we built

00:07:09.950 --> 00:07:13.150
was before there was the
echo canceling in the Chrome

00:07:13.150 --> 00:07:14.150
platform.

00:07:14.150 --> 00:07:17.230
And we were building
this for our own use,

00:07:17.230 --> 00:07:18.262
for our own company.

00:07:18.262 --> 00:07:19.470
We are a distributed company.

00:07:19.470 --> 00:07:21.240
We have employees
scattered all over.

00:07:21.240 --> 00:07:23.930
So we wanted an easy way
for us to all communicate.

00:07:23.930 --> 00:07:26.910
So we actually said to heck
with the peer connection stuff.

00:07:26.910 --> 00:07:28.030
Let's use getUserMedia.

00:07:28.030 --> 00:07:30.260
Let's get the microphone,
attach the speaker.

00:07:30.260 --> 00:07:33.460
Let's send that data over a
WebSocket back to our server,

00:07:33.460 --> 00:07:37.079
and then back to our
MCU in the back end.

00:07:37.079 --> 00:07:39.120
One of the first things
that we ran into in terms

00:07:39.120 --> 00:07:41.210
of performance
problem was the fact

00:07:41.210 --> 00:07:44.590
that Node.js, which was
the platform we're using,

00:07:44.590 --> 00:07:46.450
doesn't handle SSL termination.

00:07:46.450 --> 00:07:50.080
SSL is the secure link between
your browser and the server.

00:07:50.080 --> 00:07:53.960
And so in order to offload
that work from Node.js,

00:07:53.960 --> 00:07:58.830
we put an EngineX set of
load balancers in between.

00:07:58.830 --> 00:08:01.300
That allows SSL
connection to be moved,

00:08:01.300 --> 00:08:03.505
and then Node.js
is able to handle

00:08:03.505 --> 00:08:05.670
all of the websocket
connections.

00:08:05.670 --> 00:08:07.550
Then from Node.js,
we're able to pipe

00:08:07.550 --> 00:08:10.700
that data back to our MCUs,
which then can mix the audio,

00:08:10.700 --> 00:08:12.710
transcode it, get
everything all set up,

00:08:12.710 --> 00:08:15.520
and then ship it
all the way back.

00:08:15.520 --> 00:08:17.190
On the right-hand
side of the image,

00:08:17.190 --> 00:08:18.530
we have the control interface.

00:08:18.530 --> 00:08:20.870
So not unlike
Squiggle, we've built

00:08:20.870 --> 00:08:23.000
a REST API to handle
the setting up

00:08:23.000 --> 00:08:25.840
and tearing down of
rooms, which in our case

00:08:25.840 --> 00:08:29.210
in a local mixing
cluster, we're using Redis

00:08:29.210 --> 00:08:32.880
as our pub/sub messaging
system between our Node.js

00:08:32.880 --> 00:08:36.890
clusters and our MCUs, and
then our node REST API.

00:08:43.030 --> 00:08:45.280
However, once the peer
connection in Chrome

00:08:45.280 --> 00:08:48.180
got their echo canceling
on board, we started work--

00:08:48.180 --> 00:08:51.160
and we're still in the process
of finishing up this platform.

00:08:51.160 --> 00:08:53.790
Basically, we've
removed the need

00:08:53.790 --> 00:08:57.180
for having that EngineX
web server in the way.

00:08:57.180 --> 00:08:58.820
So now we can have
direct connection

00:08:58.820 --> 00:09:02.722
from the browser to a peer
connection running in Node.js.

00:09:02.722 --> 00:09:04.180
There's actually
a C plug-in that's

00:09:04.180 --> 00:09:09.100
running underneath Node that's
handling the raw binaries data.

00:09:09.100 --> 00:09:12.026
And then we're able to transmit
and send that back to our MCUs.

00:09:12.026 --> 00:09:13.400
And then, on the
right-hand side,

00:09:13.400 --> 00:09:15.920
I simplified things
and just put config.

00:09:15.920 --> 00:09:18.110
It's actually the same
configuration we have here,

00:09:18.110 --> 00:09:22.010
but I got sick of drawing.

00:09:22.010 --> 00:09:26.160
OK, so as you're building
out this MCU platform,

00:09:26.160 --> 00:09:27.870
one of the cool things
is that now you've

00:09:27.870 --> 00:09:29.500
got this back-end service.

00:09:29.500 --> 00:09:33.060
Now, for web developers or the
architecture side of people,

00:09:33.060 --> 00:09:35.390
this is where things, in my
opinion, get real exciting.

00:09:35.390 --> 00:09:37.450
Now you can take all
of those audio streams

00:09:37.450 --> 00:09:38.910
and send them off
to something else

00:09:38.910 --> 00:09:40.540
and do really cool
things with them.

00:09:40.540 --> 00:09:42.920
So you can do things
like recording,

00:09:42.920 --> 00:09:44.630
doing speech recognition,
text to speech,

00:09:44.630 --> 00:09:48.630
feeding data back in, being able
to recognize when a user gives

00:09:48.630 --> 00:09:49.360
a command.

00:09:49.360 --> 00:09:52.140
So we could have Google
Glass sitting back there.

00:09:52.140 --> 00:09:54.890
You can give commands to
your media control system

00:09:54.890 --> 00:09:58.364
and have it do stuff, tie
into your HipChat system

00:09:58.364 --> 00:09:59.280
or whatever it may be.

00:10:04.770 --> 00:10:09.502
A lot of the open source MCUs
are self-contained boxes.

00:10:09.502 --> 00:10:11.710
They're not able to communicate
with other platforms.

00:10:11.710 --> 00:10:13.960
Not all of them, but that
tends to be a common thing.

00:10:16.550 --> 00:10:20.610
So there's a decision you have
to make as an implementer.

00:10:20.610 --> 00:10:22.930
Do we want a given
room, when it's

00:10:22.930 --> 00:10:26.160
built-- is the room going to
be self-contained entirely

00:10:26.160 --> 00:10:28.310
in one of those MCUs?

00:10:28.310 --> 00:10:30.080
In other words, all
the browsers may

00:10:30.080 --> 00:10:32.940
go through one of the different
Node.js hops and eventually may

00:10:32.940 --> 00:10:35.260
make their way all to one MCU.

00:10:35.260 --> 00:10:38.250
And that MCU is going to
contain some number of rooms,

00:10:38.250 --> 00:10:41.990
but each room is going to
be entirely in that MCU.

00:10:41.990 --> 00:10:43.600
There's some advantages to that.

00:10:43.600 --> 00:10:46.720
One advantage is that
in terms of simplicity,

00:10:46.720 --> 00:10:48.220
that MCU can be
highly optimized.

00:10:48.220 --> 00:10:50.840
It just has to mix the
audio right there in memory

00:10:50.840 --> 00:10:54.330
and then ship it back
out over the network.

00:10:54.330 --> 00:10:57.360
It also, in my
opinion, has a feature

00:10:57.360 --> 00:11:00.160
in that if you do have something
that's going to go down

00:11:00.160 --> 00:11:02.840
and if your MCU does have a
crash or something happens--

00:11:02.840 --> 00:11:06.790
which, things happen--
then the entire room goes

00:11:06.790 --> 00:11:09.670
down all at once.

00:11:09.670 --> 00:11:11.670
The alternative is,
if you have your room

00:11:11.670 --> 00:11:15.560
spread across multiple MCUs,
if one of them goes down,

00:11:15.560 --> 00:11:18.620
you might get in this
half-on, half-off state, where

00:11:18.620 --> 00:11:21.242
some of your clients view
the room as being live

00:11:21.242 --> 00:11:22.700
and everyone's
there and connected,

00:11:22.700 --> 00:11:25.517
but maybe half the people
aren't hearing anything.

00:11:25.517 --> 00:11:27.350
That's an architectural
decision that you'll

00:11:27.350 --> 00:11:30.600
need to make and find out what
that trade-off is for you.

00:11:30.600 --> 00:11:33.122
We've elected to, for
now, keep everything

00:11:33.122 --> 00:11:34.580
all self-contained
in a single MCU.

00:11:38.810 --> 00:11:41.000
And this is how, if we
were to do this, which

00:11:41.000 --> 00:11:44.110
our platform does support,
we're siding with trying

00:11:44.110 --> 00:11:45.967
to keep things all
self-contained.

00:11:45.967 --> 00:11:48.050
But it could be done through
multicast networking.

00:11:48.050 --> 00:11:49.830
You also could, in
theory, take advantage

00:11:49.830 --> 00:11:52.500
of WebRTC between
your MCUs and have

00:11:52.500 --> 00:11:54.570
them sync in a peer-to-peer
fashion as well.

00:11:57.180 --> 00:11:59.640
Obviously, if you're going to
get to a large enough scale,

00:11:59.640 --> 00:12:01.340
you don't want to have
everything just in one data

00:12:01.340 --> 00:12:02.090
center.

00:12:02.090 --> 00:12:04.790
You want to have
multiple data centers.

00:12:04.790 --> 00:12:07.940
And the pub/sub that we have
here is actually-- we're

00:12:07.940 --> 00:12:11.270
also using RabbitMQ that
the Squiggle folks are using

00:12:11.270 --> 00:12:16.490
for the AMQP data transfer, the
consistent state of what rooms

00:12:16.490 --> 00:12:18.760
do we have across the
entire infrastructure?

00:12:18.760 --> 00:12:21.420
Not just one data center or
not just one mixing cluster,

00:12:21.420 --> 00:12:24.944
but what is the entire state
of the entire application?

00:12:24.944 --> 00:12:27.610
And the reason that we're taking
advantage of pub/sub suggesting

00:12:27.610 --> 00:12:30.081
is A, it's low latency.

00:12:30.081 --> 00:12:32.330
We can send lots and lots
of messages between our data

00:12:32.330 --> 00:12:33.240
centers.

00:12:33.240 --> 00:12:34.910
If we need to, we
can store them,

00:12:34.910 --> 00:12:36.790
if there's too much traffic.

00:12:36.790 --> 00:12:38.876
We also can scale up
our RabbitMQ system.

00:12:38.876 --> 00:12:40.250
If we just had a
single database,

00:12:40.250 --> 00:12:41.791
then we're tied to
a single database.

00:12:45.230 --> 00:12:47.022
So that's cool.

00:12:47.022 --> 00:12:48.720
At least, I think so.

00:12:48.720 --> 00:12:49.450
So now what?

00:12:49.450 --> 00:12:50.500
So you're building
an application.

00:12:50.500 --> 00:12:51.040
You're a developer.

00:12:51.040 --> 00:12:52.790
You're trying to figure
out what to build.

00:12:52.790 --> 00:12:55.010
What decisions do
you need to make?

00:12:55.010 --> 00:12:58.650
Well, first of all, you need
to analyze your requirements.

00:12:58.650 --> 00:13:00.260
Are you just
building an app where

00:13:00.260 --> 00:13:02.550
you need-- let's say it's
a medical application.

00:13:02.550 --> 00:13:05.086
You have a doctor who needs
to interact with a patient.

00:13:05.086 --> 00:13:08.650
You probably don't
need all of this.

00:13:08.650 --> 00:13:10.267
Traditional STUN
and TURN server is

00:13:10.267 --> 00:13:11.850
going to provide the
capability to get

00:13:11.850 --> 00:13:13.210
those browsers connected.

00:13:13.210 --> 00:13:16.090
Chrome and Firefox and
Opera and hopefully

00:13:16.090 --> 00:13:19.952
eventually Internet
Explorer and Safari

00:13:19.952 --> 00:13:21.285
will pick up these new features.

00:13:23.790 --> 00:13:27.285
The next question is,
if you do need an MCU,

00:13:27.285 --> 00:13:29.430
are you going to be
Squiggle and roll your own,

00:13:29.430 --> 00:13:32.800
go through the fun process of
building out your own system?

00:13:32.800 --> 00:13:35.140
Or are you going to go with
a commercial application?

00:13:35.140 --> 00:13:39.097
There are companies that sell
just a standalone MCU, where

00:13:39.097 --> 00:13:40.680
you can just take
that and drop it in.

00:13:40.680 --> 00:13:42.710
That may work if you
know that you only

00:13:42.710 --> 00:13:46.970
need somewhere between 100
or 200, 500 people in a room.

00:13:46.970 --> 00:13:48.750
That may work just fine.

00:13:48.750 --> 00:13:51.190
However, you probably
will have to figure out

00:13:51.190 --> 00:13:53.350
how to group them
together and deal

00:13:53.350 --> 00:13:56.320
with the scalability
and that sort of thing.

00:13:56.320 --> 00:13:59.460
Open source, off the
shelf, or hosted?

00:13:59.460 --> 00:14:02.820
All of which really, really
fundamentally depend on what

00:14:02.820 --> 00:14:06.720
are your specific requirements.

00:14:06.720 --> 00:14:08.190
That's all I have.

00:14:08.190 --> 00:14:08.730
Thank you.

00:14:08.730 --> 00:14:13.632
[APPLAUSE]

00:14:13.632 --> 00:14:14.340
MALE SPEAKER: OK.

00:14:14.340 --> 00:14:15.010
Thank you, Ross.

00:14:15.010 --> 00:14:17.780
We're actually running, believe
it or not, ahead of schedule.

00:14:17.780 --> 00:14:20.370
But don't get too
excited, because we're

00:14:20.370 --> 00:14:23.390
going to-- yeah,
[? Serge is ?] coming.

00:14:23.390 --> 00:14:24.160
It's coming.

00:14:24.160 --> 00:14:25.204
It's coming.

00:14:25.204 --> 00:14:26.620
Do we have any
questions for Ross?

00:14:26.620 --> 00:14:27.600
Yes, please speak up.

00:14:27.600 --> 00:14:28.490
Ross, come back up.

00:14:28.490 --> 00:14:30.007
And be sure to
repeat the question.

00:14:30.007 --> 00:14:31.756
AUDIENCE: Yeah, I must
have spaced it out,

00:14:31.756 --> 00:14:35.740
but in one of your slides, you
went from browser to Node.js.

00:14:35.740 --> 00:14:38.350
ROSS KUKULINSKI: Yes.

00:14:38.350 --> 00:14:42.332
AUDIENCE: How did you accomplish
your SSL requirements?

00:14:42.332 --> 00:14:43.790
ROSS KUKULINSKI:
There is a module.

00:14:47.790 --> 00:14:50.160
I'm now blanking on
the name of the module.

00:14:50.160 --> 00:14:52.550
What they've done is
they've taken a node module,

00:14:52.550 --> 00:14:55.840
and they have native
libraries underneath that

00:14:55.840 --> 00:14:58.280
are wrapped as a Node.js module.

00:14:58.280 --> 00:15:00.420
And the underlying
code is loaded

00:15:00.420 --> 00:15:02.620
into the V8 runtime,
which then does

00:15:02.620 --> 00:15:04.180
all of the SSL and the security.

00:15:04.180 --> 00:15:07.600
So Node is then dealing
with the security,

00:15:07.600 --> 00:15:10.370
so we actually are having to
increase the number of Node.js

00:15:10.370 --> 00:15:13.970
servers that we
have to handle that.

00:15:13.970 --> 00:15:16.650
Because before, we had EngineX,
which is really, really

00:15:16.650 --> 00:15:19.110
good at handling
SSL termination.

00:15:19.110 --> 00:15:22.091
AUDIENCE: And you gave
up load balancing also?

00:15:22.091 --> 00:15:23.840
MALE SPEAKER: Repeat
the question, please.

00:15:23.840 --> 00:15:24.965
ROSS KUKULINSKI: Oh, sorry.

00:15:24.965 --> 00:15:26.930
The question is, in
addition to switching away

00:15:26.930 --> 00:15:30.950
with the EngineX, we also
gave up the load balancing.

00:15:30.950 --> 00:15:33.979
The load balancing is actually
part of the configuration.

00:15:33.979 --> 00:15:34.520
You're right.

00:15:34.520 --> 00:15:36.450
I missed this is my drawing.

00:15:36.450 --> 00:15:40.580
As part of our library that
we've built into the browser

00:15:40.580 --> 00:15:43.940
SDK, it's able to communicate
with the config on the far

00:15:43.940 --> 00:15:46.230
right and figure out
which data center

00:15:46.230 --> 00:15:50.320
or which Node.js pure
connection termination to make.

00:15:50.320 --> 00:15:54.290
So basically the browser
initiates a pure connection

00:15:54.290 --> 00:15:57.790
as part of the
STUN configuration.

00:15:57.790 --> 00:16:00.330
It's told which room to join.

00:16:00.330 --> 00:16:03.167
And then one of
the Node.js nodes

00:16:03.167 --> 00:16:04.500
will then join that appropriate.

00:16:04.500 --> 00:16:06.125
So then we have a
one-to-one connection

00:16:06.125 --> 00:16:08.876
between the browser and Node.js.

00:16:08.876 --> 00:16:11.952
AUDIENCE: Do you know the
framework for the node SSL

00:16:11.952 --> 00:16:12.536
that you used?

00:16:12.536 --> 00:16:14.826
ROSS KUKULINSKI: I do not
know the name of the node SSL

00:16:14.826 --> 00:16:16.500
library off the top of my head.

00:16:16.500 --> 00:16:18.430
I'd be happy to talk
with you afterwards.

00:16:18.430 --> 00:16:20.570
Yeah, there's a question
in the way back.

00:16:20.570 --> 00:16:23.390
AUDIENCE: You said that you
were sending the audio raw?

00:16:23.390 --> 00:16:25.872
Does that mean
without any coding?

00:16:25.872 --> 00:16:27.580
ROSS KUKULINSKI: I
believe the question--

00:16:27.580 --> 00:16:29.204
and correct me if
I'm wrong-- is are we

00:16:29.204 --> 00:16:31.230
sending the audio raw
without any encoding?

00:16:33.930 --> 00:16:35.950
In this implementation,
where we're

00:16:35.950 --> 00:16:40.390
talking through WebSocket, we
are sending 16-bit PCM audio.

00:16:40.390 --> 00:16:46.080
So it works extremely well on
higher bandwidth applications.

00:16:46.080 --> 00:16:50.320
Obviously, we've been testing
on Chrome Android devices.

00:16:50.320 --> 00:16:53.210
On a decent Wi-Fi
network, it works fine.

00:16:53.210 --> 00:16:56.940
As you start to get
to 4G modems, it's OK.

00:16:56.940 --> 00:16:59.240
Usually it starts to fall over.

00:16:59.240 --> 00:17:02.390
And our current implementation
does not work at all on 3G.

00:17:02.390 --> 00:17:04.190
When we built this,
our primary target

00:17:04.190 --> 00:17:06.910
was for ourselves as developers
to be able to communicate.

00:17:06.910 --> 00:17:09.430
And we're all at the office
or at the different offices

00:17:09.430 --> 00:17:12.669
or at home with very solid
internet connections.

00:17:12.669 --> 00:17:14.960
With this new platform, we
take advantage of everything

00:17:14.960 --> 00:17:16.835
that Chrome browser does
underneath the hood,

00:17:16.835 --> 00:17:19.832
in terms of the Opus codecs
and VP8 and all that stuff.

00:17:19.832 --> 00:17:21.040
Another question in the back.

00:17:25.030 --> 00:17:28.920
AUDIENCE: Is the MCU a browser?

00:17:28.920 --> 00:17:30.989
ROSS KUKULINSKI: Is
the MCU a browser?

00:17:30.989 --> 00:17:32.280
AUDIENCE: Hardware or software?

00:17:32.280 --> 00:17:34.600
ROSS KUKULINSKI:
Oh, it's a software.

00:17:34.600 --> 00:17:38.440
Ours is entirely a Linux-based
real-time audio platform.

00:17:38.440 --> 00:17:42.420
It's what we've built for flight
simulation, military training.

00:17:42.420 --> 00:17:45.310
We have these installations
with thousands of flight sims

00:17:45.310 --> 00:17:47.600
and soldiers running
around playing video games,

00:17:47.600 --> 00:17:49.600
and we provide the real-time
voice communication

00:17:49.600 --> 00:17:50.240
for all that.

00:17:50.240 --> 00:17:54.180
So for us, our MCU is a
software-based Linux real-time

00:17:54.180 --> 00:17:55.400
platform.

00:17:55.400 --> 00:17:57.830
A lot of the other MCUs--
like there's Jitsi.

00:17:57.830 --> 00:18:00.180
It's got the video bridge.

00:18:00.180 --> 00:18:02.640
There's a couple of others
that are Java-based.

00:18:02.640 --> 00:18:05.000
And there are also
hardware-based MCUs.

00:18:05.000 --> 00:18:07.100
But our issue with
hardware-based MCUs

00:18:07.100 --> 00:18:09.276
is then you need lots
and lots of hardware.

00:18:09.276 --> 00:18:11.400
And then we can't take
advantage of cloud providers

00:18:11.400 --> 00:18:15.327
like Rackspace or DigitalOcean
or AWS in terms of scalability.

00:18:15.327 --> 00:18:17.160
And I've been told
that's the last question.

00:18:17.160 --> 00:18:18.620
So if there are any
other questions,

00:18:18.620 --> 00:18:19.661
we've got the break next.

00:18:19.661 --> 00:18:21.110
So I'll stick around up here.

00:18:21.110 --> 00:18:23.180
If you want to ask me
questions, I'm here.

00:18:23.180 --> 00:18:24.136
Thanks.

00:18:24.136 --> 00:18:25.260
MALE SPEAKER: Thanks, Ross.

00:18:25.260 --> 00:18:26.718
Ross has got a
wealth of knowledge.

00:18:26.718 --> 00:18:28.310
Please tap into him.

