WEBVTT
Kind: captions
Language: en

00:00:01.046 --> 00:00:05.273
(clicking)
(electronic chiming)

00:00:05.273 --> 00:00:07.856
(upbeat music)

00:00:31.080 --> 00:00:34.860
- Welcome to A Conversation
With History, I'm Harry Kreisler

00:00:34.860 --> 00:00:37.370
at the Institute of International Studies.

00:00:37.370 --> 00:00:39.730
Our guest today is Sherry Turkle,

00:00:39.730 --> 00:00:43.100
who is the Abby Rockefeller Mauze

00:00:43.100 --> 00:00:48.100
professor of social studies,
of science and technology,

00:00:48.210 --> 00:00:50.850
in the Program in Science Technology,

00:00:50.850 --> 00:00:55.850
and Society at the Massachusets
Institute of Technology.

00:00:56.450 --> 00:01:00.310
She's a prolific writer, and
has published many books,

00:01:00.310 --> 00:01:02.810
including Life on the Screen:

00:01:02.810 --> 00:01:05.510
Identity in the age of the Internet,

00:01:05.510 --> 00:01:09.650
Alone Together: Why we
Expect More from Technology

00:01:09.650 --> 00:01:11.300
and Less From Each Other.

00:01:11.300 --> 00:01:15.230
And most recently,
Reclaiming Conversation:

00:01:15.230 --> 00:01:19.130
The Power of Talk in a Digital Age.

00:01:19.130 --> 00:01:20.790
Sherry, welcome to Berkeley.

00:01:20.790 --> 00:01:21.920
- My pleasure.

00:01:21.920 --> 00:01:23.440
- Where were you born and raised?

00:01:23.440 --> 00:01:25.640
- I was born in Brooklyn, New York.

00:01:25.640 --> 00:01:27.360
And that's where I was raised.

00:01:27.360 --> 00:01:31.040
- And looking back, how
do you think your parents

00:01:31.040 --> 00:01:33.173
shape your thinking about the world?

00:01:34.830 --> 00:01:38.160
- I think they had a pretty

00:01:38.160 --> 00:01:41.170
insular view of the world,

00:01:41.170 --> 00:01:46.170
I think that they didn't
really live much past Brooklyn.

00:01:46.730 --> 00:01:49.360
And I think that they
shaped my view of the world

00:01:49.360 --> 00:01:51.623
'cause I so desperately wanted to get out.

00:01:52.740 --> 00:01:54.860
So I think that they shaped me

00:01:54.860 --> 00:01:58.350
by encouraging me to follow that dream.

00:01:58.350 --> 00:02:02.850
- And your interest in
psychology and identity,

00:02:02.850 --> 00:02:06.190
did that come as an undergraduate, later,

00:02:06.190 --> 00:02:08.510
or was it something that developed

00:02:08.510 --> 00:02:10.370
when you were still at home?

00:02:10.370 --> 00:02:11.800
- I think that's so interesting,

00:02:11.800 --> 00:02:14.240
I think I was always very introspective

00:02:14.240 --> 00:02:16.560
trying to understand my family culture.

00:02:16.560 --> 00:02:21.090
I'm writing a memoir now
about growing up in Brooklyn,

00:02:21.090 --> 00:02:23.570
about my family.

00:02:23.570 --> 00:02:25.270
So I think I was very interested in

00:02:25.270 --> 00:02:27.893
my family culture and
the people around me,

00:02:28.770 --> 00:02:31.380
so probably I've always
been very introspective

00:02:34.471 --> 00:02:36.160
but I think certainly as an undergraduate,

00:02:36.160 --> 00:02:40.313
I studied with Erik Erikson,
who was about identity,

00:02:42.860 --> 00:02:44.600
I remember Erik Erikson,

00:02:44.600 --> 00:02:46.260
I remember thinking he looked like God.

00:02:46.260 --> 00:02:50.027
He had this sort of white hair, and--

00:02:50.027 --> 00:02:52.800
- And he was very
influential in that time.

00:02:52.800 --> 00:02:55.110
- Very influential.
- You're at Harvard

00:02:55.110 --> 00:02:59.430
in the '60s, or Radcliffe,
and then Harvard in the '60s.

00:02:59.430 --> 00:03:02.750
- Yes, and he used to walk
the campus with his wife,

00:03:02.750 --> 00:03:06.210
and I mean, people used to
say, look, Mr. and Mrs. God,

00:03:06.210 --> 00:03:09.120
I mean he really had that aura.

00:03:09.120 --> 00:03:12.870
And he taught a course on
identity in the life cycle

00:03:12.870 --> 00:03:16.730
and I sat in on that
course for three years

00:03:16.730 --> 00:03:21.360
just listening to him talk about
identity in the life cycle.

00:03:21.360 --> 00:03:25.380
- And we'll talk about some
of your books in a minute,

00:03:25.380 --> 00:03:30.380
but they're written with great clarity,

00:03:30.730 --> 00:03:32.223
and writing skill,

00:03:34.519 --> 00:03:39.519
when did this concern,
focus, and craft writing,

00:03:40.780 --> 00:03:44.080
come to you, over time,
did you develop that

00:03:44.080 --> 00:03:46.960
in high school and in college?

00:03:46.960 --> 00:03:49.330
- I was the editor of my,
but probably I should've

00:03:49.330 --> 00:03:51.180
answered your question about identity

00:03:52.130 --> 00:03:55.163
by talking about being editor
of my high school newspaper.

00:03:56.100 --> 00:03:58.930
I think I saw myself as a writer,

00:03:58.930 --> 00:04:01.960
in high school, before I
saw myself as an academic,

00:04:01.960 --> 00:04:05.370
or knew anything about being an academic,

00:04:05.370 --> 00:04:08.250
I think that I was confirmed an idea

00:04:08.250 --> 00:04:11.800
that I would be a writer in high school.

00:04:11.800 --> 00:04:13.960
Because I just, it was the thing I loved.

00:04:13.960 --> 00:04:18.960
I mean, I just, I didn't know
that women could be academics.

00:04:19.160 --> 00:04:22.340
Even in college, there were
really no tenured professors

00:04:22.340 --> 00:04:24.640
at Harvard, I went to Radcliffe,

00:04:24.640 --> 00:04:27.450
which you studied with
the Harvard faculty,

00:04:27.450 --> 00:04:30.210
there were no tenured women
on the Harvard faculty.

00:04:30.210 --> 00:04:33.120
I never had a woman as a professor

00:04:33.120 --> 00:04:35.110
the whole time I was there.

00:04:35.110 --> 00:04:38.333
I'm not sure I knew that
that was a day job for girls.

00:04:39.794 --> 00:04:41.720
But I knew that there were women writers,

00:04:41.720 --> 00:04:44.270
and I think I saw myself as a writer

00:04:44.270 --> 00:04:46.580
before I thought of myself as an academic.

00:04:46.580 --> 00:04:50.450
So the idea that I
would work on my writing

00:04:50.450 --> 00:04:53.440
and craft my writing,
and rewrite, and rewrite,

00:04:53.440 --> 00:04:57.010
is certainly something that
from the very beginning

00:04:57.010 --> 00:04:58.260
was of interest to me.

00:04:58.260 --> 00:05:01.800
And I really do, when people say,

00:05:01.800 --> 00:05:05.822
when my students say to me,
oh, you're such a good writer,

00:05:05.822 --> 00:05:09.040
I always say to them, well,
you're reading the 30th draft.

00:05:09.040 --> 00:05:12.570
So writing is editing,
and I try to teach that to

00:05:12.570 --> 00:05:15.440
my students that that's the trick.

00:05:15.440 --> 00:05:20.440
- So was it an easy journey
from Brooklyn to Radcliffe?

00:05:20.850 --> 00:05:22.158
- No, no!

00:05:22.158 --> 00:05:24.207
(both laughing)

00:05:24.207 --> 00:05:27.263
No, I went to a high
school where my guidance,

00:05:29.066 --> 00:05:32.600
where no one from my high school
went to Ivy League schools,

00:05:32.600 --> 00:05:33.793
it was very unusual.

00:05:35.110 --> 00:05:38.790
I was told that to do that, you
had to be the valedictorian.

00:05:38.790 --> 00:05:41.900
And so that was very hard
to be the valedictorian,

00:05:41.900 --> 00:05:45.250
I think there were 1500 people
in the graduating class,

00:05:45.250 --> 00:05:47.590
so it was a job.

00:05:47.590 --> 00:05:52.350
And I was valedictorian, I
was very fortunate, and I--

00:05:52.350 --> 00:05:53.570
- In high school.
- In high school, right.

00:05:53.570 --> 00:05:56.893
I got to go, but it was actually quite,

00:05:57.780 --> 00:06:02.700
it was really a job to
get that accomplished.

00:06:02.700 --> 00:06:06.370
But I was, you know, I'm
sure I would've got in

00:06:06.370 --> 00:06:08.220
to a good school if I'd been number two,

00:06:08.220 --> 00:06:09.490
or three, or four, or five,

00:06:09.490 --> 00:06:14.490
but it was actually,
it was actually a task.

00:06:15.280 --> 00:06:18.560
- Besides Erikson, who were your mentors

00:06:18.560 --> 00:06:22.513
or your great influencers in
your undergraduate education?

00:06:23.600 --> 00:06:26.900
- Barrington Moore, who
was a great Marxist.

00:06:26.900 --> 00:06:31.900
Stanley Hoffmann, who ignited my study

00:06:32.320 --> 00:06:34.450
of France and French intellectual life,

00:06:34.450 --> 00:06:36.450
which I wrote my first book on France

00:06:36.450 --> 00:06:38.500
and that was very influenced

00:06:38.500 --> 00:06:41.680
by studying with Stanley Hoffmann.

00:06:41.680 --> 00:06:45.920
Laurence Wylie, another
scholar of French life.

00:06:45.920 --> 00:06:49.840
George Homans, a sociologist at Harvard

00:06:49.840 --> 00:06:51.390
who was very important to me.

00:06:51.390 --> 00:06:54.340
Marty Peretz, who was the chairman

00:06:54.340 --> 00:06:55.670
of the social studies department,

00:06:55.670 --> 00:06:57.480
which was my undergraduate major.

00:06:57.480 --> 00:06:59.550
I had many mentors, I was very fortunate,

00:06:59.550 --> 00:07:00.870
I really had many...

00:07:03.390 --> 00:07:08.343
David Riesman, a student
of American culture.

00:07:09.360 --> 00:07:11.760
There was a lot of, I was
very fortunate in that

00:07:12.840 --> 00:07:17.370
I was at Harvard at a time when...

00:07:23.130 --> 00:07:26.260
There was a lot of political ferment

00:07:26.260 --> 00:07:30.680
but also a lot of tension
paid to undergraduate teaching

00:07:30.680 --> 00:07:32.463
and to undergraduate majors.

00:07:33.960 --> 00:07:37.283
I had a great undergraduate
experience, I really did.

00:07:39.327 --> 00:07:41.100
I was very, very fortunate.

00:07:41.100 --> 00:07:43.090
- Was it the times that

00:07:44.880 --> 00:07:48.010
made you so voracious a student,

00:07:48.010 --> 00:07:51.160
or was it something that
came from your background?

00:07:51.160 --> 00:07:53.890
- Well, you know, I went there ready to,

00:07:57.346 --> 00:07:59.725
I mean, I went there ready to learn.

00:07:59.725 --> 00:08:00.770
(both laugh)

00:08:00.770 --> 00:08:03.220
- Absorb--
- I was like, I'm here,

00:08:03.220 --> 00:08:07.250
you know, so I mean I wanna
give myself full credit

00:08:07.250 --> 00:08:09.103
that I kinda got there ready to go.

00:08:10.200 --> 00:08:12.010
But I think it was also the times.

00:08:12.010 --> 00:08:15.810
I mean I think that it
was very political times,

00:08:15.810 --> 00:08:19.770
so I wanted to, you know,
Marx, Weber, Durkheim, Freud,

00:08:19.770 --> 00:08:23.840
I mean, everything was relevant
to thinking about politics,

00:08:23.840 --> 00:08:28.840
to thinking about how
did people absorb ideas,

00:08:29.150 --> 00:08:31.550
what ideas were important,
what ideas could help you

00:08:31.550 --> 00:08:33.333
think through American culture?

00:08:35.992 --> 00:08:40.367
You know, the world, I
was lit to understand

00:08:42.197 --> 00:08:45.693
what was happening, and I
didn't understand anything.

00:08:47.484 --> 00:08:50.163
And people felt that great ideas,

00:08:51.150 --> 00:08:53.230
I think this is perhaps
the difference from now

00:08:53.230 --> 00:08:57.690
is that people around me felt that history

00:08:57.690 --> 00:09:02.560
would help me understand
what was happening.

00:09:02.560 --> 00:09:03.850
- And that ideas mattered.

00:09:03.850 --> 00:09:05.320
- And that ideas mattered.

00:09:05.320 --> 00:09:08.710
And I'm not sure that now,

00:09:08.710 --> 00:09:11.600
when people try to understand
our current dilemma,

00:09:11.600 --> 00:09:14.109
people wanna go to Marx,
Weber, Durkheim, Freud,

00:09:14.109 --> 00:09:17.260
I mean, I was in a group of people

00:09:17.260 --> 00:09:19.740
where that was the first
thing that occurred to us

00:09:19.740 --> 00:09:22.130
was to try to understand our dilemma

00:09:22.130 --> 00:09:25.990
by going to history, by going
to sociology to create ideas.

00:09:25.990 --> 00:09:28.170
- You then went to France,

00:09:28.170 --> 00:09:29.003
now, was this--
- Yes.

00:09:29.003 --> 00:09:30.210
- Before you graduated?

00:09:30.210 --> 00:09:33.290
- Yes, it was an interesting
convergence of things.

00:09:33.290 --> 00:09:34.930
I had a personal difficulty,

00:09:34.930 --> 00:09:37.180
my mom died when I was in college.

00:09:37.180 --> 00:09:40.903
My mother died, and I was in no state.

00:09:43.228 --> 00:09:45.430
I couldn't study, I couldn't work,

00:09:45.430 --> 00:09:47.843
I needed to take a break.

00:09:49.630 --> 00:09:52.640
I had been studying French
politics and society

00:09:52.640 --> 00:09:55.550
and I went to France, I
dropped out of school,

00:09:55.550 --> 00:09:58.713
I worked as a cleaning lady in France.

00:10:02.275 --> 00:10:03.693
And I went to Sciences Po,

00:10:04.670 --> 00:10:07.393
so I was a kind of cleaning lady student.

00:10:13.150 --> 00:10:17.880
While there, I was there
just after the May Days,

00:10:17.880 --> 00:10:20.320
and I observed something
that would turn out

00:10:20.320 --> 00:10:22.370
to be quite fateful for my later work,

00:10:22.370 --> 00:10:26.630
I observed that people who had
been active in the May Days

00:10:26.630 --> 00:10:30.470
were starting to kind of converge towards

00:10:31.470 --> 00:10:33.200
getting interested in psychoanalysis,

00:10:33.200 --> 00:10:35.500
but not any psychoanalysis,

00:10:35.500 --> 00:10:37.300
the psychoanalysis of Jacques Lacan,

00:10:38.140 --> 00:10:40.180
which was kind of unusual
because in America

00:10:40.180 --> 00:10:41.960
the people who were interested in politics

00:10:41.960 --> 00:10:46.960
did not kind of trend
towards the psychoanalysis,

00:10:48.600 --> 00:10:51.350
on the contrary, people who
were interested in politics

00:10:52.370 --> 00:10:54.300
thought that psychoanalytic things

00:10:54.300 --> 00:10:56.330
was kind of moving away from politics

00:10:56.330 --> 00:10:57.560
towards an interest in the self,

00:10:57.560 --> 00:11:00.520
those two trends were very different.

00:11:00.520 --> 00:11:02.350
Because I was interested in Freud,

00:11:02.350 --> 00:11:04.460
and that was a very different track

00:11:04.460 --> 00:11:05.600
than being interested in politics.

00:11:05.600 --> 00:11:07.350
- And what was different about it?

00:11:07.350 --> 00:11:09.170
- Well, that was the question for me,

00:11:09.170 --> 00:11:11.020
what was there about Jacques Lacan,

00:11:11.020 --> 00:11:12.630
and his brand of psychoanalysis,

00:11:12.630 --> 00:11:16.290
that people felt that moving
from politics to psychoanalysis

00:11:16.290 --> 00:11:18.030
was kind of doing the same thing.

00:11:18.030 --> 00:11:22.880
And that question, what was
this politically acceptable

00:11:22.880 --> 00:11:26.520
psychoanalysis became the
theme of my first book

00:11:26.520 --> 00:11:31.150
because then, when I came back to Harvard

00:11:31.150 --> 00:11:35.450
to do a PhD in sociology and psychology,

00:11:35.450 --> 00:11:40.430
the subject of my dissertation
was psychoanalytic politics,

00:11:40.430 --> 00:11:44.650
became my first book
which was really what was

00:11:44.650 --> 00:11:48.030
the mystery, this intellectual
history of mystery

00:11:48.030 --> 00:11:51.520
of what was there about
the Lacanian movement

00:11:51.520 --> 00:11:53.510
that had made this slippage

00:11:53.510 --> 00:11:56.070
from politics to psychoanalysis possible,

00:11:56.070 --> 00:11:58.660
what was this infatuation with Freud

00:11:59.610 --> 00:12:03.840
that had made this a kind
of political psychoanalysis.

00:12:03.840 --> 00:12:08.840
- And did that slippage
make politics interesting,

00:12:10.610 --> 00:12:15.370
and did it offer explanatory
power for these mass movements?

00:12:15.370 --> 00:12:20.370
- Well, it offered a political
language for psychoanalysis,

00:12:20.540 --> 00:12:23.033
the communist party became
interested in Lacan,

00:12:23.999 --> 00:12:28.110
it offered a political
language to psychoanalysis

00:12:28.110 --> 00:12:31.493
and it offered a way to make,

00:12:32.730 --> 00:12:36.303
to think about politics
in a psychological way.

00:12:39.150 --> 00:12:42.950
You know, I think it...

00:12:44.440 --> 00:12:48.700
I think people sensed
that it wasn't the moment

00:12:48.700 --> 00:12:50.680
for a political revolution in France

00:12:50.680 --> 00:12:54.113
and they wanted to
continue to think about,

00:12:55.380 --> 00:12:59.700
they wanted a way to think about the self

00:12:59.700 --> 00:13:02.510
in a way that was politicized.

00:13:02.510 --> 00:13:05.403
And the Lacanian movement provided that.

00:13:06.320 --> 00:13:11.010
And it was a very interesting time,

00:13:11.010 --> 00:13:12.810
and I interviewed psychoanalysts,

00:13:12.810 --> 00:13:14.730
I interviewed political people,

00:13:14.730 --> 00:13:17.407
but what really was
very fascinating for me

00:13:17.407 --> 00:13:21.160
and that then provided a
transition to my later work

00:13:21.160 --> 00:13:26.160
is I became interested in the idea of

00:13:26.420 --> 00:13:28.300
not the psychoanalytic movement,

00:13:28.300 --> 00:13:30.440
but the psychoanalytic culture.

00:13:30.440 --> 00:13:33.540
That is to say, what happens
to psychoanalytic ideas

00:13:33.540 --> 00:13:35.030
when they sort of hit the street

00:13:35.030 --> 00:13:38.780
and they're no longer the
ideas of the intelligentsia

00:13:38.780 --> 00:13:41.240
but they're the ideas that people use

00:13:41.240 --> 00:13:42.813
really in everyday life.

00:13:44.659 --> 00:13:47.240
You know, what happens to ideas not

00:13:47.240 --> 00:13:49.870
as they're elaborated by intellectuals

00:13:49.870 --> 00:13:52.740
but as they're brought into
people's sort of everyday lives.

00:13:52.740 --> 00:13:54.380
And that became important to me

00:13:54.380 --> 00:13:57.253
because when I began to study
artificial intelligence,

00:14:00.210 --> 00:14:02.530
I wasn't interested in these ideas

00:14:02.530 --> 00:14:05.330
as they were developed in seminar rooms,

00:14:05.330 --> 00:14:08.230
but as they came down and hit the street

00:14:08.230 --> 00:14:11.980
when people began to
use ideas from computers

00:14:13.020 --> 00:14:17.070
to talk about their own minds
and their children's minds,

00:14:17.070 --> 00:14:20.080
you know, kind of as
ideas from computation

00:14:20.080 --> 00:14:21.990
became embedded in everyday life,

00:14:21.990 --> 00:14:24.023
when people had personal computers.

00:14:25.580 --> 00:14:30.580
So that notion of a
sociology of sciences of mind

00:14:31.000 --> 00:14:33.400
as we pick it up in everyday life

00:14:34.480 --> 00:14:37.493
really became my academic,

00:14:38.540 --> 00:14:42.590
kind of my academic identity.

00:14:42.590 --> 00:14:45.750
And so there was a kind of,
even though the topics changed

00:14:45.750 --> 00:14:48.610
from psychoanalysis to computer culture,

00:14:48.610 --> 00:14:50.903
that sort of became my thing.

00:14:52.190 --> 00:14:56.310
- You are a sociologist, a psychologist,

00:14:56.310 --> 00:15:01.180
that winds up sorta
focusing on the cyber world.

00:15:01.180 --> 00:15:03.690
- Yes.
- And what it's doing to us.

00:15:03.690 --> 00:15:06.410
I like to ask my guests about

00:15:07.889 --> 00:15:12.470
the skillset and the temperament

00:15:12.470 --> 00:15:16.223
that is at the heart of their work.

00:15:17.720 --> 00:15:21.640
With the possibility of, you know,

00:15:21.640 --> 00:15:25.810
advising students about how they prepare

00:15:25.810 --> 00:15:27.890
for their own future.

00:15:27.890 --> 00:15:32.283
- Well, what I would say
is that when I started out,

00:15:33.690 --> 00:15:36.350
I'd looked like I was very confused

00:15:36.350 --> 00:15:39.970
because I needed to learn

00:15:39.970 --> 00:15:42.070
how to be a sociologist,

00:15:42.070 --> 00:15:47.070
because I needed to learn about
Durkheim and Weber and Marx

00:15:47.240 --> 00:15:49.900
and how to think about
large social movements.

00:15:49.900 --> 00:15:54.900
But I needed, really I felt,
to learn how to be a clinician,

00:15:56.080 --> 00:15:58.950
how to learn how to do
clinical interviews,

00:15:58.950 --> 00:16:01.183
I'm trained as a psychoanalyst as well.

00:16:03.462 --> 00:16:05.213
I felt I needed a clinical degree.

00:16:06.290 --> 00:16:08.820
So I looked like somebody who

00:16:08.820 --> 00:16:11.280
was a little bit all over the place.

00:16:11.280 --> 00:16:14.560
And I felt very conflicted about that

00:16:14.560 --> 00:16:18.080
because other people were
either going to law school

00:16:18.080 --> 00:16:21.840
or they were going to getting
a degree in political science,

00:16:21.840 --> 00:16:24.600
I was jealous of them
because they looked so,

00:16:24.600 --> 00:16:29.010
they looked so, I don't
know, so organized.

00:16:29.010 --> 00:16:32.110
And I went to Chicago to the
Committee on Social Thought

00:16:32.110 --> 00:16:34.610
and then I went to Harvard
and I got a sociology degree,

00:16:34.610 --> 00:16:36.770
and then I said no, I also
need a clinical degree,

00:16:36.770 --> 00:16:39.590
I mean, I just, I got a joint degree

00:16:39.590 --> 00:16:42.060
in personality psychology and sociology

00:16:42.060 --> 00:16:43.920
and then I got clinical accreditation

00:16:43.920 --> 00:16:47.673
and I mean, I did a
lot of degrees (laughs)

00:16:47.673 --> 00:16:49.070
I did a lot of things.

00:16:49.070 --> 00:16:51.260
So I think that my advice would be

00:16:51.260 --> 00:16:54.640
I needed, I just needed
these different skillsets

00:16:54.640 --> 00:16:57.673
and I just got these different skillsets.

00:16:59.230 --> 00:17:03.000
And I just did to get
them one after another

00:17:03.000 --> 00:17:04.610
and I just would say to students

00:17:04.610 --> 00:17:08.513
who feel that they need
a couple of skillsets,

00:17:10.020 --> 00:17:14.200
relax, you know, you're
gonna feel a little,

00:17:14.200 --> 00:17:19.000
you may feel a little greedy,
or a little disorganized,

00:17:19.000 --> 00:17:23.460
and you'll be jealous of
people who seem more organized.

00:17:23.460 --> 00:17:26.090
But if you feel that your
intellectual identity

00:17:26.090 --> 00:17:30.340
depends on getting these
different skillsets,

00:17:30.340 --> 00:17:31.930
if you can afford it, you know,

00:17:31.930 --> 00:17:35.403
I had to work jobs, and it
took me a little longer,

00:17:37.630 --> 00:17:40.680
you know, just put one
foot in front of the other.

00:17:40.680 --> 00:17:43.870
And so I sort of am glad
you asked me this question

00:17:43.870 --> 00:17:47.428
because I think that actually I did feel,

00:17:47.428 --> 00:17:48.261
I don't wanna say I felt guilty

00:17:48.261 --> 00:17:51.070
but I felt bad about myself because other,

00:17:51.070 --> 00:17:54.100
I felt envious of other people

00:17:54.100 --> 00:17:58.320
who seemed more, you know, organized.

00:17:58.320 --> 00:18:00.230
- And I wanna just ask you,

00:18:00.230 --> 00:18:04.230
did you know where you were
going with all of this,

00:18:04.230 --> 00:18:07.690
or was it just that you were excited

00:18:07.690 --> 00:18:09.193
about what you could learn?

00:18:12.125 --> 00:18:14.470
- I knew that I needed,

00:18:14.470 --> 00:18:18.543
I had this idea of this
intimate ethnography,

00:18:19.560 --> 00:18:21.440
that's how I thought about it.

00:18:21.440 --> 00:18:25.090
That I wanted to do, it seemed
to me that I wanted to do

00:18:25.090 --> 00:18:28.510
a kind of ethnographic work,

00:18:28.510 --> 00:18:30.040
where you interviewed people,

00:18:30.040 --> 00:18:33.830
and you were on the ground in
a kind of ethnographic setting

00:18:33.830 --> 00:18:37.960
but it seemed to me the kind
of interviewing I wanted to do,

00:18:37.960 --> 00:18:39.700
to ask somebody for example

00:18:39.700 --> 00:18:41.920
about why they were in psychoanalysis

00:18:41.920 --> 00:18:45.113
when they had just been
in political action.

00:18:46.180 --> 00:18:49.000
That the kind of interview that required

00:18:49.000 --> 00:18:50.653
was actually quite intimate.

00:18:52.390 --> 00:18:55.940
I mean, the questions were not like,

00:18:55.940 --> 00:18:57.390
you know, with your microphone,

00:18:57.390 --> 00:19:02.220
you know, it was a very
intimate interview, because...

00:19:06.312 --> 00:19:07.900
You know, asking why they
were in psychoanalysis,

00:19:07.900 --> 00:19:09.980
I mean, that took a long time,

00:19:09.980 --> 00:19:13.041
you couldn't ask it directly,
you had to befriend them,

00:19:13.041 --> 00:19:14.770
they had to trust you.

00:19:14.770 --> 00:19:16.770
You know, they were maybe gonna tell you

00:19:17.850 --> 00:19:20.650
very intimate things and
there would be talking

00:19:20.650 --> 00:19:23.120
about the failure of
this political movement

00:19:23.120 --> 00:19:25.030
and how they felt about that,

00:19:25.030 --> 00:19:26.820
but now they were in psychoanalysis

00:19:26.820 --> 00:19:28.750
and they weren't gonna say
they were in psychoanalysis

00:19:28.750 --> 00:19:30.880
'cause the political movement failed,

00:19:30.880 --> 00:19:35.263
I mean, it was gonna be a
very, you needed skills.

00:19:36.650 --> 00:19:40.723
And I saw that I didn't have those skills.

00:19:42.140 --> 00:19:44.110
So to get better at that kind of thing

00:19:44.110 --> 00:19:48.113
I needed to really develop skills.

00:19:50.078 --> 00:19:52.640
And the more clinical skills I had,

00:19:52.640 --> 00:19:54.053
the better I got at it.

00:19:56.450 --> 00:20:01.450
So, I felt that I needed to
really work on clinical skills.

00:20:03.360 --> 00:20:08.360
And I developed this notion in my mind

00:20:08.680 --> 00:20:12.053
of intimate ethnography
with clinical skills.

00:20:13.000 --> 00:20:16.093
And so that, I would say
that was my guiding idea.

00:20:17.400 --> 00:20:20.290
And once I had that guiding idea,

00:20:20.290 --> 00:20:23.790
well, things fell into place.

00:20:23.790 --> 00:20:26.423
- When you look at your works,

00:20:30.130 --> 00:20:32.140
two things stand out for me.

00:20:32.140 --> 00:20:35.780
Not the only two things, but
a way to approach your work.

00:20:35.780 --> 00:20:39.110
One is what you chose to study,

00:20:39.110 --> 00:20:41.020
and we'll talk about that in a minute,

00:20:41.020 --> 00:20:45.760
but the other is your
philosophical perspective

00:20:45.760 --> 00:20:50.760
and that seems to be focused on

00:20:50.960 --> 00:20:54.390
what makes us human, our humanness,

00:20:54.390 --> 00:20:58.200
talk a little about that,
does that emerge out of this

00:20:58.200 --> 00:21:00.173
extraordinary education?

00:21:01.950 --> 00:21:06.893
Does it inform our understanding
of what it is you're doing?

00:21:09.310 --> 00:21:14.310
- Well, I think that my
concern about the human

00:21:15.520 --> 00:21:20.520
really has come out of my study of

00:21:20.650 --> 00:21:25.483
computer culture, working with people who

00:21:27.440 --> 00:21:31.653
are so often saying that
we don't need to be human.

00:21:32.530 --> 00:21:33.763
I mean, (laughing) I remember,

00:21:36.291 --> 00:21:38.950
I'm just writing a memoir now

00:21:38.950 --> 00:21:43.740
and in my work, I have
already cited this story

00:21:45.997 --> 00:21:49.970
of Marvin Minsky, and
going with Marvin Minsky

00:21:49.970 --> 00:21:51.550
to a showing of the movie Tron,

00:21:51.550 --> 00:21:54.910
Marvin Minsky is a great AI,
artificial intelligence, hero.

00:21:54.910 --> 00:21:57.690
- Is this the same Minsky
who was an economist?

00:21:57.690 --> 00:22:01.100
- No, he's an artificial
intelligence guru.

00:22:01.100 --> 00:22:01.933
- Okay.
- He's one of

00:22:01.933 --> 00:22:03.670
the founders of artificial intelligence

00:22:04.750 --> 00:22:07.090
and together we see the movie Tron,

00:22:07.090 --> 00:22:11.090
which is a movie about the brain

00:22:11.090 --> 00:22:15.280
and how the brain is made
up of a society of programs

00:22:15.280 --> 00:22:18.220
and it's a very AI movie.

00:22:18.220 --> 00:22:20.170
And we come out of the movie,

00:22:20.170 --> 00:22:21.930
and of course Minsky's very excited

00:22:21.930 --> 00:22:23.510
and we're there with all of his students

00:22:23.510 --> 00:22:25.860
and we're all talking about his movie

00:22:25.860 --> 00:22:28.400
as kind of an embodiment of his idea,

00:22:28.400 --> 00:22:30.457
his idea's called the society of mind,

00:22:30.457 --> 00:22:33.660
and the mind is made up
of embodied programs.

00:22:33.660 --> 00:22:36.350
And Marvin and I get into a conversation

00:22:36.350 --> 00:22:39.700
and he says, you know,

00:22:39.700 --> 00:22:41.750
no children should see them,

00:22:41.750 --> 00:22:43.480
all children should see this movie

00:22:43.480 --> 00:22:47.210
'cause it teaches how the
mind is made up of programs,

00:22:47.210 --> 00:22:50.150
no children, children
should see this movie

00:22:50.150 --> 00:22:52.999
and they shouldn't see the movie Bambi.

00:22:52.999 --> 00:22:56.160
(Harry laughs)

00:22:56.160 --> 00:23:00.490
And I said, you know, I love Bambi,

00:23:00.490 --> 00:23:02.860
why shouldn't they see Bambi?

00:23:02.860 --> 00:23:06.240
Because Bambi teaches that
you attach to a mother

00:23:07.250 --> 00:23:12.020
and in the future, we're all
gonna be embodied in computers

00:23:12.020 --> 00:23:13.650
and there should be no attachment,

00:23:13.650 --> 00:23:15.290
we're never gonna die 'cause we're gonna

00:23:15.290 --> 00:23:17.800
embody ourselves in computers,

00:23:17.800 --> 00:23:20.280
it's the wrong message

00:23:20.280 --> 00:23:22.640
because we shouldn't
be teaching about death

00:23:22.640 --> 00:23:26.700
and we're not gonna die, we're
just gonna become computers,

00:23:26.700 --> 00:23:28.700
there should be no attachment to mothers

00:23:28.700 --> 00:23:31.720
and he's off on this
we're not gonna be human,

00:23:31.720 --> 00:23:33.520
we're gonna be embodied in computer.

00:23:35.850 --> 00:23:37.890
This is MIT, this is my lot.

00:23:37.890 --> 00:23:41.163
So I think that I became like, very,

00:23:42.520 --> 00:23:44.980
are you kidding me, no mothers,

00:23:44.980 --> 00:23:46.470
we're gonna go into computers?

00:23:46.470 --> 00:23:48.900
You know, it's like (laughs) I became like

00:23:48.900 --> 00:23:50.870
very team human, you know?

00:23:50.870 --> 00:23:54.530
Kind of surrounded by people who

00:23:54.530 --> 00:23:57.930
either we were gonna graduate
and become computers,

00:23:57.930 --> 00:24:00.400
we're gonna become embodied in computers,

00:24:00.400 --> 00:24:04.760
we're gonna become linked to computers.

00:24:04.760 --> 00:24:07.780
So I think that I became,
and then one of his students

00:24:07.780 --> 00:24:10.230
told me that Minsky wanted,

00:24:10.230 --> 00:24:11.770
I was interviewing this student

00:24:11.770 --> 00:24:14.590
and the student said, well,
Minsky wants to create

00:24:14.590 --> 00:24:17.660
a computer that a soul
would wanna live in.

00:24:17.660 --> 00:24:21.780
I mean, I was surrounded by a culture

00:24:23.050 --> 00:24:26.500
where we were either gonna marry computers

00:24:26.500 --> 00:24:30.160
or graduate, evolve into computers,

00:24:30.160 --> 00:24:33.970
so I think that I very
early in my time at MIT

00:24:33.970 --> 00:24:35.520
started to think about, well,

00:24:35.520 --> 00:24:38.463
what was essential about being human?

00:24:40.210 --> 00:24:44.600
And I think that that
became, as I began to study

00:24:46.110 --> 00:24:49.180
children in computers, smart machines,

00:24:49.180 --> 00:24:51.530
children responding to smart machines.

00:24:51.530 --> 00:24:55.300
The question of what was
essential about being human

00:24:55.300 --> 00:24:59.600
became something that
was just like in my face

00:24:59.600 --> 00:25:01.240
to start thinking about.

00:25:01.240 --> 00:25:05.850
So it wasn't like I went
into it with this as my,

00:25:05.850 --> 00:25:08.640
I wasn't particularly
trained as a philosopher,

00:25:08.640 --> 00:25:11.293
I mean, I'm totally out
of my depth actually.

00:25:12.740 --> 00:25:16.420
It wasn't like my philosophical,

00:25:16.420 --> 00:25:18.970
it wasn't where I came
from, philosophically.

00:25:18.970 --> 00:25:21.573
But very early on in my,

00:25:22.790 --> 00:25:25.030
and literally on the
ground what I was studying

00:25:25.030 --> 00:25:27.740
these children talking
about what was special

00:25:27.740 --> 00:25:31.120
about being human, it's what
I started to think about.

00:25:31.120 --> 00:25:34.570
Surrounded by these people
who couldn't tolerate

00:25:34.570 --> 00:25:36.900
the movie Bambi 'cause
it was too sentimental

00:25:36.900 --> 00:25:38.870
about humanity.

00:25:38.870 --> 00:25:41.560
- How did you wind up at MIT,

00:25:41.560 --> 00:25:46.008
was that a choice about
studying this cyber--

00:25:46.008 --> 00:25:48.890
- No, no no no, no,

00:25:48.890 --> 00:25:50.483
I was in Cambridge,

00:25:53.140 --> 00:25:55.810
I was writing, no, it
was totally an accident.

00:25:55.810 --> 00:26:00.050
I was in Cambridge, and I
wanted to turn my dissertation,

00:26:00.050 --> 00:26:03.670
I had written my French Freud dissertation

00:26:03.670 --> 00:26:06.410
and it was, the dissertation was done,

00:26:06.410 --> 00:26:08.450
but I wanted to turn it into a book

00:26:08.450 --> 00:26:10.390
and so I really wasn't ready to take

00:26:11.272 --> 00:26:13.240
an assistant professorship job.

00:26:13.240 --> 00:26:15.050
And MIT offered me

00:26:19.305 --> 00:26:20.200
a kind of year,

00:26:23.160 --> 00:26:25.020
what was like a research fellowship

00:26:25.020 --> 00:26:27.340
and they said we have
this research fellowship

00:26:27.340 --> 00:26:31.699
in this new program called
Science, Technology, and Society.

00:26:31.699 --> 00:26:33.040
And at the end of the year,

00:26:33.040 --> 00:26:34.460
if you wanna be an assistant professor,

00:26:34.460 --> 00:26:37.030
there's a job for you in this new program.

00:26:37.030 --> 00:26:40.230
But for the year, there's no teaching,

00:26:40.230 --> 00:26:44.540
you just have to turn your
dissertation into a book.

00:26:44.540 --> 00:26:47.340
And I thought, well that's a great,

00:26:47.340 --> 00:26:51.580
you know, that's a great
deal, just by accident,

00:26:51.580 --> 00:26:54.610
but I hadn't, computers
were 100% not on my mind

00:26:54.610 --> 00:26:58.360
I just wanted to turn my
dissertation on Jacques Lacan

00:26:58.360 --> 00:26:59.830
into a book.

00:26:59.830 --> 00:27:04.830
But when I was there, I
discovered the world of computer,

00:27:07.240 --> 00:27:10.780
I mean, just like, it was all around me.

00:27:10.780 --> 00:27:15.780
And I saw the, I don't
wanna say the similarities

00:27:16.070 --> 00:27:17.713
'cause that's not strong enough.

00:27:18.870 --> 00:27:23.870
The analogy between artificial
intelligence, psychoanalysis,

00:27:24.600 --> 00:27:26.730
the science of mind that was now

00:27:26.730 --> 00:27:28.660
coming into the popular culture

00:27:30.380 --> 00:27:32.660
carried by an object.

00:27:32.660 --> 00:27:34.420
The difference between psychoanalysis

00:27:34.420 --> 00:27:37.450
and artificial intelligence
was very dramatic

00:27:37.450 --> 00:27:41.170
because psychoanalysis is
carried into the popular culture

00:27:41.170 --> 00:27:43.920
by writings or dreams, I mean,

00:27:43.920 --> 00:27:46.250
I argue that they're objects

00:27:46.250 --> 00:27:49.490
that carry psychoanalysis
into popular culture.

00:27:49.490 --> 00:27:51.700
The fact that we talk about our dreams

00:27:51.700 --> 00:27:53.340
using a psychoanalytic language

00:27:53.340 --> 00:27:56.220
is a way that it's carried
into popular culture.

00:27:56.220 --> 00:27:59.000
But the computer stuff was being carried

00:27:59.000 --> 00:28:03.080
into popular culture by this new object,

00:28:03.080 --> 00:28:06.190
the computer language being
carried into popular culture

00:28:06.190 --> 00:28:10.340
by this new object, and I came to MIT

00:28:10.340 --> 00:28:13.270
just at the moment when personal computers

00:28:13.270 --> 00:28:15.470
were starting to be in popular culture.

00:28:15.470 --> 00:28:19.923
Literally 1976 was the year of
the first personal computers.

00:28:21.175 --> 00:28:24.293
And I just lucked out.

00:28:25.170 --> 00:28:26.910
I shouldn't say I lucked out,

00:28:26.910 --> 00:28:28.700
because I mean, I had to see it.

00:28:28.700 --> 00:28:33.100
I mean, I had to you know, I saw it.

00:28:33.100 --> 00:28:34.053
I saw it.

00:28:35.600 --> 00:28:37.230
I just saw it.

00:28:37.230 --> 00:28:40.410
- Explain this a little more about the,

00:28:40.410 --> 00:28:45.410
in other words, computers
were an object to study.

00:28:46.940 --> 00:28:48.870
- Yes, I call it an evocative object.

00:28:48.870 --> 00:28:53.870
- Okay, and why are they important?

00:28:54.140 --> 00:28:56.600
Because they--
- They carry these new ideas,

00:28:56.600 --> 00:28:59.250
in other words, at MIT at the time,

00:28:59.250 --> 00:29:00.780
it was artificial intelligence,

00:29:00.780 --> 00:29:02.200
this new science that's thinking

00:29:02.200 --> 00:29:03.990
about the mind as a machine.

00:29:03.990 --> 00:29:07.050
There was this new kind of
thinking called cognitive science

00:29:07.050 --> 00:29:10.360
which was, again, thinking
about the mind as a machine,

00:29:10.360 --> 00:29:14.240
that the human memory could be analogized

00:29:14.240 --> 00:29:16.003
to the memory in a computer.

00:29:17.400 --> 00:29:19.170
So the birth of cognitive science,

00:29:19.170 --> 00:29:21.020
the birth of artificial intelligence,

00:29:21.020 --> 00:29:23.480
these new sciences of mind that were

00:29:23.480 --> 00:29:27.070
thinking about the mind in machine terms.

00:29:27.070 --> 00:29:30.240
And these new ways of
thinking about the mind

00:29:30.240 --> 00:29:31.860
which now we think of as so natural,

00:29:31.860 --> 00:29:33.560
we think of the mind as a machine,

00:29:35.610 --> 00:29:39.810
were now gonna be coming
into the culture, I thought,

00:29:39.810 --> 00:29:42.800
because at the same time as
they were being discussed

00:29:42.800 --> 00:29:45.113
in seminar rooms and laboratories,

00:29:46.250 --> 00:29:50.023
Texas Instruments or RadioShack,

00:29:50.930 --> 00:29:53.110
or Apple, you know not yet Apple,

00:29:53.110 --> 00:29:56.600
but the people in garages
that I was learning about

00:29:56.600 --> 00:29:59.940
were building personal computers

00:30:00.820 --> 00:30:05.080
that were gonna be starting
to come into the culture

00:30:06.310 --> 00:30:07.840
as objects.

00:30:07.840 --> 00:30:11.260
And in 1976, I could start to see that,

00:30:11.260 --> 00:30:13.630
you could start to see that
all of this was starting.

00:30:13.630 --> 00:30:18.103
'76, '77, '78, all of that
was starting to happen.

00:30:19.060 --> 00:30:24.060
- And in the beginning and
in your first book on this,

00:30:24.130 --> 00:30:28.320
you were more positive about

00:30:28.320 --> 00:30:33.320
the impact of these objects
coming into the culture.

00:30:36.250 --> 00:30:37.810
Talk a little about that,

00:30:37.810 --> 00:30:39.930
I mean, what was great about it then?

00:30:39.930 --> 00:30:41.620
- Well, because...

00:30:44.490 --> 00:30:47.940
You had a new science of mind,

00:30:47.940 --> 00:30:51.140
a new way of reflecting on the self,

00:30:51.140 --> 00:30:54.640
that was, I called the
children who were meeting

00:30:54.640 --> 00:30:56.970
computer toys for the first time,

00:30:56.970 --> 00:30:58.910
met them, and began talking,

00:30:58.910 --> 00:31:00.680
like I called them child philosophers,

00:31:00.680 --> 00:31:02.020
they started talking,

00:31:02.020 --> 00:31:06.363
these new objects provoked
thinking about the self.

00:31:07.270 --> 00:31:09.730
You know, children would
meet these new objects

00:31:09.730 --> 00:31:13.330
and they would start to talk about, well,

00:31:13.330 --> 00:31:16.273
these objects are programmed,
I wonder if I'm programmed?

00:31:17.413 --> 00:31:20.820
And they would start to reflect on, well,

00:31:20.820 --> 00:31:23.330
this is a programmed thing,
I wonder if I'm programmed,

00:31:23.330 --> 00:31:25.600
and they would start to talk about

00:31:25.600 --> 00:31:27.750
the nature of being programmed.

00:31:27.750 --> 00:31:28.647
And I'm not exaggerating, I mean,

00:31:28.647 --> 00:31:31.290
they were just like anybody would

00:31:31.290 --> 00:31:32.810
if they said, well, this
thing is programmed,

00:31:32.810 --> 00:31:33.960
I wonder if I'm programmed,

00:31:33.960 --> 00:31:38.823
or they would start to really talk about,

00:31:40.730 --> 00:31:43.320
and also you have to remember
that in the early days,

00:31:43.320 --> 00:31:44.880
children programmed computers,

00:31:44.880 --> 00:31:47.710
you couldn't work these computers
unless you programmed them

00:31:47.710 --> 00:31:50.570
so all children were programmers.

00:31:50.570 --> 00:31:53.110
So my first book on these objects,

00:31:53.110 --> 00:31:55.990
there are chapters and
chapters on child programmers

00:31:55.990 --> 00:31:57.820
because when children met these computers

00:31:57.820 --> 00:31:59.910
the only, you couldn't
work with the computers

00:31:59.910 --> 00:32:02.220
unless you programmed the computers.

00:32:02.220 --> 00:32:06.190
So no computers came with
stuff to do with them

00:32:06.190 --> 00:32:07.630
unless you programmed them.

00:32:07.630 --> 00:32:11.720
So everybody who had a
computer programmed a computer.

00:32:11.720 --> 00:32:14.470
So the things you did with computers

00:32:14.470 --> 00:32:17.520
involved your learning
to think like a computer

00:32:17.520 --> 00:32:20.060
and your getting involved
in computational thinking,

00:32:20.060 --> 00:32:23.370
and so it was like watching people learn

00:32:24.320 --> 00:32:26.330
a new way of thinking about, well,

00:32:26.330 --> 00:32:27.890
maybe the mind works like that,

00:32:27.890 --> 00:32:30.280
I wonder what it is to
think like a computer,

00:32:30.280 --> 00:32:32.610
I wonder if I think like a computer,

00:32:32.610 --> 00:32:36.340
I wonder if people have
always thought like computers,

00:32:36.340 --> 00:32:38.210
or what is it to think like a computer?

00:32:38.210 --> 00:32:43.210
So I was very positive about
the kinds of conversations

00:32:43.560 --> 00:32:46.350
about mind

00:32:46.350 --> 00:32:47.780
that were happening in the culture

00:32:47.780 --> 00:32:50.750
just as I had been very excited about,

00:32:50.750 --> 00:32:53.510
I wasn't particularly for or against them,

00:32:53.510 --> 00:32:55.550
that's not my place, but just as I'd been

00:32:55.550 --> 00:32:58.400
very excited about the kinds
of conversations about mind

00:32:58.400 --> 00:33:00.290
that were happening in France,

00:33:00.290 --> 00:33:05.290
when people were dialoguing
about psychoanalysis

00:33:05.906 --> 00:33:07.696
as an exciting thing to watch.

00:33:07.696 --> 00:33:12.696
- So at this stage, computers were a tool

00:33:15.060 --> 00:33:18.590
that in service of the human mind--

00:33:18.590 --> 00:33:19.990
- Yes.
- And the human--

00:33:19.990 --> 00:33:21.520
- It provoked thinking.
- Yeah.

00:33:21.520 --> 00:33:24.910
- And then what happened
is they became black boxed

00:33:26.140 --> 00:33:28.200
and they became...

00:33:32.310 --> 00:33:33.900
They became like games, I mean,

00:33:33.900 --> 00:33:37.920
they became closed down and they became

00:33:37.920 --> 00:33:40.980
something that you sort
of no longer were open

00:33:40.980 --> 00:33:42.580
for that kind of thinking,

00:33:42.580 --> 00:33:44.980
they became just sort of shut down and

00:33:46.510 --> 00:33:49.380
not transparent anymore, but opaque,

00:33:49.380 --> 00:33:53.140
and no longer were kind of
available to most people

00:33:53.140 --> 00:33:54.583
for that kind of reflection.

00:33:57.920 --> 00:34:02.413
The nature of what computer
culture meant changed.

00:34:04.059 --> 00:34:08.120
- So you fortunately wound up in a place

00:34:08.120 --> 00:34:11.900
where what you were surrounded by

00:34:11.900 --> 00:34:15.820
and what you came to study
was changing over time.

00:34:15.820 --> 00:34:20.070
- Yes, and what I did
was I studied that shift.

00:34:20.070 --> 00:34:24.170
I studied that shift from
transparency to opacity

00:34:25.030 --> 00:34:27.060
in the nature of these objects,

00:34:27.060 --> 00:34:32.060
and actually that was the
topic of kind of my next books,

00:34:32.280 --> 00:34:37.280
were really marking that shift
from transparency to opacity,

00:34:37.310 --> 00:34:39.200
and the nature of the computer culture.

00:34:39.200 --> 00:34:43.000
And that was, I think,
my contribution has been

00:34:43.000 --> 00:34:48.000
to talk about that shift,
and really to document

00:34:48.950 --> 00:34:53.330
the inner life of how the computer culture

00:34:54.760 --> 00:34:57.490
has changed our inner life,

00:34:57.490 --> 00:35:02.340
because now we're deeply
enmeshed in a computer culture

00:35:02.340 --> 00:35:05.130
that no longer is that
kind of evocative object

00:35:05.130 --> 00:35:06.450
for those sorts of issues.

00:35:06.450 --> 00:35:09.350
Now, we use the computer
for very different things

00:35:09.350 --> 00:35:12.630
and the issues that it brings
up are very different for us.

00:35:12.630 --> 00:35:15.690
Now I'm onto a whole
different set of issues

00:35:15.690 --> 00:35:17.170
when I talk about the computer.

00:35:17.170 --> 00:35:21.533
- So the next stage is really confronting,

00:35:23.780 --> 00:35:27.835
what shall we call it, the
Bambi moment essentially?

00:35:27.835 --> 00:35:29.400
(laughing)

00:35:29.400 --> 00:35:32.470
Which is to say, why not Bambi?

00:35:32.470 --> 00:35:37.470
So what's intriguing about
what you're saying is

00:35:38.000 --> 00:35:43.000
it wasn't the extraordinary
education so much

00:35:43.730 --> 00:35:47.790
as the reality that you were confronting

00:35:49.220 --> 00:35:52.650
that made you more and more sensitive

00:35:52.650 --> 00:35:55.530
to our loss of humanity.

00:35:55.530 --> 00:35:57.470
- Well, I mean--
- Or, diminishing of the--

00:35:57.470 --> 00:35:59.950
- I mean, I think that you know,

00:35:59.950 --> 00:36:02.640
that studying the computer culture at MIT,

00:36:02.640 --> 00:36:04.950
I mean I studied the changes in what

00:36:07.930 --> 00:36:12.180
computers have confronted us
with changing opportunities

00:36:12.180 --> 00:36:15.030
and changing challenges.

00:36:15.030 --> 00:36:19.530
So right now, I mean,

00:36:20.720 --> 00:36:24.980
the challenges that they confront
us with are considerable.

00:36:24.980 --> 00:36:27.500
Right now the challenges
are to our privacy,

00:36:27.500 --> 00:36:31.383
to our democracy, to our sense of self.

00:36:32.310 --> 00:36:37.210
Are we happy with the notion
of evolving with computers

00:36:37.210 --> 00:36:40.320
to a different place,
people talk about kind of

00:36:40.320 --> 00:36:42.363
co-evolution with computers,

00:36:42.363 --> 00:36:44.240
is that something we're comfortable with?

00:36:44.240 --> 00:36:49.240
The challenges Facebook poses
to democracy and privacy,

00:36:49.960 --> 00:36:51.610
that's a different kind of challenge.

00:36:51.610 --> 00:36:53.730
I mean, there are so many things

00:36:53.730 --> 00:36:55.230
that we're confronted with now

00:36:56.610 --> 00:36:59.970
but there's also the, you know.

00:36:59.970 --> 00:37:03.350
Given my background, I'm
particularly interested in

00:37:03.350 --> 00:37:05.260
what I call artificial intimacy.

00:37:05.260 --> 00:37:06.647
I mean, you know.

00:37:08.900 --> 00:37:12.980
We have computers that can
pretend to be psychotherapists,

00:37:12.980 --> 00:37:15.440
that can have a
conversation with you about

00:37:18.820 --> 00:37:23.560
you know, your love life, your feelings,

00:37:23.560 --> 00:37:25.080
your spouse, your children.

00:37:25.080 --> 00:37:27.440
I mean the fact that it can pretend,

00:37:27.440 --> 00:37:30.240
the fact that a computer can pretend

00:37:30.240 --> 00:37:33.360
or be good enough to fake intimacy

00:37:33.360 --> 00:37:36.060
doesn't mean that it's capable
of intimacy or empathy.

00:37:36.060 --> 00:37:39.233
And I think that's a,

00:37:40.290 --> 00:37:44.040
you know, this as-if intimacy and empathy,

00:37:44.040 --> 00:37:48.470
people need to sort out
whether that's good enough

00:37:48.470 --> 00:37:49.490
to be the real thing.

00:37:49.490 --> 00:37:53.050
So I'm trying to spark a
conversation about that.

00:37:53.050 --> 00:37:57.380
- One of two of the core ideas

00:37:57.380 --> 00:38:02.380
that you latch onto,
develop, one is solitude.

00:38:03.540 --> 00:38:05.810
- Yes.
- Talk a little about that,

00:38:05.810 --> 00:38:10.810
because you see solitude as key to the

00:38:12.150 --> 00:38:16.300
development and maturation
of the individuals

00:38:16.300 --> 00:38:18.780
so that they can go out
and confront the world.

00:38:18.780 --> 00:38:22.840
- Yes, so in my, in
Reclaiming Conversation,

00:38:22.840 --> 00:38:25.080
I talk about two things.

00:38:25.080 --> 00:38:30.080
I try to organize my
ideas, saying you know,

00:38:31.600 --> 00:38:33.790
there are two things that are lost

00:38:33.790 --> 00:38:38.790
in our recent fascination with our phones.

00:38:39.900 --> 00:38:40.970
Our heads in our phones.

00:38:40.970 --> 00:38:43.890
And one is is that people are becoming

00:38:44.950 --> 00:38:48.360
less capable of being bored.

00:38:48.360 --> 00:38:51.010
We're losing the capacity for boredom,

00:38:51.010 --> 00:38:53.830
and the capacity to be bored
is an incredibly important

00:38:53.830 --> 00:38:55.387
developmental moment,

00:38:59.620 --> 00:39:02.560
and it's so important because boredom,

00:39:02.560 --> 00:39:05.140
when you're feeling bored,
your brain is not bored at all,

00:39:05.140 --> 00:39:06.800
your brain is laying down

00:39:08.440 --> 00:39:10.210
what's called the default mode network,

00:39:10.210 --> 00:39:15.210
which is the pathways for the development

00:39:15.800 --> 00:39:18.700
of a stable sense of an
autobiographical self.

00:39:18.700 --> 00:39:22.360
So you need those moments
when you feel bored

00:39:22.360 --> 00:39:24.710
for your brain really to develop

00:39:24.710 --> 00:39:26.743
your stable sense of self.

00:39:29.810 --> 00:39:32.050
Right now when people feel bored,

00:39:32.050 --> 00:39:34.350
they have no tolerance and they go

00:39:34.350 --> 00:39:36.320
immediately to their phones.

00:39:36.320 --> 00:39:39.080
So the first thing is I try to argue,

00:39:39.080 --> 00:39:41.080
you know, remind people of the importance

00:39:41.080 --> 00:39:42.730
of those moments of boredom and say,

00:39:42.730 --> 00:39:44.510
you know, walk towards boredom.

00:39:44.510 --> 00:39:48.250
Make sure your child doesn't
have a phone in front of them.

00:39:48.250 --> 00:39:52.630
'Cause there are potty trainers
with slots for an iPhone

00:39:52.630 --> 00:39:55.050
and slots for an iPad, no, no, no.

00:39:55.050 --> 00:39:58.280
And baby bouncers where you
can put an iPad or an iPhone,

00:39:58.280 --> 00:40:01.253
no, no, you know, let your child be bored.

00:40:02.670 --> 00:40:04.710
Let them develop that capacity.

00:40:04.710 --> 00:40:07.800
So boredom is very
important, and with boredom,

00:40:07.800 --> 00:40:09.690
comes the capacity for solitude.

00:40:09.690 --> 00:40:13.130
Now, why is solitude, these
go together very often

00:40:13.130 --> 00:40:14.720
because very often in solitude

00:40:14.720 --> 00:40:16.613
we need to have that moment of boredom,

00:40:16.613 --> 00:40:18.540
you know, why is solitude so important?

00:40:18.540 --> 00:40:20.540
Because the capacity for solitude

00:40:21.680 --> 00:40:23.770
means you're alone with yourself,

00:40:23.770 --> 00:40:25.790
you can tolerate your own company,

00:40:25.790 --> 00:40:27.670
you know your own company,

00:40:27.670 --> 00:40:30.813
which means that when
you go to somebody else,

00:40:32.240 --> 00:40:34.960
because you're okay with yourself,

00:40:34.960 --> 00:40:39.240
you can then recognize
them for who they are.

00:40:39.240 --> 00:40:41.900
You're not trying to use who they are

00:40:41.900 --> 00:40:44.760
to buttress your fragile
sense of yourself,

00:40:44.760 --> 00:40:45.970
you're okay with yourself

00:40:45.970 --> 00:40:48.580
so you can recognize another person.

00:40:48.580 --> 00:40:52.070
So it's actually very
important to know who you are

00:40:52.070 --> 00:40:54.000
and be okay with who you are,

00:40:54.000 --> 00:40:57.400
in order to recognize someone
else for who they are.

00:40:57.400 --> 00:40:58.993
The two really go together.

00:41:01.460 --> 00:41:05.900
We forget that, we forget
the importance of solitude

00:41:06.770 --> 00:41:09.760
for relational purposes.

00:41:09.760 --> 00:41:13.170
And we have to remember the importance

00:41:13.170 --> 00:41:15.373
of solitude for relational purposes.

00:41:17.039 --> 00:41:20.630
So the psychoanalytic
tradition is so important here

00:41:20.630 --> 00:41:23.200
because the great
psychoanalyst David Winnicott,

00:41:23.200 --> 00:41:26.140
and here I paraphrase, said you know,

00:41:26.140 --> 00:41:28.890
if you don't teach your
children to be lonely,

00:41:28.890 --> 00:41:30.420
if you don't teach your
children to be alone,

00:41:30.420 --> 00:41:32.300
they'll only know how to be lonely.

00:41:32.300 --> 00:41:34.150
Which is, I think, one
of the great insights

00:41:34.150 --> 00:41:35.610
from the psychoanalytic tradition

00:41:35.610 --> 00:41:38.283
which people throw out
much too quickly now.

00:41:39.609 --> 00:41:41.200
You need to know how to be alone

00:41:41.200 --> 00:41:43.550
in order to be not lonely.

00:41:43.550 --> 00:41:46.140
Because if you know how to be alone,

00:41:46.140 --> 00:41:49.270
you'll be able to really
connect with other people.

00:41:49.270 --> 00:41:52.120
And now that we have our phones,

00:41:52.120 --> 00:41:54.520
people do not know how to be lonely,

00:41:54.520 --> 00:41:57.020
they go immediately to their phone.

00:41:57.020 --> 00:41:59.420
And the minute they start to be lonely,

00:41:59.420 --> 00:42:00.650
they, no I don't wanna do this,

00:42:00.650 --> 00:42:02.270
they go to their phone instead.

00:42:02.270 --> 00:42:04.570
So they're not really
learning about themselves

00:42:04.570 --> 00:42:06.370
the way the need to
learn about themselves.

00:42:06.370 --> 00:42:11.180
- And then the solitude makes possible

00:42:11.180 --> 00:42:14.160
the capacity to do conversation--

00:42:14.160 --> 00:42:15.680
- Yes!
- Which is then

00:42:15.680 --> 00:42:20.250
very important to the further
maturation of the self.

00:42:20.250 --> 00:42:22.420
- Right, so I'm trying to argue now,

00:42:22.420 --> 00:42:25.000
I mean, the challenges we face now

00:42:25.000 --> 00:42:28.410
are challenges to privacy,
are challenges to intimacy,

00:42:28.410 --> 00:42:32.550
are challenges to democracy,
are challenges to identity.

00:42:32.550 --> 00:42:35.350
But are deeply challenges to,

00:42:35.350 --> 00:42:39.640
can you put away your phone
long enough to know solitude

00:42:39.640 --> 00:42:41.573
so then you can have relationships?

00:42:42.560 --> 00:42:46.000
So it's not just that we face, you know,

00:42:46.000 --> 00:42:48.480
are we gonna be human and not fall in love

00:42:48.480 --> 00:42:49.960
with artificial intelligences,

00:42:49.960 --> 00:42:53.460
are we gonna be just
able to be by ourselves

00:42:53.460 --> 00:42:55.460
so that we can be with other people.

00:42:55.460 --> 00:42:58.213
So right now it's not that
I don't like technology,

00:42:58.213 --> 00:43:00.280
it's that I'm really worried,

00:43:00.280 --> 00:43:02.970
it's not like an anti-technology position.

00:43:02.970 --> 00:43:04.440
I'm worried about people.

00:43:04.440 --> 00:43:07.050
I'm not against, I'm pro-human,

00:43:07.050 --> 00:43:10.323
I'm not against technology,
I'm just very much pro-human.

00:43:11.730 --> 00:43:14.720
I don't begin with an
animosity towards technology,

00:43:14.720 --> 00:43:18.090
I'm just very concerned about human beings

00:43:18.090 --> 00:43:19.250
and their development,

00:43:19.250 --> 00:43:20.460
and being able to maintain

00:43:20.460 --> 00:43:22.510
relationships with other human beings.

00:43:22.510 --> 00:43:26.400
I don't begin with, like,
oh I'm against technology.

00:43:26.400 --> 00:43:28.853
Technology is not kind of what's on my,

00:43:30.340 --> 00:43:32.690
I don't begin with that.

00:43:32.690 --> 00:43:37.210
- So what over time, as
you've studied this subject,

00:43:37.210 --> 00:43:41.960
your concern emerges as a result of

00:43:41.960 --> 00:43:46.770
what was a tool has turned us into a tool.

00:43:46.770 --> 00:43:48.790
- Yeah, I mean, what was a tool,

00:43:48.790 --> 00:43:50.640
now I don't know what
we're using the tool for.

00:43:50.640 --> 00:43:54.310
I think we've lost our way.

00:43:54.310 --> 00:43:58.660
When people have a moment of boredom,

00:44:01.290 --> 00:44:02.490
and pick up their phone,

00:44:04.270 --> 00:44:09.270
it's no longer a tool, it's
no longer a I'm using it to,

00:44:09.410 --> 00:44:12.670
it's I'm using it to not
have a moment of boredom.

00:44:12.670 --> 00:44:14.043
Well now it's no longer,

00:44:15.480 --> 00:44:18.340
that's not exactly a tool exactly,

00:44:18.340 --> 00:44:21.880
that's like a, what is that? (laughs)

00:44:21.880 --> 00:44:25.070
- Well it's a master, it's become a--

00:44:25.070 --> 00:44:27.990
- I don't know, it's a tool to
not have a moment of boredom,

00:44:27.990 --> 00:44:29.930
but if a moment of boredom is a good thing

00:44:29.930 --> 00:44:33.870
because it's helping you
develop a self and an identity

00:44:33.870 --> 00:44:37.940
and a stable self and a set of interests

00:44:37.940 --> 00:44:40.330
and a capacity for empathy,

00:44:40.330 --> 00:44:45.330
then it's an underminer
of human potential.

00:44:46.690 --> 00:44:51.020
So that's not a tool anymore,
that's an underminer.

00:44:51.020 --> 00:44:53.910
So that's not a good thing.

00:44:53.910 --> 00:44:58.783
- And the key here is attention, that you,

00:45:00.210 --> 00:45:05.210
confronting the initial anxiety of boredom

00:45:05.530 --> 00:45:09.340
and being lonely,

00:45:09.340 --> 00:45:13.440
your attention is shifted to

00:45:14.880 --> 00:45:16.470
another place--
- Yes.

00:45:16.470 --> 00:45:20.793
- And data can stream
in or messages and so on

00:45:24.300 --> 00:45:27.080
can stream in, and distract you.

00:45:27.080 --> 00:45:29.113
- Yes, that's why I try to say,

00:45:30.190 --> 00:45:32.330
I gave these Hitchcock lectures,

00:45:32.330 --> 00:45:34.940
and I tried to say,
well what causes people

00:45:34.940 --> 00:45:36.207
to get themselves into trouble?

00:45:36.207 --> 00:45:39.060
And I tried to have, like,

00:45:39.060 --> 00:45:41.360
something people could hold onto.

00:45:41.360 --> 00:45:45.610
And I say it's vulnerability,
I try to boil it down.

00:45:45.610 --> 00:45:49.900
What is it, and it's our
human, we're vulnerable.

00:45:49.900 --> 00:45:52.620
So think about your vulnerability,

00:45:52.620 --> 00:45:54.050
what are your vulnerabilities,

00:45:54.050 --> 00:45:56.450
and people are vulnerable,
people are vulnerable,

00:45:56.450 --> 00:45:59.700
they don't wanna feel vulnerable.

00:45:59.700 --> 00:46:02.340
I try to boil it down to
something that people will

00:46:02.340 --> 00:46:05.620
be able to sort of understand
and not feel ashamed of.

00:46:05.620 --> 00:46:08.290
And I don't think people are necessarily

00:46:08.290 --> 00:46:09.890
ashamed of feeling vulnerable,

00:46:09.890 --> 00:46:12.190
I think people need to hold onto something

00:46:12.190 --> 00:46:14.860
that they don't feel, that
they can begin to act on,

00:46:14.860 --> 00:46:16.650
they don't feel ashamed of,

00:46:16.650 --> 00:46:19.850
they can say yeah, that's
right, I feel vulnerable.

00:46:19.850 --> 00:46:22.010
I don't wanna feel vulnerable.

00:46:22.010 --> 00:46:23.140
I'm getting into trouble

00:46:23.140 --> 00:46:25.760
'cause I don't wanna feel vulnerable.

00:46:25.760 --> 00:46:27.690
So I don't want people to feel ashamed

00:46:27.690 --> 00:46:30.030
that they're turning to their phone.

00:46:30.030 --> 00:46:32.480
And I think that people
can latch onto this,

00:46:32.480 --> 00:46:34.690
that they don't wanna feel vulnerable,

00:46:34.690 --> 00:46:39.690
that moment of feeling
yeah, I feel anxious,

00:46:41.210 --> 00:46:45.270
I feel alone, I feel vulnerable right now.

00:46:45.270 --> 00:46:47.457
Like, I flew into Berkeley,

00:46:47.457 --> 00:46:52.136
I'm allergic to something
in your air, (both laughing)

00:46:52.136 --> 00:46:54.420
you know, I'm like ever since I got here

00:46:54.420 --> 00:46:58.623
I'm like sniffling, I
do, I felt vulnerable.

00:46:59.710 --> 00:47:03.460
I reached for my phone, I did.

00:47:03.460 --> 00:47:07.780
I was like, alone in my
room, I'm like crying,

00:47:07.780 --> 00:47:12.780
I'm like, sniffling, I'm weeping.

00:47:13.090 --> 00:47:14.593
I reach for my phone.

00:47:15.750 --> 00:47:17.940
Because all my friends are on my phone,

00:47:17.940 --> 00:47:18.960
my family's on my phone,

00:47:18.960 --> 00:47:21.350
everybody that's nice
to me is on my phone.

00:47:21.350 --> 00:47:25.110
Okay, that's exactly what we do now

00:47:25.110 --> 00:47:28.020
when we feel, when we're
weeping and we're sneezing,

00:47:28.020 --> 00:47:29.653
we reach for our phone.

00:47:30.770 --> 00:47:32.433
It's like that is what we do.

00:47:33.630 --> 00:47:38.230
And that's fine, except if we you know,

00:47:38.230 --> 00:47:40.694
do it all the time. (laughing)

00:47:40.694 --> 00:47:45.130
And if a person is available,
we don't turn to the person.

00:47:45.130 --> 00:47:49.460
And more and more, instead
of turning to the people,

00:47:49.460 --> 00:47:51.000
we turn to our phones.

00:47:51.000 --> 00:47:53.040
My students don't wanna
come and talk to me,

00:47:53.040 --> 00:47:56.250
they'd rather send me a
message on their phone,

00:47:56.250 --> 00:47:59.000
my phone, everybody wants
to be not vulnerable

00:47:59.000 --> 00:48:02.170
because if they see me in person,

00:48:02.170 --> 00:48:03.490
I could ask them a question

00:48:03.490 --> 00:48:06.010
that would make them feel vulnerable.

00:48:06.010 --> 00:48:10.070
- You're concerned now about the societal

00:48:10.070 --> 00:48:12.730
and political consequences.
- Yes, very.

00:48:12.730 --> 00:48:14.690
- You touched on that a minute ago.

00:48:14.690 --> 00:48:19.690
I mean, we know that with
regard to social media

00:48:20.570 --> 00:48:22.940
that all this data is being collected

00:48:22.940 --> 00:48:25.130
and I get the sense from reading you

00:48:25.130 --> 00:48:30.130
that what is being created

00:48:30.140 --> 00:48:34.580
is a definition of you
based on all the data

00:48:34.580 --> 00:48:38.160
that is in some ways in conflict

00:48:38.160 --> 00:48:41.223
with who you are or may wanna be.

00:48:42.100 --> 00:48:46.700
- Yeah, I mean, I think that
we saw in our last election

00:48:46.700 --> 00:48:51.450
that there's a version of
you that's been scraped

00:48:51.450 --> 00:48:55.720
and available and that,

00:48:55.720 --> 00:48:57.883
or Brexit, you know.

00:49:00.060 --> 00:49:04.730
This data gets sold to actors that have

00:49:05.700 --> 00:49:10.700
plans and desires and agendas
that are very specific.

00:49:13.060 --> 00:49:16.653
And very powerful,

00:49:19.080 --> 00:49:24.080
and really can shape our futures

00:49:24.480 --> 00:49:25.930
and the future of the planet.

00:49:30.610 --> 00:49:35.127
And we're vulnerable
because now you can have

00:49:36.550 --> 00:49:38.380
you know, there are incredible things

00:49:38.380 --> 00:49:43.070
that artificial intelligence
and altered reality can do,

00:49:43.070 --> 00:49:45.120
you can have any political figure

00:49:45.120 --> 00:49:47.830
look at though they're saying anything.

00:49:47.830 --> 00:49:49.640
You can have Barack Obama look as though

00:49:49.640 --> 00:49:53.663
he's making a speech that's anti-Semitic.

00:49:54.764 --> 00:49:56.690
I mean, just his face and his mouth,

00:49:56.690 --> 00:49:59.490
I mean you can have
anybody saying anything.

00:49:59.490 --> 00:50:03.070
- So what--
- So that you can target,

00:50:03.070 --> 00:50:06.590
you can target him, forget
the expression fake news,

00:50:06.590 --> 00:50:11.590
you can have any figure,
any music figure from music,

00:50:12.320 --> 00:50:15.860
or art, or literature, saying anything,

00:50:15.860 --> 00:50:19.283
in a completely convincing
way, and target that message,

00:50:20.460 --> 00:50:24.230
to people who you know from what they shop

00:50:24.230 --> 00:50:25.710
and where they go and what they do

00:50:25.710 --> 00:50:27.273
and who they associate with.

00:50:28.490 --> 00:50:31.113
And have people who you know,

00:50:32.740 --> 00:50:36.180
they can be influenced by
saying anything to them.

00:50:36.180 --> 00:50:38.647
This is scary, and we just--
- Very, very.

00:50:38.647 --> 00:50:42.250
- Very very scary, and
people will do this now.

00:50:42.250 --> 00:50:43.810
And we just need to be

00:50:46.480 --> 00:50:50.110
on a different kind of
alert in this new world.

00:50:50.110 --> 00:50:53.130
- So you feel vulnerable,

00:50:53.130 --> 00:50:57.690
your attention is captured
by what you see online,

00:50:57.690 --> 00:51:02.690
and that in turn fortifies what could be

00:51:02.870 --> 00:51:06.673
very negative aspects of your own persona.

00:51:07.720 --> 00:51:10.340
- Yeah, but I mean, one of the things

00:51:11.984 --> 00:51:15.460
is that we've signed onto a system

00:51:15.460 --> 00:51:19.130
where we're used to
getting things for free.

00:51:19.130 --> 00:51:21.340
In other words, you get
Google Mail for free,

00:51:21.340 --> 00:51:24.380
you get Maps for free,
you get Docs for free,

00:51:24.380 --> 00:51:25.640
you get Facebook for free,

00:51:25.640 --> 00:51:28.460
now why are you getting all this for free?

00:51:28.460 --> 00:51:29.510
You're getting it for free

00:51:29.510 --> 00:51:32.760
because they're taking everything,

00:51:32.760 --> 00:51:35.090
they're reading your mail,
they're reading your docs,

00:51:35.090 --> 00:51:37.750
they're reading what you post.

00:51:37.750 --> 00:51:40.533
That's why it's free, it's not free.

00:51:42.703 --> 00:51:47.000
You've agreed that they
can read all your mail,

00:51:47.000 --> 00:51:48.633
they can read all your docs,

00:51:49.610 --> 00:51:53.170
and they can know where you go.

00:51:53.170 --> 00:51:54.333
That's not free.

00:51:55.470 --> 00:51:58.990
So why it was so important to
the founders of this country

00:51:59.840 --> 00:52:04.623
that the mail, the US mail, be protected.

00:52:05.770 --> 00:52:07.763
That was very important.

00:52:08.910 --> 00:52:10.140
And I remember my grandmother,

00:52:10.140 --> 00:52:11.910
I write about this in Alone Together,

00:52:11.910 --> 00:52:14.660
it was very interesting,
I mean there she is,

00:52:14.660 --> 00:52:19.080
a Jewish woman

00:52:19.080 --> 00:52:22.520
from a pogrom background,

00:52:22.520 --> 00:52:25.460
and she takes me down to
the mailboxes in Brooklyn

00:52:25.460 --> 00:52:29.300
and she teaches me that the
reason we're in this country

00:52:29.300 --> 00:52:32.240
is that nobody can tamper with our mail.

00:52:32.240 --> 00:52:34.240
Because she knows what it means

00:52:35.290 --> 00:52:39.520
to have people tamper with your mail.

00:52:39.520 --> 00:52:40.900
And she says we're in this country,

00:52:40.900 --> 00:52:43.030
now she knows about J. Edgar Hoover,

00:52:43.030 --> 00:52:45.590
I don't wanna say that
it was a perfect system,

00:52:45.590 --> 00:52:48.900
I mean, but basically that's

00:52:48.900 --> 00:52:50.360
what she teaches her granddaughter,

00:52:50.360 --> 00:52:52.700
that's what she chooses to teach me.

00:52:52.700 --> 00:52:56.190
That we're in this country
because these mailboxes,

00:52:56.190 --> 00:52:58.773
that's what America is,
it's in the mailboxes.

00:52:59.680 --> 00:53:02.240
So that was my citizenship lesson.

00:53:02.240 --> 00:53:03.680
Now, what can I teach my daughter,

00:53:03.680 --> 00:53:08.103
I say this in my book, what
can I teach my daughter about?

00:53:09.420 --> 00:53:13.580
About email, when I know that
anybody can read her email.

00:53:13.580 --> 00:53:15.430
Anybody can read her Facebook,

00:53:15.430 --> 00:53:17.663
anybody can look at
what she's doing online.

00:53:19.570 --> 00:53:23.933
It's all owned by the
people who provide it.

00:53:24.810 --> 00:53:27.210
- One final question, so,

00:53:27.210 --> 00:53:30.440
it's fair to say that a step

00:53:30.440 --> 00:53:33.460
in resisting I guess is the word

00:53:33.460 --> 00:53:37.210
is consciousness of the implications--

00:53:37.210 --> 00:53:38.311
- Yes.
- Of all

00:53:38.311 --> 00:53:39.550
that's happening to us.
- Yes, that's,

00:53:39.550 --> 00:53:43.530
and I think that this is the biggest step

00:53:43.530 --> 00:53:46.320
because people, it's like global warming,

00:53:46.320 --> 00:53:50.430
this is like massive forgetting.

00:53:50.430 --> 00:53:53.803
People, this is the thing that
people most want to forget.

00:53:54.640 --> 00:53:56.030
You can watch them forgetting.

00:53:56.030 --> 00:53:57.590
As soon as you talk to them about it,

00:53:57.590 --> 00:54:00.707
you can watch them, you
can, (laughs) you know,

00:54:02.047 --> 00:54:05.950
I'm a crack interviewer, I
can watch them forgetting

00:54:05.950 --> 00:54:07.710
as I'm interviewing them about it.

00:54:07.710 --> 00:54:09.830
Because nobody wants to be reminded,

00:54:09.830 --> 00:54:12.700
I say, do you know, let's
talk about your Gmail?

00:54:12.700 --> 00:54:15.386
You know, you know that it's (groans).

00:54:15.386 --> 00:54:17.710
(laughing)

00:54:17.710 --> 00:54:21.700
So yeah, I'm about being a
pain right now for everybody,

00:54:21.700 --> 00:54:23.620
and reminding everybody.

00:54:23.620 --> 00:54:25.850
- Well on that note (Sherry laughing)

00:54:25.850 --> 00:54:28.800
and in a positive sense,

00:54:28.800 --> 00:54:30.420
Sherry, I wanna thank you very much.

00:54:30.420 --> 00:54:32.515
- Thank you very much.
- For being on our show.

00:54:32.515 --> 00:54:33.348
- It's been a pleasure.

00:54:33.348 --> 00:54:35.920
- And thank you very much for joining us

00:54:35.920 --> 00:54:39.167
for this conversation in history.

00:54:39.167 --> 00:54:43.000
(mysterious electronic music)

