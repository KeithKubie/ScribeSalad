WEBVTT
Kind: captions
Language: en

00:00:01.230 --> 00:00:03.710
Google has an amazing
cloud infrastructure

00:00:03.710 --> 00:00:07.180
for running your business,
mobile apps, data analytics.

00:00:07.180 --> 00:00:11.590
But did you know Google is also
a great place to do science?

00:00:11.590 --> 00:00:14.140
I'd like to tell you about how
Google is helping bring data

00:00:14.140 --> 00:00:16.390
science and life
science together

00:00:16.390 --> 00:00:19.250
to benefit health
and basic research.

00:00:19.250 --> 00:00:21.150
First, some background.

00:00:21.150 --> 00:00:24.620
The human genome contains around
6 billion nucleotide letters--

00:00:24.620 --> 00:00:27.530
the A's, C's, G's and T's.

00:00:27.530 --> 00:00:29.750
That's 3 billion
from each parent.

00:00:29.750 --> 00:00:32.270
In theory that's not a
huge amount of information,

00:00:32.270 --> 00:00:34.020
especially if you compress it.

00:00:34.020 --> 00:00:39.840
People's DNA is 99.9% identical,
but in practice the files

00:00:39.840 --> 00:00:41.980
start out much
bigger because you

00:00:41.980 --> 00:00:46.060
need to do a lot of analysis
to identify that 0.1% that

00:00:46.060 --> 00:00:48.090
makes each of us unique.

00:00:48.090 --> 00:00:49.830
When the scientific
community sequenced

00:00:49.830 --> 00:00:53.450
the first human genome
it took 15 years and cost

00:00:53.450 --> 00:00:55.484
around $3 billion.

00:00:55.484 --> 00:00:58.470
Thankfully, since
then the time and cost

00:00:58.470 --> 00:01:00.840
has plummeted dramatically.

00:01:00.840 --> 00:01:03.640
As you'd expect with an
exponential price drop

00:01:03.640 --> 00:01:06.870
like that the volume of
sequencing has exploded.

00:01:06.870 --> 00:01:11.330
Projects are already underway
to sequence millions of genomes.

00:01:11.330 --> 00:01:13.010
How much data is that?

00:01:13.010 --> 00:01:14.190
Let's think about it.

00:01:14.190 --> 00:01:16.580
At 100 gigabytes
per genome, if you

00:01:16.580 --> 00:01:19.530
wanted to read the DNA
of everyone in Moscow

00:01:19.530 --> 00:01:24.000
it would take more than 1.2
million terabyte hard drives.

00:01:24.000 --> 00:01:25.840
So this is a really
big challenge.

00:01:25.840 --> 00:01:29.220
Well, Google knows a thing
or two about big data.

00:01:29.220 --> 00:01:32.830
The Google search index
is around 100 petabytes,

00:01:32.830 --> 00:01:35.950
yet search results come back
in a quarter of a second.

00:01:35.950 --> 00:01:38.440
There's a huge opportunity to
bring data science and life

00:01:38.440 --> 00:01:40.010
science together.

00:01:40.010 --> 00:01:42.700
Imagine the impact if
researchers everywhere

00:01:42.700 --> 00:01:45.360
had powerful tools to
distinguish between people

00:01:45.360 --> 00:01:47.830
who become sick and
those who remain healthy,

00:01:47.830 --> 00:01:49.950
between patients who
respond to treatment

00:01:49.950 --> 00:01:51.960
and those whose
condition worsens,

00:01:51.960 --> 00:01:54.530
between pathogens
that cause outbreaks

00:01:54.530 --> 00:01:56.200
and those that are harmless.

00:01:56.200 --> 00:01:59.280
Imagine getting results
in seconds instead of days

00:01:59.280 --> 00:02:01.030
without owning a data center.

00:02:01.030 --> 00:02:04.170
That's the world we're
trying to bring about.

00:02:04.170 --> 00:02:05.960
Our first public
announcement was

00:02:05.960 --> 00:02:08.370
that we joined the Global
Alliance for Genomics

00:02:08.370 --> 00:02:10.720
and Health, an
international consortium

00:02:10.720 --> 00:02:14.910
of over 180 top universities,
research hospitals,

00:02:14.910 --> 00:02:17.940
medical centers, health care
providers, public health

00:02:17.940 --> 00:02:20.050
organizations,
and companies that

00:02:20.050 --> 00:02:22.200
are committed to the same goal.

00:02:22.200 --> 00:02:24.200
We're a computer
science company,

00:02:24.200 --> 00:02:26.160
so we're contributing
to the teams that

00:02:26.160 --> 00:02:29.780
are defining a standard API
to promote interoperability,

00:02:29.780 --> 00:02:32.370
like the W3C for genomics.

00:02:32.370 --> 00:02:34.160
We are hosting
public data that's

00:02:34.160 --> 00:02:37.150
available through the API and
we're building open source

00:02:37.150 --> 00:02:40.280
software showing how to work
with big genomic data using

00:02:40.280 --> 00:02:41.670
that API.

00:02:41.670 --> 00:02:44.090
To give just one example
of interoperability,

00:02:44.090 --> 00:02:45.730
here is a sample
genome browser that

00:02:45.730 --> 00:02:48.300
can connect the
API to access data.

00:02:48.300 --> 00:02:52.080
In the US the National Center
for Biotechnology Information

00:02:52.080 --> 00:02:55.250
implemented the API for
their sequence read archive.

00:02:55.250 --> 00:02:57.670
And the European
Bioinformatics Institute

00:02:57.670 --> 00:02:59.790
also implemented the API.

00:02:59.790 --> 00:03:02.590
At Google we have a
third implementation.

00:03:02.590 --> 00:03:04.600
Even though all
three groups store

00:03:04.600 --> 00:03:07.710
DNA sequences using
different internal formats,

00:03:07.710 --> 00:03:10.640
the same software can
connect to all of them

00:03:10.640 --> 00:03:12.830
without code
changes-- and this has

00:03:12.830 --> 00:03:14.750
happened in a matter of weeks.

00:03:14.750 --> 00:03:17.120
The progress is fantastic.

00:03:17.120 --> 00:03:19.230
The Global Alliance
has a GitHub project

00:03:19.230 --> 00:03:21.490
where you can read the
discussion about the data model

00:03:21.490 --> 00:03:24.110
and check out the
draft API spec.

00:03:24.110 --> 00:03:27.410
We have additional examples in
our Genomics team repository

00:03:27.410 --> 00:03:30.930
showing how to call the
API from Python, Java, R,

00:03:30.930 --> 00:03:33.380
as well as how to analyze
genomic information in two

00:03:33.380 --> 00:03:36.500
modes-- by doing
interactive queries

00:03:36.500 --> 00:03:38.890
and massively
parallel processing.

00:03:38.890 --> 00:03:43.170
Check out the open source repo
on GitHub by clicking here.

00:03:43.170 --> 00:03:45.910
And of course, you can learn
more about Google Genomics

00:03:45.910 --> 00:03:50.280
by checking out our
online developer docs.

00:03:50.280 --> 00:03:52.690
Exploring genomic data
can be a challenge--

00:03:52.690 --> 00:03:55.980
partly because the
files are so large

00:03:55.980 --> 00:03:58.320
and partly because many of
the computing technologies

00:03:58.320 --> 00:04:01.440
to work with them were
built decades ago.

00:04:01.440 --> 00:04:04.530
Let's look at some of the 21st
century computing technologies

00:04:04.530 --> 00:04:07.610
that we can use to
explore DNA sequences.

00:04:07.610 --> 00:04:10.880
One tool that Google has for
exploratory data analysis

00:04:10.880 --> 00:04:12.450
is called BigQuery.

00:04:12.450 --> 00:04:14.140
The underlying
technology was built

00:04:14.140 --> 00:04:19.120
to process trillions of lines of
log files at interactive speed.

00:04:19.120 --> 00:04:21.500
In our first prototype
using Google technology

00:04:21.500 --> 00:04:23.770
to look at genetic
variation we discovered

00:04:23.770 --> 00:04:26.310
that BigQuery is a good match
for scientific questions

00:04:26.310 --> 00:04:28.810
around population
genetics, including things

00:04:28.810 --> 00:04:31.400
like minor allele frequency,
transition/transversion

00:04:31.400 --> 00:04:33.090
ratios, and more.

00:04:33.090 --> 00:04:35.620
The way it works
is really simple.

00:04:35.620 --> 00:04:37.800
Type SQL query
into your browser,

00:04:37.800 --> 00:04:40.530
hit Enter, wait a few
seconds, get results

00:04:40.530 --> 00:04:42.490
on gigantic data sets.

00:04:42.490 --> 00:04:44.820
There's also an API so
that you can call it

00:04:44.820 --> 00:04:47.220
from scripts or programs.

00:04:47.220 --> 00:04:49.670
Here's an example of
what a query looks like.

00:04:49.670 --> 00:04:50.842
It looks like SQL.

00:04:50.842 --> 00:04:52.300
We have multiple
examples in GitHub

00:04:52.300 --> 00:04:55.360
and you can copy and
paste, or modify,

00:04:55.360 --> 00:05:00.540
to ask real biological questions
and get answers in seconds.

00:05:00.540 --> 00:05:02.640
Now, let's look at
what you can do.

00:05:02.640 --> 00:05:04.790
We loaded up the
1,000 Genomes data

00:05:04.790 --> 00:05:06.910
and did some quick
summary statistics.

00:05:06.910 --> 00:05:08.080
What did we find?

00:05:08.080 --> 00:05:10.620
By design of the study about
half of the participants

00:05:10.620 --> 00:05:12.630
are female, half male.

00:05:12.630 --> 00:05:15.290
Multiple geographic
groups are represented

00:05:15.290 --> 00:05:17.010
and some families
were sequenced,

00:05:17.010 --> 00:05:19.530
but mostly individuals.

00:05:19.530 --> 00:05:22.770
In the year 2000 researchers
applied an earlier

00:05:22.770 --> 00:05:26.360
genetic testing technology
on 255 individuals.

00:05:26.360 --> 00:05:29.400
They found evidence that
Africans are more genetically

00:05:29.400 --> 00:05:31.890
diverse than other
populations in the world,

00:05:31.890 --> 00:05:34.630
and they're the likely
origin of modern humans.

00:05:34.630 --> 00:05:38.990
In 2009 large scale sequencing
confirmed the findings.

00:05:38.990 --> 00:05:41.240
Today, you can
test these findings

00:05:41.240 --> 00:05:45.560
on over 1,000 Genomes using
BigQuery in just a few seconds.

00:05:45.560 --> 00:05:48.710
The key finding, Africans--
shown in light red--

00:05:48.710 --> 00:05:51.190
have more genetic variation.

00:05:51.190 --> 00:05:52.910
Hopefully this gives
just a little bit

00:05:52.910 --> 00:05:54.740
of a flavor for the
kinds of questions

00:05:54.740 --> 00:05:58.040
you can ask interactively with
BigQuery-- by typing a query,

00:05:58.040 --> 00:06:00.590
having a sip of coffee,
looking at the answer,

00:06:00.590 --> 00:06:02.410
and typing a slightly
different query.

00:06:02.410 --> 00:06:05.910
Another way to explore genomic
data is using MapReduce,

00:06:05.910 --> 00:06:07.740
the same distributed
computing paradigm

00:06:07.740 --> 00:06:10.930
Google uses to generate
the search index.

00:06:10.930 --> 00:06:13.830
MapReduce is a way to
process data in parallel

00:06:13.830 --> 00:06:15.850
by putting lots
of servers on it.

00:06:15.850 --> 00:06:19.460
We decided to run a MapReduce
in 1,000 Genomes data.

00:06:19.460 --> 00:06:22.370
Each circle represents
an individual's variance.

00:06:22.370 --> 00:06:25.470
Using MapReduce we ran a
principal component analysis,

00:06:25.470 --> 00:06:28.950
or PCA, to project the data
into two dimensions that

00:06:28.950 --> 00:06:30.770
explain the variation.

00:06:30.770 --> 00:06:34.510
It took about a page of code
and ran in around 15 minutes.

00:06:34.510 --> 00:06:37.980
In this plot we see three
clear clusters form,

00:06:37.980 --> 00:06:40.110
but what do they mean?

00:06:40.110 --> 00:06:42.590
Color coding the
plots by population,

00:06:42.590 --> 00:06:44.700
we see that the three
clusters correspond

00:06:44.700 --> 00:06:48.370
to the super populations of the
world-- Africans in light red,

00:06:48.370 --> 00:06:51.560
Europeans in blue,
and Asians in green.

00:06:51.560 --> 00:06:55.340
And see this point in pink
in-between Europe and Africa?

00:06:55.340 --> 00:06:58.320
Those are African-Americans
from the American Southwest.

00:06:58.320 --> 00:07:03.170
This is very cool, but what
are the x- and y-axes mean?

00:07:03.170 --> 00:07:06.230
Let's look a little
closer with BigQuery.

00:07:06.230 --> 00:07:08.870
This bit of SQL selects
how many variants

00:07:08.870 --> 00:07:12.370
occur in a single allele
versus in two alleles-- that

00:07:12.370 --> 00:07:16.350
means in one copy versus both
copies of each chromosome.

00:07:16.350 --> 00:07:18.880
Copy, paste, hit Enter.

00:07:18.880 --> 00:07:21.800
A few seconds later
you've got an answer.

00:07:21.800 --> 00:07:24.240
Plotting the results with
R we see that we just

00:07:24.240 --> 00:07:26.810
generated a very similar plot
to the principal component

00:07:26.810 --> 00:07:27.680
analysis.

00:07:27.680 --> 00:07:29.670
With MapReduce and
BigQuery we have

00:07:29.670 --> 00:07:31.580
two ways of working
with data and we

00:07:31.580 --> 00:07:34.430
can go back and
forth between them.

00:07:34.430 --> 00:07:38.150
Now, just imagine what we
can do with 1,000 times

00:07:38.150 --> 00:07:39.290
as many samples.

00:07:39.290 --> 00:07:42.350
With a million genomes
representing a wide range

00:07:42.350 --> 00:07:44.430
of phenotypes,
diseases, treatments,

00:07:44.430 --> 00:07:46.420
environments-- think
of what you might

00:07:46.420 --> 00:07:48.710
learn about the genetic
basis of disease,

00:07:48.710 --> 00:07:51.760
drug response, and more.

00:07:51.760 --> 00:07:53.730
And for that to
happen the world is

00:07:53.730 --> 00:07:56.210
going to need a
lot of computers.

00:07:56.210 --> 00:07:57.700
Hopefully these
examples give you

00:07:57.700 --> 00:08:00.230
a taste of what's possible by
bringing data science and life

00:08:00.230 --> 00:08:03.110
science together on
Google Cloud Platform.

00:08:03.110 --> 00:08:05.420
All of this is
available to you today.

00:08:05.420 --> 00:08:08.190
To get started yourself you
could read the developer docs,

00:08:08.190 --> 00:08:10.980
look at the code samples,
try the genome browser,

00:08:10.980 --> 00:08:13.140
and join our discussion forum.

00:08:13.140 --> 00:08:14.430
I'm Jonathan Bingham.

00:08:14.430 --> 00:08:16.280
Thanks for listening.

