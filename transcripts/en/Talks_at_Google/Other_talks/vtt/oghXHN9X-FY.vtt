WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:01.130
&gt;&gt;Marcus: I'm slightly new to this.

00:00:01.130 --> 00:00:02.130
I've not come to Google before.

00:00:02.130 --> 00:00:07.480
So I'm guessing that given its 11 o'clock
and there are quite a few people here already

00:00:07.480 --> 00:00:09.220
I'll just make a start.

00:00:09.220 --> 00:00:12.139
So thank you for the invitation.

00:00:12.139 --> 00:00:16.320
And I'm more than happy for you to ask me
questions as I go along.

00:00:16.320 --> 00:00:20.680
It's a PowerPoint-based presentation, but
I'm gonna try to make it as engaging as possible.

00:00:20.680 --> 00:00:22.960
And hopefully there'll be time at the end
for questions.

00:00:22.960 --> 00:00:25.029
The title of the talk is, "Do I Look Happy
To You?"

00:00:25.029 --> 00:00:29.220
And what I'm gonna talk about today is some
work that myself and a colleague of mine,

00:00:29.220 --> 00:00:32.770
Ian Penton-Voak, at the University of Bristol
have been doing on the relationship between

00:00:32.770 --> 00:00:36.860
how we see the world, how we see other people
in the world and how we interact with other

00:00:36.860 --> 00:00:38.460
players in the world.

00:00:38.460 --> 00:00:44.790
And social functioning, emotional functioning
and mental health.

00:00:44.790 --> 00:00:47.860
So I'll talk a little bit about social cognition
and what that is.

00:00:47.860 --> 00:00:52.560
And I'll talk about the relationship between
mental health and depression, with a particular

00:00:52.560 --> 00:00:57.500
focus on two case studies where we've collected
some data that looks promising with respect

00:00:57.500 --> 00:01:02.739
to how we might use this information to develop
new treatments for various mental health problems,

00:01:02.739 --> 00:01:04.760
depression and aggression.

00:01:04.760 --> 00:01:09.450
And then I'll talk about the future where
this kind of research might go and the extent

00:01:09.450 --> 00:01:15.270
to which these kind of techniques in particular
lend themselves to the technologies that are

00:01:15.270 --> 00:01:20.030
increasingly available to a large proportion
of the population, smart phones, tablets and

00:01:20.030 --> 00:01:21.030
so on.

00:01:21.030 --> 00:01:27.420
Part of the back story to this is that there
is growing interest in what has been described

00:01:27.420 --> 00:01:32.770
as emotional intelligence, which is defined
in slightly different ways by different people.

00:01:32.770 --> 00:01:37.049
But which relates very closely to this idea
of social cognition that I'm gonna be talk

00:01:37.049 --> 00:01:38.049
about today.

00:01:38.049 --> 00:01:44.029
This idea that the extent to which we encode,
store, retrieve, process information about

00:01:44.029 --> 00:01:49.409
other people in the environment that we work
in that are members of the same species plays

00:01:49.409 --> 00:01:53.960
a role in our ability to navigate the world
and to make sense of it.

00:01:53.960 --> 00:01:58.209
So there's clearly a lot of interest in that,
and you can see from this "Emotional Intelligence

00:01:58.209 --> 00:02:04.679
for Dummies" snapshot that much of the information
that we use when it comes to interacting with

00:02:04.679 --> 00:02:07.630
other people is extracted from people's facial
expressions.

00:02:07.630 --> 00:02:11.860
So the way that someone is looking at you
conveys considerable information in principle

00:02:11.860 --> 00:02:17.030
at least that can guide the interactions that
we have with that person.

00:02:17.030 --> 00:02:24.570
And so when there are biases, deficits, differences
in the way in which people do that those can

00:02:24.570 --> 00:02:32.140
lead to differences in the ability of those
people to interact constructively or positively

00:02:32.140 --> 00:02:36.250
with other people in their social world.

00:02:36.250 --> 00:02:40.560
So for a long time we've known that there
are six primary or cardinal emotions.

00:02:40.560 --> 00:02:44.820
Anger, fear, disgust, surprise, happiness
and sadness.

00:02:44.820 --> 00:02:50.200
Which were very good at detecting, particularly
when you have people mugging those facial

00:02:50.200 --> 00:02:51.430
expressions as you do here.

00:02:51.430 --> 00:02:59.040
These pictures were taken from Paul Ekman's
work who was the individual who really created

00:02:59.040 --> 00:03:02.480
this field and did the early work on these
primary emotions.

00:03:02.480 --> 00:03:07.360
So hence the slightly dated look of the players
in the photographs.

00:03:07.360 --> 00:03:13.670
But what's interesting about this is that
when you present these images cross culturally,

00:03:13.670 --> 00:03:18.480
people are very good at detecting what emotion
is being expressed regardless of the specific

00:03:18.480 --> 00:03:20.560
cultural context that they come from.

00:03:20.560 --> 00:03:25.970
So for example, some early work that was done
with tribesmen in Papa New Guinea who had

00:03:25.970 --> 00:03:30.670
had very little contact with the Western world,
in some cases almost no contact showed that

00:03:30.670 --> 00:03:35.720
when you took photographs of individuals from
a Western society and showed them to individuals

00:03:35.720 --> 00:03:41.560
from these tribes in Papa New Guinea, they
were very accurately able to extract the information

00:03:41.560 --> 00:03:46.960
from those facial expressions and tell you
what emotion was being felt by that individual.

00:03:46.960 --> 00:03:51.270
And when the same was done in reverse and
photographs were taken of those tribesmen

00:03:51.270 --> 00:03:56.510
and taken back to Western societies people
in those Western societies were again very

00:03:56.510 --> 00:04:03.590
able to accurately decode the information
that was being expressed in those faces.

00:04:03.590 --> 00:04:09.790
So this seems to be a universal ability and
it seems to be to some extent relatively uncontaminated

00:04:09.790 --> 00:04:11.130
by cultural specifics.

00:04:11.130 --> 00:04:17.250
That's not to say that there isn't cultural
influence on the way in which we express ourselves

00:04:17.250 --> 00:04:19.870
and the way in which we use nonverbal communication.

00:04:19.870 --> 00:04:21.720
We know that that certainly is the case.

00:04:21.720 --> 00:04:29.000
But when it comes the facial expressions of
emotion, these seem to be universal and relatively,

00:04:29.000 --> 00:04:33.400
modestly influenced by cultural factors.

00:04:33.400 --> 00:04:38.790
So here's an example of just how much information
is contained within facial expressions or

00:04:38.790 --> 00:04:39.820
the face generally.

00:04:39.820 --> 00:04:44.280
This is called the "Mind in the Eyes Test"
which has been produced by Simon Baron-Cohen

00:04:44.280 --> 00:04:45.720
at the University of Cambridge.

00:04:45.720 --> 00:04:51.710
And the question here is simply which of these
emotions do we think is being expressed in

00:04:51.710 --> 00:04:52.710
this particular case.

00:04:52.710 --> 00:04:55.820
So playful, comforting, irritated, bored.

00:04:55.820 --> 00:04:59.880
And you can come to your own conclusions,
I won't ask people to stick their hands up

00:04:59.880 --> 00:05:07.810
but most people would converge on that answer
to these eyes.

00:05:07.810 --> 00:05:13.440
And in this case terrified, upset, arrogant
or annoyed.

00:05:13.440 --> 00:05:22.450
When we're given a range of choices the majority
of people will choose that solution.

00:05:22.450 --> 00:05:26.940
And so there are a range of these that we
can run and we can see that once you're given

00:05:26.940 --> 00:05:32.980
a range of options, in particular then people
are reasonably accurate at identifying which

00:05:32.980 --> 00:05:34.250
of those emotions is being expressed.

00:05:34.250 --> 00:05:38.480
Even in a case where you only have the eyes
to extract that information from.

00:05:38.480 --> 00:05:46.270
And clearly there's other information that
is expressed by other parts of the face.

00:05:46.270 --> 00:05:52.419
And what's interesting is that there are certain
mental health problems or learning disabilities

00:05:52.419 --> 00:05:55.919
that are associated with deficits in the ability
to do this.

00:05:55.919 --> 00:06:01.980
So for example Autism Spectrum Disorder is
associated with a relative inability to correctly

00:06:01.980 --> 00:06:08.260
identify which emotion is being expressed
in this mind in the eyes test.

00:06:08.260 --> 00:06:17.040
And there are individual differences in the
healthy population as well which may or may

00:06:17.040 --> 00:06:24.720
not relate to individual differences in for
example emotional intelligence.

00:06:24.720 --> 00:06:28.600
But to give you an idea of some of the other
information that is expressed by faces, I'm

00:06:28.600 --> 00:06:34.500
gonna show you two short video clips and the
question is, is the face that is moving male

00:06:34.500 --> 00:06:36.660
or female?

00:06:36.660 --> 00:06:39.810
I'm gonna have to come out of the PowerPoint
to do that in a moment.

00:06:39.810 --> 00:06:44.300
But what you can see is that very basic shape
information has been extracted from these

00:06:44.300 --> 00:06:49.440
faces and all you're going to see are points
of light which represent points on the face

00:06:49.440 --> 00:06:51.540
moving as the person speaks.

00:06:51.540 --> 00:06:57.540
So really distilling the information down
and the interface down to its most basic level.

00:06:57.540 --> 00:07:03.230
So is the face male or female?

00:07:03.230 --> 00:07:10.870
This is the first face; you may not want to
make a judgment until you've seen both.

00:07:10.870 --> 00:07:15.440
That's the first face.

00:07:15.440 --> 00:07:20.020
For some reason it's on a loop so it will
keep going unless I stop it.

00:07:20.020 --> 00:07:22.860
And this is the second face.

00:07:22.860 --> 00:07:33.580
The question is which of those faces is male
and which is female?

00:07:33.580 --> 00:07:38.680
Would people feel able to make a judgment,
not necessarily with 100% confidence, but

00:07:38.680 --> 00:07:42.620
with some degree of confidence just having
seen that movement information between the

00:07:42.620 --> 00:07:45.400
two?

00:07:45.400 --> 00:07:46.400
Which do you think was which?

00:07:46.400 --> 00:07:47.400
&gt;&gt;Male 1: I think the second is female.

00:07:47.400 --> 00:07:49.160
&gt;&gt;Marcus: You think the second is female?

00:07:49.160 --> 00:07:50.449
Would most people agree with that?

00:07:50.449 --> 00:07:53.860
That's certainly what most people say and
that's correct.

00:07:53.860 --> 00:07:57.180
So even when you're only represented with
points of light representing points on the

00:07:57.180 --> 00:08:02.380
face and the only information that's being
presented to you is the movements information

00:08:02.380 --> 00:08:06.400
you are able to relatively accurately decode
rather that face is male or female.

00:08:06.400 --> 00:08:10.290
And actually that's true when we look at gate
information when you show similar points of

00:08:10.290 --> 00:08:14.380
light attached to joints on the body when
someone's walking across a room you can very

00:08:14.380 --> 00:08:18.050
accurately decode whether that person is male
or female.

00:08:18.050 --> 00:08:20.560
Whether or not that person is young or old
and so on.

00:08:20.560 --> 00:08:25.560
So there's clearly a lot of information which
is conveyed nonverbally and much of that information

00:08:25.560 --> 00:08:29.640
is conveyed by the face.

00:08:29.640 --> 00:08:32.839
What's interesting is that there are differences
in how good people are at doing that.

00:08:32.839 --> 00:08:36.620
Now the majority of what I'll be talking about
today will relate to various mental health

00:08:36.620 --> 00:08:39.440
problems, low mood, aggressive behavior and
so on.

00:08:39.440 --> 00:08:45.839
But there was a very interesting article published
a couple years ago showing that those from

00:08:45.839 --> 00:08:51.630
wealthier backgrounds, those who enjoyed higher
social economic positions were actually worse

00:08:51.630 --> 00:08:56.610
at these kinds of tasks than those from more
disadvantaged backgrounds or less wealthy

00:08:56.610 --> 00:08:57.990
socioeconomic positions.

00:08:57.990 --> 00:09:02.760
There's something about presumably the way
in which individuals are brought up in those

00:09:02.760 --> 00:09:07.180
different structures of society which means
that those who are most affluent are actually

00:09:07.180 --> 00:09:15.020
less able to accurately decode information
in faces and therefore less able to be empathically

00:09:15.020 --> 00:09:19.130
accurate when making judgments about other
people and interacting with other people.

00:09:19.130 --> 00:09:24.050
It's not clear from the observational data
what the direction of causation is, what causes

00:09:24.050 --> 00:09:25.190
what.

00:09:25.190 --> 00:09:28.790
But there clearly is a relationship and a
relationship that is perhaps counterintuitive

00:09:28.790 --> 00:09:32.860
or a bit paradoxical.

00:09:32.860 --> 00:09:36.730
But our interest has been primarily in the
relationship between the ability to decode

00:09:36.730 --> 00:09:41.920
this information and our emotional well-being
and our mental health.

00:09:41.920 --> 00:09:46.110
And actually if you look across a range of
mental health problems you'll see that there's

00:09:46.110 --> 00:09:53.960
a very strong relationship between these and
the ability to decode emotional biases in

00:09:53.960 --> 00:10:00.290
the extent to which ambiguous expressions
are interpreted as either positive or negative.

00:10:00.290 --> 00:10:06.710
So for example in anxiety and depression there's
a tendency to be sensitive to negative emotions,

00:10:06.710 --> 00:10:09.550
less sensitive to positive emotions.

00:10:09.550 --> 00:10:14.209
In substance use there's a general deficit
in the ability to interpret emotions.

00:10:14.209 --> 00:10:19.930
In conduct disorder there's a general tendency
to interpret ambiguity as hostile or reflecting

00:10:19.930 --> 00:10:21.650
hostile intent.

00:10:21.650 --> 00:10:27.339
Schizophrenia, autism also associated with
a general deficit in the ability to interpret

00:10:27.339 --> 00:10:29.190
emotions.

00:10:29.190 --> 00:10:35.320
So it's surprising how ubiquitous biases and
deficits in the ability to interpret emotions

00:10:35.320 --> 00:10:37.500
are across a range of mental health problems.

00:10:37.500 --> 00:10:40.760
And again it's not clear what the direction
of causation is.

00:10:40.760 --> 00:10:45.380
For example in the case of substance use whether
that be alcoholism, heroin dependence or some

00:10:45.380 --> 00:10:49.610
other form of substance use it may be the
chronic use of the drug is leading to changes

00:10:49.610 --> 00:10:54.060
in your brain which means that you're less
able to decode this information.

00:10:54.060 --> 00:11:01.560
But it's also possible that differences, if
you like, at baseline in the ability to successfully

00:11:01.560 --> 00:11:05.681
navigate our social world because of these
deficits and the ability to interpret emotion

00:11:05.681 --> 00:11:10.940
in others might lead to maladaptive coping
strategies like the use of alcohol to cope

00:11:10.940 --> 00:11:14.209
with that inability to navigate the social
world.

00:11:14.209 --> 00:11:18.640
So an important question here is, what comes
first and what is the causal relationship

00:11:18.640 --> 00:11:25.620
between these information processing biases
and mental health?

00:11:25.620 --> 00:11:32.930
So there are a range of different cognitive
biases that color the way in which we process

00:11:32.930 --> 00:11:34.350
information in the world around us.

00:11:34.350 --> 00:11:39.140
And the range of these have been described
in relation to different mental health problems.

00:11:39.140 --> 00:11:46.560
So for example, attentional bias is a tendency
to pay attention to something which we think

00:11:46.560 --> 00:11:51.589
is important at the expense of something which
may in fact be important.

00:11:51.589 --> 00:11:56.670
In other words to focus our attention on things
which are particularly salient at this point

00:11:56.670 --> 00:11:58.709
in time.

00:11:58.709 --> 00:12:02.910
A good example of that is the cocktail party
affect where you'll be in a crowded room chatting

00:12:02.910 --> 00:12:06.779
to someone who's in front of you and your
focus of attention will be on that person,

00:12:06.779 --> 00:12:10.990
but then if you hear your name in the background,
babble of conversation that you weren't paying

00:12:10.990 --> 00:12:15.399
attention to previously your attention shifts
towards that conversation because you've heard

00:12:15.399 --> 00:12:16.399
your name.

00:12:16.399 --> 00:12:18.680
And that phenomenon is well described.

00:12:18.680 --> 00:12:24.660
Another example of attentional bias is that
if we walk down a street in the middle of

00:12:24.660 --> 00:12:28.959
a night, we're very sensitive to the sound
of twigs cracking, shapes in bushes and that

00:12:28.959 --> 00:12:29.959
kind of thing.

00:12:29.959 --> 00:12:33.920
So the heightened arousal and anxiety that
we might feel in that situation focuses our

00:12:33.920 --> 00:12:38.060
attention on certain things in a way that
it wouldn't do if we were just walking down

00:12:38.060 --> 00:12:40.410
that same street in the middle of the day.

00:12:40.410 --> 00:12:44.339
So attentional biases have been well described
in particular in relation to anxiety.

00:12:44.339 --> 00:12:47.540
This tendency to focus on threat.

00:12:47.540 --> 00:12:52.080
There are also memory biases, these are more
characteristic of depression that when we're

00:12:52.080 --> 00:12:58.360
in a depressed state we're more likely to
remember negative autobiographical experiences.

00:12:58.360 --> 00:13:02.691
Bad things that happen to us in the past tend
to dominate our thinking in a way that they

00:13:02.691 --> 00:13:06.709
don't when were in a more positive frame of
mind.

00:13:06.709 --> 00:13:10.920
And again the question is to what extent does
one cause the other?

00:13:10.920 --> 00:13:18.959
And to what extent do individuals become trapped
in a vicious cycle once those memory biases

00:13:18.959 --> 00:13:22.160
start to dominate so that you're always thinking
about negative events in the past.

00:13:22.160 --> 00:13:27.480
And that tends to maintain your depressed
mood which in turn tends to maintain your

00:13:27.480 --> 00:13:29.709
negative memory biases.

00:13:29.709 --> 00:13:34.120
And what's interesting is that antidepressant
drugs which are effective for depression seem

00:13:34.120 --> 00:13:39.900
to modify these cognitive biases.

00:13:39.900 --> 00:13:43.880
So although these cognitive biases may play
a causal role, they may be modifiable.

00:13:43.880 --> 00:13:49.660
And then there are also interpretive biases,
so here we have a sentence which can be interpreted

00:13:49.660 --> 00:13:51.810
in a couple of different ways.

00:13:51.810 --> 00:13:57.720
And depending in part on your personal history
but also in part on your mood state you can

00:13:57.720 --> 00:14:05.240
either interpret that negatively or positively.

00:14:05.240 --> 00:14:07.940
So the same sentence can be disambiguated
in a couple of different ways.

00:14:07.940 --> 00:14:14.370
And the way in which you disambiguate that
sentence tends to correlate with your emotional

00:14:14.370 --> 00:14:17.470
state.

00:14:17.470 --> 00:14:26.750
And actually there's growing consensus that
drugs which are used to treat mental health

00:14:26.750 --> 00:14:34.310
problems in particular like anxiety and depression
may in fact operate via these cognitive biases.

00:14:34.310 --> 00:14:39.690
By directly changing those cognitive biases,
antidepressant drugs typically have to be

00:14:39.690 --> 00:14:42.560
taken for a couple weeks before they begin
to have their affect.

00:14:42.560 --> 00:14:48.630
And the perceived wisdom until recently was
that that is because of the need for downstream

00:14:48.630 --> 00:14:52.089
changes in brain chemistry to occur once you
start taking the drug.

00:14:52.089 --> 00:14:57.720
An alternative explanation is that these drugs
directly change the way in which you see the

00:14:57.720 --> 00:15:01.970
world via these cognitive biases that I've
described.

00:15:01.970 --> 00:15:05.890
But in order for that to have an impact on
your mood you need to start going out into

00:15:05.890 --> 00:15:10.779
the world and interacting with people so that
that new way of seeing the world and that

00:15:10.779 --> 00:15:15.579
new way of seeing other people in the world
leads to a change in your behavior towards

00:15:15.579 --> 00:15:20.079
those people, and then a change in the behavior
that's reciprocated back to you from those

00:15:20.079 --> 00:15:25.700
people so that you establish a virtuous cycle
where you're basically engaging more positively

00:15:25.700 --> 00:15:29.730
in people in the world around you because
of this change in the way in which you see

00:15:29.730 --> 00:15:36.060
the world and that then leads to improvements
in mood downstream of that.

00:15:36.060 --> 00:15:42.829
But if that's true then of course another
possibility is to work directly on the cognitive

00:15:42.829 --> 00:15:49.950
bias without any drugs, without any of pharmaceutical
therapy using purely behavioral techniques.

00:15:49.950 --> 00:15:52.730
So that's what we've done.

00:15:52.730 --> 00:15:57.560
Using faces that express varying degrees of
emotion.

00:15:57.560 --> 00:16:03.290
So we have a sequence of faces which contain
more or less of a particular emotion or a

00:16:03.290 --> 00:16:05.200
blend of different emotions.

00:16:05.200 --> 00:16:10.750
So as you move along the sequence, that face
is reasonably ambiguous.

00:16:10.750 --> 00:16:18.829
But as we begin to add a motion to that face,
by the time we get to the end of the sequence

00:16:18.829 --> 00:16:21.230
it's relatively unambiguous.

00:16:21.230 --> 00:16:24.550
Most people would say that that person was
sad.

00:16:24.550 --> 00:16:29.220
And if we line up all the faces together you
can see that there is a gradual change.

00:16:29.220 --> 00:16:35.850
And the point at which different individuals
begin to identify that emotion reliably gives

00:16:35.850 --> 00:16:40.639
us a measure of that person's sensitivity
to that particular emotion.

00:16:40.639 --> 00:16:44.399
And we can do the same with different blends
of emotion where the faces in the middle are

00:16:44.399 --> 00:16:50.220
ambiguous and the question is which of the
two emotions that it contains dominates for

00:16:50.220 --> 00:16:52.310
you in particular.

00:16:52.310 --> 00:16:59.470
And the working model behind this is that
as observers of others in our social world,

00:16:59.470 --> 00:17:05.549
when we see other people most of the time
people's facial expressions are ambiguous.

00:17:05.549 --> 00:17:11.540
And so we need to overlay some interpretation
on that potentially ambiguous facial expression.

00:17:11.540 --> 00:17:17.510
And the interpretation that we make if it's
negative will tend to sustain a vicious cycle

00:17:17.510 --> 00:17:25.790
whereby if we think people are looking at
us in a particular way, if they are harboring

00:17:25.790 --> 00:17:30.500
some hostile intent towards us for example
then we're going to respond appropriately

00:17:30.500 --> 00:17:33.110
relative to what we think they're thinking.

00:17:33.110 --> 00:17:37.570
But which may be inappropriate if that's not
what they're actually thinking.

00:17:37.570 --> 00:17:44.770
Conversely if we can shift that initial attributional
bias, that interpretive bias so that these

00:17:44.770 --> 00:17:50.350
ambiguous faces begin to be seen as more positive
on average then of course we can establish

00:17:50.350 --> 00:17:55.150
a virtuous cycle whereby we start to see people
more positively.

00:17:55.150 --> 00:17:59.480
Behave towards them more positively and we
would hope they would behave back towards

00:17:59.480 --> 00:18:02.760
us more positively in return.

00:18:02.760 --> 00:18:08.260
So what we're targeting here is the way in
which people see the world around them to

00:18:08.260 --> 00:18:14.370
try and shift that in a positive and potentially
therapeutic direction.

00:18:14.370 --> 00:18:19.240
So those are the questions, can we change
the way people perceive ambiguous expressions?

00:18:19.240 --> 00:18:20.240
That's not trivial.

00:18:20.240 --> 00:18:26.240
The ability to do that isn't a given and we
need to ask that question first.

00:18:26.240 --> 00:18:33.700
But then if we can do that does that lead
to changes, improvements in behavior?

00:18:33.700 --> 00:18:38.620
So the way in which we do this is using a
very simple computer task run off a laptop

00:18:38.620 --> 00:18:40.130
or a tablet.

00:18:40.130 --> 00:18:42.800
We've versions of this that run on smartphones
as well.

00:18:42.800 --> 00:18:47.700
Where you present people with a screen that
they fixate on, so there's a fixation cross

00:18:47.700 --> 00:18:50.950
just to make sure they're looking in the right
place.

00:18:50.950 --> 00:18:56.440
Then very briefly, for 150 milliseconds we
present one of these faces along one of these

00:18:56.440 --> 00:18:59.960
sequences that ranges from say neutral to
happy.

00:18:59.960 --> 00:19:03.380
Or from sad to happy.

00:19:03.380 --> 00:19:08.230
Then we mask that image to remove any visual
after affects so that the image doesn't hang

00:19:08.230 --> 00:19:12.419
around for longer than the hundred and 150
milliseconds that we want it to.

00:19:12.419 --> 00:19:18.020
And then we simply ask people to judge whether
that face is happy or angry say, or happy

00:19:18.020 --> 00:19:23.411
or sad depending on the sequence of faces
that we use here.

00:19:23.411 --> 00:19:27.030
And people can answer this in their own time.

00:19:27.030 --> 00:19:32.540
And so what we get from that is a measure
of the points along the sequence at which

00:19:32.540 --> 00:19:38.080
people stop seeing one emotion and begin seeing
another emotion.

00:19:38.080 --> 00:19:41.020
So this particular sequence ranges from happy
to sad.

00:19:41.020 --> 00:19:44.880
On the left-hand side you have an ambiguously
happy face, everyone says that's happy.

00:19:44.880 --> 00:19:48.690
On the right-hand side you have an unambiguously
angry face, everyone says that angry.

00:19:48.690 --> 00:19:53.370
In the middle you have this region of ambiguity
and there's a point at which an individual

00:19:53.370 --> 00:19:57.850
will stop seeing one emotion and start seeing
another emotion.

00:19:57.850 --> 00:20:01.730
And where that point is will differ across
individuals.

00:20:01.730 --> 00:20:09.500
So we measure that point and then in a feedback
phase we run exactly the same kind of task

00:20:09.500 --> 00:20:14.450
but we provide feedback based on that initial
threshold that we've measured.

00:20:14.450 --> 00:20:19.539
The idea being that we can shift people so
that the faces that they previously said were

00:20:19.539 --> 00:20:23.370
angry we say, that wasn't angry that was happy.

00:20:23.370 --> 00:20:25.150
And we try to shift their threshold.

00:20:25.150 --> 00:20:29.050
And we have a control condition, a comparison
condition where the feedback is designed to

00:20:29.050 --> 00:20:31.520
keep their threshold the same.

00:20:31.520 --> 00:20:40.270
And so all we're using his explicit feedback
to try and shift that threshold.

00:20:40.270 --> 00:20:46.110
So what we end up with is someone who moves
from a particular threshold prior to training

00:20:46.110 --> 00:20:49.410
which is the top panel.

00:20:49.410 --> 00:20:52.750
To a different threshold after training which
is the bottom panel which is that this face

00:20:52.750 --> 00:21:00.910
in the middle that was previously described
as angry is now described as happy.

00:21:00.910 --> 00:21:01.910
So can we do this?

00:21:01.910 --> 00:21:08.520
And can we do this in a way which is beneficial
for the well-being of the individuals concerned?

00:21:08.520 --> 00:21:14.160
So in our first experiment, we looked at 80
otherwise healthy volunteers who had high

00:21:14.160 --> 00:21:15.570
levels of depression symptoms.

00:21:15.570 --> 00:21:20.440
We didn't select them on the basis of a clinical
diagnosis of depression, but about 70% of

00:21:20.440 --> 00:21:26.110
them had levels of depression that would be
indicative of clinical depression.

00:21:26.110 --> 00:21:29.110
Part the issue here is that a lot of people
suffer from depression but don't necessarily

00:21:29.110 --> 00:21:35.350
seek support for it, don't necessarily go
to their GP for some kind of treatment.

00:21:35.350 --> 00:21:41.289
So there's no real kind of unmet need for
these kind of symptoms to be addressed.

00:21:41.289 --> 00:21:48.590
And we used a sequence that ranged from happy
to sad given prior evidence that depression

00:21:48.590 --> 00:21:53.940
is associated with a relative sensitivity,
heightened sensitivity to sad facial expressions

00:21:53.940 --> 00:21:57.870
and a reduced sensitivity to happily facial
expressions.

00:21:57.870 --> 00:22:03.430
So the idea of the training was to shift the
point at which people stopped seeing happiness

00:22:03.430 --> 00:22:07.250
and started seeing sadness to increase the
extent to which ambiguous expressions were

00:22:07.250 --> 00:22:08.640
perceived as happy.

00:22:08.640 --> 00:22:10.880
And people were randomized to one of two conditions.

00:22:10.880 --> 00:22:15.190
In one condition their threshold wasn't shifted
it was kept the same and in the other condition

00:22:15.190 --> 00:22:19.929
it was shifted in the way that I've described.

00:22:19.929 --> 00:22:24.430
First of all, at baseline bearing in mind
that people differ in the point at which that

00:22:24.430 --> 00:22:30.940
threshold occurs those with low mood were
more inclined to see sadness over happiness

00:22:30.940 --> 00:22:35.530
than a controlled sample of individuals who
have normal levels of mood.

00:22:35.530 --> 00:22:43.100
So this does seem to be to some extent predictive
of emotional state where you start from if

00:22:43.100 --> 00:22:44.100
you like.

00:22:44.100 --> 00:22:51.240
So you can regard this in some way as an attempt
to bring the low mood sample up to the point

00:22:51.240 --> 00:22:55.179
where the healthy sample already are.

00:22:55.179 --> 00:22:56.700
So the first question is can we do this?

00:22:56.700 --> 00:23:00.830
Can we shift the way in which people interpret
emotional expressions in others?

00:23:00.830 --> 00:23:02.530
And the answer is yes we can.

00:23:02.530 --> 00:23:06.100
We ran the training over four consecutive
days.

00:23:06.100 --> 00:23:08.620
The training lasted about 20 minutes.

00:23:08.620 --> 00:23:13.919
The red bar represents the control group that
were given feedback designed to keep their

00:23:13.919 --> 00:23:14.919
threshold the same.

00:23:14.919 --> 00:23:17.860
And you can see that it doesn't change.

00:23:17.860 --> 00:23:24.179
And those in the green bar were given feedback
that was designed to shift their threshold

00:23:24.179 --> 00:23:25.880
and we can see that it did.

00:23:25.880 --> 00:23:30.850
And most importantly although there was a
slight drop back every day from pre to post

00:23:30.850 --> 00:23:37.190
testing and then to pretesting on the next
day, some of that shift that we'd achieved

00:23:37.190 --> 00:23:40.360
during training carried over after they left
the lab if you like.

00:23:40.360 --> 00:23:44.660
So they took some of that training away with
them out into that social world so that their

00:23:44.660 --> 00:23:50.330
interactions with other people would be modified
by that change in which they were seeing other

00:23:50.330 --> 00:23:51.330
people.

00:23:51.330 --> 00:23:55.000
And by the end of the four days of training
there was quite a marked difference between

00:23:55.000 --> 00:23:59.000
our control group and our training group.

00:23:59.000 --> 00:24:00.930
So that answers the first question.

00:24:00.930 --> 00:24:03.850
The second question is does it have an effect
on people's mood?

00:24:03.850 --> 00:24:05.990
And the short answer is yes it does.

00:24:05.990 --> 00:24:11.770
We measured people's mood before training,
immediately after training and then followed

00:24:11.770 --> 00:24:13.340
them up two weeks later.

00:24:13.340 --> 00:24:17.429
And in that two-week interim, they hadn't
done any more training, they were simply taking

00:24:17.429 --> 00:24:23.090
the training that they had done over those
four days away with them if you like.

00:24:23.090 --> 00:24:29.500
And we can see that at follow-up there was
a large and statistically significant difference

00:24:29.500 --> 00:24:33.530
in the levels of positive mood reported by
those who had received the training compared

00:24:33.530 --> 00:24:35.860
to those that were in the control condition.

00:24:35.860 --> 00:24:42.450
So this training did seem to have a positive
impact on people's mood.

00:24:42.450 --> 00:24:46.960
A second experiment that we ran was in a quite
different sample of individuals.

00:24:46.960 --> 00:24:51.530
Adolescents aged 11 to 16 years old who were
referred to our youth program on the basis

00:24:51.530 --> 00:24:53.470
of being at high risk of criminal offending.

00:24:53.470 --> 00:24:59.290
About 70% of them had an official record of
criminal offending, stealing cars, dealing

00:24:59.290 --> 00:25:04.169
drugs, antisocial behavior, aggressive behavior
and they were all screened to have high levels

00:25:04.169 --> 00:25:05.169
of aggressive behavior.

00:25:05.169 --> 00:25:07.720
So this is not a particularly easy to reach
group.

00:25:07.720 --> 00:25:14.840
And certainly any behavior changes that we
can initiate in this group are likely to be

00:25:14.840 --> 00:25:19.900
beneficial both to the individuals and to
society at large.

00:25:19.900 --> 00:25:24.539
Here we use a slightly different sequence
of faces that range from happy to angry.

00:25:24.539 --> 00:25:31.030
Again based on our prior literature that aggressive
behavior tends to be associated with an increased

00:25:31.030 --> 00:25:33.710
attribution of hostility in other people.

00:25:33.710 --> 00:25:38.600
And that's what we wanted to target.

00:25:38.600 --> 00:25:45.559
We were able to change the perceptions of
emotional faces, ambiguous emotional faces

00:25:45.559 --> 00:25:47.530
in exactly the same way as in the depression
study.

00:25:47.530 --> 00:25:52.909
And we ran the training in exactly the same
way over four consecutive days with each session

00:25:52.909 --> 00:25:55.130
lasting approximately 20 minutes.

00:25:55.130 --> 00:25:58.490
And again people were randomized to either
be in a control condition or the training

00:25:58.490 --> 00:25:59.490
condition.

00:25:59.490 --> 00:26:04.370
And here we rated, asked participants to rate
their own aggressive behavior.

00:26:04.370 --> 00:26:09.809
And they did that one week after training
and two weeks after training and you can see

00:26:09.809 --> 00:26:15.919
that their own ratings of their own aggressive
behavior changed so that there was a decrease

00:26:15.919 --> 00:26:20.240
in self-rated aggressive behavior in the training
condition relative to the control edition.

00:26:20.240 --> 00:26:25.400
What was more exciting was that we also got
staff on the program who didn't know which

00:26:25.400 --> 00:26:31.809
condition they'd been allocated to so they
weren't biased in their judgments on the basis

00:26:31.809 --> 00:26:35.970
of knowing in advance which condition these
individuals had been placed in.

00:26:35.970 --> 00:26:40.560
And there we showed that on the basis of those
independent ratings and behavior there was

00:26:40.560 --> 00:26:45.400
a 30% decrease in aggressive behavior in the
training group compared to the control group.

00:26:45.400 --> 00:26:49.030
And that persisted for up to two weeks after
the training ended.

00:26:49.030 --> 00:26:56.909
And if anything the improvements strengthened
over time even after the training had ended

00:26:56.909 --> 00:27:01.020
which is consistent with this idea that what
we're doing is subtly shifting the way in

00:27:01.020 --> 00:27:05.390
which these people are seeing the world around
them and breaking them out of that vicious

00:27:05.390 --> 00:27:09.929
cycle and putting them into a virtuous cycle
where they begin to interact more positively

00:27:09.929 --> 00:27:12.700
with their wider social world.

00:27:12.700 --> 00:27:17.210
Where do we go next with this?

00:27:17.210 --> 00:27:22.740
We've got two studies which provide us with
very promising evidence that actually we can

00:27:22.740 --> 00:27:27.380
shift the way in which people see others in
the world around them and do so in a way which

00:27:27.380 --> 00:27:32.950
is therapeutic at least with respect to particularly
problems associated with those individuals

00:27:32.950 --> 00:27:35.980
whether it be low mood or aggressive behavior.

00:27:35.980 --> 00:27:41.120
We're looking at different ways of achieving
the same end.

00:27:41.120 --> 00:27:45.320
The version of the training that I showed
you is one which is very explicit, you tell

00:27:45.320 --> 00:27:47.870
people that wasn't a happy face, that was
a happy face.

00:27:47.870 --> 00:27:53.590
And there's a question over to what extent
you're essentially leading people into responding

00:27:53.590 --> 00:27:58.340
a certain way whether than genuinely changing
anything about their perceptions of people

00:27:58.340 --> 00:27:59.500
in the world around them.

00:27:59.500 --> 00:28:04.870
Now my view would be that while that may be
true for the healthy volunteers sample that

00:28:04.870 --> 00:28:11.100
we recruited for the depression study it's
unlikely to be true for the 11 to 16-year-old

00:28:11.100 --> 00:28:14.950
individuals who are at high risk of offending
simply because that's not the kind of population

00:28:14.950 --> 00:28:17.120
that are simply going to do what you asked
him to do.

00:28:17.120 --> 00:28:20.240
And if it was that simple then there wouldn't
need to be people like me doing this kind

00:28:20.240 --> 00:28:24.289
of research we'd just tell them to behave
better and it doesn't work like that.

00:28:24.289 --> 00:28:28.340
But we have been looking at other techniques
to achieve the same end.

00:28:28.340 --> 00:28:35.179
And so what you see on the screen front of
you is what is described as "n-back" working

00:28:35.179 --> 00:28:40.070
memory task where you're presented with a
series of faces sequentially on the screen

00:28:40.070 --> 00:28:44.650
and the idea is to determine whether or not
the face that you're looking at is the same

00:28:44.650 --> 00:28:48.870
as the one that appeared two faces back.

00:28:48.870 --> 00:28:54.640
So you can see that as you move down from
top left to bottom right the second face that

00:28:54.640 --> 00:28:57.549
appears also appears two frames later.

00:28:57.549 --> 00:29:01.100
So when it appeared two frames later it'll
be a target because that face had appeared

00:29:01.100 --> 00:29:02.100
two frames previously.

00:29:02.100 --> 00:29:07.840
So you have to hold the information in your
working memory.

00:29:07.840 --> 00:29:13.210
But what this is also doing is forcing you
to focus on the facial expressions.

00:29:13.210 --> 00:29:21.529
And that means that we can make use of this
to implement what's called visual adaptation.

00:29:21.529 --> 00:29:27.279
Now visual adaptation is something that you
can all experience if you have a waterfall

00:29:27.279 --> 00:29:30.050
at hand or if you're traveling in a moving
vehicle.

00:29:30.050 --> 00:29:36.090
It's the tendency for your brain to adapt
to consistent visual input and essentially

00:29:36.090 --> 00:29:37.409
cancel that out.

00:29:37.409 --> 00:29:41.299
So that when you look at something that doesn't
include that visual input, you get the reverse

00:29:41.299 --> 00:29:42.299
effect.

00:29:42.299 --> 00:29:45.980
So when you look at a waterfall for an extended
period and then you look away everything seems

00:29:45.980 --> 00:29:47.720
to be drifting upwards.

00:29:47.720 --> 00:29:50.539
Similarly when you're in a moving vehicle
and it works best if you're sat at the back

00:29:50.539 --> 00:29:55.429
looking out back your visual field is moving
in one direction and when that vehicle comes

00:29:55.429 --> 00:29:59.390
to a halt everything seems to creep back in
the opposite direction slightly.

00:29:59.390 --> 00:30:01.600
You might be familiar with that affect, that's
visual adaptation.

00:30:01.600 --> 00:30:05.809
And actually we can get visual adaptation
for facial features.

00:30:05.809 --> 00:30:11.150
So if I were to show you lots of faces with
people's eyes very wide apart and then get

00:30:11.150 --> 00:30:14.540
you to look at a normal face the eyes would
look very close together.

00:30:14.540 --> 00:30:17.039
And that's visual adaptation.

00:30:17.039 --> 00:30:21.659
But you can get visual adaptation effects
for emotional content in faces as well.

00:30:21.659 --> 00:30:28.030
So if you look at lots of angry faces then
you look at a neutral face that neutral face

00:30:28.030 --> 00:30:32.530
looks a little bit happier, a little bit more
positive.

00:30:32.530 --> 00:30:35.680
So in a follow-up experiment, we did exactly
that.

00:30:35.680 --> 00:30:38.770
Showing people using this kind of task where
they just have to focus on the faces being

00:30:38.770 --> 00:30:44.929
presented on the screen either 50-50 happy
angry faces which wouldn't lead to any visual

00:30:44.929 --> 00:30:50.350
adaptation or lots and lots of angry faces
which would lead to visual adaptation so that

00:30:50.350 --> 00:30:53.809
neutral faces would be seen as more positive.

00:30:53.809 --> 00:30:55.990
And then we got them to rate their mood.

00:30:55.990 --> 00:31:02.169
And the group that had looked at lots of angry
faces reported feeling less angry.

00:31:02.169 --> 00:31:07.419
Which is completely paradoxical but entirely
consistent with our earlier studies because

00:31:07.419 --> 00:31:13.770
what we're doing is shifting that perception
so that neutral faces, ambiguous faces start

00:31:13.770 --> 00:31:18.330
to be seen as more positive because of this
spatial adaptation affect.

00:31:18.330 --> 00:31:23.779
So paradoxically, you look at lots of angry
faces you feel less angry in the context of

00:31:23.779 --> 00:31:25.419
this specific study.

00:31:25.419 --> 00:31:27.039
And there are lots of other things that we
can do with this.

00:31:27.039 --> 00:31:32.140
So for example, we've run versions where instead
of modifying emotional content in faces we've

00:31:32.140 --> 00:31:36.750
modified the extent to which a face is socially
dominant.

00:31:36.750 --> 00:31:41.780
Social dominance is an important driver of
behavior in itself and there are characteristics

00:31:41.780 --> 00:31:46.960
of faces which are correlated with drivers
of those behavior such as testosterone levels.

00:31:46.960 --> 00:31:48.730
Essentially it's a masculinity transform.

00:31:48.730 --> 00:31:53.140
So a socially dominant face is one with a
big jaw, solid eyebrows, that kind of thing.

00:31:53.140 --> 00:31:57.380
And more submissive faces, one which is more
feminine in its characteristics.

00:31:57.380 --> 00:32:03.340
And there's a lot of evidence that people
for example engaged in behavior economic tasks

00:32:03.340 --> 00:32:09.649
will modify the deals that they engage in
based on perceived characteristics of the

00:32:09.649 --> 00:32:12.580
person that they think they are making that
deal with.

00:32:12.580 --> 00:32:17.370
And we can modify the way in which people
see others in the world around them using

00:32:17.370 --> 00:32:26.110
that kind of information as well to make other
people look more or less socially dominant.

00:32:26.110 --> 00:32:31.640
There are also other channels of information
that I haven't talked about today but which

00:32:31.640 --> 00:32:37.029
are potentially important and which may add
context to the one channel of information

00:32:37.029 --> 00:32:39.290
that I have been talking about, facial expressions
of emotion.

00:32:39.290 --> 00:32:44.169
So here we can see for example a very nice
illustration of how exactly the same facial

00:32:44.169 --> 00:32:51.390
expression can become disambiguated in different
ways depending on other contextual information

00:32:51.390 --> 00:32:53.740
in this case postural information.

00:32:53.740 --> 00:32:57.029
So I don't want to make claims that go too
far.

00:32:57.029 --> 00:33:02.200
In that facial expressions while important
are only one channel of information and in

00:33:02.200 --> 00:33:06.770
the real world, if you like, there are multiple
channels of information that are operating

00:33:06.770 --> 00:33:11.600
in parallel and it's the combination of all
those which lead to us making our particular

00:33:11.600 --> 00:33:12.600
judgment.

00:33:12.600 --> 00:33:15.970
If we can change one of those, and that can
potentially have some impact.

00:33:15.970 --> 00:33:22.850
But we would probably, if we wanted to do
a comprehensive job, work on multiple channels.

00:33:22.850 --> 00:33:29.740
But there's a great deal of interest in the
extent to which these kinds of studies can

00:33:29.740 --> 00:33:34.950
lead to intervention which could, in principle,
be delivered very easily, cheaply, remotely

00:33:34.950 --> 00:33:41.779
via laptops, home computers, tablets, smart
phones and in particular tablets and smart

00:33:41.779 --> 00:33:46.010
phones have an interface which lends itself
very well to this kind of interaction because

00:33:46.010 --> 00:33:49.740
of the high quality screens and so on that
allow us to present the images that are central

00:33:49.740 --> 00:33:55.290
to this, critical to these interventions,
in a very accessible and user-friendly way.

00:33:55.290 --> 00:34:00.299
And this cartoon is taken from an article
in "The Economist" a couple years ago which

00:34:00.299 --> 00:34:05.970
talked about the growing interest in computerized
interventions for well-being mental health

00:34:05.970 --> 00:34:10.369
problems and so on.

00:34:10.369 --> 00:34:15.059
So I'd just like to end by thanking all of
the funding councils that support this research

00:34:15.059 --> 00:34:17.290
and for your patience in listening to me.

00:34:17.290 --> 00:34:21.859
And I'm more than happy to answer any questions
that anyone might have at this stage.

00:34:21.859 --> 00:34:25.530
And people might need to get away in which
case please feel free to, but if you have

00:34:25.530 --> 00:34:29.889
a question please ask.

00:34:29.889 --> 00:34:31.859
Yes.

00:34:31.859 --> 00:34:49.909
&gt;&gt;Male 2: [Inaudible], it wasn't clear [inaudible]
&gt;&gt;Marcus: So the scales are somewhat arbitrary

00:34:49.909 --> 00:34:54.690
in that they are for the most part questionnaire
measures or diary measures of behavior.

00:34:54.690 --> 00:34:59.060
Which allow you to show relative change if
you like.

00:34:59.060 --> 00:35:02.910
But in and of themselves don't necessarily
tell you whether or not that change is clinically

00:35:02.910 --> 00:35:04.109
significant.

00:35:04.109 --> 00:35:08.819
Certainly the magnitude of affect that we
observed in the young offenders was sufficiently

00:35:08.819 --> 00:35:14.410
large, but it would almost certainly be beneficial
if it scaled up.

00:35:14.410 --> 00:35:19.220
If it were shown to be a reliable affect that
was persistent, then that would be a change

00:35:19.220 --> 00:35:21.200
that would be valuable.

00:35:21.200 --> 00:35:27.769
The change in positive mood that was identified
in the depression study is of an order of

00:35:27.769 --> 00:35:33.369
magnitude that would be consistent with people
actually subjectively feeling better in themselves.

00:35:33.369 --> 00:35:37.380
But we're running a larger scale follow-up
at the moment just to confirm that when we

00:35:37.380 --> 00:35:42.279
see these changes in how people complete questionnaires
about their mood it actually maps onto how

00:35:42.279 --> 00:35:44.609
they feel in themselves and whether they feel
better.

00:35:44.609 --> 00:35:50.769
&gt;&gt;Male 3: [inaudible]
&gt;&gt;Marcus: No, were doing a follow-up study

00:35:50.769 --> 00:35:53.890
which is a new group of people where we'll
follow them up for a longer period and take

00:35:53.890 --> 00:35:55.519
more comprehensive measures.

00:35:55.519 --> 00:36:00.729
&gt;&gt;Male 3: [inaudible]
&gt;&gt;Marcus: No, no that was just a pilot study

00:36:00.729 --> 00:36:03.240
essentially to establish the proof of principle.

00:36:03.240 --> 00:36:04.719
It looked very encouraging.

00:36:04.719 --> 00:36:08.209
Two weeks is a reasonably long time given
that they're not doing anything in between.

00:36:08.209 --> 00:36:12.749
So to show an improvement in mood that persists
for that length of time is certainly encouraging.

00:36:12.749 --> 00:36:17.359
But you are right we need to do this more
comprehensively just to establish in principle

00:36:17.359 --> 00:36:22.250
that these improvements, if they're reliable,
are clinically significant and actually make

00:36:22.250 --> 00:36:25.550
a difference to how people feel in themselves
which is ultimately what it boils down to.

00:36:25.550 --> 00:36:33.420
&gt;&gt;Male 4: So do you see a scenario where doctors
[inaudible]

00:36:33.420 --> 00:36:36.109
&gt;&gt;Marcus: Potentially.

00:36:36.109 --> 00:36:42.509
I mean we're moving in that direction already.

00:36:42.509 --> 00:36:47.880
So for example cognitive behavioral therapy
is the psychological therapy of choice within

00:36:47.880 --> 00:36:51.180
the national health services at the moment.

00:36:51.180 --> 00:36:55.839
But it can be very expensive to deliver because
it requires one to one time with a therapist

00:36:55.839 --> 00:36:57.420
who is trained in that skill.

00:36:57.420 --> 00:37:01.440
There are computerized versions of cognitive
behavioral therapy which are increasingly

00:37:01.440 --> 00:37:05.470
being recommended because they're highly cost-effective
as long as people engage with them adequately.

00:37:05.470 --> 00:37:09.359
Now the problem with a lot of computerized
cognitive behavioral therapy is that it's

00:37:09.359 --> 00:37:10.950
quite demanding, quite time-consuming.

00:37:10.950 --> 00:37:15.109
You have to go away and do homework and come
back to it and so on.

00:37:15.109 --> 00:37:21.180
So there's probably a place in conjunction
with that for something which is more rapid

00:37:21.180 --> 00:37:23.589
and targeted of the kind that I've described.

00:37:23.589 --> 00:37:28.670
But absolutely I think increasingly that will
be the way in which several healthcare services

00:37:28.670 --> 00:37:29.670
are delivered.

00:37:29.670 --> 00:37:34.469
And the NHS already has a number of apps that
you can use to monitor various health behaviors.

00:37:34.469 --> 00:37:42.549
&gt;&gt;Male 5: So all of your participants, all
the training can be in a controlled environment.

00:37:42.549 --> 00:37:43.930
[Inaudible]?

00:37:43.930 --> 00:37:51.119
&gt;&gt;Marcus: No we didn't exclude people on the
basis of antidepressant medication, but because

00:37:51.119 --> 00:37:54.469
only I think about 30% actually had a clinical
diagnosis.

00:37:54.469 --> 00:37:57.920
The majority weren't taking any form of treatment
at the time.

00:37:57.920 --> 00:38:03.299
Again in our follow-up study, we are being
slightly more stringent about our inclusion

00:38:03.299 --> 00:38:07.180
and exclusion criteria just to select people
that aren't taking antidepressant medication

00:38:07.180 --> 00:38:12.079
simply because those pharmaceutical therapies
as I mentioned at the beginning have been

00:38:12.079 --> 00:38:14.630
shown in themselves to modify these kinds
of biases.

00:38:14.630 --> 00:38:19.230
So it could potentially contaminate our results
somewhat.

00:38:19.230 --> 00:38:34.079
&gt;&gt;Male 6: [Inaudible] Research on how people
feel in different social cultures.

00:38:34.079 --> 00:38:46.751
I mean, there is American culture [inaudible]
and European culture where people are more

00:38:46.751 --> 00:38:55.569
serious, so how individuals feel in those
cultures themselves and [inaudible]

00:38:55.569 --> 00:38:57.499
&gt;&gt;Marcus: That's a really good question.

00:38:57.499 --> 00:39:01.849
I am not aware of any research on that which
isn't to say that it hasn't been done but

00:39:01.849 --> 00:39:04.619
just that I'm not aware of it.

00:39:04.619 --> 00:39:08.440
But you could absolutely see how that could
be the case because actually having lived

00:39:08.440 --> 00:39:12.009
in different countries myself often it's the
mismatch between your sort of expectation

00:39:12.009 --> 00:39:15.460
and the way in which you're interpreting what's
going on around you and what other people

00:39:15.460 --> 00:39:21.940
are thinking and doing and expecting you to
take from that interaction that can be the

00:39:21.940 --> 00:39:22.940
problem.

00:39:22.940 --> 00:39:27.499
So you could see that if there were differences
in the way that information was expressed

00:39:27.499 --> 00:39:31.730
by one individual that didn't translate to
a different culture then that could certainly

00:39:31.730 --> 00:39:36.109
lead to problems when it came to feeling comfortable
in that culture.

00:39:36.109 --> 00:39:37.299
And that wouldn't surprise me at all.

00:39:37.299 --> 00:39:40.839
Like I say, I'm not aware of any research
that looks at that explicitly, but I certainly

00:39:40.839 --> 00:39:44.650
would expect that to play part.

00:39:44.650 --> 00:39:52.599
&gt;&gt;Male 7: The sequence of faces, how do you
create it?

00:39:52.599 --> 00:39:59.339
&gt;&gt;Marcus: So the person, so to speak, is not
a real person but it's a composite of multiple

00:39:59.339 --> 00:40:01.410
faces so that it is like an average person.

00:40:01.410 --> 00:40:05.520
So there's nothing particularly distinctive
about him and we have female versions as well.

00:40:05.520 --> 00:40:12.230
So any really unusual characteristic is essentially
smoothed out by blending you know 5, 6, 7

00:40:12.230 --> 00:40:15.740
or more different faces to create this average
composite.

00:40:15.740 --> 00:40:21.869
Then you create composites for people who
are giving you a blank expression, have a

00:40:21.869 --> 00:40:26.459
neutral expression and then you ask those
people to also mug happiness, sadness and

00:40:26.459 --> 00:40:30.240
just express the different cardinal emotions
that I mentioned.

00:40:30.240 --> 00:40:36.130
So you create composites for neutral and for
each of the different emotions.

00:40:36.130 --> 00:40:41.549
And then you create, blend between those just
using morphing techniques, computer graphic

00:40:41.549 --> 00:40:47.109
morphing techniques which are very well established
so that the faces in the middle contained

00:40:47.109 --> 00:40:50.829
some proportion of a particular emotion or
a blend of two different emotions.

00:40:50.829 --> 00:40:55.210
&gt;&gt;Male 8: [Inaudible]
&gt;&gt;Marcus: [laughs] To look very slightly sad

00:40:55.210 --> 00:40:56.349
or very slightly happy.

00:40:56.349 --> 00:40:59.930
No we just get the computer to do it, they're
much more reliable that way.

00:40:59.930 --> 00:41:03.789
Actually we do find that there are individual
differences in how good people are at sort

00:41:03.789 --> 00:41:07.079
of faking an expression which is perhaps not
surprising.

00:41:07.079 --> 00:41:09.109
That in itself might be interesting.

00:41:09.109 --> 00:41:13.999
And one of the questions that we haven't addressed
yet but which may be relevant here is the

00:41:13.999 --> 00:41:19.799
extent to which people, we're talking about
the way in which you perceive emotions in

00:41:19.799 --> 00:41:20.799
others.

00:41:20.799 --> 00:41:24.390
But of course it's also important the extent
to which you express emotions yourself.

00:41:24.390 --> 00:41:29.690
We know that depression is associated with
the relative blunting of the ability to express

00:41:29.690 --> 00:41:30.970
different emotions.

00:41:30.970 --> 00:41:34.670
And that may be something which is playing
a role too, and may be something which is

00:41:34.670 --> 00:41:38.180
potentially trainable as well.

00:41:38.180 --> 00:41:48.920
&gt;&gt;Male 9: [Inaudible]
&gt;&gt;Marcus: We have done a small pilot study

00:41:48.920 --> 00:41:55.651
in a school in Somerset with children with
Autism Spectrum Disorder where we used, we

00:41:55.651 --> 00:42:00.980
just chose one emotion happiness because there's
nothing problematic about people becoming

00:42:00.980 --> 00:42:03.420
more sensitive to happy, you would imagine
that be a good thing.

00:42:03.420 --> 00:42:05.449
So the sequence that we used ran from neutral
to happy.

00:42:05.449 --> 00:42:08.469
And we were just interested in whether we
could shift that threshold to make them more

00:42:08.469 --> 00:42:12.039
sensitive to these low levels of emotional
expression.

00:42:12.039 --> 00:42:15.700
What was interesting there is that, you know
many of these kids have quite serious learning

00:42:15.700 --> 00:42:20.170
disabilities and some of those were motor
in nature so they weren't actually able to

00:42:20.170 --> 00:42:23.460
press the buttons on the keyboard of the laptop
that was running the tasks.

00:42:23.460 --> 00:42:26.089
So often the experimenter had to actually
press the buttons.

00:42:26.089 --> 00:42:30.579
But we still saw a change in the threshold
which was quite reliable.

00:42:30.579 --> 00:42:36.400
So we were able to change their sensitivity
to these emotions in the context of the task.

00:42:36.400 --> 00:42:41.140
We haven't yet looked at any behavioral consequences
of that, whether that improves the social

00:42:41.140 --> 00:42:42.240
functioning.

00:42:42.240 --> 00:42:44.410
But we've got a project starting on that in
the autumn.

00:42:44.410 --> 00:42:51.359
And we're going to be running a similar project
in adults with Autism Spectrum Disorders well.

00:42:51.359 --> 00:43:04.759
&gt;&gt;Male 10: [Inaudible]
&gt;&gt;Marcus: Yes.

00:43:04.759 --> 00:43:08.900
So I mean as primates we are sort of inherently
hierarchical.

00:43:08.900 --> 00:43:14.440
And the difficulty in modern societies is
that it's not always clear what that hierarchy

00:43:14.440 --> 00:43:15.440
is.

00:43:15.440 --> 00:43:20.430
But one of the signals that we use to determine
someone's place in the dominance hierarchy

00:43:20.430 --> 00:43:22.349
is to just simply how they look.

00:43:22.349 --> 00:43:24.949
And that could include facial features.

00:43:24.949 --> 00:43:32.569
And so there's quite a literature on the extent
to which different faces are judged as more

00:43:32.569 --> 00:43:37.799
or less dominant depending on essentially
the masculinity of their facial features.

00:43:37.799 --> 00:43:41.589
And there's some evidence now which is emerging
which suggests that the way in which those

00:43:41.589 --> 00:43:47.890
people are interacted with, particularly in
the behavior economic games which are known

00:43:47.890 --> 00:43:53.569
to be influenced by things like testosterone
levels and so on can be modified by the perception

00:43:53.569 --> 00:43:56.380
of the person that you think you're interacting
with.

00:43:56.380 --> 00:44:02.380
&gt;&gt;Male 11: [Inaudible]
&gt;&gt;Marcus: I'm not sure if that's been looked

00:44:02.380 --> 00:44:04.779
at terribly closely.

00:44:04.779 --> 00:44:08.549
Because you have lots of other factors that
come into play when you have males interacting

00:44:08.549 --> 00:44:13.180
with males, males interacting with females,
females interacting with females and so on.

00:44:13.180 --> 00:44:15.009
So it becomes very complicated very quickly.

00:44:15.009 --> 00:44:21.619
So I wouldn't want to say that it's as simple
as because of these facial features being

00:44:21.619 --> 00:44:25.209
associated typically with masculinity that
therefore there are going to be differences

00:44:25.209 --> 00:44:26.880
in those interactions.

00:44:26.880 --> 00:44:34.630
But it's a possibility and that's an empirical
question we could find that out.

00:44:34.630 --> 00:44:42.869
All right in that case, thank you very much
for your time and your patience.

00:44:42.869 --> 00:44:57.089
And I hope that you found that reasonably
interesting.

00:44:57.089 --> 00:44:58.670
[applause]

