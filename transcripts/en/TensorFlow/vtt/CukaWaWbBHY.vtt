WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.450
[MUSIC PLAYING]

00:00:08.820 --> 00:00:12.060
PETE WARDEN: So thanks
so much, Raziel.

00:00:12.060 --> 00:00:18.090
And I'm real excited to be here
to talk about a new project

00:00:18.090 --> 00:00:21.430
that I think is pretty cool.

00:00:21.430 --> 00:00:23.910
So TensorFlow Lite
for microcontrollers--

00:00:23.910 --> 00:00:26.710
what's that all about?

00:00:26.710 --> 00:00:30.180
So this all comes back to when
I actually first joined Google

00:00:30.180 --> 00:00:31.900
back in 2014.

00:00:31.900 --> 00:00:33.900
And as you can imagine,
there were a whole bunch

00:00:33.900 --> 00:00:36.240
of internal projects
that I didn't actually

00:00:36.240 --> 00:00:38.670
know about, as a member
of the public, that

00:00:38.670 --> 00:00:40.180
sort of blew my mind.

00:00:40.180 --> 00:00:42.180
But one in particular
came about when I actually

00:00:42.180 --> 00:00:46.500
spoke to Raziel for the
first time, and he explained.

00:00:46.500 --> 00:00:48.690
And he was on the speech
team at the time working

00:00:48.690 --> 00:00:51.330
with Alex, who you just saw.

00:00:51.330 --> 00:00:53.640
And he explained that they
use neural network models

00:00:53.640 --> 00:00:58.020
of only 13 kilobytes in size.

00:00:58.020 --> 00:01:01.890
At that time I only really had
experience with image networks.

00:01:01.890 --> 00:01:04.110
And the very smallest
of them was still

00:01:04.110 --> 00:01:05.890
like multiple megabytes.

00:01:05.890 --> 00:01:08.370
So this idea of having
a 13-kilobyte model

00:01:08.370 --> 00:01:11.520
was just amazing for me.

00:01:11.520 --> 00:01:14.070
And what amazed me
even more was when

00:01:14.070 --> 00:01:17.850
he told me why these
models had to be so small.

00:01:17.850 --> 00:01:22.140
They needed to run them on these
DSPs and other embedded chips

00:01:22.140 --> 00:01:22.980
in smartphones.

00:01:22.980 --> 00:01:27.330
So Android could listen out for
wake words, like "Hey, Google,"

00:01:27.330 --> 00:01:31.420
while the main CPU was powered
off to save the battery.

00:01:31.420 --> 00:01:32.880
These microcontrollers
often only

00:01:32.880 --> 00:01:36.880
had tens of kilobytes of
RAM and flash storage.

00:01:36.880 --> 00:01:39.390
So they simply couldn't
fit anything larger.

00:01:39.390 --> 00:01:42.210
They also couldn't rely
on cloud connectivity

00:01:42.210 --> 00:01:45.330
because the amount of power that
would have been drained just

00:01:45.330 --> 00:01:47.820
keeping a radio connection
alive to send data over

00:01:47.820 --> 00:01:51.660
would have just
been prohibitive.

00:01:51.660 --> 00:01:57.200
So that really struck
me, that conversation

00:01:57.200 --> 00:01:59.840
and the continued work that
we did with the speech team,

00:01:59.840 --> 00:02:03.050
because they had
so much experience

00:02:03.050 --> 00:02:06.530
doing all sorts of different
approaches with speech.

00:02:06.530 --> 00:02:10.039
They'd spent a lot of time and
a lot of energy experimenting.

00:02:10.039 --> 00:02:11.810
And even within the
tough constraints

00:02:11.810 --> 00:02:15.200
of these embedded
devices, neural networks

00:02:15.200 --> 00:02:20.120
were better than any of the
traditional methods they used.

00:02:20.120 --> 00:02:21.560
So I was left
wondering if they'd

00:02:21.560 --> 00:02:25.010
be really useful for other
embedded sensor applications

00:02:25.010 --> 00:02:26.130
as well.

00:02:26.130 --> 00:02:29.300
And it left me really wanting
to see if we could actually

00:02:29.300 --> 00:02:35.300
build support for these kind of
devices into TensorFlow itself,

00:02:35.300 --> 00:02:39.260
so that more people could
actually get access.

00:02:39.260 --> 00:02:42.713
At the time, only people
in the speech community

00:02:42.713 --> 00:02:44.630
really knew about the
groundbreaking work that

00:02:44.630 --> 00:02:46.430
was being done,
so I really wanted

00:02:46.430 --> 00:02:49.780
to share it a lot more widely.

00:02:49.780 --> 00:02:54.700
So [LAUGHS] today, I'm
pleased to announce

00:02:54.700 --> 00:02:57.940
that we are releasing the
first experimental support

00:02:57.940 --> 00:03:01.210
for embedded platforms
in TensorFlow Lite.

00:03:01.210 --> 00:03:03.250
And to show you
what I mean, here

00:03:03.250 --> 00:03:09.040
is a demonstration board that
I actually have in my pocket.

00:03:09.040 --> 00:03:12.520
And this is a prototype
of a development

00:03:12.520 --> 00:03:14.680
board built by SparkFun.

00:03:14.680 --> 00:03:21.100
And it has a Cortex-M4 processor
with 384 kilobytes of RAM

00:03:21.100 --> 00:03:24.610
and a whole megabyte
of flash storage.

00:03:24.610 --> 00:03:28.330
And it was built by Ambiq
to be extremely low power,

00:03:28.330 --> 00:03:32.240
drawing less than one
milliwatt in a lot of cases.

00:03:32.240 --> 00:03:37.120
So it's able to run on a
single coin battery like this

00:03:37.120 --> 00:03:40.480
for many days, potentially.

00:03:40.480 --> 00:03:43.030
And I'm actually going to
take my life in my hands

00:03:43.030 --> 00:03:46.962
now by trying a live demo.

00:03:46.962 --> 00:03:52.540
[LAUGHS] So let us see
if this is actually--

00:03:55.940 --> 00:03:59.540
it's going to be
extremely hard to see,

00:03:59.540 --> 00:04:01.700
unless we dim the lights.

00:04:01.700 --> 00:04:04.170
There we go.

00:04:04.170 --> 00:04:06.410
So what I'm going
to be doing here

00:04:06.410 --> 00:04:11.330
is, by saying a particular word,
and see if it actually lights

00:04:11.330 --> 00:04:13.310
up the little yellow light.

00:04:13.310 --> 00:04:15.110
You can see the
blue LED flashing.

00:04:15.110 --> 00:04:17.490
That's just telling me that
it's running [INAUDIBLE]..

00:04:17.490 --> 00:04:21.450
So if I try saying, yes.

00:04:21.450 --> 00:04:21.990
Yes.

00:04:21.990 --> 00:04:25.395
[LAUGHS] Yes.

00:04:25.395 --> 00:04:28.900
[LAUGHS] I knew I was taking
my life into my hands here.

00:04:28.900 --> 00:04:29.880
[LAUGHTER]

00:04:29.880 --> 00:04:31.560
Yes.

00:04:31.560 --> 00:04:32.100
There we go.

00:04:32.100 --> 00:04:33.096
[LAUGHS]

00:04:33.096 --> 00:04:34.590
[APPLAUSE]

00:04:34.590 --> 00:04:37.440
So I'm going to quickly move
that out of the spotlight.

00:04:37.440 --> 00:04:43.320
[LAUGHS] So as you can see,
it's still far from perfect.

00:04:43.320 --> 00:04:46.050
[LAUGHS] But it
is managing to do

00:04:46.050 --> 00:04:49.500
a job of recognizing
when I say the word,

00:04:49.500 --> 00:04:53.940
and not lighting up when
there's unrelated conversations.

00:04:53.940 --> 00:04:57.370
So why is this useful?

00:04:57.370 --> 00:05:00.750
Well first, this is
running entirely locally

00:05:00.750 --> 00:05:02.100
on the embedded chip.

00:05:02.100 --> 00:05:05.820
So we don't need to have
any internet connection.

00:05:05.820 --> 00:05:09.360
So it's a good, useful first
component of a voice interface

00:05:09.360 --> 00:05:10.290
system.

00:05:10.290 --> 00:05:14.160
And the model itself
isn't quite 13 kilobytes,

00:05:14.160 --> 00:05:17.250
but it is down to 20 kilobytes.

00:05:17.250 --> 00:05:19.560
So it only takes up 20
kilobytes of flash storage

00:05:19.560 --> 00:05:20.730
on this device.

00:05:20.730 --> 00:05:22.980
And the footprint of
the TensorFlow Lite

00:05:22.980 --> 00:05:28.290
code for microcontrollers is
only another 25 kilobytes.

00:05:28.290 --> 00:05:31.110
And it only needs about
30 kilobytes of RAM

00:05:31.110 --> 00:05:32.820
available to operate.

00:05:32.820 --> 00:05:35.785
So it's within the
capabilities of a lot

00:05:35.785 --> 00:05:37.035
of different embedded devices.

00:05:40.770 --> 00:05:45.330
Secondly, this is
all open source.

00:05:45.330 --> 00:05:50.390
So you can actually
grab the code yourself

00:05:50.390 --> 00:05:52.610
and build it yourself.

00:05:52.610 --> 00:05:55.040
And you can modify it.

00:05:55.040 --> 00:05:57.230
I'm showing you here on
this particular platform,

00:05:57.230 --> 00:05:59.780
but it actually works
on a whole bunch

00:05:59.780 --> 00:06:02.060
of different embedded chips.

00:06:02.060 --> 00:06:06.140
And we really want to
see lots more supported,

00:06:06.140 --> 00:06:08.450
so we're keen to work
with the community

00:06:08.450 --> 00:06:14.910
on collaborating to get
more devices supported.

00:06:14.910 --> 00:06:18.680
You can also train
your own model.

00:06:18.680 --> 00:06:22.320
Just something that recognizes
yes isn't all that useful.

00:06:22.320 --> 00:06:27.320
But the key thing is that
this comes with a [INAUDIBLE]

00:06:27.320 --> 00:06:31.100
that you can use to actually
train your own models.

00:06:31.100 --> 00:06:33.650
And it also comes
with a data set

00:06:33.650 --> 00:06:38.630
of 100,000 utterances
of about 20 common words

00:06:38.630 --> 00:06:40.400
that you use as
your training set.

00:06:40.400 --> 00:06:44.600
And that first link there,
the aiyprojects one,

00:06:44.600 --> 00:06:47.000
if you could actually
go to that link

00:06:47.000 --> 00:06:51.950
and contribute your voice
to the open data set,

00:06:51.950 --> 00:06:54.950
it should actually
increase the size

00:06:54.950 --> 00:06:57.440
and the quality of the data
set that we can actually

00:06:57.440 --> 00:06:58.520
make available.

00:06:58.520 --> 00:06:59.600
So that would be awesome.

00:06:59.600 --> 00:07:02.450
And you can actually
use the same approach

00:07:02.450 --> 00:07:04.730
to do a lot of different
audio recognition

00:07:04.730 --> 00:07:06.860
to recognize different
kinds of sounds,

00:07:06.860 --> 00:07:10.610
and even start to use it for
similar signal processing

00:07:10.610 --> 00:07:15.910
problems, like things like
predictive maintenance.

00:07:15.910 --> 00:07:19.450
So how can you try
this out for yourself?

00:07:19.450 --> 00:07:23.490
If you're in the audience
here, at the end of today,

00:07:23.490 --> 00:07:26.350
you will find that
you get a gift box.

00:07:26.350 --> 00:07:29.060
And you actually have
one of these in there.

00:07:29.060 --> 00:07:30.785
[APPLAUSE]

00:07:30.785 --> 00:07:35.640
[LAUGHS]

00:07:35.640 --> 00:07:39.990
And all you should need to
do is remove the little tab

00:07:39.990 --> 00:07:42.660
between the battery, and it
should automatically boot up,

00:07:42.660 --> 00:07:46.260
pre-flashed, with
this yes example.

00:07:46.260 --> 00:07:48.270
[LAUGHTER]

00:07:48.270 --> 00:07:49.920
So you can try it
out for yourself,

00:07:49.920 --> 00:07:51.087
and let me know how it goes.

00:07:51.087 --> 00:07:53.802
Just say yes to
TensorFlow Lite is the--

00:07:53.802 --> 00:07:55.490
[LAUGHTER]

00:07:55.490 --> 00:07:57.100
And we also include
all the cables,

00:07:57.100 --> 00:07:58.770
SO you should be able
to just program it

00:07:58.770 --> 00:08:01.170
yourself through
the serial port.

00:08:01.170 --> 00:08:05.190
Now these are the first
700 boards ever built,

00:08:05.190 --> 00:08:07.480
so there is a wiring issue.

00:08:07.480 --> 00:08:08.690
So it will drain the battery.

00:08:08.690 --> 00:08:09.360
It won't last.

00:08:09.360 --> 00:08:12.790
It would last more
like hours than days.

00:08:12.790 --> 00:08:16.260
But that will actually,
knock on wood,

00:08:16.260 --> 00:08:20.490
be fixed in the final
product that's shipping.

00:08:20.490 --> 00:08:21.900
And you should be
able to develop

00:08:21.900 --> 00:08:23.790
with these in the
exact same way that you

00:08:23.790 --> 00:08:26.890
will with the final
shipping product.

00:08:26.890 --> 00:08:29.340
And if you're
watching at home, you

00:08:29.340 --> 00:08:33.000
can pre-order one of
these form SmartFun

00:08:33.000 --> 00:08:36.360
right now for, I
think, it's $15.

00:08:36.360 --> 00:08:41.159
And you'll also find lots
of other instructions

00:08:41.159 --> 00:08:44.560
for other platforms
in the documentation.

00:08:44.560 --> 00:08:47.820
So we are trying
to support as many

00:08:47.820 --> 00:08:52.140
of the modern microcontrollers
that are out there that people

00:08:52.140 --> 00:08:54.330
are using as possible.

00:08:54.330 --> 00:08:57.570
And we welcome
collaboration with everybody

00:08:57.570 --> 00:09:02.010
across the community to help
unlock all of the creativity

00:09:02.010 --> 00:09:03.510
that I know is out there.

00:09:03.510 --> 00:09:05.010
And I'm really
hoping that I'm going

00:09:05.010 --> 00:09:07.470
to be spending a lot of my
time over the next few months

00:09:07.470 --> 00:09:08.580
reviewing pull requests.

00:09:11.430 --> 00:09:15.660
And finally, this is my
first hardware project,

00:09:15.660 --> 00:09:19.020
so I needed a lot of
help from a lot of people

00:09:19.020 --> 00:09:22.270
to actually help bring
this prototype together,

00:09:22.270 --> 00:09:26.580
including the TF Lite team,
especially Raziel, Rocky, Dan,

00:09:26.580 --> 00:09:28.380
Tim, and Andy.

00:09:28.380 --> 00:09:34.590
Alister, Nathan, Owen, and Jim
at SparkFun were lifesavers.

00:09:34.590 --> 00:09:38.760
We literally got these in
our hands middle of the day

00:09:38.760 --> 00:09:39.450
yesterday.

00:09:39.450 --> 00:09:40.558
[LAUGHTER]

00:09:40.558 --> 00:09:42.600
So the fact that they
managed to pull it together

00:09:42.600 --> 00:09:44.340
is a massive tribute.

00:09:44.340 --> 00:09:48.690
And also Scott, Steve,
Arpit, and Andre

00:09:48.690 --> 00:09:52.950
at Ambiq, who actually designed
this process and helped us

00:09:52.950 --> 00:09:54.180
get the software going.

00:09:54.180 --> 00:09:57.330
And actually a lot of people
at Arm as well, including a big

00:09:57.330 --> 00:09:59.220
shout out to Neil and Zach.

00:09:59.220 --> 00:10:02.790
So this is still a
very early experiment,

00:10:02.790 --> 00:10:06.760
but I really can't wait to see
what people build with this.

00:10:06.760 --> 00:10:08.850
And one final note.

00:10:08.850 --> 00:10:11.820
I will be around
to talk about MCUs

00:10:11.820 --> 00:10:14.490
with anybody who's interested
at the breakout session on day

00:10:14.490 --> 00:10:15.613
two.

00:10:15.613 --> 00:10:17.863
So I'm really looking forward
to chatting to everyone.

00:10:17.863 --> 00:10:18.363
Thank you.

00:10:18.363 --> 00:10:20.701
[APPLAUSE]

00:10:24.432 --> 00:10:25.640
RAZIEL ALVAREZ: Thanks, Pete.

00:10:25.640 --> 00:10:27.510
We really hope
that you try this.

00:10:27.510 --> 00:10:31.590
I mean, it's the early stages,
but you see a huge effort

00:10:31.590 --> 00:10:33.440
just to make this happen.

00:10:33.440 --> 00:10:37.910
We think that it will be
really impactful for everybody.

00:10:37.910 --> 00:10:39.640
Now before we go again--

00:10:39.640 --> 00:10:42.710
and I promise this is the
last thing you hear from me--

00:10:42.710 --> 00:10:46.660
I want to welcome
June, who's going

00:10:46.660 --> 00:10:50.570
to talk about how, by using
TensorFlow Lite with the Edge

00:10:50.570 --> 00:10:55.625
TPU Delegate are able to train
these teachable machines.

00:10:55.625 --> 00:10:58.100
[MUSIC PLAYING]

00:11:01.565 --> 00:11:03.545
[APPLAUSE]

00:11:04.535 --> 00:11:07.740
JUNE TATE-GANS: Thanks, Raziel.

00:11:07.740 --> 00:11:08.240
Hi.

00:11:08.240 --> 00:11:09.920
My name is June Tate-Gans.

00:11:09.920 --> 00:11:12.170
I'm actually one of the lead
software engineers inside

00:11:12.170 --> 00:11:13.758
of Google's new Coral Group.

00:11:13.758 --> 00:11:15.800
And I've been asked to
give a talk about the Edge

00:11:15.800 --> 00:11:19.880
TPU-based teachable
machine demo.

00:11:19.880 --> 00:11:22.540
So first, I should
tell you what Coral is.

00:11:22.540 --> 00:11:26.180
Coral is a platform for products
with on-device machine learning

00:11:26.180 --> 00:11:28.760
using TensorFlow and TF Lite.

00:11:28.760 --> 00:11:31.970
Our first two products are
a single-board computer

00:11:31.970 --> 00:11:33.200
and a USB stick.

00:11:36.000 --> 00:11:38.340
So what is the Edge TPU?

00:11:38.340 --> 00:11:41.760
It's a Google-designed ASIC that
accelerates inference directly

00:11:41.760 --> 00:11:43.590
on the device that
it's embedded in.

00:11:43.590 --> 00:11:44.460
It's very fast.

00:11:44.460 --> 00:11:47.700
It localizes data to the
edge, rather than the cloud.

00:11:47.700 --> 00:11:50.500
It doesn't require a
network connection to run.

00:11:50.500 --> 00:11:53.017
And this allows for a whole
new range of applications

00:11:53.017 --> 00:11:53.850
of machine learning.

00:11:59.090 --> 00:12:04.420
So the first product we
built is the Coral Dev Board.

00:12:04.420 --> 00:12:07.640
This is a single-board
computer with a removable SOM.

00:12:07.640 --> 00:12:09.760
It runs Linux and Android.

00:12:09.760 --> 00:12:11.770
And the SOM itself
has a gigabyte

00:12:11.770 --> 00:12:16.690
of RAM, a quad-core A53
SoC, Wi-Fi and Bluetooth,

00:12:16.690 --> 00:12:20.400
and of course the Edge TPU.

00:12:20.400 --> 00:12:22.980
And the second is our
Coral accelerator board.

00:12:22.980 --> 00:12:25.890
Now, this board is just
the Edge TPU connected

00:12:25.890 --> 00:12:28.500
via USB-C to whatever
development system

00:12:28.500 --> 00:12:32.020
you need, be it a Raspberry
Pi, or a Linux workstation.

00:12:35.240 --> 00:12:37.460
Now, this teachable
machine shows off

00:12:37.460 --> 00:12:38.913
a form of edge training.

00:12:38.913 --> 00:12:41.330
Now traditionally, there's
three ways to do edge training.

00:12:41.330 --> 00:12:45.530
There's k-nearest neighbors,
weight imprinting,

00:12:45.530 --> 00:12:48.550
and last layer retraining.

00:12:48.550 --> 00:12:50.220
But for this demo,
we're actually

00:12:50.220 --> 00:12:52.110
using the k-nearest
neighbors approach.

00:12:55.050 --> 00:12:58.280
So in this animated GIF, you
can see that the TPU enables

00:12:58.280 --> 00:13:00.315
very high classification rates.

00:13:00.315 --> 00:13:01.940
The frame rate you
see here is actually

00:13:01.940 --> 00:13:04.040
the rate at which the
TPU is classifying

00:13:04.040 --> 00:13:05.567
the images that I'm showing it.

00:13:05.567 --> 00:13:07.400
In this case, you can
see that we're getting

00:13:07.400 --> 00:13:09.240
about 30 frames per second.

00:13:09.240 --> 00:13:11.344
It's essentially
real-time classification.

00:13:14.130 --> 00:13:16.620
And with that, I actually have
one of our teachable machine

00:13:16.620 --> 00:13:17.250
demos here.

00:13:20.220 --> 00:13:22.530
So if we can turn this on.

00:13:22.530 --> 00:13:24.320
There we go.

00:13:24.320 --> 00:13:25.310
OK.

00:13:25.310 --> 00:13:32.830
So on this board, we have our
Edge TPU development board

00:13:32.830 --> 00:13:35.946
assembled with a camera
and a series of buttons.

00:13:35.946 --> 00:13:38.050
And each button corresponds
with class and lights

00:13:38.050 --> 00:13:42.398
up when the model identifies
an object from the camera.

00:13:42.398 --> 00:13:43.690
First, we have to plug this in.

00:13:47.450 --> 00:13:50.600
Now every time I take
a picture by pressing

00:13:50.600 --> 00:13:52.760
one of these buttons, it
associates that picture

00:13:52.760 --> 00:13:54.740
with that particular class.

00:13:54.740 --> 00:13:57.620
And because it's running
inference on the Edge TPU,

00:13:57.620 --> 00:13:59.700
it lights up immediately.

00:13:59.700 --> 00:14:03.350
So once it's finished booting,
the first thing I have to do

00:14:03.350 --> 00:14:04.970
is train it on the background.

00:14:04.970 --> 00:14:06.860
So I'll press this blue
button, and you can

00:14:06.860 --> 00:14:08.420
see it immediately turns on.

00:14:08.420 --> 00:14:12.620
This is because, again, it's
doing inference in real time.

00:14:12.620 --> 00:14:17.740
Now, if I train one of the
other buttons using something

00:14:17.740 --> 00:14:24.330
like a tangerine,
press it a few times.

00:14:24.330 --> 00:14:29.940
OK, so now you can see it can
classify between this tangerine

00:14:29.940 --> 00:14:31.060
and the background.

00:14:31.060 --> 00:14:35.800
And further, I can even
grab other objects,

00:14:35.800 --> 00:14:37.932
such as this TF Light sticker--

00:14:37.932 --> 00:14:39.140
it looks very similar, right?

00:14:39.140 --> 00:14:39.973
It's the same color.

00:14:43.140 --> 00:14:43.640
Let's see.

00:14:43.640 --> 00:14:44.990
What was in the class I used?

00:14:44.990 --> 00:14:46.820
Yellow, OK.

00:14:46.820 --> 00:14:47.592
Sorry.

00:14:47.592 --> 00:14:49.480
[LAUGHTER]

00:14:49.480 --> 00:14:51.760
So now, even though
it's a similar color,

00:14:51.760 --> 00:14:55.330
IT can still discern
the TensorFlow Lite logo

00:14:55.330 --> 00:14:56.410
from the tangerine.

00:14:56.410 --> 00:14:57.482
Oh, sorry.

00:14:57.482 --> 00:14:58.440
Tangerine, there we go.

00:14:58.440 --> 00:15:00.432
[LAUGHTER]

00:15:00.432 --> 00:15:02.424
[APPLAUSE]

00:15:07.420 --> 00:15:09.990
So you can imagine in a
manufacturing context,

00:15:09.990 --> 00:15:12.270
your operators, with
no knowledge of machine

00:15:12.270 --> 00:15:14.490
learning or training
in machine learning,

00:15:14.490 --> 00:15:16.590
can adapt your system
easily and quickly

00:15:16.590 --> 00:15:18.820
using this exact technique.

00:15:18.820 --> 00:15:20.700
So that's about it for the demo.

00:15:20.700 --> 00:15:23.520
But before I go, I
should grab the clicker,

00:15:23.520 --> 00:15:28.800
and also I should say, we're
also giving away some Edge TPU

00:15:28.800 --> 00:15:30.330
accelerators.

00:15:30.330 --> 00:15:32.040
For those of you
here today, we'll

00:15:32.040 --> 00:15:33.900
have one available
for you as well.

00:15:33.900 --> 00:15:35.610
And for those of you
on the Livestream,

00:15:35.610 --> 00:15:39.900
you can purchase one at
coral.withgoogle.com.

00:15:39.900 --> 00:15:41.400
[APPLAUSE]

00:15:41.400 --> 00:15:42.600
OK.

00:15:42.600 --> 00:15:45.350
[MUSIC PLAYING]

