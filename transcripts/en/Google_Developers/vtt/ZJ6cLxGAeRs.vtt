WEBVTT
Kind: captions
Language: en

00:00:14.220 --> 00:00:18.040
BASTIEN LEGRAS: Who has already
tried Compute Engine?

00:00:18.040 --> 00:00:21.570
Since it has been announced for
open sign-up only at I/O,

00:00:21.570 --> 00:00:24.720
so now it's three weeks ago, I
can understand, because it was

00:00:24.720 --> 00:00:27.630
a limited preview before.

00:00:27.630 --> 00:00:31.160
Which means we had to manually
activate the product, because

00:00:31.160 --> 00:00:33.960
it has been announced last
year at I/O, but now it's

00:00:33.960 --> 00:00:36.440
really something you
can try this year.

00:00:36.440 --> 00:00:37.690
So a bit of background.

00:00:37.690 --> 00:00:40.370
We've been working on-- for
us, it's a very strategic

00:00:40.370 --> 00:00:42.900
project, ultra strategic
project.

00:00:42.900 --> 00:00:46.470
I think you all know
Amazon EC2.

00:00:46.470 --> 00:00:49.350
I guess most of you maybe
have already used.

00:00:49.350 --> 00:00:52.340
You understand that we are
going into that space.

00:00:52.340 --> 00:00:54.760
So this is a big space.

00:00:54.760 --> 00:00:57.460
We've been working for three
years on the virtualization

00:00:57.460 --> 00:00:59.710
technology and Compute Engine.

00:00:59.710 --> 00:01:03.650
So it's not a copy of what you
can find in other places.

00:01:03.650 --> 00:01:06.570
It's really unique to Google,
so from the bottom up.

00:01:06.570 --> 00:01:10.670
You know what [INAUDIBLE] was
explaining, that because of

00:01:10.670 --> 00:01:14.200
our scale, we had to
build our product.

00:01:14.200 --> 00:01:16.500
We have to design our server.

00:01:16.500 --> 00:01:19.140
We have to build our
network layers.

00:01:19.140 --> 00:01:24.010
And our machines are the same,
so the operating system, we

00:01:24.010 --> 00:01:26.490
what we find, the best, we
strip it, and then we

00:01:26.490 --> 00:01:28.960
customize it, because this
is our own hardware.

00:01:28.960 --> 00:01:33.440
So at all the layers, this is
Google-only technology.

00:01:33.440 --> 00:01:34.920
We don't use Apache.

00:01:34.920 --> 00:01:36.300
We don't-- maybe for
internal stuff.

00:01:36.300 --> 00:01:39.075
But for the project, we have
rebuilt web servers, file

00:01:39.075 --> 00:01:41.790
system, as you can see, really
from the bottom up.

00:01:41.790 --> 00:01:45.700
So that's why this
virtualization layer is

00:01:45.700 --> 00:01:50.790
completely optimized for our
platform, our servers.

00:01:50.790 --> 00:01:53.600
And what we see, and I hope
that you will try Compute

00:01:53.600 --> 00:01:59.320
Engine, is that we managed to
have a very low footprint.

00:01:59.320 --> 00:02:01.930
Which means between the physical
performance and the

00:02:01.930 --> 00:02:06.040
virtual performance, there is
always a little loss, because

00:02:06.040 --> 00:02:08.900
there is a virtualization layer
running on the machines.

00:02:08.900 --> 00:02:12.566
Here, the footprint of this loss
is very, very, very thin,

00:02:12.566 --> 00:02:14.460
because we've been
optimizing that.

00:02:14.460 --> 00:02:18.070
So you almost have the
physical machine's

00:02:18.070 --> 00:02:19.280
performance.

00:02:19.280 --> 00:02:23.670
And what is also important is
that we've been working a lot,

00:02:23.670 --> 00:02:27.120
that was in the early
specifications, on the we call

00:02:27.120 --> 00:02:28.700
the noisy neighbors problem.

00:02:28.700 --> 00:02:34.710
The noisy neighbors is that with
virtualization technology

00:02:34.710 --> 00:02:38.070
you have on public cloud
usually, you have a virtual

00:02:38.070 --> 00:02:40.190
instance running on a
physical machine.

00:02:40.190 --> 00:02:41.420
But you are not alone,
of course.

00:02:41.420 --> 00:02:45.070
You have neighbors, so other
customers that are running

00:02:45.070 --> 00:02:48.670
their own virtual instance on
the same physical machine.

00:02:48.670 --> 00:02:53.750
And let's assume there is a bit
of overbooking, when your

00:02:53.750 --> 00:02:54.710
neighbors--

00:02:54.710 --> 00:02:56.400
so co-locating on this
physical machine--

00:02:56.400 --> 00:02:57.370
are hitting hard.

00:02:57.370 --> 00:03:00.150
So maybe they have
a peak of load.

00:03:00.150 --> 00:03:03.650
You will see your own
performance dropping.

00:03:03.650 --> 00:03:05.850
That's something we want to
avoid with Compute Engine.

00:03:05.850 --> 00:03:08.590
We've been working hard on that
to do live migration of

00:03:08.590 --> 00:03:13.060
machines when a physical machine
becomes noisy, so you

00:03:13.060 --> 00:03:16.170
have your performance from
day one to the end.

00:03:16.170 --> 00:03:18.200
And you have constant
performance over time.

00:03:18.200 --> 00:03:20.140
You don't have performance
[? risks. ?]

00:03:20.140 --> 00:03:22.670
The boot time and the
availability time as well is

00:03:22.670 --> 00:03:23.240
really important.

00:03:23.240 --> 00:03:24.450
You will see in the demo.

00:03:24.450 --> 00:03:29.280
You have your machine in 20
seconds, more or less, so 20

00:03:29.280 --> 00:03:32.270
seconds from the time you click
New Machine to the time

00:03:32.270 --> 00:03:34.880
you can SSH the machine.

00:03:34.880 --> 00:03:36.440
So it's not 5 or 10 minutes.

00:03:36.440 --> 00:03:37.510
It's 20 seconds.

00:03:37.510 --> 00:03:40.030
And the boot time
is really fast.

00:03:40.030 --> 00:03:42.880
Like, it's less than 20 seconds,
because there is a

00:03:42.880 --> 00:03:46.740
staging provisioning
time before.

00:03:46.740 --> 00:03:49.490
Our objective is always
to have zero, but it's

00:03:49.490 --> 00:03:50.040
impossible.

00:03:50.040 --> 00:03:52.720
But we're trying to go
below one second.

00:03:52.720 --> 00:03:56.080
So we are working really, really
hard on Compute Engine.

00:03:56.080 --> 00:03:59.580
There is a lot of unknowns at
Google I/O that we made.

00:03:59.580 --> 00:04:04.460
Like, we are providing now load
balancing, so level 3.

00:04:04.460 --> 00:04:06.500
We are providing advanced
routine.

00:04:06.500 --> 00:04:08.550
We are providing automation.

00:04:08.550 --> 00:04:12.570
So there are a lot of features
coming on the project.

00:04:12.570 --> 00:04:15.844
So a few slides,
and then demo.

00:04:18.990 --> 00:04:22.590
What are the use cases, again,
about Compute Engine?

00:04:22.590 --> 00:04:25.480
So the first one, hence the
name Compute Engine, was

00:04:25.480 --> 00:04:29.540
compute, the idea of you can
launch any number of virtual

00:04:29.540 --> 00:04:31.440
machines using Linux.

00:04:31.440 --> 00:04:36.990
So today, we support Debian,
CentOS, and we have a core OS

00:04:36.990 --> 00:04:38.580
which is GCL--

00:04:38.580 --> 00:04:39.830
Google Compute Engine Linux--

00:04:39.830 --> 00:04:42.490
which is like Ubuntu,
let's say.

00:04:42.490 --> 00:04:44.120
And we're going to support
more operating

00:04:44.120 --> 00:04:45.310
systems over time.

00:04:45.310 --> 00:04:48.630
I can't disclose in a public
audience what we're going to

00:04:48.630 --> 00:04:51.560
support, but in the following
months, we're going to support

00:04:51.560 --> 00:04:55.370
more operating systems
that you all know.

00:04:55.370 --> 00:04:58.870
The idea is that it's not
only the machines.

00:04:58.870 --> 00:05:01.520
It's really about, again, as
always on a cloud platform,

00:05:01.520 --> 00:05:03.290
the network.

00:05:03.290 --> 00:05:06.870
The machine-to-machine networks
are incredible.

00:05:06.870 --> 00:05:11.030
In less than one millisecond,
you can transfer terabytes, at

00:05:11.030 --> 00:05:12.280
a terabyte per second.

00:05:12.280 --> 00:05:13.430
Of course, you have
the physical

00:05:13.430 --> 00:05:14.620
limit of the hard drive.

00:05:14.620 --> 00:05:16.860
What I'm saying is that there
are almost no limits from the

00:05:16.860 --> 00:05:18.520
network perspective.

00:05:18.520 --> 00:05:19.270
The storage--

00:05:19.270 --> 00:05:23.030
so there are two new
storage mechanisms.

00:05:23.030 --> 00:05:25.250
We've been talking about cloud
storage, but you will still

00:05:25.250 --> 00:05:27.310
have the local storage
on the machine.

00:05:27.310 --> 00:05:29.760
That will live with the machine,
meaning that when you

00:05:29.760 --> 00:05:32.540
create the machine, you
have this disk.

00:05:32.540 --> 00:05:35.235
It's usually hundreds
of gigabytes.

00:05:35.235 --> 00:05:38.230
It depends on how many cores
you want on your machine.

00:05:38.230 --> 00:05:40.040
And I will show you after
doing the demo.

00:05:40.040 --> 00:05:42.400
But you have also something I
mentioned earlier, which is a

00:05:42.400 --> 00:05:45.250
persistent disk, which is a
shared storage, like a SAN, if

00:05:45.250 --> 00:05:46.940
you want, across machines.

00:05:46.940 --> 00:05:48.040
And there's a lot of tuning.

00:05:48.040 --> 00:05:50.700
As always, you can use
the web REST API

00:05:50.700 --> 00:05:51.960
to create your machine.

00:05:51.960 --> 00:05:56.990
You can use the command line,
so gcutil, similar to the

00:05:56.990 --> 00:05:59.110
gsutil I showed earlier.

00:05:59.110 --> 00:06:02.720
Or you can, from the UI,
create the machine.

00:06:02.720 --> 00:06:04.150
And that's something
I will do as well.

00:06:04.150 --> 00:06:06.520
Because I need something
quite visual for you.

00:06:09.720 --> 00:06:11.540
I have talked about
all of this--

00:06:11.540 --> 00:06:13.450
scale, performance, value.

00:06:13.450 --> 00:06:17.790
So that's the overview what you
get with Compute Engine.

00:06:17.790 --> 00:06:21.340
So of course you get
what's right here,

00:06:21.340 --> 00:06:22.600
so the virtual machines.

00:06:22.600 --> 00:06:25.160
But you get a private network
within Google.

00:06:25.160 --> 00:06:29.520
And you can do sub-networks, as
many as you want, set your

00:06:29.520 --> 00:06:31.610
firewall rules.

00:06:31.610 --> 00:06:35.200
And I hope you all understand
that you are root on this

00:06:35.200 --> 00:06:37.790
machine, so this is your machine
running in Google

00:06:37.790 --> 00:06:38.290
infrastructure.

00:06:38.290 --> 00:06:39.370
That's really the idea.

00:06:39.370 --> 00:06:40.780
So you do whatever you want.

00:06:40.780 --> 00:06:42.490
And they are of course connected
to the internet, so

00:06:42.490 --> 00:06:46.930
you can host an, I don't know,
website on Tomcat if that's

00:06:46.930 --> 00:06:49.030
what you want to do.

00:06:49.030 --> 00:06:50.710
Maybe you can't read
very well.

00:06:50.710 --> 00:06:52.510
So this one was persistent
disk.

00:06:52.510 --> 00:06:54.160
This one was local disk.

00:06:54.160 --> 00:06:55.620
And this one is cloud storage.

00:06:55.620 --> 00:06:58.840
So there's three main storage
mechanisms we provide.

00:06:58.840 --> 00:07:01.705
And there's three access types,
so the command line,

00:07:01.705 --> 00:07:05.800
the web UI, and from the code,
so the API itself, so either

00:07:05.800 --> 00:07:10.110
the REST HTTP API, or using
a client implementation--

00:07:10.110 --> 00:07:15.010
again, Java .NET, PHP,
you name it.

00:07:15.010 --> 00:07:19.890
So what we call the project
is where all the

00:07:19.890 --> 00:07:22.500
machines will be linked.

00:07:22.500 --> 00:07:23.730
It's not physical stuff.

00:07:23.730 --> 00:07:27.020
It's really a way to organize
your different applications.

00:07:27.020 --> 00:07:29.520
So in one project, you have
all your machines.

00:07:29.520 --> 00:07:32.140
You can go to another project
if you want to separate.

00:07:32.140 --> 00:07:35.690
And within this project, you
have your own persistent disk,

00:07:35.690 --> 00:07:38.920
local disk that comes with the
machine, network, et cetera.

00:07:38.920 --> 00:07:40.410
And each project has an ID.

00:07:44.060 --> 00:07:47.390
So the machine-- so as I said,
root access, there are stock

00:07:47.390 --> 00:07:49.180
images you can use.

00:07:49.180 --> 00:07:53.850
The idea is that you could
build your own images.

00:07:53.850 --> 00:07:56.302
We are running a modem
processor, of course, so this

00:07:56.302 --> 00:07:58.160
is Intel Sandy Bridge.

00:07:58.160 --> 00:08:02.060
These are the virtual cores that
you can have from one.

00:08:02.060 --> 00:08:04.800
Then even now, we have
launched at I/O

00:08:04.800 --> 00:08:07.130
new very small modems.

00:08:07.130 --> 00:08:10.150
Like if you do dev, we call
them small and micro.

00:08:10.150 --> 00:08:11.530
I will show them.

00:08:11.530 --> 00:08:14.340
But basically, you have from
one to eight virtual cores.

00:08:14.340 --> 00:08:16.820
And per CPU, that's
the RAM you get.

00:08:16.820 --> 00:08:18.300
And we have various profiles.

00:08:18.300 --> 00:08:22.270
So we have what we call the
standard, which is this ratio.

00:08:22.270 --> 00:08:25.220
We have high memory, so you
have more memory per core.

00:08:25.220 --> 00:08:30.540
And we have high CPU So you
have less memory per core.

00:08:30.540 --> 00:08:33.000
I don't know what happened.

00:08:33.000 --> 00:08:34.250
Next.

00:08:36.020 --> 00:08:37.270
MALE SPEAKER: [INAUDIBLE]

00:08:48.040 --> 00:08:49.140
BASTIEN LEGRAS: Not yet, no.

00:08:49.140 --> 00:08:52.600
The question was, can I create
a custom machine from the API

00:08:52.600 --> 00:08:54.800
specifying the number of CPUs?

00:08:54.800 --> 00:08:56.660
You have to go into the types.

00:08:56.660 --> 00:08:59.470
I will show on the demo what
types of machines we provide.

00:08:59.470 --> 00:09:00.720
MALE SPEAKER: [INAUDIBLE]

00:09:25.250 --> 00:09:27.600
BASTIEN LEGRAS: That's the
high memory profile.

00:09:27.600 --> 00:09:29.070
So I will show you
all the profiles.

00:09:29.070 --> 00:09:31.440
I think you will see that
we are trying to address

00:09:31.440 --> 00:09:32.850
the main use cases.

00:09:32.850 --> 00:09:36.010
It's high memory profile what
you're talking about.

00:09:36.010 --> 00:09:38.380
So let me finish with this slide
so I can show you that

00:09:38.380 --> 00:09:39.350
right after.

00:09:39.350 --> 00:09:44.370
So external IPs, of course you
can choose to add your own IPs

00:09:44.370 --> 00:09:46.540
which are external IPs
for this machine

00:09:46.540 --> 00:09:48.830
to listen on internet.

00:09:48.830 --> 00:09:49.730
We are doing, of course,

00:09:49.730 --> 00:09:52.300
one-to-one NATing, and firewall.

00:09:52.300 --> 00:09:55.500
I will so everything
on the console.

00:09:55.500 --> 00:09:58.660
This is the persistent disk.

00:09:58.660 --> 00:09:59.810
So of course there are zones.

00:09:59.810 --> 00:10:02.290
I forgot to mention, but when
you create your machine, you

00:10:02.290 --> 00:10:06.240
choose if you want to deploy it
in US East, US Central, or

00:10:06.240 --> 00:10:11.300
West Europe, where we bring more
availability zones, of

00:10:11.300 --> 00:10:13.520
course, like in APAC,
because we are--

00:10:13.520 --> 00:10:16.080
today, GC is not deployed
in all the data

00:10:16.080 --> 00:10:17.280
centers that we have.

00:10:17.280 --> 00:10:18.950
So it's only the first ones.

00:10:18.950 --> 00:10:21.580
We are bringing more zones
so you can deploy your

00:10:21.580 --> 00:10:24.370
application closest
to your customers.

00:10:24.370 --> 00:10:27.910
And everything is encrypted in
time of storage at rest, and

00:10:27.910 --> 00:10:32.130
even machine-to-machine
transfers are encrypted, which

00:10:32.130 --> 00:10:33.570
gives you another idea
of the performance.

00:10:33.570 --> 00:10:36.590
We are not even slowed
by the encryption.

00:10:36.590 --> 00:10:40.510
So the ephemeral disk, so the
local disk, if you want, lives

00:10:40.510 --> 00:10:41.590
and dies with the instance.

00:10:41.590 --> 00:10:42.680
That's the idea.

00:10:42.680 --> 00:10:44.710
You create your instance.

00:10:44.710 --> 00:10:47.050
If you're in a compute scenario,
you don't care

00:10:47.050 --> 00:10:48.060
what's on the machine.

00:10:48.060 --> 00:10:49.210
You just create it.

00:10:49.210 --> 00:10:54.520
Then maybe you want to set up
a launch script that will

00:10:54.520 --> 00:10:55.540
configure the machine.

00:10:55.540 --> 00:10:57.660
And the machine will do
some computation.

00:10:57.660 --> 00:10:59.820
If you remember the use case
earlier with mobile and

00:10:59.820 --> 00:11:02.290
back-end and VM engine
from App Engine.

00:11:02.290 --> 00:11:03.310
That's typical [INAUDIBLE].

00:11:03.310 --> 00:11:05.720
You create the machine, he's
going to do his job, and then

00:11:05.720 --> 00:11:07.550
you destroy the machine,
and you don't care

00:11:07.550 --> 00:11:08.700
what's on the machine.

00:11:08.700 --> 00:11:11.780
So for that kind of use case,
you can use the local disk,

00:11:11.780 --> 00:11:13.740
because it will die
with the machine.

00:11:13.740 --> 00:11:17.440
If, however, you need to persist
the data generated by

00:11:17.440 --> 00:11:20.090
the machine, then you want to
use the persistent disk.

00:11:20.090 --> 00:11:22.610
And you can boot a machine
from the persistent disk.

00:11:22.610 --> 00:11:26.460
That's really key, because you
want to minimize your cost.

00:11:26.460 --> 00:11:28.550
So when you don't need the
machine anymore, you will

00:11:28.550 --> 00:11:29.420
destroy it.

00:11:29.420 --> 00:11:32.950
As it takes 10 to 20 seconds
to get the machine again,

00:11:32.950 --> 00:11:35.170
there is no need to let
it slide the light.

00:11:35.170 --> 00:11:37.540
When you go out of the room,
you switch off your light.

00:11:37.540 --> 00:11:40.410
That's really the idea
of open engine.

00:11:40.410 --> 00:11:42.850
You don't want to spend money
for a machine that is doing

00:11:42.850 --> 00:11:45.050
nothing, of course.

00:11:45.050 --> 00:11:48.440
So that's why you need to manage
your data, of course.

00:11:48.440 --> 00:11:50.850
And the cloud storage, we just
talked about cloud storage.

00:11:50.850 --> 00:11:53.270
That's, of course, integrated
with Compute Engine.

00:11:53.270 --> 00:11:56.690
Again, easy to store terabytes
of data or petabytes of data

00:11:56.690 --> 00:11:58.060
from Compute Engine.

00:11:58.060 --> 00:12:01.020
And that was the case in the big
migration use case I was

00:12:01.020 --> 00:12:03.090
showing before.

00:12:03.090 --> 00:12:07.550
And the three access doors that
you have-- so UI, command

00:12:07.550 --> 00:12:11.490
line, and from the API.

00:12:11.490 --> 00:12:13.300
I won't go into too
much detail here.

00:12:13.300 --> 00:12:14.710
We've covered that,
more or less.

00:12:14.710 --> 00:12:19.800
So Compute Engine is
in most of our big

00:12:19.800 --> 00:12:20.800
architecture diagrams.

00:12:20.800 --> 00:12:25.440
So you see it, here it's a
Hadoop MapReduce use case.

00:12:25.440 --> 00:12:27.840
Here it was the thing
of this morning.

00:12:27.840 --> 00:12:31.190
I was presenting when you want
to do batch processing for

00:12:31.190 --> 00:12:35.340
your mobile app on demand,
et cetera, et cetera.

00:12:35.340 --> 00:12:38.310
This is an analytic pipeline,
so you have a lot

00:12:38.310 --> 00:12:39.890
of data coming in.

00:12:39.890 --> 00:12:42.400
You use App Engine for
MapReduce, and then you want

00:12:42.400 --> 00:12:46.130
maybe to also use Hadoop
to analyze this data.

00:12:46.130 --> 00:12:47.370
Compute Engine is everywhere.

00:12:47.370 --> 00:12:50.300
I mean, everyone needs virtual
machines at one point.

00:12:50.300 --> 00:12:55.430
It's very, very rare that you
don't need it in your project.

00:12:55.430 --> 00:12:58.150
And before going into the demo,
so we already have, of

00:12:58.150 --> 00:12:59.690
course, an ecosystem.

00:12:59.690 --> 00:13:01.560
Right Scale is one of
the first partners.

00:13:01.560 --> 00:13:03.150
So they know very well
Compute Engine.

00:13:03.150 --> 00:13:05.940
They have their own image,
because that's the idea.

00:13:05.940 --> 00:13:10.010
You can start from a cannot
machine, so a stock image,

00:13:10.010 --> 00:13:12.340
then you can customize it,
and then you can take a

00:13:12.340 --> 00:13:14.270
snapshot, of course.

00:13:14.270 --> 00:13:17.270
You put it on cloud storage, and
then you will reuse it to

00:13:17.270 --> 00:13:18.290
reboot a new machine.

00:13:18.290 --> 00:13:22.070
So you have your own machines
in your project.

00:13:22.070 --> 00:13:25.710
So Right Scale, they are
providing their own image.

00:13:25.710 --> 00:13:28.330
And they added onto the image
a connector that connects to

00:13:28.330 --> 00:13:30.070
their central console.

00:13:30.070 --> 00:13:34.760
The idea is to have elasticity,
so scalability up

00:13:34.760 --> 00:13:36.920
and down at the infrastructure
level.

00:13:36.920 --> 00:13:38.800
We provide that with
App Engine.

00:13:38.800 --> 00:13:40.100
As you know, it scales
up and down.

00:13:40.100 --> 00:13:42.825
You don't have to worry about
how many machines you need to

00:13:42.825 --> 00:13:43.990
run in your app.

00:13:43.990 --> 00:13:46.020
When you are at the
infrastructure level, you have

00:13:46.020 --> 00:13:46.680
to manage that.

00:13:46.680 --> 00:13:48.670
So do I need to put
more machines

00:13:48.670 --> 00:13:50.330
behind my load balancer?

00:13:50.330 --> 00:13:53.140
So do I need to remove some
machines, because now I don't

00:13:53.140 --> 00:13:56.130
have the demand for
all these machines

00:13:56.130 --> 00:13:57.350
So Right Scale is doing
that for you.

00:13:57.350 --> 00:13:58.380
You just configure.

00:13:58.380 --> 00:14:01.080
You say, I don't know, you
define some threshold.

00:14:01.080 --> 00:14:04.990
You say, at above 70% of usage,
I want you to add five

00:14:04.990 --> 00:14:05.950
more machines.

00:14:05.950 --> 00:14:09.310
And the rest of the inverse
rule, so when you go below

00:14:09.310 --> 00:14:10.970
50%, you remove three
machines.

00:14:10.970 --> 00:14:14.900
You define your own rules, and
Right Scale will manage the

00:14:14.900 --> 00:14:17.100
scalability, so from
the console,

00:14:17.100 --> 00:14:19.450
directly on Compute Engine.

00:14:19.450 --> 00:14:23.540
And they do also a lot of
monitoring and stuff.

00:14:23.540 --> 00:14:26.620
These are other partners,
technical partners.

00:14:26.620 --> 00:14:30.840
MapR is a commercial Hadoop
implementation.

00:14:30.840 --> 00:14:32.140
I have a project with them.

00:14:32.140 --> 00:14:34.530
I was mentioning [INAUDIBLE]
earlier.

00:14:34.530 --> 00:14:37.000
They are using MapR for a Hadoop
project to analyze the

00:14:37.000 --> 00:14:38.420
traffic on the website
and improve

00:14:38.420 --> 00:14:39.990
their conversion ratio.

00:14:39.990 --> 00:14:42.540
So it works very well.

00:14:42.540 --> 00:14:45.920
We broke the [? teraflop ?]

00:14:45.920 --> 00:14:47.500
record.

00:14:47.500 --> 00:14:49.330
It was one minute something.

00:14:49.330 --> 00:14:51.090
With Compute Engine,
it's now less.

00:14:51.090 --> 00:14:53.040
It's like 56 seconds.

00:14:53.040 --> 00:14:56.880
So it's to give you an idea
of the pure performance of

00:14:56.880 --> 00:14:58.410
Compute Engine.

00:14:58.410 --> 00:14:59.675
I won't go into that.

00:14:59.675 --> 00:15:02.580
It's the big data landscape.

00:15:02.580 --> 00:15:05.540
Let's go on the demo for
the last 15 minutes.

00:15:05.540 --> 00:15:06.990
So I have to sit down again.

00:15:06.990 --> 00:15:08.240
Sorry.

00:15:11.410 --> 00:15:13.860
And then I will take, of
course, questions.

00:15:13.860 --> 00:15:16.030
So let me clean that up.

00:15:16.030 --> 00:15:19.410
So you start from here.

00:15:19.410 --> 00:15:21.520
Why is that there?

00:15:21.520 --> 00:15:23.190
I hope you see.

00:15:23.190 --> 00:15:28.740
So this is the console home
page for a project.

00:15:28.740 --> 00:15:30.460
The console, let's go,
so you can understand

00:15:30.460 --> 00:15:31.250
really how it works.

00:15:31.250 --> 00:15:32.460
You go on here.

00:15:32.460 --> 00:15:35.140
With your Gmail account, you
activate the services you want

00:15:35.140 --> 00:15:37.450
to use, and then you create
your project.

00:15:37.450 --> 00:15:40.330
And here I am logged with
my co-op account Google.

00:15:40.330 --> 00:15:43.590
So we see we have some projects
internally that are

00:15:43.590 --> 00:15:44.760
shared with me.

00:15:44.760 --> 00:15:49.370
And I have access to this one,
which is our demo creator.

00:15:49.370 --> 00:15:51.730
Here, you see the services
that are

00:15:51.730 --> 00:15:54.280
activated for this project.

00:15:54.280 --> 00:15:55.580
The project is like a team.

00:15:55.580 --> 00:15:59.050
You can share the project with
other people in your team,

00:15:59.050 --> 00:16:02.370
like you are sharing a doc in
Google Docs, and give specific

00:16:02.370 --> 00:16:04.400
access to everyone.

00:16:04.400 --> 00:16:08.250
So App Engine, so this means
that on this project, I guess

00:16:08.250 --> 00:16:10.220
people are using some App
Engine instances.

00:16:10.220 --> 00:16:12.230
Compute Engine, and we
will go into that.

00:16:12.230 --> 00:16:15.000
Cloud Storage, Big Query,
some APIs, [INAUDIBLE].

00:16:15.000 --> 00:16:18.760
There you see which services
are being used.

00:16:18.760 --> 00:16:21.570
So let's focus on Compute
Engine, and then let's do a

00:16:21.570 --> 00:16:25.040
quick tour of the Administration
Console.

00:16:25.040 --> 00:16:30.490
Here you can see a basic
monitoring graph.

00:16:30.490 --> 00:16:32.250
That's just showing nothing
is happening.

00:16:32.250 --> 00:16:34.240
It's a demo environment.

00:16:34.240 --> 00:16:35.910
There is no external user.

00:16:35.910 --> 00:16:39.300
And we will give it some loads
during the next demo.

00:16:39.300 --> 00:16:42.970
You can see the network traffic
as well that we are

00:16:42.970 --> 00:16:46.640
monitoring, and disk traffic.

00:16:46.640 --> 00:16:48.410
You will see here--

00:16:48.410 --> 00:16:51.060
let me zoom--

00:16:51.060 --> 00:16:54.040
that's a sample machine.

00:16:54.040 --> 00:16:55.230
So that's the name
of the machine.

00:16:55.230 --> 00:16:57.030
The machine is running.

00:16:57.030 --> 00:17:01.950
You see the profile of the
machine-- one CPU, 3.8

00:17:01.950 --> 00:17:03.460
gigabytes of memory.

00:17:03.460 --> 00:17:04.710
Where is the machine?

00:17:04.710 --> 00:17:06.640
So it's in US Central
this one.

00:17:06.640 --> 00:17:09.329
How many persistent disks are
attached to this machine?

00:17:09.329 --> 00:17:11.490
What is its external
IP address?

00:17:11.490 --> 00:17:12.740
And on which network?

00:17:12.740 --> 00:17:15.640
So that's a default network,
but you can create other

00:17:15.640 --> 00:17:20.050
networks with other rules, on
which the machine is deployed.

00:17:20.050 --> 00:17:22.430
And the images that the
machine is using.

00:17:22.430 --> 00:17:24.270
Here you see there are
some Ubuntu, GCEL.

00:17:24.270 --> 00:17:28.310
So that's a few machines we've
got on the project.

00:17:28.310 --> 00:17:30.250
Machine doing fractal
stuff, which is the

00:17:30.250 --> 00:17:33.100
point of the demo after.

00:17:33.100 --> 00:17:35.560
You see there are some
write images, so I

00:17:35.560 --> 00:17:37.430
guess it's Right Scale.

00:17:37.430 --> 00:17:39.380
And you see all your machines
and which state

00:17:39.380 --> 00:17:40.870
they are, et cetera.

00:17:40.870 --> 00:17:43.100
So now let's focus
on a machine, so

00:17:43.100 --> 00:17:46.670
that one, for example.

00:17:46.670 --> 00:17:49.860
You can put some tags on your
machine if you want to

00:17:49.860 --> 00:17:52.020
organize your machine
that way.

00:17:52.020 --> 00:17:55.090
Again, as I said, you see the
zone, external IP, internal

00:17:55.090 --> 00:17:57.380
IP, disks that are attached
to the machine.

00:17:57.380 --> 00:17:59.540
So this one is mode
one, 10 gigabytes.

00:17:59.540 --> 00:18:01.500
It has read and write access.

00:18:01.500 --> 00:18:04.940
You can add metadata, which is
useful going to want to use a

00:18:04.940 --> 00:18:07.530
launch script, et cetera,
with the API.

00:18:07.530 --> 00:18:09.660
And then you will see the
permissions the machine has

00:18:09.660 --> 00:18:11.740
with all the services.

00:18:11.740 --> 00:18:12.930
And you can [? recognize ?]

00:18:12.930 --> 00:18:14.420
storage, test use, Big Query.

00:18:14.420 --> 00:18:18.830
So that's why I said we have
integrated the projects to

00:18:18.830 --> 00:18:20.100
each other.

00:18:20.100 --> 00:18:25.890
So let's create one machine
right now, so you

00:18:25.890 --> 00:18:27.140
can see how it works.

00:18:30.980 --> 00:18:40.690
Test Bastien One, and
description, tags, metadata,

00:18:40.690 --> 00:18:42.840
so you add whatever
you want here.

00:18:42.840 --> 00:18:45.470
There, you define where you
want the machine to be.

00:18:45.470 --> 00:18:49.130
So you see I can deploy in
Europe or in US Central.

00:18:49.130 --> 00:18:52.460
Today, more zones
are coming in.

00:18:52.460 --> 00:18:57.290
So let's go in Europe West B.
And back to your question, the

00:18:57.290 --> 00:19:00.540
types of the machines, so you
can see you have the new

00:19:00.540 --> 00:19:05.010
machines, which are micro and
small, so very small, if you

00:19:05.010 --> 00:19:08.750
don't need power I don't know,
it's like a machine that is

00:19:08.750 --> 00:19:10.690
doing some networking stuff.

00:19:10.690 --> 00:19:13.110
You have the high CPU profile,
where you see the number of

00:19:13.110 --> 00:19:16.420
CPUs, and the low memory
best [? view. ?]

00:19:16.420 --> 00:19:20.370
But if you need a lot of memory,
here you can see high

00:19:20.370 --> 00:19:21.170
mem profile--

00:19:21.170 --> 00:19:26.150
two CPUs, 13 gigs, or even
eight CPUs, 52 gigs.

00:19:26.150 --> 00:19:27.780
That's the types of machines.

00:19:27.780 --> 00:19:31.390
You cannot yet define your own
type, like I want a three CPU

00:19:31.390 --> 00:19:35.200
or four CPU and 50 gigabytes.

00:19:35.200 --> 00:19:37.100
You have to choose the
closest today.

00:19:37.100 --> 00:19:40.040
MALE SPEAKER: So with the
RESTful API, is it only

00:19:40.040 --> 00:19:45.930
possible to specify
if [INAUDIBLE]?

00:19:45.930 --> 00:19:47.080
BASTIEN LEGRAS: Yeah, exactly.

00:19:47.080 --> 00:19:49.830
And from the API, you can list
which are the templates,

00:19:49.830 --> 00:19:51.870
because we are adding
new templates.

00:19:51.870 --> 00:19:54.550
So you can release the templates
dynamically, and

00:19:54.550 --> 00:19:57.330
say, OK, now I will take that
one because it's closest to my

00:19:57.330 --> 00:19:58.600
requirements.

00:19:58.600 --> 00:20:00.320
So that's a dynamic
list, actually.

00:20:03.730 --> 00:20:05.900
And you have other machines with
what we call a scratch

00:20:05.900 --> 00:20:07.800
disk, or ephemeral disk,
that was in my

00:20:07.800 --> 00:20:10.420
slide, that local storage.

00:20:10.420 --> 00:20:11.560
I can show them, by the way.

00:20:11.560 --> 00:20:15.350
So when there is the-- so you
see the machine, and it's

00:20:15.350 --> 00:20:16.130
local disk.

00:20:16.130 --> 00:20:18.620
So let's take, I don't
know, anything--

00:20:18.620 --> 00:20:20.240
high memory profile.

00:20:20.240 --> 00:20:22.860
Then you can boot from an
existing persistent disk.

00:20:22.860 --> 00:20:26.815
As I said earlier, if you need
to work on data you have

00:20:26.815 --> 00:20:32.620
persisted earlier, or you can
just take the scratch disk or

00:20:32.620 --> 00:20:36.280
a new disk that comes
with the image.

00:20:36.280 --> 00:20:37.290
So let's do that.

00:20:37.290 --> 00:20:43.240
Then you have the list of the
stock images we've got.

00:20:43.240 --> 00:20:47.740
So we build them frequently, so
you can see here we have--

00:20:47.740 --> 00:20:52.930
this is the US, so it's 7th of
May, 9th of May for Debian,

00:20:52.930 --> 00:20:55.460
CentOS and GCEL here.

00:20:55.460 --> 00:20:59.360
Or you can also save-- sorry.

00:20:59.360 --> 00:21:00.470
I hope you can see.

00:21:00.470 --> 00:21:02.130
If you can't see,
raise your hand.

00:21:02.130 --> 00:21:05.130
Or you can save your
own images.

00:21:05.130 --> 00:21:11.480
So other guys in my team, they
chose to create a Tomcat 6

00:21:11.480 --> 00:21:12.140
type of server.

00:21:12.140 --> 00:21:14.860
So it will have Tomcat already
pre-installed.

00:21:14.860 --> 00:21:17.540
Because when we did the
snapshot, we had already

00:21:17.540 --> 00:21:20.400
installed and configured
Tomcat.

00:21:20.400 --> 00:21:22.760
So let's take a standard
machine.

00:21:22.760 --> 00:21:24.390
And then you can add
other disks.

00:21:24.390 --> 00:21:27.780
If the machine has to work we
shared data, you can add other

00:21:27.780 --> 00:21:31.430
disks that you have
already created.

00:21:31.430 --> 00:21:32.900
We got in a network.

00:21:32.900 --> 00:21:34.750
So you will define in which
network you want

00:21:34.750 --> 00:21:37.205
the machine to belong.

00:21:37.205 --> 00:21:38.520
So let's keep the default.

00:21:38.520 --> 00:21:41.400
And then external IP, if the
machine has to have an

00:21:41.400 --> 00:21:44.440
external IP.

00:21:44.440 --> 00:21:47.350
And here, the access.

00:21:47.350 --> 00:21:49.480
So what it means is that if you
want the machine to have

00:21:49.480 --> 00:21:54.930
access to storage, read and
write, or no access, or to

00:21:54.930 --> 00:21:58.530
test use, we will pre-prog
this kind of access.

00:21:58.530 --> 00:22:01.660
So in your bigger projects, if
you're using App Engine in

00:22:01.660 --> 00:22:04.590
test use and you want this
machine to work with test use,

00:22:04.590 --> 00:22:08.240
then you will give it
access right now.

00:22:08.240 --> 00:22:11.340
Let's create the machine.

00:22:11.340 --> 00:22:15.250
So that's where everyone
cross your fingers.

00:22:15.250 --> 00:22:18.760
But basically, so
it's loading.

00:22:18.760 --> 00:22:22.210
It's going to the stage the
machine into Europe West,

00:22:22.210 --> 00:22:25.960
which is 20 milliseconds
from here, I think.

00:22:25.960 --> 00:22:30.400
And then we will see it
directly in the list.

00:22:30.400 --> 00:22:32.280
I have an error, but it's
not the same page.

00:22:32.280 --> 00:22:33.210
It's not my concern.

00:22:33.210 --> 00:22:33.830
Don't worry.

00:22:33.830 --> 00:22:35.420
It's still creating
the machine.

00:22:35.420 --> 00:22:36.470
It's another--

00:22:36.470 --> 00:22:41.030
and that's the demo I will do,
by the way, right after,

00:22:41.030 --> 00:22:42.580
hoping this one will work.

00:22:42.580 --> 00:22:46.390
In this demo, we're going to
create one, and here we're

00:22:46.390 --> 00:22:49.910
going to create 16, so 17
machines altogether, using--

00:22:49.910 --> 00:22:51.700
this is an App Engine app.

00:22:51.700 --> 00:22:53.920
And it's going to use the
REST API, of course,

00:22:53.920 --> 00:22:55.750
to create the machines.

00:22:55.750 --> 00:22:58.450
While it's still creating
there the machine.

00:22:58.450 --> 00:23:01.055
I think in a few seconds, the
machine should be there.

00:23:01.055 --> 00:23:03.290
Here it is.

00:23:03.290 --> 00:23:04.860
It's being created.

00:23:04.860 --> 00:23:08.250
So I guess it's alphabetical.

00:23:08.250 --> 00:23:12.560
Here it is, coming in,
in Europe West B.

00:23:12.560 --> 00:23:13.530
The machine is there.

00:23:13.530 --> 00:23:15.350
OK, quite fast, finally.

00:23:15.350 --> 00:23:16.360
I didn't measure.

00:23:16.360 --> 00:23:19.090
I think it was 20 seconds,
something like that.

00:23:19.090 --> 00:23:20.930
And the machine is available.

00:23:20.930 --> 00:23:23.760
And if you want to connect to
the machine right away, you

00:23:23.760 --> 00:23:30.870
have the REST snipped, or you
have the SSH command line you

00:23:30.870 --> 00:23:33.070
can directly use in
your terminal.

00:23:33.070 --> 00:23:35.420
So gcutil is the equivalent
of gsutil,

00:23:35.420 --> 00:23:38.110
but for Compute Engine.

00:23:38.110 --> 00:23:39.640
Let's clear that.

00:23:39.640 --> 00:23:43.310
I just passed the command line
gcutil, last version.

00:23:43.310 --> 00:23:44.755
That's the project--

00:23:44.755 --> 00:23:47.820
Google Platform Demo, SSH,
in that zone, the

00:23:47.820 --> 00:23:49.070
machine I just created.

00:23:52.430 --> 00:23:54.030
Normally what would
happen, it would

00:23:54.030 --> 00:23:56.800
ask for a login password.

00:23:56.800 --> 00:23:59.670
But no, because we have
integrated everything.

00:23:59.670 --> 00:24:01.660
So this is using OAuth.

00:24:01.660 --> 00:24:02.950
It's not visible?

00:24:02.950 --> 00:24:04.060
I'm going to zoom like
this, maybe.

00:24:04.060 --> 00:24:05.350
MALE SPEAKER: No, but
you can just--

00:24:05.350 --> 00:24:06.310
BASTIEN LEGRAS: Ah, sorry.

00:24:06.310 --> 00:24:08.690
MALE SPEAKER: So you can
enlarge your fonts.

00:24:08.690 --> 00:24:09.940
Yeah.

00:24:13.060 --> 00:24:14.800
BASTIEN LEGRAS: That's OK now?

00:24:14.800 --> 00:24:15.470
Sorry.

00:24:15.470 --> 00:24:16.420
MALE SPEAKER: [INAUDIBLE].

00:24:16.420 --> 00:24:17.510
BASTIEN LEGRAS: Good idea.

00:24:17.510 --> 00:24:18.760
Good idea, [? Fredo. ?]

00:24:23.470 --> 00:24:26.560
So I copied the GS2
command to SSH.

00:24:26.560 --> 00:24:30.000
And as I said, I didn't have to
enter login password, which

00:24:30.000 --> 00:24:32.800
is ultra-painful, by the way,
because what I've done is that

00:24:32.800 --> 00:24:38.120
the first time you run gcutil,
it will send you to a URL.

00:24:38.120 --> 00:24:40.780
You go to that URL
in your browser.

00:24:40.780 --> 00:24:44.810
This URL will ask you to
authenticate against Google.

00:24:44.810 --> 00:24:47.240
And if you authenticate
successfully, it will give you

00:24:47.240 --> 00:24:51.410
the OAuth key that you copy
paste back in gcutil.

00:24:51.410 --> 00:24:54.680
Which means that I have
authenticated gcutil to cloud

00:24:54.680 --> 00:24:57.680
platform on behalf of me.

00:24:57.680 --> 00:25:00.530
So now this gcutil installation
on my computer

00:25:00.530 --> 00:25:03.210
has access to the machines
to which I am

00:25:03.210 --> 00:25:05.920
authorized in the project.

00:25:05.920 --> 00:25:06.540
You understand that?

00:25:06.540 --> 00:25:10.270
It's very convenient, because no
need to log in, to remember

00:25:10.270 --> 00:25:11.920
password or whatever.

00:25:11.920 --> 00:25:13.790
And it's even more safe.

00:25:13.790 --> 00:25:14.790
So we are on the machine.

00:25:14.790 --> 00:25:20.460
So usually the demo stops there,
of course, because I

00:25:20.460 --> 00:25:24.680
don't have much things
to show here.

00:25:24.680 --> 00:25:25.230
I don't know.

00:25:25.230 --> 00:25:27.500
Let's check if the memory
is the right one.

00:25:27.500 --> 00:25:32.620
So we have our 26 gigabytes.

00:25:32.620 --> 00:25:35.710
What about the CPU?

00:25:35.710 --> 00:25:37.452
I need to--

00:25:37.452 --> 00:25:38.660
I have a hard time--

00:25:38.660 --> 00:25:40.910
OK.

00:25:40.910 --> 00:25:48.240
CPU info, so here you can
see, it's really big.

00:25:48.240 --> 00:25:51.840
My CPU numbers zero,
one, two, three.

00:25:51.840 --> 00:25:55.530
So there are four CPUs,
as we asked.

00:25:55.530 --> 00:25:58.990
And you see Intel Xeon CPU.

00:25:58.990 --> 00:26:01.040
You see the technical
detail of the CPU.

00:26:01.040 --> 00:26:02.490
So the machine is there.

00:26:02.490 --> 00:26:03.050
I am root.

00:26:03.050 --> 00:26:06.540
I can do whatever I want
on the machine.

00:26:06.540 --> 00:26:12.020
So let me do another demo before
we finish, and take

00:26:12.020 --> 00:26:14.500
some questions.

00:26:14.500 --> 00:26:20.210
The demo is nice and visual,
I hope it's going to work.

00:26:20.210 --> 00:26:21.920
OK, I don't want to mess up.

00:26:25.000 --> 00:26:26.030
Sorry.

00:26:26.030 --> 00:26:27.220
So this is an App Engine.

00:26:27.220 --> 00:26:33.300
And this is a demo that has been
I think showcased at I/O.

00:26:33.300 --> 00:26:36.280
This is App Engine.

00:26:36.280 --> 00:26:38.630
And the idea of this demo--
this is a very

00:26:38.630 --> 00:26:41.100
technological demo.

00:26:41.100 --> 00:26:44.460
The idea is to start
VMs using the API.

00:26:44.460 --> 00:26:46.060
That's what I'm going
to do right now.

00:26:46.060 --> 00:26:47.740
And I need to show
in parallel.

00:26:47.740 --> 00:26:47.980
Sorry.

00:26:47.980 --> 00:26:49.870
It's for the demo to
be nice to see.

00:26:54.140 --> 00:26:56.260
Sorry, I will have to do
something like this.

00:26:56.260 --> 00:26:57.860
So I want you to
see that list.

00:27:03.570 --> 00:27:09.940
And then the idea is
to start the VMs.

00:27:09.940 --> 00:27:12.840
As you can see, it's
coming blue here.

00:27:12.840 --> 00:27:16.300
So on the right, we have a
cluster, and on the left, a

00:27:16.300 --> 00:27:17.450
single instance.

00:27:17.450 --> 00:27:21.880
And here, on my poor console,
because I have [INAUDIBLE], we

00:27:21.880 --> 00:27:28.370
should see as soon as it's
going to be refreshed.

00:27:28.370 --> 00:27:28.790
Sorry.

00:27:28.790 --> 00:27:29.410
I'm going to [? force ?]

00:27:29.410 --> 00:27:29.800
refresh.

00:27:29.800 --> 00:27:31.050
Normally it's refreshed.

00:27:33.370 --> 00:27:36.350
OK, we're going to see
the fractal cluster--

00:27:36.350 --> 00:27:38.650
which is the one
I'm creating--

00:27:38.650 --> 00:27:40.300
that is being started.

00:27:40.300 --> 00:27:41.550
OK, this is this one.

00:27:44.200 --> 00:27:48.225
And on the right, the machine,
once they are green, the idea

00:27:48.225 --> 00:27:51.180
is that the machines
are ready to SSH.

00:27:51.180 --> 00:27:54.410
The program-- so App Engine
still, App Engine is going

00:27:54.410 --> 00:27:58.260
onto the machines, provision a
little program that will run

00:27:58.260 --> 00:28:00.960
some fractal imagery.

00:28:00.960 --> 00:28:03.130
So it's pure scientific computer
calculation, so it's

00:28:03.130 --> 00:28:05.220
using a lot of CPU.

00:28:05.220 --> 00:28:07.320
And then we will display--

00:28:07.320 --> 00:28:09.780
if it works, because
I am waiting also

00:28:09.780 --> 00:28:10.865
for the single instance--

00:28:10.865 --> 00:28:14.030
and display some fractal
imagery.

00:28:14.030 --> 00:28:16.700
And one is a distributed
calculation.

00:28:16.700 --> 00:28:17.770
The other is single.

00:28:17.770 --> 00:28:20.140
So we see how fast the machines
work together,

00:28:20.140 --> 00:28:24.610
because that's the type of use
case that requires a lot of

00:28:24.610 --> 00:28:26.360
network also.

00:28:26.360 --> 00:28:31.100
So the machines are there,
that just got created.

00:28:31.100 --> 00:28:33.560
I hope I can show.

00:28:33.560 --> 00:28:36.250
So I don't know why dimension
on the left, the single

00:28:36.250 --> 00:28:37.330
instance failed.

00:28:37.330 --> 00:28:39.610
But the idea is that the machine
on the right, as you

00:28:39.610 --> 00:28:45.110
can see here, zooming out, have
been able to create their

00:28:45.110 --> 00:28:47.450
own fractal.

00:28:47.450 --> 00:28:52.930
And then it will mark on the
right the render time.

00:28:52.930 --> 00:28:54.910
And it will calculate
as long as--

00:28:54.910 --> 00:29:00.340
when I zoom here, with my two
fingers, it's calculating the

00:29:00.340 --> 00:29:01.780
next layer of the fractal.

00:29:01.780 --> 00:29:04.120
So sorry half of the demo
here is not working.

00:29:04.120 --> 00:29:05.160
The idea--

00:29:05.160 --> 00:29:07.600
imagine that on the left, you
have exactly the same thing,

00:29:07.600 --> 00:29:10.200
but only one machine is
trying to do the job.

00:29:10.200 --> 00:29:13.390
Here, we have eight machines
doing the same job.

00:29:13.390 --> 00:29:16.660
So what we see on the left
usually is that the average

00:29:16.660 --> 00:29:20.320
render time is much bigger,
because it's only one core.

00:29:20.320 --> 00:29:21.960
And you can zoom,
you can zoom, it

00:29:21.960 --> 00:29:23.460
will calculate, calculate.

00:29:23.460 --> 00:29:25.870
So as soon as I zoom, it's
recalculated the fractal and

00:29:25.870 --> 00:29:28.020
rendered that in a distributed
calculation.

00:29:28.020 --> 00:29:29.950
Because all the machines are
doing the calculations.

00:29:33.190 --> 00:29:35.460
And it's really pretty.

00:29:35.460 --> 00:29:36.940
You can see the [? colors. ?]

00:29:36.940 --> 00:29:39.300
so that's the idea
on how fast.

00:29:39.300 --> 00:29:40.680
So how long did it take?

00:29:40.680 --> 00:29:42.580
I don't know, 30 seconds.

00:29:42.580 --> 00:29:46.790
And I could say three, eight, I
don't know, 128 machines, it

00:29:46.790 --> 00:29:47.570
would be the same.

00:29:47.570 --> 00:29:49.370
Because it's done in parallel.

00:29:49.370 --> 00:29:51.340
We do that every
day at Google.

00:29:51.340 --> 00:29:52.470
We have millions.

00:29:52.470 --> 00:29:55.845
We don't say exactly how much,
but are in the millions range

00:29:55.845 --> 00:29:59.310
in terms of size of cores.

00:29:59.310 --> 00:30:02.780
And then you just stop, and the
machine will be destroyed

00:30:02.780 --> 00:30:04.030
on the left.

00:30:05.790 --> 00:30:07.660
So App Engine is asking--

00:30:07.660 --> 00:30:09.730
OK, they are dying right now.

00:30:09.730 --> 00:30:12.100
It's asking for the--

00:30:12.100 --> 00:30:13.340
I don't know where they are.

00:30:13.340 --> 00:30:14.160
They should go.

00:30:14.160 --> 00:30:15.820
Maybe they already disappeared,
because they are

00:30:15.820 --> 00:30:17.720
already red.

00:30:17.720 --> 00:30:18.660
They already disappeared.

00:30:18.660 --> 00:30:20.720
But usually you see
it live, also.

00:30:20.720 --> 00:30:21.370
Here, you see the--

00:30:21.370 --> 00:30:22.380
OK, here they are.

00:30:22.380 --> 00:30:22.910
You see?

00:30:22.910 --> 00:30:24.160
It's spinning right there.

00:30:24.160 --> 00:30:28.890
They are dying, right there,
one after one.

00:30:28.890 --> 00:30:30.470
And now they have disappeared.

00:30:30.470 --> 00:30:31.570
I hope you caught it.

00:30:31.570 --> 00:30:34.540
But it has destroyed the
machine, and then it's ready

00:30:34.540 --> 00:30:36.550
back for another demo.

00:30:36.550 --> 00:30:38.410
OK, I'm done for the
[? pres-- ?]

00:30:38.410 --> 00:30:42.330
I can take some questions, if
you have, before we go into

00:30:42.330 --> 00:30:43.300
the coffee break.

00:30:43.300 --> 00:30:44.140
Yes?

00:30:44.140 --> 00:30:46.750
We'll try to pass the mic.

00:30:46.750 --> 00:30:47.800
[? We have ?] one mic.

00:30:47.800 --> 00:30:49.770
Thanks.

00:30:49.770 --> 00:30:50.440
MALE SPEAKER: Ciao, Bastien.

00:30:50.440 --> 00:30:53.090
It's more a pricing question.

00:30:53.090 --> 00:30:56.720
If I have some data, some files,
terabytes on the Cloud

00:30:56.720 --> 00:31:01.660
Storage, and I launch 10 virtual
machines which share

00:31:01.660 --> 00:31:04.770
the data on the cloud storage,
do I pay for

00:31:04.770 --> 00:31:08.150
this internal exchange?

00:31:08.150 --> 00:31:09.290
BASTIEN LEGRAS: So
good question.

00:31:09.290 --> 00:31:16.540
So we don't charge for cloud
platform service to cloud

00:31:16.540 --> 00:31:18.670
platform service network
exchange.

00:31:18.670 --> 00:31:21.600
So what it means is that you can
do any traffic between App

00:31:21.600 --> 00:31:24.160
Engine and Cloud Storage and
Compute Engine, between

00:31:24.160 --> 00:31:26.830
Compute Engine machines, between
Compute Engine zones,

00:31:26.830 --> 00:31:29.850
inter-network between Compute
Engine and of

00:31:29.850 --> 00:31:30.490
course Cloud Storage.

00:31:30.490 --> 00:31:32.870
It won't cost you anything
in terms of network.

00:31:32.870 --> 00:31:36.940
What you will only pay
is your 10 terabytes.

00:31:36.940 --> 00:31:37.560
MALE SPEAKER: The storage?

00:31:37.560 --> 00:31:39.620
BASTIEN LEGRAS: So one terabyte
is $50, so you're

00:31:39.620 --> 00:31:42.020
going to pay maybe
$500, I think.

00:31:42.020 --> 00:31:43.960
I can show the pricing
[? slide. ?]

00:31:43.960 --> 00:31:47.460
And then you will pay
for your machines.

00:31:47.460 --> 00:31:50.420
Maybe you want to have a look,
because the pricing question I

00:31:50.420 --> 00:31:52.700
think is interesting
for all of you.

00:31:52.700 --> 00:31:54.330
It's fully public.

00:31:54.330 --> 00:31:56.680
We have nothing to hide.

00:31:56.680 --> 00:31:58.870
We are transparent.

00:31:58.870 --> 00:32:02.190
So cloud.google.com, as you
understand, is the site to go.

00:32:02.190 --> 00:32:03.120
This is everything.

00:32:03.120 --> 00:32:04.900
From there, you can
find everything--

00:32:04.900 --> 00:32:10.910
the project, the project
explanation, data sheet, the

00:32:10.910 --> 00:32:13.790
website to developers where
you can see all the API

00:32:13.790 --> 00:32:15.270
documentation.

00:32:15.270 --> 00:32:16.920
And, of course, there
is the pricing,

00:32:16.920 --> 00:32:19.260
and pricing by project.

00:32:19.260 --> 00:32:22.060
So App Engine pricing is the
most complex, because we want

00:32:22.060 --> 00:32:25.810
to be really fair, to really
price only what you use.

00:32:25.810 --> 00:32:32.370
As you can see, you will
be priced by what

00:32:32.370 --> 00:32:33.630
you are using exactly.

00:32:33.630 --> 00:32:36.510
If you are using front-end
instances, dynamic, et cetera,

00:32:36.510 --> 00:32:38.350
you have the price per hour.

00:32:38.350 --> 00:32:42.770
Datastore API, we price
every 100k operations.

00:32:42.770 --> 00:32:47.030
We have a very [? fine ?] rate
for that kind of pricing.

00:32:47.030 --> 00:32:51.810
For storage, it's very
easier to understand.

00:32:51.810 --> 00:32:55.070
There is always a free tier,
so you can try for free.

00:32:55.070 --> 00:32:56.380
You have a free tier
five gigabytes

00:32:56.380 --> 00:32:57.270
of storage, et cetera.

00:32:57.270 --> 00:32:59.430
So you can try and
use storage.

00:32:59.430 --> 00:33:00.770
We have two types of storage.

00:33:00.770 --> 00:33:04.380
So the most replicated, and what
we call durable, reduced

00:33:04.380 --> 00:33:08.120
availability, less replicated,
which is of course cheaper.

00:33:08.120 --> 00:33:11.630
We do pricing in Euros, if you
want to pay in Euros with a

00:33:11.630 --> 00:33:12.720
contract, et cetera.

00:33:12.720 --> 00:33:14.530
And we price, of course,
depending on

00:33:14.530 --> 00:33:15.920
how much you need.

00:33:15.920 --> 00:33:20.720
So if you are in the 100
terabytes range, we will price

00:33:20.720 --> 00:33:21.640
by gigabyte.

00:33:21.640 --> 00:33:23.820
This is a gigabyte per month
price, that one.

00:33:23.820 --> 00:33:28.210
So if you had 10 terabytes,
you can see, it's 54--

00:33:28.210 --> 00:33:32.350
so $540 per month.

00:33:32.350 --> 00:33:35.560
And for the network, as we say,
everything that goes into

00:33:35.560 --> 00:33:39.010
the network is free.

00:33:39.010 --> 00:33:41.280
Of course, we charge for the
network, so egress network

00:33:41.280 --> 00:33:43.810
from Google to the internet
to your users.

00:33:43.810 --> 00:33:46.110
And that's the type of price.

00:33:46.110 --> 00:33:49.250
But there is no
service-to-service cost.

00:33:49.250 --> 00:33:53.430
So internal Google transfers
are free, and then some

00:33:53.430 --> 00:33:54.320
operation costs.

00:33:54.320 --> 00:33:58.150
But every 1,000 application
operations is $0.01.

00:33:58.150 --> 00:33:59.610
So basically you won't see it.

00:33:59.610 --> 00:34:03.310
And Compute Engine, very key,
so that's really important.

00:34:03.310 --> 00:34:06.070
That's something we announced
at I/O. So if you use the

00:34:06.070 --> 00:34:09.389
machine six minutes, we're going
to charge 10 minutes.

00:34:09.389 --> 00:34:11.810
If you use the machine 10
minutes, we charge 10 minutes.

00:34:11.810 --> 00:34:14.270
If you use it 11 minutes,
we charge 11 minutes.

00:34:14.270 --> 00:34:19.409
You see, so there is a minimum
set of 10 minutes, and then we

00:34:19.409 --> 00:34:20.790
charge by the minute.

00:34:20.790 --> 00:34:23.290
And then for all the machine
types you have seen earlier

00:34:23.290 --> 00:34:26.510
when I was creating a machine,
you have a price depending if

00:34:26.510 --> 00:34:28.900
the machine is in Europe
or the US.

00:34:28.900 --> 00:34:31.520
And you have a price which is
per hour, so you can divide by

00:34:31.520 --> 00:34:33.780
60 to have the by
minute price.

00:34:33.780 --> 00:34:37.929
And you have a price for each
type of machine, of course.

00:34:37.929 --> 00:34:40.870
So whether you need or not a
local disk on the machine, so

00:34:40.870 --> 00:34:44.550
that's the size of
the local disk.

00:34:44.550 --> 00:34:48.060
The high memory profile, so
you see two cores, 13

00:34:48.060 --> 00:34:50.210
gigabytes, instead
of two cores.

00:34:50.210 --> 00:34:54.909
So it's twice of it, almost,
up to 52 gigabytes.

00:34:54.909 --> 00:34:56.219
So here is everything
[INAUDIBLE].

00:34:56.219 --> 00:34:59.140
And here, it's a ratio CPU or
memory, whether that is

00:34:59.140 --> 00:35:00.950
bigger, so less memory
per CPU.

00:35:00.950 --> 00:35:02.150
If it's an [? HPC ?]

00:35:02.150 --> 00:35:05.110
use case, you may want
to use that.

00:35:05.110 --> 00:35:06.960
And you have the very new ones,
which are the small

00:35:06.960 --> 00:35:09.040
ones, the micro and the small.

00:35:09.040 --> 00:35:13.110
So we are at $0.021.

00:35:13.110 --> 00:35:16.050
It's very small, about
$0.2 an hour.

00:35:16.050 --> 00:35:22.380
And again, network pricing
between our services or in the

00:35:22.380 --> 00:35:23.550
same zone is free.

00:35:23.550 --> 00:35:27.410
We charge only external
network.

00:35:27.410 --> 00:35:31.440
And then we reduce, depending
on the amount of network.

00:35:31.440 --> 00:35:34.350
I'm not the commercial, but as
Kristoff said earlier, if

00:35:34.350 --> 00:35:36.650
you're interested in a
professional contract with

00:35:36.650 --> 00:35:42.740
support, you can see there are
several support packages,

00:35:42.740 --> 00:35:43.990
which is there.

00:35:46.880 --> 00:35:50.490
So we do up to Platinum with
dedicated account manager for

00:35:50.490 --> 00:35:52.440
you, et cetera.

00:35:52.440 --> 00:35:55.740
But we have the free one, so you
can, of course, access to

00:35:55.740 --> 00:35:59.730
the [INAUDIBLE], to the Stack
Overflow, et cetera.

00:35:59.730 --> 00:36:01.070
There's silver, so you
can do ticket.

00:36:01.070 --> 00:36:03.190
You can call, call in.

00:36:03.190 --> 00:36:03.820
And Gold--

00:36:03.820 --> 00:36:06.110
and Gold is like, you have a
committed response time.

00:36:06.110 --> 00:36:10.220
And you have all the various
commitments here, at the

00:36:10.220 --> 00:36:11.410
pricing detail.

00:36:11.410 --> 00:36:13.540
And if you are interested in
that type of support, if you

00:36:13.540 --> 00:36:16.420
are in production, you have
customers, you need to make

00:36:16.420 --> 00:36:19.480
sure it's going to be up, it's
not just test and development,

00:36:19.480 --> 00:36:21.150
then you just contact
us right there.

00:36:21.150 --> 00:36:24.520
That will arrive on
Kristoff's table.

00:36:24.520 --> 00:36:25.390
So very simple.

00:36:25.390 --> 00:36:27.300
Everything is there.

00:36:27.300 --> 00:36:30.730
And on the videos, everything
is, if you search for Google

00:36:30.730 --> 00:36:34.370
I/O sessions, you will
find them right here.

00:36:34.370 --> 00:36:37.240
And you can choose your track,
and of course, my track is

00:36:37.240 --> 00:36:39.440
Cloud Platform.

00:36:39.440 --> 00:36:41.170
OK, I think we're good.

00:36:41.170 --> 00:36:43.100
Maybe you want to have your
coffee break now.

00:36:43.100 --> 00:36:44.000
[APPLAUSE]

00:36:44.000 --> 00:36:45.250
BASTIEN LEGRAS: Thank
you very much.

