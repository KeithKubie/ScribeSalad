Speaker 1:          00:00          The Joe Rogan experience.

Speaker 2:          00:02          That's what I was kind of getting out. Are you concerned at all with artificial life? Are you concerned about the propagation of, of artificial intelligence?

Speaker 1:          00:10          Well, there are different kinds of artificial life. So, um, one is artificial intelligence and I know people like Elon Musk and late Stephen hawking or are afraid. Terrified. Yeah. And I think that we need, whether it's right or not, I think it's great for us to focus on those risks because if we just say, oh that's, that's crazy and we don't focus on it, it increases the likelihood of these bad things happening. So Kudos to, to Elon Musk. But I also think that we are, we're a long way away from that threat and we are and we will be enormous beneficiaries of these technologies. And that's why my, I don't want to sound like a broken record, but that's why I keep saying it's all about values. If I think we should take those threats very seriously and then say his are so abstract and we don't agree on them, it's true. But like, like Elon Musk, I mean they've set up this, this institute where to say, well, what are the dangers, right? And then what are the things that we can do now, what are standards that we can integrate, for example, into our computer programming. And so I mentioned my World Health Organization a committee, the question is, well, what are the, what are the standards that we can integrate into scientific culture that's not going to cure everything, but it may increase the likelihood rather better rather than worse.

Speaker 2:          01:21          But isn't there an inherent danger in other companies or other countries rather not complying with any standards that we said? Because there would be anti competitive yes. Like that would, that would, it would somehow or another diminish competition or diminish their competitive edge.

Speaker 1:          01:36          It's true. And that's why, and that's the balance that we're, we're going to need to need to hold. It's, and it's really hard, but we have a window of opportunity now to try to get ahead of that. And like I said, we have chemical weapons, biological weapons, nuclear weapons where we've had international standards that have roughly held, I mean there was a time when slavery was the norm and there was a movement to say this is, this is wrong. And it was largely successful. So we have history of being more successful rather than, uh, than less. And I think that's the goal. But you're, you're right. I mean this is a race between the technology and the best value.

Speaker 2:          02:14          My, I'm real concerned about artificial intelligence is that this paradigm shifting moment will happen before we recognize it's happening and then it'll be

Speaker 1:          02:22          too late. Yes, that's exactly right. And that's like I saying, that's, that's why I've written the book. That's why I'm out on the road so much talking to people. Why, why? It's such an honor for me to be in pleasure for me to be here with you talking about it. Cause we have to reach out to people and people can't be afraid of entering this conversation because it feels too technical or it feels like it's somebody else's business. This is all of our business because this is all of our lives and it's all of our futures.

Speaker 2:          02:48          So if in the future, you think 20 years, the thing that's gonna really change the most is predictive genetics and to be able to be able to predict accurately a person's health. What do you think in life, health and law. Yeah. What

Speaker 1:          03:00          do you think is going to be the biggest detriment for all this stuff and the thing that we have to avoid the most? Yeah, so one is, as I mentioned, this determinism, just because if we just tend to take our sense of wonder about what it means to be a human away, like that's really going to harm us. We talked about equity and access to these technologies and, and the technologies don't even need to be real in order to have a negative impact. So in India, there are no significant genetic differences between people in different castes, but the caste system has been maintained for thousands of years because people just have accepted these, uh, these differences. So this, it's a whole new way of, of understanding what is a human. And it's really going to be complicated and we aren't ready for it. We weren't ready for it.

Speaker 1:          03:51          Culturally, we aren't ready for it educationally. Certainly our political leaders aren't paying much of any attention to all this. So you have a huge job. Oof. Oof. So when you sit down and you give this speech to Congress, yeah. What, what are you anticipating from them in terms of like what do you think that there's anything that they can do now? Absolutely certain steps. Yes. So a few things. One is we need to have a national education campaign. I mean, this is so important. I would say it's on the future of genetics revolution and of Ai because I think we, it's just, it's, it's crazy. Um, that we aren't focusing on these. Like I, I learned French in, in, um, in grade school and high school and I'm happy to speak French, but I would rather have people say this is really important stuff. So that's, uh, that's number one.

Speaker 1:          04:43          Number two is we need to make sure that we have a functioning regulatory system in, in this country, in every country. And I do a lot of of comparative work. And like the United Kingdom, they're really well organized. They have a national healthcare system which allows them at a national level to kind of think about longterm care and the tradeoffs in this country. Average person changes health plans every 18 months. And I was talking with somebody the other night and they were, they were working on a predictive health company and they said their first idea was they were going to sell this information, um, to, uh, health insurers because like wouldn't this be great if you could? Hell, if you're a health insurer and you could, you had somebody who was your client and you could say, hey, here's some information. You can live healthier and you're not going to have this disease 20 years from now. And when he found out is the health insurers, they could have cared less because people were just, they were only going to be part of it for a year and a half. So we really need to think differently about how do we invest in people over the course of their lives. And certainly education is one, but thinking longterm about health and wellbeing is another.