WEBVTT
Kind: captions
Language: en

00:32:00.234 --> 00:32:03.887
      &gt;&gt; I'm going to put in a 
password.  Submit, save, and 

00:32:04.109 --> 00:32:08.769
 I'm a new balance rewards 
member                        

00:32:09.312 --> 00:32:12.173
Balance Rewards member.  So very
, very cool.  

00:32:12.174 --> 00:32:16.007
 Again, it's as simple as 
tapping in a Walgreens terminal 

00:32:16.159 --> 00:32:20.038
in 
 order to use this Balance Re

00:32:20.193 --> 00:32:23.170
wards card.  We made it very, 
 very simple and available to 

00:32:23.366 --> 00:32:25.821
all merchants as well.  Let's 
 go and try to complete this 

00:32:25.987 --> 00:32:28.709
purchase here and show you what 
 the experience looks like.

00:32:29.015 --> 00:32:33.548
     So we have here a terminal,
 can we switch to this.  

00:32:33.549 --> 00:32:36.950
 Yeah.  We have here a terminal.
  This is a actual Walgreens 

00:32:36.951 --> 00:32:38.951
 terminal.

00:32:44.134 --> 00:32:46.638
  We're going to show you what 
it's like to make a 

00:32:46.639 --> 00:32:51.329
 purchase of one of these really
 nice like almonds.  Turns 

00:32:51.330 --> 00:32:56.171
 out it normally costs $5.99.  
Can you just focus in a 

00:32:56.172 --> 00:33:00.264
 little bit close er on it so 
you can actually see the charge?

00:33:00.677 --> 00:33:06.453
     Okay.  So I think you 
notice it, right.  It's $5.99, 

00:33:06.675 --> 00:33:10.008
 except that that's just the 
regular price.  If you have a 

00:33:10.721 --> 00:33:17.802
 Balance cap rewards            
 Rewards card you get a price 

00:33:17.905 --> 00:33:21.141
break on this, which 
 is very cool, saves you money. 

00:33:21.289 --> 00:33:24.923
 I'm going to show you how 
 easy it is to use your Balance 

00:33:25.564 --> 00:33:29.356
Rewards card with Android 
 Pay.  I don't have to open the 

00:33:29.476 --> 00:33:31.813
app, I don't have to open 
 Android Pay to use it, et 

00:33:31.814 --> 00:33:35.544
cetera.  I'm just going to tap 
( 

00:33:35.545 --> 00:33:41.514
 (ding) and I've transferred my 
Balance Rewards card.  That 

00:33:41.515 --> 00:33:46.035
 simple.  I've got a price break
 and the new price is $3.99, 

00:33:46.267 --> 00:33:50.129
 and it completes the purchase. 
 All I have to do is tap 

00:33:50.130 --> 00:33:53.670
 again, transfer my Amex and the
 purchase is done.  Okay.

00:33:53.828 --> 00:33:55.828
     (Applause)

00:34:03.405 --> 00:34:07.895
 this experience, so look 
 forward to sees more merchants 

00:34:07.896 --> 00:34:10.647
integrate to this experience 
 so you can engage your 

00:34:11.023 --> 00:34:13.487
customers better and your 
customers 

00:34:13.488 --> 00:34:17.421
 get to save money.
     So with that, I want to 

00:34:17.550 --> 00:34:20.939
hand it over to Sridhar
        &gt;&gt; SRIDHAR RAMASWAMY:  

00:34:21.097 --> 00:34:23.938
Thank you, Pali.  These are 
 some amazing demos again.  Of 

00:34:23.939 --> 00:34:26.470
course, we wanted to make 
 sure that we did something for 

00:34:26.984 --> 00:34:32.046
small and medium-size ed 
 merchants as well.  So we work 

00:34:32.047 --> 00:34:34.191
with Square to make 
 available for a limited time to

00:34:34.192 --> 00:34:40.548
 qualified retailors a free 
 contact list reader as well as 

00:34:40.862 --> 00:34:42.414
a discounted payment 
process       

00:34:42.415 --> 00:34:44.739
 processing on all Android Pay 
transactions.  We want to 

00:34:44.740 --> 00:34:49.744
 make sure that all merchants 
get benefit that consumers use 

00:34:49.969 --> 00:34:53.212
 Android Pay to pay.
       I want to touch on 

00:34:53.333 --> 00:34:54.508
something really, really 
important         

00:34:54.509 --> 00:34:56.631
 important.  It's the last 
portion of our talk, but it's 

00:34:56.898 --> 00:34:59.168
 super critical.  It hits many 
of the points that I talked 

00:34:59.169 --> 00:35:05.505
 about early ier.  It's clear 
that financial institutions, the

00:35:09.863 --> 00:35:10.754
debit, all of these relation 

00:35:10.755 --> 00:35:14.269
 relationships with, need to 
play an active role in move ing 

00:35:14.579 --> 00:35:19.036
 the mobile payment ecosystem 
forward.

00:35:19.037 --> 00:35:25.298
       And when we envisioned 
Android Pay, we create ed APIs 

00:35:25.534 --> 00:35:30.470
 that these banks could use to 
bring the payment experience 

00:35:31.487 --> 00:35:35.447
 right within their app.  Why is
 this a big deal?  Because 

00:35:35.448 --> 00:35:40.939
 there is a lot of detail to 
implementing a great payment 

00:35:41.687 --> 00:35:43.908
 experience.  And they could 
integrate it right into their 

00:35:43.977 --> 00:35:48.726
 app, save ing themselves a lot 
of implementation headaches, 

00:35:48.878 --> 00:35:52.491
 security headaches, and of 
course, time, which is the most 

00:35:52.778 --> 00:35:59.301
 important current cy.
       And they do that, then 

00:35:59.444 --> 00:36:01.675
they're free to innovate on 
 what else they offer their 

00:36:02.669 --> 00:36:06.392
consumers.  These banks are 
 often the ones that know us 

00:36:06.515 --> 00:36:08.830
best.  They're the ones that 
 are observe ing our 

00:36:09.118 --> 00:36:10.549
transactions.  They are the ones
 that we 

00:36:10.550 --> 00:36:13.080
 have relationships with.  We 
think this will drive a lot of 

00:36:13.589 --> 00:36:16.461
 innovation in how mobile 
payments are brought out to 

00:36:16.462 --> 00:36:20.511
 consumers.
       So we are very please ed 

00:36:20.512 --> 00:36:26.130
that a number of banks, both 
 in the U.S. and abroad, are 

00:36:26.131 --> 00:36:32.206
working with us to integrate 
 Android Pay directly into their

00:36:32.207 --> 00:36:35.569
 app.  We think this will 
 drive more innovation and 

00:36:36.001 --> 00:36:39.865
provide more flexibility for 
 consumers.  We think of this as

00:36:39.866 --> 00:36:45.575
 a win/win for Android, 
 Android Pay, and for, you know,

00:36:45.576 --> 00:36:48.703
 these banks, and, of course 

00:36:48.704 --> 00:36:53.530
 course, consumers as well.
       And with that, now I want

00:36:53.531 --> 00:36:59.443
 to thank all of you, our 
 developer partners,s in 

00:36:59.571 --> 00:37:01.606
bringing this Android story 
forward       

00:37:01.607 --> 00:37:04.557
 forward.  Without us working 
together, there is not going 

00:37:04.656 --> 00:37:08.815
 to be a lot of involunteer 
            innovation, and so 

00:37:09.060 --> 00:37:11.621
we really look to working 
 with you to improve the way 

00:37:11.754 --> 00:37:16.604
mobile payments work and for us 
 to get passed the which bay is 

00:37:16.763 --> 00:37:19.118
doing what, and more to 
 mobile payments just work in a 

00:37:19.253 --> 00:37:24.805
way that is expected and 
 convenient for all of us.

00:37:25.118 --> 00:37:28.501
       So thanks to all of you 
for helping us realize this 

00:37:28.502 --> 00:37:34.279
 vision of Android Pay being 
everywhere in mobile app, in 

00:37:34.424 --> 00:37:38.685
 physical stores, in mobile web 
as well.

00:37:38.686 --> 00:37:41.846
       So Pali and I have barely
 touched on the surface of 

00:37:41.847 --> 00:37:45.372
 topics that can literally take 
days of discussion.  You're 

00:37:45.373 --> 00:37:47.763
 going to be having lots of 
break-out sessions over the next

00:37:50.276 --> 00:37:55.996
 after this session, right 
 here, so please come to those, 

00:37:55.997 --> 00:37:58.198
ask us lots of questions, 
 there will be folks       folks

00:37:58.199 --> 00:38:00.190
 from the payments team in all 
of these 

00:38:00.191 --> 00:38:03.483
 breakouts sessions.  We look 
forward to talking with you 

00:38:03.484 --> 00:38:07.407
 and really helping bring this 
vision of Android Pay to the 

00:38:07.892 --> 00:38:11.718
 large er role.  With that, 
thank you all for coming..

01:02:10.756 --> 01:02:14.046
 next section, we are going to 
dive into the latest and great

01:02:14.341 --> 01:02:19.772
est feature for accessibility in
 Android, and we had a lot of 

01:02:19.857 --> 01:02:23.895
very exciting things to share 
with you.

01:02:23.896 --> 01:02:29.159
The first one is vision setting 
on the welcome screen.  This 

01:02:29.160 --> 01:02:33.780
will enable visual impaired 
users to independently set up 

01:02:33.781 --> 01:02:41.007
their device.  Now, can we 
switch, please, to the

01:02:44.160 --> 01:02:50.264
 Dem?  This is the main screen, 
the welcome screen on Android.  

01:02:50.265 --> 01:02:53.844
Here at the bottom we have 
vision settings that flashes 

01:02:53.845 --> 01:02:56.983
every ten seconds.

01:03:02.071 --> 01:03:07.453
 if I tap on that, I'm presented
 a couple of options.  I have 

01:03:07.454 --> 01:03:12.544
magnification gesture, font size
, display size, talkback.  For 

01:03:12.545 --> 01:03:16.851
example, I can select 
magnification gesture and then I

01:03:17.471 --> 01:03:23.264
 can triple tap and I can 
increase the size and magnify 

01:03:23.265 --> 01:03:28.567
the UU.
Now           UI.  The other 

01:03:28.568 --> 01:03:31.680
ption I want to                 
option I want to highlight is 

01:03:31.681 --> 01:03:34.868
display size.  This is a new 
feature launched in Android.  If

01:03:34.869 --> 01:03:37.357
 this is the regular screen 
size     size, I can increase 

01:03:37.358 --> 01:03:43.877
the size of the overall UI.  to 
be bigger.  The nice thing about

01:03:44.073 --> 01:03:47.179
 all those settings, that 
whatever settings I'm selecting 

01:03:47.180 --> 01:03:51.767
it's going to be reflected both 
through all the welcome screen, 

01:03:52.284 --> 01:03:57.931
but also as the user setting 
throughout the device.

01:03:58.168 --> 01:04:00.168
Back to the slides

01:04:04.298 --> 01:04:08.660
. feature is monoaudio support. 
 This one is intended for people

01:04:09.664 --> 01:04:15.668
 who have a hearing loss in one 
ear.  This enabled them to 

01:04:15.669 --> 01:04:19.861
listen to monoaudio stream, and 
we do that by combining the left

01:04:19.862 --> 01:04:26.863
 and right channel into a single
 mono audio stream. have a 

01:04:26.864 --> 01:04:30.777
couple of new features in talk
back including improved tutorial

01:04:31.266 --> 01:04:34.575
 clarity, improved gesture 
detection to work better across 

01:04:34.576 --> 01:04:39.872
different devices and hardware, 
and also we added a new API for 

01:04:39.873 --> 01:04:44.176
accessibility service to turn 
themselves off.  So if the user 

01:04:44.177 --> 01:04:47.673
accidentally turn on talkback
          talkback on the 

01:04:47.674 --> 01:04:52.620
welcome screen, it can easily 
turn it off.

01:04:52.878 --> 01:04:56.541
Now, the next section is about 
the gesture dispatch API.  This 

01:04:56.542 --> 01:04:58.542
is something that I'm personally

01:05:00.696 --> 01:05:03.658
 very excited about it, because 
now we will allow app developer 

01:05:03.659 --> 01:05:09.293
to build services such as points
 scanning, face tracker and eye 

01:05:09.601 --> 01:05:14.487
tracker.  For the next one, I'd 
like to invite Anna, a engineer 

01:05:14.488 --> 01:05:22.190
on accessibility team to demo 
the APIs.)

01:05:26.512 --> 01:05:28.695
.
&gt;&gt; Thanks, Maya.  I'm Anna, I'll

01:05:28.696 --> 01:05:33.902
 tell but the new gesture 
dispatcher API, accessibility 

01:05:33.903 --> 01:05:36.319
services, touching the screen.  
First of all, what is a touch?  

01:05:36.320 --> 01:05:40.883
It has three parts.  Placing a 
fink other the                

01:05:40.884 --> 01:05:45.277
finger on the screen, drawing a 
gesture and lifting the finger. 

01:05:48.281 --> 01:05:48.970
 The new API letle you          
 let's you as a developer 

01:05:48.971 --> 01:05:52.486
specify the middle portion, the 
path taken by a imaginary finger

01:05:52.700 --> 01:05:55.894
 or fingers.  Why is this 
important for accessibility?  

01:05:55.895 --> 01:05:58.389
Take a look at switch access, a 
accessibility service that does 

01:05:58.795 --> 01:06:01.788
not assume that you can touch 
the screen.  Rather, it lets you

01:06:02.596 --> 01:06:07.231
 use a switch or set of switches
 to move across actionable views

01:06:07.498 --> 01:06:12.007
 and select the currently 
highlighted view.

01:06:12.008 --> 01:06:14.398
This leaves off functionality, 
when you don't want to interact 

01:06:14.399 --> 01:06:18.688
with the entire view, but rather
 a small part of it.  The 

01:06:18.689 --> 01:06:23.003
example that I'll be using is 
Google Maps, specifically the 

01:06:23.004 --> 01:06:26.603
maps area which supports complex
 gestures, things like zooming 

01:06:26.786 --> 01:06:31.717
in and out, and padding the 
advice ab area.             

01:06:31.900 --> 01:06:35.505
        the visible area.  With 
this API we can add point 

01:06:35.506 --> 01:06:39.736
scanning to switch access and 
that lets us perform complex 

01:06:39.737 --> 01:06:43.514
gestures.  Let's look at how we 
can use one switch, to operate 

01:06:43.515 --> 01:06:45.515
Google Maps.

01:06:54.734 --> 01:06:58.519
We will start in the maps app.  
You notice I have a switch 

01:06:58.520 --> 01:07:01.998
already connected to my dives 
      device.  I'd like to get 

01:07:01.999 --> 01:07:05.318
walking directions to the three 
buildings just west of here.  I 

01:07:05.319 --> 01:07:07.414
don't quite remember what they 
are called.  But fortunately, 

01:07:07.616 --> 01:07:10.225
once we make a selection on the 
map, we can get directions that 

01:07:10.226 --> 01:07:15.730
way.  Here it seems like I don't
 see those three buildings on 

01:07:15.731 --> 01:07:18.765
the map.  I'll have to pan to 
get to see them.

01:07:19.119 --> 01:07:22.119
I'll start point scanning by 
pressing the switch.  The first 

01:07:22.120 --> 01:07:25.518
thing I'll do now is select 
where I want to perform that 

01:07:25.519 --> 01:07:29.092
gesture        gesture.  First 
the white coordinate  

01:07:29.403 --> 01:07:32.490
                Y coordinate and
 then the X coordinate.  Here 

01:07:32.491 --> 01:07:34.491
I'll choose to swipe right.

01:07:38.546 --> 01:07:40.905
Now at the lower left, we see 
the three buildings that I'd 

01:07:41.134 --> 01:07:46.402
like to walk to.  I'm going to 
place a pin there by pressing, 

01:07:46.596 --> 01:07:50.222
I'll start by choosing the 
location first.  Starting with 

01:07:50.223 --> 01:07:56.599
the Y coordinate again, and then
 the X coordinate, and here I'll

01:07:57.234 --> 01:07:59.605
 choose long press from the 
actions menu.

01:08:03.557 --> 01:08:06.124
This gives me a button at the 
bottom of the screen, asking 

01:08:06.125 --> 01:08:09.458
whether I'd like walking 
directions.  As that is exactly 

01:08:09.616 --> 01:08:13.029
what I want, I'm going to select
 that button.  Again, I'll 

01:08:13.122 --> 01:08:15.533
choose the location first

01:08:22.842 --> 01:08:31.208
.  And here I'll choose select. 
 Here we are.  Directions to the

01:08:31.415 --> 01:08:34.538
 point we just chose from the 
map using just one switch.

01:08:34.820 --> 01:08:37.925
I'll hand the mic back to Maya 
now who will tell you about 

01:08:37.926 --> 01:08:40.570
another cool application of the 
gesture dispatch API.

01:08:40.571 --> 01:08:42.947
  (applause)

01:08:48.641 --> 01:08:49.200
.
&gt;&gt; MAYA BEN ARI: Thank you, Anna

01:08:49.201 --> 01:08:57.003
, for the demo.next demo is an 
extremely exciting one, for a 

01:08:57.004 --> 01:09:02.707
tracker using the dispatcher API
 by a company called Sesame 

01:09:02.708 --> 01:09:10.218
enable, a Israeli company that 
was cofounded by two people, 

01:09:10.812 --> 01:09:16.593
Beau Ded, computer vision 
expert, and Giora who is in high

01:09:16.594 --> 01:09:20.720
 current engineer who became 
quadriplegic due to spinal cord 

01:09:20.721 --> 01:09:22.721
injury.

01:09:24.615 --> 01:09:29.346
enable utilizes the phone camera
 of the device to track head 

01:09:29.347 --> 01:09:34.627
moving, head movements and move 
a mouse cursor.  I'd like to 

01:09:34.628 --> 01:09:40.321
invite Vlad the head of develop.
  From sesame Enable on to the 

01:09:41.336 --> 01:09:45.214
stage to demo the technology.
pplause)

01:09:50.983 --> 01:09:52.070
.
How are you doing?

01:09:52.071 --> 01:09:55.781
&gt;&gt; Great.
&gt;&gt; MAYA BEN ARI: Ready for this?

01:09:56.845 --> 01:10:01.451
  The first thing that Vladi 
will do is he will, can we move 

01:10:01.862 --> 01:10:08.259
to the demo?  The first thing he
 will do is enable the service. 

01:10:08.476 --> 01:10:11.782
 This can be done through voice,
 but because of the acoustics 

01:10:12.272 --> 01:10:16.780
here, Vladi will just tap on the
 sesame Enable notification.

01:10:17.181 --> 01:10:25.343
Now, the service will calibrate 
Vladi's face, after it lock it 

01:10:25.344 --> 01:10:29.843
down, he can control a mouse 
cursor using only his head.  

01:10:29.844 --> 01:10:35.372
Now    Now, if Vladi would like 
to tap on something, he just

01:10:43.858 --> 01:10:51.957
 will, and he can tap.
Once he is into his E-mail, he 

01:10:51.958 --> 01:10:56.002
can swipe up or down.

01:11:10.761 --> 01:11:12.788
  I think we are a little bit 
excited.

01:11:13.062 --> 01:11:15.062
  (chuckles)

01:11:47.124 --> 01:11:49.271
.
It's okay.

01:12:04.479 --> 01:12:06.695
  It's okay.

01:12:18.684 --> 01:12:21.603
  Would you like me to help you?

01:12:24.926 --> 01:12:26.482
&gt;&gt; You can try.
&gt;&gt; MAYA BEN ARI: Let's try it 

01:12:26.483 --> 01:12:29.093
out.  The first

01:12:33.979 --> 01:12:39.794
 here, I'm going to calibrate my
 face.

01:12:44.073 --> 01:12:48.781
  Now I can control the mouse 
cursor.  It's hard here because 

01:12:50.792 --> 01:12:54.932
the overall stage is shaky.  It 
is hard.

01:13:07.310 --> 01:13:11.820
Yairs can it's              It's
 hard to calibrate.  The overall

01:13:12.505 --> 01:13:15.679
 stage is shaky.  But it's hard 
to do.  This is what the demo is

01:13:15.890 --> 01:13:21.294
 all about.  In general, after 
we move the mouse cursor, we can

01:13:21.295 --> 01:13:26.728
 also clock the sensor, this is 
by looking 

01:13:39.189 --> 01:13:48.989
right -- yeah.  Try again.  Just
 go to ... yes, sorry

01:13:49.301 --> 01:13:51.591
.
In general, this demo is about 

01:13:51.592 --> 01:13:56.902
how to use a mouse cursor using 
the device, control the mouse 

01:13:56.903 --> 01:14:01.095
cursor.  It's hard to do it on 
stage because the stage is a 

01:14:01.096 --> 01:14:03.096
little bit shaky.  Let's try it.

01:14:21.078 --> 01:14:23.078
)

01:14:24.324 --> 01:14:25.807
.
The thing is basically, you can 

01:14:25.808 --> 01:14:29.687
do everything using a head 
tracker on the device including 

01:14:29.688 --> 01:14:32.790
tapping and touching and 
swiping        swiping.  And 

01:14:32.791 --> 01:14:36.633
also downloading any app from 
the play store and basically 

01:14:36.895 --> 01:14:41.020
interacting with that app only 
using your face.

01:14:41.021 --> 01:14:43.021
  (applause)

01:14:45.133 --> 01:14:47.010
.
If you want to try it out, in a 

01:14:47.011 --> 01:14:52.008
little bit of a less shaky stage
, you are more than welcome to 

01:14:52.009 --> 01:14:54.009
come out to access

01:14:56.592 --> 01:14:58.293
 an empathy sandbox to try it 
out.  One last note about this 

01:14:58.294 --> 01:15:03.400
API, that while this API is very
 powerful, it doesn't diminish 

01:15:04.500 --> 01:15:08.073
the need for app developer to 
make their app accessible, such 

01:15:08.074 --> 01:15:11.497
as add    adding content 
labeling or increasing touch 

01:15:11.498 --> 01:15:15.674
target size, because while the 
API allows you to interact with 

01:15:15.675 --> 01:15:19.493
different elements on the 
screen, it doesn't know which 

01:15:19.494 --> 01:15:25.684
element it interacts with.
So following every best 

01:15:25.685 --> 01:15:29.989
practices, it's still very 
important.  So thank you so much

01:15:30.607 --> 01:15:34.289
, Vladi, for your help.)

01:15:38.569 --> 01:15:39.797
.
With that, I would like to hand 

01:15:39.798 --> 01:15:46.825
it off to Patrick and Scott to 
talk about voice access.

01:15:46.826 --> 01:15:48.826
  (applause)

01:16:05.334 --> 01:16:08.090
.
&gt;&gt; All righty.  Thanks, Maya.  

01:16:08.091 --> 01:16:11.198
I'm Patrick Clary, product 
manager on accessibility at 

01:16:11.199 --> 01:16:14.387
Google.  With me is Scott 
Newman, software engineer on 

01:16:14.620 --> 01:16:18.792
accessibility at Google.
We are here, excited to talk to 

01:16:18.793 --> 01:16:20.793
you about a new accessibility 
service, for Android, called 

01:16:21.099 --> 01:16:24.405
voice access.  This is an 
accessibility service that is 

01:16:24.406 --> 01:16:28.096
meant for users with a motor 
impairment, that find it hard to

01:16:28.315 --> 01:16:30.315
 use a touch screen with their 
hands.

01:16:32.943 --> 01:16:35.415
Before I talk about that, I want
 to tell you about one of our 

01:16:35.416 --> 01:16:42.134
testers, whose name is Andy.  
Andy is a 65-year-old male, with

01:16:42.135 --> 01:16:44.910
 a central tremor.  For Andy, he
 likes to be able to communicate

01:16:45.123 --> 01:16:48.510
 with friends and family, and 
send them pictures, through 

01:16:48.511 --> 01:16:52.090
E-mail and messages and updates,
 and he generally does this at 

01:16:52.308 --> 01:16:58.451
home on his desktop PC, 
utilizing an app like Dragon 

01:16:58.452 --> 01:17:01.047
Naturally Speaking which allows 
him to dictate by voice.

01:17:01.426 --> 01:17:04.296
However, Andy would like to be 
able to do this on the go, from 

01:17:04.297 --> 01:17:08.416
his mobile device.  But due to 
his tremor, using a touch screen

01:17:09.300 --> 01:17:15.515
 is very problematic.  Now if we
 take a step back here, we 

01:17:15.516 --> 01:17:19.191
realize that Andy's experience 
is not that unique.  In fact, 

01:17:20.000 --> 01:17:22.414
there are millions of people in 
the U.S. alone that have some 

01:17:22.415 --> 01:17:25.867
form of motor impairment that 
impacts how they can use a touch

01:17:29.729 --> 01:17:32.395
 screen.
This can range from people with 

01:17:29.729 --> 01:17:33.203
a central tremor like Andy, to 
people who have Parkinson's, 

01:17:33.204 --> 01:17:36.535
amputees, people with arthritis,
 even people with spinal cord 

01:17:36.536 --> 01:17:40.002
injuries to name a few.
In addition to that, there are 

01:17:40.003 --> 01:17:42.505
many more people who have what 
we call a situational disability

01:17:43.121 --> 01:17:46.025
, like Maya mentioned before.  
This could be a temporary 

01:17:46.026 --> 01:17:48.600
impairment that affects their 
use of a touch screen.  

01:17:48.601 --> 01:17:52.713
Something like a broken hand or 
wrist, or maybe their hands are 

01:17:52.714 --> 01:17:55.894
occupied.  A common use case we 
hear is that someone might be 

01:17:56.118 --> 01:17:58.808
cooking and their hands are 
dirty, they don't want to use 

01:17:58.809 --> 01:18:01.622
their hands.  They would love to
 be able to still control their 

01:18:01.623 --> 01:18:06.947
device.
This is the motivation we have 

01:18:06.948 --> 01:18:10.705
for voice access.  Our goal is 
voice access is to provide 

01:18:10.706 --> 01:18:14.503
someone this complete control of
 their device through use of 

01:18:14.504 --> 01:18:18.212
their voice alone.  In that 
sense we want to be able to 

01:18:18.213 --> 01:18:23.631
allow users to click by voice.
Or to put in the words of one of

01:18:23.813 --> 01:18:28.452
 our testers, use your voice and
 you are able to access the 

01:18:28.453 --> 01:18:33.916
world.  You might be asking, how
 does an accessibility service 

01:18:33.917 --> 01:18:38.398
like voice access differ from a 
voice assistant, like Google Now

01:18:38.927 --> 01:18:41.421
 or okay Google where you can 
say this hot word and then 

01:18:41.422 --> 01:18:44.717
perform a search query which is 
more conversational, or you can 

01:18:44.718 --> 01:18:48.627
perform a voice action, like you
 can set a reminder, you can 

01:18:48.628 --> 01:18:51.308
create a calendar event.  An 
accessibility service is 

01:18:51.738 --> 01:18:54.108
different.
We are looking to empower people

01:18:54.315 --> 01:19:00.899
 to be able to use their device 
and have full device control.  

01:19:00.900 --> 01:19:04.918
Now the high level voice 
assistant is lacking the fine 

01:19:04.919 --> 01:19:07.819
grained commands needed to do 
this     this.  For example, I 

01:19:07.820 --> 01:19:10.804
mentioned Jeff likes to send 
messages to friends and family. 

01:19:11.020 --> 01:19:13.910
 From his mobile device, if he 
wanted to do this, he might have

01:19:13.911 --> 01:19:17.635
 to open the camera app, take a 
photo, by pressing the button, 

01:19:17.636 --> 01:19:21.031
open a app like Hangouts by 
clicking on the icon, scrolling 

01:19:21.032 --> 01:19:25.418
and swiping to the contact he 
wanted, clicking on a attach the

01:19:25.419 --> 01:19:29.226
 photo and then tapping on the 
text box, typing in text and 

01:19:29.227 --> 01:19:32.913
clicking send.
With voice access our goal is 

01:19:32.914 --> 01:19:38.919
for each of those touch actions 
to enable a corresponding voice 

01:19:38.920 --> 01:19:42.223
command that allows users to 
chain together a series of 

01:19:42.224 --> 01:19:46.880
commands to perform a complex 
task.

01:19:47.032 --> 01:19:49.521
To see it in real life, I'll 
hand it over to Scott who will 

01:19:49.522 --> 01:19:52.524
give you guys a demo.
&gt;&gt; SCOTT NEWMAN: Thanks a lot, 

01:19:52.525 --> 01:19:55.425
Patrick.  My name is Scott 
Newman.  I'm a software engineer

01:19:56.013 --> 01:19:59.228
 on the accessibility team.  I'm
 excited to give you a demo of 

01:19:59.613 --> 01:20:02.517
voice access today.  Before I go
 ahead and get started, I wanted

01:20:02.518 --> 01:20:05.430
 to mention that as some of you 
may be aware, speech recognition

01:20:06.222 --> 01:20:09.915
 demos can be fickle in front of
 live audiences.  If you run 

01:20:09.916 --> 01:20:13.714
into any issues, bear with me, 
and we will get through them., 

01:20:13.715 --> 01:20:17.930
let's go ahead and get started. 
 I remember that Patrick sent me

01:20:17.931 --> 01:20:20.915
 a message a little earlier, and
 I'd like to read it.  But 

01:20:20.916 --> 01:20:24.240
before I read the message, I'm 
going to go into accessibility 

01:20:24.241 --> 01:20:28.323
settings, and enable large text.
  It's easier for those people 

01:20:28.324 --> 01:20:31.028
in the back of the room to see 
what is on the screen.

01:20:34.655 --> 01:20:44.325
Open settings.  Scroll to the 
bottom.  Tap accessibility

01:20:46.350 --> 01:20:49.424
.  Tap large

01:20:54.061 --> 01:21:03.136
 text.  Go home.  Go home.  
Let's try one more time.  Go 

01:21:03.137 --> 01:21:10.144
home.  All right.  There we go.
That is voice access in action. 

01:21:10.236 --> 01:21:13.122
 What actually happened right 
there?  You may notice that 

01:21:13.123 --> 01:21:16.041
there is this persistent blue 
button that appears on the top 

01:21:16.042 --> 01:21:19.329
right of the screen, and so that
 is a voice access activation 

01:21:19.330 --> 01:21:22.848
button, so from any screen, you 
press that button and voice 

01:21:22.849 --> 01:21:27.338
access starts listening, and 
then from there, you can issue 

01:21:27.339 --> 01:21:30.733
commands to globally navigate 
the device, experience act  

01:21:30.944 --> 01:21:32.414
              interact with 
individual elements on the 

01:21:32.415 --> 01:21:36.348
screen and control your device 
entirely by voice.I did there 

01:21:36.349 --> 01:21:40.127
was, I opened the settings app 
by saying, open settings.  I 

01:21:40.128 --> 01:21:44.138
said scroll to the bottom, to 
scroll the screen down as if I 

01:21:44.139 --> 01:21:49.327
were performing a traditional 
tap gesture.  Then I said, tap 

01:21:49.328 --> 01:21:50.737
accessibility, to tap the 
corresponding button to the 

01:21:50.738 --> 01:21:54.324
screen that was labeled with the
 text accessibility, then I did 

01:21:54.325 --> 01:21:57.429
the exact same thing to press 
the switch labeled large text.

01:21:58.654 --> 01:22:02.018
This actually uses the same 
accessibility APIs that underlie

01:22:02.234 --> 01:22:05.127
 the other accessibility 
services that we have seen so 

01:22:05.128 --> 01:22:09.257
far, like talkback or switch 
access.  As long as you follow 

01:22:10.224 --> 01:22:13.032
accessibility development best 
practices, your app should work 

01:22:13.033 --> 01:22:17.133
with voice access right out of 
the box., let's actually see the

01:22:17.438 --> 01:22:22.656
 message that Patrick cents me
          sent me.  Can we go 

01:22:23.841 --> 01:22:26.950
back to the -- thanks.  Open 
Hangouts

01:22:33.241 --> 01:22:40.969
.  Patrick Clary.  Stop voice 
access.

01:22:41.130 --> 01:22:47.834
Again, I used voice access to 
open the Hangouts app.  When I 

01:22:47.835 --> 01:22:48.443
said Patrick Clary it actually 
found the clickable button to 

01:22:48.444 --> 01:22:51.765
the screen, with text that was 
labeled Patrick Clary, and then 

01:22:51.766 --> 01:22:55.752
clicked that button to    on my 
behalf.  One other thing that 

01:22:55.753 --> 01:22:58.447
you may notice is that there are
 these numbers that are drawn on

01:22:58.654 --> 01:23:02.223
 the screen, whenever voice 
access is actively listening.  

01:23:02.224 --> 01:23:06.344
What that is, is a safety 
fallback.  If you want to 

01:23:06.345 --> 01:23:08.126
interact with something on the 
screen that is clickable or 

01:23:08.127 --> 01:23:11.223
scrollable, and there is no text
 associated with it, let's say 

01:23:11.224 --> 01:23:15.241
clickable image, then you can 
default saying the number and it

01:23:15.324 --> 01:23:17.777
 will click that element on your
 behalf.

01:23:17.950 --> 01:23:22.940
With that, I'm going to respond 
to Patrick's message. , and then

01:23:22.941 --> 01:23:32.300
 send it.  Type, the party is at
 7.  Actually I notice that I 

01:23:32.301 --> 01:23:36.243
made a mistake.  The party is I 
think at 8 instead of 7.  Let   

01:23:36.355 --> 01:23:39.460
    Let me change that really 
quickly.

01:23:40.130 --> 01:23:42.130
Replace 7

01:23:43.366 --> 01:23:48.323
 with 8.  In addition to 
navigation, interacting with 

01:23:48.324 --> 01:23:52.046
individual elements on the 
screen, we actually offer a   a 

01:23:52.047 --> 01:23:55.738
full sweelt of           suite 
of text he had        editing 

01:23:55.739 --> 01:23:59.234
commands.  That is one of many 
you can use to Edith text       

01:23:59.533 --> 01:24:03.139
     edit text, replace parts of
 text with other text, you can 

01:24:03.140 --> 01:24:05.140
copy, move elements around

01:24:07.632 --> 01:24:11.898
.  It is a fast way to interact 
with whatever is on the current 

01:24:07.632 --> 01:24:10.530
screen, and the Hangouts app 
didn't need to do anything 

01:24:10.531 --> 01:24:13.541
special to work with voice 
access.  It works right out of 

01:24:13.542 --> 01:24:15.743
the box.
What I'm going to do now is send

01:24:15.938 --> 01:24:19.137
 the message.  You will notice 
that at the bottom right of the 

01:24:19.138 --> 01:24:22.044
screen is a green send button.  
There is no text associated with

01:24:22.248 --> 01:24:26.241
 it.  In order to click that 
button, I'm going to reactivate 

01:24:26.242 --> 01:24:28.638
voice access.  I'm going to say 
the number that is associated 

01:24:28.854 --> 01:24:31.545
with it that appears right next 
to the button.  It's going to 

01:24:31.754 --> 01:24:33.924
click that button and send the 
message.

01:24:33.925 --> 01:24:43.064
Let's go ahead and do that.  Tap
 11.  Stop voice access

01:24:45.079 --> 01:24:54.471
.  Undo.  Stop voice access

01:24:55.357 --> 01:24:59.952
.  So, that is voice access for 
you.  Notice that you can start 

01:25:00.350 --> 01:25:03.162
voice access by pressing this 
blue button.  Actually if you 

01:25:03.163 --> 01:25:07.259
want to do it completely hands-
free, if you say the Okay Google

01:25:07.458 --> 01:25:09.723
 command, there is another way 
that you can access it, 

01:25:09.724 --> 01:25:13.136
completely hands-free by voice. 
 We offer a whole host of 

01:25:13.755 --> 01:25:15.429
activation methods, so you can 
choose what is most efficient 

01:25:15.430 --> 01:25:18.544
for you.  Similarly, you can 
stop voice access by saying, 

01:25:18.545 --> 01:25:21.760
stop voice access or by touching
 the screen, which is a 

01:25:21.761 --> 01:25:25.813
fail-safe option to leave voice 
access quickly.

01:25:25.976 --> 01:25:28.945
That is voice access in 
practice.  Can we go back to the

01:25:28.946 --> 01:25:33.053
 deck     deck, please?  Thanks.
Let's hear from some actual 

01:25:33.450 --> 01:25:37.855
voice access users about how 
it's impacted their lives.  Roll

01:25:37.856 --> 01:25:40.271
 video, please.

01:25:48.577 --> 01:25:52.249
&gt;&gt; My name is Stefanie.  I just 
finished my masters in 

01:25:52.748 --> 01:25:57.456
advertising.  I'm a C4, C5 split
 level quadriplegic, I have no 

01:25:57.457 --> 01:26:01.859
feeling from my collarbone down.
  So it is absolutely vital that

01:26:01.860 --> 01:26:06.087
 I'm able to use my voice.  Okay
 Google, start voice access.

01:26:06.247 --> 01:26:10.468
&gt;&gt; My name is Jeff.  I have a 
neurological condition called 

01:26:10.469 --> 01:26:15.854
the central tremor.  It is 
incredibly difficult to use my 

01:26:15.855 --> 01:26:21.466
hands and fingers.  It is very 
easy for me to use my voice.  

01:26:21.467 --> 01:26:26.758
Okay Google.  Start voice 
access. this product for 

01:26:28.252 --> 01:26:30.529
probably about ten seconds, I 
think I'm falling in love with 

01:26:30.530 --> 01:26:35.240
it.  Open camera.  Use your 
voice and you are able to access

01:26:35.460 --> 01:26:40.563
 the world.  Shutter, share, 
Hangouts

01:26:43.659 --> 01:26:48.858
, Astrid Weber, send.
&gt;&gt; I cannot tell you how excited

01:26:49.656 --> 01:26:54.664
 I am about this product.  Open 
calendar, new.

01:26:54.665 --> 01:26:57.145
When you don't have the ability 
to use your fingers and hands  

01:26:57.966 --> 01:27:04.116
    hands, family movie night.  
It's really all about voice.

01:27:09.301 --> 01:27:11.573
  (applause)

01:27:17.923 --> 01:27:19.051
.
&gt;&gt; That is voice access.  We are

01:27:19.052 --> 01:27:22.947
 really excited for you to try 
it out.  It is in open beta now.

01:27:23.043 --> 01:27:26.045
  If you come to the access and 
empathy sandbox area, you can 

01:27:26.046 --> 01:27:29.244
try it out yourself.  With that 
I'm going to hand it over to 

01:27:29.245 --> 01:27:33.867
Astrid and Jennifer Kozenski 
Devins to talk about how you can

01:27:33.868 --> 01:27:39.072
 use research to    for the 
quality of your product with a 

01:27:39.073 --> 01:27:42.769
case study.  Thanks a lot.
&gt;&gt; Thank you, Scott.  Hi, my 

01:27:42.770 --> 01:27:45.786
name is Jennifer Kozenski Devins
 and this is Astrid.  We are 

01:27:45.787 --> 01:27:49.694
inclusive design and researchers
 in Google.  We wanted to share 

01:27:49.695 --> 01:27:52.158
with you today a little bit 
about how UX research influenced

01:27:52.947 --> 01:27:56.938
 and drove the design of voice 
access.

01:27:56.939 --> 01:28:01.362
First, what is UX research?  The
 general definition is that it 

01:28:01.456 --> 01:28:05.441
focuses on understanding user 
behaviors, needs, motivations,

01:28:08.734 --> 01:28:09.655
 through observation techniques,
 task analysis and other 

01:28:09.656 --> 01:28:13.369
methodology ies.  The key is 
that while we might think we 

01:28:13.370 --> 01:28:16.221
know what users want because 
maybe we are users of our own 

01:28:16.222 --> 01:28:20.368
products, or maybe we are close 
to it and develop and design it,

01:28:20.680 --> 01:28:24.252
 it is critical to get out there
 and get feedback from external 

01:28:24.253 --> 01:28:28.176
users and understand their 
unique perspectives, insights, 

01:28:28.177 --> 01:28:32.353
challenges and pain points.
In fact, the products that we 

01:28:32.354 --> 01:28:37.059
demo'd here today all underwent 
many iterations of design and 

01:28:37.060 --> 01:28:39.060
development, and all of

01:28:42.799 --> 01:28:43.054
 which were inspired and driven 
by UX research.

01:28:43.055 --> 01:28:46.863
The process itself is about a 
five-step process.  It can be 

01:28:46.864 --> 01:28:51.463
cyclical, if you want to keep 
refining.  The way it was 

01:28:51.464 --> 01:28:53.853
applied to voice access, it was 
first looking at what are the 

01:28:53.854 --> 01:28:59.565
objectives of the product as a 
whole?  One key objective of 

01:28:59.566 --> 01:29:03.759
voice access was that they 
wanted to ensure it was easy to 

01:29:03.760 --> 01:29:07.955
use, easy to learn how to use, 
right out of the box, in a hands

01:29:08.162 --> 01:29:10.662
-free manner.
From there they developed 

01:29:10.663 --> 01:29:18.380
hypotheses, okay.  So based on 
that objective, they thought 

01:29:18.381 --> 01:29:22.657
that contextual help was the 
best way to allow people to 

01:29:22.658 --> 01:29:27.567
learn how to use the product in 
the moment., they define what 

01:29:27.568 --> 01:29:31.566
the best methodologies were to 
use, conducted the research, 

01:29:31.567 --> 01:29:33.972
synthesize ed those findings and
 reported those back to the team

01:29:34.773 --> 01:29:39.400
, which further iterated on the 
design of the products.

01:29:39.401 --> 01:29:41.973
Now Astrid is going to take you 
through the specific 

01:29:42.603 --> 01:29:45.280
methodologies used and how those
 insights actually impacted the 

01:29:45.281 --> 01:29:50.211
design of voice access.
&gt;&gt; ASTRID WEBER: 

01:29:53.301 --> 01:29:58.784
Thank you, Jen, I'm Astrid 
Weber, UX researcher working on 

01:29:58.785 --> 01:30:03.030
voice access.  I'd like to show 
you how we accompanied the 

01:30:03.293 --> 01:30:05.796
design and development process 
with a few research 

01:30:06.296 --> 01:30:09.687
methodologies.  I'd like to get 
started with formative research.

01:30:09.897 --> 01:30:15.034
  Formative research is, if you 
go into the field in order to 

01:30:15.035 --> 01:30:17.902
understand about your users from
 the daily lives, so you go and 

01:30:17.903 --> 01:30:23.998
see how they work, how they live
 their lives at home.  We worked

01:30:24.604 --> 01:30:28.497
 with users with severe motor 
impair        impairments as you

01:30:28.596 --> 01:30:30.902
 saw before in the video.  What 
we learned is that at the moment

01:30:31.076 --> 01:30:34.902
 there is no cohesive strategy 
for people who can't use their 

01:30:35.211 --> 01:30:37.783
hands in order to access their 
mobile devices completely hands-

01:30:37.982 --> 01:30:42.517
       hands-free. knew that, we
 went back and developed the 

01:30:42.880 --> 01:30:47.281
first prototype of voice access.
  As soon as we had something 

01:30:47.282 --> 01:30:51.895
that was testable, we did test 
it.  We did so with internal 

01:30:51.896 --> 01:30:56.515
testing.  Internal testing is 
probably best known to tech 

01:30:56.516 --> 01:30:59.601
companies because all you need 
is yourself.  All of us within 

01:30:59.602 --> 01:31:02.801
the team installed the 
application, people outside the 

01:31:02.802 --> 01:31:07.405
team, and we tried to use it in 
as many circumstances and 

01:31:07.406 --> 01:31:11.404
contexts as possible.
What we found was a lot of bugs.

01:31:11.758 --> 01:31:15.322
  We addressed those bugs.  We 
made the product better.  We 

01:31:15.323 --> 01:31:18.504
iterated it, until we got to the
 point that we felt the product 

01:31:18.505 --> 01:31:21.507
is so stable now that we can 
actually put it in front of real

01:31:21.703 --> 01:31:23.703
 users.

01:31:26.591 --> 01:31:27.591
RAW COPY

01:31:26.591 --> 01:31:28.191
    Present:  AND OTHERS

01:31:26.591 --> 01:31:29.857
    Services provided by:
     Caption First, Inc.

01:31:26.591 --> 01:31:29.391
     P.O. Box 3066
     Monument, CO  80132

01:31:26.591 --> 01:31:29.324
     1-877-825-5234
     +001-719-481-9835

01:31:26.591 --> 01:31:28.257
     www.captionfirst.com

01:31:26.591 --> 01:31:29.324
      ***
    This is being provided in a 

01:31:26.591 --> 01:31:30.057
 rough draft format. 
 Communication Access Realtime 

01:31:26.591 --> 01:31:29.991
 Translation (CART) or 
 captioning are provided in 

01:31:26.591 --> 01:31:30.124
 order to facilitate 
 communication accessibility and

01:31:26.591 --> 01:31:28.991
 record of the proceedings.
      ***

01:31:26.591 --> 01:31:29.502
     we did.  We ran usability 
studies.  Usability studies are 

01:31:29.503 --> 01:31:33.411
when you invite people to 
actually come into your lab, 

01:31:33.598 --> 01:31:36.825
those are people from the core 
audience or in our case, people 

01:31:36.826 --> 01:31:41.291
with severe motor impairments.  
They test it.  You are in front 

01:31:41.292 --> 01:31:43.804
of them, you can see exactly 
what they are doing.  They are 

01:31:43.805 --> 01:31:47.289
running through a couple of 
tasks with you.  You see the 

01:31:47.290 --> 01:31:50.792
limitations of the product.  You
 see where it's failing, but you

01:31:50.793 --> 01:31:55.295
 also see where people are 
especially delighted, and what 

01:31:55.296 --> 01:31:59.318
you see in the picture is one of
 our labs.  It is designed to be

01:31:59.319 --> 01:32:02.992
 comfortable and welcome ing to 
our users, and at the same time 

01:32:02.993 --> 01:32:07.907
it has cameras to capture audio 
and video.fterwards, we can 

01:32:07.908 --> 01:32:11.321
actually go back into the data, 
analyze and see exactly how we 

01:32:11.322 --> 01:32:16.200
can improve the product.  
Usability studies are great, but

01:32:16.201 --> 01:32:20.005
 they have limitations.  I think
 the biggest limitation is that 

01:32:20.006 --> 01:32:22.396
it's a very short period of time
 that the user is interacting 

01:32:22.397 --> 01:32:26.791
with the product.  It's in the 
lab environments.  So it's not 

01:32:27.121 --> 01:32:31.313
their real life.  We went one 
step further and conducted diary

01:32:31.522 --> 01:32:35.904
 studies.  Diary studies as the 
name already indicates, are 

01:32:35.905 --> 01:32:40.597
studies where the user is going 
to keep a diary about their 

01:32:40.598 --> 01:32:44.803
usage.  What did we do?
We sent voice access home with 

01:32:44.804 --> 01:32:48.067
the users on their personal 
devices, installed, and they 

01:32:48.068 --> 01:32:51.422
could use it in whichever 
context they wanted to.  The 

01:32:51.423 --> 01:32:55.300
only thing they had to do, they 
had to promise us that they 

01:32:55.301 --> 01:32:57.301
would report back about the

01:33:00.115 --> 01:33:04.115
 experience.  You can do that 
over the phone.  You can have 

01:33:00.115 --> 01:33:02.624
them write E-mails or fill in a 
quick survey.  In the end of the

01:33:02.625 --> 01:33:07.109
 study, they will come back into
 the office with us, and give us

01:33:07.110 --> 01:33:08.713
 their report, how they used the
 product, what they liked, what 

01:33:08.714 --> 01:33:11.466
they didn't like.
What we learned from that 

01:33:11.467 --> 01:33:16.614
process is that for one voice 
access really needs to be 

01:33:16.615 --> 01:33:19.815
polished and be visually delight
ful.  You have seen in the video

01:33:20.226 --> 01:33:24.606
 the latest design that we have.
  We didn't start off on that.  

01:33:24.607 --> 01:33:27.343
I have a few more examples on 
that in a minute for you.

01:33:27.520 --> 01:33:31.220
The second thing, if you use it 
on the go, you need a really 

01:33:31.414 --> 01:33:34.326
easy way to activate and 
deactivate it, because otherwise

01:33:34.827 --> 01:33:38.519
 it's too much hassle for the 
user to actually dive into the 

01:33:38.520 --> 01:33:44.749
software and then again when you
 don't want it to deactivate it.

01:33:44.913 --> 01:33:47.804
Let me show you examples that I 
mentioned.  The first one that I

01:33:48.030 --> 01:33:52.924
 would like to talk about is how
 we improved the contextual help

01:33:53.036 --> 01:33:56.121
.  You       You see on the left
 side the before and on the 

01:33:56.122 --> 01:33:59.919
right side you see the after.  
What is that?  On the left-hand 

01:33:59.920 --> 01:34:03.324
side we see a long list of all 
the voice commands that we are 

01:34:03.325 --> 01:34:07.833
offering.  Everyone who is using
 or developing on voice based 

01:34:07.834 --> 01:34:11.422
software knows that the biggest 
challenge is how can you teach a

01:34:11.834 --> 01:34:15.544
 user what they can say and how 
can they remember that?

01:34:15.902 --> 01:34:19.123
It is essential that we are 
offering a place where the user 

01:34:19.282 --> 01:34:24.704
can go back and check again what
 they can say in order to get to

01:34:24.705 --> 01:34:26.705
 a specific result.  We thought 
it makes sense to offer one long

01:34:26.722 --> 01:34:29.978
 list, everything in one place, 
people will find their way.

01:34:30.123 --> 01:34:34.029
When we observed them in 
usability studies, we found this

01:34:35.105 --> 01:34:38.098
 is actually not the case.  
People got lost along the long 

01:34:38.304 --> 01:34:40.934
list, they even forgot what they
 were looking for because they 

01:34:40.935 --> 01:34:44.487
were so overwhelmed by all the 
stuff that we offer in there.  

01:34:44.488 --> 01:34:48.315
Also the way we presented the 
information without any examples

01:34:48.316 --> 01:34:51.646
 was not intuitive to understand
 for them.

01:34:51.825 --> 01:34:55.026
What did we do?  We see on the 
right side the first screen shot

01:34:55.224 --> 01:34:59.123
, we had categories now.  We 
have basics of navigation, 

01:34:59.519 --> 01:35:04.328
gestures and text editing.  With
 those, the users deep dive into

01:35:04.329 --> 01:35:07.432
 a smaller subset of commands, 
which you see on the next screen

01:35:09.395 --> 01:35:11.921
 shot with basics of navigation 
that the user gets specific 

01:35:11.922 --> 01:35:15.338
examples of the voice action 
that they can take.  By doing 

01:35:15.612 --> 01:35:20.041
so, we actually had much better 
results that users were able to 

01:35:20.042 --> 01:35:22.530
find what they were saying and 
also for remembering later on 

01:35:22.531 --> 01:35:25.048
where to find that command again
.

01:35:25.932 --> 01:35:27.932
The second example I'd

01:35:29.046 --> 01:35:30.118
 like to show to you is our 
tutorial.  Again, having a 

01:35:30.119 --> 01:35:33.432
really good tutorial is crucial,
 especially if people have not 

01:35:33.433 --> 01:35:37.313
used voice interactions before, 
in order to navigate the 

01:35:37.314 --> 01:35:40.414
interface.
We wanted to make it as real as 

01:35:40.415 --> 01:35:43.332
possible, so we took a screen 
shot of the interface and 

01:35:43.333 --> 01:35:47.927
explained it to the users.  What
 we didn't expect was that users

01:35:48.128 --> 01:35:51.487
 would want to interact with the
 screen shot and wouldn't 

01:35:51.635 --> 01:35:56.920
distinguish between a screen 
shot versus the real product. 

01:35:56.921 --> 01:36:01.323
the learning back, and redesign 
the experience, as you see it on

01:36:01.324 --> 01:36:05.431
 the right-hand side, to be text
, explaining the functionality, 

01:36:05.616 --> 01:36:11.515
so this is how to use the 
numbers, what had been done 

01:36:11.516 --> 01:36:14.119
before and we did have numbers 
now on the screen but those are 

01:36:14.120 --> 01:36:17.224
real.  So you can interact with 
them.  The user is learning 

01:36:17.225 --> 01:36:20.036
about it immediately and they 
can apply the learning, and with

01:36:20.538 --> 01:36:24.155
 that we actually made really 
good progress.

01:36:24.733 --> 01:36:28.539
Now, Jen is going to talk about 
usability testing and how you 

01:36:28.540 --> 01:36:31.555
can use it for your own 
application.

01:36:31.726 --> 01:36:34.107
&gt;&gt; JENNIFER KOZENSKI DEVINS: 
Thanks, Astrid.  In the few 

01:36:34.108 --> 01:36:36.921
minutes remaining, we wanted to 
leave you with a quick starter 

01:36:36.922 --> 01:36:39.817
guide of how to do your own 
usability studies because we 

01:36:39.818 --> 01:36:43.535
find them very effective. 
anything fancy to actually 

01:36:43.536 --> 01:36:48.132
execute these.  Usability 
testing is useful to understand 

01:36:48.343 --> 01:36:51.222
how people use your product, and
 why.  That is the key point, is

01:36:51.432 --> 01:36:54.729
 the why.  Before you jump in 
and just bring somebody in and 

01:36:54.730 --> 01:36:58.229
have them run through some tests
, you want to have a plan and a 

01:36:58.230 --> 01:37:00.441
strategy.  First start      
starting with what are the key 

01:37:00.442 --> 01:37:03.528
questions you want to answer 
with this research?  Write this 

01:37:03.930 --> 01:37:05.845
     these down, refer you them 
with the team, make sure 

01:37:05.846 --> 01:37:08.130
everyone is on the same page.  
These are your research 

01:37:08.131 --> 01:37:11.233
questions.  Without solid 
research questions, the end 

01:37:11.234 --> 01:37:14.137
result might not be             
 might not meet everybody's 

01:37:14.138 --> 01:37:16.332
expectations.
Based on these questions, you 

01:37:16.333 --> 01:37:19.546
will identify tasks that will 
help you answer these questions.

01:37:19.738 --> 01:37:24.240
  For example, if a question was
    was, are users able to 

01:37:24.241 --> 01:37:27.026
onboard without any additional 
assistance           assistance,

01:37:27.027 --> 01:37:30.328
 you would bring in the new user
 and have them start the app for

01:37:30.541 --> 01:37:33.430
 the first time, and maybe run 
through some of your key 

01:37:33.826 --> 01:37:36.127
fundamental tasks, and see if 
they can do it without asking 

01:37:36.341 --> 01:37:42.041
for assistance from you, looking
 in the help or on-line. happy 

01:37:42.042 --> 01:37:46.237
with your study and your test 
questions and tasks, you want to

01:37:46.442 --> 01:37:49.919
 think about who to bring in and
 actually conduct the study on. 

01:37:50.039 --> 01:37:53.621
 You can certainly start with 
friends and family.  Ideally 

01:37:53.622 --> 01:37:56.640
those people will actually be 
using your product or do use it.

01:37:56.833 --> 01:37:59.433
  We also highly recommend 
having a diverse set of 

01:37:59.852 --> 01:38:03.251
participants, as much as 
possible.  You can reach out to 

01:38:03.252 --> 01:38:08.530
various organizations that lobby
 for accessibility needs and 

01:38:08.531 --> 01:38:10.727
they are more than willing to 
accommodate you and get people 

01:38:10.728 --> 01:38:15.554
to help run the study on.
When it comes to actually 

01:38:15.555 --> 01:38:17.930
running it, figuring out where 
to run this, you don't need a 

01:38:18.149 --> 01:38:21.450
fancy lab like we showed.  You 
can find a quiet comfortable 

01:38:21.451 --> 01:38:23.733
space, and you want to make sure
 that there is room in there for

01:38:24.030 --> 01:38:28.642
 yourself, the participant 
obviously, ideally you will have

01:38:28.919 --> 01:38:32.251
 somebody to help take notes, 
and you will have some video 

01:38:32.252 --> 01:38:37.924
recording equipment, and also 
it's great to have a developer, 

01:38:37.925 --> 01:38:40.062
designer, somebody that is very 
close to the product there to 

01:38:40.063 --> 01:38:43.542
observe as well.
There's been tons of books 

01:38:43.746 --> 01:38:47.759
written on how to do, actually 
conduct usability studies 

01:38:47.760 --> 01:38:51.144
effectively.  They all kind of 
boil it down to these four key 

01:38:51.145 --> 01:38:54.030
steps.  Asking the users to 
perform the test, and then 

01:38:54.031 --> 01:39:00.012
taking a step back and observing
 them, seeing what are they 

01:39:00.013 --> 01:39:01.332
actually doing, other than 
completing the task, are they 

01:39:01.333 --> 01:39:04.026
hovering in interesting spots, 
are they using a keyboard, what 

01:39:04.027 --> 01:39:08.336
keyboard certain         short 
cuts are they using.  And that 

01:39:08.337 --> 01:39:11.835
leads to the next point, digging
 into why.  You were hovering 

01:39:11.836 --> 01:39:15.639
over the button.  Can you tell 
me why, what did you expect to 

01:39:15.640 --> 01:39:17.751
happen or after they complete a 
task, did that meet your 

01:39:17.752 --> 01:39:21.239
expectations?  This is the magic
 of use     use ability studies,

01:39:21.240 --> 01:39:24.560
 being able to understand the 
rationale and meaning behind 

01:39:24.561 --> 01:39:27.551
behaviors.
Most challenge ing part of this,

01:39:27.742 --> 01:39:30.239
 especially if you are close to 
the product, is remaining 

01:39:30.240 --> 01:39:33.943
neutral.  You might have the 
urge to want to defend or 

01:39:34.131 --> 01:39:36.644
explain, we tried this but 
couldn't do this, we tried this,

01:39:36.833 --> 01:39:39.750
 this is not the time to do that
.  You are there to listen, 

01:39:39.945 --> 01:39:44.747
absorb the feedback, and move on
.  Oh, and then practice.  

01:39:44.748 --> 01:39:46.835
Definitely practice, at least 
once, before bringing in real 

01:39:46.836 --> 01:39:51.927
users. study, you want to ensure
 that you write down the most 

01:39:52.146 --> 01:39:55.433
interesting findings right away.
  And then review those findings

01:39:55.638 --> 01:39:59.145
 with your team after each 
participant.  This will greatly 

01:39:59.146 --> 01:40:02.497
help at the end summarizing your
 findings.

01:40:02.753 --> 01:40:07.143
If you have the ability to 
videotape it, cut small video 

01:40:07.144 --> 01:40:10.441
snip      snippets to help 
support your findings.  Not 

01:40:10.442 --> 01:40:14.249
everybody will have been there 
with you observing the study.  

01:40:14.250 --> 01:40:16.248
When you are present        
presenting your findings, you 

01:40:16.249 --> 01:40:18.362
can show, look, this is how the 
users actually interacted with 

01:40:18.363 --> 01:40:20.742
the app.
Then one of the most critical 

01:40:20.743 --> 01:40:24.039
pieces is, it would be a real 
shame to do all of this work and

01:40:24.146 --> 01:40:27.731
 have it just sit in a doc 
somewhere unused.  You want to 

01:40:27.732 --> 01:40:31.839
have somebody in charge ready to
 drive the process to address 

01:40:31.840 --> 01:40:35.137
these issues.  Of course it 
doesn't have to happen right 

01:40:35.138 --> 01:40:37.438
then and there.  But you want to
 be sure that somebody is taking

01:40:37.734 --> 01:40:42.153
 the charge to prioritize and 
figure out what are bugs, what 

01:40:42.154 --> 01:40:46.892
are feature requests, and when 
they will be addressed.

01:40:47.041 --> 01:40:53.665
We have on our, on the I/O app 
and our spaces a great link to 

01:40:53.749 --> 01:40:57.153
give you more details on how to 
conduct usability studies if you

01:40:57.154 --> 01:40:59.777
 are interested.  Overall, we 
hope that you found that this 

01:40:59.778 --> 01:41:03.553
brief overview of the research 
methodologies used for 

01:41:06.846 --> 01:41:07.032
Voice Access inspiring.  
Hopefully, you can bring it back

01:41:07.033 --> 01:41:09.291
 to your team.  Back to Patrick 
now.

01:41:09.292 --> 01:41:11.686
  (applause)

01:41:15.521 --> 01:41:16.646
.
&gt;&gt; PATRICK CLARY: Thanks.  Thank

01:41:16.647 --> 01:41:19.436
 you, everyone, for attending   
       attending.  So you know, 

01:41:19.655 --> 01:41:22.642
as you can see, it's very 
important for us to hear from 

01:41:22.643 --> 01:41:25.451
users with accessibility needs, 
so that we can learn how to 

01:41:25.452 --> 01:41:29.153
improve the platform, and for 
all of our developers to take 

01:41:29.154 --> 01:41:31.848
into account Android development
 best practices, so we can all 

01:41:31.849 --> 01:41:34.756
make apps that are great for 
everyone, who has different 

01:41:34.757 --> 01:41:37.248
accessibility needs.
So, if you would like to try out

01:41:37.438 --> 01:41:40.961
 voice access it's in beta now. 
 You can sign up for the beta, 

01:41:41.256 --> 01:41:45.463
at G.CO/voice access.  List     
Listed on the screen are other 

01:41:45.464 --> 01:41:48.135
talks we are doing that are 
accessibility related.  Please 

01:41:48.136 --> 01:41:50.355
attend those.  They are all 
great      great.  Come visit 

01:41:50.356 --> 01:41:55.159
our sandbox.  It is access and 
empathy, it's right over that 

01:41:55.160 --> 01:41:59.148
way.  You can go there to do a 
demo of voice access.  You can 

01:41:59.362 --> 01:42:04.454
go see the demo of the sesame 
head tracking, learn about many 

01:42:04.643 --> 01:42:06.798
more things and also attend our 
code lab.

01:42:07.919 --> 01:42:10.864
Thank you, everyone.  Take care.
  (applause)

01:42:20.183 --> 01:42:25.352
.
  (end of session at 3:45 p.m. P

01:42:25.667 --> 01:42:27.667
T)

01:43:01.582 --> 01:43:09.802
    (Please stand by for the VR
 VRfive session on stage

01:43:12.511 --> 01:43:14.134
 1, 
 Introducing Project Tango Area 

01:43:14.135 --> 01:43:16.336
 Learning.)

01:44:58.427 --> 01:45:08.366
    (Please stand by for the VR 
 5 session on Stage

01:45:09.578 --> 01:45:09.777
 1, 
 Introducing Project Tango Area 

01:45:09.778 --> 01:45:11.778
 Learning.)

01:50:15.712 --> 01:50:17.712
 VR

01:50:20.813 --> 01:50:21.328
5 
 VR5 session, Introducing 

01:50:21.329 --> 01:50:23.329
 Project Tango Area Learning.)

01:55:27.329 --> 01:55:33.625
    (Please stand by for the 
 session to begin.)

01:55:46.937 --> 01:55:48.937
GoogleGoogle I/O

01:55:54.844 --> 01:55:58.150
 2016, VR5, 
 Introducing Project Tango Area 

01:55:58.151 --> 01:56:00.151
 Learning.)
    (Music playing.)

01:56:50.444 --> 01:56:53.032
    &gt;&gt; WIM MEEUSSEN:  Hey!  
 Hello, everybody.  We have a 

01:56:53.033 --> 01:56:55.033
 full house.
    (Applause.)

01:56:56.736 --> 01:56:58.634
    &gt;&gt; WIM MEEUSSEN:  Thank you 
 all for coming.  Welcome to 

01:56:58.635 --> 01:57:04.027
 this talk about Project tango 
 and Area learning.  My name is 

01:57:04.028 --> 01:57:08.537
 Wim Meeussen and I lead the 
 project location team.  Today I

01:57:09.832 --> 01:57:12.936
 one of the core technologies of

01:57:12.937 --> 01:57:15.043
 Project tango.  It is at the 
 foundation of everything we are

01:57:17.429 --> 01:57:20.640
 something I deeply care about 
 and it's exciting that today I 

01:57:20.641 --> 01:57:23.739
 can spend the whole session on 
 Area learning.  If you have no 

01:57:23.740 --> 01:57:26.336
 idea what Area learning is, 
 that's okay, we'll cover that 

01:57:26.337 --> 01:57:31.037
 in this talk.
    So let's get started with an

01:57:35.530 --> 01:57:39.034
 So number one, by the end of 
 this talk you will be able to 

01:57:39.035 --> 01:57:43.328
 build an augmented reality 
 application where you can put 

01:57:43.329 --> 01:57:46.539
 virtual objects in the world 
 and they will stay in place and

01:57:48.947 --> 01:57:51.942
 you have built AR applications 
 before, you know this is a real

01:57:51.973 --> 01:57:56.544
 really big deal.  I'll have a 
 live demo where I'm show you 

01:57:56.545 --> 01:58:00.344
 how I place these objects and 
 how they stay in place in the 

01:58:00.345 --> 01:58:02.846
 environment.
    Number two, by the end of 

01:58:02.847 --> 01:58:07.037
 this session you will know how 
 to build multiplayer experience

01:58:07.340 --> 01:58:10.445
 experiences where multiple 
 Tango devices interact with 

01:58:10.446 --> 01:58:13.541
 each other.  This is obviously 
 without any wiring, without any

01:58:15.248 --> 01:58:19.644
 environment.  Just works with 
 just your mobile device.  And 

01:58:19.645 --> 01:58:22.951
 finally we'll talk about some 
 future applications where you 

01:58:22.952 --> 01:58:26.433
 can imagine that you never get 
 lost anymore in large buildings

01:58:28.347 --> 01:58:30.236
 buildings.  So I always like to

01:58:30.237 --> 01:58:33.133
 start out with a quick poll to 
 get a little bit more 

01:58:33.134 --> 01:58:34.834
 background about you.  By raise

01:58:34.835 --> 01:58:38.316
 of hands, how many of you have 
 heard about Project tango 

01:58:38.317 --> 01:58:41.144
 before today?
    All right, that's most 

01:58:41.145 --> 01:58:47.138
 people.  How many people know 
 about Area learning?

01:58:47.139 --> 01:58:48.744
    That's just a handsful.  How

01:58:48.745 --> 01:58:51.938
 many of you are here because it
 it's really hot outside?

01:58:51.939 --> 01:58:54.140
    (Laughter.)
    &gt;&gt; WIM MEEUSSEN:  A few 

01:58:54.141 --> 01:58:58.940
 honest people.  All right.  So 
 today I really want you to come

01:59:01.139 --> 01:59:03.235
 of what Area learning is.  Like

01:59:03.236 --> 01:59:07.734
 how it works and also how you 
 can use Area learning to build 

01:59:07.735 --> 01:59:10.144
 new applications and enable new

01:59:10.145 --> 01:59:15.339
 user experiences.  So I'll 
 start out with a quick high 

01:59:15.340 --> 01:59:18.848
 level overview of what Project 
 Tango is, for those of you 

01:59:18.849 --> 01:59:23.545
 still new to Tango.  So 
 fundamentally Tango is about 

01:59:23.546 --> 01:59:26.635
 enableing mobile devices to 
 understand the world around 

01:59:26.636 --> 01:59:32.338
 them.  So Tango uses computer 
 vision for your device to be 

01:59:32.339 --> 01:59:35.743
 understand the geometry of the 
 world but also to know its own 

01:59:35.744 --> 01:59:39.642
 position and orientation in 
 that world.  In some sense it 

01:59:39.643 --> 01:59:42.951
 turns your screen into an 
 extension of the real world.  

01:59:42.952 --> 01:59:46.855
 Your screen becomes this magic 
 window into the real world.

01:59:46.856 --> 01:59:51.542
    And if you look at the 
 example here, think about this 

01:59:51.543 --> 01:59:54.952
 device if it understands what 
 the world around it looks like.

01:59:59.954 --> 02:00:01.249
 some interesting contents about

02:00:01.250 --> 02:00:05.052
 about the world.  Imagine you 
 can display directions on how 

02:00:05.053 --> 02:00:09.047
 to get from A to B, or you 
 could display virtual furniture

02:00:10.750 --> 02:00:14.041
 from all different angles to 
 see how it would fit.  You can 

02:00:14.042 --> 02:00:16.943
 imagine you can have a game 
 that just plays out right in 

02:00:16.944 --> 02:00:20.837
 your living room.
    Tango can enable a whole new

02:00:22.451 --> 02:00:24.451
 simply were I am impossible 
before.

02:00:28.250 --> 02:00:32.253
    So let's look at the three 
 main technologies of Project 

02:00:32.254 --> 02:00:38.045
 Tango.  There is ocean tracking
 tracking, depth perception and 

02:00:38.046 --> 02:00:40.656
 Area learning.  If you have 
 attended talks about Tango 

02:00:40.657 --> 02:00:43.389
 before, you've probably heard a

02:00:43.390 --> 02:00:45.849
 lot about the first two.  Today

02:00:45.850 --> 02:00:48.358
 we'll mostly focus on the third

02:00:48.359 --> 02:00:49.755
 one, Area learning.  Let's do a

02:00:49.756 --> 02:00:51.856
 quick overview for all three of

02:00:51.857 --> 02:00:56.755
 them.  Motion tracking is all 
 about allowing your device to 

02:00:56.756 --> 02:01:01.069
 know how it moves through the 
 world.  So as a developer you 

02:01:01.070 --> 02:01:03.261
 can use motion tracking to know

02:01:03.262 --> 02:01:07.046
 how your device moved relative 
 to where it started.  So if, 

02:01:07.047 --> 02:01:08.844
 for example, I start here and I

02:01:08.845 --> 02:01:15.062
 move 1 meter, I can ask the 
 motion tracking component how 

02:01:15.063 --> 02:01:18.956
 far I moved relative to the 
 start.  If I move back to the 

02:01:18.957 --> 02:01:20.456
 original place I can ask motion

02:01:20.457 --> 02:01:21.851
 tracking where I am and it will

02:01:21.852 --> 02:01:24.753
 tell me I'm back where I start
 started.

02:01:24.754 --> 02:01:27.748
    So motion tracking is all 
 about allowing developers to 

02:01:27.749 --> 02:01:29.861
 ask the device how it is moving

02:01:29.862 --> 02:01:37.860
 through space.  Then depth 
 perception.  So every Tango 

02:01:37.861 --> 02:01:42.852
 enableed device or every Tango 
 phone has a special 3D camera. 

02:01:45.257 --> 02:01:48.749
 device can sense the 3D 
 geometry of the world around it

02:01:49.059 --> 02:01:51.466
 it.  So if I point my device at

02:01:51.467 --> 02:01:55.057
 the speaker desk here it could 
 sense kind of this geometry at 

02:01:55.058 --> 02:01:58.251
 the front of the desk.  If I 
 point it at the back of the 

02:01:58.252 --> 02:02:01.756
 desk it would sense the 
 geometry at the back of the 

02:02:01.757 --> 02:02:05.953
 desk.  Wherever I point it it 
 can sense the 3D geometry.  As 

02:02:05.954 --> 02:02:13.368
 a developer you can query that 
 3D information in the 3D . 

02:02:13.369 --> 02:02:16.763
 clouds.
    So then the last core 

02:02:16.764 --> 02:02:20.153
 technology Area learning, this 
 is what really gives your Tango

02:02:22.558 --> 02:02:26.752
 in a very similar way to how 
 people operate in the real 

02:02:26.753 --> 02:02:32.549
 world.  Remember when you came 
 into this dome or tent thing, 

02:02:32.550 --> 02:02:35.363
 probably in the back of your 
 head you started building up a 

02:02:35.364 --> 02:02:39.262
 model of what the space looked 
 like.  You saw a speaker desk, 

02:02:39.263 --> 02:02:42.961
 there's two big screens, there
 there's a lot of chairs.  And 

02:02:42.962 --> 02:02:46.055
 you take that mental model and 
 you store it in your memory.

02:02:46.762 --> 02:02:49.783
    So imagine now if you would 
 leave the room.  Say you go to 

02:02:49.784 --> 02:02:53.053
 the restroom.  When you come 
 back later you would quickly 

02:02:53.054 --> 02:02:55.655
 recognize that you're in the 
 same space because you 

02:02:55.656 --> 02:02:58.669
 recognize the desk and the 
 screens and the chairs.  You 

02:02:58.670 --> 02:03:02.161
 would recognize that you are 
 back in that same space.

02:03:02.162 --> 02:03:05.856
    And Tango Area learning 
 works in a very similar way.  

02:03:05.857 --> 02:03:11.460
 So when you bring a Tango 
 device into a new space it will

02:03:13.860 --> 02:03:16.561
 world and compute this 
 mathematical description of 

02:03:16.562 --> 02:03:20.963
 what the world looks like and 
 it will store that mathematical

02:03:22.753 --> 02:03:26.062
 When you then bring that same 
 Tango device in the same room 

02:03:26.063 --> 02:03:27.961
 at a later time it will be able

02:03:27.962 --> 02:03:31.571
 to compare what it sees with 
 its camera to that mathematical

02:03:33.956 --> 02:03:37.669
 memory.  When those two match 
 up it recognizes the space and 

02:03:37.670 --> 02:03:39.357
 it knows exactly where it is in

02:03:39.358 --> 02:03:43.063
 that space.
    So let's dive a little deep

02:03:43.271 --> 02:03:47.154
 deeper into the details of how 
 Area learning works and even 

02:03:47.155 --> 02:03:53.957
 how Tango works under the hood.
    So Tango has this wide angle

02:03:56.165 --> 02:03:59.068
 the world.  It is much like 
 this example when you are 

02:03:59.069 --> 02:04:05.171
 visiting a mall, your Tango 
 device will look at a few key 

02:04:05.172 --> 02:04:08.356
 landmarks it cease in the world
 world.  For example here on the

02:04:09.961 --> 02:04:12.864
 machine in front of you.  There
 There's some restrooms and then

02:04:16.167 --> 02:04:18.464
    So now what happens when you

02:04:18.465 --> 02:04:23.061
 start moving in this 
 environment and you keep look

02:04:23.264 --> 02:04:26.562
 looking at those same landmarks
 landmarks.  What happens is you

02:04:28.774 --> 02:04:32.764
 sudden in different places in 
 your field of view.  So for 

02:04:32.765 --> 02:04:36.575
 example if you look at that 
 vending machine, initially it 

02:04:36.576 --> 02:04:41.160
 was on your left side.  As you 
 move, at the end the vending 

02:04:41.161 --> 02:04:44.263
 machine is almost right in 
 front of you.  And this is 

02:04:44.264 --> 02:04:48.661
 exactly how Tango motion 
 tracking works.  Tango will 

02:04:48.662 --> 02:04:53.264
 look at all these landmarks in 
 the world and see how they move

02:04:55.669 --> 02:04:59.863
 that motion it can compute its 
 own motion in space.

02:04:59.864 --> 02:05:03.361
    So this is pure motion 
 tracking.  This is still all 

02:05:03.362 --> 02:05:05.872
 without any memory.  So in this

02:05:05.873 --> 02:05:09.970
 example, if you are in the mall
 mall, if you cover your eyes, 

02:05:09.971 --> 02:05:13.261
 spin around and open your eyes 
 again, you would have no idea 

02:05:13.262 --> 02:05:15.961
 where you are because you 
 didn't have any memory of that 

02:05:15.962 --> 02:05:19.777
 space.  The same, every time 
 you start Tango motion tracking

02:05:20.475 --> 02:05:23.563
 tracking, it doesn't have any 
 memory.  So it always starts 

02:05:23.564 --> 02:05:28.268
 from scratch.
    So let's now think about 

02:05:28.269 --> 02:05:32.361
 what if we add memory to this. 

02:05:32.362 --> 02:05:36.170
 So for a Tango device it 
 doesn't need to remember the 

02:05:36.171 --> 02:05:41.467
 entire image of what it sees.  
 It only needs to remember the 

02:05:41.468 --> 02:05:44.665
 key landmarks that it's track
 tracking.  In this case it 

02:05:44.666 --> 02:05:49.677
 would look at a small square 
 patch, like the yellow squares 

02:05:49.678 --> 02:05:53.963
 around each landmark to store 
 kind of a mathematical 

02:05:53.964 --> 02:05:57.567
 description of what exactly 
 that landmark looks like.  Your

02:06:04.166 --> 02:06:08.471
 Tango will store two things in 
 memory.  One is where it saw 

02:06:08.472 --> 02:06:11.763
 that landmark, and the second 
 is that mathematical 

02:06:11.764 --> 02:06:15.974
 description of what that 
 landmark looks like.  This is 

02:06:15.975 --> 02:06:21.669
 how Tango can remember its 
 space.

02:06:21.670 --> 02:06:26.181
    So let's jump to a live demo
 demo.  So you can actually see 

02:06:26.182 --> 02:06:35.281
 how this works under the hood.
    So I'll

02:06:36.682 --> 02:06:42.582
 first just start up 
 Tango motion tracking.  Here if

02:06:43.966 --> 02:06:47.773
 the screen you get to see how 
 Tango is looking at the world. 

02:06:54.465 --> 02:07:00.178
 landmarks that Tango is seeing 
 and that Tango is tracking.  

02:07:00.179 --> 02:07:02.873
 Instead of looking at two or 
 three or four points in the 

02:07:02.874 --> 02:07:06.075
 world, Tango can look at 100 
 points at the same time.

02:07:06.076 --> 02:07:08.065
    As I move, Tango keeps track

02:07:08.066 --> 02:07:11.371
 of how all those landmarks kind

02:07:11.372 --> 02:07:15.271
 of move in the image.  If you 
 then look at the right-hand 

02:07:15.272 --> 02:07:18.477
 side of the screen it's a top-
 top-down view of where I am.  

02:07:18.478 --> 02:07:24.278
 If I walk in a big circle here 
 you can see that motion 

02:07:24.279 --> 02:07:27.582
 tracking knows exactly that I 
 walked in that circle and that 

02:07:27.583 --> 02:07:30.481
 I ended up back where I started
 started.

02:07:30.482 --> 02:07:34.883
    So this is motion tracking 
 under the hood.

02:07:34.884 --> 02:07:40.283
    Let's now jump to area 
 learning.

02:07:44.869 --> 02:07:47.781
  So initially this 
 looks very similar.  You just 

02:07:47.782 --> 02:07:49.673
 have Tango looking out into the

02:07:49.674 --> 02:07:53.771
 world, but now Tango is actual
 actually building up a memory 

02:07:53.772 --> 02:07:58.487
 of what the space looks like.  
 Once it has created a memory, 

02:07:58.488 --> 02:08:02.170
 as has happened now, you see 
 all these static yellow dots.  

02:08:02.171 --> 02:08:07.384
 Those are the landmarks that 
 Tango has remembered.  I can go

02:08:10.171 --> 02:08:13.072
 physical points in the world 
 that Tango has stored in its 

02:08:13.073 --> 02:08:15.881
 memory.
    On the right-hand side you 

02:08:15.882 --> 02:08:21.279
 see these lines coming out of 
 the device.  That is showing 

02:08:21.280 --> 02:08:27.179
 where Tango recognizes a 
 landmark that it has stored in 

02:08:27.180 --> 02:08:29.689
 its memory.
    Now we can do something real

02:08:29.714 --> 02:08:33.587
 really cool.  Say I cover the 
 cameras here.  My device has no

02:08:45.381 --> 02:08:49.277
 it learned, you can see all 
 those landmarks popped back 

02:08:49.278 --> 02:08:51.679
 into place.  It actually 
 remembered where it was based 

02:08:51.680 --> 02:08:54.472
 on that memory.  Let me do that

02:08:54.473 --> 02:08:56.473
 one more time.

02:08:58.890 --> 02:09:00.977
    So now it doesn't know where

02:09:00.978 --> 02:09:06.780
 it is.  And then you see it 
 jump and all the yellow dots 

02:09:06.781 --> 02:09:10.682
 are back in place.
    (Applause.)

02:09:10.683 --> 02:09:13.087
    &gt;&gt; WIM MEEUSSEN:  It's 
 pretty cool, right?

02:09:13.088 --> 02:09:17.683
    So this is really a view 
 under the hood of how Tango 

02:09:17.684 --> 02:09:22.285
 operates for both motion 
 tracking and for area learning.

02:09:22.286 --> 02:09:27.684
    So now let's look a little 
 bit at how we can use area 

02:09:27.685 --> 02:09:31.584
 learning.  You have a pretty 
 good understanding of how it 

02:09:31.585 --> 02:09:35.176
 works.  Let's see, what can it 
 go for you.  What kind of new 

02:09:35.177 --> 02:09:39.883
 experiences can area learning 
 enable?

02:09:39.884 --> 02:09:44.785
    And let's first cover kind 
 of an AR example.  So let's say

02:09:49.891 --> 02:09:53.295
 want to see how it fits.  The 
 problem you're having here is 

02:09:53.296 --> 02:09:57.480
 that that chair will start 
 drifting over time.  And that 

02:09:57.481 --> 02:10:00.382
 is because if you just have 
 motion tracking you will have 

02:10:00.383 --> 02:10:05.280
 very small errors that slowly 
 accumulate over time.  And if 

02:10:05.281 --> 02:10:08.592
 you walk around enough your 
 chair might look something like

02:10:10.886 --> 02:10:12.678
 and drift.  But this is exactly

02:10:12.679 --> 02:10:17.280
 the problem everyone wants 
 solved with Area learning.  You

02:10:19.794 --> 02:10:23.283
 right there.  The way area 
 learning can help here, it can 

02:10:23.284 --> 02:10:26.778
 build up a memory of where you 
 placed that chair in the world.

02:10:28.790 --> 02:10:30.885
 exactly you placed that chair. 

02:10:30.886 --> 02:10:34.891
 So even though if motion 
 tracking slowly drifts, because

02:10:36.279 --> 02:10:38.088
 placed that chair it can always

02:10:38.089 --> 02:10:41.381
 correct it and put the chair 
 right back in the right place.

02:10:43.380 --> 02:10:45.684
    And I'll have a live demo of

02:10:45.685 --> 02:10:47.587
 this coming up a little later. 

02:10:47.588 --> 02:10:50.489
 It's actually pretty cool to 
 see.

02:10:50.490 --> 02:10:53.282
    So there's obviously a 
 number of other AR based 

02:10:53.283 --> 02:10:57.686
 examples.  Let's say you are 
 using the 3D sensor to start 

02:10:57.687 --> 02:11:01.398
 measuring the geometry of your 
 world.  If you have these nice 

02:11:01.399 --> 02:11:04.487
 yellow annotations on your 
 world, you want them to stay 

02:11:04.488 --> 02:11:07.486
 exactly in the right place.  
 You don't want them to start 

02:11:07.487 --> 02:11:09.881
 drifting around.  This is again

02:11:09.882 --> 02:11:12.985
 where area learning can help.
    And even if you have an 

02:11:12.986 --> 02:11:16.682
 example where your objects are 
 in static, like, for example, 

02:11:16.683 --> 02:11:18.788
 you have these monsters running

02:11:18.789 --> 02:11:23.191
 around, you still do care that 
 your virtual world and your 

02:11:23.192 --> 02:11:26.589
 real world stay aligned with 
 each other.  If you would start

02:11:29.296 --> 02:11:31.589
 monsters would start running to

02:11:31.590 --> 02:11:36.089
 the shelving and you want them 
 to stay in the center aisle.  

02:11:36.090 --> 02:11:39.898
 You do care about that 
 alignment.  Again area learning

02:11:42.895 --> 02:11:47.995
 jump to the second kind of big 
 use case.  That is multiplayer 

02:11:47.996 --> 02:11:50.897
 experiences.
    So the problem here is 

02:11:50.898 --> 02:11:54.389
 pretty obvious.  You want to 
 know where all the other player

02:11:54.799 --> 02:11:58.692
 players are in the world.  And 
 it would be awesome if you can 

02:11:58.693 --> 02:12:00.893
 do it without needing to put in

02:12:00.894 --> 02:12:04.001
 capables 
 capable cables or 

02:12:04.002 --> 02:12:07.090
 infrastructure in your 
 environment.  How can area 

02:12:07.091 --> 02:12:08.787
 learning help here?  So the key

02:12:08.788 --> 02:12:13.287
 for multiplayer experience is 
 to have a memory of your space 

02:12:13.288 --> 02:12:17.584
 and to share that memory 
 between all the devices.  When 

02:12:17.585 --> 02:12:23.685
 all your devices have the same 
 memory, here this is the 

02:12:23.686 --> 02:12:28.104
 display of what your device 
 could have memorized.  If all 

02:12:28.105 --> 02:12:30.089
 your devices share that memory,

02:12:30.090 --> 02:12:35.995
 they can all start recognizing 
 where they are in that space.  

02:12:35.996 --> 02:12:41.487
 And in some sense you turn the 
 real world in your kind of way 

02:12:41.488 --> 02:12:46.492
 to tie all these Tango devices 
 together.  You don't need any 

02:12:46.493 --> 02:12:47.692
 special infrastructure.  You're

02:12:47.693 --> 02:12:51.593
 using your couch, your carpet, 
 the poster on the wall.  They 

02:12:51.594 --> 02:12:54.091
 literally tie together this 
 multiplayer experience.

02:12:59.603 --> 02:13:04.494
    So let's look a little bit 
 at how this actually turns out 

02:13:04.495 --> 02:13:07.903
 in the real world.  The real 
 world is always a little bit 

02:13:07.904 --> 02:13:11.597
 more messy.  Give a number of 
 examples where Tango will have 

02:13:11.598 --> 02:13:14.738
 some challenges with area 
 learning.  It will give you a 

02:13:14.739 --> 02:13:19.396
 bit of a better understanding 
 of where to best apply area 

02:13:19.397 --> 02:13:22.604
 learning.
    So if you look at these two 

02:13:22.605 --> 02:13:26.603
 images here, the left side 
 could be what your room usually

02:13:28.308 --> 02:13:31.497
 probably what you want your 
 room to look like.  If you and 

02:13:31.498 --> 02:13:35.695
 me look at these images we can 
 kind of recognize it's probably

02:13:37.707 --> 02:13:41.204
 the same shelves, there's hang
 hangers that you recognize.

02:13:41.205 --> 02:13:44.903
    Pretty sure, same place.
    But for a Tango device those

02:13:46.795 --> 02:13:51.202
 different spaces because Tango 
 has built up all these landmark

02:13:51.594 --> 02:13:54.497
 landmarks on top of the clothes
 and 

02:13:54.498 --> 02:13:56.602
 everywhere.  If all the clothes

02:13:56.603 --> 02:14:01.293
 move, the landmarks moved and 
 Tango would get confused.  

02:14:01.294 --> 02:14:03.410
 Imagine you are walking around 
 San Francisco and you are look

02:14:03.699 --> 02:14:07.706
 looking at some of the big 
 skyscrapers to keep yourself 

02:14:07.707 --> 02:14:11.110
 oriented and someone comes in 
 and moves all the skyscrapers 

02:14:11.111 --> 02:14:14.398
 around.  You would be pretty 
 lost.  This is what happens to 

02:14:14.399 --> 02:14:18.598
 Tango when stuff in the 
 environment moves a lot.

02:14:18.599 --> 02:14:22.905
    So here is an example where 
 things didn't move, but one 

02:14:22.906 --> 02:14:26.099
 image was taken in the day and 
 one at night.  Even though your

02:14:29.897 --> 02:14:33.898
 differently because of the 
 lighting, because of shadows.

02:14:33.899 --> 02:14:37.096
    And something that everyone 
 has played with cameras will 

02:14:37.097 --> 02:14:38.302
 probably recognize, if you have

02:14:38.303 --> 02:14:41.901
 a dark room and a really really
 bright 

02:14:41.902 --> 02:14:46.098
 window you have troubles with 
 your exposure.  You need to 

02:14:46.099 --> 02:14:49.206
 tune in on the window or the 
 room but you cannot have it 

02:14:49.207 --> 02:14:53.100
 both ways.  This should be 
 pretty obvious.  If you have 

02:14:53.101 --> 02:14:56.415
 large crowds they can make a 
 space look very differently.  

02:14:56.416 --> 02:15:01.107
 Then another kind of extreme 
 example, Tango looks for visual

02:15:01.403 --> 02:15:05.099
 visually interesting things in 
 the world.  If your room is all

02:15:07.300 --> 02:15:11.605
 is nothing visually interesting
 interesting.  There's no 

02:15:11.606 --> 02:15:16.705
 landmarks for Tango to 
 recognize.  If you go outside 

02:15:16.706 --> 02:15:21.612
 you can imagine a lot more 
 different scenes, weather, 

02:15:21.613 --> 02:15:25.398
 shadows, the outside gets a 
 little more challenging.

02:15:25.399 --> 02:15:29.006
    So the question is:  How do 
 you deal with all these 

02:15:29.007 --> 02:15:33.601
 challenges?  And the key point 
 here is time.  Like if you look

02:15:35.508 --> 02:15:40.002
 we talked about, those happen 
 slowly over time.  And in some 

02:15:40.003 --> 02:15:43.803
 environments will change quick
 quickly and some will change 

02:15:43.804 --> 02:15:46.007
 very slowly.  You can imagine a

02:15:46.008 --> 02:15:49.719
 museum that has the same 
 exhibition year-round and has 

02:15:49.720 --> 02:15:51.919
 maybe constant lighting.  There

02:15:51.920 --> 02:15:55.214
 your memory will be good for 
 months and months at a time.  

02:15:55.215 --> 02:15:58.814
 At the other extreme of the 
 scale you can imagine a subway 

02:15:58.815 --> 02:16:01.606
 station with lots of people 
 running around, maybe there's 

02:16:01.607 --> 02:16:03.402
 advertisements that change.  So

02:16:03.403 --> 02:16:07.406
 there your memory would be 
 valid for a lot shorter of a 

02:16:07.407 --> 02:16:09.809
 time.
    So a really good strategy to

02:16:13.709 --> 02:16:18.108
 short-term memory.  So if you 
 think about your AR application

02:16:20.307 --> 02:16:24.914
 furniture in your house, maybe 
 you want to look at it for 20, 

02:16:24.915 --> 02:16:28.113
 30 minutes.  But then during 
 those 30 minutes your house is 

02:16:28.114 --> 02:16:29.921
 not going to change.  So you're

02:16:29.922 --> 02:16:32.711
 good there.
    But if you want to play a 

02:16:32.712 --> 02:16:34.206
 multiplayer game in your living

02:16:34.207 --> 02:16:37.519
 room, maybe you want to play 
 for a couple hours.  During 

02:16:37.520 --> 02:16:40.404
 that time the living room is 
 still going to be your living 

02:16:40.405 --> 02:16:44.710
 room.  So if you rely on short
 shorter term memory, area 

02:16:44.711 --> 02:16:46.723
 learning could be a powerful 
 and reliable tool

02:16:50.307 --> 02:16:54.417
.
    So let's get to the -- oh, 

02:16:54.418 --> 02:16:56.409
 let's actually play this video.

02:16:56.410 --> 02:17:01.418
 So this is a real world example

02:17:01.419 --> 02:17:05.817
 of area learning being used.  
 This video was recorded in the 

02:17:05.818 --> 02:17:12.105
 Zurich train station.  And if 
 you look at the video, you can 

02:17:12.106 --> 02:17:15.016
 see a lot of the challenges 
 that we just talked about.  

02:17:15.017 --> 02:17:19.919
 There's some outdoors or some 
 shadows that you see.  There's 

02:17:19.920 --> 02:17:22.410
 people walking around.  You can

02:17:22.411 --> 02:17:28.905
 see the floors are kind of one 
 color.  But then still area 

02:17:28.906 --> 02:17:33.823
 learning can actually work in 
 this environment.

02:17:33.824 --> 02:17:37.106
    So area learning can be 
 pretty robust through a number 

02:17:37.107 --> 02:17:39.607
 of these changes.  The examples

02:17:39.608 --> 02:17:43.320
 I showed were extreme to drive 
 the point home but you can see 

02:17:43.321 --> 02:17:45.015
 how it actually operates in the

02:17:45.016 --> 02:17:49.311
 real world.
    Now, I'll go a little 

02:17:49.312 --> 02:17:52.524
 further in this video because 
 there's actually something cool

02:17:54.818 --> 02:17:59.216
 because Tango fully works in 3D
 3D.  You can actually go 

02:17:59.217 --> 02:18:01.317
 downstairs and it will tell you

02:18:01.318 --> 02:18:06.719
 in full three dimensions where 
 you are in the world.

02:18:11.115 --> 02:18:15.923
    So let's look a little bit 
 at how to build an application 

02:18:15.924 --> 02:18:18.417
 with area learning.  Again I'll

02:18:18.418 --> 02:18:22.522
 cover two examples.  I'll have 
 the AR example with drift 

02:18:22.523 --> 02:18:27.323
 correction and I'll have the 
 multiplayer example.

02:18:27.324 --> 02:18:32.725
    So first one, you want to 
 use memory here to keep all 

02:18:32.726 --> 02:18:34.315
 your virtual objects exactly in

02:18:34.316 --> 02:18:38.620
 the same place.  So this is 
 kind of where area learning 

02:18:38.621 --> 02:18:44.819
 will help you build this.  And 
 for this example, I will assume

02:18:51.725 --> 02:18:55.918
 you have an application that 
 uses AR, and I'll tell you how 

02:18:55.919 --> 02:19:00.614
 to transition it to area 
 learning.  If you don't yet 

02:19:00.615 --> 02:19:05.110
 know how to build an AR 
 application, Friday morning, 

02:19:05.111 --> 02:19:10.414
 there is an interesting talk 
 about how to build a full AR 

02:19:10.415 --> 02:19:11.912
 end-to-end example using Tango.

02:19:11.913 --> 02:19:15.330
 So if you're interested in that
 that, definitely go check out 

02:19:15.331 --> 02:19:17.331
 that talk.
    Here I would assume you have

02:19:23.125 --> 02:19:26.619
 area learning.  And the point 
 of this light is just to show 

02:19:26.620 --> 02:19:30.732
 you it is really easy.  You 
 need to change literally two 

02:19:30.733 --> 02:19:34.011
 lines of code.
    In the first highlighted 

02:19:34.012 --> 02:19:39.416
 line, you just tell Tango 
 please enable drift correction.

02:19:41.315 --> 02:19:43.514
 tell Tango instead of measuring

02:19:43.515 --> 02:19:47.413
 where your device is relative 
 to where you started, measure 

02:19:47.414 --> 02:19:49.726
 it relative to this memory that

02:19:49.727 --> 02:19:52.921
 we'll build up.  With just 
 those two lines you can 

02:19:52.922 --> 02:19:57.616
 transition an app from regular 
 AR to area learning AR.

02:19:57.617 --> 02:20:02.645
    Let me show you a demo of 
 how that works.

02:20:07.122 --> 02:20:11.334
    So I'll show the same app 
 first without area learning and

02:20:13.627 --> 02:20:18.120
    So this is a little AR app 
 that allows me to place a real

02:20:18.159 --> 02:20:27.021
 really large cube on top of 
 things.  So we are not using 

02:20:27.022 --> 02:20:31.718
 area learning, but the cube is 
 pretty, it stays in place 

02:20:31.719 --> 02:20:37.224
 reasonably well.  But now we 
 have a little bit more, I move 

02:20:37.225 --> 02:20:40.417
 around.  You can see it is 
 still more or less there.  If I

02:20:43.926 --> 02:20:47.023
 some point I will lose my cube.

02:20:47.024 --> 02:20:52.330
 It just doesn't remember 
 anymore where it is.

02:20:52.331 --> 02:20:57.728
    So let's now do the exact 
 same thing with area learning 

02:20:57.729 --> 02:21:03.231
 enableed.  So now in the 
 background Tango is actually 

02:21:03.232 --> 02:21:05.228
 building up that memory of what

02:21:05.229 --> 02:21:12.918
 the speaker desk looks like.  
 So now let me place the cube 

02:21:12.919 --> 02:21:17.837
 back.  So now we can do the 
 same thing.  I can shake the 

02:21:17.838 --> 02:21:22.236
 device, if I look back as soon 
 as it recognizes the space, it 

02:21:22.237 --> 02:21:25.621
 can put the cube back exactly 
 in the right place.

02:21:25.622 --> 02:21:32.437
    I can do my example where I 
 cover the camera, let the app 

02:21:32.438 --> 02:21:37.539
 get completely lost.  And when 
 I open it back, as soon as it 

02:21:37.540 --> 02:21:41.330
 recognizes it it can put the 
 cube back in exactly the right 

02:21:41.331 --> 02:21:44.431
 place.  So you can have 
 applications where your virtual

02:21:46.132 --> 02:21:50.429
 are, even if your session break
 breaks, even if your user does 

02:21:50.430 --> 02:21:53.840
 something crazy, the virtual 
 objects will stay in the same 

02:21:53.841 --> 02:21:55.841
 place.
    (Applause.)

02:22:01.642 --> 02:22:04.227
    &gt;&gt; WIM MEEUSSEN:  So let's 
 jump to the next example.  How 

02:22:04.228 --> 02:22:06.629
 do we build a multiplayer game?

02:22:06.630 --> 02:22:10.446
 So this is a little bit more 
 involved.  It includes three 

02:22:10.447 --> 02:22:16.431
 different steps.  So first we 
 will create a memory of, let's 

02:22:16.432 --> 02:22:19.629
 say your living room.  Then we 
 will share that memory with all

02:22:21.735 --> 02:22:26.324
 your game.  So let's first 
 thing about how do you create 

02:22:26.325 --> 02:22:31.127
 that memory?  So what that 
 means in your shared space, you

02:22:37.831 --> 02:22:43.039
 code in Tango?  Very simple, 
 you tell Tango start learning 

02:22:43.040 --> 02:22:48.830
 the area.  Then when you're 
 done, you say "save."

02:22:48.831 --> 02:22:52.027
    Then you have built up a 
 memory of what that space looks

02:22:58.941 --> 02:23:01.331
 devices?  Again, pretty simple.

02:23:01.332 --> 02:23:04.936
 Tango has an export and import 
 functionality.  So you can 

02:23:04.937 --> 02:23:08.333
 export your memory from one 
 device and import it on all the

02:23:10.934 --> 02:23:14.536
    So once you have all your 
 devices set up, you are ready 

02:23:14.537 --> 02:23:20.340
 to go play.  So what area 
 learning has done or what the 

02:23:20.341 --> 02:23:24.434
 building of that memory has 
 done is created this one 

02:23:24.435 --> 02:23:26.931
 reference frame that can be 
 used by all the different 

02:23:26.932 --> 02:23:31.836
 devices.  Because that entire 
 memory is all reference from 

02:23:31.837 --> 02:23:36.235
 like one frame in your 
 environment.

02:23:36.236 --> 02:23:39.433
    So every single device in 
 your multiplayer game can 

02:23:39.434 --> 02:23:41.635
 directly ask Tango:  Where am I

02:23:41.636 --> 02:23:45.138
 relative to this memory?  If 
 you have multiple devices using

02:23:47.641 --> 02:23:49.531
 get their reference relative to

02:23:49.532 --> 02:23:56.235
 the same reference frame.
    And this is how you run that

02:23:59.833 --> 02:24:04.040
 Tango please use this memory 
 and then you start asking Tango

02:24:04.333 --> 02:24:07.036
 Tango:  Where are you relative 
 to this memory?

02:24:07.037 --> 02:24:09.141
    So the code all looks pretty

02:24:09.142 --> 02:24:13.635
 simple.  So now I want to share

02:24:13.636 --> 02:24:17.830
 a video.  I want to introduce 
 the video a little because I 

02:24:17.831 --> 02:24:21.835
 think it's easy to under 
 appreciate the awesomeness of 

02:24:21.836 --> 02:24:27.144
 the video.  So the setting is 
 exactly this picture here.  So 

02:24:27.145 --> 02:24:28.734
 we have three players that have

02:24:28.735 --> 02:24:32.130
 a Tango device non-front of 
 their face.  So they are 

02:24:32.131 --> 02:24:35.033
 completely in a virtual world. 

02:24:35.034 --> 02:24:39.142
 They can not see each other.  
 And the video you are going to 

02:24:39.143 --> 02:24:42.942
 see is showing that virtual 
 world of what one of the player

02:24:43.338 --> 02:24:46.638
 players is seeing.
    And one of the key things 

02:24:46.639 --> 02:24:50.338
 you should look out for, in 
 that video you will see a Tango

02:24:53.747 --> 02:24:55.141
 virtual Tango device because it

02:24:55.142 --> 02:24:58.434
 is a virtual world.  But that 
 device is actually exactly a 

02:24:58.435 --> 02:25:02.637
 match on a real device that's 
 in the real world.  You'll see 

02:25:02.638 --> 02:25:06.342
 different players hand that 
 device to each other.  So think

02:25:10.945 --> 02:25:13.644
 virtual world.  Only if they 
 know exactly where all the 

02:25:13.645 --> 02:25:16.845
 other players are, they know 
 exactly where that device is, 

02:25:16.846 --> 02:25:20.943
 only then can they do this 
 comfortable hand-off.  It's 

02:25:20.944 --> 02:25:23.035
 pretty amazing.  Check it out.

02:25:32.244 --> 02:25:36.346
    So this is filmed from the 
 third person.  Even the third 

02:25:36.347 --> 02:25:41.239
 person is moving around.  You 
 see how the other two are just 

02:25:41.240 --> 02:25:44.850
 casually handing off the Tango 
 device from one to the other.  

02:25:44.851 --> 02:25:50.042
 So this is only possible with 
 registration between all those 

02:25:50.043 --> 02:25:51.853
 different components.  You have

02:25:51.854 --> 02:25:55.737
 two players.  You have the 
 person filming it.  And then 

02:25:55.738 --> 02:25:59.445
 the Tango device.  You have 
 four different devices tightly 

02:25:59.446 --> 02:26:02.736
 coordinated with each other.  
 So pretty amazing.

02:26:02.737 --> 02:26:04.737
    (Applause.)

02:26:08.539 --> 02:26:12.536
    &gt;&gt; WIM MEEUSSEN:  Then this 
 is an example of kind of using 

02:26:12.537 --> 02:26:16.139
 VR.  If you want to try 
 something like this for 

02:26:16.140 --> 02:26:18.548
 yourself, are tomorrow night in

02:26:18.549 --> 02:26:23.537
 the Project Tango after hours 
 we have an AR multiplayer game 

02:26:23.538 --> 02:26:26.043
 set up.  You can go try it out.

02:26:26.044 --> 02:26:30.443
 And also if you want to just 
 try Tango demos, the sandbox is

02:26:34.441 --> 02:26:39.842
 of cool stuff going on.
    Not that now that I'm 

02:26:39.843 --> 02:26:41.653
advertising 
 a couple of things, there's two

02:26:43.446 --> 02:26:47.046
 Tomorrow at 3:00 p.m., Johnny 
 Lee will be talking about 

02:26:47.047 --> 02:26:50.444
 everything that is new within 
 Tango.  Definitely go check it 

02:26:50.445 --> 02:26:57.154
 out.  Then on Friday, Friday 
 morning A hunk will be talking 

02:26:57.155 --> 02:27:02.145
 about how to build an AR 
 application.  Two more exciting

02:27:04.157 --> 02:27:07.855
    What's next for Tango?  And 
 what's next for area learning? 

02:27:09.443 --> 02:27:14.342
    So I hope by seeing the demo
 demos you have been wondering: 

02:27:18.360 --> 02:27:22.645
 everything you see until now 
 will be part of our release 

02:27:22.646 --> 02:27:27.247
 coming out next month.  So yeah

02:27:27.248 --> 02:27:29.248
 ...
    (Applause.)

02:27:32.052 --> 02:27:34.154
    &gt;&gt; WIM MEEUSSEN:  You will 
 be able to build these drift-

02:27:34.861 --> 02:27:38.551
 drift-free, drift-corrected AR 
 experiences.  You will be able 

02:27:38.552 --> 02:27:42.654
 to build multiplayer experience
 experiences.  And this release 

02:27:42.655 --> 02:27:45.946
 is just a beginning for area 
 learning.  The Tango team will 

02:27:45.947 --> 02:27:50.648
 keep improving and we'll keep 
 building better and more robust

02:27:52.845 --> 02:27:57.458
 very beginning.  As developers 
 you are getting a very early 

02:27:57.459 --> 02:28:00.548
 preview on what area learning 
 can do.

02:28:00.549 --> 02:28:04.151
    This is the start of what 
 will become a pretty exciting 

02:28:04.152 --> 02:28:08.648
 journey.  So let's take a 
 little look at where this 

02:28:08.649 --> 02:28:12.455
 journey could take us next.  
 Let's look at future 

02:28:12.456 --> 02:28:15.153
 applications.
    So here imagine you are 

02:28:15.154 --> 02:28:19.861
 wrist it 
 visiting a mall and you're 

02:28:19.862 --> 02:28:23.252
 trying to figure out where you 
 are in that mall.  You pop out 

02:28:23.253 --> 02:28:26.054
 your phone, you start up Google

02:28:26.055 --> 02:28:27.665
 Maps and you see something like

02:28:27.666 --> 02:28:29.361
 the image on the left.  You get

02:28:29.362 --> 02:28:32.752
 a nice floor plan of the mall 
 and you see the big blue circle

02:28:34.650 --> 02:28:39.251
 somewhere here, but we don't 
 know quite exactly where.  

02:28:39.252 --> 02:28:42.748
 Imagine what you can do with 
 area learning.  Imagine if your

02:28:44.759 --> 02:28:49.250
 where it is in that mall.  You 
 could pinpoint your location.  

02:28:49.251 --> 02:28:52.450
 And your experience could look 
 a lot like the image on the 

02:28:52.451 --> 02:28:56.152
 right side where you have an 
 exact location, you even know 

02:28:56.153 --> 02:28:58.557
 exactly which direction you're 
 facing.

02:28:58.558 --> 02:29:02.655
    And if you take this one 
 step further, if you combine 

02:29:02.656 --> 02:29:04.950
 the very accurate location with

02:29:04.951 --> 02:29:08.463
 augmented reality, you can 
 imagine that you can get really

02:29:08.959 --> 02:29:11.052
 really 
 accurate directions on how to 

02:29:11.053 --> 02:29:14.352
 get from where you are to, let
 let's say, your favorite store 

02:29:14.353 --> 02:29:19.567
 in the mall.  Like all augment
 augmented in the real world.

02:29:19.568 --> 02:29:23.857
    So I hope this gives you 
 some idea of where area 

02:29:23.858 --> 02:29:26.853
 learning can take us in the 
 future and you realize we're 

02:29:26.854 --> 02:29:30.063
 just at the very beginning of 
 what this technology can do.

02:29:32.464 --> 02:29:35.464
    Then obviously we are not 
 only at the very beginning of 

02:29:35.465 --> 02:29:38.366
 technologies like area learning
 learning.  We are also at the 

02:29:38.367 --> 02:29:43.166
 very beginning of the Tango 
 device ecosystem.  So you've 

02:29:43.167 --> 02:29:46.956
 all seen the Yellowstone device
 devices which is our developer 

02:29:46.957 --> 02:29:49.973
 kit.  There's thousands of 
 those in the mands of developer

02:29:50.254 --> 02:29:55.656
 developers out in the world.  
 Now Tango has partnered up with

02:29:58.657 --> 02:30:02.764
 releasing the first consumer-
 consumer-facing Tango-enableed 

02:30:02.765 --> 02:30:09.066
 phone.  It will becoming out 
 later this year as a worldwide 

02:30:09.067 --> 02:30:11.067
 launch.
    (Applause.)

02:30:15.459 --> 02:30:16.663
    &gt;&gt; WIM MEEUSSEN:  So I hope,

02:30:16.664 --> 02:30:18.258
 like I said, I want to end with

02:30:18.259 --> 02:30:21.859
 this.  I hope you realize this 
 is actually a great and amazing

02:30:26.081 --> 02:30:29.259
 lot of new technologies coming 
 out.  There's new devices 

02:30:29.260 --> 02:30:33.870
 coming out.  I think we really 
 have this unique opportunity to

02:30:36.456 --> 02:30:40.562
 with their phones.  Even how 
 phones interact with the world.

02:30:40.563 --> 02:30:42.669
    So I'm pretty excited to see

02:30:42.670 --> 02:30:45.665
 what we can build together.  
 Thank you.

02:30:45.666 --> 02:30:47.666
    (Applause.)

02:30:51.666 --> 02:30:54.763
    (Music playing.)
    (The session concluded.)

02:34:35.960 --> 02:34:39.026
           ***
    This text is being provided 

02:34:35.960 --> 02:34:39.826
 in a rough draft format.  
 Communication Access Realtime 

02:34:35.960 --> 02:34:39.693
 Translation (CART) is provided 
 in order to facilitate 

02:34:35.960 --> 02:34:38.093
 communication accessibility and

02:34:35.960 --> 02:34:35.969
 may not be a totally verbatim 
 record of the proceedings.

02:34:35.970 --> 02:34:37.970
           *** 

02:39:19.987 --> 02:39:20.987
RAW COPY

02:39:19.987 --> 02:39:21.587
    Present:  AND OTHERS

02:39:19.987 --> 02:39:23.253
    Services provided by:
     Caption First, Inc.

02:39:19.987 --> 02:39:22.787
     P.O. Box 3066
     Monument, CO  80132

02:39:19.987 --> 02:39:22.720
     1-877-825-5234
     +001-719-481-9835

02:39:19.987 --> 02:39:21.653
     www.captionfirst.com

02:39:19.987 --> 02:39:22.720
      ***
    This is being provided in a 

02:39:19.987 --> 02:39:23.453
 rough draft format. 
 Communication Access Realtime 

02:39:19.987 --> 02:39:23.387
 Translation (CART) or 
 captioning are provided in 

02:39:19.987 --> 02:39:23.520
 order to facilitate 
 communication accessibility and

02:39:19.987 --> 02:39:22.387
 record of the proceedings.
      ***

02:40:57.326 --> 02:41:04.071
    (Please stand by for the CL7

02:41:04.072 --> 02:41:04.374
 session How to Build a Smark 
 RasPi Bot with Cloud Vision and

02:41:29.607 --> 02:41:33.923
    (Please stand by for the CL7

02:41:33.924 --> 02:41:35.249
 session:  How to Build a Smart 
 RasPi Bot with Cloud Vision and

02:51:29.489 --> 02:51:35.088
      ***
    (Please stand by for the CL7

02:51:35.898 --> 02:51:37.898
 Smart RasPi Bot with Cloud 
 Vision and Speech API.)

02:56:01.809 --> 02:56:06.010
    (Please stand by for the 
 session How to Build a Smart 

02:56:06.011 --> 02:56:06.016
 RasPi Bot with Cloud Vision and

02:56:06.017 --> 02:56:08.017
 Speech API.)

02:57:27.808 --> 02:57:30.005
    &gt;&gt; Ladies and gentlemen, 
 thank you for attending this 

02:57:30.006 --> 02:57:33.018
 session.  We will be with you 
 and starting this program in 

02:57:33.019 --> 02:57:37.516
 just a few moments.  Thank you 
 for your patience.

02:57:44.114 --> 02:57:46.114
    (Music playing.)

03:02:30.622 --> 03:02:33.523
    &gt;&gt; KAZ SATO:  Hello.  Thank 
 you for taking your time for 

03:02:33.524 --> 03:02:34.338
 our session, How to Build a 
 Smart RasPi Bot with Cloud 

03:02:34.339 --> 03:02:41.634
 Vision and Speech API I'm Kaz 
 sato, I am with Google Cloud 

03:02:41.635 --> 03:02:47.239
 Platform Glen I'm Glen Shires, 
 a software engineer on the 

03:02:47.240 --> 03:02:50.027
 Cloud speech API.
    &gt;&gt; KAZ SATO:  I would like 

03:02:50.028 --> 03:02:55.429
 to show a demonstration video 
 of Cloud Vision at first.  Let 

03:02:55.430 --> 03:02:57.430
 me share the video.

03:03:05.443 --> 03:03:09.938
    &gt;&gt; Provides powerful 
 capabilityies as easy to use 

03:03:09.939 --> 03:03:12.833
API
 APIs.  It enables application 

03:03:12.834 --> 03:03:18.529
 developers to build the next 
 generation of, that can see the

03:03:23.135 --> 03:03:26.625
 that power several services.  
 The service enables developers 

03:03:26.626 --> 03:03:30.434
 to detect abroad set of 
 attitudes within an image from 

03:03:30.435 --> 03:03:35.031
 every day objects to faces.  
 The service is so easy to use. 

03:03:36.939 --> 03:03:44.034
 cases, you can have any RasPi 
 pi robot like GoPiGo calling 

03:03:44.035 --> 03:03:48.232
 the application directly.  The 
 ball can send the images taken 

03:03:48.233 --> 03:03:51.428
 by the camera to the Cloud and 
 get analysis results in 

03:03:51.429 --> 03:03:54.534
 realtime.  It takes spaces in 
 the image along with the 

03:03:54.535 --> 03:03:56.736
 associateed emotions.  The 
Cloud 

03:03:56.737 --> 03:04:00.835
 Vision API is able to detect 
 entityies within the image.  

03:04:00.836 --> 03:04:03.128
Now 
 let's see how facial 

03:04:03.129 --> 03:04:06.145
 discrimination works.  Cloud 
 Vision detects faces on the 

03:04:06.146 --> 03:04:09.044
 picture and returns the 
 position of eyes, nose, and 

03:04:09.045 --> 03:04:11.131
 mouth.  You can program the bot

03:04:11.132 --> 03:04:17.933
 to follow the face.
    (Mechanicaldigital sound.)

03:04:18.135 --> 03:04:24.041
    &gt;&gt; It detects emotion such 
 as joy, anger, surprise, sorrow

03:04:24.330 --> 03:04:27.932
 sorrow.  The ball can move 
 towards smiling faces or avoid 

03:04:27.933 --> 03:04:30.929
 anger or surprised face.
    &gt;&gt; One of the very interest

03:04:31.131 --> 03:04:33.728
 interesting interest
 interesting features of Cloud 

03:04:33.729 --> 03:04:38.344
 Vision API is the detection.  
 It detects any object you like.

03:04:47.045 --> 03:04:51.133
    (Digital voice:  It's glass
 glasses, it's awfnlt.)

03:04:51.134 --> 03:04:57.035
    &gt;&gt; Hmm.  (Digital voice:  It
 It's money.)

03:04:57.036 --> 03:05:02.144
    &gt;&gt; Cloud Vision would like 
 developers to take advantage of

03:05:05.833 --> 03:05:09.629
 website to learn more.
    &gt;&gt; KAZ SATO:  That was the 

03:05:09.630 --> 03:05:13.135
 demonstration vision video for 
Cloud 

03:05:13.136 --> 03:05:18.134
 Vision bots.  I would like to 
 discuss how to build the bot by

03:05:22.439 --> 03:05:27.247
 talking about the intelligence 
 working behind the bot.

03:05:27.248 --> 03:05:31.040
    &gt;&gt; GLEN SHIRES:  Thank you.
    &gt;&gt; KAZ SATO:  So we are 

03:05:31.041 --> 03:05:34.154
 using technology called nerual 
 networks.  What is nerual 

03:05:34.155 --> 03:05:41.334
 network?  Nerual network is a 
 function that can allow from 

03:05:41.335 --> 03:05:48.148
 the training data set.  It 
 mimics the human brain by using

03:05:49.345 --> 03:05:52.945
 example if you want to do 
 recognitions with nerual 

03:05:52.946 --> 03:05:55.543
 networks, then you can converge

03:05:55.544 --> 03:06:00.034
 your input image such as cat 
 images into a large vector and 

03:06:00.035 --> 03:06:05.138
 then put that vector to the 
 nerual networks where it does a

03:06:09.338 --> 03:06:12.336
 as multiplications or additions

03:06:12.337 --> 03:06:16.544
 between vectors and matrixes.  
 Eventually you have another 

03:06:16.545 --> 03:06:18.334
 large vector as an output which

03:06:18.335 --> 03:06:23.435
 represents the levels of the 
 objects detected such as the 

03:06:23.436 --> 03:06:27.153
 cat or automobile or the human 
 face.

03:06:27.154 --> 03:06:30.355
    So let's take a look at 
 another example, how nerual 

03:06:30.356 --> 03:06:35.837
 networks works, nerual network 
 works by using the data set 

03:06:35.838 --> 03:06:39.742
 called double spiral.  In this 
 double spiral data set we have 

03:06:39.743 --> 03:06:41.754
 two groups of the data points. 

03:06:41.755 --> 03:06:46.156
 One is the orange group.  And 
 another is food group.  If you 

03:06:46.157 --> 03:06:49.643
 have a -- if you are a program
 programmer and asked to 

03:06:49.644 --> 03:06:53.848
 classify those data points, 
 what kind of program code would

03:06:55.859 --> 03:06:59.539
 want many N statements or sweet

03:06:59.540 --> 03:07:03.143
 statements to classify the 
 points, each location with the 

03:07:03.144 --> 03:07:05.945
 points by using the condition 
 and the thresholds?  Do you 

03:07:05.946 --> 03:07:08.759
 want to write that?  I don't 
 want to write that kind of code

03:07:08.945 --> 03:07:16.262
 code.  Instead I would be yug 
 maximum likelihood weds for -- 

03:07:16.263 --> 03:07:20.551
 using machine learning to write

03:07:20.552 --> 03:07:24.946
 those.  Let's take a look at 
 this demonstration.

03:07:24.947 --> 03:07:27.760
    This is a demonstration 
 called play ground where you 

03:07:27.761 --> 03:07:34.040
 can just actually run the 
 nerual networks to solve this 

03:07:34.041 --> 03:07:38.944
 problem.  Now you are seeing 
 the computer is trying to find 

03:07:38.945 --> 03:07:42.160
 the optimal combination of the 
 parameters inside nerual 

03:07:42.161 --> 03:07:43.745
 networks to solve this problem.

03:07:43.746 --> 03:07:48.351
 Actually it is not working 
 right.  Let's try again.  

03:07:48.352 --> 03:07:52.953
 Sometimes the machine learning 
 fails.  So you have to try 

03:07:52.954 --> 03:07:55.745
 multiple times.
    Here you go.  The computer 

03:07:55.746 --> 03:08:03.354
 found a way to combine the 
 parameters in away to do the 

03:08:03.355 --> 03:08:06.849
 classification with the double 
 spiral data sets.  This is how 

03:08:06.850 --> 03:08:09.344
 nerual networks work to solve 
 your problem rather than 

03:08:09.345 --> 03:08:13.152
 instructing the computers how 
 to solve the problem by humans.

03:08:16.646 --> 03:08:21.953
    Okay.  Robot is right.  You 
 can apply this nerual network 

03:08:21.954 --> 03:08:27.225
 technologies to solve the much 
 more complex problem such as 

03:08:27.226 --> 03:08:30.747
 recognizing a cat image or 
 experience walking around the 

03:08:30.748 --> 03:08:35.056
 street.  You can do that, but 
 you have to have many more 

03:08:35.057 --> 03:08:37.958
 delays, layers inside the input

03:08:37.959 --> 03:08:43.062
 vector and output vector.  So 
 it takes a long time to retrain

03:08:43.446 --> 03:08:47.647
 retrain.  That is called deep 
 nps or deep learnings, but the 

03:08:47.648 --> 03:08:51.557
 largest problems right now for 
 deep neural networks is the 

03:08:51.558 --> 03:08:54.853
 computation resource.  It 
 usually takes like a few days 

03:08:54.854 --> 03:08:58.750
 or a few weeks sometimes to 
 finish your trainings with deep

03:08:59.955 --> 03:09:04.257
    So that's the reason why 
 Google has been researching on 

03:09:04.258 --> 03:09:08.147
 Distributed Training by using 
 Google Cloud, by using the GPUs

03:09:11.356 --> 03:09:18.462
 training time in order of one-
 one-tenth or one-hundredth.  

03:09:18.463 --> 03:09:21.449
 That's the reason why Google 
 has been so successful on apply

03:09:21.859 --> 03:09:24.853
 applying the deep neural 
 network technologies to the 

03:09:24.854 --> 03:09:28.457
 many consumer services such as 
 the voice recognition with 

03:09:28.458 --> 03:09:32.462
 Android devices or the image 
 recognitions with Google Porter

03:09:32.857 --> 03:09:37.445
 Porters or the running in the 
 Google search services.

03:09:37.446 --> 03:09:40.371
    Now we have over 20 
 production services in Google 

03:09:40.372 --> 03:09:42.866
 that has been using deep learn
 learning technologies 

03:09:42.867 --> 03:09:47.670
 underlying.  And now we have 
 started to externalize the 

03:09:47.671 --> 03:09:51.462
 power of the neural networks 
 running on Google Cloud to 

03:09:51.463 --> 03:09:53.367
 external developers.  The first

03:09:53.368 --> 03:09:59.672
 product is called Cloud Vision 
 API and the second product is 

03:09:59.673 --> 03:10:06.764
 called Cloud speech API.
    What is Cloud zigs API?  

03:10:06.765 --> 03:10:10.576
 Cloud Vision API is an image 
 analysis service that provides 

03:10:10.577 --> 03:10:14.180
 a pretrained model.  You don't 
 have to train your own neural 

03:10:14.181 --> 03:10:17.088
 networks or machine learning 
 model.  Rather than that, you 

03:10:17.089 --> 03:10:22.974
 can just use the rift API, 
 uploading your own images to 

03:10:22.975 --> 03:10:25.767
 the API and you will be 
 receiving the analysis result 

03:10:25.768 --> 03:10:29.787
 in a JSON format in a few 
 seconds.  You don't have to 

03:10:29.788 --> 03:10:31.777
 have any machine learning skill

03:10:31.778 --> 03:10:35.970
 set or experience.
    And it is so inexpensive, it

03:10:41.570 --> 03:10:44.477
 takes no charge to start trying

03:10:44.478 --> 03:10:47.566
 out the API.
    So let's look at another 

03:10:47.567 --> 03:10:51.295
 demonstration for Cloud Vision 
 API.

03:10:54.478 --> 03:10:57.965
  Here I'm launching a 
 demonstration called Cloud 

03:10:57.966 --> 03:11:03.878
 Vision exploreer which we have 
 imported over 80,000 images 

03:11:03.879 --> 03:11:07.575
 from wiki media and applied the

03:11:07.576 --> 03:11:13.270
 analysis already and by using 
 the result of the Vision API we

03:11:16.281 --> 03:11:20.572
 so you are seeing the cluster 
 of the images such as C cluster

03:11:21.079 --> 03:11:24.970
 cluster, snow cluster or area 
 cluster.

03:11:24.971 --> 03:11:28.573
    And if you take a look at 
 the cluster for cat, then you 

03:11:28.574 --> 03:11:31.381
 will be seeing many images that

03:11:31.382 --> 03:11:35.378
 is classifyied as a cat like 
 this.

03:11:35.379 --> 03:11:39.283
    If you put this next to the 
 API, the API will be sending 

03:11:39.284 --> 03:11:44.271
 back the results such as the 
 cat or pet or this must be a 

03:11:44.272 --> 03:11:48.275
 British short hair.  All those 
 results will be returned in 

03:11:48.276 --> 03:11:52.387
 JSON format like this.
    But in this demonstration 

03:11:52.388 --> 03:12:00.069
 you can see them in the UI.
    Also if your image has a 

03:12:00.070 --> 03:12:03.975
 text inside it, then the API 
 can convert the text inside the

03:12:09.682 --> 03:12:14.389
 Three crossing the -- you can 
 get it as a string.  Or if you 

03:12:14.390 --> 03:12:18.970
 have the faces in your images, 
 then the API can detect the 

03:12:18.971 --> 03:12:25.076
 faces and locations of each 
 face and also the emotions of 

03:12:25.077 --> 03:12:28.571
 each face such as joy or sorrow
 sorrow, anger or surprise.  So 

03:12:28.572 --> 03:12:35.577
 you can easily find which face 
 is smiling or not.  If your 

03:12:35.578 --> 03:12:42.974
 image contains a very popular 
 location, then it can provide 

03:12:42.975 --> 03:12:47.687
 the name of the popular 
 location such as city field 

03:12:47.688 --> 03:12:52.788
 stadium in New York City.  You 
 can even put markers on Google 

03:12:52.789 --> 03:12:55.875
 Maps.
    Oh, sorry.

03:12:55.876 --> 03:12:57.876
    (Laughter.)

03:13:00.477 --> 03:13:05.576
 you can even use 
 the product detection feature 

03:13:05.577 --> 03:13:09.074
 so you can easily understand 
 the image has the product 

03:13:09.075 --> 03:13:12.781
 corporate logo.
    So that was the 

03:13:12.782 --> 03:13:15.484
 demonstration of the Vision API
 API.

03:13:15.485 --> 03:13:19.089
    So let's take a look at how 
 you can bring this machine 

03:13:19.090 --> 03:13:28.093
 intelligence into the bot.  
 Cloud Vision bot is based on a 

03:13:28.094 --> 03:13:33.081
 RasPi product called GoPiGo.  
 That is by Dexter Industries.  

03:13:33.082 --> 03:13:37.883
 You can gone and by GoPiGo for 
 around $200.  You might want to

03:13:42.678 --> 03:13:47.778
 We have written a few hundred 
 lines of Python code to capture

03:13:49.790 --> 03:13:54.094
 the image to the API.
    It is really easy to start 

03:13:54.095 --> 03:13:58.978
 getting started with Vision API
 API.  You can go to Cloud.

03:13:58.979 --> 03:14:02.379
 Cloud.Google.comGoogle.com/
Vision to get 

03:14:02.380 --> 03:14:07.086
 started.  You can start the 
 Quickstart tutorial and that 

03:14:07.087 --> 03:14:09.882
 should be finished in about 30 
 minutes.

03:14:09.883 --> 03:14:13.779
    This is a sample of Python 
 code to send your image data to

03:14:17.188 --> 03:14:21.677
 the image binaryies into the 
 base 64 and embed that text 

03:14:21.678 --> 03:14:25.587
 into the content property of 
 the request.  You have to also 

03:14:25.588 --> 03:14:29.288
 specify the types of features 
 you want to detect.  In this 

03:14:29.289 --> 03:14:33.080
 case you specify the label 
 detections of the features so 

03:14:33.081 --> 03:14:36.383
 that you will be receiving the 
 labels as a result of the API 

03:14:36.384 --> 03:14:37.995
 analysis.  And you can make the

03:14:37.996 --> 03:14:40.404
 call to the API.  Then you will

03:14:40.405 --> 03:14:42.393
 be receiving the result JSON in

03:14:42.394 --> 03:14:48.291
 a few seconds so that you can 
 easily dig into the JSON result

03:14:50.491 --> 03:14:53.485
    If you specify face 
 detection, then you will be 

03:14:53.486 --> 03:14:58.398
 receiving the positions of the 
 face and the landmarks such as 

03:14:58.399 --> 03:15:02.395
 the bounding properties where 
 you would have the X and the Y 

03:15:02.396 --> 03:15:06.586
 positions.  And also you will 
 have the joy likelihood 

03:15:06.587 --> 03:15:09.986
 property where you can find 
 each face is smiling or not.  

03:15:09.987 --> 03:15:12.486
 So it is really easy to write a

03:15:12.487 --> 03:15:16.490
 Python code to turn the bot 
 into the direction with the 

03:15:16.491 --> 03:15:21.590
 face and also if it's smiling, 
 you can run the motors of the 

03:15:21.591 --> 03:15:26.288
 bot and follow the person.
    So let's take a look at the 

03:15:26.289 --> 03:15:29.586
 real demonstration of the 
 Vision API bot.

03:15:35.291 --> 03:15:37.291
  So I'm showing 
 the console

03:15:41.192 --> 03:15:48.195
.  This is the user 
 interface Web console for the 

03:15:48.196 --> 03:15:52.183
 bovment it is showing the 
 vision it is taking right now. 

03:15:54.184 --> 03:15:59.286
 not.  Must be working, I hope 
 it's working.

03:15:59.287 --> 03:16:07.990
    Is it working?  If you put 
 the cloud -- it is not saying 

03:16:07.991 --> 03:16:09.991
 anything.

03:16:23.291 --> 03:16:25.795
    It looks like it's not work
 working anymore.

03:16:25.796 --> 03:16:28.890
    Hmm.
    Maybe I can try fixing this 

03:16:28.891 --> 03:16:30.595
 stuff so while doing that maybe

03:16:30.596 --> 03:16:35.491
 I can pass this to him.  Yeah.
    &gt;&gt; GLEN SHIRES:  So you want

03:16:38.890 --> 03:16:42.688
    &gt;&gt; KAZ SATO:  Yeah.
    &gt;&gt; GLEN SHIRES:  Okay.

03:16:42.689 --> 03:16:44.895
    Hi.  So I would also like to

03:16:44.896 --> 03:16:47.301
 talk about the Cloud Speech API

03:16:47.302 --> 03:16:51.300
 which is actually a rather new 
 API.  It was released about a 

03:16:51.301 --> 03:16:54.997
 month and a half ago.  And it 
 joins a number of speech APIs 

03:16:54.998 --> 03:16:58.389
 that Google has had for quite 
 some time, quite a number of 

03:16:58.390 --> 03:17:01.790
 years.  You're probably 
 familiar with the Android 

03:17:01.791 --> 03:17:05.088
 Speech API which allows you to 
 do text to speech and speech to

03:17:07.193 --> 03:17:10.402
 phones, tablets, autos, TV, et 
 cetera.

03:17:10.403 --> 03:17:14.399
    So that is in Java.  That's 
 a Java-based API.

03:17:14.400 --> 03:17:18.206
    There's also the Web Speech 
 API which is in Chrome, which 

03:17:18.207 --> 03:17:23.788
 is a Javascript based API that 
 allows you to do speech.  The 

03:17:23.789 --> 03:17:28.595
 Cloud Speech API is a new API 
 we released that allows you to 

03:17:28.596 --> 03:17:31.501
 put this on any device.  Any 
 device or server you would like

03:17:33.605 --> 03:17:37.192
 it very easy and we support 
 quite a number of languages.  

03:17:37.193 --> 03:17:40.890
 So we made it very easy to 
 integrate this into all sorts 

03:17:40.891 --> 03:17:43.805
 of different clients and server
 servers.

03:17:43.806 --> 03:17:47.890
    The Cloud Speech API is 
 powered by Google's machine 

03:17:47.891 --> 03:17:51.092
 learning.  We have a lot of 
 experience with speech and we 

03:17:51.093 --> 03:17:55.791
 built that all into the API.  
 So it is the same powerful 

03:17:55.792 --> 03:17:57.690
 engine that you have on Android
 Android, you have on Chrome, 

03:17:57.691 --> 03:18:00.699
 you now have available for 
 whatever project you would like

03:18:02.907 --> 03:18:06.799
 pretrained.  There's, you do 
 not have to learn machine learn

03:18:07.001 --> 03:18:10.206
 learning to specifically use it
 it.  You can just get up and 

03:18:10.207 --> 03:18:15.096
 running immediately.  And it 
 supports over 80 languages and 

03:18:15.097 --> 03:18:18.800
 variants of languages.  It's 
 got realtime streaming.  And so

03:18:20.811 --> 03:18:25.598
 is that as I'm talking, the 
 text is actually coming out 

03:18:25.599 --> 03:18:28.699
 while I'm talking.
    What I would like to do is 

03:18:28.700 --> 03:18:30.993
 give you a quick demo of that.

03:18:36.208 --> 03:18:38.611
    I'm sure you're familiar 
 with this page which has speech

03:18:43.197 --> 03:18:45.999
 Speech API.  What I'm doing 
 here is pulling up a 

03:18:46.000 --> 03:18:52.600
 demonstration page for the 
 Chrome Web Speech API.  And 

03:18:52.601 --> 03:18:55.600
 make it a little bit bigger 
 here.  So what I'm going to do,

03:18:58.296 --> 03:19:00.812
 notice that the words are 
 coming out.  First they will be

03:19:02.510 --> 03:19:04.802
 quite sure.  When it's very 
 cath 

03:19:04.803 --> 03:19:06.299
 confident of the words it turns

03:19:06.300 --> 03:19:08.697
 them to black.
    So you can see as I'm 

03:19:08.698 --> 03:19:11.601
 speaking the words are coming 
 out and appearing on the screen

03:19:13.506 --> 03:19:17.405
 screen.  They turn black after 
 it is very confident of what I 

03:19:17.406 --> 03:19:19.416
 said.

03:19:23.706 --> 03:19:27.407
  Where is the 
 presentation?

03:19:27.408 --> 03:19:32.509
    Okay.  So that's an example 
 of the realtime streaming that

03:19:32.534 --> 03:19:34.099
 that's built in.  And we have a

03:19:34.100 --> 03:19:38.104
 limited preview right now for 
 which you can sign up and join 

03:19:38.105 --> 03:19:40.511
 and start using the Cloud 
 Speech API.

03:19:44.500 --> 03:19:46.502
    Cloud Speech API is actually

03:19:46.503 --> 03:19:51.100
 two different APIs.  At least 
 two versions of the same API is

03:19:52.707 --> 03:19:58.723
 it.  There's a rift API that's 
 a simple way to use it.  You 

03:19:58.724 --> 03:20:03.304
 can start.  It's as east easy 
as 

03:20:03.305 --> 03:20:10.211
 writing a curl commands in JSON
 JSON.  Let me show you the rest

03:20:12.005 --> 03:20:16.012
 everything you need to know to 
 do the rest API in one slide.  

03:20:16.013 --> 03:20:19.913
 On the left there's a JSON qub 
 and you can formulate that and 

03:20:19.914 --> 03:20:22.003
 make it more complicated if you

03:20:22.004 --> 03:20:26.111
 want, add languages, add 
 different types of ways you 

03:20:26.112 --> 03:20:30.214
 want to process it.  You can 
 even add context, a new thing 

03:20:30.215 --> 03:20:35.314
 we released.  You can add new 
 words to the vocabulary, new 

03:20:35.315 --> 03:20:38.915
 phrases.  That's coming out 
 this week.  You can make it as 

03:20:38.916 --> 03:20:41.913
 complicated as you want.  The 
 simpleest request would be 

03:20:41.914 --> 03:20:43.504
exact
 exactly that.  There's a couple

03:20:45.910 --> 03:20:49.309
 where you insert your audio 
 file or your audio data.

03:20:49.310 --> 03:20:53.520
    If you look at the bottom 
 there's a curl command.  Kind 

03:20:53.521 --> 03:20:57.308
 of long but basically all post
 posting the content type and 

03:20:57.309 --> 03:21:01.710
 posting to a URL.  So it's 
 taking the JSON post to the URL

03:21:01.916 --> 03:21:03.503
 URL.  What you get back is that

03:21:03.504 --> 03:21:05.106
 response that's on your right. 

03:21:05.107 --> 03:21:08.604
 Again, this is the simpleest 
 type of response.  If all you 

03:21:08.605 --> 03:21:12.313
 want is one alternative, you 
 don't want to see multiple 

03:21:12.314 --> 03:21:15.516
 alternatives and interim result
 results, you'll get something 

03:21:15.517 --> 03:21:17.517
 that looks just like this.

03:21:20.524 --> 03:21:23.814
    So like I said, there's 
 actually two types of APIs.  

03:21:23.815 --> 03:21:28.209
 The other one is remote 
 procedure call API.  And what 

03:21:28.210 --> 03:21:31.908
 that means is you can do 
 everything by simply calling 

03:21:31.909 --> 03:21:37.719
 methods in your favorite 
 language, Java, C++ or the 

03:21:37.720 --> 03:21:40.007
 other languages that are 
 supported.  You don't have to 

03:21:40.008 --> 03:21:44.110
 worry about the network.  And 
 it also supports the bi

03:21:44.111 --> 03:21:46.416
 bidirectional streaming I 
 mentioned.  As you're talking 

03:21:46.417 --> 03:21:48.417
 you're getting the data back.

03:21:52.910 --> 03:21:54.714
    So we support quite a number

03:21:54.715 --> 03:21:59.106
 of languages for the remote 
 procedure call.  And this is 

03:21:59.107 --> 03:22:02.316
 actually open source.  It's 
 free and open source.  If there

03:22:02.521 --> 03:22:03.918
 there's a language that doesn't

03:22:03.919 --> 03:22:06.622
 appear here, you can certainly 
 build the source for that 

03:22:06.623 --> 03:22:08.411
 language and actually use it on

03:22:08.412 --> 03:22:14.219
 any language.
    Also it uses HTTPS slash two

03:22:14.224 --> 03:22:17.120
 two, HTTP 2 secure which allows

03:22:17.121 --> 03:22:20.210
 you to have some robust bi
 bidirectional streaming.

03:22:23.920 --> 03:22:28.620
    So what I would like to do 
 is demonstrate this.

03:22:40.111 --> 03:22:42.331
    Go straight.

03:22:46.824 --> 03:22:48.824
    "go straight"

03:22:59.721 --> 03:23:00.718
.
    Stand still.  Thank you

03:23:00.719 --> 03:23:02.719
    (Laughter.)

03:23:09.221 --> 03:23:11.221
    &gt;&gt; GLEN SHIRES:  Go to sleep
 sleep.

03:23:20.921 --> 03:23:28.313
    Start that over and we'll 
 see.  Let me move forward.  So 

03:23:28.314 --> 03:23:32.621
 let me show you while we're 
 waiting for that to reboot 

03:23:32.622 --> 03:23:39.020
 exactly what we are sending 
 with the RPC calls.  We are 

03:23:39.021 --> 03:23:43.525
 sending initial request.  This 
 is similar to the JSON that I 

03:23:43.526 --> 03:23:45.230
 showed in the last slide but in

03:23:45.231 --> 03:23:50.332
 here we are actually using Prot
 Proto buffers to send this.  It

03:23:50.355 --> 03:23:53.727
 It's a very compact format.  In

03:23:53.728 --> 03:23:57.820
 other words you're not sending 
 extra bytes over the wire the 

03:23:57.821 --> 03:24:01.920
 way you are with JSON.  You 
 send your request.  You capture

03:24:05.214 --> 03:24:09.920
 is on the thread.  We are read
 reading a buffer full of audio 

03:24:09.921 --> 03:24:12.628
 and sending that buffer of 
 audio.

03:24:12.629 --> 03:24:17.923
    You will see what we are 
 calling here is on next.  This 

03:24:17.924 --> 03:24:21.218
 is request server on next is 
 code that is automatically 

03:24:21.219 --> 03:24:23.929
 supplied and you have ten 
 languages, so that you can keep

03:24:26.317 --> 03:24:28.921
    Finally you've got the 
 response which you can be 

03:24:28.922 --> 03:24:32.323
 running on a different thread 
 because you are sending audio 

03:24:32.324 --> 03:24:35.634
 and receiving data at the same 
 time.  Again there's an on next

03:24:37.424 --> 03:24:41.218
 automatically for you, which 
 provides the data.  In this 

03:24:41.219 --> 03:24:43.825
 case we are printing out the 
 results of what we are 

03:24:43.826 --> 03:24:45.826
 receiving.

03:24:52.727 --> 03:24:54.936
    Go forward.

03:25:00.626 --> 03:25:10.333
  Spin left.  
 Spin right.  Go back backwards.

03:25:10.528 --> 03:25:13.233
  Do 
 a dance.

03:25:13.234 --> 03:25:15.234
    (Laughter.)

03:25:16.537 --> 03:25:19.018
    &gt;&gt; GLEN SHIRES:  Go to sleep
 sleep.

03:25:19.019 --> 03:25:21.322
    Play dead.  I like that one 
 too.

03:25:21.323 --> 03:25:24.025
    (Applause.)
    &gt;&gt; GLEN SHIRES:  There we 

03:25:24.026 --> 03:25:30.531
 are.  So one thing I wanted to 
 point out is, it is responding 

03:25:30.532 --> 03:25:33.635
 very quickly.  That's because 
 it's streaming the speech as 

03:25:33.636 --> 03:25:37.031
 I'm speaking.  It is not going 
 to capture all the speech and 

03:25:37.032 --> 03:25:40.734
 then wait and send a chunk of 
 data up.  As I speak, it's 

03:25:40.735 --> 03:25:45.019
 going bidirectional.  That's 
 why I can do it so quickly.

03:25:45.020 --> 03:25:49.230
    My clicker is here.  So what

03:25:49.231 --> 03:25:54.633
 I would like to do is, this is 
 easier to show than to talk 

03:25:54.634 --> 03:26:00.125
 about.  Let me show this.  
 These are experimental features

03:26:00.323 --> 03:26:03.732
 features, I want to say.  What 
 I showed you to date is what is

03:26:06.240 --> 03:26:09.825
 Cloud Speech API.  These are 
 experimental features that will

03:26:16.536 --> 03:26:18.536
    What time is it in Tokyo?

03:26:21.329 --> 03:26:24.133
    &gt;&gt; The time in Tokyo, Japan,

03:26:24.134 --> 03:26:26.134
 is 9:29 a.m.)

03:26:30.623 --> 03:26:33.430
    &gt;&gt; GLEN SHIRES:  How do you 
 say when is the next train in 

03:26:33.431 --> 03:26:39.728
 French?
    &gt;&gt; (Digital voice:  French 

03:26:39.729 --> 03:26:41.729
 phrase.)
    (Applause.)

03:26:50.026 --> 03:26:51.335
    &gt;&gt; GLEN SHIRES:  Turn on the

03:26:51.336 --> 03:26:58.931
 table lamp.
    &gt;&gt; I'm not sure how to help 

03:26:58.932 --> 03:27:01.428
 with turn on the table lamp.
    &gt;&gt; GLEN SHIRES:  There we go

03:27:01.632 --> 03:27:05.125
 go.
    Go to sleep.

03:27:05.126 --> 03:27:08.230
    So as you can see, I've 
 demonstrated two different 

03:27:08.231 --> 03:27:10.323
 things in that demo.  The first

03:27:10.324 --> 03:27:13.627
 one is spoken answers.  What 
 that's doing is as I'm asking 

03:27:13.628 --> 03:27:18.033
 questions it's providing answer
 answers.  And the second one is

03:27:19.634 --> 03:27:24.536
 integrated with if this, then 
 that.  Which is a way that you 

03:27:24.537 --> 03:27:26.127
 can integrate with all sorts of

03:27:26.128 --> 03:27:29.044
 different devices.  In this 
 case I've integrated with a 

03:27:29.045 --> 03:27:33.939
 light module controller.  So 
 that you can actually actually 

03:27:33.940 --> 03:27:38.530
set up 
 your own triggers to do this.  

03:27:38.531 --> 03:27:40.428
 And this is exactly what I did.

03:27:40.429 --> 03:27:42.629
 There is a Web page that I went

03:27:42.630 --> 03:27:44.734
 to and I typeed in what I want
ed 

03:27:44.735 --> 03:27:49.039
 to say as triggers, voice 
 triggers.

03:27:49.040 --> 03:27:53.037
    Various ways I want to say 
 it.  And what is going to 

03:27:53.038 --> 03:27:58.046
 respond when I just say that?  
 And what it does is it goes out

03:28:00.032 --> 03:28:03.941
 speak that phrase or one of 
 those phrases, it goes out and 

03:28:03.942 --> 03:28:09.538
 triggers whatever "if" action 
 you would like to trigger.

03:28:09.539 --> 03:28:11.539
    (Applause.)

03:28:17.140 --> 03:28:18.329
    &gt;&gt; GLEN SHIRES:  So you want

03:28:18.330 --> 03:28:23.235
 to go back to yours?
    &gt;&gt; KAZ SATO:  Yes.  I am not

03:28:25.842 --> 03:28:31.929
 Maybe I can show the console.  
 Let me try again with the bot. 

03:28:38.929 --> 03:28:41.534
    Yeah, it looks like it's 
 working.

03:28:46.230 --> 03:28:54.037
    &gt;&gt; DIGITAL VOICE

03:28:56.354 --> 03:29:00.034
:  News, 
 next slide

03:29:00.035 --> 03:29:02.035
    (Laughter.)

03:29:03.632 --> 03:29:10.230
    &gt;&gt; DIGITAL VOICE:  How are 
 you?

03:29:10.231 --> 03:29:14.938
    &gt;&gt; KAZ SATO:  I'm fine.
    &gt;&gt; Digital voice:  It 

03:29:14.939 --> 03:29:20.038
 startle -- it is goggles.  
 Hello.

03:29:20.039 --> 03:29:28.151
    &gt;&gt; KAZ SATO:  Not goggles.
    &gt;&gt; It's tie, it's ...

03:29:28.152 --> 03:29:32.347
    &gt;&gt; KAZ SATO:  How about this
 this?  If you keep smileing, it

03:29:35.135 --> 03:29:45.043
    What is this?  Can you see 
 this?  Oh.  Ahh!  

03:29:45.044 --> 03:29:47.044
    (Laughter.)

03:29:50.145 --> 03:29:55.445
    (Applause.)
    (Cheering and applause.)

03:29:55.446 --> 03:29:56.136
    &gt;&gt; KAZ SATO:  Thank you.  So

03:29:56.137 --> 03:30:02.346
 yeah, it works finally.
    &gt;&gt; Digital voice ...

03:30:02.347 --> 03:30:04.140
    &gt;&gt; KAZ SATO:  So that was 
 our demonstration.

03:30:04.141 --> 03:30:06.141
    (Applause.)

03:30:10.236 --> 03:30:11.753
    &gt;&gt; GLEN SHIRES:  Want to go 
 back?

03:30:11.754 --> 03:30:13.754
    &gt;&gt; KAZ SATO:  Yeah.

03:30:15.753 --> 03:30:16.336
    &gt;&gt; GLEN SHIRES:  One thing I

03:30:16.337 --> 03:30:20.739
 failed to mention with the if 
 triggers, you can actually add 

03:30:20.740 --> 03:30:24.642
 parameters to those triggers.  
 You can add a number or string 

03:30:24.643 --> 03:30:29.441
 parameter.  You can, for 
 example, turn a robot to turn 

03:30:29.442 --> 03:30:33.236
 left or steps or degrees.  You 
 can make the triggers actually 

03:30:33.237 --> 03:30:37.241
 quite interesting.
    So we have a number of 

03:30:37.242 --> 03:30:41.753
 resources that you should go 
 out and take a look at.  The 

03:30:41.754 --> 03:30:48.348
 Cloud vision API and the Cloud 
 Speech API.  They are ready for

03:30:52.544 --> 03:30:54.244
 have a number of other sessions

03:30:54.245 --> 03:30:59.843
 that are coming up that you 
 might be interested in.  We 

03:30:59.844 --> 03:31:02.952
 have Codelabs that talk about 
 machine learning.  There's 

03:31:02.953 --> 03:31:05.153
 several machine learning 
 presentations coming up.  There

03:31:05.447 --> 03:31:08.441
 There's Cloud office hours, if 
 you want to learn more about 

03:31:08.442 --> 03:31:09.953
 Cloud and integrateing with the

03:31:09.954 --> 03:31:13.745
 Cloud APIs.  We have office 
 hours throughout this next two 

03:31:13.746 --> 03:31:17.254
 days.  And there's the Sandbox.

03:31:17.255 --> 03:31:19.444
 So thank you very much.
    &gt;&gt; KAZ SATO:  Thank you.

03:31:19.445 --> 03:31:21.445
    (Applause.)

03:31:30.258 --> 03:31:32.258
    (Session concluded.)

03:31:59.579 --> 03:32:02.645
           ***
    This text is being provided 

03:31:59.579 --> 03:32:03.445
 in a rough draft format.  
 Communication Access Realtime 

03:31:59.579 --> 03:32:03.312
 Translation (CART) is provided 
 in order to facilitate 

03:31:59.579 --> 03:32:01.712
 communication accessibility and

03:31:59.579 --> 03:32:03.445
 may not be a totally verbatim 
 record of the proceedings.

03:31:59.579 --> 03:32:01.579
           *** 

03:41:53.324 --> 03:41:56.243
    (Standing by for the

03:41:59.565 --> 03:41:59.971
 session 
 Make Shinier, Faster Mobile 

03:41:59.972 --> 03:42:01.972
 Games with Vulkan.)

03:57:18.299 --> 03:57:20.281
    (Please stand by for the 
 session Make Shinier, Faster 

03:57:20.282 --> 03:57:22.282
 Mobile Games with Vulkan to 
 begin.)

03:57:46.905 --> 03:57:48.905
    ATSC

03:58:06.288 --> 03:58:08.288
    (Music playing.)

03:59:47.291 --> 03:59:49.306
    &gt;&gt; HAI NGUYEN:  Sorry for 
 the late start.  There was some

03:59:52.205 --> 03:59:55.502
 Chrome cast, but thanks for 
 coming out to listen to me talk

03:59:57.503 --> 04:00:00.098
 day of Google I/O and hopefully

04:00:00.099 --> 04:00:03.097
 the excitement hasn't died down
 down.  It's the last talk of 

04:00:03.098 --> 04:00:05.298
 the day.  People may be anxious

04:00:05.299 --> 04:00:09.007
 to get out of here and start 
 partying.  We are here to talk 

04:00:09.008 --> 04:00:10.503
 about Vulkan.  It's exciting on

04:00:10.504 --> 04:00:15.006
 my own.  One of my favorite 
 topics to talk about.  I have 

04:00:15.007 --> 04:00:18.308
 been ask to tone down the 
 Vulkan talk a little bit 

04:00:18.309 --> 04:00:22.010
 recently.  It may be good or 
 bad for you.  Let's find out.  

04:00:22.011 --> 04:00:25.201
 Go ahead and jump in.
    Vulkan, lots of rules and no

04:00:28.424 --> 04:00:31.797
 little bit in all of my Vulkan 
 talks.  I feel it captures the 

04:00:31.798 --> 04:00:34.699
 general spirit of how people 
 feel about Vulkan right now.  

04:00:34.700 --> 04:00:39.306
 It's a bit of a joke because 
 Vulkan does bring a lot of good

04:00:40.805 --> 04:00:44.100
 have a lot of complications 
 that hopefully this talk will 

04:00:44.101 --> 04:00:49.509
 help address some of it.
    So a little bit of 

04:00:49.510 --> 04:00:52.893
 introduction before we continue
 continue.  As you can probably 

04:00:52.894 --> 04:00:54.496
 see from the program my name is

04:00:54.497 --> 04:01:00.105
 Hai.  I'm a technology lead on 
 Google's R copying code team.  

04:01:00.106 --> 04:01:02.705
 My role on the team is to 
 explore different technologies 

04:01:02.706 --> 04:01:04.504
 to find out how we can leverage

04:01:04.505 --> 04:01:07.600
 them for creative work.  Some 
 of the things that I explore 

04:01:07.601 --> 04:01:09.403
 are things like Vulkan.  How do

04:01:09.404 --> 04:01:12.699
 you leverage new graphic APIs 
 for use in applications?

04:01:12.700 --> 04:01:17.000
    And I started working with 
 Vulkan about last December, a 

04:01:17.001 --> 04:01:25.409
 few months before the, couple 
 months before the   2016 launch

04:01:26.107 --> 04:01:31.908
 launch.  I subsequently ported 
 all the demos to Vulkan.  

04:01:31.909 --> 04:01:34.410
 Cinder is a C++ creative coding

04:01:34.411 --> 04:01:38.302
 framework that runs on Android,

04:01:38.303 --> 04:01:42.407
 Windows, Linux, open source 
 under the simplifyied license. 

04:01:48.307 --> 04:01:52.102
 good will and OpenGL ES on 
 mobile.  That's what it is now.

04:01:54.402 --> 04:01:56.310
 Probably as Vulkan becomes more

04:01:56.311 --> 04:02:00.707
 possible with the exception of
 ofosis and OSS of course.  It 

04:02:00.708 --> 04:02:03.707
 scales from anything from 
 mobile to desktop to very large

04:02:05.507 --> 04:02:08.710
 see in Times Square.  Cinder 
 has been used recently in the 

04:02:08.711 --> 04:02:12.607
 Cloud to generate content.  
 Vulkan support became available

04:02:13.906 --> 04:02:17.129
 earlier on Vulkan's launch date
 date.  Since Cinder is a coding

04:02:20.114 --> 04:02:24.213
 used in many cases, the 
 implementation is very much 

04:02:24.214 --> 04:02:27.112
 ongoing.
    So what this talk is not 

04:02:27.113 --> 04:02:30.514
 about, this is an advanced 
 level talk.  It's not an 

04:02:30.515 --> 04:02:33.516
 introduction to Vulkan.  It is 
 not a tutorial on Vulkan.  It 

04:02:33.517 --> 04:02:37.102
 is not an in depth examination 
 of Vulkan.  If you likeed a 

04:02:37.103 --> 04:02:38.801
real
 really good read, quick read on

04:02:42.203 --> 04:02:46.015
 Vulkan 30 minutes document.  
 And if you need to see tutorial

04:02:46.417 --> 04:02:50.202
 tutorials on Vulkan, we have 
 some tutorials available on the

04:02:53.202 --> 04:02:57.002
 sit here and do in depth on 
 Vulkan, it would take about a 

04:02:57.003 --> 04:03:00.903
 month.  Feel free if you have 
 questions about the topics, 

04:03:00.904 --> 04:03:04.414
 stop me afterwards or find me 
 afterwards and I'd love to talk

04:03:05.713 --> 04:03:07.802
    So what this talk is about. 

04:03:07.803 --> 04:03:12.712
 This talk, the Vulkanist talk 
 is how to get up and going on 

04:03:12.713 --> 04:03:14.801
 Vulkan in a kind of large way. 

04:03:14.802 --> 04:03:19.202
 Not just like writing sample 
 code, but getting something to 

04:03:19.203 --> 04:03:21.427
 production.  So it assumes that

04:03:21.428 --> 04:03:26.650
 you know about OpenGL ES.  And 
 it assumes that you know a 

04:03:26.651 --> 04:03:29.112
 little bit about Vulkan or some

04:03:29.113 --> 04:03:34.006
 other explicit graphics API 
 like metal or direct X12.  

04:03:34.007 --> 04:03:37.007
 Since Vulkan is definitely new 
 there are sharp edges in Vulkan

04:03:37.211 --> 04:03:39.318
 Vulkan.  I try to point out the

04:03:39.319 --> 04:03:43.303
 gotchas and why it's important 
 to pay attention to device 

04:03:43.304 --> 04:03:46.506
 limits and the difference 
 between mobile -- sorry, 

04:03:46.507 --> 04:03:49.521
 desktop Vulkan and mobile 
 Vulkan.  There's a short 

04:03:49.522 --> 04:03:51.905
 session on the things to 
 consider if you are looking for

04:03:54.324 --> 04:03:59.111
    Again, these are kind of 
 heavy topics.  If you find me 

04:03:59.112 --> 04:04:02.107
 saying something that is weird 
 and it's confusing, please find

04:04:04.417 --> 04:04:06.723
 than happy to clarify them.  So

04:04:06.724 --> 04:04:08.708
 to establish a baseline between

04:04:08.709 --> 04:04:13.117
 OpenGL ES and Vulkan, this 
 question gets asked more than 

04:04:13.118 --> 04:04:15.908
 any other question when it 
 comes to Vulkan.  Is Vulkan 

04:04:15.909 --> 04:04:21.813
 faster than OpenGL/OpenGL ES?  
 The answer is yes but not from 

04:04:21.814 --> 04:04:23.618
 a direct port.  Vulkan is new. 

04:04:23.619 --> 04:04:26.112
 If you want to leverage all the

04:04:26.113 --> 04:04:28.111
 benefits of Vulkan, you have to

04:04:28.112 --> 04:04:31.414
 change a lot of your code if 
 not some of your code and 

04:04:31.415 --> 04:04:35.207
 definitely some of your 
 thinking.  Vulkan on mobile 

04:04:35.208 --> 04:04:39.018
 feature set is comparable to 
 that of OpenGL ES 3.1.  However

04:04:39.214 --> 04:04:42.822
 However, it does include 
 compute geometry and shared 

04:04:42.823 --> 04:04:47.422
 support.  It is explicit API 
 that is directly, has direct 

04:04:47.423 --> 04:04:50.719
 control of almost every object 
 in the rendering pipeline.  The

04:04:52.515 --> 04:04:57.222
 for memory management.  There 
 are some new concepts that do 

04:04:57.223 --> 04:05:00.510
 come with API.  There are also 
 things that have similar names,

04:05:02.211 --> 04:05:06.911
 differently.
    So one of the amazing 

04:05:06.912 --> 04:05:10.513
 features that Vulkan supports 
 is validation layers.  This is 

04:05:10.514 --> 04:05:13.910
 the first time you've heard of 
 validation layer, essentially 

04:05:13.911 --> 04:05:20.623
 they are a debug tool that 
 allows -- that lets you figure 

04:05:20.624 --> 04:05:24.611
 out what is happening in the 
 API.  It is a very dramatic 

04:05:24.612 --> 04:05:28.625
 departure from GL get error.  
 The general rule of thumb for 

04:05:28.626 --> 04:05:31.916
 validation layers is to turn 
 them on at the beginning of the

04:05:33.614 --> 04:05:37.217
 you ship.  They are cross 
 platform which means the same 

04:05:37.218 --> 04:05:40.525
 code gets used on Android, 
 Linux and Windows.  One of the 

04:05:40.526 --> 04:05:43.929
 cool aspects of the validation 
 is this:  It's a function call 

04:05:43.930 --> 04:05:46.015
 back that you can supply to the

04:05:46.016 --> 04:05:49.029
 validation layers that gets 
 triggered every time the 

04:05:49.030 --> 04:05:52.024
 validation message gets trigger
 triggered.  This is what the 

04:05:52.025 --> 04:05:54.720
 call signature looks like.  
 This is what a sample body 

04:05:54.721 --> 04:05:57.922
 looks like.  As you can see, 
 since it is, you can break it 

04:05:57.923 --> 04:06:00.918
 down into whatever granularity 
 you need based on the 

04:06:00.919 --> 04:06:03.914
 validation criteria.  And if 
 you are on a platform where you

04:06:07.122 --> 04:06:10.024
 you can definitely set a break 
 point on any of these and look 

04:06:10.025 --> 04:06:14.517
 in the call stack to see where 
 the validation was triggered.

04:06:14.518 --> 04:06:19.215
    All right.  So let's go deep
 deeper with Vulkan.  I am some 

04:06:19.216 --> 04:06:22.223
 friendly reminders before we 
 start.  If you were beginning 

04:06:22.224 --> 04:06:25.515
 to port from OpenGL ES to 
 Vulkan, it's good to keep these

04:06:28.124 --> 04:06:30.413
 very tariff wral.  The first is

04:06:30.414 --> 04:06:35.623
 the coordinate system.  Vulkan 
 coordinate system is open right

04:06:39.118 --> 04:06:42.113
 guard, everything I rendered 
 was upside down and backwards 

04:06:42.114 --> 04:06:46.127
 and I thought I was doing 
 something wrong.  I went and 

04:06:46.128 --> 04:06:47.717
 stareed somebody down and asked

04:06:47.718 --> 04:06:51.715
 why is it upper left.  There 
 wasn't a clear answer but it 

04:06:51.716 --> 04:06:56.823
 just is.  Memory management 
 basis.  In OpenGL you didn't 

04:06:56.824 --> 04:07:02.517
 have to handle a lot offal owe 
 cangss yourself in any.  In 

04:07:02.518 --> 04:07:05.624
 Vulkan you have to handle 
 allocations yourself.  Buffers,

04:07:07.420 --> 04:07:11.231
 pools are handled for you, but 
 script pools are not.  You 

04:07:11.232 --> 04:07:16.917
 still have to point out to 
 Vulkan what you need.  So the 

04:07:16.918 --> 04:07:21.317
 first Vulkan topic.  Command 
 buffers.  So command buffers 

04:07:21.318 --> 04:07:24.326
 are one of those things in 
 OpenGL that you hear a lot 

04:07:24.327 --> 04:07:27.524
 about but you don't have 
 explicit control over.  In 

04:07:27.525 --> 04:07:30.120
 Vulkan that changes a lot.  
 They are one of the primary 

04:07:30.121 --> 04:07:32.928
 things that you use to get 
 pretty much anything done in 

04:07:32.929 --> 04:07:36.120
 Vulkan.  Command buffer has to 
 be allocated before they are 

04:07:36.121 --> 04:07:40.021
 used.  Command buffers are 
 allocated from command pools.  

04:07:40.022 --> 04:07:43.132
 They have to to, the command 
 pools themselves must belong to

04:07:49.736 --> 04:07:55.920
 be submitted to the same cue 
 family as the command pool.  

04:07:55.921 --> 04:07:59.838
 And also while you're 
 submitting, you want to 

04:07:59.839 --> 04:08:03.020
 minimize the number of command 
 buffers per frame.  When you 

04:08:03.021 --> 04:08:05.033
 hear this, don't just use one. 

04:08:05.034 --> 04:08:10.021
 If you do that, you'll end up 
 starving the GPU.  I learned by

04:08:12.821 --> 04:08:15.536
 difficult to try to fit 
 everything into a single 

04:08:15.537 --> 04:08:19.822
 command buffer.  You do a lot 
 of code gymnastic.  In order to

04:08:24.736 --> 04:08:28.736
 buffers, but min minimize them 
as 

04:08:28.737 --> 04:08:31.033
 much as possible.
    Sharp edges on command 

04:08:31.034 --> 04:08:33.324
 buffers.  One of the terms that

04:08:33.325 --> 04:08:37.225
 is tossed around a lot with 
 Vulkan is multithreading.  

04:08:37.226 --> 04:08:41.722
 There is a portion of the API 
 that is implicitly thread safe 

04:08:41.723 --> 04:08:45.138
 but there are parts that are 
 not implicitly thread safe.  

04:08:45.139 --> 04:08:48.134
 You can't record to the same 
 command buffer from multiple 

04:08:48.135 --> 04:08:52.935
 threads but it's fine for you 
 to record to multiple command 

04:08:52.936 --> 04:08:58.524
 buffers on threads.  You can 
 take all those command buffers 

04:08:58.525 --> 04:09:02.033
 and kick them over to a single 
 submission thread and that's 

04:09:02.034 --> 04:09:05.233
 perfectly fine.  If you are 
 going to do recording from 

04:09:05.234 --> 04:09:07.530
 multiple threads, make sure 
 that each one of the threads 

04:09:07.531 --> 04:09:09.531
 has access to its own command 
 pool.

04:09:12.939 --> 04:09:16.226
    And directly related to 
 command buffers is cues.  Queue

04:09:16.523 --> 04:09:20.629
 Queues is again what you hear 
 about in OpenGL but you don't 

04:09:20.630 --> 04:09:23.442
 quite have control of.  In 
 Vulkan again it's very 

04:09:23.443 --> 04:09:27.930
 different.  It's important to 
 understand queues from their 

04:09:27.931 --> 04:09:32.427
 mode of creation.  Queues, 
 implicitly have to belong to a 

04:09:32.428 --> 04:09:35.523
 queue family.  You know which 
 queue family they belong to 

04:09:35.524 --> 04:09:38.632
 through the queue family index.

04:09:38.633 --> 04:09:42.636
 There are a limited number of 
 queues.  You can find out how 

04:09:42.637 --> 04:09:44.336
 many they support by looking at

04:09:44.337 --> 04:09:48.434
 queue family properties queue 
 counts.  We'll get to the queue

04:09:50.333 --> 04:09:52.438
 second.
    If you find yourself in a 

04:09:52.439 --> 04:09:54.636
 configuration where you want to

04:09:54.637 --> 04:09:59.338
 do both graphics and compute, 
 you want to do the queue 

04:09:59.339 --> 04:10:01.939
 combine queues over support 
 operations.  If you are looking

04:10:04.026 --> 04:10:07.244
 look for a queue family that 
 supports both.  The primary 

04:10:07.245 --> 04:10:11.933
 reason, at the beginning or 
 just at the initial port, it 

04:10:11.934 --> 04:10:14.527
 makes things easier to 
 coordinate.  If you use 

04:10:14.528 --> 04:10:18.534
 multiple queues, you will have 
 to do synchronization.  That 

04:10:18.535 --> 04:10:21.641
 can be a little bit of a 
 headache.

04:10:21.642 --> 04:10:24.636
    When you are working with 
 queues, it is important that 

04:10:24.637 --> 04:10:30.132
 you if need to order the queue 
 operations, do it through 

04:10:30.133 --> 04:10:37.040
 synchronization primitives and 
 avoid QueueWaitIdle in 

04:10:37.041 --> 04:10:40.638
 performance critical code.  
 There are good legitimate 

04:10:40.639 --> 04:10:44.527
 reasons for using QueueWaitIdle
 QueueWaitIdle.  Through 

04:10:44.528 --> 04:10:45.669
 personal experience it caused a

04:10:45.670 --> 04:10:50.142
 lot of weird bubbles in the 
 pipeline and installs that I 

04:10:50.143 --> 04:10:52.143
 didn't expect.

04:10:54.039 --> 04:10:55.832
    Some sharp edges on queues. 

04:10:55.833 --> 04:11:00.532
 Not all queues are universal.  
 The queue family dictates what 

04:11:00.533 --> 04:11:05.129
 each queue.  Android Notes on 
 queue, on Android there is at 

04:11:05.130 --> 04:11:08.834
 least one queue to supports 
 both graphics and computes.  

04:11:08.835 --> 04:11:13.008
 You can present from any queue 
 on Android.  On desktop you 

04:11:13.009 --> 04:11:16.230
 have to go looking around to 
 see which queue supports 

04:11:16.231 --> 04:11:18.035
 presentation or not.  This goes

04:11:18.036 --> 04:11:20.729
 without saying but worth saying
 saying, you have to keep kind 

04:11:20.730 --> 04:11:25.987
 of precise counts on queues.  
 There are devices that only 

04:11:25.988 --> 04:11:30.547
 support one queue.  So if a 
 device supports one queue, it 

04:11:30.548 --> 04:11:33.834
 only implicitly has one queue 
 family.  Check the properties 

04:11:33.835 --> 04:11:36.830
 before you create the cues.  If

04:11:36.831 --> 04:11:41.135
 you create queues that only 
 supports one queue, you either 

04:11:41.136 --> 04:11:44.431
 get a hang or crash.
    Pipelines or pipeline state 

04:11:44.432 --> 04:11:48.331
 objects as some people call 
 them.  Essentially these are 

04:11:48.332 --> 04:11:50.936
 data structures that control, 
 that has properties that 

04:11:50.937 --> 04:11:54.446
 control pretty much everything 
 that happens in the rendering 

04:11:54.447 --> 04:12:00.032
 process.  And they are a fixed 
 function.  So that means that 

04:12:00.033 --> 04:12:02.336
 once you compile them you can't

04:12:02.337 --> 04:12:04.836
 really change any of the 
 properties.  There's a caveat 

04:12:04.837 --> 04:12:08.038
 to that.  What are called 
 dynamic properties, the dike 

04:12:08.039 --> 04:12:09.843
 properties can be readjusted or

04:12:09.844 --> 04:12:13.632
 can be adjusted via command 
 line -- sorry, command buffer 

04:12:13.633 --> 04:12:16.640
 operations.  These include 
 things like view ports, 

04:12:16.641 --> 04:12:20.838
 scissors or blend constants.  
 How many pipelines can you have

04:12:21.136 --> 04:12:24.399
 have?  If you find yourself 
 having hundreds or thousands of

04:12:27.000 --> 04:12:29.192
 fine, a typical application may

04:12:29.193 --> 04:12:31.790
 have that many.  The reason if 
 you think about it for a moment

04:12:32.012 --> 04:12:33.993
 moment, the different 
 combinations of what you have 

04:12:33.994 --> 04:12:39.488
 in your rendering states can 
 easily create hundreds of 

04:12:39.489 --> 04:12:42.314
 permutations.  If you are 
 getting to the point where it's

04:12:44.404 --> 04:12:47.712
 figure out if you're having too

04:12:47.713 --> 04:12:54.305
 many variations, too many or 
 too much granularity in your 

04:12:54.306 --> 04:12:56.804
 variations.
    You can cache pipelines.  If

04:12:58.904 --> 04:13:04.099
 it helps speed up the pipeline 
 creation.  If you, you can also

04:13:09.494 --> 04:13:13.304
 and you can do this by looking 
 at your pipeline properties and

04:13:15.599 --> 04:13:17.798
 select the pipeline.
    Excuse me.

04:13:27.392 --> 04:13:30.102
    All right.
    So discriminate sets.  

04:13:30.103 --> 04:13:35.717
 DescriptorSets are one of my 
 favorite topics in Vulkan.  I 

04:13:35.718 --> 04:13:39.118
 had to spend so much time with 
 them.  DescriptorSets are 

04:13:39.119 --> 04:13:42.721
 basically how the C++ gives you

04:13:42.722 --> 04:13:45.128
 a perspective into how the 
 resource of the share will need

04:13:45.425 --> 04:13:51.119
 need.  And there is a few 
 things that that may catch you 

04:13:51.120 --> 04:13:54.015
 off guard about DescriptorSets 
 and we'll go over that right 

04:13:54.016 --> 04:13:55.725
 now.  They are binding numbers.

04:13:55.726 --> 04:13:58.512
 You can sparsely populate bind
 binding numbers on the 

04:13:58.513 --> 04:14:02.612
 DescriptorSets but keep the gap
 gaps small because unused bind

04:14:02.820 --> 04:14:07.124
 binding numbers still take up 
 memory.  There also is a max 

04:14:07.125 --> 04:14:10.817
 binding number.  It is not 
 obvious, but if you try to 

04:14:10.818 --> 04:14:15.517
 assign a binding number of 
 32,000 most like GPUs won't 

04:14:15.518 --> 04:14:18.710
 support it and the validation 
 will call it out and tell you 

04:14:18.711 --> 04:14:20.623
 that your binding number is too

04:14:20.624 --> 04:14:23.112
 big.
    There's also a limit on how 

04:14:23.113 --> 04:14:29.319
 many max, DescriptorSets you 
 can have down at one time.  

04:14:29.320 --> 04:14:31.228
 This will be reported to you by

04:14:31.229 --> 04:14:34.925
 max bound DescriptorSets.  
 Right now if you try to bind 

04:14:34.926 --> 04:14:37.712
 more DescriptorSets than your 
 device supports you'll just get

04:14:42.618 --> 04:14:47.514
 have to be updated once you 
 create them.  So the shareer 

04:14:47.515 --> 04:14:51.024
 will know what -- the general 
 wisdom, you want to group the 

04:14:51.025 --> 04:14:54.814
 DescriptorSets by update 
 frequency.  You only should 

04:14:54.815 --> 04:14:57.619
 update DescriptorSets that are 
 changed.  Updating a script set

04:15:01.816 --> 04:15:04.515
 right.  Sharp edges on 
 DescriptorSets.  If you, once 

04:15:04.516 --> 04:15:06.017
 you bind the DescriptorSets you

04:15:06.018 --> 04:15:09.321
 can't do any updates to it 
 until the next iteration of the

04:15:10.816 --> 04:15:14.816
 should do that before binding.
    So here is the one really 

04:15:14.817 --> 04:15:19.218
 confusing thing that caught me 
 off guard with binding 

04:15:19.219 --> 04:15:25.328
 DescriptorSets.  This function 
 vkCMD bind DescriptorSets.  

04:15:25.329 --> 04:15:29.134
 There's a parameter there 
 called first set.  It wasn't 

04:15:29.135 --> 04:15:30.525
 obvious from the spec what this

04:15:30.526 --> 04:15:35.418
 meant.  I thought it meant the 
 index on to the P descriptor 

04:15:35.419 --> 04:15:37.122
 sets which is another parameter

04:15:37.123 --> 04:15:39.723
 and to give you a better 
 perspective, this is what it 

04:15:39.724 --> 04:15:43.019
 looks like.  At the bottom you 
 see the function signature.  So

04:15:46.119 --> 04:15:50.320
 to this field in your pipeline 
 layout.  It's a little 

04:15:50.321 --> 04:15:53.221
 confusing because there is 
 nothing that helps you figure 

04:15:53.222 --> 04:15:56.430
 this out.  Somebody had to 
 point this out to me.  

04:15:56.431 --> 04:16:00.222
 Essentially what this does, it 
 aligns the descriptor set 

04:16:00.223 --> 04:16:04.517
 layout you told them you were 
 going to use, to pass into the 

04:16:04.518 --> 04:16:07.028
 bind DescriptorSets.
    If you are running into a 

04:16:07.029 --> 04:16:08.433
 place where you are binding and

04:16:08.434 --> 04:16:12.332
 getting a crash or binding and 
 getting fairly unexpected 

04:16:12.333 --> 04:16:16.126
 behavior, make sure these two 
 parameters align.

04:16:16.127 --> 04:16:19.628
    FrameBuffers.  So 
 FrameBuffers in Vulkan are 

04:16:19.629 --> 04:16:22.534
 slightly different than they 
 are in OpenGL ES.  You can 

04:16:22.535 --> 04:16:26.919
 think of frame buffers in 
 Vulkan as basically lucid 

04:16:26.920 --> 04:16:32.629
 attachment pools.  They hold 
 arrays of vkimage views.  The 

04:16:32.630 --> 04:16:37.335
 relationship between frame 
 buffers and -- is fairly strict

04:16:37.634 --> 04:16:43.625
 strict.  Subpasss and render 
 passes refer to index.  There 

04:16:43.626 --> 04:16:48.025
 is no order requirements.  The 
 attachments in FrameBuffers 

04:16:48.026 --> 04:16:51.421
 must have the same width and 
 height.  In the general case 

04:16:51.422 --> 04:16:54.930
 you still have to resolve any 
 multisample attachments to 

04:16:54.931 --> 04:16:59.925
 simple attachment before you 
 use them in textures.  Not much

04:17:02.327 --> 04:17:04.938
 mentioned before, inside render

04:17:04.939 --> 04:17:10.537
 passes refer to the index.  Sub
 Subpass dependencyies.  So when

04:17:12.034 --> 04:17:16.724
 there is, you'll see a data 
 structure called set pass 

04:17:16.725 --> 04:17:19.428
 dependencyies.  From a high 
 level perspective what this 

04:17:19.429 --> 04:17:23.126
 data structure does is that it 
 builds a dependency graph that 

04:17:23.127 --> 04:17:26.225
 you pass into Vulkan to tell 
 Vulkan the order in which you 

04:17:26.226 --> 04:17:29.422
 want the subpasses to be 
 processed.  If you don't do 

04:17:29.423 --> 04:17:34.125
 this, some GPUs will process 
 the subpasses as they see fit. 

04:17:36.043 --> 04:17:39.037
 you want them to be processed 
 in.

04:17:39.038 --> 04:17:43.931
    So make sure that when you 
 are working with subpasses, be 

04:17:43.932 --> 04:17:48.725
 clear and explicit in which 
 order you want the subpasses if

04:17:51.128 --> 04:17:54.634
 sorry, the results of the sub
 subpass in the next subpass and

04:17:56.728 --> 04:18:00.826
 you need to use a, let's say 
 you are on subpass three and 

04:18:00.827 --> 04:18:04.360
 you want to use something from 
 subpass zero you need to pre

04:18:04.361 --> 04:18:07.035
 preserve the attachment.  If 
 you don't it will get destroyed

04:18:09.428 --> 04:18:11.844
    Further on the subpasses, if

04:18:11.845 --> 04:18:15.730
 you have subpasses that have 
 multisample output and you want

04:18:17.434 --> 04:18:22.842
 to single sample, you can pass 
 in images into the subpass data

04:18:28.740 --> 04:18:32.643
    So here is the diagram that 
 describes the relationship 

04:18:32.644 --> 04:18:34.833
 between subpasses and render in

04:18:34.834 --> 04:18:37.537
 FrameBuffers.  You can see on 
 the right the FrameBuffer is a 

04:18:37.538 --> 04:18:42.338
 list and the render pass is 
 composed of multiple subpasses.

04:18:44.430 --> 04:18:48.438
 passes.  You can share as many 
 as you want as long as it's 

04:18:48.439 --> 04:18:53.637
 within the device limits.
    All right.  Okay, so these 

04:18:53.638 --> 04:18:56.128
 are, the next two topics, image

04:18:56.129 --> 04:18:59.829
 layouts and pipeline barriers, 
 I wish there was more time to 

04:18:59.830 --> 04:19:03.928
 get in depth.  They are 
 complicated topics.  I will go 

04:19:03.929 --> 04:19:07.632
 over them as best I can.  The 
 behavior of these of the images

04:19:10.532 --> 04:19:16.128
 Some GPUs require image transis
 transises, others don't.  All 

04:19:16.129 --> 04:19:20.142
 Vulkan positions accept lay out

04:19:20.143 --> 04:19:23.140
 for all.  You will take a 
 performance hit if you do that.

04:19:25.130 --> 04:19:30.636
 best to assume that all GPUs 
 require specific image layouts 

04:19:30.637 --> 04:19:36.033
 and set your code to handle it 
 in that way.  They are both 

04:19:36.034 --> 04:19:42.742
 explicit and implicit.  Which 
 can be used with image barriers

04:19:43.133 --> 04:19:47.532
 barriers.  They can be rendered

04:19:47.533 --> 04:19:52.137
 implicitly by render passes.  
 There's a field inside the sub

04:19:52.144 --> 04:19:55.643
 subpasses that ask you like 
 what do you want this to be 

04:19:55.644 --> 04:19:58.342
 once you're done?  You can also

04:19:58.343 --> 04:20:02.243
 use a validation layers to 
 correct any image layout errors

04:20:04.042 --> 04:20:06.242
 validation layers are very fond

04:20:06.243 --> 04:20:10.744
 of screaming at you every time 
 there's an image layout layer. 

04:20:12.836 --> 04:20:14.534
 around.
    All right, pipeline barriers

04:20:14.535 --> 04:20:18.842
 barriers, if you use OpenGL, 
 they can be a little bit terse.

04:20:20.563 --> 04:20:23.947
 First one, while they do look 
 complex, they become second 

04:20:23.948 --> 04:20:25.439
 nature with some practice.  The

04:20:25.440 --> 04:20:31.740
 other thing is there is a 
 restriction on the, there is a 

04:20:31.741 --> 04:20:35.069
 restriction on pipeline barrier
 barriers within render passes. 

04:20:36.859 --> 04:20:39.058
 pass, sorry, a pipeline barrier

04:20:39.059 --> 04:20:42.052
 within a render pass, the sub
 subpass that you are going to 

04:20:42.053 --> 04:20:44.953
 issue the pipeline barrier in 
 needs to have a denied eans 

04:20:44.954 --> 04:20:46.860
 within itself.  And you do that

04:20:46.861 --> 04:20:49.768
 just by telling the subpass the

04:20:49.769 --> 04:20:52.369
 two, the energy index of that 
 subpass.

04:20:52.370 --> 04:20:56.066
    And there's only two types 
 of pipeline barriers you can 

04:20:56.067 --> 04:21:02.458
 issue within a render pass.  
 That's vkmemory bare and vk

04:21:02.459 --> 04:21:03.699
 vkimagine barrier.  So a little

04:21:03.700 --> 04:21:05.360
 bit more advanced on the memory

04:21:05.361 --> 04:21:09.264
 management.  Since you are 
 directly responsible for the 

04:21:09.265 --> 04:21:11.958
 allocation and usage of memory,

04:21:11.959 --> 04:21:16.763
 just like regular old C, you 
 need to do bounds checking.  

04:21:16.764 --> 04:21:21.054
 Make sure all your bounds are 
 checked.  If you write out of 

04:21:21.055 --> 04:21:25.156
 bounds, some let you get away 
 with it.  It creates these 

04:21:25.157 --> 04:21:30.165
 difficult to track down bugs 
 and red herrings.  It creates a

04:21:33.761 --> 04:21:38.962
 uniform buffer.  So build some 
 code around air error checking 

04:21:38.963 --> 04:21:41.364
to 
 make sure all your writes are 

04:21:41.365 --> 04:21:44.967
 in boundss.  Flushing is 
 something that is making its 

04:21:44.968 --> 04:21:48.260
 way back.  After you do any 
 host writes, make sure to flush

04:21:48.465 --> 04:21:52.565
 flush.  After you, if you have 
 command buffer operations that 

04:21:52.566 --> 04:21:56.560
 do a read, all the things that 
 read depends on must be flushed

04:21:57.963 --> 04:21:59.762
 takes place.  There is a slight

04:21:59.763 --> 04:22:01.865
 caveat to the flushing.  If you

04:22:01.866 --> 04:22:05.258
 allocate a memory with the vk
 vkmemory property host parent, 

04:22:05.259 --> 04:22:11.760
 you don't need to flush.
    All right, raiderser shadeer

04:22:12.066 --> 04:22:15.966
s.  
 This is the official lack of 

04:22:15.967 --> 04:22:20.775
 Vulkan and it is a lower level 
 language.  We are using GSL for

04:22:23.865 --> 04:22:28.657
 offline or online using, the 
 same shadeer code can be used 

04:22:28.658 --> 04:22:30.458
on 
 desktop and mobile.  There is a

04:22:32.159 --> 04:22:35.677
 Uniform, obviously you have to 
 use uniform buffers but you 

04:22:35.678 --> 04:22:38.574
 can't have stand alone uniforms

04:22:38.575 --> 04:22:42.770
 anymore.  Uniforms have to be 
 within block variables and 

04:22:42.771 --> 04:22:46.561
 sorry, they have to be within 
 interface blocks.  The layout 

04:22:46.562 --> 04:22:53.069
 are governed by the SDD140 
 rules.  If you ever used with S

04:22:53.109 --> 04:22:56.576
 SDG140, it can be comply 
complicated.  

04:22:56.577 --> 04:23:02.569
 In Cinder we use shadeer to 
 extract from the spear B direct

04:23:02.767 --> 04:23:05.767
 directly.  If that's something 
 that interests you, come talk 

04:23:05.768 --> 04:23:08.976
 to me afterwards.  It saves us 
 a lot of headaches.  Whoever is

04:23:11.975 --> 04:23:13.769
 bindings or between the shadeer
s 

04:23:13.770 --> 04:23:18.079
 and the DescriptorSets, spend 
 some time understanding how 

04:23:18.080 --> 04:23:21.664
 they relate with the 
 DescriptorSets and the shadeers

04:23:23.174 --> 04:23:25.776
.  
 There's obviously a natural 

04:23:25.777 --> 04:23:29.673
 relationship but it's really 
 easy to make an error in one 

04:23:29.674 --> 04:23:31.563
 and kind of ig error r nor that

04:23:31.564 --> 04:23:35.166
 it may create an error in the 
 other because you have to keep 

04:23:35.167 --> 04:23:40.165
 them synchronized.
    Performance considerations. 

04:23:42.676 --> 04:23:45.666
 self-evident things that we 
 hopefully all hold to be true 

04:23:45.667 --> 04:23:48.966
 when we are talking about 
 performance in graphics.  

04:23:48.967 --> 04:23:53.273
 Obviously minimize host GB 
 transfers especially on mobile.

04:23:54.870 --> 04:23:59.479
 power.  Reduce round trips on 
 any reads.  That includes using

04:24:03.081 --> 04:24:07.272
 specifically try not to starve 
 the GPU.  When you starve the 

04:24:07.273 --> 04:24:11.665
 GPU the next round of pushing 
 data to the GPU can easily over

04:24:15.577 --> 04:24:17.165
    With respect to render loops

04:24:17.166 --> 04:24:21.379
 the best thing to do is keep 
 multiple frames in flight with 

04:24:21.380 --> 04:24:26.367
 Vulkan.  I find in Vulkan I 
 find it to be easier to do than

04:24:30.568 --> 04:24:34.370
 when I was trying to keep 
 multiple frames in flight.  

04:24:34.371 --> 04:24:37.271
 With Vulkan you can very 
 explicitly do this because of 

04:24:37.272 --> 04:24:40.167
 the nature of Vulkan.
    So if you have more than one

04:24:41.966 --> 04:24:47.979
 two, you obviously have to 
 double buffer the nonstatic 

04:24:47.980 --> 04:24:51.968
 resources.  If you have three, 
 triple buffer them.  And this 

04:24:51.969 --> 04:24:54.370
 includes things like command 
 buffers.  That's a good start

04:24:54.573 --> 04:24:56.965
 starting point if you want to 
 find out what resources are 

04:24:56.966 --> 04:24:58.378
 backing that particular frame. 

04:24:58.379 --> 04:25:01.374
 Build accompanied dependency 
 graph back to the resource that

04:25:02.771 --> 04:25:04.868
    And so insure since you have

04:25:04.869 --> 04:25:08.480
 multiple frames in flight, you 
 probably have to handle the 

04:25:08.481 --> 04:25:11.170
 frame rate yourself.  This 
 takes a little bit of work and 

04:25:11.171 --> 04:25:16.670
 requires both using the Vulkan 
 sync parameters plus the CPU 

04:25:16.671 --> 04:25:22.480
 side logic.  This is an area 
 when you do not want to use BK 

04:25:22.481 --> 04:25:25.476
 QueueWaitIdle.  Somebody, 
 Vulkan function names are hard 

04:25:25.477 --> 04:25:28.970
 to say.  I know I'm screwing 
 them up.  They are a mouthful 

04:25:28.971 --> 04:25:32.484
 and really long.  I apologize 
 for that.

04:25:32.485 --> 04:25:36.568
    All right.  So here is 
 something that didn't exist in 

04:25:36.569 --> 04:25:40.985
 OpenGL, but may becoming to 
 OpenGL soon.  Push constants.  

04:25:40.986 --> 04:25:44.679
 If you're looking to do 
 something quick and there is 

04:25:44.680 --> 04:25:47.379
 something you have to pass 
 between your code and the shade

04:25:47.675 --> 04:25:50.280
 shader code, use push contents.

04:25:50.281 --> 04:25:55.272
 They don't require buffers or 
 DescriptorSets.  You only push 

04:25:55.273 --> 04:25:58.187
 20 bites at a time.  The 
 limitation on them is that you 

04:25:58.188 --> 04:26:03.780
 can only have one push for all 
 shadeer stages per shadeer.  

04:26:03.781 --> 04:26:07.074
120 
 bytes, you can fit two four by 

04:26:07.075 --> 04:26:09.579
 four matrixes in there.  You 
 have to be clever how you use 

04:26:09.580 --> 04:26:13.680
 them.  This sharp edge, the 
 size of the offsets must be 

04:26:13.681 --> 04:26:16.882
 multiple four.  That is not 
 sharp edge, four is the default

04:26:19.672 --> 04:26:23.575
 If your size in offset is not 
 four, something went wrong 

04:26:23.576 --> 04:26:28.675
 somewhere else horribly.
    But they are really quick 

04:26:28.676 --> 04:26:33.476
 and fast.  Cinder does have a 
 simple of how to use this.

04:26:33.477 --> 04:26:37.382
    And here is what they look 
 like.  It just looks like a 

04:26:37.383 --> 04:26:42.073
 uniform block except where 
 layout is, it has push constant

04:26:42.686 --> 04:26:44.686
 constant.
    Excuse me.

04:26:51.582 --> 04:26:55.878
    All right.  So most projects

04:26:55.879 --> 04:27:03.288
 will probably start on desktop 
 and go to mobile.  It is, they 

04:27:03.289 --> 04:27:07.876
 are really highly skilled, but 
 for the rest of us, pretty much

04:27:09.392 --> 04:27:14.493
 and migrates to mobile.
    Vulkan, the API is actually 

04:27:14.494 --> 04:27:17.375
 crazy consistent.  Cinder took 
 three hours to port from the 

04:27:17.376 --> 04:27:20.276
 desktop to mobile.  The only 
 thing that required changing 

04:27:20.277 --> 04:27:23.881
 was basically the WSI or 
 Windows systems integration and

04:27:30.480 --> 04:27:33.038
 time to port.  But you can 
 trust that the API is 

04:27:33.039 --> 04:27:34.851
 consistent.
    The only other area that is 

04:27:34.852 --> 04:27:38.735
 different is the extensions.  
 So that's for the API.

04:27:38.736 --> 04:27:41.742
    Now, the properties are a 
 different story.  Properties 

04:27:41.743 --> 04:27:45.034
 for the features are very 
 different from GPU to GPU.  And

04:27:47.649 --> 04:27:49.733
 image formats or buffer formats

04:27:49.734 --> 04:27:53.337
 are host visible and what depth

04:27:53.338 --> 04:27:57.147
 slash stens aisle formats are 
 supported.  Don't assume that 

04:27:57.148 --> 04:27:58.933
 two devices that may be similar

04:27:58.934 --> 04:28:03.334
 in capabilityies that they are 
 Vulkan positions are equal.  I 

04:28:03.335 --> 04:28:07.748
 made that assumption.  I found 
 it to be completely not true.  

04:28:07.749 --> 04:28:13.536
 So if you must, write a little 
 tool that queryies the 

04:28:13.537 --> 04:28:15.445
 properties of the devices so it

04:28:15.446 --> 04:28:18.636
 solidifyies in your head what 
 the devices are capable of, 

04:28:18.637 --> 04:28:21.946
 since there's not a whole lot 
 of Vulkan implementations right

04:28:23.739 --> 04:28:26.941
 that way.  It really helps.
    The other thing when you're 

04:28:26.942 --> 04:28:29.440
 porting, have a strategy to 
 find the best properties for 

04:28:29.441 --> 04:28:32.852
 that particular device.  An 
 example in Cinder is we have a 

04:28:32.853 --> 04:28:37.841
 function called vkfind best 
 tensile format.  The reason is,

04:28:43.239 --> 04:28:46.638
 only 16 to 24 bit integers were

04:28:46.639 --> 04:28:49.945
 supported.  At minimum you can 
 use properties that are known 

04:28:49.946 --> 04:28:54.038
 to work across all devices.
    All right.  The other thing 

04:28:54.039 --> 04:28:58.746
 that you should be aware of is 
 three channel format support is

04:29:00.357 --> 04:29:02.949
 both image and buffer formats. 

04:29:02.950 --> 04:29:06.551
 So again, develop a tool that 
 generates a device support on 

04:29:06.552 --> 04:29:08.138
 which formats are supported for

04:29:08.139 --> 04:29:10.856
 the devices.  And if you do, if

04:29:10.857 --> 04:29:15.051
 you are relying on any data 
 packing on your vertex for 

04:29:15.052 --> 04:29:18.842
 images and you are using three 
 dimensional formats right now 

04:29:18.843 --> 04:29:22.239
 you may have to change the the 
 format that you're using which 

04:29:22.240 --> 04:29:23.943
 leads me to the next point.  If

04:29:23.944 --> 04:29:27.948
 you are also staging, if you 
 are also staging transfers 

04:29:27.949 --> 04:29:32.247
 between your source, host data 
 and GPU data, you may have to 

04:29:32.248 --> 04:29:35.458
 transform the data in the 
 staging.  An example of this is

04:29:39.041 --> 04:29:46.949
 On some devices RGB actually 
 isn't a, RGB8 isn't a visible 

04:29:46.950 --> 04:29:52.143
 host format.  You have to 
 transfer that RGBA, copy it to 

04:29:52.144 --> 04:29:56.442
 the Vulkan memory as RGBA and 
 then do the conversion inside 

04:29:56.443 --> 04:30:00.840
 of Vulkan.  The other way to 
 work around this is to do a 

04:30:00.841 --> 04:30:07.353
 direct copy from buffer to 
 image using vkimage buffer to 

04:30:07.354 --> 04:30:11.756
 to -- there's a caveat to this 
 but this does a bit to bit copy

04:30:13.844 --> 04:30:16.749
 You can basically read your 
 image into the buffer and dump 

04:30:16.750 --> 04:30:21.957
 it into the image itself.
    The desk tensile copyies are

04:30:23.260 --> 04:30:27.842
 There's a good portion of the 
 spec that talks about that.

04:30:27.843 --> 04:30:29.858
    Compressed textures.  So you

04:30:29.859 --> 04:30:31.945
 should know, I mean, we kind of

04:30:31.946 --> 04:30:34.143
 all know mostly these days what

04:30:34.144 --> 04:30:37.351
 formats are supported.  The 
 thing not to do is, don't 

04:30:37.352 --> 04:30:38.856
 assume it's supported in OpenGL

04:30:38.857 --> 04:30:41.752
 ES that it will be supported in

04:30:41.753 --> 04:30:45.656
 Vulkan.  It mate not be.  One 
 nice thing about Android in 

04:30:45.657 --> 04:30:49.354
 this regard, all Android Vulkan

04:30:49.355 --> 04:30:54.045
 will support ATSC as well.  And

04:30:54.046 --> 04:30:57.649
 the desktop support is 
 essentially the BC formats.  

04:30:57.650 --> 04:31:03.460
 They may have slightly more 
 complicated names.

04:31:03.461 --> 04:31:05.461
    Excuse me for one second.

04:31:07.856 --> 04:31:12.047
    Okay.  So this is the last 
 part of this, going from 

04:31:12.048 --> 04:31:13.951
 desktop to mobile.  Not to harp

04:31:13.952 --> 04:31:16.353
 on this too much, but some GPUs

04:31:16.354 --> 04:31:20.149
 will require very image layout 
 transitions while others won't.

04:31:23.952 --> 04:31:26.446
 important point.  I encourage 
 if you have questions about 

04:31:26.447 --> 04:31:29.956
 this come talk to me.  I can't 
 say certain things on stage, 

04:31:29.957 --> 04:31:33.747
 but I can give you specific 
 details if you want to know 

04:31:33.748 --> 04:31:39.055
 more about this.
    So pay attention to the 

04:31:39.056 --> 04:31:46.356
 device limits.  This is almost 
 goes without saying but again 

04:31:46.357 --> 04:31:53.048
 it catches people more often 
 than not, that most of the 

04:31:53.049 --> 04:31:56.465
 vendors will go above and 
 beyond in certain areas of the 

04:31:56.466 --> 04:31:59.948
 device limits and not others.  
 And some device vendors will 

04:31:59.949 --> 04:32:03.158
 just kind of do the minimum.  
 It is not because one vendor is

04:32:05.260 --> 04:32:08.863
 the implementation, right?  
 Don't assume that the same 

04:32:08.864 --> 04:32:12.158
 class of devices have similar 
 functionality.  They may not.  

04:32:12.159 --> 04:32:15.954
 If you run into any errors, 
 especially with device limits, 

04:32:15.955 --> 04:32:20.754
 you can use a validation layer 
 to track them down.

04:32:20.755 --> 04:32:24.667
    All right.  So that's about 
 41 Slides of me talking without

04:32:26.952 --> 04:32:36.059
    And let me fix that right 
 now.  So I know that the word 

04:32:36.060 --> 04:32:39.360
 games is used in the title of 
 the talk.  I am not going to 

04:32:39.361 --> 04:32:44.262
 show you engine demos, but I 
 will show you render demos, and

04:32:47.262 --> 04:32:50.063
 fact that Vulkan is up and 
 running and you can do amazing 

04:32:50.064 --> 04:32:54.759
 things with it already.  
 Hopefully these demos will be 

04:32:54.760 --> 04:32:57.552
 enticeing enough.  Go to the 
 demos, please.

04:32:57.553 --> 04:33:02.154
    So this is a simulation that

04:33:02.155 --> 04:33:07.763
 runs almost entirely on the GPU
 GPU.  It is a fox simulation of

04:33:10.859 --> 04:33:12.562
 essentially the fish simulation

04:33:12.563 --> 04:33:15.759
 is running on the GPU.  And 
 there is a Shark that comes in 

04:33:15.760 --> 04:33:19.256
 every now and then and 
 basically causes the fish to 

04:33:19.257 --> 04:33:21.559
 disperse.  The code for this is

04:33:21.560 --> 04:33:24.872
 actually open source.  It is a 
 sample on Cinder if you want to

04:33:27.160 --> 04:33:32.260
 totally free.
    Whoops.  Stay awake.  The 

04:33:32.261 --> 04:33:38.364
 original work was done by my 
 friend Robert Hodge inwho was 

04:33:38.365 --> 04:33:41.968
 kind enough to donate it as 
 part of the Vulkan efforts.

04:33:41.969 --> 04:33:43.658
    The next demo I want to show

04:33:43.659 --> 04:33:48.662
 you, it is another demo by 
 Robert and essentially if you 

04:33:48.663 --> 04:33:53.371
 are familiar with NASA's 
 capture of sun spots, this is 

04:33:53.372 --> 04:33:59.269
 what the images look like.
    So Robert wanted to create 

04:33:59.270 --> 04:34:03.056
 something that was a realtime 
 version of the sun spots.  So 

04:34:03.057 --> 04:34:09.177
 you know, he likes to create 
 pictures, but it turns out to 

04:34:09.178 --> 04:34:11.559
 be beautiful.  The funny tidbit

04:34:11.560 --> 04:34:15.959
 about this, somebody -- actual
 actually more than a few people

04:34:17.861 --> 04:34:22.963
 was the actual NASA capture.  
 So this one unfortunately isn't

04:34:28.678 --> 04:34:33.572
 talk to me afterwards and I'm 
 happy to give it to you.  Can 

04:34:33.573 --> 04:34:36.663
 we go to the Slides?
    So to wrap things up, if you

04:34:38.676 --> 04:34:42.060
 implementation, it is at GitHub

04:34:42.061 --> 04:34:45.571
 slash Cinder/Cinder on the 
 Vulkan branch.  If you want to 

04:34:45.572 --> 04:34:49.559
 connect with us about Vulkan, 
 we want to work with you to 

04:34:49.560 --> 04:34:53.666
 make Vulkan successful.  Visit 
 this URL.  I have 12 minutes 

04:34:53.667 --> 04:34:55.476
 left and I'm more than happy to

04:34:55.477 --> 04:34:57.564
 take any questions you have 
 about Vulkan or Cinder.

04:35:04.163 --> 04:35:06.474
    Okay.  You have to speak up.

04:35:06.475 --> 04:35:10.265
 I won't be able to hear you.  
 Yeah?

04:35:10.266 --> 04:35:12.266
    &gt;&gt;Audience:  (Speaker away
 from microphone.)

04:35:23.578 --> 04:35:28.677
    &gt;&gt;Audience:  Can you hear me
 me?  So my question is, is 

04:35:28.678 --> 04:35:30.666
 Android itself being powered by

04:35:30.667 --> 04:35:32.683
 Vulkan?

04:35:40.464 --> 04:35:44.862
    &gt;&gt; It means when they come 
 back another time, they are in 

04:35:44.863 --> 04:35:51.964
 airplane mode that shell will 
 load up quickly ...  You can 

04:35:51.965 --> 04:35:55.175
 cache that content so that 
 entire view is then available 

04:35:55.176 --> 04:36:00.268
 whenever they try accessing it 
 without a network connection.  

04:36:00.269 --> 04:36:02.277
 Spot on

04:36:06.067 --> 04:36:08.067
.
    (The session concluded.)

04:37:02.352 --> 04:37:05.418
           ***
    This text is being provided 

04:37:02.352 --> 04:37:06.218
 in a rough draft format.  
 Communication Access Realtime 

04:37:02.352 --> 04:37:06.085
 Translation (CART) is provided 
 in order to facilitate 

04:37:02.352 --> 04:37:04.485
 communication accessibility and

04:37:02.352 --> 04:37:06.218
 may not be a totally verbatim 
 record of the proceedings.

