WEBVTT
Kind: captions
Language: en

00:00:03.244 --> 00:00:05.410
JESSE ENGEL: One of the
goals of the Magenta project

00:00:05.410 --> 00:00:07.000
is to engage the
artist community

00:00:07.000 --> 00:00:09.195
and get people making art
with machine learning.

00:00:09.195 --> 00:00:11.320
So to help with that, we've
created an Ableton Live

00:00:11.320 --> 00:00:13.780
set for synthesizing
audio, which we control

00:00:13.780 --> 00:00:15.430
with a maximumus p patch.

00:00:15.430 --> 00:00:18.400
And we've even created a
nice interface here for iPad

00:00:18.400 --> 00:00:19.780
so that we get
real time feedback

00:00:19.780 --> 00:00:23.041
during performance and
interactive control surface.

00:00:23.041 --> 00:00:24.790
So a cool thing we can
do with this set up

00:00:24.790 --> 00:00:27.700
is we can create continuously
evolving drumbeats.

00:00:27.700 --> 00:00:32.170
Because I can input a very
basic pattern into the LCM.

00:00:32.170 --> 00:00:34.588
Here, I'm going to play four
beats of a pattern here.

00:00:34.588 --> 00:00:38.074
[DRUMMING]

00:00:43.417 --> 00:00:45.250
JESSE ENGEL: And you'll
hear that LCM is now

00:00:45.250 --> 00:00:46.630
doing the next step prediction.

00:00:46.630 --> 00:00:48.999
It's predicting what the
most likely sound is.

00:00:48.999 --> 00:00:51.040
And it sounds very much
the same as when I input,

00:00:51.040 --> 00:00:54.040
because drummers often
keep the steady beat, maybe

00:00:54.040 --> 00:00:56.540
throwing a fill in
every once in a while.

00:00:56.540 --> 00:00:58.720
But what we can do
with our AI drummer

00:00:58.720 --> 00:01:01.510
is we can add a little
bit of temperature

00:01:01.510 --> 00:01:04.180
to add some more randomness
into the sampling process.

00:01:04.180 --> 00:01:06.070
And then when we hit
the mutate button,

00:01:06.070 --> 00:01:09.010
it's going to create a new
sequence of drum patterns

00:01:09.010 --> 00:01:11.080
by feeding the old
one in and generating

00:01:11.080 --> 00:01:12.250
new samples afterwards.

00:01:12.250 --> 00:01:12.880
So here we go.

00:01:17.370 --> 00:01:17.940
All right.

00:01:17.940 --> 00:01:20.190
So you can hear that it
adds a little variety.

00:01:20.190 --> 00:01:23.970
So this way, we can have a
continuously evolving drumbeat

00:01:23.970 --> 00:01:27.090
over which we can play
melodies and chords on top of.

00:01:27.090 --> 00:01:29.832
And it creates a real,
interactive musical experience.

00:01:29.832 --> 00:01:31.290
SAGEEV OORE: So
one of the fun ways

00:01:31.290 --> 00:01:34.410
of playing with the system is
using the call and response.

00:01:34.410 --> 00:01:36.130
I'll play a call
using an organ sound.

00:01:36.130 --> 00:01:38.846
The system will respond
with a digital piano sound.

00:01:38.846 --> 00:01:40.470
I'll start by turning
the metronome on.

00:01:43.458 --> 00:01:46.446
[KEYBOARD]

00:02:01.070 --> 00:02:05.300
And another variation
on that is that I

00:02:05.300 --> 00:02:12.444
use the bass sound and loop
whatever response it has.

00:02:12.444 --> 00:02:15.402
[KEYBOARD]

00:02:18.405 --> 00:02:21.158
And then I can play
over top of that.

00:02:21.158 --> 00:02:24.581
[KEYBOARD]

00:02:41.935 --> 00:02:44.697
So what's interesting
is the feedback loop

00:02:44.697 --> 00:02:46.780
that happens between the
system and the performer.

00:02:46.780 --> 00:02:50.380
So I make a choice and that
affects what it'll play back.

00:02:50.380 --> 00:02:52.000
And then what it
plays back in turn

00:02:52.000 --> 00:02:56.710
affects how I'll
continue playing with it.

00:02:56.710 --> 00:02:59.434
And it's fun to
experiment with that.

00:02:59.434 --> 00:03:00.850
DOUG ECK: What we
see from Magenta

00:03:00.850 --> 00:03:03.830
is a future where artists,
musicians for example,

00:03:03.830 --> 00:03:07.752
can use machine learning
as a genuine creative tool.

00:03:07.752 --> 00:03:10.210
ADAM ROBERTS: So now that we
have this instrument out there

00:03:10.210 --> 00:03:12.550
on our GitHub, we're really
excited about having people

00:03:12.550 --> 00:03:14.979
download it, play with it,
and share the music back

00:03:14.979 --> 00:03:15.770
with the community.

00:03:15.770 --> 00:03:17.854
So we can hear what great
stuff they come up with.

00:03:17.854 --> 00:03:20.020
CURTIS HAWTHORNE: The code
base that we've developed

00:03:20.020 --> 00:03:22.210
makes it easy for researchers
and creative coders

00:03:22.210 --> 00:03:25.630
to take information from
MIDI files and music scores

00:03:25.630 --> 00:03:28.480
and extract that information and
make it available for training

00:03:28.480 --> 00:03:29.967
models in TensorFlow.

00:03:29.967 --> 00:03:32.050
You can then take those
models that you've trained

00:03:32.050 --> 00:03:35.380
and use our generation API to
connect it to music production

00:03:35.380 --> 00:03:37.450
software, like
Ableton or Pro Tools

00:03:37.450 --> 00:03:40.240
and also interact
with it in real time.

00:03:40.240 --> 00:03:42.390
[MUSIC PLAYING]

