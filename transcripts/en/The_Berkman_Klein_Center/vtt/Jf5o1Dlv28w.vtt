WEBVTT
Kind: captions
Language: en

00:00:06.400 --> 00:00:08.530
Artificial Intelligence is one label for

00:00:08.530 --> 00:00:10.270
it, but another label for it is just

00:00:10.270 --> 00:00:13.960
forms of systems that evolve under

00:00:13.960 --> 00:00:16.090
their own rules, in ways that might be

00:00:16.100 --> 00:00:17.950
unexpected even to the creator of those

00:00:17.950 --> 00:00:22.000
systems, that will be used in some way to

00:00:22.000 --> 00:00:26.500
substitute for human agency in a lot of

00:00:26.500 --> 00:00:28.779
instances; and that substitution for

00:00:28.779 --> 00:00:31.060
human agency might be something that is

00:00:31.060 --> 00:00:33.580
quite autonomy- enhancing for humans,

00:00:33.580 --> 00:00:36.370
individually or in groups. If you have a

00:00:36.370 --> 00:00:38.830
system that can worry about stuff that

00:00:38.830 --> 00:00:40.000
you don't have to worry about anymore

00:00:40.000 --> 00:00:41.980
you can turn your attention to other,

00:00:41.980 --> 00:00:44.620
possibly more interesting or important

00:00:44.620 --> 00:00:46.240
issues. On the other hand, if you're

00:00:46.240 --> 00:00:48.670
consigning to a system agenda-setting

00:00:48.670 --> 00:00:51.430
power, decision-making power, again either

00:00:51.430 --> 00:00:55.210
individually or in a group, that may

00:00:55.210 --> 00:00:57.340
really carry with it consequences that

00:00:57.340 --> 00:00:59.350
people aren't so much keeping an eye on

00:00:59.350 --> 00:01:01.090
it, or people who are directly affected

00:01:01.090 --> 00:01:03.610
aren't in a position to keep an eye on it. I

00:01:03.610 --> 00:01:04.989
think that's creating some of the

00:01:04.989 --> 00:01:07.600
discomfort we see right now with the

00:01:07.600 --> 00:01:10.270
pace at which AI is growing and

00:01:10.270 --> 00:01:12.130
applications of machine learning and

00:01:12.130 --> 00:01:14.450
other systems that can develop under

00:01:14.650 --> 00:01:16.090
their own steam.

00:01:16.090 --> 00:01:17.830
These are the sorts of things that give

00:01:17.830 --> 00:01:20.530
us some pause. And I think about the

00:01:20.530 --> 00:01:23.110
provision of government services, or

00:01:23.110 --> 00:01:25.330
decisions that are uniquely often made by

00:01:25.330 --> 00:01:28.510
governments, such as under what

00:01:28.510 --> 00:01:30.040
circumstances somebody should get bail

00:01:30.040 --> 00:01:31.659
and how much the bail should be set at,

00:01:31.659 --> 00:01:33.820
whether somebody should be paroled from

00:01:33.820 --> 00:01:34.720
prison,

00:01:34.720 --> 00:01:37.659
how long should a sentence be? These are

00:01:37.659 --> 00:01:39.729
things we usually consigned to human

00:01:39.729 --> 00:01:43.780
actors&nbsp;— judges — but those judges are

00:01:43.780 --> 00:01:46.060
subject to their own biases and

00:01:46.060 --> 00:01:48.610
fallibilities and inconsistencies. And

00:01:48.610 --> 00:01:50.650
there is now an opportunity to start

00:01:50.650 --> 00:01:53.290
thinking about what would it mean — equal

00:01:53.290 --> 00:01:55.060
protection under the law — to treat

00:01:55.060 --> 00:01:58.150
similar people similarly? And machines

00:01:58.150 --> 00:01:59.890
could either be quite helpful with that

00:01:59.890 --> 00:02:01.540
in double-checking the way in which our

00:02:01.540 --> 00:02:04.540
cohort of judges is behaving.

00:02:04.540 --> 00:02:07.659
It could also be I think an unfortunate

00:02:07.659 --> 00:02:10.179
example of "set it and forget it" and

00:02:10.179 --> 00:02:12.099
biases could creep in, and often in

00:02:12.099 --> 00:02:15.129
unexpected ways or circumstances that

00:02:15.129 --> 00:02:16.659
really will require some form of

00:02:16.659 --> 00:02:19.960
oversight. All of these systems

00:02:19.960 --> 00:02:23.830
not only have their own outputs and

00:02:23.830 --> 00:02:27.340
dependencies and people that they affect.

00:02:27.340 --> 00:02:29.680
They may also be interacting with other

00:02:29.680 --> 00:02:32.170
systems, and that can end up with

00:02:32.170 --> 00:02:35.050
unexpected results and quite possibly

00:02:35.050 --> 00:02:38.110
counter-intuitive ones. We have had for

00:02:38.110 --> 00:02:41.710
many, many years for the functions in

00:02:41.710 --> 00:02:44.290
society undertaken by professionals,

00:02:44.290 --> 00:02:45.880
where the professionals are the most

00:02:45.880 --> 00:02:48.880
empowered, able to really affect other

00:02:48.880 --> 00:02:50.950
people's lives, we often have them

00:02:50.950 --> 00:02:53.260
organized into a formal profession, even

00:02:53.260 --> 00:02:55.030
with a guild that you need special

00:02:55.030 --> 00:02:57.310
qualifications to join. There are

00:02:57.310 --> 00:02:59.410
professional ethics independent of what

00:02:59.410 --> 00:03:01.180
you agree to do for a customer or a

00:03:01.180 --> 00:03:03.460
client. Now I don't know if AI is ready

00:03:03.460 --> 00:03:05.740
for that. I don't know that we would want

00:03:05.740 --> 00:03:07.840
to restrict somebody in a garage from

00:03:07.840 --> 00:03:09.490
experimenting with some cool code and

00:03:09.490 --> 00:03:11.860
neat data and doing things. At the same

00:03:11.860 --> 00:03:13.720
time, when that data gets spun up and it

00:03:13.720 --> 00:03:16.090
starts affecting millions or tens of

00:03:16.090 --> 00:03:17.440
millions of people,

00:03:17.440 --> 00:03:19.180
it's not clear that we still want it to

00:03:19.180 --> 00:03:21.400
be as if it's just a cool project in a

00:03:21.400 --> 00:03:24.640
garage. Interestingly the academia in huge

00:03:24.640 --> 00:03:27.130
part gave us the internet, which in turn

00:03:27.130 --> 00:03:28.360
has been the gift that keeps on giving;

00:03:28.360 --> 00:03:30.280
and so many features of the way the

00:03:30.280 --> 00:03:32.050
Internet was designed, and continues to

00:03:32.050 --> 00:03:34.960
operate, reflect the values of academia

00:03:34.960 --> 00:03:36.880
that have to do with an openness to

00:03:36.880 --> 00:03:39.850
contribution from nearly anywhere, an

00:03:39.850 --> 00:03:41.440
understanding that we should try things

00:03:41.440 --> 00:03:44.860
out and have things sink or swim on

00:03:44.860 --> 00:03:46.780
their reception, rather than trying to

00:03:46.780 --> 00:03:48.610
handicap ahead of time what exactly is

00:03:48.610 --> 00:03:50.470
going to work, tightly controlled by one

00:03:50.470 --> 00:03:52.600
firm or a handful.

00:03:52.600 --> 00:03:54.130
These are all reflected in the Internet,

00:03:54.130 --> 00:03:56.260
and for AI, I think there's a similar

00:03:56.260 --> 00:04:00.490
desire to be welcoming to as many

00:04:00.490 --> 00:04:03.880
different ways of implementing and

00:04:03.880 --> 00:04:07.150
refining a remarkable tool set that has

00:04:07.150 --> 00:04:09.490
developed in just a few years, and the

00:04:09.490 --> 00:04:12.700
corresponding reams of data that can be

00:04:12.700 --> 00:04:18.100
used, and that in turn, can go from innocuous to quite sensitive in just one

00:04:18.100 --> 00:04:22.360
flop. To be able to have academia not

00:04:22.360 --> 00:04:23.560
just playing a meaningful role, but

00:04:23.560 --> 00:04:26.530
central to these efforts, strikes me as

00:04:26.530 --> 00:04:30.580
an important societal hedge against what

00:04:30.580 --> 00:04:32.110
otherwise can be the propriatization of

00:04:32.110 --> 00:04:33.639
some of the

00:04:33.639 --> 00:04:36.249
best technologies, and our inability to

00:04:36.249 --> 00:04:38.349
understand how they're doing what they

00:04:38.349 --> 00:04:39.939
do, because often we don't know what we

00:04:39.939 --> 00:04:41.169
don't know,

00:04:41.169 --> 00:04:44.169
Able even to suggest design changes or

00:04:44.169 --> 00:04:47.349
tweaks, and to then compare it rigorously

00:04:47.349 --> 00:04:51.370
against some set of criteria that are

00:04:51.370 --> 00:04:53.080
criteria that in turn can be debated

00:04:53.080 --> 00:04:55.509
about what makes for a better society,

00:04:55.509 --> 00:04:57.939
what is helping humanity,

00:04:57.939 --> 00:05:00.819
what is respecting dignity and autonomy,

00:05:00.819 --> 00:05:05.110
and those are questions that we may

00:05:05.110 --> 00:05:06.789
never fully settle but we may have a

00:05:06.789 --> 00:05:08.319
sense on the spectrum of which is

00:05:08.319 --> 00:05:10.180
pushing things in

00:05:10.180 --> 00:05:13.330
one direction or another. If we didn't

00:05:13.330 --> 00:05:15.009
have academia playing a role,

00:05:15.009 --> 00:05:16.870
it might just be a traditional private

00:05:16.870 --> 00:05:20.650
arms race and we could find that "gosh

00:05:20.650 --> 00:05:24.159
somehow this magic box does some cool

00:05:24.159 --> 00:05:26.740
thing offered by name your company we

00:05:26.740 --> 00:05:28.060
don't really know how it works and

00:05:28.060 --> 00:05:30.250
because it's a robot it's never going to

00:05:30.250 --> 00:05:31.930
quit his job and move to another company

00:05:31.930 --> 00:05:33.819
and spread that knowledge or retire and

00:05:33.819 --> 00:05:35.860
teach." These are the sorts of things that

00:05:35.860 --> 00:05:38.139
over the medium to longer-term mean that

00:05:38.139 --> 00:05:41.800
having a meaningful, open project that

00:05:41.800 --> 00:05:44.949
really develops this next round of

00:05:44.949 --> 00:05:47.169
technology in the kind of open manner in

00:05:47.169 --> 00:05:49.000
which the internet was developed, and is

00:05:49.000 --> 00:05:52.659
often healthily criticized and refined,

00:05:52.659 --> 00:05:55.029
that's what we should be aiming for, for AI.

00:05:55.029 --> 00:06:06.470
 

