WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
So now we're ready to get back to the problem of extracting a list

00:00:04.000 --> 00:00:06.000
that contains all the links in a webpage.

00:00:06.000 --> 00:00:10.000
This is the first step towards our crawler, which will crawl a set of webpages,

00:00:10.000 --> 00:00:13.000
finding all of the links that can be found from a seed page.

00:00:13.000 --> 00:00:16.000
We're going to start with a webpage.

00:00:16.000 --> 00:00:19.000
We have the url of some seed page.

00:00:19.000 --> 00:00:24.000
We use the get_page procedure to get a string which is the text of that page.

00:00:24.000 --> 00:00:26.000
That's got lots of stuff in it that we don't care about,

00:00:26.000 --> 00:00:29.000
but it also includes some hyperlinks,

00:00:29.000 --> 00:00:33.000
and inside the hyperlinks are the url's to that page links too.

00:00:33.000 --> 00:00:36.000
Our goal is to define a procedure--we'll call it get<u>all</u>links--

00:00:36.000 --> 00:00:41.000
that takes as input, a string representing the text on a webpage,

00:00:41.000 --> 00:00:44.000
and produces as output, a list containing all of the url's that are linked to by that page.

