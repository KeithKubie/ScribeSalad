WEBVTT
Kind: captions
Language: en

00:00:00.420 --> 00:00:04.960
 
[Music]

00:00:04.960 --> 00:00:04.970
[Music]
 

00:00:04.970 --> 00:00:07.850
[Music]
recently I was on the Richard Quest show

00:00:07.850 --> 00:00:07.860
recently I was on the Richard Quest show
 

00:00:07.860 --> 00:00:10.310
recently I was on the Richard Quest show
on CNN TV and that was that's the

00:00:10.310 --> 00:00:10.320
on CNN TV and that was that's the
 

00:00:10.320 --> 00:00:12.350
on CNN TV and that was that's the
question that we have the Battle of the

00:00:12.350 --> 00:00:12.360
question that we have the Battle of the
 

00:00:12.360 --> 00:00:14.810
question that we have the Battle of the
billionaires on one hand we have Mark

00:00:14.810 --> 00:00:14.820
billionaires on one hand we have Mark
 

00:00:14.820 --> 00:00:16.730
billionaires on one hand we have Mark
Zuckerberg saying don't worry

00:00:16.730 --> 00:00:16.740
Zuckerberg saying don't worry
 

00:00:16.740 --> 00:00:18.679
Zuckerberg saying don't worry
artificial intelligence will give us new

00:00:18.679 --> 00:00:18.689
artificial intelligence will give us new
 

00:00:18.689 --> 00:00:21.470
artificial intelligence will give us new
jobs new industries create wealth

00:00:21.470 --> 00:00:21.480
jobs new industries create wealth
 

00:00:21.480 --> 00:00:24.349
jobs new industries create wealth
prosperity and then we have people like

00:00:24.349 --> 00:00:24.359
prosperity and then we have people like
 

00:00:24.359 --> 00:00:27.560
prosperity and then we have people like
well Elon Musk who says watch out they

00:00:27.560 --> 00:00:27.570
well Elon Musk who says watch out they
 

00:00:27.570 --> 00:00:30.409
well Elon Musk who says watch out they
pose an existential threat to humanity

00:00:30.409 --> 00:00:30.419
pose an existential threat to humanity
 

00:00:30.419 --> 00:00:33.350
pose an existential threat to humanity
who knows maybe one day they'll put us

00:00:33.350 --> 00:00:33.360
who knows maybe one day they'll put us
 

00:00:33.360 --> 00:00:35.990
who knows maybe one day they'll put us
in zoos and throw peanuts at us and make

00:00:35.990 --> 00:00:36.000
in zoos and throw peanuts at us and make
 

00:00:36.000 --> 00:00:38.780
in zoos and throw peanuts at us and make
us dance make us dance behind bars like

00:00:38.780 --> 00:00:38.790
us dance make us dance behind bars like
 

00:00:38.790 --> 00:00:42.470
us dance make us dance behind bars like
we do with monkeys and with bears well

00:00:42.470 --> 00:00:42.480
we do with monkeys and with bears well
 

00:00:42.480 --> 00:00:44.660
we do with monkeys and with bears well
my personal point of view is that both

00:00:44.660 --> 00:00:44.670
my personal point of view is that both
 

00:00:44.670 --> 00:00:47.390
my personal point of view is that both
points of view are in some sense correct

00:00:47.390 --> 00:00:47.400
points of view are in some sense correct
 

00:00:47.400 --> 00:00:51.230
points of view are in some sense correct
in the short term I think Zuckerberg is

00:00:51.230 --> 00:00:51.240
in the short term I think Zuckerberg is
 

00:00:51.240 --> 00:00:54.200
in the short term I think Zuckerberg is
right artificial intelligence will open

00:00:54.200 --> 00:00:54.210
right artificial intelligence will open
 

00:00:54.210 --> 00:00:57.020
right artificial intelligence will open
up whole new vistas it'll make life more

00:00:57.020 --> 00:00:57.030
up whole new vistas it'll make life more
 

00:00:57.030 --> 00:00:59.690
up whole new vistas it'll make life more
convenient things will be cheaper new

00:00:59.690 --> 00:00:59.700
convenient things will be cheaper new
 

00:00:59.700 --> 00:01:02.210
convenient things will be cheaper new
industries will be created I personally

00:01:02.210 --> 00:01:02.220
industries will be created I personally
 

00:01:02.220 --> 00:01:04.039
industries will be created I personally
think the AI industry will be bigger

00:01:04.039 --> 00:01:04.049
think the AI industry will be bigger
 

00:01:04.049 --> 00:01:07.400
think the AI industry will be bigger
than the automobile industry in fact I

00:01:07.400 --> 00:01:07.410
than the automobile industry in fact I
 

00:01:07.410 --> 00:01:09.500
than the automobile industry in fact I
think the automobile is going to become

00:01:09.500 --> 00:01:09.510
think the automobile is going to become
 

00:01:09.510 --> 00:01:12.110
think the automobile is going to become
a robot you'll talk to your car you'll

00:01:12.110 --> 00:01:12.120
a robot you'll talk to your car you'll
 

00:01:12.120 --> 00:01:14.480
a robot you'll talk to your car you'll
argue with your car your car will give

00:01:14.480 --> 00:01:14.490
argue with your car your car will give
 

00:01:14.490 --> 00:01:16.490
argue with your car your car will give
you the best facts the best Rob between

00:01:16.490 --> 00:01:16.500
you the best facts the best Rob between
 

00:01:16.500 --> 00:01:19.460
you the best facts the best Rob between
point A and point B the car will be part

00:01:19.460 --> 00:01:19.470
point A and point B the car will be part
 

00:01:19.470 --> 00:01:22.880
point A and point B the car will be part
of the robotics industry whole new

00:01:22.880 --> 00:01:22.890
of the robotics industry whole new
 

00:01:22.890 --> 00:01:24.440
of the robotics industry whole new
industries involving the repair

00:01:24.440 --> 00:01:24.450
industries involving the repair
 

00:01:24.450 --> 00:01:26.990
industries involving the repair
maintenance servicing of robots

00:01:26.990 --> 00:01:27.000
maintenance servicing of robots
 

00:01:27.000 --> 00:01:29.270
maintenance servicing of robots
not to mention robots that are software

00:01:29.270 --> 00:01:29.280
not to mention robots that are software
 

00:01:29.280 --> 00:01:31.490
not to mention robots that are software
programs that you talk to and make life

00:01:31.490 --> 00:01:31.500
programs that you talk to and make life
 

00:01:31.500 --> 00:01:34.580
programs that you talk to and make life
more convenient however let's not be

00:01:34.580 --> 00:01:34.590
more convenient however let's not be
 

00:01:34.590 --> 00:01:37.850
more convenient however let's not be
naive there is a point a tipping point

00:01:37.850 --> 00:01:37.860
naive there is a point a tipping point
 

00:01:37.860 --> 00:01:40.790
naive there is a point a tipping point
at which they could become dangerous and

00:01:40.790 --> 00:01:40.800
at which they could become dangerous and
 

00:01:40.800 --> 00:01:43.490
at which they could become dangerous and
pose an existential threat and that

00:01:43.490 --> 00:01:43.500
pose an existential threat and that
 

00:01:43.500 --> 00:01:47.539
pose an existential threat and that
tipping point is self-awareness you see

00:01:47.539 --> 00:01:47.549
tipping point is self-awareness you see
 

00:01:47.549 --> 00:01:49.910
tipping point is self-awareness you see
robots are not aware of the fact that

00:01:49.910 --> 00:01:49.920
robots are not aware of the fact that
 

00:01:49.920 --> 00:01:52.340
robots are not aware of the fact that
they're robots they're so stupid

00:01:52.340 --> 00:01:52.350
they're robots they're so stupid
 

00:01:52.350 --> 00:01:54.530
they're robots they're so stupid
they simply carry out what they are

00:01:54.530 --> 00:01:54.540
they simply carry out what they are
 

00:01:54.540 --> 00:01:57.170
they simply carry out what they are
instructed to do because they're adding

00:01:57.170 --> 00:01:57.180
instructed to do because they're adding
 

00:01:57.180 --> 00:01:59.810
instructed to do because they're adding
machines we forget that any machines

00:01:59.810 --> 00:01:59.820
machines we forget that any machines
 

00:01:59.820 --> 00:02:02.210
machines we forget that any machines
don't have a will adding machines simply

00:02:02.210 --> 00:02:02.220
don't have a will adding machines simply
 

00:02:02.220 --> 00:02:04.700
don't have a will adding machines simply
do when you program to do now of course

00:02:04.700 --> 00:02:04.710
do when you program to do now of course
 

00:02:04.710 --> 00:02:07.160
do when you program to do now of course
let's not be naive about this eventually

00:02:07.160 --> 00:02:07.170
let's not be naive about this eventually
 

00:02:07.170 --> 00:02:09.969
let's not be naive about this eventually
adding machines may be able to compute

00:02:09.969 --> 00:02:09.979
adding machines may be able to compute
 

00:02:09.979 --> 00:02:13.660
adding machines may be able to compute
alternate goals in alternate scenarios

00:02:13.660 --> 00:02:13.670
alternate goals in alternate scenarios
 

00:02:13.670 --> 00:02:16.370
alternate goals in alternate scenarios
when they realize that they aren't

00:02:16.370 --> 00:02:16.380
when they realize that they aren't
 

00:02:16.380 --> 00:02:19.490
when they realize that they aren't
human right now robots do not know that

00:02:19.490 --> 00:02:19.500
human right now robots do not know that
 

00:02:19.500 --> 00:02:21.680
human right now robots do not know that
however there is a tipping point at

00:02:21.680 --> 00:02:21.690
however there is a tipping point at
 

00:02:21.690 --> 00:02:23.050
however there is a tipping point at
which point they could become dangerous

00:02:23.050 --> 00:02:23.060
which point they could become dangerous
 

00:02:23.060 --> 00:02:25.940
which point they could become dangerous
now right now our most advanced robot

00:02:25.940 --> 00:02:25.950
now right now our most advanced robot
 

00:02:25.950 --> 00:02:28.700
now right now our most advanced robot
has the intelligence of a cockroach a

00:02:28.700 --> 00:02:28.710
has the intelligence of a cockroach a
 

00:02:28.710 --> 00:02:32.090
has the intelligence of a cockroach a
rather stupid cockroach however it's

00:02:32.090 --> 00:02:32.100
rather stupid cockroach however it's
 

00:02:32.100 --> 00:02:33.740
rather stupid cockroach however it's
only a matter of time before robots

00:02:33.740 --> 00:02:33.750
only a matter of time before robots
 

00:02:33.750 --> 00:02:36.950
only a matter of time before robots
become as smart as a mouse then as smart

00:02:36.950 --> 00:02:36.960
become as smart as a mouse then as smart
 

00:02:36.960 --> 00:02:40.610
become as smart as a mouse then as smart
as a rat then a rabbit then a cat dog

00:02:40.610 --> 00:02:40.620
as a rat then a rabbit then a cat dog
 

00:02:40.620 --> 00:02:44.240
as a rat then a rabbit then a cat dog
and eventually as smart as a monkey now

00:02:44.240 --> 00:02:44.250
and eventually as smart as a monkey now
 

00:02:44.250 --> 00:02:47.540
and eventually as smart as a monkey now
monkeys know they are not human they

00:02:47.540 --> 00:02:47.550
monkeys know they are not human they
 

00:02:47.550 --> 00:02:49.330
monkeys know they are not human they
have a certain amount of self-awareness

00:02:49.330 --> 00:02:49.340
have a certain amount of self-awareness
 

00:02:49.340 --> 00:02:52.370
have a certain amount of self-awareness
dogs especially young dogs are not quite

00:02:52.370 --> 00:02:52.380
dogs especially young dogs are not quite
 

00:02:52.380 --> 00:02:55.280
dogs especially young dogs are not quite
sure one reason why dogs obey the master

00:02:55.280 --> 00:02:55.290
sure one reason why dogs obey the master
 

00:02:55.290 --> 00:02:57.170
sure one reason why dogs obey the master
is because they think the master is the

00:02:57.170 --> 00:02:57.180
is because they think the master is the
 

00:02:57.180 --> 00:02:59.480
is because they think the master is the
top dog and so there will be confused

00:02:59.480 --> 00:02:59.490
top dog and so there will be confused
 

00:02:59.490 --> 00:03:02.270
top dog and so there will be confused
about whether or not we humans are part

00:03:02.270 --> 00:03:02.280
about whether or not we humans are part
 

00:03:02.280 --> 00:03:04.790
about whether or not we humans are part
of the dog tribe but monkeys I think

00:03:04.790 --> 00:03:04.800
of the dog tribe but monkeys I think
 

00:03:04.800 --> 00:03:07.190
of the dog tribe but monkeys I think
have no no problems with that they know

00:03:07.190 --> 00:03:07.200
have no no problems with that they know
 

00:03:07.200 --> 00:03:09.680
have no no problems with that they know
they're not human so when robots become

00:03:09.680 --> 00:03:09.690
they're not human so when robots become
 

00:03:09.690 --> 00:03:11.450
they're not human so when robots become
as intelligent as monkeys I think we

00:03:11.450 --> 00:03:11.460
as intelligent as monkeys I think we
 

00:03:11.460 --> 00:03:13.190
as intelligent as monkeys I think we
should put a chip in their brain that

00:03:13.190 --> 00:03:13.200
should put a chip in their brain that
 

00:03:13.200 --> 00:03:15.470
should put a chip in their brain that
shut them off if they begin to have

00:03:15.470 --> 00:03:15.480
shut them off if they begin to have
 

00:03:15.480 --> 00:03:17.720
shut them off if they begin to have
murderous thoughts when will that happen

00:03:17.720 --> 00:03:17.730
murderous thoughts when will that happen
 

00:03:17.730 --> 00:03:21.860
murderous thoughts when will that happen
I don't know I suspect it'll happen late

00:03:21.860 --> 00:03:21.870
I don't know I suspect it'll happen late
 

00:03:21.870 --> 00:03:24.530
I don't know I suspect it'll happen late
in this century because I think we have

00:03:24.530 --> 00:03:24.540
in this century because I think we have
 

00:03:24.540 --> 00:03:27.650
in this century because I think we have
decades of experience that have to be

00:03:27.650 --> 00:03:27.660
decades of experience that have to be
 

00:03:27.660 --> 00:03:29.870
decades of experience that have to be
that haven't we have to go through and

00:03:29.870 --> 00:03:29.880
that haven't we have to go through and
 

00:03:29.880 --> 00:03:33.200
that haven't we have to go through and
learn before we can pose this particular

00:03:33.200 --> 00:03:33.210
learn before we can pose this particular
 

00:03:33.210 --> 00:03:35.990
learn before we can pose this particular
problem so in other words I don't think

00:03:35.990 --> 00:03:36.000
problem so in other words I don't think
 

00:03:36.000 --> 00:03:38.660
problem so in other words I don't think
there's any rush today to deal with

00:03:38.660 --> 00:03:38.670
there's any rush today to deal with
 

00:03:38.670 --> 00:03:40.760
there's any rush today to deal with
killer robots that are gonna destroy the

00:03:40.760 --> 00:03:40.770
killer robots that are gonna destroy the
 

00:03:40.770 --> 00:03:43.340
killer robots that are gonna destroy the
human race and take over but I think we

00:03:43.340 --> 00:03:43.350
human race and take over but I think we
 

00:03:43.350 --> 00:03:45.380
human race and take over but I think we
have to keep one eye one eye in the ball

00:03:45.380 --> 00:03:45.390
have to keep one eye one eye in the ball
 

00:03:45.390 --> 00:03:47.390
have to keep one eye one eye in the ball
and realize that by the end of this

00:03:47.390 --> 00:03:47.400
and realize that by the end of this
 

00:03:47.400 --> 00:03:49.790
and realize that by the end of this
century when robots do become self-aware

00:03:49.790 --> 00:03:49.800
century when robots do become self-aware
 

00:03:49.800 --> 00:03:53.330
century when robots do become self-aware
we have to be careful

00:03:53.330 --> 00:03:53.340
we have to be careful
 

00:03:53.340 --> 00:03:56.590
we have to be careful
[Music]

