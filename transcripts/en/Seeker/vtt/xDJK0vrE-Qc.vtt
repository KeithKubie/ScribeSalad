WEBVTT
Kind: captions
Language: en

00:00:00.187 --> 00:00:02.145
Do you think you could
be friends with a robot?

00:00:02.145 --> 00:00:03.960
Would you maybe
even die for one?

00:00:09.969 --> 00:00:11.010
Anthony here, for D News.

00:00:11.010 --> 00:00:13.550
And we love to
anthropomorphic stuff.

00:00:13.550 --> 00:00:15.390
That's where we
assign human qualities

00:00:15.390 --> 00:00:16.710
to animals or objects.

00:00:16.710 --> 00:00:19.180
You know like, that electrical
socket looks hungry,

00:00:19.180 --> 00:00:21.160
or that lamp is sad.

00:00:21.160 --> 00:00:24.560
Probably because that electrical
socket is eating its tail.

00:00:24.560 --> 00:00:26.740
Researchers think it
helps us feel connected

00:00:26.740 --> 00:00:28.720
to things, gives us
a feeling of control.

00:00:28.720 --> 00:00:30.910
We might not understand
why our car is broken down,

00:00:30.910 --> 00:00:33.080
but it makes us feel
less overwhelmed to say,

00:00:33.080 --> 00:00:34.300
oh, it's just mad at me.

00:00:34.300 --> 00:00:36.630
This becomes particularly
interesting with something

00:00:36.630 --> 00:00:39.150
like a robot, which is
built to actually behave

00:00:39.150 --> 00:00:40.940
like it does have
a mind of its own.

00:00:40.940 --> 00:00:43.100
Recently a lot of studies
and pilot programs

00:00:43.100 --> 00:00:46.050
have shown that the elderly
and disabled, especially people

00:00:46.050 --> 00:00:49.510
with dementia can benefit from
the social interaction that

00:00:49.510 --> 00:00:52.520
comes with having a
simple robot in the house.

00:00:52.520 --> 00:00:54.390
It can keep them
more engaged and make

00:00:54.390 --> 00:00:56.000
them feel less isolated.

00:00:56.000 --> 00:00:58.940
But there's a downside to that
sort of anthropomorphizing.

00:00:58.940 --> 00:01:01.060
A recent university
of Washington study

00:01:01.060 --> 00:01:03.750
suggests that forming
emotional bond to a robot

00:01:03.750 --> 00:01:06.810
might affect a soldiers
outcome in the field.

00:01:06.810 --> 00:01:09.540
See, robots are used for a
lot of reasons in battle.

00:01:09.540 --> 00:01:12.220
Everything from weapon
diffusion to search and rescue,

00:01:12.220 --> 00:01:13.190
even combat.

00:01:13.190 --> 00:01:16.000
There a tool design to keep
humans out of harm's way.

00:01:16.000 --> 00:01:18.140
But after a while,
soldiers begin

00:01:18.140 --> 00:01:19.790
to look at them as friends.

00:01:19.790 --> 00:01:23.220
And the concern is that might
compromise their decision

00:01:23.220 --> 00:01:23.880
making.

00:01:23.880 --> 00:01:26.270
23 soldiers that work
regularly with robots

00:01:26.270 --> 00:01:27.840
were interviewed
by the researchers.

00:01:27.840 --> 00:01:29.980
And they all said that
they named their robots,

00:01:29.980 --> 00:01:31.770
they gave their
robots a gender, they

00:01:31.770 --> 00:01:33.520
admitted to having
feelings of sadness

00:01:33.520 --> 00:01:35.310
or anger when the
robot got damaged.

00:01:35.310 --> 00:01:37.790
They would say things
like, oh poor little guy.

00:01:37.790 --> 00:01:41.149
And in some cases, the soldiers
admitted to a feeling of loss

00:01:41.149 --> 00:01:42.690
when the robot was
destroyed and even

00:01:42.690 --> 00:01:44.230
had mock funerals for them.

00:01:44.230 --> 00:01:46.170
They're considered team members.

00:01:46.170 --> 00:01:48.310
But while they admitted to
thinking of their robots

00:01:48.310 --> 00:01:50.460
as little buddies, every
soldier interviewed

00:01:50.460 --> 00:01:53.710
said that they did not believe
that that outlook compromised

00:01:53.710 --> 00:01:56.100
their decision making
in the field at all.

00:01:56.100 --> 00:01:57.710
Which is probably true.

00:01:57.710 --> 00:02:00.380
But it would require much
more long term observation

00:02:00.380 --> 00:02:02.610
of their behavior in the
field to actually prove it.

00:02:02.610 --> 00:02:04.490
Researchers are more
concerned about what

00:02:04.490 --> 00:02:08.100
happens when the current simple
Rover Wally looking robots

00:02:08.100 --> 00:02:11.980
are replaced by humanoid or
animal like ones like Boston

00:02:11.980 --> 00:02:13.090
Dynamics big dog.

00:02:13.090 --> 00:02:15.660
The more a robot seems
like a living thing,

00:02:15.660 --> 00:02:17.300
the more we get attached to it.

00:02:17.300 --> 00:02:20.220
And the more we begin to give
it credit for more intelligence

00:02:20.220 --> 00:02:21.782
or ability than it actually has.

00:02:21.782 --> 00:02:23.740
And that doesn't just
mean physical appearance,

00:02:23.740 --> 00:02:26.570
that means movement or
other behavior as well.

00:02:26.570 --> 00:02:28.750
So how lifelike
would a robot have

00:02:28.750 --> 00:02:32.370
to be before a soldier really
does look at it like a pet?

00:02:32.370 --> 00:02:33.660
Or even like another soldier?

00:02:33.660 --> 00:02:36.310
And could it lead them to
make emotionally inappropriate

00:02:36.310 --> 00:02:39.500
decisions to keep that
robot out of harm's way?

00:02:39.500 --> 00:02:41.980
I worry about my
neighbors in animal

00:02:41.980 --> 00:02:43.890
crossing like they
are real people.

00:02:43.890 --> 00:02:46.350
So I can absolutely
see myself getting way

00:02:46.350 --> 00:02:47.356
to attached to a robot.

00:02:47.356 --> 00:02:47.980
What about you?

00:02:47.980 --> 00:02:49.570
Do you think that
we will eventually

00:02:49.570 --> 00:02:50.910
see robots as friends?

00:02:50.910 --> 00:02:53.360
Or will we always be able
to think of them as tools?

00:02:53.360 --> 00:02:57.280
Let us know down below and
subscribe for more D News.

