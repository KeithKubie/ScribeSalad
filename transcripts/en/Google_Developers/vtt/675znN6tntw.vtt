WEBVTT
Kind: captions
Language: en

00:00:00.419 --> 00:00:02.210
JF BASTIEN: Speed
matters for applications.

00:00:02.210 --> 00:00:04.330
You could be doing
intense image processing,

00:00:04.330 --> 00:00:06.720
complex scientific
computing, or just delighting

00:00:06.720 --> 00:00:08.540
users with an immersive game.

00:00:08.540 --> 00:00:11.630
Portable Native Client
brings speed to the web.

00:00:11.630 --> 00:00:13.880
I'm JF, lead engineer on
portable code performance,

00:00:13.880 --> 00:00:16.280
and I'm going to walk you
through how PNaCl delivers

00:00:16.280 --> 00:00:19.900
the speed your users
demand and you deserve.

00:00:19.900 --> 00:00:22.880
Going faster allows
us for better games,

00:00:22.880 --> 00:00:25.680
makes users wait less when they
interact with applications,

00:00:25.680 --> 00:00:28.170
and reduces the amount of
energy used by the device.

00:00:28.170 --> 00:00:30.550
And as we all know,
longer battery life

00:00:30.550 --> 00:00:33.206
means more game play
time and happier users.

00:00:33.206 --> 00:00:35.455
Modern processors have a
treasure trove of performance

00:00:35.455 --> 00:00:37.090
that often goes unused.

00:00:37.090 --> 00:00:38.850
Let's explore a few
kinds of parallelism

00:00:38.850 --> 00:00:41.030
that unlock this performance.

00:00:41.030 --> 00:00:43.330
One source of parallelism
is at the task level,

00:00:43.330 --> 00:00:45.650
where independent
work is conducted

00:00:45.650 --> 00:00:47.820
in parallel on multiple cores.

00:00:47.820 --> 00:00:50.410
This is achieved in PNaCl
through POSIX Threads, which

00:00:50.410 --> 00:00:52.480
have been available
since launch.

00:00:52.480 --> 00:00:55.910
Another type of parallelism
is at the instruction level.

00:00:55.910 --> 00:00:58.460
Modern CPUs fetch an
instruction stream

00:00:58.460 --> 00:01:03.240
and decode, reorder, schedule,
and execute instructions

00:01:03.240 --> 00:01:05.540
using a plethora of
functional units, all

00:01:05.540 --> 00:01:07.340
in a very deep pipeline.

00:01:07.340 --> 00:01:09.160
This parallelism allows
the CPU to execute

00:01:09.160 --> 00:01:12.110
multiple different
instructions at the same time

00:01:12.110 --> 00:01:14.310
and is mostly free
for programmers.

00:01:14.310 --> 00:01:16.910
Typically, this has been the
realm of compile engineers.

00:01:16.910 --> 00:01:20.140
But it turns out that those
functional units are just there

00:01:20.140 --> 00:01:21.350
waiting to do something.

00:01:21.350 --> 00:01:23.525
And some of them
are pretty powerful,

00:01:23.525 --> 00:01:25.440
yet usually go unused.

00:01:25.440 --> 00:01:26.960
If you don't use
them, then your CPU

00:01:26.960 --> 00:01:28.340
isn't showcasing its full power.

00:01:28.340 --> 00:01:30.560
It's leaking power
instead, trickling

00:01:30.560 --> 00:01:34.112
in small amounts of work
instead of going to sleep.

00:01:34.112 --> 00:01:36.070
Let's zoom into one of
the previously mentioned

00:01:36.070 --> 00:01:37.750
functional units.

00:01:37.750 --> 00:01:40.570
Programming languages typically
expose scalar instructions,

00:01:40.570 --> 00:01:43.530
shown here, as a stream
of four instructions.

00:01:43.530 --> 00:01:46.950
The CPU loads one input data
per instruction and then

00:01:46.950 --> 00:01:49.190
executes one
instruction to generate

00:01:49.190 --> 00:01:51.640
one output data per instruction.

00:01:51.640 --> 00:01:53.920
This is a scalar way to
do computation, which

00:01:53.920 --> 00:01:55.650
gets the job done,
but it doesn't fully

00:01:55.650 --> 00:01:57.440
use the CPU's capabilities.

00:01:57.440 --> 00:01:59.460
CPUs have more than
just load, store,

00:01:59.460 --> 00:02:01.350
and scalar functional units.

00:02:01.350 --> 00:02:03.430
And that's where data
parallelism comes in,

00:02:03.430 --> 00:02:06.540
where the functional unit
takes instructions and performs

00:02:06.540 --> 00:02:09.080
the same work on
multiple sources of data

00:02:09.080 --> 00:02:11.580
per instruction,
generating multiple output

00:02:11.580 --> 00:02:13.310
data per instruction.

00:02:13.310 --> 00:02:16.611
This single instruction multiple
data model is called SIMD.

00:02:16.611 --> 00:02:18.360
There's still a single
instruction stream,

00:02:18.360 --> 00:02:21.930
but multiple pieces of data
are fetched at the same time,

00:02:21.930 --> 00:02:24.760
operated on, and multiple
corresponding outputs

00:02:24.760 --> 00:02:26.080
are created.

00:02:26.080 --> 00:02:28.970
The SIMD functional unit
can perform 2, 4, 8, 16

00:02:28.970 --> 00:02:31.880
or more operations in
a single instruction.

00:02:31.880 --> 00:02:33.244
Let's look at some code.

00:02:33.244 --> 00:02:35.160
SIMD is usually expressed
through architecture

00:02:35.160 --> 00:02:37.390
specific assembly
code or intrinsics--

00:02:37.390 --> 00:02:40.820
SSC and AVX on x86
and NEON on ARM.

00:02:40.820 --> 00:02:43.320
PNaCl expresses SIMD using
portable intrinsics that

00:02:43.320 --> 00:02:45.725
are very similar to those
used on x86 and ARM.

00:02:45.725 --> 00:02:48.870
And those intrinsics lower to
efficient code for each target

00:02:48.870 --> 00:02:50.400
architecture.

00:02:50.400 --> 00:02:52.940
You can see a great example
of PNaCl in action by taking

00:02:52.940 --> 00:02:55.500
a look at Google+ Photos editor.

00:02:55.500 --> 00:02:58.060
The team took existing photo
filtering software written

00:02:58.060 --> 00:03:01.460
in C++ and were able to use
it directly in the browser.

00:03:01.460 --> 00:03:05.090
Photo filtering typically uses
many forms of parallelism,

00:03:05.090 --> 00:03:06.380
including SIMD.

00:03:06.380 --> 00:03:08.960
And they operate very
fast on large images

00:03:08.960 --> 00:03:12.270
by using fairly complex imaging
pipelines, most of which

00:03:12.270 --> 00:03:14.010
are inscrutably
complicated to me.

00:03:14.010 --> 00:03:16.960
But hey, they work
and they're fast.

00:03:16.960 --> 00:03:19.350
Those complex pipelines
deliver beautiful results,

00:03:19.350 --> 00:03:21.320
and allow users to add
some magical elements

00:03:21.320 --> 00:03:22.720
to their pictures.

00:03:22.720 --> 00:03:25.270
Using portable SIMD
intrinsics was minimal effort

00:03:25.270 --> 00:03:28.190
on the photo team's part
because some of their filters

00:03:28.190 --> 00:03:32.070
use a language called Halide, an
open source language developed

00:03:32.070 --> 00:03:35.550
at MIT, which simplifies
image processing by decoupling

00:03:35.550 --> 00:03:39.320
the algorithm from its schedule.

00:03:39.320 --> 00:03:43.630
Sometimes it's more efficient
to compute images breadth first.

00:03:43.630 --> 00:03:46.600
Sometimes it's better to
fuse value computations, use

00:03:46.600 --> 00:03:51.080
sliding Windows or tiles,
or even a mix of techniques.

00:03:51.080 --> 00:03:53.430
SIMD plays a small
but critical part

00:03:53.430 --> 00:03:55.590
in using all of the
CPU's capabilities,

00:03:55.590 --> 00:03:59.220
and Halide's biggest strength is
in expressing image processing

00:03:59.220 --> 00:04:01.480
algorithms and mapping
them very efficiently

00:04:01.480 --> 00:04:04.640
onto the underlying
machine, as shown here.

00:04:04.640 --> 00:04:07.520
Applications which are suited
to Halide's computational model

00:04:07.520 --> 00:04:10.130
should definitely
consider using it.

00:04:10.130 --> 00:04:13.290
Here's another usage of SIMD
as well as threads on the web.

00:04:13.290 --> 00:04:15.880
Folding@Home does protein
folding for medical research

00:04:15.880 --> 00:04:18.730
to help cure diseases like
Parkinson's, Alzheimer's,

00:04:18.730 --> 00:04:19.930
and cancer.

00:04:19.930 --> 00:04:22.330
Protein folding is
incredibly complex,

00:04:22.330 --> 00:04:23.970
and the research
greatly benefits

00:04:23.970 --> 00:04:25.890
from the web's huge reach.

00:04:25.890 --> 00:04:29.170
Merely using PNaCl over the
usual web platform increases

00:04:29.170 --> 00:04:32.170
performance by two to
four X. Using threads

00:04:32.170 --> 00:04:35.470
is a multiple that's roughly
linear the number of CPU cores.

00:04:35.470 --> 00:04:39.450
And using SIMD is yet
another two to four X.

00:04:39.450 --> 00:04:41.450
The Chrome browser enables
these great speed ups

00:04:41.450 --> 00:04:44.730
through PNaCl with technologies
like threading and intrinsics.

00:04:44.730 --> 00:04:46.750
That doesn't mean that
your development process

00:04:46.750 --> 00:04:49.130
on other browsers
have to suffer though.

00:04:49.130 --> 00:04:51.850
PNaCl offers a powerful
tool chain based on LVM,

00:04:51.850 --> 00:04:55.430
and we support generating
PNaCl executables, as well

00:04:55.430 --> 00:04:59.080
as JavaScript ones, so you can
fold proteins in all browsers.

00:04:59.080 --> 00:05:02.490
This is done through pepper.js,
which relies on Emscripten.

00:05:02.490 --> 00:05:05.020
While this fall back
comes with some caveats,

00:05:05.020 --> 00:05:07.600
we strongly believe in
evolutionary improvements

00:05:07.600 --> 00:05:10.460
to the web platform as
well as revolutionary ones,

00:05:10.460 --> 00:05:14.265
such as what I've
just presented.

00:05:14.265 --> 00:05:16.890
This completes our brief tour of
some of the latest performance

00:05:16.890 --> 00:05:18.920
improvements we've
brought to PNaCl.

00:05:18.920 --> 00:05:22.620
SIMD will be available in
PNaCl as part of Chrome 37,

00:05:22.620 --> 00:05:24.530
to be released at
the end of August.

00:05:24.530 --> 00:05:26.902
For more, check out
our site gonacl.com.

00:05:26.902 --> 00:05:29.235
We're just getting started
with performance improvements

00:05:29.235 --> 00:05:30.730
to the PNaCl platform.

00:05:30.730 --> 00:05:33.630
On the SIMD side, performance
will improve significantly

00:05:33.630 --> 00:05:35.400
over the next few
releases, and we'll

00:05:35.400 --> 00:05:38.230
add powerful new intrinsics
as well as fun features

00:05:38.230 --> 00:05:39.850
like auto-vectorization.

00:05:39.850 --> 00:05:43.510
It's now your turn to use
all this power on the web.

00:05:43.510 --> 00:05:45.120
Thank you.

