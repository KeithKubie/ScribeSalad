WEBVTT
Kind: captions
Language: en

00:00:00.270 --> 00:00:05.040
So today I'm talking Doctor Jimeng Sun
from right here at Georgia Tech.

00:00:05.040 --> 00:00:10.900
Jimeng joined us earlier this year
after many years at IBM, where his

00:00:10.900 --> 00:00:16.440
work has depended heavily on analyzing
data from electronic health records.

00:00:16.440 --> 00:00:21.090
Jimeng thanks very much for
taking the time to be in the course.

00:00:21.090 --> 00:00:25.700
I've heard you talk many times about the
difficulties of working with EHR data.

00:00:25.700 --> 00:00:28.490
Could you explain some of
those to the students?

00:00:28.490 --> 00:00:29.030
&gt;&gt; Sure.

00:00:29.030 --> 00:00:30.990
First, Mark great to be here.

00:00:32.420 --> 00:00:37.470
So electronic health records very
important for my research and

00:00:37.470 --> 00:00:41.660
many other people who work
on clinical informatics,

00:00:41.660 --> 00:00:46.600
house care informatics, also need
to access electronic house records.

00:00:46.600 --> 00:00:53.220
But electronic house record is very
messy, and lot of missing data in there,

00:00:53.220 --> 00:00:59.630
because they are collected for
billing and clinical operation purpose.

00:00:59.630 --> 00:01:01.750
They're not designed for research.

00:01:01.750 --> 00:01:06.730
So there are a lot of information
in the HR systems, but for a given

00:01:06.730 --> 00:01:12.520
patient they only have a small subset
of those, and they're not uniform.

00:01:12.520 --> 00:01:16.340
So some patient have a lot more
information than the others, and

00:01:16.340 --> 00:01:21.060
that makes the electronic health records
very messy, very difficult to deal with.

00:01:21.060 --> 00:01:24.800
The other thing is,
there are just a lot of different kinds

00:01:24.800 --> 00:01:29.050
of information that are in EHR systems,
and it's getting more and more.

00:01:29.050 --> 00:01:34.910
For example, there are diagnosis
information such as ICD code in there.

00:01:34.910 --> 00:01:38.760
And their medication information,
there's lab test.

00:01:38.760 --> 00:01:42.630
And their clinical notes
represented as free text.

00:01:42.630 --> 00:01:44.000
And their medical images.

00:01:45.280 --> 00:01:49.590
And more and more genomic data
getting into the EHR system.

00:01:49.590 --> 00:01:54.640
So all of those different type of
information requires different kind of

00:01:54.640 --> 00:01:58.330
techniques to process them,
to analyze them.

00:01:58.330 --> 00:01:59.040
For example,

00:01:59.040 --> 00:02:04.920
for text data like clinical notes,
you need natural language processing.

00:02:04.920 --> 00:02:10.160
And for image, you need specialized
medical image analysis tools.

00:02:10.160 --> 00:02:13.690
For structured data like
diagnosis medications,

00:02:13.690 --> 00:02:17.820
you would use general
data mining techniques.

00:02:17.820 --> 00:02:22.880
So people have to be able to pick the
right tools to deal with the right data.

00:02:22.880 --> 00:02:25.750
&gt;&gt; In a moment, we're going to talk
about some work you've done around

00:02:25.750 --> 00:02:28.830
the early diagnosis of
congestive heart failure.

00:02:28.830 --> 00:02:32.130
Which is interesting, particularly
within the context of this course,

00:02:32.130 --> 00:02:36.280
because chronic disease has really been
the exemplar I've used throughout.

00:02:36.280 --> 00:02:42.730
But first, in that work,
you've had to use that free text data.

00:02:42.730 --> 00:02:47.210
And in fact, you've extracted from it,
clinical features.

00:02:47.210 --> 00:02:51.090
That can be used by a machine
learning algorithms.

00:02:51.090 --> 00:02:52.430
So how do you do that?

00:02:52.430 --> 00:02:53.040
How does that work?

00:02:54.090 --> 00:02:56.850
&gt;&gt; Right so first for
people who are not so

00:02:56.850 --> 00:03:01.920
familiar with clinical notes,
it's very rich information.

00:03:01.920 --> 00:03:08.170
A lot of subtlety and a lot of
symptoms are represented in the notes.

00:03:08.170 --> 00:03:10.160
Only in the notes,
not in the structured data.

00:03:10.160 --> 00:03:14.350
So, it's very important to process
the clinical notes, to extract

00:03:14.350 --> 00:03:19.250
those symptom information, the severity
information that are hidden in the text.

00:03:19.250 --> 00:03:23.820
So, that's the reason of why we
need to process clinical notes.

00:03:23.820 --> 00:03:30.130
And the way we did that is
to use a softer pipeline for

00:03:30.130 --> 00:03:34.768
dealing with test called UIMA,
unstructure information

00:03:34.768 --> 00:03:40.520
management architecture that's
originally developed at IBM research and

00:03:40.520 --> 00:03:45.780
later on becomes an open source project
that many people are using that.

00:03:45.780 --> 00:03:48.006
Including later on the Watson project.

00:03:48.006 --> 00:03:54.480
So it's facilitate natural language
processing development and you develop

00:03:54.480 --> 00:03:59.820
a pipeline of extractors to go through
the text, extracting the information

00:03:59.820 --> 00:04:04.540
that you cares about like symptoms
that related to heart failures so

00:04:04.540 --> 00:04:10.370
we used heart failure signs and
symptoms, and also the context.

00:04:10.370 --> 00:04:14.940
You not only want to know the symptoms
are present in the texts, but

00:04:14.940 --> 00:04:18.950
also whether it's in
the positive context,

00:04:18.950 --> 00:04:22.550
meaning that the patient is
confirmed to have the symptoms, or

00:04:22.550 --> 00:04:27.290
it's in the negative context,
the patient doesn't have the symptom.

00:04:27.290 --> 00:04:29.800
So, you also need to know the context.

00:04:29.800 --> 00:04:32.920
So, we did many different extractors and

00:04:32.920 --> 00:04:35.700
to extract that information and
also the context.

00:04:35.700 --> 00:04:37.280
So, it's a lot of work.

00:04:37.280 --> 00:04:39.350
&gt;&gt; So armed with that information and

00:04:39.350 --> 00:04:43.840
the structured information, you've
developed a machine monitoring algorithm

00:04:43.840 --> 00:04:47.190
to diagnose congestive
heart failure earlier.

00:04:47.190 --> 00:04:51.230
I should mention to the students
without a clinical background that

00:04:51.230 --> 00:04:54.880
congestive heart failure is the single
most expensive medical condition.

00:04:56.440 --> 00:05:01.040
And that diagnosing and treating it
early, as we discussed in the course,

00:05:01.040 --> 00:05:02.510
is true of most chronic diseases,

00:05:02.510 --> 00:05:07.500
we can hope to avoid the complications
that are very expensive to treat.

00:05:07.500 --> 00:05:13.680
But it's very subtle at first, there
is no test like a blood glucose you can

00:05:13.680 --> 00:05:18.420
take, or a hemoglobin A1C to say
you've got congestive heart failure.

00:05:18.420 --> 00:05:23.760
So clinicians often don't pick up on
it as early as might be the case.

00:05:23.760 --> 00:05:26.100
Your model does,
can you tell us how you did that?

00:05:27.180 --> 00:05:32.510
&gt;&gt; Right, so that's a project we
started when I was at IBM Research

00:05:32.510 --> 00:05:37.860
a few years ago in collaboration
with Geisinger health systems.

00:05:37.860 --> 00:05:41.980
So we would visit Geisinger and I mean,
trying to learn about what are the most

00:05:41.980 --> 00:05:45.605
important or challenging problems
that we can tackle together,

00:05:45.605 --> 00:05:49.300
using data-mining machine
learning techniques.

00:05:49.300 --> 00:05:52.400
And they identify heart failures, one.

00:05:52.400 --> 00:05:57.480
And at times, there are already many
groups are interested in heart failures.

00:05:57.480 --> 00:06:03.220
Mostly in the post-diagnosis
phases in terms of readmission,

00:06:03.220 --> 00:06:06.515
hospitalization, readmission
after heart failure's diagnosis.

00:06:06.515 --> 00:06:09.616
But that groups in Geisinger, the focuc,

00:06:09.616 --> 00:06:14.613
they wanted to look at pre-diagnosis,
look at what are the signs and

00:06:14.613 --> 00:06:18.650
symptoms that lead to
diagnosis of heart failures.

00:06:18.650 --> 00:06:24.320
Can we identify the patient of high risk
of developing heart failures earlier?

00:06:24.320 --> 00:06:27.620
So the goal is for early detection.

00:06:27.620 --> 00:06:32.080
And we leverage The first thing we
did is we want to see whether that's

00:06:32.080 --> 00:06:32.930
even possible.

00:06:32.930 --> 00:06:39.030
Are there relevant signal in the data
that earlier than the diagnosis time?

00:06:39.030 --> 00:06:43.550
And we look at the clinical notes and
that's where we first developed

00:06:43.550 --> 00:06:48.090
natural language processing
techniques to extract that and

00:06:48.090 --> 00:06:52.930
the findings from those
notes are very shocking.

00:06:52.930 --> 00:06:57.309
In fact,
just defining from the clinical notes,

00:06:57.309 --> 00:07:02.540
we're able to publish in
the journal in cardiac failures.

00:07:02.540 --> 00:07:05.010
And thus, are medical journals
that clinicians write.

00:07:05.010 --> 00:07:09.090
There are some exciting
findings in terms of signs and

00:07:09.090 --> 00:07:11.530
symptoms that in
the electronic house records

00:07:11.530 --> 00:07:15.570
two years prior to the diagnosis,
and that's very surprising.

00:07:15.570 --> 00:07:17.522
Many people don't believe those.

00:07:17.522 --> 00:07:19.809
I mean% of patients have that sign and

00:07:19.809 --> 00:07:24.360
symptom already in the clinical notes
two years before the diagnosis.

00:07:24.360 --> 00:07:27.560
So those make us believe
we can do something.

00:07:27.560 --> 00:07:34.100
Then the question is how do we really
leverage that reach the HR information.

00:07:34.100 --> 00:07:39.870
So, it would be the integrated data
analysis tools to integrate diagnosis,

00:07:39.870 --> 00:07:42.980
lab measure, and medication, and

00:07:42.980 --> 00:07:47.970
also clinical notes together to view
the very reach patient profiles.

00:07:47.970 --> 00:07:51.430
Then score those patient
profiles using advanced

00:07:52.510 --> 00:07:56.167
machine learning techniques to
be able to predict a model.

00:07:56.167 --> 00:08:00.650
And that helped us to develop this very
accurate predicting model that can

00:08:00.650 --> 00:08:06.780
predict heart failures diagnosis six to
12 months before the actual diagnosis.

