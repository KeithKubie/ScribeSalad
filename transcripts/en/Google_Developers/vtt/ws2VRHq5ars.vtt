WEBVTT
Kind: captions
Language: en

00:00:06.660 --> 00:00:10.500
JOE BEDA: Hello my name
is Joe Beda and

00:00:10.500 --> 00:00:12.630
welcome to Session 313.

00:00:12.630 --> 00:00:16.329
This is the technical details
or sort of advanced Google

00:00:16.329 --> 00:00:17.620
Compute Engine.

00:00:17.620 --> 00:00:20.600
And in this session we're going
to be going over in a

00:00:20.600 --> 00:00:23.600
little bit more depth the
different parts of a Google

00:00:23.600 --> 00:00:26.510
Compute Engine, given a little
bit more meat on the bones of

00:00:26.510 --> 00:00:28.710
how things work.

00:00:28.710 --> 00:00:31.570
We're going to show some
examples of real world

00:00:31.570 --> 00:00:33.670
applications and experiences.

00:00:33.670 --> 00:00:36.760
And then I'm going to take some
time to dig into some of

00:00:36.760 --> 00:00:41.300
the details that make Google
Compute Engine interesting and

00:00:41.300 --> 00:00:42.805
how to get the best use
out of the product.

00:00:47.350 --> 00:00:48.600
My little remote.

00:00:53.020 --> 00:00:54.270
This isn't good.

00:00:56.380 --> 00:00:59.020
There we go.

00:00:59.020 --> 00:00:59.250
OK.

00:00:59.250 --> 00:01:01.290
So just a little
bit of review.

00:01:01.290 --> 00:01:05.620
I want to cover what exactly
Compute Engine is.

00:01:05.620 --> 00:01:08.310
It's infrastructure as a service
provided by Google.

00:01:08.310 --> 00:01:11.300
And when people think
infrastructure, they usually

00:01:11.300 --> 00:01:12.590
start thinking about
virtual machines.

00:01:12.590 --> 00:01:15.880
And it's a very important part
of what we're doing.

00:01:15.880 --> 00:01:17.500
But it's only part
of the picture.

00:01:17.500 --> 00:01:19.850
So we're going to cover the
virtual machines, but I also

00:01:19.850 --> 00:01:24.660
want to talk about the network
storage and tools that go

00:01:24.660 --> 00:01:26.490
along with that.

00:01:26.490 --> 00:01:27.840
This completes the picture.

00:01:27.840 --> 00:01:32.760
And I think we have interesting
offerings at each

00:01:32.760 --> 00:01:33.860
of these levels.

00:01:33.860 --> 00:01:38.080
And we're launching in limited
preview today.

00:01:38.080 --> 00:01:42.790
And as part of that limited
preview we're concentrating on

00:01:42.790 --> 00:01:47.050
large computationally intensive
batch workloads.

00:01:47.050 --> 00:01:49.080
And as we continue to develop
the product, we're going to

00:01:49.080 --> 00:01:52.770
expand the scope of that
program and the type of

00:01:52.770 --> 00:01:55.620
workloads that we take on and
are appropriate for running on

00:01:55.620 --> 00:01:56.870
Compute Engine.

00:01:59.760 --> 00:02:03.920
So one of the things that I
think really makes Compute

00:02:03.920 --> 00:02:07.310
Engine interesting is that it
builds on top of Google's

00:02:07.310 --> 00:02:10.229
infrastructure and Google's
experiences.

00:02:10.229 --> 00:02:13.210
And this really breaks down
four different ways.

00:02:13.210 --> 00:02:14.870
So the first thing
is one of scale.

00:02:14.870 --> 00:02:18.710
And I think you saw this very
dramatically with [? Orze's ?]

00:02:18.710 --> 00:02:22.790
keynote this morning about
sort of how much scale we

00:02:22.790 --> 00:02:23.940
really have at Google.

00:02:23.940 --> 00:02:26.830
And we're really excited to
start bringing some of that

00:02:26.830 --> 00:02:30.000
capacity online so that
you can start taking

00:02:30.000 --> 00:02:32.290
advantage of it.

00:02:32.290 --> 00:02:35.030
The next thing is speed.

00:02:35.030 --> 00:02:37.680
Google's infrastructure is
optimized for search.

00:02:40.250 --> 00:02:42.900
This is an industry where one
millisecond translates to

00:02:42.900 --> 00:02:44.600
millions of dollars.

00:02:44.600 --> 00:02:48.660
And we've spent years optimizing
our infrastructure

00:02:48.660 --> 00:02:53.740
both at the software and
hardware level, and especially

00:02:53.740 --> 00:02:57.910
our networking systems, to be
able to provide low latency,

00:02:57.910 --> 00:03:02.000
high bandwidth, enormous
services, at a

00:03:02.000 --> 00:03:02.900
really unique scale.

00:03:02.900 --> 00:03:07.750
And there's no other provider
out there that actually brings

00:03:07.750 --> 00:03:10.940
together that level of scale,
that global footprint, and the

00:03:10.940 --> 00:03:14.390
comprehensive set of services
that we have.

00:03:14.390 --> 00:03:17.160
The next thing is really
our global footprint.

00:03:17.160 --> 00:03:22.215
And this is not just in terms of
where we have data centers

00:03:22.215 --> 00:03:23.730
and where we have presence.

00:03:23.730 --> 00:03:25.520
It's really about
our networking.

00:03:25.520 --> 00:03:28.240
And this comes into play in so
many different ways in terms

00:03:28.240 --> 00:03:31.040
of communicating between virtual
machines that are in

00:03:31.040 --> 00:03:34.330
different regions or how your
traffic gets from your virtual

00:03:34.330 --> 00:03:40.080
machine to any end user
out on the internet.

00:03:40.080 --> 00:03:44.365
And finally, we have a
comprehensive and growing and

00:03:44.365 --> 00:03:46.790
well integrated platform
of services.

00:03:46.790 --> 00:03:48.720
And this stretches from
everything from App Engine to

00:03:48.720 --> 00:03:51.680
Google Cloud Storage to Big
Query to Translate to Maps and

00:03:51.680 --> 00:03:53.330
all sorts of other APIs.

00:03:53.330 --> 00:03:56.370
And Google Compute Engine
complements these by allowing

00:03:56.370 --> 00:03:59.490
you to run your code in a
familiar environment close to

00:03:59.490 --> 00:04:02.060
where these API endpoints are.

00:04:06.420 --> 00:04:07.780
So I want to review you a little
bit-- if you were at

00:04:07.780 --> 00:04:10.860
the earlier talk, Craig
McLuckie's talk, he covered

00:04:10.860 --> 00:04:11.530
some of this stuff.

00:04:11.530 --> 00:04:13.950
But I want to go over it
again very quickly.

00:04:13.950 --> 00:04:16.820
What are the things that we
thought about as we built

00:04:16.820 --> 00:04:17.500
Compute Engine?

00:04:17.500 --> 00:04:20.240
And I think you'll see these
themes really reoccur as we

00:04:20.240 --> 00:04:21.950
give some concrete examples.

00:04:21.950 --> 00:04:24.910
So the first thing here is that
we built Compute Engine

00:04:24.910 --> 00:04:27.410
to be as secure as possible
from the get-go.

00:04:27.410 --> 00:04:30.400
We really thought about security
deeply, even in the

00:04:30.400 --> 00:04:31.710
very early days of
the product.

00:04:31.710 --> 00:04:35.210
And this really manifests itself
in terms of providing a

00:04:35.210 --> 00:04:39.350
secure, isolated virtual network
for each individual

00:04:39.350 --> 00:04:43.240
application or project to
encrypting all data at risk as

00:04:43.240 --> 00:04:47.760
it is written to or read from
with the virtual machine.

00:04:47.760 --> 00:04:50.380
The next thing is we want things
to be open and flexible

00:04:50.380 --> 00:04:51.110
and familiar.

00:04:51.110 --> 00:04:53.480
And this applies both at
the control layer.

00:04:53.480 --> 00:04:58.190
Our API, while it's a Google
Compute Engine specific API,

00:04:58.190 --> 00:05:00.430
we've built it to leverage
well-known

00:05:00.430 --> 00:05:02.890
concepts and to be familiar.

00:05:02.890 --> 00:05:06.620
But also within the virtual
machine we provide a familiar

00:05:06.620 --> 00:05:08.260
environment that you
can get up and

00:05:08.260 --> 00:05:09.510
running as quick as possible.

00:05:11.990 --> 00:05:15.300
The next point is really
around consistency.

00:05:15.300 --> 00:05:19.000
If you build an application, and
you test it, and it works,

00:05:19.000 --> 00:05:20.660
you want to actually feel
that it's going

00:05:20.660 --> 00:05:22.250
to continue to work.

00:05:22.250 --> 00:05:26.890
And so Google has a deep
expertise in terms of running

00:05:26.890 --> 00:05:29.990
shared workloads internally
across all of our

00:05:29.990 --> 00:05:31.960
infrastructure for our
own applications.

00:05:31.960 --> 00:05:34.990
And we've applied a lot of the
same technology there to

00:05:34.990 --> 00:05:39.770
actually provide a really
amazing level of consistency

00:05:39.770 --> 00:05:43.130
for our virtual machine
product.

00:05:43.130 --> 00:05:47.250
And finally, we want you to
know-- well, not finally.

00:05:47.250 --> 00:05:50.640
We have two more points--
proven.

00:05:50.640 --> 00:05:54.920
We're running real workloads on
this infrastructure today.

00:05:54.920 --> 00:05:59.510
And we're going to have an
example in this talk from one

00:05:59.510 --> 00:06:03.690
of our early usages
internally.

00:06:03.690 --> 00:06:06.750
But this is not a
beta product.

00:06:06.750 --> 00:06:09.240
This is actually something
that is in use.

00:06:09.240 --> 00:06:12.360
There's real Google revenue
flowing through this product

00:06:12.360 --> 00:06:15.700
today, and we're offering this
same exact product to you.

00:06:15.700 --> 00:06:18.450
And then finally, we want to
actually enable an ecosystem.

00:06:18.450 --> 00:06:23.380
We want to be able to have
partners and be able to

00:06:23.380 --> 00:06:26.810
leverage open source systems
that already exist.

00:06:26.810 --> 00:06:31.000
And again, this is either from
outside the system at the API

00:06:31.000 --> 00:06:35.900
level, but also what's running
inside the virtual machine.

00:06:35.900 --> 00:06:40.140
So to jump right in, I'm going
to invite up Evan Anderson

00:06:40.140 --> 00:06:45.680
who's another member of our team
to give you a quick Hello

00:06:45.680 --> 00:06:47.480
World type demo.

00:06:47.480 --> 00:06:48.300
Evan?

00:06:48.300 --> 00:06:50.580
EVAN ANDERSON: So I'm going to
be using our command line

00:06:50.580 --> 00:06:57.100
tools to start up a new virtual
machine and then show

00:06:57.100 --> 00:07:00.970
you a little bit about how the
API works and login, show you

00:07:00.970 --> 00:07:02.050
a few features.

00:07:02.050 --> 00:07:06.130
And you can do all of these same
things through our web

00:07:06.130 --> 00:07:08.720
API, through our web UI.

00:07:08.720 --> 00:07:12.140
But in this case, I'm going to
use the command line so that

00:07:12.140 --> 00:07:13.240
you can sort of see
a little bit more

00:07:13.240 --> 00:07:15.730
about how things happen.

00:07:15.730 --> 00:07:23.240
So each virtual machine has a
name and you can associate--

00:07:23.240 --> 00:07:24.090
you may have seen
[? Chris Eych's ?]

00:07:24.090 --> 00:07:25.340
talk earlier--

00:07:27.320 --> 00:07:30.720
various permissions
with each VM.

00:07:30.720 --> 00:07:35.110
So in this case, I'm going to
say that I want access to

00:07:35.110 --> 00:07:38.450
Google Storage and I want it
to be read write access.

00:07:38.450 --> 00:07:40.500
And it will prompt
me saying, OK.

00:07:40.500 --> 00:07:44.670
Which of these zones would you
like to launch your virtual

00:07:44.670 --> 00:07:48.600
machine in, and which
virtual machine type

00:07:48.600 --> 00:07:49.320
would you like to launch?

00:07:49.320 --> 00:07:51.270
So I'm going to launch
a four-CPU VM.

00:07:51.270 --> 00:07:54.510
And we've submitted the request

00:07:54.510 --> 00:07:56.060
to start this instance.

00:07:56.060 --> 00:07:58.990
And our API says, OK.

00:07:58.990 --> 00:08:02.400
This is instance is in the
process of being started.

00:08:02.400 --> 00:08:07.990
You can query and get the
status of this instance.

00:08:07.990 --> 00:08:11.190
And you can see that right
now it is staging.

00:08:11.190 --> 00:08:16.380
And you can also use this tool
while you're sort of debugging

00:08:16.380 --> 00:08:18.890
or figuring out how this API
works, to actually get the

00:08:18.890 --> 00:08:20.180
JSON output.

00:08:20.180 --> 00:08:25.020
And you can see there's a bunch
of properties that the

00:08:25.020 --> 00:08:29.340
summary tells you the
interesting useful stuff if

00:08:29.340 --> 00:08:30.310
you're a person.

00:08:30.310 --> 00:08:32.309
But you may be interested
in things like an

00:08:32.309 --> 00:08:34.250
ID if you're a program.

00:08:34.250 --> 00:08:41.470
So I'm going to SSH into this
VM and install a software

00:08:41.470 --> 00:08:44.310
package called Context Free,
which is used to generate

00:08:44.310 --> 00:08:46.210
algorithmic graphics.

00:08:57.200 --> 00:09:00.550
So this is just a standard
Ubuntu Linux VM.

00:09:00.550 --> 00:09:03.500
And I've got access to all
of the Ubuntu packages.

00:09:03.500 --> 00:09:06.630
Obviously, I could also build
something of my own.

00:09:06.630 --> 00:09:12.650
And I'm going to generate a
2000 by 2000 image of a

00:09:12.650 --> 00:09:18.790
Sierpinski gasket that is one
of the context-free demos.

00:09:31.500 --> 00:09:37.380
And so my virtual machine is
going, generating a bunch of

00:09:37.380 --> 00:09:40.210
fractals and it's done.

00:09:40.210 --> 00:09:42.740
One other thing I'll note, we
talked earlier about how I

00:09:42.740 --> 00:09:44.360
named this virtual
machine Demo.

00:09:44.360 --> 00:09:46.360
You can see that the host
name is actually

00:09:46.360 --> 00:09:48.090
also set to be demo.

00:09:48.090 --> 00:09:52.840
We do this via DHCP, so it
should work with most standard

00:09:52.840 --> 00:09:53.880
Linux installations.

00:09:53.880 --> 00:09:57.490
And I could just copy this
back or run Apache or

00:09:57.490 --> 00:10:00.250
something like that to show
you how this works.

00:10:00.250 --> 00:10:03.660
But I'm going to actually copy
this to Google Storage that I

00:10:03.660 --> 00:10:08.650
gave permissions to earlier and
make it publicly readable

00:10:08.650 --> 00:10:10.080
so anyone can see it.

00:10:28.340 --> 00:10:30.430
And so this gets copied.

00:10:30.430 --> 00:10:32.940
And as you can see, it's the
only one and a half megabytes,

00:10:32.940 --> 00:10:34.790
so it's pretty fast.

00:10:34.790 --> 00:10:41.870
And then we can go and look at
it at common data storage.

00:10:41.870 --> 00:10:44.210
And this should load after
a few moments.

00:10:44.210 --> 00:10:48.550
And here is the Sierpinski
triangle.

00:10:48.550 --> 00:10:51.630
As you can see, access to Google
Storage is a little bit

00:10:51.630 --> 00:10:55.040
faster from this virtual
machine than

00:10:55.040 --> 00:10:56.420
it is from my laptop.

00:10:56.420 --> 00:10:58.700
But it's loading.

00:10:58.700 --> 00:11:00.790
And I think we left
the wireless on.

00:11:00.790 --> 00:11:01.450
JOE BEDA: That's the mistake.

00:11:01.450 --> 00:11:02.750
EVAN ANDERSON: Oh,
that would do it.

00:11:02.750 --> 00:11:04.850
That would do it.

00:11:04.850 --> 00:11:08.210
So as you'll note when we're
interacting with most of this

00:11:08.210 --> 00:11:10.360
stuff, we've been using Google
Storage because it's close and

00:11:10.360 --> 00:11:14.460
it's local and not using stuff
on your local workstation,

00:11:14.460 --> 00:11:15.540
because it's further way.

00:11:15.540 --> 00:11:19.973
And with that, we'll let Joe
get back to the slides.

00:11:27.820 --> 00:11:30.010
And Joe will tell you a bit more
about how that actually

00:11:30.010 --> 00:11:30.800
comes to be.

00:11:30.800 --> 00:11:33.020
JOE BEDA: Actually, I'm going
to-- you'll have excuse me for

00:11:33.020 --> 00:11:33.760
a second here.

00:11:33.760 --> 00:11:38.830
Let's go through and turn
off the wireless.

00:11:38.830 --> 00:11:40.960
I am plugged in here, so let's
keep our fingers crossed.

00:11:44.780 --> 00:11:45.210
OK.

00:11:45.210 --> 00:11:46.250
So thank you, Evan.

00:11:46.250 --> 00:11:48.590
Hopefully that gives you a taste
of how Compute Engine

00:11:48.590 --> 00:11:51.740
works, and the familiar
environment, and then also

00:11:51.740 --> 00:11:53.180
some of the seamless
connections to

00:11:53.180 --> 00:11:54.030
other Google services.

00:11:54.030 --> 00:11:56.400
We're going to go into a lot
more detail on a lot of what

00:11:56.400 --> 00:11:57.030
you just saw.

00:11:57.030 --> 00:12:00.770
But I just wanted to jump
in real quick there.

00:12:00.770 --> 00:12:02.740
So let's cover the
architecture of

00:12:02.740 --> 00:12:03.730
Google Compute Engine.

00:12:03.730 --> 00:12:06.050
So I'm going to talk about all
the main pieces and how they

00:12:06.050 --> 00:12:08.340
fit together and give you
as much detail as I can

00:12:08.340 --> 00:12:10.650
fit into this talk.

00:12:10.650 --> 00:12:12.540
And so I have a diagram
that shows--

00:12:12.540 --> 00:12:16.430
and this is based on the diagram
that Craig had in his

00:12:16.430 --> 00:12:17.650
earlier talk.

00:12:17.650 --> 00:12:19.350
But I'm going to go through
this piece by piece and as

00:12:19.350 --> 00:12:21.500
much detail as I can here.

00:12:21.500 --> 00:12:23.440
So it really starts
with the API.

00:12:23.440 --> 00:12:25.730
And this is the model for the
different things that you can

00:12:25.730 --> 00:12:28.460
touch, and mess with,
and modify, and

00:12:28.460 --> 00:12:30.820
inspect with the system.

00:12:30.820 --> 00:12:33.750
And this is an adjacent
over HTTP API.

00:12:33.750 --> 00:12:35.310
It's REST inspired.

00:12:35.310 --> 00:12:38.460
And you're authorized to that
with OAuth 2, like pretty much

00:12:38.460 --> 00:12:40.430
every other API at Google.

00:12:40.430 --> 00:12:43.290
And the concepts here
are very familiar.

00:12:43.290 --> 00:12:45.170
I think there's probably
one or two new

00:12:45.170 --> 00:12:46.020
things on this list.

00:12:46.020 --> 00:12:47.250
And we can cover those.

00:12:47.250 --> 00:12:50.550
But we tried not to reinvent
the wheel in terms of the

00:12:50.550 --> 00:12:53.040
basic structure and concepts of
an infrastructure service.

00:12:55.860 --> 00:12:59.740
So calling this API is you can
always be a real hacker and

00:12:59.740 --> 00:13:02.390
write your JSON by
hand into telnet.

00:13:05.930 --> 00:13:07.370
But most people want some
help doing that.

00:13:07.370 --> 00:13:09.000
And so you saw the command
line tool that

00:13:09.000 --> 00:13:12.060
Evan was using earlier.

00:13:12.060 --> 00:13:14.480
We're not going to cover
it in this talk, but we

00:13:14.480 --> 00:13:16.890
also have a web UI.

00:13:16.890 --> 00:13:18.020
And then we have a
set of libraries.

00:13:18.020 --> 00:13:21.080
And these are both the standard
Google API libraries

00:13:21.080 --> 00:13:24.330
that work across a whole
slew of APIs.

00:13:24.330 --> 00:13:27.330
But we've also worked to build
a very easy-to-use

00:13:27.330 --> 00:13:32.030
Python-based API that's really
hand-tuned to provide a great

00:13:32.030 --> 00:13:33.610
experience.

00:13:33.610 --> 00:13:38.890
All of these things are open and
they use the API directly.

00:13:38.890 --> 00:13:41.250
So we're not cheating and going
around and making an end

00:13:41.250 --> 00:13:42.950
run and using special calls.

00:13:42.950 --> 00:13:46.110
So the API really is the
interface to the product.

00:13:46.110 --> 00:13:49.600
And that web UI itself is built
on top of App Engine.

00:13:49.600 --> 00:13:54.520
So this is a great example of
how App Engine can drive the

00:13:54.520 --> 00:13:59.200
Google Compute Engine API to
provide orchestration or

00:13:59.200 --> 00:14:00.630
administration.

00:14:00.630 --> 00:14:06.680
And finally, we have partners
and an ecosystem.

00:14:06.680 --> 00:14:09.730
And so they're using the API
itself to actually be able to

00:14:09.730 --> 00:14:13.070
provide services on top of
Compute Engine on your behalf.

00:14:13.070 --> 00:14:16.740
And so if you were at the
previous talk, you saw the

00:14:16.740 --> 00:14:17.790
demo from RightScale.

00:14:17.790 --> 00:14:21.360
But we've also been working
with puppet and ops code.

00:14:21.360 --> 00:14:24.640
And there's a whole slew of
systems built up around cloud

00:14:24.640 --> 00:14:28.180
management that are welcome to
use this API and we hope to

00:14:28.180 --> 00:14:29.880
really foster an ecosystem
there.

00:14:29.880 --> 00:14:33.520
And so that's both, again, at
the API level but also what's

00:14:33.520 --> 00:14:36.940
going on inside the
virtual machine.

00:14:36.940 --> 00:14:38.730
Now, there's this concept
of a project.

00:14:38.730 --> 00:14:42.560
And everything that happens in
Compute Engine happens within

00:14:42.560 --> 00:14:44.120
the context of a project.

00:14:44.120 --> 00:14:48.400
Evan in his example actually had
sort of an any file set up

00:14:48.400 --> 00:14:51.460
so that there was a default
project there.

00:14:51.460 --> 00:14:55.330
And the project is a container
for all these resources.

00:14:55.330 --> 00:14:56.650
There's a set of members
that are

00:14:56.650 --> 00:14:57.610
associated with that project.

00:14:57.610 --> 00:15:00.980
In some ways, it's very similar
to an App Engine app.

00:15:00.980 --> 00:15:02.730
But the idea here is that these
things are owned by the

00:15:02.730 --> 00:15:04.520
project, not by people.

00:15:04.520 --> 00:15:09.800
And so whenever there is an
action on the API, it's

00:15:09.800 --> 00:15:12.270
actually traced back to a person
instead of an anonymous

00:15:12.270 --> 00:15:13.530
set of credentials.

00:15:13.530 --> 00:15:16.700
And so, actually, keeping this
sort of identity of who's

00:15:16.700 --> 00:15:20.540
operating with the API is, we
think, a very unique and

00:15:20.540 --> 00:15:23.490
powerful feature.

00:15:23.490 --> 00:15:27.320
And if the API is sort of the
front door to the product, the

00:15:27.320 --> 00:15:29.360
virtual machine is definitely
the heart of

00:15:29.360 --> 00:15:30.780
what we're doing here.

00:15:30.780 --> 00:15:32.490
And so we're offering Linux
virtual machines.

00:15:32.490 --> 00:15:33.830
You get root access
on these machines.

00:15:33.830 --> 00:15:39.440
You saw Evan install a
package from Ubuntu.

00:15:39.440 --> 00:15:42.210
And one thing that we should
note is that we are locking

00:15:42.210 --> 00:15:43.110
down the Linux kernel.

00:15:43.110 --> 00:15:45.290
And this is really for reasons
of security and performance.

00:15:45.290 --> 00:15:47.300
We've actually tuned that kernel
to work very well with

00:15:47.300 --> 00:15:49.420
our networking environment.

00:15:49.420 --> 00:15:52.580
And we're offering a couple
stock images based off of

00:15:52.580 --> 00:15:54.600
Ubuntu and sentOS.

00:15:54.600 --> 00:15:56.310
And you're free to customize
these and build your own

00:15:56.310 --> 00:15:57.430
custom images.

00:15:57.430 --> 00:16:01.020
Or if you're a real hacker, you
can build your own Linux

00:16:01.020 --> 00:16:05.140
distribution by hand
carving bits.

00:16:05.140 --> 00:16:07.520
And so our images, we've done
a couple of things.

00:16:07.520 --> 00:16:10.190
We've installed a couple of
utilities by default, things

00:16:10.190 --> 00:16:14.840
like the GSUtil that Evan was
calling, just so that stuff is

00:16:14.840 --> 00:16:16.060
ready to go.

00:16:16.060 --> 00:16:19.230
And we've done a little bit of
security lock down, things

00:16:19.230 --> 00:16:21.220
like turning off password
authentication and only

00:16:21.220 --> 00:16:24.120
relying on SSH keys or turning
on automatic security updates.

00:16:26.850 --> 00:16:29.470
Now, what do you get when you
actually buy a virtual machine

00:16:29.470 --> 00:16:30.880
from Google Compute Engine?

00:16:30.880 --> 00:16:33.840
Well, the first thing is that
you're getting a really

00:16:33.840 --> 00:16:38.350
impressively fast Intel 2.6
gigahertz Sandy Bridge

00:16:38.350 --> 00:16:40.210
processor, Xeon processor.

00:16:40.210 --> 00:16:43.420
We offer these things in one,
two, four, and eight virtual

00:16:43.420 --> 00:16:44.940
CPU configurations.

00:16:44.940 --> 00:16:48.610
And we map one of these virtual
CPUs to a hyperthread.

00:16:48.610 --> 00:16:53.290
And so if you get a two CPU
instance, you'll get both

00:16:53.290 --> 00:16:56.440
halves of a real
physical core.

00:16:56.440 --> 00:17:00.370
We're offering 3.75 gigabytes
of RAM per virtual CPU.

00:17:00.370 --> 00:17:02.350
And that scales up linearly.

00:17:02.350 --> 00:17:05.300
And we're offering a significant
amount of what

00:17:05.300 --> 00:17:07.210
we're calling ephemeral
or local storage.

00:17:07.210 --> 00:17:09.130
And if you buy one of the
bigger instances--

00:17:09.130 --> 00:17:13.380
these are the four or the
eight core instances--

00:17:13.380 --> 00:17:15.700
you also are provided with
dedicated spindles.

00:17:15.700 --> 00:17:18.280
And so this actually comes
back to this level of

00:17:18.280 --> 00:17:19.050
consistency.

00:17:19.050 --> 00:17:20.650
If you know that you're the only
one reading and writing

00:17:20.650 --> 00:17:22.329
from that disc, you're going to
get a lot more predictable

00:17:22.329 --> 00:17:24.240
performance.

00:17:24.240 --> 00:17:28.170
As part of this launch, we're
defining a new performance

00:17:28.170 --> 00:17:34.090
metric called a Google Compute
Engine unit, or the GQ I think

00:17:34.090 --> 00:17:35.860
is the cute name for it.

00:17:35.860 --> 00:17:39.900
And we've built this to
approximate an ECU as best we

00:17:39.900 --> 00:17:40.560
could figure it.

00:17:40.560 --> 00:17:45.220
And so as far as we can
determine, we're rating our

00:17:45.220 --> 00:17:52.480
virtual CPUs at 2.75 GQs
per virtual CPU.

00:17:52.480 --> 00:17:54.910
And we're also working on
smaller machine types for

00:17:54.910 --> 00:17:56.300
prototyping and debugging.

00:17:56.300 --> 00:17:57.710
And so those will
be forthcoming.

00:18:00.960 --> 00:18:02.930
I want to got into a little
bit of detail of sort of

00:18:02.930 --> 00:18:04.730
what's going on under the covers
and the technology

00:18:04.730 --> 00:18:08.000
stack that we've chosen and
what we're building on.

00:18:08.000 --> 00:18:12.230
You may not know it but Google
actually has a great kernel

00:18:12.230 --> 00:18:13.000
engineering team.

00:18:13.000 --> 00:18:15.390
We actually of a lot expertise
with the Linux kernel.

00:18:15.390 --> 00:18:19.920
And we really leveraged these
guys when we started looking

00:18:19.920 --> 00:18:22.610
at which virtualization
technology we

00:18:22.610 --> 00:18:23.760
wanted to build on.

00:18:23.760 --> 00:18:26.910
And we ended up going with a
combination of kernel virtual

00:18:26.910 --> 00:18:30.700
machines, or KVM, and
Linux cgroups.

00:18:30.700 --> 00:18:36.400
So KVM is really a great and
relatively recent entrance

00:18:36.400 --> 00:18:38.270
into the virtualization world.

00:18:38.270 --> 00:18:42.870
And it's interesting because it
actually reuses the Linux

00:18:42.870 --> 00:18:45.640
kernel to actually play the
role of hypervisor.

00:18:45.640 --> 00:18:51.080
And so you end up reusing the
Linux memory manager and

00:18:51.080 --> 00:18:54.910
scheduler to actually manage the
memory and the scheduling

00:18:54.910 --> 00:18:57.250
of the virtual machines.

00:18:57.250 --> 00:19:00.040
So one of the great advantages
that you get out of this is

00:19:00.040 --> 00:19:02.080
that you can run both
virtualized and

00:19:02.080 --> 00:19:04.980
non-virtualized workloads on
the same kernel and perhaps

00:19:04.980 --> 00:19:06.000
even on the same machine.

00:19:06.000 --> 00:19:09.740
And so with a number of machines
that Google manages,

00:19:09.740 --> 00:19:12.580
having one single kernel that we
deploy and that we test, is

00:19:12.580 --> 00:19:14.730
a huge, huge advantage.

00:19:14.730 --> 00:19:18.970
So we worked closely with Red
Hat, and we really appreciate

00:19:18.970 --> 00:19:21.380
the leadership that they've
shown in terms of getting KVM

00:19:21.380 --> 00:19:22.800
where it's at today.

00:19:22.800 --> 00:19:26.220
And we're going to be looking to
engage further with Red Hat

00:19:26.220 --> 00:19:27.310
and the KVM community.

00:19:27.310 --> 00:19:32.130
So stay tuned as we detail
our involvement there.

00:19:32.130 --> 00:19:34.220
Now, the other piece of this
puzzle is this feature called

00:19:34.220 --> 00:19:35.670
Linux cgroups.

00:19:35.670 --> 00:19:37.800
So KVM provides virtualization.

00:19:37.800 --> 00:19:40.630
Cgroups provides resource
isolation.

00:19:40.630 --> 00:19:43.250
And this is something that
was pioneered by the

00:19:43.250 --> 00:19:44.480
Google kernel team.

00:19:44.480 --> 00:19:47.180
And it's been released to open
source for quite a while now.

00:19:47.180 --> 00:19:49.240
And it's used a very, very
widely at Google.

00:19:49.240 --> 00:19:52.710
So this is an example of Google
reusing technology that

00:19:52.710 --> 00:19:56.240
we've built to solve some of
our own problems across our

00:19:56.240 --> 00:19:59.030
own set of requirements, but
reapplying this into the

00:19:59.030 --> 00:20:00.510
virtualization world.

00:20:00.510 --> 00:20:04.010
And so we have a lot of
experience in terms of making

00:20:04.010 --> 00:20:05.830
sure that we can keep workloads

00:20:05.830 --> 00:20:06.980
isolated from each other.

00:20:06.980 --> 00:20:11.780
And Linux cgroups is
a big part of that.

00:20:11.780 --> 00:20:13.950
So moving away from the virtual
machines themselves, I

00:20:13.950 --> 00:20:16.120
want to talk a little bit
about our networking.

00:20:16.120 --> 00:20:20.050
So each project gets its own
private, virtual network.

00:20:20.050 --> 00:20:23.060
You don't share this virtual
network with anybody else.

00:20:23.060 --> 00:20:26.430
And this virtual network
actually spans across all of

00:20:26.430 --> 00:20:28.620
your virtual machines, no
matter where they are.

00:20:28.620 --> 00:20:30.880
So we think that's a really
interesting property.

00:20:30.880 --> 00:20:35.090
So that means that if you have
a virtual machine running in

00:20:35.090 --> 00:20:37.470
the East Coast of the United
States, and you have another

00:20:37.470 --> 00:20:40.210
one running in Central US-- and
they can be hundreds or

00:20:40.210 --> 00:20:42.070
thousands of miles away--

00:20:42.070 --> 00:20:45.310
they can talk to each other
over this secure private,

00:20:45.310 --> 00:20:47.720
virtual network.

00:20:47.720 --> 00:20:50.560
And all that traffic, instead of
going through the Wild West

00:20:50.560 --> 00:20:54.790
of the internet, actually goes
over Google's highly-managed

00:20:54.790 --> 00:20:56.040
secure private network.

00:20:58.710 --> 00:21:03.480
Inside of this virtual network,
you're going to see

00:21:03.480 --> 00:21:05.880
private IP addresses,
RFC 1918 addresses.

00:21:05.880 --> 00:21:08.920
These are like 10 dot
type of addresses.

00:21:08.920 --> 00:21:15.320
And this network is all our IP
Layer 3 level networking.

00:21:15.320 --> 00:21:18.095
So that means that you can be
sure that if you get a packet,

00:21:18.095 --> 00:21:20.410
and it comes from a particular
IP address, that it really

00:21:20.410 --> 00:21:23.780
came from that virtual machine
on your private network.

00:21:23.780 --> 00:21:27.070
Now beyond these sort of flat
geographical regions, which we

00:21:27.070 --> 00:21:31.570
think is a great feature, we've
also worked to actually

00:21:31.570 --> 00:21:34.300
bridge the gap between the API,
what's happening at the

00:21:34.300 --> 00:21:36.080
API level, and what's happening

00:21:36.080 --> 00:21:37.610
inside the virtual machine.

00:21:37.610 --> 00:21:41.310
And so, as you saw with Evan's
demo, when we name a virtual

00:21:41.310 --> 00:21:44.000
machine demo-- or you name it
Foo or whatever you want to

00:21:44.000 --> 00:21:46.060
name it, Worker Number 37--

00:21:46.060 --> 00:21:48.690
that gets propagated into the
virtual machine so it becomes

00:21:48.690 --> 00:21:50.630
that virtual machine's
host name.

00:21:50.630 --> 00:21:53.590
Not only do we do that, but we
actually overlay the DNS

00:21:53.590 --> 00:21:55.680
that's provided to that virtual
machine so that your

00:21:55.680 --> 00:21:58.680
virtual machines can use those
host names to find each other.

00:21:58.680 --> 00:22:01.700
When you're actually bringing up
a distributed system naming

00:22:01.700 --> 00:22:03.610
is a really, really hard
thing to get right.

00:22:03.610 --> 00:22:07.950
And it's really important, and
it's really useful to actually

00:22:07.950 --> 00:22:10.430
have this system provide sort
of that substrate of naming

00:22:10.430 --> 00:22:11.840
that you can take
advantage of.

00:22:11.840 --> 00:22:14.430
This is actually a lesson that
Google's learned well as we've

00:22:14.430 --> 00:22:15.880
built larger and
larger systems.

00:22:19.010 --> 00:22:22.690
Moving away from the private
virtual network, I want to

00:22:22.690 --> 00:22:24.760
talk about how our virtual
machines get

00:22:24.760 --> 00:22:26.790
access to the internet.

00:22:26.790 --> 00:22:31.190
So every virtual machine can be
assigned an IP address, and

00:22:31.190 --> 00:22:34.060
it gets full use of
that IP address.

00:22:34.060 --> 00:22:37.410
It won't show up if you do like
ifconfig inside the VM.

00:22:37.410 --> 00:22:40.100
But instead, as your traffic
exits or enters from your

00:22:40.100 --> 00:22:43.170
virtual network to the internet,
we actually rewrite

00:22:43.170 --> 00:22:44.590
that IP address using NAT.

00:22:44.590 --> 00:22:46.580
We're calling this 1-to-1 NAT
because it's not doing the

00:22:46.580 --> 00:22:51.370
port mapping that you'll find is
relatively common with NAT.

00:22:51.370 --> 00:22:53.990
These external IP address
is similar to the global

00:22:53.990 --> 00:22:56.460
footprint of our virtual
networks, actually float

00:22:56.460 --> 00:22:58.050
between regions also.

00:22:58.050 --> 00:23:00.830
So this means that you can
actually detach an IP address

00:23:00.830 --> 00:23:03.570
from a VM running in one region
and reattach it to

00:23:03.570 --> 00:23:05.830
another VM running in a
different region that may be

00:23:05.830 --> 00:23:07.580
hundreds or thousands
of miles away.

00:23:07.580 --> 00:23:09.850
And Google automatically takes
care of making sure that the

00:23:09.850 --> 00:23:13.720
traffic gets to the
right destination.

00:23:13.720 --> 00:23:15.830
In addition, we have a built-in
firewall system so

00:23:15.830 --> 00:23:18.170
that, again, this threat of
security, we want to make sure

00:23:18.170 --> 00:23:20.510
that as you start your virtual
machine you don't get any

00:23:20.510 --> 00:23:22.030
surprises with respect
to traffic

00:23:22.030 --> 00:23:23.770
that you're not expecting.

00:23:23.770 --> 00:23:27.410
And this utilizes,
again, Google's

00:23:27.410 --> 00:23:28.760
global network footprint.

00:23:28.760 --> 00:23:32.670
And so what happens is that no
matter where in the world this

00:23:32.670 --> 00:23:35.850
traffic is coming from, as soon
as we can, we get it on

00:23:35.850 --> 00:23:38.080
to Google's network, and it gets
a first class ticket from

00:23:38.080 --> 00:23:40.990
wherever in the world it is
to your virtual machine.

00:23:40.990 --> 00:23:44.830
And so instead of actually
dealing with sort of the chaos

00:23:44.830 --> 00:23:47.550
that is the internet at large,
we try and actually eliminate

00:23:47.550 --> 00:23:49.890
that to provide as much
consistency, as much

00:23:49.890 --> 00:23:52.090
performance as we
possibly can.

00:23:52.090 --> 00:23:53.660
So, again, this brings
in consistency.

00:23:53.660 --> 00:23:55.570
We want to make sure that
we can provide a great

00:23:55.570 --> 00:24:00.330
experience, no matter what's
going on with respect to the

00:24:00.330 --> 00:24:03.700
weather of the network
currently.

00:24:03.700 --> 00:24:06.820
And then finally a couple of
limitations I want to mention.

00:24:06.820 --> 00:24:10.120
We're restricting outgoing email
access, SMTP traffic, as

00:24:10.120 --> 00:24:12.660
an abuse measure.

00:24:12.660 --> 00:24:15.760
If you have a need for that,
we're going to evaluate it on

00:24:15.760 --> 00:24:17.440
a case-by-case basis.

00:24:17.440 --> 00:24:23.010
And while you can do any sort
of IP level traffic between

00:24:23.010 --> 00:24:25.910
instances on the private virtual
network, we're only

00:24:25.910 --> 00:24:29.880
supporting UDP, TCP, and ICMP
for network traffic to the

00:24:29.880 --> 00:24:31.130
internet at large.

00:24:33.220 --> 00:24:36.150
So shifting away from
networking, I want to talk

00:24:36.150 --> 00:24:37.300
about storage.

00:24:37.300 --> 00:24:40.170
It's probably as important, if
not more important, than

00:24:40.170 --> 00:24:41.060
networking.

00:24:41.060 --> 00:24:44.220
And so the first thing I want
to highlight is what we've

00:24:44.220 --> 00:24:46.550
been calling Persistent Disk.

00:24:46.550 --> 00:24:49.850
So this is storage that builds
on top of Google's deep

00:24:49.850 --> 00:24:54.250
experience with storage
infrastructure and provides a

00:24:54.250 --> 00:24:57.140
virtual hard drive
that outlives the

00:24:57.140 --> 00:24:58.910
lifetime of your instance.

00:24:58.910 --> 00:25:03.350
And we've built this from the
ground up to be as fast and as

00:25:03.350 --> 00:25:05.420
consistent as we possibly can.

00:25:05.420 --> 00:25:08.350
We've really sort of started
measuring things out to like

00:25:08.350 --> 00:25:11.060
the 99.999th percentile
and looking at

00:25:11.060 --> 00:25:12.310
the latencies there.

00:25:15.100 --> 00:25:17.210
And so this is provisioned
just like instances.

00:25:17.210 --> 00:25:19.050
So whereas Evan called
[? GCU ?]

00:25:19.050 --> 00:25:21.710
[? add ?] instance, you can
call add disk also.

00:25:21.710 --> 00:25:25.670
And these things are actually
located within a zone, similar

00:25:25.670 --> 00:25:26.750
to instances also.

00:25:26.750 --> 00:25:28.690
And you can mount these things
read, write to a single

00:25:28.690 --> 00:25:30.780
instance or you can mount
them read, write a

00:25:30.780 --> 00:25:31.660
whole bunch of instances.

00:25:31.660 --> 00:25:34.480
And we think that being able to
actually have a static data

00:25:34.480 --> 00:25:37.250
set that you can mount
read only is a

00:25:37.250 --> 00:25:40.150
really interesting feature.

00:25:40.150 --> 00:25:42.660
We're also encrypting all of
the data coming from your

00:25:42.660 --> 00:25:45.870
virtual machine before it
actually gets written anywhere

00:25:45.870 --> 00:25:47.440
persistently.

00:25:47.440 --> 00:25:49.900
And this is a really important
feature for

00:25:49.900 --> 00:25:51.100
just peace of mind.

00:25:51.100 --> 00:25:55.120
And because we're building on
these newer processors, we can

00:25:55.120 --> 00:25:59.240
do this with essentially very
little to no overhead.

00:25:59.240 --> 00:26:03.070
And so it's essentially
transparent to you.

00:26:03.070 --> 00:26:05.670
We're making sure that your data
gets encrypted before it

00:26:05.670 --> 00:26:07.380
gets written down.

00:26:07.380 --> 00:26:07.540
OK.

00:26:07.540 --> 00:26:10.550
So a number I want to share with
respect to consistency

00:26:10.550 --> 00:26:14.220
and the persistent disk product,
we've measured this

00:26:14.220 --> 00:26:20.000
in less than 3% variance on I/O
bandwidth when doing 4K

00:26:20.000 --> 00:26:21.960
random reads and writes.

00:26:21.960 --> 00:26:25.150
And with local disk you can
actually see this very by up

00:26:25.150 --> 00:26:26.620
to the 13%.

00:26:26.620 --> 00:26:28.130
So this is very, very
consistent.

00:26:28.130 --> 00:26:30.310
Not only that, but when you're
doing large block read and

00:26:30.310 --> 00:26:34.950
writes you can actually see
up to, I think, triple the

00:26:34.950 --> 00:26:37.590
overall bandwidth as what you
would get to local disk.

00:26:37.590 --> 00:26:40.090
And so we're really, really
proud of this persistent disk

00:26:40.090 --> 00:26:44.120
product we're really happy
with where it's at.

00:26:44.120 --> 00:26:46.710
But sometimes you don't need
that persistent data.

00:26:46.710 --> 00:26:48.980
Sometimes, you need something
local that's sort of cheap and

00:26:48.980 --> 00:26:51.360
cheerful, I think, was the
phrase that Craig used.

00:26:51.360 --> 00:26:54.300
And in that case we have local
storage or ephemeral storage.

00:26:54.300 --> 00:26:55.920
This is tied to your instance.

00:26:55.920 --> 00:26:58.010
It lives and dies with
the instance.

00:26:58.010 --> 00:26:59.220
Currently, all of our
instances are

00:26:59.220 --> 00:27:00.010
booting off of this.

00:27:00.010 --> 00:27:01.750
We're going to be looking at
putting off of the persistent

00:27:01.750 --> 00:27:06.780
disk product in the future, and
you get a lot of it, up to

00:27:06.780 --> 00:27:11.980
three and a half terabytes
with the 8 CPU instance.

00:27:11.980 --> 00:27:14.150
And again, with the larger
instances, you're going to get

00:27:14.150 --> 00:27:19.690
dedicated spindles, one
spindle with the 4 CPU

00:27:19.690 --> 00:27:22.360
instance and then two spindles
with the 8 CPU instance.

00:27:22.360 --> 00:27:25.920
And just like the persistent
disk, we encrypt this at rest.

00:27:25.920 --> 00:27:28.480
And that key that actually
encrypts it actually never

00:27:28.480 --> 00:27:30.612
leaves the machine that
the VM's sitting on.

00:27:33.390 --> 00:27:37.800
Now I also want to talk about
Google Cloud Storage.

00:27:37.800 --> 00:27:40.850
Now this isn't part of Google
Compute Engine proper.

00:27:40.850 --> 00:27:44.360
But it's kind of a sister
product that we've worked well

00:27:44.360 --> 00:27:45.120
to integrate with.

00:27:45.120 --> 00:27:47.440
And this is an internet
object store.

00:27:47.440 --> 00:27:49.870
It has its own HTTP API
for getting and

00:27:49.870 --> 00:27:51.660
setting values into it.

00:27:51.660 --> 00:27:54.980
And it's a great service for
getting data in and out of

00:27:54.980 --> 00:27:56.230
Google's cloud.

00:27:56.230 --> 00:27:58.510
You don't have to think about
managing your data.

00:27:58.510 --> 00:28:02.610
It's really a lot of automatic
sort of management replication

00:28:02.610 --> 00:28:04.540
happening for you.

00:28:04.540 --> 00:28:06.210
And we have this feature that
I'm going to talk to a little

00:28:06.210 --> 00:28:08.550
bit later-- and I think you saw
with it with Evan's demo

00:28:08.550 --> 00:28:09.880
called service accounts--

00:28:09.880 --> 00:28:11.610
that really make it frictionless
to use this.

00:28:11.610 --> 00:28:14.620
You don't have to think about
propagating credentials and

00:28:14.620 --> 00:28:17.290
making sure that those don't
leak and things like that.

00:28:17.290 --> 00:28:20.600
And so Google Cloud Storage
also takes advantage of

00:28:20.600 --> 00:28:22.940
Google's global infrastructure.

00:28:22.940 --> 00:28:25.330
And not only do you get that
first class ticket for your

00:28:25.330 --> 00:28:27.220
packets to anywhere
in the world, but

00:28:27.220 --> 00:28:29.800
you also get caching.

00:28:29.800 --> 00:28:32.910
So if your objects are publicly
readable, we can

00:28:32.910 --> 00:28:35.200
cache them very close to where
they're going to be used.

00:28:35.200 --> 00:28:37.490
And you get like CDN-type
performance out of that.

00:28:40.480 --> 00:28:41.650
And then finally, I
mentioned zones.

00:28:41.650 --> 00:28:43.030
I just want to mention this
for completeness.

00:28:43.030 --> 00:28:44.910
We have this idea of
a region, which is

00:28:44.910 --> 00:28:47.030
geography and routing domain.

00:28:47.030 --> 00:28:49.120
And then we also have a zone,
which is really all about

00:28:49.120 --> 00:28:50.230
fault tolerance.

00:28:50.230 --> 00:28:53.210
For this limited preview, we're
launching in three zones

00:28:53.210 --> 00:28:56.290
spread across the Central and
Eastern United States.

00:28:56.290 --> 00:28:58.770
And we're going to be looking
to expand that

00:28:58.770 --> 00:29:01.770
as the product develops.

00:29:01.770 --> 00:29:05.230
So with that, that's sort of the
basics of the overview of

00:29:05.230 --> 00:29:08.190
systems for Google
Compute Engine.

00:29:08.190 --> 00:29:11.280
But I'd like to give you a real
idea of what it looks

00:29:11.280 --> 00:29:13.840
like to run an application
on top of Compute Engine.

00:29:13.840 --> 00:29:17.630
And with that I'd like to
introduce Hamza Kaya, who is

00:29:17.630 --> 00:29:20.500
with Invite Media, to tell us
about his experience of

00:29:20.500 --> 00:29:21.460
working with Compute Engine.

00:29:21.460 --> 00:29:21.860
Hamza?

00:29:21.860 --> 00:29:23.240
HAMZA KAYA: Thank you, Joe.

00:29:23.240 --> 00:29:25.860
Hello everybody.

00:29:25.860 --> 00:29:28.120
Invite Media is in a demand-side
platform that

00:29:28.120 --> 00:29:31.930
allows advertisers to
buy from multiple ad

00:29:31.930 --> 00:29:34.390
exchanges in real time.

00:29:34.390 --> 00:29:36.800
Since everything happens in
real time, we have to deal

00:29:36.800 --> 00:29:39.910
with two main challenges.

00:29:39.910 --> 00:29:45.610
The first one is we need to
buy as many ad requests as

00:29:45.610 --> 00:29:48.980
possible to multiple
ad exchanges.

00:29:48.980 --> 00:29:52.620
As you can imagine, this results
in a very high volume

00:29:52.620 --> 00:29:54.470
of traffic.

00:29:54.470 --> 00:29:58.220
To give you an idea, Invite
these days handles close to

00:29:58.220 --> 00:30:01.200
400K queries per second.

00:30:01.200 --> 00:30:06.770
And the second challenge is that
we need to return a valid

00:30:06.770 --> 00:30:09.470
response back to the
exchange within a

00:30:09.470 --> 00:30:11.380
very short time period.

00:30:11.380 --> 00:30:15.260
Usually this is 150
milliseconds, including the

00:30:15.260 --> 00:30:16.523
network [INAUDIBLE]

00:30:16.523 --> 00:30:17.370
time.

00:30:17.370 --> 00:30:23.040
Handling many ad requests with
these short period of time is

00:30:23.040 --> 00:30:26.470
definitely a challenging task
and requires good computing

00:30:26.470 --> 00:30:31.430
power and a consistently
good networking.

00:30:31.430 --> 00:30:35.730
Invite Media has been using
the same infrastructure

00:30:35.730 --> 00:30:37.370
provider since the beginning.

00:30:37.370 --> 00:30:40.990
And recently, we started to
evaluate Google Compute Engine

00:30:40.990 --> 00:30:43.680
as an alternative.

00:30:43.680 --> 00:30:49.800
Initially we wanted to build a
test cluster on Google Compute

00:30:49.800 --> 00:30:53.990
Engine to see how teams
are working on

00:30:53.990 --> 00:30:57.020
Google Compute Engine.

00:30:57.020 --> 00:31:00.240
And what we saw was
pretty familiar to

00:31:00.240 --> 00:31:02.260
our existing system.

00:31:02.260 --> 00:31:04.630
Basically you have instances
running Linux.

00:31:04.630 --> 00:31:07.780
And you can attach disks.

00:31:07.780 --> 00:31:09.220
You can assign static IPs.

00:31:09.220 --> 00:31:11.290
You can provide a
start-up script.

00:31:11.290 --> 00:31:14.610
And you have a nice
API, which is

00:31:14.610 --> 00:31:18.180
well-documented and easy to use.

00:31:18.180 --> 00:31:24.540
With this familiar model, we
managed to port our system to

00:31:24.540 --> 00:31:29.270
Google Compute Engine, and it
was fairly simple and quick.

00:31:29.270 --> 00:31:33.190
We only spent two weeks of
engineering time to build a

00:31:33.190 --> 00:31:37.440
fully functional cluster and
start serving traffic on

00:31:37.440 --> 00:31:39.310
Google Compute Engine.

00:31:39.310 --> 00:31:43.380
And honestly, two weeks is the
time we usually spend whenever

00:31:43.380 --> 00:31:47.170
we need to expand our operation
to another region

00:31:47.170 --> 00:31:49.880
within our existing provider.

00:31:49.880 --> 00:31:56.220
So I'd like to share some of the
results that we achieved

00:31:56.220 --> 00:31:58.690
through our initial test run.

00:31:58.690 --> 00:32:03.590
So after we set up the test
cluster we decided to actually

00:32:03.590 --> 00:32:06.170
serve a portion of our
production traffic through

00:32:06.170 --> 00:32:08.050
Google Compute Engine.

00:32:08.050 --> 00:32:14.220
And we used 8 core instances on
both our existing provider

00:32:14.220 --> 00:32:16.800
and the Google Compute Engine.

00:32:16.800 --> 00:32:20.460
On our existing provider a
single 8 core instance can

00:32:20.460 --> 00:32:25.690
handle up to 250 queries per
second, while respecting the

00:32:25.690 --> 00:32:27.570
latency requirements.

00:32:27.570 --> 00:32:30.880
And on the other hand, on
Google Compute Engine, a

00:32:30.880 --> 00:32:35.740
single instance can handle up
to 650 queries per second.

00:32:35.740 --> 00:32:37.600
And that's pretty impressive.

00:32:37.600 --> 00:32:46.380
And with that we used to serve
that portion of traffic with

00:32:46.380 --> 00:32:48.600
284 machines.

00:32:48.600 --> 00:32:51.940
Whereas after migrating to
Google Compute Engine, we are

00:32:51.940 --> 00:32:56.110
currently serving with only
140 machines, which is

00:32:56.110 --> 00:32:59.400
essentially halving our
number of servers

00:32:59.400 --> 00:33:01.850
that we need to manage.

00:33:01.850 --> 00:33:07.040
Another point that I want to
talk about is we have observed

00:33:07.040 --> 00:33:09.100
a consistently good network
performance on

00:33:09.100 --> 00:33:11.170
Google Compute Engine.

00:33:11.170 --> 00:33:15.660
When we receive an ad request
we have 10 milliseconds to

00:33:15.660 --> 00:33:19.760
find out an available back end
server and establish a

00:33:19.760 --> 00:33:21.320
connection to it.

00:33:21.320 --> 00:33:28.110
When we fail to establish a
connection in 10 milliseconds,

00:33:28.110 --> 00:33:32.400
this usually counts as
a connection error.

00:33:32.400 --> 00:33:39.860
With our current provider,
we usually have 5%

00:33:39.860 --> 00:33:41.510
of connection errors.

00:33:41.510 --> 00:33:45.760
So we error out 5%
of our requests.

00:33:45.760 --> 00:33:49.340
With Google Compute Engine, this
error rate decreased to

00:33:49.340 --> 00:33:51.750
under a half percent.

00:33:51.750 --> 00:33:54.400
So that's quite an
achievement.

00:33:54.400 --> 00:34:00.900
And another point is that with
our current provider, we time

00:34:00.900 --> 00:34:08.190
out 11% off incoming requests,
which means that we cannot

00:34:08.190 --> 00:34:11.500
return a response back
to exchange within

00:34:11.500 --> 00:34:14.610
the given time limit.

00:34:14.610 --> 00:34:20.880
On Google Compute Engine, this
error rate decreased to 6%,

00:34:20.880 --> 00:34:24.889
which means that, essentially,
we have now 5% more ad

00:34:24.889 --> 00:34:28.070
requests that we can buy
for our advertisers.

00:34:30.909 --> 00:34:39.000
After seeing these results, we
decided to migrate our entire

00:34:39.000 --> 00:34:41.920
operation to Google
Compute Engine.

00:34:41.920 --> 00:34:46.139
And currently, we are in the
process of moving globally to

00:34:46.139 --> 00:34:48.060
Google Compute Engine.

00:34:48.060 --> 00:34:49.800
With that, I end.

00:34:49.800 --> 00:34:52.420
That's all I have
to say today.

00:34:52.420 --> 00:34:53.670
Thank you, Joe.

00:35:01.020 --> 00:35:01.820
JOE BEDA: Thank you
very much, Hamza.

00:35:01.820 --> 00:35:04.840
And I really appreciate you
being an early user of the

00:35:04.840 --> 00:35:07.650
system and giving us a lot
of great feedback.

00:35:07.650 --> 00:35:12.470
So the next example that we want
to give is a system that

00:35:12.470 --> 00:35:15.500
was written by, actually, an
intern that started with us

00:35:15.500 --> 00:35:18.180
about a month ago named
Dustin Carlino.

00:35:18.180 --> 00:35:19.790
He's back in Seattle.

00:35:19.790 --> 00:35:22.756
And this is a sample
application-- we're going to

00:35:22.756 --> 00:35:24.920
be releasing the code for that--
for running Hadoop on

00:35:24.920 --> 00:35:26.740
top of Compute Engine.

00:35:26.740 --> 00:35:30.690
And I'd like to introduce Evan
again to run through how the

00:35:30.690 --> 00:35:31.650
system works.

00:35:31.650 --> 00:35:32.900
Evan?

00:35:35.300 --> 00:35:40.280
EVAN ANDERSON: So I'm going to
start by outlining how the

00:35:40.280 --> 00:35:41.870
application is designed.

00:35:41.870 --> 00:35:50.660
And then we will actually start
up a Hadoop cluster.

00:35:50.660 --> 00:35:53.000
And we'll run a job.

00:35:53.000 --> 00:35:57.050
And all of this code, as Joe
mentioned, is going to be

00:35:57.050 --> 00:35:59.290
released as example code
in the future.

00:35:59.290 --> 00:36:01.720
So I'm going to go through this
a little bit quickly.

00:36:01.720 --> 00:36:04.670
But you will have a chance later
to actually pore over

00:36:04.670 --> 00:36:06.810
the code and see how
all of it works.

00:36:06.810 --> 00:36:11.340
So the design allows for either
a command line or an

00:36:11.340 --> 00:36:17.360
App Engine front end to talk
to the Google Compute API.

00:36:17.360 --> 00:36:24.870
And the first step is to launch
a coordinator instance,

00:36:24.870 --> 00:36:29.020
which we package up some data
and we push it to Google

00:36:29.020 --> 00:36:30.220
Compute Engine.

00:36:30.220 --> 00:36:36.900
And then, it starts up and
begins configuring itself.

00:36:36.900 --> 00:36:43.340
And once the coordinator has
launched, it exposes a REST

00:36:43.340 --> 00:36:47.420
JSON API, which can be used to
actually set up the rest of

00:36:47.420 --> 00:36:48.140
the cluster.

00:36:48.140 --> 00:36:51.010
So we're using one virtual
machine to drive the setup of

00:36:51.010 --> 00:36:53.650
all of the other virtual
machines and provide

00:36:53.650 --> 00:36:56.270
monitoring, and status
information, and so forth.

00:36:56.270 --> 00:37:03.010
So right now, the coordinator
just started running.

00:37:03.010 --> 00:37:06.830
So it will take a few minutes
for it to download all of the

00:37:06.830 --> 00:37:11.420
packages it needs, and start
up, and get the actual

00:37:11.420 --> 00:37:13.140
application service running.

00:37:13.140 --> 00:37:17.710
This is booting from a fresh
Ubuntu image like in my

00:37:17.710 --> 00:37:18.770
previous demo.

00:37:18.770 --> 00:37:23.120
There is no special software,
except for what's running

00:37:23.120 --> 00:37:27.390
after in this coordinator
bundle.

00:37:27.390 --> 00:37:29.890
And Joe will talk more
about how that works.

00:37:29.890 --> 00:37:32.810
So the controller is up.

00:37:32.810 --> 00:37:37.770
And now, I'm going to request
that this coordinator start up

00:37:37.770 --> 00:37:39.020
the rest of the cluster.

00:37:44.480 --> 00:37:50.830
And so starting up the Hadoop
cluster involves requesting

00:37:50.830 --> 00:37:54.690
that the coordinator download
all the Hadoop software, and

00:37:54.690 --> 00:37:57.840
then stage it on to Google
storage so that all the rest

00:37:57.840 --> 00:38:01.550
of the nodes can read it very
quickly, and also so that we

00:38:01.550 --> 00:38:05.300
don't overwhelm our friendly
local Apache mirror.

00:38:05.300 --> 00:38:11.040
So we've built a cluster
that's only about

00:38:11.040 --> 00:38:12.200
100 nodes or so.

00:38:12.200 --> 00:38:15.920
But we've requested
the coordinator

00:38:15.920 --> 00:38:17.430
start spinning up nodes.

00:38:17.430 --> 00:38:20.200
And as you can see, it's keeping
track of all of the

00:38:20.200 --> 00:38:24.430
nodes that it's already launched
and the status of the

00:38:24.430 --> 00:38:27.400
nodes that have been launched.

00:38:27.400 --> 00:38:29.520
They are moving from
provisioning to staging and

00:38:29.520 --> 00:38:30.860
you'll see some other steps.

00:38:30.860 --> 00:38:33.190
And then it's launching
additional ones through the

00:38:33.190 --> 00:38:39.060
API when it decides
that things are

00:38:39.060 --> 00:38:41.810
making enough progress.

00:38:41.810 --> 00:38:45.750
So all of this work is being
done on the coordinator node.

00:38:45.750 --> 00:38:48.410
If I were to kill this script,
the coordinator would just

00:38:48.410 --> 00:38:51.120
keep going along setting
up the cluster.

00:38:51.120 --> 00:38:52.950
As you can see, several
of these nodes

00:38:52.950 --> 00:38:54.210
have gotten to running.

00:38:54.210 --> 00:38:57.120
Running means that the virtual
machine has booted, and it's

00:38:57.120 --> 00:38:58.600
downloading Java.

00:38:58.600 --> 00:38:59.950
It's downloading Hadoop.

00:38:59.950 --> 00:39:02.140
It's installing Java
and Hadoop.

00:39:02.140 --> 00:39:05.750
It's waiting for the agent
to start running on these

00:39:05.750 --> 00:39:08.210
machines, which we use for
additional control that the

00:39:08.210 --> 00:39:09.340
coordinator uses.

00:39:09.340 --> 00:39:12.290
And that's this snitch
ready state.

00:39:12.290 --> 00:39:16.600
The script will exit once it
has a sufficient quorum of

00:39:16.600 --> 00:39:17.390
nodes available.

00:39:17.390 --> 00:39:19.270
So you can see the Hadoop
name node just came up.

00:39:19.270 --> 00:39:21.500
And now it's ready to
be part of Hadoop.

00:39:21.500 --> 00:39:23.300
The JobTracker is
still coming up.

00:39:23.300 --> 00:39:27.340
Once the JobTracker and the
NameNode are up, and there are

00:39:27.340 --> 00:39:30.260
enough slaves, the script
will say, OK.

00:39:30.260 --> 00:39:33.890
You can start launching Hadoop
jobs now, even though the rest

00:39:33.890 --> 00:39:35.140
of the cluster isn't up yet.

00:39:37.770 --> 00:39:40.790
So it's just going to finish
now, because it says, hey,

00:39:40.790 --> 00:39:42.130
we've got some slaves up.

00:39:42.130 --> 00:39:44.980
And we've got the Hadoop
masters up.

00:39:44.980 --> 00:39:46.600
So that's enough for
you start running

00:39:46.600 --> 00:39:47.880
Hadoop jobs if you want.

00:39:47.880 --> 00:39:52.060
And as I said, all this will be
available as sample code.

00:39:52.060 --> 00:39:56.800
But one of the nice additional
features of having this

00:39:56.800 --> 00:39:59.740
separate controller is that you
can ask it, hey, what's

00:39:59.740 --> 00:40:00.190
the status of the cluster?

00:40:00.190 --> 00:40:02.690
And you can see now
we have something

00:40:02.690 --> 00:40:04.560
like 41 Hadoop nodes.

00:40:04.560 --> 00:40:07.020
And as they make progress--

00:40:09.690 --> 00:40:11.330
we still have 44.

00:40:11.330 --> 00:40:12.400
But that's fine.

00:40:12.400 --> 00:40:14.170
44 is enough to start
our job with.

00:40:14.170 --> 00:40:16.180
And as the rest come online
they will just

00:40:16.180 --> 00:40:17.580
get added to cluster.

00:40:17.580 --> 00:40:26.946
So I'm going to launch a job
on the Hadoop master that--

00:40:26.946 --> 00:40:31.320
wow, I just got really
loud, sorry.

00:40:31.320 --> 00:40:33.440
I'm going to launch a job on
the Hadoop master that

00:40:33.440 --> 00:40:37.970
downloads 60 gigs of compressed
XML data of

00:40:37.970 --> 00:40:40.060
Wikipedia revisions.

00:40:40.060 --> 00:40:46.460
And then it--

00:40:46.460 --> 00:40:47.830
sorry.

00:40:47.830 --> 00:40:50.480
So we'll go and take a look at
that in the JobTracker first,

00:40:50.480 --> 00:40:52.510
and then I will explain
how it works.

00:40:52.510 --> 00:40:59.830
And I don't want to let this
go too long because Hadoop

00:40:59.830 --> 00:41:05.620
will make short work of
it with 94 nodes.

00:41:05.620 --> 00:41:07.450
So one note, it looks like
it's still setting up.

00:41:07.450 --> 00:41:09.880
But this downloads 60
gigs of compressed

00:41:09.880 --> 00:41:12.270
Wikipedia edit history.

00:41:12.270 --> 00:41:17.680
And this is all the history of
Wikipedia for the last several

00:41:17.680 --> 00:41:19.730
years of all the edits
that have been made.

00:41:19.730 --> 00:41:22.430
And you could do a lot of
interesting stuff with this,

00:41:22.430 --> 00:41:26.090
training machine learning,
training language algorithms,

00:41:26.090 --> 00:41:28.550
analyzing social graphs,
or other sorts of

00:41:28.550 --> 00:41:29.890
behavior like that.

00:41:29.890 --> 00:41:33.270
And you can see we're
22% done right now.

00:41:33.270 --> 00:41:37.520
And this has a tendency, because
it's only got 300 jobs

00:41:37.520 --> 00:41:41.080
or so to run, to jump at the end
as all the jobs get done

00:41:41.080 --> 00:41:43.230
at the same time.

00:41:43.230 --> 00:41:45.690
We just went from 22 to 77%.

00:41:45.690 --> 00:41:50.860
So this slices all the Wikipedia
data up into CSV

00:41:50.860 --> 00:41:57.200
format, which is great for
exporting to Google Big Query.

00:41:57.200 --> 00:42:00.790
And I will show you in a moment
how that would work

00:42:00.790 --> 00:42:01.740
once you've done that.

00:42:01.740 --> 00:42:06.040
Obviously, you could run other
interesting algorithms.

00:42:06.040 --> 00:42:10.810
And you can see here
the job is done.

00:42:10.810 --> 00:42:12.990
It took one and 1/2 minutes.

00:42:12.990 --> 00:42:15.750
And we wrote 70 gigabytes
of data into HTFS

00:42:15.750 --> 00:42:18.130
at the end of this.

00:42:18.130 --> 00:42:23.430
So now if we load this data into
Google Big Query, we can

00:42:23.430 --> 00:42:27.720
ask some interesting questions
like, which Wikipedia articles

00:42:27.720 --> 00:42:30.640
have had the most
edits over time?

00:42:30.640 --> 00:42:34.740
And so we say OK.

00:42:34.740 --> 00:42:38.070
And you can see that there
are a lot of potentially

00:42:38.070 --> 00:42:39.575
controversial topics here.

00:42:43.900 --> 00:42:51.660
And if we look through the
results, we'll see, oh hey,

00:42:51.660 --> 00:42:53.440
there's some interesting
things here.

00:42:53.440 --> 00:42:55.530
It looks like people are more
interested in making edits on

00:42:55.530 --> 00:42:58.320
Britney Spears' page than they
are about the Catholic Church.

00:42:58.320 --> 00:43:01.660
So who's been making
all these edits?

00:43:01.660 --> 00:43:06.830
Well, with Big Query you can
dig in and you can find the

00:43:06.830 --> 00:43:10.420
top editors of the Britney
Spears page.

00:43:10.420 --> 00:43:12.110
And obviously, you
could do lots of

00:43:12.110 --> 00:43:13.440
other interesting things.

00:43:13.440 --> 00:43:15.520
The great thing with Big Query
is it lets you do these sorts

00:43:15.520 --> 00:43:18.990
of interactive, hey, I wonder,
sorts of questions.

00:43:18.990 --> 00:43:21.400
And then that can guide your
later development of

00:43:21.400 --> 00:43:24.510
additional Hadoop jobs to
mine interesting data.

00:43:24.510 --> 00:43:28.430
So we discover some interesting
patterns doing a

00:43:28.430 --> 00:43:30.440
couple of queries, and we say,
I wonder if that's true for

00:43:30.440 --> 00:43:32.840
all Wikipedia users?

00:43:32.840 --> 00:43:36.910
Well, now you can build your
Hadoop job, and you can find

00:43:36.910 --> 00:43:38.900
the answer in a couple
of minutes.

00:43:38.900 --> 00:43:42.150
And with that, I'm going to let
Joe get back to talking

00:43:42.150 --> 00:43:47.770
about how all of this is put
together and the magic and

00:43:47.770 --> 00:43:50.760
unique features behind the
scenes that let you do this

00:43:50.760 --> 00:43:52.010
seamlessly.

00:43:59.720 --> 00:44:01.270
JOE BEDA: Thank you
very much, Evan.

00:44:01.270 --> 00:44:05.450
I think that does a great job of
showing how Google Compute

00:44:05.450 --> 00:44:09.080
Engine to run familiar code to
actually solve new problems,

00:44:09.080 --> 00:44:12.150
yet also integrate with the
other set of cloud services

00:44:12.150 --> 00:44:14.890
that we're offering.

00:44:14.890 --> 00:44:16.800
So I want to talk about some of
the features that actually

00:44:16.800 --> 00:44:17.890
makes this possible.

00:44:17.890 --> 00:44:20.650
And I think we've alluded to
this a couple times, but I

00:44:20.650 --> 00:44:24.380
want to go into some detail on
what a service account is.

00:44:24.380 --> 00:44:27.670
Like I said, every call that
actually comes into the Google

00:44:27.670 --> 00:44:31.130
API, and pretty much any API, is
based on OAuth 2, and it's

00:44:31.130 --> 00:44:32.420
tied back to a user.

00:44:32.420 --> 00:44:35.720
But what if you want to make a
call to that API from code?

00:44:35.720 --> 00:44:36.210
Right.

00:44:36.210 --> 00:44:38.160
Would you take your
Gmail password and

00:44:38.160 --> 00:44:40.270
put it in your VM?

00:44:40.270 --> 00:44:42.560
That's probably not
a great idea.

00:44:42.560 --> 00:44:44.940
So instead, what we did is we
invented this concept called

00:44:44.940 --> 00:44:45.980
Service Accounts.

00:44:45.980 --> 00:44:50.060
And this is a synthetic identity
for VMs and codes.

00:44:50.060 --> 00:44:52.140
Your code actually sort
of is its own user.

00:44:52.140 --> 00:44:56.090
And hopefully, maybe one day
it'll come and take over, and

00:44:56.090 --> 00:44:59.250
decide they don't
need the humans.

00:44:59.250 --> 00:45:03.370
But the great example here is
Google Compute Engine calling

00:45:03.370 --> 00:45:05.860
other Google APIs, whether
that be Google Storage or

00:45:05.860 --> 00:45:07.800
whether it be the task
queue pull API, which

00:45:07.800 --> 00:45:09.710
is part of App Engine.

00:45:09.710 --> 00:45:12.020
And then App Engine also support
Service Accounts.

00:45:12.020 --> 00:45:16.260
And so you can use App Engine to
call the Google Compute API

00:45:16.260 --> 00:45:18.900
to do all sorts of interesting
orchestration.

00:45:18.900 --> 00:45:21.390
And so we think that these
things really complement each

00:45:21.390 --> 00:45:24.240
other, and it actually stitches
together to make a

00:45:24.240 --> 00:45:25.740
great seamless platform.

00:45:29.110 --> 00:45:30.280
So here's some--

00:45:30.280 --> 00:45:33.690
let's just put some meat
on the bones here.

00:45:33.690 --> 00:45:36.990
You've seen some of this syntax
already when Evan

00:45:36.990 --> 00:45:38.650
launched his first example.

00:45:38.650 --> 00:45:41.290
When we launch a virtual
machine, we're providing the

00:45:41.290 --> 00:45:42.610
Service Accounts scopes.

00:45:42.610 --> 00:45:44.470
And you see storage-rw there.

00:45:44.470 --> 00:45:47.590
That's actually an alias for
a full OAuth 2 scope.

00:45:47.590 --> 00:45:52.000
And then when you SSH into that
machine, you can start

00:45:52.000 --> 00:45:53.440
running the Google
Storage Utility.

00:45:53.440 --> 00:45:55.930
It's actually modified to
automatically grab its

00:45:55.930 --> 00:46:00.350
credentials from a special
metadata server that's

00:46:00.350 --> 00:46:02.530
available only to the
virtual machine.

00:46:02.530 --> 00:46:05.660
And you can just seamlessly
communicate with Google

00:46:05.660 --> 00:46:07.520
Storage without having to
worry about further

00:46:07.520 --> 00:46:08.950
configuration or passwords.

00:46:08.950 --> 00:46:11.900
And so this is a great example
of how we've taken these a la

00:46:11.900 --> 00:46:14.605
carte services, but made them
actually work well together.

00:46:17.160 --> 00:46:20.260
So the next feature here
is Instance Metadata.

00:46:20.260 --> 00:46:26.370
So this is a little bit of a
twist on a familiar concept in

00:46:26.370 --> 00:46:27.530
the infrastructure world.

00:46:27.530 --> 00:46:30.590
But we're providing a set of key
value pairs that you set

00:46:30.590 --> 00:46:34.070
at the API that are then
available and exposed into the

00:46:34.070 --> 00:46:36.150
virtual machine.

00:46:36.150 --> 00:46:38.895
And so in this way, you can take
a single image, and it

00:46:38.895 --> 00:46:42.080
can specialize itself at runtime
to do what it needs to

00:46:42.080 --> 00:46:44.490
do based on the metadata
that's passed into it.

00:46:44.490 --> 00:46:47.840
And so that's exactly how the
Hadoop example that Evan just

00:46:47.840 --> 00:46:53.410
showed can take a sort of a
generic image, and from that

00:46:53.410 --> 00:46:55.520
bootstrap everything up
to installing Hadoop.

00:46:58.030 --> 00:47:00.830
So this metadata is accessible
from within the virtual

00:47:00.830 --> 00:47:03.110
machine at a special server
called metadata.

00:47:03.110 --> 00:47:04.400
That's very creative.

00:47:04.400 --> 00:47:08.980
And this server is a private
HTTP server just for that

00:47:08.980 --> 00:47:09.490
virtual machine.

00:47:09.490 --> 00:47:11.960
Nobody else sees that metadata
except for that particular

00:47:11.960 --> 00:47:13.890
virtual machine.

00:47:13.890 --> 00:47:16.400
This is great for configuration
data.

00:47:16.400 --> 00:47:20.530
And we also have the support
for project-wide metadata.

00:47:20.530 --> 00:47:23.470
And so you can set a key value
pair that will then get

00:47:23.470 --> 00:47:25.840
inherited into all of
these instances.

00:47:25.840 --> 00:47:28.560
And so this is the mechanism
that we use to push your SSH

00:47:28.560 --> 00:47:31.090
keys into the virtual machine
at boot up time.

00:47:31.090 --> 00:47:33.090
So there's nothing magical
going on there.

00:47:33.090 --> 00:47:35.470
Just start default image, knows
how to read a special

00:47:35.470 --> 00:47:38.430
metadata value called SSH keys,
and then goes through

00:47:38.430 --> 00:47:40.960
and installs those into
the virtual machine.

00:47:43.770 --> 00:47:45.370
Now, here again is a
little bit code to

00:47:45.370 --> 00:47:46.920
show how this works.

00:47:46.920 --> 00:47:50.290
So here, we're launching an
instance, and we're providing

00:47:50.290 --> 00:47:51.440
two metadata values here.

00:47:51.440 --> 00:47:53.650
One of them is a simple key
value pair with some short

00:47:53.650 --> 00:47:55.540
strings called role
and master.

00:47:55.540 --> 00:47:59.330
And then the other one,
the key is config.

00:47:59.330 --> 00:48:01.660
And then the actual contents of
that is in this text file

00:48:01.660 --> 00:48:04.450
called confic.txt.

00:48:04.450 --> 00:48:07.580
And then what you can do is
from within the virtual

00:48:07.580 --> 00:48:09.950
machine here you can actually
go through and hit up this

00:48:09.950 --> 00:48:11.250
metadata server.

00:48:11.250 --> 00:48:13.780
Curl is a simple utility that
downloads from HTTP from the

00:48:13.780 --> 00:48:16.410
command line, and you get
that metadata back.

00:48:16.410 --> 00:48:18.300
It's a pretty simple concept
but it's really, really

00:48:18.300 --> 00:48:22.930
powerful for customizing virtual
machines at boot time.

00:48:22.930 --> 00:48:25.760
So we've built on top of this
further with this idea called

00:48:25.760 --> 00:48:27.290
Start Up Scripts.

00:48:27.290 --> 00:48:30.770
And this utilizes both the
metadata and support that

00:48:30.770 --> 00:48:33.810
we've built into the virtual
machine, such that you can

00:48:33.810 --> 00:48:37.040
provide essentially a program
that gets run on startup.

00:48:37.040 --> 00:48:41.310
It's very similar to rc.local
if you're familiar with Unix

00:48:41.310 --> 00:48:44.380
startup semantics.

00:48:44.380 --> 00:48:48.890
And so you can use this to
install your software, to grab

00:48:48.890 --> 00:48:51.930
binaries or code or do get
[? sink ?] and build or

00:48:51.930 --> 00:48:54.680
whatever you need to
do as part of this.

00:48:54.680 --> 00:48:58.110
But it's also very useful for
bootstrapping more functional,

00:48:58.110 --> 00:49:00.570
more complicated and
comprehensive management

00:49:00.570 --> 00:49:02.210
frameworks.

00:49:02.210 --> 00:49:04.690
So it's just enough to get you
started and then you can just

00:49:04.690 --> 00:49:06.830
take it from there.

00:49:06.830 --> 00:49:07.660
So here's an example.

00:49:07.660 --> 00:49:12.330
So we're taking that original
example of the Sierpinski

00:49:12.330 --> 00:49:14.350
gasket that Evan did.

00:49:14.350 --> 00:49:16.620
And I've got to commend him for
actually doing a demo with

00:49:16.620 --> 00:49:18.540
a word like Sierpinski in it.

00:49:18.540 --> 00:49:21.880
And we're specifying all that
as a startup script.

00:49:21.880 --> 00:49:23.640
And so this virtual machine
will boot and it'll

00:49:23.640 --> 00:49:25.670
immediately start executing
this code.

00:49:25.670 --> 00:49:27.430
And if you want to actually see
what's happening, go in

00:49:27.430 --> 00:49:28.640
there and touch it
and feel it.

00:49:28.640 --> 00:49:30.150
You can actually SSH in.

00:49:30.150 --> 00:49:33.380
And you can actually look at
a log of what's going on.

00:49:33.380 --> 00:49:37.630
So we actually saved that data
away for debugging purposes.

00:49:37.630 --> 00:49:40.250
Now, when you add all this stuff
together, we're actually

00:49:40.250 --> 00:49:43.190
talking about sort of a change
in how you think about

00:49:43.190 --> 00:49:46.380
building things from thinking
about building servers to

00:49:46.380 --> 00:49:47.520
building services.

00:49:47.520 --> 00:49:51.820
And this helps deal with the
reality of what it means to

00:49:51.820 --> 00:49:52.910
run in a data center.

00:49:52.910 --> 00:49:54.960
Software and hardware
will fail.

00:49:54.960 --> 00:49:57.220
And if you can launch more
machines, if you can deal with

00:49:57.220 --> 00:49:59.300
more hardware, you're going to
have a lot more exposure to

00:49:59.300 --> 00:50:00.360
that failure.

00:50:00.360 --> 00:50:02.010
And so something that becomes
a once in awhile

00:50:02.010 --> 00:50:03.530
event becomes a--

00:50:03.530 --> 00:50:08.140
it happens more often
than you would like.

00:50:08.140 --> 00:50:11.200
Hopefully not that often.

00:50:11.200 --> 00:50:15.170
So we really want people to use
patterns where they build

00:50:15.170 --> 00:50:16.120
across zones.

00:50:16.120 --> 00:50:18.480
They think about using that
ephemeral disk as really a

00:50:18.480 --> 00:50:20.290
cache or a scratch area.

00:50:20.290 --> 00:50:23.350
You build automation, either
through building your own

00:50:23.350 --> 00:50:26.940
systems , building on top of App
Engine, which is a great

00:50:26.940 --> 00:50:28.840
infrastructure for building the
automation to manage this

00:50:28.840 --> 00:50:33.920
stuff, or by using one of our
partners like RightScale, or

00:50:33.920 --> 00:50:38.070
Puppet, or Opscode to do this
stuff or any number of open

00:50:38.070 --> 00:50:40.010
source projects that are built
to do this type of

00:50:40.010 --> 00:50:41.590
orchestration role.

00:50:41.590 --> 00:50:43.260
Now, one other thing that I want
to mention here is that

00:50:43.260 --> 00:50:45.330
during our limited preview,
we're going to have these

00:50:45.330 --> 00:50:46.760
things that we're calling
maintenance windows, where

00:50:46.760 --> 00:50:50.130
we're actually going to be
updating both are our hardware

00:50:50.130 --> 00:50:52.310
and software in the data centers
that we're running in.

00:50:52.310 --> 00:50:55.030
And so this will be up to two
weeks every 20 weeks.

00:50:55.030 --> 00:50:56.030
We're going to work
to keep these

00:50:56.030 --> 00:50:57.290
things as short as possible.

00:50:57.290 --> 00:50:58.880
We're only going to do one at a
time we're going to give you

00:50:58.880 --> 00:51:00.260
plenty of warning.

00:51:00.260 --> 00:51:03.340
But I think this is an example
of what it means to actually

00:51:03.340 --> 00:51:06.740
be in a data center and having
to deal with regular

00:51:06.740 --> 00:51:08.290
maintenance.

00:51:08.290 --> 00:51:10.070
We're going to be addressing
this in future visions.

00:51:10.070 --> 00:51:13.730
This is not something that is
going to be a long-term

00:51:13.730 --> 00:51:16.190
quality of the system.

00:51:16.190 --> 00:51:19.300
And so with that, I'd like to
invite you all to apply to our

00:51:19.300 --> 00:51:21.790
limited preview program.

00:51:21.790 --> 00:51:23.790
Like I said, we're starting
with large scale computes.

00:51:23.790 --> 00:51:27.980
And as we are able to build
out our capability to take

00:51:27.980 --> 00:51:30.050
customers on, we'll be expanding
that and we'll be

00:51:30.050 --> 00:51:32.520
expanding the number
of customers.

00:51:32.520 --> 00:51:34.010
So if anybody has any
questions, I'd

00:51:34.010 --> 00:51:34.760
love to answer them.

00:51:34.760 --> 00:51:38.930
And there's Evan, and
the other team

00:51:38.930 --> 00:51:39.795
members are here also.

00:51:39.795 --> 00:51:42.590
Step up to the microphone.

00:51:42.590 --> 00:51:43.060
AUDIENCE: Hello.

00:51:43.060 --> 00:51:44.520
I have a question.

00:51:44.520 --> 00:51:49.710
How about, perhaps not now but
later, government compliance

00:51:49.710 --> 00:51:54.450
for the data transport and
all that kind of thing?

00:51:54.450 --> 00:51:57.760
Government, like a HIPAA or
something like that, PCI

00:51:57.760 --> 00:52:00.660
compliance.

00:52:00.660 --> 00:52:02.650
JOE BEDA: Craig, do you
want to answer this?

00:52:02.650 --> 00:52:04.800
So I'd like to introduce--

00:52:04.800 --> 00:52:07.520
Craig McLuckie is the lead
product manager for Google

00:52:07.520 --> 00:52:08.090
Compute Engine.

00:52:08.090 --> 00:52:09.230
CRAIG MCLUCKIE: Hey,
how are you doing?

00:52:09.230 --> 00:52:11.360
So the question was
around compliance?

00:52:11.360 --> 00:52:14.440
AUDIENCE: Yeah, the question is
basically do you guys plan

00:52:14.440 --> 00:52:17.865
or have already some sort of
compliance certification like

00:52:17.865 --> 00:52:19.900
the HIPAA or something
like that?

00:52:19.900 --> 00:52:21.180
CRAIG MCLUCKIE: That's
a great question.

00:52:21.180 --> 00:52:22.780
Obviously, for a lot
of businesses,

00:52:22.780 --> 00:52:24.170
compliance is critical.

00:52:24.170 --> 00:52:25.840
At this point we haven't
started focusing on

00:52:25.840 --> 00:52:28.220
compliance-related issues.

00:52:28.220 --> 00:52:29.180
It's something we'll absolutely

00:52:29.180 --> 00:52:30.380
consider as we move forward.

00:52:30.380 --> 00:52:32.300
But I can't actually make
any clean statements

00:52:32.300 --> 00:52:33.550
about that right now.

00:52:35.740 --> 00:52:36.690
AUDIENCE: Two questions.

00:52:36.690 --> 00:52:39.000
Where is the key for
the persistent

00:52:39.000 --> 00:52:41.320
storage being stored?

00:52:41.320 --> 00:52:43.810
JOE BEDA: What is the key?

00:52:43.810 --> 00:52:48.070
Deep experience with running
distributed systems--

00:52:48.070 --> 00:52:49.683
CRAIG MCLUCKIE: Sorry, I think
the question was where is the

00:52:49.683 --> 00:52:50.410
key being stored.

00:52:50.410 --> 00:52:52.080
JOE BEDA: Oh, where's the key?

00:52:52.080 --> 00:52:53.810
Oh, OK.

00:52:53.810 --> 00:52:57.675
So what is the key or
where is the key.

00:52:57.675 --> 00:53:02.420
So we store that in our
management infrastructure.

00:53:02.420 --> 00:53:05.390
But Google has a bunch of
systems in place to actually

00:53:05.390 --> 00:53:09.490
isolate and further encrypt that
key to control it with

00:53:09.490 --> 00:53:10.790
key rotation policies.

00:53:10.790 --> 00:53:14.470
And I think this really comes
back to the compliance issue.

00:53:14.470 --> 00:53:16.020
I mean that's the type of
thing that we'd like to

00:53:16.020 --> 00:53:20.010
document and provide some
exposure into as we move down

00:53:20.010 --> 00:53:20.960
those paths.

00:53:20.960 --> 00:53:24.470
But we're very careful to make
sure that we control access to

00:53:24.470 --> 00:53:28.550
that key and securely know
how to delete it.

00:53:28.550 --> 00:53:30.900
AUDIENCE: My second
question is--

00:53:30.900 --> 00:53:33.860
I know with Google App Engine
you have the scheduler that'll

00:53:33.860 --> 00:53:36.590
spin up new instances based
on a load balancer

00:53:36.590 --> 00:53:38.830
and a number of hits.

00:53:38.830 --> 00:53:43.820
Since you have public facing
IPs, is there a plan to have

00:53:43.820 --> 00:53:47.450
some sort of a load balancer to
push into that or are they

00:53:47.450 --> 00:53:50.360
just going to be more
back end instances?

00:53:50.360 --> 00:53:53.860
JOE BEDA: So this is definitely
a feature that

00:53:53.860 --> 00:53:55.020
we're missing right now.

00:53:55.020 --> 00:53:58.550
And it's one of the reasons
why we're concentrating on

00:53:58.550 --> 00:54:01.150
these batch workloads.

00:54:01.150 --> 00:54:04.720
And as we continue to develop
the product, that's the type

00:54:04.720 --> 00:54:07.920
of thing that we're going
to want to address.

00:54:07.920 --> 00:54:12.170
AUDIENCE: And you're using BGP
to get the traffic off the net

00:54:12.170 --> 00:54:14.950
onto your local networks
and route it into the--

00:54:14.950 --> 00:54:17.160
JOE BEDA: Actually what we're
doing is we're advertising all

00:54:17.160 --> 00:54:20.320
these IP addresses
with anycast.

00:54:20.320 --> 00:54:23.430
And no matter where they are
we get them onto Google's

00:54:23.430 --> 00:54:27.940
network and then we encapsulate
it and then

00:54:27.940 --> 00:54:31.360
forward it on with your
virtual network.

00:54:31.360 --> 00:54:35.750
So yeah, there's BGP to get the
data as soon as possible.

00:54:35.750 --> 00:54:37.800
But we're actually--

00:54:37.800 --> 00:54:39.730
like I said, anywhere in the
world we try and get it on our

00:54:39.730 --> 00:54:40.980
network as fast as possible.

00:54:44.080 --> 00:54:46.570
AUDIENCE: I have another
question.

00:54:46.570 --> 00:54:50.750
When you provision a project,
does that provision the

00:54:50.750 --> 00:54:53.560
virtual private network
automatically for you?

00:54:53.560 --> 00:54:56.680
So any instance in that project
will automatically be

00:54:56.680 --> 00:54:59.610
part of that virtual
private network?

00:54:59.610 --> 00:55:01.560
JOE BEDA: Yeah, there's a little
bit of detail that I

00:55:01.560 --> 00:55:02.250
glossed over.

00:55:02.250 --> 00:55:05.200
And if you dig into the API
docs, you'll see this.

00:55:05.200 --> 00:55:08.570
You can actually have multiple
virtual networks, as many as

00:55:08.570 --> 00:55:11.540
you want, in your project.

00:55:11.540 --> 00:55:14.450
We create one called Default by
default, and all our tools

00:55:14.450 --> 00:55:18.300
are built to reference that
project by default.

00:55:18.300 --> 00:55:20.450
We find that most users
don't need more than

00:55:20.450 --> 00:55:21.510
the one virtual network.

00:55:21.510 --> 00:55:23.680
But there's going to be a couple
situation where you're

00:55:23.680 --> 00:55:26.230
going to want to have separate
VMs running their own isolated

00:55:26.230 --> 00:55:28.050
virtual networks.

00:55:28.050 --> 00:55:32.400
AUDIENCE: Just a quick follow-up
question to that.

00:55:32.400 --> 00:55:37.360
I believe you said that all the
instances across different

00:55:37.360 --> 00:55:42.880
regions in that project will
be covered under the same

00:55:42.880 --> 00:55:44.323
virtual private network?

00:55:44.323 --> 00:55:45.050
JOE BEDA: Yes.

00:55:45.050 --> 00:55:46.900
AUDIENCE: And then
that never--

00:55:46.900 --> 00:55:48.390
or almost never I suppose--

00:55:48.390 --> 00:55:49.910
hits the actual internet?

00:55:49.910 --> 00:55:52.060
It goes through your
pipeline, right?

00:55:52.060 --> 00:55:52.510
JOE BEDA: Exactly.

00:55:52.510 --> 00:55:55.510
So if you're communicating
between two virtual machines

00:55:55.510 --> 00:55:58.560
over this private network, this
private virtual network

00:55:58.560 --> 00:56:00.750
across regions, it will
stay within Google's

00:56:00.750 --> 00:56:03.040
network as we do that.

00:56:03.040 --> 00:56:07.770
And we can provide a much more
consistent experience and much

00:56:07.770 --> 00:56:10.360
more secure and sort of easy
by default experience with

00:56:10.360 --> 00:56:13.940
moving data between regions.

00:56:13.940 --> 00:56:17.920
AUDIENCE: If I launch, say,
four instances, is there a

00:56:17.920 --> 00:56:20.270
guarantee they won't be
on the same hardware?

00:56:20.270 --> 00:56:23.400
Or is there some risk I could
end up running all my VMs on

00:56:23.400 --> 00:56:24.990
the same piece of equipment?

00:56:24.990 --> 00:56:27.490
JOE BEDA: That's a
great question.

00:56:27.490 --> 00:56:30.000
I think we try hard to make
sure that doesn't

00:56:30.000 --> 00:56:30.800
happen right now.

00:56:30.800 --> 00:56:33.150
We don't offer any guarantees.

00:56:33.150 --> 00:56:35.020
But that's definitely
something that

00:56:35.020 --> 00:56:37.484
we're thinking about.

00:56:37.484 --> 00:56:39.600
EVAN ANDERSON: I don't know that
I could actually do that

00:56:39.600 --> 00:56:41.250
on purpose if I wanted to
but there's a chance.

00:56:41.250 --> 00:56:42.150
JOE BEDA: What's that?

00:56:42.150 --> 00:56:44.730
EVAN ANDERSON: I was saying that
I don't know that I could

00:56:44.730 --> 00:56:48.030
actually get four-- you know,
if launched four virtual

00:56:48.030 --> 00:56:50.450
machines from the API, that I
could get them to land on the

00:56:50.450 --> 00:56:52.390
same machine if I tried.

00:56:52.390 --> 00:56:53.390
But there's a chance.

00:56:53.390 --> 00:56:56.300
JOE BEDA: I mean just to be
clear, for our own testing we

00:56:56.300 --> 00:56:58.590
do sort of what we call stack
testing, where we try and load

00:56:58.590 --> 00:57:01.270
as many VMs as possible on a
single physical machine to

00:57:01.270 --> 00:57:02.910
test out this consistency.

00:57:02.910 --> 00:57:04.790
And we've had to do some
specialized things to actually

00:57:04.790 --> 00:57:06.910
force them to land on the same
machine for those cases.

00:57:09.430 --> 00:57:14.190
AUDIENCE: Can I specify the IP
space within my project?

00:57:14.190 --> 00:57:16.070
JOE BEDA: The IP space for
the virtual network?

00:57:16.070 --> 00:57:17.120
AUDIENCE: Yes.

00:57:17.120 --> 00:57:21.330
JOE BEDA: Yes you can specify,
I believe, any 1918 IP space.

00:57:21.330 --> 00:57:21.660
Yeah.

00:57:21.660 --> 00:57:22.910
AUDIENCE: OK.

00:57:22.910 --> 00:57:26.840
And then within a project or--

00:57:26.840 --> 00:57:29.920
so the use case I'm thinking
about is I have development

00:57:29.920 --> 00:57:33.680
teams, and I want to basically
give them a project.

00:57:33.680 --> 00:57:36.000
And they need to talk
to each other.

00:57:36.000 --> 00:57:38.550
Can I isolate one development
team from terminating

00:57:38.550 --> 00:57:43.960
resources and instances in
another project based on some

00:57:43.960 --> 00:57:45.050
sort of a role or--

00:57:45.050 --> 00:57:46.890
EVAN ANDERSON: If those two--

00:57:46.890 --> 00:57:49.700
if you have two separate
projects, they will be

00:57:49.700 --> 00:57:50.930
isolated from each other.

00:57:50.930 --> 00:57:51.360
AUDIENCE: OK.

00:57:51.360 --> 00:57:53.510
So and what if I wanted
the two projects to

00:57:53.510 --> 00:57:54.520
talk to each other?

00:57:54.520 --> 00:57:56.030
Should I not use
projects then?

00:57:56.030 --> 00:57:59.500
Should I use one
project with--

00:57:59.500 --> 00:58:02.000
JOE BEDA: So what you can do
is you can actually add the

00:58:02.000 --> 00:58:04.650
service account from one project
to the team of the

00:58:04.650 --> 00:58:05.750
other project.

00:58:05.750 --> 00:58:07.830
And so you can give one project
permission to actually

00:58:07.830 --> 00:58:11.510
call the Compute Engine API
of the other project.

00:58:11.510 --> 00:58:14.390
And so the interesting thing
about Service Accounts is you

00:58:14.390 --> 00:58:16.130
can add them to any
other [INAUDIBLE].

00:58:16.130 --> 00:58:18.330
It's really sort of like
a synthetic user.

00:58:22.280 --> 00:58:25.750
AUDIENCE: You mentioned that
you can mount a persistent

00:58:25.750 --> 00:58:29.190
storage device read, write on a
single instance or read only

00:58:29.190 --> 00:58:30.240
on multiple instances.

00:58:30.240 --> 00:58:32.090
Can you do that simultaneously?

00:58:32.090 --> 00:58:32.460
Read, write on one and--

00:58:32.460 --> 00:58:33.380
EVAN ANDERSON: No.

00:58:33.380 --> 00:58:33.620
AUDIENCE: OK.

00:58:33.620 --> 00:58:36.536
So it's read only on all and
then you have to unmount--

00:58:36.536 --> 00:58:39.620
EVAN ANDERSON: Linux doesn't
like it when you do that.

00:58:39.620 --> 00:58:41.390
JOE BEDA: Yeah, there are
specialized file systems that

00:58:41.390 --> 00:58:44.880
actually do deal with multiple
parties partying on the same

00:58:44.880 --> 00:58:45.840
disk at the same time.

00:58:45.840 --> 00:58:47.630
It's relatively esoteric.

00:58:47.630 --> 00:58:49.830
And one of the ways that
we can get the type of

00:58:49.830 --> 00:58:53.520
performance that we can is by
doing fairly aggressive sort

00:58:53.520 --> 00:59:00.060
of caching and mapping
on the same machine

00:59:00.060 --> 00:59:02.480
as the virtual machine.

00:59:02.480 --> 00:59:06.150
AUDIENCE: Hey, is it possibly to
run Asterisk on top off the

00:59:06.150 --> 00:59:08.320
Compute Engine?

00:59:08.320 --> 00:59:10.380
JOE BEDA: I don't know if
anybody has, but there should

00:59:10.380 --> 00:59:12.430
be no reason why you couldn't.

00:59:12.430 --> 00:59:18.180
In fact, we were just talking
with one of the members of the

00:59:18.180 --> 00:59:22.470
Web RTC team about him using
Compute Engine to actually run

00:59:22.470 --> 00:59:25.300
some code to test out real-time
communications.

00:59:25.300 --> 00:59:27.880
So that's definitely something
that we think is appropriate

00:59:27.880 --> 00:59:28.975
for Compute Engine eventually.

00:59:28.975 --> 00:59:29.250
AUDIENCE: OK.

00:59:29.250 --> 00:59:33.190
And another question, would we
be getting some free instances

00:59:33.190 --> 00:59:35.290
to try it out?

00:59:35.290 --> 00:59:36.780
JOE BEDA: So Craig?

00:59:36.780 --> 00:59:38.863
CRAIG MCLUCKIE: So yeah,
so we invite you to

00:59:38.863 --> 00:59:40.760
apply to the program.

00:59:40.760 --> 00:59:44.000
So we have a program, which is
a limited preview program.

00:59:44.000 --> 00:59:46.720
And folks that we accept into
that program will absolutely

00:59:46.720 --> 00:59:48.350
get some free instances.

00:59:48.350 --> 00:59:51.090
Now, obviously, there's a pretty
high demand for free

00:59:51.090 --> 00:59:53.950
compute, so we can't give it
to everybody right away.

00:59:53.950 --> 00:59:56.360
So please do apply to the
program and just give a little

00:59:56.360 --> 00:59:58.690
description of the specifics
of the workload.

00:59:58.690 --> 01:00:00.610
And we'll put you
into the queue.

01:00:00.610 --> 01:00:02.130
And as soon as we can
service that, we

01:00:02.130 --> 01:00:03.520
will offer you access.

01:00:03.520 --> 01:00:05.840
EVAN ANDERSON: We also want to
make sure that our first

01:00:05.840 --> 01:00:07.910
customers for the limited
preview have a really good

01:00:07.910 --> 01:00:09.200
support experience, as well.

01:00:09.200 --> 01:00:11.770
So that's another reason why
we're limiting the total

01:00:11.770 --> 01:00:12.790
number of people
to start with.

01:00:12.790 --> 01:00:14.040
CRAIG MCLUCKIE: Absolutely.

01:00:15.780 --> 01:00:18.700
AUDIENCE: Hi, I would like to
know how much is the lag

01:00:18.700 --> 01:00:23.580
between the App Engine and the
service, and if it's feasible

01:00:23.580 --> 01:00:25.555
to tie the [INAUDIBLE]

01:00:25.555 --> 01:00:31.780
that is running the instances
with my App Engine up?

01:00:31.780 --> 01:00:31.880
JOE BEDA: I'm sorry.

01:00:31.880 --> 01:00:33.410
I didn't quite understand.

01:00:33.410 --> 01:00:34.950
So App Engine and
Compute Engine--

01:00:34.950 --> 01:00:36.410
AUDIENCE: How much is the lag?

01:00:36.410 --> 01:00:36.920
JOE BEDA: Oh the lag.

01:00:36.920 --> 01:00:40.090
AUDIENCE: Like the round
trip between--?

01:00:40.090 --> 01:00:43.660
JOE BEDA: So Adam did some
experiments recently, I think.

01:00:43.660 --> 01:00:44.720
CRAIG MCLUCKIE: We don't
have numbers we can

01:00:44.720 --> 01:00:45.860
publish right now.

01:00:45.860 --> 01:00:50.200
What we can say is that a lot of
our early partners and our

01:00:50.200 --> 01:00:52.390
early customers that have used
the service have been

01:00:52.390 --> 01:00:55.840
extremely impressed by our very
high-speed global network

01:00:55.840 --> 01:00:58.530
backbone that all of this
is running over.

01:00:58.530 --> 01:01:02.380
So we don't make any strong
guarantees about that latency.

01:01:02.380 --> 01:01:05.060
But our early users have been
consistently impressed with

01:01:05.060 --> 01:01:09.550
their ability to access other
services like Google App

01:01:09.550 --> 01:01:12.060
Engine, or a Google storage
product, or anything else

01:01:12.060 --> 01:01:14.320
that's in the Google portfolio
of technologies.

01:01:14.320 --> 01:01:17.300
So if you have access, do try
it out and let us know.

01:01:20.210 --> 01:01:22.460
JOE BEDA: And with that, I
think we're out of time.

01:01:22.460 --> 01:01:24.090
I thank everybody for coming.

01:01:24.090 --> 01:01:25.810
Feel free to grab us--

01:01:25.810 --> 01:01:28.060
do we have the booth tomorrow?

01:01:28.060 --> 01:01:28.880
CRAIG MCLUCKIE: Yeah,
we've got the booth.

01:01:28.880 --> 01:01:30.280
So stop by, say hello.

01:01:30.280 --> 01:01:33.130
JOE BEDA: So yeah, I really
enjoy answering the questions,

01:01:33.130 --> 01:01:34.800
and I want to continue doing
so, but we're out of time.

01:01:34.800 --> 01:01:36.050
Thank you very much.

