WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.360 align:start position:0%
 
so<00:00:00.390><c> what</c><00:00:00.719><c> a</c><00:00:00.750><c> deep</c><00:00:01.020><c> learning</c><00:00:01.439><c> have</c><00:00:01.740><c> to</c><00:00:01.890><c> do</c><00:00:02.070><c> the</c>

00:00:02.360 --> 00:00:02.370 align:start position:0%
so what a deep learning have to do the
 

00:00:02.370 --> 00:00:04.370 align:start position:0%
so what a deep learning have to do the
brain<00:00:02.639><c> at</c><00:00:02.939><c> the</c><00:00:03.360><c> risk</c><00:00:03.570><c> of</c><00:00:03.720><c> giving</c><00:00:03.929><c> away</c><00:00:04.230><c> the</c>

00:00:04.370 --> 00:00:04.380 align:start position:0%
brain at the risk of giving away the
 

00:00:04.380 --> 00:00:06.470 align:start position:0%
brain at the risk of giving away the
punchline<00:00:04.650><c> I</c><00:00:05.069><c> would</c><00:00:05.220><c> say</c><00:00:05.430><c> not</c><00:00:06.000><c> a</c><00:00:06.029><c> whole</c><00:00:06.299><c> lot</c>

00:00:06.470 --> 00:00:06.480 align:start position:0%
punchline I would say not a whole lot
 

00:00:06.480 --> 00:00:08.660 align:start position:0%
punchline I would say not a whole lot
but<00:00:07.109><c> let's</c><00:00:07.290><c> take</c><00:00:07.799><c> a</c><00:00:07.830><c> quick</c><00:00:08.099><c> look</c><00:00:08.309><c> at</c><00:00:08.519><c> why</c>

00:00:08.660 --> 00:00:08.670 align:start position:0%
but let's take a quick look at why
 

00:00:08.670 --> 00:00:10.459 align:start position:0%
but let's take a quick look at why
people<00:00:08.700><c> keep</c><00:00:09.330><c> making</c><00:00:09.480><c> the</c><00:00:09.780><c> analogy</c><00:00:10.200><c> between</c>

00:00:10.459 --> 00:00:10.469 align:start position:0%
people keep making the analogy between
 

00:00:10.469 --> 00:00:13.490 align:start position:0%
people keep making the analogy between
deep<00:00:10.920><c> learning</c><00:00:11.099><c> and</c><00:00:11.490><c> the</c><00:00:12.300><c> human</c><00:00:12.630><c> brain</c><00:00:12.780><c> when</c>

00:00:13.490 --> 00:00:13.500 align:start position:0%
deep learning and the human brain when
 

00:00:13.500 --> 00:00:15.440 align:start position:0%
deep learning and the human brain when
you<00:00:13.769><c> implement</c><00:00:14.370><c> a</c><00:00:14.460><c> neural</c><00:00:14.610><c> network</c><00:00:14.910><c> this</c><00:00:15.389><c> is</c>

00:00:15.440 --> 00:00:15.450 align:start position:0%
you implement a neural network this is
 

00:00:15.450 --> 00:00:18.590 align:start position:0%
you implement a neural network this is
what<00:00:15.929><c> you</c><00:00:16.109><c> do</c><00:00:16.260><c> for</c><00:00:16.590><c> prop</c><00:00:16.920><c> and</c><00:00:17.160><c> back</c><00:00:17.220><c> prop</c><00:00:17.520><c> and</c><00:00:18.119><c> I</c>

00:00:18.590 --> 00:00:18.600 align:start position:0%
what you do for prop and back prop and I
 

00:00:18.600 --> 00:00:20.269 align:start position:0%
what you do for prop and back prop and I
think<00:00:18.840><c> because</c><00:00:19.199><c> it's</c><00:00:19.410><c> been</c><00:00:19.560><c> difficult</c><00:00:20.100><c> to</c>

00:00:20.269 --> 00:00:20.279 align:start position:0%
think because it's been difficult to
 

00:00:20.279 --> 00:00:22.700 align:start position:0%
think because it's been difficult to
convey<00:00:20.609><c> intuitions</c><00:00:21.390><c> about</c><00:00:21.600><c> what</c><00:00:21.810><c> these</c>

00:00:22.700 --> 00:00:22.710 align:start position:0%
convey intuitions about what these
 

00:00:22.710 --> 00:00:24.560 align:start position:0%
convey intuitions about what these
equations<00:00:23.279><c> are</c><00:00:23.460><c> doing</c><00:00:23.820><c> really</c><00:00:24.060><c> great</c><00:00:24.330><c> and</c>

00:00:24.560 --> 00:00:24.570 align:start position:0%
equations are doing really great and
 

00:00:24.570 --> 00:00:27.140 align:start position:0%
equations are doing really great and
descends<00:00:25.019><c> on</c><00:00:25.140><c> a</c><00:00:25.170><c> very</c><00:00:25.470><c> complex</c><00:00:25.920><c> function</c><00:00:26.400><c> the</c>

00:00:27.140 --> 00:00:27.150 align:start position:0%
descends on a very complex function the
 

00:00:27.150 --> 00:00:29.720 align:start position:0%
descends on a very complex function the
analogy<00:00:27.750><c> that</c><00:00:27.779><c> is</c><00:00:28.349><c> like</c><00:00:28.650><c> the</c><00:00:28.830><c> brain</c><00:00:29.070><c> has</c>

00:00:29.720 --> 00:00:29.730 align:start position:0%
analogy that is like the brain has
 

00:00:29.730 --> 00:00:32.389 align:start position:0%
analogy that is like the brain has
become<00:00:30.349><c> really</c><00:00:31.349><c> an</c><00:00:31.529><c> oversimplified</c>

00:00:32.389 --> 00:00:32.399 align:start position:0%
become really an oversimplified
 

00:00:32.399 --> 00:00:34.430 align:start position:0%
become really an oversimplified
explanation<00:00:33.210><c> for</c><00:00:33.420><c> what</c><00:00:33.600><c> this</c><00:00:33.719><c> is</c><00:00:33.899><c> doing</c><00:00:34.110><c> but</c>

00:00:34.430 --> 00:00:34.440 align:start position:0%
explanation for what this is doing but
 

00:00:34.440 --> 00:00:36.650 align:start position:0%
explanation for what this is doing but
the<00:00:34.559><c> simplicity</c><00:00:34.770><c> of</c><00:00:35.309><c> this</c><00:00:35.550><c> makes</c><00:00:35.880><c> it</c><00:00:36.059><c> you</c><00:00:36.540><c> know</c>

00:00:36.650 --> 00:00:36.660 align:start position:0%
the simplicity of this makes it you know
 

00:00:36.660 --> 00:00:39.139 align:start position:0%
the simplicity of this makes it you know
kind<00:00:36.870><c> of</c><00:00:36.899><c> seductive</c><00:00:37.500><c> for</c><00:00:37.800><c> people</c><00:00:38.730><c> to</c><00:00:38.790><c> just</c><00:00:38.969><c> say</c>

00:00:39.139 --> 00:00:39.149 align:start position:0%
kind of seductive for people to just say
 

00:00:39.149 --> 00:00:41.389 align:start position:0%
kind of seductive for people to just say
it<00:00:39.300><c> publicly</c><00:00:39.450><c> as</c><00:00:40.020><c> well</c><00:00:40.290><c> as</c><00:00:40.469><c> the</c><00:00:40.710><c> media</c><00:00:41.190><c> to</c>

00:00:41.389 --> 00:00:41.399 align:start position:0%
it publicly as well as the media to
 

00:00:41.399 --> 00:00:43.280 align:start position:0%
it publicly as well as the media to
report<00:00:41.550><c> it</c><00:00:42.000><c> and</c><00:00:42.270><c> certainly</c><00:00:42.690><c> called</c><00:00:43.140><c> the</c>

00:00:43.280 --> 00:00:43.290 align:start position:0%
report it and certainly called the
 

00:00:43.290 --> 00:00:45.889 align:start position:0%
report it and certainly called the
popular<00:00:43.680><c> imagination</c><00:00:43.920><c> and</c><00:00:44.700><c> there</c><00:00:45.120><c> is</c><00:00:45.300><c> a</c><00:00:45.629><c> very</c>

00:00:45.889 --> 00:00:45.899 align:start position:0%
popular imagination and there is a very
 

00:00:45.899 --> 00:00:48.459 align:start position:0%
popular imagination and there is a very
loose<00:00:46.200><c> analogy</c><00:00:46.829><c> between</c><00:00:47.180><c> let's</c><00:00:48.180><c> say</c><00:00:48.390><c> a</c>

00:00:48.459 --> 00:00:48.469 align:start position:0%
loose analogy between let's say a
 

00:00:48.469 --> 00:00:51.770 align:start position:0%
loose analogy between let's say a
logistic<00:00:49.469><c> regression</c><00:00:49.980><c> unit</c><00:00:50.340><c> with</c><00:00:51.270><c> a</c><00:00:51.300><c> sigmoid</c>

00:00:51.770 --> 00:00:51.780 align:start position:0%
logistic regression unit with a sigmoid
 

00:00:51.780 --> 00:00:55.939 align:start position:0%
logistic regression unit with a sigmoid
activation<00:00:51.960><c> function</c><00:00:52.410><c> and</c><00:00:54.320><c> here's</c><00:00:55.320><c> a</c><00:00:55.440><c> cartoon</c>

00:00:55.939 --> 00:00:55.949 align:start position:0%
activation function and here's a cartoon
 

00:00:55.949 --> 00:00:58.580 align:start position:0%
activation function and here's a cartoon
of<00:00:56.160><c> a</c><00:00:56.280><c> single</c><00:00:56.670><c> neuron</c><00:00:56.699><c> in</c><00:00:57.420><c> the</c><00:00:57.510><c> brain</c><00:00:57.690><c> in</c><00:00:58.350><c> this</c>

00:00:58.580 --> 00:00:58.590 align:start position:0%
of a single neuron in the brain in this
 

00:00:58.590 --> 00:01:01.880 align:start position:0%
of a single neuron in the brain in this
picture<00:00:59.010><c> of</c><00:00:59.039><c> a</c><00:00:59.340><c> biological</c><00:00:59.910><c> neuron</c><00:01:00.300><c> on</c><00:01:00.890><c> this</c>

00:01:01.880 --> 00:01:01.890 align:start position:0%
picture of a biological neuron on this
 

00:01:01.890 --> 00:01:03.590 align:start position:0%
picture of a biological neuron on this
neuron<00:01:02.399><c> which</c><00:01:02.609><c> is</c><00:01:02.730><c> a</c><00:01:02.760><c> cell</c><00:01:03.090><c> in</c><00:01:03.239><c> your</c><00:01:03.359><c> brain</c>

00:01:03.590 --> 00:01:03.600 align:start position:0%
neuron which is a cell in your brain
 

00:01:03.600 --> 00:01:06.320 align:start position:0%
neuron which is a cell in your brain
receives<00:01:04.320><c> electric</c><00:01:04.920><c> signals</c><00:01:05.400><c> from</c><00:01:05.790><c> you</c><00:01:06.240><c> know</c>

00:01:06.320 --> 00:01:06.330 align:start position:0%
receives electric signals from you know
 

00:01:06.330 --> 00:01:09.410 align:start position:0%
receives electric signals from you know
other<00:01:06.630><c> neurons</c><00:01:07.260><c> mu</c><00:01:07.920><c> X</c><00:01:08.189><c> 1</c><00:01:08.400><c> X</c><00:01:08.580><c> 2</c><00:01:08.640><c> X</c><00:01:08.880><c> 3</c><00:01:09.000><c> or</c><00:01:09.270><c> maybe</c>

00:01:09.410 --> 00:01:09.420 align:start position:0%
other neurons mu X 1 X 2 X 3 or maybe
 

00:01:09.420 --> 00:01:12.289 align:start position:0%
other neurons mu X 1 X 2 X 3 or maybe
from<00:01:09.570><c> other</c><00:01:09.750><c> neurons</c><00:01:10.290><c> a</c><00:01:10.500><c> 1</c><00:01:10.740><c> a</c><00:01:10.770><c> 2</c><00:01:10.890><c> a</c><00:01:11.040><c> 3</c><00:01:11.210><c> there's</c><00:01:12.210><c> a</c>

00:01:12.289 --> 00:01:12.299 align:start position:0%
from other neurons a 1 a 2 a 3 there's a
 

00:01:12.299 --> 00:01:15.109 align:start position:0%
from other neurons a 1 a 2 a 3 there's a
simple<00:01:12.720><c> thresholded</c><00:01:13.409><c> computation</c><00:01:14.159><c> and</c><00:01:14.369><c> then</c>

00:01:15.109 --> 00:01:15.119 align:start position:0%
simple thresholded computation and then
 

00:01:15.119 --> 00:01:17.840 align:start position:0%
simple thresholded computation and then
if<00:01:15.720><c> this</c><00:01:15.990><c> neuron</c><00:01:16.380><c> fires</c><00:01:16.890><c> it</c><00:01:17.130><c> sends</c><00:01:17.430><c> a</c><00:01:17.490><c> pulse</c><00:01:17.640><c> of</c>

00:01:17.840 --> 00:01:17.850 align:start position:0%
if this neuron fires it sends a pulse of
 

00:01:17.850 --> 00:01:20.690 align:start position:0%
if this neuron fires it sends a pulse of
electricity<00:01:18.240><c> down</c><00:01:19.080><c> the</c><00:01:19.290><c> axon</c><00:01:19.770><c> down</c><00:01:20.250><c> this</c><00:01:20.460><c> long</c>

00:01:20.690 --> 00:01:20.700 align:start position:0%
electricity down the axon down this long
 

00:01:20.700 --> 00:01:23.630 align:start position:0%
electricity down the axon down this long
wire<00:01:21.000><c> I</c><00:01:21.420><c> have</c><00:01:22.020><c> two</c><00:01:22.259><c> other</c><00:01:22.500><c> neurons</c><00:01:23.040><c> so</c><00:01:23.430><c> there</c>

00:01:23.630 --> 00:01:23.640 align:start position:0%
wire I have two other neurons so there
 

00:01:23.640 --> 00:01:27.469 align:start position:0%
wire I have two other neurons so there
is<00:01:23.790><c> a</c><00:01:24.000><c> very</c><00:01:24.950><c> simplistic</c><00:01:25.950><c> analogy</c><00:01:26.880><c> between</c><00:01:27.270><c> a</c>

00:01:27.469 --> 00:01:27.479 align:start position:0%
is a very simplistic analogy between a
 

00:01:27.479 --> 00:01:29.569 align:start position:0%
is a very simplistic analogy between a
single<00:01:27.780><c> logistic</c><00:01:28.350><c> unit</c><00:01:28.740><c> between</c><00:01:29.130><c> a</c><00:01:29.280><c> single</c>

00:01:29.569 --> 00:01:29.579 align:start position:0%
single logistic unit between a single
 

00:01:29.579 --> 00:01:32.179 align:start position:0%
single logistic unit between a single
neuron<00:01:30.060><c> and</c><00:01:30.240><c> your</c><00:01:30.479><c> network</c><00:01:30.720><c> and</c><00:01:31.170><c> a</c><00:01:31.530><c> biological</c>

00:01:32.179 --> 00:01:32.189 align:start position:0%
neuron and your network and a biological
 

00:01:32.189 --> 00:01:35.090 align:start position:0%
neuron and your network and a biological
neuron<00:01:32.549><c> like</c><00:01:32.729><c> that</c><00:01:32.970><c> shown</c><00:01:33.570><c> on</c><00:01:33.720><c> a</c><00:01:33.780><c> right</c><00:01:34.049><c> but</c><00:01:34.860><c> I</c>

00:01:35.090 --> 00:01:35.100 align:start position:0%
neuron like that shown on a right but I
 

00:01:35.100 --> 00:01:37.490 align:start position:0%
neuron like that shown on a right but I
think<00:01:35.430><c> that</c><00:01:35.579><c> today</c><00:01:36.000><c> even</c><00:01:36.500><c> neuroscientists</c>

00:01:37.490 --> 00:01:37.500 align:start position:0%
think that today even neuroscientists
 

00:01:37.500 --> 00:01:40.160 align:start position:0%
think that today even neuroscientists
have<00:01:37.680><c> almost</c><00:01:38.189><c> no</c><00:01:38.430><c> idea</c><00:01:38.850><c> what</c><00:01:39.509><c> even</c><00:01:39.840><c> a</c><00:01:39.930><c> single</c>

00:01:40.160 --> 00:01:40.170 align:start position:0%
have almost no idea what even a single
 

00:01:40.170 --> 00:01:42.710 align:start position:0%
have almost no idea what even a single
neuron<00:01:40.710><c> is</c><00:01:40.890><c> doing</c><00:01:41.250><c> a</c><00:01:41.430><c> single</c><00:01:41.610><c> neuron</c><00:01:41.970><c> appears</c>

00:01:42.710 --> 00:01:42.720 align:start position:0%
neuron is doing a single neuron appears
 

00:01:42.720 --> 00:01:44.690 align:start position:0%
neuron is doing a single neuron appears
to<00:01:42.899><c> be</c><00:01:43.020><c> much</c><00:01:43.259><c> more</c><00:01:43.409><c> complex</c><00:01:43.860><c> than</c><00:01:44.040><c> we</c><00:01:44.490><c> are</c><00:01:44.670><c> able</c>

00:01:44.690 --> 00:01:44.700 align:start position:0%
to be much more complex than we are able
 

00:01:44.700 --> 00:01:48.080 align:start position:0%
to be much more complex than we are able
to<00:01:45.000><c> characterize</c><00:01:45.420><c> with</c><00:01:45.960><c> neuroscience</c><00:01:47.090><c> and</c>

00:01:48.080 --> 00:01:48.090 align:start position:0%
to characterize with neuroscience and
 

00:01:48.090 --> 00:01:50.690 align:start position:0%
to characterize with neuroscience and
while<00:01:48.600><c> some</c><00:01:49.350><c> of</c><00:01:49.470><c> what</c><00:01:49.649><c> is</c><00:01:49.770><c> doing</c><00:01:50.130><c> is</c><00:01:50.280><c> a</c><00:01:50.310><c> little</c>

00:01:50.690 --> 00:01:50.700 align:start position:0%
while some of what is doing is a little
 

00:01:50.700 --> 00:01:53.210 align:start position:0%
while some of what is doing is a little
bit<00:01:50.820><c> like</c><00:01:51.000><c> logistic</c><00:01:51.270><c> regression</c><00:01:52.220><c> there's</c>

00:01:53.210 --> 00:01:53.220 align:start position:0%
bit like logistic regression there's
 

00:01:53.220 --> 00:01:55.069 align:start position:0%
bit like logistic regression there's
still<00:01:53.490><c> a</c><00:01:53.520><c> lot</c><00:01:53.850><c> about</c><00:01:54.119><c> what</c><00:01:54.420><c> even</c><00:01:54.720><c> a</c><00:01:54.810><c> single</c>

00:01:55.069 --> 00:01:55.079 align:start position:0%
still a lot about what even a single
 

00:01:55.079 --> 00:01:57.380 align:start position:0%
still a lot about what even a single
neuron<00:01:55.409><c> does</c><00:01:55.770><c> that</c><00:01:56.130><c> no</c><00:01:56.369><c> one</c><00:01:56.640><c> then</c><00:01:56.880><c> no</c><00:01:57.030><c> human</c>

00:01:57.380 --> 00:01:57.390 align:start position:0%
neuron does that no one then no human
 

00:01:57.390 --> 00:02:00.260 align:start position:0%
neuron does that no one then no human
today<00:01:57.540><c> understands</c><00:01:58.350><c> for</c><00:01:59.250><c> example</c><00:01:59.670><c> exactly</c>

00:02:00.260 --> 00:02:00.270 align:start position:0%
today understands for example exactly
 

00:02:00.270 --> 00:02:01.969 align:start position:0%
today understands for example exactly
how<00:02:00.450><c> neurons</c><00:02:00.750><c> in</c><00:02:01.110><c> the</c><00:02:01.200><c> human</c><00:02:01.350><c> brain</c><00:02:01.590><c> learn</c>

00:02:01.969 --> 00:02:01.979 align:start position:0%
how neurons in the human brain learn
 

00:02:01.979 --> 00:02:04.890 align:start position:0%
how neurons in the human brain learn
this<00:02:02.130><c> is</c><00:02:02.250><c> still</c><00:02:02.520><c> a</c><00:02:02.670><c> very</c><00:02:03.060><c> mysterious</c><00:02:03.329><c> process</c>

00:02:04.890 --> 00:02:04.900 align:start position:0%
this is still a very mysterious process
 

00:02:04.900 --> 00:02:07.170 align:start position:0%
this is still a very mysterious process
and<00:02:05.590><c> it's</c><00:02:05.920><c> completely</c><00:02:06.310><c> unclear</c><00:02:06.790><c> today</c>

00:02:07.170 --> 00:02:07.180 align:start position:0%
and it's completely unclear today
 

00:02:07.180 --> 00:02:08.969 align:start position:0%
and it's completely unclear today
whether<00:02:07.660><c> the</c><00:02:07.870><c> human</c><00:02:08.050><c> brain</c><00:02:08.440><c> uses</c><00:02:08.860><c> an</c>

00:02:08.969 --> 00:02:08.979 align:start position:0%
whether the human brain uses an
 

00:02:08.979 --> 00:02:10.410 align:start position:0%
whether the human brain uses an
algorithm<00:02:09.220><c> does</c><00:02:09.520><c> anything</c><00:02:09.970><c> like</c><00:02:10.180><c> back</c>

00:02:10.410 --> 00:02:10.420 align:start position:0%
algorithm does anything like back
 

00:02:10.420 --> 00:02:12.300 align:start position:0%
algorithm does anything like back
propagation<00:02:11.020><c> or</c><00:02:11.260><c> gradient</c><00:02:11.650><c> descent</c><00:02:11.950><c> or</c><00:02:12.190><c> if</c>

00:02:12.300 --> 00:02:12.310 align:start position:0%
propagation or gradient descent or if
 

00:02:12.310 --> 00:02:14.220 align:start position:0%
propagation or gradient descent or if
there's<00:02:12.490><c> some</c><00:02:12.780><c> fundamentally</c><00:02:13.780><c> different</c>

00:02:14.220 --> 00:02:14.230 align:start position:0%
there's some fundamentally different
 

00:02:14.230 --> 00:02:16.620 align:start position:0%
there's some fundamentally different
learning<00:02:14.590><c> principle</c><00:02:15.280><c> that</c><00:02:16.060><c> the</c><00:02:16.180><c> human</c><00:02:16.480><c> brain</c>

00:02:16.620 --> 00:02:16.630 align:start position:0%
learning principle that the human brain
 

00:02:16.630 --> 00:02:20.610 align:start position:0%
learning principle that the human brain
uses<00:02:17.490><c> so</c><00:02:18.490><c> when</c><00:02:18.730><c> I</c><00:02:18.760><c> think</c><00:02:19.120><c> of</c><00:02:19.300><c> deep</c><00:02:19.930><c> learning</c><00:02:20.170><c> I</c>

00:02:20.610 --> 00:02:20.620 align:start position:0%
uses so when I think of deep learning I
 

00:02:20.620 --> 00:02:22.980 align:start position:0%
uses so when I think of deep learning I
think<00:02:20.980><c> of</c><00:02:21.100><c> it</c><00:02:21.250><c> as</c><00:02:21.430><c> being</c><00:02:22.030><c> very</c><00:02:22.300><c> good</c><00:02:22.720><c> and</c>

00:02:22.980 --> 00:02:22.990 align:start position:0%
think of it as being very good and
 

00:02:22.990 --> 00:02:25.260 align:start position:0%
think of it as being very good and
learning<00:02:23.530><c> very</c><00:02:23.740><c> sectional</c><00:02:24.460><c> functions</c><00:02:24.940><c> very</c>

00:02:25.260 --> 00:02:25.270 align:start position:0%
learning very sectional functions very
 

00:02:25.270 --> 00:02:28.410 align:start position:0%
learning very sectional functions very
complex<00:02:25.810><c> functions</c><00:02:26.010><c> to</c><00:02:27.010><c> learn</c><00:02:27.220><c> X</c><00:02:27.850><c> to</c><00:02:28.240><c> Y</c>

00:02:28.410 --> 00:02:28.420 align:start position:0%
complex functions to learn X to Y
 

00:02:28.420 --> 00:02:30.450 align:start position:0%
complex functions to learn X to Y
mappings<00:02:28.960><c> to</c><00:02:29.110><c> learn</c><00:02:29.290><c> input-output</c><00:02:29.980><c> mappings</c>

00:02:30.450 --> 00:02:30.460 align:start position:0%
mappings to learn input-output mappings
 

00:02:30.460 --> 00:02:33.630 align:start position:0%
mappings to learn input-output mappings
in<00:02:30.700><c> supervised</c><00:02:31.300><c> learning</c><00:02:31.350><c> and</c><00:02:32.350><c> whereas</c><00:02:33.070><c> D</c><00:02:33.340><c> is</c>

00:02:33.630 --> 00:02:33.640 align:start position:0%
in supervised learning and whereas D is
 

00:02:33.640 --> 00:02:35.790 align:start position:0%
in supervised learning and whereas D is
like<00:02:33.910><c> the</c><00:02:34.090><c> brain</c><00:02:34.330><c> analogy</c><00:02:34.990><c> maybe</c><00:02:35.380><c> that</c><00:02:35.590><c> was</c>

00:02:35.790 --> 00:02:35.800 align:start position:0%
like the brain analogy maybe that was
 

00:02:35.800 --> 00:02:38.610 align:start position:0%
like the brain analogy maybe that was
useful<00:02:36.280><c> once</c><00:02:36.490><c> I</c><00:02:36.760><c> think</c><00:02:37.390><c> the</c><00:02:37.870><c> field</c><00:02:38.140><c> has</c><00:02:38.320><c> moved</c>

00:02:38.610 --> 00:02:38.620 align:start position:0%
useful once I think the field has moved
 

00:02:38.620 --> 00:02:40.800 align:start position:0%
useful once I think the field has moved
to<00:02:39.400><c> the</c><00:02:39.490><c> point</c><00:02:39.670><c> where</c><00:02:39.970><c> that</c><00:02:40.120><c> analogy</c><00:02:40.660><c> is</c>

00:02:40.800 --> 00:02:40.810 align:start position:0%
to the point where that analogy is
 

00:02:40.810 --> 00:02:43.140 align:start position:0%
to the point where that analogy is
breaking<00:02:41.440><c> down</c><00:02:41.650><c> and</c><00:02:41.950><c> I</c><00:02:42.100><c> tend</c><00:02:42.640><c> not</c><00:02:42.730><c> to</c><00:02:42.850><c> use</c><00:02:43.000><c> that</c>

00:02:43.140 --> 00:02:43.150 align:start position:0%
breaking down and I tend not to use that
 

00:02:43.150 --> 00:02:46.500 align:start position:0%
breaking down and I tend not to use that
analogy<00:02:43.600><c> much</c><00:02:44.080><c> anymore</c><00:02:44.700><c> so</c><00:02:45.700><c> that's</c><00:02:45.970><c> it</c><00:02:46.270><c> for</c>

00:02:46.500 --> 00:02:46.510 align:start position:0%
analogy much anymore so that's it for
 

00:02:46.510 --> 00:02:49.050 align:start position:0%
analogy much anymore so that's it for
neural<00:02:46.870><c> networks</c><00:02:47.230><c> and</c><00:02:47.440><c> the</c><00:02:47.710><c> brain</c><00:02:47.950><c> um</c><00:02:48.250><c> I</c><00:02:48.790><c> do</c>

00:02:49.050 --> 00:02:49.060 align:start position:0%
neural networks and the brain um I do
 

00:02:49.060 --> 00:02:50.700 align:start position:0%
neural networks and the brain um I do
think<00:02:49.420><c> that</c><00:02:49.600><c> the</c><00:02:49.810><c> good</c><00:02:49.960><c> field</c><00:02:50.200><c> of</c><00:02:50.290><c> computer</c>

00:02:50.700 --> 00:02:50.710 align:start position:0%
think that the good field of computer
 

00:02:50.710 --> 00:02:53.250 align:start position:0%
think that the good field of computer
vision<00:02:50.860><c> has</c><00:02:51.340><c> taken</c><00:02:51.730><c> a</c><00:02:51.820><c> bit</c><00:02:52.030><c> more</c><00:02:52.270><c> inspiration</c>

00:02:53.250 --> 00:02:53.260 align:start position:0%
vision has taken a bit more inspiration
 

00:02:53.260 --> 00:02:55.500 align:start position:0%
vision has taken a bit more inspiration
from<00:02:53.470><c> human</c><00:02:53.860><c> brains</c><00:02:54.070><c> and</c><00:02:54.340><c> other</c><00:02:54.550><c> disciplines</c>

00:02:55.500 --> 00:02:55.510 align:start position:0%
from human brains and other disciplines
 

00:02:55.510 --> 00:02:57.900 align:start position:0%
from human brains and other disciplines
that<00:02:55.600><c> also</c><00:02:55.900><c> apply</c><00:02:56.320><c> deep</c><00:02:56.560><c> learning</c><00:02:56.740><c> but</c><00:02:57.550><c> I</c>

00:02:57.900 --> 00:02:57.910 align:start position:0%
that also apply deep learning but I
 

00:02:57.910 --> 00:03:00.270 align:start position:0%
that also apply deep learning but I
personally<00:02:58.690><c> use</c><00:02:58.930><c> the</c><00:02:59.140><c> analogy</c><00:02:59.650><c> you</c><00:03:00.010><c> know</c><00:03:00.100><c> to</c>

00:03:00.270 --> 00:03:00.280 align:start position:0%
personally use the analogy you know to
 

00:03:00.280 --> 00:03:02.060 align:start position:0%
personally use the analogy you know to
the<00:03:00.370><c> human</c><00:03:00.640><c> brain</c><00:03:00.760><c> less</c><00:03:01.090><c> than</c><00:03:01.270><c> I</c><00:03:01.360><c> used</c><00:03:01.600><c> to</c>

00:03:02.060 --> 00:03:02.070 align:start position:0%
the human brain less than I used to
 

00:03:02.070 --> 00:03:05.730 align:start position:0%
the human brain less than I used to
so<00:03:03.070><c> that's</c><00:03:03.430><c> it</c><00:03:03.700><c> for</c><00:03:04.000><c> this</c><00:03:04.210><c> video</c><00:03:04.660><c> you</c><00:03:05.320><c> now</c><00:03:05.470><c> know</c>

00:03:05.730 --> 00:03:05.740 align:start position:0%
so that's it for this video you now know
 

00:03:05.740 --> 00:03:07.830 align:start position:0%
so that's it for this video you now know
how<00:03:06.190><c> to</c><00:03:06.220><c> implement</c><00:03:06.700><c> for</c><00:03:06.970><c> prop</c><00:03:07.420><c> and</c><00:03:07.630><c> back</c><00:03:07.690><c> prop</c>

00:03:07.830 --> 00:03:07.840 align:start position:0%
how to implement for prop and back prop
 

00:03:07.840 --> 00:03:09.870 align:start position:0%
how to implement for prop and back prop
in<00:03:08.230><c> gradient</c><00:03:08.500><c> descent</c><00:03:08.620><c> even</c><00:03:09.100><c> for</c><00:03:09.400><c> deep</c><00:03:09.610><c> neural</c>

00:03:09.870 --> 00:03:09.880 align:start position:0%
in gradient descent even for deep neural
 

00:03:09.880 --> 00:03:12.060 align:start position:0%
in gradient descent even for deep neural
networks<00:03:10.290><c> best</c><00:03:11.290><c> of</c><00:03:11.470><c> luck</c><00:03:11.620><c> with</c><00:03:11.650><c> the</c><00:03:11.860><c> pro</c>

00:03:12.060 --> 00:03:12.070 align:start position:0%
networks best of luck with the pro
 

00:03:12.070 --> 00:03:14.070 align:start position:0%
networks best of luck with the pro
exercise<00:03:12.580><c> and</c><00:03:12.910><c> I</c><00:03:13.090><c> look</c><00:03:13.300><c> forward</c><00:03:13.540><c> to</c><00:03:13.780><c> sharing</c>

00:03:14.070 --> 00:03:14.080 align:start position:0%
exercise and I look forward to sharing
 

00:03:14.080 --> 00:03:16.320 align:start position:0%
exercise and I look forward to sharing
more<00:03:14.500><c> of</c><00:03:14.560><c> these</c><00:03:14.709><c> ideas</c><00:03:15.100><c> of</c><00:03:15.310><c> you</c><00:03:15.459><c> in</c><00:03:15.640><c> the</c><00:03:15.970><c> second</c>

00:03:16.320 --> 00:03:16.330 align:start position:0%
more of these ideas of you in the second
 

00:03:16.330 --> 00:03:18.510 align:start position:0%
more of these ideas of you in the second
course

