WEBVTT
Kind: captions
Language: en

00:00:02.080 --> 00:00:05.269 align:start position:0%
 
I<00:00:02.139><c> want</c><00:00:02.889><c> to</c><00:00:02.949><c> bring</c><00:00:03.070><c> this</c><00:00:03.810><c> part</c><00:00:04.810><c> of</c><00:00:04.960><c> the</c><00:00:05.050><c> class</c>

00:00:05.269 --> 00:00:05.279 align:start position:0%
I want to bring this part of the class
 

00:00:05.279 --> 00:00:07.889 align:start position:0%
I want to bring this part of the class
to<00:00:06.279><c> an</c><00:00:06.370><c> end</c><00:00:06.520><c> so</c><00:00:06.640><c> this</c><00:00:06.759><c> is</c><00:00:06.879><c> our</c><00:00:07.029><c> last</c><00:00:07.270><c> lecture</c>

00:00:07.889 --> 00:00:07.899 align:start position:0%
to an end so this is our last lecture
 

00:00:07.899 --> 00:00:10.020 align:start position:0%
to an end so this is our last lecture
but<00:00:08.320><c> for</c><00:00:08.379><c> our</c><00:00:08.650><c> series</c><00:00:08.889><c> of</c><00:00:09.010><c> guest</c><00:00:09.370><c> lectures</c><00:00:09.790><c> and</c>

00:00:10.020 --> 00:00:10.030 align:start position:0%
but for our series of guest lectures and
 

00:00:10.030 --> 00:00:13.080 align:start position:0%
but for our series of guest lectures and
in<00:00:10.660><c> this</c><00:00:10.840><c> talk</c><00:00:11.080><c> I</c><00:00:11.200><c> hope</c><00:00:11.349><c> to</c><00:00:11.559><c> address</c><00:00:12.059><c> some</c><00:00:13.059><c> of</c>

00:00:13.080 --> 00:00:13.090 align:start position:0%
in this talk I hope to address some of
 

00:00:13.090 --> 00:00:14.640 align:start position:0%
in this talk I hope to address some of
the<00:00:13.269><c> state</c><00:00:13.480><c> of</c><00:00:13.630><c> deep</c><00:00:13.780><c> learning</c><00:00:13.960><c> today</c><00:00:14.290><c> and</c>

00:00:14.640 --> 00:00:14.650 align:start position:0%
the state of deep learning today and
 

00:00:14.650 --> 00:00:16.049 align:start position:0%
the state of deep learning today and
kind<00:00:14.889><c> of</c><00:00:14.980><c> bring</c><00:00:15.190><c> up</c><00:00:15.309><c> some</c><00:00:15.490><c> of</c><00:00:15.580><c> the</c><00:00:15.700><c> limitations</c>

00:00:16.049 --> 00:00:16.059 align:start position:0%
kind of bring up some of the limitations
 

00:00:16.059 --> 00:00:18.030 align:start position:0%
kind of bring up some of the limitations
of<00:00:16.660><c> the</c><00:00:17.230><c> algorithms</c><00:00:17.619><c> that</c><00:00:17.710><c> you've</c><00:00:17.919><c> been</c>

00:00:18.030 --> 00:00:18.040 align:start position:0%
of the algorithms that you've been
 

00:00:18.040 --> 00:00:19.560 align:start position:0%
of the algorithms that you've been
seeing<00:00:18.250><c> in</c><00:00:18.400><c> this</c><00:00:18.490><c> class</c><00:00:18.730><c> so</c><00:00:18.939><c> far</c><00:00:19.150><c> so</c><00:00:19.330><c> we</c><00:00:19.420><c> got</c><00:00:19.539><c> a</c>

00:00:19.560 --> 00:00:19.570 align:start position:0%
seeing in this class so far so we got a
 

00:00:19.570 --> 00:00:20.779 align:start position:0%
seeing in this class so far so we got a
really<00:00:19.750><c> good</c><00:00:19.990><c> taste</c><00:00:20.170><c> of</c><00:00:20.410><c> some</c><00:00:20.560><c> of</c><00:00:20.590><c> the</c>

00:00:20.779 --> 00:00:20.789 align:start position:0%
really good taste of some of the
 

00:00:20.789 --> 00:00:22.470 align:start position:0%
really good taste of some of the
limitations<00:00:21.789><c> specifically</c><00:00:22.390><c> in</c>

00:00:22.470 --> 00:00:22.480 align:start position:0%
limitations specifically in
 

00:00:22.480 --> 00:00:24.960 align:start position:0%
limitations specifically in
reinforcement<00:00:23.170><c> learning</c><00:00:23.320><c> algorithms</c><00:00:24.010><c> that</c>

00:00:24.960 --> 00:00:24.970 align:start position:0%
reinforcement learning algorithms that
 

00:00:24.970 --> 00:00:27.060 align:start position:0%
reinforcement learning algorithms that
Lex<00:00:25.300><c> gave</c><00:00:25.510><c> in</c><00:00:25.689><c> the</c><00:00:25.779><c> last</c><00:00:25.990><c> lecture</c><00:00:26.439><c> and</c><00:00:26.619><c> that's</c>

00:00:27.060 --> 00:00:27.070 align:start position:0%
Lex gave in the last lecture and that's
 

00:00:27.070 --> 00:00:29.820 align:start position:0%
Lex gave in the last lecture and that's
really<00:00:27.310><c> going</c><00:00:27.550><c> to</c><00:00:27.609><c> build</c><00:00:27.849><c> on</c><00:00:28.529><c> or</c><00:00:29.529><c> I'm</c><00:00:29.710><c> gonna</c>

00:00:29.820 --> 00:00:29.830 align:start position:0%
really going to build on or I'm gonna
 

00:00:29.830 --> 00:00:31.919 align:start position:0%
really going to build on or I'm gonna
use<00:00:30.070><c> that</c><00:00:30.099><c> to</c><00:00:30.369><c> build</c><00:00:30.550><c> on</c><00:00:30.760><c> top</c><00:00:30.789><c> of</c><00:00:31.029><c> during</c><00:00:31.810><c> this</c>

00:00:31.919 --> 00:00:31.929 align:start position:0%
use that to build on top of during this
 

00:00:31.929 --> 00:00:34.229 align:start position:0%
use that to build on top of during this
lecture<00:00:32.169><c> and</c><00:00:32.559><c> just</c><00:00:32.619><c> to</c><00:00:33.610><c> end</c><00:00:33.790><c> on</c><00:00:33.970><c> I'm</c><00:00:34.089><c> gonna</c>

00:00:34.229 --> 00:00:34.239 align:start position:0%
lecture and just to end on I'm gonna
 

00:00:34.239 --> 00:00:36.509 align:start position:0%
lecture and just to end on I'm gonna
bring<00:00:35.049><c> you</c><00:00:35.260><c> I'm</c><00:00:35.620><c> gonna</c><00:00:35.799><c> introduce</c><00:00:36.220><c> you</c><00:00:36.489><c> to</c>

00:00:36.509 --> 00:00:36.519 align:start position:0%
bring you I'm gonna introduce you to
 

00:00:36.519 --> 00:00:39.990 align:start position:0%
bring you I'm gonna introduce you to
some<00:00:36.879><c> new</c><00:00:37.269><c> frontiers</c><00:00:37.809><c> in</c><00:00:38.170><c> deep</c><00:00:39.070><c> learning</c><00:00:39.280><c> that</c>

00:00:39.990 --> 00:00:40.000 align:start position:0%
some new frontiers in deep learning that
 

00:00:40.000 --> 00:00:41.910 align:start position:0%
some new frontiers in deep learning that
are<00:00:40.150><c> really</c><00:00:40.510><c> really</c><00:00:40.659><c> inspiring</c><00:00:41.140><c> it</c><00:00:41.409><c> and</c><00:00:41.589><c> at</c>

00:00:41.910 --> 00:00:41.920 align:start position:0%
are really really inspiring it and at
 

00:00:41.920 --> 00:00:45.140 align:start position:0%
are really really inspiring it and at
the<00:00:42.070><c> cutting</c><00:00:42.250><c> edge</c><00:00:42.489><c> of</c><00:00:42.699><c> research</c><00:00:43.080><c> today</c>

00:00:45.140 --> 00:00:45.150 align:start position:0%
the cutting edge of research today
 

00:00:45.150 --> 00:00:48.990 align:start position:0%
the cutting edge of research today
before<00:00:46.150><c> we</c><00:00:46.420><c> do</c><00:00:46.570><c> that</c><00:00:46.860><c> I'd</c><00:00:47.860><c> like</c><00:00:47.920><c> to</c><00:00:48.309><c> just</c><00:00:48.580><c> make</c>

00:00:48.990 --> 00:00:49.000 align:start position:0%
before we do that I'd like to just make
 

00:00:49.000 --> 00:00:51.750 align:start position:0%
before we do that I'd like to just make
some<00:00:49.180><c> administrative</c><00:00:49.809><c> announcements</c><00:00:50.760><c> so</c>

00:00:51.750 --> 00:00:51.760 align:start position:0%
some administrative announcements so
 

00:00:51.760 --> 00:00:53.009 align:start position:0%
some administrative announcements so
t-shirts<00:00:52.180><c> have</c><00:00:52.299><c> arrived</c><00:00:52.600><c> and</c><00:00:52.809><c> we'll</c><00:00:52.900><c> be</c>

00:00:53.009 --> 00:00:53.019 align:start position:0%
t-shirts have arrived and we'll be
 

00:00:53.019 --> 00:00:54.840 align:start position:0%
t-shirts have arrived and we'll be
distributing<00:00:53.440><c> them</c><00:00:53.739><c> today</c><00:00:53.949><c> and</c><00:00:54.309><c> we'd</c><00:00:54.580><c> like</c><00:00:54.729><c> to</c>

00:00:54.840 --> 00:00:54.850 align:start position:0%
distributing them today and we'd like to
 

00:00:54.850 --> 00:00:57.030 align:start position:0%
distributing them today and we'd like to
distribute<00:00:55.330><c> first</c><00:00:55.540><c> to</c><00:00:55.900><c> the</c><00:00:56.049><c> registered</c><00:00:56.559><c> for</c>

00:00:57.030 --> 00:00:57.040 align:start position:0%
distribute first to the registered for
 

00:00:57.040 --> 00:01:00.810 align:start position:0%
distribute first to the registered for
credit<00:00:57.400><c> students</c><00:00:58.650><c> after</c><00:00:59.650><c> that</c><00:00:59.830><c> we</c><00:01:00.010><c> will</c><00:01:00.699><c> be</c>

00:01:00.810 --> 00:01:00.820 align:start position:0%
credit students after that we will be
 

00:01:00.820 --> 00:01:02.160 align:start position:0%
credit students after that we will be
happy<00:01:01.059><c> to</c><00:01:01.180><c> distribute</c><00:01:01.600><c> to</c><00:01:01.629><c> registered</c>

00:01:02.160 --> 00:01:02.170 align:start position:0%
happy to distribute to registered
 

00:01:02.170 --> 00:01:03.719 align:start position:0%
happy to distribute to registered
listeners<00:01:02.650><c> and</c><00:01:02.890><c> then</c><00:01:02.979><c> after</c><00:01:03.250><c> that</c><00:01:03.369><c> if</c><00:01:03.549><c> there's</c>

00:01:03.719 --> 00:01:03.729 align:start position:0%
listeners and then after that if there's
 

00:01:03.729 --> 00:01:05.009 align:start position:0%
listeners and then after that if there's
any<00:01:03.879><c> remaining</c><00:01:04.210><c> we'll</c><00:01:04.510><c> give</c><00:01:04.689><c> out</c><00:01:04.809><c> to</c>

00:01:05.009 --> 00:01:05.019 align:start position:0%
any remaining we'll give out to
 

00:01:05.019 --> 00:01:06.720 align:start position:0%
any remaining we'll give out to
listeners<00:01:05.439><c> if</c><00:01:05.830><c> they'd</c><00:01:06.100><c> want</c><00:01:06.310><c> if</c><00:01:06.460><c> they're</c>

00:01:06.720 --> 00:01:06.730 align:start position:0%
listeners if they'd want if they're
 

00:01:06.730 --> 00:01:10.980 align:start position:0%
listeners if they'd want if they're
interested<00:01:09.210><c> so</c><00:01:10.210><c> for</c><00:01:10.450><c> those</c><00:01:10.540><c> of</c><00:01:10.600><c> you</c><00:01:10.750><c> who</c><00:01:10.900><c> are</c>

00:01:10.980 --> 00:01:10.990 align:start position:0%
interested so for those of you who are
 

00:01:10.990 --> 00:01:12.570 align:start position:0%
interested so for those of you who are
taking<00:01:11.320><c> this</c><00:01:11.410><c> class</c><00:01:11.560><c> for</c><00:01:11.830><c> credit</c><00:01:11.950><c> I</c><00:01:12.220><c> need</c><00:01:12.430><c> to</c>

00:01:12.570 --> 00:01:12.580 align:start position:0%
taking this class for credit I need to
 

00:01:12.580 --> 00:01:16.200 align:start position:0%
taking this class for credit I need to
reiterate<00:01:13.200><c> what</c><00:01:14.200><c> kind</c><00:01:14.470><c> of</c><00:01:14.880><c> options</c><00:01:15.880><c> you</c><00:01:16.000><c> have</c>

00:01:16.200 --> 00:01:16.210 align:start position:0%
reiterate what kind of options you have
 

00:01:16.210 --> 00:01:17.670 align:start position:0%
reiterate what kind of options you have
to<00:01:16.510><c> actually</c><00:01:16.750><c> fulfill</c><00:01:17.050><c> your</c><00:01:17.380><c> credit</c>

00:01:17.670 --> 00:01:17.680 align:start position:0%
to actually fulfill your credit
 

00:01:17.680 --> 00:01:19.860 align:start position:0%
to actually fulfill your credit
requirement<00:01:18.220><c> so</c><00:01:19.090><c> the</c><00:01:19.180><c> first</c><00:01:19.360><c> option</c><00:01:19.720><c> is</c><00:01:19.810><c> a</c>

00:01:19.860 --> 00:01:19.870 align:start position:0%
requirement so the first option is a
 

00:01:19.870 --> 00:01:22.950 align:start position:0%
requirement so the first option is a
group<00:01:20.140><c> project</c><00:01:20.220><c> proposal</c><00:01:21.220><c> presentation</c><00:01:21.960><c> so</c>

00:01:22.950 --> 00:01:22.960 align:start position:0%
group project proposal presentation so
 

00:01:22.960 --> 00:01:24.060 align:start position:0%
group project proposal presentation so
for<00:01:23.140><c> this</c><00:01:23.230><c> option</c><00:01:23.590><c> you'll</c><00:01:23.710><c> be</c><00:01:23.800><c> given</c><00:01:24.010><c> the</c>

00:01:24.060 --> 00:01:24.070 align:start position:0%
for this option you'll be given the
 

00:01:24.070 --> 00:01:25.710 align:start position:0%
for this option you'll be given the
opportunity<00:01:24.550><c> to</c><00:01:24.580><c> pitch</c><00:01:24.940><c> a</c><00:01:25.120><c> novel</c><00:01:25.510><c> deep</c>

00:01:25.710 --> 00:01:25.720 align:start position:0%
opportunity to pitch a novel deep
 

00:01:25.720 --> 00:01:27.960 align:start position:0%
opportunity to pitch a novel deep
learning<00:01:25.870><c> idea</c><00:01:26.410><c> to</c><00:01:26.830><c> a</c><00:01:26.860><c> panel</c><00:01:27.250><c> of</c><00:01:27.310><c> judges</c><00:01:27.370><c> on</c>

00:01:27.960 --> 00:01:27.970 align:start position:0%
learning idea to a panel of judges on
 

00:01:27.970 --> 00:01:31.230 align:start position:0%
learning idea to a panel of judges on
Friday<00:01:28.890><c> you'll</c><00:01:29.890><c> have</c><00:01:30.070><c> exactly</c><00:01:30.610><c> one</c><00:01:30.820><c> minute</c><00:01:31.000><c> to</c>

00:01:31.230 --> 00:01:31.240 align:start position:0%
Friday you'll have exactly one minute to
 

00:01:31.240 --> 00:01:33.570 align:start position:0%
Friday you'll have exactly one minute to
make<00:01:31.360><c> your</c><00:01:31.570><c> pitch</c><00:01:31.810><c> as</c><00:01:32.080><c> clear</c><00:01:32.530><c> error</c><00:01:32.800><c> as</c><00:01:33.010><c> clear</c>

00:01:33.570 --> 00:01:33.580 align:start position:0%
make your pitch as clear error as clear
 

00:01:33.580 --> 00:01:36.180 align:start position:0%
make your pitch as clear error as clear
and<00:01:33.730><c> as</c><00:01:33.790><c> concisely</c><00:01:34.270><c> as</c><00:01:34.450><c> possible</c><00:01:35.080><c> so</c><00:01:35.950><c> this</c><00:01:36.010><c> is</c>

00:01:36.180 --> 00:01:36.190 align:start position:0%
and as concisely as possible so this is
 

00:01:36.190 --> 00:01:37.890 align:start position:0%
and as concisely as possible so this is
really<00:01:36.550><c> difficult</c><00:01:36.790><c> to</c><00:01:37.030><c> do</c><00:01:37.240><c> in</c><00:01:37.360><c> one</c><00:01:37.570><c> minute</c><00:01:37.750><c> and</c>

00:01:37.890 --> 00:01:37.900 align:start position:0%
really difficult to do in one minute and
 

00:01:37.900 --> 00:01:39.810 align:start position:0%
really difficult to do in one minute and
this<00:01:38.350><c> kind</c><00:01:38.650><c> of</c><00:01:38.710><c> one</c><00:01:38.890><c> of</c><00:01:38.920><c> the</c><00:01:39.100><c> challenges</c><00:01:39.610><c> that</c>

00:01:39.810 --> 00:01:39.820 align:start position:0%
this kind of one of the challenges that
 

00:01:39.820 --> 00:01:41.880 align:start position:0%
this kind of one of the challenges that
were<00:01:40.000><c> we're</c><00:01:40.600><c> putting</c><00:01:40.930><c> on</c><00:01:41.080><c> you</c><00:01:41.230><c> in</c><00:01:41.350><c> addition</c><00:01:41.740><c> to</c>

00:01:41.880 --> 00:01:41.890 align:start position:0%
were we're putting on you in addition to
 

00:01:41.890 --> 00:01:43.560 align:start position:0%
were we're putting on you in addition to
actually<00:01:42.250><c> coming</c><00:01:43.030><c> up</c><00:01:43.090><c> with</c><00:01:43.270><c> the</c><00:01:43.390><c> deep</c>

00:01:43.560 --> 00:01:43.570 align:start position:0%
actually coming up with the deep
 

00:01:43.570 --> 00:01:47.070 align:start position:0%
actually coming up with the deep
learning<00:01:43.720><c> idea</c><00:01:44.470><c> itself</c><00:01:45.120><c> if</c><00:01:46.120><c> you</c><00:01:46.630><c> want</c><00:01:46.900><c> to</c><00:01:46.990><c> go</c>

00:01:47.070 --> 00:01:47.080 align:start position:0%
learning idea itself if you want to go
 

00:01:47.080 --> 00:01:49.010 align:start position:0%
learning idea itself if you want to go
down<00:01:47.290><c> this</c><00:01:47.470><c> route</c><00:01:47.740><c> for</c><00:01:48.130><c> your</c><00:01:48.250><c> final</c><00:01:48.520><c> project</c>

00:01:49.010 --> 00:01:49.020 align:start position:0%
down this route for your final project
 

00:01:49.020 --> 00:01:51.540 align:start position:0%
down this route for your final project
then<00:01:50.020><c> you'll</c><00:01:50.170><c> need</c><00:01:50.290><c> to</c><00:01:50.350><c> submit</c><00:01:50.620><c> your</c><00:01:51.130><c> teams</c>

00:01:51.540 --> 00:01:51.550 align:start position:0%
then you'll need to submit your teams
 

00:01:51.550 --> 00:01:53.820 align:start position:0%
then you'll need to submit your teams
which<00:01:52.360><c> have</c><00:01:52.450><c> to</c><00:01:52.690><c> be</c><00:01:52.780><c> of</c><00:01:52.900><c> size</c><00:01:53.050><c> three</c><00:01:53.470><c> or</c><00:01:53.560><c> four</c>

00:01:53.820 --> 00:01:53.830 align:start position:0%
which have to be of size three or four
 

00:01:53.830 --> 00:01:55.710 align:start position:0%
which have to be of size three or four
by<00:01:54.159><c> the</c><00:01:54.220><c> end</c><00:01:54.430><c> of</c><00:01:54.610><c> today</c><00:01:55.090><c> so</c><00:01:55.150><c> at</c><00:01:55.479><c> 9:00</c><00:01:55.690><c> p.m.</c>

00:01:55.710 --> 00:01:55.720 align:start position:0%
by the end of today so at 9:00 p.m.
 

00:01:55.720 --> 00:01:59.610 align:start position:0%
by the end of today so at 9:00 p.m.
today<00:01:56.200><c> we'd</c><00:01:56.470><c> like</c><00:01:56.500><c> those</c><00:01:56.800><c> in</c><00:01:58.409><c> you'll</c><00:01:59.409><c> have</c><00:01:59.530><c> to</c>

00:01:59.610 --> 00:01:59.620 align:start position:0%
today we'd like those in you'll have to
 

00:01:59.620 --> 00:02:01.350 align:start position:0%
today we'd like those in you'll have to
do<00:01:59.740><c> teams</c><00:02:00.070><c> of</c><00:02:00.220><c> three</c><00:02:00.400><c> or</c><00:02:00.490><c> four</c><00:02:00.760><c> so</c><00:02:01.000><c> if</c><00:02:01.120><c> you</c><00:02:01.180><c> want</c>

00:02:01.350 --> 00:02:01.360 align:start position:0%
do teams of three or four so if you want
 

00:02:01.360 --> 00:02:03.120 align:start position:0%
do teams of three or four so if you want
a<00:02:01.420><c> group</c><00:02:01.570><c> working</c><00:02:01.900><c> in</c><00:02:02.110><c> groups</c><00:02:02.320><c> of</c><00:02:02.470><c> one</c><00:02:02.680><c> or</c><00:02:02.890><c> two</c>

00:02:03.120 --> 00:02:03.130 align:start position:0%
a group working in groups of one or two
 

00:02:03.130 --> 00:02:05.370 align:start position:0%
a group working in groups of one or two
then<00:02:03.700><c> you'll</c><00:02:03.880><c> have</c><00:02:03.970><c> to</c><00:02:04.240><c> you're</c><00:02:05.020><c> you're</c>

00:02:05.370 --> 00:02:05.380 align:start position:0%
then you'll have to you're you're
 

00:02:05.380 --> 00:02:06.780 align:start position:0%
then you'll have to you're you're
welcome<00:02:05.710><c> to</c><00:02:05.830><c> do</c><00:02:05.950><c> that</c><00:02:05.979><c> but</c><00:02:06.159><c> you</c><00:02:06.370><c> won't</c><00:02:06.549><c> be</c><00:02:06.670><c> able</c>

00:02:06.780 --> 00:02:06.790 align:start position:0%
welcome to do that but you won't be able
 

00:02:06.790 --> 00:02:09.899 align:start position:0%
welcome to do that but you won't be able
to<00:02:06.880><c> actually</c><00:02:07.360><c> submit</c><00:02:07.570><c> your</c><00:02:08.310><c> final</c><00:02:09.310><c> project</c><00:02:09.729><c> as</c>

00:02:09.899 --> 00:02:09.909 align:start position:0%
to actually submit your final project as
 

00:02:09.909 --> 00:02:12.510 align:start position:0%
to actually submit your final project as
part<00:02:10.179><c> of</c><00:02:10.330><c> a</c><00:02:10.390><c> presentation</c><00:02:10.690><c> on</c><00:02:11.230><c> Friday</c><00:02:11.920><c> you</c><00:02:12.310><c> can</c>

00:02:12.510 --> 00:02:12.520 align:start position:0%
part of a presentation on Friday you can
 

00:02:12.520 --> 00:02:15.000 align:start position:0%
part of a presentation on Friday you can
submit<00:02:12.760><c> it</c><00:02:12.880><c> to</c><00:02:13.060><c> us</c><00:02:13.209><c> and</c><00:02:13.540><c> we'll</c><00:02:13.690><c> we'll</c><00:02:14.650><c> give</c><00:02:14.890><c> you</c>

00:02:15.000 --> 00:02:15.010 align:start position:0%
submit it to us and we'll we'll give you
 

00:02:15.010 --> 00:02:15.809 align:start position:0%
submit it to us and we'll we'll give you
the<00:02:15.130><c> grade</c><00:02:15.280><c> for</c><00:02:15.459><c> the</c><00:02:15.550><c> class</c>

00:02:15.809 --> 00:02:15.819 align:start position:0%
the grade for the class
 

00:02:15.819 --> 00:02:19.920 align:start position:0%
the grade for the class
like<00:02:15.969><c> that</c><00:02:17.069><c> so</c><00:02:18.069><c> groups</c><00:02:19.060><c> are</c><00:02:19.209><c> due</c><00:02:19.359><c> 9:00</c><00:02:19.719><c> p.m.</c>

00:02:19.920 --> 00:02:19.930 align:start position:0%
like that so groups are due 9:00 p.m.
 

00:02:19.930 --> 00:02:22.110 align:start position:0%
like that so groups are due 9:00 p.m.
today<00:02:20.170><c> and</c><00:02:20.530><c> you</c><00:02:21.040><c> have</c><00:02:21.129><c> to</c><00:02:21.280><c> submit</c><00:02:21.670><c> your</c><00:02:21.819><c> slides</c>

00:02:22.110 --> 00:02:22.120 align:start position:0%
today and you have to submit your slides
 

00:02:22.120 --> 00:02:24.239 align:start position:0%
today and you have to submit your slides
by<00:02:22.359><c> 9:00</c><00:02:22.540><c> p.m.</c><00:02:22.719><c> tomorrow</c><00:02:23.099><c> presentations</c><00:02:24.099><c> are</c>

00:02:24.239 --> 00:02:24.249 align:start position:0%
by 9:00 p.m. tomorrow presentations are
 

00:02:24.249 --> 00:02:27.959 align:start position:0%
by 9:00 p.m. tomorrow presentations are
at<00:02:24.370><c> class</c><00:02:25.269><c> on</c><00:02:25.569><c> Friday</c><00:02:25.810><c> in</c><00:02:26.530><c> this</c><00:02:26.799><c> room</c><00:02:27.010><c> if</c><00:02:27.879><c> you</c>

00:02:27.959 --> 00:02:27.969 align:start position:0%
at class on Friday in this room if you
 

00:02:27.969 --> 00:02:29.059 align:start position:0%
at class on Friday in this room if you
don't<00:02:28.150><c> want</c><00:02:28.299><c> to</c><00:02:28.389><c> do</c><00:02:28.510><c> a</c><00:02:28.540><c> project</c><00:02:28.900><c> for</c>

00:02:29.059 --> 00:02:29.069 align:start position:0%
don't want to do a project for
 

00:02:29.069 --> 00:02:30.809 align:start position:0%
don't want to do a project for
presentation<00:02:30.069><c> you</c><00:02:30.189><c> have</c><00:02:30.310><c> a</c><00:02:30.340><c> second</c><00:02:30.670><c> option</c>

00:02:30.809 --> 00:02:30.819 align:start position:0%
presentation you have a second option
 

00:02:30.819 --> 00:02:32.849 align:start position:0%
presentation you have a second option
which<00:02:31.090><c> is</c><00:02:31.120><c> to</c><00:02:31.389><c> write</c><00:02:31.510><c> a</c><00:02:31.569><c> one-page</c><00:02:31.859><c> paper</c>

00:02:32.849 --> 00:02:32.859 align:start position:0%
which is to write a one-page paper
 

00:02:32.859 --> 00:02:35.819 align:start position:0%
which is to write a one-page paper
review<00:02:33.280><c> of</c><00:02:33.400><c> a</c><00:02:33.459><c> deep</c><00:02:33.670><c> learning</c><00:02:33.819><c> idea</c><00:02:34.650><c> so</c><00:02:35.650><c> any</c>

00:02:35.819 --> 00:02:35.829 align:start position:0%
review of a deep learning idea so any
 

00:02:35.829 --> 00:02:38.429 align:start position:0%
review of a deep learning idea so any
idea<00:02:36.189><c> or</c><00:02:36.250><c> any</c><00:02:36.870><c> paper</c><00:02:37.870><c> that</c><00:02:38.139><c> you</c><00:02:38.200><c> find</c>

00:02:38.429 --> 00:02:38.439 align:start position:0%
idea or any paper that you find
 

00:02:38.439 --> 00:02:40.770 align:start position:0%
idea or any paper that you find
interesting<00:02:38.650><c> is</c><00:02:39.159><c> is</c><00:02:39.909><c> welcome</c><00:02:40.359><c> here</c><00:02:40.540><c> so</c><00:02:40.659><c> we</c>

00:02:40.770 --> 00:02:40.780 align:start position:0%
interesting is is welcome here so we
 

00:02:40.780 --> 00:02:42.209 align:start position:0%
interesting is is welcome here so we
really<00:02:41.049><c> accept</c><00:02:41.349><c> anything</c><00:02:41.590><c> and</c><00:02:41.950><c> we're</c><00:02:42.040><c> really</c>

00:02:42.209 --> 00:02:42.219 align:start position:0%
really accept anything and we're really
 

00:02:42.219 --> 00:02:45.979 align:start position:0%
really accept anything and we're really
free<00:02:42.489><c> in</c><00:02:42.519><c> this</c><00:02:42.790><c> in</c><00:02:43.000><c> this</c><00:02:43.919><c> option</c><00:02:44.919><c> as</c><00:02:45.040><c> well</c><00:02:45.159><c> I</c>

00:02:45.979 --> 00:02:45.989 align:start position:0%
free in this in this option as well I
 

00:02:45.989 --> 00:02:48.629 align:start position:0%
free in this in this option as well I
want<00:02:46.989><c> to</c><00:02:47.049><c> highlight</c><00:02:47.200><c> some</c><00:02:47.590><c> of</c><00:02:47.620><c> the</c><00:02:47.859><c> exciting</c>

00:02:48.629 --> 00:02:48.639 align:start position:0%
want to highlight some of the exciting
 

00:02:48.639 --> 00:02:50.640 align:start position:0%
want to highlight some of the exciting
new<00:02:48.669><c> talks</c><00:02:49.359><c> that</c><00:02:49.599><c> we</c><00:02:49.689><c> have</c><00:02:49.810><c> coming</c><00:02:50.079><c> up</c><00:02:50.260><c> after</c>

00:02:50.640 --> 00:02:50.650 align:start position:0%
new talks that we have coming up after
 

00:02:50.650 --> 00:02:53.129 align:start position:0%
new talks that we have coming up after
today<00:02:50.829><c> so</c><00:02:51.730><c> tomorrow</c><00:02:52.120><c> will</c><00:02:52.329><c> have</c><00:02:52.450><c> two</c><00:02:52.780><c> sets</c><00:02:53.049><c> of</c>

00:02:53.129 --> 00:02:53.139 align:start position:0%
today so tomorrow will have two sets of
 

00:02:53.139 --> 00:02:54.390 align:start position:0%
today so tomorrow will have two sets of
guest<00:02:53.349><c> lectures</c><00:02:53.709><c> first</c><00:02:53.949><c> we'll</c><00:02:54.129><c> hear</c><00:02:54.250><c> from</c>

00:02:54.390 --> 00:02:54.400 align:start position:0%
guest lectures first we'll hear from
 

00:02:54.400 --> 00:02:57.000 align:start position:0%
guest lectures first we'll hear from
aura's<00:02:55.090><c> Muller</c><00:02:55.510><c> who</c><00:02:55.900><c> is</c><00:02:56.049><c> the</c><00:02:56.230><c> chief</c><00:02:56.439><c> architect</c>

00:02:57.000 --> 00:02:57.010 align:start position:0%
aura's Muller who is the chief architect
 

00:02:57.010 --> 00:03:00.539 align:start position:0%
aura's Muller who is the chief architect
of<00:02:57.189><c> nvidia</c><00:02:57.459><c> x'</c><00:02:57.689><c> self-driving</c><00:02:58.689><c> car</c><00:02:58.989><c> team</c><00:02:59.549><c> so</c>

00:03:00.539 --> 00:03:00.549 align:start position:0%
of nvidia x' self-driving car team so
 

00:03:00.549 --> 00:03:02.069 align:start position:0%
of nvidia x' self-driving car team so
hers<00:03:00.909><c> and</c><00:03:01.150><c> his</c><00:03:01.239><c> team</c><00:03:01.510><c> were</c><00:03:01.599><c> actually</c><00:03:01.870><c> known</c>

00:03:02.069 --> 00:03:02.079 align:start position:0%
hers and his team were actually known
 

00:03:02.079 --> 00:03:04.050 align:start position:0%
hers and his team were actually known
for<00:03:02.109><c> some</c><00:03:02.469><c> really</c><00:03:02.620><c> exciting</c><00:03:02.889><c> work</c><00:03:03.069><c> that</c><00:03:03.250><c> abu</c>

00:03:04.050 --> 00:03:04.060 align:start position:0%
for some really exciting work that abu
 

00:03:04.060 --> 00:03:06.509 align:start position:0%
for some really exciting work that abu
is<00:03:04.180><c> showing</c><00:03:04.480><c> yesterday</c><00:03:05.040><c> during</c><00:03:06.040><c> her</c><00:03:06.159><c> lecture</c>

00:03:06.509 --> 00:03:06.519 align:start position:0%
is showing yesterday during her lecture
 

00:03:06.519 --> 00:03:08.309 align:start position:0%
is showing yesterday during her lecture
and<00:03:06.730><c> they're</c><00:03:07.060><c> known</c><00:03:07.209><c> for</c><00:03:07.419><c> this</c><00:03:07.540><c> development</c>

00:03:08.309 --> 00:03:08.319 align:start position:0%
and they're known for this development
 

00:03:08.319 --> 00:03:10.110 align:start position:0%
and they're known for this development
of<00:03:08.500><c> an</c><00:03:08.590><c> end-to-end</c><00:03:08.889><c> platform</c><00:03:09.549><c> for</c><00:03:09.760><c> autonomous</c>

00:03:10.110 --> 00:03:10.120 align:start position:0%
of an end-to-end platform for autonomous
 

00:03:10.120 --> 00:03:13.020 align:start position:0%
of an end-to-end platform for autonomous
driving<00:03:10.419><c> that</c><00:03:11.169><c> takes</c><00:03:11.590><c> directly</c><00:03:12.430><c> image</c><00:03:12.760><c> data</c>

00:03:13.020 --> 00:03:13.030 align:start position:0%
driving that takes directly image data
 

00:03:13.030 --> 00:03:15.300 align:start position:0%
driving that takes directly image data
and<00:03:13.150><c> produces</c><00:03:13.810><c> a</c><00:03:14.019><c> steering</c><00:03:14.620><c> control</c><00:03:14.919><c> command</c>

00:03:15.300 --> 00:03:15.310 align:start position:0%
and produces a steering control command
 

00:03:15.310 --> 00:03:17.270 align:start position:0%
and produces a steering control command
at<00:03:15.549><c> the</c><00:03:15.760><c> car</c><00:03:15.969><c> for</c><00:03:16.359><c> the</c><00:03:16.449><c> car</c><00:03:16.629><c> at</c><00:03:16.719><c> the</c><00:03:16.840><c> output</c>

00:03:17.270 --> 00:03:17.280 align:start position:0%
at the car for the car at the output
 

00:03:17.280 --> 00:03:20.039 align:start position:0%
at the car for the car at the output
then<00:03:18.280><c> we'll</c><00:03:18.400><c> hear</c><00:03:18.579><c> about</c><00:03:18.810><c> we'll</c><00:03:19.810><c> hear</c><00:03:19.930><c> from</c>

00:03:20.039 --> 00:03:20.049 align:start position:0%
then we'll hear about we'll hear from
 

00:03:20.049 --> 00:03:22.259 align:start position:0%
then we'll hear about we'll hear from
two<00:03:20.199><c> Google</c><00:03:20.709><c> brain</c><00:03:20.889><c> researchers</c><00:03:21.579><c> on</c><00:03:21.879><c> recent</c>

00:03:22.259 --> 00:03:22.269 align:start position:0%
two Google brain researchers on recent
 

00:03:22.269 --> 00:03:24.689 align:start position:0%
two Google brain researchers on recent
advancements<00:03:22.870><c> on</c><00:03:23.019><c> image</c><00:03:23.489><c> classification</c><00:03:24.489><c> at</c>

00:03:24.689 --> 00:03:24.699 align:start position:0%
advancements on image classification at
 

00:03:24.699 --> 00:03:27.240 align:start position:0%
advancements on image classification at
Google<00:03:25.090><c> and</c><00:03:25.419><c> also</c><00:03:26.319><c> we'll</c><00:03:26.709><c> hear</c><00:03:26.859><c> about</c><00:03:26.889><c> some</c>

00:03:27.240 --> 00:03:27.250 align:start position:0%
Google and also we'll hear about some
 

00:03:27.250 --> 00:03:29.969 align:start position:0%
Google and also we'll hear about some
super<00:03:28.030><c> recent</c><00:03:28.180><c> advancements</c><00:03:29.079><c> and</c><00:03:29.290><c> additions</c>

00:03:29.969 --> 00:03:29.979 align:start position:0%
super recent advancements and additions
 

00:03:29.979 --> 00:03:32.069 align:start position:0%
super recent advancements and additions
to<00:03:30.069><c> the</c><00:03:30.250><c> tensorflow</c><00:03:30.609><c> pipeline</c><00:03:31.269><c> that</c><00:03:31.930><c> were</c>

00:03:32.069 --> 00:03:32.079 align:start position:0%
to the tensorflow pipeline that were
 

00:03:32.079 --> 00:03:34.080 align:start position:0%
to the tensorflow pipeline that were
actually<00:03:32.379><c> just</c><00:03:32.470><c> released</c><00:03:32.829><c> a</c><00:03:33.250><c> couple</c><00:03:33.609><c> days</c><00:03:33.909><c> ago</c>

00:03:34.080 --> 00:03:34.090 align:start position:0%
actually just released a couple days ago
 

00:03:34.090 --> 00:03:36.979 align:start position:0%
actually just released a couple days ago
so<00:03:34.780><c> this</c><00:03:34.900><c> is</c><00:03:35.049><c> really</c><00:03:35.290><c> really</c><00:03:35.409><c> new</c><00:03:35.709><c> stuff</c>

00:03:36.979 --> 00:03:36.989 align:start position:0%
so this is really really new stuff
 

00:03:36.989 --> 00:03:39.030 align:start position:0%
so this is really really new stuff
tomorrow<00:03:37.989><c> afternoon</c><00:03:38.409><c> we'll</c><00:03:38.620><c> get</c><00:03:38.739><c> together</c>

00:03:39.030 --> 00:03:39.040 align:start position:0%
tomorrow afternoon we'll get together
 

00:03:39.040 --> 00:03:40.979 align:start position:0%
tomorrow afternoon we'll get together
for<00:03:39.280><c> one</c><00:03:39.430><c> of</c><00:03:39.549><c> the</c><00:03:39.759><c> most</c><00:03:39.939><c> exciting</c><00:03:40.299><c> parts</c><00:03:40.780><c> of</c>

00:03:40.979 --> 00:03:40.989 align:start position:0%
for one of the most exciting parts of
 

00:03:40.989 --> 00:03:44.789 align:start position:0%
for one of the most exciting parts of
this<00:03:41.109><c> class</c><00:03:42.479><c> so</c><00:03:43.479><c> what</c><00:03:44.049><c> will</c><00:03:44.199><c> happen</c><00:03:44.229><c> is</c><00:03:44.650><c> we'll</c>

00:03:44.789 --> 00:03:44.799 align:start position:0%
this class so what will happen is we'll
 

00:03:44.799 --> 00:03:46.229 align:start position:0%
this class so what will happen is we'll
have<00:03:44.829><c> each</c><00:03:45.129><c> of</c><00:03:45.280><c> the</c><00:03:45.400><c> sponsors</c><00:03:45.790><c> actually</c><00:03:45.939><c> come</c>

00:03:46.229 --> 00:03:46.239 align:start position:0%
have each of the sponsors actually come
 

00:03:46.239 --> 00:03:48.300 align:start position:0%
have each of the sponsors actually come
up<00:03:46.269><c> to</c><00:03:46.509><c> the</c><00:03:46.599><c> front</c><00:03:46.720><c> of</c><00:03:46.930><c> the</c><00:03:47.019><c> class</c><00:03:47.229><c> here</c><00:03:47.560><c> we</c>

00:03:48.300 --> 00:03:48.310 align:start position:0%
up to the front of the class here we
 

00:03:48.310 --> 00:03:50.069 align:start position:0%
up to the front of the class here we
have<00:03:48.400><c> four</c><00:03:48.609><c> sponsors</c><00:03:49.120><c> that</c><00:03:49.329><c> will</c><00:03:49.449><c> present</c><00:03:49.959><c> on</c>

00:03:50.069 --> 00:03:50.079 align:start position:0%
have four sponsors that will present on
 

00:03:50.079 --> 00:03:52.289 align:start position:0%
have four sponsors that will present on
each<00:03:50.199><c> of</c><00:03:50.319><c> these</c><00:03:50.409><c> four</c><00:03:50.470><c> boards</c><00:03:51.040><c> and</c><00:03:51.250><c> you'll</c><00:03:52.180><c> be</c>

00:03:52.289 --> 00:03:52.299 align:start position:0%
each of these four boards and you'll be
 

00:03:52.299 --> 00:03:53.280 align:start position:0%
each of these four boards and you'll be
given<00:03:52.569><c> the</c><00:03:52.629><c> opportunity</c><00:03:53.049><c> to</c><00:03:53.079><c> basically</c>

00:03:53.280 --> 00:03:53.290 align:start position:0%
given the opportunity to basically
 

00:03:53.290 --> 00:03:56.240 align:start position:0%
given the opportunity to basically
connect<00:03:54.129><c> with</c><00:03:54.280><c> each</c><00:03:54.430><c> of</c><00:03:54.609><c> them</c><00:03:54.790><c> through</c><00:03:55.000><c> the</c>

00:03:56.240 --> 00:03:56.250 align:start position:0%
connect with each of them through the
 

00:03:56.250 --> 00:03:58.679 align:start position:0%
connect with each of them through the
through<00:03:57.250><c> the</c><00:03:57.340><c> ways</c><00:03:57.489><c> of</c><00:03:57.759><c> a</c><00:03:57.879><c> recruitment</c><00:03:58.329><c> booth</c>

00:03:58.679 --> 00:03:58.689 align:start position:0%
through the ways of a recruitment booth
 

00:03:58.689 --> 00:03:59.939 align:start position:0%
through the ways of a recruitment booth
and<00:03:59.079><c> basically</c><00:03:59.469><c> they're</c><00:03:59.620><c> going</c><00:03:59.739><c> to</c><00:03:59.859><c> be</c>

00:03:59.939 --> 00:03:59.949 align:start position:0%
and basically they're going to be
 

00:03:59.949 --> 00:04:01.979 align:start position:0%
and basically they're going to be
looking<00:04:00.129><c> at</c><00:04:00.549><c> students</c><00:04:01.449><c> that</c><00:04:01.750><c> might</c><00:04:01.930><c> be</c>

00:04:01.979 --> 00:04:01.989 align:start position:0%
looking at students that might be
 

00:04:01.989 --> 00:04:04.110 align:start position:0%
looking at students that might be
interested<00:04:02.590><c> in</c><00:04:02.739><c> deep</c><00:04:02.949><c> learning</c><00:04:03.400><c> internships</c>

00:04:04.110 --> 00:04:04.120 align:start position:0%
interested in deep learning internships
 

00:04:04.120 --> 00:04:06.629 align:start position:0%
interested in deep learning internships
or<00:04:04.599><c> employment</c><00:04:05.109><c> opportunities</c><00:04:05.680><c> so</c><00:04:05.949><c> this</c><00:04:06.459><c> is</c>

00:04:06.629 --> 00:04:06.639 align:start position:0%
or employment opportunities so this is
 

00:04:06.639 --> 00:04:08.459 align:start position:0%
or employment opportunities so this is
really<00:04:06.879><c> an</c><00:04:06.969><c> incredible</c><00:04:07.120><c> opportunity</c><00:04:07.870><c> for</c><00:04:08.259><c> you</c>

00:04:08.459 --> 00:04:08.469 align:start position:0%
really an incredible opportunity for you
 

00:04:08.469 --> 00:04:11.309 align:start position:0%
really an incredible opportunity for you
guys<00:04:08.530><c> to</c><00:04:08.650><c> connect</c><00:04:09.159><c> with</c><00:04:09.310><c> these</c><00:04:09.430><c> companies</c><00:04:10.319><c> in</c>

00:04:11.309 --> 00:04:11.319 align:start position:0%
guys to connect with these companies in
 

00:04:11.319 --> 00:04:14.099 align:start position:0%
guys to connect with these companies in
a<00:04:11.439><c> very</c><00:04:11.709><c> very</c><00:04:12.009><c> very</c><00:04:12.430><c> direct</c><00:04:12.840><c> manner</c><00:04:13.840><c> so</c><00:04:14.079><c> we</c>

00:04:14.099 --> 00:04:14.109 align:start position:0%
a very very very direct manner so we
 

00:04:14.109 --> 00:04:15.659 align:start position:0%
a very very very direct manner so we
highly<00:04:14.560><c> recommend</c><00:04:14.590><c> that</c><00:04:15.189><c> you</c><00:04:15.280><c> take</c><00:04:15.549><c> advantage</c>

00:04:15.659 --> 00:04:15.669 align:start position:0%
highly recommend that you take advantage
 

00:04:15.669 --> 00:04:18.810 align:start position:0%
highly recommend that you take advantage
of<00:04:16.060><c> that</c><00:04:16.709><c> there</c><00:04:17.709><c> will</c><00:04:17.829><c> be</c><00:04:17.859><c> info</c><00:04:18.219><c> sessions</c><00:04:18.639><c> with</c>

00:04:18.810 --> 00:04:18.820 align:start position:0%
of that there will be info sessions with
 

00:04:18.820 --> 00:04:21.330 align:start position:0%
of that there will be info sessions with
pizza<00:04:19.180><c> provided</c><00:04:19.659><c> on</c><00:04:19.780><c> Thursday</c><00:04:20.289><c> with</c><00:04:20.979><c> one</c><00:04:21.219><c> of</c>

00:04:21.330 --> 00:04:21.340 align:start position:0%
pizza provided on Thursday with one of
 

00:04:21.340 --> 00:04:22.890 align:start position:0%
pizza provided on Thursday with one of
these<00:04:21.459><c> guest</c><00:04:21.759><c> lectures</c><00:04:22.150><c> with</c><00:04:22.509><c> one</c><00:04:22.690><c> of</c><00:04:22.780><c> these</c>

00:04:22.890 --> 00:04:22.900 align:start position:0%
these guest lectures with one of these
 

00:04:22.900 --> 00:04:25.620 align:start position:0%
these guest lectures with one of these
industry<00:04:23.830><c> companies</c><00:04:24.250><c> and</c><00:04:24.490><c> we'll</c><00:04:25.270><c> be</c><00:04:25.360><c> sending</c>

00:04:25.620 --> 00:04:25.630 align:start position:0%
industry companies and we'll be sending
 

00:04:25.630 --> 00:04:29.320 align:start position:0%
industry companies and we'll be sending
out<00:04:25.690><c> more</c><00:04:25.870><c> details</c><00:04:26.260><c> with</c><00:04:26.440><c> that</c><00:04:26.590><c> today</c><00:04:27.099><c> as</c><00:04:27.219><c> well</c>

00:04:29.320 --> 00:04:29.330 align:start position:0%
out more details with that today as well
 

00:04:29.330 --> 00:04:31.390 align:start position:0%
out more details with that today as well
so<00:04:29.930><c> on</c><00:04:30.199><c> Friday</c><00:04:30.530><c> we'll</c><00:04:30.800><c> continue</c><00:04:30.979><c> with</c><00:04:31.280><c> the</c>

00:04:31.390 --> 00:04:31.400 align:start position:0%
so on Friday we'll continue with the
 

00:04:31.400 --> 00:04:32.890 align:start position:0%
so on Friday we'll continue with the
guest<00:04:31.580><c> lectures</c><00:04:31.970><c> and</c><00:04:32.300><c> hear</c><00:04:32.419><c> from</c><00:04:32.509><c> Lisa</c><00:04:32.720><c> and</c>

00:04:32.890 --> 00:04:32.900 align:start position:0%
guest lectures and hear from Lisa and
 

00:04:32.900 --> 00:04:35.170 align:start position:0%
guest lectures and hear from Lisa and
meanie<00:04:33.199><c> who</c><00:04:33.889><c> is</c><00:04:34.009><c> the</c><00:04:34.129><c> head</c><00:04:34.310><c> of</c><00:04:34.340><c> IBM</c><00:04:34.789><c> Research</c>

00:04:35.170 --> 00:04:35.180 align:start position:0%
meanie who is the head of IBM Research
 

00:04:35.180 --> 00:04:39.600 align:start position:0%
meanie who is the head of IBM Research
in<00:04:35.389><c> Cambridge</c><00:04:36.310><c> she's</c><00:04:37.310><c> actually</c><00:04:37.610><c> also</c><00:04:38.210><c> the</c>

00:04:39.600 --> 00:04:39.610 align:start position:0%
in Cambridge she's actually also the
 

00:04:39.610 --> 00:04:43.600 align:start position:0%
in Cambridge she's actually also the
director<00:04:40.610><c> of</c><00:04:40.669><c> the</c><00:04:40.940><c> MIT</c><00:04:41.060><c> IBM</c><00:04:41.810><c> lab</c><00:04:42.080><c> and</c><00:04:43.039><c> this</c><00:04:43.490><c> is</c>

00:04:43.600 --> 00:04:43.610 align:start position:0%
director of the MIT IBM lab and this is
 

00:04:43.610 --> 00:04:47.050 align:start position:0%
director of the MIT IBM lab and this is
a<00:04:43.639><c> lab</c><00:04:43.909><c> that</c><00:04:43.940><c> was</c><00:04:44.330><c> just</c><00:04:44.889><c> founded</c><00:04:45.889><c> a</c><00:04:46.069><c> couple</c><00:04:46.430><c> or</c>

00:04:47.050 --> 00:04:47.060 align:start position:0%
a lab that was just founded a couple or
 

00:04:47.060 --> 00:04:48.640 align:start position:0%
a lab that was just founded a couple or
actually<00:04:47.389><c> about</c><00:04:47.419><c> a</c><00:04:47.629><c> month</c><00:04:47.900><c> ago</c><00:04:48.050><c> or</c><00:04:48.139><c> two</c><00:04:48.409><c> months</c>

00:04:48.640 --> 00:04:48.650 align:start position:0%
actually about a month ago or two months
 

00:04:48.650 --> 00:04:49.379 align:start position:0%
actually about a month ago or two months
ago

00:04:49.379 --> 00:04:49.389 align:start position:0%
ago
 

00:04:49.389 --> 00:04:52.570 align:start position:0%
ago
we'll<00:04:50.389><c> be</c><00:04:50.479><c> hearing</c><00:04:50.750><c> about</c><00:04:50.810><c> how</c><00:04:51.220><c> IBM</c><00:04:52.220><c> is</c>

00:04:52.570 --> 00:04:52.580 align:start position:0%
we'll be hearing about how IBM is
 

00:04:52.580 --> 00:04:54.640 align:start position:0%
we'll be hearing about how IBM is
creating<00:04:53.060><c> AI</c><00:04:53.270><c> systems</c><00:04:53.870><c> that</c><00:04:54.050><c> are</c><00:04:54.169><c> capable</c><00:04:54.349><c> of</c>

00:04:54.640 --> 00:04:54.650 align:start position:0%
creating AI systems that are capable of
 

00:04:54.650 --> 00:04:56.260 align:start position:0%
creating AI systems that are capable of
not<00:04:54.830><c> only</c><00:04:55.039><c> deep</c><00:04:55.250><c> learning</c><00:04:55.400><c> but</c><00:04:55.699><c> going</c><00:04:55.849><c> a</c><00:04:55.940><c> step</c>

00:04:56.260 --> 00:04:56.270 align:start position:0%
not only deep learning but going a step
 

00:04:56.270 --> 00:04:58.899 align:start position:0%
not only deep learning but going a step
past<00:04:56.479><c> deep</c><00:04:56.750><c> learning</c><00:04:56.979><c> they're</c><00:04:57.979><c> capable</c><00:04:58.220><c> of</c><00:04:58.669><c> or</c>

00:04:58.899 --> 00:04:58.909 align:start position:0%
past deep learning they're capable of or
 

00:04:58.909 --> 00:05:00.939 align:start position:0%
past deep learning they're capable of or
trying<00:04:59.270><c> to</c><00:04:59.330><c> be</c><00:04:59.509><c> capable</c><00:04:59.720><c> of</c><00:05:00.050><c> learning</c><00:05:00.620><c> and</c>

00:05:00.939 --> 00:05:00.949 align:start position:0%
trying to be capable of learning and
 

00:05:00.949 --> 00:05:03.540 align:start position:0%
trying to be capable of learning and
recently<00:05:01.280><c> on</c><00:05:01.400><c> a</c><00:05:01.430><c> higher-order</c><00:05:01.759><c> sense</c><00:05:02.629><c> and</c>

00:05:03.540 --> 00:05:03.550 align:start position:0%
recently on a higher-order sense and
 

00:05:03.550 --> 00:05:06.040 align:start position:0%
recently on a higher-order sense and
then<00:05:04.550><c> finally</c><00:05:04.940><c> we'll</c><00:05:05.060><c> hear</c><00:05:05.180><c> from</c><00:05:05.360><c> a</c><00:05:05.449><c> principal</c>

00:05:06.040 --> 00:05:06.050 align:start position:0%
then finally we'll hear from a principal
 

00:05:06.050 --> 00:05:08.770 align:start position:0%
then finally we'll hear from a principal
researcher<00:05:06.770><c> at</c><00:05:06.860><c> $0.10</c><00:05:07.340><c> AI</c><00:05:07.550><c> lab</c><00:05:07.940><c> about</c>

00:05:08.770 --> 00:05:08.780 align:start position:0%
researcher at $0.10 AI lab about
 

00:05:08.780 --> 00:05:10.659 align:start position:0%
researcher at $0.10 AI lab about
combining<00:05:09.259><c> computer</c><00:05:09.650><c> vision</c><00:05:10.190><c> and</c><00:05:10.310><c> social</c>

00:05:10.659 --> 00:05:10.669 align:start position:0%
combining computer vision and social
 

00:05:10.669 --> 00:05:13.570 align:start position:0%
combining computer vision and social
networks<00:05:11.229><c> it's</c><00:05:12.229><c> a</c><00:05:12.319><c> very</c><00:05:12.560><c> interesting</c><00:05:13.129><c> topic</c>

00:05:13.570 --> 00:05:13.580 align:start position:0%
networks it's a very interesting topic
 

00:05:13.580 --> 00:05:15.100 align:start position:0%
networks it's a very interesting topic
that<00:05:13.610><c> we</c><00:05:13.969><c> haven't</c><00:05:14.270><c> really</c><00:05:14.419><c> touched</c><00:05:14.659><c> upon</c><00:05:14.870><c> in</c>

00:05:15.100 --> 00:05:15.110 align:start position:0%
that we haven't really touched upon in
 

00:05:15.110 --> 00:05:17.950 align:start position:0%
that we haven't really touched upon in
this<00:05:15.259><c> class</c><00:05:15.849><c> this</c><00:05:16.849><c> topic</c><00:05:17.180><c> of</c><00:05:17.300><c> social</c><00:05:17.629><c> networks</c>

00:05:17.950 --> 00:05:17.960 align:start position:0%
this class this topic of social networks
 

00:05:17.960 --> 00:05:20.140 align:start position:0%
this class this topic of social networks
and<00:05:18.169><c> using</c><00:05:18.469><c> massive</c><00:05:18.800><c> big</c><00:05:19.310><c> data</c><00:05:19.580><c> collected</c>

00:05:20.140 --> 00:05:20.150 align:start position:0%
and using massive big data collected
 

00:05:20.150 --> 00:05:24.430 align:start position:0%
and using massive big data collected
from<00:05:20.330><c> from</c><00:05:20.870><c> humans</c><00:05:21.229><c> themselves</c><00:05:22.270><c> and</c><00:05:23.270><c> then</c><00:05:24.139><c> as</c>

00:05:24.430 --> 00:05:24.440 align:start position:0%
from from humans themselves and then as
 

00:05:24.440 --> 00:05:25.959 align:start position:0%
from from humans themselves and then as
I<00:05:24.710><c> mentioned</c><00:05:25.099><c> before</c><00:05:25.159><c> in</c><00:05:25.490><c> the</c><00:05:25.520><c> afternoon</c>

00:05:25.959 --> 00:05:25.969 align:start position:0%
I mentioned before in the afternoon
 

00:05:25.969 --> 00:05:27.100 align:start position:0%
I mentioned before in the afternoon
we'll<00:05:26.150><c> go</c><00:05:26.270><c> through</c><00:05:26.479><c> and</c><00:05:26.569><c> hear</c><00:05:26.750><c> about</c><00:05:26.960><c> the</c>

00:05:27.100 --> 00:05:27.110 align:start position:0%
we'll go through and hear about the
 

00:05:27.110 --> 00:05:28.570 align:start position:0%
we'll go through and hear about the
final<00:05:27.409><c> project</c><00:05:27.590><c> presentations</c><00:05:28.370><c> we'll</c>

00:05:28.570 --> 00:05:28.580 align:start position:0%
final project presentations we'll
 

00:05:28.580 --> 00:05:30.520 align:start position:0%
final project presentations we'll
celebrate<00:05:28.789><c> with</c><00:05:29.060><c> some</c><00:05:29.240><c> pizza</c><00:05:29.449><c> and</c><00:05:29.780><c> the</c><00:05:30.139><c> awards</c>

00:05:30.520 --> 00:05:30.530 align:start position:0%
celebrate with some pizza and the awards
 

00:05:30.530 --> 00:05:32.219 align:start position:0%
celebrate with some pizza and the awards
that<00:05:30.979><c> will</c><00:05:31.099><c> be</c><00:05:31.219><c> given</c><00:05:31.460><c> out</c><00:05:31.550><c> to</c><00:05:31.610><c> the</c><00:05:31.789><c> top</c>

00:05:32.219 --> 00:05:32.229 align:start position:0%
that will be given out to the top
 

00:05:32.229 --> 00:05:34.839 align:start position:0%
that will be given out to the top
projects<00:05:33.229><c> during</c><00:05:33.529><c> those</c><00:05:33.740><c> during</c><00:05:34.639><c> that</c>

00:05:34.839 --> 00:05:34.849 align:start position:0%
projects during those during that
 

00:05:34.849 --> 00:05:38.260 align:start position:0%
projects during those during that
session<00:05:35.210><c> as</c><00:05:35.509><c> well</c><00:05:36.699><c> so</c><00:05:37.699><c> now</c><00:05:37.819><c> let's</c><00:05:38.000><c> start</c><00:05:38.090><c> with</c>

00:05:38.260 --> 00:05:38.270 align:start position:0%
session as well so now let's start with
 

00:05:38.270 --> 00:05:41.439 align:start position:0%
session as well so now let's start with
the<00:05:38.360><c> technical</c><00:05:38.479><c> content</c><00:05:39.169><c> for</c><00:05:39.380><c> this</c><00:05:39.469><c> class</c><00:05:40.449><c> I'd</c>

00:05:41.439 --> 00:05:41.449 align:start position:0%
the technical content for this class I'd
 

00:05:41.449 --> 00:05:43.659 align:start position:0%
the technical content for this class I'd
like<00:05:41.599><c> to</c><00:05:41.719><c> start</c><00:05:41.960><c> by</c><00:05:42.050><c> just</c><00:05:42.469><c> kind</c><00:05:43.009><c> of</c><00:05:43.130><c> over</c>

00:05:43.659 --> 00:05:43.669 align:start position:0%
like to start by just kind of over
 

00:05:43.669 --> 00:05:45.909 align:start position:0%
like to start by just kind of over
viewing<00:05:44.060><c> the</c><00:05:44.719><c> type</c><00:05:44.990><c> of</c><00:05:45.229><c> architectures</c><00:05:45.889><c> that</c>

00:05:45.909 --> 00:05:45.919 align:start position:0%
viewing the type of architectures that
 

00:05:45.919 --> 00:05:48.519 align:start position:0%
viewing the type of architectures that
we've<00:05:46.219><c> talked</c><00:05:46.490><c> about</c><00:05:46.610><c> so</c><00:05:46.909><c> far</c><00:05:47.259><c> for</c><00:05:48.259><c> the</c><00:05:48.319><c> most</c>

00:05:48.519 --> 00:05:48.529 align:start position:0%
we've talked about so far for the most
 

00:05:48.529 --> 00:05:49.899 align:start position:0%
we've talked about so far for the most
part<00:05:48.770><c> these</c><00:05:48.889><c> architectures</c><00:05:49.460><c> can</c><00:05:49.610><c> be</c><00:05:49.729><c> thought</c>

00:05:49.899 --> 00:05:49.909 align:start position:0%
part these architectures can be thought
 

00:05:49.909 --> 00:05:51.360 align:start position:0%
part these architectures can be thought
of<00:05:50.060><c> almost</c><00:05:50.389><c> pattern-recognition</c>

00:05:51.360 --> 00:05:51.370 align:start position:0%
of almost pattern-recognition
 

00:05:51.370 --> 00:05:54.189 align:start position:0%
of almost pattern-recognition
architectures<00:05:52.370><c> so</c><00:05:52.460><c> they</c><00:05:52.580><c> take</c><00:05:52.789><c> as</c><00:05:52.909><c> input</c><00:05:53.199><c> data</c>

00:05:54.189 --> 00:05:54.199 align:start position:0%
architectures so they take as input data
 

00:05:54.199 --> 00:05:57.790 align:start position:0%
architectures so they take as input data
and<00:05:55.210><c> the</c><00:05:56.210><c> whole</c><00:05:56.389><c> point</c><00:05:56.900><c> of</c><00:05:57.110><c> their</c><00:05:57.319><c> pipeline</c>

00:05:57.790 --> 00:05:57.800 align:start position:0%
and the whole point of their pipeline
 

00:05:57.800 --> 00:06:00.969 align:start position:0%
and the whole point of their pipeline
their<00:05:57.979><c> internals</c><00:05:58.699><c> are</c><00:05:59.029><c> performing</c><00:05:59.979><c> feature</c>

00:06:00.969 --> 00:06:00.979 align:start position:0%
their internals are performing feature
 

00:06:00.979 --> 00:06:02.800 align:start position:0%
their internals are performing feature
extraction<00:06:01.729><c> and</c><00:06:02.029><c> and</c><00:06:02.360><c> what</c><00:06:02.599><c> they're</c><00:06:02.779><c> really</c>

00:06:02.800 --> 00:06:02.810 align:start position:0%
extraction and and what they're really
 

00:06:02.810 --> 00:06:04.450 align:start position:0%
extraction and and what they're really
doing<00:06:03.110><c> is</c><00:06:03.349><c> taking</c><00:06:03.500><c> all</c><00:06:03.770><c> the</c><00:06:03.949><c> sensory</c><00:06:04.310><c> data</c>

00:06:04.450 --> 00:06:04.460 align:start position:0%
doing is taking all the sensory data
 

00:06:04.460 --> 00:06:05.709 align:start position:0%
doing is taking all the sensory data
trying<00:06:04.909><c> to</c><00:06:05.000><c> figure</c><00:06:05.180><c> out</c><00:06:05.240><c> what</c><00:06:05.449><c> are</c><00:06:05.599><c> the</c>

00:06:05.709 --> 00:06:05.719 align:start position:0%
trying to figure out what are the
 

00:06:05.719 --> 00:06:07.360 align:start position:0%
trying to figure out what are the
important<00:06:06.080><c> pieces</c><00:06:06.319><c> what</c><00:06:06.919><c> are</c><00:06:07.039><c> the</c><00:06:07.129><c> patterns</c>

00:06:07.360 --> 00:06:07.370 align:start position:0%
important pieces what are the patterns
 

00:06:07.370 --> 00:06:09.670 align:start position:0%
important pieces what are the patterns
to<00:06:07.729><c> be</c><00:06:07.819><c> learned</c><00:06:08.150><c> within</c><00:06:08.479><c> the</c><00:06:08.719><c> data</c><00:06:08.930><c> such</c><00:06:09.650><c> that</c>

00:06:09.670 --> 00:06:09.680 align:start position:0%
to be learned within the data such that
 

00:06:09.680 --> 00:06:11.320 align:start position:0%
to be learned within the data such that
they<00:06:09.979><c> can</c><00:06:10.159><c> produce</c><00:06:10.340><c> a</c><00:06:10.639><c> decision</c><00:06:11.090><c> at</c><00:06:11.210><c> the</c>

00:06:11.320 --> 00:06:11.330 align:start position:0%
they can produce a decision at the
 

00:06:11.330 --> 00:06:13.600 align:start position:0%
they can produce a decision at the
output<00:06:11.690><c> we've</c><00:06:12.590><c> seen</c><00:06:12.830><c> this</c><00:06:12.949><c> take</c><00:06:13.129><c> many</c><00:06:13.340><c> forms</c>

00:06:13.600 --> 00:06:13.610 align:start position:0%
output we've seen this take many forms
 

00:06:13.610 --> 00:06:16.330 align:start position:0%
output we've seen this take many forms
so<00:06:14.150><c> the</c><00:06:14.419><c> decision</c><00:06:14.870><c> could</c><00:06:14.990><c> be</c><00:06:15.050><c> a</c><00:06:15.169><c> prediction</c><00:06:15.740><c> it</c>

00:06:16.330 --> 00:06:16.340 align:start position:0%
so the decision could be a prediction it
 

00:06:16.340 --> 00:06:18.159 align:start position:0%
so the decision could be a prediction it
could<00:06:16.490><c> be</c><00:06:16.610><c> a</c><00:06:16.639><c> detection</c><00:06:17.120><c> or</c><00:06:17.479><c> even</c><00:06:17.690><c> an</c><00:06:17.810><c> action</c>

00:06:18.159 --> 00:06:18.169 align:start position:0%
could be a detection or even an action
 

00:06:18.169 --> 00:06:19.420 align:start position:0%
could be a detection or even an action
like<00:06:18.319><c> an</c><00:06:18.440><c> agree</c><00:06:18.650><c> enforcement</c><00:06:19.159><c> learning</c>

00:06:19.420 --> 00:06:19.430 align:start position:0%
like an agree enforcement learning
 

00:06:19.430 --> 00:06:21.760 align:start position:0%
like an agree enforcement learning
setting<00:06:19.900><c> we've</c><00:06:20.900><c> even</c><00:06:21.139><c> learned</c><00:06:21.379><c> how</c><00:06:21.590><c> these</c>

00:06:21.760 --> 00:06:21.770 align:start position:0%
setting we've even learned how these
 

00:06:21.770 --> 00:06:24.040 align:start position:0%
setting we've even learned how these
models<00:06:22.219><c> can</c><00:06:22.669><c> be</c><00:06:22.789><c> viewed</c><00:06:23.120><c> in</c><00:06:23.300><c> a</c><00:06:23.509><c> generative</c>

00:06:24.040 --> 00:06:24.050 align:start position:0%
models can be viewed in a generative
 

00:06:24.050 --> 00:06:26.290 align:start position:0%
models can be viewed in a generative
sense<00:06:24.469><c> to</c><00:06:25.009><c> go</c><00:06:25.129><c> in</c><00:06:25.219><c> the</c><00:06:25.310><c> opposite</c><00:06:25.729><c> direction</c><00:06:25.789><c> it</c>

00:06:26.290 --> 00:06:26.300 align:start position:0%
sense to go in the opposite direction it
 

00:06:26.300 --> 00:06:31.029 align:start position:0%
sense to go in the opposite direction it
actually<00:06:26.629><c> generate</c><00:06:27.050><c> new</c><00:06:27.319><c> synthetic</c><00:06:28.099><c> data</c><00:06:30.039><c> but</c>

00:06:31.029 --> 00:06:31.039 align:start position:0%
actually generate new synthetic data but
 

00:06:31.039 --> 00:06:32.469 align:start position:0%
actually generate new synthetic data but
in<00:06:31.190><c> general</c><00:06:31.610><c> we've</c><00:06:31.969><c> been</c><00:06:32.150><c> dealing</c><00:06:32.330><c> with</c>

00:06:32.469 --> 00:06:32.479 align:start position:0%
in general we've been dealing with
 

00:06:32.479 --> 00:06:34.360 align:start position:0%
in general we've been dealing with
algorithms<00:06:33.020><c> that</c><00:06:33.169><c> are</c><00:06:33.229><c> really</c><00:06:33.650><c> optimized</c><00:06:34.159><c> to</c>

00:06:34.360 --> 00:06:34.370 align:start position:0%
algorithms that are really optimized to
 

00:06:34.370 --> 00:06:37.629 align:start position:0%
algorithms that are really optimized to
do<00:06:34.550><c> well</c><00:06:34.789><c> and</c><00:06:35.029><c> only</c><00:06:35.270><c> a</c><00:06:35.449><c> single</c><00:06:35.719><c> task</c><00:06:36.520><c> but</c><00:06:37.520><c> they</c>

00:06:37.629 --> 00:06:37.639 align:start position:0%
do well and only a single task but they
 

00:06:37.639 --> 00:06:39.579 align:start position:0%
do well and only a single task but they
really<00:06:37.880><c> fail</c><00:06:38.120><c> to</c><00:06:38.330><c> think</c><00:06:38.570><c> like</c><00:06:38.899><c> humans</c><00:06:39.139><c> do</c>

00:06:39.579 --> 00:06:39.589 align:start position:0%
really fail to think like humans do
 

00:06:39.589 --> 00:06:41.769 align:start position:0%
really fail to think like humans do
especially<00:06:40.490><c> when</c><00:06:40.610><c> we</c><00:06:40.729><c> consider</c><00:06:41.120><c> a</c><00:06:41.210><c> higher</c>

00:06:41.769 --> 00:06:41.779 align:start position:0%
especially when we consider a higher
 

00:06:41.779 --> 00:06:43.150 align:start position:0%
especially when we consider a higher
order<00:06:42.110><c> level</c><00:06:42.440><c> of</c><00:06:42.770><c> an</c>

00:06:43.150 --> 00:06:43.160 align:start position:0%
order level of an
 

00:06:43.160 --> 00:06:47.250 align:start position:0%
order level of an
telogen<00:06:43.400><c> Slyke</c><00:06:43.760><c> I</c><00:06:43.880><c> defined</c><00:06:44.210><c> on</c><00:06:44.330><c> the</c><00:06:44.420><c> first</c><00:06:44.630><c> day</c>

00:06:47.250 --> 00:06:47.260 align:start position:0%
 
 

00:06:47.260 --> 00:06:49.690 align:start position:0%
 
to<00:06:48.260><c> understand</c><00:06:48.650><c> this</c><00:06:48.770><c> in</c><00:06:48.890><c> a</c><00:06:48.980><c> lot</c><00:06:49.160><c> more</c><00:06:49.310><c> detail</c>

00:06:49.690 --> 00:06:49.700 align:start position:0%
to understand this in a lot more detail
 

00:06:49.700 --> 00:06:51.040 align:start position:0%
to understand this in a lot more detail
we<00:06:49.820><c> have</c><00:06:49.910><c> to</c><00:06:50.000><c> go</c><00:06:50.120><c> back</c><00:06:50.300><c> to</c><00:06:50.480><c> this</c><00:06:50.570><c> very</c><00:06:50.780><c> famous</c>

00:06:51.040 --> 00:06:51.050 align:start position:0%
we have to go back to this very famous
 

00:06:51.050 --> 00:06:53.770 align:start position:0%
we have to go back to this very famous
theorem<00:06:51.590><c> that</c><00:06:52.010><c> was</c><00:06:52.180><c> dating</c><00:06:53.180><c> back</c><00:06:53.330><c> almost</c><00:06:53.360><c> 30</c>

00:06:53.770 --> 00:06:53.780 align:start position:0%
theorem that was dating back almost 30
 

00:06:53.780 --> 00:06:57.100 align:start position:0%
theorem that was dating back almost 30
years<00:06:54.350><c> from</c><00:06:54.560><c> today</c><00:06:55.330><c> this</c><00:06:56.330><c> theorem</c><00:06:56.780><c> which</c><00:06:56.960><c> is</c>

00:06:57.100 --> 00:06:57.110 align:start position:0%
years from today this theorem which is
 

00:06:57.110 --> 00:06:58.660 align:start position:0%
years from today this theorem which is
known<00:06:57.440><c> as</c><00:06:57.560><c> the</c><00:06:57.590><c> universal</c><00:06:58.130><c> approximation</c>

00:06:58.660 --> 00:06:58.670 align:start position:0%
known as the universal approximation
 

00:06:58.670 --> 00:07:01.330 align:start position:0%
known as the universal approximation
theorem<00:06:59.060><c> was</c><00:07:00.020><c> one</c><00:07:00.230><c> of</c><00:07:00.320><c> the</c><00:07:00.500><c> most</c><00:07:00.680><c> impactful</c>

00:07:01.330 --> 00:07:01.340 align:start position:0%
theorem was one of the most impactful
 

00:07:01.340 --> 00:07:03.520 align:start position:0%
theorem was one of the most impactful
theorems<00:07:02.330><c> and</c><00:07:02.540><c> neural</c><00:07:02.810><c> networks</c><00:07:03.170><c> when</c><00:07:03.410><c> it</c>

00:07:03.520 --> 00:07:03.530 align:start position:0%
theorems and neural networks when it
 

00:07:03.530 --> 00:07:05.380 align:start position:0%
theorems and neural networks when it
first<00:07:03.680><c> came</c><00:07:03.920><c> out</c><00:07:04.130><c> because</c><00:07:04.580><c> it</c><00:07:04.910><c> had</c><00:07:05.090><c> such</c><00:07:05.360><c> a</c>

00:07:05.380 --> 00:07:05.390 align:start position:0%
first came out because it had such a
 

00:07:05.390 --> 00:07:08.670 align:start position:0%
first came out because it had such a
profound<00:07:06.010><c> it</c><00:07:07.010><c> proved</c><00:07:07.370><c> such</c><00:07:07.550><c> a</c><00:07:07.580><c> profound</c><00:07:08.210><c> claim</c>

00:07:08.670 --> 00:07:08.680 align:start position:0%
profound it proved such a profound claim
 

00:07:08.680 --> 00:07:11.020 align:start position:0%
profound it proved such a profound claim
what<00:07:09.680><c> it</c><00:07:09.770><c> states</c><00:07:10.040><c> is</c><00:07:10.190><c> that</c><00:07:10.220><c> a</c><00:07:10.370><c> neural</c><00:07:10.700><c> network</c>

00:07:11.020 --> 00:07:11.030 align:start position:0%
what it states is that a neural network
 

00:07:11.030 --> 00:07:13.810 align:start position:0%
what it states is that a neural network
with<00:07:11.240><c> a</c><00:07:11.270><c> single</c><00:07:11.750><c> hidden</c><00:07:11.900><c> layer</c><00:07:12.020><c> is</c><00:07:12.820><c> sufficient</c>

00:07:13.810 --> 00:07:13.820 align:start position:0%
with a single hidden layer is sufficient
 

00:07:13.820 --> 00:07:16.150 align:start position:0%
with a single hidden layer is sufficient
to<00:07:13.880><c> approximate</c><00:07:14.420><c> any</c><00:07:14.660><c> function</c><00:07:15.380><c> to</c><00:07:15.950><c> any</c>

00:07:16.150 --> 00:07:16.160 align:start position:0%
to approximate any function to any
 

00:07:16.160 --> 00:07:19.090 align:start position:0%
to approximate any function to any
arbitrary<00:07:16.490><c> level</c><00:07:17.090><c> of</c><00:07:17.330><c> accuracy</c><00:07:17.830><c> now</c><00:07:18.830><c> in</c><00:07:18.950><c> this</c>

00:07:19.090 --> 00:07:19.100 align:start position:0%
arbitrary level of accuracy now in this
 

00:07:19.100 --> 00:07:21.310 align:start position:0%
arbitrary level of accuracy now in this
class<00:07:19.310><c> we</c><00:07:19.550><c> deal</c><00:07:19.760><c> with</c><00:07:19.790><c> networks</c><00:07:20.480><c> that</c><00:07:21.200><c> are</c>

00:07:21.310 --> 00:07:21.320 align:start position:0%
class we deal with networks that are
 

00:07:21.320 --> 00:07:23.200 align:start position:0%
class we deal with networks that are
deep<00:07:21.650><c> they're</c><00:07:21.920><c> not</c><00:07:22.100><c> single</c><00:07:22.610><c> layered</c><00:07:22.820><c> so</c>

00:07:23.200 --> 00:07:23.210 align:start position:0%
deep they're not single layered so
 

00:07:23.210 --> 00:07:24.280 align:start position:0%
deep they're not single layered so
they're<00:07:23.360><c> actually</c><00:07:23.450><c> more</c><00:07:23.840><c> than</c><00:07:24.020><c> a</c><00:07:24.050><c> single</c>

00:07:24.280 --> 00:07:24.290 align:start position:0%
they're actually more than a single
 

00:07:24.290 --> 00:07:26.080 align:start position:0%
they're actually more than a single
layer<00:07:24.590><c> so</c><00:07:25.100><c> actually</c><00:07:25.400><c> they</c><00:07:25.490><c> contain</c><00:07:25.820><c> even</c><00:07:26.060><c> more</c>

00:07:26.080 --> 00:07:26.090 align:start position:0%
layer so actually they contain even more
 

00:07:26.090 --> 00:07:28.420 align:start position:0%
layer so actually they contain even more
complexity<00:07:27.080><c> than</c><00:07:27.650><c> the</c><00:07:27.890><c> network</c><00:07:28.280><c> down</c>

00:07:28.420 --> 00:07:28.430 align:start position:0%
complexity than the network down
 

00:07:28.430 --> 00:07:30.400 align:start position:0%
complexity than the network down
referring<00:07:28.910><c> to</c><00:07:29.030><c> here</c><00:07:29.300><c> but</c><00:07:29.810><c> this</c><00:07:30.050><c> theorem</c>

00:07:30.400 --> 00:07:30.410 align:start position:0%
referring to here but this theorem
 

00:07:30.410 --> 00:07:34.480 align:start position:0%
referring to here but this theorem
proves<00:07:31.330><c> that</c><00:07:32.330><c> we</c><00:07:33.170><c> actually</c><00:07:33.410><c> only</c><00:07:33.740><c> need</c><00:07:33.890><c> one</c>

00:07:34.480 --> 00:07:34.490 align:start position:0%
proves that we actually only need one
 

00:07:34.490 --> 00:07:37.330 align:start position:0%
proves that we actually only need one
layer<00:07:34.760><c> to</c><00:07:35.630><c> accomplish</c><00:07:36.200><c> or</c><00:07:36.410><c> to</c><00:07:36.620><c> approximate</c>

00:07:37.330 --> 00:07:37.340 align:start position:0%
layer to accomplish or to approximate
 

00:07:37.340 --> 00:07:39.430 align:start position:0%
layer to accomplish or to approximate
any<00:07:37.520><c> function</c><00:07:38.060><c> in</c><00:07:38.210><c> the</c><00:07:38.300><c> world</c><00:07:38.450><c> and</c><00:07:38.780><c> if</c><00:07:39.350><c> you</c>

00:07:39.430 --> 00:07:39.440 align:start position:0%
any function in the world and if you
 

00:07:39.440 --> 00:07:42.010 align:start position:0%
any function in the world and if you
believe<00:07:39.620><c> that</c><00:07:39.680><c> any</c><00:07:40.390><c> problem</c><00:07:41.390><c> can</c><00:07:41.660><c> actually</c><00:07:41.930><c> be</c>

00:07:42.010 --> 00:07:42.020 align:start position:0%
believe that any problem can actually be
 

00:07:42.020 --> 00:07:44.080 align:start position:0%
believe that any problem can actually be
reduced<00:07:42.200><c> to</c><00:07:43.130><c> a</c><00:07:43.160><c> sets</c><00:07:43.430><c> of</c><00:07:43.550><c> inputs</c><00:07:43.940><c> and</c><00:07:44.000><c> outputs</c>

00:07:44.080 --> 00:07:44.090 align:start position:0%
reduced to a sets of inputs and outputs
 

00:07:44.090 --> 00:07:47.380 align:start position:0%
reduced to a sets of inputs and outputs
in<00:07:44.630><c> this</c><00:07:44.720><c> form</c><00:07:45.020><c> of</c><00:07:45.170><c> a</c><00:07:45.260><c> function</c><00:07:46.150><c> then</c><00:07:47.150><c> this</c>

00:07:47.380 --> 00:07:47.390 align:start position:0%
in this form of a function then this
 

00:07:47.390 --> 00:07:49.360 align:start position:0%
in this form of a function then this
theorem<00:07:47.660><c> shows</c><00:07:47.810><c> you</c><00:07:48.260><c> that</c><00:07:48.530><c> it's</c><00:07:48.830><c> that</c><00:07:49.340><c> a</c>

00:07:49.360 --> 00:07:49.370 align:start position:0%
theorem shows you that it's that a
 

00:07:49.370 --> 00:07:50.860 align:start position:0%
theorem shows you that it's that a
neural<00:07:49.730><c> network</c><00:07:49.910><c> with</c><00:07:50.150><c> just</c><00:07:50.360><c> a</c><00:07:50.420><c> single</c><00:07:50.720><c> layer</c>

00:07:50.860 --> 00:07:50.870 align:start position:0%
neural network with just a single layer
 

00:07:50.870 --> 00:07:53.320 align:start position:0%
neural network with just a single layer
is<00:07:51.140><c> able</c><00:07:51.560><c> to</c><00:07:51.770><c> solve</c><00:07:52.340><c> any</c><00:07:52.700><c> problem</c><00:07:53.150><c> in</c><00:07:53.240><c> the</c>

00:07:53.320 --> 00:07:53.330 align:start position:0%
is able to solve any problem in the
 

00:07:53.330 --> 00:07:56.140 align:start position:0%
is able to solve any problem in the
world<00:07:53.830><c> now</c><00:07:54.830><c> this</c><00:07:54.980><c> is</c><00:07:55.130><c> an</c><00:07:55.250><c> incredibly</c><00:07:55.760><c> powerful</c>

00:07:56.140 --> 00:07:56.150 align:start position:0%
world now this is an incredibly powerful
 

00:07:56.150 --> 00:07:57.910 align:start position:0%
world now this is an incredibly powerful
result<00:07:56.750><c> but</c><00:07:56.870><c> if</c><00:07:56.960><c> you</c><00:07:57.050><c> look</c><00:07:57.230><c> closely</c><00:07:57.530><c> there</c><00:07:57.860><c> are</c>

00:07:57.910 --> 00:07:57.920 align:start position:0%
result but if you look closely there are
 

00:07:57.920 --> 00:08:00.550 align:start position:0%
result but if you look closely there are
a<00:07:58.070><c> few</c><00:07:58.370><c> very</c><00:07:58.790><c> important</c><00:07:59.210><c> caveats</c><00:07:59.419><c> I'm</c><00:07:59.930><c> not</c>

00:08:00.550 --> 00:08:00.560 align:start position:0%
a few very important caveats I'm not
 

00:08:00.560 --> 00:08:02.650 align:start position:0%
a few very important caveats I'm not
actually<00:08:00.740><c> telling</c><00:08:01.280><c> you</c><00:08:01.430><c> how</c><00:08:01.850><c> large</c><00:08:02.240><c> that</c>

00:08:02.650 --> 00:08:02.660 align:start position:0%
actually telling you how large that
 

00:08:02.660 --> 00:08:04.300 align:start position:0%
actually telling you how large that
hidden<00:08:02.900><c> layer</c><00:08:03.140><c> has</c><00:08:03.350><c> to</c><00:08:03.380><c> be</c><00:08:03.680><c> to</c><00:08:03.890><c> accomplish</c>

00:08:04.300 --> 00:08:04.310 align:start position:0%
hidden layer has to be to accomplish
 

00:08:04.310 --> 00:08:05.040 align:start position:0%
hidden layer has to be to accomplish
this<00:08:04.460><c> task</c>

00:08:05.040 --> 00:08:05.050 align:start position:0%
this task
 

00:08:05.050 --> 00:08:08.320 align:start position:0%
this task
now<00:08:06.050><c> with</c><00:08:06.200><c> the</c><00:08:06.320><c> size</c><00:08:07.100><c> of</c><00:08:07.280><c> your</c><00:08:07.340><c> problem</c><00:08:07.669><c> the</c>

00:08:08.320 --> 00:08:08.330 align:start position:0%
now with the size of your problem the
 

00:08:08.330 --> 00:08:09.820 align:start position:0%
now with the size of your problem the
hidden<00:08:08.600><c> layer</c><00:08:08.810><c> and</c><00:08:08.840><c> the</c><00:08:09.020><c> number</c><00:08:09.290><c> of</c><00:08:09.380><c> units</c><00:08:09.770><c> in</c>

00:08:09.820 --> 00:08:09.830 align:start position:0%
hidden layer and the number of units in
 

00:08:09.830 --> 00:08:11.800 align:start position:0%
hidden layer and the number of units in
that<00:08:09.980><c> hidden</c><00:08:10.160><c> layer</c><00:08:10.430><c> may</c><00:08:11.000><c> be</c><00:08:11.030><c> exponentially</c>

00:08:11.800 --> 00:08:11.810 align:start position:0%
that hidden layer may be exponentially
 

00:08:11.810 --> 00:08:13.150 align:start position:0%
that hidden layer may be exponentially
large<00:08:12.080><c> and</c><00:08:12.260><c> they'll</c><00:08:12.380><c> grow</c><00:08:12.590><c> exponentially</c>

00:08:13.150 --> 00:08:13.160 align:start position:0%
large and they'll grow exponentially
 

00:08:13.160 --> 00:08:15.580 align:start position:0%
large and they'll grow exponentially
with<00:08:14.000><c> the</c><00:08:14.240><c> difficulty</c><00:08:14.810><c> of</c><00:08:14.900><c> your</c><00:08:14.990><c> problem</c>

00:08:15.580 --> 00:08:15.590 align:start position:0%
with the difficulty of your problem
 

00:08:15.590 --> 00:08:17.710 align:start position:0%
with the difficulty of your problem
this<00:08:16.160><c> makes</c><00:08:16.400><c> training</c><00:08:16.910><c> that</c><00:08:17.030><c> network</c><00:08:17.419><c> very</c>

00:08:17.710 --> 00:08:17.720 align:start position:0%
this makes training that network very
 

00:08:17.720 --> 00:08:19.390 align:start position:0%
this makes training that network very
difficult<00:08:18.260><c> so</c><00:08:18.380><c> I</c><00:08:18.410><c> never</c><00:08:18.530><c> actually</c><00:08:18.890><c> told</c><00:08:19.190><c> you</c>

00:08:19.390 --> 00:08:19.400 align:start position:0%
difficult so I never actually told you
 

00:08:19.400 --> 00:08:21.280 align:start position:0%
difficult so I never actually told you
anything<00:08:19.640><c> about</c><00:08:19.850><c> how</c><00:08:20.540><c> to</c><00:08:20.600><c> obtain</c><00:08:20.870><c> that</c>

00:08:21.280 --> 00:08:21.290 align:start position:0%
anything about how to obtain that
 

00:08:21.290 --> 00:08:23.980 align:start position:0%
anything about how to obtain that
Network<00:08:21.590><c> I</c><00:08:21.740><c> just</c><00:08:21.950><c> told</c><00:08:22.130><c> you</c><00:08:22.340><c> that</c><00:08:22.550><c> it</c><00:08:23.240><c> existed</c>

00:08:23.980 --> 00:08:23.990 align:start position:0%
Network I just told you that it existed
 

00:08:23.990 --> 00:08:26.080 align:start position:0%
Network I just told you that it existed
and<00:08:24.169><c> there</c><00:08:24.470><c> is</c><00:08:24.620><c> a</c><00:08:24.650><c> possible</c><00:08:25.100><c> network</c><00:08:25.430><c> in</c><00:08:25.669><c> the</c>

00:08:26.080 --> 00:08:26.090 align:start position:0%
and there is a possible network in the
 

00:08:26.090 --> 00:08:27.700 align:start position:0%
and there is a possible network in the
realm<00:08:26.360><c> of</c><00:08:26.510><c> all</c><00:08:26.630><c> neural</c><00:08:26.960><c> networks</c><00:08:27.260><c> that</c><00:08:27.590><c> could</c>

00:08:27.700 --> 00:08:27.710 align:start position:0%
realm of all neural networks that could
 

00:08:27.710 --> 00:08:29.770 align:start position:0%
realm of all neural networks that could
solve<00:08:27.919><c> that</c><00:08:28.040><c> problem</c><00:08:28.370><c> but</c><00:08:28.490><c> as</c><00:08:28.700><c> we</c><00:08:29.480><c> know</c><00:08:29.660><c> in</c>

00:08:29.770 --> 00:08:29.780 align:start position:0%
solve that problem but as we know in
 

00:08:29.780 --> 00:08:31.540 align:start position:0%
solve that problem but as we know in
practice<00:08:29.960><c> actually</c><00:08:30.470><c> training</c><00:08:31.370><c> neural</c>

00:08:31.540 --> 00:08:31.550 align:start position:0%
practice actually training neural
 

00:08:31.550 --> 00:08:33.550 align:start position:0%
practice actually training neural
networks<00:08:31.910><c> because</c><00:08:32.810><c> of</c><00:08:32.930><c> their</c><00:08:33.050><c> non</c><00:08:33.260><c> convex</c>

00:08:33.550 --> 00:08:33.560 align:start position:0%
networks because of their non convex
 

00:08:33.560 --> 00:08:40.810 align:start position:0%
networks because of their non convex
structure<00:08:34.160><c> is</c><00:08:34.340><c> extremely</c><00:08:35.060><c> difficult</c><00:08:39.640><c> so</c><00:08:40.640><c> this</c>

00:08:40.810 --> 00:08:40.820 align:start position:0%
structure is extremely difficult so this
 

00:08:40.820 --> 00:08:42.610 align:start position:0%
structure is extremely difficult so this
theorem<00:08:41.060><c> is</c><00:08:41.210><c> really</c><00:08:41.419><c> a</c><00:08:41.450><c> perfect</c><00:08:41.900><c> example</c><00:08:42.020><c> of</c>

00:08:42.610 --> 00:08:42.620 align:start position:0%
theorem is really a perfect example of
 

00:08:42.620 --> 00:08:45.930 align:start position:0%
theorem is really a perfect example of
the<00:08:42.740><c> possible</c><00:08:43.099><c> effects</c><00:08:43.460><c> of</c><00:08:43.870><c> overhyping</c><00:08:44.870><c> in</c><00:08:45.200><c> AI</c>

00:08:45.930 --> 00:08:45.940 align:start position:0%
the possible effects of overhyping in AI
 

00:08:45.940 --> 00:08:49.480 align:start position:0%
the possible effects of overhyping in AI
so<00:08:46.940><c> over</c><00:08:47.210><c> the</c><00:08:47.390><c> history</c><00:08:47.720><c> of</c><00:08:47.840><c> AI</c><00:08:48.020><c> we've</c><00:08:48.380><c> had</c><00:08:48.590><c> two</c>

00:08:49.480 --> 00:08:49.490 align:start position:0%
so over the history of AI we've had two
 

00:08:49.490 --> 00:08:52.450 align:start position:0%
so over the history of AI we've had two
AI<00:08:49.730><c> winters</c><00:08:50.240><c> and</c><00:08:50.450><c> this</c><00:08:50.780><c> theorem</c><00:08:51.500><c> was</c><00:08:51.770><c> one</c><00:08:52.310><c> of</c>

00:08:52.450 --> 00:08:52.460 align:start position:0%
AI winters and this theorem was one of
 

00:08:52.460 --> 00:08:56.420 align:start position:0%
AI winters and this theorem was one of
the<00:08:54.670><c> resurgence</c>

00:08:56.420 --> 00:08:56.430 align:start position:0%
the resurgence
 

00:08:56.430 --> 00:08:58.250 align:start position:0%
the resurgence
after<00:08:56.670><c> the</c><00:08:57.029><c> first</c><00:08:57.300><c> day</c><00:08:57.420><c> I</c><00:08:57.450><c> winter</c><00:08:57.839><c> but</c><00:08:57.990><c> it</c><00:08:58.110><c> also</c>

00:08:58.250 --> 00:08:58.260 align:start position:0%
after the first day I winter but it also
 

00:08:58.260 --> 00:09:01.519 align:start position:0%
after the first day I winter but it also
caused<00:08:58.649><c> a</c><00:08:58.890><c> huge</c><00:08:59.100><c> false</c><00:08:59.910><c> hype</c><00:09:00.210><c> in</c><00:09:00.540><c> the</c><00:09:01.110><c> power</c><00:09:01.350><c> of</c>

00:09:01.519 --> 00:09:01.529 align:start position:0%
caused a huge false hype in the power of
 

00:09:01.529 --> 00:09:02.900 align:start position:0%
caused a huge false hype in the power of
these<00:09:01.680><c> neural</c><00:09:01.920><c> networks</c><00:09:02.250><c> which</c><00:09:02.730><c> ultimately</c>

00:09:02.900 --> 00:09:02.910 align:start position:0%
these neural networks which ultimately
 

00:09:02.910 --> 00:09:06.680 align:start position:0%
these neural networks which ultimately
led<00:09:03.420><c> to</c><00:09:03.450><c> yet</c><00:09:03.779><c> another</c><00:09:03.899><c> AI</c><00:09:04.320><c> winter</c><00:09:04.680><c> and</c><00:09:05.180><c> I</c><00:09:06.180><c> feel</c>

00:09:06.680 --> 00:09:06.690 align:start position:0%
led to yet another AI winter and I feel
 

00:09:06.690 --> 00:09:08.120 align:start position:0%
led to yet another AI winter and I feel
like<00:09:06.810><c> as</c><00:09:06.960><c> a</c><00:09:06.990><c> class</c><00:09:07.260><c> it's</c><00:09:07.500><c> very</c><00:09:07.560><c> important</c><00:09:08.040><c> to</c>

00:09:08.120 --> 00:09:08.130 align:start position:0%
like as a class it's very important to
 

00:09:08.130 --> 00:09:10.460 align:start position:0%
like as a class it's very important to
bring<00:09:08.399><c> this</c><00:09:08.580><c> up</c><00:09:08.790><c> because</c><00:09:09.149><c> right</c><00:09:10.020><c> now</c><00:09:10.230><c> we're</c>

00:09:10.460 --> 00:09:10.470 align:start position:0%
bring this up because right now we're
 

00:09:10.470 --> 00:09:16.639 align:start position:0%
bring this up because right now we're
very<00:09:11.160><c> much</c><00:09:11.460><c> in</c><00:09:11.850><c> the</c><00:09:12.690><c> state</c><00:09:13.620><c> of</c><00:09:13.920><c> a</c><00:09:14.339><c> huge</c><00:09:15.649><c> amount</c>

00:09:16.639 --> 00:09:16.649 align:start position:0%
very much in the state of a huge amount
 

00:09:16.649 --> 00:09:18.440 align:start position:0%
very much in the state of a huge amount
of<00:09:17.070><c> overhyping</c><00:09:17.850><c> in</c><00:09:18.060><c> deep</c><00:09:18.270><c> learning</c>

00:09:18.440 --> 00:09:18.450 align:start position:0%
of overhyping in deep learning
 

00:09:18.450 --> 00:09:21.050 align:start position:0%
of overhyping in deep learning
algorithms<00:09:19.220><c> so</c><00:09:20.220><c> these</c><00:09:20.370><c> algorithms</c><00:09:20.670><c> are</c>

00:09:21.050 --> 00:09:21.060 align:start position:0%
algorithms so these algorithms are
 

00:09:21.060 --> 00:09:23.329 align:start position:0%
algorithms so these algorithms are
especially<00:09:21.690><c> in</c><00:09:21.899><c> the</c><00:09:21.959><c> media</c><00:09:22.290><c> being</c><00:09:22.500><c> portrayed</c>

00:09:23.329 --> 00:09:23.339 align:start position:0%
especially in the media being portrayed
 

00:09:23.339 --> 00:09:26.329 align:start position:0%
especially in the media being portrayed
that<00:09:23.940><c> they</c><00:09:24.149><c> can</c><00:09:24.360><c> accomplish</c><00:09:25.040><c> human</c><00:09:26.040><c> level</c>

00:09:26.329 --> 00:09:26.339 align:start position:0%
that they can accomplish human level
 

00:09:26.339 --> 00:09:28.460 align:start position:0%
that they can accomplish human level
intelligence<00:09:26.459><c> and</c><00:09:27.300><c> human</c><00:09:27.690><c> level</c><00:09:27.959><c> reasoning</c>

00:09:28.460 --> 00:09:28.470 align:start position:0%
intelligence and human level reasoning
 

00:09:28.470 --> 00:09:30.769 align:start position:0%
intelligence and human level reasoning
and<00:09:28.649><c> simply</c><00:09:29.430><c> this</c><00:09:29.490><c> is</c><00:09:29.670><c> not</c><00:09:29.820><c> true</c><00:09:30.089><c> so</c><00:09:30.300><c> I</c><00:09:30.480><c> think</c>

00:09:30.769 --> 00:09:30.779 align:start position:0%
and simply this is not true so I think
 

00:09:30.779 --> 00:09:32.810 align:start position:0%
and simply this is not true so I think
such<00:09:31.230><c> over</c><00:09:31.529><c> hype</c><00:09:31.709><c> is</c><00:09:31.920><c> extremely</c><00:09:32.580><c> dangerous</c>

00:09:32.810 --> 00:09:32.820 align:start position:0%
such over hype is extremely dangerous
 

00:09:32.820 --> 00:09:35.810 align:start position:0%
such over hype is extremely dangerous
and<00:09:33.390><c> resulted</c><00:09:34.020><c> well</c><00:09:34.920><c> we</c><00:09:35.040><c> know</c><00:09:35.190><c> it</c><00:09:35.310><c> resulted</c><00:09:35.790><c> in</c>

00:09:35.810 --> 00:09:35.820 align:start position:0%
and resulted well we know it resulted in
 

00:09:35.820 --> 00:09:38.660 align:start position:0%
and resulted well we know it resulted in
in<00:09:36.149><c> both</c><00:09:36.420><c> of</c><00:09:36.630><c> the</c><00:09:36.779><c> two</c><00:09:37.170><c> past</c><00:09:37.500><c> AI</c><00:09:37.740><c> winters</c><00:09:38.220><c> and</c><00:09:38.490><c> I</c>

00:09:38.660 --> 00:09:38.670 align:start position:0%
in both of the two past AI winters and I
 

00:09:38.670 --> 00:09:40.160 align:start position:0%
in both of the two past AI winters and I
think<00:09:38.880><c> as</c><00:09:38.970><c> a</c><00:09:39.000><c> class</c><00:09:39.300><c> it's</c><00:09:39.510><c> very</c><00:09:39.540><c> important</c><00:09:40.050><c> for</c>

00:09:40.160 --> 00:09:40.170 align:start position:0%
think as a class it's very important for
 

00:09:40.170 --> 00:09:42.110 align:start position:0%
think as a class it's very important for
us<00:09:40.350><c> to</c><00:09:40.860><c> focus</c><00:09:41.190><c> on</c><00:09:41.310><c> some</c><00:09:41.520><c> of</c><00:09:41.610><c> the</c><00:09:41.730><c> limitations</c>

00:09:42.110 --> 00:09:42.120 align:start position:0%
us to focus on some of the limitations
 

00:09:42.120 --> 00:09:44.660 align:start position:0%
us to focus on some of the limitations
of<00:09:42.450><c> these</c><00:09:42.570><c> algorithms</c><00:09:43.220><c> so</c><00:09:44.220><c> that</c><00:09:44.370><c> we</c><00:09:44.459><c> don't</c>

00:09:44.660 --> 00:09:44.670 align:start position:0%
of these algorithms so that we don't
 

00:09:44.670 --> 00:09:46.370 align:start position:0%
of these algorithms so that we don't
overhyped<00:09:45.180><c> them</c><00:09:45.360><c> but</c><00:09:45.540><c> we</c><00:09:45.660><c> provide</c><00:09:45.990><c> realistic</c>

00:09:46.370 --> 00:09:46.380 align:start position:0%
overhyped them but we provide realistic
 

00:09:46.380 --> 00:09:48.740 align:start position:0%
overhyped them but we provide realistic
guarantees<00:09:47.100><c> or</c><00:09:47.459><c> realistic</c><00:09:47.820><c> expectations</c>

00:09:48.740 --> 00:09:48.750 align:start position:0%
guarantees or realistic expectations
 

00:09:48.750 --> 00:09:50.690 align:start position:0%
guarantees or realistic expectations
rather<00:09:49.020><c> on</c><00:09:49.260><c> what</c><00:09:49.920><c> these</c><00:09:50.070><c> algorithms</c><00:09:50.339><c> can</c>

00:09:50.690 --> 00:09:50.700 align:start position:0%
rather on what these algorithms can
 

00:09:50.700 --> 00:09:55.280 align:start position:0%
rather on what these algorithms can
accomplish<00:09:50.970><c> and</c><00:09:53.750><c> finally</c><00:09:54.750><c> going</c><00:09:54.899><c> past</c><00:09:55.170><c> these</c>

00:09:55.280 --> 00:09:55.290 align:start position:0%
accomplish and finally going past these
 

00:09:55.290 --> 00:09:56.810 align:start position:0%
accomplish and finally going past these
limitations<00:09:55.709><c> the</c><00:09:56.130><c> last</c><00:09:56.310><c> part</c><00:09:56.520><c> of</c><00:09:56.580><c> this</c><00:09:56.640><c> talk</c>

00:09:56.810 --> 00:09:56.820 align:start position:0%
limitations the last part of this talk
 

00:09:56.820 --> 00:09:58.550 align:start position:0%
limitations the last part of this talk
will<00:09:56.970><c> actually</c><00:09:57.209><c> focus</c><00:09:57.570><c> on</c><00:09:57.779><c> some</c><00:09:58.410><c> of</c><00:09:58.440><c> the</c>

00:09:58.550 --> 00:09:58.560 align:start position:0%
will actually focus on some of the
 

00:09:58.560 --> 00:10:00.050 align:start position:0%
will actually focus on some of the
exciting<00:09:59.010><c> research</c><00:09:59.339><c> like</c><00:09:59.610><c> I</c><00:09:59.700><c> mentioned</c>

00:10:00.050 --> 00:10:00.060 align:start position:0%
exciting research like I mentioned
 

00:10:00.060 --> 00:10:02.570 align:start position:0%
exciting research like I mentioned
before<00:10:00.089><c> that</c><00:10:00.630><c> tries</c><00:10:01.260><c> to</c><00:10:01.290><c> take</c><00:10:01.470><c> a</c><00:10:01.980><c> couple</c><00:10:02.430><c> of</c>

00:10:02.570 --> 00:10:02.580 align:start position:0%
before that tries to take a couple of
 

00:10:02.580 --> 00:10:05.930 align:start position:0%
before that tries to take a couple of
these<00:10:02.760><c> limitations</c><00:10:03.180><c> and</c><00:10:03.890><c> really</c><00:10:04.890><c> focus</c><00:10:05.760><c> on</c>

00:10:05.930 --> 00:10:05.940 align:start position:0%
these limitations and really focus on
 

00:10:05.940 --> 00:10:07.460 align:start position:0%
these limitations and really focus on
possible<00:10:06.480><c> solutions</c><00:10:06.660><c> and</c><00:10:07.080><c> possible</c><00:10:07.410><c> ways</c>

00:10:07.460 --> 00:10:07.470 align:start position:0%
possible solutions and possible ways
 

00:10:07.470 --> 00:10:11.600 align:start position:0%
possible solutions and possible ways
that<00:10:07.620><c> we</c><00:10:07.920><c> can</c><00:10:08.070><c> move</c><00:10:08.400><c> past</c><00:10:08.580><c> them</c><00:10:10.310><c> okay</c><00:10:11.310><c> so</c><00:10:11.370><c> let's</c>

00:10:11.600 --> 00:10:11.610 align:start position:0%
that we can move past them okay so let's
 

00:10:11.610 --> 00:10:13.550 align:start position:0%
that we can move past them okay so let's
start<00:10:11.850><c> and</c><00:10:12.450><c> I</c><00:10:12.540><c> think</c><00:10:12.750><c> one</c><00:10:12.900><c> of</c><00:10:12.930><c> the</c><00:10:13.140><c> best</c>

00:10:13.550 --> 00:10:13.560 align:start position:0%
start and I think one of the best
 

00:10:13.560 --> 00:10:16.940 align:start position:0%
start and I think one of the best
examples<00:10:14.190><c> of</c><00:10:14.279><c> a</c><00:10:14.370><c> potential</c><00:10:14.910><c> danger</c><00:10:15.420><c> of</c><00:10:15.950><c> neural</c>

00:10:16.940 --> 00:10:16.950 align:start position:0%
examples of a potential danger of neural
 

00:10:16.950 --> 00:10:18.680 align:start position:0%
examples of a potential danger of neural
networks<00:10:17.279><c> comes</c><00:10:17.820><c> from</c><00:10:17.970><c> this</c><00:10:18.120><c> paper</c><00:10:18.390><c> from</c>

00:10:18.680 --> 00:10:18.690 align:start position:0%
networks comes from this paper from
 

00:10:18.690 --> 00:10:22.100 align:start position:0%
networks comes from this paper from
google<00:10:19.080><c> deepmind</c><00:10:20.209><c> named</c><00:10:21.209><c> understanding</c><00:10:21.930><c> deep</c>

00:10:22.100 --> 00:10:22.110 align:start position:0%
google deepmind named understanding deep
 

00:10:22.110 --> 00:10:23.949 align:start position:0%
google deepmind named understanding deep
neural<00:10:22.260><c> networks</c><00:10:22.740><c> requires</c><00:10:23.279><c> rethinking</c>

00:10:23.949 --> 00:10:23.959 align:start position:0%
neural networks requires rethinking
 

00:10:23.959 --> 00:10:27.920 align:start position:0%
neural networks requires rethinking
generalization<00:10:24.959><c> and</c><00:10:26.810><c> generalization</c><00:10:27.810><c> was</c>

00:10:27.920 --> 00:10:27.930 align:start position:0%
generalization and generalization was
 

00:10:27.930 --> 00:10:29.900 align:start position:0%
generalization and generalization was
this<00:10:28.080><c> topic</c><00:10:28.500><c> that</c><00:10:28.650><c> we</c><00:10:28.770><c> discussed</c><00:10:29.250><c> in</c><00:10:29.640><c> the</c>

00:10:29.900 --> 00:10:29.910 align:start position:0%
this topic that we discussed in the
 

00:10:29.910 --> 00:10:32.120 align:start position:0%
this topic that we discussed in the
first<00:10:29.940><c> lecture</c><00:10:30.209><c> so</c><00:10:30.630><c> this</c><00:10:30.720><c> is</c><00:10:30.870><c> the</c><00:10:31.050><c> notion</c><00:10:31.260><c> of</c><00:10:31.500><c> a</c>

00:10:32.120 --> 00:10:32.130 align:start position:0%
first lecture so this is the notion of a
 

00:10:32.130 --> 00:10:35.000 align:start position:0%
first lecture so this is the notion of a
gap<00:10:32.970><c> or</c><00:10:33.300><c> a</c><00:10:33.390><c> difference</c><00:10:34.140><c> between</c><00:10:34.440><c> your</c>

00:10:35.000 --> 00:10:35.010 align:start position:0%
gap or a difference between your
 

00:10:35.010 --> 00:10:37.070 align:start position:0%
gap or a difference between your
training<00:10:35.400><c> accuracy</c><00:10:35.910><c> and</c><00:10:36.120><c> your</c><00:10:36.209><c> test</c><00:10:36.480><c> accuracy</c>

00:10:37.070 --> 00:10:37.080 align:start position:0%
training accuracy and your test accuracy
 

00:10:37.080 --> 00:10:40.940 align:start position:0%
training accuracy and your test accuracy
if<00:10:37.680><c> you're</c><00:10:37.890><c> able</c><00:10:38.040><c> to</c><00:10:38.279><c> achieve</c><00:10:38.400><c> equal</c><00:10:39.950><c> training</c>

00:10:40.940 --> 00:10:40.950 align:start position:0%
if you're able to achieve equal training
 

00:10:40.950 --> 00:10:42.319 align:start position:0%
if you're able to achieve equal training
and<00:10:41.070><c> test</c><00:10:41.310><c> accuracy</c><00:10:41.820><c> that</c><00:10:41.940><c> means</c><00:10:42.120><c> you</c><00:10:42.209><c> have</c>

00:10:42.319 --> 00:10:42.329 align:start position:0%
and test accuracy that means you have
 

00:10:42.329 --> 00:10:44.720 align:start position:0%
and test accuracy that means you have
essentially<00:10:42.810><c> no</c><00:10:42.839><c> generalization</c><00:10:43.800><c> gap</c><00:10:44.040><c> you're</c>

00:10:44.720 --> 00:10:44.730 align:start position:0%
essentially no generalization gap you're
 

00:10:44.730 --> 00:10:47.750 align:start position:0%
essentially no generalization gap you're
able<00:10:45.029><c> to</c><00:10:45.060><c> generalize</c><00:10:45.450><c> perfectly</c><00:10:46.320><c> to</c><00:10:46.650><c> to</c><00:10:47.610><c> your</c>

00:10:47.750 --> 00:10:47.760 align:start position:0%
able to generalize perfectly to to your
 

00:10:47.760 --> 00:10:49.490 align:start position:0%
able to generalize perfectly to to your
test<00:10:48.180><c> dataset</c><00:10:48.510><c> but</c><00:10:48.839><c> if</c><00:10:48.930><c> there's</c><00:10:49.140><c> a</c><00:10:49.230><c> huge</c>

00:10:49.490 --> 00:10:49.500 align:start position:0%
test dataset but if there's a huge
 

00:10:49.500 --> 00:10:52.160 align:start position:0%
test dataset but if there's a huge
disparity<00:10:50.339><c> between</c><00:10:50.550><c> these</c><00:10:50.970><c> two</c><00:10:51.150><c> datasets</c><00:10:51.450><c> and</c>

00:10:52.160 --> 00:10:52.170 align:start position:0%
disparity between these two datasets and
 

00:10:52.170 --> 00:10:53.960 align:start position:0%
disparity between these two datasets and
your<00:10:52.320><c> model</c><00:10:52.620><c> is</c><00:10:52.709><c> performing</c><00:10:53.190><c> much</c><00:10:53.370><c> better</c><00:10:53.399><c> on</c>

00:10:53.960 --> 00:10:53.970 align:start position:0%
your model is performing much better on
 

00:10:53.970 --> 00:10:55.550 align:start position:0%
your model is performing much better on
your<00:10:54.360><c> training</c><00:10:54.600><c> data</c><00:10:54.810><c> set</c><00:10:55.079><c> than</c><00:10:55.230><c> your</c><00:10:55.350><c> test</c>

00:10:55.550 --> 00:10:55.560 align:start position:0%
your training data set than your test
 

00:10:55.560 --> 00:10:57.260 align:start position:0%
your training data set than your test
dataset<00:10:55.829><c> this</c><00:10:56.430><c> means</c><00:10:56.640><c> that</c><00:10:56.760><c> you're</c><00:10:56.910><c> not</c><00:10:57.029><c> able</c>

00:10:57.260 --> 00:10:57.270 align:start position:0%
dataset this means that you're not able
 

00:10:57.270 --> 00:10:59.389 align:start position:0%
dataset this means that you're not able
to<00:10:57.450><c> actually</c><00:10:57.690><c> generalize</c><00:10:58.440><c> to</c><00:10:58.980><c> brand</c><00:10:59.250><c> new</c>

00:10:59.389 --> 00:10:59.399 align:start position:0%
to actually generalize to brand new
 

00:10:59.399 --> 00:11:02.480 align:start position:0%
to actually generalize to brand new
images<00:10:59.820><c> you're</c><00:11:00.420><c> only</c><00:11:00.600><c> just</c><00:11:00.899><c> memorizing</c><00:11:01.490><c> the</c>

00:11:02.480 --> 00:11:02.490 align:start position:0%
images you're only just memorizing the
 

00:11:02.490 --> 00:11:04.630 align:start position:0%
images you're only just memorizing the
training<00:11:03.060><c> examples</c>

00:11:04.630 --> 00:11:04.640 align:start position:0%
training examples
 

00:11:04.640 --> 00:11:06.610 align:start position:0%
training examples
and<00:11:05.180><c> what</c><00:11:05.420><c> this</c><00:11:05.570><c> paper</c><00:11:05.930><c> did</c><00:11:06.260><c> was</c><00:11:06.440><c> they</c>

00:11:06.610 --> 00:11:06.620 align:start position:0%
and what this paper did was they
 

00:11:06.620 --> 00:11:08.500 align:start position:0%
and what this paper did was they
performed<00:11:07.370><c> the</c><00:11:07.459><c> following</c><00:11:07.790><c> experiment</c><00:11:08.120><c> so</c>

00:11:08.500 --> 00:11:08.510 align:start position:0%
performed the following experiment so
 

00:11:08.510 --> 00:11:11.079 align:start position:0%
performed the following experiment so
they<00:11:08.630><c> took</c><00:11:08.779><c> images</c><00:11:08.990><c> from</c><00:11:09.380><c> imagenet</c><00:11:10.029><c> so</c><00:11:11.029><c> you</c>

00:11:11.079 --> 00:11:11.089 align:start position:0%
they took images from imagenet so you
 

00:11:11.089 --> 00:11:12.519 align:start position:0%
they took images from imagenet so you
can<00:11:11.240><c> here</c><00:11:11.390><c> see</c><00:11:11.540><c> four</c><00:11:11.870><c> examples</c><00:11:12.140><c> of</c><00:11:12.380><c> these</c>

00:11:12.519 --> 00:11:12.529 align:start position:0%
can here see four examples of these
 

00:11:12.529 --> 00:11:14.410 align:start position:0%
can here see four examples of these
images<00:11:12.950><c> here</c><00:11:13.190><c> and</c><00:11:13.370><c> what</c><00:11:13.820><c> they</c><00:11:13.940><c> did</c><00:11:14.120><c> was</c><00:11:14.269><c> they</c>

00:11:14.410 --> 00:11:14.420 align:start position:0%
images here and what they did was they
 

00:11:14.420 --> 00:11:18.579 align:start position:0%
images here and what they did was they
rolled<00:11:14.750><c> a</c><00:11:15.079><c> case</c><00:11:15.829><c> I</c><00:11:16.070><c> did</c><00:11:16.250><c> die</c><00:11:16.839><c> where</c><00:11:17.839><c> K</c><00:11:18.140><c> is</c><00:11:18.170><c> the</c>

00:11:18.579 --> 00:11:18.589 align:start position:0%
rolled a case I did die where K is the
 

00:11:18.589 --> 00:11:21.009 align:start position:0%
rolled a case I did die where K is the
number<00:11:18.620><c> of</c><00:11:19.010><c> all</c><00:11:19.220><c> possible</c><00:11:19.630><c> labels</c><00:11:20.630><c> in</c><00:11:20.810><c> that</c>

00:11:21.009 --> 00:11:21.019 align:start position:0%
number of all possible labels in that
 

00:11:21.019 --> 00:11:23.550 align:start position:0%
number of all possible labels in that
data<00:11:21.230><c> set</c><00:11:21.500><c> and</c><00:11:22.370><c> this</c><00:11:22.490><c> allowed</c><00:11:22.790><c> them</c><00:11:22.940><c> to</c>

00:11:23.550 --> 00:11:23.560 align:start position:0%
data set and this allowed them to
 

00:11:23.560 --> 00:11:26.740 align:start position:0%
data set and this allowed them to
randomly<00:11:24.560><c> assign</c><00:11:24.950><c> brand</c><00:11:25.850><c> new</c><00:11:26.029><c> labels</c><00:11:26.450><c> to</c><00:11:26.600><c> each</c>

00:11:26.740 --> 00:11:26.750 align:start position:0%
randomly assign brand new labels to each
 

00:11:26.750 --> 00:11:29.680 align:start position:0%
randomly assign brand new labels to each
of<00:11:26.899><c> these</c><00:11:27.019><c> images</c><00:11:27.320><c> so</c><00:11:28.250><c> what</c><00:11:28.910><c> used</c><00:11:29.089><c> to</c><00:11:29.240><c> be</c><00:11:29.360><c> a</c><00:11:29.390><c> dog</c>

00:11:29.680 --> 00:11:29.690 align:start position:0%
of these images so what used to be a dog
 

00:11:29.690 --> 00:11:32.680 align:start position:0%
of these images so what used to be a dog
they<00:11:30.110><c> call</c><00:11:30.470><c> now</c><00:11:30.709><c> a</c><00:11:30.920><c> banana</c><00:11:31.450><c> and</c><00:11:32.450><c> what</c><00:11:32.570><c> they</c>

00:11:32.680 --> 00:11:32.690 align:start position:0%
they call now a banana and what they
 

00:11:32.690 --> 00:11:34.389 align:start position:0%
they call now a banana and what they
used<00:11:33.079><c> to</c><00:11:33.170><c> be</c><00:11:33.230><c> that</c><00:11:33.470><c> banana</c><00:11:33.769><c> is</c><00:11:33.950><c> now</c><00:11:34.070><c> called</c><00:11:34.339><c> the</c>

00:11:34.389 --> 00:11:34.399 align:start position:0%
used to be that banana is now called the
 

00:11:34.399 --> 00:11:36.160 align:start position:0%
used to be that banana is now called the
dog<00:11:34.670><c> and</c><00:11:35.180><c> what</c><00:11:35.420><c> it</c><00:11:35.510><c> used</c><00:11:35.690><c> to</c><00:11:35.750><c> be</c><00:11:35.839><c> called</c><00:11:36.110><c> that</c>

00:11:36.160 --> 00:11:36.170 align:start position:0%
dog and what it used to be called that
 

00:11:36.170 --> 00:11:38.740 align:start position:0%
dog and what it used to be called that
second<00:11:36.709><c> dog</c><00:11:36.890><c> is</c><00:11:37.130><c> now</c><00:11:37.279><c> a</c><00:11:37.310><c> tree</c><00:11:37.670><c> so</c><00:11:38.390><c> note</c><00:11:38.570><c> that</c>

00:11:38.740 --> 00:11:38.750 align:start position:0%
second dog is now a tree so note that
 

00:11:38.750 --> 00:11:40.540 align:start position:0%
second dog is now a tree so note that
the<00:11:38.870><c> two</c><00:11:39.079><c> dogs</c><00:11:39.380><c> have</c><00:11:40.070><c> actually</c><00:11:40.430><c> been</c>

00:11:40.540 --> 00:11:40.550 align:start position:0%
the two dogs have actually been
 

00:11:40.550 --> 00:11:42.310 align:start position:0%
the two dogs have actually been
transformed<00:11:41.209><c> into</c><00:11:41.360><c> two</c><00:11:41.600><c> separate</c><00:11:41.959><c> things</c><00:11:42.110><c> so</c>

00:11:42.310 --> 00:11:42.320 align:start position:0%
transformed into two separate things so
 

00:11:42.320 --> 00:11:43.750 align:start position:0%
transformed into two separate things so
things<00:11:42.529><c> that</c><00:11:42.620><c> used</c><00:11:42.860><c> to</c><00:11:42.950><c> be</c><00:11:43.070><c> in</c><00:11:43.160><c> the</c><00:11:43.250><c> same</c><00:11:43.490><c> class</c>

00:11:43.750 --> 00:11:43.760 align:start position:0%
things that used to be in the same class
 

00:11:43.760 --> 00:11:46.269 align:start position:0%
things that used to be in the same class
are<00:11:44.420><c> now</c><00:11:44.660><c> in</c><00:11:44.810><c> completely</c><00:11:45.290><c> disjoint</c><00:11:45.800><c> classes</c>

00:11:46.269 --> 00:11:46.279 align:start position:0%
are now in completely disjoint classes
 

00:11:46.279 --> 00:11:47.680 align:start position:0%
are now in completely disjoint classes
and<00:11:46.430><c> things</c><00:11:46.519><c> that</c><00:11:46.640><c> were</c><00:11:46.820><c> in</c><00:11:46.940><c> disjoint</c><00:11:47.329><c> classes</c>

00:11:47.680 --> 00:11:47.690 align:start position:0%
and things that were in disjoint classes
 

00:11:47.690 --> 00:11:50.170 align:start position:0%
and things that were in disjoint classes
maybe<00:11:47.930><c> now</c><00:11:48.290><c> in</c><00:11:48.440><c> the</c><00:11:48.560><c> same</c><00:11:48.740><c> class</c><00:11:49.010><c> so</c><00:11:49.820><c> basically</c>

00:11:50.170 --> 00:11:50.180 align:start position:0%
maybe now in the same class so basically
 

00:11:50.180 --> 00:11:52.180 align:start position:0%
maybe now in the same class so basically
we're<00:11:50.420><c> completely</c><00:11:50.899><c> randomizing</c><00:11:51.709><c> our</c><00:11:51.800><c> labels</c>

00:11:52.180 --> 00:11:52.190 align:start position:0%
we're completely randomizing our labels
 

00:11:52.190 --> 00:11:54.970 align:start position:0%
we're completely randomizing our labels
entirely<00:11:53.089><c> and</c><00:11:53.480><c> what</c><00:11:54.440><c> they</c><00:11:54.560><c> did</c><00:11:54.709><c> was</c><00:11:54.860><c> they</c>

00:11:54.970 --> 00:11:54.980 align:start position:0%
entirely and what they did was they
 

00:11:54.980 --> 00:11:56.620 align:start position:0%
entirely and what they did was they
tried<00:11:55.040><c> to</c><00:11:55.250><c> see</c><00:11:55.459><c> if</c><00:11:55.610><c> a</c><00:11:55.700><c> neural</c><00:11:55.970><c> network</c><00:11:56.149><c> could</c>

00:11:56.620 --> 00:11:56.630 align:start position:0%
tried to see if a neural network could
 

00:11:56.630 --> 00:12:01.030 align:start position:0%
tried to see if a neural network could
still<00:11:56.930><c> learn</c><00:11:57.339><c> random</c><00:11:58.339><c> labels</c><00:11:58.700><c> and</c><00:12:00.040><c> here's</c>

00:12:01.030 --> 00:12:01.040 align:start position:0%
still learn random labels and here's
 

00:12:01.040 --> 00:12:04.420 align:start position:0%
still learn random labels and here's
what<00:12:01.160><c> they</c><00:12:01.250><c> found</c><00:12:02.589><c> so</c><00:12:03.589><c> as</c><00:12:03.769><c> you'd</c><00:12:03.950><c> expect</c><00:12:04.310><c> when</c>

00:12:04.420 --> 00:12:04.430 align:start position:0%
what they found so as you'd expect when
 

00:12:04.430 --> 00:12:06.400 align:start position:0%
what they found so as you'd expect when
they<00:12:04.579><c> tested</c><00:12:05.029><c> this</c><00:12:05.149><c> neural</c><00:12:05.420><c> network</c><00:12:05.450><c> with</c>

00:12:06.400 --> 00:12:06.410 align:start position:0%
they tested this neural network with
 

00:12:06.410 --> 00:12:08.680 align:start position:0%
they tested this neural network with
random<00:12:06.800><c> labels</c><00:12:07.190><c> as</c><00:12:07.430><c> they</c><00:12:08.089><c> increase</c><00:12:08.510><c> the</c>

00:12:08.680 --> 00:12:08.690 align:start position:0%
random labels as they increase the
 

00:12:08.690 --> 00:12:12.160 align:start position:0%
random labels as they increase the
randomness<00:12:09.260><c> on</c><00:12:09.410><c> the</c><00:12:09.500><c> x</c><00:12:09.649><c> axis</c><00:12:10.720><c> so</c><00:12:11.720><c> going</c><00:12:11.990><c> from</c>

00:12:12.160 --> 00:12:12.170 align:start position:0%
randomness on the x axis so going from
 

00:12:12.170 --> 00:12:13.480 align:start position:0%
randomness on the x axis so going from
left<00:12:12.350><c> to</c><00:12:12.440><c> right</c><00:12:12.649><c> this</c><00:12:12.800><c> is</c><00:12:12.860><c> the</c><00:12:13.070><c> original</c>

00:12:13.480 --> 00:12:13.490 align:start position:0%
left to right this is the original
 

00:12:13.490 --> 00:12:15.460 align:start position:0%
left to right this is the original
labels<00:12:13.820><c> before</c><00:12:14.050><c> randomizing</c><00:12:15.050><c> anything</c><00:12:15.380><c> and</c>

00:12:15.460 --> 00:12:15.470 align:start position:0%
labels before randomizing anything and
 

00:12:15.470 --> 00:12:17.889 align:start position:0%
labels before randomizing anything and
then<00:12:15.560><c> they</c><00:12:15.680><c> started</c><00:12:15.949><c> randomizing</c><00:12:16.670><c> their</c><00:12:17.390><c> test</c>

00:12:17.889 --> 00:12:17.899 align:start position:0%
then they started randomizing their test
 

00:12:17.899 --> 00:12:20.380 align:start position:0%
then they started randomizing their test
accuracy<00:12:18.529><c> gradually</c><00:12:19.459><c> decreased</c><00:12:19.940><c> and</c><00:12:20.149><c> this</c><00:12:20.240><c> is</c>

00:12:20.380 --> 00:12:20.390 align:start position:0%
accuracy gradually decreased and this is
 

00:12:20.390 --> 00:12:22.480 align:start position:0%
accuracy gradually decreased and this is
as<00:12:20.540><c> expected</c><00:12:21.170><c> because</c><00:12:21.740><c> we're</c><00:12:22.010><c> trying</c><00:12:22.279><c> to</c>

00:12:22.480 --> 00:12:22.490 align:start position:0%
as expected because we're trying to
 

00:12:22.490 --> 00:12:24.670 align:start position:0%
as expected because we're trying to
learn<00:12:22.670><c> something</c><00:12:23.660><c> that</c><00:12:23.779><c> has</c><00:12:23.930><c> absolutely</c><00:12:24.470><c> no</c>

00:12:24.670 --> 00:12:24.680 align:start position:0%
learn something that has absolutely no
 

00:12:24.680 --> 00:12:28.540 align:start position:0%
learn something that has absolutely no
pattern<00:12:25.100><c> in</c><00:12:25.310><c> it</c><00:12:27.100><c> but</c><00:12:28.100><c> then</c><00:12:28.220><c> what's</c><00:12:28.370><c> really</c>

00:12:28.540 --> 00:12:28.550 align:start position:0%
pattern in it but then what's really
 

00:12:28.550 --> 00:12:29.920 align:start position:0%
pattern in it but then what's really
interesting<00:12:28.850><c> is</c><00:12:29.180><c> that</c><00:12:29.329><c> then</c><00:12:29.570><c> they</c><00:12:29.660><c> looked</c><00:12:29.839><c> at</c>

00:12:29.920 --> 00:12:29.930 align:start position:0%
interesting is that then they looked at
 

00:12:29.930 --> 00:12:32.800 align:start position:0%
interesting is that then they looked at
the<00:12:30.079><c> training</c><00:12:30.320><c> accuracy</c><00:12:30.980><c> and</c><00:12:31.690><c> what</c><00:12:32.690><c> they</c>

00:12:32.800 --> 00:12:32.810 align:start position:0%
the training accuracy and what they
 

00:12:32.810 --> 00:12:34.630 align:start position:0%
the training accuracy and what they
found<00:12:32.990><c> was</c><00:12:33.170><c> that</c><00:12:33.290><c> the</c><00:12:33.949><c> neural</c><00:12:34.220><c> network</c><00:12:34.490><c> was</c>

00:12:34.630 --> 00:12:34.640 align:start position:0%
found was that the neural network was
 

00:12:34.640 --> 00:12:38.439 align:start position:0%
found was that the neural network was
able<00:12:34.910><c> to</c><00:12:35.120><c> with</c><00:12:35.870><c> 100%</c><00:12:36.800><c> accuracy</c><00:12:37.269><c> get</c><00:12:38.269><c> the</c>

00:12:38.439 --> 00:12:38.449 align:start position:0%
able to with 100% accuracy get the
 

00:12:38.449 --> 00:12:41.639 align:start position:0%
able to with 100% accuracy get the
training<00:12:38.779><c> set</c><00:12:38.990><c> correct</c><00:12:39.640><c> every</c><00:12:40.640><c> single</c><00:12:41.000><c> time</c>

00:12:41.639 --> 00:12:41.649 align:start position:0%
training set correct every single time
 

00:12:41.649 --> 00:12:44.410 align:start position:0%
training set correct every single time
no<00:12:42.649><c> matter</c><00:12:42.860><c> how</c><00:12:43.130><c> many</c><00:12:43.490><c> random</c><00:12:43.790><c> labels</c><00:12:44.269><c> they</c>

00:12:44.410 --> 00:12:44.420 align:start position:0%
no matter how many random labels they
 

00:12:44.420 --> 00:12:46.930 align:start position:0%
no matter how many random labels they
introduced<00:12:44.980><c> the</c><00:12:45.980><c> training</c><00:12:46.339><c> set</c><00:12:46.550><c> would</c><00:12:46.730><c> always</c>

00:12:46.930 --> 00:12:46.940 align:start position:0%
introduced the training set would always
 

00:12:46.940 --> 00:12:48.910 align:start position:0%
introduced the training set would always
be<00:12:47.269><c> shattered</c><00:12:47.720><c> or</c><00:12:47.930><c> in</c><00:12:48.140><c> other</c><00:12:48.290><c> words</c><00:12:48.529><c> every</c>

00:12:48.910 --> 00:12:48.920 align:start position:0%
be shattered or in other words every
 

00:12:48.920 --> 00:12:51.340 align:start position:0%
be shattered or in other words every
single<00:12:49.000><c> example</c><00:12:50.000><c> in</c><00:12:50.360><c> the</c><00:12:50.510><c> training</c><00:12:50.810><c> set</c><00:12:51.019><c> could</c>

00:12:51.340 --> 00:12:51.350 align:start position:0%
single example in the training set could
 

00:12:51.350 --> 00:12:54.280 align:start position:0%
single example in the training set could
be<00:12:51.440><c> perfectly</c><00:12:51.920><c> classified</c><00:12:52.959><c> so</c><00:12:53.959><c> this</c><00:12:54.079><c> means</c>

00:12:54.280 --> 00:12:54.290 align:start position:0%
be perfectly classified so this means
 

00:12:54.290 --> 00:12:57.759 align:start position:0%
be perfectly classified so this means
that<00:12:55.959><c> modern</c><00:12:56.959><c> deep</c><00:12:57.199><c> neural</c><00:12:57.350><c> networks</c>

00:12:57.759 --> 00:12:57.769 align:start position:0%
that modern deep neural networks
 

00:12:57.769 --> 00:12:59.439 align:start position:0%
that modern deep neural networks
actually<00:12:58.190><c> have</c><00:12:58.399><c> the</c><00:12:58.579><c> capacity</c><00:12:58.730><c> to</c>

00:12:59.439 --> 00:12:59.449 align:start position:0%
actually have the capacity to
 

00:12:59.449 --> 00:13:03.069 align:start position:0%
actually have the capacity to
brute-force<00:13:00.519><c> memorize</c><00:13:01.570><c> massive</c><00:13:02.570><c> data</c><00:13:02.779><c> sets</c>

00:13:03.069 --> 00:13:03.079 align:start position:0%
brute-force memorize massive data sets
 

00:13:03.079 --> 00:13:05.829 align:start position:0%
brute-force memorize massive data sets
even<00:13:03.260><c> on</c><00:13:03.560><c> the</c><00:13:03.680><c> size</c><00:13:03.920><c> of</c><00:13:04.220><c> imagenet</c><00:13:04.839><c> with</c>

00:13:05.829 --> 00:13:05.839 align:start position:0%
even on the size of imagenet with
 

00:13:05.839 --> 00:13:07.569 align:start position:0%
even on the size of imagenet with
completely<00:13:06.290><c> random</c><00:13:06.769><c> labels</c><00:13:07.130><c> they're</c><00:13:07.339><c> able</c><00:13:07.430><c> to</c>

00:13:07.569 --> 00:13:07.579 align:start position:0%
completely random labels they're able to
 

00:13:07.579 --> 00:13:10.449 align:start position:0%
completely random labels they're able to
memorize<00:13:07.850><c> every</c><00:13:08.839><c> single</c><00:13:08.870><c> example</c><00:13:09.560><c> in</c><00:13:09.949><c> that</c>

00:13:10.449 --> 00:13:10.459 align:start position:0%
memorize every single example in that
 

00:13:10.459 --> 00:13:12.819 align:start position:0%
memorize every single example in that
data<00:13:10.670><c> set</c><00:13:10.940><c> and</c><00:13:11.180><c> this</c><00:13:12.079><c> is</c><00:13:12.140><c> a</c><00:13:12.260><c> very</c><00:13:12.560><c> powerful</c>

00:13:12.819 --> 00:13:12.829 align:start position:0%
data set and this is a very powerful
 

00:13:12.829 --> 00:13:15.970 align:start position:0%
data set and this is a very powerful
result<00:13:13.220><c> is</c><00:13:13.940><c> it</c><00:13:14.720><c> drives</c><00:13:15.050><c> home</c><00:13:15.230><c> this</c><00:13:15.380><c> point</c><00:13:15.649><c> that</c>

00:13:15.970 --> 00:13:15.980 align:start position:0%
result is it drives home this point that
 

00:13:15.980 --> 00:13:17.769 align:start position:0%
result is it drives home this point that
neural<00:13:16.339><c> networks</c><00:13:16.640><c> are</c><00:13:16.819><c> you</c>

00:13:17.769 --> 00:13:17.779 align:start position:0%
neural networks are you
 

00:13:17.779 --> 00:13:19.540 align:start position:0%
neural networks are you
really<00:13:18.110><c> excellent</c><00:13:18.529><c> function</c><00:13:18.949><c> approximator</c>

00:13:19.540 --> 00:13:19.550 align:start position:0%
really excellent function approximator
 

00:13:19.550 --> 00:13:22.059 align:start position:0%
really excellent function approximator
x'<00:13:19.779><c> so</c><00:13:20.779><c> this</c><00:13:20.899><c> also</c><00:13:21.170><c> connects</c><00:13:21.649><c> back</c><00:13:21.800><c> to</c><00:13:21.980><c> the</c>

00:13:22.059 --> 00:13:22.069 align:start position:0%
x' so this also connects back to the
 

00:13:22.069 --> 00:13:24.129 align:start position:0%
x' so this also connects back to the
universal<00:13:22.519><c> approximation</c><00:13:22.999><c> theorem</c><00:13:23.360><c> that</c><00:13:24.110><c> I</c>

00:13:24.129 --> 00:13:24.139 align:start position:0%
universal approximation theorem that I
 

00:13:24.139 --> 00:13:27.100 align:start position:0%
universal approximation theorem that I
talked<00:13:24.470><c> about</c><00:13:24.560><c> before</c><00:13:24.860><c> but</c><00:13:25.870><c> they're</c><00:13:26.870><c> really</c>

00:13:27.100 --> 00:13:27.110 align:start position:0%
talked about before but they're really
 

00:13:27.110 --> 00:13:28.509 align:start position:0%
talked about before but they're really
good<00:13:27.259><c> approximator</c><00:13:27.800><c> is</c><00:13:27.889><c> for</c><00:13:28.069><c> just</c><00:13:28.249><c> a</c><00:13:28.339><c> single</c>

00:13:28.509 --> 00:13:28.519 align:start position:0%
good approximator is for just a single
 

00:13:28.519 --> 00:13:31.150 align:start position:0%
good approximator is for just a single
function<00:13:28.819><c> like</c><00:13:29.180><c> I</c><00:13:29.209><c> said</c><00:13:29.709><c> which</c><00:13:30.709><c> means</c><00:13:30.949><c> that</c><00:13:31.069><c> we</c>

00:13:31.150 --> 00:13:31.160 align:start position:0%
function like I said which means that we
 

00:13:31.160 --> 00:13:32.470 align:start position:0%
function like I said which means that we
can<00:13:31.310><c> always</c><00:13:31.639><c> create</c><00:13:31.850><c> this</c><00:13:32.029><c> maximum</c>

00:13:32.470 --> 00:13:32.480 align:start position:0%
can always create this maximum
 

00:13:32.480 --> 00:13:34.629 align:start position:0%
can always create this maximum
likelihood<00:13:32.839><c> estimate</c><00:13:33.350><c> of</c><00:13:33.470><c> our</c><00:13:33.529><c> data</c><00:13:33.829><c> using</c><00:13:34.579><c> a</c>

00:13:34.629 --> 00:13:34.639 align:start position:0%
likelihood estimate of our data using a
 

00:13:34.639 --> 00:13:37.210 align:start position:0%
likelihood estimate of our data using a
neural<00:13:34.910><c> network</c><00:13:35.709><c> such</c><00:13:36.709><c> that</c><00:13:36.889><c> if</c><00:13:37.009><c> we</c><00:13:37.160><c> were</c>

00:13:37.210 --> 00:13:37.220 align:start position:0%
neural network such that if we were
 

00:13:37.220 --> 00:13:38.980 align:start position:0%
neural network such that if we were
given<00:13:37.339><c> a</c><00:13:37.519><c> new</c><00:13:37.699><c> data</c><00:13:37.999><c> point</c><00:13:38.120><c> like</c><00:13:38.600><c> this</c><00:13:38.749><c> purple</c>

00:13:38.980 --> 00:13:38.990 align:start position:0%
given a new data point like this purple
 

00:13:38.990 --> 00:13:41.170 align:start position:0%
given a new data point like this purple
one<00:13:39.199><c> on</c><00:13:39.230><c> the</c><00:13:39.470><c> bottom</c><00:13:39.800><c> it's</c><00:13:40.550><c> easy</c><00:13:40.790><c> for</c><00:13:41.029><c> us</c><00:13:41.149><c> to</c>

00:13:41.170 --> 00:13:41.180 align:start position:0%
one on the bottom it's easy for us to
 

00:13:41.180 --> 00:13:43.660 align:start position:0%
one on the bottom it's easy for us to
compute<00:13:41.720><c> its</c><00:13:41.949><c> estimate</c><00:13:42.949><c> probability</c><00:13:43.490><c> or</c><00:13:43.550><c> its</c>

00:13:43.660 --> 00:13:43.670 align:start position:0%
compute its estimate probability or its
 

00:13:43.670 --> 00:13:46.869 align:start position:0%
compute its estimate probability or its
estimate<00:13:44.149><c> output</c><00:13:44.990><c> just</c><00:13:45.649><c> by</c><00:13:45.829><c> intercepting</c><00:13:46.790><c> it</c>

00:13:46.869 --> 00:13:46.879 align:start position:0%
estimate output just by intercepting it
 

00:13:46.879 --> 00:13:49.110 align:start position:0%
estimate output just by intercepting it
with<00:13:47.029><c> that</c><00:13:47.120><c> maximum</c><00:13:47.329><c> likelihood</c><00:13:47.839><c> estimate</c>

00:13:49.110 --> 00:13:49.120 align:start position:0%
with that maximum likelihood estimate
 

00:13:49.120 --> 00:13:51.400 align:start position:0%
with that maximum likelihood estimate
but<00:13:50.120><c> if</c><00:13:50.209><c> that's</c><00:13:50.509><c> only</c><00:13:50.689><c> if</c><00:13:50.870><c> I'm</c><00:13:50.990><c> looking</c><00:13:51.139><c> at</c><00:13:51.379><c> a</c>

00:13:51.400 --> 00:13:51.410 align:start position:0%
but if that's only if I'm looking at a
 

00:13:51.410 --> 00:13:52.989 align:start position:0%
but if that's only if I'm looking at a
place<00:13:51.559><c> that</c><00:13:51.649><c> we</c><00:13:51.920><c> have</c><00:13:52.129><c> sufficient</c><00:13:52.370><c> training</c>

00:13:52.989 --> 00:13:52.999 align:start position:0%
place that we have sufficient training
 

00:13:52.999 --> 00:13:55.420 align:start position:0%
place that we have sufficient training
data<00:13:53.240><c> already</c><00:13:54.230><c> what</c><00:13:54.529><c> if</c><00:13:54.620><c> I</c><00:13:54.709><c> extend</c><00:13:55.040><c> these</c><00:13:55.220><c> x</c>

00:13:55.420 --> 00:13:55.430 align:start position:0%
data already what if I extend these x
 

00:13:55.430 --> 00:13:57.790 align:start position:0%
data already what if I extend these x
axes<00:13:55.910><c> and</c><00:13:56.120><c> look</c><00:13:56.329><c> at</c><00:13:56.449><c> what</c><00:13:56.629><c> the</c><00:13:57.290><c> neural</c><00:13:57.559><c> network</c>

00:13:57.790 --> 00:13:57.800 align:start position:0%
axes and look at what the neural network
 

00:13:57.800 --> 00:14:00.249 align:start position:0%
axes and look at what the neural network
predicts<00:13:58.189><c> beyond</c><00:13:58.579><c> that</c><00:13:58.850><c> in</c><00:13:59.029><c> these</c><00:13:59.870><c> locations</c>

00:14:00.249 --> 00:14:00.259 align:start position:0%
predicts beyond that in these locations
 

00:14:00.259 --> 00:14:02.110 align:start position:0%
predicts beyond that in these locations
these<00:14:00.680><c> are</c><00:14:00.860><c> actually</c><00:14:01.160><c> the</c><00:14:01.249><c> locations</c><00:14:01.759><c> that</c><00:14:01.939><c> we</c>

00:14:02.110 --> 00:14:02.120 align:start position:0%
these are actually the locations that we
 

00:14:02.120 --> 00:14:04.210 align:start position:0%
these are actually the locations that we
care<00:14:02.420><c> about</c><00:14:02.449><c> most</c><00:14:02.990><c> right</c><00:14:03.680><c> these</c><00:14:03.829><c> are</c><00:14:03.860><c> the</c><00:14:03.980><c> edge</c>

00:14:04.210 --> 00:14:04.220 align:start position:0%
care about most right these are the edge
 

00:14:04.220 --> 00:14:06.730 align:start position:0%
care about most right these are the edge
cases<00:14:04.639><c> and</c><00:14:04.970><c> driving</c><00:14:05.389><c> these</c><00:14:06.050><c> are</c><00:14:06.230><c> the</c><00:14:06.350><c> cases</c>

00:14:06.730 --> 00:14:06.740 align:start position:0%
cases and driving these are the cases
 

00:14:06.740 --> 00:14:09.340 align:start position:0%
cases and driving these are the cases
that<00:14:06.769><c> we</c><00:14:07.220><c> don't</c><00:14:07.490><c> have</c><00:14:07.730><c> met</c><00:14:08.089><c> many</c><00:14:08.480><c> or</c><00:14:08.720><c> a</c><00:14:08.779><c> lot</c><00:14:09.199><c> of</c>

00:14:09.340 --> 00:14:09.350 align:start position:0%
that we don't have met many or a lot of
 

00:14:09.350 --> 00:14:12.489 align:start position:0%
that we don't have met many or a lot of
data<00:14:09.680><c> that</c><00:14:10.040><c> was</c><00:14:10.790><c> collected</c><00:14:11.089><c> and</c><00:14:11.660><c> these</c><00:14:12.350><c> are</c>

00:14:12.489 --> 00:14:12.499 align:start position:0%
data that was collected and these are
 

00:14:12.499 --> 00:14:15.720 align:start position:0%
data that was collected and these are
usually<00:14:12.680><c> the</c><00:14:12.860><c> cases</c><00:14:13.370><c> where</c><00:14:13.749><c> safety</c><00:14:14.749><c> critical</c>

00:14:15.720 --> 00:14:15.730 align:start position:0%
usually the cases where safety critical
 

00:14:15.730 --> 00:14:20.110 align:start position:0%
usually the cases where safety critical
applications<00:14:16.730><c> are</c><00:14:18.189><c> like</c><00:14:19.189><c> our</c><00:14:19.339><c> most</c><00:14:19.550><c> important</c>

00:14:20.110 --> 00:14:20.120 align:start position:0%
applications are like our most important
 

00:14:20.120 --> 00:14:22.329 align:start position:0%
applications are like our most important
right<00:14:20.749><c> so</c><00:14:21.110><c> we</c><00:14:21.259><c> need</c><00:14:21.439><c> to</c><00:14:21.559><c> be</c><00:14:21.680><c> able</c><00:14:21.769><c> to</c><00:14:21.949><c> make</c><00:14:22.220><c> sure</c>

00:14:22.329 --> 00:14:22.339 align:start position:0%
right so we need to be able to make sure
 

00:14:22.339 --> 00:14:23.949 align:start position:0%
right so we need to be able to make sure
when<00:14:22.550><c> we</c><00:14:22.699><c> sample</c><00:14:23.209><c> the</c><00:14:23.300><c> neural</c><00:14:23.540><c> network</c><00:14:23.779><c> from</c>

00:14:23.949 --> 00:14:23.959 align:start position:0%
when we sample the neural network from
 

00:14:23.959 --> 00:14:26.949 align:start position:0%
when we sample the neural network from
these<00:14:24.139><c> locations</c><00:14:24.529><c> are</c><00:14:25.269><c> we</c><00:14:26.269><c> able</c><00:14:26.449><c> to</c><00:14:26.600><c> know</c><00:14:26.930><c> that</c>

00:14:26.949 --> 00:14:26.959 align:start position:0%
these locations are we able to know that
 

00:14:26.959 --> 00:14:28.749 align:start position:0%
these locations are we able to know that
the<00:14:27.290><c> neural</c><00:14:27.529><c> network</c><00:14:27.829><c> are</c><00:14:28.220><c> we</c><00:14:28.339><c> able</c><00:14:28.459><c> to</c><00:14:28.610><c> get</c>

00:14:28.749 --> 00:14:28.759 align:start position:0%
the neural network are we able to get
 

00:14:28.759 --> 00:14:30.249 align:start position:0%
the neural network are we able to get
feedback<00:14:29.000><c> from</c><00:14:29.209><c> the</c><00:14:29.480><c> neural</c><00:14:29.689><c> network</c><00:14:29.959><c> that</c><00:14:30.139><c> it</c>

00:14:30.249 --> 00:14:30.259 align:start position:0%
feedback from the neural network that it
 

00:14:30.259 --> 00:14:31.329 align:start position:0%
feedback from the neural network that it
actually<00:14:30.529><c> doesn't</c><00:14:30.709><c> know</c><00:14:30.920><c> what</c><00:14:31.069><c> it's</c><00:14:31.189><c> talking</c>

00:14:31.329 --> 00:14:31.339 align:start position:0%
actually doesn't know what it's talking
 

00:14:31.339 --> 00:14:35.889 align:start position:0%
actually doesn't know what it's talking
about<00:14:33.730><c> so</c><00:14:34.730><c> this</c><00:14:34.819><c> notion</c><00:14:35.059><c> leads</c><00:14:35.389><c> nicely</c><00:14:35.600><c> into</c>

00:14:35.889 --> 00:14:35.899 align:start position:0%
about so this notion leads nicely into
 

00:14:35.899 --> 00:14:38.379 align:start position:0%
about so this notion leads nicely into
the<00:14:36.230><c> idea</c><00:14:37.009><c> of</c><00:14:37.160><c> what</c><00:14:37.309><c> is</c><00:14:37.430><c> known</c><00:14:37.639><c> as</c><00:14:37.819><c> advertised</c>

00:14:38.379 --> 00:14:38.389 align:start position:0%
the idea of what is known as advertised
 

00:14:38.389 --> 00:14:41.679 align:start position:0%
the idea of what is known as advertised
adversarial<00:14:39.199><c> attacks</c><00:14:39.850><c> where</c><00:14:40.850><c> I</c><00:14:41.180><c> can</c><00:14:41.449><c> give</c><00:14:41.569><c> you</c>

00:14:41.679 --> 00:14:41.689 align:start position:0%
adversarial attacks where I can give you
 

00:14:41.689 --> 00:14:43.629 align:start position:0%
adversarial attacks where I can give you
directly<00:14:42.230><c> and</c><00:14:42.350><c> give</c><00:14:42.559><c> and</c><00:14:42.829><c> neural</c><00:14:43.069><c> network</c><00:14:43.370><c> to</c>

00:14:43.629 --> 00:14:43.639 align:start position:0%
directly and give and neural network to
 

00:14:43.639 --> 00:14:46.059 align:start position:0%
directly and give and neural network to
images<00:14:44.059><c> like</c><00:14:44.300><c> on</c><00:14:44.420><c> the</c><00:14:44.540><c> left</c><00:14:44.779><c> like</c><00:14:45.680><c> this</c><00:14:45.889><c> one</c>

00:14:46.059 --> 00:14:46.069 align:start position:0%
images like on the left like this one
 

00:14:46.069 --> 00:14:48.069 align:start position:0%
images like on the left like this one
and<00:14:46.309><c> on</c><00:14:46.399><c> the</c><00:14:46.430><c> right</c><00:14:46.759><c> an</c><00:14:47.000><c> adversarial</c><00:14:47.779><c> image</c>

00:14:48.069 --> 00:14:48.079 align:start position:0%
and on the right an adversarial image
 

00:14:48.079 --> 00:14:50.549 align:start position:0%
and on the right an adversarial image
that<00:14:48.860><c> to</c><00:14:49.040><c> a</c><00:14:49.069><c> human</c><00:14:49.430><c> look</c><00:14:49.610><c> exactly</c><00:14:49.970><c> the</c><00:14:50.240><c> same</c>

00:14:50.549 --> 00:14:50.559 align:start position:0%
that to a human look exactly the same
 

00:14:50.559 --> 00:14:53.650 align:start position:0%
that to a human look exactly the same
but<00:14:51.559><c> to</c><00:14:51.740><c> the</c><00:14:51.860><c> networks</c><00:14:52.189><c> they're</c><00:14:52.660><c> incorrectly</c>

00:14:53.650 --> 00:14:53.660 align:start position:0%
but to the networks they're incorrectly
 

00:14:53.660 --> 00:14:56.980 align:start position:0%
but to the networks they're incorrectly
classified<00:14:54.430><c> 100%</c><00:14:55.430><c> of</c><00:14:55.550><c> the</c><00:14:55.610><c> time</c><00:14:55.819><c> so</c><00:14:56.660><c> the</c><00:14:56.779><c> image</c>

00:14:56.980 --> 00:14:56.990 align:start position:0%
classified 100% of the time so the image
 

00:14:56.990 --> 00:14:58.329 align:start position:0%
classified 100% of the time so the image
on<00:14:57.110><c> the</c><00:14:57.139><c> right</c><00:14:57.230><c> shows</c><00:14:57.379><c> an</c><00:14:57.680><c> example</c><00:14:58.040><c> of</c><00:14:58.129><c> a</c>

00:14:58.329 --> 00:14:58.339 align:start position:0%
on the right shows an example of a
 

00:14:58.339 --> 00:15:00.220 align:start position:0%
on the right shows an example of a
temple<00:14:59.000><c> which</c><00:14:59.300><c> when</c><00:14:59.509><c> I</c><00:14:59.540><c> feed</c><00:14:59.779><c> to</c><00:14:59.930><c> a</c><00:14:59.959><c> neural</c>

00:15:00.220 --> 00:15:00.230 align:start position:0%
temple which when I feed to a neural
 

00:15:00.230 --> 00:15:01.960 align:start position:0%
temple which when I feed to a neural
network<00:15:00.410><c> it</c><00:15:00.589><c> gives</c><00:15:00.740><c> me</c><00:15:00.949><c> back</c><00:15:00.980><c> label</c><00:15:01.790><c> of</c><00:15:01.879><c> a</c>

00:15:01.960 --> 00:15:01.970 align:start position:0%
network it gives me back label of a
 

00:15:01.970 --> 00:15:05.379 align:start position:0%
network it gives me back label of a
temple<00:15:02.949><c> but</c><00:15:03.949><c> when</c><00:15:04.069><c> I</c><00:15:04.100><c> apply</c><00:15:04.459><c> some</c><00:15:04.490><c> adversarial</c>

00:15:05.379 --> 00:15:05.389 align:start position:0%
temple but when I apply some adversarial
 

00:15:05.389 --> 00:15:08.259 align:start position:0%
temple but when I apply some adversarial
noise<00:15:06.279><c> it</c><00:15:07.279><c> classifies</c><00:15:07.730><c> this</c><00:15:07.879><c> image</c>

00:15:08.259 --> 00:15:08.269 align:start position:0%
noise it classifies this image
 

00:15:08.269 --> 00:15:13.900 align:start position:0%
noise it classifies this image
incorrectly<00:15:08.839><c> as</c><00:15:09.139><c> an</c><00:15:09.620><c> ostrich</c><00:15:12.639><c> so</c><00:15:13.639><c> for</c><00:15:13.819><c> this</c>

00:15:13.900 --> 00:15:13.910 align:start position:0%
incorrectly as an ostrich so for this
 

00:15:13.910 --> 00:15:15.610 align:start position:0%
incorrectly as an ostrich so for this
I'd<00:15:14.089><c> like</c><00:15:14.209><c> to</c><00:15:14.329><c> focus</c><00:15:14.540><c> on</c><00:15:14.899><c> this</c><00:15:15.350><c> piece</c>

00:15:15.610 --> 00:15:15.620 align:start position:0%
I'd like to focus on this piece
 

00:15:15.620 --> 00:15:17.350 align:start position:0%
I'd like to focus on this piece
specifically<00:15:16.429><c> so</c><00:15:16.699><c> to</c><00:15:16.759><c> understand</c><00:15:17.269><c> the</c>

00:15:17.350 --> 00:15:17.360 align:start position:0%
specifically so to understand the
 

00:15:17.360 --> 00:15:18.850 align:start position:0%
specifically so to understand the
limitations<00:15:17.720><c> of</c><00:15:17.990><c> neural</c><00:15:18.259><c> networks</c><00:15:18.559><c> the</c><00:15:18.679><c> first</c>

00:15:18.850 --> 00:15:18.860 align:start position:0%
limitations of neural networks the first
 

00:15:18.860 --> 00:15:19.809 align:start position:0%
limitations of neural networks the first
thing<00:15:19.009><c> we</c><00:15:19.100><c> have</c><00:15:19.189><c> to</c><00:15:19.249><c> do</c><00:15:19.429><c> is</c><00:15:19.550><c> actually</c>

00:15:19.809 --> 00:15:19.819 align:start position:0%
thing we have to do is actually
 

00:15:19.819 --> 00:15:22.379 align:start position:0%
thing we have to do is actually
understand<00:15:20.240><c> how</c><00:15:20.509><c> we</c><00:15:20.990><c> can</c><00:15:21.230><c> break</c><00:15:21.439><c> them</c><00:15:21.649><c> and</c>

00:15:22.379 --> 00:15:22.389 align:start position:0%
understand how we can break them and
 

00:15:22.389 --> 00:15:26.220 align:start position:0%
understand how we can break them and
this<00:15:23.389><c> perturb</c><00:15:23.899><c> noise</c><00:15:24.230><c> is</c><00:15:24.620><c> actually</c><00:15:24.769><c> very</c>

00:15:26.220 --> 00:15:26.230 align:start position:0%
this perturb noise is actually very
 

00:15:26.230 --> 00:15:28.299 align:start position:0%
this perturb noise is actually very
intelligently<00:15:27.230><c> designed</c><00:15:27.709><c> so</c><00:15:27.920><c> this</c><00:15:28.040><c> is</c><00:15:28.160><c> not</c>

00:15:28.299 --> 00:15:28.309 align:start position:0%
intelligently designed so this is not
 

00:15:28.309 --> 00:15:30.369 align:start position:0%
intelligently designed so this is not
just<00:15:28.519><c> random</c><00:15:28.939><c> noise</c><00:15:29.120><c> but</c><00:15:30.019><c> we're</c><00:15:30.199><c> actually</c>

00:15:30.369 --> 00:15:30.379 align:start position:0%
just random noise but we're actually
 

00:15:30.379 --> 00:15:31.749 align:start position:0%
just random noise but we're actually
modifying<00:15:31.220><c> pics</c>

00:15:31.749 --> 00:15:31.759 align:start position:0%
modifying pics
 

00:15:31.759 --> 00:15:34.449 align:start position:0%
modifying pics
in<00:15:31.970><c> specific</c><00:15:32.449><c> locations</c><00:15:33.290><c> to</c><00:15:33.889><c> maximally</c>

00:15:34.449 --> 00:15:34.459 align:start position:0%
in specific locations to maximally
 

00:15:34.459 --> 00:15:37.419 align:start position:0%
in specific locations to maximally
change<00:15:34.910><c> or</c><00:15:35.209><c> mess</c><00:15:35.899><c> up</c><00:15:36.139><c> our</c><00:15:36.319><c> output</c><00:15:36.949><c> prediction</c>

00:15:37.419 --> 00:15:37.429 align:start position:0%
change or mess up our output prediction
 

00:15:37.429 --> 00:15:39.309 align:start position:0%
change or mess up our output prediction
so<00:15:37.819><c> we</c><00:15:37.910><c> want</c><00:15:38.119><c> to</c><00:15:38.209><c> modify</c><00:15:38.480><c> the</c><00:15:38.629><c> pixels</c><00:15:39.049><c> in</c><00:15:39.169><c> such</c>

00:15:39.309 --> 00:15:39.319 align:start position:0%
so we want to modify the pixels in such
 

00:15:39.319 --> 00:15:41.829 align:start position:0%
so we want to modify the pixels in such
a<00:15:39.350><c> way</c><00:15:39.589><c> that</c><00:15:39.829><c> we're</c><00:15:40.339><c> decreasing</c><00:15:41.029><c> our</c><00:15:41.419><c> accuracy</c>

00:15:41.829 --> 00:15:41.839 align:start position:0%
a way that we're decreasing our accuracy
 

00:15:41.839 --> 00:15:44.319 align:start position:0%
a way that we're decreasing our accuracy
as<00:15:42.139><c> much</c><00:15:42.470><c> as</c><00:15:42.619><c> possible</c><00:15:42.829><c> and</c><00:15:43.339><c> if</c><00:15:43.999><c> you</c><00:15:44.119><c> remember</c>

00:15:44.319 --> 00:15:44.329 align:start position:0%
as much as possible and if you remember
 

00:15:44.329 --> 00:15:45.699 align:start position:0%
as much as possible and if you remember
back<00:15:44.509><c> to</c><00:15:44.689><c> how</c><00:15:44.989><c> we</c><00:15:45.019><c> actually</c><00:15:45.259><c> trained</c><00:15:45.589><c> our</c>

00:15:45.699 --> 00:15:45.709 align:start position:0%
back to how we actually trained our
 

00:15:45.709 --> 00:15:47.259 align:start position:0%
back to how we actually trained our
neural<00:15:45.980><c> networks</c><00:15:46.309><c> this</c><00:15:46.489><c> might</c><00:15:46.669><c> sound</c><00:15:46.850><c> very</c>

00:15:47.259 --> 00:15:47.269 align:start position:0%
neural networks this might sound very
 

00:15:47.269 --> 00:15:50.319 align:start position:0%
neural networks this might sound very
similar<00:15:47.829><c> so</c><00:15:48.829><c> if</c><00:15:49.040><c> you</c><00:15:49.160><c> remember</c><00:15:49.339><c> training</c><00:15:50.239><c> and</c>

00:15:50.319 --> 00:15:50.329 align:start position:0%
similar so if you remember training and
 

00:15:50.329 --> 00:15:52.419 align:start position:0%
similar so if you remember training and
neural<00:15:50.509><c> network</c><00:15:50.779><c> is</c><00:15:50.989><c> simply</c><00:15:51.379><c> optimizing</c><00:15:51.829><c> over</c>

00:15:52.419 --> 00:15:52.429 align:start position:0%
neural network is simply optimizing over
 

00:15:52.429 --> 00:15:55.329 align:start position:0%
neural network is simply optimizing over
our<00:15:52.549><c> weights</c><00:15:52.819><c> theta</c><00:15:53.739><c> so</c><00:15:54.739><c> to</c><00:15:54.799><c> do</c><00:15:55.009><c> this</c><00:15:55.160><c> we</c>

00:15:55.329 --> 00:15:55.339 align:start position:0%
our weights theta so to do this we
 

00:15:55.339 --> 00:15:56.979 align:start position:0%
our weights theta so to do this we
simply<00:15:55.730><c> compute</c><00:15:55.879><c> the</c><00:15:56.149><c> gradient</c><00:15:56.600><c> of</c><00:15:56.720><c> theta</c>

00:15:56.979 --> 00:15:56.989 align:start position:0%
simply compute the gradient of theta
 

00:15:56.989 --> 00:15:59.439 align:start position:0%
simply compute the gradient of theta
with<00:15:57.230><c> respect</c><00:15:57.259><c> to</c><00:15:58.160><c> our</c><00:15:58.730><c> loss</c><00:15:58.910><c> function</c><00:15:59.329><c> with</c>

00:15:59.439 --> 00:15:59.449 align:start position:0%
with respect to our loss function with
 

00:15:59.449 --> 00:16:02.049 align:start position:0%
with respect to our loss function with
respect<00:15:59.899><c> to</c><00:15:59.989><c> theta</c><00:16:00.169><c> and</c><00:16:00.589><c> we</c><00:16:01.309><c> simply</c><00:16:01.489><c> perturb</c>

00:16:02.049 --> 00:16:02.059 align:start position:0%
respect to theta and we simply perturb
 

00:16:02.059 --> 00:16:04.329 align:start position:0%
respect to theta and we simply perturb
our<00:16:02.239><c> weights</c><00:16:02.480><c> in</c><00:16:02.809><c> the</c><00:16:03.319><c> direction</c><00:16:03.619><c> that</c><00:16:04.220><c> will</c>

00:16:04.329 --> 00:16:04.339 align:start position:0%
our weights in the direction that will
 

00:16:04.339 --> 00:16:08.739 align:start position:0%
our weights in the direction that will
minimize<00:16:04.579><c> our</c><00:16:05.029><c> loss</c><00:16:06.669><c> now</c><00:16:07.669><c> also</c><00:16:07.910><c> remember</c><00:16:08.089><c> that</c>

00:16:08.739 --> 00:16:08.749 align:start position:0%
minimize our loss now also remember that
 

00:16:08.749 --> 00:16:10.689 align:start position:0%
minimize our loss now also remember that
when<00:16:09.139><c> we</c><00:16:09.290><c> do</c><00:16:09.499><c> this</c><00:16:09.649><c> we're</c><00:16:09.889><c> perturbing</c><00:16:10.429><c> theta</c>

00:16:10.689 --> 00:16:10.699 align:start position:0%
when we do this we're perturbing theta
 

00:16:10.699 --> 00:16:13.090 align:start position:0%
when we do this we're perturbing theta
but<00:16:11.029><c> we're</c><00:16:11.179><c> fixing</c><00:16:11.660><c> our</c><00:16:11.809><c> X</c><00:16:11.989><c> and</c><00:16:12.169><c> our</c><00:16:12.259><c> Y</c><00:16:12.319><c> this</c><00:16:12.949><c> is</c>

00:16:13.090 --> 00:16:13.100 align:start position:0%
but we're fixing our X and our Y this is
 

00:16:13.100 --> 00:16:14.889 align:start position:0%
but we're fixing our X and our Y this is
our<00:16:13.220><c> training</c><00:16:13.519><c> label</c><00:16:13.999><c> our</c><00:16:14.149><c> training</c><00:16:14.509><c> data</c><00:16:14.689><c> and</c>

00:16:14.889 --> 00:16:14.899 align:start position:0%
our training label our training data and
 

00:16:14.899 --> 00:16:17.289 align:start position:0%
our training label our training data and
our<00:16:14.989><c> training</c><00:16:15.169><c> labels</c><00:16:15.649><c> now</c><00:16:16.519><c> for</c><00:16:16.730><c> adversarial</c>

00:16:17.289 --> 00:16:17.299 align:start position:0%
our training labels now for adversarial
 

00:16:17.299 --> 00:16:18.220 align:start position:0%
our training labels now for adversarial
examples

00:16:18.220 --> 00:16:18.230 align:start position:0%
examples
 

00:16:18.230 --> 00:16:20.379 align:start position:0%
examples
we're<00:16:18.919><c> just</c><00:16:19.160><c> shuffling</c><00:16:19.759><c> the</c><00:16:19.939><c> variables</c><00:16:20.329><c> a</c>

00:16:20.379 --> 00:16:20.389 align:start position:0%
we're just shuffling the variables a
 

00:16:20.389 --> 00:16:22.239 align:start position:0%
we're just shuffling the variables a
little<00:16:20.600><c> bit</c><00:16:20.779><c> so</c><00:16:20.989><c> now</c><00:16:21.019><c> we</c><00:16:21.679><c> want</c><00:16:21.889><c> to</c><00:16:21.949><c> optimize</c>

00:16:22.239 --> 00:16:22.249 align:start position:0%
little bit so now we want to optimize
 

00:16:22.249 --> 00:16:24.429 align:start position:0%
little bit so now we want to optimize
over<00:16:22.699><c> the</c><00:16:22.790><c> image</c><00:16:23.149><c> itself</c><00:16:23.540><c> not</c><00:16:23.869><c> the</c><00:16:24.019><c> weight</c><00:16:24.169><c> so</c>

00:16:24.429 --> 00:16:24.439 align:start position:0%
over the image itself not the weight so
 

00:16:24.439 --> 00:16:27.879 align:start position:0%
over the image itself not the weight so
we<00:16:24.589><c> fix</c><00:16:24.859><c> the</c><00:16:25.100><c> weights</c><00:16:25.309><c> and</c><00:16:25.660><c> the</c><00:16:26.660><c> target</c><00:16:27.559><c> label</c>

00:16:27.879 --> 00:16:27.889 align:start position:0%
we fix the weights and the target label
 

00:16:27.889 --> 00:16:31.059 align:start position:0%
we fix the weights and the target label
itself<00:16:28.279><c> and</c><00:16:28.660><c> we</c><00:16:29.660><c> optimize</c><00:16:30.139><c> over</c><00:16:30.319><c> the</c><00:16:30.499><c> image</c><00:16:30.829><c> X</c>

00:16:31.059 --> 00:16:31.069 align:start position:0%
itself and we optimize over the image X
 

00:16:31.069 --> 00:16:33.159 align:start position:0%
itself and we optimize over the image X
we<00:16:31.759><c> want</c><00:16:31.939><c> to</c><00:16:32.029><c> make</c><00:16:32.149><c> small</c><00:16:32.419><c> changes</c><00:16:32.449><c> to</c><00:16:33.019><c> that</c>

00:16:33.159 --> 00:16:33.169 align:start position:0%
we want to make small changes to that
 

00:16:33.169 --> 00:16:35.739 align:start position:0%
we want to make small changes to that
image<00:16:33.470><c> X</c><00:16:33.739><c> such</c><00:16:34.489><c> that</c><00:16:34.519><c> we</c><00:16:34.790><c> increase</c><00:16:35.329><c> our</c><00:16:35.540><c> loss</c>

00:16:35.739 --> 00:16:35.749 align:start position:0%
image X such that we increase our loss
 

00:16:35.749 --> 00:16:37.569 align:start position:0%
image X such that we increase our loss
as<00:16:36.049><c> much</c><00:16:36.350><c> as</c><00:16:36.499><c> possible</c><00:16:36.679><c> and</c><00:16:37.069><c> we</c><00:16:37.189><c> want</c><00:16:37.369><c> to</c><00:16:37.429><c> go</c><00:16:37.519><c> in</c>

00:16:37.569 --> 00:16:37.579 align:start position:0%
as much as possible and we want to go in
 

00:16:37.579 --> 00:16:39.569 align:start position:0%
as much as possible and we want to go in
the<00:16:37.669><c> opposite</c><00:16:37.970><c> direction</c><00:16:38.029><c> of</c><00:16:38.419><c> training</c><00:16:38.749><c> now</c>

00:16:39.569 --> 00:16:39.579 align:start position:0%
the opposite direction of training now
 

00:16:39.579 --> 00:16:41.590 align:start position:0%
the opposite direction of training now
and<00:16:40.579><c> these</c><00:16:40.939><c> are</c><00:16:41.089><c> just</c><00:16:41.179><c> some</c><00:16:41.359><c> of</c><00:16:41.509><c> the</c>

00:16:41.590 --> 00:16:41.600 align:start position:0%
and these are just some of the
 

00:16:41.600 --> 00:16:44.859 align:start position:0%
and these are just some of the
limitations<00:16:42.199><c> of</c><00:16:42.559><c> neural</c><00:16:43.069><c> networks</c><00:16:43.429><c> and</c><00:16:43.869><c> for</c>

00:16:44.859 --> 00:16:44.869 align:start position:0%
limitations of neural networks and for
 

00:16:44.869 --> 00:16:46.299 align:start position:0%
limitations of neural networks and for
the<00:16:44.959><c> remainder</c><00:16:45.439><c> of</c><00:16:45.559><c> this</c><00:16:45.739><c> class</c><00:16:45.949><c> I</c><00:16:46.100><c> want</c><00:16:46.189><c> to</c>

00:16:46.299 --> 00:16:46.309 align:start position:0%
the remainder of this class I want to
 

00:16:46.309 --> 00:16:48.099 align:start position:0%
the remainder of this class I want to
focus<00:16:46.459><c> on</c><00:16:46.759><c> some</c><00:16:46.970><c> of</c><00:16:46.999><c> the</c><00:16:47.209><c> really</c><00:16:47.749><c> really</c>

00:16:48.099 --> 00:16:48.109 align:start position:0%
focus on some of the really really
 

00:16:48.109 --> 00:16:49.809 align:start position:0%
focus on some of the really really
exciting<00:16:48.559><c> new</c><00:16:48.829><c> frontiers</c><00:16:49.309><c> of</c><00:16:49.519><c> deep</c><00:16:49.669><c> learning</c>

00:16:49.809 --> 00:16:49.819 align:start position:0%
exciting new frontiers of deep learning
 

00:16:49.819 --> 00:16:51.720 align:start position:0%
exciting new frontiers of deep learning
that<00:16:50.089><c> focus</c><00:16:50.449><c> on</c><00:16:50.600><c> just</c><00:16:50.749><c> two</c><00:16:50.989><c> of</c><00:16:51.109><c> these</c>

00:16:51.720 --> 00:16:51.730 align:start position:0%
that focus on just two of these
 

00:16:51.730 --> 00:16:54.039 align:start position:0%
that focus on just two of these
specifically<00:16:52.730><c> I</c><00:16:53.059><c> want</c><00:16:53.449><c> to</c><00:16:53.509><c> focus</c><00:16:53.629><c> on</c><00:16:53.929><c> the</c>

00:16:54.039 --> 00:16:54.049 align:start position:0%
specifically I want to focus on the
 

00:16:54.049 --> 00:16:55.960 align:start position:0%
specifically I want to focus on the
notion<00:16:54.230><c> of</c><00:16:54.439><c> understanding</c><00:16:54.730><c> uncertainty</c><00:16:55.730><c> and</c>

00:16:55.960 --> 00:16:55.970 align:start position:0%
notion of understanding uncertainty and
 

00:16:55.970 --> 00:16:57.599 align:start position:0%
notion of understanding uncertainty and
deep<00:16:56.149><c> neural</c><00:16:56.269><c> networks</c><00:16:56.660><c> and</c><00:16:56.839><c> understanding</c>

00:16:57.599 --> 00:16:57.609 align:start position:0%
deep neural networks and understanding
 

00:16:57.609 --> 00:17:00.909 align:start position:0%
deep neural networks and understanding
when<00:16:58.609><c> our</c><00:16:58.879><c> model</c><00:16:59.269><c> doesn't</c><00:16:59.539><c> know</c><00:16:59.869><c> what</c><00:17:00.649><c> it</c><00:17:00.799><c> was</c>

00:17:00.909 --> 00:17:00.919 align:start position:0%
when our model doesn't know what it was
 

00:17:00.919 --> 00:17:02.859 align:start position:0%
when our model doesn't know what it was
trained<00:17:01.220><c> to</c><00:17:01.369><c> know</c><00:17:01.519><c> maybe</c><00:17:02.149><c> because</c><00:17:02.449><c> it</c><00:17:02.569><c> wasn't</c>

00:17:02.859 --> 00:17:02.869 align:start position:0%
trained to know maybe because it wasn't
 

00:17:02.869 --> 00:17:04.840 align:start position:0%
trained to know maybe because it wasn't
it<00:17:03.139><c> didn't</c><00:17:03.350><c> receive</c><00:17:03.619><c> enough</c><00:17:03.649><c> training</c><00:17:04.519><c> data</c>

00:17:04.840 --> 00:17:04.850 align:start position:0%
it didn't receive enough training data
 

00:17:04.850 --> 00:17:08.039 align:start position:0%
it didn't receive enough training data
to<00:17:05.240><c> support</c><00:17:05.419><c> that</c><00:17:05.809><c> hypothesis</c><00:17:06.789><c> and</c>

00:17:08.039 --> 00:17:08.049 align:start position:0%
to support that hypothesis and
 

00:17:08.049 --> 00:17:10.389 align:start position:0%
to support that hypothesis and
furthermore<00:17:09.049><c> I</c><00:17:09.110><c> wanted</c><00:17:09.409><c> to</c><00:17:09.500><c> focus</c><00:17:09.679><c> on</c><00:17:10.010><c> this</c>

00:17:10.389 --> 00:17:10.399 align:start position:0%
furthermore I wanted to focus on this
 

00:17:10.399 --> 00:17:12.819 align:start position:0%
furthermore I wanted to focus on this
notion<00:17:10.610><c> of</c><00:17:10.970><c> learning</c><00:17:11.659><c> how</c><00:17:12.019><c> to</c><00:17:12.049><c> learn</c><00:17:12.350><c> models</c>

00:17:12.819 --> 00:17:12.829 align:start position:0%
notion of learning how to learn models
 

00:17:12.829 --> 00:17:15.279 align:start position:0%
notion of learning how to learn models
because<00:17:13.610><c> optimization</c><00:17:14.510><c> of</c><00:17:14.659><c> neural</c><00:17:14.990><c> networks</c>

00:17:15.279 --> 00:17:15.289 align:start position:0%
because optimization of neural networks
 

00:17:15.289 --> 00:17:18.429 align:start position:0%
because optimization of neural networks
is<00:17:15.470><c> extremely</c><00:17:16.269><c> difficult</c><00:17:17.269><c> it's</c><00:17:17.899><c> extremely</c>

00:17:18.429 --> 00:17:18.439 align:start position:0%
is extremely difficult it's extremely
 

00:17:18.439 --> 00:17:20.470 align:start position:0%
is extremely difficult it's extremely
limited<00:17:18.889><c> in</c><00:17:19.010><c> its</c><00:17:19.100><c> current</c><00:17:19.459><c> nature</c><00:17:20.179><c> because</c>

00:17:20.470 --> 00:17:20.480 align:start position:0%
limited in its current nature because
 

00:17:20.480 --> 00:17:21.939 align:start position:0%
limited in its current nature because
they're<00:17:20.720><c> optimized</c><00:17:21.199><c> just</c><00:17:21.470><c> to</c><00:17:21.559><c> do</c><00:17:21.649><c> a</c><00:17:21.679><c> single</c>

00:17:21.939 --> 00:17:21.949 align:start position:0%
they're optimized just to do a single
 

00:17:21.949 --> 00:17:23.559 align:start position:0%
they're optimized just to do a single
task<00:17:22.250><c> so</c><00:17:22.399><c> what</c><00:17:22.579><c> we</c><00:17:22.699><c> really</c><00:17:23.000><c> want</c><00:17:23.149><c> to</c><00:17:23.209><c> do</c><00:17:23.419><c> is</c>

00:17:23.559 --> 00:17:23.569 align:start position:0%
task so what we really want to do is
 

00:17:23.569 --> 00:17:25.539 align:start position:0%
task so what we really want to do is
create<00:17:23.839><c> neural</c><00:17:24.199><c> networks</c><00:17:24.500><c> that</c><00:17:25.189><c> are</c><00:17:25.220><c> capable</c>

00:17:25.539 --> 00:17:25.549 align:start position:0%
create neural networks that are capable
 

00:17:25.549 --> 00:17:29.169 align:start position:0%
create neural networks that are capable
of<00:17:25.959><c> performing</c><00:17:26.959><c> not</c><00:17:27.439><c> one</c><00:17:27.649><c> task</c><00:17:27.919><c> but</c><00:17:28.580><c> a</c><00:17:28.610><c> set</c><00:17:29.000><c> of</c>

00:17:29.169 --> 00:17:29.179 align:start position:0%
of performing not one task but a set of
 

00:17:29.179 --> 00:17:31.659 align:start position:0%
of performing not one task but a set of
sequences<00:17:29.570><c> of</c><00:17:30.200><c> tasks</c><00:17:30.769><c> that</c><00:17:30.950><c> are</c><00:17:31.519><c> maybe</c>

00:17:31.659 --> 00:17:31.669 align:start position:0%
sequences of tasks that are maybe
 

00:17:31.669 --> 00:17:35.950 align:start position:0%
sequences of tasks that are maybe
dependent<00:17:32.330><c> in</c><00:17:32.480><c> some</c><00:17:32.690><c> fashion</c><00:17:33.139><c> so</c><00:17:34.720><c> let's</c><00:17:35.720><c> start</c>

00:17:35.950 --> 00:17:35.960 align:start position:0%
dependent in some fashion so let's start
 

00:17:35.960 --> 00:17:37.930 align:start position:0%
dependent in some fashion so let's start
with<00:17:36.080><c> this</c><00:17:36.260><c> notion</c><00:17:36.500><c> of</c><00:17:36.710><c> uncertainty</c><00:17:37.399><c> in</c><00:17:37.580><c> deep</c>

00:17:37.930 --> 00:17:37.940 align:start position:0%
with this notion of uncertainty in deep
 

00:17:37.940 --> 00:17:39.340 align:start position:0%
with this notion of uncertainty in deep
neural<00:17:38.090><c> networks</c><00:17:38.510><c> and</c><00:17:38.750><c> to</c><00:17:38.840><c> do</c><00:17:38.960><c> that</c>

00:17:39.340 --> 00:17:39.350 align:start position:0%
neural networks and to do that
 

00:17:39.350 --> 00:17:43.450 align:start position:0%
neural networks and to do that
I'd<00:17:39.440><c> like</c><00:17:39.620><c> to</c><00:17:39.740><c> introduce</c><00:17:39.919><c> this</c><00:17:40.429><c> field</c><00:17:42.460><c> called</c>

00:17:43.450 --> 00:17:43.460 align:start position:0%
I'd like to introduce this field called
 

00:17:43.460 --> 00:17:45.900 align:start position:0%
I'd like to introduce this field called
Bayesian<00:17:43.789><c> deep</c><00:17:44.120><c> learning</c>

00:17:45.900 --> 00:17:45.910 align:start position:0%
Bayesian deep learning
 

00:17:45.910 --> 00:17:48.550 align:start position:0%
Bayesian deep learning
now<00:17:46.910><c> to</c><00:17:47.510><c> understand</c><00:17:47.900><c> Bayesian</c><00:17:48.260><c> deep</c><00:17:48.410><c> learning</c>

00:17:48.550 --> 00:17:48.560 align:start position:0%
now to understand Bayesian deep learning
 

00:17:48.560 --> 00:17:51.400 align:start position:0%
now to understand Bayesian deep learning
let's<00:17:48.920><c> first</c><00:17:49.190><c> understand</c><00:17:49.820><c> why</c><00:17:50.720><c> we</c><00:17:50.960><c> even</c><00:17:51.050><c> care</c>

00:17:51.400 --> 00:17:51.410 align:start position:0%
let's first understand why we even care
 

00:17:51.410 --> 00:17:53.290 align:start position:0%
let's first understand why we even care
about<00:17:51.560><c> uncertainty</c><00:17:52.310><c> so</c><00:17:52.640><c> this</c><00:17:52.760><c> should</c><00:17:53.180><c> be</c>

00:17:53.290 --> 00:17:53.300 align:start position:0%
about uncertainty so this should be
 

00:17:53.300 --> 00:17:55.600 align:start position:0%
about uncertainty so this should be
pretty<00:17:53.510><c> obvious</c><00:17:53.800><c> but</c><00:17:54.800><c> suppose</c><00:17:55.100><c> we</c><00:17:55.130><c> were</c><00:17:55.310><c> given</c>

00:17:55.600 --> 00:17:55.610 align:start position:0%
pretty obvious but suppose we were given
 

00:17:55.610 --> 00:17:58.270 align:start position:0%
pretty obvious but suppose we were given
a<00:17:56.020><c> network</c><00:17:57.020><c> that</c><00:17:57.200><c> was</c><00:17:57.290><c> trained</c><00:17:57.680><c> to</c>

00:17:58.270 --> 00:17:58.280 align:start position:0%
a network that was trained to
 

00:17:58.280 --> 00:18:01.060 align:start position:0%
a network that was trained to
distinguish<00:17:58.820><c> between</c><00:17:58.970><c> cats</c><00:17:59.450><c> and</c><00:17:59.750><c> dogs</c><00:18:00.070><c> that</c>

00:18:01.060 --> 00:18:01.070 align:start position:0%
distinguish between cats and dogs that
 

00:18:01.070 --> 00:18:02.770 align:start position:0%
distinguish between cats and dogs that
input<00:18:01.310><c> were</c><00:18:01.640><c> given</c><00:18:01.970><c> a</c><00:18:02.120><c> lot</c><00:18:02.360><c> of</c><00:18:02.480><c> tests</c>

00:18:02.770 --> 00:18:02.780 align:start position:0%
input were given a lot of tests
 

00:18:02.780 --> 00:18:05.380 align:start position:0%
input were given a lot of tests
imitating<00:18:03.680><c> images</c><00:18:04.100><c> of</c><00:18:04.310><c> cats</c><00:18:04.700><c> and</c><00:18:04.880><c> dogs</c><00:18:04.940><c> and</c>

00:18:05.380 --> 00:18:05.390 align:start position:0%
imitating images of cats and dogs and
 

00:18:05.390 --> 00:18:06.820 align:start position:0%
imitating images of cats and dogs and
it's<00:18:05.930><c> simply</c><00:18:06.170><c> at</c><00:18:06.320><c> the</c><00:18:06.350><c> output</c><00:18:06.710><c> we're</c>

00:18:06.820 --> 00:18:06.830 align:start position:0%
it's simply at the output we're
 

00:18:06.830 --> 00:18:09.100 align:start position:0%
it's simply at the output we're
producing<00:18:07.220><c> an</c><00:18:07.340><c> output</c><00:18:07.460><c> probability</c><00:18:08.300><c> of</c><00:18:08.480><c> being</c>

00:18:09.100 --> 00:18:09.110 align:start position:0%
producing an output probability of being
 

00:18:09.110 --> 00:18:12.970 align:start position:0%
producing an output probability of being
a<00:18:09.140><c> cat</c><00:18:09.410><c> or</c><00:18:09.620><c> a</c><00:18:09.680><c> dog</c><00:18:11.080><c> now</c><00:18:12.080><c> this</c><00:18:12.260><c> model</c><00:18:12.470><c> is</c><00:18:12.650><c> trained</c>

00:18:12.970 --> 00:18:12.980 align:start position:0%
a cat or a dog now this model is trained
 

00:18:12.980 --> 00:18:15.190 align:start position:0%
a cat or a dog now this model is trained
on<00:18:13.130><c> either</c><00:18:13.280><c> on</c><00:18:13.610><c> only</c><00:18:14.030><c> cats</c><00:18:14.510><c> or</c><00:18:14.690><c> dogs</c><00:18:14.720><c> so</c><00:18:15.020><c> if</c><00:18:15.110><c> I</c>

00:18:15.190 --> 00:18:15.200 align:start position:0%
on either on only cats or dogs so if I
 

00:18:15.200 --> 00:18:17.770 align:start position:0%
on either on only cats or dogs so if I
showed<00:18:15.410><c> another</c><00:18:15.770><c> cat</c><00:18:16.100><c> it</c><00:18:16.460><c> should</c><00:18:17.120><c> be</c><00:18:17.360><c> very</c>

00:18:17.770 --> 00:18:17.780 align:start position:0%
showed another cat it should be very
 

00:18:17.780 --> 00:18:20.320 align:start position:0%
showed another cat it should be very
confident<00:18:18.350><c> in</c><00:18:18.560><c> its</c><00:18:18.740><c> output</c><00:18:19.180><c> well</c><00:18:20.180><c> let's</c>

00:18:20.320 --> 00:18:20.330 align:start position:0%
confident in its output well let's
 

00:18:20.330 --> 00:18:22.990 align:start position:0%
confident in its output well let's
suppose<00:18:20.420><c> I</c><00:18:20.690><c> give</c><00:18:20.870><c> it</c><00:18:20.960><c> a</c><00:18:20.990><c> horse</c><00:18:21.230><c> and</c><00:18:21.640><c> I</c><00:18:22.640><c> force</c>

00:18:22.990 --> 00:18:23.000 align:start position:0%
suppose I give it a horse and I force
 

00:18:23.000 --> 00:18:24.850 align:start position:0%
suppose I give it a horse and I force
that<00:18:23.270><c> network</c><00:18:23.660><c> because</c><00:18:24.470><c> it's</c><00:18:24.620><c> the</c><00:18:24.710><c> same</c>

00:18:24.850 --> 00:18:24.860 align:start position:0%
that network because it's the same
 

00:18:24.860 --> 00:18:27.130 align:start position:0%
that network because it's the same
network<00:18:25.130><c> to</c><00:18:25.610><c> produce</c><00:18:25.790><c> an</c><00:18:26.150><c> output</c><00:18:26.600><c> of</c><00:18:26.930><c> being</c><00:18:27.080><c> a</c>

00:18:27.130 --> 00:18:27.140 align:start position:0%
network to produce an output of being a
 

00:18:27.140 --> 00:18:28.720 align:start position:0%
network to produce an output of being a
probability<00:18:27.530><c> of</c><00:18:27.650><c> a</c><00:18:27.770><c> cat</c><00:18:27.980><c> or</c><00:18:28.130><c> a</c><00:18:28.190><c> probability</c><00:18:28.610><c> of</c>

00:18:28.720 --> 00:18:28.730 align:start position:0%
probability of a cat or a probability of
 

00:18:28.730 --> 00:18:32.200 align:start position:0%
probability of a cat or a probability of
a<00:18:28.850><c> dog</c><00:18:29.380><c> now</c><00:18:30.380><c> we</c><00:18:30.890><c> know</c><00:18:31.130><c> that</c><00:18:31.210><c> these</c>

00:18:32.200 --> 00:18:32.210 align:start position:0%
a dog now we know that these
 

00:18:32.210 --> 00:18:33.640 align:start position:0%
a dog now we know that these
probabilities<00:18:32.630><c> have</c><00:18:32.960><c> to</c><00:18:33.020><c> add</c><00:18:33.140><c> up</c><00:18:33.230><c> to</c><00:18:33.350><c> 1</c>

00:18:33.640 --> 00:18:33.650 align:start position:0%
probabilities have to add up to 1
 

00:18:33.650 --> 00:18:34.570 align:start position:0%
probabilities have to add up to 1
because<00:18:33.830><c> that's</c><00:18:34.010><c> actually</c><00:18:34.280><c> the</c><00:18:34.490><c> definition</c>

00:18:34.570 --> 00:18:34.580 align:start position:0%
because that's actually the definition
 

00:18:34.580 --> 00:18:37.020 align:start position:0%
because that's actually the definition
that<00:18:35.090><c> we</c><00:18:35.300><c> constrain</c><00:18:35.660><c> our</c><00:18:35.810><c> network</c><00:18:36.140><c> to</c><00:18:36.290><c> follow</c>

00:18:37.020 --> 00:18:37.030 align:start position:0%
that we constrain our network to follow
 

00:18:37.030 --> 00:18:39.790 align:start position:0%
that we constrain our network to follow
so<00:18:38.030><c> that</c><00:18:38.150><c> means</c><00:18:38.330><c> by</c><00:18:38.510><c> definition</c><00:18:38.570><c> one</c><00:18:39.440><c> of</c><00:18:39.620><c> these</c>

00:18:39.790 --> 00:18:39.800 align:start position:0%
so that means by definition one of these
 

00:18:39.800 --> 00:18:41.890 align:start position:0%
so that means by definition one of these
categories<00:18:40.130><c> so</c><00:18:41.000><c> the</c><00:18:41.120><c> network</c><00:18:41.390><c> has</c><00:18:41.600><c> to</c><00:18:41.630><c> produce</c>

00:18:41.890 --> 00:18:41.900 align:start position:0%
categories so the network has to produce
 

00:18:41.900 --> 00:18:45.130 align:start position:0%
categories so the network has to produce
one<00:18:42.200><c> of</c><00:18:42.320><c> these</c><00:18:42.470><c> categories</c><00:18:43.420><c> so</c><00:18:44.420><c> the</c><00:18:44.750><c> notion</c><00:18:44.930><c> of</c>

00:18:45.130 --> 00:18:45.140 align:start position:0%
one of these categories so the notion of
 

00:18:45.140 --> 00:18:46.420 align:start position:0%
one of these categories so the notion of
probability<00:18:45.860><c> and</c><00:18:45.950><c> the</c><00:18:46.070><c> notion</c><00:18:46.370><c> of</c>

00:18:46.420 --> 00:18:46.430 align:start position:0%
probability and the notion of
 

00:18:46.430 --> 00:18:47.790 align:start position:0%
probability and the notion of
uncertainty<00:18:47.090><c> are</c><00:18:47.180><c> actually</c><00:18:47.450><c> very</c><00:18:47.600><c> different</c>

00:18:47.790 --> 00:18:47.800 align:start position:0%
uncertainty are actually very different
 

00:18:47.800 --> 00:18:50.440 align:start position:0%
uncertainty are actually very different
but<00:18:48.800><c> a</c><00:18:48.830><c> lot</c><00:18:49.040><c> of</c><00:18:49.070><c> deep</c><00:18:49.490><c> learning</c><00:18:49.640><c> practitioners</c>

00:18:50.440 --> 00:18:50.450 align:start position:0%
but a lot of deep learning practitioners
 

00:18:50.450 --> 00:18:53.590 align:start position:0%
but a lot of deep learning practitioners
often<00:18:50.960><c> mix</c><00:18:51.230><c> these</c><00:18:51.410><c> two</c><00:18:51.590><c> ideas</c><00:18:51.980><c> so</c><00:18:52.600><c> uncertainty</c>

00:18:53.590 --> 00:18:53.600 align:start position:0%
often mix these two ideas so uncertainty
 

00:18:53.600 --> 00:18:55.810 align:start position:0%
often mix these two ideas so uncertainty
is<00:18:53.750><c> not</c><00:18:53.780><c> probability</c><00:18:54.740><c> neural</c><00:18:55.430><c> networks</c><00:18:55.700><c> are</c>

00:18:55.810 --> 00:18:55.820 align:start position:0%
is not probability neural networks are
 

00:18:55.820 --> 00:18:58.320 align:start position:0%
is not probability neural networks are
detect<00:18:56.240><c> or</c><00:18:56.420><c> trained</c><00:18:56.810><c> to</c><00:18:56.960><c> detect</c><00:18:57.290><c> or</c><00:18:57.830><c> produce</c>

00:18:58.320 --> 00:18:58.330 align:start position:0%
detect or trained to detect or produce
 

00:18:58.330 --> 00:19:00.670 align:start position:0%
detect or trained to detect or produce
probabilities<00:18:59.330><c> at</c><00:18:59.510><c> their</c><00:18:59.720><c> output</c><00:19:00.050><c> at</c><00:19:00.380><c> their</c>

00:19:00.670 --> 00:19:00.680 align:start position:0%
probabilities at their output at their
 

00:19:00.680 --> 00:19:02.890 align:start position:0%
probabilities at their output at their
output<00:19:01.100><c> but</c><00:19:01.670><c> they're</c><00:19:01.850><c> not</c><00:19:02.090><c> trained</c><00:19:02.570><c> to</c>

00:19:02.890 --> 00:19:02.900 align:start position:0%
output but they're not trained to
 

00:19:02.900 --> 00:19:06.790 align:start position:0%
output but they're not trained to
produce<00:19:03.380><c> uncertainty</c><00:19:04.160><c> values</c><00:19:05.170><c> so</c><00:19:06.170><c> if</c><00:19:06.350><c> we</c><00:19:06.500><c> put</c>

00:19:06.790 --> 00:19:06.800 align:start position:0%
produce uncertainty values so if we put
 

00:19:06.800 --> 00:19:09.040 align:start position:0%
produce uncertainty values so if we put
this<00:19:06.920><c> horse</c><00:19:07.190><c> into</c><00:19:07.610><c> the</c><00:19:07.640><c> same</c><00:19:07.940><c> network</c><00:19:08.180><c> we'll</c>

00:19:09.040 --> 00:19:09.050 align:start position:0%
this horse into the same network we'll
 

00:19:09.050 --> 00:19:11.380 align:start position:0%
this horse into the same network we'll
get<00:19:09.230><c> a</c><00:19:09.260><c> set</c><00:19:09.620><c> of</c><00:19:09.710><c> uncertainty</c><00:19:10.160><c> bility</c><00:19:11.060><c> values</c>

00:19:11.380 --> 00:19:11.390 align:start position:0%
get a set of uncertainty bility values
 

00:19:11.390 --> 00:19:14.380 align:start position:0%
get a set of uncertainty bility values
that<00:19:11.600><c> add</c><00:19:11.720><c> up</c><00:19:11.750><c> to</c><00:19:11.900><c> 1</c><00:19:12.640><c> but</c><00:19:13.640><c> what</c><00:19:13.820><c> we</c><00:19:13.940><c> really</c><00:19:14.240><c> want</c>

00:19:14.380 --> 00:19:14.390 align:start position:0%
that add up to 1 but what we really want
 

00:19:14.390 --> 00:19:16.240 align:start position:0%
that add up to 1 but what we really want
to<00:19:14.480><c> see</c><00:19:14.720><c> is</c><00:19:14.900><c> we</c><00:19:15.320><c> want</c><00:19:15.500><c> to</c><00:19:15.590><c> see</c><00:19:15.710><c> a</c><00:19:15.740><c> very</c><00:19:16.010><c> low</c>

00:19:16.240 --> 00:19:16.250 align:start position:0%
to see is we want to see a very low
 

00:19:16.250 --> 00:19:19.150 align:start position:0%
to see is we want to see a very low
uncertainty<00:19:16.910><c> in</c><00:19:17.150><c> that</c><00:19:17.210><c> a</c><00:19:17.900><c> very</c><00:19:18.200><c> low</c><00:19:18.440><c> certainty</c>

00:19:19.150 --> 00:19:19.160 align:start position:0%
uncertainty in that a very low certainty
 

00:19:19.160 --> 00:19:22.990 align:start position:0%
uncertainty in that a very low certainty
in<00:19:19.370><c> that</c><00:19:19.430><c> prediction</c><00:19:21.400><c> and</c><00:19:22.400><c> one</c><00:19:22.610><c> possible</c><00:19:22.940><c> way</c>

00:19:22.990 --> 00:19:23.000 align:start position:0%
in that prediction and one possible way
 

00:19:23.000 --> 00:19:24.580 align:start position:0%
in that prediction and one possible way
to<00:19:23.150><c> accomplish</c><00:19:23.690><c> this</c><00:19:23.840><c> in</c><00:19:24.020><c> deep</c><00:19:24.170><c> learning</c><00:19:24.320><c> is</c>

00:19:24.580 --> 00:19:24.590 align:start position:0%
to accomplish this in deep learning is
 

00:19:24.590 --> 00:19:26.170 align:start position:0%
to accomplish this in deep learning is
through<00:19:24.770><c> the</c><00:19:24.860><c> eyes</c><00:19:25.010><c> of</c><00:19:25.430><c> Bayesian</c><00:19:26.000><c> deep</c>

00:19:26.170 --> 00:19:26.180 align:start position:0%
through the eyes of Bayesian deep
 

00:19:26.180 --> 00:19:28.330 align:start position:0%
through the eyes of Bayesian deep
learning<00:19:26.570><c> and</c><00:19:26.750><c> to</c><00:19:27.470><c> understand</c><00:19:27.890><c> this</c><00:19:28.040><c> let's</c>

00:19:28.330 --> 00:19:28.340 align:start position:0%
learning and to understand this let's
 

00:19:28.340 --> 00:19:30.340 align:start position:0%
learning and to understand this let's
briefly<00:19:28.730><c> start</c><00:19:29.150><c> by</c><00:19:29.240><c> formulating</c><00:19:29.690><c> our</c><00:19:29.990><c> problem</c>

00:19:30.340 --> 00:19:30.350 align:start position:0%
briefly start by formulating our problem
 

00:19:30.350 --> 00:19:35.560 align:start position:0%
briefly start by formulating our problem
again<00:19:31.060><c> so</c><00:19:32.060><c> first</c><00:19:32.920><c> let's</c><00:19:33.920><c> go</c><00:19:34.280><c> through</c><00:19:34.550><c> like</c><00:19:35.390><c> the</c>

00:19:35.560 --> 00:19:35.570 align:start position:0%
again so first let's go through like the
 

00:19:35.570 --> 00:19:37.110 align:start position:0%
again so first let's go through like the
variables<00:19:36.020><c> right</c><00:19:36.140><c> so</c><00:19:36.350><c> we</c><00:19:36.470><c> want</c><00:19:36.680><c> to</c>

00:19:37.110 --> 00:19:37.120 align:start position:0%
variables right so we want to
 

00:19:37.120 --> 00:19:40.720 align:start position:0%
variables right so we want to
approximate<00:19:38.140><c> this</c><00:19:39.140><c> variable</c><00:19:39.710><c> Y</c><00:19:39.860><c> or</c><00:19:40.130><c> output</c><00:19:40.490><c> Y</c>

00:19:40.720 --> 00:19:40.730 align:start position:0%
approximate this variable Y or output Y
 

00:19:40.730 --> 00:19:43.690 align:start position:0%
approximate this variable Y or output Y
given<00:19:41.210><c> some</c><00:19:41.390><c> raw</c><00:19:41.570><c> data</c><00:19:41.870><c> X</c><00:19:42.200><c> and</c><00:19:42.590><c> really</c><00:19:43.460><c> what</c><00:19:43.610><c> we</c>

00:19:43.690 --> 00:19:43.700 align:start position:0%
given some raw data X and really what we
 

00:19:43.700 --> 00:19:45.580 align:start position:0%
given some raw data X and really what we
mean<00:19:43.880><c> by</c><00:19:43.940><c> training</c><00:19:44.540><c> is</c><00:19:44.660><c> we</c><00:19:44.990><c> want</c><00:19:45.170><c> to</c><00:19:45.260><c> find</c><00:19:45.470><c> this</c>

00:19:45.580 --> 00:19:45.590 align:start position:0%
mean by training is we want to find this
 

00:19:45.590 --> 00:19:48.220 align:start position:0%
mean by training is we want to find this
functional<00:19:46.070><c> mapping</c><00:19:46.310><c> F</c><00:19:46.840><c> parameterize</c><00:19:47.840><c> by</c><00:19:47.900><c> our</c>

00:19:48.220 --> 00:19:48.230 align:start position:0%
functional mapping F parameterize by our
 

00:19:48.230 --> 00:19:50.890 align:start position:0%
functional mapping F parameterize by our
weights<00:19:48.560><c> theta</c><00:19:49.070><c> such</c><00:19:50.000><c> that</c><00:19:50.030><c> we</c><00:19:50.300><c> minimize</c><00:19:50.480><c> the</c>

00:19:50.890 --> 00:19:50.900 align:start position:0%
weights theta such that we minimize the
 

00:19:50.900 --> 00:19:53.170 align:start position:0%
weights theta such that we minimize the
loss<00:19:51.080><c> between</c><00:19:51.410><c> our</c><00:19:51.920><c> predict</c><00:19:52.310><c> examples</c><00:19:52.940><c> and</c>

00:19:53.170 --> 00:19:53.180 align:start position:0%
loss between our predict examples and
 

00:19:53.180 --> 00:19:57.850 align:start position:0%
loss between our predict examples and
our<00:19:53.360><c> true</c><00:19:53.600><c> outputs</c><00:19:54.560><c> y</c><00:19:56.290><c> so</c><00:19:57.290><c> Bayesian</c><00:19:57.680><c> neural</c>

00:19:57.850 --> 00:19:57.860 align:start position:0%
our true outputs y so Bayesian neural
 

00:19:57.860 --> 00:19:58.909 align:start position:0%
our true outputs y so Bayesian neural
networks<00:19:58.190><c> take</c><00:19:58.670><c> it</c>

00:19:58.909 --> 00:19:58.919 align:start position:0%
networks take it
 

00:19:58.919 --> 00:20:01.580 align:start position:0%
networks take it
different<00:19:59.749><c> approach</c><00:20:00.749><c> to</c><00:20:00.989><c> solve</c><00:20:01.200><c> this</c><00:20:01.379><c> problem</c>

00:20:01.580 --> 00:20:01.590 align:start position:0%
different approach to solve this problem
 

00:20:01.590 --> 00:20:05.330 align:start position:0%
different approach to solve this problem
they<00:20:02.460><c> aim</c><00:20:02.789><c> to</c><00:20:03.509><c> learn</c><00:20:03.840><c> a</c><00:20:04.049><c> posterior</c><00:20:04.590><c> over</c><00:20:05.190><c> our</c>

00:20:05.330 --> 00:20:05.340 align:start position:0%
they aim to learn a posterior over our
 

00:20:05.340 --> 00:20:08.060 align:start position:0%
they aim to learn a posterior over our
weights<00:20:05.639><c> given</c><00:20:06.330><c> the</c><00:20:06.480><c> data</c><00:20:06.629><c> so</c><00:20:07.350><c> they</c><00:20:07.499><c> attempt</c>

00:20:08.060 --> 00:20:08.070 align:start position:0%
weights given the data so they attempt
 

00:20:08.070 --> 00:20:10.430 align:start position:0%
weights given the data so they attempt
to<00:20:08.159><c> say</c><00:20:08.399><c> what</c><00:20:09.059><c> is</c><00:20:09.149><c> the</c><00:20:09.269><c> probability</c><00:20:09.720><c> that</c><00:20:10.230><c> I</c>

00:20:10.430 --> 00:20:10.440 align:start position:0%
to say what is the probability that I
 

00:20:10.440 --> 00:20:12.979 align:start position:0%
to say what is the probability that I
see<00:20:10.799><c> this</c><00:20:11.100><c> model</c><00:20:11.399><c> with</c><00:20:11.639><c> these</c><00:20:11.850><c> weights</c><00:20:12.149><c> given</c>

00:20:12.979 --> 00:20:12.989 align:start position:0%
see this model with these weights given
 

00:20:12.989 --> 00:20:14.659 align:start position:0%
see this model with these weights given
the<00:20:13.289><c> data</c><00:20:13.529><c> in</c><00:20:13.769><c> my</c><00:20:13.919><c> training</c><00:20:14.249><c> set</c>

00:20:14.659 --> 00:20:14.669 align:start position:0%
the data in my training set
 

00:20:14.669 --> 00:20:16.580 align:start position:0%
the data in my training set
now<00:20:15.659><c> it's</c><00:20:15.779><c> called</c><00:20:15.929><c> Bayesian</c><00:20:16.139><c> deep</c><00:20:16.440><c> learning</c>

00:20:16.580 --> 00:20:16.590 align:start position:0%
now it's called Bayesian deep learning
 

00:20:16.590 --> 00:20:19.099 align:start position:0%
now it's called Bayesian deep learning
because<00:20:16.980><c> we</c><00:20:17.100><c> can</c><00:20:17.249><c> simply</c><00:20:17.869><c> rewrite</c><00:20:18.869><c> this</c>

00:20:19.099 --> 00:20:19.109 align:start position:0%
because we can simply rewrite this
 

00:20:19.109 --> 00:20:25.489 align:start position:0%
because we can simply rewrite this
posterior<00:20:19.619><c> using</c><00:20:20.489><c> Bayes</c><00:20:20.669><c> rule</c><00:20:24.350><c> however</c><00:20:25.350><c> in</c>

00:20:25.489 --> 00:20:25.499 align:start position:0%
posterior using Bayes rule however in
 

00:20:25.499 --> 00:20:27.529 align:start position:0%
posterior using Bayes rule however in
practice<00:20:25.950><c> it's</c><00:20:26.369><c> rarely</c><00:20:26.789><c> possible</c><00:20:27.389><c> to</c>

00:20:27.529 --> 00:20:27.539 align:start position:0%
practice it's rarely possible to
 

00:20:27.539 --> 00:20:31.639 align:start position:0%
practice it's rarely possible to
actually<00:20:27.690><c> compute</c><00:20:28.259><c> this</c><00:20:29.749><c> compute</c><00:20:30.749><c> this</c><00:20:30.929><c> Bayes</c>

00:20:31.639 --> 00:20:31.649 align:start position:0%
actually compute this compute this Bayes
 

00:20:31.649 --> 00:20:35.479 align:start position:0%
actually compute this compute this Bayes
rule<00:20:31.679><c> update</c><00:20:33.320><c> and</c><00:20:34.320><c> it</c><00:20:34.919><c> just</c><00:20:35.100><c> turns</c><00:20:35.249><c> out</c><00:20:35.340><c> to</c><00:20:35.399><c> be</c>

00:20:35.479 --> 00:20:35.489 align:start position:0%
rule update and it just turns out to be
 

00:20:35.489 --> 00:20:38.090 align:start position:0%
rule update and it just turns out to be
intractable<00:20:35.909><c> so</c><00:20:36.509><c> instead</c><00:20:36.840><c> we</c><00:20:37.230><c> have</c><00:20:37.379><c> to</c><00:20:37.619><c> find</c>

00:20:38.090 --> 00:20:38.100 align:start position:0%
intractable so instead we have to find
 

00:20:38.100 --> 00:20:39.889 align:start position:0%
intractable so instead we have to find
out<00:20:38.249><c> ways</c><00:20:38.489><c> to</c><00:20:38.519><c> actually</c><00:20:39.119><c> approximate</c><00:20:39.419><c> it</c>

00:20:39.889 --> 00:20:39.899 align:start position:0%
out ways to actually approximate it
 

00:20:39.899 --> 00:20:42.019 align:start position:0%
out ways to actually approximate it
through<00:20:40.470><c> sampling</c><00:20:40.830><c> so</c><00:20:41.460><c> one</c><00:20:41.669><c> way</c><00:20:41.820><c> that</c><00:20:41.850><c> I'll</c>

00:20:42.019 --> 00:20:42.029 align:start position:0%
through sampling so one way that I'll
 

00:20:42.029 --> 00:20:44.869 align:start position:0%
through sampling so one way that I'll
talk<00:20:42.210><c> about</c><00:20:42.269><c> today</c><00:20:42.539><c> is</c><00:20:43.049><c> a</c><00:20:43.859><c> very</c><00:20:44.129><c> simple</c><00:20:44.429><c> notion</c>

00:20:44.869 --> 00:20:44.879 align:start position:0%
talk about today is a very simple notion
 

00:20:44.879 --> 00:20:46.789 align:start position:0%
talk about today is a very simple notion
that<00:20:45.389><c> we've</c><00:20:45.539><c> actually</c><00:20:45.779><c> already</c><00:20:46.080><c> seen</c><00:20:46.529><c> in</c><00:20:46.679><c> the</c>

00:20:46.789 --> 00:20:46.799 align:start position:0%
that we've actually already seen in the
 

00:20:46.799 --> 00:20:48.710 align:start position:0%
that we've actually already seen in the
first<00:20:46.830><c> lecture</c><00:20:47.279><c> and</c><00:20:48.029><c> it</c><00:20:48.119><c> goes</c><00:20:48.269><c> back</c><00:20:48.480><c> to</c><00:20:48.629><c> this</c>

00:20:48.710 --> 00:20:48.720 align:start position:0%
first lecture and it goes back to this
 

00:20:48.720 --> 00:20:51.499 align:start position:0%
first lecture and it goes back to this
idea<00:20:49.080><c> of</c><00:20:49.139><c> using</c><00:20:49.559><c> dropout</c><00:20:50.009><c> so</c><00:20:50.999><c> if</c><00:20:51.090><c> you</c><00:20:51.179><c> remember</c>

00:20:51.499 --> 00:20:51.509 align:start position:0%
idea of using dropout so if you remember
 

00:20:51.509 --> 00:20:53.899 align:start position:0%
idea of using dropout so if you remember
what<00:20:52.409><c> dropout</c><00:20:52.799><c> was</c><00:20:52.980><c> dropout</c><00:20:53.399><c> is</c><00:20:53.519><c> this</c><00:20:53.669><c> notion</c>

00:20:53.899 --> 00:20:53.909 align:start position:0%
what dropout was dropout is this notion
 

00:20:53.909 --> 00:20:57.169 align:start position:0%
what dropout was dropout is this notion
of<00:20:54.200><c> randomly</c><00:20:55.429><c> killing</c><00:20:56.429><c> off</c><00:20:56.549><c> a</c><00:20:56.820><c> certain</c>

00:20:57.169 --> 00:20:57.179 align:start position:0%
of randomly killing off a certain
 

00:20:57.179 --> 00:20:59.899 align:start position:0%
of randomly killing off a certain
percentage<00:20:57.690><c> of</c><00:20:57.960><c> neurons</c><00:20:58.470><c> in</c><00:20:58.679><c> each</c><00:20:59.489><c> of</c><00:20:59.700><c> the</c>

00:20:59.899 --> 00:20:59.909 align:start position:0%
percentage of neurons in each of the
 

00:20:59.909 --> 00:21:02.450 align:start position:0%
percentage of neurons in each of the
hidden<00:21:00.450><c> layers</c><00:21:00.830><c> now</c><00:21:01.830><c> I'm</c><00:21:01.919><c> going</c><00:21:02.100><c> to</c><00:21:02.190><c> tell</c><00:21:02.369><c> you</c>

00:21:02.450 --> 00:21:02.460 align:start position:0%
hidden layers now I'm going to tell you
 

00:21:02.460 --> 00:21:04.369 align:start position:0%
hidden layers now I'm going to tell you
not<00:21:02.639><c> how</c><00:21:02.850><c> to</c><00:21:02.909><c> use</c><00:21:03.210><c> it</c><00:21:03.359><c> as</c><00:21:03.450><c> a</c><00:21:03.480><c> regularizer</c>

00:21:04.369 --> 00:21:04.379 align:start position:0%
not how to use it as a regularizer
 

00:21:04.379 --> 00:21:06.560 align:start position:0%
not how to use it as a regularizer
but<00:21:04.889><c> how</c><00:21:05.070><c> to</c><00:21:05.129><c> use</c><00:21:05.399><c> dropout</c><00:21:05.909><c> as</c><00:21:06.149><c> a</c><00:21:06.210><c> way</c><00:21:06.509><c> to</c>

00:21:06.560 --> 00:21:06.570 align:start position:0%
but how to use dropout as a way to
 

00:21:06.570 --> 00:21:08.960 align:start position:0%
but how to use dropout as a way to
produce<00:21:06.929><c> reliable</c><00:21:07.639><c> uncertainty</c><00:21:08.639><c> measures</c>

00:21:08.960 --> 00:21:08.970 align:start position:0%
produce reliable uncertainty measures
 

00:21:08.970 --> 00:21:13.220 align:start position:0%
produce reliable uncertainty measures
for<00:21:09.210><c> your</c><00:21:09.330><c> neural</c><00:21:09.570><c> network</c><00:21:10.460><c> so</c><00:21:11.460><c> to</c><00:21:11.519><c> do</c><00:21:11.730><c> this</c><00:21:12.230><c> we</c>

00:21:13.220 --> 00:21:13.230 align:start position:0%
for your neural network so to do this we
 

00:21:13.230 --> 00:21:15.889 align:start position:0%
for your neural network so to do this we
have<00:21:13.409><c> to</c><00:21:13.440><c> think</c><00:21:14.159><c> of</c><00:21:14.309><c> capital</c><00:21:15.090><c> T</c><00:21:15.299><c> stochastic</c>

00:21:15.889 --> 00:21:15.899 align:start position:0%
have to think of capital T stochastic
 

00:21:15.899 --> 00:21:17.299 align:start position:0%
have to think of capital T stochastic
passes<00:21:16.259><c> through</c><00:21:16.470><c> our</c><00:21:16.559><c> network</c><00:21:16.919><c> where</c><00:21:17.129><c> each</c>

00:21:17.299 --> 00:21:17.309 align:start position:0%
passes through our network where each
 

00:21:17.309 --> 00:21:19.549 align:start position:0%
passes through our network where each
stochastic<00:21:17.820><c> pass</c><00:21:17.999><c> performs</c><00:21:18.779><c> one</c><00:21:19.019><c> iteration</c>

00:21:19.549 --> 00:21:19.559 align:start position:0%
stochastic pass performs one iteration
 

00:21:19.559 --> 00:21:20.210 align:start position:0%
stochastic pass performs one iteration
of<00:21:19.679><c> dropouts</c>

00:21:20.210 --> 00:21:20.220 align:start position:0%
of dropouts
 

00:21:20.220 --> 00:21:22.310 align:start position:0%
of dropouts
each<00:21:21.029><c> time</c><00:21:21.330><c> you</c><00:21:21.450><c> iterate</c><00:21:21.779><c> dropout</c><00:21:22.169><c> you're</c>

00:21:22.310 --> 00:21:22.320 align:start position:0%
each time you iterate dropout you're
 

00:21:22.320 --> 00:21:24.259 align:start position:0%
each time you iterate dropout you're
basically<00:21:22.710><c> just</c><00:21:22.799><c> applying</c><00:21:23.279><c> a</c><00:21:23.399><c> Bernoulli</c><00:21:23.999><c> mask</c>

00:21:24.259 --> 00:21:24.269 align:start position:0%
basically just applying a Bernoulli mask
 

00:21:24.269 --> 00:21:26.840 align:start position:0%
basically just applying a Bernoulli mask
of<00:21:24.659><c> ones</c><00:21:25.440><c> and</c><00:21:25.590><c> zeros</c><00:21:25.980><c> over</c><00:21:26.399><c> each</c><00:21:26.549><c> of</c><00:21:26.700><c> your</c>

00:21:26.840 --> 00:21:26.850 align:start position:0%
of ones and zeros over each of your
 

00:21:26.850 --> 00:21:28.759 align:start position:0%
of ones and zeros over each of your
weights<00:21:27.029><c> so</c><00:21:27.840><c> going</c><00:21:28.019><c> from</c><00:21:28.169><c> the</c><00:21:28.259><c> left</c><00:21:28.559><c> to</c><00:21:28.710><c> the</c>

00:21:28.759 --> 00:21:28.769 align:start position:0%
weights so going from the left to the
 

00:21:28.769 --> 00:21:31.070 align:start position:0%
weights so going from the left to the
right<00:21:28.859><c> you</c><00:21:29.159><c> can</c><00:21:29.309><c> see</c><00:21:29.489><c> our</c><00:21:29.580><c> weights</c><00:21:29.929><c> which</c><00:21:30.929><c> is</c>

00:21:31.070 --> 00:21:31.080 align:start position:0%
right you can see our weights which is
 

00:21:31.080 --> 00:21:32.930 align:start position:0%
right you can see our weights which is
like<00:21:31.200><c> this</c><00:21:31.379><c> matrix</c><00:21:31.769><c> here</c><00:21:32.070><c> different</c><00:21:32.489><c> colors</c>

00:21:32.930 --> 00:21:32.940 align:start position:0%
like this matrix here different colors
 

00:21:32.940 --> 00:21:35.299 align:start position:0%
like this matrix here different colors
represent<00:21:33.149><c> the</c><00:21:33.859><c> intensity</c><00:21:34.859><c> of</c><00:21:34.950><c> that</c><00:21:35.100><c> weight</c>

00:21:35.299 --> 00:21:35.309 align:start position:0%
represent the intensity of that weight
 

00:21:35.309 --> 00:21:37.489 align:start position:0%
represent the intensity of that weight
and<00:21:35.609><c> we</c><00:21:36.149><c> element-wise</c><00:21:36.690><c> multiply</c><00:21:37.289><c> those</c>

00:21:37.489 --> 00:21:37.499 align:start position:0%
and we element-wise multiply those
 

00:21:37.499 --> 00:21:39.259 align:start position:0%
and we element-wise multiply those
weights<00:21:37.799><c> by</c><00:21:38.129><c> our</c><00:21:38.279><c> Bernoulli</c><00:21:38.759><c> mask</c><00:21:38.999><c> width</c>

00:21:39.259 --> 00:21:39.269 align:start position:0%
weights by our Bernoulli mask width
 

00:21:39.269 --> 00:21:41.749 align:start position:0%
weights by our Bernoulli mask width
which<00:21:39.749><c> is</c><00:21:39.899><c> just</c><00:21:40.169><c> either</c><00:21:40.320><c> a</c><00:21:40.440><c> 1</c><00:21:40.710><c> or</c><00:21:40.919><c> a</c><00:21:40.950><c> 0</c><00:21:41.039><c> in</c><00:21:41.460><c> every</c>

00:21:41.749 --> 00:21:41.759 align:start position:0%
which is just either a 1 or a 0 in every
 

00:21:41.759 --> 00:21:45.440 align:start position:0%
which is just either a 1 or a 0 in every
location<00:21:42.859><c> the</c><00:21:43.859><c> output</c><00:21:44.309><c> is</c><00:21:44.489><c> a</c><00:21:44.820><c> new</c><00:21:45.090><c> set</c><00:21:45.330><c> of</c>

00:21:45.440 --> 00:21:45.450 align:start position:0%
location the output is a new set of
 

00:21:45.450 --> 00:21:47.810 align:start position:0%
location the output is a new set of
weights<00:21:45.739><c> with</c><00:21:46.739><c> certain</c><00:21:47.129><c> of</c><00:21:47.249><c> those</c><00:21:47.399><c> dropped</c>

00:21:47.810 --> 00:21:47.820 align:start position:0%
weights with certain of those dropped
 

00:21:47.820 --> 00:21:49.460 align:start position:0%
weights with certain of those dropped
out<00:21:47.999><c> with</c><00:21:48.359><c> certain</c><00:21:48.600><c> aspects</c><00:21:49.230><c> of</c><00:21:49.350><c> those</c>

00:21:49.460 --> 00:21:49.470 align:start position:0%
out with certain aspects of those
 

00:21:49.470 --> 00:21:54.399 align:start position:0%
out with certain aspects of those
dropped<00:21:49.769><c> out</c><00:21:51.139><c> now</c><00:21:52.190><c> all</c><00:21:53.190><c> we</c><00:21:53.489><c> have</c><00:21:53.639><c> to</c><00:21:53.669><c> do</c><00:21:53.940><c> is</c>

00:21:54.399 --> 00:21:54.409 align:start position:0%
dropped out now all we have to do is
 

00:21:54.409 --> 00:21:57.590 align:start position:0%
dropped out now all we have to do is
compute<00:21:55.409><c> this</c><00:21:55.649><c> T</c><00:21:56.369><c> times</c><00:21:56.639><c> capital</c><00:21:57.090><c> T</c><00:21:57.119><c> times</c><00:21:57.450><c> we</c>

00:21:57.590 --> 00:21:57.600 align:start position:0%
compute this T times capital T times we
 

00:21:57.600 --> 00:22:01.070 align:start position:0%
compute this T times capital T times we
get<00:21:57.690><c> Kappa</c><00:21:58.049><c> theta</c><00:21:58.739><c> T</c><00:21:59.100><c> weights</c><00:21:59.369><c> and</c><00:21:59.840><c> we</c><00:22:00.840><c> use</c>

00:22:01.070 --> 00:22:01.080 align:start position:0%
get Kappa theta T weights and we use
 

00:22:01.080 --> 00:22:04.129 align:start position:0%
get Kappa theta T weights and we use
those<00:22:01.259><c> theta</c><00:22:01.619><c> T</c><00:22:01.859><c> different</c><00:22:02.129><c> models</c><00:22:03.139><c> to</c>

00:22:04.129 --> 00:22:04.139 align:start position:0%
those theta T different models to
 

00:22:04.139 --> 00:22:06.529 align:start position:0%
those theta T different models to
actually<00:22:04.289><c> produce</c><00:22:04.889><c> an</c><00:22:05.190><c> empirical</c><00:22:05.789><c> average</c><00:22:06.269><c> of</c>

00:22:06.529 --> 00:22:06.539 align:start position:0%
actually produce an empirical average of
 

00:22:06.539 --> 00:22:11.359 align:start position:0%
actually produce an empirical average of
our<00:22:07.349><c> output</c><00:22:07.830><c> class</c><00:22:08.489><c> given</c><00:22:09.480><c> the</c><00:22:09.570><c> data</c><00:22:10.369><c> so</c>

00:22:11.359 --> 00:22:11.369 align:start position:0%
our output class given the data so
 

00:22:11.369 --> 00:22:12.590 align:start position:0%
our output class given the data so
that's<00:22:11.609><c> this</c><00:22:11.789><c> guy</c>

00:22:12.590 --> 00:22:12.600 align:start position:0%
that's this guy
 

00:22:12.600 --> 00:22:14.690 align:start position:0%
that's this guy
well<00:22:13.350><c> we're</c><00:22:13.500><c> actually</c><00:22:13.649><c> really</c><00:22:14.130><c> interested</c><00:22:14.580><c> in</c>

00:22:14.690 --> 00:22:14.700 align:start position:0%
well we're actually really interested in
 

00:22:14.700 --> 00:22:16.460 align:start position:0%
well we're actually really interested in
why<00:22:14.909><c> I</c><00:22:14.940><c> brought</c><00:22:15.210><c> this</c><00:22:15.389><c> topic</c><00:22:15.779><c> up</c><00:22:15.929><c> was</c><00:22:16.110><c> the</c>

00:22:16.460 --> 00:22:16.470 align:start position:0%
why I brought this topic up was the
 

00:22:16.470 --> 00:22:18.499 align:start position:0%
why I brought this topic up was the
notion<00:22:16.740><c> of</c><00:22:16.799><c> uncertainty</c><00:22:17.370><c> though</c><00:22:17.519><c> and</c><00:22:17.789><c> that's</c>

00:22:18.499 --> 00:22:18.509 align:start position:0%
notion of uncertainty though and that's
 

00:22:18.509 --> 00:22:22.669 align:start position:0%
notion of uncertainty though and that's
the<00:22:19.019><c> variance</c><00:22:19.529><c> of</c><00:22:19.830><c> our</c><00:22:20.039><c> predictions</c><00:22:21.679><c> right</c>

00:22:22.669 --> 00:22:22.679 align:start position:0%
the variance of our predictions right
 

00:22:22.679 --> 00:22:25.490 align:start position:0%
the variance of our predictions right
there<00:22:23.360><c> so</c><00:22:24.360><c> this</c><00:22:24.450><c> is</c><00:22:24.509><c> a</c><00:22:24.659><c> very</c><00:22:24.960><c> powerful</c><00:22:25.169><c> idea</c>

00:22:25.490 --> 00:22:25.500 align:start position:0%
there so this is a very powerful idea
 

00:22:25.500 --> 00:22:28.990 align:start position:0%
there so this is a very powerful idea
all<00:22:25.799><c> it</c><00:22:25.950><c> means</c><00:22:26.070><c> is</c><00:22:26.370><c> that</c><00:22:26.429><c> we</c><00:22:27.269><c> can</c><00:22:27.450><c> obtain</c>

00:22:28.990 --> 00:22:29.000 align:start position:0%
all it means is that we can obtain
 

00:22:29.000 --> 00:22:31.370 align:start position:0%
all it means is that we can obtain
reliable<00:22:30.000><c> model</c><00:22:30.690><c> uncertainty</c><00:22:31.230><c> estimates</c>

00:22:31.370 --> 00:22:31.380 align:start position:0%
reliable model uncertainty estimates
 

00:22:31.380 --> 00:22:33.799 align:start position:0%
reliable model uncertainty estimates
simply<00:22:32.340><c> by</c><00:22:32.549><c> training</c><00:22:32.909><c> our</c><00:22:33.090><c> network</c><00:22:33.450><c> during</c>

00:22:33.799 --> 00:22:33.809 align:start position:0%
simply by training our network during
 

00:22:33.809 --> 00:22:36.049 align:start position:0%
simply by training our network during
runtime<00:22:34.019><c> with</c><00:22:34.380><c> dropout</c><00:22:34.799><c> and</c><00:22:35.009><c> then</c><00:22:35.730><c> instead</c><00:22:36.000><c> of</c>

00:22:36.049 --> 00:22:36.059 align:start position:0%
runtime with dropout and then instead of
 

00:22:36.059 --> 00:22:39.049 align:start position:0%
runtime with dropout and then instead of
estimating<00:22:37.049><c> or</c><00:22:37.259><c> classifying</c><00:22:38.250><c> just</c><00:22:38.490><c> a</c><00:22:38.610><c> single</c>

00:22:39.049 --> 00:22:39.059 align:start position:0%
estimating or classifying just a single
 

00:22:39.059 --> 00:22:40.820 align:start position:0%
estimating or classifying just a single
pass<00:22:39.600><c> through</c><00:22:39.840><c> this</c><00:22:39.960><c> network</c><00:22:40.320><c> at</c><00:22:40.470><c> test</c><00:22:40.740><c> time</c>

00:22:40.820 --> 00:22:40.830 align:start position:0%
pass through this network at test time
 

00:22:40.830 --> 00:22:44.120 align:start position:0%
pass through this network at test time
we<00:22:41.519><c> classify</c><00:22:42.000><c> capital</c><00:22:42.630><c> teet</c><00:22:42.980><c> iterations</c><00:22:43.980><c> of</c>

00:22:44.120 --> 00:22:44.130 align:start position:0%
we classify capital teet iterations of
 

00:22:44.130 --> 00:22:46.850 align:start position:0%
we classify capital teet iterations of
this<00:22:44.279><c> network</c><00:22:44.610><c> and</c><00:22:45.110><c> then</c><00:22:46.110><c> use</c><00:22:46.320><c> it</c><00:22:46.500><c> to</c><00:22:46.620><c> compute</c>

00:22:46.850 --> 00:22:46.860 align:start position:0%
this network and then use it to compute
 

00:22:46.860 --> 00:22:48.560 align:start position:0%
this network and then use it to compute
a<00:22:46.980><c> variance</c><00:22:47.340><c> over</c><00:22:47.610><c> these</c><00:22:47.820><c> outputs</c><00:22:48.210><c> and</c><00:22:48.419><c> that</c>

00:22:48.560 --> 00:22:48.570 align:start position:0%
a variance over these outputs and that
 

00:22:48.570 --> 00:22:50.629 align:start position:0%
a variance over these outputs and that
variance<00:22:49.049><c> gives</c><00:22:49.320><c> us</c><00:22:49.470><c> a</c><00:22:49.500><c> estimation</c><00:22:50.279><c> of</c><00:22:50.490><c> our</c>

00:22:50.629 --> 00:22:50.639 align:start position:0%
variance gives us a estimation of our
 

00:22:50.639 --> 00:22:54.379 align:start position:0%
variance gives us a estimation of our
uncertainty<00:22:52.580><c> now</c><00:22:53.580><c> to</c><00:22:53.639><c> give</c><00:22:53.850><c> you</c><00:22:53.940><c> an</c><00:22:54.090><c> example</c>

00:22:54.379 --> 00:22:54.389 align:start position:0%
uncertainty now to give you an example
 

00:22:54.389 --> 00:22:56.389 align:start position:0%
uncertainty now to give you an example
of<00:22:54.570><c> how</c><00:22:54.629><c> this</c><00:22:54.809><c> looks</c><00:22:55.080><c> in</c><00:22:55.200><c> practice</c><00:22:55.379><c> let's</c><00:22:56.159><c> look</c>

00:22:56.389 --> 00:22:56.399 align:start position:0%
of how this looks in practice let's look
 

00:22:56.399 --> 00:22:59.690 align:start position:0%
of how this looks in practice let's look
at<00:22:56.519><c> this</c><00:22:57.049><c> this</c><00:22:58.049><c> network</c><00:22:58.769><c> that</c><00:22:58.980><c> was</c><00:22:59.070><c> trained</c><00:22:59.429><c> to</c>

00:22:59.690 --> 00:22:59.700 align:start position:0%
at this this network that was trained to
 

00:22:59.700 --> 00:23:03.499 align:start position:0%
at this this network that was trained to
take<00:22:59.970><c> as</c><00:23:00.179><c> input</c><00:23:01.429><c> images</c><00:23:02.429><c> of</c><00:23:02.700><c> the</c><00:23:03.090><c> real</c><00:23:03.269><c> world</c>

00:23:03.499 --> 00:23:03.509 align:start position:0%
take as input images of the real world
 

00:23:03.509 --> 00:23:07.580 align:start position:0%
take as input images of the real world
and<00:23:03.899><c> outputs</c><00:23:04.820><c> predicted</c><00:23:05.820><c> depth</c><00:23:06.059><c> maps</c><00:23:06.330><c> oh</c><00:23:06.659><c> it</c>

00:23:07.580 --> 00:23:07.590 align:start position:0%
and outputs predicted depth maps oh it
 

00:23:07.590 --> 00:23:10.700 align:start position:0%
and outputs predicted depth maps oh it
looks<00:23:07.799><c> like</c><00:23:07.980><c> my</c><00:23:08.779><c> text</c><00:23:09.779><c> was</c><00:23:09.960><c> a</c><00:23:09.990><c> little</c><00:23:10.289><c> off</c><00:23:10.440><c> but</c>

00:23:10.700 --> 00:23:10.710 align:start position:0%
looks like my text was a little off but
 

00:23:10.710 --> 00:23:14.990 align:start position:0%
looks like my text was a little off but
that's<00:23:10.860><c> okay</c><00:23:12.080><c> so</c><00:23:13.129><c> at</c><00:23:14.129><c> the</c><00:23:14.340><c> output</c><00:23:14.730><c> we</c><00:23:14.850><c> have</c><00:23:14.879><c> a</c>

00:23:14.990 --> 00:23:15.000 align:start position:0%
that's okay so at the output we have a
 

00:23:15.000 --> 00:23:16.789 align:start position:0%
that's okay so at the output we have a
predicted<00:23:15.509><c> death</c><00:23:15.659><c> map</c><00:23:15.899><c> where</c><00:23:16.110><c> at</c><00:23:16.200><c> each</c><00:23:16.470><c> pixel</c>

00:23:16.789 --> 00:23:16.799 align:start position:0%
predicted death map where at each pixel
 

00:23:16.799 --> 00:23:19.789 align:start position:0%
predicted death map where at each pixel
the<00:23:17.279><c> network</c><00:23:17.549><c> is</c><00:23:17.730><c> predicting</c><00:23:18.360><c> the</c><00:23:19.259><c> depth</c><00:23:19.559><c> in</c>

00:23:19.789 --> 00:23:19.799 align:start position:0%
the network is predicting the depth in
 

00:23:19.799 --> 00:23:23.990 align:start position:0%
the network is predicting the depth in
the<00:23:19.980><c> real</c><00:23:20.159><c> world</c><00:23:20.429><c> of</c><00:23:20.759><c> that</c><00:23:21.330><c> pixel</c><00:23:22.669><c> now</c><00:23:23.669><c> when</c><00:23:23.820><c> we</c>

00:23:23.990 --> 00:23:24.000 align:start position:0%
the real world of that pixel now when we
 

00:23:24.000 --> 00:23:26.930 align:start position:0%
the real world of that pixel now when we
run<00:23:24.240><c> Bayesian</c><00:23:24.750><c> model</c><00:23:25.440><c> uncertainty</c><00:23:26.100><c> using</c><00:23:26.639><c> the</c>

00:23:26.930 --> 00:23:26.940 align:start position:0%
run Bayesian model uncertainty using the
 

00:23:26.940 --> 00:23:28.519 align:start position:0%
run Bayesian model uncertainty using the
exact<00:23:27.210><c> same</c><00:23:27.240><c> dropout</c><00:23:27.809><c> method</c><00:23:28.139><c> that</c><00:23:28.259><c> I</c><00:23:28.289><c> just</c>

00:23:28.519 --> 00:23:28.529 align:start position:0%
exact same dropout method that I just
 

00:23:28.529 --> 00:23:32.899 align:start position:0%
exact same dropout method that I just
described<00:23:29.809><c> we</c><00:23:30.809><c> can</c><00:23:30.990><c> see</c><00:23:31.490><c> that</c><00:23:32.490><c> the</c><00:23:32.669><c> end</c><00:23:32.759><c> the</c>

00:23:32.899 --> 00:23:32.909 align:start position:0%
described we can see that the end the
 

00:23:32.909 --> 00:23:34.850 align:start position:0%
described we can see that the end the
model<00:23:33.269><c> is</c><00:23:33.509><c> most</c><00:23:33.870><c> uncertain</c><00:23:34.259><c> in</c><00:23:34.470><c> some</c><00:23:34.649><c> very</c>

00:23:34.850 --> 00:23:34.860 align:start position:0%
model is most uncertain in some very
 

00:23:34.860 --> 00:23:37.039 align:start position:0%
model is most uncertain in some very
interesting<00:23:35.159><c> locations</c><00:23:35.879><c> so</c><00:23:36.690><c> first</c><00:23:36.929><c> of</c><00:23:37.019><c> all</c>

00:23:37.039 --> 00:23:37.049 align:start position:0%
interesting locations so first of all
 

00:23:37.049 --> 00:23:38.539 align:start position:0%
interesting locations so first of all
pay<00:23:37.320><c> attention</c><00:23:37.679><c> to</c><00:23:37.799><c> that</c><00:23:37.919><c> location</c><00:23:38.399><c> right</c>

00:23:38.539 --> 00:23:38.549 align:start position:0%
pay attention to that location right
 

00:23:38.549 --> 00:23:41.810 align:start position:0%
pay attention to that location right
there<00:23:38.610><c> if</c><00:23:39.090><c> you</c><00:23:39.629><c> look</c><00:23:40.250><c> where</c><00:23:41.250><c> where</c><00:23:41.549><c> is</c><00:23:41.669><c> that</c>

00:23:41.810 --> 00:23:41.820 align:start position:0%
there if you look where where is that
 

00:23:41.820 --> 00:23:43.970 align:start position:0%
there if you look where where is that
location<00:23:42.210><c> exactly</c><00:23:42.450><c> it's</c><00:23:43.259><c> just</c><00:23:43.559><c> the</c><00:23:43.679><c> window</c>

00:23:43.970 --> 00:23:43.980 align:start position:0%
location exactly it's just the window
 

00:23:43.980 --> 00:23:47.210 align:start position:0%
location exactly it's just the window
sill<00:23:44.250><c> of</c><00:23:44.429><c> this</c><00:23:44.580><c> car</c><00:23:44.820><c> and</c><00:23:45.679><c> in</c><00:23:46.679><c> computer</c><00:23:47.190><c> vision</c>

00:23:47.210 --> 00:23:47.220 align:start position:0%
sill of this car and in computer vision
 

00:23:47.220 --> 00:23:51.409 align:start position:0%
sill of this car and in computer vision
windows<00:23:47.940><c> and</c><00:23:48.419><c> specular</c><00:23:49.200><c> objects</c><00:23:49.710><c> are</c><00:23:50.669><c> very</c>

00:23:51.409 --> 00:23:51.419 align:start position:0%
windows and specular objects are very
 

00:23:51.419 --> 00:23:54.619 align:start position:0%
windows and specular objects are very
difficult<00:23:52.350><c> to</c><00:23:52.950><c> to</c><00:23:53.639><c> basically</c><00:23:53.909><c> model</c><00:23:54.330><c> because</c>

00:23:54.619 --> 00:23:54.629 align:start position:0%
difficult to to basically model because
 

00:23:54.629 --> 00:23:56.960 align:start position:0%
difficult to to basically model because
we<00:23:55.139><c> can't</c><00:23:55.470><c> actually</c><00:23:55.620><c> tell</c><00:23:56.129><c> their</c><00:23:56.490><c> surface</c>

00:23:56.960 --> 00:23:56.970 align:start position:0%
we can't actually tell their surface
 

00:23:56.970 --> 00:23:58.909 align:start position:0%
we can't actually tell their surface
reliably<00:23:57.539><c> right</c><00:23:57.870><c> so</c><00:23:58.110><c> we're</c><00:23:58.259><c> seeing</c><00:23:58.529><c> the</c><00:23:58.710><c> light</c>

00:23:58.909 --> 00:23:58.919 align:start position:0%
reliably right so we're seeing the light
 

00:23:58.919 --> 00:24:01.039 align:start position:0%
reliably right so we're seeing the light
from<00:23:59.370><c> actually</c><00:23:59.730><c> the</c><00:23:59.879><c> sky</c><00:24:00.179><c> we're</c><00:24:00.750><c> not</c><00:24:00.899><c> actually</c>

00:24:01.039 --> 00:24:01.049 align:start position:0%
from actually the sky we're not actually
 

00:24:01.049 --> 00:24:02.690 align:start position:0%
from actually the sky we're not actually
seeing<00:24:01.440><c> the</c><00:24:01.620><c> surface</c><00:24:01.950><c> of</c><00:24:02.100><c> the</c><00:24:02.220><c> window</c><00:24:02.519><c> in</c><00:24:02.669><c> that</c>

00:24:02.690 --> 00:24:02.700 align:start position:0%
seeing the surface of the window in that
 

00:24:02.700 --> 00:24:04.970 align:start position:0%
seeing the surface of the window in that
location<00:24:03.090><c> so</c><00:24:03.750><c> it</c><00:24:03.809><c> can</c><00:24:03.899><c> be</c><00:24:04.019><c> very</c><00:24:04.230><c> difficult</c><00:24:04.470><c> for</c>

00:24:04.970 --> 00:24:04.980 align:start position:0%
location so it can be very difficult for
 

00:24:04.980 --> 00:24:08.289 align:start position:0%
location so it can be very difficult for
us<00:24:05.279><c> to</c><00:24:05.460><c> model</c><00:24:05.820><c> the</c><00:24:05.970><c> the</c><00:24:06.629><c> depth</c><00:24:06.899><c> in</c><00:24:07.110><c> that</c><00:24:07.139><c> place</c>

00:24:08.289 --> 00:24:08.299 align:start position:0%
us to model the the depth in that place
 

00:24:08.299 --> 00:24:10.820 align:start position:0%
us to model the the depth in that place
additionally<00:24:09.299><c> we</c><00:24:09.450><c> see</c><00:24:09.480><c> that</c><00:24:10.379><c> the</c><00:24:10.559><c> model</c><00:24:10.799><c> is</c>

00:24:10.820 --> 00:24:10.830 align:start position:0%
additionally we see that the model is
 

00:24:10.830 --> 00:24:13.039 align:start position:0%
additionally we see that the model is
very<00:24:11.039><c> uncertain</c><00:24:11.370><c> on</c><00:24:11.580><c> the</c><00:24:11.940><c> edges</c><00:24:12.419><c> of</c><00:24:12.450><c> the</c><00:24:12.840><c> cars</c>

00:24:13.039 --> 00:24:13.049 align:start position:0%
very uncertain on the edges of the cars
 

00:24:13.049 --> 00:24:16.279 align:start position:0%
very uncertain on the edges of the cars
because<00:24:13.710><c> these</c><00:24:13.889><c> are</c><00:24:14.299><c> places</c><00:24:15.299><c> where</c><00:24:15.659><c> the</c><00:24:15.870><c> depth</c>

00:24:16.279 --> 00:24:16.289 align:start position:0%
because these are places where the depth
 

00:24:16.289 --> 00:24:18.529 align:start position:0%
because these are places where the depth
is<00:24:16.500><c> changing</c><00:24:16.529><c> very</c><00:24:17.309><c> rapidly</c><00:24:17.639><c> so</c><00:24:18.509><c> the</c>

00:24:18.529 --> 00:24:18.539 align:start position:0%
is changing very rapidly so the
 

00:24:18.539 --> 00:24:20.210 align:start position:0%
is changing very rapidly so the
prediction<00:24:18.929><c> may</c><00:24:19.169><c> be</c><00:24:19.230><c> least</c><00:24:19.740><c> accurate</c><00:24:20.159><c> in</c>

00:24:20.210 --> 00:24:20.220 align:start position:0%
prediction may be least accurate in
 

00:24:20.220 --> 00:24:23.029 align:start position:0%
prediction may be least accurate in
these<00:24:20.340><c> locations</c><00:24:21.529><c> so</c><00:24:22.529><c> having</c><00:24:22.799><c> reliable</c>

00:24:23.029 --> 00:24:23.039 align:start position:0%
these locations so having reliable
 

00:24:23.039 --> 00:24:25.100 align:start position:0%
these locations so having reliable
uncertainty<00:24:23.820><c> estimates</c><00:24:24.299><c> can</c><00:24:24.809><c> be</c><00:24:24.870><c> an</c>

00:24:25.100 --> 00:24:25.110 align:start position:0%
uncertainty estimates can be an
 

00:24:25.110 --> 00:24:26.420 align:start position:0%
uncertainty estimates can be an
extremely<00:24:25.440><c> powerful</c>

00:24:26.420 --> 00:24:26.430 align:start position:0%
extremely powerful
 

00:24:26.430 --> 00:24:28.670 align:start position:0%
extremely powerful
way<00:24:26.850><c> to</c><00:24:26.910><c> actually</c><00:24:27.570><c> interpret</c><00:24:28.020><c> deep</c><00:24:28.350><c> learning</c>

00:24:28.670 --> 00:24:28.680 align:start position:0%
way to actually interpret deep learning
 

00:24:28.680 --> 00:24:31.070 align:start position:0%
way to actually interpret deep learning
models<00:24:29.040><c> and</c><00:24:29.280><c> also</c><00:24:29.520><c> provide</c><00:24:30.080><c> human</c>

00:24:31.070 --> 00:24:31.080 align:start position:0%
models and also provide human
 

00:24:31.080 --> 00:24:33.050 align:start position:0%
models and also provide human
practitioners<00:24:31.680><c> especially</c><00:24:32.250><c> in</c><00:24:32.610><c> the</c><00:24:32.730><c> realm</c><00:24:32.910><c> of</c>

00:24:33.050 --> 00:24:33.060 align:start position:0%
practitioners especially in the realm of
 

00:24:33.060 --> 00:24:37.460 align:start position:0%
practitioners especially in the realm of
safe<00:24:33.600><c> AI</c><00:24:34.010><c> that's</c><00:24:35.010><c> a</c><00:24:35.220><c> way</c><00:24:35.400><c> to</c><00:24:36.230><c> interpret</c><00:24:37.230><c> the</c>

00:24:37.460 --> 00:24:37.470 align:start position:0%
safe AI that's a way to interpret the
 

00:24:37.470 --> 00:24:41.990 align:start position:0%
safe AI that's a way to interpret the
results<00:24:37.890><c> and</c><00:24:38.010><c> also</c><00:24:40.160><c> trusts</c><00:24:41.160><c> our</c><00:24:41.280><c> results</c><00:24:41.880><c> with</c>

00:24:41.990 --> 00:24:42.000 align:start position:0%
results and also trusts our results with
 

00:24:42.000 --> 00:24:43.580 align:start position:0%
results and also trusts our results with
a<00:24:42.030><c> certain</c><00:24:42.420><c> amount</c><00:24:42.600><c> of</c><00:24:42.780><c> or</c><00:24:43.050><c> a</c><00:24:43.110><c> certain</c><00:24:43.410><c> grain</c>

00:24:43.580 --> 00:24:43.590 align:start position:0%
a certain amount of or a certain grain
 

00:24:43.590 --> 00:24:48.680 align:start position:0%
a certain amount of or a certain grain
of<00:24:43.680><c> salt</c><00:24:46.520><c> so</c><00:24:47.520><c> for</c><00:24:47.670><c> the</c><00:24:47.730><c> next</c><00:24:47.850><c> and</c><00:24:48.270><c> final</c><00:24:48.570><c> part</c>

00:24:48.680 --> 00:24:48.690 align:start position:0%
of salt so for the next and final part
 

00:24:48.690 --> 00:24:50.810 align:start position:0%
of salt so for the next and final part
of<00:24:48.810><c> this</c><00:24:48.930><c> talk</c><00:24:49.200><c> I'd</c><00:24:49.530><c> like</c><00:24:49.920><c> to</c><00:24:50.100><c> address</c><00:24:50.310><c> this</c>

00:24:50.810 --> 00:24:50.820 align:start position:0%
of this talk I'd like to address this
 

00:24:50.820 --> 00:24:53.270 align:start position:0%
of this talk I'd like to address this
notion<00:24:51.120><c> of</c><00:24:51.480><c> learning</c><00:24:51.960><c> to</c><00:24:52.290><c> learn</c><00:24:52.500><c> so</c><00:24:53.040><c> this</c><00:24:53.130><c> is</c><00:24:53.250><c> a</c>

00:24:53.270 --> 00:24:53.280 align:start position:0%
notion of learning to learn so this is a
 

00:24:53.280 --> 00:24:57.980 align:start position:0%
notion of learning to learn so this is a
really<00:24:53.580><c> cool</c><00:24:53.820><c> sounding</c><00:24:54.240><c> topic</c><00:24:55.790><c> it</c><00:24:56.790><c> aims</c><00:24:57.510><c> to</c>

00:24:57.980 --> 00:24:57.990 align:start position:0%
really cool sounding topic it aims to
 

00:24:57.990 --> 00:25:00.440 align:start position:0%
really cool sounding topic it aims to
basically<00:24:58.350><c> learn</c><00:24:59.100><c> not</c><00:24:59.370><c> just</c><00:24:59.580><c> a</c><00:24:59.670><c> single</c><00:24:59.940><c> model</c>

00:25:00.440 --> 00:25:00.450 align:start position:0%
basically learn not just a single model
 

00:25:00.450 --> 00:25:02.480 align:start position:0%
basically learn not just a single model
that's<00:25:00.810><c> optimized</c><00:25:01.560><c> to</c><00:25:01.710><c> perform</c><00:25:02.040><c> a</c><00:25:02.100><c> single</c>

00:25:02.480 --> 00:25:02.490 align:start position:0%
that's optimized to perform a single
 

00:25:02.490 --> 00:25:04.700 align:start position:0%
that's optimized to perform a single
task<00:25:02.670><c> like</c><00:25:03.600><c> we've</c><00:25:03.750><c> learned</c><00:25:03.990><c> basically</c><00:25:04.470><c> and</c>

00:25:04.700 --> 00:25:04.710 align:start position:0%
task like we've learned basically and
 

00:25:04.710 --> 00:25:07.190 align:start position:0%
task like we've learned basically and
all<00:25:04.860><c> of</c><00:25:05.040><c> our</c><00:25:05.550><c> lectures</c><00:25:05.790><c> previous</c><00:25:06.690><c> to</c><00:25:06.840><c> this</c><00:25:06.960><c> one</c>

00:25:07.190 --> 00:25:07.200 align:start position:0%
all of our lectures previous to this one
 

00:25:07.200 --> 00:25:10.220 align:start position:0%
all of our lectures previous to this one
but<00:25:07.890><c> it</c><00:25:08.010><c> learns</c><00:25:08.220><c> how</c><00:25:08.580><c> to</c><00:25:08.610><c> learn</c><00:25:09.120><c> which</c><00:25:09.750><c> model</c>

00:25:10.220 --> 00:25:10.230 align:start position:0%
but it learns how to learn which model
 

00:25:10.230 --> 00:25:14.900 align:start position:0%
but it learns how to learn which model
to<00:25:10.650><c> use</c><00:25:10.860><c> to</c><00:25:11.400><c> train</c><00:25:11.640><c> that</c><00:25:11.670><c> task</c><00:25:13.520><c> so</c><00:25:14.520><c> first</c><00:25:14.730><c> let's</c>

00:25:14.900 --> 00:25:14.910 align:start position:0%
to use to train that task so first let's
 

00:25:14.910 --> 00:25:16.550 align:start position:0%
to use to train that task so first let's
understand<00:25:15.360><c> like</c><00:25:15.570><c> why</c><00:25:15.720><c> we</c><00:25:15.870><c> might</c><00:25:16.050><c> want</c><00:25:16.290><c> to</c><00:25:16.350><c> do</c>

00:25:16.550 --> 00:25:16.560 align:start position:0%
understand like why we might want to do
 

00:25:16.560 --> 00:25:18.140 align:start position:0%
understand like why we might want to do
something<00:25:16.920><c> like</c><00:25:17.040><c> that</c><00:25:17.100><c> I</c><00:25:17.520><c> hope</c><00:25:17.820><c> this</c><00:25:18.000><c> is</c>

00:25:18.140 --> 00:25:18.150 align:start position:0%
something like that I hope this is
 

00:25:18.150 --> 00:25:20.570 align:start position:0%
something like that I hope this is
pretty<00:25:18.360><c> obvious</c><00:25:18.540><c> to</c><00:25:18.900><c> you</c><00:25:18.990><c> by</c><00:25:19.200><c> now</c><00:25:19.380><c> but</c><00:25:20.160><c> humans</c>

00:25:20.570 --> 00:25:20.580 align:start position:0%
pretty obvious to you by now but humans
 

00:25:20.580 --> 00:25:23.270 align:start position:0%
pretty obvious to you by now but humans
are<00:25:20.730><c> not</c><00:25:20.850><c> built</c><00:25:21.270><c> in</c><00:25:21.660><c> a</c><00:25:21.990><c> way</c><00:25:22.130><c> where</c><00:25:23.130><c> we're</c>

00:25:23.270 --> 00:25:23.280 align:start position:0%
are not built in a way where we're
 

00:25:23.280 --> 00:25:26.060 align:start position:0%
are not built in a way where we're
learning<00:25:23.520><c> where</c><00:25:24.180><c> we're</c><00:25:24.500><c> executing</c><00:25:25.500><c> just</c><00:25:26.010><c> a</c>

00:25:26.060 --> 00:25:26.070 align:start position:0%
learning where we're executing just a
 

00:25:26.070 --> 00:25:27.950 align:start position:0%
learning where we're executing just a
single<00:25:26.370><c> task</c><00:25:26.580><c> at</c><00:25:26.790><c> a</c><00:25:26.850><c> time</c><00:25:26.910><c> we're</c><00:25:27.660><c> executing</c>

00:25:27.950 --> 00:25:27.960 align:start position:0%
single task at a time we're executing
 

00:25:27.960 --> 00:25:31.670 align:start position:0%
single task at a time we're executing
many<00:25:28.410><c> many</c><00:25:28.710><c> many</c><00:25:29.010><c> different</c><00:25:29.400><c> tasks</c><00:25:29.850><c> and</c><00:25:30.680><c> all</c>

00:25:31.670 --> 00:25:31.680 align:start position:0%
many many many different tasks and all
 

00:25:31.680 --> 00:25:33.200 align:start position:0%
many many many different tasks and all
of<00:25:31.920><c> these</c><00:25:32.070><c> tasks</c><00:25:32.490><c> are</c><00:25:32.550><c> constantly</c>

00:25:33.200 --> 00:25:33.210 align:start position:0%
of these tasks are constantly
 

00:25:33.210 --> 00:25:35.930 align:start position:0%
of these tasks are constantly
interacting<00:25:33.960><c> with</c><00:25:34.110><c> each</c><00:25:34.140><c> other</c><00:25:34.380><c> in</c><00:25:34.740><c> ways</c><00:25:35.520><c> that</c>

00:25:35.930 --> 00:25:35.940 align:start position:0%
interacting with each other in ways that
 

00:25:35.940 --> 00:25:38.510 align:start position:0%
interacting with each other in ways that
learning<00:25:36.930><c> one</c><00:25:37.110><c> task</c><00:25:37.380><c> can</c><00:25:37.650><c> actually</c><00:25:38.040><c> aid</c>

00:25:38.510 --> 00:25:38.520 align:start position:0%
learning one task can actually aid
 

00:25:38.520 --> 00:25:40.310 align:start position:0%
learning one task can actually aid
speed-up<00:25:39.270><c> or</c><00:25:39.480><c> deter</c><00:25:39.780><c> the</c><00:25:39.960><c> learning</c><00:25:40.260><c> of</c>

00:25:40.310 --> 00:25:40.320 align:start position:0%
speed-up or deter the learning of
 

00:25:40.320 --> 00:25:43.790 align:start position:0%
speed-up or deter the learning of
another<00:25:40.620><c> task</c><00:25:40.890><c> at</c><00:25:41.070><c> any</c><00:25:41.280><c> given</c><00:25:41.430><c> time</c><00:25:42.800><c> modern</c>

00:25:43.790 --> 00:25:43.800 align:start position:0%
another task at any given time modern
 

00:25:43.800 --> 00:25:45.050 align:start position:0%
another task at any given time modern
deep<00:25:43.980><c> neural</c><00:25:44.130><c> network</c><00:25:44.490><c> architectures</c><00:25:45.030><c> are</c>

00:25:45.050 --> 00:25:45.060 align:start position:0%
deep neural network architectures are
 

00:25:45.060 --> 00:25:46.550 align:start position:0%
deep neural network architectures are
not<00:25:45.330><c> like</c><00:25:45.510><c> this</c><00:25:45.720><c> they're</c><00:25:45.930><c> optimized</c><00:25:46.350><c> for</c><00:25:46.500><c> a</c>

00:25:46.550 --> 00:25:46.560 align:start position:0%
not like this they're optimized for a
 

00:25:46.560 --> 00:25:48.170 align:start position:0%
not like this they're optimized for a
single<00:25:46.860><c> task</c><00:25:47.070><c> and</c><00:25:47.370><c> this</c><00:25:47.490><c> goes</c><00:25:47.670><c> back</c><00:25:47.880><c> to</c><00:25:47.910><c> the</c>

00:25:48.170 --> 00:25:48.180 align:start position:0%
single task and this goes back to the
 

00:25:48.180 --> 00:25:49.400 align:start position:0%
single task and this goes back to the
very<00:25:48.360><c> beginning</c><00:25:48.720><c> of</c><00:25:48.750><c> this</c><00:25:48.870><c> talk</c><00:25:49.110><c> where</c><00:25:49.320><c> we</c>

00:25:49.400 --> 00:25:49.410 align:start position:0%
very beginning of this talk where we
 

00:25:49.410 --> 00:25:50.960 align:start position:0%
very beginning of this talk where we
talked<00:25:49.620><c> about</c><00:25:49.740><c> the</c><00:25:49.920><c> universal</c><00:25:50.400><c> approximator</c>

00:25:50.960 --> 00:25:50.970 align:start position:0%
talked about the universal approximator
 

00:25:50.970 --> 00:25:54.980 align:start position:0%
talked about the universal approximator
and<00:25:52.190><c> as</c><00:25:53.190><c> these</c><00:25:53.730><c> models</c><00:25:54.150><c> become</c><00:25:54.420><c> more</c><00:25:54.660><c> and</c><00:25:54.810><c> more</c>

00:25:54.980 --> 00:25:54.990 align:start position:0%
and as these models become more and more
 

00:25:54.990 --> 00:25:57.170 align:start position:0%
and as these models become more and more
complex<00:25:55.470><c> what</c><00:25:56.280><c> ends</c><00:25:56.520><c> up</c><00:25:56.580><c> happening</c><00:25:56.640><c> is</c><00:25:57.150><c> that</c>

00:25:57.170 --> 00:25:57.180 align:start position:0%
complex what ends up happening is that
 

00:25:57.180 --> 00:25:59.840 align:start position:0%
complex what ends up happening is that
you<00:25:57.690><c> have</c><00:25:57.720><c> to</c><00:25:58.050><c> have</c><00:25:58.170><c> more</c><00:25:58.440><c> and</c><00:25:58.620><c> more</c><00:25:58.850><c> expert</c>

00:25:59.840 --> 00:25:59.850 align:start position:0%
you have to have more and more expert
 

00:25:59.850 --> 00:26:02.030 align:start position:0%
you have to have more and more expert
knowledge<00:26:00.330><c> to</c><00:26:00.840><c> actually</c><00:26:00.990><c> build</c><00:26:01.380><c> and</c><00:26:01.740><c> deploy</c>

00:26:02.030 --> 00:26:02.040 align:start position:0%
knowledge to actually build and deploy
 

00:26:02.040 --> 00:26:03.470 align:start position:0%
knowledge to actually build and deploy
these<00:26:02.220><c> models</c><00:26:02.580><c> in</c><00:26:02.700><c> practice</c><00:26:03.150><c> and</c><00:26:03.390><c> that's</c>

00:26:03.470 --> 00:26:03.480 align:start position:0%
these models in practice and that's
 

00:26:03.480 --> 00:26:05.210 align:start position:0%
these models in practice and that's
exactly<00:26:03.780><c> why</c><00:26:04.080><c> all</c><00:26:04.230><c> of</c><00:26:04.260><c> you</c><00:26:04.470><c> are</c><00:26:04.500><c> here</c><00:26:04.830><c> you're</c>

00:26:05.210 --> 00:26:05.220 align:start position:0%
exactly why all of you are here you're
 

00:26:05.220 --> 00:26:07.010 align:start position:0%
exactly why all of you are here you're
here<00:26:05.490><c> to</c><00:26:05.730><c> basically</c><00:26:06.000><c> get</c><00:26:06.240><c> that</c><00:26:06.420><c> experience</c>

00:26:07.010 --> 00:26:07.020 align:start position:0%
here to basically get that experience
 

00:26:07.020 --> 00:26:09.590 align:start position:0%
here to basically get that experience
such<00:26:07.560><c> that</c><00:26:07.710><c> you</c><00:26:07.890><c> yourselves</c><00:26:08.340><c> can</c><00:26:08.700><c> build</c><00:26:09.450><c> these</c>

00:26:09.590 --> 00:26:09.600 align:start position:0%
such that you yourselves can build these
 

00:26:09.600 --> 00:26:14.120 align:start position:0%
such that you yourselves can build these
deep<00:26:09.810><c> learning</c><00:26:10.080><c> models</c><00:26:12.470><c> so</c><00:26:13.470><c> what</c><00:26:13.620><c> we</c><00:26:13.740><c> want</c><00:26:13.950><c> is</c>

00:26:14.120 --> 00:26:14.130 align:start position:0%
deep learning models so what we want is
 

00:26:14.130 --> 00:26:16.910 align:start position:0%
deep learning models so what we want is
actually<00:26:14.310><c> an</c><00:26:14.990><c> automated</c><00:26:15.990><c> machine</c><00:26:16.290><c> learning</c>

00:26:16.910 --> 00:26:16.920 align:start position:0%
actually an automated machine learning
 

00:26:16.920 --> 00:26:19.070 align:start position:0%
actually an automated machine learning
framework<00:26:17.520><c> where</c><00:26:18.270><c> we</c><00:26:18.300><c> can</c><00:26:18.540><c> actually</c><00:26:18.690><c> learn</c><00:26:19.020><c> to</c>

00:26:19.070 --> 00:26:19.080 align:start position:0%
framework where we can actually learn to
 

00:26:19.080 --> 00:26:20.900 align:start position:0%
framework where we can actually learn to
learn<00:26:19.470><c> and</c><00:26:19.830><c> this</c><00:26:20.040><c> basically</c><00:26:20.400><c> means</c><00:26:20.580><c> we</c><00:26:20.730><c> want</c>

00:26:20.900 --> 00:26:20.910 align:start position:0%
learn and this basically means we want
 

00:26:20.910 --> 00:26:22.850 align:start position:0%
learn and this basically means we want
to<00:26:21.000><c> build</c><00:26:21.180><c> the</c><00:26:21.390><c> model</c><00:26:21.690><c> that</c><00:26:21.870><c> learns</c><00:26:22.170><c> which</c>

00:26:22.850 --> 00:26:22.860 align:start position:0%
to build the model that learns which
 

00:26:22.860 --> 00:26:27.850 align:start position:0%
to build the model that learns which
model<00:26:23.430><c> to</c><00:26:24.300><c> use</c><00:26:24.570><c> given</c><00:26:25.260><c> a</c><00:26:25.500><c> problem</c><00:26:26.070><c> definition</c>

00:26:27.850 --> 00:26:27.860 align:start position:0%
model to use given a problem definition
 

00:26:27.860 --> 00:26:30.230 align:start position:0%
model to use given a problem definition
one<00:26:28.860><c> example</c><00:26:29.160><c> that</c><00:26:29.370><c> I'd</c><00:26:29.460><c> like</c><00:26:29.610><c> to</c><00:26:29.640><c> just</c><00:26:29.910><c> use</c><00:26:30.060><c> as</c>

00:26:30.230 --> 00:26:30.240 align:start position:0%
one example that I'd like to just use as
 

00:26:30.240 --> 00:26:32.150 align:start position:0%
one example that I'd like to just use as
an<00:26:30.390><c> illustration</c><00:26:30.870><c> of</c><00:26:31.110><c> this</c><00:26:31.290><c> idea</c><00:26:31.650><c> so</c><00:26:32.010><c> there</c>

00:26:32.150 --> 00:26:32.160 align:start position:0%
an illustration of this idea so there
 

00:26:32.160 --> 00:26:34.610 align:start position:0%
an illustration of this idea so there
are<00:26:32.250><c> many</c><00:26:32.430><c> ways</c><00:26:32.640><c> that</c><00:26:32.700><c> auto</c><00:26:33.150><c> ml</c><00:26:33.540><c> can</c><00:26:34.470><c> be</c>

00:26:34.610 --> 00:26:34.620 align:start position:0%
are many ways that auto ml can be
 

00:26:34.620 --> 00:26:36.290 align:start position:0%
are many ways that auto ml can be
accomplished<00:26:35.370><c> and</c><00:26:35.640><c> this</c><00:26:35.820><c> is</c><00:26:35.940><c> just</c><00:26:36.090><c> one</c>

00:26:36.290 --> 00:26:36.300 align:start position:0%
accomplished and this is just one
 

00:26:36.300 --> 00:26:37.700 align:start position:0%
accomplished and this is just one
example<00:26:36.330><c> of</c><00:26:36.870><c> those</c><00:26:37.020><c> ways</c><00:26:37.230><c> so</c><00:26:37.440><c> I'd</c><00:26:37.530><c> like</c><00:26:37.650><c> to</c>

00:26:37.700 --> 00:26:37.710 align:start position:0%
example of those ways so I'd like to
 

00:26:37.710 --> 00:26:39.220 align:start position:0%
example of those ways so I'd like to
focus<00:26:38.100><c> on</c><00:26:38.250><c> this</c>

00:26:39.220 --> 00:26:39.230 align:start position:0%
focus on this
 

00:26:39.230 --> 00:26:41.080 align:start position:0%
focus on this
illustration<00:26:40.100><c> here</c><00:26:40.340><c> and</c><00:26:40.550><c> I</c><00:26:40.670><c> like</c><00:26:40.820><c> to</c><00:26:40.940><c> walk</c>

00:26:41.080 --> 00:26:41.090 align:start position:0%
illustration here and I like to walk
 

00:26:41.090 --> 00:26:43.380 align:start position:0%
illustration here and I like to walk
through<00:26:41.390><c> it</c><00:26:41.510><c> it's</c><00:26:41.750><c> just</c><00:26:41.870><c> a</c><00:26:42.080><c> way</c><00:26:42.410><c> that</c><00:26:42.680><c> we</c><00:26:42.800><c> can</c>

00:26:43.380 --> 00:26:43.390 align:start position:0%
through it it's just a way that we can
 

00:26:43.390 --> 00:26:48.040 align:start position:0%
through it it's just a way that we can
learn<00:26:44.390><c> to</c><00:26:44.660><c> learn</c><00:26:45.790><c> so</c><00:26:46.790><c> this</c><00:26:47.270><c> this</c><00:26:47.660><c> system</c>

00:26:48.040 --> 00:26:48.050 align:start position:0%
learn to learn so this this system
 

00:26:48.050 --> 00:26:50.500 align:start position:0%
learn to learn so this this system
focuses<00:26:48.530><c> on</c><00:26:48.710><c> two</c><00:26:49.040><c> parts</c><00:26:49.340><c> the</c><00:26:49.880><c> first</c><00:26:49.910><c> part</c><00:26:50.180><c> is</c>

00:26:50.500 --> 00:26:50.510 align:start position:0%
focuses on two parts the first part is
 

00:26:50.510 --> 00:26:52.570 align:start position:0%
focuses on two parts the first part is
the<00:26:50.540><c> controller</c><00:26:51.020><c> RNN</c><00:26:51.500><c> in</c><00:26:51.710><c> red</c><00:26:52.070><c> on</c><00:26:52.250><c> the</c><00:26:52.370><c> left</c>

00:26:52.570 --> 00:26:52.580 align:start position:0%
the controller RNN in red on the left
 

00:26:52.580 --> 00:26:55.540 align:start position:0%
the controller RNN in red on the left
and<00:26:53.150><c> this</c><00:26:53.960><c> controller</c><00:26:54.350><c> RNN</c><00:26:54.830><c> is</c><00:26:55.040><c> basically</c>

00:26:55.540 --> 00:26:55.550 align:start position:0%
and this controller RNN is basically
 

00:26:55.550 --> 00:26:57.910 align:start position:0%
and this controller RNN is basically
just<00:26:55.970><c> sampling</c><00:26:56.810><c> different</c><00:26:57.110><c> architectures</c><00:26:57.890><c> of</c>

00:26:57.910 --> 00:26:57.920 align:start position:0%
just sampling different architectures of
 

00:26:57.920 --> 00:27:00.070 align:start position:0%
just sampling different architectures of
neural<00:26:58.280><c> networks</c><00:26:58.640><c> so</c><00:26:59.540><c> if</c><00:26:59.630><c> you</c><00:26:59.750><c> remember</c><00:26:59.930><c> in</c>

00:27:00.070 --> 00:27:00.080 align:start position:0%
neural networks so if you remember in
 

00:27:00.080 --> 00:27:02.920 align:start position:0%
neural networks so if you remember in
your<00:27:00.170><c> first</c><00:27:00.470><c> lab</c><00:27:00.740><c> you</c><00:27:01.430><c> created</c><00:27:01.940><c> an</c><00:27:02.060><c> RNN</c><00:27:02.600><c> that</c>

00:27:02.920 --> 00:27:02.930 align:start position:0%
your first lab you created an RNN that
 

00:27:02.930 --> 00:27:06.040 align:start position:0%
your first lab you created an RNN that
could<00:27:03.080><c> sample</c><00:27:03.350><c> different</c><00:27:03.980><c> music</c><00:27:04.370><c> notes</c><00:27:05.050><c> this</c>

00:27:06.040 --> 00:27:06.050 align:start position:0%
could sample different music notes this
 

00:27:06.050 --> 00:27:07.720 align:start position:0%
could sample different music notes this
is<00:27:06.260><c> no</c><00:27:06.440><c> different</c><00:27:06.680><c> except</c><00:27:07.280><c> now</c><00:27:07.430><c> we're</c><00:27:07.610><c> not</c>

00:27:07.720 --> 00:27:07.730 align:start position:0%
is no different except now we're not
 

00:27:07.730 --> 00:27:10.150 align:start position:0%
is no different except now we're not
sampling<00:27:08.120><c> music</c><00:27:08.360><c> notes</c><00:27:08.810><c> we're</c><00:27:09.440><c> sampling</c><00:27:09.860><c> an</c>

00:27:10.150 --> 00:27:10.160 align:start position:0%
sampling music notes we're sampling an
 

00:27:10.160 --> 00:27:13.060 align:start position:0%
sampling music notes we're sampling an
entire<00:27:10.670><c> neural</c><00:27:11.150><c> network</c><00:27:11.480><c> itself</c><00:27:12.380><c> so</c><00:27:12.920><c> we're</c>

00:27:13.060 --> 00:27:13.070 align:start position:0%
entire neural network itself so we're
 

00:27:13.070 --> 00:27:14.680 align:start position:0%
entire neural network itself so we're
sampling<00:27:13.460><c> that</c><00:27:13.610><c> parameters</c><00:27:14.270><c> that</c><00:27:14.510><c> define</c>

00:27:14.680 --> 00:27:14.690 align:start position:0%
sampling that parameters that define
 

00:27:14.690 --> 00:27:17.050 align:start position:0%
sampling that parameters that define
that<00:27:15.110><c> neural</c><00:27:15.440><c> network</c><00:27:15.740><c> so</c><00:27:16.640><c> let's</c><00:27:16.790><c> call</c><00:27:16.910><c> that</c>

00:27:17.050 --> 00:27:17.060 align:start position:0%
that neural network so let's call that
 

00:27:17.060 --> 00:27:18.880 align:start position:0%
that neural network so let's call that
the<00:27:17.210><c> architecture</c><00:27:17.810><c> or</c><00:27:17.930><c> the</c><00:27:17.960><c> child's</c><00:27:18.470><c> network</c>

00:27:18.880 --> 00:27:18.890 align:start position:0%
the architecture or the child's network
 

00:27:18.890 --> 00:27:20.650 align:start position:0%
the architecture or the child's network
so<00:27:19.340><c> that's</c><00:27:19.520><c> the</c><00:27:19.700><c> network</c><00:27:19.970><c> that</c><00:27:20.150><c> will</c><00:27:20.240><c> actually</c>

00:27:20.650 --> 00:27:20.660 align:start position:0%
so that's the network that will actually
 

00:27:20.660 --> 00:27:24.520 align:start position:0%
so that's the network that will actually
be<00:27:20.810><c> used</c><00:27:21.080><c> to</c><00:27:21.500><c> solve</c><00:27:21.680><c> our</c><00:27:21.890><c> task</c><00:27:22.130><c> in</c><00:27:22.340><c> the</c><00:27:22.460><c> end</c><00:27:23.530><c> so</c>

00:27:24.520 --> 00:27:24.530 align:start position:0%
be used to solve our task in the end so
 

00:27:24.530 --> 00:27:26.560 align:start position:0%
be used to solve our task in the end so
that<00:27:24.560><c> network</c><00:27:24.980><c> is</c><00:27:25.130><c> passed</c><00:27:25.400><c> on</c><00:27:25.670><c> to</c><00:27:25.940><c> the</c><00:27:26.210><c> second</c>

00:27:26.560 --> 00:27:26.570 align:start position:0%
that network is passed on to the second
 

00:27:26.570 --> 00:27:30.010 align:start position:0%
that network is passed on to the second
bottle<00:27:27.820><c> so</c><00:27:28.820><c> that</c><00:27:28.970><c> network</c><00:27:29.270><c> is</c><00:27:29.360><c> passed</c><00:27:29.630><c> on</c><00:27:29.840><c> to</c>

00:27:30.010 --> 00:27:30.020 align:start position:0%
bottle so that network is passed on to
 

00:27:30.020 --> 00:27:30.850 align:start position:0%
bottle so that network is passed on to
the<00:27:30.200><c> second</c><00:27:30.560><c> one</c>

00:27:30.850 --> 00:27:30.860 align:start position:0%
the second one
 

00:27:30.860 --> 00:27:35.110 align:start position:0%
the second one
and<00:27:31.540><c> in</c><00:27:32.540><c> that</c><00:27:32.720><c> piece</c><00:27:33.290><c> we</c><00:27:34.220><c> actually</c><00:27:34.640><c> use</c><00:27:34.880><c> that</c>

00:27:35.110 --> 00:27:35.120 align:start position:0%
and in that piece we actually use that
 

00:27:35.120 --> 00:27:37.090 align:start position:0%
and in that piece we actually use that
network<00:27:35.420><c> that</c><00:27:35.450><c> was</c><00:27:35.720><c> generated</c><00:27:36.350><c> by</c><00:27:36.530><c> the</c><00:27:36.590><c> Arnon</c>

00:27:37.090 --> 00:27:37.100 align:start position:0%
network that was generated by the Arnon
 

00:27:37.100 --> 00:27:40.240 align:start position:0%
network that was generated by the Arnon
to<00:27:37.640><c> train</c><00:27:37.940><c> a</c><00:27:38.240><c> model</c><00:27:38.740><c> depending</c><00:27:39.740><c> on</c><00:27:39.800><c> how</c><00:27:40.010><c> well</c>

00:27:40.240 --> 00:27:40.250 align:start position:0%
to train a model depending on how well
 

00:27:40.250 --> 00:27:43.660 align:start position:0%
to train a model depending on how well
that<00:27:40.430><c> model</c><00:27:40.760><c> did</c><00:27:41.980><c> we</c><00:27:42.980><c> can</c><00:27:43.190><c> provide</c><00:27:43.430><c> feedback</c>

00:27:43.660 --> 00:27:43.670 align:start position:0%
that model did we can provide feedback
 

00:27:43.670 --> 00:27:45.970 align:start position:0%
that model did we can provide feedback
to<00:27:44.060><c> the</c><00:27:44.150><c> RNN</c><00:27:44.540><c> such</c><00:27:44.840><c> I</c><00:27:45.020><c> can</c><00:27:45.050><c> produce</c><00:27:45.470><c> an</c><00:27:45.710><c> even</c>

00:27:45.970 --> 00:27:45.980 align:start position:0%
to the RNN such I can produce an even
 

00:27:45.980 --> 00:27:49.630 align:start position:0%
to the RNN such I can produce an even
better<00:27:46.190><c> model</c><00:27:46.610><c> on</c><00:27:46.760><c> the</c><00:27:46.970><c> next</c><00:27:47.210><c> time</c><00:27:47.330><c> step</c><00:27:48.640><c> so</c>

00:27:49.630 --> 00:27:49.640 align:start position:0%
better model on the next time step so
 

00:27:49.640 --> 00:27:51.580 align:start position:0%
better model on the next time step so
let's<00:27:49.820><c> go</c><00:27:50.000><c> into</c><00:27:50.480><c> this</c><00:27:50.630><c> piece</c><00:27:51.080><c> by</c><00:27:51.260><c> piece</c><00:27:51.290><c> so</c>

00:27:51.580 --> 00:27:51.590 align:start position:0%
let's go into this piece by piece so
 

00:27:51.590 --> 00:27:53.590 align:start position:0%
let's go into this piece by piece so
let's<00:27:51.770><c> look</c><00:27:51.860><c> at</c><00:27:52.010><c> just</c><00:27:52.040><c> the</c><00:27:52.340><c> RNN</c><00:27:52.730><c> part</c><00:27:53.030><c> in</c><00:27:53.240><c> more</c>

00:27:53.590 --> 00:27:53.600 align:start position:0%
let's look at just the RNN part in more
 

00:27:53.600 --> 00:27:56.050 align:start position:0%
let's look at just the RNN part in more
detail<00:27:53.960><c> so</c><00:27:54.830><c> this</c><00:27:54.950><c> is</c><00:27:55.100><c> the</c><00:27:55.310><c> RNN</c><00:27:55.730><c> or</c><00:27:55.910><c> the</c>

00:27:56.050 --> 00:27:56.060 align:start position:0%
detail so this is the RNN or the
 

00:27:56.060 --> 00:27:58.450 align:start position:0%
detail so this is the RNN or the
architecture<00:27:56.570><c> generator</c><00:27:57.170><c> so</c><00:27:57.950><c> like</c><00:27:58.130><c> I</c><00:27:58.250><c> said</c>

00:27:58.450 --> 00:27:58.460 align:start position:0%
architecture generator so like I said
 

00:27:58.460 --> 00:28:00.100 align:start position:0%
architecture generator so like I said
this<00:27:58.520><c> is</c><00:27:58.670><c> very</c><00:27:58.730><c> similar</c><00:27:59.390><c> to</c><00:27:59.630><c> the</c><00:27:59.720><c> way</c><00:27:59.840><c> that</c><00:27:59.870><c> you</c>

00:28:00.100 --> 00:28:00.110 align:start position:0%
this is very similar to the way that you
 

00:28:00.110 --> 00:28:01.960 align:start position:0%
this is very similar to the way that you
are<00:28:00.140><c> generating</c><00:28:00.500><c> songs</c><00:28:01.130><c> in</c><00:28:01.430><c> your</c><00:28:01.460><c> first</c><00:28:01.760><c> lab</c>

00:28:01.960 --> 00:28:01.970 align:start position:0%
are generating songs in your first lab
 

00:28:01.970 --> 00:28:04.050 align:start position:0%
are generating songs in your first lab
except<00:28:02.720><c> now</c><00:28:02.840><c> we're</c><00:28:02.990><c> not</c><00:28:03.110><c> generating</c><00:28:03.530><c> songs</c>

00:28:04.050 --> 00:28:04.060 align:start position:0%
except now we're not generating songs
 

00:28:04.060 --> 00:28:07.300 align:start position:0%
except now we're not generating songs
the<00:28:05.060><c> time</c><00:28:05.360><c> steps</c><00:28:05.720><c> are</c><00:28:06.050><c> going</c><00:28:06.350><c> from</c><00:28:06.560><c> layers</c><00:28:06.920><c> on</c>

00:28:07.300 --> 00:28:07.310 align:start position:0%
the time steps are going from layers on
 

00:28:07.310 --> 00:28:10.980 align:start position:0%
the time steps are going from layers on
the<00:28:07.490><c> x-axis</c><00:28:07.820><c> and</c><00:28:08.920><c> we're</c><00:28:09.920><c> just</c><00:28:10.070><c> generating</c>

00:28:10.980 --> 00:28:10.990 align:start position:0%
the x-axis and we're just generating
 

00:28:10.990 --> 00:28:13.200 align:start position:0%
the x-axis and we're just generating
parameters<00:28:11.990><c> or</c>

00:28:13.200 --> 00:28:13.210 align:start position:0%
parameters or
 

00:28:13.210 --> 00:28:16.150 align:start position:0%
parameters or
hyper<00:28:14.210><c> parameters</c><00:28:14.780><c> rather</c><00:28:15.020><c> for</c><00:28:15.890><c> each</c><00:28:16.010><c> of</c>

00:28:16.150 --> 00:28:16.160 align:start position:0%
hyper parameters rather for each of
 

00:28:16.160 --> 00:28:18.370 align:start position:0%
hyper parameters rather for each of
those<00:28:16.280><c> layers</c><00:28:16.490><c> so</c><00:28:16.880><c> this</c><00:28:17.060><c> is</c><00:28:17.210><c> a</c><00:28:17.390><c> generator</c><00:28:18.170><c> for</c>

00:28:18.370 --> 00:28:18.380 align:start position:0%
those layers so this is a generator for
 

00:28:18.380 --> 00:28:20.680 align:start position:0%
those layers so this is a generator for
a<00:28:18.440><c> convolutional</c><00:28:19.070><c> neural</c><00:28:19.250><c> network</c><00:28:19.700><c> because</c>

00:28:20.680 --> 00:28:20.690 align:start position:0%
a convolutional neural network because
 

00:28:20.690 --> 00:28:22.000 align:start position:0%
a convolutional neural network because
we're<00:28:20.870><c> producing</c><00:28:21.350><c> parameters</c><00:28:21.830><c> like</c><00:28:21.950><c> the</c>

00:28:22.000 --> 00:28:22.010 align:start position:0%
we're producing parameters like the
 

00:28:22.010 --> 00:28:23.500 align:start position:0%
we're producing parameters like the
filter<00:28:22.400><c> height</c><00:28:22.610><c> the</c><00:28:22.790><c> filter</c><00:28:23.120><c> width</c><00:28:23.300><c> the</c>

00:28:23.500 --> 00:28:23.510 align:start position:0%
filter height the filter width the
 

00:28:23.510 --> 00:28:26.920 align:start position:0%
filter height the filter width the
stride<00:28:23.780><c> height</c><00:28:23.990><c> etc</c><00:28:25.240><c> so</c><00:28:26.240><c> what</c><00:28:26.420><c> we</c><00:28:26.540><c> can</c><00:28:26.690><c> do</c><00:28:26.810><c> is</c>

00:28:26.920 --> 00:28:26.930 align:start position:0%
stride height etc so what we can do is
 

00:28:26.930 --> 00:28:28.750 align:start position:0%
stride height etc so what we can do is
we<00:28:27.080><c> can</c><00:28:27.200><c> add</c><00:28:27.410><c> each</c><00:28:27.650><c> time</c><00:28:27.950><c> step</c><00:28:28.100><c> produce</c><00:28:28.400><c> a</c>

00:28:28.750 --> 00:28:28.760 align:start position:0%
we can add each time step produce a
 

00:28:28.760 --> 00:28:31.000 align:start position:0%
we can add each time step produce a
probability<00:28:29.510><c> distribution</c><00:28:29.780><c> of</c><00:28:30.350><c> over</c><00:28:30.500><c> each</c><00:28:30.860><c> of</c>

00:28:31.000 --> 00:28:31.010 align:start position:0%
probability distribution of over each of
 

00:28:31.010 --> 00:28:32.890 align:start position:0%
probability distribution of over each of
these<00:28:31.130><c> parameters</c><00:28:31.670><c> and</c><00:28:31.880><c> we</c><00:28:32.360><c> can</c><00:28:32.510><c> essentially</c>

00:28:32.890 --> 00:28:32.900 align:start position:0%
these parameters and we can essentially
 

00:28:32.900 --> 00:28:34.840 align:start position:0%
these parameters and we can essentially
just<00:28:33.020><c> sample</c><00:28:33.530><c> an</c><00:28:33.680><c> architecture</c><00:28:34.280><c> or</c><00:28:34.400><c> sample</c><00:28:34.790><c> a</c>

00:28:34.840 --> 00:28:34.850 align:start position:0%
just sample an architecture or sample a
 

00:28:34.850 --> 00:28:37.360 align:start position:0%
just sample an architecture or sample a
child<00:28:35.120><c> Network</c><00:28:35.590><c> once</c><00:28:36.590><c> we</c><00:28:36.770><c> have</c><00:28:36.920><c> that</c><00:28:36.950><c> child</c>

00:28:37.360 --> 00:28:37.370 align:start position:0%
child Network once we have that child
 

00:28:37.370 --> 00:28:39.310 align:start position:0%
child Network once we have that child
Network<00:28:37.790><c> which</c><00:28:38.450><c> I'm</c><00:28:38.600><c> showing</c><00:28:38.780><c> right</c><00:28:39.050><c> here</c><00:28:39.110><c> in</c>

00:28:39.310 --> 00:28:39.320 align:start position:0%
Network which I'm showing right here in
 

00:28:39.320 --> 00:28:44.080 align:start position:0%
Network which I'm showing right here in
blue<00:28:39.640><c> we</c><00:28:40.640><c> can</c><00:28:40.820><c> train</c><00:28:41.150><c> it</c><00:28:41.360><c> using</c><00:28:42.290><c> our</c><00:28:42.820><c> data</c><00:28:43.820><c> set</c>

00:28:44.080 --> 00:28:44.090 align:start position:0%
blue we can train it using our data set
 

00:28:44.090 --> 00:28:46.390 align:start position:0%
blue we can train it using our data set
that<00:28:44.120><c> we</c><00:28:44.360><c> ultimately</c><00:28:44.480><c> want</c><00:28:44.930><c> to</c><00:28:44.990><c> solve</c><00:28:45.280><c> so</c><00:28:46.280><c> we</c>

00:28:46.390 --> 00:28:46.400 align:start position:0%
that we ultimately want to solve so we
 

00:28:46.400 --> 00:28:48.430 align:start position:0%
that we ultimately want to solve so we
put<00:28:46.610><c> our</c><00:28:46.700><c> training</c><00:28:47.000><c> data</c><00:28:47.180><c> in</c><00:28:47.390><c> and</c><00:28:47.720><c> we</c><00:28:48.170><c> get</c><00:28:48.320><c> our</c>

00:28:48.430 --> 00:28:48.440 align:start position:0%
put our training data in and we get our
 

00:28:48.440 --> 00:28:50.590 align:start position:0%
put our training data in and we get our
predicted<00:28:48.860><c> labels</c><00:28:49.160><c> out</c><00:28:49.310><c> this</c><00:28:49.520><c> is</c><00:28:49.700><c> the</c><00:28:49.940><c> this</c><00:28:50.420><c> is</c>

00:28:50.590 --> 00:28:50.600 align:start position:0%
predicted labels out this is the this is
 

00:28:50.600 --> 00:28:51.850 align:start position:0%
predicted labels out this is the this is
the<00:28:50.750><c> realm</c><00:28:50.990><c> that</c><00:28:51.140><c> we've</c><00:28:51.380><c> been</c><00:28:51.500><c> dealing</c><00:28:51.680><c> with</c>

00:28:51.850 --> 00:28:51.860 align:start position:0%
the realm that we've been dealing with
 

00:28:51.860 --> 00:28:53.220 align:start position:0%
the realm that we've been dealing with
so<00:28:52.130><c> far</c><00:28:52.370><c> in</c><00:28:52.550><c> this</c>

00:28:53.220 --> 00:28:53.230 align:start position:0%
so far in this
 

00:28:53.230 --> 00:28:55.680 align:start position:0%
so far in this
right<00:28:53.920><c> so</c><00:28:54.100><c> we</c><00:28:54.220><c> have</c><00:28:54.370><c> our</c><00:28:54.400><c> this</c><00:28:54.880><c> is</c><00:28:55.060><c> basically</c>

00:28:55.680 --> 00:28:55.690 align:start position:0%
right so we have our this is basically
 

00:28:55.690 --> 00:28:57.540 align:start position:0%
right so we have our this is basically
what<00:28:55.960><c> we've</c><00:28:56.140><c> seen</c><00:28:56.470><c> so</c><00:28:56.710><c> far</c><00:28:56.740><c> so</c><00:28:57.070><c> this</c><00:28:57.190><c> is</c><00:28:57.310><c> just</c><00:28:57.490><c> a</c>

00:28:57.540 --> 00:28:57.550 align:start position:0%
what we've seen so far so this is just a
 

00:28:57.550 --> 00:28:59.460 align:start position:0%
what we've seen so far so this is just a
single<00:28:57.880><c> network</c><00:28:58.180><c> and</c><00:28:58.900><c> we</c><00:28:58.990><c> have</c><00:28:59.170><c> our</c><00:28:59.290><c> training</c>

00:28:59.460 --> 00:28:59.470 align:start position:0%
single network and we have our training
 

00:28:59.470 --> 00:29:02.940 align:start position:0%
single network and we have our training
data<00:28:59.770><c> that</c><00:28:59.890><c> we're</c><00:29:00.160><c> using</c><00:29:00.340><c> to</c><00:29:00.610><c> Train</c><00:29:00.820><c> it</c><00:29:01.740><c> we</c><00:29:02.740><c> see</c>

00:29:02.940 --> 00:29:02.950 align:start position:0%
data that we're using to Train it we see
 

00:29:02.950 --> 00:29:05.400 align:start position:0%
data that we're using to Train it we see
how<00:29:03.100><c> well</c><00:29:03.310><c> this</c><00:29:03.580><c> does</c><00:29:04.230><c> depending</c><00:29:05.230><c> on</c><00:29:05.320><c> the</c>

00:29:05.400 --> 00:29:05.410 align:start position:0%
how well this does depending on the
 

00:29:05.410 --> 00:29:08.220 align:start position:0%
how well this does depending on the
accuracy<00:29:06.010><c> of</c><00:29:06.040><c> this</c><00:29:06.280><c> model</c><00:29:06.790><c> that</c><00:29:07.050><c> accuracy</c><00:29:08.050><c> is</c>

00:29:08.220 --> 00:29:08.230 align:start position:0%
accuracy of this model that accuracy is
 

00:29:08.230 --> 00:29:11.460 align:start position:0%
accuracy of this model that accuracy is
used<00:29:08.710><c> to</c><00:29:09.430><c> provide</c><00:29:09.700><c> feedback</c><00:29:10.030><c> back</c><00:29:10.690><c> to</c><00:29:10.750><c> the</c><00:29:10.930><c> RNN</c>

00:29:11.460 --> 00:29:11.470 align:start position:0%
used to provide feedback back to the RNN
 

00:29:11.470 --> 00:29:14.550 align:start position:0%
used to provide feedback back to the RNN
and<00:29:11.680><c> update</c><00:29:12.430><c> how</c><00:29:13.240><c> it</c><00:29:13.480><c> produces</c><00:29:13.690><c> or</c><00:29:14.230><c> how</c><00:29:14.410><c> it</c>

00:29:14.550 --> 00:29:14.560 align:start position:0%
and update how it produces or how it
 

00:29:14.560 --> 00:29:19.290 align:start position:0%
and update how it produces or how it
generates<00:29:14.920><c> these</c><00:29:15.160><c> models</c><00:29:17.460><c> so</c><00:29:18.460><c> let's</c><00:29:18.640><c> look</c><00:29:19.150><c> at</c>

00:29:19.290 --> 00:29:19.300 align:start position:0%
generates these models so let's look at
 

00:29:19.300 --> 00:29:21.690 align:start position:0%
generates these models so let's look at
this<00:29:19.420><c> one</c><00:29:19.630><c> more</c><00:29:19.780><c> time</c><00:29:19.990><c> to</c><00:29:20.140><c> summarize</c><00:29:20.530><c> this</c><00:29:21.520><c> is</c>

00:29:21.690 --> 00:29:21.700 align:start position:0%
this one more time to summarize this is
 

00:29:21.700 --> 00:29:23.430 align:start position:0%
this one more time to summarize this is
an<00:29:21.850><c> extremely</c><00:29:22.270><c> powerful</c><00:29:22.540><c> idea</c><00:29:23.140><c> it's</c><00:29:23.380><c> really</c>

00:29:23.430 --> 00:29:23.440 align:start position:0%
an extremely powerful idea it's really
 

00:29:23.440 --> 00:29:25.830 align:start position:0%
an extremely powerful idea it's really
really<00:29:24.070><c> really</c><00:29:24.280><c> exciting</c><00:29:24.490><c> because</c><00:29:25.060><c> it</c><00:29:25.450><c> shows</c>

00:29:25.830 --> 00:29:25.840 align:start position:0%
really really exciting because it shows
 

00:29:25.840 --> 00:29:29.100 align:start position:0%
really really exciting because it shows
that<00:29:25.870><c> an</c><00:29:26.520><c> RNN</c><00:29:27.520><c> can</c><00:29:28.150><c> be</c><00:29:28.270><c> actually</c><00:29:28.540><c> combined</c><00:29:28.960><c> in</c>

00:29:29.100 --> 00:29:29.110 align:start position:0%
that an RNN can be actually combined in
 

00:29:29.110 --> 00:29:31.620 align:start position:0%
that an RNN can be actually combined in
a<00:29:29.200><c> reinforcement</c><00:29:29.860><c> learning</c><00:29:29.950><c> paradigm</c><00:29:30.640><c> where</c>

00:29:31.620 --> 00:29:31.630 align:start position:0%
a reinforcement learning paradigm where
 

00:29:31.630 --> 00:29:33.720 align:start position:0%
a reinforcement learning paradigm where
the<00:29:31.840><c> R</c><00:29:32.080><c> and</c><00:29:32.380><c> n</c><00:29:32.470><c> itself</c><00:29:32.860><c> is</c><00:29:33.130><c> almost</c><00:29:33.340><c> like</c><00:29:33.550><c> the</c>

00:29:33.720 --> 00:29:33.730 align:start position:0%
the R and n itself is almost like the
 

00:29:33.730 --> 00:29:35.610 align:start position:0%
the R and n itself is almost like the
agent<00:29:34.150><c> in</c><00:29:34.360><c> reinforcement</c><00:29:35.230><c> learning</c><00:29:35.260><c> it's</c>

00:29:35.610 --> 00:29:35.620 align:start position:0%
agent in reinforcement learning it's
 

00:29:35.620 --> 00:29:39.420 align:start position:0%
agent in reinforcement learning it's
learning<00:29:35.950><c> to</c><00:29:36.790><c> make</c><00:29:37.750><c> changes</c><00:29:38.320><c> to</c><00:29:38.380><c> the</c><00:29:38.740><c> child</c>

00:29:39.420 --> 00:29:39.430 align:start position:0%
learning to make changes to the child
 

00:29:39.430 --> 00:29:41.700 align:start position:0%
learning to make changes to the child
network<00:29:39.850><c> architecture</c><00:29:40.600><c> depending</c><00:29:41.440><c> on</c><00:29:41.500><c> how</c>

00:29:41.700 --> 00:29:41.710 align:start position:0%
network architecture depending on how
 

00:29:41.710 --> 00:29:43.560 align:start position:0%
network architecture depending on how
that<00:29:41.770><c> child</c><00:29:42.250><c> network</c><00:29:42.640><c> performs</c><00:29:43.240><c> on</c><00:29:43.510><c> a</c>

00:29:43.560 --> 00:29:43.570 align:start position:0%
that child network performs on a
 

00:29:43.570 --> 00:29:47.460 align:start position:0%
that child network performs on a
training<00:29:44.230><c> set</c><00:29:45.900><c> this</c><00:29:46.900><c> means</c><00:29:47.080><c> that</c><00:29:47.200><c> we're</c><00:29:47.350><c> able</c>

00:29:47.460 --> 00:29:47.470 align:start position:0%
training set this means that we're able
 

00:29:47.470 --> 00:29:49.290 align:start position:0%
training set this means that we're able
to<00:29:47.680><c> create</c><00:29:47.830><c> an</c><00:29:48.070><c> AI</c><00:29:48.250><c> system</c><00:29:48.790><c> capable</c><00:29:49.210><c> of</c>

00:29:49.290 --> 00:29:49.300 align:start position:0%
to create an AI system capable of
 

00:29:49.300 --> 00:29:51.560 align:start position:0%
to create an AI system capable of
generating<00:29:49.650><c> brand-new</c><00:29:50.650><c> neural</c><00:29:51.010><c> networks</c>

00:29:51.560 --> 00:29:51.570 align:start position:0%
generating brand-new neural networks
 

00:29:51.570 --> 00:29:53.880 align:start position:0%
generating brand-new neural networks
specialized<00:29:52.570><c> to</c><00:29:52.720><c> solve</c><00:29:52.960><c> specific</c><00:29:53.440><c> tasks</c>

00:29:53.880 --> 00:29:53.890 align:start position:0%
specialized to solve specific tasks
 

00:29:53.890 --> 00:29:55.740 align:start position:0%
specialized to solve specific tasks
rather<00:29:54.430><c> than</c><00:29:54.730><c> just</c><00:29:54.970><c> creating</c><00:29:55.360><c> a</c><00:29:55.420><c> single</c>

00:29:55.740 --> 00:29:55.750 align:start position:0%
rather than just creating a single
 

00:29:55.750 --> 00:29:58.050 align:start position:0%
rather than just creating a single
neural<00:29:55.900><c> network</c><00:29:56.290><c> that</c><00:29:56.530><c> we</c><00:29:56.980><c> create</c><00:29:57.370><c> just</c><00:29:57.910><c> to</c>

00:29:58.050 --> 00:29:58.060 align:start position:0%
neural network that we create just to
 

00:29:58.060 --> 00:29:59.430 align:start position:0%
neural network that we create just to
solve<00:29:58.240><c> that</c><00:29:58.390><c> tasks</c><00:29:58.780><c> that</c><00:29:58.870><c> we</c><00:29:59.020><c> want</c><00:29:59.200><c> to</c><00:29:59.260><c> create</c>

00:29:59.430 --> 00:29:59.440 align:start position:0%
solve that tasks that we want to create
 

00:29:59.440 --> 00:30:01.310 align:start position:0%
solve that tasks that we want to create
that<00:29:59.800><c> we</c><00:30:00.070><c> want</c><00:30:00.250><c> to</c><00:30:00.340><c> solve</c>

00:30:01.310 --> 00:30:01.320 align:start position:0%
that we want to solve
 

00:30:01.320 --> 00:30:03.960 align:start position:0%
that we want to solve
thus<00:30:02.320><c> this</c><00:30:02.560><c> has</c><00:30:02.740><c> significantly</c><00:30:03.430><c> reduced</c><00:30:03.610><c> the</c>

00:30:03.960 --> 00:30:03.970 align:start position:0%
thus this has significantly reduced the
 

00:30:03.970 --> 00:30:06.060 align:start position:0%
thus this has significantly reduced the
difficulty<00:30:04.600><c> in</c><00:30:04.690><c> optimizing</c><00:30:05.200><c> these</c><00:30:05.740><c> neural</c>

00:30:06.060 --> 00:30:06.070 align:start position:0%
difficulty in optimizing these neural
 

00:30:06.070 --> 00:30:09.390 align:start position:0%
difficulty in optimizing these neural
networks<00:30:06.400><c> for</c><00:30:07.800><c> architectures</c><00:30:08.800><c> for</c><00:30:09.040><c> different</c>

00:30:09.390 --> 00:30:09.400 align:start position:0%
networks for architectures for different
 

00:30:09.400 --> 00:30:11.580 align:start position:0%
networks for architectures for different
tasks<00:30:09.790><c> and</c><00:30:09.910><c> this</c><00:30:10.210><c> also</c><00:30:10.390><c> reduces</c><00:30:10.600><c> the</c><00:30:10.930><c> need</c><00:30:11.320><c> for</c>

00:30:11.580 --> 00:30:11.590 align:start position:0%
tasks and this also reduces the need for
 

00:30:11.590 --> 00:30:13.560 align:start position:0%
tasks and this also reduces the need for
expert<00:30:12.190><c> engineers</c><00:30:12.670><c> to</c><00:30:12.910><c> design</c><00:30:13.390><c> these</c>

00:30:13.560 --> 00:30:13.570 align:start position:0%
expert engineers to design these
 

00:30:13.570 --> 00:30:16.770 align:start position:0%
expert engineers to design these
architectures<00:30:15.090><c> so</c><00:30:16.090><c> this</c><00:30:16.210><c> really</c><00:30:16.360><c> gets</c><00:30:16.600><c> at</c><00:30:16.690><c> the</c>

00:30:16.770 --> 00:30:16.780 align:start position:0%
architectures so this really gets at the
 

00:30:16.780 --> 00:30:19.770 align:start position:0%
architectures so this really gets at the
heart<00:30:16.810><c> of</c><00:30:17.260><c> artificial</c><00:30:18.250><c> intelligence</c><00:30:18.790><c> so</c><00:30:19.630><c> when</c>

00:30:19.770 --> 00:30:19.780 align:start position:0%
heart of artificial intelligence so when
 

00:30:19.780 --> 00:30:22.560 align:start position:0%
heart of artificial intelligence so when
I<00:30:19.810><c> began</c><00:30:20.140><c> this</c><00:30:20.320><c> course</c><00:30:20.910><c> we</c><00:30:21.910><c> spoke</c><00:30:22.150><c> about</c><00:30:22.360><c> what</c>

00:30:22.560 --> 00:30:22.570 align:start position:0%
I began this course we spoke about what
 

00:30:22.570 --> 00:30:24.770 align:start position:0%
I began this course we spoke about what
it<00:30:22.690><c> actually</c><00:30:22.720><c> means</c><00:30:23.170><c> to</c><00:30:23.410><c> be</c><00:30:23.530><c> intelligent</c><00:30:24.250><c> and</c>

00:30:24.770 --> 00:30:24.780 align:start position:0%
it actually means to be intelligent and
 

00:30:24.780 --> 00:30:27.030 align:start position:0%
it actually means to be intelligent and
loosely<00:30:25.780><c> I</c><00:30:25.810><c> defined</c><00:30:26.230><c> this</c><00:30:26.350><c> as</c><00:30:26.470><c> the</c><00:30:26.620><c> ability</c><00:30:26.800><c> to</c>

00:30:27.030 --> 00:30:27.040 align:start position:0%
loosely I defined this as the ability to
 

00:30:27.040 --> 00:30:28.920 align:start position:0%
loosely I defined this as the ability to
take<00:30:27.310><c> information</c><00:30:27.780><c> process</c><00:30:28.780><c> that</c>

00:30:28.920 --> 00:30:28.930 align:start position:0%
take information process that
 

00:30:28.930 --> 00:30:32.340 align:start position:0%
take information process that
information<00:30:29.080><c> and</c><00:30:29.650><c> use</c><00:30:29.830><c> it</c><00:30:30.570><c> to</c><00:30:31.570><c> inform</c><00:30:31.990><c> future</c>

00:30:32.340 --> 00:30:32.350 align:start position:0%
information and use it to inform future
 

00:30:32.350 --> 00:30:37.590 align:start position:0%
information and use it to inform future
decisions<00:30:35.220><c> so</c><00:30:36.220><c> the</c><00:30:36.670><c> human</c><00:30:36.970><c> learning</c><00:30:37.090><c> pipeline</c>

00:30:37.590 --> 00:30:37.600 align:start position:0%
decisions so the human learning pipeline
 

00:30:37.600 --> 00:30:39.480 align:start position:0%
decisions so the human learning pipeline
is<00:30:37.750><c> not</c><00:30:37.930><c> restricted</c><00:30:38.530><c> to</c><00:30:38.620><c> solving</c><00:30:39.040><c> just</c><00:30:39.070><c> one</c>

00:30:39.480 --> 00:30:39.490 align:start position:0%
is not restricted to solving just one
 

00:30:39.490 --> 00:30:41.160 align:start position:0%
is not restricted to solving just one
task<00:30:39.760><c> at</c><00:30:40.150><c> a</c><00:30:40.240><c> time</c><00:30:40.450><c> like</c><00:30:40.690><c> I</c><00:30:40.810><c> mentioned</c><00:30:41.140><c> before</c>

00:30:41.160 --> 00:30:41.170 align:start position:0%
task at a time like I mentioned before
 

00:30:41.170 --> 00:30:43.580 align:start position:0%
task at a time like I mentioned before
how<00:30:41.680><c> we</c><00:30:41.740><c> learn</c><00:30:42.070><c> one</c><00:30:42.310><c> task</c><00:30:42.550><c> can</c><00:30:42.760><c> greatly</c><00:30:42.970><c> impact</c>

00:30:43.580 --> 00:30:43.590 align:start position:0%
how we learn one task can greatly impact
 

00:30:43.590 --> 00:30:47.190 align:start position:0%
how we learn one task can greatly impact
speed<00:30:44.590><c> up</c><00:30:44.800><c> or</c><00:30:45.010><c> even</c><00:30:45.580><c> slow</c><00:30:45.910><c> down</c><00:30:45.940><c> our</c><00:30:46.420><c> learning</c>

00:30:47.190 --> 00:30:47.200 align:start position:0%
speed up or even slow down our learning
 

00:30:47.200 --> 00:30:50.190 align:start position:0%
speed up or even slow down our learning
of<00:30:47.320><c> other</c><00:30:47.500><c> tasks</c><00:30:48.070><c> and</c><00:30:48.480><c> the</c><00:30:49.480><c> artificial</c><00:30:49.750><c> models</c>

00:30:50.190 --> 00:30:50.200 align:start position:0%
of other tasks and the artificial models
 

00:30:50.200 --> 00:30:51.690 align:start position:0%
of other tasks and the artificial models
that<00:30:50.320><c> we</c><00:30:50.410><c> create</c><00:30:50.710><c> today</c><00:30:50.950><c> simply</c><00:30:51.280><c> do</c><00:30:51.550><c> not</c>

00:30:51.690 --> 00:30:51.700 align:start position:0%
that we create today simply do not
 

00:30:51.700 --> 00:30:54.030 align:start position:0%
that we create today simply do not
capture<00:30:51.940><c> this</c><00:30:52.240><c> phenomenon</c><00:30:52.890><c> to</c><00:30:53.890><c> reach</c>

00:30:54.030 --> 00:30:54.040 align:start position:0%
capture this phenomenon to reach
 

00:30:54.040 --> 00:30:56.040 align:start position:0%
capture this phenomenon to reach
artificial<00:30:54.880><c> general</c><00:30:55.120><c> intelligence</c><00:30:55.360><c> we</c><00:30:55.960><c> need</c>

00:30:56.040 --> 00:30:56.050 align:start position:0%
artificial general intelligence we need
 

00:30:56.050 --> 00:30:58.320 align:start position:0%
artificial general intelligence we need
to<00:30:56.200><c> actually</c><00:30:56.350><c> build</c><00:30:56.770><c> AI</c><00:30:57.250><c> that</c><00:30:57.790><c> can</c><00:30:58.030><c> not</c><00:30:58.150><c> only</c>

00:30:58.320 --> 00:30:58.330 align:start position:0%
to actually build AI that can not only
 

00:30:58.330 --> 00:31:01.560 align:start position:0%
to actually build AI that can not only
learn<00:30:58.570><c> a</c><00:30:58.630><c> single</c><00:30:58.930><c> task</c><00:30:59.760><c> but</c><00:31:00.760><c> also</c><00:31:01.180><c> be</c><00:31:01.300><c> able</c><00:31:01.390><c> to</c>

00:31:01.560 --> 00:31:01.570 align:start position:0%
learn a single task but also be able to
 

00:31:01.570 --> 00:31:03.870 align:start position:0%
learn a single task but also be able to
improve<00:31:01.900><c> its</c><00:31:02.140><c> own</c><00:31:02.350><c> learning</c><00:31:03.010><c> and</c><00:31:03.220><c> reasoning</c>

00:31:03.870 --> 00:31:03.880 align:start position:0%
improve its own learning and reasoning
 

00:31:03.880 --> 00:31:05.880 align:start position:0%
improve its own learning and reasoning
such<00:31:04.330><c> that</c><00:31:04.480><c> it</c><00:31:04.570><c> can</c><00:31:04.690><c> generalize</c><00:31:05.170><c> two</c><00:31:05.470><c> sets</c><00:31:05.740><c> of</c>

00:31:05.880 --> 00:31:05.890 align:start position:0%
such that it can generalize two sets of
 

00:31:05.890 --> 00:31:06.720 align:start position:0%
such that it can generalize two sets of
related

00:31:06.720 --> 00:31:06.730 align:start position:0%
related
 

00:31:06.730 --> 00:31:10.080 align:start position:0%
related
dependent<00:31:07.419><c> tasks</c><00:31:08.370><c> I'll</c><00:31:09.370><c> leave</c><00:31:09.610><c> this</c><00:31:09.760><c> with</c><00:31:09.940><c> you</c>

00:31:10.080 --> 00:31:10.090 align:start position:0%
dependent tasks I'll leave this with you
 

00:31:10.090 --> 00:31:11.789 align:start position:0%
dependent tasks I'll leave this with you
as<00:31:10.179><c> a</c><00:31:10.210><c> thought-provoking</c><00:31:10.990><c> point</c><00:31:11.559><c> and</c>

00:31:11.789 --> 00:31:11.799 align:start position:0%
as a thought-provoking point and
 

00:31:11.799 --> 00:31:14.370 align:start position:0%
as a thought-provoking point and
encourage<00:31:12.160><c> you</c><00:31:12.340><c> to</c><00:31:12.510><c> to</c><00:31:13.510><c> all</c><00:31:13.780><c> talk</c><00:31:14.140><c> to</c><00:31:14.320><c> each</c>

00:31:14.370 --> 00:31:14.380 align:start position:0%
encourage you to to all talk to each
 

00:31:14.380 --> 00:31:16.169 align:start position:0%
encourage you to to all talk to each
other<00:31:14.590><c> on</c><00:31:14.890><c> some</c><00:31:15.370><c> ways</c><00:31:15.520><c> that</c><00:31:15.730><c> we</c><00:31:15.790><c> can</c><00:31:15.940><c> reach</c>

00:31:16.169 --> 00:31:16.179 align:start position:0%
other on some ways that we can reach
 

00:31:16.179 --> 00:31:18.060 align:start position:0%
other on some ways that we can reach
this<00:31:16.419><c> this</c><00:31:16.900><c> higher-order</c><00:31:17.230><c> level</c><00:31:18.010><c> of</c>

00:31:18.060 --> 00:31:18.070 align:start position:0%
this this higher-order level of
 

00:31:18.070 --> 00:31:20.010 align:start position:0%
this this higher-order level of
intelligence<00:31:18.549><c> that's</c><00:31:18.790><c> not</c><00:31:19.000><c> just</c><00:31:19.270><c> pattern</c>

00:31:20.010 --> 00:31:20.020 align:start position:0%
intelligence that's not just pattern
 

00:31:20.020 --> 00:31:22.850 align:start position:0%
intelligence that's not just pattern
recognition<00:31:20.799><c> but</c><00:31:21.580><c> rather</c><00:31:21.760><c> a</c><00:31:22.150><c> higher-order</c>

00:31:22.850 --> 00:31:22.860 align:start position:0%
recognition but rather a higher-order
 

00:31:22.860 --> 00:31:25.500 align:start position:0%
recognition but rather a higher-order
form<00:31:23.860><c> of</c><00:31:23.980><c> reasoning</c><00:31:24.549><c> and</c><00:31:24.790><c> actually</c><00:31:25.120><c> thinking</c>

00:31:25.500 --> 00:31:25.510 align:start position:0%
form of reasoning and actually thinking
 

00:31:25.510 --> 00:31:27.750 align:start position:0%
form of reasoning and actually thinking
about<00:31:25.720><c> about</c><00:31:26.710><c> the</c><00:31:26.890><c> problems</c><00:31:27.280><c> that</c><00:31:27.340><c> we're</c>

00:31:27.750 --> 00:31:27.760 align:start position:0%
about about the problems that we're
 

00:31:27.760 --> 00:31:31.650 align:start position:0%
about about the problems that we're
trying<00:31:28.030><c> to</c><00:31:28.150><c> solve</c><00:31:29.309><c> thank</c><00:31:30.309><c> you</c>

00:31:31.650 --> 00:31:31.660 align:start position:0%
trying to solve thank you
 

00:31:31.660 --> 00:31:37.890 align:start position:0%
trying to solve thank you
[Applause]

