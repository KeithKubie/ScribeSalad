WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:02.950
Hey there trendy 30-something
Silicon Valley resident,

00:00:02.950 --> 00:00:04.420
what you working on?

00:00:04.420 --> 00:00:05.760
Oh, a new app idea for mobile.

00:00:05.760 --> 00:00:06.782
That's pretty cool.

00:00:06.782 --> 00:00:08.490
So you've got your
venture capital ready?

00:00:08.490 --> 00:00:09.000
Good, good.

00:00:09.000 --> 00:00:10.300
Fancy designer and website?

00:00:10.300 --> 00:00:11.302
Great.

00:00:11.302 --> 00:00:13.760
Man, I can't wait to see how
your collaborative intelligent

00:00:13.760 --> 00:00:16.372
algorithm helps users
find-- oh, you're not,

00:00:16.372 --> 00:00:17.580
you're not doing any of that.

00:00:17.580 --> 00:00:20.490
Oh well, you know I bet you've
got a really cool compression

00:00:20.490 --> 00:00:20.990
algorithm.

00:00:20.990 --> 00:00:23.000
I mean, reducing your
data transfer sizes

00:00:23.000 --> 00:00:24.530
to third world country-- no?

00:00:24.530 --> 00:00:26.180
Not doing that either, huh?

00:00:26.180 --> 00:00:28.700
Well, I mean are you doing
anything with data compression?

00:00:28.700 --> 00:00:31.124
I mean, that's kind
of important today.

00:00:31.124 --> 00:00:31.790
No, nothing huh?

00:00:31.790 --> 00:00:32.576
Well, hey listen.

00:00:32.576 --> 00:00:33.700
Don't get down on yourself.

00:00:33.700 --> 00:00:34.874
Come on, it's not that bad.

00:00:34.874 --> 00:00:36.040
I mean you can still fix it.

00:00:36.040 --> 00:00:37.460
All you need to do
is take your recipe

00:00:37.460 --> 00:00:39.420
and sprinkle on a little
bit of Markov chains

00:00:39.420 --> 00:00:41.710
and you'll be compressing
data in no time.

00:00:41.710 --> 00:00:43.190
Well, you know Markov chains.

00:00:43.190 --> 00:00:45.040
The mathematical
system that undergoes

00:00:45.040 --> 00:00:47.930
transitions from one state to
another state on a state space

00:00:47.930 --> 00:00:50.030
and is generally
characterized as memory-less.

00:00:50.030 --> 00:00:52.337
Such that the state depends
only on the current state

00:00:52.337 --> 00:00:53.920
and not that of the
sequence of events

00:00:53.920 --> 00:00:56.130
preceding it, providing
that applications follow

00:00:56.130 --> 00:00:58.501
statistical models of
real world processes.

00:00:58.501 --> 00:00:59.000
No?

00:00:59.000 --> 00:01:00.097
Nothing still?

00:01:00.097 --> 00:01:00.680
You know what?

00:01:00.680 --> 00:01:02.510
Maybe we should start
from the beginning.

00:01:02.510 --> 00:01:05.332
But fret not, young
Silicon Valley hipster.

00:01:05.332 --> 00:01:06.040
I'm here to help.

00:01:06.040 --> 00:01:08.986
My name is Colt McAnlis and
this is Compressor Head.

00:01:08.986 --> 00:01:11.441
[THEME MUSIC]

00:01:11.441 --> 00:01:15.369
Teleprompter activate.

00:01:15.369 --> 00:01:20.300
[LAUGHTER]

00:01:20.300 --> 00:01:22.740
Now one of my favorite
pastimes is actually

00:01:22.740 --> 00:01:25.350
taking great American
traditions and distilling them

00:01:25.350 --> 00:01:27.990
into their state
graph counterparts.

00:01:27.990 --> 00:01:30.290
Take example, baseball.

00:01:30.290 --> 00:01:32.510
Although it may seem like
a bunch of random actions

00:01:32.510 --> 00:01:34.920
to have one team win
or the other one lose,

00:01:34.920 --> 00:01:37.630
there's actually a
very simple graph.

00:01:37.630 --> 00:01:40.430
Let's just look at a
batter coming up to base.

00:01:40.430 --> 00:01:42.302
So the batter comes
up to hit here.

00:01:42.302 --> 00:01:43.760
And there's really
only two states.

00:01:43.760 --> 00:01:46.600
Number one, he can actually
be out by hitting the ball

00:01:46.600 --> 00:01:48.350
or striking out or
some other force of it.

00:01:48.350 --> 00:01:51.060
Or he can actually get on base.

00:01:51.060 --> 00:01:52.990
Now what the interesting
part about this

00:01:52.990 --> 00:01:55.860
is that once you've move
to either the on-base state

00:01:55.860 --> 00:01:58.790
or the out state, you
actually return back

00:01:58.790 --> 00:02:01.910
and another batter
comes up to bat.

00:02:01.910 --> 00:02:03.530
The cool thing about
this is that it's

00:02:03.530 --> 00:02:05.280
pretty self-explanatory, right?

00:02:05.280 --> 00:02:07.770
Only three states and a couple
transitions between them.

00:02:07.770 --> 00:02:11.250
Now what if we actually want
to transmit some movement

00:02:11.250 --> 00:02:13.030
through this graph to
another individual?

00:02:13.030 --> 00:02:19.540
Say for example, we have
batter up, batter out, up,

00:02:19.540 --> 00:02:21.290
and then they get on base.

00:02:21.290 --> 00:02:23.650
Get up again and then
another batter out.

00:02:23.650 --> 00:02:26.460
Well the simplest thing to do
that we've been doing so far

00:02:26.460 --> 00:02:30.350
is assume that each
state is a finite symbol.

00:02:30.350 --> 00:02:33.149
And we can encode each
one with about two bits.

00:02:33.149 --> 00:02:35.190
Which means here we've
got one, two, three, four,

00:02:35.190 --> 00:02:37.030
five six, at two
bits per-- means

00:02:37.030 --> 00:02:38.530
if we want to send
this to somebody,

00:02:38.530 --> 00:02:42.240
it'll be about 12 bits
for the entire stream.

00:02:42.240 --> 00:02:43.880
However when we
look at this, there

00:02:43.880 --> 00:02:45.800
may be a better way to do it.

00:02:45.800 --> 00:02:49.360
Now what if instead of
assigning a variable bit lengths

00:02:49.360 --> 00:02:51.050
to each of its
states, we instead

00:02:51.050 --> 00:02:55.300
actually assign bit codes to the
transition between the states.

00:02:55.300 --> 00:02:59.250
So for example, we put a zero
here, one here, zero here,

00:02:59.250 --> 00:03:01.120
and a zero here.

00:03:01.120 --> 00:03:04.040
Effectively, this allows us
to encode the transitions

00:03:04.040 --> 00:03:05.670
between the states
very differently,

00:03:05.670 --> 00:03:08.620
as long as the encoder and
decoder know the states

00:03:08.620 --> 00:03:10.900
and how we're
moving between them.

00:03:10.900 --> 00:03:12.346
Now if you take
this set up here,

00:03:12.346 --> 00:03:13.970
that means that we're
actually encoding

00:03:13.970 --> 00:03:15.964
these green arrows in our state.

00:03:15.964 --> 00:03:17.880
And this allows us to
encode the entire stream

00:03:17.880 --> 00:03:20.810
in five bits, which
is pretty good.

00:03:20.810 --> 00:03:23.530
But I think we can do better.

00:03:23.530 --> 00:03:25.140
If you look at our
graph here, there's

00:03:25.140 --> 00:03:26.990
some implicit rules
about baseball

00:03:26.990 --> 00:03:29.400
that we know to be true,
that we don't actually

00:03:29.400 --> 00:03:31.320
have to encode in our graph.

00:03:31.320 --> 00:03:34.430
For example, when a batter
is either out or on base,

00:03:34.430 --> 00:03:35.950
we know that another
batter is going

00:03:35.950 --> 00:03:37.619
to come up no matter what.

00:03:37.619 --> 00:03:39.910
So we actually don't need to
encode this in our stream.

00:03:39.910 --> 00:03:44.410
So we can get rid of
this and get rid of this.

00:03:44.410 --> 00:03:46.800
Which means that the only
information we really

00:03:46.800 --> 00:03:48.920
need to encode is
whether or not when

00:03:48.920 --> 00:03:52.410
a better comes up, if they
end up out or on base.

00:03:52.410 --> 00:03:56.630
This information allows us to
encode all of our symbol data

00:03:56.630 --> 00:03:59.390
here in actually
only three bits.

00:03:59.390 --> 00:04:02.620
So moving from 12 bits to 3 bits
is actually pretty important.

00:04:02.620 --> 00:04:05.200
And what we've described
here-- the ability

00:04:05.200 --> 00:04:09.620
to encode transitions
rather than the exact states

00:04:09.620 --> 00:04:11.710
and then having some
of the transitions

00:04:11.710 --> 00:04:13.920
be implicit in the
encoder and decoder

00:04:13.920 --> 00:04:17.180
is actually the basis of
how Markov encoding works.

00:04:17.180 --> 00:04:19.170
But of course, this
is a simple example

00:04:19.170 --> 00:04:21.300
and it gets a little bit
more tricky than this.

00:04:25.800 --> 00:04:30.720
In 1913, A.A. Markov found a
new branch of probability theory

00:04:30.720 --> 00:04:33.090
by combining
mathematics and poetry.

00:04:33.090 --> 00:04:36.570
Effectively delving into the
text of an Alexander Pushkin

00:04:36.570 --> 00:04:38.520
novel, Markov
spend hours sifting

00:04:38.520 --> 00:04:40.270
through patterns of
vowels and consonants.

00:04:40.270 --> 00:04:42.940
And on January 23,
1913 publishers

00:04:42.940 --> 00:04:45.620
were detailing a statistical
model that given a letter,

00:04:45.620 --> 00:04:48.620
it was a finite and reproducible
probability associated

00:04:48.620 --> 00:04:50.010
with what letter would follow.

00:04:50.010 --> 00:04:52.860
You see by most accounts,
Markov was a pretty meddlesome

00:04:52.860 --> 00:04:56.230
character, constantly
involved with political feuds,

00:04:56.230 --> 00:04:57.185
public protests.

00:04:57.185 --> 00:05:01.000
He was fiercely competitive
with any rivals in his field

00:05:01.000 --> 00:05:03.410
and actually spend a
lot of time in jail

00:05:03.410 --> 00:05:06.350
for massive rounds
of fisticuffs.

00:05:06.350 --> 00:05:09.130
How fitting is that the
inventor of the algorithm,

00:05:09.130 --> 00:05:11.610
which is powering most
of modern Silicon Valley,

00:05:11.610 --> 00:05:13.010
was a rebel without a cause.

00:05:17.080 --> 00:05:19.960
You see, Markov's concept o of
probabilistic events selection

00:05:19.960 --> 00:05:22.440
was massively contrary to
the world of statistics

00:05:22.440 --> 00:05:24.800
at the time, which mostly
involves modeling count

00:05:24.800 --> 00:05:26.310
flipping and dice rolling.

00:05:26.310 --> 00:05:28.250
You see at its
core, Markov chains

00:05:28.250 --> 00:05:31.510
help us answer questions
about associative probability.

00:05:31.510 --> 00:05:33.281
For example, if
it's cloudy today

00:05:33.281 --> 00:05:34.780
what are the chances
that it's going

00:05:34.780 --> 00:05:36.790
to rain two days from now?

00:05:36.790 --> 00:05:40.440
A concept, which in 1913, was
as predictable with mathematics

00:05:40.440 --> 00:05:42.390
as casting chicken bones.

00:05:42.390 --> 00:05:43.630
Think about that.

00:05:43.630 --> 00:05:47.230
Today Markov chains power some
of the biggest and most complex

00:05:47.230 --> 00:05:49.800
big data algorithms
in Silicon Valley.

00:05:49.800 --> 00:05:52.180
They're seen everywhere
from cancer research

00:05:52.180 --> 00:05:55.860
to weather prediction to
modeling consumer behavior

00:05:55.860 --> 00:05:58.150
and even figuring out
what the best pizza

00:05:58.150 --> 00:05:59.990
joint is in San Jose.

00:05:59.990 --> 00:06:03.190
The best part is, we can use the
same exact base algorithm that

00:06:03.190 --> 00:06:06.060
powers all these big things
and use it for compression.

00:06:06.060 --> 00:06:06.810
Let's take a look.

00:06:09.910 --> 00:06:12.600
Channeling Markov's work,
we can encode a given string

00:06:12.600 --> 00:06:14.890
by looking at a letter
and noting the transition

00:06:14.890 --> 00:06:17.674
to the following letter.

00:06:17.674 --> 00:06:19.340
Now for the sake of
simplicity here, I'm

00:06:19.340 --> 00:06:21.520
going to redraw the
symbol pair transitions

00:06:21.520 --> 00:06:24.510
as a tree with the first
letter in each pair

00:06:24.510 --> 00:06:27.430
resides the head of tree
and the second pair resides

00:06:27.430 --> 00:06:28.459
as the child node.

00:06:28.459 --> 00:06:30.500
To give us some better
terminology in this topic,

00:06:30.500 --> 00:06:34.530
we denote each pair in the
context as a zero based order.

00:06:34.530 --> 00:06:37.820
That is the first letter
of the pairs context zero,

00:06:37.820 --> 00:06:41.350
well the subsequent
letters are context one.

00:06:41.350 --> 00:06:43.810
Now some of you graph purist
may be looking at this graph

00:06:43.810 --> 00:06:46.540
and asking why T and
N don't both point

00:06:46.540 --> 00:06:49.490
to O node as a child
of context one.

00:06:49.490 --> 00:06:52.420
It is true that for both of
these context zero symbols,

00:06:52.420 --> 00:06:55.110
O does follow as context one.

00:06:55.110 --> 00:06:56.940
But it's actually
wrong to do that.

00:06:56.940 --> 00:07:00.220
Here's why.

00:07:00.220 --> 00:07:02.240
To understand why, let's
re-encode the string

00:07:02.240 --> 00:07:05.410
with three simple steps, also
known as second-order context.

00:07:05.410 --> 00:07:10.060
And use your concept of
sharing the context one state.

00:07:10.060 --> 00:07:12.440
Now while this tree may look
visually stunning and very

00:07:12.440 --> 00:07:14.620
pleasing it's actually quite
inaccurate with respect

00:07:14.620 --> 00:07:16.630
to how the string
is constructed.

00:07:16.630 --> 00:07:18.130
You see for example,
this graph will

00:07:18.130 --> 00:07:21.840
allow you to move from T
through O in context one,

00:07:21.840 --> 00:07:26.060
and then to T in context two,
introducing the string TOT,

00:07:26.060 --> 00:07:28.940
which of course doesn't
exist in the input data.

00:07:28.940 --> 00:07:31.910
This is of course an incorrect
to the proper thing to do.

00:07:31.910 --> 00:07:35.320
And the proper thing to do is
only chart context transition

00:07:35.320 --> 00:07:37.160
as unshared links.

00:07:37.160 --> 00:07:39.920
Now let's extend the
concept forward a bit

00:07:39.920 --> 00:07:42.190
and take a look at a
longer string using

00:07:42.190 --> 00:07:46.070
first-order contexts,
that is two symbol pairs.

00:07:46.070 --> 00:07:47.510
You can see that
a more real life

00:07:47.510 --> 00:07:50.340
example changes our
distribution and gives us

00:07:50.340 --> 00:07:52.770
a different sort of tree for
encoding with slightly more

00:07:52.770 --> 00:07:56.435
complex state relationships,
with letters like T, O, and E

00:07:56.435 --> 00:07:58.290
have multiple
potential transitions

00:07:58.290 --> 00:07:59.560
to the next context.

00:07:59.560 --> 00:08:02.009
If we wanted to
encode this example,

00:08:02.009 --> 00:08:03.550
we would need some
way to assign bits

00:08:03.550 --> 00:08:05.960
to each of the transitions
between the context.

00:08:05.960 --> 00:08:07.580
The question, of
course, is how many

00:08:07.580 --> 00:08:10.250
bits to assign to a transition,
which we can determine

00:08:10.250 --> 00:08:14.870
as the max number of transitions
from a node in the entire set.

00:08:14.870 --> 00:08:18.080
In this case, the O
node in context zero

00:08:18.080 --> 00:08:19.980
has three transitions,
which means

00:08:19.980 --> 00:08:24.310
we can use 2 bits
for everything.

00:08:24.310 --> 00:08:25.860
Of course, this
is a bit wasteful.

00:08:25.860 --> 00:08:27.710
For example, states
with only one transition

00:08:27.710 --> 00:08:29.120
shouldn't need 2 bits.

00:08:29.120 --> 00:08:31.830
Plus, we need to keep
around some number per node

00:08:31.830 --> 00:08:34.840
to let the decoder know
how many bits to read.

00:08:34.840 --> 00:08:37.169
And what happens if there's
16 transitions per node

00:08:37.169 --> 00:08:38.799
instead of just 2?

00:08:38.799 --> 00:08:41.789
The correct answer here is
to use variable length codes

00:08:41.789 --> 00:08:43.490
to describe transitions.

00:08:43.490 --> 00:08:46.280
This way, code words used
to describe these transition

00:08:46.280 --> 00:08:47.970
can be variable
in size and it can

00:08:47.970 --> 00:08:51.090
scale based upon
what's actually needed.

00:08:51.090 --> 00:08:53.680
But remember, VLCs
only work if you

00:08:53.680 --> 00:08:57.200
assign the most probable
symbol the smallest code word.

00:08:57.200 --> 00:09:00.020
So in order to get the most
efficient compression possible,

00:09:00.020 --> 00:09:02.520
we need to take
probability into account

00:09:02.520 --> 00:09:04.940
when assigning code
words, which thankfully

00:09:04.940 --> 00:09:09.350
is easy to do given the way we
actually construct our chains.

00:09:09.350 --> 00:09:13.140
Doing so allows us to properly
use VLCs to encode our data.

00:09:13.140 --> 00:09:15.810
And note one of the trickier
parts about our scheme

00:09:15.810 --> 00:09:17.940
is that each context
transition-- that

00:09:17.940 --> 00:09:22.360
is to say zero to each of
its children in context one--

00:09:22.360 --> 00:09:24.520
manage its own
probability table.

00:09:24.520 --> 00:09:26.970
And as such, has
its own VLC set.

00:09:26.970 --> 00:09:29.970
To be clear, you're not
creating a VLC distribution

00:09:29.970 --> 00:09:31.860
across the entire graph.

00:09:31.860 --> 00:09:32.640
No, no.

00:09:32.640 --> 00:09:33.683
That would be madness.

00:09:36.736 --> 00:09:38.360
Recent years have
seen the construction

00:09:38.360 --> 00:09:40.440
of truly enormous Markov chains.

00:09:40.440 --> 00:09:42.610
For example, page
rank algorithm devised

00:09:42.610 --> 00:09:46.340
by Larry Page and Sergey
Brin, the founders of Google,

00:09:46.340 --> 00:09:48.770
is based on a Markov
chain whose states are

00:09:48.770 --> 00:09:52.470
the pages of the world wide
web, perhaps 40 billion of them.

00:09:52.470 --> 00:09:54.850
The transitions
between the states

00:09:54.850 --> 00:09:56.500
are actually links
between the pages.

00:09:56.500 --> 00:09:59.580
The aim of the algorithm is
to calculate for each page

00:09:59.580 --> 00:10:01.880
the probability that a
reader following a link

00:10:01.880 --> 00:10:05.560
will randomly arrive
at some further page.

00:10:05.560 --> 00:10:08.150
Now in order to make Markov
practical for compression,

00:10:08.150 --> 00:10:11.095
we need to take a more
technical look at the problem.

00:10:17.810 --> 00:10:20.200
Now when it comes
to Markov chains,

00:10:20.200 --> 00:10:22.280
theory and practical
implementations

00:10:22.280 --> 00:10:24.006
are night and day different.

00:10:24.006 --> 00:10:25.380
Sadly though this
isn't something

00:10:25.380 --> 00:10:26.529
I can just talk about.

00:10:26.529 --> 00:10:28.820
No, we're actually going to
have to get our hands dirty

00:10:28.820 --> 00:10:31.710
and encode some things to
figure out what's going on.

00:10:31.710 --> 00:10:34.350
As efficient as Markov
is for compression,

00:10:34.350 --> 00:10:36.680
it comes with one huge flaw.

00:10:36.680 --> 00:10:39.460
Let's say you want to transmit
this encoding to the decoder.

00:10:39.460 --> 00:10:42.260
Well for each context
transition or a parent

00:10:42.260 --> 00:10:45.370
to child transition, you'll
need to store a frequency

00:10:45.370 --> 00:10:48.517
table-- that is the symbol and
its frequency of incurrence.

00:10:48.517 --> 00:10:50.100
This data, of course,
would need to be

00:10:50.100 --> 00:10:52.840
listed in the compressed streams
so the decoder could properly

00:10:52.840 --> 00:10:54.236
decode this information.

00:10:54.236 --> 00:10:55.610
But even for this
simple example,

00:10:55.610 --> 00:10:58.130
the overhead of this
process is extreme.

00:10:58.130 --> 00:11:00.010
Just as for all of this
frequency data, such

00:11:00.010 --> 00:11:02.020
that the decoder
can properly work,

00:11:02.020 --> 00:11:04.780
we would need 53
bytes to this stream.

00:11:04.780 --> 00:11:06.410
The original stream
is only 22 bytes,

00:11:06.410 --> 00:11:09.100
so obviously this
is not helping.

00:11:09.100 --> 00:11:12.130
And it gets even worse
the larger our data set is

00:11:12.130 --> 00:11:14.440
or the more context
we decide to keep.

00:11:14.440 --> 00:11:17.135
The point here is that we can't
simply transmit our percentages

00:11:17.135 --> 00:11:20.150
from the encoder to the
decoder using the data stream.

00:11:20.150 --> 00:11:22.180
Instead we need to make
the whole thing work

00:11:22.180 --> 00:11:25.685
as the decoder will generate
the same statistical properties

00:11:25.685 --> 00:11:28.290
that the encoder is
using for the data,

00:11:28.290 --> 00:11:30.740
as it's decoding the stream.

00:11:30.740 --> 00:11:32.656
Let's say we wanted
to decode this stream,

00:11:32.656 --> 00:11:34.280
dynamically generate
our probabilities,

00:11:34.280 --> 00:11:37.290
and Markov chain encode
it all at the same time.

00:11:37.290 --> 00:11:40.160
We start out with a completely
empty Markov data set.

00:11:40.160 --> 00:11:42.700
When we read the first letter,
A, from the input stream,

00:11:42.700 --> 00:11:43.970
we need to encode it.

00:11:43.970 --> 00:11:47.190
But we can't because there's
no data so far to use.

00:11:47.190 --> 00:11:50.150
As such, we need to
start creating our tree.

00:11:50.150 --> 00:11:51.690
Once the trees is
created, we need

00:11:51.690 --> 00:11:54.040
to encode A with a
variable length code

00:11:54.040 --> 00:11:55.460
but we can't yet
because we first

00:11:55.460 --> 00:11:57.025
need to assign it a probability.

00:11:57.025 --> 00:11:58.900
Since this is the first
character we've seen,

00:11:58.900 --> 00:12:02.279
we can give it a
probability of 100%.

00:12:02.279 --> 00:12:04.820
Once we have our probability,
we can generate a Huffman tree,

00:12:04.820 --> 00:12:07.620
which will let us assign
a code word to the symbol

00:12:07.620 --> 00:12:09.730
A. Since we've got
nothing else in the tree,

00:12:09.730 --> 00:12:13.290
it gets the code word 0.

00:12:13.290 --> 00:12:15.450
Once we go to read
our second letter, B,

00:12:15.450 --> 00:12:17.490
we also haven't seen it before.

00:12:17.490 --> 00:12:19.790
So we need to add it as a
symbol and its probability

00:12:19.790 --> 00:12:20.850
to our tree.

00:12:20.850 --> 00:12:23.280
We also at this point need
to update our probability

00:12:23.280 --> 00:12:26.650
for all the symbols
in this context.

00:12:26.650 --> 00:12:28.780
Note that we've seen
a second B, which

00:12:28.780 --> 00:12:30.400
updates its probability
in the table

00:12:30.400 --> 00:12:34.244
and swaps its code word with A,
which is exactly what we wanted

00:12:34.244 --> 00:12:35.660
since we're updating
probabilities

00:12:35.660 --> 00:12:38.690
dynamically and generating
variable length codes based

00:12:38.690 --> 00:12:39.280
on that.

00:12:39.280 --> 00:12:40.740
The best part is
that we don't need

00:12:40.740 --> 00:12:42.985
to transmit the probabilities
to the stream, just

00:12:42.985 --> 00:12:45.110
the encoded bits.

00:12:45.110 --> 00:12:46.710
However when we
try to decode this,

00:12:46.710 --> 00:12:48.810
we run into a large
problem, namely

00:12:48.810 --> 00:12:50.950
that we have no information
about the literals

00:12:50.950 --> 00:12:53.910
or the probability table that
was used to construct this bit

00:12:53.910 --> 00:12:57.130
stream, which basically means
the decoder can't actually

00:12:57.130 --> 00:13:00.455
decode the stream and this
is an incorrect encoding.

00:13:00.455 --> 00:13:01.830
To fix this, we're
actually going

00:13:01.830 --> 00:13:04.090
to have to revisit our
encoder and figure out

00:13:04.090 --> 00:13:06.920
a proper way to output
literals so the decoder can

00:13:06.920 --> 00:13:11.020
consume them and reconstruct
the original stream.

00:13:11.020 --> 00:13:12.980
Once we add A to the
tree for the first time,

00:13:12.980 --> 00:13:16.270
we need some way of providing
it to the output encoded stream

00:13:16.270 --> 00:13:18.440
so that the decoder can get it.

00:13:18.440 --> 00:13:20.860
To do this, we add a
second output stream

00:13:20.860 --> 00:13:25.390
called the literal stream, which
only contains 8 bits per symbol

00:13:25.390 --> 00:13:28.219
characters that we
haven't actually seen yet.

00:13:28.219 --> 00:13:29.760
We now need to tell
the output stream

00:13:29.760 --> 00:13:33.620
when it should read the explicit
symbol from the literal stream,

00:13:33.620 --> 00:13:36.390
rather than expecting
a variable length code.

00:13:36.390 --> 00:13:40.420
To do this, we introduced the
concept of an escape code.

00:13:40.420 --> 00:13:42.902
An escape code is
a special symbol

00:13:42.902 --> 00:13:45.110
that we're going to use in
our probability table that

00:13:45.110 --> 00:13:48.060
allows the decoder
to know when to read

00:13:48.060 --> 00:13:51.350
a full literal from
our literal stream.

00:13:51.350 --> 00:13:53.920
Now an escape code is
not a symbol in the sense

00:13:53.920 --> 00:13:56.480
that A, B, or C is
but it does have

00:13:56.480 --> 00:13:58.460
residency in our
probability table.

00:13:58.460 --> 00:14:03.710
So it will get a variable
length code in the encoding.

00:14:03.710 --> 00:14:05.710
Rather than starting
off with a blank tree,

00:14:05.710 --> 00:14:07.800
any new context nodes
that are instead

00:14:07.800 --> 00:14:11.639
initialized with an escape code
and set to 100% probability.

00:14:11.639 --> 00:14:13.680
When we read the letter
A from the symbol stream,

00:14:13.680 --> 00:14:16.160
we add it to the context,
update our code words,

00:14:16.160 --> 00:14:19.400
output an escape code to the bit
stream, and then the letter A

00:14:19.400 --> 00:14:20.495
to the literal stream.

00:14:23.800 --> 00:14:25.640
Reading the letter B
is the same process.

00:14:25.640 --> 00:14:26.900
We haven't seen it before.

00:14:26.900 --> 00:14:29.320
So we output the code
word for an escape code

00:14:29.320 --> 00:14:31.940
and then a literal value.

00:14:31.940 --> 00:14:34.420
This is where the fun really
starts to happen, kids.

00:14:34.420 --> 00:14:37.050
Once we read the next B,
it's not a new symbol.

00:14:37.050 --> 00:14:39.104
We've actually seen it before.

00:14:39.104 --> 00:14:40.520
As such, it's
critically important

00:14:40.520 --> 00:14:43.450
to note that when we're
encoding an existing symbol

00:14:43.450 --> 00:14:45.190
that we output the
variable length code

00:14:45.190 --> 00:14:49.560
before updating our stats
and table code words.

00:14:49.560 --> 00:14:52.450
Once we update the probabilities
of the table with the second B,

00:14:52.450 --> 00:14:55.170
the weights change the
code word assignment.

00:14:55.170 --> 00:14:58.390
As such, the decoder wouldn't be
able to see this type of change

00:14:58.390 --> 00:15:01.560
and it would break things.

00:15:01.560 --> 00:15:03.524
Decoding works the
exact same way.

00:15:03.524 --> 00:15:05.940
Except when we encounter an
escape code, it tells us to go

00:15:05.940 --> 00:15:08.960
read a symbol off the
literal stream and output it.

00:15:08.960 --> 00:15:11.440
First we employ the process
of reading variable length

00:15:11.440 --> 00:15:12.710
code from the bit stream.

00:15:12.710 --> 00:15:15.770
If you're not familiar with
that, go check out Episode One.

00:15:15.770 --> 00:15:17.790
Since the only value we
have is an escape code,

00:15:17.790 --> 00:15:19.915
we simply need to read a
single bit from the stream

00:15:19.915 --> 00:15:22.340
and find that we're
using an escape code.

00:15:22.340 --> 00:15:24.350
This tells us to go
ahead and read 8 bits

00:15:24.350 --> 00:15:26.620
from the literal stream,
push it to the output stream,

00:15:26.620 --> 00:15:29.932
and update our
probability tables.

00:15:29.932 --> 00:15:31.640
We read the next zero
from the bit stream

00:15:31.640 --> 00:15:33.610
and seeing that it's
a variable length code

00:15:33.610 --> 00:15:36.110
as well, we know to
read the next literal,

00:15:36.110 --> 00:15:38.620
output it, and update
the probability tables.

00:15:38.620 --> 00:15:40.980
At this point, we have
enough table information

00:15:40.980 --> 00:15:43.640
that the next 2 bits
read off the bit stream

00:15:43.640 --> 00:15:46.420
match with the letter B, which
of course we happily output.

00:15:49.590 --> 00:15:51.430
We've read A from
the input stream

00:15:51.430 --> 00:15:53.350
and realized it's in the table.

00:15:53.350 --> 00:15:55.410
We've output our codes
to the output bit stream

00:15:55.410 --> 00:15:57.030
and updated our probabilities.

00:15:57.030 --> 00:15:58.740
But because we're
supporting context

00:15:58.740 --> 00:16:01.980
we need to actually create
a new branch in the tree.

00:16:01.980 --> 00:16:05.190
In the naive solution, each
symbol at each context level

00:16:05.190 --> 00:16:08.345
would contain a pointer to its
children in the next context.

00:16:08.345 --> 00:16:09.970
But in order to make
things work right,

00:16:09.970 --> 00:16:14.510
we have to start all subsequent
context with an escape code.

00:16:14.510 --> 00:16:17.020
So the good news is
that's the basics.

00:16:17.020 --> 00:16:18.950
However, the bad news
is that we actually

00:16:18.950 --> 00:16:21.970
need to support a
multi-context chain in order

00:16:21.970 --> 00:16:24.280
to get proper and
legitimate compression.

00:16:24.280 --> 00:16:25.990
And in order to
support that, we're

00:16:25.990 --> 00:16:28.910
going to revisit the
encoder again and change

00:16:28.910 --> 00:16:31.529
how a few things work.

00:16:31.529 --> 00:16:33.862
Since we've just seen a new
symbol at this context level

00:16:33.862 --> 00:16:36.030
that we haven't
seen before, we need

00:16:36.030 --> 00:16:39.530
to start our chain back
over again at context zero.

00:16:43.970 --> 00:16:45.870
Each time we read a
symbol in context zero

00:16:45.870 --> 00:16:47.560
that already exists
in the context,

00:16:47.560 --> 00:16:50.820
we move forward to read
the next symbol operating

00:16:50.820 --> 00:16:52.910
in the subsequent context.

00:16:52.910 --> 00:16:54.820
So if the first two
symbols were A, C,

00:16:54.820 --> 00:16:56.580
we would find the
letter A and then add

00:16:56.580 --> 00:17:01.540
C to the first-order
context set for encoding.

00:17:01.540 --> 00:17:03.770
And to be clear we
treat a new symbol

00:17:03.770 --> 00:17:07.109
at any context as a
completely new symbol.

00:17:07.109 --> 00:17:09.880
So if we encounter the series
A, B, C in this encoding it's

00:17:09.880 --> 00:17:12.530
the first time that we've
seen the letter C in context

00:17:12.530 --> 00:17:14.310
to following B.

00:17:14.310 --> 00:17:16.569
So we treat it the same way
as we would with context

00:17:16.569 --> 00:17:18.900
zero by outputting it
to the literal stream

00:17:18.900 --> 00:17:21.859
and emitting an escape code.

00:17:21.859 --> 00:17:24.030
Once this is
entirely encoded, we

00:17:24.030 --> 00:17:25.964
take our final bit
stream and literal stream

00:17:25.964 --> 00:17:28.130
and pass it along to whatever
person on the internet

00:17:28.130 --> 00:17:30.350
wants it, without having to
keep a single probability

00:17:30.350 --> 00:17:31.650
table around at all.

00:17:31.650 --> 00:17:33.150
In this solution
the original stream

00:17:33.150 --> 00:17:36.710
was 88 bits while the encoded
stream is only 46 bits,

00:17:36.710 --> 00:17:40.000
almost 50% reduction
which isn't bad.

00:17:40.000 --> 00:17:42.150
So it should be really
obvious at this point

00:17:42.150 --> 00:17:44.810
that efficient encoding
of Markov chains

00:17:44.810 --> 00:17:47.420
has to strike a unique
balance between the length

00:17:47.420 --> 00:17:49.320
of the chains that you
need for compression

00:17:49.320 --> 00:17:51.590
and the available memory
that you have on the system

00:17:51.590 --> 00:17:53.870
itself that you're
running the encoder on.

00:17:53.870 --> 00:17:55.660
If you run out of
memory early then

00:17:55.660 --> 00:17:58.160
it's not necessarily
a good thing.

00:17:58.160 --> 00:18:00.180
A real encoder
strike this balance

00:18:00.180 --> 00:18:03.070
with all separate profiles
of system analysis memory

00:18:03.070 --> 00:18:05.430
and also writing
additional context to disk

00:18:05.430 --> 00:18:07.650
to find the optimal solution.

00:18:07.650 --> 00:18:09.090
Now hopefully one
of the questions

00:18:09.090 --> 00:18:10.860
you're asking
yourself here is how

00:18:10.860 --> 00:18:14.520
do we properly adjusted the
probability of an escape code

00:18:14.520 --> 00:18:16.270
when new symbols are added?

00:18:16.270 --> 00:18:18.220
In our little
examples we did here,

00:18:18.220 --> 00:18:20.640
we simply subtracted
hundredth of a point from it.

00:18:20.640 --> 00:18:23.010
But in reality it's
not that simple.

00:18:23.010 --> 00:18:25.471
Unfortunately that's an
entirely separate show

00:18:25.471 --> 00:18:26.970
that we're not going
to cover today.

00:18:26.970 --> 00:18:30.445
In the mean time, Google it.

00:18:30.445 --> 00:18:32.020
Now some people
view Markov chains

00:18:32.020 --> 00:18:33.860
as a step in an
inevitable future

00:18:33.860 --> 00:18:35.710
where artificial
intelligence algorithms

00:18:35.710 --> 00:18:38.930
run the entire gamut
of data compression.

00:18:38.930 --> 00:18:40.210
And that's pretty easy to see.

00:18:40.210 --> 00:18:42.310
You see, keeping a
multi-level context is

00:18:42.310 --> 00:18:44.310
much like tuning
a neural network

00:18:44.310 --> 00:18:46.460
algorithm for
artificial intelligence.

00:18:46.460 --> 00:18:50.490
Of course, we know by now those
most successful Markov chains

00:18:50.490 --> 00:18:52.780
are actually terabytes
of relational data

00:18:52.780 --> 00:18:55.510
long with thousands
of context in two.

00:18:55.510 --> 00:18:57.880
Now lighter weight
versions of Markov chains

00:18:57.880 --> 00:19:00.590
are already available
today in modern compressors

00:19:00.590 --> 00:19:04.380
like 7-zip L pack and ZPack.

00:19:04.380 --> 00:19:06.380
It's easy to see a
future down the road

00:19:06.380 --> 00:19:09.290
where artificial intelligence
and cloud computing come

00:19:09.290 --> 00:19:12.430
together in some weird hybrid
to create a revolution of data

00:19:12.430 --> 00:19:14.860
compression that we haven't
seen it over 40 years.

00:19:14.860 --> 00:19:18.140
But that is a topic
for a different show.

00:19:18.140 --> 00:19:22.850
My name is Colt McAnlis and
this is Compressor Head.

00:19:22.850 --> 00:19:27.400
[THEME MUSIC]

