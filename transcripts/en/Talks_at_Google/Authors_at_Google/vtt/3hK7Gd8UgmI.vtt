WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.400
[MUSIC PLAYING]

00:00:06.400 --> 00:00:08.950
SPEAKER 1: I'm here to
introduce Dan Levitin.

00:00:08.950 --> 00:00:11.470
So he's here today to talk
about his new book, which

00:00:11.470 --> 00:00:14.560
was originally published in
hardcover under the title

00:00:14.560 --> 00:00:18.820
"Field Guide to Lies," which is
why it was advertised that way.

00:00:18.820 --> 00:00:22.060
But the paperback just came
out like this week or Tuesday,

00:00:22.060 --> 00:00:24.530
and they retitled it
"Weaponized Lies."

00:00:24.530 --> 00:00:26.020
I wonder why?

00:00:26.020 --> 00:00:28.100
To make it a little
bit more trendy.

00:00:28.100 --> 00:00:29.892
Dan Levitin to talk a
lot more about lies.

00:00:29.892 --> 00:00:30.850
DAN LEVITIN: Thank you.

00:00:35.470 --> 00:00:36.080
Thank you all.

00:00:36.080 --> 00:00:39.400
I'm delighted to
be back at Google.

00:00:39.400 --> 00:00:45.610
I want to talk about the current
state of facts and pseudo facts

00:00:45.610 --> 00:00:47.755
in the world and perhaps
in the White House.

00:00:53.280 --> 00:00:56.030
Well, one of the reasons we
reissued my book in paperback

00:00:56.030 --> 00:00:59.360
with this updated title is
what I want to talk about.

00:00:59.360 --> 00:01:02.090
I'm beginning to feel
that our country is

00:01:02.090 --> 00:01:08.390
in a crisis that could
possibly set us back 400 years.

00:01:08.390 --> 00:01:10.340
And I know that sounds dramatic.

00:01:10.340 --> 00:01:12.170
And I'm not talking
about politics.

00:01:12.170 --> 00:01:15.350
I'm talking about reversing
the Age of Reason, which

00:01:15.350 --> 00:01:19.370
ushered in a period of
unprecedented intellectual,

00:01:19.370 --> 00:01:23.090
economic, cultural,
and social growth.

00:01:23.090 --> 00:01:25.910
The Enlightenment,
as it is also called,

00:01:25.910 --> 00:01:30.230
drew a line in the sand
between rumor and fact,

00:01:30.230 --> 00:01:34.800
between testable
hypotheses and anecdote,

00:01:34.800 --> 00:01:38.980
and between demonstrable
facts and nonsense.

00:01:38.980 --> 00:01:41.230
Prior to the Age
of Reason, people

00:01:41.230 --> 00:01:43.480
who heard voices in
their heads might

00:01:43.480 --> 00:01:47.380
have been burned at the
stake or drowned as witches.

00:01:47.380 --> 00:01:51.460
By the 20th century, we had
identified a biological disease

00:01:51.460 --> 00:01:55.310
called schizophrenia that
causes these voices in the head.

00:01:55.310 --> 00:01:57.220
We've developed
drugs to treat it.

00:01:57.220 --> 00:01:59.500
The Age of Reason led
us to the germ theory

00:01:59.500 --> 00:02:01.420
of disease, penicillin.

00:02:01.420 --> 00:02:05.200
And although it took us a while
and still isn't ubiquitous,

00:02:05.200 --> 00:02:07.990
women's rights,
child labor laws,

00:02:07.990 --> 00:02:11.350
and a reduction in racist
attitudes around the world.

00:02:11.350 --> 00:02:16.090
All thanks to the Age of Reason,
to evidence-based thinking.

00:02:16.090 --> 00:02:19.110
But until the last
few months, I think,

00:02:19.110 --> 00:02:21.730
it allowed us as
citizens to engage

00:02:21.730 --> 00:02:25.120
in a constructive discussion
with elected officials

00:02:25.120 --> 00:02:29.890
and public policy makers
about public policy matters.

00:02:29.890 --> 00:02:33.280
And these discussions
largely were based on facts,

00:02:33.280 --> 00:02:36.010
on evidence that
everybody agreed to.

00:02:36.010 --> 00:02:38.807
When I was a kid, if
you ran into somebody,

00:02:38.807 --> 00:02:41.140
the proverbial stranger in
the street, somebody at a bus

00:02:41.140 --> 00:02:44.530
stop, and you wanted to
talk about the news--

00:02:44.530 --> 00:02:47.230
forget when I was a kid, all
the way through my 30s and 40s--

00:02:47.230 --> 00:02:50.350
you run into a stranger,
you could be pretty sure

00:02:50.350 --> 00:02:52.510
that if you wanted to
talk about the news,

00:02:52.510 --> 00:02:54.730
they had the same
news that you did.

00:02:54.730 --> 00:02:56.290
There was a limited
number of places

00:02:56.290 --> 00:02:58.360
you could get the
news from, and you

00:02:58.360 --> 00:03:00.910
might have differed in
your views about how

00:03:00.910 --> 00:03:04.120
a particular fact should
be handled or dealt with

00:03:04.120 --> 00:03:06.940
or what the best way to
solve unemployment might be

00:03:06.940 --> 00:03:08.650
or the best way to solve crime.

00:03:08.650 --> 00:03:11.050
But you didn't disagree
about the numbers

00:03:11.050 --> 00:03:13.960
underlying crime
or unemployment.

00:03:13.960 --> 00:03:17.000
But as you know, the
White House gave, well,

00:03:17.000 --> 00:03:20.830
President Trump in particular,
gave wildly different estimates

00:03:20.830 --> 00:03:23.640
of the unemployment rate
all in one sentence.

00:03:23.640 --> 00:03:27.670
It varied, he said,
between 4 and 1/2% and 43%,

00:03:27.670 --> 00:03:29.470
depending on how
you measured it.

00:03:29.470 --> 00:03:34.600
Now one of those numbers
is clearly nonsense,

00:03:34.600 --> 00:03:38.200
and I think undermines
the ability of us

00:03:38.200 --> 00:03:41.050
as citizens to have any kind
of constructive dialogue

00:03:41.050 --> 00:03:44.800
about unemployment, if the
numbers can't be agreed upon.

00:03:44.800 --> 00:03:48.730
If the current administration
is going to brand as fake facts

00:03:48.730 --> 00:03:51.550
that they find
inconvenient, it undermines

00:03:51.550 --> 00:03:53.710
the entire political system.

00:03:53.710 --> 00:03:56.290
If we're going to throw
out facts as a prerequisite

00:03:56.290 --> 00:03:58.780
to discussion, we're
reversing centuries

00:03:58.780 --> 00:04:00.010
of cognitive progress.

00:04:00.010 --> 00:04:04.510
Now again, I don't see
this as a political matter.

00:04:04.510 --> 00:04:07.090
It's not about
Republican or Democrat

00:04:07.090 --> 00:04:10.150
or Green Party or libertarian.

00:04:10.150 --> 00:04:12.130
And it's not about this
particular White House.

00:04:12.130 --> 00:04:15.730
It's about an attitude
that facts don't matter.

00:04:15.730 --> 00:04:17.050
And I think they do.

00:04:17.050 --> 00:04:18.250
I think evidence matters.

00:04:18.250 --> 00:04:20.680
If you're going to
build roads and you've

00:04:20.680 --> 00:04:23.740
got a particular county that
you want to put those roads in,

00:04:23.740 --> 00:04:26.649
it would be helpful to know
whether you actually need roads

00:04:26.649 --> 00:04:27.190
there or not.

00:04:27.190 --> 00:04:28.490
Are there drivers there?

00:04:28.490 --> 00:04:31.270
Are the roads that are
there not serving us well?

00:04:31.270 --> 00:04:34.300
This is the kind of data
collection that many of us

00:04:34.300 --> 00:04:35.890
do for a living.

00:04:35.890 --> 00:04:38.260
Evidence matters.

00:04:38.260 --> 00:04:42.700
The reason I'm calling the book
"Weaponized Lies" is that some

00:04:42.700 --> 00:04:47.230
of these distortions
and fake news and things

00:04:47.230 --> 00:04:51.360
that we've seen over
the last few months--

00:04:51.360 --> 00:04:54.400
first of all, words matter.

00:04:54.400 --> 00:04:59.590
I don't like words like
alt-truth or alternative facts

00:04:59.590 --> 00:05:00.610
or fake news.

00:05:00.610 --> 00:05:05.790
Because I think they're
just euphemisms for lies.

00:05:05.790 --> 00:05:07.960
There are no alternative facts.

00:05:07.960 --> 00:05:11.260
There are facts, and then there
are things that are not facts.

00:05:11.260 --> 00:05:14.470
There's evidence, and then
there's stuff that's not.

00:05:14.470 --> 00:05:18.760
Fake news bothers me, because
there's nothing newsy about it.

00:05:18.760 --> 00:05:20.080
There's no news in it.

00:05:20.080 --> 00:05:23.574
And calling it fake almost
sounds a little too playful,

00:05:23.574 --> 00:05:25.990
like a kid trying to get out
of going to school because he

00:05:25.990 --> 00:05:29.130
or she is sick, faking illness.

00:05:29.130 --> 00:05:31.930
But let's call them what
they are, they're lies.

00:05:31.930 --> 00:05:34.990
And these lies have
become weaponized.

00:05:34.990 --> 00:05:37.960
In our lifetime, the
original weaponized lie

00:05:37.960 --> 00:05:39.430
was the lie that
there were weapons

00:05:39.430 --> 00:05:42.910
of mass destruction in
Iraq, which actually led us

00:05:42.910 --> 00:05:44.140
into a war.

00:05:44.140 --> 00:05:46.860
That's what I mean by a lie
that becomes weaponized.

00:05:46.860 --> 00:05:48.370
Or how many of you
heard the story

00:05:48.370 --> 00:05:52.060
that Hillary Clinton was
operating a child sex slave

00:05:52.060 --> 00:05:54.790
operation out of the
back of a pizza store

00:05:54.790 --> 00:05:56.470
in suburban Washington, DC?

00:05:56.470 --> 00:05:58.930
Is this familiar to you?

00:05:58.930 --> 00:06:01.580
It turns out that this is a lie.

00:06:01.580 --> 00:06:04.570
It was traced to a
Macedonian teenager who

00:06:04.570 --> 00:06:08.170
made it up just to get the click
through revenue on advertising.

00:06:08.170 --> 00:06:10.750
That lie had a million hits.

00:06:10.750 --> 00:06:14.440
When snopes.com
and other sources

00:06:14.440 --> 00:06:19.420
revealed it to be a hoax,
that story got 35,000 hits.

00:06:19.420 --> 00:06:22.960
One of the people
who believed the lie

00:06:22.960 --> 00:06:27.400
drove from North Carolina
to DC with an assault rifle

00:06:27.400 --> 00:06:30.430
to investigate, and
then actually discharged

00:06:30.430 --> 00:06:31.870
the weapon at the pizza place.

00:06:31.870 --> 00:06:33.580
Not finding any
evidence, but feeling

00:06:33.580 --> 00:06:35.670
that he had to do something.

00:06:35.670 --> 00:06:38.190
And so again the lie
became weaponized.

00:06:38.190 --> 00:06:42.180
And I think all of us have
to stop and take a breath

00:06:42.180 --> 00:06:44.550
and figure out what
we can do to stop

00:06:44.550 --> 00:06:47.100
the promulgation of
this kind of nonsense

00:06:47.100 --> 00:06:50.760
and I think that's what,
at least in some broadly

00:06:50.760 --> 00:06:53.190
writ fashion, that's what
all of you do for a living,

00:06:53.190 --> 00:06:55.740
is trying to stop
nonsense and to get data

00:06:55.740 --> 00:06:57.460
and evidence into the world.

00:06:57.460 --> 00:06:59.370
That's what Google is about.

00:06:59.370 --> 00:07:03.480
And I think even apart from
Google, outside of Google,

00:07:03.480 --> 00:07:05.610
all of us have a
personal responsibility

00:07:05.610 --> 00:07:08.490
as citizens of a free
country to try and keep

00:07:08.490 --> 00:07:11.610
the conversation on track.

00:07:11.610 --> 00:07:15.360
Now why does any of this
matter to you in your own life?

00:07:15.360 --> 00:07:16.750
Maybe you're not political.

00:07:16.750 --> 00:07:18.380
Maybe you don't want
to get involved.

00:07:18.380 --> 00:07:21.250
Maybe you're just
trying to figure out how

00:07:21.250 --> 00:07:23.026
to get by one day at a time.

00:07:23.026 --> 00:07:24.400
And I'll tell you
why it matters.

00:07:24.400 --> 00:07:27.040
Because evidence-based
thinking in your personal life,

00:07:27.040 --> 00:07:30.850
setting aside the
public sphere, it's

00:07:30.850 --> 00:07:34.580
correlated with a number
of important outcomes.

00:07:34.580 --> 00:07:36.490
Evidence-based
thinking is associated

00:07:36.490 --> 00:07:39.550
with conscientiousness,
which is a factor that's

00:07:39.550 --> 00:07:41.230
been shown to
correlate very highly

00:07:41.230 --> 00:07:45.430
with increased longevity, fewer
health problems, more life

00:07:45.430 --> 00:07:46.930
satisfaction.

00:07:46.930 --> 00:07:49.390
And in a very real
fashion, being

00:07:49.390 --> 00:07:53.050
able to engage in evidence-based
thinking will save you time.

00:07:53.050 --> 00:07:55.180
You'll be able to make
decisions more quickly.

00:07:55.180 --> 00:07:58.009
You won't have to recover
from bad decisions,

00:07:58.009 --> 00:07:59.800
which always takes a
lot longer than having

00:07:59.800 --> 00:08:03.700
made a good decision the first
time out, especially decisions

00:08:03.700 --> 00:08:06.700
about your health care or
where to invest your retirement

00:08:06.700 --> 00:08:07.450
money.

00:08:07.450 --> 00:08:09.899
Evidence-based
thinking helps there.

00:08:09.899 --> 00:08:12.190
For those of you that have
children or younger brothers

00:08:12.190 --> 00:08:14.530
and sisters, this
kind of thinking

00:08:14.530 --> 00:08:16.930
will help them get
better grades in school

00:08:16.930 --> 00:08:19.180
and to do better on their
papers and assignments.

00:08:22.600 --> 00:08:26.080
Non-evidence-based
thinking has actually

00:08:26.080 --> 00:08:30.130
had a very dire and
very local consequence.

00:08:30.130 --> 00:08:32.870
Just not to put too
fine a point on it,

00:08:32.870 --> 00:08:36.909
but you all know that Steve
Jobs died of pancreatic cancer.

00:08:36.909 --> 00:08:39.429
What isn't as widely
known is a little bit

00:08:39.429 --> 00:08:42.970
of the nuance about the
treatment that he chose.

00:08:42.970 --> 00:08:48.040
So when faced with the
opinions of medical experts,

00:08:48.040 --> 00:08:51.130
Steve Jobs decided--

00:08:51.130 --> 00:08:54.950
look Steve Jobs is clearly
a brilliant man, right?

00:08:54.950 --> 00:08:58.530
But he didn't make an
evidence-based decision,

00:08:58.530 --> 00:09:01.170
which he later admitted
towards the end of his life.

00:09:01.170 --> 00:09:03.660
Rather than go with
traditional Western medicine,

00:09:03.660 --> 00:09:07.830
he decided to follow an
alternative medicine regimen,

00:09:07.830 --> 00:09:11.010
changing his diet and
getting exercise and things

00:09:11.010 --> 00:09:13.620
like that were going to
beat the pancreatic cancer.

00:09:13.620 --> 00:09:16.950
Well, by the time he realized
that it wasn't working,

00:09:16.950 --> 00:09:19.260
the cancer had progressed
to such a degree

00:09:19.260 --> 00:09:22.410
that Western medicine could no
longer help him, and he died.

00:09:22.410 --> 00:09:25.020
And he admitted that he had
made an error in judgment

00:09:25.020 --> 00:09:27.210
there by not going
with the evidence.

00:09:27.210 --> 00:09:29.670
Now I've been a little bit
sloppy with my language

00:09:29.670 --> 00:09:33.150
here by referring to
traditional Western medicine

00:09:33.150 --> 00:09:35.760
and what he pursued as
alternative medicine.

00:09:35.760 --> 00:09:40.040
Because really there's no such
thing as alternative medicine.

00:09:40.040 --> 00:09:42.540
I know that I may make some
of you mad by saying that.

00:09:42.540 --> 00:09:44.580
I know that Silicon
Valley is ground zero

00:09:44.580 --> 00:09:48.750
for alternative health, as
is Marin County I suppose.

00:09:48.750 --> 00:09:53.220
I got chewed out when I talked
about this in Nevada recently.

00:09:53.220 --> 00:09:57.790
But the way I look at
it, alternative medicine

00:09:57.790 --> 00:09:59.350
is a non-sequitur.

00:09:59.350 --> 00:10:01.450
It's not like there are
two kinds of medicine,

00:10:01.450 --> 00:10:03.610
and one is running in
parallel to the other.

00:10:03.610 --> 00:10:06.910
There is medicine which
has been proven to work,

00:10:06.910 --> 00:10:09.610
and then anything for
which we have no evidence,

00:10:09.610 --> 00:10:11.560
we call alternative medicine.

00:10:11.560 --> 00:10:13.780
And then, as soon as
it's been shown to work,

00:10:13.780 --> 00:10:16.360
it becomes medicine, right?

00:10:16.360 --> 00:10:19.060
Alternative medicine is
simply the category of things

00:10:19.060 --> 00:10:21.470
that we have no evidence for.

00:10:21.470 --> 00:10:24.260
So just to call it
alternative medicine,

00:10:24.260 --> 00:10:27.020
like calling something fake
news kind of elevates it

00:10:27.020 --> 00:10:29.180
to a dignity that I
don't think it deserves.

00:10:31.790 --> 00:10:36.770
The problem, of course, with
lies and distortions of truth

00:10:36.770 --> 00:10:39.890
is that they can lead
you down the wrong path.

00:10:39.890 --> 00:10:42.590
And getting back to
the Age of Reason,

00:10:42.590 --> 00:10:44.120
it was Voltaire
who said, those who

00:10:44.120 --> 00:10:46.580
can make you
believe absurdities,

00:10:46.580 --> 00:10:50.010
can make you commit atrocities.

00:10:50.010 --> 00:10:51.510
And this is what
I think all of us

00:10:51.510 --> 00:10:55.260
need to make a concerted
effort to change

00:10:55.260 --> 00:10:59.160
about the way the current
public discourse is going.

00:10:59.160 --> 00:11:01.200
Part of the problem,
too, is that there

00:11:01.200 --> 00:11:04.230
has been a balkanization
of news sources.

00:11:04.230 --> 00:11:06.480
As I said earlier, it
used to be most of us

00:11:06.480 --> 00:11:08.880
got all our news
from a few sources.

00:11:08.880 --> 00:11:11.250
And sure there was some
crank-- if you went into a city

00:11:11.250 --> 00:11:14.880
like San Francisco, and you
went into a Market Street,

00:11:14.880 --> 00:11:17.550
there'd be some crank on
the corner with a sandwich

00:11:17.550 --> 00:11:19.770
board saying the world
is coming to an end.

00:11:19.770 --> 00:11:21.450
Or he might be yelling
into a bullhorn

00:11:21.450 --> 00:11:26.220
that there is a terrible
conspiracy, that the CIA is

00:11:26.220 --> 00:11:28.170
spreading germs in
the atmosphere to keep

00:11:28.170 --> 00:11:30.060
us all docile or whatever.

00:11:30.060 --> 00:11:32.430
And you knew because it
was a guy with a sandwich

00:11:32.430 --> 00:11:35.520
board and a bullhorn,
you knew it was a crank.

00:11:35.520 --> 00:11:38.610
The problem is now those cranks
have turned to the internet,

00:11:38.610 --> 00:11:40.320
and it's very difficult to tell.

00:11:40.320 --> 00:11:43.020
Because you know, face
it, any 11-year-old

00:11:43.020 --> 00:11:46.020
can make a website that looks
professional, as professional

00:11:46.020 --> 00:11:48.090
as that of General
Motors or Ford Motors

00:11:48.090 --> 00:11:51.130
or a big American company.

00:11:51.130 --> 00:11:55.910
And it's harder, because we
don't have the traditional cues

00:11:55.910 --> 00:11:56.630
telling us.

00:11:56.630 --> 00:11:58.340
I grew up in the
East Bay, and we

00:11:58.340 --> 00:12:00.800
had some crank in
our community when

00:12:00.800 --> 00:12:03.680
I was a kid who had a little
printing press in his basement

00:12:03.680 --> 00:12:04.610
with rubber type.

00:12:04.610 --> 00:12:06.860
And he'd print out these
screeds and put them

00:12:06.860 --> 00:12:08.480
in front of everybody's door.

00:12:08.480 --> 00:12:10.580
And you knew from the
kind of tilty type

00:12:10.580 --> 00:12:13.280
and the uneven inking
that this was not

00:12:13.280 --> 00:12:16.790
a professional operation, which
didn't mean he wasn't right.

00:12:16.790 --> 00:12:18.960
But I believe in
playing statistics.

00:12:18.960 --> 00:12:20.755
The statistics are
"The New York Times"

00:12:20.755 --> 00:12:22.130
and "The San
Francisco Chronicle"

00:12:22.130 --> 00:12:25.130
were more likely to be right
than this guy who was printing

00:12:25.130 --> 00:12:27.590
off stuff in his basement,
who might have been right

00:12:27.590 --> 00:12:29.150
about things once in a while.

00:12:29.150 --> 00:12:32.660
But then sooner or later, "The
Chronicle" would pick up on it.

00:12:32.660 --> 00:12:35.720
And then I would read
about it for realsies.

00:12:35.720 --> 00:12:37.850
But this balkanization
of the news media

00:12:37.850 --> 00:12:40.700
has left us without the
traditional gatekeepers

00:12:40.700 --> 00:12:42.410
and checks and balances.

00:12:42.410 --> 00:12:44.780
People get their news from
all different sources.

00:12:44.780 --> 00:12:47.810
And when they're talking to each
other in the street or online

00:12:47.810 --> 00:12:50.660
or through social media,
they're dealing with what

00:12:50.660 --> 00:12:52.460
they think are different facts.

00:12:52.460 --> 00:12:55.150
I want to clarify there
are not different facts.

00:12:55.150 --> 00:12:56.330
There is a set of facts.

00:12:56.330 --> 00:12:58.040
But there are
different opinions,

00:12:58.040 --> 00:13:02.270
and then there's nonsense
being promoted as fact.

00:13:02.270 --> 00:13:07.880
I think that all of us need
to take seriously President

00:13:07.880 --> 00:13:09.650
Obama's parting words.

00:13:09.650 --> 00:13:12.690
Again, I don't intend
for this to be political.

00:13:12.690 --> 00:13:15.830
I imagine that it may sound
political to some of you.

00:13:15.830 --> 00:13:21.870
I consider myself to be
nonpartisan and down the center

00:13:21.870 --> 00:13:24.170
in most issues.

00:13:24.170 --> 00:13:27.380
I think that one of the tests of
the fact that I am nonpartisan

00:13:27.380 --> 00:13:30.470
is that I've gotten an equal
number of angry letters

00:13:30.470 --> 00:13:33.020
about this latest book
from people on the right

00:13:33.020 --> 00:13:35.900
and people on the left, each
of them accusing me of being

00:13:35.900 --> 00:13:37.800
a partisan for the other side.

00:13:37.800 --> 00:13:40.770
So I must be doing
something right.

00:13:40.770 --> 00:13:42.860
So I'm mentioning
Obama not because I

00:13:42.860 --> 00:13:45.410
favor democratic
elected officials,

00:13:45.410 --> 00:13:48.100
but I think his words were wise.

00:13:48.100 --> 00:13:51.990
In his exit speech, he said
that democracy takes work.

00:13:51.990 --> 00:13:54.900
That you can't just
take it for granted.

00:13:54.900 --> 00:13:56.910
Each of us has to
contribute in some way.

00:13:56.910 --> 00:13:59.140
It was his call for
us to be involved.

00:13:59.140 --> 00:14:01.530
And Obama wasn't saying
only get involved if you're

00:14:01.530 --> 00:14:02.490
going to be a Democrat.

00:14:02.490 --> 00:14:03.614
He was saying get involved.

00:14:03.614 --> 00:14:05.640
Follow your beliefs.

00:14:05.640 --> 00:14:08.130
And I believe that we all
need to be more involved

00:14:08.130 --> 00:14:10.620
in supporting three
institutions that

00:14:10.620 --> 00:14:13.500
are vital to the future
of our democracy.

00:14:13.500 --> 00:14:16.410
One of them is the free
and independent press.

00:14:16.410 --> 00:14:21.120
I think we need to support them
by subscribing, by backing them

00:14:21.120 --> 00:14:25.170
up when there are
attempts to silence them.

00:14:25.170 --> 00:14:28.200
I was gratified to see that
instead of backing down

00:14:28.200 --> 00:14:31.540
after Sean Spicer's
first press conference,

00:14:31.540 --> 00:14:34.980
the press actually doubled down,
and they're working harder.

00:14:34.980 --> 00:14:38.160
"The New York Times"
did a lot of soul

00:14:38.160 --> 00:14:40.950
searching about their
failures in the fall.

00:14:40.950 --> 00:14:43.159
I know that "The Chronicle" is--

00:14:43.159 --> 00:14:44.700
"The San Francisco
Chronicle"-- and I

00:14:44.700 --> 00:14:47.850
know that a number of
other publications have.

00:14:47.850 --> 00:14:51.240
"The New York Times" issued
a scathing internal report

00:14:51.240 --> 00:14:54.000
in which they admitted
to a number of failures.

00:14:54.000 --> 00:14:58.410
And as a result, they're
hiring more reporters

00:14:58.410 --> 00:15:00.330
with diverse backgrounds.

00:15:00.330 --> 00:15:02.910
They're hiring more editors
with diverse backgrounds.

00:15:02.910 --> 00:15:05.460
They're ensuring that "New York
Times" reporters and editors

00:15:05.460 --> 00:15:06.990
have better training.

00:15:06.990 --> 00:15:10.260
And they're making
an effort to address

00:15:10.260 --> 00:15:13.080
voices that might not have been
heard in "The New York Times."

00:15:13.080 --> 00:15:15.180
Just in the last two weeks,
"The New York Times,"

00:15:15.180 --> 00:15:18.750
which has a leftist bent,
in the last two weeks

00:15:18.750 --> 00:15:25.950
I read a pro-life,
anti-abortion op ed,

00:15:25.950 --> 00:15:29.585
which you never would have seen
in the last couple of decades

00:15:29.585 --> 00:15:30.210
in "The Times."

00:15:30.210 --> 00:15:34.020
And I read a pro
Steve Bannon op ed.

00:15:34.020 --> 00:15:35.220
Steve Bannon's not bad.

00:15:35.220 --> 00:15:37.080
This is why he's good.

00:15:37.080 --> 00:15:40.032
So they're making an effort
to address a broad readership.

00:15:40.032 --> 00:15:41.240
I think they need to do that.

00:15:41.240 --> 00:15:43.500
We need to support
the free press.

00:15:43.500 --> 00:15:46.050
The other institution
is the judiciary.

00:15:46.050 --> 00:15:50.430
We need to support an
independent judiciary, which

00:15:50.430 --> 00:15:52.350
functions as a separate
branch of government

00:15:52.350 --> 00:15:55.170
and engages in
evidence-based thinking.

00:15:55.170 --> 00:15:57.540
It was no accident,
it was telling

00:15:57.540 --> 00:16:03.030
that when the federal judges
reviewed the original Trump

00:16:03.030 --> 00:16:05.460
immigration ban, the
phrase that stuck out

00:16:05.460 --> 00:16:09.940
was there is no evidence that
these seven countries are

00:16:09.940 --> 00:16:12.750
posing a danger to us.

00:16:12.750 --> 00:16:14.240
They are evidence-based.

00:16:14.240 --> 00:16:18.860
Now the third institution
is science, scientists,

00:16:18.860 --> 00:16:20.370
the scientific method.

00:16:20.370 --> 00:16:22.500
Scientific method
believes in collecting

00:16:22.500 --> 00:16:25.650
data, withholding
judgment until you

00:16:25.650 --> 00:16:29.550
have a preponderance of
evidence, rigorously assessed,

00:16:29.550 --> 00:16:30.810
peer reviewed.

00:16:30.810 --> 00:16:34.980
Now certainly all of you
can complain that these

00:16:34.980 --> 00:16:36.870
are imperfect systems.

00:16:36.870 --> 00:16:38.700
You know of corrupt journalists.

00:16:38.700 --> 00:16:41.520
You've heard about
journalists making up stories.

00:16:41.520 --> 00:16:44.040
You've heard of corrupt judges.

00:16:44.040 --> 00:16:45.840
You know that there
are corrupt scientists.

00:16:45.840 --> 00:16:47.910
In my own field, in
cognitive neuroscience,

00:16:47.910 --> 00:16:53.400
we've had two or three terrible
episodes in the last few years

00:16:53.400 --> 00:16:55.530
where leading
scientists in our field

00:16:55.530 --> 00:16:58.020
admitted to making up data.

00:16:58.020 --> 00:17:01.140
Harvard scientists,
we read in the '60s,

00:17:01.140 --> 00:17:03.600
took money from
the sugar industry

00:17:03.600 --> 00:17:07.680
in order to play down the
bad health effects of sugar.

00:17:07.680 --> 00:17:11.700
Yes, there are corrupt people
in all these institutions.

00:17:11.700 --> 00:17:16.510
But they're the best we've got,
and they're self-correcting.

00:17:16.510 --> 00:17:19.390
They eventually root
out the corruption.

00:17:19.390 --> 00:17:24.220
And when they work, they
work to sustain democracy.

00:17:24.220 --> 00:17:25.630
Think of judges.

00:17:25.630 --> 00:17:27.609
The whole idea of an
independent judiciary

00:17:27.609 --> 00:17:30.280
is they're not beholden
to special interests.

00:17:30.280 --> 00:17:32.620
They protect the weak
from the powerful.

00:17:32.620 --> 00:17:34.810
They protect the
poor from the rich.

00:17:34.810 --> 00:17:37.150
They protect people
who might be from under

00:17:37.150 --> 00:17:39.820
representative or
disenfranchised communities

00:17:39.820 --> 00:17:40.960
from the majority.

00:17:40.960 --> 00:17:42.777
That's the way it's
supposed to work.

00:17:42.777 --> 00:17:44.110
Again, there are corrupt judges.

00:17:44.110 --> 00:17:45.814
There are biased judges.

00:17:45.814 --> 00:17:47.980
But that doesn't mean we
throw out the whole system.

00:17:51.580 --> 00:17:53.290
Another big point
I'd like to make

00:17:53.290 --> 00:17:58.060
is that I think we
need to, as a society,

00:17:58.060 --> 00:18:00.850
as a community, and
especially here at Google,

00:18:00.850 --> 00:18:03.400
start thinking a little
more carefully about experts

00:18:03.400 --> 00:18:04.810
and venerating experts.

00:18:04.810 --> 00:18:07.780
There's a kind of culture
in the country right now

00:18:07.780 --> 00:18:10.420
of being suspicious of them.

00:18:10.420 --> 00:18:14.470
And that has led to the
current climate of fake news

00:18:14.470 --> 00:18:18.750
and alternative facts, I think.

00:18:18.750 --> 00:18:21.160
And I think we scientists
share some of the blame

00:18:21.160 --> 00:18:25.600
here for the fact that
people don't trust experts.

00:18:25.600 --> 00:18:29.380
Again, some scientists have
admitted to falsifying data.

00:18:29.380 --> 00:18:33.640
The doctor who claimed a link
between autism and vaccines

00:18:33.640 --> 00:18:35.350
had his medical license revoked.

00:18:35.350 --> 00:18:37.000
His paper was retracted.

00:18:37.000 --> 00:18:39.760
He admitted to
falsifying documents.

00:18:39.760 --> 00:18:41.140
Andrew Wakefield was his name.

00:18:41.140 --> 00:18:45.220
But you still, 20
or 25 years later--

00:18:45.220 --> 00:18:47.840
it was 1987 I think,
30 years later--

00:18:47.840 --> 00:18:49.750
we still read about
people who are

00:18:49.750 --> 00:18:54.610
convinced that there is a link
between autism and the MMR

00:18:54.610 --> 00:18:55.640
vaccine.

00:18:55.640 --> 00:18:57.250
I'll come back to
that in a bit when I

00:18:57.250 --> 00:18:58.810
talk about particular examples.

00:18:58.810 --> 00:19:02.410
But I think we scientists
are to blame for not

00:19:02.410 --> 00:19:04.250
policing each other better.

00:19:04.250 --> 00:19:07.210
And part of it has to do
with pseudo expertise, which

00:19:07.210 --> 00:19:09.810
has become kind of a
fascination of mine.

00:19:09.810 --> 00:19:12.160
Often times, people
who are qualified

00:19:12.160 --> 00:19:14.530
and expert in one
domain will start

00:19:14.530 --> 00:19:17.770
pontificating in another domain
that they know nothing about.

00:19:17.770 --> 00:19:20.290
And it drives me crazy.

00:19:20.290 --> 00:19:24.010
A famous local example
again, William Shockley,

00:19:24.010 --> 00:19:27.670
Stanford professor who won
the Nobel Prize in physics.

00:19:27.670 --> 00:19:29.650
He shared it with
two other researchers

00:19:29.650 --> 00:19:32.470
for inventing, co-inventing
the transistor.

00:19:32.470 --> 00:19:34.450
Well, later in his
life, William Shockley,

00:19:34.450 --> 00:19:37.660
PhD in physics, Nobel
Prize in physics,

00:19:37.660 --> 00:19:41.500
developed deeply racist views
about the genetic inferiority

00:19:41.500 --> 00:19:45.080
of a subset of the
American population.

00:19:45.080 --> 00:19:47.950
And he went around the
country espousing these views,

00:19:47.950 --> 00:19:49.600
and people believed him.

00:19:49.600 --> 00:19:52.090
And they must thought, oh, my
god, he's got a Nobel Prize.

00:19:52.090 --> 00:19:53.740
He must be really smart.

00:19:53.740 --> 00:19:58.660
Well, yes, in physics, but he
had no training in genetics

00:19:58.660 --> 00:20:02.230
or genealogy or cognitive
assessment or any of the things

00:20:02.230 --> 00:20:03.490
he'd need to know.

00:20:03.490 --> 00:20:05.680
And by the way, he was wrong.

00:20:05.680 --> 00:20:07.450
But we tended to believe him.

00:20:07.450 --> 00:20:10.349
And I'd like to point out
that the PhD in physics

00:20:10.349 --> 00:20:11.890
doesn't even mean
that he's an expert

00:20:11.890 --> 00:20:13.590
in other kinds of physics.

00:20:13.590 --> 00:20:15.320
He was a materials
physics expert.

00:20:15.320 --> 00:20:17.350
And I wouldn't have
trusted him to start

00:20:17.350 --> 00:20:22.920
talking about cosmology
or about string theory.

00:20:22.920 --> 00:20:25.420
Expertise it turns
out is very narrow,

00:20:25.420 --> 00:20:27.070
and it's domain specific.

00:20:27.070 --> 00:20:28.540
Occasionally, you
run into people

00:20:28.540 --> 00:20:30.280
who are expert in
a couple of fields.

00:20:30.280 --> 00:20:34.480
But really, when an expert's
talking about something,

00:20:34.480 --> 00:20:36.610
you want to be sure
that they are qualified

00:20:36.610 --> 00:20:39.590
and that their
expertise is relevant.

00:20:39.590 --> 00:20:41.560
There are some funny
examples of this.

00:20:41.560 --> 00:20:43.690
How many of you
remember the claim,

00:20:43.690 --> 00:20:46.360
hearing the ad campaign,
"four out of five dentists

00:20:46.360 --> 00:20:49.200
recommend Colgate?"

00:20:49.200 --> 00:20:51.240
Famous ad campaign--
well, it turns out

00:20:51.240 --> 00:20:54.270
Colgate got sued for it.

00:20:54.270 --> 00:20:56.081
Not because of pseudo
experts, but I'll

00:20:56.081 --> 00:20:57.080
get to that in a moment.

00:20:57.080 --> 00:20:58.371
I'll make the link in a moment.

00:20:58.371 --> 00:21:01.860
They got sued for it because
of what the claim implies.

00:21:01.860 --> 00:21:04.530
To the average person, the
court upheld, the claim

00:21:04.530 --> 00:21:07.830
that four out of five
recommend Colgate

00:21:07.830 --> 00:21:11.160
is tantamount to saying that
four out of five dentists

00:21:11.160 --> 00:21:13.180
prefer Colgate.

00:21:13.180 --> 00:21:14.610
But in fact, they don't.

00:21:14.610 --> 00:21:17.440
Part of critical thinking is
we have to say to ourselves,

00:21:17.440 --> 00:21:21.954
what question were the dentists
asked by the pollsters?

00:21:21.954 --> 00:21:23.370
Well, it turns out
they were asked

00:21:23.370 --> 00:21:26.010
to list on a piece of
paper as many toothpastes

00:21:26.010 --> 00:21:29.320
as they like that they
recommend to their patients?

00:21:29.320 --> 00:21:32.140
And it turns out they listed
Colgate and Crest and Aim

00:21:32.140 --> 00:21:34.990
and Aquafresh and Gleam and
Arm and Hammer and a bunch

00:21:34.990 --> 00:21:36.470
toothpastes.

00:21:36.470 --> 00:21:38.470
It makes you wonder, what
was that fifth dentist

00:21:38.470 --> 00:21:39.857
recommending, right?

00:21:39.857 --> 00:21:41.190
That you don't brush your teeth?

00:21:41.190 --> 00:21:42.040
Who knows?

00:21:42.040 --> 00:21:44.080
But four out of
five-- it was sued.

00:21:44.080 --> 00:21:46.630
They had to stop doing
the ads because it's

00:21:46.630 --> 00:21:48.230
a misleading claim.

00:21:48.230 --> 00:21:50.494
So when you counter
claims like that,

00:21:50.494 --> 00:21:51.910
part of the "Field
Guide to Lies,"

00:21:51.910 --> 00:21:55.690
the "Weaponized Lies" book
is to give every one of us

00:21:55.690 --> 00:21:59.410
some tools, easy to
reach tools, that we

00:21:59.410 --> 00:22:01.360
can use when we hear
a claim like that

00:22:01.360 --> 00:22:02.990
and know what questions to ask.

00:22:02.990 --> 00:22:05.590
So the first question
to ask may not be this.

00:22:05.590 --> 00:22:07.930
But somewhere down
the list, if you

00:22:07.930 --> 00:22:10.630
hear the result of a
survey, ask yourself

00:22:10.630 --> 00:22:13.930
what question do you suppose
these folks were asked.

00:22:13.930 --> 00:22:16.120
And if it's a good
report, if it's

00:22:16.120 --> 00:22:19.330
in a good newspaper or
a good NPR reporter,

00:22:19.330 --> 00:22:21.610
or if somebody has written
a good article on it,

00:22:21.610 --> 00:22:23.890
they'll tell you
what the survey was.

00:22:23.890 --> 00:22:25.180
They'll reveal that.

00:22:25.180 --> 00:22:27.117
They show you what
the questions were.

00:22:27.117 --> 00:22:29.200
But getting back to pseudo
experts, the thing that

00:22:29.200 --> 00:22:31.990
fascinates me about
this is I'm not

00:22:31.990 --> 00:22:35.140
sure dentists are the
right people to ask.

00:22:35.140 --> 00:22:37.270
Why do I say that?

00:22:37.270 --> 00:22:39.880
I've been going to
dentists all my life.

00:22:39.880 --> 00:22:42.872
My dentist has never asked
me what toothpaste I use.

00:22:42.872 --> 00:22:44.830
And I'm usually in a
room, and there's somebody

00:22:44.830 --> 00:22:46.540
in a room on either side of me.

00:22:46.540 --> 00:22:49.300
And the dentist is going around
and visiting three people

00:22:49.300 --> 00:22:50.050
at once.

00:22:50.050 --> 00:22:51.962
And I've overheard
his conversations.

00:22:51.962 --> 00:22:53.920
I've never heard him ask
any other patient what

00:22:53.920 --> 00:22:55.590
toothpaste they use.

00:22:55.590 --> 00:22:59.631
So why is it that we think
dentists are the right people

00:22:59.631 --> 00:23:00.130
to ask?

00:23:00.130 --> 00:23:01.060
And who would you ask?

00:23:01.060 --> 00:23:02.590
Well, you probably
would want to get

00:23:02.590 --> 00:23:04.750
a scientist or a
medical researcher

00:23:04.750 --> 00:23:08.245
to randomly assign toothpastes
to a group of people.

00:23:08.245 --> 00:23:10.120
And then they use these
different toothpastes

00:23:10.120 --> 00:23:12.070
and you follow them
for a few years.

00:23:12.070 --> 00:23:15.790
And then you measure various
outcomes of oral health.

00:23:15.790 --> 00:23:18.040
Gingivitis, gum
disease, bad breath,

00:23:18.040 --> 00:23:21.670
cavities, whatever it is, and
then you've got your answer.

00:23:21.670 --> 00:23:24.836
That's a scientific study.

00:23:24.836 --> 00:23:26.710
Dentists aren't necessarily
the ones to know.

00:23:26.710 --> 00:23:29.200
Shame on those dentists
for answering the question

00:23:29.200 --> 00:23:30.520
in the first place.

00:23:30.520 --> 00:23:33.070
And shame on the rest
of the dental community

00:23:33.070 --> 00:23:34.720
for not pointing
out that dentists

00:23:34.720 --> 00:23:36.280
don't know the answer to this.

00:23:36.280 --> 00:23:37.702
Now I'm kind of
making fun of this

00:23:37.702 --> 00:23:39.160
because there's
not a lot at stake.

00:23:39.160 --> 00:23:42.250
Which toothpaste you use
doesn't seem to matter much

00:23:42.250 --> 00:23:43.330
according to science.

00:23:43.330 --> 00:23:45.400
And the recent report
that even flossing

00:23:45.400 --> 00:23:47.740
doesn't seem to matter much.

00:23:47.740 --> 00:23:51.100
But it's not funny when
people's lives are at stake.

00:23:51.100 --> 00:23:53.320
And there was a
tragic consequence

00:23:53.320 --> 00:23:55.630
to this issue of
pseudo expertise

00:23:55.630 --> 00:23:59.320
when a young woman named
Kelly Clark in England

00:23:59.320 --> 00:24:03.010
was on trial for
murdering her infant.

00:24:03.010 --> 00:24:06.370
This was the second
infant of hers that died.

00:24:06.370 --> 00:24:10.690
And in testimony,
the pediatrician

00:24:10.690 --> 00:24:16.210
testified that the odds of both
babies dying of natural causes

00:24:16.210 --> 00:24:18.310
were phenomenally against her.

00:24:18.310 --> 00:24:20.890
That she had to have
killed this baby.

00:24:20.890 --> 00:24:27.880
That the probability was
very, very extremely,

00:24:27.880 --> 00:24:31.000
significantly low that
the baby could have died

00:24:31.000 --> 00:24:32.590
other than at her own hand.

00:24:32.590 --> 00:24:34.450
So she went to prison
for three years.

00:24:34.450 --> 00:24:37.510
The whole time her husband
worked to have her exonerated.

00:24:37.510 --> 00:24:41.440
He finally had some
microbiological studies

00:24:41.440 --> 00:24:43.060
done of the infant's brain.

00:24:43.060 --> 00:24:46.420
And it was found out that the
infant had a congenital disease

00:24:46.420 --> 00:24:48.940
that killed it.

00:24:48.940 --> 00:24:51.910
Now we believe the
dentists on the toothpaste,

00:24:51.910 --> 00:24:54.730
because we think ah,
dentists, teeth, oral health,

00:24:54.730 --> 00:24:55.870
they would know.

00:24:55.870 --> 00:24:56.954
But they don't.

00:24:56.954 --> 00:24:58.870
We believe the pediatrician,
because we think,

00:24:58.870 --> 00:25:00.160
oh, infants, pediatrician.

00:25:00.160 --> 00:25:01.730
That's a baby doctor.

00:25:01.730 --> 00:25:05.350
But most pediatricians
go an entire lifetime

00:25:05.350 --> 00:25:07.820
without ever seeing
an infant mortality.

00:25:07.820 --> 00:25:11.026
Because fortunately, infant
mortalities are rare.

00:25:11.026 --> 00:25:13.920
A pediatrician's not
the right one to ask.

00:25:13.920 --> 00:25:17.310
You'd have to ask a medical
examiner, a coroner,

00:25:17.310 --> 00:25:20.610
or an epidemiologist, somebody
trained in large population

00:25:20.610 --> 00:25:23.100
statistics of
infant death, people

00:25:23.100 --> 00:25:25.950
who have seen hundreds or
thousands of infant deaths.

00:25:25.950 --> 00:25:28.170
That's the right
person to have testify.

00:25:28.170 --> 00:25:29.670
And if the defense
attorney had been

00:25:29.670 --> 00:25:33.450
any good in Kelly Clark's case,
he would have pointed that out.

00:25:33.450 --> 00:25:36.000
And she wouldn't have had to
spend three years in prison.

00:25:36.000 --> 00:25:38.880
Just imagine you're
grieving over the loss

00:25:38.880 --> 00:25:42.480
of your second child and in the
middle of the grieving process,

00:25:42.480 --> 00:25:44.700
actually in her case at the
beginning of the grieving

00:25:44.700 --> 00:25:47.730
process, you're shackled
and taken from your home

00:25:47.730 --> 00:25:50.860
and thrown in prison and
then you're put on trial.

00:25:50.860 --> 00:25:51.960
It's just horrible.

00:25:51.960 --> 00:25:56.100
This is another
kind of consequence

00:25:56.100 --> 00:25:59.130
of a failure of thinking
clearly about what's

00:25:59.130 --> 00:26:00.750
in front of our very eyes.

00:26:00.750 --> 00:26:05.190
I have an interest in
conspiracy theories.

00:26:05.190 --> 00:26:07.215
We can talk about that
more later during the Q&amp;A

00:26:07.215 --> 00:26:07.950
if you want.

00:26:07.950 --> 00:26:10.020
I don't want to
get side tracked.

00:26:10.020 --> 00:26:12.570
And certainly I believe
there are conspiracies.

00:26:12.570 --> 00:26:15.000
I mean Watergate
was a conspiracy.

00:26:15.000 --> 00:26:16.620
It certainly seems
to be the case

00:26:16.620 --> 00:26:18.990
that there was some
conspiratorial aspect

00:26:18.990 --> 00:26:20.880
to the Kennedy
assassination, if not

00:26:20.880 --> 00:26:24.060
the subsequent
investigation of it.

00:26:24.060 --> 00:26:26.820
There are conspiracies going
on all around the world

00:26:26.820 --> 00:26:28.350
all the time.

00:26:28.350 --> 00:26:30.600
But they're probably
not as many of them

00:26:30.600 --> 00:26:33.560
as some conspiracy
theorists would think.

00:26:33.560 --> 00:26:37.440
And I think that part
of critical thinking

00:26:37.440 --> 00:26:41.490
here is that a handful
of unexplained anomalies

00:26:41.490 --> 00:26:44.970
doesn't discredit or undermine
an established theory that's

00:26:44.970 --> 00:26:47.520
based on thousands
of data points.

00:26:47.520 --> 00:26:51.720
And especially, if you're
talking about crime scenes.

00:26:51.720 --> 00:26:55.590
Crime scenes are really
messy in a real world case.

00:26:55.590 --> 00:26:58.710
And you can't recover every
piece of the airplane.

00:26:58.710 --> 00:27:00.750
And you can't recover
every body part

00:27:00.750 --> 00:27:02.460
from the people who
were dismembered.

00:27:02.460 --> 00:27:06.030
And so you can't have
a 100% investigation.

00:27:06.030 --> 00:27:08.310
There are always
unanswered questions.

00:27:08.310 --> 00:27:10.650
But if you've got a
well-formed theory that's

00:27:10.650 --> 00:27:13.890
corroborated and backed
up by true experts, not

00:27:13.890 --> 00:27:18.780
pseudo experts, I think that you
can assume that you're probably

00:27:18.780 --> 00:27:19.720
on the right track.

00:27:23.000 --> 00:27:25.580
By the way, there are often
many unanswered questions

00:27:25.580 --> 00:27:28.970
because the witnesses
didn't see the entire thing

00:27:28.970 --> 00:27:32.060
or the witnesses were at odd
angles and different angles

00:27:32.060 --> 00:27:36.560
from one another and that
contributes to it as well.

00:27:36.560 --> 00:27:39.020
I want to talk about
a handful of tips

00:27:39.020 --> 00:27:42.040
that I cover in the book.

00:27:42.040 --> 00:27:45.870
I'm grateful to you for inviting
me to talk about the book.

00:27:45.870 --> 00:27:47.930
I'll tell you a little
bit about why I wrote it.

00:27:47.930 --> 00:27:51.640
I started writing
it in 2001 because I

00:27:51.640 --> 00:27:54.340
was charged with the
responsibility of teaching

00:27:54.340 --> 00:27:59.590
McGill honors students in
psychology and neuroscience

00:27:59.590 --> 00:28:01.090
how to think critically.

00:28:01.090 --> 00:28:04.420
And I used a little
book called "How

00:28:04.420 --> 00:28:07.450
to Lie with Statistics,"
which I highly recommend.

00:28:07.450 --> 00:28:10.180
It was written by Darrel Huff.

00:28:10.180 --> 00:28:11.500
It's a thin little paperback.

00:28:11.500 --> 00:28:12.970
It's very amusing.

00:28:12.970 --> 00:28:14.920
The problem I had with
the book was that most

00:28:14.920 --> 00:28:17.350
of the examples in it-- it
was written in the early '50s

00:28:17.350 --> 00:28:18.680
or late '40s.

00:28:18.680 --> 00:28:22.240
Most of the examples come from
the US Steel Annual Report

00:28:22.240 --> 00:28:27.470
from 1943 or the
Coolidge presidency.

00:28:27.470 --> 00:28:30.400
And I wanted to have more
contemporary examples.

00:28:30.400 --> 00:28:33.680
So I asked my students to
gather them from the media.

00:28:33.680 --> 00:28:36.450
And I ended up with
boxes and boxes of these,

00:28:36.450 --> 00:28:38.680
and I started
writing about them.

00:28:38.680 --> 00:28:41.970
And I'm a bit of
a procrastinator.

00:28:41.970 --> 00:28:44.380
So although I started
the book in 2001.

00:28:44.380 --> 00:28:46.900
I wrote three other
books in the meantime.

00:28:46.900 --> 00:28:49.720
But in 2014, after
visiting you here

00:28:49.720 --> 00:28:52.060
to talk about the
organized mind,

00:28:52.060 --> 00:28:54.640
a lot of the
conversations I had here

00:28:54.640 --> 00:28:57.062
were about the critical
thinking chapter in that book.

00:28:57.062 --> 00:28:59.020
And I thought, oh, well,
I've got this old book

00:28:59.020 --> 00:29:00.040
on the backburner.

00:29:00.040 --> 00:29:03.550
I think that I'll double
down and work on that.

00:29:03.550 --> 00:29:05.860
And I wanted it to be a
kind of an updated, "How

00:29:05.860 --> 00:29:09.520
to Lie with Statistics," but I
wanted it to be very practical.

00:29:09.520 --> 00:29:12.460
No theory, there's nothing
about brain science.

00:29:12.460 --> 00:29:14.650
It's just practical steps
that any high school

00:29:14.650 --> 00:29:17.440
kid or any adult who's
interested in this

00:29:17.440 --> 00:29:21.040
could follow in order to arm
yourself against the people who

00:29:21.040 --> 00:29:22.960
want to separate
you from your money

00:29:22.960 --> 00:29:26.290
or deceive you or distort
facts for their own means,

00:29:26.290 --> 00:29:28.810
their own ends.

00:29:28.810 --> 00:29:30.940
It really is a tool
kit that each of us

00:29:30.940 --> 00:29:33.960
can reach for that's
simple to apply.

00:29:33.960 --> 00:29:35.210
So let me give you an example.

00:29:35.210 --> 00:29:39.280
I've already kind of
talked in generalities

00:29:39.280 --> 00:29:40.520
about some of them.

00:29:40.520 --> 00:29:44.350
One of the powerful things
is to check for plausibility.

00:29:44.350 --> 00:29:48.220
Now all you engineers know this.

00:29:48.220 --> 00:29:51.130
Plausibility is
usually the first thing

00:29:51.130 --> 00:29:52.900
you want to look
at with anything

00:29:52.900 --> 00:29:54.074
that has a number on it.

00:29:54.074 --> 00:29:56.740
Because the number could just be
ridiculous, and then everything

00:29:56.740 --> 00:29:59.380
that follows you don't
have to worry about.

00:29:59.380 --> 00:30:02.970
So I was in a taxicab last fall.

00:30:02.970 --> 00:30:06.160
And I was working in
the back on my computer,

00:30:06.160 --> 00:30:09.850
I have a little internet,
remote internet Wi-Fi device.

00:30:09.850 --> 00:30:13.280
And the taxicab driver says,
oh, you're on the internet.

00:30:13.280 --> 00:30:14.422
And I said yes.

00:30:14.422 --> 00:30:15.880
He says, oh, I just
read that there

00:30:15.880 --> 00:30:21.790
are 17 billion people in the
world who lack internet access.

00:30:21.790 --> 00:30:25.900
And you know, I'm not really an
expert on the world population.

00:30:25.900 --> 00:30:29.320
But the last time I looked, it
was hovering above 7 billion.

00:30:29.320 --> 00:30:31.330
It might even have been
as high as 7 and 1/2,

00:30:31.330 --> 00:30:32.920
I don't really remember.

00:30:32.920 --> 00:30:36.010
I suppose it could have crept
up to 8 billion since I looked,

00:30:36.010 --> 00:30:38.320
but I don't think
it's at 17 billion.

00:30:38.320 --> 00:30:40.360
That's just not plausible.

00:30:40.360 --> 00:30:44.560
So I mean you can throw out
a claim like that right away

00:30:44.560 --> 00:30:46.720
with just some real
world knowledge.

00:30:46.720 --> 00:30:48.910
In fact, we had a very
interesting conversation

00:30:48.910 --> 00:30:51.580
because I had just
visited Google X, where

00:30:51.580 --> 00:30:55.720
I was shown your balloon project
which is going to be providing

00:30:55.720 --> 00:30:57.820
internet to Africans.

00:30:57.820 --> 00:30:59.230
He was very excited about it.

00:30:59.230 --> 00:31:02.230
I was very excited
to tell about it.

00:31:02.230 --> 00:31:06.250
And the interesting thing
is I didn't contradict him

00:31:06.250 --> 00:31:07.810
at the beginning of
the conversation,

00:31:07.810 --> 00:31:10.900
because I could tell he
wanted to talk about this.

00:31:10.900 --> 00:31:12.649
And I said, you know
it is a tragedy.

00:31:12.649 --> 00:31:14.440
There are a lot of
people without internet.

00:31:14.440 --> 00:31:17.290
You'd think in this
day and age, internet,

00:31:17.290 --> 00:31:20.800
which is the great
democratizing force that

00:31:20.800 --> 00:31:27.442
can help raise people out
of ignorance and such,

00:31:27.442 --> 00:31:28.650
it should be more widespread.

00:31:28.650 --> 00:31:30.140
So we had that
conversation, then

00:31:30.140 --> 00:31:31.580
just as I got out of the cab.

00:31:31.580 --> 00:31:34.790
I said, oh, and by the way, I
don't think it's 17 billion,

00:31:34.790 --> 00:31:37.670
because there's only 7 and 1/2
billion people in the world.

00:31:37.670 --> 00:31:40.760
At that point, he was
receptive to being corrected.

00:31:40.760 --> 00:31:43.460
My younger self would have
just said, no, you're wrong.

00:31:46.280 --> 00:31:47.590
Here's another one.

00:31:47.590 --> 00:31:51.050
This was actually published.

00:31:51.050 --> 00:31:55.340
The anti-marijuana initiative
folks claimed that,

00:31:55.340 --> 00:31:59.330
in the 35 years since California
stopped enforcing its marijuana

00:31:59.330 --> 00:32:04.250
laws, the number of
arrests for marijuana--

00:32:04.250 --> 00:32:07.610
I'm sorry, the number of users,
the number of marijuana users--

00:32:07.610 --> 00:32:09.770
in the 35 years since
marijuana laws stopped

00:32:09.770 --> 00:32:13.190
being enforced in California,
the number of marijuana users

00:32:13.190 --> 00:32:14.922
has doubled every year.

00:32:14.922 --> 00:32:17.557
[LAUGHTER]

00:32:17.557 --> 00:32:19.140
For those of you who
aren't chuckling,

00:32:19.140 --> 00:32:21.390
these are engineers
chuckling because they

00:32:21.390 --> 00:32:25.320
know what happens when you
double a number for 35 times.

00:32:25.320 --> 00:32:26.820
And you can do
this just by making

00:32:26.820 --> 00:32:27.940
a very simple assumption.

00:32:27.940 --> 00:32:30.180
Let's assume that
35 years ago, there

00:32:30.180 --> 00:32:34.110
was only one marijuana smoker in
the entire state of California.

00:32:34.110 --> 00:32:39.180
I'm pretty sure there was
more than one marijuana smoker

00:32:39.180 --> 00:32:41.889
in this very spot 35
years ago, but let's just

00:32:41.889 --> 00:32:43.680
say for the whole state
there was only one.

00:32:43.680 --> 00:32:46.870
And let's double that number
every year for 35 years.

00:32:46.870 --> 00:32:50.070
Well, by the time you get to 35,
you're up at that 17 billion I

00:32:50.070 --> 00:32:51.430
mentioned before.

00:32:51.430 --> 00:32:54.120
It's not plausible, more people
than there are in the world.

00:32:54.120 --> 00:33:00.460
So throw that out, very easy
to do, check for plausibility.

00:33:05.310 --> 00:33:12.010
More people died in plane
crashes in 2014 than in 1960.

00:33:12.010 --> 00:33:18.160
Therefore, air travel
is at unsafe levels

00:33:18.160 --> 00:33:20.080
and you should stop
traveling by air.

00:33:20.080 --> 00:33:24.490
It's one of the most
unsafe levels in history.

00:33:24.490 --> 00:33:26.890
So plausibility--
is it plausible

00:33:26.890 --> 00:33:30.730
that there were more airplane
crashes in 2014 than 1960?

00:33:30.730 --> 00:33:32.500
Yeah, that seems plausible.

00:33:32.500 --> 00:33:35.860
I don't know, but it
doesn't seem implausible.

00:33:35.860 --> 00:33:40.210
But wait a minute, does the
conclusion follow the premise?

00:33:40.210 --> 00:33:42.250
Are the data that
they're citing actually

00:33:42.250 --> 00:33:44.110
relevant to the
claim they're making?

00:33:44.110 --> 00:33:46.744
They're claiming that
air travel is unsafe.

00:33:46.744 --> 00:33:48.160
It turns out that,
yes, there were

00:33:48.160 --> 00:33:49.780
more plane crashes in 2014.

00:33:49.780 --> 00:33:51.820
But there were a
lot more flights

00:33:51.820 --> 00:33:55.780
than in 1960 and a
lot more passengers.

00:33:55.780 --> 00:33:59.530
So the relevant statistic
here isn't how many crashes,

00:33:59.530 --> 00:34:02.350
but how many crashes
per 1,000 miles flown

00:34:02.350 --> 00:34:05.140
or how many crashes
per 1,000 flights,

00:34:05.140 --> 00:34:07.990
or how many fatalities
per 1,000 miles flown.

00:34:07.990 --> 00:34:10.270
Anything like that
that scales so

00:34:10.270 --> 00:34:12.790
that you're dealing
with a proportion rather

00:34:12.790 --> 00:34:13.960
than raw numbers.

00:34:13.960 --> 00:34:16.510
You have to account for the
fact that the world has changed.

00:34:16.510 --> 00:34:22.210
So we often find that people,
either because they're

00:34:22.210 --> 00:34:25.929
trying to deceive us or
because they don't know better

00:34:25.929 --> 00:34:28.719
themselves, will bring
up irrelevant facts.

00:34:28.719 --> 00:34:32.710
And a lot of public debate
goes around these kinds of--

00:34:32.710 --> 00:34:35.909
well, this is true,
so this must be true.

00:34:35.909 --> 00:34:38.489
No, it's not true that
that must be true.

00:34:38.489 --> 00:34:40.810
It doesn't necessarily follow.

00:34:40.810 --> 00:34:43.239
By the way, for
those of you that

00:34:43.239 --> 00:34:47.290
are fans of Sherlock Holmes
and his famous saying,

00:34:47.290 --> 00:34:48.850
"deduction, my dear Watson."

00:34:48.850 --> 00:34:51.550
Sherlock Holmes does
not engage in deduction.

00:34:51.550 --> 00:34:54.370
He engages in something
called abduction,

00:34:54.370 --> 00:34:57.490
which is clever guesses
that fit the facts.

00:34:57.490 --> 00:35:00.130
Deduction is something
that has to be true

00:35:00.130 --> 00:35:02.800
given the premises or the facts
or the evidence that you've

00:35:02.800 --> 00:35:03.610
collected.

00:35:03.610 --> 00:35:05.320
That's not what he does.

00:35:05.320 --> 00:35:08.110
If you look carefully, most
of the time he's saying,

00:35:08.110 --> 00:35:10.060
well, I notice that
there is a cigarette

00:35:10.060 --> 00:35:13.697
burn on the left sleeve, which
must mean that this person is

00:35:13.697 --> 00:35:16.030
right-handed, because it would
be very difficult to burn

00:35:16.030 --> 00:35:19.360
your own sleeve
if you're smoking

00:35:19.360 --> 00:35:22.570
with the left hand or
these kinds of things.

00:35:22.570 --> 00:35:23.530
It's not deduction.

00:35:23.530 --> 00:35:24.820
It's abduction.

00:35:24.820 --> 00:35:27.400
Another thing I'd
like to remind you

00:35:27.400 --> 00:35:32.787
is that averages are
distortions by definition.

00:35:32.787 --> 00:35:35.120
Anytime you're looking at an
average, it's a distortion,

00:35:35.120 --> 00:35:36.980
and it may not be
telling you all

00:35:36.980 --> 00:35:39.290
that you really need to know.

00:35:39.290 --> 00:35:42.560
So I could tell you that
there is a room next door

00:35:42.560 --> 00:35:45.680
and the net worth, the average
net worth of people in it,

00:35:45.680 --> 00:35:48.110
there's 10 people in there,
their average net worth

00:35:48.110 --> 00:35:48.920
is $5 billion.

00:35:48.920 --> 00:35:52.880
And if you're collecting
for your favorite charity

00:35:52.880 --> 00:35:56.240
or you're running a bake
sale for your kid's school

00:35:56.240 --> 00:35:59.921
or you're thinking of
leaving Google and working

00:35:59.921 --> 00:36:02.420
for a startup, and if only you
can get a little bit of money

00:36:02.420 --> 00:36:06.380
going, you're thinking, well,
10 people, 5 billion apiece,

00:36:06.380 --> 00:36:08.000
I've got to get in that room.

00:36:08.000 --> 00:36:10.670
But you know it could be
nine homeless people and Mark

00:36:10.670 --> 00:36:12.890
Zuckerberg, whose net
worth is $50 billion,

00:36:12.890 --> 00:36:15.290
and it averages out
to $5 billion each.

00:36:15.290 --> 00:36:16.760
The average is correct.

00:36:16.760 --> 00:36:20.360
Averages are a distortion
because they don't tell you

00:36:20.360 --> 00:36:21.830
all you need to
know and what you

00:36:21.830 --> 00:36:24.500
should insist on
having, of course,

00:36:24.500 --> 00:36:27.740
along with an average is
the range and some measure

00:36:27.740 --> 00:36:30.444
of the dispersion.

00:36:30.444 --> 00:36:32.860
Next time you encounter an
average, if those things aren't

00:36:32.860 --> 00:36:34.960
reported, the range and
the standard deviation

00:36:34.960 --> 00:36:38.830
or some measure of dispersion,
ignore it, because it probably

00:36:38.830 --> 00:36:39.730
isn't very helpful.

00:36:44.560 --> 00:36:47.300
I think that getting
back to society.

00:36:47.300 --> 00:36:51.130
I think that we
all need models of

00:36:51.130 --> 00:36:52.600
clear evidence-based thinking.

00:36:52.600 --> 00:36:55.330
And they're in short
supply these days.

00:36:55.330 --> 00:36:58.960
We need them in the White House
and the courts and the media.

00:36:58.960 --> 00:37:02.320
TV shows like "Perry
Mason," when I was growing,

00:37:02.320 --> 00:37:07.240
up they showed evidence-based
thinking to a wide audience.

00:37:07.240 --> 00:37:11.887
Perry Mason would try a case,
and he'd present evidence,

00:37:11.887 --> 00:37:13.720
and then there'd be
some surprising evidence

00:37:13.720 --> 00:37:15.989
from the defense or
from the prosecutor.

00:37:15.989 --> 00:37:16.780
He was the defense.

00:37:16.780 --> 00:37:18.910
There was a prosecutor.

00:37:18.910 --> 00:37:20.800
The judge would allow
some evidence and not

00:37:20.800 --> 00:37:21.460
other evidence.

00:37:21.460 --> 00:37:23.500
Now this was entertainment.

00:37:23.500 --> 00:37:25.430
It wasn't an education.

00:37:25.430 --> 00:37:29.380
But it did model the very notion
that evidence-based thinking

00:37:29.380 --> 00:37:30.610
is a thing.

00:37:30.610 --> 00:37:33.880
And it made it look
attractive and sexy.

00:37:33.880 --> 00:37:39.070
Whether you were a William
F. Buckley fan or not,

00:37:39.070 --> 00:37:41.950
his television show,
"Crossfire" was it?

00:37:41.950 --> 00:37:43.300
AUDIENCE: Yeah.

00:37:43.300 --> 00:37:46.000
DAN LEVITIN: That had civil
discussion between people

00:37:46.000 --> 00:37:47.920
who disagreed about
things, and they

00:37:47.920 --> 00:37:50.459
stuck close to what the
evidence had to say.

00:37:50.459 --> 00:37:52.000
Their viewpoints
might have differed.

00:37:52.000 --> 00:37:55.090
But they were engaging in
evidence-based thinking.

00:37:55.090 --> 00:37:57.580
I think we need better
models for that.

00:37:57.580 --> 00:38:01.030
I'd like to see a
site called, that

00:38:01.030 --> 00:38:02.410
mirrors scholar.google.com.

00:38:02.410 --> 00:38:05.680
By the way, I've been telling
everybody I know about it.

00:38:05.680 --> 00:38:08.710
I don't think you do a very
good job of advertising it.

00:38:08.710 --> 00:38:11.380
But I tell people that if
you go to scholar.google

00:38:11.380 --> 00:38:14.320
and you're looking for something
about a scientific claim

00:38:14.320 --> 00:38:17.530
like is echinacea really
going to help me with my cold?

00:38:17.530 --> 00:38:19.870
Or I've just been
prescribed this statin,

00:38:19.870 --> 00:38:22.030
and I want to know what
the side effects are.

00:38:22.030 --> 00:38:23.860
Rather than searching
in regular Google,

00:38:23.860 --> 00:38:26.680
if people search in
scholar.google.com,

00:38:26.680 --> 00:38:29.950
they end up getting a much
narrower set of results

00:38:29.950 --> 00:38:33.070
that are primarily, as you
know, from the peer reviewed

00:38:33.070 --> 00:38:34.612
scientific literature.

00:38:34.612 --> 00:38:36.070
And so they're
getting results that

00:38:36.070 --> 00:38:38.320
have been vetted
in some sense, that

00:38:38.320 --> 00:38:42.277
are much more helpful
than just if you

00:38:42.277 --> 00:38:44.110
put in the name of a
drug in regular Google.

00:38:44.110 --> 00:38:47.740
You could end up on
the website set up

00:38:47.740 --> 00:38:49.370
by the manufacturer of the drug.

00:38:49.370 --> 00:38:51.340
And there could be
biases, of course.

00:38:51.340 --> 00:38:53.830
Or a site set up
by the manufacturer

00:38:53.830 --> 00:38:56.770
of a competing drug who's trying
to get you away from this one.

00:38:56.770 --> 00:38:59.025
Or a shill site like
Americansforbett

00:38:59.025 --> 00:39:02.800
erhealthcare.org, which really
is run by Pfizer or something.

00:39:02.800 --> 00:39:05.860
I mean scholar.google is
this nice independent thing.

00:39:05.860 --> 00:39:10.840
And what I'd like to suggest
that Google do, in addition

00:39:10.840 --> 00:39:13.630
to scholar.google.com, I'd
like to see evidence.google.com

00:39:13.630 --> 00:39:18.190
where you can just type
in anything like sex slave

00:39:18.190 --> 00:39:23.770
operation in pizza parlor
or who had the larger

00:39:23.770 --> 00:39:27.850
crowd at their inauguration,
and evidence.google

00:39:27.850 --> 00:39:31.120
will return just the evidence
that weighs in on that issue.

00:39:31.120 --> 00:39:35.020
Both sides, so that the
intelligent searcher,

00:39:35.020 --> 00:39:37.840
web user can make
up their own mind.

00:39:37.840 --> 00:39:40.330
But you would see,
I would imagine

00:39:40.330 --> 00:39:43.300
there'd be two columns, right,
evidence for, evidence against.

00:39:43.300 --> 00:39:47.590
And you can see by the
quality and amount of evidence

00:39:47.590 --> 00:39:50.200
where the needle tends to lean.

00:39:50.200 --> 00:39:52.060
Every time I come here
and make suggestions,

00:39:52.060 --> 00:39:53.726
I feel like you're
all rolling your eyes

00:39:53.726 --> 00:39:58.090
in the back of your head,
but that's what I think.

00:39:58.090 --> 00:39:59.890
Last time I was here,
I said that I thought

00:39:59.890 --> 00:40:05.620
that regular Google search--

00:40:05.620 --> 00:40:07.630
I had just been
told in the lunch

00:40:07.630 --> 00:40:10.360
that I had before I came
here last time that Google

00:40:10.360 --> 00:40:14.800
was very proud of the fact that
when they first started out--

00:40:14.800 --> 00:40:17.650
well, when you
first started out,

00:40:17.650 --> 00:40:19.930
when Google was in a
dorm room effectively--

00:40:19.930 --> 00:40:21.880
and you searched Google
in the early days,

00:40:21.880 --> 00:40:24.310
you had to scroll
down quite a ways

00:40:24.310 --> 00:40:27.460
before you would find the thing
you were really looking for.

00:40:27.460 --> 00:40:30.545
And Google has been working
tirelessly of course,

00:40:30.545 --> 00:40:32.170
to make the thing
you're really looking

00:40:32.170 --> 00:40:35.980
for the first hit on the
list, so that you're not

00:40:35.980 --> 00:40:37.180
wasting time.

00:40:37.180 --> 00:40:40.600
And there's been a lot
of discussion about how,

00:40:40.600 --> 00:40:43.720
because Google knows your IP
address, whether you're signed

00:40:43.720 --> 00:40:46.150
in or not, and it knows
your search history,

00:40:46.150 --> 00:40:49.090
it tends to tailor
the results for you.

00:40:49.090 --> 00:40:57.070
So if I were to search for
something about climate change,

00:40:57.070 --> 00:40:58.690
I might get a very
different result

00:40:58.690 --> 00:41:01.030
than you get, searching
about climate change,

00:41:01.030 --> 00:41:04.300
depending on the kinds of things
we've clicked on in the past.

00:41:04.300 --> 00:41:06.040
I might never get
any of your results,

00:41:06.040 --> 00:41:08.230
and you might never
get any of mine.

00:41:08.230 --> 00:41:10.380
And so I wonder
what you all think

00:41:10.380 --> 00:41:14.230
I'd be curious to know your
feelings about how or whether

00:41:14.230 --> 00:41:17.560
this has contributed to
this echo chamber phenomenon

00:41:17.560 --> 00:41:19.480
that we've been
accused of living in,

00:41:19.480 --> 00:41:22.390
this bubble phenomenon that
we're only hearing views

00:41:22.390 --> 00:41:24.850
that support our own views.

00:41:24.850 --> 00:41:27.730
And we're not being exposed
to what the great promise

00:41:27.730 --> 00:41:29.680
of the internet was.

00:41:29.680 --> 00:41:33.310
The great democratizing force
was that for once and for all

00:41:33.310 --> 00:41:35.350
we could have a free
marketplace of ideas.

00:41:35.350 --> 00:41:37.330
You could encounter any
idea that was out there

00:41:37.330 --> 00:41:39.040
and judge it for yourself.

00:41:39.040 --> 00:41:42.400
But that's getting
harder and harder to do.

00:41:42.400 --> 00:41:44.530
And so last time I
was here, I suggested

00:41:44.530 --> 00:41:47.890
that Google search should
have like the equivalent

00:41:47.890 --> 00:41:50.640
of the hyperspace
button in Asteroids,

00:41:50.640 --> 00:41:52.390
where every once in a
while you would say,

00:41:52.390 --> 00:41:54.400
I don't want the stuff
that you usually give me.

00:41:54.400 --> 00:41:56.590
I want to see something
that's way out there.

00:41:56.590 --> 00:41:59.320
I want to see some stuff
that I wouldn't normally see.

00:41:59.320 --> 00:42:02.270
Or maybe a little button that
you could enable that says,

00:42:02.270 --> 00:42:04.455
I want to see the stuff
you would normally give me,

00:42:04.455 --> 00:42:06.580
and I want to see the stuff
that you would normally

00:42:06.580 --> 00:42:10.120
give someone else, maybe someone
chosen at random or somebody

00:42:10.120 --> 00:42:14.500
who has a very different,
mathematically defined,

00:42:14.500 --> 00:42:17.410
higher dimensional manifold
of search history than I do.

00:42:17.410 --> 00:42:22.480
And so I'm being exposed
to ideas other than my own.

00:42:22.480 --> 00:42:24.637
When I said that two
years ago, people

00:42:24.637 --> 00:42:26.470
could not have rolled
their eyes any farther

00:42:26.470 --> 00:42:28.120
in the back of their heads.

00:42:28.120 --> 00:42:31.120
Possibly because I also
opined that it would be nice

00:42:31.120 --> 00:42:34.450
for Google Maps to have a scenic
route button, because when

00:42:34.450 --> 00:42:36.700
my wife and I go driving
on Saturday afternoon

00:42:36.700 --> 00:42:38.110
to our favorite restaurant.

00:42:38.110 --> 00:42:39.760
We don't want the fastest way.

00:42:39.760 --> 00:42:41.350
We want the picturesque way.

00:42:41.350 --> 00:42:46.100
But I can never get Google
Maps to help me find it.

00:42:46.100 --> 00:42:49.230
Again, this is sorry for
the little digression,

00:42:49.230 --> 00:42:50.960
but this is Google.

00:42:50.960 --> 00:42:55.190
I have the chance to
say what I want to say.

00:42:55.190 --> 00:42:56.822
Getting back to my
main theme here.

00:42:56.822 --> 00:42:59.030
I think that there are three
institutions that we all

00:42:59.030 --> 00:42:59.780
need to support.

00:42:59.780 --> 00:43:01.550
That's the take home message.

00:43:01.550 --> 00:43:06.150
The free press, the scientific
method, independent judiciary--

00:43:06.150 --> 00:43:09.350
I think that we need to
work hard to support them,

00:43:09.350 --> 00:43:11.870
and we need to work hard
to do for ourselves.

00:43:11.870 --> 00:43:14.540
Frankly, the media can't
keep up with all the lies

00:43:14.540 --> 00:43:15.770
that are running around.

00:43:15.770 --> 00:43:16.910
They're working overtime.

00:43:16.910 --> 00:43:20.630
Fact checking sites aren't able
to keep up with all the lies.

00:43:20.630 --> 00:43:23.210
So each of us has
a responsibility,

00:43:23.210 --> 00:43:27.410
a personal responsibility,
to figure out what's true

00:43:27.410 --> 00:43:30.950
and what's not, to
think for ourselves.

00:43:30.950 --> 00:43:33.080
That is the basis
of a free society.

00:43:33.080 --> 00:43:39.050
And I think to do that the one
most valuable quality that we

00:43:39.050 --> 00:43:41.060
all need, which
unfortunately has

00:43:41.060 --> 00:43:46.410
been in somewhat short
supply lately, is humility.

00:43:46.410 --> 00:43:49.020
I think we all need a
little more humility.

00:43:49.020 --> 00:43:51.240
And I say that
because somebody who

00:43:51.240 --> 00:43:54.860
thinks they know everything,
can't learn anything.

00:43:54.860 --> 00:43:57.570
But somebody who adopts a
humble attitude that maybe I

00:43:57.570 --> 00:44:00.420
don't know everything, well,
then you start asking questions

00:44:00.420 --> 00:44:01.860
and you start
looking at evidence.

00:44:01.860 --> 00:44:03.780
And you start
seeking out experts

00:44:03.780 --> 00:44:05.580
who may know more than you.

00:44:05.580 --> 00:44:07.336
That's where true
learning can take place,

00:44:07.336 --> 00:44:09.210
and that's where true
evidence-based thinking

00:44:09.210 --> 00:44:10.540
can take place.

00:44:10.540 --> 00:44:12.840
And I think this comes
down to education.

00:44:12.840 --> 00:44:15.030
I've devoted the last
three decades of my life

00:44:15.030 --> 00:44:16.410
to being an educator.

00:44:16.410 --> 00:44:18.480
And I've seen that
education works.

00:44:18.480 --> 00:44:21.600
And fortunately, it works
across the spectrum.

00:44:21.600 --> 00:44:23.760
You don't have to have a
high IQ for it to work.

00:44:23.760 --> 00:44:27.090
You don't need to be coming from
a high socioeconomic background

00:44:27.090 --> 00:44:28.350
for education to work.

00:44:28.350 --> 00:44:30.030
It works with everybody.

00:44:30.030 --> 00:44:31.650
And the education,
I think, needs

00:44:31.650 --> 00:44:32.844
to start with 12-year-olds.

00:44:32.844 --> 00:44:34.260
Teaching them
things like when you

00:44:34.260 --> 00:44:37.230
land on a website, that's
not the end of the research

00:44:37.230 --> 00:44:39.730
enterprise, that's
only the beginning.

00:44:39.730 --> 00:44:42.090
You have to ask yourself
who operates the website,

00:44:42.090 --> 00:44:43.600
if there are biases.

00:44:43.600 --> 00:44:44.610
Who else links to it?

00:44:44.610 --> 00:44:46.230
Are they trusted sources?

00:44:46.230 --> 00:44:48.360
Use the link tool
in Google search

00:44:48.360 --> 00:44:50.850
to see what other
sites are linked to it

00:44:50.850 --> 00:44:54.090
and whether they are
reputable or not.

00:44:54.090 --> 00:44:56.670
And I think all of
this comes naturally

00:44:56.670 --> 00:45:00.270
to us, this kind of
humility and question asking

00:45:00.270 --> 00:45:01.800
and inquisitiveness.

00:45:01.800 --> 00:45:04.110
Any of you who spend any
time with a four-year-old

00:45:04.110 --> 00:45:07.320
at bedtime, knows about
this inquisitiveness, right?

00:45:07.320 --> 00:45:08.970
Because you say to
the four-year-old,

00:45:08.970 --> 00:45:10.350
it's time to go to bed.

00:45:10.350 --> 00:45:12.195
And the four-year-old says why.

00:45:12.195 --> 00:45:14.770
And then you say, well,
it's your bed time.

00:45:14.770 --> 00:45:15.600
Why?

00:45:15.600 --> 00:45:17.220
Well, we set your
bedtime because you

00:45:17.220 --> 00:45:18.580
have school in the morning.

00:45:18.580 --> 00:45:19.800
Why?

00:45:19.800 --> 00:45:22.020
Because we want you to
be rested for school.

00:45:22.020 --> 00:45:22.680
Why?

00:45:22.680 --> 00:45:24.330
This goes on and on and on.

00:45:24.330 --> 00:45:26.790
This is a very natural
human instinct and a phase

00:45:26.790 --> 00:45:28.470
that all children go through.

00:45:28.470 --> 00:45:30.240
But they have it
beaten out of them.

00:45:30.240 --> 00:45:32.970
We have it beaten out of
us by impatient teachers

00:45:32.970 --> 00:45:34.880
and impatient parents.

00:45:34.880 --> 00:45:37.950
It's often the grandparents
who encourage it.

00:45:37.950 --> 00:45:41.280
But I say you know that's a
very natural human inclination.

00:45:41.280 --> 00:45:44.430
Asking why is a good start.

00:45:44.430 --> 00:45:47.130
Again, I think we need to
take communal responsibility.

00:45:47.130 --> 00:45:49.530
And I would like to
recommend that you

00:45:49.530 --> 00:45:53.610
don't hit the thumbs
up button on a story

00:45:53.610 --> 00:45:56.940
that you read in your social
network, you don't forward it,

00:45:56.940 --> 00:45:59.340
unless you've taken
maybe 30 or 40 seconds

00:45:59.340 --> 00:46:01.890
to ask yourself whether
it's true or not.

00:46:01.890 --> 00:46:03.990
Is it plausible?

00:46:03.990 --> 00:46:06.630
Is the evidence that's
being given for the claim

00:46:06.630 --> 00:46:09.630
actually was it
relevant to the claim?

00:46:09.630 --> 00:46:12.810
Does it come from a good source?

00:46:12.810 --> 00:46:14.790
I gave a talk in
England a few weeks ago

00:46:14.790 --> 00:46:20.100
and a gentleman said to
me, he says, a lot of us

00:46:20.100 --> 00:46:22.980
voted for Brexit
because we believed

00:46:22.980 --> 00:46:26.940
this story-- it turned out to
be fake news-- that Britons were

00:46:26.940 --> 00:46:29.580
learning losing
350 million pounds

00:46:29.580 --> 00:46:34.120
sterling a week by being in the
EU, money that could otherwise

00:46:34.120 --> 00:46:37.240
have gone to the National Health
Service, over a billion pounds

00:46:37.240 --> 00:46:39.160
a month they were losing.

00:46:39.160 --> 00:46:40.840
And he says it turned
out to be false.

00:46:40.840 --> 00:46:42.090
But so many of us believed it.

00:46:42.090 --> 00:46:44.050
How could we have known?

00:46:44.050 --> 00:46:46.240
And I said, well, where
did you read about it?

00:46:46.240 --> 00:46:48.310
He said, we all read about
it in the same place.

00:46:48.310 --> 00:46:51.637
It was written on the sides
of buses going around town.

00:46:51.637 --> 00:46:53.470
I said, did you read
about it anywhere else?

00:46:53.470 --> 00:46:56.510
He says, no, but it was
on the sides of the buses?

00:46:56.510 --> 00:47:00.130
Well, I said, if the only source
that you have for something

00:47:00.130 --> 00:47:02.860
is the side of a bus
or a man on the corner

00:47:02.860 --> 00:47:07.496
with a bullhorn and a sandwich
board, it might not be true.

00:47:07.496 --> 00:47:09.870
And he says, oh, well, the
media is part of a conspiracy.

00:47:09.870 --> 00:47:11.950
And I said, well,
yeah, they are, maybe.

00:47:11.950 --> 00:47:14.830
But the media is also
made up of people like you

00:47:14.830 --> 00:47:17.720
and me, who are trying to earn
a living and want to get ahead,

00:47:17.720 --> 00:47:19.739
maybe win a Pulitzer Prize.

00:47:19.739 --> 00:47:21.280
And if there's a
real story out there

00:47:21.280 --> 00:47:22.570
they're going to
investigate it, and they're

00:47:22.570 --> 00:47:23.757
going to publish it.

00:47:23.757 --> 00:47:25.840
And so you're going to get
it sooner or later most

00:47:25.840 --> 00:47:28.000
of the time, not to
mention Wikileaks

00:47:28.000 --> 00:47:29.800
exposing this kind of stuff.

00:47:29.800 --> 00:47:32.870
So you know there is a hierarchy
of information sources.

00:47:32.870 --> 00:47:36.430
And I think we need to
be sensitive to that

00:47:36.430 --> 00:47:37.240
and rely on it.

00:47:37.240 --> 00:47:39.130
It's just statistical.

00:47:39.130 --> 00:47:40.810
So thank you very
much for your time.

00:47:40.810 --> 00:47:43.090
I'm very much looking
forward to the comments

00:47:43.090 --> 00:47:45.310
that you might have
to share with me.

00:47:45.310 --> 00:47:46.036
Thank you.

00:47:46.036 --> 00:47:47.482
[APPLAUSE]

00:47:47.482 --> 00:47:48.440
SPEAKER 1: Thanks, Dan.

00:47:48.440 --> 00:47:49.982
We have a limited
time for questions.

00:47:49.982 --> 00:47:50.481
I got one.

00:47:50.481 --> 00:47:51.890
Was is the side of a Google bus?

00:47:51.890 --> 00:47:53.620
DAN LEVITIN: No.

00:47:53.620 --> 00:47:57.130
AUDIENCE: Is there any
physiological evidence or any

00:47:57.130 --> 00:48:04.120
kind of study in the area or
in your field to suggest that

00:48:04.120 --> 00:48:11.470
there may be physical
differences between people who

00:48:11.470 --> 00:48:22.155
can evaluate issues based on
evidence and those who can't?

00:48:22.155 --> 00:48:24.530
DAN LEVITIN: I have a couple
of things to say about that.

00:48:28.680 --> 00:48:32.001
First of all, there's a new
construct called the RQ.

00:48:32.001 --> 00:48:34.240
You've heard of the IQ,
the intelligence quotient.

00:48:34.240 --> 00:48:36.420
This is the
rationality quotient.

00:48:36.420 --> 00:48:39.360
And it turns out that the
rationality quotient is not

00:48:39.360 --> 00:48:42.480
at all correlated with
the intelligence quotient.

00:48:42.480 --> 00:48:45.150
You can have people that are
very high in rationality that

00:48:45.150 --> 00:48:48.130
have low IQs and vice versa.

00:48:48.130 --> 00:48:50.700
Now what I suspect is
going on in the brain

00:48:50.700 --> 00:48:53.610
is that people who
have poor impulse

00:48:53.610 --> 00:48:55.710
control and poor
emotional control

00:48:55.710 --> 00:48:59.550
are more likely to jump to
conclusions than to sit back

00:48:59.550 --> 00:49:02.280
and dispassionately let
the evidence come in

00:49:02.280 --> 00:49:05.760
before they make an evaluation.

00:49:05.760 --> 00:49:08.580
And this could have to do
with configuration differences

00:49:08.580 --> 00:49:11.100
in the prefrontal cortex,
the part of the human brain

00:49:11.100 --> 00:49:13.350
that's most highly
advanced in humans

00:49:13.350 --> 00:49:16.630
compared to other species.

00:49:16.630 --> 00:49:23.130
There's also an interesting
link between political party

00:49:23.130 --> 00:49:24.870
and fake news.

00:49:24.870 --> 00:49:26.430
So it turns out for reasons--

00:49:26.430 --> 00:49:27.600
I'm not a sociologist.

00:49:27.600 --> 00:49:29.440
So I don't really know
what underlies this.

00:49:29.440 --> 00:49:32.460
But a number of studies have
shown that Republican voters

00:49:32.460 --> 00:49:34.320
are more likely to
believe the fake news

00:49:34.320 --> 00:49:36.730
stories than Democratic voters.

00:49:36.730 --> 00:49:39.210
Now it's probably
being driven by

00:49:39.210 --> 00:49:42.720
underlying demographic
differences between members

00:49:42.720 --> 00:49:43.560
of the two parties.

00:49:43.560 --> 00:49:51.660
That in general, Democrats
tend to have better education.

00:49:51.660 --> 00:49:54.690
But I mean certainly they're
uneducated Democrats and very

00:49:54.690 --> 00:49:56.070
highly educated Republicans.

00:49:56.070 --> 00:49:58.427
I'm talking about as a group.

00:49:58.427 --> 00:50:00.510
There could be some
demographic differences there.

00:50:00.510 --> 00:50:03.510
Republican voters tend to,
although not exclusively,

00:50:03.510 --> 00:50:07.470
tend to be in more rural areas
where they have less contact

00:50:07.470 --> 00:50:09.990
with a large number of people.

00:50:09.990 --> 00:50:12.130
And it's complicated.

00:50:12.130 --> 00:50:15.970
AUDIENCE: I was reminded
of some of the analysis

00:50:15.970 --> 00:50:18.540
by Noam Chomsky on the media.

00:50:18.540 --> 00:50:22.240
And one of his
comments was media

00:50:22.240 --> 00:50:24.430
organizations which
are in a sense

00:50:24.430 --> 00:50:27.940
far from in a sense
what's going on

00:50:27.940 --> 00:50:31.540
tend to be a lot more objective
and stick more to the facts.

00:50:31.540 --> 00:50:36.430
And he found that,
compared to American media,

00:50:36.430 --> 00:50:38.800
the best media that
he was able to find

00:50:38.800 --> 00:50:41.630
was actually in Belgium.

00:50:41.630 --> 00:50:45.490
Now presumably if you were
at McGill for 17 years,

00:50:45.490 --> 00:50:48.970
you lived in Montreal,
I am a Canadian.

00:50:48.970 --> 00:50:50.880
And I read "The
Economist" magazine.

00:50:50.880 --> 00:50:54.670
I don't rely on American
media, by and large.

00:50:54.670 --> 00:50:59.710
What do you think or can you
give an opinion about how

00:50:59.710 --> 00:51:05.260
foreigners view
America events, and I

00:51:05.260 --> 00:51:09.880
guess foreign media relating on
American politics in general?

00:51:09.880 --> 00:51:12.760
Would you think
that because they

00:51:12.760 --> 00:51:15.260
don't have skin in the game,
they don't have a bias.

00:51:15.260 --> 00:51:17.385
They don't have a motivation,
that they're actually

00:51:17.385 --> 00:51:18.950
more objective and fair?

00:51:18.950 --> 00:51:20.890
DAN LEVITIN: Well, I
will answer the question.

00:51:20.890 --> 00:51:24.550
But first I'd like to say that
I am not an expert on this,

00:51:24.550 --> 00:51:27.440
and I don't want to become
a pseudo expert here.

00:51:27.440 --> 00:51:29.590
I don't have expertise
in media studies

00:51:29.590 --> 00:51:33.490
or communication or sociology
or political science.

00:51:33.490 --> 00:51:36.640
People in those fields might
have a better bead on this.

00:51:36.640 --> 00:51:40.870
I can speak as a private
citizen, just my own views.

00:51:40.870 --> 00:51:44.320
By the way, you may
say, well, what's

00:51:44.320 --> 00:51:47.950
a neuroscientist doing
talking about statistics?

00:51:47.950 --> 00:51:51.100
I am a member of the American
Statistical Association.

00:51:51.100 --> 00:51:53.800
And I've published papers
in statistical journals,

00:51:53.800 --> 00:51:55.720
and I've taught statistics.

00:51:55.720 --> 00:52:00.190
And I had 40 members of
the American Statistical

00:52:00.190 --> 00:52:03.880
Association review the book
before it went to press.

00:52:03.880 --> 00:52:06.220
So I've been trying
to be very careful not

00:52:06.220 --> 00:52:09.310
to become a pseudo expert.

00:52:09.310 --> 00:52:14.950
I think that certainly there are
some great foreign newspapers

00:52:14.950 --> 00:52:19.350
and magazines and the
BBC, great news network.

00:52:19.350 --> 00:52:22.150
I think that we
don't all have time

00:52:22.150 --> 00:52:26.350
to read six or eight
newspapers a day.

00:52:26.350 --> 00:52:28.300
I think you can just
choose one that you

00:52:28.300 --> 00:52:33.671
like, for whatever reason,
or two, or broadcast news.

00:52:33.671 --> 00:52:34.420
And stick with it.

00:52:34.420 --> 00:52:36.220
And just figure that
the major stories

00:52:36.220 --> 00:52:37.670
are going to be reported there.

00:52:37.670 --> 00:52:41.200
Now a news source based
in Belgium or in London

00:52:41.200 --> 00:52:43.810
may not pick up on the fact
that the Orrville Dam was

00:52:43.810 --> 00:52:48.190
about to collapse or
that the water table here

00:52:48.190 --> 00:52:50.080
in northern California
is finally restored

00:52:50.080 --> 00:52:51.900
after x years of drought.

00:52:51.900 --> 00:52:53.650
But the big things
they'll get, and if you

00:52:53.650 --> 00:52:55.733
want some local color, you
read "The Mercury News"

00:52:55.733 --> 00:52:57.990
or something.

00:52:57.990 --> 00:53:00.490
But I don't know whether they're
more objective because they

00:53:00.490 --> 00:53:03.130
don't have skin in the game.

00:53:03.130 --> 00:53:05.050
AUDIENCE: Most of what
you said about arguing

00:53:05.050 --> 00:53:08.320
for evidence-based reasoning
and advocating for the media

00:53:08.320 --> 00:53:13.840
and judiciary and science
sounds pretty reasonable to me.

00:53:13.840 --> 00:53:16.290
What kind of
objections do you get?

00:53:16.290 --> 00:53:18.460
Do people object to these ideas?

00:53:18.460 --> 00:53:21.400
DAN LEVITIN: Yes,
they do vehemently.

00:53:21.400 --> 00:53:24.610
They say evidence-based
thinking is just

00:53:24.610 --> 00:53:27.280
for a bunch of
Poindexters and egg heads.

00:53:27.280 --> 00:53:30.070
And I don't trust you people.

00:53:30.070 --> 00:53:33.610
You people have kept people
like me out of the workplace,

00:53:33.610 --> 00:53:34.935
or I don't have the job I want.

00:53:34.935 --> 00:53:37.070
Or I'm only working part-time.

00:53:37.070 --> 00:53:41.827
And you coastal lefties
talk about evidence,

00:53:41.827 --> 00:53:43.285
you know, well, I
don't have a job.

00:53:47.572 --> 00:53:50.560
You scientists can't
make up your minds.

00:53:50.560 --> 00:53:52.000
Every time I pick
up the newspaper

00:53:52.000 --> 00:53:54.830
to figure out what to eat,
I hear a different story.

00:53:54.830 --> 00:53:57.550
And so, if I can't trust
you about that, how can

00:53:57.550 --> 00:53:59.080
I trust you about anything?

00:53:59.080 --> 00:54:00.820
And I read that
three scientists who

00:54:00.820 --> 00:54:04.630
were saying that
climate change is real

00:54:04.630 --> 00:54:07.450
were being bribed to say it.

00:54:07.450 --> 00:54:08.780
So I can't trust any of it.

00:54:08.780 --> 00:54:10.336
I'm just going with my gut.

00:54:10.336 --> 00:54:11.710
That's one of the
big objections.

00:54:11.710 --> 00:54:14.680
And the other objection I get
is that there is a conspiracy

00:54:14.680 --> 00:54:17.560
and that I'm part of it
and I'm being paid off.

00:54:17.560 --> 00:54:20.530
And I suppose, but
I don't think I'd

00:54:20.530 --> 00:54:23.650
be driving a 10-year-old
car if that were true.

00:54:23.650 --> 00:54:24.640
I actually say that.

00:54:24.640 --> 00:54:26.265
I say, come with me
to the parking lot.

00:54:26.265 --> 00:54:27.710
I'll show you my
10-year-old car.

00:54:27.710 --> 00:54:29.209
And they say, oh,
well, you probably

00:54:29.209 --> 00:54:31.150
have a fancy car in the garage.

00:54:31.150 --> 00:54:33.460
You can't win with a
conspiracy theorist,

00:54:33.460 --> 00:54:35.667
because there's always
some other level.

00:54:35.667 --> 00:54:38.250
SPEAKER 1: Thanks for coming to
talk to Google, and thank you,

00:54:38.250 --> 00:54:38.750
Dan.

00:54:38.750 --> 00:54:41.000
[APPLAUSE]

