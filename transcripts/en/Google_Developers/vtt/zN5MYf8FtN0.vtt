WEBVTT
Kind: captions
Language: en

00:00:01.832 --> 00:00:04.600
ROBERTO PEON: Hello, my
name is Roberto Peon.

00:00:04.600 --> 00:00:07.860
I'm one of the co-inventors
for SPDY, welcome.

00:00:07.860 --> 00:00:11.330
If you are here to hear about
SPDY, well, you are in the

00:00:11.330 --> 00:00:13.660
right place because it's here.

00:00:13.660 --> 00:00:15.040
So what we're going
to talk about.

00:00:15.040 --> 00:00:16.290
We're going to talk
about the past.

00:00:16.290 --> 00:00:18.740
We're going to talk about what
the world looks like today.

00:00:18.740 --> 00:00:21.210
What is speedy, how to optimize
for it, where we're

00:00:21.210 --> 00:00:22.480
going in the future.

00:00:22.480 --> 00:00:25.730
And then we'll talk about stuff
that's either supporting

00:00:25.730 --> 00:00:28.390
it already or that you can
use to get it working.

00:00:28.390 --> 00:00:32.299
And then I'll go over an example
of adding ServerPush.

00:00:32.299 --> 00:00:39.590
So the past, in the beginning
the speed of light was C. OK,

00:00:39.590 --> 00:00:40.690
well let's try again.

00:00:40.690 --> 00:00:41.860
That was a little bit too far.

00:00:41.860 --> 00:00:47.230
So in the beginning of the
web, we had HTTP 0.9.

00:00:47.230 --> 00:00:48.320
Well, that's what
we call it now.

00:00:48.320 --> 00:00:50.670
It didn't have a name there.

00:00:50.670 --> 00:00:52.600
In 1991 it was defined.

00:00:52.600 --> 00:00:58.140
And basically HTTP 0.9 was a
request, get HTML protocol.

00:00:58.140 --> 00:01:01.640
There was no images,
no anything else.

00:01:01.640 --> 00:01:06.280
And very soon after, in
1996, we got HTP 1.0.

00:01:06.280 --> 00:01:08.990
And it brought in headers,
including unresponses, and

00:01:08.990 --> 00:01:10.520
servers could reply
with errors.

00:01:10.520 --> 00:01:14.280
And clients could now upload
data, not just in the URL, but

00:01:14.280 --> 00:01:15.330
with posts.

00:01:15.330 --> 00:01:17.100
And they could indicate that
resources we're going to be

00:01:17.100 --> 00:01:19.400
cast, and lots of other
good features.

00:01:19.400 --> 00:01:23.370
Shortly thereafter, 1997-1999,
so basically they got to work

00:01:23.370 --> 00:01:26.380
on it immediately,
we got HTTP 1.1.

00:01:26.380 --> 00:01:29.160
And HTTP 1.1 gave us persistent

00:01:29.160 --> 00:01:30.820
connections, which is great.

00:01:30.820 --> 00:01:34.210
It also gave us trunk transfers,
which allows us to

00:01:34.210 --> 00:01:39.110
send responses that don't
necessarily have there size

00:01:39.110 --> 00:01:43.660
pre-computed before we've
begun the response.

00:01:43.660 --> 00:01:47.260
So in 1999 pages were
very different.

00:01:47.260 --> 00:01:49.960
Specifically, they were tiny.

00:01:49.960 --> 00:01:52.400
They were around
60k on average.

00:01:52.400 --> 00:01:54.560
And at that time, it was
probably good enough.

00:01:54.560 --> 00:01:56.900
And I'll show you what Google
looked like in 1999.

00:01:56.900 --> 00:01:57.950
Here it is.

00:01:57.950 --> 00:02:02.100
Google, this page here, was
between the 13k compressed and

00:02:02.100 --> 00:02:03.990
14k uncompressed.

00:02:03.990 --> 00:02:05.880
It was tiny.

00:02:05.880 --> 00:02:09.310
OK, so what does it
look like today?

00:02:09.310 --> 00:02:12.170
In 2012, here you go.

00:02:12.170 --> 00:02:14.666
This page is around 200k
compressed, and with

00:02:14.666 --> 00:02:16.880
uncompressed, it's
around 600k.

00:02:16.880 --> 00:02:20.040
This is a big difference
from 14k.

00:02:20.040 --> 00:02:24.010
So today, pages are
a lot bigger.

00:02:24.010 --> 00:02:26.790
And they're composed of
more resources, using

00:02:26.790 --> 00:02:27.870
a bunch more domains.

00:02:27.870 --> 00:02:30.740
And I'll get into exactly how
many on average soon.

00:02:30.740 --> 00:02:33.050
And they're far more dynamic.

00:02:33.050 --> 00:02:36.510
And, because of something
that's about to come up,

00:02:36.510 --> 00:02:39.210
security is a much bigger
concern than it was.

00:02:39.210 --> 00:02:43.080
And, of course, today the speed
of light is still C. It

00:02:43.080 --> 00:02:44.440
hasn't changed.

00:02:44.440 --> 00:02:48.350
And that means that RTTs are
not going to be going down,

00:02:48.350 --> 00:02:50.020
because of course we haven't
made the speed

00:02:50.020 --> 00:02:50.970
of light any faster.

00:02:50.970 --> 00:02:55.210
And the speed of light
actually bounds RTT.

00:02:55.210 --> 00:02:57.250
So here let's look
at the effective

00:02:57.250 --> 00:02:59.790
bandwidth as RTT decreases.

00:02:59.790 --> 00:03:02.510
You'll notice that the bandwidth
goes up quite a bit

00:03:02.510 --> 00:03:07.590
more as we decrease RTT than
if we just simply add

00:03:07.590 --> 00:03:09.730
bandwidth to our
communications.

00:03:09.730 --> 00:03:12.640
So on the right hand side
here, we see effective

00:03:12.640 --> 00:03:19.650
bandwidth of HTTP if we
add more speed to

00:03:19.650 --> 00:03:20.320
the connection, right?

00:03:20.320 --> 00:03:21.590
We're widening the pipe.

00:03:21.590 --> 00:03:28.460
And basically it looks like we
kind of top out at around 1.6

00:03:28.460 --> 00:03:29.920
megabytes a second here.

00:03:29.920 --> 00:03:34.430
Whereas if we look on the other
side, we achieve that by

00:03:34.430 --> 00:03:40.360
decreasing latency to around
50 milliseconds or so.

00:03:40.360 --> 00:03:44.576
So RTT actually ends
up mattering a lot.

00:03:44.576 --> 00:03:47.880
In 2010, which was about a year
after we started doing

00:03:47.880 --> 00:03:54.460
all this, a web page was about
702k on average, used about 74

00:03:54.460 --> 00:03:55.990
individual resources.

00:03:55.990 --> 00:03:58.320
And it talked to about
10 different domains.

00:03:58.320 --> 00:04:03.400
And today bigger,
more, more, OK?

00:04:06.150 --> 00:04:11.560
And now, as compared to 1999,
as compared to 2010, the

00:04:11.560 --> 00:04:13.140
stakes are higher.

00:04:13.140 --> 00:04:16.440
More people depend on it.

00:04:16.440 --> 00:04:20.839
And, more specifically, because
of this, you probably

00:04:20.839 --> 00:04:23.240
depend upon it.

00:04:23.240 --> 00:04:26.990
So SPDY, it's here.

00:04:26.990 --> 00:04:28.370
What is it?

00:04:28.370 --> 00:04:30.070
I've heard this question a
number of times today as I was

00:04:30.070 --> 00:04:31.380
talking to random people.

00:04:31.380 --> 00:04:33.920
It's a session-layer replacement
for HTTP.

00:04:33.920 --> 00:04:38.330
And, well, so, why?

00:04:38.330 --> 00:04:40.900
HTTP, I mean, it's been
here for a while.

00:04:40.900 --> 00:04:43.430
It's been here since 1999 in
it's current incarnation.

00:04:43.430 --> 00:04:44.670
Why do we care?

00:04:44.670 --> 00:04:48.670
Well, you should care because
the idea is that it's going to

00:04:48.670 --> 00:04:51.080
make it faster.

00:04:51.080 --> 00:04:53.280
It's going to make
it more secure.

00:04:53.280 --> 00:04:56.150
And it should be doing it with
less effort on your part.

00:04:56.150 --> 00:04:58.410
So I've spent some time trying
to do some webpage page

00:04:58.410 --> 00:05:00.450
organization.

00:05:00.450 --> 00:05:03.750
It's pretty hard, You have to
keep a lot in your head.

00:05:03.750 --> 00:05:06.810
And you have to know a lot about
who your customers are,

00:05:06.810 --> 00:05:09.370
where they are, how far away
from you, what their links are

00:05:09.370 --> 00:05:13.330
like, what they're packet loss
is like, how the particular

00:05:13.330 --> 00:05:16.110
set of browsers that they're
using are going to interpret

00:05:16.110 --> 00:05:17.640
the resources when you get it.

00:05:17.640 --> 00:05:21.020
It's a big, really difficult
problem.

00:05:21.020 --> 00:05:24.000
I'm hoping that we can make
some of this easier.

00:05:24.000 --> 00:05:28.690
And, as a result, make webpages
faster, because we

00:05:28.690 --> 00:05:31.620
should be doing things that make
it faster for you when

00:05:31.620 --> 00:05:35.280
you do it the way that you
think is most forthright.

00:05:35.280 --> 00:05:37.220
We shouldn't be making it so
you have to do all this

00:05:37.220 --> 00:05:40.430
complex stuff in order to get a
page that is performing for

00:05:40.430 --> 00:05:41.680
your users.

00:05:43.770 --> 00:05:46.300
But no guarantees.

00:05:46.300 --> 00:05:47.330
So how does it work?

00:05:47.330 --> 00:05:50.510
So first of all, it's
always over TLS.

00:05:50.510 --> 00:05:54.020
So you can have HTTPS
schemes in your URLs

00:05:54.020 --> 00:05:54.840
and it can be SPDY.

00:05:54.840 --> 00:05:57.830
You can have HTTP schemes
in your URLs.

00:05:57.830 --> 00:06:00.510
It can still be SPDY, although
we don't do the same

00:06:00.510 --> 00:06:02.340
certificate checks for
those resources.

00:06:02.340 --> 00:06:04.810
It's still going to be better
than HTTP because you're at

00:06:04.810 --> 00:06:07.170
least going to get point
to point privacy.

00:06:07.170 --> 00:06:12.290
So if you're in a web cafe and
somebody is sniffing, you

00:06:12.290 --> 00:06:14.130
never know, right?

00:06:14.130 --> 00:06:18.170
If you're using SPDY, and that
HTTP resource is going over

00:06:18.170 --> 00:06:22.330
SPDY, then that person doing the
sniffing isn't going to be

00:06:22.330 --> 00:06:24.360
able to catch it.

00:06:24.360 --> 00:06:28.420
That, I think, is pretty cool.

00:06:28.420 --> 00:06:29.750
That's not the only
reason though.

00:06:32.690 --> 00:06:34.030
Has anyone experienced this?

00:06:34.030 --> 00:06:37.010
Transparent proxies get in
your way all the time.

00:06:37.010 --> 00:06:41.190
You think, you know what, I've
deployed my own application.

00:06:41.190 --> 00:06:42.290
Let's say on an Android phone.

00:06:42.290 --> 00:06:43.480
It does some HTML.

00:06:43.480 --> 00:06:44.360
I control it.

00:06:44.360 --> 00:06:46.730
Got the server, control
that too.

00:06:46.730 --> 00:06:49.510
Surprise, compression
doesn't work.

00:06:49.510 --> 00:06:52.250
Surprise, other things happen.

00:06:52.250 --> 00:06:54.800
OK, well the truth of the matter
is, on port 80, despite

00:06:54.800 --> 00:06:56.540
the fact that you think you
own both sides of the

00:06:56.540 --> 00:06:58.910
connection, transparent
proxies are in there.

00:06:58.910 --> 00:06:59.810
They're mucking with it.

00:06:59.810 --> 00:07:00.580
They're changing stuff.

00:07:00.580 --> 00:07:03.860
This basically makes it really
hard to deploy anything new,

00:07:03.860 --> 00:07:08.220
whether or not it's part of the
HTTP/1.1 spec on port 80.

00:07:08.220 --> 00:07:10.940
And actually, just so you know,
it makes it really hard

00:07:10.940 --> 00:07:15.050
to deploy HTTP/1.1 on port 80
because the subset of HTTP

00:07:15.050 --> 00:07:18.060
that people actually speak
on port 80, it's

00:07:18.060 --> 00:07:20.540
not the full subset.

00:07:20.540 --> 00:07:25.630
So, another fun bit, firewalls,
great security,

00:07:25.630 --> 00:07:27.370
great for keeping the stuff
you don't want out.

00:07:27.370 --> 00:07:29.620
But, of course, you have to
know you don't want it.

00:07:29.620 --> 00:07:33.450
So most firewalls end up,
they're open on port 80 and

00:07:33.450 --> 00:07:34.300
443 by default.

00:07:34.300 --> 00:07:38.010
And that's the world
as it exists.

00:07:38.010 --> 00:07:41.910
So, as I mentioned before, if
you're always over TLS,

00:07:41.910 --> 00:07:45.630
doesn't matter what the scheme,
then all the various

00:07:45.630 --> 00:07:48.535
requests that you make will have
that kind of security.

00:07:51.460 --> 00:07:53.490
SPDY does header compression.

00:07:53.490 --> 00:07:57.070
So if you've ever looked at the
HTTP request stream, for

00:07:57.070 --> 00:08:00.620
instance you've brought up the
Dev tools in Chrome, you will

00:08:00.620 --> 00:08:02.430
see a lot of headers.

00:08:02.430 --> 00:08:03.740
And it's a lot of text.

00:08:03.740 --> 00:08:05.080
And it's text.

00:08:05.080 --> 00:08:07.340
And you will see that most of
the stuff is repeated over,

00:08:07.340 --> 00:08:09.470
and over, and over, again
for every request.

00:08:09.470 --> 00:08:16.160
As an example, your user agent,
yeah, you know, I've

00:08:16.160 --> 00:08:18.350
noticed that my user agent
doesn't change terribly often

00:08:18.350 --> 00:08:20.025
over the lifetime of a
connection for my browser.

00:08:22.630 --> 00:08:25.590
No, not really, except
encoding,

00:08:25.590 --> 00:08:27.030
pretty much the same.

00:08:27.030 --> 00:08:28.540
All of these other things
don't change.

00:08:28.540 --> 00:08:30.760
The version of the connection.

00:08:30.760 --> 00:08:32.850
It generally doesn't change.

00:08:32.850 --> 00:08:35.810
At least over SPDY you're
guaranteed it's a full end to

00:08:35.810 --> 00:08:36.429
end connection.

00:08:36.429 --> 00:08:38.360
So it's not going to change.

00:08:38.360 --> 00:08:40.049
All this stuff means that
we're sending a lot of

00:08:40.049 --> 00:08:42.330
information over and over again
that we really don't

00:08:42.330 --> 00:08:43.580
have to do.

00:08:43.580 --> 00:08:47.200
So, as I said, much of the
headers are repeated.

00:08:51.130 --> 00:08:53.300
I mentioned user agent.

00:08:53.300 --> 00:08:55.090
Thought about the cookie yet?

00:08:55.090 --> 00:08:56.610
How big is that cookie
you send on every

00:08:56.610 --> 00:08:59.780
request, every time?

00:08:59.780 --> 00:09:00.980
They're pretty big.

00:09:00.980 --> 00:09:02.570
At least they can be.

00:09:02.570 --> 00:09:04.670
I've seen cookies in
excess of 32k.

00:09:04.670 --> 00:09:06.640
It's really cool when that ends
up being represented by

00:09:06.640 --> 00:09:10.260
one byte, much faster.

00:09:10.260 --> 00:09:12.830
HTTP methods, most
of them are get.

00:09:12.830 --> 00:09:15.640
Some of them are posts.

00:09:15.640 --> 00:09:17.190
Yeah, I don't know why we just
keep using all those

00:09:17.190 --> 00:09:18.740
characters for that
every time.

00:09:18.740 --> 00:09:21.450
And, of course, the HTTP version
string, mentioned

00:09:21.450 --> 00:09:23.770
that, right?

00:09:23.770 --> 00:09:26.260
Slash r, slash ns at the
end of every line?

00:09:26.260 --> 00:09:27.880
Every line, two bytes, why?

00:09:31.850 --> 00:09:33.080
And there's more.

00:09:33.080 --> 00:09:35.120
So how effective is it?

00:09:35.120 --> 00:09:37.630
Well on the first request on
the left hand side of this

00:09:37.630 --> 00:09:41.190
graph, we see it's somewhere
between 10 and 40% on the

00:09:41.190 --> 00:09:42.265
first request.

00:09:42.265 --> 00:09:45.310
That's pretty good.

00:09:45.310 --> 00:09:48.440
On subsequent requests on the
same connection, you can get

00:09:48.440 --> 00:09:49.810
much better.

00:09:49.810 --> 00:09:53.430
For instance, looking at this,
we see generally between 80

00:09:53.430 --> 00:10:00.190
and 99% of compression with
a big spike around 97%.

00:10:00.190 --> 00:10:04.020
I think that's pretty good
because I think that most of

00:10:04.020 --> 00:10:05.900
the stuff that's in the headers
isn't actually useful

00:10:05.900 --> 00:10:08.250
most of the time.

00:10:08.250 --> 00:10:09.745
So we shouldn't be
penalized for it.

00:10:12.910 --> 00:10:18.162
So mobile, I've noticed a lot of
excitement over at Android.

00:10:18.162 --> 00:10:21.310
Got one in my pocket,
I like it too.

00:10:21.310 --> 00:10:24.130
But I've also notice that the
net connection, despite all

00:10:24.130 --> 00:10:25.740
the promises I've
been getting, is

00:10:25.740 --> 00:10:27.400
really not that fast.

00:10:27.400 --> 00:10:28.570
And it seems to be a lot faster

00:10:28.570 --> 00:10:30.090
in the upload direction.

00:10:30.090 --> 00:10:32.060
Wait, OK, it's slower in
the upload direction.

00:10:34.850 --> 00:10:36.830
This actually really matters for
requests because most of

00:10:36.830 --> 00:10:39.520
what you're sending isn't going
to be a big upload from

00:10:39.520 --> 00:10:40.190
a mobile phone.

00:10:40.190 --> 00:10:40.850
Sometimes it is.

00:10:40.850 --> 00:10:42.980
Sometimes you've taken a
wonderful video of your

00:10:42.980 --> 00:10:44.480
daughter or something
like that.

00:10:44.480 --> 00:10:45.330
And you're going to upload it.

00:10:45.330 --> 00:10:47.990
In which case, you probably
don't care about latency.

00:10:47.990 --> 00:10:51.890
But if you're doing web stuff,
you're sending requests.

00:10:51.890 --> 00:10:53.350
And generally, there's
not a big post

00:10:53.350 --> 00:10:54.260
body attached to them.

00:10:54.260 --> 00:10:56.400
So the headers end up
being most of it.

00:10:56.400 --> 00:10:58.840
And when you're opening up your
connection, because of

00:10:58.840 --> 00:11:02.700
the way TCP works, it's going
to throttle you down.

00:11:02.700 --> 00:11:04.080
And it's going to throttle
you down early.

00:11:04.080 --> 00:11:05.720
And it's going to
learn over time.

00:11:05.720 --> 00:11:08.730
And it's going to open up that
window slowly, so that we

00:11:08.730 --> 00:11:10.620
don't cause congestion and
a cascade failure of the

00:11:10.620 --> 00:11:12.070
internet, which would be bad.

00:11:12.070 --> 00:11:16.620
So it's probably a good idea
But if we put more relevant

00:11:16.620 --> 00:11:19.220
information in the upload
direction, we're more likely

00:11:19.220 --> 00:11:21.210
to get responses in the downward
direction by the

00:11:21.210 --> 00:11:22.270
server sooner.

00:11:22.270 --> 00:11:25.692
So that's the basic idea.

00:11:25.692 --> 00:11:27.190
It's Binary Framed.

00:11:27.190 --> 00:11:29.015
Now, if you're writing
a web app this

00:11:29.015 --> 00:11:30.120
isn't going to matter.

00:11:30.120 --> 00:11:31.780
But if you're deciding that
you're going to modify your

00:11:31.780 --> 00:11:35.470
server or your client to speak
SPDY it's a lot easier to

00:11:35.470 --> 00:11:38.840
write a binary protocol than
it is to parse HTTP.

00:11:38.840 --> 00:11:45.490
And, having written a few HTTP
parsers, it's a lot easier.

00:11:45.490 --> 00:11:46.310
OK

00:11:46.310 --> 00:11:47.810
So it's also faster to parse.

00:11:47.810 --> 00:11:48.650
It's a nice benefit.

00:11:48.650 --> 00:11:50.480
It's not a huge field.

00:11:50.480 --> 00:11:53.150
HTTP parsing shouldn't be taking
up any major amount of

00:11:53.150 --> 00:11:56.140
time, even if you're doing it
in interpretive language.

00:11:56.140 --> 00:11:59.110
It's the complexity of writing
it that's the hard bit.

00:11:59.110 --> 00:12:00.880
It's multiplexed.

00:12:00.880 --> 00:12:03.980
It's multiplexed to the tune of,
let's say, we can support

00:12:03.980 --> 00:12:08.780
around a billion on one
TCP connection.

00:12:08.780 --> 00:12:12.030
Now, I've mentioned the
average before.

00:12:12.030 --> 00:12:14.820
The average is around 80
something, 84 I think it was,

00:12:14.820 --> 00:12:15.900
requests per page.

00:12:15.900 --> 00:12:18.240
So we have some runway.

00:12:18.240 --> 00:12:21.530
And if we decide in the future
that we don't have enough, one

00:12:21.530 --> 00:12:25.140
billion is not enough, we can
add another opp code, define

00:12:25.140 --> 00:12:28.140
another frame type,
and there we go.

00:12:28.140 --> 00:12:30.640
And the way to protocol is
specced out, that should

00:12:30.640 --> 00:12:32.320
basically be backwards
compatible because we'll be

00:12:32.320 --> 00:12:33.710
able to figure out whether
or not that

00:12:33.710 --> 00:12:35.580
will work in the handshake.

00:12:35.580 --> 00:12:38.210
And we can reject individual
frames if we have to.

00:12:41.680 --> 00:12:45.750
Unlike HTTP, SPDY is full
duplex bi-directional.

00:12:45.750 --> 00:12:51.170
So any stream can be sending and
receiving simultaneously.

00:12:51.170 --> 00:12:53.640
This will make things like
layering web sockets over, if

00:12:53.640 --> 00:12:56.970
we ever actually get to
it, really easy to do.

00:12:56.970 --> 00:12:59.770
And this will allow us to use
the one TCP connection for all

00:12:59.770 --> 00:13:01.080
of these things.

00:13:01.080 --> 00:13:03.770
So we're trying to plan not
just for HTTP, although we

00:13:03.770 --> 00:13:05.580
think that we can get a lot
of benefit for HTTP.

00:13:05.580 --> 00:13:07.635
But we're also trying to plan
for other things in the future

00:13:07.635 --> 00:13:13.690
that will allow us to do more
interesting things for you.

00:13:13.690 --> 00:13:18.100
Prioritization, I don't
know how intently

00:13:18.100 --> 00:13:19.980
you've looked at things.

00:13:19.980 --> 00:13:21.730
But you've probably done it.

00:13:21.730 --> 00:13:25.450
And you've probably been curious
because you see the

00:13:25.450 --> 00:13:28.960
request go out, you see the
response come back, and then

00:13:28.960 --> 00:13:30.240
there's this period
of time where

00:13:30.240 --> 00:13:31.300
nothing appears to happen.

00:13:31.300 --> 00:13:33.640
The browser isn't sending
any requests.

00:13:33.640 --> 00:13:36.770
Well, what's happening there
is the browser is actually

00:13:36.770 --> 00:13:39.300
doing something that's really
smart for you for HTTP.

00:13:39.300 --> 00:13:43.050
It's looking at it, and it says,
aha, I haven't quite

00:13:43.050 --> 00:13:46.590
finished receiving that CSS or
JavaScript that you requested

00:13:46.590 --> 00:13:47.840
as part of a page.

00:13:49.970 --> 00:13:54.080
I'm not going to request these
images yet, because in HTTP if

00:13:54.080 --> 00:13:56.140
you're connected to 10 different
domains, maybe you

00:13:56.140 --> 00:13:58.260
have 12, let's say.

00:13:58.260 --> 00:14:01.880
Maybe you have 70 some
odd connections.

00:14:01.880 --> 00:14:04.790
There's no way of throttling the
server when it's sending

00:14:04.790 --> 00:14:05.850
you those images.

00:14:05.850 --> 00:14:08.010
And as a result, those images
are going to compete with your

00:14:08.010 --> 00:14:10.040
bandwidth for the important
resources.

00:14:10.040 --> 00:14:12.100
So the browser is doing
you a favor.

00:14:12.100 --> 00:14:16.530
Now, if you have a way of
coordinating all these things.

00:14:16.530 --> 00:14:19.670
And you have a way of saying
this is higher priority.

00:14:19.670 --> 00:14:22.690
For instance, give me my HTML
before you bother to send me

00:14:22.690 --> 00:14:23.680
the images.

00:14:23.680 --> 00:14:25.260
Give me the JavaScript before
you bother to send me the

00:14:25.260 --> 00:14:26.830
images, et cetera.

00:14:26.830 --> 00:14:29.670
Then the browser doesn't have
to do this heuristic.

00:14:29.670 --> 00:14:31.760
Instead, it can send all the
requests to the server.

00:14:31.760 --> 00:14:33.870
And the server can keep filling
up the pipe whenever

00:14:33.870 --> 00:14:36.030
it's empty with the most
important thing that it can

00:14:36.030 --> 00:14:37.280
find to fill it up with.

00:14:39.940 --> 00:14:41.690
SPDY also those interleaving.

00:14:41.690 --> 00:14:45.740
Now what this means is that if I
start downloading a video of

00:14:45.740 --> 00:14:48.910
my daughter and my boss calls me
up and tells me one of the

00:14:48.910 --> 00:14:51.680
servers isn't working, I can
open up a new tab in my web

00:14:51.680 --> 00:14:56.060
browser to the same thing and
start looking at the site.

00:14:56.060 --> 00:15:00.290
And the server will be smart
enough to pause that

00:15:00.290 --> 00:15:01.470
download for me.

00:15:01.470 --> 00:15:04.440
And it'll pause it only so long
as it has more important

00:15:04.440 --> 00:15:05.860
things to send.

00:15:05.860 --> 00:15:08.080
So interleaving means
interruption.

00:15:08.080 --> 00:15:11.190
We can interrupt any of the
streams at any point in time

00:15:11.190 --> 00:15:13.110
if we have something more
important to say.

00:15:13.110 --> 00:15:15.870
And it also means that we can
say things in parallel.

00:15:15.870 --> 00:15:18.850
Now what this means,
effectively, is that if your

00:15:18.850 --> 00:15:22.910
server has decided to think
for a long time about

00:15:22.910 --> 00:15:26.360
something, it's not going to
slow down all the things it

00:15:26.360 --> 00:15:28.540
doesn't have to think
about for.

00:15:28.540 --> 00:15:31.300
And this ends up being a very
interesting problem for HTTP

00:15:31.300 --> 00:15:34.000
called head of line blocking,
probably familiar with it.

00:15:34.000 --> 00:15:35.900
We don't suffer from that with
SPDY because of interleaving.

00:15:39.190 --> 00:15:41.830
All right, ServerPush.

00:15:41.830 --> 00:15:44.670
Now we're just beginning to
play around with this.

00:15:44.670 --> 00:15:48.010
And, frankly, I'm really excited
about ServerPush.

00:15:48.010 --> 00:15:54.390
ServerPush gives us much better
control over every

00:15:54.390 --> 00:15:56.500
aspect of our transaction.

00:15:56.500 --> 00:16:01.810
And in particular, unlike inline
which allows us about

00:16:01.810 --> 00:16:06.400
the same latency win on the
first request, it allows us to

00:16:06.400 --> 00:16:08.920
put stuff in the
browser cache.

00:16:08.920 --> 00:16:10.870
It's referred to by its name.

00:16:10.870 --> 00:16:14.330
That means on the next page
load, and I hope that you guys

00:16:14.330 --> 00:16:16.930
are planning to have the
customer come back to the page

00:16:16.930 --> 00:16:19.610
so this should matter.

00:16:19.610 --> 00:16:21.150
Is there anyone here that
doesn't hope that the

00:16:21.150 --> 00:16:24.040
customers come back
to the page?

00:16:24.040 --> 00:16:25.940
Sometimes silence is golden.

00:16:25.940 --> 00:16:30.160
So on the second page load, or
subsequent, having these

00:16:30.160 --> 00:16:34.930
things in the cache can
be a great benefit.

00:16:34.930 --> 00:16:36.460
Don't know about you, what
do you guys think?

00:16:36.460 --> 00:16:39.000
Is inlining annoying?

00:16:39.000 --> 00:16:40.380
Well I think it is.

00:16:40.380 --> 00:16:44.110
So one of the reasons it's
annoying, is despite the fact

00:16:44.110 --> 00:16:45.970
it shaves off an RTT,
it's really,

00:16:45.970 --> 00:16:48.070
really easy to get wrong.

00:16:48.070 --> 00:16:52.040
If I accidentally inline an
image, for instance, before

00:16:52.040 --> 00:16:56.480
that critical JavaScript,
I've just ruined my user

00:16:56.480 --> 00:16:57.990
experience.

00:16:57.990 --> 00:17:02.140
And what works today for
inlining my page doesn't work

00:17:02.140 --> 00:17:03.840
tomorrow necessarily.

00:17:03.840 --> 00:17:07.420
Because one of the resources may
be written by a different

00:17:07.420 --> 00:17:09.920
developer than the other one.

00:17:09.920 --> 00:17:14.050
And unless we have some
mechanism that allows us to

00:17:14.050 --> 00:17:17.369
redo the order in which we're
inlining every time we've

00:17:17.369 --> 00:17:19.970
changed one of the resources
we may be getting it wrong.

00:17:19.970 --> 00:17:22.354
And that is fairly often,
unfortunately.

00:17:25.010 --> 00:17:27.310
And as I mentioned, beginning
to make its way into

00:17:27.310 --> 00:17:28.290
implementations.

00:17:28.290 --> 00:17:29.890
And, again, you'll see that
in the demo soon.

00:17:33.350 --> 00:17:36.100
I've heard people arguing
against ServerPush.

00:17:36.100 --> 00:17:40.260
And I think that they need
to think about it

00:17:40.260 --> 00:17:41.580
a little bit more.

00:17:41.580 --> 00:17:44.660
The way I think about ServerPush
is that ServerPush

00:17:44.660 --> 00:17:46.490
is much better inlining.

00:17:46.490 --> 00:17:48.810
It's inlining that
is forgiving.

00:17:48.810 --> 00:17:52.580
It's inlining that, when you
make a mistake, and you

00:17:52.580 --> 00:17:56.000
include an unimportant resource
because of the

00:17:56.000 --> 00:17:57.610
interleaving, the
prioritization, I mentioned

00:17:57.610 --> 00:18:02.210
before, it allows the server to
help fix the error for you

00:18:02.210 --> 00:18:03.760
without you even really
thinking about it.

00:18:03.760 --> 00:18:05.720
And without it impacting
the user much.

00:18:05.720 --> 00:18:09.220
So let's say I said,
you know what?

00:18:09.220 --> 00:18:12.070
Let's push this image.

00:18:12.070 --> 00:18:15.140
And, unfortunately, I forgot
that the CSS is mentioned

00:18:15.140 --> 00:18:16.430
after this for some reason.

00:18:16.430 --> 00:18:18.700
I just got it wrong.

00:18:18.700 --> 00:18:21.390
As soon as the server sees that
there's a request for the

00:18:21.390 --> 00:18:24.320
CSS, it will stop filling up
the pipe with that image.

00:18:24.320 --> 00:18:26.520
It will send the CSS.

00:18:26.520 --> 00:18:28.570
The idea is that we're always
going to send the most

00:18:28.570 --> 00:18:32.050
important information
as soon as we can.

00:18:32.050 --> 00:18:35.010
So if I get it wrong, server
will make most

00:18:35.010 --> 00:18:37.550
of it go away, hopefully.

00:18:37.550 --> 00:18:40.550
It's not magic, though.

00:18:40.550 --> 00:18:42.240
SPDY uses one connection.

00:18:42.240 --> 00:18:43.630
This is actually enabling.

00:18:43.630 --> 00:18:45.480
Because this allows us to
do all this beautiful

00:18:45.480 --> 00:18:46.570
prioritization.

00:18:46.570 --> 00:18:48.970
This allows us to do the
ServerPush because we don't

00:18:48.970 --> 00:18:52.440
have this untenable coordination
problem.

00:18:52.440 --> 00:18:56.780
For large services, when you
make six connections per

00:18:56.780 --> 00:18:59.860
domain, it's very unlikely that
those six connections end

00:18:59.860 --> 00:19:01.920
up going to the same host.

00:19:01.920 --> 00:19:03.290
Inevitably, most of them
are going to go

00:19:03.290 --> 00:19:04.830
to different hosts.

00:19:04.830 --> 00:19:07.640
As a result, if you want to
coordinate what's happening

00:19:07.640 --> 00:19:10.930
for that user session, you're
going to have to coordinate

00:19:10.930 --> 00:19:14.570
the machines that are all
terminating those requests.

00:19:14.570 --> 00:19:16.010
That ends up being really
difficult with many

00:19:16.010 --> 00:19:16.950
connections.

00:19:16.950 --> 00:19:19.625
Now, having one connection
offers other benefits.

00:19:19.625 --> 00:19:21.610
It reduces buffer bloat.

00:19:21.610 --> 00:19:23.520
And if you're not familiar
with buffer bloat, buffer

00:19:23.520 --> 00:19:26.830
bloat is basically the idea
that, because TCP is designed

00:19:26.830 --> 00:19:29.770
to fill up every buffer in
between you and the way you're

00:19:29.770 --> 00:19:34.560
going, if there's more space
in a buffer it's

00:19:34.560 --> 00:19:36.060
going to use it.

00:19:36.060 --> 00:19:38.980
And because it's using it, it's
going to increase the

00:19:38.980 --> 00:19:42.640
latency, or the apparent latency
over that link as time

00:19:42.640 --> 00:19:43.700
progresses.

00:19:43.700 --> 00:19:48.440
And I don't know if any of you
have a large buffer on a cable

00:19:48.440 --> 00:19:52.430
modem, or have had that
experience in the past.

00:19:52.430 --> 00:19:54.400
It gets very painful when
you're doing VOIP.

00:19:54.400 --> 00:19:57.170
And the delay with the person
you're conversing with

00:19:57.170 --> 00:20:03.580
increases as you've been
talking to them.

00:20:03.580 --> 00:20:04.880
I think it's really painful.

00:20:04.880 --> 00:20:05.740
I don't like it.

00:20:05.740 --> 00:20:07.660
So SPDY, it's helpful.

00:20:07.660 --> 00:20:09.130
It doesn't make so
many connections.

00:20:09.130 --> 00:20:11.980
As a result, it's less likely
to fill up more buffers.

00:20:11.980 --> 00:20:13.990
It will fill up only as much
as it absolutely needs to.

00:20:17.360 --> 00:20:20.450
If you're a server guy, it's
nice, the idea that this thing

00:20:20.450 --> 00:20:22.570
might use less server
resources.

00:20:22.570 --> 00:20:24.980
Now, there's a kind of
trade off in SPDY.

00:20:24.980 --> 00:20:26.170
Because we do the header
compression,

00:20:26.170 --> 00:20:27.120
we have a Gzip context.

00:20:27.120 --> 00:20:30.890
So you're going to be Gzipping
the headers, only the headers

00:20:30.890 --> 00:20:34.100
hopefully, on the response.

00:20:34.100 --> 00:20:36.590
So you're going to be spending
a little bit more CPU there.

00:20:36.590 --> 00:20:39.720
Now we're looking in the
future to change that.

00:20:39.720 --> 00:20:41.330
We're looking to make
that faster,

00:20:41.330 --> 00:20:42.770
hopefully extremely cheap.

00:20:42.770 --> 00:20:48.250
But, for today, it does use
a little bit more CPU,

00:20:48.250 --> 00:20:49.650
only for that part.

00:20:49.650 --> 00:20:52.300
However, if you have a
lot of SSL because

00:20:52.300 --> 00:20:53.320
you care about security.

00:20:53.320 --> 00:20:56.480
And your users care about
security, which is probably

00:20:56.480 --> 00:20:59.880
why you do, then it might
actually make things cheaper,

00:20:59.880 --> 00:21:02.060
because you're going to have
to do many fewer SSL

00:21:02.060 --> 00:21:02.660
handshakes.

00:21:02.660 --> 00:21:04.500
You're going to have to
be many fewer accepts.

00:21:04.500 --> 00:21:07.510
You're going to have to manage
fewer file descriptors.

00:21:07.510 --> 00:21:10.140
You're kernel is going to have
to do less context switches.

00:21:10.140 --> 00:21:13.100
So there are all of these games
that happen not in the

00:21:13.100 --> 00:21:16.650
user space of your application,
but in the system

00:21:16.650 --> 00:21:20.360
part of your host.

00:21:20.360 --> 00:21:23.370
Another thing it allows you to
do, it allows you to better

00:21:23.370 --> 00:21:26.460
measure TCP properties
on your connection.

00:21:26.460 --> 00:21:29.830
So one of those, and perhaps the
most important one, is the

00:21:29.830 --> 00:21:32.430
congestion window.

00:21:32.430 --> 00:21:36.000
The congestion window parameter
for TCP basically

00:21:36.000 --> 00:21:39.460
says how many bytes in flight
you're allowed to have at any

00:21:39.460 --> 00:21:41.180
point in time.

00:21:41.180 --> 00:21:44.280
This ends up being important,
of course, because this is a

00:21:44.280 --> 00:21:46.120
form of rate control.

00:21:46.120 --> 00:21:53.470
And the way TCP works is that
it discovers this parameter

00:21:53.470 --> 00:21:55.320
over the course of
the connection.

00:21:55.320 --> 00:21:59.290
And it starts out relatively
small.

00:21:59.290 --> 00:22:02.550
For most implementations today,
it's going to start out

00:22:02.550 --> 00:22:06.940
around two packets worth.

00:22:06.940 --> 00:22:11.580
I don't know about you, but MMS,
let's call it 1,500 just

00:22:11.580 --> 00:22:12.450
to make it easy.

00:22:12.450 --> 00:22:15.080
That's 3k.

00:22:15.080 --> 00:22:19.100
Most request don't fit in 3k,
let alone the responses.

00:22:19.100 --> 00:22:22.100
So basically that means that
we're going to have to take

00:22:22.100 --> 00:22:25.300
some round trips in order to
open this window up, in order

00:22:25.300 --> 00:22:27.660
to be able to actually send all
the request so that then

00:22:27.660 --> 00:22:29.300
we can get the responses.

00:22:29.300 --> 00:22:33.480
So if we can do something to
speed up that part, then we

00:22:33.480 --> 00:22:38.400
have increased the chance that
we have a bigger pipe earlier.

00:22:38.400 --> 00:22:41.390
So because, with SPDY, we have
the one connection it gets a

00:22:41.390 --> 00:22:44.690
better estimation of what this
is, because speedy allows you

00:22:44.690 --> 00:22:48.430
to have the client cache that
setting and tell the server

00:22:48.430 --> 00:22:50.810
what it was when it comes
back in the future.

00:22:50.810 --> 00:22:54.160
We can open up the pipes
to where it was before.

00:22:54.160 --> 00:22:55.550
Not unfairly, right?

00:22:55.550 --> 00:22:56.730
We're not doing this
arbitrarily.

00:22:56.730 --> 00:23:00.130
We're doing this based on what
the internet said-- or what we

00:23:00.130 --> 00:23:03.790
measured of the congestion
over the path for that

00:23:03.790 --> 00:23:05.670
particular connection
at that time.

00:23:05.670 --> 00:23:08.600
I think that's really cool
because it means that I'm not

00:23:08.600 --> 00:23:11.350
limited to sending 3k of
requests for that first thing.

00:23:11.350 --> 00:23:14.090
I can send however much the
Seawind eventually got to.

00:23:17.180 --> 00:23:20.150
As a result of all this, in
case we are writing load

00:23:20.150 --> 00:23:23.140
balancers, for instance,
we use fewer packets.

00:23:23.140 --> 00:23:24.930
We use fewer packet, of course,
because we are doing

00:23:24.930 --> 00:23:26.220
compression.

00:23:26.220 --> 00:23:29.470
And we use fewer packets because
we are using one

00:23:29.470 --> 00:23:30.560
connection.

00:23:30.560 --> 00:23:33.250
And, as a result of doing
one connection, we

00:23:33.250 --> 00:23:35.560
have more full packets.

00:23:35.560 --> 00:23:37.470
So we are not forced to fragment
the packets because

00:23:37.470 --> 00:23:38.720
they're going to
the same place.

00:23:41.310 --> 00:23:43.940
SPDY doesn't require rewriting
your site.

00:23:43.940 --> 00:23:46.540
You do not have to
change the URLs.

00:23:46.540 --> 00:23:48.870
They remain HTTPS and HTTP.

00:23:48.870 --> 00:23:52.800
Those schemes, I'm afraid, are
likely to be here for a very

00:23:52.800 --> 00:23:56.670
long time, regardless of what
is spoken underneath.

00:23:56.670 --> 00:24:00.770
And the way it works is that
when a connection is made, in

00:24:00.770 --> 00:24:05.505
particular an SSL connection,
if your browser speaks SPDY,

00:24:05.505 --> 00:24:10.290
it will advertise to the server
in an extension called

00:24:10.290 --> 00:24:16.617
Next Protocol Negotiation, I
speak SPDY2 SPDY3, HTTPS, web

00:24:16.617 --> 00:24:19.150
sockets, whatever
else it speaks.

00:24:19.150 --> 00:24:22.010
And the server can then
respond saying, I have

00:24:22.010 --> 00:24:24.520
selected SPDY2.

00:24:24.520 --> 00:24:27.950
And, as a result, we get a
zero additional latency

00:24:27.950 --> 00:24:30.600
handshake that allows
us to negotiate

00:24:30.600 --> 00:24:32.510
whatever protocol we want.

00:24:32.510 --> 00:24:34.270
Now, this isn't SPDY specific.

00:24:34.270 --> 00:24:36.810
This just a fall out of the work
that was done in order to

00:24:36.810 --> 00:24:38.230
enable SPDY.

00:24:38.230 --> 00:24:42.680
But it's nice because it gives
us a path forward.

00:24:42.680 --> 00:24:45.580
It gives us a path on
a port that allows

00:24:45.580 --> 00:24:47.070
us to do new things.

00:24:47.070 --> 00:24:49.470
And to stop this ossification
that seemed to be

00:24:49.470 --> 00:24:50.530
happening on the web.

00:24:50.530 --> 00:24:52.730
We want a web that's continually
fresh, that

00:24:52.730 --> 00:24:57.550
renews, all the way down to
its roots, if we can.

00:24:57.550 --> 00:25:03.890
So all of this prioritization,
all of the multiplexing, we

00:25:03.890 --> 00:25:06.900
figure most of this can
help your site.

00:25:06.900 --> 00:25:09.170
But there's that ServerPush
thing.

00:25:09.170 --> 00:25:12.600
And ServerPush might take
a little more effort.

00:25:15.100 --> 00:25:17.360
SPDY isn't magic.

00:25:17.360 --> 00:25:18.950
I've just describe what it is.

00:25:18.950 --> 00:25:21.690
Hopefully, you're already
thinking about scenarios where

00:25:21.690 --> 00:25:22.900
it may not work for you.

00:25:22.900 --> 00:25:26.120
But, in any case,
here they are.

00:25:26.120 --> 00:25:28.530
SPDY isn't going to work for
you very well if you have a

00:25:28.530 --> 00:25:30.620
whole lot of third
party domains.

00:25:30.620 --> 00:25:33.060
And what I mean by third party
domains, is domains that you

00:25:33.060 --> 00:25:34.300
do not control the
servers, you do

00:25:34.300 --> 00:25:36.320
not control the content.

00:25:36.320 --> 00:25:40.790
The more connections you have,
the less likely multiplexing,

00:25:40.790 --> 00:25:42.950
and prioritization, and all
this fancy stuff, is

00:25:42.950 --> 00:25:44.380
likely to help you.

00:25:44.380 --> 00:25:48.110
The more cold starts connections
you have, the less

00:25:48.110 --> 00:25:49.685
likely SPDY is to help you.

00:25:49.685 --> 00:25:52.740
And I'll point out, when you
have a lot of cold start

00:25:52.740 --> 00:25:55.260
connections, it generally means
you don't have a lot of

00:25:55.260 --> 00:25:57.930
ongoing engagement
with your users.

00:25:57.930 --> 00:26:02.050
So I'm hoping that I've guessed
right, and that you

00:26:02.050 --> 00:26:05.500
guys want more engagement
with the user.

00:26:05.500 --> 00:26:08.740
And you want that user to be
sticky to your site for as

00:26:08.740 --> 00:26:10.620
long as possible.

00:26:10.620 --> 00:26:12.650
So the protocol is designed
to help when that happens.

00:26:15.790 --> 00:26:18.080
Oh, of course, and if you've
optimized your site so much

00:26:18.080 --> 00:26:21.190
that you don't actually have
to use a lot of requests it

00:26:21.190 --> 00:26:22.235
may not help you.

00:26:22.235 --> 00:26:24.450
It can.

00:26:24.450 --> 00:26:26.870
But it may not.

00:26:26.870 --> 00:26:29.350
All right so just
to go over it.

00:26:29.350 --> 00:26:30.895
HTTP has a bunch
of limitations.

00:26:33.630 --> 00:26:34.735
It's not secure.

00:26:34.735 --> 00:26:37.255
It doesn't compress, all that
redundancy in the headers.

00:26:37.255 --> 00:26:39.190
It doesn't do multiplexing.

00:26:39.190 --> 00:26:41.450
It's only half-duplex.

00:26:41.450 --> 00:26:42.460
It doesn't do prioritization.

00:26:42.460 --> 00:26:44.720
So if you get the order of
requests wrong, well, it's not

00:26:44.720 --> 00:26:46.480
going to help you.

00:26:46.480 --> 00:26:50.850
No ServerPush, no interleaving,
and of course,

00:26:50.850 --> 00:26:52.960
because you have to do all that
domain charting, which I

00:26:52.960 --> 00:26:56.120
find annoying, it requires you
to do more DNS lookups.

00:26:56.120 --> 00:26:59.600
And, of course, it requires you
to make more connections.

00:26:59.600 --> 00:27:02.440
All right, so, aren't browsers
getting smarter?

00:27:04.990 --> 00:27:08.060
Yeah, they're getting smarter.

00:27:08.060 --> 00:27:09.570
But they're still going
to be worse than

00:27:09.570 --> 00:27:12.720
what we do with SPDY.

00:27:12.720 --> 00:27:14.540
So why do I say that?

00:27:14.540 --> 00:27:15.920
I say that because each
connection that

00:27:15.920 --> 00:27:17.380
you make has a cost.

00:27:17.380 --> 00:27:19.520
And if we think back to the
beginning, we're using 12

00:27:19.520 --> 00:27:21.230
different domains on average.

00:27:21.230 --> 00:27:22.990
We're using 84 different
requests.

00:27:22.990 --> 00:27:25.590
That's going to require a fair
number of connections.

00:27:25.590 --> 00:27:28.270
And each one of these
connections, requires a DNS

00:27:28.270 --> 00:27:29.200
resolution.

00:27:29.200 --> 00:27:31.660
And looking at data, for a large
percentage of people

00:27:31.660 --> 00:27:33.940
that's more than 100
milliseconds right there, just

00:27:33.940 --> 00:27:35.490
the DNS request.

00:27:35.490 --> 00:27:38.010
It requires a new TCP
connection, which requires a

00:27:38.010 --> 00:27:39.280
three way handshake.

00:27:39.280 --> 00:27:42.080
You get the SIN, SINAC, AC.

00:27:42.080 --> 00:27:43.596
That's another RTT.

00:27:43.596 --> 00:27:47.210
If you're using HTTPS, and it
seems like we're going towards

00:27:47.210 --> 00:27:48.840
that more and more, than
you're going to

00:27:48.840 --> 00:27:51.770
have another few RTTS.

00:27:51.770 --> 00:27:55.520
And, of course, these
connections aren't free.

00:27:55.520 --> 00:27:58.720
The resources for them don't
show up out of thin air.

00:27:58.720 --> 00:28:00.810
We have to pay for the servers
that are making these

00:28:00.810 --> 00:28:01.680
connections.

00:28:01.680 --> 00:28:06.910
So we want to limit
them if we can.

00:28:06.910 --> 00:28:09.200
And, of course, something that
everybody forgets about,

00:28:09.200 --> 00:28:12.540
including me, which is why we
have these slides, every

00:28:12.540 --> 00:28:15.240
connection you make takes
up space in an address

00:28:15.240 --> 00:28:17.830
translation table
on a NAT box.

00:28:17.830 --> 00:28:22.080
And these NAT boxes get really
funny when you start

00:28:22.080 --> 00:28:23.450
overflowing these tables.

00:28:23.450 --> 00:28:24.900
And what ends up happening--

00:28:24.900 --> 00:28:26.560
this is super annoying
by the way--

00:28:26.560 --> 00:28:30.090
what ends up happening is that
it doesn't bother to send you

00:28:30.090 --> 00:28:31.070
any packets anymore.

00:28:31.070 --> 00:28:33.150
And it doesn't bother to forward
the packets anymore.

00:28:33.150 --> 00:28:35.250
That means it doesn't even
close the connection.

00:28:35.250 --> 00:28:37.200
That means that you're
now making requests

00:28:37.200 --> 00:28:38.730
into a black hole.

00:28:38.730 --> 00:28:40.360
You've put your connection
to dev null.

00:28:40.360 --> 00:28:42.740
It's gone.

00:28:42.740 --> 00:28:45.290
So we have to be kind of careful
to not overflow these

00:28:45.290 --> 00:28:46.220
things if we can.

00:28:46.220 --> 00:28:47.430
SPDY and help a lot there.

00:28:47.430 --> 00:28:50.910
We're talking about a factor
of, hopefully, an order of

00:28:50.910 --> 00:28:52.170
magnitude decrease
in the number of

00:28:52.170 --> 00:28:53.720
connections we use today.

00:28:53.720 --> 00:28:56.920
And if we continue to use SPDY
for other protocols, if we

00:28:56.920 --> 00:28:59.560
continue to use SPDY for HTTP,
HTTPS, hopefully something

00:28:59.560 --> 00:29:02.120
like web sockets, we're
going to have less

00:29:02.120 --> 00:29:03.370
problems in this area.

00:29:05.810 --> 00:29:08.800
So what can you do?

00:29:08.800 --> 00:29:12.160
If you're a system administrator
and this is a

00:29:12.160 --> 00:29:15.540
complex issue, try and optimize
your searching.

00:29:15.540 --> 00:29:17.840
And I'll point out that every
single one of the things I'm

00:29:17.840 --> 00:29:20.710
going to talk about here, with
the exception of some DNS

00:29:20.710 --> 00:29:23.810
stuff, is going to be helpful
for you regardless of whether

00:29:23.810 --> 00:29:25.520
or not you're optimizing
for SPDY.

00:29:25.520 --> 00:29:27.530
When you're optimizing for SPDY,
you end up optimizing

00:29:27.530 --> 00:29:29.110
for HTTPS as well.

00:29:29.110 --> 00:29:34.180
So ask your cert provider hard
questions, like how many

00:29:34.180 --> 00:29:38.150
browsers that are out there
right now have you as a

00:29:38.150 --> 00:29:41.680
trusted cert provider?

00:29:41.680 --> 00:29:44.490
The more browsers that are
there, the fewer certs in your

00:29:44.490 --> 00:29:46.100
cert you have to send.

00:29:46.100 --> 00:29:50.290
Now, typically I think we see a
cert chain of around three,

00:29:50.290 --> 00:29:53.620
which means that we need three
certs to get to most of them.

00:29:53.620 --> 00:29:55.500
But we can get more
cute than that.

00:29:55.500 --> 00:29:58.810
If we're doing SPDY, we see
SPDY has been negotiated.

00:29:58.810 --> 00:30:05.280
We know it's either Firefox
13 or a Chrome browser.

00:30:05.280 --> 00:30:07.470
Both of those are
fairly modern.

00:30:07.470 --> 00:30:10.050
Thus, we don't have to send
all of that data.

00:30:10.050 --> 00:30:11.900
We don't have to send that
third one definitely.

00:30:11.900 --> 00:30:13.730
We may only have to
send one cert.

00:30:13.730 --> 00:30:16.560
And as a result, our handshake
gets smaller.

00:30:16.560 --> 00:30:18.470
The amount of bandwidth
we spend is smaller.

00:30:18.470 --> 00:30:21.630
And this happens whether or
not we're using SPDY.

00:30:21.630 --> 00:30:23.970
If you see the NPN is there,
even if you don't want to do

00:30:23.970 --> 00:30:27.560
SPDY you can change which
SSL certs you send.

00:30:27.560 --> 00:30:30.500
So because we deployed SPDY, we
might speed up HTTPS, ah,

00:30:30.500 --> 00:30:31.750
competition, oh well.

00:30:33.860 --> 00:30:35.560
You can change your
TCP settings.

00:30:35.560 --> 00:30:39.070
If you have a modern Linux
kernel on your server this may

00:30:39.070 --> 00:30:41.400
be done for you already.

00:30:41.400 --> 00:30:45.170
The trunk for Linux, and some
other versions, I don't recall

00:30:45.170 --> 00:30:47.850
exactly which unfortunately,
already have an initial

00:30:47.850 --> 00:30:49.440
congestion window of 10.

00:30:49.440 --> 00:30:51.990
But here's the magic
command to set it.

00:30:51.990 --> 00:30:55.150
It's IP route change default,
via whatever is your gateway,

00:30:55.150 --> 00:30:55.990
[? IPCwind ?]

00:30:55.990 --> 00:30:56.500
10.

00:30:56.500 --> 00:30:59.330
And that magic invocation will
set it to 10, which according

00:30:59.330 --> 00:31:01.070
to Google research seems
to be about right.

00:31:03.580 --> 00:31:06.520
You also want to turn off this
TCP-slow-start-after-idle,

00:31:06.520 --> 00:31:08.000
which, despite the
way it sounds--

00:31:08.000 --> 00:31:09.350
I mean, it sounds like it
should be nice, right?

00:31:09.350 --> 00:31:11.810
I mean idle, if my connection
has not been doing anything

00:31:11.810 --> 00:31:14.920
for 60 seconds, yeah let's
close it down.

00:31:14.920 --> 00:31:16.960
Unfortunately, it doesn't
always end up that way.

00:31:16.960 --> 00:31:20.860
The connection can be idle for
one packet worth sometimes.

00:31:20.860 --> 00:31:22.530
And it can cut the Seawind
down all the

00:31:22.530 --> 00:31:25.204
way back to the beginning.

00:31:25.204 --> 00:31:28.850
Ow, we probably need to
rethink this thing.

00:31:28.850 --> 00:31:33.520
But for now you can just turn
it off using that command.

00:31:33.520 --> 00:31:36.990
DNS, this one gets
complicated.

00:31:36.990 --> 00:31:40.610
SPDY can share a connection
on multiple domains.

00:31:40.610 --> 00:31:42.130
But it requires two
things to happen.

00:31:45.700 --> 00:31:48.250
It requires that the resolution
for the host that

00:31:48.250 --> 00:31:52.450
you're going to go to next
overlaps with the IP of the

00:31:52.450 --> 00:31:54.970
connection that you're connected
to right now.

00:31:54.970 --> 00:31:56.220
And that the cert matches.

00:31:58.680 --> 00:32:00.000
Got it?

00:32:00.000 --> 00:32:01.290
Good.

00:32:01.290 --> 00:32:07.890
So, profit, fewer connections
means less latency, means less

00:32:07.890 --> 00:32:09.040
server utilization--

00:32:09.040 --> 00:32:13.250
well, rather, more server
utilization, less CPU.

00:32:13.250 --> 00:32:16.640
And it's basically
a good thing.

00:32:16.640 --> 00:32:18.380
Don't shard host names when
you're using speedy.

00:32:18.380 --> 00:32:19.610
You don't have to.

00:32:19.610 --> 00:32:21.880
You already have a lot
of parallelism.

00:32:21.880 --> 00:32:26.260
SPDY has a default parallelism
of 100.

00:32:26.260 --> 00:32:30.240
And it seems like the browsers
jack that up as

00:32:30.240 --> 00:32:31.350
soon as they connect.

00:32:31.350 --> 00:32:35.540
I think Chrome is announcing
10,000 now for the next

00:32:35.540 --> 00:32:36.980
version that's coming out.

00:32:36.980 --> 00:32:38.800
So you don't have to shard
your host names.

00:32:38.800 --> 00:32:42.810
Doing so may cause at least a
DNS look up, and potentially

00:32:42.810 --> 00:32:43.680
another connection.

00:32:43.680 --> 00:32:45.040
You don't need to do it.

00:32:47.950 --> 00:32:50.400
Try and use ServerPush instead
of inlining in the future when

00:32:50.400 --> 00:32:52.430
support for it becomes a
little bit more mature.

00:32:52.430 --> 00:32:55.240
And support for this is
maturing very quickly.

00:32:55.240 --> 00:32:58.750
I know, for instance, that Jetty
has an implementation

00:32:58.750 --> 00:33:00.790
that does some things that don't
require any action on

00:33:00.790 --> 00:33:01.900
your behalf at all.

00:33:01.900 --> 00:33:05.290
And, in fact, it learns from
the referrer what resources

00:33:05.290 --> 00:33:08.440
end up being associated
with stuff.

00:33:08.440 --> 00:33:10.670
We're hoping that we can make
this even better as time goes

00:33:10.670 --> 00:33:12.400
on and make this even
more hands free.

00:33:15.310 --> 00:33:17.230
Get a wild card cert.

00:33:17.230 --> 00:33:18.790
You should do this because
it's cheaper

00:33:18.790 --> 00:33:20.100
in the first place.

00:33:20.100 --> 00:33:23.500
And I mean that because if you
get one cert, it's most of the

00:33:23.500 --> 00:33:27.190
time cheaper than getting five
certs, six certs, however many

00:33:27.190 --> 00:33:28.590
subdomains you have.

00:33:28.590 --> 00:33:30.940
It's also good because it
allows SPDY to share the

00:33:30.940 --> 00:33:31.640
connections.

00:33:31.640 --> 00:33:34.400
Remember, SPDY will share
a connection when the IP

00:33:34.400 --> 00:33:36.840
overlaps with whatever
connection it already has and

00:33:36.840 --> 00:33:37.730
when the cert matches.

00:33:37.730 --> 00:33:40.370
A wild card cert matches
more than one domain.

00:33:40.370 --> 00:33:41.620
That's great.

00:33:43.780 --> 00:33:47.640
Just to let you know on
standards, hopefully, because

00:33:47.640 --> 00:33:51.100
of us, HTTP2.0 has
been kicked off.

00:33:51.100 --> 00:33:54.610
And we have proposed
SPDY as one of the

00:33:54.610 --> 00:33:56.100
inputs to this standard.

00:33:56.100 --> 00:33:59.030
So we're hoping that we end up
with an HTTP2.0 that gives us

00:33:59.030 --> 00:34:01.070
many of the things that
SPDY gives us today.

00:34:01.070 --> 00:34:04.680
Hopefully all of them.

00:34:04.680 --> 00:34:09.139
So the future, we don't think
we're done with SPDY.

00:34:09.139 --> 00:34:11.460
I believe that we'll be done,
at least at the application

00:34:11.460 --> 00:34:16.110
layer, when there is no dead air
on that connection at all.

00:34:16.110 --> 00:34:20.139
And at the end of that sending
of data, the page has been

00:34:20.139 --> 00:34:23.940
delivered completely
to the user.

00:34:23.940 --> 00:34:25.090
We're not there yet.

00:34:25.090 --> 00:34:26.630
We use multiple domains.

00:34:26.630 --> 00:34:28.550
We use multiple domains that
have different certs.

00:34:28.550 --> 00:34:30.870
We use multiple domains that
have different certs that end

00:34:30.870 --> 00:34:32.620
up going to the same server.

00:34:32.620 --> 00:34:33.909
So we can do better.

00:34:33.909 --> 00:34:36.080
We can push the SSL certs.

00:34:36.080 --> 00:34:38.710
We can also push the
DNS information.

00:34:38.710 --> 00:34:40.350
And pushing the DNS information
gets really

00:34:40.350 --> 00:34:41.699
interesting for other reasons.

00:34:41.699 --> 00:34:45.780
If you have a CDN, for instance,
you can do much

00:34:45.780 --> 00:34:48.770
better geolocation.

00:34:48.770 --> 00:34:52.239
You can change where the user
is making that connection to

00:34:52.239 --> 00:34:55.120
something that's significantly
closer to your resources.

00:34:55.120 --> 00:34:58.010
And thus you can decrease both
the amount of work that's done

00:34:58.010 --> 00:35:00.570
by you, but also you can
decrease the latency, which

00:35:00.570 --> 00:35:04.100
is, of course, why we're
talking about this.

00:35:04.100 --> 00:35:07.410
So as I mentioned before, we've
got Chrome supporting.

00:35:07.410 --> 00:35:09.180
And we have Firefox
supporting it.

00:35:09.180 --> 00:35:11.930
And I'll point out that's
a lot of users.

00:35:15.180 --> 00:35:20.330
Now on the server side, of
course Google Sites use it.

00:35:20.330 --> 00:35:22.820
Any App Engine sites
using HTTPS use it.

00:35:22.820 --> 00:35:25.990
So if you have an App Engine
app that uses HTTPS stuff,

00:35:25.990 --> 00:35:26.690
you're already using it.

00:35:26.690 --> 00:35:28.700
You don't even realize it.

00:35:28.700 --> 00:35:30.340
Twitter uses it.

00:35:30.340 --> 00:35:32.850
Akamai has announced that they
are going to support it very

00:35:32.850 --> 00:35:35.600
soon, as a technology preview
starting very soon.

00:35:35.600 --> 00:35:38.390
And next quarter they say that
they're going to have it out

00:35:38.390 --> 00:35:41.130
in production for everyone.

00:35:41.130 --> 00:35:46.440
Cotendo, EngineX, F5, Jetty,
Mod SPDY, node SPDY,

00:35:46.440 --> 00:35:47.690
Momentum, et cetera.

00:35:50.260 --> 00:35:52.760
So let's get to some
more good stuff.

00:35:56.500 --> 00:35:58.610
So here we have a page
we want to optimize.

00:36:03.280 --> 00:36:06.910
And you'll see, as I'm moving
the cursor around, that this

00:36:06.910 --> 00:36:08.840
seems to be made up of a
whole bunch of tiles.

00:36:08.840 --> 00:36:09.650
You're right.

00:36:09.650 --> 00:36:10.640
It is.

00:36:10.640 --> 00:36:12.255
It's 640 tiles.

00:36:12.255 --> 00:36:14.480
Now hopefully this is going to
be more resources than your

00:36:14.480 --> 00:36:17.470
average webpage today.

00:36:17.470 --> 00:36:23.210
And obviously this is
going a little far.

00:36:23.210 --> 00:36:26.720
But I'm here to make a point.

00:36:26.720 --> 00:36:28.960
So here we go.

00:36:28.960 --> 00:36:32.630
I have conditioned my local
host to act kind of like a

00:36:32.630 --> 00:36:34.310
mobile connection that
we would get today.

00:36:34.310 --> 00:36:36.790
It's a megabit 200
millisecond RTT.

00:36:36.790 --> 00:36:38.040
Let's see how this loads.

00:36:42.710 --> 00:36:44.130
This is eight way
domain charted.

00:36:47.960 --> 00:36:50.570
Not too speedy.

00:36:50.570 --> 00:36:53.750
All right, let's try it again.

00:36:53.750 --> 00:36:55.110
This time we're just
going use SPDY.

00:36:55.110 --> 00:36:56.340
We didn't do anything fancy.

00:36:56.340 --> 00:36:57.700
We're not doing any
ServerPush.

00:36:57.700 --> 00:36:59.470
I didn't modify the
site in any way.

00:36:59.470 --> 00:37:00.720
Let's see what it looks like.

00:37:05.010 --> 00:37:06.330
It seems to be going better.

00:37:06.330 --> 00:37:07.710
You'll notice that
it got faster as

00:37:07.710 --> 00:37:09.180
it loaded more resources.

00:37:09.180 --> 00:37:11.450
That's that opening up of the
TCP connection that I was

00:37:11.450 --> 00:37:12.620
talking about.

00:37:12.620 --> 00:37:15.810
If I load this again it's
going to end up faster.

00:37:15.810 --> 00:37:17.280
But I have more interesting
things to show you.

00:37:17.280 --> 00:37:18.530
So I'm not going to do that.

00:37:20.890 --> 00:37:22.940
So I told you about
ServerPush.

00:37:22.940 --> 00:37:25.960
So I imagine many of you have
imagined you might be

00:37:25.960 --> 00:37:27.070
something like this.

00:37:27.070 --> 00:37:29.540
You might decide, you know what,
I'm just going to tell

00:37:29.540 --> 00:37:33.570
it it should push all
those resources.

00:37:33.570 --> 00:37:35.495
If you look at timing, by the
way, that was a lot faster.

00:37:38.840 --> 00:37:41.321
This is my favorite.

00:37:41.321 --> 00:37:43.230
You know what?

00:37:43.230 --> 00:37:45.840
I don't really care about
how quickly the

00:37:45.840 --> 00:37:47.680
full site comes there.

00:37:47.680 --> 00:37:49.800
I only really care about the
above the fold time.

00:37:49.800 --> 00:37:53.480
I care about the amount of time
it takes before the site

00:37:53.480 --> 00:37:57.010
becomes useful to the user,
before it becomes attractive

00:37:57.010 --> 00:37:58.360
for the user to use.

00:37:58.360 --> 00:37:59.610
So why don't I do this?

00:38:04.680 --> 00:38:07.970
Why don't I push the resources
that are important first.

00:38:11.090 --> 00:38:13.010
Let me do that again.

00:38:13.010 --> 00:38:15.160
I'll make a note.

00:38:15.160 --> 00:38:17.500
Personally, I think
SPDY is important.

00:38:17.500 --> 00:38:20.710
You know, I kind of
helped invent it.

00:38:20.710 --> 00:38:21.960
So there you go.

00:38:28.260 --> 00:38:29.270
And that's all I have.

00:38:29.270 --> 00:38:31.420
I'll take questions
for two minutes.

00:38:31.420 --> 00:38:33.060
And I'll let somebody
else fill the time.

00:38:33.060 --> 00:38:34.534
Any questions?

00:38:34.534 --> 00:38:35.784
AUDIENCE: [INAUDIBLE]

00:38:52.812 --> 00:38:56.600
ROBERTO PEON: So one of the
things that's great about

00:38:56.600 --> 00:38:59.020
SPDY, is that you're guaranteed
that if anybody

00:38:59.020 --> 00:38:59.840
supports it.

00:38:59.840 --> 00:39:01.980
And actually, you can just
look at it from the NPN

00:39:01.980 --> 00:39:02.470
perspective.

00:39:02.470 --> 00:39:05.380
If anybody supports NPN, you
know they're a modern browser.

00:39:05.380 --> 00:39:12.060
You know that they do the TLS
thing that announces the name

00:39:12.060 --> 00:39:13.550
as part of the TLS handshake.

00:39:13.550 --> 00:39:14.800
AUDIENCE: [INAUDIBLE]

00:39:26.368 --> 00:39:27.400
ROBERTO PEON: You
don't have to.

00:39:27.400 --> 00:39:31.520
So if you don't have NPN in the
SSL extension it just ends

00:39:31.520 --> 00:39:32.760
up being HTTPS.

00:39:32.760 --> 00:39:34.135
So it's fully backwards
compatible.

00:39:34.135 --> 00:39:35.385
AUDIENCE: [INAUDIBLE]

00:39:50.571 --> 00:39:52.150
ROBERTO PEON: Right,
any other questions

00:39:52.150 --> 00:39:54.720
AUDIENCE: Why not
a SETP or a TCP?

00:39:54.720 --> 00:39:56.870
ROBERTO PEON: We
looked at that.

00:39:56.870 --> 00:40:00.180
SETP has some problems for
actual deployment.

00:40:00.180 --> 00:40:04.710
In particular, it deals very
poorly with NAT boxes.

00:40:04.710 --> 00:40:11.550
A lot of the things that we
designed for with SPDY were

00:40:11.550 --> 00:40:14.570
inspired by things like
SETP and [? Beep ?].

00:40:14.570 --> 00:40:16.720
AUDIENCE: But it gives you
multi-homing and high

00:40:16.720 --> 00:40:19.130
availability, which I think is
not there in SPDY right now.

00:40:19.130 --> 00:40:20.710
ROBERTO PEON: That's correct.

00:40:20.710 --> 00:40:22.490
It doesn't give us multi-path.

00:40:22.490 --> 00:40:25.510
Now, in reality, I haven't
actually seen SETP give us

00:40:25.510 --> 00:40:28.340
multi-path, either, though.

00:40:28.340 --> 00:40:29.840
I would really like for it to.

00:40:29.840 --> 00:40:32.570
It's just very difficult
to deploy for real.

00:40:32.570 --> 00:40:35.990
And in this case we're trying
to deliver something that we

00:40:35.990 --> 00:40:38.674
can deliver very widely.

00:40:38.674 --> 00:40:42.630
AUDIENCE: Specifically about the
congestion window caching.

00:40:42.630 --> 00:40:45.390
I know you guys online have
talked about the potential

00:40:45.390 --> 00:40:49.040
issues around forging that and
issues with the connection

00:40:49.040 --> 00:40:50.550
changing between requests.

00:40:50.550 --> 00:40:54.290
But I guess what hasn't been
clear to me, is the connection

00:40:54.290 --> 00:40:57.130
window sizing a requirement?

00:40:57.130 --> 00:40:59.880
If a browser sends it are you
required to start with the

00:40:59.880 --> 00:41:00.740
number they want?

00:41:00.740 --> 00:41:01.880
ROBERTO PEON: You are
not required.

00:41:01.880 --> 00:41:04.231
It is a hint.

00:41:04.231 --> 00:41:07.500
AUDIENCE: How does SPDY handle
termination of SSL at the load

00:41:07.500 --> 00:41:09.250
balancer if you have a hardware
load balancer that's

00:41:09.250 --> 00:41:10.750
passing to the back end?

00:41:10.750 --> 00:41:12.660
ROBERTO PEON: If you have a
hardware load balancer, and it

00:41:12.660 --> 00:41:15.260
doesn't support SPDY, you're not
going to be speaking SPDY.

00:41:15.260 --> 00:41:17.630
So the way it's going to be
handled is hopefully,

00:41:17.630 --> 00:41:19.920
eventually, many of
these vendors will

00:41:19.920 --> 00:41:20.870
be supporting SPDY.

00:41:20.870 --> 00:41:23.950
And having gone around and
talked to a number of them, I

00:41:23.950 --> 00:41:24.920
can't promise anything.

00:41:24.920 --> 00:41:26.160
I'm not the vendors.

00:41:26.160 --> 00:41:27.410
But it seems like there's
interest.

00:41:30.639 --> 00:41:34.025
AUDIENCE: How is the priority
defined for these?

00:41:34.025 --> 00:41:37.270
ROBERTO PEON: There's a bit
field that's in there.

00:41:37.270 --> 00:41:39.980
And basically the lower the
number in that bit field the

00:41:39.980 --> 00:41:41.440
higher the priority.

00:41:41.440 --> 00:41:42.840
Probably should have done it the
other way around because

00:41:42.840 --> 00:41:43.620
it gets confusing.

00:41:43.620 --> 00:41:44.870
But that's how it is.

00:41:47.980 --> 00:41:51.860
I know there are at least 16
different levels of priority.

00:41:51.860 --> 00:41:55.150
We might decide to change that
at any point in the future.

00:41:55.150 --> 00:41:56.420
But if we did it would
probably just

00:41:56.420 --> 00:41:57.670
be to increase it.

00:42:00.714 --> 00:42:03.040
All right, one last question
and then I'll yield.

00:42:03.040 --> 00:42:05.710
AUDIENCE: The other thing would
be is there any point to

00:42:05.710 --> 00:42:07.580
doing push versus inlining.

00:42:07.580 --> 00:42:10.760
Like, normally for HTTP you do
inlining so that you don't get

00:42:10.760 --> 00:42:11.560
the round trips.

00:42:11.560 --> 00:42:14.120
Is there any point to push with
SPDY since it's already

00:42:14.120 --> 00:42:16.170
doing that RTT compression?

00:42:16.170 --> 00:42:17.410
ROBERTO PEON: There is.

00:42:17.410 --> 00:42:19.820
Hopefully, you're optimizing
your site for the whole

00:42:19.820 --> 00:42:22.120
experience and not just
the first page load.

00:42:22.120 --> 00:42:24.760
So if all you're doing is the
first page load, you're right.

00:42:24.760 --> 00:42:26.870
So long as you get the inlining
right, which is

00:42:26.870 --> 00:42:29.160
another problem, so long as you
get it right, it's going

00:42:29.160 --> 00:42:30.770
to be basically the same
as ServerPush.

00:42:30.770 --> 00:42:32.410
If you get it wrong, it's not.

00:42:32.410 --> 00:42:35.370
If you have resources that could
have been cached, but

00:42:35.370 --> 00:42:37.430
aren't because data URLs don't
allow you to do anything like

00:42:37.430 --> 00:42:40.310
that, then ServerPush is going
to end up better the second

00:42:40.310 --> 00:42:42.620
page load even when they
come to it anew.

00:42:42.620 --> 00:42:47.090
And it's going to be better on
any portion of the session

00:42:47.090 --> 00:42:48.040
after that.

00:42:48.040 --> 00:42:51.005
Last question?

00:42:51.005 --> 00:42:54.660
AUDIENCE: For a scenario where
you have browsers which you

00:42:54.660 --> 00:42:58.480
can't really change, at least
not in a short amount of time

00:42:58.480 --> 00:43:03.390
like embedded systems, would a
scenario like a client side

00:43:03.390 --> 00:43:09.410
proxy of HTTP to SPDY actually
be worth it?

00:43:09.410 --> 00:43:12.200
ROBERTO PEON: Do you mean a
proxy from SPDY to HTTP?

00:43:12.200 --> 00:43:13.260
So SPDY on the client side?

00:43:13.260 --> 00:43:14.830
AUDIENCE: The other way
around actually.

00:43:14.830 --> 00:43:19.720
The browser does HTTP requests,
but they get out of

00:43:19.720 --> 00:43:21.670
the embedded equipment
in SPDY.

00:43:21.670 --> 00:43:22.600
ROBERTO PEON: Both can work.

00:43:22.600 --> 00:43:25.300
SPDY is going to be most
advantageous when it's used

00:43:25.300 --> 00:43:27.080
over the higher RTT link.

00:43:27.080 --> 00:43:31.000
So if you're speaking SPDY
directly to your server,

00:43:31.000 --> 00:43:32.740
because there's a load balancer
in front of it that's

00:43:32.740 --> 00:43:35.380
speaking SPDY to your server,
the benefits, in terms of

00:43:35.380 --> 00:43:37.040
latency, aren't going
to be there.

00:43:37.040 --> 00:43:41.680
But if that proxy is close to
the client, then you will see

00:43:41.680 --> 00:43:44.260
benefit hopefully.

00:43:44.260 --> 00:43:45.510
Thank you very much.

