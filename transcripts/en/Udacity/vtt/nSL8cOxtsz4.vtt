WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:03.320
A problem with adding more and more lights to a scene is the expense. Every

00:00:03.320 --> 00:00:06.660
light you add means yet another light that must be evaluated for the surface.

00:00:06.660 --> 00:00:10.160
One way around this is deferred rendering. Look at this demo. There are 50

00:00:10.160 --> 00:00:14.360
lights in the scene, and it runs just fine. Normally, you render a surface, and

00:00:14.360 --> 00:00:17.000
the fragment color for each pixel is stored, if it's the closest visible

00:00:17.000 --> 00:00:20.780
object. This is often called forward rendering. In a deferred rendering

00:00:20.780 --> 00:00:24.420
algorithm, you instead store data of some sort in each pixel. There are many

00:00:24.420 --> 00:00:28.052
variations, with names such as deferred shading versus deferred lighting. And

00:00:28.052 --> 00:00:31.479
here's just one. You could store the position, normal, and material color and

00:00:31.479 --> 00:00:35.590
shininess of the closest surface at each pixel. You also draw into the Z-buffer

00:00:35.590 --> 00:00:38.815
as usual. I'm not going to get into the details of how you store these various

00:00:38.815 --> 00:00:43.034
pieces of data, the point is that you can do so. It's just image data in

00:00:43.034 --> 00:00:46.424
another format. With deferred rendering every point light in the scene has an

00:00:46.424 --> 00:00:50.637
upper limit as to how far its light goes. This distance forms a sphere. So a

00:00:50.637 --> 00:00:54.688
sphere is drawn in a special way for each light. Another way of saying this is

00:00:54.688 --> 00:00:58.332
that each light can affect a volume in space. Whatever surfaces we find inside

00:00:58.332 --> 00:01:02.152
the sphere are affected by the light. Each light effects a fairly small number

00:01:02.152 --> 00:01:06.108
of pixels on the screen, namely whatever area the light sphere covers. This

00:01:06.108 --> 00:01:09.022
means that a huge number of lights with a limited radius can be evaluated in

00:01:09.022 --> 00:01:13.095
this way. By drawing a sphere, we're telling the GPU which pixels on the screen

00:01:13.095 --> 00:01:16.862
are covered by the light and so, should be evaluated. There are variants on

00:01:16.862 --> 00:01:20.420
what shapes you draw. A circle, a screen aligned rectangle. Whatever is drawn,

00:01:20.420 --> 00:01:23.420
the idea is that the geometry's purpose is to test only the limited set of

00:01:23.420 --> 00:01:27.690
pixels potentially in range of the light. This is as opposed to standard

00:01:27.690 --> 00:01:31.450
lights, where every light is evaluated for every surface at every pixel. I hope

00:01:31.450 --> 00:01:34.967
this give you a flavor of how deferred rendering works. I'm really jumping the

00:01:34.967 --> 00:01:38.034
gun, here. You need to know about shader programming to implement these. But

00:01:38.034 --> 00:01:41.058
the idea is to treat lights as objects that are rendered into the scene after

00:01:41.058 --> 00:01:44.944
all object surface values are recorded. There's some problem cases for

00:01:44.944 --> 00:01:47.804
preferred rendering techniques, such as transparency, but it offers a way to

00:01:47.804 --> 00:01:50.639
have an incredible number of lights in a scene.

