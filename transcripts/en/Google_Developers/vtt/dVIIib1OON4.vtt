WEBVTT
Kind: captions
Language: en

00:00:06.720 --> 00:00:09.130
CORINNA CORTES: I'm sorry
if I'm not too dressed up,

00:00:09.130 --> 00:00:11.950
but I was told that I could
just show up in my regular work

00:00:11.950 --> 00:00:14.740
clothing, so this is
actually how I often

00:00:14.740 --> 00:00:17.190
end up coming to work.

00:00:17.190 --> 00:00:22.240
So, yes, I've been here
for more than 10 years,

00:00:22.240 --> 00:00:24.780
and that means that
seniority-wise I'm

00:00:24.780 --> 00:00:28.080
in the 99.8 percentile
or something like that.

00:00:28.080 --> 00:00:30.730
When I started it was
actually a very small office

00:00:30.730 --> 00:00:32.180
in Times Square.

00:00:32.180 --> 00:00:36.880
So my plan the next-- I
thought I had 45 minutes.

00:00:36.880 --> 00:00:39.260
I didn't leave any time
for questions, by the way.

00:00:39.260 --> 00:00:41.860
I wasn't aware that you
had anything to say, right?

00:00:44.858 --> 00:00:46.910
But my idea was to
tell a little bit

00:00:46.910 --> 00:00:49.540
about how I ended
up in the tech world

00:00:49.540 --> 00:00:52.370
and give some examples of
work that are happening,

00:00:52.370 --> 00:00:54.000
is happening in my team.

00:00:54.000 --> 00:00:58.710
But maybe I should just ask
you a few questions first.

00:00:58.710 --> 00:01:01.817
How many of you-- show of
hands-- actually associated

00:01:01.817 --> 00:01:02.650
with the tech world?

00:01:02.650 --> 00:01:05.711
Students or professionals
or anything?

00:01:05.711 --> 00:01:06.210
Oh.

00:01:06.210 --> 00:01:08.060
That is almost everybody.

00:01:08.060 --> 00:01:10.280
How many are actually
students though?

00:01:10.280 --> 00:01:11.110
A good amount.

00:01:11.110 --> 00:01:13.920
A good amount.

00:01:13.920 --> 00:01:17.870
So two more questions.

00:01:17.870 --> 00:01:20.870
When you, a couple
of years ago, started

00:01:20.870 --> 00:01:23.920
telling friends and
family that you wanted

00:01:23.920 --> 00:01:29.400
to pursue a degree in science,
computer science, whatever,

00:01:29.400 --> 00:01:32.340
did you meet any objections?

00:01:32.340 --> 00:01:34.010
Show of hands.

00:01:34.010 --> 00:01:36.410
You did?

00:01:36.410 --> 00:01:38.080
Who told you anything?

00:01:38.080 --> 00:01:40.580
AUDIENCE: Well, because it's
not like a career like medicine

00:01:40.580 --> 00:01:42.780
or law that's known
to be successful.

00:01:42.780 --> 00:01:46.880
So it's kind of a new thing
that my family wasn't aware of.

00:01:46.880 --> 00:01:50.060
CORINNA CORTES: So they were
sort of reluctant about that?

00:01:50.060 --> 00:01:50.990
Yeah.

00:01:50.990 --> 00:01:53.470
OK, well, but fortunately
it wasn't too many

00:01:53.470 --> 00:01:55.470
here that had any objections.

00:01:55.470 --> 00:01:59.290
But inside yourself, how
did you feel about it?

00:01:59.290 --> 00:02:02.610
Did you think, I really don't
want really to be a nerd

00:02:02.610 --> 00:02:04.260
and be associated with all that?

00:02:04.260 --> 00:02:06.240
I don't want to
be the Amy Farrah

00:02:06.240 --> 00:02:09.690
Fowler in "Big Bang Theory."

00:02:09.690 --> 00:02:14.150
I mean, I wanted more
to be like Penny, right?

00:02:14.150 --> 00:02:17.220
Except for I wanted a degree.

00:02:17.220 --> 00:02:18.140
Yeah, OK.

00:02:18.140 --> 00:02:18.960
That's better.

00:02:18.960 --> 00:02:21.850
Let's be honest, right?

00:02:21.850 --> 00:02:23.710
My goodness, you
knew what you wanted.

00:02:23.710 --> 00:02:24.390
OK.

00:02:24.390 --> 00:02:28.830
Well, so I still think
that we have a little ways

00:02:28.830 --> 00:02:30.670
to go with this
perception of what

00:02:30.670 --> 00:02:33.010
is a woman in computer science.

00:02:33.010 --> 00:02:35.270
But we have come a
long way from that we

00:02:35.270 --> 00:02:38.290
don't get too much objections
to when we come and say

00:02:38.290 --> 00:02:40.410
we want to have a
degree in science.

00:02:40.410 --> 00:02:42.700
And I just want to
point out that it

00:02:42.700 --> 00:02:46.020
wasn't like that
about 60 years ago.

00:02:46.020 --> 00:02:48.490
Here we have a very proud woman.

00:02:48.490 --> 00:02:50.870
She looks very happy, and
she has all good reasons

00:02:50.870 --> 00:02:52.010
to be happy.

00:02:52.010 --> 00:02:55.010
She has a Ph.D. In agriculture.

00:02:55.010 --> 00:02:58.550
And at this point in her
life, she's in her mid-50s

00:02:58.550 --> 00:03:00.190
just like me.

00:03:00.190 --> 00:03:02.144
She has developed
a new wheat brand.

00:03:02.144 --> 00:03:03.560
I don't know if
you call it brand,

00:03:03.560 --> 00:03:07.220
but that is more robust
towards diseases.

00:03:07.220 --> 00:03:10.210
So it's less pesticides
in the ground.

00:03:10.210 --> 00:03:12.720
It's less fertilizers.

00:03:12.720 --> 00:03:14.490
And at this point of
time it was actually

00:03:14.490 --> 00:03:19.390
covering like 20% of the wheat
fields in northern Germany

00:03:19.390 --> 00:03:21.300
and Scandinavia.

00:03:21.300 --> 00:03:24.090
So very impressive career.

00:03:24.090 --> 00:03:27.240
What the picture doesn't
show is that she only

00:03:27.240 --> 00:03:30.500
got her Ph.D. five years before.

00:03:30.500 --> 00:03:31.200
OK.

00:03:31.200 --> 00:03:35.460
So when she was contemplating
going to university,

00:03:35.460 --> 00:03:38.880
she knew exactly what
she wanted to become.

00:03:38.880 --> 00:03:40.910
But her parents said,
no, no, no, no, no.

00:03:40.910 --> 00:03:45.810
A good girl like you don't go
into any science or technology

00:03:45.810 --> 00:03:46.840
like that.

00:03:46.840 --> 00:03:49.250
And it wasn't as
much that she would

00:03:49.250 --> 00:03:52.350
have to move to the big
city, because there wasn't

00:03:52.350 --> 00:03:54.640
a technical university
where she lived.

00:03:54.640 --> 00:03:57.390
Because they did send
her to the big city

00:03:57.390 --> 00:04:02.700
to teach her housekeeping and
cooking and all these things.

00:04:02.700 --> 00:04:06.570
And it wasn't that her
family wasn't well-educated.

00:04:06.570 --> 00:04:09.700
Her father was a civil
engineer, and her older brother

00:04:09.700 --> 00:04:12.710
had been sent to the technical
university in the big city just

00:04:12.710 --> 00:04:13.830
three years before.

00:04:13.830 --> 00:04:17.790
It was simply that a nice
girl shouldn't get a degree

00:04:17.790 --> 00:04:21.410
in any kind of
science or technology.

00:04:21.410 --> 00:04:22.920
So what did she do?

00:04:22.920 --> 00:04:24.950
Well, she became a
kindergarten teacher,

00:04:24.950 --> 00:04:27.732
and I benefited a lot from that.

00:04:27.732 --> 00:04:28.440
That's my mother.

00:04:32.150 --> 00:04:33.440
Yeah.

00:04:33.440 --> 00:04:38.690
So as time passed, it happened
that we moved to the big city,

00:04:38.690 --> 00:04:43.440
and when my older sister started
contemplating going to school,

00:04:43.440 --> 00:04:45.894
going to the university,
my mother sort of

00:04:45.894 --> 00:04:47.130
got back to this.

00:04:47.130 --> 00:04:49.220
And one day she
came home and said,

00:04:49.220 --> 00:04:51.680
I'm going to brush up on
my math, and my physics,

00:04:51.680 --> 00:04:54.270
and my chemistry, and I'm
going to go to school.

00:04:54.270 --> 00:04:57.490
So when she was 44, something
like that, she enrolled,

00:04:57.490 --> 00:05:02.170
and she got her Ph.D. and
obviously was very successful.

00:05:02.170 --> 00:05:07.105
So that has always been a
good inspiration for me.

00:05:07.105 --> 00:05:09.730
And you would think
then with a background

00:05:09.730 --> 00:05:13.880
like that, my own
career-- simple, right?

00:05:13.880 --> 00:05:15.710
I was also good in
math and physics

00:05:15.710 --> 00:05:20.080
in school, so why not just go
to the university and study it?

00:05:20.080 --> 00:05:21.920
No, no, no, no, no, no, no.

00:05:21.920 --> 00:05:25.062
We found something much more
effective than these parents

00:05:25.062 --> 00:05:26.770
telling us what to do
and what not to do,

00:05:26.770 --> 00:05:30.360
and that's the peer pressure
that I believe is around.

00:05:30.360 --> 00:05:32.800
We don't want to go
into these degrees.

00:05:32.800 --> 00:05:36.900
So here you have me
when I was 17 or 18.

00:05:36.900 --> 00:05:40.800
Do I look as somebody who wants
to go in and study physics?

00:05:40.800 --> 00:05:41.300
No.

00:05:41.300 --> 00:05:43.190
No, no, no, no, no.

00:05:43.190 --> 00:05:45.050
No.

00:05:45.050 --> 00:05:48.370
I wanted to do something where
the boys wouldn't be running

00:05:48.370 --> 00:05:51.320
away if I met them in a bar,
and I said I'm studying physics,

00:05:51.320 --> 00:05:52.080
right?

00:05:52.080 --> 00:05:55.780
So I went for something
innocent-- theology.

00:05:55.780 --> 00:06:00.030
Now don't-- it's not as
bad as you think actually,

00:06:00.030 --> 00:06:02.430
because in Denmark we
have a state religion.

00:06:02.430 --> 00:06:06.810
So studying theology
is not that uncommon.

00:06:06.810 --> 00:06:09.180
But I did realize
after some months

00:06:09.180 --> 00:06:11.950
that I was probably heading
to become a priest then.

00:06:11.950 --> 00:06:15.100
Maybe that was not the
career call for me though.

00:06:15.100 --> 00:06:17.580
In retrospect, I must
say, that being a manager

00:06:17.580 --> 00:06:19.520
or being a priest,
I don't really

00:06:19.520 --> 00:06:21.270
know if there's that
much of a difference.

00:06:21.270 --> 00:06:21.770
Right?

00:06:21.770 --> 00:06:23.700
It's all about
guiding lost souls.

00:06:28.230 --> 00:06:31.740
So I changed.

00:06:31.740 --> 00:06:32.240
OK.

00:06:32.240 --> 00:06:33.115
I went to literature.

00:06:33.115 --> 00:06:34.380
Still very innocent.

00:06:34.380 --> 00:06:37.395
I can walk up to any boy and
say, I'm studying literature.

00:06:37.395 --> 00:06:38.584
Right?

00:06:38.584 --> 00:06:40.610
And he'd say, oh, very nice.

00:06:40.610 --> 00:06:42.540
Right?

00:06:42.540 --> 00:06:45.990
I wasn't happy there either.

00:06:45.990 --> 00:06:49.050
Fortunately, I was
short on money.

00:06:49.050 --> 00:06:50.360
All students are.

00:06:50.360 --> 00:06:55.180
So in January just like here,
in Denmark, the universities

00:06:55.180 --> 00:06:57.860
they are closed, and I went
to the student job center

00:06:57.860 --> 00:06:58.980
to get a job.

00:06:58.980 --> 00:07:00.760
Now we're talking
the early 80s, so I

00:07:00.760 --> 00:07:02.520
thought it was
really, really cool

00:07:02.520 --> 00:07:04.460
to get a job at a conveyor belt.

00:07:04.460 --> 00:07:04.960
Right?

00:07:04.960 --> 00:07:07.820
I had to feel what the
working class was all about.

00:07:07.820 --> 00:07:08.360
Right?

00:07:08.360 --> 00:07:11.700
So I got this job, and
I had to adjust engines

00:07:11.700 --> 00:07:15.740
for vacuum cleaners
for eight hours a day.

00:07:15.740 --> 00:07:19.580
The other students that
have picked the same job,

00:07:19.580 --> 00:07:21.250
they were actually
engineering students.

00:07:21.250 --> 00:07:24.289
And I discovered they
were really, really nice.

00:07:24.289 --> 00:07:26.830
I could actually go out and have
a beer with them afterwards,

00:07:26.830 --> 00:07:29.060
and they arranged ski trips.

00:07:29.060 --> 00:07:31.980
If you go to their parties,
also, you're the only girl,

00:07:31.980 --> 00:07:34.910
and there are all
these nice girls.

00:07:34.910 --> 00:07:36.620
That's a benefit.

00:07:36.620 --> 00:07:40.460
So finally after
a lot of detours,

00:07:40.460 --> 00:07:46.900
I ended up studying physics and
later math, computer science,

00:07:46.900 --> 00:07:50.330
and that's how I ended
up in this field.

00:07:50.330 --> 00:07:52.000
But it was a detour
of about two,

00:07:52.000 --> 00:07:54.540
three years before
I dared actually

00:07:54.540 --> 00:07:58.410
go in and pursue the degree
that I really wanted to get.

00:07:58.410 --> 00:08:02.190
So I made it through
graduate life, and just

00:08:02.190 --> 00:08:05.240
my five pieces of advice.

00:08:05.240 --> 00:08:08.140
There's probably way too many.

00:08:08.140 --> 00:08:10.510
For the ones that
are still students,

00:08:10.510 --> 00:08:12.470
get the most out of
your graduate time.

00:08:12.470 --> 00:08:14.710
And I mean on the
technical side, right?

00:08:14.710 --> 00:08:18.300
Nowadays, particularly, they
try to stuff all kinds of fluff

00:08:18.300 --> 00:08:22.980
into the computer science degree
to make it more attractive.

00:08:22.980 --> 00:08:27.960
At least if you want
to get a job at Google,

00:08:27.960 --> 00:08:29.710
not that you necessarily--
but in general,

00:08:29.710 --> 00:08:31.210
if you want to
get a job, I think

00:08:31.210 --> 00:08:34.179
it's important that you learn
as many core skills as possible

00:08:34.179 --> 00:08:36.020
while you are in school.

00:08:36.020 --> 00:08:39.179
Don't specialize too much
so you cannot easily adapt

00:08:39.179 --> 00:08:39.970
to something else.

00:08:39.970 --> 00:08:40.610
Right?

00:08:40.610 --> 00:08:43.150
Take all your programming,
the algorithms,

00:08:43.150 --> 00:08:46.350
the kind of hard
courses, data structures.

00:08:46.350 --> 00:08:48.260
It will pay off.

00:08:48.260 --> 00:08:50.270
No matter where you want
to go in the future.

00:08:50.270 --> 00:08:50.770
Right?

00:08:50.770 --> 00:08:56.714
You will have the foundation
to really get a good job.

00:08:56.714 --> 00:08:58.380
Publish while you're
in graduate school.

00:08:58.380 --> 00:09:01.260
I learned that
too late, I think.

00:09:01.260 --> 00:09:03.070
But when you want
to apply for a job,

00:09:03.070 --> 00:09:05.610
it's really good to have
a couple of publications

00:09:05.610 --> 00:09:06.690
on your resume.

00:09:06.690 --> 00:09:11.460
And it also makes writing
the thesis much, much easier.

00:09:11.460 --> 00:09:14.610
You could write it around
a few publications.

00:09:14.610 --> 00:09:16.090
Don't drag it out.

00:09:16.090 --> 00:09:19.180
Ask your advisor to sit down
with you and make a plan,

00:09:19.180 --> 00:09:22.430
because writing that thesis,
it's not that big a deal.

00:09:22.430 --> 00:09:22.930
Right?

00:09:22.930 --> 00:09:25.050
We all think that this
is going, oh, no, no, no.

00:09:25.050 --> 00:09:26.260
We're never going
to get through it.

00:09:26.260 --> 00:09:27.843
But it really isn't,
especially if you

00:09:27.843 --> 00:09:31.830
have a couple of publications,
so you kind of staged it.

00:09:31.830 --> 00:09:32.640
Be competitive.

00:09:32.640 --> 00:09:34.930
Get all the As that
you can, but try

00:09:34.930 --> 00:09:39.740
to be good friends also
with-- leverage of each other.

00:09:39.740 --> 00:09:45.390
Make good use of the other
students, especially the girls,

00:09:45.390 --> 00:09:47.700
I found, It's kind of
strange, because now

00:09:47.700 --> 00:09:51.110
in my professional
life, I get so much

00:09:51.110 --> 00:09:53.870
out of interacting
with the other women,

00:09:53.870 --> 00:09:56.830
but I found in graduate
school, we were just competing,

00:09:56.830 --> 00:10:00.030
and we were kind of being
nasty against each other.

00:10:00.030 --> 00:10:02.880
It's really a pity
to somehow try

00:10:02.880 --> 00:10:07.490
to be good friends, especially
with your female classmates.

00:10:07.490 --> 00:10:09.150
Keep a hobby.

00:10:09.150 --> 00:10:11.970
Don't make your hobby
into your profession.

00:10:11.970 --> 00:10:13.930
That was one advice
I was once given.

00:10:13.930 --> 00:10:15.140
I have a hobby.

00:10:15.140 --> 00:10:17.060
I run.

00:10:17.060 --> 00:10:18.980
And that's the
way I keep saying.

00:10:18.980 --> 00:10:19.850
Right?

00:10:19.850 --> 00:10:21.960
I've been out doing
22 miles this morning.

00:10:21.960 --> 00:10:24.260
That's why I look like this.

00:10:24.260 --> 00:10:25.720
I wouldn't miss it.

00:10:25.720 --> 00:10:29.150
I meet with my other
girlfriends at 7 o'clock

00:10:29.150 --> 00:10:32.720
up in Central Park,
and we run around.

00:10:32.720 --> 00:10:36.180
I do it every
Saturday, also today.

00:10:36.180 --> 00:10:37.280
The family thing, right?

00:10:37.280 --> 00:10:37.850
It's hard.

00:10:37.850 --> 00:10:40.130
There's never a good time.

00:10:40.130 --> 00:10:43.650
So my mother told me, my good
old mother that's otherwise

00:10:43.650 --> 00:10:49.260
a fine woman, she said, you
first have to get a degree.

00:10:49.260 --> 00:10:51.090
You have to get a
job, and then you

00:10:51.090 --> 00:10:52.320
get a man and your children.

00:10:55.290 --> 00:10:56.280
I don't know.

00:10:56.280 --> 00:10:58.040
There's never a good time.

00:10:58.040 --> 00:11:02.520
I would say don't put it
off too much, because it's

00:11:02.520 --> 00:11:04.310
kind of hard to have children.

00:11:04.310 --> 00:11:06.390
It's a lot of work, right?

00:11:06.390 --> 00:11:09.080
And the older we get, the
more tired we actually get.

00:11:11.690 --> 00:11:16.500
So I would rather have started
a little earlier, I think.

00:11:16.500 --> 00:11:19.870
And then, you know, if you don't
like the education you're in,

00:11:19.870 --> 00:11:21.700
change.

00:11:21.700 --> 00:11:22.677
Don't stick with it.

00:11:22.677 --> 00:11:24.260
You're going to have
to live with this

00:11:24.260 --> 00:11:25.900
the rest of your life.

00:11:25.900 --> 00:11:27.980
Just get out, and change.

00:11:27.980 --> 00:11:29.180
Don't be shy about it.

00:11:29.180 --> 00:11:31.901
Say it's not fit for me.

00:11:31.901 --> 00:11:34.150
I definitely did that a
couple of times, and my mother

00:11:34.150 --> 00:11:35.400
had to do it.

00:11:35.400 --> 00:11:39.700
Afterwards, find a job
that's right for you.

00:11:39.700 --> 00:11:43.310
I see a lot of
students coming out,

00:11:43.310 --> 00:11:45.170
and they think
maybe that academia,

00:11:45.170 --> 00:11:46.620
that's the golden standard.

00:11:46.620 --> 00:11:47.250
Right?

00:11:47.250 --> 00:11:48.666
That's where we
should be heading.

00:11:48.666 --> 00:11:50.030
We shouldn't go into industry.

00:11:50.030 --> 00:11:53.430
But in reality, they don't
like to stand in front of--

00:11:53.430 --> 00:11:55.040
and they don't like to teach.

00:11:55.040 --> 00:11:58.030
They don't like to be up in
the spotlight all the time.

00:11:58.030 --> 00:12:01.350
And the sweat is sort
of howling from them.

00:12:01.350 --> 00:12:04.290
But academia, that's
where I should be.

00:12:04.290 --> 00:12:05.720
Find what's good for you.

00:12:05.720 --> 00:12:08.662
If you work best
in small groups,

00:12:08.662 --> 00:12:11.625
then there are plenty of
other options for you.

00:12:11.625 --> 00:12:14.730
Google is one great place.

00:12:14.730 --> 00:12:17.254
They got to have to stop
pitching this place.

00:12:17.254 --> 00:12:19.670
I really think it's a nice
place, because we work together

00:12:19.670 --> 00:12:20.980
in small groups.

00:12:20.980 --> 00:12:25.360
And really what counts is
the technical abilities

00:12:25.360 --> 00:12:26.420
of what you're doing.

00:12:26.420 --> 00:12:28.940
You don't have to
be the one who brags

00:12:28.940 --> 00:12:31.070
about how wonderful
your worker is.

00:12:31.070 --> 00:12:34.520
It's simply, if it works,
then you have a say.

00:12:34.520 --> 00:12:39.260
So there are many ways you can
have your professional life.

00:12:39.260 --> 00:12:42.840
Don't do something that
you're not happy in.

00:12:42.840 --> 00:12:47.080
Always keep in mind, what is
it I want to leave behind?

00:12:47.080 --> 00:12:49.660
Because there's a tendency
that we fall into these local

00:12:49.660 --> 00:12:50.160
minimas.

00:12:50.160 --> 00:12:50.659
Right?

00:12:50.659 --> 00:12:52.590
Where we just go along.

00:12:52.590 --> 00:12:54.880
But sometimes you should
just stop and say,

00:12:54.880 --> 00:12:59.880
what is it I would like
to leave behind when I go?

00:12:59.880 --> 00:13:01.570
Is it a couple of good papers?

00:13:01.570 --> 00:13:04.170
Is it-- I mean, on
a technical side.

00:13:04.170 --> 00:13:08.050
Let's take the other things at
a different-- think about it,

00:13:08.050 --> 00:13:09.050
and work towards.

00:13:09.050 --> 00:13:10.170
Don't forget it.

00:13:10.170 --> 00:13:13.510
Because otherwise we
tend to just flatten out.

00:13:13.510 --> 00:13:19.460
And again, if you're not
happy in your job, change job.

00:13:19.460 --> 00:13:20.350
It's not that bad.

00:13:20.350 --> 00:13:23.660
You go into Humanities
and you say, I'm changing.

00:13:23.660 --> 00:13:27.570
And he won't kill you.

00:13:27.570 --> 00:13:30.620
We tend to get stuck, and
that's kind of a pity.

00:13:30.620 --> 00:13:33.820
So enough of my
pointed fingers here.

00:13:33.820 --> 00:13:37.390
I'd like to just spend a
little bit of time telling you

00:13:37.390 --> 00:13:39.790
about some of the great things
that the people on my team

00:13:39.790 --> 00:13:40.723
are doing.

00:13:40.723 --> 00:13:44.250
I don't do all the work.

00:13:44.250 --> 00:13:48.440
So I'm heading the research
group here in New York.

00:13:48.440 --> 00:13:51.474
And we have-- it's like a little
computer science department

00:13:51.474 --> 00:13:52.890
except we don't
have the products,

00:13:52.890 --> 00:13:55.530
and we don't have a whole lot
of the theoretical complexity

00:13:55.530 --> 00:13:59.370
hierarchies and
things like that.

00:13:59.370 --> 00:14:01.180
I definitely have a
lot of computer vision,

00:14:01.180 --> 00:14:03.610
and I'd like to start out by
showing you some of the work

00:14:03.610 --> 00:14:05.420
that we've done in
computer vision.

00:14:05.420 --> 00:14:11.520
And let's start out
with a visualiz-- nah,

00:14:11.520 --> 00:14:13.260
let's first go back
and do something.

00:14:13.260 --> 00:14:13.800
OK?

00:14:13.800 --> 00:14:17.250
We're going to take the
picture here of my mother.

00:14:17.250 --> 00:14:23.160
And we're going to
save it on the desktop.

00:14:23.160 --> 00:14:23.930
Good.

00:14:23.930 --> 00:14:25.400
All right.

00:14:25.400 --> 00:14:28.560
And now we're going to
go to this application.

00:14:28.560 --> 00:14:32.030
It's called Visually
Similar Images,

00:14:32.030 --> 00:14:34.410
and you probably
all Image Search.

00:14:34.410 --> 00:14:36.600
This is a good old
Google Image Search

00:14:36.600 --> 00:14:40.110
as we have come to live
and love it for many years.

00:14:40.110 --> 00:14:43.060
But you may have noticed up here
that there's a little camera.

00:14:43.060 --> 00:14:43.780
Right?

00:14:43.780 --> 00:14:46.780
So you can actually
do search by image.

00:14:46.780 --> 00:14:47.660
OK?

00:14:47.660 --> 00:14:50.360
So upload an image.

00:14:50.360 --> 00:14:53.040
Now choose the file,
and I would believe now

00:14:53.040 --> 00:14:55.410
that image-- here is it.

00:14:55.410 --> 00:14:56.410
OK.

00:14:56.410 --> 00:14:57.260
All right.

00:14:57.260 --> 00:15:00.340
So this one is definitely
not in the index.

00:15:00.340 --> 00:15:00.970
Right?

00:15:00.970 --> 00:15:03.030
Because we just created it.

00:15:03.030 --> 00:15:04.540
So we're going to open.

00:15:04.540 --> 00:15:08.380
We're uploading the
file, and look at that.

00:15:08.380 --> 00:15:08.960
Right.

00:15:08.960 --> 00:15:14.900
In real time, we get actually
very good images, I would say.

00:15:14.900 --> 00:15:17.570
Very similar images,
and look at here.

00:15:17.570 --> 00:15:18.070
Right?

00:15:18.070 --> 00:15:19.340
So this is not cheating.

00:15:19.340 --> 00:15:19.890
Right?

00:15:19.890 --> 00:15:23.900
Wheat, if I say that
I also want that,

00:15:23.900 --> 00:15:26.290
I mean you couldn't ask
to get it much better.

00:15:26.290 --> 00:15:28.624
Right?

00:15:28.624 --> 00:15:29.490
Look here.

00:15:29.490 --> 00:15:31.530
Another person standing
in a wheat field.

00:15:31.530 --> 00:15:33.360
Right?

00:15:33.360 --> 00:15:36.600
Many people standing
in a wheat field.

00:15:36.600 --> 00:15:37.560
Look at this one.

00:15:37.560 --> 00:15:41.800
She's even better-looking,
almost, than my mother.

00:15:41.800 --> 00:15:42.740
All right.

00:15:42.740 --> 00:15:45.700
And just so that you think
that I'm not cheating,

00:15:45.700 --> 00:15:47.440
let's see here.

00:15:47.440 --> 00:15:48.200
No, that's moment.

00:15:48.200 --> 00:15:49.570
That's not really
where we want to be.

00:15:49.570 --> 00:15:51.450
That's how I enter it,
so let's just go too.

00:15:55.620 --> 00:15:58.400
Google-- I just want
to show that we're not

00:15:58.400 --> 00:16:02.540
cheating, because if I had
gone here, and I said, "wheat,"

00:16:02.540 --> 00:16:05.750
I would get something
completely different.

00:16:05.750 --> 00:16:09.380
So it actually made use
of the image and the text

00:16:09.380 --> 00:16:12.840
that I gave with the image,
and it did a special search

00:16:12.840 --> 00:16:14.480
that was different
from just going

00:16:14.480 --> 00:16:19.330
to Image Search with
the word "wheat."

00:16:19.330 --> 00:16:22.370
I think I just lost
my presentation.

00:16:22.370 --> 00:16:23.970
That's OK.

00:16:23.970 --> 00:16:24.510
That's OK.

00:16:24.510 --> 00:16:27.172
I can find it again.

00:16:27.172 --> 00:16:29.390
I can find it again.

00:16:29.390 --> 00:16:30.910
I'm sure I can find it again.

00:16:33.800 --> 00:16:35.050
I did a mistake.

00:16:35.050 --> 00:16:40.090
I shouldn't have done
it like that, but so.

00:16:40.090 --> 00:16:40.700
All right.

00:16:40.700 --> 00:16:43.710
So how do we do it?

00:16:43.710 --> 00:16:47.390
Just through-- we should
go back also here.

00:16:47.390 --> 00:16:50.560
I have to do a little
adjustment like this.

00:16:50.560 --> 00:16:55.480
Let's spend three minutes
building an image browser

00:16:55.480 --> 00:16:57.440
together.

00:16:57.440 --> 00:16:59.850
Now the first thing
that we would need

00:16:59.850 --> 00:17:04.069
is, of course, a similarity
matrix between two images.

00:17:04.069 --> 00:17:04.619
Right?

00:17:04.619 --> 00:17:09.500
We'll represent the images
by say, some vectors, right?

00:17:09.500 --> 00:17:12.560
And this is not just going to be
a vector of the pixel elements

00:17:12.560 --> 00:17:14.700
in the image, because
that's not very robust.

00:17:14.700 --> 00:17:16.859
If I rescale the
image, then the vectors

00:17:16.859 --> 00:17:18.359
have a different length.

00:17:18.359 --> 00:17:20.579
Computer science, the
computer vision people,

00:17:20.579 --> 00:17:23.690
they're very good at coming up
with good image descriptors.

00:17:23.690 --> 00:17:26.500
They're called sift features,
and all these things.

00:17:26.500 --> 00:17:30.060
So let's imagine that we
have two images that we want

00:17:30.060 --> 00:17:33.380
to have the similarity between,
and these computer vision

00:17:33.380 --> 00:17:35.310
people, they've given
us a number of features.

00:17:35.310 --> 00:17:37.060
We are extracting
them from the images,

00:17:37.060 --> 00:17:40.480
and for simplicity, let's just
say that the similarity, that's

00:17:40.480 --> 00:17:43.110
the inner product
between these two images.

00:17:43.110 --> 00:17:45.690
The vectors representing
these two images.

00:17:45.690 --> 00:17:48.100
We're projecting one
vector down on the other.

00:17:48.100 --> 00:17:51.920
And the more they're aligned,
the more the similarity is.

00:17:51.920 --> 00:17:56.560
Let's now say that we want
to build image collection

00:17:56.560 --> 00:18:01.360
for the query, New York.

00:18:01.360 --> 00:18:02.290
What would we do?

00:18:02.290 --> 00:18:05.570
Well, we would probably say, OK.

00:18:05.570 --> 00:18:07.760
We'll go to the information
retrieval people,

00:18:07.760 --> 00:18:11.310
and they'll tell us, if you
want images for New York,

00:18:11.310 --> 00:18:13.790
why don't you scrape
all the pages that

00:18:13.790 --> 00:18:17.110
contain the word "New York"
and have images on it.

00:18:17.110 --> 00:18:19.800
Probably those images
on those pages,

00:18:19.800 --> 00:18:21.650
since the page
mentioned New York,

00:18:21.650 --> 00:18:23.630
the images are
relevant for New York.

00:18:23.630 --> 00:18:24.160
Right?

00:18:24.160 --> 00:18:29.410
So we'll take maybe, say
10,000 images that we've

00:18:29.410 --> 00:18:33.080
found on pages that mention
New York, and we can do,

00:18:33.080 --> 00:18:34.620
we can extract the features.

00:18:34.620 --> 00:18:36.630
We'll do the inner product.

00:18:36.630 --> 00:18:38.380
We'll find all
these similarities

00:18:38.380 --> 00:18:41.260
between the thousands
and thousands of images,

00:18:41.260 --> 00:18:43.780
and then we can build
our clustering tree.

00:18:43.780 --> 00:18:45.260
We'll build them bottom up.

00:18:45.260 --> 00:18:47.610
We'll say the ones that
are the most similar,

00:18:47.610 --> 00:18:51.520
we'll cluster together, and
then we'll build it forward up,

00:18:51.520 --> 00:18:53.640
and we'll get this
cluster tree, and then

00:18:53.640 --> 00:18:57.310
if somebody wants to do
a search for New York,

00:18:57.310 --> 00:19:00.870
well, what we can do is we
can cut the clustering tree

00:19:00.870 --> 00:19:02.110
at some kind of level.

00:19:02.110 --> 00:19:02.610
Right?

00:19:02.610 --> 00:19:05.530
So we have maybe,
I hate when I don't

00:19:05.530 --> 00:19:06.900
have the screen in front of me.

00:19:06.900 --> 00:19:09.640
So say that we cut
it about here, right?

00:19:09.640 --> 00:19:14.400
And we present back to
the user these clusters

00:19:14.400 --> 00:19:18.260
of images representing
different aspects of New York.

00:19:18.260 --> 00:19:20.540
And that was
exactly what we did.

00:19:20.540 --> 00:19:21.110
Right?

00:19:21.110 --> 00:19:23.840
The first similar
images is this one,

00:19:23.840 --> 00:19:26.120
and you're going
to see something

00:19:26.120 --> 00:19:28.080
that used to be out
there, but now it

00:19:28.080 --> 00:19:30.650
only exists inside
the Google firewall.

00:19:30.650 --> 00:19:33.220
Here we have what was
called Image Swirl,

00:19:33.220 --> 00:19:35.140
and we have put in
the query New York,

00:19:35.140 --> 00:19:37.230
and then you could go
down here, and you'll

00:19:37.230 --> 00:19:39.330
get these clusters
of images, and you

00:19:39.330 --> 00:19:43.560
could continue down
and play with it.

00:19:43.560 --> 00:19:46.590
So here, give me a query.

00:19:46.590 --> 00:19:50.050
Which image cluster
would you like to see?

00:19:50.050 --> 00:19:50.800
AUDIENCE: Bridges.

00:19:50.800 --> 00:19:51.800
CORINNA CORTES: Bridges.

00:19:54.240 --> 00:19:56.400
OK.

00:19:56.400 --> 00:19:58.441
Bridges.

00:19:58.441 --> 00:19:58.940
OK.

00:20:04.840 --> 00:20:05.560
All right.

00:20:05.560 --> 00:20:07.480
I'm sure that this
woman, actually her name

00:20:07.480 --> 00:20:09.970
is probably something
with Bridges, right?

00:20:09.970 --> 00:20:13.600
I would think so.

00:20:13.600 --> 00:20:15.110
Otherwise, it makes sense.

00:20:15.110 --> 00:20:18.151
But this is a silly thing.

00:20:18.151 --> 00:20:18.650
Right?

00:20:18.650 --> 00:20:20.066
Computer are pretty
stupid, right?

00:20:20.066 --> 00:20:22.320
Because they take the
word very literally.

00:20:22.320 --> 00:20:25.060
I'm sure that her
name is Bridges.

00:20:25.060 --> 00:20:26.890
Do we know who she is?

00:20:26.890 --> 00:20:27.495
AUDIENCE: No.

00:20:27.495 --> 00:20:28.036
AUDIENCE: No.

00:20:31.235 --> 00:20:32.860
CORINNA CORTES: I'm
pretty sure there's

00:20:32.860 --> 00:20:37.219
a very logical
explanation for this.

00:20:37.219 --> 00:20:38.260
Google is not very smart.

00:20:38.260 --> 00:20:40.680
But one thing you
see here, if we

00:20:40.680 --> 00:20:48.110
type in "international
women's--" OK.

00:20:48.110 --> 00:20:50.590
Sorry this query is not
included in your demo.

00:20:50.590 --> 00:20:58.820
So the problem here is that
the first similar images

00:20:58.820 --> 00:21:03.280
we constructed, it
was all pre-computed.

00:21:03.280 --> 00:21:05.970
Why did it have to
be pre-computed?

00:21:05.970 --> 00:21:08.830
Well, think of the process
that I outlined for you

00:21:08.830 --> 00:21:11.940
that we were actually doing
in order to create this.

00:21:11.940 --> 00:21:16.170
We would execute a query,
go out and get 10,000 pages

00:21:16.170 --> 00:21:20.260
with images, pages that
contain this query word.

00:21:20.260 --> 00:21:23.790
We'll extract the images,
we'll form the feature vectors.

00:21:23.790 --> 00:21:27.560
So say we now have 10,000
images over feature vectors,

00:21:27.560 --> 00:21:31.100
we'll have to compute all
the [INAUDIBLE] similarities.

00:21:31.100 --> 00:21:32.930
That's 10,000 by 10,000.

00:21:32.930 --> 00:21:36.300
I think it gets something like
100 million inner products

00:21:36.300 --> 00:21:37.270
we have to form.

00:21:37.270 --> 00:21:40.750
Built the clustering, cut
it, and present it back

00:21:40.750 --> 00:21:41.780
in web time.

00:21:41.780 --> 00:21:44.870
And web time is how much?

00:21:44.870 --> 00:21:45.790
Less than a second.

00:21:45.790 --> 00:21:46.290
Right?

00:21:46.290 --> 00:21:48.176
200 milliseconds.

00:21:48.176 --> 00:21:50.050
Google has a lot of
resources, but we

00:21:50.050 --> 00:21:51.980
don't have that many resources.

00:21:51.980 --> 00:21:54.950
So we had to do something,
and that was to pre-compute.

00:21:54.950 --> 00:22:00.682
So Image Swirl was only working
for the top 20,000 queries.

00:22:00.682 --> 00:22:03.590
But we want to do something
that is broader than that.

00:22:03.590 --> 00:22:07.655
So we had to find
something smarter.

00:22:07.655 --> 00:22:11.460
And now I again done
something stupid,

00:22:11.460 --> 00:22:15.170
so I have to go
back and find my--

00:22:15.170 --> 00:22:17.990
I've got to stop doing
this stupid thing where--

00:22:17.990 --> 00:22:21.490
because I actually know
how to avoid doing it.

00:22:21.490 --> 00:22:24.360
We had to do something
smarter, and what we do instead

00:22:24.360 --> 00:22:25.951
is that we cheat.

00:22:25.951 --> 00:22:26.450
No.

00:22:26.450 --> 00:22:28.399
It's not called
cheating in this world.

00:22:28.399 --> 00:22:29.565
It's called, we approximate.

00:22:32.660 --> 00:22:34.360
All right.

00:22:34.360 --> 00:22:37.940
So what do we do?

00:22:37.940 --> 00:22:39.290
We stayed out.

00:22:39.290 --> 00:22:43.260
We built the clustering to kind
of top down instead of bottom

00:22:43.260 --> 00:22:44.060
up, right?

00:22:44.060 --> 00:22:47.550
We first take all the
images that we can find out

00:22:47.550 --> 00:22:52.120
on the web, and we extract
these feature vectors for them.

00:22:52.120 --> 00:22:53.520
Make them very short.

00:22:53.520 --> 00:22:57.300
We don't want to spend too much
time on taking inner products.

00:22:57.300 --> 00:23:02.120
And then we randomly
take some direction

00:23:02.120 --> 00:23:04.720
in this space of
feature vectors.

00:23:04.720 --> 00:23:05.260
Right?

00:23:05.260 --> 00:23:08.290
And we project down
on that direction.

00:23:08.290 --> 00:23:11.259
Do you fall on this side of it,
or do you fall on that side?

00:23:11.259 --> 00:23:13.800
So the images that fall on this
side, they go down that path,

00:23:13.800 --> 00:23:16.080
and the images on the other
side go down that path.

00:23:16.080 --> 00:23:19.410
And we continue growing
the tree top down

00:23:19.410 --> 00:23:22.630
until we have a couple
of thousand nodes down

00:23:22.630 --> 00:23:24.520
at the bottom.

00:23:24.520 --> 00:23:28.260
And with each image, we
save the ID off the node

00:23:28.260 --> 00:23:30.360
that it ended up in.

00:23:30.360 --> 00:23:33.570
Actually each image, we cheat
a little bit also there.

00:23:33.570 --> 00:23:34.070
Right?

00:23:34.070 --> 00:23:36.930
Because if you're very close
to the boundary at some point

00:23:36.930 --> 00:23:39.380
in time, we don't want you
just to go down on that side,

00:23:39.380 --> 00:23:41.030
and we would never
find you there.

00:23:41.030 --> 00:23:44.030
So we spill a little
bit, so every image

00:23:44.030 --> 00:23:47.530
ends up being in
about five nodes.

00:23:47.530 --> 00:23:49.780
So what do we do at query time?

00:23:49.780 --> 00:23:53.020
Well, we take the
query image, the one

00:23:53.020 --> 00:23:57.130
that I uploaded of my mother,
and we extract the feature

00:23:57.130 --> 00:24:03.210
vector for that query image, and
then we send it down the tree.

00:24:03.210 --> 00:24:05.050
Now it's down in some node.

00:24:05.050 --> 00:24:10.890
We extract all the other images
that are down in that node.

00:24:10.890 --> 00:24:16.030
We can afford to do the
similarity with at least some

00:24:16.030 --> 00:24:17.210
of them down there.

00:24:17.210 --> 00:24:19.200
And we present that back to you.

00:24:19.200 --> 00:24:23.420
If we additionally have keywords
like the word "wheat," then

00:24:23.420 --> 00:24:29.040
we only consider
the images that were

00:24:29.040 --> 00:24:32.420
found on a page that also
mention the word "wheat."

00:24:32.420 --> 00:24:36.030
So that's how we are doing
the image search nowadays.

00:24:36.030 --> 00:24:39.230
Now because you
are here at Google

00:24:39.230 --> 00:24:45.919
today, I can show you how these
clusters actually look like.

00:24:45.919 --> 00:24:48.210
And now I'm going to do it
the smart way, because now I

00:24:48.210 --> 00:24:48.880
know I'm better.

00:24:48.880 --> 00:24:51.220
Right?

00:24:51.220 --> 00:24:54.360
This is cluster numbers
700, a random cluster

00:24:54.360 --> 00:24:57.680
in this tree we built of all the
images that we find on the web.

00:24:57.680 --> 00:25:02.740
And you can see, it's
kind of similar in a way.

00:25:02.740 --> 00:25:05.070
It's a lot of faces, right?

00:25:05.070 --> 00:25:07.270
And what we can
actually do here is

00:25:07.270 --> 00:25:12.080
we can say if we additionally
had the word "International

00:25:12.080 --> 00:25:17.190
Women's Day," what would we get?

00:25:17.190 --> 00:25:17.890
Look at that.

00:25:17.890 --> 00:25:18.440
Right?

00:25:18.440 --> 00:25:20.500
There actually,
well, of course we

00:25:20.500 --> 00:25:24.620
get the First Lady,
Michelle Obama.

00:25:24.620 --> 00:25:28.240
Then we get a very sad,
very inspirational image

00:25:28.240 --> 00:25:29.680
as the second one.

00:25:29.680 --> 00:25:32.330
A women all hidden.

00:25:32.330 --> 00:25:33.970
Right?

00:25:33.970 --> 00:25:38.620
With the little birds
in a cage on top.

00:25:38.620 --> 00:25:52.440
We could've taken
another 900 just

00:25:52.440 --> 00:25:55.650
so you get a feeling
for how different

00:25:55.650 --> 00:25:59.920
the images actually are
in the various nodes.

00:25:59.920 --> 00:26:04.020
1,400.

00:26:04.020 --> 00:26:06.306
Let's do 1200 instead.

00:26:06.306 --> 00:26:08.090
That it doesn't like either.

00:26:08.090 --> 00:26:10.790
1100.

00:26:10.790 --> 00:26:11.290
OK.

00:26:11.290 --> 00:26:12.100
I broke something.

00:26:16.350 --> 00:26:17.100
Here we are.

00:26:17.100 --> 00:26:19.790
So they have very
different color tones,

00:26:19.790 --> 00:26:24.820
and depending on
what node you are in.

00:26:24.820 --> 00:26:28.377
But this is how visual similar
images, they're working.

00:26:28.377 --> 00:26:30.210
So now you learned a
little bit about what's

00:26:30.210 --> 00:26:32.690
going on inside one
of these applications

00:26:32.690 --> 00:26:35.660
that you see online.

00:26:35.660 --> 00:26:39.320
Let me show you another
application also

00:26:39.320 --> 00:26:44.900
if I can find my presentation,
which I can never do so.

00:26:44.900 --> 00:26:47.560
I don't know what I did now.

00:26:47.560 --> 00:26:49.740
Where is my tap?

00:26:49.740 --> 00:26:54.060
Oh, the third-- it's
good that I have you.

00:26:54.060 --> 00:26:56.300
You are more with it than--

00:26:56.300 --> 00:26:58.620
So in my groups
inside we-- OK, these

00:26:58.620 --> 00:27:01.530
are just in case I couldn't
get anything to work.

00:27:01.530 --> 00:27:07.370
Since we now successfully
had managed to give you back

00:27:07.370 --> 00:27:09.120
similar images,
we thought that we

00:27:09.120 --> 00:27:11.640
can master any kind
of similarities.

00:27:11.640 --> 00:27:14.470
So we went on to the
next kind of similarities

00:27:14.470 --> 00:27:17.990
that we thought was interesting,
and that was time series.

00:27:17.990 --> 00:27:20.560
This is actually a very
interesting project

00:27:20.560 --> 00:27:22.070
that some of you
may have heard of.

00:27:22.070 --> 00:27:25.382
How many have heard
about Flu Trends?

00:27:25.382 --> 00:27:26.760
Well, I have.

00:27:26.760 --> 00:27:27.260
OK.

00:27:27.260 --> 00:27:31.450
So Flu Trends is a project
we formed here at Google.

00:27:31.450 --> 00:27:35.480
It is trying to measure
the current level of flu

00:27:35.480 --> 00:27:37.700
in any country.

00:27:37.700 --> 00:27:40.280
The Centers for
Disease Control only

00:27:40.280 --> 00:27:44.000
reports at the end of
the month the number

00:27:44.000 --> 00:27:47.440
of people that went
to doctors and were

00:27:47.440 --> 00:27:49.850
diagnosed with having the flu.

00:27:49.850 --> 00:27:53.330
So if we want to meter what
is the flu level in the US

00:27:53.330 --> 00:27:55.660
we have to wait until
the end of the month.

00:27:55.660 --> 00:27:58.270
That is a long
time to wait if we

00:27:58.270 --> 00:28:00.890
want to produce
vaccines, for instance.

00:28:00.890 --> 00:28:05.700
So how can we get a current
estimate of the flu level

00:28:05.700 --> 00:28:06.980
in the US?

00:28:06.980 --> 00:28:10.110
Well, some smart people at
Google-- they are awfully smart

00:28:10.110 --> 00:28:14.960
of them-- they thought,
well, if people have the flu,

00:28:14.960 --> 00:28:16.610
somebody in their
family has the flu,

00:28:16.610 --> 00:28:22.320
maybe they search online
for runny nose, temperature,

00:28:22.320 --> 00:28:26.350
symptoms of flu, things
that are sort of correlated

00:28:26.350 --> 00:28:27.220
with having the flu.

00:28:27.220 --> 00:28:29.220
We're not talking causality.

00:28:29.220 --> 00:28:30.540
This is very important.

00:28:30.540 --> 00:28:34.760
We're just talking, what is
correlated with things here?

00:28:34.760 --> 00:28:38.490
So the project is called Google
Correlate, and that is actually

00:28:38.490 --> 00:28:43.280
available out in
the public world.

00:28:43.280 --> 00:28:45.660
Their first application
was this Flu Trend,

00:28:45.660 --> 00:28:50.710
so they had them--
let me show you.

00:28:50.710 --> 00:28:56.430
So this is the time series
in blue from the CDC.

00:28:56.430 --> 00:29:03.030
We have the number of reported
incidents of flu as the doctors

00:29:03.030 --> 00:29:07.110
they have come up with him
from going back to 2005.

00:29:07.110 --> 00:29:11.990
And we have a query
term "influenza type A."

00:29:11.990 --> 00:29:17.400
How many instances we've had
of that query, or what time,

00:29:17.400 --> 00:29:20.070
and you can see they are
pretty well correlated.

00:29:20.070 --> 00:29:25.920
So if I, in 2011, were to
predict at some point of time,

00:29:25.920 --> 00:29:28.910
what is the flu level despite
that I haven't observed

00:29:28.910 --> 00:29:33.830
the level from CDC, this would
be a good estimator of it.

00:29:33.830 --> 00:29:37.772
The true model is built
on, I think, 40 keywords

00:29:37.772 --> 00:29:38.730
or something like that.

00:29:38.730 --> 00:29:40.850
We do not make
publicly available

00:29:40.850 --> 00:29:43.070
what these keywords
they are, in order not

00:29:43.070 --> 00:29:44.670
to get the model spammed.

00:29:44.670 --> 00:29:47.610
Because then people could sit
there and artificially hike up

00:29:47.610 --> 00:29:50.530
the current level of flu.

00:29:50.530 --> 00:29:54.470
But we have this site called
Flu Trends where you can go in,

00:29:54.470 --> 00:29:56.660
and you can see the
current level of flu.

00:29:56.660 --> 00:29:59.930
This is from the other
day, and fortunately you

00:29:59.930 --> 00:30:02.170
can see this year it
hasn't been as bad as it's

00:30:02.170 --> 00:30:04.180
been some of the past years.

00:30:04.180 --> 00:30:06.159
And we are on the
way down, though I

00:30:06.159 --> 00:30:08.450
must admit that I've been
sick the last couple of days.

00:30:08.450 --> 00:30:12.370
We also try to do it
for some other diseases.

00:30:12.370 --> 00:30:13.620
This is for the United States.

00:30:13.620 --> 00:30:18.660
We have it for a number
of other countries,

00:30:18.660 --> 00:30:21.350
and you can in the United
States actually drill down

00:30:21.350 --> 00:30:26.370
to the city level, and get what
is the current level of flu

00:30:26.370 --> 00:30:30.640
as we estimated based on query
terms that are coordinated

00:30:30.640 --> 00:30:32.870
with these CDC numbers,
or historically

00:30:32.870 --> 00:30:35.500
have been correlated
with the CDC numbers.

00:30:35.500 --> 00:30:37.710
What do we believe
that the current flu

00:30:37.710 --> 00:30:40.220
level is in the various cities?

00:30:40.220 --> 00:30:44.890
Now what we would like
to make available for you

00:30:44.890 --> 00:30:47.150
so you can make your
own flu models, right?

00:30:47.150 --> 00:30:50.640
Or you can have your
own series of something

00:30:50.640 --> 00:30:53.200
that you'd like to find
something correlated with

00:30:53.200 --> 00:30:54.470
and write a new article.

00:30:54.470 --> 00:30:56.850
And we actually had this as
a paper in nature, right?

00:30:56.850 --> 00:31:00.680
We want you to discover
correlations and find things

00:31:00.680 --> 00:31:05.890
in the world that can be
to benefit of everyone.

00:31:05.890 --> 00:31:13.540
So we have worked on getting Flu
Trends or Correlate out there

00:31:13.540 --> 00:31:16.930
as publicly available data.

00:31:16.930 --> 00:31:19.020
So what we found
out was, however,

00:31:19.020 --> 00:31:22.960
that this simple version
we've done for the images,

00:31:22.960 --> 00:31:26.882
it didn't work one
bit for time series.

00:31:26.882 --> 00:31:28.590
Now with time series,
there's this thing.

00:31:28.590 --> 00:31:31.540
They go along, and then
there's kind of a change point.

00:31:31.540 --> 00:31:33.370
And then they have a
different behavior,

00:31:33.370 --> 00:31:34.360
and then there's a change point.

00:31:34.360 --> 00:31:36.200
And then they have a
different behavior.

00:31:36.200 --> 00:31:38.670
So we found out
that in order for us

00:31:38.670 --> 00:31:41.560
to find good correlations, we
had to do something different.

00:31:41.560 --> 00:31:44.210
And we did what we call
asymmetric hashing,

00:31:44.210 --> 00:31:48.050
and it has to be a little bit
of equations also here today.

00:31:48.050 --> 00:31:53.540
So what we do is we take
all our query time series,

00:31:53.540 --> 00:31:56.870
and we split them into chunks.

00:31:56.870 --> 00:31:59.400
Well, we cannot detect change
points for each time series,

00:31:59.400 --> 00:32:01.650
so we just all- everybody's
going to have to live with

00:32:01.650 --> 00:32:02.680
the same change points.

00:32:02.680 --> 00:32:03.390
Right?

00:32:03.390 --> 00:32:08.150
So we split them into N
or K, so that it's N long,

00:32:08.150 --> 00:32:11.980
and then we want to
have N our K chunks.

00:32:11.980 --> 00:32:15.710
And now each chunk, we're going
to represent with a cluster

00:32:15.710 --> 00:32:16.210
center.

00:32:16.210 --> 00:32:19.220
So we decided we can't afford
to have a whole lot of cluster

00:32:19.220 --> 00:32:21.960
centers, so we're just going to
take all these little chunks,

00:32:21.960 --> 00:32:25.770
and then we're going
to find 256 centers.

00:32:25.770 --> 00:32:31.390
We run a K means algorithm
to find these centers.

00:32:31.390 --> 00:32:35.090
And now we are going to
represent all our queries just

00:32:35.090 --> 00:32:40.290
with these N or K centers,
for which the first chunk was

00:32:40.290 --> 00:32:42.390
most similar to
center number 10.

00:32:42.390 --> 00:32:45.560
The next chunk was most
similar to center number 14,

00:32:45.560 --> 00:32:47.720
so we just instead
of a time series,

00:32:47.720 --> 00:32:52.805
we get a sequence of what
centers it was most similar to.

00:32:52.805 --> 00:32:56.240
That we can call kind of a
hash code for the time series,

00:32:56.240 --> 00:32:59.240
for all our query streams
that we've had over.

00:32:59.240 --> 00:33:02.790
Now when we come in with a new
time series, all we have to do

00:33:02.790 --> 00:33:06.470
is we have to divide
it into the chunks.

00:33:06.470 --> 00:33:10.690
We can compute each chunk's
distance to the centers,

00:33:10.690 --> 00:33:15.300
and now if I want to find the
distance from the new time

00:33:15.300 --> 00:33:17.220
series to one of
my query streams,

00:33:17.220 --> 00:33:19.595
I just have to do
N or K additions.

00:33:25.250 --> 00:33:26.556
Does that mean I'm out of time?

00:33:31.150 --> 00:33:32.300
OK.

00:33:32.300 --> 00:33:36.900
I did start late, but I-- OK.

00:33:36.900 --> 00:33:37.490
OK.

00:33:37.490 --> 00:33:41.150
We call it asymmetric,
because it's

00:33:41.150 --> 00:33:46.230
asymmetric in that we keep
the real data of the new time

00:33:46.230 --> 00:33:48.160
series we come in
with, but we only

00:33:48.160 --> 00:33:51.650
keep the hash code for
all the query terms.

00:33:51.650 --> 00:33:56.211
So let me give you an example
of how it's actually working.

00:33:56.211 --> 00:33:58.460
Here we have the site, and
you can go and play with it

00:33:58.460 --> 00:33:59.740
yourself.

00:33:59.740 --> 00:34:01.850
OK.

00:34:01.850 --> 00:34:04.852
March Madness.

00:34:04.852 --> 00:34:06.680
Who knows what March Madness is?

00:34:06.680 --> 00:34:09.400
I know.

00:34:09.400 --> 00:34:10.460
Not a big surprise.

00:34:10.460 --> 00:34:10.960
Right?

00:34:10.960 --> 00:34:16.183
March Madness has big
peaks in March, right?

00:34:16.183 --> 00:34:19.510
But what do we find that
the series-- so here we

00:34:19.510 --> 00:34:22.500
are taking as our
new time series

00:34:22.500 --> 00:34:25.449
is the one that corresponds
to the query term, "March

00:34:25.449 --> 00:34:29.800
Madness." so what is
correlated with March Madness?

00:34:29.800 --> 00:34:32.500
When people search
for March Madness,

00:34:32.500 --> 00:34:35.810
what do they also search for?

00:34:35.810 --> 00:34:36.435
AUDIENCE: Beer.

00:34:36.435 --> 00:34:37.310
CORINNA CORTES: Beer.

00:34:37.310 --> 00:34:40.413
No, you see what comes up here.

00:34:40.413 --> 00:34:44.469
It's a basketball, NCAA
tournament, it's brackets.

00:34:44.469 --> 00:34:52.250
I think that's a system
for how you can show more.

00:34:52.250 --> 00:34:56.460
And if you're logged on, you can
also upload into your own data.

00:34:56.460 --> 00:34:58.920
So if you had the CDC
data or something else,

00:34:58.920 --> 00:35:03.535
you can upload
that and find where

00:35:03.535 --> 00:35:04.910
it's correlated
with that, so you

00:35:04.910 --> 00:35:07.440
can build your own
Flu Trends model.

00:35:07.440 --> 00:35:11.755
We can take something else that
you also know-- Super Bowl.

00:35:11.755 --> 00:35:12.420
Uh-oh.

00:35:12.420 --> 00:35:15.660
If I could just spell,
it would be a plus.

00:35:15.660 --> 00:35:16.160
Right?

00:35:16.160 --> 00:35:19.260
Super Bowl.

00:35:19.260 --> 00:35:21.380
What on earth is
that, you think?

00:35:21.380 --> 00:35:22.830
Yeah, it's Japanese.

00:35:22.830 --> 00:35:27.180
But ladies and gentleman, there
are a few gentleman here also.

00:35:27.180 --> 00:35:29.450
Now look at this.

00:35:29.450 --> 00:35:30.010
Come on.

00:35:30.010 --> 00:35:30.510
OK.

00:35:30.510 --> 00:35:32.470
So we're here.

00:35:32.470 --> 00:35:34.197
It's not a big surprise
that it came up.

00:35:34.197 --> 00:35:34.696
Right?

00:35:41.020 --> 00:35:45.090
The project internally was
actually called Mittens,

00:35:45.090 --> 00:35:48.270
and there's an
explanation for that.

00:35:48.270 --> 00:35:49.850
Because it's kind
of cute, right?

00:35:49.850 --> 00:35:51.350
Mittens, you have,
of course, you're

00:35:51.350 --> 00:35:53.610
searching for it in a
window, but look at what's

00:35:53.610 --> 00:35:54.850
correlated with it also.

00:35:54.850 --> 00:35:59.830
Knit hat, wool socks,
things like that.

00:35:59.830 --> 00:36:02.185
Spring.

00:36:02.185 --> 00:36:03.480
We're all thinking spring.

00:36:03.480 --> 00:36:06.590
It's nice outside today.

00:36:06.590 --> 00:36:11.090
And if we say we don't want
anything that has spring in it,

00:36:11.090 --> 00:36:12.490
baseball cleats.

00:36:12.490 --> 00:36:13.230
Track Spikes.

00:36:13.230 --> 00:36:15.700
We want to go out and
use our body weight.

00:36:15.700 --> 00:36:16.345
Dress shop.

00:36:21.160 --> 00:36:21.660
Wedding.

00:36:21.660 --> 00:36:23.650
It used to bring up diet.

00:36:26.770 --> 00:36:28.501
Let's see what it
does these days.

00:36:28.501 --> 00:36:29.000
No.

00:36:29.000 --> 00:36:30.550
We got the diet out.

00:36:30.550 --> 00:36:34.280
I think this is the place
you go for your honeymoon.

00:36:36.870 --> 00:36:37.420
All right.

00:36:37.420 --> 00:36:40.340
These are always
fun to play with.

00:36:40.340 --> 00:36:45.420
We can also do more
childcare job posting.

00:36:45.420 --> 00:36:46.286
Family law.

00:36:49.480 --> 00:36:51.680
It's actually interesting
about the job posting.

00:36:51.680 --> 00:36:54.530
There was some article the other
day that one of the reasons

00:36:54.530 --> 00:36:56.980
that women, they
don't stay in jobs,

00:36:56.980 --> 00:37:00.190
and they don't
complete in academia

00:37:00.190 --> 00:37:05.510
as much as-- it's hard
to have both a job

00:37:05.510 --> 00:37:07.265
and take care of your children.

00:37:09.931 --> 00:37:10.430
All right.

00:37:10.430 --> 00:37:14.310
So give me a word
that you'd like

00:37:14.310 --> 00:37:15.957
to see the correlations with.

00:37:15.957 --> 00:37:16.790
AUDIENCE: Hamburger.

00:37:16.790 --> 00:37:17.300
CORINNA CORTES: Hamburger?

00:37:17.300 --> 00:37:18.264
AUDIENCE: Yes.

00:37:18.264 --> 00:37:27.129
[LAUGHTER]

00:37:27.129 --> 00:37:27.920
CORINNA CORTES: Oh.

00:37:27.920 --> 00:37:36.360
I forgot the R.
That is interesting.

00:37:36.360 --> 00:37:38.570
Flink.

00:37:38.570 --> 00:37:39.070
Mt.

00:37:39.070 --> 00:37:39.610
Pleasant.

00:37:39.610 --> 00:37:44.932
I have no idea why
we-- It looks OK.

00:37:44.932 --> 00:37:46.640
I'm sorry we have a
problem with the data

00:37:46.640 --> 00:37:48.730
here in the
beginning of January.

00:37:48.730 --> 00:37:51.420
We're correcting next week, so
if you go in and play with it

00:37:51.420 --> 00:37:55.035
next week, you shouldn't see
all these horrendous things.

00:37:57.640 --> 00:38:00.050
Virginia?

00:38:00.050 --> 00:38:02.007
You want the correlations
for Virginia?

00:38:02.007 --> 00:38:03.230
AUDIENCE: Yeah.

00:38:03.230 --> 00:38:04.688
CORINNA CORTES:
Well, I'm happy to.

00:38:15.260 --> 00:38:16.370
I don't know.

00:38:16.370 --> 00:38:18.530
I mean there's often
a good explanation.

00:38:18.530 --> 00:38:24.390
If you go online, you'll find
that there was probably some--

00:38:29.600 --> 00:38:30.720
OK.

00:38:30.720 --> 00:38:35.730
And you see when I visit
schools, if I go to MIT,

00:38:35.730 --> 00:38:37.310
I put in and say
what do people also

00:38:37.310 --> 00:38:40.200
think of when I-- The
other day I was in Finland.

00:38:40.200 --> 00:38:40.700
Right?

00:38:40.700 --> 00:38:41.570
It's hockey.

00:38:41.570 --> 00:38:42.150
Right?

00:38:42.150 --> 00:38:45.500
That's the only thing
they care about.

00:38:45.500 --> 00:38:46.870
Finland and hockey.

00:38:46.870 --> 00:38:49.110
OK.

00:38:49.110 --> 00:38:51.210
I encourage you to
play with this site.

00:38:51.210 --> 00:38:55.190
It's a lot of fun, and the
reason we put it out there

00:38:55.190 --> 00:38:57.360
is of course that we
hope that somebody

00:38:57.360 --> 00:39:02.920
is going to discover some
great correlations and advance

00:39:02.920 --> 00:39:03.530
humanity.

00:39:03.530 --> 00:39:04.030
Whatever.

00:39:07.970 --> 00:39:09.070
OK.

00:39:09.070 --> 00:39:12.380
So I should probably try to
wrap up, because otherwise we're

00:39:12.380 --> 00:39:13.940
going to be sitting
here all day.

00:39:13.940 --> 00:39:16.270
And I'm already six
minutes overtime despite,

00:39:16.270 --> 00:39:19.440
but I did start late.

00:39:19.440 --> 00:39:21.910
I can talk forever, right.

00:39:21.910 --> 00:39:24.750
Other projects that
have come from my team--

00:39:24.750 --> 00:39:26.630
Chinese handwriting for Android.

00:39:26.630 --> 00:39:27.330
Right?

00:39:27.330 --> 00:39:29.330
Can you imagine when
you have to-- there must

00:39:29.330 --> 00:39:32.300
be a lot of Asians
here that, and they

00:39:32.300 --> 00:39:35.350
use to enter this
hideous keyboard.

00:39:35.350 --> 00:39:35.850
Right?

00:39:35.850 --> 00:39:37.536
How do you do that?

00:39:37.536 --> 00:39:38.410
AUDIENCE: No idea.

00:39:38.410 --> 00:39:39.080
CORINNA CORTES: No idea?

00:39:39.080 --> 00:39:39.579
No.

00:39:39.579 --> 00:39:40.710
It must be impossible.

00:39:40.710 --> 00:39:41.320
I cannot.

00:39:41.320 --> 00:39:44.610
So what we came up with was
a handwriting application

00:39:44.610 --> 00:39:47.410
where you can actually write.

00:39:47.410 --> 00:39:51.640
And then you can get-- it's
an extension of something

00:39:51.640 --> 00:39:52.140
like that.

00:39:52.140 --> 00:39:54.260
Download it and play with it.

00:39:54.260 --> 00:39:57.440
So for a lot of the Asian
languages, you can write,

00:39:57.440 --> 00:40:00.220
and you can get suggestions
for what it's recognized at.

00:40:00.220 --> 00:40:04.550
And it's getting an
enormous amount of traffic.

00:40:16.780 --> 00:40:18.580
And speech recognition.

00:40:18.580 --> 00:40:24.790
I must say that I'm very proud
that I have the team that's

00:40:24.790 --> 00:40:29.320
behind all the algorithms in
the Google Speech Recognizer

00:40:29.320 --> 00:40:33.340
that I'm sure that
we all have used.

00:40:33.340 --> 00:40:35.680
It still needs a little work.

00:40:35.680 --> 00:40:36.920
It's not very good in Danish.

00:40:36.920 --> 00:40:39.840
I can say that.

00:40:39.840 --> 00:40:44.300
So please if you're
still in graduate school,

00:40:44.300 --> 00:40:48.710
try to learn a little bit about
signaling processing for speech

00:40:48.710 --> 00:40:50.810
recognition, and the
algorithms behind that,

00:40:50.810 --> 00:40:53.790
and join Google, because
we still need you.

00:40:53.790 --> 00:40:55.000
We still need you.

00:40:55.000 --> 00:40:56.990
All these problems,
as you can see,

00:40:56.990 --> 00:40:59.130
they're far from
solved problems.

00:40:59.130 --> 00:41:00.670
We're just scratching
the surface,

00:41:00.670 --> 00:41:04.274
but we try to put out at least
something that is usable.

00:41:04.274 --> 00:41:05.690
And I think the
speech recognition

00:41:05.690 --> 00:41:08.310
at least in English,
is getting to the level

00:41:08.310 --> 00:41:10.040
where it is meaningful.

00:41:10.040 --> 00:41:13.250
I sometimes at least try
to dictate email messages

00:41:13.250 --> 00:41:16.870
and then correct
them afterwards.

00:41:16.870 --> 00:41:18.570
Somehow my accent
is not good for it.

00:41:18.570 --> 00:41:21.700
It's funny, because
the father of my kids,

00:41:21.700 --> 00:41:24.930
he's actually one of these
people behind the algorithms.

00:41:24.930 --> 00:41:30.590
And he's working in speech
recognition for 25 years.

00:41:30.590 --> 00:41:33.675
He's French, and he
also has an accent.

00:41:33.675 --> 00:41:36.630
But when he speaks
to this telephone,

00:41:36.630 --> 00:41:39.650
he just becomes another person.

00:41:39.650 --> 00:41:42.790
And he has this
perfect pronunciation

00:41:42.790 --> 00:41:46.375
that doesn't sound
one bit like him.

00:41:46.375 --> 00:41:49.170
But it recognizes it perfectly.

00:41:49.170 --> 00:41:53.210
So maybe we can-- we'll
get somewhere adapting.

00:41:53.210 --> 00:41:56.360
We adapt to the machines, and
the machines also get better,

00:41:56.360 --> 00:42:01.270
and eventually we'll be able
to recognize each other.

00:42:01.270 --> 00:42:04.210
So these are just
examples of the projects

00:42:04.210 --> 00:42:06.400
that I have in my group.

00:42:06.400 --> 00:42:08.300
I'm the very proud
mother of this group.

00:42:08.300 --> 00:42:11.155
I have built it all.

00:42:11.155 --> 00:42:13.910
So this is where I am today.

00:42:13.910 --> 00:42:15.532
You've seen a few of them.

00:42:15.532 --> 00:42:16.490
You've seen that I run.

00:42:16.490 --> 00:42:17.980
Right?

00:42:17.980 --> 00:42:19.360
I do run.

00:42:19.360 --> 00:42:21.140
That's my hobby.

00:42:21.140 --> 00:42:23.870
And that does mean
that I was up at 5

00:42:23.870 --> 00:42:26.370
o'clock this morning
to go out for my run.

00:42:26.370 --> 00:42:30.660
It's hard to get it
all to fit together.

00:42:30.660 --> 00:42:31.900
I like to do my research.

00:42:31.900 --> 00:42:35.090
I'm a manager here,
and I have my twins

00:42:35.090 --> 00:42:37.170
that are now just
turned teenagers.

00:42:39.710 --> 00:42:41.940
You can do it all.

00:42:41.940 --> 00:42:46.790
It does require a lot of will,
and the day is not long enough.

00:42:46.790 --> 00:42:50.200
I could easily use five
hours extra in every day.

00:42:50.200 --> 00:42:56.540
But I encourage you still
to pursue all your dreams,

00:42:56.540 --> 00:43:00.080
because you can fit
it in if you want to.

00:43:00.080 --> 00:43:02.900
And if you are stuck in
something that you don't really

00:43:02.900 --> 00:43:06.102
like, be honest to yourself.

00:43:06.102 --> 00:43:08.480
Get out of it.

00:43:08.480 --> 00:43:10.020
Change your job.

00:43:10.020 --> 00:43:11.790
Change your education.

00:43:11.790 --> 00:43:13.360
It's not too late.

00:43:13.360 --> 00:43:17.840
You still have a lot
of years ahead of you.

00:43:17.840 --> 00:43:18.700
OK?

00:43:18.700 --> 00:43:19.756
All right.

00:43:19.756 --> 00:43:24.576
[APPLAUSE]

00:43:29.439 --> 00:43:30.730
I'm supposed to take questions.

00:43:30.730 --> 00:43:31.605
FEMALE SPEAKER: Yeah.

00:43:31.605 --> 00:43:33.797
I was going to say.

00:43:33.797 --> 00:43:34.630
CORINNA CORTES: Yes.

00:43:34.630 --> 00:43:35.210
FEMALE SPEAKER: Oh, wait.

00:43:35.210 --> 00:43:35.709
Sorry.

00:43:35.709 --> 00:43:36.920
Can you come to the mic?

00:43:36.920 --> 00:43:37.820
Sorry.

00:43:37.820 --> 00:43:39.550
Just because we
want to hear people.

00:43:43.069 --> 00:43:44.860
AUDIENCE: I know you
started with academia,

00:43:44.860 --> 00:43:48.730
and you have very
impressive credentials.

00:43:48.730 --> 00:43:51.920
But what do you think
about getting into teach

00:43:51.920 --> 00:43:53.270
without ever going to school?

00:43:53.270 --> 00:43:55.190
Which is like what I did.

00:43:55.190 --> 00:43:57.160
And I'm supposedly in
the highest percentile

00:43:57.160 --> 00:44:00.964
per hour for making
money in the country.

00:44:00.964 --> 00:44:02.880
And I think it's a good
opportunity for women,

00:44:02.880 --> 00:44:04.770
so that's always my preach.

00:44:04.770 --> 00:44:06.100
[? Mooks. ?] You know.

00:44:06.100 --> 00:44:06.600
Lynda.com.

00:44:06.600 --> 00:44:08.330
Get a job.

00:44:08.330 --> 00:44:09.373
Just keep moving up.

00:44:09.373 --> 00:44:12.610
CORINNA CORTES: I have
no experience in that.

00:44:12.610 --> 00:44:15.910
I'm impressed that
you have made it.

00:44:15.910 --> 00:44:20.630
Very good for you,
but maybe you're

00:44:20.630 --> 00:44:23.690
the one who should instead
be coming up at some point

00:44:23.690 --> 00:44:27.720
and tell these
women here today how

00:44:27.720 --> 00:44:33.530
it is possible without going
into a formal degree first.

00:44:33.530 --> 00:44:35.770
I kind of did it the
easy way, I could say.

00:44:35.770 --> 00:44:38.215
AUDIENCE: I never had
a class in IT ever.

00:44:38.215 --> 00:44:39.340
CORINNA CORTES: You didn't?

00:44:39.340 --> 00:44:40.620
AUDIENCE: No.

00:44:40.620 --> 00:44:43.780
CORINNA CORTES: And
they still accept you?

00:44:43.780 --> 00:44:45.232
AUDIENCE: They didn't care.

00:44:45.232 --> 00:44:46.200
They don't care.

00:44:46.200 --> 00:44:48.140
Not anymore.

00:44:48.140 --> 00:44:49.193
30 years.

00:44:49.193 --> 00:44:50.401
CORINNA CORTES: Good for you.

00:44:54.340 --> 00:44:56.440
You managed somehow.

00:44:56.440 --> 00:44:59.280
Usually I tell people
to stay in school

00:44:59.280 --> 00:45:01.960
and get their diploma
just because it hedges

00:45:01.960 --> 00:45:03.403
your best for later on in life.

00:45:03.403 --> 00:45:04.694
AUDIENCE: If you can afford it.

00:45:04.694 --> 00:45:06.930
See my point is that a lot
of women can't afford it.

00:45:06.930 --> 00:45:07.429
You know?

00:45:07.429 --> 00:45:09.770
I couldn't afford
it when I was 17.

00:45:12.432 --> 00:45:14.140
CORINNA CORTES:
[? Mooks ?] are out here?

00:45:14.140 --> 00:45:15.140
There's also a lot of junk.

00:45:15.140 --> 00:45:15.640
Yeah.

00:45:15.640 --> 00:45:18.170
But congratulations to you.

00:45:18.170 --> 00:45:19.860
You'll come up later
and tell everybody

00:45:19.860 --> 00:45:22.859
how to do it without
going to school.

00:45:22.859 --> 00:45:23.900
AUDIENCE: Hello, Corinna.

00:45:23.900 --> 00:45:26.130
It's privilege to have you here.

00:45:26.130 --> 00:45:28.310
It's really nice.

00:45:28.310 --> 00:45:29.180
I have question.

00:45:29.180 --> 00:45:32.770
So when your engineers are
trying to create a product,

00:45:32.770 --> 00:45:34.540
and they're also
trying to create

00:45:34.540 --> 00:45:37.780
a product in the
research-oriented stream,

00:45:37.780 --> 00:45:42.160
how do they manage being
productive in the sense

00:45:42.160 --> 00:45:44.600
like creating the software,
but at the same time

00:45:44.600 --> 00:45:46.027
discovering something new?

00:45:46.027 --> 00:45:47.860
CORINNA CORTES: That's
a very good question,

00:45:47.860 --> 00:45:50.510
and it is a tricky balance.

00:45:50.510 --> 00:45:53.230
So all the
researchers at Google,

00:45:53.230 --> 00:45:55.060
we are of course at
Google, because we

00:45:55.060 --> 00:45:57.640
like the ideas, the
mission of Google,

00:45:57.640 --> 00:46:02.150
and we want to contribute
to the Google brand.

00:46:02.150 --> 00:46:04.450
If we were not
interested in that,

00:46:04.450 --> 00:46:07.780
we would probably
be in academia.

00:46:07.780 --> 00:46:13.930
So it's whenever you go out and
make a cup of coffee at Google

00:46:13.930 --> 00:46:17.000
and talk to any random
person out there,

00:46:17.000 --> 00:46:20.870
you'll find that they're
working on something fascinating

00:46:20.870 --> 00:46:23.550
that you would love
to contribute to.

00:46:23.550 --> 00:46:26.100
For my researchers, I tell
them that they shouldn't

00:46:26.100 --> 00:46:28.030
be consultants to
their projects.

00:46:28.030 --> 00:46:28.660
Right?

00:46:28.660 --> 00:46:31.970
They should try to find a novel
aspect in a project where they

00:46:31.970 --> 00:46:34.680
cannot just say, go
and read this paper,

00:46:34.680 --> 00:46:38.790
and it will be a good
algorithm for you to do.

00:46:38.790 --> 00:46:40.670
They should try to
go for their projects

00:46:40.670 --> 00:46:43.430
where there really is
something new and exciting

00:46:43.430 --> 00:46:45.240
for them to do.

00:46:45.240 --> 00:46:47.890
And they often end
up actually sitting

00:46:47.890 --> 00:46:51.300
for a long time with
the engineering teams

00:46:51.300 --> 00:46:54.300
in order to find out what
the engineering team really

00:46:54.300 --> 00:46:55.880
wants to do.

00:46:55.880 --> 00:46:58.030
Then I ask them
after they'd done

00:46:58.030 --> 00:47:00.480
that to come back to
the research group

00:47:00.480 --> 00:47:04.870
and write up what was it that
was the novel thing about what

00:47:04.870 --> 00:47:05.930
they did?

00:47:05.930 --> 00:47:08.980
In what way was the
solution optimal?

00:47:08.980 --> 00:47:11.160
It can be computational
complexity,

00:47:11.160 --> 00:47:12.400
or it can be whatsoever.

00:47:12.400 --> 00:47:12.900
Right?

00:47:12.900 --> 00:47:16.440
But they have to have a good
reason for why they did it,

00:47:16.440 --> 00:47:19.270
why they recommend
it, the way they did.

00:47:19.270 --> 00:47:23.080
So we try to balance
these things.

00:47:23.080 --> 00:47:26.820
Trying to in a research team
to go for the novel things

00:47:26.820 --> 00:47:32.320
that nobody has found a
good solution to before.

00:47:32.320 --> 00:47:39.650
But yeah, it's often something
that you spend some time doing

00:47:39.650 --> 00:47:42.410
product development,
and then you come home

00:47:42.410 --> 00:47:45.530
and you write up
the paper about it.

00:47:45.530 --> 00:47:50.310
We also try to generalize the
algorithms then and write it up

00:47:50.310 --> 00:47:52.710
as libraries and give
it back as open source.

00:47:52.710 --> 00:47:54.480
For instance, all
the speech algorithms

00:47:54.480 --> 00:47:57.290
that are out there as
open source libraries,

00:47:57.290 --> 00:48:00.880
so they can be used
by universities

00:48:00.880 --> 00:48:02.866
or other industries.

00:48:02.866 --> 00:48:03.699
AUDIENCE: Thank you.

00:48:08.269 --> 00:48:08.810
AUDIENCE: OK.

00:48:08.810 --> 00:48:09.320
Hi, Corinna.

00:48:09.320 --> 00:48:11.180
First of all, I loved
your quote about not

00:48:11.180 --> 00:48:12.430
settling for the local minima.

00:48:12.430 --> 00:48:13.970
I'm going to use that.

00:48:13.970 --> 00:48:16.070
But I actually had
a question for you

00:48:16.070 --> 00:48:17.550
about breadth versus
depth when you

00:48:17.550 --> 00:48:20.850
come to deciding what
you want to work in.

00:48:20.850 --> 00:48:24.864
Do you have your own perspective
or from people you know,

00:48:24.864 --> 00:48:26.530
when you should stick
to the same career

00:48:26.530 --> 00:48:29.690
path for a long time versus
when you should decide to switch

00:48:29.690 --> 00:48:31.120
and move ahead to
something else?

00:48:31.120 --> 00:48:34.540
Because the year of
companies having lifers

00:48:34.540 --> 00:48:38.620
is probably kind of now being
turned around by the start-ups,

00:48:38.620 --> 00:48:40.790
so I was wondering what
you had to say on that.

00:48:43.360 --> 00:48:46.780
CORINNA CORTES: I started
in the Bell Labs system.

00:48:46.780 --> 00:48:51.090
I was there for 15
years, and I thought

00:48:51.090 --> 00:48:54.630
I would be there forever.

00:48:54.630 --> 00:48:56.890
I was commuting for
15 years from New York

00:48:56.890 --> 00:48:59.470
City to New Jersey.

00:48:59.470 --> 00:49:03.210
Then all of a sudden, well,
the telephone industry

00:49:03.210 --> 00:49:04.410
had been going down, right?

00:49:04.410 --> 00:49:09.450
And the internet was going up,
and Google was in New York.

00:49:09.450 --> 00:49:12.340
And it was clear that Google
was a good search engine,

00:49:12.340 --> 00:49:14.770
and it hadn't gone public yet.

00:49:14.770 --> 00:49:17.130
But if it was not going
to be Google itself,

00:49:17.130 --> 00:49:19.460
then it was just going to
be bought by somebody else.

00:49:19.460 --> 00:49:21.220
So I made the move.

00:49:21.220 --> 00:49:25.600
I think you often
know with yourself.

00:49:25.600 --> 00:49:29.640
But allow yourself
to think it through.

00:49:29.640 --> 00:49:30.280
Is it time?

00:49:30.280 --> 00:49:32.500
If you begin to think it's
time, it's probably time.

00:49:32.500 --> 00:49:33.260
Right?

00:49:33.260 --> 00:49:34.980
And then there's often
the danger, then,

00:49:34.980 --> 00:49:37.820
you just stick around
for another five years,

00:49:37.820 --> 00:49:39.120
because that's the easy thing.

00:49:39.120 --> 00:49:39.620
Right?

00:49:39.620 --> 00:49:40.970
And you don't have
to upset anything,

00:49:40.970 --> 00:49:42.761
and you don't actually
have to do anything.

00:49:42.761 --> 00:49:46.960
But if you begin to even
think the thought, it's time.

00:49:51.920 --> 00:49:52.920
AUDIENCE: Hi.

00:49:52.920 --> 00:49:54.900
First of all, it
was a great talk.

00:49:54.900 --> 00:49:56.910
And being a mom
of a two-year-old

00:49:56.910 --> 00:50:00.620
and a graduate student,
I can relate to it a lot,

00:50:00.620 --> 00:50:02.990
and it was great inspiration.

00:50:02.990 --> 00:50:04.825
So call me a nerd.

00:50:04.825 --> 00:50:07.280
I have couple of technical
questions with respect

00:50:07.280 --> 00:50:09.250
to image clustering.

00:50:09.250 --> 00:50:12.770
First of all, when you get
new data, like new images,

00:50:12.770 --> 00:50:15.305
how do you train
them for the samples?

00:50:15.305 --> 00:50:17.420
Like what would be
the time period?

00:50:17.420 --> 00:50:19.811
So because everything is based
on the data from the web,

00:50:19.811 --> 00:50:20.310
right?

00:50:20.310 --> 00:50:20.660
CORINNA CORTES: Yes.

00:50:20.660 --> 00:50:22.745
AUDIENCE: So how do you
make sure to incorporate

00:50:22.745 --> 00:50:26.720
the new data as
well into algorithm?

00:50:26.720 --> 00:50:28.740
CORINNA CORTES: So the
clustering we're doing,

00:50:28.740 --> 00:50:30.535
we don't redo it very often.

00:50:33.310 --> 00:50:35.900
Also because we have
billions of images,

00:50:35.900 --> 00:50:39.310
and even if you add
100,000 new images a day,

00:50:39.310 --> 00:50:40.840
it doesn't change too much.

00:50:40.840 --> 00:50:42.900
But of course there
could be completely

00:50:42.900 --> 00:50:46.610
new things that are popping
up, and you begin to

00:50:46.610 --> 00:50:49.990
just having that they all
end up down in the same node,

00:50:49.990 --> 00:50:52.600
and you have to recluster.

00:50:52.600 --> 00:50:56.830
I don't think that we change
the clustering too often.

00:50:56.830 --> 00:51:02.490
But we should probably-- and we
probably do-- once in a while.

00:51:02.490 --> 00:51:03.400
Right?

00:51:03.400 --> 00:51:04.800
Every half year.

00:51:04.800 --> 00:51:07.319
Just scratch at all,
and start all over.

00:51:07.319 --> 00:51:07.860
AUDIENCE: OK.

00:51:07.860 --> 00:51:12.780
And the second question
is about deep learning.

00:51:12.780 --> 00:51:16.040
Can we use deep learning kind of
thing like for image clustering

00:51:16.040 --> 00:51:19.550
and the neural
networks behind it?

00:51:19.550 --> 00:51:23.590
CORINNA CORTES: Don't get
me started in deep learning.

00:51:23.590 --> 00:51:25.120
OK.

00:51:25.120 --> 00:51:28.390
So I have the right to
be hard on deep learning.

00:51:28.390 --> 00:51:31.850
I was at the labs where
[INAUDIBLE] also was.

00:51:31.850 --> 00:51:33.840
We were in the same group
for many, many years.

00:51:33.840 --> 00:51:38.330
So he's a good friend
of me, and deep learning

00:51:38.330 --> 00:51:40.270
is not the answer to everything.

00:51:40.270 --> 00:51:43.490
Deep learning is just another
machine learning algorithm.

00:51:43.490 --> 00:51:48.730
So I have I worked on support
vector machines a lot.

00:51:48.730 --> 00:51:52.090
I hold the patent for support
vector machines actually.

00:51:52.090 --> 00:51:58.110
So that's another-- so
there's deep learning.

00:51:58.110 --> 00:52:00.480
That's a non-convex
optimization problem.

00:52:00.480 --> 00:52:01.950
You have no clue
what you're doing.

00:52:01.950 --> 00:52:04.010
You're getting into
a local minimum.

00:52:04.010 --> 00:52:06.220
It might be a perfectly
good local minimum,

00:52:06.220 --> 00:52:08.890
but you have no
generalization guarantees

00:52:08.890 --> 00:52:11.760
for the deep networks.

00:52:11.760 --> 00:52:15.080
Convex optimization is
often a different story.

00:52:15.080 --> 00:52:17.620
You know what you're
doing is one minimum.

00:52:17.620 --> 00:52:21.290
You can find your way into it,
and a lot of those algorithms

00:52:21.290 --> 00:52:23.700
also come with
learning guarantees.

00:52:23.700 --> 00:52:25.980
That doesn't mean that
deep learning hasn't

00:52:25.980 --> 00:52:28.870
had impressive results recently.

00:52:28.870 --> 00:52:33.970
We've had two instances
where it has outperformed

00:52:33.970 --> 00:52:36.950
many of the other algorithms
that we otherwise see.

00:52:36.950 --> 00:52:41.070
They're characterized by being
multi-class classification

00:52:41.070 --> 00:52:41.780
problems.

00:52:41.780 --> 00:52:43.900
And we're not talking
multi-class like it's ten

00:52:43.900 --> 00:52:46.020
classes that we
have to recognize.

00:52:46.020 --> 00:52:49.040
It is hundreds of
millions of classes.

00:52:49.040 --> 00:52:51.600
It has exactly been
in the image world.

00:52:51.600 --> 00:52:52.260
Right?

00:52:52.260 --> 00:52:56.700
There are some standard data
set out there and images.

00:52:56.700 --> 00:52:58.700
Of course, there's so
many objects in the world.

00:52:58.700 --> 00:52:58.930
Right?

00:52:58.930 --> 00:53:01.100
So if you need a classifier
for your job objective,

00:53:01.100 --> 00:53:05.480
we're talking multi- multi-
multi-class recognizers.

00:53:05.480 --> 00:53:07.630
They are in an acoustic
model where we also

00:53:07.630 --> 00:53:09.980
have hundreds of
thousands of classes.

00:53:09.980 --> 00:53:13.130
These are the two instances
when neural networks recently

00:53:13.130 --> 00:53:15.610
have outperformed anything else.

00:53:15.610 --> 00:53:19.340
So yes, neural networks can
be used for image recognition.

00:53:19.340 --> 00:53:20.820
It's not the only solution.

00:53:20.820 --> 00:53:24.570
I'm waiting for the
other learning algorithms

00:53:24.570 --> 00:53:27.182
to somehow dig in to
or find out what is it

00:53:27.182 --> 00:53:28.640
about the neural
networks that make

00:53:28.640 --> 00:53:31.430
them work so well
in these regimes?

00:53:31.430 --> 00:53:35.390
And how can we leverage that
incorporated in our learning

00:53:35.390 --> 00:53:38.435
algorithms, and be even better?

00:53:38.435 --> 00:53:38.976
AUDIENCE: OK.

00:53:38.976 --> 00:53:39.475
Awesome.

00:53:39.475 --> 00:53:40.684
Thank you.

00:53:40.684 --> 00:53:42.612
FEMALE SPEAKER 2: We'll
just take one more.

00:53:42.612 --> 00:53:44.060
CORINNA CORTES: OK.

00:53:44.060 --> 00:53:44.930
AUDIENCE: Hi.

00:53:44.930 --> 00:53:47.350
Thanks a lot for sharing
your experiences.

00:53:47.350 --> 00:53:50.340
I'm also a runner, so I
wanted to know, I guess,

00:53:50.340 --> 00:53:52.790
what made you pick
running as a hobby,

00:53:52.790 --> 00:53:56.280
and what parallels do you see
between your hobby, running,

00:53:56.280 --> 00:54:00.302
and your career as a
researcher at Google?

00:54:00.302 --> 00:54:01.760
CORINNA CORTES:
Running is so easy.

00:54:01.760 --> 00:54:03.500
Right?

00:54:03.500 --> 00:54:06.090
All you need is a
pair of running shoes.

00:54:06.090 --> 00:54:08.110
And they last a long time.

00:54:08.110 --> 00:54:11.830
There's no equipment you
otherwise need to buy.

00:54:11.830 --> 00:54:14.870
So that's one of the reasons
that I picked running.

00:54:14.870 --> 00:54:16.930
It's something you can
just go out and do.

00:54:19.720 --> 00:54:21.780
The other reason-- no,
I didn't pick running.

00:54:21.780 --> 00:54:24.670
It was actually, there were
some of these guys also,

00:54:24.670 --> 00:54:29.630
the vacuum cleaner guys.

00:54:29.630 --> 00:54:32.010
They were also running.

00:54:32.010 --> 00:54:35.530
So they actually not only
got me to change career,

00:54:35.530 --> 00:54:38.950
but they also got
me into running.

00:54:38.950 --> 00:54:40.460
But the reason I
stuck with running

00:54:40.460 --> 00:54:42.820
is probably because
it's so easy to do.

00:54:42.820 --> 00:54:44.610
I can do it at all
hours of the day.

00:54:44.610 --> 00:54:47.340
I can get up at 3 o'clock at
night, and I can go running.

00:54:47.340 --> 00:54:49.560
And I think it's great
for solving problems,

00:54:49.560 --> 00:54:53.250
because I'm out there
just with myself.

00:54:53.250 --> 00:54:55.670
I have to live with just myself.

00:54:55.670 --> 00:54:59.280
And I can take all the problems
that I have in my head,

00:54:59.280 --> 00:55:02.020
and I can turn them around.

00:55:02.020 --> 00:55:03.690
I can look at them.

00:55:03.690 --> 00:55:05.700
It's just the
miles and the miles

00:55:05.700 --> 00:55:08.900
and the miles and the miles.

00:55:08.900 --> 00:55:12.050
People that cannot interact,
the problems that I solve.

00:55:12.050 --> 00:55:15.000
I debugged a lot of
code out running.

00:55:15.000 --> 00:55:19.925
The space, the endlessness of
it, the calmness, the peace.

00:55:23.400 --> 00:55:25.110
I solve a lot of my
problems out there.

00:55:25.110 --> 00:55:27.030
I think it's good
for me as a manager.

00:55:27.030 --> 00:55:29.180
One thing I have noticed also.

00:55:29.180 --> 00:55:31.690
I run away from my family.

00:55:31.690 --> 00:55:33.580
I have to be honest.

00:55:33.580 --> 00:55:36.250
If they're not around, I
don't go running as much.

00:55:36.250 --> 00:55:39.850
[LAUGHTER]

00:55:39.850 --> 00:55:44.400
[APPLAUSE]

