WEBVTT
Kind: captions
Language: en

00:00:03.616 --> 00:00:06.180
KARTHIK KASHINATH: Extreme
weather is changing.

00:00:06.180 --> 00:00:10.090
There's more extreme rainfall,
heavy flooding, forest fires.

00:00:10.090 --> 00:00:12.400
There's the radio
signature, [INAUDIBLE]..

00:00:12.400 --> 00:00:15.520
Being able to predict these
extreme events more accurately

00:00:15.520 --> 00:00:18.750
is kind of the big challenge
that we're facing right now.

00:00:18.750 --> 00:00:21.430
There's 100 terabytes of
climate data every day

00:00:21.430 --> 00:00:23.815
from satellites, from
observations, from models.

00:00:23.815 --> 00:00:26.925
So climate data is
a big data problem.

00:00:26.925 --> 00:00:28.300
We need things
that are fast that

00:00:28.300 --> 00:00:31.500
can sift through all of that
data rapidly and accurately.

00:00:31.500 --> 00:00:34.018
And deep learning is almost
perfectly poised for problems

00:00:34.018 --> 00:00:34.810
in climate science.

00:00:39.190 --> 00:00:42.010
THORSTEN KURTH: A lot of NERSC
users are using TensorFlow.

00:00:42.010 --> 00:00:44.470
It's one of the more
popular frameworks.

00:00:44.470 --> 00:00:46.720
We use TensorFlow
to iterate quickly

00:00:46.720 --> 00:00:50.230
over the different models,
different layer parameters.

00:00:50.230 --> 00:00:51.730
For this particular
climate project,

00:00:51.730 --> 00:00:53.250
to create the deep
learning model,

00:00:53.250 --> 00:00:55.220
we started from
segmentation models,

00:00:55.220 --> 00:00:57.430
which have proven
to be successful,

00:00:57.430 --> 00:01:00.610
for example, our satellite
imagery segmentation tasks.

00:01:00.610 --> 00:01:02.920
And then we use TensorFlow
to enhance the models

00:01:02.920 --> 00:01:05.410
until we found a set of
models to perform well

00:01:05.410 --> 00:01:07.880
enough for this specific task.

00:01:07.880 --> 00:01:10.390
But for the volume of the
data, complexity of the data,

00:01:10.390 --> 00:01:12.910
the network required
14 teraflops.

00:01:12.910 --> 00:01:14.880
So if you want to do
this on your workstation,

00:01:14.880 --> 00:01:17.050
it would take months to train.

00:01:17.050 --> 00:01:19.300
MIKE HOUSTON: To really
tackle these problems requires

00:01:19.300 --> 00:01:20.983
the largest computational
resources that

00:01:20.983 --> 00:01:22.150
are available on the planet.

00:01:22.150 --> 00:01:24.295
So systems like the
Summit supercomputer,

00:01:24.295 --> 00:01:26.530
it's two tennis
courts in total size.

00:01:26.530 --> 00:01:28.370
I mean, this thing
is state-of-the-art.

00:01:28.370 --> 00:01:31.300
It's a million times faster
than your common laptop.

00:01:31.300 --> 00:01:33.625
3.3 exaflops.

00:01:33.625 --> 00:01:35.500
Just imagine what you
do at your workstation,

00:01:35.500 --> 00:01:39.040
but now imagine having
27,000 times that power.

00:01:39.040 --> 00:01:40.150
We can do that now.

00:01:40.150 --> 00:01:42.400
THORSTEN KURTH: We were
surprised how good it actually

00:01:42.400 --> 00:01:43.000
scales.

00:01:43.000 --> 00:01:44.730
1,000 nodes, then 2,000 nodes.

00:01:44.730 --> 00:01:45.790
5,000 nodes.

00:01:45.790 --> 00:01:47.332
MIKE HOUSTON: This
was the first time

00:01:47.332 --> 00:01:49.690
anybody's ever run an AI
application at this scale.

00:01:49.690 --> 00:01:52.210
Instead of having the
climate scientists figure out

00:01:52.210 --> 00:01:53.980
how to write high
tune code, they

00:01:53.980 --> 00:01:56.600
could express things in a
very natural way in Python,

00:01:56.600 --> 00:01:58.930
in TensorFlow, and get all
the high performance code

00:01:58.930 --> 00:02:01.502
that most HPC people are
used to within TensorFlow.

00:02:01.502 --> 00:02:03.710
KARTHIK KASHINATH: We're
now entering the space where

00:02:03.710 --> 00:02:06.130
AI can actually contribute
to the predictions

00:02:06.130 --> 00:02:08.798
of these extreme weather events.

00:02:08.798 --> 00:02:11.090
MIKE HOUSTON: When you combine
traditional HPC with AI,

00:02:11.090 --> 00:02:13.750
you can tackle things we never
thought that we could tackle.

00:02:13.750 --> 00:02:17.140
Fusion reactor research,
understanding diseases

00:02:17.140 --> 00:02:19.810
like Alzheimer's, cancer, right?

00:02:19.810 --> 00:02:21.050
That's incredible.

00:02:21.050 --> 00:02:23.342
THORSTEN KURTH: We've shown
that with the hyperactivity

00:02:23.342 --> 00:02:25.900
framework such as TensorFlow,
you can get to massive scale,

00:02:25.900 --> 00:02:27.670
and you can get
awesome performance

00:02:27.670 --> 00:02:29.200
and accomplish your goals.

00:02:29.200 --> 00:02:31.450
KARTHIK KASHINATH: Genetics,
neuroscience, cosmology,

00:02:31.450 --> 00:02:36.510
high energy physics, that is
immensely exciting for me.

