WEBVTT
Kind: captions
Language: en

00:00:02.080 --> 00:00:05.269
 
I want to bring this part of the class

00:00:05.269 --> 00:00:05.279
I want to bring this part of the class
 

00:00:05.279 --> 00:00:07.889
I want to bring this part of the class
to an end so this is our last lecture

00:00:07.889 --> 00:00:07.899
to an end so this is our last lecture
 

00:00:07.899 --> 00:00:10.020
to an end so this is our last lecture
but for our series of guest lectures and

00:00:10.020 --> 00:00:10.030
but for our series of guest lectures and
 

00:00:10.030 --> 00:00:13.080
but for our series of guest lectures and
in this talk I hope to address some of

00:00:13.080 --> 00:00:13.090
in this talk I hope to address some of
 

00:00:13.090 --> 00:00:14.640
in this talk I hope to address some of
the state of deep learning today and

00:00:14.640 --> 00:00:14.650
the state of deep learning today and
 

00:00:14.650 --> 00:00:16.049
the state of deep learning today and
kind of bring up some of the limitations

00:00:16.049 --> 00:00:16.059
kind of bring up some of the limitations
 

00:00:16.059 --> 00:00:18.030
kind of bring up some of the limitations
of the algorithms that you've been

00:00:18.030 --> 00:00:18.040
of the algorithms that you've been
 

00:00:18.040 --> 00:00:19.560
of the algorithms that you've been
seeing in this class so far so we got a

00:00:19.560 --> 00:00:19.570
seeing in this class so far so we got a
 

00:00:19.570 --> 00:00:20.779
seeing in this class so far so we got a
really good taste of some of the

00:00:20.779 --> 00:00:20.789
really good taste of some of the
 

00:00:20.789 --> 00:00:22.470
really good taste of some of the
limitations specifically in

00:00:22.470 --> 00:00:22.480
limitations specifically in
 

00:00:22.480 --> 00:00:24.960
limitations specifically in
reinforcement learning algorithms that

00:00:24.960 --> 00:00:24.970
reinforcement learning algorithms that
 

00:00:24.970 --> 00:00:27.060
reinforcement learning algorithms that
Lex gave in the last lecture and that's

00:00:27.060 --> 00:00:27.070
Lex gave in the last lecture and that's
 

00:00:27.070 --> 00:00:29.820
Lex gave in the last lecture and that's
really going to build on or I'm gonna

00:00:29.820 --> 00:00:29.830
really going to build on or I'm gonna
 

00:00:29.830 --> 00:00:31.919
really going to build on or I'm gonna
use that to build on top of during this

00:00:31.919 --> 00:00:31.929
use that to build on top of during this
 

00:00:31.929 --> 00:00:34.229
use that to build on top of during this
lecture and just to end on I'm gonna

00:00:34.229 --> 00:00:34.239
lecture and just to end on I'm gonna
 

00:00:34.239 --> 00:00:36.509
lecture and just to end on I'm gonna
bring you I'm gonna introduce you to

00:00:36.509 --> 00:00:36.519
bring you I'm gonna introduce you to
 

00:00:36.519 --> 00:00:39.990
bring you I'm gonna introduce you to
some new frontiers in deep learning that

00:00:39.990 --> 00:00:40.000
some new frontiers in deep learning that
 

00:00:40.000 --> 00:00:41.910
some new frontiers in deep learning that
are really really inspiring it and at

00:00:41.910 --> 00:00:41.920
are really really inspiring it and at
 

00:00:41.920 --> 00:00:45.140
are really really inspiring it and at
the cutting edge of research today

00:00:45.140 --> 00:00:45.150
the cutting edge of research today
 

00:00:45.150 --> 00:00:48.990
the cutting edge of research today
before we do that I'd like to just make

00:00:48.990 --> 00:00:49.000
before we do that I'd like to just make
 

00:00:49.000 --> 00:00:51.750
before we do that I'd like to just make
some administrative announcements so

00:00:51.750 --> 00:00:51.760
some administrative announcements so
 

00:00:51.760 --> 00:00:53.009
some administrative announcements so
t-shirts have arrived and we'll be

00:00:53.009 --> 00:00:53.019
t-shirts have arrived and we'll be
 

00:00:53.019 --> 00:00:54.840
t-shirts have arrived and we'll be
distributing them today and we'd like to

00:00:54.840 --> 00:00:54.850
distributing them today and we'd like to
 

00:00:54.850 --> 00:00:57.030
distributing them today and we'd like to
distribute first to the registered for

00:00:57.030 --> 00:00:57.040
distribute first to the registered for
 

00:00:57.040 --> 00:01:00.810
distribute first to the registered for
credit students after that we will be

00:01:00.810 --> 00:01:00.820
credit students after that we will be
 

00:01:00.820 --> 00:01:02.160
credit students after that we will be
happy to distribute to registered

00:01:02.160 --> 00:01:02.170
happy to distribute to registered
 

00:01:02.170 --> 00:01:03.719
happy to distribute to registered
listeners and then after that if there's

00:01:03.719 --> 00:01:03.729
listeners and then after that if there's
 

00:01:03.729 --> 00:01:05.009
listeners and then after that if there's
any remaining we'll give out to

00:01:05.009 --> 00:01:05.019
any remaining we'll give out to
 

00:01:05.019 --> 00:01:06.720
any remaining we'll give out to
listeners if they'd want if they're

00:01:06.720 --> 00:01:06.730
listeners if they'd want if they're
 

00:01:06.730 --> 00:01:10.980
listeners if they'd want if they're
interested so for those of you who are

00:01:10.980 --> 00:01:10.990
interested so for those of you who are
 

00:01:10.990 --> 00:01:12.570
interested so for those of you who are
taking this class for credit I need to

00:01:12.570 --> 00:01:12.580
taking this class for credit I need to
 

00:01:12.580 --> 00:01:16.200
taking this class for credit I need to
reiterate what kind of options you have

00:01:16.200 --> 00:01:16.210
reiterate what kind of options you have
 

00:01:16.210 --> 00:01:17.670
reiterate what kind of options you have
to actually fulfill your credit

00:01:17.670 --> 00:01:17.680
to actually fulfill your credit
 

00:01:17.680 --> 00:01:19.860
to actually fulfill your credit
requirement so the first option is a

00:01:19.860 --> 00:01:19.870
requirement so the first option is a
 

00:01:19.870 --> 00:01:22.950
requirement so the first option is a
group project proposal presentation so

00:01:22.950 --> 00:01:22.960
group project proposal presentation so
 

00:01:22.960 --> 00:01:24.060
group project proposal presentation so
for this option you'll be given the

00:01:24.060 --> 00:01:24.070
for this option you'll be given the
 

00:01:24.070 --> 00:01:25.710
for this option you'll be given the
opportunity to pitch a novel deep

00:01:25.710 --> 00:01:25.720
opportunity to pitch a novel deep
 

00:01:25.720 --> 00:01:27.960
opportunity to pitch a novel deep
learning idea to a panel of judges on

00:01:27.960 --> 00:01:27.970
learning idea to a panel of judges on
 

00:01:27.970 --> 00:01:31.230
learning idea to a panel of judges on
Friday you'll have exactly one minute to

00:01:31.230 --> 00:01:31.240
Friday you'll have exactly one minute to
 

00:01:31.240 --> 00:01:33.570
Friday you'll have exactly one minute to
make your pitch as clear error as clear

00:01:33.570 --> 00:01:33.580
make your pitch as clear error as clear
 

00:01:33.580 --> 00:01:36.180
make your pitch as clear error as clear
and as concisely as possible so this is

00:01:36.180 --> 00:01:36.190
and as concisely as possible so this is
 

00:01:36.190 --> 00:01:37.890
and as concisely as possible so this is
really difficult to do in one minute and

00:01:37.890 --> 00:01:37.900
really difficult to do in one minute and
 

00:01:37.900 --> 00:01:39.810
really difficult to do in one minute and
this kind of one of the challenges that

00:01:39.810 --> 00:01:39.820
this kind of one of the challenges that
 

00:01:39.820 --> 00:01:41.880
this kind of one of the challenges that
were we're putting on you in addition to

00:01:41.880 --> 00:01:41.890
were we're putting on you in addition to
 

00:01:41.890 --> 00:01:43.560
were we're putting on you in addition to
actually coming up with the deep

00:01:43.560 --> 00:01:43.570
actually coming up with the deep
 

00:01:43.570 --> 00:01:47.070
actually coming up with the deep
learning idea itself if you want to go

00:01:47.070 --> 00:01:47.080
learning idea itself if you want to go
 

00:01:47.080 --> 00:01:49.010
learning idea itself if you want to go
down this route for your final project

00:01:49.010 --> 00:01:49.020
down this route for your final project
 

00:01:49.020 --> 00:01:51.540
down this route for your final project
then you'll need to submit your teams

00:01:51.540 --> 00:01:51.550
then you'll need to submit your teams
 

00:01:51.550 --> 00:01:53.820
then you'll need to submit your teams
which have to be of size three or four

00:01:53.820 --> 00:01:53.830
which have to be of size three or four
 

00:01:53.830 --> 00:01:55.710
which have to be of size three or four
by the end of today so at 9:00 p.m.

00:01:55.710 --> 00:01:55.720
by the end of today so at 9:00 p.m.
 

00:01:55.720 --> 00:01:59.610
by the end of today so at 9:00 p.m.
today we'd like those in you'll have to

00:01:59.610 --> 00:01:59.620
today we'd like those in you'll have to
 

00:01:59.620 --> 00:02:01.350
today we'd like those in you'll have to
do teams of three or four so if you want

00:02:01.350 --> 00:02:01.360
do teams of three or four so if you want
 

00:02:01.360 --> 00:02:03.120
do teams of three or four so if you want
a group working in groups of one or two

00:02:03.120 --> 00:02:03.130
a group working in groups of one or two
 

00:02:03.130 --> 00:02:05.370
a group working in groups of one or two
then you'll have to you're you're

00:02:05.370 --> 00:02:05.380
then you'll have to you're you're
 

00:02:05.380 --> 00:02:06.780
then you'll have to you're you're
welcome to do that but you won't be able

00:02:06.780 --> 00:02:06.790
welcome to do that but you won't be able
 

00:02:06.790 --> 00:02:09.899
welcome to do that but you won't be able
to actually submit your final project as

00:02:09.899 --> 00:02:09.909
to actually submit your final project as
 

00:02:09.909 --> 00:02:12.510
to actually submit your final project as
part of a presentation on Friday you can

00:02:12.510 --> 00:02:12.520
part of a presentation on Friday you can
 

00:02:12.520 --> 00:02:15.000
part of a presentation on Friday you can
submit it to us and we'll we'll give you

00:02:15.000 --> 00:02:15.010
submit it to us and we'll we'll give you
 

00:02:15.010 --> 00:02:15.809
submit it to us and we'll we'll give you
the grade for the class

00:02:15.809 --> 00:02:15.819
the grade for the class
 

00:02:15.819 --> 00:02:19.920
the grade for the class
like that so groups are due 9:00 p.m.

00:02:19.920 --> 00:02:19.930
like that so groups are due 9:00 p.m.
 

00:02:19.930 --> 00:02:22.110
like that so groups are due 9:00 p.m.
today and you have to submit your slides

00:02:22.110 --> 00:02:22.120
today and you have to submit your slides
 

00:02:22.120 --> 00:02:24.239
today and you have to submit your slides
by 9:00 p.m. tomorrow presentations are

00:02:24.239 --> 00:02:24.249
by 9:00 p.m. tomorrow presentations are
 

00:02:24.249 --> 00:02:27.959
by 9:00 p.m. tomorrow presentations are
at class on Friday in this room if you

00:02:27.959 --> 00:02:27.969
at class on Friday in this room if you
 

00:02:27.969 --> 00:02:29.059
at class on Friday in this room if you
don't want to do a project for

00:02:29.059 --> 00:02:29.069
don't want to do a project for
 

00:02:29.069 --> 00:02:30.809
don't want to do a project for
presentation you have a second option

00:02:30.809 --> 00:02:30.819
presentation you have a second option
 

00:02:30.819 --> 00:02:32.849
presentation you have a second option
which is to write a one-page paper

00:02:32.849 --> 00:02:32.859
which is to write a one-page paper
 

00:02:32.859 --> 00:02:35.819
which is to write a one-page paper
review of a deep learning idea so any

00:02:35.819 --> 00:02:35.829
review of a deep learning idea so any
 

00:02:35.829 --> 00:02:38.429
review of a deep learning idea so any
idea or any paper that you find

00:02:38.429 --> 00:02:38.439
idea or any paper that you find
 

00:02:38.439 --> 00:02:40.770
idea or any paper that you find
interesting is is welcome here so we

00:02:40.770 --> 00:02:40.780
interesting is is welcome here so we
 

00:02:40.780 --> 00:02:42.209
interesting is is welcome here so we
really accept anything and we're really

00:02:42.209 --> 00:02:42.219
really accept anything and we're really
 

00:02:42.219 --> 00:02:45.979
really accept anything and we're really
free in this in this option as well I

00:02:45.979 --> 00:02:45.989
free in this in this option as well I
 

00:02:45.989 --> 00:02:48.629
free in this in this option as well I
want to highlight some of the exciting

00:02:48.629 --> 00:02:48.639
want to highlight some of the exciting
 

00:02:48.639 --> 00:02:50.640
want to highlight some of the exciting
new talks that we have coming up after

00:02:50.640 --> 00:02:50.650
new talks that we have coming up after
 

00:02:50.650 --> 00:02:53.129
new talks that we have coming up after
today so tomorrow will have two sets of

00:02:53.129 --> 00:02:53.139
today so tomorrow will have two sets of
 

00:02:53.139 --> 00:02:54.390
today so tomorrow will have two sets of
guest lectures first we'll hear from

00:02:54.390 --> 00:02:54.400
guest lectures first we'll hear from
 

00:02:54.400 --> 00:02:57.000
guest lectures first we'll hear from
aura's Muller who is the chief architect

00:02:57.000 --> 00:02:57.010
aura's Muller who is the chief architect
 

00:02:57.010 --> 00:03:00.539
aura's Muller who is the chief architect
of nvidia x' self-driving car team so

00:03:00.539 --> 00:03:00.549
of nvidia x' self-driving car team so
 

00:03:00.549 --> 00:03:02.069
of nvidia x' self-driving car team so
hers and his team were actually known

00:03:02.069 --> 00:03:02.079
hers and his team were actually known
 

00:03:02.079 --> 00:03:04.050
hers and his team were actually known
for some really exciting work that abu

00:03:04.050 --> 00:03:04.060
for some really exciting work that abu
 

00:03:04.060 --> 00:03:06.509
for some really exciting work that abu
is showing yesterday during her lecture

00:03:06.509 --> 00:03:06.519
is showing yesterday during her lecture
 

00:03:06.519 --> 00:03:08.309
is showing yesterday during her lecture
and they're known for this development

00:03:08.309 --> 00:03:08.319
and they're known for this development
 

00:03:08.319 --> 00:03:10.110
and they're known for this development
of an end-to-end platform for autonomous

00:03:10.110 --> 00:03:10.120
of an end-to-end platform for autonomous
 

00:03:10.120 --> 00:03:13.020
of an end-to-end platform for autonomous
driving that takes directly image data

00:03:13.020 --> 00:03:13.030
driving that takes directly image data
 

00:03:13.030 --> 00:03:15.300
driving that takes directly image data
and produces a steering control command

00:03:15.300 --> 00:03:15.310
and produces a steering control command
 

00:03:15.310 --> 00:03:17.270
and produces a steering control command
at the car for the car at the output

00:03:17.270 --> 00:03:17.280
at the car for the car at the output
 

00:03:17.280 --> 00:03:20.039
at the car for the car at the output
then we'll hear about we'll hear from

00:03:20.039 --> 00:03:20.049
then we'll hear about we'll hear from
 

00:03:20.049 --> 00:03:22.259
then we'll hear about we'll hear from
two Google brain researchers on recent

00:03:22.259 --> 00:03:22.269
two Google brain researchers on recent
 

00:03:22.269 --> 00:03:24.689
two Google brain researchers on recent
advancements on image classification at

00:03:24.689 --> 00:03:24.699
advancements on image classification at
 

00:03:24.699 --> 00:03:27.240
advancements on image classification at
Google and also we'll hear about some

00:03:27.240 --> 00:03:27.250
Google and also we'll hear about some
 

00:03:27.250 --> 00:03:29.969
Google and also we'll hear about some
super recent advancements and additions

00:03:29.969 --> 00:03:29.979
super recent advancements and additions
 

00:03:29.979 --> 00:03:32.069
super recent advancements and additions
to the tensorflow pipeline that were

00:03:32.069 --> 00:03:32.079
to the tensorflow pipeline that were
 

00:03:32.079 --> 00:03:34.080
to the tensorflow pipeline that were
actually just released a couple days ago

00:03:34.080 --> 00:03:34.090
actually just released a couple days ago
 

00:03:34.090 --> 00:03:36.979
actually just released a couple days ago
so this is really really new stuff

00:03:36.979 --> 00:03:36.989
so this is really really new stuff
 

00:03:36.989 --> 00:03:39.030
so this is really really new stuff
tomorrow afternoon we'll get together

00:03:39.030 --> 00:03:39.040
tomorrow afternoon we'll get together
 

00:03:39.040 --> 00:03:40.979
tomorrow afternoon we'll get together
for one of the most exciting parts of

00:03:40.979 --> 00:03:40.989
for one of the most exciting parts of
 

00:03:40.989 --> 00:03:44.789
for one of the most exciting parts of
this class so what will happen is we'll

00:03:44.789 --> 00:03:44.799
this class so what will happen is we'll
 

00:03:44.799 --> 00:03:46.229
this class so what will happen is we'll
have each of the sponsors actually come

00:03:46.229 --> 00:03:46.239
have each of the sponsors actually come
 

00:03:46.239 --> 00:03:48.300
have each of the sponsors actually come
up to the front of the class here we

00:03:48.300 --> 00:03:48.310
up to the front of the class here we
 

00:03:48.310 --> 00:03:50.069
up to the front of the class here we
have four sponsors that will present on

00:03:50.069 --> 00:03:50.079
have four sponsors that will present on
 

00:03:50.079 --> 00:03:52.289
have four sponsors that will present on
each of these four boards and you'll be

00:03:52.289 --> 00:03:52.299
each of these four boards and you'll be
 

00:03:52.299 --> 00:03:53.280
each of these four boards and you'll be
given the opportunity to basically

00:03:53.280 --> 00:03:53.290
given the opportunity to basically
 

00:03:53.290 --> 00:03:56.240
given the opportunity to basically
connect with each of them through the

00:03:56.240 --> 00:03:56.250
connect with each of them through the
 

00:03:56.250 --> 00:03:58.679
connect with each of them through the
through the ways of a recruitment booth

00:03:58.679 --> 00:03:58.689
through the ways of a recruitment booth
 

00:03:58.689 --> 00:03:59.939
through the ways of a recruitment booth
and basically they're going to be

00:03:59.939 --> 00:03:59.949
and basically they're going to be
 

00:03:59.949 --> 00:04:01.979
and basically they're going to be
looking at students that might be

00:04:01.979 --> 00:04:01.989
looking at students that might be
 

00:04:01.989 --> 00:04:04.110
looking at students that might be
interested in deep learning internships

00:04:04.110 --> 00:04:04.120
interested in deep learning internships
 

00:04:04.120 --> 00:04:06.629
interested in deep learning internships
or employment opportunities so this is

00:04:06.629 --> 00:04:06.639
or employment opportunities so this is
 

00:04:06.639 --> 00:04:08.459
or employment opportunities so this is
really an incredible opportunity for you

00:04:08.459 --> 00:04:08.469
really an incredible opportunity for you
 

00:04:08.469 --> 00:04:11.309
really an incredible opportunity for you
guys to connect with these companies in

00:04:11.309 --> 00:04:11.319
guys to connect with these companies in
 

00:04:11.319 --> 00:04:14.099
guys to connect with these companies in
a very very very direct manner so we

00:04:14.099 --> 00:04:14.109
a very very very direct manner so we
 

00:04:14.109 --> 00:04:15.659
a very very very direct manner so we
highly recommend that you take advantage

00:04:15.659 --> 00:04:15.669
highly recommend that you take advantage
 

00:04:15.669 --> 00:04:18.810
highly recommend that you take advantage
of that there will be info sessions with

00:04:18.810 --> 00:04:18.820
of that there will be info sessions with
 

00:04:18.820 --> 00:04:21.330
of that there will be info sessions with
pizza provided on Thursday with one of

00:04:21.330 --> 00:04:21.340
pizza provided on Thursday with one of
 

00:04:21.340 --> 00:04:22.890
pizza provided on Thursday with one of
these guest lectures with one of these

00:04:22.890 --> 00:04:22.900
these guest lectures with one of these
 

00:04:22.900 --> 00:04:25.620
these guest lectures with one of these
industry companies and we'll be sending

00:04:25.620 --> 00:04:25.630
industry companies and we'll be sending
 

00:04:25.630 --> 00:04:29.320
industry companies and we'll be sending
out more details with that today as well

00:04:29.320 --> 00:04:29.330
out more details with that today as well
 

00:04:29.330 --> 00:04:31.390
out more details with that today as well
so on Friday we'll continue with the

00:04:31.390 --> 00:04:31.400
so on Friday we'll continue with the
 

00:04:31.400 --> 00:04:32.890
so on Friday we'll continue with the
guest lectures and hear from Lisa and

00:04:32.890 --> 00:04:32.900
guest lectures and hear from Lisa and
 

00:04:32.900 --> 00:04:35.170
guest lectures and hear from Lisa and
meanie who is the head of IBM Research

00:04:35.170 --> 00:04:35.180
meanie who is the head of IBM Research
 

00:04:35.180 --> 00:04:39.600
meanie who is the head of IBM Research
in Cambridge she's actually also the

00:04:39.600 --> 00:04:39.610
in Cambridge she's actually also the
 

00:04:39.610 --> 00:04:43.600
in Cambridge she's actually also the
director of the MIT IBM lab and this is

00:04:43.600 --> 00:04:43.610
director of the MIT IBM lab and this is
 

00:04:43.610 --> 00:04:47.050
director of the MIT IBM lab and this is
a lab that was just founded a couple or

00:04:47.050 --> 00:04:47.060
a lab that was just founded a couple or
 

00:04:47.060 --> 00:04:48.640
a lab that was just founded a couple or
actually about a month ago or two months

00:04:48.640 --> 00:04:48.650
actually about a month ago or two months
 

00:04:48.650 --> 00:04:49.379
actually about a month ago or two months
ago

00:04:49.379 --> 00:04:49.389
ago
 

00:04:49.389 --> 00:04:52.570
ago
we'll be hearing about how IBM is

00:04:52.570 --> 00:04:52.580
we'll be hearing about how IBM is
 

00:04:52.580 --> 00:04:54.640
we'll be hearing about how IBM is
creating AI systems that are capable of

00:04:54.640 --> 00:04:54.650
creating AI systems that are capable of
 

00:04:54.650 --> 00:04:56.260
creating AI systems that are capable of
not only deep learning but going a step

00:04:56.260 --> 00:04:56.270
not only deep learning but going a step
 

00:04:56.270 --> 00:04:58.899
not only deep learning but going a step
past deep learning they're capable of or

00:04:58.899 --> 00:04:58.909
past deep learning they're capable of or
 

00:04:58.909 --> 00:05:00.939
past deep learning they're capable of or
trying to be capable of learning and

00:05:00.939 --> 00:05:00.949
trying to be capable of learning and
 

00:05:00.949 --> 00:05:03.540
trying to be capable of learning and
recently on a higher-order sense and

00:05:03.540 --> 00:05:03.550
recently on a higher-order sense and
 

00:05:03.550 --> 00:05:06.040
recently on a higher-order sense and
then finally we'll hear from a principal

00:05:06.040 --> 00:05:06.050
then finally we'll hear from a principal
 

00:05:06.050 --> 00:05:08.770
then finally we'll hear from a principal
researcher at $0.10 AI lab about

00:05:08.770 --> 00:05:08.780
researcher at $0.10 AI lab about
 

00:05:08.780 --> 00:05:10.659
researcher at $0.10 AI lab about
combining computer vision and social

00:05:10.659 --> 00:05:10.669
combining computer vision and social
 

00:05:10.669 --> 00:05:13.570
combining computer vision and social
networks it's a very interesting topic

00:05:13.570 --> 00:05:13.580
networks it's a very interesting topic
 

00:05:13.580 --> 00:05:15.100
networks it's a very interesting topic
that we haven't really touched upon in

00:05:15.100 --> 00:05:15.110
that we haven't really touched upon in
 

00:05:15.110 --> 00:05:17.950
that we haven't really touched upon in
this class this topic of social networks

00:05:17.950 --> 00:05:17.960
this class this topic of social networks
 

00:05:17.960 --> 00:05:20.140
this class this topic of social networks
and using massive big data collected

00:05:20.140 --> 00:05:20.150
and using massive big data collected
 

00:05:20.150 --> 00:05:24.430
and using massive big data collected
from from humans themselves and then as

00:05:24.430 --> 00:05:24.440
from from humans themselves and then as
 

00:05:24.440 --> 00:05:25.959
from from humans themselves and then as
I mentioned before in the afternoon

00:05:25.959 --> 00:05:25.969
I mentioned before in the afternoon
 

00:05:25.969 --> 00:05:27.100
I mentioned before in the afternoon
we'll go through and hear about the

00:05:27.100 --> 00:05:27.110
we'll go through and hear about the
 

00:05:27.110 --> 00:05:28.570
we'll go through and hear about the
final project presentations we'll

00:05:28.570 --> 00:05:28.580
final project presentations we'll
 

00:05:28.580 --> 00:05:30.520
final project presentations we'll
celebrate with some pizza and the awards

00:05:30.520 --> 00:05:30.530
celebrate with some pizza and the awards
 

00:05:30.530 --> 00:05:32.219
celebrate with some pizza and the awards
that will be given out to the top

00:05:32.219 --> 00:05:32.229
that will be given out to the top
 

00:05:32.229 --> 00:05:34.839
that will be given out to the top
projects during those during that

00:05:34.839 --> 00:05:34.849
projects during those during that
 

00:05:34.849 --> 00:05:38.260
projects during those during that
session as well so now let's start with

00:05:38.260 --> 00:05:38.270
session as well so now let's start with
 

00:05:38.270 --> 00:05:41.439
session as well so now let's start with
the technical content for this class I'd

00:05:41.439 --> 00:05:41.449
the technical content for this class I'd
 

00:05:41.449 --> 00:05:43.659
the technical content for this class I'd
like to start by just kind of over

00:05:43.659 --> 00:05:43.669
like to start by just kind of over
 

00:05:43.669 --> 00:05:45.909
like to start by just kind of over
viewing the type of architectures that

00:05:45.909 --> 00:05:45.919
viewing the type of architectures that
 

00:05:45.919 --> 00:05:48.519
viewing the type of architectures that
we've talked about so far for the most

00:05:48.519 --> 00:05:48.529
we've talked about so far for the most
 

00:05:48.529 --> 00:05:49.899
we've talked about so far for the most
part these architectures can be thought

00:05:49.899 --> 00:05:49.909
part these architectures can be thought
 

00:05:49.909 --> 00:05:51.360
part these architectures can be thought
of almost pattern-recognition

00:05:51.360 --> 00:05:51.370
of almost pattern-recognition
 

00:05:51.370 --> 00:05:54.189
of almost pattern-recognition
architectures so they take as input data

00:05:54.189 --> 00:05:54.199
architectures so they take as input data
 

00:05:54.199 --> 00:05:57.790
architectures so they take as input data
and the whole point of their pipeline

00:05:57.790 --> 00:05:57.800
and the whole point of their pipeline
 

00:05:57.800 --> 00:06:00.969
and the whole point of their pipeline
their internals are performing feature

00:06:00.969 --> 00:06:00.979
their internals are performing feature
 

00:06:00.979 --> 00:06:02.800
their internals are performing feature
extraction and and what they're really

00:06:02.800 --> 00:06:02.810
extraction and and what they're really
 

00:06:02.810 --> 00:06:04.450
extraction and and what they're really
doing is taking all the sensory data

00:06:04.450 --> 00:06:04.460
doing is taking all the sensory data
 

00:06:04.460 --> 00:06:05.709
doing is taking all the sensory data
trying to figure out what are the

00:06:05.709 --> 00:06:05.719
trying to figure out what are the
 

00:06:05.719 --> 00:06:07.360
trying to figure out what are the
important pieces what are the patterns

00:06:07.360 --> 00:06:07.370
important pieces what are the patterns
 

00:06:07.370 --> 00:06:09.670
important pieces what are the patterns
to be learned within the data such that

00:06:09.670 --> 00:06:09.680
to be learned within the data such that
 

00:06:09.680 --> 00:06:11.320
to be learned within the data such that
they can produce a decision at the

00:06:11.320 --> 00:06:11.330
they can produce a decision at the
 

00:06:11.330 --> 00:06:13.600
they can produce a decision at the
output we've seen this take many forms

00:06:13.600 --> 00:06:13.610
output we've seen this take many forms
 

00:06:13.610 --> 00:06:16.330
output we've seen this take many forms
so the decision could be a prediction it

00:06:16.330 --> 00:06:16.340
so the decision could be a prediction it
 

00:06:16.340 --> 00:06:18.159
so the decision could be a prediction it
could be a detection or even an action

00:06:18.159 --> 00:06:18.169
could be a detection or even an action
 

00:06:18.169 --> 00:06:19.420
could be a detection or even an action
like an agree enforcement learning

00:06:19.420 --> 00:06:19.430
like an agree enforcement learning
 

00:06:19.430 --> 00:06:21.760
like an agree enforcement learning
setting we've even learned how these

00:06:21.760 --> 00:06:21.770
setting we've even learned how these
 

00:06:21.770 --> 00:06:24.040
setting we've even learned how these
models can be viewed in a generative

00:06:24.040 --> 00:06:24.050
models can be viewed in a generative
 

00:06:24.050 --> 00:06:26.290
models can be viewed in a generative
sense to go in the opposite direction it

00:06:26.290 --> 00:06:26.300
sense to go in the opposite direction it
 

00:06:26.300 --> 00:06:31.029
sense to go in the opposite direction it
actually generate new synthetic data but

00:06:31.029 --> 00:06:31.039
actually generate new synthetic data but
 

00:06:31.039 --> 00:06:32.469
actually generate new synthetic data but
in general we've been dealing with

00:06:32.469 --> 00:06:32.479
in general we've been dealing with
 

00:06:32.479 --> 00:06:34.360
in general we've been dealing with
algorithms that are really optimized to

00:06:34.360 --> 00:06:34.370
algorithms that are really optimized to
 

00:06:34.370 --> 00:06:37.629
algorithms that are really optimized to
do well and only a single task but they

00:06:37.629 --> 00:06:37.639
do well and only a single task but they
 

00:06:37.639 --> 00:06:39.579
do well and only a single task but they
really fail to think like humans do

00:06:39.579 --> 00:06:39.589
really fail to think like humans do
 

00:06:39.589 --> 00:06:41.769
really fail to think like humans do
especially when we consider a higher

00:06:41.769 --> 00:06:41.779
especially when we consider a higher
 

00:06:41.779 --> 00:06:43.150
especially when we consider a higher
order level of an

00:06:43.150 --> 00:06:43.160
order level of an
 

00:06:43.160 --> 00:06:47.250
order level of an
telogen Slyke I defined on the first day

00:06:47.250 --> 00:06:47.260
 
 

00:06:47.260 --> 00:06:49.690
 
to understand this in a lot more detail

00:06:49.690 --> 00:06:49.700
to understand this in a lot more detail
 

00:06:49.700 --> 00:06:51.040
to understand this in a lot more detail
we have to go back to this very famous

00:06:51.040 --> 00:06:51.050
we have to go back to this very famous
 

00:06:51.050 --> 00:06:53.770
we have to go back to this very famous
theorem that was dating back almost 30

00:06:53.770 --> 00:06:53.780
theorem that was dating back almost 30
 

00:06:53.780 --> 00:06:57.100
theorem that was dating back almost 30
years from today this theorem which is

00:06:57.100 --> 00:06:57.110
years from today this theorem which is
 

00:06:57.110 --> 00:06:58.660
years from today this theorem which is
known as the universal approximation

00:06:58.660 --> 00:06:58.670
known as the universal approximation
 

00:06:58.670 --> 00:07:01.330
known as the universal approximation
theorem was one of the most impactful

00:07:01.330 --> 00:07:01.340
theorem was one of the most impactful
 

00:07:01.340 --> 00:07:03.520
theorem was one of the most impactful
theorems and neural networks when it

00:07:03.520 --> 00:07:03.530
theorems and neural networks when it
 

00:07:03.530 --> 00:07:05.380
theorems and neural networks when it
first came out because it had such a

00:07:05.380 --> 00:07:05.390
first came out because it had such a
 

00:07:05.390 --> 00:07:08.670
first came out because it had such a
profound it proved such a profound claim

00:07:08.670 --> 00:07:08.680
profound it proved such a profound claim
 

00:07:08.680 --> 00:07:11.020
profound it proved such a profound claim
what it states is that a neural network

00:07:11.020 --> 00:07:11.030
what it states is that a neural network
 

00:07:11.030 --> 00:07:13.810
what it states is that a neural network
with a single hidden layer is sufficient

00:07:13.810 --> 00:07:13.820
with a single hidden layer is sufficient
 

00:07:13.820 --> 00:07:16.150
with a single hidden layer is sufficient
to approximate any function to any

00:07:16.150 --> 00:07:16.160
to approximate any function to any
 

00:07:16.160 --> 00:07:19.090
to approximate any function to any
arbitrary level of accuracy now in this

00:07:19.090 --> 00:07:19.100
arbitrary level of accuracy now in this
 

00:07:19.100 --> 00:07:21.310
arbitrary level of accuracy now in this
class we deal with networks that are

00:07:21.310 --> 00:07:21.320
class we deal with networks that are
 

00:07:21.320 --> 00:07:23.200
class we deal with networks that are
deep they're not single layered so

00:07:23.200 --> 00:07:23.210
deep they're not single layered so
 

00:07:23.210 --> 00:07:24.280
deep they're not single layered so
they're actually more than a single

00:07:24.280 --> 00:07:24.290
they're actually more than a single
 

00:07:24.290 --> 00:07:26.080
they're actually more than a single
layer so actually they contain even more

00:07:26.080 --> 00:07:26.090
layer so actually they contain even more
 

00:07:26.090 --> 00:07:28.420
layer so actually they contain even more
complexity than the network down

00:07:28.420 --> 00:07:28.430
complexity than the network down
 

00:07:28.430 --> 00:07:30.400
complexity than the network down
referring to here but this theorem

00:07:30.400 --> 00:07:30.410
referring to here but this theorem
 

00:07:30.410 --> 00:07:34.480
referring to here but this theorem
proves that we actually only need one

00:07:34.480 --> 00:07:34.490
proves that we actually only need one
 

00:07:34.490 --> 00:07:37.330
proves that we actually only need one
layer to accomplish or to approximate

00:07:37.330 --> 00:07:37.340
layer to accomplish or to approximate
 

00:07:37.340 --> 00:07:39.430
layer to accomplish or to approximate
any function in the world and if you

00:07:39.430 --> 00:07:39.440
any function in the world and if you
 

00:07:39.440 --> 00:07:42.010
any function in the world and if you
believe that any problem can actually be

00:07:42.010 --> 00:07:42.020
believe that any problem can actually be
 

00:07:42.020 --> 00:07:44.080
believe that any problem can actually be
reduced to a sets of inputs and outputs

00:07:44.080 --> 00:07:44.090
reduced to a sets of inputs and outputs
 

00:07:44.090 --> 00:07:47.380
reduced to a sets of inputs and outputs
in this form of a function then this

00:07:47.380 --> 00:07:47.390
in this form of a function then this
 

00:07:47.390 --> 00:07:49.360
in this form of a function then this
theorem shows you that it's that a

00:07:49.360 --> 00:07:49.370
theorem shows you that it's that a
 

00:07:49.370 --> 00:07:50.860
theorem shows you that it's that a
neural network with just a single layer

00:07:50.860 --> 00:07:50.870
neural network with just a single layer
 

00:07:50.870 --> 00:07:53.320
neural network with just a single layer
is able to solve any problem in the

00:07:53.320 --> 00:07:53.330
is able to solve any problem in the
 

00:07:53.330 --> 00:07:56.140
is able to solve any problem in the
world now this is an incredibly powerful

00:07:56.140 --> 00:07:56.150
world now this is an incredibly powerful
 

00:07:56.150 --> 00:07:57.910
world now this is an incredibly powerful
result but if you look closely there are

00:07:57.910 --> 00:07:57.920
result but if you look closely there are
 

00:07:57.920 --> 00:08:00.550
result but if you look closely there are
a few very important caveats I'm not

00:08:00.550 --> 00:08:00.560
a few very important caveats I'm not
 

00:08:00.560 --> 00:08:02.650
a few very important caveats I'm not
actually telling you how large that

00:08:02.650 --> 00:08:02.660
actually telling you how large that
 

00:08:02.660 --> 00:08:04.300
actually telling you how large that
hidden layer has to be to accomplish

00:08:04.300 --> 00:08:04.310
hidden layer has to be to accomplish
 

00:08:04.310 --> 00:08:05.040
hidden layer has to be to accomplish
this task

00:08:05.040 --> 00:08:05.050
this task
 

00:08:05.050 --> 00:08:08.320
this task
now with the size of your problem the

00:08:08.320 --> 00:08:08.330
now with the size of your problem the
 

00:08:08.330 --> 00:08:09.820
now with the size of your problem the
hidden layer and the number of units in

00:08:09.820 --> 00:08:09.830
hidden layer and the number of units in
 

00:08:09.830 --> 00:08:11.800
hidden layer and the number of units in
that hidden layer may be exponentially

00:08:11.800 --> 00:08:11.810
that hidden layer may be exponentially
 

00:08:11.810 --> 00:08:13.150
that hidden layer may be exponentially
large and they'll grow exponentially

00:08:13.150 --> 00:08:13.160
large and they'll grow exponentially
 

00:08:13.160 --> 00:08:15.580
large and they'll grow exponentially
with the difficulty of your problem

00:08:15.580 --> 00:08:15.590
with the difficulty of your problem
 

00:08:15.590 --> 00:08:17.710
with the difficulty of your problem
this makes training that network very

00:08:17.710 --> 00:08:17.720
this makes training that network very
 

00:08:17.720 --> 00:08:19.390
this makes training that network very
difficult so I never actually told you

00:08:19.390 --> 00:08:19.400
difficult so I never actually told you
 

00:08:19.400 --> 00:08:21.280
difficult so I never actually told you
anything about how to obtain that

00:08:21.280 --> 00:08:21.290
anything about how to obtain that
 

00:08:21.290 --> 00:08:23.980
anything about how to obtain that
Network I just told you that it existed

00:08:23.980 --> 00:08:23.990
Network I just told you that it existed
 

00:08:23.990 --> 00:08:26.080
Network I just told you that it existed
and there is a possible network in the

00:08:26.080 --> 00:08:26.090
and there is a possible network in the
 

00:08:26.090 --> 00:08:27.700
and there is a possible network in the
realm of all neural networks that could

00:08:27.700 --> 00:08:27.710
realm of all neural networks that could
 

00:08:27.710 --> 00:08:29.770
realm of all neural networks that could
solve that problem but as we know in

00:08:29.770 --> 00:08:29.780
solve that problem but as we know in
 

00:08:29.780 --> 00:08:31.540
solve that problem but as we know in
practice actually training neural

00:08:31.540 --> 00:08:31.550
practice actually training neural
 

00:08:31.550 --> 00:08:33.550
practice actually training neural
networks because of their non convex

00:08:33.550 --> 00:08:33.560
networks because of their non convex
 

00:08:33.560 --> 00:08:40.810
networks because of their non convex
structure is extremely difficult so this

00:08:40.810 --> 00:08:40.820
structure is extremely difficult so this
 

00:08:40.820 --> 00:08:42.610
structure is extremely difficult so this
theorem is really a perfect example of

00:08:42.610 --> 00:08:42.620
theorem is really a perfect example of
 

00:08:42.620 --> 00:08:45.930
theorem is really a perfect example of
the possible effects of overhyping in AI

00:08:45.930 --> 00:08:45.940
the possible effects of overhyping in AI
 

00:08:45.940 --> 00:08:49.480
the possible effects of overhyping in AI
so over the history of AI we've had two

00:08:49.480 --> 00:08:49.490
so over the history of AI we've had two
 

00:08:49.490 --> 00:08:52.450
so over the history of AI we've had two
AI winters and this theorem was one of

00:08:52.450 --> 00:08:52.460
AI winters and this theorem was one of
 

00:08:52.460 --> 00:08:56.420
AI winters and this theorem was one of
the resurgence

00:08:56.420 --> 00:08:56.430
the resurgence
 

00:08:56.430 --> 00:08:58.250
the resurgence
after the first day I winter but it also

00:08:58.250 --> 00:08:58.260
after the first day I winter but it also
 

00:08:58.260 --> 00:09:01.519
after the first day I winter but it also
caused a huge false hype in the power of

00:09:01.519 --> 00:09:01.529
caused a huge false hype in the power of
 

00:09:01.529 --> 00:09:02.900
caused a huge false hype in the power of
these neural networks which ultimately

00:09:02.900 --> 00:09:02.910
these neural networks which ultimately
 

00:09:02.910 --> 00:09:06.680
these neural networks which ultimately
led to yet another AI winter and I feel

00:09:06.680 --> 00:09:06.690
led to yet another AI winter and I feel
 

00:09:06.690 --> 00:09:08.120
led to yet another AI winter and I feel
like as a class it's very important to

00:09:08.120 --> 00:09:08.130
like as a class it's very important to
 

00:09:08.130 --> 00:09:10.460
like as a class it's very important to
bring this up because right now we're

00:09:10.460 --> 00:09:10.470
bring this up because right now we're
 

00:09:10.470 --> 00:09:16.639
bring this up because right now we're
very much in the state of a huge amount

00:09:16.639 --> 00:09:16.649
very much in the state of a huge amount
 

00:09:16.649 --> 00:09:18.440
very much in the state of a huge amount
of overhyping in deep learning

00:09:18.440 --> 00:09:18.450
of overhyping in deep learning
 

00:09:18.450 --> 00:09:21.050
of overhyping in deep learning
algorithms so these algorithms are

00:09:21.050 --> 00:09:21.060
algorithms so these algorithms are
 

00:09:21.060 --> 00:09:23.329
algorithms so these algorithms are
especially in the media being portrayed

00:09:23.329 --> 00:09:23.339
especially in the media being portrayed
 

00:09:23.339 --> 00:09:26.329
especially in the media being portrayed
that they can accomplish human level

00:09:26.329 --> 00:09:26.339
that they can accomplish human level
 

00:09:26.339 --> 00:09:28.460
that they can accomplish human level
intelligence and human level reasoning

00:09:28.460 --> 00:09:28.470
intelligence and human level reasoning
 

00:09:28.470 --> 00:09:30.769
intelligence and human level reasoning
and simply this is not true so I think

00:09:30.769 --> 00:09:30.779
and simply this is not true so I think
 

00:09:30.779 --> 00:09:32.810
and simply this is not true so I think
such over hype is extremely dangerous

00:09:32.810 --> 00:09:32.820
such over hype is extremely dangerous
 

00:09:32.820 --> 00:09:35.810
such over hype is extremely dangerous
and resulted well we know it resulted in

00:09:35.810 --> 00:09:35.820
and resulted well we know it resulted in
 

00:09:35.820 --> 00:09:38.660
and resulted well we know it resulted in
in both of the two past AI winters and I

00:09:38.660 --> 00:09:38.670
in both of the two past AI winters and I
 

00:09:38.670 --> 00:09:40.160
in both of the two past AI winters and I
think as a class it's very important for

00:09:40.160 --> 00:09:40.170
think as a class it's very important for
 

00:09:40.170 --> 00:09:42.110
think as a class it's very important for
us to focus on some of the limitations

00:09:42.110 --> 00:09:42.120
us to focus on some of the limitations
 

00:09:42.120 --> 00:09:44.660
us to focus on some of the limitations
of these algorithms so that we don't

00:09:44.660 --> 00:09:44.670
of these algorithms so that we don't
 

00:09:44.670 --> 00:09:46.370
of these algorithms so that we don't
overhyped them but we provide realistic

00:09:46.370 --> 00:09:46.380
overhyped them but we provide realistic
 

00:09:46.380 --> 00:09:48.740
overhyped them but we provide realistic
guarantees or realistic expectations

00:09:48.740 --> 00:09:48.750
guarantees or realistic expectations
 

00:09:48.750 --> 00:09:50.690
guarantees or realistic expectations
rather on what these algorithms can

00:09:50.690 --> 00:09:50.700
rather on what these algorithms can
 

00:09:50.700 --> 00:09:55.280
rather on what these algorithms can
accomplish and finally going past these

00:09:55.280 --> 00:09:55.290
accomplish and finally going past these
 

00:09:55.290 --> 00:09:56.810
accomplish and finally going past these
limitations the last part of this talk

00:09:56.810 --> 00:09:56.820
limitations the last part of this talk
 

00:09:56.820 --> 00:09:58.550
limitations the last part of this talk
will actually focus on some of the

00:09:58.550 --> 00:09:58.560
will actually focus on some of the
 

00:09:58.560 --> 00:10:00.050
will actually focus on some of the
exciting research like I mentioned

00:10:00.050 --> 00:10:00.060
exciting research like I mentioned
 

00:10:00.060 --> 00:10:02.570
exciting research like I mentioned
before that tries to take a couple of

00:10:02.570 --> 00:10:02.580
before that tries to take a couple of
 

00:10:02.580 --> 00:10:05.930
before that tries to take a couple of
these limitations and really focus on

00:10:05.930 --> 00:10:05.940
these limitations and really focus on
 

00:10:05.940 --> 00:10:07.460
these limitations and really focus on
possible solutions and possible ways

00:10:07.460 --> 00:10:07.470
possible solutions and possible ways
 

00:10:07.470 --> 00:10:11.600
possible solutions and possible ways
that we can move past them okay so let's

00:10:11.600 --> 00:10:11.610
that we can move past them okay so let's
 

00:10:11.610 --> 00:10:13.550
that we can move past them okay so let's
start and I think one of the best

00:10:13.550 --> 00:10:13.560
start and I think one of the best
 

00:10:13.560 --> 00:10:16.940
start and I think one of the best
examples of a potential danger of neural

00:10:16.940 --> 00:10:16.950
examples of a potential danger of neural
 

00:10:16.950 --> 00:10:18.680
examples of a potential danger of neural
networks comes from this paper from

00:10:18.680 --> 00:10:18.690
networks comes from this paper from
 

00:10:18.690 --> 00:10:22.100
networks comes from this paper from
google deepmind named understanding deep

00:10:22.100 --> 00:10:22.110
google deepmind named understanding deep
 

00:10:22.110 --> 00:10:23.949
google deepmind named understanding deep
neural networks requires rethinking

00:10:23.949 --> 00:10:23.959
neural networks requires rethinking
 

00:10:23.959 --> 00:10:27.920
neural networks requires rethinking
generalization and generalization was

00:10:27.920 --> 00:10:27.930
generalization and generalization was
 

00:10:27.930 --> 00:10:29.900
generalization and generalization was
this topic that we discussed in the

00:10:29.900 --> 00:10:29.910
this topic that we discussed in the
 

00:10:29.910 --> 00:10:32.120
this topic that we discussed in the
first lecture so this is the notion of a

00:10:32.120 --> 00:10:32.130
first lecture so this is the notion of a
 

00:10:32.130 --> 00:10:35.000
first lecture so this is the notion of a
gap or a difference between your

00:10:35.000 --> 00:10:35.010
gap or a difference between your
 

00:10:35.010 --> 00:10:37.070
gap or a difference between your
training accuracy and your test accuracy

00:10:37.070 --> 00:10:37.080
training accuracy and your test accuracy
 

00:10:37.080 --> 00:10:40.940
training accuracy and your test accuracy
if you're able to achieve equal training

00:10:40.940 --> 00:10:40.950
if you're able to achieve equal training
 

00:10:40.950 --> 00:10:42.319
if you're able to achieve equal training
and test accuracy that means you have

00:10:42.319 --> 00:10:42.329
and test accuracy that means you have
 

00:10:42.329 --> 00:10:44.720
and test accuracy that means you have
essentially no generalization gap you're

00:10:44.720 --> 00:10:44.730
essentially no generalization gap you're
 

00:10:44.730 --> 00:10:47.750
essentially no generalization gap you're
able to generalize perfectly to to your

00:10:47.750 --> 00:10:47.760
able to generalize perfectly to to your
 

00:10:47.760 --> 00:10:49.490
able to generalize perfectly to to your
test dataset but if there's a huge

00:10:49.490 --> 00:10:49.500
test dataset but if there's a huge
 

00:10:49.500 --> 00:10:52.160
test dataset but if there's a huge
disparity between these two datasets and

00:10:52.160 --> 00:10:52.170
disparity between these two datasets and
 

00:10:52.170 --> 00:10:53.960
disparity between these two datasets and
your model is performing much better on

00:10:53.960 --> 00:10:53.970
your model is performing much better on
 

00:10:53.970 --> 00:10:55.550
your model is performing much better on
your training data set than your test

00:10:55.550 --> 00:10:55.560
your training data set than your test
 

00:10:55.560 --> 00:10:57.260
your training data set than your test
dataset this means that you're not able

00:10:57.260 --> 00:10:57.270
dataset this means that you're not able
 

00:10:57.270 --> 00:10:59.389
dataset this means that you're not able
to actually generalize to brand new

00:10:59.389 --> 00:10:59.399
to actually generalize to brand new
 

00:10:59.399 --> 00:11:02.480
to actually generalize to brand new
images you're only just memorizing the

00:11:02.480 --> 00:11:02.490
images you're only just memorizing the
 

00:11:02.490 --> 00:11:04.630
images you're only just memorizing the
training examples

00:11:04.630 --> 00:11:04.640
training examples
 

00:11:04.640 --> 00:11:06.610
training examples
and what this paper did was they

00:11:06.610 --> 00:11:06.620
and what this paper did was they
 

00:11:06.620 --> 00:11:08.500
and what this paper did was they
performed the following experiment so

00:11:08.500 --> 00:11:08.510
performed the following experiment so
 

00:11:08.510 --> 00:11:11.079
performed the following experiment so
they took images from imagenet so you

00:11:11.079 --> 00:11:11.089
they took images from imagenet so you
 

00:11:11.089 --> 00:11:12.519
they took images from imagenet so you
can here see four examples of these

00:11:12.519 --> 00:11:12.529
can here see four examples of these
 

00:11:12.529 --> 00:11:14.410
can here see four examples of these
images here and what they did was they

00:11:14.410 --> 00:11:14.420
images here and what they did was they
 

00:11:14.420 --> 00:11:18.579
images here and what they did was they
rolled a case I did die where K is the

00:11:18.579 --> 00:11:18.589
rolled a case I did die where K is the
 

00:11:18.589 --> 00:11:21.009
rolled a case I did die where K is the
number of all possible labels in that

00:11:21.009 --> 00:11:21.019
number of all possible labels in that
 

00:11:21.019 --> 00:11:23.550
number of all possible labels in that
data set and this allowed them to

00:11:23.550 --> 00:11:23.560
data set and this allowed them to
 

00:11:23.560 --> 00:11:26.740
data set and this allowed them to
randomly assign brand new labels to each

00:11:26.740 --> 00:11:26.750
randomly assign brand new labels to each
 

00:11:26.750 --> 00:11:29.680
randomly assign brand new labels to each
of these images so what used to be a dog

00:11:29.680 --> 00:11:29.690
of these images so what used to be a dog
 

00:11:29.690 --> 00:11:32.680
of these images so what used to be a dog
they call now a banana and what they

00:11:32.680 --> 00:11:32.690
they call now a banana and what they
 

00:11:32.690 --> 00:11:34.389
they call now a banana and what they
used to be that banana is now called the

00:11:34.389 --> 00:11:34.399
used to be that banana is now called the
 

00:11:34.399 --> 00:11:36.160
used to be that banana is now called the
dog and what it used to be called that

00:11:36.160 --> 00:11:36.170
dog and what it used to be called that
 

00:11:36.170 --> 00:11:38.740
dog and what it used to be called that
second dog is now a tree so note that

00:11:38.740 --> 00:11:38.750
second dog is now a tree so note that
 

00:11:38.750 --> 00:11:40.540
second dog is now a tree so note that
the two dogs have actually been

00:11:40.540 --> 00:11:40.550
the two dogs have actually been
 

00:11:40.550 --> 00:11:42.310
the two dogs have actually been
transformed into two separate things so

00:11:42.310 --> 00:11:42.320
transformed into two separate things so
 

00:11:42.320 --> 00:11:43.750
transformed into two separate things so
things that used to be in the same class

00:11:43.750 --> 00:11:43.760
things that used to be in the same class
 

00:11:43.760 --> 00:11:46.269
things that used to be in the same class
are now in completely disjoint classes

00:11:46.269 --> 00:11:46.279
are now in completely disjoint classes
 

00:11:46.279 --> 00:11:47.680
are now in completely disjoint classes
and things that were in disjoint classes

00:11:47.680 --> 00:11:47.690
and things that were in disjoint classes
 

00:11:47.690 --> 00:11:50.170
and things that were in disjoint classes
maybe now in the same class so basically

00:11:50.170 --> 00:11:50.180
maybe now in the same class so basically
 

00:11:50.180 --> 00:11:52.180
maybe now in the same class so basically
we're completely randomizing our labels

00:11:52.180 --> 00:11:52.190
we're completely randomizing our labels
 

00:11:52.190 --> 00:11:54.970
we're completely randomizing our labels
entirely and what they did was they

00:11:54.970 --> 00:11:54.980
entirely and what they did was they
 

00:11:54.980 --> 00:11:56.620
entirely and what they did was they
tried to see if a neural network could

00:11:56.620 --> 00:11:56.630
tried to see if a neural network could
 

00:11:56.630 --> 00:12:01.030
tried to see if a neural network could
still learn random labels and here's

00:12:01.030 --> 00:12:01.040
still learn random labels and here's
 

00:12:01.040 --> 00:12:04.420
still learn random labels and here's
what they found so as you'd expect when

00:12:04.420 --> 00:12:04.430
what they found so as you'd expect when
 

00:12:04.430 --> 00:12:06.400
what they found so as you'd expect when
they tested this neural network with

00:12:06.400 --> 00:12:06.410
they tested this neural network with
 

00:12:06.410 --> 00:12:08.680
they tested this neural network with
random labels as they increase the

00:12:08.680 --> 00:12:08.690
random labels as they increase the
 

00:12:08.690 --> 00:12:12.160
random labels as they increase the
randomness on the x axis so going from

00:12:12.160 --> 00:12:12.170
randomness on the x axis so going from
 

00:12:12.170 --> 00:12:13.480
randomness on the x axis so going from
left to right this is the original

00:12:13.480 --> 00:12:13.490
left to right this is the original
 

00:12:13.490 --> 00:12:15.460
left to right this is the original
labels before randomizing anything and

00:12:15.460 --> 00:12:15.470
labels before randomizing anything and
 

00:12:15.470 --> 00:12:17.889
labels before randomizing anything and
then they started randomizing their test

00:12:17.889 --> 00:12:17.899
then they started randomizing their test
 

00:12:17.899 --> 00:12:20.380
then they started randomizing their test
accuracy gradually decreased and this is

00:12:20.380 --> 00:12:20.390
accuracy gradually decreased and this is
 

00:12:20.390 --> 00:12:22.480
accuracy gradually decreased and this is
as expected because we're trying to

00:12:22.480 --> 00:12:22.490
as expected because we're trying to
 

00:12:22.490 --> 00:12:24.670
as expected because we're trying to
learn something that has absolutely no

00:12:24.670 --> 00:12:24.680
learn something that has absolutely no
 

00:12:24.680 --> 00:12:28.540
learn something that has absolutely no
pattern in it but then what's really

00:12:28.540 --> 00:12:28.550
pattern in it but then what's really
 

00:12:28.550 --> 00:12:29.920
pattern in it but then what's really
interesting is that then they looked at

00:12:29.920 --> 00:12:29.930
interesting is that then they looked at
 

00:12:29.930 --> 00:12:32.800
interesting is that then they looked at
the training accuracy and what they

00:12:32.800 --> 00:12:32.810
the training accuracy and what they
 

00:12:32.810 --> 00:12:34.630
the training accuracy and what they
found was that the neural network was

00:12:34.630 --> 00:12:34.640
found was that the neural network was
 

00:12:34.640 --> 00:12:38.439
found was that the neural network was
able to with 100% accuracy get the

00:12:38.439 --> 00:12:38.449
able to with 100% accuracy get the
 

00:12:38.449 --> 00:12:41.639
able to with 100% accuracy get the
training set correct every single time

00:12:41.639 --> 00:12:41.649
training set correct every single time
 

00:12:41.649 --> 00:12:44.410
training set correct every single time
no matter how many random labels they

00:12:44.410 --> 00:12:44.420
no matter how many random labels they
 

00:12:44.420 --> 00:12:46.930
no matter how many random labels they
introduced the training set would always

00:12:46.930 --> 00:12:46.940
introduced the training set would always
 

00:12:46.940 --> 00:12:48.910
introduced the training set would always
be shattered or in other words every

00:12:48.910 --> 00:12:48.920
be shattered or in other words every
 

00:12:48.920 --> 00:12:51.340
be shattered or in other words every
single example in the training set could

00:12:51.340 --> 00:12:51.350
single example in the training set could
 

00:12:51.350 --> 00:12:54.280
single example in the training set could
be perfectly classified so this means

00:12:54.280 --> 00:12:54.290
be perfectly classified so this means
 

00:12:54.290 --> 00:12:57.759
be perfectly classified so this means
that modern deep neural networks

00:12:57.759 --> 00:12:57.769
that modern deep neural networks
 

00:12:57.769 --> 00:12:59.439
that modern deep neural networks
actually have the capacity to

00:12:59.439 --> 00:12:59.449
actually have the capacity to
 

00:12:59.449 --> 00:13:03.069
actually have the capacity to
brute-force memorize massive data sets

00:13:03.069 --> 00:13:03.079
brute-force memorize massive data sets
 

00:13:03.079 --> 00:13:05.829
brute-force memorize massive data sets
even on the size of imagenet with

00:13:05.829 --> 00:13:05.839
even on the size of imagenet with
 

00:13:05.839 --> 00:13:07.569
even on the size of imagenet with
completely random labels they're able to

00:13:07.569 --> 00:13:07.579
completely random labels they're able to
 

00:13:07.579 --> 00:13:10.449
completely random labels they're able to
memorize every single example in that

00:13:10.449 --> 00:13:10.459
memorize every single example in that
 

00:13:10.459 --> 00:13:12.819
memorize every single example in that
data set and this is a very powerful

00:13:12.819 --> 00:13:12.829
data set and this is a very powerful
 

00:13:12.829 --> 00:13:15.970
data set and this is a very powerful
result is it drives home this point that

00:13:15.970 --> 00:13:15.980
result is it drives home this point that
 

00:13:15.980 --> 00:13:17.769
result is it drives home this point that
neural networks are you

00:13:17.769 --> 00:13:17.779
neural networks are you
 

00:13:17.779 --> 00:13:19.540
neural networks are you
really excellent function approximator

00:13:19.540 --> 00:13:19.550
really excellent function approximator
 

00:13:19.550 --> 00:13:22.059
really excellent function approximator
x' so this also connects back to the

00:13:22.059 --> 00:13:22.069
x' so this also connects back to the
 

00:13:22.069 --> 00:13:24.129
x' so this also connects back to the
universal approximation theorem that I

00:13:24.129 --> 00:13:24.139
universal approximation theorem that I
 

00:13:24.139 --> 00:13:27.100
universal approximation theorem that I
talked about before but they're really

00:13:27.100 --> 00:13:27.110
talked about before but they're really
 

00:13:27.110 --> 00:13:28.509
talked about before but they're really
good approximator is for just a single

00:13:28.509 --> 00:13:28.519
good approximator is for just a single
 

00:13:28.519 --> 00:13:31.150
good approximator is for just a single
function like I said which means that we

00:13:31.150 --> 00:13:31.160
function like I said which means that we
 

00:13:31.160 --> 00:13:32.470
function like I said which means that we
can always create this maximum

00:13:32.470 --> 00:13:32.480
can always create this maximum
 

00:13:32.480 --> 00:13:34.629
can always create this maximum
likelihood estimate of our data using a

00:13:34.629 --> 00:13:34.639
likelihood estimate of our data using a
 

00:13:34.639 --> 00:13:37.210
likelihood estimate of our data using a
neural network such that if we were

00:13:37.210 --> 00:13:37.220
neural network such that if we were
 

00:13:37.220 --> 00:13:38.980
neural network such that if we were
given a new data point like this purple

00:13:38.980 --> 00:13:38.990
given a new data point like this purple
 

00:13:38.990 --> 00:13:41.170
given a new data point like this purple
one on the bottom it's easy for us to

00:13:41.170 --> 00:13:41.180
one on the bottom it's easy for us to
 

00:13:41.180 --> 00:13:43.660
one on the bottom it's easy for us to
compute its estimate probability or its

00:13:43.660 --> 00:13:43.670
compute its estimate probability or its
 

00:13:43.670 --> 00:13:46.869
compute its estimate probability or its
estimate output just by intercepting it

00:13:46.869 --> 00:13:46.879
estimate output just by intercepting it
 

00:13:46.879 --> 00:13:49.110
estimate output just by intercepting it
with that maximum likelihood estimate

00:13:49.110 --> 00:13:49.120
with that maximum likelihood estimate
 

00:13:49.120 --> 00:13:51.400
with that maximum likelihood estimate
but if that's only if I'm looking at a

00:13:51.400 --> 00:13:51.410
but if that's only if I'm looking at a
 

00:13:51.410 --> 00:13:52.989
but if that's only if I'm looking at a
place that we have sufficient training

00:13:52.989 --> 00:13:52.999
place that we have sufficient training
 

00:13:52.999 --> 00:13:55.420
place that we have sufficient training
data already what if I extend these x

00:13:55.420 --> 00:13:55.430
data already what if I extend these x
 

00:13:55.430 --> 00:13:57.790
data already what if I extend these x
axes and look at what the neural network

00:13:57.790 --> 00:13:57.800
axes and look at what the neural network
 

00:13:57.800 --> 00:14:00.249
axes and look at what the neural network
predicts beyond that in these locations

00:14:00.249 --> 00:14:00.259
predicts beyond that in these locations
 

00:14:00.259 --> 00:14:02.110
predicts beyond that in these locations
these are actually the locations that we

00:14:02.110 --> 00:14:02.120
these are actually the locations that we
 

00:14:02.120 --> 00:14:04.210
these are actually the locations that we
care about most right these are the edge

00:14:04.210 --> 00:14:04.220
care about most right these are the edge
 

00:14:04.220 --> 00:14:06.730
care about most right these are the edge
cases and driving these are the cases

00:14:06.730 --> 00:14:06.740
cases and driving these are the cases
 

00:14:06.740 --> 00:14:09.340
cases and driving these are the cases
that we don't have met many or a lot of

00:14:09.340 --> 00:14:09.350
that we don't have met many or a lot of
 

00:14:09.350 --> 00:14:12.489
that we don't have met many or a lot of
data that was collected and these are

00:14:12.489 --> 00:14:12.499
data that was collected and these are
 

00:14:12.499 --> 00:14:15.720
data that was collected and these are
usually the cases where safety critical

00:14:15.720 --> 00:14:15.730
usually the cases where safety critical
 

00:14:15.730 --> 00:14:20.110
usually the cases where safety critical
applications are like our most important

00:14:20.110 --> 00:14:20.120
applications are like our most important
 

00:14:20.120 --> 00:14:22.329
applications are like our most important
right so we need to be able to make sure

00:14:22.329 --> 00:14:22.339
right so we need to be able to make sure
 

00:14:22.339 --> 00:14:23.949
right so we need to be able to make sure
when we sample the neural network from

00:14:23.949 --> 00:14:23.959
when we sample the neural network from
 

00:14:23.959 --> 00:14:26.949
when we sample the neural network from
these locations are we able to know that

00:14:26.949 --> 00:14:26.959
these locations are we able to know that
 

00:14:26.959 --> 00:14:28.749
these locations are we able to know that
the neural network are we able to get

00:14:28.749 --> 00:14:28.759
the neural network are we able to get
 

00:14:28.759 --> 00:14:30.249
the neural network are we able to get
feedback from the neural network that it

00:14:30.249 --> 00:14:30.259
feedback from the neural network that it
 

00:14:30.259 --> 00:14:31.329
feedback from the neural network that it
actually doesn't know what it's talking

00:14:31.329 --> 00:14:31.339
actually doesn't know what it's talking
 

00:14:31.339 --> 00:14:35.889
actually doesn't know what it's talking
about so this notion leads nicely into

00:14:35.889 --> 00:14:35.899
about so this notion leads nicely into
 

00:14:35.899 --> 00:14:38.379
about so this notion leads nicely into
the idea of what is known as advertised

00:14:38.379 --> 00:14:38.389
the idea of what is known as advertised
 

00:14:38.389 --> 00:14:41.679
the idea of what is known as advertised
adversarial attacks where I can give you

00:14:41.679 --> 00:14:41.689
adversarial attacks where I can give you
 

00:14:41.689 --> 00:14:43.629
adversarial attacks where I can give you
directly and give and neural network to

00:14:43.629 --> 00:14:43.639
directly and give and neural network to
 

00:14:43.639 --> 00:14:46.059
directly and give and neural network to
images like on the left like this one

00:14:46.059 --> 00:14:46.069
images like on the left like this one
 

00:14:46.069 --> 00:14:48.069
images like on the left like this one
and on the right an adversarial image

00:14:48.069 --> 00:14:48.079
and on the right an adversarial image
 

00:14:48.079 --> 00:14:50.549
and on the right an adversarial image
that to a human look exactly the same

00:14:50.549 --> 00:14:50.559
that to a human look exactly the same
 

00:14:50.559 --> 00:14:53.650
that to a human look exactly the same
but to the networks they're incorrectly

00:14:53.650 --> 00:14:53.660
but to the networks they're incorrectly
 

00:14:53.660 --> 00:14:56.980
but to the networks they're incorrectly
classified 100% of the time so the image

00:14:56.980 --> 00:14:56.990
classified 100% of the time so the image
 

00:14:56.990 --> 00:14:58.329
classified 100% of the time so the image
on the right shows an example of a

00:14:58.329 --> 00:14:58.339
on the right shows an example of a
 

00:14:58.339 --> 00:15:00.220
on the right shows an example of a
temple which when I feed to a neural

00:15:00.220 --> 00:15:00.230
temple which when I feed to a neural
 

00:15:00.230 --> 00:15:01.960
temple which when I feed to a neural
network it gives me back label of a

00:15:01.960 --> 00:15:01.970
network it gives me back label of a
 

00:15:01.970 --> 00:15:05.379
network it gives me back label of a
temple but when I apply some adversarial

00:15:05.379 --> 00:15:05.389
temple but when I apply some adversarial
 

00:15:05.389 --> 00:15:08.259
temple but when I apply some adversarial
noise it classifies this image

00:15:08.259 --> 00:15:08.269
noise it classifies this image
 

00:15:08.269 --> 00:15:13.900
noise it classifies this image
incorrectly as an ostrich so for this

00:15:13.900 --> 00:15:13.910
incorrectly as an ostrich so for this
 

00:15:13.910 --> 00:15:15.610
incorrectly as an ostrich so for this
I'd like to focus on this piece

00:15:15.610 --> 00:15:15.620
I'd like to focus on this piece
 

00:15:15.620 --> 00:15:17.350
I'd like to focus on this piece
specifically so to understand the

00:15:17.350 --> 00:15:17.360
specifically so to understand the
 

00:15:17.360 --> 00:15:18.850
specifically so to understand the
limitations of neural networks the first

00:15:18.850 --> 00:15:18.860
limitations of neural networks the first
 

00:15:18.860 --> 00:15:19.809
limitations of neural networks the first
thing we have to do is actually

00:15:19.809 --> 00:15:19.819
thing we have to do is actually
 

00:15:19.819 --> 00:15:22.379
thing we have to do is actually
understand how we can break them and

00:15:22.379 --> 00:15:22.389
understand how we can break them and
 

00:15:22.389 --> 00:15:26.220
understand how we can break them and
this perturb noise is actually very

00:15:26.220 --> 00:15:26.230
this perturb noise is actually very
 

00:15:26.230 --> 00:15:28.299
this perturb noise is actually very
intelligently designed so this is not

00:15:28.299 --> 00:15:28.309
intelligently designed so this is not
 

00:15:28.309 --> 00:15:30.369
intelligently designed so this is not
just random noise but we're actually

00:15:30.369 --> 00:15:30.379
just random noise but we're actually
 

00:15:30.379 --> 00:15:31.749
just random noise but we're actually
modifying pics

00:15:31.749 --> 00:15:31.759
modifying pics
 

00:15:31.759 --> 00:15:34.449
modifying pics
in specific locations to maximally

00:15:34.449 --> 00:15:34.459
in specific locations to maximally
 

00:15:34.459 --> 00:15:37.419
in specific locations to maximally
change or mess up our output prediction

00:15:37.419 --> 00:15:37.429
change or mess up our output prediction
 

00:15:37.429 --> 00:15:39.309
change or mess up our output prediction
so we want to modify the pixels in such

00:15:39.309 --> 00:15:39.319
so we want to modify the pixels in such
 

00:15:39.319 --> 00:15:41.829
so we want to modify the pixels in such
a way that we're decreasing our accuracy

00:15:41.829 --> 00:15:41.839
a way that we're decreasing our accuracy
 

00:15:41.839 --> 00:15:44.319
a way that we're decreasing our accuracy
as much as possible and if you remember

00:15:44.319 --> 00:15:44.329
as much as possible and if you remember
 

00:15:44.329 --> 00:15:45.699
as much as possible and if you remember
back to how we actually trained our

00:15:45.699 --> 00:15:45.709
back to how we actually trained our
 

00:15:45.709 --> 00:15:47.259
back to how we actually trained our
neural networks this might sound very

00:15:47.259 --> 00:15:47.269
neural networks this might sound very
 

00:15:47.269 --> 00:15:50.319
neural networks this might sound very
similar so if you remember training and

00:15:50.319 --> 00:15:50.329
similar so if you remember training and
 

00:15:50.329 --> 00:15:52.419
similar so if you remember training and
neural network is simply optimizing over

00:15:52.419 --> 00:15:52.429
neural network is simply optimizing over
 

00:15:52.429 --> 00:15:55.329
neural network is simply optimizing over
our weights theta so to do this we

00:15:55.329 --> 00:15:55.339
our weights theta so to do this we
 

00:15:55.339 --> 00:15:56.979
our weights theta so to do this we
simply compute the gradient of theta

00:15:56.979 --> 00:15:56.989
simply compute the gradient of theta
 

00:15:56.989 --> 00:15:59.439
simply compute the gradient of theta
with respect to our loss function with

00:15:59.439 --> 00:15:59.449
with respect to our loss function with
 

00:15:59.449 --> 00:16:02.049
with respect to our loss function with
respect to theta and we simply perturb

00:16:02.049 --> 00:16:02.059
respect to theta and we simply perturb
 

00:16:02.059 --> 00:16:04.329
respect to theta and we simply perturb
our weights in the direction that will

00:16:04.329 --> 00:16:04.339
our weights in the direction that will
 

00:16:04.339 --> 00:16:08.739
our weights in the direction that will
minimize our loss now also remember that

00:16:08.739 --> 00:16:08.749
minimize our loss now also remember that
 

00:16:08.749 --> 00:16:10.689
minimize our loss now also remember that
when we do this we're perturbing theta

00:16:10.689 --> 00:16:10.699
when we do this we're perturbing theta
 

00:16:10.699 --> 00:16:13.090
when we do this we're perturbing theta
but we're fixing our X and our Y this is

00:16:13.090 --> 00:16:13.100
but we're fixing our X and our Y this is
 

00:16:13.100 --> 00:16:14.889
but we're fixing our X and our Y this is
our training label our training data and

00:16:14.889 --> 00:16:14.899
our training label our training data and
 

00:16:14.899 --> 00:16:17.289
our training label our training data and
our training labels now for adversarial

00:16:17.289 --> 00:16:17.299
our training labels now for adversarial
 

00:16:17.299 --> 00:16:18.220
our training labels now for adversarial
examples

00:16:18.220 --> 00:16:18.230
examples
 

00:16:18.230 --> 00:16:20.379
examples
we're just shuffling the variables a

00:16:20.379 --> 00:16:20.389
we're just shuffling the variables a
 

00:16:20.389 --> 00:16:22.239
we're just shuffling the variables a
little bit so now we want to optimize

00:16:22.239 --> 00:16:22.249
little bit so now we want to optimize
 

00:16:22.249 --> 00:16:24.429
little bit so now we want to optimize
over the image itself not the weight so

00:16:24.429 --> 00:16:24.439
over the image itself not the weight so
 

00:16:24.439 --> 00:16:27.879
over the image itself not the weight so
we fix the weights and the target label

00:16:27.879 --> 00:16:27.889
we fix the weights and the target label
 

00:16:27.889 --> 00:16:31.059
we fix the weights and the target label
itself and we optimize over the image X

00:16:31.059 --> 00:16:31.069
itself and we optimize over the image X
 

00:16:31.069 --> 00:16:33.159
itself and we optimize over the image X
we want to make small changes to that

00:16:33.159 --> 00:16:33.169
we want to make small changes to that
 

00:16:33.169 --> 00:16:35.739
we want to make small changes to that
image X such that we increase our loss

00:16:35.739 --> 00:16:35.749
image X such that we increase our loss
 

00:16:35.749 --> 00:16:37.569
image X such that we increase our loss
as much as possible and we want to go in

00:16:37.569 --> 00:16:37.579
as much as possible and we want to go in
 

00:16:37.579 --> 00:16:39.569
as much as possible and we want to go in
the opposite direction of training now

00:16:39.569 --> 00:16:39.579
the opposite direction of training now
 

00:16:39.579 --> 00:16:41.590
the opposite direction of training now
and these are just some of the

00:16:41.590 --> 00:16:41.600
and these are just some of the
 

00:16:41.600 --> 00:16:44.859
and these are just some of the
limitations of neural networks and for

00:16:44.859 --> 00:16:44.869
limitations of neural networks and for
 

00:16:44.869 --> 00:16:46.299
limitations of neural networks and for
the remainder of this class I want to

00:16:46.299 --> 00:16:46.309
the remainder of this class I want to
 

00:16:46.309 --> 00:16:48.099
the remainder of this class I want to
focus on some of the really really

00:16:48.099 --> 00:16:48.109
focus on some of the really really
 

00:16:48.109 --> 00:16:49.809
focus on some of the really really
exciting new frontiers of deep learning

00:16:49.809 --> 00:16:49.819
exciting new frontiers of deep learning
 

00:16:49.819 --> 00:16:51.720
exciting new frontiers of deep learning
that focus on just two of these

00:16:51.720 --> 00:16:51.730
that focus on just two of these
 

00:16:51.730 --> 00:16:54.039
that focus on just two of these
specifically I want to focus on the

00:16:54.039 --> 00:16:54.049
specifically I want to focus on the
 

00:16:54.049 --> 00:16:55.960
specifically I want to focus on the
notion of understanding uncertainty and

00:16:55.960 --> 00:16:55.970
notion of understanding uncertainty and
 

00:16:55.970 --> 00:16:57.599
notion of understanding uncertainty and
deep neural networks and understanding

00:16:57.599 --> 00:16:57.609
deep neural networks and understanding
 

00:16:57.609 --> 00:17:00.909
deep neural networks and understanding
when our model doesn't know what it was

00:17:00.909 --> 00:17:00.919
when our model doesn't know what it was
 

00:17:00.919 --> 00:17:02.859
when our model doesn't know what it was
trained to know maybe because it wasn't

00:17:02.859 --> 00:17:02.869
trained to know maybe because it wasn't
 

00:17:02.869 --> 00:17:04.840
trained to know maybe because it wasn't
it didn't receive enough training data

00:17:04.840 --> 00:17:04.850
it didn't receive enough training data
 

00:17:04.850 --> 00:17:08.039
it didn't receive enough training data
to support that hypothesis and

00:17:08.039 --> 00:17:08.049
to support that hypothesis and
 

00:17:08.049 --> 00:17:10.389
to support that hypothesis and
furthermore I wanted to focus on this

00:17:10.389 --> 00:17:10.399
furthermore I wanted to focus on this
 

00:17:10.399 --> 00:17:12.819
furthermore I wanted to focus on this
notion of learning how to learn models

00:17:12.819 --> 00:17:12.829
notion of learning how to learn models
 

00:17:12.829 --> 00:17:15.279
notion of learning how to learn models
because optimization of neural networks

00:17:15.279 --> 00:17:15.289
because optimization of neural networks
 

00:17:15.289 --> 00:17:18.429
because optimization of neural networks
is extremely difficult it's extremely

00:17:18.429 --> 00:17:18.439
is extremely difficult it's extremely
 

00:17:18.439 --> 00:17:20.470
is extremely difficult it's extremely
limited in its current nature because

00:17:20.470 --> 00:17:20.480
limited in its current nature because
 

00:17:20.480 --> 00:17:21.939
limited in its current nature because
they're optimized just to do a single

00:17:21.939 --> 00:17:21.949
they're optimized just to do a single
 

00:17:21.949 --> 00:17:23.559
they're optimized just to do a single
task so what we really want to do is

00:17:23.559 --> 00:17:23.569
task so what we really want to do is
 

00:17:23.569 --> 00:17:25.539
task so what we really want to do is
create neural networks that are capable

00:17:25.539 --> 00:17:25.549
create neural networks that are capable
 

00:17:25.549 --> 00:17:29.169
create neural networks that are capable
of performing not one task but a set of

00:17:29.169 --> 00:17:29.179
of performing not one task but a set of
 

00:17:29.179 --> 00:17:31.659
of performing not one task but a set of
sequences of tasks that are maybe

00:17:31.659 --> 00:17:31.669
sequences of tasks that are maybe
 

00:17:31.669 --> 00:17:35.950
sequences of tasks that are maybe
dependent in some fashion so let's start

00:17:35.950 --> 00:17:35.960
dependent in some fashion so let's start
 

00:17:35.960 --> 00:17:37.930
dependent in some fashion so let's start
with this notion of uncertainty in deep

00:17:37.930 --> 00:17:37.940
with this notion of uncertainty in deep
 

00:17:37.940 --> 00:17:39.340
with this notion of uncertainty in deep
neural networks and to do that

00:17:39.340 --> 00:17:39.350
neural networks and to do that
 

00:17:39.350 --> 00:17:43.450
neural networks and to do that
I'd like to introduce this field called

00:17:43.450 --> 00:17:43.460
I'd like to introduce this field called
 

00:17:43.460 --> 00:17:45.900
I'd like to introduce this field called
Bayesian deep learning

00:17:45.900 --> 00:17:45.910
Bayesian deep learning
 

00:17:45.910 --> 00:17:48.550
Bayesian deep learning
now to understand Bayesian deep learning

00:17:48.550 --> 00:17:48.560
now to understand Bayesian deep learning
 

00:17:48.560 --> 00:17:51.400
now to understand Bayesian deep learning
let's first understand why we even care

00:17:51.400 --> 00:17:51.410
let's first understand why we even care
 

00:17:51.410 --> 00:17:53.290
let's first understand why we even care
about uncertainty so this should be

00:17:53.290 --> 00:17:53.300
about uncertainty so this should be
 

00:17:53.300 --> 00:17:55.600
about uncertainty so this should be
pretty obvious but suppose we were given

00:17:55.600 --> 00:17:55.610
pretty obvious but suppose we were given
 

00:17:55.610 --> 00:17:58.270
pretty obvious but suppose we were given
a network that was trained to

00:17:58.270 --> 00:17:58.280
a network that was trained to
 

00:17:58.280 --> 00:18:01.060
a network that was trained to
distinguish between cats and dogs that

00:18:01.060 --> 00:18:01.070
distinguish between cats and dogs that
 

00:18:01.070 --> 00:18:02.770
distinguish between cats and dogs that
input were given a lot of tests

00:18:02.770 --> 00:18:02.780
input were given a lot of tests
 

00:18:02.780 --> 00:18:05.380
input were given a lot of tests
imitating images of cats and dogs and

00:18:05.380 --> 00:18:05.390
imitating images of cats and dogs and
 

00:18:05.390 --> 00:18:06.820
imitating images of cats and dogs and
it's simply at the output we're

00:18:06.820 --> 00:18:06.830
it's simply at the output we're
 

00:18:06.830 --> 00:18:09.100
it's simply at the output we're
producing an output probability of being

00:18:09.100 --> 00:18:09.110
producing an output probability of being
 

00:18:09.110 --> 00:18:12.970
producing an output probability of being
a cat or a dog now this model is trained

00:18:12.970 --> 00:18:12.980
a cat or a dog now this model is trained
 

00:18:12.980 --> 00:18:15.190
a cat or a dog now this model is trained
on either on only cats or dogs so if I

00:18:15.190 --> 00:18:15.200
on either on only cats or dogs so if I
 

00:18:15.200 --> 00:18:17.770
on either on only cats or dogs so if I
showed another cat it should be very

00:18:17.770 --> 00:18:17.780
showed another cat it should be very
 

00:18:17.780 --> 00:18:20.320
showed another cat it should be very
confident in its output well let's

00:18:20.320 --> 00:18:20.330
confident in its output well let's
 

00:18:20.330 --> 00:18:22.990
confident in its output well let's
suppose I give it a horse and I force

00:18:22.990 --> 00:18:23.000
suppose I give it a horse and I force
 

00:18:23.000 --> 00:18:24.850
suppose I give it a horse and I force
that network because it's the same

00:18:24.850 --> 00:18:24.860
that network because it's the same
 

00:18:24.860 --> 00:18:27.130
that network because it's the same
network to produce an output of being a

00:18:27.130 --> 00:18:27.140
network to produce an output of being a
 

00:18:27.140 --> 00:18:28.720
network to produce an output of being a
probability of a cat or a probability of

00:18:28.720 --> 00:18:28.730
probability of a cat or a probability of
 

00:18:28.730 --> 00:18:32.200
probability of a cat or a probability of
a dog now we know that these

00:18:32.200 --> 00:18:32.210
a dog now we know that these
 

00:18:32.210 --> 00:18:33.640
a dog now we know that these
probabilities have to add up to 1

00:18:33.640 --> 00:18:33.650
probabilities have to add up to 1
 

00:18:33.650 --> 00:18:34.570
probabilities have to add up to 1
because that's actually the definition

00:18:34.570 --> 00:18:34.580
because that's actually the definition
 

00:18:34.580 --> 00:18:37.020
because that's actually the definition
that we constrain our network to follow

00:18:37.020 --> 00:18:37.030
that we constrain our network to follow
 

00:18:37.030 --> 00:18:39.790
that we constrain our network to follow
so that means by definition one of these

00:18:39.790 --> 00:18:39.800
so that means by definition one of these
 

00:18:39.800 --> 00:18:41.890
so that means by definition one of these
categories so the network has to produce

00:18:41.890 --> 00:18:41.900
categories so the network has to produce
 

00:18:41.900 --> 00:18:45.130
categories so the network has to produce
one of these categories so the notion of

00:18:45.130 --> 00:18:45.140
one of these categories so the notion of
 

00:18:45.140 --> 00:18:46.420
one of these categories so the notion of
probability and the notion of

00:18:46.420 --> 00:18:46.430
probability and the notion of
 

00:18:46.430 --> 00:18:47.790
probability and the notion of
uncertainty are actually very different

00:18:47.790 --> 00:18:47.800
uncertainty are actually very different
 

00:18:47.800 --> 00:18:50.440
uncertainty are actually very different
but a lot of deep learning practitioners

00:18:50.440 --> 00:18:50.450
but a lot of deep learning practitioners
 

00:18:50.450 --> 00:18:53.590
but a lot of deep learning practitioners
often mix these two ideas so uncertainty

00:18:53.590 --> 00:18:53.600
often mix these two ideas so uncertainty
 

00:18:53.600 --> 00:18:55.810
often mix these two ideas so uncertainty
is not probability neural networks are

00:18:55.810 --> 00:18:55.820
is not probability neural networks are
 

00:18:55.820 --> 00:18:58.320
is not probability neural networks are
detect or trained to detect or produce

00:18:58.320 --> 00:18:58.330
detect or trained to detect or produce
 

00:18:58.330 --> 00:19:00.670
detect or trained to detect or produce
probabilities at their output at their

00:19:00.670 --> 00:19:00.680
probabilities at their output at their
 

00:19:00.680 --> 00:19:02.890
probabilities at their output at their
output but they're not trained to

00:19:02.890 --> 00:19:02.900
output but they're not trained to
 

00:19:02.900 --> 00:19:06.790
output but they're not trained to
produce uncertainty values so if we put

00:19:06.790 --> 00:19:06.800
produce uncertainty values so if we put
 

00:19:06.800 --> 00:19:09.040
produce uncertainty values so if we put
this horse into the same network we'll

00:19:09.040 --> 00:19:09.050
this horse into the same network we'll
 

00:19:09.050 --> 00:19:11.380
this horse into the same network we'll
get a set of uncertainty bility values

00:19:11.380 --> 00:19:11.390
get a set of uncertainty bility values
 

00:19:11.390 --> 00:19:14.380
get a set of uncertainty bility values
that add up to 1 but what we really want

00:19:14.380 --> 00:19:14.390
that add up to 1 but what we really want
 

00:19:14.390 --> 00:19:16.240
that add up to 1 but what we really want
to see is we want to see a very low

00:19:16.240 --> 00:19:16.250
to see is we want to see a very low
 

00:19:16.250 --> 00:19:19.150
to see is we want to see a very low
uncertainty in that a very low certainty

00:19:19.150 --> 00:19:19.160
uncertainty in that a very low certainty
 

00:19:19.160 --> 00:19:22.990
uncertainty in that a very low certainty
in that prediction and one possible way

00:19:22.990 --> 00:19:23.000
in that prediction and one possible way
 

00:19:23.000 --> 00:19:24.580
in that prediction and one possible way
to accomplish this in deep learning is

00:19:24.580 --> 00:19:24.590
to accomplish this in deep learning is
 

00:19:24.590 --> 00:19:26.170
to accomplish this in deep learning is
through the eyes of Bayesian deep

00:19:26.170 --> 00:19:26.180
through the eyes of Bayesian deep
 

00:19:26.180 --> 00:19:28.330
through the eyes of Bayesian deep
learning and to understand this let's

00:19:28.330 --> 00:19:28.340
learning and to understand this let's
 

00:19:28.340 --> 00:19:30.340
learning and to understand this let's
briefly start by formulating our problem

00:19:30.340 --> 00:19:30.350
briefly start by formulating our problem
 

00:19:30.350 --> 00:19:35.560
briefly start by formulating our problem
again so first let's go through like the

00:19:35.560 --> 00:19:35.570
again so first let's go through like the
 

00:19:35.570 --> 00:19:37.110
again so first let's go through like the
variables right so we want to

00:19:37.110 --> 00:19:37.120
variables right so we want to
 

00:19:37.120 --> 00:19:40.720
variables right so we want to
approximate this variable Y or output Y

00:19:40.720 --> 00:19:40.730
approximate this variable Y or output Y
 

00:19:40.730 --> 00:19:43.690
approximate this variable Y or output Y
given some raw data X and really what we

00:19:43.690 --> 00:19:43.700
given some raw data X and really what we
 

00:19:43.700 --> 00:19:45.580
given some raw data X and really what we
mean by training is we want to find this

00:19:45.580 --> 00:19:45.590
mean by training is we want to find this
 

00:19:45.590 --> 00:19:48.220
mean by training is we want to find this
functional mapping F parameterize by our

00:19:48.220 --> 00:19:48.230
functional mapping F parameterize by our
 

00:19:48.230 --> 00:19:50.890
functional mapping F parameterize by our
weights theta such that we minimize the

00:19:50.890 --> 00:19:50.900
weights theta such that we minimize the
 

00:19:50.900 --> 00:19:53.170
weights theta such that we minimize the
loss between our predict examples and

00:19:53.170 --> 00:19:53.180
loss between our predict examples and
 

00:19:53.180 --> 00:19:57.850
loss between our predict examples and
our true outputs y so Bayesian neural

00:19:57.850 --> 00:19:57.860
our true outputs y so Bayesian neural
 

00:19:57.860 --> 00:19:58.909
our true outputs y so Bayesian neural
networks take it

00:19:58.909 --> 00:19:58.919
networks take it
 

00:19:58.919 --> 00:20:01.580
networks take it
different approach to solve this problem

00:20:01.580 --> 00:20:01.590
different approach to solve this problem
 

00:20:01.590 --> 00:20:05.330
different approach to solve this problem
they aim to learn a posterior over our

00:20:05.330 --> 00:20:05.340
they aim to learn a posterior over our
 

00:20:05.340 --> 00:20:08.060
they aim to learn a posterior over our
weights given the data so they attempt

00:20:08.060 --> 00:20:08.070
weights given the data so they attempt
 

00:20:08.070 --> 00:20:10.430
weights given the data so they attempt
to say what is the probability that I

00:20:10.430 --> 00:20:10.440
to say what is the probability that I
 

00:20:10.440 --> 00:20:12.979
to say what is the probability that I
see this model with these weights given

00:20:12.979 --> 00:20:12.989
see this model with these weights given
 

00:20:12.989 --> 00:20:14.659
see this model with these weights given
the data in my training set

00:20:14.659 --> 00:20:14.669
the data in my training set
 

00:20:14.669 --> 00:20:16.580
the data in my training set
now it's called Bayesian deep learning

00:20:16.580 --> 00:20:16.590
now it's called Bayesian deep learning
 

00:20:16.590 --> 00:20:19.099
now it's called Bayesian deep learning
because we can simply rewrite this

00:20:19.099 --> 00:20:19.109
because we can simply rewrite this
 

00:20:19.109 --> 00:20:25.489
because we can simply rewrite this
posterior using Bayes rule however in

00:20:25.489 --> 00:20:25.499
posterior using Bayes rule however in
 

00:20:25.499 --> 00:20:27.529
posterior using Bayes rule however in
practice it's rarely possible to

00:20:27.529 --> 00:20:27.539
practice it's rarely possible to
 

00:20:27.539 --> 00:20:31.639
practice it's rarely possible to
actually compute this compute this Bayes

00:20:31.639 --> 00:20:31.649
actually compute this compute this Bayes
 

00:20:31.649 --> 00:20:35.479
actually compute this compute this Bayes
rule update and it just turns out to be

00:20:35.479 --> 00:20:35.489
rule update and it just turns out to be
 

00:20:35.489 --> 00:20:38.090
rule update and it just turns out to be
intractable so instead we have to find

00:20:38.090 --> 00:20:38.100
intractable so instead we have to find
 

00:20:38.100 --> 00:20:39.889
intractable so instead we have to find
out ways to actually approximate it

00:20:39.889 --> 00:20:39.899
out ways to actually approximate it
 

00:20:39.899 --> 00:20:42.019
out ways to actually approximate it
through sampling so one way that I'll

00:20:42.019 --> 00:20:42.029
through sampling so one way that I'll
 

00:20:42.029 --> 00:20:44.869
through sampling so one way that I'll
talk about today is a very simple notion

00:20:44.869 --> 00:20:44.879
talk about today is a very simple notion
 

00:20:44.879 --> 00:20:46.789
talk about today is a very simple notion
that we've actually already seen in the

00:20:46.789 --> 00:20:46.799
that we've actually already seen in the
 

00:20:46.799 --> 00:20:48.710
that we've actually already seen in the
first lecture and it goes back to this

00:20:48.710 --> 00:20:48.720
first lecture and it goes back to this
 

00:20:48.720 --> 00:20:51.499
first lecture and it goes back to this
idea of using dropout so if you remember

00:20:51.499 --> 00:20:51.509
idea of using dropout so if you remember
 

00:20:51.509 --> 00:20:53.899
idea of using dropout so if you remember
what dropout was dropout is this notion

00:20:53.899 --> 00:20:53.909
what dropout was dropout is this notion
 

00:20:53.909 --> 00:20:57.169
what dropout was dropout is this notion
of randomly killing off a certain

00:20:57.169 --> 00:20:57.179
of randomly killing off a certain
 

00:20:57.179 --> 00:20:59.899
of randomly killing off a certain
percentage of neurons in each of the

00:20:59.899 --> 00:20:59.909
percentage of neurons in each of the
 

00:20:59.909 --> 00:21:02.450
percentage of neurons in each of the
hidden layers now I'm going to tell you

00:21:02.450 --> 00:21:02.460
hidden layers now I'm going to tell you
 

00:21:02.460 --> 00:21:04.369
hidden layers now I'm going to tell you
not how to use it as a regularizer

00:21:04.369 --> 00:21:04.379
not how to use it as a regularizer
 

00:21:04.379 --> 00:21:06.560
not how to use it as a regularizer
but how to use dropout as a way to

00:21:06.560 --> 00:21:06.570
but how to use dropout as a way to
 

00:21:06.570 --> 00:21:08.960
but how to use dropout as a way to
produce reliable uncertainty measures

00:21:08.960 --> 00:21:08.970
produce reliable uncertainty measures
 

00:21:08.970 --> 00:21:13.220
produce reliable uncertainty measures
for your neural network so to do this we

00:21:13.220 --> 00:21:13.230
for your neural network so to do this we
 

00:21:13.230 --> 00:21:15.889
for your neural network so to do this we
have to think of capital T stochastic

00:21:15.889 --> 00:21:15.899
have to think of capital T stochastic
 

00:21:15.899 --> 00:21:17.299
have to think of capital T stochastic
passes through our network where each

00:21:17.299 --> 00:21:17.309
passes through our network where each
 

00:21:17.309 --> 00:21:19.549
passes through our network where each
stochastic pass performs one iteration

00:21:19.549 --> 00:21:19.559
stochastic pass performs one iteration
 

00:21:19.559 --> 00:21:20.210
stochastic pass performs one iteration
of dropouts

00:21:20.210 --> 00:21:20.220
of dropouts
 

00:21:20.220 --> 00:21:22.310
of dropouts
each time you iterate dropout you're

00:21:22.310 --> 00:21:22.320
each time you iterate dropout you're
 

00:21:22.320 --> 00:21:24.259
each time you iterate dropout you're
basically just applying a Bernoulli mask

00:21:24.259 --> 00:21:24.269
basically just applying a Bernoulli mask
 

00:21:24.269 --> 00:21:26.840
basically just applying a Bernoulli mask
of ones and zeros over each of your

00:21:26.840 --> 00:21:26.850
of ones and zeros over each of your
 

00:21:26.850 --> 00:21:28.759
of ones and zeros over each of your
weights so going from the left to the

00:21:28.759 --> 00:21:28.769
weights so going from the left to the
 

00:21:28.769 --> 00:21:31.070
weights so going from the left to the
right you can see our weights which is

00:21:31.070 --> 00:21:31.080
right you can see our weights which is
 

00:21:31.080 --> 00:21:32.930
right you can see our weights which is
like this matrix here different colors

00:21:32.930 --> 00:21:32.940
like this matrix here different colors
 

00:21:32.940 --> 00:21:35.299
like this matrix here different colors
represent the intensity of that weight

00:21:35.299 --> 00:21:35.309
represent the intensity of that weight
 

00:21:35.309 --> 00:21:37.489
represent the intensity of that weight
and we element-wise multiply those

00:21:37.489 --> 00:21:37.499
and we element-wise multiply those
 

00:21:37.499 --> 00:21:39.259
and we element-wise multiply those
weights by our Bernoulli mask width

00:21:39.259 --> 00:21:39.269
weights by our Bernoulli mask width
 

00:21:39.269 --> 00:21:41.749
weights by our Bernoulli mask width
which is just either a 1 or a 0 in every

00:21:41.749 --> 00:21:41.759
which is just either a 1 or a 0 in every
 

00:21:41.759 --> 00:21:45.440
which is just either a 1 or a 0 in every
location the output is a new set of

00:21:45.440 --> 00:21:45.450
location the output is a new set of
 

00:21:45.450 --> 00:21:47.810
location the output is a new set of
weights with certain of those dropped

00:21:47.810 --> 00:21:47.820
weights with certain of those dropped
 

00:21:47.820 --> 00:21:49.460
weights with certain of those dropped
out with certain aspects of those

00:21:49.460 --> 00:21:49.470
out with certain aspects of those
 

00:21:49.470 --> 00:21:54.399
out with certain aspects of those
dropped out now all we have to do is

00:21:54.399 --> 00:21:54.409
dropped out now all we have to do is
 

00:21:54.409 --> 00:21:57.590
dropped out now all we have to do is
compute this T times capital T times we

00:21:57.590 --> 00:21:57.600
compute this T times capital T times we
 

00:21:57.600 --> 00:22:01.070
compute this T times capital T times we
get Kappa theta T weights and we use

00:22:01.070 --> 00:22:01.080
get Kappa theta T weights and we use
 

00:22:01.080 --> 00:22:04.129
get Kappa theta T weights and we use
those theta T different models to

00:22:04.129 --> 00:22:04.139
those theta T different models to
 

00:22:04.139 --> 00:22:06.529
those theta T different models to
actually produce an empirical average of

00:22:06.529 --> 00:22:06.539
actually produce an empirical average of
 

00:22:06.539 --> 00:22:11.359
actually produce an empirical average of
our output class given the data so

00:22:11.359 --> 00:22:11.369
our output class given the data so
 

00:22:11.369 --> 00:22:12.590
our output class given the data so
that's this guy

00:22:12.590 --> 00:22:12.600
that's this guy
 

00:22:12.600 --> 00:22:14.690
that's this guy
well we're actually really interested in

00:22:14.690 --> 00:22:14.700
well we're actually really interested in
 

00:22:14.700 --> 00:22:16.460
well we're actually really interested in
why I brought this topic up was the

00:22:16.460 --> 00:22:16.470
why I brought this topic up was the
 

00:22:16.470 --> 00:22:18.499
why I brought this topic up was the
notion of uncertainty though and that's

00:22:18.499 --> 00:22:18.509
notion of uncertainty though and that's
 

00:22:18.509 --> 00:22:22.669
notion of uncertainty though and that's
the variance of our predictions right

00:22:22.669 --> 00:22:22.679
the variance of our predictions right
 

00:22:22.679 --> 00:22:25.490
the variance of our predictions right
there so this is a very powerful idea

00:22:25.490 --> 00:22:25.500
there so this is a very powerful idea
 

00:22:25.500 --> 00:22:28.990
there so this is a very powerful idea
all it means is that we can obtain

00:22:28.990 --> 00:22:29.000
all it means is that we can obtain
 

00:22:29.000 --> 00:22:31.370
all it means is that we can obtain
reliable model uncertainty estimates

00:22:31.370 --> 00:22:31.380
reliable model uncertainty estimates
 

00:22:31.380 --> 00:22:33.799
reliable model uncertainty estimates
simply by training our network during

00:22:33.799 --> 00:22:33.809
simply by training our network during
 

00:22:33.809 --> 00:22:36.049
simply by training our network during
runtime with dropout and then instead of

00:22:36.049 --> 00:22:36.059
runtime with dropout and then instead of
 

00:22:36.059 --> 00:22:39.049
runtime with dropout and then instead of
estimating or classifying just a single

00:22:39.049 --> 00:22:39.059
estimating or classifying just a single
 

00:22:39.059 --> 00:22:40.820
estimating or classifying just a single
pass through this network at test time

00:22:40.820 --> 00:22:40.830
pass through this network at test time
 

00:22:40.830 --> 00:22:44.120
pass through this network at test time
we classify capital teet iterations of

00:22:44.120 --> 00:22:44.130
we classify capital teet iterations of
 

00:22:44.130 --> 00:22:46.850
we classify capital teet iterations of
this network and then use it to compute

00:22:46.850 --> 00:22:46.860
this network and then use it to compute
 

00:22:46.860 --> 00:22:48.560
this network and then use it to compute
a variance over these outputs and that

00:22:48.560 --> 00:22:48.570
a variance over these outputs and that
 

00:22:48.570 --> 00:22:50.629
a variance over these outputs and that
variance gives us a estimation of our

00:22:50.629 --> 00:22:50.639
variance gives us a estimation of our
 

00:22:50.639 --> 00:22:54.379
variance gives us a estimation of our
uncertainty now to give you an example

00:22:54.379 --> 00:22:54.389
uncertainty now to give you an example
 

00:22:54.389 --> 00:22:56.389
uncertainty now to give you an example
of how this looks in practice let's look

00:22:56.389 --> 00:22:56.399
of how this looks in practice let's look
 

00:22:56.399 --> 00:22:59.690
of how this looks in practice let's look
at this this network that was trained to

00:22:59.690 --> 00:22:59.700
at this this network that was trained to
 

00:22:59.700 --> 00:23:03.499
at this this network that was trained to
take as input images of the real world

00:23:03.499 --> 00:23:03.509
take as input images of the real world
 

00:23:03.509 --> 00:23:07.580
take as input images of the real world
and outputs predicted depth maps oh it

00:23:07.580 --> 00:23:07.590
and outputs predicted depth maps oh it
 

00:23:07.590 --> 00:23:10.700
and outputs predicted depth maps oh it
looks like my text was a little off but

00:23:10.700 --> 00:23:10.710
looks like my text was a little off but
 

00:23:10.710 --> 00:23:14.990
looks like my text was a little off but
that's okay so at the output we have a

00:23:14.990 --> 00:23:15.000
that's okay so at the output we have a
 

00:23:15.000 --> 00:23:16.789
that's okay so at the output we have a
predicted death map where at each pixel

00:23:16.789 --> 00:23:16.799
predicted death map where at each pixel
 

00:23:16.799 --> 00:23:19.789
predicted death map where at each pixel
the network is predicting the depth in

00:23:19.789 --> 00:23:19.799
the network is predicting the depth in
 

00:23:19.799 --> 00:23:23.990
the network is predicting the depth in
the real world of that pixel now when we

00:23:23.990 --> 00:23:24.000
the real world of that pixel now when we
 

00:23:24.000 --> 00:23:26.930
the real world of that pixel now when we
run Bayesian model uncertainty using the

00:23:26.930 --> 00:23:26.940
run Bayesian model uncertainty using the
 

00:23:26.940 --> 00:23:28.519
run Bayesian model uncertainty using the
exact same dropout method that I just

00:23:28.519 --> 00:23:28.529
exact same dropout method that I just
 

00:23:28.529 --> 00:23:32.899
exact same dropout method that I just
described we can see that the end the

00:23:32.899 --> 00:23:32.909
described we can see that the end the
 

00:23:32.909 --> 00:23:34.850
described we can see that the end the
model is most uncertain in some very

00:23:34.850 --> 00:23:34.860
model is most uncertain in some very
 

00:23:34.860 --> 00:23:37.039
model is most uncertain in some very
interesting locations so first of all

00:23:37.039 --> 00:23:37.049
interesting locations so first of all
 

00:23:37.049 --> 00:23:38.539
interesting locations so first of all
pay attention to that location right

00:23:38.539 --> 00:23:38.549
pay attention to that location right
 

00:23:38.549 --> 00:23:41.810
pay attention to that location right
there if you look where where is that

00:23:41.810 --> 00:23:41.820
there if you look where where is that
 

00:23:41.820 --> 00:23:43.970
there if you look where where is that
location exactly it's just the window

00:23:43.970 --> 00:23:43.980
location exactly it's just the window
 

00:23:43.980 --> 00:23:47.210
location exactly it's just the window
sill of this car and in computer vision

00:23:47.210 --> 00:23:47.220
sill of this car and in computer vision
 

00:23:47.220 --> 00:23:51.409
sill of this car and in computer vision
windows and specular objects are very

00:23:51.409 --> 00:23:51.419
windows and specular objects are very
 

00:23:51.419 --> 00:23:54.619
windows and specular objects are very
difficult to to basically model because

00:23:54.619 --> 00:23:54.629
difficult to to basically model because
 

00:23:54.629 --> 00:23:56.960
difficult to to basically model because
we can't actually tell their surface

00:23:56.960 --> 00:23:56.970
we can't actually tell their surface
 

00:23:56.970 --> 00:23:58.909
we can't actually tell their surface
reliably right so we're seeing the light

00:23:58.909 --> 00:23:58.919
reliably right so we're seeing the light
 

00:23:58.919 --> 00:24:01.039
reliably right so we're seeing the light
from actually the sky we're not actually

00:24:01.039 --> 00:24:01.049
from actually the sky we're not actually
 

00:24:01.049 --> 00:24:02.690
from actually the sky we're not actually
seeing the surface of the window in that

00:24:02.690 --> 00:24:02.700
seeing the surface of the window in that
 

00:24:02.700 --> 00:24:04.970
seeing the surface of the window in that
location so it can be very difficult for

00:24:04.970 --> 00:24:04.980
location so it can be very difficult for
 

00:24:04.980 --> 00:24:08.289
location so it can be very difficult for
us to model the the depth in that place

00:24:08.289 --> 00:24:08.299
us to model the the depth in that place
 

00:24:08.299 --> 00:24:10.820
us to model the the depth in that place
additionally we see that the model is

00:24:10.820 --> 00:24:10.830
additionally we see that the model is
 

00:24:10.830 --> 00:24:13.039
additionally we see that the model is
very uncertain on the edges of the cars

00:24:13.039 --> 00:24:13.049
very uncertain on the edges of the cars
 

00:24:13.049 --> 00:24:16.279
very uncertain on the edges of the cars
because these are places where the depth

00:24:16.279 --> 00:24:16.289
because these are places where the depth
 

00:24:16.289 --> 00:24:18.529
because these are places where the depth
is changing very rapidly so the

00:24:18.529 --> 00:24:18.539
is changing very rapidly so the
 

00:24:18.539 --> 00:24:20.210
is changing very rapidly so the
prediction may be least accurate in

00:24:20.210 --> 00:24:20.220
prediction may be least accurate in
 

00:24:20.220 --> 00:24:23.029
prediction may be least accurate in
these locations so having reliable

00:24:23.029 --> 00:24:23.039
these locations so having reliable
 

00:24:23.039 --> 00:24:25.100
these locations so having reliable
uncertainty estimates can be an

00:24:25.100 --> 00:24:25.110
uncertainty estimates can be an
 

00:24:25.110 --> 00:24:26.420
uncertainty estimates can be an
extremely powerful

00:24:26.420 --> 00:24:26.430
extremely powerful
 

00:24:26.430 --> 00:24:28.670
extremely powerful
way to actually interpret deep learning

00:24:28.670 --> 00:24:28.680
way to actually interpret deep learning
 

00:24:28.680 --> 00:24:31.070
way to actually interpret deep learning
models and also provide human

00:24:31.070 --> 00:24:31.080
models and also provide human
 

00:24:31.080 --> 00:24:33.050
models and also provide human
practitioners especially in the realm of

00:24:33.050 --> 00:24:33.060
practitioners especially in the realm of
 

00:24:33.060 --> 00:24:37.460
practitioners especially in the realm of
safe AI that's a way to interpret the

00:24:37.460 --> 00:24:37.470
safe AI that's a way to interpret the
 

00:24:37.470 --> 00:24:41.990
safe AI that's a way to interpret the
results and also trusts our results with

00:24:41.990 --> 00:24:42.000
results and also trusts our results with
 

00:24:42.000 --> 00:24:43.580
results and also trusts our results with
a certain amount of or a certain grain

00:24:43.580 --> 00:24:43.590
a certain amount of or a certain grain
 

00:24:43.590 --> 00:24:48.680
a certain amount of or a certain grain
of salt so for the next and final part

00:24:48.680 --> 00:24:48.690
of salt so for the next and final part
 

00:24:48.690 --> 00:24:50.810
of salt so for the next and final part
of this talk I'd like to address this

00:24:50.810 --> 00:24:50.820
of this talk I'd like to address this
 

00:24:50.820 --> 00:24:53.270
of this talk I'd like to address this
notion of learning to learn so this is a

00:24:53.270 --> 00:24:53.280
notion of learning to learn so this is a
 

00:24:53.280 --> 00:24:57.980
notion of learning to learn so this is a
really cool sounding topic it aims to

00:24:57.980 --> 00:24:57.990
really cool sounding topic it aims to
 

00:24:57.990 --> 00:25:00.440
really cool sounding topic it aims to
basically learn not just a single model

00:25:00.440 --> 00:25:00.450
basically learn not just a single model
 

00:25:00.450 --> 00:25:02.480
basically learn not just a single model
that's optimized to perform a single

00:25:02.480 --> 00:25:02.490
that's optimized to perform a single
 

00:25:02.490 --> 00:25:04.700
that's optimized to perform a single
task like we've learned basically and

00:25:04.700 --> 00:25:04.710
task like we've learned basically and
 

00:25:04.710 --> 00:25:07.190
task like we've learned basically and
all of our lectures previous to this one

00:25:07.190 --> 00:25:07.200
all of our lectures previous to this one
 

00:25:07.200 --> 00:25:10.220
all of our lectures previous to this one
but it learns how to learn which model

00:25:10.220 --> 00:25:10.230
but it learns how to learn which model
 

00:25:10.230 --> 00:25:14.900
but it learns how to learn which model
to use to train that task so first let's

00:25:14.900 --> 00:25:14.910
to use to train that task so first let's
 

00:25:14.910 --> 00:25:16.550
to use to train that task so first let's
understand like why we might want to do

00:25:16.550 --> 00:25:16.560
understand like why we might want to do
 

00:25:16.560 --> 00:25:18.140
understand like why we might want to do
something like that I hope this is

00:25:18.140 --> 00:25:18.150
something like that I hope this is
 

00:25:18.150 --> 00:25:20.570
something like that I hope this is
pretty obvious to you by now but humans

00:25:20.570 --> 00:25:20.580
pretty obvious to you by now but humans
 

00:25:20.580 --> 00:25:23.270
pretty obvious to you by now but humans
are not built in a way where we're

00:25:23.270 --> 00:25:23.280
are not built in a way where we're
 

00:25:23.280 --> 00:25:26.060
are not built in a way where we're
learning where we're executing just a

00:25:26.060 --> 00:25:26.070
learning where we're executing just a
 

00:25:26.070 --> 00:25:27.950
learning where we're executing just a
single task at a time we're executing

00:25:27.950 --> 00:25:27.960
single task at a time we're executing
 

00:25:27.960 --> 00:25:31.670
single task at a time we're executing
many many many different tasks and all

00:25:31.670 --> 00:25:31.680
many many many different tasks and all
 

00:25:31.680 --> 00:25:33.200
many many many different tasks and all
of these tasks are constantly

00:25:33.200 --> 00:25:33.210
of these tasks are constantly
 

00:25:33.210 --> 00:25:35.930
of these tasks are constantly
interacting with each other in ways that

00:25:35.930 --> 00:25:35.940
interacting with each other in ways that
 

00:25:35.940 --> 00:25:38.510
interacting with each other in ways that
learning one task can actually aid

00:25:38.510 --> 00:25:38.520
learning one task can actually aid
 

00:25:38.520 --> 00:25:40.310
learning one task can actually aid
speed-up or deter the learning of

00:25:40.310 --> 00:25:40.320
speed-up or deter the learning of
 

00:25:40.320 --> 00:25:43.790
speed-up or deter the learning of
another task at any given time modern

00:25:43.790 --> 00:25:43.800
another task at any given time modern
 

00:25:43.800 --> 00:25:45.050
another task at any given time modern
deep neural network architectures are

00:25:45.050 --> 00:25:45.060
deep neural network architectures are
 

00:25:45.060 --> 00:25:46.550
deep neural network architectures are
not like this they're optimized for a

00:25:46.550 --> 00:25:46.560
not like this they're optimized for a
 

00:25:46.560 --> 00:25:48.170
not like this they're optimized for a
single task and this goes back to the

00:25:48.170 --> 00:25:48.180
single task and this goes back to the
 

00:25:48.180 --> 00:25:49.400
single task and this goes back to the
very beginning of this talk where we

00:25:49.400 --> 00:25:49.410
very beginning of this talk where we
 

00:25:49.410 --> 00:25:50.960
very beginning of this talk where we
talked about the universal approximator

00:25:50.960 --> 00:25:50.970
talked about the universal approximator
 

00:25:50.970 --> 00:25:54.980
talked about the universal approximator
and as these models become more and more

00:25:54.980 --> 00:25:54.990
and as these models become more and more
 

00:25:54.990 --> 00:25:57.170
and as these models become more and more
complex what ends up happening is that

00:25:57.170 --> 00:25:57.180
complex what ends up happening is that
 

00:25:57.180 --> 00:25:59.840
complex what ends up happening is that
you have to have more and more expert

00:25:59.840 --> 00:25:59.850
you have to have more and more expert
 

00:25:59.850 --> 00:26:02.030
you have to have more and more expert
knowledge to actually build and deploy

00:26:02.030 --> 00:26:02.040
knowledge to actually build and deploy
 

00:26:02.040 --> 00:26:03.470
knowledge to actually build and deploy
these models in practice and that's

00:26:03.470 --> 00:26:03.480
these models in practice and that's
 

00:26:03.480 --> 00:26:05.210
these models in practice and that's
exactly why all of you are here you're

00:26:05.210 --> 00:26:05.220
exactly why all of you are here you're
 

00:26:05.220 --> 00:26:07.010
exactly why all of you are here you're
here to basically get that experience

00:26:07.010 --> 00:26:07.020
here to basically get that experience
 

00:26:07.020 --> 00:26:09.590
here to basically get that experience
such that you yourselves can build these

00:26:09.590 --> 00:26:09.600
such that you yourselves can build these
 

00:26:09.600 --> 00:26:14.120
such that you yourselves can build these
deep learning models so what we want is

00:26:14.120 --> 00:26:14.130
deep learning models so what we want is
 

00:26:14.130 --> 00:26:16.910
deep learning models so what we want is
actually an automated machine learning

00:26:16.910 --> 00:26:16.920
actually an automated machine learning
 

00:26:16.920 --> 00:26:19.070
actually an automated machine learning
framework where we can actually learn to

00:26:19.070 --> 00:26:19.080
framework where we can actually learn to
 

00:26:19.080 --> 00:26:20.900
framework where we can actually learn to
learn and this basically means we want

00:26:20.900 --> 00:26:20.910
learn and this basically means we want
 

00:26:20.910 --> 00:26:22.850
learn and this basically means we want
to build the model that learns which

00:26:22.850 --> 00:26:22.860
to build the model that learns which
 

00:26:22.860 --> 00:26:27.850
to build the model that learns which
model to use given a problem definition

00:26:27.850 --> 00:26:27.860
model to use given a problem definition
 

00:26:27.860 --> 00:26:30.230
model to use given a problem definition
one example that I'd like to just use as

00:26:30.230 --> 00:26:30.240
one example that I'd like to just use as
 

00:26:30.240 --> 00:26:32.150
one example that I'd like to just use as
an illustration of this idea so there

00:26:32.150 --> 00:26:32.160
an illustration of this idea so there
 

00:26:32.160 --> 00:26:34.610
an illustration of this idea so there
are many ways that auto ml can be

00:26:34.610 --> 00:26:34.620
are many ways that auto ml can be
 

00:26:34.620 --> 00:26:36.290
are many ways that auto ml can be
accomplished and this is just one

00:26:36.290 --> 00:26:36.300
accomplished and this is just one
 

00:26:36.300 --> 00:26:37.700
accomplished and this is just one
example of those ways so I'd like to

00:26:37.700 --> 00:26:37.710
example of those ways so I'd like to
 

00:26:37.710 --> 00:26:39.220
example of those ways so I'd like to
focus on this

00:26:39.220 --> 00:26:39.230
focus on this
 

00:26:39.230 --> 00:26:41.080
focus on this
illustration here and I like to walk

00:26:41.080 --> 00:26:41.090
illustration here and I like to walk
 

00:26:41.090 --> 00:26:43.380
illustration here and I like to walk
through it it's just a way that we can

00:26:43.380 --> 00:26:43.390
through it it's just a way that we can
 

00:26:43.390 --> 00:26:48.040
through it it's just a way that we can
learn to learn so this this system

00:26:48.040 --> 00:26:48.050
learn to learn so this this system
 

00:26:48.050 --> 00:26:50.500
learn to learn so this this system
focuses on two parts the first part is

00:26:50.500 --> 00:26:50.510
focuses on two parts the first part is
 

00:26:50.510 --> 00:26:52.570
focuses on two parts the first part is
the controller RNN in red on the left

00:26:52.570 --> 00:26:52.580
the controller RNN in red on the left
 

00:26:52.580 --> 00:26:55.540
the controller RNN in red on the left
and this controller RNN is basically

00:26:55.540 --> 00:26:55.550
and this controller RNN is basically
 

00:26:55.550 --> 00:26:57.910
and this controller RNN is basically
just sampling different architectures of

00:26:57.910 --> 00:26:57.920
just sampling different architectures of
 

00:26:57.920 --> 00:27:00.070
just sampling different architectures of
neural networks so if you remember in

00:27:00.070 --> 00:27:00.080
neural networks so if you remember in
 

00:27:00.080 --> 00:27:02.920
neural networks so if you remember in
your first lab you created an RNN that

00:27:02.920 --> 00:27:02.930
your first lab you created an RNN that
 

00:27:02.930 --> 00:27:06.040
your first lab you created an RNN that
could sample different music notes this

00:27:06.040 --> 00:27:06.050
could sample different music notes this
 

00:27:06.050 --> 00:27:07.720
could sample different music notes this
is no different except now we're not

00:27:07.720 --> 00:27:07.730
is no different except now we're not
 

00:27:07.730 --> 00:27:10.150
is no different except now we're not
sampling music notes we're sampling an

00:27:10.150 --> 00:27:10.160
sampling music notes we're sampling an
 

00:27:10.160 --> 00:27:13.060
sampling music notes we're sampling an
entire neural network itself so we're

00:27:13.060 --> 00:27:13.070
entire neural network itself so we're
 

00:27:13.070 --> 00:27:14.680
entire neural network itself so we're
sampling that parameters that define

00:27:14.680 --> 00:27:14.690
sampling that parameters that define
 

00:27:14.690 --> 00:27:17.050
sampling that parameters that define
that neural network so let's call that

00:27:17.050 --> 00:27:17.060
that neural network so let's call that
 

00:27:17.060 --> 00:27:18.880
that neural network so let's call that
the architecture or the child's network

00:27:18.880 --> 00:27:18.890
the architecture or the child's network
 

00:27:18.890 --> 00:27:20.650
the architecture or the child's network
so that's the network that will actually

00:27:20.650 --> 00:27:20.660
so that's the network that will actually
 

00:27:20.660 --> 00:27:24.520
so that's the network that will actually
be used to solve our task in the end so

00:27:24.520 --> 00:27:24.530
be used to solve our task in the end so
 

00:27:24.530 --> 00:27:26.560
be used to solve our task in the end so
that network is passed on to the second

00:27:26.560 --> 00:27:26.570
that network is passed on to the second
 

00:27:26.570 --> 00:27:30.010
that network is passed on to the second
bottle so that network is passed on to

00:27:30.010 --> 00:27:30.020
bottle so that network is passed on to
 

00:27:30.020 --> 00:27:30.850
bottle so that network is passed on to
the second one

00:27:30.850 --> 00:27:30.860
the second one
 

00:27:30.860 --> 00:27:35.110
the second one
and in that piece we actually use that

00:27:35.110 --> 00:27:35.120
and in that piece we actually use that
 

00:27:35.120 --> 00:27:37.090
and in that piece we actually use that
network that was generated by the Arnon

00:27:37.090 --> 00:27:37.100
network that was generated by the Arnon
 

00:27:37.100 --> 00:27:40.240
network that was generated by the Arnon
to train a model depending on how well

00:27:40.240 --> 00:27:40.250
to train a model depending on how well
 

00:27:40.250 --> 00:27:43.660
to train a model depending on how well
that model did we can provide feedback

00:27:43.660 --> 00:27:43.670
that model did we can provide feedback
 

00:27:43.670 --> 00:27:45.970
that model did we can provide feedback
to the RNN such I can produce an even

00:27:45.970 --> 00:27:45.980
to the RNN such I can produce an even
 

00:27:45.980 --> 00:27:49.630
to the RNN such I can produce an even
better model on the next time step so

00:27:49.630 --> 00:27:49.640
better model on the next time step so
 

00:27:49.640 --> 00:27:51.580
better model on the next time step so
let's go into this piece by piece so

00:27:51.580 --> 00:27:51.590
let's go into this piece by piece so
 

00:27:51.590 --> 00:27:53.590
let's go into this piece by piece so
let's look at just the RNN part in more

00:27:53.590 --> 00:27:53.600
let's look at just the RNN part in more
 

00:27:53.600 --> 00:27:56.050
let's look at just the RNN part in more
detail so this is the RNN or the

00:27:56.050 --> 00:27:56.060
detail so this is the RNN or the
 

00:27:56.060 --> 00:27:58.450
detail so this is the RNN or the
architecture generator so like I said

00:27:58.450 --> 00:27:58.460
architecture generator so like I said
 

00:27:58.460 --> 00:28:00.100
architecture generator so like I said
this is very similar to the way that you

00:28:00.100 --> 00:28:00.110
this is very similar to the way that you
 

00:28:00.110 --> 00:28:01.960
this is very similar to the way that you
are generating songs in your first lab

00:28:01.960 --> 00:28:01.970
are generating songs in your first lab
 

00:28:01.970 --> 00:28:04.050
are generating songs in your first lab
except now we're not generating songs

00:28:04.050 --> 00:28:04.060
except now we're not generating songs
 

00:28:04.060 --> 00:28:07.300
except now we're not generating songs
the time steps are going from layers on

00:28:07.300 --> 00:28:07.310
the time steps are going from layers on
 

00:28:07.310 --> 00:28:10.980
the time steps are going from layers on
the x-axis and we're just generating

00:28:10.980 --> 00:28:10.990
the x-axis and we're just generating
 

00:28:10.990 --> 00:28:13.200
the x-axis and we're just generating
parameters or

00:28:13.200 --> 00:28:13.210
parameters or
 

00:28:13.210 --> 00:28:16.150
parameters or
hyper parameters rather for each of

00:28:16.150 --> 00:28:16.160
hyper parameters rather for each of
 

00:28:16.160 --> 00:28:18.370
hyper parameters rather for each of
those layers so this is a generator for

00:28:18.370 --> 00:28:18.380
those layers so this is a generator for
 

00:28:18.380 --> 00:28:20.680
those layers so this is a generator for
a convolutional neural network because

00:28:20.680 --> 00:28:20.690
a convolutional neural network because
 

00:28:20.690 --> 00:28:22.000
a convolutional neural network because
we're producing parameters like the

00:28:22.000 --> 00:28:22.010
we're producing parameters like the
 

00:28:22.010 --> 00:28:23.500
we're producing parameters like the
filter height the filter width the

00:28:23.500 --> 00:28:23.510
filter height the filter width the
 

00:28:23.510 --> 00:28:26.920
filter height the filter width the
stride height etc so what we can do is

00:28:26.920 --> 00:28:26.930
stride height etc so what we can do is
 

00:28:26.930 --> 00:28:28.750
stride height etc so what we can do is
we can add each time step produce a

00:28:28.750 --> 00:28:28.760
we can add each time step produce a
 

00:28:28.760 --> 00:28:31.000
we can add each time step produce a
probability distribution of over each of

00:28:31.000 --> 00:28:31.010
probability distribution of over each of
 

00:28:31.010 --> 00:28:32.890
probability distribution of over each of
these parameters and we can essentially

00:28:32.890 --> 00:28:32.900
these parameters and we can essentially
 

00:28:32.900 --> 00:28:34.840
these parameters and we can essentially
just sample an architecture or sample a

00:28:34.840 --> 00:28:34.850
just sample an architecture or sample a
 

00:28:34.850 --> 00:28:37.360
just sample an architecture or sample a
child Network once we have that child

00:28:37.360 --> 00:28:37.370
child Network once we have that child
 

00:28:37.370 --> 00:28:39.310
child Network once we have that child
Network which I'm showing right here in

00:28:39.310 --> 00:28:39.320
Network which I'm showing right here in
 

00:28:39.320 --> 00:28:44.080
Network which I'm showing right here in
blue we can train it using our data set

00:28:44.080 --> 00:28:44.090
blue we can train it using our data set
 

00:28:44.090 --> 00:28:46.390
blue we can train it using our data set
that we ultimately want to solve so we

00:28:46.390 --> 00:28:46.400
that we ultimately want to solve so we
 

00:28:46.400 --> 00:28:48.430
that we ultimately want to solve so we
put our training data in and we get our

00:28:48.430 --> 00:28:48.440
put our training data in and we get our
 

00:28:48.440 --> 00:28:50.590
put our training data in and we get our
predicted labels out this is the this is

00:28:50.590 --> 00:28:50.600
predicted labels out this is the this is
 

00:28:50.600 --> 00:28:51.850
predicted labels out this is the this is
the realm that we've been dealing with

00:28:51.850 --> 00:28:51.860
the realm that we've been dealing with
 

00:28:51.860 --> 00:28:53.220
the realm that we've been dealing with
so far in this

00:28:53.220 --> 00:28:53.230
so far in this
 

00:28:53.230 --> 00:28:55.680
so far in this
right so we have our this is basically

00:28:55.680 --> 00:28:55.690
right so we have our this is basically
 

00:28:55.690 --> 00:28:57.540
right so we have our this is basically
what we've seen so far so this is just a

00:28:57.540 --> 00:28:57.550
what we've seen so far so this is just a
 

00:28:57.550 --> 00:28:59.460
what we've seen so far so this is just a
single network and we have our training

00:28:59.460 --> 00:28:59.470
single network and we have our training
 

00:28:59.470 --> 00:29:02.940
single network and we have our training
data that we're using to Train it we see

00:29:02.940 --> 00:29:02.950
data that we're using to Train it we see
 

00:29:02.950 --> 00:29:05.400
data that we're using to Train it we see
how well this does depending on the

00:29:05.400 --> 00:29:05.410
how well this does depending on the
 

00:29:05.410 --> 00:29:08.220
how well this does depending on the
accuracy of this model that accuracy is

00:29:08.220 --> 00:29:08.230
accuracy of this model that accuracy is
 

00:29:08.230 --> 00:29:11.460
accuracy of this model that accuracy is
used to provide feedback back to the RNN

00:29:11.460 --> 00:29:11.470
used to provide feedback back to the RNN
 

00:29:11.470 --> 00:29:14.550
used to provide feedback back to the RNN
and update how it produces or how it

00:29:14.550 --> 00:29:14.560
and update how it produces or how it
 

00:29:14.560 --> 00:29:19.290
and update how it produces or how it
generates these models so let's look at

00:29:19.290 --> 00:29:19.300
generates these models so let's look at
 

00:29:19.300 --> 00:29:21.690
generates these models so let's look at
this one more time to summarize this is

00:29:21.690 --> 00:29:21.700
this one more time to summarize this is
 

00:29:21.700 --> 00:29:23.430
this one more time to summarize this is
an extremely powerful idea it's really

00:29:23.430 --> 00:29:23.440
an extremely powerful idea it's really
 

00:29:23.440 --> 00:29:25.830
an extremely powerful idea it's really
really really exciting because it shows

00:29:25.830 --> 00:29:25.840
really really exciting because it shows
 

00:29:25.840 --> 00:29:29.100
really really exciting because it shows
that an RNN can be actually combined in

00:29:29.100 --> 00:29:29.110
that an RNN can be actually combined in
 

00:29:29.110 --> 00:29:31.620
that an RNN can be actually combined in
a reinforcement learning paradigm where

00:29:31.620 --> 00:29:31.630
a reinforcement learning paradigm where
 

00:29:31.630 --> 00:29:33.720
a reinforcement learning paradigm where
the R and n itself is almost like the

00:29:33.720 --> 00:29:33.730
the R and n itself is almost like the
 

00:29:33.730 --> 00:29:35.610
the R and n itself is almost like the
agent in reinforcement learning it's

00:29:35.610 --> 00:29:35.620
agent in reinforcement learning it's
 

00:29:35.620 --> 00:29:39.420
agent in reinforcement learning it's
learning to make changes to the child

00:29:39.420 --> 00:29:39.430
learning to make changes to the child
 

00:29:39.430 --> 00:29:41.700
learning to make changes to the child
network architecture depending on how

00:29:41.700 --> 00:29:41.710
network architecture depending on how
 

00:29:41.710 --> 00:29:43.560
network architecture depending on how
that child network performs on a

00:29:43.560 --> 00:29:43.570
that child network performs on a
 

00:29:43.570 --> 00:29:47.460
that child network performs on a
training set this means that we're able

00:29:47.460 --> 00:29:47.470
training set this means that we're able
 

00:29:47.470 --> 00:29:49.290
training set this means that we're able
to create an AI system capable of

00:29:49.290 --> 00:29:49.300
to create an AI system capable of
 

00:29:49.300 --> 00:29:51.560
to create an AI system capable of
generating brand-new neural networks

00:29:51.560 --> 00:29:51.570
generating brand-new neural networks
 

00:29:51.570 --> 00:29:53.880
generating brand-new neural networks
specialized to solve specific tasks

00:29:53.880 --> 00:29:53.890
specialized to solve specific tasks
 

00:29:53.890 --> 00:29:55.740
specialized to solve specific tasks
rather than just creating a single

00:29:55.740 --> 00:29:55.750
rather than just creating a single
 

00:29:55.750 --> 00:29:58.050
rather than just creating a single
neural network that we create just to

00:29:58.050 --> 00:29:58.060
neural network that we create just to
 

00:29:58.060 --> 00:29:59.430
neural network that we create just to
solve that tasks that we want to create

00:29:59.430 --> 00:29:59.440
solve that tasks that we want to create
 

00:29:59.440 --> 00:30:01.310
solve that tasks that we want to create
that we want to solve

00:30:01.310 --> 00:30:01.320
that we want to solve
 

00:30:01.320 --> 00:30:03.960
that we want to solve
thus this has significantly reduced the

00:30:03.960 --> 00:30:03.970
thus this has significantly reduced the
 

00:30:03.970 --> 00:30:06.060
thus this has significantly reduced the
difficulty in optimizing these neural

00:30:06.060 --> 00:30:06.070
difficulty in optimizing these neural
 

00:30:06.070 --> 00:30:09.390
difficulty in optimizing these neural
networks for architectures for different

00:30:09.390 --> 00:30:09.400
networks for architectures for different
 

00:30:09.400 --> 00:30:11.580
networks for architectures for different
tasks and this also reduces the need for

00:30:11.580 --> 00:30:11.590
tasks and this also reduces the need for
 

00:30:11.590 --> 00:30:13.560
tasks and this also reduces the need for
expert engineers to design these

00:30:13.560 --> 00:30:13.570
expert engineers to design these
 

00:30:13.570 --> 00:30:16.770
expert engineers to design these
architectures so this really gets at the

00:30:16.770 --> 00:30:16.780
architectures so this really gets at the
 

00:30:16.780 --> 00:30:19.770
architectures so this really gets at the
heart of artificial intelligence so when

00:30:19.770 --> 00:30:19.780
heart of artificial intelligence so when
 

00:30:19.780 --> 00:30:22.560
heart of artificial intelligence so when
I began this course we spoke about what

00:30:22.560 --> 00:30:22.570
I began this course we spoke about what
 

00:30:22.570 --> 00:30:24.770
I began this course we spoke about what
it actually means to be intelligent and

00:30:24.770 --> 00:30:24.780
it actually means to be intelligent and
 

00:30:24.780 --> 00:30:27.030
it actually means to be intelligent and
loosely I defined this as the ability to

00:30:27.030 --> 00:30:27.040
loosely I defined this as the ability to
 

00:30:27.040 --> 00:30:28.920
loosely I defined this as the ability to
take information process that

00:30:28.920 --> 00:30:28.930
take information process that
 

00:30:28.930 --> 00:30:32.340
take information process that
information and use it to inform future

00:30:32.340 --> 00:30:32.350
information and use it to inform future
 

00:30:32.350 --> 00:30:37.590
information and use it to inform future
decisions so the human learning pipeline

00:30:37.590 --> 00:30:37.600
decisions so the human learning pipeline
 

00:30:37.600 --> 00:30:39.480
decisions so the human learning pipeline
is not restricted to solving just one

00:30:39.480 --> 00:30:39.490
is not restricted to solving just one
 

00:30:39.490 --> 00:30:41.160
is not restricted to solving just one
task at a time like I mentioned before

00:30:41.160 --> 00:30:41.170
task at a time like I mentioned before
 

00:30:41.170 --> 00:30:43.580
task at a time like I mentioned before
how we learn one task can greatly impact

00:30:43.580 --> 00:30:43.590
how we learn one task can greatly impact
 

00:30:43.590 --> 00:30:47.190
how we learn one task can greatly impact
speed up or even slow down our learning

00:30:47.190 --> 00:30:47.200
speed up or even slow down our learning
 

00:30:47.200 --> 00:30:50.190
speed up or even slow down our learning
of other tasks and the artificial models

00:30:50.190 --> 00:30:50.200
of other tasks and the artificial models
 

00:30:50.200 --> 00:30:51.690
of other tasks and the artificial models
that we create today simply do not

00:30:51.690 --> 00:30:51.700
that we create today simply do not
 

00:30:51.700 --> 00:30:54.030
that we create today simply do not
capture this phenomenon to reach

00:30:54.030 --> 00:30:54.040
capture this phenomenon to reach
 

00:30:54.040 --> 00:30:56.040
capture this phenomenon to reach
artificial general intelligence we need

00:30:56.040 --> 00:30:56.050
artificial general intelligence we need
 

00:30:56.050 --> 00:30:58.320
artificial general intelligence we need
to actually build AI that can not only

00:30:58.320 --> 00:30:58.330
to actually build AI that can not only
 

00:30:58.330 --> 00:31:01.560
to actually build AI that can not only
learn a single task but also be able to

00:31:01.560 --> 00:31:01.570
learn a single task but also be able to
 

00:31:01.570 --> 00:31:03.870
learn a single task but also be able to
improve its own learning and reasoning

00:31:03.870 --> 00:31:03.880
improve its own learning and reasoning
 

00:31:03.880 --> 00:31:05.880
improve its own learning and reasoning
such that it can generalize two sets of

00:31:05.880 --> 00:31:05.890
such that it can generalize two sets of
 

00:31:05.890 --> 00:31:06.720
such that it can generalize two sets of
related

00:31:06.720 --> 00:31:06.730
related
 

00:31:06.730 --> 00:31:10.080
related
dependent tasks I'll leave this with you

00:31:10.080 --> 00:31:10.090
dependent tasks I'll leave this with you
 

00:31:10.090 --> 00:31:11.789
dependent tasks I'll leave this with you
as a thought-provoking point and

00:31:11.789 --> 00:31:11.799
as a thought-provoking point and
 

00:31:11.799 --> 00:31:14.370
as a thought-provoking point and
encourage you to to all talk to each

00:31:14.370 --> 00:31:14.380
encourage you to to all talk to each
 

00:31:14.380 --> 00:31:16.169
encourage you to to all talk to each
other on some ways that we can reach

00:31:16.169 --> 00:31:16.179
other on some ways that we can reach
 

00:31:16.179 --> 00:31:18.060
other on some ways that we can reach
this this higher-order level of

00:31:18.060 --> 00:31:18.070
this this higher-order level of
 

00:31:18.070 --> 00:31:20.010
this this higher-order level of
intelligence that's not just pattern

00:31:20.010 --> 00:31:20.020
intelligence that's not just pattern
 

00:31:20.020 --> 00:31:22.850
intelligence that's not just pattern
recognition but rather a higher-order

00:31:22.850 --> 00:31:22.860
recognition but rather a higher-order
 

00:31:22.860 --> 00:31:25.500
recognition but rather a higher-order
form of reasoning and actually thinking

00:31:25.500 --> 00:31:25.510
form of reasoning and actually thinking
 

00:31:25.510 --> 00:31:27.750
form of reasoning and actually thinking
about about the problems that we're

00:31:27.750 --> 00:31:27.760
about about the problems that we're
 

00:31:27.760 --> 00:31:31.650
about about the problems that we're
trying to solve thank you

00:31:31.650 --> 00:31:31.660
trying to solve thank you
 

00:31:31.660 --> 00:31:37.890
trying to solve thank you
[Applause]

