WEBVTT
Kind: captions
Language: en

00:00:00.090 --> 00:00:02.423
CHRISTOPHER L. EISGRUBER: This
year's Princeton-Fung Global

00:00:02.423 --> 00:00:05.280
Forum addresses one of the most
important political and social

00:00:05.280 --> 00:00:06.720
issues of our time --

00:00:06.720 --> 00:00:09.365
can liberty survive
the digital age?

00:00:09.365 --> 00:00:11.490
CECILIA ROUSE: We're so
happy to be here in Berlin,

00:00:11.490 --> 00:00:15.330
because we just believe it's
so important that Princeton get

00:00:15.330 --> 00:00:18.090
out into the world -- and we
mean that at all levels --

00:00:18.090 --> 00:00:19.830
that our students
have an opportunity

00:00:19.830 --> 00:00:22.515
to live and learn
and work abroad,

00:00:22.515 --> 00:00:24.450
that our faculty
also have a chance

00:00:24.450 --> 00:00:27.300
to interact with faculty
at other institutions,

00:00:27.300 --> 00:00:30.660
and that other faculty and
policymakers and students

00:00:30.660 --> 00:00:33.187
from around the world have a
chance to interact as well.

00:00:33.187 --> 00:00:34.770
ASA CRAIG: We did a
short walking tour

00:00:34.770 --> 00:00:38.490
in the pouring down
rain the other day.

00:00:38.490 --> 00:00:41.310
It was interesting to see
sort of a community that's

00:00:41.310 --> 00:00:45.390
been in development, to
see how people bounce back

00:00:45.390 --> 00:00:47.880
and move forward, and then
at the same time, about some

00:00:47.880 --> 00:00:50.800
of the impacts of different
aspects of history.

00:00:50.800 --> 00:00:53.940
ELISABETH DONAHUE: Putting on
a conference in Berlin, Germany,

00:00:53.940 --> 00:00:56.560
with the organization and
planning going on in Princeton,

00:00:56.560 --> 00:00:58.350
New Jersey, has a
lot of challenges.

00:00:58.350 --> 00:01:00.480
We asked the panelists
to get together

00:01:00.480 --> 00:01:02.730
to really work out
the themes that they

00:01:02.730 --> 00:01:04.290
want to cover in their panels.

00:01:04.290 --> 00:01:06.840
It's not meant to
be a session where

00:01:06.840 --> 00:01:09.280
they plan every single thing
that they're going to say,

00:01:09.280 --> 00:01:11.670
but helps them figure
out what major themes

00:01:11.670 --> 00:01:14.430
and what major topics they want
to make sure to hit when they

00:01:14.430 --> 00:01:15.630
get on stage at the forum.

00:01:15.630 --> 00:01:17.713
VINTON CERF: We're here
to talk about the internet

00:01:17.713 --> 00:01:20.730
and what has happened over the
course of the last 40 years

00:01:20.730 --> 00:01:24.210
since it was invented and
roughly 35 years since it

00:01:24.210 --> 00:01:26.820
was turned on in 1983.

00:01:26.820 --> 00:01:32.640
I think that it would be
impossible to overemphasize

00:01:32.640 --> 00:01:37.710
how critical public trust
is in this internet online

00:01:37.710 --> 00:01:38.340
environment.

00:01:38.340 --> 00:01:42.270
And it is eroding,
with good reason,

00:01:42.270 --> 00:01:45.290
because there are frailties
in the system that need

00:01:45.290 --> 00:01:47.390
to be remedied technically.

00:01:47.390 --> 00:01:49.010
There are problems
that can only be

00:01:49.010 --> 00:01:52.850
addressed by common agreements
across national boundaries.

00:01:52.850 --> 00:01:56.030
There are technologies, like
in the internet of things,

00:01:56.030 --> 00:01:59.270
that need to be
implemented in a way that

00:01:59.270 --> 00:02:03.770
regains people's trust in
the safety and reliability

00:02:03.770 --> 00:02:05.060
of those devices.

00:02:05.060 --> 00:02:08.479
CECILIA ROUSE: It is a pleasure
to introduce our first panel

00:02:08.479 --> 00:02:11.114
the "world" wide web.

00:02:11.114 --> 00:02:12.530
JULIE BRILL: I do
agree that there

00:02:12.530 --> 00:02:14.570
are technological
issues that absolutely

00:02:14.570 --> 00:02:17.600
should be addressed, full stop.

00:02:17.600 --> 00:02:19.100
But I don't think
the alternative

00:02:19.100 --> 00:02:21.580
is to have the government
control these platforms.

00:02:21.580 --> 00:02:23.630
One of the things I'm
very passionate about

00:02:23.630 --> 00:02:26.390
is to make sure that we
set up systems and controls

00:02:26.390 --> 00:02:30.320
and ethical frameworks,
co-regulatory frameworks,

00:02:30.320 --> 00:02:34.670
as well as laws, that will
work when the people in power

00:02:34.670 --> 00:02:37.250
are people you agree
with, as well as when

00:02:37.250 --> 00:02:40.310
the people in power are people
with whom you vehemently

00:02:40.310 --> 00:02:41.230
disagree.

00:02:41.230 --> 00:02:43.640
You need to
future-proof whatever

00:02:43.640 --> 00:02:46.310
you're going to set up
so that it will work,

00:02:46.310 --> 00:02:48.601
whatever your political
persuasion is.

00:02:48.601 --> 00:02:52.706
[INTERPOSING VOICES]

00:02:52.706 --> 00:02:54.330
FRED KAPLAN: Thank
you for coming here.

00:02:54.330 --> 00:02:55.560
[APPLAUSE]

00:02:55.560 --> 00:02:57.180
In terms of our
overall question,

00:02:57.180 --> 00:02:59.550
can liberty survive
the digital age,

00:02:59.550 --> 00:03:05.890
what is it precisely that
concerns you the most?

00:03:05.890 --> 00:03:06.390
David.

00:03:06.390 --> 00:03:07.306
DAVID DOBKIN: I worry.

00:03:07.306 --> 00:03:10.080
There are at least two
other David Dobkins

00:03:10.080 --> 00:03:15.060
that I'm aware of, because I
get their mail, because we're

00:03:15.060 --> 00:03:17.740
conflated in various ways.

00:03:17.740 --> 00:03:21.720
I worry about machine learning
algorithm gone a little bit

00:03:21.720 --> 00:03:24.090
awry that somehow
puts information

00:03:24.090 --> 00:03:27.180
from the three of us together,
assigns it all to me.

00:03:27.180 --> 00:03:28.800
This semester, as
it turns out, I'm

00:03:28.800 --> 00:03:30.720
teaching a course on IT policy.

00:03:30.720 --> 00:03:32.154
And two of my students are here.

00:03:32.154 --> 00:03:34.570
ELIZABETH GARLOW: This forum
is giving us an opportunity

00:03:34.570 --> 00:03:37.870
to hear certainly a European and
a North American perspective,

00:03:37.870 --> 00:03:40.985
but also a global perspective,
that I think will really enrich

00:03:40.985 --> 00:03:42.384
our public policy education.

00:03:42.384 --> 00:03:43.800
ANNIE KHOA: And
what's fascinating

00:03:43.800 --> 00:03:45.300
is that we talk about
a lot of the issues

00:03:45.300 --> 00:03:47.910
in the classroom, but to be
here and listen to practitioners

00:03:47.910 --> 00:03:50.400
and academics talk about
the issue from both sides,

00:03:50.400 --> 00:03:52.320
working on it from
the research side,

00:03:52.320 --> 00:03:54.660
as well as how does this
have policy implications

00:03:54.660 --> 00:03:56.850
on marginalized
communities, et cetera,

00:03:56.850 --> 00:03:58.410
has been a great
learning experience.

00:03:58.410 --> 00:04:01.200
CECILIA ROUSE: Our
third panel of the day,

00:04:01.200 --> 00:04:04.860
called "The Internet of
Things, or Is Your Bow Tie

00:04:04.860 --> 00:04:05.850
Really a Camera?"

00:04:05.850 --> 00:04:07.230
MARGARET MARTONOSI: First
of all, the relevance

00:04:07.230 --> 00:04:08.610
of the conference itself --

00:04:08.610 --> 00:04:11.160
I think it's really struck
a nerve with a lot of people

00:04:11.160 --> 00:04:16.470
to examine what democracy means
in a era where information

00:04:16.470 --> 00:04:18.450
flows so freely in
many ways and what's

00:04:18.450 --> 00:04:19.720
technology's role in that.

00:04:19.720 --> 00:04:22.170
And I think it's particularly
important for technologists

00:04:22.170 --> 00:04:23.619
to be a part of that discussion.

00:04:23.619 --> 00:04:25.410
JULIA BOORSTIN: Nick,
give us some examples

00:04:25.410 --> 00:04:27.600
of ordinary use cases
where things might not

00:04:27.600 --> 00:04:28.809
talk to each other perfectly.

00:04:28.809 --> 00:04:29.641
NICK FEAMSTER: Sure.

00:04:29.641 --> 00:04:31.590
I think even though
this panel is called --

00:04:31.590 --> 00:04:33.750
it refers to the
internet of things,

00:04:33.750 --> 00:04:35.920
I think it's a little
bit of a misnomer.

00:04:35.920 --> 00:04:38.670
We should really just think
of it as the internet.

00:04:38.670 --> 00:04:40.380
And by that, I
mean, increasingly,

00:04:40.380 --> 00:04:43.080
we're seeing more
and more devices

00:04:43.080 --> 00:04:46.800
that have a Wi-Fi radio
just baked into them.

00:04:46.800 --> 00:04:50.820
So it's cool now to have an
internet-connected thermostat.

00:04:50.820 --> 00:04:52.710
Pretty soon everything
you buy is basically

00:04:52.710 --> 00:04:54.293
going to be connected
to the internet.

00:04:54.293 --> 00:04:56.020
So what does that mean?

00:04:56.020 --> 00:04:58.560
Well, when I buy a
house or sell a house

00:04:58.560 --> 00:05:01.620
and there are now 100 things
connected to the internet,

00:05:01.620 --> 00:05:04.860
from the thermostat to the
door locks to the wall switches

00:05:04.860 --> 00:05:06.870
to the light bulbs,
I'm not going

00:05:06.870 --> 00:05:09.030
to disassociate with all those.

00:05:09.030 --> 00:05:10.310
I'm not going to --

00:05:10.310 --> 00:05:12.790
there's no easy way
to delete all my data.

00:05:12.790 --> 00:05:17.817
So what's the factory
reset for my house?

00:05:17.817 --> 00:05:19.900
CHRISTOPHER L. EISGRUBER: We
are grateful that Neelie

00:05:19.900 --> 00:05:23.180
can join us here today to
address a critical question --

00:05:23.180 --> 00:05:25.880
have we lost control
of the internet?

00:05:25.880 --> 00:05:28.460
Please welcome Neelie Kroes.

00:05:28.460 --> 00:05:31.120
NEELIE KROES: It is not only
about debating and discussing

00:05:31.120 --> 00:05:36.850
in this audience, for this
is an outstanding audience --

00:05:36.850 --> 00:05:39.900
international, very
competent and knowledgeable.

00:05:39.900 --> 00:05:43.130
But it's also talking
about how can we

00:05:43.130 --> 00:05:46.216
implement what will
be, at the end,

00:05:46.216 --> 00:05:49.200
be concluded during
this conference.

00:05:49.200 --> 00:05:53.550
Leaking has become a
fact of our daily life.

00:05:53.550 --> 00:05:57.930
Leaks in the White House,
leaks via WikiLeak --

00:05:57.930 --> 00:06:03.020
we witness an unprecedented
amount of orchestrated

00:06:03.020 --> 00:06:06.070
leaks via foreign countries.

00:06:06.070 --> 00:06:08.620
And the latest news
is interesting --

00:06:08.620 --> 00:06:11.460
but you got it
already, which led

00:06:11.460 --> 00:06:14.427
to disrupt the elections
of the free world.

00:06:17.047 --> 00:06:18.630
LAURA ROBERTS: So
I'm a third-year Ph.D.

00:06:18.630 --> 00:06:21.300
student in computer
science at Princeton.

00:06:21.300 --> 00:06:24.444
I'm here with other Princeton
students as volunteers.

00:06:24.444 --> 00:06:26.610
JASMIN PELED: Students
coming from different majors,

00:06:26.610 --> 00:06:27.776
different areas of interest.

00:06:27.776 --> 00:06:30.000
We have graduate students
and undergraduate students,

00:06:30.000 --> 00:06:32.190
people getting their masters,
people getting their Ph.D.s,

00:06:32.190 --> 00:06:33.920
people like me who are
still undergraduate --

00:06:33.920 --> 00:06:34.870
it's a whole group of us.

00:06:34.870 --> 00:06:36.150
GABRIEL STENGEL: We're
about to do a Facebook Live

00:06:36.150 --> 00:06:38.054
event, answering some
questions about Berlin,

00:06:38.054 --> 00:06:39.720
about things we've
learned at the forum.

00:06:39.720 --> 00:06:42.303
ROSE KELLY: Hi, I'm Rose Kelly
from the Woodrow Wilson School,

00:06:42.303 --> 00:06:45.630
and we are live on Facebook Live
from the Princeton-Fung Global

00:06:45.630 --> 00:06:46.449
Forum in Berlin.

00:06:46.449 --> 00:06:47.990
I'm here with our
student volunteers.

00:06:47.990 --> 00:06:48.680
We're going to ask them
a couple questions.

00:06:48.680 --> 00:06:50.400
And we've been really
pleased that we've

00:06:50.400 --> 00:06:53.100
had so many German media
attend this year's event.

00:06:53.100 --> 00:06:55.150
We had 40 reporters sign up.

00:06:55.150 --> 00:06:57.420
We've had some great
experiences with some TV crews.

00:06:57.420 --> 00:06:59.590
And we've been really
thankful for their coverage.

00:06:59.590 --> 00:07:01.173
ELISABETH DONAHUE:
Humboldt University

00:07:01.173 --> 00:07:03.420
and Princeton University
have a special relationship.

00:07:03.420 --> 00:07:07.177
And it takes on many different
types of connections.

00:07:07.177 --> 00:07:08.760
CLAUDIA SCHMIDT-MEMMLER: My name 
is Claudia Schmidt-Memmler.

00:07:08.760 --> 00:07:11.820
And I work at the International
Strategy Office at Humboldt

00:07:11.820 --> 00:07:13.230
University here in Berlin.

00:07:13.230 --> 00:07:16.730
And we are an international
strategic partner

00:07:16.730 --> 00:07:17.730
of Princeton University.

00:07:17.730 --> 00:07:20.117
And I am responsible for
the connection to Princeton

00:07:20.117 --> 00:07:22.200
and the connection between
Humboldt and Princeton.

00:07:22.200 --> 00:07:23.760
And that's why I'm here.

00:07:23.760 --> 00:07:25.301
CHRISTOPHER L. EISGRUBER:
Please join me

00:07:25.301 --> 00:07:27.270
in welcoming Microsoft
President Brad Smith.

00:07:27.270 --> 00:07:29.700
[APPLAUSE]

00:07:29.700 --> 00:07:30.561
Brad --

00:07:30.561 --> 00:07:31.644
BRAD SMITH: Thanks, Chris.

00:07:31.644 --> 00:07:33.600
CHRISTOPHER L. EISGRUBER: 
Thank you.

00:07:33.600 --> 00:07:34.590
BRAD SMITH: I thought it
was worth taking a page out

00:07:34.590 --> 00:07:36.480
of the history
books and thinking

00:07:36.480 --> 00:07:38.490
a little bit about the
diplomatic conference

00:07:38.490 --> 00:07:41.970
that had convened
in Geneva in 1949 --

00:07:41.970 --> 00:07:44.160
the diplomatic conference
that had created

00:07:44.160 --> 00:07:46.470
the Fourth Geneva
Convention that protects

00:07:46.470 --> 00:07:49.700
civilians in times of war.

00:07:49.700 --> 00:07:52.650
And I thought it was worthwhile
to start to talk about creating

00:07:52.650 --> 00:07:55.276
a digital Geneva Convention --

00:07:55.276 --> 00:07:57.150
a convention that would
bring the governments

00:07:57.150 --> 00:07:59.040
of the world together,
at least those

00:07:59.040 --> 00:08:02.520
that are like-minded, so that
they would pledge and create

00:08:02.520 --> 00:08:04.370
new international law.

00:08:04.370 --> 00:08:06.540
HANS-CHRISTOPH BOEMERS: I
came to Princeton in 1956

00:08:06.540 --> 00:08:09.900
as a graduate student in
the Woodrow Wilson School.

00:08:09.900 --> 00:08:12.770
So far, I must say I'm
not disappointed at all.

00:08:12.770 --> 00:08:14.540
It's been a very
good conference.

00:08:14.540 --> 00:08:20.250
And especially today,
the speech by Brad Smith

00:08:20.250 --> 00:08:22.334
was really extraordinary.

00:08:22.334 --> 00:08:24.000
CECILIA ROUSE: Now
I'd like to introduce

00:08:24.000 --> 00:08:27.720
our fourth panel, entitled
"Communication Silos

00:08:27.720 --> 00:08:29.790
and Information Overload."

00:08:29.790 --> 00:08:33.240
GABRIELLA COLEMAN: Visual
culture really matters.

00:08:33.240 --> 00:08:35.280
Psychological studies
show that if you

00:08:35.280 --> 00:08:38.159
have a statement with
an image, more people

00:08:38.159 --> 00:08:40.128
are likely to believe it.

00:08:40.128 --> 00:08:41.669
And even though a
lot of their images

00:08:41.669 --> 00:08:43.627
are kind of totally
ridiculous, because they're

00:08:43.627 --> 00:08:46.471
these funny, weird memes
like Hillary like a zombie --

00:08:46.471 --> 00:08:47.970
nevertheless, there's
something very

00:08:47.970 --> 00:08:50.280
compelling about a
statement -- sometimes

00:08:50.280 --> 00:08:52.680
a very catchy statement,
funny statement,

00:08:52.680 --> 00:08:55.140
transgressive statement --
and then the image.

00:08:55.140 --> 00:08:57.960
And that kind of circulates
all over the place.

00:08:57.960 --> 00:08:59.790
YOUNGSUK CHI: I'm so
glad to see Princeton

00:08:59.790 --> 00:09:03.150
able to leave the cozy
campus and come out

00:09:03.150 --> 00:09:05.640
to the rest of the
world to gather

00:09:05.640 --> 00:09:08.340
really thoughtful
minds of experts

00:09:08.340 --> 00:09:12.360
to address these issues
under the Princeton banner.

00:09:12.360 --> 00:09:15.700
JILLIAN YORK: As a Microsoft
president said earlier today,

00:09:15.700 --> 00:09:18.000
all of these companies
produce transparency reports.

00:09:18.000 --> 00:09:19.890
And they're quite excellent when
it comes to what governments

00:09:19.890 --> 00:09:20.730
are asking of them.

00:09:20.730 --> 00:09:22.770
So if a government
asks for a user's data

00:09:22.770 --> 00:09:25.080
or asks for a piece of
content to be taken down,

00:09:25.080 --> 00:09:27.450
you can go to Facebook
or Google or Microsoft

00:09:27.450 --> 00:09:30.060
and find some information
about what that

00:09:30.060 --> 00:09:31.400
looks like in those countries.

00:09:31.400 --> 00:09:33.090
But when it comes to terms
of service take-downs,

00:09:33.090 --> 00:09:33.930
we know nothing.

00:09:33.930 --> 00:09:36.130
When we think about
democracy and the internet,

00:09:36.130 --> 00:09:38.088
a lot of times we think
about how nation-states

00:09:38.088 --> 00:09:39.760
are restricting what we can do.

00:09:39.760 --> 00:09:41.730
But in fact, today
corporations like Facebook

00:09:41.730 --> 00:09:45.472
have more users than the
entire country of China.

00:09:45.472 --> 00:09:47.430
And so we need to think
about the new paradigms

00:09:47.430 --> 00:09:49.170
in which these
companies are enacting

00:09:49.170 --> 00:09:50.855
control over so many people.

00:09:50.855 --> 00:09:52.230
ROGER DINGLEDINE:
I think privacy

00:09:52.230 --> 00:09:55.520
is one of the key ways of
becoming free and staying free

00:09:55.520 --> 00:09:56.580
on the internet.

00:09:56.580 --> 00:09:59.670
I remember being up here
probably six or seven years ago

00:09:59.670 --> 00:10:02.820
or something, when I was talking
about the Tor Bridge design

00:10:02.820 --> 00:10:05.610
to get around
censorship and basically

00:10:05.610 --> 00:10:08.280
provide a way for
Tor users to not get

00:10:08.280 --> 00:10:10.345
oppressed by certain
countries around the world.

00:10:10.345 --> 00:10:11.970
And at the very end,
there was a person

00:10:11.970 --> 00:10:14.070
who came up in the Q&amp;A session.

00:10:14.070 --> 00:10:18.910
And his question was simply,
in a very thick Russian accent,

00:10:18.910 --> 00:10:21.780
they'll kill you.

00:10:21.780 --> 00:10:25.630
And there I am in the CCC video
with my mouth open thinking,

00:10:25.630 --> 00:10:27.240
how do I answer a
question like this?

00:10:27.240 --> 00:10:28.950
And eventually,
I figured it out.

00:10:28.950 --> 00:10:31.580
It was, then I guess
I'd better build it

00:10:31.580 --> 00:10:34.500
so that killing me doesn't
actually -- isn't actually

00:10:34.500 --> 00:10:36.720
a useful step to take.

00:10:36.720 --> 00:10:38.640
So here I am back in Berlin.

00:10:38.640 --> 00:10:40.970
CECILIA ROUSE: Our last
panel is "Living With

00:10:40.970 --> 00:10:44.017
and Regulating Web 3.0 Plus."

00:10:44.017 --> 00:10:45.600
NIVA ELKIN-KOREN:
Unless you take down

00:10:45.600 --> 00:10:50.500
the materials that are allegedly
copyright infringement,

00:10:50.500 --> 00:10:53.419
you might be liable
for copyright damages.

00:10:53.419 --> 00:10:54.960
EDWARD FELTEN: These
days, encryption

00:10:54.960 --> 00:10:59.010
is a best practice, really,
to protect your security

00:10:59.010 --> 00:11:00.930
and privacy when you're online.

00:11:00.930 --> 00:11:04.350
If you're on a public
Wi-Fi network like, say,

00:11:04.350 --> 00:11:07.320
the one in this room, and
you go to a website that's

00:11:07.320 --> 00:11:10.320
unencrypted, that's actually
a somewhat risky thing to do.

00:11:10.320 --> 00:11:11.820
CHRISTOPHER L. EISGRUBER:
I thank them.

00:11:11.820 --> 00:11:14.319
I thank all of you for what has
been a wonderful conference.

00:11:14.319 --> 00:11:17.010
And I invite you all to join us
for a reception, which will be

00:11:17.010 --> 00:11:18.300
downstairs on the first floor.

00:11:18.300 --> 00:11:20.091
Thank you for being a
part of this. Good night.

00:11:20.091 --> 00:11:20.812
[APPLAUSE]

00:11:20.812 --> 00:11:22.820
YUSUF DAHL: The
forum's wrapping up.

00:11:22.820 --> 00:11:27.720
It was two days of just
amazing conversations

00:11:27.720 --> 00:11:29.167
and an opportunity
to really meet

00:11:29.167 --> 00:11:31.000
and network with folks
throughout the world.

00:11:31.000 --> 00:11:33.601
So it was a outstanding
event, a great weekend.

00:11:33.601 --> 00:11:35.100
And I'm thankful
for the opportunity

00:11:35.100 --> 00:11:36.870
to hear so many
different perspectives

00:11:36.870 --> 00:11:38.100
on this critical issue.

00:11:38.100 --> 00:11:40.250
[MUSIC PLAYING]

