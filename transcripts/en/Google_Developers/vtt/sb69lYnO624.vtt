WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.415
[MUSIC PLAYING]

00:00:03.381 --> 00:00:05.508
KENRIC MCDOWELL: If you've
been at the conference,

00:00:05.508 --> 00:00:07.300
maybe you had a little
chance this morning,

00:00:07.300 --> 00:00:08.717
or you were here
yesterday, you've

00:00:08.717 --> 00:00:11.200
probably seen some of the
artwork that's around,

00:00:11.200 --> 00:00:12.850
some video installations.

00:00:12.850 --> 00:00:16.600
Or if you were at
presentations and performances

00:00:16.600 --> 00:00:18.640
last night in this
very room, you

00:00:18.640 --> 00:00:20.800
would have seen some
of the programming

00:00:20.800 --> 00:00:26.140
that Alex Czetwertysnki and
I curated for the I/O Arts

00:00:26.140 --> 00:00:29.360
program at I/O this year.

00:00:29.360 --> 00:00:31.970
So we're going to have a
little conversation today,

00:00:31.970 --> 00:00:35.470
and I just wanted to introduce
myself and talk a little bit

00:00:35.470 --> 00:00:36.310
about the--

00:00:36.310 --> 00:00:39.970
just set up some
context for the program.

00:00:39.970 --> 00:00:42.430
And then we'll get
to some conversation

00:00:42.430 --> 00:00:46.650
with artists, which I know
we're all looking forward to.

00:00:46.650 --> 00:00:50.210
So as I mentioned, there
are some installations

00:00:50.210 --> 00:00:53.330
and performances that were
curated for the I/O Arts

00:00:53.330 --> 00:00:53.880
program.

00:00:53.880 --> 00:00:57.220
A lot of the work has
to do with artists that

00:00:57.220 --> 00:00:59.190
use artificial intelligence.

00:00:59.190 --> 00:01:06.150
And we have two of them here
with us today, Cedric Kiefer

00:01:06.150 --> 00:01:07.980
from onformative,
whose installation is

00:01:07.980 --> 00:01:09.380
out here on the boardwalk--

00:01:09.380 --> 00:01:11.130
you may have seen it,
"Meandering River"--

00:01:11.130 --> 00:01:12.930
and Sougwen Chung, whose
performance was last night,

00:01:12.930 --> 00:01:13.960
and whose work is hanging here.

00:01:13.960 --> 00:01:15.960
So please, a round of
applause for both of them.

00:01:15.960 --> 00:01:18.230
[APPLAUSE]

00:01:24.900 --> 00:01:29.100
Cedric and Sougwen are going
to give some presentations

00:01:29.100 --> 00:01:30.510
on their work,
and then we'll get

00:01:30.510 --> 00:01:32.250
into conversation about that.

00:01:32.250 --> 00:01:33.120
CEDRIC KIEFER: OK.

00:01:33.120 --> 00:01:34.495
KENRIC MCDOWELL:
Thank you, guys.

00:01:34.495 --> 00:01:35.840
CEDRIC KIEFER: Thank you.

00:01:35.840 --> 00:01:38.150
Yeah, I will start right away.

00:01:38.150 --> 00:01:39.150
Thanks for having me.

00:01:39.150 --> 00:01:41.900
And it's a great
pleasure to speak

00:01:41.900 --> 00:01:43.190
in front of such an audience.

00:01:43.190 --> 00:01:47.810
And I want to talk a little bit
about our work, our practice.

00:01:47.810 --> 00:01:53.420
And when I talk about our
practice, what I mean by that--

00:01:53.420 --> 00:01:55.780
or if I have to describe
it in one short sentence,

00:01:55.780 --> 00:01:58.030
I would usually say
that we are searching

00:01:58.030 --> 00:02:00.190
for new ways of
creative expression.

00:02:00.190 --> 00:02:03.510
And we do that by
using technology.

00:02:03.510 --> 00:02:05.460
And to give a little
bit of a background

00:02:05.460 --> 00:02:08.699
where I'm coming from, or where
onformative-- the studio I'm

00:02:08.699 --> 00:02:11.220
running-- is coming
from, about 10 years ago,

00:02:11.220 --> 00:02:13.530
we co-published the
"Generative Design" book.

00:02:13.530 --> 00:02:17.410
And for us, that has always
been the starting point.

00:02:17.410 --> 00:02:18.960
And since then,
our work has always

00:02:18.960 --> 00:02:21.060
been focusing
around digital art,

00:02:21.060 --> 00:02:26.330
using code and using technology
to create art and design.

00:02:26.330 --> 00:02:28.920
And what I want to talk
about today, though,

00:02:28.920 --> 00:02:34.130
is more what inspiration
and improvisation actually

00:02:34.130 --> 00:02:36.330
means in such a setup--

00:02:36.330 --> 00:02:39.650
in a technology-driven
setup, but also in general.

00:02:39.650 --> 00:02:42.860
Because if you look
back, improvisation

00:02:42.860 --> 00:02:46.250
plays an important role
in arts in general,

00:02:46.250 --> 00:02:47.820
in totally different
disciplines.

00:02:47.820 --> 00:02:51.080
So for example, looking
at [? traffic ?]

00:02:51.080 --> 00:02:52.970
scores and classical
music composition

00:02:52.970 --> 00:02:55.520
is a really good
example of how people

00:02:55.520 --> 00:02:59.510
start to think about how
they can foster improvisation

00:02:59.510 --> 00:03:02.720
by creating visually
abstract [? traffic ?]

00:03:02.720 --> 00:03:05.880
scores that leave a lot of
room for interpretation.

00:03:05.880 --> 00:03:09.020
So they started to develop
tools to actually come up

00:03:09.020 --> 00:03:14.390
with something new to
create moments of chance.

00:03:14.390 --> 00:03:17.150
And I think that's
really interesting.

00:03:17.150 --> 00:03:20.870
But it is not only happening
in classical music.

00:03:20.870 --> 00:03:24.680
Performance and dance is another
case where such a thing exists.

00:03:24.680 --> 00:03:26.450
For example,
improvisation technologies

00:03:26.450 --> 00:03:29.330
by William Forsythe,
developed in the '90s,

00:03:29.330 --> 00:03:31.130
where he started
to actually come up

00:03:31.130 --> 00:03:33.680
with an imaginary
system of rules.

00:03:33.680 --> 00:03:36.480
It's kind of like a toolset
for him to improvise.

00:03:36.480 --> 00:03:40.940
So he was thinking
about lines and boxes--

00:03:40.940 --> 00:03:42.500
imaginary ones.

00:03:42.500 --> 00:03:44.780
And he started to
interact with them

00:03:44.780 --> 00:03:48.467
by either avoiding
them or following them.

00:03:48.467 --> 00:03:50.300
I think that's a really
interesting thought.

00:03:50.300 --> 00:03:53.220
And we have been using
technology in a similar way.

00:03:53.220 --> 00:03:56.745
We use it to get inspiration
and to do things differently,

00:03:56.745 --> 00:03:58.370
because I think that's
what it's about.

00:03:58.370 --> 00:04:01.430
When you want to search for
new ways of visual expression,

00:04:01.430 --> 00:04:03.540
you have to do
things differently.

00:04:03.540 --> 00:04:05.540
And as a student,
we are not really

00:04:05.540 --> 00:04:08.270
focused on specific
media, which means

00:04:08.270 --> 00:04:13.880
we create work that ranges from
interactive art installations

00:04:13.880 --> 00:04:20.730
to kinetic sculptures, but also
work that is purely visual.

00:04:20.730 --> 00:04:23.370
This is a project that I want
to talk a little bit about more.

00:04:23.370 --> 00:04:27.310
It's "Collide," something
that we did a few years ago,

00:04:27.310 --> 00:04:29.400
a digital art piece
which is based

00:04:29.400 --> 00:04:32.580
on the idea of visualizing
dance and motion.

00:04:32.580 --> 00:04:35.760
And we do it with
a lot of projects.

00:04:35.760 --> 00:04:38.760
We started with researching,
exploring, writing software,

00:04:38.760 --> 00:04:40.890
writing code and
tools, and trying

00:04:40.890 --> 00:04:45.060
to understand how, actually,
energy flows through the body.

00:04:45.060 --> 00:04:49.080
And during the work and time
we spent with the dancers

00:04:49.080 --> 00:04:53.370
and performers that we tracked--
so we used motion tracking

00:04:53.370 --> 00:04:55.780
to actually detect
their movement

00:04:55.780 --> 00:04:58.038
and use that as an
input for the art piece.

00:04:58.038 --> 00:05:00.330
And one thing that they always
mentioned and brought up

00:05:00.330 --> 00:05:04.050
during the rehearsals is
the fact that, at one point,

00:05:04.050 --> 00:05:05.970
as a performer, you get
lost in what you do.

00:05:05.970 --> 00:05:07.500
You get lost in the performance.

00:05:07.500 --> 00:05:09.090
You are in the zone.

00:05:09.090 --> 00:05:10.230
Everything blurs.

00:05:10.230 --> 00:05:13.650
And we really like the
idea of actually exploring

00:05:13.650 --> 00:05:19.137
how energy actually expands
and flows into the space.

00:05:19.137 --> 00:05:20.970
And at this point, we
started to interpret--

00:05:20.970 --> 00:05:21.525
[VIDEO PLAYBACK]

00:05:21.525 --> 00:05:22.275
[SLOW CELLO MUSIC]

00:05:22.275 --> 00:05:24.270
--the screens
actually as a window

00:05:24.270 --> 00:05:25.990
into that abstract world.

00:05:25.990 --> 00:05:27.750
So what you see here
is our interpretation

00:05:27.750 --> 00:05:30.990
of what it feels like if you
get lost in a performance,

00:05:30.990 --> 00:05:32.790
in a creative process.

00:05:32.790 --> 00:05:34.560
And yeah.

00:05:34.560 --> 00:05:38.400
You see parts of bodies
coming towards the screen,

00:05:38.400 --> 00:05:40.860
becoming a little bit more
concrete, and then also quickly

00:05:40.860 --> 00:05:41.910
disappearing again.

00:05:43.440 --> 00:05:45.805
But I don't want to talk
much about the visual side

00:05:45.805 --> 00:05:48.180
of this project, but I want
to talk about the music side,

00:05:48.180 --> 00:05:50.160
because for this piece,
we also want to create

00:05:50.160 --> 00:05:52.290
a powerful soundscape.

00:05:52.290 --> 00:05:54.870
[END PLAYBACK]

00:05:54.870 --> 00:05:57.150
And we thought a lot
about what the best

00:05:57.150 --> 00:05:59.080
way would be to do that.

00:05:59.080 --> 00:06:01.380
So instead of
handing the visuals

00:06:01.380 --> 00:06:03.390
over to a sound
designer and just

00:06:03.390 --> 00:06:05.935
asking him to do
some sound on top,

00:06:05.935 --> 00:06:07.560
we wanted to make
sure that we actually

00:06:07.560 --> 00:06:10.200
stay true to the concept,
which is actually

00:06:10.200 --> 00:06:13.290
being immersed, and
being totally focused.

00:06:13.290 --> 00:06:15.390
And at the same
time, we also wanted

00:06:15.390 --> 00:06:20.970
to actually foster this moment
of creativity, inspiration,

00:06:20.970 --> 00:06:21.810
improvisation.

00:06:21.810 --> 00:06:23.730
And for that
purpose, we actually

00:06:23.730 --> 00:06:25.170
invited three cello players--

00:06:25.170 --> 00:06:26.010
[VIDEO PLAYBACK]

00:06:26.010 --> 00:06:28.680
--and put VR glasses
on their heads,

00:06:28.680 --> 00:06:30.630
and put them into
that virtual world.

00:06:30.630 --> 00:06:34.650
So they were actually being
present in that virtual world

00:06:34.650 --> 00:06:37.470
at different positions and
were actually improvising

00:06:37.470 --> 00:06:40.590
and reacting to everything that
happened in front of their eyes

00:06:40.590 --> 00:06:42.020
the moment it happened.

00:06:42.020 --> 00:06:43.437
And we recorded
that and used that

00:06:43.437 --> 00:06:44.728
as the base for the soundscape.

00:06:44.728 --> 00:06:45.510
[SLOW CELLO MUSIC]

00:06:45.510 --> 00:06:49.590
So this is obviously not the
most or not the easiest way

00:06:49.590 --> 00:06:51.390
to actually create
music, but it's

00:06:51.390 --> 00:06:54.698
a way that actually leads to
some new, unexpected results.

00:06:54.698 --> 00:06:56.240
And this is what we
always try to do.

00:06:56.240 --> 00:06:58.110
We try to push boundaries.

00:06:58.110 --> 00:07:00.455
We try to actually
look for new things.

00:07:00.455 --> 00:07:01.830
And this is a
pretty good example

00:07:01.830 --> 00:07:06.590
how we incorporate
technology to do that.

00:07:06.590 --> 00:07:07.500
[END PLAYBACK]

00:07:07.500 --> 00:07:10.250
The last project I want to
talk about a little bit more

00:07:10.250 --> 00:07:12.530
in detail is the one that
Kenric already mentioned,

00:07:12.530 --> 00:07:15.740
the one that you can see
outside at the boardwalk.

00:07:15.740 --> 00:07:17.330
And with a lot of
our project, it

00:07:17.330 --> 00:07:19.730
started with some inspiration.

00:07:19.730 --> 00:07:23.480
In this case, satellite
images of rivers.

00:07:23.480 --> 00:07:25.760
So for another project,
I did some research

00:07:25.760 --> 00:07:28.910
and came across these
beautiful river landscapes.

00:07:28.910 --> 00:07:32.240
And I was totally fascinated
about how they actually

00:07:32.240 --> 00:07:34.130
leave these patterns.

00:07:34.130 --> 00:07:34.965
And I wanted to--

00:07:34.965 --> 00:07:36.840
I needed to understand
how it actually works.

00:07:36.840 --> 00:07:39.780
And it's really interesting,
because you might not know it,

00:07:39.780 --> 00:07:41.870
but in reality,
they're really moving.

00:07:41.870 --> 00:07:43.670
They're just moving
really, really slow.

00:07:43.670 --> 00:07:44.337
[VIDEO PLAYBACK]

00:07:44.337 --> 00:07:47.570
So if you look at Google Earth
time lapse of such river,

00:07:47.570 --> 00:07:50.180
over the course
of 20 or 30 years,

00:07:50.180 --> 00:07:53.720
you can really see how the river
carves through the landscape.

00:07:53.720 --> 00:07:55.430
And this is happening
because there's

00:07:55.430 --> 00:07:59.930
some sediment being taken
from one side where the water

00:07:59.930 --> 00:08:03.200
pressure is higher and
left on the other side.

00:08:03.200 --> 00:08:05.600
And through decades,
the river really

00:08:05.600 --> 00:08:07.370
moves through the landscape.

00:08:07.370 --> 00:08:10.010
And these are the
moments where we

00:08:10.010 --> 00:08:12.710
feel that there's
something in such a system

00:08:12.710 --> 00:08:15.640
that we need to understand, that
we need to recreate, that we--

00:08:15.640 --> 00:08:17.410
yeah, we need to understand.

00:08:17.410 --> 00:08:19.580
And at that point,
we start, again,

00:08:19.580 --> 00:08:22.640
researching,
exploring, and building

00:08:22.640 --> 00:08:25.290
software representations
of such a system.

00:08:25.290 --> 00:08:28.820
So this is our river simulation,
one of the few, or one--

00:08:28.820 --> 00:08:30.980
yeah, we did quite a
lot, because we also

00:08:30.980 --> 00:08:32.360
need to explore these things.

00:08:32.360 --> 00:08:36.049
And this is a combination of
different algorithms actually

00:08:36.049 --> 00:08:38.520
simulating this behavior.

00:08:38.520 --> 00:08:41.480
And the moment you have
the logic in place,

00:08:41.480 --> 00:08:44.059
you can start thinking about
what is the visual aesthetic

00:08:44.059 --> 00:08:45.410
that I put on top of that.

00:08:45.410 --> 00:08:48.500
And in that sense, you
can use such a river

00:08:48.500 --> 00:08:51.110
as a digital brush
on your canvas

00:08:51.110 --> 00:08:54.200
making [INAUDIBLE]
beautiful, abstract images.

00:08:54.200 --> 00:08:58.220
But we also felt that looking
at all those satellite

00:08:58.220 --> 00:09:01.230
images as inspiration
references,

00:09:01.230 --> 00:09:04.130
there's such a beauty
in these images already

00:09:04.130 --> 00:09:08.180
which has a really painterly
aesthetic purely on its own.

00:09:08.180 --> 00:09:10.760
And we felt that we need to
stay close to that aesthetic

00:09:10.760 --> 00:09:11.530
in some ways.

00:09:11.530 --> 00:09:12.113
[END PLAYBACK]

00:09:12.113 --> 00:09:14.780
So on top of this simulation
that I just showed,

00:09:14.780 --> 00:09:16.940
we developed some
new visual shaders.

00:09:16.940 --> 00:09:18.440
And all these
shaders were actually

00:09:18.440 --> 00:09:26.090
representing different aspects,
like vegetation, or erosion,

00:09:26.090 --> 00:09:27.630
and so on.

00:09:27.630 --> 00:09:29.810
And in the end,
we developed a lot

00:09:29.810 --> 00:09:32.425
of different visual
aesthetics-- about 20,

00:09:32.425 --> 00:09:33.800
and these are just
four of them--

00:09:33.800 --> 00:09:39.680
that were representing abstract
interpretations of rivers

00:09:39.680 --> 00:09:44.030
influencing and
changing landscapes.

00:09:44.030 --> 00:09:48.230
And while I talked a lot about
the algorithms and the logic

00:09:48.230 --> 00:09:50.900
behind the visuals,
there's another story

00:09:50.900 --> 00:09:53.210
about the sound creation again.

00:09:53.210 --> 00:09:55.932
Because one of the biggest
struggles or questions

00:09:55.932 --> 00:09:57.890
that we asked ourselves
is, how do you actually

00:09:57.890 --> 00:10:00.860
create a soundscape or music
for an endlessly-moving visual?

00:10:00.860 --> 00:10:04.260
Because what you see there
is actually a real-time piece

00:10:04.260 --> 00:10:05.480
which is constantly moving.

00:10:05.480 --> 00:10:08.760
It's a lot about change
and unpredictability,

00:10:08.760 --> 00:10:10.650
so you don't really
know what happens next.

00:10:10.650 --> 00:10:13.040
So theoretically,
it can run forever.

00:10:13.040 --> 00:10:16.790
And we like the idea of actually
having somebody improvising

00:10:16.790 --> 00:10:19.550
or interpreting
what is happening.

00:10:19.550 --> 00:10:21.000
But you can't do that forever.

00:10:21.000 --> 00:10:26.360
So this is where, actually, the
idea of using an AI came in.

00:10:26.360 --> 00:10:28.370
So for this part, we
collaborated with a--

00:10:28.370 --> 00:10:29.037
[VIDEO PLAYBACK]

00:10:29.037 --> 00:10:31.610
--studio called kling klang
klong, and great sound

00:10:31.610 --> 00:10:34.280
designers we've been working
with in the past as well.

00:10:34.280 --> 00:10:39.170
And we came up with the
idea to actually have

00:10:39.170 --> 00:10:40.520
human piano players--

00:10:40.520 --> 00:10:42.680
we had four of them
interpreting all

00:10:42.680 --> 00:10:45.900
the different visual aesthetics
in a lot of different styles.

00:10:45.900 --> 00:10:48.170
So we had four
people interpreting

00:10:48.170 --> 00:10:51.230
about eight different aesthetics
in four different styles

00:10:51.230 --> 00:10:52.430
and three different tempos.

00:10:52.430 --> 00:10:55.890
And we ended up with about
350 different interpretations,

00:10:55.890 --> 00:10:59.330
which was our training
data set for the AI.

00:10:59.330 --> 00:11:03.420
And for that, we
used Google Magenta

00:11:03.420 --> 00:11:05.310
to create the musical score.

00:11:05.310 --> 00:11:07.710
And what we did was just
feeding all the data in there,

00:11:07.710 --> 00:11:11.130
and training it over
and over and over again,

00:11:11.130 --> 00:11:18.660
leading to a lot of different
outputs in terms of music.

00:11:18.660 --> 00:11:21.840
And they differ a lot
in terms of complexity.

00:11:21.840 --> 00:11:24.540
And you can see that, depending
on the training iterations,

00:11:24.540 --> 00:11:28.200
like 200, 500, 1,000, 6,000.

00:11:28.200 --> 00:11:31.185
It was getting more and more
complex, and more and more--

00:11:31.185 --> 00:11:33.060
I wouldn't say interesting,
but at one point,

00:11:33.060 --> 00:11:35.370
we also reached a point where
we had some overfitting.

00:11:35.370 --> 00:11:36.347
It was too much.

00:11:36.347 --> 00:11:36.930
[END PLAYBACK]

00:11:36.930 --> 00:11:41.040
But these were then actually
used to create the soundscape.

00:11:41.040 --> 00:11:45.240
And I really liked the idea of
actually having this multi-view

00:11:45.240 --> 00:11:48.720
where you have the visual
side of this piece interpreted

00:11:48.720 --> 00:11:49.620
by the human.

00:11:49.620 --> 00:11:50.610
[VIDEO PLAYBACK]

00:11:50.610 --> 00:11:53.430
And the machine learns
from that and does

00:11:53.430 --> 00:11:56.160
their own interpretation
based on what

00:11:56.160 --> 00:11:59.410
the machine understands,
which is the raw data.

00:11:59.410 --> 00:12:02.010
And this led to this
beautiful combination

00:12:02.010 --> 00:12:05.022
of sound and visuals.

00:12:05.022 --> 00:12:06.480
And this is the
final piece the way

00:12:06.480 --> 00:12:11.712
we showed it first time at our
exhibition at Funkhaus Berlin,

00:12:11.712 --> 00:12:13.170
and quite similar
to how we have it

00:12:13.170 --> 00:12:14.462
executed here at the boardwalk.

00:12:14.462 --> 00:12:16.626
[LIGHT PIANO MUSIC]

00:12:21.780 --> 00:12:23.113
SOUGWEN CHUNG: It's really nice.

00:12:44.093 --> 00:12:45.260
CEDRIC KIEFER: So thank you.

00:12:45.260 --> 00:12:46.960
I'm going to hand over to you.

00:12:46.960 --> 00:12:48.150
SOUGWEN CHUNG: Great.

00:12:48.150 --> 00:12:48.810
KENRIC MCDOWELL:
Thank you, Cedric.

00:12:48.810 --> 00:12:48.970
[END PLAYBACK]

00:12:48.970 --> 00:12:49.290
CEDRIC KIEFER: Thank you.

00:12:49.290 --> 00:12:50.498
KENRIC MCDOWELL: Fascinating.

00:12:50.498 --> 00:12:52.290
[APPLAUSE]

00:12:55.510 --> 00:12:57.785
SOUGWEN CHUNG: Good
morning, everyone.

00:12:57.785 --> 00:12:59.160
Thank you for
coming, by the way.

00:12:59.160 --> 00:13:02.520
It's so early, so I
really appreciate it.

00:13:02.520 --> 00:13:06.480
And it's a pleasure to
be up here with everyone.

00:13:06.480 --> 00:13:08.040
Actually, I'll go back.

00:13:08.040 --> 00:13:10.380
I did a performance
yesterday in this room

00:13:10.380 --> 00:13:14.197
where I showcased a
duet performance of some

00:13:14.197 --> 00:13:16.030
of the things I'm going
to be talking about.

00:13:16.030 --> 00:13:16.950
I'm going to try
to speed through it

00:13:16.950 --> 00:13:19.325
really quickly, though, because
I think the heart of this

00:13:19.325 --> 00:13:20.940
is the discussion.

00:13:20.940 --> 00:13:22.030
I'll do my best.

00:13:22.030 --> 00:13:23.250
I make no promises.

00:13:23.250 --> 00:13:26.610
So this is an
interesting premise

00:13:26.610 --> 00:13:29.290
that I like to bring out
when I speak about my work.

00:13:29.290 --> 00:13:31.500
And the question is, if
technology is the answer,

00:13:31.500 --> 00:13:32.490
what is the question?

00:13:32.490 --> 00:13:36.190
It's really cool to be
able to ask that at I/O.

00:13:36.190 --> 00:13:41.290
So my work, I use the mark
made by hand and the mark

00:13:41.290 --> 00:13:45.610
made by machine, handmade
and digital approaches

00:13:45.610 --> 00:13:48.520
to understanding systems.

00:13:48.520 --> 00:13:52.390
I've been working on this body
of work for about five years

00:13:52.390 --> 00:13:56.620
now, exploring the realm of
human and robot collaboration.

00:13:56.620 --> 00:14:03.190
And it's in many phases of
generations of features,

00:14:03.190 --> 00:14:05.350
essentially, but these
are the three that I'm

00:14:05.350 --> 00:14:06.920
going to discuss today.

00:14:06.920 --> 00:14:10.180
The first one involves
mimicry, the second one memory,

00:14:10.180 --> 00:14:14.660
and the third multiplicity,
and a collaboration

00:14:14.660 --> 00:14:16.340
with a multi-agent body.

00:14:16.340 --> 00:14:18.250
So it started off really simply.

00:14:18.250 --> 00:14:21.290
I had background as a
performer and a violinist.

00:14:21.290 --> 00:14:23.000
So I've been really--

00:14:23.000 --> 00:14:25.340
I've thought a lot
about gesture and how

00:14:25.340 --> 00:14:30.360
that might relate to cognition
and an improvisation,

00:14:30.360 --> 00:14:32.360
and that's always been
at the heart of the work.

00:14:32.360 --> 00:14:35.060
It's almost like the
control by which I

00:14:35.060 --> 00:14:40.650
throw a lot of different
digital approaches.

00:14:40.650 --> 00:14:42.620
The first generation
started with mimicry,

00:14:42.620 --> 00:14:45.980
where I programmed a
robotic arm to mimic

00:14:45.980 --> 00:14:49.580
my gesture in real time using
a very simple computer vision

00:14:49.580 --> 00:14:50.410
software.

00:14:50.410 --> 00:14:54.500
And I found it became a really
interesting performative

00:14:54.500 --> 00:14:58.190
moment of human and
machine co-creation

00:14:58.190 --> 00:15:01.850
that I've been exploring
now with machine learning

00:15:01.850 --> 00:15:02.990
over the past few years.

00:15:02.990 --> 00:15:05.480
This is a generation
that's trained

00:15:05.480 --> 00:15:12.100
just the very early iterations
on my own drawing style

00:15:12.100 --> 00:15:15.790
at an attempt of speculating
at robotic memory.

00:15:15.790 --> 00:15:19.180
This third piece is a
really interesting project

00:15:19.180 --> 00:15:21.250
called "Omnia per
Omnia," where I

00:15:21.250 --> 00:15:23.740
designed a multi-robotic
system that was

00:15:23.740 --> 00:15:25.850
linked to the flow of the city.

00:15:25.850 --> 00:15:27.790
I just flew in from
New York, and we

00:15:27.790 --> 00:15:34.150
trained the robot's motions on
publicly-available surveillance

00:15:34.150 --> 00:15:36.280
feeds in New York City.

00:15:36.280 --> 00:15:43.180
So all this comes from a few
different sparks of curiosity

00:15:43.180 --> 00:15:47.520
that we're going to talk about
today, which is this idea of--

00:15:47.520 --> 00:15:52.300
and something that I read
in Cade Metz's documentation

00:15:52.300 --> 00:15:56.080
of the DeepMind,
AlphaGo, Lee Sedol

00:15:56.080 --> 00:15:59.990
moment, which I'm sure most
people in this room know about.

00:15:59.990 --> 00:16:05.500
But when DeepMind and AlphaGo
beat Lee Sedol, the top Go

00:16:05.500 --> 00:16:10.500
player in the world, he said
that in move 33, move 33,

00:16:10.500 --> 00:16:13.180
it represented a really
watershed moment in how

00:16:13.180 --> 00:16:17.560
he thought about his
practice and his game, which

00:16:17.560 --> 00:16:23.290
is that the system outputted a
non-human move that he deemed

00:16:23.290 --> 00:16:24.520
impossibly beautiful.

00:16:24.520 --> 00:16:26.800
So a lot of what
I do is an attempt

00:16:26.800 --> 00:16:30.260
to find that impossibly
beautiful non-human move.

00:16:30.260 --> 00:16:32.680
Because I think
there's a lot of--

00:16:32.680 --> 00:16:37.540
this is a really tried
and cliched binary

00:16:37.540 --> 00:16:40.180
of men and machine that
ends up being really quite

00:16:40.180 --> 00:16:41.920
dystopian that I try to--

00:16:41.920 --> 00:16:45.380
think we can really
imagine beyond now.

00:16:45.380 --> 00:16:46.233
So I can show--

00:16:46.233 --> 00:16:46.900
[VIDEO PLAYBACK]

00:16:46.900 --> 00:16:48.130
--some of the videos for it.

00:16:48.130 --> 00:16:53.230
This is the first video
that shows the Generation 1.

00:16:53.230 --> 00:16:55.570
In the performance
yesterday, I performed

00:16:55.570 --> 00:17:00.430
with two robotic arms,
Generation 1, Generation 2,

00:17:00.430 --> 00:17:04.452
that showed the process of me
working with these evolving

00:17:04.452 --> 00:17:05.619
machines and their behavior.

00:17:05.619 --> 00:17:07.887
[MUSIC - ERIK SATIE,
"GNOSSIENE NO.

00:17:07.887 --> 00:17:12.089
1"]

00:17:12.089 --> 00:17:13.740
It was so experimental.

00:17:13.740 --> 00:17:20.440
This is just actually a
really mediocre webcam feed

00:17:20.440 --> 00:17:24.040
that I just had up in
my performance area, so.

00:17:24.040 --> 00:17:28.480
[CHUCKLES] But I
thought this showed

00:17:28.480 --> 00:17:33.850
this interesting attention of
agency and making that really,

00:17:33.850 --> 00:17:37.012
really sparked a lot of
ideas in me creatively.

00:17:37.012 --> 00:17:38.290
[END PLAYBACK]

00:17:38.290 --> 00:17:41.093
I'll go through to
the next one too.

00:17:41.093 --> 00:17:41.760
[VIDEO PLAYBACK]

00:17:41.760 --> 00:17:44.250
And then shortly after
I released that project,

00:17:44.250 --> 00:17:46.530
I got really interested
in the idea of generating

00:17:46.530 --> 00:17:48.570
new types of machine behaviors.

00:17:48.570 --> 00:17:52.050
Not just a simple relay
of the positional data

00:17:52.050 --> 00:17:53.760
that I was inputting,
but something

00:17:53.760 --> 00:17:55.620
that could function
a little bit more

00:17:55.620 --> 00:17:59.370
as a creative catalyst
for my own drawing style.

00:17:59.370 --> 00:18:01.765
[LIGHT MUSIC]

00:18:06.247 --> 00:18:06.830
[END PLAYBACK]

00:18:06.830 --> 00:18:08.410
I'll just go through that.

00:18:08.410 --> 00:18:10.100
And a lot of this,
I think we have

00:18:10.100 --> 00:18:11.840
to think a lot
about how language

00:18:11.840 --> 00:18:14.630
and how the words we use
to describe these systems

00:18:14.630 --> 00:18:18.140
end up shaping how
we think about it.

00:18:18.140 --> 00:18:23.750
And in English, the etymological
origin for the word "computer"

00:18:23.750 --> 00:18:26.720
is that it's a system meant
to produce automation.

00:18:26.720 --> 00:18:30.290
And I'm Chinese, and I always
found it really interesting

00:18:30.290 --> 00:18:33.740
to compare it to the Chinese
interpretation of computer,

00:18:33.740 --> 00:18:37.230
which is [CHINESE],,
which is electric brain.

00:18:37.230 --> 00:18:40.940
So I think that speaks a lot to
the possibilities and promises

00:18:40.940 --> 00:18:43.520
and a little bit of
where we're heading

00:18:43.520 --> 00:18:45.680
in working with these
systems, and thinking

00:18:45.680 --> 00:18:48.212
about ways we can align--

00:18:48.212 --> 00:18:49.670
I've been reading
a little bit more

00:18:49.670 --> 00:18:51.680
about this idea
of cosmotechnics,

00:18:51.680 --> 00:18:56.690
and the origin of some
of these technologies,

00:18:56.690 --> 00:18:59.310
and how they can inform
our way moving forward.

00:18:59.310 --> 00:19:02.150
So this is actually a
diagram of the I Ching.

00:19:02.150 --> 00:19:06.110
But doesn't it look a little
bit like an ML architecture?

00:19:06.110 --> 00:19:08.450
I thought there's some
interesting parallels there,

00:19:08.450 --> 00:19:12.602
and something that I'm exploring
in my forthcoming works.

00:19:12.602 --> 00:19:14.810
I'm going to really run
through these, because I know

00:19:14.810 --> 00:19:16.760
we have a lot to talk about.

00:19:16.760 --> 00:19:21.590
But I think this comes from
this idea of hybrid seeing.

00:19:21.590 --> 00:19:25.160
We see in our own
unique spectrum.

00:19:25.160 --> 00:19:31.070
But also, the systems that we
work with see in their own way.

00:19:31.070 --> 00:19:35.330
And that presents interesting
particularities and biases.

00:19:35.330 --> 00:19:40.010
You could even describe
an artist's artistic style

00:19:40.010 --> 00:19:43.730
through landscape painting
as a type of visual bias.

00:19:43.730 --> 00:19:49.340
That, of course, we know is
quite a topic of discussion

00:19:49.340 --> 00:19:52.670
in a lot of how we think
about these systems of data

00:19:52.670 --> 00:19:53.810
and how they're trained.

00:19:53.810 --> 00:19:57.050
So I've always found
an interesting parallel

00:19:57.050 --> 00:20:00.470
between how a human
sees a landscape

00:20:00.470 --> 00:20:02.210
and how a computer
might, and how we

00:20:02.210 --> 00:20:04.730
might be training it to do so.

00:20:04.730 --> 00:20:08.810
This is the screencap of
the project-- hold on.

00:20:08.810 --> 00:20:12.740
Anyway, so the project that
I'm going to show after this

00:20:12.740 --> 00:20:14.660
is inspired by that idea.

00:20:14.660 --> 00:20:17.150
Thinking about how
I would interpret

00:20:17.150 --> 00:20:22.400
the flow of a city versus how
the algorithms that were used

00:20:22.400 --> 00:20:24.350
interpret the flow
of the city, and how

00:20:24.350 --> 00:20:29.240
that might be able to combine
to a human and machine agency

00:20:29.240 --> 00:20:30.960
that's performed in real time.

00:20:30.960 --> 00:20:36.440
This is inspired by some of
the work of Akira Kanayama,

00:20:36.440 --> 00:20:40.010
from the Gutai collective
in 1960s Japan,

00:20:40.010 --> 00:20:43.093
thinking about ways of expanding
our idea of collaboration.

00:20:43.093 --> 00:20:43.760
[VIDEO PLAYBACK]

00:20:43.760 --> 00:20:46.300
[MUSIC PLAYING]

00:20:46.300 --> 00:20:49.600
We did a short film around
this project that's available

00:20:49.600 --> 00:20:50.740
online for you to see.

00:20:50.740 --> 00:20:52.630
I'm going to skip
through because we

00:20:52.630 --> 00:20:53.770
don't have much time left.

00:20:53.770 --> 00:20:54.520
[END PLAYBACK]

00:20:54.520 --> 00:20:57.220
And it's all
informed by this idea

00:20:57.220 --> 00:20:59.500
that we're part of a larger
creative ecosystem, which

00:20:59.500 --> 00:21:03.350
I'm sure is a sentiment
that many of you share here.

00:21:03.350 --> 00:21:06.650
So I just guess I'll
leave it at that.

00:21:06.650 --> 00:21:07.150
Thank you.

00:21:07.150 --> 00:21:08.275
KENRIC MCDOWELL: Thank you.

00:21:08.275 --> 00:21:09.931
[APPLAUSE]

00:21:13.859 --> 00:21:16.645
So it's so exciting
to see this work.

00:21:16.645 --> 00:21:19.270
The group that I lead at Google
that's called Artists + Machine

00:21:19.270 --> 00:21:23.590
Intelligence, and we put on the
first exhibition and auction

00:21:23.590 --> 00:21:26.470
of neural net-based artworks
in San Francisco's Gray Area

00:21:26.470 --> 00:21:28.860
in 2016 after Deep
Dream came out.

00:21:28.860 --> 00:21:31.540
And I feel like these practices
that you've shared with us--

00:21:31.540 --> 00:21:33.940
and thank you so much
for sharing them--

00:21:33.940 --> 00:21:37.483
really represent a maturation
of the relationship of artists

00:21:37.483 --> 00:21:39.400
with machine learning
and with AI in the sense

00:21:39.400 --> 00:21:44.320
that we're really looking at
not just what the AI can produce

00:21:44.320 --> 00:21:47.380
visually, but how it can be part
of a actual artistic practice

00:21:47.380 --> 00:21:51.288
in a really integrated
way, and what types of--

00:21:51.288 --> 00:21:53.830
how those integrations might
not necessarily appear visually,

00:21:53.830 --> 00:21:55.288
whether it's through
music, or it's

00:21:55.288 --> 00:22:01.320
through the process of
creation in the gesture itself.

00:22:01.320 --> 00:22:05.190
So one of the things
that came up early

00:22:05.190 --> 00:22:09.060
on when we started doing this
work with Artists + Machine

00:22:09.060 --> 00:22:10.800
Intelligence is this question--

00:22:10.800 --> 00:22:13.770
when people learn that
AI and machine learning

00:22:13.770 --> 00:22:15.570
can be used to make
art, they often

00:22:15.570 --> 00:22:17.460
go straight to this
question of automation.

00:22:17.460 --> 00:22:20.118
And they say, like, does
this mean that artists

00:22:20.118 --> 00:22:21.160
are going to be replaced?

00:22:21.160 --> 00:22:23.202
Is there going to be robots
that make all the art

00:22:23.202 --> 00:22:26.010
and then there's no need
for human artists anymore?

00:22:26.010 --> 00:22:28.622
So I don't think
that that's the case.

00:22:28.622 --> 00:22:30.330
And I think we can
clearly see that there

00:22:30.330 --> 00:22:31.453
are other alternatives.

00:22:31.453 --> 00:22:33.120
I don't think we need
to reiterate that,

00:22:33.120 --> 00:22:37.943
but I would like to ask,
having seen somewhat the role

00:22:37.943 --> 00:22:40.110
that automation does play
in both of your practices,

00:22:40.110 --> 00:22:42.720
how did you come to an
interest in integrating that

00:22:42.720 --> 00:22:45.180
into your practice?

00:22:45.180 --> 00:22:46.642
Whoever wants to--

00:22:46.642 --> 00:22:48.100
CEDRIC KIEFER: What
you just meant.

00:22:48.100 --> 00:22:50.660
I think integrating,
that's the important part.

00:22:50.660 --> 00:22:55.540
You raised the question if AI
is actually replacing artists

00:22:55.540 --> 00:22:57.700
at one point-- or
it's not about art.

00:22:57.700 --> 00:23:00.790
It's about replacing
everything, right?

00:23:00.790 --> 00:23:03.940
I definitely disagree,
specifically for art.

00:23:03.940 --> 00:23:06.190
But I think it's also the
question of how you actually

00:23:06.190 --> 00:23:09.593
use it in your art,
in your practice.

00:23:09.593 --> 00:23:11.260
And I think it's
really about-- at least

00:23:11.260 --> 00:23:13.555
for me-- integrating it.

00:23:13.555 --> 00:23:15.650
I like to actually
be responsible,

00:23:15.650 --> 00:23:17.950
and I like to define the
starting point, which

00:23:17.950 --> 00:23:21.130
in this case, could
be the training data,

00:23:21.130 --> 00:23:24.560
define the variables that
are actually responsible.

00:23:24.560 --> 00:23:26.560
But I also would like
to actually take over.

00:23:26.560 --> 00:23:30.250
I rarely like to hand the
end result fully to the AI

00:23:30.250 --> 00:23:31.520
or to the algorithm.

00:23:31.520 --> 00:23:33.882
But I like to include
it in the process.

00:23:33.882 --> 00:23:35.590
I think that's important,
because it also

00:23:35.590 --> 00:23:39.070
means that I start to
rethink how I do things,

00:23:39.070 --> 00:23:43.908
and that helps me to actually
come up with new results.

00:23:43.908 --> 00:23:46.450
I know that there are artists
who actually do it differently,

00:23:46.450 --> 00:23:49.090
and they hand things
over to the machine,

00:23:49.090 --> 00:23:51.550
and the output is the piece.

00:23:51.550 --> 00:23:53.530
That's not necessarily
what I like to do,

00:23:53.530 --> 00:23:56.020
because I like to
have control over what

00:23:56.020 --> 00:23:59.740
happens to a certain
degree, definitely.

00:23:59.740 --> 00:24:03.070
But it's an important topic,
because that question, as you

00:24:03.070 --> 00:24:04.300
said, comes up quite often.

00:24:04.300 --> 00:24:06.730
It's like, oh, do you just
write a little bit of code

00:24:06.730 --> 00:24:09.570
and then press art,
art, art, more art.

00:24:09.570 --> 00:24:11.360
And that's not
exactly how it is.

00:24:11.360 --> 00:24:12.770
SOUGWEN CHUNG: [CHUCKLES]

00:24:12.770 --> 00:24:13.860
KENRIC MCDOWELL: Is that
what you do, Sougwen?

00:24:13.860 --> 00:24:14.020
Do you just--

00:24:14.020 --> 00:24:15.310
SOUGWEN CHUNG: That would
be a great art project.

00:24:15.310 --> 00:24:17.310
KENRIC MCDOWELL: You don't
have a button either?

00:24:17.310 --> 00:24:22.270
SOUGWEN CHUNG: Oh, I don't
yet, but I want to now.

00:24:22.270 --> 00:24:25.720
When I think of the conversation
around automation and agency,

00:24:25.720 --> 00:24:28.340
and how I employ
my robots, for me,

00:24:28.340 --> 00:24:34.030
it's very much about
re-contextualizing the visual

00:24:34.030 --> 00:24:36.880
metaphor of the robotic
arm-- which is a symbol

00:24:36.880 --> 00:24:39.790
of the Industrial Revolution
and of automation--

00:24:39.790 --> 00:24:42.970
into something that's a
little bit more collaborative.

00:24:42.970 --> 00:24:46.300
I'm really incensed
by this idea that AI

00:24:46.300 --> 00:24:51.520
can serve as a creative catalyst
to take my practice, even

00:24:51.520 --> 00:24:54.880
in its simplest form, to places
that I wouldn't otherwise

00:24:54.880 --> 00:24:56.890
be comfortable going.

00:24:56.890 --> 00:25:01.240
I think, in that way,
showing this project

00:25:01.240 --> 00:25:04.810
as a co-creation and a
collaborative process

00:25:04.810 --> 00:25:06.850
I think reminds us that
the human hand is always

00:25:06.850 --> 00:25:08.770
present in these systems anyway.

00:25:08.770 --> 00:25:12.100
So there's no such thing as
a true relinquishing of it

00:25:12.100 --> 00:25:14.830
to this AI deity
that sometimes I

00:25:14.830 --> 00:25:17.920
think we're tempted
to really align to.

00:25:17.920 --> 00:25:24.490
But again, that collaborative
co-creative agent is something

00:25:24.490 --> 00:25:25.690
that I--

00:25:25.690 --> 00:25:28.270
it draws me to the work.

00:25:28.270 --> 00:25:33.016
And yeah, and that's what I
want to continue to evolve.

00:25:33.016 --> 00:25:38.322
KENRIC MCDOWELL: So one logical
step that's often taken--

00:25:38.322 --> 00:25:40.030
I think this is what
you're speaking to--

00:25:40.030 --> 00:25:42.850
with the word "integration,"
but also augmentation.

00:25:42.850 --> 00:25:44.800
The idea that we
might be, rather

00:25:44.800 --> 00:25:47.290
than automating or replacing
aspects of ourselves

00:25:47.290 --> 00:25:51.430
with machine learning and AI, we
could augment our capabilities,

00:25:51.430 --> 00:25:53.270
or produce new types
of capabilities,

00:25:53.270 --> 00:25:54.820
new types of imagination.

00:25:54.820 --> 00:25:58.930
So I wanted to ask,
have you experienced--

00:25:58.930 --> 00:26:02.410
well, first, how has
working with these systems

00:26:02.410 --> 00:26:05.830
changed your conception
or imagination

00:26:05.830 --> 00:26:07.570
in the process of making work?

00:26:07.570 --> 00:26:10.180
And have you experienced
moments of emergence,

00:26:10.180 --> 00:26:14.470
or serendipity, or
co-creation, co-thinking

00:26:14.470 --> 00:26:19.322
with these tools that might not
have been possible otherwise?

00:26:19.322 --> 00:26:21.280
CEDRIC KIEFER: In my
specific case, definitely,

00:26:21.280 --> 00:26:24.790
because we started
with code-based design

00:26:24.790 --> 00:26:25.850
from the very beginning.

00:26:25.850 --> 00:26:27.910
And one of the things
that draw my attention

00:26:27.910 --> 00:26:31.630
is just the way that the
creation process actually

00:26:31.630 --> 00:26:34.450
differs from the, I would
say, like the classical design

00:26:34.450 --> 00:26:36.250
process, where
you have a vision,

00:26:36.250 --> 00:26:38.740
and you just try to
execute it, and then get

00:26:38.740 --> 00:26:40.550
closer and closer step by step.

00:26:40.550 --> 00:26:44.380
But in this case, you start
to actually form and define

00:26:44.380 --> 00:26:46.030
a system, a rule set.

00:26:46.030 --> 00:26:48.580
But there are also some parts
that are actually left open.

00:26:48.580 --> 00:26:52.090
And this is what you just
described, this lucky accident,

00:26:52.090 --> 00:26:54.580
and this little bit of chance.

00:26:54.580 --> 00:26:58.210
And then this is the same with
the system that I mentioned,

00:26:58.210 --> 00:27:00.670
the William Forsythe
improvisation technologies.

00:27:00.670 --> 00:27:02.380
It just leads to
a point when you

00:27:02.380 --> 00:27:04.570
start to rethink
what you usually do,

00:27:04.570 --> 00:27:07.690
and it is some kind of a
trigger to actually do things

00:27:07.690 --> 00:27:08.630
differently.

00:27:08.630 --> 00:27:11.020
And I really like to
foster these moments

00:27:11.020 --> 00:27:12.820
and make them part of
the creation process,

00:27:12.820 --> 00:27:14.797
because that's when
beautiful things happen.

00:27:14.797 --> 00:27:15.630
KENRIC MCDOWELL: Mm.

00:27:15.630 --> 00:27:16.965
Mm-hm.

00:27:16.965 --> 00:27:19.250
SOUGWEN CHUNG: I think my
response to that would be,

00:27:19.250 --> 00:27:20.212
when--

00:27:20.212 --> 00:27:21.670
and what I'm really
trying to do is

00:27:21.670 --> 00:27:25.180
I'm trying to create an
artistic behavior that's

00:27:25.180 --> 00:27:28.150
really quite linked
to my control, which

00:27:28.150 --> 00:27:30.070
is a drawing style.

00:27:30.070 --> 00:27:32.620
I think when that
happens, it's one way

00:27:32.620 --> 00:27:34.840
to think about that as
automation or augmentation,

00:27:34.840 --> 00:27:36.580
but it's also--

00:27:36.580 --> 00:27:39.100
for me, it's a
different way of being

00:27:39.100 --> 00:27:40.870
able to look at my own practice.

00:27:40.870 --> 00:27:43.870
It becomes a bed of
not only introspection,

00:27:43.870 --> 00:27:49.950
but also a way to create
behaviors in a time capsule.

00:27:49.950 --> 00:27:54.890
So it's a way to engage with
my different drawing behaviors

00:27:54.890 --> 00:27:59.480
over time, and to see how
that's evolved in a really

00:27:59.480 --> 00:28:02.120
physical and embodied way.

00:28:02.120 --> 00:28:04.330
And also, it's something that--

00:28:04.330 --> 00:28:06.050
a new project that
I'm working on--

00:28:06.050 --> 00:28:09.090
something that I would be able
to share with other people.

00:28:09.090 --> 00:28:13.370
So it becomes this
polygeographic artistic agent

00:28:13.370 --> 00:28:17.780
that I have a lot of control
and agency and design over,

00:28:17.780 --> 00:28:19.620
and it's a very
consensual system.

00:28:19.620 --> 00:28:22.400
But it's a way to
really expand my process

00:28:22.400 --> 00:28:26.720
and bring other people into the
work in a way that would not

00:28:26.720 --> 00:28:29.870
be possible if it was just
me and a stick of graphite.

00:28:29.870 --> 00:28:31.555
So I find that really exciting.

00:28:31.555 --> 00:28:32.060
KENRIC MCDOWELL: Yeah.

00:28:32.060 --> 00:28:33.602
This is interesting
that you bring up

00:28:33.602 --> 00:28:38.540
these notions of training sets,
personalizing the training data

00:28:38.540 --> 00:28:39.980
as well as the
notion of consent,

00:28:39.980 --> 00:28:42.710
and who is part of the system.

00:28:42.710 --> 00:28:44.210
Along with the
question of agency,

00:28:44.210 --> 00:28:47.360
this is, I think,
a important point

00:28:47.360 --> 00:28:50.840
where we can imagine that these
practices are, in some ways,

00:28:50.840 --> 00:28:53.120
experiments in how to
relate with technology.

00:28:53.120 --> 00:28:56.630
And so in the past,
artists did work

00:28:56.630 --> 00:28:58.815
with different tool
makers, and their influence

00:28:58.815 --> 00:29:00.190
was felt in the
work in some way.

00:29:00.190 --> 00:29:01.982
But I think we can look
at machine learning

00:29:01.982 --> 00:29:03.740
and say that working
with Magenta,

00:29:03.740 --> 00:29:08.900
or creating a data set versus
using an already-existing data

00:29:08.900 --> 00:29:13.790
set, or a trained neural net,
are moments where artists are

00:29:13.790 --> 00:29:16.580
making choices
about which partners

00:29:16.580 --> 00:29:19.520
they're bringing into their
technological practice.

00:29:19.520 --> 00:29:22.280
And this is something that
maybe is probably new, or is

00:29:22.280 --> 00:29:23.780
relatively new with media art.

00:29:23.780 --> 00:29:28.580
So I wanted to really ask the
question about collaboration,

00:29:28.580 --> 00:29:31.120
and, really, agency.

00:29:31.120 --> 00:29:32.960
So if this is a
collaboration, whether it's

00:29:32.960 --> 00:29:35.960
with a machine learning
system that you describe

00:29:35.960 --> 00:29:37.550
as an independent
entity, or a machine

00:29:37.550 --> 00:29:39.560
learning system that's
a sort of extrusion

00:29:39.560 --> 00:29:45.710
of Google, or other open
source research, with whom

00:29:45.710 --> 00:29:48.230
does the agency lie when
we're using these systems?

00:29:48.230 --> 00:29:50.270
And what does it
mean to you to use

00:29:50.270 --> 00:29:53.930
a tool that is
likely not created

00:29:53.930 --> 00:29:55.190
for an artistic purpose?

00:29:55.190 --> 00:29:56.640
Maybe Magenta
might be different,

00:29:56.640 --> 00:29:58.620
but a lot of neural
nets are not.

00:29:58.620 --> 00:30:02.492
How does that play into your
thinking about your practice?

00:30:02.492 --> 00:30:03.700
CEDRIC KIEFER: Good question.

00:30:03.700 --> 00:30:05.260
A tricky one.

00:30:05.260 --> 00:30:07.570
But I think it's also partly
the answer to the question

00:30:07.570 --> 00:30:08.945
that you raised
in the beginning.

00:30:08.945 --> 00:30:13.460
Are computers or AI
replacing artists?

00:30:13.460 --> 00:30:18.850
And my answer to that would be,
again, no, because there's--

00:30:18.850 --> 00:30:21.070
as you said-- an intention
that artists have.

00:30:21.070 --> 00:30:23.770
They really have the will
to produce something.

00:30:23.770 --> 00:30:25.900
I think that's something
that machines are missing.

00:30:25.900 --> 00:30:27.810
I'm not saying they
will miss that forever.

00:30:27.810 --> 00:30:29.720
Might change, for sure.

00:30:29.720 --> 00:30:31.330
But at least in
the beginning, it's

00:30:31.330 --> 00:30:34.897
always like the artist that
comes first that actually tells

00:30:34.897 --> 00:30:37.480
the machine to create something,
that even creates the machine

00:30:37.480 --> 00:30:38.950
to create art.

00:30:38.950 --> 00:30:43.540
So until this isn't
changing, I think there's

00:30:43.540 --> 00:30:44.920
no replacement happening.

00:30:44.920 --> 00:30:47.350
And it's also, still, as you
said, the artist who actually

00:30:47.350 --> 00:30:50.680
defines what the input
is, which could be input

00:30:50.680 --> 00:30:53.650
that you created yourself,
like you do in your pieces,

00:30:53.650 --> 00:30:55.340
but we also did with the music.

00:30:55.340 --> 00:30:59.350
But also other artists, other
creatives actually taking input

00:30:59.350 --> 00:31:01.360
from totally different
sources, which, again,

00:31:01.360 --> 00:31:02.750
leads to different results.

00:31:02.750 --> 00:31:06.820
But what this source is is,
again, defined by the artist.

00:31:06.820 --> 00:31:10.270
So there's still this agency
missing that you mentioned,

00:31:10.270 --> 00:31:11.080
I feel.

00:31:11.080 --> 00:31:13.000
KENRIC MCDOWELL: Mm-hm, mm-hm.

00:31:13.000 --> 00:31:14.440
SOUGWEN CHUNG: I
think one reason

00:31:14.440 --> 00:31:17.440
why we're so interested
in talking about AI

00:31:17.440 --> 00:31:22.090
and art is because it's
about this idea of agency.

00:31:22.090 --> 00:31:23.920
And agency has been
something that I

00:31:23.920 --> 00:31:27.910
think artists have historically
addressed the meta-narrative

00:31:27.910 --> 00:31:29.620
of that as well over time.

00:31:29.620 --> 00:31:34.600
But when I think about that,
I get into my head a lot

00:31:34.600 --> 00:31:36.520
about whether--

00:31:36.520 --> 00:31:39.190
I sort of question
my own agency.

00:31:39.190 --> 00:31:43.330
If I am to question the
agency of a machine,

00:31:43.330 --> 00:31:46.750
I question my own, and
that gets into notions

00:31:46.750 --> 00:31:48.390
of free will and all this.

00:31:48.390 --> 00:31:51.190
But I think it's made me
think a little bit more

00:31:51.190 --> 00:31:58.160
about what actually motivates
an individual's decision.

00:31:58.160 --> 00:32:00.190
And is it the microbiome?

00:32:00.190 --> 00:32:03.880
Is it the gut bacteria
in your system?

00:32:03.880 --> 00:32:05.440
Is that a driving force?

00:32:05.440 --> 00:32:12.190
I think our ideas of agency
have become really pluralistic.

00:32:12.190 --> 00:32:16.420
And that, alongside machines,
alongside our own physiology,

00:32:16.420 --> 00:32:21.070
has been a really
unexpected, creative "a-ha"

00:32:21.070 --> 00:32:24.340
moment in a lot of the work
that I've been trying to bring

00:32:24.340 --> 00:32:29.170
in through these kinetic robotic
sculptures as a way of really

00:32:29.170 --> 00:32:32.795
confusing and making
that ambiguous.

00:32:32.795 --> 00:32:35.170
That's a very long-winded way
of answering your question.

00:32:35.170 --> 00:32:36.850
KENRIC MCDOWELL:
[CHUCKLES] Yeah.

00:32:36.850 --> 00:32:38.683
If we could figure out
free will, then maybe

00:32:38.683 --> 00:32:40.820
we can answer that question.

00:32:40.820 --> 00:32:43.000
So I wanted to address
questions individually

00:32:43.000 --> 00:32:45.820
for the last couple questions,
and for the last part

00:32:45.820 --> 00:32:48.810
of the talk.

00:32:48.810 --> 00:32:49.920
And I think this--

00:32:49.920 --> 00:32:53.575
I'll address this
question to you, Sougwen.

00:32:53.575 --> 00:32:55.200
If we imagine that
cities in the future

00:32:55.200 --> 00:32:59.210
are managed in part by local
intelligence systems for--

00:32:59.210 --> 00:33:02.400
a mundane example, self-driving
cars that interact with, say,

00:33:02.400 --> 00:33:04.050
a intelligent traffic light--

00:33:04.050 --> 00:33:07.080
then we can view your
practice as a prototype

00:33:07.080 --> 00:33:10.990
for a co-creative relationship
with our built environment.

00:33:10.990 --> 00:33:13.350
What do you think
designers, architects,

00:33:13.350 --> 00:33:16.080
and urban planners should
know about working creatively

00:33:16.080 --> 00:33:18.040
with intelligent systems?

00:33:18.040 --> 00:33:20.690
SOUGWEN CHUNG: That's a
really big question, actually.

00:33:24.540 --> 00:33:30.210
I think it's important to
view the intelligent system,

00:33:30.210 --> 00:33:32.490
the entity that we're
collaborating with,

00:33:32.490 --> 00:33:34.200
as something that's
already happening.

00:33:34.200 --> 00:33:37.170
Actually, we have
these layered systems,

00:33:37.170 --> 00:33:40.560
like Uber and all those places.

00:33:40.560 --> 00:33:44.970
Those already exist in
our architectures now.

00:33:44.970 --> 00:33:48.910
I think there's ways to
integrate that in a way that--

00:33:48.910 --> 00:33:52.260
when I think about this,
I think about music.

00:33:52.260 --> 00:33:53.910
Something with a
rhythm, and something

00:33:53.910 --> 00:34:00.600
that responds to the broadest
spectrum of human need.

00:34:00.600 --> 00:34:02.850
Because there's
obviously a desire

00:34:02.850 --> 00:34:05.340
for efficiency in urban flow.

00:34:05.340 --> 00:34:10.170
But there's also moments of
pause that need to be baked in.

00:34:10.170 --> 00:34:12.840
And even in the
design of this space,

00:34:12.840 --> 00:34:16.650
there's places for digital
detox and places for meditation.

00:34:16.650 --> 00:34:19.170
And obviously, I
wouldn't be the one

00:34:19.170 --> 00:34:25.830
to speak to about
optimization of traffic flow.

00:34:25.830 --> 00:34:29.460
But I think to think about
it as a whole organism that

00:34:29.460 --> 00:34:33.659
represents the best
interests of the collective,

00:34:33.659 --> 00:34:38.730
I think is a way to set goals
for these intelligent systems

00:34:38.730 --> 00:34:39.965
in urban environments.

00:34:39.965 --> 00:34:42.260
KENRIC MCDOWELL:
Well, thank you.

00:34:42.260 --> 00:34:46.712
And Cedric, your piece
with onformative,

00:34:46.712 --> 00:34:48.170
"Meandering River,"
as well as many

00:34:48.170 --> 00:34:51.230
of the works at I/O Arts,
including Jenna Sutela's

00:34:51.230 --> 00:34:53.540
film, "nimiia cetii," which
will be screened tonight,

00:34:53.540 --> 00:34:57.890
and Anna Ridler's
"Mosaic Virus,"

00:34:57.890 --> 00:35:00.440
which is also on the
boardwalk, reflect not only

00:35:00.440 --> 00:35:02.540
a co-creative relationship
with machines, but also

00:35:02.540 --> 00:35:05.900
a co-creative relationship
with plants and animals.

00:35:05.900 --> 00:35:07.820
And in the case of
"Meandering River,"

00:35:07.820 --> 00:35:10.960
I think a new vision of
how to see natural systems

00:35:10.960 --> 00:35:12.980
through technology.

00:35:12.980 --> 00:35:15.232
As we collaborate with
machines, can we not

00:35:15.232 --> 00:35:17.690
also collaborate with plants
and animals, or even the Earth

00:35:17.690 --> 00:35:19.050
itself?

00:35:19.050 --> 00:35:21.830
What can you share
with us about relating

00:35:21.830 --> 00:35:23.690
to these natural systems
through the tools

00:35:23.690 --> 00:35:28.130
that you've used, for example
with "Meandering River?"

00:35:28.130 --> 00:35:31.160
CEDRIC KIEFER:
Yeah, good question.

00:35:31.160 --> 00:35:33.350
What we usually like
to do in our work

00:35:33.350 --> 00:35:39.410
is we like to look a little
bit beyond what we usually do.

00:35:39.410 --> 00:35:41.990
And I find that in a lot
of different disciplines.

00:35:41.990 --> 00:35:47.580
Could be from dance
to classical music.

00:35:47.580 --> 00:35:50.000
But again, could also be nature.

00:35:50.000 --> 00:35:51.440
Inspiration comes
from everywhere.

00:35:51.440 --> 00:35:53.482
And especially with the
"Meandering River" piece,

00:35:53.482 --> 00:35:56.690
I think one of the
interesting things that

00:35:56.690 --> 00:36:00.650
resonate with us so strongly
is the fact that it's heavily

00:36:00.650 --> 00:36:03.260
about change and
unpredictability.

00:36:03.260 --> 00:36:05.340
And you find that
a lot in nature.

00:36:05.340 --> 00:36:08.480
So if we talk about, if there
could be a collaborative work

00:36:08.480 --> 00:36:13.880
with nature directly, then
that might be hard to answer,

00:36:13.880 --> 00:36:17.270
because a collaborative process
requires some kind of feedback,

00:36:17.270 --> 00:36:20.300
and the feedback is a
little more indirect.

00:36:20.300 --> 00:36:23.510
Not saying that nature doesn't
react to what we do as humans.

00:36:23.510 --> 00:36:25.580
We definitely know that's true.

00:36:25.580 --> 00:36:27.400
Not always for the best.

00:36:27.400 --> 00:36:29.920
But definitely.

00:36:29.920 --> 00:36:32.223
Our work is not really
focused on nature,

00:36:32.223 --> 00:36:34.640
so I think there are different
artists who can answer that

00:36:34.640 --> 00:36:37.880
better, and who have much
stronger focus on actually

00:36:37.880 --> 00:36:39.620
including-- as you said--

00:36:39.620 --> 00:36:42.060
animals, plants,
or just the world

00:36:42.060 --> 00:36:43.750
surrounding them into their art.

00:36:43.750 --> 00:36:46.850
For us, it's a little bit
more about making the process

00:36:46.850 --> 00:36:49.200
visible, making change visible.

00:36:49.200 --> 00:36:52.840
And for that reason, nature
is always an important topic.

00:36:52.840 --> 00:36:54.590
But to answer the
question, I think, yeah,

00:36:54.590 --> 00:36:55.900
that's definitely possible.

00:36:55.900 --> 00:36:58.310
And machine learning
is just one example

00:36:58.310 --> 00:37:01.500
of how such a collaborator
could look like,

00:37:01.500 --> 00:37:05.030
but you can find it everywhere.

00:37:05.030 --> 00:37:05.960
KENRIC MCDOWELL: Wow.

00:37:05.960 --> 00:37:10.563
Well, I want to thank you both
for contributing your work

00:37:10.563 --> 00:37:12.980
to this experience for everyone
at I/O. I think it's added

00:37:12.980 --> 00:37:15.060
a lot to the experience here.

00:37:15.060 --> 00:37:15.920
It has for me.

00:37:15.920 --> 00:37:17.870
And for sharing with
us today your practice

00:37:17.870 --> 00:37:18.810
and this conversation.

00:37:18.810 --> 00:37:19.310
Thank you so much.

00:37:19.310 --> 00:37:20.910
Everyone, a round of applause,
please, for Sougwen and Cedric.

00:37:20.910 --> 00:37:21.415
CEDRIC KIEFER: Yeah, thank you.

00:37:21.415 --> 00:37:22.820
SOUGWEN CHUNG: Thank you.

00:37:22.820 --> 00:37:25.570
[MUSIC PLAYING]

