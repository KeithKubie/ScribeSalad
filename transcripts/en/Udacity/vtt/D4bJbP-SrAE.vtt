WEBVTT
Kind: captions
Language: en

00:00:00.180 --> 00:00:02.200
First let's talk a little bit
about camera calibration.

00:00:02.200 --> 00:00:04.400
There are two different
types of camera calibration.

00:00:04.400 --> 00:00:06.930
First is a geometric calibration,

00:00:06.930 --> 00:00:10.890
where we basically are interested when
we look at a 3D scene is how each and

00:00:10.890 --> 00:00:15.230
every pixel in the real world
is relating to directions,

00:00:15.230 --> 00:00:20.350
angles, shapes, you know, any kind of
geometric information in the real world.

00:00:20.350 --> 00:00:23.640
So that requires us to now
calibrate the camera and

00:00:23.640 --> 00:00:27.270
the location of the camera with respect
to the scenes and objects in a scene, so

00:00:27.270 --> 00:00:29.830
we can actually get more 3D information.

00:00:29.830 --> 00:00:31.130
That's geometric.

00:00:31.130 --> 00:00:34.420
Of course, we're also interested,
remember from our earlier lectures,

00:00:34.420 --> 00:00:38.217
to be able to capture radiometric,
photometric, information from

00:00:38.217 --> 00:00:43.150
a scene you know, like reflectances and
scattering of light information.

00:00:43.150 --> 00:00:44.650
Here, basically,
we're interested in each and

00:00:44.650 --> 00:00:48.930
every pixel related to the radiance
amounts in the real world.

00:00:48.930 --> 00:00:50.220
You know, what's happening in a scene?

00:00:50.220 --> 00:00:53.580
What's the exact radiance
value at any point in a scene?

00:00:53.580 --> 00:00:56.670
How can we capture it
onto a pixel in an image?

00:00:56.670 --> 00:00:58.960
Again, this is the whole
pipeline we just saw,

00:00:58.960 --> 00:01:03.130
where we basically want to be able
to go from l all the way to i.

00:01:03.130 --> 00:01:06.175
Now, we study this a little
bit when we did panaromas.

00:01:06.175 --> 00:01:11.370
Sometimes, we might not have ability
to capture everything in a 3D world

00:01:11.370 --> 00:01:13.750
directly from the sensors so

00:01:13.750 --> 00:01:17.130
what we want to do now is take a little
bit of a data-driven approach.

00:01:17.130 --> 00:01:20.230
Basically, that suggests
is let's actually do this

00:01:20.230 --> 00:01:24.710
by looking at a bunch of images, not
just one image, and use that information

00:01:24.710 --> 00:01:27.650
as to how things change when I
take a bunch of different images.

00:01:27.650 --> 00:01:30.080
So, for example, here,
I may have a color pattern,

00:01:30.080 --> 00:01:32.800
which tells me everything else about
it but I could take a color pattern,

00:01:32.800 --> 00:01:36.690
a checkered pattern, and
move it around and as I move it around,

00:01:36.690 --> 00:01:40.390
if knowing a little bit more about the
information in that scene, in this case,

00:01:40.390 --> 00:01:44.200
of course, the exact nature of the
structure pattern associated here and

00:01:44.200 --> 00:01:46.370
if I look at it from the same camera,

00:01:46.370 --> 00:01:50.030
I should be able to kind of now get
different data, at different points.

00:01:50.030 --> 00:01:55.140
That basically suggests is that
now I can get how pixel relates to

00:01:55.140 --> 00:01:59.270
the geometry in a scene by just looking
at a whole lot of other images.

00:01:59.270 --> 00:02:01.780
Well, the same thing is true
in the case of photometric.

00:02:01.780 --> 00:02:04.900
This was relevant when we looked
at the whole case of paranomas.

00:02:04.900 --> 00:02:08.710
This is more relevant in the kind of
world of HDR, where basically now we're

00:02:08.710 --> 00:02:13.800
trying to relate is how the radiance of
any point on the scene is accounting for

00:02:13.800 --> 00:02:18.450
a specific pixel intensity and we do
this by calibrating a camera by getting

00:02:18.450 --> 00:02:23.380
a lot of data by the same scene
by having different images.

00:02:23.380 --> 00:02:26.950
Remember, again, these were both issues
that help us when we start thinking

00:02:26.950 --> 00:02:28.860
about concepts like epsilon photography.

