WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:03.020 align:start position:0%
 
in<00:00:00.989><c> this</c><00:00:01.500><c> video</c><00:00:01.770><c> we'll</c><00:00:02.070><c> quickly</c><00:00:02.370><c> talk</c><00:00:02.730><c> about</c>

00:00:03.020 --> 00:00:03.030 align:start position:0%
in this video we'll quickly talk about
 

00:00:03.030 --> 00:00:06.349 align:start position:0%
in this video we'll quickly talk about
how<00:00:03.589><c> training</c><00:00:04.589><c> would</c><00:00:04.740><c> work</c><00:00:04.980><c> in</c><00:00:05.279><c> a</c><00:00:05.790><c> more</c>

00:00:06.349 --> 00:00:06.359 align:start position:0%
how training would work in a more
 

00:00:06.359 --> 00:00:10.629 align:start position:0%
how training would work in a more
general<00:00:06.890><c> conditional</c><00:00:07.890><c> random</c><00:00:08.010><c> field</c><00:00:08.429><c> setup</c>

00:00:10.629 --> 00:00:10.639 align:start position:0%
general conditional random field setup
 

00:00:10.639 --> 00:00:13.180 align:start position:0%
general conditional random field setup
we've<00:00:11.639><c> mentioned</c><00:00:12.059><c> in</c><00:00:12.330><c> previous</c><00:00:12.480><c> videos</c><00:00:13.110><c> that</c>

00:00:13.180 --> 00:00:13.190 align:start position:0%
we've mentioned in previous videos that
 

00:00:13.190 --> 00:00:15.890 align:start position:0%
we've mentioned in previous videos that
we<00:00:14.190><c> do</c><00:00:14.370><c> not</c><00:00:14.549><c> need</c><00:00:14.790><c> to</c><00:00:15.000><c> restrict</c><00:00:15.299><c> ourselves</c><00:00:15.480><c> to</c>

00:00:15.890 --> 00:00:15.900 align:start position:0%
we do not need to restrict ourselves to
 

00:00:15.900 --> 00:00:18.109 align:start position:0%
we do not need to restrict ourselves to
linear<00:00:16.320><c> chain</c><00:00:16.560><c> conditional</c><00:00:17.460><c> random</c><00:00:17.550><c> fields</c>

00:00:18.109 --> 00:00:18.119 align:start position:0%
linear chain conditional random fields
 

00:00:18.119 --> 00:00:20.900 align:start position:0%
linear chain conditional random fields
if<00:00:18.240><c> we</c><00:00:18.630><c> were</c><00:00:18.869><c> modeling</c><00:00:19.680><c> a</c><00:00:19.830><c> pixel</c><00:00:20.430><c> labeling</c>

00:00:20.900 --> 00:00:20.910 align:start position:0%
if we were modeling a pixel labeling
 

00:00:20.910 --> 00:00:22.970 align:start position:0%
if we were modeling a pixel labeling
problem<00:00:21.390><c> we</c><00:00:21.750><c> could</c><00:00:21.869><c> use</c><00:00:22.020><c> a</c><00:00:22.050><c> grid</c><00:00:22.380><c> structure</c>

00:00:22.970 --> 00:00:22.980 align:start position:0%
problem we could use a grid structure
 

00:00:22.980 --> 00:00:25.970 align:start position:0%
problem we could use a grid structure
where<00:00:23.460><c> each</c><00:00:23.640><c> node</c><00:00:24.060><c> would</c><00:00:24.660><c> correspond</c><00:00:25.170><c> to</c><00:00:25.289><c> one</c>

00:00:25.970 --> 00:00:25.980 align:start position:0%
where each node would correspond to one
 

00:00:25.980 --> 00:00:27.830 align:start position:0%
where each node would correspond to one
of<00:00:26.099><c> the</c><00:00:26.160><c> pixels</c><00:00:26.430><c> in</c><00:00:26.580><c> the</c><00:00:26.670><c> image</c><00:00:26.699><c> and</c><00:00:27.210><c> we'd</c><00:00:27.630><c> have</c>

00:00:27.830 --> 00:00:27.840 align:start position:0%
of the pixels in the image and we'd have
 

00:00:27.840 --> 00:00:29.779 align:start position:0%
of the pixels in the image and we'd have
factors<00:00:28.349><c> that</c><00:00:28.650><c> would</c><00:00:28.830><c> express</c><00:00:29.490><c> preferences</c>

00:00:29.779 --> 00:00:29.789 align:start position:0%
factors that would express preferences
 

00:00:29.789 --> 00:00:33.440 align:start position:0%
factors that would express preferences
on<00:00:30.390><c> the</c><00:00:31.199><c> joint</c><00:00:31.650><c> value</c><00:00:32.099><c> of</c><00:00:32.340><c> neighboring</c><00:00:33.030><c> pixels</c>

00:00:33.440 --> 00:00:33.450 align:start position:0%
on the joint value of neighboring pixels
 

00:00:33.450 --> 00:00:36.430 align:start position:0%
on the joint value of neighboring pixels
in<00:00:33.660><c> the</c><00:00:33.780><c> image</c><00:00:34.190><c> or</c><00:00:35.190><c> we</c><00:00:35.430><c> could</c><00:00:35.579><c> have</c><00:00:35.700><c> a</c><00:00:35.760><c> very</c>

00:00:36.430 --> 00:00:36.440 align:start position:0%
in the image or we could have a very
 

00:00:36.440 --> 00:00:40.520 align:start position:0%
in the image or we could have a very
complicated<00:00:38.059><c> structure</c><00:00:39.059><c> over</c><00:00:39.780><c> a</c><00:00:39.809><c> graph</c><00:00:40.170><c> where</c>

00:00:40.520 --> 00:00:40.530 align:start position:0%
complicated structure over a graph where
 

00:00:40.530 --> 00:00:42.799 align:start position:0%
complicated structure over a graph where
we<00:00:41.309><c> have</c><00:00:41.489><c> several</c><00:00:41.730><c> types</c><00:00:42.030><c> of</c><00:00:42.239><c> loops</c><00:00:42.510><c> and</c><00:00:42.750><c> we</c>

00:00:42.799 --> 00:00:42.809 align:start position:0%
we have several types of loops and we
 

00:00:42.809 --> 00:00:44.720 align:start position:0%
we have several types of loops and we
can<00:00:42.930><c> even</c><00:00:43.200><c> have</c><00:00:43.469><c> factors</c><00:00:44.219><c> that</c><00:00:44.340><c> will</c><00:00:44.430><c> involve</c>

00:00:44.720 --> 00:00:44.730 align:start position:0%
can even have factors that will involve
 

00:00:44.730 --> 00:00:48.770 align:start position:0%
can even have factors that will involve
more<00:00:45.090><c> than</c><00:00:45.120><c> just</c><00:00:45.860><c> two</c><00:00:46.860><c> variables</c><00:00:47.460><c> I</c><00:00:47.780><c> could</c>

00:00:48.770 --> 00:00:48.780 align:start position:0%
more than just two variables I could
 

00:00:48.780 --> 00:00:51.260 align:start position:0%
more than just two variables I could
even<00:00:48.899><c> have</c><00:00:49.170><c> a</c><00:00:49.230><c> structure</c><00:00:49.770><c> that</c><00:00:49.800><c> varies</c><00:00:50.520><c> for</c>

00:00:51.260 --> 00:00:51.270 align:start position:0%
even have a structure that varies for
 

00:00:51.270 --> 00:00:54.470 align:start position:0%
even have a structure that varies for
different<00:00:51.680><c> pairs</c><00:00:52.680><c> of</c><00:00:52.920><c> training</c><00:00:53.399><c> inputs</c><00:00:54.239><c> and</c>

00:00:54.470 --> 00:00:54.480 align:start position:0%
different pairs of training inputs and
 

00:00:54.480 --> 00:00:57.619 align:start position:0%
different pairs of training inputs and
targets<00:00:55.079><c> so</c><00:00:55.710><c> I'm</c><00:00:56.579><c> mentioning</c><00:00:57.030><c> an</c><00:00:57.210><c> example</c>

00:00:57.619 --> 00:00:57.629 align:start position:0%
targets so I'm mentioning an example
 

00:00:57.629 --> 00:01:01.010 align:start position:0%
targets so I'm mentioning an example
where<00:00:57.750><c> we</c><00:00:57.840><c> have</c><00:00:57.930><c> webpages</c><00:00:58.609><c> that</c><00:00:59.609><c> and</c><00:01:00.600><c> we're</c>

00:01:01.010 --> 00:01:01.020 align:start position:0%
where we have webpages that and we're
 

00:01:01.020 --> 00:01:04.310 align:start position:0%
where we have webpages that and we're
modeling<00:01:01.289><c> the</c><00:01:01.530><c> label</c><00:01:01.859><c> between</c><00:01:03.080><c> webpages</c><00:01:04.080><c> that</c>

00:01:04.310 --> 00:01:04.320 align:start position:0%
modeling the label between webpages that
 

00:01:04.320 --> 00:01:06.980 align:start position:0%
modeling the label between webpages that
share<00:01:04.979><c> a</c><00:01:05.010><c> link</c><00:01:05.430><c> and</c><00:01:05.729><c> if</c><00:01:06.330><c> we</c><00:01:06.600><c> have</c><00:01:06.750><c> different</c>

00:01:06.980 --> 00:01:06.990 align:start position:0%
share a link and if we have different
 

00:01:06.990 --> 00:01:09.980 align:start position:0%
share a link and if we have different
groups<00:01:07.470><c> of</c><00:01:07.710><c> webpages</c><00:01:08.040><c> then</c><00:01:08.790><c> the</c><00:01:09.689><c> different</c>

00:01:09.980 --> 00:01:09.990 align:start position:0%
groups of webpages then the different
 

00:01:09.990 --> 00:01:12.859 align:start position:0%
groups of webpages then the different
groups<00:01:10.170><c> of</c><00:01:10.380><c> webpages</c><00:01:10.590><c> might</c><00:01:11.220><c> have</c><00:01:11.869><c> different</c>

00:01:12.859 --> 00:01:12.869 align:start position:0%
groups of webpages might have different
 

00:01:12.869 --> 00:01:15.289 align:start position:0%
groups of webpages might have different
will<00:01:13.350><c> of</c><00:01:13.560><c> course</c><00:01:13.710><c> have</c><00:01:13.890><c> different</c><00:01:14.299><c> network</c>

00:01:15.289 --> 00:01:15.299 align:start position:0%
will of course have different network
 

00:01:15.299 --> 00:01:17.330 align:start position:0%
will of course have different network
structures<00:01:15.810><c> or</c><00:01:16.049><c> from</c><00:01:16.229><c> modeling</c><00:01:16.619><c> the</c><00:01:16.860><c> web</c>

00:01:17.330 --> 00:01:17.340 align:start position:0%
structures or from modeling the web
 

00:01:17.340 --> 00:01:22.340 align:start position:0%
structures or from modeling the web
pages<00:01:17.580><c> from</c><00:01:18.409><c> the</c><00:01:19.409><c> pages</c><00:01:19.950><c> of</c><00:01:20.130><c> one</c><00:01:21.080><c> on</c><00:01:22.080><c> one</c>

00:01:22.340 --> 00:01:22.350 align:start position:0%
pages from the pages of one on one
 

00:01:22.350 --> 00:01:24.950 align:start position:0%
pages from the pages of one on one
University<00:01:23.130><c> website</c><00:01:23.549><c> versus</c><00:01:24.509><c> another</c>

00:01:24.950 --> 00:01:24.960 align:start position:0%
University website versus another
 

00:01:24.960 --> 00:01:26.990 align:start position:0%
University website versus another
University<00:01:25.500><c> of</c><00:01:25.560><c> websites</c><00:01:25.920><c> of</c><00:01:26.159><c> course</c><00:01:26.820><c> these</c>

00:01:26.990 --> 00:01:27.000 align:start position:0%
University of websites of course these
 

00:01:27.000 --> 00:01:28.880 align:start position:0%
University of websites of course these
would<00:01:27.659><c> be</c><00:01:27.750><c> different</c><00:01:27.869><c> pages</c><00:01:28.229><c> and</c><00:01:28.409><c> they'll</c><00:01:28.710><c> be</c>

00:01:28.880 --> 00:01:28.890 align:start position:0%
would be different pages and they'll be
 

00:01:28.890 --> 00:01:32.390 align:start position:0%
would be different pages and they'll be
connected<00:01:29.340><c> differently</c><00:01:30.020><c> so</c><00:01:31.020><c> the</c><00:01:31.860><c> conditional</c>

00:01:32.390 --> 00:01:32.400 align:start position:0%
connected differently so the conditional
 

00:01:32.400 --> 00:01:34.760 align:start position:0%
connected differently so the conditional
random<00:01:32.490><c> field</c><00:01:33.020><c> framework</c><00:01:34.020><c> is</c><00:01:34.140><c> very</c><00:01:34.200><c> general</c>

00:01:34.760 --> 00:01:34.770 align:start position:0%
random field framework is very general
 

00:01:34.770 --> 00:01:36.100 align:start position:0%
random field framework is very general
for<00:01:34.979><c> modeling</c><00:01:35.340><c> the</c><00:01:35.490><c> interaction</c><00:01:35.880><c> between</c>

00:01:36.100 --> 00:01:36.110 align:start position:0%
for modeling the interaction between
 

00:01:36.110 --> 00:01:39.620 align:start position:0%
for modeling the interaction between
random<00:01:37.110><c> variables</c><00:01:37.619><c> so</c><00:01:37.920><c> concepts</c><00:01:38.909><c> that</c><00:01:39.420><c> we're</c>

00:01:39.620 --> 00:01:39.630 align:start position:0%
random variables so concepts that we're
 

00:01:39.630 --> 00:01:42.499 align:start position:0%
random variables so concepts that we're
trying<00:01:39.869><c> to</c><00:01:40.079><c> model</c><00:01:40.729><c> now</c><00:01:41.729><c> what</c><00:01:41.909><c> about</c><00:01:42.119><c> training</c>

00:01:42.499 --> 00:01:42.509 align:start position:0%
trying to model now what about training
 

00:01:42.509 --> 00:01:47.410 align:start position:0%
trying to model now what about training
such<00:01:43.020><c> general</c><00:01:43.619><c> conditional</c><00:01:44.159><c> random</c><00:01:44.250><c> fields</c>

00:01:47.410 --> 00:01:47.420 align:start position:0%
 
 

00:01:47.420 --> 00:01:50.960 align:start position:0%
 
well<00:01:48.420><c> to</c><00:01:49.140><c> do</c><00:01:49.259><c> that</c><00:01:49.290><c> we</c><00:01:49.799><c> still</c><00:01:50.280><c> perform</c>

00:01:50.960 --> 00:01:50.970 align:start position:0%
well to do that we still perform
 

00:01:50.970 --> 00:01:53.830 align:start position:0%
well to do that we still perform
gradient<00:01:51.420><c> descents</c><00:01:51.960><c> so</c><00:01:52.229><c> for</c><00:01:52.829><c> a</c><00:01:52.860><c> given</c><00:01:53.009><c> pair</c><00:01:53.430><c> of</c>

00:01:53.830 --> 00:01:53.840 align:start position:0%
gradient descents so for a given pair of
 

00:01:53.840 --> 00:01:58.249 align:start position:0%
gradient descents so for a given pair of
target<00:01:54.840><c> and</c><00:01:55.020><c> input</c><00:01:55.740><c> we</c><00:01:56.250><c> would</c><00:01:56.490><c> need</c><00:01:56.729><c> to</c><00:01:57.259><c> derive</c>

00:01:58.249 --> 00:01:58.259 align:start position:0%
target and input we would need to derive
 

00:01:58.259 --> 00:02:00.319 align:start position:0%
target and input we would need to derive
what<00:01:58.590><c> is</c><00:01:58.770><c> the</c><00:01:59.159><c> expression</c><00:01:59.460><c> for</c><00:01:59.759><c> the</c><00:02:00.119><c> partial</c>

00:02:00.319 --> 00:02:00.329 align:start position:0%
what is the expression for the partial
 

00:02:00.329 --> 00:02:02.690 align:start position:0%
what is the expression for the partial
derivative<00:02:00.930><c> of</c><00:02:01.140><c> the</c><00:02:01.860><c> negative</c><00:02:02.399><c> log</c>

00:02:02.690 --> 00:02:02.700 align:start position:0%
derivative of the negative log
 

00:02:02.700 --> 00:02:05.330 align:start position:0%
derivative of the negative log
likelihood<00:02:03.479><c> of</c><00:02:03.689><c> observing</c><00:02:04.290><c> some</c><00:02:05.070><c> given</c>

00:02:05.330 --> 00:02:05.340 align:start position:0%
likelihood of observing some given
 

00:02:05.340 --> 00:02:07.580 align:start position:0%
likelihood of observing some given
target<00:02:05.700><c> given</c><00:02:06.119><c> some</c><00:02:06.270><c> input</c><00:02:06.630><c> with</c><00:02:07.049><c> respect</c><00:02:07.469><c> to</c>

00:02:07.580 --> 00:02:07.590 align:start position:0%
target given some input with respect to
 

00:02:07.590 --> 00:02:11.449 align:start position:0%
target given some input with respect to
any<00:02:07.799><c> parameter</c><00:02:08.459><c> theta</c><00:02:08.700><c> in</c><00:02:09.060><c> our</c><00:02:09.270><c> model</c><00:02:09.660><c> and</c><00:02:10.459><c> it</c>

00:02:11.449 --> 00:02:11.459 align:start position:0%
any parameter theta in our model and it
 

00:02:11.459 --> 00:02:13.760 align:start position:0%
any parameter theta in our model and it
also<00:02:11.640><c> it</c><00:02:12.629><c> actually</c><00:02:12.810><c> takes</c><00:02:13.170><c> a</c><00:02:13.349><c> failed</c>

00:02:13.760 --> 00:02:13.770 align:start position:0%
also it actually takes a failed
 

00:02:13.770 --> 00:02:18.080 align:start position:0%
also it actually takes a failed
simple<00:02:14.340><c> expression</c><00:02:15.410><c> that's</c><00:02:16.410><c> very</c><00:02:16.920><c> general</c><00:02:17.430><c> so</c>

00:02:18.080 --> 00:02:18.090 align:start position:0%
simple expression that's very general so
 

00:02:18.090 --> 00:02:20.150 align:start position:0%
simple expression that's very general so
that's<00:02:18.630><c> partial</c><00:02:19.230><c> data</c><00:02:19.350><c> it</c><00:02:19.530><c> will</c><00:02:19.680><c> always</c><00:02:19.830><c> be</c>

00:02:20.150 --> 00:02:20.160 align:start position:0%
that's partial data it will always be
 

00:02:20.160 --> 00:02:23.150 align:start position:0%
that's partial data it will always be
minus<00:02:20.670><c> the</c><00:02:21.270><c> sum</c><00:02:21.630><c> over</c><00:02:21.990><c> all</c><00:02:22.020><c> the</c><00:02:22.320><c> factors</c><00:02:22.800><c> of</c>

00:02:23.150 --> 00:02:23.160 align:start position:0%
minus the sum over all the factors of
 

00:02:23.160 --> 00:02:25.790 align:start position:0%
minus the sum over all the factors of
the<00:02:24.120><c> partial</c><00:02:24.750><c> derivative</c><00:02:25.080><c> with</c><00:02:25.320><c> respect</c><00:02:25.710><c> to</c>

00:02:25.790 --> 00:02:25.800 align:start position:0%
the partial derivative with respect to
 

00:02:25.800 --> 00:02:28.520 align:start position:0%
the partial derivative with respect to
my<00:02:26.070><c> parameter</c><00:02:26.760><c> of</c><00:02:26.850><c> interest</c><00:02:26.940><c> of</c><00:02:27.420><c> the</c><00:02:28.320><c> log</c>

00:02:28.520 --> 00:02:28.530 align:start position:0%
my parameter of interest of the log
 

00:02:28.530 --> 00:02:31.490 align:start position:0%
my parameter of interest of the log
factors<00:02:29.100><c> so</c><00:02:29.820><c> over</c><00:02:30.420><c> all</c><00:02:30.450><c> the</c><00:02:30.720><c> factors</c><00:02:31.110><c> I'm</c>

00:02:31.490 --> 00:02:31.500 align:start position:0%
factors so over all the factors I'm
 

00:02:31.500 --> 00:02:35.060 align:start position:0%
factors so over all the factors I'm
taking<00:02:32.220><c> the</c><00:02:32.580><c> sum</c><00:02:33.420><c> of</c><00:02:33.690><c> the</c><00:02:34.350><c> partial</c><00:02:34.560><c> live</c><00:02:34.830><c> of</c>

00:02:35.060 --> 00:02:35.070 align:start position:0%
taking the sum of the partial live of
 

00:02:35.070 --> 00:02:37.160 align:start position:0%
taking the sum of the partial live of
the<00:02:35.100><c> each</c><00:02:35.580><c> log</c><00:02:35.940><c> factor</c><00:02:36.420><c> with</c><00:02:36.630><c> respect</c><00:02:36.960><c> to</c><00:02:37.020><c> my</c>

00:02:37.160 --> 00:02:37.170 align:start position:0%
the each log factor with respect to my
 

00:02:37.170 --> 00:02:39.920 align:start position:0%
the each log factor with respect to my
parameter<00:02:37.650><c> and</c><00:02:37.860><c> I'm</c><00:02:38.490><c> subtracting</c><00:02:39.030><c> to</c><00:02:39.690><c> that</c>

00:02:39.920 --> 00:02:39.930 align:start position:0%
parameter and I'm subtracting to that
 

00:02:39.930 --> 00:02:44.420 align:start position:0%
parameter and I'm subtracting to that
the<00:02:40.610><c> expectation</c><00:02:41.610><c> over</c><00:02:42.390><c> the</c><00:02:43.380><c> what</c><00:02:44.100><c> could</c><00:02:44.310><c> be</c>

00:02:44.420 --> 00:02:44.430 align:start position:0%
the expectation over the what could be
 

00:02:44.430 --> 00:02:47.990 align:start position:0%
the expectation over the what could be
the<00:02:44.550><c> true</c><00:02:44.580><c> label</c><00:02:45.150><c> why</c><00:02:45.360><c> I</c><00:02:46.400><c> did</c><00:02:47.400><c> this</c><00:02:47.640><c> is</c><00:02:47.700><c> the</c>

00:02:47.990 --> 00:02:48.000 align:start position:0%
the true label why I did this is the
 

00:02:48.000 --> 00:02:52.210 align:start position:0%
the true label why I did this is the
expectation<00:02:48.660><c> with</c><00:02:49.170><c> respect</c><00:02:49.620><c> to</c><00:02:49.790><c> the</c><00:02:50.790><c> model</c>

00:02:52.210 --> 00:02:52.220 align:start position:0%
expectation with respect to the model
 

00:02:52.220 --> 00:02:55.370 align:start position:0%
expectation with respect to the model
again<00:02:53.220><c> the</c><00:02:53.400><c> sum</c><00:02:53.730><c> of</c><00:02:53.970><c> the</c><00:02:54.660><c> partial</c><00:02:54.870><c> derivative</c>

00:02:55.370 --> 00:02:55.380 align:start position:0%
again the sum of the partial derivative
 

00:02:55.380 --> 00:02:57.830 align:start position:0%
again the sum of the partial derivative
of<00:02:55.530><c> the</c><00:02:56.100><c> log</c><00:02:56.310><c> factors</c><00:02:56.760><c> so</c><00:02:57.480><c> here</c><00:02:57.600><c> we</c><00:02:57.690><c> have</c><00:02:57.810><c> a</c>

00:02:57.830 --> 00:02:57.840 align:start position:0%
of the log factors so here we have a
 

00:02:57.840 --> 00:03:01.160 align:start position:0%
of the log factors so here we have a
difference<00:02:58.380><c> between</c><00:02:58.530><c> what</c><00:02:59.520><c> a</c><00:02:59.910><c> grain</c><00:03:00.750><c> of</c><00:03:00.780><c> what</c>

00:03:01.160 --> 00:03:01.170 align:start position:0%
difference between what a grain of what
 

00:03:01.170 --> 00:03:03.530 align:start position:0%
difference between what a grain of what
is<00:03:01.290><c> based</c><00:03:01.770><c> on</c><00:03:01.920><c> what</c><00:03:02.100><c> is</c><00:03:02.250><c> observed</c><00:03:02.430><c> minus</c><00:03:03.420><c> the</c>

00:03:03.530 --> 00:03:03.540 align:start position:0%
is based on what is observed minus the
 

00:03:03.540 --> 00:03:05.870 align:start position:0%
is based on what is observed minus the
gradient<00:03:03.750><c> based</c><00:03:04.080><c> on</c><00:03:04.380><c> what</c><00:03:04.710><c> the</c><00:03:05.520><c> modeled</c>

00:03:05.870 --> 00:03:05.880 align:start position:0%
gradient based on what the modeled
 

00:03:05.880 --> 00:03:08.570 align:start position:0%
gradient based on what the modeled
thinks<00:03:06.300><c> its</c><00:03:07.170><c> conditioned</c><00:03:07.620><c> on</c><00:03:07.830><c> the</c><00:03:07.890><c> input</c><00:03:08.370><c> but</c>

00:03:08.570 --> 00:03:08.580 align:start position:0%
thinks its conditioned on the input but
 

00:03:08.580 --> 00:03:10.760 align:start position:0%
thinks its conditioned on the input but
we're<00:03:08.850><c> doing</c><00:03:09.540><c> an</c><00:03:09.630><c> expectation</c><00:03:09.930><c> over</c><00:03:10.380><c> what</c><00:03:10.650><c> the</c>

00:03:10.760 --> 00:03:10.770 align:start position:0%
we're doing an expectation over what the
 

00:03:10.770 --> 00:03:14.240 align:start position:0%
we're doing an expectation over what the
model<00:03:11.040><c> thinks</c><00:03:11.370><c> is</c><00:03:11.520><c> most</c><00:03:12.090><c> likely</c><00:03:12.360><c> and</c><00:03:13.130><c> if</c><00:03:14.130><c> you</c>

00:03:14.240 --> 00:03:14.250 align:start position:0%
model thinks is most likely and if you
 

00:03:14.250 --> 00:03:15.650 align:start position:0%
model thinks is most likely and if you
think<00:03:14.460><c> about</c><00:03:14.640><c> this</c><00:03:14.760><c> expression</c><00:03:15.330><c> what</c><00:03:15.540><c> it's</c>

00:03:15.650 --> 00:03:15.660 align:start position:0%
think about this expression what it's
 

00:03:15.660 --> 00:03:17.690 align:start position:0%
think about this expression what it's
trying<00:03:15.870><c> to</c><00:03:15.990><c> do</c><00:03:16.260><c> is</c><00:03:16.500><c> that</c><00:03:16.740><c> it's</c><00:03:16.980><c> trying</c><00:03:17.250><c> to</c><00:03:17.490><c> make</c>

00:03:17.690 --> 00:03:17.700 align:start position:0%
trying to do is that it's trying to make
 

00:03:17.700 --> 00:03:21.320 align:start position:0%
trying to do is that it's trying to make
the<00:03:18.240><c> log</c><00:03:18.480><c> factor</c><00:03:18.990><c> larger</c><00:03:19.680><c> for</c><00:03:20.430><c> the</c><00:03:20.459><c> values</c><00:03:21.150><c> of</c>

00:03:21.320 --> 00:03:21.330 align:start position:0%
the log factor larger for the values of
 

00:03:21.330 --> 00:03:23.480 align:start position:0%
the log factor larger for the values of
Y<00:03:21.570><c> that</c><00:03:21.600><c> are</c><00:03:22.050><c> in</c><00:03:22.170><c> the</c><00:03:22.260><c> training</c><00:03:22.500><c> set</c><00:03:22.800><c> and</c><00:03:22.980><c> an</c>

00:03:23.480 --> 00:03:23.490 align:start position:0%
Y that are in the training set and an
 

00:03:23.490 --> 00:03:27.020 align:start position:0%
Y that are in the training set and an
expectation<00:03:23.850><c> is</c><00:03:24.270><c> trying</c><00:03:24.600><c> to</c><00:03:24.810><c> make</c><00:03:25.080><c> the</c><00:03:26.030><c> log</c>

00:03:27.020 --> 00:03:27.030 align:start position:0%
expectation is trying to make the log
 

00:03:27.030 --> 00:03:30.110 align:start position:0%
expectation is trying to make the log
factor<00:03:27.540><c> smaller</c><00:03:28.110><c> an</c><00:03:28.620><c> expectation</c><00:03:29.459><c> for</c>

00:03:30.110 --> 00:03:30.120 align:start position:0%
factor smaller an expectation for
 

00:03:30.120 --> 00:03:32.900 align:start position:0%
factor smaller an expectation for
essentially<00:03:30.959><c> every</c><00:03:31.380><c> value</c><00:03:31.740><c> of</c><00:03:31.890><c> y</c><00:03:32.070><c> based</c><00:03:32.610><c> on</c>

00:03:32.900 --> 00:03:32.910 align:start position:0%
essentially every value of y based on
 

00:03:32.910 --> 00:03:35.540 align:start position:0%
essentially every value of y based on
what<00:03:33.090><c> the</c><00:03:33.240><c> model</c><00:03:33.770><c> currently</c><00:03:34.770><c> thinks</c><00:03:35.280><c> the</c><00:03:35.400><c> way</c>

00:03:35.540 --> 00:03:35.550 align:start position:0%
what the model currently thinks the way
 

00:03:35.550 --> 00:03:37.970 align:start position:0%
what the model currently thinks the way
the<00:03:35.700><c> signs</c><00:03:35.940><c> probability</c><00:03:36.690><c> to</c><00:03:36.900><c> other</c><00:03:37.500><c> values</c><00:03:37.950><c> of</c>

00:03:37.970 --> 00:03:37.980 align:start position:0%
the signs probability to other values of
 

00:03:37.980 --> 00:03:40.699 align:start position:0%
the signs probability to other values of
Y<00:03:38.250><c> so</c><00:03:38.940><c> if</c><00:03:39.060><c> the</c><00:03:39.180><c> model</c><00:03:39.450><c> becomes</c><00:03:39.840><c> very</c><00:03:40.080><c> good</c><00:03:40.440><c> then</c>

00:03:40.699 --> 00:03:40.709 align:start position:0%
Y so if the model becomes very good then
 

00:03:40.709 --> 00:03:43.790 align:start position:0%
Y so if the model becomes very good then
P<00:03:41.010><c> of</c><00:03:41.190><c> Y</c><00:03:41.550><c> given</c><00:03:41.580><c> X</c><00:03:42.150><c> T</c><00:03:42.390><c> is</c><00:03:42.630><c> going</c><00:03:43.110><c> to</c><00:03:43.230><c> be</c><00:03:43.320><c> peaked</c>

00:03:43.790 --> 00:03:43.800 align:start position:0%
P of Y given X T is going to be peaked
 

00:03:43.800 --> 00:03:46.460 align:start position:0%
P of Y given X T is going to be peaked
you<00:03:44.790><c> can</c><00:03:44.910><c> assign</c><00:03:45.150><c> a</c><00:03:45.209><c> very</c><00:03:45.660><c> high</c><00:03:45.810><c> probability</c>

00:03:46.460 --> 00:03:46.470 align:start position:0%
you can assign a very high probability
 

00:03:46.470 --> 00:03:50.540 align:start position:0%
you can assign a very high probability
to<00:03:46.620><c> the</c><00:03:47.010><c> true</c><00:03:47.990><c> target</c><00:03:48.990><c> Y</c><00:03:49.260><c> T</c><00:03:49.320><c> and</c><00:03:49.860><c> then</c><00:03:50.190><c> 0</c><00:03:50.459><c> to</c>

00:03:50.540 --> 00:03:50.550 align:start position:0%
to the true target Y T and then 0 to
 

00:03:50.550 --> 00:03:52.460 align:start position:0%
to the true target Y T and then 0 to
everything<00:03:51.030><c> else</c><00:03:51.209><c> in</c><00:03:51.510><c> which</c><00:03:51.750><c> case</c><00:03:51.990><c> these</c><00:03:52.260><c> two</c>

00:03:52.460 --> 00:03:52.470 align:start position:0%
everything else in which case these two
 

00:03:52.470 --> 00:03:54.590 align:start position:0%
everything else in which case these two
terms<00:03:52.680><c> will</c><00:03:52.890><c> cancel</c><00:03:53.040><c> out</c><00:03:53.400><c> and</c><00:03:53.640><c> otherwise</c>

00:03:54.590 --> 00:03:54.600 align:start position:0%
terms will cancel out and otherwise
 

00:03:54.600 --> 00:03:57.830 align:start position:0%
terms will cancel out and otherwise
training<00:03:55.230><c> would</c><00:03:55.380><c> proceed</c><00:03:55.830><c> until</c><00:03:56.630><c> we</c><00:03:57.630><c> have</c>

00:03:57.830 --> 00:03:57.840 align:start position:0%
training would proceed until we have
 

00:03:57.840 --> 00:03:59.810 align:start position:0%
training would proceed until we have
converged<00:03:58.260><c> to</c><00:03:58.560><c> a</c><00:03:58.770><c> conditional</c><00:03:59.640><c> distribution</c>

00:03:59.810 --> 00:03:59.820 align:start position:0%
converged to a conditional distribution
 

00:03:59.820 --> 00:04:02.900 align:start position:0%
converged to a conditional distribution
that's<00:04:00.420><c> very</c><00:04:01.170><c> close</c><00:04:01.500><c> to</c><00:04:01.760><c> assigns</c>

00:04:02.900 --> 00:04:02.910 align:start position:0%
that's very close to assigns
 

00:04:02.910 --> 00:04:06.140 align:start position:0%
that's very close to assigns
essentially<00:04:03.810><c> perfect</c><00:04:04.140><c> probability</c><00:04:04.860><c> to</c><00:04:05.040><c> D</c><00:04:05.459><c> the</c>

00:04:06.140 --> 00:04:06.150 align:start position:0%
essentially perfect probability to D the
 

00:04:06.150 --> 00:04:10.460 align:start position:0%
essentially perfect probability to D the
true<00:04:06.330><c> answer</c><00:04:07.459><c> now</c><00:04:08.459><c> in</c><00:04:08.730><c> this</c><00:04:08.910><c> expression</c><00:04:09.470><c> the</c>

00:04:10.460 --> 00:04:10.470 align:start position:0%
true answer now in this expression the
 

00:04:10.470 --> 00:04:11.960 align:start position:0%
true answer now in this expression the
main<00:04:10.650><c> problem</c><00:04:11.070><c> is</c><00:04:11.250><c> computing</c><00:04:11.820><c> the</c>

00:04:11.960 --> 00:04:11.970 align:start position:0%
main problem is computing the
 

00:04:11.970 --> 00:04:14.630 align:start position:0%
main problem is computing the
expectation<00:04:12.680><c> over</c><00:04:13.680><c> Y</c><00:04:13.890><c> here</c><00:04:14.250><c> so</c><00:04:14.459><c> this</c>

00:04:14.630 --> 00:04:14.640 align:start position:0%
expectation over Y here so this
 

00:04:14.640 --> 00:04:17.000 align:start position:0%
expectation over Y here so this
expectation<00:04:15.020><c> here</c><00:04:16.020><c> of</c><00:04:16.200><c> this</c><00:04:16.440><c> whole</c>

00:04:17.000 --> 00:04:17.010 align:start position:0%
expectation here of this whole
 

00:04:17.010 --> 00:04:19.789 align:start position:0%
expectation here of this whole
expression<00:04:17.700><c> so</c><00:04:18.540><c> for</c><00:04:18.690><c> one</c><00:04:18.780><c> thing</c><00:04:18.989><c> and</c><00:04:19.169><c> it's</c><00:04:19.530><c> an</c>

00:04:19.789 --> 00:04:19.799 align:start position:0%
expression so for one thing and it's an
 

00:04:19.799 --> 00:04:23.090 align:start position:0%
expression so for one thing and it's an
expectation<00:04:20.070><c> over</c><00:04:20.549><c> all</c><00:04:20.989><c> values</c><00:04:21.989><c> for</c><00:04:22.229><c> all</c><00:04:22.440><c> the</c>

00:04:23.090 --> 00:04:23.100 align:start position:0%
expectation over all values for all the
 

00:04:23.100 --> 00:04:26.540 align:start position:0%
expectation over all values for all the
elements<00:04:23.700><c> in</c><00:04:23.820><c> the</c><00:04:23.850><c> Y</c><00:04:24.120><c> vector</c>

00:04:26.540 --> 00:04:26.550 align:start position:0%
 
 

00:04:26.550 --> 00:04:28.339 align:start position:0%
 
but<00:04:26.699><c> usually</c><00:04:27.419><c> since</c><00:04:27.629><c> each</c><00:04:27.900><c> of</c><00:04:28.080><c> the</c><00:04:28.169><c> log</c>

00:04:28.339 --> 00:04:28.349 align:start position:0%
but usually since each of the log
 

00:04:28.349 --> 00:04:31.010 align:start position:0%
but usually since each of the log
factors<00:04:28.740><c> will</c><00:04:28.919><c> only</c><00:04:29.550><c> involved</c><00:04:30.210><c> maybe</c><00:04:30.599><c> a</c><00:04:30.720><c> pair</c>

00:04:31.010 --> 00:04:31.020 align:start position:0%
factors will only involved maybe a pair
 

00:04:31.020 --> 00:04:33.050 align:start position:0%
factors will only involved maybe a pair
or<00:04:31.199><c> triplet</c><00:04:31.620><c> or</c><00:04:31.800><c> just</c><00:04:32.069><c> a</c><00:04:32.159><c> subset</c><00:04:32.580><c> of</c><00:04:32.610><c> the</c><00:04:32.849><c> Y's</c>

00:04:33.050 --> 00:04:33.060 align:start position:0%
or triplet or just a subset of the Y's
 

00:04:33.060 --> 00:04:35.510 align:start position:0%
or triplet or just a subset of the Y's
then<00:04:33.419><c> usually</c><00:04:33.990><c> this</c><00:04:34.110><c> expectation</c><00:04:34.530><c> reduces</c><00:04:35.340><c> to</c>

00:04:35.510 --> 00:04:35.520 align:start position:0%
then usually this expectation reduces to
 

00:04:35.520 --> 00:04:37.550 align:start position:0%
then usually this expectation reduces to
an<00:04:35.610><c> expectation</c><00:04:35.909><c> over</c><00:04:36.300><c> just</c><00:04:36.659><c> a</c><00:04:36.750><c> subset</c><00:04:37.169><c> of</c><00:04:37.319><c> the</c>

00:04:37.550 --> 00:04:37.560 align:start position:0%
an expectation over just a subset of the
 

00:04:37.560 --> 00:04:40.909 align:start position:0%
an expectation over just a subset of the
variables<00:04:38.000><c> so</c><00:04:39.000><c> you</c><00:04:39.780><c> know</c><00:04:39.990><c> use</c><00:04:40.199><c> for</c><00:04:40.740><c> instance</c>

00:04:40.909 --> 00:04:40.919 align:start position:0%
variables so you know use for instance
 

00:04:40.919 --> 00:04:42.469 align:start position:0%
variables so you know use for instance
in<00:04:41.159><c> the</c><00:04:41.280><c> linear</c><00:04:41.639><c> chain</c><00:04:41.849><c> conditional</c><00:04:42.389><c> random</c>

00:04:42.469 --> 00:04:42.479 align:start position:0%
in the linear chain conditional random
 

00:04:42.479 --> 00:04:44.029 align:start position:0%
in the linear chain conditional random
field<00:04:42.840><c> we</c><00:04:42.960><c> saw</c><00:04:43.110><c> that</c><00:04:43.259><c> essentially</c><00:04:43.919><c> these</c>

00:04:44.029 --> 00:04:44.039 align:start position:0%
field we saw that essentially these
 

00:04:44.039 --> 00:04:46.369 align:start position:0%
field we saw that essentially these
expectations<00:04:44.400><c> were</c><00:04:44.819><c> only</c><00:04:45.240><c> over</c><00:04:45.960><c> either</c><00:04:46.259><c> a</c>

00:04:46.369 --> 00:04:46.379 align:start position:0%
expectations were only over either a
 

00:04:46.379 --> 00:04:48.980 align:start position:0%
expectations were only over either a
single<00:04:46.860><c> Y</c><00:04:47.400><c> key</c><00:04:47.610><c> variable</c><00:04:48.030><c> or</c><00:04:48.270><c> pair</c><00:04:48.569><c> Y</c><00:04:48.810><c> key</c>

00:04:48.980 --> 00:04:48.990 align:start position:0%
single Y key variable or pair Y key
 

00:04:48.990 --> 00:04:50.930 align:start position:0%
single Y key variable or pair Y key
variable<00:04:49.409><c> so</c><00:04:49.560><c> often</c><00:04:49.919><c> it's</c><00:04:50.460><c> only</c><00:04:50.639><c> going</c><00:04:50.849><c> to</c>

00:04:50.930 --> 00:04:50.940 align:start position:0%
variable so often it's only going to
 

00:04:50.940 --> 00:04:53.980 align:start position:0%
variable so often it's only going to
involve<00:04:51.360><c> a</c><00:04:51.629><c> few</c><00:04:52.289><c> of</c><00:04:52.530><c> these</c><00:04:52.740><c> Y</c><00:04:52.979><c> key</c><00:04:53.190><c> variables</c>

00:04:53.980 --> 00:04:53.990 align:start position:0%
involve a few of these Y key variables
 

00:04:53.990 --> 00:04:57.260 align:start position:0%
involve a few of these Y key variables
that<00:04:54.990><c> being</c><00:04:55.289><c> said</c><00:04:55.849><c> computing</c><00:04:56.849><c> the</c>

00:04:57.260 --> 00:04:57.270 align:start position:0%
that being said computing the
 

00:04:57.270 --> 00:04:59.570 align:start position:0%
that being said computing the
conditional<00:04:58.199><c> distribution</c><00:04:58.319><c> over</c><00:04:59.250><c> these</c>

00:04:59.570 --> 00:04:59.580 align:start position:0%
conditional distribution over these
 

00:04:59.580 --> 00:05:03.740 align:start position:0%
conditional distribution over these
subsets<00:05:00.330><c> of</c><00:05:00.449><c> Y</c><00:05:00.960><c> variables</c><00:05:01.610><c> if</c><00:05:02.610><c> the</c><00:05:03.090><c> graph</c><00:05:03.539><c> is</c>

00:05:03.740 --> 00:05:03.750 align:start position:0%
subsets of Y variables if the graph is
 

00:05:03.750 --> 00:05:07.010 align:start position:0%
subsets of Y variables if the graph is
not<00:05:03.930><c> a</c><00:05:04.229><c> tree</c><00:05:04.800><c> or</c><00:05:05.159><c> a</c><00:05:05.190><c> chain</c><00:05:05.699><c> that's</c><00:05:06.690><c> still</c>

00:05:07.010 --> 00:05:07.020 align:start position:0%
not a tree or a chain that's still
 

00:05:07.020 --> 00:05:09.080 align:start position:0%
not a tree or a chain that's still
intractable<00:05:07.830><c> we</c><00:05:07.979><c> have</c><00:05:08.099><c> to</c><00:05:08.250><c> approximate</c><00:05:08.849><c> that</c>

00:05:09.080 --> 00:05:09.090 align:start position:0%
intractable we have to approximate that
 

00:05:09.090 --> 00:05:11.330 align:start position:0%
intractable we have to approximate that
conditional<00:05:09.780><c> distribution</c><00:05:09.960><c> and</c><00:05:10.590><c> what</c><00:05:11.129><c> we</c><00:05:11.219><c> can</c>

00:05:11.330 --> 00:05:11.340 align:start position:0%
conditional distribution and what we can
 

00:05:11.340 --> 00:05:14.149 align:start position:0%
conditional distribution and what we can
use<00:05:11.550><c> is</c><00:05:11.840><c> the</c><00:05:12.840><c> loopy</c><00:05:13.169><c> variant</c><00:05:13.590><c> of</c><00:05:13.740><c> belief</c>

00:05:14.149 --> 00:05:14.159 align:start position:0%
use is the loopy variant of belief
 

00:05:14.159 --> 00:05:16.730 align:start position:0%
use is the loopy variant of belief
propagation<00:05:15.080><c> to</c><00:05:16.080><c> approximate</c><00:05:16.620><c> that</c>

00:05:16.730 --> 00:05:16.740 align:start position:0%
propagation to approximate that
 

00:05:16.740 --> 00:05:20.990 align:start position:0%
propagation to approximate that
conditional<00:05:17.310><c> distribution</c><00:05:19.580><c> so</c><00:05:20.580><c> it's</c><00:05:20.729><c> just</c><00:05:20.849><c> a</c>

00:05:20.990 --> 00:05:21.000 align:start position:0%
conditional distribution so it's just a
 

00:05:21.000 --> 00:05:25.610 align:start position:0%
conditional distribution so it's just a
reminder<00:05:21.509><c> of</c><00:05:21.990><c> how</c><00:05:22.800><c> we</c><00:05:23.310><c> can</c><00:05:23.699><c> use</c><00:05:24.259><c> the</c><00:05:25.259><c> log</c>

00:05:25.610 --> 00:05:25.620 align:start position:0%
reminder of how we can use the log
 

00:05:25.620 --> 00:05:28.070 align:start position:0%
reminder of how we can use the log
messages<00:05:25.830><c> as</c><00:05:26.460><c> computed</c><00:05:27.449><c> by</c><00:05:27.599><c> belief</c>

00:05:28.070 --> 00:05:28.080 align:start position:0%
messages as computed by belief
 

00:05:28.080 --> 00:05:30.559 align:start position:0%
messages as computed by belief
propagation<00:05:28.199><c> so</c><00:05:28.979><c> we're</c><00:05:29.159><c> running</c><00:05:29.520><c> a</c><00:05:29.909><c> belief</c>

00:05:30.559 --> 00:05:30.569 align:start position:0%
propagation so we're running a belief
 

00:05:30.569 --> 00:05:33.439 align:start position:0%
propagation so we're running a belief
propagation<00:05:30.719><c> usually</c><00:05:31.710><c> in</c><00:05:31.800><c> log</c><00:05:32.009><c> space</c><00:05:32.310><c> we</c><00:05:33.029><c> run</c>

00:05:33.439 --> 00:05:33.449 align:start position:0%
propagation usually in log space we run
 

00:05:33.449 --> 00:05:35.600 align:start position:0%
propagation usually in log space we run
it<00:05:33.599><c> where</c><00:05:33.900><c> we</c><00:05:34.259><c> iterate</c><00:05:35.009><c> over</c><00:05:35.130><c> all</c><00:05:35.310><c> the</c>

00:05:35.600 --> 00:05:35.610 align:start position:0%
it where we iterate over all the
 

00:05:35.610 --> 00:05:37.610 align:start position:0%
it where we iterate over all the
messages<00:05:36.029><c> that</c><00:05:36.090><c> are</c><00:05:36.300><c> being</c><00:05:36.479><c> passed</c><00:05:36.960><c> between</c>

00:05:37.610 --> 00:05:37.620 align:start position:0%
messages that are being passed between
 

00:05:37.620 --> 00:05:41.230 align:start position:0%
messages that are being passed between
factors<00:05:38.460><c> and</c><00:05:38.759><c> variables</c><00:05:39.229><c> and</c><00:05:40.229><c> vice</c><00:05:40.440><c> versa</c><00:05:40.710><c> and</c>

00:05:41.230 --> 00:05:41.240 align:start position:0%
factors and variables and vice versa and
 

00:05:41.240 --> 00:05:44.059 align:start position:0%
factors and variables and vice versa and
we<00:05:42.240><c> go</c><00:05:42.539><c> over</c><00:05:42.690><c> these</c><00:05:43.020><c> messages</c><00:05:43.469><c> several</c><00:05:43.830><c> times</c>

00:05:44.059 --> 00:05:44.069 align:start position:0%
we go over these messages several times
 

00:05:44.069 --> 00:05:46.100 align:start position:0%
we go over these messages several times
until<00:05:44.340><c> the</c><00:05:44.880><c> value</c><00:05:45.060><c> of</c><00:05:45.240><c> the</c><00:05:45.330><c> messages</c><00:05:45.779><c> doesn't</c>

00:05:46.100 --> 00:05:46.110 align:start position:0%
until the value of the messages doesn't
 

00:05:46.110 --> 00:05:48.499 align:start position:0%
until the value of the messages doesn't
change<00:05:46.319><c> and</c><00:05:46.650><c> once</c><00:05:47.190><c> this</c><00:05:47.370><c> has</c><00:05:47.550><c> converged</c><00:05:47.940><c> then</c>

00:05:48.499 --> 00:05:48.509 align:start position:0%
change and once this has converged then
 

00:05:48.509 --> 00:05:50.269 align:start position:0%
change and once this has converged then
we<00:05:48.659><c> can</c><00:05:48.840><c> compute</c><00:05:49.199><c> for</c><00:05:49.469><c> instance</c><00:05:49.710><c> the</c><00:05:49.889><c> marginal</c>

00:05:50.269 --> 00:05:50.279 align:start position:0%
we can compute for instance the marginal
 

00:05:50.279 --> 00:05:53.809 align:start position:0%
we can compute for instance the marginal
probability<00:05:50.460><c> over</c><00:05:51.060><c> just</c><00:05:51.300><c> a</c><00:05:51.389><c> single</c><00:05:51.810><c> Y</c><00:05:52.490><c> given</c><00:05:53.490><c> X</c>

00:05:53.809 --> 00:05:53.819 align:start position:0%
probability over just a single Y given X
 

00:05:53.819 --> 00:05:56.119 align:start position:0%
probability over just a single Y given X
as<00:05:54.090><c> just</c><00:05:54.569><c> the</c><00:05:54.659><c> exponential</c><00:05:55.379><c> of</c><00:05:55.590><c> the</c><00:05:55.949><c> log</c>

00:05:56.119 --> 00:05:56.129 align:start position:0%
as just the exponential of the log
 

00:05:56.129 --> 00:05:59.899 align:start position:0%
as just the exponential of the log
factor<00:05:56.520><c> that</c><00:05:56.639><c> only</c><00:05:56.940><c> involves</c><00:05:57.629><c> YK</c><00:05:58.229><c> plus</c><00:05:59.219><c> the</c>

00:05:59.899 --> 00:05:59.909 align:start position:0%
factor that only involves YK plus the
 

00:05:59.909 --> 00:06:02.899 align:start position:0%
factor that only involves YK plus the
sum<00:06:00.210><c> for</c><00:06:00.449><c> all</c><00:06:00.479><c> the</c><00:06:00.870><c> other</c><00:06:00.990><c> factors</c><00:06:01.529><c> of</c><00:06:01.800><c> the</c><00:06:02.580><c> log</c>

00:06:02.899 --> 00:06:02.909 align:start position:0%
sum for all the other factors of the log
 

00:06:02.909 --> 00:06:06.740 align:start position:0%
sum for all the other factors of the log
messages<00:06:03.590><c> that</c><00:06:04.590><c> comes</c><00:06:04.889><c> from</c><00:06:05.159><c> them</c><00:06:05.599><c> so</c><00:06:06.599><c> this</c>

00:06:06.740 --> 00:06:06.750 align:start position:0%
messages that comes from them so this
 

00:06:06.750 --> 00:06:08.779 align:start position:0%
messages that comes from them so this
way<00:06:06.960><c> we</c><00:06:07.169><c> have</c><00:06:07.199><c> a</c><00:06:07.440><c> way</c><00:06:07.650><c> of</c><00:06:07.710><c> approximating</c><00:06:08.039><c> in</c>

00:06:08.779 --> 00:06:08.789 align:start position:0%
way we have a way of approximating in
 

00:06:08.789 --> 00:06:10.730 align:start position:0%
way we have a way of approximating in
this<00:06:09.180><c> case</c><00:06:09.360><c> the</c><00:06:09.509><c> marginal</c><00:06:09.930><c> distribution</c><00:06:10.110><c> but</c>

00:06:10.730 --> 00:06:10.740 align:start position:0%
this case the marginal distribution but
 

00:06:10.740 --> 00:06:12.740 align:start position:0%
this case the marginal distribution but
we<00:06:10.919><c> can</c><00:06:11.069><c> generalize</c><00:06:11.400><c> this</c><00:06:11.460><c> formula</c><00:06:12.060><c> to</c><00:06:12.300><c> any</c>

00:06:12.740 --> 00:06:12.750 align:start position:0%
we can generalize this formula to any
 

00:06:12.750 --> 00:06:16.430 align:start position:0%
we can generalize this formula to any
subset<00:06:13.469><c> of</c><00:06:13.590><c> Y</c><00:06:14.190><c> k's</c><00:06:14.750><c> so</c><00:06:15.750><c> I</c><00:06:15.810><c> won't</c><00:06:15.990><c> go</c><00:06:16.110><c> more</c><00:06:16.319><c> into</c>

00:06:16.430 --> 00:06:16.440 align:start position:0%
subset of Y k's so I won't go more into
 

00:06:16.440 --> 00:06:17.959 align:start position:0%
subset of Y k's so I won't go more into
the<00:06:16.560><c> details</c><00:06:17.400><c> of</c><00:06:17.610><c> this</c>

00:06:17.959 --> 00:06:17.969 align:start position:0%
the details of this
 

00:06:17.969 --> 00:06:19.730 align:start position:0%
the details of this
this<00:06:18.240><c> just</c><00:06:18.509><c> give</c><00:06:18.690><c> you</c><00:06:18.810><c> a</c><00:06:18.840><c> head</c><00:06:19.050><c> start</c><00:06:19.080><c> if</c><00:06:19.590><c> you</c>

00:06:19.730 --> 00:06:19.740 align:start position:0%
this just give you a head start if you
 

00:06:19.740 --> 00:06:21.290 align:start position:0%
this just give you a head start if you
want<00:06:19.979><c> to</c><00:06:20.069><c> go</c><00:06:20.159><c> look</c><00:06:20.370><c> at</c><00:06:20.490><c> the</c><00:06:20.580><c> literature</c><00:06:20.759><c> for</c>

00:06:21.290 --> 00:06:21.300 align:start position:0%
want to go look at the literature for
 

00:06:21.300 --> 00:06:24.309 align:start position:0%
want to go look at the literature for
how<00:06:21.629><c> to</c><00:06:21.690><c> perform</c><00:06:22.319><c> and</c><00:06:22.590><c> train</c><00:06:23.430><c> general</c>

00:06:24.309 --> 00:06:24.319 align:start position:0%
how to perform and train general
 

00:06:24.319 --> 00:06:26.779 align:start position:0%
how to perform and train general
conditional<00:06:25.319><c> random</c><00:06:25.409><c> field</c><00:06:25.860><c> models</c><00:06:26.490><c> using</c>

00:06:26.779 --> 00:06:26.789 align:start position:0%
conditional random field models using
 

00:06:26.789 --> 00:06:29.779 align:start position:0%
conditional random field models using
loopy<00:06:27.330><c> belief</c><00:06:27.629><c> propagation</c>

