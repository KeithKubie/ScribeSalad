WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.020
A few years ago I came across these commercially available E.E.G. headsets, NeuroSky, these

00:00:06.280 --> 00:00:09.880
As part of my company that I was running at the time

00:00:09.940 --> 00:00:14.120
We started experimenting with different games and different things to do with them

00:00:14.160 --> 00:00:16.680
but the main thing that we started doing is like

00:00:16.680 --> 00:00:19.120
taking edits, taking video edits

00:00:19.120 --> 00:00:24.100
and then dropping them into a program that would allow the view to cut basically.

00:00:24.280 --> 00:00:27.560
We're using like just stuff off the cutting room floor really.

00:00:27.780 --> 00:00:31.040
This was a different way of making a film as I usually do

00:00:31.040 --> 00:00:34.100
usually like you script it, and you storyboard it and go out and shoot it.

00:00:34.100 --> 00:00:38.780
This one was made specifically with the interactivity of the film in mind.

00:00:41.120 --> 00:00:44.460
We had to do like four different treatments from the script

00:00:45.120 --> 00:00:47.820
and then also in editing I usually

00:00:47.880 --> 00:00:48.380
you

00:00:48.500 --> 00:00:52.360
I take the viewer on and journey in the edit and you choose very

00:00:53.280 --> 00:00:55.620
succinctly, when, what they see when they see it

00:00:55.660 --> 00:01:01.260
And this, the creativity that you would put in the edit that gets passed off onto the viewer

00:01:01.260 --> 00:01:03.440
Interviewer:
How does it work from a technical point of view?

00:01:03.440 --> 00:01:05.060
This sits on your head

00:01:05.080 --> 00:01:11.760
electrical signals from your brain and also from your skin it gets filtered out and sent via Bluetooth

00:01:12.280 --> 00:01:14.640
We've got a Python program here.

00:01:14.640 --> 00:01:16.409
Interviewer:
So that's live Data now

00:01:16.409 --> 00:01:20.360
Yeah, it's just getting like fuzz at the minute

00:01:21.100 --> 00:01:22.360
(Quietly to self) Just stick this on.

00:01:23.200 --> 00:01:25.200
So, as a I put it on

00:01:25.360 --> 00:01:28.500
The signal quality should drop to zero and that means I've got a good

00:01:28.820 --> 00:01:31.240
connection with the data coming out

00:01:31.240 --> 00:01:33.240
so you can see in the background the film's playing

00:01:34.260 --> 00:01:36.600
as I blink it's cutting

00:01:37.380 --> 00:01:39.740
As you can see as I blend between two layers

00:01:39.780 --> 00:01:42.420
that's my attention going from high to low

00:01:42.420 --> 00:01:44.740
You see if I blink, you'll see this blink coming up.

00:01:44.800 --> 00:01:49.320
When I press play it fires off four videos at once, they're all playing in sync.

00:01:49.320 --> 00:01:53.200
And when I blink it chooses a set of two videos to play.

00:01:54.140 --> 00:02:00.100
When it's playing those two videos, the attention is changing the blending between those two videos.

00:02:00.100 --> 00:02:05.520
When I blink it will jump to the other two videos.

00:02:05.920 --> 00:02:06.920
Blending between those.

00:02:06.980 --> 00:02:11.800
At the same time meditation is controlling the mix of the music

00:02:12.000 --> 00:02:17.060
so the higher my meditation level the more levels of the music.

00:02:17.060 --> 00:02:21.720
So the data is coming from the headset via Bluetooth to the computer

00:02:21.720 --> 00:02:25.360
then our Python program is picking that data up

00:02:25.360 --> 00:02:29.640
send it via OSC (Open Sound Control)

00:02:30.540 --> 00:02:34.740
to MaxMSP, which is a program a lot of artists use code.

00:02:34.740 --> 00:02:36.480
It's a visual programming language

00:02:36.480 --> 00:02:38.100
It looks a lot like this

00:02:38.100 --> 00:02:41.940
So the data comes in here from the headset

00:02:41.940 --> 00:02:43.940
It's receiving the blink, the attention, the meditation

00:02:44.440 --> 00:02:48.320
It's coming down there to blink to cut between scenes.

00:02:48.320 --> 00:02:51.020
and then over here the the meditation has been

00:02:51.020 --> 00:02:54.840
scaled to the four audio levels, so we can see

00:02:57.260 --> 00:02:58.980
So my meditations about 50% here.

00:02:59.700 --> 00:03:01.220
That one's going up a bit.

00:03:01.230 --> 00:03:03.539
You just like add these patch cords together

00:03:03.610 --> 00:03:08.819
so there's there's my meditation point for it's between zero and one so I've got that number

00:03:08.819 --> 00:03:11.488
This bot- This number here, so you can see it's

00:03:12.280 --> 00:03:14.280
35 which is round about here?

00:03:14.500 --> 00:03:16.400
And it's going up, 66.

00:03:16.400 --> 00:03:19.300
Interviewer:
Do you find some people are more in control of their brains than others?

00:03:19.300 --> 00:03:24.500
Yeah totally and like I've had a few people who do a lot of meditation in the morning

00:03:24.500 --> 00:03:29.720
they are really able to control the meditation aspect of it, most people can't control that at all

00:03:32.260 --> 00:03:36.040
The biggest differences of people, [is] how people want to control the film

00:03:36.040 --> 00:03:37.799
some people want to experience a film

00:03:37.799 --> 00:03:39.799
some people want to control it

00:03:40.150 --> 00:03:42.130
and a few

00:03:42.130 --> 00:03:46.589
Group experiences where there was like one person who just wanted to see their feedback

00:03:46.589 --> 00:03:51.060
And they made this crazy film that just really hurt other people's heads

00:03:53.400 --> 00:03:58.860
so this was initially designed as a one-person experience

00:03:58.860 --> 00:04:02.160
initially we had a lot a little tent and you went in and just watched it by yourself

00:04:03.970 --> 00:04:10.229
when we took on tour we found that people would have a little bit.... (fades out)

