WEBVTT
Kind: captions
Language: en

00:00:03.910 --> 00:00:06.250
HENG-TZE CHENG:
So hey, everyone.

00:00:06.250 --> 00:00:07.770
Thanks for coming to the talk.

00:00:07.770 --> 00:00:08.610
My name is Heng-Tze.

00:00:08.610 --> 00:00:09.840
You can call me Heng.

00:00:09.840 --> 00:00:11.760
I work at Google Research.

00:00:11.760 --> 00:00:15.180
And today I'm very excited
to tell you all about Wide

00:00:15.180 --> 00:00:18.960
and Deep Learning and how you
can use it to combine the power

00:00:18.960 --> 00:00:24.150
of Memorization+Generalization
on TensorFlow.

00:00:24.150 --> 00:00:27.990
At Google, we started the Wide
and Deep project with a mission

00:00:27.990 --> 00:00:32.310
to combine the power of
memorization and generalization

00:00:32.310 --> 00:00:36.920
on one unified machine
learning platform for everyone.

00:00:36.920 --> 00:00:39.880
And when we say, everyone,
we really mean not

00:00:39.880 --> 00:00:42.190
just every product
team at Google,

00:00:42.190 --> 00:00:45.520
but also, everyone in the
open source community,

00:00:45.520 --> 00:00:49.320
everyone in academia,
as well as industry.

00:00:49.320 --> 00:00:52.170
So we started working
towards this mission

00:00:52.170 --> 00:00:56.730
by jointly training Wide Linear
Models on the left and Deep

00:00:56.730 --> 00:01:00.930
Neural Networks on the
right, and create an easy

00:01:00.930 --> 00:01:04.500
to use API, high-level API,
available in TensorFlow,

00:01:04.500 --> 00:01:07.860
so users can start with
simple linear models

00:01:07.860 --> 00:01:11.010
and gradually add
complexity without ever

00:01:11.010 --> 00:01:14.880
having to leave the platform.

00:01:14.880 --> 00:01:17.400
So the first question
is, what do we really

00:01:17.400 --> 00:01:20.640
mean by memorization
and generalization?

00:01:20.640 --> 00:01:21.870
And to answer that--

00:01:21.870 --> 00:01:23.820
before we dive into
machine learning,

00:01:23.820 --> 00:01:28.350
let's take a step back to think
about how we learn as humans.

00:01:28.350 --> 00:01:30.810
So as little kids we start
forming our knowledge

00:01:30.810 --> 00:01:33.450
by observing everyday events.

00:01:33.450 --> 00:01:39.300
For example, seagulls can
fly or pigeons can fly.

00:01:39.300 --> 00:01:43.230
We're very good at memorizing
these maybe unrelated

00:01:43.230 --> 00:01:46.560
boring facts very precisely.

00:01:46.560 --> 00:01:51.150
But, as you can imagine,
good memorization probably

00:01:51.150 --> 00:01:54.840
doesn't scale well
to over eight million

00:01:54.840 --> 00:01:56.700
animal species in the world.

00:01:56.700 --> 00:01:58.380
You're not going
to see all of them

00:01:58.380 --> 00:02:00.780
and not going to memorize
all of their names

00:02:00.780 --> 00:02:03.060
and whether they can fly or not.

00:02:03.060 --> 00:02:08.639
So a very powerful step in our
learning is generalization.

00:02:08.639 --> 00:02:12.280
By saying, animals
with wings can fly,

00:02:12.280 --> 00:02:17.730
we're basically summarizing all
of these sparse observations

00:02:17.730 --> 00:02:21.690
into one very compact
representation of knowledge,

00:02:21.690 --> 00:02:25.680
and that's whether the animal
has wings or not, right?

00:02:25.680 --> 00:02:30.120
Using these compact rules you
can generalize to many more

00:02:30.120 --> 00:02:33.690
animals you may or may
not have seen before.

00:02:33.690 --> 00:02:37.730
However, generalization
has its own limitations

00:02:37.730 --> 00:02:42.130
because it doesn't
always work on all cases.

00:02:42.130 --> 00:02:46.424
For example, penguins,
well, at least they try,

00:02:46.424 --> 00:02:48.590
but the best they can do
is some sort of a free fall

00:02:48.590 --> 00:02:50.360
into the ocean, right?

00:02:50.360 --> 00:02:56.120
So the real power
lies in how we combine

00:02:56.120 --> 00:02:59.600
the power of memorization
and generalization.

00:02:59.600 --> 00:03:04.750
And interestingly, this is
very similar to what we observe

00:03:04.750 --> 00:03:08.780
in the progression from a pure
wide model for memorization

00:03:08.780 --> 00:03:12.140
to a pure deep model,
which gives us more power

00:03:12.140 --> 00:03:18.050
in generalization, and finally,
in combining wide and deep,

00:03:18.050 --> 00:03:21.560
which is generalization
plus memorizing exceptions,

00:03:21.560 --> 00:03:24.590
which is saying, animals
with wings can fly,

00:03:24.590 --> 00:03:28.540
but penguins cannot fly.

00:03:28.540 --> 00:03:32.680
So enough with the
hypothetical animal examples.

00:03:32.680 --> 00:03:35.860
Now let's come back to
a real world example,

00:03:35.860 --> 00:03:37.600
and I'll walk you through it.

00:03:37.600 --> 00:03:39.640
In this running
example we'll see

00:03:39.640 --> 00:03:43.960
how we can apply wide, deep,
and wide and deep learning

00:03:43.960 --> 00:03:47.470
on the Google Play apps
recommendation problem.

00:03:47.470 --> 00:03:49.990
So suppose one of
our favorite users,

00:03:49.990 --> 00:03:52.900
Chris, recently installed
the Priceline app.

00:03:52.900 --> 00:03:56.110
The question we want to
ask is, which other apps

00:03:56.110 --> 00:03:59.160
should we now recommend, right?

00:03:59.160 --> 00:04:02.700
And one way to frame
this problem is--

00:04:02.700 --> 00:04:06.720
to frame the recommendation
problem as Retrieval+Ranking.

00:04:06.720 --> 00:04:09.900
So let's start from the
upper left, where I'll

00:04:09.900 --> 00:04:12.270
walk you through a live query.

00:04:12.270 --> 00:04:16.380
So we get a query from the users
in the recommendation system

00:04:16.380 --> 00:04:20.060
case as the user feature plus
some contextual features maybe

00:04:20.060 --> 00:04:22.510
at the time and so on.

00:04:22.510 --> 00:04:24.150
And then our
retrieval system will

00:04:24.150 --> 00:04:27.960
retrieve the relevant
items that relate

00:04:27.960 --> 00:04:29.640
to this user and context.

00:04:29.640 --> 00:04:33.300
And maybe, let's say, give us
hundreds of candidates, right?

00:04:33.300 --> 00:04:37.830
The ranking module will
rank these candidates

00:04:37.830 --> 00:04:42.120
and present the most promising
ones, the most relevant ones,

00:04:42.120 --> 00:04:43.490
to the user.

00:04:43.490 --> 00:04:47.010
The user takes a look at
the items on their phones.

00:04:47.010 --> 00:04:49.860
And they can take one
of the possible actions,

00:04:49.860 --> 00:04:54.300
like, click on the app,
install the app, and so on.

00:04:54.300 --> 00:04:59.750
All of these are recorded in the
logs, which the learner picks

00:04:59.750 --> 00:05:02.990
up, and trains a new model.

00:05:02.990 --> 00:05:07.430
And this new model will power
the next iteration of ranking.

00:05:07.430 --> 00:05:11.780
And that's a cycle of
recommendation, right.

00:05:11.780 --> 00:05:15.620
So this talk we will focus
on how we use Wide and Deep

00:05:15.620 --> 00:05:18.830
Learning to solve the
ranking model of this app

00:05:18.830 --> 00:05:21.140
recommendation problem.

00:05:21.140 --> 00:05:22.940
And the query
features, as I said,

00:05:22.940 --> 00:05:25.180
is user and contextual features.

00:05:25.180 --> 00:05:29.540
The item features are the
app impression features which

00:05:29.540 --> 00:05:31.430
we show to the users phones.

00:05:31.430 --> 00:05:35.270
And the objective we're
optimizing for is app installs.

00:05:35.270 --> 00:05:38.870
So if the user installed
the app the label is one,

00:05:38.870 --> 00:05:40.480
otherwise the label is zero.

00:05:40.480 --> 00:05:41.570
OK.

00:05:41.570 --> 00:05:43.490
So let's get started.

00:05:43.490 --> 00:05:46.940
Now the first probably the
simplest model you can pick

00:05:46.940 --> 00:05:51.160
is a Linear Model, or known
as logistic regression,

00:05:51.160 --> 00:05:52.040
in this case.

00:05:52.040 --> 00:05:55.130
So the inputs are a
bunch of features, right.

00:05:55.130 --> 00:05:59.390
You can have the user features
installed app as Priceline,

00:05:59.390 --> 00:06:01.880
and impression
features, which is

00:06:01.880 --> 00:06:04.340
if we show KAYAK as
impression, what's

00:06:04.340 --> 00:06:06.080
the likelihood of install?

00:06:06.080 --> 00:06:08.720
So the impression app,
let's say, is KAYAK.

00:06:08.720 --> 00:06:11.630
And we want to predict the
probability that the user will

00:06:11.630 --> 00:06:13.520
install the app.

00:06:13.520 --> 00:06:17.840
Now how do we generalize
memorization capability?

00:06:17.840 --> 00:06:22.350
This can be done by adding
a Crossed Feature, which

00:06:22.350 --> 00:06:27.620
is the end operation over
this binary base features.

00:06:27.620 --> 00:06:32.000
So the cross feature can be,
install app as Priceline,

00:06:32.000 --> 00:06:34.370
and impression app as KAYAK.

00:06:34.370 --> 00:06:37.910
If both are true, what is
the likelihood of install?

00:06:37.910 --> 00:06:39.380
And if we go into
the data and we

00:06:39.380 --> 00:06:42.340
see a lot of correlation,
people who installed this also

00:06:42.340 --> 00:06:46.130
installed that later, then you
can memorize this frequent co

00:06:46.130 --> 00:06:48.950
occurrence of these features.

00:06:48.950 --> 00:06:52.700
So crosses help you with that.

00:06:52.700 --> 00:06:56.660
Now you might think that, well,
that's very specific, right?

00:06:56.660 --> 00:07:00.490
How do we actually
generalize to other apps that

00:07:00.490 --> 00:07:02.630
are not Priceline or KAYAK?

00:07:02.630 --> 00:07:05.870
Well, one way you can do
it with Wide Linear Models

00:07:05.870 --> 00:07:10.700
is to add less specific
features, like app categories.

00:07:10.700 --> 00:07:15.020
So for example, if you add a
cross saying, if install app

00:07:15.020 --> 00:07:18.830
category is travel and the
impression app category

00:07:18.830 --> 00:07:22.190
is also travel, what is
the likelihood of user

00:07:22.190 --> 00:07:23.570
installing that, right?

00:07:23.570 --> 00:07:25.670
So once you learn
this, you can apply it

00:07:25.670 --> 00:07:30.270
to other travel apps not
just Priceline or KAYAK.

00:07:30.270 --> 00:07:34.200
Now the problem, which you
might have seen already,

00:07:34.200 --> 00:07:38.860
is that the feature space is
very wide and very sparse.

00:07:38.860 --> 00:07:40.530
There are millions
of apps, billions

00:07:40.530 --> 00:07:45.370
of users, if you cross
apps with apps that's

00:07:45.370 --> 00:07:48.670
a million times million which is
a trillion combinations, right?

00:07:48.670 --> 00:07:52.600
So most of these user
impression app pairs will never

00:07:52.600 --> 00:07:55.070
occur in your training data.

00:07:55.070 --> 00:07:58.480
So how do you actually
generalize to these unseen

00:07:58.480 --> 00:08:01.990
pairs without doing a lot of
manual feature engineering

00:08:01.990 --> 00:08:05.140
that we did in the
last slide, right?

00:08:05.140 --> 00:08:08.500
And remember, in many cases,
it might be hard for humans

00:08:08.500 --> 00:08:11.110
to come up with these
really good high level,

00:08:11.110 --> 00:08:15.330
less specific feature
crosses in the first place.

00:08:15.330 --> 00:08:19.640
So one way to solve this to
generalize more automatically

00:08:19.640 --> 00:08:25.190
is to use Deep Neural Network
with a dense embedding layer.

00:08:25.190 --> 00:08:28.250
So starting from the
bottom, you still

00:08:28.250 --> 00:08:31.850
have your base
binarized features,

00:08:31.850 --> 00:08:33.890
which is, user
install Priceline,

00:08:33.890 --> 00:08:36.960
and let's say, impression
app is Yelp now.

00:08:36.960 --> 00:08:38.929
And let's say,
you've never shown--

00:08:38.929 --> 00:08:41.659
you happen to never have
shown Yelp after people have

00:08:41.659 --> 00:08:45.090
installed Priceline,
so you cannot memorize.

00:08:45.090 --> 00:08:50.450
Now one way you can train this
is for each unique feature ID

00:08:50.450 --> 00:08:53.640
you look up dense
embedding vector

00:08:53.640 --> 00:08:56.340
and these are
initialized randomly

00:08:56.340 --> 00:08:59.790
so initially you will
make very poor predictions

00:08:59.790 --> 00:09:03.330
and you compare the error
between your prediction

00:09:03.330 --> 00:09:04.920
and the ground
truth label and you

00:09:04.920 --> 00:09:06.650
start adjusting your embedding.

00:09:06.650 --> 00:09:09.030
So you predict
better and better.

00:09:09.030 --> 00:09:12.720
So over time, the
embeddings will

00:09:12.720 --> 00:09:16.980
act more like automatically
extracted features, high level

00:09:16.980 --> 00:09:21.930
features, that very well
describe these base features.

00:09:21.930 --> 00:09:25.080
So combined with the
hidden layers on top of it,

00:09:25.080 --> 00:09:29.100
you can now automatically
learn complex interactions

00:09:29.100 --> 00:09:32.500
between e-space features.

00:09:32.500 --> 00:09:35.430
Now we've talked about
Wide and talked about Deep.

00:09:35.430 --> 00:09:39.460
So when is Wide better
than Deep and vice versa?

00:09:39.460 --> 00:09:42.480
So we can look into
the traffic patterns.

00:09:42.480 --> 00:09:44.730
So on the left using
the Wide Model,

00:09:44.730 --> 00:09:48.960
you're basically learning a
matrix to memorize which user

00:09:48.960 --> 00:09:53.460
install app and impression app
combinations correlates with

00:09:53.460 --> 00:09:56.480
install and which one doesn't.

00:09:56.480 --> 00:10:00.230
The problem is there are these
question marks which means

00:10:00.230 --> 00:10:04.010
there are no data to train on.

00:10:04.010 --> 00:10:08.660
So if you notice that
in the rows and columns

00:10:08.660 --> 00:10:11.660
there are a lot of repetitive
or similar structures

00:10:11.660 --> 00:10:12.750
you can leverage.

00:10:12.750 --> 00:10:15.230
So if you map all of
these apps onto a lower

00:10:15.230 --> 00:10:17.540
dimensional embedding
space, on the right,

00:10:17.540 --> 00:10:22.040
you might have that
similar apps that

00:10:22.040 --> 00:10:24.740
will be closer to each other
in the embedding space.

00:10:24.740 --> 00:10:27.500
So we can now generalize
your prediction

00:10:27.500 --> 00:10:30.800
to any app in the
embedding space, right?

00:10:30.800 --> 00:10:33.920
And in this hypothetical
example on the left,

00:10:33.920 --> 00:10:39.980
you would need 22 floats numbers
to memorize these interactions,

00:10:39.980 --> 00:10:42.110
whereas on the right,
you only need 20

00:10:42.110 --> 00:10:44.510
floats to store the embeddings.

00:10:44.510 --> 00:10:48.530
Being able to represent
the same or even richer

00:10:48.530 --> 00:10:53.120
information using less number
of parameters, meaning you

00:10:53.120 --> 00:10:56.840
are leveraging the structure
of the data better.

00:10:56.840 --> 00:10:58.850
Now, on the other
hand, there are

00:10:58.850 --> 00:11:05.090
a lot of specific user tastes,
niche apps, or just exceptions

00:11:05.090 --> 00:11:08.000
in the app training data.

00:11:08.000 --> 00:11:12.590
So for example, a Sheldon
Cooper Bazinka app probably

00:11:12.590 --> 00:11:15.110
wouldn't make sense to recommend
unless the user has seen

00:11:15.110 --> 00:11:17.270
the show, "Big Bang Theory."

00:11:17.270 --> 00:11:21.440
So there are all these
kind of niche combinations.

00:11:21.440 --> 00:11:26.780
And if we use a Wide Model
to memorize you can just

00:11:26.780 --> 00:11:30.500
use five ways to memorize
this diagonal matrix

00:11:30.500 --> 00:11:32.750
in this hypothetical
example, right?

00:11:32.750 --> 00:11:34.880
Whereas, if you
still try to learn

00:11:34.880 --> 00:11:37.880
a low dimensional
embedding, then you

00:11:37.880 --> 00:11:39.950
will still need 20 floats.

00:11:39.950 --> 00:11:41.750
And now the learner
will try very

00:11:41.750 --> 00:11:45.880
hard to push these irrelevant
apps away from each other,

00:11:45.880 --> 00:11:49.340
but find it very hard to do so
in a crowded low dimensional

00:11:49.340 --> 00:11:50.450
embedding space.

00:11:50.450 --> 00:11:54.860
And what will happen is you
will accidentally recommend

00:11:54.860 --> 00:11:57.600
less relevant apps to the user.

00:11:57.600 --> 00:12:02.600
And that's partly because if
you have a high rank sparse

00:12:02.600 --> 00:12:05.570
matrix like the diagonal
matrix on the left

00:12:05.570 --> 00:12:08.210
is, theoretically,
very hard or impossible

00:12:08.210 --> 00:12:10.700
to find these lower
dimensional embedding that

00:12:10.700 --> 00:12:13.170
will reconstruct the left.

00:12:13.170 --> 00:12:14.340
OK.

00:12:14.340 --> 00:12:17.870
So our idea is very simple.

00:12:17.870 --> 00:12:21.520
Why not just combine the
power of Wide and Deep, right?

00:12:21.520 --> 00:12:24.520
So we not only get the
combination of memorization

00:12:24.520 --> 00:12:28.480
and generalization, and in
many recommendation systems

00:12:28.480 --> 00:12:30.820
and search ranking
problems we often want

00:12:30.820 --> 00:12:34.480
to balance relevance
versus diversity,

00:12:34.480 --> 00:12:37.870
as well, so we satisfy
our users need.

00:12:37.870 --> 00:12:39.610
So that's what we did.

00:12:39.610 --> 00:12:45.160
We jointly train Wide Linear
Model and Deep Neural Network

00:12:45.160 --> 00:12:49.240
simultaneously by back
propagating to both sides

00:12:49.240 --> 00:12:51.220
at the same time in training.

00:12:51.220 --> 00:12:56.610
So we connect them to the same
last function and backdrop

00:12:56.610 --> 00:12:58.260
to both sides.

00:12:58.260 --> 00:13:01.780
Now you might notice
that this is somewhat

00:13:01.780 --> 00:13:05.950
similar to an Ensemble Model.

00:13:05.950 --> 00:13:09.100
But in the Ensemble Model
you would train two models

00:13:09.100 --> 00:13:11.490
separately without
knowing each other.

00:13:11.490 --> 00:13:14.590
And only at prediction
time you would combine

00:13:14.590 --> 00:13:16.060
their predictions, right?

00:13:16.060 --> 00:13:18.130
So we've been trying both.

00:13:18.130 --> 00:13:21.370
And what we've observe is
that doing a joint training,

00:13:21.370 --> 00:13:24.010
because they know each
other in the training time,

00:13:24.010 --> 00:13:27.130
the Wide Model only needs to
augment what the Deep Model

00:13:27.130 --> 00:13:30.860
cannot learn well,
and vice versa.

00:13:30.860 --> 00:13:34.270
So you often get a
much smaller model,

00:13:34.270 --> 00:13:37.740
whereas if you train
ensemble, both models

00:13:37.740 --> 00:13:41.670
need to be fairly large
and self-sufficient models

00:13:41.670 --> 00:13:45.620
so their ensemble will
make a good prediction.

00:13:45.620 --> 00:13:47.980
And we're definitely
actively working

00:13:47.980 --> 00:13:51.550
on comparing the
performance of both.

00:13:51.550 --> 00:13:56.890
And we're happy to here
what you find as well.

00:13:56.890 --> 00:14:01.380
So this is what
we got eventually

00:14:01.380 --> 00:14:04.290
that was launched into the
production of Google Play

00:14:04.290 --> 00:14:05.860
apps recommendation.

00:14:05.860 --> 00:14:11.850
So it's a three layer
neural networks on the left.

00:14:11.850 --> 00:14:14.250
And down below, you have
your continuous feature

00:14:14.250 --> 00:14:17.610
and categorical features
that feeds into the model.

00:14:17.610 --> 00:14:21.080
And this is augmented by a
cross product transformation,

00:14:21.080 --> 00:14:25.020
a cross between the user install
app and the impression app.

00:14:25.020 --> 00:14:28.110
And both are connected
to the logistic loss

00:14:28.110 --> 00:14:30.660
for joint training.

00:14:30.660 --> 00:14:34.950
And we published these results
in the paper, previously.

00:14:34.950 --> 00:14:38.070
We ran online experiments
on Google Play.

00:14:38.070 --> 00:14:43.110
And we've seen that the Wide and
Deep Model had a significant 4%

00:14:43.110 --> 00:14:48.660
gain on our Wide Model, which
is a very mature, highly

00:14:48.660 --> 00:14:52.320
optimized, previous generation
model that's been used.

00:14:52.320 --> 00:14:55.830
And we also compare it with the
Deep part of the Wide and Deep

00:14:55.830 --> 00:14:59.370
Model, and it has a
1% gain on top of it.

00:14:59.370 --> 00:15:03.500
And that's pretty
significant for Google Play.

00:15:03.500 --> 00:15:08.210
Now the good news is all
these you can do today

00:15:08.210 --> 00:15:13.040
in about 10 lines of code using
the high level estimator API,

00:15:13.040 --> 00:15:16.640
which Martin and others
have talked about.

00:15:16.640 --> 00:15:20.510
So all you have to do is, first,
define the features you want

00:15:20.510 --> 00:15:26.630
to use in your Wide Models, and
configure the crosses you think

00:15:26.630 --> 00:15:30.770
might be useful for memorizing
a lot of combinations.

00:15:30.770 --> 00:15:33.200
And the second part,
you define the features

00:15:33.200 --> 00:15:35.210
you want to use
in the Deep Model,

00:15:35.210 --> 00:15:38.000
and the embedding
configurations.

00:15:38.000 --> 00:15:40.070
And finally, define
your model structure,

00:15:40.070 --> 00:15:43.550
like, how many hidden layers,
how wide are the hidden layers.

00:15:43.550 --> 00:15:47.510
And boom, you can start
training right away.

00:15:47.510 --> 00:15:53.180
So I encourage you to go online
and search for Wide and Deep

00:15:53.180 --> 00:15:58.720
Learning to learn more
about Wide and Deep

00:15:58.720 --> 00:16:00.860
from the resources we provide.

00:16:00.860 --> 00:16:03.470
So we've open-sourced it.

00:16:03.470 --> 00:16:08.150
We have blog post, paper,
a YouTube video, and also

00:16:08.150 --> 00:16:11.150
TensorFlow tutorials to
walk you through these.

00:16:11.150 --> 00:16:14.900
And we found it useful for
general recommendations,

00:16:14.900 --> 00:16:17.270
search, and ranking
problems, especially

00:16:17.270 --> 00:16:20.780
if you have sparse categorical
inputs with a large number

00:16:20.780 --> 00:16:23.920
of unique feature values.

00:16:23.920 --> 00:16:27.710
We're excited to learn if you
find it useful in other use

00:16:27.710 --> 00:16:30.280
cases as well.

00:16:30.280 --> 00:16:33.930
And finally, I think
we all want to learn

00:16:33.930 --> 00:16:37.230
Wider and Deeper about machine
learning and maybe just

00:16:37.230 --> 00:16:38.980
everything else.

00:16:38.980 --> 00:16:43.300
But I think the true power
lies in the word, together.

00:16:43.300 --> 00:16:45.420
So in the Wide and
Deep project we

00:16:45.420 --> 00:16:49.560
brought two pretty different
modeling techniques together

00:16:49.560 --> 00:16:52.320
on one unified platform.

00:16:52.320 --> 00:16:55.600
And that benefited many
product teams at Google.

00:16:55.600 --> 00:17:00.180
And by open-sourcing and
sharing our findings,

00:17:00.180 --> 00:17:05.190
you and we are now able to
collaborate even if we're not

00:17:05.190 --> 00:17:06.660
in the same organization.

00:17:06.660 --> 00:17:10.890
And together, we can get
a deeper understanding

00:17:10.890 --> 00:17:14.130
of how to combine these
machine learning technologies

00:17:14.130 --> 00:17:16.800
with a community
that's wider than ever.

00:17:16.800 --> 00:17:20.119
And I think that's a
very powerful thing.

00:17:20.119 --> 00:17:22.180
So I'd like to thank
all the contributors

00:17:22.180 --> 00:17:23.920
to the Wide and Deep Project.

00:17:23.920 --> 00:17:27.970
And thank you very much for
listening to the talk today.

00:17:27.970 --> 00:17:29.760
Thank you.

