WEBVTT
Kind: captions
Language: en

00:00:00.780 --> 00:00:05.280
&gt;&gt; From the Library of
Congress in Washington DC.

00:00:17.150 --> 00:00:18.730
&gt;&gt; So let's begin.

00:00:18.730 --> 00:00:22.560 position:56%
Our opening keynote speaker just got
back from the Okavango River Basin,

00:00:22.560 --> 00:00:25.540
Africa's largest wetland, where
he and his team of scientists,

00:00:25.540 --> 00:00:28.310
filmmakers, and journalists
collected environmental data

00:00:28.310 --> 00:00:31.000
to document the river's ecosystem.

00:00:31.000 --> 00:00:33.590
This National Geographic
project is making all

00:00:33.590 --> 00:00:36.160
of the data open-source
for us to explore.

00:00:36.160 --> 00:00:39.490
Participating in this expedition
and almost getting eaten by a lion,

00:00:39.490 --> 00:00:42.380
I'm telling you, you should
really read the journal article,

00:00:42.380 --> 00:00:45.210
is one of many ways in which
Jer Thorp is using data

00:00:45.210 --> 00:00:46.620
to improve our world.

00:00:46.620 --> 00:00:49.910
His portfolio reflects the dynamic
ways in which data can be applied,

00:00:49.910 --> 00:00:54.380
from creating the algorithm for the
9/11 memorial that placed the names

00:00:54.380 --> 00:00:57.980
of the deceased closest to those
they knew, to developing a tool

00:00:57.980 --> 00:01:00.850
that constructs a detailed
picture of how information moves

00:01:00.850 --> 00:01:04.140
through social media, to leading
a theater group to interpret

00:01:04.140 --> 00:01:08.360
and perform 120,000 objects
in MoMA's collection.

00:01:08.360 --> 00:01:11.580
These projects demonstrate how Jer
is changing the public's perception

00:01:11.580 --> 00:01:13.920
of data from cold, remote,

00:01:13.920 --> 00:01:17.280
and sterile to interesting,
relevant, and vibrant.

00:01:17.280 --> 00:01:19.400
Even though many of us
haven't been able to trek

00:01:19.400 --> 00:01:21.090
through Sub-Saharan Africa,

00:01:21.090 --> 00:01:24.120
I believe that we have the same
mission as Jer in many ways,

00:01:24.120 --> 00:01:27.460
to make information in all of
its forms relevant to the public

00:01:27.460 --> 00:01:29.350
in the hopes that it
will improve our Earth,

00:01:29.350 --> 00:01:31.240
ourselves, and our future.

00:01:31.240 --> 00:01:35.120
Please welcome award-winning data
artist, cofounder of the Office

00:01:35.120 --> 00:01:39.520 position:56%
for Creative Research, 2013 National
Geographic Emerging Explorer,

00:01:39.520 --> 00:01:42.420
and adjunct professor at New
York University's Interactive

00:01:42.420 --> 00:01:46.510
Telecommunications
program, Jer Thorp.

00:01:46.510 --> 00:01:54.080
[ Applause ]

00:01:54.080 --> 00:01:55.380
&gt;&gt; Jer Thorp: Thank you.

00:01:55.380 --> 00:01:56.680
Good morning.

00:01:56.680 --> 00:01:58.660
I think it goes without saying

00:01:58.660 --> 00:02:01.690
that I feel tremendously
honored to be here today.

00:02:01.690 --> 00:02:12.320
I'm a Canadian and, nonetheless,
I'm really honored to be here.

00:02:15.540 --> 00:02:18.480
I came up with this entire
talk to give this morning,

00:02:18.480 --> 00:02:21.180 position:56%
I run a studio called The Office for
Creative Research and we do a lot

00:02:21.180 --> 00:02:24.780
of work surrounding collections,
and so I put together a talk

00:02:24.780 --> 00:02:27.540
which was specifically about
our work around collections,

00:02:27.540 --> 00:02:32.720
although as was just mentioned, we
do a lot of very different things.

00:02:32.720 --> 00:02:37.790
I was almost finished with the
talk when I read the program

00:02:37.790 --> 00:02:41.020
for the event when I found out that
the talk that I was actually going

00:02:41.020 --> 00:02:43.410
to give was called "Data
and Humans: A Love Story,"

00:02:43.410 --> 00:02:46.040
which is a title that
I didn't make up.

00:02:46.040 --> 00:02:50.820
And so, I thought, okay,
I'll do this talk instead,

00:02:50.820 --> 00:02:52.150
and what will this talk be?

00:02:52.150 --> 00:02:55.860
Well, obviously, this talk is
going to be about data and humans,

00:02:55.860 --> 00:02:58.180
and to start to talk
about data and humans,

00:02:58.180 --> 00:03:02.360
we must begin, I think, with data.

00:03:02.360 --> 00:03:05.630
There's an artifact of our
understanding of data which many

00:03:05.630 --> 00:03:08.100
of you have seen before
which is this pyramid,

00:03:08.100 --> 00:03:10.930
and it describes a kind
of progression from data

00:03:10.930 --> 00:03:14.270
at the bottom upwards
towards wisdom.

00:03:14.270 --> 00:03:17.850
And I think the shape of
that pyramid defines a lot

00:03:17.850 --> 00:03:21.160
of what we've been trying to
do with data over the last five

00:03:21.160 --> 00:03:23.740
to ten years, and that
is create as much --

00:03:23.740 --> 00:03:29.050
collect as much of it as possible
with the hope that, at scale,

00:03:29.050 --> 00:03:30.970
we can also get wisdom at scale.

00:03:30.970 --> 00:03:33.770
But what I'm going to
argue during this talk is

00:03:33.770 --> 00:03:36.110
that we're missing something
at the bottom of that pyramid,

00:03:36.110 --> 00:03:38.640
and I'm not going to
give it away yet.

00:03:38.640 --> 00:03:42.160
But I am going to start with a
little bit of wisdom from one

00:03:42.160 --> 00:03:44.230
of my favorite people,
Ursula Franklin,

00:03:44.230 --> 00:03:46.110
who actually just recently
passed away.

00:03:46.110 --> 00:03:51.570
She's a metallurgist
and a thinker and writer

00:03:51.570 --> 00:03:56.280
and in her Massey Lectures, she
talks about the idea that most

00:03:56.280 --> 00:03:59.830
of the world of technology that
we live in wasn't really made

00:03:59.830 --> 00:04:01.940
with our well-being in mind.

00:04:01.940 --> 00:04:05.320
And I think, as we are
constructing data systems

00:04:05.320 --> 00:04:07.920
and as we're constructing
a world of data to live in,

00:04:07.920 --> 00:04:11.150
this has never been more true.

00:04:11.150 --> 00:04:13.690
And so the central question that
I want to bring to us today is,

00:04:13.690 --> 00:04:15.840
what is it like to live in data?

00:04:15.840 --> 00:04:19.390 position:56%
Because, at one time, we might have
been satisfied with collecting data.

00:04:19.390 --> 00:04:22.520
At one point, we might have been
satisfied with visualizing it,

00:04:22.520 --> 00:04:26.160
but more and more and more,
we're actually creating systems

00:04:26.160 --> 00:04:29.890
and worlds that we must reside in.

00:04:29.890 --> 00:04:36.090
This is a diagram by a
sociologist named Jacob Moreno --

00:04:36.090 --> 00:04:38.370
made this in the beginning
of the 20th century

00:04:38.370 --> 00:04:43.070 position:56%
and it's called a sociogram, and you
can think of it as a social network.

00:04:43.070 --> 00:04:48.080
This diagram is of a seventh grade
classroom, girls on the right,

00:04:48.080 --> 00:04:54.290
boys on the left, two brave vectors
of puberty crossing that gulf.

00:04:54.290 --> 00:04:56.600
I like this diagram
though because I think

00:04:56.600 --> 00:04:57.960
about how it would have been made.

00:04:57.960 --> 00:05:00.160
The scientist or the
researcher would have had to sit

00:05:00.160 --> 00:05:02.520
in the classroom and they would
have had to watch the students.

00:05:02.520 --> 00:05:04.700
The students would
have to watch them.

00:05:04.700 --> 00:05:07.490
They would have had to
smell that teenage smell

00:05:07.490 --> 00:05:11.400
and learn people's names
and understand that,

00:05:11.400 --> 00:05:14.910
while these objects are being
drawn an circles and triangles,

00:05:14.910 --> 00:05:16.910
that they are in fact humans.

00:05:16.910 --> 00:05:18.690
How would we do something
like this today?

00:05:18.690 --> 00:05:21.750
Well, we might do it
like a university or,

00:05:21.750 --> 00:05:24.030
a research group rather, in
Cambridge, Massachusetts,

00:05:24.030 --> 00:05:26.930 position:56%
did where they used the Twitter API.

00:05:26.930 --> 00:05:31.220
They pulled 600,000 tweets from the
New York area, and they ran them

00:05:31.220 --> 00:05:32.940
through something called
sentiment analysis,

00:05:32.940 --> 00:05:38.400 position:56%
and sentiment analysis attempts to
decide which tweets are sad or angry

00:05:38.400 --> 00:05:40.970
or happy, so on, and so on.

00:05:40.970 --> 00:05:44.980
They found out that the
saddest place in New York City,

00:05:44.980 --> 00:05:48.160 position:56%
according to their study, was a high
school called Hunter College High

00:05:48.160 --> 00:05:51.210
School, which is up
above the reservoir.

00:05:51.210 --> 00:05:56.470
It shows up as a purple dot
above the reservoir in this map.

00:05:56.470 --> 00:05:59.200 position:56%
And I think a lot about what it
have been like to be those students.

00:05:59.200 --> 00:06:01.040
This was a September day,

00:06:01.040 --> 00:06:04.230
and the day before you were not
the saddest school in Manhattan,

00:06:04.230 --> 00:06:08.110
but the day of, you were the
saddest school in Manhattan.

00:06:08.110 --> 00:06:13.260
And I often think about what it
was like to be in high school,

00:06:13.260 --> 00:06:16.970
and I can only imagine how weird
of a day that must have been

00:06:16.970 --> 00:06:18.780
for these students
to arrive in class.

00:06:18.780 --> 00:06:21.910
I don't think the researchers
were thinking about that,

00:06:21.910 --> 00:06:25.130
because they didn't, I don't
think, understand these data points

00:06:25.130 --> 00:06:29.190
as humans, but instead
as returns from an API.

00:06:29.190 --> 00:06:34.070
And this story -- I
become obsessed with partly

00:06:34.070 --> 00:06:38.490
because they made a big mistake --

00:06:38.490 --> 00:06:42.780
their algorithm that they used
to locate the tweets was wrong,

00:06:42.780 --> 00:06:44.990
and so it wasn't actually
this high school,

00:06:44.990 --> 00:06:48.500
but it was somewhere else
nearby that they had determined

00:06:48.500 --> 00:06:50.660
to be the saddest point
in Manhattan.

00:06:50.660 --> 00:06:53.720
And I actually went and visited the
vice principal of this high school

00:06:53.720 --> 00:06:56.350
because I was so interested in
this and I asked her, I said,

00:06:56.350 --> 00:06:57.830
what was the mood in the students

00:06:57.830 --> 00:07:00.240
like that first day
that this was published?

00:07:00.240 --> 00:07:01.660
And then she said, nobody cared.

00:07:01.660 --> 00:07:02.960 position:56%
I was like, wow, that's interesting.

00:07:02.960 --> 00:07:05.200
Why did nobody care?

00:07:05.200 --> 00:07:07.070
And they said, well,
we knew it was wrong

00:07:07.070 --> 00:07:11.400
because high school
students don't use Twitter.

00:07:12.540 --> 00:07:15.130
We know that they're not
allowed to use social media.

00:07:15.130 --> 00:07:19.270 position:56%
We know they are using it, but
Twitter is for old people and nobody

00:07:19.270 --> 00:07:22.110
in our high school uses it,
which is kind of amazing, right?

00:07:22.110 --> 00:07:24.680
Like these guys had gone and
published the study based

00:07:24.680 --> 00:07:28.510
on a premise which was just
false from the beginning,

00:07:28.510 --> 00:07:32.730
and I think this example
highlights a lot of our problems.

00:07:32.730 --> 00:07:37.950
This amazing ability we have to
harvest and collect more data has

00:07:37.950 --> 00:07:40.740
to be balanced with the idea
that the mechanisms we use to do

00:07:40.740 --> 00:07:42.980
so are bringing us further
away from the people

00:07:42.980 --> 00:07:45.760
that we were engaged
with in the beginning.

00:07:45.760 --> 00:07:48.170
So what is like to live in data?

00:07:48.170 --> 00:07:52.880
It sucks. And I don't mean
that only in the pejorative,

00:07:52.880 --> 00:07:56.210
I also mean that it's like
a gigantic vacuum cleaner.

00:07:56.210 --> 00:07:59.490
We are the subject
of extraction, right?

00:07:59.490 --> 00:08:03.010
The word collection is in
the title of today's event,

00:08:03.010 --> 00:08:06.110 position:56%
and then word collection or the word
gathering are these kind of neat

00:08:06.110 --> 00:08:08.070
and polite ways to
describe something,

00:08:08.070 --> 00:08:12.040
which I think is a little
more violent, we're scraping

00:08:12.040 --> 00:08:16.380
and abstracting and mining
data from individuals.

00:08:16.380 --> 00:08:21.170 position:56%
A few years ago it -- actually in
2009, I became a little bit obsessed

00:08:21.170 --> 00:08:25.370
with these tweets that people would
write when they landed at airports,

00:08:25.370 --> 00:08:27.200
so they weren't allowed
to do it at the time,

00:08:27.200 --> 00:08:28.500
but people still what they would.

00:08:28.500 --> 00:08:30.350
They would tweet as soon as they
landed, and I just pulled a few

00:08:30.350 --> 00:08:33.440
from the feed this morning these.

00:08:33.440 --> 00:08:35.880
These are quotidian statements.

00:08:35.880 --> 00:08:38.000
There's nothing particularly
exciting here,

00:08:38.000 --> 00:08:41.190
although they are little
glimpses into somebody's life,

00:08:41.190 --> 00:08:44.330
but what they also are, are
data points, because I know

00:08:44.330 --> 00:08:46.140
where they've just landed,

00:08:46.140 --> 00:08:49.110
and I know from their
profile where they live.

00:08:49.110 --> 00:08:54.450
We could reconstruct a system from
just those tweets, which is a kind

00:08:54.450 --> 00:08:58.290
of simulation of air travel,
and this actually came

00:08:58.290 --> 00:09:01.680
out of a discussion with a friend
of mine who is an epidemiologist,

00:09:01.680 --> 00:09:03.750
and epidemiologists are
always looking for ways

00:09:03.750 --> 00:09:06.850 position:56%
to model human travel, and we
thought maybe could model them based

00:09:06.850 --> 00:09:09.900
on these weird, kind of
thinly veiled, show-off tweets

00:09:09.900 --> 00:09:14.820
that people were making as
they landed on the tarmac.

00:09:14.820 --> 00:09:16.900
This is the project of this
which I made a week later,

00:09:16.900 --> 00:09:18.200
it's called "Good Morning."

00:09:18.200 --> 00:09:22.160
This is everybody on Twitter
in 2009 saying good morning.

00:09:22.160 --> 00:09:26.140
And you can see the waves
travel around the world.

00:09:26.140 --> 00:09:28.220
Green dots are people
who get up early,

00:09:28.220 --> 00:09:29.910 position:56%
red dots are people who get up late.

00:09:29.910 --> 00:09:32.260
I'll let you see the East
Coast and the West Coast,

00:09:32.260 --> 00:09:36.420 position:56%
and you can make your decision as to
which one is lazier than the other.

00:09:36.420 --> 00:09:39.050
There's nothing exciting
happening here,

00:09:39.050 --> 00:09:42.290
but there was something really
captivating for me about being able

00:09:42.290 --> 00:09:45.890
to construct something from
nothing and to do it at scale.

00:09:45.890 --> 00:09:48.720
And I wasn't the only one, you
know, advertisers were very excited

00:09:48.720 --> 00:09:51.720
about this potential that we
could scrape up data from people

00:09:51.720 --> 00:09:53.710
and put it together into stories.

00:09:53.710 --> 00:09:58.030
In 2011, a couple of
researchers discovered

00:09:58.030 --> 00:10:01.010
that Apple was storing
all of your location data,

00:10:01.010 --> 00:10:03.130
and it was storing it
unsecurely on your device.

00:10:03.130 --> 00:10:07.860 position:56%
What that meant is that anybody who
knew where to look could find a file

00:10:07.860 --> 00:10:11.410 position:56%
that would say exactly where you
had been since you owned your phone.

00:10:11.410 --> 00:10:14.090
I don't really have to think
about that for very long

00:10:14.090 --> 00:10:17.350
to understand the privacy
concerns here.

00:10:17.350 --> 00:10:19.890
But a group of people
that I was working

00:10:19.890 --> 00:10:23.830
with at the New York Times lab at
the time, Matt Boggie, Jake Porway,

00:10:23.830 --> 00:10:27.310
Brian House, and I decided,
what an opportunity!

00:10:27.310 --> 00:10:28.610
There's all this data.

00:10:28.610 --> 00:10:32.130
Let's get as much of it as we can,
and so we started a project called

00:10:32.130 --> 00:10:35.310
"OpenPaths" and you can
still find it openpaths.cc,

00:10:35.310 --> 00:10:36.740
and the way that it works today is

00:10:36.740 --> 00:10:39.010
that you install an
app on your phone.

00:10:39.010 --> 00:10:43.300
That app collects data about your
location, but it stores it securely

00:10:43.300 --> 00:10:46.910
and only you have access to it.

00:10:46.910 --> 00:10:48.740
There's an additional thing
that you can do as well,

00:10:48.740 --> 00:10:50.860
which is that you can share
this data with researchers,

00:10:50.860 --> 00:10:53.630
for whom this kind of data
is kind of gold, right?

00:10:53.630 --> 00:10:56.850
Location data is really, really
exciting for epidemiologists

00:10:56.850 --> 00:11:00.520
to study disaster response for
urban planners, but almost all

00:11:00.520 --> 00:11:03.090
of this data is held by a
couple of private entities,

00:11:03.090 --> 00:11:05.160
and to get that data
is very difficult.

00:11:05.160 --> 00:11:07.500
So our idea was, can we
make a collective tool

00:11:07.500 --> 00:11:09.310
so that people could
visualize this data?

00:11:09.310 --> 00:11:11.530
They could understand what's
going on in their world,

00:11:11.530 --> 00:11:13.470
but they could also share
this with researchers.

00:11:13.470 --> 00:11:15.240
So this is what the
interface looks like.

00:11:15.240 --> 00:11:18.250
You can go and look at your date
and kind of see where you've been

00:11:18.250 --> 00:11:21.070
and the patterns of your
travel, and so on, and so on.

00:11:21.070 --> 00:11:23.010
It's pretty simple.

00:11:23.010 --> 00:11:25.300
But, for us, it was an
experiment in something,

00:11:25.300 --> 00:11:28.560
it was an experiment
in data ownership.

00:11:28.560 --> 00:11:32.210
What happens when we give
people ownership of their data?

00:11:32.210 --> 00:11:34.300
And, in this case, they
really do have ownership.

00:11:34.300 --> 00:11:37.430
If I wanted to look up your data
on OpenPaths, I run the server,

00:11:37.430 --> 00:11:39.660
I did for a while, I can't do it.

00:11:39.660 --> 00:11:41.010
It's encoded on our server.

00:11:41.010 --> 00:11:42.310
It's encrypted on our server.

00:11:42.310 --> 00:11:44.040
Only you can find it.

00:11:44.040 --> 00:11:46.010
An idea was that maybe this idea --

00:11:46.010 --> 00:11:48.360
this experience of data
ownership would foster a kind

00:11:48.360 --> 00:11:50.780
of personal relationship with data,

00:11:50.780 --> 00:11:53.350
which I think we're pretty far
away from right now, right?

00:11:53.350 --> 00:11:55.400
I think when I say this phrase
to people, they're like,

00:11:55.400 --> 00:11:56.720
what are you talking about?

00:11:56.720 --> 00:12:00.970
But there is a lot of personal
information in this data.

00:12:00.970 --> 00:12:02.750
This is a graphic by Brian House

00:12:02.750 --> 00:12:05.240
and it shows what he calls
his meaningful locations,

00:12:05.240 --> 00:12:09.440
and this is just derived from
the data, and the data knows

00:12:09.440 --> 00:12:12.430
where he lives, where his
girlfriend lived at the time,

00:12:12.430 --> 00:12:14.310
where he practiced with his band.

00:12:14.310 --> 00:12:17.890
These pieces of meaning
are encoded in this data,

00:12:17.890 --> 00:12:19.600
just by the nature of it.

00:12:19.600 --> 00:12:21.980
I did something a little
bit different with my data,

00:12:21.980 --> 00:12:24.920
these are little arrows
and they're the direction

00:12:24.920 --> 00:12:29.510
that I was traveling in, and this
reads like a clock on its so over

00:12:29.510 --> 00:12:32.530
on the left here is the
beginning of the day.

00:12:32.530 --> 00:12:33.830
That's me going to work.

00:12:33.830 --> 00:12:36.550
I go, at the time, I
went northwest to work.

00:12:36.550 --> 00:12:40.220
And then that's lunch up at the
top, and then down at the bottom,

00:12:40.220 --> 00:12:41.520
I just moved to New York.

00:12:41.520 --> 00:12:43.930
I never went home, so that's kind
of me going all over New York,

00:12:43.930 --> 00:12:47.090
and there might be some
stumbling bits there in the end

00:12:47.090 --> 00:12:49.100
in the very late evening.

00:12:49.100 --> 00:12:51.550
But the idea of this was,
could we make an artifact

00:12:51.550 --> 00:12:53.070
that people would put
up on their wall?

00:12:53.070 --> 00:12:55.190
I had this dream that someone
would put this up on their wall

00:12:55.190 --> 00:12:57.760
above their bed, and before
they went to bed at night,

00:12:57.760 --> 00:13:04.390
they would look up at it
and say, good night data.

00:13:04.390 --> 00:13:05.690
It's weird, right?

00:13:05.690 --> 00:13:08.560
And it's weird because this
is what this data looks like.

00:13:08.560 --> 00:13:14.160
This is one data point, another
data point, another data point.

00:13:14.160 --> 00:13:17.940
I moved to New York City from,
after living in Vancouver, Canada,

00:13:17.940 --> 00:13:21.060
for my whole life, and --
or for most of my life,

00:13:21.060 --> 00:13:25.910
and this is the moment I stepped
off the plane at LaGuardia Airport.

00:13:25.910 --> 00:13:30.780
It's kind of the beginning
of a new chapter in my life.

00:13:30.780 --> 00:13:35.800 position:56%
The second data point is, that night
I had this crisp glass of Riesling

00:13:35.800 --> 00:13:39.140
up at this Thai restaurant
on Amsterdam Avenue

00:13:39.140 --> 00:13:41.040
and I would have forgotten entirely

00:13:41.040 --> 00:13:44.240
about if it weren't
for this data point.

00:13:44.240 --> 00:13:50.290
And then this data point, five and
a half years ago, I opened the door

00:13:50.290 --> 00:13:52.400
at the end of my hallway
of my apartment building

00:13:52.400 --> 00:13:58.750
and met my partner Nora, who's
here, and instantly fell in love,

00:13:58.750 --> 00:14:02.580
and this point to me, I have this
idea that I'll sit my grandchild

00:14:02.580 --> 00:14:04.900
down on my lap and I'll
show them this data point.

00:14:04.900 --> 00:14:07.520
And I'll say, this
is how it started,

00:14:07.520 --> 00:14:09.390
and we made some progress there.

00:14:09.390 --> 00:14:12.620
This is my favorite data
point, our son who was born,

00:14:12.620 --> 00:14:14.620
oh, just over a year ago.

00:14:14.620 --> 00:14:18.410
And, I actually, when I saw
that, when I wrote this out,

00:14:18.410 --> 00:14:20.010
I remembered something
very interesting,

00:14:20.010 --> 00:14:21.830
which is that we are all
kind of born as data.

00:14:21.830 --> 00:14:24.910
This is what we share with
our family and friends,

00:14:24.910 --> 00:14:28.400
we share these numbers and these
statistics to prove something,

00:14:28.400 --> 00:14:30.370
to prove that this child was born.

00:14:30.370 --> 00:14:32.950
And similarly, these numbers,
they're evidence, they're evidence

00:14:32.950 --> 00:14:39.010
of our existence of our, of our,
of our, our time on the planet.

00:14:39.010 --> 00:14:41.900
But anyways, what is it
like to live in data?

00:14:41.900 --> 00:14:44.680
I think that there's this
sensation for most people

00:14:44.680 --> 00:14:47.850
that we're being used, and
we are being used, and again,

00:14:47.850 --> 00:14:50.340
primarily by advertisers.

00:14:50.340 --> 00:14:54.860
So most of the machinery around
data goes towards placing ads

00:14:54.860 --> 00:14:56.990
in your web browser,
you know, we might argue

00:14:56.990 --> 00:14:59.660
that maybe the machinery
behind the NSA

00:14:59.660 --> 00:15:02.780
and surveillance is slightly more
sophisticated, but probably not.

00:15:02.780 --> 00:15:07.140
Most of the effort is being done
to place ads in your web browser.

00:15:07.140 --> 00:15:09.810
I teach a class at
New York University,

00:15:09.810 --> 00:15:12.810
and one of my students had this
great project called "Cookie Jar."

00:15:12.810 --> 00:15:16.040
And she took collections
of people's advertisements

00:15:16.040 --> 00:15:18.700 position:56%
and then she sent them to
strangers and had them write stories

00:15:18.700 --> 00:15:21.430
about people, based only on their
ads, so it was kind of a way

00:15:21.430 --> 00:15:25.200
to reverse the -- advertisers are
trying to find things out about you

00:15:25.200 --> 00:15:28.080
and give you ads, and could we turn
that around and could we take ads

00:15:28.080 --> 00:15:30.490
and try to find something
out about ourselves?

00:15:30.490 --> 00:15:33.960
And, at the time, I was working
on a project which allowed me

00:15:33.960 --> 00:15:38.740 position:56%
to collect all of my ads, so this is
a month worth of web ads that I saw,

00:15:38.740 --> 00:15:41.300
and I sent this to ten strangers
and paid them ten dollars

00:15:41.300 --> 00:15:43.560
and asked them to write about me.

00:15:43.560 --> 00:15:47.770
And it was interesting [laughter].

00:15:53.610 --> 00:15:56.920
I learned some things about
myself, actually, you know,

00:15:56.920 --> 00:15:59.680
I learned nothing about myself,
but I learned some things

00:15:59.680 --> 00:16:03.600 position:56%
about what advertisers believe about
me, which is that I'm in my 30's,

00:16:03.600 --> 00:16:05.970
I live alone, and I
play video games.

00:16:05.970 --> 00:16:07.270
None of those things are true.

00:16:07.270 --> 00:16:12.210
This is my favorite
one, I love this one.

00:16:12.210 --> 00:16:15.040
I want to get it framed [laughter].

00:16:15.040 --> 00:16:16.720
But there's something
interesting happening here, right?

00:16:16.720 --> 00:16:19.040
Advertisers are collecting
data about us,

00:16:19.040 --> 00:16:20.810
a then they're building
these profiles,

00:16:20.810 --> 00:16:24.140
and they're making decisions based
on that data, and those decisions,

00:16:24.140 --> 00:16:26.190
more and more, are
affecting our lives.

00:16:26.190 --> 00:16:29.010
They might affect the level
to which we can be insured.

00:16:29.010 --> 00:16:32.220 position:56%
They might affect the type of health
insurance we're being presented.

00:16:32.220 --> 00:16:34.300
They might affect the
type of credit card

00:16:34.300 --> 00:16:36.180
that we're being offered, right?

00:16:36.180 --> 00:16:38.230
And so, this tool that we've built

00:16:38.230 --> 00:16:41.160
in my studio called Floodwatch
allows you to keep track

00:16:41.160 --> 00:16:43.620
of the types of ads that
are being shown to you,

00:16:43.620 --> 00:16:47.150
and like the last project I showed,
it allows you to donate this data

00:16:47.150 --> 00:16:50.380
to researchers, so researchers,
in particular, who are interested

00:16:50.380 --> 00:16:53.460
in discriminatory advertising
practices,

00:16:53.460 --> 00:16:57.090
so places in which advertisers
are discriminating based

00:16:57.090 --> 00:16:58.990
on the things you're not
allowed to discriminate

00:16:58.990 --> 00:17:03.190
on under the Constitution, race and
age and gender and religious belief

00:17:03.190 --> 00:17:04.850
and political affiliation.

00:17:04.850 --> 00:17:06.860
Those are all things that
we're trying to investigate

00:17:06.860 --> 00:17:09.830
and actually there's no real good
way to investigate them right now,

00:17:09.830 --> 00:17:12.070
and so we're building this tool.

00:17:12.070 --> 00:17:15.200
We're hoping to get tens
of thousands of users

00:17:15.200 --> 00:17:19.140 position:56%
so that they can collect the
largest database of advertising data

00:17:19.140 --> 00:17:22.910
and then just don't
give it to advertisers.

00:17:22.910 --> 00:17:26.160
So you can find out more about
the tool at floodwatch.ocr.nyc,

00:17:26.160 --> 00:17:30.540 position:56%
and we're releasing a new version
in the fall, so if you're interested

00:17:30.540 --> 00:17:31.840
in this, I would say hold off,

00:17:31.840 --> 00:17:35.110
because our next version's
going to be really amazing.

00:17:35.110 --> 00:17:39.430
What we've done, I
think, in the creation

00:17:39.430 --> 00:17:42.620 position:56%
of our data systems is not
dissimilar to what we started to do,

00:17:42.620 --> 00:17:44.800
or we continue to do,
with our cities.

00:17:44.800 --> 00:17:48.740
And Jane Jacobs, who of course,
the famous urbanism critic

00:17:48.740 --> 00:17:51.620
and an amazing writer and
thinker, talked about one

00:17:51.620 --> 00:17:54.370
of the biggest problems with
cities at the time and I think one

00:17:54.370 --> 00:17:57.540
of the continued problems in
cities, was the lack of feedback

00:17:57.540 --> 00:17:59.610
for the people who live in cities.

00:17:59.610 --> 00:18:02.620
And similarly, tools like
OpenPaths and Floodwatch are

00:18:02.620 --> 00:18:08.280
about giving people who live in
data mechanisms for feedback.

00:18:08.280 --> 00:18:11.650
What we want to do is be
able to give them agency,

00:18:11.650 --> 00:18:14.800
because I think one of the other
things that it's like to be living

00:18:14.800 --> 00:18:17.530
in data today is to
be without agency.

00:18:17.530 --> 00:18:20.860
So what does it mean
to give people agency?

00:18:20.860 --> 00:18:23.660
This is a project that my
studio has been working on.

00:18:23.660 --> 00:18:26.620
We've been working with a doctor
in Manchester named Will Dixon

00:18:26.620 --> 00:18:28.340
and Will is a rheumatologist.

00:18:28.340 --> 00:18:33.320 position:56%
He studies chronic pain, mostly, and
he had found from all of his work

00:18:33.320 --> 00:18:36.970
over the years with pain sufferers
this thing that we kind of know,

00:18:36.970 --> 00:18:41.590
which was that pain
symptoms can seem

00:18:41.590 --> 00:18:44.990
to be correlated with
the weather, right?

00:18:44.990 --> 00:18:48.140
And this is confusing,
we don't really know why.

00:18:48.140 --> 00:18:51.010
And in fact, we don't
really know if it exists.

00:18:51.010 --> 00:18:53.740
There had been no really good
scientific research about this.

00:18:53.740 --> 00:18:56.620
So we started this project called
"Cloudy with a chance of pain,"

00:18:56.620 --> 00:19:00.930
and we recruited, now almost
10,000 UK chronic pain sufferers,

00:19:00.930 --> 00:19:04.450
and we asked them to record
data around their pain symptoms.

00:19:04.450 --> 00:19:06.800
And then we built them a website
in which they can do a couple

00:19:06.800 --> 00:19:10.100 position:56%
of things, they can first come and
see how their pain symptoms compared

00:19:10.100 --> 00:19:12.360
to everybody else in the data set.

00:19:12.360 --> 00:19:14.700
So you can kind of explore
your own experiences

00:19:14.700 --> 00:19:17.580
and how they compare
to everybody else.

00:19:17.580 --> 00:19:22.150
We also set up a system
where we mailed people

00:19:22.150 --> 00:19:25.930
through email weekly visualizations
of what the project was doing,

00:19:25.930 --> 00:19:27.240
so that we made sure
that they were --

00:19:27.240 --> 00:19:29.600
felt like they were part of
this project and not just kind

00:19:29.600 --> 00:19:32.330
of throwing their data
into a black hole

00:19:32.330 --> 00:19:34.980 position:56%
where it might never come out again.

00:19:34.980 --> 00:19:37.650 position:56%
But the big thing, the biggest thing
that I think we did in this project

00:19:37.650 --> 00:19:41.180
which I'm the most proud of
is that we produced a tool

00:19:41.180 --> 00:19:45.070
which allowed the contributors
to the project

00:19:45.070 --> 00:19:47.090
to pose their own hypotheses.

00:19:47.090 --> 00:19:49.470
So we call this a citizen
science project,

00:19:49.470 --> 00:19:52.320
and you've probably heard a lot
about citizen science projects.

00:19:52.320 --> 00:19:54.650
I think that most citizen
science projects fall into one

00:19:54.650 --> 00:19:59.190
or two categories, they're
either citizen data collection

00:19:59.190 --> 00:20:04.040
or they're citizen labor that they
couldn't find a grad student to do.

00:20:04.040 --> 00:20:06.420
But not too many of them
are actual citizen science,

00:20:06.420 --> 00:20:09.010
like we're not asking citizens
to actually be scientists,

00:20:09.010 --> 00:20:12.490
so what we're doing here is we're
asking them to do exactly that,

00:20:12.490 --> 00:20:16.350
to look at their data and make
a hypotheses, make a hypothesis.

00:20:16.350 --> 00:20:18.020
And so, what we end
up with is we end

00:20:18.020 --> 00:20:20.720
up with not only 10,000 people
participating in the study,

00:20:20.720 --> 00:20:23.510
we end up with thousands of
hypotheses, which tell us a,

00:20:23.510 --> 00:20:26.880 position:56%
what people are thinking about
their symptoms and their conditions,

00:20:26.880 --> 00:20:29.160
but also, hey, this is
actually really good

00:20:29.160 --> 00:20:30.460
to look at those hypotheses.

00:20:30.460 --> 00:20:33.680
Maybe people are finding something
that we weren't able to find.

00:20:33.680 --> 00:20:36.700
And this idea of like putting
people in the driver's seat,

00:20:36.700 --> 00:20:40.030
giving them agency, is super,
super, super important to us

00:20:40.030 --> 00:20:41.690
and to the work that we do.

00:20:41.690 --> 00:20:44.600
What is it like to live in data?

00:20:44.600 --> 00:20:47.990
I believe that one of the primary
conditions of living in data is

00:20:47.990 --> 00:20:50.880
to be overwhelmed, to feel
like you're underwater.

00:20:50.880 --> 00:20:53.230
We can't really even look
at these data systems

00:20:53.230 --> 00:20:57.940
with our limited human
sensoriums because they're so big

00:20:57.940 --> 00:20:59.840
and so complicated, right?

00:20:59.840 --> 00:21:03.780
And there's this idea, I do
a lot of data visualization,

00:21:03.780 --> 00:21:07.590
and there's this idea that
visualization is a remedy to this,

00:21:07.590 --> 00:21:10.850
that visualization can
help us with complexity.

00:21:10.850 --> 00:21:13.010
Well, I would argue that, actually,

00:21:13.010 --> 00:21:15.240
visualization doesn't usually
help with what complexity.

00:21:15.240 --> 00:21:18.230
What it does is, it can get rid
of complexity, but getting rid

00:21:18.230 --> 00:21:21.050
of complexity is like
sweeping something very scary

00:21:21.050 --> 00:21:22.660
under a rug, right?

00:21:22.660 --> 00:21:25.460
We don't actually want to get rid
of it, we want to be able to engage

00:21:25.460 --> 00:21:27.280
with it in ways that
help us understand it.

00:21:27.280 --> 00:21:30.040
And this is something we've
always had to do as humans, right,

00:21:30.040 --> 00:21:32.690
we've always had to
engage with complex things.

00:21:32.690 --> 00:21:37.800 position:56%
And we've had to engage them in ways
that allow us to understand them.

00:21:37.800 --> 00:21:40.530
And sometimes complex things can
be the hardest because they might

00:21:40.530 --> 00:21:42.770
at the same time be right
and wrong or what they might

00:21:42.770 --> 00:21:45.680
at the same time be one
thing and the other.

00:21:45.680 --> 00:21:49.070
And so what have we developed
as humans over millions

00:21:49.070 --> 00:21:51.040
of years of evolution to do this?

00:21:51.040 --> 00:21:54.980
I believe that the mechanism
that we've developed is the arts.

00:21:54.980 --> 00:21:58.690 position:56%
And we do a lot of projects that try

00:21:58.690 --> 00:22:04.430
to counter this very appealing
approach to do visualizations.

00:22:04.430 --> 00:22:07.460
So for example, this is
a map, yeah, it's a map.

00:22:07.460 --> 00:22:09.800
This is all of the
hotels in the world.

00:22:09.800 --> 00:22:12.460
There's 500,000 hotels
in this data set.

00:22:12.460 --> 00:22:15.600
And each one of them shows
as a little white dot.

00:22:15.600 --> 00:22:20.460
If I wanted to explain to
people what hotels look

00:22:20.460 --> 00:22:23.060
like from space, this is useful.

00:22:23.060 --> 00:22:25.880
If I want to explain to people
what hotels are actually like,

00:22:25.880 --> 00:22:28.390
this is not useful at all.

00:22:28.390 --> 00:22:31.770
And so we were asked by
the Vancouver Art Gallery

00:22:31.770 --> 00:22:34.570
to develop a piece exactly
about this, to try to talk

00:22:34.570 --> 00:22:38.300
about the diversity and
richness and complexity

00:22:38.300 --> 00:22:41.510
of the system of 500,000 hotels.

00:22:41.510 --> 00:22:42.810
And so instead of turning

00:22:42.810 --> 00:22:44.990
to visualization, we
turned to narrative.

00:22:44.990 --> 00:22:48.450
This is that an image
that Jack Kerouac drew

00:22:48.450 --> 00:22:50.130
to help understand the journey

00:22:50.130 --> 00:22:54.670
that his characters were
going to take on the road.

00:22:54.670 --> 00:22:56.790
And so we thought, oh,
this is interesting.

00:22:56.790 --> 00:22:58.410
What if we did this?

00:22:58.410 --> 00:23:02.030
What if we took hundreds of
characters from fictional novels

00:23:02.030 --> 00:23:05.150
and dropped them into
today's world and told them

00:23:05.150 --> 00:23:08.070
that they would travel the
same route that they traveled

00:23:08.070 --> 00:23:13.410
in their books or in the novels,
and they had to stay at a hotel.

00:23:13.410 --> 00:23:17.180
So we dropped these people
into this imaginary world.

00:23:17.180 --> 00:23:21.110
It was projected in
real time continuously

00:23:21.110 --> 00:23:23.550
at the art gallery
for over three months.

00:23:23.550 --> 00:23:26.830
And during this three-month
period, these imaginary,

00:23:26.830 --> 00:23:28.130
these fictional characters,

00:23:28.130 --> 00:23:30.720
they lived within this
database of hotels.

00:23:30.720 --> 00:23:40.040
So here we're going to see the
-- I skipped the video here.

00:23:40.040 --> 00:23:41.570
These are the characters
from Lolita.

00:23:41.570 --> 00:23:44.970
They're driving along the Eastern
Seaboard, and they're about to stop

00:23:44.970 --> 00:23:46.470
at a hotel for the night.

00:23:46.470 --> 00:23:49.280
They don't have a lot of money,
so they're going to search

00:23:49.280 --> 00:23:51.400
for what's available
in their budget.

00:23:51.400 --> 00:23:54.290
In this particular day
when the piece was running,

00:23:54.290 --> 00:23:57.100
and as you can see from some of
the returns, they don't have a lot

00:23:57.100 --> 00:24:01.020
of luck in finding
a beautiful hotel.

00:24:01.020 --> 00:24:05.520 position:56%
And so we showed the viewer in the
projections is kind of a combination

00:24:05.520 --> 00:24:08.200
of photo documentation
from the hotel itself

00:24:08.200 --> 00:24:09.530
but also from the users.

00:24:09.530 --> 00:24:11.880
We show them the names
of the hotels.

00:24:11.880 --> 00:24:13.380
We look up the price.

00:24:13.380 --> 00:24:16.050
And one of the interesting things
about this it's a living system.

00:24:16.050 --> 00:24:18.820
So on one given night, they
might find these hotels.

00:24:18.820 --> 00:24:21.220
But the next one, there might be
a football game near that town,

00:24:21.220 --> 00:24:22.890
and there are no hotels available.

00:24:22.890 --> 00:24:27.390 position:56%
So they have to drive to the next
town and find a place to stay there.

00:24:27.390 --> 00:24:31.510
And this idea of using
narrative to frame our way

00:24:31.510 --> 00:24:33.640
through a complex data set
is something that we've done

00:24:33.640 --> 00:24:35.050
over and over and over again.

00:24:35.050 --> 00:24:38.280
Because I think it does give us a
chance to investigate these things

00:24:38.280 --> 00:24:41.280
that are otherwise really
difficult to investigate.

00:24:41.280 --> 00:24:43.750
I believe that if aliens
were to touch down today,

00:24:43.750 --> 00:24:45.410
and try to understand our culture,

00:24:45.410 --> 00:24:47.880
they would look towards these
gigantic data sets to try

00:24:47.880 --> 00:24:49.330
to understand what was going on.

00:24:49.330 --> 00:24:50.630
So how would they do that?

00:24:50.630 --> 00:24:52.560
Well, maybe they would do
it using a similar tactic

00:24:52.560 --> 00:24:53.860
to what we've done here.

00:24:53.860 --> 00:24:58.650
This is a data set which was
mentioned in the introduction.

00:24:58.650 --> 00:25:04.410
This is MoMA's permanent
collection, 127,000 objects.

00:25:04.410 --> 00:25:08.530
And we were approached by MoMA to
do an artist residency and to try

00:25:08.530 --> 00:25:12.080
to understand how we could make
an artwork about this data set

00:25:12.080 --> 00:25:13.380
that would help people
understand it.

00:25:13.380 --> 00:25:16.140
And that would help people
understand what is the character

00:25:16.140 --> 00:25:18.320
of this data set and what
are some of the possibilities

00:25:18.320 --> 00:25:20.440
that are entrenched within it.

00:25:20.440 --> 00:25:22.260
So what did we do?

00:25:22.260 --> 00:25:24.250
well, what do you do with a CSV?

00:25:24.250 --> 00:25:26.800
We load it into a database
and we start querying it,

00:25:26.800 --> 00:25:28.160
we start asking it questions.

00:25:28.160 --> 00:25:30.610
And so some of the first
things we did was to try

00:25:30.610 --> 00:25:31.910
to look for some pattern.

00:25:31.910 --> 00:25:35.450
And so I wrote a little this
is called a recursive query,

00:25:35.450 --> 00:25:38.550
which takes a title, and then it
looks for a title which is similar

00:25:38.550 --> 00:25:40.030
to it and a little bit longer.

00:25:40.030 --> 00:25:41.740
And then we do it again
and again and again.

00:25:41.740 --> 00:25:43.880
And we get these kind
of constructions,

00:25:43.880 --> 00:25:49.170
these poetic constructions,
of the titles of artworks.

00:25:49.170 --> 00:25:52.060
And I like these, first of
all, because they're evocative.

00:25:52.060 --> 00:25:53.360
They're fun to read.

00:25:53.360 --> 00:25:55.990
But second because they're this
kind of strange curatorial.

00:25:55.990 --> 00:25:57.440
We're mashing things together.

00:25:57.440 --> 00:26:01.020
I think of it as a kind of cocktail
party, where these artworks get

00:26:01.020 --> 00:26:02.440
to meet for the first time.

00:26:02.440 --> 00:26:05.740
So this one artwork is like,
oh, you're a trapeze girl,

00:26:05.740 --> 00:26:07.280
I'm another girl on another planet.

00:26:07.280 --> 00:26:11.130
And across the wall they're
like, I'm [inaudible].

00:26:11.130 --> 00:26:13.470
Like they have never
been able to meet.

00:26:13.470 --> 00:26:15.180
But through some commonalities
in the way

00:26:15.180 --> 00:26:17.100
that these titles are
structured, they're able to kind

00:26:17.100 --> 00:26:18.470
of meet and talk to each other.

00:26:18.470 --> 00:26:21.090
I meant to give this warning
at the beginning of the talk,

00:26:21.090 --> 00:26:24.330
and that is that there is some
obscene language in this talk,

00:26:24.330 --> 00:26:28.960
and it's coming up, not in
the slide but the next one.

00:26:28.960 --> 00:26:32.110
And so we were very
interested in these structures,

00:26:32.110 --> 00:26:34.520
particularly the ones around
girl, because there was this kind

00:26:34.520 --> 00:26:37.870
of entrenched record of kind
of the sexualization of art

00:26:37.870 --> 00:26:42.710
and this gendering of art
inside of these titles.

00:26:42.710 --> 00:26:47.260
Here's every obscene
title in MoMA's database.

00:26:47.260 --> 00:26:49.370
And you know, these are also
historically interesting.

00:26:49.370 --> 00:26:52.300
They came in a period where artists
for a long time had been trying

00:26:52.300 --> 00:26:54.580
to like challenge expectations
of galleries.

00:26:54.580 --> 00:26:57.030
They're like, here's a painting,
it's all just black, right.

00:26:57.030 --> 00:26:59.740
And originally curators
were like whoa,

00:26:59.740 --> 00:27:01.400
and now they were --
they accepted that.

00:27:01.400 --> 00:27:03.820
And then so the next step was like,
here's a painting, it's called --

00:27:03.820 --> 00:27:07.910
I'm not going to read it, but
it's called something like that.

00:27:07.910 --> 00:27:11.600
And then Mike Hansen who is one
of my collaborators, was sitting

00:27:11.600 --> 00:27:14.920 position:56%
and doing some database queries,
and he asked a very simple question.

00:27:14.920 --> 00:27:17.500
What is the most common
name, first name,

00:27:17.500 --> 00:27:19.910 position:56%
of an artist in the MoMA's database?

00:27:19.910 --> 00:27:21.390
The most common first name is John.

00:27:21.390 --> 00:27:24.360
There are 200 artists named
John who have a piece or more

00:27:24.360 --> 00:27:27.080
than one piece in the
MoMA collection.

00:27:27.080 --> 00:27:28.380
These are the top four.

00:27:28.380 --> 00:27:31.370
Here are the top 40.

00:27:31.370 --> 00:27:35.490
I'm giving you a second.

00:27:35.490 --> 00:27:41.360 position:56%
And so it was this piece that really
set the tone for what we were going

00:27:41.360 --> 00:27:42.960
to do because these are names.

00:27:42.960 --> 00:27:45.320
And what is the natural
human thing to do with names?

00:27:45.320 --> 00:27:48.490
That natural human thing to
do with names is to read them.

00:27:48.490 --> 00:27:49.790
And so we'd worked in the past

00:27:49.790 --> 00:27:53.130 position:56%
with this experimental theater group
called the elevator repair service.

00:27:53.130 --> 00:27:56.490
And we decided that we
would perform the database.

00:27:56.490 --> 00:28:00.030
And so for 40-minute
performances, we did eight of them.

00:28:00.030 --> 00:28:03.730
These actors would essentially
read the database in the gallery,

00:28:03.730 --> 00:28:05.840
but they would do it in a way
that was quite performative.

00:28:05.840 --> 00:28:07.180
So I'm going to play
you a section of this.

00:28:07.180 --> 00:28:08.970
Again, there's some
obscene language.

00:28:08.970 --> 00:28:12.160
And it's actually the
performing of this data set

00:28:12.160 --> 00:28:14.510 position:56%
that I'm just showing you right now.

00:28:14.510 --> 00:29:56.040
[ Video ]

00:29:56.040 --> 00:30:00.510 position:56%
So we show the names of every artist
in the database during this piece.

00:30:00.510 --> 00:32:01.610
[ Video ]

00:32:01.610 --> 00:32:05.990
And part of this was a response to
try to understand how can we act

00:32:05.990 --> 00:32:07.590
against people's expectations

00:32:07.590 --> 00:32:10.010
for what they're going
to receive from data.

00:32:10.010 --> 00:32:12.470
But really it was an
opportunity to present the data

00:32:12.470 --> 00:32:15.340
in what I thought was one of
the most engaging possible ways,

00:32:15.340 --> 00:32:17.400
to have it read and
to have it performed.

00:32:17.400 --> 00:32:19.910
And again, these mechanisms,
these things like performance,

00:32:19.910 --> 00:32:21.920
they're built for these
types of things,

00:32:21.920 --> 00:32:26.580
to be able to present complex
issues to people in ways

00:32:26.580 --> 00:32:31.190
that don't give them a prescribed
answer, but instead give them a set

00:32:31.190 --> 00:32:33.900
of questions that they
might leave with.

00:32:33.900 --> 00:32:36.580
This is Manchester, where we
did that Cloudy with a Chance

00:32:36.580 --> 00:32:38.650
of Pain project that
I mentioned before.

00:32:38.650 --> 00:32:43.260
And I want to show you one
other project which talks also

00:32:43.260 --> 00:32:45.700
about unusual ways to show data.

00:32:45.700 --> 00:32:49.140
We took some of the data from that
study, actually all the people

00:32:49.140 --> 00:32:53.860
from Manchester, and we constructed
a 60-foot long essentially bar

00:32:53.860 --> 00:32:59.780
graph, a histogram, that people
could walk under and see the data

00:32:59.780 --> 00:33:03.280
and help to sort of guess
whether it's correlated

00:33:03.280 --> 00:33:04.580
to certain weather conditions.

00:33:04.580 --> 00:33:07.990
And what I loved about this
is that, how often do you get

00:33:07.990 --> 00:33:10.980
to experience data as a
collective, like as a family,

00:33:10.980 --> 00:33:12.980
or as a class, or as a group?

00:33:12.980 --> 00:33:17.400
I think that our methods
for examining data typically

00:33:17.400 --> 00:33:18.700
through a computer or maybe

00:33:18.700 --> 00:33:20.710
through a phone are really
meant for one person.

00:33:20.710 --> 00:33:22.090
Whereas the problems
that we're dealing

00:33:22.090 --> 00:33:25.720
with that data is his
encoded in or data is involved

00:33:25.720 --> 00:33:29.310
in really do require us to deal
with those things as a group.

00:33:29.310 --> 00:33:33.120
And this also gave me a new
metric for a successful project,

00:33:33.120 --> 00:33:37.400 position:56%
which is that any successful project
we do involving data has to be able

00:33:37.400 --> 00:33:41.220
to fit an entire marching
band underneath it.

00:33:41.220 --> 00:33:44.080
You know, we use the word "public"
a lot when we talk about data.

00:33:44.080 --> 00:33:46.130
But I would argue that
most of our engagements

00:33:46.130 --> 00:33:48.350 position:56%
with data are inherently not public.

00:33:48.350 --> 00:33:50.870
I said this before,
but they're public

00:33:50.870 --> 00:33:53.010
in the way the White House
is public, and not public

00:33:53.010 --> 00:33:54.530
in the way the library's public.

00:33:54.530 --> 00:33:57.290
They're public in that
we're told it's for us,

00:33:57.290 --> 00:33:59.000
but we can't really go in.

00:33:59.000 --> 00:34:01.390
We don't have the tools
or the access to do so.

00:34:01.390 --> 00:34:05.720
And so how do we make public
data more like libraries?

00:34:05.720 --> 00:34:07.670
And I would argue that it is

00:34:07.670 --> 00:34:10.420
about understanding this
collective experience.

00:34:10.420 --> 00:34:12.300
Something very interesting
has happened to data

00:34:12.300 --> 00:34:14.250
over the last few years, which is

00:34:14.250 --> 00:34:16.570
that our public understanding
of it has changed.

00:34:16.570 --> 00:34:18.890
And when I give a data talk,
sometimes people come up to me

00:34:18.890 --> 00:34:24.950
and they say, did you know that
data is collective and is plural

00:34:24.950 --> 00:34:28.010
and that you should be
saying datum in the singular.

00:34:28.010 --> 00:34:29.740
And I'm like, I did
know that actually,

00:34:29.740 --> 00:34:33.730
but the average person
doesn't know that.

00:34:33.730 --> 00:34:36.470
We use it in a different
way in society these days.

00:34:36.470 --> 00:34:38.090
We use it as a mass noun.

00:34:38.090 --> 00:34:40.300
These are some other mass nouns.

00:34:40.300 --> 00:34:43.020
So the way that the
average person uses data,

00:34:43.020 --> 00:34:44.660
as something that is indivisible,

00:34:44.660 --> 00:34:48.110
which I think is very,
very, very interesting.

00:34:48.110 --> 00:34:53.820
I had the great opportunity to
work with the poet and photographer

00:34:53.820 --> 00:34:56.680
and author Teju Cole, and we
built this project called Time

00:34:56.680 --> 00:34:58.140
of the Game Together.

00:34:58.140 --> 00:35:01.010
And what Teju did is he
asked his Twitter followers

00:35:01.010 --> 00:35:03.340
when they were watching the
World Cup to take a photograph

00:35:03.340 --> 00:35:07.790
of their television and to post it
with the hashtag time of the game.

00:35:07.790 --> 00:35:11.330
And we pulled thousands and
thousands of these images

00:35:11.330 --> 00:35:12.660 position:56%
and we ran them through an algorithm

00:35:12.660 --> 00:35:14.810
which automatically
centered the television

00:35:14.810 --> 00:35:17.340
so they were exactly
on top of one another.

00:35:17.340 --> 00:35:20.390
To try to give this idea that there
was this collective experience

00:35:20.390 --> 00:35:22.440
happening at the same
time around the World Cup.

00:35:22.440 --> 00:35:25.960
And Teju, who is 900 times
more eloquent than I am,

00:35:25.960 --> 00:35:29.460
had these really nice things
to say about the concept.

00:35:29.460 --> 00:35:31.390
He said that the time of
the game becomes almost

00:35:31.390 --> 00:35:33.300
like a pilgrimage time,
like a public time

00:35:33.300 --> 00:35:35.740
which is the chronological
equivalent of public space.

00:35:35.740 --> 00:35:38.160 position:56%
And I love this idea of public time.

00:35:38.160 --> 00:35:41.440
I love this idea of these
mechanisms that can allow people

00:35:41.440 --> 00:35:44.540
to come together, not necessarily
in the same physical space,

00:35:44.540 --> 00:35:47.910
but at the same time,
to be able to engage

00:35:47.910 --> 00:35:50.200
with what was essentially
a very large data set.

00:35:50.200 --> 00:35:53.290
And the other thing that I love
from this quote is this idea

00:35:53.290 --> 00:35:56.370
of data having the ability
to allow ourselves to testify

00:35:56.370 --> 00:36:01.040
to each other's existence.

00:36:01.040 --> 00:36:03.730
At my studio, we've been
working on one last project --

00:36:03.730 --> 00:36:06.410
one very new project, and I'm
not going to show you much of it

00:36:06.410 --> 00:36:08.060
because there's not
much of it to exist.

00:36:08.060 --> 00:36:11.890
But what we're doing in St. Louis,
is we're building a community space

00:36:11.890 --> 00:36:15.430
in which people can come and create
very large scale maps together

00:36:15.430 --> 00:36:18.000
about their lived experience
in St. Louis.

00:36:18.000 --> 00:36:21.980
And then to use those maps as
instruments to explore civic data.

00:36:21.980 --> 00:36:23.880
So you may draw a map
of your neighborhood,

00:36:23.880 --> 00:36:27.160
and then we can project on top
of it demographic information,

00:36:27.160 --> 00:36:30.800
traffic information, access to
healthcare, so on and so on.

00:36:30.800 --> 00:36:32.850
And the idea here is like,
how do we balance maps

00:36:32.850 --> 00:36:34.610
like these ones, you know.

00:36:34.610 --> 00:36:38.830
This is a typical map
room, a kind of war room.

00:36:38.830 --> 00:36:42.180
With these ones, these
hand-drawn very beautiful maps.

00:36:42.180 --> 00:36:45.760
This is a map of somebody's paper
route when they were a child.

00:36:45.760 --> 00:36:50.140
How do we balance maps like
this, this is the census dot map

00:36:50.140 --> 00:36:53.020
of St. Louis which shows
the incredible racial divide

00:36:53.020 --> 00:36:54.720
that exists within St. Louis.

00:36:54.720 --> 00:36:59.710
How do we balance maps like this
one, a historic map of blighted,

00:36:59.710 --> 00:37:02.420
so-called blighted districts

00:37:02.420 --> 00:37:07.860
in St. Louis during the 1800s,
with maps like this one?

00:37:07.860 --> 00:37:11.830 position:56%
This is a hand-drawn map by an early
resident of St. Louis, Gene Taylor,

00:37:11.830 --> 00:37:15.460
who drew what the city
looked like in 1877.

00:37:15.460 --> 00:37:17.560
And here I think lies
the central conflict of,

00:37:17.560 --> 00:37:18.860
how do we deal with data.

00:37:18.860 --> 00:37:21.960
How do we present the objective
in line with the subjective?

00:37:21.960 --> 00:37:26.100
How do we present the kind of
clinical, cold clinical magnitude

00:37:26.100 --> 00:37:28.470 position:56%
of data, alongside with human story?

00:37:28.470 --> 00:37:30.620
And I don't think I
have an answer for you.

00:37:30.620 --> 00:37:33.490
But I was doing some
research around this project

00:37:33.490 --> 00:37:35.720
and I stumbled upon this
phrase called geosophy,

00:37:35.720 --> 00:37:39.940 position:56%
which is the opposite, maybe not the
opposite, but a pair to geography.

00:37:39.940 --> 00:37:44.160
Whereas geography is about what
the world "actually looks like,"

00:37:44.160 --> 00:37:46.100
Geosophy is the study of world

00:37:46.100 --> 00:37:48.620
as people conceive
of it and imagine it.

00:37:48.620 --> 00:37:51.800
And I love this idea that we
might move away from using data

00:37:51.800 --> 00:37:55.250
as this purely objective
thing and instead as a data

00:37:55.250 --> 00:37:59.260
to understand knowledge from
any or all points of view.

00:37:59.260 --> 00:38:02.440
JK Wright who came up
with this idea writes

00:38:02.440 --> 00:38:05.190
about how geosophy is really
this idea of geography

00:38:05.190 --> 00:38:07.230
but geography for everyone.

00:38:07.230 --> 00:38:10.530
And in tandem for this, I want us
to consider, what does data look

00:38:10.530 --> 00:38:13.060
like if data were for everyone?

00:38:13.060 --> 00:38:16.070
What is it like to live in data?

00:38:16.070 --> 00:38:18.770
It's to be used.

00:38:18.770 --> 00:38:20.900
It's to be without agency.

00:38:20.900 --> 00:38:24.560
It's to be overwhelmed
by complexity.

00:38:24.560 --> 00:38:25.960
What if we were to turn that around

00:38:25.960 --> 00:38:29.870
and leave this so-called big data
behind and instead enter an era

00:38:29.870 --> 00:38:34.070
of data humanism, where we
might first design data systems

00:38:34.070 --> 00:38:38.220
for the well-being of the
people, from whom it was taken.

00:38:38.220 --> 00:38:42.890
We might wherever possible
provide mechanisms for feedback.

00:38:42.890 --> 00:38:47.910
We might honor the complexity of
individual and community realities.

00:38:47.910 --> 00:38:51.210
We might create real and
functioning data public.

00:38:51.210 --> 00:38:53.130
You know, everybody in this room

00:38:53.130 --> 00:38:56.420
in case I think is a data
professional in some weird way.

00:38:56.420 --> 00:38:59.880
And I think it's up to
us to build these worlds.

00:38:59.880 --> 00:39:01.400
You know, I've been
thinking about this mostly

00:39:01.400 --> 00:39:05.220
because I have a 13-month-old son
who has to live in this new world

00:39:05.220 --> 00:39:08.080
of data that we are all
collectively creating.

00:39:08.080 --> 00:39:12.120 position:56%
And I hope that if we consider these
things, and we primarily do this,

00:39:12.120 --> 00:39:15.790
we put another layer of wisdom
at the bottom before we go

00:39:15.790 --> 00:39:18.420
about our endeavor
of collecting data,

00:39:18.420 --> 00:39:22.830
to make sure that these structures
that we build our livable.

00:39:22.830 --> 00:39:26.810
And if we do that, maybe
the answers are different.

00:39:26.810 --> 00:39:28.680
What is it like to live in data?

00:39:28.680 --> 00:39:30.990
To be empowered?

00:39:30.990 --> 00:39:33.180
To be engaged?

00:39:33.180 --> 00:39:34.910
To be equal?

00:39:34.910 --> 00:39:37.260
To be given new ways of seeing?

00:39:37.260 --> 00:39:40.550
To be given new ways of being?

00:39:40.550 --> 00:39:42.570
And maybe most importantly,
to be at home.

00:39:42.570 --> 00:39:44.510
Thank you.

00:39:44.510 --> 00:39:49.140
[ Applause ]

00:39:49.140 --> 00:39:53.000
&gt;&gt; This has been a presentation
of the Library of Congress.

00:39:53.000 --> 00:39:58.500
Visit us at LOC.com.

