WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
[Narrator] Let me explain how the second half works.

00:00:04.000 --> 00:00:06.000
Suppose an actual robot sits over here,

00:00:06.000 --> 00:00:10.000
and it measures these exact distances to the landmarks over here.

00:00:10.000 --> 00:00:13.000
Obviously, there some measurement noise that

00:00:13.000 --> 00:00:16.000
we just model as an added Gaussian with 0 mean.

00:00:16.000 --> 00:00:20.000
Meaning there would be a certain chance of being too short or too long

00:00:20.000 --> 00:00:23.000
and that probability is governed by a Gaussian.

00:00:23.000 --> 00:00:26.000
So, this process gives us a measurement vector of 4 values

00:00:26.000 --> 00:00:30.000
of those 4 distances to the landmarks L1 to L4.

00:00:30.000 --> 00:00:33.000
Now let's consider a particle that hypothesizes the robot coordinates

00:00:33.000 --> 00:00:39.000
are over here and not over here, and it also hypothesizes a different heading direction.

00:00:39.000 --> 00:00:44.000
We can then take the measurement vector and apply it to this particle.

00:00:44.000 --> 00:00:46.000
Obviously this would be a very poor measurement vector

00:00:46.000 --> 00:00:49.000
for this specific particle over here.

00:00:49.000 --> 00:00:54.000
In particular, the measurement vector we would've expected looks more like this.

00:00:54.000 --> 00:00:57.000
That just makes this specific location really unlikely.

00:00:57.000 --> 00:01:01.000
In fact, the closer our particle to the correct position

00:01:01.000 --> 00:01:06.000
the more likely will be the set of measurements given that position.

00:01:06.000 --> 00:01:09.000
And now here comes the big trick in particle filters:

00:01:09.000 --> 00:01:13.000
the mismatch of the actual measurement and the predicted measurement

00:01:13.000 --> 00:01:17.000
leads to a so called importance weight

00:01:17.000 --> 00:01:22.000
that tells us how important that specific particle is.

00:01:22.000 --> 00:01:25.000
The larger the weight the more important it is.

00:01:25.000 --> 00:01:29.000
Well, we now have many, many different particles and a specific measurement.

00:01:29.000 --> 00:01:32.000
Each of these particles will have a different weight.

00:01:32.000 --> 00:01:36.000
Some look very plausible, others might look very implausible

00:01:36.000 --> 00:01:39.000
as indicated by the size of the circles over here.

00:01:39.000 --> 00:01:43.000
We now let these particles survive somewhat at random,

00:01:43.000 --> 00:01:48.000
but the probability of survival will be proportional to their weights.

00:01:48.000 --> 00:01:51.000
If something has a very big weight like this guy over here

00:01:51.000 --> 00:01:53.000
will survive at a higher proportion than

00:01:53.000 --> 00:01:56.000
someone with a really small weight over here, which means

00:01:56.000 --> 00:01:59.000
after what's called resampling,

00:01:59.000 --> 00:02:04.000
which is just a technical term for randomly drawing N

00:02:04.000 --> 00:02:08.000
new particles from these old ones with replacement

00:02:08.000 --> 00:02:11.000
in proportion to the importance weight.

00:02:11.000 --> 00:02:13.000
After that resampling phase,

00:02:13.000 --> 00:02:17.000
those guys over here very likely to live on, in fact many, many times.

00:02:17.000 --> 00:02:20.000
Whereas those guys over here likely have died out.

00:02:20.000 --> 00:02:24.000
That's exactly what happened in our movie in the beginning

00:02:24.000 --> 00:02:27.000
when we looked at localization in this corridor environment.

00:02:27.000 --> 00:02:30.000
The particles that are very consistent with the sensor measurement

00:02:30.000 --> 00:02:34.000
survive with a higher probability, and the ones with lower importance weight

00:02:34.000 --> 00:02:36.000
tended to die out.

00:02:36.000 --> 00:02:39.000
So, we get the fact that the particles cluster

00:02:39.000 --> 00:02:42.000
around regions of higher posterior probability.

00:02:42.000 --> 00:02:45.000
That is really cool and all we have to do is

00:02:45.000 --> 00:02:48.000
we have to implement a method for setting importance weights

00:02:48.000 --> 00:02:51.000
and that is, of course, related to the likelihood of a measurement,

00:02:51.000 --> 00:02:54.000
as we will find out, and we have to implement a method for resampling

00:02:54.000 --> 00:02:58.000
that grabs particles in proportion to those weights.

00:02:58.000 --> 00:03:01.000
So, let's just do this.

00:03:01.000 --> 00:03:04.000
So, let me add back the robot code.

00:03:04.000 --> 00:03:07.000
We build a robot, and we make the robot move,

00:03:07.000 --> 00:03:13.000
and we now get a sensor measurement for that specific robot using the sense function.

00:03:13.000 --> 00:03:15.000
So, let's just print this out.

00:03:15.000 --> 00:03:20.000
These are the ranges or distances to the 4 landmarks

00:03:20.000 --> 00:03:23.000
and by adding a print myrobot statement

00:03:23.000 --> 00:03:27.000
you can also figure out where the robot is - it's at 33, 48, 0.5,

00:03:27.000 --> 00:03:30.000
obviously this is a random output

00:03:30.000 --> 00:03:34.000
because you randomly initialized the position of the robot.

00:03:34.000 --> 00:03:38.000
What I want you to program now is a way to assign importance weights

00:03:38.000 --> 00:03:40.000
to each of the particles in here.

00:03:40.000 --> 00:03:44.000
I want you to make a list of 1000 elements

00:03:44.000 --> 00:03:48.000
where each element on the list contains a number.

00:03:48.000 --> 00:03:54.000
So, this number is proportional to how important that particle is,

00:03:54.000 --> 00:04:00.000
and to make things easier I coded for you a function in the class robot

00:04:00.000 --> 00:04:02.000
called the measurement probability.

00:04:02.000 --> 00:04:06.000
This function accepts a single parameter, the measurement vector,

00:04:06.000 --> 00:04:11.000
the Z I just defined, and it calculates as an output

00:04:11.000 --> 00:04:16.000
how likely this measurement is, and it uses effectively a Gaussian

00:04:16.000 --> 00:04:19.000
that measures how far away the

00:04:19.000 --> 00:04:22.000
predicted measurements would be from the actual measurements.

00:04:22.000 --> 00:04:25.000
You can dive into this code and understand what's going on.

00:04:25.000 --> 00:04:28.000
There's one last change we have to do to make this code run.

00:04:28.000 --> 00:04:31.000
We have to actually assume that there is measurement noise.

00:04:31.000 --> 00:04:36.000
If there is 0 measurement noise, then this function will end up dividing by 0.

00:04:36.000 --> 00:04:41.000
So, let's put in a clause that specifies what we believe the actual measurement noise is.

00:04:41.000 --> 00:04:44.000
I'm going to do this not for the robot,

00:04:44.000 --> 00:04:46.000
but I do this for the particles.

00:04:46.000 --> 00:04:51.000
In this line of code over here where we create the particles for the first time,

00:04:51.000 --> 00:04:54.000
I don't just initialize these positions with random numbers,

00:04:54.000 --> 00:04:58.000
but also assume a certain amount of noise that goes with each particle,

00:04:58.000 --> 00:05:02.000
0.05 for the translational noise, 0.05 for the rotational noise,

00:05:02.000 --> 00:05:06.000
and 5.0 for the measurement noise in those ranges.

00:05:06.000 --> 00:05:09.000
So, this is the crucial number over here.

00:05:09.000 --> 00:05:11.000
So, coming back to what I want you to do,

00:05:11.000 --> 00:05:15.000
I wish you to construct a list of 1000 elements in W

00:05:15.000 --> 00:05:24.000
so that each number in this vector reflects the output of the

00:05:24.000 --> 00:05:27.000
function measurement_prob() applied to the measurement Z that we receive from

00:05:27.000 --> 00:05:33.000
the real robot, such that when I hit print W,

00:05:33.000 --> 00:05:36.898
I actually get a list of 1000 importance weights.

