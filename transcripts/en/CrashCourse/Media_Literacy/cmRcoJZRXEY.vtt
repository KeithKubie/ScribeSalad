WEBVTT
Kind: captions
Language: en

00:00:05.330 --> 00:00:07.250
Have you ever been window shopping?

00:00:07.250 --> 00:00:09.390
Just looking in the windows of stores...browsing?

00:00:09.390 --> 00:00:12.620
Did anything from the store ever just...follow
you around?

00:00:12.620 --> 00:00:16.380
You’re browsing for a new hat and see one
you like, but pass it by.

00:00:16.380 --> 00:00:20.730
Then in the video game store next door the
hat is just...sitting on the shelf?

00:00:20.730 --> 00:00:22.580
And in the clothing store after that.

00:00:22.580 --> 00:00:23.580
Looking at you.

00:00:23.580 --> 00:00:24.580
Following you.

00:00:24.580 --> 00:00:28.160
Last episode we talked about advertising,
and the long history of techniques for getting

00:00:28.160 --> 00:00:29.160
us to buy things.

00:00:29.160 --> 00:00:33.800
In today’s episode, we’re looking at what
happens when those techniques move online,

00:00:33.800 --> 00:00:36.100
where you might be followed much more than
you think.

00:00:36.100 --> 00:00:39.980
In the olden days, before online shopping,
stores didn’t know what you were looking at.

00:00:40.040 --> 00:00:43.620
They couldn’t track your shopping habits
and then place advertisements for stuff you

00:00:43.620 --> 00:00:45.110
like wherever your went.

00:00:45.110 --> 00:00:47.160
Hats were just hats; they couldn’t follow
you around.

00:00:47.160 --> 00:00:52.209
Traditional advertisements were contextual,
they were put in specific places – or contexts

00:00:52.209 --> 00:00:54.850
– where advertisers expected people to be.

00:00:54.850 --> 00:01:00.000
Commercials during must-see TV, billboards
along traffic-filled highways, pages in popular

00:01:00.000 --> 00:01:01.000
magazines.

00:01:01.000 --> 00:01:03.720
Places with lots of eyes and people with nothing
else to do.

00:01:03.720 --> 00:01:07.470
Advertisers had to jam all of the persuasive
techniques and logical fallacies they could

00:01:07.470 --> 00:01:10.600
into expensive ads, and then HOPE the right
people would see.

00:01:10.600 --> 00:01:12.410
But that was before the internet.

00:01:12.410 --> 00:01:13.410
And smartphones.

00:01:13.410 --> 00:01:15.150
And social media.

00:01:15.150 --> 00:01:19.210
And geolocation and cookies and pop-up ads
and ad blockers and…

00:01:19.210 --> 00:01:20.210
Yeah.

00:01:20.210 --> 00:01:22.020
It’s about to get scary.

00:01:22.020 --> 00:01:32.140
[Theme Music]

00:01:32.140 --> 00:01:36.340
Old-timey advertisers didn’t know who would
see their ads, and they also didn’t really

00:01:36.340 --> 00:01:37.870
know how well they were doing.

00:01:37.870 --> 00:01:41.780
Put up an ad for soda right by a high school,
and maybe they’d have a rough idea of who

00:01:41.780 --> 00:01:43.230
walked by it everyday.

00:01:43.230 --> 00:01:45.500
But they wouldn’t know how many kids actually
bought soda.

00:01:45.500 --> 00:01:49.229
It wasn’t a total guessing game, but it
wasn’t a science, either.

00:01:49.229 --> 00:01:54.420
Because of this, advertisers targeted different
groups of people, or demographics: teenagers,

00:01:54.420 --> 00:01:58.980
older men and women, business professionals,
families, white people, black people, Asian people.

00:01:58.980 --> 00:02:01.200
Still, these groups are pretty broad.

00:02:01.210 --> 00:02:05.450
You could place an ad with a TV show that
drew mostly female viewers or a radio program

00:02:05.450 --> 00:02:08.569
that had mostly teen listeners, but you couldn’t
get too specific.

00:02:08.569 --> 00:02:13.410
So, ads had to be broad, too, and the products
being sold were incentivized to be one-size

00:02:13.410 --> 00:02:14.640
fits all.

00:02:14.640 --> 00:02:19.220
Anything too niche for a wide audience couldn’t
afford to spend money on big, broad advertising.

00:02:19.220 --> 00:02:23.440
Since the birth of mass media, advertisers
have been looking for better ways to do this,

00:02:23.440 --> 00:02:26.120
to make sure their ads hit just the right
people.

00:02:26.120 --> 00:02:27.380
Enter: the internet.

00:02:27.380 --> 00:02:32.530
In the early days of the internet, the ad
world, was still just like print or TV advertising.

00:02:32.530 --> 00:02:35.200
Ads were created to reach as broad an audience
as possible.

00:02:35.200 --> 00:02:39.700
First came display ads – and like print
ads, they’d just sit there on your screen.

00:02:39.700 --> 00:02:45.950
And quickly advertisers tried to gussy these
up: pop-ups (the worst) and animated ads.

00:02:45.950 --> 00:02:46.960
Everything to get attention.

00:02:46.960 --> 00:02:49.840
But the real innovation was turning ads into
links.

00:02:49.840 --> 00:02:51.870
What happens when an Ad is a Link?

00:02:51.870 --> 00:02:52.870
It’s convenient.

00:02:52.870 --> 00:02:54.240
See an ad for a hat.

00:02:54.240 --> 00:02:55.240
Click.

00:02:55.240 --> 00:02:56.780
Bam – you’re at hatstore.com.

00:02:56.780 --> 00:03:02.560
But that also means hatstore.com can COUNT
how many times that link was clicked.

00:03:02.560 --> 00:03:06.030
Advertisers no longer had to estimate how
many eyes saw their ads or what they did in

00:03:06.030 --> 00:03:07.180
response.

00:03:07.180 --> 00:03:10.600
And for a while, the click-through was an
unstoppable measurement tool.

00:03:10.600 --> 00:03:14.580
This brings us to: the web cookie, which made
these ads even stronger.

00:03:14.580 --> 00:03:18.350
Cookies are like little breadcrumbs that websites
and apps place on your device.

00:03:18.350 --> 00:03:21.319
They follow you around the web and report
back on your habits.

00:03:21.319 --> 00:03:25.880
Suddenly advertisers could track who was clicking
on those ads and where they’d go next.

00:03:25.880 --> 00:03:27.150
Did they browse the site?

00:03:27.150 --> 00:03:28.520
Did they download a coupon?

00:03:28.520 --> 00:03:30.890
Did they – [gasp] – buy something??

00:03:30.890 --> 00:03:34.490
They could figure out who those viewers were,
their shopping habits, and even what their

00:03:34.490 --> 00:03:35.940
life was like.

00:03:35.940 --> 00:03:40.130
Pre-cookie, advertisers put their targets
– that’s you – in pretty broad demographic

00:03:40.130 --> 00:03:42.500
buckets, but now they could narrow that immensely.

00:03:42.500 --> 00:03:46.849
Ads can target just 18-24 year old women with
an interest in science who live in Brazil

00:03:46.849 --> 00:03:50.740
or 34-45 year old men who like soccer in Canada.

00:03:50.740 --> 00:03:55.030
This is called addressable advertising, sometimes
referred to as behavioral targeting.

00:03:55.030 --> 00:03:57.190
Take a look around this video.

00:03:57.190 --> 00:03:58.690
Are you seeing any ads?

00:03:58.690 --> 00:04:00.770
If so, are they things you’re interested
in?

00:04:00.770 --> 00:04:05.490
That might be because YouTube is using cookies
to display what it thinks you want to see.

00:04:05.490 --> 00:04:07.530
Your recommended videos work that way, too.

00:04:07.530 --> 00:04:11.489
Every time you use your phone or computer,
you’re leaving data breadcrumb trails.

00:04:11.489 --> 00:04:16.329
The websites you visit log your IP address
a unique set of numbers used to identify your

00:04:16.329 --> 00:04:17.919
computer as you browse the web.

00:04:17.919 --> 00:04:20.139
There are other kinds of unique identifiers,
too.

00:04:20.139 --> 00:04:24.330
They can track what kind of device you’re
using, where you are, how fast your internet

00:04:24.330 --> 00:04:25.740
is, who else you follow.

00:04:25.740 --> 00:04:26.740
All kinds of stuff.

00:04:26.740 --> 00:04:30.479
You may be thinking, “Isn’t getting better
music recommendations and seeing actually

00:04:30.479 --> 00:04:32.349
relevant ads worth a few cookie crumbs?”

00:04:32.349 --> 00:04:36.710
The problem is, the websites and apps you
do trust to use your data trails don’t keep

00:04:36.710 --> 00:04:37.710
it to themselves.

00:04:37.710 --> 00:04:39.669
Let’s take a deeper look at this in the
Thought Bubble.

00:04:39.669 --> 00:04:43.629
When you open up a new app or website, or
login to a social network, you’ll often

00:04:43.629 --> 00:04:46.409
come across some Terms and Conditions.

00:04:46.409 --> 00:04:47.669
Sometimes they’re called Terms of Service.

00:04:47.669 --> 00:04:49.120
These are the rules of the road.

00:04:49.120 --> 00:04:53.310
The company is telling you what you can and
can’t do in the app – like use it to commit

00:04:53.310 --> 00:04:55.349
a crime, or share stolen work.

00:04:55.349 --> 00:04:58.169
But they’re also telling you what they will
and won’t do.

00:04:58.169 --> 00:05:01.710
Most of the time when we create a new account
like this, we just check the box to accept

00:05:01.710 --> 00:05:03.529
the terms and conditions and move on.

00:05:03.529 --> 00:05:06.770
But companies know we don’t read those ridiculous
documents.

00:05:06.770 --> 00:05:12.009
Research even shows it would take us 25 days
each year to read all the things we agree

00:05:12.009 --> 00:05:13.009
to.

00:05:13.009 --> 00:05:16.319
So, more often than not, we’re actually
consenting to a lot of stuff we probably wouldn’t

00:05:16.319 --> 00:05:17.990
if we actually read the darn thing.

00:05:17.990 --> 00:05:19.279
For example: Instagram.

00:05:19.279 --> 00:05:22.539
You think you’re using an app to share photos
with friends and chat with them.

00:05:22.539 --> 00:05:24.210
The app’s Terms of Use say:

00:05:24.210 --> 00:05:28.669
You can’t post sexually explicit, violent,
hateful, or discriminatory things on Instagram.

00:05:28.669 --> 00:05:32.369
You can’t steal someone else’s login,
or use your account for illegal purposes.

00:05:32.369 --> 00:05:36.270
They have a right to kick you out if you break
the rules, like spamming or threatening others

00:05:36.270 --> 00:05:38.169
or stealing someone else’s photos.

00:05:38.169 --> 00:05:39.300
Ok, that makes sense.

00:05:39.300 --> 00:05:41.539
But their Terms of Use also say

00:05:41.539 --> 00:05:44.800
If they do want to kick you out, they can
do so without warning.

00:05:44.800 --> 00:05:49.479
And afterwards all of your photos and data
and comments will no longer be accessible

00:05:49.479 --> 00:05:50.500
through your account.

00:05:50.500 --> 00:05:54.800
Despite their Community guidelines, they say
they have no official obligation to take down

00:05:54.800 --> 00:05:55.830
any Instagram content.

00:05:55.830 --> 00:06:00.770
They don’t own your content, but you DO
grant them a “non-exclusive, fully paid

00:06:00.770 --> 00:06:05.819
and royalty-free, transferable, sub-licensable,
worldwide license” to use your content.

00:06:05.819 --> 00:06:10.069
In other words, they could use your photos
however they want, including selling them

00:06:10.069 --> 00:06:11.159
to third parties.

00:06:11.159 --> 00:06:14.880
Doing so would be a big breach of trust, so
they probably wouldn’t.

00:06:14.880 --> 00:06:15.880
But they could.

00:06:15.880 --> 00:06:20.280
They use analytics tools that collect information
sent by your device, including the web pages

00:06:20.280 --> 00:06:21.280
you visit.

00:06:21.280 --> 00:06:25.279
And they may use “device identifiers”
on your phone to track your browsing habits

00:06:25.279 --> 00:06:27.949
to serve you personalized content or ads.

00:06:27.949 --> 00:06:32.529
With Instagram or any app you use, with the
right clause hidden in all that legal jargon,

00:06:32.529 --> 00:06:36.210
your info can be sold to third parties, over
and over again.

00:06:36.210 --> 00:06:39.740
Then, advertisers can sell you more, better
targeted ads.

00:06:39.740 --> 00:06:43.639
So when you absent mindedly check the box
to accept god-knows-what terms and conditions,

00:06:43.639 --> 00:06:46.969
you’re often also signing away your right
to privacy.

00:06:46.969 --> 00:06:51.310
Right now, that info mainly goes to advertisers,
but you can see how our ambivalent attitude

00:06:51.310 --> 00:06:54.539
around privacy could make us vulnerable to
bad actors.

00:06:54.539 --> 00:06:59.240
Or, say foreign influence on things like...you
know...presidential elections.

00:06:59.240 --> 00:07:01.039
Thanks, Thought Bubble.

00:07:01.039 --> 00:07:04.289
Data tracking isn’t just used to serve you
personalized ads, either.

00:07:04.289 --> 00:07:07.349
It can actually determine what kind of content
you see elsewhere.

00:07:07.349 --> 00:07:11.869
When we browse Amazon or Netflix, they provide
us with suggestions based on stuff we’ve

00:07:11.869 --> 00:07:12.869
already seen.

00:07:12.869 --> 00:07:15.770
These recommendation engines, in a way, are
advertisements.

00:07:15.770 --> 00:07:20.899
It’s showing you one show or product over
another and, by extension, hiding others.

00:07:20.899 --> 00:07:24.119
The companies that use them certainly say
they’re just being helpful.

00:07:24.119 --> 00:07:28.849
But these can actually limit our options,
and keep us boxed into the things big corporations

00:07:28.849 --> 00:07:29.960
want us to see.

00:07:29.960 --> 00:07:32.439
There are many different kinds of these low-key
ads.

00:07:32.439 --> 00:07:34.710
But two really common ones are easy to overlook.

00:07:34.710 --> 00:07:37.129
The first is sponsored content.

00:07:37.129 --> 00:07:41.369
Sponsored content can mean anything from an
Instagram post to a documentary, that an advertiser

00:07:41.369 --> 00:07:43.050
paid to make and publish.

00:07:43.050 --> 00:07:47.819
It may not be obviously selling anything – like
an article about taking care of your car,

00:07:47.819 --> 00:07:51.159
but paid for by a car company with its logo
at the top.

00:07:51.159 --> 00:07:55.550
Or it’s that weird list of outlandish, tabloid-y
articles at the bottom of a more reputable

00:07:55.550 --> 00:07:59.240
site – like “you’ll never believe how
they died” with a picture of a celebrity

00:07:59.240 --> 00:08:00.240
who is definitely alive.

00:08:00.240 --> 00:08:04.649
These are particularly hard to pick out, because
publishers like your favorite magazines and

00:08:04.649 --> 00:08:09.249
websites, will place them alongside their
own original stuff, the editorial content,

00:08:09.249 --> 00:08:10.249
so they blend in.

00:08:10.249 --> 00:08:14.099
First: Learn to distinguish between ads and
non-commercial information.

00:08:14.099 --> 00:08:19.219
Look for phrases like “sponsored content”
“native content” “advertorial” or

00:08:19.219 --> 00:08:20.909
“presented by brand name here.”

00:08:20.909 --> 00:08:25.270
Celebrities and media creators may say they’re
“partnering” with a brand – that means

00:08:25.270 --> 00:08:27.400
they’ve getting money to promote that brand.

00:08:27.400 --> 00:08:31.610
Even when you Google, scope out the tiny green
“ad” in a listing that shows they paid

00:08:31.610 --> 00:08:33.339
to be at the top of the list.

00:08:33.339 --> 00:08:38.300
Second: if nothing else, remember this: when
something is free, you’re the product.

00:08:38.300 --> 00:08:41.830
If you’re sitting through ads to watch a
video, or scrolling past them on Instagram,

00:08:41.830 --> 00:08:46.400
that’s the price you pay to share photos
and make vlogs shipping Kate Winslet and Leonardo

00:08:46.400 --> 00:08:47.900
DiCaprio IRL.

00:08:47.900 --> 00:08:52.150
Check through all your online profiles and
see how much info you’re giving away.

00:08:52.150 --> 00:08:56.640
Head to the settings on your phone and turn
off geolocation features and microphone access

00:08:56.640 --> 00:08:58.080
wherever you can.

00:08:58.080 --> 00:09:02.450
And next time you create an account, think
twice about handing over any personal info.

00:09:02.450 --> 00:09:05.190
Create a dummy email address for that stuff
if you have to.

00:09:05.190 --> 00:09:07.660
Finally, know that nothing ever goes away
online.

00:09:07.660 --> 00:09:12.580
Sure, the internet may forget about your embarrassing
photos and Snaps may “disappear,” but

00:09:12.580 --> 00:09:14.390
when you’re online, you’re being tracked.

00:09:14.390 --> 00:09:16.270
It sounds scary because it is.

00:09:16.270 --> 00:09:21.800
The best way to navigate this hyper-targeted
media environment would be to, well, log off.

00:09:21.800 --> 00:09:22.800
Forever.

00:09:22.800 --> 00:09:25.110
But we know you’re not going to do that,
that’s why you’re here with us today.

00:09:25.110 --> 00:09:29.860
The next best thing is to be hyper vigilant
about what information you share online and

00:09:29.860 --> 00:09:31.700
minimize it whenever you can.

00:09:31.700 --> 00:09:35.780
Be wary of anything that seems free, because
chances are you’re paying for it with your

00:09:35.780 --> 00:09:37.750
attention and your life story.

00:09:37.750 --> 00:09:42.090
Right now, the biggest internet and tech companies
make the rules, and we all follow along because

00:09:42.090 --> 00:09:44.510
we don’t like to read long legal documents.

00:09:44.510 --> 00:09:49.490
But, with any new technology, there are organizations
and policies that try to reign in the power

00:09:49.490 --> 00:09:52.300
of big players like Facebook and Google.

00:09:52.300 --> 00:09:54.390
Sometimes they’re successful, and sometimes...not
so much.

00:09:54.390 --> 00:09:58.560
We’re going to learn all about that next
time on Crash Course Media Literacy.

00:09:58.560 --> 00:10:00.290
Until then, I’m Jay Smooth.

00:10:00.290 --> 00:10:01.290
See ya!

00:10:01.290 --> 00:10:04.680
Crash Course Media Literacy is filmed in the
Dr. Cheryl C. Kinney Studio in Missoula, MT.

00:10:04.680 --> 00:10:08.150
It’s made with the help of all of these
nice people, and our animation team is Thought

00:10:08.150 --> 00:10:09.150
Cafe.

00:10:09.150 --> 00:10:10.210
Crash Course is a Complexly production.

00:10:10.210 --> 00:10:14.210
If you wanna keep imagining the world complexly
with us check out some of our other channels,

00:10:14.210 --> 00:10:16.690
like Sexplanations, How To Adult, and Healthcare
Triage.

00:10:16.690 --> 00:10:20.330
If you'd like to keep Crash Course free for
everyone, forever, you can support the series

00:10:20.330 --> 00:10:24.130
at Patreon, a crowdfunding platform that allows
you to support the content you love.

00:10:24.130 --> 00:10:27.200
Thank you to all of our patrons for making
Crash Course possible with their continued

00:10:27.200 --> 00:10:27.700
support.

