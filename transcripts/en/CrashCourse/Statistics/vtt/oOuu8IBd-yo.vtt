WEBVTT
Kind: captions
Language: en

00:00:02.980 --> 00:00:06.620
Hi, I’m Adriene Hill, and welcome back to
Crash Course Statistics.

00:00:06.630 --> 00:00:10.570
In many of our episodes we’ve looked at
t-tests, which among other things, are good

00:00:10.570 --> 00:00:13.639
for testing the difference between two groups.

00:00:13.639 --> 00:00:15.190
Like people with or without cats.

00:00:15.190 --> 00:00:18.190
Families below the poverty line...and families
above it.

00:00:18.190 --> 00:00:22.240
Petri dishes of cells that are treated with
a chemical and those that aren't.

00:00:22.240 --> 00:00:24.400
But the world isn’t always so binary.

00:00:24.400 --> 00:00:27.380
We often want to compare measurements of MORE
than two groups.

00:00:27.380 --> 00:00:31.330
Things like ethnicity, medical diagnosis,
country of origin, or job title.

00:00:31.330 --> 00:00:36.460
So today, we’re going to apply the General
Linear Model Framework we learned in the last episode

00:00:36.460 --> 00:00:41.340
to test the difference between multiple groups using a new model called the ANOVA.

00:00:41.340 --> 00:00:50.700
INTRO

00:00:50.710 --> 00:00:54.940
The GLM Framework takes all the information
that our data contain, and partitions it into

00:00:54.940 --> 00:01:00.260
two piles: information that can be explained
by a model that represents the way we think

00:01:00.260 --> 00:01:05.260
things work, and error, which is the amount
of information that our model fails to explain.

00:01:05.260 --> 00:01:08.359
So let’s apply that to a new model: the
ANOVA.

00:01:08.359 --> 00:01:11.859
ANOVA is an acronym for ANalysis Of VAriance.

00:01:11.859 --> 00:01:16.250
It’s actually very similar to Regression,
except we’re using a categorical variable

00:01:16.250 --> 00:01:18.109
to predict a continuous one.

00:01:18.109 --> 00:01:22.659
Like using a soccer player’s position to
predict the number of yards he runs in a game.

00:01:22.659 --> 00:01:27.749
Or using highest completed degree to predict
a person’s salary, note that this alone

00:01:27.749 --> 00:01:33.460
isn’t evidence that getting a degree causes
a higher salary, just that knowing someone’s

00:01:33.460 --> 00:01:36.479
degree might help estimate how much they get
paid.

00:01:36.479 --> 00:01:40.210
Like Regression, the ANOVA builds a model
of how the world works.

00:01:40.210 --> 00:01:44.240
For example, my model for how many bunnies
I’ll see on my walk into work might be that

00:01:44.240 --> 00:01:47.780
if it’s raining I’ll see 1 bunny, and
if it’s sunny, I’ll see 5.

00:01:47.780 --> 00:01:49.679
I walk through a bunny preserve...

00:01:49.680 --> 00:01:54.840
1 and 5 are my predictions for how many bunnies I’ll see, based on whether or not it’s raining.

00:01:54.840 --> 00:01:56.120
Yesterday it rained.

00:01:56.120 --> 00:01:57.800
And I saw two bunnies!

00:01:57.800 --> 00:02:00.850
My model predicted 1, and my error is 1.

00:02:00.850 --> 00:02:05.319
And we can represent this model as a sort
of Regression where there are ONLY two possible

00:02:05.319 --> 00:02:08.240
values that the Variable Weather can have.

00:02:08.240 --> 00:02:10.880
0--if it rains--or 1--if it doesn’t.

00:02:10.880 --> 00:02:15.830
In this case, expected number of bunnies on
a rainy day is 1 and beta is the difference

00:02:15.830 --> 00:02:19.440
between the two means, 5-1 = 4.

00:02:19.440 --> 00:02:21.580
Which means our ANOVA model looks like this:

00:02:21.580 --> 00:02:25.850
In a Regression we did a statistical test
of the slope and that’s what this simple

00:02:25.850 --> 00:02:27.610
ANOVA is doing too.

00:02:27.610 --> 00:02:32.160
Since we assigned rainy days to be coded as
0, and sunny days as 1, the change in the

00:02:32.160 --> 00:02:35.800
X-direction is just one (1-0).

00:02:35.810 --> 00:02:40.800
So the slope of this line is the difference
between mean bunny count on sunny days, five,

00:02:40.800 --> 00:02:43.690
minus mean bunny count on rainy days, one.

00:02:43.690 --> 00:02:47.350
This difference of 4 is the change in the
Y direction.

00:02:47.350 --> 00:02:50.530
We test this difference in the same way that
we tested the regression slope.

00:02:50.530 --> 00:02:54.450
And this slope tells us the difference between
the means of the two groups.

00:02:54.450 --> 00:02:57.960
Usually we’ll like to think of this slope
as the difference between two group means.

00:02:57.960 --> 00:03:02.890
But, knowing that our model treats it like
a slope helps us understand how ANOVAs relate

00:03:02.890 --> 00:03:04.150
to regression.

00:03:04.150 --> 00:03:10.170
In a regression the slope tells you how much
an increase in one unit of X affects Y.

00:03:10.170 --> 00:03:14.880
Like for example, how much an increase of
1 year increases shoe size in kids.

00:03:14.880 --> 00:03:16.790
An ANOVA actually does the same thing.

00:03:16.790 --> 00:03:22.680
It looks at how much an increase from 0 (rainy
days) to 1 (non-rainy days) affects the number

00:03:22.680 --> 00:03:24.040
of bunnies you’d see.

00:03:24.040 --> 00:03:25.080
Now...to another example.

00:03:25.080 --> 00:03:29.590
Let’s look at the ratings of various chocolate
bars based on the type of cocoa bean used.

00:03:29.590 --> 00:03:34.140
We’ll use a dataset you can find at Kaggle.com
courtesy of Brady Brelinski.

00:03:34.140 --> 00:03:40.160
Our three groups are chocolate bars made with Criollo beans, Forastero beans, or Trinitario beans.

00:03:40.160 --> 00:03:46.360
Chocolate making is complex, so we took a
small sample of bars that only contained 1

00:03:46.360 --> 00:03:47.610
of these three beans.

00:03:47.610 --> 00:03:52.510
And the chocolate taster used a scale--with
5 as the highest score --transcending beyond

00:03:52.510 --> 00:03:53.880
the ordinary limits.

00:03:53.880 --> 00:03:56.500
1 was “mostly unpalatable”...

00:03:56.500 --> 00:04:00.480
But is there really “mostly unpalatable” chocolate out there?

00:04:00.480 --> 00:04:03.940
We want to know if the type of bean affects
our taster’s ratings.

00:04:03.940 --> 00:04:06.230
To find out, we need the ANOVA model!

00:04:06.230 --> 00:04:10.410
Like Regression, we can calculate a Sums of
Squares Total by adding up the squared differences

00:04:10.410 --> 00:04:14.510
between each chocolate rating, and the overall
mean chocolate rating.

00:04:14.510 --> 00:04:17.340
This gives us our Sums of Squares Total, or
SST.

00:04:17.340 --> 00:04:21.180
If that sounds like how we calculated variance,
that’s because it is!

00:04:21.180 --> 00:04:23.360
SST is just N times Variance.

00:04:23.360 --> 00:04:27.439
This Sum represents the total amount of variation,
or information, in the data.

00:04:27.439 --> 00:04:30.150
Now, we need to partition this variation.

00:04:30.150 --> 00:04:34.240
When we previously used a simple linear regression
model, we partitioned this variation into

00:04:34.240 --> 00:04:38.370
two parts: Sums of Squares for Regression,
and Sums of Squares for Error.

00:04:38.370 --> 00:04:40.080
And the ANOVA does the same thing.

00:04:40.080 --> 00:04:45.379
The first step is to figure out how much of
the variation is explained by our model.

00:04:45.379 --> 00:04:50.169
In an ANOVA--what we’re using here--our
best guess of a chocolate bar’s rating is

00:04:50.169 --> 00:04:51.540
its group mean.

00:04:51.540 --> 00:05:01.199
For bars made with Criollo beans 3.1, Forastero
beans 3.25, and Trinitario beans 3.27.

00:05:01.199 --> 00:05:05.889
So we sum up the squared distances between
each point and its group mean.

00:05:05.889 --> 00:05:11.740
This is called our Model Sums of Squares (or SSM) because it’s the variation our model explains.

00:05:11.800 --> 00:05:15.040
So now that we have the amount of variation
explained by the model.

00:05:15.040 --> 00:05:21.139
In other words, how much variation is accounted
for if we just assumed each rating value were

00:05:21.139 --> 00:05:22.599
it’s group mean rating.

00:05:22.599 --> 00:05:26.759
We’re also going to need the amount of variation
that it DOESN’T explain.

00:05:26.759 --> 00:05:30.759
In other words, how much ratings vary within
each group of Cacao beans.

00:05:30.759 --> 00:05:36.009
So, we can sum up the squared differences
between each data point and its group mean

00:05:36.009 --> 00:05:41.500
to get our Sums of Squares for Error: the
amount of information that our model doesn’t explain.

00:05:41.500 --> 00:05:45.440
Now that we have that information, we can
calculate our F-statistic, just like we did

00:05:45.440 --> 00:05:46.610
for regression.

00:05:46.610 --> 00:05:53.270
The F-statistic compares how much variation
our model accounts for vs. how much it can’t

00:05:53.270 --> 00:05:54.319
account for.

00:05:54.319 --> 00:05:59.050
The larger that F is, the more information
our model is able to give us about our chocolate

00:05:59.050 --> 00:06:00.050
bar ratings.

00:06:00.050 --> 00:06:04.680
Again, SSM is the variation our model explains
and SSE is the variation it doesn’t explain.

00:06:04.680 --> 00:06:05.930
We want to compare the two.

00:06:05.930 --> 00:06:10.569
But we also need to account for the amount
of independent information that each one uses.

00:06:10.569 --> 00:06:14.720
So, we divide each Sums of Squares by its
degrees of freedom.

00:06:14.720 --> 00:06:16.710
Our ANOVA model has 2 degrees of freedom.

00:06:16.710 --> 00:06:21.540
In general, the formula for degrees of freedom
for categorical variables (like cocoa bean

00:06:21.540 --> 00:06:27.900
types) in an ANOVA is k-1, where k is the
number of groups. In our case we have 3 groups.

00:06:27.900 --> 00:06:34.920
Our Sums of Squares for Error has 787 degrees
of freedom because we originally had 790 data

00:06:34.930 --> 00:06:37.780
points, but we calculated 3 means.

00:06:37.780 --> 00:06:42.360
The general formula for degrees of freedom
for your errors is n minus k where n is the

00:06:42.360 --> 00:06:45.270
sample size and k is the number of groups.

00:06:45.270 --> 00:06:49.789
For our test, we got an F-statistic of 7.7619.

00:06:49.789 --> 00:06:53.919
This F-statistic--sometimes called an F-ratio--has
a distribution that looks like this:

00:06:53.919 --> 00:06:56.990
And we’re going to use this distribution
to find our p-value.

00:06:56.990 --> 00:07:01.719
We want to know whether the effect of bean
type on chocolate bar ratings is significant.

00:07:01.719 --> 00:07:05.529
In this case we have a p-value of 0.000459.

00:07:05.529 --> 00:07:07.589
Small enough to reject the null.

00:07:07.589 --> 00:07:11.710
So we’ve found evidence that beans influenced
the chocolate bar ratings.

00:07:11.710 --> 00:07:16.500
A statistically significant result means that
there is SOME statistically significant difference

00:07:16.500 --> 00:07:20.439
SOMEWHERE in the groups, but it doesn’t
tell you where that difference is.

00:07:20.439 --> 00:07:25.770
Maybe Trinitario is significantly different
from Criollo but not Forastero beans..

00:07:25.770 --> 00:07:30.680
An F-test is an example of an Omnibus test,
which means it’s a test that contains many

00:07:30.680 --> 00:07:32.360
items or groups.

00:07:32.360 --> 00:07:38.210
When we get a significant F-statistic, it
means that there’s SOME statistically significant

00:07:38.210 --> 00:07:41.349
difference somewhere between the groups, but
we still have to look for it.

00:07:41.349 --> 00:07:45.669
It’s kinda like walking into your kitchen
and smelling something realllllllly stinky.

00:07:45.669 --> 00:07:50.499
You know there’s SOMETHING gross, but you
have to do more work to find out exactly what

00:07:50.499 --> 00:07:51.499
is rotting...

00:07:51.499 --> 00:07:55.759
We already have tools to do this, in statistics
at least, because you can follow up a significant

00:07:55.759 --> 00:08:01.740
F-test in an ANOVA with multiple t-tests,
one for every unique pair of categories your

00:08:01.740 --> 00:08:03.289
variable had.

00:08:03.289 --> 00:08:09.089
We had 3, which means we only need to do 3
t-tests in order to find the statistically

00:08:09.089 --> 00:08:10.699
significant difference or differences.

00:08:10.699 --> 00:08:16.069
To conduct these T-tests, we take just the
data in the two categories for that t-test,

00:08:16.069 --> 00:08:19.159
and calculate the t-statistic and p-value.

00:08:19.159 --> 00:08:24.210
For our first t-test we just look at the bars
with Trinitario and Criollo beans.

00:08:24.210 --> 00:08:27.039
First, we follow our Test statistic general
formula:

00:08:27.040 --> 00:08:31.580
We take the difference between the mean rating of chocolates made with Trinitario and Criollo beans.

00:08:31.580 --> 00:08:33.700
And divide by the standard error.

00:08:33.710 --> 00:08:38.060
And once we do this for all three comparisons,
we can see where our statistically significant

00:08:38.060 --> 00:08:39.060
differences are.

00:08:39.060 --> 00:08:43.830
It looks--from our graph--like ratings of
chocolate bars made with Criollo beans are

00:08:43.830 --> 00:08:48.570
different...in a statistically significant
way... than those made with Trinitario or

00:08:48.570 --> 00:08:50.060
Forastero beans.

00:08:50.060 --> 00:08:53.880
And our graph and group means show that Criollo
bars have a slightly lower mean rating.

00:08:53.880 --> 00:08:58.899
But bars made with Trinitario beans are NOT
statistically significantly different than

00:08:58.899 --> 00:09:01.250
those made with Forastero beans.

00:09:01.250 --> 00:09:06.800
So our ANOVA F-test told us that there WERE
some differences, and our follow up t-tests

00:09:06.800 --> 00:09:08.050
told us WHERE they were.

00:09:08.050 --> 00:09:09.209
And this is interesting.

00:09:09.209 --> 00:09:15.380
Criollo beans are generally considered a delicacy
and of a much higher quality than Forastero.

00:09:15.380 --> 00:09:18.089
And Trinitario are hybrid of the two.

00:09:18.089 --> 00:09:24.500
But we found...in this data set... that Criollo
bars had statistically significantly lower ratings.

00:09:24.500 --> 00:09:28.900
This might be because we excluded bars with
combinations of our three bean types...or

00:09:28.910 --> 00:09:34.800
because the rater has a different preference...or
even be caused by some other unknown factor

00:09:34.810 --> 00:09:36.850
that our model does not include.

00:09:36.850 --> 00:09:37.889
Like who made the chocolate.

00:09:37.889 --> 00:09:40.000
Or the country of origin of the beans.

00:09:40.000 --> 00:09:42.560
We can also use ANOVAs for more than 3 groups.

00:09:42.560 --> 00:09:47.720
For example, the ANOVA was first created by
the statistician R.A. Fisher when he was on

00:09:47.720 --> 00:09:50.829
a potato farm looking at studies of fertilizer.

00:09:50.829 --> 00:09:55.430
In one of the first experiments he described,
he looked at 12 different species of potato

00:09:55.430 --> 00:09:57.980
and the effect of various fertilizers.

00:09:57.980 --> 00:10:01.420
Let’s look at a simple version of Fisher’s
potato study.

00:10:01.420 --> 00:10:04.209
Here we have 12 different varieties of potato.

00:10:04.209 --> 00:10:07.009
We’ll represent each of them with a letter
A through L.

00:10:07.009 --> 00:10:12.769
There are 21 of each of the potato plants,
for a total of 252 potato plants.

00:10:12.769 --> 00:10:17.240
We give our future french fries about a season to grow, then we dig them up and weigh each one.

00:10:17.240 --> 00:10:22.340
This graph shows the potato weights that we
recorded, as well as the total mean potato

00:10:22.340 --> 00:10:25.180
weight and each group mean potato weight.

00:10:25.180 --> 00:10:29.339
Using these numbers, we can calculate our
Total Sums of Squares, Model Sums of Squares,

00:10:29.339 --> 00:10:30.690
and Sums of Squares error.

00:10:30.690 --> 00:10:33.930
We’re going to let a computer do that for
us this time.

00:10:33.930 --> 00:10:39.040
And our computer spit out this: the degrees
of freedom, sums of squares, mean squares,

00:10:39.040 --> 00:10:41.190
F-statistic, and p-value.

00:10:41.190 --> 00:10:46.400
This is called an ANOVA table and it organizes all the information our ANOVA models give us.

00:10:46.400 --> 00:10:54.120
Here we can see that our Model had an F-statistic--or
F-value--of around 3, and a p-value of 0.000829.

00:10:54.120 --> 00:10:56.540
So we reject the null hypothesis.

00:10:56.540 --> 00:11:01.209
We found evidence that the potato varieties
don’t all have the same mean weight.

00:11:01.209 --> 00:11:06.839
But since this was an Omnibus test, our statistically
significant F-test just means that there is

00:11:06.840 --> 00:11:12.780
some statistically significant difference
somewhere in those 12 potato varieties.

00:11:12.780 --> 00:11:14.040
We don’t know where it is.

00:11:14.050 --> 00:11:17.500
In that way, ANOVAs can be thought of as a
first step.

00:11:17.500 --> 00:11:22.459
We do an overall test that tells us whether
there’s a needle in our haystack.

00:11:22.459 --> 00:11:26.230
If we find out there is a needle, then we
go looking for it.

00:11:26.230 --> 00:11:29.860
However, if our test tells us there’s no
needle, we’re done.

00:11:29.860 --> 00:11:32.480
No need to look for something that probably
doesn’t exist.

00:11:32.480 --> 00:11:37.910
But you can see that this significant F-statistic
for potato varieties will require MANY follow

00:11:37.910 --> 00:11:38.910
up tests.

00:11:38.910 --> 00:11:40.130
12 choose 2.

00:11:40.130 --> 00:11:41.560
Or 66.

00:11:41.560 --> 00:11:45.170
We showed a lot of calculations today, but
there’s two big ANOVA ideas to take away

00:11:45.170 --> 00:11:46.170
from this.

00:11:46.170 --> 00:11:51.680
First, a lot of these different statistical
models are more similar than they are actually different.

00:11:51.680 --> 00:11:57.760
ANOVAs and Regressions both use the General
Linear Model form to create a story about

00:11:57.760 --> 00:11:59.240
how the world might work.

00:11:59.250 --> 00:12:03.949
The ANOVA says that the best guess for a data
point--like the rating of a new chocolate

00:12:03.949 --> 00:12:07.960
bar--is the mean rating of whatever Group
it belongs to.

00:12:07.960 --> 00:12:11.790
Whether that’s Criollo, Trinitario , or
Forastero.

00:12:11.790 --> 00:12:16.339
If we don’t know anything else, we’d guess
that the rating of a Criollo chocolate bar

00:12:16.339 --> 00:12:18.899
is the mean rating for all Criollo bars.

00:12:18.899 --> 00:12:21.570
Also, an ANOVA is a great example of filtering.

00:12:21.570 --> 00:12:26.190
If there’s no evidence that bean type has
an overall effect on chocolate-bar ratings,

00:12:26.190 --> 00:12:29.519
we don’t want to go chasing more specific
effects.

00:12:29.519 --> 00:12:33.300
Our time is precious...and we want to use
it as best as we can.

00:12:33.300 --> 00:12:36.050
So we have more time out in the world...to
look for bunnies.

00:12:36.050 --> 00:12:38.420
Thanks for watching, I’ll see you next time.

