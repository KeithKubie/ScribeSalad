WEBVTT
Kind: captions
Language: en

00:00:03.140 --> 00:00:08.820
Someday in the near future, you might be
wandering around town at night when out of the
blue you’ll stumble across a robot.

00:00:08.820 --> 00:00:11.220
If that happens, maybe you shouldn’t be
too surprised.

00:00:11.220 --> 00:00:14.900
Not so long ago, robots were mostly found
in the realms of science fiction.

00:00:14.900 --> 00:00:20.030
Today, they’re vacuuming floors, building
cars, and even roaming the surface of Mars.

00:00:20.030 --> 00:00:25.620
Robots are still pretty far from having a human level
capacity of intelligence, or even dexterity for that matter,

00:00:25.620 --> 00:00:28.720
but they’re already a big part of many
branches of engineering.

00:00:28.720 --> 00:00:33.020
In the US, over a hundred thousand robots
have been added to factory floors since 2010.

00:00:33.020 --> 00:00:38.480
Knowing what exactly robots are, what they
can do and how they work is more important
than you might think.

00:00:38.480 --> 00:00:41.480
Because soon, they might be living among us.

00:00:41.480 --> 00:00:51.680
[Theme Music]

00:00:51.680 --> 00:00:57.220
The classic picture of a robot is something
with human-like intelligence, and maybe even
a humanoid appearance.

00:00:57.220 --> 00:01:01.560
But like so much else, real-life robots aren’t
much like what you usually see on TV.

00:01:01.560 --> 00:01:06.380
Robots come in all shapes and sizes, and
they can be built very differently depending
on what they’re used for.

00:01:06.380 --> 00:01:11.680
For example, some of the robots used in mining
are made from a camera, mounted on a small 
chassis with wheels.

00:01:11.680 --> 00:01:18.170
That allows them to enter and inspect mine
shafts, and even retrieve leftover material from
places it’s hard to get people in and out of.

00:01:18.170 --> 00:01:25.860
Meanwhile, in medicine, specialized robotic
arms, with a bit of human assistance, can perform
precise surgeries through the tiniest incisions.

00:01:25.860 --> 00:01:32.040
There’s also a difference between robotics
and artificial intelligence, or AI, which
people sometimes confuse.

00:01:32.040 --> 00:01:38.820
While some of the concepts are similar,
robotics deals with a specific set of ideas,
although it does borrow a few from AI.

00:01:38.820 --> 00:01:46.240
AI deals broadly with the goal of automating
decision-making for complex tasks – the kind
you can’t write a simple set of rules for.

00:01:46.240 --> 00:01:49.260
That could be everything from playing chess
to driving cars.

00:01:49.260 --> 00:01:52.800
Right now, AI systems tend to have very narrow
goals.

00:01:52.800 --> 00:02:00.960
But the holy grail of AI is to develop a system
that can make intelligent decisions about any sort
of task using different sources of information.

00:02:00.960 --> 00:02:05.760
Our focus will be on robots, which are designed
for more specific purposes in the physical world.

00:02:05.760 --> 00:02:13.260
In engineering terms, a robot is a machine
designed to interact with its environment, make an
appropriate decision based on those surroundings,

00:02:13.260 --> 00:02:17.080
and then carry out the jobs related to its
goal, all automatically.

00:02:17.080 --> 00:02:20.890
Which means a true robot doesn’t require
a human controlling exactly what it does.

00:02:20.890 --> 00:02:25.940
In general, the field of robotics also deals
with machines that do all of the same things,

00:02:25.940 --> 00:02:29.140
but might require a human operator to carry
out some tasks.

00:02:29.140 --> 00:02:34.080
Whether fully automatic or not, virtually
all robots have a few features in common.

00:02:34.080 --> 00:02:40.320
First, robots are machines made from
materials that occupy physical space, so they’re
more than just lines of computer code.

00:02:40.320 --> 00:02:46.100
That’s one of the key features that distinguishes
them from an AI, although computer engineering
is important for robots as well.

00:02:46.100 --> 00:02:53.300
Second, most robots have some way of sensing
features of their environment, usually by measuring
light, sound, or force feedback.

00:02:53.300 --> 00:02:58.540
They can then use that information to make
a decision about what to do next, depending
on what they’re designed for.

00:02:58.540 --> 00:03:04.040
The tasks robots are built for tend to be
complex, requiring a sequence of different
motions.

00:03:04.040 --> 00:03:10.250
So an automatic door that opens or shuts in
response to whether you stand in front of a
sensor wouldn’t be considered a robot.

00:03:10.250 --> 00:03:16.080
The tasks that robots handle are more
sophisticated, like welding two intricately-shaped
pieces of metal together.

00:03:16.080 --> 00:03:24.020
Third, to interpret the signals they receive from their environment and coordinate some sort of response, robots have computers built somewhere into their design.

00:03:24.020 --> 00:03:27.580
These work just like any computer, taking
inputs and delivering outputs.

00:03:27.580 --> 00:03:35.000
But unlike most ordinary software, the software on
a robot’s computer generates electrical signals that
are directly passed on to the robot’s hardware,

00:03:35.000 --> 00:03:38.100
instead of just changing information in a
file or on a screen.

00:03:38.100 --> 00:03:40.080
That also requires a power source.

00:03:40.080 --> 00:03:44.160
One option is to physically hook up to the
power grid using wires and a socket.

00:03:44.160 --> 00:03:54.000
For example, the 2013 version of the Atlas robot developed by robotics company Boston Dynamics had a humanoid design that could walk and carry objects, much like humans do.

00:03:54.000 --> 00:03:57.500
To operate, Atlas relied on a cable that tethered
it to a power supply.

00:03:57.500 --> 00:04:02.100
But tethering robots like this limits how
far they can move and interferes with the
robot’s mobility.

00:04:02.100 --> 00:04:08.180
So to let Atlas move around more freely,
engineers installed a battery on the robot’s
structure so it could power itself.

00:04:08.180 --> 00:04:13.000
Unfortunately the materials of a battery tend
to be rather heavy, which posed its own challenges.

00:04:13.010 --> 00:04:15.970
If we don’t want robots like these toppling
over all the time,

00:04:15.970 --> 00:04:22.620
it takes a bit of mechanical engineering knowhow
to work out where to position the battery with respect
to the robot’s center of mass.

00:04:22.620 --> 00:04:25.720
You might need some chemical engineering in
the design of the battery, too.

00:04:25.720 --> 00:04:32.400
In the case of Atlas, engineers gave it a
hydraulic pump in its torso to help it support
the extra weight of its lithium-ion battery.

00:04:32.409 --> 00:04:35.840
And now, only a few years later, it can do
backflips and parkour.

00:04:35.840 --> 00:04:42.700
More generally, some electrical engineering
also has to go into wiring the signals from the
computer program to the robot’s physical parts.

00:04:42.700 --> 00:04:45.500
Which brings us to another common feature
of robots:

00:04:45.500 --> 00:04:51.220
they have mechanical parts, like grips or
wheels, for carrying out whatever physical
tasks they need to in their environments.

00:04:51.220 --> 00:04:55.099
That might be turning a lever, picking up
an object, or just moving somewhere else.

00:04:55.099 --> 00:04:57.849
And there are some unique challenges to designing
those parts.

00:04:57.849 --> 00:05:00.520
Consider a robot designed to pick fruit from
trees.

00:05:00.520 --> 00:05:04.060
From an engineering perspective, it needs
some fundamental qualities:

00:05:04.060 --> 00:05:08.020
the ability to recognize fruits and distinguish
them from the rest of the plant,

00:05:08.020 --> 00:05:11.530
navigate its environment to move toward fruits
that need picking,

00:05:11.530 --> 00:05:14.060
and then to pick them and put them into a
container.

00:05:14.060 --> 00:05:18.330
Let’s start with how it moves – a fairly
basic requirement for lots of robots.

00:05:18.330 --> 00:05:26.200
Like with that mining robot, you could simply put
some standard axles with wheels on the bottom of
your robot and attach them to a motor, like on a car.

00:05:26.200 --> 00:05:32.440
That would be fine if the robot was going to
be operating mostly on smooth, even surfaces,
like roads or factory floors.

00:05:32.440 --> 00:05:36.840
But most fruits are grown outdoors, sometimes
in rough terrain and difficult environments.

00:05:36.840 --> 00:05:43.280
So you might need to design adjustable wheels
that change height independently, or add treads
to overcome small bumps, like on a tank.

00:05:43.280 --> 00:05:47.419
The problem with wheels is that they’re
not very good at overcoming large obstacles.

00:05:47.420 --> 00:05:52.740
If there’s a fallen branch or a boulder
blocking the way, the robot needs to be able
to climb over it.

00:05:52.740 --> 00:05:59.460
Giving the robot legs could allow it to jump,
but that has its own problems: robots with
legs tend to fall down...a lot.

00:05:59.460 --> 00:06:03.140
As the team at Boston Dynamics found when
designing Atlas,

00:06:03.140 --> 00:06:10.780
programming a robot’s computer to interpret its
environment while handling the dynamics of all
those mechanical parts is trickier than it seems!

00:06:10.780 --> 00:06:13.720
It really makes you appreciate what a good
job your brain is doing.

00:06:13.720 --> 00:06:19.480
Of course, to actually make sense of its environment
and find fruit, the robot will need sensors

00:06:19.480 --> 00:06:23.279
– devices that measure physical characteristics
and translate them into a signal.

00:06:23.280 --> 00:06:28.140
To find apples, for example, the robot might
have an array of light-sensitive semiconductors,

00:06:28.140 --> 00:06:32.520
like the kind that make up the light-capturing
pixels in a digital camera, to scan an orchard.

00:06:32.520 --> 00:06:39.880
But the information sent by the camera sensor is
interpreted by the computer as an array of colored
pixels that don’t mean an awful lot on their own.

00:06:39.880 --> 00:06:46.180
The average person, can take one glance at
a curvy shape of reddish pixels and instantly
recognize it as an apple.

00:06:46.189 --> 00:06:49.920
For a computer, that requires a fairly sophisticated
visual algorithm.

00:06:49.920 --> 00:06:57.800
What’s more, people are good at seeing where the edges
|of objects are, and interpreting the relationships they
have to their environment and how far away they are.

00:06:57.800 --> 00:07:01.640
You know an apple that looks very small is
most likely one that’s far away.

00:07:01.640 --> 00:07:05.200
But even a relatively smart computer that
can recognize apples

00:07:05.200 --> 00:07:11.200
might not know whether it’s a tiny apple only
a few centimeters away or an enormous apple
a few kilometers away.

00:07:11.200 --> 00:07:15.080
Which would affect whether the computer’s
programming tells it to pick the apple or not.

00:07:15.080 --> 00:07:18.500
All of these issues are what are known as
computer vision problems.

00:07:18.500 --> 00:07:23.120
Computer vision deals with how to train software
to take the input data from images or video,

00:07:23.120 --> 00:07:27.540
like the kind that are delivered from digital
cameras, and interpret it the way a human would.

00:07:27.540 --> 00:07:33.880
Even once it’s found an apple and moved
itself close to it, the fruit picker is going to
need mechanical parts to actually pick fruit.

00:07:33.880 --> 00:07:38.580
The main mechanical parts used by most industrial
robots are called actuators and effectors.

00:07:38.580 --> 00:07:40.960
Actuators are like a robot’s muscles.

00:07:40.960 --> 00:07:43.400
They convert stored energy into movement.

00:07:43.400 --> 00:07:52.200
One popular type are electrical actuators, electrical
motors that turn wheels or gears to rotate the robot’s
connected parts with respect to one another.

00:07:52.200 --> 00:07:58.120
These are the sorts of mechanisms that
would extend the robot’s arms toward or away
from a particular branch.

00:07:58.120 --> 00:08:04.800
Linear actuators can achieve this by using a
motor to extend the part up and down a thread,
like a nut on a bolt.

00:08:04.800 --> 00:08:12.960
They can also use compressed fluids, like air or oil, to
extend a part outwards, then use a motor to compress
the fluid and bring the parts back when needed.

00:08:12.960 --> 00:08:18.520
Effectors, meanwhile are the parts that actually
have an effect on the robot’s environment –
basically, the robot’s hands.

00:08:18.520 --> 00:08:25.540
To deal with the irregular shapes of different fruits,
you could have what’s called a vacuum grip that
can suck up large objects and hold them in place.

00:08:25.540 --> 00:08:32.580
But most of the focus on building robots has
been on mechanical effectors – the kind that rely
on tactile feedback and manipulating.

00:08:32.580 --> 00:08:39.180
In other words, they give the robot an artificial
sense of touch, perhaps with force-sensitive 
electrodes on the effector’s surface.

00:08:39.180 --> 00:08:46.980
Having a sense of feedback is important for applying the
right amount of pressure – otherwise the apple might
slip out of the robot’s grip or be crushed into a pulp.

00:08:46.980 --> 00:08:53.580
To achieve this, the effector might be a simple
two-part claw, or something more sophisticated with
many parts modeled on a human hand.

00:08:53.580 --> 00:09:01.020
Picking fruit is the kind of job that robots could
accomplish at scale much more easily than humans,
freeing them to work on other aspects of farming.

00:09:01.020 --> 00:09:03.460
But robotics isn’t just aimed at saving
labor.

00:09:03.460 --> 00:09:07.660
Robots can also be used in environments that
are far too dangerous to send humans into.

00:09:07.660 --> 00:09:15.890
Bomb disposal robots – which are actually more like
drones – are operated by humans to find explosive
devices and disarm them from a safe distance.

00:09:15.890 --> 00:09:21.840
In the future, fully automated robots might
find uses in other harsh environments like
the deep sea and space.

00:09:21.840 --> 00:09:29.400
But it’s likely that the place robots will have the
most impact won’t be in the jobs they do instead
of humans, but the ones they do alongside them.

00:09:29.400 --> 00:09:34.680
Features of robotics are already making their
way into healthcare, like in the development
of prosthetic limbs.

00:09:34.680 --> 00:09:38.380
But in situations like surgery or disaster
rescue operations,

00:09:38.380 --> 00:09:46.200
a combination of human smarts and purpose-built
robotic strength could create safer, more efficient,
and totally new ways of doing things.

00:09:46.200 --> 00:09:53.630
So like many engineering tools, robots will work
best when they weave into our existing methods,
working alongside us to accomplish our goals.

00:09:53.630 --> 00:09:56.860
Robots might be the future, but it’s a far
cry from the Terminator.

00:09:56.860 --> 00:10:00.840
In this episode we looked at robots and the
engineering principles of robots.

00:10:00.840 --> 00:10:03.920
We learned how robots use sensors to interpret
their environment,

00:10:03.920 --> 00:10:08.920
how actuators and effectors allow a robot to
manipulate the objects around it to accomplish a task,

00:10:08.920 --> 00:10:11.740
and how computers coordinate the efforts of the two.

00:10:11.740 --> 00:10:20.880
AR Poster available now at DFTBA.com!

00:10:20.880 --> 00:10:27.500
Crash Course Engineering is produced in association
with PBS Digital Studios, which also produces
It's Okay To Be Smart,

00:10:27.500 --> 00:10:33.280
a show all about our curious universe and
the science that makes it possible, hosted
by Dr. Joe Hanson.

00:10:33.280 --> 00:10:35.140
Check it out at the link in the description.

00:10:35.140 --> 00:10:42.200
Crash Course is a Complexly production and this
episode was filmed in the Doctor Cheryl C. Kinney
Studio with the help of these wonderful people.

00:10:42.200 --> 00:10:45.100
And our amazing graphics team is Thought Cafe.

