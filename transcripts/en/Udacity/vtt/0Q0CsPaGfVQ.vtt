WEBVTT
Kind: captions
Language: en

00:00:00.300 --> 00:00:03.030
One solution to tracking the various paths that light can take to reach the eye

00:00:03.030 --> 00:00:05.424
is to shoot a lot more rays per pixel and bounce them around in hopes of

00:00:05.424 --> 00:00:10.192
finding light sources. This is called path tracing. It can be very noisy to

00:00:10.192 --> 00:00:14.114
start with but can give correct results with enough time. This is a real-time

00:00:14.114 --> 00:00:18.207
demo by Evan Wallace in WebGL, one I recommend you try yourself. Notice the

00:00:18.207 --> 00:00:22.058
color bleeding effect of light bouncing off the walls onto the spheres. You can

00:00:22.058 --> 00:00:24.896
also make objects have glossy reflections instead of the sharp ones we see with

00:00:24.896 --> 00:00:28.675
classical ray tracing. This demo uses what is called progressive rendering,

00:00:28.675 --> 00:00:32.570
shooting more and more rays for each pixel and blending in the results. The

00:00:32.570 --> 00:00:35.980
longer you wait, the better the image gets. You can even use path tracing to

00:00:35.980 --> 00:00:39.188
render scenes form MineCraft. Here's one I made using the free chunky path

00:00:39.188 --> 00:00:42.890
tracer, giving a beam of light effect down the scene. A basic pure path tracer

00:00:42.890 --> 00:00:46.370
is pretty straightforward to write. You generally shoot more rays in sensible

00:00:46.370 --> 00:00:49.990
directions and sum up the light contributions found. Where all the time gets

00:00:49.990 --> 00:00:53.790
burned is that you're shooting tens of thousands of rays per pixel or more.

00:00:53.790 --> 00:00:57.255
This scene took about 16 hours with 12 CPU threads and it was still a bit noisy

00:00:57.255 --> 00:01:01.163
at that point. I should mention there are many other algorithms such as photon

00:01:01.163 --> 00:01:03.623
mapping and bidirectional path tracing that work to get the best of both

00:01:03.623 --> 00:01:07.378
worlds. The general idea is to send light out from emitters using rays

00:01:07.378 --> 00:01:11.540
depositing radiance wherever the rays reach. The scene is then retraced from

00:01:11.540 --> 00:01:15.149
the camera's view and the emitted light is gathered. Algorithms such as path

00:01:15.149 --> 00:01:18.680
tracing can give unparalleled realism, given enough time. Set up properly, a

00:01:18.680 --> 00:01:22.435
rendering can be a true simulation of how light percolates through a scene. Not

00:01:22.435 --> 00:01:26.308
just an artistic approximation. I used to work on a global illumination system

00:01:26.308 --> 00:01:30.486
back in the 80s and 90s. Even back then we knew that path tracing could, given

00:01:30.486 --> 00:01:34.222
enough computer cycles, get the right answer. The running joke was that we were

00:01:34.222 --> 00:01:37.304
mostly just biding our time, coming up with optimizations for other algorithms

00:01:37.304 --> 00:01:40.202
while wait the 50 years needed for computers to get powerful enough to shoot

00:01:40.202 --> 00:01:45.465
10,000 rays per pixel to get the right answer. Nowadays I think you probably

00:01:45.465 --> 00:01:48.165
need more like 100,000 or a million rays per pixel, but by my watch, I just

00:01:48.165 --> 00:01:50.955
need to wait another quarter century for rendering to be over, and then the

00:01:50.955 --> 00:01:53.790
singularity comes anyway, assuming people don't put more objects in their

00:01:53.790 --> 00:01:56.279
scenes.

