WEBVTT
Kind: captions
Language: en

00:00:06.280 --> 00:00:07.910
HAYES RAFFLE: Hello.

00:00:07.910 --> 00:00:10.670
AUDIENCE: Hi.

00:00:10.670 --> 00:00:12.450
HAYES RAFFLE: Hi,
I'm Hayes Raffle.

00:00:12.450 --> 00:00:14.930
I'm here today with
three colleagues

00:00:14.930 --> 00:00:18.240
I've been working with a
long time, Bob Ryskamp, Emmet

00:00:18.240 --> 00:00:19.585
Connolly, and Alex Faaborg.

00:00:19.585 --> 00:00:22.210
Actually, the four of us go back
a long time in different ways.

00:00:22.210 --> 00:00:24.460
Alex and I were at
the MIT Media Lab

00:00:24.460 --> 00:00:26.720
together about 10 years ago.

00:00:26.720 --> 00:00:30.550
And Bob and Emmet were
on the watch design team,

00:00:30.550 --> 00:00:33.100
I think, about three years ago,
doing the very early design

00:00:33.100 --> 00:00:35.500
iterations of Android Wear.

00:00:35.500 --> 00:00:38.580
And now Alex and Emmet work
together on the Wear team,

00:00:38.580 --> 00:00:42.090
and Bob I have been working on
Glass for about three years.

00:00:42.090 --> 00:00:44.640
And you guys are sort of getting
four for the price of one

00:00:44.640 --> 00:00:45.370
today.

00:00:45.370 --> 00:00:47.870
We're here to share with
you some of the things

00:00:47.870 --> 00:00:51.010
that we've learned along the
way because over the last three

00:00:51.010 --> 00:00:53.019
or four years,
we've been finding

00:00:53.019 --> 00:00:54.810
our way through this
new space of wearables

00:00:54.810 --> 00:00:58.600
and trying to understand
what it means, what works,

00:00:58.600 --> 00:01:04.137
and what direction it makes
sense to go in this new space.

00:01:04.137 --> 00:01:06.720
And so I wanted to start with a
little bit of philosophy, some

00:01:06.720 --> 00:01:09.100
of the things that
we've found useful

00:01:09.100 --> 00:01:12.330
as we've worked
through this space.

00:01:12.330 --> 00:01:15.230
And a couple of things that
have been most helpful for me

00:01:15.230 --> 00:01:19.040
are some of the things
that Sergey and Larry have

00:01:19.040 --> 00:01:21.056
talked about over the years.

00:01:21.056 --> 00:01:23.430
Larry talks about how technology
should do the hard work,

00:01:23.430 --> 00:01:25.721
and you should have a chance
to live, have a good life,

00:01:25.721 --> 00:01:26.620
and get on with it.

00:01:26.620 --> 00:01:27.080
And that's great.

00:01:27.080 --> 00:01:28.770
And you see that in
products like Google Search

00:01:28.770 --> 00:01:31.145
that try and get you what you
need and get out of the way

00:01:31.145 --> 00:01:32.440
as fast as possible.

00:01:32.440 --> 00:01:34.650
And Sergey talks
about how computing

00:01:34.650 --> 00:01:36.200
needs to be more comfortable.

00:01:36.200 --> 00:01:37.530
And on their surface,
these might actually

00:01:37.530 --> 00:01:38.640
seem like different statements.

00:01:38.640 --> 00:01:39.520
One is about form.

00:01:39.520 --> 00:01:40.970
The other one's about function.

00:01:40.970 --> 00:01:42.610
But they're really
the same idea.

00:01:42.610 --> 00:01:45.511
And the idea is that computing
should start to disappear.

00:01:45.511 --> 00:01:47.510
It should fade into the
background of our lives.

00:01:47.510 --> 00:01:49.940
It should be ephemeral,
not the foreground

00:01:49.940 --> 00:01:54.420
of our attention all the time
because life is beautiful.

00:01:54.420 --> 00:01:56.810
It's full of beautiful
people and puppies

00:01:56.810 --> 00:02:00.160
and sunsets and things that
are just really lovely.

00:02:00.160 --> 00:02:02.750
And computing shouldn't be
taking us away from that.

00:02:02.750 --> 00:02:06.410
It should be helping to bring
us closer to it, if anything.

00:02:06.410 --> 00:02:07.895
And so one of the
phrases that we

00:02:07.895 --> 00:02:09.520
use a lot when we're
doing design is we

00:02:09.520 --> 00:02:11.910
talk about the world
being the experience.

00:02:11.910 --> 00:02:14.160
The user experience, the
experience with the product,

00:02:14.160 --> 00:02:16.540
could never possibly compete
with the beautiful things

00:02:16.540 --> 00:02:17.660
around you.

00:02:17.660 --> 00:02:21.080
At best, it can provide timely
information and help and things

00:02:21.080 --> 00:02:22.930
that can help you be
connected to others

00:02:22.930 --> 00:02:26.180
and be connected to the
moment that you're in.

00:02:26.180 --> 00:02:27.860
And you see that
in lots of aspects

00:02:27.860 --> 00:02:30.040
of the design of the
products that we're building.

00:02:30.040 --> 00:02:32.260
You see it in the placement
of the Glass display.

00:02:32.260 --> 00:02:33.700
It's not in front of you.

00:02:33.700 --> 00:02:35.170
It's off on the periphery.

00:02:35.170 --> 00:02:38.060
You see that even
in the font weights,

00:02:38.060 --> 00:02:41.160
very thin, light strokes
with a black background

00:02:41.160 --> 00:02:43.800
which shows up as transparent
on the Glass display.

00:02:46.460 --> 00:02:48.980
You see that in some of the use
cases, some of my favorites,

00:02:48.980 --> 00:02:51.772
this one of Sebastian Thrun
swinging his son around

00:02:51.772 --> 00:02:53.480
in a circle right
after we got the camera

00:02:53.480 --> 00:02:55.710
working on Glass
a couple years ago

00:02:55.710 --> 00:02:59.510
and showing how technology
could really help transport us

00:02:59.510 --> 00:03:01.290
into that moment
of joy that he was

00:03:01.290 --> 00:03:04.484
having with his three-year-old.

00:03:04.484 --> 00:03:05.900
This is what it
means when we say,

00:03:05.900 --> 00:03:09.270
"The world is the experience."

00:03:09.270 --> 00:03:11.722
And now my background
actually is in fine art.

00:03:11.722 --> 00:03:13.430
And the thing that I
care most about when

00:03:13.430 --> 00:03:16.600
I do my work is creating a
sense of empathy between people,

00:03:16.600 --> 00:03:19.880
getting people closer
together, because while we talk

00:03:19.880 --> 00:03:21.910
so much at Google about
the user experience

00:03:21.910 --> 00:03:25.340
and designing for the user,
none of us live in isolation.

00:03:25.340 --> 00:03:28.200
We live in a world surrounded
by people that we care about.

00:03:28.200 --> 00:03:32.584
And how can technology help
to bring us closer to others?

00:03:32.584 --> 00:03:34.250
And I want to show
you a couple examples

00:03:34.250 --> 00:03:37.200
that I think are starting
to get in that direction.

00:03:37.200 --> 00:03:40.260
This is a picture of a
journalist named Tim Pool.

00:03:40.260 --> 00:03:42.260
Tim works for "Vice Magazine."

00:03:42.260 --> 00:03:44.670
And about a year ago, he was
in the streets of Istanbul

00:03:44.670 --> 00:03:47.160
documenting the riots
that were happening there

00:03:47.160 --> 00:03:52.040
and broadcasting live from
Glass to a huge viewer base

00:03:52.040 --> 00:03:53.722
that he has.

00:03:53.722 --> 00:03:55.430
And Tim's been doing
this for a long time

00:03:55.430 --> 00:03:58.660
with cameras on his shoulder,
with his cell phone,

00:03:58.660 --> 00:04:00.077
now with Glass.

00:04:00.077 --> 00:04:02.160
And I think for me the
transformative thing that's

00:04:02.160 --> 00:04:05.300
happening is that
Glass is allowing him

00:04:05.300 --> 00:04:07.540
to interview people in
a more intimate way.

00:04:07.540 --> 00:04:10.034
When he talks to people
in the street with Glass,

00:04:10.034 --> 00:04:11.450
they're not talking
to his camera.

00:04:11.450 --> 00:04:12.445
They're talking to him.

00:04:12.445 --> 00:04:14.070
And what that means
is that when you're

00:04:14.070 --> 00:04:16.450
watching that
broadcast from far away

00:04:16.450 --> 00:04:18.707
and trying to understand
what's happening in Istanbul,

00:04:18.707 --> 00:04:20.290
you're that much
closer to the action.

00:04:20.290 --> 00:04:21.700
You're that much
closer to the way

00:04:21.700 --> 00:04:23.574
that people are feeling
in the streets there.

00:04:26.862 --> 00:04:28.570
There's another thing
that we think a lot

00:04:28.570 --> 00:04:32.210
about with wearables and
this idea of being connected.

00:04:32.210 --> 00:04:35.040
Wearables themselves
are very, very intimate.

00:04:35.040 --> 00:04:36.790
You're wearing
them on your body.

00:04:36.790 --> 00:04:39.310
In fact, these glasses are
so specially designed for me,

00:04:39.310 --> 00:04:41.520
if you put them on, you
probably can't see then

00:04:41.520 --> 00:04:43.280
because I have my
prescription on them.

00:04:43.280 --> 00:04:44.750
They're very hard to share.

00:04:44.750 --> 00:04:47.910
And in the same token, the way
that we design the experience

00:04:47.910 --> 00:04:49.830
for wearables needs
to be very personal.

00:04:49.830 --> 00:04:52.820
It needs to reflect the
things about me as the wearer

00:04:52.820 --> 00:04:54.410
that I find important.

00:04:54.410 --> 00:04:56.980
It needs to be about the
closest people, the people

00:04:56.980 --> 00:04:59.530
that I care about who are close
both in time and in space,

00:04:59.530 --> 00:05:02.488
whether it's my family or you
who are in this room with me

00:05:02.488 --> 00:05:05.620
right now.

00:05:05.620 --> 00:05:08.400
It's about surfacing the
information from the people

00:05:08.400 --> 00:05:13.930
you care about in a way
that feels personal to you.

00:05:13.930 --> 00:05:18.840
It's about being able to bring
your niece to her grandmother's

00:05:18.840 --> 00:05:22.134
birthday party to see 100
candles get blown out,

00:05:22.134 --> 00:05:23.800
even if she couldn't
be there in person.

00:05:27.600 --> 00:05:32.530
Again, this is what we mean by,
"The world is the experience."

00:05:32.530 --> 00:05:36.287
Now one of the tactics that we
talk about, how do you do this?

00:05:36.287 --> 00:05:38.620
And we're going to talk about
some different ways today.

00:05:38.620 --> 00:05:40.411
But the first one that
I want to talk about

00:05:40.411 --> 00:05:42.320
is called micro interactions.

00:05:42.320 --> 00:05:44.230
And the idea with
micro interactions

00:05:44.230 --> 00:05:47.570
is that wearables
are on the periphery.

00:05:47.570 --> 00:05:49.780
You're not designing
the windshield.

00:05:49.780 --> 00:05:53.120
You're designing what goes
in the rear view mirror

00:05:53.120 --> 00:05:56.349
because whatever is happening in
front of the user in their life

00:05:56.349 --> 00:05:57.390
is going to be demanding.

00:05:57.390 --> 00:05:58.723
It's going to be happening fast.

00:05:58.723 --> 00:06:00.900
And it's going to need
most of their attention.

00:06:00.900 --> 00:06:04.690
And whatever you're giving them
needs to be very glanceable.

00:06:04.690 --> 00:06:06.740
And this idea of
glanceability is really

00:06:06.740 --> 00:06:09.660
about getting to the
essence of the information

00:06:09.660 --> 00:06:12.270
that that person needs
in the time and the place

00:06:12.270 --> 00:06:14.600
that they are.

00:06:14.600 --> 00:06:17.760
And so what does that mean
in how you design software?

00:06:17.760 --> 00:06:21.771
Well, if you look at driving
directions on Glass, when

00:06:21.771 --> 00:06:23.520
you ask for directions,
for the most part,

00:06:23.520 --> 00:06:25.040
the screen is turned off.

00:06:25.040 --> 00:06:27.060
But before you
have to turn, it'll

00:06:27.060 --> 00:06:30.290
turn on and tell you, turn
right on Greenwich Avenue

00:06:30.290 --> 00:06:33.470
in 100 feet, show you a map
of where you need to go,

00:06:33.470 --> 00:06:37.050
and then after you've completed
the turn, disappear again.

00:06:37.050 --> 00:06:38.350
This is glanceable.

00:06:38.350 --> 00:06:40.750
This is what it means to be
the rear view mirror, not

00:06:40.750 --> 00:06:43.280
the windshield.

00:06:43.280 --> 00:06:47.010
It means when you're designing
a messaging app for the watch,

00:06:47.010 --> 00:06:48.950
how minimal can you make it?

00:06:48.950 --> 00:06:51.360
What is the simplest
amount of information

00:06:51.360 --> 00:06:56.300
that the user needs to
get the task completed?

00:06:56.300 --> 00:06:58.399
Here's two designs.

00:06:58.399 --> 00:07:00.690
And the big difference between
them is that one of them

00:07:00.690 --> 00:07:04.060
has twice as much
information as the other one.

00:07:04.060 --> 00:07:06.990
On the left, six pieces
of information for a user

00:07:06.990 --> 00:07:10.210
to look at, on the
right only three.

00:07:10.210 --> 00:07:13.120
That difference is
about 900 milliseconds

00:07:13.120 --> 00:07:16.200
of attention for
someone who's focused.

00:07:16.200 --> 00:07:18.840
Now 900 milliseconds, why
would you care about that?

00:07:18.840 --> 00:07:21.010
Well, you have to remember
this person's wearing it

00:07:21.010 --> 00:07:22.130
on their wrist.

00:07:22.130 --> 00:07:24.742
They might be running
to the next meeting.

00:07:24.742 --> 00:07:26.200
Which one of these
would you rather

00:07:26.200 --> 00:07:28.910
have if you're running to the
next session in room seven?

00:07:28.910 --> 00:07:30.880
We've even played
around with, could we

00:07:30.880 --> 00:07:34.960
put an emulator like this
into the developer tools

00:07:34.960 --> 00:07:36.490
that you could play with this?

00:07:36.490 --> 00:07:39.550
But I think the real idea,
and Timothy mentioned earlier,

00:07:39.550 --> 00:07:41.915
is that none of this stuff
is particularly intuitive.

00:07:41.915 --> 00:07:44.700
It's taken us a long time to
get to where we're at today.

00:07:44.700 --> 00:07:47.525
And there's certainly
a long way to go still.

00:07:47.525 --> 00:07:48.900
And the way that
we make progress

00:07:48.900 --> 00:07:51.894
is by continually testing
on the device in the context

00:07:51.894 --> 00:07:53.310
where we mean to
use these things.

00:07:56.820 --> 00:07:58.570
This is sort of a
paradigm shift, I think,

00:07:58.570 --> 00:08:01.670
because if you look at the way
that people use their phones

00:08:01.670 --> 00:08:04.784
today, people get
out their phone,

00:08:04.784 --> 00:08:05.950
and then they do their task.

00:08:05.950 --> 00:08:07.850
And then they get distracted
by a lot of other things

00:08:07.850 --> 00:08:08.475
that are there.

00:08:08.475 --> 00:08:10.590
They got lost in
their phone, and they

00:08:10.590 --> 00:08:13.190
are taken out of the world.

00:08:13.190 --> 00:08:15.440
And what we're trying to do
with wearables is actually

00:08:15.440 --> 00:08:18.310
get to a place where people
have the same utility

00:08:18.310 --> 00:08:20.670
and benefit from computing,
but there's actually

00:08:20.670 --> 00:08:23.760
less computing in their
life because we've

00:08:23.760 --> 00:08:25.470
designed experiences
for them that

00:08:25.470 --> 00:08:28.780
are much more compact so
they can get in and out,

00:08:28.780 --> 00:08:30.290
get their goal completed.

00:08:30.290 --> 00:08:32.520
Put another way, I
think our job now

00:08:32.520 --> 00:08:36.200
as designers and developers
is to create experiences that

00:08:36.200 --> 00:08:39.039
are as short as possible,
as fast as possible,

00:08:39.039 --> 00:08:43.350
to complete the task that
the user needs to do.

00:08:43.350 --> 00:08:45.600
So we're going to talk more
about different strategies

00:08:45.600 --> 00:08:48.489
that we've developed and
ideas we have to do that.

00:08:48.489 --> 00:08:50.030
And I want to turn
over the stage now

00:08:50.030 --> 00:08:52.340
to Bob, who's going to talk
about some of the things

00:08:52.340 --> 00:08:54.467
he's learned about voice.

00:08:54.467 --> 00:08:56.800
Bob's been wearing computers
since they weren't quite so

00:08:56.800 --> 00:09:01.025
wearable, and so he has a
lot of perspective on it.

00:09:01.025 --> 00:09:02.150
BOB RYSKAMP: Thanks, Hayes.

00:09:07.740 --> 00:09:10.100
So ever since the
bike helmet days,

00:09:10.100 --> 00:09:12.090
we've been designing
our wearable products

00:09:12.090 --> 00:09:14.544
to help you be more engaged
with the real world.

00:09:14.544 --> 00:09:16.710
And one way that we've done
that is through creating

00:09:16.710 --> 00:09:20.370
natural language voice
interfaces for our products.

00:09:20.370 --> 00:09:22.810
We've tried a lot of different
interaction techniques

00:09:22.810 --> 00:09:24.950
for Wear and for Glass.

00:09:24.950 --> 00:09:27.640
And one thing we found is that
when you can speak naturally

00:09:27.640 --> 00:09:30.980
to a device, just like
you and I could talk,

00:09:30.980 --> 00:09:33.400
it makes your
interactions much faster.

00:09:33.400 --> 00:09:35.600
It makes it much easier
to stay connected

00:09:35.600 --> 00:09:38.380
to the people you're with
and the places you're in.

00:09:38.380 --> 00:09:41.000
And for wearables, this
is even more important

00:09:41.000 --> 00:09:44.590
than for some other devices.

00:09:44.590 --> 00:09:47.390
For instance, Hayes and I
both love to go cycling.

00:09:47.390 --> 00:09:51.100
And this is a fantastic place
in the world to go cycling.

00:09:51.100 --> 00:09:53.430
It's a sport that's
all about the outdoors,

00:09:53.430 --> 00:09:55.950
but it's also got a bunch
of just amazing technology

00:09:55.950 --> 00:09:58.600
that you can really get into.

00:09:58.600 --> 00:10:01.140
And it's an example
of an activity where,

00:10:01.140 --> 00:10:03.950
like Hayes said, the
world is the experience.

00:10:03.950 --> 00:10:08.910
And it's very, very important
to pay attention to it.

00:10:08.910 --> 00:10:11.990
And I also love my phone.

00:10:11.990 --> 00:10:14.560
But that same gorgeous
phone interface

00:10:14.560 --> 00:10:17.540
that works so well when
I'm sitting and standing

00:10:17.540 --> 00:10:19.750
doesn't work as well
when I'm active.

00:10:19.750 --> 00:10:21.210
Maybe my hands are sweaty.

00:10:21.210 --> 00:10:24.220
I'm trying to ride
at the same time,

00:10:24.220 --> 00:10:26.800
trying to hit those
small icons on a screen.

00:10:26.800 --> 00:10:30.320
Maybe the sun is
causing some glare.

00:10:30.320 --> 00:10:32.660
So we felt that
Glass and wearables

00:10:32.660 --> 00:10:34.980
could be great to
use while cycling.

00:10:34.980 --> 00:10:37.430
You can keep your hands
on the handlebars.

00:10:37.430 --> 00:10:39.054
You can keep your
eyes on the road.

00:10:39.054 --> 00:10:40.095
It works with your voice.

00:10:42.860 --> 00:10:45.470
But when we first started
designing the interfaces

00:10:45.470 --> 00:10:48.880
for Glass, we tried to use a
lot of the same interaction

00:10:48.880 --> 00:10:50.430
and visual design
patterns that we

00:10:50.430 --> 00:10:53.830
knew from designing for
phones and desktops.

00:10:53.830 --> 00:10:55.040
We had a screen.

00:10:55.040 --> 00:10:58.110
We put it roughly in the
middle of your perspective.

00:10:58.110 --> 00:11:00.870
You'd first try to
choose an app to run,

00:11:00.870 --> 00:11:03.430
and then you'd select
a few features.

00:11:03.430 --> 00:11:05.040
You'd choose an option.

00:11:05.040 --> 00:11:07.320
Then maybe finally you
could view individual items.

00:11:07.320 --> 00:11:09.920
You could input
some information.

00:11:09.920 --> 00:11:11.742
And with all of
those steps, we found

00:11:11.742 --> 00:11:13.950
that we weren't really
getting a different experience

00:11:13.950 --> 00:11:15.140
from the phone.

00:11:15.140 --> 00:11:17.080
You still have to
think about, what's

00:11:17.080 --> 00:11:18.810
the structure of my
operating system?

00:11:18.810 --> 00:11:21.130
And what features
does each app have?

00:11:21.130 --> 00:11:25.510
And where do I input those
information into those fields?

00:11:25.510 --> 00:11:27.280
Now this is a very
powerful system,

00:11:27.280 --> 00:11:31.687
which is why we use it
on desktops and phones.

00:11:31.687 --> 00:11:33.895
But it didn't feel appropriate
for a wearable device.

00:11:36.720 --> 00:11:38.530
And when you step back
and think about it,

00:11:38.530 --> 00:11:40.610
when you're engaged
with the real world,

00:11:40.610 --> 00:11:42.260
your interactions
aren't like that.

00:11:42.260 --> 00:11:44.960
If you're cycling with
a group of friends,

00:11:44.960 --> 00:11:47.570
you're not opening menu
options and clicking buttons.

00:11:47.570 --> 00:11:49.940
You're looking at people,
and you're talking to them.

00:11:49.940 --> 00:11:52.170
You're seeing things,
you point at them.

00:11:52.170 --> 00:11:54.660
You reach for things
and hold them.

00:11:54.660 --> 00:11:56.510
These are all very
natural interactions.

00:11:56.510 --> 00:11:59.430
You don't need a manual to
tell you how to do them.

00:11:59.430 --> 00:12:01.630
And so we wanted as
much as possible to make

00:12:01.630 --> 00:12:04.060
our experiences on
wearables more like that.

00:12:06.740 --> 00:12:09.469
For instance, we designed the
messaging experience on Glass

00:12:09.469 --> 00:12:11.260
to be as close as
possible to the way you'd

00:12:11.260 --> 00:12:13.510
talk to a close friend.

00:12:13.510 --> 00:12:16.330
OK, Glass, send a
message to Jane Williams.

00:12:16.330 --> 00:12:17.000
Hey, Jane.

00:12:17.000 --> 00:12:19.060
It was great to see you today.

00:12:19.060 --> 00:12:21.590
We even show a photo of the
person in the background

00:12:21.590 --> 00:12:23.080
while you're talking.

00:12:23.080 --> 00:12:25.040
Overall, we wanted
to make it feel

00:12:25.040 --> 00:12:26.770
like that face to
face conversation,

00:12:26.770 --> 00:12:30.570
except now you could do
it across time and space.

00:12:30.570 --> 00:12:34.190
Now this cuts out a whole bunch
of the decisions and steps

00:12:34.190 --> 00:12:37.740
required to do that same
action on a phone or a desktop.

00:12:37.740 --> 00:12:40.240
And it turns out to
be tremendously faster

00:12:40.240 --> 00:12:43.940
than pulling your phone out and
manipulating all those options.

00:12:43.940 --> 00:12:46.850
That's because when we designed
the messaging Glassware,

00:12:46.850 --> 00:12:48.880
we chose just a
single experience,

00:12:48.880 --> 00:12:51.840
sending one message
to a single contact.

00:12:51.840 --> 00:12:54.660
And we designed a unique voice
command and a unique flow

00:12:54.660 --> 00:12:56.840
for just that experience.

00:12:56.840 --> 00:12:58.870
Now if you want to look
at an older message

00:12:58.870 --> 00:13:01.131
or you want to
edit your contacts,

00:13:01.131 --> 00:13:03.130
you want to do any of the
other things you think

00:13:03.130 --> 00:13:05.760
of belong a messaging
application,

00:13:05.760 --> 00:13:08.600
you can do those in other
ways in other places.

00:13:08.600 --> 00:13:11.840
But this experience is very
singular and very focused.

00:13:11.840 --> 00:13:14.851
You do just one thing at a
time, and you see just one thing

00:13:14.851 --> 00:13:15.350
at a time.

00:13:18.330 --> 00:13:21.240
And with Android Wear, we
wanted to bring that same kind

00:13:21.240 --> 00:13:23.870
of experience to a
lot more devices.

00:13:23.870 --> 00:13:25.840
As you saw in today's
keynote, if you

00:13:25.840 --> 00:13:29.190
have a car service or a ride
sharing application installed,

00:13:29.190 --> 00:13:31.280
you can simply speak a command.

00:13:31.280 --> 00:13:34.710
OK, Google, call me a car.

00:13:34.710 --> 00:13:37.180
It's a simple natural
language command.

00:13:37.180 --> 00:13:39.610
It instantly gets a
car headed your way.

00:13:39.610 --> 00:13:42.030
Again, it's almost like
you're able to talk across

00:13:42.030 --> 00:13:46.180
the city directly to the driver.

00:13:46.180 --> 00:13:49.340
So one thing you can do to make
your wearable interface more

00:13:49.340 --> 00:13:53.550
natural is to carefully
design that voice experience.

00:13:53.550 --> 00:13:56.030
Don't just pour it over
the structure of your app

00:13:56.030 --> 00:13:59.410
from your mobile
device or your desktop.

00:13:59.410 --> 00:14:00.900
Think very carefully
about, what's

00:14:00.900 --> 00:14:04.960
that individual short experience
that people want to have?

00:14:04.960 --> 00:14:08.960
And break up that bit app
into individual flows.

00:14:08.960 --> 00:14:12.380
And then you can design and
craft one single voice action

00:14:12.380 --> 00:14:14.480
just for that flow and
just get that person

00:14:14.480 --> 00:14:18.830
that perfect experience and
make that as much like normal

00:14:18.830 --> 00:14:21.170
speech as possible.

00:14:21.170 --> 00:14:23.310
We believe that natural
language speech, when

00:14:23.310 --> 00:14:25.330
it's connected to all
the amazing services

00:14:25.330 --> 00:14:27.220
that all of you are
building, is going

00:14:27.220 --> 00:14:30.030
to make interacting with
wearables even easier

00:14:30.030 --> 00:14:34.270
and faster than using
phones and desktops.

00:14:34.270 --> 00:14:36.010
But this example of
calling for a car

00:14:36.010 --> 00:14:38.830
also does something else
to improve the experience.

00:14:38.830 --> 00:14:43.080
And that's use knowledge about
your context and where you are.

00:14:43.080 --> 00:14:45.150
So I'll next hand
over to Emmet, who

00:14:45.150 --> 00:14:47.751
is one of the founding
designers of the Wear project.

00:14:47.751 --> 00:14:49.250
And he'll walk you
through how we've

00:14:49.250 --> 00:14:52.640
been designing using context.

00:14:52.640 --> 00:14:54.290
Emmet and I worked
in Zurich together

00:14:54.290 --> 00:14:56.373
while he was working on
some of these early ideas,

00:14:56.373 --> 00:14:59.380
so I got to see all of his crazy
embarrassing early prototypes

00:14:59.380 --> 00:15:01.732
as well.

00:15:01.732 --> 00:15:02.940
EMMET CONNOLLY: Hi, everyone.

00:15:08.400 --> 00:15:11.050
So Bob talked about
how speaking a command

00:15:11.050 --> 00:15:13.930
can be one of the fastest
and easiest ways of actually

00:15:13.930 --> 00:15:15.500
performing an action.

00:15:15.500 --> 00:15:17.450
And I'm going to talk
about one way that's

00:15:17.450 --> 00:15:19.300
potentially even
faster than that.

00:15:19.300 --> 00:15:21.920
And that's to not even
speak a command at all,

00:15:21.920 --> 00:15:24.400
to just have the right
information appear

00:15:24.400 --> 00:15:27.280
automatically based
solely on the context

00:15:27.280 --> 00:15:30.060
that the user is in.

00:15:30.060 --> 00:15:31.440
So let's rewind for a minute.

00:15:31.440 --> 00:15:34.150
This is a wooden prototype
of the Palm Pilot

00:15:34.150 --> 00:15:37.820
that Jeff Hawkins made when
they were first designing

00:15:37.820 --> 00:15:41.360
and developing it, one of
the first portable computers.

00:15:41.360 --> 00:15:44.235
It's a little stylus, a
chopstick stylus, there.

00:15:44.235 --> 00:15:45.720
I love that.

00:15:45.720 --> 00:15:48.790
So before they ever
started building anything,

00:15:48.790 --> 00:15:51.526
Jeff used to carry this
around with him every day.

00:15:51.526 --> 00:15:53.026
And if someone said
to him, hey, are

00:15:53.026 --> 00:15:54.987
you free at 3 o'clock
today, or whatever,

00:15:54.987 --> 00:15:56.820
he would pull out his
little wooden computer

00:15:56.820 --> 00:15:59.160
and tap away on it
with his chopstick

00:15:59.160 --> 00:16:02.320
and pretend to actually
check if he was free.

00:16:02.320 --> 00:16:03.970
He would do this
every day for months.

00:16:03.970 --> 00:16:05.580
And what he was
actually doing was

00:16:05.580 --> 00:16:09.150
trying to figure out what it was
like to use a device like this,

00:16:09.150 --> 00:16:12.750
a new type of device at the
time, on a day to day basis

00:16:12.750 --> 00:16:15.740
and in a regular
day to day context.

00:16:15.740 --> 00:16:18.200
He was trying to figure
out what kind of UI

00:16:18.200 --> 00:16:22.020
might feel right for
this new form factor.

00:16:22.020 --> 00:16:24.990
And in retrospect, he was trying
to avoid a common mistake.

00:16:24.990 --> 00:16:28.370
It seems like that very often
when these new devices come

00:16:28.370 --> 00:16:31.710
along, the general
reaction seems

00:16:31.710 --> 00:16:35.450
to be to take the dominant
paradigm, UI paradigm,

00:16:35.450 --> 00:16:38.140
of the day and just slap
it on these new devices.

00:16:38.140 --> 00:16:40.830
And the truth is, that never
really works out all that well.

00:16:40.830 --> 00:16:43.000
You have these new
types of devices,

00:16:43.000 --> 00:16:48.580
and they're often really begging
for some new interface ideas.

00:16:48.580 --> 00:16:50.700
And to a certain extent,
we've seen this play out

00:16:50.700 --> 00:16:52.990
with the early wearables
market as well.

00:16:52.990 --> 00:16:54.590
A lot of these
devices are really

00:16:54.590 --> 00:16:58.990
just taking the grid of apps and
putting it on this tiny screen.

00:16:58.990 --> 00:17:01.690
And again, we see that this
doesn't often really work out

00:17:01.690 --> 00:17:03.390
so well.

00:17:03.390 --> 00:17:05.970
To start with, these are
really tiny tap targets.

00:17:05.970 --> 00:17:09.920
And so especially on a moving
target, it's hard to hit.

00:17:09.920 --> 00:17:12.310
You can't see very many
of these icons at once,

00:17:12.310 --> 00:17:14.630
so it's hard to build up
a spatial memory of even

00:17:14.630 --> 00:17:16.619
where everything is located.

00:17:16.619 --> 00:17:18.460
And it can just take
a lot of swiping

00:17:18.460 --> 00:17:21.045
to go through all these
screens and actually access

00:17:21.045 --> 00:17:22.670
what it is that you're
trying to access

00:17:22.670 --> 00:17:25.430
to even start with your action.

00:17:25.430 --> 00:17:27.265
So we took a step
back from this.

00:17:27.265 --> 00:17:28.640
And we tried to
think about, what

00:17:28.640 --> 00:17:31.770
if we didn't require any
input at all, that we just

00:17:31.770 --> 00:17:36.290
had the right information
show up at the right time.

00:17:36.290 --> 00:17:39.290
And this is what
we came up with.

00:17:39.290 --> 00:17:42.320
So some of you notice the subtle
detail in this photograph.

00:17:42.320 --> 00:17:44.590
Yes, it's just a phone
strapped to a wrist.

00:17:44.590 --> 00:17:45.770
Well done.

00:17:45.770 --> 00:17:48.870
But there is something
interesting happening here.

00:17:48.870 --> 00:17:50.960
This is an actual
prototype that we built.

00:17:50.960 --> 00:17:53.040
And there's no
grid of apps here.

00:17:53.040 --> 00:17:55.020
There is just one
simple clear piece

00:17:55.020 --> 00:17:58.130
of information
showing up at a time.

00:17:58.130 --> 00:18:00.140
And if another piece of
information comes along,

00:18:00.140 --> 00:18:02.590
and that's more important
for the user to know about,

00:18:02.590 --> 00:18:05.180
then we'll show that instead.

00:18:05.180 --> 00:18:07.137
So we kept thinking about this.

00:18:07.137 --> 00:18:09.720
We thought, what if there's more
than one piece of information

00:18:09.720 --> 00:18:11.320
that's useful to know about?

00:18:11.320 --> 00:18:15.190
Maybe we could arrange these
simple screens as a row

00:18:15.190 --> 00:18:17.900
or as a group of cards,
and you could just

00:18:17.900 --> 00:18:19.790
rank them and have the
most important stuff

00:18:19.790 --> 00:18:21.710
appear at the top.

00:18:21.710 --> 00:18:23.780
And you see this
thinking today reflected

00:18:23.780 --> 00:18:26.310
in the philosophy of
the Android Wear UI

00:18:26.310 --> 00:18:28.650
and also of the Glass UI.

00:18:28.650 --> 00:18:31.570
In both devices, there's just
this targeted relevant piece

00:18:31.570 --> 00:18:34.440
of information.

00:18:34.440 --> 00:18:37.050
And in both devices, the way
that you interact with them

00:18:37.050 --> 00:18:37.580
is the same.

00:18:37.580 --> 00:18:41.210
You're just swiping through this
really clear stream of cards.

00:18:41.210 --> 00:18:43.580
And it feels like
roughly the right level

00:18:43.580 --> 00:18:47.620
of interaction for these devices
in terms of the ergonomics,

00:18:47.620 --> 00:18:52.180
visually how they appear, and
just the overall interaction.

00:18:52.180 --> 00:18:54.640
So it's kind of a nice
UI model for wearables.

00:18:54.640 --> 00:18:56.190
But we still have
this problem of,

00:18:56.190 --> 00:18:59.480
how do we know when to show
the right piece of information?

00:18:59.480 --> 00:19:02.980
When do we put this
information in front of users?

00:19:02.980 --> 00:19:05.760
Well, there's something
special about these devices.

00:19:05.760 --> 00:19:08.220
They're packed
with these sensors.

00:19:08.220 --> 00:19:10.670
They're aware of their
situation and state.

00:19:10.670 --> 00:19:13.020
They're aware of the context
that they're being used in.

00:19:15.680 --> 00:19:17.600
For example, your
application can

00:19:17.600 --> 00:19:19.530
know where the user
is, potentially

00:19:19.530 --> 00:19:20.715
where they're headed.

00:19:20.715 --> 00:19:22.590
And then you can ask
yourself, what's nearby?

00:19:22.590 --> 00:19:25.820
What might be useful for
the user to know about?

00:19:25.820 --> 00:19:27.980
Your app obviously knows
what time of day it is

00:19:27.980 --> 00:19:29.910
and what date it is.

00:19:29.910 --> 00:19:32.450
And the user may have
granted permission

00:19:32.450 --> 00:19:33.930
to access their
events and what's

00:19:33.930 --> 00:19:36.900
important to them coming up.

00:19:36.900 --> 00:19:40.710
There is of course the identity
of the user, their patterns,

00:19:40.710 --> 00:19:43.450
their preferences, their habits.

00:19:43.450 --> 00:19:46.690
And then these devices
also have motion sensors.

00:19:46.690 --> 00:19:48.680
And because they're
worn on the body,

00:19:48.680 --> 00:19:53.036
we can transfer this raw motion
information into activities.

00:19:53.036 --> 00:19:55.160
And we actually have APIs
that are available to you

00:19:55.160 --> 00:19:58.240
as developers that can sense
these simple activities

00:19:58.240 --> 00:20:01.200
that you can pattern match
against, things like walking,

00:20:01.200 --> 00:20:02.890
cycling, driving, and so on.

00:20:05.590 --> 00:20:07.950
These devices are connected,
of course, and often

00:20:07.950 --> 00:20:09.960
to other nearby devices.

00:20:09.960 --> 00:20:11.590
So you can start
to ask questions

00:20:11.590 --> 00:20:13.920
like, what is the
phone doing right now?

00:20:13.920 --> 00:20:16.270
Is the TV being used?

00:20:16.270 --> 00:20:19.100
Maybe there's music
streaming to the speaker.

00:20:19.100 --> 00:20:21.140
Maybe the thermostat
knows something.

00:20:21.140 --> 00:20:25.760
And these are all signals
that add into this context.

00:20:25.760 --> 00:20:27.656
And finally there are
additional sensors,

00:20:27.656 --> 00:20:29.030
some of them built
into the Wear.

00:20:40.460 --> 00:20:41.930
I could get a
spare-- no, I'm back.

00:20:41.930 --> 00:20:42.430
OK.

00:20:53.170 --> 00:20:54.620
Is it me?

00:20:54.620 --> 00:20:56.541
I'll try and keep going.

00:20:56.541 --> 00:20:57.040
Thanks.

00:21:01.010 --> 00:21:02.570
Yeah, so there
are nearby devices

00:21:02.570 --> 00:21:05.630
that can provide the
other information, perhaps

00:21:05.630 --> 00:21:09.810
like a precise location
from Bluetooth beacons.

00:21:09.810 --> 00:21:12.050
So the real interesting
thing happens

00:21:12.050 --> 00:21:15.220
when we take the combined total
of all of this sensor data

00:21:15.220 --> 00:21:18.180
and put it together into
one single rich picture

00:21:18.180 --> 00:21:20.540
of the user's situation,
the scenario that they're

00:21:20.540 --> 00:21:22.360
in right now.

00:21:22.360 --> 00:21:24.660
So as developers, we can
look at this situation

00:21:24.660 --> 00:21:26.600
and we can ask
ourselves the question,

00:21:26.600 --> 00:21:29.160
how can we present the user
with useful information

00:21:29.160 --> 00:21:31.192
that will help them?

00:21:31.192 --> 00:21:33.150
And for you guys as
developers, what you can do

00:21:33.150 --> 00:21:37.010
is define detailed
contextual trigger conditions

00:21:37.010 --> 00:21:40.390
and have your app show up
at precisely the right time

00:21:40.390 --> 00:21:42.640
based on those
trigger conditions.

00:21:42.640 --> 00:21:46.630
So let's look at a
practical example now.

00:21:46.630 --> 00:21:51.450
So first we'll look at a typical
interaction as it exists today.

00:21:51.450 --> 00:21:53.450
Let's say you're
going for a run.

00:21:53.450 --> 00:21:55.640
You probably pull
out your phone,

00:21:55.640 --> 00:22:00.030
then you launch a running
app, maybe tap in some goals.

00:22:00.030 --> 00:22:02.630
You might decide to switch
over to a music app,

00:22:02.630 --> 00:22:05.490
queue up that album that you
had been listening to earlier,

00:22:05.490 --> 00:22:08.250
switch back to the
running app, tap Start

00:22:08.250 --> 00:22:11.430
so that you can get going,
strap the phone onto your arm.

00:22:11.430 --> 00:22:12.740
And off you go.

00:22:12.740 --> 00:22:16.830
Fairly typical interaction
that we're probably used to.

00:22:16.830 --> 00:22:20.370
Now we'll try and redesign
this experience for wearables

00:22:20.370 --> 00:22:22.415
using context to
drive the interaction.

00:22:26.220 --> 00:22:30.840
So in this case, assume you're
using an Android Wear device.

00:22:30.840 --> 00:22:32.690
It's a pleasant
Sunday afternoon.

00:22:32.690 --> 00:22:34.380
You're at the head
of your running trail

00:22:34.380 --> 00:22:36.740
that maybe you run
at most Sundays.

00:22:36.740 --> 00:22:40.230
You probably just stretch
out, plug in your headphones,

00:22:40.230 --> 00:22:42.450
and start running.

00:22:42.450 --> 00:22:46.030
So based just on the simple
inputs from our sensors,

00:22:46.030 --> 00:22:47.840
the things that we
can detect, things

00:22:47.840 --> 00:22:52.580
like the time, the location,
your habits, physical movement,

00:22:52.580 --> 00:22:55.140
even what the headphone
jack is doing,

00:22:55.140 --> 00:22:58.480
it really looks like this person
is going for a run right now.

00:22:58.480 --> 00:23:01.180
So why shouldn't we
do the obvious thing

00:23:01.180 --> 00:23:03.410
and present them with
helpful information?

00:23:03.410 --> 00:23:05.770
In this case, it would be
something like start tracking

00:23:05.770 --> 00:23:11.440
their run and perhaps also offer
to pick up playing that album.

00:23:11.440 --> 00:23:13.800
So the user didn't have to
do very much at all here.

00:23:13.800 --> 00:23:16.300
They just acted as
they normally would.

00:23:16.300 --> 00:23:19.142
And the technology does the
right thing automatically.

00:23:19.142 --> 00:23:20.100
It was like Hayes said.

00:23:20.100 --> 00:23:22.900
The world is the experience,
and the technology just

00:23:22.900 --> 00:23:26.940
adapts to what
the user is doing.

00:23:26.940 --> 00:23:29.280
So again, rather
than asking the user

00:23:29.280 --> 00:23:32.530
to manually tell the device
what they want to do and then

00:23:32.530 --> 00:23:34.942
have to manage state
on an ongoing basis,

00:23:34.942 --> 00:23:37.150
on wearables we're going to
do something much simpler

00:23:37.150 --> 00:23:37.840
than that.

00:23:37.840 --> 00:23:40.620
We're going to do all the
heavy lifting for them based

00:23:40.620 --> 00:23:43.590
on context and present them
with just the right information

00:23:43.590 --> 00:23:45.920
at the right time.

00:23:45.920 --> 00:23:47.450
So that was a simple example.

00:23:47.450 --> 00:23:51.540
Next up, Alex is going to talk
you through some more examples

00:23:51.540 --> 00:23:53.876
and also introduce you
to some design tools that

00:23:53.876 --> 00:23:55.250
will help you
apply this thinking

00:23:55.250 --> 00:23:56.291
to your own applications.

00:24:01.171 --> 00:24:02.170
ALEX FAABORG: All right.

00:24:02.170 --> 00:24:03.717
So that was a lot
of information.

00:24:03.717 --> 00:24:05.300
And this is a new
form factor, so that

00:24:05.300 --> 00:24:08.700
means thinking about building
entirely new types of software.

00:24:08.700 --> 00:24:10.514
But it also means a
lot of opportunities

00:24:10.514 --> 00:24:11.930
to build breakthrough
applications

00:24:11.930 --> 00:24:13.180
because this is
a new form factor

00:24:13.180 --> 00:24:14.540
and we're just getting started.

00:24:14.540 --> 00:24:16.370
So first let's summarize.

00:24:16.370 --> 00:24:18.930
Hayes talked about how the
world is the experience, sunsets

00:24:18.930 --> 00:24:20.430
and puppies and
these things that we

00:24:20.430 --> 00:24:23.072
care about more than having
to interact with devices.

00:24:23.072 --> 00:24:25.280
And how do we achieve the
world being the experience?

00:24:25.280 --> 00:24:27.946
Well, we achieve it by having
the user be in the world more.

00:24:27.946 --> 00:24:29.820
And we can do that
through micro interactions

00:24:29.820 --> 00:24:31.800
so that you're more present
ad engaged in the real world.

00:24:31.800 --> 00:24:33.010
But you're also more
connected virtually

00:24:33.010 --> 00:24:34.343
because you have more check-ins.

00:24:34.343 --> 00:24:36.850
It's just your engagement with
the technology is shorter.

00:24:36.850 --> 00:24:38.558
How do we make those
engagements shorter?

00:24:38.558 --> 00:24:40.120
How do we achieve
micro interactions?

00:24:40.120 --> 00:24:43.190
Well, the two core components,
voice, as Bob talked about,

00:24:43.190 --> 00:24:46.430
and context, as
Emmet talked about.

00:24:46.430 --> 00:24:48.410
So now you're thinking, OK.

00:24:48.410 --> 00:24:50.769
That sounds cool, but
where do I actually start?

00:24:50.769 --> 00:24:52.060
I want to build an application.

00:24:52.060 --> 00:24:54.760
We've got this OS that's built
around voice and context,

00:24:54.760 --> 00:24:56.540
but how do I translate my app?

00:24:56.540 --> 00:24:59.020
How do I build an entirely
new app for this platform?

00:24:59.020 --> 00:25:00.910
And of course it's good to start
sketching, but at this stage,

00:25:00.910 --> 00:25:02.826
you're just looking at
a blank piece of paper,

00:25:02.826 --> 00:25:03.909
and you're kind of lost.

00:25:03.909 --> 00:25:05.950
So I want you to consider
two thought experiments

00:25:05.950 --> 00:25:07.533
to kind of ground
your thinking in how

00:25:07.533 --> 00:25:10.860
to approach wearable
applications.

00:25:10.860 --> 00:25:12.450
So the first one's about voice.

00:25:12.450 --> 00:25:14.149
Now imagine that
you are your app.

00:25:14.149 --> 00:25:16.440
And the only way that the
user can communicate with you

00:25:16.440 --> 00:25:17.890
is through voice.

00:25:17.890 --> 00:25:19.784
So as the app, you're
sitting in a room.

00:25:19.784 --> 00:25:20.950
It's a very nice white room.

00:25:20.950 --> 00:25:22.330
And the only thing in
the room is a pedestal,

00:25:22.330 --> 00:25:23.930
and there's this
red telephone on it.

00:25:23.930 --> 00:25:25.280
And when the user
needs something,

00:25:25.280 --> 00:25:26.330
that telephone's going to ring.

00:25:26.330 --> 00:25:28.100
Then you're going to answer
it, and it's the user.

00:25:28.100 --> 00:25:30.420
And they're going to say exactly
what they need from the app.

00:25:30.420 --> 00:25:31.710
So what's the first
thing that the user

00:25:31.710 --> 00:25:33.086
says when you pick
up that phone?

00:25:33.086 --> 00:25:34.626
What's the range of
calls that you're

00:25:34.626 --> 00:25:36.170
expecting to get
throughout the day?

00:25:36.170 --> 00:25:38.080
How does the user
phrase the request?

00:25:38.080 --> 00:25:39.050
And the great thing
about building

00:25:39.050 --> 00:25:40.841
on top of Google's
voice recognition system

00:25:40.841 --> 00:25:43.310
is that we're building out
all of the capabilities.

00:25:43.310 --> 00:25:46.240
We're actually handling
all of the transcription

00:25:46.240 --> 00:25:48.384
and natural language
processing and grammars.

00:25:48.384 --> 00:25:50.050
And all you have to
do is just subscribe

00:25:50.050 --> 00:25:51.490
to a particular intent.

00:25:51.490 --> 00:25:54.202
But then the question is,
which intents do you want?

00:25:54.202 --> 00:25:55.660
So as we're building
up the system,

00:25:55.660 --> 00:25:56.900
we really definitely
want to hear from you

00:25:56.900 --> 00:25:58.265
about the applications
you're trying to build

00:25:58.265 --> 00:26:00.670
and which voice intents you're
interested in so we can start

00:26:00.670 --> 00:26:02.260
working on those and getting
those into the system

00:26:02.260 --> 00:26:04.137
so that your apps can
subscribe to them.

00:26:04.137 --> 00:26:06.470
So you can go to this form,
just fill it out and tell us

00:26:06.470 --> 00:26:08.428
what you're interested
in the voice recognition

00:26:08.428 --> 00:26:09.640
system being capable of.

00:26:09.640 --> 00:26:13.160
And we'll show some examples
of what it can currently do.

00:26:13.160 --> 00:26:15.530
So the second thought
experiment is about context.

00:26:15.530 --> 00:26:17.299
And as Emmet said,
even faster than voice

00:26:17.299 --> 00:26:19.090
is the application
being able to anticipate

00:26:19.090 --> 00:26:21.060
the information that you need.

00:26:21.060 --> 00:26:23.410
So for here, I want you
to think about this moment

00:26:23.410 --> 00:26:25.710
where a surgeon
reaches out their hand

00:26:25.710 --> 00:26:29.350
and immediately, without
ever having to look away,

00:26:29.350 --> 00:26:31.660
the tool that they need
is placed in that hand.

00:26:31.660 --> 00:26:33.520
And what's interesting
about context

00:26:33.520 --> 00:26:35.954
is contextual currents
aren't meant to be surprises.

00:26:35.954 --> 00:26:38.120
Users are going to reach
out their hand for your app

00:26:38.120 --> 00:26:39.200
at various times.

00:26:39.200 --> 00:26:40.700
They're going to
adapt to the system

00:26:40.700 --> 00:26:42.650
as much as the system's
adapting to them.

00:26:42.650 --> 00:26:44.520
And they're expecting
the app to be there.

00:26:44.520 --> 00:26:46.700
So imagine that
you're with the user

00:26:46.700 --> 00:26:48.270
and you have the app ready.

00:26:48.270 --> 00:26:50.090
And you're ready to give the
user the app at any moment.

00:26:50.090 --> 00:26:52.256
When do you expect the user
to reach their hand out?

00:26:52.256 --> 00:26:53.900
What's going on
in that situation?

00:26:53.900 --> 00:26:54.925
What's the environment?

00:26:54.925 --> 00:26:56.300
And then as you
think about that,

00:26:56.300 --> 00:26:58.350
you can think about how you can
build the contextual trigger

00:26:58.350 --> 00:26:59.880
conditions so that
the card is there

00:26:59.880 --> 00:27:03.771
on their device at
just the right moment.

00:27:03.771 --> 00:27:05.812
So we're almost ready to
start sketching our app,

00:27:05.812 --> 00:27:07.730
but we still have this
blank piece of paper.

00:27:07.730 --> 00:27:09.760
And one thing that's
really useful for sketching

00:27:09.760 --> 00:27:11.480
applications is, of
course, stencils.

00:27:11.480 --> 00:27:14.705
This is a stencil that was made
for Android phone applications.

00:27:14.705 --> 00:27:15.670
And it's really great.

00:27:15.670 --> 00:27:17.586
You have all the patterns,
and you can quickly

00:27:17.586 --> 00:27:18.900
sketch out all of your screens.

00:27:18.900 --> 00:27:19.890
So then the question
is, well, what

00:27:19.890 --> 00:27:22.410
does a stencil look like
for wearable applications?

00:27:22.410 --> 00:27:24.160
So we started playing
around with that.

00:27:24.160 --> 00:27:24.990
And we haven't
actually built it,

00:27:24.990 --> 00:27:27.650
but here's a picture of what
we think it would look like.

00:27:27.650 --> 00:27:30.527
So what's sort of interesting
is of course voice, right?

00:27:30.527 --> 00:27:32.860
We're just hoping to have
something with speech bubbles,

00:27:32.860 --> 00:27:35.775
where you can draw speech
bubbles, sort of sketch what

00:27:35.775 --> 00:27:37.296
you expect the user to say.

00:27:37.296 --> 00:27:39.670
And then next we have context,
all the contextual trigger

00:27:39.670 --> 00:27:41.670
conditions that Emmet
was talking about.

00:27:41.670 --> 00:27:43.730
And only then do we move
on to then sketching

00:27:43.730 --> 00:27:45.860
the actual UI on the watch,
the card that appears

00:27:45.860 --> 00:27:50.010
or the screen that's a
result of the voice action.

00:27:50.010 --> 00:27:52.494
So let's look at some
examples of voice.

00:27:52.494 --> 00:27:53.910
The talk's been
pretty high level,

00:27:53.910 --> 00:27:56.160
but I want to run through
some very specific examples,

00:27:56.160 --> 00:27:58.890
a few apps that are
actually already available.

00:27:58.890 --> 00:28:00.970
So imagine you're going
furniture shopping,

00:28:00.970 --> 00:28:01.960
and you see a new
couch that you're

00:28:01.960 --> 00:28:03.650
interested in that
you want to remember.

00:28:03.650 --> 00:28:05.610
You can just say, OK,
Google, take a note.

00:28:05.610 --> 00:28:07.651
And apps can subscribe to
the take a note intent.

00:28:07.651 --> 00:28:10.140
So in this case, Evernote
is the user's favorite note

00:28:10.140 --> 00:28:12.639
application, but it could be
any number of note applications

00:28:12.639 --> 00:28:15.410
that the user likes to use.

00:28:15.410 --> 00:28:17.899
Say you're going for the
run, back to Emmet's example.

00:28:17.899 --> 00:28:19.440
And as you're running,
you're curious

00:28:19.440 --> 00:28:20.439
what your heart rate is.

00:28:20.439 --> 00:28:22.830
So you can just say, OK,
Google, what's my heart rate?

00:28:22.830 --> 00:28:24.352
And if the device
has the sensor,

00:28:24.352 --> 00:28:26.560
that'll be available just
with a quick voice command.

00:28:26.560 --> 00:28:29.624
And this is another intent
that we currently support.

00:28:29.624 --> 00:28:32.040
Then at the end of the run,
if you want to stop recording,

00:28:32.040 --> 00:28:34.370
you can just say, OK,
Google, stop running.

00:28:34.370 --> 00:28:36.150
And apps can subscribe
to that intent.

00:28:36.150 --> 00:28:40.040
So we have all of these various
natural language processing

00:28:40.040 --> 00:28:41.880
grammars built up for
all the different ways

00:28:41.880 --> 00:28:43.213
that users can say these things.

00:28:43.213 --> 00:28:45.350
But from the app side, all
they have to think about

00:28:45.350 --> 00:28:48.320
is they're subscribing to
stop a run or take a note

00:28:48.320 --> 00:28:51.860
or what the basic intents are.

00:28:51.860 --> 00:28:53.690
Let's look at some
examples for context.

00:28:53.690 --> 00:28:55.315
There's a few really
good ones on Glass

00:28:55.315 --> 00:28:56.570
that are already shipping.

00:28:56.570 --> 00:28:58.460
This is LynxFit.

00:28:58.460 --> 00:29:00.260
Developers are
actually in the room.

00:29:00.260 --> 00:29:02.254
They did an awesome job.

00:29:02.254 --> 00:29:03.420
[? Huzzah, Bob ?] might say.

00:29:03.420 --> 00:29:04.770
It's so good.

00:29:04.770 --> 00:29:08.020
So how this works is it's
going to use motion sensors

00:29:08.020 --> 00:29:10.580
to actually watch
you do the workout.

00:29:10.580 --> 00:29:13.460
And it guides you
by speaking to you

00:29:13.460 --> 00:29:15.410
and showing you quick
little video clips.

00:29:15.410 --> 00:29:17.597
And it really works like
a personal trainer would

00:29:17.597 --> 00:29:19.680
in real life, in that it's
giving you instructions

00:29:19.680 --> 00:29:21.560
and it's actually
observing your motion.

00:29:21.560 --> 00:29:22.310
And this is great.

00:29:22.310 --> 00:29:24.351
I mean, it doesn't get
more contextual than this.

00:29:24.351 --> 00:29:26.970
It's like actually
recording each motion.

00:29:26.970 --> 00:29:29.566
Another example of
context is Field Trip,

00:29:29.566 --> 00:29:31.940
where this shows you information
about your surroundings.

00:29:31.940 --> 00:29:33.898
In this case, the user's
interested in history,

00:29:33.898 --> 00:29:36.590
so they're seeing some
historical information.

00:29:36.590 --> 00:29:37.590
This one's pretty crazy.

00:29:37.590 --> 00:29:39.110
It's 94Fifty.

00:29:39.110 --> 00:29:40.690
It uses a special
basketball that

00:29:40.690 --> 00:29:43.790
has sensors that can
sense your shot style.

00:29:43.790 --> 00:29:46.030
And it gives you feedback
on the shot on Glass.

00:29:46.030 --> 00:29:47.935
This is also kind of a good
example of the world being

00:29:47.935 --> 00:29:49.510
the experience because,
really, the experience

00:29:49.510 --> 00:29:51.130
here is you're
shooting a basketball.

00:29:51.130 --> 00:29:53.130
But this is just giving
you some additional data

00:29:53.130 --> 00:29:55.690
to help you have a better shot.

00:29:55.690 --> 00:29:56.980
Similar example with golf.

00:29:56.980 --> 00:29:58.830
This is Swingbyte,
which connects

00:29:58.830 --> 00:30:00.340
to a sensor on your club.

00:30:00.340 --> 00:30:02.520
And this logs all sorts
of really useful data

00:30:02.520 --> 00:30:03.614
as you're playing.

00:30:03.614 --> 00:30:05.280
In some ways, it's
kind of like a caddy,

00:30:05.280 --> 00:30:06.946
but it's even more
accurate than a caddy

00:30:06.946 --> 00:30:09.480
because it has really
detailed information.

00:30:09.480 --> 00:30:12.120
So let's look at some
examples on Wear.

00:30:12.120 --> 00:30:14.690
So imagine your friend has an
Pinterest board of the best

00:30:14.690 --> 00:30:16.210
gummy candy in North America.

00:30:16.210 --> 00:30:18.470
And of course, you're
going to subscribe to that.

00:30:18.470 --> 00:30:20.620
So you subscribed to
it a long time ago.

00:30:20.620 --> 00:30:21.590
You've since forgotten.

00:30:21.590 --> 00:30:24.220
But as you're traveling
and you're walking around,

00:30:24.220 --> 00:30:25.652
Pinterest fires,
and it says, hey,

00:30:25.652 --> 00:30:27.360
one of the pins that
you're interested in

00:30:27.360 --> 00:30:28.568
is actually walking distance.

00:30:28.568 --> 00:30:31.390
You can go check it out because
it knew that that was something

00:30:31.390 --> 00:30:33.260
that you were interested in.

00:30:33.260 --> 00:30:36.190
And this is currently available.

00:30:36.190 --> 00:30:39.130
Another great application from
Trulia, this one's really cool.

00:30:39.130 --> 00:30:42.120
So as you're going to
open houses, when you're

00:30:42.120 --> 00:30:44.120
near the property it's
going to show information

00:30:44.120 --> 00:30:45.180
about the property.

00:30:45.180 --> 00:30:47.390
It gives you actions like
you can call the agent.

00:30:47.390 --> 00:30:49.100
You can quickly
favorite the property.

00:30:49.100 --> 00:30:51.190
And again, this is very much
the world is the experience.

00:30:51.190 --> 00:30:53.250
It's kind of like you're
right clicking on the world.

00:30:53.250 --> 00:30:55.208
It's like the world has
a contextual menu where

00:30:55.208 --> 00:30:57.830
you can just say, like,
favorite this property, which

00:30:57.830 --> 00:31:00.101
I think this one's really cool.

00:31:00.101 --> 00:31:00.601
All right.

00:31:00.601 --> 00:31:02.750
So let's look at a few more
were hypothetical examples.

00:31:02.750 --> 00:31:03.900
So imagine you're at home.

00:31:03.900 --> 00:31:06.000
Your device detects that
you're at home, gives you

00:31:06.000 --> 00:31:08.747
controls for your thermostat.

00:31:08.747 --> 00:31:11.330
Imagine you're going skiing and
the conditions are pretty icy.

00:31:11.330 --> 00:31:13.879
But since you're inside the
grounds of the ski resort,

00:31:13.879 --> 00:31:15.420
your device could
just tell you which

00:31:15.420 --> 00:31:17.607
lifts are running, which
trails have been groomed,

00:31:17.607 --> 00:31:19.940
all the contextual information
that you want right then.

00:31:22.790 --> 00:31:24.220
Imagine you're at the airport.

00:31:24.220 --> 00:31:25.590
And as you're scrolling
through your cards,

00:31:25.590 --> 00:31:27.440
you see that the
airline that you're on

00:31:27.440 --> 00:31:31.045
is providing information on
how many miles you've acquired

00:31:31.045 --> 00:31:31.920
and how you're doing.

00:31:34.550 --> 00:31:36.540
You're staying at a
hotel, and the hotel chain

00:31:36.540 --> 00:31:38.650
recognizes that you're on
one of their properties.

00:31:38.650 --> 00:31:40.230
They can give you
quick access to actions

00:31:40.230 --> 00:31:41.605
like requesting
a late check-out.

00:31:44.240 --> 00:31:45.690
Imagine you're at a conference.

00:31:45.690 --> 00:31:47.480
Social network could
tell you, hey, here's

00:31:47.480 --> 00:31:48.990
some friends that you have
that you haven't actually

00:31:48.990 --> 00:31:49.730
seen in a long time.

00:31:49.730 --> 00:31:50.880
But they're also
at the conference,

00:31:50.880 --> 00:31:52.046
if you guys want to meet up.

00:31:54.770 --> 00:31:57.190
If you're at a restaurant,
a nutritional application

00:31:57.190 --> 00:31:59.570
could detect which
restaurant chain you're in,

00:31:59.570 --> 00:32:01.870
quickly look up nutritional
information for that chain

00:32:01.870 --> 00:32:04.369
and provide suggestions of the
healthiest items on the menu.

00:32:06.872 --> 00:32:08.830
Say you're getting the
oil changed in your car.

00:32:08.830 --> 00:32:10.454
You could have an
assistant application

00:32:10.454 --> 00:32:11.992
that recognizes
that and just offers

00:32:11.992 --> 00:32:13.700
to set a reminder for
another six months.

00:32:16.424 --> 00:32:18.840
You're at the zoo, and you
have a watch that automatically

00:32:18.840 --> 00:32:20.673
knows when the penguins
are going to be fed.

00:32:23.315 --> 00:32:24.940
Imagine if you're
able to ask real time

00:32:24.940 --> 00:32:26.104
location-based questions.

00:32:26.104 --> 00:32:27.520
And people using
the service could

00:32:27.520 --> 00:32:28.970
choose if they
wanted to respond.

00:32:28.970 --> 00:32:30.040
And these wouldn't
be interruptive.

00:32:30.040 --> 00:32:32.000
But if you saw one come by
as you were using the device

00:32:32.000 --> 00:32:34.160
and you felt like responding,
you could help them out.

00:32:34.160 --> 00:32:36.243
So questions that you could
otherwise never search

00:32:36.243 --> 00:32:38.450
for, you could use,
like saying, are there

00:32:38.450 --> 00:32:40.700
any picnic tables free, and
getting an answer to that.

00:32:43.569 --> 00:32:45.360
Imagine you're using
a car sharing service.

00:32:45.360 --> 00:32:46.720
And as you approach
the vehicle, you

00:32:46.720 --> 00:32:48.310
get a quick action
to unlock the car.

00:32:53.291 --> 00:32:55.540
So what's sort of interesting
about all those examples

00:32:55.540 --> 00:32:57.750
is that the UI wasn't
actually that complicated.

00:32:57.750 --> 00:32:59.683
The UI's usually just
a card or a button.

00:32:59.683 --> 00:33:02.010
And when you look
at the stencil,

00:33:02.010 --> 00:33:04.100
there's not much of the
stencil devoted to the UI.

00:33:04.100 --> 00:33:06.266
This isn't about sketching
a variety of different UI

00:33:06.266 --> 00:33:07.050
widgets.

00:33:07.050 --> 00:33:10.004
What the stencil is about
is the user and their world.

00:33:10.004 --> 00:33:11.670
It's about what the
user's going to say.

00:33:11.670 --> 00:33:13.919
It's about what the contextual
trigger conditions are.

00:33:13.919 --> 00:33:15.587
Even with our mock-ups,
we focused more

00:33:15.587 --> 00:33:17.170
on sort of the
background of the scene

00:33:17.170 --> 00:33:18.664
than when the device came up.

00:33:18.664 --> 00:33:20.330
So what's really
important when thinking

00:33:20.330 --> 00:33:21.710
about these wearable
applications

00:33:21.710 --> 00:33:26.000
is thinking about the world
and what the user needs.

00:33:26.000 --> 00:33:27.460
And we ran through
a bunch of them,

00:33:27.460 --> 00:33:30.060
but this brings us back to our
overall notion of the world

00:33:30.060 --> 00:33:30.950
being the experience.

00:33:30.950 --> 00:33:32.908
It's really being the
thing that drives the use

00:33:32.908 --> 00:33:35.010
cases for these
wearable applications.

00:33:35.010 --> 00:33:36.550
And the world's a big place.

00:33:36.550 --> 00:33:38.091
So there's really
a tremendous amount

00:33:38.091 --> 00:33:40.640
of opportunity for really
interesting applications built

00:33:40.640 --> 00:33:43.140
in this space by
designers and developers.

00:33:43.140 --> 00:33:45.270
Google's crafting the
infrastructure with APIs

00:33:45.270 --> 00:33:47.840
for voice and context that
you guys can build on.

00:33:47.840 --> 00:33:50.500
And this is in the same spirit
as our initial work on Google

00:33:50.500 --> 00:33:52.083
Now, but we're opening
up the platform

00:33:52.083 --> 00:33:54.350
to the entire ecosystem for
contextual cards and voice

00:33:54.350 --> 00:33:54.910
actions.

00:33:54.910 --> 00:33:57.100
And really, together we'll
be able to build things

00:33:57.100 --> 00:33:58.630
that are really
far beyond anything

00:33:58.630 --> 00:34:01.634
that we could build on our own.

00:34:01.634 --> 00:34:03.050
So a quick
announcement, which you

00:34:03.050 --> 00:34:04.626
may have heard in
the last session.

00:34:04.626 --> 00:34:06.000
If you're watching
this on video,

00:34:06.000 --> 00:34:08.659
check out Timothy's session,
Wearable Computing at Google.

00:34:08.659 --> 00:34:09.949
Wear notifications
are going to start

00:34:09.949 --> 00:34:11.704
appearing on Glass in the
next few months, which

00:34:11.704 --> 00:34:14.120
will make life much easier for
developers because they can

00:34:14.120 --> 00:34:15.800
develop for both
devices simultaneously.

00:34:15.800 --> 00:34:17.820
And this will get you
access to pages, stacks,

00:34:17.820 --> 00:34:20.620
voice replies, and actions.

00:34:20.620 --> 00:34:22.969
And with that, we'd love
to take your questions.

00:34:22.969 --> 00:34:23.469
Thank you.

00:34:39.170 --> 00:34:39.770
Any questions?

00:34:39.770 --> 00:34:41.770
BOB RYSKAMP: We've got
microphones in the center

00:34:41.770 --> 00:34:45.069
if you want to step up to those.

00:34:45.069 --> 00:34:48.640
Give people a second.

00:34:48.640 --> 00:34:49.630
AUDIENCE: Hi.

00:34:49.630 --> 00:34:53.270
I have a question
about the Wear.

00:34:53.270 --> 00:34:55.280
And [? blocking ?]
out the SDK doesn't

00:34:55.280 --> 00:34:57.170
allow you to modify
the notifications

00:34:57.170 --> 00:35:00.620
that it can post
from your phone APK.

00:35:00.620 --> 00:35:03.880
Is there a reason why the
design has been in such a way

00:35:03.880 --> 00:35:06.260
that the developer
doesn't fully control

00:35:06.260 --> 00:35:09.490
the layout of the notification?

00:35:09.490 --> 00:35:11.530
You have to actually
build an APK for the Wear

00:35:11.530 --> 00:35:15.030
in order to do design a layout
that uses the full screen.

00:35:15.030 --> 00:35:17.310
You're sort of bound
in that tiny square

00:35:17.310 --> 00:35:18.170
of the notification.

00:35:18.170 --> 00:35:19.810
What was the reasoning behind?

00:35:19.810 --> 00:35:21.809
ALEX FAABORG: So the nice
thing about developers

00:35:21.809 --> 00:35:24.070
using templates is then as
new form factors come out,

00:35:24.070 --> 00:35:26.070
those notifications can
be automatically adapted

00:35:26.070 --> 00:35:28.380
to the new form factor.

00:35:28.380 --> 00:35:31.370
Even for Wear, we have square
and circular devices, right?

00:35:31.370 --> 00:35:32.470
So that's pretty useful.

00:35:32.470 --> 00:35:34.290
So it provides less
work for the developer

00:35:34.290 --> 00:35:35.430
when you're using one
of those templates

00:35:35.430 --> 00:35:36.730
because you just know
you're sort of guaranteed

00:35:36.730 --> 00:35:38.310
for all future form factors.

00:35:38.310 --> 00:35:40.290
But you can of course
create an activity view

00:35:40.290 --> 00:35:41.800
and control every
pixel if you want.

00:35:41.800 --> 00:35:44.242
Then it's more overhead for
testing on the new devices

00:35:44.242 --> 00:35:46.200
and making sure everything's
working correctly.

00:35:46.200 --> 00:35:46.650
AUDIENCE: Right.

00:35:46.650 --> 00:35:48.108
Is there a plan in
the future where

00:35:48.108 --> 00:35:50.740
you would allow developers
to completely custom design

00:35:50.740 --> 00:35:52.360
the layout of the notifications?

00:35:52.360 --> 00:35:54.401
ALEX FAABORG: Yeah, that
actually launched today.

00:35:54.401 --> 00:35:56.425
The Wear SDK lets
you do activity views

00:35:56.425 --> 00:35:58.450
inside cards, where
you can do the full UI.

00:35:58.450 --> 00:35:59.200
AUDIENCE: Awesome.

00:35:59.200 --> 00:35:59.700
Thank you.

00:35:59.700 --> 00:36:02.280
ALEX FAABORG: No problem.

00:36:02.280 --> 00:36:03.020
AUDIENCE: Hi.

00:36:03.020 --> 00:36:04.080
My name is Jonathan.

00:36:04.080 --> 00:36:08.090
I want to ask when
will we see some more

00:36:08.090 --> 00:36:10.160
sensors on the
Android Wear devices?

00:36:10.160 --> 00:36:14.020
I mean, temperature,
moisture, some more.

00:36:14.020 --> 00:36:15.730
I mean, the LG doesn't
have a heart rate.

00:36:15.730 --> 00:36:18.250
And most of the really
interesting applications

00:36:18.250 --> 00:36:20.183
would be around more sensors.

00:36:20.183 --> 00:36:20.974
ALEX FAABORG: Yeah.

00:36:20.974 --> 00:36:24.025
Well, I think as people are
seeing the types of apps

00:36:24.025 --> 00:36:26.570
that developers want to build
and the ecosystem's growing,

00:36:26.570 --> 00:36:28.640
we're going to see a lot of
innovation in this space.

00:36:28.640 --> 00:36:30.223
And one of the great
things about Wear

00:36:30.223 --> 00:36:32.120
is we're going to
have lots of devices.

00:36:32.120 --> 00:36:35.180
So that will enable competition
in the marketplace for people

00:36:35.180 --> 00:36:37.960
to add sensors and have
really cool use cases.

00:36:37.960 --> 00:36:40.175
AUDIENCE: Any known
watches coming out

00:36:40.175 --> 00:36:41.092
with multiple sensors?

00:36:41.092 --> 00:36:43.508
ALEX FAABORG: I can't-- I'm
not going to preannounce other

00:36:43.508 --> 00:36:44.130
watches.

00:36:44.130 --> 00:36:44.440
AUDIENCE: Thanks.

00:36:44.440 --> 00:36:45.606
ALEX FAABORG: Theoretically.

00:36:48.070 --> 00:36:50.500
AUDIENCE: Thank you all
for the presentation.

00:36:50.500 --> 00:36:53.670
So you've been mentioning
all these things

00:36:53.670 --> 00:36:56.990
where smartwatches and
smartglasses are similar

00:36:56.990 --> 00:37:02.760
and how Android Wear is going to
work with both Glass and Wear.

00:37:02.760 --> 00:37:05.240
So my question is
exactly the opposite.

00:37:05.240 --> 00:37:08.220
Where do you see Glass and
smartwatches being totally very

00:37:08.220 --> 00:37:09.340
different?

00:37:09.340 --> 00:37:11.486
And this is for any of you.

00:37:11.486 --> 00:37:15.260
What's the feature where
a smartwatch makes sense

00:37:15.260 --> 00:37:18.782
but Glass doesn't,
and vice versa?

00:37:18.782 --> 00:37:20.490
ALEX FAABORG: You want
to take that, Bob?

00:37:20.490 --> 00:37:21.270
BOB RYSKAMP: Sure.

00:37:21.270 --> 00:37:24.110
I think as Timothy Jordan
said in the last session,

00:37:24.110 --> 00:37:26.990
a lot of it does come down
to the individual user,

00:37:26.990 --> 00:37:28.890
what people's preferences are.

00:37:28.890 --> 00:37:30.740
I think one thing I've
found while working

00:37:30.740 --> 00:37:33.980
on wearable devices is they're
much more like other things you

00:37:33.980 --> 00:37:38.460
wear like shoes and socks and
shirts and jackets and hats

00:37:38.460 --> 00:37:42.050
and actually less like phones
and tablets in a lot of ways,

00:37:42.050 --> 00:37:44.880
in that you might
one day wear one,

00:37:44.880 --> 00:37:47.260
another day wear
another, depending

00:37:47.260 --> 00:37:49.120
on what you plan to do that day.

00:37:49.120 --> 00:37:55.280
For example, myself, I love to
wear the watch around my house.

00:37:55.280 --> 00:37:57.480
It frees me from my phone,
which can be downstairs

00:37:57.480 --> 00:38:00.190
and I can still get
my notifications.

00:38:00.190 --> 00:38:02.920
But I love to wear Glass when
I'm cycling or when I'm playing

00:38:02.920 --> 00:38:05.220
with my one-and-a-half-year-old.

00:38:05.220 --> 00:38:07.800
It's the world's
best baby camera.

00:38:07.800 --> 00:38:09.790
So I'll take one off,
put one on depending

00:38:09.790 --> 00:38:12.790
on what I want to do that day.

00:38:12.790 --> 00:38:16.580
I think that's probably the
future of wearable technology,

00:38:16.580 --> 00:38:19.770
is that sort of use
case, very flexible.

00:38:19.770 --> 00:38:22.390
And people get to choose and
customize for themselves.

00:38:22.390 --> 00:38:23.140
AUDIENCE: Awesome.

00:38:23.140 --> 00:38:23.610
Thank you.

00:38:23.610 --> 00:38:25.400
ALEX FAABORG: Another thing to
consider as an app developer is

00:38:25.400 --> 00:38:27.730
if the user has to maintain
eye contact with something,

00:38:27.730 --> 00:38:29.610
then Glass is definitely better.

00:38:29.610 --> 00:38:32.110
So, like, the basketball example
works really long on Glass,

00:38:32.110 --> 00:38:33.568
but I don't think
you'd necessarily

00:38:33.568 --> 00:38:36.200
want to be looking down at your
watch while playing basketball.

00:38:36.200 --> 00:38:38.770
So there's some significant
sort of form factor differences

00:38:38.770 --> 00:38:41.722
to consider for
your specific case.

00:38:41.722 --> 00:38:43.180
AUDIENCE: My name's
Julie Stanford,

00:38:43.180 --> 00:38:45.930
and I run a UX design agency
called Sliced Bread where

00:38:45.930 --> 00:38:47.850
we do a lot of
interactive prototyping

00:38:47.850 --> 00:38:49.590
like the kind you showed.

00:38:49.590 --> 00:38:52.780
And we use a lot of HTML jQuery
to do just quick Wizard of Oz

00:38:52.780 --> 00:38:53.280
prototypes.

00:38:53.280 --> 00:38:55.660
And I'm wondering
if Android Wear is

00:38:55.660 --> 00:38:58.250
going to support doing that
type of quick prototyping

00:38:58.250 --> 00:39:01.060
without having to go through
creating a back end and di di

00:39:01.060 --> 00:39:02.770
dah, or if there's
just some quick way

00:39:02.770 --> 00:39:05.770
to do rapid prototyping
on that platform.

00:39:05.770 --> 00:39:07.310
ALEX FAABORG: Well, it should.

00:39:07.310 --> 00:39:08.310
It doesn't currently.

00:39:08.310 --> 00:39:09.260
AUDIENCE: OK.

00:39:09.260 --> 00:39:10.099
But it will?

00:39:10.099 --> 00:39:10.890
ALEX FAABORG: Yeah.

00:39:10.890 --> 00:39:13.280
Well, I mean it
should in theory.

00:39:13.280 --> 00:39:13.780
Yeah.

00:39:13.780 --> 00:39:14.920
It's still pretty early.

00:39:14.920 --> 00:39:17.370
The team's been really focused
on getting a product out

00:39:17.370 --> 00:39:20.350
before we've been able to do
more robust things like helping

00:39:20.350 --> 00:39:21.390
prototypers and stuff.

00:39:21.390 --> 00:39:21.540
AUDIENCE: OK.

00:39:21.540 --> 00:39:22.840
So you can't just, like,
create something HTML

00:39:22.840 --> 00:39:24.870
and quickly show it to
see how it might work?

00:39:24.870 --> 00:39:27.090
ALEX FAABORG: No, it doesn't
have a rendering engine.

00:39:27.090 --> 00:39:30.620
BOB RYSKAMP: But I would say,
don't let that discourage you.

00:39:30.620 --> 00:39:33.689
Strap a bicycle helmet to your
head or a phone to your wrist.

00:39:33.689 --> 00:39:34.470
AUDIENCE: Oh, I'm
not discouraged.

00:39:34.470 --> 00:39:35.845
BOB RYSKAMP: We'll
all designers.

00:39:35.845 --> 00:39:39.310
We actually did a bunch in
HTML and JavaScript prototypes.

00:39:39.310 --> 00:39:42.280
And the real important
thing is that you can just

00:39:42.280 --> 00:39:44.440
wear it and try it
in any way possible.

00:39:44.440 --> 00:39:44.990
ALEX FAABORG: You could
also just draw out

00:39:44.990 --> 00:39:47.206
a smaller area of a phone screen
and have people read that.

00:39:47.206 --> 00:39:47.580
AUDIENCE: Right.

00:39:47.580 --> 00:39:48.229
Makes sense.

00:39:48.229 --> 00:39:50.015
ALEX FAABORG: I mean,
that stuff works OK.

00:39:50.015 --> 00:39:50.990
AUDIENCE: Hi.

00:39:50.990 --> 00:39:52.990
Just a quick question.

00:39:52.990 --> 00:39:54.900
I'm just thinking
about on average

00:39:54.900 --> 00:39:56.787
most people have, like, 50 apps.

00:39:56.787 --> 00:39:58.245
And there's a lot
of competing apps

00:39:58.245 --> 00:39:59.703
and a lot of
competing information.

00:39:59.703 --> 00:40:02.540
So let's say, where
should I eat tonight?

00:40:02.540 --> 00:40:04.010
Which card comes up?

00:40:04.010 --> 00:40:06.070
Something from Foursquare,
something from Yelp?

00:40:06.070 --> 00:40:07.510
Or, where should I stay tonight?

00:40:07.510 --> 00:40:10.500
Does Airbnb give me a
suggestion or Hotel Tonight?

00:40:10.500 --> 00:40:13.240
I'm just wondering how does
wearable kind of tackle that,

00:40:13.240 --> 00:40:14.762
or I mean Android Wear?

00:40:14.762 --> 00:40:16.220
ALEX FAABORG: So
the first time you

00:40:16.220 --> 00:40:19.027
say it, if you have
multiple apps installed

00:40:19.027 --> 00:40:20.860
or after you've installed
a new application,

00:40:20.860 --> 00:40:23.150
the user has a menu
of choices they

00:40:23.150 --> 00:40:25.852
can choose for the
application at that moment.

00:40:25.852 --> 00:40:27.810
In the future, it's going
to default to the one

00:40:27.810 --> 00:40:28.810
that you previously selected.

00:40:28.810 --> 00:40:30.750
But it gives you a moment
to pause and choose

00:40:30.750 --> 00:40:32.880
one of the others, which
is kind of nice for voice

00:40:32.880 --> 00:40:34.526
because you can say a
command, just drop your arm,

00:40:34.526 --> 00:40:35.790
and it's just going to happen.

00:40:35.790 --> 00:40:38.115
Or you could say a command and
then quickly pause it and say,

00:40:38.115 --> 00:40:40.115
now I want to switch over
to this other service.

00:40:40.115 --> 00:40:41.490
Also in the campaign
app, you can

00:40:41.490 --> 00:40:43.610
set which defaults are
associated with everything.

00:40:43.610 --> 00:40:45.180
AUDIENCE: And in terms
of the passive cards

00:40:45.180 --> 00:40:47.180
and the ranking of the
order, is that determined

00:40:47.180 --> 00:40:49.930
by Google in terms of what's
most relevant to you as you

00:40:49.930 --> 00:40:52.097
kind of scroll through the
different decks of cards?

00:40:52.097 --> 00:40:53.471
ALEX FAABORG: At
the moment, it's

00:40:53.471 --> 00:40:55.950
determined by a number of
signals that the developers are

00:40:55.950 --> 00:40:58.151
providing, priority levels.

00:40:58.151 --> 00:41:00.150
In the future we're looking
at ranking based off

00:41:00.150 --> 00:41:01.917
of how contextual things are.

00:41:01.917 --> 00:41:04.250
So it's kind of working hand
in hand with the developers

00:41:04.250 --> 00:41:06.830
to understand what's
important about their card

00:41:06.830 --> 00:41:07.910
and how it fits in.

00:41:07.910 --> 00:41:10.130
AUDIENCE: Cool.

00:41:10.130 --> 00:41:10.630
Hi.

00:41:10.630 --> 00:41:13.569
My name is Conrad, and I work
at the University of Washington.

00:41:13.569 --> 00:41:14.610
I'm a grad student there.

00:41:14.610 --> 00:41:17.250
And a number of my colleagues
are working on accessibility,

00:41:17.250 --> 00:41:19.250
and they're all really
excited about wearables

00:41:19.250 --> 00:41:21.490
because they're adding
more modalities for people

00:41:21.490 --> 00:41:23.590
that are blind or
that can't hear.

00:41:23.590 --> 00:41:25.050
And it's all really exciting.

00:41:25.050 --> 00:41:26.490
And so I'm wondering,
is your team

00:41:26.490 --> 00:41:29.059
working on any accessibility
technologies with wearables?

00:41:29.059 --> 00:41:30.600
Like for instance,
you have a screen,

00:41:30.600 --> 00:41:33.640
and you can put Talkback,
which is on Android phones,

00:41:33.640 --> 00:41:35.790
on to watches as well.

00:41:35.790 --> 00:41:37.899
Are you working on
anything like that?

00:41:37.899 --> 00:41:38.690
ALEX FAABORG: Yeah.

00:41:38.690 --> 00:41:41.381
I don't want to talk too much
about what we're working on

00:41:41.381 --> 00:41:42.880
in the future, but
I think something

00:41:42.880 --> 00:41:46.010
that is really exciting
is, particularly

00:41:46.010 --> 00:41:47.920
with Glass, the voice feedback.

00:41:47.920 --> 00:41:50.170
And building natural voice
interactions, of course,

00:41:50.170 --> 00:41:52.810
are incredibly
accessible, and they also

00:41:52.810 --> 00:41:56.050
benefit everyone, just as
the sidewalk ramps benefit

00:41:56.050 --> 00:41:56.550
everyone.

00:41:56.550 --> 00:41:58.690
So even if it's done
initially for accessibility,

00:41:58.690 --> 00:42:02.292
it's super powerful to
give everyone access to it.

00:42:02.292 --> 00:42:04.250
HAYES RAFFLE: And I think
on the Glass platform

00:42:04.250 --> 00:42:06.710
we've seen most innovation
for accessibility

00:42:06.710 --> 00:42:09.570
from third parties, a lot of it
actually from academic sectors,

00:42:09.570 --> 00:42:11.540
people doing really
innovative stuff.

00:42:11.540 --> 00:42:13.284
I think that from
our point of view,

00:42:13.284 --> 00:42:14.950
we're trying to design
more towards what

00:42:14.950 --> 00:42:19.300
I'd call universal access, which
is how to make stuff that's

00:42:19.300 --> 00:42:21.460
as usable as possible
for everybody.

00:42:21.460 --> 00:42:23.190
But a lot of these
ideas transfer over

00:42:23.190 --> 00:42:24.430
to the accessibility space.

00:42:24.430 --> 00:42:26.846
And of course there's some
that don't and some custom work

00:42:26.846 --> 00:42:27.980
that needs to be done.

00:42:27.980 --> 00:42:30.120
But the developer community's
been amazing and productive

00:42:30.120 --> 00:42:31.453
in that space so far with Glass.

00:42:31.453 --> 00:42:33.180
And I expect to see
more about with Wear

00:42:33.180 --> 00:42:34.625
as the platform emerges.

00:42:34.625 --> 00:42:34.950
AUDIENCE: All right.

00:42:34.950 --> 00:42:35.450
Thank you.

00:42:38.660 --> 00:42:41.240
I have a question
regarding context.

00:42:41.240 --> 00:42:45.870
Is it possible to
provide custom contexts?

00:42:45.870 --> 00:42:50.220
So for example,
if I can actually

00:42:50.220 --> 00:42:53.180
have an algorithm that
determines whether I'm

00:42:53.180 --> 00:42:57.730
in a noisy room or
in a quiet place,

00:42:57.730 --> 00:43:01.080
or any other type
of custom context,

00:43:01.080 --> 00:43:03.120
is that something
that I can actually

00:43:03.120 --> 00:43:07.070
use to trigger certain
mechanisms in wearables?

00:43:07.070 --> 00:43:08.290
EMMET CONNOLLY: Yeah.

00:43:08.290 --> 00:43:09.680
So from the user's
point of view,

00:43:09.680 --> 00:43:11.520
we'd prefer to keep
it really simple,

00:43:11.520 --> 00:43:15.860
where they didn't need to do
a lot of setting up of trigger

00:43:15.860 --> 00:43:18.209
conditions and so on, just
have things to appear.

00:43:18.209 --> 00:43:20.500
But I think you might be
asking from an app developer's

00:43:20.500 --> 00:43:20.810
point of view.

00:43:20.810 --> 00:43:22.380
And we would
absolutely encourage

00:43:22.380 --> 00:43:25.770
you to use every single
signal possible to really

00:43:25.770 --> 00:43:27.780
focus and target
content to the users.

00:43:27.780 --> 00:43:30.810
So all of those examples
that you specified, I think,

00:43:30.810 --> 00:43:33.360
are great signals
and really paint

00:43:33.360 --> 00:43:36.090
that picture of what
the user is doing.

00:43:36.090 --> 00:43:37.850
AUDIENCE: So I'm asking
if I can actually

00:43:37.850 --> 00:43:41.669
do a custom context to create
a trigger, a custom trigger.

00:43:41.669 --> 00:43:42.460
ALEX FAABORG: Yeah.

00:43:42.460 --> 00:43:44.690
So it somewhat depends on
the hardware being used.

00:43:44.690 --> 00:43:50.220
So like for Microphone, there's
permissions surrounding that.

00:43:50.220 --> 00:43:52.710
Also there's battery
implications.

00:43:52.710 --> 00:43:54.210
And the other aspect
is we're trying

00:43:54.210 --> 00:43:58.079
to build systems that are
pretty robust that everyone can

00:43:58.079 --> 00:43:59.870
benefit from, like with
activity detection.

00:43:59.870 --> 00:44:02.560
It's really hard to do machine
learning on accelerometer data

00:44:02.560 --> 00:44:05.190
to figure out the difference
between biking and driving.

00:44:05.190 --> 00:44:07.670
So by us providing that to
all the developers, then

00:44:07.670 --> 00:44:10.190
they get all of that
learning for free.

00:44:10.190 --> 00:44:12.195
But for the things
that you can't access,

00:44:12.195 --> 00:44:13.990
yeah, we totally
encourage you guys

00:44:13.990 --> 00:44:16.200
to build your own
models of context.

00:44:16.200 --> 00:44:18.840
It'll give you a leg up in the
market against your competitors

00:44:18.840 --> 00:44:20.209
if you're more contextual.

00:44:20.209 --> 00:44:20.750
AUDIENCE: OK.

00:44:20.750 --> 00:44:23.083
EMMET CONNOLLY: And raw sensor
data is available to you.

00:44:23.083 --> 00:44:24.830
For example, in the
accelerometer case,

00:44:24.830 --> 00:44:26.590
like if you don't want to,
you don't have to use those.

00:44:26.590 --> 00:44:26.620
ALEX FAABORG: Yeah.

00:44:26.620 --> 00:44:28.274
If you have a better
model, then yeah.

00:44:28.274 --> 00:44:29.690
AUDIENCE: Could
that be triggered?

00:44:29.690 --> 00:44:32.780
I mean, I can't use that
to trigger anything, right,

00:44:32.780 --> 00:44:34.500
raw accelerometer data?

00:44:34.500 --> 00:44:38.840
Accelerometer data, I can't
use that to trigger something

00:44:38.840 --> 00:44:40.380
from the background, right?

00:44:40.380 --> 00:44:42.360
BOB RYSKAMP: It seems like maybe
we can follow up afterward?

00:44:42.360 --> 00:44:43.490
We can talk in more depth.

00:44:43.490 --> 00:44:44.930
ALEX FAABORG: Generally, you
can put a card into the stream

00:44:44.930 --> 00:44:46.879
whenever you feel
that it's contextual.

00:44:46.879 --> 00:44:49.170
BOB RYSKAMP: We'll take just
one more question, thanks.

00:44:49.170 --> 00:44:50.010
AUDIENCE: Well, this is crazy.

00:44:50.010 --> 00:44:51.160
You just stole my question.

00:44:51.160 --> 00:44:53.775
But I'll add a little bit more.

00:44:53.775 --> 00:44:56.150
You guys have been working on
this space for a while now.

00:44:56.150 --> 00:44:58.550
Do you have any sort of
conceptual frameworks

00:44:58.550 --> 00:45:02.130
for thinking about
multiplexing contextual data?

00:45:02.130 --> 00:45:05.020
You can often be overwhelmed
by a particular signal

00:45:05.020 --> 00:45:09.090
or have a particular signal
that is not represented as well.

00:45:09.090 --> 00:45:12.075
Is there any sort of, more
towards the theoretical side

00:45:12.075 --> 00:45:14.367
of, like, where to go to
combine these things together?

00:45:14.367 --> 00:45:16.325
ALEX FAABORG: It would
be a really good problem

00:45:16.325 --> 00:45:18.930
for us to have because right
now we're figuring out context

00:45:18.930 --> 00:45:21.263
and then matching that against
all the available sources

00:45:21.263 --> 00:45:24.430
of information that have
cards that can match.

00:45:24.430 --> 00:45:26.800
At the moment Android Wear
is just launching now,

00:45:26.800 --> 00:45:29.170
so we don't have a tremendous
number of applications.

00:45:29.170 --> 00:45:30.961
But it'd be a great
problem for us to have,

00:45:30.961 --> 00:45:32.920
that suddenly there's
too many contextual cards

00:45:32.920 --> 00:45:33.794
for your environment.

00:45:33.794 --> 00:45:35.780
And then we'd have to
think about ranking.

00:45:35.780 --> 00:45:37.830
And then that's the sort of
fundamentally a search problem.

00:45:37.830 --> 00:45:39.560
So I think we're
hopefully pretty well

00:45:39.560 --> 00:45:40.476
equipped to tackle it.

00:45:40.476 --> 00:45:43.164
I'm looking forward to that
being something we can work on.

00:45:43.164 --> 00:45:43.970
AUDIENCE: OK.

00:45:43.970 --> 00:45:44.470
Thanks.

00:45:44.470 --> 00:45:46.250
BOB RYSKAMP: So go forth
and give us that problem.

00:45:46.250 --> 00:45:47.180
ALEX FAABORG: Yes, please.

00:45:47.180 --> 00:45:48.430
BOB RYSKAMP: Thanks, everyone.

00:45:48.430 --> 00:45:50.490
HAYES RAFFLE: Yeah, thanks
very much, everybody.

