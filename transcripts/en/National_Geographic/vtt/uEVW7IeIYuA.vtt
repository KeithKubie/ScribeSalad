WEBVTT
Kind: captions
Language: en

00:00:00.734 --> 00:00:01.567
I'm Richard Bacon.

00:00:01.567 --> 00:00:03.500
Let's talk about surveillance.

00:00:03.500 --> 00:00:06.567
But let's do it quietly because
they're probably listening.

00:00:06.567 --> 00:00:10.467
That thing in your pocket
that you call a smartphone,

00:00:10.467 --> 00:00:14.400
it's a tracking device that
just happens to make calls.

00:00:14.400 --> 00:00:17.967
Digital tracking has become
a part of our everyday lives.

00:00:17.967 --> 00:00:20.967
It is how we answer
our biggest questions.

00:00:20.967 --> 00:00:23.333
When are those cute
shoes going on sale?

00:00:23.333 --> 00:00:25.967
What happened to that cute
girl I knew in high school?

00:00:25.967 --> 00:00:28.000
Where's that cute
commander of ISIS?

00:00:28.000 --> 00:00:29.900
[laughter]

00:00:29.900 --> 00:00:31.000
That's right.

00:00:31.000 --> 00:00:33.800
The same technology
that targets terrorists

00:00:33.800 --> 00:00:36.567
is also being used
to sell you Halloween

00:00:36.567 --> 00:00:39.100
costumes for your dog.

00:00:39.100 --> 00:00:41.567
You're probably
aware that companies

00:00:41.567 --> 00:00:42.934
are collecting your data.

00:00:42.934 --> 00:00:44.867
But you don't know
the half of it.

00:00:44.867 --> 00:00:46.633
Let's run the numbers.

00:00:46.633 --> 00:00:48.867
[applause]

00:00:50.867 --> 00:00:55.533
1,500, that is how many pieces
of information data company

00:00:55.533 --> 00:01:00.467
Acxiom has on every single
consumer in the United States,

00:01:00.467 --> 00:01:01.867
1,500.

00:01:01.867 --> 00:01:03.967
If you asked me for
10 interesting pieces

00:01:03.967 --> 00:01:06.500
of information about
myself, I'd struggle.

00:01:06.500 --> 00:01:10.800
Acxiom bundles your information
into profiles with catchy names

00:01:10.800 --> 00:01:15.033
like "Men in Trouble," and
then sells them to advertisers.

00:01:15.033 --> 00:01:17.700
"Men in Trouble"
is the file made up

00:01:17.700 --> 00:01:19.934
of married men who've
recently searched

00:01:19.934 --> 00:01:21.233
for flowers and chocolates.

00:01:21.233 --> 00:01:23.166
[laughter]

00:01:23.166 --> 00:01:24.700
In trouble.

00:01:24.700 --> 00:01:29.166
91-- researches at the
University of Pennsylvania

00:01:29.166 --> 00:01:31.834
found that when you look
up-- this is amazing.

00:01:31.834 --> 00:01:35.000
When you look at
medical symptoms online,

00:01:35.000 --> 00:01:39.633
91% of those websites
are sharing your searches

00:01:39.633 --> 00:01:43.066
with third parties, even
shipping the information

00:01:43.066 --> 00:01:47.900
directly to the same brokers
who monitor your credit scores.

00:01:47.900 --> 00:01:52.867
In other words, everybody
knows about your weird rash.

00:01:52.867 --> 00:01:55.700
300-- according
to a recent study,

00:01:55.700 --> 00:02:01.033
it takes just 300 Facebook
likes for big data

00:02:01.033 --> 00:02:03.533
to know you better
than your spouse.

00:02:03.533 --> 00:02:07.333
The algorithms used by
Facebook are so good,

00:02:07.333 --> 00:02:09.433
they can predict your
sexual preference

00:02:09.433 --> 00:02:13.900
with up to 88% accuracy,
which means Mark Zuckerberg

00:02:13.900 --> 00:02:16.900
knows you're gay before you do.

00:02:16.900 --> 00:02:19.867
0-- that is the
amount of messages

00:02:19.867 --> 00:02:21.700
that you have
deleted in your life.

00:02:21.700 --> 00:02:24.133
There may be a Delete
button, but there's

00:02:24.133 --> 00:02:26.100
no such thing as delete.

00:02:26.100 --> 00:02:28.734
Apps track every
key that you push.

00:02:28.734 --> 00:02:33.433
You can find anything you want
online except for privacy.

00:02:33.433 --> 00:02:34.934
And those were the numbers.

00:02:34.934 --> 00:02:35.834
[music playing]

00:02:35.834 --> 00:02:38.166
[applause]

