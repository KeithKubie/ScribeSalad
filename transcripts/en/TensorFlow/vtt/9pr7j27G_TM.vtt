WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.335
[MUSIC PLAYING]

00:00:03.277 --> 00:00:05.110
LAURENCE MORONEY: Hi,
everybody, and welcome

00:00:05.110 --> 00:00:06.100
to "TensorFlow Meets."

00:00:06.100 --> 00:00:08.320
In this episode, I'm
chatting with Haohan Wang--

00:00:08.320 --> 00:00:09.670
HAOHAN WANG: Thank you
for having me here.

00:00:09.670 --> 00:00:11.712
LAURENCE MORONEY: --who's
been doing some really,

00:00:11.712 --> 00:00:14.260
really cool work with
neuroscience, and TensorFlow,

00:00:14.260 --> 00:00:16.360
and machine learning, and
all kinds of cool stuff,

00:00:16.360 --> 00:00:17.277
and even a new course.

00:00:17.277 --> 00:00:20.350
So you've been working
on Dyad X Machina, which

00:00:20.350 --> 00:00:23.670
is a beautiful name for what
looks like a beautiful site.

00:00:23.670 --> 00:00:24.970
Could you tell us all about it?

00:00:24.970 --> 00:00:25.720
HAOHAN WANG: Sure.

00:00:25.720 --> 00:00:29.140
So I will start from
the name Dyad X Machina.

00:00:29.140 --> 00:00:31.900
Dyad means two as
one, which is me

00:00:31.900 --> 00:00:34.113
and my partner, Christian Fanli.

00:00:34.113 --> 00:00:35.530
LAURENCE MORONEY:
And Christian is

00:00:35.530 --> 00:00:37.405
going to be on a future
show, which is great.

00:00:37.405 --> 00:00:38.350
HAOHAN WANG: Yes.

00:00:38.350 --> 00:00:40.840
So machine-- things we
constantly work with machine.

00:00:40.840 --> 00:00:44.680
And we're at the intersection
of deep learning and affective

00:00:44.680 --> 00:00:46.190
computing.

00:00:46.190 --> 00:00:48.730
So as for why we
started Dyad X Machina,

00:00:48.730 --> 00:00:51.970
I think the story really
starts four to five years ago

00:00:51.970 --> 00:00:53.650
when we first met.

00:00:53.650 --> 00:00:56.380
So I was a student
in finance and he was

00:00:56.380 --> 00:00:59.200
working in human behavior area.

00:00:59.200 --> 00:01:02.260
And we started to
collaborate because we

00:01:02.260 --> 00:01:05.040
both shared the same strong
interest in machine learning.

00:01:05.040 --> 00:01:06.040
LAURENCE MORONEY: Right.

00:01:06.040 --> 00:01:08.457
HAOHAN WANG: So one of the
first machine learning projects

00:01:08.457 --> 00:01:12.305
that we worked on together is
to create a trading algorithms.

00:01:12.305 --> 00:01:13.180
LAURENCE MORONEY: OK.

00:01:13.180 --> 00:01:16.180
HAOHAN WANG: Well, so
Christian challenged

00:01:16.180 --> 00:01:18.160
us to think outside
the box instead

00:01:18.160 --> 00:01:21.940
of using the traditional
technical or fundamental

00:01:21.940 --> 00:01:24.860
analysis into your
algorithm, why can't we

00:01:24.860 --> 00:01:28.180
add some human behavioral
elements, like emotions,

00:01:28.180 --> 00:01:29.050
into your algorithm?

00:01:29.050 --> 00:01:29.925
LAURENCE MORONEY: OK.

00:01:29.925 --> 00:01:32.140
HAOHAN WANG: Well, so
we end up including

00:01:32.140 --> 00:01:34.360
sentiment into our algorithm.

00:01:34.360 --> 00:01:37.450
And surprisingly, sentiment
is a great training--

00:01:37.450 --> 00:01:39.490
a very indicative
training signals.

00:01:39.490 --> 00:01:40.510
LAURENCE MORONEY: I can
see that because I'm

00:01:40.510 --> 00:01:41.980
sure when some
people are buying,

00:01:41.980 --> 00:01:43.060
then everybody jumps on board.

00:01:43.060 --> 00:01:44.060
And when some
people are selling,

00:01:44.060 --> 00:01:45.132
everybody-- you know,
that kind of thing.

00:01:45.132 --> 00:01:45.240
There's a lot of sentiment.

00:01:45.240 --> 00:01:46.080
HAOHAN WANG: Yeah, early signal.

00:01:46.080 --> 00:01:46.490
LAURENCE MORONEY:
Yeah, definitely.

00:01:46.490 --> 00:01:47.620
HAOHAN WANG: Yeah.

00:01:47.620 --> 00:01:50.710
Well, so after that, I think
it really brought emotion

00:01:50.710 --> 00:01:52.060
into our attention.

00:01:52.060 --> 00:01:55.600
And then we started
to study a lot more

00:01:55.600 --> 00:01:59.050
into this field, affective
neuroscience especially.

00:01:59.050 --> 00:02:01.730
And we read numerous
book in the field.

00:02:01.730 --> 00:02:04.570
And I think we started to
notice a problem, which

00:02:04.570 --> 00:02:10.060
is how society at large tends
to ignore how important emotion

00:02:10.060 --> 00:02:13.750
is, especially like in our
daily decision-making process

00:02:13.750 --> 00:02:16.840
because people tend
to overvalue cognition

00:02:16.840 --> 00:02:19.660
and rationality over emotion.

00:02:19.660 --> 00:02:20.910
LAURENCE MORONEY: Interesting.

00:02:20.910 --> 00:02:21.700
HAOHAN WANG: Yeah.

00:02:21.700 --> 00:02:25.060
So I think, well, that's really
the starting point that we

00:02:25.060 --> 00:02:27.340
think probably it's our job--

00:02:27.340 --> 00:02:31.450
it's Dyad X Machina's job to
bring this affective layer back

00:02:31.450 --> 00:02:32.540
into people's daily life.

00:02:32.540 --> 00:02:34.540
LAURENCE MORONEY: So it's
you saw an opportunity

00:02:34.540 --> 00:02:36.700
to bring emotion into
what are traditionally

00:02:36.700 --> 00:02:37.850
logical decisions?

00:02:37.850 --> 00:02:38.810
HAOHAN WANG: Yep.

00:02:38.810 --> 00:02:41.240
There is where Dyad X
Machina started, yeah.

00:02:41.240 --> 00:02:42.490
LAURENCE MORONEY: Interesting.

00:02:42.490 --> 00:02:43.870
And now, a lot of
the work that you've

00:02:43.870 --> 00:02:45.220
been doing and a
lot of the learning

00:02:45.220 --> 00:02:47.387
that you've been doing,
you're turning into a course

00:02:47.387 --> 00:02:48.340
now, right?

00:02:48.340 --> 00:02:49.330
HAOHAN WANG: Yes.

00:02:49.330 --> 00:02:51.850
So start from there
actually-- well,

00:02:51.850 --> 00:02:55.450
here is where deep learning
and TensorFlow came in.

00:02:55.450 --> 00:02:58.330
So we were studying
machine learning,

00:02:58.330 --> 00:03:02.290
but then we discovered
deep learning.

00:03:02.290 --> 00:03:06.190
So I think so here is also the
point that we hit a point that

00:03:06.190 --> 00:03:10.750
we cannot make any more progress
because we're both working full

00:03:10.750 --> 00:03:13.208
time and we'd dedicate all our
free time on reading books--

00:03:13.208 --> 00:03:15.417
LAURENCE MORONEY: Those day
jobs just get in the way,

00:03:15.417 --> 00:03:16.030
don't they?

00:03:16.030 --> 00:03:19.270
HAOHAN WANG: Yep-- trying to
understand machine learning

00:03:19.270 --> 00:03:21.190
and affective computing.

00:03:21.190 --> 00:03:25.150
So I think we had a discussion
and made a hard decision--

00:03:25.150 --> 00:03:29.890
I took one year off, focused
fully on deep learning

00:03:29.890 --> 00:03:31.990
and affective computing.

00:03:31.990 --> 00:03:34.330
So here, you can
think of this course--

00:03:34.330 --> 00:03:37.570
and we end up making this course
because this course is really

00:03:37.570 --> 00:03:41.230
the synthesis of our
learning because we really

00:03:41.230 --> 00:03:43.030
dedicated a lot
of time and effort

00:03:43.030 --> 00:03:44.600
on learning deep learning.

00:03:44.600 --> 00:03:48.250
And we think this course will
be a great start for people

00:03:48.250 --> 00:03:50.200
who are new to deep
learning to get started.

00:03:50.200 --> 00:03:53.320
But more importantly,
I think our main focus

00:03:53.320 --> 00:03:57.250
is to help people who want to
use deep learning to the field

00:03:57.250 --> 00:04:00.612
that they are passionate about
to be able to get started.

00:04:00.612 --> 00:04:02.320
LAURENCE MORONEY: So
your course is about

00:04:02.320 --> 00:04:04.520
applied deep learning with
TensorFlow and Cloud AI?

00:04:04.520 --> 00:04:04.820
HAOHAN WANG: Yes.

00:04:04.820 --> 00:04:06.020
LAURENCE MORONEY:
There's a lot in there.

00:04:06.020 --> 00:04:07.970
So what kind of
content do you have?

00:04:07.970 --> 00:04:10.810
HAOHAN WANG: Well, so this
is our very first course.

00:04:10.810 --> 00:04:13.630
And we're a little
bit ambitious trying

00:04:13.630 --> 00:04:15.160
to put everything in there.

00:04:15.160 --> 00:04:18.130
But the course is
really meant to help

00:04:18.130 --> 00:04:20.260
people who are new
to machine learning

00:04:20.260 --> 00:04:22.930
to be able to build their
first deep learning model

00:04:22.930 --> 00:04:25.840
and to take it all
the way to deploy

00:04:25.840 --> 00:04:27.635
their model as
production-level API.

00:04:27.635 --> 00:04:28.510
LAURENCE MORONEY: OK.

00:04:28.510 --> 00:04:30.010
HAOHAN WANG: Then
we move on to talk

00:04:30.010 --> 00:04:32.680
about the basics
of deep learning

00:04:32.680 --> 00:04:37.360
and how to design an experiment
with some typical neural

00:04:37.360 --> 00:04:39.222
networks using Keras.

00:04:39.222 --> 00:04:40.430
LAURENCE MORONEY: Keras, yep.

00:04:40.430 --> 00:04:41.380
HAOHAN WANG: Yep.

00:04:41.380 --> 00:04:45.600
And then we move on-- we
dove deep into TensorFlow.

00:04:45.600 --> 00:04:47.620
We start from
low-level TensorFlow.

00:04:47.620 --> 00:04:51.040
We introduce the concept
like dataflow graph

00:04:51.040 --> 00:04:55.210
and a TensorBoard, then we move
on to high-level TensorFlow.

00:04:55.210 --> 00:04:58.360
Then help people to build
a model in the cloud,

00:04:58.360 --> 00:05:00.220
train the model,
evaluate the model,

00:05:00.220 --> 00:05:01.990
and eventually
deploy their model

00:05:01.990 --> 00:05:04.363
as a production-level API.

00:05:04.363 --> 00:05:06.030
LAURENCE MORONEY: So
the deployment part

00:05:06.030 --> 00:05:07.470
is really fascinating
to me because there's

00:05:07.470 --> 00:05:10.137
lots of great material out there
about training models and maybe

00:05:10.137 --> 00:05:12.510
doing a little bit of a test,
but making it real world,

00:05:12.510 --> 00:05:14.772
making it applied
is really cool.

00:05:14.772 --> 00:05:16.980
HAOHAN WANG: Yeah, that's
our intention-- help people

00:05:16.980 --> 00:05:19.602
to apply it to the field
they're interested in.

00:05:19.602 --> 00:05:20.560
LAURENCE MORONEY: Nice.

00:05:20.560 --> 00:05:23.970
And we'll put a link to the
course in the comments below.

00:05:23.970 --> 00:05:26.845
So you've started
with neuroscience,

00:05:26.845 --> 00:05:29.220
and then you've moved into
taking a year off and creating

00:05:29.220 --> 00:05:29.790
a course.

00:05:29.790 --> 00:05:32.430
And you've obviously gotten
very deep into machine learning

00:05:32.430 --> 00:05:34.410
and you've gotten very
deep into neuroscience

00:05:34.410 --> 00:05:36.600
and the intersection
between the two of them.

00:05:36.600 --> 00:05:38.100
What advice would
you give to people

00:05:38.100 --> 00:05:40.400
who are just starting out?

00:05:40.400 --> 00:05:41.440
HAOHAN WANG: Well, yes.

00:05:41.440 --> 00:05:44.420
So I'd like to talk a little
bit about-- connect it back

00:05:44.420 --> 00:05:48.440
to our learning experience
of a journey of deep learning

00:05:48.440 --> 00:05:52.520
and possible a little bit
about affective neuroscience.

00:05:52.520 --> 00:05:55.430
So we also summarize
this four P's

00:05:55.430 --> 00:05:57.470
of learning that I'd
like to share here.

00:05:57.470 --> 00:05:58.670
LAURENCE MORONEY: The
four P's of learning?

00:05:58.670 --> 00:05:59.140
HAOHAN WANG: Well, yeah.

00:05:59.140 --> 00:06:01.740
LAURENCE MORONEY: OK, I'll
try to remember them myself.

00:06:01.740 --> 00:06:04.160
HAOHAN WANG: We published
an article on our website

00:06:04.160 --> 00:06:06.050
so people can check it out.

00:06:06.050 --> 00:06:06.750
LAURENCE MORONEY: Ah, so
we've got a link for that,

00:06:06.750 --> 00:06:07.790
so I don't need to remember it.

00:06:07.790 --> 00:06:09.340
HAOHAN WANG: Yeah, and you
don't have to remember it.

00:06:09.340 --> 00:06:10.340
LAURENCE MORONEY: Great.

00:06:10.340 --> 00:06:12.650
HAOHAN WANG: So the first
P-- papers and books.

00:06:12.650 --> 00:06:13.190
LAURENCE MORONEY: Papers, OK.

00:06:13.190 --> 00:06:15.398
HAOHAN WANG: Well, I think
it's really the foundation

00:06:15.398 --> 00:06:19.400
because we make
sure we read papers

00:06:19.400 --> 00:06:21.500
and books every single day.

00:06:21.500 --> 00:06:25.483
And we got up 4:30 AM, the
first task is to read paper.

00:06:25.483 --> 00:06:26.400
LAURENCE MORONEY: Wow.

00:06:26.400 --> 00:06:28.067
HAOHAN WANG: Yeah,
deep learning papers.

00:06:28.067 --> 00:06:29.660
So at the beginning,
we read some more

00:06:29.660 --> 00:06:32.030
like basic deep
learning paper to know

00:06:32.030 --> 00:06:34.880
what is trending in the field
or how people solve problems

00:06:34.880 --> 00:06:36.080
with deep learning.

00:06:36.080 --> 00:06:39.450
Then we move on to be more
specific about our domain--

00:06:39.450 --> 00:06:42.020
how people use deep
learning to solve

00:06:42.020 --> 00:06:45.020
like neuroscience problems--
affective neuroscience

00:06:45.020 --> 00:06:45.890
problems?

00:06:45.890 --> 00:06:47.950
LAURENCE MORONEY: So
4:30 AM for the first P?

00:06:47.950 --> 00:06:48.200
HAOHAN WANG: Yeah.

00:06:48.200 --> 00:06:50.160
LAURENCE MORONEY: I think
you've lost me already.

00:06:50.160 --> 00:06:50.510
HAOHAN WANG: Yeah, first day.

00:06:50.510 --> 00:06:52.190
LAURENCE MORONEY: Just kidding.

00:06:52.190 --> 00:06:52.940
So papers.

00:06:52.940 --> 00:06:54.110
And what was the second?

00:06:54.110 --> 00:06:54.650
HAOHAN WANG: Paper and books.

00:06:54.650 --> 00:06:55.100
LAURENCE MORONEY:
And books, yeah.

00:06:55.100 --> 00:06:55.990
HAOHAN WANG: Well,
paper and books.

00:06:55.990 --> 00:06:57.138
Second P is practice.

00:06:57.138 --> 00:06:58.430
LAURENCE MORONEY: Practice, OK.

00:06:58.430 --> 00:07:00.990
HAOHAN WANG: Yeah, so I think
practice is very important.

00:07:00.990 --> 00:07:03.320
Especially like
I think I am very

00:07:03.320 --> 00:07:04.955
passionate about
like every day, I

00:07:04.955 --> 00:07:07.340
will use TensorFlow
to build some--

00:07:07.340 --> 00:07:09.620
start from the basic
neural networks

00:07:09.620 --> 00:07:12.920
and understand like
dataflow graph.

00:07:12.920 --> 00:07:17.630
And like, I'm very interested in
using TensorBoard to visualize

00:07:17.630 --> 00:07:21.380
my training, and
evaluating resource,

00:07:21.380 --> 00:07:24.830
and how to tune my
model's hyperparameters.

00:07:24.830 --> 00:07:27.650
So I think then practice.

00:07:27.650 --> 00:07:30.060
And you can find those
problems very easily

00:07:30.060 --> 00:07:31.967
on Kaggle and Crowd AI.

00:07:31.967 --> 00:07:33.300
LAURENCE MORONEY: Kaggle, right.

00:07:33.300 --> 00:07:33.800
Yep.

00:07:33.800 --> 00:07:36.710
HAOHAN WANG: So the third
P, which I think personally

00:07:36.710 --> 00:07:39.272
is very helpful for my
learning, which is preach.

00:07:39.272 --> 00:07:40.480
LAURENCE MORONEY: Preach, OK.

00:07:40.480 --> 00:07:44.000
HAOHAN WANG: Yeah, you can
think of lecturing or teaching.

00:07:44.000 --> 00:07:47.380
So every day, I
will give Christian

00:07:47.380 --> 00:07:50.510
a mini-lecture about what
I learned during the day

00:07:50.510 --> 00:07:52.820
about deep learning,
some theories,

00:07:52.820 --> 00:07:55.470
or even neural network
I built that day.

00:07:55.470 --> 00:07:57.125
So I think it's
mutually beneficial.

00:07:57.125 --> 00:07:59.660
It helped me to
consolidate my knowledge

00:07:59.660 --> 00:08:02.390
and helped him to have
an overview about what

00:08:02.390 --> 00:08:06.873
I learned and also making
some progress from his side.

00:08:06.873 --> 00:08:08.040
LAURENCE MORONEY: Excellent.

00:08:08.040 --> 00:08:11.420
HAOHAN WANG: Well,
last P, we think

00:08:11.420 --> 00:08:14.030
is really helping us to
get where we are right

00:08:14.030 --> 00:08:15.100
now is passion.

00:08:15.100 --> 00:08:16.170
LAURENCE MORONEY: Yeah.

00:08:16.170 --> 00:08:17.620
They definitely need passion.

00:08:17.620 --> 00:08:18.370
HAOHAN WANG: Yeah.

00:08:18.370 --> 00:08:21.700
So well, first like
I mentioned, we

00:08:21.700 --> 00:08:24.310
saw this great potential of
deep learning and TensorFlow

00:08:24.310 --> 00:08:28.270
that you can leverage to really
bring the transformative change

00:08:28.270 --> 00:08:32.500
into the domain because
this is new technology.

00:08:32.500 --> 00:08:34.960
And regularly in
the past, at least

00:08:34.960 --> 00:08:38.650
based on our study about
the effect of neuroscience,

00:08:38.650 --> 00:08:40.900
no one has ever
leveraged this technology

00:08:40.900 --> 00:08:43.240
to build any algorithm yet.

00:08:43.240 --> 00:08:45.310
So we set out to
make that happen.

00:08:45.310 --> 00:08:47.560
LAURENCE MORONEY: So bringing
emotion into algorithms.

00:08:47.560 --> 00:08:48.268
HAOHAN WANG: Yes.

00:08:48.268 --> 00:08:50.010
LAURENCE MORONEY: It
sounds fascinating.

00:08:50.010 --> 00:08:52.990
So you started this
journey as you were

00:08:52.990 --> 00:08:54.440
doing financial trading stuff--

00:08:54.440 --> 00:08:54.680
HAOHAN WANG: Yep.

00:08:54.680 --> 00:08:56.560
LAURENCE MORONEY: --and then
you just took a look at emotions

00:08:56.560 --> 00:08:57.520
in that.

00:08:57.520 --> 00:08:59.687
You know, from out of that
has grown Dyad X Machina.

00:08:59.687 --> 00:09:00.437
HAOHAN WANG: Yeah.

00:09:00.437 --> 00:09:02.750
LAURENCE MORONEY: And
now, you have a course.

00:09:02.750 --> 00:09:05.162
You have your daily four
P's that you're doing.

00:09:05.162 --> 00:09:07.120
It's like there's a lot
of amazing stuff there.

00:09:07.120 --> 00:09:09.520
So what's next for Haohan?

00:09:09.520 --> 00:09:13.420
HAOHAN WANG: Yeah, so next
for me and Dyad X Machina

00:09:13.420 --> 00:09:16.240
is we're right
now, still working

00:09:16.240 --> 00:09:20.000
on running experiments
every day and doing research

00:09:20.000 --> 00:09:21.670
in affective computing area.

00:09:21.670 --> 00:09:23.410
We're trying to
put things together

00:09:23.410 --> 00:09:25.990
to be able to eventually
present to the-- share

00:09:25.990 --> 00:09:27.350
with the community.

00:09:27.350 --> 00:09:31.460
So we will be working on
this part of the study.

00:09:31.460 --> 00:09:33.575
What's more is another
thing about the course.

00:09:33.575 --> 00:09:34.450
LAURENCE MORONEY: OK.

00:09:34.450 --> 00:09:37.627
HAOHAN WANG: We are planning
to make a new course.

00:09:37.627 --> 00:09:38.710
LAURENCE MORONEY: Oh, wow.

00:09:38.710 --> 00:09:40.540
HAOHAN WANG: And we plan
to deliver the course

00:09:40.540 --> 00:09:42.820
by the end of this year or
the beginning of next year.

00:09:42.820 --> 00:09:46.600
The course will be called
"Affective Computing

00:09:46.600 --> 00:09:48.857
and Deep Learning
using TensorFlow."

00:09:48.857 --> 00:09:51.190
LAURENCE MORONEY: "Affective
Computing and Deep Learning

00:09:51.190 --> 00:09:51.952
using TensorFlow?"

00:09:51.952 --> 00:09:52.660
HAOHAN WANG: Yes.

00:09:52.660 --> 00:09:53.820
LAURENCE MORONEY: I'll
look forward to it.

00:09:53.820 --> 00:09:54.570
HAOHAN WANG: Yeah.

00:09:54.570 --> 00:09:57.070
So in this course, we
will be teaching people

00:09:57.070 --> 00:10:00.520
how to use TensorFlow and
the Google Cloud machine

00:10:00.520 --> 00:10:04.210
learning engine to stream
in your psychophysiological

00:10:04.210 --> 00:10:07.630
signals over time and
to process your signals.

00:10:07.630 --> 00:10:10.450
And eventually, the
algorithm should

00:10:10.450 --> 00:10:12.550
be able to make a
real-time prediction

00:10:12.550 --> 00:10:14.137
about your affective state.

00:10:14.137 --> 00:10:15.470
LAURENCE MORONEY: OK, excellent.

00:10:15.470 --> 00:10:17.110
So your course on
affective computing,

00:10:17.110 --> 00:10:18.910
it's going to be coming out
pretty soon-- maybe the end

00:10:18.910 --> 00:10:20.650
of this year or sometime
early next year.

00:10:20.650 --> 00:10:22.060
And maybe after the
course comes out,

00:10:22.060 --> 00:10:23.850
we'll have you on
again to talk about it.

00:10:23.850 --> 00:10:25.170
HAOHAN WANG: Yes,
I would love to.

00:10:25.170 --> 00:10:27.087
LAURENCE MORONEY: So
we'll look forward to it.

00:10:27.087 --> 00:10:28.220
So thanks so much, Haohan.

00:10:28.220 --> 00:10:30.220
And thanks, everybody,
for watching this episode

00:10:30.220 --> 00:10:31.480
of "TensorFlow Meets."

00:10:31.480 --> 00:10:32.860
If you have any questions
for me or if you

00:10:32.860 --> 00:10:34.390
have any questions for
Haohan, please just

00:10:34.390 --> 00:10:35.610
leave them in the
comments below.

00:10:35.610 --> 00:10:36.730
And whatever you
do, don't forget

00:10:36.730 --> 00:10:37.938
to hit that Subscribe button.

00:10:37.938 --> 00:10:39.040
Thank you.

00:10:39.040 --> 00:10:42.090
[MUSIC PLAYING]

