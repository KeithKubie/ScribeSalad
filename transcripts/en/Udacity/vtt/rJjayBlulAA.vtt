WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:03.410
Okay, so in the general mathematical sense that's how we

00:00:03.410 --> 00:00:07.010
would optimize the parameters on our model theta by using

00:00:07.010 --> 00:00:09.850
batch gradient descent to minimize our cost function, j of

00:00:09.850 --> 00:00:13.830
theta. Below is an implementation of linear regression and gradient descent

00:00:13.830 --> 00:00:16.190
to try and determine how many lifetime home runs a

00:00:16.190 --> 00:00:19.520
player in a baseball data set will hit. Given their height

00:00:19.520 --> 00:00:22.410
and weight. I'd encourage you to really look through all

00:00:22.410 --> 00:00:25.280
of this code and make sure you understand how it works.

00:00:25.280 --> 00:00:26.860
But for now, I'd like you to write some code

00:00:26.860 --> 00:00:29.220
here that updates the values of theta a number of

00:00:29.220 --> 00:00:33.770
times equal to num_iterations. You should initialize an array called

00:00:33.770 --> 00:00:36.640
the cost_history, and every time you've computed the cost for a

00:00:36.640 --> 00:00:39.170
given set of thetas You should append it to cost

00:00:39.170 --> 00:00:42.980
history. The function should return both the final values of theta

00:00:42.980 --> 00:00:46.930
in your theta array, and cost history array. Your code

00:00:46.930 --> 00:00:50.290
should go here. Feel free to use other helper functions in

00:00:50.290 --> 00:00:52.130
this code, such as compute cost.

