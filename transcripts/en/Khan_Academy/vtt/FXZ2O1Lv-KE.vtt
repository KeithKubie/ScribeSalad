WEBVTT
Kind: captions
Language: en

00:00:00.374 --> 00:00:02.040
In the last video,
we learned about what

00:00:02.040 --> 00:00:05.189
is quite possibly the most
profound idea in statistics,

00:00:05.189 --> 00:00:06.730
and that's the
central limit theorem.

00:00:06.730 --> 00:00:07.730
And the reason why
it's so neat is,

00:00:07.730 --> 00:00:09.740
we could start with
any distribution that

00:00:09.740 --> 00:00:13.152
has a well defined mean
and variance-- actually,

00:00:13.152 --> 00:00:14.610
I wrote the standard
deviation here

00:00:14.610 --> 00:00:16.760
in the last video, that
should be the mean,

00:00:16.760 --> 00:00:18.330
and let's say it
has some variance.

00:00:18.330 --> 00:00:19.990
I could write it
like that, or I could

00:00:19.990 --> 00:00:21.960
write the standard
deviation there.

00:00:21.960 --> 00:00:23.480
But as long as it
has a well defined

00:00:23.480 --> 00:00:25.240
mean and standard
deviation, I don't

00:00:25.240 --> 00:00:27.890
care what the
distribution looks like.

00:00:27.890 --> 00:00:30.730
What I can do is take samples--
in the last video of say,

00:00:30.730 --> 00:00:35.060
size four-- that means
I take literally four

00:00:35.060 --> 00:00:38.120
instances of this random
variable, this is one example.

00:00:38.120 --> 00:00:40.480
I take their mean,
and I consider

00:00:40.480 --> 00:00:42.880
this the sample mean
from my first trial,

00:00:42.880 --> 00:00:44.870
or you could almost say
for my first sample.

00:00:44.870 --> 00:00:47.080
I know it's very confusing,
because you can consider

00:00:47.080 --> 00:00:49.000
that a sample, the
set to be a sample,

00:00:49.000 --> 00:00:52.787
or you could consider each
member of the set is a sample.

00:00:52.787 --> 00:00:54.620
So that can be a little
bit confusing there.

00:00:54.620 --> 00:00:56.050
But I have this
first sample mean,

00:00:56.050 --> 00:00:57.758
and then I keep doing
that over and over.

00:00:57.758 --> 00:01:00.430
In my second sample,
my sample size is four.

00:01:00.430 --> 00:01:02.970
I got four instances of
this random variable,

00:01:02.970 --> 00:01:05.770
I average them, I have
another sample mean.

00:01:05.770 --> 00:01:08.720
And the cool thing about
the central limit theorem,

00:01:08.720 --> 00:01:10.800
is as I keep plotting
the frequency

00:01:10.800 --> 00:01:13.100
distribution of my
sample means, it

00:01:13.100 --> 00:01:14.730
starts to approach
something that

00:01:14.730 --> 00:01:17.150
approximates the
normal distribution.

00:01:17.150 --> 00:01:19.310
And it's going to do a
better job of approximating

00:01:19.310 --> 00:01:22.614
that normal distribution
as n gets larger.

00:01:22.614 --> 00:01:24.280
And just so we have
a little terminology

00:01:24.280 --> 00:01:28.030
on our belt, this
frequency distribution

00:01:28.030 --> 00:01:30.640
right here that
I've plotted out,

00:01:30.640 --> 00:01:34.900
or here, or up here that
I started plotting out,

00:01:34.900 --> 00:01:37.520
that is called-- and
it's kind of confusing,

00:01:37.520 --> 00:01:39.590
because we use the word
sample so much-- that

00:01:39.590 --> 00:01:51.100
is called the sampling
distribution of the sample

00:01:51.100 --> 00:01:52.191
mean.

00:01:52.191 --> 00:01:53.690
And let's dissect
this a little bit,

00:01:53.690 --> 00:01:55.670
just so that this
long description

00:01:55.670 --> 00:01:58.810
of this distribution starts
to make a little bit of sense.

00:01:58.810 --> 00:02:01.230
When we say it's the
sampling distribution,

00:02:01.230 --> 00:02:03.060
that's telling us that
it's being derived

00:02:03.060 --> 00:02:06.300
from-- it's a distribution
of some statistic, which

00:02:06.300 --> 00:02:08.550
in this case happens
to be the sample mean--

00:02:08.550 --> 00:02:10.870
and we're deriving
it from samples

00:02:10.870 --> 00:02:12.190
of an original distribution.

00:02:12.190 --> 00:02:13.790
So each of these.

00:02:13.790 --> 00:02:16.610
So this is my first sample,
my sample size is four.

00:02:16.610 --> 00:02:18.590
I'm using the
statistic, the mean.

00:02:18.590 --> 00:02:20.590
I actually could have
done it with other things,

00:02:20.590 --> 00:02:24.050
I could have done the mode or
the range or other statistics.

00:02:24.050 --> 00:02:28.460
But sampling distribution
of the sample mean

00:02:28.460 --> 00:02:29.710
is the most common one.

00:02:29.710 --> 00:02:31.690
It's probably, in
my mind, the best

00:02:31.690 --> 00:02:34.880
place to start learning about
the central limit theorem,

00:02:34.880 --> 00:02:37.160
and even frankly,
sampling distribution.

00:02:37.160 --> 00:02:38.320
So that's what it's called.

00:02:38.320 --> 00:02:39.720
And just as a little bit
of background-- and I'll

00:02:39.720 --> 00:02:41.230
prove this to you
experimentally,

00:02:41.230 --> 00:02:44.070
not mathematically, but
I think the experimental

00:02:44.070 --> 00:02:46.800
is on some levels more
satisfying with statistics--

00:02:46.800 --> 00:02:52.290
that this will
have the same mean

00:02:52.290 --> 00:02:54.630
as your original distribution.

00:02:54.630 --> 00:02:56.360
As your original
distribution right here.

00:02:56.360 --> 00:02:59.050
So it has the same mean, but
we'll see in the next video

00:02:59.050 --> 00:03:01.840
that this is actually going
to start approximating

00:03:01.840 --> 00:03:04.480
a normal distribution, even
though my original distribution

00:03:04.480 --> 00:03:07.510
that this is kind of generated
from, is completely non-normal.

00:03:07.510 --> 00:03:10.750
So let's do that with
this app right here.

00:03:10.750 --> 00:03:13.176
And just to give proper
credit where credit is due,

00:03:13.176 --> 00:03:15.550
this is-- I think was developed
at Rice University-- this

00:03:15.550 --> 00:03:16.675
is from onlinestatbook.com.

00:03:23.030 --> 00:03:25.280
This is their app, which I
think is a really neat app,

00:03:25.280 --> 00:03:28.040
because it really helps you
to visualize what a sampling

00:03:28.040 --> 00:03:30.330
distribution of
the sample mean is.

00:03:30.330 --> 00:03:33.680
So I can literally create my
own custom distribution here.

00:03:33.680 --> 00:03:35.900
So let me make
something kind of crazy.

00:03:35.900 --> 00:03:38.680
So you could do this, in
theory, with a discrete

00:03:38.680 --> 00:03:42.820
or a continuous probability
density function.

00:03:42.820 --> 00:03:45.370
But what they have here, we
could take on one of 32 values,

00:03:45.370 --> 00:03:47.578
and I'm just going to set
the different probabilities

00:03:47.578 --> 00:03:49.730
of getting any of
those 32 values.

00:03:49.730 --> 00:03:52.295
So clearly, this right here
is not a normal distribution.

00:03:52.295 --> 00:03:55.772
It looks a little bit bimodal,
but it doesn't have long tails.

00:03:55.772 --> 00:03:57.980
But what I want to do is,
first just use a simulation

00:03:57.980 --> 00:04:00.400
to understand, or to
better understand,

00:04:00.400 --> 00:04:02.840
what the sampling
distribution is all about.

00:04:02.840 --> 00:04:04.590
So what I'm going
to do is, I'm going

00:04:04.590 --> 00:04:07.010
to take-- we'll start
with-- five at a time.

00:04:07.010 --> 00:04:09.924
So my sample size
is going to be five.

00:04:09.924 --> 00:04:12.090
And so when I click animated,
what it's going to do,

00:04:12.090 --> 00:04:15.350
is it's going to take five
samples from this probability

00:04:15.350 --> 00:04:16.319
distribution function.

00:04:16.319 --> 00:04:18.110
It's going to take five
samples, and you're

00:04:18.110 --> 00:04:19.850
going to see them
when I click animated,

00:04:19.850 --> 00:04:22.350
it's going to average them and
plot the average down here.

00:04:22.350 --> 00:04:23.250
And then I'm going
to click it again,

00:04:23.250 --> 00:04:24.520
and it's going to do it again.

00:04:24.520 --> 00:04:26.520
So there you go, it got
five samples from there,

00:04:26.520 --> 00:04:29.440
it averaged them,
and it hit there.

00:04:29.440 --> 00:04:31.070
So what I just do?

00:04:31.070 --> 00:04:34.250
I clicked-- oh, I
wanted to clear that.

00:04:34.250 --> 00:04:36.042
Let me make this
bottom one none.

00:04:36.042 --> 00:04:37.250
So let me do that over again.

00:04:37.250 --> 00:04:39.780
So I'm going to
take five at time.

00:04:39.780 --> 00:04:43.210
So I took five samples from up
here, and then it took its mean

00:04:43.210 --> 00:04:44.390
and plotted the mean there.

00:04:44.390 --> 00:04:45.970
Let me do it again.

00:04:45.970 --> 00:04:48.390
Five samples from this
probability distribution

00:04:48.390 --> 00:04:50.110
function, plotted
it right there.

00:04:50.110 --> 00:04:51.080
I could keep doing it.

00:04:51.080 --> 00:04:52.390
It'll take some time.

00:04:52.390 --> 00:04:54.511
But you can see I
plotted it right there.

00:04:54.511 --> 00:04:57.010
Now I could do this 1,000 times,
it's going to take forever.

00:04:57.010 --> 00:04:59.370
Let's say I just wanted
to do it 1,000 times.

00:04:59.370 --> 00:05:01.080
So this program,
just to be clear,

00:05:01.080 --> 00:05:02.913
it's actually generating
the random numbers.

00:05:02.913 --> 00:05:04.500
This isn't like
a rigged program.

00:05:04.500 --> 00:05:07.000
It's actually going to generate
the random numbers according

00:05:07.000 --> 00:05:08.870
to this probability
distribution function.

00:05:08.870 --> 00:05:11.220
It's going to take five at
a time, find their means,

00:05:11.220 --> 00:05:12.110
and plot the means.

00:05:12.110 --> 00:05:15.020
So if I click 10,000, it's
going to do that 10,000 times.

00:05:15.020 --> 00:05:17.720
So it's going to take five
numbers from here 10,000 times

00:05:17.720 --> 00:05:21.090
and find their
means 10,000 times

00:05:21.090 --> 00:05:22.780
and then plot the
10,000 means here.

00:05:22.780 --> 00:05:25.144
So let's do that.

00:05:25.144 --> 00:05:25.810
So there you go.

00:05:25.810 --> 00:05:27.670
And notice it's
already looking a lot

00:05:27.670 --> 00:05:29.280
like a normal distribution.

00:05:29.280 --> 00:05:32.600
And like I said, the original
mean of my crazy distribution

00:05:32.600 --> 00:05:38.160
here was 14.45, and after doing
10,000 samples-- or 10,000

00:05:38.160 --> 00:05:41.040
trials-- my mean here is 14.42.

00:05:41.040 --> 00:05:43.492
So I'm already getting pretty
close to the mean there.

00:05:43.492 --> 00:05:45.950
My standard deviation, you
might notice, is less than that.

00:05:45.950 --> 00:05:47.990
We'll talk about that
in a future video.

00:05:47.990 --> 00:05:51.640
And the skew and
kurtosis, these are

00:05:51.640 --> 00:05:54.617
things that help us measure
how normal a distribution is.

00:05:54.617 --> 00:05:56.700
And I've talked a little
bit about it in the past,

00:05:56.700 --> 00:06:01.210
and let me actually just diverge
a little bit, it's interesting.

00:06:01.210 --> 00:06:03.190
And they're fairly
straightforward concepts.

00:06:03.190 --> 00:06:05.770
Skew literally
tells-- so if this

00:06:05.770 --> 00:06:08.740
is-- let me do it in
a different color--

00:06:08.740 --> 00:06:11.260
if this is a perfect
normal distribution--

00:06:11.260 --> 00:06:14.840
and clearly my drawing is
very far from perfect--

00:06:14.840 --> 00:06:17.600
if that's a perfect
distribution,

00:06:17.600 --> 00:06:19.556
this would have a skew of zero.

00:06:19.556 --> 00:06:20.930
If you have a
positive skew, that

00:06:20.930 --> 00:06:24.040
means you have a larger right
tail than you would otherwise

00:06:24.040 --> 00:06:24.540
expect.

00:06:24.540 --> 00:06:27.690
So something with a positive
skew might look like this.

00:06:27.690 --> 00:06:29.960
It would have a large
tail to the right.

00:06:29.960 --> 00:06:33.796
So this would be
a positive skew,

00:06:33.796 --> 00:06:35.420
which makes it a
little less than ideal

00:06:35.420 --> 00:06:36.472
for normal distribution.

00:06:36.472 --> 00:06:38.180
And a negative skew
would look like this,

00:06:38.180 --> 00:06:40.630
it has a long tail to the left.

00:06:40.630 --> 00:06:43.380
So negative skew
might look like that.

00:06:43.380 --> 00:06:44.842
So that is a negative skew.

00:06:44.842 --> 00:06:46.300
If you have trouble
remembering it,

00:06:46.300 --> 00:06:47.960
just remember which
direction the tail is going.

00:06:47.960 --> 00:06:49.990
This tail is going towards
a negative direction,

00:06:49.990 --> 00:06:51.930
this tail is going to
the positive direction.

00:06:51.930 --> 00:06:53.305
So if something
has no skew, that

00:06:53.305 --> 00:06:56.107
means that it's nice and
symmetrical around its mean.

00:06:56.107 --> 00:06:58.190
Now kurtosis, which sounds
like a very fancy word,

00:06:58.190 --> 00:07:03.720
is similarly not that
fancy of an idea.

00:07:03.720 --> 00:07:08.344
So once again, if I were to draw
a perfect normal distribution.

00:07:08.344 --> 00:07:10.260
Remember, there is no
one normal distribution,

00:07:10.260 --> 00:07:11.676
you could have
different means and

00:07:11.676 --> 00:07:14.600
different standard deviations.

00:07:14.600 --> 00:07:16.990
Let's say that's a perfect
normal distribution.

00:07:16.990 --> 00:07:21.820
If I have positive kurtosis,
what's going to happen

00:07:21.820 --> 00:07:24.160
is, I'm going to have
fatter tails-- let

00:07:24.160 --> 00:07:27.030
me draw it a little nicer than
that-- I'm going to have fatter

00:07:27.030 --> 00:07:30.729
tails, but I'm going to
have a more pointy peak.

00:07:30.729 --> 00:07:32.270
I didn't have to
draw it that pointy,

00:07:32.270 --> 00:07:33.440
let me draw it like this.

00:07:33.440 --> 00:07:36.250
I'm going to have
fatter tails, and I'm

00:07:36.250 --> 00:07:39.500
going to have a more pointy
peak than a normal distribution.

00:07:39.500 --> 00:07:41.820
So this right here
is positive kurtosis.

00:07:41.820 --> 00:07:44.572
So something that has
positive kurtosis-- depending

00:07:44.572 --> 00:07:46.280
on how positive it
is-- it tells you it's

00:07:46.280 --> 00:07:51.360
a little bit more pointy than
a real normal distribution.

00:07:51.360 --> 00:07:54.900
And negative kurtosis
has smaller tails,

00:07:54.900 --> 00:07:57.400
but it's smoother
near the middle.

00:07:57.400 --> 00:07:58.650
So it's like this.

00:07:58.650 --> 00:08:02.380
So something like this would
have negative kurtosis.

00:08:04.990 --> 00:08:07.740
And maybe in future videos we'll
explore that in more detail,

00:08:07.740 --> 00:08:09.420
but in the context
of the simulation,

00:08:09.420 --> 00:08:12.410
it's just telling us how
normal this distribution is.

00:08:12.410 --> 00:08:14.650
So when our sample
size was n equal 5

00:08:14.650 --> 00:08:16.590
and we did 10,000 trials,
we got pretty close

00:08:16.590 --> 00:08:17.820
to a normal distribution.

00:08:17.820 --> 00:08:21.304
Let's do another 10,000 trials,
just to see what happens.

00:08:21.304 --> 00:08:23.220
It looks even more like
a normal distribution.

00:08:23.220 --> 00:08:24.826
Our mean is now the
exact same number,

00:08:24.826 --> 00:08:26.450
but we still have a
little bit of skew,

00:08:26.450 --> 00:08:27.784
and a little bit of kurtosis.

00:08:27.784 --> 00:08:30.450
Now let's see what happens if we
do the same thing with a larger

00:08:30.450 --> 00:08:31.790
sample size.

00:08:31.790 --> 00:08:33.679
And we could actually
do them simultaneously.

00:08:33.679 --> 00:08:35.100
So here's n equal 5.

00:08:35.100 --> 00:08:37.909
Let's do here, n equals 25.

00:08:37.909 --> 00:08:39.380
Just let me clear them.

00:08:39.380 --> 00:08:42.179
I'm going to do the sampling
distribution of the sample

00:08:42.179 --> 00:08:42.932
mean.

00:08:42.932 --> 00:08:44.640
And I'm going to run
10,000 trials-- I'll

00:08:44.640 --> 00:08:47.367
do one animated trial, just so
you remember what's going on.

00:08:47.367 --> 00:08:49.700
So I'm literally taking first
five samples from up here,

00:08:49.700 --> 00:08:50.690
find their mean.

00:08:50.690 --> 00:08:55.420
Now I'm taking 25 samples
from up here, find its mean,

00:08:55.420 --> 00:08:56.990
and then plotting it down here.

00:08:56.990 --> 00:08:59.200
So here the sample size
is 25, here it's five.

00:08:59.200 --> 00:09:01.220
I'll do it one more time.

00:09:01.220 --> 00:09:03.310
I take five, get
the mean, plot it.

00:09:03.310 --> 00:09:07.960
Take 25, get the mean, and
then plot it down there.

00:09:07.960 --> 00:09:09.950
This is a larger sample size.

00:09:09.950 --> 00:09:15.660
Now that thing that I just did,
I'm going to do 10,000 times.

00:09:15.660 --> 00:09:17.390
And remember, our
first distribution

00:09:17.390 --> 00:09:21.150
was just this really crazy
very non-normal distribution,

00:09:21.150 --> 00:09:23.290
but once we did it--
whoops, I didn't

00:09:23.290 --> 00:09:24.340
want to make it that big.

00:09:27.380 --> 00:09:28.800
Scroll up a little bit.

00:09:28.800 --> 00:09:29.970
So here, what's interesting?

00:09:29.970 --> 00:09:31.630
I mean they both
look a little normal,

00:09:31.630 --> 00:09:33.505
but if you look at the
skew and the kurtosis,

00:09:33.505 --> 00:09:36.460
when our sample size is
larger, it's more normal.

00:09:36.460 --> 00:09:40.090
This has a lower skew than when
our sample size was only five.

00:09:40.090 --> 00:09:42.900
And it has a less
negative kurtosis

00:09:42.900 --> 00:09:44.750
than when our sample
size was five.

00:09:44.750 --> 00:09:47.179
So this is a more
normal distribution.

00:09:47.179 --> 00:09:49.220
And one thing that we're
going to explore further

00:09:49.220 --> 00:09:53.180
in a future video, is not only
is it more normal in its shape,

00:09:53.180 --> 00:09:55.810
but it's also tighter
fit around the mean.

00:09:55.810 --> 00:09:58.550
And you can even think about
why that kind of makes sense.

00:09:58.550 --> 00:10:01.370
When your sample size
is larger, your odds

00:10:01.370 --> 00:10:03.760
of getting really far away
from the mean is lower.

00:10:03.760 --> 00:10:05.200
Because it's very
low likelihood,

00:10:05.200 --> 00:10:07.249
if you're taking 25 samples,
or 100 samples, that

00:10:07.249 --> 00:10:09.540
you're just going to get a
bunch of stuff way out here,

00:10:09.540 --> 00:10:10.500
or a bunch of
stuff way out here.

00:10:10.500 --> 00:10:12.937
You're very likely to get a
reasonable spread of things.

00:10:12.937 --> 00:10:15.270
So it makes sense that your
mean-- your sample mean-- is

00:10:15.270 --> 00:10:17.664
less likely to be far
away from the mean.

00:10:17.664 --> 00:10:20.080
We're going to talk a little
bit more about in the future.

00:10:20.080 --> 00:10:21.940
But hopefully this
kind of satisfies you

00:10:21.940 --> 00:10:23.340
that-- at least
experimentally, I

00:10:23.340 --> 00:10:25.750
haven't proven it to you with
mathematical rigor, which

00:10:25.750 --> 00:10:27.370
hopefully we'll
do in the future.

00:10:27.370 --> 00:10:28.720
But hopefully this
satisfies you, at least

00:10:28.720 --> 00:10:30.928
experimentally, that the
central limit theorem really

00:10:30.928 --> 00:10:32.340
does apply to any distribution.

00:10:32.340 --> 00:10:34.210
I mean, this is a
crazy distribution.

00:10:34.210 --> 00:10:38.150
And I encourage you to use this
applet at onlinestatbook.com

00:10:38.150 --> 00:10:40.340
and experiment with
other crazy distributions

00:10:40.340 --> 00:10:41.540
to believe it for yourself.

00:10:41.540 --> 00:10:43.710
But the interesting
things are that we're

00:10:43.710 --> 00:10:45.140
approaching a
normal distribution,

00:10:45.140 --> 00:10:47.680
but as my sample
size got larger,

00:10:47.680 --> 00:10:51.143
it's a better fit for
a normal distribution.

