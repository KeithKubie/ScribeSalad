WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.740
Okay. I hope you enjoyed the course to this point.

00:00:02.740 --> 00:00:05.390
In this lesson, we're going to work with a collection of

00:00:05.390 --> 00:00:08.150
tweets. Now, I need to make clear that since this is

00:00:08.150 --> 00:00:11.070
a collection that was gathered some time ago, it does not

00:00:11.070 --> 00:00:13.070
reflect the state of Twitter feeds as they look right

00:00:13.070 --> 00:00:17.300
now. It's a small snapshot in time. So our tweets had

00:00:17.300 --> 00:00:20.822
the following form. So you can see that there is a,

00:00:20.822 --> 00:00:25.340
unique identifier. There will be text for the tweet itself and

00:00:25.340 --> 00:00:28.040
then an entities field. Now the entities field is broken

00:00:28.040 --> 00:00:30.290
down into user mentions, urls and hashtags and we actually

00:00:30.290 --> 00:00:33.120
took a look at one tweet, in the last lesson,

00:00:33.120 --> 00:00:35.700
so this should be at least partially familiar to you.

00:00:35.700 --> 00:00:39.920
User mentions, urls and hashtags represent that type of data,

00:00:39.920 --> 00:00:43.430
and where it's found in the text of a tweet.

00:00:43.430 --> 00:00:46.000
It's been extracted for us and stored in these individual

00:00:46.000 --> 00:00:50.349
fields. Okay and then with each tweet, there's information about the

00:00:50.349 --> 00:00:52.278
user at the time the tweet was made. As

00:00:52.278 --> 00:00:55.450
you will see, our tweet documents actually contain many more

00:00:55.450 --> 00:00:58.299
fields. We're representing those by the ellipses you see

00:00:58.299 --> 00:01:01.130
in this example. As with the other data sets we've

00:01:01.130 --> 00:01:04.599
considered, this type of data, is representative of what

00:01:04.599 --> 00:01:08.070
you might work with as a data scientist. Many data

00:01:08.070 --> 00:01:10.900
scientists are employed in spaces that work heavily with social

00:01:10.900 --> 00:01:15.420
media. Google, Facebook, and Twitter are some of the most

00:01:15.420 --> 00:01:18.890
prominent of thousands of firms, actually, that employ people to analyze this

00:01:18.890 --> 00:01:21.840
type of data. Now, just for a moment imagine the types of

00:01:21.840 --> 00:01:24.710
analysis you might want to do on tweets. Common for this type

00:01:24.710 --> 00:01:28.870
of data is to understand the behavior of users, and the networks involved.

00:01:28.870 --> 00:01:31.270
There are lots of ways we can do that. Now, one of

00:01:31.270 --> 00:01:34.630
the most powerful things about putting our data in a database is

00:01:34.630 --> 00:01:38.610
that most databases provide some analytics tools built in, that enable us

00:01:38.610 --> 00:01:40.670
to explore our data a bit and get a sense for the story

00:01:40.670 --> 00:01:44.910
it tells. In MongoDB, the built-in analytics tools take

00:01:44.910 --> 00:01:47.180
the form of what we call the aggregation framework.

00:01:48.180 --> 00:01:50.310
While not a replacement for map reduce in a

00:01:50.310 --> 00:01:53.490
lot of situations, it does provide a powerful tool for

00:01:53.490 --> 00:01:57.000
exploring our data, and exploring it whether we're auditing

00:01:57.000 --> 00:01:59.950
the quality of our data or doing some analysis.

00:01:59.950 --> 00:02:03.120
And with each major release of MongoDB, this becomes

00:02:03.120 --> 00:02:05.824
a more powerful tool. There are several really valuable feature

00:02:05.824 --> 00:02:07.600
enhancements actually in the 2.6 release.

