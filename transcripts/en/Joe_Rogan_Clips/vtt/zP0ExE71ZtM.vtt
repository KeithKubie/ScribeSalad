WEBVTT

1
00:00:00.000 --> 00:00:02.220
If I had Google glass,
I didn't know him already.

2
00:00:02.330 --> 00:00:02.571
<v 1>Yeah.</v>

3
00:00:02.571 --> 00:00:07.460
If I had that memory link wire thing that Jamie's worried about,

4
00:00:07.610 --> 00:00:09.860
Jamie's going to be the first one to get it and then he's going to like organize

5
00:00:09.861 --> 00:00:12.050
to make sure that no one at my thought on that too.

6
00:00:12.051 --> 00:00:15.230
It's like who is going to be the first one they get it and how you had the side

7
00:00:15.231 --> 00:00:18.200
that I'm,
well for sure like money,

8
00:00:18.710 --> 00:00:21.800
Marcus Brownley and Lou from unbox therapy,

9
00:00:21.801 --> 00:00:24.530
they'll get it first and they'll put it on and then they'll start running the

10
00:00:24.531 --> 00:00:28.380
world that does not have it and they go,
ah,
no one else gets this shot.

11
00:00:29.180 --> 00:00:31.630
But Mark Zuckerberg probably already has it.
You don't want to know.

12
00:00:31.631 --> 00:00:34.610
And I think that right now,
yeah.
Fend his case.

13
00:00:38.990 --> 00:00:43.790
Yeah.
It's um,
it's coming.
Something's coming.
Yeah,
man.
What's it going to be?

14
00:00:43.820 --> 00:00:46.850
Who knows what's going to be,
yeah,
something's coming.

15
00:00:47.010 --> 00:00:49.490
Something's going to be more invasive than what we're experiencing now,

16
00:00:50.300 --> 00:00:53.300
so I can be sure of.
You're going to figure out how to get more and more data.

17
00:00:53.540 --> 00:00:56.870
You know,
Sam Harris has a really interesting podcast.
It's out.

18
00:00:56.871 --> 00:00:59.600
It's either the one that's going on,
right.

19
00:01:00.140 --> 00:01:04.520
Maybe the two weeks ago.
And it was all about,
so I should probably find it.

20
00:01:04.850 --> 00:01:08.810
It was all about um,
privacy,
privacy.

21
00:01:08.811 --> 00:01:13.320
And what's the difference between the way a different tech companies approach

22
00:01:13.321 --> 00:01:17.960
privacy actually makes your respect how apple does it?
Oh yeah,
yeah.

23
00:01:17.990 --> 00:01:21.920
I mean they apparently they do it much more.
Um,

24
00:01:22.730 --> 00:01:26.840
I guess the word would be there more ethical about it was that they're trying

25
00:01:26.841 --> 00:01:30.290
not to give away any,
the trouble with Facebook is what it's called.

26
00:01:30.900 --> 00:01:32.430
<v 0>I was reading a thing yesterday that,
you know,</v>

27
00:01:32.431 --> 00:01:36.180
you put those a doorbell things on,
you know,
like ring,
you know,

28
00:01:36.181 --> 00:01:40.500
the records.
People coming up to me and they said,
you know,

29
00:01:40.800 --> 00:01:42.720
you think it's cool for you and your family,

30
00:01:43.200 --> 00:01:48.200
but the ups guy or all these delivery people are getting their picture taken and

31
00:01:48.631 --> 00:01:50.770
sent to a database every day.
Right?

32
00:01:50.780 --> 00:01:54.840
Like these people are being monitored all the time.
So while it's good for you,

33
00:01:54.841 --> 00:01:57.360
it's not that great for these other people that visit you.

34
00:01:57.470 --> 00:02:01.130
<v 1>This guy's name is Roger Mcnamee.
That's the,
the trouble of Facebook.</v>

35
00:02:01.131 --> 00:02:03.410
It's episode one 52 it's really,

36
00:02:03.411 --> 00:02:08.411
it's very interesting because what would it goes into is about how tech

37
00:02:08.661 --> 00:02:13.661
companies figured out how to tap into a resource that no one thought of in that

38
00:02:14.661 --> 00:02:17.420
resources.
Your data and how much is that worth?
Well,

39
00:02:17.421 --> 00:02:20.090
it turns out it's worth fucking untold billions.

40
00:02:20.570 --> 00:02:24.050
It's one of the most valuable things cause it you can direct market to people.

41
00:02:24.051 --> 00:02:27.230
You could find out what people are into,
what they're not into.
You get,

42
00:02:27.410 --> 00:02:29.030
you get a lot of people that you can get ahold of.

43
00:02:29.480 --> 00:02:34.460
And we kind of gave our consent to this without understanding it.
Yeah.

44
00:02:34.550 --> 00:02:39.350
And they got in through a loophole and this is how they're able to make,

45
00:02:39.550 --> 00:02:41.150
you know,
ungodly amounts of money

46
00:02:41.450 --> 00:02:44.990
<v 0>just because we want it to have that cool feature.
So you just say,
yeah,</v>

47
00:02:44.991 --> 00:02:46.190
here's a ticket from me.
I

48
00:02:46.220 --> 00:02:47.730
<v 1>mean,
thinking about the amount of money,</v>

49
00:02:47.940 --> 00:02:51.390
something like Facebook brings in versus what it is.
Like what is it?

50
00:02:51.420 --> 00:02:53.310
What are you doing?
What are you doing this making all that money.

51
00:02:53.740 --> 00:02:57.220
They're providing people with data,
you know,

52
00:02:57.270 --> 00:03:00.580
and they're also getting people to the,
the,
it's like a,

53
00:03:00.590 --> 00:03:05.590
an ongoing psychological experiment in what makes people engage.

54
00:03:06.910 --> 00:03:11.820
Like what makes people comment more turns out it's anger.
Oh really?
Yeah.

55
00:03:12.070 --> 00:03:16.510
It turns out that what makes people engage the most is things they disagree with

56
00:03:16.750 --> 00:03:20.450
when they started having fights.
So having fights back and forth.
So you,

57
00:03:20.650 --> 00:03:25.450
you get people to get really into these polarizing subject,
right?

58
00:03:25.720 --> 00:03:26.830
And then you,

59
00:03:26.920 --> 00:03:30.160
once they start looking for those subjects and those subjects starts showing up

60
00:03:30.161 --> 00:03:33.040
in their feet.
So there's all sorts of things that they get angry about.

61
00:03:33.041 --> 00:03:35.290
So then they start interacting with these things.
The more you interact,

62
00:03:35.291 --> 00:03:37.780
the more more it shows up in your feed.

63
00:03:37.810 --> 00:03:41.710
And all the while they're profiting on enraging you.

64
00:03:42.550 --> 00:03:44.890
I'm like God,
I mean this is essentially what they do.

65
00:03:44.920 --> 00:03:49.920
She creepy Facebook patent uses image recognition to scan your personal photos

66
00:03:50.321 --> 00:03:51.154
for brands.

67
00:03:51.170 --> 00:03:53.700
<v 0>Oh my God.
Yeah.</v>

68
00:03:53.701 --> 00:03:57.380
So they just take all your photos and the Dorito bags in the back

69
00:03:57.830 --> 00:04:02.270
<v 1>applying computer vision algorithms to user uploaded multimedia objects to</v>

70
00:04:02.271 --> 00:04:05.480
detect specific objects within the multimedia object.

71
00:04:05.840 --> 00:04:10.840
And promoting the uploaded multimedia object from a user's news feed to a

72
00:04:11.601 --> 00:04:16.500
sponsored stories area.
That's what the patent was awarded for.

73
00:04:17.710 --> 00:04:22.580
[inaudible] vision content detection for sponsored stories.

74
00:04:22.880 --> 00:04:23.780
Wow,

75
00:04:24.300 --> 00:04:25.860
<v 0>that's crazy,
man.
Yeah.</v>

76
00:04:26.370 --> 00:04:30.150
You snap a selfie sipping a Unicorn frappe it's Starbucks and then shares that

77
00:04:30.151 --> 00:04:33.360
selfie on Facebook or Instagram.

78
00:04:33.780 --> 00:04:37.110
Facebook's newly patented technology can theoretically scan the photo,

79
00:04:37.111 --> 00:04:41.430
spot the Starbucks cup with the help of an image object recognition algorithm,

80
00:04:42.150 --> 00:04:44.340
and then sell that info to Starbucks.

81
00:04:45.120 --> 00:04:47.850
Alerting the coffee giant of the fact that you like it's product.

82
00:04:48.560 --> 00:04:51.620
<v 1>Well,
they're already doing a version of that with your search,</v>

83
00:04:51.990 --> 00:04:55.210
with the things you're looking at.
You know when you go through their browser,

84
00:04:55.220 --> 00:04:56.060
they're already doing that.

85
00:04:56.100 --> 00:04:57.810
<v 0>Well,
they're doing it also with voice.</v>

86
00:04:58.170 --> 00:05:02.700
Your phone is listening to you all the time.
If you have Alexa in your home,

87
00:05:02.701 --> 00:05:05.670
it's listening.
My kids and when we do it all the time,

88
00:05:05.671 --> 00:05:08.430
like if you talking about something and they know all of a sudden you see,

89
00:05:08.700 --> 00:05:12.900
I was performing in Boise and so we were talking about Boise,
Boise,
Boise,

90
00:05:12.901 --> 00:05:17.430
and then everybody on their Instagram was getting an ad for vacationing and

91
00:05:17.431 --> 00:05:20.550
Boise.
See,
that seems just from a speaking it.
Yeah.

92
00:05:20.820 --> 00:05:24.570
That seems like a really serious thing.
It is.

93
00:05:24.600 --> 00:05:27.030
It seems like a really serious thing that everybody is just like,
oh,

94
00:05:27.031 --> 00:05:29.460
this is happening.
Yeah.
I don't remember signing off on this.

95
00:05:29.461 --> 00:05:33.390
The technology is ahead of our anger or our recognition of it.
Yeah.

96
00:05:33.630 --> 00:05:35.120
We don't understand.
Yeah.

97
00:05:35.150 --> 00:05:39.490
So it's already happened by the time you're upset that it exists,
right?
Yeah.

98
00:05:39.520 --> 00:05:44.460
It's,
it's in full full force right now.
Yeah.
Yeah.
It's really weird.

99
00:05:44.461 --> 00:05:48.210
It's really weird.
It's really weird.
I mean,
we're just talking about it.

100
00:05:48.211 --> 00:05:52.920
This is just,
we think it's,
you're just in your home.
You were in a private place,

101
00:05:54.180 --> 00:05:57.560
but these phones,
they're just listen,
you know,
we just all have them.
And again,

102
00:05:57.590 --> 00:05:58.250
this is something

103
00:05:58.250 --> 00:06:02.990
<v 1>that didn't exist 10 years ago,
15 years ago.
These concerns didn't exist.</v>

104
00:06:03.320 --> 00:06:05.570
What would be the concerns 15 years from now?

105
00:06:05.840 --> 00:06:09.560
Like how much more invasive as it's going to get before we even recognize that

106
00:06:09.561 --> 00:06:12.340
it's happening because this is,
this is something,
the,
the,

107
00:06:12.341 --> 00:06:15.470
the listening in on things is something that people didn't think about before it

108
00:06:15.471 --> 00:06:18.680
happened.
Right now.
They know it does.
Well,

109
00:06:18.681 --> 00:06:23.480
the face recognition thing is there's a lot of articles on that and how that we

110
00:06:23.481 --> 00:06:25.970
don't realize what they're trying to think.
Totally makes sense.
Right.

111
00:06:25.971 --> 00:06:30.650
Especially if so many people's phones use face recognition software with the

112
00:06:30.651 --> 00:06:34.880
Samsung phones have it,
you know,
my,
my galaxy note nine has it.

113
00:06:35.080 --> 00:06:38.810
Hi phones have it.
Yeah,
and you're psyched about it.
You're just like,
oh,

114
00:06:38.811 --> 00:06:41.720
that's cool.
I don't have to put in my password anymore.
It's just look at it.

115
00:06:41.720 --> 00:06:45.920
Yeah.
I'm in my app.
They also have one that's an iris scanner on the note.

116
00:06:46.100 --> 00:06:50.630
The note scans your irises.
Oh really?
Wow.
Bro.

117
00:06:51.050 --> 00:06:55.490
It's quick too.
It looks at your eyeballs like,
Yep,
you're you,
she fucked.

118
00:06:55.510 --> 00:06:57.470
You know,
man.
What does that say,
Jamie?

119
00:06:58.760 --> 00:07:00.410
I was trying to find this the first time you brought up,

120
00:07:00.411 --> 00:07:04.550
but I know that there's these masks that exist that are in quotes like

121
00:07:04.551 --> 00:07:07.920
hyperrealistic masks that can be used to,
I don't know if it's this,

122
00:07:07.980 --> 00:07:10.370
it's used to help the facial recognition,

123
00:07:10.371 --> 00:07:13.840
but I think people are using them to trick it and do fake stuff and like,
no,

124
00:07:13.870 --> 00:07:16.160
I don't know if you could commit a robbery with that on and Whoa,

125
00:07:16.620 --> 00:07:18.830
just like having a ski mask on now.
They just can't see your face.

126
00:07:18.831 --> 00:07:21.570
But it'll thinks I'm right.
If you had a Hoodie on.
Yeah.

127
00:07:21.980 --> 00:07:25.010
What about in minority report?
Remember when they had to pull his eye,

128
00:07:25.011 --> 00:07:28.430
they were selling eyeballs on the black market for the eye scan to get into

129
00:07:28.431 --> 00:07:32.780
buildings and stuff to do with that is put like a Bandana around your mouth.

130
00:07:33.410 --> 00:07:36.260
Right?
So it could,
no one could see your mouth moving.

131
00:07:36.560 --> 00:07:40.400
Have that thing on your sunglasses.
Yeah,
but my,

132
00:07:40.401 --> 00:07:44.410
even my iPhone gets through my sunglasses.
I don't know how I know.

133
00:07:44.420 --> 00:07:48.080
So let's facial recognition.
So,
but,
but what I'm saying is with this,

134
00:07:48.500 --> 00:07:52.850
like if you'd wanted to rob someone and have something like even the facial

135
00:07:52.851 --> 00:07:54.020
recognition software would,

136
00:07:54.800 --> 00:07:57.860
would think that it would legitimately think you were somebody else.

137
00:07:58.580 --> 00:08:01.640
Hopefully now.
And what about fully,
if you're wondering doing our crops.

138
00:08:01.750 --> 00:08:03.820
Someone tried to rob somebody and we're trying to rob.
Sorry.

139
00:08:03.850 --> 00:08:06.380
Hopefully not you guys.
Criminals.

140
00:08:08.770 --> 00:08:13.280
That's crazy.
It's kind of happened but it's so fast too.
I mean,
you know,

141
00:08:13.281 --> 00:08:14.700
this is so new wall.

142
00:08:14.710 --> 00:08:18.960
So the like the special effects technology that allows people to make faces
like,

143
00:08:19.000 --> 00:08:23.180
oh look how beautiful those things look like.
So close to a person.

144
00:08:23.181 --> 00:08:27.650
Commodities for 200 bucks.
You can buy one should do it.
Listen,

145
00:08:28.100 --> 00:08:31.190
I'm going to get you cool.
I should buy you and then see if I

146
00:08:32.940 --> 00:08:35.780
yeah bro.
That would be crazy.
It would be cool.

147
00:08:36.140 --> 00:08:38.690
That'd be crazy to see if he can put up your phone.

148
00:08:38.691 --> 00:08:43.400
It looks super creepy but oh that's so weird.
Yeah,
he looks like a demon.

149
00:08:43.480 --> 00:08:46.880
If they could add a little latex there could be moveable Kinda.
Wow.

150
00:08:46.881 --> 00:08:49.640
That looks pretty real though.
I mean,
you know,
a little creepy,

151
00:08:49.641 --> 00:08:52.310
but that looks pretty accurate.
That's crazy.
Act.

152
00:08:52.311 --> 00:08:54.310
I wouldn't look twice on the walking down the street.

153
00:08:54.311 --> 00:08:56.100
Wouldn't even think about now you'd be like,

154
00:08:56.100 --> 00:08:59.610
<v 0>that guy has a good shave.
It's like beautiful person.
His skin so smooth,</v>

155
00:09:00.800 --> 00:09:02.430
like a baby's bottom.

156
00:09:07.020 --> 00:09:10.320
It was started off,
that's my face.com and it's now been switched to whatever.

157
00:09:10.321 --> 00:09:11.170
This is your mean.

