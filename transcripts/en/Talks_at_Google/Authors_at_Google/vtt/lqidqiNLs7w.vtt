WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.299
&gt;&gt; I could tell you all sorts of things about
Paul, but I'm not going to because I think

00:00:06.299 --> 00:00:10.730
his message is just too important to Ident
anymore. So without any further ado, I'd like

00:00:10.730 --> 00:00:17.770
to welcome Paul Brest. Thank you.
&gt;&gt; BREST: I wonder whether the talk should

00:00:17.770 --> 00:00:24.630
be called, "Philanthropy, with or without
anesthesia," based on that accompanying metaphor.

00:00:24.630 --> 00:00:31.320
So, how Harvey is sorry that he couldn't be
here with me, my co-author. But it also will

00:00:31.320 --> 00:00:36.170
allow me to kind of say some things that he
might disagree with. I'll talk a little bit--I'm

00:00:36.170 --> 00:00:42.140
not going to talk about the book as such except
to tell you that our notion was that this

00:00:42.140 --> 00:00:48.190
is the book that would be found in the self-help
section of bookstores. But it would be of

00:00:48.190 --> 00:00:53.969
an airplane bookstore, airport bookstores,
but it would be in the executive air terminal.

00:00:53.969 --> 00:00:59.851
That hasn't yet been realized. Afterwards,
we can, you know--I'm happy to tell you something

00:00:59.851 --> 00:01:04.519
about the process of writing a book--a number
of you--probably many of you have written

00:01:04.519 --> 00:01:12.950
a code with other people. And writing a book
with one other person has its own complexities,

00:01:12.950 --> 00:01:19.050
not different ones from--when you're sharing
a code. What I want to talk about is not the

00:01:19.050 --> 00:01:23.181
book as such, but the only thing I really
know about, which is, is strategic philanthropy,

00:01:23.181 --> 00:01:29.540
and that's what the book is about. And strategic
philanthropy is basically about reaching a

00:01:29.540 --> 00:01:36.250
goal. And I'm going to use the metaphor of
a destination--probably go further with it

00:01:36.250 --> 00:01:42.680
than you think makes any sense. But I want
to begin by saying strategic philanthropy

00:01:42.680 --> 00:01:48.781
has nothing to say about what your goal should
be. If you think about traveling, you know,

00:01:48.781 --> 00:01:55.729
you might decide you want to go to Africa
to work for the Peace Corps or go to Mount

00:01:55.729 --> 00:02:02.781
Everest to climb it or go across town to see
Aunt Sally or go to a bank to rob it. And

00:02:02.781 --> 00:02:07.649
that's--those are pre-strategic decisions,
right? It's only after you choose the goal

00:02:07.649 --> 00:02:13.450
that you can figure out the best way to go
there. And so too in philanthropy; there are

00:02:13.450 --> 00:02:22.559
also its impossible goals. And what strategic
philanthropy doesn't say which goal to choose,

00:02:22.559 --> 00:02:29.659
it tells you--it's a framework, really, for
how to get their best. You know, there's this

00:02:29.659 --> 00:02:37.129
old saying from the Cunard (ph) lines which
used to have--maybe they still have cruises.

00:02:37.129 --> 00:02:42.040
They used to have great trench--oceanic service.
And it was getting there that is half the

00:02:42.040 --> 00:02:48.290
fun. Well, what's really important about strategic
philanthropy is getting there. If it's not

00:02:48.290 --> 00:02:53.260
fun on the way, then you're probably not going
to continue doing it. But the real objective

00:02:53.260 --> 00:02:57.349
is not the fun of the journey, it's getting
there. So I want to talk about what I think

00:02:57.349 --> 00:03:02.839
are the basic elements. We already--I'll come
back a little bit, but it's having a clear

00:03:02.839 --> 00:03:08.099
goal, having a strategy for achieving the
goal. The strategy needs to be based on a

00:03:08.099 --> 00:03:15.349
sound theory of change, which is the sort
of non-profit term for the theory of how the

00:03:15.349 --> 00:03:21.169
world works. You need feedback and you need
to talk about risk. So I'm going to begin

00:03:21.169 --> 00:03:28.559
by talking about some earlier philanthropists.
Does anybody recognize these guys? Ferdinand

00:03:28.559 --> 00:03:36.640
and Isabella, right? Ferdinand and Isabella
are my philanthropists, and their goal was--I

00:03:36.640 --> 00:03:39.849
would think you could describe it too. One
of their goals was to have their grant to

00:03:39.849 --> 00:03:46.620
get to India, but it was better trade routes
to the Far East. More effective--I should

00:03:46.620 --> 00:03:53.819
say, by the way, that--and motives are really
not important in understanding strategic philanthropy.

00:03:53.819 --> 00:04:01.829
But it's interesting to think about their
motives. They were--they had some purely unself-interested

00:04:01.829 --> 00:04:06.920
motives. They were interested in spreading
Christianity to the world. But they were obviously

00:04:06.920 --> 00:04:11.519
interested in their own, in their country's
welfare, which was probably not distinguishable

00:04:11.519 --> 00:04:15.870
at that time. So you could think of them as
sort of early mission-related philanthropist

00:04:15.870 --> 00:04:22.849
in the same way that Google's philanthropy
is mission-oriented as well; doing good but

00:04:22.849 --> 00:04:30.690
also connected with the company's mission.
So people's goals can change over time. Indeed,

00:04:30.690 --> 00:04:35.889
the very process of pursuing your goal may
give you some different goals. But at any

00:04:35.889 --> 00:04:42.669
given time, you need to know of where you're
going, right? That's sort of a tenant of strategic

00:04:42.669 --> 00:04:55.280
philanthropy. It maybe fun to toddle around
in the--I wonder what is blocking the top

00:04:55.280 --> 00:05:00.229
of the thing. Well, it doesn't matter, as
long as we can see part of the pictures. You

00:05:00.229 --> 00:05:07.020
know, that no one is going to pay it on profit
organizations just to go sailing around the

00:05:07.020 --> 00:05:13.469
bay, sailing around the bay just for the fun
of it. You need to have some sort of destination.

00:05:13.469 --> 00:05:18.949
Okay. So before, you know, no philanthropy
happens on a blank slate, right? There's always

00:05:18.949 --> 00:05:26.860
something that has gone before. And the first
thing to do if you're a philanthropist starting

00:05:26.860 --> 00:05:32.090
in an area is learn what the relevant knowledge
is in the field. At this point, Ferdinand

00:05:32.090 --> 00:05:40.039
and Isabella looked to the Hogwarts Press'
classic book on, "Navigation In The 15th Century."

00:05:40.039 --> 00:05:48.430
And they learned about navigation, whether
ships--whatever they need to learn about.

00:05:48.430 --> 00:05:52.300
Well, I'm talking about philanthropy that
is grant-making philanthropy. And if you're

00:05:52.300 --> 00:05:59.189
a grant maker, you need to look for a grantee.
So maybe what Ferdinand and Isabella had in

00:05:59.189 --> 00:06:05.710
mind was Horatio Nelson, a great--since I'm
playing [indistinct] with history, you know,

00:06:05.710 --> 00:06:11.639
a great leader of a great organization, the
British Navy. For better or worse, they ended

00:06:11.639 --> 00:06:21.210
up with Columbus as their grantee. So you
have a goal, you have a general approach at

00:06:21.210 --> 00:06:28.659
this point. You've done due diligence and
you've found your grantee. And--but you need

00:06:28.659 --> 00:06:36.159
to have a strategy for achieving your goal.
And in this case, the strategy was sail west.

00:06:36.159 --> 00:06:42.349
Up to this point, trips from Europe to the
Indies had taken Eastern water routes. They

00:06:42.349 --> 00:06:50.539
had very often taken parallels overland routes
and here the idea was sail west. A strategy

00:06:50.539 --> 00:06:56.520
is only as good as the theory that underlies
it, right? So in this case, the theory which

00:06:56.520 --> 00:07:03.580
you're all familiar with is--that the earth
is round. And by the late 15th century, most

00:07:03.580 --> 00:07:09.850
educated Europeans thought that the earth
was round. There were some serious mis-estimations

00:07:09.850 --> 00:07:16.669
in just how large it was. But without a theory,
as you'll see, I mean, it make sense to engineers

00:07:16.669 --> 00:07:23.590
for sure, your strategy is not going to work.
Well, let's--we'll return to Columbus. But

00:07:23.590 --> 00:07:29.229
let's talk about philanthropy. So at this--in
some ways, I'm just giving you, you know,

00:07:29.229 --> 00:07:37.069
a short list of thousands of possible philanthropic
goals. These are goals that people are actually

00:07:37.069 --> 00:07:44.289
pursuing, and so, reducing meth abuse in Montana,
preventing malaria in Africa. I put in the

00:07:44.289 --> 00:07:49.610
two sides of say, proposition A, promoting
and opposing gay marriage to emphasize that

00:07:49.610 --> 00:07:54.779
point that I've said earlier, which is you
can be strategic in achieving any goals and

00:07:54.779 --> 00:08:00.759
you can be strategic in--on opposite sides
of an issue. So there were philanthropies--individual

00:08:00.759 --> 00:08:08.419
philanthropies and--at least in some foundations
on both sides of proposition eight. Being

00:08:08.419 --> 00:08:12.400
strategic doesn't mean you're on the right
side; it means you're using your resources

00:08:12.400 --> 00:08:18.080
as best as possible to achieve your goals
whatever they happen to be. I'm going to use

00:08:18.080 --> 00:08:25.710
the last of these examples. Achieving education
for better outcomes for disadvantaged children

00:08:25.710 --> 00:08:30.940
in Philadelphia, which is a goal that, you
know, no one would be on the opposite side

00:08:30.940 --> 00:08:40.289
even if that is not your passion. And I use
the example for some reasons that I will explain.

00:08:40.289 --> 00:08:47.490
So here's a general goal. Once again, you
need to do due diligence. You want to find

00:08:47.490 --> 00:08:53.800
a good leader of a good institution and, you
know, then the philanthropist might have looked

00:08:53.800 --> 00:08:59.420
for a charter school, organization school.
They might have decided to look for a different

00:08:59.420 --> 00:09:06.209
place in Philadelphia. But in this case, look
for, you know, found the school superintendent

00:09:06.209 --> 00:09:14.910
of Philadelphia, a good leader of a good school.
I think before--I think I've gotten a little

00:09:14.910 --> 00:09:19.420
bit ahead of myself because what I like you
to do is take a minute. And I've given you

00:09:19.420 --> 00:09:25.100
a hand-out sheet and, you know, if you have
a pen or pencil and willing to use a low tech

00:09:25.100 --> 00:09:32.529
device like that, just jot down; and if you
don't, just keep it in your mind. What is

00:09:32.529 --> 00:09:37.790
the goal--whether you have done philanthropy,
you know, from your checkbook or have a donor

00:09:37.790 --> 00:09:44.459
advised fund or just do interest in philanthropy,
choose a goal that you're really excited about,

00:09:44.459 --> 00:09:52.570
something that motivates you as a goal for
your own philanthropy. Let me take just a

00:09:52.570 --> 00:10:10.930
second to let you think about that. All right.
So, I won't to ask you to do the due diligence

00:10:10.930 --> 00:10:21.480
part, but we'll come back to some other parts
of the form. So, just as Columbus and his

00:10:21.480 --> 00:10:25.709
philanthropist had to learn from the field,
there's a lot of learning--there's a lot of

00:10:25.709 --> 00:10:32.240
information out there anyway about what might
improve the outcomes for disadvantaged kids

00:10:32.240 --> 00:10:40.769
in Philadelphia. Some places have tried dressing
the kids in school uniforms, Teach for America,

00:10:40.769 --> 00:10:48.339
you know, has bright, committed kids from
university starting to teach, KIPP academies

00:10:48.339 --> 00:10:55.470
have long school days and long school years,
and so on, and so forth. What's really important

00:10:55.470 --> 00:11:03.930
is that you have some reason to believe that
the activity you're engaging--having school

00:11:03.930 --> 00:11:09.130
uniforms, whatever it is, leads to better
outcomes. You need to fill in, and this is

00:11:09.130 --> 00:11:14.600
sort of a basic tenant of strategic philanthropy
or any sort of strategy. You need to fill

00:11:14.600 --> 00:11:23.810
in the blank, and you can't rely on a miracle.
If you haven't filled in the blank between

00:11:23.810 --> 00:11:28.899
your activity and the outcome you have, and
sometimes it's the number of steps you need

00:11:28.899 --> 00:11:34.460
to fill in, then you expect the miracle to
happen. And, you know, social change is so

00:11:34.460 --> 00:11:44.740
hard that the likelihood of a miracle is really,
really small. So take a moment. You set out

00:11:44.740 --> 00:11:51.190
a goal, take a moment and jot down for yourself.
I'm not--nobody is going to call on you to

00:11:51.190 --> 00:11:58.940
answer this. What is your general strategy
and what is the theory that underlies it?

00:11:58.940 --> 00:12:08.279
The equivalent of sale west being the strategy
and the earth is round being the theory. Now,

00:12:08.279 --> 00:12:29.670
what's going to get you to your philanthropic
goal? Well--so there was an overall strategy

00:12:29.670 --> 00:12:34.620
that Columbus had and Ferdinand and Isabella,
his philanthropists. But an overall strategy

00:12:34.620 --> 00:12:39.649
like sail west needs to be implemented, right?
It's pretty vague. So what you need next is

00:12:39.649 --> 00:12:46.639
a plan. So--oh, I'm sorry. Once again, I'm
ahead of myself. So the particular strategy

00:12:46.639 --> 00:12:51.020
we're going to use in this example, by the
way, is adaptive learning. And let me tell

00:12:51.020 --> 00:12:55.649
you what adaptive learning is in the Philadelphia
example and then we'll come back to Columbus.

00:12:55.649 --> 00:13:02.420
Adaptive learning is the idea that the teachers
make plans for each student individually.

00:13:02.420 --> 00:13:08.851
They see how the student is doing. They give
the student feedback based on how he's doing;

00:13:08.851 --> 00:13:17.231
they then change the lesson plan as necessary.
So it's a continuous loop in--and the theory

00:13:17.231 --> 00:13:22.980
is that that will lead to better educational
outcomes. And I use it--the reason I like

00:13:22.980 --> 00:13:26.620
it because I think it's a metaphor for philanthropy
as you'll see by the time we're done with

00:13:26.620 --> 00:13:32.720
this, that philanthropy also is adaptive and
feedback plays a really important rule. All

00:13:32.720 --> 00:13:39.480
right. So back to what a plan is, though.
So, it wasn't just enough to say, you know,

00:13:39.480 --> 00:13:45.100
like sail west, they need Columbus needed
and a philanthropist needed a business plan,

00:13:45.100 --> 00:13:49.111
you know, how they need to buy and provision
the ships and recruit a crew, but then you

00:13:49.111 --> 00:13:56.980
also need to chart the course. You need to
chart the course as well. And so, too, you

00:13:56.980 --> 00:14:04.829
know, a school example, you know, adaptive
learning is a kind of broad idea. But you

00:14:04.829 --> 00:14:08.720
need to implement it. So you need to train
the teachers in assessment, the teachers need

00:14:08.720 --> 00:14:15.370
to specify achievement goals for each student,
they need to translate those into assessments

00:14:15.370 --> 00:14:21.199
for each student and its sort of a recursive
process which ultimately leads to improved

00:14:21.199 --> 00:14:27.259
outcomes. So my question for you is what's
your plan? That would probably take longer

00:14:27.259 --> 00:14:31.860
to really specify, but, you know, you had
a general strategy. What do you actually need

00:14:31.860 --> 00:14:38.199
to do to make it work? For example, if the
goal--if you're interested in reducing teen

00:14:38.199 --> 00:14:44.470
pregnancy, then you probably have a teen pregnancy
clinic and the strategy would be to recruit

00:14:44.470 --> 00:14:49.589
the kids you thought you wanted to work with,
to recruit counselors and so on and so forth.

00:14:49.589 --> 00:15:10.649
So what would be a strategy for achieving
your goals? Well, I'm not going to call on

00:15:10.649 --> 00:15:16.560
anybody to be great during the discussion
if you can allude to some of your own examples.

00:15:16.560 --> 00:15:21.959
Okay. Something that's really helpful in philanthropy
is to have targets, right? So the target for

00:15:21.959 --> 00:15:31.041
them, Isabella and their grantee, Columbus
was India. In this case, the philanthropist

00:15:31.041 --> 00:15:37.019
and the school superintendent have agreed
that in 2008, only 60% of fifth graders were

00:15:37.019 --> 00:15:44.430
doing math at grade level and the goal is
by 2012, to have 80%. You might say, "Gosh,

00:15:44.430 --> 00:15:48.699
you know, I mean, why not aim for a 100%"
because the target--you've done fundraising

00:15:48.699 --> 00:15:54.040
campaign. So the target needs to be ambitious,
but realistic. There's sort of two reasons

00:15:54.040 --> 00:15:58.920
to have targets. One is you hold--everybody
knows what they're aiming for, you hold yourselves

00:15:58.920 --> 00:16:03.560
accountable to try to achieve it. There's
another reason that's sort of structural.

00:16:03.560 --> 00:16:09.649
There's nothing like a target to clarify what
your goal is, right? As between going to the

00:16:09.649 --> 00:16:15.000
less improved outcomes for disadvantage kids
and saying, "This is actually what we want

00:16:15.000 --> 00:16:18.829
to accomplish." You know, you know if you're
there, you know, you know if you've gotten

00:16:18.829 --> 00:16:28.189
to India. So you might jot down the target
for, you know, a--it could be ideally numerical,

00:16:28.189 --> 00:16:33.550
but it might be a qualitative target that
you and somebody else could agree--that you

00:16:33.550 --> 00:16:47.709
would achieve it or not, how you would know
whether you would actually achieve your goal.

00:16:47.709 --> 00:16:56.500
So, I now come to kind of one of the weakest
parts of philanthropy. Surprisingly, we called--though

00:16:56.500 --> 00:17:04.180
I think there's work in remedying it, and
that is getting feedback. Oh dear, I don't

00:17:04.180 --> 00:17:12.340
think Columbus is--so, that's okay. So what
Columbus had, you know, Columbus basically

00:17:12.340 --> 00:17:18.960
relied on a compass and dead reckoning. And
we were talking before about flying. If you

00:17:18.960 --> 00:17:30.820
have ever flown a plane or had gone on a boat,
you can start off with a great compass heading.

00:17:30.820 --> 00:17:34.870
You can even know what the winds are, but
if you don't have some other form of feedback,

00:17:34.870 --> 00:17:43.910
you're going to be off course very soon. After
awhile came the sextants and a--actually,

00:17:43.910 --> 00:17:50.650
the result of a great philanthropic contest,
the ships goniometer, which is a way of keeping

00:17:50.650 --> 00:17:55.600
track of longitude and latitude. And now,
my guess is that those of you who drive to

00:17:55.600 --> 00:18:01.200
work probably have a GPS system in your car.
I mean, feedback is absolutely essential.

00:18:01.200 --> 00:18:07.420
Dead reckoning doesn't work with flying and
sailing, and it sure doesn't work in social

00:18:07.420 --> 00:18:14.060
change. So how do you track in this Philadelphia
school example whether we're on the course?

00:18:14.060 --> 00:18:17.700
Well, we said initially, you know, in order
to make this work; teachers need to be trained

00:18:17.700 --> 00:18:22.070
in assessment. Well, you see whether the teacher
show up for training. You may give them little

00:18:22.070 --> 00:18:27.650
spot quizzes. They need to specify achievement
for the--targets for the kids. You may rely

00:18:27.650 --> 00:18:32.440
on self-reporting. You may kind of randomly
sit in and see how they're doing. But they're

00:18:32.440 --> 00:18:35.790
also some ways of assessing whether they're
on course. The issue at this point is not

00:18:35.790 --> 00:18:41.480
whether they achieve the ultimate goal, but
are they--are they on course toward achieving

00:18:41.480 --> 00:18:48.260
it? And a question for you, not surprisingly,
is how would you track progress for your goal?

00:18:48.260 --> 00:18:52.960
Not whether you would have gotten there. Not
whether you had saved whatever part of the

00:18:52.960 --> 00:18:57.890
world you're trying to save in your own philanthropy,
but how would you know if you're on the way?

00:18:57.890 --> 00:19:04.650
To go back to my example, if it's a teen pregnancy
prevention clinic and part of it is counseling

00:19:04.650 --> 00:19:10.190
kids, then if the kids--you need to know whether
the kid show up, whether the counselor show

00:19:10.190 --> 00:19:19.760
up and whether there are counseling sessions,
and you might want to know what actually goes

00:19:19.760 --> 00:19:28.420
on in the counseling sessions. So, Columbus'
tracking was as good as it could be at that

00:19:28.420 --> 00:19:37.760
time. The basic theory of change, the basic
idea that the earth was round was right. But

00:19:37.760 --> 00:19:45.500
the map was sort of incomplete as you know.
And Columbus' voyage turns out to be an example

00:19:45.500 --> 00:19:56.190
of failed philanthropy, right? The crew may
have been really happy in where they ended

00:19:56.190 --> 00:20:04.760
up. But the philanthropists were disappointed
in the result. There's a lot of failed philanthropy.

00:20:04.760 --> 00:20:10.940
I mean, a lot of philanthropy is like this
in the sense that it's high risk. The likelihood

00:20:10.940 --> 00:20:15.830
of achieving your outcome is not so great.
Of course, unless you're clear about what

00:20:15.830 --> 00:20:22.050
your goals are, and that's why targets help,
you don't even know whether you achieve your

00:20:22.050 --> 00:20:29.870
outcome as well. So how did our project in
Philadelphia work? Well, then if you look

00:20:29.870 --> 00:20:36.241
at a whole lot of different studies not in
any one city, adaptive learning has--can make

00:20:36.241 --> 00:20:41.780
a huge boost especially for disadvantaged
kids, seven-tenths of the grade level. Did

00:20:41.780 --> 00:20:47.640
it actually work in Philadelphia? You know,
I don't know. For one thing, the reason I

00:20:47.640 --> 00:20:51.290
use Philadelphia as an example was, it's the
only place where I could see something that

00:20:51.290 --> 00:20:54.860
said Philadelphia, the name of the school
district. I couldn't find the slide that had

00:20:54.860 --> 00:20:59.300
other school there. So it's hypothetical.
But there are a lot of reasons that adaptive

00:20:59.300 --> 00:21:03.790
learning might work in general and might not
work in a particular case. It might be that

00:21:03.790 --> 00:21:08.530
the population is a different one or if it's
just not implemented very well. Why, because

00:21:08.530 --> 00:21:14.180
I mean, you know, implementing any social
change strategy and educational strategy,

00:21:14.180 --> 00:21:24.030
for example, is difficult. So I mentioned
the failed philanthropy of Ferdinand and Isabella,

00:21:24.030 --> 00:21:32.900
and let's talk a little bit about risk in
philanthropy. The risk for Columbus and his

00:21:32.900 --> 00:21:40.500
grantee were--all the risk of navigating in,
you know, navigating the ocean in those days.

00:21:40.500 --> 00:21:45.050
And the rest of the crew might mutiny because
they ran out of provisions or they were afraid

00:21:45.050 --> 00:21:51.040
of falling off the face of the earth. And
the risk of falling off the face of the earth,

00:21:51.040 --> 00:21:57.750
that was a possibility. For most philanthropy,
the risk is not endangering life and limb,

00:21:57.750 --> 00:22:04.300
although sometimes it is. It's that that you
have put money into something. You put a lot

00:22:04.300 --> 00:22:13.050
of money into something and it just doesn't
turn out to work. And you might think for

00:22:13.050 --> 00:22:17.050
a moment about what the risks are in your
own plans, where could things go wrong in

00:22:17.050 --> 00:22:27.840
a way in your own strategic plan that the
money would turn out to be wasted. Where are

00:22:27.840 --> 00:22:33.870
the possibilities for failure the greatest?
How do you know if a risk is worth taking?

00:22:33.870 --> 00:22:37.530
Because I'm going to suggest--when I think
about the work of the Hewlett Foundation where

00:22:37.530 --> 00:22:44.770
I work, I would say that a huge amount of
the philanthropy we do has a lower than fifty-fifty

00:22:44.770 --> 00:22:51.650
chance of succeeding. So how do you think
about risk? Well, some of you are probably

00:22:51.650 --> 00:22:57.510
familiar with kind of a simplified version
of expected return. Expected return is the

00:22:57.510 --> 00:23:05.790
benefit of everything works out, discounted
by the possibility that it won't work out

00:23:05.790 --> 00:23:11.610
over the cost. And what I want to suggest
is this is a healthy way, a good way of thinking

00:23:11.610 --> 00:23:18.740
about risk even if you can't quantify. And
I think philanthropy could do a lot more of

00:23:18.740 --> 00:23:24.510
work in quantifying, both what the benefit
is and what the probability of achieving the

00:23:24.510 --> 00:23:30.860
benefit is than we do for the most part. But
even if--even where you can't quantify, the

00:23:30.860 --> 00:23:35.290
first point of it is we think this way in
everyday life, right? We certainly think about

00:23:35.290 --> 00:23:39.970
business investments, right? And so, you--I
mean, this is a hard time to talk about what

00:23:39.970 --> 00:23:46.660
a safe--what a safe investment for your personal
IRA is. But, you know, you can put it onto

00:23:46.660 --> 00:23:53.530
your mattress or put it in a government bond,
and it's very little risk and low return or

00:23:53.530 --> 00:24:00.040
you can put them something riskier. We think
about it when we get car insurance, when we

00:24:00.040 --> 00:24:05.670
go out of [indistinct] and somebody tries
to sell us an extended warranty for the product.

00:24:05.670 --> 00:24:12.400
Probably not a good idea, but--so we think
about it--I think it's a good way to think

00:24:12.400 --> 00:24:16.790
about philanthropy for these reasons. First
of all, if you don't recognize the risk, you're

00:24:16.790 --> 00:24:22.200
not going to know how to mitigate them. All
right? If you don't know where the dragons

00:24:22.200 --> 00:24:28.260
are if you're crossing the ocean, you're not
going to know how to avoid them. And philanthropy

00:24:28.260 --> 00:24:36.300
is full of dragons. And it justifies--this
is the expected return approach, it justifies

00:24:36.300 --> 00:24:43.090
high risk, high return ventures. The Hewlett
Foundation has made the single largest commitment

00:24:43.090 --> 00:24:48.050
in its history, $100 million a year for five
years to support work, to reduce climate change.

00:24:48.050 --> 00:24:53.800
In fact, Hal Harvey, my co-author, we spun
off an organization that he's running called

00:24:53.800 --> 00:25:01.550
ClimateWorks. The likelihood that all of the
philanthropy together is going to change government

00:25:01.550 --> 00:25:09.101
policies that will ultimately change CO2 emissions,
I would put it far less than 50 percent but,

00:25:09.101 --> 00:25:16.020
boy, is the impact important if the theory
of change is right. And we have good reason

00:25:16.020 --> 00:25:24.661
to think that it is that CO2 emissions do
cause global warming. And global warming is

00:25:24.661 --> 00:25:28.110
likely to do damage. If there is--the word
"failure" is a dirty word in the non-profit

00:25:28.110 --> 00:25:34.820
sector in general and in philanthropy. And
talking about risks is a way of talking about

00:25:34.820 --> 00:25:38.840
failure in a rational way. I mean, there's
no venture capitalist who doesn't expect quite

00:25:38.840 --> 00:25:47.040
a few of his or her investments to fail. And
philanthropy is not all that different. And

00:25:47.040 --> 00:25:53.160
it can help understand your own risk tolerance
as an individual or foundation. Some people

00:25:53.160 --> 00:25:59.650
are willing to take huge risks. Others want
things to be safer. So let me stop there.

00:25:59.650 --> 00:26:06.550
Actually, one--I want to show you one last
slide. Then I want to leave time for Q&amp;A.

00:26:06.550 --> 00:26:12.840
So I was thinking when I thought that hell
wasn't going to be here, this is the one picture

00:26:12.840 --> 00:26:19.700
in the--but we have a few cartoons. In this
one picture that we designed and this is hell's--among

00:26:19.700 --> 00:26:25.270
hell's many contributions, but somehow, I
think hell is the proudest stuff in the book.

00:26:25.270 --> 00:26:31.230
And it's a way of thinking about your own
philanthropy, which is--imagine a scale--you

00:26:31.230 --> 00:26:39.140
can have a more complicated scale but imagine
three vectors. One is the problem that you're

00:26:39.140 --> 00:26:43.590
dealing with. You can talk about philanthropy
in terms of opportunities or problems. I think

00:26:43.590 --> 00:26:47.950
problem orientation is probably a good way.
Is the problem you're dealing with one that

00:26:47.950 --> 00:26:55.020
affects the quality of life or does it affect
life itself? So quality of life, you might

00:26:55.020 --> 00:27:01.380
decide, you know, to build a football field
or supports arts organizations in your community.

00:27:01.380 --> 00:27:08.330
And the other extreme is the extinction of
life or much of it through nuclear proliferation,

00:27:08.330 --> 00:27:15.590
nuclear explosion, climate change, what have
you. That's one axis. Another one is the problem

00:27:15.590 --> 00:27:21.760
you're dealing with the danger, reversible
or not. That is the vertical axis. So, you

00:27:21.760 --> 00:27:28.250
know, air pollution is actually quite easily
reversal. You stop the pollution one day and

00:27:28.250 --> 00:27:34.920
it ends the next. Water pollution is usually
reversible and they take decades to do it.

00:27:34.920 --> 00:27:44.280
Loss of bio-diversity is irreversible unless
Google comes up with some great new convention.

00:27:44.280 --> 00:27:47.770
And then, what's the scale of it? And scale
can mean lots of different things. Once can

00:27:47.770 --> 00:27:55.000
be--is it local and kind of tangible? You
know, the high school football field, it's

00:27:55.000 --> 00:28:01.100
local. Or, you know, at the other extreme--you
know, is it--is the scale of one that is distant

00:28:01.100 --> 00:28:06.730
and going to affect huge numbers of people
who are anonymous to you. Well, you could

00:28:06.730 --> 00:28:16.910
think of this as the small cube, being issues
that are local, reversible quality of life.

00:28:16.910 --> 00:28:21.780
And then you can imagine some issues, and
I think climate change, nuclear--the dangers

00:28:21.780 --> 00:28:28.940
of nuclear explosion are in and all of the
scales there in the big cube, right? They

00:28:28.940 --> 00:28:36.110
threaten life itself. They're distant, anonymous,
and irreversible. It's maybe a way of thinking--and

00:28:36.110 --> 00:28:42.080
of course, you don't--you can have mid points
of any of these and you can be at one end

00:28:42.080 --> 00:28:49.340
of the spectrum on one of these vectors, and
another, and another. I think a lot of people

00:28:49.340 --> 00:28:55.900
at the beginning of their own philanthropy,
tend--I think my own personal philanthropy

00:28:55.900 --> 00:29:00.430
is being very much in the small cube, right?
You want things that are local, tangible,

00:29:00.430 --> 00:29:08.220
your college, your high school, your town,
your symphony orchestra. And then some people

00:29:08.220 --> 00:29:15.210
branch out. How has a very clear normative
view about this? Barely disguised in the book,

00:29:15.210 --> 00:29:20.660
which is being out in the outer cube dealing
with the big problems is what should be done.

00:29:20.660 --> 00:29:26.370
And I think--I think for established foundations.
That maybe right. But my own view is that

00:29:26.370 --> 00:29:29.860
we, you know, that the different people need
to find their different comfort level. You

00:29:29.860 --> 00:29:35.970
can deal with the same essential problem on
different levels. So why don't I stop there

00:29:35.970 --> 00:29:45.010
and--it says, "The end," that's a good place
to stop. And let's open it up for conversations.

00:29:45.010 --> 00:29:54.020
What did I say that you found utterly wrong
or annoying and in need of correction, and

00:29:54.020 --> 00:29:58.610
what are your own thoughts on some of these
issues. And if you want to allude to your--you

00:29:58.610 --> 00:30:02.930
don't need to, but if you had some thoughts
as you jotted down your own thoughts, your

00:30:02.930 --> 00:30:11.180
own philanthropic strategy, that's fine.
&gt;&gt; So, I'm not sure if I can articulate this

00:30:11.180 --> 00:30:17.780
point clearly but much of what you said seems
to apply in the context of large foundation

00:30:17.780 --> 00:30:22.630
such as the Hewlett Foundation where there's
a large sum of money that needs to be invested

00:30:22.630 --> 00:30:29.060
so that you could make significant social
change with this. But for those of us who

00:30:29.060 --> 00:30:38.330
have more modest means, shall we say, the
philanthropy we do is unlikely to have a significant

00:30:38.330 --> 00:30:44.630
impact like this. And so, in our own giving,
for example, we've often given through intermediaries,

00:30:44.630 --> 00:30:50.390
whether they'd be foundations or disaster
relief organizations, or what have you. So

00:30:50.390 --> 00:30:56.210
intermediaries that have presumably much more
significant means and you're adding a little

00:30:56.210 --> 00:31:03.830
to it. How does this idea of strategic philanthropy
help for individual contributors with modest

00:31:03.830 --> 00:31:10.660
means? It's not--as clear to me.
&gt;&gt; BREST: Well, I-I think that's--the book

00:31:10.660 --> 00:31:19.340
says--this book is written for anybody who
gives away between $100,000 thousand and $100

00:31:19.340 --> 00:31:28.320
million a year. And I think your question
is right. How--you can't do the kind of due

00:31:28.320 --> 00:31:34.590
diligence that Ferdinand and Isabella do when
you're giving away the amount of money that

00:31:34.590 --> 00:31:40.330
most of us in this room, myself included,
do for our personal account. What aspects

00:31:40.330 --> 00:31:46.540
of strategy work? Well, one is being clear
about your goals, you know, for example, you

00:31:46.540 --> 00:31:52.610
know, what do you expect before you look for
the organizations, if you're doing disaster

00:31:52.610 --> 00:32:01.230
relief or trying to reduce malaria in Africa.
So, what are you trying to accomplish? And

00:32:01.230 --> 00:32:08.450
then, even though you can't do deep due diligence
because you don't have time for it? There

00:32:08.450 --> 00:32:13.250
are ways of finding out whether the organizations
that you're supporting are achieving those

00:32:13.250 --> 00:32:20.920
goals. I think that personal philanthropy
and most of the non-profit sector are stuck

00:32:20.920 --> 00:32:28.590
in an unfortunate cycle where the organizations
provide very little information about what

00:32:28.590 --> 00:32:32.680
they're actually accomplishing. I mean you
can get glossy brochures and you may get the

00:32:32.680 --> 00:32:39.020
same glossy brochure five times a year in
the mail. But does it say, "What are the organization's

00:32:39.020 --> 00:32:43.890
goals? What are its strategies for accomplishing
them? And how well is it doing? Is it--are

00:32:43.890 --> 00:32:50.380
they on course? Are they achieving some of
their targets?" So the organizations don't

00:32:50.380 --> 00:32:58.690
provide that and individual philanthropists,
most of us, don't ask for it. And I wonder

00:32:58.690 --> 00:33:02.400
why we don't ask for it. And I think sometimes
we don't ask for it because we think that

00:33:02.400 --> 00:33:07.360
it's not available, and of course, they maybe
not be available because we don't ask for

00:33:07.360 --> 00:33:11.560
it. I think the key to this, and I think even
right now--my guess is if do you think about

00:33:11.560 --> 00:33:18.510
your own philanthropy, all of us in this room,
we could be more demanding of information

00:33:18.510 --> 00:33:23.140
for the organizations and then decide. You
know, this organization really looks like

00:33:23.140 --> 00:33:27.050
it's doing a good job. At least they have
a theory of change. At least they have a strategy,

00:33:27.050 --> 00:33:33.270
whereas some of us don't. I think the key
to this ultimately lies in Web-based devices.

00:33:33.270 --> 00:33:40.340
There are few interesting experiments where
organizations. In order--the Greater Kansas

00:33:40.340 --> 00:33:46.560
Community Foundation has a Website for all
of its donors. And the organization who wants

00:33:46.560 --> 00:33:50.990
to be listed on the Website has to at least
have the elements of what we've talked about.

00:33:50.990 --> 00:33:54.620
They have to say, "What their goals are? How
they would know--what their targets are? How

00:33:54.620 --> 00:33:59.330
they would know if they were achieving it?
And how did they do last year?" And you only

00:33:59.330 --> 00:34:05.270
get listed if you have that. Well, Kansas
City donors are becoming better informed,

00:34:05.270 --> 00:34:10.440
and I think more demanding. So what used to
be everybody being stuck, you can think of

00:34:10.440 --> 00:34:16.349
as rising possibilities. So I think back for
the individual philanthropist, is what you

00:34:16.349 --> 00:34:19.280
can do even without giving away $100,000 a
year.

00:34:19.280 --> 00:34:25.859
&gt;&gt; So, in fact, to brainstorm just a bit on
this last point. There are all of these charity

00:34:25.859 --> 00:34:31.240
rating organizations. I'm blanking on the
names of all of them. But that basically say

00:34:31.240 --> 00:34:38.089
how efficient they are in X, Y, and Z. Would
it be a useful exercise to figure out if you

00:34:38.089 --> 00:34:43.710
could convince one of these, or one or more
of these organizations to add additional criteria

00:34:43.710 --> 00:34:49.569
so that in order to be--in order to be rated,
you know, you get your four-star rating but

00:34:49.569 --> 00:34:54.220
you also have to have your theory of change
listed in one of these organizations. I'm

00:34:54.220 --> 00:35:00.359
trying to figure out if there's anything individuals
or an organization could do to prod these

00:35:00.359 --> 00:35:03.740
charity rating organizations to do that.
&gt;&gt; BREST: Well, that's something which we--we

00:35:03.740 --> 00:35:09.520
actually have a small--as you know, we have
a small program in philanthropy of the foundation.

00:35:09.520 --> 00:35:16.039
And this is the probably the central thing
we're working on. There is a rating organization

00:35:16.039 --> 00:35:22.609
which, at the moment I think, does more harm
than good called Charity Navigator. And it

00:35:22.609 --> 00:35:29.009
just presents the financials, so it--you know,
how much--what are your administrative cost?

00:35:29.009 --> 00:35:34.279
What are your fund raising cost and--just
looks so where you can get off the internal

00:35:34.279 --> 00:35:41.420
revenue code returned, or the internal revenue
return. Well, looking only in financials should

00:35:41.420 --> 00:35:45.680
be looking and only at cost mainly, we'll
be looking at one half of the balance sheet

00:35:45.680 --> 00:35:50.470
as a business. In every single, you know,
what are you doing this--make any difference.

00:35:50.470 --> 00:35:57.530
You can be in an organization with very low
cost and be doing zero in terms of whatever

00:35:57.530 --> 00:36:03.310
your philanthropic outcomes are, or an organization
with fairly high cost and just having a terrific

00:36:03.310 --> 00:36:12.110
impact. The new head of Charity Navigator
has said that he wants to move to more outcome-oriented

00:36:12.110 --> 00:36:17.290
measures. And I think that's been a bit of
peer pressure, it's been people like me and

00:36:17.290 --> 00:36:23.829
others saying that they're harmful. We'll
see where it goes. It's much easier to just

00:36:23.829 --> 00:36:31.599
look at the metrics of the IRS return than
it is to look at outcomes. And the non-profit

00:36:31.599 --> 00:36:35.859
sector to me, you think its strategy--strategic
philanthropy, you could put strategic anything.

00:36:35.859 --> 00:36:40.980
I mean, strategy is strategy whether it's
business, philanthropy, public policy. But

00:36:40.980 --> 00:36:48.829
a lot of the sector doesn't think or doesn't
know the concepts--not the vocabulary--and

00:36:48.829 --> 00:36:57.829
the basic concepts of goal strategy feedback
in the like. And it's odd, isn't it? Because

00:36:57.829 --> 00:37:09.060
the same person who's running a non-profit
organization, who can't tell you what their

00:37:09.060 --> 00:37:12.579
goals are and how they're going to achieve
it. If they're doing a home improvement project,

00:37:12.579 --> 00:37:18.099
you know, they're building a new sun porch.
It can basically do a strategy in this way.

00:37:18.099 --> 00:37:25.280
So it's a matter, I think, of educating the
organizations. And I think that the Web-based

00:37:25.280 --> 00:37:35.549
services like this are going to make all the
difference. Yes.

00:37:35.549 --> 00:37:48.440
&gt;&gt; Hi. I have a question about risk. If you
are strategizing about how to go about your

00:37:48.440 --> 00:37:55.170
project and you discovered that the risk is
extremely high, how do you--how do you work

00:37:55.170 --> 00:38:01.710
through that in a sense of being able to solicit
funds or making--or persuading people to come

00:38:01.710 --> 00:38:06.470
to your cause if you know specifically that
there is a high risk? And I know you're saying,

00:38:06.470 --> 00:38:11.890
"Well, the payoff has to be extremely high."
But how do you advance that argument? What--you

00:38:11.890 --> 00:38:16.209
know--what has been your experience on addressing
risk?

00:38:16.209 --> 00:38:22.109
&gt;&gt; BREST: All right. So, in some ways, it
could be that the non-profit sector has benefited

00:38:22.109 --> 00:38:27.059
from the fact that nobody ever talks explicitly
about what the risk is. And that, you know,

00:38:27.059 --> 00:38:32.769
if you put your money into something and the
organization says, "You know, there's only

00:38:32.769 --> 00:38:36.279
one-in-a-hundred chance you will succeed.
That may de-motivate people." Let me come

00:38:36.279 --> 00:38:43.140
back to that respond. But then talk about
the problem of de-motivation. But if you think

00:38:43.140 --> 00:38:47.769
of--if you actually think about the charity
that any of us do. But if you're giving to

00:38:47.769 --> 00:38:52.819
a high school football team or to the San
Francisco symphony, which the Hewlett Foundation

00:38:52.819 --> 00:38:58.619
does, the latter, not the former, the risks
are very low, right? And, you know, non-profit

00:38:58.619 --> 00:39:03.750
arts organizations are in a lot of peril right
now. But the San Francisco Symphony is going

00:39:03.750 --> 00:39:10.710
to be here next year and your contribution
to it is going to help. But think about work,

00:39:10.710 --> 00:39:24.270
whether it's trying to reduce malaria in Africa
or, you know, improve the environment in some

00:39:24.270 --> 00:39:29.270
part of California. We put money into something
which is, it doesn't seem all that risky,

00:39:29.270 --> 00:39:38.319
which is improving air quality in the central
valley, Fresno, and other areas where diesel

00:39:38.319 --> 00:39:42.190
and other pollutions just makes it--makes
people very sick. The work--because the work

00:39:42.190 --> 00:39:49.589
is policy change and any work that involves
policy change is high-risk. There's no assurance

00:39:49.589 --> 00:39:54.660
that we're going to succeed or other foundations
working in this are going to succeed. And

00:39:54.660 --> 00:40:00.150
you can succeed and then there can be a setback,
right? So that the economic problems of the

00:40:00.150 --> 00:40:05.109
valley have resulted in what looked like we're
on a trajectory to success suddenly being

00:40:05.109 --> 00:40:12.749
cut because it costs money to reduce diesel
pollution. I guess I think that this is maybe

00:40:12.749 --> 00:40:20.390
more optimistic than realistic that if organizations
are really candid about the risk, but also

00:40:20.390 --> 00:40:27.810
what the potential returns are, that, that
will create a conversation at a more--at a

00:40:27.810 --> 00:40:33.079
higher and more realistic level. You know,
every time somebody puts money into cancer

00:40:33.079 --> 00:40:39.670
research or research on any disease, the likelihood
that a particular research team is going to

00:40:39.670 --> 00:40:45.359
come up with something is very low. You hope
that enough people will put enough money into

00:40:45.359 --> 00:40:52.530
different approaches. I just want to say one
thing about--you know, I teach in my--I continue--I

00:40:52.530 --> 00:40:56.849
used to be at Stanford. I continue to teach
one course on judgment and decision making

00:40:56.849 --> 00:41:05.220
in a public policy program. And the judgment
decision making literature which as how people

00:41:05.220 --> 00:41:09.630
actually--It's not the normative literature
of how--you know, what a good model for decision

00:41:09.630 --> 00:41:14.160
making is like and the expected returns, how
do people actually make decisions, has sort

00:41:14.160 --> 00:41:22.380
of some depressing thoughts for a strategic
approach to philanthropy, which is when people

00:41:22.380 --> 00:41:30.150
start being very cognitive rather than emotional
about philanthropy, they give less. If you

00:41:30.150 --> 00:41:37.509
want to--there's a depressing experiment where
if you want people to give for hunger in Africa

00:41:37.509 --> 00:41:44.220
and you show them a picture of one starving
child, they'll give this much. If you show

00:41:44.220 --> 00:41:51.400
this child and then give statistics about
starving children, they will give less. So

00:41:51.400 --> 00:41:57.920
it looks like it may actually involve different
parts of your brain, and when the cognitive

00:41:57.920 --> 00:42:02.920
rather than the emotional parts of the brain
light up, you become less philanthropic. I

00:42:02.920 --> 00:42:07.539
don't think that's an issue for philanthropy
for foundations, especially where you're giving

00:42:07.539 --> 00:42:17.039
away other people's money. But I--it's a little
bit worrisome in terms of asking organizations

00:42:17.039 --> 00:42:24.210
to be really articulate about their goals
and their achievements. Go ahead.

00:42:24.210 --> 00:42:29.440
&gt;&gt; Hi. Thanks for the talk. It's been very
useful. I have an example--and there are few

00:42:29.440 --> 00:42:35.339
examples like this of philanthropic projects
where many of the steps seem to be kind of

00:42:35.339 --> 00:42:40.990
not applicable. And so, I'm going to give
the example of proposition eight, right? So

00:42:40.990 --> 00:42:45.700
the goal is clear. The strategy is reasonably
clear. There's an organization called "No

00:42:45.700 --> 00:42:49.099
One Profit," and you would donate to them
and they had a set of things they were planning

00:42:49.099 --> 00:42:56.339
to do. There was actually no way to track
progress. We have no unascertained date whether

00:42:56.339 --> 00:43:00.619
you'd succeeded or you'd fail. And the risks
are unknown, right? You don't know what the

00:43:00.619 --> 00:43:05.280
chance of success is. How would the Hewlett
Foundation think of a problem like that?

00:43:05.280 --> 00:43:14.640
&gt;&gt; BREST: So, policy--a huge amount of the
work we do involves policy change. And I think

00:43:14.640 --> 00:43:21.230
you're right that with policy change, whether
it's Prop 8 or Waxman-Markey which, a lot

00:43:21.230 --> 00:43:28.140
of our grantees have been working on, you
know, pass the house, the climate cap legislation,

00:43:28.140 --> 00:43:36.109
risky in the Senate. Unlike the symphony or
unlike feeding starving children, right? If

00:43:36.109 --> 00:43:42.930
you're getting to a food bank, assuming the
place is even halfway while running, you can

00:43:42.930 --> 00:43:48.799
find out every additional dollar provides
more food. And it's linear, or more or less

00:43:48.799 --> 00:43:54.900
linear. With policy change--and you can think
of prop--know on Prop 8 is being--I mean,

00:43:54.900 --> 00:44:00.680
it is, it was attempt to influence policy
not by a legislature but by the whole electorate.

00:44:00.680 --> 00:44:07.289
It's not linear. So you can, you know, sometimes
it's all or nothing. And you're going on this

00:44:07.289 --> 00:44:14.730
level and you either win or lose. I think
that grantee organizations can be more or

00:44:14.730 --> 00:44:19.119
less smart about that. And that, again, this
goes back to the question of how much individual

00:44:19.119 --> 00:44:29.349
due diligence you can do. We ended up supporting
the ACOU on this issue. And other foundations

00:44:29.349 --> 00:44:38.069
we know supported other organizations based
on their track record. That is how smarter

00:44:38.069 --> 00:44:42.230
they are about advocacy. And they just--you
know, so with respect to advocacy, you want

00:44:42.230 --> 00:44:46.339
to ask if you have the time, you know, who
are you, you know, what is your strategy,

00:44:46.339 --> 00:44:49.799
who are you trying to reach, what voters are
you trying to reach, how are you doing it?

00:44:49.799 --> 00:44:55.839
And this year you had an interesting strategy
for trying to get on college campuses, young

00:44:55.839 --> 00:45:07.650
voters. And--but I think--let me--so, the
answer is, it's really hard to quantify. And,

00:45:07.650 --> 00:45:13.960
you know, Prop 8, sort of whichever side you
were on, you may have thought it was so important

00:45:13.960 --> 00:45:20.099
that no matter what the risks are, it was
worth doing it. And in fact, you had enough

00:45:20.099 --> 00:45:24.690
public opinion polls to know that the risk
were seem to be roughly 50-50, right, because

00:45:24.690 --> 00:45:29.710
I mean the electorate was pretty divided ahead
of time. I mean, I think about the work we

00:45:29.710 --> 00:45:36.180
do in climate--we're supporting in climate
change where it has to pass the house. There's

00:45:36.180 --> 00:45:41.240
also--I mean the bill has already been watered
down in ways that some environmental advocates

00:45:41.240 --> 00:45:49.200
think they'd rather not see it pass. I think
that's wrong. You know, the ex-ante, the probability

00:45:49.200 --> 00:45:55.160
of passing the house seemed, you know, lower
than 58 percent. The probably of passing the

00:45:55.160 --> 00:46:00.740
Senate seemed--and now seems pretty low. And
of course, for those of you, probably everybody

00:46:00.740 --> 00:46:06.069
in this room who knows how to do probabilities,
you have to multiply it, right? So if there's,

00:46:06.069 --> 00:46:12.279
you know, a 40 percent chance of passing the
House and a 40 percent chance of passing the

00:46:12.279 --> 00:46:21.960
Senate, then the overall chance is pretty
low. So you have to decide it is really important.

00:46:21.960 --> 00:46:27.940
But policy change requires a significant appetite
for risk.

00:46:27.940 --> 00:46:34.690
&gt;&gt; Okay. I think we're just about out of time
now, so I want us to thank Paul one more time

00:46:34.690 --> 00:46:37.729
for coming out and--well, Mr. Brest, thank
you.

00:46:37.729 --> 00:46:39.759
&gt;&gt; BREST: Thank you.

