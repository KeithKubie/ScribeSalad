WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.304
[GOOGLE LOGO MUSIC]

00:00:04.248 --> 00:00:06.300
JOHN HSU: Hi,
everyone, and welcome.

00:00:06.300 --> 00:00:08.800
Thank you for joining us today
whether you're here in person

00:00:08.800 --> 00:00:10.030
or joining us in--

00:00:10.030 --> 00:00:12.340
tuning in on the live stream.

00:00:12.340 --> 00:00:15.820
Yesterday during the keynote,
we announced Interactive Canvas,

00:00:15.820 --> 00:00:17.830
a new set of tools
that allow developers

00:00:17.830 --> 00:00:21.310
to create visual content
for the Google Assistant.

00:00:21.310 --> 00:00:23.230
Today, we want to
talk to you about how

00:00:23.230 --> 00:00:26.380
you can use this technology
to build interactive games

00:00:26.380 --> 00:00:27.940
for the Google Assistant.

00:00:27.940 --> 00:00:29.560
First, a quick
introduction, though.

00:00:29.560 --> 00:00:30.610
I'm John Hsu.

00:00:30.610 --> 00:00:32.740
I'm the product manager
for Interactive Canvas

00:00:32.740 --> 00:00:34.310
and for games on
Google Assistant.

00:00:34.310 --> 00:00:36.010
And I'm joined by
Leon Nicholls, who's

00:00:36.010 --> 00:00:39.250
on our developer relations team.

00:00:39.250 --> 00:00:41.350
10 years-- the
past 10 years, I've

00:00:41.350 --> 00:00:44.290
had the pleasure of building
games for new platforms.

00:00:44.290 --> 00:00:48.160
From web games to social games
to mobile games to voice games.

00:00:48.160 --> 00:00:51.460
What I'm excited about whenever
a new technology comes out

00:00:51.460 --> 00:00:53.410
is the fact that a
transformative type

00:00:53.410 --> 00:00:56.620
of experience starts to
emerge for the player.

00:00:56.620 --> 00:00:59.110
And in addition to that,
a transformative type

00:00:59.110 --> 00:01:01.090
of experience allows
new developers

00:01:01.090 --> 00:01:06.130
to enter the marketplace and
create these experiences.

00:01:06.130 --> 00:01:08.740
What we believe the Google
Assistant and Interactive

00:01:08.740 --> 00:01:11.230
Canvas unlocks
together is a new way

00:01:11.230 --> 00:01:14.440
and a new potential for players
to engage with our games.

00:01:14.440 --> 00:01:17.200
I'm excited for everyone here
to start building visual games

00:01:17.200 --> 00:01:18.680
on Google Assistant.

00:01:21.620 --> 00:01:24.470
First, let's talk a little bit
about games on the Assistant

00:01:24.470 --> 00:01:25.100
today.

00:01:25.100 --> 00:01:27.530
The past two years,
we've seen good traction

00:01:27.530 --> 00:01:29.600
on voice games
built for Assistant.

00:01:29.600 --> 00:01:32.120
Developers have crafted
great interact experiences,

00:01:32.120 --> 00:01:33.920
like Akinator and
Trivia Crack, that

00:01:33.920 --> 00:01:36.380
really take advantage of
what Google Assistant is

00:01:36.380 --> 00:01:37.310
meant to do.

00:01:37.310 --> 00:01:40.640
Understand what
the user is saying.

00:01:40.640 --> 00:01:42.680
These games have been
successful at creating

00:01:42.680 --> 00:01:47.440
immersive experiences with
only audio as the output.

00:01:47.440 --> 00:01:51.850
Last year, when we announced
smart displays, we were able--

00:01:51.850 --> 00:01:54.760
we're starting to see
increased engagement

00:01:54.760 --> 00:01:58.120
from players that on these--

00:01:58.120 --> 00:02:00.160
excuse me, on these
display devices.

00:02:00.160 --> 00:02:02.830
Over the course of
2019, the percentage

00:02:02.830 --> 00:02:06.550
of smart homes that now
include a smart display device

00:02:06.550 --> 00:02:10.630
has quadrupled from less
than 3% to over 13%.

00:02:10.630 --> 00:02:13.030
Canvas is the tool
that will unlock

00:02:13.030 --> 00:02:17.560
these visual capabilities in
conjunction with Google's NLU--

00:02:17.560 --> 00:02:21.220
natural language understanding--
and speech recognition.

00:02:21.220 --> 00:02:24.730
Canvas essentially gives you
full access to the display.

00:02:24.730 --> 00:02:29.590
You can create fluid animations
and custom game experiences

00:02:29.590 --> 00:02:32.190
with technology that you're
already familiar with.

00:02:32.190 --> 00:02:36.520
HTML, CSS, JavaScript,
and even WebAssembly.

00:02:36.520 --> 00:02:38.410
Pairing these
visual capabilities

00:02:38.410 --> 00:02:40.960
with our speech
recognition allows

00:02:40.960 --> 00:02:43.360
you to create
transformative experiences.

00:02:43.360 --> 00:02:46.570
This technology is
available on Android devices

00:02:46.570 --> 00:02:50.150
and our smart displays, with
more surfaces coming soon.

00:02:50.150 --> 00:02:51.430
Let's take a quick example--

00:02:51.430 --> 00:02:52.580
quick look.

00:02:52.580 --> 00:02:54.400
Let's take a quick
look at the examples

00:02:54.400 --> 00:02:57.160
and see what's possible.

00:02:57.160 --> 00:03:00.210
HQ University, as you saw
in the keynote yesterday,

00:03:00.210 --> 00:03:03.460
leverages HTML animations
to create a high quality

00:03:03.460 --> 00:03:05.630
experience for the user.

00:03:05.630 --> 00:03:07.780
In addition to just
having animations,

00:03:07.780 --> 00:03:10.390
we have the
capability to leverage

00:03:10.390 --> 00:03:12.970
those animations to create
moments of user payoff

00:03:12.970 --> 00:03:14.530
when they get the
answer correct.

00:03:17.050 --> 00:03:20.200
Lucky Trivia, also known
as, Are You Feeling Lucky?,

00:03:20.200 --> 00:03:22.510
uses a similar technique
to provide payoff.

00:03:22.510 --> 00:03:25.240
But also uses the visual
surface to simplify

00:03:25.240 --> 00:03:27.040
multiplayer experiences.

00:03:27.040 --> 00:03:30.280
When you only have audio output,
it's often very difficult

00:03:30.280 --> 00:03:33.130
to keep track in a trivia
game of whose turn it is,

00:03:33.130 --> 00:03:34.480
who made what answer.

00:03:34.480 --> 00:03:37.180
Enough so that Lucky
Trivia team actually--

00:03:37.180 --> 00:03:40.180
in the voice only experience--

00:03:40.180 --> 00:03:41.890
changed the
interaction models so

00:03:41.890 --> 00:03:44.160
that you actually
sequentially ask questions

00:03:44.160 --> 00:03:45.610
to different players.

00:03:45.610 --> 00:03:48.100
With a visual surface
though, Lucky Trivia

00:03:48.100 --> 00:03:50.230
can take advantage
of the visual display

00:03:50.230 --> 00:03:53.110
to effortlessly show
who's making the answer,

00:03:53.110 --> 00:03:55.270
and more importantly,
who got the answer right.

00:03:58.390 --> 00:04:02.620
Finally, in our
sandbox, in sandbox.h,

00:04:02.620 --> 00:04:06.340
we are displaying a
new interactive game

00:04:06.340 --> 00:04:08.380
called Jungle
Dream, where we are

00:04:08.380 --> 00:04:12.640
leveraging visual puzzles that
can't be done on audio devices.

00:04:12.640 --> 00:04:15.670
By allowing the visual surface
to be integrated with your core

00:04:15.670 --> 00:04:17.950
mechanic, we are
allowing developers

00:04:17.950 --> 00:04:20.800
to create awesome new
experiences that really

00:04:20.800 --> 00:04:22.105
utilize this visual surface.

00:04:25.520 --> 00:04:26.770
But that's just the beginning.

00:04:26.770 --> 00:04:28.187
By the end of this
session, you'll

00:04:28.187 --> 00:04:30.110
be equipped to create
even better experiences

00:04:30.110 --> 00:04:31.760
than what we've just shown.

00:04:31.760 --> 00:04:33.875
Here's how we get started.

00:04:33.875 --> 00:04:37.690
LEON NICHOLLS: So let's look
at the technical details.

00:04:37.690 --> 00:04:41.250
So Interactive Canvas
uses regular HTML.

00:04:41.250 --> 00:04:47.090
That means CSS, JavaScript,
SVG, even WebAssembly.

00:04:47.090 --> 00:04:51.110
WebGL has been optimized
for 2D and 3D graphics,

00:04:51.110 --> 00:04:54.170
but you can also just use the
standard HTML canvas feature

00:04:54.170 --> 00:04:57.250
to do some basic graphics.

00:04:57.250 --> 00:04:59.530
You can use the standard
HTML media element

00:04:59.530 --> 00:05:04.680
to play audio or video
within the local web app.

00:05:04.680 --> 00:05:06.860
We also support the
standard touch events

00:05:06.860 --> 00:05:10.980
for both smart displays
and for mobile devices.

00:05:10.980 --> 00:05:14.240
Now Interactive Canvas gives
you pixel level control

00:05:14.240 --> 00:05:17.060
over the rendering of your UI.

00:05:17.060 --> 00:05:21.250
So that means custom
layouts, use your own fonts,

00:05:21.250 --> 00:05:25.310
add transitions, add
animations, create a custom GUI.

00:05:25.310 --> 00:05:27.998
Create your own custom buttons,
tables, lists, whatever.

00:05:27.998 --> 00:05:29.165
All of this is now possible.

00:05:32.270 --> 00:05:35.060
So what is an
interactive Action?

00:05:35.060 --> 00:05:37.200
Well, it's a
conversational Action.

00:05:37.200 --> 00:05:39.200
And just like you create
a conversational Action

00:05:39.200 --> 00:05:40.930
in the Actions console.

00:05:40.930 --> 00:05:44.460
You do the same with
an interactive Action.

00:05:44.460 --> 00:05:47.510
Also, you use our existing tools
like Dialogflow or the Action

00:05:47.510 --> 00:05:48.670
SDK.

00:05:48.670 --> 00:05:51.690
Now we definitely
recommend using Dialogflow,

00:05:51.690 --> 00:05:55.200
it has a very nice grid for
you to easily create intent.

00:05:55.200 --> 00:05:58.890
And it has multi-natural
language understanding.

00:05:58.890 --> 00:06:01.470
You also write code, which
is the fulfillment that

00:06:01.470 --> 00:06:04.890
provides dynamic
responses for your intent.

00:06:04.890 --> 00:06:07.940
And now you provide a
new kind of response,

00:06:07.940 --> 00:06:09.740
an immersive response.

00:06:09.740 --> 00:06:12.170
If you've done a
conversational Action before,

00:06:12.170 --> 00:06:15.187
you already know about simple
responses and reach responses.

00:06:15.187 --> 00:06:16.270
This is something similar.

00:06:19.720 --> 00:06:22.630
So let's go through
all of those in steps.

00:06:22.630 --> 00:06:25.290
How do we start creating
an interactive Action?

00:06:25.290 --> 00:06:28.950
Now, we're launching Interactive
Canvas for games initially.

00:06:28.950 --> 00:06:33.210
So in our Actions console, at
console.actions.google.com,

00:06:33.210 --> 00:06:35.400
you select the games
vertical to begin.

00:06:38.510 --> 00:06:41.540
Next, you get a list of options
for creating different kinds

00:06:41.540 --> 00:06:42.780
of games on our platform.

00:06:42.780 --> 00:06:44.638
The first three are
based on templates.

00:06:44.638 --> 00:06:46.430
But we're going to pick
the last one, which

00:06:46.430 --> 00:06:47.870
is for conversational Action.

00:06:51.050 --> 00:06:53.940
Next, in the directory
listing for your project,

00:06:53.940 --> 00:06:57.500
you have to ensure that the
category is games and fun.

00:06:57.500 --> 00:06:59.150
And there's a new
check box right

00:06:59.150 --> 00:07:01.640
at the bottom of the screen
for the Canvas feature.

00:07:01.640 --> 00:07:03.300
You have to check that.

00:07:03.300 --> 00:07:04.340
And then save it.

00:07:04.340 --> 00:07:07.580
Now your project is capable
of using the new feature.

00:07:10.720 --> 00:07:12.200
Next, we add the Action.

00:07:12.200 --> 00:07:13.990
So we go to the Actions page.

00:07:13.990 --> 00:07:17.560
You click on a big blue button.

00:07:17.560 --> 00:07:19.600
And now we display a
dialogue with a list

00:07:19.600 --> 00:07:21.750
of built-in intents.

00:07:21.750 --> 00:07:23.800
Now, built-in intents
is a way for your Action

00:07:23.800 --> 00:07:27.350
to tell the Google Assistant
what kind of action it is.

00:07:27.350 --> 00:07:31.090
And, also, what kind of
user requests it can handle.

00:07:31.090 --> 00:07:32.560
Now, since we are
creating a game,

00:07:32.560 --> 00:07:35.020
we're going to pick the
play game built-in intent.

00:07:38.100 --> 00:07:40.710
After you've clicked on that,
the Dialogflow GUI is loaded

00:07:40.710 --> 00:07:43.080
and you get three intents.

00:07:43.080 --> 00:07:46.230
The first one is for the
play game built-in intent.

00:07:46.230 --> 00:07:49.440
The second one is the
default fallback intent.

00:07:49.440 --> 00:07:52.560
That's what Dialogflow invokes
when none of the other intents

00:07:52.560 --> 00:07:53.760
are matched.

00:07:53.760 --> 00:07:57.580
And then, thirdly, there is
a default welcome intent.

00:07:57.580 --> 00:07:59.130
Now, that gets
invoked when the user

00:07:59.130 --> 00:08:00.330
invokes the Action by name.

00:08:00.330 --> 00:08:03.590
So the user would say, OK, G.
Talk to conversational Action.

00:08:07.590 --> 00:08:09.960
Let's take a look at
the play game intent.

00:08:09.960 --> 00:08:13.220
Now, in Dialogflow, it's
actually a play game event.

00:08:13.220 --> 00:08:16.190
And you can associate that
event with any other intent.

00:08:16.190 --> 00:08:19.190
For example, you could associate
that with the welcome intent

00:08:19.190 --> 00:08:21.920
and reuse that intent for
the various different ways

00:08:21.920 --> 00:08:23.900
that the user can actually
start your Action.

00:08:27.320 --> 00:08:30.250
Dialogflow also has a very
convenient inline editor.

00:08:30.250 --> 00:08:32.590
So, right within its
GUI, you can go and write

00:08:32.590 --> 00:08:36.159
Node.js code for the Cloud
Functions for Firebase.

00:08:36.159 --> 00:08:40.867
Every Dialogflow agent actually
gets a Cloud Function for free.

00:08:40.867 --> 00:08:42.659
And we're going to base
all of our examples

00:08:42.659 --> 00:08:46.970
on the Cloud Function's syntax.

00:08:46.970 --> 00:08:47.842
OK.

00:08:47.842 --> 00:08:49.050
Let's start at the beginning.

00:08:49.050 --> 00:08:50.830
Let's look at what a
conversational Action

00:08:50.830 --> 00:08:53.560
is implemented in Dialogflow.

00:08:53.560 --> 00:08:55.600
We start with the user.

00:08:55.600 --> 00:08:58.870
The user talks to a
device with a screen.

00:08:58.870 --> 00:09:00.760
That information is
passed on to the Actions

00:09:00.760 --> 00:09:02.680
on Google Cloud Platform.

00:09:02.680 --> 00:09:05.230
Actions on Google realizes,
oh, this particular Action

00:09:05.230 --> 00:09:08.580
is implemented in Dialogflow
and forwards it to Dialogflow.

00:09:08.580 --> 00:09:13.330
Dialogflow takes the user input,
matches that to an intent,

00:09:13.330 --> 00:09:15.450
and then invokes the
associated fulfillment--

00:09:15.450 --> 00:09:16.750
the code behind that--

00:09:16.750 --> 00:09:19.230
to provide a dynamic response.

00:09:19.230 --> 00:09:20.980
And for screens, you
can provide something

00:09:20.980 --> 00:09:21.897
like a reach response.

00:09:21.897 --> 00:09:23.840
It could be a list, a table.

00:09:23.840 --> 00:09:26.080
These are all existing widgets.

00:09:26.080 --> 00:09:28.420
That reach response is
forwarded to the device

00:09:28.420 --> 00:09:30.770
and it's displayed to the user.

00:09:30.770 --> 00:09:35.430
So that's how conversational
Actions work today.

00:09:35.430 --> 00:09:37.800
So what is an interactive
Action, also implemented

00:09:37.800 --> 00:09:38.570
in Dialogflow.

00:09:38.570 --> 00:09:40.620
Well you notice our
diagram is very similar,

00:09:40.620 --> 00:09:43.850
but we have this new component.

00:09:43.850 --> 00:09:46.070
So, again, let's look
at the life cycle.

00:09:46.070 --> 00:09:47.740
The user talks to the device.

00:09:47.740 --> 00:09:50.610
That user input is passed
onto Actions on Google.

00:09:50.610 --> 00:09:53.040
Actions on Google
invokes Dialogflow.

00:09:53.040 --> 00:09:56.490
Dialogflow matches the intent
based on that user phrase.

00:09:56.490 --> 00:09:59.890
It then invokes the
associated fulfillment logic.

00:09:59.890 --> 00:10:01.360
And it provides a response.

00:10:01.360 --> 00:10:03.970
But now it provides a
new kind of response,

00:10:03.970 --> 00:10:06.780
an immersive response.

00:10:06.780 --> 00:10:08.280
So it's similar to
simple and reach,

00:10:08.280 --> 00:10:10.770
but it has some
extra data in there.

00:10:10.770 --> 00:10:14.100
As part of the immersive
response, you provide a URL.

00:10:14.100 --> 00:10:16.620
That URL is forwarded
to the device.

00:10:16.620 --> 00:10:20.100
The device loads the associated
web app from that URL.

00:10:23.100 --> 00:10:25.440
When the web app
starts on the device,

00:10:25.440 --> 00:10:29.320
it initializes the
Interactive Canvas API.

00:10:29.320 --> 00:10:32.152
It also registers
some callbacks.

00:10:32.152 --> 00:10:34.485
Now, this is the way to pass
some information to the web

00:10:34.485 --> 00:10:34.850
app.

00:10:34.850 --> 00:10:36.308
And it's also a
way for the web app

00:10:36.308 --> 00:10:39.050
to communicate back
to Actions on Google.

00:10:39.050 --> 00:10:40.550
So if you look at
this diagram, it's

00:10:40.550 --> 00:10:42.800
very similar to an
existing life cycle

00:10:42.800 --> 00:10:44.300
of the conversational Action.

00:10:44.300 --> 00:10:47.690
We just now have this new
way of visualizing the Action

00:10:47.690 --> 00:10:49.880
on a device with a screen.

00:10:53.570 --> 00:10:54.730
But let's look at the code.

00:10:54.730 --> 00:10:57.250
Both for the fulfillment,
for the intent,

00:10:57.250 --> 00:11:01.870
and also for the WebApp
Logic for your game.

00:11:01.870 --> 00:11:04.000
Now the intent fulfillment
needs to provide

00:11:04.000 --> 00:11:05.920
an immersive response.

00:11:05.920 --> 00:11:06.447
Right?

00:11:06.447 --> 00:11:08.780
Actions on Google through
Dialogflow matches the intent.

00:11:08.780 --> 00:11:10.480
The intent says,
here's some code.

00:11:10.480 --> 00:11:11.350
Invoke that code.

00:11:11.350 --> 00:11:14.030
That code generates
an immersive response.

00:11:14.030 --> 00:11:17.020
Node.js client library
has been extended

00:11:17.020 --> 00:11:20.610
with a new class that's really
called ImmersiveResponse.

00:11:20.610 --> 00:11:23.020
Very simple like simple
and reach response.

00:11:23.020 --> 00:11:25.243
There's also a new
surface capability.

00:11:25.243 --> 00:11:26.910
So, in your fulfillment
code, you can go

00:11:26.910 --> 00:11:30.570
and check is the device that
the user is talking to capable

00:11:30.570 --> 00:11:32.460
of doing a Canvas experience?

00:11:32.460 --> 00:11:35.130
If it is, you can use
immersive response.

00:11:35.130 --> 00:11:37.590
If it isn't, use our existing
responses like simple

00:11:37.590 --> 00:11:39.593
and reach responses.

00:11:39.593 --> 00:11:41.010
As part of the
immersive response,

00:11:41.010 --> 00:11:42.093
you need to provide a URL.

00:11:42.093 --> 00:11:45.390
It needs to be an
https endpoint.

00:11:45.390 --> 00:11:46.972
That gets forwarded
to the device

00:11:46.972 --> 00:11:48.180
the device loads the web app.

00:11:52.370 --> 00:11:54.540
Let's look at the
fulfillment logic.

00:11:54.540 --> 00:11:56.840
So this is our
Cloud Function code.

00:11:56.840 --> 00:11:59.420
We're using our
Node.js client library.

00:11:59.420 --> 00:12:01.820
And here we have
an intent handler

00:12:01.820 --> 00:12:04.860
for the default welcome intent.

00:12:04.860 --> 00:12:08.520
Note we're using an instance
of the ImmersiveResponse class.

00:12:08.520 --> 00:12:11.920
And there's two pieces of
information you need to pass.

00:12:11.920 --> 00:12:12.910
Firstly, the URL.

00:12:12.910 --> 00:12:16.040
That's the https
endpoint of your web app.

00:12:16.040 --> 00:12:18.250
Secondly, some
state information.

00:12:18.250 --> 00:12:21.100
Now here we have a variable
that's initialized to the value

00:12:21.100 --> 00:12:21.910
welcome.

00:12:21.910 --> 00:12:25.480
But that state object is
actually a JSON object.

00:12:25.480 --> 00:12:28.990
So you can parse in any JSON
payload from fulfillment

00:12:28.990 --> 00:12:30.615
to your web app.

00:12:30.615 --> 00:12:31.990
But for our
examples, we're going

00:12:31.990 --> 00:12:34.570
to keep it simple
with simple states.

00:12:34.570 --> 00:12:36.310
And that's quite a
common thing for games

00:12:36.310 --> 00:12:40.080
to track states from fulfillment
and pass it on to the web app.

00:12:42.920 --> 00:12:45.320
So the web app,
it's regular HTML.

00:12:45.320 --> 00:12:47.090
You have to write
some JavaScript code.

00:12:47.090 --> 00:12:48.950
There's a few things
you need to do.

00:12:48.950 --> 00:12:52.830
Firstly, declare
these event callbacks.

00:12:52.830 --> 00:12:55.470
Second, you need to
initialize the library

00:12:55.470 --> 00:12:56.873
we provide for Canvas.

00:12:56.873 --> 00:12:58.290
And, as part of
that, you actually

00:12:58.290 --> 00:13:00.360
register those callbacks
with the library.

00:13:00.360 --> 00:13:02.640
And then is ready
to accept events.

00:13:02.640 --> 00:13:04.830
And then in within
your event handler,

00:13:04.830 --> 00:13:06.180
you'll have some custom logic.

00:13:06.180 --> 00:13:07.980
That as the events
are coming in,

00:13:07.980 --> 00:13:10.920
you'll match that with the
game state within your game.

00:13:14.507 --> 00:13:16.090
Now, if you're a web
developer, you're

00:13:16.090 --> 00:13:19.960
probably relying on some
popular framework or library.

00:13:19.960 --> 00:13:22.130
Those will just work as is.

00:13:22.130 --> 00:13:25.240
So if you're using Pixi
or TweenJS or React,

00:13:25.240 --> 00:13:28.400
those will work just
fine out of the box.

00:13:28.400 --> 00:13:33.265
However, we do recommend you
use a single page application.

00:13:33.265 --> 00:13:35.390
And this is important
because you can reuse the web

00:13:35.390 --> 00:13:37.540
app across intent invocations.

00:13:37.540 --> 00:13:42.930
It also ensures a seamless
UX experience for the user.

00:13:42.930 --> 00:13:46.100
Now, we recommend using Firebase
hosting for getting started.

00:13:46.100 --> 00:13:49.620
It's actually a super fast
way of updating your web app.

00:13:49.620 --> 00:13:51.410
But if you've got an
existing web server,

00:13:51.410 --> 00:13:52.760
you can just reuse it for that.

00:13:56.550 --> 00:13:57.360
Here's the web app.

00:13:57.360 --> 00:13:59.080
This is the HTML code.

00:13:59.080 --> 00:14:01.740
So there's a few things you
need to do in your web app.

00:14:01.740 --> 00:14:05.340
The first thing is you need
to include our style sheet.

00:14:05.340 --> 00:14:06.420
Now on the display--

00:14:06.420 --> 00:14:09.632
on the device with a screen--
we add a header at the top.

00:14:09.632 --> 00:14:10.840
There's two reasons for that.

00:14:10.840 --> 00:14:12.630
One is to brand your action.

00:14:12.630 --> 00:14:16.560
And secondly, it allows users to
navigate away from your action.

00:14:16.560 --> 00:14:19.382
Now that means you can't
use that area for your game.

00:14:19.382 --> 00:14:21.090
And the style sheet
gives you information

00:14:21.090 --> 00:14:22.548
about the rest of
the screen that's

00:14:22.548 --> 00:14:25.830
available for rendering
your game state.

00:14:25.830 --> 00:14:29.020
So that's the first thing.

00:14:29.020 --> 00:14:30.870
Secondly, you
include our library.

00:14:30.870 --> 00:14:35.590
So this will give you access
to the Interactive Canvas API.

00:14:35.590 --> 00:14:37.410
We also have some code
here in our example

00:14:37.410 --> 00:14:41.210
in the main doT.js file,
which we'll take a look at.

00:14:41.210 --> 00:14:45.020
Now in your web app, we import
and initialize our library.

00:14:45.020 --> 00:14:48.200
Once you do that you get access
to a special instance variable

00:14:48.200 --> 00:14:50.540
called assistantCanvas.

00:14:50.540 --> 00:14:53.240
That is how you
actually call the API.

00:14:53.240 --> 00:14:55.910
The very first thing you need
to do when the web app loads

00:14:55.910 --> 00:14:57.350
is called the ready method.

00:14:57.350 --> 00:14:59.390
And that's how you
register these callbacks

00:14:59.390 --> 00:15:02.670
that you've declared in your
JavaScript with the API.

00:15:02.670 --> 00:15:05.800
And now it's ready
to accept events.

00:15:05.800 --> 00:15:07.700
So yes, a super simple example.

00:15:07.700 --> 00:15:10.150
So we've declared one callback.

00:15:10.150 --> 00:15:13.580
And we call the
assistantCanvas.ready method.

00:15:13.580 --> 00:15:14.830
That's how we invoke the API.

00:15:14.830 --> 00:15:17.630
And we're parsing in
reference to those callbacks.

00:15:17.630 --> 00:15:19.760
So now, once your web
app have done that--

00:15:19.760 --> 00:15:22.000
and typically you should
do this on page load--

00:15:22.000 --> 00:15:24.640
it's ready to accept
events based on fulfillment

00:15:24.640 --> 00:15:25.490
from your intents.

00:15:28.480 --> 00:15:32.110
So, the callbacks for handing
those fulfillment updates.

00:15:32.110 --> 00:15:33.840
There is a special
one called onUpdates.

00:15:33.840 --> 00:15:36.870
So that-- you needed a clear
function called onUpdate.

00:15:36.870 --> 00:15:39.480
As a parameter, the
JSON payload that we

00:15:39.480 --> 00:15:41.430
specified in our
fulfillment logic

00:15:41.430 --> 00:15:42.880
is parsed in as a parameter.

00:15:42.880 --> 00:15:44.350
And then you can unpack that.

00:15:44.350 --> 00:15:47.790
And typically that would contain
some game data and some state

00:15:47.790 --> 00:15:48.810
information.

00:15:48.810 --> 00:15:51.285
And then you synchronize
your local web app state

00:15:51.285 --> 00:15:52.410
with the fulfillment state.

00:15:56.410 --> 00:15:58.160
Here's an example
that's been fleshed out.

00:15:58.160 --> 00:16:00.770
Again, this is the same
callback we looked at before.

00:16:00.770 --> 00:16:03.530
You declared this onUpdate--
and onUpdate function.

00:16:03.530 --> 00:16:07.400
And the parameter is the
state we got from fulfillment.

00:16:07.400 --> 00:16:08.960
Just some very basic logic.

00:16:08.960 --> 00:16:12.410
Remember we declared the state
variable as a value of welcome

00:16:12.410 --> 00:16:13.350
in our fulfillment.

00:16:13.350 --> 00:16:15.540
Here we're just
checking in the web app

00:16:15.540 --> 00:16:17.540
whether that is the
state that is passed in

00:16:17.540 --> 00:16:19.760
and then do some
associated logic.

00:16:19.760 --> 00:16:21.552
And as other states
are coming in,

00:16:21.552 --> 00:16:23.260
you can just extend
your switch statement

00:16:23.260 --> 00:16:25.790
to add other custom
logic for your game.

00:16:29.820 --> 00:16:31.590
Let's go back to fulfillment.

00:16:31.590 --> 00:16:33.140
So here's another
intent handler.

00:16:33.140 --> 00:16:34.560
So the user said something else.

00:16:34.560 --> 00:16:36.930
Another intent got
matched by Dialogflow.

00:16:36.930 --> 00:16:39.240
Again, we're using our
Node.js client library

00:16:39.240 --> 00:16:43.660
and we are declaring an instance
of the ImmersiveResponse class.

00:16:43.660 --> 00:16:46.150
Now, you note there's
no URL, right?

00:16:46.150 --> 00:16:48.010
We previously invoked
the welcome intent.

00:16:48.010 --> 00:16:49.040
It loaded the web app.

00:16:49.040 --> 00:16:50.440
It's on the device.

00:16:50.440 --> 00:16:52.360
Waiting for new events.

00:16:52.360 --> 00:16:54.760
When you parse in
this information,

00:16:54.760 --> 00:16:56.110
it doesn't reload the web app.

00:16:56.110 --> 00:16:58.730
It just passes the
state information.

00:16:58.730 --> 00:17:01.490
So here we are using the same
state variable we had before,

00:17:01.490 --> 00:17:03.430
but now it has a
different value.

00:17:03.430 --> 00:17:05.849
Within your web app, you just
extend that switch statement

00:17:05.849 --> 00:17:07.599
and now you can check
for the change value

00:17:07.599 --> 00:17:09.609
and do something appropriate.

00:17:09.609 --> 00:17:12.369
So now we have ways for
parsing information initially

00:17:12.369 --> 00:17:15.270
when you load the page and then
subsequently when other intents

00:17:15.270 --> 00:17:16.270
are invoked by the user.

00:17:19.730 --> 00:17:20.230
OK.

00:17:20.230 --> 00:17:22.500
So now we know how
to get data and state

00:17:22.500 --> 00:17:24.660
information from
fulfillment to the web app.

00:17:24.660 --> 00:17:26.970
But there actually is
other way for the web app

00:17:26.970 --> 00:17:28.950
to invoke intent.

00:17:28.950 --> 00:17:31.820
So this is very similar to the
user talking to the device.

00:17:31.820 --> 00:17:34.320
That the user provides
voice or keyboard input,

00:17:34.320 --> 00:17:35.910
then it invokes an intent.

00:17:35.910 --> 00:17:38.100
But now we have an API
to do the same thing.

00:17:38.100 --> 00:17:39.570
You can do this
programmatically.

00:17:39.570 --> 00:17:42.180
And the API is
called sendTextQuery.

00:17:42.180 --> 00:17:46.930
Again, use our assistantCanvas
instance to call that API.

00:17:46.930 --> 00:17:49.410
So this is very useful
in your custom GUI

00:17:49.410 --> 00:17:52.710
for handling buttons or even
doing asynchronous intent

00:17:52.710 --> 00:17:58.220
invocations, which wasn't
possible up until now.

00:17:58.220 --> 00:18:00.330
OK, here's a super
simple example.

00:18:00.330 --> 00:18:01.570
At the top is the HTML.

00:18:01.570 --> 00:18:02.800
We're declaring a button.

00:18:02.800 --> 00:18:05.280
And we're just saying, there
is a JavaScript function

00:18:05.280 --> 00:18:08.290
that gets called when the
user clicks on the button.

00:18:08.290 --> 00:18:10.020
And then in our
function, we are simply

00:18:10.020 --> 00:18:12.510
calling the same
text query method

00:18:12.510 --> 00:18:14.520
of our assistantCanvas API.

00:18:14.520 --> 00:18:16.110
And we parse in a phrase.

00:18:16.110 --> 00:18:17.850
So, again, it's like
the user said this,

00:18:17.850 --> 00:18:20.290
but you're doing this
programmatically.

00:18:20.290 --> 00:18:22.600
That gets passed
on to Dialogflow.

00:18:22.600 --> 00:18:25.030
Dialogflow does the same as
it does with the user input.

00:18:25.030 --> 00:18:28.005
Matches an intent and
invokes the fulfillment.

00:18:31.970 --> 00:18:35.530
Another very useful
feature that is provided

00:18:35.530 --> 00:18:38.110
as part of the Interactive
Canvas experience

00:18:38.110 --> 00:18:43.140
is the ability to sync audio
with your game animation.

00:18:43.140 --> 00:18:46.750
And a lot of our games that we
are showcasing is using that.

00:18:46.750 --> 00:18:50.190
So what you do is you
render TTS like you normally

00:18:50.190 --> 00:18:52.060
do in a conversational Action.

00:18:52.060 --> 00:18:54.420
For example, you might
provide a simple response

00:18:54.420 --> 00:18:56.310
in your fulfillment.

00:18:56.310 --> 00:18:57.770
But now we have a
special callback

00:18:57.770 --> 00:19:00.830
that gets invoked that
tracks the completion

00:19:00.830 --> 00:19:03.750
of each part of that TTS.

00:19:03.750 --> 00:19:06.390
And, at each time that
callback is called,

00:19:06.390 --> 00:19:10.380
you can now synchronize some
game animation or game state

00:19:10.380 --> 00:19:12.180
with each of those invocations.

00:19:14.968 --> 00:19:15.760
How does this work?

00:19:15.760 --> 00:19:17.988
Well, we are
relying on the SSML.

00:19:17.988 --> 00:19:20.280
So SSML is something we've
supported from the beginning

00:19:20.280 --> 00:19:21.000
with Actions.

00:19:21.000 --> 00:19:23.880
It's a super powerful
feature for developers

00:19:23.880 --> 00:19:26.530
to basically control the
way the TTS get pronounced.

00:19:26.530 --> 00:19:28.770
So developers can
change the pronunciation

00:19:28.770 --> 00:19:31.180
of individual
words or sentences.

00:19:31.180 --> 00:19:32.460
You can add sound effects.

00:19:32.460 --> 00:19:34.380
You can even add
background music.

00:19:34.380 --> 00:19:36.300
And in particular
on our platform,

00:19:36.300 --> 00:19:40.110
we actually allow you to layer
TTS and various sounds, which

00:19:40.110 --> 00:19:42.780
is unique to our platform.

00:19:42.780 --> 00:19:46.210
There's is a standard
mark tag in SSML.

00:19:46.210 --> 00:19:48.590
And we are using that
for this feature.

00:19:48.590 --> 00:19:51.190
So that allows you to
place markers in the TTS

00:19:51.190 --> 00:19:53.470
that you're providing
for your response.

00:19:53.470 --> 00:19:55.840
And events are generated
for each of those

00:19:55.840 --> 00:19:58.550
when the TTS is played back.

00:19:58.550 --> 00:20:01.578
The platform also automatically
gives you start and end event

00:20:01.578 --> 00:20:02.120
for your TTS.

00:20:05.960 --> 00:20:07.550
Here's has a super
simple example.

00:20:07.550 --> 00:20:09.190
This is the SSML.

00:20:09.190 --> 00:20:10.840
Here we have got two marks.

00:20:10.840 --> 00:20:13.780
The one is called "here" and
the other one is called "there."

00:20:17.020 --> 00:20:18.282
Here's our callback.

00:20:18.282 --> 00:20:19.990
Now previously we
looked at the onUpdate.

00:20:19.990 --> 00:20:23.080
Now we're looking at another
one called onTtsMark.

00:20:23.080 --> 00:20:25.210
Works in a similar way,
but now the parameter

00:20:25.210 --> 00:20:26.980
is the name of the mark.

00:20:26.980 --> 00:20:30.430
So as the TTS is played back,
it hits each of those marks.

00:20:30.430 --> 00:20:32.800
That name is parsed
into this callback

00:20:32.800 --> 00:20:35.140
and then your code can
do the appropriate thing.

00:20:35.140 --> 00:20:37.180
So here we are just
checking for here and there.

00:20:37.180 --> 00:20:39.310
And we can synchronize
our game animation

00:20:39.310 --> 00:20:40.270
based on those events.

00:20:44.050 --> 00:20:46.470
So let's do a quick
recap on the life cycle.

00:20:46.470 --> 00:20:48.180
The user talks to the device.

00:20:48.180 --> 00:20:51.150
That user input gets
passed on to Dialogflow.

00:20:51.150 --> 00:20:53.070
Dialogflow matches
an intent, which

00:20:53.070 --> 00:20:54.930
then invokes fulfillment,
the code that

00:20:54.930 --> 00:20:56.920
provides a dynamic response.

00:20:56.920 --> 00:20:58.980
And now it provides a
new kind of response,

00:20:58.980 --> 00:21:00.660
an immersive response.

00:21:00.660 --> 00:21:03.450
Which gives a URL to the device.

00:21:03.450 --> 00:21:06.270
The device loads the
associated web app.

00:21:06.270 --> 00:21:08.920
When the web loads, it
initializes our Interactive

00:21:08.920 --> 00:21:11.850
Canvas API and register
some callbacks.

00:21:11.850 --> 00:21:15.330
Now the web app is ready to
accept events from fulfillment.

00:21:15.330 --> 00:21:18.330
The web app is also
capable of invoking intent

00:21:18.330 --> 00:21:19.810
on the platform.

00:21:19.810 --> 00:21:22.500
So, if you've done a
conversational Action before,

00:21:22.500 --> 00:21:23.590
it's very similar.

00:21:23.590 --> 00:21:27.580
We're reusing almost all of
that existing life cycle.

00:21:27.580 --> 00:21:30.060
Now we just have
a web app as a way

00:21:30.060 --> 00:21:32.580
of providing a different
view on your action.

00:21:35.790 --> 00:21:38.430
There are some technical
considerations.

00:21:38.430 --> 00:21:39.960
As I mentioned, we add a header.

00:21:39.960 --> 00:21:43.260
And on mobile devices,
it's 56 dp high.

00:21:43.260 --> 00:21:46.170
On Google Nest Hub, it's 96 dp.

00:21:46.170 --> 00:21:48.970
And on other smart
displays it's 120 dp high.

00:21:48.970 --> 00:21:51.660
So don't put any content
or interactive elements

00:21:51.660 --> 00:21:53.940
behind that area on the screen.

00:21:53.940 --> 00:21:57.090
Also, on mobile devices, when
the user provides voice input,

00:21:57.090 --> 00:21:58.650
there's like a
transient transcript

00:21:58.650 --> 00:22:01.020
that the Assistant provides
of what the user is saying.

00:22:01.020 --> 00:22:02.585
So don't put any
critical information

00:22:02.585 --> 00:22:03.960
towards the bottom
of the screen.

00:22:08.130 --> 00:22:10.770
From a technical point of view,
start with a responsive design.

00:22:10.770 --> 00:22:12.645
So that will help you
to automatically handle

00:22:12.645 --> 00:22:15.120
different screen sizes,
from small phones

00:22:15.120 --> 00:22:19.690
to smart displays, which come
in different resolutions.

00:22:19.690 --> 00:22:22.340
You can use your favorite
responsive framework or library

00:22:22.340 --> 00:22:25.000
or you can just use
CSS media queries.

00:22:25.000 --> 00:22:28.258
Also decide whether your game is
going to support both landscape

00:22:28.258 --> 00:22:28.800
and portrait.

00:22:32.600 --> 00:22:35.900
Users should be able to
use the mic or the keyboard

00:22:35.900 --> 00:22:39.670
to complete any critical
conversational Actions.

00:22:39.670 --> 00:22:42.790
You can provide access to
any non-critical interactions

00:22:42.790 --> 00:22:45.680
via touch-only if you want.

00:22:45.680 --> 00:22:47.480
Consider using the
HTML media element

00:22:47.480 --> 00:22:49.797
to provide sound playing
locally within the web app.

00:22:49.797 --> 00:22:52.130
This is very useful for like
sound effects or background

00:22:52.130 --> 00:22:52.790
music.

00:22:52.790 --> 00:22:56.110
It really elevates the
production value of your game.

00:22:56.110 --> 00:23:01.940
Also very importantly, keep
your game logic in fulfillment.

00:23:01.940 --> 00:23:03.860
If you are supporting
voice-only,

00:23:03.860 --> 00:23:06.290
start with that first.

00:23:06.290 --> 00:23:08.870
Then reuse the logic
to drive updates

00:23:08.870 --> 00:23:11.280
to the interactive
version of the Action.

00:23:11.280 --> 00:23:15.370
So think of Interactive Canvas
as another view on your Action.

00:23:18.150 --> 00:23:19.482
There are some limitations.

00:23:19.482 --> 00:23:21.190
So when you load the
web app, it actually

00:23:21.190 --> 00:23:25.390
loads like a web page within
incognito mode within Chrome.

00:23:25.390 --> 00:23:28.690
So that means no local
storage within the web app.

00:23:28.690 --> 00:23:31.390
However, you can use
our existing API's

00:23:31.390 --> 00:23:34.720
in fulfillment to
store session data.

00:23:34.720 --> 00:23:35.860
No pop-ups are allowed.

00:23:35.860 --> 00:23:37.390
No modal dialogues.

00:23:37.390 --> 00:23:39.760
Also the origin is set to null.

00:23:39.760 --> 00:23:42.520
That will have an impact
on things like AJAX calls

00:23:42.520 --> 00:23:44.650
and requests for static media.

00:23:44.650 --> 00:23:46.390
So you might have to
configure your web

00:23:46.390 --> 00:23:48.470
server to support that.

00:23:48.470 --> 00:23:51.460
Also, be aware that devices that
run the interactive experience

00:23:51.460 --> 00:23:53.780
might have limited
hardware capabilities.

00:23:53.780 --> 00:23:55.780
So this goes for
both smart displays

00:23:55.780 --> 00:23:58.030
and all the mobile phones.

00:23:58.030 --> 00:23:59.542
Don't expect the
kind of performance

00:23:59.542 --> 00:24:01.000
you would get on
a desktop browser.

00:24:03.750 --> 00:24:05.800
We've open-sourced
a very simple sample

00:24:05.800 --> 00:24:07.970
that you can go
and try on GitHub.

00:24:07.970 --> 00:24:09.220
It's a very simple animation.

00:24:09.220 --> 00:24:11.620
It's got a little shape
and it keeps turning.

00:24:11.620 --> 00:24:14.860
And then the user can use voice
commands to basically interact

00:24:14.860 --> 00:24:16.370
with this animation.

00:24:16.370 --> 00:24:19.840
The user could say change
it to red or change to blue

00:24:19.840 --> 00:24:21.580
and then it will
actually do that.

00:24:21.580 --> 00:24:24.140
Or the user can say stop
animating or start animating.

00:24:24.140 --> 00:24:25.390
And then you can control that.

00:24:25.390 --> 00:24:27.223
Very simple, but it
shows you the basic life

00:24:27.223 --> 00:24:31.910
cycle of a typical
conversational Action.

00:24:31.910 --> 00:24:34.960
So voice commands are
implemented in Dialogflow.

00:24:34.960 --> 00:24:36.320
We do intent matching.

00:24:36.320 --> 00:24:38.360
Let's take a look at the
code, the fulfillment,

00:24:38.360 --> 00:24:41.810
and the WebLogic behind that.

00:24:41.810 --> 00:24:43.190
So here in our
fulfillment logic,

00:24:43.190 --> 00:24:45.950
we have gotten intent handler
for the welcome intent.

00:24:45.950 --> 00:24:47.740
Note we're using
ImmersiveResponse.

00:24:47.740 --> 00:24:51.800
We're providing the URL to the
https endpoint for our web app.

00:24:51.800 --> 00:24:54.980
So that you should
be familiar with.

00:24:54.980 --> 00:24:56.070
Here with another intent.

00:24:56.070 --> 00:24:57.778
This is the intent
that gets matched when

00:24:57.778 --> 00:24:59.710
the user changes the color.

00:24:59.710 --> 00:25:02.388
And all we're doing now is
we're using immersive response.

00:25:02.388 --> 00:25:03.680
We don't need to provide a URL.

00:25:03.680 --> 00:25:05.500
We're going to keep
that web app running.

00:25:05.500 --> 00:25:07.540
We provide state information,
which is just the color

00:25:07.540 --> 00:25:08.498
that the user selected.

00:25:11.720 --> 00:25:13.700
Here are [INAUDIBLE]
intents, and this is

00:25:13.700 --> 00:25:15.800
for controlling the animation.

00:25:15.800 --> 00:25:18.830
Here we provide a spin
value, which is just

00:25:18.830 --> 00:25:20.438
the state of the animation.

00:25:23.310 --> 00:25:25.470
Here's the web app part of it.

00:25:25.470 --> 00:25:28.680
You have to include
our library, and we're

00:25:28.680 --> 00:25:30.720
going to use the Pixi
JavaScript library, which

00:25:30.720 --> 00:25:33.732
is a very popular framework
for doing JavaScript animation.

00:25:36.510 --> 00:25:38.070
We also have some
coding main.js,

00:25:38.070 --> 00:25:40.390
and we're going to look at that.

00:25:40.390 --> 00:25:42.240
So to start with,
we just initialize

00:25:42.240 --> 00:25:45.195
Pixi and we get a renderer that
actually draws the graphics.

00:25:45.195 --> 00:25:46.570
There's also some
other variables

00:25:46.570 --> 00:25:48.830
for the display
and the game state.

00:25:52.160 --> 00:25:53.700
Here's our main callback.

00:25:53.700 --> 00:25:56.755
And we are implementing that
onUpdate function callback

00:25:56.755 --> 00:25:58.380
and we're just checking
for two things.

00:25:58.380 --> 00:26:00.130
We look at the JSON
data that's parsed in.

00:26:00.130 --> 00:26:02.437
We get the color value
and we get the spin value.

00:26:02.437 --> 00:26:04.270
And then we synchronize
the local variables.

00:26:04.270 --> 00:26:06.022
And this is a typical
pattern with data

00:26:06.022 --> 00:26:07.980
from fulfillment and
synchronize with variables

00:26:07.980 --> 00:26:08.880
within your game.

00:26:11.127 --> 00:26:13.710
This one is interesting in that
you can also touch the screen.

00:26:13.710 --> 00:26:15.835
So as you touch the screen,
it toggles the variable

00:26:15.835 --> 00:26:17.340
that controls the animation.

00:26:17.340 --> 00:26:19.710
So again we are just flipping
the value of the spin

00:26:19.710 --> 00:26:22.690
variable in the game state.

00:26:22.690 --> 00:26:24.460
Here's our main animation frame.

00:26:24.460 --> 00:26:27.113
It's the function that
get calls for generating

00:26:27.113 --> 00:26:28.280
each frame in the animation.

00:26:28.280 --> 00:26:30.220
It does a little bit
of math and figures

00:26:30.220 --> 00:26:31.480
out how to rotate the shape.

00:26:31.480 --> 00:26:33.063
And then of course,
it uses the values

00:26:33.063 --> 00:26:36.010
of the color and the spin
whether it should be animating

00:26:36.010 --> 00:26:37.280
or not.

00:26:37.280 --> 00:26:39.800
And that's pretty much all the
code that's in our samples.

00:26:39.800 --> 00:26:42.560
So go and give it
a try on GitHub.

00:26:42.560 --> 00:26:43.300
OK.

00:26:43.300 --> 00:26:46.660
So as a developer, how do you
debug your Interactive Canvas

00:26:46.660 --> 00:26:47.700
Action?

00:26:47.700 --> 00:26:49.210
Well, our simulator
supports this.

00:26:49.210 --> 00:26:50.380
So you can run it
just like you normally

00:26:50.380 --> 00:26:51.850
do a conversational Action.

00:26:51.850 --> 00:26:54.120
But in particular, you can
use the Chrome DevTools

00:26:54.120 --> 00:26:57.040
to look at the iframe that
we use to host that web app.

00:26:57.040 --> 00:26:59.020
So you can use all
the existing tools

00:26:59.020 --> 00:27:02.680
for logging, for debugging, for
looking at the DOM structure.

00:27:02.680 --> 00:27:06.440
It's all very powerful
too for debugging.

00:27:06.440 --> 00:27:09.020
You can also test it on any
device with the same developer

00:27:09.020 --> 00:27:09.725
account.

00:27:09.725 --> 00:27:13.160
And, in our example, we provide
debug overlay, which just

00:27:13.160 --> 00:27:14.450
provides the console output.

00:27:14.450 --> 00:27:17.790
So it's useful for looking
at the output on a display.

00:27:17.790 --> 00:27:21.320
We also use an open-source
library for the statistics.

00:27:21.320 --> 00:27:24.860
And this is useful for tracking
how well our performance is

00:27:24.860 --> 00:27:26.550
going on different devices.

00:27:26.550 --> 00:27:28.550
What is the frame
rate, for example.

00:27:28.550 --> 00:27:31.870
And that's all it takes to
create an Interactive Canvas

00:27:31.870 --> 00:27:34.560
Action.

00:27:34.560 --> 00:27:37.892
[APPLAUSE]

00:27:40.272 --> 00:27:43.580
JOHN HSU: Well, I hope you're
all excited to get started.

00:27:43.580 --> 00:27:45.410
Before we get off to
the races, though,

00:27:45.410 --> 00:27:47.868
I want to talk through some
design principles and some best

00:27:47.868 --> 00:27:49.360
practices that
will help maximize

00:27:49.360 --> 00:27:51.395
the impact of your content.

00:27:51.395 --> 00:27:52.770
Let me get a quick
show of hands.

00:27:52.770 --> 00:27:55.290
How many of you have
created a voice action--

00:27:55.290 --> 00:27:58.300
voice game for Google Assistant?

00:27:58.300 --> 00:27:58.800
OK.

00:27:58.800 --> 00:28:00.175
A few of you in
the room and sure

00:28:00.175 --> 00:28:03.690
there's several that are
following along online as well.

00:28:03.690 --> 00:28:06.510
For you, there's a lot of
ways to enhance your voice

00:28:06.510 --> 00:28:10.200
games by leveraging the visual
capabilities of the platform.

00:28:10.200 --> 00:28:13.440
As Leon mentioned, the
backbone of a Canvas Action

00:28:13.440 --> 00:28:15.030
is a conversational Action.

00:28:15.030 --> 00:28:16.470
And so adding
visuals is actually

00:28:16.470 --> 00:28:18.840
a very straightforward process.

00:28:18.840 --> 00:28:21.690
In the act of building
your voice game,

00:28:21.690 --> 00:28:24.310
you've probably thought
a lot about where the--

00:28:24.310 --> 00:28:26.820
where the payoffs and
experiences that you really

00:28:26.820 --> 00:28:28.515
want to reward the player are.

00:28:28.515 --> 00:28:33.000
And using SSML, it's extremely
easy to align your animations

00:28:33.000 --> 00:28:36.300
with your voices and sounds
that maximizes impact

00:28:36.300 --> 00:28:38.920
for your users.

00:28:38.920 --> 00:28:41.420
Another thing when you've been
building voice games that you

00:28:41.420 --> 00:28:43.520
might run into is
some complexity

00:28:43.520 --> 00:28:46.310
where something that might
be very difficult to describe

00:28:46.310 --> 00:28:49.200
or done through
lengthy conversation.

00:28:49.200 --> 00:28:52.610
For example, whose turn it is
or lengthy clues about visuals.

00:28:52.610 --> 00:28:55.220
Keep in mind that these
moments might be easily solved

00:28:55.220 --> 00:28:58.400
using visuals and leverage
that capability in order

00:28:58.400 --> 00:29:00.170
to enhance your game.

00:29:00.170 --> 00:29:02.330
Oftentimes, people are
nervous that maybe this will

00:29:02.330 --> 00:29:04.550
create a situation
where their voice

00:29:04.550 --> 00:29:05.900
action won't work as well.

00:29:05.900 --> 00:29:08.840
But, because you
can determine what

00:29:08.840 --> 00:29:11.360
the capabilities of the
surface you're on is,

00:29:11.360 --> 00:29:13.670
you can actually create
different conversations

00:29:13.670 --> 00:29:17.090
depending on what surface
your user is playing on.

00:29:19.920 --> 00:29:22.350
Now, for those of you who
haven't created a voice game,

00:29:22.350 --> 00:29:23.993
we're excited--

00:29:23.993 --> 00:29:26.160
we're excited for you to
start developing games that

00:29:26.160 --> 00:29:29.100
are bespoke for the
visual display device.

00:29:29.100 --> 00:29:31.890
Games historically that have
been successful on the platform

00:29:31.890 --> 00:29:37.500
have really leveraged the unique
capabilities of the platform.

00:29:37.500 --> 00:29:41.490
What we believe is the
unique advantage of Canvas

00:29:41.490 --> 00:29:44.280
and the Google Assistant is that
it enables a new interaction

00:29:44.280 --> 00:29:47.190
model that just isn't
possible on other platforms.

00:29:47.190 --> 00:29:49.650
For voice games,
we've already been

00:29:49.650 --> 00:29:51.780
able to use Google
speech recognition

00:29:51.780 --> 00:29:53.280
and natural language
understanding

00:29:53.280 --> 00:29:54.720
to create complex--

00:29:54.720 --> 00:29:56.850
to process complex voice inputs.

00:29:56.850 --> 00:29:59.670
But the output is
strictly been audio.

00:29:59.670 --> 00:30:01.650
For traditional games,
you've had access

00:30:01.650 --> 00:30:03.150
to the visual surface.

00:30:03.150 --> 00:30:06.690
But you haven't had access to
the more sophisticated language

00:30:06.690 --> 00:30:10.420
understanding that Google
Assistant provides.

00:30:10.420 --> 00:30:12.850
Interactive Canvas, along
with Google Assistant,

00:30:12.850 --> 00:30:17.430
provides you this new way to
interact and create content.

00:30:17.430 --> 00:30:19.520
One of the key important
things to keep in mind

00:30:19.520 --> 00:30:22.820
is that the experiences that are
going to succeed in this space

00:30:22.820 --> 00:30:26.000
are focused on voice
being the right input

00:30:26.000 --> 00:30:27.320
for your experience.

00:30:27.320 --> 00:30:29.090
If you simply map
verbal commands

00:30:29.090 --> 00:30:31.820
to a controller input
and the user saying up,

00:30:31.820 --> 00:30:33.110
go right, shoot.

00:30:33.110 --> 00:30:35.000
You're probably not
taking advantage

00:30:35.000 --> 00:30:38.300
of what the capabilities of
the platform fully allows.

00:30:38.300 --> 00:30:40.100
If you've built
voice games and you

00:30:40.100 --> 00:30:41.540
create you've
spent a lot of time

00:30:41.540 --> 00:30:45.292
creating an immersive
world through text-only,

00:30:45.292 --> 00:30:47.000
make sure that you're
taking a step back.

00:30:47.000 --> 00:30:48.830
And realizing that
there are mechanics

00:30:48.830 --> 00:30:51.560
that you can use with
a visual display that

00:30:51.560 --> 00:30:54.410
will create a transformative
experience for the player

00:30:54.410 --> 00:30:55.580
as well.

00:30:55.580 --> 00:30:57.650
While on the technical
side, we can just

00:30:57.650 --> 00:30:59.750
simply port HTML5 games.

00:30:59.750 --> 00:31:01.760
We're encouraged and
interested in seeing

00:31:01.760 --> 00:31:04.850
you create games that
really leverage the voice

00:31:04.850 --> 00:31:07.207
component of the platform.

00:31:07.207 --> 00:31:08.790
Let's take a look a
couple of examples

00:31:08.790 --> 00:31:10.498
that really leverage this.

00:31:10.498 --> 00:31:12.790
One thing that we've been
thinking about is word games.

00:31:12.790 --> 00:31:15.270
I think there's a lot that
affords word games to be

00:31:15.270 --> 00:31:16.320
on the platform.

00:31:16.320 --> 00:31:19.170
Because of the fact that
visual puzzles are a way--

00:31:19.170 --> 00:31:21.630
the visual capabilities
showcase a lot of ways

00:31:21.630 --> 00:31:23.670
that you can engage
with word puzzles.

00:31:23.670 --> 00:31:26.250
Crossword puzzles, anagrams--
like what we're showing

00:31:26.250 --> 00:31:27.420
on the right hand there--

00:31:27.420 --> 00:31:29.400
even image puzzles where
you're given images

00:31:29.400 --> 00:31:33.030
and have to determine what
the clue are well designed

00:31:33.030 --> 00:31:34.710
for the visual surface.

00:31:34.710 --> 00:31:36.990
In addition, because they're
word games and the inputs

00:31:36.990 --> 00:31:38.340
are actually words.

00:31:38.340 --> 00:31:41.040
It actually affords the
user to speak those answers

00:31:41.040 --> 00:31:43.330
with their voice.

00:31:43.330 --> 00:31:46.167
A slightly more complex
example is an adventure game.

00:31:46.167 --> 00:31:48.500
Text-based adventures were
super popular back in the day

00:31:48.500 --> 00:31:51.350
and created an immersive world
when the only input a user

00:31:51.350 --> 00:31:52.790
had was through text.

00:31:52.790 --> 00:31:55.700
We have an opportunity
today to restructure

00:31:55.700 --> 00:31:57.230
how adventure games work.

00:31:57.230 --> 00:31:59.360
We don't have to
have text based input

00:31:59.360 --> 00:32:01.970
where you're issuing
commands to your character.

00:32:01.970 --> 00:32:05.840
Rather, let's create experiences
where characters in the game

00:32:05.840 --> 00:32:07.820
are helping you
navigate the experience

00:32:07.820 --> 00:32:10.950
through conversation, not
through direct actions.

00:32:10.950 --> 00:32:13.410
So in this example on
the right that you see,

00:32:13.410 --> 00:32:14.730
we've created a world--

00:32:14.730 --> 00:32:16.310
and this is just
a simple example--

00:32:16.310 --> 00:32:20.060
where characters are helping
you guide the conversation.

00:32:20.060 --> 00:32:22.580
You're not in a situation
where you're like,

00:32:22.580 --> 00:32:24.673
talk to character on the left.

00:32:24.673 --> 00:32:26.840
The character is already
initiating the conversation

00:32:26.840 --> 00:32:27.470
with you.

00:32:27.470 --> 00:32:30.290
And astute users will notice
that the response to the

00:32:30.290 --> 00:32:31.400
where we are?

00:32:31.400 --> 00:32:34.280
Is based on the context
clue on the top right where

00:32:34.280 --> 00:32:35.840
Big Ben is in the background.

00:32:35.840 --> 00:32:39.640
And they'll recognize
that the answer is London.

00:32:39.640 --> 00:32:41.200
Another unique
platform advantage

00:32:41.200 --> 00:32:43.510
is specifically to
our smart displays,

00:32:43.510 --> 00:32:46.480
is that they often
reside in common areas.

00:32:46.480 --> 00:32:48.280
Because of this,
having games that

00:32:48.280 --> 00:32:50.700
really focus on
social interaction

00:32:50.700 --> 00:32:53.302
is something that's
unique to this platform.

00:32:53.302 --> 00:32:54.760
And as well, being
in the home, you

00:32:54.760 --> 00:32:57.970
have access to a very
unique social graph.

00:32:57.970 --> 00:33:01.010
That of your family
and your home.

00:33:01.010 --> 00:33:03.560
One way to engage with this
is through trivia games

00:33:03.560 --> 00:33:04.935
as Lucky Trivia has done.

00:33:04.935 --> 00:33:07.310
But there are other types of
examples where you're really

00:33:07.310 --> 00:33:10.250
playing on the fact that
being in the same environment

00:33:10.250 --> 00:33:13.390
allows social
interactions to flourish.

00:33:13.390 --> 00:33:15.610
Additionally, rather
than having to setup

00:33:15.610 --> 00:33:17.410
multiple types of
inputs or making

00:33:17.410 --> 00:33:19.180
sure things are
connected, everyone

00:33:19.180 --> 00:33:22.560
can use what they've already
have for input, Their voice.

00:33:25.520 --> 00:33:27.650
Persistent games have
been popular in mobile

00:33:27.650 --> 00:33:31.100
and really showcase
the progress of RPGs

00:33:31.100 --> 00:33:33.032
as well as farming games.

00:33:33.032 --> 00:33:34.490
These types of
environments-- where

00:33:34.490 --> 00:33:36.620
users are making
continuous progress--

00:33:36.620 --> 00:33:39.650
have been very popular there
but have relied primarily

00:33:39.650 --> 00:33:42.020
on multi player
online interactions

00:33:42.020 --> 00:33:43.640
to showcase the progress.

00:33:43.640 --> 00:33:47.330
We have an opportunity here
where by focusing on the local,

00:33:47.330 --> 00:33:49.640
we can create collaborative
experiences where

00:33:49.640 --> 00:33:51.260
players within
the same household

00:33:51.260 --> 00:33:54.600
are able to contribute to
the same persistent state.

00:33:54.600 --> 00:33:57.560
In addition, we have access
to a local graph, not simply

00:33:57.560 --> 00:33:59.900
through Google's APIs,
but as well as to the fact

00:33:59.900 --> 00:34:02.060
that you're co-located
in the same area

00:34:02.060 --> 00:34:03.340
and can collaborate together.

00:34:06.228 --> 00:34:08.270
At the end of the day,
we're interested in seeing

00:34:08.270 --> 00:34:09.080
what you have.

00:34:09.080 --> 00:34:10.730
These are not meant
to be prescriptive.

00:34:10.730 --> 00:34:13.489
They're simply ideas that help
the creative juices start.

00:34:13.489 --> 00:34:17.620
We're really looking forward
to see what you create.

00:34:17.620 --> 00:34:20.415
So, before we wrap up, I wanted
to spend a couple more minutes

00:34:20.415 --> 00:34:21.790
talking about some
best practices

00:34:21.790 --> 00:34:24.960
that we found in working
with Interactive Canvas.

00:34:24.960 --> 00:34:27.620
First, as more
assistive devices--

00:34:27.620 --> 00:34:30.830
assistant display devices
start to arise in the market,

00:34:30.830 --> 00:34:34.250
it's tempting to create a
one-size-fits-all design that

00:34:34.250 --> 00:34:36.199
actually targets
all the surfaces.

00:34:36.199 --> 00:34:38.000
While creating
responsive design will

00:34:38.000 --> 00:34:40.790
enable Canvas to deploy
your action to all

00:34:40.790 --> 00:34:43.370
of these surfaces, it's
important to also keep in mind

00:34:43.370 --> 00:34:45.110
that usage patterns
for these surfaces

00:34:45.110 --> 00:34:46.820
are actually very unique.

00:34:46.820 --> 00:34:50.030
Smart displays afford multiple
users are in common areas

00:34:50.030 --> 00:34:52.340
so that multiple people
can engage with them.

00:34:52.340 --> 00:34:55.040
And phones are better suited
for personal, quick interactions

00:34:55.040 --> 00:34:57.980
that might take action
throughout the course

00:34:57.980 --> 00:34:59.140
of the day.

00:34:59.140 --> 00:35:01.640
Consider how your players are
going to engage with your game

00:35:01.640 --> 00:35:02.990
even outside of your game.

00:35:05.910 --> 00:35:09.900
Really focus on voice
forward interactions.

00:35:09.900 --> 00:35:11.850
Conversations are
much more helpful

00:35:11.850 --> 00:35:14.760
and create a deeper sense of
immersion for your player base.

00:35:14.760 --> 00:35:17.400
And if you only use your
voice as a controller,

00:35:17.400 --> 00:35:20.190
there is a sense of breakage in
terms of what the players are

00:35:20.190 --> 00:35:21.660
actively engaging with.

00:35:21.660 --> 00:35:23.550
Where possible,
set up situations

00:35:23.550 --> 00:35:25.260
where you can interact
with characters,

00:35:25.260 --> 00:35:30.100
rather than issue direct
commands to your character.

00:35:30.100 --> 00:35:32.650
For traditional game
developers, it's

00:35:32.650 --> 00:35:35.950
important challenge to realize
that these scope of what

00:35:35.950 --> 00:35:38.990
voice commands entails
is actually quite large.

00:35:38.990 --> 00:35:40.930
And so we need to
definitely leverage

00:35:40.930 --> 00:35:43.750
our visual capabilities
to showcase what

00:35:43.750 --> 00:35:45.508
the users can interact with.

00:35:45.508 --> 00:35:47.050
If you're coming
from the world where

00:35:47.050 --> 00:35:48.790
you've created
voice games, you've

00:35:48.790 --> 00:35:50.530
already engaged in
this creative process

00:35:50.530 --> 00:35:52.210
to come up with the right text.

00:35:52.210 --> 00:35:54.190
But take advantage
of the visuals

00:35:54.190 --> 00:35:58.650
to potentially simplify
those interactions.

00:35:58.650 --> 00:36:01.740
Despite our best efforts, users
can still potentially get lost.

00:36:01.740 --> 00:36:03.660
Or, in a social
setting, there might

00:36:03.660 --> 00:36:06.090
be some crosstalk that
issues incorrect commands

00:36:06.090 --> 00:36:07.830
to the platform.

00:36:07.830 --> 00:36:09.750
In these types of
situations, make sure

00:36:09.750 --> 00:36:11.620
that you're handling
the errors as well.

00:36:11.620 --> 00:36:14.760
And potentially provide explicit
audio suggestions for the user,

00:36:14.760 --> 00:36:16.980
so that they can get back
on track in your game.

00:36:19.920 --> 00:36:21.900
Optimizing your
display is important.

00:36:21.900 --> 00:36:26.160
With a visual display that
is right for visual pay off,

00:36:26.160 --> 00:36:29.130
make sure that you use SSML and
other tools to really maximize

00:36:29.130 --> 00:36:31.200
the payoff and
synchronize your audio

00:36:31.200 --> 00:36:33.030
with your video animations.

00:36:33.030 --> 00:36:35.370
Again, understand
that these devices

00:36:35.370 --> 00:36:38.130
can be viewed at multiple
viewing angles and distances.

00:36:38.130 --> 00:36:42.960
So make sure that your
text is sized correctly.

00:36:42.960 --> 00:36:45.290
Once you've created your
game, figuring out how you get

00:36:45.290 --> 00:36:47.270
discovered as vitally
important as well.

00:36:47.270 --> 00:36:49.940
As Leon mentioned before,
setting up built-in intents

00:36:49.940 --> 00:36:52.890
allow you to be cataloged
when the user says,

00:36:52.890 --> 00:36:54.800
hey, G. Play a game.

00:36:54.800 --> 00:36:56.960
In addition to this,
focus on making sure

00:36:56.960 --> 00:36:58.460
that your games
are high quality,

00:36:58.460 --> 00:37:00.200
have high retention
and engagement,

00:37:00.200 --> 00:37:04.730
and leverage some of the new
technologies that we bring.

00:37:04.730 --> 00:37:08.450
And finally, we're excited to
announce Interactive Canvas

00:37:08.450 --> 00:37:09.800
for developer preview.

00:37:09.800 --> 00:37:14.420
But your feedback is vital to us
for improving and continuously

00:37:14.420 --> 00:37:15.630
improving the platform.

00:37:15.630 --> 00:37:18.230
We'll help and continue to
develop new tools for you.

00:37:18.230 --> 00:37:21.620
But your feedback in terms of
finding bugs and submitting

00:37:21.620 --> 00:37:23.480
them in our public bug
tracker is important.

00:37:23.480 --> 00:37:25.670
But also features that
you would like to see

00:37:25.670 --> 00:37:30.178
and would like access to over
the course of your development.

00:37:30.178 --> 00:37:32.220
We have a couple of more
recommended I/O sessions

00:37:32.220 --> 00:37:33.600
that cover Interactive Canvas.

00:37:33.600 --> 00:37:35.070
Voice and visuals
talks about how

00:37:35.070 --> 00:37:38.190
you can create multi-modal
experiences that span

00:37:38.190 --> 00:37:39.690
the smart speakers, as well as.

00:37:39.690 --> 00:37:40.950
Display devices.

00:37:40.950 --> 00:37:43.350
And how we built
our sandbox demos,

00:37:43.350 --> 00:37:46.350
will showcase how we
created Jungle Dream

00:37:46.350 --> 00:37:49.230
and how you can create a
similar experience as well.

00:37:49.230 --> 00:37:50.500
Times are listed on here.

00:37:50.500 --> 00:37:53.180
But if you happen to miss
them or aren't available,

00:37:53.180 --> 00:37:57.890
they're are going to be
available as videos on YouTube.

00:37:57.890 --> 00:37:59.240
And that's it.

00:37:59.240 --> 00:38:02.960
Primarily, we want you to hit
g.co/interactivecanvas to get

00:38:02.960 --> 00:38:03.590
started.

00:38:03.590 --> 00:38:07.580
That will give you access to
APIs and to the documentation.

00:38:07.580 --> 00:38:09.810
Leon talked us through
some code samples.

00:38:09.810 --> 00:38:11.330
They're available on GitHub.

00:38:11.330 --> 00:38:13.260
Make sure you talk to
us on social media,

00:38:13.260 --> 00:38:14.420
Twitter and Reddit.

00:38:14.420 --> 00:38:17.300
And we'd love your feedback
on our public bug tracker.

00:38:17.300 --> 00:38:18.780
Thank you for coming today.

00:38:18.780 --> 00:38:20.600
We can't wait to see
what you'll create.

00:38:20.600 --> 00:38:23.650
[GOOGLE LOGO MUSIC]

