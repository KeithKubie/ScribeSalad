WEBVTT
Kind: captions
Language: en

00:00:05.593 --> 00:00:09.093
(mellow electronic music)

00:00:14.341 --> 00:00:16.440
- Alright so the question that we are

00:00:16.440 --> 00:00:19.510
studying in my lab is, how does something

00:00:19.510 --> 00:00:22.830
as complex as the brain form in the course

00:00:22.830 --> 00:00:24.340
of embryonic development?

00:00:24.340 --> 00:00:26.240
How do the first circuits develop?

00:00:26.240 --> 00:00:28.576
How do they become functionally active?

00:00:28.576 --> 00:00:31.340
How do they perform the first computations

00:00:31.340 --> 00:00:33.120
and instruct the first behaviors?

00:00:33.120 --> 00:00:35.570
And so because all of these aspects

00:00:35.570 --> 00:00:37.341
are highly dynamic aspects,

00:00:37.341 --> 00:00:40.860
we spend quite a large
fraction of our time

00:00:40.860 --> 00:00:42.550
actually also developing technology

00:00:42.550 --> 00:00:45.437
that allows us to
visualize and also measure,

00:00:45.437 --> 00:00:49.110
at the cellular level and
at even smaller scales,

00:00:49.110 --> 00:00:53.230
what's happening during the
development and the emergence

00:00:53.230 --> 00:00:54.900
of function in the nervous system.

00:00:54.900 --> 00:00:57.660
And so, I'd just like to start with two

00:00:57.660 --> 00:01:00.010
examples of microscopes and imaging,

00:01:00.010 --> 00:01:02.179
as we've developed for this purpose.

00:01:02.179 --> 00:01:04.929
What you can see here is a life-imaging

00:01:04.929 --> 00:01:07.910
experiment with a nuclear
labeled, Drosophila embryo,

00:01:07.910 --> 00:01:09.530
going through embryogenesis.

00:01:09.530 --> 00:01:11.134
And we can basically follow all of

00:01:11.134 --> 00:01:14.746
the different cells, as
they move and divide,

00:01:14.746 --> 00:01:17.250
and specifically,
reconstruct the formation

00:01:17.250 --> 00:01:18.624
of the early nervous system.

00:01:18.624 --> 00:01:20.620
So that the structure is the equivalent

00:01:20.620 --> 00:01:24.390
of the vertebrate spinal cord
that's being formed here.

00:01:24.390 --> 00:01:26.944
So we have this len-esh-wee
construction and the

00:01:26.944 --> 00:01:31.223
morphodynamic building plan
of the early nervous system.

00:01:31.223 --> 00:01:34.370
Now, complementing this
developmental perspective,

00:01:34.370 --> 00:01:36.540
we also like to capture what's happening

00:01:36.540 --> 00:01:38.610
in the angio neurons once the

00:01:38.610 --> 00:01:40.780
nervous system is really up and running.

00:01:40.780 --> 00:01:42.598
So we need tools that are even faster.

00:01:42.598 --> 00:01:45.050
Now we're imaging at
100 times higher speed,

00:01:45.050 --> 00:01:46.640
and even larger volume.

00:01:46.640 --> 00:01:49.120
This is the brain of the larval zebrafish,

00:01:49.120 --> 00:01:51.154
with about 100,000 neurons.

00:01:51.154 --> 00:01:56.115
And using calcium indicators,
we can follow the activity

00:01:56.115 --> 00:01:58.100
during different times of behaviors.

00:01:58.100 --> 00:02:01.440
And so from these whole-brain
function imaging recordings,

00:02:01.440 --> 00:02:03.495
we can then figure out
what kind of circuits

00:02:03.495 --> 00:02:05.865
are involved in certain
kinds of behaviors.

00:02:05.865 --> 00:02:08.110
And what kind of networks across the brain

00:02:08.110 --> 00:02:09.530
are communicating with each other,

00:02:09.530 --> 00:02:10.910
and are jointly involved

00:02:10.910 --> 00:02:12.560
in certain types of computations.

00:02:13.831 --> 00:02:15.690
I chose these two examples, also,

00:02:15.690 --> 00:02:17.310
because in both of these cases,

00:02:17.310 --> 00:02:19.240
these imaging experiments
mark the first time

00:02:19.240 --> 00:02:21.310
that an analysis like this was possible.

00:02:21.310 --> 00:02:22.990
This was the first time
that we could actually

00:02:22.990 --> 00:02:25.940
track cells systematically,
across a high-end vertebrate.

00:02:25.940 --> 00:02:27.490
And the first time that we could image

00:02:27.490 --> 00:02:28.916
neural activity at the cellular level,

00:02:28.916 --> 00:02:30.870
across a vertebrate brain.

00:02:30.870 --> 00:02:34.642
And what's made it possible
to do these types of...

00:02:34.642 --> 00:02:37.190
To record these types of data sets,

00:02:37.190 --> 00:02:38.410
to do these types of analysis,

00:02:38.410 --> 00:02:40.642
is the concept of light-sheet microscopy.

00:02:40.642 --> 00:02:43.386
So I'd just like to
remind you, very briefly,

00:02:43.386 --> 00:02:46.258
what the key concept is
behind this technique.

00:02:46.258 --> 00:02:48.040
It's actually a very old technique,

00:02:48.040 --> 00:02:49.400
it's been around for more
than a hundred years,

00:02:49.400 --> 00:02:51.896
which makes it twice as
old as confocal microscopy.

00:02:51.896 --> 00:02:55.387
And to the present day,
the fundamental concept

00:02:55.387 --> 00:02:56.840
has basically remained the same.

00:02:56.840 --> 00:02:58.530
What we are doing, is we are illuminating

00:02:58.530 --> 00:03:01.380
a sample with a thin sheet of light,

00:03:01.380 --> 00:03:04.640
of laser light, that is entering the

00:03:04.640 --> 00:03:05.650
sample chamber from the side.

00:03:05.650 --> 00:03:07.250
So we are selectively illuminating

00:03:07.250 --> 00:03:09.028
a thin volume section in the sample.

00:03:09.028 --> 00:03:10.570
And then the throo-ess-ance
that is emitted

00:03:10.570 --> 00:03:14.050
by this thin section is
imaged with a commercial

00:03:14.050 --> 00:03:15.610
light field detection
subsystem, oriented at

00:03:15.610 --> 00:03:17.580
right angle to this incidence light sheet.

00:03:17.580 --> 00:03:19.500
So we have this textual objective

00:03:19.500 --> 00:03:21.641
and then a camera further up in that arm,

00:03:21.641 --> 00:03:23.765
that takes a snapshot of that plane,

00:03:23.765 --> 00:03:25.370
of that thin section.

00:03:25.370 --> 00:03:28.250
And so, that makes this
technique a very fast imaging

00:03:28.250 --> 00:03:30.230
technique because, with one snapshot,

00:03:30.230 --> 00:03:31.860
we can capture millions of volume elements

00:03:31.860 --> 00:03:33.210
across this plane.

00:03:33.210 --> 00:03:35.360
And we can do rapid 3-D imaging

00:03:35.360 --> 00:03:36.530
by just moving the light-sheet through

00:03:36.530 --> 00:03:37.800
the sample, step-by-step.

00:03:37.800 --> 00:03:39.475
Just recording the image sequence.

00:03:39.475 --> 00:03:40.810
And so then,

00:03:40.810 --> 00:03:41.990
we're basically just limited by the

00:03:41.990 --> 00:03:43.834
speed of the detector, the camera,

00:03:43.834 --> 00:03:46.177
can get gigavoxels per second with

00:03:46.177 --> 00:03:48.300
modern eh-see-muss cameras.

00:03:48.300 --> 00:03:50.254
But, it's also a very gentle technique.

00:03:50.254 --> 00:03:52.200
And so it's gentle because we are

00:03:52.200 --> 00:03:53.835
only sending light exactly to the

00:03:53.835 --> 00:03:55.060
part of the sample that we're taking

00:03:55.060 --> 00:03:56.420
the image off at any point in time.

00:03:56.420 --> 00:03:58.107
We're not sending light
to all the focus regions.

00:03:58.107 --> 00:04:02.180
We are not breaching or
damaging parts out of focus.

00:04:02.180 --> 00:04:03.150
And so this combination is

00:04:03.150 --> 00:04:04.800
really important for our work.

00:04:04.800 --> 00:04:06.470
And so now, I'd like to be a little

00:04:06.470 --> 00:04:08.120
more quantitative about the imaging

00:04:08.120 --> 00:04:08.990
experiments I just showed you on the

00:04:08.990 --> 00:04:10.200
first two slides.

00:04:10.200 --> 00:04:11.305
And as a reference,

00:04:11.305 --> 00:04:15.860
just basically embed these experiences

00:04:15.860 --> 00:04:18.360
in a parameter space that
we would care about a lot.

00:04:18.360 --> 00:04:19.840
In most of these live-imaging experiments,

00:04:19.840 --> 00:04:21.697
we are looking at the
size of the sample image,

00:04:21.697 --> 00:04:23.630
the duration for which we can image it,

00:04:23.630 --> 00:04:25.349
and the spacial temporal
resolution we can achieve.

00:04:25.349 --> 00:04:27.007
And as a reference point,

00:04:27.007 --> 00:04:29.499
just connecting to Dana's talk, again,

00:04:29.499 --> 00:04:31.284
I think Dana made this nice point that,

00:04:31.284 --> 00:04:34.060
if you use a state-of-the-art
spinning disc

00:04:34.060 --> 00:04:36.150
confocal microscope, a very powerful,

00:04:36.150 --> 00:04:39.136
fast imaging device, you can still kind of

00:04:39.136 --> 00:04:41.280
do this experiment of tracking cells

00:04:41.280 --> 00:04:43.520
in a se-li-ance embryo,

00:04:43.520 --> 00:04:44.950
but only up to a certain point of time.

00:04:44.950 --> 00:04:46.634
If you go too far into development,

00:04:46.634 --> 00:04:48.884
the embryo moves too quickly
that you can't follow

00:04:48.884 --> 00:04:50.039
the cells anymore.

00:04:50.039 --> 00:04:51.578
But, this is kind of like at the limit

00:04:51.578 --> 00:04:53.132
of the performance of the system

00:04:53.132 --> 00:04:54.780
and so that puts us somewhere here

00:04:54.780 --> 00:04:56.386
in this parameter space.

00:04:56.386 --> 00:04:58.054
And I'm sure you've heard of the work

00:04:58.054 --> 00:05:01.850
of my colleague, Eric Betzig at Janelia,

00:05:01.850 --> 00:05:03.480
who is also using light-sheet microscopy

00:05:03.480 --> 00:05:07.810
to push spacial resolution
in these experiments.

00:05:07.810 --> 00:05:09.960
And so he's able to get these really

00:05:09.960 --> 00:05:11.845
dramatic improvements in
spacial resolution of more than

00:05:11.845 --> 00:05:14.271
a factor of 10, same-model system.

00:05:14.271 --> 00:05:16.080
And so using these really, really thin

00:05:16.080 --> 00:05:17.680
light sheets, either using bessel beams,

00:05:17.680 --> 00:05:20.240
or lattice light-sheet techniques.

00:05:20.240 --> 00:05:22.339
So for us the challenge
has been a different one.

00:05:22.339 --> 00:05:25.150
We wanted to stay at
the single-cell level,

00:05:25.150 --> 00:05:26.300
but scale this up to a much,

00:05:26.300 --> 00:05:28.138
much larger model system.

00:05:28.138 --> 00:05:29.980
So for the Drosophila we were imaging

00:05:29.980 --> 00:05:32.040
at 1,000 times larger volume.

00:05:32.040 --> 00:05:33.709
We still want to follow
cells at the same speed,

00:05:33.709 --> 00:05:35.197
at the same volume rate.

00:05:35.197 --> 00:05:37.658
And then, if you push it
into the functional realm,

00:05:37.658 --> 00:05:41.170
we need to image, not only
at 1,000 times larger volume,

00:05:41.170 --> 00:05:43.292
but also, image that
volume at 100 fold faster

00:05:43.292 --> 00:05:44.623
volume rate.

00:05:44.623 --> 00:05:47.170
So, this is where light-sheet microscopy

00:05:47.170 --> 00:05:49.040
has been really helpful to us.

00:05:49.040 --> 00:05:50.898
But if you look at these different

00:05:50.898 --> 00:05:53.070
data points in this plot,

00:05:53.070 --> 00:05:55.510
there's one thing that's
really unsatisfying about it.

00:05:55.510 --> 00:05:56.544
And that's...

00:05:56.544 --> 00:05:58.040
The implication here is that

00:05:58.040 --> 00:05:59.791
there's seemingly this trade-off.

00:05:59.791 --> 00:06:02.620
You know, you can either
image a fairly small

00:06:02.620 --> 00:06:03.955
sample at very high resolution,

00:06:03.955 --> 00:06:05.871
or a fairly large volume,

00:06:05.871 --> 00:06:08.904
at the cellular level, very quickly.

00:06:08.904 --> 00:06:11.440
But you can't do both at the same time.

00:06:11.440 --> 00:06:14.018
And so I think what we
really want is a technique

00:06:14.018 --> 00:06:16.437
that allows us to image
a fairly large volume,

00:06:16.437 --> 00:06:19.567
like the brain of a larva zebrafish,

00:06:19.567 --> 00:06:21.640
over long periods of time,

00:06:22.687 --> 00:06:24.490
and over the mental time scales,

00:06:24.490 --> 00:06:27.630
during behaviors, both at high spatial and

00:06:27.630 --> 00:06:29.515
high temporal resolution.

00:06:29.515 --> 00:06:32.470
And so, I'd like to show you

00:06:32.470 --> 00:06:34.570
first how we can get to this part in the

00:06:34.570 --> 00:06:35.610
parameter space.

00:06:35.610 --> 00:06:37.937
And so the goal here
is really to find a way

00:06:37.937 --> 00:06:40.349
to add this fourth parameter.

00:06:40.349 --> 00:06:42.310
Three out of the four parameters,

00:06:42.310 --> 00:06:43.190
we're kind of happy with.

00:06:43.190 --> 00:06:45.598
We have the large volume,
we have the high speed.

00:06:45.598 --> 00:06:48.130
But what's missing is
the spatial resolution.

00:06:48.130 --> 00:06:50.466
So how can we add spatial
resolution to this

00:06:50.466 --> 00:06:54.000
mix without trading-off, sacrificing

00:06:54.000 --> 00:06:55.110
any other parameter?

00:06:56.530 --> 00:06:59.150
So, let's look at the challenge first.

00:06:59.150 --> 00:07:00.840
What's the problem we need to solve?

00:07:00.840 --> 00:07:02.160
The reason why spatial resolution

00:07:02.160 --> 00:07:03.780
is not as high as you'd want it to be

00:07:03.780 --> 00:07:06.380
in these experiments, is that we suffer,

00:07:06.380 --> 00:07:08.580
in many light practice groups, in fact,

00:07:08.580 --> 00:07:10.525
from anisotropic spatial resolution.

00:07:10.525 --> 00:07:11.720
So the problem here is that,

00:07:11.720 --> 00:07:13.150
we are not really collecting all

00:07:13.150 --> 00:07:15.523
of the light that is
provided by our object.

00:07:15.523 --> 00:07:17.718
So we have a limited numerical aperture,

00:07:17.718 --> 00:07:20.350
only collecting light on a certain,

00:07:20.350 --> 00:07:21.410
small angular range.

00:07:21.410 --> 00:07:24.246
And so this anisotrophy
and sampling information,

00:07:24.246 --> 00:07:26.781
which starts in the anisotrophy,

00:07:26.781 --> 00:07:28.420
in the way in which we form the image,

00:07:28.420 --> 00:07:31.360
and represent the samples,

00:07:31.360 --> 00:07:33.379
we have typically much
lower axel resolution.

00:07:33.379 --> 00:07:35.948
That lateral resolution as
Dana pointed out earlier.

00:07:35.948 --> 00:07:38.560
So, ideally what you'd want to have

00:07:38.560 --> 00:07:42.197
is axle resolution be as
good as lateral resolution,

00:07:42.197 --> 00:07:44.600
so that would be a big step forward.

00:07:44.600 --> 00:07:45.860
I mean, light-sheet microscopy often has

00:07:45.860 --> 00:07:47.999
a factor of 10 that you're talking about.

00:07:47.999 --> 00:07:49.270
And then, on top of that,

00:07:49.270 --> 00:07:50.710
it would be biologically
much more meaningful

00:07:50.710 --> 00:07:51.950
because we are treating
all of the dimensions

00:07:51.950 --> 00:07:54.110
the same way, which makes much more sense.

00:07:55.510 --> 00:07:57.490
So, what we need to find, now,

00:07:57.490 --> 00:07:59.877
is a way to solve this problem without

00:07:59.877 --> 00:08:02.700
compromising any of the other
aspects of our performance.

00:08:02.700 --> 00:08:03.610
Because for our experiments,

00:08:03.610 --> 00:08:05.020
it's really important that we

00:08:05.020 --> 00:08:06.730
can maintain the high
temporal resolutions,

00:08:06.730 --> 00:08:08.867
we can still stay in the
realm of calcium imaging,

00:08:08.867 --> 00:08:11.280
maybe even push this forward
towards watt-age imaging

00:08:11.280 --> 00:08:12.113
in the future.

00:08:12.113 --> 00:08:13.930
We really don't want to touch speed

00:08:13.930 --> 00:08:17.300
and still get imaging at
the whole-brain level.

00:08:18.290 --> 00:08:19.710
So the way we can do this,

00:08:21.150 --> 00:08:23.364
is we combine light-sheet imaging

00:08:23.364 --> 00:08:26.150
with another fairly old concept.

00:08:26.150 --> 00:08:27.690
And that's the concept
of multiview imaging.

00:08:27.690 --> 00:08:31.890
So what we do in this approach is that,

00:08:31.890 --> 00:08:35.834
counter-intuitively, the
first step is that we don't

00:08:35.834 --> 00:08:38.690
solve this problem of
anisotropic resolution.

00:08:38.690 --> 00:08:40.124
We simply accept the fact that,

00:08:40.124 --> 00:08:41.750
let's say you have a point-like object,

00:08:41.750 --> 00:08:43.520
the image that we get is ellipse,

00:08:43.520 --> 00:08:45.666
so to store it at res-in-tay-shun.

00:08:45.666 --> 00:08:48.450
So we have low-resolution
along the axle component,

00:08:48.450 --> 00:08:50.090
high resolution laterally.

00:08:50.090 --> 00:08:51.390
But then in the next step what we do,

00:08:51.390 --> 00:08:55.443
is we rotate the sample by
90 degrees to the microscope.

00:08:55.443 --> 00:08:57.260
And so we caught a second view

00:08:57.260 --> 00:08:58.452
of the same scene.

00:08:58.452 --> 00:08:59.958
And so now, we've permuted

00:08:59.958 --> 00:09:01.530
the dimensions along which resolutions

00:09:01.530 --> 00:09:03.040
high and low, respectively, and

00:09:03.040 --> 00:09:04.920
taken together, across these two images,

00:09:04.920 --> 00:09:07.330
we have actually almost
all of the frequency

00:09:07.330 --> 00:09:09.720
content that we're
interested in of our sample.

00:09:09.720 --> 00:09:11.610
And we basically just have to register

00:09:11.610 --> 00:09:14.100
these two views, combine
them, for example,

00:09:14.100 --> 00:09:15.350
for a process called
multiview deconvolution,

00:09:15.350 --> 00:09:16.430
and we have this neo-isotropic
spatial resolution.

00:09:18.693 --> 00:09:22.280
So, that would be a
powerful way to improve

00:09:22.280 --> 00:09:23.880
spatial resolution
because we can just keep

00:09:23.880 --> 00:09:26.136
our microscope and the way in which

00:09:26.136 --> 00:09:28.838
we build our light sheets, the way it is.

00:09:28.838 --> 00:09:30.650
Basically, the main challenge that

00:09:30.650 --> 00:09:31.700
we have to solve now is to find a way

00:09:31.700 --> 00:09:34.490
to record these multiple
views at the same time.

00:09:34.490 --> 00:09:37.142
Then we haven't sacrificed
temporal resolution.

00:09:37.142 --> 00:09:40.370
And so, Raghav Chhetetri
post-doc in my lab,

00:09:40.370 --> 00:09:42.390
addressed this problem,
and built a microscope

00:09:42.390 --> 00:09:43.448
that can do that.

00:09:43.448 --> 00:09:45.234
And so yes, the idea.

00:09:45.234 --> 00:09:47.520
The arrangement is a little bit more

00:09:47.520 --> 00:09:48.724
complex than this basic idea.

00:09:48.724 --> 00:09:49.740
As it describes,

00:09:49.740 --> 00:09:52.070
we don't only have two
views of the sample.

00:09:52.070 --> 00:09:53.422
We actually have four opposing objectives,

00:09:53.422 --> 00:09:55.716
so that gives us four following views,

00:09:55.716 --> 00:09:57.444
which simply means that we can scale

00:09:57.444 --> 00:09:59.650
this idea up to larger specimens that

00:09:59.650 --> 00:10:00.981
are not entirely transparent.

00:10:00.981 --> 00:10:02.860
So for for Drosophila and zebrafish,

00:10:02.860 --> 00:10:03.693
it's actually very helpful.

00:10:03.693 --> 00:10:06.505
Also for mouse embryos
that we are studying.

00:10:06.505 --> 00:10:08.350
But now, the problem is, if we

00:10:08.350 --> 00:10:10.882
sent in four light
sheets at the same time,

00:10:10.882 --> 00:10:12.310
from all these four objectives,

00:10:12.310 --> 00:10:13.770
and then take four images,

00:10:13.770 --> 00:10:15.650
light-filled images of these objectives,

00:10:15.650 --> 00:10:17.144
we've violated a fundamental concept

00:10:17.144 --> 00:10:21.237
of the optical sectioning concept in

00:10:21.237 --> 00:10:22.070
light-sheet microscopy.

00:10:22.070 --> 00:10:24.150
So we've actually sent in light

00:10:24.150 --> 00:10:26.850
in a way that now illuminates out-of-focus

00:10:26.850 --> 00:10:28.950
structures with respect to the respective

00:10:28.950 --> 00:10:30.070
other light sheets.

00:10:30.070 --> 00:10:31.740
So we get out-of-focus light,

00:10:31.740 --> 00:10:33.640
we basically degrade the image quality

00:10:34.740 --> 00:10:36.290
by doing this at the same time.

00:10:37.300 --> 00:10:39.590
So the way we can solve this is

00:10:39.590 --> 00:10:41.450
that we don't actually use light sheets

00:10:41.450 --> 00:10:42.857
in our light-sheet microscopes.

00:10:42.857 --> 00:10:45.020
What we do is, we send in a very,

00:10:45.020 --> 00:10:46.671
very thin pencil beam.

00:10:46.671 --> 00:10:49.160
And so then, if you take this pencil beam

00:10:49.160 --> 00:10:51.357
and you scan it up and down very quickly,

00:10:51.357 --> 00:10:53.149
across your plane of interest,

00:10:53.149 --> 00:10:54.780
and you just keep the camera shot open,

00:10:54.780 --> 00:10:56.680
you get the equivalent of a light sheet.

00:10:56.680 --> 00:10:58.410
And so we have a scanned light sheet.

00:10:59.968 --> 00:11:02.713
And so, if you use this concept now,

00:11:02.713 --> 00:11:05.833
and implement it in a way that...

00:11:05.833 --> 00:11:08.787
The beams that come in
from these different views

00:11:08.787 --> 00:11:11.480
are slightly offset in space.

00:11:11.480 --> 00:11:12.680
So we keep them maybe a couple of tenths

00:11:12.680 --> 00:11:14.980
of microns apart, and then we scan them

00:11:14.980 --> 00:11:17.270
across their respective
planes at a constant pace,

00:11:17.270 --> 00:11:18.903
so they maintain that
same constant distance,

00:11:18.903 --> 00:11:21.814
so they never cross their
paths in real space.

00:11:21.814 --> 00:11:23.559
Then all we need to do is match this up

00:11:23.559 --> 00:11:26.264
with a set of confocal line detectors,

00:11:26.264 --> 00:11:28.610
that really only detect the light

00:11:28.610 --> 00:11:30.520
that comes from the beam and blocks

00:11:30.520 --> 00:11:32.270
out the light that comes from the

00:11:32.270 --> 00:11:33.610
ee-phon-or-al beam that is
slightly offset in space.

00:11:33.610 --> 00:11:35.720
It's just hitting the
detector at the wrong spot.

00:11:35.720 --> 00:11:38.017
Not where the rolling shut
is at that point in time.

00:11:38.017 --> 00:11:39.590
We have the same place offset

00:11:39.590 --> 00:11:41.094
in our confocal line detectors.

00:11:41.094 --> 00:11:43.845
Everything is matched up and synchronized,

00:11:43.845 --> 00:11:47.260
and now we can scan four
views at the same time,

00:11:47.260 --> 00:11:49.009
without any signal crosstalk.

00:11:49.009 --> 00:11:50.889
So that's the key idea in what we

00:11:50.889 --> 00:11:53.320
call the isotropic multiview
light-sheet microscope.

00:11:53.320 --> 00:11:54.153
The ay-si-you microscope.

00:11:54.153 --> 00:11:55.670
And so here's the way that we can

00:11:55.670 --> 00:11:56.820
get with this approach.

00:11:58.240 --> 00:12:01.270
Again, the low anasotropic
resolution in the

00:12:01.270 --> 00:12:02.710
contributing views, but if you

00:12:02.710 --> 00:12:04.800
combine these views into one single image,

00:12:04.800 --> 00:12:06.540
this is a multiview deconvolved image,

00:12:06.540 --> 00:12:07.900
we now have isotropic resolution.

00:12:07.900 --> 00:12:09.630
We can turn this in any way.

00:12:09.630 --> 00:12:13.528
And you don't have any
perceived difference in

00:12:13.528 --> 00:12:14.510
spatial resolution.

00:12:14.510 --> 00:12:18.306
This is a sheet cAMP
expressing drosophila larva,

00:12:18.306 --> 00:12:20.714
chee-cAMP throughout the
entire nervous system.

00:12:20.714 --> 00:12:22.890
And so let me just zoom into this cluster

00:12:22.890 --> 00:12:24.300
of neurons so you can
actually see the impact

00:12:24.300 --> 00:12:25.884
on spatial resolution.

00:12:25.884 --> 00:12:27.510
So now the contributing views,

00:12:27.510 --> 00:12:29.980
we have one dimension along which,

00:12:29.980 --> 00:12:32.170
it's very hard to distinguish
these individual neurons.

00:12:32.170 --> 00:12:33.790
They're just blurring into each other.

00:12:33.790 --> 00:12:34.700
In the other set of views,

00:12:34.700 --> 00:12:37.170
there's a different dimension,
but the same problem.

00:12:37.170 --> 00:12:39.370
But then combining all this information

00:12:39.370 --> 00:12:41.617
into the IsoView construction,
we now have high resolution,

00:12:41.617 --> 00:12:45.950
from any view along the
X, Y, Z in the axis.

00:12:45.950 --> 00:12:48.319
And so we basically restored
cellular resolution, even in

00:12:48.319 --> 00:12:51.360
these deeper regions
of the nervous system.

00:12:51.360 --> 00:12:52.750
And so overall we find we have about

00:12:52.750 --> 00:12:54.370
four nanometers spatial resolution.

00:12:55.509 --> 00:12:57.730
And so, because we haven't sacrificed

00:12:57.730 --> 00:12:59.078
temporal resolution, we can now do these

00:12:59.078 --> 00:13:01.000
types of functional imaging experiments.

00:13:01.000 --> 00:13:03.350
For example, imaging at
the whole animal level,

00:13:03.350 --> 00:13:05.340
the entire drosophila larva expressing

00:13:05.340 --> 00:13:07.190
sheet cAMP, during motor behaviors.

00:13:07.190 --> 00:13:08.930
You can see forward/backward crawling.

00:13:08.930 --> 00:13:10.506
And then, sort of concurrent
calcium activity that is

00:13:10.506 --> 00:13:14.160
sort of orchestrating this behavior

00:13:14.160 --> 00:13:15.142
in the ventral nerve course,

00:13:15.142 --> 00:13:17.301
you see these waves in the vee-and-see

00:13:17.301 --> 00:13:22.190
and sort of a similar
context in the zebrafish.

00:13:22.190 --> 00:13:23.760
So we have a larva zebrafish here,

00:13:23.760 --> 00:13:25.950
that's executing different
types of swimming behaviors.

00:13:25.950 --> 00:13:27.590
And you can see this
activity in the hind brain

00:13:27.590 --> 00:13:29.526
and the spinal cord
during these behaviors.

00:13:29.526 --> 00:13:32.580
And so this is imaged at two
hertz and this is at one hertz.

00:13:32.580 --> 00:13:33.860
And it's just rotating the fish here.

00:13:33.860 --> 00:13:35.840
So you can see, there's
no change in resolution

00:13:35.840 --> 00:13:37.900
as we rotate the volume.

00:13:38.760 --> 00:13:40.130
So I think live imaging is where this

00:13:40.130 --> 00:13:41.970
really unfolds its full potential.

00:13:41.970 --> 00:13:43.900
But you can, of course, also
use it for structural imaging.

00:13:43.900 --> 00:13:45.530
Experiments with fixed samples.

00:13:45.530 --> 00:13:48.199
And so the main gain is that
you get isotropic resolution

00:13:48.199 --> 00:13:50.235
and you can image it very quickly.

00:13:50.235 --> 00:13:52.970
So this is now an
expanded drosophila brain,

00:13:52.970 --> 00:13:54.549
combined with the expansion microscopy.

00:13:54.549 --> 00:13:58.880
So that makes it about
two millimeters long,

00:13:58.880 --> 00:14:00.190
along each side.

00:14:00.190 --> 00:14:01.618
And so within about 15 minutes,

00:14:01.618 --> 00:14:04.850
we get then 100 nanometer
isotropic spatial resolution

00:14:04.850 --> 00:14:05.960
across the brain.

00:14:05.960 --> 00:14:08.250
And there's a sparse pattern of fruitless

00:14:08.250 --> 00:14:09.890
neurons that are labeled here.

00:14:09.890 --> 00:14:10.723
And so if you zoom in,

00:14:10.723 --> 00:14:12.650
you can see the fine structural details,

00:14:12.650 --> 00:14:14.661
which can aid connectomics-types analysis,

00:14:14.661 --> 00:14:16.970
in relatively high throughput,

00:14:16.970 --> 00:14:18.520
with these imaging experiments.

00:14:19.750 --> 00:14:21.410
So let me just summarize this.

00:14:21.410 --> 00:14:23.170
We have basically an improvement of

00:14:23.170 --> 00:14:24.670
about 10-fold in resolution,

00:14:24.670 --> 00:14:26.503
without sacrificing
speed and field of view.

00:14:26.503 --> 00:14:29.310
And in more absolute quantitative terms,

00:14:29.310 --> 00:14:31.250
that means 400 nanometers
spatial resolution,

00:14:31.250 --> 00:14:34.045
system resolution, at
sub-second time scales

00:14:34.045 --> 00:14:37.230
for the volume of about 800 microm cubed.

00:14:37.230 --> 00:14:38.870
And so I just showed you very short

00:14:38.870 --> 00:14:40.960
sequences from actually
longer imaging experiments.

00:14:40.960 --> 00:14:42.710
We've imaged these
samples for hours to days

00:14:42.710 --> 00:14:43.990
in each of these cases,

00:14:43.990 --> 00:14:45.230
so you can use it under physiological

00:14:45.230 --> 00:14:47.428
conditions in this parameter space.

00:14:47.428 --> 00:14:49.589
But one thing I'd like
to point out is that,

00:14:49.589 --> 00:14:52.324
intentionally, I set the
system resolution here.

00:14:52.324 --> 00:14:55.790
Which means, this is the
performance we expect

00:14:55.790 --> 00:14:56.950
on ideal imaging conditions,

00:14:56.950 --> 00:14:59.090
if you have a fairly transparent sample.

00:14:59.090 --> 00:15:01.980
And unfortunately, most
of these we're looking at

00:15:01.980 --> 00:15:02.990
are far from transparent,

00:15:02.990 --> 00:15:05.410
and we end up in this realm of imaging

00:15:05.410 --> 00:15:07.780
relatively large specimens
for live-imaging,

00:15:07.780 --> 00:15:11.385
drosophila larva, zebrafish brain.

00:15:11.385 --> 00:15:13.635
They actually perturb the light that we

00:15:13.635 --> 00:15:16.550
need to use to rely on,
to do the measurement

00:15:16.550 --> 00:15:17.717
in the first place.

00:15:17.717 --> 00:15:19.870
And so this is a problem we need to solve.

00:15:19.870 --> 00:15:22.380
Because the way it impacts
our light shield microscope,

00:15:22.380 --> 00:15:23.810
is that because of the heterogeneity,

00:15:23.810 --> 00:15:25.180
the optical heterogeneity of the sample,

00:15:25.180 --> 00:15:28.900
so this toy model of this
cross section of, let's say,

00:15:28.900 --> 00:15:30.984
this drosophila larva.

00:15:30.984 --> 00:15:33.460
As the light sheets enter the sample,

00:15:33.460 --> 00:15:35.511
they are deviated from the light path

00:15:35.511 --> 00:15:37.553
to change their course.

00:15:37.553 --> 00:15:41.170
And so this can change
further inside the sample,

00:15:41.170 --> 00:15:42.730
depending on the optical properties,

00:15:42.730 --> 00:15:43.920
can change over time, you know,

00:15:43.920 --> 00:15:45.980
as optical properties change,
as the sample develops.

00:15:45.980 --> 00:15:48.247
And the same thing happens
in the detection process.

00:15:48.247 --> 00:15:49.620
We have increasing curvature of...

00:15:49.620 --> 00:15:51.780
The focal planes are not
really clean planes anymore.

00:15:51.780 --> 00:15:54.370
They get bent as a
function of this spatial

00:15:54.370 --> 00:15:56.150
location and a function of time.

00:15:56.150 --> 00:15:58.330
And so bottom line is that we lose this

00:15:58.330 --> 00:16:01.580
nice coplanarity that we rely on in the

00:16:01.580 --> 00:16:03.030
light-shield microscope.

00:16:03.030 --> 00:16:05.350
The light shield should be
coplane with the focal plane

00:16:05.350 --> 00:16:07.000
to get an in-focus image.

00:16:07.000 --> 00:16:08.200
That's not really the case anymore,

00:16:08.200 --> 00:16:10.050
and so we basically image out-of-focus,

00:16:10.050 --> 00:16:13.345
and we get low-resolution
and low image contrast.

00:16:13.345 --> 00:16:16.666
And so, Loiic Royer,
another post-doc in the lab,

00:16:16.666 --> 00:16:19.311
addressed this problem
in the following way.

00:16:19.311 --> 00:16:22.170
Basically, developed, first of all...

00:16:22.170 --> 00:16:24.780
So there are two components
to this solution.

00:16:24.780 --> 00:16:26.470
First of all, we need a microscope

00:16:26.470 --> 00:16:28.210
that has access to the degrees of freedom

00:16:28.210 --> 00:16:29.940
that we need to bend
things back into shape.

00:16:29.940 --> 00:16:31.080
We need to be able to rotate

00:16:31.080 --> 00:16:32.560
and translate the light
sheets and the focal

00:16:32.560 --> 00:16:34.550
planes so we can actually fix the problem,

00:16:34.550 --> 00:16:36.817
if you know what the
problem is geometrically.

00:16:36.817 --> 00:16:39.610
And so the second part is
that we need to measure,

00:16:39.610 --> 00:16:40.490
take the right measurements.

00:16:40.490 --> 00:16:43.244
We have algorithms
deployed on the microscope

00:16:43.244 --> 00:16:46.115
that allow us to estimate image quality

00:16:46.115 --> 00:16:49.090
as a function of changes in
these degrees of freedom.

00:16:49.090 --> 00:16:51.210
And basically, build a
model of this sampling in a

00:16:51.210 --> 00:16:52.940
background of the live-imaging experiment,

00:16:52.940 --> 00:16:55.070
to constantly improve in space and time,

00:16:55.070 --> 00:16:57.150
the spatial relationship
between focal planes

00:16:57.150 --> 00:16:58.370
and light sheets.

00:16:58.370 --> 00:16:59.430
And so with this combined,

00:16:59.430 --> 00:17:01.139
sort of adaptive imaging approach,

00:17:01.139 --> 00:17:03.635
we can now hand the experiment over

00:17:03.635 --> 00:17:06.440
to this real-time control layer,

00:17:06.440 --> 00:17:09.652
and basically have it
optimized in image quality.

00:17:09.652 --> 00:17:11.639
For example, in the zebrafish embryo

00:17:11.639 --> 00:17:13.302
that has the falling effect,

00:17:13.302 --> 00:17:15.374
if you look at different regions here,

00:17:15.374 --> 00:17:17.730
we're trying to track
the cells as they're from

00:17:17.730 --> 00:17:18.949
the nervous system.

00:17:18.949 --> 00:17:22.390
We can't really, with
all the adaptive imaging,

00:17:22.390 --> 00:17:24.810
follow cells in many parts of
the sample anymore, over time.

00:17:24.810 --> 00:17:26.490
Just, image quality degrades,

00:17:26.490 --> 00:17:28.160
and with the adaptive imaging approach,

00:17:28.160 --> 00:17:29.923
we can recover that high resolution.

00:17:29.923 --> 00:17:32.695
We can also use it in a
functional imaging context.

00:17:32.695 --> 00:17:36.130
So this is now a zebrafish larval brain.

00:17:37.470 --> 00:17:38.389
Again, I'm showing you the quality

00:17:38.389 --> 00:17:40.770
with the adaptive imaging engaged

00:17:40.770 --> 00:17:42.380
and with all this framework.

00:17:42.380 --> 00:17:43.796
And after some time of imaging,

00:17:43.796 --> 00:17:45.510
you can see how quality really

00:17:45.510 --> 00:17:47.160
degrades because as the brain is growing,

00:17:47.160 --> 00:17:48.580
the fish is actually growing.

00:17:48.580 --> 00:17:51.690
And we are changing the optical context

00:17:51.690 --> 00:17:54.440
and losing the ability
to really accurately

00:17:54.440 --> 00:17:57.286
measure activity at the
single-neuron level.

00:17:57.286 --> 00:17:59.945
And with that, I'm at the end.

00:17:59.945 --> 00:18:01.860
I'd just like to give you a quick outlook.

00:18:01.860 --> 00:18:04.145
We are now integrating these imaging tools

00:18:04.145 --> 00:18:05.780
with optical manipulation tools.

00:18:05.780 --> 00:18:07.270
We don't only want to
watch what's happening,

00:18:07.270 --> 00:18:09.360
we want to control what's
happening, manipulate it.

00:18:09.360 --> 00:18:10.938
And so particularly, with
a layer that allows us

00:18:10.938 --> 00:18:13.026
to classify behavior in real time,

00:18:13.026 --> 00:18:16.310
so that we can interact with
behavior at different stages,

00:18:16.310 --> 00:18:17.470
at different phases.

00:18:17.470 --> 00:18:20.930
And for example, control the
state that the network is in.

00:18:20.930 --> 00:18:22.524
Control, for example, motor behavior

00:18:22.524 --> 00:18:25.610
from forward-walking to
backward-walking and so on.

00:18:25.610 --> 00:18:27.230
And so that's the next stage now

00:18:27.230 --> 00:18:28.908
for this technology, for us.

00:18:28.908 --> 00:18:30.780
And so with that I'm
at the end of the talk,

00:18:30.780 --> 00:18:33.068
and just would like to
acknowledge, very briefly,

00:18:33.068 --> 00:18:35.559
Raghav Chhetri who built
the IsoView microscope,

00:18:35.559 --> 00:18:38.320
Leo Guignard who developed the
adaptive imaging framework,

00:18:38.320 --> 00:18:39.634
built a lot of the imaging,

00:18:39.634 --> 00:18:42.036
helped a lot with these
imaging experiments.

00:18:42.036 --> 00:18:45.140
And then we have a lot of
fantastic collaborators at Janelia

00:18:45.140 --> 00:18:47.370
that contributed a lot to the
work that I showed you here.

00:18:47.370 --> 00:18:49.553
And Misha Ahrens and Kristin
Branson, in particular,

00:18:49.553 --> 00:18:51.285
to whom I am very grateful.

00:18:51.285 --> 00:18:52.118
Alright.

00:18:52.118 --> 00:18:53.221
Thank you.

00:18:53.221 --> 00:18:55.791
(audience claps)

00:18:55.791 --> 00:18:59.291
(mellow electronic music)

