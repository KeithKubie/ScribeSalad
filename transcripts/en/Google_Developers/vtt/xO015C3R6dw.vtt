WEBVTT
Kind: captions
Language: en

00:00:05.300 --> 00:00:07.300
Fuller: So my name
is Alfred Fuller,

00:00:07.300 --> 00:00:08.868
and this is Matt Wilder,

00:00:08.868 --> 00:00:11.701
and we're gonna be talking
about how to get more 9's

00:00:11.701 --> 00:00:14.767
with the high replication
datastore.

00:00:14.767 --> 00:00:17.767
I'm a sophomore engineer on
the App Engine Datastore team,

00:00:17.767 --> 00:00:20.400
Wilder: And I am
a site reliability engineer

00:00:20.400 --> 00:00:22.400
on the App Engine team.

00:00:22.400 --> 00:00:24.400
My focus is distributed storage.

00:00:24.400 --> 00:00:26.400
So you may be asking yourself,

00:00:26.400 --> 00:00:28.400
"Site reliability--
What is that?"

00:00:28.400 --> 00:00:30.868
well, um, site reliability
is a position at Google

00:00:30.868 --> 00:00:34.300
whose focus is the performance
and reliability

00:00:34.300 --> 00:00:36.300
of Google services,

00:00:36.300 --> 00:00:38.901
so if you'd like to know
a little bit more about that,

00:00:38.901 --> 00:00:41.834
and what it's like running
App Engine in production,

00:00:41.834 --> 00:00:44.834
um, I recommend that you attend
Alan Green and Michael Handler's

00:00:44.834 --> 00:00:46.834
talk this afternoon, uh,

00:00:46.834 --> 00:00:48.834
"Life In App Engine Production."

00:00:48.834 --> 00:00:50.834
Fuller: And, uh, I can assume,
I think,

00:00:50.834 --> 00:00:53.501
that you're all interested
in the datastore in general,

00:00:53.501 --> 00:00:56.501
and if that's true, you should
check out past I/O talks,

00:00:56.501 --> 00:00:58.501
name--specifically
the ones listed here

00:00:58.501 --> 00:01:00.501
to get a better understanding

00:01:00.501 --> 00:01:03.067
of how the datastore
works as a whole.

00:01:03.067 --> 00:01:05.067
Today, though,
we're gonna talk about--

00:01:05.067 --> 00:01:07.734
well, we're gonna give you a
brief overview of the datastore,

00:01:07.734 --> 00:01:09.734
uh, highlighting the common
infrastructure components

00:01:09.734 --> 00:01:11.400
that it actually uses,

00:01:11.400 --> 00:01:13.400
talk about the datastore
in production,

00:01:13.400 --> 00:01:15.400
highlighting specifically
common cases,

00:01:15.400 --> 00:01:18.400
uh, planned maintenance,
and unplanned events,

00:01:18.400 --> 00:01:20.400
then talk about
lessons learned, uh,

00:01:20.400 --> 00:01:23.067
from running the datastore
for over three years now.

00:01:23.067 --> 00:01:25.567
And then give you some tips
on how to, uh,

00:01:25.567 --> 00:01:28.067
better acclimate to
the high replication datastore,

00:01:28.067 --> 00:01:29.734
if you so wish.

00:01:29.734 --> 00:01:31.400
So the master/slave--

00:01:31.400 --> 00:01:33.901
um, so the datastore comes
in two flavors now--

00:01:33.901 --> 00:01:36.901
the master/slave datastore
is what we launched with

00:01:36.901 --> 00:01:38.567
in April of 2008.

00:01:38.567 --> 00:01:41.567
It uses asynchronous replication
from a master to a slave,

00:01:41.567 --> 00:01:44.567
uh, and all--
since it has a master,

00:01:44.567 --> 00:01:47.567
all rights and reads
go to a master,

00:01:47.567 --> 00:01:49.567
and then they're replicated
to a slave.

00:01:49.567 --> 00:01:51.567
High replication,
on the other hand,

00:01:51.567 --> 00:01:53.567
uh, was released this January,

00:01:53.567 --> 00:01:55.567
and what it does
is it synchronously writes

00:01:55.567 --> 00:01:57.601
to greater than two replicas,

00:01:57.601 --> 00:02:00.567
and it has no master,
so it's true multi-homing,

00:02:00.567 --> 00:02:03.567
in that you can read and write
from any replica.

00:02:05.801 --> 00:02:07.801
Wilder: So, uh, in order
to understand, uh,

00:02:07.801 --> 00:02:09.467
how the datastore works,

00:02:09.467 --> 00:02:11.467
it's important to understand
what it's made of.

00:02:11.467 --> 00:02:13.467
So, uh, the datastore
is not actually

00:02:13.467 --> 00:02:16.467
one large monolithic
piece of software,

00:02:16.467 --> 00:02:18.467
but it's rather the culmination

00:02:18.467 --> 00:02:21.467
of many layers of distributed
storage architecture.

00:02:21.467 --> 00:02:23.467
Lots of these layers
are actually common

00:02:23.467 --> 00:02:25.467
to lots
of Google services.

00:02:25.467 --> 00:02:27.467
So, uh, at the top
we have the datastore,

00:02:27.467 --> 00:02:29.467
which you're all probably
familiar with.

00:02:29.467 --> 00:02:31.501
Um, it provides
a schemeless storage

00:02:31.501 --> 00:02:33.133
to App Engine applications,

00:02:33.133 --> 00:02:35.968
and provides, uh, arguably,
one of the most advanced

00:02:35.968 --> 00:02:39.334
query engines of any distributed
storage database out there.

00:02:39.334 --> 00:02:42.701
So, uh, the datastore stores
its data directly in megastore,

00:02:42.701 --> 00:02:46.234
um, so everything I'm gonna talk
about this layer and below

00:02:46.234 --> 00:02:49.567
is actually a common piece
of Google infrastructure.

00:02:49.567 --> 00:02:52.567
So megastore provides
a sort of SQL-like interface

00:02:52.567 --> 00:02:55.133
to distributed storage.

00:02:55.133 --> 00:02:58.367
Um, it, uh,
has a strict schema,

00:02:58.367 --> 00:03:00.834
so you define tables
and things like that,

00:03:00.834 --> 00:03:03.400
similar to an SQL database.

00:03:03.400 --> 00:03:06.434
Um, it provides
multi-row transactions

00:03:06.434 --> 00:03:09.267
that can actually span machines.

00:03:09.267 --> 00:03:12.901
Um, where it's different
than a standard SQL database,

00:03:12.901 --> 00:03:14.934
though, is its unit
of transactionality,

00:03:14.934 --> 00:03:17.067
which is centered
around an entity group.

00:03:17.067 --> 00:03:19.767
Um, Alfred will talk a little
bit more about that later.

00:03:19.767 --> 00:03:21.868
Um, megastore stores its data
in Bigtable,

00:03:21.868 --> 00:03:24.100
which many of you very well
may have heard of.

00:03:24.100 --> 00:03:28.734
Um, Bigtable is, um, a large
distributed key value datastore.

00:03:28.734 --> 00:03:31.968
Um, it's not a standard database
like you would think.

00:03:31.968 --> 00:03:34.968
Um, you can store data
in, uh, columns,

00:03:34.968 --> 00:03:37.634
and access them
via the row key only.

00:03:37.634 --> 00:03:39.734
It's a very important piece
of the datastore,

00:03:39.734 --> 00:03:41.601
we'll talk a little bit more
about it later,

00:03:41.601 --> 00:03:43.334
and it's widely used
at Google.

00:03:43.334 --> 00:03:46.334
Um, at the bottom, uh,
Bigtable stores its data

00:03:46.334 --> 00:03:49.300
in Google's Next Generation
distributed file system,

00:03:49.300 --> 00:03:51.701
which is our successor
to GFS.

00:03:51.701 --> 00:03:53.901
Fuller: So you might
be asking yourself,

00:03:53.901 --> 00:03:55.400
"What's an entity group?"

00:03:55.400 --> 00:03:57.267
Because up until
the high replication datastore,

00:03:57.267 --> 00:03:59.200
you didn't really have to care
that much.

00:03:59.200 --> 00:04:03.067
Um, uh, what it is, is it's
a logical grouping of entities

00:04:03.067 --> 00:04:04.934
through a parent/child
key relationship.

00:04:04.934 --> 00:04:08.400
And how it functions is,
it's a unit of transactionality,

00:04:08.400 --> 00:04:11.334
as Matt said, so transactions
can only read and write

00:04:11.334 --> 00:04:12.968
to entities in
a single entity group.

00:04:12.968 --> 00:04:14.801
So if I wanted
to change entities

00:04:14.801 --> 00:04:16.434
in the blue entity group

00:04:16.434 --> 00:04:18.434
and entities
in the green entity group,

00:04:18.434 --> 00:04:20.434
there's no way
to do that atomically.

00:04:20.434 --> 00:04:23.434
But if I want to do it just in
the blue or just in the green,

00:04:23.434 --> 00:04:25.434
then you can perform
atomic transactions on those.

00:04:25.434 --> 00:04:27.434
Um, and more importantly for
the high replication datastore

00:04:27.434 --> 00:04:29.067
is the unit of consistency.

00:04:29.067 --> 00:04:31.467
So entity groups enforce
strong serial consistency,

00:04:31.467 --> 00:04:34.534
so what you, uh, what you get--
or what you put,

00:04:34.534 --> 00:04:37.634
you will always get after--
uh, after that put,

00:04:37.634 --> 00:04:39.601
and you will never see
part of a transaction.

00:04:39.601 --> 00:04:41.667
You will either see
all of a transaction,

00:04:41.667 --> 00:04:43.434
or none of a transaction.

00:04:43.434 --> 00:04:47.334
Um, so here's an example
of entities

00:04:47.334 --> 00:04:50.701
that are arranged in
a parent/child relationship.

00:04:50.701 --> 00:04:53.567
So we have users,
we have photos,

00:04:53.567 --> 00:04:56.267
and a child entity under photos
of comments,

00:04:56.267 --> 00:04:57.534
so the photo owns
those comments,

00:04:57.534 --> 00:04:59.534
their comment on the photos.

00:04:59.534 --> 00:05:02.467
Uh, it's probably created
by the users.

00:05:02.467 --> 00:05:04.133
Uh, and then we have documents

00:05:04.133 --> 00:05:06.434
and, uh, revision history
for those documents,

00:05:06.434 --> 00:05:08.767
and comments on those documents,
and a blog post,

00:05:08.767 --> 00:05:10.934
which is like a combination
of photos and documents.

00:05:10.934 --> 00:05:14.334
I'm sorry--picture--yeah,
I said that right--cool.

00:05:14.334 --> 00:05:17.801
Uh, and has comments
on those, as well.

00:05:17.801 --> 00:05:20.534
Um, so if we look at the entity
groups that are here,

00:05:20.534 --> 00:05:22.534
we can see that there's these,
uh, boundaries

00:05:22.534 --> 00:05:24.334
that are imposed
by these entity groups,

00:05:24.334 --> 00:05:26.200
so you can operate
on the revision history

00:05:26.200 --> 00:05:28.634
of a document atomically, um,

00:05:28.634 --> 00:05:31.567
but if you wanted to change
a photo and a document

00:05:31.567 --> 00:05:33.300
at the same time,

00:05:33.300 --> 00:05:36.167
you'd actually have to do
two transactions to do that.

00:05:36.167 --> 00:05:38.701
So there's some limitations
besides just these boundaries

00:05:38.701 --> 00:05:40.334
on entity groups, um,

00:05:40.334 --> 00:05:42.267
the biggest of which
is a throughput limitation,

00:05:42.267 --> 00:05:44.267
so we say that you can get
at least one write per second.

00:05:44.267 --> 00:05:46.267
In practice,
in high replication datastore,

00:05:46.267 --> 00:05:48.267
you can get, uh, five to ten.

00:05:48.267 --> 00:05:51.400
And what happens is
if five writes

00:05:51.400 --> 00:05:53.100
come in all at the same time,

00:05:53.100 --> 00:05:55.133
four of 'em die with
a concurrency exception

00:05:55.133 --> 00:05:57.968
and one of 'em gets through,
so this is--it's rate limits,

00:05:57.968 --> 00:06:01.501
uh, how quickly you can write
to these entity groups.

00:06:01.501 --> 00:06:03.501
However, it's important
to keep in mind

00:06:03.501 --> 00:06:05.901
that a write per second does not
mean an entity per second.

00:06:05.901 --> 00:06:08.000
If you use batch puts
and transactions,

00:06:08.000 --> 00:06:09.667
those all count
as a single write,

00:06:09.667 --> 00:06:12.467
so you can get high entities
per second throughput

00:06:12.467 --> 00:06:14.467
if you, um, fan in your writes

00:06:14.467 --> 00:06:16.467
and do 'em in batches.

00:06:16.467 --> 00:06:18.467
Another thing
it's important to note

00:06:18.467 --> 00:06:21.133
is that these can be arbitrarily
large groups--

00:06:21.133 --> 00:06:23.033
groupings of entities.

00:06:23.033 --> 00:06:25.067
As Matt said, uh,

00:06:25.067 --> 00:06:28.234
entity groups
can span multiple machines

00:06:28.234 --> 00:06:30.934
and still enforce
that transactionality,

00:06:30.934 --> 00:06:33.400
um, so we actually
have entity groups

00:06:33.400 --> 00:06:36.000
with tens of millions
of entities in 'em,

00:06:36.000 --> 00:06:38.300
and it's no degradation
to performance.

00:06:38.300 --> 00:06:41.634
So here's another outline
of the same entities,

00:06:41.634 --> 00:06:43.667
just, uh, arranged
slightly differently,

00:06:43.667 --> 00:06:45.701
uh, taking into consideration

00:06:45.701 --> 00:06:47.701
the limitations
of the entity group.

00:06:47.701 --> 00:06:49.701
In this case, I've grouped
all of the comments

00:06:49.701 --> 00:06:51.701
that a user makes
under the user,

00:06:51.701 --> 00:06:53.367
so it's in his entity group.

00:06:53.367 --> 00:06:56.367
And if I show you the entity
group, uh, boundaries here,

00:06:56.367 --> 00:06:58.734
you can see that, um, blog posts

00:06:58.734 --> 00:07:00.968
are separate from comments,

00:07:00.968 --> 00:07:03.634
are separate from documents,
are separate from photos.

00:07:03.634 --> 00:07:06.834
And the reason why this grouping
may be a better grouping,

00:07:06.834 --> 00:07:08.667
given the limitations
of entity groups,

00:07:08.667 --> 00:07:10.767
is that it's unlikely
for a user

00:07:10.767 --> 00:07:14.267
to write to a comment greater
than one comment per second,

00:07:14.267 --> 00:07:16.534
while a blog post,
if it gets popular,

00:07:16.534 --> 00:07:19.567
or, you know,
uh, someone tweets it,

00:07:19.567 --> 00:07:22.601
uh, could spike
in the comments,

00:07:22.601 --> 00:07:25.267
um, and that--at those points,

00:07:25.267 --> 00:07:27.634
you probably want to have
a higher write rate

00:07:27.634 --> 00:07:29.667
than one entity per second.

00:07:29.667 --> 00:07:32.801
So speaking of consistency, um,

00:07:32.801 --> 00:07:35.000
this is a very important thing
to understand

00:07:35.000 --> 00:07:37.000
about the difference
between the high replication

00:07:37.000 --> 00:07:38.667
and the master/slave datastore--

00:07:38.667 --> 00:07:41.133
um, pretty much, there's only
really one difference,

00:07:41.133 --> 00:07:43.167
and this is, uh,
the eventual consistency

00:07:43.167 --> 00:07:44.934
for non-ancestor queries.

00:07:44.934 --> 00:07:46.934
These are queries
where the entity group

00:07:46.934 --> 00:07:48.601
is not known ahead of time,

00:07:48.601 --> 00:07:50.601
because the query spans
multiple entity groups,

00:07:50.601 --> 00:07:53.734
so there's no way to enforce
that strong serial consistency

00:07:53.734 --> 00:07:55.334
that an entity group provides.

00:07:55.334 --> 00:07:58.501
An example of
a non-ancestor query,

00:07:58.501 --> 00:08:01.567
um, is "Select star From Comment

00:08:01.567 --> 00:08:04.667
where user I.D. equals user.Id."

00:08:04.667 --> 00:08:06.634
This is what you
would have to use

00:08:06.634 --> 00:08:08.634
in that first grouping
of entities

00:08:08.634 --> 00:08:10.634
to find out all the comments
that a user has made.

00:08:10.634 --> 00:08:13.267
However, in the second
grouping of entities,

00:08:13.267 --> 00:08:15.267
you can use this, uh, query,

00:08:15.267 --> 00:08:17.334
which is
"Select star From Comment

00:08:17.334 --> 00:08:19.334
where ancestor is user.Key,"

00:08:19.334 --> 00:08:21.000
and when you do this query,

00:08:21.000 --> 00:08:24.367
you are guaranteed to see
all the most recent results.

00:08:24.367 --> 00:08:27.067
So for a user,
this is very important,

00:08:27.067 --> 00:08:28.968
because they want
to have consistency.

00:08:28.968 --> 00:08:32.467
They put a comment, and you
redirect them to the page

00:08:32.467 --> 00:08:35.067
that shows that comment,
and they really want to see

00:08:35.067 --> 00:08:38.467
the comment they just put, or
they think your site's broken.

00:08:38.467 --> 00:08:40.901
So let's see why
this is the case,

00:08:40.901 --> 00:08:44.200
why this difference exists
between master/slave

00:08:44.200 --> 00:08:46.901
and, uh,
the high replication datastore.

00:08:46.901 --> 00:08:50.033
Um, and to do this, we have
to look at how reads and writes

00:08:50.033 --> 00:08:52.334
operate in both systems
in the common case.

00:08:52.334 --> 00:08:54.334
So for a write
in master/slave,

00:08:54.334 --> 00:08:57.868
we write to the local replica,
which is the master,

00:08:57.868 --> 00:09:00.434
and then we asynchronously
replicate that write

00:09:00.434 --> 00:09:03.534
to the slave, so that when you
read from that local master,

00:09:03.534 --> 00:09:05.534
you know the local master,

00:09:05.534 --> 00:09:07.868
um, saw any writes

00:09:07.868 --> 00:09:09.868
that have been accepted
by the system,

00:09:09.868 --> 00:09:11.901
so you're guaranteed
to see that write.

00:09:11.901 --> 00:09:13.868
And if we look at this,
this is, uh,

00:09:13.868 --> 00:09:16.868
a very simplified layout
of one of these replicas

00:09:16.868 --> 00:09:19.534
in a datacenter.

00:09:19.534 --> 00:09:22.567
So we have Datacenter "A" that
is hosting your application,

00:09:22.567 --> 00:09:25.801
and we have a Bigtable "A"
that is hosting your data.

00:09:25.801 --> 00:09:29.567
And when the datastore--
you invoke a datastore write,

00:09:29.567 --> 00:09:31.434
it'll write to Bigtable "A",

00:09:31.434 --> 00:09:34.033
which is the local Bigtable
in this case, and the master,

00:09:34.033 --> 00:09:36.400
and then that write will
asynchronously replicate

00:09:36.400 --> 00:09:38.901
to Bigtable "B"
at some later point.

00:09:38.901 --> 00:09:40.901
So it'll return to you

00:09:40.901 --> 00:09:43.534
as soon as we write
to Bigtable "A."

00:09:43.534 --> 00:09:46.534
When you do a read, that read
goes directly to Bigtable "A",

00:09:46.534 --> 00:09:49.033
and we know that that has seen

00:09:49.033 --> 00:09:51.634
any writes that have succeeded.

00:09:51.634 --> 00:09:53.801
However, in
the high replication case,

00:09:53.801 --> 00:09:56.567
this is slightly
more complicated.

00:09:56.567 --> 00:09:59.367
Maybe not slightly--
it's pretty complicated.

00:09:59.367 --> 00:10:01.033
Uh...
Wilder: [laughs]

00:10:01.033 --> 00:10:03.033
Fuller: Um, so a write--

00:10:03.033 --> 00:10:05.868
you write to at least
a majority of replicas,

00:10:05.868 --> 00:10:08.868
and you do this in two phases,
and when you do this,

00:10:08.868 --> 00:10:10.868
it means that a minority
of replicas

00:10:10.868 --> 00:10:12.868
may not have gotten
that write synchronously.

00:10:12.868 --> 00:10:14.901
Then we replicate asynchronously

00:10:14.901 --> 00:10:17.434
any write that a replica
hasn't seen,

00:10:17.434 --> 00:10:20.367
or we do it on demand
when you do the read.

00:10:20.367 --> 00:10:23.133
Uh, we can update whatever
replica you're reading from

00:10:23.133 --> 00:10:25.834
and force that strong
serial consistency.

00:10:25.834 --> 00:10:28.300
Reads are slightly different,
as well.

00:10:28.300 --> 00:10:31.133
What we will do is we'll read
from the fastest replica,

00:10:31.133 --> 00:10:34.501
which is usually the local,
but can be another replica,

00:10:34.501 --> 00:10:36.267
and we can catch up on demand.

00:10:36.267 --> 00:10:38.434
So if the fastest replica
isn't up to date,

00:10:38.434 --> 00:10:40.067
what we will actually do--

00:10:40.067 --> 00:10:42.067
I think I have it in a--

00:10:42.067 --> 00:10:44.067
Yeah, cool, I'll do it
in this one--

00:10:44.067 --> 00:10:46.067
Um... [laughs]

00:10:46.067 --> 00:10:48.868
so if Replica "A"
isn't actually caught up,

00:10:48.868 --> 00:10:51.868
what we will do is we'll
actually fail over--

00:10:51.868 --> 00:10:54.567
Hold on--
There it goes--

00:10:54.567 --> 00:10:56.734
We'll read from
Replica "C" instead,

00:10:56.734 --> 00:10:58.734
and wait for Replica "A"
to catch up,

00:10:58.734 --> 00:11:00.734
and as soon as Replica "A"
is caught up,

00:11:00.734 --> 00:11:02.801
we'll start reading
from Replica "A,"

00:11:02.801 --> 00:11:05.300
and this is all done,
uh, on a sub-RPC level,

00:11:05.300 --> 00:11:07.634
so in the middle of an RPC,
we can switch back,

00:11:07.634 --> 00:11:10.133
and make sure you're always
getting the fastest reads.

00:11:10.133 --> 00:11:13.133
Writes, um, are complicated,
as I said.

00:11:13.133 --> 00:11:16.133
There's two phases.
The first phase is a Prepare--

00:11:16.133 --> 00:11:18.133
whoops--wrong slide, hold on.
[chuckles]

00:11:18.133 --> 00:11:20.000
They look idintical--
identical.

00:11:20.000 --> 00:11:21.834
Uh, the first stage
is a "Prepare,"

00:11:21.834 --> 00:11:24.400
and the second stage
is an "Accept,"

00:11:24.400 --> 00:11:26.400
which actually sends out
the payload,

00:11:26.400 --> 00:11:28.400
which is your entity to write.

00:11:28.400 --> 00:11:30.400
And you can see that this write
is actually

00:11:30.400 --> 00:11:33.467
talking across datacenters
to all replicas synchronously,

00:11:33.467 --> 00:11:37.067
and as long as a majority
of these datacenters, uh,

00:11:37.067 --> 00:11:39.467
have all your--
or--or accept that write,

00:11:39.467 --> 00:11:41.267
then the write succeeds.

00:11:41.267 --> 00:11:43.834
And you can see in master/slave,
I had one replica--

00:11:43.834 --> 00:11:46.434
or one Bigtable that was dark,
and trying to indicate that

00:11:46.434 --> 00:11:48.501
that had all the "data,"
and in high replication,

00:11:48.501 --> 00:11:50.801
there's no guarantee
that any replica

00:11:50.801 --> 00:11:53.567
has all your data
at any given time.

00:11:53.567 --> 00:11:56.734
And another thing, uh,
that's important to note

00:11:56.734 --> 00:12:00.067
about this slide is that, uh,
there's no master in this case,

00:12:00.067 --> 00:12:02.634
so that we can run apps
in multiple datacenters,

00:12:02.634 --> 00:12:04.534
so we can have an app
in Datacenter "B"

00:12:04.534 --> 00:12:07.534
reading and writing, uh,

00:12:07.534 --> 00:12:10.434
to--to these, uh, Bigtables,
and--

00:12:10.434 --> 00:12:12.434
Ops--Oh, that's also
important, I guess.

00:12:12.434 --> 00:12:15.167
[chuckles]
Sorry, this is--

00:12:15.167 --> 00:12:18.000
Yeah, I should have made
a distinction on these slides.

00:12:18.000 --> 00:12:20.868
Um, yes, so we can have them
going all at the same time,

00:12:20.868 --> 00:12:22.968
and everyone's happy
and everyone

00:12:22.968 --> 00:12:24.634
can see in consistent views.

00:12:24.634 --> 00:12:27.834
And theoretically, um, if it
was just the datastore alone,

00:12:27.834 --> 00:12:30.434
we could actually be talking
to the same entity group

00:12:30.434 --> 00:12:32.567
and writing to the same
entity groups, and, uh,

00:12:32.567 --> 00:12:36.000
you'd still have your
data integrity maintained.

00:12:36.000 --> 00:12:39.000
So obviously,

00:12:39.000 --> 00:12:41.000
it's--
the world's a little slightly

00:12:41.000 --> 00:12:44.000
more complicated in
the high replication datastore,

00:12:44.000 --> 00:12:47.000
and if we look at the latencies,
this is reflected.

00:12:47.000 --> 00:12:49.000
Um, we look
at the read latencies,

00:12:49.000 --> 00:12:51.000
and you can see
that we've optimized

00:12:51.000 --> 00:12:53.000
the high replication datastore
for reads.

00:12:53.000 --> 00:12:55.000
In most cases,
it's almost identical

00:12:55.000 --> 00:12:57.667
to what happens in
the master/slave datastore,

00:12:57.667 --> 00:13:01.000
so the average read latency
is identical.

00:13:01.000 --> 00:13:05.434
The write latency, on
the other hand, is, uh, higher,

00:13:05.434 --> 00:13:07.033
um, because we have to do this
cross-datacenter

00:13:07.033 --> 00:13:08.801
synchronous replication, um,

00:13:08.801 --> 00:13:11.167
and we have to talk
to at least a majority,

00:13:11.167 --> 00:13:13.167
uh, we have
additional latency here,

00:13:13.167 --> 00:13:14.834
and it's also
two round trips,

00:13:14.834 --> 00:13:17.834
um, so we have about twice
the amount of latency.

00:13:17.834 --> 00:13:19.834
However, where
the high replication datastore

00:13:19.834 --> 00:13:22.100
really shines is in its, uh,
error rates.

00:13:22.100 --> 00:13:25.100
So if we look at these
average error rates,

00:13:25.100 --> 00:13:27.100
and we look at the master/slave
error rate,

00:13:27.100 --> 00:13:30.100
we can see that this .1%,
uh, error rate

00:13:30.100 --> 00:13:33.133
is actually 3 9's, which
is the purpose of this talk,

00:13:33.133 --> 00:13:35.634
is trying to get
more of these 9's,

00:13:35.634 --> 00:13:39.033
and it's the common terminology
when we talk about it in SLA,

00:13:39.033 --> 00:13:40.868
which is
a service level agreement.

00:13:40.868 --> 00:13:43.234
So in this case,
3 9's actually means

00:13:43.234 --> 00:13:46.334
that your datastore is down
for 8.7 hours a year.

00:13:46.334 --> 00:13:48.901
And I'm not taking
into consideration here

00:13:48.901 --> 00:13:51.734
planned maintenance
or catastrophic failures.

00:13:51.734 --> 00:13:54.234
This is the ambient error rate
that you can expect

00:13:54.234 --> 00:13:55.734
with the master/slave datastore.

00:13:55.734 --> 00:13:58.234
With a high replication
datastore, on the other hand,

00:13:58.234 --> 00:14:00.801
you can see
that we actually have 5 9's,

00:14:00.801 --> 00:14:02.567
which is many more 9's,

00:14:02.567 --> 00:14:05.968
especially when you take into
consideration its impact, uh...

00:14:05.968 --> 00:14:08.701
[clears throat]

00:14:08.701 --> 00:14:11.334
uh, which is 5 minutes a year

00:14:11.334 --> 00:14:13.667
as opposed to almost 9 hours
of downtime

00:14:13.667 --> 00:14:15.367
in times of ambient error rates.

00:14:15.367 --> 00:14:19.234
Wilder: So let's talk about how
these two datastores differ

00:14:19.234 --> 00:14:21.067
in some of
the less common cases.

00:14:21.067 --> 00:14:23.901
The first one we're gonna talk
about is planned maintenance.

00:14:23.901 --> 00:14:27.934
So Google datacenters undergo
planned maintenance periods.

00:14:27.934 --> 00:14:29.801
During these periods,

00:14:29.801 --> 00:14:33.200
low-level pieces
of the common infrastructure,

00:14:33.200 --> 00:14:36.400
such as networking,
power, cooling,

00:14:36.400 --> 00:14:38.634
maybe low-level
cluster management,

00:14:38.634 --> 00:14:40.334
distributed storage services

00:14:40.334 --> 00:14:42.033
are--undergo maintenances

00:14:42.033 --> 00:14:44.033
that require a downtime
to accomplish.

00:14:44.033 --> 00:14:46.100
Most Google services,
including App Engine,

00:14:46.100 --> 00:14:47.801
are able to do
in-place upgrades.

00:14:47.801 --> 00:14:49.801
So, you know, we can
upgrade our software,

00:14:49.801 --> 00:14:51.734
and your app
doesn't know about it.

00:14:51.734 --> 00:14:53.400
However, with low-level things
like power,

00:14:53.400 --> 00:14:55.400
it's kind of hard to do that.

00:14:55.400 --> 00:14:59.300
Um, so, you know, kind of hard
to turn off machines one by one,

00:14:59.300 --> 00:15:01.367
and, you know,
do things like that.

00:15:01.367 --> 00:15:04.801
So, uh, Google groups these,
uh, upgrades

00:15:04.801 --> 00:15:06.734
into contiguous time periods.

00:15:06.734 --> 00:15:10.234
That way, you know, all of these
sort of chaotic maintenances

00:15:10.234 --> 00:15:12.734
can happen at the datacenter
at the same time

00:15:12.734 --> 00:15:15.267
or as close to the same time
as possible.

00:15:15.267 --> 00:15:17.567
So when these cases
are happening, you know,

00:15:17.567 --> 00:15:19.868
a datacenter can be offline
for several days,

00:15:19.868 --> 00:15:22.367
um, depending upon the type
of maintenance.

00:15:22.367 --> 00:15:24.801
So what does this look like

00:15:24.801 --> 00:15:26.901
for master/slave datastore?

00:15:26.901 --> 00:15:29.100
Um, so when one of these
maintenance periods

00:15:29.100 --> 00:15:30.634
happens to the datacenter

00:15:30.634 --> 00:15:32.968
that we're serving master/slave
applications out of,

00:15:32.968 --> 00:15:35.968
we don't want those applications
to be offline for several days

00:15:35.968 --> 00:15:37.634
while these maintenances
are performed.

00:15:37.634 --> 00:15:39.300
So we need to switch
which datacenter

00:15:39.300 --> 00:15:42.067
is currently the master and
which one is the slave.

00:15:42.067 --> 00:15:45.734
To do this, we perform what we
call a master switch operation.

00:15:45.734 --> 00:15:47.901
Um, this operation

00:15:47.901 --> 00:15:50.534
involves about one hour
of read-only datastore,

00:15:50.534 --> 00:15:53.801
and it's a fairly complicated
semi-automatic procedure

00:15:53.801 --> 00:15:55.834
that requires a member
of the engineering team

00:15:55.834 --> 00:15:58.868
to execute a very specific set
of steps to accomplish.

00:15:58.868 --> 00:16:03.267
Um, a lot of these steps
depend on other Google services

00:16:03.267 --> 00:16:05.501
and pieces of
internal infrastructure.

00:16:05.501 --> 00:16:07.834
Um, if those services
aren't working well

00:16:07.834 --> 00:16:09.834
or they're experiencing
unavailability,

00:16:09.834 --> 00:16:12.934
it can cause us
to slow down our process,

00:16:12.934 --> 00:16:15.434
and it can make us miss
the maintenance window

00:16:15.434 --> 00:16:17.434
that we tell you about
in advance

00:16:17.434 --> 00:16:19.934
or make us be read-only longer
than we want to.

00:16:19.934 --> 00:16:22.067
So, um, we work hard
to make sure

00:16:22.067 --> 00:16:23.901
that we catch these things
in advance,

00:16:23.901 --> 00:16:25.834
so that if we do find them,

00:16:25.834 --> 00:16:27.467
we will cancel
the maintenance period

00:16:27.467 --> 00:16:29.434
and move it
to another time period.

00:16:29.434 --> 00:16:32.267
And we try to improve
the process as much as we can.

00:16:32.267 --> 00:16:34.234
Fuller: So let's see
what this looks like,

00:16:34.234 --> 00:16:36.267
uh, given that diagram
that I showed you earlier.

00:16:36.267 --> 00:16:39.901
So we have an app that's reading
and writing to Bigtable "A"

00:16:39.901 --> 00:16:41.767
and replicating to Bigtable "B".

00:16:41.767 --> 00:16:44.834
And we are notified of
a planned maintenance period,

00:16:44.834 --> 00:16:46.501
and we notify you, in turn,

00:16:46.501 --> 00:16:48.467
that we're gonna take your app
into read-only.

00:16:48.467 --> 00:16:51.834
And then during the window,
we initiate a read-only period,

00:16:51.834 --> 00:16:54.567
so that your app can still read,
but it cannot write.

00:16:54.567 --> 00:16:56.367
Then we flush the replication

00:16:56.367 --> 00:16:58.834
of anything that hasn't been
replicated yet

00:16:58.834 --> 00:17:01.701
to make sure that Bigtable "A"
and Bigtable "B"

00:17:01.701 --> 00:17:03.534
both have identical information

00:17:03.534 --> 00:17:05.701
and all of the most
up-to-date information.

00:17:05.701 --> 00:17:09.100
Then we drain Datacenter "A"
into Datacenter "B,"

00:17:09.100 --> 00:17:10.968
and we switch the master
and the slave.

00:17:10.968 --> 00:17:13.467
During this period, since they
contain, uh, both information,

00:17:13.467 --> 00:17:16.300
your app experiences
no interruption

00:17:16.300 --> 00:17:19.834
in read-only service,
uh, so they can both read,

00:17:19.834 --> 00:17:21.667
'cause they're gonna see
the same data.

00:17:21.667 --> 00:17:23.601
As soon as we've completed
that drain,

00:17:23.601 --> 00:17:25.567
we can enable the writing
to your app.

00:17:25.567 --> 00:17:27.501
So now you're reading
from Bigtable "B",

00:17:27.501 --> 00:17:29.234
and you're writing
to Bigtable "B,"

00:17:29.234 --> 00:17:31.968
and then "A" synchronously
replicating to Bigtable "A".

00:17:31.968 --> 00:17:33.467
And at this point,

00:17:33.467 --> 00:17:35.300
there's no guarantee
that Bigtable "A"

00:17:35.300 --> 00:17:39.300
has all of the data,
thus is now the slave.

00:17:39.300 --> 00:17:42.901
Wilder: So what happens to
high replication applications

00:17:42.901 --> 00:17:45.067
when we have one of these
maintenance periods?

00:17:45.067 --> 00:17:48.200
Um, they're pretty much,
uh, not affected at all.

00:17:48.200 --> 00:17:51.234
Um, while we do still
primarily serve

00:17:51.234 --> 00:17:54.033
high replication applications
out of a single datacenter,

00:17:54.033 --> 00:17:57.200
which we'll talk a little bit
more about why in a minute,

00:17:57.200 --> 00:17:59.634
we're able to seamlessly migrate
these applications

00:17:59.634 --> 00:18:01.434
from one datacenter to another

00:18:01.434 --> 00:18:03.934
without almost any notice
to the developer

00:18:03.934 --> 00:18:05.701
or the user of the application.

00:18:05.701 --> 00:18:07.901
Um, furthermore,
we're able to do this

00:18:07.901 --> 00:18:10.701
without any interaction
from the app engine team at all.

00:18:10.701 --> 00:18:13.234
None of our team
has to initiate this process.

00:18:13.234 --> 00:18:16.467
The reason why we can do this
is that Google datacenters

00:18:16.467 --> 00:18:20.234
have a system for notifying
services running within them

00:18:20.234 --> 00:18:22.100
that these maintenance periods
are beginning,

00:18:22.100 --> 00:18:25.167
and they should move their
traffic out of that datacenter.

00:18:25.167 --> 00:18:27.367
So when App Engine
receives this signal,

00:18:27.367 --> 00:18:30.000
we automatically move
the application

00:18:30.000 --> 00:18:31.934
serving in that datacenter
to another one

00:18:31.934 --> 00:18:34.434
that's not gonna go under one
of these maintenance periods

00:18:34.434 --> 00:18:36.000
anytime soon.

00:18:36.000 --> 00:18:38.534
As I said, this switching
is almost transparent.

00:18:38.534 --> 00:18:42.334
Um, what is noticeable
is a flush of Memcache

00:18:42.334 --> 00:18:44.267
at approximately one minute

00:18:44.267 --> 00:18:46.501
where you can read
from Memcache,

00:18:46.501 --> 00:18:48.467
but it's always empty,
and you can write,

00:18:48.467 --> 00:18:50.167
and it just pretends to succeed.

00:18:50.167 --> 00:18:52.968
The reason that this is the case
is that we--

00:18:52.968 --> 00:18:56.667
and the primary reason why we
only serve HR applications

00:18:56.667 --> 00:19:00.167
out of a single datacenter
is that--is Memcache

00:19:00.167 --> 00:19:02.501
is a very fast API,
you know?

00:19:02.501 --> 00:19:05.667
If you've used it, you get
requests and responses back

00:19:05.667 --> 00:19:07.400
in, like, in order
of milliseconds.

00:19:07.400 --> 00:19:09.701
Um, that's because we don't
replicate it

00:19:09.701 --> 00:19:11.300
to the other datacenters

00:19:11.300 --> 00:19:13.334
we serve your higher
applications applications from.

00:19:13.334 --> 00:19:16.400
If we did, um, the time
it would take that data

00:19:16.400 --> 00:19:19.167
to transmit
to those other datacenters

00:19:19.167 --> 00:19:22.100
would make Memcache
a very slow API

00:19:22.100 --> 00:19:24.968
and not as useful for what
you probably use it for.

00:19:24.968 --> 00:19:28.801
Unfortunately, even Google is
limited by the speed of light.

00:19:28.801 --> 00:19:31.033
Fuller: So let's see
what that looks like

00:19:31.033 --> 00:19:32.567
in the high replication.

00:19:32.567 --> 00:19:34.501
So we get a signal
from our infrastructure team,

00:19:34.501 --> 00:19:37.501
and our system automatically
drains apps from Datacenter "A"

00:19:37.501 --> 00:19:40.000
and serves them
out of Datacenter "B."

00:19:40.000 --> 00:19:43.734
And then the infrastructure team
takes down to the Bigtable

00:19:43.734 --> 00:19:45.734
and Datacenter "A,"
so it's unavailable.

00:19:45.734 --> 00:19:48.434
And when we do a read,
we read from Bigtable "B".

00:19:48.434 --> 00:19:51.300
And when we do a write,
we write to a majority.

00:19:51.300 --> 00:19:52.868
And in this case,

00:19:52.868 --> 00:19:55.000
you can see that Bigtable "A"
is not responding

00:19:55.000 --> 00:19:57.501
to any of our writes,
but the write still succeeds,

00:19:57.501 --> 00:20:00.334
because we have a majority
of replicas still responding

00:20:00.334 --> 00:20:02.334
to our write.

00:20:02.334 --> 00:20:05.567
Wilder: So, uh, let's talk
about some other reasons

00:20:05.567 --> 00:20:08.133
why the 9's and the datastores
are different.

00:20:08.133 --> 00:20:11.901
Um, uh, no distributed
storage system is perfect.

00:20:11.901 --> 00:20:15.634
Google is no exception.
Um, we do have unplanned issues.

00:20:15.634 --> 00:20:17.901
Um, we tend to group
these issues

00:20:17.901 --> 00:20:21.300
into two primary categories--
global and local failures.

00:20:21.300 --> 00:20:23.267
So we're gonna talk
about local failures first.

00:20:23.267 --> 00:20:26.901
Um, we, at Google,
group local failures

00:20:26.901 --> 00:20:29.200
into two other
various categories--

00:20:29.200 --> 00:20:31.801
expected and unexpected.

00:20:31.801 --> 00:20:33.734
So it may sound a little strange

00:20:33.734 --> 00:20:36.501
that we have unplanned
expected failures,

00:20:36.501 --> 00:20:38.801
but in reality,
they're a fundamental part

00:20:38.801 --> 00:20:40.334
of storage Google.

00:20:40.334 --> 00:20:42.834
The primary reason for this
is Bigtable.

00:20:42.834 --> 00:20:46.367
Um, as I said before, Bigtable
is a very important part

00:20:46.367 --> 00:20:48.968
of the datastore storage stack.

00:20:48.968 --> 00:20:50.968
It's also a very widely used,

00:20:50.968 --> 00:20:53.067
important piece of software
at Google.

00:20:53.067 --> 00:20:56.701
Bigtable is a very amazing piece
of software.

00:20:56.701 --> 00:21:00.267
It's able to scale
to incredibly large size.

00:21:00.267 --> 00:21:03.667
It can have an un--mind-boggling
amounts of data in it,

00:21:03.667 --> 00:21:06.834
and it can support huge amounts
of transactions per second,

00:21:06.834 --> 00:21:08.367
reads, and writes.

00:21:08.367 --> 00:21:11.133
And it can span many, many,
many, many machines.

00:21:11.133 --> 00:21:13.634
Well, in order
to make this possible,

00:21:13.634 --> 00:21:16.434
the designers of Bigtable
made some trade-offs

00:21:16.434 --> 00:21:18.968
that result in data
being unavailable

00:21:18.968 --> 00:21:20.968
for short periods of time.

00:21:20.968 --> 00:21:22.968
Here's why--
Um, at its core,

00:21:22.968 --> 00:21:24.701
Bigtable splits its data up

00:21:24.701 --> 00:21:27.267
into contiguous blocks
called tablets.

00:21:27.267 --> 00:21:29.701
Um, these tablets
are made available

00:21:29.701 --> 00:21:32.200
by a process that's called
tablet servers.

00:21:32.200 --> 00:21:35.501
So every Bigtable cell
has a lot of tablet servers,

00:21:35.501 --> 00:21:38.501
and each tablet server
has a lot of tablets loaded.

00:21:38.501 --> 00:21:41.133
Now these tablets
can only sustain

00:21:41.133 --> 00:21:43.901
a certain threshold
of reads and writes.

00:21:43.901 --> 00:21:46.367
If they get more reads
and writes than that,

00:21:46.367 --> 00:21:48.601
then performance
will be degraded.

00:21:48.601 --> 00:21:50.701
So Bigtable responds to this

00:21:50.701 --> 00:21:53.667
by splitting that tablet into
two or more smaller tablets.

00:21:53.667 --> 00:21:56.300
And if the tablet server
serving those tablets

00:21:56.300 --> 00:21:57.801
is experiencing too much load,

00:21:57.801 --> 00:21:59.801
it will move those tablets
to another tablet server,

00:21:59.801 --> 00:22:01.934
which is less--less loaded.

00:22:01.934 --> 00:22:04.634
Now while these operations
are happening,

00:22:04.634 --> 00:22:07.701
um, the data is unavailable
for that period of time.

00:22:07.701 --> 00:22:10.067
Now these operations
are supposed to be very fast,

00:22:10.067 --> 00:22:11.834
but occasionally, they are slow.

00:22:11.834 --> 00:22:13.834
This is one of
the most common causes

00:22:13.834 --> 00:22:15.834
of unexpected local issues.

00:22:15.834 --> 00:22:18.167
Um, occasionally,

00:22:18.167 --> 00:22:22.133
something causes these split
or merge operations to be slow.

00:22:22.133 --> 00:22:24.133
Um, one example
that we have noticed

00:22:24.133 --> 00:22:25.968
is a tablet server

00:22:25.968 --> 00:22:28.200
is on a machine
that's maybe unhealthy,

00:22:28.200 --> 00:22:30.200
or something is causing it
to perform poorly.

00:22:30.200 --> 00:22:31.767
If this is happening,

00:22:31.767 --> 00:22:33.968
requests to this tablet server
will be slower,

00:22:33.968 --> 00:22:36.033
and maybe those split operations

00:22:36.033 --> 00:22:38.534
aren't happening as fast
as they should be.

00:22:38.534 --> 00:22:41.200
Another example of reasons

00:22:41.200 --> 00:22:43.400
that we have seen
this performance happen

00:22:43.400 --> 00:22:45.968
is due to the distributed
file system underneath.

00:22:45.968 --> 00:22:49.100
When those tablets move
to other tablet servers,

00:22:49.100 --> 00:22:52.234
um, the new tablet server
needs to load that tablet

00:22:52.234 --> 00:22:54.667
off of Google's distributed
file system.

00:22:54.667 --> 00:22:57.367
If for some reason
that operation is slow,

00:22:57.367 --> 00:23:00.067
then the data is unavailable
for longer

00:23:00.067 --> 00:23:03.667
while the tablet server
is trying to load that data

00:23:03.667 --> 00:23:05.701
to make it available again.

00:23:05.701 --> 00:23:09.467
One of the most causes of this
happening is isolation.

00:23:09.467 --> 00:23:11.133
As I said,

00:23:11.133 --> 00:23:13.400
Bigtable and Google's
distributed file system

00:23:13.400 --> 00:23:15.501
are pieces of
common infrastructure.

00:23:15.501 --> 00:23:17.501
So multiple users
of the datacenter

00:23:17.501 --> 00:23:19.434
use the same instants.

00:23:19.434 --> 00:23:22.601
While isolation has been
built in from the ground up,

00:23:22.601 --> 00:23:24.434
it's not perfect.

00:23:24.434 --> 00:23:27.334
Isolation on distributed
storage systems of this scale

00:23:27.334 --> 00:23:30.901
is a--is a very hard problem
to solve.

00:23:30.901 --> 00:23:33.534
So what do these issues,
uh, look like

00:23:33.534 --> 00:23:36.801
for applications that you use
in master/slave datastore?

00:23:36.801 --> 00:23:38.801
Well, as Alfred said,

00:23:38.801 --> 00:23:42.234
um, applications that use
master/slave datastore

00:23:42.234 --> 00:23:45.601
depend upon a single Bigtable
to be available

00:23:45.601 --> 00:23:47.534
to support those reads
and writes.

00:23:47.534 --> 00:23:49.167
So if that Bigtable

00:23:49.167 --> 00:23:50.767
is experiencing these
unavailability issues,

00:23:50.767 --> 00:23:53.000
then those translate directly
into unavailability

00:23:53.000 --> 00:23:54.534
with the datastore.

00:23:54.534 --> 00:23:56.033
Um, as I said,

00:23:56.033 --> 00:23:58.534
the type of availability we're
talking about here is local,

00:23:58.534 --> 00:24:00.934
which means it only affects
small portions of data,

00:24:00.934 --> 00:24:02.667
which means
that some applications

00:24:02.667 --> 00:24:04.334
may be completely unaffected,

00:24:04.334 --> 00:24:06.801
and some applications
may be affected.

00:24:06.801 --> 00:24:08.801
What does this look like?

00:24:08.801 --> 00:24:10.968
Um, the most common thing

00:24:10.968 --> 00:24:13.000
that this will present itself
to its users

00:24:13.000 --> 00:24:14.667
is those random
deadline exceeded errors

00:24:14.667 --> 00:24:16.667
that you'll see in your
application's error logs.

00:24:16.667 --> 00:24:18.167
Typically in the stack trace,

00:24:18.167 --> 00:24:20.734
you may see a datastore RPC
or something like that.

00:24:20.734 --> 00:24:23.400
If the problem persists
for a long time,

00:24:23.400 --> 00:24:26.567
requests can back up
in your request queue,

00:24:26.567 --> 00:24:29.601
and it can actually begin
to affect requests

00:24:29.601 --> 00:24:31.634
that don't actually involve
the datastore.

00:24:31.634 --> 00:24:34.267
If you have
a master/slave application,

00:24:34.267 --> 00:24:36.267
you may have experienced this
on availability,

00:24:36.267 --> 00:24:37.801
and you may have noticed

00:24:37.801 --> 00:24:39.968
that maybe this App Engine
status site

00:24:39.968 --> 00:24:42.934
doesn't display that their
datastore is having any issues.

00:24:42.934 --> 00:24:45.334
The reason for this
is that at its core,

00:24:45.334 --> 00:24:46.934
the App Engine status site

00:24:46.934 --> 00:24:48.968
currently uses
actual applications

00:24:48.968 --> 00:24:51.467
to monitor the health
of the various APIs

00:24:51.467 --> 00:24:53.801
and present them
on the status site.

00:24:53.801 --> 00:24:56.634
So if those applications
aren't being affected

00:24:56.634 --> 00:24:58.834
by this local unavailability,

00:24:58.834 --> 00:25:00.667
it may not show up
on the status site,

00:25:00.667 --> 00:25:02.667
despite the fact
that it's affecting you.

00:25:02.667 --> 00:25:04.501
It's important to note

00:25:04.501 --> 00:25:07.067
that our internal monitoring
does catch these issues,

00:25:07.067 --> 00:25:09.234
and when they happen,
we are notified,

00:25:09.234 --> 00:25:12.033
and the on-call engineering team
will respond to them

00:25:12.033 --> 00:25:13.901
as quickly as we possibly can.

00:25:13.901 --> 00:25:16.067
We're also working on improving
the status site

00:25:16.067 --> 00:25:18.567
to better catch and report
these type of issues.

00:25:18.567 --> 00:25:21.701
Fuller: So let's look
at what this looks like.

00:25:21.701 --> 00:25:24.434
So your application tries to do
a read, and it fails.

00:25:24.434 --> 00:25:26.367
We try to do a write,
and it fails.

00:25:26.367 --> 00:25:27.934
We just get no response.

00:25:27.934 --> 00:25:29.868
We retry this,
and eventually, it times out.

00:25:29.868 --> 00:25:31.868
However, there is one thing
that you can do

00:25:31.868 --> 00:25:33.868
to improve the scenario
in your application's case,

00:25:33.868 --> 00:25:36.200
which is to enable
eventually consistent reads.

00:25:36.200 --> 00:25:38.601
In this case, what will happen

00:25:38.601 --> 00:25:41.100
is your application will try
to read, which will fail,

00:25:41.100 --> 00:25:43.601
and then it will read
from the slave instance,

00:25:43.601 --> 00:25:46.033
which may have stale data,

00:25:46.033 --> 00:25:48.234
but in some cases,
that's acceptable.

00:25:48.234 --> 00:25:50.601
In these cases, we recommend
that you enable this

00:25:50.601 --> 00:25:52.968
if you're gonna use
master/slave.

00:25:52.968 --> 00:25:56.400
Wilder: So how do these issues
affect applications

00:25:56.400 --> 00:25:58.400
that use
the high replication datastore?

00:25:58.400 --> 00:26:00.634
In short,
they have no impact at all.

00:26:00.634 --> 00:26:03.601
As we've mentioned,
high replication applications

00:26:03.601 --> 00:26:06.100
don't depend on the health
of a single Bigtable cell

00:26:06.100 --> 00:26:07.601
in order to perform.

00:26:07.601 --> 00:26:09.801
So if the local Bigtable
to your application

00:26:09.801 --> 00:26:11.467
is experiencing these problems,

00:26:11.467 --> 00:26:14.133
requests will seamlessly
fail over to another Bigtable,

00:26:14.133 --> 00:26:17.167
and this happens on
a per-request basis

00:26:17.167 --> 00:26:20.033
with no interaction
from anyone whatsoever.

00:26:20.033 --> 00:26:21.434
Fuller: I should point out

00:26:21.434 --> 00:26:23.334
that I made the tech lead
of Megastore,

00:26:23.334 --> 00:26:25.434
which is--
He's one of the masterminds

00:26:25.434 --> 00:26:27.634
behind the paxos implementation

00:26:27.634 --> 00:26:29.467
that runs
the high replication datastore,

00:26:29.467 --> 00:26:31.300
posed for this picture.

00:26:31.300 --> 00:26:34.367
Um, so let's see what this
looks like.

00:26:34.367 --> 00:26:36.067
So we have local failures,

00:26:36.067 --> 00:26:38.100
your app tries to do a read
from Bigtable "A",

00:26:38.100 --> 00:26:40.734
and it'll immediately fail over
to Bigtable "C"

00:26:40.734 --> 00:26:43.234
without any loss of consistency,
and it can do this

00:26:43.234 --> 00:26:44.934
because we're operating
on entity groups.

00:26:44.934 --> 00:26:47.701
And if Bigtable "C" doesn't have
the most current data,

00:26:47.701 --> 00:26:50.734
it can on demand
replicate that data.

00:26:50.734 --> 00:26:52.734
And, in fact,
when we do this operation,

00:26:52.734 --> 00:26:54.400
we'll look at all the replicas

00:26:54.400 --> 00:26:57.133
and see which one does have
the data and prefer that one,

00:26:57.133 --> 00:27:00.200
so we don't actually have
to block on the catch-up

00:27:00.200 --> 00:27:03.434
that has to happen in a replica
that doesn't have that data.

00:27:03.434 --> 00:27:06.834
When we do a write, it simply
doesn't affect the algorithm

00:27:06.834 --> 00:27:09.734
because we only require
a majority in these cases.

00:27:09.734 --> 00:27:12.734
So you don't see
any user visible effect.

00:27:12.734 --> 00:27:16.734
And eventually, since we track
the health of these Bigtables,

00:27:16.734 --> 00:27:19.534
uh, the health tracker

00:27:19.534 --> 00:27:21.267
will decide that Bigtable "A"

00:27:21.267 --> 00:27:22.934
is either slow
or being unavailable,

00:27:22.934 --> 00:27:24.901
and it won't even try
to read from it.

00:27:24.901 --> 00:27:27.434
It will actually just read
from another replica

00:27:27.434 --> 00:27:30.901
that is the fastest replica
to serve your writes.

00:27:30.901 --> 00:27:32.901
And eventually,
this error will go away

00:27:32.901 --> 00:27:35.367
and will switch back to reading
from the local replica,

00:27:35.367 --> 00:27:36.968
as it is usually the fastest.

00:27:36.968 --> 00:27:39.901
Wilder: So let's talk about
failures on a global level.

00:27:39.901 --> 00:27:42.501
Um, these are the type
of failures

00:27:42.501 --> 00:27:44.567
that render
an entire datacenter

00:27:44.567 --> 00:27:46.601
either offline or unusable.

00:27:46.601 --> 00:27:48.534
Some of the examples
of the causes

00:27:48.534 --> 00:27:50.133
of these types of errors is--

00:27:50.133 --> 00:27:51.934
Let's say the fiber-optic cables

00:27:51.934 --> 00:27:54.501
connecting the datacenter
of the network get cut,

00:27:54.501 --> 00:27:58.000
or there's a power outage,
and the backup generators fail,

00:27:58.000 --> 00:27:59.834
powering off the datacenter.

00:27:59.834 --> 00:28:02.501
Maybe there's some bug
or major issue

00:28:02.501 --> 00:28:05.334
with, you know, lower-level
pieces of the infrastructure

00:28:05.334 --> 00:28:07.634
that just render the datacenter
completely kaput,

00:28:07.634 --> 00:28:09.133
completely useless.

00:28:09.133 --> 00:28:12.167
Google's datacenters
are really big,

00:28:12.167 --> 00:28:14.734
so when these sort
of things happen,

00:28:14.734 --> 00:28:17.067
it tends to take a long time
to recover.

00:28:17.067 --> 00:28:19.567
If we power off an entire
datacenter, for example,

00:28:19.567 --> 00:28:21.834
you know, turning all
those machines back on

00:28:21.834 --> 00:28:23.934
and making sure
all the machines turn up

00:28:23.934 --> 00:28:25.834
and check their disks
if necessary

00:28:25.834 --> 00:28:27.834
and start up
all those processes,

00:28:27.834 --> 00:28:30.067
it takes a long time
on Google's scale.

00:28:30.067 --> 00:28:32.667
Furthermore, you know,
if fiber-optic cables get cut--

00:28:32.667 --> 00:28:35.467
I don't know if any of you have
ever experienced this--

00:28:35.467 --> 00:28:38.300
it takes a long time
to get those tables repaired.

00:28:38.300 --> 00:28:40.801
So these things take
the datacenter offline

00:28:40.801 --> 00:28:42.467
for quite some time.

00:28:42.467 --> 00:28:44.734
Fuller: Now although this is
unfortunate when this happens,

00:28:44.734 --> 00:28:46.400
they do make great stories.

00:28:46.400 --> 00:28:50.534
So I will again plug Handler's
talk that comes after this.

00:28:50.534 --> 00:28:53.934
Wilder: So what effect
do these outages happen

00:28:53.934 --> 00:28:55.767
on master/slave applications?

00:28:55.767 --> 00:28:57.434
Well, as you can probably guess,

00:28:57.434 --> 00:28:59.434
if that datacenter that we're
serving at disappears,

00:28:59.434 --> 00:29:01.167
the applications disappear, too.

00:29:01.167 --> 00:29:03.667
It's important to note
in this case

00:29:03.667 --> 00:29:05.834
that with global failures,

00:29:05.834 --> 00:29:08.801
it typically is not just
a datastore that goes offline.

00:29:08.801 --> 00:29:11.300
But if it's like a power outage
or networking,

00:29:11.300 --> 00:29:13.534
the whole app engine
serving stack goes away,

00:29:13.534 --> 00:29:15.434
which means that it's not
just the datastore

00:29:15.434 --> 00:29:16.934
that's unavailable,

00:29:16.934 --> 00:29:18.567
but your whole application
is unavailable.

00:29:18.567 --> 00:29:20.567
So what do we do about this?

00:29:20.567 --> 00:29:24.567
Well, when this happens, we
perform an emergency failover.

00:29:24.567 --> 00:29:27.300
This is an emergency
switch operation

00:29:27.300 --> 00:29:29.133
so we can just
switch applications

00:29:29.133 --> 00:29:31.367
to serve out
of the other datacenter.

00:29:31.367 --> 00:29:32.868
Now master/slave

00:29:32.868 --> 00:29:35.267
uses an asynchronous
replication scheme.

00:29:35.267 --> 00:29:37.601
So if we do an emergency switch,

00:29:37.601 --> 00:29:40.901
there's gonna be some data loss
on a temporary level.

00:29:40.901 --> 00:29:44.667
Now this data loss presents
itself in two primary ways.

00:29:44.667 --> 00:29:46.868
One is just unreplicated data.

00:29:46.868 --> 00:29:49.601
This is data that was written
to the master

00:29:49.601 --> 00:29:51.367
and never replicated over

00:29:51.367 --> 00:29:53.334
when that master datacenter
went offline.

00:29:53.334 --> 00:29:55.334
So this data is just missing

00:29:55.334 --> 00:29:58.667
until that datacenter comes
back, and we can recover it.

00:29:58.667 --> 00:30:01.701
Another type is partially
replicated data.

00:30:01.701 --> 00:30:04.634
This is when the data
was written to the master

00:30:04.634 --> 00:30:07.601
and was in the process of being
replicated to the slave

00:30:07.601 --> 00:30:09.534
when the datacenter
went offline,

00:30:09.534 --> 00:30:11.767
and we performed
this emergency failover.

00:30:11.767 --> 00:30:14.801
In this case, when we have part
of a transaction applied

00:30:14.801 --> 00:30:16.501
or part of an update made,

00:30:16.501 --> 00:30:19.534
and the datastore knows
that it's missing this data,

00:30:19.534 --> 00:30:22.267
and so it does not allow writes
to this data

00:30:22.267 --> 00:30:25.467
until it receives the rest of
that transaction or that update.

00:30:25.467 --> 00:30:27.000
Now as I said before,

00:30:27.000 --> 00:30:29.000
this datacenter may be offline
for a while,

00:30:29.000 --> 00:30:30.801
so we don't want to wait

00:30:30.801 --> 00:30:33.801
for that datacenter to come back
to finish that write.

00:30:33.801 --> 00:30:36.801
So what we do is once we finish
this emergency procedure,

00:30:36.801 --> 00:30:39.968
we then go through and check
the entire datastore

00:30:39.968 --> 00:30:42.334
for any instance of this, uh,

00:30:42.334 --> 00:30:44.534
this partially replicated data,

00:30:44.534 --> 00:30:46.501
and we manually roll back
those transactions,

00:30:46.501 --> 00:30:48.501
making your data
available again.

00:30:48.501 --> 00:30:50.501
Now eventually,
this other datacenter

00:30:50.501 --> 00:30:52.033
does come back online,

00:30:52.033 --> 00:30:54.167
and that Bigtable comes back
with it.

00:30:54.167 --> 00:30:57.534
At this point,
we have data in that Bigtable

00:30:57.534 --> 00:30:59.267
that was not replicated over.

00:30:59.267 --> 00:31:02.033
However, we can't just replicate
that data now,

00:31:02.033 --> 00:31:05.100
because you may have written
to that data since

00:31:05.100 --> 00:31:06.667
or deleted it or something,

00:31:06.667 --> 00:31:08.634
and so there would be
a conflict.

00:31:08.634 --> 00:31:10.501
So instead, what we do

00:31:10.501 --> 00:31:12.934
is we dump the data out
of that Bigtable

00:31:12.934 --> 00:31:15.467
and provide it to the developers

00:31:15.467 --> 00:31:17.200
on an offline basis,

00:31:17.200 --> 00:31:20.601
so they can decide
what they think is best to do.

00:31:20.601 --> 00:31:22.601
Fuller: So let's look

00:31:22.601 --> 00:31:25.234
at what this emergency failover
looks like.

00:31:25.234 --> 00:31:27.133
Reads and writes are failing,

00:31:27.133 --> 00:31:29.400
and then we decide
that Bigtable "A'

00:31:29.400 --> 00:31:31.367
is probably gonna be down
for a while,

00:31:31.367 --> 00:31:34.734
and it would be much better
for our users

00:31:34.734 --> 00:31:36.868
to have our sites active.

00:31:36.868 --> 00:31:39.667
Um, and so we initiate

00:31:39.667 --> 00:31:41.300
an emergency failover,

00:31:41.300 --> 00:31:44.200
which just force-swaps
the master and the slave.

00:31:44.200 --> 00:31:46.133
And as you can see, Bigtable "B"

00:31:46.133 --> 00:31:48.067
hasn't had
its replication flushed,

00:31:48.067 --> 00:31:50.033
thus does not have all the data.

00:31:50.033 --> 00:31:52.634
And as Matt said, that data
is still durable

00:31:52.634 --> 00:31:56.167
and in Bigtable "A,"
so we can recover it later.

00:31:56.167 --> 00:31:59.200
But the more important thing is
to get your apps running again,

00:31:59.200 --> 00:32:02.501
so now this app is, uh,
reading and writing

00:32:02.501 --> 00:32:04.534
from Bigtable "B."

00:32:04.534 --> 00:32:06.834
Wilder: So what effect do
these global failures have

00:32:06.834 --> 00:32:09.167
on applications that use
the high replication datastore?

00:32:09.167 --> 00:32:11.634
Well, as I said before,

00:32:11.634 --> 00:32:14.467
they do primarily serve out
of a single datacenter,

00:32:14.467 --> 00:32:16.701
so when we have these major
global failures,

00:32:16.701 --> 00:32:19.067
there is a slight bit
of unavailability,

00:32:19.067 --> 00:32:21.067
but they recover within minutes,

00:32:21.067 --> 00:32:23.067
and there is absolutely
no data loss.

00:32:23.067 --> 00:32:25.734
The reason why they are able
to recover so quickly

00:32:25.734 --> 00:32:27.701
is you remember that system
I talked about

00:32:27.701 --> 00:32:29.601
when we do planned maintenance

00:32:29.601 --> 00:32:33.133
where the infrastructure can
notify users of that datacenter

00:32:33.133 --> 00:32:35.634
that the datacenter is going
offline for maintenance?

00:32:35.634 --> 00:32:37.834
Well, when these
global failures happen

00:32:37.834 --> 00:32:39.601
that take
the datacenter offline,

00:32:39.601 --> 00:32:41.968
the same system is used
to notify those services

00:32:41.968 --> 00:32:43.634
that, hey,
an emergency has happened.

00:32:43.634 --> 00:32:45.968
This datacenter is unusable.
Move your traffic now.

00:32:45.968 --> 00:32:47.534
So when we get that signal,

00:32:47.534 --> 00:32:49.267
just like with
the planned maintenance,

00:32:49.267 --> 00:32:50.868
we seamlessly migrate
the applications

00:32:50.868 --> 00:32:53.367
to serve out
of another datacenter.

00:32:53.367 --> 00:32:56.968
Um, data is written
to more than one Bigtable

00:32:56.968 --> 00:32:58.734
with high replication datastore,

00:32:58.734 --> 00:33:01.300
which means that we haven't lost
any data at all.

00:33:01.300 --> 00:33:03.501
Furthermore, due
to the masterless nature

00:33:03.501 --> 00:33:05.501
of the high replication
datastore,

00:33:05.501 --> 00:33:08.000
we actually provision
each application,

00:33:08.000 --> 00:33:10.267
so that they can lose
multiple datacenters

00:33:10.267 --> 00:33:11.901
and still serve normally.

00:33:11.901 --> 00:33:14.767
This means that if
the datacenter is offline

00:33:14.767 --> 00:33:17.667
for a really long time due
to a tornado or a fire

00:33:17.667 --> 00:33:20.167
or an alien invasion
or something like that,

00:33:20.167 --> 00:33:22.767
your application
can still experience

00:33:22.767 --> 00:33:25.334
any of the type of failures that
I've talked about right now

00:33:25.334 --> 00:33:28.267
and not experience
any unavailability.

00:33:28.267 --> 00:33:32.133
Fuller: So this slide
should be familiar,

00:33:32.133 --> 00:33:34.734
because it's exactly the same
as a planned failover,

00:33:34.734 --> 00:33:36.734
which is important to notice.

00:33:36.734 --> 00:33:38.601
If your application--

00:33:38.601 --> 00:33:41.434
if the global failure just
affects the durability layer,

00:33:41.434 --> 00:33:44.467
you will see that the adaptation
will still serve

00:33:44.467 --> 00:33:46.834
and will still
read and write successfully,

00:33:46.834 --> 00:33:49.801
because we can always use--
not use Bigtable "A".

00:33:49.801 --> 00:33:51.767
If it does affect
the entire stack,

00:33:51.767 --> 00:33:53.968
and even when it just affects
the Bigtable,

00:33:53.968 --> 00:33:56.067
the infrastructure team,
as Matt said,

00:33:56.067 --> 00:33:58.067
will notify
our automated system,

00:33:58.067 --> 00:34:01.067
which will do a drain,

00:34:01.067 --> 00:34:04.200
and now your app is serving out
of Datacenter "B."

00:34:04.200 --> 00:34:07.334
And so it's important to note
that unplanned failures

00:34:07.334 --> 00:34:09.467
have the exact same effect
as planned ones

00:34:09.467 --> 00:34:11.734
in the high replication
datastore.

00:34:11.734 --> 00:34:16.000
So they--they're as Matt said,
your data is maintained.

00:34:16.000 --> 00:34:17.801
The consistency is there,

00:34:17.801 --> 00:34:21.501
and your application sees
very little downtime, if any.

00:34:21.501 --> 00:34:23.701
Wilder: So what lessons
have we learned

00:34:23.701 --> 00:34:25.300
from three years of running

00:34:25.300 --> 00:34:27.467
the App Engine
master/slave datastore

00:34:27.467 --> 00:34:29.834
and building the high
replication datastore?

00:34:29.834 --> 00:34:32.234
First is expect the unexpected.

00:34:32.234 --> 00:34:34.834
Global failures--you don't
expect them to happen,

00:34:34.834 --> 00:34:36.334
but they do happen.

00:34:36.334 --> 00:34:38.834
They've happened a few times
to App Engine in the past,

00:34:38.834 --> 00:34:40.834
and they will probably
someday happen again.

00:34:40.834 --> 00:34:43.100
Another is that the improbable
is probable

00:34:43.100 --> 00:34:45.934
when you're dealing with a scale
of Google.

00:34:45.934 --> 00:34:49.300
Errors that have
an incredibly small chance

00:34:49.300 --> 00:34:52.267
of happening, say,
memory corruption or CPU bugs,

00:34:52.267 --> 00:34:54.634
things like that,
happen on a regular basis

00:34:54.634 --> 00:34:56.801
when you're dealing with systems
of this scale,

00:34:56.801 --> 00:34:58.767
and you have to think
about them.

00:34:58.767 --> 00:35:00.767
Otherwise, they're gonna
really bite you.

00:35:00.767 --> 00:35:03.267
Fuller: Another thing
we've, um, heard

00:35:03.267 --> 00:35:06.801
from feedback from our users
is that consistent performance

00:35:06.801 --> 00:35:09.267
is typically better
than low latency,

00:35:09.267 --> 00:35:11.501
because low latency
plus inconsistent performance

00:35:11.501 --> 00:35:14.501
is not something
you can plan for.

00:35:14.501 --> 00:35:18.400
Uh, typically, applications that
are built in the master/slave

00:35:18.400 --> 00:35:21.400
expect the consistent behavior
that they experience

00:35:21.400 --> 00:35:23.367
when they test
their applications.

00:35:23.367 --> 00:35:25.934
And when you experience
these local failures,

00:35:25.934 --> 00:35:28.367
you will get random
deadlines exceeded,

00:35:28.367 --> 00:35:30.868
and it will kind of
speckle through--

00:35:30.868 --> 00:35:34.434
those errors will speckle
through all your request logs.

00:35:34.434 --> 00:35:37.033
And one important thing

00:35:37.033 --> 00:35:39.701
that we've actually heard back
from developers

00:35:39.701 --> 00:35:43.367
is that if they know the latency
is gonna be slower

00:35:43.367 --> 00:35:45.868
yet consistent, they can
typically program around that

00:35:45.868 --> 00:35:47.901
and make accommodations
for that,

00:35:47.901 --> 00:35:50.901
so consistency is generally
better in these cases.

00:35:50.901 --> 00:35:52.901
Wilder: So another thing

00:35:52.901 --> 00:35:56.334
is the more that we can
automatically handle failures,

00:35:56.334 --> 00:35:58.334
the less downtime we have
for our users

00:35:58.334 --> 00:36:00.334
and the less work
we have operationally

00:36:00.334 --> 00:36:02.067
to keep the service running.

00:36:02.067 --> 00:36:05.567
A human being is a lot slower
at pushing a button

00:36:05.567 --> 00:36:07.734
responding to an event
than a computer is.

00:36:07.734 --> 00:36:10.567
And if the computer can respond
to that event

00:36:10.567 --> 00:36:14.334
by failing over or doing
something to avoid the error

00:36:14.334 --> 00:36:16.501
that's happened, um, seamlessly,

00:36:16.501 --> 00:36:18.834
then we can hide that error
from our users

00:36:18.834 --> 00:36:21.167
and present
a consistent experience.

00:36:21.167 --> 00:36:23.767
Fuller: And another benefit
of this

00:36:23.767 --> 00:36:27.400
is that we can focus on more
features for our developers,

00:36:27.400 --> 00:36:29.701
such as Next Gen queries,

00:36:29.701 --> 00:36:33.367
if any of you remember that talk
from last year.

00:36:33.367 --> 00:36:35.434
I don't know.
[laughs]

00:36:35.434 --> 00:36:37.501
Um, and one thing
we really notice

00:36:37.501 --> 00:36:40.033
is that unavailability
is never good.

00:36:40.033 --> 00:36:42.100
Small percentages
at Google scales

00:36:42.100 --> 00:36:44.400
have a big impact
on--on many apps,

00:36:44.400 --> 00:36:47.367
um, so that when these
local failures happen,

00:36:47.367 --> 00:36:49.701
they typically affect,
uh, an app

00:36:49.701 --> 00:36:51.901
to a large degree,

00:36:51.901 --> 00:36:54.234
even though it doesn't affect
the entire cluster.

00:36:54.234 --> 00:36:55.634
And these types of problems--

00:36:55.634 --> 00:36:57.801
well, they're important to us
to fix,

00:36:57.801 --> 00:37:00.834
because we want every app
to--to have a good experience

00:37:00.834 --> 00:37:03.400
on App Engine,
and we hope that the master--

00:37:03.400 --> 00:37:06.434
the high replication datastore
will address these issues.

00:37:06.434 --> 00:37:08.100
So as a recap,

00:37:08.100 --> 00:37:10.567
the high replication datastore
is, uh,

00:37:10.567 --> 00:37:12.567
has a slightly higher
write latency,

00:37:12.567 --> 00:37:15.000
is slightly less
globally consistent,

00:37:15.000 --> 00:37:18.000
which is in that one case
of global queries,

00:37:18.000 --> 00:37:20.901
um, and it--but it's
incredibly fault-tolerant.

00:37:20.901 --> 00:37:23.601
So we have designed it to be
geographically distributed,

00:37:23.601 --> 00:37:26.801
and it's resilient in the face
of catastrophic failure.

00:37:26.801 --> 00:37:30.501
And we think that, uh, it will
get you a lot more 9's.

00:37:30.501 --> 00:37:33.067
And, uh, from--since launch,

00:37:33.067 --> 00:37:35.767
we actually--we really believe
this so much

00:37:35.767 --> 00:37:38.133
that we're gonna set it
as a default

00:37:38.133 --> 00:37:39.634
as we announced yesterday,

00:37:39.634 --> 00:37:41.200
and we're also
lowering the price

00:37:41.200 --> 00:37:42.767
to match that of master/slave,

00:37:42.767 --> 00:37:45.000
'cause we really feel strongly
in this product.

00:37:45.000 --> 00:37:47.934
[applause]

00:37:51.567 --> 00:37:53.567
Wilder: So what's next?

00:37:53.567 --> 00:37:55.934
Um, well, we may
have convinced you

00:37:55.934 --> 00:37:58.601
to use the high replication
datastore with this talk.

00:37:58.601 --> 00:38:01.234
And you may have an application
and say "Wow, this is great.

00:38:01.234 --> 00:38:02.901
"Well, I have
a master/slave application.

00:38:02.901 --> 00:38:04.801
I want to migrate to
the high replication datastore."

00:38:04.801 --> 00:38:07.300
So we have a procedure
for doing this now.

00:38:07.300 --> 00:38:10.434
It requires a read-only period
while we copy your data

00:38:10.434 --> 00:38:12.167
from the master/slave datastore

00:38:12.167 --> 00:38:13.801
to the high replication
datastore.

00:38:13.801 --> 00:38:15.501
This can be slightly less ideal

00:38:15.501 --> 00:38:18.033
for applications that have
a large amount of data.

00:38:18.033 --> 00:38:21.801
So we're really hard at work
on some new migration tools

00:38:21.801 --> 00:38:23.567
that will dramatically
improve this

00:38:23.567 --> 00:38:25.868
and dramatically reduce
the amount of read-only period

00:38:25.868 --> 00:38:27.701
you will need to migrate
your application,

00:38:27.701 --> 00:38:30.701
and you can expect those
to come out really soon.

00:38:30.701 --> 00:38:32.934
Fuller: So that being said,

00:38:32.934 --> 00:38:35.067
that we want you
to migrate over,

00:38:35.067 --> 00:38:37.033
and we think it's better
for everyone,

00:38:37.033 --> 00:38:39.334
let's talk about
what you have to do to--

00:38:39.334 --> 00:38:43.067
in terms of your app's logic to
deal with eventual consistency

00:38:43.067 --> 00:38:45.133
that you see in global queries.

00:38:45.133 --> 00:38:47.834
So the first thing you have
to do is a code audit

00:38:47.834 --> 00:38:50.367
for all global queries, queries
without ancestors in them,

00:38:50.367 --> 00:38:53.033
um, 'cause everything else
is strongly consistent,

00:38:53.033 --> 00:38:55.734
and you can rely on that it will
operate the exact same way

00:38:55.734 --> 00:38:58.234
it's operated before in
the master/slave datastore.

00:38:58.234 --> 00:39:00.934
And these global queries
that you look for

00:39:00.934 --> 00:39:03.734
shouldn't just be the ones that
are immediately after a put,

00:39:03.734 --> 00:39:06.067
because when you have
change requests,

00:39:06.067 --> 00:39:07.901
like in a user experience

00:39:07.901 --> 00:39:09.734
and you put something
in one request,

00:39:09.734 --> 00:39:12.267
and you go to the next request,
the user usually expects

00:39:12.267 --> 00:39:14.334
what they have written
to show up immediately.

00:39:14.334 --> 00:39:17.300
So there are many ways to handle
this situation

00:39:17.300 --> 00:39:18.834
once you find these queries.

00:39:18.834 --> 00:39:22.167
The first one that I would
suggest is accept it.

00:39:22.167 --> 00:39:25.901
There are a lot of queries that
don't need strong consistency.

00:39:25.901 --> 00:39:28.667
When you have a write rate
that is incredibly high,

00:39:28.667 --> 00:39:30.667
that it doesn't support
a single entity group,

00:39:30.667 --> 00:39:32.400
in these cases,

00:39:32.400 --> 00:39:35.400
if you don't see the last
hundred milliseconds to seconds,

00:39:35.400 --> 00:39:38.100
which is the type of eventual
consistency we're talking about

00:39:38.100 --> 00:39:39.767
with a high replication
datastore,

00:39:39.767 --> 00:39:41.434
it's not as important.

00:39:41.434 --> 00:39:44.167
So if you have a Twitter stream

00:39:44.167 --> 00:39:45.834
come flooding into your app,

00:39:45.834 --> 00:39:49.400
in these cases, eventual
consistency is acceptable.

00:39:49.400 --> 00:39:51.767
Another thing you can do
is avoid it,

00:39:51.767 --> 00:39:53.767
so you can isolate the cases

00:39:53.767 --> 00:39:57.100
where you actually can,
um, have this limit

00:39:57.100 --> 00:39:59.567
of the write rate
for the entity groups

00:39:59.567 --> 00:40:01.400
and build larger entity groups,

00:40:01.400 --> 00:40:03.734
'cause entity group size
can be arbitrarily big.

00:40:03.734 --> 00:40:05.934
So as long as you trickle it in,

00:40:05.934 --> 00:40:08.100
you don't have to worry about,
uh, you know,

00:40:08.100 --> 00:40:09.767
getting over that, uh,

00:40:09.767 --> 00:40:12.467
you know, how big your
entity group actually is.

00:40:12.467 --> 00:40:15.067
Now one of the most interesting
things you can do,

00:40:15.067 --> 00:40:16.934
um, is work around it.

00:40:16.934 --> 00:40:20.133
And you can do this
by mixing datastore results.

00:40:20.133 --> 00:40:23.367
So in that example
I showed you previously

00:40:23.367 --> 00:40:26.300
where the comments were
clustered under the user

00:40:26.300 --> 00:40:28.801
and we had the blog post
that was separate--

00:40:28.801 --> 00:40:30.400
in a separate entity group,

00:40:30.400 --> 00:40:33.367
if I wanted to show a user
the comments from a blog post,

00:40:33.367 --> 00:40:35.067
I would actually perform
two queries.

00:40:35.067 --> 00:40:38.033
One query would be
a strongly consistent query

00:40:38.033 --> 00:40:40.033
that has the user
as an ancestor,

00:40:40.033 --> 00:40:42.434
so it gives me all
of the user's comments.

00:40:42.434 --> 00:40:46.100
And I know I see most or all
of the user's comments

00:40:46.100 --> 00:40:47.601
that he's posted,

00:40:47.601 --> 00:40:49.767
and the other one that grabs
everyone else's comments,

00:40:49.767 --> 00:40:51.567
because it's really important

00:40:51.567 --> 00:40:53.434
that the user sees
his own comments.

00:40:53.434 --> 00:40:55.901
But if he doesn't see the last--
the comments that were posted

00:40:55.901 --> 00:40:57.634
in the last hundred
milliseconds,

00:40:57.634 --> 00:41:00.234
it's not that big of a deal
in these situations.

00:41:00.234 --> 00:41:02.601
So you really have to look
at your app

00:41:02.601 --> 00:41:06.234
and decide what one of
these methods do you use where.

00:41:06.234 --> 00:41:08.400
Another option here
is you can use Memcache

00:41:08.400 --> 00:41:10.901
to store writes
to have a write cache

00:41:10.901 --> 00:41:13.901
and inject those into
your datastore query results,

00:41:13.901 --> 00:41:16.400
as well.

00:41:16.400 --> 00:41:18.400
So that's it.

00:41:18.400 --> 00:41:21.267
Um, we're open for questions.

00:41:21.267 --> 00:41:24.200
[applause]

00:41:32.200 --> 00:41:34.534
Wilder: I guess it's
the front mic. I don't know.

00:41:34.534 --> 00:41:38.200
Fuller: Yeah. Robert.

00:41:38.200 --> 00:41:40.200
Robert: So about Next Gen--No.
Wilder: [laughs]

00:41:40.200 --> 00:41:43.801
Robert: Um, so I have
a hopefully easy question.

00:41:43.801 --> 00:41:46.467
If you do a batch get

00:41:46.467 --> 00:41:48.133
across entity groups,

00:41:48.133 --> 00:41:50.167
and you do it
with eventually consistent--

00:41:50.167 --> 00:41:53.734
you know, if you set up the RPC
eventually consistent,

00:41:53.734 --> 00:41:57.634
will that cause the tablet
that winds up getting hit

00:41:57.634 --> 00:42:00.901
to catch up if it's late?
So it'll--I know it'll fetch

00:42:00.901 --> 00:42:02.701
and return what's there.
Fuller: Yeah.

00:42:02.701 --> 00:42:04.701
Robert: But does it initiate
the catch-up sequence

00:42:04.701 --> 00:42:06.534
in the background?
Fuller: So you--you still

00:42:06.534 --> 00:42:08.834
have a benefit of doing
eventually consistent reads

00:42:08.834 --> 00:42:10.501
in the high replication
datastore.

00:42:10.501 --> 00:42:12.601
It will not catch up
the replica, and always just

00:42:12.601 --> 00:42:14.934
pick the fastest in that case.
Robert: Okay.

00:42:14.934 --> 00:42:16.934
Fuller: So you're guaranteed
to have a little boost

00:42:16.934 --> 00:42:18.501
in many cases. Uh--

00:42:18.501 --> 00:42:20.501
Wilder: The reason for this
is that we don't know

00:42:20.501 --> 00:42:22.501
what the entity group is
if it's spanning entity groups.

00:42:22.501 --> 00:42:24.501
Fuller: Oh, this
is different, though.

00:42:24.501 --> 00:42:26.501
Wilder: Oh, sorry. [chuckles]
Fuller: So yeah.

00:42:26.501 --> 00:42:29.000
This is for batch gets. Yeah.
Wilder: Batch get, oh, okay.

00:42:29.000 --> 00:42:31.000
Robert: Yes. Yep. Okay, cool.
Wilder: Thanks.

00:42:31.000 --> 00:42:34.200
man: Is there any information
or ways to control

00:42:34.200 --> 00:42:35.801
where the data goes

00:42:35.801 --> 00:42:38.534
and especially for the case
of Megastore,

00:42:38.534 --> 00:42:40.601
if you start running paxos

00:42:40.601 --> 00:42:42.601
across, say,
the Atlantic Ocean,

00:42:42.601 --> 00:42:44.667
um...

00:42:44.667 --> 00:42:47.501
Wilder: So we--we don't
currently offer

00:42:47.501 --> 00:42:49.501
any sort of um,

00:42:49.501 --> 00:42:53.133
uh, different geographic
distributions for our data.

00:42:53.133 --> 00:42:55.434
man: Okay, so it runs
in a single datacenter?

00:42:55.434 --> 00:42:57.434
Fuller: No.
Wilder: No. So we have one set

00:42:57.434 --> 00:42:59.434
of specifics...
Fuller: Ev--

00:42:59.434 --> 00:43:02.200
Wilder: One geographic set
of distributed data bases--

00:43:02.200 --> 00:43:05.267
or datacenters, but we don't
offer any sort of locality.

00:43:05.267 --> 00:43:08.267
Fuller: So we--they each run
in a different datacenter,

00:43:08.267 --> 00:43:10.734
and all datacenters are
currently in North America.

00:43:10.734 --> 00:43:12.734
man: Okay.
Wilder: Yeah, right.

00:43:12.734 --> 00:43:16.300
Fuller: But if you want
to have fast operations

00:43:16.300 --> 00:43:19.434
in other places,
you should use caching headers.

00:43:19.434 --> 00:43:22.934
man: Okay, thanks.

00:43:22.934 --> 00:43:25.934
man: One question I had.
Wilder: Oh, go ahead.

00:43:25.934 --> 00:43:27.601
man: When you mentioned
about the tablets

00:43:27.601 --> 00:43:30.901
and how it stores the data in
the tablets and splits that,

00:43:30.901 --> 00:43:32.400
what's the decision path

00:43:32.400 --> 00:43:34.400
about what data gets stored
in what tablet where

00:43:34.400 --> 00:43:37.234
and how does it know
what tablet to go get it from?

00:43:37.234 --> 00:43:39.234
Wilder: So all this is built
into Bigtable, basically.

00:43:39.234 --> 00:43:41.267
Fuller: [whispers]
Repeat the question.

00:43:41.267 --> 00:43:44.701
Wilder: Oh, the question was,
How does the tablet logic work?

00:43:44.701 --> 00:43:47.400
How does it know where to fetch
the data and when to split,

00:43:47.400 --> 00:43:48.968
stuff like that?

00:43:48.968 --> 00:43:51.067
So it's all part
of the Bigtable service.

00:43:51.067 --> 00:43:54.000
Um, there's many data
and things involved,

00:43:54.000 --> 00:43:56.801
uh, that is updated
when these things happen,

00:43:56.801 --> 00:43:59.467
which is part of the reason why
there's brief unavailability,

00:43:59.467 --> 00:44:00.968
is because the tablet moves,

00:44:00.968 --> 00:44:02.901
and certain things
have to be updated,

00:44:02.901 --> 00:44:05.400
and that takes just a little bit
of time to happen.

00:44:05.400 --> 00:44:08.000
man: So is it like a hash off of
the key or something like that?

00:44:08.000 --> 00:44:10.000
Wilder: I can't
really comment much

00:44:10.000 --> 00:44:12.000
on the specific implementation.
man: Okay, thanks.

00:44:12.000 --> 00:44:13.968
Fuller: [normal voice]
There's some Bigtable papers.

00:44:13.968 --> 00:44:16.434
I don't know if they actually go
into that much detail,

00:44:16.434 --> 00:44:17.934
but they're a nice read...
Wilder: Yeah.

00:44:17.934 --> 00:44:19.434
Fuller: If you're
really interested

00:44:19.434 --> 00:44:21.000
in that level.
man: Okay.

00:44:21.000 --> 00:44:23.000
Fuller: There's also a Megastore
paper that is very accessible,

00:44:23.000 --> 00:44:26.234
and I would really recommend
anyone who is interested

00:44:26.234 --> 00:44:28.067
in the exact details
of this algorithm--

00:44:28.067 --> 00:44:31.701
This was a very, uh,
glossed overview

00:44:31.701 --> 00:44:34.200
of what actually happens
in terms of writes.

00:44:34.200 --> 00:44:35.701
And so if you're interested,

00:44:35.701 --> 00:44:37.667
I highly recommend checking out
that paper.

00:44:37.667 --> 00:44:41.000
man: For the, uh,
high replication datastore

00:44:41.000 --> 00:44:42.834
writing to the majority
of datacenters,

00:44:42.834 --> 00:44:44.667
how many datacenters
are we talking about?

00:44:44.667 --> 00:44:46.801
Is that something...
Wilder: More than two.

00:44:46.801 --> 00:44:49.667
Fuller: So we--we can't tell you
the exact numbers...

00:44:49.667 --> 00:44:52.000
man: Yeah.
Fuller: But it's more than two,

00:44:52.000 --> 00:44:54.868
and we can withstand multiple
datacenters going down.

00:44:54.868 --> 00:44:56.868
man: Right.
man: I think it's also--

00:44:56.868 --> 00:44:58.868
it's an odd number, right?
Wilder: Yes, it is

00:44:58.868 --> 00:45:01.434
an odd number. Yeah.
[laughter]

00:45:01.434 --> 00:45:04.400
Wilder: It's hard to have a
majority without an odd number.

00:45:04.400 --> 00:45:06.400
man: Um, I wanted to ask

00:45:06.400 --> 00:45:08.801
about the, uh, entity groups.

00:45:08.801 --> 00:45:11.267
Is there a prac--
What are the practical limits

00:45:11.267 --> 00:45:13.267
on how big an entity group
could be?

00:45:13.267 --> 00:45:15.267
I mean, from what you described,
it sounds like

00:45:15.267 --> 00:45:17.400
you can just throw everything
into one entity group...

00:45:17.400 --> 00:45:19.400
Fuller: Yes, it--
man: And obviously,

00:45:19.400 --> 00:45:21.067
that's probably not wise.

00:45:21.067 --> 00:45:23.434
And do those,
uh, limitations change

00:45:23.434 --> 00:45:26.000
with the high replication
datastore?

00:45:26.000 --> 00:45:28.801
Fuller: So the limitation
is just on throughput.

00:45:28.801 --> 00:45:30.801
And J.J.,

00:45:30.801 --> 00:45:33.334
uh, the picture I showed

00:45:33.334 --> 00:45:36.067
of the guy who actually designed
entity groups

00:45:36.067 --> 00:45:38.234
and was kind of the mastermind
behind that

00:45:38.234 --> 00:45:41.334
would suggest to you
that you put all your entities

00:45:41.334 --> 00:45:43.868
and an application
into a single entity group.

00:45:43.868 --> 00:45:46.601
Now we want your application
to scale.

00:45:46.601 --> 00:45:48.834
If you get hit
really hard with traffic,

00:45:48.834 --> 00:45:51.300
and that's good for you
and good for us,

00:45:51.300 --> 00:45:53.567
so we won't make that exact
same recommendation.

00:45:53.567 --> 00:45:55.601
But if you're expecting
a write rate

00:45:55.601 --> 00:45:58.834
of less than one write per
second for your app forever--

00:45:58.834 --> 00:46:00.334
say it's an Enterprise app--

00:46:00.334 --> 00:46:02.667
you can definitely put
all of your data

00:46:02.667 --> 00:46:04.601
into a single entity group.

00:46:06.834 --> 00:46:08.834
Fuller: Okay.
man: One question

00:46:08.834 --> 00:46:11.801
about the, uh,
high replication strategy.

00:46:11.801 --> 00:46:15.901
So how can you decide the global
order for the transaction

00:46:15.901 --> 00:46:18.400
if the transaction comes through
different server--

00:46:18.400 --> 00:46:21.400
I mean, the, no,
in the cluster?

00:46:21.400 --> 00:46:23.234
Fuller: So the question is, uh,

00:46:23.234 --> 00:46:26.234
How can we decide the global
order of transactions

00:46:26.234 --> 00:46:28.067
if they come in
from multiple servers?

00:46:28.067 --> 00:46:30.067
man: Yes. Uh, yes.
Fuller: Yeah, okay.

00:46:30.067 --> 00:46:32.067
She told me
to repeat the question...

00:46:32.067 --> 00:46:34.067
[laughter]

00:46:34.067 --> 00:46:36.067
Fuller: Even though
you're miked.

00:46:36.067 --> 00:46:39.901
Um, uh, so, um, before you--

00:46:39.901 --> 00:46:42.801
So we use optimistic locking,
right?

00:46:42.801 --> 00:46:44.400
So what happens is

00:46:44.400 --> 00:46:48.033
the transaction will start
on both, uh, replicas,

00:46:48.033 --> 00:46:51.501
but only one will succeed if
they're happening concurrently.

00:46:51.501 --> 00:46:53.534
So the serial consistency
is enforced

00:46:53.534 --> 00:46:56.133
in that we know that only one

00:46:56.133 --> 00:46:58.934
can s--can--can--
succeed in this case.

00:46:58.934 --> 00:47:00.968
And we use optimistic locking,

00:47:00.968 --> 00:47:04.100
because someone who starts
a transaction may die

00:47:04.100 --> 00:47:06.701
or may stop or may never
complete it or may take forever,

00:47:06.701 --> 00:47:09.868
so that we know that we can push
writes through

00:47:09.868 --> 00:47:13.000
even in the case of failure
or long--

00:47:13.000 --> 00:47:15.000
Like if we use
pessimistic locking,

00:47:15.000 --> 00:47:17.167
you would have to wait
for the lock to expire

00:47:17.167 --> 00:47:20.534
if the writer disappears, so we
use this for fault tolerance,

00:47:20.534 --> 00:47:23.334
and it also makes it
so that it works well.

00:47:23.334 --> 00:47:27.434
man: So this part...
[speaking indistinctly]

00:47:27.434 --> 00:47:29.400
or it's...
Wilder: It's part

00:47:29.400 --> 00:47:31.400
of a Megastore.
Fuller: So the--

00:47:31.400 --> 00:47:33.434
So the Prepare and Accept...
man: Mm-hmm.

00:47:33.434 --> 00:47:35.767
Fuller: is what happened,
how it gets around.

00:47:35.767 --> 00:47:39.267
So if you prepare,
and then someone else prepares,

00:47:39.267 --> 00:47:42.934
they, um, they overwrite
your prepare.

00:47:42.934 --> 00:47:45.767
And if you try to get everyone
who agreed to your prepare

00:47:45.767 --> 00:47:47.467
to accept,
you'll get rejected.

00:47:47.467 --> 00:47:49.734
And then we have a backoff

00:47:49.734 --> 00:47:52.234
to make sure that this pattern
doesn't keep on going,

00:47:52.234 --> 00:47:54.434
because the next thing you do
is you try to prepare again.

00:47:54.434 --> 00:47:56.934
So you fight back and forth,
and there's a backoff

00:47:56.934 --> 00:47:58.767
to make sure that this doesn't
go on forever,

00:47:58.767 --> 00:48:00.267
and someone eventually wins.

00:48:00.267 --> 00:48:02.834
man: Thank you.

00:48:02.834 --> 00:48:06.467
man: I have a question about
the performance limitation

00:48:06.467 --> 00:48:08.133
of tablet splitting

00:48:08.133 --> 00:48:10.801
when you have them autonomically
increasing indexed value,

00:48:10.801 --> 00:48:12.334
like a date time stamp.

00:48:12.334 --> 00:48:15.767
Is that less of a problem with
the high replication datastore

00:48:15.767 --> 00:48:17.367
than the master/slave?

00:48:17.367 --> 00:48:19.334
Fuller: Um, I--yes.

00:48:19.334 --> 00:48:22.300
It's still a problem.
So the question is,

00:48:22.300 --> 00:48:25.834
is when you're writing
to the same spot in a table--

00:48:25.834 --> 00:48:29.033
uh, say I'm autonomically
increasing index

00:48:29.033 --> 00:48:30.834
based on a time stamp--

00:48:30.834 --> 00:48:33.534
That creates a hot spot
on the table,

00:48:33.534 --> 00:48:35.467
and the tablet can only split

00:48:35.467 --> 00:48:37.701
in the existing data
that it has,

00:48:37.701 --> 00:48:40.901
and the smallest it can split
is a single row.

00:48:40.901 --> 00:48:43.400
So if you write to a row,
a lot of times,

00:48:43.400 --> 00:48:46.067
you would have a hot spot
that you can actually split.

00:48:46.067 --> 00:48:48.601
But this will limit your
write rate in master/slave

00:48:48.601 --> 00:48:51.400
to empirically about 200 writes
per second

00:48:51.400 --> 00:48:54.067
to that spot in that index.

00:48:54.067 --> 00:48:56.567
Um, and it's a problem

00:48:56.567 --> 00:49:00.400
that Bigtable
can't really resolve for you.

00:49:00.400 --> 00:49:03.033
Um, and so the master/slave--

00:49:03.033 --> 00:49:04.934
what would happen in this case

00:49:04.934 --> 00:49:07.801
is those writes would fail
in one datacenter

00:49:07.801 --> 00:49:09.434
that's getting a lot of traffic,

00:49:09.434 --> 00:49:11.400
and then that traffic
would bleed over

00:49:11.400 --> 00:49:13.934
to the other datacenters
where the write wouldn't fail,

00:49:13.934 --> 00:49:15.567
because the asynchronous
replication

00:49:15.567 --> 00:49:17.400
isn't hammering it as hard.

00:49:17.400 --> 00:49:19.501
So in this case, it will help,

00:49:19.501 --> 00:49:21.367
but it will not solve
the problem.

00:49:21.367 --> 00:49:23.133
To really solve that problem,

00:49:23.133 --> 00:49:25.868
you have to use some sort
of sharding on that index

00:49:25.868 --> 00:49:29.033
to make it, uh, split
among different tablets.

00:49:29.033 --> 00:49:32.501
Wilder: Yeah, it'll help
for a while, but eventually,

00:49:32.501 --> 00:49:34.567
all of the replicas
will have this same problem.

00:49:34.567 --> 00:49:36.400
And so you're
just kind of delaying

00:49:36.400 --> 00:49:37.901
the inevitable, basically.

00:49:37.901 --> 00:49:40.734
Fuller: But, you know, you get
up to 400 instead of 200...

00:49:40.734 --> 00:49:42.934
Wilder: Yeah. [chuckles]
Fuller: or 600 instead of 200,

00:49:42.934 --> 00:49:44.534
but I don't know
the exact numbers,

00:49:44.534 --> 00:49:46.534
and the numbers
that I am saying right now

00:49:46.534 --> 00:49:48.667
are definitely empirical

00:49:48.667 --> 00:49:51.767
that I heard from Brett Slatkin

00:49:51.767 --> 00:49:53.767
who runs PubSubHubbub.
man: [chuckles]

00:49:53.767 --> 00:49:56.901
man: All right, thank you.
Fuller: Yeah.

00:49:56.901 --> 00:49:59.667
man: Um, along the same lines

00:49:59.667 --> 00:50:02.801
of the guy asking about entity
groups and recommendations,

00:50:02.801 --> 00:50:05.467
do you guys
have any documentation

00:50:05.467 --> 00:50:09.167
about, um, the best use
of entity groups

00:50:09.167 --> 00:50:12.167
or any recommendations
about how to group your data,

00:50:12.167 --> 00:50:15.534
um, aside from coming
to Google I/O

00:50:15.534 --> 00:50:17.200
or watching the videos?

00:50:17.200 --> 00:50:19.701
'Cause that's the only place
I've been able to find it

00:50:19.701 --> 00:50:21.200
in the past.

00:50:21.200 --> 00:50:23.534
Fuller: I think
that's a very good point.

00:50:23.534 --> 00:50:26.534
I think we should improve
our documentation around this,

00:50:26.534 --> 00:50:28.801
and I know that, um, we are--

00:50:28.801 --> 00:50:31.868
There's several people who are
try to do that internally.

00:50:31.868 --> 00:50:33.868
The Megastore paper
is a good resource,

00:50:33.868 --> 00:50:35.834
and my recommendation would be

00:50:35.834 --> 00:50:38.701
to look at the throughput
you need and base it on that.

00:50:38.701 --> 00:50:41.167
And usually, well,
you can think about this

00:50:41.167 --> 00:50:43.934
is a lot of micro databases.

00:50:43.934 --> 00:50:45.934
Each entity group
is like a micro database.

00:50:45.934 --> 00:50:47.934
and so from the example I gave,

00:50:47.934 --> 00:50:50.367
the micro database is based
around a user, right?

00:50:50.367 --> 00:50:53.567
So where the user really cares
about that consistency,

00:50:53.567 --> 00:50:55.701
whereas the interactions
between you--

00:50:55.701 --> 00:50:57.701
there can be a little less.

00:50:57.701 --> 00:50:59.501
Uh...

00:50:59.501 --> 00:51:02.267
You know, it can get a little
looser around that consistency,

00:51:02.267 --> 00:51:05.634
so...

00:51:05.634 --> 00:51:09.067
Oh, and Anderson?
Wilder: Dan Sanderson.

00:51:09.067 --> 00:51:11.334
Fuller: Sanderson. Yeah,
Dan Sanderon's App Engine book

00:51:11.334 --> 00:51:15.567
apparently goes into talking
about this, as well.

00:51:15.567 --> 00:51:18.567
man: Yeah, I have some question
about this writing part.

00:51:18.567 --> 00:51:20.067
Fuller: Mm-hmm.
man: Uh, I read

00:51:20.067 --> 00:51:22.067
those Google file systems,
and they usually--

00:51:22.067 --> 00:51:24.567
when you write, usually
they kind of serial write.

00:51:24.567 --> 00:51:26.267
When you write one,

00:51:26.267 --> 00:51:29.400
and then they will just write
replica each other like that.

00:51:29.400 --> 00:51:32.601
When I see your,
uh, presentation,

00:51:32.601 --> 00:51:35.133
it looks like one
write application

00:51:35.133 --> 00:51:37.934
talk to all the replica
at the same time.

00:51:37.934 --> 00:51:40.100
Is it like do you change it,

00:51:40.100 --> 00:51:43.868
or you are using some kind of
group communication to do that?

00:51:43.868 --> 00:51:46.567
Or is it just the serial still?

00:51:46.567 --> 00:51:48.400
Fuller: We use--
we write asynchronous--

00:51:48.400 --> 00:51:51.000
Or we write in parallel
to multiple datacenters...

00:51:51.000 --> 00:51:53.501
man: Mm-hmm. Mm-hmm.

00:51:53.501 --> 00:51:55.501
Fuller: Using
inter datacenter band width.

00:51:55.501 --> 00:51:57.067
So we go around
these boundaries,

00:51:57.067 --> 00:52:00.367
but inside the datacenter
is probably--

00:52:00.367 --> 00:52:02.067
I can't really speak to it.

00:52:02.067 --> 00:52:04.300
man: But usually in datacenter,

00:52:04.300 --> 00:52:07.300
they have closer locality,
right?

00:52:07.300 --> 00:52:10.334
so I saw in Google...
[indistinct] version 1,

00:52:10.334 --> 00:52:13.334
they're just using
one close replica,

00:52:13.334 --> 00:52:15.901
and then that replica will find
their neighbors, like that.

00:52:15.901 --> 00:52:17.901
Fuller: Yeah, so--
man: And then the final

00:52:17.901 --> 00:52:19.901
will return, say,
everything complete.

00:52:19.901 --> 00:52:22.267
That was what I understood,
but is it--

00:52:22.267 --> 00:52:25.267
Fuller: So that would happen
inside a single datacenter,

00:52:25.267 --> 00:52:28.734
but we--we write to multiple
of them, right?

00:52:28.734 --> 00:52:30.734
man: Yeah, but, I mean--
Fuller: So on that level,

00:52:30.734 --> 00:52:34.033
I don't know exactly how it
works, but it sounds reasonable.

00:52:34.033 --> 00:52:36.534
man: Yeah, so I was just
wondering if you change it

00:52:36.534 --> 00:52:38.334
or if you change it,

00:52:38.334 --> 00:52:41.067
then the underlying should be
a lot of different things

00:52:41.067 --> 00:52:42.734
need to be done.
Fuller: Yeah, so, um...

00:52:42.734 --> 00:52:46.601
Wilder: So the underlying stuff
is a little bit different,

00:52:46.601 --> 00:52:48.934
um, but, um,

00:52:48.934 --> 00:52:51.100
we haven't really released
any information

00:52:51.100 --> 00:52:53.667
about how it's different,
so I can't really comment much.

00:52:53.667 --> 00:52:56.167
Fuller: Yeah.
man: Yeah, but I read some paper

00:52:56.167 --> 00:52:58.934
about this Google file system
you've probably seen.

00:52:58.934 --> 00:53:03.000
Fuller: Yeah. So we're using
another version of that

00:53:03.000 --> 00:53:04.701
that's similar but not the same.

00:53:04.701 --> 00:53:07.534
Wilder: The primary difference
that we've actually talked about

00:53:07.534 --> 00:53:09.501
is that the original one
had a single master,

00:53:09.501 --> 00:53:11.501
and this one has multi master.
man: Okay.

00:53:11.501 --> 00:53:13.501
Wilder: That's
the primary difference.

00:53:13.501 --> 00:53:15.434
man: Yeah, okay. Thank you.

00:53:17.000 --> 00:53:19.000
Fuller: Any more questions?

00:53:21.234 --> 00:53:24.234
Fuller: Well, I guess that's it.
Well, thank you all for coming.

00:53:24.234 --> 00:53:26.167
[applause]
Wilder: THANK YOU.

