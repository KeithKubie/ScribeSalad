WEBVTT
Kind: captions
Language: en

00:00:03.120 --> 00:00:05.800
Hi, I’m Carrie Anne, and welcome to CrashCourse
Computer Science!

00:00:05.800 --> 00:00:10.380
Over the past five episodes, we’ve worked
up from text-based teletype interfaces to

00:00:10.380 --> 00:00:15.910
pixelated bitmapped graphics. Then, last episode,
we covered Graphical User Interfaces and all

00:00:15.910 --> 00:00:17.100
their “Ooey Gooey” richness.

00:00:17.100 --> 00:00:21.850
All of these examples have been 2D. But of
course “we are living in a 3D world, and

00:00:21.850 --> 00:00:23.180
I’m a 3 dimensional girl!”

00:00:23.180 --> 00:00:27.860
So today, we're going to talk about some fundamental
methods in 3D computer graphics and how you

00:00:27.860 --> 00:00:29.480
render them onto a 2D screen.

00:00:29.600 --> 00:00:38.940
INTRO

00:00:38.940 --> 00:00:44.960
As we discussed in episode 24 we can write functions that draw a line between any two points like A and B.

00:00:44.960 --> 00:00:49.780
By manipulating the X and Y coordinates of
points A and B, we can manipulate the line.

00:00:49.780 --> 00:00:55.050
In 3D graphics, points have not just two coordinates,
but three -- X, Y and Z. Or “zee” but

00:00:55.050 --> 00:00:56.220
I’m going to say “zed”.

00:00:56.220 --> 00:01:01.219
Of course, we don’t have X/Y/Z coordinates
on a 2D computer screen, so graphics algorithms

00:01:01.219 --> 00:01:05.260
are responsible for “flattening” 3D coordinates
onto a 2D plane.

00:01:05.260 --> 00:01:09.780
This process is known as 3D Projection. Once
all of the points have been converted from

00:01:09.780 --> 00:01:15.540
3D to 2D, we can use the regular 2D line drawing
function to connect the dots… literally.

00:01:15.540 --> 00:01:17.470
This is called Wireframe Rendering.

00:01:17.470 --> 00:01:21.500
Imagine building a cube out of chopsticks,
and shining a flashlight on it. The shadow

00:01:21.500 --> 00:01:25.890
it casts onto your wall – its projection
– is flat. If you rotate the cube around,

00:01:25.890 --> 00:01:29.940
you can see it’s a 3D object, even though
it’s a flat projection.

00:01:29.940 --> 00:01:34.770
This transformation from 3D to 2D is exactly
what your computer is doing, just with a lot

00:01:34.770 --> 00:01:36.810
more math… and less chopsticks.

00:01:36.810 --> 00:01:41.270
There are several types of 3D Projection.
What you’re seeing right now is an Orthographic

00:01:41.270 --> 00:01:46.020
Projection, where, for example, the parallel
sides in the cube appear as parallel in the

00:01:46.020 --> 00:01:47.020
projection.

00:01:47.020 --> 00:01:50.910
In the real 3D world through, parallel lines
converge as they get further from the viewer,

00:01:50.910 --> 00:01:56.040
like a road going to the horizon. This type
of 3D projection is called Perspective Projection.

00:01:56.040 --> 00:02:00.950
It’s the same process, just with different
math. Sometimes you want perspective and sometimes

00:02:00.950 --> 00:02:03.610
you don’t -- the choice is up to the developer.

00:02:03.610 --> 00:02:08.649
Simple shapes, like cubes, are easily defined
by straight lines. But for more complex shapes,

00:02:08.649 --> 00:02:11.800
triangles are better -- what are called polygons
in 3D graphics.

00:02:11.800 --> 00:02:16.400
Look at this beautiful teapot made out of
polygons. A collection of polygons like this

00:02:16.409 --> 00:02:17.409
is a mesh.

00:02:17.409 --> 00:02:21.239
The denser the mesh, the smoother the curves
and the finer the details. But, that also

00:02:21.239 --> 00:02:24.819
increases the polygon count, which means more
work for the computer.

00:02:24.819 --> 00:02:29.819
Game designers have to carefully balance model
fidelity vs. polygon count, because if the

00:02:29.819 --> 00:02:34.599
count goes too high, the framerate of an animation
drops below what users perceive as smooth.

00:02:34.599 --> 00:02:37.999
For this reason, there are algorithms for
simplifying meshes.

00:02:37.999 --> 00:02:42.319
The reason triangles are used, and not squares,
or polygons, or some other more complex shape

00:02:42.319 --> 00:02:46.900
is simplicity: three points in space unambiguously
define a plane.

00:02:46.900 --> 00:02:51.629
If you give me three points in a 3D space,
I can draw a plane through it - there is only

00:02:51.629 --> 00:02:52.879
one.. single.. answer.

00:02:52.879 --> 00:02:57.049
This isn’t guaranteed to be true for shapes
with four or more points. Also, two points

00:02:57.049 --> 00:03:01.489
aren’t enough to define a plane, only a
line, so three is the perfect and minimal

00:03:01.489 --> 00:03:03.599
number. Triangles for the win!

00:03:03.599 --> 00:03:08.180
Wireframe rendering is cool and all – sorta
retro – but of course 3D graphics can also

00:03:08.180 --> 00:03:09.180
be filled.

00:03:09.180 --> 00:03:13.799
The classic algorithm for doing this is called
Scanline Rendering, first developed in 1967

00:03:13.799 --> 00:03:19.090
at the University of Utah. For a simple example,
let’s consider just one polygon.

00:03:19.090 --> 00:03:23.519
Our job here is to figure out how this polygon
translates to filled pixels on a computer

00:03:23.519 --> 00:03:26.500
screen, so let’s first overlay a grid of
pixels to fill.

00:03:26.500 --> 00:03:30.799
The scanline algorithm starts by reading the
three points that make up the polygon, and

00:03:30.799 --> 00:03:35.189
finding the lowest and highest Y values. It
will only consider rows between these two

00:03:35.189 --> 00:03:36.189
points.

00:03:36.189 --> 00:03:40.060
Then, the algorithm works down one row at
a time. In each row, it calculates where a

00:03:40.060 --> 00:03:44.459
line – running through the center of a row
– intersects with the side of the polygon.

00:03:44.459 --> 00:03:49.340
Because polygons are triangles, if you intersect
one line, you have to intersect with another.

00:03:49.340 --> 00:03:53.709
It’s guaranteed! The job of the scanline
algorithm is to fill in the pixels between

00:03:53.709 --> 00:03:56.400
the two intersections. Let’s see how this
works.

00:03:56.400 --> 00:03:59.569
On the first row we look at we intersect here
and here.

00:03:59.569 --> 00:04:03.349
The algorithm then colors in all pixels between
those two intersections.

00:04:03.349 --> 00:04:08.090
And this just continues, row by row, which
is why it’s called Scan... Line... Rendering.

00:04:08.090 --> 00:04:11.730
When we hit the bottom of the polygon, we’re
done. The rate at which a computer fills in

00:04:11.730 --> 00:04:13.779
polygons is called the fillrate.

00:04:13.779 --> 00:04:18.290
Admittedly, this is a pretty ugly filled polygon.
It has what are known as “Jaggies” -- those

00:04:18.290 --> 00:04:23.110
rough edges. This effect is less pronounced
when using smaller pixels. But nonetheless,

00:04:23.110 --> 00:04:26.770
you see these in games all the time, especially
on lower powered platforms.

00:04:26.770 --> 00:04:31.160
One method to soften this effect is Antialiasing.
Instead of filling pixels in a polygon with

00:04:31.160 --> 00:04:35.729
the same color, we can adjust the color based
on how much the polygon cuts through each

00:04:35.729 --> 00:04:36.729
pixel.

00:04:36.729 --> 00:04:40.910
If a pixel is entirely inside of a polygon,
it gets fully colored. But if the polygon

00:04:40.910 --> 00:04:45.319
only grazes a pixel, it’ll get a lighter
shade. This feathering of the edges is much

00:04:45.319 --> 00:04:46.879
more pleasant to the eyes.

00:04:46.879 --> 00:04:52.060
Antialiasing is used all over the place, including
in 2D graphics, like fonts and icons. If you

00:04:52.060 --> 00:04:55.389
lean in real close to your monitor.. Closer…
closer…. Closer!

00:04:55.389 --> 00:04:59.140
You’ll see all the fonts in your browser
are Antialiased. So smooth!

00:04:59.140 --> 00:05:03.789
In a 3D scene, there are polygons that are
part objects in the back, near the front,

00:05:03.789 --> 00:05:08.330
and just about everywhere. Only some are visible,
because some objects are hidden behind other

00:05:08.330 --> 00:05:10.960
objects in the scene -- what’s called occlusion.

00:05:10.960 --> 00:05:14.930
The most straightforward way to handle this
is to use a sort algorithm, and arrange all

00:05:14.930 --> 00:05:19.060
the polygons in the scene from farthest to
nearest, then render them in that order.

00:05:19.060 --> 00:05:23.240
This is called the Painter's Algorithm, because
painters also have to start with the background,

00:05:23.240 --> 00:05:25.960
and then increasingly work up to foreground
elements.

00:05:25.960 --> 00:05:29.120
Consider this example scene with three overlapping
polygons.

00:05:29.120 --> 00:05:33.569
To make things easier to follow, we’re going
to color the polygons differently. Also for

00:05:33.569 --> 00:05:38.050
simplicity, we’ll assume these polygons
are all parallel to the screen, but in a real

00:05:38.050 --> 00:05:41.520
program, like a game, the polygons can be
tilted in 3D space.

00:05:41.520 --> 00:05:46.280
Our three polygons, A B and C… are at distance
20, 12 and 14.

00:05:46.280 --> 00:05:49.820
The first thing the Painter’s Algorithm
does is sort all the polygons, from farthest

00:05:49.820 --> 00:05:50.820
to nearest.

00:05:50.820 --> 00:05:55.630
Now that they’re in order, we can use scanline
rendering to fill each polygon, one at a time.

00:05:55.630 --> 00:05:57.840
We start with Polygon A, the farthest one
away.

00:05:57.840 --> 00:06:01.840
Then we repeat the process for the next farthest
polygon, in this case, C.

00:06:01.840 --> 00:06:03.810
And then we repeat this again, for Polygon
B.

00:06:03.810 --> 00:06:08.139
Now we’re all done, and you can see the
ordering is correct. The polygons that are

00:06:08.139 --> 00:06:09.199
closer, are in front!

00:06:09.199 --> 00:06:13.560
An alternative method for handling occlusion
is called Z-Buffering. It achieves the same

00:06:13.560 --> 00:06:15.720
output as before, but with a different algorithm.

00:06:15.720 --> 00:06:20.531
Let’s go back to our previous example, before
it was sorted. That’s because this algorithm

00:06:20.531 --> 00:06:23.460
doesn’t need to sort any polygons, which
makes it faster.

00:06:23.460 --> 00:06:27.949
In short, Z-buffering keeps track of the closest
distance to a polygon for every pixel in the

00:06:27.949 --> 00:06:32.949
scene. It does this by maintaining a Z-Buffer,
which is just a matrix of values that sits

00:06:32.949 --> 00:06:33.949
in memory.

00:06:33.949 --> 00:06:36.470
At first, every pixel is initialized to infinity.

00:06:36.470 --> 00:06:41.289
Then Z-buffering starts with the first polygon
in its list. In this case, that’s A.

00:06:41.289 --> 00:06:45.490
It follows the same logic as the scanline
algorithm, but instead of coloring in pixels,

00:06:45.490 --> 00:06:49.479
it checks the distance of the polygon versus
what’s recorded in its Z-Buffer.

00:06:49.479 --> 00:06:54.260
It records the lower of the two values. For
our Polygon A, with a distance of 20, it wins

00:06:54.260 --> 00:06:56.210
against infinity every time.

00:06:56.210 --> 00:07:00.120
When it’s done with Polygon A, it moves
on to the next polygon in its list, and the

00:07:00.120 --> 00:07:01.219
same thing happens.

00:07:01.219 --> 00:07:05.000
Now, because we didn’t sort the polygons,
it’s not always the case that later polygons

00:07:05.000 --> 00:07:10.139
overwrite high values. In the case of Polygon
C, only some of the values in the Z-buffer

00:07:10.139 --> 00:07:11.800
get new minimum distances.

00:07:11.800 --> 00:07:16.330
This completed Z-buffer is used in conjunction
with a fancier version of scanline rendering

00:07:16.330 --> 00:07:20.409
that not only tests for line intersection,
but also does a lookup to see if that pixel

00:07:20.409 --> 00:07:25.220
will even be visible in the final scene. If
it’s not, the algorithm skips it and moves

00:07:25.220 --> 00:07:26.220
on.

00:07:26.220 --> 00:07:30.310
An interesting problem arises when two polygons
have the same distance, like if Polygon A

00:07:30.310 --> 00:07:34.849
and B are both at a distance of 20. Which
one do you draw on top?

00:07:34.849 --> 00:07:39.000
Polygons are constantly being shuffled around
in memory and changing their access order.

00:07:39.000 --> 00:07:43.690
Plus, rounding errors are inherent in floating
point computations. So, which one gets drawn

00:07:43.690 --> 00:07:45.270
on top is often unpredictable.

00:07:45.270 --> 00:07:50.240
The result is a flickering effect called Z-Fighting,
which if you’ve played 3D games, you’ve

00:07:50.240 --> 00:07:53.479
no doubt encountered.
Speaking of glitches, another common optimization

00:07:53.479 --> 00:07:55.960
in 3D graphics is called Back-Face Culling.

00:07:55.960 --> 00:08:00.099
If you think about it, a triangle has two
sides, a front and a back. With something

00:08:00.099 --> 00:08:04.090
like the head of an avatar, or the ground
in a game, you should only ever see one side

00:08:04.090 --> 00:08:06.090
-- the side facing outwards.

00:08:06.090 --> 00:08:10.319
So to save processing time, the back-side
of polygons are often ignored in the rendering

00:08:10.319 --> 00:08:14.130
pipeline, which cuts the number of polygon
faces to consider in half.

00:08:14.130 --> 00:08:17.930
This is great, except when there’s a bug
that lets you get inside of those objects,

00:08:17.930 --> 00:08:21.300
and look outwards. Then the avatar head or
ground becomes invisible.

00:08:21.300 --> 00:08:26.090
Moving on. We need to talk about lighting
-- also known as shading -- because if it’s

00:08:26.090 --> 00:08:29.470
a 3D scene, the lighting should vary over
the surface of objects.

00:08:29.470 --> 00:08:31.530
Let’s go back to our teapot mesh.

00:08:31.530 --> 00:08:35.590
With scanline rendering coloring in all the
polygons, our teapot looks like this. Not

00:08:35.590 --> 00:08:36.590
very 3D.

00:08:36.590 --> 00:08:39.300
So, let’s add some lighting to enhance the
realism!

00:08:39.300 --> 00:08:43.200
As an example, we’ll pick 3 polygons from
different parts of our teapot.

00:08:43.200 --> 00:08:47.290
Unlike our previous examples, we’re now
going to consider how these polygons are oriented

00:08:47.290 --> 00:08:52.190
in 3D space -- they’re no longer parallel
to the screen, but rather tilted in different

00:08:52.190 --> 00:08:53.370
3D directions.

00:08:53.370 --> 00:08:57.680
The direction they face is called the Surface
Normal, and we can visualize that direction

00:08:57.680 --> 00:09:01.600
with a little 3D arrow that’s perpendicular
to the polygon’s surface.

00:09:01.600 --> 00:09:03.320
Now let’s add a light source.

00:09:03.320 --> 00:09:07.200
Each polygon is going to be illuminated a
different amount. Some will appear brighter,

00:09:07.200 --> 00:09:10.200
because their angle causes more light to be
reflected towards the viewer.

00:09:10.200 --> 00:09:14.800
For example, the bottom-most polygon is tilted
downwards, away from the light source, which

00:09:14.800 --> 00:09:16.060
means it’s going to be dark.

00:09:16.060 --> 00:09:19.970
In a similar way, the rightmost polygon is
slightly facing away from the light, so it

00:09:19.970 --> 00:09:21.639
will be partially illuminated.

00:09:21.639 --> 00:09:25.540
And finally, there’s the upper-left polygon.
Its angle means that it will reflect light

00:09:25.540 --> 00:09:27.380
from the light source towards our view.

00:09:27.380 --> 00:09:28.850
So, it’ll appear bright.

00:09:28.850 --> 00:09:33.769
If we do this for every polygon, our teapot
looks like this which is much more realistic!

00:09:33.769 --> 00:09:37.800
This approach is called Flat Shading, and
it’s the most basic lighting algorithm.

00:09:37.800 --> 00:09:42.370
Unfortunately, it also makes all those polygon
boundaries really noticeable and the mesh

00:09:42.370 --> 00:09:43.459
doesn’t look smooth.

00:09:43.459 --> 00:09:48.070
For this reason, more advanced lighting algorithms
were developed, such as Gouraud Shading and

00:09:48.070 --> 00:09:53.030
Phong Shading. Instead of coloring in polygons
using just one colour, they vary the colour

00:09:53.030 --> 00:09:56.959
across the surface in clever ways, which results
in much nicer output.

00:09:56.959 --> 00:10:01.350
We also need to talk about textures, which
in graphics refers to the look of a surface,

00:10:01.350 --> 00:10:02.860
rather than its feel.

00:10:02.860 --> 00:10:07.500
Like with lighting, there are many algorithms
with all sorts of fancy effects. The simplest

00:10:07.500 --> 00:10:12.070
is texture mapping. To visualize this process,
let’s go back to our single polygon.

00:10:12.070 --> 00:10:15.950
When we’re filling this in, using scanline
rendering, we can look up what color to use

00:10:15.950 --> 00:10:21.199
at every pixel according to a texture image
saved in memory. To do this, we need a mapping

00:10:21.199 --> 00:10:24.329
between the polygon’s coordinates and the
texture’s coordinates.

00:10:24.329 --> 00:10:27.579
Let’s jump to the first pixel that scanline
rendering needs to fill in.

00:10:27.579 --> 00:10:31.800
The texturing algorithm will consult the texture
in memory, take the average color from the

00:10:31.800 --> 00:10:34.680
corresponding region, and fill the polygon
accordingly.

00:10:34.680 --> 00:10:39.019
This process repeats for all pixels in the
polygon, and that’s how we get textures.

00:10:39.019 --> 00:10:42.589
If you combine all the techniques we’ve
talked about this episode, you get a wonderfully

00:10:42.589 --> 00:10:43.930
funky little teapot.

00:10:43.930 --> 00:10:48.670
And this teapot can sit in an even bigger
scene, comprised of millions of polygons.

00:10:48.670 --> 00:10:52.860
Rendering a scene like this takes a fair amount
of computation. But importantly, it’s the

00:10:52.860 --> 00:10:57.190
same type of calculations being performed
over and over and over again for many millions

00:10:57.190 --> 00:11:02.680
of polygons – scanline filling, antialiasing,
lighting, and texturing. However there are

00:11:02.680 --> 00:11:05.050
a couple of ways to make this much faster!

00:11:05.050 --> 00:11:08.920
First off, we can speed things up by having
special hardware with extra bells and whistles

00:11:08.920 --> 00:11:14.139
just for these specific types of computations,
making them lightning fast. And secondly,

00:11:14.139 --> 00:11:19.149
we can divide up a 3D scene into many smaller
parts, and then render all the pieces in parallel,

00:11:19.149 --> 00:11:20.670
rather than sequentially.

00:11:20.670 --> 00:11:24.850
CPU’s aren’t designed for this, so they
aren’t particularly fast. So, computer engineers

00:11:24.850 --> 00:11:29.980
created special processors just for graphics
– a GPU, or Graphics Processing Unit.

00:11:29.980 --> 00:11:34.519
These can be found on graphics cards inside
of your computer, along with RAM reserved

00:11:34.519 --> 00:11:39.000
for graphics. This is where all the meshes
and textures live, allowing them to be accessed

00:11:39.000 --> 00:11:42.589
super fast by many different cores of the
GPU all at once.

00:11:42.589 --> 00:11:51.110
A modern graphics card, like a GeForce GTX
1080 TI, contains 3584 processing cores, offering

00:11:51.110 --> 00:11:56.019
massive parallelization. It can process hundreds
of millions of polygons every second!

00:11:56.020 --> 00:12:01.660
Ok, that concludes our whistle stop tour of
3D graphics. Next week, we switch topics entirely.

00:12:01.660 --> 00:12:03.360
I’ll ping you then.

