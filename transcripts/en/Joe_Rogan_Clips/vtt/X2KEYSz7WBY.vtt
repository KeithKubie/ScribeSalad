WEBVTT

1
00:00:00.240 --> 00:00:02.130
If you are in that community,

2
00:00:02.640 --> 00:00:07.020
good fucking luck getting out.
Right.
Good luck.
The,

3
00:00:07.030 --> 00:00:10.800
the money that you get other than Welfare's from selling pills,
you know,

4
00:00:10.801 --> 00:00:13.200
everybody's on these pills so you're all whacked out.

5
00:00:13.230 --> 00:00:17.250
You don't know what the fuck is going on.
Half the day you're on opiates.
I mean,

6
00:00:17.251 --> 00:00:21.120
it is a bananas environment and there's a lot of people like that in this

7
00:00:21.121 --> 00:00:25.920
country and in poor Latino communities and poor white communities in poor black

8
00:00:25.921 --> 00:00:26.754
communities.

9
00:00:27.000 --> 00:00:29.400
The idea that these people are just going to pull themselves up by their

10
00:00:29.401 --> 00:00:32.700
bootstraps,
it's crazy.
I just think they don't have a plan.

11
00:00:32.701 --> 00:00:36.000
And I think if we really want to help them there,

12
00:00:36.240 --> 00:00:39.840
there's gotta be some way where you can give these people the opportunity to

13
00:00:39.841 --> 00:00:43.950
step out of that pattern,
whatever that community centers,

14
00:00:43.951 --> 00:00:45.970
outreach programs,
whatever it is.
I don't know what

15
00:00:46.240 --> 00:00:48.850
<v 1>I mean.
The truth is,
the truth is that historically speaking,</v>

16
00:00:48.851 --> 00:00:51.620
it was people actually going to church.
Yeah.
I mean,
and,
and yeah,

17
00:00:52.120 --> 00:00:56.860
<v 0>there's a good lot of good PR church going person.
Right,
right.
Absolutely.</v>

18
00:00:56.861 --> 00:01:00.490
Recognize that there's a lot of good involved and having that framework

19
00:01:00.570 --> 00:01:02.970
<v 1>right.
And,
and that,
that,
I'm not sure that that's,</v>

20
00:01:03.400 --> 00:01:07.950
I don't think you can create sort of a fake social fabric with just a government

21
00:01:07.951 --> 00:01:11.580
welfare system.
Like it just,
it does,
it hasn't worked.
I mean,
disability exists.

22
00:01:11.610 --> 00:01:14.160
I'd been increasing every year.
It's,
it's not this,

23
00:01:14.190 --> 00:01:15.990
it's a question I asked Andrew getting,
actually,
sorry.

24
00:01:15.991 --> 00:01:20.070
Our episode comes out on Sunday and obviously Andrew is a big fan of the ubi,

25
00:01:20.071 --> 00:01:21.000
universal basic income.

26
00:01:21.240 --> 00:01:25.500
And I'm not averse to the idea of ubi in a future where legitimately 50% of the

27
00:01:25.501 --> 00:01:28.080
population can't work because they've all been automated out of existence and

28
00:01:28.081 --> 00:01:28.740
all of this.

29
00:01:28.740 --> 00:01:32.880
But there's one section in his book where Andrea talks about how if we cut

30
00:01:32.881 --> 00:01:34.350
people a check for ubi,

31
00:01:34.380 --> 00:01:39.380
then they will spend their extra time creating art and engaging in hobbies that

32
00:01:39.391 --> 00:01:41.370
they like.
And I just thought to myself,
I'm mean,

33
00:01:41.410 --> 00:01:44.970
set it to him like people are on disability at it,
what they're doing right.

34
00:01:45.010 --> 00:01:47.670
And if you're on disability,
the people you're talking about who are suffering,

35
00:01:48.090 --> 00:01:50.430
they're not out there writing poetry.
Right.
I mean the,
the,

36
00:01:50.431 --> 00:01:55.320
the rise of the opioid epidemic and people who are oding on drugs and and all

37
00:01:55.321 --> 00:01:58.710
this stuff that's in precisely the same demographic you're talking about.

38
00:01:58.711 --> 00:02:01.290
You're just talking about a check from one place as opposed to another place.

39
00:02:01.291 --> 00:02:03.060
I don't,
I don't really see how that solves the problem.

40
00:02:03.270 --> 00:02:06.330
I think we have a crisis of purpose.
Yes.

41
00:02:06.360 --> 00:02:10.230
Right now and I don't think that that crisis is purpose is solvable on the one

42
00:02:10.231 --> 00:02:13.110
hand by changing our trade rules and I also don't think that that crisis is a

43
00:02:13.111 --> 00:02:15.960
purpose is solvable by by cutting a government check.

44
00:02:15.961 --> 00:02:18.790
I just don't think that that's how people are wired.

45
00:02:19.060 --> 00:02:22.150
<v 0>I absolutely agree with you that there is a crisis of purpose.</v>

46
00:02:22.210 --> 00:02:25.030
My concern is about automation and my concern,

47
00:02:25.060 --> 00:02:28.600
and obviously I haven't really studied this other than talking to Andrew Yang

48
00:02:28.601 --> 00:02:32.050
and talking to Ilan mosque and a few other people that are proponents of

49
00:02:32.051 --> 00:02:33.190
universal basic income,

50
00:02:33.191 --> 00:02:36.820
they think that there's going to be such a massive loss of jobs in such a short

51
00:02:36.821 --> 00:02:41.770
period of time from people that are non skilled laborers and it's going to go

52
00:02:41.771 --> 00:02:45.340
away.
There's millions and millions of jobs and these people are not gonna have

53
00:02:45.341 --> 00:02:46.990
anything and that it could be chaos,
right?

54
00:02:47.020 --> 00:02:47.471
<v 1>So there's,</v>

55
00:02:47.471 --> 00:02:50.410
there's two problems that come up there and this is where Andrew's book is

56
00:02:50.411 --> 00:02:53.770
interesting because problem number one is that the people will be poor.

57
00:02:53.771 --> 00:02:55.810
They won't have a source of income.
Yeah,
you'll be ice,
all of that.

58
00:02:56.020 --> 00:02:56.770
The other part of it,

59
00:02:56.770 --> 00:02:58.900
<v 0>but does it even that gives him $1,000 a month</v>

60
00:02:59.020 --> 00:02:59.950
<v 1>if he opted,
right.
I mean,</v>

61
00:02:59.951 --> 00:03:03.240
even even if you just had a Swedish redistribution system and,

62
00:03:03.280 --> 00:03:07.190
and the average tax rate went up to 60% or something,
it might let,

63
00:03:07.191 --> 00:03:10.150
let's say we could solve the money problem for a second,
which,
you know,

64
00:03:10.151 --> 00:03:12.550
without tanking the economy,
which is questionable,

65
00:03:12.670 --> 00:03:13.510
but let's say we could do that.

66
00:03:13.511 --> 00:03:15.820
We could add trillions of dollars to the budget every year,

67
00:03:15.940 --> 00:03:18.880
and we could tell that I'm still not sure that that solves the deeper problem,

68
00:03:18.881 --> 00:03:21.640
which is that when people lose jobs,
they lose purpose,
right?

69
00:03:21.641 --> 00:03:24.910
So I'm not sure that UBI solves that problem.
As I say,
we have,

70
00:03:24.920 --> 00:03:27.970
we have a rich social welfare network in the United States and we're seeing this

71
00:03:27.971 --> 00:03:31.330
stuff happen anyway.
You know,
I'm,
I'm a little bit,

72
00:03:31.570 --> 00:03:33.670
I'm a little bit less catastrophic by a little bit,
I mean,

73
00:03:33.671 --> 00:03:36.310
a fair bit less catastrophic in my thinking about automation than,

74
00:03:36.360 --> 00:03:40.690
than either Andrew Yang or Elon Musk will be able to adapt quick enough to avoid

75
00:03:40.691 --> 00:03:42.850
the problems.
They'll realize the jobs aren't there any more,

76
00:03:42.851 --> 00:03:45.940
and they'll just naturally gravitate towards other professionals.

77
00:03:45.941 --> 00:03:48.010
I think over time that people will do that,

78
00:03:48.011 --> 00:03:50.920
but they're not always the same people or there's always shifts in the economy

79
00:03:50.921 --> 00:03:54.280
and the ideal economic model has a truck or becoming a coder.
Right.
But that's,

80
00:03:54.281 --> 00:03:56.980
that's not real.
That was the whole learn to code fiasco.

81
00:03:57.210 --> 00:04:00.820
People ticked off of Twitter.
Right,
and it still,
yeah,

82
00:04:00.821 --> 00:04:03.340
apparently if you say to journalists,
then that's,
that's very bad.
If you say,

83
00:04:03.341 --> 00:04:06.760
let's go to a truck.
Yeah,
that's what it was.
[inaudible] to code to a trucker.

84
00:04:06.790 --> 00:04:09.730
If you say learn to code to a trucker,
then that's just you being helpful.

85
00:04:09.970 --> 00:04:11.740
If you say learn to code to a journalist,

86
00:04:11.770 --> 00:04:14.740
then that is targeted harassment on Twitter.
That's where that starts is to me,

87
00:04:15.310 --> 00:04:18.310
well I meant were Twitter doesn't care about you.
I can say whatever I want,

88
00:04:20.410 --> 00:04:25.060
but it's a,
but yeah,
I mean I think that,
but if you just say it to a friend,
hey,

89
00:04:25.061 --> 00:04:27.460
fuck face,
learn to code.
They that,
I don't know,

90
00:04:27.461 --> 00:04:30.760
it's your friend could report you to the censorship board over at Twitter.

91
00:04:30.761 --> 00:04:32.520
It's such a dumb thing to take people out for it.

92
00:04:32.521 --> 00:04:37.521
It's one of the best examples of like how censorship oversteps its boundaries

93
00:04:37.571 --> 00:04:42.190
and becomes almost like satire.
Yeah.
It's,
it's real.
It's really,
really absurd.

94
00:04:42.440 --> 00:04:45.700
This is the biggest aggression ever.
Learn to code.
Learn to code.

95
00:04:46.210 --> 00:04:47.043
That's something,
look,

96
00:04:47.320 --> 00:04:50.680
this is a stupid thing that someone said about coal miners.

97
00:04:50.700 --> 00:04:53.950
They readily said that about coal miners that maybe they can learn to code and

98
00:04:53.951 --> 00:04:55.200
so every like what?
Fuck,

99
00:04:55.220 --> 00:04:58.210
and so learn to code became a joke and became something that you would mock

100
00:04:58.211 --> 00:05:01.990
people,
right there is their explanation for it was so crazy.
It was like,
no.

101
00:05:02.050 --> 00:05:06.010
Then learn to code got connected with white supremacists and all this other

102
00:05:06.011 --> 00:05:10.240
stuff.
That's the Hitler owned a dog.
They recommend,
right?
Dogs are bad.

103
00:05:10.241 --> 00:05:13.150
Hitler owned one.
Okay,
white supremacists are bad.
They used the phrase,

104
00:05:13.151 --> 00:05:15.660
learn to code.
That means if you say learn to code,
you're a white supremacist.

105
00:05:15.661 --> 00:05:19.780
Like what?
Tommy lost the frog.
That fucking frog feels good,
man.
Frog.

106
00:05:20.200 --> 00:05:23.050
That's what happened to pepe.
They lie.
They killed the frog.

107
00:05:23.051 --> 00:05:27.420
They turned the front frog gay.
I mean,
what?
Yeah.
Oh yeah.
Yeah.

108
00:05:27.440 --> 00:05:29.770
I mean it's hot as far as automation.
Um,
you know,

109
00:05:30.040 --> 00:05:32.750
there's constantly people saying this is the,

110
00:05:32.751 --> 00:05:35.200
the Nicholas Nassim tell lead view of reality,

111
00:05:35.201 --> 00:05:37.600
which that the Black Swan incident can happen any any second.

112
00:05:37.601 --> 00:05:41.110
So watch out for it.
Versus the sort of Steven pinker view of reality,

113
00:05:41.111 --> 00:05:44.260
which is the black swan incident is called the black swan incident because it's

114
00:05:44.261 --> 00:05:47.560
a black swan incident,
meaning that it happens incredibly rarely the,

115
00:05:47.710 --> 00:05:52.390
the idea that we are on the verge of a catastrophic drop in job numbers because

116
00:05:52.450 --> 00:05:56.530
of the automation of trucking for example.
I'm not sure that I buy it.

117
00:05:56.590 --> 00:05:59.300
The reason I don't buy it is because you still are gonna need someone sitting

118
00:05:59.301 --> 00:06:02.450
behind the wheel of that truck there human drivers on the road.
Uh,
it's going to,

119
00:06:02.480 --> 00:06:06.380
there will be a gradual transition away from some of these jobs with the Andrew

120
00:06:06.381 --> 00:06:09.680
getting talks about radiologists and how radiologists are going to be priced out

121
00:06:09.681 --> 00:06:12.230
of the market by computers that can do a better job of diagnosing tumors,

122
00:06:12.290 --> 00:06:15.080
first of all.
Awesome.
Right?
I mean,
that's,
that's good.

123
00:06:15.350 --> 00:06:19.510
First of all that brings down cost and you won't get cancer is advanced.

124
00:06:19.530 --> 00:06:21.770
That'd be,
that'd be a good thing.
And then second of all,
what,

125
00:06:21.800 --> 00:06:26.030
what a lot of technology studies have had attended to show is that technology

126
00:06:26.031 --> 00:06:28.570
just gets integrated into different Wagan in particular careers.

127
00:06:28.571 --> 00:06:30.710
So there will be jobs that are eliminated for sure.

128
00:06:30.890 --> 00:06:33.020
There'll be jobs we haven't heard of that will be created also.

129
00:06:33.230 --> 00:06:38.230
And mostly technology will will become more of a productivity aid to to people.

130
00:06:38.241 --> 00:06:42.370
So this is true in factories.
Jobs have been lost in factories.

131
00:06:42.380 --> 00:06:44.900
It's the best example of our jobs are lost,
but it's mostly true and offices,

132
00:06:44.901 --> 00:06:47.990
right?
How many office jobs had been created because you have computers?

133
00:06:48.280 --> 00:06:50.330
What's more office jobs exist because I write by hand.

134
00:06:50.400 --> 00:06:53.040
<v 0>Do you think that this is akin to like a government bailout?</v>

135
00:06:53.460 --> 00:06:57.390
Like the idea of the government bailout was like the banks are too big to fail

136
00:06:57.450 --> 00:06:58.830
and some people thought,
you know what,

137
00:06:58.831 --> 00:07:02.880
you got to let them fail so you figure out why they failed and we'll never have

138
00:07:02.881 --> 00:07:06.840
it happen again.
If there is this thing and the government steps in and says,

139
00:07:06.841 --> 00:07:09.480
wait a minute,
I know you lost all your jobs,
we're going to give you $1,000.

140
00:07:09.481 --> 00:07:12.870
You don't have to figure it out $1,000 a month.
And some people go,
okay,

141
00:07:12.871 --> 00:07:14.130
I'm not going to figure it out now.

142
00:07:14.280 --> 00:07:19.280
Whereas those people might have gone on a fear filled journey to try to figure

143
00:07:21.451 --> 00:07:23.620
out their purpose in life because now they're stuck.

144
00:07:23.710 --> 00:07:26.120
They're stuck where their job doesn't exist anymore.
So there

145
00:07:26.840 --> 00:07:28.780
<v 1>what are their owner?
I mean they have to act.
There is,</v>

146
00:07:28.810 --> 00:07:31.310
there is an innovation that comes from,
from a welfare check.

147
00:07:31.311 --> 00:07:33.800
I mean there are people who become dependent on government than they're used to

148
00:07:33.801 --> 00:07:37.390
being dependent on government.
That that stuff is true.
It does happen.
And listen,

149
00:07:37.410 --> 00:07:40.940
Milton Friedman made an argument for universal basic income as a replacement for

150
00:07:40.941 --> 00:07:41.810
the welfare system.

151
00:07:42.410 --> 00:07:45.530
There is another problem with universal basic income that I asked Andrew about

152
00:07:45.531 --> 00:07:50.390
also.
And that was one of the,
one of the big issues is that poor people,

153
00:07:50.420 --> 00:07:52.850
very often people who are permanently impoverished,

154
00:07:52.851 --> 00:07:53.990
not people who are temporarily poor,

155
00:07:54.290 --> 00:07:57.260
but they tend not to spend money where we think they ought to spend money,
right?

156
00:07:57.261 --> 00:08:00.290
They're not taking that money and they're not putting it into education or into

157
00:08:00.291 --> 00:08:03.740
the marches and Ho hos and cigarettes.
The,
the average,

158
00:08:03.770 --> 00:08:08.420
the average person who is making less than,
I think it was $16,000 a year,

159
00:08:08.421 --> 00:08:10.260
we're spending $400 here in lottery tickets.
Right?

160
00:08:10.261 --> 00:08:12.140
But it's legitimately just flushing your money down the toilet.

161
00:08:12.440 --> 00:08:14.360
So it's so how do you,

162
00:08:14.960 --> 00:08:18.050
aren't you just going to end up back in the same place you could in six months

163
00:08:18.080 --> 00:08:21.500
where people took that money and used it in ways that actually didn't benefit

164
00:08:21.501 --> 00:08:24.980
them.
And at a certain point,
the question is,
are your,
do you own your decisions?

165
00:08:24.981 --> 00:08:26.060
You do not own your decisions.

166
00:08:26.061 --> 00:08:30.770
And at what level of incompetence or inability do we say you no longer own your

167
00:08:30.771 --> 00:08:33.050
decisions and so we're just going to take care of you on a permanent basis.

168
00:08:33.051 --> 00:08:35.750
That's,
that's really the,
the,
the question here.

169
00:08:36.560 --> 00:08:40.070
<v 0>Yeah.
Uh,
when you're talking about welfare,
we're looking at worst case scenario,</v>

170
00:08:40.071 --> 00:08:40.341
right?

171
00:08:40.341 --> 00:08:44.690
Where someone does get dependent upon the welfare state and does use that money

172
00:08:44.691 --> 00:08:47.660
frivolously and does make poor decisions.

173
00:08:47.960 --> 00:08:51.500
But then there's gotta be other people that are single moms that,
you know,

174
00:08:51.501 --> 00:08:55.170
maybe had a kid with some fucking asshole that doesn't want to pay.

175
00:08:55.590 --> 00:08:58.470
It was a piece of shit and they have to hide from them and they're just trying

176
00:08:58.471 --> 00:09:00.120
to feed their kids.
Yeah.
For sure.

177
00:09:00.150 --> 00:09:04.200
Those people exist to have a community to do,

178
00:09:04.390 --> 00:09:06.570
to help them out and maybe they're not a part of a church,

179
00:09:06.610 --> 00:09:08.760
then maybe they don't have a good group of neighbors.

180
00:09:08.761 --> 00:09:12.270
Maybe they had to move somewhere for work and they got stuck in some place where

181
00:09:12.271 --> 00:09:13.104
they don't know anybody.

182
00:09:13.230 --> 00:09:13.790
<v 1>But it,
I,</v>

183
00:09:13.790 --> 00:09:16.740
I think part of this is to recognize that incentives matter on both ends.

184
00:09:16.741 --> 00:09:19.770
So the idea is that you give some people more money and they'll,
they'll do well.

185
00:09:20.020 --> 00:09:22.410
It's also true that if you create a welfare system that benefits single

186
00:09:22.411 --> 00:09:24.360
motherhood,
you will get more single motherhood.
I mean the,

187
00:09:24.361 --> 00:09:26.530
the single mother had written the black community before wealth,

188
00:09:26.531 --> 00:09:30.690
there was 20% now it's 70% in the white community was like 5% now it's 40%

189
00:09:30.691 --> 00:09:31.650
you've said that like

190
00:09:31.830 --> 00:09:35.940
<v 0>out of wedlock children and having a kid when you're young is like,</v>

191
00:09:36.060 --> 00:09:37.680
it's a terrible idea for your life,

192
00:09:38.070 --> 00:09:42.900
but what do you recommend to have kids avoid that?
Are you one of those people

193
00:09:43.250 --> 00:09:46.730
<v 1>don't add up there without that thing on it?
No condoms is what you're saying,</v>

194
00:09:46.760 --> 00:09:49.790
right?
Like don't,
don't,
don't,
don't have unprotected sex.
I mean like this,

195
00:09:49.940 --> 00:09:53.930
this is not,
it's not part of my,
but my fake cursing.

196
00:09:53.931 --> 00:09:55.400
It's not anything rocket science.

197
00:09:55.401 --> 00:09:59.400
I mean like apologizing for not courteous and apologetic or not cursing.

198
00:10:00.660 --> 00:10:04.150
It's not rocket science.
It's one of the holy fathers.
Kids make mistakes yet.

199
00:10:04.160 --> 00:10:06.080
I mean that's what happens.
People get thrown it.
But,

200
00:10:06.440 --> 00:10:08.900
and then if the government pays for those mistakes,
it becomes less.

201
00:10:09.290 --> 00:10:13.870
So what should,
what should happen?
Should the kids suffer?
So the who no,

202
00:10:13.880 --> 00:10:16.550
I mean presumption it be any actually be worked out.

203
00:10:16.610 --> 00:10:21.200
I mean it depends on the situation.
If there are parents available to the kid,

204
00:10:21.201 --> 00:10:25.430
presumably the parents,
the grandparents would take a pretty active role in the,

205
00:10:25.431 --> 00:10:29.210
in the raising the kid.
I'll assume that they're there.
Well,
I,
how about this?

206
00:10:29.211 --> 00:10:31.610
How about we assume that if you are old enough to get pregnant,

207
00:10:31.670 --> 00:10:33.830
then you are old enough to l let's,

208
00:10:33.831 --> 00:10:36.740
let's talk about a 17 year old or 18 year old.
Used to be shotgun marriages,

209
00:10:36.780 --> 00:10:40.340
a thing and uh,
and really like that's a good idea.

210
00:10:40.460 --> 00:10:43.010
I think the idea of parents staying together for the sake of a kid,

211
00:10:43.011 --> 00:10:45.950
did they accidentally is absolutely a good idea.
Yes.
I think that,

212
00:10:45.951 --> 00:10:48.260
I think that is a better idea than the man walking away and the kid being

213
00:10:48.261 --> 00:10:50.360
without a man in the house.

214
00:10:50.480 --> 00:10:54.050
So you're saying that their childhood panels figure a way to work it out?
Yes.

215
00:10:54.110 --> 00:10:56.120
And if they were both reasonable,
they could do that.

