WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.968
[MUSIC PLAYING]

00:00:08.752 --> 00:00:09.960
NICK KREEGER: Hey, everybody.

00:00:09.960 --> 00:00:12.690
My name's Nick, and this
is my colleague, Yannick.

00:00:12.690 --> 00:00:17.410
We're going to talk today
about JavaScript and ML.

00:00:17.410 --> 00:00:20.270
TensorFlow.js is a library
we launched last year.

00:00:20.270 --> 00:00:22.890
It's a library for training
and deploying ML models

00:00:22.890 --> 00:00:25.710
in the browser and on Node.js.

00:00:25.710 --> 00:00:28.800
We want to showcase what you
can do today with the platform

00:00:28.800 --> 00:00:31.900
and where we're going.

00:00:31.900 --> 00:00:33.640
One of the great parts
about the library

00:00:33.640 --> 00:00:35.350
is there's really no
drivers to install.

00:00:35.350 --> 00:00:38.350
If you run it in the browser,
you can get out-of-the-box GPU

00:00:38.350 --> 00:00:40.960
acceleration.

00:00:40.960 --> 00:00:44.350
The browser itself tends to
be very interactive by nature,

00:00:44.350 --> 00:00:46.600
which builds really
great applications

00:00:46.600 --> 00:00:50.160
and demos for using ML.

00:00:50.160 --> 00:00:54.300
And privacy is a very
important part to the library.

00:00:54.300 --> 00:00:56.370
You can run inference
and training locally

00:00:56.370 --> 00:00:59.160
on the client, which works
around all sorts of privacy

00:00:59.160 --> 00:01:02.190
issues you might have with
doing server-side inference

00:01:02.190 --> 00:01:04.668
or training.

00:01:04.668 --> 00:01:06.460
And what can you do
today with the library?

00:01:06.460 --> 00:01:10.390
Well, we have a collection
of pre-trained, off-the-shelf

00:01:10.390 --> 00:01:15.350
models that you can use
without any knowledge of ML.

00:01:15.350 --> 00:01:18.020
We also have the ability to
take existing Python models

00:01:18.020 --> 00:01:20.450
and convert them and run
them in TensorFlow.js.

00:01:23.040 --> 00:01:26.850
We also have a full stack
for training, inference,

00:01:26.850 --> 00:01:29.150
and low-level linear algebra.

00:01:29.150 --> 00:01:32.958
And that runs in the
browser and Node.js.

00:01:32.958 --> 00:01:34.500
And we also have a
bunch of platforms

00:01:34.500 --> 00:01:38.993
that JavaScript can run on
outside of just the browser.

00:01:38.993 --> 00:01:40.410
The first thing I
want to showcase

00:01:40.410 --> 00:01:42.580
is some of our new,
off-the-shelf models

00:01:42.580 --> 00:01:44.520
we've launched.

00:01:44.520 --> 00:01:50.810
The first one is a bunch of
pre-trained-- or off-the-shelf

00:01:50.810 --> 00:01:54.650
models are bunch of
pre-trained models.

00:01:54.650 --> 00:01:59.840
They are image, audio, and
text classification models.

00:01:59.840 --> 00:02:01.830
And the APIs are
all user-friendly.

00:02:01.830 --> 00:02:03.830
You don't have to worry
about converting images.

00:02:03.830 --> 00:02:05.525
The tensors are resizing.

00:02:05.525 --> 00:02:09.360
They're very high-level,
easy-to-use APIs.

00:02:09.360 --> 00:02:12.630
These are available on NPM for
local application development.

00:02:12.630 --> 00:02:16.640
Or we also have pre-compiled
hosted scripts as well.

00:02:16.640 --> 00:02:19.060
We'll also be working on this
a lot in the upcoming year.

00:02:19.060 --> 00:02:22.480
We'll have more and more
models as we go forward.

00:02:22.480 --> 00:02:23.880
The first model is BodyPix.

00:02:23.880 --> 00:02:25.980
We were actually showcasing
this at our booth.

00:02:25.980 --> 00:02:29.090
And I want to show you how
easy it is to use this model.

00:02:29.090 --> 00:02:31.800
So the first thing we need
do is include the library

00:02:31.800 --> 00:02:33.480
and our BodyPix model.

00:02:33.480 --> 00:02:35.700
This can be done with
our pre-compiled scripts.

00:02:35.700 --> 00:02:39.100
So it's two simple imports.

00:02:39.100 --> 00:02:41.060
And the next step is to--

00:02:41.060 --> 00:02:43.360
we'll just create
a image in the DOM.

00:02:43.360 --> 00:02:46.660
So this is a body
image detection thing.

00:02:46.660 --> 00:02:49.300
So I have a picture of my
toddler trying to do yoga.

00:02:49.300 --> 00:02:50.920
It's kind of a
funny picture that

00:02:50.920 --> 00:02:54.560
isn't so much a human just like
this and finding arms and legs.

00:02:54.560 --> 00:02:55.270
So this is Frank.

00:02:55.270 --> 00:02:58.360
He's trying to do
something on the couch.

00:02:58.360 --> 00:03:00.100
But I want to actually
load the model

00:03:00.100 --> 00:03:02.050
and find body parts on Frank.

00:03:02.050 --> 00:03:05.590
So the first thing to do is
to load the BodyPix model--

00:03:05.590 --> 00:03:07.960
just a simple, one-line call.

00:03:07.960 --> 00:03:10.940
And the next step is to call
one of the methods we expose,

00:03:10.940 --> 00:03:13.370
which is
estimatePersonSegmentation.

00:03:13.370 --> 00:03:15.640
And I can pass in a DOM element.

00:03:15.640 --> 00:03:19.480
This returns a JavaScript
object with the width and height

00:03:19.480 --> 00:03:24.100
of the object or the image and
a value for every pixel that

00:03:24.100 --> 00:03:26.770
was in the image, if
it's an arm, or a leg,

00:03:26.770 --> 00:03:28.600
or a head, et cetera.

00:03:28.600 --> 00:03:31.780
There's also a bunch of really
easy-to-use methods for doing

00:03:31.780 --> 00:03:33.105
filtering on the image.

00:03:33.105 --> 00:03:34.480
So I can take the
results of that

00:03:34.480 --> 00:03:37.690
and render it
directly on the DOM.

00:03:37.690 --> 00:03:39.690
So it shows head,
body, arm, and so on.

00:03:42.480 --> 00:03:44.750
Another model we just launched
just a couple of weeks

00:03:44.750 --> 00:03:46.520
ago is the Toxicity model.

00:03:46.520 --> 00:03:51.650
It's a out-of-the-box
text classification model.

00:03:51.650 --> 00:03:54.860
Again, to use this model, we'll
use the pre-hosted scripts--

00:03:54.860 --> 00:03:57.140
two lines of code.

00:03:57.140 --> 00:04:00.940
And then I'll load
the Toxicity model

00:04:00.940 --> 00:04:03.760
and ask the model
to classify just

00:04:03.760 --> 00:04:07.090
some really lovely text,
pretty PG-- you suck.

00:04:07.090 --> 00:04:10.270
And I'll get a result back
again as a JavaScript object

00:04:10.270 --> 00:04:14.260
that has the seven
labels that we identify

00:04:14.260 --> 00:04:17.439
different types of toxic type
text, and the probabilities,

00:04:17.439 --> 00:04:18.189
and if it matches.

00:04:21.810 --> 00:04:24.243
We also have the ability to
take pre-trained Python models

00:04:24.243 --> 00:04:25.660
and run them
directly in browsers.

00:04:25.660 --> 00:04:27.952
So if you have a pre-trained
model today that's already

00:04:27.952 --> 00:04:32.040
been trained in Python world,
we have a command line tool

00:04:32.040 --> 00:04:35.580
that makes it very easy to
serialize the model as a JSON

00:04:35.580 --> 00:04:37.770
object, and the weights,
and distribute them

00:04:37.770 --> 00:04:40.580
in a web format.

00:04:40.580 --> 00:04:45.195
We support Saved Model,
TFHub, and Keras models.

00:04:45.195 --> 00:04:46.820
The converter itself
right now supports

00:04:46.820 --> 00:04:49.890
over 170 and counting ops.

00:04:49.890 --> 00:04:54.390
And we will be TensorFlow
2.0 compatible.

00:04:54.390 --> 00:04:57.190
I want to walk through how
simple it is to use this.

00:04:57.190 --> 00:04:59.650
I have a Python model.

00:04:59.650 --> 00:05:01.318
I run it through the
command line tool,

00:05:01.318 --> 00:05:03.610
and then I can easily just
a load that in my JavaScript

00:05:03.610 --> 00:05:04.870
application.

00:05:04.870 --> 00:05:06.522
Very simple.

00:05:06.522 --> 00:05:08.480
And with that, I want to
hand it off to Yannick

00:05:08.480 --> 00:05:09.897
to walk through
our training APIs.

00:05:09.897 --> 00:05:12.310
YANNICK ASSOGBA: Thanks, Nick.

00:05:12.310 --> 00:05:14.680
So in addition to working
with pre-trained models,

00:05:14.680 --> 00:05:17.580
TensorFlow.js also allows you
to author and train models

00:05:17.580 --> 00:05:21.720
directly in JavaScript, both
in the browser and in Node.

00:05:21.720 --> 00:05:24.150
The primary tool for
this is the Layers API,

00:05:24.150 --> 00:05:28.000
which is a Keras-compatible
API for authoring models.

00:05:28.000 --> 00:05:30.120
There's also a lower
level op-driven API,

00:05:30.120 --> 00:05:32.170
if you need fine control
over model architecture

00:05:32.170 --> 00:05:32.920
or execution.

00:05:32.920 --> 00:05:34.420
And we're going to
take a quick look

00:05:34.420 --> 00:05:36.303
at what TFJS code for
training looks like.

00:05:36.303 --> 00:05:37.720
And the main
takeaway is that it's

00:05:37.720 --> 00:05:40.000
pretty similar to
using Keras and Python,

00:05:40.000 --> 00:05:43.400
but follows JavaScript
conventions.

00:05:43.400 --> 00:05:46.650
So the first step is
to import the library.

00:05:46.650 --> 00:05:49.320
And when working in Node,js,
you can also use the Node.js

00:05:49.320 --> 00:05:52.650
bindings, which execute the
TensorFlow operations using

00:05:52.650 --> 00:05:56.280
native compiled C++ code.

00:05:56.280 --> 00:05:58.340
If you're on a system
that supports CUDA,

00:05:58.340 --> 00:06:01.140
you can import
tfjs-node-gpu to get

00:06:01.140 --> 00:06:02.640
CUDA-accelerated
performance when

00:06:02.640 --> 00:06:05.970
doing training or inference.

00:06:05.970 --> 00:06:08.000
And this is what creating
a convolutional model

00:06:08.000 --> 00:06:11.510
for a classification task
looks like in JavaScript.

00:06:11.510 --> 00:06:13.490
As you can see, it's very
similar to Keras code

00:06:13.490 --> 00:06:14.780
and Python.

00:06:14.780 --> 00:06:16.850
We start by
instantiating a model.

00:06:16.850 --> 00:06:19.370
We add our convolutional
layers, and we finish our model

00:06:19.370 --> 00:06:22.670
definition by adding a flatten
operation and a dense layer

00:06:22.670 --> 00:06:25.790
with a number of output classes.

00:06:25.790 --> 00:06:27.723
Similar to Python, we
use model.compile to get

00:06:27.723 --> 00:06:28.640
it ready for training.

00:06:28.640 --> 00:06:32.630
And here, we specify our loss
function and our optimizer.

00:06:32.630 --> 00:06:35.287
And model.fit is the function
that drives the train loop.

00:06:35.287 --> 00:06:36.870
In JavaScript, it's
an async function.

00:06:36.870 --> 00:06:38.537
So here, we want to
wait for the result,

00:06:38.537 --> 00:06:41.540
or wait for it to be done.

00:06:41.540 --> 00:06:44.450
Once the model is done
training, we can save the model.

00:06:44.450 --> 00:06:47.760
And here, we're saving it to
the browser's local storage.

00:06:47.760 --> 00:06:50.060
We support saving to a
number of different targets,

00:06:50.060 --> 00:06:53.067
both on the client
and on the server.

00:06:53.067 --> 00:06:54.650
And finally, just
like you're used to,

00:06:54.650 --> 00:06:57.420
you can use model.predict to
get a result from the model.

00:07:00.540 --> 00:07:02.637
So over the past year,
we've also heard feedback

00:07:02.637 --> 00:07:04.970
from the community on ways
we can improve the experience

00:07:04.970 --> 00:07:06.980
of training with TensorFlow.js.

00:07:06.980 --> 00:07:08.540
And two particular
requested areas

00:07:08.540 --> 00:07:10.690
are that of data management
and data visualization.

00:07:10.690 --> 00:07:12.815
So we'd like to show you
some of the progress we've

00:07:12.815 --> 00:07:15.440
made in those areas.

00:07:15.440 --> 00:07:16.810
So first up is tf.data.

00:07:16.810 --> 00:07:18.340
And it's an API
for managing data

00:07:18.340 --> 00:07:21.010
pipelines to drive training.

00:07:21.010 --> 00:07:24.820
It's a JS analog
to Python's tf.data

00:07:24.820 --> 00:07:26.770
and provides a whole
set of utility functions

00:07:26.770 --> 00:07:29.380
for data set transformation.

00:07:29.380 --> 00:07:30.940
And finally, it
works with streams.

00:07:30.940 --> 00:07:32.650
And the lazy
evaluation allows you

00:07:32.650 --> 00:07:35.410
to work with data that
doesn't fit in memory,

00:07:35.410 --> 00:07:36.890
which can be quite important.

00:07:36.890 --> 00:07:40.230
So let's take a look
at a simple example.

00:07:40.230 --> 00:07:44.330
So here, we load up a CSV
file, using tf.data.csv loader.

00:07:44.330 --> 00:07:46.940
And we specify that we want to
predict the price column, using

00:07:46.940 --> 00:07:49.268
the isLabel attribute.

00:07:49.268 --> 00:07:50.810
So this is going to
set it as a label

00:07:50.810 --> 00:07:53.290
in future transformations.

00:07:53.290 --> 00:07:56.160
So for example, in this
map transformation,

00:07:56.160 --> 00:07:58.320
the price data has
been separated out

00:07:58.320 --> 00:07:59.760
into that y's object.

00:07:59.760 --> 00:08:02.100
And the rest of the features
are in the x's object.

00:08:05.080 --> 00:08:06.510
Once we've flattened
our data, we

00:08:06.510 --> 00:08:09.760
can now apply typical ML
transformation operations,

00:08:09.760 --> 00:08:12.660
including things like shuffling,
which is an ML best practice,

00:08:12.660 --> 00:08:16.140
and batching, which will do
the work of creating properly

00:08:16.140 --> 00:08:18.330
sized mini-batches
for training and know

00:08:18.330 --> 00:08:21.207
what to pull into memory when,
when the train loop is running.

00:08:21.207 --> 00:08:22.790
And the other kinds
of transformations

00:08:22.790 --> 00:08:27.613
you may want to do here include
things like normalization.

00:08:27.613 --> 00:08:29.780
And finally, we run the
train loop on this data set.

00:08:29.780 --> 00:08:33.470
So model.fitDataset is
an analog to model.fit

00:08:33.470 --> 00:08:35.780
that supports
consuming TF data sets

00:08:35.780 --> 00:08:39.650
and knows how to pull the right
stuff into memory as needed.

00:08:39.650 --> 00:08:42.200
And that's tf.data.

00:08:42.200 --> 00:08:44.210
So the other area
we've been responding

00:08:44.210 --> 00:08:46.510
to community feedback is
that of visualization.

00:08:46.510 --> 00:08:48.385
And the first thing I
want to talk about here

00:08:48.385 --> 00:08:52.610
is tfjs-vis, which is a library
for in-browser visualization

00:08:52.610 --> 00:08:55.240
of model behavior.

00:08:55.240 --> 00:08:57.240
So with it, you can
view training behavior,

00:08:57.240 --> 00:09:00.430
model internals, as well
as evaluation metrics.

00:09:00.430 --> 00:09:04.077
And we're going to take
a look at the first two.

00:09:04.077 --> 00:09:05.410
So first, we import the library.

00:09:05.410 --> 00:09:07.840
And here, you should note
that we do provide tfjs-vis

00:09:07.840 --> 00:09:11.010
as a separate package.

00:09:11.010 --> 00:09:12.630
And to visualize
training behavior,

00:09:12.630 --> 00:09:15.750
we can use this
show.fitCallbacks function.

00:09:15.750 --> 00:09:17.640
And we're going to
specify a named drawing

00:09:17.640 --> 00:09:21.090
area to render the charts to,
as well as our metrics that we

00:09:21.090 --> 00:09:22.350
want to see.

00:09:22.350 --> 00:09:25.710
So in one line,
show.fitCallbacks

00:09:25.710 --> 00:09:28.920
will plot our selected
metrics, in this case our loss

00:09:28.920 --> 00:09:31.290
and our accuracy or
metrics on batch end

00:09:31.290 --> 00:09:33.030
and at the end of each epoch.

00:09:33.030 --> 00:09:35.850
So this lets us view how
the model is converging live

00:09:35.850 --> 00:09:36.800
in the browser.

00:09:36.800 --> 00:09:37.770
That's [? adjust ?]
[? hyper parameters ?]

00:09:37.770 --> 00:09:38.270
as usual.

00:09:41.170 --> 00:09:42.900
You can also look at
the model internals

00:09:42.900 --> 00:09:45.120
with functions like
show.modelSummary

00:09:45.120 --> 00:09:46.500
and show.layer.

00:09:46.500 --> 00:09:50.310
And similarly we pass
these named drawing areas.

00:09:50.310 --> 00:09:53.005
And here, we see the
architecture of the model,

00:09:53.005 --> 00:09:55.380
including things like output
shapes of the various layers

00:09:55.380 --> 00:09:57.650
and the number of
trainable parameters.

00:09:57.650 --> 00:10:00.350
And in this example, we
also see the distribution

00:10:00.350 --> 00:10:03.560
of values in the first
convolutional layer

00:10:03.560 --> 00:10:06.560
of this network, including
important statistics, like nans

00:10:06.560 --> 00:10:09.200
and 0 counts, which are
useful for debugging models.

00:10:11.865 --> 00:10:14.240
And finally, we also want to
announce TensorBoard support

00:10:14.240 --> 00:10:16.630
in Node.js.

00:10:16.630 --> 00:10:18.580
Now you can monitor
training performance right

00:10:18.580 --> 00:10:21.250
in TensorBoard when using
the TensorFlow.js layers

00:10:21.250 --> 00:10:23.470
API in Node.

00:10:23.470 --> 00:10:25.100
You can see what
that looks like.

00:10:25.100 --> 00:10:28.450
So a single line will generate
the necessary callbacks

00:10:28.450 --> 00:10:31.570
to write the model metrics
to a TensorBoard log file,

00:10:31.570 --> 00:10:36.440
using this
tf.node.tensorBoard command.

00:10:36.440 --> 00:10:37.910
Then you can open
it in TensorBoard

00:10:37.910 --> 00:10:39.680
and look at how you're
training is going,

00:10:39.680 --> 00:10:42.340
just like you may be used to.

00:10:42.340 --> 00:10:44.340
And with that, I'm going
to hand it back to Nick

00:10:44.340 --> 00:10:46.440
to talk about some of the
platforms we execute on.

00:10:49.047 --> 00:10:51.130
NICK KREEGER: JavaScript's
an interesting language

00:10:51.130 --> 00:10:55.520
because it actually runs in a
lot more places than you think.

00:10:55.520 --> 00:10:57.730
There's the traditional
browser front

00:10:57.730 --> 00:10:59.710
for running JavaScript
in the browser.

00:10:59.710 --> 00:11:01.580
We all know about that.

00:11:01.580 --> 00:11:03.970
Node.js is a big
server-side solution.

00:11:03.970 --> 00:11:06.110
Very popular.

00:11:06.110 --> 00:11:09.500
But there's also a growing trend
with JavaScript in more places.

00:11:09.500 --> 00:11:11.450
One of them is
desktop applications.

00:11:11.450 --> 00:11:15.050
Electron is a very,
very popular platform

00:11:15.050 --> 00:11:16.880
for developing applications.

00:11:16.880 --> 00:11:18.860
Those of you who have
used the Spotify desktop

00:11:18.860 --> 00:11:20.660
application or Visual
Studio Code, those

00:11:20.660 --> 00:11:23.840
are good examples of Electron.

00:11:23.840 --> 00:11:26.690
And JavaScript is also
moving into the mobile space.

00:11:26.690 --> 00:11:29.390
I want to highlight
a couple of examples

00:11:29.390 --> 00:11:33.240
that we've seen in the
industry on all four platforms.

00:11:33.240 --> 00:11:35.490
First is the browser.

00:11:35.490 --> 00:11:37.140
Our friends at
Google Creative Labs

00:11:37.140 --> 00:11:39.570
have built a series
of experiments

00:11:39.570 --> 00:11:41.220
to explore how
creative tools can be

00:11:41.220 --> 00:11:43.608
more accessible for everyone.

00:11:43.608 --> 00:11:45.150
There's going to be
a great lightning

00:11:45.150 --> 00:11:47.220
talk on this tomorrow,
and I encourage you to go.

00:11:47.220 --> 00:11:48.600
And they'll talk about
everything they've

00:11:48.600 --> 00:11:49.600
built with this project.

00:11:53.140 --> 00:11:56.680
Uber has built a
in-browser tool for

00:11:56.680 --> 00:12:00.960
model-agnostic visualization
of ML performance.

00:12:00.960 --> 00:12:04.140
They use TensorFlow.js for
acceleration of their linear

00:12:04.140 --> 00:12:05.370
algebra--

00:12:05.370 --> 00:12:09.600
k-means clustering, KL-divergent
computations, and so on.

00:12:09.600 --> 00:12:11.550
They are also giving
a great lighting talk

00:12:11.550 --> 00:12:14.280
about how they use
TensorFlow.js solve this problem

00:12:14.280 --> 00:12:15.375
for their platform.

00:12:15.375 --> 00:12:18.530
And again, this
is all in-browser.

00:12:18.530 --> 00:12:21.920
Another really cool
industry example is Airbnb.

00:12:21.920 --> 00:12:26.740
Airbnb built a identity
document detection model

00:12:26.740 --> 00:12:30.220
that they use as a full
TensorFlow ecosystem solution.

00:12:30.220 --> 00:12:33.380
So on your Airbnb
profile, if you

00:12:33.380 --> 00:12:35.200
were to upload a
government-issued ID,

00:12:35.200 --> 00:12:38.660
it is a very big trust
and safety issue.

00:12:38.660 --> 00:12:41.860
So the Trust team at Airbnb
built a TensorFlow model

00:12:41.860 --> 00:12:44.950
to detect if a profile
picture that you're

00:12:44.950 --> 00:12:47.290
trying to upload
directly in the client

00:12:47.290 --> 00:12:49.300
contains government-issued IDs.

00:12:49.300 --> 00:12:52.300
They use this in the
browser, using TensorFlow.js,

00:12:52.300 --> 00:12:54.340
as well as on their mobile
devices with TFLite.

00:12:56.860 --> 00:13:01.160
On Node.js, a good example of
this being used in the industry

00:13:01.160 --> 00:13:03.620
is Clinic Doctor and Clinic.js.

00:13:03.620 --> 00:13:06.920
This is a Node.js
performance analysis tool.

00:13:06.920 --> 00:13:09.110
And they use our
Node.js bindings

00:13:09.110 --> 00:13:13.160
to filter out GC
spikes on [? node ?]

00:13:13.160 --> 00:13:16.250
processes that are running
to give a true, accurate CPU

00:13:16.250 --> 00:13:19.430
performance benchmark.

00:13:19.430 --> 00:13:23.630
And on the desktop, our
team here at Google,

00:13:23.630 --> 00:13:28.100
with Magenta and their
music generation models,

00:13:28.100 --> 00:13:32.570
have built a series of desktop
plugins for the Ableton Studio.

00:13:32.570 --> 00:13:34.670
So these apps are a
little mini-applications

00:13:34.670 --> 00:13:36.500
that are full desktop
applications that

00:13:36.500 --> 00:13:40.350
use the Magenta models and
accelerate them all into GPU

00:13:40.350 --> 00:13:42.270
and desktop applications.

00:13:42.270 --> 00:13:45.590
And we have a demo at our booth,
as well, for how this works.

00:13:45.590 --> 00:13:48.890
Again, the really cool part
is all JavaScript and GPU

00:13:48.890 --> 00:13:51.890
acceleration on the desktop,
with no CUDA drivers

00:13:51.890 --> 00:13:55.600
all through our webGL bindings.

00:13:55.600 --> 00:13:59.360
And mobile is another
interesting space.

00:13:59.360 --> 00:14:02.000
WeChat, for example, is one
of the most popular apps

00:14:02.000 --> 00:14:02.660
in the world.

00:14:02.660 --> 00:14:05.150
They have over one
billion total users

00:14:05.150 --> 00:14:06.920
and have a
sub-application platform

00:14:06.920 --> 00:14:09.513
called the mini-programs.

00:14:09.513 --> 00:14:11.180
The mini-programs are
great because it's

00:14:11.180 --> 00:14:14.630
a no need to install app
in advance, use on-demand.

00:14:14.630 --> 00:14:19.580
And it has over one million
apps and 1.5 million developers.

00:14:19.580 --> 00:14:23.450
The mini-program itself
is built using JavaScript.

00:14:23.450 --> 00:14:25.640
And it makes it really
easy for developers

00:14:25.640 --> 00:14:28.820
to create and deploy and share
these on the WeChat platform.

00:14:28.820 --> 00:14:32.270
I actually want to show a
demo of one of our TFJS models

00:14:32.270 --> 00:14:33.170
running on WeChat.

00:14:37.050 --> 00:14:40.110
So I have just a
regular iOS device here,

00:14:40.110 --> 00:14:41.870
and I'm going to open WeChat.

00:14:41.870 --> 00:14:45.050
Someone shared with
me this TFJS example.

00:14:45.050 --> 00:14:47.880
And I can load up
the application,

00:14:47.880 --> 00:14:51.300
and it's running
our PoseNet model.

00:14:51.300 --> 00:14:54.570
And if I aim at it
Yannick here, I can do--

00:14:54.570 --> 00:14:57.370
yeah, there we go.

00:14:57.370 --> 00:15:00.010
So this is just purely
done in JavaScript.

00:15:00.010 --> 00:15:02.800
And it's running our
off-the-shelf MobileNet model.

00:15:02.800 --> 00:15:04.780
And we're doing about
30 frames a second.

00:15:04.780 --> 00:15:07.240
And this is all done with the
WeChat JavaScript platform.

00:15:13.390 --> 00:15:14.515
YANNICK ASSOGBA: Thank you.

00:15:17.920 --> 00:15:21.010
So all this work over the past
year and the fantastic projects

00:15:21.010 --> 00:15:23.740
created by the community
makes us very excited

00:15:23.740 --> 00:15:27.120
to announce
TensorFlow.js 1.0 today.

00:15:27.120 --> 00:15:28.160
It's available now.

00:15:28.160 --> 00:15:30.200
And we're super excited to
see what that community builds

00:15:30.200 --> 00:15:32.060
with it and hope that
the API stability will

00:15:32.060 --> 00:15:35.222
make this even easier for
developers, going forward.

00:15:35.222 --> 00:15:36.680
And really with
this release, we're

00:15:36.680 --> 00:15:39.530
focusing on two main things--
providing a stable API that you

00:15:39.530 --> 00:15:41.690
can build applications
on and make

00:15:41.690 --> 00:15:44.480
managing your upgrades
easier, and also bringing

00:15:44.480 --> 00:15:47.720
marked improvements in
performance, particularly

00:15:47.720 --> 00:15:48.880
on mobile devices.

00:15:48.880 --> 00:15:51.510
And we'll look at that
in a bit more detail.

00:15:51.510 --> 00:15:53.090
So to look at it a bit closer--

00:15:53.090 --> 00:15:56.480
since we announced TensorFlow.js
last year at the Dev Summit,

00:15:56.480 --> 00:15:59.030
we've been steadily working
on performance improvements

00:15:59.030 --> 00:16:00.710
across a number of platforms.

00:16:00.710 --> 00:16:05.420
And today, we see increases
of about 1.4x to 9x in some

00:16:05.420 --> 00:16:07.780
extreme cases.

00:16:07.780 --> 00:16:10.320
So this chart shows
inference performance

00:16:10.320 --> 00:16:14.010
with a batch size of 1
on MobileNet in Chrome.

00:16:14.010 --> 00:16:16.140
So MobileNet is a
mobile-friendly image

00:16:16.140 --> 00:16:17.730
classification model.

00:16:17.730 --> 00:16:20.970
And we see inference times
going from about 15 milliseconds

00:16:20.970 --> 00:16:23.640
on a modern laptop
with discrete graphics

00:16:23.640 --> 00:16:26.633
to about 150 milliseconds
on the Pixel 2.

00:16:26.633 --> 00:16:28.050
And over the past
year, we've been

00:16:28.050 --> 00:16:30.450
able to do quite a bit of
work to improve performance

00:16:30.450 --> 00:16:32.050
on iOS devices as well.

00:16:32.050 --> 00:16:36.100
So really excited
for you to try this.

00:16:36.100 --> 00:16:38.810
So what's next for us?

00:16:38.810 --> 00:16:42.740
Well, we want to enable
you to execute saved models

00:16:42.740 --> 00:16:45.590
on our Node.js backend without
going through the conversion

00:16:45.590 --> 00:16:46.170
process.

00:16:46.170 --> 00:16:47.990
And this will open
up many more models

00:16:47.990 --> 00:16:51.850
to be able to serve
using the Node.js stack.

00:16:51.850 --> 00:16:53.940
We want to provide more
off-the-shelf models,

00:16:53.940 --> 00:16:55.898
like we talked about
earlier, to make it easier

00:16:55.898 --> 00:16:58.350
to build ML-powered JavaScript
apps without getting

00:16:58.350 --> 00:17:02.450
into the nitty-gritty of
machine learning models.

00:17:02.450 --> 00:17:05.810
We're always keeping an eye on
browser acceleration proposals,

00:17:05.810 --> 00:17:08.839
like SIMD and WASM, as
well as emerging proposals,

00:17:08.839 --> 00:17:10.700
like WebGPU and WebML.

00:17:10.700 --> 00:17:15.775
So the browser's only going
to get faster, and so will we.

00:17:15.775 --> 00:17:17.150
And finally, we
also want to work

00:17:17.150 --> 00:17:20.670
on expanding the platforms on
which TensorFlow.js can run.

00:17:20.670 --> 00:17:22.609
So for example, we saw
examples of Electron

00:17:22.609 --> 00:17:24.210
and things like WeChat.

00:17:24.210 --> 00:17:26.150
They're also working
on platforms,

00:17:26.150 --> 00:17:30.710
like the Raspberry Pi and
other hybrid mobile platforms

00:17:30.710 --> 00:17:33.760
that run JavaScript.

00:17:33.760 --> 00:17:34.403
So thanks.

00:17:34.403 --> 00:17:36.820
And for more information about
the things we talked about,

00:17:36.820 --> 00:17:39.290
you can visit any
one of these links.

00:17:39.290 --> 00:17:39.960
Thank you.

00:17:39.960 --> 00:17:40.560
[APPLAUSE]

00:17:40.560 --> 00:17:43.010
[MUSIC PLAYING]

