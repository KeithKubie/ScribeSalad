WEBVTT
Kind: captions
Language: en

00:00:02.410 --> 00:00:02.780
SHIRLEY GAW: Hi.

00:00:02.780 --> 00:00:06.580
My name is Shirley, and I'm a
software engineer working in

00:00:06.580 --> 00:00:11.760
the Paris office, and I'm on
the YouTube Data API team.

00:00:11.760 --> 00:00:13.060
PHILIPP PFEIFFENBERGER: And I'm
Philipp Pfeiffenberger.

00:00:13.060 --> 00:00:15.430
I'm also a software engineer
working in the Paris office,

00:00:15.430 --> 00:00:16.190
and I'm working on the semantic

00:00:16.190 --> 00:00:19.220
annotation of YouTube videos.

00:00:19.220 --> 00:00:22.170
SHIRLEY GAW: So in this session,
I'd like to go over

00:00:22.170 --> 00:00:28.210
how I taught YouTube that my
baby is cute, but more

00:00:28.210 --> 00:00:32.650
generally, how you as a content
creator can improve

00:00:32.650 --> 00:00:35.960
semantic annotations for your
videos and channels.

00:00:35.960 --> 00:00:38.790
And also, how you as application
developers can

00:00:38.790 --> 00:00:41.820
discover content on YouTube
based on Freebase topics.

00:00:44.770 --> 00:00:47.890
So Philipp's team's been working
on automatically

00:00:47.890 --> 00:00:50.790
annotating resources such as
videos and channels with

00:00:50.790 --> 00:00:52.440
Freebase topics.

00:00:52.440 --> 00:00:55.600
Now, if you're not familiar with
Freebase, it's an open,

00:00:55.600 --> 00:00:59.610
crowd-sourced Knowledge Graph
where nodes corresponds to

00:00:59.610 --> 00:01:04.500
real world things-- so for
example, a person or a place

00:01:04.500 --> 00:01:05.930
or a song--

00:01:05.930 --> 00:01:08.870
and each of these nodes
has a unique ID.

00:01:08.870 --> 00:01:11.940
So in the latest version of the
YouTube Data API, you can

00:01:11.940 --> 00:01:16.480
actually look up, for example,
a YouTube video and see what

00:01:16.480 --> 00:01:18.500
Freebase topics have
been automatically

00:01:18.500 --> 00:01:20.500
associated with it.

00:01:20.500 --> 00:01:24.450
Furthermore, you can supply a
Freebase topic ID and see what

00:01:24.450 --> 00:01:28.890
YouTube resources are related
to that topic.

00:01:28.890 --> 00:01:31.820
So in the session, I'm going to
talk about why you should

00:01:31.820 --> 00:01:35.140
care about the quality of these
video annotations--

00:01:35.140 --> 00:01:38.860
so how it's being used, and also
how you can improve the

00:01:38.860 --> 00:01:42.700
quality of the annotations
for your content.

00:01:42.700 --> 00:01:45.800
Philipp will go into my specific
example explaining

00:01:45.800 --> 00:01:49.090
how we arrive at those video
annotations and then other

00:01:49.090 --> 00:01:51.225
signals that go into the
annotations process.

00:01:53.740 --> 00:01:56.500
Understanding that, we'll go
back to my first example and

00:01:56.500 --> 00:02:00.390
explain how I was able to
improve the annotations.

00:02:00.390 --> 00:02:03.000
And then, we'll walk through
an integration between the

00:02:03.000 --> 00:02:06.340
Freebase API for getting
related topics--

00:02:06.340 --> 00:02:08.300
getting topics in general,
actually--

00:02:08.300 --> 00:02:13.390
and the YouTube Data API to
find content on YouTube.

00:02:13.390 --> 00:02:15.420
And then finally, Philipp's
going to talk about work that

00:02:15.420 --> 00:02:18.580
his team's been doing that will
give you more Freebase

00:02:18.580 --> 00:02:21.380
annotations, and hopefully
we'll see it in

00:02:21.380 --> 00:02:22.630
the API real soon.

00:02:25.460 --> 00:02:28.450
So why should you care about
the quality of video

00:02:28.450 --> 00:02:29.700
annotations?

00:02:31.670 --> 00:02:34.060
Well actually, at YouTube, this
is one of the signals we

00:02:34.060 --> 00:02:38.470
use for surfacing content
and organizing it.

00:02:38.470 --> 00:02:41.530
So for example, if you're
looking at the Home page, it's

00:02:41.530 --> 00:02:45.010
one of the signals that we use
for featuring content--

00:02:45.010 --> 00:02:48.400
also when you do search and
some special features.

00:02:48.400 --> 00:02:51.760
Also specifically, we're using
it as a signal in our video

00:02:51.760 --> 00:02:55.150
and channel recommendations, and
this is how some external

00:02:55.150 --> 00:02:57.620
partners have been using
it in the Topics API.

00:02:57.620 --> 00:03:02.830
So for example, Interesante is
focused on Latino users and

00:03:02.830 --> 00:03:05.460
culturally-relevant content
for those users.

00:03:05.460 --> 00:03:09.420
So they look in Freebase, find
related topics for things that

00:03:09.420 --> 00:03:12.720
people are interested in, find
content on YouTube, and then

00:03:12.720 --> 00:03:15.290
suggest that to their users as
things that they can add in

00:03:15.290 --> 00:03:16.750
their collections.

00:03:16.750 --> 00:03:18.870
Showyou is more general,
in that it's

00:03:18.870 --> 00:03:20.160
showing internet videos.

00:03:20.160 --> 00:03:22.330
And when you're watching
something in the latest iPhone

00:03:22.330 --> 00:03:27.820
app, it'll show you the topic it
thinks the video is about.

00:03:27.820 --> 00:03:30.180
It's using the Topics API
as one of the signals.

00:03:30.180 --> 00:03:33.230
And then from there, it can
suggest other internet videos

00:03:33.230 --> 00:03:35.020
related to that topic.

00:03:35.020 --> 00:03:38.340
Seevl is actually specializing
in music recommendation.

00:03:38.340 --> 00:03:41.320
So say your friend likes
an obscure band.

00:03:41.320 --> 00:03:44.500
If you're using the YouTube
data as your music source,

00:03:44.500 --> 00:03:47.530
then you can actually find
more YouTube videos

00:03:47.530 --> 00:03:51.020
related to that band.

00:03:51.020 --> 00:03:54.030
So now that you understand why
video annotations and quality

00:03:54.030 --> 00:03:56.680
video annotations are important
for content, let's

00:03:56.680 --> 00:04:00.600
go into my favorite example.

00:04:00.600 --> 00:04:02.990
So this is my daughter.

00:04:02.990 --> 00:04:07.860
And if you're a human being,
what would you say

00:04:07.860 --> 00:04:10.480
this video is about?

00:04:10.480 --> 00:04:11.788
Be nice.

00:04:11.788 --> 00:04:13.660
[LAUGHTER]

00:04:13.660 --> 00:04:15.540
AUDIENCE: Self-discovery.

00:04:15.540 --> 00:04:19.219
SHIRLEY GAW: Self-discovery as
kind of a step in development.

00:04:22.553 --> 00:04:24.530
AUDIENCE: I'd say it's
about mirrors.

00:04:24.530 --> 00:04:25.300
SHIRLEY GAW: Mirrors.

00:04:25.300 --> 00:04:28.680
So you can talk about some
things in the scene,

00:04:28.680 --> 00:04:31.310
particular people in the
scene, describing

00:04:31.310 --> 00:04:33.080
what you see there.

00:04:33.080 --> 00:04:36.610
What does YouTube think
of this video?

00:04:36.610 --> 00:04:40.130
So actually, we only
expose this in the

00:04:40.130 --> 00:04:41.280
Topics API for now.

00:04:41.280 --> 00:04:42.690
So you don't see
it on the site.

00:04:42.690 --> 00:04:47.270
What you do is make an HTTP GET
request to googleapis.com.

00:04:47.270 --> 00:04:49.940
The latest version of YouTube.

00:04:49.940 --> 00:04:51.600
We look at the videos
collection for a

00:04:51.600 --> 00:04:53.270
specific video ID.

00:04:53.270 --> 00:04:55.170
And now, we say that we're
interested in the video

00:04:55.170 --> 00:04:57.550
annotations by saying in the
response that we want

00:04:57.550 --> 00:05:00.670
part="topicDetails."

00:05:00.670 --> 00:05:03.170
So what did YouTube you think
this video was about?

00:05:03.170 --> 00:05:06.360
There's no green, which means
it doesn't think anything

00:05:06.360 --> 00:05:08.140
about my video.

00:05:08.140 --> 00:05:12.160
Of course, working on the Topics
API, that's clearly not

00:05:12.160 --> 00:05:13.520
good enough for the mother.

00:05:13.520 --> 00:05:18.050
So I uploaded a second version
of this video, and I made sure

00:05:18.050 --> 00:05:20.690
that there were some high
quality annotations.

00:05:20.690 --> 00:05:23.270
I did a few tweaks and a
little search engine

00:05:23.270 --> 00:05:26.190
optimization, which I'll
discuss later.

00:05:26.190 --> 00:05:28.590
But now, when we query
this new video, it's

00:05:28.590 --> 00:05:30.670
the exact same content.

00:05:30.670 --> 00:05:33.590
But now, we get two topics,
which are shown in green.

00:05:33.590 --> 00:05:36.440
We can go to Freebase, append
the Freebase ID, and you can

00:05:36.440 --> 00:05:37.570
see the first thing.

00:05:37.570 --> 00:05:40.590
The first topic is that
it's about an infant.

00:05:40.590 --> 00:05:43.600
The second topic, cuteness.

00:05:43.600 --> 00:05:45.430
I like to conclude
that I taught

00:05:45.430 --> 00:05:47.020
YouTube my baby is cute.

00:05:51.140 --> 00:05:52.090
PHILIPP PFEIFFENBERGER:
Thanks, Shirley.

00:05:52.090 --> 00:05:54.700
So we've received a lot of
questions from developers--

00:05:54.700 --> 00:05:57.830
exactly how videos are
annotated and how the

00:05:57.830 --> 00:06:01.580
annotations that we export for
videos should be interpreted.

00:06:01.580 --> 00:06:03.990
In order to shed some light onto
those questions, I want

00:06:03.990 --> 00:06:05.960
to walk through the annotation
process using

00:06:05.960 --> 00:06:08.330
a few example cases.

00:06:08.330 --> 00:06:10.210
Well, before we can start
annotating anything, we want

00:06:10.210 --> 00:06:12.500
to look at what kind of data
we have available for the

00:06:12.500 --> 00:06:14.000
annotation process.

00:06:14.000 --> 00:06:17.310
We want to list these in the
order of their availability.

00:06:17.310 --> 00:06:19.990
So first and foremost, we
have the text metadata.

00:06:19.990 --> 00:06:22.270
At the time of upload, the
uploader will insert some

00:06:22.270 --> 00:06:24.520
text-- a title, description,
and so on--

00:06:24.520 --> 00:06:26.790
and we have this immediately
available.

00:06:26.790 --> 00:06:29.160
A few minutes after upload,
we'll have extracted some

00:06:29.160 --> 00:06:32.480
audiovisual features that we can
use to classify the video.

00:06:32.480 --> 00:06:35.790
And finally, if the video's
popular enough, there may be

00:06:35.790 --> 00:06:39.090
some context, both on the open
internet and on YouTube, that

00:06:39.090 --> 00:06:42.240
we can help to further
guide annotation.

00:06:42.240 --> 00:06:45.000
So I want to illustrate these
with one example video for

00:06:45.000 --> 00:06:46.030
each data type.

00:06:46.030 --> 00:06:48.370
But as I do this, we should
keep in mind that for your

00:06:48.370 --> 00:06:50.770
average YouTube video, we
try to make use of all

00:06:50.770 --> 00:06:52.560
three types of data.

00:06:52.560 --> 00:06:55.640
I want to start with Shirley's
video, which was just uploaded

00:06:55.640 --> 00:06:59.210
and only has text metadata to
work with at this point.

00:06:59.210 --> 00:07:01.430
So I'm going to walk through the
annotation process using

00:07:01.430 --> 00:07:04.680
Shirley's video, the text, and
the entities as an example.

00:07:04.680 --> 00:07:06.900
And as I do this, you should
keep in mind that also for the

00:07:06.900 --> 00:07:09.210
other data sources,
the process I walk

00:07:09.210 --> 00:07:12.440
through is the same.

00:07:12.440 --> 00:07:15.250
So we know that the
text metadata is

00:07:15.250 --> 00:07:16.150
provided by the uploader.

00:07:16.150 --> 00:07:18.850
It includes title, description,
any tags that the

00:07:18.850 --> 00:07:20.970
uploader included
at that time.

00:07:20.970 --> 00:07:24.250
And we also know that text and
concepts have a many-to-many

00:07:24.250 --> 00:07:25.550
association.

00:07:25.550 --> 00:07:27.190
That is, text is ambiguous.

00:07:27.190 --> 00:07:29.530
The concept of infant can be
communicated by the word

00:07:29.530 --> 00:07:32.910
"baby," by the word "infant," by
the word "toddler," so on.

00:07:32.910 --> 00:07:37.960
And likewise, the word "baby"
without any sort of context

00:07:37.960 --> 00:07:40.900
can refer to a Justin Bieber
song, can refer to an infant,

00:07:40.900 --> 00:07:42.960
can refer to a number
of other things.

00:07:42.960 --> 00:07:46.700
For that reason, we depend on
the text to be consistent to

00:07:46.700 --> 00:07:48.850
allow us to correctly
dereference what concepts are

00:07:48.850 --> 00:07:49.980
mentioned therein.

00:07:49.980 --> 00:07:52.670
Now, even though we depend on
the uploader to give us this

00:07:52.670 --> 00:07:55.990
text metadata and we have to
correlate this with other data

00:07:55.990 --> 00:07:59.360
sources, it's really valuable,
because it's available to us

00:07:59.360 --> 00:08:01.040
immediately.

00:08:01.040 --> 00:08:02.355
So now, to walk through
the process.

00:08:12.420 --> 00:08:14.350
I'm not sure why it's
not showing up.

00:08:35.409 --> 00:08:38.610
OK, we're back.

00:08:38.610 --> 00:08:40.740
Sorry about that.

00:08:40.740 --> 00:08:43.250
All right, so we have
some text metadata.

00:08:43.250 --> 00:08:46.040
And luckily, we have enough of
it to correctly dereference

00:08:46.040 --> 00:08:47.060
all the concepts within it.

00:08:47.060 --> 00:08:50.400
From Shirley's video, her
description, and her title, we

00:08:50.400 --> 00:08:53.370
were able to extract the
concepts of mother, daughter,

00:08:53.370 --> 00:08:55.650
infant, mirror, and so on.

00:08:55.650 --> 00:08:58.460
Now, you see that some of
these are shown in bold.

00:08:58.460 --> 00:09:02.040
That's because we assign a score
to each concept based on

00:09:02.040 --> 00:09:03.840
its prevalence in
the metadata.

00:09:03.840 --> 00:09:06.520
For this simplified example,
I'm simply giving twice the

00:09:06.520 --> 00:09:10.180
score for any entities that
show up in the title.

00:09:10.180 --> 00:09:11.900
So now, we have some entities.

00:09:11.900 --> 00:09:13.060
We have some weighting.

00:09:13.060 --> 00:09:15.590
But we can't quite go ahead and
say infant and mirror are

00:09:15.590 --> 00:09:17.380
what this video's about
because they

00:09:17.380 --> 00:09:19.130
showed up in the title.

00:09:19.130 --> 00:09:21.300
In order to figure out what the
central entities for the

00:09:21.300 --> 00:09:26.210
video are, we use links
between concepts.

00:09:26.210 --> 00:09:28.640
We extract these from the open
internet, where we learned

00:09:28.640 --> 00:09:31.470
that mother and daughter,
daughter and infant, infant

00:09:31.470 --> 00:09:34.640
and cute tend to co-occur, and
we can build a support graph

00:09:34.640 --> 00:09:36.340
between these concepts.

00:09:36.340 --> 00:09:37.720
So now, we have weighted
entities.

00:09:37.720 --> 00:09:39.070
We have a support graph.

00:09:39.070 --> 00:09:40.760
How do we figure out
which entities are

00:09:40.760 --> 00:09:42.380
central to the video?

00:09:42.380 --> 00:09:44.640
That's where we go to scoring
and thresholding.

00:09:44.640 --> 00:09:48.970
So first, we give each entity
one point simply for existing,

00:09:48.970 --> 00:09:51.830
two points for existing in the
title in this example.

00:09:51.830 --> 00:09:54.490
And then, we give one additional
point for each

00:09:54.490 --> 00:09:56.820
entity that links
to that entity.

00:09:56.820 --> 00:09:59.110
So infant gets three more
points, because three other

00:09:59.110 --> 00:10:00.600
entities link to it.

00:10:00.600 --> 00:10:02.380
Mirror gets one more point.

00:10:02.380 --> 00:10:04.910
And after applying some
thresholding, we determine

00:10:04.910 --> 00:10:06.570
that the central entities
for this video

00:10:06.570 --> 00:10:09.310
are infant and cute.

00:10:09.310 --> 00:10:10.770
Now, that's all fair and
well when we have

00:10:10.770 --> 00:10:12.240
really good text metadata.

00:10:12.240 --> 00:10:14.920
But we're not always that
lucky, especially in

00:10:14.920 --> 00:10:16.620
the world of gaming.

00:10:16.620 --> 00:10:19.200
Oftentimes, we get gaming
videos that mention

00:10:19.200 --> 00:10:20.520
characters, that mention
levels, but

00:10:20.520 --> 00:10:21.870
don't mention the game.

00:10:21.870 --> 00:10:23.870
If you look at the video on the
right, you see "Book raid

00:10:23.870 --> 00:10:24.370
on the nether!

00:10:24.370 --> 00:10:27.046
Working Draft." If you're a
human that plays games, you

00:10:27.046 --> 00:10:28.030
know it's Minecraft.

00:10:28.030 --> 00:10:31.250
But looking just at the
metadata, you're kind of lost.

00:10:31.250 --> 00:10:33.010
Luckily, this is
a gaming video.

00:10:33.010 --> 00:10:35.700
And luckily, for gaming videos,
we're guaranteed

00:10:35.700 --> 00:10:37.520
predictable lighting
conditions.

00:10:37.520 --> 00:10:39.320
And we're also guaranteed
some static features--

00:10:39.320 --> 00:10:41.500
status bar, fonts, and
so on and so forth--

00:10:41.500 --> 00:10:45.080
so we can train classifiers to
help us identify these games.

00:10:45.080 --> 00:10:48.220
Now, this is great for games,
but it's usefulness rapidly

00:10:48.220 --> 00:10:50.640
decays when you generalize
to the general

00:10:50.640 --> 00:10:52.400
content we have on YouTube.

00:10:52.400 --> 00:10:54.420
If, for example, I were
a really great set of

00:10:54.420 --> 00:10:58.750
classifiers, and I told you that
some video featured a man

00:10:58.750 --> 00:11:01.890
in a top hat with a beard, a man
with a t-shirt, flip flops

00:11:01.890 --> 00:11:04.810
in a mall, you wouldn't be able
to deduce that this might

00:11:04.810 --> 00:11:07.760
be a modern-day parody involving
Abraham Lincoln.

00:11:07.760 --> 00:11:11.310
Those types of nuances are lost
when you use classifiers.

00:11:11.310 --> 00:11:14.300
However, because this is
available just minutes after

00:11:14.300 --> 00:11:17.370
upload and applicable for some
verticals, it remains in

00:11:17.370 --> 00:11:20.290
active development for us.

00:11:20.290 --> 00:11:23.370
But sometimes we don't even have
audiovisual features to

00:11:23.370 --> 00:11:25.560
work with or no classifiers
to match.

00:11:25.560 --> 00:11:29.370
So in the case where we have a
video that lacks both good

00:11:29.370 --> 00:11:32.090
metadata and distinct
audiovisual feature--

00:11:32.090 --> 00:11:35.170
like the video on the right
titled "Me at the zoo"--

00:11:35.170 --> 00:11:37.910
if we had a good classifier, we
might get "elephant" and we

00:11:37.910 --> 00:11:40.540
might get "man." That's
about it.

00:11:40.540 --> 00:11:43.300
However, if we look at the
context of the video--

00:11:43.300 --> 00:11:45.965
that is, the discussions going
on in the comments, the web

00:11:45.965 --> 00:11:48.400
pages that it's embedded in and
what those web pages are

00:11:48.400 --> 00:11:51.230
about, and the overall
user engagement--

00:11:51.230 --> 00:11:53.370
then we can try to figure
out what is

00:11:53.370 --> 00:11:54.405
notable about this video.

00:11:54.405 --> 00:11:56.910
And we can figure out that it's
notable because Jawed

00:11:56.910 --> 00:11:59.540
Karim is in it, and he's one of
the co-founders of YouTube,

00:11:59.540 --> 00:12:02.990
and this was the first video
ever uploaded to YouTube.

00:12:02.990 --> 00:12:05.800
Now, individually, all of these
signals are hideously

00:12:05.800 --> 00:12:07.280
noisy, as you can imagine.

00:12:07.280 --> 00:12:09.720
But on the aggregate, once you
have enough of them, they

00:12:09.720 --> 00:12:12.960
become really powerful for
really popular videos that we

00:12:12.960 --> 00:12:15.600
otherwise don't know
much about.

00:12:15.600 --> 00:12:18.010
Now, you can't quite rely on
this as uploaders, because you

00:12:18.010 --> 00:12:20.710
probably won't have every video
reach 10 million views.

00:12:20.710 --> 00:12:23.990
But if you're consumers of the
API, you can deduce from this

00:12:23.990 --> 00:12:26.800
that a video with a lot of views
is probably going to

00:12:26.800 --> 00:12:29.430
have more confident annotations
than a video with

00:12:29.430 --> 00:12:33.090
just a handful of views.

00:12:33.090 --> 00:12:36.590
So now that we know how
annotations work, I'm going to

00:12:36.590 --> 00:12:38.620
give it back to Shirley, who's
going to show us what she did

00:12:38.620 --> 00:12:41.200
on her second upload to get
better annotations.

00:12:41.200 --> 00:12:42.450
SHIRLEY GAW: So let's
talk about my

00:12:42.450 --> 00:12:46.000
favorite YouTube not-star.

00:12:46.000 --> 00:12:48.720
If you recall from the beginning
of the session, I

00:12:48.720 --> 00:12:51.420
had two versions of the
exact same video.

00:12:51.420 --> 00:12:54.080
The first version had no
annotations, and the second

00:12:54.080 --> 00:12:56.490
version had two annotations.

00:12:56.490 --> 00:12:58.170
Now, what happened in between?

00:12:58.170 --> 00:13:01.850
The first thing to recall is
that, for some reason, this

00:13:01.850 --> 00:13:05.370
video is not as popular
as I would expect.

00:13:05.370 --> 00:13:08.890
And we don't have any
blogosphere love and no

00:13:08.890 --> 00:13:11.620
comments, so that means
we can't use the

00:13:11.620 --> 00:13:13.500
video context signal.

00:13:13.500 --> 00:13:17.110
Likewise, we don't have any
audiovisual feature matching,

00:13:17.110 --> 00:13:20.510
so in this particular case,
we're relying entirely on

00:13:20.510 --> 00:13:22.460
video metadata.

00:13:22.460 --> 00:13:25.530
So if we're doing that,
then we need to have

00:13:25.530 --> 00:13:26.520
the video be public.

00:13:26.520 --> 00:13:28.900
Otherwise, it's not
caught by our

00:13:28.900 --> 00:13:31.570
video annotations pipeline.

00:13:31.570 --> 00:13:35.760
Also, if we're relying on text
metadata, that text metadata

00:13:35.760 --> 00:13:37.040
should say something.

00:13:37.040 --> 00:13:40.560
So the title should actually
be a concise description of

00:13:40.560 --> 00:13:43.570
the content of the video, and we
should be adding supporting

00:13:43.570 --> 00:13:45.290
text and tags.

00:13:45.290 --> 00:13:47.890
So the second version of video
is the same content.

00:13:47.890 --> 00:13:51.070
But it's a public video, and
we're adding metadata to

00:13:51.070 --> 00:13:55.770
support what we say that
the video is about.

00:13:55.770 --> 00:13:58.180
PHILIPP PFEIFFENBERGER: So I've
made a few references to

00:13:58.180 --> 00:14:00.540
centrality and central
annotations without really

00:14:00.540 --> 00:14:03.280
defining what it is, and that's
because it's a very

00:14:03.280 --> 00:14:05.890
narrow but powerful concept.

00:14:05.890 --> 00:14:08.950
We consider a video's
annotations to be central if

00:14:08.950 --> 00:14:10.910
these applications
are complete--

00:14:10.910 --> 00:14:13.110
that is, given the annotations,
you can figure

00:14:13.110 --> 00:14:14.840
out what the video is about--

00:14:14.840 --> 00:14:16.150
if they're specific--

00:14:16.150 --> 00:14:18.940
that is, if you can't replace
any of these entities with a

00:14:18.940 --> 00:14:20.790
more specific entity that still

00:14:20.790 --> 00:14:22.610
refers to the same concept--

00:14:22.610 --> 00:14:23.630
and if they're compact--

00:14:23.630 --> 00:14:26.360
that is, if you can't remove
any of these entities and

00:14:26.360 --> 00:14:28.600
still completely describe
the video.

00:14:28.600 --> 00:14:31.800
For example, if we had a video
of this talk and we wanted to

00:14:31.800 --> 00:14:35.250
annotate it, you would likely
choose the entities "semantic

00:14:35.250 --> 00:14:39.140
annotation," "Google I/O 2013,"
and "YouTube API,"

00:14:39.140 --> 00:14:40.960
because these would be
complete-- you know what the

00:14:40.960 --> 00:14:42.000
video's about--

00:14:42.000 --> 00:14:43.490
specific-- we can't
find anything more

00:14:43.490 --> 00:14:45.030
specific for any of them--

00:14:45.030 --> 00:14:45.840
and compact.

00:14:45.840 --> 00:14:48.190
You can't really remove any of
them and still understand what

00:14:48.190 --> 00:14:49.240
it's about.

00:14:49.240 --> 00:14:53.580
However, if we had a single
entity for this talk in

00:14:53.580 --> 00:14:56.700
Freebase, you would gladly
remove all three of these and

00:14:56.700 --> 00:14:59.790
replace them with that one
entity, because it would still

00:14:59.790 --> 00:15:03.570
be complete, specific, and
definitely compact.

00:15:03.570 --> 00:15:05.770
You could use Freebase to still
figure out that this was

00:15:05.770 --> 00:15:09.970
a talk at Google I/O, this was
about YouTube API, and so on.

00:15:09.970 --> 00:15:17.940
A layman's way that we've kind
of put this into words is an

00:15:17.940 --> 00:15:20.260
annotation is likely to be
part of a set of central

00:15:20.260 --> 00:15:23.820
annotations if you would include
the name of the entity

00:15:23.820 --> 00:15:26.670
in a one sentence description
of the video.

00:15:26.670 --> 00:15:29.610
And separately, if you are
curating a YouTube channel

00:15:29.610 --> 00:15:33.810
about this topic, would you
choose this video as a

00:15:33.810 --> 00:15:35.870
canonical example about
that entity?

00:15:35.870 --> 00:15:38.110
If you answer both of those
questions as yes

00:15:38.110 --> 00:15:40.900
independently, then this is
likely an entity that's part

00:15:40.900 --> 00:15:42.800
of the central set
of annotations.

00:15:42.800 --> 00:15:44.960
It follows then that relevant
is not central.

00:15:44.960 --> 00:15:48.370
A video of this talk annotated
with an entity for Moscone

00:15:48.370 --> 00:15:51.610
Center, that entity would not
be part of a central set of

00:15:51.610 --> 00:15:53.400
annotations, because we can
remove it and still

00:15:53.400 --> 00:15:54.500
describe the talk.

00:15:54.500 --> 00:15:56.530
And also, of course, related
is not central.

00:15:56.530 --> 00:15:58.250
Android API would not be part
of a central set of

00:15:58.250 --> 00:16:00.520
annotations.

00:16:00.520 --> 00:16:02.190
So what does that mean
for developers?

00:16:02.190 --> 00:16:05.310
Well, it means that for your
average YouTube video, you can

00:16:05.310 --> 00:16:08.160
expect one to three very
specific, very narrow

00:16:08.160 --> 00:16:12.070
annotations that should
completely describe the video.

00:16:12.070 --> 00:16:14.590
Even though these are very
specific and narrow, you can

00:16:14.590 --> 00:16:17.540
use the structured data in
Freebase, which is available

00:16:17.540 --> 00:16:20.440
as a downloadable data dump, to
get more information about

00:16:20.440 --> 00:16:22.030
these entities.

00:16:22.030 --> 00:16:25.340
Also, you should know that
more popular videos will

00:16:25.340 --> 00:16:27.840
probably have more confidence
in annotations, because we

00:16:27.840 --> 00:16:30.620
have more signals to help
us annotate them.

00:16:30.620 --> 00:16:34.200
And if you're an uploader, you
should use precise titles and

00:16:34.200 --> 00:16:36.740
cohesive descriptions that talk
about what the video's

00:16:36.740 --> 00:16:39.280
about to help us give you the
correct entities from the

00:16:39.280 --> 00:16:42.240
start and so that the other
signals simply dovetail those

00:16:42.240 --> 00:16:46.220
correct entities we
started from.

00:16:46.220 --> 00:16:48.810
So not just to talk about what
you can do with these narrow

00:16:48.810 --> 00:16:51.680
entities, but I actually kind
of want to show you what is

00:16:51.680 --> 00:16:53.210
possible with the central
annotations

00:16:53.210 --> 00:16:54.790
that we have today.

00:16:54.790 --> 00:16:57.000
I'm not going to talk about what
the demo does before I go

00:16:57.000 --> 00:16:59.560
into it, but you should
know that this is not

00:16:59.560 --> 00:17:00.750
a rules-based demo.

00:17:00.750 --> 00:17:03.030
That is, it's agnostic about
what kind of entity I'm

00:17:03.030 --> 00:17:07.390
currying for, and it's about
maybe 60 lines of Python.

00:17:07.390 --> 00:17:10.790
So say, for example, I want to
explore origami on YouTube.

00:17:10.790 --> 00:17:13.160
I don't know what origami's
about except it's about

00:17:13.160 --> 00:17:14.900
folding paper, but I
want to learn more.

00:17:14.900 --> 00:17:19.510
So I look up the entity
on Freebase.

00:17:19.510 --> 00:17:21.940
And how are videos categorized
if I use entities?

00:17:21.940 --> 00:17:24.960
Well, it turns out that origami
on YouTube tends to be

00:17:24.960 --> 00:17:28.820
different shapes of organisms,
and I can use this to learn

00:17:28.820 --> 00:17:30.050
how to fold origami.

00:17:30.050 --> 00:17:32.700
So I can start learning
folding roses, cats.

00:17:32.700 --> 00:17:35.670
And after I've spent enough time
indoors folding origami,

00:17:35.670 --> 00:17:37.630
I want to go outside and
travel a little bit.

00:17:37.630 --> 00:17:39.830
So I want to look up
what do we have

00:17:39.830 --> 00:17:41.400
about travel on YouTube.

00:17:41.400 --> 00:17:46.050
Probably videos categorized
into countries and cities.

00:17:46.050 --> 00:17:48.370
And sure enough, we have travel
videos about different

00:17:48.370 --> 00:17:52.110
countries and different
cities and so on.

00:17:52.110 --> 00:17:54.610
After a lot of traveling and
walking and sightseeing, I'm

00:17:54.610 --> 00:17:55.850
probably hungry.

00:17:55.850 --> 00:17:57.800
I want to check out some
local cuisine.

00:17:57.800 --> 00:18:00.800
So I look up what videos we have
about cuisine on YouTube,

00:18:00.800 --> 00:18:02.000
how we can structure those.

00:18:02.000 --> 00:18:04.640
And probably, we're going to see
different ingredients and

00:18:04.640 --> 00:18:06.380
different types of food.

00:18:06.380 --> 00:18:08.505
So this is actually relatively
straightforward.

00:18:13.010 --> 00:18:16.750
All I'm doing is I'm searching
for 100 videos that were

00:18:16.750 --> 00:18:19.850
centrally annotated
with origami.

00:18:19.850 --> 00:18:22.040
And then, I take all of the
other entities that those

00:18:22.040 --> 00:18:25.120
videos were annotated with, and
I use Freebase to look up

00:18:25.120 --> 00:18:26.840
their notable types.

00:18:26.840 --> 00:18:29.290
I then create clusters
of notable types.

00:18:29.290 --> 00:18:31.890
Say, for example, I had a video
annotated with origami

00:18:31.890 --> 00:18:34.256
and cat, another one
origami and bat.

00:18:34.256 --> 00:18:35.870
Cat and Bat would fall into the

00:18:35.870 --> 00:18:39.080
canonical type of organism.

00:18:39.080 --> 00:18:43.000
And then, I choose the largest
set of notable types, and then

00:18:43.000 --> 00:18:45.970
I present the entities along
with the videos that were

00:18:45.970 --> 00:18:47.440
annotated with them.

00:18:47.440 --> 00:18:49.600
So I'm going to give it back
to Shirley, who's going to

00:18:49.600 --> 00:18:52.320
walk us through the API calls
that were made behind the

00:18:52.320 --> 00:18:54.100
scenes to make this happen.

00:18:54.100 --> 00:18:55.850
SHIRLEY GAW: So just to
summarize, we're fetching

00:18:55.850 --> 00:18:59.410
content on YouTube based on a
specific Freebase topic ID.

00:18:59.410 --> 00:19:02.370
That's selected from
the user using the

00:19:02.370 --> 00:19:04.090
Freebase suggestion widget.

00:19:04.090 --> 00:19:06.900
Once we have a topic ID, we
can discover content on

00:19:06.900 --> 00:19:08.950
YouTube using universal
search.

00:19:08.950 --> 00:19:11.320
So for YouTube, that means
that we can find videos,

00:19:11.320 --> 00:19:12.730
channels, and playlists.

00:19:12.730 --> 00:19:16.230
In this particular case, we're
interested only in the videos.

00:19:16.230 --> 00:19:18.110
So suppose that the
user selected

00:19:18.110 --> 00:19:19.960
origami, like shown earlier.

00:19:19.960 --> 00:19:22.710
Then, we want to find content on
YouTube related to origami,

00:19:22.710 --> 00:19:23.940
and we get a bunch of videos--

00:19:23.940 --> 00:19:25.350
100 in this case.

00:19:25.350 --> 00:19:27.780
Now, we want to see, are
these videos about

00:19:27.780 --> 00:19:29.170
more than just origami?

00:19:29.170 --> 00:19:32.470
We want to find what are the
other central topics.

00:19:32.470 --> 00:19:35.710
So we've go to the video's
list service, find those

00:19:35.710 --> 00:19:38.580
central topics, and then look
up the notable types and

00:19:38.580 --> 00:19:41.030
cluster based on that, which is
the coloring that he showed

00:19:41.030 --> 00:19:42.290
in the demo.

00:19:42.290 --> 00:19:44.820
So first of all, Freebase
suggestion widget.

00:19:44.820 --> 00:19:46.810
This is just something that
you can find going to this

00:19:46.810 --> 00:19:49.470
website, and they'll give you
instructions for embedding it

00:19:49.470 --> 00:19:52.010
in your web page.

00:19:52.010 --> 00:19:55.740
Users type in text their
suggested entries.

00:19:55.740 --> 00:19:58.500
Now, you get a Freebase
machine ID.

00:19:58.500 --> 00:20:01.650
Let's switch over
to API Explorer.

00:20:01.650 --> 00:20:05.165
So this is a nice way of being
able to play with Google APIs

00:20:05.165 --> 00:20:06.450
for different products.

00:20:06.450 --> 00:20:09.350
So developers.googl
e.com/apis-explorer.

00:20:09.350 --> 00:20:12.860
You select the YouTube Data
API, so the latest public

00:20:12.860 --> 00:20:14.270
version of our Data API.

00:20:14.270 --> 00:20:17.330
You'll see these are different
resources and operations on

00:20:17.330 --> 00:20:18.680
those resources.

00:20:18.680 --> 00:20:21.250
In this case, we want to
discover content on YouTube

00:20:21.250 --> 00:20:23.390
related to a specific topic.

00:20:23.390 --> 00:20:26.120
And then, once we find those
videos that we're interested

00:20:26.120 --> 00:20:28.160
in, let's get more information
about them

00:20:28.160 --> 00:20:29.660
through videos list.

00:20:29.660 --> 00:20:33.690
So let's start off with finding
content on YouTube.

00:20:33.690 --> 00:20:36.440
The nice thing about the API
Explorer is that it explains

00:20:36.440 --> 00:20:39.890
what all the different
parameters are using this text

00:20:39.890 --> 00:20:40.860
on the right.

00:20:40.860 --> 00:20:43.580
And you can see what all of
them possibly are and how

00:20:43.580 --> 00:20:44.900
they're used.

00:20:44.900 --> 00:20:47.440
And then, if it's in red,
it means it's a required

00:20:47.440 --> 00:20:49.330
parameter for the request.

00:20:49.330 --> 00:20:52.922
Now, I've pre-filled
out this form.

00:20:52.922 --> 00:20:58.510
And recall the user selected a
specific suggested topic ID,

00:20:58.510 --> 00:21:03.700
topic, and then we get the
Freebase machine ID.

00:21:03.700 --> 00:21:05.265
Oops, that's a bit overkill.

00:21:07.890 --> 00:21:11.940
We say we want to find videos,
type="video" on

00:21:11.940 --> 00:21:13.180
this specific topic.

00:21:13.180 --> 00:21:15.470
I'm using origami
as the example.

00:21:15.470 --> 00:21:20.440
And we want the IDs of the
resources, and for this demo,

00:21:20.440 --> 00:21:22.740
I'm going to show you the
metadata as well.

00:21:22.740 --> 00:21:26.270
Now, Philipp's demo uses 100
videos and fetches that.

00:21:26.270 --> 00:21:29.460
In the case of the API, we can
only get 50 at a time, so

00:21:29.460 --> 00:21:32.330
we're going to have to do two
calls to get 100 videos.

00:21:32.330 --> 00:21:34.770
I'm going to execute
this request again.

00:21:34.770 --> 00:21:37.650
You'll see here this is the HTTP
GET request that you need

00:21:37.650 --> 00:21:40.750
to make, and it pretty-prints
the format of the results--

00:21:40.750 --> 00:21:43.790
so different origami videos.

00:21:43.790 --> 00:21:48.100
We can then select
these video IDs.

00:21:48.100 --> 00:21:52.140
If you recall, we have videos
related to a specific topic.

00:21:52.140 --> 00:21:53.610
Now, we're going to see
what other essential

00:21:53.610 --> 00:21:55.980
annotations there are.

00:21:55.980 --> 00:22:00.450
So I have preselected three of
these results, and we go to

00:22:00.450 --> 00:22:04.270
the videos list service up here,
GET just like in the

00:22:04.270 --> 00:22:07.690
example I showed before
with the baby.

00:22:07.690 --> 00:22:10.250
In this case though, I'm just
filling it out in a form in

00:22:10.250 --> 00:22:11.190
the API Explorer.

00:22:11.190 --> 00:22:12.790
So part="topicDetials."

00:22:12.790 --> 00:22:15.810
Comma-separated video IDs here.

00:22:15.810 --> 00:22:18.530
Execute the request.

00:22:18.530 --> 00:22:23.000
And you see in the response that
some videos have not just

00:22:23.000 --> 00:22:26.320
origami as a central topic,
but they have other topics

00:22:26.320 --> 00:22:28.480
associated with them as well.

00:22:28.480 --> 00:22:32.530
Now to see what these topics
are, we can use the Freebase

00:22:32.530 --> 00:22:34.790
Search API.

00:22:34.790 --> 00:22:40.020
So Freebase has another service
to be able to play

00:22:40.020 --> 00:22:40.620
with filters.

00:22:40.620 --> 00:22:43.061
So
api-examples.freebaseapps.com.

00:22:43.061 --> 00:22:46.440
I pre-filled in this particular

00:22:46.440 --> 00:22:47.960
Freebase machine ID.

00:22:47.960 --> 00:22:52.060
And you can see in the request
that this video was actually

00:22:52.060 --> 00:22:55.570
also about an octopus, so
origami octopus, and that its

00:22:55.570 --> 00:22:57.100
notable type is organism.

00:22:57.100 --> 00:22:59.030
So we can group videos that
are about organisms.

00:23:07.490 --> 00:23:07.601
PHILIPP PFEIFFENBERGER: Cool.

00:23:07.601 --> 00:23:09.650
So what does this tell us,
except that it's possible to

00:23:09.650 --> 00:23:12.510
build topic-agnostic
applications?

00:23:12.510 --> 00:23:14.930
Well, even though these entities
are really specific

00:23:14.930 --> 00:23:17.400
and really narrow, you can
use Freebase to get more

00:23:17.400 --> 00:23:19.210
information about each
of the entities we

00:23:19.210 --> 00:23:20.940
annotate a video with.

00:23:20.940 --> 00:23:22.980
Also, if you're building
an application

00:23:22.980 --> 00:23:24.210
that's domain specific--

00:23:24.210 --> 00:23:25.940
say, for example,
a movie site--

00:23:25.940 --> 00:23:28.790
you can use Freebase to look up
the director of a movie, to

00:23:28.790 --> 00:23:31.600
look up actors in a movie, and
then to cluster videos based

00:23:31.600 --> 00:23:33.790
on whether there are interviews,
trailers, and so

00:23:33.790 --> 00:23:35.360
on and so forth.

00:23:35.360 --> 00:23:37.410
And of course, if you think this
is really cool and you

00:23:37.410 --> 00:23:39.610
want to play with it more, we've
got a Codelab on Friday

00:23:39.610 --> 00:23:41.570
where both Shirley and
I will be TAing.

00:23:41.570 --> 00:23:43.500
And we'll guarantee you that if
you go there, you're going

00:23:43.500 --> 00:23:45.810
to walk away with a working app
that works with the Topics

00:23:45.810 --> 00:23:47.730
API and the Freebase API.

00:23:47.730 --> 00:23:51.870
And it's movies-based,
so it's pretty cool.

00:23:51.870 --> 00:23:54.040
OK, so we know we have some
decent annotations that we can

00:23:54.040 --> 00:23:57.700
do some cool stuff with, but
our work is far from over.

00:23:57.700 --> 00:23:59.790
We take quality really
seriously, and we use human

00:23:59.790 --> 00:24:02.660
evaluations to assess the
centrality of entities.

00:24:02.660 --> 00:24:04.800
We take raters, knowing their
language, pairing them with

00:24:04.800 --> 00:24:08.010
the language of the video, and
ask them, given a video, is

00:24:08.010 --> 00:24:10.580
the entity off-topic, relevant,
or central?

00:24:10.580 --> 00:24:12.720
And doing this, we've been able
to reduce the number of

00:24:12.720 --> 00:24:15.620
off-topic annotations over the
past year while maintaining

00:24:15.620 --> 00:24:17.750
coverage across the
YouTube corpus.

00:24:17.750 --> 00:24:20.740
Now aside from raters, we
depend on your feedback.

00:24:20.740 --> 00:24:22.760
So if you see off-topic
annotations, or you see

00:24:22.760 --> 00:24:25.650
systematic patterns of off-topic
annotations, please

00:24:25.650 --> 00:24:27.880
file a ticket using
gdata-issues.

00:24:27.880 --> 00:24:29.880
If you have more general
questions about annotations,

00:24:29.880 --> 00:24:32.760
you can reach out via
YouTubeDev, and we'll get them

00:24:32.760 --> 00:24:34.010
answered for you.

00:24:36.040 --> 00:24:37.990
So there are some classes of
problems that are pretty

00:24:37.990 --> 00:24:39.820
nefarious that we're battling
that I want to highlight for

00:24:39.820 --> 00:24:40.940
just a second.

00:24:40.940 --> 00:24:42.630
Common knowledge
is one of them.

00:24:42.630 --> 00:24:44.970
We assume that everyone knows
what a daughter is, what a

00:24:44.970 --> 00:24:46.470
mother is, what a baby is.

00:24:46.470 --> 00:24:48.590
And therefore, we don't put the
stuff on Wikipedia to a

00:24:48.590 --> 00:24:49.620
great extent.

00:24:49.620 --> 00:24:52.200
So for these really common
concepts, the machine

00:24:52.200 --> 00:24:54.520
repositories of knowledge that
we have are actually pretty

00:24:54.520 --> 00:24:57.080
barren, which makes it more
difficult for us to annotate

00:24:57.080 --> 00:24:58.960
these common concepts.

00:24:58.960 --> 00:25:01.260
Similarly, new topics.

00:25:01.260 --> 00:25:04.240
When "Harlem Shake" first got
popular, we happily annotated

00:25:04.240 --> 00:25:06.275
the video with "Harlem Shake,
a dance introduced

00:25:06.275 --> 00:25:08.980
in 1981." Not right.

00:25:08.980 --> 00:25:12.920
After a week and a few days,
we had an entity for Harlem

00:25:12.920 --> 00:25:15.580
Shake the internet meme, but
that's not good enough in a

00:25:15.580 --> 00:25:19.510
world where memes tend to rise
and fade within days,

00:25:19.510 --> 00:25:21.420
Also, local facts.

00:25:21.420 --> 00:25:24.550
If you upload a video simply
entitled "Hiro's Sushi

00:25:24.550 --> 00:25:26.260
Restaurant," we're going to
have a really hard time

00:25:26.260 --> 00:25:28.410
figuring out which Hiro's
Sushi restaurant it is,

00:25:28.410 --> 00:25:31.040
because there are thousands
across the country.

00:25:31.040 --> 00:25:33.480
However, in this case, it
was titled "Hiro's Sushi

00:25:33.480 --> 00:25:34.030
Restaurant--

00:25:34.030 --> 00:25:36.870
Sedona, Arizona." So we can
probably use this to figure

00:25:36.870 --> 00:25:39.790
out which restaurant was
actually mentioned, assuming

00:25:39.790 --> 00:25:43.300
we have an entity for this
restaurant in Freebase.

00:25:43.300 --> 00:25:46.220
Lastly, overlapping names in
the same concept space are

00:25:46.220 --> 00:25:47.210
pretty tricky.

00:25:47.210 --> 00:25:49.510
One of our partners, seevl,
pointed out to us that there

00:25:49.510 --> 00:25:52.140
was a little-known band called
Nirvana that we annotated

00:25:52.140 --> 00:25:54.050
wrong all the time.

00:25:54.050 --> 00:25:56.240
And we were lost, because we
know Nirvana really well.

00:25:56.240 --> 00:25:57.700
We grew up with Nirvana.

00:25:57.700 --> 00:26:00.730
And it turns out that there's
a 1970s British psychedelic

00:26:00.730 --> 00:26:03.810
band called Nirvana that we just
didn't annotate when we

00:26:03.810 --> 00:26:05.230
really should have.

00:26:05.230 --> 00:26:07.710
Again, with more metadata,
we can do a better job at

00:26:07.710 --> 00:26:08.990
disambiguation.

00:26:08.990 --> 00:26:11.340
If we have a video entitled
"Nirvana--

00:26:11.340 --> 00:26:13.860
In Bloom," which is one of their
songs from the 1990s

00:26:13.860 --> 00:26:16.460
band, we can get the right
band without a problem.

00:26:16.460 --> 00:26:18.420
But if we have "Nirvana--

00:26:18.420 --> 00:26:21.850
Live in Bristol," and nothing
else, and it's the 1970s band,

00:26:21.850 --> 00:26:24.420
we're going to guess that's it
the 1990s band, because it's a

00:26:24.420 --> 00:26:26.350
safer guess without any
other information.

00:26:26.350 --> 00:26:30.260
And we'll get it wrong
in that case.

00:26:30.260 --> 00:26:33.130
So aside from fixing bugs, which
is always fun, there's

00:26:33.130 --> 00:26:35.180
some really exciting stuff that
I'm working on right now

00:26:35.180 --> 00:26:37.320
that I'm really excited
about getting into.

00:26:37.320 --> 00:26:39.320
One of them is relevant
annotations.

00:26:39.320 --> 00:26:42.670
So we've heard the cries for
more entities per video, and

00:26:42.670 --> 00:26:45.230
we're addressing it using
relevant annotations.

00:26:45.230 --> 00:26:47.720
So just like central
annotations, relevant

00:26:47.720 --> 00:26:50.330
applications are their own
class of annotations.

00:26:50.330 --> 00:26:52.800
They're entities that are
relevant to the video and

00:26:52.800 --> 00:26:54.900
would be of interest to someone
watching the video.

00:26:54.900 --> 00:26:57.630
So, for example, in Shirley's
video, most likely "mirror"

00:26:57.630 --> 00:26:59.940
would be relevant, at least.

00:26:59.940 --> 00:27:03.560
Likewise, if we had a video of
a live concert, the location

00:27:03.560 --> 00:27:06.210
of the concert, band members
that are featured in the

00:27:06.210 --> 00:27:08.770
video, would also be relevant.

00:27:08.770 --> 00:27:10.740
Now, relevant is not related.

00:27:10.740 --> 00:27:14.910
A different band in the same
genre would not be relevant.

00:27:14.910 --> 00:27:17.480
Likewise, relevant is
not low confidence

00:27:17.480 --> 00:27:19.020
or low quality central.

00:27:19.020 --> 00:27:22.910
It's its own distinct class of
annotations that you can use

00:27:22.910 --> 00:27:25.190
knowing that they're relevant.

00:27:25.190 --> 00:27:28.780
Similarly, we'll be exposing a
taxonomy of annotations that

00:27:28.780 --> 00:27:31.970
we've established internally.

00:27:31.970 --> 00:27:35.340
At this point, if we had a video
of a tennis match, we'd

00:27:35.340 --> 00:27:38.710
be happy annotating with the
names of the tennis players,

00:27:38.710 --> 00:27:41.480
the name of the tournament,
and if we have any other

00:27:41.480 --> 00:27:45.090
information, maybe the year of
the tournament and so on.

00:27:45.090 --> 00:27:47.590
However, even though you can get
the information about it

00:27:47.590 --> 00:27:49.730
that these are tennis players
and it's about tennis from

00:27:49.730 --> 00:27:52.350
Freebase, we want to offload
some of that by exploiting

00:27:52.350 --> 00:27:55.050
taxonomy and telling you
explicitly this is a video

00:27:55.050 --> 00:27:58.940
about tennis, about racquet
sports, and about sports.

00:27:58.940 --> 00:28:01.570
So to kind of drive this home
a little bit, I took a

00:28:01.570 --> 00:28:03.370
screenshot of a video
on the right.

00:28:03.370 --> 00:28:06.050
"DVF (through Glass)." DVF
stands for Diane Von

00:28:06.050 --> 00:28:07.400
Furstenberg.

00:28:07.400 --> 00:28:10.400
And I want to ask you, looking
at this video, what do you

00:28:10.400 --> 00:28:14.670
think would be the central
entities, relevant entities,

00:28:14.670 --> 00:28:15.920
and taxonomy entities?

00:28:19.480 --> 00:28:20.730
Any brave takers?

00:28:20.730 --> 00:28:21.990
AUDIENCE: Fashion Week.

00:28:21.990 --> 00:28:22.730
PHILIPP PFEIFFENBERGER:
Fashion Week.

00:28:22.730 --> 00:28:26.330
For central, relevant,
or taxonomy?

00:28:26.330 --> 00:28:26.720
Relevant?

00:28:26.720 --> 00:28:29.150
OK.

00:28:29.150 --> 00:28:32.489
Anyone else for central
or taxonomy?

00:28:32.489 --> 00:28:33.910
AUDIENCE: Glass.

00:28:33.910 --> 00:28:34.420
PHILIPP PFEIFFENBERGER: Glass.

00:28:34.420 --> 00:28:34.890
Very good.

00:28:34.890 --> 00:28:37.310
For central, I'm guessing?

00:28:37.310 --> 00:28:38.190
Anyone else?

00:28:38.190 --> 00:28:39.070
Going once, going twice.

00:28:39.070 --> 00:28:41.186
SHIRLEY GAW: Heard something
in the audience.

00:28:41.186 --> 00:28:42.970
AUDIENCE: Events.

00:28:42.970 --> 00:28:43.310
PHILIPP PFEIFFENBERGER:
Events.

00:28:43.310 --> 00:28:45.324
For relevant?

00:28:45.324 --> 00:28:47.490
AUDIENCE: For taxonomy.

00:28:47.490 --> 00:28:49.970
PHILIPP PFEIFFENBERGER:
Yeah, that could be.

00:28:49.970 --> 00:28:50.210
OK.

00:28:50.210 --> 00:28:54.380
So for this example, which I
didn't actually annotate,

00:28:54.380 --> 00:28:56.040
central, we actually
annotated.

00:28:56.040 --> 00:28:58.580
And we had Google Glass and
Diane Von Furstenberg.

00:28:58.580 --> 00:29:01.940
Relevant would be New York
Fashion Week, because this is

00:29:01.940 --> 00:29:03.400
where this video was shot.

00:29:03.400 --> 00:29:06.770
And then taxonomy, we'd probably
put it into gadgets

00:29:06.770 --> 00:29:09.060
and technology, because it's
primarily about Google Glass.

00:29:09.060 --> 00:29:11.910
But similarly, events probably
could also fall into the

00:29:11.910 --> 00:29:13.280
taxonomy classification.

00:29:13.280 --> 00:29:17.750
So hopefully, this answered your
questions and maybe even

00:29:17.750 --> 00:29:19.690
raised some new ones that
we would love to

00:29:19.690 --> 00:29:21.311
hear at this point.

00:29:21.311 --> 00:29:24.197
[APPLAUSE]

00:29:24.197 --> 00:29:26.602
PHILIPP PFEIFFENBERGER:
Thank you.

00:29:26.602 --> 00:29:27.852
SHIRLEY GAW: Thank you.

00:29:29.970 --> 00:29:33.670
AUDIENCE: So I was curious
about Minecraft example.

00:29:33.670 --> 00:29:36.960
So how do you seed your data
for that and sort of how

00:29:36.960 --> 00:29:38.320
expansive that?

00:29:38.320 --> 00:29:43.090
So would you have every game
ever made in there?

00:29:43.090 --> 00:29:43.680
PHILIPP PFEIFFENBERGER:
I wish.

00:29:43.680 --> 00:29:45.820
AUDIENCE: Or are you
specifically listing which

00:29:45.820 --> 00:29:48.170
things you care about?

00:29:48.170 --> 00:29:49.080
PHILIPP PFEIFFENBERGER: I
wish we had every game

00:29:49.080 --> 00:29:50.150
ever made in there.

00:29:50.150 --> 00:29:53.170
That would be a dream of mine.

00:29:53.170 --> 00:29:55.670
We've got some things that
we're classifying for.

00:29:55.670 --> 00:29:58.830
I can't disclose the list of
things, because it's not very

00:29:58.830 --> 00:29:59.910
well defined.

00:29:59.910 --> 00:30:02.060
But it's something that we're
expanding to increase coverage

00:30:02.060 --> 00:30:04.970
on, because it was a big hit in
the first iteration, and we

00:30:04.970 --> 00:30:08.340
definitely want to
go further on it.

00:30:08.340 --> 00:30:08.770
AUDIENCE: Hi.

00:30:08.770 --> 00:30:11.740
I'm Lek Lek Mai from
Yale University.

00:30:11.740 --> 00:30:17.210
And we have a lot of videos that
have topics that are not

00:30:17.210 --> 00:30:20.120
covered in Freebase, but we
have our own semantic

00:30:20.120 --> 00:30:21.470
repository.

00:30:21.470 --> 00:30:25.740
So what you would you suggest
for the best way of connecting

00:30:25.740 --> 00:30:26.770
all that up?

00:30:26.770 --> 00:30:28.810
PHILIPP PFEIFFENBERGER: That's
a good question.

00:30:28.810 --> 00:30:32.800
I would reach out maybe to
someone on the Knowledge team.

00:30:32.800 --> 00:30:34.700
SHIRLEY GAW: Freebase has
a session here too.

00:30:34.700 --> 00:30:35.030
PHILIPP PFEIFFENBERGER: Yeah.

00:30:35.030 --> 00:30:37.970
Definitely reach out to
the folks on Freebase.

00:30:37.970 --> 00:30:40.520
And people working in Knowledge
in general, I think,

00:30:40.520 --> 00:30:41.830
would be really great
contacts for that.

00:30:41.830 --> 00:30:44.330
Regrettably, we're only
consumers of these knowledge

00:30:44.330 --> 00:30:46.580
repositories, and we don't
get to fully administer

00:30:46.580 --> 00:30:48.460
what goes onto them.

00:30:48.460 --> 00:30:51.980
SHIRLEY GAW: But this does come
up as a sparseness in the

00:30:51.980 --> 00:30:55.070
Knowledge Graph for specific
use cases, and one of the

00:30:55.070 --> 00:30:57.740
things to do is being able to
contribute to that graph.

00:30:57.740 --> 00:31:01.220
But since you've already had
something more developed, you

00:31:01.220 --> 00:31:03.480
might want to just directly
ask Freebase how you can

00:31:03.480 --> 00:31:05.210
contribute that information.

00:31:05.210 --> 00:31:05.500
AUDIENCE: OK.

00:31:05.500 --> 00:31:07.110
Could I ask one more
quick question?

00:31:07.110 --> 00:31:07.540
PHILIPP PFEIFFENBERGER:
Of course.

00:31:07.540 --> 00:31:10.460
AUDIENCE: So you talked about
terms and vocabularies that

00:31:10.460 --> 00:31:11.180
you're using.

00:31:11.180 --> 00:31:15.320
And just wanted to ask, have you
looked at other services

00:31:15.320 --> 00:31:17.640
that have vocabularies in
broader terms and narrower

00:31:17.640 --> 00:31:21.470
terms, like the Getty
Vocabulary, for example, and

00:31:21.470 --> 00:31:23.070
utilizing those?

00:31:23.070 --> 00:31:25.220
PHILIPP PFEIFFENBERGER:
No, I have not.

00:31:25.220 --> 00:31:27.200
That sounds really interesting
though.

00:31:27.200 --> 00:31:27.610
AUDIENCE: OK.

00:31:27.610 --> 00:31:28.400
Maybe after the session.

00:31:28.400 --> 00:31:29.650
PHILIPP PFEIFFENBERGER:
Yeah, definitely.

00:31:31.840 --> 00:31:32.520
AUDIENCE: Hi there.

00:31:32.520 --> 00:31:33.785
I'm Jarom McDonald.

00:31:33.785 --> 00:31:35.420
I'm from Brigham Young
University.

00:31:35.420 --> 00:31:37.430
One question that I had--

00:31:37.430 --> 00:31:39.820
and you may have quickly
glossed over it.

00:31:39.820 --> 00:31:42.330
But if you have any further
details, it'd be really

00:31:42.330 --> 00:31:42.950
interesting.

00:31:42.950 --> 00:31:48.470
Other types of YouTube
annotations, the interactive

00:31:48.470 --> 00:31:52.550
clicks and the questions that
are in and so forth are able

00:31:52.550 --> 00:31:55.230
to link temporally and spatial
to your video, whereas it

00:31:55.230 --> 00:31:57.560
looks like a lot of the things
you can do with the Topics API

00:31:57.560 --> 00:31:59.430
is just for the video
as a whole.

00:31:59.430 --> 00:32:02.530
And do you see any ability,
either now or eventually, to

00:32:02.530 --> 00:32:06.280
be able to link topics to
individual temporal moments in

00:32:06.280 --> 00:32:09.370
the video or spatial
areas of the video?

00:32:09.370 --> 00:32:11.780
PHILIPP PFEIFFENBERGER: That's
a really good idea.

00:32:11.780 --> 00:32:14.710
To be honest, at this point, we
really want to get it right

00:32:14.710 --> 00:32:15.620
for the video as a whole.

00:32:15.620 --> 00:32:17.800
But having that finer
granularity would definitely

00:32:17.800 --> 00:32:20.110
be an asset.

00:32:20.110 --> 00:32:20.550
AUDIENCE: Thanks.

00:32:20.550 --> 00:32:21.630
SHIRLEY GAW: Thanks for
the suggestion.

00:32:21.630 --> 00:32:23.426
PHILIPP PFEIFFENBERGER: Yeah.

00:32:23.426 --> 00:32:23.870
AUDIENCE: Hey.

00:32:23.870 --> 00:32:26.480
So you guys were talking about
the text metadata for a little

00:32:26.480 --> 00:32:29.440
while and how that's kind of
like the first line of defense

00:32:29.440 --> 00:32:31.630
since you have it earliest.

00:32:31.630 --> 00:32:34.620
And maybe I just missed it, but
do you guys also work with

00:32:34.620 --> 00:32:38.490
comments and user data
afterwards as that comes in?

00:32:38.490 --> 00:32:39.340
PHILIPP PFEIFFENBERGER:
Yes, exactly.

00:32:39.340 --> 00:32:41.690
So that's part of the context
of the video.

00:32:41.690 --> 00:32:46.500
So we look at the comments of
the video, and we look at all

00:32:46.500 --> 00:32:48.740
the web pages where
the video appears.

00:32:48.740 --> 00:32:51.730
And then, we also extract
concepts from the comments and

00:32:51.730 --> 00:32:54.280
from the web pages and
try to figure, OK,

00:32:54.280 --> 00:32:55.720
well, what's the overlap?

00:32:55.720 --> 00:32:57.240
And sometimes, there
can be some pretty

00:32:57.240 --> 00:32:59.200
funny stuff that happens.

00:32:59.200 --> 00:33:03.540
When I was first playing with
this, there was a video of

00:33:03.540 --> 00:33:06.680
"Another One Bites the Dust,"
and one of the entities that

00:33:06.680 --> 00:33:08.740
kept coming up was
Kim Jong-il.

00:33:08.740 --> 00:33:10.260
And I'm like, why is that?

00:33:10.260 --> 00:33:12.670
And it turns out that when Kim
Jong-il passed away, in the

00:33:12.670 --> 00:33:14.860
forums, people kept embedding
this video.

00:33:14.860 --> 00:33:18.180
So individually, these sources
you can kind of forget about.

00:33:18.180 --> 00:33:19.950
But again, once you have enough
of them, and once you

00:33:19.950 --> 00:33:23.720
have enough data, you can see
what kind of things emerge

00:33:23.720 --> 00:33:26.160
from them after doing
some filtering.

00:33:26.160 --> 00:33:28.660
AUDIENCE: Thanks.

00:33:28.660 --> 00:33:28.970
AUDIENCE: Hi.

00:33:28.970 --> 00:33:31.510
I was wondering if you also did
speech recognition on the

00:33:31.510 --> 00:33:34.220
video themselves to get
extra text from that.

00:33:34.220 --> 00:33:35.080
PHILIPP PFEIFFENBERGER: That's
a good question.

00:33:35.080 --> 00:33:37.870
So we've looked at a
number of things--

00:33:37.870 --> 00:33:39.480
speech recognition,
transcripts, and

00:33:39.480 --> 00:33:40.400
so on and so forth.

00:33:40.400 --> 00:33:43.200
And what tends to happen is if,
for example, you have a

00:33:43.200 --> 00:33:45.440
video of the State of the
Union, and you do speech

00:33:45.440 --> 00:33:48.490
recognition, you'll figure that
it's about the economy,

00:33:48.490 --> 00:33:51.520
it's about jobs, it's about
current events, and

00:33:51.520 --> 00:33:52.840
so on and so forth.

00:33:52.840 --> 00:33:55.490
But you miss that it's the
State of the Union.

00:33:55.490 --> 00:33:58.660
So it's something that we
might look in again as a

00:33:58.660 --> 00:33:59.810
guiding signal.

00:33:59.810 --> 00:34:02.910
But by itself, oftentimes what's
mentioned in the video

00:34:02.910 --> 00:34:04.890
isn't necessarily what
the video is about,

00:34:04.890 --> 00:34:06.140
except in a few cases.

00:34:09.032 --> 00:34:10.480
AUDIENCE: Hi.

00:34:10.480 --> 00:34:12.570
So actually, that's kind of a
related question to what I

00:34:12.570 --> 00:34:13.820
want to ask.

00:34:13.820 --> 00:34:16.280
A lot of the stuff you're doing
seems to be where you

00:34:16.280 --> 00:34:19.300
have an explicit word or
something like infant that

00:34:19.300 --> 00:34:20.760
represents a concept,
and then you go and

00:34:20.760 --> 00:34:22.780
find that in Freebase.

00:34:22.780 --> 00:34:26.960
Is there, I guess, potential for
expansion using something

00:34:26.960 --> 00:34:30.909
like WordNet, where if you don't
recognize maybe one of

00:34:30.909 --> 00:34:33.239
the words in it, going and
finding something that might

00:34:33.239 --> 00:34:34.889
be semantically related?

00:34:34.889 --> 00:34:40.230
Or is that kind of too noisy,
I guess, for your approach?

00:34:40.230 --> 00:34:43.080
PHILIPP PFEIFFENBERGER: I'm
not familiar with WordNet.

00:34:43.080 --> 00:34:46.510
But if there are words that we
don't recognize, we basically

00:34:46.510 --> 00:34:47.350
just don't treat them.

00:34:47.350 --> 00:34:49.469
Like if you have the name of
someone who we don't recognize

00:34:49.469 --> 00:34:52.380
or who doesn't match any
sort of concept,

00:34:52.380 --> 00:34:53.659
then that's just skipped.

00:34:53.659 --> 00:34:56.290
SHIRLEY GAW: So WordNet, I'm
more familiar with that.

00:34:56.290 --> 00:35:00.240
So it would be like synonyms and
antonyms of that concept.

00:35:00.240 --> 00:35:01.950
I don't know if it's actually
a source for

00:35:01.950 --> 00:35:03.040
the Knowledge Graph.

00:35:03.040 --> 00:35:05.100
I can't specify for that one.

00:35:05.100 --> 00:35:07.590
But in the case of the baby
video, it was really tough.

00:35:07.590 --> 00:35:11.000
Because "baby" can be, as he
said, a Justin Bieber song.

00:35:11.000 --> 00:35:14.920
So I did actually have to look
at a data dump from Freebase

00:35:14.920 --> 00:35:17.190
and see what kinds of concepts
would support

00:35:17.190 --> 00:35:18.980
the topic of baby.

00:35:18.980 --> 00:35:21.410
So that's actually where
it would come in.

00:35:21.410 --> 00:35:24.040
I don't know if WordNet would do
that for you, but you could

00:35:24.040 --> 00:35:27.310
definitely use Freebase and
the related concepts to

00:35:27.310 --> 00:35:28.120
support that.

00:35:28.120 --> 00:35:29.340
PHILIPP PFEIFFENBERGER: And
we do support synonyms.

00:35:29.340 --> 00:35:33.870
So for example, DVF would
probably dereference to Diane

00:35:33.870 --> 00:35:35.630
Von Furstenberg, especially
with other

00:35:35.630 --> 00:35:36.760
things supporting it.

00:35:36.760 --> 00:35:41.650
So as long as you mention the
concepts in the video and you

00:35:41.650 --> 00:35:44.440
help us dereference it to get
to the right ones, even if

00:35:44.440 --> 00:35:46.570
there are synonyms, we try
to be smart enough

00:35:46.570 --> 00:35:48.620
to allow for that.

00:35:48.620 --> 00:35:50.780
AUDIENCE: Thank you.

00:35:50.780 --> 00:35:51.290
AUDIENCE: Hey.

00:35:51.290 --> 00:35:54.410
You said in your simple case
that you were just weighting

00:35:54.410 --> 00:35:57.250
title as double the
description.

00:35:57.250 --> 00:35:59.300
Obviously, the world is
not a simple case.

00:35:59.300 --> 00:36:02.210
What machine learning approaches
are you taking to

00:36:02.210 --> 00:36:04.160
work out what these weightings
should be?

00:36:04.160 --> 00:36:06.660
PHILIPP PFEIFFENBERGER: We
try a lot of things.

00:36:06.660 --> 00:36:09.380
I can't speak to the actual
approaches that we use in

00:36:09.380 --> 00:36:13.170
detail, but it's definitely
not the simple case.

00:36:13.170 --> 00:36:15.086
I'm sorry, I can't answer
to more detail on that.

00:36:19.850 --> 00:36:23.080
Anyone else?

00:36:23.080 --> 00:36:23.310
OK.

00:36:23.310 --> 00:36:25.460
Well, we'll also be hanging out
in the Sandbox for a few

00:36:25.460 --> 00:36:27.810
minutes after this talk if you
have questions you want to ask

00:36:27.810 --> 00:36:28.740
one on one.

00:36:28.740 --> 00:36:30.220
And thank you for attending
this talk.

00:36:30.220 --> 00:36:31.230
SHIRLEY GAW: Thanks very much.

00:36:31.230 --> 00:36:35.130
[APPLAUSE]

