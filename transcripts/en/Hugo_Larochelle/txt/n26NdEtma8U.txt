Speaker 1:          00:00          In this video, we'll look at an example of a running, a restricted both in machine learning algorithm with contrasted divergence on some given dataset. And in particular, what we'll look at is what types of features. So what types of hidden units, uh, it would have restrictive Bolsa machine learn on a Dataset of Hendrickson, uh, characters, Henry the digits. So here are a few, uh, uh, visualize is a visualization of a few training example from a, they said call the amness Dataset. It's a very popular data set for neural network research. Uh, so in this case, the, uh, images are 28 by 28 pixel images. And uh, well we can do is use these images, uh, and put them into the form of effector and then just train the restrictive bolsa machine on these examples. And then once that's done, look at the types of features that each of the different hidden units represent.

Speaker 2:          01:06          Okay.

Speaker 1:          01:07          To do this, where we can do is we can take each hidden unit and visualize the connections between that hidden unit and each element and the input vectors. I'm actually drawing arrows, uh, though, remember the receipts of both the machine is undirected. But what I want to emphasize is that each of the illustration here actually corresponds to, uh, the, uh, vector of connections between one hidden unit, h j and each of the pixel x one up to x d. And, uh, because x is actually an image, I can take that vector of connections, actually reshape it into an image in order to visualize it. So specifically each square here, curse bonds to one hidden unit, and then the color of the pixel at the intensity of the Pixel, a says something about what's the value of the connection between that hidden unit and the Pixel at the same position in the original image.

Speaker 1:          02:14          So our gray in particular in this visualization corresponds to await, uh, equal to zero, whereas a, a white pixel corresponds to a weight that is a positive. And the wider it is, the more positive it is. Whereas black [inaudible] negative pixels. And again, the darker the Pixel is, the more negative the weights. And, uh, so what this means is that for instance, if we take that hidden unit, when we compute the probability of that hidden, you're being called to one, it means that we are doing a, uh, essentially applying what we can think of as a filter on the image. So we're multiplying this a set of connections to the image and then we're summing the uh, uh, the product of each, uh, element here in this connection with the image. Uh, so if uh, part of the image is great means that we're multiplying by zero.

Speaker 1:          03:16          So whatever the value of the Pixel is it one, uh, actually have an impact on the value of the or the probability of the hidden unit. If it's white, it means that if the pixel is none, zero, then uh, it will actually increase the probability of that hidden units. So if we add white pixels here in the original image, then that would increase the property of that hidden unit to be equal to one. And if it's black like here, it means that. And the other hand, if the, uh, of the Pixel is, is positive there is non zero, then this will actually decrease the probability of the hidden unit being called to one. So, uh, an interpretation of this particular neuron is that it detects whether there's a pen stroke with this orientation where there's background here and here and we have, she have a stroke like this.

Speaker 1:          04:07          Similarly here, this sit in unit would be sensitive if there's a pen stroke like that in the image with some, uh, background here and here. And so we actually find that a lot of these hidden units essentially learned that in characters, Hendrick, the characters of images, there are essentially pen strokes. Uh, so, you know, this would be another pen stroke here where it happened at stroke, kind of like this. Uh, we have other units that are not necessarily as easily interpretable as pen strokes, but still it's a learn some, uh, I think, um, position essentially, uh, what Henry did, character is as a set of different, uh, uh, uh, pen strokes in different isolated regions of the image. And we can think that, you know, it's not too hard to convince ourselves that these types of features might actually be useful in order to identify him. For instance, what's the category of the, uh, of the, uh, of the image. Um, in particular when we have an image of a character, he, it's much more easier for us to describe it as a composition of pen strokes then as a composition of pixels. So perhaps a representation of an image of a character as a set of pen strokes might actually be, make the identity of the, uh, of the character much more evident to the learning algorithm.

Speaker 3:          05:32          Yeah.

Speaker 1:          05:32          Um, unfortunately, rbms are not very easy to debug, so we can actually use a finite difference, a approximation of the gradient. Then compare that with our estimate that the gradient in the learning update. And that's again, because we have a partition function which is intractable. Uh, so I just want to mention a few tricks that people sometimes use to try to debug their implementation. Sometimes people look at something, a we'll call an average stacastic reconstruction, which is does the squared a norm between of the difference between each training example and the result of performing one step of GIB sampling starting at x t. Um, and so normally you'd sort of expect that initially, uh, you'd get a high value of that average and then this would sort of get smaller and smaller and smaller. We don't essentially, we don't necessarily expect this to converge to zero for instance, but it should in a general, we sort of expected to decrease.

Speaker 1:          06:33          Um, also we can visualize the features that are learned, like which is still, uh, if we have images then we tend to expect things that are visually meaningful like edges or a pen, strokes for handwritten characters. Uh, and another thing we can do is actually try to approximate the partition function in order to be able to evaluate what is log of p of XD. And then if we can do this, then we could, for instance, track on the training set how this progresses. So in particular, the average negative log likelihood we'd expect it to decrease. On the training set. Um, now, uh, getting a good approximate of this is not very easy. Uh, there is some work that I'm citing here, uh, which has suggested a fairly efficient way of estimating the partition function. Still. It's, uh, it's efficient for a fixed RBM, uh, but it will still require, uh, uh, you know, not an exponential amount of time, but still a meaningful amount of time for a fixed RBM to compute this, if we wanted to actually track how the partition function changes as we're updating a reperforming, that computation can be, uh, still expensive.

Speaker 1:          07:50          Though there are some research we're trying to track the partition function, uh, which, uh, you can find online, but essentially we have tricks for trying to get an idea as to whether, uh, an implementation of an RBM training works well. But these are really tricks and unfortunately we don't have a tool as reliable as a finite difference approximation.