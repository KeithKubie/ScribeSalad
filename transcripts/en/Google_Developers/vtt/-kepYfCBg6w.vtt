WEBVTT
Kind: captions
Language: en

00:00:01.133 --> 00:00:03.767
Haugh: Hi, everybody.
I'm Justin Haugh.

00:00:03.767 --> 00:00:05.200
Darke:
And I'm Greg Darke.

00:00:05.200 --> 00:00:07.334
Haugh: So I hope you guys
had a good lunch,

00:00:07.334 --> 00:00:11.467
and you're ready
for something cool.

00:00:11.467 --> 00:00:14.667
So we're here today to talk
about App Engine Backends.

00:00:14.667 --> 00:00:16.934
I'm a software engineer

00:00:16.934 --> 00:00:19.534
on the App Engines Systems
Infrastructure team.

00:00:19.534 --> 00:00:20.968
Darke: And I'm also
a software engineer,

00:00:20.968 --> 00:00:23.100
but I work on
the Task Queue Infrastructure.

00:00:23.100 --> 00:00:26.334
Haugh: So there's
a few links on this page,

00:00:26.334 --> 00:00:29.667
if you guys are following along,
a link to the session

00:00:29.667 --> 00:00:32.801
and you can go
to SpeakerMeter

00:00:32.801 --> 00:00:37.234
to rate our performance.

00:00:37.234 --> 00:00:42.267
Okay, so we're here today to
talk about App Engine Backends.

00:00:42.267 --> 00:00:44.934
We'll start off with a little
bit of a brief description

00:00:44.934 --> 00:00:46.567
of how we do things
on App Engine,

00:00:46.567 --> 00:00:49.167
why we do,
what that means,

00:00:49.167 --> 00:00:50.667
and then we'll talk
about backends

00:00:50.667 --> 00:00:53.601
and what they're offering,

00:00:53.601 --> 00:00:55.067
go through
"Hello world" examples,

00:00:55.067 --> 00:00:59.033
some configuration, and then,
we'll have a brief demo.

00:00:59.033 --> 00:01:00.801
We'll wrap up with
some best practices,

00:01:00.801 --> 00:01:03.634
caveats,
and the future.

00:01:03.634 --> 00:01:06.734
Okay, so I just want to talk
just for a second

00:01:06.734 --> 00:01:08.901
about the App Engine way
of doing things.

00:01:08.901 --> 00:01:11.467
If you go back to the original
blog post for App Engine,

00:01:11.467 --> 00:01:12.834
the goal of App Engine

00:01:12.834 --> 00:01:14.801
is to make it easy to get
started with a new web app

00:01:14.801 --> 00:01:16.267
and then make it easy
to scale that app

00:01:16.267 --> 00:01:18.934
when it reaches the point
where it's receiving

00:01:18.934 --> 00:01:21.667
significant traffic
and has millions of users.

00:01:21.667 --> 00:01:22.734
So App Engine is supposed--

00:01:22.734 --> 00:01:24.634
the goal of App Engine
is to have--

00:01:24.634 --> 00:01:26.467
to provide
a very high performance

00:01:26.467 --> 00:01:31.701
web application infrastructure
for your applications.

00:01:31.701 --> 00:01:32.934
And what that means is,

00:01:32.934 --> 00:01:35.200
it should be very easy
to deploy new apps.

00:01:35.200 --> 00:01:36.968
It scales
dynamically for you.

00:01:36.968 --> 00:01:39.734
You have
a really high performance

00:01:39.734 --> 00:01:43.300
scalable storage layer,
a rich set of APIs,

00:01:43.300 --> 00:01:48.300
and the whole philosophy
behind App Engine

00:01:48.300 --> 00:01:50.501
is about breaking
very large problems,

00:01:50.501 --> 00:01:52.767
like serving thousands
of queries a second,

00:01:52.767 --> 00:01:57.334
into very small pieces
and performing them in parallel,

00:01:57.334 --> 00:01:59.534
being fault-tolerant,
horizontal scaling.

00:01:59.534 --> 00:02:03.000
So this is the philosophy
behind how App Engine works,

00:02:03.000 --> 00:02:07.734
and you guys are probably
very familiar with that.

00:02:07.734 --> 00:02:10.267
But there's a few things
about this philosophy.

00:02:10.267 --> 00:02:12.234
Not everything
is a web app.

00:02:12.234 --> 00:02:14.534
Maybe you just want to run
a command on the server

00:02:14.534 --> 00:02:18.400
and generate a report.

00:02:18.400 --> 00:02:20.434
What if you want to just have
a single global counter

00:02:20.434 --> 00:02:21.868
or set of global counters

00:02:21.868 --> 00:02:25.601
that are tracking data and
aggregate for your application.

00:02:25.601 --> 00:02:27.501
These things are a little
hard to do.

00:02:27.501 --> 00:02:29.601
You might have to
shard your counter

00:02:29.601 --> 00:02:34.167
and have relatively
complex operations

00:02:34.167 --> 00:02:37.467
to try to compute a total.

00:02:37.467 --> 00:02:39.400
The instances
are very lightweight.

00:02:39.400 --> 00:02:42.901
They have relatively low memory,
limited amounts of CPU,

00:02:42.901 --> 00:02:44.334
and they're anonymous.

00:02:44.334 --> 00:02:46.200
They're not addressable,
so you can't guarantee

00:02:46.200 --> 00:02:47.701
that you're going back
to the same instance

00:02:47.701 --> 00:02:49.667
on a second request.

00:02:49.667 --> 00:02:51.000
There's 30-second deadlines,

00:02:51.000 --> 00:02:53.467
which I'm guessing you guys
are familiar with.

00:02:53.467 --> 00:02:58.434
And, again,
they're anonymous.

00:02:58.434 --> 00:03:00.868
So there's a lot of
restrictions

00:03:00.868 --> 00:03:04.734
that App Engine puts in place
in order to guide you

00:03:04.734 --> 00:03:07.434
to making a very highly scalable
application.

00:03:07.434 --> 00:03:10.300
Break things into small pieces,
30-second requests,

00:03:10.300 --> 00:03:13.501
a lot of small instances
that grow and shrink

00:03:13.501 --> 00:03:17.501
in response to traffic.

00:03:17.501 --> 00:03:19.834
Well, today, we're announcing
something called backends,

00:03:19.834 --> 00:03:23.968
which changes how things work
on App Engine.

00:03:23.968 --> 00:03:25.100
This is the full
public release,

00:03:25.100 --> 00:03:28.067
as of this morning,
of App Engine Backends.

00:03:28.067 --> 00:03:30.133
We posted on the blog
this morning,

00:03:30.133 --> 00:03:33.033
and this talk will be about
how backends work

00:03:33.033 --> 00:03:35.634
and what they do for you.

00:03:35.634 --> 00:03:39.501
They're a powerful new way
to write programs on App Engine.

00:03:39.501 --> 00:03:42.934
They let you do things
that were not possible before,

00:03:42.934 --> 00:03:46.367
and they make App Engine
much more of a complete

00:03:46.367 --> 00:03:50.000
general purpose
computing platform.

00:03:50.000 --> 00:03:53.868
So what are backends?

00:03:53.868 --> 00:03:56.234
Backends
are App Engine instances

00:03:56.234 --> 00:03:58.934
with some unique features.

00:03:58.934 --> 00:04:02.334
They can run
for long periods of time.

00:04:02.334 --> 00:04:04.234
They're high performance.

00:04:04.234 --> 00:04:06.968
They're configurable.

00:04:06.968 --> 00:04:09.801
Each backend
is addressable.

00:04:09.801 --> 00:04:13.367
They're persistent in memory
over long periods of time.

00:04:13.367 --> 00:04:18.968
These are high-performance cloud
processes running on App Engine.

00:04:18.968 --> 00:04:21.400
They're powerful building blocks
for application

00:04:21.400 --> 00:04:25.133
and can be combined
to make really interesting

00:04:25.133 --> 00:04:28.968
high performance
distributed applications.

00:04:28.968 --> 00:04:32.734
They're very easy to use,
and they're very flexible.

00:04:32.734 --> 00:04:35.734
So what are the features?

00:04:35.734 --> 00:04:38.200
Well, an App Engine backend
can be configured

00:04:38.200 --> 00:04:42.534
with anywhere from 128 megs
up to a gigabyte of RAM.

00:04:42.534 --> 00:04:45.667
They can use up to
4.8 gigahertz of CPU.

00:04:45.667 --> 00:04:49.501
There's no request deadlines
to backends.

00:04:49.501 --> 00:04:51.834
They can run indefinitely.

00:04:51.834 --> 00:04:54.467
They can be addressed
individually.

00:04:54.467 --> 00:04:56.300
They can be configured
to be resident in memory

00:04:56.300 --> 00:04:58.000
for long periods,

00:04:58.000 --> 00:05:00.834
or dynamic in response
to traffic,

00:05:00.834 --> 00:05:04.534
and they automatically restart
if they ever go down,

00:05:04.534 --> 00:05:05.801
and they're very App Engine-y.

00:05:05.801 --> 00:05:06.868
They're easy to configure.

00:05:06.868 --> 00:05:08.901
You can deploy them
very quickly.

00:05:08.901 --> 00:05:11.000
You get all the nice graphs,
and consoles, and charts

00:05:11.000 --> 00:05:13.000
that you're used to having
with App Engine,

00:05:13.000 --> 00:05:16.334
and there's dev appserver
support for backends.

00:05:16.334 --> 00:05:19.133
So what does this mean?

00:05:19.133 --> 00:05:21.567
App Engine, again,
it's now much more of

00:05:21.567 --> 00:05:23.667
a general purpose
cloud computing platform.

00:05:23.667 --> 00:05:26.033
It's suitable for
high-performance servers.

00:05:26.033 --> 00:05:28.634
You can do large amounts
of in-memory caching,

00:05:28.634 --> 00:05:32.734
self-driven programs that start
and just run continuously,

00:05:32.734 --> 00:05:36.000
tiered architectures, and
heavyweight offline processing.

00:05:36.000 --> 00:05:38.300
And at this point,
App Engine is really suitable

00:05:38.300 --> 00:05:43.067
for a lot more
than just websites.

00:05:43.067 --> 00:05:46.901
So what are use cases
for backends?

00:05:46.901 --> 00:05:49.033
Anything memory intensive
is a good fit.

00:05:49.033 --> 00:05:50.868
So if you have
a web search index

00:05:50.868 --> 00:05:52.400
that you want to keep
in memory,

00:05:52.400 --> 00:05:54.567
or really any type of
search index,

00:05:54.567 --> 00:05:56.367
if you want to have
a giant social graph

00:05:56.367 --> 00:05:58.067
that you keep in memory,

00:05:58.067 --> 00:05:59.968
if you're running
a game server,

00:05:59.968 --> 00:06:01.834
if you want to do
your own custom memcache

00:06:01.834 --> 00:06:04.701
with your own hash function
and sharding,

00:06:04.701 --> 00:06:06.734
if you want to do something
that uses a lot of CPU,

00:06:06.734 --> 00:06:10.234
image manipulation,
audio/video encoding.

00:06:10.234 --> 00:06:12.934
If you're doing some
scientific computing,

00:06:12.934 --> 00:06:16.267
App Engine now could be a better
fit for that, or, of course,

00:06:16.267 --> 00:06:20.734
mean generation could be
definitely a case.

00:06:20.734 --> 00:06:24.467
So background processing,
if you have a data pipeline

00:06:24.467 --> 00:06:27.934
that's taking data and
performing several transforms,

00:06:27.934 --> 00:06:29.234
something that runs
continuously,

00:06:29.234 --> 00:06:30.968
that's a good fit.

00:06:30.968 --> 00:06:34.567
A web crawler, task execution.
You can now handle tasks.

00:06:34.567 --> 00:06:36.334
You can direct tasks
at a backend,

00:06:36.334 --> 00:06:39.901
and they can just run
without a deadline, basically.

00:06:39.901 --> 00:06:41.300
It's actually 24 hours,

00:06:41.300 --> 00:06:44.434
but that's a little bit
of an improvement.

00:06:44.434 --> 00:06:45.767
Commands and scripts,

00:06:45.767 --> 00:06:49.334
you can issue a command yourself
to a dynamic backend.

00:06:49.334 --> 00:06:50.467
It starts up.

00:06:50.467 --> 00:06:53.300
It can just run
until the script is done.

00:06:53.300 --> 00:06:54.968
You can have
ad-hoc queries.

00:06:54.968 --> 00:06:56.834
You can have backends
that generate load

00:06:56.834 --> 00:06:58.067
for your application,

00:06:58.067 --> 00:06:59.534
and if you were
at the last talk,

00:06:59.534 --> 00:07:01.701
you know how important
that is for building

00:07:01.701 --> 00:07:05.200
a scalable app
or report generation.

00:07:05.200 --> 00:07:07.701
So let's see "Hello world."

00:07:07.701 --> 00:07:08.767
Okay, this is an app.yaml.

00:07:08.767 --> 00:07:12.734
Looks pretty simple,
pretty familiar.

00:07:12.734 --> 00:07:15.200
So what we add here
is a backends.yaml file,

00:07:15.200 --> 00:07:17.400
and we're going to create
one backend named "Hello,"

00:07:17.400 --> 00:07:20.434
and we'll make it public,
so that we can access it,

00:07:20.434 --> 00:07:24.000
and it's available at
hellobackends-io.appspot.com.

00:07:24.000 --> 00:07:26.767
So you'll notice that we're
addressing this backend

00:07:26.767 --> 00:07:30.234
by adding the backend name
as a prefix to the URL.

00:07:30.234 --> 00:07:32.567
So traffic,
without this prefix,

00:07:32.567 --> 00:07:36.501
is directed to backends-io
dynamic application version

00:07:36.501 --> 00:07:39.601
with the prefix instruct
at the backend.

00:07:39.601 --> 00:07:42.200
And you can add instances.
So here's 15 instances.

00:07:42.200 --> 00:07:43.400
Each one has an address,

00:07:43.400 --> 00:07:46.167
and you can reliably
contact each instance

00:07:46.167 --> 00:07:50.100
by appending
the instance index to the URL.

00:07:53.000 --> 00:07:55.801
Hello.py,
pretty simple, right?

00:07:55.801 --> 00:07:59.100
And we have added
this new backends API

00:07:59.100 --> 00:08:01.367
with methods like
get the backend name.

00:08:01.367 --> 00:08:03.734
You can get the instance
index of the backend

00:08:03.734 --> 00:08:05.334
that you're working with.

00:08:05.334 --> 00:08:08.200
There's functions for
computing the URL of a backend

00:08:08.200 --> 00:08:11.434
or other backends
and the host name.

00:08:11.434 --> 00:08:13.601
So commands for working
with backends,

00:08:13.601 --> 00:08:17.734
these are new, as of 1-5-0.

00:08:17.734 --> 00:08:19.467
Fairly familiar
backends update,

00:08:19.467 --> 00:08:22.968
works a lot like
appcfg update does currently.

00:08:22.968 --> 00:08:24.834
You could figure
your backend.

00:08:24.834 --> 00:08:27.033
You run appcfg update,
and now you have a backend

00:08:27.033 --> 00:08:30.467
that's running
in Google's cloud.

00:08:30.467 --> 00:08:32.267
List, start,
stop, delete;

00:08:32.267 --> 00:08:34.868
we'll get into
more of what those do.

00:08:34.868 --> 00:08:37.501
So here's an example
of what this looks like--

00:08:37.501 --> 00:08:41.033
pretty similar to
what you guys are used to.

00:08:41.033 --> 00:08:44.767
If you do a list,
this is what you'll get back.

00:08:44.767 --> 00:08:47.467
You're getting back the backend
config that the server has,

00:08:47.467 --> 00:08:49.734
and you'll notice
that the state is "start."

00:08:49.734 --> 00:08:53.033
So with backends, you can
start and stop them yourself,

00:08:53.033 --> 00:08:57.434
and you can decide whether
they're serving traffic or not.

00:08:57.434 --> 00:09:02.601
And appcfgbackends.stop
will stop the server.

00:09:02.601 --> 00:09:06.634
And you can see, if you
do a list, that it stopped.

00:09:06.634 --> 00:09:11.501
And again, you can
start and stop them.

00:09:11.501 --> 00:09:13.801
Okay, so let's dive
into some configuration.

00:09:13.801 --> 00:09:15.167
What can you do here?

00:09:15.167 --> 00:09:17.567
So the backends.yaml file,
it lists each backend.

00:09:17.567 --> 00:09:19.667
You can define up to five.

00:09:19.667 --> 00:09:21.901
The app.yaml is the same
as it is before,

00:09:21.901 --> 00:09:23.334
except the version
is now optional,

00:09:23.334 --> 00:09:26.267
because you may have just an app
that only has backends,

00:09:26.267 --> 00:09:29.567
so you can just configure
it that way.

00:09:29.567 --> 00:09:32.334
The handlers that you are
normally used to working with

00:09:32.334 --> 00:09:34.200
are still defined
in app.yaml,

00:09:34.200 --> 00:09:36.167
and they're shared
by the app in any backends

00:09:36.167 --> 00:09:37.834
that you have defined.

00:09:37.834 --> 00:09:40.300
The code is also shared,

00:09:40.300 --> 00:09:44.400
and you update each one
individually.

00:09:44.400 --> 00:09:46.467
So here's what a more
fleshed-out backends.yaml file

00:09:46.467 --> 00:09:47.834
will look like,

00:09:47.834 --> 00:09:50.467
and I'll go into some of
these settings in just a second.

00:09:50.467 --> 00:09:52.234
But here's a crawler.

00:09:52.234 --> 00:09:53.501
We defined a start script

00:09:53.501 --> 00:09:56.501
where the crawler runs main.py,
when it starts up.

00:09:56.501 --> 00:09:57.934
Here's a search backend.

00:09:57.934 --> 00:10:02.334
It's configured as a B8,
which has high memory in CPU,

00:10:02.334 --> 00:10:05.868
five instances of this
and a worker.

00:10:05.868 --> 00:10:07.801
Here, we've made
this worker dynamic,

00:10:07.801 --> 00:10:10.300
so that it doesn't
always stay at memory.

00:10:10.300 --> 00:10:12.400
It only comes up
in response to traffic

00:10:12.400 --> 00:10:15.334
or a command that the worker
has to execute.

00:10:15.334 --> 00:10:18.767
So you can see how we've added
a number of different

00:10:18.767 --> 00:10:21.767
server processes,
each of which can be configured

00:10:21.767 --> 00:10:24.234
with multiple instances
to your applications.

00:10:24.234 --> 00:10:26.133
So now we essentially have
almost four different things

00:10:26.133 --> 00:10:29.200
going on in this application:
the normal application version,

00:10:29.200 --> 00:10:32.000
and each of these
three backends.

00:10:32.000 --> 00:10:35.567
So things you can add
in backends.yaml,

00:10:35.567 --> 00:10:38.734
the name is using commands
to identify the backend.

00:10:38.734 --> 00:10:40.300
It's using URLs.

00:10:40.300 --> 00:10:43.534
You can target a backend
using the--

00:10:43.534 --> 00:10:47.634
with a task or with a cron job
by adding the target parameter

00:10:47.634 --> 00:10:49.901
in syntax or the names
used there.

00:10:49.901 --> 00:10:51.133
The name is global,

00:10:51.133 --> 00:10:53.801
and it's shared
across the version space,

00:10:53.801 --> 00:10:56.167
namespace
for your application,

00:10:56.167 --> 00:10:59.234
and backends currently
are not versioned,

00:10:59.234 --> 00:11:01.467
and it's using
in the backends API.

00:11:01.467 --> 00:11:03.367
So instances--control
the number of instances

00:11:03.367 --> 00:11:06.667
for your backend.

00:11:06.667 --> 00:11:10.634
There are two ways that
the instances account works.

00:11:10.634 --> 00:11:12.801
If you have a resident backend,
which is the default,

00:11:12.801 --> 00:11:14.868
you always will have
exactly that many instances,

00:11:14.868 --> 00:11:16.300
and when you
start the backend,

00:11:16.300 --> 00:11:18.300
all of them come up
at the same time.

00:11:18.300 --> 00:11:21.734
With a dynamic backend,
as I mentioned before,

00:11:21.734 --> 00:11:23.801
the instances do not
come up immediately.

00:11:23.801 --> 00:11:26.467
They wait until traffic arrives
and are brought up

00:11:26.467 --> 00:11:28.067
and taken down,
as you're used to,

00:11:28.067 --> 00:11:31.033
with a normal application
version on App Engine.

00:11:31.033 --> 00:11:33.634
And in the instances
used in URL, like so,

00:11:33.634 --> 00:11:35.000
like I showed before,

00:11:35.000 --> 00:11:40.501
you can only have 20 instances
currently per backend.

00:11:40.501 --> 00:11:42.534
The class specifies
the performance

00:11:42.534 --> 00:11:44.801
and price characteristics
of the backend,

00:11:44.801 --> 00:11:47.934
so we're going out today
with four classes:

00:11:47.934 --> 00:11:50.067
B1, B2, B4, and B8,

00:11:50.067 --> 00:11:54.434
and you can see the limits,
the memory and CPU limits,

00:11:54.434 --> 00:11:55.801
and the prices.

00:11:55.801 --> 00:11:57.000
And so
the price includes

00:11:57.000 --> 00:11:59.701
the memory in the CPU
used by the instance,

00:11:59.701 --> 00:12:01.267
and they're priced
by the hour,

00:12:01.267 --> 00:12:02.834
or by the minute,
actually,

00:12:02.834 --> 00:12:06.868
so we're tracking exactly the
uptime of each backend instance,

00:12:06.868 --> 00:12:09.767
and you're billed according
to this hourly rate,

00:12:09.767 --> 00:12:13.667
just according to how much
your backends are up.

00:12:13.667 --> 00:12:15.234
There's an additional
15-minute charge

00:12:15.234 --> 00:12:18.067
associated with starting up
a backend instance.

00:12:18.067 --> 00:12:21.934
So once one is up,
you should try to keep it up.

00:12:21.934 --> 00:12:23.200
We don't want
people creating

00:12:23.200 --> 00:12:27.901
and bringing down backend
instances very rapidly.

00:12:27.901 --> 00:12:29.534
And you can adjust the class,
over time,

00:12:29.534 --> 00:12:33.133
if you want more memory
or CPU.

00:12:33.133 --> 00:12:35.934
The start directive
configures a script

00:12:35.934 --> 00:12:37.534
to handle
the /_ah/start request,

00:12:37.534 --> 00:12:39.701
which is a special request
that App Engine will send

00:12:39.701 --> 00:12:42.200
each backend instance
to start it up,

00:12:42.200 --> 00:12:45.000
and the start directive
allows you to configure

00:12:45.000 --> 00:12:47.834
a separate handler for this,
for each backend.

00:12:47.834 --> 00:12:49.567
This is only in Python
right now.

00:12:49.567 --> 00:12:53.133
We're working on something
similar in Java,

00:12:53.133 --> 00:12:55.334
but there's two uses
for the start request

00:12:55.334 --> 00:12:57.601
to initialize state
for a backends coming up,

00:12:57.601 --> 00:12:59.834
that's going to then
process user requests

00:12:59.834 --> 00:13:01.501
or to just take
that start request

00:13:01.501 --> 00:13:04.167
and just continue to run,
like, if you're a web crawler,

00:13:04.167 --> 00:13:07.367
or if you're doing a load test
or something like that.

00:13:07.367 --> 00:13:10.400
And during the startup period,
other requests will wait

00:13:10.400 --> 00:13:13.100
until the start finishes,
at which point

00:13:13.100 --> 00:13:15.767
App Engine considers the backend
to have become initialized

00:13:15.767 --> 00:13:17.400
and ready to serve traffic,

00:13:17.400 --> 00:13:20.734
and success is basically
a 200-response code.

00:13:20.734 --> 00:13:23.334
We also consider
a 404 a success.

00:13:23.334 --> 00:13:26.133
A failed start causes
the instance to be restarted.

00:13:26.133 --> 00:13:28.367
So if you're working
with backends,

00:13:28.367 --> 00:13:29.667
and you're having trouble
seeing them come up,

00:13:29.667 --> 00:13:31.100
go check the logs.

00:13:31.100 --> 00:13:34.934
It's usually because that
the start request is filled.

00:13:34.934 --> 00:13:37.501
So options, these are
a set of boolean flags

00:13:37.501 --> 00:13:39.467
that configure
how backend works.

00:13:39.467 --> 00:13:42.901
So public allows it to accept
external HTTP requests.

00:13:42.901 --> 00:13:44.434
By default,
they're private,

00:13:44.434 --> 00:13:46.701
and that means
that they accept requests

00:13:46.701 --> 00:13:48.501
from either an admin
of the application

00:13:48.501 --> 00:13:51.067
or from another instance
of the application

00:13:51.067 --> 00:13:53.400
or the task queue
or cron,

00:13:53.400 --> 00:13:56.834
something internal
to App Engine.

00:13:56.834 --> 00:14:01.200
Dynamic, so this switches the
mode from resident to dynamic,

00:14:01.200 --> 00:14:03.000
which causes the backends
to only come up

00:14:03.000 --> 00:14:05.167
if they are
receiving traffic,

00:14:05.167 --> 00:14:07.534
and there is
some scalability here,

00:14:07.534 --> 00:14:10.634
up to the 20-instance limit
that I mentioned before.

00:14:10.634 --> 00:14:14.033
So App Engine will only create
instances up to that 20,

00:14:14.033 --> 00:14:15.734
according to traffic,

00:14:15.734 --> 00:14:17.501
and they're shut down
when they're idle.

00:14:17.501 --> 00:14:20.467
So dynamic is really a way
to give App Engine

00:14:20.467 --> 00:14:22.534
more automatic control
of your backend instances,

00:14:22.534 --> 00:14:23.934
which can save you money,

00:14:23.934 --> 00:14:26.467
because they'll be turned down
kind of immediately,

00:14:26.467 --> 00:14:31.534
relatively immediately
after they become idle.

00:14:31.534 --> 00:14:34.834
Fail-fast is another option,
which disables the pending queue

00:14:34.834 --> 00:14:37.634
for your backend instance,
which is useful

00:14:37.634 --> 00:14:40.767
for working with clients
that are more sophisticated,

00:14:40.767 --> 00:14:43.267
that want a very quick response
to just know whether

00:14:43.267 --> 00:14:46.033
a request can be handled,
or should it be retried

00:14:46.033 --> 00:14:48.767
or potentially tried later.

00:14:48.767 --> 00:14:50.968
Okay, let's see a demo.

00:14:50.968 --> 00:14:55.501
Greg is here, and will be
showing you some backends.

00:14:55.501 --> 00:14:59.200
Darke: Okay, so I think
I will first start off

00:14:59.200 --> 00:15:02.367
with a generic
counting service.

00:15:02.367 --> 00:15:05.033
And so currently
people use memcache

00:15:05.033 --> 00:15:07.567
to get this particular feature,
but the problem

00:15:07.567 --> 00:15:10.334
with Memcache is that you don't
know how long the data

00:15:10.334 --> 00:15:13.934
is actually going to last for,
as it's quite transient.

00:15:13.934 --> 00:15:16.801
So with backends,
you get full control of this,

00:15:16.801 --> 00:15:19.434
and you're able to have
your own hashing algorithm,

00:15:19.434 --> 00:15:21.400
so you can shard it across
any backend you want.

00:15:21.400 --> 00:15:23.200
You can control how long
the data is there for

00:15:23.200 --> 00:15:24.868
and how much
you want to store.

00:15:24.868 --> 00:15:26.300
And in this particular example,

00:15:26.300 --> 00:15:28.133
this is actually
going to use Datastore

00:15:28.133 --> 00:15:30.267
to do this
persistently.

00:15:30.267 --> 00:15:32.567
So if you want to click
on the link down the bottom,

00:15:32.567 --> 00:15:34.501
it'll show you an example
of this page.

00:15:34.501 --> 00:15:37.033
And as you can see, it says,
"Welcome, visitor 2,"

00:15:37.033 --> 00:15:38.467
because this is
the second person

00:15:38.467 --> 00:15:40.701
who's visited the page.

00:15:40.701 --> 00:15:43.767
So what I'll do is I'll
quickly go over the frontend

00:15:43.767 --> 00:15:45.334
that I just demoed to you.

00:15:45.334 --> 00:15:48.801
As you can see,
we use the new backends API

00:15:48.801 --> 00:15:52.067
to use the get URL call
to get the URL

00:15:52.067 --> 00:15:54.567
for the counter's backend.

00:15:54.567 --> 00:15:58.200
We then use that URL and
the form and coding mechanism

00:15:58.200 --> 00:16:00.300
to send the payload
with the name of the visitor,

00:16:00.300 --> 00:16:03.667
delta=1, and we send
that to the backend,

00:16:03.667 --> 00:16:05.200
and then the content that we
get back from that backend,

00:16:05.200 --> 00:16:07.601
we just display
straight to the user.

00:16:07.601 --> 00:16:11.200
So while I'm doing this,
I'll just start off a load test,

00:16:11.200 --> 00:16:13.868
and I'm currently doing that
with a backend.

00:16:13.868 --> 00:16:17.767
This is a resident backend.
It has ten instances.

00:16:17.767 --> 00:16:20.400
I want to just
start that now,

00:16:20.400 --> 00:16:22.133
and I'll actually
go over that code.

00:16:22.133 --> 00:16:25.834
So this particular example,
we use the same method,

00:16:25.834 --> 00:16:28.701
the get URL, to get where we're
going to send the request to,

00:16:28.701 --> 00:16:31.701
and we have
ten different counters.

00:16:31.701 --> 00:16:33.434
And as you see,
this is something

00:16:33.434 --> 00:16:34.968
that you don't normally see
in App Engine.

00:16:34.968 --> 00:16:37.234
You have a while true loop,
and that's it.

00:16:37.234 --> 00:16:39.100
So we pick a random
counter.

00:16:39.100 --> 00:16:41.734
We send that request
through with urlfetch,

00:16:41.734 --> 00:16:43.634
and then we just
ignore the result

00:16:43.634 --> 00:16:47.033
and go back through
on the loop.

00:16:47.033 --> 00:16:49.501
So now on to the actual
other backend,

00:16:49.501 --> 00:16:51.601
the counter backend.

00:16:51.601 --> 00:16:54.367
So we have a fairly
simple model here.

00:16:54.367 --> 00:16:55.968
There's only a single
value stored,

00:16:55.968 --> 00:16:59.367
and that is value,
and that's written to Datastore.

00:16:59.367 --> 00:17:01.267
We also have
this dirty flag,

00:17:01.267 --> 00:17:02.801
and I'll get into that
a bit more later,

00:17:02.801 --> 00:17:05.934
but that's not written
to Datastore.

00:17:05.934 --> 00:17:08.834
So with the counting store,
it's quite simple.

00:17:08.834 --> 00:17:10.834
We get the name in
from the request,

00:17:10.834 --> 00:17:15.801
and we check if the model
exists in our cache,

00:17:15.801 --> 00:17:18.667
and if not,
we load it from Datastore.

00:17:18.667 --> 00:17:19.734
Once we've loaded it,

00:17:19.734 --> 00:17:21.567
we then return it
back to the user,

00:17:21.567 --> 00:17:23.968
if they did
a get request.

00:17:23.968 --> 00:17:26.067
If it was an increase request,

00:17:26.067 --> 00:17:27.934
what we do is we increase it
by the amount,

00:17:27.934 --> 00:17:30.367
and we set the dirty flag
to be true.

00:17:30.367 --> 00:17:32.667
You'll notice
the shutdown flag here.

00:17:32.667 --> 00:17:34.734
What this is there for

00:17:34.734 --> 00:17:40.234
is that your application may get
a shutdown request at any time,

00:17:40.234 --> 00:17:43.767
and so we set
the shutdown flag

00:17:43.767 --> 00:17:45.467
just after we've written
everything to disk.

00:17:45.467 --> 00:17:48.167
I'll get to that
in a second.

00:17:48.167 --> 00:17:50.801
This is the shutdown that I was
actually talking about.

00:17:50.801 --> 00:17:56.434
So what we do is in the event
of this backend being shut down,

00:17:56.434 --> 00:17:57.601
we write everything
to disk.

00:17:57.601 --> 00:18:00.234
We set the shutdown flag
to true,

00:18:00.234 --> 00:18:02.601
and then that will ensure
that everything is persisted

00:18:02.601 --> 00:18:04.234
to disk correctly.

00:18:04.234 --> 00:18:06.133
The way how we actually
set this shutdown hook

00:18:06.133 --> 00:18:08.434
is in the start-off handler,
which is the first request

00:18:08.434 --> 00:18:10.901
that goes to this instance.

00:18:10.901 --> 00:18:15.067
We use the set shutdown hook
command.

00:18:15.067 --> 00:18:17.033
So I'll go back to
the example load test

00:18:17.033 --> 00:18:18.934
that I started out before.

00:18:18.934 --> 00:18:21.067
You have a look
at the instances console.

00:18:21.067 --> 00:18:22.868
You'll see that this particular
instance has been doing

00:18:22.868 --> 00:18:25.901
about 120 requests per second.

00:18:25.901 --> 00:18:27.567
It's quite good.

00:18:27.567 --> 00:18:29.434
So we'll stop the load test,

00:18:29.434 --> 00:18:31.767
and we'll have a look
at Datastore.

00:18:31.767 --> 00:18:33.300
So if I do a query
on Datastore,

00:18:33.300 --> 00:18:34.701
you'll see that it's empty,

00:18:34.701 --> 00:18:37.567
so that there's actually
nothing in Datastore.

00:18:37.567 --> 00:18:39.567
But if I go back
to the instances console

00:18:39.567 --> 00:18:42.000
and press the shutdown button,

00:18:42.000 --> 00:18:44.234
you'll see that a shutdown
request has been sent.

00:18:44.234 --> 00:18:47.200
If we go back to the Datastore
viewer and run this query,

00:18:47.200 --> 00:18:49.901
you'll see that all the counters
have actually been updated.

00:18:49.901 --> 00:18:52.968
This is just a simple example
of doing a counter.

00:18:52.968 --> 00:18:55.133
This particular example could
easily be moved to memcache,

00:18:55.133 --> 00:18:56.534
but there are many more
advanced things

00:18:56.534 --> 00:18:58.767
that you can actually do,
and the code for this example

00:18:58.767 --> 00:19:01.834
is up on
backends-io.appspot.com.

00:19:01.834 --> 00:19:03.934
and I'll pass it
back to Justin

00:19:03.934 --> 00:19:07.067
for more information
about backends.

00:19:07.067 --> 00:19:10.133
Haugh: All right,
thanks, Greg.

00:19:10.133 --> 00:19:13.000
So let's talk about
using backends

00:19:13.000 --> 00:19:15.334
and some best practices.

00:19:15.334 --> 00:19:19.200
So we'll cover using resident
backends versus dynamic.

00:19:19.200 --> 00:19:22.534
We'll cover scaling,
startup and shutdown,

00:19:22.534 --> 00:19:27.234
how logging works with backends
during long-running requests,

00:19:27.234 --> 00:19:29.234
a little bit more
about fail-fast,

00:19:29.234 --> 00:19:32.067
some ideas about message passing
between frontends and backends

00:19:32.067 --> 00:19:34.868
and instances,
how task queues work,

00:19:34.868 --> 00:19:39.634
and handlers, so--
a lot to get through.

00:19:39.634 --> 00:19:41.400
Okay, resident backends.

00:19:41.400 --> 00:19:43.367
So a resident backend,
as I mentioned before,

00:19:43.367 --> 00:19:45.734
they are always on,
so they are always up,

00:19:45.734 --> 00:19:48.234
once you start the backend.

00:19:48.234 --> 00:19:49.634
Automatically
will be restarted,

00:19:49.634 --> 00:19:51.667
if anything happens
to cause a shutdown,

00:19:51.667 --> 00:19:54.300
so if you go to that instances
console that Greg showed,

00:19:54.300 --> 00:19:57.334
and hit shutdown,
they'll come right back up.

00:19:57.334 --> 00:20:00.434
If there's an App Engine
maintenance,

00:20:00.434 --> 00:20:03.033
and we're potentially moving
from one data center to another,

00:20:03.033 --> 00:20:05.968
they'll be immediately brought
up in the new data center.

00:20:05.968 --> 00:20:08.868
If there's any other issues
that may occur,

00:20:08.868 --> 00:20:10.534
they come right back.

00:20:10.534 --> 00:20:13.601
Resident instances also
just can run forever,

00:20:13.601 --> 00:20:16.100
so you can take the start
request and just run,

00:20:16.100 --> 00:20:20.200
and because they're restarted,
you can reliably know

00:20:20.200 --> 00:20:21.934
that this backend
will be taking start

00:20:21.934 --> 00:20:23.200
and just kind of
running continuously.

00:20:23.200 --> 00:20:25.234
So these are really great for,
like, background,

00:20:25.234 --> 00:20:29.033
continuous background
processing applications,

00:20:29.033 --> 00:20:31.200
explicit start and stop,
like I mentioned before,

00:20:31.200 --> 00:20:34.167
so they're going to stay up
and resident in memory

00:20:34.167 --> 00:20:37.100
until you stop them
yourself.

00:20:37.100 --> 00:20:40.300
So uses for this, again,
continuous execution.

00:20:40.300 --> 00:20:42.000
Pull queues
is a great example,

00:20:42.000 --> 00:20:43.868
where you have a backend
that comes up,

00:20:43.868 --> 00:20:47.567
and it chooses to pull requests
from a pull queue

00:20:47.567 --> 00:20:51.300
and passes a process task
in batch

00:20:51.300 --> 00:20:54.200
that can be a lot more efficient
that using push queues.

00:20:54.200 --> 00:20:56.834
These are great for large
addressable amounts of memory.

00:20:56.834 --> 00:20:59.467
So let's say you have,
I don't know,

00:20:59.467 --> 00:21:00.934
let's say you have a lot of data
in the Datastore.

00:21:00.934 --> 00:21:02.234
You want to load it all up
in the memory

00:21:02.234 --> 00:21:04.234
and then access it
at memory speed,

00:21:04.234 --> 00:21:07.501
so like, sub millisecond
or on the order of, you know,

00:21:07.501 --> 00:21:10.767
just very, very quickly perform
any sort of computation

00:21:10.767 --> 00:21:12.734
you want over that data.

00:21:12.734 --> 00:21:14.434
You can have
that in a backend,

00:21:14.434 --> 00:21:16.033
and you can split it up
across backends,

00:21:16.033 --> 00:21:19.067
so that you can address, like,
say, you could shard users

00:21:19.067 --> 00:21:21.701
so that users are split
across the backends,

00:21:21.701 --> 00:21:23.601
and you can know,
hash the user name

00:21:23.601 --> 00:21:27.667
and go contact the backend
that has that user's data,

00:21:27.667 --> 00:21:29.367
and it could be flushed
at shutdown time

00:21:29.367 --> 00:21:33.667
or periodically,
like Greg showed,

00:21:33.667 --> 00:21:37.400
or you can write your own
custom Memcache using backends.

00:21:37.400 --> 00:21:39.400
So the pattern here
is that at start time,

00:21:39.400 --> 00:21:41.667
load up some state,
and then handle request,

00:21:41.667 --> 00:21:46.400
or just do start
and run continuously.

00:21:46.400 --> 00:21:49.267
So dynamic backends
are similar

00:21:49.267 --> 00:21:51.534
to existing instances
on App Engine,

00:21:51.534 --> 00:21:54.534
except that you configure
the amount of memory in CPU

00:21:54.534 --> 00:21:55.667
they have access to,

00:21:55.667 --> 00:21:57.267
and there's a limit
of 20 of them.

00:21:57.267 --> 00:22:01.133
So these only come up
when they're sent a request.

00:22:01.133 --> 00:22:04.434
At that point, App Engine will
kind of hold the user's request

00:22:04.434 --> 00:22:07.334
and issue the start
to bring up the backend;

00:22:07.334 --> 00:22:09.801
and once the backend is up,
it will handle the user request.

00:22:09.801 --> 00:22:11.467
So with these,

00:22:11.467 --> 00:22:13.367
you really want to minimize
the amount of time,

00:22:13.367 --> 00:22:15.868
amount of state you're
initializing at startup

00:22:15.868 --> 00:22:18.734
or perform some kind of
routing on your own

00:22:18.734 --> 00:22:21.467
or some sort of, like,
warm-up requests on your own

00:22:21.467 --> 00:22:24.968
to get the dynamic instances up
before you flip traffic over,

00:22:24.968 --> 00:22:28.601
if you want to do
a lot of state initialization.

00:22:28.601 --> 00:22:30.467
So here, you pay
for what you use.

00:22:30.467 --> 00:22:33.801
You do this with resident,
as well,

00:22:33.801 --> 00:22:36.067
but with dynamic backends,
they'll be turned down,

00:22:36.067 --> 00:22:39.000
if there's not traffic
for a few minutes,

00:22:39.000 --> 00:22:41.000
and there's no management
of start and stop,

00:22:41.000 --> 00:22:43.267
so you can configure
a backend to be dynamic

00:22:43.267 --> 00:22:46.901
and really not have to worry
about doing too much management

00:22:46.901 --> 00:22:48.934
with that backend.

00:22:48.934 --> 00:22:51.000
The counter server
that Greg mentioned

00:22:51.000 --> 00:22:55.300
would function as
a dynamic backend as well,

00:22:55.300 --> 00:22:57.334
because it was integrated
with your application.

00:22:57.334 --> 00:22:59.300
If it was getting traffic,
it would be in memory.

00:22:59.300 --> 00:23:00.567
It would be working.

00:23:00.567 --> 00:23:02.400
As traffic fell off,
it would be shut down.

00:23:02.400 --> 00:23:06.767
It'd flush its state, and
you wouldn't be paying for it.

00:23:06.767 --> 00:23:09.467
So the pattern here,
load up a little bit of state,

00:23:09.467 --> 00:23:11.834
handle requests,
and then write out state,

00:23:11.834 --> 00:23:17.834
either intermediately
or during shutdown.

00:23:17.834 --> 00:23:20.133
So, scaling.

00:23:20.133 --> 00:23:22.968
I just gave a talk
on scaling.

00:23:22.968 --> 00:23:26.701
backends don't scale the same
way that normal applications.

00:23:26.701 --> 00:23:28.901
This is due on App Engine.

00:23:28.901 --> 00:23:32.534
They're designed to work
either online or offline,

00:23:32.534 --> 00:23:35.434
but they really, really shine
when it comes to offline work,

00:23:35.434 --> 00:23:37.400
because you're controlling
the number of instances.

00:23:37.400 --> 00:23:39.434
You're controlling
the amount of throughput

00:23:39.434 --> 00:23:42.167
that your offline processing
is handling.

00:23:42.167 --> 00:23:45.400
If you hit limits,
if you're maxing out the memory

00:23:45.400 --> 00:23:47.434
and CPU of your backends,
you're just going to have a--

00:23:47.434 --> 00:23:49.701
your processing is going to
slow down a little bit,

00:23:49.701 --> 00:23:52.033
but nothing that bad happens.
And if you want to resize,

00:23:52.033 --> 00:23:55.033
you can pause
the offline execution,

00:23:55.033 --> 00:23:56.367
resize it
and bring it right back up.

00:23:56.367 --> 00:23:57.734
No big deal.

00:23:57.734 --> 00:24:00.734
When you integrate a backend
into an online web flow,

00:24:00.734 --> 00:24:02.467
you're usually not in control
of the traffic

00:24:02.467 --> 00:24:08.100
that's coming at that backend,
unless you are rerouting traffic

00:24:08.100 --> 00:24:09.567
between different versions
of your application

00:24:09.567 --> 00:24:12.234
or different backends.

00:24:12.234 --> 00:24:14.801
If you hit limits
in a web flow,

00:24:14.801 --> 00:24:17.100
if you scale up to
all 20 backends,

00:24:17.100 --> 00:24:19.601
and they're running out of,
kind of, CPU,

00:24:19.601 --> 00:24:20.968
they're maxing out their CPU,

00:24:20.968 --> 00:24:24.200
it could be a problem
for your application.

00:24:24.200 --> 00:24:27.100
So we urge caution when
you're introducing backends

00:24:27.100 --> 00:24:28.467
into an online flow.

00:24:28.467 --> 00:24:30.801
We'd like for you
to carefully consider

00:24:30.801 --> 00:24:35.334
and monitor the resource usage
and probably overprovision,

00:24:35.334 --> 00:24:38.601
or if you're using
dynamic backends,

00:24:38.601 --> 00:24:40.901
just, again, be careful
about the resource usage,

00:24:40.901 --> 00:24:43.767
because there is
that 20-instance limit.

00:24:43.767 --> 00:24:45.133
App Engine will scale you up
to that 20,

00:24:45.133 --> 00:24:48.901
but there is that fixed limit
currently.

00:24:48.901 --> 00:24:50.534
So look at the instances
console.

00:24:50.534 --> 00:24:53.100
We're also providing
a new runtime API,

00:24:53.100 --> 00:24:56.334
which exposes the CPU and
memory usage of each instance.

00:24:56.334 --> 00:24:58.868
And using this,
you can dynamically see

00:24:58.868 --> 00:25:03.234
how your instances
are performing.

00:25:03.234 --> 00:25:06.067
The strategies
for dealing with situations

00:25:06.067 --> 00:25:08.934
where you're kind of hitting
limits of your backends,

00:25:08.934 --> 00:25:11.033
the default is to just take
a little bit of downtime.

00:25:11.033 --> 00:25:13.434
You do an update,
add some more instances.

00:25:13.434 --> 00:25:15.367
There's a brief window,
when you're doing an update,

00:25:15.367 --> 00:25:19.267
where the old instances
of your backend are taken down,

00:25:19.267 --> 00:25:20.601
and then new ones
are brought up.

00:25:20.601 --> 00:25:21.734
So if you minimize
the shutdown time,

00:25:21.734 --> 00:25:23.501
and you minimize
that start time,

00:25:23.501 --> 00:25:26.634
that can be
a very short window,

00:25:26.634 --> 00:25:29.467
and you won't really see
a whole lot of downtime.

00:25:29.467 --> 00:25:32.801
A better option probably would
be to do some routing yourself,

00:25:32.801 --> 00:25:37.834
where you have two backends,
A and B, or 1 and 2.

00:25:37.834 --> 00:25:40.167
Bring up the second one,
flip the traffic over,

00:25:40.167 --> 00:25:42.334
take down the first one.

00:25:42.334 --> 00:25:44.601
And this is useful for doing
canaries of new code

00:25:44.601 --> 00:25:46.767
or doing a little bit
of staging.

00:25:46.767 --> 00:25:49.000
The best option is probably,
again, to use options dynamic

00:25:49.000 --> 00:25:51.901
where App Engine will scale you
up to those 20 instances.

00:25:51.901 --> 00:25:54.367
You could do custom routing
logic yourself,

00:25:54.367 --> 00:25:57.434
where you have
more instances configured

00:25:57.434 --> 00:25:59.734
than you're actually using,
typically,

00:25:59.734 --> 00:26:04.033
and proxy requests through some
of your own application logic.

00:26:04.033 --> 00:26:06.868
If you don't target a request
at a backend instance,

00:26:06.868 --> 00:26:09.367
it won't actually come up;
so you could choose

00:26:09.367 --> 00:26:12.100
to only load balance
across some fraction

00:26:12.100 --> 00:26:15.601
of the configured instances
like five or ten out of 20

00:26:15.601 --> 00:26:17.667
and kind of
just on the fly,

00:26:17.667 --> 00:26:21.501
using some
configuration command,

00:26:21.501 --> 00:26:27.133
or an admin request
to change that.

00:26:27.133 --> 00:26:30.467
Okay, so
let's move on to startup.

00:26:30.467 --> 00:26:32.634
I mentioned before
that this AH start request

00:26:32.634 --> 00:26:34.467
is a special request
that App Engine will send

00:26:34.467 --> 00:26:37.000
to bring up
your backend instances.

00:26:37.000 --> 00:26:39.400
This is sent
for resident backends

00:26:39.400 --> 00:26:40.734
as soon as you
hit the start,

00:26:40.734 --> 00:26:44.300
as soon as you
start the backend.

00:26:44.300 --> 00:26:46.701
With a dynamic backend,
again,

00:26:46.701 --> 00:26:49.300
it only arrives
when a user request arrives,

00:26:49.300 --> 00:26:52.767
and it allows you
to then run indefinitely.

00:26:52.767 --> 00:26:55.868
And I think I've pretty much
covered this, then.

00:26:55.868 --> 00:26:59.100
So shutdown,
there's two types of shutdown,

00:26:59.100 --> 00:27:01.734
polite and a hard shutdown.

00:27:01.734 --> 00:27:05.834
So with polite shutdown,
we give your backend instance

00:27:05.834 --> 00:27:09.067
30 seconds of notice
before it's terminated.

00:27:09.067 --> 00:27:12.801
This allows you to do
some checkpointing of state.

00:27:12.801 --> 00:27:18.133
And so some examples of when
polite shutdown occurs

00:27:18.133 --> 00:27:20.434
are when machines
undergo maintenance,

00:27:20.434 --> 00:27:22.267
when App Engine undergoes
maintenance.

00:27:22.267 --> 00:27:23.667
If there's a scheduling change,

00:27:23.667 --> 00:27:26.200
and we have to move your backend
instance to a different machine,

00:27:26.200 --> 00:27:28.801
those are all examples
of polite shutdown.

00:27:28.801 --> 00:27:31.167
So most of the time,
we expect to be able to provide

00:27:31.167 --> 00:27:34.334
polite shutdown notice
for your backend instances.

00:27:34.334 --> 00:27:38.267
Hard shutdown is when we
don't have that opportunity.

00:27:38.267 --> 00:27:40.934
When a machine dies,
this can happen.

00:27:40.934 --> 00:27:44.334
If there's some sort of
hardware failure,

00:27:44.334 --> 00:27:46.300
if you've exceeded
your memory limits,

00:27:46.300 --> 00:27:49.734
if there's some problems with
the network to a data center,

00:27:49.734 --> 00:27:53.167
that can be a case
where we have a hard shutdown.

00:27:53.167 --> 00:27:57.033
So when this occurs,
there's not a lot of time.

00:27:57.033 --> 00:27:59.100
Really, there's no time
to write out any state.

00:27:59.100 --> 00:28:04.300
So a best practice then
is to don't-- use the backend

00:28:04.300 --> 00:28:07.367
as a cache of data
that's persistent

00:28:07.367 --> 00:28:11.067
or be okay with
a little bit of loss.

00:28:11.067 --> 00:28:15.167
And you really need to figure
out how to handle shutdowns.

00:28:15.167 --> 00:28:20.667
So the runtime API

00:28:20.667 --> 00:28:22.334
is what we've provided.

00:28:22.334 --> 00:28:26.067
There's two methods
of handling shutdown.

00:28:26.067 --> 00:28:30.234
The first method is to pull
the is shutting down method.

00:28:30.234 --> 00:28:34.200
This will flip to True,
when you are being shut down,

00:28:34.200 --> 00:28:35.567
and you'll have
30 seconds of notice

00:28:35.567 --> 00:28:37.434
to do whatever you'd like.

00:28:37.434 --> 00:28:41.167
So in this example,
we have backend that's looping.

00:28:41.167 --> 00:28:44.801
It's doing work
for ten seconds each time.

00:28:44.801 --> 00:28:47.200
Then it will check
the shutting down,

00:28:47.200 --> 00:28:53.200
and if so, it'll checkpoint
and break out of the loop.

00:28:53.200 --> 00:28:54.934
The other way
is the shutdown callback,

00:28:54.934 --> 00:28:56.434
that Greg mentioned.

00:28:56.434 --> 00:28:59.267
So you define the callback,
the checkpoint callback,

00:28:59.267 --> 00:29:01.934
and just shutdown hook
when you start up,

00:29:01.934 --> 00:29:03.100
and you can just
work continuously.

00:29:03.100 --> 00:29:07.601
So this is a little bit
easier.

00:29:07.601 --> 00:29:09.501
Okay, so the way logging
works with backends--

00:29:09.501 --> 00:29:11.400
so these requests
can take a long time.

00:29:11.400 --> 00:29:15.200
Normally, logs are only written
out to the admin console

00:29:15.200 --> 00:29:16.501
at the end of a request.

00:29:16.501 --> 00:29:19.367
But with backends,
we automatically flush logs,

00:29:19.367 --> 00:29:22.434
and there's this
log service API

00:29:22.434 --> 00:29:24.534
that we've introduced
that has constants.

00:29:24.534 --> 00:29:27.834
You continue to decide
how often the auto flush works;

00:29:27.834 --> 00:29:30.067
every so many bytes
of log messages,

00:29:30.067 --> 00:29:32.868
every so many log lines
or seconds,

00:29:32.868 --> 00:29:37.400
and you can manually flush
whenever you'd like.

00:29:37.400 --> 00:29:39.868
Okay, so fail-fast.

00:29:39.868 --> 00:29:42.000
This is for sophisticated
clients

00:29:42.000 --> 00:29:45.901
that want to know immediately
when a request can't be handled,

00:29:45.901 --> 00:29:48.033
and they have some sort of
alternative strategy.

00:29:48.033 --> 00:29:52.534
They have their own ability
to have a queue of requests,

00:29:52.534 --> 00:29:55.133
things that they need done,
external queuing systems,

00:29:55.133 --> 00:29:56.267
an example of this,

00:29:56.267 --> 00:29:57.567
they want to perform
their own retries,

00:29:57.567 --> 00:30:00.667
or they have some sort of
fallback behavior.

00:30:00.667 --> 00:30:02.868
So if you configure
your backend with options,

00:30:02.868 --> 00:30:05.167
fail-fast, all the requests
to that backend

00:30:05.167 --> 00:30:07.400
will get fail-fast
behavior.

00:30:07.400 --> 00:30:08.667
On the client side,
you can set this

00:30:08.667 --> 00:30:12.534
with a new header called
X-AppEngine-FailFast,

00:30:12.534 --> 00:30:14.601
and that causes
that particular request

00:30:14.601 --> 00:30:20.601
to have fail-fast behavior;
so client or server side.

00:30:20.601 --> 00:30:24.100
Okay, message passing.

00:30:24.100 --> 00:30:26.300
With backends,
you can have requests

00:30:26.300 --> 00:30:28.501
that are running
for long periods of time.

00:30:28.501 --> 00:30:32.601
So it's not always possible
to send a backend to request.

00:30:32.601 --> 00:30:36.667
If it's a single-threaded
instance,

00:30:36.667 --> 00:30:38.501
you can't really send it
another request

00:30:38.501 --> 00:30:41.300
until the first one
is finished;

00:30:41.300 --> 00:30:42.367
and if it's running
for a long time,

00:30:42.367 --> 00:30:43.834
that can be a little
problematic.

00:30:43.834 --> 00:30:46.000
So urlfetch, you know,
of course,

00:30:46.000 --> 00:30:48.000
is kind of the typical way
you'd exchange information

00:30:48.000 --> 00:30:49.133
between instances.

00:30:49.133 --> 00:30:51.501
They could just
fetch each other.

00:30:51.501 --> 00:30:54.300
But when you have this
long-running request,

00:30:54.300 --> 00:30:55.300
you probably
want to use something

00:30:55.300 --> 00:30:57.033
like memcache or datastore,

00:30:57.033 --> 00:30:58.467
where you have a reader
and a writer.

00:30:58.467 --> 00:31:00.033
So the writer
is writing entities.

00:31:00.033 --> 00:31:02.667
They're probably annotated
with the backend instance name

00:31:02.667 --> 00:31:05.934
or instance ID,
and the backend is then reading

00:31:05.934 --> 00:31:08.367
and periodically pulling
to see if there's a message

00:31:08.367 --> 00:31:09.868
or if there's something
for it to do.

00:31:09.868 --> 00:31:11.200
You can also use
task queues for this.

00:31:11.200 --> 00:31:12.534
It's really convenient.

00:31:12.534 --> 00:31:13.667
If you want to
send something out,

00:31:13.667 --> 00:31:16.467
send a message to backend,
you just insert.

00:31:16.467 --> 00:31:17.701
You just add the target,

00:31:17.701 --> 00:31:21.434
and that task will be
directed at a backend,

00:31:21.434 --> 00:31:23.100
or if you use pull queues,

00:31:23.100 --> 00:31:24.767
each backend
could have its own queue

00:31:24.767 --> 00:31:28.000
that's just periodically
pulling tasks from.

00:31:28.000 --> 00:31:29.534
And if someone wants
to send it a message,

00:31:29.534 --> 00:31:33.601
you can just put something
in the pull queue.

00:31:33.601 --> 00:31:35.934
And so that brings us
to task queues.

00:31:35.934 --> 00:31:38.834
So I think I've pretty
much covered this.

00:31:38.834 --> 00:31:41.200
There's the target directive
and queues.yaml.

00:31:41.200 --> 00:31:43.133
There's the target parameter
to taskqueue.add.

00:31:43.133 --> 00:31:45.167
That's how you target
a backend.

00:31:45.167 --> 00:31:47.167
And with pull queues,

00:31:47.167 --> 00:31:50.601
you can decide how many tasks
you want to lease.

00:31:50.601 --> 00:31:52.467
You lease them
for a brief period

00:31:52.467 --> 00:31:54.968
and then complete them.

00:31:54.968 --> 00:31:57.000
There's a talk coming up
right after this called,

00:31:57.000 --> 00:31:58.334
"Putting Task Queues to Work,"

00:31:58.334 --> 00:31:59.634
which will go into
a lot more detail

00:31:59.634 --> 00:32:01.400
about how pull queues work

00:32:01.400 --> 00:32:03.934
and the differences between
push and pull queues,

00:32:03.934 --> 00:32:08.834
when you might want to use
the different options.

00:32:08.834 --> 00:32:10.701
So the last best practice
I'll talk about

00:32:10.701 --> 00:32:12.434
is code and handlers.

00:32:12.434 --> 00:32:13.767
So with this release,

00:32:13.767 --> 00:32:15.834
all the handlers
for your application in Python

00:32:15.834 --> 00:32:17.534
are specified in app.yaml.

00:32:17.534 --> 00:32:21.601
For Java, they're expressed
in webxml, the servlets.

00:32:21.601 --> 00:32:24.033
We don't currently have
a mechanism for you

00:32:24.033 --> 00:32:27.033
to specify a different set
of handlers for backends,

00:32:27.033 --> 00:32:30.167
so if you have a set of URLs

00:32:30.167 --> 00:32:34.200
that you only want to express
or expose in a backend,

00:32:34.200 --> 00:32:37.067
we advise you to mark them
with login admin.

00:32:37.067 --> 00:32:41.901
If other instances of your
application access those URLs,

00:32:41.901 --> 00:32:43.901
they'll be able to do this
seamlessly

00:32:43.901 --> 00:32:45.901
without any additional
configuration,

00:32:45.901 --> 00:32:50.300
but they'll be protected from
open requests on the web.

00:32:50.300 --> 00:32:53.467
Another strategy would be
to have two directories:

00:32:53.467 --> 00:32:55.601
an app directory
and then a directory

00:32:55.601 --> 00:32:57.434
where you have
your backends.

00:32:57.434 --> 00:33:02.701
The app.yaml in the main
app pretty much stays the same,

00:33:02.701 --> 00:33:04.834
but then in the backends
directory,

00:33:04.834 --> 00:33:08.300
the app.yaml will have the
handlers for just the backends,

00:33:08.300 --> 00:33:10.067
and you don't have to go
through this work

00:33:10.067 --> 00:33:11.734
of adding login admin,

00:33:11.734 --> 00:33:13.300
because you don't have to
worry about those handlers

00:33:13.300 --> 00:33:16.634
being exposed
in the main application.

00:33:16.634 --> 00:33:19.601
Or you could have
a directory for each backend,

00:33:19.601 --> 00:33:24.434
and you kind of
get the idea there.

00:33:24.434 --> 00:33:26.067
If you're downloading
some third party backend

00:33:26.067 --> 00:33:27.267
that somebody else has written,

00:33:27.267 --> 00:33:28.834
you want to integrate it
into your application.

00:33:28.834 --> 00:33:30.300
You can just have
a directory for that.

00:33:30.300 --> 00:33:33.601
In that app.yaml,
just don't have the version,

00:33:33.601 --> 00:33:35.634
don't have a version
of your application.

00:33:35.634 --> 00:33:37.801
The handlers there will be
the handlers for the backend,

00:33:37.801 --> 00:33:39.033
and when you do an update,

00:33:39.033 --> 00:33:40.567
it will only update
that backend.

00:33:40.567 --> 00:33:43.701
And if a backend is missing
in a backends.yaml,

00:33:43.701 --> 00:33:44.701
it's not deleted.

00:33:44.701 --> 00:33:47.000
It's sort of additive.

00:33:47.000 --> 00:33:48.334
When you do an update,

00:33:48.334 --> 00:33:52.834
it will only update the backends
listed in backends.yaml.

00:33:52.834 --> 00:33:55.467
Okay, so we've heard a lot
about backends,

00:33:55.467 --> 00:33:58.634
a lot of great things,
but some caveats.

00:33:58.634 --> 00:34:00.601
Okay, so currently,
you can only configure

00:34:00.601 --> 00:34:02.701
five backends
for your application.

00:34:02.701 --> 00:34:04.601
You can have
up to ten gigabytes total

00:34:04.601 --> 00:34:06.267
across all the different
backends,

00:34:06.267 --> 00:34:09.534
adding up all the instances
of each backend.

00:34:09.534 --> 00:34:13.734
A backend can have 20 instances,
and here's some combinations

00:34:13.734 --> 00:34:16.367
of how you can arrive
at ten gigabytes.

00:34:16.367 --> 00:34:20.300
You can either have ten B8's,
each of which is a gig,

00:34:20.300 --> 00:34:22.601
20 B4's, which are
half a gig each,

00:34:22.601 --> 00:34:26.400
and you can get the idea.

00:34:26.400 --> 00:34:28.801
So all the normal API deadlines
still apply.

00:34:28.801 --> 00:34:31.467
So urlfetch deadlines
still apply.

00:34:31.467 --> 00:34:36.300
The datastore has a 30-second
deadline for requests.

00:34:36.300 --> 00:34:40.767
Size limits apply,
so HTTP requests to a backend,

00:34:40.767 --> 00:34:43.434
you can have
32 megabyte requests.

00:34:43.434 --> 00:34:48.133
The total size of all requests
to your backends,

00:34:48.133 --> 00:34:50.467
your backend instance
is also limited.

00:34:50.467 --> 00:34:52.834
So if you're using
very large requests,

00:34:52.834 --> 00:34:55.834
you need to sort of serialize
them a little bit.

00:34:55.834 --> 00:34:58.601
Urlfetch, memcache,
blobstore, mail, tasks.

00:34:58.601 --> 00:35:00.901
So all of these normal limits
are still in place.

00:35:00.901 --> 00:35:03.334
What we've done is just swapped
out the instance

00:35:03.334 --> 00:35:07.234
that's performing
these API calls.

00:35:07.234 --> 00:35:09.300
Also there's not
an uptime guarantee

00:35:09.300 --> 00:35:11.100
for backends right now.

00:35:11.100 --> 00:35:12.868
This is a best effort service.

00:35:12.868 --> 00:35:14.133
You should expect shutdown.

00:35:14.133 --> 00:35:16.934
You should expect polite
shutdown most of the time.

00:35:16.934 --> 00:35:18.033
You should write
your application

00:35:18.033 --> 00:35:20.701
the way that tolerates
hard shutdown,

00:35:20.701 --> 00:35:22.467
and there's various causes,
like I've mentioned:

00:35:22.467 --> 00:35:25.434
software bugs, hardware
failures, emergencies.

00:35:25.434 --> 00:35:27.801
I would strongly recommend
you guys check out the talk

00:35:27.801 --> 00:35:29.367
called "Life in App
Engine Production,"

00:35:29.367 --> 00:35:30.734
which is tomorrow.

00:35:30.734 --> 00:35:34.067
Michael Handler and Alan Green
are giving this talk.

00:35:34.067 --> 00:35:35.067
It's a great talk.

00:35:35.067 --> 00:35:36.601
Definitely check it out.

00:35:36.601 --> 00:35:39.968
There's a lot of interesting
stuff going on in production.

00:35:39.968 --> 00:35:43.767
So the future.

00:35:43.767 --> 00:35:46.067
There's a lot of things
that we are releasing today

00:35:46.067 --> 00:35:48.167
with backends, but there's
a lot more we can do.

00:35:48.167 --> 00:35:49.701
Better scaling.

00:35:49.701 --> 00:35:54.901
So you've seen how backends
can scale up to 20 instances.

00:35:54.901 --> 00:35:57.501
We're looking into ways
of introducing auto scaling,

00:35:57.501 --> 00:36:02.434
the same auto scaling behavior
we have for frontend versions,

00:36:02.434 --> 00:36:05.667
which is another term
we sometimes use

00:36:05.667 --> 00:36:08.701
when we're referring to
the main app version,

00:36:08.701 --> 00:36:11.100
introducing that for backends,
as well.

00:36:11.100 --> 00:36:12.634
We're considering
a scaling API

00:36:12.634 --> 00:36:13.901
to give you
a little more control,

00:36:13.901 --> 00:36:15.567
where you can dynamically
increase the number

00:36:15.567 --> 00:36:18.067
of instances of your backend
at any time.

00:36:18.067 --> 00:36:20.834
Better updates, so that you
don't have a period of downtime

00:36:20.834 --> 00:36:22.133
when you're performing updates,

00:36:22.133 --> 00:36:25.234
so each instance is kind of
updated in sequence.

00:36:25.234 --> 00:36:26.801
Or you have online updates,

00:36:26.801 --> 00:36:29.200
where if you just want to
change the number of instances,

00:36:29.200 --> 00:36:31.200
you don't have to take down
the existing ones.

00:36:31.200 --> 00:36:34.934
You can just change that number,
and the new ones will come up.

00:36:34.934 --> 00:36:37.200
We're looking to
better concurrency;

00:36:37.200 --> 00:36:40.934
so background threads in Java,
Python concurrency,

00:36:40.934 --> 00:36:43.667
so that a single Python
backend instance

00:36:43.667 --> 00:36:46.868
can essentially handle more
than one request at a time.

00:36:46.868 --> 00:36:49.000
We're looking into ways
of doing that.

00:36:49.000 --> 00:36:50.467
And better configuration,

00:36:50.467 --> 00:36:54.467
which solve some of the problems
around having handlers

00:36:54.467 --> 00:36:59.100
be the same for both backends
and the application version.

00:36:59.100 --> 00:37:04.100
And also versioning for backends
is on our radar.

00:37:04.100 --> 00:37:06.167
Better uptime.

00:37:06.167 --> 00:37:11.467
Backend uptime is pretty good,
but minimizing restarts

00:37:11.467 --> 00:37:13.567
and keeping them up
as long as possible

00:37:13.567 --> 00:37:15.601
is something we're going
to continue to work on,

00:37:15.601 --> 00:37:17.934
and we'll have some statistics,
over time,

00:37:17.934 --> 00:37:20.400
to share with you about that.

00:37:20.400 --> 00:37:23.434
There'll be API integrations,
more of them.

00:37:23.434 --> 00:37:25.701
I'd recommend you guys
check out the MapReduce talk.

00:37:25.701 --> 00:37:28.868
There'll be ways
to configure backends

00:37:28.868 --> 00:37:32.934
to be MapReduce workers,
or to send mail out of backend,

00:37:32.934 --> 00:37:34.434
or have a backend share,

00:37:34.434 --> 00:37:38.400
a channel that a frontend
instance created.

00:37:38.400 --> 00:37:41.834
Also looking at more power,
so new instance classes,

00:37:41.834 --> 00:37:45.934
over time, longer deadlines,
larger API calls.

00:37:45.934 --> 00:37:48.133
These are things that the
serving infrastructure team

00:37:48.133 --> 00:37:50.133
is always thinking about.

00:37:50.133 --> 00:37:55.501
And potentially streamed
responses and sockets.

00:37:55.501 --> 00:38:01.033
So just to recap, I think
you can say that backends

00:38:01.033 --> 00:38:03.367
really sort of redefine
what App Engine is.

00:38:03.367 --> 00:38:06.601
It's not just for
30-second requests.

00:38:06.601 --> 00:38:09.767
It's not just for
lightweight web serving.

00:38:09.767 --> 00:38:12.634
It's really for
heavyweight processing,

00:38:12.634 --> 00:38:16.100
offline processing,
large in memory indexes.

00:38:16.100 --> 00:38:18.901
We're giving you a lot of memory
and CPU to work with.

00:38:18.901 --> 00:38:21.133
backends are a building block
that you guys can use

00:38:21.133 --> 00:38:24.901
to build a lot of
really cool stuff.

00:38:24.901 --> 00:38:28.434
And, lastly, they're both
very easy to configure.

00:38:28.434 --> 00:38:30.934
They have all the production
support, deployment,

00:38:30.934 --> 00:38:35.501
and ease of use that you're
used to with App Engine,

00:38:35.501 --> 00:38:37.467
and they're managed
by our Google production,

00:38:37.467 --> 00:38:40.000
a team of crack
production engineers,

00:38:40.000 --> 00:38:41.767
who are amazing
at solving problems

00:38:41.767 --> 00:38:46.501
that you guys don't even
have to know about.

00:38:46.501 --> 00:38:48.868
And that's it.
So thank you for coming,

00:38:48.868 --> 00:38:50.200
and if you guys
have any questions,

00:38:50.200 --> 00:38:51.934
please come up to the mics,

00:38:51.934 --> 00:38:54.501
and we'll have some time
for questions.

00:38:54.501 --> 00:39:00.501
[applause]

00:39:03.167 --> 00:39:06.100
man: Hi, could you share
some best practices

00:39:06.100 --> 00:39:09.501
for coping with
hard shutdowns?

00:39:09.501 --> 00:39:12.934
Haugh: So the best practice
is to expect hard shutdown,

00:39:12.934 --> 00:39:16.133
and use the memory
of your backend

00:39:16.133 --> 00:39:17.968
as primarily a cache.

00:39:17.968 --> 00:39:19.968
If you are worried about--

00:39:19.968 --> 00:39:23.000
if you're tolerant of small
amounts of data loss,

00:39:23.000 --> 00:39:25.501
or if the state is being
regenerated from the Datastore

00:39:25.501 --> 00:39:27.367
or can be regenerated
from the Datastore,

00:39:27.367 --> 00:39:30.968
that's really the ideal.

00:39:30.968 --> 00:39:32.534
That's what I'd say there.

00:39:32.534 --> 00:39:34.234
Darke: And I'd also suggest
you look at

00:39:34.234 --> 00:39:37.067
the actual example code that is
for that counters demo.

00:39:37.067 --> 00:39:39.968
That example also uses
the task queue

00:39:39.968 --> 00:39:41.901
to flush the state
back out to datastore

00:39:41.901 --> 00:39:43.334
about every two seconds,

00:39:43.334 --> 00:39:46.801
and you can make it go faster,
if you want to.

00:39:46.801 --> 00:39:49.901
man: You said
extended API deadlines.

00:39:49.901 --> 00:39:53.400
Are you talking about
urlfetch as one example?

00:39:53.400 --> 00:39:56.300
Haugh: Yeah,
that's one example.

00:39:56.300 --> 00:39:57.567
man:
Soon.

00:39:57.567 --> 00:40:00.501
Haugh:
Mmm-hmm.

00:40:00.501 --> 00:40:02.801
man: What are some examples
of real world apps

00:40:02.801 --> 00:40:05.000
that are being written
with backends

00:40:05.000 --> 00:40:07.200
either at Google
or with partners?

00:40:07.200 --> 00:40:10.267
Haugh: Oh, that have been
written right now?

00:40:10.267 --> 00:40:13.033
I don't think I can really
mention anything at the moment

00:40:13.033 --> 00:40:15.667
that's using backends.

00:40:15.667 --> 00:40:20.434
We have plans to use backends
for some App Engine services

00:40:20.434 --> 00:40:25.133
in the future, but they're
nothing ready to announce.

00:40:29.167 --> 00:40:31.400
All right.

00:40:31.400 --> 00:40:32.601
All right, well,
thank you, everyone,

00:40:32.601 --> 00:40:34.901
and enjoy using
App Engine Backends.

00:40:34.901 --> 00:40:36.734
[applause]

