WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:05.040
Suppose, I've got a depth scene here and

00:00:05.040 --> 00:00:08.610
I'd like to match it to some model or
some previously observed depth scene.

00:00:08.610 --> 00:00:10.250
How might I do that?

00:00:10.250 --> 00:00:13.990
Well, what I need to do,
is I need to find some patches,

00:00:13.990 --> 00:00:19.490
some locations on my object and match
them to some locations on my object.

00:00:19.490 --> 00:00:23.390
And you know it should be somewhat
invariant to how I look at it.

00:00:23.390 --> 00:00:25.100
All right, so I'm looking over here,
looking over there.

00:00:25.100 --> 00:00:27.980
I want to find the same thing,
the object might be rotated.

00:00:27.980 --> 00:00:31.400
Things might,
we've seen this movie before.

00:00:31.400 --> 00:00:36.518
Remember we we're matching pictures as
we had two pictures that were rotated,

00:00:36.518 --> 00:00:39.708
translated, scaled, and
we wanted to align them.

00:00:39.708 --> 00:00:41.435
Do you remember SIF?

00:00:41.435 --> 00:00:44.900
SIF was a way of saying,
in Harris points, remember they were

00:00:44.900 --> 00:00:47.290
Harris Stevens points, and
nobody ever remembered Stevens.

00:00:47.290 --> 00:00:51.250
We had ways of finding points, and
then generating a descriptor and

00:00:51.250 --> 00:00:57.140
that descriptor had to be,
sort of discriminative and yet, robust.

00:00:57.140 --> 00:00:59.640
That is, we wanted them to be
relatively unique but robust, so

00:00:59.640 --> 00:01:02.280
that when we found a description
here and we matched it with

00:01:02.280 --> 00:01:05.540
the description there,
it would most likely be the right one.

00:01:05.540 --> 00:01:06.410
And then we improve that,

00:01:06.410 --> 00:01:09.400
we use ransack in order to find
the right sets of matches.

00:01:09.400 --> 00:01:11.490
Well, we can do exactly
the same thing with depth.

00:01:11.490 --> 00:01:15.550
You know what's drawn here is that
I've got this interest point and

00:01:15.550 --> 00:01:19.310
I've got this sort of neighborhood
of these five points around it or

00:01:19.310 --> 00:01:21.790
I might look at a, at a volume of these.

00:01:21.790 --> 00:01:25.210
And what I'm going to do it, I might
find the relationship between these

00:01:25.210 --> 00:01:28.130
points and say the little local
normals associated with the point, or

00:01:28.130 --> 00:01:30.040
something to do with the geometry.

00:01:30.040 --> 00:01:33.250
The idea is whatever it is that
I'm measuring is not a function

00:01:33.250 --> 00:01:35.270
of how I looked at the points.

00:01:35.270 --> 00:01:40.040
So in fact, the way we often do these
is, we typically will build a, we'll,

00:01:40.040 --> 00:01:43.150
we'll take these points and
we'll build a, a description and

00:01:43.150 --> 00:01:44.690
we'll put them into a histogram.

00:01:44.690 --> 00:01:48.760
Okay, so maybe we just quantized these
different orientations into, you know,

00:01:48.760 --> 00:01:52.710
five different levels, so we have,
you know, five, level thing, and

00:01:52.710 --> 00:01:54.550
then we might have distances.

00:01:54.550 --> 00:01:58.430
So, in fact, one example,
they used a five by five by five

00:01:58.430 --> 00:02:01.970
histogram that gave you 125
different values, okay?

00:02:01.970 --> 00:02:04.900
Remember in SIF I think we
had 128 different values.

00:02:04.900 --> 00:02:07.430
So here we have 125 different values.

00:02:07.430 --> 00:02:09.669
And then for every patch,
we compute these and

00:02:09.669 --> 00:02:13.680
we can compare them against the patches
in our model, find the putative matches,

00:02:13.680 --> 00:02:17.220
and then do something like ransack to,
to do the matching.

00:02:17.220 --> 00:02:21.850
There's a version called
the fast point feature histogram

00:02:21.850 --> 00:02:24.430
which is a way of doing this in 3D,
and again,

00:02:24.430 --> 00:02:28.020
I think is probably influenced
directly in the Point Cloud Library.

00:02:29.040 --> 00:02:33.820
So there are a couple of places
where the Point Cloud Library, I,

00:02:33.820 --> 00:02:36.220
I already pointed you
at 'PointClouds.org'.

00:02:36.220 --> 00:02:39.720
For many of you in the robotics
universe there's something called ROS,

00:02:39.720 --> 00:02:43.040
the Robot Operating System originally
out of Willow Garage and then it's,

00:02:43.040 --> 00:02:46.080
it's robotic software open found,
it's got all those letters in it,

00:02:46.080 --> 00:02:49.650
it's an open source ongoing development
system for doing robotics and

00:02:49.650 --> 00:02:51.650
the Point Cloud Library and
by the way, Open CV,

00:02:51.650 --> 00:02:55.040
Computer Vision Library
are all part of that universe.

00:02:55.040 --> 00:02:58.680
And that's really helped make it easy
for people to do that development.

00:02:58.680 --> 00:03:01.670
And there are drivers, by the way,
in that for using the Kinect or

00:03:01.670 --> 00:03:05.400
PrimeSense sensors as well, so you can
go get your point clouds that way.

00:03:05.400 --> 00:03:10.130
So here's a picture that I showed
you before from pointclouds.org.

00:03:10.130 --> 00:03:14.040
And in fact, here it says,
ransack cylinder segmentation.

00:03:14.040 --> 00:03:17.830
So basically, they ransacked to
find the different planes and

00:03:17.830 --> 00:03:19.790
to also find these different cylinders.

00:03:19.790 --> 00:03:22.530
You know how to do that already,
so you could do this and

00:03:22.530 --> 00:03:25.650
it basically gives you a direct
interpretation of the geometry

