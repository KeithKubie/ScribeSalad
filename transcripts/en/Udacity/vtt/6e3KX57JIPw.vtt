WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:00.940
So let's see if we can be a

00:00:00.940 --> 00:00:05.150
bit more formal about this notion of usefulness. Okay?

00:00:05.150 --> 00:00:08.010
So, I erased all the stuff I had before

00:00:08.010 --> 00:00:10.580
but basically you could summarize that last side, as

00:00:10.580 --> 00:00:12.800
saying that relevance measures the effect on the

00:00:12.800 --> 00:00:16.420
bayes optimal classifier. Right? So a variable is relevant

00:00:16.420 --> 00:00:19.350
if it can make the bayes optimal classifiers performance

00:00:19.350 --> 00:00:24.210
better or worse. So, really relevance is about information.

00:00:25.360 --> 00:00:27.750
So, when you were talking earlier about things that you might use for

00:00:27.750 --> 00:00:30.870
filtering you said, well, I like things that have variance or things that have

00:00:30.870 --> 00:00:34.880
entropy or things that give me information gain. Those are all measures of

00:00:34.880 --> 00:00:36.660
the information that is present in a

00:00:36.660 --> 00:00:39.410
particular variable or a particular feature. Right?

00:00:39.410 --> 00:00:39.810
&gt;&gt; Yeah.

00:00:39.810 --> 00:00:41.800
&gt;&gt; So really from the bayes optimal

00:00:41.800 --> 00:00:43.570
classify point of view the only thing that

00:00:43.570 --> 00:00:46.470
matters is how much information a particular variable

00:00:46.470 --> 00:00:51.050
provides. You know, conditioned on some label or

00:00:51.050 --> 00:00:53.270
just in general how much information it provides so a

00:00:53.270 --> 00:00:57.300
variable like C here which doesn't change has zero entropy, provides

00:00:57.300 --> 00:01:00.550
no information, independent of the value of the label and therefore

00:01:00.550 --> 00:01:04.680
cannot be relevant to the bayes optimal classifier. That make sense?

00:01:04.680 --> 00:01:07.020
&gt;&gt; It does. Now I, and, and the,

00:01:07.020 --> 00:01:10.370
this this notion of help, usefulness. Not helpfulness, but

00:01:10.370 --> 00:01:13.930
usefulness. Is when we condition on particular predictor

00:01:13.930 --> 00:01:16.270
and that's why we can have C being useful

00:01:16.270 --> 00:01:18.290
in the context of a, perceptron.

00:01:18.290 --> 00:01:24.100
&gt;&gt; Right. So usefulness is exactly about effect on error given a

00:01:24.100 --> 00:01:27.050
particular classifier, or some specific model.

00:01:27.050 --> 00:01:31.380
So usefulness is exactly about minimizing error

00:01:32.630 --> 00:01:37.640
given some particular model or some particular learning algorithm, right? So, in

00:01:37.640 --> 00:01:42.470
this case although C is clearly not relevant, it is in fact useful

00:01:42.470 --> 00:01:47.030
at least for something like W transpose X. Now,

00:01:47.030 --> 00:01:50.610
this is not useful for a decision tree, nor

00:01:50.610 --> 00:01:52.740
is it relevant. It is not relevant to this

00:01:52.740 --> 00:01:56.540
particular problem, but it is however useful for some algorithms.

00:01:56.540 --> 00:01:58.320
&gt;&gt; Now, just to clarify so, so it

00:01:58.320 --> 00:02:00.130
seems like the base optimal classifier has a

00:02:00.130 --> 00:02:02.660
privileged position in this definition right, so can

00:02:02.660 --> 00:02:06.110
we define relevant as measuring effect on, a perceptron.

00:02:06.110 --> 00:02:07.420
&gt;&gt; Relevance, no.

00:02:07.420 --> 00:02:07.726
&gt;&gt; No I'm

00:02:07.726 --> 00:02:10.122
saying, but it, you just, you plugged in, a, a kind of

00:02:10.122 --> 00:02:12.805
classifier there. Why can't we plug it some other kind of classifier?

00:02:12.805 --> 00:02:14.610
&gt;&gt; For the base optimal classifier?

00:02:14.610 --> 00:02:16.010
&gt;&gt; Yeah, why is that one special?

00:02:16.010 --> 00:02:17.510
&gt;&gt; Because the base optimal classifier

00:02:17.510 --> 00:02:21.190
captures this notion of the optimal thing

00:02:21.190 --> 00:02:24.390
that you could do. It's not a specific algorithm. I mean you could write

00:02:24.390 --> 00:02:27.510
down an algorithm that would compute the base optimal classifier, except that it

00:02:27.510 --> 00:02:29.660
requires you looking at all possibly infinite

00:02:29.660 --> 00:02:33.190
number of hypotheses. Right? But it is,

00:02:33.190 --> 00:02:36.100
the, it the base optimal classifier computes

00:02:36.100 --> 00:02:38.760
the best label, given all the probabilities

00:02:38.760 --> 00:02:41.330
that you could, ostensibly compute over all

00:02:41.330 --> 00:02:44.310
the hypothesis space. It doesn't have to

00:02:44.310 --> 00:02:46.550
actually require specific algorithm to do so.

00:02:46.550 --> 00:02:49.060
It truly is a measure of information

00:02:49.060 --> 00:02:51.310
of variables. So, any other algorithm you

00:02:51.310 --> 00:02:53.540
have has a bias, in particular inductive bias.

00:02:53.540 --> 00:02:54.120
&gt;&gt; Okay.

00:02:54.120 --> 00:02:56.280
&gt;&gt; [LAUGH]

00:02:56.280 --> 00:02:58.280
Okay, that's a fine answer. So, at the very

00:02:58.280 --> 00:03:01.560
beginning of our discussion, Michael, you actually asked me this

00:03:01.560 --> 00:03:04.440
question of what the criteria was? When I said that

00:03:04.440 --> 00:03:07.260
features selection was about maximizing

00:03:07.260 --> 00:03:09.590
some criteria, removing features according

00:03:09.590 --> 00:03:11.920
to some criteria and I told you that eventually we'd

00:03:11.920 --> 00:03:13.750
kind of get to the point of what the criteria is.

00:03:13.750 --> 00:03:16.490
The notion of relevance versus usefulness gives us an idea

00:03:16.490 --> 00:03:19.940
of thinking about what that criteria is. Ultimately we've been

00:03:19.940 --> 00:03:23.280
talking about unsupervised learning, mostly in a kind of vacuum but

00:03:23.280 --> 00:03:25.170
presumably you know wheather some

00:03:25.170 --> 00:03:27.220
particular description compact or otherwise, some

00:03:27.220 --> 00:03:30.630
particular label is in fact a good one based on how

00:03:30.630 --> 00:03:33.510
it's used later on. So, one way of thinking about this

00:03:33.510 --> 00:03:35.690
is the labels that I come up with for a set of

00:03:35.690 --> 00:03:38.500
data are exactly good ones in so far as they help

00:03:38.500 --> 00:03:41.890
me to do something else like classification later. All that clustering

00:03:41.890 --> 00:03:44.920
that we did before, like with k means and E M.

00:03:44.920 --> 00:03:48.390
You could think of those as a kind of feature transformation algorithm

00:03:48.390 --> 00:03:51.950
which is what we'll be talking about next where you've taken a bunch

00:03:51.950 --> 00:03:55.410
of features and you've converted them into something simple like a label. And

00:03:55.410 --> 00:03:58.630
whether that label is a good label or a bad label, depends entirely

00:03:58.630 --> 00:04:00.580
upon whether you can then do some

00:04:00.580 --> 00:04:02.520
kind of classification or regression problem later.

00:04:02.520 --> 00:04:06.130
&gt;&gt; Label in this case meaning the cluster name? Right.

00:04:06.130 --> 00:04:06.920
&gt;&gt; Got it.

00:04:06.920 --> 00:04:07.070
&gt;&gt; Okay.

00:04:07.070 --> 00:04:08.270
&gt;&gt; That's interesting.

00:04:08.270 --> 00:04:11.320
&gt;&gt; So, you'll actually find if you go through the

00:04:11.320 --> 00:04:13.460
literature and you, you look at some algorithms people have

00:04:13.460 --> 00:04:17.399
predicted, that a lot of the, measures like information

00:04:17.399 --> 00:04:20.790
gain or entropy or whatever, often end up being couched

00:04:20.790 --> 00:04:24.110
in terms of relevance. But ultimately, what we really

00:04:24.110 --> 00:04:27.080
care about is usefulness, or at least one could argue.

00:04:27.080 --> 00:04:27.280
&gt;&gt; Cool.

00:04:27.280 --> 00:04:30.770
&gt;&gt; Okay. So that's pretty much what I wanted to talk about

00:04:30.770 --> 00:04:33.670
for a feature selection. There's a lot of algorithms and, I mean,

00:04:33.670 --> 00:04:36.040
if you go and you look at the material we've made available

00:04:36.040 --> 00:04:38.760
to everyone you'll be able to see some of these algorithms discussed

00:04:38.760 --> 00:04:41.440
in more detail. But at a high level these are the, the key

00:04:41.440 --> 00:04:44.510
issues that I wanted you to see. So, with that Michael, let's wrap up.

