WEBVTT
Kind: captions
Language: en

00:00:00.350 --> 00:00:01.870
And we're back. What's the answer, Michael?

00:00:01.870 --> 00:00:04.030
&gt;&gt; Okay, so it depends.

00:00:04.030 --> 00:00:05.080
&gt;&gt; What does it depend on?

00:00:05.080 --> 00:00:07.110
I've given you everything. This is straightforward.

00:00:07.110 --> 00:00:09.360
&gt;&gt; Well, so, okay, I guess. The here, so here's what I'm seeing.

00:00:09.360 --> 00:00:13.940
So I'm, what I'm seeing is that hypothesis one is the most likely hypothesis.

00:00:13.940 --> 00:00:16.790
&gt;&gt; It's not just the most likely, it's the most a posteriori.

00:00:16.790 --> 00:00:18.220
&gt;&gt; Well, that's what I mean by likely.

00:00:18.220 --> 00:00:20.530
Right, is the map hypothesis? It's the maximum a

00:00:20.530 --> 00:00:22.900
posteriori hypothesis. So if we say, what is the

00:00:22.900 --> 00:00:25.490
label according to the map hypothesis? Boom, it's plus.

00:00:25.490 --> 00:00:26.030
&gt;&gt; Yes.

00:00:26.030 --> 00:00:28.030
&gt;&gt; But, if we're saying what's the

00:00:28.030 --> 00:00:30.860
most likely label. So the most likely label

00:00:30.860 --> 00:00:35.890
is, is, we have to actually look over all the hypotheses and in a sense,

00:00:35.890 --> 00:00:41.200
let them vote. So the probability that the label is minus is actually 0.6, which

00:00:41.200 --> 00:00:44.489
is greater than 0.4, so if I had to pick, I would go with minus.

00:00:44.489 --> 00:00:47.610
&gt;&gt; And you would be correct. So I did a

00:00:47.610 --> 00:00:50.510
little tricky thing here for you Michael. You've been complaining about

00:00:50.510 --> 00:00:52.860
my titles, because everyone said Bayesian learning and

00:00:52.860 --> 00:00:54.850
I changed the title here to Bayesian Classification.

00:00:54.850 --> 00:00:55.550
&gt;&gt; Ohhh.

00:00:55.550 --> 00:00:58.430
&gt;&gt; Because in fact the problem here, we've been talking about all along

00:00:58.430 --> 00:01:03.550
is, what's the best hypothesis. But here. I ask you what's the best label?

00:01:03.550 --> 00:01:06.780
&gt;&gt; Hm. And exactly as you point out, finding the

00:01:06.780 --> 00:01:09.350
best hypothesis is a, is a very simple algorithm. Here I'll

00:01:09.350 --> 00:01:11.640
write it for you because we did it before. For

00:01:11.640 --> 00:01:15.590
every H in hypothesis set, simply compute the probability that it

00:01:15.590 --> 00:01:20.570
is the best one, and then simply output max. That's how you find the best

00:01:20.570 --> 00:01:24.210
hypothesis, but that's not how you find the best label. The way you find the

00:01:24.210 --> 00:01:26.210
best label is you basically do a

00:01:26.210 --> 00:01:29.568
weighted vote for every single hypothesis in the

00:01:29.568 --> 00:01:33.770
hypothesis set, according to the weight being

00:01:33.770 --> 00:01:35.600
the probability of that hypothesis given the data.

00:01:35.600 --> 00:01:36.520
&gt;&gt; Okay.

00:01:36.520 --> 00:01:40.540
&gt;&gt; So the best, if you can only output hypothesis and use that hypothesis,

00:01:40.540 --> 00:01:43.920
in fact, you would say plus. But if you asked everyone

00:01:43.920 --> 00:01:45.950
to vote, just like we did with boosting, just like we

00:01:45.950 --> 00:01:49.160
did effectively with KNN and all these other kind of. Weighted

00:01:49.160 --> 00:01:52.062
regression techniques we've used before, you need to do the voting.

00:01:52.062 --> 00:01:54.680
&gt;&gt; And I, and I feel like I could probably derive

00:01:54.680 --> 00:01:58.090
that using rules of probability. Right, because really what we want is

00:01:58.090 --> 00:02:02.270
we're trying to maximize the probability of the label, given the

00:02:02.270 --> 00:02:05.590
data, and I think the probability laws would tell us that's equal

00:02:05.590 --> 00:02:09.900
to the sum over all hypotheses of the hypothesis and the

00:02:09.900 --> 00:02:13.550
label given the data, which is, like, the probability of the

00:02:13.550 --> 00:02:17.160
hypothesis given the data, times the probability of the label

00:02:17.160 --> 00:02:20.120
given the hypothesis, and that's what we did, we summed up.

00:02:20.120 --> 00:02:21.970
You know, the probability of the label given the hypothesis

00:02:21.970 --> 00:02:25.340
is either one or zero. That's your left column. And then

00:02:25.340 --> 00:02:28.140
we're summing up the probabilities that corresponding to the pluses. And

00:02:28.140 --> 00:02:30.660
we're summing up the probabilities corresponding to the minuses and choosing

00:02:30.660 --> 00:02:31.740
the largest one.

00:02:31.740 --> 00:02:33.370
&gt;&gt; So, this is what you just said written down

00:02:33.370 --> 00:02:38.700
as an equation. basically, the most likely value. Is the

00:02:38.700 --> 00:02:43.495
one that maximizes this expression. And this follows directly from

00:02:43.495 --> 00:02:46.130
Bayesian's rule where now instead of trying to maximize the

00:02:46.130 --> 00:02:48.620
hypothesis given the data, you're trying to maximize the value

00:02:48.620 --> 00:02:51.070
given the data. And I think it's pretty straightforward to

00:02:51.070 --> 00:02:52.490
derive that but I'd like to leave it up to

00:02:52.490 --> 00:02:55.930
the students to do it on their own. Okay, so Michael,

00:02:55.930 --> 00:02:57.790
in some sense everything that I've told you before is a

00:02:57.790 --> 00:03:00.570
lie, in that I've led you down this path that somehow,

00:03:00.570 --> 00:03:02.880
finding the best hypothesis is the right thing to do. But

00:03:02.880 --> 00:03:07.250
the truth is, finding the value is what we actually care about.

00:03:07.250 --> 00:03:09.130
Finding a hypothesis is just a means to an end. And

00:03:09.130 --> 00:03:12.480
if we have a way of actually computing the probabilities for

00:03:12.480 --> 00:03:14.960
all the hypotheses, then we should let them to vote in order

00:03:14.960 --> 00:03:17.780
to find the best actual label or the best value for it.

00:03:17.780 --> 00:03:18.700
&gt;&gt; Got it.

00:03:18.700 --> 00:03:19.880
&gt;&gt; All right. Good.

