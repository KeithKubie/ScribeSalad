WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.340
[TITLE MUSIC PLAYING]

00:00:04.680 --> 00:00:07.090
MAYANK BANSAL: Good
afternoon, everyone.

00:00:07.090 --> 00:00:11.080
I am Mayank Bansal, and I'm a
research scientist at Waymo.

00:00:11.080 --> 00:00:14.070
Today, I'm going to be
talking about teaching a car

00:00:14.070 --> 00:00:16.120
to drive itself.

00:00:16.120 --> 00:00:19.690
We are going to walk through the
design of ChauffeurNet, which

00:00:19.690 --> 00:00:22.030
is a deep-learned
driving network.

00:00:22.030 --> 00:00:25.120
But before we do, let's
look at some examples

00:00:25.120 --> 00:00:29.271
of this network driving a
real car at our test facility.

00:00:32.960 --> 00:00:35.210
Here is an example
demonstrating lane

00:00:35.210 --> 00:00:37.590
following down a curved road.

00:00:37.590 --> 00:00:40.460
You can look at both the
overhead view as well as

00:00:40.460 --> 00:00:43.400
the camera view to witness
the smoothness of the drive.

00:00:46.450 --> 00:00:51.200
The second example demonstrates
stopping for a stop sign.

00:00:51.200 --> 00:00:53.770
The car detects the
stop sign, slows down,

00:00:53.770 --> 00:00:56.440
comes to a full stop,
and then continues

00:00:56.440 --> 00:01:01.260
with a right turn, all of it
being executed by ChauffeurNet.

00:01:01.260 --> 00:01:02.960
The change in the
color of the car

00:01:02.960 --> 00:01:05.500
indicates braking
issued by the net.

00:01:17.050 --> 00:01:20.680
Now let's jump right into
designing this network.

00:01:20.680 --> 00:01:22.590
And, in order to
do that, we first

00:01:22.590 --> 00:01:25.690
need to define the scope of
what this network will do.

00:01:29.380 --> 00:01:31.400
So here is a quick
overview of what

00:01:31.400 --> 00:01:35.260
a typical self-driving
software stack looks like.

00:01:35.260 --> 00:01:37.050
So you start from
sensor data, which

00:01:37.050 --> 00:01:39.600
could come from a
multitude of sensors,

00:01:39.600 --> 00:01:43.120
like cameras,
radars, and lasers.

00:01:43.120 --> 00:01:45.960
And then a perception module
takes all that sensor data

00:01:45.960 --> 00:01:49.510
and converts it into a
higher-level representation,

00:01:49.510 --> 00:01:51.930
for example, where all the
objects are, how they're

00:01:51.930 --> 00:01:54.600
moving, their speeds,
accelerations,

00:01:54.600 --> 00:01:57.640
what is the state of
traffic lights, and so on.

00:01:57.640 --> 00:02:01.140
All of this information is then
fed to a behavior prediction

00:02:01.140 --> 00:02:02.110
module.

00:02:02.110 --> 00:02:05.790
This module is responsible for
predicting possible futures

00:02:05.790 --> 00:02:06.820
for objects.

00:02:06.820 --> 00:02:08.880
For example, there's
a car in front--

00:02:08.880 --> 00:02:12.540
is it going to turn left,
turn right, or stay stopped,

00:02:12.540 --> 00:02:14.280
things like that.

00:02:14.280 --> 00:02:16.560
Then, all of this
information goes further

00:02:16.560 --> 00:02:18.070
into a planning module.

00:02:18.070 --> 00:02:21.120
This module then absorbs
all this information

00:02:21.120 --> 00:02:23.940
and converts it into a
higher-level trajectory

00:02:23.940 --> 00:02:25.470
representation.

00:02:25.470 --> 00:02:29.640
This representation might be in
the form of a sequence of poses

00:02:29.640 --> 00:02:32.100
or in some other representation.

00:02:32.100 --> 00:02:34.860
But essentially, you
take this and feed it

00:02:34.860 --> 00:02:36.950
to a controls optimizer.

00:02:36.950 --> 00:02:38.610
The controls
optimizer is the one

00:02:38.610 --> 00:02:41.550
which is optimizing,
through this trajectory,

00:02:41.550 --> 00:02:45.360
to convert it to throttle
and steering commands, which

00:02:45.360 --> 00:02:48.180
ultimately the controller
onboard the car will

00:02:48.180 --> 00:02:51.690
use to drive the car forward.

00:02:51.690 --> 00:02:53.640
Now when it comes
to actually thinking

00:02:53.640 --> 00:02:57.400
about machine learning
for the driving task,

00:02:57.400 --> 00:02:59.290
we have a number of options.

00:02:59.290 --> 00:03:02.280
We can either replace each
of the independent modules

00:03:02.280 --> 00:03:07.590
with ML, or replace
multiple of them together.

00:03:07.590 --> 00:03:10.400
One of the approaches which
sits at one end of the spectrum

00:03:10.400 --> 00:03:12.920
is called end-to-end driving.

00:03:12.920 --> 00:03:15.410
In this case, you
replace the entire stack

00:03:15.410 --> 00:03:17.510
with a single
machine-learned model

00:03:17.510 --> 00:03:20.150
which starts directly
from sensor data

00:03:20.150 --> 00:03:23.195
and directly produces throttle
and steering commands.

00:03:26.290 --> 00:03:29.410
You can also do
mid-to-mid driving.

00:03:29.410 --> 00:03:32.870
In this case, you produce
a high-level trajectory

00:03:32.870 --> 00:03:36.520
instead of directly outputting
throttle and steering commands.

00:03:36.520 --> 00:03:38.650
And instead of starting
from sensor data,

00:03:38.650 --> 00:03:41.740
you start from a
higher-level representation

00:03:41.740 --> 00:03:45.130
that was generated by
the perception module.

00:03:45.130 --> 00:03:47.050
This is precisely
the representation

00:03:47.050 --> 00:03:50.870
we'll use for ChauffeurNet.

00:03:50.870 --> 00:03:54.590
To go into more detail, here
is a view of what exactly

00:03:54.590 --> 00:03:56.340
the input looks like.

00:03:56.340 --> 00:03:58.580
So the input is like
a top-down view,

00:03:58.580 --> 00:04:01.790
with the rendering of the
perception output in the form

00:04:01.790 --> 00:04:03.890
of these white boxes.

00:04:03.890 --> 00:04:06.350
And the output will be
the sequence of poses

00:04:06.350 --> 00:04:09.230
which is our trajectory
representation here.

00:04:09.230 --> 00:04:11.480
Now, there are a
number of advantages

00:04:11.480 --> 00:04:13.640
to this particular
representation.

00:04:13.640 --> 00:04:16.670
First, since we are
using perception output,

00:04:16.670 --> 00:04:19.430
it allows us to
decouple the complexity

00:04:19.430 --> 00:04:23.630
of learning a perception system
from the complexity of learning

00:04:23.630 --> 00:04:25.160
a driver.

00:04:25.160 --> 00:04:28.340
Then, we can also use any
other perception algorithm,

00:04:28.340 --> 00:04:31.560
independent of how
we train the model.

00:04:31.560 --> 00:04:35.240
And finally, if we want to train
and evaluate in simulation,

00:04:35.240 --> 00:04:38.720
we can do it without having
to bother about how would we

00:04:38.720 --> 00:04:42.830
actually generate sensor data in
simulation, because perception

00:04:42.830 --> 00:04:47.550
can actually be generated
much easily in simulation.

00:04:50.430 --> 00:04:53.220
Now that we have defined
this scope for this network,

00:04:53.220 --> 00:04:56.370
let's think about how the
inputs and outputs will be more

00:04:56.370 --> 00:04:57.230
precisely defined.

00:05:01.230 --> 00:05:04.200
So we start with our
top-down or bird's eye view,

00:05:04.200 --> 00:05:06.150
like I showed in
the previous slide.

00:05:06.150 --> 00:05:10.800
In this case, we fixed 80
meters by 80 meters world

00:05:10.800 --> 00:05:12.900
representation.

00:05:12.900 --> 00:05:15.210
And our agent, or
the self-driving car,

00:05:15.210 --> 00:05:18.390
would be placed at a specific
location within this view.

00:05:18.390 --> 00:05:24.000
This is shown by the
white box in this figure.

00:05:24.000 --> 00:05:26.340
Then we'll represent
all the context

00:05:26.340 --> 00:05:30.400
around the SDC or the agent
in the same coordinate system.

00:05:30.400 --> 00:05:32.760
So the first image
shows a road map,

00:05:32.760 --> 00:05:36.960
which represents all the known
a priori features of the map.

00:05:36.960 --> 00:05:40.020
For instance, you
see the lane markers,

00:05:40.020 --> 00:05:43.390
the center line shown as
yellow, the crosswalks in blue.

00:05:43.390 --> 00:05:46.470
And we can add a lot of
features, like stop signs,

00:05:46.470 --> 00:05:49.200
the presence of traffic lights,
and so on, in the same map.

00:05:52.148 --> 00:05:53.690
Now, when it comes
to traffic lights,

00:05:53.690 --> 00:05:55.700
we need to convey
to the net what

00:05:55.700 --> 00:05:57.260
is the state of traffic lights.

00:05:57.260 --> 00:06:01.190
This is, again, being generated
by the perception system.

00:06:01.190 --> 00:06:04.310
In this picture, we show
how we represent that.

00:06:04.310 --> 00:06:08.180
These are all center lanes of
the lanes in this same grid

00:06:08.180 --> 00:06:11.270
as the map, and the
intensities encode

00:06:11.270 --> 00:06:13.340
the traffic light states.

00:06:13.340 --> 00:06:15.950
So in this particular
example, the brighter shades

00:06:15.950 --> 00:06:19.430
would reflect a red light,
and the other shades

00:06:19.430 --> 00:06:23.220
would reflect green light.

00:06:23.220 --> 00:06:26.900
This is the speed limit channel,
again encoding different speeds

00:06:26.900 --> 00:06:28.340
with different
intensity profiles.

00:06:32.310 --> 00:06:34.860
Now, the perception objects
which we talked about before--

00:06:34.860 --> 00:06:38.140
in this case, it's a
sequence of images--

00:06:38.140 --> 00:06:40.860
we want the net to know
exactly how they were moving

00:06:40.860 --> 00:06:42.480
over the past time frame.

00:06:42.480 --> 00:06:45.810
So we have a sequence of images
going from the past one or two

00:06:45.810 --> 00:06:46.930
seconds.

00:06:46.930 --> 00:06:49.230
And for each of
those timestamps,

00:06:49.230 --> 00:06:53.130
we'll have a single slice
of the sequence, which

00:06:53.130 --> 00:06:57.802
shows all the objects in this
scene as these bounding boxes,

00:06:57.802 --> 00:06:59.010
which are colored white here.

00:07:02.310 --> 00:07:04.260
In a similar
representation, we also

00:07:04.260 --> 00:07:08.100
want to show how exactly
our agent was placed

00:07:08.100 --> 00:07:13.320
and its heading, which is
shown by the white box here.

00:07:13.320 --> 00:07:15.720
Now, to convey how
the agent actually

00:07:15.720 --> 00:07:18.150
was moving in the past,
we also have a channel

00:07:18.150 --> 00:07:20.830
which shows a sequence of dots.

00:07:20.830 --> 00:07:22.830
Each of these pixels
is the location

00:07:22.830 --> 00:07:24.820
of the agent over the past--

00:07:24.820 --> 00:07:28.420
some timestamp in the past.

00:07:28.420 --> 00:07:30.660
And finally, we want
to convey to the net

00:07:30.660 --> 00:07:34.770
exactly what we want
the agent to do.

00:07:34.770 --> 00:07:38.180
So this is the planned route
channel which conveys that.

00:07:38.180 --> 00:07:40.070
So if we look at
it closely, this

00:07:40.070 --> 00:07:42.200
is essentially a
Google-Maps-style

00:07:42.200 --> 00:07:44.510
representation
which shows that we

00:07:44.510 --> 00:07:49.500
want the agent to actually turn
right in the next few seconds.

00:07:49.500 --> 00:07:51.470
Now, given all this
information, we

00:07:51.470 --> 00:07:54.950
want the net to
output a trajectory.

00:07:54.950 --> 00:07:56.870
As I said before,
this trajectory

00:07:56.870 --> 00:07:59.690
is in the form of
these waypoints which

00:07:59.690 --> 00:08:03.230
are shown by this animated
set of green dots.

00:08:07.740 --> 00:08:10.110
Now we have defined
this scope as well as

00:08:10.110 --> 00:08:12.160
the inputs and outputs.

00:08:12.160 --> 00:08:14.160
The next point here
is to actually pick up

00:08:14.160 --> 00:08:15.602
a model architecture.

00:08:18.320 --> 00:08:22.520
For our first model, we'll use
a convolutional recurrent neural

00:08:22.520 --> 00:08:23.820
network.

00:08:23.820 --> 00:08:25.820
So this is a
high-level schematic

00:08:25.820 --> 00:08:29.010
of what this network
will look like.

00:08:29.010 --> 00:08:32.809
So, if you follow the picture
with me from top to bottom,

00:08:32.809 --> 00:08:34.940
you start with the
rendered inputs,

00:08:34.940 --> 00:08:38.150
you pass them through a set
of convolutional layers, which

00:08:38.150 --> 00:08:40.549
is shown as a feature net here.

00:08:40.549 --> 00:08:43.340
That produces an embedding
of all the inputs

00:08:43.340 --> 00:08:44.930
the net has seen.

00:08:44.930 --> 00:08:48.320
And that gets passed
on to Agent RNN.

00:08:48.320 --> 00:08:50.600
This Agent RNN is
actually directed

00:08:50.600 --> 00:08:54.770
in part of the net which is
responsible for producing

00:08:54.770 --> 00:08:59.570
a sequence of waypoints which,
together, from the trajectory.

00:08:59.570 --> 00:09:01.460
Now, for each of
those waypoints,

00:09:01.460 --> 00:09:03.200
you want some metadata,
which is shown

00:09:03.200 --> 00:09:06.650
by these different
arrows, with heading speed

00:09:06.650 --> 00:09:09.530
as well as what the
box looks like at each

00:09:09.530 --> 00:09:11.660
of those waypoints.

00:09:11.660 --> 00:09:14.180
And as we can see in the
bottom part of the picture,

00:09:14.180 --> 00:09:17.060
all of these
predictions are guided

00:09:17.060 --> 00:09:20.390
by the ground route
known from the log data,

00:09:20.390 --> 00:09:22.265
and are driven by usual losses.

00:09:26.710 --> 00:09:30.230
Now, to look at it in a
little bit more detail,

00:09:30.230 --> 00:09:33.280
this is a blow-up of some
parts of the network.

00:09:33.280 --> 00:09:38.540
If you focus on the output of
Agent RNN, on the top right,

00:09:38.540 --> 00:09:41.440
you can see a
predicted location PK.

00:09:41.440 --> 00:09:45.730
Now, this predicted location
PK is one particular output.

00:09:45.730 --> 00:09:48.760
You actually produce
that, and then update

00:09:48.760 --> 00:09:54.400
a memory, M. This memory gets
fed back into the Agent RNN,

00:09:54.400 --> 00:09:57.640
and the Agent RNN
then can then use this

00:09:57.640 --> 00:10:00.250
to produce the next waypoint.

00:10:00.250 --> 00:10:02.080
On the bottom
right, we show what

00:10:02.080 --> 00:10:04.450
it does for the agent boxes.

00:10:04.450 --> 00:10:06.700
It has a similar
reference to produce

00:10:06.700 --> 00:10:10.040
a sequence of box locations.

00:10:10.040 --> 00:10:15.520
So in a sense, the Agent RNN is
taking in all the input data,

00:10:15.520 --> 00:10:18.790
and conditioned on whatever
it has predicted till now,

00:10:18.790 --> 00:10:22.070
it's actually predicting
the very next waypoint.

00:10:22.070 --> 00:10:25.098
And in this way, it can
predict the entire trajectory.

00:10:28.520 --> 00:10:32.450
Now, once we have this model,
we generated training data

00:10:32.450 --> 00:10:37.910
by sampling 26 million examples
from lots of our driving logs,

00:10:37.910 --> 00:10:39.160
and then we trained the model.

00:10:43.470 --> 00:10:44.910
Now comes the interesting part.

00:10:44.910 --> 00:10:46.650
Now that we have
a model trained,

00:10:46.650 --> 00:10:50.670
the question is, how
exactly do we evaluate it?

00:10:50.670 --> 00:10:53.830
Unlike traditional ML
models, in this case,

00:10:53.830 --> 00:10:56.310
we want this model to be
able to drive the car.

00:10:56.310 --> 00:10:58.170
So it's important
to pay attention

00:10:58.170 --> 00:11:01.320
to exactly how we evaluate it.

00:11:01.320 --> 00:11:04.590
As I'll discuss next, there
are two approaches in which

00:11:04.590 --> 00:11:06.060
we can evaluate this model--

00:11:06.060 --> 00:11:07.860
open loop and
closed loop control.

00:11:11.130 --> 00:11:13.760
So this is the traditional
way in which you typically

00:11:13.760 --> 00:11:15.710
evaluate models.

00:11:15.710 --> 00:11:18.920
In the diagram here, you take
the locked poses as well as

00:11:18.920 --> 00:11:22.550
all your input data for
a given test example.

00:11:22.550 --> 00:11:26.930
You feed it through the net, and
then you predict the waypoints

00:11:26.930 --> 00:11:28.850
and compare them
to the ground route

00:11:28.850 --> 00:11:34.420
to actually get an idea of how
well the network is performing.

00:11:34.420 --> 00:11:37.890
But if you really want the net
to be able to drive the car,

00:11:37.890 --> 00:11:41.730
you need to think about it in
a slightly different manner.

00:11:41.730 --> 00:11:44.790
That brings us to
closed loop control.

00:11:44.790 --> 00:11:47.850
So in this case, once you
have the predicted waypoints,

00:11:47.850 --> 00:11:51.540
you actually feed them
to a vehicle simulator.

00:11:51.540 --> 00:11:56.070
Think of it as a simulation
of the vehicle dynamics.

00:11:56.070 --> 00:11:58.980
In practice, in reality, this
will be the actual vehicle

00:11:58.980 --> 00:12:02.190
taking in those waypoints.

00:12:02.190 --> 00:12:04.890
Now, for evaluating
in simulation,

00:12:04.890 --> 00:12:06.930
we'll use the vehicle
simulator, which

00:12:06.930 --> 00:12:12.000
will use these waypoints
to drive the car forward.

00:12:12.000 --> 00:12:15.000
Because of that, the car
might actually drive forward

00:12:15.000 --> 00:12:17.580
and generate new poses.

00:12:17.580 --> 00:12:19.770
Now, an interesting
aspect of this

00:12:19.770 --> 00:12:24.150
is that those poses might
be very different from what

00:12:24.150 --> 00:12:26.880
the net was trained at.

00:12:26.880 --> 00:12:29.550
Now, given that, it would
be really hard for the net

00:12:29.550 --> 00:12:32.460
to generalize if it has
never seen this data

00:12:32.460 --> 00:12:36.090
or it actually lands
outside its distribution.

00:12:36.090 --> 00:12:38.160
So it's important to
evaluate the network,

00:12:38.160 --> 00:12:41.070
both in open loop as well
as closed loop settings.

00:12:44.850 --> 00:12:46.910
So let's look at
what our network does

00:12:46.910 --> 00:12:49.020
in our very first test.

00:12:49.020 --> 00:12:53.240
So the very first test is the
simple task of lane following.

00:12:53.240 --> 00:12:56.330
We find that it's able to
follow lanes seamlessly

00:12:56.330 --> 00:13:00.740
in the open loop, but in
closed loop, it goes off road.

00:13:00.740 --> 00:13:02.630
Now, let's look at why that is.

00:13:05.440 --> 00:13:07.825
So here is a single
test example.

00:13:07.825 --> 00:13:10.810
The blue dots are the
past, and red dots

00:13:10.810 --> 00:13:14.080
are the future locations
predicted by the net.

00:13:14.080 --> 00:13:16.930
You can see that these locations
are well-aligned with the lane

00:13:16.930 --> 00:13:20.860
boundaries, which shows that
the agent did a good job using

00:13:20.860 --> 00:13:24.100
this net as a driver.

00:13:24.100 --> 00:13:26.680
Now consider these
other two examples.

00:13:26.680 --> 00:13:30.250
These were generated in a
closed-loop setting, where

00:13:30.250 --> 00:13:34.270
the lane lines had a
slight offset in the angle

00:13:34.270 --> 00:13:37.690
relative to the image
coordinate system.

00:13:37.690 --> 00:13:40.000
As you can see, the
red dots are no longer

00:13:40.000 --> 00:13:41.110
aligned with the lanes.

00:13:41.110 --> 00:13:45.470
In fact, they're taking
the car off road.

00:13:45.470 --> 00:13:47.690
Closer attention in
these green boxes

00:13:47.690 --> 00:13:50.480
shows that the red
dots are more or less

00:13:50.480 --> 00:13:53.270
aligned with the image axis.

00:13:53.270 --> 00:13:55.460
So what's happening
here is that the net

00:13:55.460 --> 00:13:59.000
has learned a bias from
the top-down orientation

00:13:59.000 --> 00:14:00.740
of the input data.

00:14:00.740 --> 00:14:02.480
All of our input
data was rendered

00:14:02.480 --> 00:14:04.820
with a specific
orientation, and the net

00:14:04.820 --> 00:14:07.670
has learned that
that orientation is

00:14:07.670 --> 00:14:11.000
much more important than
the lane orientation.

00:14:11.000 --> 00:14:14.660
So we really want the
net to be able to learn

00:14:14.660 --> 00:14:17.300
what it is like to
drive along the lanes,

00:14:17.300 --> 00:14:18.830
and not along the image axis.

00:14:22.090 --> 00:14:24.150
So what we do here
to resolve that

00:14:24.150 --> 00:14:26.550
is to actually render
the training data

00:14:26.550 --> 00:14:31.180
with a whole bunch of
randomized heading offsets.

00:14:31.180 --> 00:14:33.930
So here are three
examples of different ways

00:14:33.930 --> 00:14:36.580
in which we have
oriented the input.

00:14:36.580 --> 00:14:38.610
So when it goes through
the training pipeline,

00:14:38.610 --> 00:14:42.940
the net can actually focus
on the lane orientations.

00:14:42.940 --> 00:14:45.090
So this is one
example of the kind

00:14:45.090 --> 00:14:48.510
of domain-specific perturbations
we might need to actually make

00:14:48.510 --> 00:14:50.610
the ML system work.

00:14:54.820 --> 00:14:58.720
Now, the next task that
we evaluated the net at

00:14:58.720 --> 00:15:01.150
was related to stop signs.

00:15:01.150 --> 00:15:03.370
So once again we
find, in open loop,

00:15:03.370 --> 00:15:07.300
the agent stops for a stop
sign, but in closed loop,

00:15:07.300 --> 00:15:12.940
it actually never stops, and
continues driving past them.

00:15:12.940 --> 00:15:16.402
Now, this one is a little
bit more interesting.

00:15:16.402 --> 00:15:17.860
So if you consider
what's happening

00:15:17.860 --> 00:15:20.350
in most of our
training data, we find

00:15:20.350 --> 00:15:22.480
that most of our
training data has

00:15:22.480 --> 00:15:24.970
past motion profile,
which is already

00:15:24.970 --> 00:15:27.170
braking for the stop sign.

00:15:27.170 --> 00:15:29.560
So the agent is already
braking for these top lanes

00:15:29.560 --> 00:15:32.690
when it comes into
its field of view.

00:15:32.690 --> 00:15:34.960
Now, because of that,
the net doesn't actually

00:15:34.960 --> 00:15:37.870
learn that it has to slow
down for the stop sign.

00:15:37.870 --> 00:15:40.390
It rather learns that
if for just purely

00:15:40.390 --> 00:15:42.860
extrapolates from that
data, it can come to a stop.

00:15:45.840 --> 00:15:48.120
Now if you apply
the same analogy

00:15:48.120 --> 00:15:50.010
to the closed-loop
setting, we find

00:15:50.010 --> 00:15:52.650
that, in most
closed-loop examples,

00:15:52.650 --> 00:15:54.870
an agent is actually
approaching the stop

00:15:54.870 --> 00:15:56.900
sign at a constant speed.

00:15:56.900 --> 00:15:59.040
Now, because of
that, the net again

00:15:59.040 --> 00:16:02.250
extrapolates, continues
driving at constant speeds,

00:16:02.250 --> 00:16:04.466
and just runs off the stop sign.

00:16:07.160 --> 00:16:09.290
So once again, the
important point

00:16:09.290 --> 00:16:12.980
is the net has learned a bias,
this time, not from the way

00:16:12.980 --> 00:16:16.580
the data was generated, but just
from the characteristic of what

00:16:16.580 --> 00:16:18.350
it has been fed.

00:16:18.350 --> 00:16:21.830
So the bias in this case
is from the past motion,

00:16:21.830 --> 00:16:24.620
and we really want
to remove that to be

00:16:24.620 --> 00:16:27.300
able to avoid this bias.

00:16:27.300 --> 00:16:29.570
But the issue is it's
important for the net

00:16:29.570 --> 00:16:32.330
to know what speed and
acceleration the car

00:16:32.330 --> 00:16:35.960
was driving with so it can
actually predict the future.

00:16:35.960 --> 00:16:41.070
So we can't really
remove that past motion.

00:16:41.070 --> 00:16:44.100
Instead, what we do
here is we propose

00:16:44.100 --> 00:16:47.370
adding dropout on these poses.

00:16:47.370 --> 00:16:52.150
What that means in practice is
that for a subset of examples,

00:16:52.150 --> 00:16:54.330
we actually remove
the past motion,

00:16:54.330 --> 00:16:58.470
but we do keep it for
the rest of the examples.

00:16:58.470 --> 00:17:01.260
And that lets the net
actually learn that,

00:17:01.260 --> 00:17:04.650
to explain the stop sign,
it has to really look

00:17:04.650 --> 00:17:08.190
not on the past poses, but
on the real things which

00:17:08.190 --> 00:17:09.480
are rendered into the input.

00:17:14.890 --> 00:17:19.380
Now we found the agent followed
lane lines, it came to a stop.

00:17:19.380 --> 00:17:22.390
But now an interesting
problem came up--

00:17:22.390 --> 00:17:24.450
it never moved after that.

00:17:24.450 --> 00:17:26.450
It really got stuck.

00:17:26.450 --> 00:17:29.430
Again, this difference
was pretty evident

00:17:29.430 --> 00:17:32.490
between open and
closed-loop evaluation.

00:17:32.490 --> 00:17:35.640
And unlike the other
two cases, this really

00:17:35.640 --> 00:17:38.360
has to do with the way we
have modeled the problem.

00:17:40.890 --> 00:17:43.310
So we are using a
recurrent neural network

00:17:43.310 --> 00:17:47.540
to actually predict the
successive waypoints.

00:17:47.540 --> 00:17:49.400
But if you consider
the problem of what

00:17:49.400 --> 00:17:51.320
happens when you
want to really move

00:17:51.320 --> 00:17:53.990
the agent from a
standstill, you really

00:17:53.990 --> 00:17:56.450
need to focus on the
first few waypoints

00:17:56.450 --> 00:17:59.640
adding an incremental
amount of motion.

00:17:59.640 --> 00:18:02.150
Now, the RNN, in our
case, doesn't know

00:18:02.150 --> 00:18:04.040
which waypoint it's predicting.

00:18:04.040 --> 00:18:06.830
So the very first
waypoint it predicts

00:18:06.830 --> 00:18:09.740
has a small motion,
which might be subpixel,

00:18:09.740 --> 00:18:13.400
and it doesn't move the
agent forward at all.

00:18:13.400 --> 00:18:17.450
Next time through, it again sees
that the agent is where it was,

00:18:17.450 --> 00:18:20.180
and it again issues
a small motion.

00:18:20.180 --> 00:18:25.350
Compounding that together,
the agent never moves.

00:18:25.350 --> 00:18:27.800
So, in a sense, the
RNN keeps predicting

00:18:27.800 --> 00:18:30.380
less than one pixel
motion, and that's not

00:18:30.380 --> 00:18:31.880
enough to move
the agent forward.

00:18:35.040 --> 00:18:37.680
So a solution to
that, in this case,

00:18:37.680 --> 00:18:41.920
was actually modification
of the network itself.

00:18:41.920 --> 00:18:46.530
We focus on the teal
box that we have added.

00:18:46.530 --> 00:18:48.840
It tells the network
what waypoint

00:18:48.840 --> 00:18:50.910
it's actually predicting.

00:18:50.910 --> 00:18:53.670
So for the first waypoint,
it knows it's the first one.

00:18:53.670 --> 00:18:55.770
And by, let's say,
the fifth waypoint,

00:18:55.770 --> 00:18:59.250
since it knows it's the fifth
waypoint, it can issue a bigger

00:18:59.250 --> 00:19:02.640
motion, irrespective of how
much it has moved along.

00:19:02.640 --> 00:19:04.540
And that gets it unstuck.

00:19:11.440 --> 00:19:13.690
Till now we have looked
at a number of issues

00:19:13.690 --> 00:19:14.620
we saw in the model.

00:19:14.620 --> 00:19:19.240
And, for each of those, we saw a
number of ways to resolve them.

00:19:19.240 --> 00:19:23.520
For orientation bias, we
looked at data augmentation.

00:19:23.520 --> 00:19:27.100
For motion bias related
to the past motion,

00:19:27.100 --> 00:19:29.870
we looked at the input dropout.

00:19:29.870 --> 00:19:33.430
And then, for an issue with
the model architecture itself,

00:19:33.430 --> 00:19:35.470
we had to improve
with the model itself.

00:19:40.060 --> 00:19:41.810
Now that we have
this model, we'll

00:19:41.810 --> 00:19:44.980
call this as an imitation model.

00:19:44.980 --> 00:19:48.000
And that's because we have
used purely supervised data

00:19:48.000 --> 00:19:50.230
to train this network.

00:19:50.230 --> 00:19:52.500
Now let's look at what
happens when we actually

00:19:52.500 --> 00:19:56.040
evaluate this model in a
closed-loop setting in a more

00:19:56.040 --> 00:19:56.880
complex scenario.

00:19:59.980 --> 00:20:03.280
In this video, pay
attention to the gray box,

00:20:03.280 --> 00:20:07.240
which is the agent being
driven by the imitation model.

00:20:07.240 --> 00:20:10.780
As it continues driving, we
find that it drifts and lands

00:20:10.780 --> 00:20:14.320
on top of the yellow line.

00:20:14.320 --> 00:20:17.410
So the agent is not able
to maintain its trajectory,

00:20:17.410 --> 00:20:19.910
and over time it slowly drifts.

00:20:19.910 --> 00:20:22.120
But because there is
no way for the net

00:20:22.120 --> 00:20:24.850
to actually know how to
correct these mistakes,

00:20:24.850 --> 00:20:26.050
it is not able to recover.

00:20:28.640 --> 00:20:31.240
So in this case, we again
need some sort of mechanism

00:20:31.240 --> 00:20:34.130
to teach the net this recovery.

00:20:34.130 --> 00:20:38.350
But it cannot be done simply by
augmenting the data the way we

00:20:38.350 --> 00:20:40.600
did before.

00:20:40.600 --> 00:20:43.330
So consider this
training example.

00:20:43.330 --> 00:20:47.440
Here, the red dot is the
current location of the agent.

00:20:47.440 --> 00:20:50.710
White dots are the past
poses, and green dots

00:20:50.710 --> 00:20:54.760
are the future that we
want the net to predict.

00:20:54.760 --> 00:20:57.940
Now, we take this example,
we shift the position

00:20:57.940 --> 00:21:01.150
of the agent, which is the
red dot, randomly along one

00:21:01.150 --> 00:21:04.630
direction, and we fit
another trajectory

00:21:04.630 --> 00:21:08.140
through the red dot and
the first and last points

00:21:08.140 --> 00:21:11.560
to generate a smooth profile.

00:21:11.560 --> 00:21:13.510
If you look at this
animation here,

00:21:13.510 --> 00:21:16.960
you can see that the profile
of the perturbed image

00:21:16.960 --> 00:21:20.530
is actually a feasible
driving profile.

00:21:20.530 --> 00:21:23.680
And it's really telling
the net that, if you ever

00:21:23.680 --> 00:21:25.870
land up in this
situation, how do

00:21:25.870 --> 00:21:30.850
you actually bring the agent
back to the center of the lane.

00:21:30.850 --> 00:21:33.970
So we can do this with
random amount of shifts

00:21:33.970 --> 00:21:36.190
for all our training and data.

00:21:36.190 --> 00:21:39.940
And given both our original
as well as perturbed examples,

00:21:39.940 --> 00:21:43.450
we can train the net
to basically learn

00:21:43.450 --> 00:21:47.251
from both the original data
as well as the perturbations.

00:21:51.100 --> 00:21:55.870
Here is a test example of
a perturbed example set.

00:21:58.490 --> 00:22:00.410
The second image
shows what happens

00:22:00.410 --> 00:22:02.900
with our original model,
which did not know how

00:22:02.900 --> 00:22:05.210
to recover from perturbation.

00:22:05.210 --> 00:22:08.030
So in this case, you see
that the agent goes off road

00:22:08.030 --> 00:22:10.940
because clearly it has no
idea how to bring it back.

00:22:14.120 --> 00:22:16.220
Now, this is the result
of the model which

00:22:16.220 --> 00:22:18.530
was trained with perturbations.

00:22:18.530 --> 00:22:20.840
So as you can see,
it's not completely

00:22:20.840 --> 00:22:22.970
reflective of the
ground routes, but it

00:22:22.970 --> 00:22:26.240
achieves its goal of actually
bringing the agent back

00:22:26.240 --> 00:22:27.140
to the lane center.

00:22:31.960 --> 00:22:35.070
So now we'll revisit the example
we had before of the agent

00:22:35.070 --> 00:22:38.640
going around the turn
and where it landed

00:22:38.640 --> 00:22:39.840
on top of the yellow marker.

00:22:56.220 --> 00:22:58.770
So, as we saw here,
the agent no longer

00:22:58.770 --> 00:23:00.360
lands on top of
the yellow marker.

00:23:00.360 --> 00:23:03.660
It's able to issue small
correction commands to actually

00:23:03.660 --> 00:23:06.030
keep it well-aligned in
the center of the lane.

00:23:10.860 --> 00:23:12.770
Now we have an imitation
model, and it's

00:23:12.770 --> 00:23:17.600
able to perform lane following,
even over longer scenarios.

00:23:17.600 --> 00:23:21.470
But are we done yet?

00:23:21.470 --> 00:23:22.010
Sort of.

00:23:22.010 --> 00:23:26.120
So we find that it's able to
avoid collisions in most cases,

00:23:26.120 --> 00:23:28.250
but it doesn't have
the generalization

00:23:28.250 --> 00:23:32.386
ability to actually avoid
collisions in new situations.

00:23:35.720 --> 00:23:39.820
So here is an example of an
agent approaching a parking

00:23:39.820 --> 00:23:44.060
area where you'll see a car
pulling out of its spot.

00:23:44.060 --> 00:23:46.210
And as you saw here,
briefly, the agent

00:23:46.210 --> 00:23:48.945
passed right through
the unparking car.

00:23:48.945 --> 00:23:50.320
So the agent has
learned to avoid

00:23:50.320 --> 00:23:53.510
collisions, but clearly
not general enough

00:23:53.510 --> 00:23:55.630
to face these situations.

00:23:55.630 --> 00:23:59.710
And this situation is rare
enough to not be present a lot,

00:23:59.710 --> 00:24:02.750
or even at all, in
our training data.

00:24:02.750 --> 00:24:03.880
So how do we fix this?

00:24:08.300 --> 00:24:10.720
So going back to the
architecture diagram

00:24:10.720 --> 00:24:14.950
of our net, we really want to
teach the net explicitly what

00:24:14.950 --> 00:24:17.967
it is like to avoid collisions.

00:24:22.440 --> 00:24:25.380
So we do this by adding
a loss that explicitly

00:24:25.380 --> 00:24:28.005
measures overlap
of each prediction

00:24:28.005 --> 00:24:29.130
with the rest of the scene.

00:24:32.090 --> 00:24:34.460
So if you focus
on the inset here,

00:24:34.460 --> 00:24:36.140
the yellow box is
the agent which

00:24:36.140 --> 00:24:38.600
is predicted at a
particular time,

00:24:38.600 --> 00:24:41.510
and the blue boxes
are the bounding boxes

00:24:41.510 --> 00:24:46.090
of all the other agents in the
scene know from ground route.

00:24:46.090 --> 00:24:48.360
Now, if you overlay
these boxes together,

00:24:48.360 --> 00:24:51.650
you can get a fair idea as
to whether the agent has

00:24:51.650 --> 00:24:54.300
any overlap with
the other objects.

00:24:54.300 --> 00:24:58.130
And if there is an overlap, that
should drive a loss function

00:24:58.130 --> 00:25:01.250
to actually update
the model rates to not

00:25:01.250 --> 00:25:03.930
perform the action that
generated this overlap.

00:25:07.370 --> 00:25:10.100
We can do a similar
thing to avoid collision

00:25:10.100 --> 00:25:13.850
with road agents like curves
and so on by painting the road

00:25:13.850 --> 00:25:18.650
edge in a view, and then
overlapping it with the agent

00:25:18.650 --> 00:25:19.820
to test this loss.

00:25:22.830 --> 00:25:26.460
Now, this is good in theory,
but, in practice, this does not

00:25:26.460 --> 00:25:28.440
actually solve anything.

00:25:28.440 --> 00:25:31.620
The reason being that our
training data has no collision

00:25:31.620 --> 00:25:32.830
examples.

00:25:32.830 --> 00:25:35.250
Our training data came
from expert driving,

00:25:35.250 --> 00:25:37.050
so there were no collisions.

00:25:37.050 --> 00:25:40.710
And hence, if you look at these
losses, they'll always be zero,

00:25:40.710 --> 00:25:42.255
and would not
update any gradient.

00:25:45.170 --> 00:25:48.310
So, for us, the
only reason it works

00:25:48.310 --> 00:25:51.500
is because of our
perturbed examples.

00:25:51.500 --> 00:25:54.430
So if we look at any of our
synthesized perturbations,

00:25:54.430 --> 00:25:58.810
we have made no attempt to
actually resolve collisions.

00:25:58.810 --> 00:26:00.850
So lots of those
perturbations will actually

00:26:00.850 --> 00:26:03.310
have synthetic collisions,
either with the road

00:26:03.310 --> 00:26:05.080
or with other objects.

00:26:05.080 --> 00:26:07.060
And all of those
synthetic collisions

00:26:07.060 --> 00:26:10.850
will actually have a
non-zero value for this loss.

00:26:10.850 --> 00:26:13.900
So using those
synthesized perturbations,

00:26:13.900 --> 00:26:17.255
we can actually make
the net use these losses

00:26:17.255 --> 00:26:18.130
through our training.

00:26:22.780 --> 00:26:26.180
So let's look at that example
again, of an unparking car,

00:26:26.180 --> 00:26:28.410
but this time after
having trained it

00:26:28.410 --> 00:26:29.490
with the collision loss.

00:26:33.180 --> 00:26:34.830
Once again, the
car is approaching

00:26:34.830 --> 00:26:39.800
that unparking zone, and
it sort of drifts over,

00:26:39.800 --> 00:26:42.680
and nudges around, and avoids
collision with that car.

00:26:49.080 --> 00:26:52.430
OK, so far, we have the net
which can avoid collisions,

00:26:52.430 --> 00:26:56.160
drive smoothly through the
lane boundaries, and so on.

00:26:56.160 --> 00:26:59.070
But we want to do even better.

00:26:59.070 --> 00:27:00.890
Typically, in machine
learning, a way

00:27:00.890 --> 00:27:03.800
to improve generalization
of any models

00:27:03.800 --> 00:27:06.920
is to co-train with other
objectives which might

00:27:06.920 --> 00:27:10.610
be relevant to the main task.

00:27:10.610 --> 00:27:13.310
For the task of
driving, one such task

00:27:13.310 --> 00:27:17.120
is to predict the
future of other agents.

00:27:17.120 --> 00:27:18.950
As we saw in the
architecture diagram

00:27:18.950 --> 00:27:21.030
for our self-driving
software stack,

00:27:21.030 --> 00:27:23.960
behavior prediction is
an important module.

00:27:23.960 --> 00:27:26.900
What if we could predict
the future of other objects

00:27:26.900 --> 00:27:31.490
together with predicting
our own trajectory?

00:27:31.490 --> 00:27:34.970
This is precisely what
we do with the addition

00:27:34.970 --> 00:27:38.910
of another network here
that's shown as Perception

00:27:38.910 --> 00:27:41.630
RNN in this image.

00:27:41.630 --> 00:27:44.930
This is, again, a
recurring neural network.

00:27:44.930 --> 00:27:47.400
But instead of predicting
our own future,

00:27:47.400 --> 00:27:51.440
it predicts the future of all
the other objects in the scene.

00:27:51.440 --> 00:27:54.380
If you pay closer
attention, you can

00:27:54.380 --> 00:27:58.280
see that this particular
output is also

00:27:58.280 --> 00:28:01.400
driven by the same
set target boxes which

00:28:01.400 --> 00:28:03.500
we use for measuring collision.

00:28:03.500 --> 00:28:06.050
So in this sense
using the same labels

00:28:06.050 --> 00:28:11.020
we can drive this
co-trained output as well.

00:28:11.020 --> 00:28:13.880
And because this
particular RNN is

00:28:13.880 --> 00:28:18.110
branched from the same feature
net that we use for Agent RNN,

00:28:18.110 --> 00:28:21.500
it can actually
improve the feature net

00:28:21.500 --> 00:28:25.100
and lead to better performance
for the main task as well.

00:28:28.040 --> 00:28:30.790
So these are two examples
of what the predictions

00:28:30.790 --> 00:28:33.890
from Perception RNN look like.

00:28:33.890 --> 00:28:38.450
So the red and yellow
boxes are the past boxes--

00:28:38.450 --> 00:28:41.940
or the past perception
object, and the green trails

00:28:41.940 --> 00:28:44.950
are the predictions
from this net.

00:28:44.950 --> 00:28:48.130
So it's pretty good in
terms of predicting u-turns,

00:28:48.130 --> 00:28:52.180
as well as figuring out the
intent of other object--

00:28:52.180 --> 00:28:55.543
when, for example, they're
in a right-turn lane,

00:28:55.543 --> 00:28:57.460
whether they're actually
going to make a right

00:28:57.460 --> 00:28:58.950
turn or continue straight.

00:29:04.190 --> 00:29:05.810
Now, we can also
do the same thing

00:29:05.810 --> 00:29:09.620
for the road mask,
which is essentially

00:29:09.620 --> 00:29:14.660
a bitmap of drivable
and non-drivable areas.

00:29:14.660 --> 00:29:17.525
This is not RNN, because
we just want to know,

00:29:17.525 --> 00:29:22.370
in the current map, which area
is drivable and which is not.

00:29:22.370 --> 00:29:24.470
And this is another
co-trained output

00:29:24.470 --> 00:29:27.740
which we use to actually
drive better features

00:29:27.740 --> 00:29:30.440
and then better
performance from agent RNN.

00:29:34.960 --> 00:29:37.780
The final piece of the puzzle
that I'm going to talk about

00:29:37.780 --> 00:29:39.430
is called imitation dropout.

00:29:43.580 --> 00:29:46.110
If you focus on the
losses that we added,

00:29:46.110 --> 00:29:48.410
which are in the
green box here, these

00:29:48.410 --> 00:29:53.510
are all meant to imitate
what exactly the agent did

00:29:53.510 --> 00:29:55.140
in the log data.

00:29:55.140 --> 00:29:58.640
In essence, these are
all imitation losses.

00:29:58.640 --> 00:30:01.090
All the other losses
that you see here

00:30:01.090 --> 00:30:06.350
are meant to just test or
infer how exactly the agent is

00:30:06.350 --> 00:30:08.908
coordinating with the
rest of the environment.

00:30:11.660 --> 00:30:15.080
Now, in order to make the
net generalize better,

00:30:15.080 --> 00:30:17.800
we want to give it some
freedom to explore, even

00:30:17.800 --> 00:30:20.440
when it doesn't want
to imitate whatever

00:30:20.440 --> 00:30:23.050
it was given in the log.

00:30:23.050 --> 00:30:26.990
So to do that, we add
an imitation dropout.

00:30:26.990 --> 00:30:30.730
What that means is that for a
random subset of our training

00:30:30.730 --> 00:30:35.170
examples, we actually remove
these imitation losses,

00:30:35.170 --> 00:30:37.990
and the gradients
are driven entirely

00:30:37.990 --> 00:30:39.265
by the rest of the losses.

00:30:41.810 --> 00:30:43.330
So for those
examples, the net is

00:30:43.330 --> 00:30:45.100
free to explore
whatever alternate

00:30:45.100 --> 00:30:47.420
trajectories it wants to.

00:30:47.420 --> 00:30:50.620
And then the only basis
for them to be correct

00:30:50.620 --> 00:30:53.650
is that they should
interact correctly

00:30:53.650 --> 00:30:55.720
with the rest of the
environment, which

00:30:55.720 --> 00:30:59.690
is driven by the collision
loss, road mask loss, and so on.

00:31:03.730 --> 00:31:07.270
And just empirically, we found
that this particular strategy

00:31:07.270 --> 00:31:10.740
works much better than simply
leaving between the losses.

00:31:15.700 --> 00:31:18.140
Till now, we have looked
at how the model behaves

00:31:18.140 --> 00:31:22.780
and we have shown some example
videos of how we can debug it.

00:31:22.780 --> 00:31:25.600
But for a complex
model like this,

00:31:25.600 --> 00:31:28.240
we would typically
want a better strategy,

00:31:28.240 --> 00:31:32.230
and ablation experiments
is one such strategy

00:31:32.230 --> 00:31:35.950
to confirm what the model
has actually learned.

00:31:38.870 --> 00:31:41.530
So here is a scenario
where we have drawn a stop

00:31:41.530 --> 00:31:43.630
sign with a red block.

00:31:43.630 --> 00:31:45.670
We have taken this
same scenario,

00:31:45.670 --> 00:31:48.940
and we have removed the stop
sign during the rendering stage

00:31:48.940 --> 00:31:51.640
to generate the
scenario on the right.

00:31:51.640 --> 00:31:55.420
Now we'll take both
scenarios and run our net

00:31:55.420 --> 00:31:57.200
on both of them.

00:31:57.200 --> 00:32:00.385
And if it's actually learned
the meaning of a stop sign,

00:32:00.385 --> 00:32:02.260
it should behave
differently between the two.

00:32:06.520 --> 00:32:09.860
So we can see, in the
video on the left,

00:32:09.860 --> 00:32:14.490
the agent comes to a full
stop behind the stop sign,

00:32:14.490 --> 00:32:17.820
and then continues
after a short wait.

00:32:17.820 --> 00:32:19.840
If you look at the
video on the right,

00:32:19.840 --> 00:32:22.230
you can see that, in the
absence of the stop sign,

00:32:22.230 --> 00:32:25.740
it merely slows down in
anticipation of the turn

00:32:25.740 --> 00:32:27.180
and then continues.

00:32:32.090 --> 00:32:34.220
We can perform the
same experiment

00:32:34.220 --> 00:32:36.050
with vehicles in the scene.

00:32:36.050 --> 00:32:40.110
On the left is this scenario
with all the original vehicles,

00:32:40.110 --> 00:32:43.610
which are shown by
these yellow boxes.

00:32:43.610 --> 00:32:46.430
On the right, we have
removed these yellow boxes

00:32:46.430 --> 00:32:48.380
to simulate the
absence of any traffic.

00:32:51.680 --> 00:32:55.680
Once again, if we focus on these
videos one by one, on the left,

00:32:55.680 --> 00:32:59.450
the car sees these stopped
cars, it waits behind,

00:32:59.450 --> 00:33:04.130
and it does a
stop-and-go, as expected.

00:33:04.130 --> 00:33:07.760
On the right, in the
absence of any traffic,

00:33:07.760 --> 00:33:10.160
it behaves in a completely
different manner

00:33:10.160 --> 00:33:13.580
because there's no reason for
it to stop for anything, which

00:33:13.580 --> 00:33:16.010
shows that the agent
has really learned what

00:33:16.010 --> 00:33:17.750
we intended for it to learn.

00:33:20.780 --> 00:33:23.340
Now, we can perform the
same test at the model net

00:33:23.340 --> 00:33:25.380
to really figure out
what is the difference

00:33:25.380 --> 00:33:32.130
between the different
models that we have built.

00:33:32.130 --> 00:33:34.470
So here's a scenario
we created where

00:33:34.470 --> 00:33:37.200
we put a parked car in
the middle of the road

00:33:37.200 --> 00:33:39.450
and have our agent approach it.

00:33:39.450 --> 00:33:43.840
We find that our
car starts off well.

00:33:43.840 --> 00:33:45.840
But as soon as it
sees this parked car,

00:33:45.840 --> 00:33:49.840
it slows down, and comes to
a full stop, and gets stuck.

00:33:49.840 --> 00:33:51.990
So this is the result
from our imitation model

00:33:51.990 --> 00:33:54.270
which doesn't have the
other techniques built in.

00:33:57.380 --> 00:33:59.820
Now, if we repeat the same
test for the full model,

00:33:59.820 --> 00:34:04.590
we find that the agent is again
able to nicely nudge around

00:34:04.590 --> 00:34:07.500
the parked car, and
continues to make progress.

00:34:15.590 --> 00:34:17.600
The second scenario
illustrates, again,

00:34:17.600 --> 00:34:20.870
recovery from
trajectory perturbation.

00:34:20.870 --> 00:34:23.750
So we put our agent at
a slight heading offset,

00:34:23.750 --> 00:34:25.880
approaching a tight curve.

00:34:25.880 --> 00:34:28.550
And we find that, on the
left, the imitation model

00:34:28.550 --> 00:34:31.989
once again gets stuck, not
knowing how to recover,

00:34:31.989 --> 00:34:35.090
while the full-weight
model is able to recover

00:34:35.090 --> 00:34:38.540
nicely and continue along
the path of the entire turn.

00:34:44.090 --> 00:34:48.699
The final scenario is that
of a slow-moving vehicle.

00:34:48.699 --> 00:34:52.110
So we put our agent at the
speed limit of the road,

00:34:52.110 --> 00:34:55.900
approaching a car moving
at a much slower speed,

00:34:55.900 --> 00:34:59.100
and we want to see
how it generalizes.

00:34:59.100 --> 00:35:02.820
The imitation model slows
down for the slow-moving car,

00:35:02.820 --> 00:35:07.740
but ultimately it keeps slowing
down until it gets stuck.

00:35:07.740 --> 00:35:09.670
The full model,
on the other hand,

00:35:09.670 --> 00:35:12.540
is able to adjust
its speed, and then

00:35:12.540 --> 00:35:15.780
continues making progress in a
typical cruise control fashion.

00:35:20.340 --> 00:35:23.030
Those were examples of
some of the log data.

00:35:23.030 --> 00:35:26.390
Let's look at some more of
these locked driving examples.

00:35:29.570 --> 00:35:33.760
So this is an example of
approaching traffic lights.

00:35:33.760 --> 00:35:36.220
Once again, if you recall,
the lane center lines

00:35:36.220 --> 00:35:38.230
encode the state
of traffic lights.

00:35:38.230 --> 00:35:43.450
In this case, the traffic
lights turn from orange to red,

00:35:43.450 --> 00:35:46.900
and the cars in front escape
the light, as expected.

00:35:46.900 --> 00:35:49.900
By our agent, instead of
just following behind them,

00:35:49.900 --> 00:35:52.360
it comes to a stop
for the red light,

00:35:52.360 --> 00:35:54.160
and then continues
as it turns green.

00:36:02.920 --> 00:36:06.880
This next example shows stop
sign handling, which all of you

00:36:06.880 --> 00:36:09.760
are familiar with by now.

00:36:09.760 --> 00:36:11.560
But the interesting
part is the car

00:36:11.560 --> 00:36:13.780
is coming out of
a cul-de-sac, it

00:36:13.780 --> 00:36:15.790
sees a number of
parked vehicles,

00:36:15.790 --> 00:36:19.480
it's able to nudge around,
make way for itself,

00:36:19.480 --> 00:36:23.780
and then continues, and
stops for the stop sign.

00:36:23.780 --> 00:36:25.570
So the key point
here is these are

00:36:25.570 --> 00:36:28.810
all scenarios with different
levels of complexities,

00:36:28.810 --> 00:36:31.060
and we can't expect all
of them to be present

00:36:31.060 --> 00:36:32.480
in our training data.

00:36:32.480 --> 00:36:34.090
So we really need
to teach the net

00:36:34.090 --> 00:36:36.130
to generalize to be
able to handle these.

00:36:39.660 --> 00:36:43.870
This final example shows
a stop-and-go situation

00:36:43.870 --> 00:36:45.400
at a traffic light.

00:36:45.400 --> 00:36:49.030
The agent comes behind
a stopped car, stops,

00:36:49.030 --> 00:36:53.110
and as the light turns green,
instead of again stopping just

00:36:53.110 --> 00:36:56.200
like the other car, it
continues very naturally.

00:37:01.490 --> 00:37:04.460
Before we wrap up,
I'd like to showcase

00:37:04.460 --> 00:37:07.340
some of the current
issues with the net.

00:37:07.340 --> 00:37:09.620
The very first issue
that we see has

00:37:09.620 --> 00:37:13.360
to do with the way we have
represented the input.

00:37:13.360 --> 00:37:16.940
So the input is a fixed, 80
by 80 meter representation,

00:37:16.940 --> 00:37:21.590
and that basically removes a
lot of possibilities in terms

00:37:21.590 --> 00:37:24.150
of what the agent can see.

00:37:24.150 --> 00:37:26.030
So in the first
video I'll show here,

00:37:26.030 --> 00:37:29.630
the agent is approaching a
turn on a fast-moving road.

00:37:29.630 --> 00:37:32.570
But because it can't see
the turn soon enough,

00:37:32.570 --> 00:37:34.250
it's not able to
execute that turn.

00:37:41.090 --> 00:37:44.520
So I believe this is
45-miles-per-hour road.

00:37:44.520 --> 00:37:48.570
The yellow box shows what the
car actually did in the log.

00:37:48.570 --> 00:37:56.100
But our agent, being too fast
for the turn, simply gets hit.

00:37:56.100 --> 00:38:00.360
The second example is one
representative example

00:38:00.360 --> 00:38:03.300
of a rare event, for
example, u-turns,

00:38:03.300 --> 00:38:06.960
which are not present frequently
enough in our training data.

00:38:06.960 --> 00:38:09.240
And so we can't expect
the net to actually

00:38:09.240 --> 00:38:14.800
be able to generalize well
to new situations like that.

00:38:14.800 --> 00:38:18.040
So in this case, the agent,
which is the green box,

00:38:18.040 --> 00:38:22.870
will again try to execute the
route, but will fail to do so.

00:38:22.870 --> 00:38:26.240
The yellow box was the box
in the log which correctly

00:38:26.240 --> 00:38:29.540
did this maneuver as expected.

00:38:29.540 --> 00:38:32.230
And finally, lots of highly
interactive situations which

00:38:32.230 --> 00:38:34.870
we encounter every day
during driving, for example,

00:38:34.870 --> 00:38:37.780
during lane changes
and merges, those all

00:38:37.780 --> 00:38:39.940
involve a lot of
social interaction

00:38:39.940 --> 00:38:44.660
for which the net really needs
newer features, for example,

00:38:44.660 --> 00:38:46.690
to be able to use
reinforcement learning,

00:38:46.690 --> 00:38:48.790
or a real simulator
where you can

00:38:48.790 --> 00:38:53.550
simulate these interactions.

00:38:53.550 --> 00:38:58.500
In conclusion, what we talked
about today is essentially

00:38:58.500 --> 00:39:01.180
that, in order to
solve the driving task,

00:39:01.180 --> 00:39:05.520
it's not enough to have
tons of logged driving data,

00:39:05.520 --> 00:39:10.110
and that we really need lots
of task-specific techniques

00:39:10.110 --> 00:39:13.920
to really simplify the problem
and to help the net everywhere

00:39:13.920 --> 00:39:17.580
possible so that it
can generalize across,

00:39:17.580 --> 00:39:20.520
away from what it
has seen in the data.

00:39:20.520 --> 00:39:22.320
For more details
about this work,

00:39:22.320 --> 00:39:26.430
please see our paper as well
as the associated website.

00:39:26.430 --> 00:39:28.150
Thanks for all your interest.

00:39:28.150 --> 00:39:29.190
Thank you.

00:39:29.190 --> 00:39:32.840
[TITLE MUSIC PLAYING]

