WEBVTT
Kind: captions
Language: en

00:00:03.785 --> 00:00:04.910
JOSH GORDON: Hey, everyone.

00:00:04.910 --> 00:00:05.720
Thanks for joining us.

00:00:05.720 --> 00:00:07.428
My name's Josh Gordon,
and I'm very, very

00:00:07.428 --> 00:00:09.400
happy to be here today
with Jeremy Howard, who

00:00:09.400 --> 00:00:11.800
is the co-founder of a
course I'm sure many of you

00:00:11.800 --> 00:00:15.345
have heard of called fast.ai,
and he's faculty at USF.

00:00:15.345 --> 00:00:17.470
So, Jeremy, thank you so
much for joining us today.

00:00:17.470 --> 00:00:18.730
JEREMY HOWARD: Oh,
it's a pleasure.

00:00:18.730 --> 00:00:21.230
JOSH GORDON: And, today, I'd
love to talk about a new course

00:00:21.230 --> 00:00:24.040
that you're working
on for Swift.

00:00:24.040 --> 00:00:25.990
So I am totally new to Swift.

00:00:25.990 --> 00:00:29.380
So could you tell me a little
bit maybe first about fast.ai

00:00:29.380 --> 00:00:31.090
in general, and then
maybe a little bit

00:00:31.090 --> 00:00:32.530
about your plans for Swift?

00:00:32.530 --> 00:00:34.120
JEREMY HOWARD: Yeah, absolutely.

00:00:34.120 --> 00:00:42.310
So fast.ai, as you know,
is a self-funded nonprofit.

00:00:42.310 --> 00:00:43.340
We do a few things.

00:00:43.340 --> 00:00:47.860
We do research, we do teaching,
we do software development,

00:00:47.860 --> 00:00:49.270
and we do community development.

00:00:49.270 --> 00:00:52.030
So the research we
do is all about how

00:00:52.030 --> 00:00:55.030
do we make world class
deep learning more

00:00:55.030 --> 00:00:56.500
accessible to regular people.

00:00:56.500 --> 00:00:59.080
So we do lots of algorithm
development and testing

00:00:59.080 --> 00:01:00.660
and curation.

00:01:00.660 --> 00:01:02.950
That research ends
up in courses that we

00:01:02.950 --> 00:01:05.287
provide online through fast.ai.

00:01:05.287 --> 00:01:07.120
There are a couple of
main ones people know.

00:01:07.120 --> 00:01:08.950
One is Practical Deep
Learning for Coders,

00:01:08.950 --> 00:01:11.230
which is taking that research
and saying, how can that

00:01:11.230 --> 00:01:14.620
be used to make somebody with
a year of coding background,

00:01:14.620 --> 00:01:16.090
but no particular
math background,

00:01:16.090 --> 00:01:18.590
into an effective deep
learning practitioner.

00:01:18.590 --> 00:01:21.500
And then there's a
more advanced course,

00:01:21.500 --> 00:01:24.400
which is about research
level deep learning.

00:01:24.400 --> 00:01:26.800
And then we have our
community online, which

00:01:26.800 --> 00:01:28.957
we're super excited about.

00:01:28.957 --> 00:01:31.040
But then there's a really
interesting thing we do,

00:01:31.040 --> 00:01:34.190
which is to help all
that stuff become easier,

00:01:34.190 --> 00:01:35.680
we have a software
library called

00:01:35.680 --> 00:01:40.087
fast.ai, which currently sits
on top of PyTorch and Python.

00:01:43.290 --> 00:01:47.450
But we're very interested by
what Chris Lattner and his team

00:01:47.450 --> 00:01:51.400
are doing with Swift now
and Swift for TensorFlow.

00:01:51.400 --> 00:01:53.990
We think there are big
opportunities to help all four

00:01:53.990 --> 00:01:59.060
of those areas by embracing
Swift for TensorFlow

00:01:59.060 --> 00:02:01.710
as well as PyTorch and Python.

00:02:01.710 --> 00:02:04.130
JOSH GORDON: OK, so moving on
to Swift, so traditionally,

00:02:04.130 --> 00:02:05.540
almost all of machine
learning development

00:02:05.540 --> 00:02:07.310
is done in Python, and
of course languages

00:02:07.310 --> 00:02:08.870
like R and now JavaScript.

00:02:08.870 --> 00:02:09.412
So why Swift?

00:02:09.412 --> 00:02:11.078
Could you tell me a
little bit about it?

00:02:11.078 --> 00:02:12.170
JEREMY HOWARD: Sure.

00:02:12.170 --> 00:02:15.110
So I'm a real programming
language nerd.

00:02:15.110 --> 00:02:17.450
I like studying
programming languages,

00:02:17.450 --> 00:02:19.790
and I've been involved in
lots of different programming

00:02:19.790 --> 00:02:20.540
languages.

00:02:20.540 --> 00:02:22.910
I actually was the chair
of the working group that

00:02:22.910 --> 00:02:24.860
tried to bring
scientific programming

00:02:24.860 --> 00:02:29.750
capabilities to Perl 6 back
in the late '90s, early 2000s.

00:02:29.750 --> 00:02:32.090
And my programming
language nerdship

00:02:32.090 --> 00:02:36.920
is driven by a deep discontent
with any programming language

00:02:36.920 --> 00:02:39.200
when it comes to
numerical programming.

00:02:39.200 --> 00:02:43.250
I did a lot of work in C++ in
the early 2000s and got really

00:02:43.250 --> 00:02:45.860
turned off by the long compile
times and the complexity

00:02:45.860 --> 00:02:49.370
of expression templates.

00:02:49.370 --> 00:02:54.320
I quite like C# and F#,
but there's always been--

00:02:54.320 --> 00:02:56.660
cross platform took
a long time to come,

00:02:56.660 --> 00:03:00.050
and then cross platform has
come with some performance

00:03:00.050 --> 00:03:01.470
regressions in some way.

00:03:01.470 --> 00:03:05.180
So I've always been looking
for a really good programming

00:03:05.180 --> 00:03:09.500
language for
numerical computing.

00:03:09.500 --> 00:03:11.150
Python isn't that language.

00:03:11.150 --> 00:03:13.670
Python is a great glue
language to sit on top of other

00:03:13.670 --> 00:03:17.000
languages, so like
NumPy is basically C.

00:03:17.000 --> 00:03:20.720
And TensorFlow Python
is just wrapping up C++,

00:03:20.720 --> 00:03:24.650
which sits on top of Cuda C
libraries and Icon and the C++

00:03:24.650 --> 00:03:25.250
library.

00:03:25.250 --> 00:03:28.202
And, in the end, it's
dissatisfying for a student

00:03:28.202 --> 00:03:29.910
and for a teacher,
because at some point,

00:03:29.910 --> 00:03:32.740
I have to say, this is the point
at which we can stop finding

00:03:32.740 --> 00:03:34.490
out what's going on,
because beneath here,

00:03:34.490 --> 00:03:36.530
it's kind of assembly
code, or machine code,

00:03:36.530 --> 00:03:38.120
or compiled stuff.

00:03:38.120 --> 00:03:40.670
It's very frustrating,
as a researcher,

00:03:40.670 --> 00:03:42.680
like an NLP, where
you keep on wanting

00:03:42.680 --> 00:03:44.412
to do more stuff with RNNs.

00:03:44.412 --> 00:03:46.620
And we keep on hitting the
point where it's like, oh,

00:03:46.620 --> 00:03:49.520
we can't really implement
this different RNN cell,

00:03:49.520 --> 00:03:52.430
because if we do, then it's
not going to use cuDNN anymore,

00:03:52.430 --> 00:03:54.890
and the performance is
going to fall apart.

00:03:54.890 --> 00:03:59.280
Swift offers a
way past all this.

00:03:59.280 --> 00:04:02.960
It lets us write on
a language that's

00:04:02.960 --> 00:04:06.410
a thin layer over the amazing
LLVM infrastructure, compiler

00:04:06.410 --> 00:04:09.950
infrastructure,
which can get lots

00:04:09.950 --> 00:04:12.530
of different bits of an
algorithm pulled together,

00:04:12.530 --> 00:04:17.690
optimize the whole thing,
for CPU and for GPU.

00:04:17.690 --> 00:04:19.820
And, at the same
time, because it

00:04:19.820 --> 00:04:22.320
has the view of everything
going on from top to bottom,

00:04:22.320 --> 00:04:25.070
it can tell me all the
times I've screwed up.

00:04:25.070 --> 00:04:28.323
So, hey, you thought that
this dimension was batch size,

00:04:28.323 --> 00:04:30.740
but over here, you use this
other dimension as batch size,

00:04:30.740 --> 00:04:34.130
and I tried to multiply
those two tensors.

00:04:34.130 --> 00:04:36.183
At compile time, I
could tell the shapes

00:04:36.183 --> 00:04:37.100
aren't going to match.

00:04:37.100 --> 00:04:37.610
JOSH GORDON: It's huge.

00:04:37.610 --> 00:04:38.443
JEREMY HOWARD: Yeah.

00:04:38.443 --> 00:04:40.520
So I'm very excited
to learn how it's

00:04:40.520 --> 00:04:44.010
going to make me more
productive as a programmer.

00:04:44.010 --> 00:04:47.090
It's going to allow me to turn
my research ideas into code.

00:04:47.090 --> 00:04:49.370
At the moment, I keep
butting up against things

00:04:49.370 --> 00:04:52.490
where I just can't do it.

00:04:52.490 --> 00:04:55.880
And it's going to
let us teach things

00:04:55.880 --> 00:04:58.030
deeper, which is what
I'm always trying to do.

00:04:58.030 --> 00:04:58.822
JOSH GORDON: Right.

00:04:58.822 --> 00:05:01.370
So how does this
relate to fast.ai?

00:05:01.370 --> 00:05:04.262
JEREMY HOWARD: So then,
the next course, which

00:05:04.262 --> 00:05:05.720
is going to be in
a couple of weeks

00:05:05.720 --> 00:05:07.370
at the University
of San Francisco,

00:05:07.370 --> 00:05:09.680
we'll be recording it, and
then that recording will

00:05:09.680 --> 00:05:13.220
become our next MOOC in June.

00:05:13.220 --> 00:05:15.050
It's going to be a
seven part course.

00:05:15.050 --> 00:05:17.930
It's going to be called
Deeper Deep Learning.

00:05:17.930 --> 00:05:20.060
And Deeper Deep
Learning is going

00:05:20.060 --> 00:05:25.880
to be all about how do we
take a practical practitioner

00:05:25.880 --> 00:05:28.580
of deep learning and turn
them into somebody who

00:05:28.580 --> 00:05:32.840
can go further, like do
cutting edge research,

00:05:32.840 --> 00:05:35.970
get things into production,
make things run fast.

00:05:35.970 --> 00:05:38.070
So of the seven lessons
in the next course,

00:05:38.070 --> 00:05:41.368
the last two are going to be
about Swift for TensorFlow.

00:05:41.368 --> 00:05:43.660
And it's going to be really
cool, because actually, I'm

00:05:43.660 --> 00:05:46.040
going to be co-teaching
it with Chris Lattner.

00:05:46.040 --> 00:05:47.998
JOSH GORDON: And so for
people that don't know,

00:05:47.998 --> 00:05:49.940
so Chris Lattner is
the inventor of Swift.

00:05:49.940 --> 00:05:51.482
JEREMY HOWARD: The
inventor of Swift.

00:05:51.482 --> 00:05:54.833
So, for me, I'm kind of having
a little flashy moment now,

00:05:54.833 --> 00:05:56.250
where I'm like,
oh my god, I can't

00:05:56.250 --> 00:05:58.500
believe I'll be standing next
to Chris Lattner, the Chris

00:05:58.500 --> 00:05:59.000
Lattner.

00:05:59.000 --> 00:06:00.690
So I'm very excited about that.

00:06:00.690 --> 00:06:02.120
And I'm very excited
about what it

00:06:02.120 --> 00:06:04.880
means in terms of
what we can say

00:06:04.880 --> 00:06:07.820
to these students
who are at the very

00:06:07.820 --> 00:06:09.710
advanced level at this point.

00:06:09.710 --> 00:06:11.930
They've done 100
plus hours of study,

00:06:11.930 --> 00:06:13.610
and they're competent coders.

00:06:13.610 --> 00:06:17.648
And we will be
able to say, here's

00:06:17.648 --> 00:06:21.650
a deeply well-designed,
thoughtful, fast, brilliant

00:06:21.650 --> 00:06:25.400
language, which has had very,
very little numerical computing

00:06:25.400 --> 00:06:29.360
so far, but has the might now
of Google, and Chris Lattner,

00:06:29.360 --> 00:06:32.030
and a brilliant team behind it.

00:06:32.030 --> 00:06:33.320
The world's your oyster.

00:06:33.320 --> 00:06:35.000
Almost nothing's
been implemented.

00:06:35.000 --> 00:06:39.440
So the class projects are
going to be things like, create

00:06:39.440 --> 00:06:42.750
this layer that hasn't
been implemented yet,

00:06:42.750 --> 00:06:45.590
or implement this
architecture, or be

00:06:45.590 --> 00:06:49.620
the first person that's run this
model end to end on ImageNet.

00:06:49.620 --> 00:06:51.680
So the class projects--
and there'll also

00:06:51.680 --> 00:06:58.610
be things like, help us create
the fast.ai library for Swift

00:06:58.610 --> 00:06:59.472
for TensorFlow.

00:06:59.472 --> 00:07:00.180
JOSH GORDON: Yes.

00:07:00.180 --> 00:07:03.455
JEREMY HOWARD: So I can tell you
the fast.ai library for Swift

00:07:03.455 --> 00:07:05.365
for TensorFlow even
has a code name now.

00:07:05.365 --> 00:07:06.240
JOSH GORDON: Awesome.

00:07:06.240 --> 00:07:08.113
JEREMY HOWARD: The
code name is harebrain.

00:07:08.113 --> 00:07:08.780
JOSH GORDON: OK.

00:07:08.780 --> 00:07:10.947
JEREMY HOWARD: Harebrain,
because it's a crazy idea.

00:07:10.947 --> 00:07:12.570
It's this amazingly
crazy idea, which

00:07:12.570 --> 00:07:16.860
is, we can take something
that's so early,

00:07:16.860 --> 00:07:18.660
but it's going to
be such potential,

00:07:18.660 --> 00:07:22.287
and actually start writing the
dev UX layer from the start.

00:07:22.287 --> 00:07:23.370
JOSH GORDON: You're right.

00:07:23.370 --> 00:07:23.750
So this is all new territory.

00:07:23.750 --> 00:07:24.495
JEREMY HOWARD: So
it's this crazy idea.

00:07:24.495 --> 00:07:25.920
It's super exciting.

00:07:25.920 --> 00:07:28.050
But also hare, because
hares are fast.

00:07:28.050 --> 00:07:30.073
And Swift's fast, and
fast.ai is fast, right.

00:07:30.073 --> 00:07:31.240
JOSH GORDON: It sounds cool.

00:07:31.240 --> 00:07:33.407
JEREMY HOWARD: And then
brain, because we're working

00:07:33.407 --> 00:07:34.540
with Google Brain on this.

00:07:34.540 --> 00:07:37.110
So that's going to be our little
internal code name for this.

00:07:37.110 --> 00:07:40.160
So anybody who's getting
involved in the next course,

00:07:40.160 --> 00:07:42.510
through the MOOC or in
person, can actually

00:07:42.510 --> 00:07:46.680
help contribute to this
codename harebrain library

00:07:46.680 --> 00:07:48.030
from the very earliest days.

00:07:48.030 --> 00:07:50.395
And so for a language nerd
like me, it's so exciting.

00:07:50.395 --> 00:07:51.270
JOSH GORDON: Awesome.

00:07:51.270 --> 00:07:52.687
And what's the
best way for people

00:07:52.687 --> 00:07:55.330
to find out about the new course
and follow it, keep updated,

00:07:55.330 --> 00:07:56.202
sign up?

00:07:56.202 --> 00:07:57.660
JEREMY HOWARD:
Yeah, so if you want

00:07:57.660 --> 00:08:01.210
to sign up for the in-person
course, do it right now.

00:08:01.210 --> 00:08:05.342
So just go to the University of
San Francisco Data Institute.

00:08:05.342 --> 00:08:07.800
But that's in San Francisco,
so, obviously, a lot of people

00:08:07.800 --> 00:08:09.420
won't be able to
make it in person.

00:08:09.420 --> 00:08:13.440
Otherwise, keep an eye
on fast.ai in June,

00:08:13.440 --> 00:08:17.790
where we'll be launching
that course as a MOOC.

00:08:17.790 --> 00:08:21.567
And yeah, at that
point, it's still

00:08:21.567 --> 00:08:23.400
going to be super early
days for everything.

00:08:23.400 --> 00:08:24.930
So there'll be lots
of opportunities

00:08:24.930 --> 00:08:28.080
for people to
become part of what

00:08:28.080 --> 00:08:31.410
I think is going to
be a very, very, very

00:08:31.410 --> 00:08:34.728
impactful project for
scientific programming,

00:08:34.728 --> 00:08:37.020
and for deep learning, and
for differentiable computing

00:08:37.020 --> 00:08:39.630
more generally, being
Swift for TensorFlow.

00:08:39.630 --> 00:08:41.637
JOSH GORDON: I'm really
looking forward to it.

00:08:41.637 --> 00:08:43.220
I have one last
question for you, too.

00:08:43.220 --> 00:08:43.710
JEREMY HOWARD: OK, hit me.

00:08:43.710 --> 00:08:45.335
JOSH GORDON: So will
Swift be primarily

00:08:45.335 --> 00:08:47.110
for researchers, novices?

00:08:47.110 --> 00:08:49.110
Long-term, how do you see
the evolution of Swift

00:08:49.110 --> 00:08:49.860
for deep learning?

00:08:49.860 --> 00:08:52.630
JEREMY HOWARD: Because
it's so versatile,

00:08:52.630 --> 00:08:55.650
I plan to do a lot of
research in Swift myself,

00:08:55.650 --> 00:08:59.520
to get past that boundary
I described of places where

00:08:59.520 --> 00:09:03.840
you can't go with
Python as a researcher.

00:09:03.840 --> 00:09:07.120
I also expect it to be
great in production,

00:09:07.120 --> 00:09:09.930
because it's going to allow
you to take the stuff that you

00:09:09.930 --> 00:09:13.920
wrote at prototyping time
and have something that's

00:09:13.920 --> 00:09:17.250
super fast straight away,
particularly because, for most

00:09:17.250 --> 00:09:18.030
people--

00:09:18.030 --> 00:09:20.820
maybe not most Googlers,
but most normal people--

00:09:20.820 --> 00:09:24.660
production inference
means CPU, not GPU.

00:09:24.660 --> 00:09:27.630
And Swift will be a really
great option for that

00:09:27.630 --> 00:09:30.630
because we're going to
get all that compilation

00:09:30.630 --> 00:09:33.985
niceness of LLVM to make
that CPU code super fast.

00:09:33.985 --> 00:09:34.860
JOSH GORDON: Awesome.

00:09:34.860 --> 00:09:36.600
So thank you so
much for joining us.

00:09:36.600 --> 00:09:37.830
And thank you, everyone.

00:09:37.830 --> 00:09:39.180
I learned a lot from
this talk, and I'm really

00:09:39.180 --> 00:09:40.260
looking forward to your course.

00:09:40.260 --> 00:09:40.725
JEREMY HOWARD: Cheers.

00:09:40.725 --> 00:09:41.392
JOSH GORDON: OK.

00:09:41.392 --> 00:09:42.450
Thanks very much.

00:09:42.450 --> 00:09:46.400
[MUSIC PLAYING]

