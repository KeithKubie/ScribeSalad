WEBVTT
Kind: captions
Language: en

00:00:07.840 --> 00:00:09.870
&gt;&gt; I think most of us would give the same answer.

00:00:09.870 --> 00:00:13.680
The pitcher, not the backpack or the car or this box. Now for humans, for

00:00:13.680 --> 00:00:15.760
you and me, this is a little bit of an easy problem.

00:00:15.760 --> 00:00:19.230
All of us get it right pretty much all the time. And what about a machine?

00:00:19.230 --> 00:00:24.200
What about a robot? How would a robot decide that a pitcher is a good utensil to

00:00:24.200 --> 00:00:27.200
use for transporting soup from the kitchen to the dining table, but

00:00:27.200 --> 00:00:32.540
not a backpack and not a box? For a robot, this is a surprisingly hard problem.

00:00:32.540 --> 00:00:36.280
So the question then becomes, well, what is it that makes it easy for humans and

00:00:36.280 --> 00:00:40.480
hard for robots? How can we program AI agents so that it would be easy for

00:00:40.480 --> 00:00:45.250
them as well? One important thing to note here, this is another example of

00:00:45.250 --> 00:00:49.130
incremental learning. Now we have come across incremental learning earlier,

00:00:49.130 --> 00:00:51.870
when we were talking about incremental concept learning.

00:00:51.870 --> 00:00:56.580
There we were given one example at a time, that was the example of art, and

00:00:56.580 --> 00:01:01.010
we were learning one concept, the concept of art. This is in contrast to other

00:01:01.010 --> 00:01:05.269
methods of machine learning. Where one is given a, large amount of data, and

00:01:05.269 --> 00:01:09.280
one has to detect patterns with a variety in that data. Here,

00:01:09.280 --> 00:01:14.040
there is learning occurring one step at a time, from a small number of examples,

00:01:14.040 --> 00:01:17.720
one single concept has been learned. We also came across the notion of

00:01:17.720 --> 00:01:21.320
incremental learning, when we were talking about chunking. Day two,

00:01:21.320 --> 00:01:25.679
there was one particular problem, and from a small number of previous episodes,

00:01:25.679 --> 00:01:30.430
we chunked a particular rule. This notion of incremental learning, for

00:01:30.430 --> 00:01:35.336
me it's much of knowledge based AI. Another thing to note here, this notion or

00:01:35.336 --> 00:01:38.980
expression based learning is related to creativity.

00:01:38.980 --> 00:01:42.886
We talked earlier about the relationship between creativity and novelty.

00:01:42.886 --> 00:01:47.350
Here is an example in which an AI agent is dealing with a novel situation.

00:01:47.350 --> 00:01:49.930
Usual utensils for taking soup from the kitchen to

00:01:49.930 --> 00:01:53.080
the dining table are not available. What should the robot do?

00:01:53.080 --> 00:01:57.650
The robot comes up with a creative solution of taking the pitcher as the utensil

