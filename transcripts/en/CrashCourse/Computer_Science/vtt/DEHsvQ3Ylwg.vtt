WEBVTT
Kind: captions
Language: en

00:00:03.020 --> 00:00:05.819
Hi, I’m Carrie Anne, and welcome to Crash
Course Computer Science!

00:00:05.819 --> 00:00:10.200
So, over the course of this series, we’ve
focused almost exclusively on computers – the

00:00:10.200 --> 00:00:12.549
circuits and algorithms that make them tick.

00:00:12.549 --> 00:00:15.190
Because...this is Crash Course Computer Science.

00:00:15.190 --> 00:00:17.790
But ultimately, computers are tools employed
by people.

00:00:17.790 --> 00:00:19.810
And humans are… well… messy.

00:00:19.810 --> 00:00:23.650
We haven’t been designed by human engineers
from the ground up with known performance

00:00:23.650 --> 00:00:24.760
specifications.

00:00:24.760 --> 00:00:27.620
We can be logical one moment and irrational
the next.

00:00:27.620 --> 00:00:31.460
Have you ever gotten angry at your navigation
system? Surfed wikipedia aimlessly?

00:00:31.460 --> 00:00:34.140
Begged your internet browser to load faster?

00:00:34.140 --> 00:00:35.790
Nicknamed your roomba?

00:00:35.790 --> 00:00:37.949
These behaviors are quintessentially human!

00:00:37.949 --> 00:00:42.179
To build computer systems that are useful,
usable and enjoyable, we need to understand

00:00:42.179 --> 00:00:45.489
the strengths and weaknesses of both computers
and humans.

00:00:45.489 --> 00:00:50.260
And for this reason, when good system designers
are creating software, they employ social,

00:00:50.260 --> 00:00:53.680
cognitive, behavioral, and perceptual psychology
principles.

00:00:53.680 --> 00:01:02.700
INTRO

00:01:02.700 --> 00:01:06.480
No doubt you’ve encountered a physical or
computer interface that was frustrating to

00:01:06.480 --> 00:01:08.570
use, impeding your progress.

00:01:08.570 --> 00:01:12.170
Maybe it was so badly designed that you couldn’t
figure it out and just gave up.

00:01:12.170 --> 00:01:14.410
That interface had poor usability.

00:01:14.410 --> 00:01:18.360
Usability is the degree to which a human-made
artifact – like software – can be used

00:01:18.360 --> 00:01:21.500
to achieve an objective effectively and efficiently.

00:01:21.500 --> 00:01:26.450
To facilitate human work, we need to understand
humans - from how they see and think, to how

00:01:26.450 --> 00:01:27.800
they react and interact.

00:01:27.800 --> 00:01:31.480
For instance, the human visual system has
been well studied by Psychologists.

00:01:31.480 --> 00:01:34.560
Like, we know that people are good at ordering
intensities of colors.

00:01:34.560 --> 00:01:35.560
Here are three.

00:01:35.560 --> 00:01:38.040
Can you arrange these from lightest to darkest?

00:01:38.040 --> 00:01:40.510
You probably don’t have to think too much
about it.

00:01:40.510 --> 00:01:44.260
Because of this innate ability, color intensity
is a great choice for displaying data with

00:01:44.260 --> 00:01:45.500
continuous values.

00:01:45.500 --> 00:01:48.570
On the other hand, humans are terrible at
ordering colors.

00:01:48.570 --> 00:01:53.230
Here’s another example for you to put in
order… is orange before blue, or after blue?

00:01:53.230 --> 00:01:54.250
Where does green go?

00:01:54.250 --> 00:01:57.850
You might be thinking we could order this
by wavelength of light, like a rainbow, but

00:01:57.850 --> 00:01:59.820
that’s a lot more to think about.

00:01:59.820 --> 00:02:03.170
Most people are going to be much slower and
error-prone at ordering.

00:02:03.170 --> 00:02:06.880
Because of this innate ineptitude of your
visual system, displaying continuous data

00:02:06.880 --> 00:02:09.819
using colors can be a disastrous design choice.

00:02:09.819 --> 00:02:14.060
You’ll find yourself constantly referring
back to a color legend to compare items.

00:02:14.060 --> 00:02:18.489
However, colors are perfect for when the data
is discrete with no ordering, like categorical

00:02:18.489 --> 00:02:19.320
data.

00:02:19.320 --> 00:02:23.200
This might seem obvious, but you’d be amazed
at how many interfaces get basic things like

00:02:23.200 --> 00:02:23.880
this wrong.

00:02:23.880 --> 00:02:28.360
Beyond visual perception, understanding human
cognition helps us design interfaces that

00:02:28.360 --> 00:02:30.260
align with how the mind works.

00:02:30.260 --> 00:02:35.200
Like, humans can read, remember and process
information more effectively when it’s chunked

00:02:35.200 --> 00:02:38.760
– that is, when items are put together into
small, meaningful groups.

00:02:38.760 --> 00:02:43.080
Humans can generally juggle seven items, plus-or-minus
two, in short-term memory.

00:02:43.080 --> 00:02:46.079
To be conservative, we typically see groupings
of five or less.

00:02:46.080 --> 00:02:51.760
That’s why telephone numbers are broken
into chunks, like 317, 555, 3897.

00:02:51.760 --> 00:02:55.760
Instead of being ten individual digits that
we’d likely forget, it’s three chunks,

00:02:55.769 --> 00:02:56.870
which we can handle better.

00:02:56.870 --> 00:03:00.920
From a computer's standpoint, this needlessly
takes more time and space, so it’s less

00:03:00.920 --> 00:03:01.920
efficient.

00:03:01.920 --> 00:03:06.569
But, it’s way more efficient for us humans
– a tradeoff we almost always make in our

00:03:06.569 --> 00:03:09.109
favor, since we’re the ones running the
show...for now.

00:03:09.109 --> 00:03:12.950
Chunking has been applied to computer interfaces
for things like drop-down menu items and menu

00:03:12.950 --> 00:03:14.029
bars with buttons.

00:03:14.029 --> 00:03:18.069
It’d be more efficient for computers to
just pack all those together, edge to edge

00:03:18.069 --> 00:03:20.569
– it’s wasted memory and screen real estate.

00:03:20.569 --> 00:03:24.480
But designing interfaces in this way makes
them much easier to visually scan, remember

00:03:24.480 --> 00:03:25.420
and access.

00:03:25.420 --> 00:03:29.580
Another central concept used in interface
design is affordances.

00:03:29.600 --> 00:03:33.689
According to Don Norman, who popularized the
term in computing, “affordances provide

00:03:33.689 --> 00:03:36.640
strong clues to the operations of things.

00:03:36.640 --> 00:03:37.840
Plates are for pushing.

00:03:37.840 --> 00:03:39.240
Knobs are for turning.

00:03:39.249 --> 00:03:41.409
Slots are for inserting things into.

00:03:41.409 --> 00:03:45.940
[...] When affordances are taken advantage
of, the user knows what to do just by looking:

00:03:45.940 --> 00:03:48.450
no picture, label, or instruction needed.”

00:03:48.450 --> 00:03:52.389
If you’ve ever tried to pull a door handle,
only to realize that you have to push it open,

00:03:52.389 --> 00:03:54.319
you’ve discovered a broken affordance.

00:03:54.319 --> 00:03:57.680
On the other hand, a door plate is a better
design because it only gives you the option

00:03:57.680 --> 00:03:58.440
to push.

00:03:58.440 --> 00:04:01.980
Doors are pretty straightforward – if you
need to put written instructions on them,

00:04:01.980 --> 00:04:04.540
you should probably go back to the drawing
board.

00:04:04.549 --> 00:04:08.189
Affordances are used extensively in graphical
user interfaces, which we discussed in episode

00:04:08.189 --> 00:04:09.189
26.

00:04:09.189 --> 00:04:13.670
It’s one of the reasons why computers became
so much easier to use than with command lines.

00:04:13.670 --> 00:04:18.019
You don’t have to guess what things on-screen
are clickable, because they look like buttons.

00:04:18.020 --> 00:04:20.200
They pop out, just waiting for you to press
them!

00:04:20.200 --> 00:04:24.900
One of my favorite affordances, which suggests
to users that an on-screen element is draggable,

00:04:24.910 --> 00:04:29.280
is knurling – that texture added to objects
to improve grip and show you where to best

00:04:29.290 --> 00:04:30.290
grab them.

00:04:30.290 --> 00:04:33.280
This idea and pattern was borrowed from real
world physical tools.

00:04:33.280 --> 00:04:38.090
Related to the concept of affordances is the
psychology of recognition vs recall.

00:04:38.090 --> 00:04:42.169
You know this effect well from tests – it’s
why multiple choice questions are easier than

00:04:42.169 --> 00:04:43.460
fill-in-the-blank ones.

00:04:43.460 --> 00:04:47.530
In general, human memory is much better when
it’s triggered by a sensory cue, like a

00:04:47.530 --> 00:04:48.780
word, picture or sound.

00:04:48.780 --> 00:04:53.349
That’s why interfaces use icons – pictorial
representations of functions – like a trash

00:04:53.349 --> 00:04:55.600
can for where files go to be deleted.

00:04:55.600 --> 00:04:59.720
We don’t have to recall what that icon does,
we just have to recognise the icon.

00:04:59.720 --> 00:05:03.560
This was also a huge improvement over command
line interfaces, where you had to rely on

00:05:03.560 --> 00:05:05.800
your memory for what commands to use.

00:05:05.800 --> 00:05:10.660
Do I have to type “delete”, or “remove”,
or... “trash”, or… shoot, it could be anything!

00:05:10.660 --> 00:05:14.420
It’s actually “rm” in linux, but anyway,
making everything easy to discover and learn

00:05:14.420 --> 00:05:19.590
sometimes means slow to access, which conflicts
with another psychology concept: expertise.

00:05:19.590 --> 00:05:23.700
As you gain experience with interfaces, you
get faster, building mental models of how

00:05:23.700 --> 00:05:25.140
to do things efficiently.

00:05:25.140 --> 00:05:28.620
So, good interfaces should offer multiple
paths to accomplish goals.

00:05:28.639 --> 00:05:32.570
A great example of this is copy and paste,
which can be found in the edit dropdown menu

00:05:32.570 --> 00:05:36.569
of word processors, and is also triggered
with keyboard shortcuts.

00:05:36.569 --> 00:05:41.080
One approach caters to novices, while the
other caters to experts, slowing down neither.

00:05:41.080 --> 00:05:43.820
So, you can have your cake and eat it too!

00:05:43.820 --> 00:05:47.870
In addition to making humans more efficient,
we’d also like computers to be emotionally

00:05:47.870 --> 00:05:52.151
intelligent – adapting their behavior to
respond appropriately to their users’ emotional

00:05:52.151 --> 00:05:54.610
state – also called affect.

00:05:54.610 --> 00:05:58.419
That could make experiences more empathetic,
enjoyable, or even delightful.

00:05:58.419 --> 00:06:03.639
This vision was articulated by Rosalind Picard
in her 1995 paper on Affective Computing,

00:06:03.639 --> 00:06:08.300
which kickstarted an interdisciplinary field
combining aspects of psychology, social and

00:06:08.300 --> 00:06:09.300
computer sciences.

00:06:09.300 --> 00:06:13.789
It spurred work on computing systems that
could recognize, interpret, simulate and alter

00:06:13.789 --> 00:06:14.939
human affect.

00:06:14.939 --> 00:06:19.550
This was a huge deal, because we know emotion
influences cognition and perception in everyday

00:06:19.550 --> 00:06:23.070
tasks like learning, communication, and decision
making.

00:06:23.070 --> 00:06:26.930
Affect-aware systems use sensors, sometimes
worn, that capture things like speech and

00:06:26.930 --> 00:06:31.129
video of the face, as well as biometrics,
like sweatiness and heart rate.

00:06:31.129 --> 00:06:35.980
This multimodal sensor data is used in conjunction
with computational models that represent how

00:06:35.980 --> 00:06:40.720
people develop and express affective states,
like happiness and frustration, and social

00:06:40.720 --> 00:06:42.610
states, like friendship and trust.

00:06:42.610 --> 00:06:46.539
These models estimate the likelihood of a
user being in a particular state, and figure

00:06:46.539 --> 00:06:50.860
out how to best respond to that state, in
order to achieve the goals of the system.

00:06:50.860 --> 00:06:55.220
This might be to calm the user down, build
trust, or help them get their homework done.

00:06:55.220 --> 00:06:59.129
A study, looking at user affect, was conducted
by Facebook in 2012.

00:06:59.129 --> 00:07:03.210
For one week, data scientists altered the
content on hundreds of thousands of users’

00:07:03.210 --> 00:07:03.740
feeds.

00:07:03.740 --> 00:07:07.580
Some people were shown more items with positive
content, while others were presented with

00:07:07.600 --> 00:07:08.879
more negative content.

00:07:08.879 --> 00:07:12.830
The researchers analyzed people's posts during
that week, and found that users who were shown

00:07:12.830 --> 00:07:16.639
more positive content, tended to also post
more positive content.

00:07:16.639 --> 00:07:21.229
On the other hand, users who saw more negative
content, tended to have more negative posts.

00:07:21.229 --> 00:07:25.110
Clearly, what Facebook and other services
show you can absolutely have an affect on

00:07:25.110 --> 00:07:25.760
you.

00:07:25.760 --> 00:07:29.560
As gatekeepers of content, that’s a huge
opportunity and responsibility.

00:07:29.560 --> 00:07:32.060
Which is why this study ended up being pretty
controversial.

00:07:32.060 --> 00:07:35.949
Also, it raises some interesting questions
about how computer programs should respond

00:07:35.949 --> 00:07:37.640
to human communication.

00:07:37.640 --> 00:07:41.660
If the user is being negative, maybe the computer shouldn’t be annoying by responding in a

00:07:41.660 --> 00:07:43.280
cheery, upbeat manner.

00:07:43.280 --> 00:07:47.080
Or, maybe the computer should attempt to evoke
a positive response, even if it’s a bit

00:07:47.080 --> 00:07:48.080
awkward.

00:07:48.090 --> 00:07:51.319
The “correct” behavior is very much an
open research question.

00:07:51.319 --> 00:07:56.030
Speaking of Facebook, it’s a great example
of computer-mediated communication, or CMC,

00:07:56.030 --> 00:07:57.740
another large field of research.

00:07:57.740 --> 00:08:01.970
This includes synchronous communication – like
video calls, where all participants are online

00:08:01.970 --> 00:08:06.469
simultaneously – as well as asynchronous
communication – like tweets, emails, and

00:08:06.469 --> 00:08:09.480
text messages, where people respond whenever
they can or want.

00:08:09.480 --> 00:08:13.920
Researchers study things like the use of emoticons,
rules such as turn-taking, and language used

00:08:13.920 --> 00:08:15.460
in different communication channels.

00:08:15.460 --> 00:08:19.480
One interesting finding is that people exhibit
higher levels of self-disclosure – that

00:08:19.500 --> 00:08:24.880
is, reveal personal information – in computer-mediated
conversations, as opposed to face-to-face

00:08:24.880 --> 00:08:25.520
interactions.

00:08:25.520 --> 00:08:29.480
So if you want to build a system that knows
how many hours a user truly spent watching

00:08:29.480 --> 00:08:33.690
The Great British Bakeoff, it might be better
to build a chatbot than a virtual agent with

00:08:33.690 --> 00:08:34.180
a face.

00:08:34.180 --> 00:08:38.440
Psychology research has also demonstrated
that eye gaze is extremely important in persuading,

00:08:38.440 --> 00:08:40.400
teaching and getting people's attention.

00:08:40.400 --> 00:08:43.599
Looking at others while talking is called
mutual gaze.

00:08:43.599 --> 00:08:47.490
This has been shown to boost engagement and
help achieve the goals of a conversation,

00:08:47.490 --> 00:08:50.540
whether that’s learning, making a friend,
or closing a business deal.

00:08:50.540 --> 00:08:54.899
In settings like a videotaped lecture, the
instructor rarely, if ever, looks into the

00:08:54.899 --> 00:08:58.550
camera, and instead generally looks at the
students who are physically present.

00:08:58.550 --> 00:09:02.500
That’s ok for them, but it means people
who watch the lectures online have reduced

00:09:02.500 --> 00:09:03.240
engagement.

00:09:03.240 --> 00:09:07.180
In response, researchers have developed computer
vision and graphics software that can warp

00:09:07.190 --> 00:09:10.780
the head and eyes, making it appear as though
the instructor is looking into the camera

00:09:10.790 --> 00:09:12.900
– right at the remote viewer.

00:09:12.900 --> 00:09:15.090
This technique is called augmented gaze.

00:09:15.090 --> 00:09:18.470
Similar techniques have also been applied
to video conference calls, to correct for

00:09:18.470 --> 00:09:21.810
the placement of webcams, which are almost
always located above screens.

00:09:21.810 --> 00:09:25.350
Since you’re typically looking at the video
of your conversation partner, rather than

00:09:25.350 --> 00:09:28.701
directly into the webcam, you’ll always
appear to them as though you’re looking

00:09:28.701 --> 00:09:33.160
downwards – breaking mutual gaze – which
can create all kinds of unfortunate social

00:09:33.160 --> 00:09:35.380
side effects, like a power imbalance.

00:09:35.380 --> 00:09:39.510
Fortunately, this can be corrected digitally,
and appear to participants as though you’re

00:09:39.510 --> 00:09:41.260
lovingly gazing into their eyes.

00:09:41.260 --> 00:09:46.160
Humans also love anthropomorphizing objects,
and computers are no exception, especially

00:09:46.160 --> 00:09:49.180
if they move, like our Robots from last episode.

00:09:49.180 --> 00:09:53.470
Beyond industrial uses that prevailed over
the last century, robots are used increasingly

00:09:53.470 --> 00:09:58.560
in medical, education, and entertainment settings,
where they frequently interact with humans.

00:09:58.560 --> 00:10:03.880
Human-Robot Interaction – or HRI – is
a field dedicated to studying these interactions,

00:10:03.890 --> 00:10:08.000
like how people perceive different robots
behaviors and forms, or how robots can interpret

00:10:08.000 --> 00:10:11.089
human social cues to blend in and not be super
awkward.

00:10:11.089 --> 00:10:15.060
As we discussed last episode, there’s an
ongoing quest to make robots as human-like

00:10:15.060 --> 00:10:17.880
in their appearance and interactions as possible.

00:10:17.880 --> 00:10:22.500
When engineers first made robots in the 1940s and 50s, they didn’t look very human at all.

00:10:22.500 --> 00:10:25.900
They were almost exclusively industrial machines
with no human-likeness.

00:10:25.900 --> 00:10:30.030
Over time, engineers got better and better
at making human-like robots – they gained

00:10:30.030 --> 00:10:34.000
heads and walked around on two legs, but…
they couldn’t exactly go to restaurants

00:10:34.000 --> 00:10:35.440
and masquerade as humans.

00:10:35.440 --> 00:10:39.730
As people pushed closer and closer to human
likeness, replacing cameras with artificial

00:10:39.730 --> 00:10:44.420
eyeballs, and covering metal chassis with
synthetic flesh, things started to get a bit...

00:10:44.420 --> 00:10:47.870
uncanny... eliciting an eerie and unsettling
feeling.

00:10:47.870 --> 00:10:53.380
This dip in realism between almost-human and actually-human became known as the uncanny valley.

00:10:53.420 --> 00:10:56.340
There’s debate over whether robots should
act like humans too.

00:10:56.340 --> 00:11:00.351
Lots of evidence already suggests that even
if robots don’t act like us, people will

00:11:00.351 --> 00:11:02.690
treat them as though they know our social
conventions.

00:11:02.690 --> 00:11:06.640
And when they violate these rules – such
as not apologizing if they cut in front of

00:11:06.640 --> 00:11:09.800
you or roll over your foot – people get
really mad!

00:11:09.800 --> 00:11:13.839
Without a doubt, psychology and computer science
are a potent combination, and have tremendous

00:11:13.839 --> 00:11:16.209
potential to affect our everyday lives.

00:11:16.209 --> 00:11:20.110
Which leaves us with a lot of question like
you might lie to your laptop, but should your

00:11:20.110 --> 00:11:21.440
laptop lie to you?

00:11:21.440 --> 00:11:23.660
What if it makes you more efficient or happy?

00:11:23.670 --> 00:11:27.360
Or should social media companies curate the
content they show you to make you stay on

00:11:27.360 --> 00:11:29.860
their site longer to make you buy more products?

00:11:29.860 --> 00:11:31.260
They do by the way.

00:11:31.260 --> 00:11:35.580
These types of ethical considerations aren’t
easy to answer, but psychology can at least

00:11:35.589 --> 00:11:40.120
help us understand the effects and implications
of design choices in our computing systems.

00:11:40.130 --> 00:11:45.240
But, on the positive side, understanding the
psychology behind design might lead to increased

00:11:45.240 --> 00:11:46.240
accessibility.

00:11:46.240 --> 00:11:50.560
A greater number of people can understand
and use computers now that they're more intuitive

00:11:50.560 --> 00:11:51.340
than ever.

00:11:51.340 --> 00:11:55.420
Conference calls and virtual classrooms are
becoming more agreeable experiences.

00:11:55.430 --> 00:11:59.220
As robot technology continues to improve,
the population will grow more comfortable

00:11:59.230 --> 00:12:00.740
in those interactions.

00:12:00.740 --> 00:12:04.660
Plus, thanks to psychology, we can all bond
over our love of knurling.

00:12:04.660 --> 00:12:05.980
I’ll see you next week.

