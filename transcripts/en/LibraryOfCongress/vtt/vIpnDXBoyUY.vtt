WEBVTT
Kind: captions
Language: en

00:00:00.780 --> 00:00:04.730
&gt;&gt; From the Library of
Congress in Washington DC.

00:00:16.260 --> 00:00:17.810
&gt;&gt; Stephanie Stillo: Hello.

00:00:17.810 --> 00:00:23.160
So I realized I do not look like
John Hessler, but we are going

00:00:23.160 --> 00:00:26.440
to pertained that I am right now

00:00:26.440 --> 00:00:30.940
to welcome Vince
Rossi to the stage.

00:00:30.940 --> 00:00:34.140
And I'm going to try not to
touch his computer right now

00:00:34.140 --> 00:00:37.220
that is very carefully set up.

00:00:37.220 --> 00:00:40.000
It is my pleasure
to introduce Vince.

00:00:40.000 --> 00:00:45.570
He is a fantastic innovator,
and just a lovely person

00:00:45.570 --> 00:00:47.800
and a colleague within
the city as well.

00:00:47.800 --> 00:00:50.020
And we're so excited to have
him at the library today.

00:00:50.020 --> 00:00:54.730
Vince has a BFA in sculpture
from the university of arts

00:00:54.730 --> 00:00:57.940
in Philadelphia and graduate
level fine arts study

00:00:57.940 --> 00:01:01.270
at Goldsmith College,
the University of London.

00:01:01.270 --> 00:01:07.030
From 2004 to 2011, he worked
as a sculptor, model maker,

00:01:07.030 --> 00:01:10.200
and project manager for
the Smithsonian's office

00:01:10.200 --> 00:01:11.660
of exhibit central.

00:01:11.660 --> 00:01:14.540
And helped produce and manage
many Smithsonian exhibits.

00:01:14.540 --> 00:01:17.670
And I have to day, after
speaking with Vince,

00:01:17.670 --> 00:01:22.410
he has a sort of fabulous
history of these different,

00:01:22.410 --> 00:01:23.760
interesting jobs that he does.

00:01:23.760 --> 00:01:26.680
He's one of those people that
are just really sort of fun

00:01:26.680 --> 00:01:27.980
to talk to and you sort of wish

00:01:27.980 --> 00:01:29.670
that you lived his
life, you know?

00:01:29.670 --> 00:01:31.870
So very exciting.

00:01:31.870 --> 00:01:35.810
From 2011 to present,
Vince has worked

00:01:35.810 --> 00:01:38.660
as a senior 3D program officer

00:01:38.660 --> 00:01:42.430
for the Smithsonian's
digitization program office

00:01:42.430 --> 00:01:46.210
building 3D capacity and
developing 3D workflows,

00:01:46.210 --> 00:01:48.360
which is not an easy
thing to do.

00:01:48.360 --> 00:01:52.370
Vince has the remarkable
challenge of thinking

00:01:52.370 --> 00:01:55.550
about access to museum
collections.

00:01:55.550 --> 00:01:57.170
And not just any museum.

00:01:57.170 --> 00:01:59.750
Specifically thinking
about access

00:01:59.750 --> 00:02:04.020
to the Smithsonian's
massive collection of varied,

00:02:04.020 --> 00:02:07.900
and as he's going to suggest,
sometimes hidden material.

00:02:07.900 --> 00:02:12.480
So today, we are, or he is
going to address his innovative

00:02:12.480 --> 00:02:16.070
and visionary approach
to this subject.

00:02:16.070 --> 00:02:17.600
And Vince's commitment

00:02:17.600 --> 00:02:20.510
to furthering the
Smithsonian's core mission

00:02:20.510 --> 00:02:26.310
of increasing the diffusion of
knowledge is truly inspiring.

00:02:26.310 --> 00:02:27.610
So we are very pleased

00:02:27.610 --> 00:02:31.510
to welcome Vince
Rossi to the stage.

00:02:31.510 --> 00:02:37.920
[ Applause ]

00:02:37.920 --> 00:02:40.490
&gt;&gt; Vincent Rossi: Alright,
thank you, Stephanie.

00:02:40.490 --> 00:02:41.970
So it's an honor to be here.

00:02:41.970 --> 00:02:46.400
Thanks for hanging
out for the last talk.

00:02:46.400 --> 00:02:49.560
So I want to just start with
our contact info website.

00:02:49.560 --> 00:02:52.390
This will be up again at
the end of the presentation.

00:02:52.390 --> 00:02:55.950
Or you could simply
Google "Smithsonian 3D"

00:02:55.950 --> 00:02:59.310
and our link should come up.

00:02:59.310 --> 00:03:02.200
So a little bit of context,
we're here in Washington DC,

00:03:02.200 --> 00:03:05.580
so I'm sure many of you
know about the Smithsonian.

00:03:05.580 --> 00:03:07.360
I'm sure we have some
Smithsonian folks

00:03:07.360 --> 00:03:09.120
in the audience.

00:03:09.120 --> 00:03:11.760
But for some context, it's
of course not one museum,

00:03:11.760 --> 00:03:16.880
it's 19 museums, nine research
centers, we have a national zoo,

00:03:16.880 --> 00:03:19.510
and we have scientists operating

00:03:19.510 --> 00:03:21.920
in over 100 countries
around the world.

00:03:21.920 --> 00:03:27.850
So in total, we have
155 million objects.

00:03:27.850 --> 00:03:30.480
And we simply can't
display all these objects.

00:03:30.480 --> 00:03:35.630
Less than 1% are ever on
display at any one time.

00:03:35.630 --> 00:03:38.140
So some would see this
as a huge access problem.

00:03:38.140 --> 00:03:41.610
But our office really sees
it as an amazing opportunity.

00:03:41.610 --> 00:03:46.510
So here's just a glimpse of, you
know, some of the amazing things

00:03:46.510 --> 00:03:49.890
as a Smithsonian employee I
get to see behind the scenes.

00:03:49.890 --> 00:03:53.190
And our team is really figuring
out how we can use a variety

00:03:53.190 --> 00:03:56.570
of 3D scanning tools to
unlock these collections.

00:03:56.570 --> 00:04:00.150
So that we can bring them
out to the world and so

00:04:00.150 --> 00:04:01.450
that they can be used

00:04:01.450 --> 00:04:04.200
for research education
and public access.

00:04:04.200 --> 00:04:10.740
So if we think about, you know,
the way humans have documented

00:04:10.740 --> 00:04:14.330
and you know, used
tools to understand

00:04:14.330 --> 00:04:17.150
and interpret the world around
us throughout time, you know,

00:04:17.150 --> 00:04:19.990
we've used painting,
drawing, printmaking,

00:04:19.990 --> 00:04:25.240
more recently photography, and
a variety of digital tools.

00:04:25.240 --> 00:04:29.260
But we've also used a variety
of measurement devices.

00:04:29.260 --> 00:04:30.560
So for thousands of years,

00:04:30.560 --> 00:04:35.180
we've taken point-to-point
measurements and if we think

00:04:35.180 --> 00:04:40.540
about how a researcher might
analyze a skull, for example,

00:04:40.540 --> 00:04:43.390
they might take maybe a
dozen landmark measurements

00:04:43.390 --> 00:04:45.850
that describe the
morphology of this object.

00:04:45.850 --> 00:04:49.270
And then of course they actually
have to be there in the museum

00:04:49.270 --> 00:04:50.900
to take these measurements.

00:04:50.900 --> 00:04:54.490
So with the 3D scan, we're able

00:04:54.490 --> 00:04:57.660
to collect not a dozen
measurement points,

00:04:57.660 --> 00:05:01.060
but we might be collecting
millions or sometimes billions

00:05:01.060 --> 00:05:03.660
of measurement points
that describe the surface

00:05:03.660 --> 00:05:05.480
and morphology of an object.

00:05:05.480 --> 00:05:09.170
And once we have that data,
once we have it in digital form,

00:05:09.170 --> 00:05:12.000
we're able to unlock a whole
new world of research potential.

00:05:12.000 --> 00:05:15.450
So at a click of a button,
we could do surface area

00:05:15.450 --> 00:05:17.700
or volume calculation
and we could do things

00:05:17.700 --> 00:05:19.750
that we simply cannot
do with the objects

00:05:19.750 --> 00:05:21.790
if we are holding
them in our hands.

00:05:21.790 --> 00:05:24.300
So this psychedelic
rainbow skull we see

00:05:24.300 --> 00:05:27.620
on the screen is actually
an overlay of two 3D scans.

00:05:27.620 --> 00:05:29.710
So we're looking at
the deviation analysis

00:05:29.710 --> 00:05:32.270
of every surface on this object.

00:05:34.060 --> 00:05:36.990
So our team uses a variety
of 3D capture methods.

00:05:36.990 --> 00:05:39.200
This is an example of
a 3D laser scanning.

00:05:39.200 --> 00:05:41.710
We're scanning Abraham
Lincoln's life mask.

00:05:41.710 --> 00:05:43.870
We deliver that content
in two ways.

00:05:43.870 --> 00:05:47.340
One is through our 3D viewer,
which I'll be doing a live demo.

00:05:47.340 --> 00:05:50.010
And then we also make the
data available for download.

00:05:50.010 --> 00:05:52.260
So if you have access to
a 3D printer or if you go

00:05:52.260 --> 00:05:56.280
to the DC public library, you
can create a 3D print from any

00:05:56.280 --> 00:05:59.450
of the Smithsonian scans
that we have online.

00:05:59.450 --> 00:06:01.840
So a quick glimpse of our team.

00:06:01.840 --> 00:06:03.220
We operate behind the scenes.

00:06:03.220 --> 00:06:06.000
All the 3D scanning tools
we bring to the objects

00:06:06.000 --> 00:06:07.960
and to the collections.

00:06:07.960 --> 00:06:10.580
And we document scientific
research sites,

00:06:10.580 --> 00:06:12.630
individual objects, and
now we're really trying

00:06:12.630 --> 00:06:15.440
to turn the corner to
document entire collections.

00:06:15.440 --> 00:06:19.300
I won't go into the
details here.

00:06:19.300 --> 00:06:22.780
But essentially the
Smithsonian has everything

00:06:22.780 --> 00:06:24.330
from insects to airplanes.

00:06:24.330 --> 00:06:28.060
So there's no one single
3D capture tool we can use.

00:06:28.060 --> 00:06:31.790
So we use a variety of
laser scanners, CT scanners,

00:06:31.790 --> 00:06:34.010
structured light, and
photogrammetry tools

00:06:34.010 --> 00:06:38.240
that involve using a camera to
take photographs of a object

00:06:38.240 --> 00:06:40.860
and software to create
a 3D construction.

00:06:40.860 --> 00:06:46.070
And I want to make sure we
all understand what I mean

00:06:46.070 --> 00:06:48.060
when I say 3D or 3D model.

00:06:48.060 --> 00:06:49.360
Because it's kind
of a loaded term.

00:06:49.360 --> 00:06:52.660
You might think 3D TV,
you know, 3D movie.

00:06:52.660 --> 00:06:54.260
What I'm talking
about is scanning

00:06:54.260 --> 00:06:56.920
and capturing the
geometry of an object.

00:06:56.920 --> 00:06:58.560
So I won't go through
all these layers,

00:06:58.560 --> 00:07:01.100
but we'll go through
the raw data.

00:07:01.100 --> 00:07:02.780
And Kim touched on
this yesterday,

00:07:02.780 --> 00:07:06.260
similar capture method for
some of the deep space objects

00:07:06.260 --> 00:07:08.070
that she was scanning.

00:07:08.070 --> 00:07:09.370
This is a point cloud.

00:07:09.370 --> 00:07:11.970
So generally, this is the raw
data that we're collecting.

00:07:11.970 --> 00:07:15.220
And it's essentially the
visualization of a text file.

00:07:15.220 --> 00:07:19.250
So .1 to 1 million of
David Livingston's gun

00:07:19.250 --> 00:07:23.030
that we scanned here, each
has an X, Y, and Z value.

00:07:23.030 --> 00:07:25.780
So it's essentially a
visualization of a text file

00:07:25.780 --> 00:07:30.090
and you can literally open up
a 3D scan in Microsoft Excel.

00:07:31.370 --> 00:07:33.780
And then we interpret
that data, we process it.

00:07:33.780 --> 00:07:36.900
So the next step in processing
is we essentially connect

00:07:36.900 --> 00:07:38.200
the dots.

00:07:38.200 --> 00:07:39.500
So these polygons are
much bigger but we've sort

00:07:39.500 --> 00:07:41.770
of enlarged them so
you can get an idea.

00:07:41.770 --> 00:07:43.930
Normally it'd be much
denser than this.

00:07:43.930 --> 00:07:46.400
So now we can calculate volume.

00:07:46.400 --> 00:07:50.050
We can also reflect
virtual light.

00:07:50.050 --> 00:07:52.580
And we can apply color
to that 3D model.

00:07:52.580 --> 00:08:01.010
So I'm going to go through five
use cases that describe some

00:08:01.010 --> 00:08:03.240
of our project that
we've worked.

00:08:03.240 --> 00:08:07.350
A number of onsite projects as
well as 3D scanning objects.

00:08:07.350 --> 00:08:08.650
And at the end of the talk,

00:08:08.650 --> 00:08:12.230
I can describe our whole
new vision and plans

00:08:12.230 --> 00:08:14.820
over the next two years and how
we're hoping to shift from going

00:08:14.820 --> 00:08:18.960
from these one-off objects,
which are incredible stories,

00:08:18.960 --> 00:08:20.960
to scan the entire collections.

00:08:20.960 --> 00:08:23.740
So here we are in
the Atacama Desert.

00:08:23.740 --> 00:08:26.090
This is in 2011.

00:08:26.090 --> 00:08:28.760
And they were widening
the pan-American highway.

00:08:28.760 --> 00:08:33.500
And they uncovered over 40
complete fossil whale specimens.

00:08:33.500 --> 00:08:34.960
Dr. Nicholas Pyenson,

00:08:34.960 --> 00:08:37.730
the curator of fossil marine
mammals, was blown away

00:08:37.730 --> 00:08:39.030
when he saw this site.

00:08:39.030 --> 00:08:41.080
He called our team
down to Chile.

00:08:41.080 --> 00:08:43.380
And we were able,
luckily we were able

00:08:43.380 --> 00:08:45.900
to respond pretty quickly.

00:08:45.900 --> 00:08:49.210
So if you look at the
traditional method

00:08:49.210 --> 00:08:53.410
of documentation for a site
like this, you draw a meter

00:08:53.410 --> 00:08:55.590
by meter string line
across the site.

00:08:55.590 --> 00:08:58.020
And then you sketch the
approximate location

00:08:58.020 --> 00:09:00.660
of each fossil in the ground.

00:09:00.660 --> 00:09:03.110
So our team was able to take
that level of documentation

00:09:03.110 --> 00:09:04.410
to a much higher level.

00:09:04.410 --> 00:09:07.440
We used a lighter system,
a laser arm scanner,

00:09:07.440 --> 00:09:09.800
and photogrammetry tools
and we combined all

00:09:09.800 --> 00:09:14.470
of those three datasets to
create cohesive models as well

00:09:14.470 --> 00:09:16.760
as scans of the entire
environment.

00:09:16.760 --> 00:09:19.480
So the fossils themselves,

00:09:19.480 --> 00:09:21.600
the pan-American
highway was widened.

00:09:21.600 --> 00:09:24.360
The fossils were extracted from
the ground, but they're encased

00:09:24.360 --> 00:09:27.430
in tons of dirt and
earth and rock.

00:09:27.430 --> 00:09:31.490
So they were not going to see
the light of day for years.

00:09:31.490 --> 00:09:36.470
Our team after capturing the
3D data, within being back

00:09:36.470 --> 00:09:40.410
from the site, I think it was
five days, we created 3D prints

00:09:40.410 --> 00:09:42.480
for the researcher,
for the director

00:09:42.480 --> 00:09:45.640
of the natural history museum as
well as for National Geographic,

00:09:45.640 --> 00:09:47.190
they helped fund this project.

00:09:47.190 --> 00:09:50.680
In the bottom left hand corner,
that looks like a photograph,

00:09:50.680 --> 00:09:54.100
but essentially it's a render
derived from the 3D data.

00:09:54.100 --> 00:09:56.990
So one might think like okay,
you could just send a drone up

00:09:56.990 --> 00:10:00.330
and take a picture, but then
you would have lens distortion.

00:10:00.330 --> 00:10:02.310
With an orthographic rendering,

00:10:02.310 --> 00:10:04.380
we can take accurate
measurements in the X

00:10:04.380 --> 00:10:09.150
and Y direction and we're also
looking at the 3D data in 2D.

00:10:09.150 --> 00:10:10.740
So on the right side
of the screen,

00:10:10.740 --> 00:10:13.040
that's essentially the
elevation map at grade scale.

00:10:13.040 --> 00:10:15.200
And it was important
for these researchers

00:10:15.200 --> 00:10:19.400
who didn't have proficiency in
3D tools to have an easy way

00:10:19.400 --> 00:10:21.650
to analyze the 3D scans.

00:10:21.650 --> 00:10:26.690
We also partnered
with 3D Systems.

00:10:26.690 --> 00:10:29.720
They helped us create the
largest museum quality 3D print

00:10:29.720 --> 00:10:31.020
in the world.

00:10:31.020 --> 00:10:32.540
This is about 23 feet long.

00:10:32.540 --> 00:10:34.680
And for those of you who are
familiar with 3D printing,

00:10:34.680 --> 00:10:36.210
that is incredibly massive.

00:10:36.210 --> 00:10:39.210
Normally 3D prints
are much smaller.

00:10:39.210 --> 00:10:41.840
Ping Fu, who was the vice
president of 3D Systems,

00:10:41.840 --> 00:10:45.040
helped make this
donation happen.

00:10:45.040 --> 00:10:47.500
And this hangs in the
natural history museum.

00:10:47.500 --> 00:10:50.810
So essentially with
this project,

00:10:50.810 --> 00:10:53.940
we have scientists bringing
home data instead of fossils.

00:10:53.940 --> 00:10:56.210
We have a new form of
collecting happening.

00:10:56.210 --> 00:11:00.410
We created this 23 foot 3D
print for exhibit display.

00:11:00.410 --> 00:11:05.030
A scientific research paper was
created and it was published

00:11:05.030 --> 00:11:06.330
in the Research Society.

00:11:06.330 --> 00:11:07.860
And as someone who has
a degree in sculpture,

00:11:07.860 --> 00:11:09.360
I found myself kind
of blown away

00:11:09.360 --> 00:11:12.270
that suddenly I'm a
co-author for a paper

00:11:12.270 --> 00:11:14.210
at the research society.

00:11:14.210 --> 00:11:15.980
And then of course
public access.

00:11:15.980 --> 00:11:18.600
All of the data that we create
usually starts supporting a

00:11:18.600 --> 00:11:21.950
research project, we make that
data available for the public

00:11:21.950 --> 00:11:24.670
through our 3D viewer,
and also as a download.

00:11:24.670 --> 00:11:28.550
So we make the data available in
the highest resolution possible.

00:11:32.370 --> 00:11:35.920
So this next project I'm going
to talk about if a collaboration

00:11:35.920 --> 00:11:38.430
with the Office of
Repatriation at the Smithsonian.

00:11:38.430 --> 00:11:40.210
This is an incredible story,

00:11:40.210 --> 00:11:42.320
we have these object
that's a killer whale hat.

00:11:42.320 --> 00:11:47.730
And the repatriation office has
over 14,000 funerary remains

00:11:47.730 --> 00:11:49.290
that are being repatriated

00:11:49.290 --> 00:11:51.730
to the rightful honors
of these objects.

00:11:51.730 --> 00:11:54.140
But after these objects
are repatriated,

00:11:54.140 --> 00:11:57.190
there's often not much
of a record left behind.

00:11:57.190 --> 00:12:00.040
So we partnered with
this office,

00:12:00.040 --> 00:12:01.940
as well as the Tlingit
community,

00:12:01.940 --> 00:12:04.200
and really this is
the first time

00:12:04.200 --> 00:12:07.200
that the Smithsonian ever
repatriated an object

00:12:07.200 --> 00:12:09.630
to a community and
they brought it back

00:12:09.630 --> 00:12:11.460
for further documentations.

00:12:11.460 --> 00:12:13.900
This is kind of a
pretty cool experiment

00:12:13.900 --> 00:12:15.200
that we thought worked
out really well.

00:12:15.200 --> 00:12:17.700
So here we are scanning
the object.

00:12:17.700 --> 00:12:21.410
Here's the raw data.

00:12:21.410 --> 00:12:25.910
And then we took that data and
we partnered with the office

00:12:25.910 --> 00:12:29.500
of exhibit central, and we
essentially fed that 3D data

00:12:29.500 --> 00:12:31.080
into a milling machine.

00:12:31.080 --> 00:12:33.420
And with partnered really
closely with the community.

00:12:33.420 --> 00:12:35.550
And we worked with the
traditional woodcarver,

00:12:35.550 --> 00:12:37.630
and he supplied us
with the type of wood

00:12:37.630 --> 00:12:40.040
that he would have used
to create a replica.

00:12:40.040 --> 00:12:43.780
And it was interesting
because as a maker myself,

00:12:43.780 --> 00:12:47.210
I wasn't sure how he was going
to react to this technology.

00:12:47.210 --> 00:12:48.820
And his response was
really interesting.

00:12:48.820 --> 00:12:51.680
He said you know "When
chainsaws became mass produced,

00:12:51.680 --> 00:12:55.640
native communities saw them as
useful tools and we used them."

00:12:55.640 --> 00:12:58.620
And his perspective was
that he saw this 3D scanning

00:12:58.620 --> 00:13:02.670
and CNC milling technique
as just another tool

00:13:02.670 --> 00:13:05.440
that could be in his toolbox.

00:13:05.440 --> 00:13:08.620
So here we are presenting
the replica

00:13:08.620 --> 00:13:10.850
at the clan conference
in Sitka, Alaska.

00:13:10.850 --> 00:13:13.220
And what was really
interesting is

00:13:13.220 --> 00:13:15.810
that the community immediately
started brainstorming

00:13:15.810 --> 00:13:18.310
about okay, how could
we use this technology?

00:13:18.310 --> 00:13:19.740
And there were some
tragic stories

00:13:19.740 --> 00:13:22.620
where they had I think it
was a dozen of these hats

00:13:22.620 --> 00:13:26.140
that are incredibly sacred
and they've been passed along

00:13:26.140 --> 00:13:27.640
from generation to generation.

00:13:27.640 --> 00:13:30.600
So in some cases, they're
hundreds of years old.

00:13:30.600 --> 00:13:32.130
And one of the houses
burned down

00:13:32.130 --> 00:13:34.500
and they lost 12
of these objects.

00:13:34.500 --> 00:13:35.800
And they're really,

00:13:35.800 --> 00:13:39.090
and immediately [inaudible]
we could use this technology

00:13:39.090 --> 00:13:42.130
to archive these sacred
objects that we have.

00:13:42.130 --> 00:13:45.940
And if something was to
happen, we could create replicas

00:13:45.940 --> 00:13:49.580
for their own ceremonial use.

00:13:51.320 --> 00:13:54.460
Another interesting,
unexpected thing that happened

00:13:54.460 --> 00:13:57.090
with this project is that
from our perspective,

00:13:57.090 --> 00:13:59.940
with thought we were making
a replica for museum display.

00:13:59.940 --> 00:14:02.570
But when we presented it
at the clan conference,

00:14:02.570 --> 00:14:05.850
the community took this
replica, and brought it on stage

00:14:05.850 --> 00:14:07.920
with the actual object
and danced with it.

00:14:07.920 --> 00:14:10.550
So they breathed new
life into this object.

00:14:10.550 --> 00:14:13.780
And usually if you think
about the journey of an object

00:14:13.780 --> 00:14:15.790
that ends up landing
in a museum,

00:14:15.790 --> 00:14:17.670
that's usually the
end of the story.

00:14:17.670 --> 00:14:21.870
And here's an example of
that story continuing.

00:14:21.870 --> 00:14:24.340
Through this replica process.

00:14:24.340 --> 00:14:28.260
So we had a really
deep partnership

00:14:28.260 --> 00:14:30.640
with the Tlingit community,
the data is archived

00:14:30.640 --> 00:14:33.590
for the community and
for the Smithsonian,

00:14:33.590 --> 00:14:36.220
the object replica
remains on display,

00:14:36.220 --> 00:14:39.600
and part of the agreement we
had with the Tlingit clan is

00:14:39.600 --> 00:14:41.820
that whenever they're
in Washington DC,

00:14:41.820 --> 00:14:43.610
they reserve the right
to dance with this hat.

00:14:43.610 --> 00:14:46.420
And this has already happened
twice, which I think is amazing.

00:14:46.420 --> 00:14:49.730
This idea of, you know, a museum
object is usually, you know,

00:14:49.730 --> 00:14:52.660
sitting dusty in a vatrine,
and no one ever touches it.

00:14:52.660 --> 00:14:55.420
And here we have
this replica object

00:14:55.420 --> 00:14:58.360
that actually gets pulled
off display and is danced

00:14:58.360 --> 00:14:59.660
with by the community.

00:14:59.660 --> 00:15:01.950
And then of course we
make the model available

00:15:01.950 --> 00:15:04.620
for viewing online
with our 3D viewer

00:15:04.620 --> 00:15:06.280
but not available for downloads.

00:15:06.280 --> 00:15:08.900
That's not something that the
community wanted us to do,

00:15:08.900 --> 00:15:13.230
and of course we respected that.

00:15:13.230 --> 00:15:16.240
So another onsite project.

00:15:16.240 --> 00:15:19.640
Excuse me.

00:15:19.640 --> 00:15:22.770
So here we have, this is
at historic Jamestown,

00:15:22.770 --> 00:15:27.330
a collaboration between our
team, Dr. Douglas Owsley,

00:15:27.330 --> 00:15:30.930
a forensic anthropologist, and
the historic Jamestown team.

00:15:30.930 --> 00:15:33.970
Another example of
a finding happening

00:15:33.970 --> 00:15:36.260
through a construction project.

00:15:36.260 --> 00:15:39.420
So these graves were
essentially stumbled upon.

00:15:39.420 --> 00:15:42.840
And our team was called down
to scan each individual grave

00:15:42.840 --> 00:15:44.690
as well as the site itself.

00:15:44.690 --> 00:15:47.310
So we used a variety

00:15:47.310 --> 00:15:50.310
of 3D capture methods
to do documentation.

00:15:50.310 --> 00:15:52.560
And this proved to
be really important

00:15:52.560 --> 00:15:56.650
because once these remains
were pulled from the ground,

00:15:56.650 --> 00:15:58.320
you can see, especially
with the ribcage,

00:15:58.320 --> 00:16:00.490
you can see that there's
sort of a defined rib cage

00:16:00.490 --> 00:16:03.920
on the 3D scan with the
object still encased in earth.

00:16:03.920 --> 00:16:05.680
But once the remains
were removed

00:16:05.680 --> 00:16:07.700
by the forensic anthropologists,

00:16:07.700 --> 00:16:10.230
a lot of it literally
turned to dust.

00:16:10.230 --> 00:16:13.360
So we've captured this
research moment in time,

00:16:13.360 --> 00:16:16.550
not just as a picture,
but as measurable,

00:16:16.550 --> 00:16:19.810
tree-dimensional
scientific data.

00:16:19.810 --> 00:16:22.280
So we're documenting a site

00:16:22.280 --> 00:16:24.630
where context is
completely lost.

00:16:24.630 --> 00:16:27.340
Once the remains are
removed from the earth,

00:16:27.340 --> 00:16:29.900
they're extremely
fragmented and incomplete.

00:16:29.900 --> 00:16:31.200
And the 3D documentation

00:16:31.200 --> 00:16:34.820
and visualizations supported
not only the science,

00:16:34.820 --> 00:16:36.570
but also a lot of media outrage.

00:16:36.570 --> 00:16:40.170
The 3D renders we created ended
up being on the front page

00:16:40.170 --> 00:16:42.630
of the New York Times,
the Washington Post,

00:16:42.630 --> 00:16:44.800
and the Wall Street Journal.

00:16:44.800 --> 00:16:47.360
And then these models are
also available for viewing

00:16:47.360 --> 00:16:49.280
and downloading on our website.

00:16:49.280 --> 00:16:54.800
So moving over to the
air and space museum,

00:16:54.800 --> 00:16:56.950
the Apollo 11 command module.

00:16:56.950 --> 00:16:59.010
This is a great collaboration
between one

00:16:59.010 --> 00:17:01.140
of our main technology
partners, Autodesk,

00:17:01.140 --> 00:17:03.520
they make a lot of 3D software.

00:17:03.520 --> 00:17:06.270
So I'm not sure if anyone
has seen this version

00:17:06.270 --> 00:17:08.800
of the display, it's actually
the display of change,

00:17:08.800 --> 00:17:12.170
but for decades it was encased
in this Plexiglas vatrine.

00:17:12.170 --> 00:17:14.270
And if you were an adult and
you were tall enough, you could,

00:17:14.270 --> 00:17:16.050
you know, kind of
peek into the window

00:17:16.050 --> 00:17:17.350
and see what was going on.

00:17:17.350 --> 00:17:18.650
But if you're a kid,
forget about it,

00:17:18.650 --> 00:17:21.130
you couldn't see what
was going on inside.

00:17:21.130 --> 00:17:24.710
So we got word that this
object was coming off display,

00:17:24.710 --> 00:17:28.180
the vatrine was being taken off,
and we partnered with the air

00:17:28.180 --> 00:17:31.190
and space museum to do
some, an incredible level

00:17:31.190 --> 00:17:33.340
of documentation,
on this object.

00:17:33.340 --> 00:17:36.530
And of course for
context, you know, this,

00:17:36.530 --> 00:17:41.800
the Apollo command module sat
on top of the Saturn 5 rocket.

00:17:41.800 --> 00:17:45.060
We were not able to get inside
the command module, of course,

00:17:45.060 --> 00:17:46.870
so we had to design
a number of systems

00:17:46.870 --> 00:17:49.270
and motion control
systems that reached inside

00:17:49.270 --> 00:17:51.320
that allowed us to
do 3D scanning.

00:17:51.320 --> 00:17:53.280
That was really one of
the main challenges.

00:17:53.280 --> 00:17:56.600
So here we have some renderings.

00:17:56.600 --> 00:17:59.380
These are renderings
from the 3D data.

00:17:59.380 --> 00:18:01.810
They look like photographs.

00:18:01.810 --> 00:18:04.320
And this was really
a great example

00:18:04.320 --> 00:18:06.160
of a public private partnership.

00:18:06.160 --> 00:18:09.420
We could not have done this
project under our own strength.

00:18:09.420 --> 00:18:13.130
Autodesk, our technology
partner, they invented software

00:18:13.130 --> 00:18:16.750
to deal with the volume of data
that we were collecting as well

00:18:16.750 --> 00:18:20.940
as the six different 3D
scanning tools that we used

00:18:20.940 --> 00:18:24.200
with varying resolutions
and accuracy levels.

00:18:24.200 --> 00:18:27.310
And combining that to create
one seamless 3D model is

00:18:27.310 --> 00:18:29.090
extremely challenging.

00:18:29.090 --> 00:18:30.590
So for us, we have
this, you know,

00:18:30.590 --> 00:18:33.720
amazing world-class 3D
model of the command module.

00:18:33.720 --> 00:18:37.330
And for Autodesk, it was really
a way to drive innovation

00:18:37.330 --> 00:18:40.540
for them as a software company.

00:18:47.530 --> 00:18:49.760
And then through the
3D scanning process,

00:18:49.760 --> 00:18:52.200
something unexpected happened.

00:18:52.200 --> 00:18:55.280
We uncovered a number of
what the curator called

00:18:55.280 --> 00:18:56.980
astronaut graffiti.

00:18:56.980 --> 00:19:00.810
And here we have an
inspirational quote

00:19:00.810 --> 00:19:03.440
by Michael Collins
"The best shift to come

00:19:03.440 --> 00:19:05.740
down the line, God bless her."

00:19:05.740 --> 00:19:07.530
Which was pretty cool.

00:19:07.530 --> 00:19:10.470
There were also some less
inspirational writings

00:19:10.470 --> 00:19:12.010
on the walls.

00:19:12.010 --> 00:19:13.970
One in particular
said "Smelly waste."

00:19:13.970 --> 00:19:16.070
And it was a reminder
not to open

00:19:16.070 --> 00:19:20.780
up this door for
obvious reasons.

00:19:20.780 --> 00:19:24.640
So here we have a
rendering of a 3D model.

00:19:24.640 --> 00:19:28.120
So we have again, example
of, we have a 3D scan

00:19:28.120 --> 00:19:30.130
and we're using this asset
in many different ways.

00:19:30.130 --> 00:19:34.760
High-resolution, 2D renders,
high-resolution, 3D animations,

00:19:34.760 --> 00:19:38.550
and again, the curator himself
who had studied this object

00:19:38.550 --> 00:19:42.080
for decades never allowed
himself to go inside

00:19:42.080 --> 00:19:44.760
of this object because
it posed too much risk.

00:19:44.760 --> 00:19:48.620
The object is from 1969, there's
plastic that has degraded,

00:19:48.620 --> 00:19:51.750
the fabric has degraded,
we're able to do things again

00:19:51.750 --> 00:19:54.340
that we simply cannot do
with the physical object.

00:19:54.340 --> 00:19:57.360
We can look at the
negative space outside

00:19:57.360 --> 00:20:00.330
of the crew chamber and
in between the walls

00:20:00.330 --> 00:20:03.390
of the command module.

00:20:03.390 --> 00:20:08.480
So here we have a photo of the
handsome Mr. Collins in 1969.

00:20:08.480 --> 00:20:14.400
I had the good fortune to
meet Mr. Collins in 2017.

00:20:14.400 --> 00:20:16.860
And this was really amazing,
it was an incredible experience

00:20:16.860 --> 00:20:19.850
because we virtually
put Michael Collins,

00:20:19.850 --> 00:20:23.430
the pilot of the command
module, back into the pilot seat

00:20:23.430 --> 00:20:25.650
which was just super,
super cool.

00:20:25.650 --> 00:20:28.690
So it really gives me goosebumps
that we were able to do that.

00:20:28.690 --> 00:20:32.010
And he was funny
because he basically said

00:20:32.010 --> 00:20:36.040
"Don't ask me what any of these
switches or buttons do anymore."

00:20:36.040 --> 00:20:42.500
But I don't believe that, I
think he knows what they all do.

00:20:42.500 --> 00:20:45.110
This is, I don't like
to play favorites,

00:20:45.110 --> 00:20:47.310
but this is really one
of my favorite objects,

00:20:47.310 --> 00:20:50.030
one of my favorite projects.

00:20:50.030 --> 00:20:52.150
This is, this object
is in the collection

00:20:52.150 --> 00:20:53.910
of the Freer-Sackler galleries.

00:20:53.910 --> 00:20:55.610
It's the cosmological Buddha.

00:20:55.610 --> 00:20:58.330
It's a standing,
robed Buddha figure

00:20:58.330 --> 00:21:00.310
that stands about 6 feet tall.

00:21:00.310 --> 00:21:02.830
It's about 1400 years old.

00:21:02.830 --> 00:21:04.410
And if you walk into
the gallery,

00:21:04.410 --> 00:21:07.050
it's just a really
compelling object.

00:21:07.050 --> 00:21:11.190
Every inch of all the surfaces
has this [inaudible] leaf

00:21:11.190 --> 00:21:13.900
carving across the
entire robed figure.

00:21:13.900 --> 00:21:16.570
Now if you read the
text panel that's

00:21:16.570 --> 00:21:19.870
on exhibit, it's
maybe 500 words.

00:21:19.870 --> 00:21:22.800
And it doesn't even scratch
the surface of the volumes

00:21:22.800 --> 00:21:25.600
of information that are
encoded in this object.

00:21:25.600 --> 00:21:29.800
And the curator thinks that
this object was created

00:21:29.800 --> 00:21:34.200
as a teaching tool to
teach about Buddhism.

00:21:34.200 --> 00:21:38.100
So the traditional method
of documentation is ink

00:21:38.100 --> 00:21:40.110
and charcoal rubbings on paper.

00:21:40.110 --> 00:21:43.140
So 100 years ago, this was
an acceptable thing to do,

00:21:43.140 --> 00:21:45.960
it was a way to kind of show
these scenes graphically

00:21:45.960 --> 00:21:49.280
and share them by mailing
the pieces of paper around.

00:21:49.280 --> 00:21:52.690
By today's conservation
standards, this is not something

00:21:52.690 --> 00:21:55.100
that they want happening.

00:21:55.100 --> 00:21:59.640
So we use the laser scanner,
some photogrammetry tools,

00:21:59.640 --> 00:22:02.200
we combine those two
different datasets,

00:22:02.200 --> 00:22:04.960
and we passed off some draft
renderings to the curator,

00:22:04.960 --> 00:22:10.330
Keith Wilson, and he started
to decode this object and sort

00:22:10.330 --> 00:22:13.060
of circling different
areas that he knows connect

00:22:13.060 --> 00:22:15.760
to different areas of
Buddhist scripture.

00:22:15.760 --> 00:22:17.500
So that was kind of
like the back and forth

00:22:17.500 --> 00:22:19.380
and conversation we had

00:22:19.380 --> 00:22:23.310
to create the narrative
using the 3D model

00:22:23.310 --> 00:22:25.400
as a storytelling tool.

00:22:25.400 --> 00:22:28.440
So photograph on the left,
3D rendering of our data

00:22:28.440 --> 00:22:31.800
on the right with the
stone texture stripped out.

00:22:31.800 --> 00:22:34.650
And then we're able to do
other things, you know?

00:22:34.650 --> 00:22:39.010
Think about the way we have a
globe and then we could unwrap

00:22:39.010 --> 00:22:41.200
that into 2D space
to create a map.

00:22:41.200 --> 00:22:43.400
We're doing a similar
thing with this object

00:22:43.400 --> 00:22:46.570
where we have a 3D scan of
this cosmological Buddha

00:22:46.570 --> 00:22:49.660
with an incredible amount of
information being conveyed

00:22:49.660 --> 00:22:51.080
through these carvings.

00:22:51.080 --> 00:22:55.120
So we essentially unwrapped
that 3D model into flat space.

00:22:55.120 --> 00:22:56.420
So for the first time,

00:22:56.420 --> 00:22:59.760
we can look into that
narrative in one go.

00:22:59.760 --> 00:23:04.330
Alright so we're going to
jump into the live demo.

00:23:04.330 --> 00:23:06.280
Let's see if this works.

00:23:06.280 --> 00:23:07.980
It's working.

00:23:07.980 --> 00:23:10.710
Okay, so our 3D viewer, this
is something else we worked

00:23:10.710 --> 00:23:12.120
on in collaboration
with Autodesk.

00:23:12.120 --> 00:23:13.810
So we're able to do some things.

00:23:13.810 --> 00:23:16.360
This is happening in my browser.

00:23:16.360 --> 00:23:20.670
So if you go to 3D.SI.edu,
you can explore our 3D models.

00:23:20.670 --> 00:23:23.300
So we can do some things
like look at the shoulders.

00:23:23.300 --> 00:23:25.770
This is something you couldn't
do if you're in the gallery

00:23:25.770 --> 00:23:27.070
because it's on a pedestal.

00:23:27.070 --> 00:23:28.810
Unless you were really tall.

00:23:28.810 --> 00:23:31.790
You couldn't really see
that part of the object.

00:23:31.790 --> 00:23:35.320
And we, I won't go into all
these different tool sets,

00:23:35.320 --> 00:23:37.280
but I'll just highlight
a few of them.

00:23:37.280 --> 00:23:38.580
We could do a number of things.

00:23:38.580 --> 00:23:42.420
We could turn off
that stone texture

00:23:42.420 --> 00:23:44.630
and look at just the geometry.

00:23:44.630 --> 00:23:48.000
And then I can adjust the
ambient inclusion apps.

00:23:48.000 --> 00:23:49.980
And I could start to pull
out details that are hard

00:23:49.980 --> 00:23:51.750
to see with the naked eye.

00:23:51.750 --> 00:23:53.700
Now this looks like
a Photoshop filter,

00:23:53.700 --> 00:23:56.170
but it's actually an algorithm
that's darkening areas

00:23:56.170 --> 00:23:59.840
of high curvature and lightning
areas of low curvature.

00:23:59.840 --> 00:24:03.800
And this tool in particular was
very helpful for the researcher

00:24:03.800 --> 00:24:06.350
to see details that were
hard to see otherwise.

00:24:06.350 --> 00:24:10.670
So I'm going to pull that back.

00:24:18.290 --> 00:24:19.740
Another thing we're able to do

00:24:19.740 --> 00:24:23.440
with the 3D viewer is we can
click on the hot spot areas.

00:24:23.440 --> 00:24:25.280
And now we can start to click

00:24:25.280 --> 00:24:28.050
around on these different
hot spot areas, and we start

00:24:28.050 --> 00:24:29.990
to discover that down low,

00:24:29.990 --> 00:24:32.130
there are all these
scenes depicting hell

00:24:32.130 --> 00:24:35.720
up to the animal
kingdom to humans,

00:24:35.720 --> 00:24:39.190
all the way up to enlightenment
around the shoulders.

00:24:43.250 --> 00:24:45.590
And then we also
worked with the curator,

00:24:45.590 --> 00:24:49.040
and really the whole
goal of this project was

00:24:49.040 --> 00:24:53.850
to marry the power of 3D assets
that we could deliver those

00:24:53.850 --> 00:24:57.480
over the web, and really connect
it with the content expert

00:24:57.480 --> 00:24:59.700
so we could do storytelling.

00:24:59.700 --> 00:25:01.630
So you can see we have
about seven different,

00:25:01.630 --> 00:25:04.930
what we're calling guided tours.

00:25:04.930 --> 00:25:07.790
And with the guided tour,
we can essentially click

00:25:07.790 --> 00:25:10.030
through these different
viewpoints

00:25:10.030 --> 00:25:12.680
that we're zooming to, and then
we have additional information

00:25:12.680 --> 00:25:14.550
popping up on the right.

00:25:14.550 --> 00:25:16.400
At this point, we're
working with the curator

00:25:16.400 --> 00:25:19.160
in creating these
tours behind the sense.

00:25:19.160 --> 00:25:22.970
Our dream is to open up this
functionality so that anyone,

00:25:22.970 --> 00:25:25.010
any scholar or teacher,

00:25:25.010 --> 00:25:29.230
can create these 3D
guided tours on their own.

00:25:29.230 --> 00:25:31.310
So that's one of our dreams

00:25:31.310 --> 00:25:33.440
and something we're
trying to work towards.

00:25:33.440 --> 00:25:39.370
So you can see we have
a lot of functionality

00:25:39.370 --> 00:25:41.260
that you would normally
would see in 3D software

00:25:41.260 --> 00:25:44.050
and this is just
happening in a browser.

00:25:44.050 --> 00:25:47.720
And then we have, we can
adjust lighting conditions.

00:25:47.720 --> 00:25:50.640
We can also take
measurements on the model.

00:25:52.950 --> 00:25:55.520
And we can also do things,

00:25:55.520 --> 00:25:59.280
for this model the cross-section
tool might not be super helpful,

00:25:59.280 --> 00:26:02.310
but we can adjust the crawl
sections and maybe examine

00:26:02.310 --> 00:26:05.500
that cavity and take
a measurement there.

00:26:05.500 --> 00:26:09.450
And then with all of these
parameters I just adjusted,

00:26:09.450 --> 00:26:12.930
we click the share button and
a unique URL is generated,

00:26:12.930 --> 00:26:14.910
so I can share the scene.

00:26:14.910 --> 00:26:18.240
Or I can grab the embed code and
we can bed this in our website

00:26:18.240 --> 00:26:21.970
and our blog in the same way
we would embed a YouTube video.

00:26:27.080 --> 00:26:30.140
So the five projects
I just described,

00:26:30.140 --> 00:26:31.440
that was really our strategy.

00:26:31.440 --> 00:26:32.780
Because we're a five
person team.

00:26:32.780 --> 00:26:36.020
And our big question was how
does a five person team have an

00:26:36.020 --> 00:26:39.200
impact on an institution as
large as the Smithsonian.

00:26:39.200 --> 00:26:40.980
So we would go big
on these projects,

00:26:40.980 --> 00:26:45.110
like the command module,
the cosmological Buddha,

00:26:45.110 --> 00:26:46.410
and really what we're
trying to do

00:26:46.410 --> 00:26:50.080
over the next two years is
how do we document entire

00:26:50.080 --> 00:26:52.200
collections of Smithsonian
objects?

00:26:52.200 --> 00:26:55.390
So we already have
precedent with conveyor belts

00:26:55.390 --> 00:26:58.100
for 2D digitization efforts.

00:26:58.100 --> 00:27:01.280
We're working with Virginia
Tech and you could see

00:27:01.280 --> 00:27:05.140
in the top left hand corner,
that's kind of a design document

00:27:05.140 --> 00:27:07.260
that involves the robotic
arm that's grabbing

00:27:07.260 --> 00:27:10.680
onto standardized containers
that hold wet specimens.

00:27:10.680 --> 00:27:14.230
So we can micro CT scan
what specimen collections.

00:27:14.230 --> 00:27:18.550
And next week, I'm actually
off to Darmstadt in Germany.

00:27:18.550 --> 00:27:21.410
There's a group,
the Fraunhofer IGD,

00:27:21.410 --> 00:27:23.970
they've created an
automated 3D scanning device

00:27:23.970 --> 00:27:27.160
that we're investigating
and looking possibly

00:27:27.160 --> 00:27:28.990
to bring into the Smithsonian.

00:27:28.990 --> 00:27:32.530
So we think that, you know, we
have this incredible opportunity

00:27:32.530 --> 00:27:36.250
to marry this technology with
all these incredible objects

00:27:36.250 --> 00:27:37.980
that we have behind the scenes.

00:27:37.980 --> 00:27:40.660
As well as the curators, the
researchers, the educators

00:27:40.660 --> 00:27:42.640
who have studied these objects.

00:27:42.640 --> 00:27:43.940
And we think the potential

00:27:43.940 --> 00:27:47.530
of combining these things
will be very powerful.

00:27:47.530 --> 00:27:49.650
So a great quote

00:27:49.650 --> 00:27:53.920
by my entomologist friend Matt
Buffington, "You don't have

00:27:53.920 --> 00:27:55.440
to shake a tree in
the rainforest

00:27:55.440 --> 00:27:56.740
to discover a new species.

00:27:56.740 --> 00:27:58.440
You can do it right
here in the collections

00:27:58.440 --> 00:27:59.970
of the natural history museum."

00:27:59.970 --> 00:28:03.100
And this has happened
a number of times.

00:28:03.100 --> 00:28:06.130
Where a new species was
discovered and it was sitting

00:28:06.130 --> 00:28:10.870
in a drawer or on a shelf
in suburban Maryland.

00:28:12.120 --> 00:28:13.810
So our existing pipeline,

00:28:13.810 --> 00:28:16.740
everything we do right
now is hard and manual.

00:28:16.740 --> 00:28:20.480
So we're using tools that were
not really fit for our purpose,

00:28:20.480 --> 00:28:23.550
we're adapting from
Hollywood engineering

00:28:23.550 --> 00:28:25.090
and aerospace industries

00:28:25.090 --> 00:28:27.340
and we're building
pipelines around that.

00:28:27.340 --> 00:28:31.220
It requires a high degree
of expertise to 3D scan,

00:28:31.220 --> 00:28:33.530
the processing, even more so.

00:28:33.530 --> 00:28:36.540
And sometimes up to 10 different
pieces of software that we have

00:28:36.540 --> 00:28:38.480
to use to create
these derivatives

00:28:38.480 --> 00:28:40.430
so that we can deliver
on mobile platforms,

00:28:40.430 --> 00:28:43.550
3D printing platforms,
and virtual reality.

00:28:43.550 --> 00:28:47.200
And then we have this amazing
viewer that we've created

00:28:47.200 --> 00:28:48.720
in collaboration with Autodesk.

00:28:48.720 --> 00:28:50.360
But it's just one platform.

00:28:50.360 --> 00:28:53.410
So we're hoping to
expand upon that.

00:28:53.410 --> 00:28:55.780
So our new pipeline that
we're very excited about

00:28:55.780 --> 00:28:57.680
and everything you
see here, this is kind

00:28:57.680 --> 00:29:00.230
of a greatly simplified
version of our platform,

00:29:00.230 --> 00:29:02.760
this will all be open sourced.

00:29:02.760 --> 00:29:04.520
And it's built in
a very modular way

00:29:04.520 --> 00:29:06.110
because we know this
technology's going

00:29:06.110 --> 00:29:09.640
to evolve quickly and we need to
be able to swap out components

00:29:09.640 --> 00:29:12.960
as opposed to creating
some monolithic pipeline

00:29:12.960 --> 00:29:17.250
that would be difficult to
maintain and update over time.

00:29:17.250 --> 00:29:19.470
So we're using a number
of motion control systems.

00:29:19.470 --> 00:29:23.640
Here we have a cast of Abraham
Lincoln by Leonard Volk.

00:29:23.640 --> 00:29:26.780
It's going to guide us through
this new proposed pipeline.

00:29:26.780 --> 00:29:29.960
We have an array of
censors and a turntable

00:29:29.960 --> 00:29:33.120
so that we can put an object
on the table and 3D scan

00:29:33.120 --> 00:29:37.310
that object, remaining a lot
of the manual work of capture.

00:29:37.310 --> 00:29:40.370
We're also creating
a 3D repository,

00:29:40.370 --> 00:29:43.560
so 3D metadata standards
simply don't exist.

00:29:43.560 --> 00:29:46.000
So we have the Smithsonian
1.0 version

00:29:46.000 --> 00:29:49.250
of a 3D capture metadata
model that we've established,

00:29:49.250 --> 00:29:50.550
and we're working with a number

00:29:50.550 --> 00:29:52.400
of other universities
and museums.

00:29:52.400 --> 00:29:55.050
So this not really the
standard yet, but it's a start.

00:29:55.050 --> 00:29:58.530
And that informs the development
of this 3D repository

00:29:58.530 --> 00:30:02.110
that we're creating, which
will also be open sourced.

00:30:02.110 --> 00:30:03.410
And then the automated pipeline.

00:30:03.410 --> 00:30:06.150
This is really one of the
most important components.

00:30:06.150 --> 00:30:08.790
If you spend an hour 3D
scanning an object, you're going

00:30:08.790 --> 00:30:11.130
to spend 10 hours
processing that data.

00:30:11.130 --> 00:30:13.710
So building an automation
is really key if we want

00:30:13.710 --> 00:30:16.000
to scale up this effort.

00:30:16.000 --> 00:30:19.620
And then a viewer
agnostic authoring tool.

00:30:19.620 --> 00:30:22.320
So what that means really
is that if I'm working

00:30:22.320 --> 00:30:26.120
with Dr. Keith Wilson and
he's creating this experience

00:30:26.120 --> 00:30:29.620
around the cosmological Buddha,
if he's adding annotations,

00:30:29.620 --> 00:30:33.380
creating storytelling, I want to
be able to save the coordinates

00:30:33.380 --> 00:30:35.620
of everyone of those annotations

00:30:35.620 --> 00:30:38.670
so that this would not just be
an experience that's contained

00:30:38.670 --> 00:30:40.630
in this one-off platform.

00:30:40.630 --> 00:30:43.680
But that could then proliferate
to other 3D platforms.

00:30:43.680 --> 00:30:47.140
And also be archived and
become a part or a history

00:30:47.140 --> 00:30:50.470
of the 3D model and a
record of the 3D model.

00:30:50.470 --> 00:30:52.490
So that viewer agnostic
authoring tool is

00:30:52.490 --> 00:30:53.790
really important.

00:30:53.790 --> 00:30:55.310
Because trying to stay on top

00:30:55.310 --> 00:30:59.650
of 3D viewing platforms is
kind of a sisyphean task.

00:30:59.650 --> 00:31:01.810
And the Smithsonian
really isn't poised,

00:31:01.810 --> 00:31:04.380
we're not a software company.

00:31:04.380 --> 00:31:06.590
So that tool is super important.

00:31:06.590 --> 00:31:09.640
And that ultimately feeds to
this Smithsonian 3D portal

00:31:09.640 --> 00:31:10.940
that we started developing.

00:31:10.940 --> 00:31:12.660
So this is a Smithsonian 3D API,

00:31:12.660 --> 00:31:15.030
an application programming
interface.

00:31:15.030 --> 00:31:18.360
So that we have our
scan of Abraham Lincoln

00:31:18.360 --> 00:31:20.250
or a collection of scans.

00:31:20.250 --> 00:31:23.540
And that we want to deliver to
all of our platforms right now.

00:31:23.540 --> 00:31:28.850
So we see this ecosystem
of platforms that except

00:31:28.850 --> 00:31:32.450
and leverage 3D data growing
exponentially right now.

00:31:32.450 --> 00:31:34.840
We're also developing an
open serious 3D viewer.

00:31:34.840 --> 00:31:37.260
So our current viewer's
not open source.

00:31:37.260 --> 00:31:39.640
Our new viewer will
be open source.

00:31:39.640 --> 00:31:42.030
And then we want to connect
to web based platforms.

00:31:42.030 --> 00:31:45.520
We see Google, Bing, Sketchfab,

00:31:45.520 --> 00:31:48.450
a number of these web
based 3D viewing solutions

00:31:48.450 --> 00:31:49.930
that are becoming available.

00:31:49.930 --> 00:31:51.230
Wikimedia just announced

00:31:51.230 --> 00:31:55.000
that they're accepting 3D
data I think three weeks ago.

00:31:55.000 --> 00:31:56.300
And Facebook as well.

00:31:56.300 --> 00:31:58.600
So you can now drag
and drop a 3D model

00:31:58.600 --> 00:32:02.510
into your Facebook news feed
the same way you would an image

00:32:02.510 --> 00:32:04.660
or a video of your kids.

00:32:04.660 --> 00:32:07.180
Research platforms
like I Dig Bio

00:32:07.180 --> 00:32:09.500
and Duke University's
MorphoSource we're looking

00:32:09.500 --> 00:32:14.070
at connecting to, as well as
providing Smithsonian 3D content

00:32:14.070 --> 00:32:18.610
as a resource for app developers
for IOS and Android devices.

00:32:18.610 --> 00:32:21.830
Desktop applications
like Microsoft Office.

00:32:21.830 --> 00:32:24.420
Apparently Microsoft
Office is 3D ready.

00:32:24.420 --> 00:32:26.940
So not a lot of people know
that, but you can just drag

00:32:26.940 --> 00:32:30.110
and drop a 3D model
into PowerPoint now.

00:32:30.110 --> 00:32:32.700
3D printing platforms,
and then VR

00:32:32.700 --> 00:32:34.570
and AR I think is
incredibly exciting.

00:32:34.570 --> 00:32:37.480
There's a tremendous amount
of hype around VR right now.

00:32:37.480 --> 00:32:40.490
But I think, you know, if
you have a chance to get

00:32:40.490 --> 00:32:43.590
into a VR system, you
know, if you're looking

00:32:43.590 --> 00:32:44.890
at the right experience,

00:32:44.890 --> 00:32:47.430
for me the powerful experience
was the command module.

00:32:47.430 --> 00:32:50.970
Actually feeling that
like what it's like to be

00:32:50.970 --> 00:32:54.090
in the command module and just
that cramped space and looking

00:32:54.090 --> 00:32:55.390
at all these switches.

00:32:55.390 --> 00:32:57.170
And just, it's mind boggling.

00:32:57.170 --> 00:33:01.590
And then different cloud
based softwares as well.

00:33:01.590 --> 00:33:04.150
We're looking at connecting to.

00:33:04.150 --> 00:33:06.310
So future launches.

00:33:06.310 --> 00:33:09.110
We're partnering
with the Hydrous,

00:33:09.110 --> 00:33:11.840
that's a non-profit
out of California.

00:33:11.840 --> 00:33:17.870
That uses different types of
technology to allow people

00:33:17.870 --> 00:33:20.430
to have an emotional
connection to the oceans

00:33:20.430 --> 00:33:22.540
and to coral reef
bleaching events.

00:33:22.540 --> 00:33:25.970
So our team at the Smithsonian,
we're 3D scanning a collection

00:33:25.970 --> 00:33:28.370
of corals that was
collected over 100 years ago,

00:33:28.370 --> 00:33:29.690
so that's kind of the benchmark

00:33:29.690 --> 00:33:33.260
of where these species
should be pre-climate change.

00:33:33.260 --> 00:33:36.040
Dealing with and then
working with the Hydrous.

00:33:36.040 --> 00:33:39.440
And their team is basically
doing underwater 3D scanning

00:33:39.440 --> 00:33:41.340
and virtual reality capture

00:33:41.340 --> 00:33:43.010
of these coral reef
bleaching events.

00:33:43.010 --> 00:33:46.350
This is an exciting
project for us.

00:33:46.350 --> 00:33:49.260
We also had a successful
Kickstarter campaign

00:33:49.260 --> 00:33:53.010
that we collaborated with
the air and space museum,

00:33:53.010 --> 00:33:55.830
this involves documenting
Neil Armstrong's spacesuit,

00:33:55.830 --> 00:33:59.210
making that data
available to the world.

00:33:59.210 --> 00:34:00.960
And then the nation's T Rex.

00:34:00.960 --> 00:34:02.970
This is a fun one.

00:34:02.970 --> 00:34:04.890
So this was scanned
a few years ago,

00:34:04.890 --> 00:34:06.190
but there's an enormous amount

00:34:06.190 --> 00:34:07.890
of processing that
has to happen.

00:34:07.890 --> 00:34:12.130
And we scanned every single
bone before the object was

00:34:12.130 --> 00:34:15.370
articulated, and then we scanned
the articulated specimen.

00:34:15.370 --> 00:34:16.950
So we're working with the
natural history museum

00:34:16.950 --> 00:34:18.250
and a launch date.

00:34:18.250 --> 00:34:22.300
But soon you too can have
your own nation's T Rex

00:34:22.300 --> 00:34:23.700
in your living room.

00:34:23.700 --> 00:34:27.440
This is a very recent
announcement.

00:34:27.440 --> 00:34:28.740
So just two days ago,

00:34:28.740 --> 00:34:30.580
we announced our
partnership with Google.

00:34:30.580 --> 00:34:34.120
This involves light
field capture.

00:34:34.120 --> 00:34:35.690
And light field capture
is basically,

00:34:35.690 --> 00:34:36.990
it's a little bit different

00:34:36.990 --> 00:34:39.590
from the 3D scanning technology
I was just talking about.

00:34:39.590 --> 00:34:42.960
It's documenting the way
that light hits objects

00:34:42.960 --> 00:34:44.550
and is reflected
back into our eyes.

00:34:44.550 --> 00:34:48.130
So we're actually doing a form
of essentially light scanning.

00:34:48.130 --> 00:34:49.430
And that's really great

00:34:49.430 --> 00:34:52.500
for hyper-realistic
virtual reality experiences.

00:34:52.500 --> 00:34:56.210
And it's good to see that that
project is getting good press

00:34:56.210 --> 00:34:59.440
with the MIT media review
as well as the Verge.

00:34:59.440 --> 00:35:02.740
And we were working with Paul
Debevec, he's formally of USC,

00:35:02.740 --> 00:35:09.590
he helped us 3D scan Barack
Obama a few years ago.

00:35:11.640 --> 00:35:14.730
So again, if you want to
check out more of our work,

00:35:14.730 --> 00:35:17.430
learn more, you can simply
Google "Smithsonian 3D."

00:35:17.430 --> 00:35:21.830
And something I'm really
interested in is reaching

00:35:21.830 --> 00:35:23.630
out to you, the community,
you know,

00:35:23.630 --> 00:35:26.810
we've built all these different
tools within our 3D viewer.

00:35:26.810 --> 00:35:28.970
But we haven't thought
of everything.

00:35:28.970 --> 00:35:31.670
So if you're interested,
if you have the time,

00:35:31.670 --> 00:35:32.970
I'll leave this up on screen.

00:35:32.970 --> 00:35:34.270
If you want to take a picture

00:35:34.270 --> 00:35:36.290
and if you have a QR code
reader, this will link you

00:35:36.290 --> 00:35:39.390
to a survey, so we're really
interested in feedback.

00:35:39.390 --> 00:35:46.050
Or you could simply just jot
down the Bitly, or tweet us.

00:35:46.050 --> 00:35:48.390
And at that, I want to thank
you all for your attention

00:35:48.390 --> 00:35:50.510
and it's been an
honor to be here.

00:35:50.510 --> 00:35:59.270
[ Applause ]

00:35:59.270 --> 00:36:02.960
&gt;&gt; This has been a presentation
of the Library of Congress.

00:36:02.960 --> 00:36:05.340
Visit us at LOC.gov.

