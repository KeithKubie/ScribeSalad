WEBVTT

1
00:00:00.030 --> 00:00:04.230
Oh,
so this is where free and open source software is just essential.

2
00:00:04.260 --> 00:00:05.850
Like the big networks,

3
00:00:05.970 --> 00:00:10.930
there's no excuse for them not to be sharing their software.
Right.

4
00:00:11.030 --> 00:00:14.310
It's like when you're a public forum on that scale,

5
00:00:15.390 --> 00:00:18.120
the community just has a right to know what the algorithms are doing.

6
00:00:18.270 --> 00:00:22.200
So you think that they're not sharing their software because their software is

7
00:00:22.440 --> 00:00:26.940
encoded in designed to spy on you and extract information and sell that

8
00:00:26.941 --> 00:00:30.780
information?
Partially like when Jamie gives up your contacts,

9
00:00:31.410 --> 00:00:33.480
when he signs up for an APP and he says,
yes,

10
00:00:33.720 --> 00:00:35.880
you can get access to all my contacts.

11
00:00:35.910 --> 00:00:38.070
There's a lot of reason and they don't want people to compete with them.

12
00:00:38.071 --> 00:00:40.800
Like anyone could actually take all of our code and make their own social

13
00:00:40.801 --> 00:00:41.790
network and compete with us.

14
00:00:42.690 --> 00:00:45.720
They could set up on their own servers and we encourage that.

15
00:00:45.720 --> 00:00:50.670
That's what like the Fed averse is called.
That's what Elon Musk does with Tesla,

16
00:00:50.820 --> 00:00:53.460
all of his electric patents for electric cars.

17
00:00:53.490 --> 00:00:55.780
I think that he opened up the pants.
I don't think if he,

18
00:00:55.890 --> 00:01:00.030
he opened sourced all the,
the code of the car.
Right.

19
00:01:00.031 --> 00:01:03.840
He's definitely in moving in the right direction of like he wants to build the

20
00:01:03.841 --> 00:01:08.520
market.
Yes.
And he also wants to save the world.
I mean he legitimately has any,

21
00:01:08.550 --> 00:01:12.630
also has a shitload of money and was kind enough plumbing.
Yeah.
Yeah.
That's,

22
00:01:12.750 --> 00:01:14.430
I think that's a big factor with those guys.

23
00:01:14.670 --> 00:01:19.670
But don't you think that it's almost like it's going to help whatever network

24
00:01:20.730 --> 00:01:25.230
does that Oh,
is more transparent,
stop spying on people.

25
00:01:25.470 --> 00:01:29.760
Is More community run and evolved?

26
00:01:30.000 --> 00:01:33.480
Wouldn't that be the network that you would think humanity would want to stick

27
00:01:33.481 --> 00:01:37.710
with in the longterm?
Like wouldn't that be a good move of them?
Yes and no.

28
00:01:37.890 --> 00:01:39.120
For the average person,

29
00:01:39.390 --> 00:01:43.050
what are they losing when they get on Facebook or Google?

30
00:01:44.220 --> 00:01:47.730
What are the,
what's bad?
What happened?
Now their legs are going down,

31
00:01:48.060 --> 00:01:50.910
everybody's likes are going down.
And that makes everyone very sad.

32
00:01:50.970 --> 00:01:52.740
What do you mean will the algorithms,

33
00:01:52.770 --> 00:01:57.770
you're only reaching 5% of your own followers organically on Facebook now.

34
00:01:58.230 --> 00:02:01.590
And they're starting to change the chronological feed on Instagram too.

35
00:02:02.280 --> 00:02:06.630
And they know that this causes depression and they're still doing it because

36
00:02:06.631 --> 00:02:09.870
they know that the,
you know,
they're,

37
00:02:10.050 --> 00:02:14.370
they think they're better at showing you what you want to see than you are and

38
00:02:14.371 --> 00:02:15.330
they want to make money from it.

39
00:02:15.510 --> 00:02:17.970
What do you mean by they know that this causes depression?

40
00:02:18.240 --> 00:02:23.240
They've done studies about mental health in relation to,

41
00:02:23.401 --> 00:02:28.401
actually Facebook got exposed like five years ago for doing a secret study on

42
00:02:28.771 --> 00:02:33.120
like a few million users where they were injecting both positive and negative

43
00:02:33.121 --> 00:02:36.960
content into the newsfeed and they proved that they could affect people's moods.

44
00:02:37.080 --> 00:02:40.140
This was with Princeton,
there's a huge backlash and they're like,
oh,
sorry.

45
00:02:41.250 --> 00:02:43.800
Whoops.
Right,

46
00:02:43.801 --> 00:02:47.250
but this isn't a injecting negative or positive content.

47
00:02:47.251 --> 00:02:52.251
This is just moving these images or these posts around so that less people see

48
00:02:52.561 --> 00:02:54.660
them.
There's two different topics there.

49
00:02:55.140 --> 00:03:00.140
The basic news feed on Facebook is now a mysterious conglomeration of thousands

50
00:03:01.661 --> 00:03:06.430
of variables,
which we don't know.
And,
but additionally,
like a few years ago,

51
00:03:06.431 --> 00:03:11.431
they were exposed for having been experimenting with people's brains.

52
00:03:12.310 --> 00:03:16.090
That's right.
I remember that now.
I remember that now that,
that that's right.

53
00:03:16.510 --> 00:03:21.260
Yeah.
I remember thinking like,
wow,
that's kinda creepy.
[inaudible]

54
00:03:21.400 --> 00:03:25.090
the people that are on their site and they're not telling these people that are

55
00:03:25.091 --> 00:03:28.000
experimenting on them.
Yeah.
But do they,
I mean,

56
00:03:28.420 --> 00:03:32.950
if they're trying to make it better,
um,
do you think that they're really,

57
00:03:33.490 --> 00:03:36.100
that's a factor that it actually,
it actually could.
I mean,

58
00:03:36.101 --> 00:03:38.140
how does it cause depression if they're just,

59
00:03:38.170 --> 00:03:43.170
if your images or your posts are not being seen as by as many people have you

60
00:03:44.281 --> 00:03:49.281
talked to kids posting on social media and their reactions to how many likes

61
00:03:50.011 --> 00:03:54.450
they're getting,
they get very,

62
00:03:54.660 --> 00:03:57.510
very,
um,
concerned.

63
00:03:57.750 --> 00:04:02.310
Well that seems like more of a problem with that.
It is both.
It's not,

64
00:04:02.340 --> 00:04:06.990
it is on both sides being addicted to likes as some sort of,
uh,

65
00:04:07.560 --> 00:04:09.660
you know,
to weird dopamine.
Yeah.
Right.

66
00:04:09.690 --> 00:04:13.350
It's not healthy and we need to learn to not care about that.

67
00:04:13.740 --> 00:04:18.300
But I think that the core purpose of the social network is to subscribe to

68
00:04:18.301 --> 00:04:21.420
someone and see their stuff.
And when people subscribe to you,

69
00:04:21.870 --> 00:04:23.460
they see your stuff.
Right?

70
00:04:23.490 --> 00:04:28.490
So when you spend years building up a following on social media and say earn

71
00:04:29.071 --> 00:04:32.880
100,000 followers or something and then suddenly the network says,

72
00:04:32.950 --> 00:04:37.260
hmm Nah,
now your friends can't see that anymore.

73
00:04:38.340 --> 00:04:39.980
That's not cool.
And,

74
00:04:40.160 --> 00:04:44.160
and even like Twitter's default newsfeed is no longer chronological.

75
00:04:44.190 --> 00:04:48.720
You have to click it to go chronological and then it defaults back to their

76
00:04:48.721 --> 00:04:52.890
weird algorithm thing.
So we're saying look,
100% organic,
chronological,

77
00:04:52.891 --> 00:04:56.910
raw forever as default.
And then if you want to curate,
you know,

78
00:04:56.911 --> 00:05:00.450
algorithms or have recommended stuff come in as a alternative,
fine.

79
00:05:00.810 --> 00:05:05.160
But that is the core purpose of social media is to connect with people that

80
00:05:05.161 --> 00:05:08.630
follow you and the other way around.
What do you think the purpose is?

81
00:05:08.631 --> 00:05:13.580
Like why do you think Facebook would decide to have things not in chronological

82
00:05:13.581 --> 00:05:16.490
order and only be seen by 5% of your followers?

83
00:05:16.490 --> 00:05:20.390
Like what will it be the benefit of that for them?
Revenue.
Revenue.
How so?

84
00:05:20.840 --> 00:05:21.920
How's that generate revenue?

85
00:05:22.060 --> 00:05:27.060
They just know that they can keep you on the app better if you had less likes.

86
00:05:28.960 --> 00:05:32.380
No.
If your your stuff seen by less people,
it doesn't make sense.

87
00:05:33.070 --> 00:05:35.770
That's a good point.
It sort of works both ways.

88
00:05:35.771 --> 00:05:40.771
I think that they think they know the people that you're going to react to the

89
00:05:41.531 --> 00:05:45.370
most.
So as a consumer,
when you're getting that content,

90
00:05:46.630 --> 00:05:49.780
you know the algorithms are showing you what you typically like.

91
00:05:49.781 --> 00:05:50.614
Have you noticed that?

92
00:05:51.340 --> 00:05:55.750
I'm really not paying much attention but I don't believe you.
So yeah,

93
00:05:55.780 --> 00:06:00.680
for Creator it's hurting creators.
People who post are getting hurt.

94
00:06:00.890 --> 00:06:03.650
People who are sitting there just scrolling.

95
00:06:03.740 --> 00:06:08.740
They're the ones who are really getting addicted more so with the algorithms.

96
00:06:10.580 --> 00:06:12.380
So how are the people that are posting getting hurt?

97
00:06:12.380 --> 00:06:15.080
They're getting hurt because their stuff is being seen by last people.
Yeah,

98
00:06:15.260 --> 00:06:19.940
because it's not chronological and it's an organic cause.
It's curated.
Huh?

99
00:06:20.300 --> 00:06:23.390
But aren't they doing it because they think it's going to be a better and

100
00:06:23.850 --> 00:06:26.750
unexperienced?
It's more conducive to your life.
That's what they say.

101
00:06:26.930 --> 00:06:28.130
What do you think they're doing it for then?

102
00:06:28.250 --> 00:06:33.250
They're doing it because they have studied through looking at the data,

103
00:06:33.860 --> 00:06:36.170
how to keep people on the APP more.
Right?

104
00:06:36.171 --> 00:06:40.460
And that way is to give them like say if I Google or if I look at muscle cars on

105
00:06:40.461 --> 00:06:43.940
Instagram now if I go to my search,
it's all muscle car stuff.

106
00:06:44.570 --> 00:06:47.090
So that's what it is.
They say,
oh,
he likes that.
So we're going to,

107
00:06:47.120 --> 00:06:50.330
we're just going to give him a lot of that and I think that's okay as an

108
00:06:50.331 --> 00:06:53.720
alternative feed or to put that somewhere.

109
00:06:53.750 --> 00:06:57.440
I just think the core feed always needs to stay pure.
Hmm.

110
00:06:57.890 --> 00:07:02.510
Because otherwise you're just down the slippery slope again and understand just

111
00:07:02.511 --> 00:07:03.150
feeding their,

112
00:07:03.150 --> 00:07:07.040
they're injecting things into your head that you didn't ask for it.
Right.

113
00:07:07.070 --> 00:07:10.610
And they're doing it because they want to keep you around.
Yeah.
That makes sense.

114
00:07:11.480 --> 00:07:15.810
Um,
how many different companies are subscribing to that is,

115
00:07:15.820 --> 00:07:20.820
it seems like all the big ones were saying are curating and moving things around

116
00:07:20.841 --> 00:07:24.830
and all the big ones have an algorithm that's designed to keep you on board.

117
00:07:24.831 --> 00:07:27.560
Right.
And that's okay to pursue.

118
00:07:27.590 --> 00:07:30.530
I think there's really cool things you can do with AI and machine learning and

119
00:07:30.531 --> 00:07:33.950
algorithms that is really beneficial,

120
00:07:33.980 --> 00:07:38.980
but it's just taking away people's reach when they have worked years and years

121
00:07:38.991 --> 00:07:40.820
to achieve it.
It's not okay.

122
00:07:41.060 --> 00:07:46.060
Do you think that this is this marriage between something that is this social

123
00:07:46.131 --> 00:07:49.730
media network that's designed to allow people to communicate with each other and

124
00:07:49.731 --> 00:07:53.690
then commerce like this business,
like how do we maximize this business?

125
00:07:53.690 --> 00:07:55.400
How do we get more profit out of this business?

126
00:07:55.670 --> 00:07:57.470
How do we get these people to engage more?

127
00:07:57.890 --> 00:08:02.060
And then they start monkeying with the code and screwing with what you see and

128
00:08:02.061 --> 00:08:04.640
what you don't say.
You think that's what's happening?
Yeah,

129
00:08:04.820 --> 00:08:06.890
but in the short term it's probably working,

130
00:08:07.280 --> 00:08:09.650
but in the long term they're betraying everybody's trust.

131
00:08:09.651 --> 00:08:14.570
It has to be more of a consent based system.
So you know,
at least give people,

132
00:08:14.720 --> 00:08:18.470
well it should be a opt out by default and find,

133
00:08:18.471 --> 00:08:22.490
give me messages to opt in so that you can show me certain things.

134
00:08:22.491 --> 00:08:27.491
But this whole force forcing people into surveillance is,

135
00:08:28.400 --> 00:08:32.540
it just has to stop.
It's,
it's super scary.

136
00:08:32.910 --> 00:08:37.260
How's it super security you?
It's just too much power.
Mm.

137
00:08:37.760 --> 00:08:41.330
Yeah.
It's too much power for something that supposed to be silly,
right?

138
00:08:41.331 --> 00:08:42.680
Like what was Facebook supposed to do?

139
00:08:42.690 --> 00:08:45.950
Supposed to be some silly thing that you just can communicate with friends.

140
00:08:46.130 --> 00:08:49.340
It was,
but from the beginning,
all of these,

141
00:08:49.341 --> 00:08:53.060
none of these networks I've ever really been about the people of the networks.

142
00:08:53.061 --> 00:08:57.780
It's always been closed source since the inception.
So,

143
00:08:57.810 --> 00:09:01.050
but then you look at open networks out there,
you have Wikipedia,

144
00:09:01.530 --> 00:09:03.600
totally open source community.

145
00:09:03.601 --> 00:09:06.300
Ryan granted they have their issues with moderation.
Fine.

146
00:09:07.050 --> 00:09:10.830
But it's a top 10 website in the world is totally open sores,

147
00:09:10.831 --> 00:09:14.670
creative Commons content,
incredible human achievement,

148
00:09:15.330 --> 00:09:17.250
bitcoin,
open source money.

149
00:09:17.730 --> 00:09:22.730
Wordpress even is an open source CMS system that is like powering 25% of the

150
00:09:23.431 --> 00:09:27.540
Internet.
So why when that happened with social media it should,

151
00:09:27.570 --> 00:09:29.400
I mean this is where Mons hanging out.

152
00:09:29.460 --> 00:09:32.550
So we should all sort of collectively even own it.

153
00:09:33.180 --> 00:09:35.190
We did a an equity crowd funding round.

154
00:09:35.191 --> 00:09:39.630
So like thousands members of our community actually own the site.
Hm.
Now,

155
00:09:39.631 --> 00:09:43.680
how many people are on machines?
We have like a million and a half registered,

156
00:09:43.710 --> 00:09:46.650
like quarter million active.
Various we're,
we're,
we're small.

157
00:09:46.680 --> 00:09:51.680
But the weird thing is that even though we're a fraction of the size,

158
00:09:52.830 --> 00:09:56.610
especially smaller creators who come get better reach on minds than they do on

159
00:09:56.611 --> 00:10:00.360
Facebook and Twitter because we have this reward and incentive system sort of

160
00:10:00.361 --> 00:10:05.361
like gamified where you earn reach and you earn more of a voice for

161
00:10:07.171 --> 00:10:08.004
contributing.

162
00:10:08.160 --> 00:10:13.160
So like you could have a account on Twitter for 10 years in post thousands and

163
00:10:14.550 --> 00:10:17.250
thousands of tweets and you never hit that viral nerve and you just never,

164
00:10:17.580 --> 00:10:22.140
never really get much exposure.
So we're trying to help people be heard.

165
00:10:22.290 --> 00:10:25.950
And so you'll find a small creator who on other networks has no followers,

166
00:10:25.951 --> 00:10:27.830
have thousands and thousands of followers on mines.

167
00:10:29.160 --> 00:10:32.970
And what do you think you would like to do with mines in the future that you

168
00:10:32.971 --> 00:10:33.960
haven't been able to do yet?

169
00:10:35.640 --> 00:10:40.640
Engineer the control out of ourselves so that we aren't even in a position to

170
00:10:43.741 --> 00:10:46.350
really,
you know,

171
00:10:46.710 --> 00:10:51.420
take people stuffed down or what if someone posts your house and your

172
00:10:51.421 --> 00:10:53.550
information where your kids go to school?

173
00:10:53.580 --> 00:10:58.140
I think that on the central servers obviously yes,

174
00:10:58.141 --> 00:11:03.141
we're always going to moderate and if it's legal it can stay.

175
00:11:03.211 --> 00:11:05.010
If it's not illegal it can't.
But

176
00:11:06.510 --> 00:11:11.510
a decentralized social network is definitely where we have to go because,

177
00:11:12.050 --> 00:11:14.940
and yeah.
Okay.
It's,
it's scary.
And you know,
you've talked about this,

178
00:11:14.941 --> 00:11:18.390
like things are getting more transparent our lives.

179
00:11:18.391 --> 00:11:22.050
It's sort of like the inevitable evolution of technology.
I mean,

180
00:11:22.051 --> 00:11:25.020
how many hours a day do you stream a couple,
you know,

181
00:11:25.350 --> 00:11:29.220
25 years ago would you have thought you'd be sharing,
you know,

182
00:11:29.221 --> 00:11:32.460
20% of your life live streaming to,
you know,

183
00:11:32.461 --> 00:11:36.810
millions of people like you're,
our lives are becoming more transparent.

184
00:11:36.810 --> 00:11:40.110
Just inevitably it's just pulling us.
Yeah,
I agree.

185
00:11:40.170 --> 00:11:44.280
So you know,
Bitcoin Crypto,

186
00:11:45.300 --> 00:11:50.190
dat torrent,
Stipe,
torrent type architecture,

187
00:11:50.220 --> 00:11:54.040
that is just where we're going because it's more resilient,

188
00:11:54.790 --> 00:11:59.050
it's less censorship prone,
there's just benefits of it.

189
00:11:59.051 --> 00:12:03.400
I think that we can balance it to like maybe when you post,
you have a decision,

190
00:12:03.700 --> 00:12:07.180
do you want to be able to delete this at any point?
All right,
fine.

191
00:12:07.181 --> 00:12:10.600
Then you can post the central server.
Do you want this to get unleashed?
Yeah.

192
00:12:10.601 --> 00:12:14.170
It's scary because,
you know,
they're scary stuff on the Internet.

193
00:12:14.320 --> 00:12:18.550
It's already like that.
But,
you know,
getting into censorship more.

194
00:12:18.900 --> 00:12:23.900
Does censorship even solve the problem or does it make it worse?

195
00:12:24.160 --> 00:12:27.940
What problem?
The problem of crazy content,
illegal content does it,

196
00:12:27.941 --> 00:12:30.310
how could it make it worse?
Well,
I mean,

197
00:12:30.311 --> 00:12:34.750
it seems like it can often amplify radicalization.
The definitely can,
right?
Yeah.

198
00:12:34.780 --> 00:12:38.410
Yeah.
And it definitely,
um,
when you censor people,

199
00:12:38.680 --> 00:12:42.700
it just makes them aware that there's plot against them too.
Right?

200
00:12:43.150 --> 00:12:46.380
It's a lot of conservatives on Twitter filing that.
Somebody us,

201
00:12:46.381 --> 00:12:49.360
Sam Harris actually just sent me an article.
Um,

202
00:12:49.510 --> 00:12:54.040
there was a detailing the bias against conservatives on Twitter that they've

203
00:12:54.130 --> 00:12:55.450
actually done,
you know,

204
00:12:55.451 --> 00:13:00.451
like some real studying it and it's pretty demonstrated [inaudible] demonstrably

205
00:13:01.030 --> 00:13:04.330
it affects both the left and the right rail,
demonstrably.
Yeah.

206
00:13:04.390 --> 00:13:08.230
The way I'm saying it wrong.
Um,
but it's,
it affects the left than the right.

207
00:13:08.231 --> 00:13:10.100
For sure.
Yeah,
that's what Kyle was saying.

208
00:13:10.101 --> 00:13:13.340
I watched that video that he did and he's antiestablishment that seems to be

209
00:13:13.341 --> 00:13:15.920
getting targeted.
And so,
you know,

210
00:13:15.921 --> 00:13:20.810
Abby's been censored on face and being going to learn.
Um,
and yeah,

211
00:13:20.811 --> 00:13:22.730
this person today that,
I mean,

212
00:13:22.731 --> 00:13:25.880
most of the stuff coming out of our t is progressive,
which is weird.

213
00:13:25.880 --> 00:13:29.690
And who knows what kind of games are getting played behind the scenes with the

214
00:13:29.691 --> 00:13:34.550
rush.
I mean,
who knows?
But the point is they have a right to be there.

215
00:13:34.610 --> 00:13:39.290
And I mean,
look at,
this is not youtube fault,
but remember the youtube shooter,

216
00:13:40.550 --> 00:13:45.020
I mean she thought she was getting censored on Youtube and she went and brought

217
00:13:45.021 --> 00:13:46.700
a gun to the youtube headquarters.

218
00:13:47.360 --> 00:13:50.690
Like people get pissed when they get censored.

219
00:13:51.740 --> 00:13:54.120
It affects you.
Right.
But in her case,

220
00:13:54.121 --> 00:13:57.330
you're talking about a crazy person that loves being sensory people out there.

221
00:13:57.331 --> 00:13:59.100
Yeah,
no,
she,
she wasn't being,

222
00:13:59.110 --> 00:14:02.400
she was getting censored just like everybody else is getting soft censored on

223
00:14:02.401 --> 00:14:05.460
these networks.
Well,
she just thought wasn't,
she didn't,

224
00:14:05.461 --> 00:14:07.670
wasn't getting promoted the way she wanted to wait.

225
00:14:07.710 --> 00:14:10.100
I don't think anybody was actively doing anything at all.

226
00:14:10.101 --> 00:14:13.490
I'm not saying that her stuff was 10 saying that the soft censorship of the

227
00:14:13.491 --> 00:14:14.330
algorithms,

228
00:14:14.331 --> 00:14:19.070
people getting demonetized this has an impact on psychology.

229
00:14:19.460 --> 00:14:21.320
Okay.
I see what you're saying.
So it's,

230
00:14:21.321 --> 00:14:24.680
I'm not saying they were deliberately targeting her and it's horrible what

231
00:14:24.681 --> 00:14:28.730
happened,
but
yeah.
Mm.

232
00:14:28.760 --> 00:14:32.360
So what you're saying is that these algorithms that they use in order to

233
00:14:32.361 --> 00:14:35.870
maximize their revenue and give people things that they like,

234
00:14:35.930 --> 00:14:40.010
but actually takes away from things being posted chronologically,

235
00:14:40.250 --> 00:14:42.920
keep certain things from being seen by as many people.

236
00:14:42.921 --> 00:14:44.600
So it keeps him from being as viral,

237
00:14:44.601 --> 00:14:48.960
so keeps the whole thing from being ordered organic.
Yeah.
Yeah.

238
00:14:49.440 --> 00:14:51.650
Makes Sense.
Yeah.
It's,
uh,

239
00:14:51.710 --> 00:14:56.090
it gets to that point where we're realizing that all of these things,

240
00:14:56.091 --> 00:14:58.220
all these social media things are really recent.

241
00:14:58.730 --> 00:15:02.630
We've only had them for a few years and we don't necessarily know what the rules

242
00:15:02.631 --> 00:15:05.060
should or shouldn't be.
So it's good.
I mean,

243
00:15:05.061 --> 00:15:06.500
this is one of the reasons why I wanted to have you on.

244
00:15:06.770 --> 00:15:09.290
I wanted to find out where these upstarts,

245
00:15:09.291 --> 00:15:11.900
where these new people are coming into the game,
like minds,

246
00:15:12.170 --> 00:15:17.150
like where you're coming into the game from and what,
what is your position on?

247
00:15:17.150 --> 00:15:20.960
What's wrong with the current state of affairs?
Yeah.
Look,

248
00:15:20.961 --> 00:15:25.400
there is messed up stuff on social media.
Like I'm not,

249
00:15:26.030 --> 00:15:29.390
we'll get pigeonholed into being like,
oh,
you support all of this,

250
00:15:29.480 --> 00:15:33.640
this crazy stuff.
First of all,
most of the users on mines are like artists,

251
00:15:33.680 --> 00:15:36.020
musicians,
filmmakers,
activists,
journalists.

252
00:15:36.050 --> 00:15:37.460
Just trying to get their content out there.

253
00:15:37.660 --> 00:15:42.170
There's a very tiny minority of like actually,
you know,
crazy content.

254
00:15:42.650 --> 00:15:46.750
But when you say crazy content,
what do you mean?
You all right?
Yeah,
yeah.

255
00:15:46.780 --> 00:15:50.630
Or I mean,
I'm not even going to make decisions on what is and isn't crazy.

256
00:15:50.690 --> 00:15:52.340
That's not,
that's not my place,
but

257
00:15:54.570 --> 00:15:55.440
<v 1>the,</v>

258
00:15:57.390 --> 00:16:02.100
<v 0>it's been proven that censorship is not the answer.</v>

259
00:16:02.101 --> 00:16:03.690
I mean to look at the history of prohibition.

260
00:16:05.260 --> 00:16:05.480
<v 1>Okay.</v>

261
00:16:05.480 --> 00:16:09.320
<v 0>Yes.
It's,
it's you have digital content,
it's substances,
it's,</v>

262
00:16:09.800 --> 00:16:12.590
it's anything in from,
people want information.

263
00:16:12.620 --> 00:16:15.020
They want the ability to make the decision for themselves.

