WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.330
 in this capsule we will see how we 

00:00:01.860 --> 00:00:07.170
 can approach the problem the 

00:00:03.330 --> 00:00:09.870
 object recognition then we saw 

00:00:07.170 --> 00:00:11.610
 previously only from an image on 

00:00:09.870 --> 00:00:13.710
 could extract features 

00:00:11.610 --> 00:00:17.250
 histogram histogram app 

00:00:13.710 --> 00:00:19.320
 gradient which corresponds to calculate 

00:00:17.250 --> 00:00:22.260
 gradian exchange partition the image 

00:00:19.320 --> 00:00:23.939
 in multiple segments extract there in 

00:00:22.260 --> 00:00:25.740
 each of the segments a histogram of 

00:00:23.939 --> 00:00:29.099
 gaza that is there is finally 

00:00:25.740 --> 00:00:31.080
 convert all this story g from 

00:00:29.099 --> 00:00:33.570
 gardians there in water vector we 

00:00:31.080 --> 00:00:36.059
 could give as input a proud glaze 

00:00:33.570 --> 00:00:38.129
 linear as a tax collector a 

00:00:36.059 --> 00:00:40.200
 logistic regression oumaima casper no 

00:00:38.129 --> 00:00:43.940
 linear as a case on a body more 

00:00:40.200 --> 00:00:43.940
 near neighbor or a neural network 

00:00:44.539 --> 00:00:49.250
 so that's a way to solve by 

00:00:47.940 --> 00:00:52.199
 example the problem of recognition 

00:00:49.250 --> 00:00:56.160
 of objects so this problem here corresponds 

00:00:52.199 --> 00:00:58.379
 to take an image and to identify if 

00:00:56.160 --> 00:00:59.910
 a certain type of object is beautiful and 

00:00:58.379 --> 00:01:02.280
 well in the picture 

00:00:59.910 --> 00:01:03.809
 or not for example no need to 

00:01:02.280 --> 00:01:07.170
 object recognition this is the 

00:01:03.809 --> 00:01:08.580
 pedestrian recognition have created a 

00:01:07.170 --> 00:01:10.799
 image and one would like to identified in 

00:01:08.580 --> 00:01:13.080
 the image if they find a 

00:01:10.799 --> 00:01:15.869
 pedestrian or not so what can we do 

00:01:13.080 --> 00:01:17.549
 that's the problem 

00:01:15.869 --> 00:01:20.549
 object recognition 

00:01:17.549 --> 00:01:22.170
 pedestrians or any object of 

00:01:20.549 --> 00:01:24.270
 generally as a problem of 

00:01:22.170 --> 00:01:24.990
 standard classification in apprenticeship 

00:01:24.270 --> 00:01:26.520
 automatic 

00:01:24.990 --> 00:01:29.220
 so what would we do if we 

00:01:26.520 --> 00:01:33.030
 would build a training set 

00:01:29.220 --> 00:01:35.009
 where people very excited corresponded to 

00:01:33.030 --> 00:01:37.170
 the rogge representation is a 

00:01:35.009 --> 00:01:40.619
 gradient histogram for an image 

00:01:37.170 --> 00:01:42.509
 given is the target yt that would be a 

00:01:40.619 --> 00:01:45.390
 indication of the presence so there 

00:01:42.509 --> 00:01:48.090
 connect one or the absence ci is equal 

00:01:45.390 --> 00:01:51.689
 zero for a given object we want 

00:01:48.090 --> 00:01:54.509
 recognizes laurent collecting a set 

00:01:51.689 --> 00:01:56.040
 workout like that we could 

00:01:54.509 --> 00:01:57.450
 give this training set the a1 

00:01:56.040 --> 00:02:00.479
 to cure given learning they 

00:01:57.450 --> 00:02:02.310
 learn to make the link between and to 

00:02:00.479 --> 00:02:04.740
 make a prediction from an entry 

00:02:02.310 --> 00:02:09.500
 the presence or not of a given object 

00:02:04.740 --> 00:02:09.500
 in the image represented by the entrance 

00:02:10.780 --> 00:02:16.540
 an example here of works that have 

00:02:14.400 --> 00:02:19.110
 always attack this problem in this 

00:02:16.540 --> 00:02:22.120
 that if the problem of detecting 

00:02:19.110 --> 00:02:24.790
 two pedestrians so people actually 

00:02:22.120 --> 00:02:27.280
 in images we have the image we saw 

00:02:24.790 --> 00:02:31.000
 previously and as well as 

00:02:27.280 --> 00:02:34.660
 characteristics corresponding to 

00:02:31.000 --> 00:02:37.360
 gradient histograms and what has been 

00:02:34.660 --> 00:02:38.950
 done here is that several examples 

00:02:37.360 --> 00:02:41.260
 like that so that would be an example 

00:02:38.950 --> 00:02:45.060
 yt feast on 1 since well and truly a 

00:02:41.260 --> 00:02:47.650
 pedestrian a person in the picture 

00:02:45.060 --> 00:02:49.600
 so we gave pictures like that 

00:02:47.650 --> 00:02:52.450
 as well as other images where there would be 

00:02:49.600 --> 00:02:54.730
 be pedestrian let's not be so we would 

00:02:52.450 --> 00:02:56.920
 would have to collect images of both 

00:02:54.730 --> 00:03:00.489
 types give back meaning to lead a 

00:02:56.920 --> 00:03:02.950
 classified as minor is shown 

00:03:00.489 --> 00:03:06.040
 here is what the classifier has learned 

00:03:02.950 --> 00:03:08.709
 in fact it shows that they are the 

00:03:06.040 --> 00:03:10.420
 weights that have a positive value so 

00:03:08.709 --> 00:03:14.230
 we remember that in a classic and 

00:03:10.420 --> 00:03:16.630
 linear we have a weight wy for each 

00:03:14.230 --> 00:03:20.440
 entries explains in my sector 

00:03:16.630 --> 00:03:21.310
 to enter wy multiply xxi in my 

00:03:20.440 --> 00:03:23.440
 prediction 

00:03:21.310 --> 00:03:25.209
 in fact if wy is positive it means 

00:03:23.440 --> 00:03:28.420
 that the presence so a high value 

00:03:25.209 --> 00:03:31.390
 of eksi and a helmet educator 

00:03:28.420 --> 00:03:33.459
 also for this problem if of class 1 

00:03:31.390 --> 00:03:36.100
 therefore the presence of a pedestrian 

00:03:33.459 --> 00:03:38.440
 and then if double life was negative with 

00:03:36.100 --> 00:03:41.260
 a high value of eksi created a 

00:03:38.440 --> 00:03:42.130
 education of the absence of a person 

00:03:41.260 --> 00:03:45.250
 in the picture 

00:03:42.130 --> 00:03:47.530
 and when we can do lustrous series in 

00:03:45.250 --> 00:03:49.870
 made for the skin positive to what 

00:03:47.530 --> 00:03:50.500
 gradient orientation that corresponds 

00:03:49.870 --> 00:03:52.329
 in the picture 

00:03:50.500 --> 00:03:55.660
 and that's what we have here illustrated 

00:03:52.329 --> 00:04:00.040
 only orientations that have a 

00:03:55.660 --> 00:04:02.200
 high positive weights have done there 

00:04:00.040 --> 00:04:03.790
 the presence or importance of a 

00:04:02.200 --> 00:04:06.939
 gradient basically corresponds to 

00:04:03.790 --> 00:04:09.730
 how much weight and such a life is 

00:04:06.939 --> 00:04:12.099
 what we observe is that we made 

00:04:09.730 --> 00:04:16.720
 positive steps that fits more or 

00:04:12.099 --> 00:04:17.709
 less to the shape of a person in at 

00:04:16.720 --> 00:04:19.660
 center of an image that no 

00:04:17.709 --> 00:04:21.639
 to actually be successful who 

00:04:19.660 --> 00:04:23.770
 could match the head 

00:04:21.639 --> 00:04:26.169
 here we have traits that could trace 

00:04:23.770 --> 00:04:28.930
 the contours of a person's shoulders 

00:04:26.169 --> 00:04:33.009
 and if it could be the feet of the 

00:04:28.930 --> 00:04:35.740
 no one here legend and we rather 

00:04:33.009 --> 00:04:37.419
 others a trait that are less 

00:04:35.740 --> 00:04:39.520
 competitive with the shape of a 

00:04:37.419 --> 00:04:41.889
 nobody during that if the workbook 

00:04:39.520 --> 00:04:45.699
 have essentially learned to detect 

00:04:41.889 --> 00:04:47.440
 the shape of a person in a picture and 

00:04:45.699 --> 00:04:49.419
 to ignore what might 

00:04:47.440 --> 00:04:51.910
 maybe was in rather in 

00:04:49.419 --> 00:04:55.630
 the background of a person has 

00:04:51.910 --> 00:04:57.009
 found in the center of an image for if 

00:04:55.630 --> 00:04:58.810
 you want more details on this 

00:04:57.009 --> 00:05:01.360
 classification system there I you 

00:04:58.810 --> 00:05:03.960
 encourages to consult the book of 

00:05:01.360 --> 00:05:03.960
 Nordic resources 

00:05:04.409 --> 00:05:09.039
 now if we have a proud glaze that 

00:05:07.090 --> 00:05:12.400
 able to tell if an object is 

00:05:09.039 --> 00:05:13.990
 in an image but that the way we have 

00:05:12.400 --> 00:05:15.970
 trained a class up by going the 

00:05:13.990 --> 00:05:17.590
 images or object were six 

00:05:15.970 --> 00:05:19.840
 find the pictures he was at 

00:05:17.590 --> 00:05:21.940
 center of the image how is that 

00:05:19.840 --> 00:05:23.710
 now we're doing a detection of a 

00:05:21.940 --> 00:05:24.880
 object so could be found 

00:05:23.710 --> 00:05:27.639
 anywhere in the picture 

00:05:24.880 --> 00:05:29.949
 the general approach is actually 

00:05:27.639 --> 00:05:31.690
 simply to apply our ranking 

00:05:29.949 --> 00:05:33.550
 in question but to apply it to 

00:05:31.690 --> 00:05:36.190
 several positions in the image and to 

00:05:33.550 --> 00:05:38.050
 several possible scales let's start 

00:05:36.190 --> 00:05:40.500
 by cosec imagine we have this 

00:05:38.050 --> 00:05:43.270
 image there as well as we want to detect a 

00:05:40.500 --> 00:05:46.389
 face so we classify faces 

00:05:43.270 --> 00:05:49.530
 who were trained on pictures where 

00:05:46.389 --> 00:05:51.280
 the face was in the center of the image 

00:05:49.530 --> 00:05:55.229
 because if what we could do 

00:05:51.280 --> 00:05:59.080
 actually extracted all the images 

00:05:55.229 --> 00:06:01.419
 possibly with overlap so 

00:05:59.080 --> 00:06:05.139
 at all possible positions in my 

00:06:01.419 --> 00:06:07.330
 my overall image which is bigger 

00:06:05.139 --> 00:06:09.190
 typically that the images that I have 

00:06:07.330 --> 00:06:12.490
 given in input of my case so proud of 

00:06:09.190 --> 00:06:13.580
 my image detector is what I 

00:06:12.490 --> 00:06:15.710
 will do is that my class 

00:06:13.580 --> 00:06:17.569
 h for each of these worries image there I 

00:06:15.710 --> 00:06:20.360
 ask him to tell me is it 

00:06:17.569 --> 00:06:23.419
 with what confidence if they believe that 

00:06:20.360 --> 00:06:25.539
 there is a face there 

00:06:23.419 --> 00:06:27.500
 in the picture and if that would give me a 

00:06:25.539 --> 00:06:29.270
 new image if we want them 

00:06:27.500 --> 00:06:32.840
 would contain each position 

00:06:29.270 --> 00:06:34.639
 the confidence of the classifier so 

00:06:32.840 --> 00:06:37.250
 question arises that black that fits 

00:06:34.639 --> 00:06:38.569
 at a high confidence that a face then 

00:06:37.250 --> 00:06:40.189
 low trust white 

00:06:38.569 --> 00:06:41.900
 so that would give me an image that 

00:06:40.189 --> 00:06:43.849
 could look like this here so we 

00:06:41.900 --> 00:06:46.849
 would have a lot of blacks to the plates of 

00:06:43.849 --> 00:06:48.830
 positions where is an image then the 

00:06:46.849 --> 00:06:50.240
 black the confidence finally would diminish 

00:06:48.830 --> 00:06:53.569
 offered music we would move away from 

00:06:50.240 --> 00:06:55.340
 each of the pictures have pale faces and 

00:06:53.569 --> 00:06:55.940
 finally to have a single position 

00:06:55.340 --> 00:06:59.569
 unique 

00:06:55.940 --> 00:07:01.370
 we can apply an operation of 

00:06:59.569 --> 00:07:04.069
 English this is called our maximum 

00:07:01.370 --> 00:07:06.289
 China roughly the way it's 

00:07:04.069 --> 00:07:10.340
 works is to take each of 

00:07:06.289 --> 00:07:12.919
 answers here and check in a 

00:07:10.340 --> 00:07:15.590
 auto window is what the answer of the 

00:07:12.919 --> 00:07:16.069
 center and the maximum response in the 

00:07:15.590 --> 00:07:21.050
 window 

00:07:16.069 --> 00:07:23.949
 if so I will keep the value at a 

00:07:21.050 --> 00:07:27.349
 high confidence value otherwise I'm going 

00:07:23.949 --> 00:07:30.110
 do a deletion finally of the 

00:07:27.349 --> 00:07:31.370
 value towards zero trust so in 

00:07:30.110 --> 00:07:32.750
 this case because it's not the value 

00:07:31.370 --> 00:07:37.969
 higher to see all high 

00:07:32.750 --> 00:07:40.759
 rather find here ben the answer so 

00:07:37.969 --> 00:07:43.789
 the position associated with that window there 

00:07:40.759 --> 00:07:47.839
 now a value of zero for 

00:07:43.789 --> 00:07:50.029
 trust on the other hand at the center where 

00:07:47.839 --> 00:07:51.349
 confidence is the highest she is 

00:07:50.029 --> 00:07:52.940
 actually trust more she lives 

00:07:51.349 --> 00:07:56.120
 in a window around and there we go 

00:07:52.940 --> 00:07:59.839
 keep a positive value of the 

00:07:56.120 --> 00:08:01.370
 confidence of the answer so we succeed 

00:07:59.839 --> 00:08:05.029
 finally to remove this uncertainty 

00:08:01.370 --> 00:08:07.460
 on the exact position of the face and 

00:08:05.029 --> 00:08:09.819
 get more specific points where 

00:08:07.460 --> 00:08:12.379
 could find the face 

00:08:09.819 --> 00:08:14.270
 now good for a given image in 

00:08:12.379 --> 00:08:17.210
 does he could have pictures close 

00:08:14.270 --> 00:08:19.600
 to decide photos for example near 

00:08:17.210 --> 00:08:21.760
 the camera in the distance 

00:08:19.600 --> 00:08:24.370
 how are we able to 

00:08:21.760 --> 00:08:25.840
 detect those faces that if they could 

00:08:24.370 --> 00:08:28.060
 to be in the background is recovering 

00:08:25.840 --> 00:08:30.790
 smaller than the faces closer to 

00:08:28.060 --> 00:08:31.960
 the camera so bigger in the image this 

00:08:30.790 --> 00:08:33.849
 that we want in practice these camps do 

00:08:31.960 --> 00:08:35.410
 take the picture in question and then we go 

00:08:33.849 --> 00:08:36.849
 generate multiple versions of this 

00:08:35.410 --> 00:08:39.729
 image there but on scales 

00:08:36.849 --> 00:08:42.060
 different and then of that for 

00:08:39.729 --> 00:08:45.310
 each of the images we will calculate its 

00:08:42.060 --> 00:08:47.410
 answers there with windows but who 

00:08:45.310 --> 00:08:51.400
 always going at the same time so the 

00:08:47.410 --> 00:08:53.710
 extreme windows in the windows 

00:08:51.400 --> 00:08:55.390
 by whose images under a ladder 

00:08:53.710 --> 00:08:59.680
 different sales correspond in fact 

00:08:55.390 --> 00:09:01.750
 to a size plus a surface more 

00:08:59.680 --> 00:09:03.370
 big in the given image so that's fine 

00:09:01.750 --> 00:09:06.790
 to finally detect the 

00:09:03.370 --> 00:09:08.230
 faces on different scales and for 

00:09:06.790 --> 00:09:09.280
 improve detections can do 

00:09:08.230 --> 00:09:10.900
 else 

00:09:09.280 --> 00:09:13.300
 other things we can try to 

00:09:10.900 --> 00:09:14.770
 correct by by elimination so even 

00:09:13.300 --> 00:09:15.490
 if the two guardians histograms are 

00:09:14.770 --> 00:09:17.200
 quite robust 

00:09:15.490 --> 00:09:19.180
 sometimes we can make improvements 

00:09:17.200 --> 00:09:20.890
 from this point of view I will not talk about it 

00:09:19.180 --> 00:09:23.710
 here you can consult the literature 

00:09:20.890 --> 00:09:27.010
 to know more we can also 

00:09:23.710 --> 00:09:28.750
 and estimate the orientation of the object that 

00:09:27.010 --> 00:09:30.580
 could be in the image so if 

00:09:28.750 --> 00:09:33.970
 in the face what I could not do 

00:09:30.580 --> 00:09:38.320
 a rotation of the image of the window 

00:09:33.970 --> 00:09:42.400
 for example the window here before the 

00:09:38.320 --> 00:09:44.200
 give as input to monk the sphere and there 

00:09:42.400 --> 00:09:45.640
 extract features 

00:09:44.200 --> 00:09:47.230
 so it's possible to 

00:09:45.640 --> 00:09:48.700
 develop algorithms that make 

00:09:47.230 --> 00:09:51.550
 is that they are trying to do this 

00:09:48.700 --> 00:09:54.490
 rotation there and so that allows in addition 

00:09:51.550 --> 00:09:57.070
 to have a little more than a variant on the 

00:09:54.490 --> 00:10:00.160
 possible rotations of an object 

00:09:57.070 --> 00:10:01.420
 would like to detect so to have 

00:10:00.160 --> 00:10:03.790
 more information when once i 

00:10:01.420 --> 00:10:05.530
 invite you to consult the law book 

00:10:03.790 --> 00:10:07.870
 underlines rich as well as the different 

00:10:05.530 --> 00:10:09.490
 references that are already there that that 

00:10:07.870 --> 00:10:12.040
 gives you an idea the general of 

00:10:09.490 --> 00:10:14.230
 how does multiple systems work 

00:10:12.040 --> 00:10:16.260
 recognition of objects in vision by 

00:10:14.230 --> 00:10:16.260
 computer 

