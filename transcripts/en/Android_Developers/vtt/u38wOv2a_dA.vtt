WEBVTT
Kind: captions
Language: en

00:00:07.720 --> 00:00:08.900
VINIT MODI: Hi, everyone.

00:00:08.900 --> 00:00:12.190
Welcome to the session on
the new multi-camera API.

00:00:12.190 --> 00:00:15.220
My name is Vinit Modi, and
I'm the product manager

00:00:15.220 --> 00:00:17.110
on the camera platform.

00:00:17.110 --> 00:00:19.420
Just a quick reminder--
after this talk,

00:00:19.420 --> 00:00:21.670
please step outside
to the sandbox area

00:00:21.670 --> 00:00:24.700
if you'd like to ask
us more questions.

00:00:24.700 --> 00:00:27.400
Before we talk
about the new API,

00:00:27.400 --> 00:00:30.960
let me give a quick update
on the state of camera.

00:00:30.960 --> 00:00:35.820
Historically, most camera apps
focus on the native camera app

00:00:35.820 --> 00:00:37.950
that ships with the device.

00:00:37.950 --> 00:00:41.070
It turns out, however, that
more than twice the amount

00:00:41.070 --> 00:00:44.920
of camera usage occurs on
the apps that you build.

00:00:44.920 --> 00:00:47.370
And it's extremely
important that you

00:00:47.370 --> 00:00:49.140
support the new
features that are

00:00:49.140 --> 00:00:52.880
available in the
new Android APIs.

00:00:52.880 --> 00:00:56.510
When we speak to a lot of
developers, what we find

00:00:56.510 --> 00:01:01.190
is that the number one question
is the state of camera2 API

00:01:01.190 --> 00:01:04.050
and where we're going
to be going forward.

00:01:04.050 --> 00:01:05.660
We've been working very hard.

00:01:05.660 --> 00:01:08.240
And starting with Android
P, what you'll find

00:01:08.240 --> 00:01:13.250
is almost all new devices will
support camera2 and HALv3.

00:01:13.250 --> 00:01:16.340
What this means is when you look
at the camera characteristics,

00:01:16.340 --> 00:01:18.620
you'll find that the device
will advertise itself

00:01:18.620 --> 00:01:21.950
as either camera2 LIMITED,
which is similar to a point

00:01:21.950 --> 00:01:25.190
and shoot, a camera2
FULL, which offers

00:01:25.190 --> 00:01:27.920
advanced capabilities
like per frame control,

00:01:27.920 --> 00:01:33.110
and LEVEL_3, which enables
YUV reprocessing and RAW.

00:01:33.110 --> 00:01:36.180
In addition, we've been
working with several OEMs,

00:01:36.180 --> 00:01:40.690
or manufacturers, to open
up new APIs at launch.

00:01:40.690 --> 00:01:43.710
So we're excited this year
that both the Google Pixel

00:01:43.710 --> 00:01:47.160
3 and the Huawei Mate
20 series support

00:01:47.160 --> 00:01:48.315
the new multi-camera API.

00:01:50.825 --> 00:01:52.690
Now, let me step
back and say why

00:01:52.690 --> 00:01:54.880
this new API is so important.

00:01:54.880 --> 00:01:58.510
Prior to Android P, as
developers, you only

00:01:58.510 --> 00:02:01.390
get access to one of the
physical sensors, where

00:02:01.390 --> 00:02:04.780
the native camera app gets
access to the full hardware

00:02:04.780 --> 00:02:06.426
capability.

00:02:06.426 --> 00:02:09.500
But starting with P,
you'll get the same access

00:02:09.500 --> 00:02:11.310
as the native camera app.

00:02:11.310 --> 00:02:13.640
This includes all
the physical sensors

00:02:13.640 --> 00:02:15.710
plus the logical camera.

00:02:15.710 --> 00:02:18.260
And the logical camera
is an abstraction

00:02:18.260 --> 00:02:22.250
of all the physical sensors
that allows you to easily take

00:02:22.250 --> 00:02:25.280
advantage of the hardware.

00:02:25.280 --> 00:02:28.040
There are several new use
cases and possibilities

00:02:28.040 --> 00:02:30.150
with the new multi-camera API.

00:02:30.150 --> 00:02:33.500
Today, Oscar's going to
talk about optical zoom,

00:02:33.500 --> 00:02:37.220
and Emilie is going
to cover bokeh.

00:02:37.220 --> 00:02:39.600
Thank you very much.

00:02:39.600 --> 00:02:42.011
Oscar is up next.

00:02:42.011 --> 00:02:42.945
[APPLAUSE]

00:02:45.582 --> 00:02:47.540
OSCAR WAHLTINEZ: Hi
everyone, my name is Oscar.

00:02:47.540 --> 00:02:49.610
I work in the developer
relations team,

00:02:49.610 --> 00:02:52.250
and we're going to start
off with a live demo.

00:02:52.250 --> 00:02:53.912
What could go wrong?

00:02:53.912 --> 00:02:54.834
[LAUGHTER]

00:02:56.448 --> 00:02:58.510
So here I have a Mate 20 phone.

00:02:58.510 --> 00:03:01.090
We are implementing
multi-camera zoom.

00:03:01.090 --> 00:03:04.890
What we're doing here is we
are swapping the UI layer,

00:03:04.890 --> 00:03:06.410
the two camera streams.

00:03:06.410 --> 00:03:08.817
I'm not doing any kind of
detail zoom or cropping.

00:03:08.817 --> 00:03:10.150
I'm simply swapping the streams.

00:03:10.150 --> 00:03:11.899
As you can see, it's
almost instantaneous.

00:03:11.899 --> 00:03:13.500
There's no tear
down I'm bringing up

00:03:13.500 --> 00:03:14.500
with the camera session.

00:03:14.500 --> 00:03:17.530
It's just a single session,
and I'm swapping the two camera

00:03:17.530 --> 00:03:18.970
streams.

00:03:18.970 --> 00:03:22.190
The idea is that, as I said,
single camera session--

00:03:22.190 --> 00:03:22.967
two streams.

00:03:22.967 --> 00:03:24.800
And we're going to swap
between the streams,

00:03:24.800 --> 00:03:26.840
and we're going to show
you how this was built.

00:03:26.840 --> 00:03:29.810
The key component, though,
is that we had the same code

00:03:29.810 --> 00:03:31.010
running on both devices.

00:03:31.010 --> 00:03:34.760
As many camera developers
know, it is quite a feat

00:03:34.760 --> 00:03:37.800
to have the same code running
across such different devices,

00:03:37.800 --> 00:03:40.960
especially for something
as tied to the hardware

00:03:40.960 --> 00:03:44.310
as it is multi-camera.

00:03:44.310 --> 00:03:47.360
So first, let's talk about
how we can use multiple camera

00:03:47.360 --> 00:03:48.920
streams simultaneously.

00:03:48.920 --> 00:03:51.160
The basic guarantee
provided by the framework

00:03:51.160 --> 00:03:52.850
in the multi-camera
APIs is that you

00:03:52.850 --> 00:03:55.940
can use at least
two physical camera

00:03:55.940 --> 00:03:59.090
streams at the same time.

00:03:59.090 --> 00:04:01.670
Recall the guaranteed
stream configurations

00:04:01.670 --> 00:04:03.980
for single camera devices.

00:04:03.980 --> 00:04:08.060
It is a set of rules based
on hardware level, target

00:04:08.060 --> 00:04:10.400
type, and target size.

00:04:10.400 --> 00:04:13.640
If we use the multi-camera
APIs correctly,

00:04:13.640 --> 00:04:17.529
we can get an exception
to these rules.

00:04:17.529 --> 00:04:20.360
Let's illustrate
this with an example.

00:04:20.360 --> 00:04:24.730
We have a single YUV
stream of maximum size.

00:04:24.730 --> 00:04:28.360
As per the previous table,
devices with limited hardware

00:04:28.360 --> 00:04:31.320
level will be able to
use a single stream

00:04:31.320 --> 00:04:32.720
with that configuration.

00:04:32.720 --> 00:04:35.260
If we use the
multi-camera APIs, we

00:04:35.260 --> 00:04:40.770
can actually use two streams
of equivalent configuration

00:04:40.770 --> 00:04:42.610
from the underlying
physical cameras.

00:04:46.730 --> 00:04:48.390
Let's walk through
what we need to do

00:04:48.390 --> 00:04:50.850
to implement the app that
we just demoed earlier.

00:04:50.850 --> 00:04:52.457
We broke it down to five steps.

00:04:52.457 --> 00:04:53.040
Are you ready?

00:04:56.004 --> 00:04:59.290
Step number one-- find
the physical cameras.

00:04:59.290 --> 00:05:02.380
We start by identifying
pairs of physical cameras

00:05:02.380 --> 00:05:05.530
that can be opened
simultaneously.

00:05:05.530 --> 00:05:09.360
Using the camera
character as the subject,

00:05:09.360 --> 00:05:13.386
we look for the
[? request ?] capabilities,

00:05:13.386 --> 00:05:16.200
and if logical multi-camera
is one of them,

00:05:16.200 --> 00:05:18.890
we know this device
is a logical camera.

00:05:22.290 --> 00:05:26.260
Now that we found a logical
camera, we store it.

00:05:26.260 --> 00:05:30.060
We'll need the ID
for later, we'll see.

00:05:30.060 --> 00:05:34.580
And we get the physical
cameras associated with it.

00:05:34.580 --> 00:05:36.180
Then, we can move
on to the next step.

00:05:40.030 --> 00:05:42.310
Here's a visualization of
what we just described.

00:05:42.310 --> 00:05:47.140
We take that logical camera ID,
and with the characteristics,

00:05:47.140 --> 00:05:50.410
we call get physical
camera IDs, and now we

00:05:50.410 --> 00:05:52.320
retrieve the physical
cameras associated

00:05:52.320 --> 00:05:53.570
with the logical camera group.

00:05:56.780 --> 00:05:58.130
Onto the next step.

00:05:58.130 --> 00:06:00.910
Open logical camera.

00:06:00.910 --> 00:06:02.450
The second step is nothing new.

00:06:02.450 --> 00:06:04.360
We open the camera.

00:06:04.360 --> 00:06:07.810
Recall the logical camera
ID we saved earlier.

00:06:07.810 --> 00:06:11.450
That is the only one we use
to pass to the camera manager.

00:06:11.450 --> 00:06:16.222
So to reiterate, we only
open the logical camera.

00:06:16.222 --> 00:06:19.220
The step callback will trigger
when the device is ready.

00:06:21.900 --> 00:06:24.529
We have now opened
the logical camera.

00:06:24.529 --> 00:06:26.820
In the next step, we'll create
the output configuration

00:06:26.820 --> 00:06:28.530
updates.

00:06:28.530 --> 00:06:31.790
They will be used to
create the camera session.

00:06:31.790 --> 00:06:34.160
For each desired
output target, we

00:06:34.160 --> 00:06:37.280
may have a physical camera ID
from the list we found earlier

00:06:37.280 --> 00:06:39.620
if we want to retrieve frames
from a specific hardware

00:06:39.620 --> 00:06:40.280
camera.

00:06:40.280 --> 00:06:43.010
Let's go into more details.

00:06:43.010 --> 00:06:46.110
We create the output
configuration object using

00:06:46.110 --> 00:06:49.340
our desired output target.

00:06:49.340 --> 00:06:51.260
And if we want to
associate that output

00:06:51.260 --> 00:06:55.370
with a specific
physical camera, then we

00:06:55.370 --> 00:07:00.080
pass the ID in the set
physical camera ID API.

00:07:00.080 --> 00:07:02.120
If we want to use
a logical camera,

00:07:02.120 --> 00:07:04.520
we can simply skip this step.

00:07:04.520 --> 00:07:08.360
We may also have a
combination of both.

00:07:08.360 --> 00:07:10.090
So at the end of the
day, we have a list

00:07:10.090 --> 00:07:12.130
of output configurations,
some of which

00:07:12.130 --> 00:07:14.650
may be associated with physical
cameras, some of which--

00:07:14.650 --> 00:07:16.690
logical camera.

00:07:16.690 --> 00:07:18.850
The goal is to put
all the configurations

00:07:18.850 --> 00:07:21.170
into a single session
configuration.

00:07:21.170 --> 00:07:23.680
As we just explained,
each output configuration

00:07:23.680 --> 00:07:27.100
has an associated output
target and, optionally,

00:07:27.100 --> 00:07:28.130
a physical camera ID.

00:07:31.410 --> 00:07:34.120
Now, we create the
capture session.

00:07:34.120 --> 00:07:37.010
How do we create the capture
session using the new session

00:07:37.010 --> 00:07:39.410
configuration object?

00:07:39.410 --> 00:07:41.990
We start off with our list
of output configurations

00:07:41.990 --> 00:07:44.120
that we just created.

00:07:44.120 --> 00:07:48.020
With that, we instantiate
a session configuration,

00:07:48.020 --> 00:07:52.400
which includes the
capture session callback.

00:07:52.400 --> 00:07:54.530
From that callback, we're
going to get an instance

00:07:54.530 --> 00:07:55.821
of the create a camera session.

00:07:59.140 --> 00:08:01.090
We take that session
configuration object

00:08:01.090 --> 00:08:03.880
and the camera device, which
we got from step number two

00:08:03.880 --> 00:08:05.974
when we opened logical camera.

00:08:05.974 --> 00:08:07.390
And we send a frame
with a request

00:08:07.390 --> 00:08:11.990
to create a new session with
our desired configuration.

00:08:11.990 --> 00:08:14.750
The callback provided in the
session configuration object

00:08:14.750 --> 00:08:16.040
will be triggered now.

00:08:16.040 --> 00:08:18.590
And then we'll have our camera
session ready to be used.

00:08:22.080 --> 00:08:22.580
Last step.

00:08:22.580 --> 00:08:23.288
Capture requests.

00:08:25.790 --> 00:08:28.230
Once that has happened, we
can start getting frames out

00:08:28.230 --> 00:08:29.470
of the cameras.

00:08:29.470 --> 00:08:32.460
For example, you want to
capture a frame from two

00:08:32.460 --> 00:08:37.970
physical cameras
simultaneously, we

00:08:37.970 --> 00:08:40.280
take the session
we created earlier

00:08:40.280 --> 00:08:42.049
and a pair of output targets.

00:08:42.049 --> 00:08:44.120
In this particular
case, each target

00:08:44.120 --> 00:08:48.610
will be associated with
a specific camera ID.

00:08:48.610 --> 00:08:50.630
We create the capture
request that we normally

00:08:50.630 --> 00:08:54.230
do, in this case,
using template preview.

00:08:54.230 --> 00:08:58.580
We attach the output targets to
it, again like we normally do.

00:08:58.580 --> 00:09:01.110
And now, we dispatch
the capture request.

00:09:01.110 --> 00:09:02.340
Nothing different here.

00:09:02.340 --> 00:09:05.190
Except in this case,
the output surfaces

00:09:05.190 --> 00:09:08.010
will receive image
data from each

00:09:08.010 --> 00:09:09.750
of the associated
physical cameras,

00:09:09.750 --> 00:09:15.120
and the capture request
callback will trigger only once.

00:09:15.120 --> 00:09:17.070
So again, it's just like
any capture request.

00:09:17.070 --> 00:09:20.670
The big difference is that
the completion callback

00:09:20.670 --> 00:09:25.440
will give me back two start
exposure timestamps instead

00:09:25.440 --> 00:09:27.615
of just a single value from
normal capture requests.

00:09:30.140 --> 00:09:31.770
So to recap, this
is how I implement

00:09:31.770 --> 00:09:33.750
our optical zoom demo.

00:09:33.750 --> 00:09:35.400
We found the physical cameras.

00:09:35.400 --> 00:09:38.560
We opened the logical camera
that is part of that group.

00:09:38.560 --> 00:09:40.980
We created the output
configurations.

00:09:40.980 --> 00:09:42.300
We [? print ?] a list.

00:09:42.300 --> 00:09:44.649
We create our capture session.

00:09:44.649 --> 00:09:46.440
And then, we dispatch
our capture requests.

00:09:49.990 --> 00:09:54.770
One more topic I wanted to
touch on is lens distortion.

00:09:54.770 --> 00:09:58.560
A classical example of lens
distortion is the fisheye lens.

00:09:58.560 --> 00:09:59.910
This is not a real example.

00:09:59.910 --> 00:10:03.364
It is here for
illustration purposes only.

00:10:03.364 --> 00:10:06.350
All lenses have some
amount of distortion.

00:10:06.350 --> 00:10:09.170
For logical cameras, you can
assume that that distortion

00:10:09.170 --> 00:10:10.310
will be minimal.

00:10:10.310 --> 00:10:14.190
For the most part, it'll
be corrected by a drivers.

00:10:14.190 --> 00:10:15.960
However, for physical
cameras, distortion

00:10:15.960 --> 00:10:19.530
can be pretty significant.

00:10:19.530 --> 00:10:21.790
The physical lens
distortion is described

00:10:21.790 --> 00:10:25.300
in a set of radial and
tangential coefficients.

00:10:25.300 --> 00:10:28.330
The coefficients can be queried
using the lens distortion

00:10:28.330 --> 00:10:30.580
camera characteristics key.

00:10:30.580 --> 00:10:34.600
The documentation has a lot more
details if you're interested.

00:10:34.600 --> 00:10:37.360
The good news is that there's
a way to correct distortion

00:10:37.360 --> 00:10:39.310
without doing a bunch of math.

00:10:39.310 --> 00:10:41.890
We can simply set the
distortion correction mode

00:10:41.890 --> 00:10:44.250
on our capture requests.

00:10:44.250 --> 00:10:47.320
OFF means that no
distortion is applied.

00:10:47.320 --> 00:10:48.820
We may need to use
this if we want

00:10:48.820 --> 00:10:50.860
to do things like
[INAUDIBLE] synchronization.

00:10:50.860 --> 00:10:53.948
Emilie will touch on that later.

00:10:53.948 --> 00:10:55.910
FAST means that the
best possible correction

00:10:55.910 --> 00:10:59.260
is applied while meeting
the advertised frame rate.

00:10:59.260 --> 00:11:01.250
If no FAST correction
is possible,

00:11:01.250 --> 00:11:04.434
this may be the same as OFF.

00:11:04.434 --> 00:11:05.850
HIGH QUALITY means
that distortion

00:11:05.850 --> 00:11:09.210
will be corrected as much as
the lens allows, potentially

00:11:09.210 --> 00:11:12.260
at the cost of frame rate.

00:11:12.260 --> 00:11:14.650
If we don't specify
a correction mode,

00:11:14.650 --> 00:11:16.775
it will be either
FAST or HIGH QUALITY.

00:11:16.775 --> 00:11:19.150
It is going to be up to the
implementation details, which

00:11:19.150 --> 00:11:21.340
is the default.
You, as a developer,

00:11:21.340 --> 00:11:23.800
can query to see which one
was applied to your capture

00:11:23.800 --> 00:11:26.100
request.

00:11:26.100 --> 00:11:27.810
Let's see a code
snippet demonstrating

00:11:27.810 --> 00:11:30.150
how this lens distortion is
set to high quality, which

00:11:30.150 --> 00:11:34.160
is probably what we want
for a still image capture.

00:11:34.160 --> 00:11:37.630
Assuming we already
started our camera session,

00:11:37.630 --> 00:11:39.840
we instantiate the
capture request builder

00:11:39.840 --> 00:11:41.850
using our desired
template, in this case,

00:11:41.850 --> 00:11:44.690
as I said, image capture.

00:11:44.690 --> 00:11:46.390
Then, we use the
camera characteristics

00:11:46.390 --> 00:11:48.670
to determine if HIGH QUALITY
distortion correction

00:11:48.670 --> 00:11:51.890
mode is available.

00:11:51.890 --> 00:11:54.410
Now that we know that
we have a HIGH QUALITY

00:11:54.410 --> 00:12:01.170
correction for distortion, we
set it on the capture request,

00:12:01.170 --> 00:12:03.750
and we do what we always do--
dispatch the capture request.

00:12:11.654 --> 00:12:14.210
For more sample code
and technical details,

00:12:14.210 --> 00:12:16.840
take a look at our blog post.

00:12:16.840 --> 00:12:18.574
We covered this and some more.

00:12:18.574 --> 00:12:19.990
We published it
earlier this week.

00:12:19.990 --> 00:12:22.096
And now, I'll hand
it over to Emilie.

00:12:22.096 --> 00:12:23.545
[APPLAUSE]

00:12:26.926 --> 00:12:28.430
EMILIE ROBERTS: Thanks, Oscar.

00:12:28.430 --> 00:12:29.990
My name is Emilie Roberts.

00:12:29.990 --> 00:12:31.841
I'm a partner
developer advocate,

00:12:31.841 --> 00:12:33.590
and I'm going to show
you a cool demo that

00:12:33.590 --> 00:12:35.810
uses some of these
multi-camera APIs

00:12:35.810 --> 00:12:40.350
to do a bokeh effect
on the Pixel 3.

00:12:40.350 --> 00:12:43.270
So we actually have
three-- well, two demos.

00:12:43.270 --> 00:12:44.760
2.5 demos.

00:12:44.760 --> 00:12:47.130
The first one is
a single cam demo.

00:12:47.130 --> 00:12:48.720
There's no multi-camera at all.

00:12:48.720 --> 00:12:50.910
But I wanted to sort
of show the mechanisms

00:12:50.910 --> 00:12:52.410
for creating the bokeh effect.

00:12:52.410 --> 00:12:57.180
Then, when we get into the dual
cam demo, you'll see exactly--

00:12:57.180 --> 00:12:59.640
you know, we can focus on
the multi-camera aspects

00:12:59.640 --> 00:13:02.140
and not worry so much about
the bokeh effect itself.

00:13:02.140 --> 00:13:04.200
And it's going to
be published soon--

00:13:04.200 --> 00:13:05.220
Open Source.

00:13:05.220 --> 00:13:08.740
So don't worry about
scribbling down too much code.

00:13:08.740 --> 00:13:11.890
So can we go to this phone?

00:13:11.890 --> 00:13:12.390
Demo.

00:13:15.530 --> 00:13:17.370
Excuse me.

00:13:17.370 --> 00:13:18.220
Okey dokey.

00:13:18.220 --> 00:13:19.330
So we have--

00:13:19.330 --> 00:13:21.310
I didn't set this up properly.

00:13:21.310 --> 00:13:24.340
OK, let's do the single
cam bokeh effect.

00:13:24.340 --> 00:13:27.900
Taking a selfie here.

00:13:27.900 --> 00:13:31.555
And I think you can see on the
screen, it's finding my face.

00:13:31.555 --> 00:13:32.980
It's cutting it out.

00:13:32.980 --> 00:13:35.140
Let me bump up the
final result. And it's

00:13:35.140 --> 00:13:38.830
kind of pasting the
portrait mode in there.

00:13:38.830 --> 00:13:41.590
This is kind of a rough
cut portrait mode.

00:13:41.590 --> 00:13:43.561
And I do have an
optimization on this.

00:13:43.561 --> 00:13:44.560
Let's see how that goes.

00:13:50.101 --> 00:13:51.600
I'll show you the
output steps here.

00:13:54.460 --> 00:13:57.100
So it's trying to do a better
job of finding the foreground.

00:13:57.100 --> 00:13:58.450
Hey, it didn't do too bad.

00:13:58.450 --> 00:14:02.090
It's generating the foreground
image, the background,

00:14:02.090 --> 00:14:05.170
which is just monochromed and
blurred a little bit, and--

00:14:05.170 --> 00:14:06.010
come on, app.

00:14:06.010 --> 00:14:07.170
Don't let us down--

00:14:07.170 --> 00:14:09.240
pasting on the final result.

00:14:09.240 --> 00:14:12.780
So that's not too
bad for a single cam.

00:14:12.780 --> 00:14:14.100
Let's try the dual cam demo.

00:14:14.100 --> 00:14:16.980
And with these stage
lights, I'm not sure.

00:14:16.980 --> 00:14:17.700
Come on.

00:14:21.813 --> 00:14:23.420
Hey, not too bad.

00:14:23.420 --> 00:14:24.470
We're doing good.

00:14:24.470 --> 00:14:31.250
So you can see a depth map being
created in the bottom left-hand

00:14:31.250 --> 00:14:35.210
corner that's detecting me
in the foreground and then

00:14:35.210 --> 00:14:37.790
the rest of y'all a
little bit faded out.

00:14:37.790 --> 00:14:39.830
You can see the closer
folks are a gray.

00:14:39.830 --> 00:14:41.600
And then black goes
right to the back.

00:14:41.600 --> 00:14:43.600
You can also see the
lights wreaking some havoc.

00:14:43.600 --> 00:14:45.710
Let me show you
the final result.

00:14:45.710 --> 00:14:48.940
Obviously, there are a few
optimizations that can happen,

00:14:48.940 --> 00:14:50.370
but it's working pretty well.

00:14:50.370 --> 00:14:53.930
So again, this is using the two
front cameras on the Pixel 2.

00:14:53.930 --> 00:14:57.740
You can see the two
streams going at once.

00:14:57.740 --> 00:14:58.680
Oops.

00:14:58.680 --> 00:15:01.391
Will this connect back up?

00:15:01.391 --> 00:15:01.890
No.

00:15:01.890 --> 00:15:03.210
Anyway, both streams at once.

00:15:03.210 --> 00:15:05.085
The wide angle lens and
the normal angle lens

00:15:05.085 --> 00:15:06.480
going at the same time.

00:15:06.480 --> 00:15:09.690
Can we head back to
the slides please?

00:15:09.690 --> 00:15:11.960
So let's talk about
how we do that.

00:15:11.960 --> 00:15:13.160
Oh, there we are.

00:15:13.160 --> 00:15:15.140
Anyway, so we had
the normal camera

00:15:15.140 --> 00:15:19.160
and the wide angle lens
running at the same time.

00:15:19.160 --> 00:15:22.030
Again, we're going to publish
this on probably GitHub,

00:15:22.030 --> 00:15:25.240
open-source it, so you can dig
into it, help us optimize it,

00:15:25.240 --> 00:15:26.630
make it even better.

00:15:26.630 --> 00:15:28.510
So the first case--
the single cam.

00:15:28.510 --> 00:15:29.770
Let's look at that quickly.

00:15:29.770 --> 00:15:32.780
The floating head
bokeh effect I call it.

00:15:32.780 --> 00:15:34.690
We're going to take a
photo with face detect.

00:15:34.690 --> 00:15:35.850
We're going to make two copies.

00:15:35.850 --> 00:15:37.266
So we have background,
foreground.

00:15:37.266 --> 00:15:39.520
Do some sort of fancy
background effects

00:15:39.520 --> 00:15:44.230
and then paste that floating
head back where it belongs.

00:15:44.230 --> 00:15:47.170
Face detect is built
into the Camera2 API.

00:15:47.170 --> 00:15:50.545
It's quite easy in
code to implement.

00:15:50.545 --> 00:15:52.420
First thing we want to
do is check the camera

00:15:52.420 --> 00:15:54.628
characteristics to see if
your camera device supports

00:15:54.628 --> 00:15:55.930
FaceDetect.

00:15:55.930 --> 00:15:58.150
If it does, you find
the mode you want.

00:15:58.150 --> 00:16:01.210
There is off, and
then simple, and full,

00:16:01.210 --> 00:16:04.494
depending on your camera device.

00:16:04.494 --> 00:16:06.790
Then, when we make our
camera capture request,

00:16:06.790 --> 00:16:09.520
we just include
that in the request.

00:16:09.520 --> 00:16:12.670
When we get our
results, you can see

00:16:12.670 --> 00:16:16.390
if the mode was set,
if you found any faces.

00:16:16.390 --> 00:16:18.550
And in this example,
I just search

00:16:18.550 --> 00:16:21.490
for the first face that it
finds is the one I used.

00:16:21.490 --> 00:16:24.700
We could imagine expanding
this to have multiple faces.

00:16:24.700 --> 00:16:28.840
Just a note-- FaceDetect
really grabs really the face.

00:16:28.840 --> 00:16:32.330
So I just bumped those
bounds out a little bit.

00:16:32.330 --> 00:16:35.200
So it's more of a head
getting chopped off.

00:16:35.200 --> 00:16:36.040
That sounds bad.

00:16:36.040 --> 00:16:39.410
A head being pasted
onto the background.

00:16:39.410 --> 00:16:41.350
Let's talk about the
fun background effects.

00:16:41.350 --> 00:16:42.880
So you can do what
you want here.

00:16:42.880 --> 00:16:43.990
I did a couple things.

00:16:43.990 --> 00:16:46.570
First, using
RenderScript, we just

00:16:46.570 --> 00:16:48.570
did a blur on the background.

00:16:48.570 --> 00:16:51.760
And because it's a
multi-camera talk,

00:16:51.760 --> 00:16:53.660
some cameras have a manual zoom.

00:16:53.660 --> 00:16:55.660
So you could-- if you're
working with multi-cam,

00:16:55.660 --> 00:16:57.618
you could do the background
with another camera

00:16:57.618 --> 00:16:59.650
and zoom way out of focus.

00:16:59.650 --> 00:17:01.480
So you could actually
do an optical blur,

00:17:01.480 --> 00:17:03.021
which would be kind
of cool, and also

00:17:03.021 --> 00:17:05.896
save you that software step.

00:17:05.896 --> 00:17:09.240
In this demo, we also did a
custom software sepia effect

00:17:09.240 --> 00:17:10.403
using RenderScript.

00:17:10.403 --> 00:17:12.569
But if you're using multi-cam
again, lots of cameras

00:17:12.569 --> 00:17:15.180
have built in effects,
like monochrome and sepia,

00:17:15.180 --> 00:17:17.520
that you can query and include
in your capture request

00:17:17.520 --> 00:17:18.974
as well.

00:17:18.974 --> 00:17:20.640
If you haven't used
RenderScript before,

00:17:20.640 --> 00:17:22.510
it looks something like this.

00:17:22.510 --> 00:17:25.020
And for our blur
effect, we care most

00:17:25.020 --> 00:17:27.180
about the three middle lines.

00:17:27.180 --> 00:17:30.330
And it's a built in
script, intrinsic blur.

00:17:30.330 --> 00:17:31.780
It's pretty handy.

00:17:31.780 --> 00:17:33.960
And it basically
works out of the box.

00:17:36.940 --> 00:17:39.260
In this case, it blurred
outside of the box

00:17:39.260 --> 00:17:42.080
because the box is not blurry.

00:17:42.080 --> 00:17:46.900
This is a custom RenderScript
script for the sepia effect.

00:17:46.900 --> 00:17:49.100
You can see in those
first three lines,

00:17:49.100 --> 00:17:51.450
basically we're taking
the input red, green,

00:17:51.450 --> 00:17:54.269
and blue channels, kind
of muting the colors,

00:17:54.269 --> 00:17:56.060
making them a bit
yellow, and sending those

00:17:56.060 --> 00:17:57.018
to the output channels.

00:18:00.050 --> 00:18:00.550
Okey dokey.

00:18:00.550 --> 00:18:01.630
So we've got the background.

00:18:01.630 --> 00:18:03.100
It's got this cool
bokeh effect on it.

00:18:03.100 --> 00:18:04.516
What do we do with
the foreground?

00:18:04.516 --> 00:18:07.930
From FaceDetect, we've
got the face cut out.

00:18:07.930 --> 00:18:10.240
And we just apply a PorterDuff
with a linear gradient

00:18:10.240 --> 00:18:12.230
to make the edges a bit softer.

00:18:12.230 --> 00:18:15.280
So when we paste it on,
it's not that harsh line.

00:18:15.280 --> 00:18:17.110
And ta-da.

00:18:17.110 --> 00:18:21.340
Paste it on, and things
look pretty good.

00:18:21.340 --> 00:18:23.320
There are a couple
of optimizations.

00:18:23.320 --> 00:18:26.230
One you saw, which is with
the GrabCut algorithm.

00:18:26.230 --> 00:18:29.320
This is built into OpenCV, the
Open Computer Vision library

00:18:29.320 --> 00:18:32.830
that we're using for the
depth map demo later on.

00:18:32.830 --> 00:18:35.770
Basically, I found the face.

00:18:35.770 --> 00:18:37.990
And then I chose a
rectangle a bit larger

00:18:37.990 --> 00:18:40.300
to try to guess where
the body might be.

00:18:40.300 --> 00:18:42.720
And then GrabCut does its best--

00:18:42.720 --> 00:18:45.070
like the Magic Wand tool in
your favorite photo editor--

00:18:45.070 --> 00:18:48.160
to shrink down that foreground
to the actual foreground

00:18:48.160 --> 00:18:48.970
bounds.

00:18:48.970 --> 00:18:52.060
We could also, as I mentioned,
add in multiple faces.

00:18:52.060 --> 00:18:53.960
Now, the moment you've
all been waiting for.

00:18:53.960 --> 00:18:59.010
Let's talk about dual cam
bokeh with the depth map.

00:18:59.010 --> 00:19:01.316
We're going to use to
cameras simultaneously.

00:19:01.316 --> 00:19:02.690
And we're going
to create a depth

00:19:02.690 --> 00:19:04.106
map, which is the
hard part, which

00:19:04.106 --> 00:19:06.282
I highlighted that in bold.

00:19:06.282 --> 00:19:08.240
But then we go ahead and
use the same mechanism

00:19:08.240 --> 00:19:09.710
we already talked about.

00:19:09.710 --> 00:19:10.310
Okey dokey.

00:19:10.310 --> 00:19:12.130
How does this work?

00:19:12.130 --> 00:19:13.860
First of all, the
double capture.

00:19:13.860 --> 00:19:17.450
So this, on the left, is
me hanging out with my pets

00:19:17.450 --> 00:19:18.260
at home.

00:19:18.260 --> 00:19:22.880
The left is the normal camera
in the Pixel 3 front cameras.

00:19:22.880 --> 00:19:26.514
And the right is
the wide angle shot.

00:19:26.514 --> 00:19:28.960
To do that, just as
Oscar walked through,

00:19:28.960 --> 00:19:31.120
we set out multiple
output configurations.

00:19:31.120 --> 00:19:33.820
So for each lens, we set up--

00:19:33.820 --> 00:19:37.030
here, we have the previous
surface as well as an image

00:19:37.030 --> 00:19:38.620
reader for the normal lens.

00:19:38.620 --> 00:19:42.340
We use set physical camera
ID to the normal lens.

00:19:42.340 --> 00:19:45.447
And we do the same thing
for the wide angle lens.

00:19:45.447 --> 00:19:47.530
So we end up with four
output configurations we're

00:19:47.530 --> 00:19:51.500
putting into our configuration.

00:19:51.500 --> 00:19:53.670
From then-- or from
there, it's just

00:19:53.670 --> 00:19:56.340
a matter of choosing our
output targets for the capture.

00:19:56.340 --> 00:19:58.120
In this case, we
want those photos

00:19:58.120 --> 00:19:59.530
so we can operate on them.

00:19:59.530 --> 00:20:02.330
So we say we want the image
reader from the normal lens

00:20:02.330 --> 00:20:03.330
and the wide angle lens.

00:20:07.030 --> 00:20:08.390
OK, so we have our images.

00:20:08.390 --> 00:20:10.390
Now we have to do a bunch
of math and some magic

00:20:10.390 --> 00:20:12.790
and make that bokeh
effect happen.

00:20:12.790 --> 00:20:16.180
I want to give a brief
introduction to stereo vision

00:20:16.180 --> 00:20:18.220
before we get into all the code.

00:20:18.220 --> 00:20:20.620
But I have to say,
looking at these slides,

00:20:20.620 --> 00:20:23.370
working on these slides,
I got a little bit bored.

00:20:23.370 --> 00:20:26.960
I like geometry, but you
know, it's a lot of letters.

00:20:26.960 --> 00:20:31.090
And I started asking myself,
what does P stand for anyway?

00:20:31.090 --> 00:20:33.580
Obviously, it's a
pile of chocolate.

00:20:33.580 --> 00:20:35.150
P stands for pile of chocolate.

00:20:35.150 --> 00:20:36.941
And this is what we're
going to be focusing

00:20:36.941 --> 00:20:38.850
on for the rest of this demo.

00:20:38.850 --> 00:20:42.610
And you know, camera one is a
little bit boring, camera two.

00:20:42.610 --> 00:20:44.710
So S here, we're going
to replace with a shark.

00:20:44.710 --> 00:20:46.450
This is my friend,
Pepper the Shark.

00:20:46.450 --> 00:20:47.686
And H is Hippo.

00:20:47.686 --> 00:20:49.060
So these are our
helpers that are

00:20:49.060 --> 00:20:51.680
going to help us talk
about stereo vision.

00:20:51.680 --> 00:20:56.400
So left camera, normal
lens, is Pepper the Shark.

00:20:56.400 --> 00:20:59.670
Wide angle lens is Susie
Loo, the couch hippopotamus.

00:20:59.670 --> 00:21:02.850
And they're both zeroing in
on that big pile of chocolate.

00:21:02.850 --> 00:21:05.500
And already, it's
a lot more fun.

00:21:05.500 --> 00:21:07.180
I hope you agree.

00:21:07.180 --> 00:21:09.630
So those skewed
rectangles there.

00:21:09.630 --> 00:21:11.460
That's the 2D surface.

00:21:11.460 --> 00:21:14.850
That's like the image that the
cameras are going to capture.

00:21:14.850 --> 00:21:17.130
In other words, the
2D representation

00:21:17.130 --> 00:21:20.250
of that real live
3D object we have.

00:21:20.250 --> 00:21:22.000
Let's take a look at
what that looks like.

00:21:22.000 --> 00:21:24.420
The shark eye view
is right in there

00:21:24.420 --> 00:21:27.090
on the almonds, sea
salt, and dark chocolate,

00:21:27.090 --> 00:21:31.210
whereas the hippo cam is focused
in on the raspberry crunch.

00:21:31.210 --> 00:21:33.370
So they're both seeing
the same 3D object,

00:21:33.370 --> 00:21:35.510
but they have this
2D representation.

00:21:35.510 --> 00:21:39.120
And what we really want to do
is take their separate views

00:21:39.120 --> 00:21:41.250
and be able to combine
them, so we get a little bit

00:21:41.250 --> 00:21:43.140
more information
than that 2D view

00:21:43.140 --> 00:21:46.200
and be able to create
a great depth map.

00:21:46.200 --> 00:21:48.816
So we have, again, the normal
view, the wide angle view.

00:21:48.816 --> 00:21:50.440
Well in this case,
they're both normal.

00:21:50.440 --> 00:21:52.860
But the left-hand,
the right-hand overlay

00:21:52.860 --> 00:21:56.184
on each other, you get that
kind of 3D ruler effect

00:21:56.184 --> 00:21:57.600
from elementary
school that I hope

00:21:57.600 --> 00:22:01.410
you got to enjoy as a child.

00:22:01.410 --> 00:22:03.660
And from there, we can
create a depth map,

00:22:03.660 --> 00:22:06.570
which allows you to do really
cool things like awesome bokeh

00:22:06.570 --> 00:22:09.870
effects as well as know how
far away the chocolate is

00:22:09.870 --> 00:22:13.580
so that you can reach out
and grab it, obviously.

00:22:13.580 --> 00:22:14.490
Okey dokey.

00:22:14.490 --> 00:22:17.990
So those two cameras,
those two pictures,

00:22:17.990 --> 00:22:20.580
are at a different
orientation from each other.

00:22:20.580 --> 00:22:22.230
And they're separated in space.

00:22:22.230 --> 00:22:24.750
So we need to get those
on top of each other.

00:22:24.750 --> 00:22:27.140
This is what we call
the camera extrinsics.

00:22:27.140 --> 00:22:30.409
How the two cameras
relate to each other.

00:22:30.409 --> 00:22:32.700
So we need to rotate and
translate each of those images

00:22:32.700 --> 00:22:34.980
so they appear on
top of each other.

00:22:34.980 --> 00:22:36.676
Normally, we say that--

00:22:36.676 --> 00:22:39.050
normally, we give the rotation
and translation parameters

00:22:39.050 --> 00:22:41.906
for a camera in
relation to World.

00:22:41.906 --> 00:22:43.520
So instead of Camera
1 to World, we'll

00:22:43.520 --> 00:22:46.327
have Shark to World
and Hippo to World.

00:22:46.327 --> 00:22:48.410
But when we're doing stereo
vision, what we really

00:22:48.410 --> 00:22:49.993
need to worry about
is Shark to Hippo.

00:22:49.993 --> 00:22:52.460
So how are these two cameras
related to each other?

00:22:52.460 --> 00:22:54.410
Like a good engineer,
all I know is

00:22:54.410 --> 00:22:57.800
I have to switch Hippo to
World to be World to Hippo.

00:22:57.800 --> 00:23:01.732
And now I have this pathway
from Shark to World to Hippo.

00:23:01.732 --> 00:23:03.940
I hope that was a fun
introduction to the math, which

00:23:03.940 --> 00:23:05.590
you can read all
about on Wikipedia

00:23:05.590 --> 00:23:08.040
and look something like this.

00:23:08.040 --> 00:23:10.120
To get the rotation
matrix, we're

00:23:10.120 --> 00:23:12.940
going to inverse the
rotation matrix for Camera 2

00:23:12.940 --> 00:23:14.970
and cross multiply
it with Camera 1.

00:23:14.970 --> 00:23:17.660
And for translation,
it's something like this.

00:23:17.660 --> 00:23:21.260
Take the inner
product and subtract.

00:23:21.260 --> 00:23:25.639
You can read all about it on
Wikipedia or other sources.

00:23:25.639 --> 00:23:27.180
So one thing I want
to just point out

00:23:27.180 --> 00:23:30.450
if you're working on this
yourself is the translation

00:23:30.450 --> 00:23:32.610
matrix for a Pixel 3
from the normal camera

00:23:32.610 --> 00:23:33.750
to the wide camera.

00:23:33.750 --> 00:23:35.310
This is what I got out.

00:23:35.310 --> 00:23:37.851
What do you notice about it?

00:23:37.851 --> 00:23:40.750
The 9 millimeter separation
between the cameras

00:23:40.750 --> 00:23:42.520
looks just about right.

00:23:42.520 --> 00:23:45.032
If you look at the phone,
you know there's a good--

00:23:45.032 --> 00:23:45.865
what's the American?

00:23:45.865 --> 00:23:49.044
A good-- anyway, there's
a good nine millimeters

00:23:49.044 --> 00:23:49.960
between those cameras.

00:23:49.960 --> 00:23:51.322
That makes perfect sense.

00:23:51.322 --> 00:23:52.780
But what I didn't
notice, and which

00:23:52.780 --> 00:23:57.920
cost me about a week of time, is
that it's in the y-coordinate.

00:23:57.920 --> 00:24:00.340
So the cameras are
on top of each other.

00:24:00.340 --> 00:24:02.560
And so while I'm
working with this phone,

00:24:02.560 --> 00:24:04.926
looking at the two
cameras beside each other,

00:24:04.926 --> 00:24:06.550
I just assumed that
they were obviously

00:24:06.550 --> 00:24:08.650
horizontally displaced.

00:24:08.650 --> 00:24:11.440
No big deal, except that
the depth map function

00:24:11.440 --> 00:24:12.940
that I'm using
assumes that they're

00:24:12.940 --> 00:24:14.190
going to be beside each other.

00:24:14.190 --> 00:24:16.210
It assumes horizontal
displacement.

00:24:16.210 --> 00:24:17.260
So you just have--

00:24:17.260 --> 00:24:19.240
because-- oh, I didn't
say the important part.

00:24:19.240 --> 00:24:22.000
Camera sensors are often
optimized for landscape,

00:24:22.000 --> 00:24:23.180
which makes sense.

00:24:23.180 --> 00:24:25.360
If you do it wrong, your
depth maps don't work.

00:24:25.360 --> 00:24:26.770
You pull your hair out.

00:24:26.770 --> 00:24:28.540
You have a great
week like I did.

00:24:28.540 --> 00:24:31.900
Anyway, just a note if
you're implementing this.

00:24:31.900 --> 00:24:33.397
So we have the
camera extrinsics,

00:24:33.397 --> 00:24:35.980
how we get the pictures from the
cameras on top of each other,

00:24:35.980 --> 00:24:37.510
how they relate to each other.

00:24:37.510 --> 00:24:40.780
Camera intrinsics are properties
of the cameras themselves.

00:24:40.780 --> 00:24:43.450
So we know we have a normal
lens and a wide angle lens.

00:24:43.450 --> 00:24:45.790
And they have
different properties.

00:24:45.790 --> 00:24:47.134
So there are two things.

00:24:47.134 --> 00:24:48.550
One is the camera
characteristics.

00:24:48.550 --> 00:24:51.190
This is things like the focal
length, the principle axis,

00:24:51.190 --> 00:24:54.210
and if that axis is
skewed for some reason.

00:24:54.210 --> 00:24:57.460
This appears often in the
three by three matrix.

00:24:57.460 --> 00:25:01.644
And distortion-- the wide angle
lens and any wide angle lens--

00:25:01.644 --> 00:25:03.060
near the edges,
especially, you're

00:25:03.060 --> 00:25:04.685
going to get a little
bit of distortion

00:25:04.685 --> 00:25:07.770
going on that we need to
consider as we're mapping

00:25:07.770 --> 00:25:09.580
the two images to each other.

00:25:09.580 --> 00:25:14.240
Another note-- so we're going
to use the intrinsic distortion

00:25:14.240 --> 00:25:16.830
properties of the lens
to undistort the image.

00:25:16.830 --> 00:25:19.310
But as Oscar told
us, by default,

00:25:19.310 --> 00:25:21.290
the camera undistorts
the image for us.

00:25:21.290 --> 00:25:22.940
So we're going to
undistort it and then

00:25:22.940 --> 00:25:26.490
reundistort, which means we're
actually going to distort it,

00:25:26.490 --> 00:25:27.440
which is bad news.

00:25:27.440 --> 00:25:29.814
So we actually need to turn
off the distortion correction

00:25:29.814 --> 00:25:31.430
if you want to do depth maps.

00:25:31.430 --> 00:25:33.984
That's easy enough with
our camera requests.

00:25:33.984 --> 00:25:35.900
We just make sure that
distortion mode is off.

00:25:38.090 --> 00:25:38.590
Okey dokey.

00:25:38.590 --> 00:25:39.760
So here are the four things.

00:25:39.760 --> 00:25:42.670
Rotation, translation, the
camera characteristics matrix,

00:25:42.670 --> 00:25:44.530
and the lens distortion.

00:25:44.530 --> 00:25:46.640
How do you get these properties?

00:25:46.640 --> 00:25:48.080
It's pretty easy.

00:25:48.080 --> 00:25:49.840
You just take an
entire afternoon,

00:25:49.840 --> 00:25:52.060
print out a checkerboard
sheet, or-- has anyone

00:25:52.060 --> 00:25:53.377
in this room done this before?

00:25:53.377 --> 00:25:54.460
It's called camera-- yeah?

00:25:54.460 --> 00:25:55.126
It's fun, right?

00:25:55.126 --> 00:25:56.920
It's great-- camera calibration.

00:25:56.920 --> 00:26:00.080
Take a whole series of
shots with both the cameras.

00:26:00.080 --> 00:26:01.330
You run a bunch of algorithms.

00:26:01.330 --> 00:26:04.000
You figure out these four
camera characteristics.

00:26:04.000 --> 00:26:06.550
And from then, you can go ahead
and start making depth maps

00:26:06.550 --> 00:26:09.182
from the cameras.

00:26:09.182 --> 00:26:10.640
You can tell from
my cheerful face,

00:26:10.640 --> 00:26:12.090
it's not actually that fun.

00:26:12.090 --> 00:26:13.620
Don't do it.

00:26:13.620 --> 00:26:14.550
It's no good.

00:26:14.550 --> 00:26:17.190
Luckily, in the camera2
multi-camera APIs,

00:26:17.190 --> 00:26:20.320
we have these great fields--

00:26:20.320 --> 00:26:22.540
rotation, translation,
calibration, and distortion.

00:26:22.540 --> 00:26:26.351
So you can get it straight out
of the API, which is wonderful.

00:26:26.351 --> 00:26:28.350
I'm going to just tell
you a few notes if you're

00:26:28.350 --> 00:26:31.230
implementing these yourself.

00:26:31.230 --> 00:26:34.950
So the camera characteristics,
the focal length,

00:26:34.950 --> 00:26:38.490
and the access information
comes in five parameters.

00:26:38.490 --> 00:26:40.712
This is in the
Android documentation.

00:26:40.712 --> 00:26:42.420
But to create that
three by three matrix,

00:26:42.420 --> 00:26:44.760
you just have to follow
the documentation

00:26:44.760 --> 00:26:46.627
and plug-in the numbers.

00:26:46.627 --> 00:26:48.210
Another thing that
might throw you off

00:26:48.210 --> 00:26:51.870
is the distortion coefficients
again are five values.

00:26:51.870 --> 00:26:54.600
But the OpenCV library uses
them in a different order

00:26:54.600 --> 00:26:56.700
than the values you
get out of the API.

00:26:56.700 --> 00:27:01.260
So you just need to know
that it goes 0, 1, 3, 4, 2.

00:27:01.260 --> 00:27:04.100
The good news is if you
use them in the 0, 1, 2, 3,

00:27:04.100 --> 00:27:06.999
4 order, when you
undistort your images,

00:27:06.999 --> 00:27:08.790
they look like they've
been in a whirlpool.

00:27:08.790 --> 00:27:11.760
So you're sure something's
wrong with those coefficients.

00:27:11.760 --> 00:27:15.920
Anyway, so once we have
all those parameters,

00:27:15.920 --> 00:27:18.110
we can go ahead and start
preparing our images

00:27:18.110 --> 00:27:20.450
to do a depth map comparison.

00:27:20.450 --> 00:27:21.899
This is me in my kitchen.

00:27:21.899 --> 00:27:23.690
And I don't know if
you can see from there,

00:27:23.690 --> 00:27:25.970
but if you look at
the ceiling, you'll

00:27:25.970 --> 00:27:28.940
notice there's kind
of a curve going down.

00:27:28.940 --> 00:27:30.230
We don't live in a fun house.

00:27:30.230 --> 00:27:32.271
It's the distortion effects
we were talking about

00:27:32.271 --> 00:27:35.570
with the wide angle lens with
the distortion correction off.

00:27:35.570 --> 00:27:37.780
As well when you're
comparing two images,

00:27:37.780 --> 00:27:39.530
the straight lines--
well, and the curved

00:27:39.530 --> 00:27:42.050
lines-- need to line up
in each of the images

00:27:42.050 --> 00:27:43.490
when you're making depth map.

00:27:43.490 --> 00:27:45.050
We call that rectifying.

00:27:45.050 --> 00:27:48.690
And we use the camera
characteristics to do that.

00:27:48.690 --> 00:27:51.660
That's just showing
the bent roof.

00:27:51.660 --> 00:27:54.570
All of these functions are in
the OpenCV library, the Open

00:27:54.570 --> 00:27:55.980
Computer Vision library.

00:27:55.980 --> 00:27:57.750
The first one is Stereo Rectify.

00:27:57.750 --> 00:27:59.520
This gets us a set
of parameters we

00:27:59.520 --> 00:28:02.190
can use to perform
these calculations.

00:28:02.190 --> 00:28:04.320
So we pass in the--

00:28:04.320 --> 00:28:08.730
sorry, the values we got from
the API, the camera matrix,

00:28:08.730 --> 00:28:11.250
the distortion coefficients,
the rotation, and translation

00:28:11.250 --> 00:28:13.320
that we calculated before.

00:28:13.320 --> 00:28:16.620
We get these parameters out, and
we call undistort rectify map,

00:28:16.620 --> 00:28:18.570
which creates a
map telling us how

00:28:18.570 --> 00:28:22.080
we can take two images from
these two different cameras

00:28:22.080 --> 00:28:23.950
and map them onto each other.

00:28:23.950 --> 00:28:27.280
And the Remap function
does just this.

00:28:27.280 --> 00:28:29.661
So let's see what that gives us.

00:28:29.661 --> 00:28:33.860
Here is, on the left again,
from the normal cam, front cam,

00:28:33.860 --> 00:28:37.370
of the Pixel 3 and the wide
angle lens from the Pixel 3.

00:28:37.370 --> 00:28:39.050
You can see they
look pretty good.

00:28:39.050 --> 00:28:42.800
The shark lines are lined up.

00:28:42.800 --> 00:28:43.964
The crop is about right.

00:28:43.964 --> 00:28:46.130
You know, the wide angle
has a lot more crop region.

00:28:46.130 --> 00:28:47.120
That's all lined up.

00:28:47.120 --> 00:28:48.990
The roof lines, the
door lines are straight.

00:28:48.990 --> 00:28:50.389
There's no wacky distortion.

00:28:50.389 --> 00:28:52.430
And actually, I'd say,
from where you're sitting,

00:28:52.430 --> 00:28:54.230
you probably have
to look closely

00:28:54.230 --> 00:28:57.650
to notice that the left-hand
picture is a little bit closer

00:28:57.650 --> 00:28:59.720
to the left-hand
side of the frame.

00:28:59.720 --> 00:29:03.110
So they're actually offset by
a little bit, which is just

00:29:03.110 --> 00:29:05.630
about what you'd expect
if you had two cameras 9

00:29:05.630 --> 00:29:06.420
millimeters apart.

00:29:09.306 --> 00:29:10.530
So we got the images.

00:29:10.530 --> 00:29:11.280
We've undistorted.

00:29:11.280 --> 00:29:12.350
We've rectified them.

00:29:12.350 --> 00:29:14.200
We're very close to
creating the depth maps.

00:29:14.200 --> 00:29:16.990
All we have to do is call
the depth map function.

00:29:16.990 --> 00:29:21.220
We use stereoBM or stereoSGBM.

00:29:21.220 --> 00:29:23.330
One has a few more
parameters than the other.

00:29:23.330 --> 00:29:25.455
And when you get to play
with the open-source demo,

00:29:25.455 --> 00:29:29.740
you can see how these parameters
work, and play around with it,

00:29:29.740 --> 00:29:32.920
optimize them,
commit your changes,

00:29:32.920 --> 00:29:34.200
help make that app better.

00:29:34.200 --> 00:29:37.340
And we call compute and
make this depth map.

00:29:37.340 --> 00:29:39.950
And when you do that, you'll
get an amazing photo-- something

00:29:39.950 --> 00:29:42.274
like this.

00:29:42.274 --> 00:29:44.440
Actually, sometimes it looks
a lot better than that.

00:29:44.440 --> 00:29:45.110
But anyway.

00:29:45.110 --> 00:29:46.950
This isn't quite what
we want to work with.

00:29:46.950 --> 00:29:49.910
What we really want to do is
filter that, in this case,

00:29:49.910 --> 00:29:52.190
using a weighted least
squares filter, which

00:29:52.190 --> 00:29:54.950
smooths that out and gives us
a little bit more useful depth

00:29:54.950 --> 00:29:55.450
map.

00:29:55.450 --> 00:29:58.097
So the darker pixels,
as we saw in the demo,

00:29:58.097 --> 00:29:59.180
are the ones farther back.

00:29:59.180 --> 00:30:01.714
The whiter pixels
are the closer ones.

00:30:01.714 --> 00:30:03.380
And it's probably a
little hard to see--

00:30:03.380 --> 00:30:06.200
you can see the shark's snout
and the hippo's snout are

00:30:06.200 --> 00:30:07.640
a little bit grayed out.

00:30:07.640 --> 00:30:10.340
So it's actually working
to some extent there.

00:30:10.340 --> 00:30:12.340
This is how we call the filter.

00:30:12.340 --> 00:30:14.930
It's also included in
the OpenCV libraries

00:30:14.930 --> 00:30:17.510
in the contributor modules.

00:30:17.510 --> 00:30:18.940
It's all open source.

00:30:18.940 --> 00:30:20.390
And it's really cool.

00:30:20.390 --> 00:30:24.890
When you get a depth map that
is perfect, it's exhilarating.

00:30:24.890 --> 00:30:27.080
OK, here we have our depth map.

00:30:27.080 --> 00:30:29.341
What do we do with it?

00:30:29.341 --> 00:30:33.610
So we can just apply this depth
map as a mask on top of it.

00:30:33.610 --> 00:30:36.490
And the black areas,
we want to fade out,

00:30:36.490 --> 00:30:39.372
and we want to highlight
the foreground.

00:30:39.372 --> 00:30:42.080
That's pretty easy to
do with a PorterDuff.

00:30:47.150 --> 00:30:50.080
And the result is
something like this.

00:30:50.080 --> 00:30:54.770
So indeed, the foreground
is more present.

00:30:54.770 --> 00:30:57.140
And then the background
is faded out.

00:30:57.140 --> 00:30:59.300
Personally, I have
high standards.

00:30:59.300 --> 00:31:01.130
I see like a
translucent floating

00:31:01.130 --> 00:31:02.780
shark over my shoulder.

00:31:02.780 --> 00:31:05.750
My face is a little bit grayed
out, my eyeball's missing.

00:31:05.750 --> 00:31:08.344
So I'm going to put another
big red X through this and say,

00:31:08.344 --> 00:31:09.260
not quite good enough.

00:31:09.260 --> 00:31:10.340
It's a good start.

00:31:10.340 --> 00:31:13.560
But what we really want is
a depth map more like this.

00:31:13.560 --> 00:31:15.860
So we're going to put a hard
threshold on the depth map

00:31:15.860 --> 00:31:18.270
and decide foreground,
background, that's it.

00:31:20.830 --> 00:31:23.170
In other apps, you may want
to do something similar

00:31:23.170 --> 00:31:25.350
but maybe not such
a harsh distinction.

00:31:25.350 --> 00:31:28.750
It could be a smoother curve.

00:31:28.750 --> 00:31:33.010
To do that, we can use the
OpenCV function, threshold.

00:31:33.010 --> 00:31:34.840
We give it some cutoff value.

00:31:34.840 --> 00:31:40.817
For the app, it's somewhere
around 80 to 140 out of 255.

00:31:40.817 --> 00:31:43.150
And that's just that limit
where something is considered

00:31:43.150 --> 00:31:44.810
foreground or background.

00:31:44.810 --> 00:31:46.780
I wanted to note
this in case you're

00:31:46.780 --> 00:31:48.919
implementing any of this.

00:31:48.919 --> 00:31:50.710
When we applied the
mask like I showed you,

00:31:50.710 --> 00:31:52.543
you actually need to
turn those black pixels

00:31:52.543 --> 00:31:54.364
to transparent pixels.

00:31:54.364 --> 00:31:55.780
So this function
just goes through

00:31:55.780 --> 00:31:58.876
and converts all the black
ones to transparency.

00:32:02.105 --> 00:32:02.730
And here we go.

00:32:02.730 --> 00:32:03.510
We're almost there.

00:32:03.510 --> 00:32:05.343
So I wanted to note one
thing on this slide.

00:32:05.343 --> 00:32:08.940
The middle picture-- you can
see my eye is a bit blacked out.

00:32:08.940 --> 00:32:12.770
Just remember that for
three more slides or so.

00:32:12.770 --> 00:32:16.080
So we have our initial picture,
we've got our depth map,

00:32:16.080 --> 00:32:20.355
we do this hard threshold on it.

00:32:20.355 --> 00:32:22.042
And we can again
create our background

00:32:22.042 --> 00:32:23.500
just like we did
in the first demo,

00:32:23.500 --> 00:32:28.580
blur it out, monochrome it,
and cut out that foreground.

00:32:28.580 --> 00:32:32.160
We have all the pieces
we need to paste it on.

00:32:32.160 --> 00:32:36.010
And this is our amazing,
final, portrait shot,

00:32:36.010 --> 00:32:38.710
which is pretty good.

00:32:38.710 --> 00:32:39.610
I'm proud of it.

00:32:39.610 --> 00:32:42.130
So let's talk about
an optimization.

00:32:42.130 --> 00:32:44.290
Remember that eyeball
thing I was talking about?

00:32:44.290 --> 00:32:47.800
So anything kind of
gleaming and shiny

00:32:47.800 --> 00:32:50.639
can get messed up in
this current iteration

00:32:50.639 --> 00:32:51.430
of the application.

00:32:51.430 --> 00:32:54.530
Or bright lights can throw
off the depth map generation.

00:32:54.530 --> 00:32:57.490
And so I did one
optimization, which was we

00:32:57.490 --> 00:32:59.290
have the FaceDetect region.

00:32:59.290 --> 00:33:02.300
I'm pretty sure I want the
face in the foreground.

00:33:02.300 --> 00:33:05.570
So I just used it and
hard cut it in and said,

00:33:05.570 --> 00:33:07.820
anything on the face is going
to be in the foreground.

00:33:07.820 --> 00:33:10.720
So that protected like
my teeth and my eye

00:33:10.720 --> 00:33:14.755
from that masking out effect.

00:33:14.755 --> 00:33:16.630
I don't know if you
noticed-- can I go back--

00:33:16.630 --> 00:33:19.920
my fuzzy red hair
and the red couch--

00:33:19.920 --> 00:33:22.910
there we go-- they
kind of blend in.

00:33:22.910 --> 00:33:25.070
And so I'm thinking we
could use GrabCut possibly

00:33:25.070 --> 00:33:27.830
to do a little bit better
job of figuring out exactly

00:33:27.830 --> 00:33:30.150
what's in the foreground.

00:33:30.150 --> 00:33:31.560
So thanks a lot.

00:33:31.560 --> 00:33:33.810
We really hope that this
gave you a bit of a deep dive

00:33:33.810 --> 00:33:36.990
into using camera2 and
the multi-camera APIs,

00:33:36.990 --> 00:33:39.390
giving you some
exciting creative ideas.

00:33:39.390 --> 00:33:40.890
We really want to
hear your ideas,

00:33:40.890 --> 00:33:42.930
and we really want to
see them in your apps.

00:33:42.930 --> 00:33:46.650
And we also want to know what
features you're looking for.

00:33:46.650 --> 00:33:49.021
We think they're
great, and we want

00:33:49.021 --> 00:33:51.270
to keep pushing the camera
ecosystem forward and doing

00:33:51.270 --> 00:33:55.990
more and more stuff
really ecosystem wide.

00:33:55.990 --> 00:33:57.357
Thanks so much again.

00:33:57.357 --> 00:33:59.440
And please do come to the
sandbox, camera sandbox,

00:33:59.440 --> 00:34:00.985
if you want to ask
us any questions,

00:34:00.985 --> 00:34:02.860
if you want any follow ups,
you want to try this app,

00:34:02.860 --> 00:34:03.850
and see if it works.

00:34:03.850 --> 00:34:07.750
And look for it
soon open source.

00:34:07.750 --> 00:34:08.650
Thanks a lot.

00:34:08.650 --> 00:34:09.850
[APPLAUSE]

00:34:09.850 --> 00:34:13.200
[MUSIC PLAYING]

