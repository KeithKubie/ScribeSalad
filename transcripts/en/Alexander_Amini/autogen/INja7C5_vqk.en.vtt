WEBVTT
Kind: captions
Language: en

00:00:03.250 --> 00:00:06.700
 
okay so welcome everyone to the final

00:00:06.700 --> 00:00:06.710
okay so welcome everyone to the final
 

00:00:06.710 --> 00:00:09.090
okay so welcome everyone to the final
foundational lecture of this year's

00:00:09.090 --> 00:00:09.100
foundational lecture of this year's
 

00:00:09.100 --> 00:00:11.259
foundational lecture of this year's
offering of six s-191

00:00:11.259 --> 00:00:11.269
offering of six s-191
 

00:00:11.269 --> 00:00:14.440
offering of six s-191
where we'll be taking kind of a step

00:00:14.440 --> 00:00:14.450
where we'll be taking kind of a step
 

00:00:14.450 --> 00:00:16.749
where we'll be taking kind of a step
back from the architectures and the

00:00:16.749 --> 00:00:16.759
back from the architectures and the
 

00:00:16.759 --> 00:00:18.790
back from the architectures and the
algorithms we've been exploring over the

00:00:18.790 --> 00:00:18.800
algorithms we've been exploring over the
 

00:00:18.800 --> 00:00:21.370
algorithms we've been exploring over the
past two days to take a broader

00:00:21.370 --> 00:00:21.380
past two days to take a broader
 

00:00:21.380 --> 00:00:24.190
past two days to take a broader
perspective on some of the limitations

00:00:24.190 --> 00:00:24.200
perspective on some of the limitations
 

00:00:24.200 --> 00:00:26.470
perspective on some of the limitations
of deep learning and a couple of

00:00:26.470 --> 00:00:26.480
of deep learning and a couple of
 

00:00:26.480 --> 00:00:29.790
of deep learning and a couple of
exciting new subfields that are emerging

00:00:29.790 --> 00:00:29.800
exciting new subfields that are emerging
 

00:00:29.800 --> 00:00:33.370
exciting new subfields that are emerging
within deep learning so before we dive

00:00:33.370 --> 00:00:33.380
within deep learning so before we dive
 

00:00:33.380 --> 00:00:35.830
within deep learning so before we dive
into that some very important

00:00:35.830 --> 00:00:35.840
into that some very important
 

00:00:35.840 --> 00:00:39.900
into that some very important
announcements first and foremost we have

00:00:39.900 --> 00:00:39.910
announcements first and foremost we have
 

00:00:39.910 --> 00:00:42.310
announcements first and foremost we have
amazing t-shirts for you that have

00:00:42.310 --> 00:00:42.320
amazing t-shirts for you that have
 

00:00:42.320 --> 00:00:44.800
amazing t-shirts for you that have
arrived and we'll be distributing them

00:00:44.800 --> 00:00:44.810
arrived and we'll be distributing them
 

00:00:44.810 --> 00:00:48.550
arrived and we'll be distributing them
today after lecture so we'll have them

00:00:48.550 --> 00:00:48.560
today after lecture so we'll have them
 

00:00:48.560 --> 00:00:50.590
today after lecture so we'll have them
arranged sort of in the front by size

00:00:50.590 --> 00:00:50.600
arranged sort of in the front by size
 

00:00:50.600 --> 00:00:53.700
arranged sort of in the front by size
and we'd first like to distribute two

00:00:53.700 --> 00:00:53.710
and we'd first like to distribute two
 

00:00:53.710 --> 00:00:56.500
and we'd first like to distribute two
for credit registered students we should

00:00:56.500 --> 00:00:56.510
for credit registered students we should
 

00:00:56.510 --> 00:00:58.360
for credit registered students we should
have plenty for everyone

00:00:58.360 --> 00:00:58.370
have plenty for everyone
 

00:00:58.370 --> 00:01:00.430
have plenty for everyone
but then to registered listeners and

00:01:00.430 --> 00:01:00.440
but then to registered listeners and
 

00:01:00.440 --> 00:01:02.979
but then to registered listeners and
then to all other guests and lesson and

00:01:02.979 --> 00:01:02.989
then to all other guests and lesson and
 

00:01:02.989 --> 00:01:06.520
then to all other guests and lesson and
listeners so there should be more than

00:01:06.520 --> 00:01:06.530
listeners so there should be more than
 

00:01:06.530 --> 00:01:10.210
listeners so there should be more than
enough we also have some shirts from

00:01:10.210 --> 00:01:10.220
enough we also have some shirts from
 

00:01:10.220 --> 00:01:12.250
enough we also have some shirts from
Google as well as some other swag so

00:01:12.250 --> 00:01:12.260
Google as well as some other swag so
 

00:01:12.260 --> 00:01:14.020
Google as well as some other swag so
it's gonna be really exciting and please

00:01:14.020 --> 00:01:14.030
it's gonna be really exciting and please
 

00:01:14.030 --> 00:01:19.660
it's gonna be really exciting and please
do stick around for that so sort of

00:01:19.660 --> 00:01:19.670
do stick around for that so sort of
 

00:01:19.670 --> 00:01:22.060
do stick around for that so sort of
where have we been and where are we

00:01:22.060 --> 00:01:22.070
where have we been and where are we
 

00:01:22.070 --> 00:01:25.210
where have we been and where are we
going so following this lecture we have

00:01:25.210 --> 00:01:25.220
going so following this lecture we have
 

00:01:25.220 --> 00:01:27.060
going so following this lecture we have
our final lab which is going to be on

00:01:27.060 --> 00:01:27.070
our final lab which is going to be on
 

00:01:27.070 --> 00:01:29.649
our final lab which is going to be on
reinforcement learning and then tomorrow

00:01:29.649 --> 00:01:29.659
reinforcement learning and then tomorrow
 

00:01:29.659 --> 00:01:32.410
reinforcement learning and then tomorrow
we have two extremely exciting guest

00:01:32.410 --> 00:01:32.420
we have two extremely exciting guest
 

00:01:32.420 --> 00:01:35.649
we have two extremely exciting guest
lectures from Google and IBM as well as

00:01:35.649 --> 00:01:35.659
lectures from Google and IBM as well as
 

00:01:35.659 --> 00:01:38.109
lectures from Google and IBM as well as
time for you to work on your final

00:01:38.109 --> 00:01:38.119
time for you to work on your final
 

00:01:38.119 --> 00:01:40.719
time for you to work on your final
projects during the lab portion and on

00:01:40.719 --> 00:01:40.729
projects during the lab portion and on
 

00:01:40.729 --> 00:01:42.789
projects during the lab portion and on
Friday we'll have one final guest

00:01:42.789 --> 00:01:42.799
Friday we'll have one final guest
 

00:01:42.799 --> 00:01:46.330
Friday we'll have one final guest
lecture from Nvidia the project pitch

00:01:46.330 --> 00:01:46.340
lecture from Nvidia the project pitch
 

00:01:46.340 --> 00:01:49.120
lecture from Nvidia the project pitch
competition as well as the judging and

00:01:49.120 --> 00:01:49.130
competition as well as the judging and
 

00:01:49.130 --> 00:01:52.990
competition as well as the judging and
awards ceremony so I've we've received a

00:01:52.990 --> 00:01:53.000
awards ceremony so I've we've received a
 

00:01:53.000 --> 00:01:56.020
awards ceremony so I've we've received a
lot of inquiries about the the final

00:01:56.020 --> 00:01:56.030
lot of inquiries about the the final
 

00:01:56.030 --> 00:01:58.359
lot of inquiries about the the final
projects and specific logistics so I'd

00:01:58.359 --> 00:01:58.369
projects and specific logistics so I'd
 

00:01:58.369 --> 00:02:01.390
projects and specific logistics so I'd
like to take a few minutes to to recap

00:02:01.390 --> 00:02:01.400
like to take a few minutes to to recap
 

00:02:01.400 --> 00:02:03.580
like to take a few minutes to to recap
that so for those of you who are taking

00:02:03.580 --> 00:02:03.590
that so for those of you who are taking
 

00:02:03.590 --> 00:02:05.530
that so for those of you who are taking
the course for credit right you have two

00:02:05.530 --> 00:02:05.540
the course for credit right you have two
 

00:02:05.540 --> 00:02:07.600
the course for credit right you have two
options to fulfill your final

00:02:07.600 --> 00:02:07.610
options to fulfill your final
 

00:02:07.610 --> 00:02:10.059
options to fulfill your final
requirement the first is a project

00:02:10.059 --> 00:02:10.069
requirement the first is a project
 

00:02:10.069 --> 00:02:13.239
requirement the first is a project
proposal and here we're asking you to

00:02:13.239 --> 00:02:13.249
proposal and here we're asking you to
 

00:02:13.249 --> 00:02:16.000
proposal and here we're asking you to
really pitch a novel deep learning

00:02:16.000 --> 00:02:16.010
really pitch a novel deep learning
 

00:02:16.010 --> 00:02:19.600
really pitch a novel deep learning
architecture idea application and we've

00:02:19.600 --> 00:02:19.610
architecture idea application and we've
 

00:02:19.610 --> 00:02:21.729
architecture idea application and we've
we've gotten a lot of questions about

00:02:21.729 --> 00:02:21.739
we've gotten a lot of questions about
 

00:02:21.739 --> 00:02:24.640
we've gotten a lot of questions about
the size of the groups so groups of one

00:02:24.640 --> 00:02:24.650
the size of the groups so groups of one
 

00:02:24.650 --> 00:02:27.580
the size of the groups so groups of one
are welcome but you will not be eligible

00:02:27.580 --> 00:02:27.590
are welcome but you will not be eligible
 

00:02:27.590 --> 00:02:30.339
are welcome but you will not be eligible
to receive a prize if you are a group of

00:02:30.339 --> 00:02:30.349
to receive a prize if you are a group of
 

00:02:30.349 --> 00:02:34.059
to receive a prize if you are a group of
one listeners are welcome to to present

00:02:34.059 --> 00:02:34.069
one listeners are welcome to to present
 

00:02:34.069 --> 00:02:37.690
one listeners are welcome to to present
ideas and join groups in order to be

00:02:37.690 --> 00:02:37.700
ideas and join groups in order to be
 

00:02:37.700 --> 00:02:39.640
ideas and join groups in order to be
eligible for a prize you must have a

00:02:39.640 --> 00:02:39.650
eligible for a prize you must have a
 

00:02:39.650 --> 00:02:42.220
eligible for a prize you must have a
group of two to four people and your

00:02:42.220 --> 00:02:42.230
group of two to four people and your
 

00:02:42.230 --> 00:02:44.650
group of two to four people and your
group must include at least one for

00:02:44.650 --> 00:02:44.660
group must include at least one for
 

00:02:44.660 --> 00:02:49.300
group must include at least one for
credit registered student we're gonna

00:02:49.300 --> 00:02:49.310
credit registered student we're gonna
 

00:02:49.310 --> 00:02:51.699
credit registered student we're gonna
give you three minutes to do your

00:02:51.699 --> 00:02:51.709
give you three minutes to do your
 

00:02:51.709 --> 00:02:55.780
give you three minutes to do your
pitches and this link there's pretty

00:02:55.780 --> 00:02:55.790
pitches and this link there's pretty
 

00:02:55.790 --> 00:02:58.630
pitches and this link there's pretty
detailed instructions for the the

00:02:58.630 --> 00:02:58.640
detailed instructions for the the
 

00:02:58.640 --> 00:03:01.420
detailed instructions for the the
proposal on that link so last year we we

00:03:01.420 --> 00:03:01.430
proposal on that link so last year we we
 

00:03:01.430 --> 00:03:03.190
proposal on that link so last year we we
only gave people one minute for their

00:03:03.190 --> 00:03:03.200
only gave people one minute for their
 

00:03:03.200 --> 00:03:05.349
only gave people one minute for their
pitch which was really really short so

00:03:05.349 --> 00:03:05.359
pitch which was really really short so
 

00:03:05.359 --> 00:03:07.119
pitch which was really really short so
by giving you three minutes we're really

00:03:07.119 --> 00:03:07.129
by giving you three minutes we're really
 

00:03:07.129 --> 00:03:10.390
by giving you three minutes we're really
hoping that you have spent some time to

00:03:10.390 --> 00:03:10.400
hoping that you have spent some time to
 

00:03:10.400 --> 00:03:13.089
hoping that you have spent some time to
think in-depth about your idea how it

00:03:13.089 --> 00:03:13.099
think in-depth about your idea how it
 

00:03:13.099 --> 00:03:16.479
think in-depth about your idea how it
could work why it's compelling and we're

00:03:16.479 --> 00:03:16.489
could work why it's compelling and we're
 

00:03:16.489 --> 00:03:18.280
could work why it's compelling and we're
going to have a panel of judges

00:03:18.280 --> 00:03:18.290
going to have a panel of judges
 

00:03:18.290 --> 00:03:21.280
going to have a panel of judges
including judges from industry as well

00:03:21.280 --> 00:03:21.290
including judges from industry as well
 

00:03:21.290 --> 00:03:24.400
including judges from industry as well
as Alexander myself and and other guest

00:03:24.400 --> 00:03:24.410
as Alexander myself and and other guest
 

00:03:24.410 --> 00:03:27.970
as Alexander myself and and other guest
judges and our prizes are these three

00:03:27.970 --> 00:03:27.980
judges and our prizes are these three
 

00:03:27.980 --> 00:03:30.550
judges and our prizes are these three
nvidia gpus as well as a set of four

00:03:30.550 --> 00:03:30.560
nvidia gpus as well as a set of four
 

00:03:30.560 --> 00:03:35.050
nvidia gpus as well as a set of four
google homes sort of how the the prize

00:03:35.050 --> 00:03:35.060
google homes sort of how the the prize
 

00:03:35.060 --> 00:03:38.140
google homes sort of how the the prize
Awards awarding is going to go is that

00:03:38.140 --> 00:03:38.150
Awards awarding is going to go is that
 

00:03:38.150 --> 00:03:41.770
Awards awarding is going to go is that
top three teams will be awarded a GPU

00:03:41.770 --> 00:03:41.780
top three teams will be awarded a GPU
 

00:03:41.780 --> 00:03:44.530
top three teams will be awarded a GPU
per team and the Google homes will be

00:03:44.530 --> 00:03:44.540
per team and the Google homes will be
 

00:03:44.540 --> 00:03:48.759
per team and the Google homes will be
distributed within one team so if you

00:03:48.759 --> 00:03:48.769
distributed within one team so if you
 

00:03:48.769 --> 00:03:50.860
distributed within one team so if you
have a team that has four people right

00:03:50.860 --> 00:03:50.870
have a team that has four people right
 

00:03:50.870 --> 00:03:52.870
have a team that has four people right
and you're awarded the the Google home

00:03:52.870 --> 00:03:52.880
and you're awarded the the Google home
 

00:03:52.880 --> 00:03:54.879
and you're awarded the the Google home
prize everyone will get a Google home if

00:03:54.879 --> 00:03:54.889
prize everyone will get a Google home if
 

00:03:54.889 --> 00:03:57.789
prize everyone will get a Google home if
you have two each of you will get one

00:03:57.789 --> 00:03:57.799
you have two each of you will get one
 

00:03:57.799 --> 00:03:59.890
you have two each of you will get one
and then the remaining two will be

00:03:59.890 --> 00:03:59.900
and then the remaining two will be
 

00:03:59.900 --> 00:04:06.250
and then the remaining two will be
awarded to to the next best team okay so

00:04:06.250 --> 00:04:06.260
awarded to to the next best team okay so
 

00:04:06.260 --> 00:04:10.089
awarded to to the next best team okay so
in terms of actually completing this we

00:04:10.089 --> 00:04:10.099
in terms of actually completing this we
 

00:04:10.099 --> 00:04:12.879
in terms of actually completing this we
ask that you prepare slides for your for

00:04:12.879 --> 00:04:12.889
ask that you prepare slides for your for
 

00:04:12.889 --> 00:04:16.120
ask that you prepare slides for your for
your pitch on Google slides so on Friday

00:04:16.120 --> 00:04:16.130
your pitch on Google slides so on Friday
 

00:04:16.130 --> 00:04:17.890
your pitch on Google slides so on Friday
if you're participating you'll come down

00:04:17.890 --> 00:04:17.900
if you're participating you'll come down
 

00:04:17.900 --> 00:04:20.770
if you're participating you'll come down
to the front present your pitch to the

00:04:20.770 --> 00:04:20.780
to the front present your pitch to the
 

00:04:20.780 --> 00:04:23.439
to the front present your pitch to the
rest of the class and to our judges we

00:04:23.439 --> 00:04:23.449
rest of the class and to our judges we
 

00:04:23.449 --> 00:04:26.050
rest of the class and to our judges we
ask that you please submit your groups

00:04:26.050 --> 00:04:26.060
ask that you please submit your groups
 

00:04:26.060 --> 00:04:27.760
ask that you please submit your groups
on by today

00:04:27.760 --> 00:04:27.770
on by today
 

00:04:27.770 --> 00:04:30.550
on by today
tonight at 10 p.m. there's this link

00:04:30.550 --> 00:04:30.560
tonight at 10 p.m. there's this link
 

00:04:30.560 --> 00:04:33.490
tonight at 10 p.m. there's this link
leads to a Google sheet where you can

00:04:33.490 --> 00:04:33.500
leads to a Google sheet where you can
 

00:04:33.500 --> 00:04:36.490
leads to a Google sheet where you can
sign up with your your team members

00:04:36.490 --> 00:04:36.500
sign up with your your team members
 

00:04:36.500 --> 00:04:39.339
sign up with your your team members
names and a tentative like title for

00:04:39.339 --> 00:04:39.349
names and a tentative like title for
 

00:04:39.349 --> 00:04:40.680
names and a tentative like title for
your for your project

00:04:40.680 --> 00:04:40.690
your for your project
 

00:04:40.690 --> 00:04:42.850
your for your project
tomorrow's lab portion will be

00:04:42.850 --> 00:04:42.860
tomorrow's lab portion will be
 

00:04:42.860 --> 00:04:46.480
tomorrow's lab portion will be
completely devoted to in-class work on

00:04:46.480 --> 00:04:46.490
completely devoted to in-class work on
 

00:04:46.490 --> 00:04:49.540
completely devoted to in-class work on
the project then we ask that you submit

00:04:49.540 --> 00:04:49.550
the project then we ask that you submit
 

00:04:49.550 --> 00:04:53.499
the project then we ask that you submit
your slides by midnight Thursday night

00:04:53.499 --> 00:04:53.509
your slides by midnight Thursday night
 

00:04:53.509 --> 00:04:56.080
your slides by midnight Thursday night
so that we have everything ready and in

00:04:56.080 --> 00:04:56.090
so that we have everything ready and in
 

00:04:56.090 --> 00:04:58.570
so that we have everything ready and in
order for Friday and the link for doing

00:04:58.570 --> 00:04:58.580
order for Friday and the link for doing
 

00:04:58.580 --> 00:05:00.580
order for Friday and the link for doing
that is there and finally our our

00:05:00.580 --> 00:05:00.590
that is there and finally our our
 

00:05:00.590 --> 00:05:05.230
that is there and finally our our
presentations will be on Friday so as

00:05:05.230 --> 00:05:05.240
presentations will be on Friday so as
 

00:05:05.240 --> 00:05:07.390
presentations will be on Friday so as
was discussed in the first lecture the

00:05:07.390 --> 00:05:07.400
was discussed in the first lecture the
 

00:05:07.400 --> 00:05:11.140
was discussed in the first lecture the
section second arguably most more boring

00:05:11.140 --> 00:05:11.150
section second arguably most more boring
 

00:05:11.150 --> 00:05:14.290
section second arguably most more boring
option is to write a one-page review of

00:05:14.290 --> 00:05:14.300
option is to write a one-page review of
 

00:05:14.300 --> 00:05:16.600
option is to write a one-page review of
a recent deep learning paper it can be

00:05:16.600 --> 00:05:16.610
a recent deep learning paper it can be
 

00:05:16.610 --> 00:05:18.909
a recent deep learning paper it can be
either on you know deep learning

00:05:18.909 --> 00:05:18.919
either on you know deep learning
 

00:05:18.919 --> 00:05:20.649
either on you know deep learning
fundamentals and theory or an

00:05:20.649 --> 00:05:20.659
fundamentals and theory or an
 

00:05:20.659 --> 00:05:23.379
fundamentals and theory or an
interesting application of deep learning

00:05:23.379 --> 00:05:23.389
interesting application of deep learning
 

00:05:23.389 --> 00:05:25.360
interesting application of deep learning
to a different domain that you may be

00:05:25.360 --> 00:05:25.370
to a different domain that you may be
 

00:05:25.370 --> 00:05:28.240
to a different domain that you may be
interested in and this would be due

00:05:28.240 --> 00:05:28.250
interested in and this would be due
 

00:05:28.250 --> 00:05:30.850
interested in and this would be due
Friday at the beginning of class by

00:05:30.850 --> 00:05:30.860
Friday at the beginning of class by
 

00:05:30.860 --> 00:05:33.870
Friday at the beginning of class by
email to - intro to deep learning stuff

00:05:33.870 --> 00:05:33.880
email to - intro to deep learning stuff
 

00:05:33.880 --> 00:05:38.920
email to - intro to deep learning stuff
mit.edu okay so tomorrow we're going to

00:05:38.920 --> 00:05:38.930
mit.edu okay so tomorrow we're going to
 

00:05:38.930 --> 00:05:42.129
mit.edu okay so tomorrow we're going to
have two guest speakers the first is

00:05:42.129 --> 00:05:42.139
have two guest speakers the first is
 

00:05:42.139 --> 00:05:44.110
have two guest speakers the first is
going to be where we're really really

00:05:44.110 --> 00:05:44.120
going to be where we're really really
 

00:05:44.120 --> 00:05:45.519
going to be where we're really really
lucky and privileged to have her

00:05:45.519 --> 00:05:45.529
lucky and privileged to have her
 

00:05:45.529 --> 00:05:49.570
lucky and privileged to have her
Fernanda Viegas she is an MIT alum and

00:05:49.570 --> 00:05:49.580
Fernanda Viegas she is an MIT alum and
 

00:05:49.580 --> 00:05:52.089
Fernanda Viegas she is an MIT alum and
she's the co-director of Google's people

00:05:52.089 --> 00:05:52.099
she's the co-director of Google's people
 

00:05:52.099 --> 00:05:54.760
she's the co-director of Google's people
and artificial intelligence Research Lab

00:05:54.760 --> 00:05:54.770
and artificial intelligence Research Lab
 

00:05:54.770 --> 00:05:57.510
and artificial intelligence Research Lab
or pair and she's a world-class

00:05:57.510 --> 00:05:57.520
or pair and she's a world-class
 

00:05:57.520 --> 00:06:00.820
or pair and she's a world-class
specialist on visualization techniques

00:06:00.820 --> 00:06:00.830
specialist on visualization techniques
 

00:06:00.830 --> 00:06:02.860
specialist on visualization techniques
for machine learning and deep learning

00:06:02.860 --> 00:06:02.870
for machine learning and deep learning
 

00:06:02.870 --> 00:06:05.230
for machine learning and deep learning
so it should be a really fun interactive

00:06:05.230 --> 00:06:05.240
so it should be a really fun interactive
 

00:06:05.240 --> 00:06:08.439
so it should be a really fun interactive
a cool talk and we really hope to see

00:06:08.439 --> 00:06:08.449
a cool talk and we really hope to see
 

00:06:08.449 --> 00:06:11.740
a cool talk and we really hope to see
everyone there the second talk will be

00:06:11.740 --> 00:06:11.750
everyone there the second talk will be
 

00:06:11.750 --> 00:06:15.339
everyone there the second talk will be
given by Dimitri or dima crota from the

00:06:15.339 --> 00:06:15.349
given by Dimitri or dima crota from the
 

00:06:15.349 --> 00:06:18.670
given by Dimitri or dima crota from the
MIT IBM Watson AI lab he's a physicist

00:06:18.670 --> 00:06:18.680
MIT IBM Watson AI lab he's a physicist
 

00:06:18.680 --> 00:06:20.980
MIT IBM Watson AI lab he's a physicist
by training really exciting and fun guy

00:06:20.980 --> 00:06:20.990
by training really exciting and fun guy
 

00:06:20.990 --> 00:06:24.550
by training really exciting and fun guy
and his research focuses on biologically

00:06:24.550 --> 00:06:24.560
and his research focuses on biologically
 

00:06:24.560 --> 00:06:27.909
and his research focuses on biologically
plausible algorithms for training neural

00:06:27.909 --> 00:06:27.919
plausible algorithms for training neural
 

00:06:27.919 --> 00:06:30.249
plausible algorithms for training neural
network so he'll he'll give some insight

00:06:30.249 --> 00:06:30.259
network so he'll he'll give some insight
 

00:06:30.259 --> 00:06:32.080
network so he'll he'll give some insight
onto whether or not back propagation

00:06:32.080 --> 00:06:32.090
onto whether or not back propagation
 

00:06:32.090 --> 00:06:34.450
onto whether or not back propagation
could actually be biologically plausible

00:06:34.450 --> 00:06:34.460
could actually be biologically plausible
 

00:06:34.460 --> 00:06:37.420
could actually be biologically plausible
and if not what are some you know

00:06:37.420 --> 00:06:37.430
and if not what are some you know
 

00:06:37.430 --> 00:06:40.269
and if not what are some you know
exciting new ideas about how learning

00:06:40.269 --> 00:06:40.279
exciting new ideas about how learning
 

00:06:40.279 --> 00:06:41.200
exciting new ideas about how learning
could act

00:06:41.200 --> 00:06:41.210
could act
 

00:06:41.210 --> 00:06:45.999
could act
we work in in the neuroscientific sense

00:06:45.999 --> 00:06:46.009
we work in in the neuroscientific sense
 

00:06:46.009 --> 00:06:49.059
we work in in the neuroscientific sense
I guess then the lab portion is going to

00:06:49.059 --> 00:06:49.069
I guess then the lab portion is going to
 

00:06:49.069 --> 00:06:51.219
I guess then the lab portion is going to
be devoted to work on the final projects

00:06:51.219 --> 00:06:51.229
be devoted to work on the final projects
 

00:06:51.229 --> 00:06:53.110
be devoted to work on the final projects
we'll be here the TAS will be here you

00:06:53.110 --> 00:06:53.120
we'll be here the TAS will be here you
 

00:06:53.120 --> 00:06:55.290
we'll be here the TAS will be here you
can brainstorm with us ask us questions

00:06:55.290 --> 00:06:55.300
can brainstorm with us ask us questions
 

00:06:55.300 --> 00:06:58.120
can brainstorm with us ask us questions
you know work with your team you get the

00:06:58.120 --> 00:06:58.130
you know work with your team you get the
 

00:06:58.130 --> 00:06:58.830
you know work with your team you get the
point

00:06:58.830 --> 00:06:58.840
point
 

00:06:58.840 --> 00:07:01.540
point
finally Thursday we'll have our final

00:07:01.540 --> 00:07:01.550
finally Thursday we'll have our final
 

00:07:01.550 --> 00:07:04.180
finally Thursday we'll have our final
guest lecture given by Yann Kouts from

00:07:04.180 --> 00:07:04.190
guest lecture given by Yann Kouts from
 

00:07:04.190 --> 00:07:06.990
guest lecture given by Yann Kouts from
Nvidia who's a leader in computer vision

00:07:06.990 --> 00:07:07.000
Nvidia who's a leader in computer vision
 

00:07:07.000 --> 00:07:10.029
Nvidia who's a leader in computer vision
and then we'll have the project proposal

00:07:10.029 --> 00:07:10.039
and then we'll have the project proposal
 

00:07:10.039 --> 00:07:12.990
and then we'll have the project proposal
competition the awards as well as pizza

00:07:12.990 --> 00:07:13.000
competition the awards as well as pizza
 

00:07:13.000 --> 00:07:18.010
competition the awards as well as pizza
celebration at the end ok so that is

00:07:18.010 --> 00:07:18.020
celebration at the end ok so that is
 

00:07:18.020 --> 00:07:21.430
celebration at the end ok so that is
sort of the administrivia for for today

00:07:21.430 --> 00:07:21.440
sort of the administrivia for for today
 

00:07:21.440 --> 00:07:25.629
sort of the administrivia for for today
and ideally the rest of the class so now

00:07:25.629 --> 00:07:25.639
and ideally the rest of the class so now
 

00:07:25.639 --> 00:07:27.700
and ideally the rest of the class so now
let's start with with the technical

00:07:27.700 --> 00:07:27.710
let's start with with the technical
 

00:07:27.710 --> 00:07:30.700
let's start with with the technical
content so on day one Alexandre showed

00:07:30.700 --> 00:07:30.710
content so on day one Alexandre showed
 

00:07:30.710 --> 00:07:33.700
content so on day one Alexandre showed
this slide which sort of summarized how

00:07:33.700 --> 00:07:33.710
this slide which sort of summarized how
 

00:07:33.710 --> 00:07:35.800
this slide which sort of summarized how
deep learning has revolutionised so many

00:07:35.800 --> 00:07:35.810
deep learning has revolutionised so many
 

00:07:35.810 --> 00:07:38.200
deep learning has revolutionised so many
different research areas from autonomous

00:07:38.200 --> 00:07:38.210
different research areas from autonomous
 

00:07:38.210 --> 00:07:40.409
different research areas from autonomous
vehicles to medicine and healthcare

00:07:40.409 --> 00:07:40.419
vehicles to medicine and healthcare
 

00:07:40.419 --> 00:07:42.730
vehicles to medicine and healthcare
reinforcement learning generative

00:07:42.730 --> 00:07:42.740
reinforcement learning generative
 

00:07:42.740 --> 00:07:45.730
reinforcement learning generative
modeling robotics and the list goes on

00:07:45.730 --> 00:07:45.740
modeling robotics and the list goes on
 

00:07:45.740 --> 00:07:48.850
modeling robotics and the list goes on
and on and hopefully now through this

00:07:48.850 --> 00:07:48.860
and on and hopefully now through this
 

00:07:48.860 --> 00:07:51.159
and on and hopefully now through this
series of 5 lectures you have a more

00:07:51.159 --> 00:07:51.169
series of 5 lectures you have a more
 

00:07:51.169 --> 00:07:53.860
series of 5 lectures you have a more
concrete understanding of how and why

00:07:53.860 --> 00:07:53.870
concrete understanding of how and why
 

00:07:53.870 --> 00:07:56.040
concrete understanding of how and why
deep learning is so well suited for

00:07:56.040 --> 00:07:56.050
deep learning is so well suited for
 

00:07:56.050 --> 00:07:58.990
deep learning is so well suited for
these kinds of really complex tasks and

00:07:58.990 --> 00:07:59.000
these kinds of really complex tasks and
 

00:07:59.000 --> 00:08:02.050
these kinds of really complex tasks and
how its enabled these advances across a

00:08:02.050 --> 00:08:02.060
how its enabled these advances across a
 

00:08:02.060 --> 00:08:07.270
how its enabled these advances across a
multitude of disciplines and also you

00:08:07.270 --> 00:08:07.280
multitude of disciplines and also you
 

00:08:07.280 --> 00:08:09.430
multitude of disciplines and also you
know so far we've primarily dealt with

00:08:09.430 --> 00:08:09.440
know so far we've primarily dealt with
 

00:08:09.440 --> 00:08:12.189
know so far we've primarily dealt with
these algorithms that take as input some

00:08:12.189 --> 00:08:12.199
these algorithms that take as input some
 

00:08:12.199 --> 00:08:14.230
these algorithms that take as input some
set of data in the form of signals

00:08:14.230 --> 00:08:14.240
set of data in the form of signals
 

00:08:14.240 --> 00:08:17.439
set of data in the form of signals
sequences images or other sensory data

00:08:17.439 --> 00:08:17.449
sequences images or other sensory data
 

00:08:17.449 --> 00:08:21.129
sequences images or other sensory data
to directly produce a decision at the as

00:08:21.129 --> 00:08:21.139
to directly produce a decision at the as
 

00:08:21.139 --> 00:08:24.010
to directly produce a decision at the as
an output whether that's a prediction or

00:08:24.010 --> 00:08:24.020
an output whether that's a prediction or
 

00:08:24.020 --> 00:08:26.080
an output whether that's a prediction or
an action as in the case of

00:08:26.080 --> 00:08:26.090
an action as in the case of
 

00:08:26.090 --> 00:08:28.510
an action as in the case of
reinforcement learning and we've also

00:08:28.510 --> 00:08:28.520
reinforcement learning and we've also
 

00:08:28.520 --> 00:08:32.170
reinforcement learning and we've also
seen ways in which we can go from sort

00:08:32.170 --> 00:08:32.180
seen ways in which we can go from sort
 

00:08:32.180 --> 00:08:34.420
seen ways in which we can go from sort
of from decision to data in the context

00:08:34.420 --> 00:08:34.430
of from decision to data in the context
 

00:08:34.430 --> 00:08:37.060
of from decision to data in the context
of generative modeling and to sample

00:08:37.060 --> 00:08:37.070
of generative modeling and to sample
 

00:08:37.070 --> 00:08:40.029
of generative modeling and to sample
brand new data from the decision space

00:08:40.029 --> 00:08:40.039
brand new data from the decision space
 

00:08:40.039 --> 00:08:43.019
brand new data from the decision space
in sort of this probabilistic setting

00:08:43.019 --> 00:08:43.029
in sort of this probabilistic setting
 

00:08:43.029 --> 00:08:45.670
in sort of this probabilistic setting
more generally in in all these cases

00:08:45.670 --> 00:08:45.680
more generally in in all these cases
 

00:08:45.680 --> 00:08:47.230
more generally in in all these cases
we've really been dealing with

00:08:47.230 --> 00:08:47.240
we've really been dealing with
 

00:08:47.240 --> 00:08:50.319
we've really been dealing with
algorithms that are designed to do that

00:08:50.319 --> 00:08:50.329
algorithms that are designed to do that
 

00:08:50.329 --> 00:08:52.480
algorithms that are designed to do that
are optimized to do well on

00:08:52.480 --> 00:08:52.490
are optimized to do well on
 

00:08:52.490 --> 00:08:55.960
are optimized to do well on
Ingle tasks right but fail to think like

00:08:55.960 --> 00:08:55.970
Ingle tasks right but fail to think like
 

00:08:55.970 --> 00:08:58.780
Ingle tasks right but fail to think like
humans or operate like humans sort of at

00:08:58.780 --> 00:08:58.790
humans or operate like humans sort of at
 

00:08:58.790 --> 00:09:00.699
humans or operate like humans sort of at
a at a higher love order level of

00:09:00.699 --> 00:09:00.709
a at a higher love order level of
 

00:09:00.709 --> 00:09:04.000
a at a higher love order level of
intelligence and to understand this in

00:09:04.000 --> 00:09:04.010
intelligence and to understand this in
 

00:09:04.010 --> 00:09:06.490
intelligence and to understand this in
more detail we have to go back to a

00:09:06.490 --> 00:09:06.500
more detail we have to go back to a
 

00:09:06.500 --> 00:09:08.710
more detail we have to go back to a
famous theorem in sort of the theory of

00:09:08.710 --> 00:09:08.720
famous theorem in sort of the theory of
 

00:09:08.720 --> 00:09:11.230
famous theorem in sort of the theory of
neural networks which was presented in

00:09:11.230 --> 00:09:11.240
neural networks which was presented in
 

00:09:11.240 --> 00:09:14.590
neural networks which was presented in
1989 and generated quite the stir and

00:09:14.590 --> 00:09:14.600
1989 and generated quite the stir and
 

00:09:14.600 --> 00:09:16.170
1989 and generated quite the stir and
this is called the universal

00:09:16.170 --> 00:09:16.180
this is called the universal
 

00:09:16.180 --> 00:09:18.610
this is called the universal
approximation theorem and basically what

00:09:18.610 --> 00:09:18.620
approximation theorem and basically what
 

00:09:18.620 --> 00:09:20.920
approximation theorem and basically what
it states is that a neural network with

00:09:20.920 --> 00:09:20.930
it states is that a neural network with
 

00:09:20.930 --> 00:09:24.310
it states is that a neural network with
a single hidden layer is sufficient to

00:09:24.310 --> 00:09:24.320
a single hidden layer is sufficient to
 

00:09:24.320 --> 00:09:29.260
a single hidden layer is sufficient to
approximate any arbitrary function any

00:09:29.260 --> 00:09:29.270
approximate any arbitrary function any
 

00:09:29.270 --> 00:09:31.600
approximate any arbitrary function any
continuous function and in this class

00:09:31.600 --> 00:09:31.610
continuous function and in this class
 

00:09:31.610 --> 00:09:33.519
continuous function and in this class
you know we've we've mostly been talking

00:09:33.519 --> 00:09:33.529
you know we've we've mostly been talking
 

00:09:33.529 --> 00:09:35.680
you know we've we've mostly been talking
about deep models that use multiple

00:09:35.680 --> 00:09:35.690
about deep models that use multiple
 

00:09:35.690 --> 00:09:37.600
about deep models that use multiple
layers but this theorem you know

00:09:37.600 --> 00:09:37.610
layers but this theorem you know
 

00:09:37.610 --> 00:09:39.760
layers but this theorem you know
completely ignores this and says you

00:09:39.760 --> 00:09:39.770
completely ignores this and says you
 

00:09:39.770 --> 00:09:43.449
completely ignores this and says you
just need one one neural layer and if

00:09:43.449 --> 00:09:43.459
just need one one neural layer and if
 

00:09:43.459 --> 00:09:45.310
just need one one neural layer and if
you believe that any problem can be

00:09:45.310 --> 00:09:45.320
you believe that any problem can be
 

00:09:45.320 --> 00:09:47.650
you believe that any problem can be
reduced sort of to a set of inputs and

00:09:47.650 --> 00:09:47.660
reduced sort of to a set of inputs and
 

00:09:47.660 --> 00:09:50.889
reduced sort of to a set of inputs and
an output this means that there exists a

00:09:50.889 --> 00:09:50.899
an output this means that there exists a
 

00:09:50.899 --> 00:09:53.320
an output this means that there exists a
neural network to solve any problem in

00:09:53.320 --> 00:09:53.330
neural network to solve any problem in
 

00:09:53.330 --> 00:09:54.790
neural network to solve any problem in
the world right so long as you can

00:09:54.790 --> 00:09:54.800
the world right so long as you can
 

00:09:54.800 --> 00:09:57.579
the world right so long as you can
define it using some continuous function

00:09:57.579 --> 00:09:57.589
define it using some continuous function
 

00:09:57.589 --> 00:10:00.639
define it using some continuous function
and this may seem like an incredibly

00:10:00.639 --> 00:10:00.649
and this may seem like an incredibly
 

00:10:00.649 --> 00:10:03.940
and this may seem like an incredibly
powerful result but if you look closely

00:10:03.940 --> 00:10:03.950
powerful result but if you look closely
 

00:10:03.950 --> 00:10:08.199
powerful result but if you look closely
right there are two really big caveats

00:10:08.199 --> 00:10:08.209
right there are two really big caveats
 

00:10:08.209 --> 00:10:12.160
right there are two really big caveats
to this first this this theorem makes no

00:10:12.160 --> 00:10:12.170
to this first this this theorem makes no
 

00:10:12.170 --> 00:10:14.680
to this first this this theorem makes no
guarantee on the number of hidden units

00:10:14.680 --> 00:10:14.690
guarantee on the number of hidden units
 

00:10:14.690 --> 00:10:16.900
guarantee on the number of hidden units
or the size of the hidden layer that's

00:10:16.900 --> 00:10:16.910
or the size of the hidden layer that's
 

00:10:16.910 --> 00:10:19.180
or the size of the hidden layer that's
going to be required to solve you know

00:10:19.180 --> 00:10:19.190
going to be required to solve you know
 

00:10:19.190 --> 00:10:21.850
going to be required to solve you know
your arbitrary problem and additionally

00:10:21.850 --> 00:10:21.860
your arbitrary problem and additionally
 

00:10:21.860 --> 00:10:23.949
your arbitrary problem and additionally
it leaves open this question of how do

00:10:23.949 --> 00:10:23.959
it leaves open this question of how do
 

00:10:23.959 --> 00:10:25.840
it leaves open this question of how do
we actually go about finding the weights

00:10:25.840 --> 00:10:25.850
we actually go about finding the weights
 

00:10:25.850 --> 00:10:29.650
we actually go about finding the weights
to support whatever architecture that

00:10:29.650 --> 00:10:29.660
to support whatever architecture that
 

00:10:29.660 --> 00:10:31.810
to support whatever architecture that
could be used to solve this problem it

00:10:31.810 --> 00:10:31.820
could be used to solve this problem it
 

00:10:31.820 --> 00:10:34.690
could be used to solve this problem it
just claims that and actually proves

00:10:34.690 --> 00:10:34.700
just claims that and actually proves
 

00:10:34.700 --> 00:10:37.810
just claims that and actually proves
that such an architecture exists but as

00:10:37.810 --> 00:10:37.820
that such an architecture exists but as
 

00:10:37.820 --> 00:10:40.300
that such an architecture exists but as
we know from gradient descent and this

00:10:40.300 --> 00:10:40.310
we know from gradient descent and this
 

00:10:40.310 --> 00:10:43.060
we know from gradient descent and this
idea of finding ways and sort of like a

00:10:43.060 --> 00:10:43.070
idea of finding ways and sort of like a
 

00:10:43.070 --> 00:10:47.380
idea of finding ways and sort of like a
non convex landscape there's no

00:10:47.380 --> 00:10:47.390
non convex landscape there's no
 

00:10:47.390 --> 00:10:51.310
non convex landscape there's no
guarantee that this this process of

00:10:51.310 --> 00:10:51.320
guarantee that this this process of
 

00:10:51.320 --> 00:10:53.199
guarantee that this this process of
learning these weights would be anyway

00:10:53.199 --> 00:10:53.209
learning these weights would be anyway
 

00:10:53.209 --> 00:10:56.829
learning these weights would be anyway
straightforward right and finally this

00:10:56.829 --> 00:10:56.839
straightforward right and finally this
 

00:10:56.839 --> 00:11:00.010
straightforward right and finally this
theorem doesn't provide any guarantees

00:11:00.010 --> 00:11:00.020
theorem doesn't provide any guarantees
 

00:11:00.020 --> 00:11:02.620
theorem doesn't provide any guarantees
that whatever model is that's learned

00:11:02.620 --> 00:11:02.630
that whatever model is that's learned
 

00:11:02.630 --> 00:11:05.829
that whatever model is that's learned
would generalize well to other tasks

00:11:05.829 --> 00:11:05.839
would generalize well to other tasks
 

00:11:05.839 --> 00:11:09.970
would generalize well to other tasks
and this theorem is is a perfect example

00:11:09.970 --> 00:11:09.980
and this theorem is is a perfect example
 

00:11:09.980 --> 00:11:13.329
and this theorem is is a perfect example
of sort of the possible effects of

00:11:13.329 --> 00:11:13.339
of sort of the possible effects of
 

00:11:13.339 --> 00:11:17.019
of sort of the possible effects of
overhype in AI and as a community I

00:11:17.019 --> 00:11:17.029
overhype in AI and as a community I
 

00:11:17.029 --> 00:11:19.389
overhype in AI and as a community I
think we're all interested in sort of

00:11:19.389 --> 00:11:19.399
think we're all interested in sort of
 

00:11:19.399 --> 00:11:20.800
think we're all interested in sort of
the state of deep learning and how we

00:11:20.800 --> 00:11:20.810
the state of deep learning and how we
 

00:11:20.810 --> 00:11:23.170
the state of deep learning and how we
can use in that's probably a big

00:11:23.170 --> 00:11:23.180
can use in that's probably a big
 

00:11:23.180 --> 00:11:25.090
can use in that's probably a big
motivation of why you're sitting in this

00:11:25.090 --> 00:11:25.100
motivation of why you're sitting in this
 

00:11:25.100 --> 00:11:28.030
motivation of why you're sitting in this
lecture today but I think we we really

00:11:28.030 --> 00:11:28.040
lecture today but I think we we really
 

00:11:28.040 --> 00:11:29.980
lecture today but I think we we really
need to be extremely careful in terms of

00:11:29.980 --> 00:11:29.990
need to be extremely careful in terms of
 

00:11:29.990 --> 00:11:31.840
need to be extremely careful in terms of
how we market and advertise these

00:11:31.840 --> 00:11:31.850
how we market and advertise these
 

00:11:31.850 --> 00:11:35.590
how we market and advertise these
algorithms so while the universal

00:11:35.590 --> 00:11:35.600
algorithms so while the universal
 

00:11:35.600 --> 00:11:37.840
algorithms so while the universal
approximation theorem generated a lot of

00:11:37.840 --> 00:11:37.850
approximation theorem generated a lot of
 

00:11:37.850 --> 00:11:39.639
approximation theorem generated a lot of
excitement when it first came out it

00:11:39.639 --> 00:11:39.649
excitement when it first came out it
 

00:11:39.649 --> 00:11:42.970
excitement when it first came out it
also provided some false hope to the AI

00:11:42.970 --> 00:11:42.980
also provided some false hope to the AI
 

00:11:42.980 --> 00:11:45.819
also provided some false hope to the AI
community that neural networks as they

00:11:45.819 --> 00:11:45.829
community that neural networks as they
 

00:11:45.829 --> 00:11:49.749
community that neural networks as they
existed dirt could solve any problem in

00:11:49.749 --> 00:11:49.759
existed dirt could solve any problem in
 

00:11:49.759 --> 00:11:52.389
existed dirt could solve any problem in
the world right and this overhype is

00:11:52.389 --> 00:11:52.399
the world right and this overhype is
 

00:11:52.399 --> 00:11:54.519
the world right and this overhype is
extremely dangerous and historically

00:11:54.519 --> 00:11:54.529
extremely dangerous and historically
 

00:11:54.529 --> 00:11:55.840
extremely dangerous and historically
there have actually been to

00:11:55.840 --> 00:11:55.850
there have actually been to
 

00:11:55.850 --> 00:11:59.049
there have actually been to
quote-unquote AI winters where research

00:11:59.049 --> 00:11:59.059
quote-unquote AI winters where research
 

00:11:59.059 --> 00:12:01.569
quote-unquote AI winters where research
in AI and neural networks specifically

00:12:01.569 --> 00:12:01.579
in AI and neural networks specifically
 

00:12:01.579 --> 00:12:04.929
in AI and neural networks specifically
in in the second AI winter came to sort

00:12:04.929 --> 00:12:04.939
in in the second AI winter came to sort
 

00:12:04.939 --> 00:12:08.920
in in the second AI winter came to sort
of a grinding halt and so this is why

00:12:08.920 --> 00:12:08.930
of a grinding halt and so this is why
 

00:12:08.930 --> 00:12:11.170
of a grinding halt and so this is why
you know for the first portion of this

00:12:11.170 --> 00:12:11.180
you know for the first portion of this
 

00:12:11.180 --> 00:12:14.019
you know for the first portion of this
lecture I'd like to focus on some of the

00:12:14.019 --> 00:12:14.029
lecture I'd like to focus on some of the
 

00:12:14.029 --> 00:12:16.660
lecture I'd like to focus on some of the
limitations of these algorithms that

00:12:16.660 --> 00:12:16.670
limitations of these algorithms that
 

00:12:16.670 --> 00:12:19.240
limitations of these algorithms that
we've learned about so far but also to

00:12:19.240 --> 00:12:19.250
we've learned about so far but also to
 

00:12:19.250 --> 00:12:23.049
we've learned about so far but also to
take it a step further to touch on some

00:12:23.049 --> 00:12:23.059
take it a step further to touch on some
 

00:12:23.059 --> 00:12:24.910
take it a step further to touch on some
really exciting new research that's

00:12:24.910 --> 00:12:24.920
really exciting new research that's
 

00:12:24.920 --> 00:12:27.490
really exciting new research that's
looking to address these problems and

00:12:27.490 --> 00:12:27.500
looking to address these problems and
 

00:12:27.500 --> 00:12:28.179
looking to address these problems and
limitations

00:12:28.179 --> 00:12:28.189
limitations
 

00:12:28.189 --> 00:12:30.929
limitations
so first let's let's talk about

00:12:30.929 --> 00:12:30.939
so first let's let's talk about
 

00:12:30.939 --> 00:12:33.790
so first let's let's talk about
limitations of deep learning and one of

00:12:33.790 --> 00:12:33.800
limitations of deep learning and one of
 

00:12:33.800 --> 00:12:35.920
limitations of deep learning and one of
my favorite examples of a potential

00:12:35.920 --> 00:12:35.930
my favorite examples of a potential
 

00:12:35.930 --> 00:12:37.929
my favorite examples of a potential
danger of deep neural networks comes

00:12:37.929 --> 00:12:37.939
danger of deep neural networks comes
 

00:12:37.939 --> 00:12:41.460
danger of deep neural networks comes
from this paper from Google Google brain

00:12:41.460 --> 00:12:41.470
from this paper from Google Google brain
 

00:12:41.470 --> 00:12:44.110
from this paper from Google Google brain
that was entitled understanding deep

00:12:44.110 --> 00:12:44.120
that was entitled understanding deep
 

00:12:44.120 --> 00:12:46.259
that was entitled understanding deep
neural networks requires rethinking

00:12:46.259 --> 00:12:46.269
neural networks requires rethinking
 

00:12:46.269 --> 00:12:49.299
neural networks requires rethinking
generalization and this paper really did

00:12:49.299 --> 00:12:49.309
generalization and this paper really did
 

00:12:49.309 --> 00:12:51.129
generalization and this paper really did
something really simple but very

00:12:51.129 --> 00:12:51.139
something really simple but very
 

00:12:51.139 --> 00:12:51.910
something really simple but very
powerful

00:12:51.910 --> 00:12:51.920
powerful
 

00:12:51.920 --> 00:12:54.490
powerful
they took images from the imagenet

00:12:54.490 --> 00:12:54.500
they took images from the imagenet
 

00:12:54.500 --> 00:12:57.160
they took images from the imagenet
dataset and you know their labels first

00:12:57.160 --> 00:12:57.170
dataset and you know their labels first
 

00:12:57.170 --> 00:13:00.069
dataset and you know their labels first
four examples are shown here and what

00:13:00.069 --> 00:13:00.079
four examples are shown here and what
 

00:13:00.079 --> 00:13:02.079
four examples are shown here and what
they did is that for every image in

00:13:02.079 --> 00:13:02.089
they did is that for every image in
 

00:13:02.089 --> 00:13:05.470
they did is that for every image in
their data set they flipped a die write

00:13:05.470 --> 00:13:05.480
their data set they flipped a die write
 

00:13:05.480 --> 00:13:08.470
their data set they flipped a die write
a K sided die where K is the number of

00:13:08.470 --> 00:13:08.480
a K sided die where K is the number of
 

00:13:08.480 --> 00:13:10.389
a K sided die where K is the number of
possible classes that they were trying

00:13:10.389 --> 00:13:10.399
possible classes that they were trying
 

00:13:10.399 --> 00:13:12.249
possible classes that they were trying
to consider in a classification problem

00:13:12.249 --> 00:13:12.259
to consider in a classification problem
 

00:13:12.259 --> 00:13:15.879
to consider in a classification problem
and they use this result of this die

00:13:15.879 --> 00:13:15.889
and they use this result of this die
 

00:13:15.889 --> 00:13:19.580
and they use this result of this die
roll to assign a brand

00:13:19.580 --> 00:13:19.590
roll to assign a brand
 

00:13:19.590 --> 00:13:22.880
roll to assign a brand
you randomly sampled label to that image

00:13:22.880 --> 00:13:22.890
you randomly sampled label to that image
 

00:13:22.890 --> 00:13:26.030
you randomly sampled label to that image
and this means that you know these new

00:13:26.030 --> 00:13:26.040
and this means that you know these new
 

00:13:26.040 --> 00:13:28.220
and this means that you know these new
labels associated with each image were

00:13:28.220 --> 00:13:28.230
labels associated with each image were
 

00:13:28.230 --> 00:13:30.860
labels associated with each image were
completely random with respect to what

00:13:30.860 --> 00:13:30.870
completely random with respect to what
 

00:13:30.870 --> 00:13:33.800
completely random with respect to what
was actually present in the image and if

00:13:33.800 --> 00:13:33.810
was actually present in the image and if
 

00:13:33.810 --> 00:13:36.050
was actually present in the image and if
you'll notice that these two examples of

00:13:36.050 --> 00:13:36.060
you'll notice that these two examples of
 

00:13:36.060 --> 00:13:39.410
you'll notice that these two examples of
dogs ended up in this in this

00:13:39.410 --> 00:13:39.420
dogs ended up in this in this
 

00:13:39.420 --> 00:13:41.990
dogs ended up in this in this
demonstration that I'm showing being

00:13:41.990 --> 00:13:42.000
demonstration that I'm showing being
 

00:13:42.000 --> 00:13:44.560
demonstration that I'm showing being
mapped to different classes altogether

00:13:44.560 --> 00:13:44.570
mapped to different classes altogether
 

00:13:44.570 --> 00:13:47.450
mapped to different classes altogether
so we're literally trying to randomize

00:13:47.450 --> 00:13:47.460
so we're literally trying to randomize
 

00:13:47.460 --> 00:13:51.560
so we're literally trying to randomize
our labels entirely then what they did

00:13:51.560 --> 00:13:51.570
our labels entirely then what they did
 

00:13:51.570 --> 00:13:54.140
our labels entirely then what they did
was that they tried to fit a deep neural

00:13:54.140 --> 00:13:54.150
was that they tried to fit a deep neural
 

00:13:54.150 --> 00:13:57.290
was that they tried to fit a deep neural
network model to the sampled image net

00:13:57.290 --> 00:13:57.300
network model to the sampled image net
 

00:13:57.300 --> 00:14:01.400
network model to the sampled image net
data ranging from either the the

00:14:01.400 --> 00:14:01.410
data ranging from either the the
 

00:14:01.410 --> 00:14:03.890
data ranging from either the the
untouched original data with the

00:14:03.890 --> 00:14:03.900
untouched original data with the
 

00:14:03.900 --> 00:14:07.450
untouched original data with the
original labels to data that they had

00:14:07.450 --> 00:14:07.460
original labels to data that they had
 

00:14:07.460 --> 00:14:09.680
original labels to data that they had
reassigned the labels using this

00:14:09.680 --> 00:14:09.690
reassigned the labels using this
 

00:14:09.690 --> 00:14:12.100
reassigned the labels using this
completely random sampling approach and

00:14:12.100 --> 00:14:12.110
completely random sampling approach and
 

00:14:12.110 --> 00:14:15.260
completely random sampling approach and
then they tested the accuracy of their

00:14:15.260 --> 00:14:15.270
then they tested the accuracy of their
 

00:14:15.270 --> 00:14:18.560
then they tested the accuracy of their
model on a test data set and as you may

00:14:18.560 --> 00:14:18.570
model on a test data set and as you may
 

00:14:18.570 --> 00:14:22.090
model on a test data set and as you may
expect the accuracy of their models

00:14:22.090 --> 00:14:22.100
expect the accuracy of their models
 

00:14:22.100 --> 00:14:24.590
expect the accuracy of their models
progressively decreased as the

00:14:24.590 --> 00:14:24.600
progressively decreased as the
 

00:14:24.600 --> 00:14:27.190
progressively decreased as the
randomness in the training data set

00:14:27.190 --> 00:14:27.200
randomness in the training data set
 

00:14:27.200 --> 00:14:30.620
randomness in the training data set
increased right but what was really

00:14:30.620 --> 00:14:30.630
increased right but what was really
 

00:14:30.630 --> 00:14:33.350
increased right but what was really
interesting was when they tried was what

00:14:33.350 --> 00:14:33.360
interesting was when they tried was what
 

00:14:33.360 --> 00:14:35.390
interesting was when they tried was what
happened when they looked at what

00:14:35.390 --> 00:14:35.400
happened when they looked at what
 

00:14:35.400 --> 00:14:37.640
happened when they looked at what
happened in the training data set and

00:14:37.640 --> 00:14:37.650
happened in the training data set and
 

00:14:37.650 --> 00:14:40.580
happened in the training data set and
this is what they found that no matter

00:14:40.580 --> 00:14:40.590
this is what they found that no matter
 

00:14:40.590 --> 00:14:43.280
this is what they found that no matter
how much they randomized the labels the

00:14:43.280 --> 00:14:43.290
how much they randomized the labels the
 

00:14:43.290 --> 00:14:46.070
how much they randomized the labels the
model was able to get 100% accuracy on

00:14:46.070 --> 00:14:46.080
model was able to get 100% accuracy on
 

00:14:46.080 --> 00:14:47.870
model was able to get 100% accuracy on
the training set right because in

00:14:47.870 --> 00:14:47.880
the training set right because in
 

00:14:47.880 --> 00:14:50.810
the training set right because in
training you know you're doing input

00:14:50.810 --> 00:14:50.820
training you know you're doing input
 

00:14:50.820 --> 00:14:55.190
training you know you're doing input
label you know both right and this is a

00:14:55.190 --> 00:14:55.200
label you know both right and this is a
 

00:14:55.200 --> 00:14:57.440
label you know both right and this is a
really powerful example because it shows

00:14:57.440 --> 00:14:57.450
really powerful example because it shows
 

00:14:57.450 --> 00:15:00.170
really powerful example because it shows
once again in a similar way as the

00:15:00.170 --> 00:15:00.180
once again in a similar way as the
 

00:15:00.180 --> 00:15:02.000
once again in a similar way as the
universal approximation theorem that

00:15:02.000 --> 00:15:02.010
universal approximation theorem that
 

00:15:02.010 --> 00:15:04.580
universal approximation theorem that
deep neural Nets can perfectly fit to

00:15:04.580 --> 00:15:04.590
deep neural Nets can perfectly fit to
 

00:15:04.590 --> 00:15:08.000
deep neural Nets can perfectly fit to
any function even if that function sort

00:15:08.000 --> 00:15:08.010
any function even if that function sort
 

00:15:08.010 --> 00:15:11.000
any function even if that function sort
of is based on entirely random labels

00:15:11.000 --> 00:15:11.010
of is based on entirely random labels
 

00:15:11.010 --> 00:15:14.510
of is based on entirely random labels
and to drive this point home we can

00:15:14.510 --> 00:15:14.520
and to drive this point home we can
 

00:15:14.520 --> 00:15:16.760
and to drive this point home we can
understand neural networks simply as

00:15:16.760 --> 00:15:16.770
understand neural networks simply as
 

00:15:16.770 --> 00:15:20.300
understand neural networks simply as
functional approximator x' and only

00:15:20.300 --> 00:15:20.310
functional approximator x' and only
 

00:15:20.310 --> 00:15:22.940
functional approximator x' and only
universal function approximation theorem

00:15:22.940 --> 00:15:22.950
universal function approximation theorem
 

00:15:22.950 --> 00:15:25.520
universal function approximation theorem
States is that neural networks are

00:15:25.520 --> 00:15:25.530
States is that neural networks are
 

00:15:25.530 --> 00:15:28.420
States is that neural networks are
really really good at doing this so

00:15:28.420 --> 00:15:28.430
really really good at doing this so
 

00:15:28.430 --> 00:15:31.400
really really good at doing this so
suppose you have this you know the set

00:15:31.400 --> 00:15:31.410
suppose you have this you know the set
 

00:15:31.410 --> 00:15:32.900
suppose you have this you know the set
of training data

00:15:32.900 --> 00:15:32.910
of training data
 

00:15:32.910 --> 00:15:36.200
of training data
we can learn you we can use a neural

00:15:36.200 --> 00:15:36.210
we can learn you we can use a neural
 

00:15:36.210 --> 00:15:38.870
we can learn you we can use a neural
network to learn a maximum likelihood

00:15:38.870 --> 00:15:38.880
network to learn a maximum likelihood
 

00:15:38.880 --> 00:15:42.980
network to learn a maximum likelihood
estimate of this training data and if we

00:15:42.980 --> 00:15:42.990
estimate of this training data and if we
 

00:15:42.990 --> 00:15:44.690
estimate of this training data and if we
were to give the model a new data point

00:15:44.690 --> 00:15:44.700
were to give the model a new data point
 

00:15:44.700 --> 00:15:48.710
were to give the model a new data point
shown here in this purple arrow we can

00:15:48.710 --> 00:15:48.720
shown here in this purple arrow we can
 

00:15:48.720 --> 00:15:52.010
shown here in this purple arrow we can
use it to predict what the maximum

00:15:52.010 --> 00:15:52.020
use it to predict what the maximum
 

00:15:52.020 --> 00:15:54.500
use it to predict what the maximum
likelihood estimate for that data point

00:15:54.500 --> 00:15:54.510
likelihood estimate for that data point
 

00:15:54.510 --> 00:15:57.890
likelihood estimate for that data point
is going to be but if we extend the axis

00:15:57.890 --> 00:15:57.900
is going to be but if we extend the axis
 

00:15:57.900 --> 00:16:00.080
is going to be but if we extend the axis
a bit left and right outside of the

00:16:00.080 --> 00:16:00.090
a bit left and right outside of the
 

00:16:00.090 --> 00:16:01.670
a bit left and right outside of the
space of the training data that the

00:16:01.670 --> 00:16:01.680
space of the training data that the
 

00:16:01.680 --> 00:16:04.540
space of the training data that the
network has seen what happens right

00:16:04.540 --> 00:16:04.550
network has seen what happens right
 

00:16:04.550 --> 00:16:07.430
network has seen what happens right
there are no guarantees on what the

00:16:07.430 --> 00:16:07.440
there are no guarantees on what the
 

00:16:07.440 --> 00:16:09.110
there are no guarantees on what the
training data will look like outside

00:16:09.110 --> 00:16:09.120
training data will look like outside
 

00:16:09.120 --> 00:16:11.480
training data will look like outside
these bounds and this is a huge

00:16:11.480 --> 00:16:11.490
these bounds and this is a huge
 

00:16:11.490 --> 00:16:15.140
these bounds and this is a huge
limitation that exists in modern deep

00:16:15.140 --> 00:16:15.150
limitation that exists in modern deep
 

00:16:15.150 --> 00:16:17.360
limitation that exists in modern deep
neural networks and and in deep learning

00:16:17.360 --> 00:16:17.370
neural networks and and in deep learning
 

00:16:17.370 --> 00:16:21.140
neural networks and and in deep learning
generally and so you know if you look

00:16:21.140 --> 00:16:21.150
generally and so you know if you look
 

00:16:21.150 --> 00:16:23.960
generally and so you know if you look
here outside of these bounds that the

00:16:23.960 --> 00:16:23.970
here outside of these bounds that the
 

00:16:23.970 --> 00:16:26.690
here outside of these bounds that the
network has been trained on we can't

00:16:26.690 --> 00:16:26.700
network has been trained on we can't
 

00:16:26.700 --> 00:16:28.400
network has been trained on we can't
really know what our function looks like

00:16:28.400 --> 00:16:28.410
really know what our function looks like
 

00:16:28.410 --> 00:16:31.160
really know what our function looks like
if the network has never seen data from

00:16:31.160 --> 00:16:31.170
if the network has never seen data from
 

00:16:31.170 --> 00:16:34.280
if the network has never seen data from
those pieces before right so it's not

00:16:34.280 --> 00:16:34.290
those pieces before right so it's not
 

00:16:34.290 --> 00:16:38.200
those pieces before right so it's not
going to do very well and this notion

00:16:38.200 --> 00:16:38.210
going to do very well and this notion
 

00:16:38.210 --> 00:16:41.150
going to do very well and this notion
leaves really nicely into this idea of

00:16:41.150 --> 00:16:41.160
leaves really nicely into this idea of
 

00:16:41.160 --> 00:16:43.640
leaves really nicely into this idea of
what's known as adversarial attacks on

00:16:43.640 --> 00:16:43.650
what's known as adversarial attacks on
 

00:16:43.650 --> 00:16:46.670
what's known as adversarial attacks on
neural networks and the idea here is to

00:16:46.670 --> 00:16:46.680
neural networks and the idea here is to
 

00:16:46.680 --> 00:16:49.520
neural networks and the idea here is to
take some example for example this this

00:16:49.520 --> 00:16:49.530
take some example for example this this
 

00:16:49.530 --> 00:16:52.340
take some example for example this this
image of what you can see is a temple

00:16:52.340 --> 00:16:52.350
image of what you can see is a temple
 

00:16:52.350 --> 00:16:56.090
image of what you can see is a temple
which a standard CNN trained on imagenet

00:16:56.090 --> 00:16:56.100
which a standard CNN trained on imagenet
 

00:16:56.100 --> 00:16:58.640
which a standard CNN trained on imagenet
let's say can classify as a temple with

00:16:58.640 --> 00:16:58.650
let's say can classify as a temple with
 

00:16:58.650 --> 00:17:02.210
let's say can classify as a temple with
you know 97 percent probability and then

00:17:02.210 --> 00:17:02.220
you know 97 percent probability and then
 

00:17:02.220 --> 00:17:05.120
you know 97 percent probability and then
we can apply some perturbation to that

00:17:05.120 --> 00:17:05.130
we can apply some perturbation to that
 

00:17:05.130 --> 00:17:08.449
we can apply some perturbation to that
image to generate what we call an

00:17:08.449 --> 00:17:08.459
image to generate what we call an
 

00:17:08.459 --> 00:17:11.150
image to generate what we call an
adversarial example which to us looks

00:17:11.150 --> 00:17:11.160
adversarial example which to us looks
 

00:17:11.160 --> 00:17:14.329
adversarial example which to us looks
completely similar to the original image

00:17:14.329 --> 00:17:14.339
completely similar to the original image
 

00:17:14.339 --> 00:17:17.540
completely similar to the original image
right but if we were now to feed this

00:17:17.540 --> 00:17:17.550
right but if we were now to feed this
 

00:17:17.550 --> 00:17:19.910
right but if we were now to feed this
adversarial example through that same

00:17:19.910 --> 00:17:19.920
adversarial example through that same
 

00:17:19.920 --> 00:17:22.550
adversarial example through that same
CNN we can no longer recognize it as a

00:17:22.550 --> 00:17:22.560
CNN we can no longer recognize it as a
 

00:17:22.560 --> 00:17:25.309
CNN we can no longer recognize it as a
temple you know and instead we predict

00:17:25.309 --> 00:17:25.319
temple you know and instead we predict
 

00:17:25.319 --> 00:17:27.020
temple you know and instead we predict
okay this is an image of an ostrich

00:17:27.020 --> 00:17:27.030
okay this is an image of an ostrich
 

00:17:27.030 --> 00:17:29.050
okay this is an image of an ostrich
right that makes no sense right so

00:17:29.050 --> 00:17:29.060
right that makes no sense right so
 

00:17:29.060 --> 00:17:32.360
right that makes no sense right so
what's going on what is it about these

00:17:32.360 --> 00:17:32.370
what's going on what is it about these
 

00:17:32.370 --> 00:17:34.010
what's going on what is it about these
perturbations and how are we generating

00:17:34.010 --> 00:17:34.020
perturbations and how are we generating
 

00:17:34.020 --> 00:17:37.310
perturbations and how are we generating
them that we're able to fool the network

00:17:37.310 --> 00:17:37.320
them that we're able to fool the network
 

00:17:37.320 --> 00:17:41.360
them that we're able to fool the network
in in this way so remember that normally

00:17:41.360 --> 00:17:41.370
in in this way so remember that normally
 

00:17:41.370 --> 00:17:43.370
in in this way so remember that normally
during training when we train our

00:17:43.370 --> 00:17:43.380
during training when we train our
 

00:17:43.380 --> 00:17:45.320
during training when we train our
network using gradient descent

00:17:45.320 --> 00:17:45.330
network using gradient descent
 

00:17:45.330 --> 00:17:47.749
network using gradient descent
we have some like objective loss

00:17:47.749 --> 00:17:47.759
we have some like objective loss
 

00:17:47.759 --> 00:17:51.169
we have some like objective loss
function J right that we're trying to

00:17:51.169 --> 00:17:51.179
function J right that we're trying to
 

00:17:51.179 --> 00:17:54.159
function J right that we're trying to
optimize given a set of weights theta

00:17:54.159 --> 00:17:54.169
optimize given a set of weights theta
 

00:17:54.169 --> 00:17:59.889
optimize given a set of weights theta
input data X and some output label Y and

00:17:59.889 --> 00:17:59.899
input data X and some output label Y and
 

00:17:59.899 --> 00:18:03.320
input data X and some output label Y and
what we're asking is how does a small

00:18:03.320 --> 00:18:03.330
what we're asking is how does a small
 

00:18:03.330 --> 00:18:06.789
what we're asking is how does a small
shift in the weights change our loss

00:18:06.789 --> 00:18:06.799
shift in the weights change our loss
 

00:18:06.799 --> 00:18:09.799
shift in the weights change our loss
specifically how can we change our

00:18:09.799 --> 00:18:09.809
specifically how can we change our
 

00:18:09.809 --> 00:18:12.200
specifically how can we change our
weights theta in some way to minimize

00:18:12.200 --> 00:18:12.210
weights theta in some way to minimize
 

00:18:12.210 --> 00:18:15.669
weights theta in some way to minimize
this loss and when we train our networks

00:18:15.669 --> 00:18:15.679
this loss and when we train our networks
 

00:18:15.679 --> 00:18:18.950
this loss and when we train our networks
to you know optimize this set of weights

00:18:18.950 --> 00:18:18.960
to you know optimize this set of weights
 

00:18:18.960 --> 00:18:22.759
to you know optimize this set of weights
we're using a fixed input X and a fixed

00:18:22.759 --> 00:18:22.769
we're using a fixed input X and a fixed
 

00:18:22.769 --> 00:18:26.210
we're using a fixed input X and a fixed
label Y and we're again reiterating

00:18:26.210 --> 00:18:26.220
label Y and we're again reiterating
 

00:18:26.220 --> 00:18:28.489
label Y and we're again reiterating
trying to update our weights to minimize

00:18:28.489 --> 00:18:28.499
trying to update our weights to minimize
 

00:18:28.499 --> 00:18:32.810
trying to update our weights to minimize
that loss with adversarial attacks we're

00:18:32.810 --> 00:18:32.820
that loss with adversarial attacks we're
 

00:18:32.820 --> 00:18:35.919
that loss with adversarial attacks we're
asking a different problem how can we

00:18:35.919 --> 00:18:35.929
asking a different problem how can we
 

00:18:35.929 --> 00:18:40.070
asking a different problem how can we
modify our input our input for example

00:18:40.070 --> 00:18:40.080
modify our input our input for example
 

00:18:40.080 --> 00:18:42.950
modify our input our input for example
an image our input X in order to now

00:18:42.950 --> 00:18:42.960
an image our input X in order to now
 

00:18:42.960 --> 00:18:46.190
an image our input X in order to now
increase the error in our networks

00:18:46.190 --> 00:18:46.200
increase the error in our networks
 

00:18:46.200 --> 00:18:50.149
increase the error in our networks
prediction so we're trying to optimize

00:18:50.149 --> 00:18:50.159
prediction so we're trying to optimize
 

00:18:50.159 --> 00:18:53.989
prediction so we're trying to optimize
over the input X right to perturb it in

00:18:53.989 --> 00:18:53.999
over the input X right to perturb it in
 

00:18:53.999 --> 00:18:57.440
over the input X right to perturb it in
some way given a fixed set of weights

00:18:57.440 --> 00:18:57.450
some way given a fixed set of weights
 

00:18:57.450 --> 00:19:01.759
some way given a fixed set of weights
theta and a fixed output Y and instead

00:19:01.759 --> 00:19:01.769
theta and a fixed output Y and instead
 

00:19:01.769 --> 00:19:03.739
theta and a fixed output Y and instead
of minimizing the loss we're now trying

00:19:03.739 --> 00:19:03.749
of minimizing the loss we're now trying
 

00:19:03.749 --> 00:19:06.349
of minimizing the loss we're now trying
to increase the loss to try to fool our

00:19:06.349 --> 00:19:06.359
to increase the loss to try to fool our
 

00:19:06.359 --> 00:19:08.989
to increase the loss to try to fool our
network into making incorrect

00:19:08.989 --> 00:19:08.999
network into making incorrect
 

00:19:08.999 --> 00:19:12.289
network into making incorrect
predictions and an extension of this

00:19:12.289 --> 00:19:12.299
predictions and an extension of this
 

00:19:12.299 --> 00:19:14.810
predictions and an extension of this
idea was recently presented by a group

00:19:14.810 --> 00:19:14.820
idea was recently presented by a group
 

00:19:14.820 --> 00:19:17.960
idea was recently presented by a group
of students here at MIT and they devised

00:19:17.960 --> 00:19:17.970
of students here at MIT and they devised
 

00:19:17.970 --> 00:19:21.349
of students here at MIT and they devised
an algorithm for synthesizing a set of

00:19:21.349 --> 00:19:21.359
an algorithm for synthesizing a set of
 

00:19:21.359 --> 00:19:24.830
an algorithm for synthesizing a set of
examples that would be adversarial over

00:19:24.830 --> 00:19:24.840
examples that would be adversarial over
 

00:19:24.840 --> 00:19:28.009
examples that would be adversarial over
a diverse set of transformations like

00:19:28.009 --> 00:19:28.019
a diverse set of transformations like
 

00:19:28.019 --> 00:19:31.070
a diverse set of transformations like
rotations or color changes and so the

00:19:31.070 --> 00:19:31.080
rotations or color changes and so the
 

00:19:31.080 --> 00:19:32.599
rotations or color changes and so the
first thing that they demonstrated was

00:19:32.599 --> 00:19:32.609
first thing that they demonstrated was
 

00:19:32.609 --> 00:19:34.759
first thing that they demonstrated was
that they were able to generate 2d

00:19:34.759 --> 00:19:34.769
that they were able to generate 2d
 

00:19:34.769 --> 00:19:38.389
that they were able to generate 2d
images that were robust to noise

00:19:38.389 --> 00:19:38.399
images that were robust to noise
 

00:19:38.399 --> 00:19:40.729
images that were robust to noise
transformations distortions other

00:19:40.729 --> 00:19:40.739
transformations distortions other
 

00:19:40.739 --> 00:19:43.220
transformations distortions other
transformations but what was really

00:19:43.220 --> 00:19:43.230
transformations but what was really
 

00:19:43.230 --> 00:19:44.239
transformations but what was really
really cool

00:19:44.239 --> 00:19:44.249
really cool
 

00:19:44.249 --> 00:19:46.220
really cool
was that they actually showed that they

00:19:46.220 --> 00:19:46.230
was that they actually showed that they
 

00:19:46.230 --> 00:19:49.549
was that they actually showed that they
could extend this idea to 3d objects and

00:19:49.549 --> 00:19:49.559
could extend this idea to 3d objects and
 

00:19:49.559 --> 00:19:51.979
could extend this idea to 3d objects and
they actually used 3d printing to create

00:19:51.979 --> 00:19:51.989
they actually used 3d printing to create
 

00:19:51.989 --> 00:19:55.310
they actually used 3d printing to create
actual physical adversarial objects and

00:19:55.310 --> 00:19:55.320
actual physical adversarial objects and
 

00:19:55.320 --> 00:19:58.440
actual physical adversarial objects and
this was the first demonstration of

00:19:58.440 --> 00:19:58.450
this was the first demonstration of
 

00:19:58.450 --> 00:20:01.230
this was the first demonstration of
Rosario examples that exist in the

00:20:01.230 --> 00:20:01.240
Rosario examples that exist in the
 

00:20:01.240 --> 00:20:04.980
Rosario examples that exist in the
physical world so what they did in in

00:20:04.980 --> 00:20:04.990
physical world so what they did in in
 

00:20:04.990 --> 00:20:07.920
physical world so what they did in in
this result shown here is that they 3d

00:20:07.920 --> 00:20:07.930
this result shown here is that they 3d
 

00:20:07.930 --> 00:20:11.460
this result shown here is that they 3d
printed a set of turtles that were

00:20:11.460 --> 00:20:11.470
printed a set of turtles that were
 

00:20:11.470 --> 00:20:14.910
printed a set of turtles that were
designed to be adversarial to a you know

00:20:14.910 --> 00:20:14.920
designed to be adversarial to a you know
 

00:20:14.920 --> 00:20:18.480
designed to be adversarial to a you know
a given network and took images of those

00:20:18.480 --> 00:20:18.490
a given network and took images of those
 

00:20:18.490 --> 00:20:22.830
a given network and took images of those
of those turtles and fed them in through

00:20:22.830 --> 00:20:22.840
of those turtles and fed them in through
 

00:20:22.840 --> 00:20:25.500
of those turtles and fed them in through
the network and in the majority of cases

00:20:25.500 --> 00:20:25.510
the network and in the majority of cases
 

00:20:25.510 --> 00:20:29.940
the network and in the majority of cases
right the network classifies these 3d

00:20:29.940 --> 00:20:29.950
right the network classifies these 3d
 

00:20:29.950 --> 00:20:34.020
right the network classifies these 3d
turtles as rifles right and these these

00:20:34.020 --> 00:20:34.030
turtles as rifles right and these these
 

00:20:34.030 --> 00:20:37.170
turtles as rifles right and these these
objects are designed to be adversarial

00:20:37.170 --> 00:20:37.180
objects are designed to be adversarial
 

00:20:37.180 --> 00:20:40.200
objects are designed to be adversarial
they're designed to fool the network so

00:20:40.200 --> 00:20:40.210
they're designed to fool the network so
 

00:20:40.210 --> 00:20:42.690
they're designed to fool the network so
this is pretty scary right and you know

00:20:42.690 --> 00:20:42.700
this is pretty scary right and you know
 

00:20:42.700 --> 00:20:46.350
this is pretty scary right and you know
it opens a whole Pandora's box of how

00:20:46.350 --> 00:20:46.360
it opens a whole Pandora's box of how
 

00:20:46.360 --> 00:20:49.170
it opens a whole Pandora's box of how
can we trick networks and and has some

00:20:49.170 --> 00:20:49.180
can we trick networks and and has some
 

00:20:49.180 --> 00:20:51.090
can we trick networks and and has some
pretty severe implications for things

00:20:51.090 --> 00:20:51.100
pretty severe implications for things
 

00:20:51.100 --> 00:20:54.300
pretty severe implications for things
like security and so these are just a

00:20:54.300 --> 00:20:54.310
like security and so these are just a
 

00:20:54.310 --> 00:20:56.760
like security and so these are just a
couple of limitations that of neural

00:20:56.760 --> 00:20:56.770
couple of limitations that of neural
 

00:20:56.770 --> 00:20:59.280
couple of limitations that of neural
networks that I've highlighted here you

00:20:59.280 --> 00:20:59.290
networks that I've highlighted here you
 

00:20:59.290 --> 00:21:01.440
networks that I've highlighted here you
know as we've sort of touched on

00:21:01.440 --> 00:21:01.450
know as we've sort of touched on
 

00:21:01.450 --> 00:21:03.660
know as we've sort of touched on
throughout this course they're very data

00:21:03.660 --> 00:21:03.670
throughout this course they're very data
 

00:21:03.670 --> 00:21:06.510
throughout this course they're very data
hungry it's computationally intensive to

00:21:06.510 --> 00:21:06.520
hungry it's computationally intensive to
 

00:21:06.520 --> 00:21:08.400
hungry it's computationally intensive to
train them they can be fooled by

00:21:08.400 --> 00:21:08.410
train them they can be fooled by
 

00:21:08.410 --> 00:21:11.700
train them they can be fooled by
adversarial examples they can be subject

00:21:11.700 --> 00:21:11.710
adversarial examples they can be subject
 

00:21:11.710 --> 00:21:15.270
adversarial examples they can be subject
to algorithmic bias they're relatively

00:21:15.270 --> 00:21:15.280
to algorithmic bias they're relatively
 

00:21:15.280 --> 00:21:19.350
to algorithmic bias they're relatively
poor at representing uncertainty then a

00:21:19.350 --> 00:21:19.360
poor at representing uncertainty then a
 

00:21:19.360 --> 00:21:21.480
poor at representing uncertainty then a
big point is this this question of

00:21:21.480 --> 00:21:21.490
big point is this this question of
 

00:21:21.490 --> 00:21:23.730
big point is this this question of
interpretability right are known

00:21:23.730 --> 00:21:23.740
interpretability right are known
 

00:21:23.740 --> 00:21:25.800
interpretability right are known
networks just black boxes that you can't

00:21:25.800 --> 00:21:25.810
networks just black boxes that you can't
 

00:21:25.810 --> 00:21:31.050
networks just black boxes that you can't
peer into and sort of in the ml and AI

00:21:31.050 --> 00:21:31.060
peer into and sort of in the ml and AI
 

00:21:31.060 --> 00:21:34.860
peer into and sort of in the ml and AI
community people tend to fall you know

00:21:34.860 --> 00:21:34.870
community people tend to fall you know
 

00:21:34.870 --> 00:21:37.230
community people tend to fall you know
in sort of two camps one camp saying

00:21:37.230 --> 00:21:37.240
in sort of two camps one camp saying
 

00:21:37.240 --> 00:21:39.600
in sort of two camps one camp saying
interpret interpret ability of neural

00:21:39.600 --> 00:21:39.610
interpret interpret ability of neural
 

00:21:39.610 --> 00:21:41.700
interpret interpret ability of neural
networks matters a lot it's something

00:21:41.700 --> 00:21:41.710
networks matters a lot it's something
 

00:21:41.710 --> 00:21:43.470
networks matters a lot it's something
that we should devote a lot of energy

00:21:43.470 --> 00:21:43.480
that we should devote a lot of energy
 

00:21:43.480 --> 00:21:46.380
that we should devote a lot of energy
and thought into and others that very

00:21:46.380 --> 00:21:46.390
and thought into and others that very
 

00:21:46.390 --> 00:21:48.450
and thought into and others that very
strongly argue that oh no we should not

00:21:48.450 --> 00:21:48.460
strongly argue that oh no we should not
 

00:21:48.460 --> 00:21:49.920
strongly argue that oh no we should not
really concern ourselves with

00:21:49.920 --> 00:21:49.930
really concern ourselves with
 

00:21:49.930 --> 00:21:52.380
really concern ourselves with
interpretability what's more important

00:21:52.380 --> 00:21:52.390
interpretability what's more important
 

00:21:52.390 --> 00:21:55.560
interpretability what's more important
is you know generating these

00:21:55.560 --> 00:21:55.570
is you know generating these
 

00:21:55.570 --> 00:21:57.480
is you know generating these
architectures that perform really really

00:21:57.480 --> 00:21:57.490
architectures that perform really really
 

00:21:57.490 --> 00:22:02.880
architectures that perform really really
well on a task of interest and in going

00:22:02.880 --> 00:22:02.890
well on a task of interest and in going
 

00:22:02.890 --> 00:22:05.160
well on a task of interest and in going
from limitations to sort of new

00:22:05.160 --> 00:22:05.170
from limitations to sort of new
 

00:22:05.170 --> 00:22:07.590
from limitations to sort of new
frontiers in emerging areas in deep

00:22:07.590 --> 00:22:07.600
frontiers in emerging areas in deep
 

00:22:07.600 --> 00:22:09.690
frontiers in emerging areas in deep
learning research I like to focus on

00:22:09.690 --> 00:22:09.700
learning research I like to focus on
 

00:22:09.700 --> 00:22:12.130
learning research I like to focus on
these two sort of

00:22:12.130 --> 00:22:12.140
these two sort of
 

00:22:12.140 --> 00:22:14.740
these two sort of
of points highlighted here the first is

00:22:14.740 --> 00:22:14.750
of points highlighted here the first is
 

00:22:14.750 --> 00:22:17.190
of points highlighted here the first is
the notion of understanding uncertainty

00:22:17.190 --> 00:22:17.200
the notion of understanding uncertainty
 

00:22:17.200 --> 00:22:21.100
the notion of understanding uncertainty
and the second is ways in which we can

00:22:21.100 --> 00:22:21.110
and the second is ways in which we can
 

00:22:21.110 --> 00:22:25.920
and the second is ways in which we can
move past building models that are

00:22:25.920 --> 00:22:25.930
move past building models that are
 

00:22:25.930 --> 00:22:29.350
move past building models that are
optimized for a single task to actually

00:22:29.350 --> 00:22:29.360
optimized for a single task to actually
 

00:22:29.360 --> 00:22:32.350
optimized for a single task to actually
learning how to build a model capable of

00:22:32.350 --> 00:22:32.360
learning how to build a model capable of
 

00:22:32.360 --> 00:22:34.660
learning how to build a model capable of
solving not one but many different

00:22:34.660 --> 00:22:34.670
solving not one but many different
 

00:22:34.670 --> 00:22:37.600
solving not one but many different
problems so the first sort of new

00:22:37.600 --> 00:22:37.610
problems so the first sort of new
 

00:22:37.610 --> 00:22:39.700
problems so the first sort of new
frontier is this field called Bayesian

00:22:39.700 --> 00:22:39.710
frontier is this field called Bayesian
 

00:22:39.710 --> 00:22:42.160
frontier is this field called Bayesian
deep learning and so if we consider

00:22:42.160 --> 00:22:42.170
deep learning and so if we consider
 

00:22:42.170 --> 00:22:44.290
deep learning and so if we consider
again right the very simple problem of

00:22:44.290 --> 00:22:44.300
again right the very simple problem of
 

00:22:44.300 --> 00:22:47.080
again right the very simple problem of
image classification what we've learned

00:22:47.080 --> 00:22:47.090
image classification what we've learned
 

00:22:47.090 --> 00:22:49.210
image classification what we've learned
so far is has been about modeling

00:22:49.210 --> 00:22:49.220
so far is has been about modeling
 

00:22:49.220 --> 00:22:51.670
so far is has been about modeling
probabilities over a fixed number of

00:22:51.670 --> 00:22:51.680
probabilities over a fixed number of
 

00:22:51.680 --> 00:22:55.150
probabilities over a fixed number of
classes so if if we are to train a model

00:22:55.150 --> 00:22:55.160
classes so if if we are to train a model
 

00:22:55.160 --> 00:22:58.420
classes so if if we are to train a model
to predict you know dogs versus cats we

00:22:58.420 --> 00:22:58.430
to predict you know dogs versus cats we
 

00:22:58.430 --> 00:23:00.610
to predict you know dogs versus cats we
output some probability that an input

00:23:00.610 --> 00:23:00.620
output some probability that an input
 

00:23:00.620 --> 00:23:05.440
output some probability that an input
image is either a dog or a cat but I'd

00:23:05.440 --> 00:23:05.450
image is either a dog or a cat but I'd
 

00:23:05.450 --> 00:23:07.510
image is either a dog or a cat but I'd
like to draw a distinction between a

00:23:07.510 --> 00:23:07.520
like to draw a distinction between a
 

00:23:07.520 --> 00:23:10.510
like to draw a distinction between a
probability and this notion of

00:23:10.510 --> 00:23:10.520
probability and this notion of
 

00:23:10.520 --> 00:23:13.270
probability and this notion of
uncertainty or confidence so if we were

00:23:13.270 --> 00:23:13.280
uncertainty or confidence so if we were
 

00:23:13.280 --> 00:23:15.610
uncertainty or confidence so if we were
to feed in in the image of a horse into

00:23:15.610 --> 00:23:15.620
to feed in in the image of a horse into
 

00:23:15.620 --> 00:23:17.860
to feed in in the image of a horse into
this network for example we would still

00:23:17.860 --> 00:23:17.870
this network for example we would still
 

00:23:17.870 --> 00:23:21.030
this network for example we would still
output a probability of being dog or cat

00:23:21.030 --> 00:23:21.040
output a probability of being dog or cat
 

00:23:21.040 --> 00:23:23.890
output a probability of being dog or cat
because right probabilities need to sum

00:23:23.890 --> 00:23:23.900
because right probabilities need to sum
 

00:23:23.900 --> 00:23:27.340
because right probabilities need to sum
to one but the model may even even if

00:23:27.340 --> 00:23:27.350
to one but the model may even even if
 

00:23:27.350 --> 00:23:29.080
to one but the model may even even if
it's more saying that it's more likely

00:23:29.080 --> 00:23:29.090
it's more saying that it's more likely
 

00:23:29.090 --> 00:23:31.930
it's more saying that it's more likely
that this image of is of a horse it may

00:23:31.930 --> 00:23:31.940
that this image of is of a horse it may
 

00:23:31.940 --> 00:23:34.390
that this image of is of a horse it may
be more uncertain in terms of you know

00:23:34.390 --> 00:23:34.400
be more uncertain in terms of you know
 

00:23:34.400 --> 00:23:39.000
be more uncertain in terms of you know
its confidence in that prediction and

00:23:39.000 --> 00:23:39.010
its confidence in that prediction and
 

00:23:39.010 --> 00:23:41.530
its confidence in that prediction and
there's this whole field of Bayesian

00:23:41.530 --> 00:23:41.540
there's this whole field of Bayesian
 

00:23:41.540 --> 00:23:45.400
there's this whole field of Bayesian
deep learning that looks at modeling and

00:23:45.400 --> 00:23:45.410
deep learning that looks at modeling and
 

00:23:45.410 --> 00:23:48.190
deep learning that looks at modeling and
understanding uncertainty in deep neural

00:23:48.190 --> 00:23:48.200
understanding uncertainty in deep neural
 

00:23:48.200 --> 00:23:52.450
understanding uncertainty in deep neural
networks and sort of this gets into a

00:23:52.450 --> 00:23:52.460
networks and sort of this gets into a
 

00:23:52.460 --> 00:23:56.560
networks and sort of this gets into a
lot of of statistics but the key idea is

00:23:56.560 --> 00:23:56.570
lot of of statistics but the key idea is
 

00:23:56.570 --> 00:23:59.080
lot of of statistics but the key idea is
that Bayesian neural networks are trying

00:23:59.080 --> 00:23:59.090
that Bayesian neural networks are trying
 

00:23:59.090 --> 00:24:01.540
that Bayesian neural networks are trying
to rather than learn a set of weights

00:24:01.540 --> 00:24:01.550
to rather than learn a set of weights
 

00:24:01.550 --> 00:24:04.210
to rather than learn a set of weights
they're trying to learn a distribution

00:24:04.210 --> 00:24:04.220
they're trying to learn a distribution
 

00:24:04.220 --> 00:24:07.210
they're trying to learn a distribution
over the possible weights right given

00:24:07.210 --> 00:24:07.220
over the possible weights right given
 

00:24:07.220 --> 00:24:13.570
over the possible weights right given
some input data X and some output labels

00:24:13.570 --> 00:24:13.580
some input data X and some output labels
 

00:24:13.580 --> 00:24:16.810
some input data X and some output labels
Y and to actually parameterize this

00:24:16.810 --> 00:24:16.820
Y and to actually parameterize this
 

00:24:16.820 --> 00:24:20.530
Y and to actually parameterize this
problem they use Bayes rule which is a

00:24:20.530 --> 00:24:20.540
problem they use Bayes rule which is a
 

00:24:20.540 --> 00:24:23.560
problem they use Bayes rule which is a
fundamental you know law from from

00:24:23.560 --> 00:24:23.570
fundamental you know law from from
 

00:24:23.570 --> 00:24:25.180
fundamental you know law from from
probability theory

00:24:25.180 --> 00:24:25.190
probability theory
 

00:24:25.190 --> 00:24:28.149
probability theory
but in practice this what's called this

00:24:28.149 --> 00:24:28.159
but in practice this what's called this
 

00:24:28.159 --> 00:24:31.060
but in practice this what's called this
posterior distribution of the likelihood

00:24:31.060 --> 00:24:31.070
posterior distribution of the likelihood
 

00:24:31.070 --> 00:24:35.109
posterior distribution of the likelihood
the probe a set of weights given input

00:24:35.109 --> 00:24:35.119
the probe a set of weights given input
 

00:24:35.119 --> 00:24:37.330
the probe a set of weights given input
and output is computationally

00:24:37.330 --> 00:24:37.340
and output is computationally
 

00:24:37.340 --> 00:24:41.440
and output is computationally
intractable and so instead of we can't

00:24:41.440 --> 00:24:41.450
intractable and so instead of we can't
 

00:24:41.450 --> 00:24:43.599
intractable and so instead of we can't
learn this distribution directly so what

00:24:43.599 --> 00:24:43.609
learn this distribution directly so what
 

00:24:43.609 --> 00:24:47.080
learn this distribution directly so what
we can do is find ways to approximate

00:24:47.080 --> 00:24:47.090
we can do is find ways to approximate
 

00:24:47.090 --> 00:24:49.450
we can do is find ways to approximate
this posterior distribution through

00:24:49.450 --> 00:24:49.460
this posterior distribution through
 

00:24:49.460 --> 00:24:51.820
this posterior distribution through
different types of sampling operations

00:24:51.820 --> 00:24:51.830
different types of sampling operations
 

00:24:51.830 --> 00:24:54.489
different types of sampling operations
and one example of such a sampling

00:24:54.489 --> 00:24:54.499
and one example of such a sampling
 

00:24:54.499 --> 00:24:56.979
and one example of such a sampling
approach is to use the principle of

00:24:56.979 --> 00:24:56.989
approach is to use the principle of
 

00:24:56.989 --> 00:24:59.680
approach is to use the principle of
dropout which was introduced in the

00:24:59.680 --> 00:24:59.690
dropout which was introduced in the
 

00:24:59.690 --> 00:25:01.839
dropout which was introduced in the
first lecture to actually obtain an

00:25:01.839 --> 00:25:01.849
first lecture to actually obtain an
 

00:25:01.849 --> 00:25:05.619
first lecture to actually obtain an
estimate of the network's uncertainty so

00:25:05.619 --> 00:25:05.629
estimate of the network's uncertainty so
 

00:25:05.629 --> 00:25:07.749
estimate of the network's uncertainty so
if we look at what this may look like

00:25:07.749 --> 00:25:07.759
if we look at what this may look like
 

00:25:07.759 --> 00:25:10.629
if we look at what this may look like
for a network that's composed of

00:25:10.629 --> 00:25:10.639
for a network that's composed of
 

00:25:10.639 --> 00:25:14.919
for a network that's composed of
convolutional layers consisting of like

00:25:14.919 --> 00:25:14.929
convolutional layers consisting of like
 

00:25:14.929 --> 00:25:18.999
convolutional layers consisting of like
two dimensional feature Maps what how we

00:25:18.999 --> 00:25:19.009
two dimensional feature Maps what how we
 

00:25:19.009 --> 00:25:22.830
two dimensional feature Maps what how we
can use dropout to SMA uncertainty by

00:25:22.830 --> 00:25:22.840
can use dropout to SMA uncertainty by
 

00:25:22.840 --> 00:25:26.379
can use dropout to SMA uncertainty by
performing stochastic passes through the

00:25:26.379 --> 00:25:26.389
performing stochastic passes through the
 

00:25:26.389 --> 00:25:28.629
performing stochastic passes through the
network and each time we make a pass

00:25:28.629 --> 00:25:28.639
network and each time we make a pass
 

00:25:28.639 --> 00:25:32.019
network and each time we make a pass
through the network we sample each of

00:25:32.019 --> 00:25:32.029
through the network we sample each of
 

00:25:32.029 --> 00:25:33.940
through the network we sample each of
these sets of weights right these filter

00:25:33.940 --> 00:25:33.950
these sets of weights right these filter
 

00:25:33.950 --> 00:25:37.089
these sets of weights right these filter
maps according to some drop out mask

00:25:37.089 --> 00:25:37.099
maps according to some drop out mask
 

00:25:37.099 --> 00:25:39.789
maps according to some drop out mask
that these are either zeros or ones

00:25:39.789 --> 00:25:39.799
that these are either zeros or ones
 

00:25:39.799 --> 00:25:43.719
that these are either zeros or ones
meaning will will keep these weights

00:25:43.719 --> 00:25:43.729
meaning will will keep these weights
 

00:25:43.729 --> 00:25:45.940
meaning will will keep these weights
highlighted in blue and will discard

00:25:45.940 --> 00:25:45.950
highlighted in blue and will discard
 

00:25:45.950 --> 00:25:46.659
highlighted in blue and will discard
these weights

00:25:46.659 --> 00:25:46.669
these weights
 

00:25:46.669 --> 00:25:50.379
these weights
highlight highlighted and white to

00:25:50.379 --> 00:25:50.389
highlight highlighted and white to
 

00:25:50.389 --> 00:25:52.889
highlight highlighted and white to
generate this stochastic sample of our

00:25:52.889 --> 00:25:52.899
generate this stochastic sample of our
 

00:25:52.899 --> 00:25:57.399
generate this stochastic sample of our
original filters and from this these

00:25:57.399 --> 00:25:57.409
original filters and from this these
 

00:25:57.409 --> 00:25:59.919
original filters and from this these
passes what we can actually obtain is an

00:25:59.919 --> 00:25:59.929
passes what we can actually obtain is an
 

00:25:59.929 --> 00:26:04.749
passes what we can actually obtain is an
estimate of sort of the expected value

00:26:04.749 --> 00:26:04.759
estimate of sort of the expected value
 

00:26:04.759 --> 00:26:07.539
estimate of sort of the expected value
of the output labels given the input the

00:26:07.539 --> 00:26:07.549
of the output labels given the input the
 

00:26:07.549 --> 00:26:10.930
of the output labels given the input the
mean as well as this variance term which

00:26:10.930 --> 00:26:10.940
mean as well as this variance term which
 

00:26:10.940 --> 00:26:13.239
mean as well as this variance term which
provides an uncertainty estimate and

00:26:13.239 --> 00:26:13.249
provides an uncertainty estimate and
 

00:26:13.249 --> 00:26:17.399
provides an uncertainty estimate and
this is useful in understanding the

00:26:17.399 --> 00:26:17.409
this is useful in understanding the
 

00:26:17.409 --> 00:26:19.810
this is useful in understanding the
uncertainty of the model in making a

00:26:19.810 --> 00:26:19.820
uncertainty of the model in making a
 

00:26:19.820 --> 00:26:24.129
uncertainty of the model in making a
prediction and one application of this

00:26:24.129 --> 00:26:24.139
prediction and one application of this
 

00:26:24.139 --> 00:26:26.739
prediction and one application of this
type of approach is shown here in the

00:26:26.739 --> 00:26:26.749
type of approach is shown here in the
 

00:26:26.749 --> 00:26:29.589
type of approach is shown here in the
context of depth estimation so given

00:26:29.589 --> 00:26:29.599
context of depth estimation so given
 

00:26:29.599 --> 00:26:32.019
context of depth estimation so given
some input image we train a network to

00:26:32.019 --> 00:26:32.029
some input image we train a network to
 

00:26:32.029 --> 00:26:34.960
some input image we train a network to
predict the depth of the pixels present

00:26:34.960 --> 00:26:34.970
predict the depth of the pixels present
 

00:26:34.970 --> 00:26:37.400
predict the depth of the pixels present
in that image

00:26:37.400 --> 00:26:37.410
in that image
 

00:26:37.410 --> 00:26:39.860
in that image
we also asked it okay give us an

00:26:39.860 --> 00:26:39.870
we also asked it okay give us an
 

00:26:39.870 --> 00:26:42.500
we also asked it okay give us an
estimate of your uncertainty in making

00:26:42.500 --> 00:26:42.510
estimate of your uncertainty in making
 

00:26:42.510 --> 00:26:45.140
estimate of your uncertainty in making
that prediction and we when we visualize

00:26:45.140 --> 00:26:45.150
that prediction and we when we visualize
 

00:26:45.150 --> 00:26:47.390
that prediction and we when we visualize
that what you can see is that the model

00:26:47.390 --> 00:26:47.400
that what you can see is that the model
 

00:26:47.400 --> 00:26:50.029
that what you can see is that the model
is more uncertain in this sort of edge

00:26:50.029 --> 00:26:50.039
is more uncertain in this sort of edge
 

00:26:50.039 --> 00:26:54.440
is more uncertain in this sort of edge
here which makes sense if you look back

00:26:54.440 --> 00:26:54.450
here which makes sense if you look back
 

00:26:54.450 --> 00:26:57.470
here which makes sense if you look back
at this original input that the edge is

00:26:57.470 --> 00:26:57.480
at this original input that the edge is
 

00:26:57.480 --> 00:26:59.210
at this original input that the edge is
sort of at this point where those two

00:26:59.210 --> 00:26:59.220
sort of at this point where those two
 

00:26:59.220 --> 00:27:01.640
sort of at this point where those two
cars are overlapping and so you can

00:27:01.640 --> 00:27:01.650
cars are overlapping and so you can
 

00:27:01.650 --> 00:27:04.010
cars are overlapping and so you can
imagine that the model may have more

00:27:04.010 --> 00:27:04.020
imagine that the model may have more
 

00:27:04.020 --> 00:27:06.890
imagine that the model may have more
difficulty in estimating the pixels that

00:27:06.890 --> 00:27:06.900
difficulty in estimating the pixels that
 

00:27:06.900 --> 00:27:09.470
difficulty in estimating the pixels that
line that edge the depth of the pixels

00:27:09.470 --> 00:27:09.480
line that edge the depth of the pixels
 

00:27:09.480 --> 00:27:13.720
line that edge the depth of the pixels
that line that edge furthermore if you

00:27:13.720 --> 00:27:13.730
that line that edge furthermore if you
 

00:27:13.730 --> 00:27:16.520
that line that edge furthermore if you
remember from from yesterday's lecture I

00:27:16.520 --> 00:27:16.530
remember from from yesterday's lecture I
 

00:27:16.530 --> 00:27:19.640
remember from from yesterday's lecture I
showed this video which is worked from

00:27:19.640 --> 00:27:19.650
showed this video which is worked from
 

00:27:19.650 --> 00:27:22.220
showed this video which is worked from
the same group at Cambridge where they

00:27:22.220 --> 00:27:22.230
the same group at Cambridge where they
 

00:27:22.230 --> 00:27:24.909
the same group at Cambridge where they
trained a convolutional base

00:27:24.909 --> 00:27:24.919
trained a convolutional base
 

00:27:24.919 --> 00:27:27.010
trained a convolutional base
convolutional neural network based

00:27:27.010 --> 00:27:27.020
convolutional neural network based
 

00:27:27.020 --> 00:27:29.240
convolutional neural network based
architecture on three tasks

00:27:29.240 --> 00:27:29.250
architecture on three tasks
 

00:27:29.250 --> 00:27:31.700
architecture on three tasks
simultaneously semantic segmentation

00:27:31.700 --> 00:27:31.710
simultaneously semantic segmentation
 

00:27:31.710 --> 00:27:34.279
simultaneously semantic segmentation
depth estimation and instant

00:27:34.279 --> 00:27:34.289
depth estimation and instant
 

00:27:34.289 --> 00:27:37.279
depth estimation and instant
segmentation and what we really focused

00:27:37.279 --> 00:27:37.289
segmentation and what we really focused
 

00:27:37.289 --> 00:27:39.830
segmentation and what we really focused
on yesterday was how this segmentation

00:27:39.830 --> 00:27:39.840
on yesterday was how this segmentation
 

00:27:39.840 --> 00:27:43.070
on yesterday was how this segmentation
result was much crisper and cleaner from

00:27:43.070 --> 00:27:43.080
result was much crisper and cleaner from
 

00:27:43.080 --> 00:27:45.590
result was much crisper and cleaner from
there this group's previous result from

00:27:45.590 --> 00:27:45.600
there this group's previous result from
 

00:27:45.600 --> 00:27:48.230
there this group's previous result from
one year prior but what we didn't talk

00:27:48.230 --> 00:27:48.240
one year prior but what we didn't talk
 

00:27:48.240 --> 00:27:50.659
one year prior but what we didn't talk
about was how they're actually achieving

00:27:50.659 --> 00:27:50.669
about was how they're actually achieving
 

00:27:50.669 --> 00:27:54.560
about was how they're actually achieving
this improvement and what they're doing

00:27:54.560 --> 00:27:54.570
this improvement and what they're doing
 

00:27:54.570 --> 00:27:58.220
this improvement and what they're doing
is they're using uncertainty by training

00:27:58.220 --> 00:27:58.230
is they're using uncertainty by training
 

00:27:58.230 --> 00:28:00.020
is they're using uncertainty by training
their network on these three different

00:28:00.020 --> 00:28:00.030
their network on these three different
 

00:28:00.030 --> 00:28:03.350
their network on these three different
tasks simultaneously what they're able

00:28:03.350 --> 00:28:03.360
tasks simultaneously what they're able
 

00:28:03.360 --> 00:28:08.930
tasks simultaneously what they're able
to achieve is to use the uncertainty

00:28:08.930 --> 00:28:08.940
to achieve is to use the uncertainty
 

00:28:08.940 --> 00:28:13.370
to achieve is to use the uncertainty
estimates from two of two tasks to

00:28:13.370 --> 00:28:13.380
estimates from two of two tasks to
 

00:28:13.380 --> 00:28:16.610
estimates from two of two tasks to
improve the accuracy of the third task

00:28:16.610 --> 00:28:16.620
improve the accuracy of the third task
 

00:28:16.620 --> 00:28:20.450
improve the accuracy of the third task
and this is used to regularize the the

00:28:20.450 --> 00:28:20.460
and this is used to regularize the the
 

00:28:20.460 --> 00:28:24.070
and this is used to regularize the the
network and improve its generalization

00:28:24.070 --> 00:28:24.080
network and improve its generalization
 

00:28:24.080 --> 00:28:27.500
network and improve its generalization
in one domain such as segmentation and

00:28:27.500 --> 00:28:27.510
in one domain such as segmentation and
 

00:28:27.510 --> 00:28:30.289
in one domain such as segmentation and
this is just another example of their

00:28:30.289 --> 00:28:30.299
this is just another example of their
 

00:28:30.299 --> 00:28:32.750
this is just another example of their
results and as you can see right each of

00:28:32.750 --> 00:28:32.760
results and as you can see right each of
 

00:28:32.760 --> 00:28:36.740
results and as you can see right each of
these semantic segmentation instant

00:28:36.740 --> 00:28:36.750
these semantic segmentation instant
 

00:28:36.750 --> 00:28:37.909
these semantic segmentation instant
segmentation and depth

00:28:37.909 --> 00:28:37.919
segmentation and depth
 

00:28:37.919 --> 00:28:40.549
segmentation and depth
estimation seemed pretty crisp and clean

00:28:40.549 --> 00:28:40.559
estimation seemed pretty crisp and clean
 

00:28:40.559 --> 00:28:45.649
estimation seemed pretty crisp and clean
when compared to the input image so the

00:28:45.649 --> 00:28:45.659
when compared to the input image so the
 

00:28:45.659 --> 00:28:48.380
when compared to the input image so the
second exciting area of new research

00:28:48.380 --> 00:28:48.390
second exciting area of new research
 

00:28:48.390 --> 00:28:50.180
second exciting area of new research
that I'd like to highlight is this idea

00:28:50.180 --> 00:28:50.190
that I'd like to highlight is this idea
 

00:28:50.190 --> 00:28:50.749
that I'd like to highlight is this idea
of

00:28:50.749 --> 00:28:50.759
of
 

00:28:50.759 --> 00:28:55.489
of
learning to learn and to understand why

00:28:55.489 --> 00:28:55.499
learning to learn and to understand why
 

00:28:55.499 --> 00:28:57.469
learning to learn and to understand why
this may be useful and why you may want

00:28:57.469 --> 00:28:57.479
this may be useful and why you may want
 

00:28:57.479 --> 00:29:00.019
this may be useful and why you may want
to build out algorithms that can learn

00:29:00.019 --> 00:29:00.029
to build out algorithms that can learn
 

00:29:00.029 --> 00:29:03.199
to build out algorithms that can learn
to learn right well first like to

00:29:03.199 --> 00:29:03.209
to learn right well first like to
 

00:29:03.209 --> 00:29:07.249
to learn right well first like to
reiterate that most most neural networks

00:29:07.249 --> 00:29:07.259
reiterate that most most neural networks
 

00:29:07.259 --> 00:29:09.979
reiterate that most most neural networks
today are optimized for a single task

00:29:09.979 --> 00:29:09.989
today are optimized for a single task
 

00:29:09.989 --> 00:29:13.909
today are optimized for a single task
and as models get more and more complex

00:29:13.909 --> 00:29:13.919
and as models get more and more complex
 

00:29:13.919 --> 00:29:16.639
and as models get more and more complex
you know they increasingly require

00:29:16.639 --> 00:29:16.649
you know they increasingly require
 

00:29:16.649 --> 00:29:19.609
you know they increasingly require
expert knowledge in terms of engineering

00:29:19.609 --> 00:29:19.619
expert knowledge in terms of engineering
 

00:29:19.619 --> 00:29:22.310
expert knowledge in terms of engineering
them and building them and deploying

00:29:22.310 --> 00:29:22.320
them and building them and deploying
 

00:29:22.320 --> 00:29:24.919
them and building them and deploying
them and hopefully you've gotten a taste

00:29:24.919 --> 00:29:24.929
them and hopefully you've gotten a taste
 

00:29:24.929 --> 00:29:29.889
them and hopefully you've gotten a taste
of that knowledge through this course so

00:29:29.889 --> 00:29:29.899
of that knowledge through this course so
 

00:29:29.899 --> 00:29:32.479
of that knowledge through this course so
this can be kind of a bottleneck right

00:29:32.479 --> 00:29:32.489
this can be kind of a bottleneck right
 

00:29:32.489 --> 00:29:34.189
this can be kind of a bottleneck right
because you know there are so many

00:29:34.189 --> 00:29:34.199
because you know there are so many
 

00:29:34.199 --> 00:29:36.439
because you know there are so many
different settings where deep learning

00:29:36.439 --> 00:29:36.449
different settings where deep learning
 

00:29:36.449 --> 00:29:38.930
different settings where deep learning
may be useful but only so many deep

00:29:38.930 --> 00:29:38.940
may be useful but only so many deep
 

00:29:38.940 --> 00:29:41.649
may be useful but only so many deep
learning researchers and engineers right

00:29:41.649 --> 00:29:41.659
learning researchers and engineers right
 

00:29:41.659 --> 00:29:45.019
learning researchers and engineers right
so why can't we build a learning

00:29:45.019 --> 00:29:45.029
so why can't we build a learning
 

00:29:45.029 --> 00:29:47.869
so why can't we build a learning
algorithm that actually learns which

00:29:47.869 --> 00:29:47.879
algorithm that actually learns which
 

00:29:47.879 --> 00:29:50.659
algorithm that actually learns which
model is most well suited for an

00:29:50.659 --> 00:29:50.669
model is most well suited for an
 

00:29:50.669 --> 00:29:53.629
model is most well suited for an
arbitrary set of data and an arbitrary

00:29:53.629 --> 00:29:53.639
arbitrary set of data and an arbitrary
 

00:29:53.639 --> 00:29:57.049
arbitrary set of data and an arbitrary
task and Google asked this question a

00:29:57.049 --> 00:29:57.059
task and Google asked this question a
 

00:29:57.059 --> 00:29:59.269
task and Google asked this question a
few years ago and it turns out that we

00:29:59.269 --> 00:29:59.279
few years ago and it turns out that we
 

00:29:59.279 --> 00:30:01.369
few years ago and it turns out that we
can do this and this is the idea behind

00:30:01.369 --> 00:30:01.379
can do this and this is the idea behind
 

00:30:01.379 --> 00:30:07.369
can do this and this is the idea behind
this this this concept of Auto ml which

00:30:07.369 --> 00:30:07.379
this this this concept of Auto ml which
 

00:30:07.379 --> 00:30:09.739
this this this concept of Auto ml which
stands for sort of automatic machine

00:30:09.739 --> 00:30:09.749
stands for sort of automatic machine
 

00:30:09.749 --> 00:30:11.839
stands for sort of automatic machine
learning automatically learning how to

00:30:11.839 --> 00:30:11.849
learning automatically learning how to
 

00:30:11.849 --> 00:30:14.479
learning automatically learning how to
create new machine learning models for a

00:30:14.479 --> 00:30:14.489
create new machine learning models for a
 

00:30:14.489 --> 00:30:18.439
create new machine learning models for a
particular problem and in the original

00:30:18.439 --> 00:30:18.449
particular problem and in the original
 

00:30:18.449 --> 00:30:20.689
particular problem and in the original
auto ml which was proposed by Google

00:30:20.689 --> 00:30:20.699
auto ml which was proposed by Google
 

00:30:20.699 --> 00:30:23.329
auto ml which was proposed by Google
uses a reinforcement learning framework

00:30:23.329 --> 00:30:23.339
uses a reinforcement learning framework
 

00:30:23.339 --> 00:30:26.089
uses a reinforcement learning framework
and how it works is is the following

00:30:26.089 --> 00:30:26.099
and how it works is is the following
 

00:30:26.099 --> 00:30:29.209
and how it works is is the following
they have sort of this like agent

00:30:29.209 --> 00:30:29.219
they have sort of this like agent
 

00:30:29.219 --> 00:30:31.909
they have sort of this like agent
environment structure that Alexander

00:30:31.909 --> 00:30:31.919
environment structure that Alexander
 

00:30:31.919 --> 00:30:35.239
environment structure that Alexander
introduced where they have a first

00:30:35.239 --> 00:30:35.249
introduced where they have a first
 

00:30:35.249 --> 00:30:38.239
introduced where they have a first
Network the controller which in this

00:30:38.239 --> 00:30:38.249
Network the controller which in this
 

00:30:38.249 --> 00:30:44.569
Network the controller which in this
case is a RNN that proposes a child

00:30:44.569 --> 00:30:44.579
case is a RNN that proposes a child
 

00:30:44.579 --> 00:30:47.809
case is a RNN that proposes a child
model architecture right in terms of the

00:30:47.809 --> 00:30:47.819
model architecture right in terms of the
 

00:30:47.819 --> 00:30:51.259
model architecture right in terms of the
parameters of that model which can then

00:30:51.259 --> 00:30:51.269
parameters of that model which can then
 

00:30:51.269 --> 00:30:55.369
parameters of that model which can then
be trained and evaluated for its

00:30:55.369 --> 00:30:55.379
be trained and evaluated for its
 

00:30:55.379 --> 00:30:59.169
be trained and evaluated for its
performance on a particular task and

00:30:59.169 --> 00:30:59.179
performance on a particular task and
 

00:30:59.179 --> 00:31:02.029
performance on a particular task and
feedback on how well that child model

00:31:02.029 --> 00:31:02.039
feedback on how well that child model
 

00:31:02.039 --> 00:31:03.400
feedback on how well that child model
does

00:31:03.400 --> 00:31:03.410
does
 

00:31:03.410 --> 00:31:06.310
does
you know your tasks of interest is then

00:31:06.310 --> 00:31:06.320
you know your tasks of interest is then
 

00:31:06.320 --> 00:31:11.590
you know your tasks of interest is then
used to inform the controller on how to

00:31:11.590 --> 00:31:11.600
used to inform the controller on how to
 

00:31:11.600 --> 00:31:15.730
used to inform the controller on how to
improve its proposals for the next round

00:31:15.730 --> 00:31:15.740
improve its proposals for the next round
 

00:31:15.740 --> 00:31:18.730
improve its proposals for the next round
in terms of okay what is the updated

00:31:18.730 --> 00:31:18.740
in terms of okay what is the updated
 

00:31:18.740 --> 00:31:20.650
in terms of okay what is the updated
child network that I'm going to propose

00:31:20.650 --> 00:31:20.660
child network that I'm going to propose
 

00:31:20.660 --> 00:31:23.560
child network that I'm going to propose
and this process is repeated thousands

00:31:23.560 --> 00:31:23.570
and this process is repeated thousands
 

00:31:23.570 --> 00:31:26.140
and this process is repeated thousands
of times you know iteratively generating

00:31:26.140 --> 00:31:26.150
of times you know iteratively generating
 

00:31:26.150 --> 00:31:28.120
of times you know iteratively generating
new architectures testing them and

00:31:28.120 --> 00:31:28.130
new architectures testing them and
 

00:31:28.130 --> 00:31:30.370
new architectures testing them and
giving that feedback back to the

00:31:30.370 --> 00:31:30.380
giving that feedback back to the
 

00:31:30.380 --> 00:31:33.280
giving that feedback back to the
controller to learn from and eventually

00:31:33.280 --> 00:31:33.290
controller to learn from and eventually
 

00:31:33.290 --> 00:31:34.960
controller to learn from and eventually
the controller is going to learn to

00:31:34.960 --> 00:31:34.970
the controller is going to learn to
 

00:31:34.970 --> 00:31:39.310
the controller is going to learn to
assign high probability to sort of areas

00:31:39.310 --> 00:31:39.320
assign high probability to sort of areas
 

00:31:39.320 --> 00:31:41.860
assign high probability to sort of areas
of the architecture space that achieve

00:31:41.860 --> 00:31:41.870
of the architecture space that achieve
 

00:31:41.870 --> 00:31:45.210
of the architecture space that achieve
better accuracy on that desired task and

00:31:45.210 --> 00:31:45.220
better accuracy on that desired task and
 

00:31:45.220 --> 00:31:48.190
better accuracy on that desired task and
low probability to those architectures

00:31:48.190 --> 00:31:48.200
low probability to those architectures
 

00:31:48.200 --> 00:31:51.730
low probability to those architectures
that don't perform well so how does this

00:31:51.730 --> 00:31:51.740
that don't perform well so how does this
 

00:31:51.740 --> 00:31:54.520
that don't perform well so how does this
agent work as I mentioned it's an RNN

00:31:54.520 --> 00:31:54.530
agent work as I mentioned it's an RNN
 

00:31:54.530 --> 00:31:56.860
agent work as I mentioned it's an RNN
controller that sort of at the macro

00:31:56.860 --> 00:31:56.870
controller that sort of at the macro
 

00:31:56.870 --> 00:32:00.570
controller that sort of at the macro
scale considers different layers in the

00:32:00.570 --> 00:32:00.580
scale considers different layers in the
 

00:32:00.580 --> 00:32:03.820
scale considers different layers in the
proposed generated network and at the

00:32:03.820 --> 00:32:03.830
proposed generated network and at the
 

00:32:03.830 --> 00:32:07.600
proposed generated network and at the
internal level of each candidate layer

00:32:07.600 --> 00:32:07.610
internal level of each candidate layer
 

00:32:07.610 --> 00:32:11.020
internal level of each candidate layer
it predicts different what are known as

00:32:11.020 --> 00:32:11.030
it predicts different what are known as
 

00:32:11.030 --> 00:32:13.570
it predicts different what are known as
hyper parameters that define the

00:32:13.570 --> 00:32:13.580
hyper parameters that define the
 

00:32:13.580 --> 00:32:15.520
hyper parameters that define the
architecture of that layer so for

00:32:15.520 --> 00:32:15.530
architecture of that layer so for
 

00:32:15.530 --> 00:32:17.320
architecture of that layer so for
example if we're trying to generate a

00:32:17.320 --> 00:32:17.330
example if we're trying to generate a
 

00:32:17.330 --> 00:32:21.520
example if we're trying to generate a
child CNN we may want to predict you

00:32:21.520 --> 00:32:21.530
child CNN we may want to predict you
 

00:32:21.530 --> 00:32:23.740
child CNN we may want to predict you
know the number of different filters of

00:32:23.740 --> 00:32:23.750
know the number of different filters of
 

00:32:23.750 --> 00:32:26.410
know the number of different filters of
a layer the the dimensionality of those

00:32:26.410 --> 00:32:26.420
a layer the the dimensionality of those
 

00:32:26.420 --> 00:32:29.590
a layer the the dimensionality of those
filters the destryed that we're going to

00:32:29.590 --> 00:32:29.600
filters the destryed that we're going to
 

00:32:29.600 --> 00:32:32.200
filters the destryed that we're going to
you know slide our filter patch over

00:32:32.200 --> 00:32:32.210
you know slide our filter patch over
 

00:32:32.210 --> 00:32:35.350
you know slide our filter patch over
during the convolution operation all

00:32:35.350 --> 00:32:35.360
during the convolution operation all
 

00:32:35.360 --> 00:32:37.600
during the convolution operation all
parameters associated with convolutional

00:32:37.600 --> 00:32:37.610
parameters associated with convolutional
 

00:32:37.610 --> 00:32:41.260
parameters associated with convolutional
layers so then if we consider the the

00:32:41.260 --> 00:32:41.270
layers so then if we consider the the
 

00:32:41.270 --> 00:32:43.330
layers so then if we consider the the
other network in this picture the child

00:32:43.330 --> 00:32:43.340
other network in this picture the child
 

00:32:43.340 --> 00:32:47.470
other network in this picture the child
network what is it what is it doing to

00:32:47.470 --> 00:32:47.480
network what is it what is it doing to
 

00:32:47.480 --> 00:32:49.960
network what is it what is it doing to
to reiterate this is a network that's

00:32:49.960 --> 00:32:49.970
to reiterate this is a network that's
 

00:32:49.970 --> 00:32:52.480
to reiterate this is a network that's
generated by another neural network

00:32:52.480 --> 00:32:52.490
generated by another neural network
 

00:32:52.490 --> 00:32:54.490
generated by another neural network
that's why it's called the child right

00:32:54.490 --> 00:32:54.500
that's why it's called the child right
 

00:32:54.500 --> 00:32:57.070
that's why it's called the child right
and what we can do is we can take this

00:32:57.070 --> 00:32:57.080
and what we can do is we can take this
 

00:32:57.080 --> 00:33:00.490
and what we can do is we can take this
this child network that's sampled from

00:33:00.490 --> 00:33:00.500
this child network that's sampled from
 

00:33:00.500 --> 00:33:05.170
this child network that's sampled from
the RNN train it on a desire task right

00:33:05.170 --> 00:33:05.180
the RNN train it on a desire task right
 

00:33:05.180 --> 00:33:08.110
the RNN train it on a desire task right
with the desired data set and evaluate

00:33:08.110 --> 00:33:08.120
with the desired data set and evaluate
 

00:33:08.120 --> 00:33:10.660
with the desired data set and evaluate
its accuracy and after we do this we can

00:33:10.660 --> 00:33:10.670
its accuracy and after we do this we can
 

00:33:10.670 --> 00:33:13.020
its accuracy and after we do this we can
then go back to our RNN controller

00:33:13.020 --> 00:33:13.030
then go back to our RNN controller
 

00:33:13.030 --> 00:33:16.510
then go back to our RNN controller
update it right based on how the child

00:33:16.510 --> 00:33:16.520
update it right based on how the child
 

00:33:16.520 --> 00:33:16.840
update it right based on how the child
met

00:33:16.840 --> 00:33:16.850
met
 

00:33:16.850 --> 00:33:19.779
met
work performed after training and now

00:33:19.779 --> 00:33:19.789
work performed after training and now
 

00:33:19.789 --> 00:33:22.810
work performed after training and now
the RNN parent can learn to create an

00:33:22.810 --> 00:33:22.820
the RNN parent can learn to create an
 

00:33:22.820 --> 00:33:26.379
the RNN parent can learn to create an
even better child model right so this is

00:33:26.379 --> 00:33:26.389
even better child model right so this is
 

00:33:26.389 --> 00:33:28.149
even better child model right so this is
a really powerful idea and what does it

00:33:28.149 --> 00:33:28.159
a really powerful idea and what does it
 

00:33:28.159 --> 00:33:31.779
a really powerful idea and what does it
mean for us in practice well Google has

00:33:31.779 --> 00:33:31.789
mean for us in practice well Google has
 

00:33:31.789 --> 00:33:34.240
mean for us in practice well Google has
now put the service on the cloud Google

00:33:34.240 --> 00:33:34.250
now put the service on the cloud Google
 

00:33:34.250 --> 00:33:37.120
now put the service on the cloud Google
being Google right so that you can go in

00:33:37.120 --> 00:33:37.130
being Google right so that you can go in
 

00:33:37.130 --> 00:33:41.919
being Google right so that you can go in
provide the auto Amell system a data set

00:33:41.919 --> 00:33:41.929
provide the auto Amell system a data set
 

00:33:41.929 --> 00:33:44.320
provide the auto Amell system a data set
and a set of metrics that you wanted to

00:33:44.320 --> 00:33:44.330
and a set of metrics that you wanted to
 

00:33:44.330 --> 00:33:47.080
and a set of metrics that you wanted to
optimize over and they will use parent

00:33:47.080 --> 00:33:47.090
optimize over and they will use parent
 

00:33:47.090 --> 00:33:50.169
optimize over and they will use parent
RNN controllers to generate a candidate

00:33:50.169 --> 00:33:50.179
RNN controllers to generate a candidate
 

00:33:50.179 --> 00:33:52.899
RNN controllers to generate a candidate
child Network that's designed to train

00:33:52.899 --> 00:33:52.909
child Network that's designed to train
 

00:33:52.909 --> 00:33:55.570
child Network that's designed to train
optimally on your data set for your task

00:33:55.570 --> 00:33:55.580
optimally on your data set for your task
 

00:33:55.580 --> 00:33:58.570
optimally on your data set for your task
right and this end result is this new

00:33:58.570 --> 00:33:58.580
right and this end result is this new
 

00:33:58.580 --> 00:34:00.340
right and this end result is this new
child network that it gives back to you

00:34:00.340 --> 00:34:00.350
child network that it gives back to you
 

00:34:00.350 --> 00:34:03.430
child network that it gives back to you
spawned from this rnm controller which

00:34:03.430 --> 00:34:03.440
spawned from this rnm controller which
 

00:34:03.440 --> 00:34:05.740
spawned from this rnm controller which
you can then go and deploy on your data

00:34:05.740 --> 00:34:05.750
you can then go and deploy on your data
 

00:34:05.750 --> 00:34:08.619
you can then go and deploy on your data
set right this is a pretty big deal

00:34:08.619 --> 00:34:08.629
set right this is a pretty big deal
 

00:34:08.629 --> 00:34:12.220
set right this is a pretty big deal
right and it sort of gets that sort of

00:34:12.220 --> 00:34:12.230
right and it sort of gets that sort of
 

00:34:12.230 --> 00:34:14.919
right and it sort of gets that sort of
this deeper question right they've

00:34:14.919 --> 00:34:14.929
this deeper question right they've
 

00:34:14.929 --> 00:34:17.020
this deeper question right they've
demonstrated that we can create these AI

00:34:17.020 --> 00:34:17.030
demonstrated that we can create these AI
 

00:34:17.030 --> 00:34:20.909
demonstrated that we can create these AI
systems that can generate new AI

00:34:20.909 --> 00:34:20.919
systems that can generate new AI
 

00:34:20.919 --> 00:34:25.510
systems that can generate new AI
specifically designed to solve Mazar

00:34:25.510 --> 00:34:25.520
specifically designed to solve Mazar
 

00:34:25.520 --> 00:34:28.030
specifically designed to solve Mazar
tasks right and this significantly

00:34:28.030 --> 00:34:28.040
tasks right and this significantly
 

00:34:28.040 --> 00:34:30.359
tasks right and this significantly
reduces sort of the difficulties that

00:34:30.359 --> 00:34:30.369
reduces sort of the difficulties that
 

00:34:30.369 --> 00:34:32.980
reduces sort of the difficulties that
machine learning engineers face in terms

00:34:32.980 --> 00:34:32.990
machine learning engineers face in terms
 

00:34:32.990 --> 00:34:36.960
machine learning engineers face in terms
of optimizing a network architecture for

00:34:36.960 --> 00:34:36.970
of optimizing a network architecture for
 

00:34:36.970 --> 00:34:40.659
of optimizing a network architecture for
for a different task right and this sort

00:34:40.659 --> 00:34:40.669
for a different task right and this sort
 

00:34:40.669 --> 00:34:43.480
for a different task right and this sort
of gets at the heart of the question

00:34:43.480 --> 00:34:43.490
of gets at the heart of the question
 

00:34:43.490 --> 00:34:45.909
of gets at the heart of the question
that Alexander proposed at the beginning

00:34:45.909 --> 00:34:45.919
that Alexander proposed at the beginning
 

00:34:45.919 --> 00:34:48.700
that Alexander proposed at the beginning
of this course right this notion of

00:34:48.700 --> 00:34:48.710
of this course right this notion of
 

00:34:48.710 --> 00:34:51.129
of this course right this notion of
generalized artificial intelligence and

00:34:51.129 --> 00:34:51.139
generalized artificial intelligence and
 

00:34:51.139 --> 00:34:53.619
generalized artificial intelligence and
we spoke about a bit about what it means

00:34:53.619 --> 00:34:53.629
we spoke about a bit about what it means
 

00:34:53.629 --> 00:34:55.899
we spoke about a bit about what it means
to be intelligent right loosely speaking

00:34:55.899 --> 00:34:55.909
to be intelligent right loosely speaking
 

00:34:55.909 --> 00:34:59.710
to be intelligent right loosely speaking
the sense of taking in information using

00:34:59.710 --> 00:34:59.720
the sense of taking in information using
 

00:34:59.720 --> 00:35:02.650
the sense of taking in information using
it to inform a future decision and as

00:35:02.650 --> 00:35:02.660
it to inform a future decision and as
 

00:35:02.660 --> 00:35:04.720
it to inform a future decision and as
humans our learning pipeline is not

00:35:04.720 --> 00:35:04.730
humans our learning pipeline is not
 

00:35:04.730 --> 00:35:07.960
humans our learning pipeline is not
restricted to solving only specific

00:35:07.960 --> 00:35:07.970
restricted to solving only specific
 

00:35:07.970 --> 00:35:11.140
restricted to solving only specific
defined tasks how we learn one task can

00:35:11.140 --> 00:35:11.150
defined tasks how we learn one task can
 

00:35:11.150 --> 00:35:16.569
defined tasks how we learn one task can
impact you know what we do on something

00:35:16.569 --> 00:35:16.579
impact you know what we do on something
 

00:35:16.579 --> 00:35:17.859
impact you know what we do on something
something completely unrelated

00:35:17.859 --> 00:35:17.869
something completely unrelated
 

00:35:17.869 --> 00:35:23.470
something completely unrelated
completely separate right and in order

00:35:23.470 --> 00:35:23.480
completely separate right and in order
 

00:35:23.480 --> 00:35:26.790
completely separate right and in order
to reach sort of that same level with AI

00:35:26.790 --> 00:35:26.800
to reach sort of that same level with AI
 

00:35:26.800 --> 00:35:29.710
to reach sort of that same level with AI
we really need to build systems that can

00:35:29.710 --> 00:35:29.720
we really need to build systems that can
 

00:35:29.720 --> 00:35:30.310
we really need to build systems that can
not only

00:35:30.310 --> 00:35:30.320
not only
 

00:35:30.320 --> 00:35:33.280
not only
learn single tasks but can improve their

00:35:33.280 --> 00:35:33.290
learn single tasks but can improve their
 

00:35:33.290 --> 00:35:36.220
learn single tasks but can improve their
own learning and their reasoning so as

00:35:36.220 --> 00:35:36.230
own learning and their reasoning so as
 

00:35:36.230 --> 00:35:38.860
own learning and their reasoning so as
to be able to generalize well two sets

00:35:38.860 --> 00:35:38.870
to be able to generalize well two sets
 

00:35:38.870 --> 00:35:43.600
to be able to generalize well two sets
of related and dependent tasks so I'll

00:35:43.600 --> 00:35:43.610
of related and dependent tasks so I'll
 

00:35:43.610 --> 00:35:45.550
of related and dependent tasks so I'll
leave you with this thought and I

00:35:45.550 --> 00:35:45.560
leave you with this thought and I
 

00:35:45.560 --> 00:35:48.400
leave you with this thought and I
encourage you to to continue to discuss

00:35:48.400 --> 00:35:48.410
encourage you to to continue to discuss
 

00:35:48.410 --> 00:35:51.040
encourage you to to continue to discuss
and think about these ideas amongst

00:35:51.040 --> 00:35:51.050
and think about these ideas amongst
 

00:35:51.050 --> 00:35:52.780
and think about these ideas amongst
yourselves internally through

00:35:52.780 --> 00:35:52.790
yourselves internally through
 

00:35:52.790 --> 00:35:55.150
yourselves internally through
introspection and also we're happy to

00:35:55.150 --> 00:35:55.160
introspection and also we're happy to
 

00:35:55.160 --> 00:35:58.420
introspection and also we're happy to
chat and I think I can speak for the TAS

00:35:58.420 --> 00:35:58.430
chat and I think I can speak for the TAS
 

00:35:58.430 --> 00:36:00.460
chat and I think I can speak for the TAS
in saying that they're happy to chat as

00:36:00.460 --> 00:36:00.470
in saying that they're happy to chat as
 

00:36:00.470 --> 00:36:04.420
in saying that they're happy to chat as
well so that concludes you know the

00:36:04.420 --> 00:36:04.430
well so that concludes you know the
 

00:36:04.430 --> 00:36:06.520
well so that concludes you know the
series of lectures from Alexander and I

00:36:06.520 --> 00:36:06.530
series of lectures from Alexander and I
 

00:36:06.530 --> 00:36:08.860
series of lectures from Alexander and I
and we'll have our three guest lecturers

00:36:08.860 --> 00:36:08.870
and we'll have our three guest lecturers
 

00:36:08.870 --> 00:36:11.620
and we'll have our three guest lecturers
over the next couple of days and then

00:36:11.620 --> 00:36:11.630
over the next couple of days and then
 

00:36:11.630 --> 00:36:13.510
over the next couple of days and then
we'll have the final lab on

00:36:13.510 --> 00:36:13.520
we'll have the final lab on
 

00:36:13.520 --> 00:36:16.260
we'll have the final lab on
reinforcement learning thank you

00:36:16.260 --> 00:36:16.270
reinforcement learning thank you
 

00:36:16.270 --> 00:36:21.869
reinforcement learning thank you
[Applause]

