WEBVTT
Kind: captions
Language: en

00:00:07.100 --> 00:00:08.340
WOLFF DOBSON: Hi, I'm Wolff.

00:00:08.340 --> 00:00:10.080
I'm the tech lead for
developer relations

00:00:10.080 --> 00:00:13.590
for machine learning at Google,
which includes the Brain Team.

00:00:13.590 --> 00:00:15.900
Brain Team's big
project is TensorFlow,

00:00:15.900 --> 00:00:18.200
which is an open
source library that

00:00:18.200 --> 00:00:21.090
builds computational
graphs and is

00:00:21.090 --> 00:00:23.490
used for machine learning,
especially deep learning.

00:00:23.490 --> 00:00:24.000
It's free.

00:00:24.000 --> 00:00:24.850
It's open source.

00:00:24.850 --> 00:00:26.160
You can download it now.

00:00:26.160 --> 00:00:27.259
I strongly recommend it.

00:00:27.259 --> 00:00:28.800
But I'm not going
to teach you to use

00:00:28.800 --> 00:00:30.079
TensorFlow in five minutes.

00:00:30.079 --> 00:00:31.620
So let's talk instead
about why you'd

00:00:31.620 --> 00:00:33.369
want to use machine
learning in your games

00:00:33.369 --> 00:00:35.652
besides that wonderful
talk that we just had.

00:00:35.652 --> 00:00:37.110
Let me give you
five things you can

00:00:37.110 --> 00:00:38.735
do with machine
learning with your game

00:00:38.735 --> 00:00:41.310
right now from
easiest to hardest.

00:00:41.310 --> 00:00:42.470
Step 0.

00:00:42.470 --> 00:00:44.560
We're all engineers--
well, lots of us are.

00:00:44.560 --> 00:00:46.170
So we're going to start with 0.

00:00:46.170 --> 00:00:48.570
Use analytics to predict stuff.

00:00:48.570 --> 00:00:51.340
So modern games can produce
all kinds of interesting data.

00:00:51.340 --> 00:00:55.320
And if you're smart, you're
probably collecting some.

00:00:55.320 --> 00:00:57.380
Things you can do
are like how much

00:00:57.380 --> 00:00:58.680
is this player likely to spend.

00:00:58.680 --> 00:01:00.030
Is this player likely to quit.

00:01:00.030 --> 00:01:01.200
Is this player cheating.

00:01:01.200 --> 00:01:02.766
Is this player being toxic.

00:01:02.766 --> 00:01:04.349
These are all things
you can find out.

00:01:04.349 --> 00:01:06.300
This is super basic
stuff that you

00:01:06.300 --> 00:01:08.409
can do with TensorFlow
or any other tool kit.

00:01:08.409 --> 00:01:10.200
And it doesn't even
have to be complicated.

00:01:10.200 --> 00:01:12.750
A simple linear regression
or linear classifier

00:01:12.750 --> 00:01:15.780
can help you get a boost
and understand your audience

00:01:15.780 --> 00:01:17.460
better.

00:01:17.460 --> 00:01:17.977
Step 1.

00:01:17.977 --> 00:01:18.810
A little bit harder.

00:01:18.810 --> 00:01:20.790
Let's grab some
open source models--

00:01:20.790 --> 00:01:25.450
deep models-- and retrain them
to be useful to your game.

00:01:25.450 --> 00:01:27.760
So Inception is
an award winning--

00:01:27.760 --> 00:01:29.220
well, we have awards--

00:01:29.220 --> 00:01:31.860
deep network that does
image classification.

00:01:31.860 --> 00:01:34.380
Because of the contest
data, it's kind of

00:01:34.380 --> 00:01:36.570
obsessed with dog breeds.

00:01:36.570 --> 00:01:40.770
But it is really easy to
retrain that and classify images

00:01:40.770 --> 00:01:42.660
with, actually, a fairly
small amount of data

00:01:42.660 --> 00:01:45.030
by deep learning standards
just on your laptop.

00:01:45.030 --> 00:01:45.780
We have code labs.

00:01:45.780 --> 00:01:46.530
We have samples.

00:01:46.530 --> 00:01:47.550
All kinds of stuff.

00:01:47.550 --> 00:01:49.549
Think about the player
activity you want to see.

00:01:49.549 --> 00:01:51.750
Think about hand gestures
in front of cameras.

00:01:51.750 --> 00:01:53.260
Think about all kinds of stuff.

00:01:53.260 --> 00:01:56.640
Graph some image data
and get classifying.

00:01:56.640 --> 00:01:58.350
And if you don't like
image processing,

00:01:58.350 --> 00:02:00.280
we have other open source
models to play with.

00:02:00.280 --> 00:02:04.350
Parsey McParseface--
that is its real name--

00:02:04.350 --> 00:02:09.840
explains the functional role of
each word in a sentence, which

00:02:09.840 --> 00:02:12.480
gives you the ability
to find meaning

00:02:12.480 --> 00:02:15.660
from words and speech and text.

00:02:15.660 --> 00:02:16.410
Super neat.

00:02:16.410 --> 00:02:19.110
You should totally check it out.

00:02:19.110 --> 00:02:21.090
All right, a little bit
harder than retraining.

00:02:21.090 --> 00:02:25.560
You can use neural networks to
give your game art some style.

00:02:25.560 --> 00:02:27.630
In neural style
transfer, you're taking

00:02:27.630 --> 00:02:30.570
advantage of deep neural
networks semantic understanding

00:02:30.570 --> 00:02:35.100
of a picture as well of both
the scene and the style.

00:02:35.100 --> 00:02:37.290
So you can apply the
style of one image

00:02:37.290 --> 00:02:40.420
to the semantics scene
data of the other.

00:02:40.420 --> 00:02:42.760
So in this case, we have
a creepy clown image

00:02:42.760 --> 00:02:45.010
and we have a
beautiful seaside town.

00:02:45.010 --> 00:02:49.500
With style transfer, you can
then apply creepy clown style

00:02:49.500 --> 00:02:52.394
to seaside town.

00:02:52.394 --> 00:02:54.060
You can do that with
all kinds of stuff.

00:02:54.060 --> 00:02:55.476
Again, there's
open-source models.

00:02:55.476 --> 00:02:57.240
There's open source
examples to do this.

00:02:57.240 --> 00:02:58.320
Think how much fun
your artists are

00:02:58.320 --> 00:03:00.278
going to have coming up
with all different ways

00:03:00.278 --> 00:03:03.660
to blend pictures that
are drawn with art in 2D

00:03:03.660 --> 00:03:06.567
and 3D models within your game.

00:03:06.567 --> 00:03:08.400
And if you have a good
GPU, you can actually

00:03:08.400 --> 00:03:10.140
do style transfer in real time.

00:03:10.140 --> 00:03:13.680
This dog, Peekaboo, is
getting styled transferred

00:03:13.680 --> 00:03:19.874
at varied amounts by different
amounts when using the sliders.

00:03:19.874 --> 00:03:20.790
Now we're getting fun.

00:03:20.790 --> 00:03:22.950
So step 3 is dream
up new content

00:03:22.950 --> 00:03:25.920
for your game using
deep learning.

00:03:25.920 --> 00:03:29.790
Most people probably run into
these weird recursive dream

00:03:29.790 --> 00:03:33.150
models which come from sort of
running an image recognition

00:03:33.150 --> 00:03:34.230
model backwards.

00:03:34.230 --> 00:03:36.720
But unless your game
is entirely on acid,

00:03:36.720 --> 00:03:39.095
you're probably going to need
something a little bit more

00:03:39.095 --> 00:03:40.320
practical.

00:03:40.320 --> 00:03:42.360
One example is actually
from the community.

00:03:42.360 --> 00:03:43.820
It's a web engineer in Japan--

00:03:43.820 --> 00:03:46.814
wanted to learn ML in TensorFlow
as his personal hobby.

00:03:46.814 --> 00:03:48.480
So in a few months,
he was able to build

00:03:48.480 --> 00:03:52.170
a deep convolutional generative
adversarial network to generate

00:03:52.170 --> 00:03:55.790
arbitrary TV popstar faces
based on a database of other pop

00:03:55.790 --> 00:03:58.080
stars.

00:03:58.080 --> 00:04:00.870
Another totally awesome research
using adversarial networks

00:04:00.870 --> 00:04:03.060
is downsampling photos of
people and then learning

00:04:03.060 --> 00:04:06.060
the mappings between the
low resolution photos

00:04:06.060 --> 00:04:07.710
and the high resolution photos.

00:04:07.710 --> 00:04:10.050
So then you can edit
in low resolution

00:04:10.050 --> 00:04:11.910
and generate high
resolution photos.

00:04:11.910 --> 00:04:14.730
So in this image, ground
truth is on the left.

00:04:14.730 --> 00:04:18.630
In the middle, you have you
have the low resolution version

00:04:18.630 --> 00:04:21.510
and on the right, you have
the generated image based

00:04:21.510 --> 00:04:23.670
on that low resolution image.

00:04:23.670 --> 00:04:25.220
If you've got pixel
artists, they're

00:04:25.220 --> 00:04:27.487
going to have a lot
of fun with this.

00:04:27.487 --> 00:04:29.070
No time to explain
this at all, but as

00:04:29.070 --> 00:04:30.611
another adversial
model that lets you

00:04:30.611 --> 00:04:32.760
do neural editing of faces.

00:04:32.760 --> 00:04:35.100
Quickly transform a
brunette to a blonde or male

00:04:35.100 --> 00:04:36.895
to female with
just a few pixels.

00:04:36.895 --> 00:04:37.770
There's a link there.

00:04:37.770 --> 00:04:38.520
Check it out.

00:04:38.520 --> 00:04:41.580
It's totally cool deep
learning research.

00:04:41.580 --> 00:04:45.390
And again, if images aren't
your bag, you can do music.

00:04:45.390 --> 00:04:47.022
Google has Project
Magenta, which

00:04:47.022 --> 00:04:48.480
is an open source
project that uses

00:04:48.480 --> 00:04:52.560
ML that takes the problem of
given n minus one notes, what

00:04:52.560 --> 00:04:54.540
is the nth note.

00:04:54.540 --> 00:04:57.120
You can train it on all kinds
of music from Radiohead to Bach

00:04:57.120 --> 00:04:58.920
and use a recurrent
neural network

00:04:58.920 --> 00:05:03.030
to generate new
music for your game.

00:05:03.030 --> 00:05:04.980
And finally, step 4--

00:05:04.980 --> 00:05:05.842
NPC control.

00:05:05.842 --> 00:05:07.550
This is kind of the
elephant in the room,

00:05:07.550 --> 00:05:09.240
if you think about it.

00:05:09.240 --> 00:05:11.820
There's obviously been a lot
of super interesting work

00:05:11.820 --> 00:05:15.240
from our neighbors in London
at DeepMind on AlphaGo.

00:05:15.240 --> 00:05:18.510
There's some recent good
successes with poker.

00:05:18.510 --> 00:05:21.150
I just read a paper about
using reinforcement learning

00:05:21.150 --> 00:05:22.500
to play Super Smash Brothers.

00:05:22.500 --> 00:05:24.750
Totally cool stuff.

00:05:24.750 --> 00:05:25.760
One note of caution--

00:05:25.760 --> 00:05:28.220
I think is absolutely
fascinating research,

00:05:28.220 --> 00:05:31.650
but at least in the experiences
that I've had with it,

00:05:31.650 --> 00:05:33.100
the danger is that
cameras in game

00:05:33.100 --> 00:05:34.950
play kind of work against you.

00:05:34.950 --> 00:05:36.630
That kid in a blue hat?

00:05:36.630 --> 00:05:39.390
He has no idea how complicated
the neural networks

00:05:39.390 --> 00:05:40.680
of the kids around him are.

00:05:40.680 --> 00:05:41.589
Just zero idea.

00:05:41.589 --> 00:05:42.630
He has got his head down.

00:05:42.630 --> 00:05:43.630
He's focused on hopping.

00:05:43.630 --> 00:05:45.671
You're going to find that
when you start applying

00:05:45.671 --> 00:05:46.980
deep learning to NPC control.

00:05:49.940 --> 00:05:53.440
Yet super excited
about this anyway.

00:05:53.440 --> 00:05:56.300
There's going to be a lot of
things you can do with this.

00:05:56.300 --> 00:05:59.880
Learning animation
parameters from video data.

00:05:59.880 --> 00:06:02.400
There's interesting
work going on here.

00:06:02.400 --> 00:06:03.680
Player dropout and take over.

00:06:03.680 --> 00:06:06.710
If you have players playing some
online game and they disappear,

00:06:06.710 --> 00:06:08.900
we need to replace with
a copy of them that's

00:06:08.900 --> 00:06:11.330
learned from their behavior.

00:06:11.330 --> 00:06:13.526
Sidekicks, dialog generation.

00:06:13.526 --> 00:06:15.900
You know, we're generating
music in the previous example.

00:06:15.900 --> 00:06:18.275
There's no reason why you
couldn't apply that to dialogue

00:06:18.275 --> 00:06:21.260
although obviously, it's a lot
more semantically complicated.

00:06:21.260 --> 00:06:23.300
Custom content
generation for opponents

00:06:23.300 --> 00:06:24.950
and levels and stories.

00:06:24.950 --> 00:06:26.210
The world is your oyster.

00:06:26.210 --> 00:06:29.460
And speaking of oysters,
here's where we have ours.

00:06:29.460 --> 00:06:31.280
TensorFlow.org is
where you can find

00:06:31.280 --> 00:06:33.800
tutorials and code and
the TensorFlow framework

00:06:33.800 --> 00:06:34.970
for doing deep learning.

00:06:34.970 --> 00:06:36.660
We have a Udacity course.

00:06:36.660 --> 00:06:39.080
I strongly recommend--
if you're interested

00:06:39.080 --> 00:06:42.866
in this-- the Stanford
CS231 class on GitHub.

00:06:42.866 --> 00:06:44.240
They have an
amazing introduction

00:06:44.240 --> 00:06:46.400
to how machine learning works.

00:06:46.400 --> 00:06:48.470
And we also just
have a video series

00:06:48.470 --> 00:06:51.380
that introduces the basic
concepts of machine learning.

00:06:51.380 --> 00:06:53.060
And there we are.

00:06:53.060 --> 00:06:55.030
Thank you very much.

