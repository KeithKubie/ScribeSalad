WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.170
I wanted to talk a little bit more about deep learning and some of a kind of slightly more,

00:00:04.170 --> 00:00:04.670
 

00:00:04.670 --> 00:00:05.170
 

00:00:05.170 --> 00:00:05.670
 

00:00:05.670 --> 00:00:09.809
Large and interesting architectures that have been coming along in the last couple of years, last few years.

00:00:11.050 --> 00:00:14.189
So just a very brief recap, right? We've got videos on this

00:00:15.400 --> 00:00:20.310
I'm going to draw my network from the top down this time. So rather than there being a square input image

00:00:20.310 --> 00:00:22.420
I'm just going to draw a line which is the image from the top

00:00:22.600 --> 00:00:26.640
So you can work with your animation magic and sort this all out for me. Brilliant.

00:00:26.640 --> 00:00:27.720
 

00:00:29.020 --> 00:00:31.920
So I'm going to be talking about deep learning and convolutional neural networks.

00:00:32.920 --> 00:00:37.080
So a convolutional neural network is one where you have some input like an image.

00:00:37.080 --> 00:00:39.440
You filter it using a convolution operation.

00:00:39.460 --> 00:00:41.700
And then you repeat that process a number of times.

00:00:42.300 --> 00:00:44.300
To learn something interesting about that image.

00:00:44.300 --> 00:00:46.000
Some interesting features.

00:00:46.000 --> 00:00:48.400
And then you make a classification decision based on it.

00:00:48.560 --> 00:00:50.300
That is usually what you do, right?

00:00:50.300 --> 00:00:53.760
So you might decide, well this have got a cat in it or this one's got a dog in it.

00:00:53.960 --> 00:00:56.000
Or this one's got a cat and a dog in it and that's very exciting.

00:00:56.140 --> 00:00:58.040
So from the top down right because I've always

00:00:58.140 --> 00:01:01.160
My pens gonna run out of ink if I start trying to draw too many boxes.

00:01:02.000 --> 00:01:04.680
You've got an input image, but it's quite large usually.

00:01:05.040 --> 00:01:07.260
So here's an input image and I'm gonna draw it like this.

00:01:07.580 --> 00:01:08.380
This is from the top.

00:01:08.800 --> 00:01:12.680
So if this is my image, I'm gonna go to the top and look at it straight down.

00:01:12.740 --> 00:01:15.180
Which I realized sort of like that. Does that work?

00:01:15.380 --> 00:01:18.960
Now there's three input channels because of course we had usually red green and blue, right?

00:01:18.960 --> 00:01:24.150
So in some sense, this is multi-dimensional. We're gonna have our little filtering so I'm going to draw a couple of kernels.

00:01:24.150 --> 00:01:28.499
Let's maybe draw four. We're gonna do a convolution operation using this one on here

00:01:28.500 --> 00:01:30.500
So it's going to look over all of these three channels

00:01:30.640 --> 00:01:36.150
it's going to scan along and it's going to calculate some kind of features like an edge or something like this and that's going to

00:01:36.150 --> 00:01:42.359
Produce another feature right and now there's four kernels of each gonna do this. So we're gonna have four outputs. Don't worry

00:01:42.360 --> 00:01:44.699
I'm not going to do an 800 layer deep network this way

00:01:44.700 --> 00:01:49.619
So each of these gets to look at all of the three something that's a bit a bit of a sort of quirk of deep

00:01:49.619 --> 00:01:51.369
Learning but maybe isn't explained

00:01:51.369 --> 00:01:55.139
Often enough, but actually these I'll have an extra dimension that lets them. Look at these

00:01:55.140 --> 00:02:00.419
so the next layer along will look at all four of these ones and so on what we also then do and I'm going to

00:02:00.420 --> 00:02:03.140
Sort of get why not? Why not use multiple colors?

00:02:04.080 --> 00:02:10.140
We then sometimes also spatially down sample. So we take the maximum of a region of pixels.

00:02:10.320 --> 00:02:13.420
So that we can make the whole thing smaller and fit it better on our graphics card.

00:02:13.740 --> 00:02:18.960
We're gonna downsample this so it's gonna look like this and then okay, I'll just do a yellow one. Why not?

00:02:18.960 --> 00:02:21.359
Can we see yellow on this? We'll soon find out. Yeah. Yeah

00:02:21.400 --> 00:02:24.200
So let's say there's two kernels here and you can kind of see it.

00:02:24.380 --> 00:02:28.140
I think we need to go pink here. Pink? Pink! Alright pink, forget yellow.

00:02:28.360 --> 00:02:31.540
No yellow on white. That was what I was told when I first started using PowerPoint.

00:02:31.540 --> 00:02:33.780
I like pink. Yeah, that kinda, that can work.

00:02:33.780 --> 00:02:35.560
It kinda looks a bit like the red.

00:02:35.560 --> 00:02:41.480
So that's going to look at all these four so and there's two of them. So there's going to be two outputs, right?

00:02:41.490 --> 00:02:45.540
Just think of in terms of four inputs two outputs. So that's going to be sort of like this

00:02:45.540 --> 00:02:50.549
I'm just going to go back to my blue and forget the colors now and you just repeat this process for quite a while

00:02:50.550 --> 00:02:55.559
Right depending on the network. There are more advanced architectures like resinates, but let this become very very deep you

00:02:56.140 --> 00:02:59.609
Know hundreds of layers sometimes but for the sake of argument

00:02:59.610 --> 00:03:01.240
Let's just say it's into the dozens

00:03:01.240 --> 00:03:06.629
usually so we're gonna down sample a bit more and so on and then we'll get some kind of

00:03:07.360 --> 00:03:09.160
final feature vector

00:03:09.160 --> 00:03:12.749
Hopefully a summary of everything that's in all these images sort of summarized for us

00:03:12.750 --> 00:03:14.700
And that's where we do our classification

00:03:14.700 --> 00:03:20.999
so we attach a little neural network to this here and that all connects to all of these and then this is our reading of

00:03:21.190 --> 00:03:26.490
Whether it's a cat or not, that's the idea the problem with this is that these number of connections here are fixed

00:03:26.490 --> 00:03:28.769
This is the big drawback of this kind of network

00:03:29.170 --> 00:03:35.249
You're using this to do this very interesting feature calculation and then you've got this fixed number of it's always three here

00:03:35.250 --> 00:03:36.090
There's always one here

00:03:36.090 --> 00:03:41.940
So this always has to be the same size which means that this input also has to always be the same size. Let's say

00:03:42.670 --> 00:03:46.199
256 pixels by 256 pixels, which is not actually very big

00:03:46.510 --> 00:03:48.510
So what tends to happen is that?

00:03:48.520 --> 00:03:54.540
We take our image that we were interested in and we shrink it to 256 by 256 and put that in you know

00:03:54.540 --> 00:03:56.609
and so when we train our network

00:03:56.610 --> 00:04:02.550
We make a decision early on as to what kind of appropriate size we should use now, of course, it doesn't really make any sense

00:04:03.250 --> 00:04:06.149
Currently because we have lots of different kinds of sizes image, obviously

00:04:06.150 --> 00:04:08.150
They can't be too big because we're run out of RAM

00:04:08.290 --> 00:04:11.670
But it would be nice if we if it was a little bit flexible

00:04:11.670 --> 00:04:16.289
The other issue is but this is actually taking our entire image and summarizing it in one value

00:04:16.290 --> 00:04:19.589
So all spatial information is lost right?

00:04:19.720 --> 00:04:25.320
you can see that the spatial information is getting lower and lower as we go through this network to the point where all we

00:04:25.420 --> 00:04:30.039
Care about is if it's a cat not where is the cat? What if we wanted to find out where the cat was or?

00:04:30.590 --> 00:04:35.829
Segment the cat tutor or somet in a person or count a number of people right to do that

00:04:35.830 --> 00:04:40.029
This isn't gonna work because it always goes down to one. So that's kind of a yes or no is yeah

00:04:40.030 --> 00:04:41.560
Yeah, yes or no. You could have multiple outputs

00:04:41.560 --> 00:04:44.650
If it was yes, dog, no cat, you know different outputs

00:04:44.660 --> 00:04:48.910
Sometimes instead of a classification you output an actual value like the amount of something

00:04:49.070 --> 00:04:52.120
But in this case, that's not that's not worry about it now

00:04:52.850 --> 00:04:56.020
You've told me that this is an amazing market so I'm gonna have a go at this

00:04:56.120 --> 00:05:00.549
I said anyone ever raised your marker in your videos. I mean, this is a first that

00:05:02.570 --> 00:05:06.879
Okay, it's work he's just gonna take quite a while because it stuck this rubber is tiny you know what I qualities Marcus

00:05:06.880 --> 00:05:08.880
All right. There we go

00:05:09.290 --> 00:05:13.420
All right. So the same input still produces this little feature vector

00:05:13.420 --> 00:05:16.960
But now instead of a fixed size neural network on the end

00:05:16.960 --> 00:05:20.439
We're just going to put another convolution of one pixel by one pixel

00:05:20.440 --> 00:05:22.340
So it's just a tiny little filter

00:05:22.340 --> 00:05:26.409
but it's just one by one and that's going to scan over here and produce an image of

00:05:26.810 --> 00:05:32.680
Exactly the same size but this of course we'll be looking for all of these and working out in detail what the object is

00:05:32.680 --> 00:05:34.959
So it will have much more information than these ones back here

00:05:35.060 --> 00:05:36.190
So, you know

00:05:36.190 --> 00:05:40.090
this could be outputting a heat map of where the cats are or where the dogs are or

00:05:40.430 --> 00:05:44.560
You know the areas of disease in sort of a medical image or something like this

00:05:44.560 --> 00:05:48.340
And so this is called a fully convolutional network because there are no longer any

00:05:48.890 --> 00:05:56.229
Fully connected or fixed size layers in this network. So normal deep learning in some sense or at least up until so 2014-2015

00:05:56.840 --> 00:06:00.969
Predominantly just put a little new network on the end of this. That was a fixed size now

00:06:01.040 --> 00:06:02.080
We don't do that

00:06:02.080 --> 00:06:06.400
And the nice thing is if we double the size of this input image, I mean we're using more RAM

00:06:06.400 --> 00:06:08.919
But this is going to double little double and in the end

00:06:08.920 --> 00:06:14.920
This will also double and we'll just get the exact same result which is bigger so we can now put in different size images

00:06:15.170 --> 00:06:19.629
the way this actually works in practice is that when one your deep learning library like

00:06:19.880 --> 00:06:24.460
Cafe 2 or pi stalks or tensorflow will allocate memory as required

00:06:24.460 --> 00:06:28.030
So you put in an input image and it goes well, ok with that input image

00:06:28.030 --> 00:06:32.889
We're going to need to allocate this much RAM to do all this and so the nice thing is that this can now have information

00:06:32.890 --> 00:06:37.049
On where the objects are as well as what they are picks output. So

00:06:37.690 --> 00:06:42.239
We'll show a few examples of semantic segmentation on the screen so you can see the kind of thing

00:06:42.240 --> 00:06:46.049
We're talking about the obvious downside here, which is what I'm going to leave for

00:06:46.050 --> 00:06:49.169
Another video is that this is very very small, you know

00:06:49.169 --> 00:06:52.228
maybe this is only a few pixels by a few pixels or something like this or

00:06:52.300 --> 00:06:57.509
You haven't done that much down sampling and so it's not a very deep network and you haven't learned a whole lot if you are

00:06:57.509 --> 00:07:03.779
Looking for where is the carrier's image? You have kind of it's down in the bottom left. It would be very very general

00:07:03.780 --> 00:07:07.319
So it would be you know bit sort of area. Maybe there's something else going on over here

00:07:07.659 --> 00:07:13.619
It depends on the resolution of this image looks great with different colors in line. But what are you actually using this stuff?

00:07:13.620 --> 00:07:17.009
Alright, so, I mean we have to extend this slightly, which I'm you know

00:07:17.080 --> 00:07:21.569
Normally going to postpone for another video because this is too small for us to be practical, right?

00:07:21.569 --> 00:07:24.539
What we could do is just up up sample this we could use linear or bilinear interpolation

00:07:25.150 --> 00:07:29.639
to just make this way bigger like this and have a bigger output image and

00:07:30.099 --> 00:07:35.339
It would still be very low resolution you'd get the rough idea of where something was but it wouldn't be great

00:07:35.379 --> 00:07:37.379
Right, so you could use this to find

00:07:37.479 --> 00:07:41.699
Objects that you're looking for. So for example in our lab, we're using this for things like analysis of plants

00:07:41.699 --> 00:07:46.049
So where are the wheat is how many are there that can be useful in a field to try and work out

00:07:46.050 --> 00:07:50.849
What the yield or disease problems are going to be you can do it for medical images where the tumors in this image

00:07:51.310 --> 00:07:55.529
Segmenting x-ray images we're also doing it on human pose estimation and face

00:07:56.529 --> 00:08:00.059
Estimation so you know, where is the face in this image? Where are the eyes?

00:08:00.400 --> 00:08:03.989
What shape is the face this kind of thing so you can use this for a huge amount of things?

00:08:03.990 --> 00:08:07.019
But we're going to need to extend it a little bit more to get the best out of it

00:08:07.080 --> 00:08:09.719
And the extension we'll call an encoder decoder Network

00:08:11.819 --> 00:08:17.899
Are you tying it up now? What are you doing? It's not neat enough this there's little bits of unwrapped out bits

00:08:19.650 --> 00:08:23.720
Bear with me I start on the next video in a minute. Yeah

00:08:24.990 --> 00:08:26.990
That's as good as it's getting it

