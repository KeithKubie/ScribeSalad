WEBVTT
Kind: captions
Language: en

00:00:01.280 --> 00:00:02.420
Hello.

00:00:02.420 --> 00:00:04.210
Welcome to Breaking the
JavaScript Speed

00:00:04.210 --> 00:00:05.220
Barrier with V8.

00:00:05.220 --> 00:00:07.190
My name is Daniel Clifford.

00:00:07.190 --> 00:00:10.240
I'm the tech lead and manager
of the V8 team.

00:00:10.240 --> 00:00:12.410
If you'd like to follow along in
the slides, there's a link

00:00:12.410 --> 00:00:14.230
here on the first slide.

00:00:14.230 --> 00:00:18.060
It might help for you in the
back rows to read the smaller

00:00:18.060 --> 00:00:20.025
fonts in some of the
code slides later.

00:00:23.720 --> 00:00:26.300
I'd like to talk to you today
about optimizing the

00:00:26.300 --> 00:00:28.020
performance of your
web application.

00:00:28.020 --> 00:00:30.130
Now this could mean a lot of
different things to a lot of

00:00:30.130 --> 00:00:31.090
different people.

00:00:31.090 --> 00:00:34.030
This could mean optimizing your
WebGL code to get more

00:00:34.030 --> 00:00:35.270
frames per second in the game.

00:00:35.270 --> 00:00:39.040
This could mean reducing the
number of network round trips

00:00:39.040 --> 00:00:40.910
in a client server
application.

00:00:40.910 --> 00:00:46.500
But what I'd like to talk to
you about today is Raw

00:00:46.500 --> 00:00:50.290
JavaScript Execution Performance
with V8, the

00:00:50.290 --> 00:00:53.110
JavaScript engine inside
of Chrome.

00:00:53.110 --> 00:00:56.150
The V8 project has recently
moved to the development

00:00:56.150 --> 00:00:58.860
center, the Google Development
Center in Munich, Germany.

00:00:58.860 --> 00:01:05.459
And as you may know, Germany is
the home of the Autobahn.

00:01:05.459 --> 00:01:08.520
And what you may not know is the
Autobahn is not actually a

00:01:08.520 --> 00:01:12.690
single stretch of road from
Hamburg to Munich that runs

00:01:12.690 --> 00:01:14.200
straight through the middle
of the country.

00:01:14.200 --> 00:01:15.950
But rather it's a network
of roads.

00:01:15.950 --> 00:01:19.030
And these days, most
of the Autobahn

00:01:19.030 --> 00:01:20.420
actually has a speed limit.

00:01:20.420 --> 00:01:23.590
But there are still a few
stretches of the road that

00:01:23.590 --> 00:01:25.880
don't have any speed
limit whatsoever.

00:01:25.880 --> 00:01:29.990
And you can go as fast as you
want, as fast as you can.

00:01:29.990 --> 00:01:34.280
And so, as a resident of Munich
and a resident of

00:01:34.280 --> 00:01:36.990
Germany, I feel especially
qualified to speak about

00:01:36.990 --> 00:01:39.000
moving at speeds that would get
you ticketed here in the

00:01:39.000 --> 00:01:40.250
United States.

00:01:42.880 --> 00:01:44.770
You might ask the question, who
cares about performance?

00:01:44.770 --> 00:01:46.180
JavaScript performance
is fast enough.

00:01:46.180 --> 00:01:48.350
This is something that only game
developers need to worry

00:01:48.350 --> 00:01:50.490
about, or the developers
of highly interactive

00:01:50.490 --> 00:01:52.240
applications.

00:01:52.240 --> 00:01:55.450
But I'm here to tell you that
you should care about

00:01:55.450 --> 00:01:55.900
performance.

00:01:55.900 --> 00:01:58.690
Everybody who develops a web
application should care about

00:01:58.690 --> 00:01:59.690
performance.

00:01:59.690 --> 00:02:01.390
And the reason is, is that

00:02:01.390 --> 00:02:03.140
JavaScript performance matters.

00:02:03.140 --> 00:02:06.080
It still matters.

00:02:06.080 --> 00:02:08.210
It's not just about making
your current

00:02:08.210 --> 00:02:09.460
application run faster.

00:02:11.760 --> 00:02:14.270
It's about enabling things that
you have never been able

00:02:14.270 --> 00:02:14.950
to do in the past.

00:02:14.950 --> 00:02:18.010
Every cycle that you win back
when you do performance

00:02:18.010 --> 00:02:21.560
optimization, you can invest
in something new that you

00:02:21.560 --> 00:02:23.430
haven't been able
to do before.

00:02:23.430 --> 00:02:25.280
An interesting comment about
these pictures, they were

00:02:25.280 --> 00:02:27.890
taken on the same street,
only a few feet away.

00:02:27.890 --> 00:02:30.490
I think it's interesting that
in the same place, given a

00:02:30.490 --> 00:02:32.290
slightly different perspective,
you can have a

00:02:32.290 --> 00:02:35.550
completely different
view of the world.

00:02:35.550 --> 00:02:36.800
So let's see.

00:02:36.800 --> 00:02:41.450
Let's talk about breaking
the speed limit today.

00:02:41.450 --> 00:02:47.570
I'd like to use a checklist as
the basis of how you optimize

00:02:47.570 --> 00:02:49.080
your web application.

00:02:49.080 --> 00:02:51.950
It's a relatively
straightforward model.

00:02:51.950 --> 00:02:54.390
But it's very powerful.

00:02:54.390 --> 00:02:57.880
And the first step of the
checklist is to make sure you

00:02:57.880 --> 00:03:00.320
are prepared before you
have a problem.

00:03:00.320 --> 00:03:02.620
This is the piece that is
the most expensive.

00:03:02.620 --> 00:03:04.180
This is the one that takes
the most amount of time.

00:03:04.180 --> 00:03:05.870
And I'll be spending the
most amount of time

00:03:05.870 --> 00:03:08.160
talking about it today.

00:03:08.160 --> 00:03:11.230
But this is the one that you
have to do to make the second

00:03:11.230 --> 00:03:13.770
two steps possible at all.

00:03:13.770 --> 00:03:16.540
The second step is to identify
and understand the crux of

00:03:16.540 --> 00:03:18.050
your problem.

00:03:18.050 --> 00:03:22.180
And if you know how
a system works.

00:03:22.180 --> 00:03:24.550
If you prepare before you go
into the second step, it makes

00:03:24.550 --> 00:03:27.650
it much easier to find
your problem.

00:03:27.650 --> 00:03:30.830
The third step, you
fix what matters.

00:03:30.830 --> 00:03:33.300
And hopefully this is the step
that's actually really easy

00:03:33.300 --> 00:03:36.920
after you've done
the first two.

00:03:36.920 --> 00:03:40.050
Now, this is a relatively
simple model.

00:03:40.050 --> 00:03:41.700
But, like I said, it's
very powerful.

00:03:41.700 --> 00:03:45.230
And you can even apply it to
real world situations.

00:03:45.230 --> 00:03:47.460
So I'd like to tell you a story

00:03:47.460 --> 00:03:48.800
about using the checklist.

00:03:48.800 --> 00:03:52.450
And I like to do recreational
mountain climbing.

00:03:52.450 --> 00:03:53.340
I'm not very good at it.

00:03:53.340 --> 00:03:55.190
But I have a friend
who is very good

00:03:55.190 --> 00:03:56.900
at it, Michael Stanton.

00:03:56.900 --> 00:03:59.130
And he's taught me
everything I know

00:03:59.130 --> 00:04:00.700
about mountain climbing.

00:04:00.700 --> 00:04:03.420
And I trust him on
the mountain.

00:04:03.420 --> 00:04:04.700
I trust him with my life.

00:04:04.700 --> 00:04:07.150
And that's how we found
ourselves in the summer of

00:04:07.150 --> 00:04:10.040
2010 up here.

00:04:10.040 --> 00:04:11.650
And it was a beautiful day.

00:04:11.650 --> 00:04:13.030
We'd been on the mountain
all day.

00:04:13.030 --> 00:04:14.210
We hadn't seen another soul.

00:04:14.210 --> 00:04:15.960
We had the whole mountain
to ourselves.

00:04:15.960 --> 00:04:18.820
And we were two rope lengths
from the top, from the summit.

00:04:18.820 --> 00:04:20.589
We were almost there.

00:04:20.589 --> 00:04:21.970
And I was belaying Michael.

00:04:21.970 --> 00:04:23.840
I was making sure that if
he were to fall that

00:04:23.840 --> 00:04:24.520
I would catch him.

00:04:24.520 --> 00:04:26.280
And he was leading ahead.

00:04:26.280 --> 00:04:29.700
And he climbed ahead of me
around a corner, out of sight.

00:04:29.700 --> 00:04:31.620
And I heard him struggling with
a particularly tricky

00:04:31.620 --> 00:04:32.300
climbing problem.

00:04:32.300 --> 00:04:35.290
Then I heard two sounds that I
will never forget in my life.

00:04:35.290 --> 00:04:39.200
And the first one was the
percussive sound of a rock

00:04:39.200 --> 00:04:40.160
coming loose.

00:04:40.160 --> 00:04:43.707
And the second sound was the
sickening thud of that rock

00:04:43.707 --> 00:04:46.110
hitting Michael.

00:04:46.110 --> 00:04:48.070
He fell.

00:04:48.070 --> 00:04:49.680
I called his name.

00:04:49.680 --> 00:04:52.640
But all I heard was silence.

00:04:52.640 --> 00:04:55.895
I realized in that moment that
I had a performance problem.

00:04:58.740 --> 00:05:02.100
And the checklist that I just
presented to you would be the

00:05:02.100 --> 00:05:05.650
key for me to get out
of that situation.

00:05:05.650 --> 00:05:09.630
I had to be prepared before I
ever got on that mountain.

00:05:09.630 --> 00:05:13.320
I had to make sure to identify
the problem that I had in that

00:05:13.320 --> 00:05:15.090
very moment, the key
problem, so that I

00:05:15.090 --> 00:05:16.490
could fix it quickly.

00:05:16.490 --> 00:05:19.710
Somebody's life could
depend on it.

00:05:19.710 --> 00:05:24.030
Now, I hope you never are in a
situation like that, that your

00:05:24.030 --> 00:05:26.690
life depends on applying
the checklist.

00:05:26.690 --> 00:05:29.960
So why don't we go to an
example, which talks about a

00:05:29.960 --> 00:05:32.430
less life threatening
performance problem.

00:05:32.430 --> 00:05:34.940
Let's talk about JavaScript.

00:05:34.940 --> 00:05:38.290
So I have put together a sample
problem that I'd like

00:05:38.290 --> 00:05:40.900
to talk about throughout the
course of this talk.

00:05:40.900 --> 00:05:44.690
And it is a toy problem that
I've come up with.

00:05:44.690 --> 00:05:46.030
But I think it's representative
of some of the

00:05:46.030 --> 00:05:46.710
things that--

00:05:46.710 --> 00:05:48.260
some of the performance problems
that you might face

00:05:48.260 --> 00:05:49.590
in your own code.

00:05:49.590 --> 00:05:54.980
And the problem is to compute
the 25,000th prime.

00:05:54.980 --> 00:05:57.880
Pretty simple algorithm here,
you start at one.

00:05:57.880 --> 00:05:59.120
You count up.

00:05:59.120 --> 00:06:02.180
And you take each candidate
number.

00:06:02.180 --> 00:06:04.260
And you look in a list of primes
that you're maintaining

00:06:04.260 --> 00:06:07.720
and see if any of those primes
can be divided into that

00:06:07.720 --> 00:06:08.590
candidate number.

00:06:08.590 --> 00:06:10.690
And if it can, then
the candidate

00:06:10.690 --> 00:06:12.030
number is not a prime.

00:06:12.030 --> 00:06:14.940
If none of the prime numbers go
into that candidate number,

00:06:14.940 --> 00:06:19.150
then we have a new prime
and we add it to list.

00:06:19.150 --> 00:06:25.330
And I wrote some code in
C++ and in JavaScript.

00:06:25.330 --> 00:06:27.730
Don't sweat the details
of this code.

00:06:27.730 --> 00:06:29.390
I just wanted to show you
that it's about the

00:06:29.390 --> 00:06:30.170
same amount of code.

00:06:30.170 --> 00:06:33.600
And I tried to do a pretty good
job of porting the code

00:06:33.600 --> 00:06:35.410
from JavaScript to C++.

00:06:35.410 --> 00:06:36.660
So it does the same thing.

00:06:39.520 --> 00:06:42.280
And then what I did is I
actually ran the code.

00:06:42.280 --> 00:06:47.490
I compiled the C++ code
with GCC and ran it.

00:06:47.490 --> 00:06:51.580
And you can see it took about
three seconds to compute the

00:06:51.580 --> 00:06:53.840
25,000th prime.

00:06:53.840 --> 00:06:56.030
Then I took the JavaScript
code.

00:06:56.030 --> 00:06:57.090
And I didn't run
it in browser.

00:06:57.090 --> 00:06:58.910
What I did was I took the
debugging shell that's

00:06:58.910 --> 00:07:01.530
available as part of the V8
open source code project.

00:07:01.530 --> 00:07:05.250
And I compiled that and ran
the JavaScript with the

00:07:05.250 --> 00:07:06.240
debugging shell.

00:07:06.240 --> 00:07:08.030
The debugging shell makes
it possible for you to

00:07:08.030 --> 00:07:10.350
concentrate on JavaScript
specific problems.

00:07:10.350 --> 00:07:13.620
So for this presentation, I'll
refer to the debugging shell

00:07:13.620 --> 00:07:14.950
in most of my examples.

00:07:14.950 --> 00:07:19.700
You'll see that when I ran the
prime code in JavaScript, it

00:07:19.700 --> 00:07:24.060
took 15 seconds.

00:07:24.060 --> 00:07:28.290
So JavaScript's about five
times slower than C++.

00:07:28.290 --> 00:07:29.540
That's not so bad, right?

00:07:31.760 --> 00:07:34.800
Of course it is, yeah.

00:07:34.800 --> 00:07:37.880
So I just made a big mistake.

00:07:37.880 --> 00:07:39.490
I've told you about
this checklist.

00:07:39.490 --> 00:07:42.070
And I just completely
ignored it.

00:07:42.070 --> 00:07:43.910
I was not prepared.

00:07:43.910 --> 00:07:45.660
I don't have enough information
to make judgment

00:07:45.660 --> 00:07:49.120
about whether my code is bad or
good, whether that number

00:07:49.120 --> 00:07:51.290
is something I should
expect or not.

00:07:51.290 --> 00:07:53.910
I didn't even try
to analyze any

00:07:53.910 --> 00:07:55.810
potential performance problem.

00:07:55.810 --> 00:08:01.100
And I didn't even get anywhere
close to fixing any problem.

00:08:01.100 --> 00:08:05.180
I'd like to show you
how V8 has improved

00:08:05.180 --> 00:08:07.480
since Chrome came out.

00:08:07.480 --> 00:08:11.100
This is V8's score on the V8
benchmark, version seven.

00:08:11.100 --> 00:08:13.780
And you can see that it's
got a lot better

00:08:13.780 --> 00:08:16.120
since we launched Chrome.

00:08:16.120 --> 00:08:20.830
And we're now at the position
with V8 that we can actually

00:08:20.830 --> 00:08:25.690
make a comparison against the
performance of C and C++ code.

00:08:25.690 --> 00:08:30.620
You can expect to be in the
ballpark for certain code.

00:08:30.620 --> 00:08:33.330
So don't give up here.

00:08:33.330 --> 00:08:36.000
When you're in the same
situation, where you say,

00:08:36.000 --> 00:08:37.549
we're slower than C++.

00:08:37.549 --> 00:08:39.030
Or I'm slower where
I want to be.

00:08:39.030 --> 00:08:40.760
Don't just give up.

00:08:40.760 --> 00:08:43.370
Apply the checklist that
I presented to you.

00:08:43.370 --> 00:08:45.630
And see how far you can get.

00:08:45.630 --> 00:08:50.260
Demand that your application
is faster.

00:08:50.260 --> 00:08:53.680
So how much faster do you
think we can get the

00:08:53.680 --> 00:08:56.680
JavaScript code to run?

00:08:56.680 --> 00:08:58.130
Who here thinks we can do it--

00:08:58.130 --> 00:09:00.921
we can get it three and
a half times faster?

00:09:00.921 --> 00:09:03.650
All right, we've got
maybe 5, 10 people.

00:09:03.650 --> 00:09:04.810
35 times?

00:09:04.810 --> 00:09:06.080
Takers?

00:09:06.080 --> 00:09:08.430
OK, also a couple of people,
I know you know

00:09:08.430 --> 00:09:09.520
how this game works.

00:09:09.520 --> 00:09:12.030
350 times?

00:09:12.030 --> 00:09:17.305
OK, one person, the V8 PMs.

00:09:17.305 --> 00:09:19.650
[LAUGHTER]

00:09:19.650 --> 00:09:22.090
3,500?

00:09:22.090 --> 00:09:25.140
All right, we've got to get at
least one brave taker here.

00:09:25.140 --> 00:09:29.910
So I think the most votes
were for 35 times.

00:09:29.910 --> 00:09:34.770
Let's apply the checklist and
see how far we can get.

00:09:34.770 --> 00:09:38.450
Now I told you the first step
was to be prepared.

00:09:38.450 --> 00:09:40.270
And this means we're going to
dive into some technical

00:09:40.270 --> 00:09:44.450
details of V8, so you can
understand how it works.

00:09:44.450 --> 00:09:46.730
So fasten your seat belts.

00:09:46.730 --> 00:09:51.410
This is where things get
a little bit racy.

00:09:51.410 --> 00:09:53.460
So what does prepared
mean for V8?

00:09:53.460 --> 00:09:54.840
I mentioned this before.

00:09:54.840 --> 00:09:57.860
You need to understand
how V8 optimizes

00:09:57.860 --> 00:09:59.000
your JavaScript code.

00:09:59.000 --> 00:10:02.330
You need to understand how V8
actually works so that you can

00:10:02.330 --> 00:10:05.070
help it optimize your code.

00:10:05.070 --> 00:10:08.770
Because once you understand how
V8 works, then when you

00:10:08.770 --> 00:10:10.780
actually write your JavaScript
code, you can keep those

00:10:10.780 --> 00:10:12.400
things in mind and make sure
that you don't make some of

00:10:12.400 --> 00:10:16.850
the mistakes that
will fool V8.

00:10:16.850 --> 00:10:19.020
Make sure you learn the tools
that are available to you.

00:10:19.020 --> 00:10:21.770
There's some great tools in
Chrome, the dev tools.

00:10:21.770 --> 00:10:25.520
And V8 has some built-in tools
in the debugging shell that

00:10:25.520 --> 00:10:27.350
can really help you understand
what's going on in your

00:10:27.350 --> 00:10:29.050
JavaScript and help you
make it better.

00:10:31.770 --> 00:10:32.020
All right.

00:10:32.020 --> 00:10:33.620
So the first thing I'd
like to talk to you

00:10:33.620 --> 00:10:36.720
about is hidden classes.

00:10:36.720 --> 00:10:40.070
So JavaScript doesn't
have explicit types.

00:10:40.070 --> 00:10:43.260
And this presents a bit of
a challenge to a language

00:10:43.260 --> 00:10:46.930
implementer, because type
information is very valuable

00:10:46.930 --> 00:10:50.750
in specializing generated code
to be very efficient.

00:10:50.750 --> 00:10:52.870
And if you don't have that type
information, it makes it

00:10:52.870 --> 00:10:54.520
much more difficult.

00:10:54.520 --> 00:10:57.180
And it's hard to gather this
information efficiently and

00:10:57.180 --> 00:10:59.290
quickly when you're compiling
JavaScript code because

00:10:59.290 --> 00:11:02.230
compilation is part of
the execution time of

00:11:02.230 --> 00:11:03.140
a JavaScript program.

00:11:03.140 --> 00:11:06.870
Every cycle that you spend
compiling a JavaScript script

00:11:06.870 --> 00:11:10.050
before you execute it is a cycle
longer than it takes to

00:11:10.050 --> 00:11:11.830
actually get to doing
the work.

00:11:11.830 --> 00:11:15.730
So we have to find a way
to get executing

00:11:15.730 --> 00:11:17.000
code as fast as possible.

00:11:17.000 --> 00:11:20.950
And it makes it difficult to do
expensive reasoning about

00:11:20.950 --> 00:11:23.470
types at compilation time.

00:11:23.470 --> 00:11:26.440
And that makes it extremely
difficult to get it close to

00:11:26.440 --> 00:11:29.700
the performance of C++.

00:11:29.700 --> 00:11:34.170
However, there are
some tricks.

00:11:34.170 --> 00:11:39.250
Hidden classes help make V8
run JavaScript faster.

00:11:39.250 --> 00:11:44.550
V8 internally creates hidden
classes for objects at run

00:11:44.550 --> 00:11:47.290
time, not at compile time.

00:11:47.290 --> 00:11:50.510
And that's how we get around
the problem of compiling

00:11:50.510 --> 00:11:52.820
upfront, getting the information
upfront, because

00:11:52.820 --> 00:11:56.480
we gather the hidden class
information as we go.

00:11:56.480 --> 00:11:58.150
And here's a key insight.

00:11:58.150 --> 00:12:00.000
And this is one that we'll
repeat throughout the

00:12:00.000 --> 00:12:00.600
presentation.

00:12:00.600 --> 00:12:03.530
Objects with the same hidden
class can use the same

00:12:03.530 --> 00:12:05.390
optimized generated code.

00:12:05.390 --> 00:12:08.710
And that means if you help teach
V8 through the way that

00:12:08.710 --> 00:12:11.920
you structure your code, which
object has the same hidden

00:12:11.920 --> 00:12:15.300
class, you can help it to
generate optimized code for

00:12:15.300 --> 00:12:17.490
those cases.

00:12:17.490 --> 00:12:18.940
I'd like to show you
how this works in

00:12:18.940 --> 00:12:21.180
a very simple example.

00:12:21.180 --> 00:12:23.650
So I've got a constructor
function here

00:12:23.650 --> 00:12:25.870
for an object point.

00:12:25.870 --> 00:12:28.700
And I'm going to instantiate
it twice.

00:12:28.700 --> 00:12:32.470
And let's see actually what
V8 does behind the scenes.

00:12:32.470 --> 00:12:37.020
So the first time the
constructor gets called, V8

00:12:37.020 --> 00:12:38.260
creates a new hidden class.

00:12:38.260 --> 00:12:40.910
So what you see here is-- on the
right hand side-- is you

00:12:40.910 --> 00:12:43.160
see the new point object.

00:12:43.160 --> 00:12:47.940
The first entry in the point
object is a hidden class to an

00:12:47.940 --> 00:12:50.420
empty point hidden class.

00:12:50.420 --> 00:12:54.750
And as we assign to the members,
in point, what V8

00:12:54.750 --> 00:12:57.750
does is actually realizes, ah,
you're changing the hidden

00:12:57.750 --> 00:13:00.020
class by adding a
member to it.

00:13:00.020 --> 00:13:03.610
And we create a new
hidden class.

00:13:03.610 --> 00:13:06.280
And the point object
gets assigned to

00:13:06.280 --> 00:13:07.510
this new hidden class.

00:13:07.510 --> 00:13:09.680
And if we had another member--

00:13:09.680 --> 00:13:10.920
in this case y--

00:13:10.920 --> 00:13:12.740
we get yet another
hidden class.

00:13:12.740 --> 00:13:15.190
And you see what happens here
is that not only does V8

00:13:15.190 --> 00:13:18.120
create new hidden classes as
new members are added.

00:13:18.120 --> 00:13:21.480
But it keeps track of what had
to happen to get from one

00:13:21.480 --> 00:13:23.500
hidden class to another one.

00:13:23.500 --> 00:13:26.290
So you see we went from empty
point object to a point object

00:13:26.290 --> 00:13:31.190
with an x, to a point object
with an x and a y.

00:13:31.190 --> 00:13:34.880
And that's important because the
second time that we call

00:13:34.880 --> 00:13:38.890
the point constructor, this
hidden class structure is

00:13:38.890 --> 00:13:40.460
already there.

00:13:40.460 --> 00:13:44.720
And as the code is executed to
add the members x and the

00:13:44.720 --> 00:13:49.160
members y, you'll see
that the object also

00:13:49.160 --> 00:13:50.650
gets new hidden classes.

00:13:50.650 --> 00:13:52.570
But it gets the same hidden
classes that we created the

00:13:52.570 --> 00:13:54.050
first time through.

00:13:54.050 --> 00:13:59.290
So that at the end, we actually
have P1 and P2 having

00:13:59.290 --> 00:14:01.050
the same hidden class.

00:14:01.050 --> 00:14:06.670
The problem is, is that if we
add a member to P2 that we

00:14:06.670 --> 00:14:08.040
haven't added to P1--

00:14:08.040 --> 00:14:10.550
after the fact, outside
of the constructor--

00:14:10.550 --> 00:14:13.020
what happens is that we
create yet another

00:14:13.020 --> 00:14:14.810
hidden class for P2.

00:14:14.810 --> 00:14:17.660
And it is different from
the class for P1.

00:14:17.660 --> 00:14:20.780
So they are now-- we're not able
to use the same optimize

00:14:20.780 --> 00:14:23.050
code for both of
those objects.

00:14:23.050 --> 00:14:27.880
So be aware that by doing
something like this and

00:14:27.880 --> 00:14:29.780
creating hidden classes, you're
defeating some of the

00:14:29.780 --> 00:14:34.480
optimizations that V8 can do.

00:14:34.480 --> 00:14:37.990
I'd like to talk about speed
traps to avoid in this

00:14:37.990 --> 00:14:39.030
presentation.

00:14:39.030 --> 00:14:41.690
For the most part, all of the
advice I'm going to give you

00:14:41.690 --> 00:14:44.050
today is something
that is eternal.

00:14:44.050 --> 00:14:47.850
You can assume that the tips
that I give you today you can

00:14:47.850 --> 00:14:50.530
use forever, except for a couple
of cases where I'll

00:14:50.530 --> 00:14:52.280
say, this is something that's
temporary, something that

00:14:52.280 --> 00:14:54.230
we're working on and we're
trying to make better.

00:14:54.230 --> 00:14:57.580
So let's get to the first speed
trap, which is make sure

00:14:57.580 --> 00:15:00.070
to initialize all members in
your constructor functions.

00:15:00.070 --> 00:15:02.470
This comes from the example I
just showed you, which is you

00:15:02.470 --> 00:15:06.100
need to teach V8 which hidden
class objects should have

00:15:06.100 --> 00:15:07.150
after they're constructed.

00:15:07.150 --> 00:15:09.730
And the way to do that is by
putting all of the member

00:15:09.730 --> 00:15:12.450
initialization in
the constructor.

00:15:12.450 --> 00:15:15.490
Always initialize object members
in the same order.

00:15:15.490 --> 00:15:18.310
This follows from that example
that I gave you.

00:15:18.310 --> 00:15:21.710
If you add members in different
orders, you create a

00:15:21.710 --> 00:15:23.720
different tree of
hidden classes.

00:15:23.720 --> 00:15:25.950
And at the end, you'll have
objects with two different

00:15:25.950 --> 00:15:27.840
hidden classes that can't use
the same optimized code.

00:15:31.370 --> 00:15:36.290
Next thing I'd like to talk
about are numbers.

00:15:36.290 --> 00:15:39.870
So because we don't have a lot
of type information in

00:15:39.870 --> 00:15:42.560
JavaScript, we have
this dilemma.

00:15:42.560 --> 00:15:45.400
We want to be able to generate
code that can handle all

00:15:45.400 --> 00:15:49.700
possible different values, all
different possible types.

00:15:49.700 --> 00:15:52.560
But you want to be able
to have an efficient

00:15:52.560 --> 00:15:55.400
representation of numbers.

00:15:55.400 --> 00:15:56.470
And how do we do this?

00:15:56.470 --> 00:15:59.530
Well, we use a technique
called tagging.

00:15:59.530 --> 00:16:02.380
So inside of V8 we pass
around values of

00:16:02.380 --> 00:16:05.310
32-bit numbers and objects.

00:16:05.310 --> 00:16:07.800
But we want to be able to
use the same 32 bits

00:16:07.800 --> 00:16:09.240
to represent both.

00:16:09.240 --> 00:16:12.580
And that way we can have one
code path that can handle, in

00:16:12.580 --> 00:16:16.020
many cases, the objects
and integers.

00:16:16.020 --> 00:16:19.240
So what we do is we use
the bottom bit.

00:16:19.240 --> 00:16:22.110
And each of the values have
a special meaning.

00:16:22.110 --> 00:16:24.695
If the bit is set, it's
an object pointer.

00:16:24.695 --> 00:16:28.470
If it's clear, it's what we
call small integer or smi.

00:16:28.470 --> 00:16:32.120
And that's a 31-bit
signed integer.

00:16:32.120 --> 00:16:34.660
Now if you have a numeric value
that you're passing

00:16:34.660 --> 00:16:37.810
around, assigning to a member
that is bigger--

00:16:37.810 --> 00:16:41.620
it's a numeric value that's
bigger than 31 signed bits--

00:16:41.620 --> 00:16:45.420
then it doesn't fit in
one of these smis.

00:16:45.420 --> 00:16:47.400
And we have to create what's
called a box for it.

00:16:47.400 --> 00:16:49.160
We box the number.

00:16:49.160 --> 00:16:50.490
We turn it into a double.

00:16:50.490 --> 00:16:53.380
And we create a new object to
put that number inside of it.

00:16:53.380 --> 00:16:56.960
And what follows from that is
the next speed trap to avoid,

00:16:56.960 --> 00:17:02.340
which is make sure, whenever
possible, you use 31-bit

00:17:02.340 --> 00:17:06.510
signed numbers for performance
critical calculations.

00:17:06.510 --> 00:17:09.819
Because if you exceed 31 signed
bits, we will have to

00:17:09.819 --> 00:17:12.000
convert it to a double value.

00:17:12.000 --> 00:17:14.369
Now there's some optimizations
that we have that doesn't make

00:17:14.369 --> 00:17:15.390
it as bad as it seems.

00:17:15.390 --> 00:17:18.859
But there are cases where that
process causes an allocation.

00:17:18.859 --> 00:17:20.790
And that means that some
mathematical operations can

00:17:20.790 --> 00:17:22.040
cause allocation.

00:17:25.250 --> 00:17:26.940
The next thing I'd like to
talk about is arrays.

00:17:26.940 --> 00:17:28.840
This brings some of the elements
together of the

00:17:28.840 --> 00:17:30.880
previous two sections.

00:17:30.880 --> 00:17:32.610
In JavaScript, you can have
very large arrays.

00:17:32.610 --> 00:17:34.440
And you can have arrays that
are sparse, that don't have

00:17:34.440 --> 00:17:36.230
every element inside of them.

00:17:36.230 --> 00:17:40.230
And so V8 actually has two
different methods to handle

00:17:40.230 --> 00:17:41.710
two different types of arrays.

00:17:41.710 --> 00:17:43.990
The first one is
fast elements.

00:17:43.990 --> 00:17:47.400
And fast elements, they have
a linear storage buffer.

00:17:47.400 --> 00:17:49.840
And V8 uses them if the
set of keys for the

00:17:49.840 --> 00:17:51.600
array is very compact.

00:17:54.150 --> 00:17:56.830
If that's not the case-- so you
have a very sparse array--

00:17:56.830 --> 00:17:58.150
then it uses a different
format, which

00:17:58.150 --> 00:17:59.830
is dictionary elements.

00:17:59.830 --> 00:18:03.380
Fast elements, linear buffer,
very fast and

00:18:03.380 --> 00:18:05.550
efficient to access.

00:18:05.550 --> 00:18:07.930
Dictionary elements,
it's a hash table.

00:18:07.930 --> 00:18:11.410
Much more compact but
also more expensive

00:18:11.410 --> 00:18:12.660
at run time to access.

00:18:15.670 --> 00:18:19.600
Kind of obvious here, if you
want to have your arrays be

00:18:19.600 --> 00:18:24.310
very fast, make sure that
V8 uses fast elements to

00:18:24.310 --> 00:18:24.870
represent them.

00:18:24.870 --> 00:18:28.090
And the way to do this is to
make sure that your keys start

00:18:28.090 --> 00:18:30.390
at zero and that they're
contiguous.

00:18:30.390 --> 00:18:33.620
So don't create an array
and start using

00:18:33.620 --> 00:18:36.280
index number 25,000.

00:18:36.280 --> 00:18:40.010
Start at zero and go up.

00:18:40.010 --> 00:18:43.990
Also, don't allocate really
large arrays that you're not

00:18:43.990 --> 00:18:45.160
going to use everything in.

00:18:45.160 --> 00:18:48.390
So if you allocate an array with
65,000 elements and you

00:18:48.390 --> 00:18:51.070
only use the first five, V8
thinks, well, that's a very

00:18:51.070 --> 00:18:55.050
sparse array, and will switch
into dictionary mode, which

00:18:55.050 --> 00:19:00.250
means the access of the elements
will be slower.

00:19:00.250 --> 00:19:02.970
Don't delete elements
inside of arrays.

00:19:02.970 --> 00:19:05.900
Same principle here, because
when you delete elements, it

00:19:05.900 --> 00:19:08.910
makes the key set sparse.

00:19:08.910 --> 00:19:11.780
And it can lead to V8 switching
the elements to

00:19:11.780 --> 00:19:14.620
dictionary mode.

00:19:14.620 --> 00:19:17.650
Don't load from uninitialized
or deleted elements.

00:19:17.650 --> 00:19:18.710
This is an important one.

00:19:18.710 --> 00:19:21.440
It's easy to get wrong.

00:19:21.440 --> 00:19:22.960
Here's an example.

00:19:22.960 --> 00:19:24.430
Your code will work.

00:19:24.430 --> 00:19:25.750
You won't notice.

00:19:25.750 --> 00:19:27.930
And it won't make a difference
in the output.

00:19:27.930 --> 00:19:30.350
However, it will make
things a lot slower.

00:19:30.350 --> 00:19:33.630
So here's an example of
doing exactly this.

00:19:33.630 --> 00:19:37.330
I have a loop here that
accesses an array.

00:19:37.330 --> 00:19:39.570
And it uses the or equals
operator, which means it takes

00:19:39.570 --> 00:19:42.380
the existing value in the array,
ors it to something and

00:19:42.380 --> 00:19:43.210
then writes it back.

00:19:43.210 --> 00:19:47.770
But the first time that you do
that, you're accessing an

00:19:47.770 --> 00:19:50.150
empty array.

00:19:50.150 --> 00:19:53.960
And when you do that, the
JavaScript spec says, that's

00:19:53.960 --> 00:19:55.480
an undefined value.

00:19:55.480 --> 00:19:56.270
But that's OK.

00:19:56.270 --> 00:19:57.410
It can be converted to zero.

00:19:57.410 --> 00:19:59.640
And it's exactly what
it does here.

00:19:59.640 --> 00:20:01.660
It converts that zero to do the
or equals and then stores

00:20:01.660 --> 00:20:01.940
it back in.

00:20:01.940 --> 00:20:04.990
But that process of conversion
means that this operation has

00:20:04.990 --> 00:20:05.740
to do more checking.

00:20:05.740 --> 00:20:07.300
And it's more expensive.

00:20:07.300 --> 00:20:10.030
And by simply initializing the
value before you use it--

00:20:10.030 --> 00:20:12.200
that's the second
example here--

00:20:12.200 --> 00:20:14.020
you can make your code,
in this case,

00:20:14.020 --> 00:20:15.270
about twice as fast.

00:20:18.100 --> 00:20:20.200
So what about arrays
of doubles?

00:20:20.200 --> 00:20:22.350
Remember I talked about tagging,
that we have to wrap

00:20:22.350 --> 00:20:26.100
double numbers inside
of special objects.

00:20:26.100 --> 00:20:27.480
So if you have an array of them,
doesn't that make it

00:20:27.480 --> 00:20:29.880
expensive because each element
has to have this wrapper

00:20:29.880 --> 00:20:32.230
object to store the
double value.

00:20:32.230 --> 00:20:35.480
Well, there's a trick that we
can use there too as well.

00:20:35.480 --> 00:20:39.520
So we have a mechanism
called unboxing.

00:20:39.520 --> 00:20:44.450
When you unbox a double, you
take the 64-bit IEEE number

00:20:44.450 --> 00:20:46.200
inside of this double object.

00:20:46.200 --> 00:20:47.100
And you take it out.

00:20:47.100 --> 00:20:49.650
And you put it into
a linear buffer.

00:20:49.650 --> 00:20:54.740
So what we can do is track in
the hidden class of an array

00:20:54.740 --> 00:20:56.720
the types of elements that are
contained in the array.

00:20:56.720 --> 00:20:59.620
And if the array contains
only double

00:20:59.620 --> 00:21:02.075
values, it becomes unboxed.

00:21:02.075 --> 00:21:04.550
And what that means is that it
takes all of those numbers out

00:21:04.550 --> 00:21:07.800
of the heap objects, out of the
wrapper objects, and lays

00:21:07.800 --> 00:21:10.900
them out in a linear
buffer of doubles.

00:21:10.900 --> 00:21:12.900
But again, it's only if there
are double numbers

00:21:12.900 --> 00:21:15.720
inside of the array.

00:21:15.720 --> 00:21:18.290
This causes the hidden
class change.

00:21:18.290 --> 00:21:20.970
Generally, that's good because
if you convert the double

00:21:20.970 --> 00:21:22.470
numbers into a flat buffer--

00:21:22.470 --> 00:21:25.090
if you have array of doubles
and it's in a flat

00:21:25.090 --> 00:21:28.150
representation, it's very
efficient to access that.

00:21:28.150 --> 00:21:29.830
And when you store into it,
it doesn't require any

00:21:29.830 --> 00:21:30.950
allocation.

00:21:30.950 --> 00:21:35.280
But you must be aware that
converting between the array

00:21:35.280 --> 00:21:37.650
that's boxed and unboxed
has a cost.

00:21:37.650 --> 00:21:40.490
And it changes the
hidden class.

00:21:40.490 --> 00:21:44.170
And careless manipulation of
arrays can lead to a lot of

00:21:44.170 --> 00:21:46.500
extra work through this
boxing and unboxing.

00:21:46.500 --> 00:21:49.180
I'll give you an example
of that.

00:21:49.180 --> 00:21:52.250
Here's a pretty simple
snippet of code.

00:21:52.250 --> 00:21:53.220
I create a new array.

00:21:53.220 --> 00:21:55.860
And I sign a bunch
of values to the

00:21:55.860 --> 00:21:57.920
first couple of elements.

00:21:57.920 --> 00:22:00.730
Looks like there's not a whole
lot of work to do here.

00:22:00.730 --> 00:22:04.060
But because I create an empty
array, the initial

00:22:04.060 --> 00:22:05.490
object that I have--

00:22:05.490 --> 00:22:06.490
you'll see--

00:22:06.490 --> 00:22:07.890
doesn't actually have
any elements at all

00:22:07.890 --> 00:22:09.680
because it's empty.

00:22:09.680 --> 00:22:13.820
So the hidden class says,
hey, I'm an array.

00:22:13.820 --> 00:22:18.530
And I'm optimistically going
to assume it contains smi

00:22:18.530 --> 00:22:23.690
values and that I'm not going to
have any deletes, no holes.

00:22:23.690 --> 00:22:25.050
We can do that because
the arrays empty.

00:22:25.050 --> 00:22:27.210
So it's actually a
true statement.

00:22:27.210 --> 00:22:29.970
It only has smis because
it has nothing in it.

00:22:29.970 --> 00:22:33.230
What happens when we assigned
the first element of the

00:22:33.230 --> 00:22:36.190
array, because we didn't have
a backing store for the

00:22:36.190 --> 00:22:39.130
elements yet, we have
to allocate it.

00:22:39.130 --> 00:22:42.910
And by default, we allocate
a buffer that has

00:22:42.910 --> 00:22:45.420
room for four elements.

00:22:45.420 --> 00:22:47.870
Now that the backing store is
actually there, we can store

00:22:47.870 --> 00:22:48.920
the first element in here.

00:22:48.920 --> 00:22:51.520
And, again, this is stored as a
smi, as one of these compact

00:22:51.520 --> 00:22:54.860
31-bit signed integers.

00:22:54.860 --> 00:22:57.840
And now that we have space, we
can also assign the second

00:22:57.840 --> 00:23:00.360
element, also not a problem.

00:23:00.360 --> 00:23:05.440
However, the next assignment
assigns a double value.

00:23:05.440 --> 00:23:10.450
And what this does is forces
V8 to convert the format of

00:23:10.450 --> 00:23:15.530
the backing store, because we
can't store a double value

00:23:15.530 --> 00:23:16.750
directly into the array.

00:23:16.750 --> 00:23:18.610
But what we could do is we could
convert the existing

00:23:18.610 --> 00:23:20.500
integer values to doubles.

00:23:20.500 --> 00:23:24.060
And then, with the unboxed
version of this array, we

00:23:24.060 --> 00:23:26.080
could store the 0.5 value.

00:23:26.080 --> 00:23:27.510
And that's exactly
what V8 does.

00:23:27.510 --> 00:23:28.960
It reallocates a new buffer.

00:23:28.960 --> 00:23:32.970
This time each of the elements
slots is 64 bits.

00:23:32.970 --> 00:23:36.640
It converts the existing small
integers into double values.

00:23:36.640 --> 00:23:43.800
And then it assigns the 0.5
to the third element.

00:23:43.800 --> 00:23:45.670
You'll also notice that a hidden
class change happened

00:23:45.670 --> 00:23:48.810
here, because what we did
is added a double value.

00:23:48.810 --> 00:23:52.580
So it's no longer true that
the array only has smis.

00:23:52.580 --> 00:23:54.600
We now have doubles in there.

00:23:54.600 --> 00:23:56.615
That means that the hidden
class has to be changed.

00:23:56.615 --> 00:23:59.450
It causes a hidden
class change.

00:23:59.450 --> 00:24:02.760
Something similar happens when
we try to assign true.

00:24:02.760 --> 00:24:05.490
So true, there are certain
objects in JavaScript which

00:24:05.490 --> 00:24:07.130
are kind of oddballs.

00:24:07.130 --> 00:24:08.740
We actually call
them oddballs.

00:24:08.740 --> 00:24:12.960
True, undefined, null, they
are not really objects.

00:24:12.960 --> 00:24:14.240
But they kind of act
like objects.

00:24:14.240 --> 00:24:15.490
But they're certainly
not numbers.

00:24:15.490 --> 00:24:18.560
So when I assign true to the
third element or the fourth

00:24:18.560 --> 00:24:22.160
element here, it causes another
allocation because we

00:24:22.160 --> 00:24:26.890
can no longer represent this
new value in this unboxed

00:24:26.890 --> 00:24:27.420
double array.

00:24:27.420 --> 00:24:30.720
So we have to convert it back
into its tagged format, which

00:24:30.720 --> 00:24:34.650
means converting the elements
that can be represented as

00:24:34.650 --> 00:24:36.090
smis back into smis.

00:24:36.090 --> 00:24:39.370
It means reboxing the
double value.

00:24:39.370 --> 00:24:41.900
And now we have a backing store
that we can actually

00:24:41.900 --> 00:24:43.560
store the true value in.

00:24:46.060 --> 00:24:47.440
That's a lot of work.

00:24:47.440 --> 00:24:48.430
This is a very short
piece of code.

00:24:48.430 --> 00:24:55.360
But we did four allocations,
two array, two hidden class

00:24:55.360 --> 00:24:58.150
changes for just a couple
lines of code.

00:24:58.150 --> 00:25:00.250
There is a better way.

00:25:00.250 --> 00:25:05.130
If you use an array literal,
this is a hint to V8 upfront

00:25:05.130 --> 00:25:08.630
what the values are going to
be inside of the array.

00:25:08.630 --> 00:25:11.170
And given this example here, we
have a single allocation.

00:25:11.170 --> 00:25:13.490
All of this can be done
in one allocation.

00:25:13.490 --> 00:25:17.980
The correct backing store format
can be selected at

00:25:17.980 --> 00:25:19.300
compile time.

00:25:19.300 --> 00:25:22.030
And we don't have all of these
conversions in the

00:25:22.030 --> 00:25:23.280
initialization of the array.

00:25:25.670 --> 00:25:27.960
So touched on this already.

00:25:27.960 --> 00:25:30.690
Speed trap, make sure, wherever
possible, you

00:25:30.690 --> 00:25:34.890
initialize arrays with array
literals, especially for fixed

00:25:34.890 --> 00:25:38.180
size, small arrays.

00:25:38.180 --> 00:25:42.910
Also for small arrays, make
sure to preallocate them

00:25:42.910 --> 00:25:44.580
before you use them.

00:25:44.580 --> 00:25:46.150
Now, again, this is different
than large arrays.

00:25:46.150 --> 00:25:49.590
Large arrays, remember, more
than 65,000 elements, you want

00:25:49.590 --> 00:25:51.840
to make sure you grow as you go
so that you don't go into

00:25:51.840 --> 00:25:52.450
dictionary mode.

00:25:52.450 --> 00:25:56.390
For small arrays, even if
they're not completely filled,

00:25:56.390 --> 00:25:59.930
even if they're small, if
they're sparse, if they're

00:25:59.930 --> 00:26:04.650
small, V8 will use fast
elements for them.

00:26:04.650 --> 00:26:08.710
But only if you allocate the
correct size will you be able

00:26:08.710 --> 00:26:12.020
to avoid allocations when you
go from an empty array and

00:26:12.020 --> 00:26:15.410
store the first element
into it.

00:26:15.410 --> 00:26:18.380
Don't store non-numeric values
in numeric arrays.

00:26:18.380 --> 00:26:22.600
So if you have an array of
double values, V8 can generate

00:26:22.600 --> 00:26:25.370
very good code for manipulating
those values, for

00:26:25.370 --> 00:26:26.150
those double values.

00:26:26.150 --> 00:26:28.840
But if you put an object into
the array, we have to box

00:26:28.840 --> 00:26:29.500
everything again.

00:26:29.500 --> 00:26:34.660
And the code that we generate
is a lot less efficient.

00:26:34.660 --> 00:26:37.540
OK, we've talked about hidden
classes and how they are an

00:26:37.540 --> 00:26:39.810
important piece of
optimizing code.

00:26:39.810 --> 00:26:42.810
Let's actually talk about how
we generate code in V8.

00:26:42.810 --> 00:26:44.380
And this will maybe help you
understand a little bit better

00:26:44.380 --> 00:26:47.060
why it's important to make sure
that you understand the

00:26:47.060 --> 00:26:48.490
hidden classes.

00:26:48.490 --> 00:26:50.130
So a V8 has two compilers.

00:26:50.130 --> 00:26:52.300
The first one is called the full
compiler, because it can

00:26:52.300 --> 00:26:56.810
actually implement the full set
of JavaScript features.

00:26:56.810 --> 00:27:00.430
It generates good code
but not great code.

00:27:00.430 --> 00:27:01.870
There's an optimizing compiler,
which I'll talk

00:27:01.870 --> 00:27:05.500
about later, which produces much
better code for most of

00:27:05.500 --> 00:27:06.750
the language.

00:27:08.380 --> 00:27:12.280
The goal of the full compiler
is to generate code quickly.

00:27:12.280 --> 00:27:14.830
I talked about before the fact
that any time you spend

00:27:14.830 --> 00:27:20.270
compiling code is added to
your execution time.

00:27:20.270 --> 00:27:23.610
So the full compiler strategy
is to get executing code as

00:27:23.610 --> 00:27:24.480
quickly as possible.

00:27:24.480 --> 00:27:27.430
It generates code that
is just good enough.

00:27:27.430 --> 00:27:30.230
But because of that,
it basically

00:27:30.230 --> 00:27:31.600
doesn't do any type analysis.

00:27:31.600 --> 00:27:34.430
It doesn't know anything
about types.

00:27:34.430 --> 00:27:39.200
And the way that it solves the
problem of implementing

00:27:39.200 --> 00:27:41.630
operations on different types
efficiently is a technique

00:27:41.630 --> 00:27:44.640
called inline caching
or inline caches.

00:27:44.640 --> 00:27:48.270
And what inline caches do is
they gather type information

00:27:48.270 --> 00:27:49.460
and run time.

00:27:49.460 --> 00:27:51.030
And they optimize the
code as you go.

00:27:51.030 --> 00:27:54.220
So you pay as you go.

00:27:54.220 --> 00:27:57.540
And here's the way inline
caches work.

00:27:57.540 --> 00:28:02.110
An inline cache, or an IC, is
a type-dependent small chunk

00:28:02.110 --> 00:28:05.850
of code that knows how to do
an operation given specific

00:28:05.850 --> 00:28:07.130
hidden class--

00:28:07.130 --> 00:28:09.840
inputs of a particular
hidden class.

00:28:09.840 --> 00:28:12.760
And what they do is they
validate the type assumptions.

00:28:12.760 --> 00:28:14.530
They get a couple
arguments in.

00:28:14.530 --> 00:28:15.750
They check to see if the hidden

00:28:15.750 --> 00:28:17.590
classes are as they expect.

00:28:17.590 --> 00:28:19.690
And if they are, then they know
that the code that is in

00:28:19.690 --> 00:28:22.950
the IC is the optimal code for
implementing that operation.

00:28:22.950 --> 00:28:25.160
If not, something
has to happen.

00:28:25.160 --> 00:28:27.620
A new IC has to be generated
that can handle the new type

00:28:27.620 --> 00:28:29.780
information.

00:28:29.780 --> 00:28:33.460
And at runtime, if different
types are seen than what are

00:28:33.460 --> 00:28:37.970
expected, then through
backpatching the code is

00:28:37.970 --> 00:28:41.290
changed to use new specialized
code for the new

00:28:41.290 --> 00:28:42.380
types that are seen.

00:28:42.380 --> 00:28:45.200
I'll give you an example
of how that works.

00:28:45.200 --> 00:28:49.330
Here's a fragment from the code
example at the beginning,

00:28:49.330 --> 00:28:50.420
a prime number generator.

00:28:50.420 --> 00:28:53.620
I'd like to take a particular
fragment of code there, which

00:28:53.620 --> 00:28:58.510
takes an element from the
prime's array and checks

00:28:58.510 --> 00:29:01.700
whether the candidate number is
divisible by that number.

00:29:01.700 --> 00:29:03.800
And let's see what the
full code generator

00:29:03.800 --> 00:29:04.850
does with this code.

00:29:04.850 --> 00:29:05.920
Don't sweat the details.

00:29:05.920 --> 00:29:07.760
I'm going to show some assembly
language here.

00:29:07.760 --> 00:29:10.370
And it's not actually
important what

00:29:10.370 --> 00:29:11.480
the details are here.

00:29:11.480 --> 00:29:14.460
But I want to show the pattern
of what actually goes on here.

00:29:14.460 --> 00:29:17.480
So each expression generates a
little chunk of code here.

00:29:17.480 --> 00:29:19.680
You'll see that there's some
preparation code and then

00:29:19.680 --> 00:29:25.870
there's a call out, a call to an
IC to actually do the work.

00:29:25.870 --> 00:29:29.340
Likewise, for the array element
access, there is some

00:29:29.340 --> 00:29:32.540
preparation work and then a call
out to the IC to do the

00:29:32.540 --> 00:29:35.630
work, and for the [INAUDIBLE]
the same thing.

00:29:35.630 --> 00:29:39.230
And the thing to notice here is
that, initially, the call

00:29:39.230 --> 00:29:43.380
is to this initialize version
of the IC, because we don't

00:29:43.380 --> 00:29:44.760
know what the types
are going to be.

00:29:44.760 --> 00:29:47.940
We'll only know that
at run time.

00:29:47.940 --> 00:29:49.410
And this is how it works
at run time.

00:29:49.410 --> 00:29:52.100
The code on the left here is a
small, almost impossible to

00:29:52.100 --> 00:29:54.470
read version of the code
I just showed you.

00:29:54.470 --> 00:29:58.240
And when we're executing this
code for the first time, and

00:29:58.240 --> 00:30:02.920
we get to this IC, the first
IC, it calls an internal

00:30:02.920 --> 00:30:04.580
routine that initializes
the IC.

00:30:04.580 --> 00:30:06.790
It looks at what the arguments
are to that operation the

00:30:06.790 --> 00:30:07.250
first time.

00:30:07.250 --> 00:30:09.050
It checks the hidden classes.

00:30:09.050 --> 00:30:10.670
And it says, oh, I know
how to do that.

00:30:10.670 --> 00:30:13.200
I can generate specialized
code for that.

00:30:13.200 --> 00:30:15.190
It does so.

00:30:15.190 --> 00:30:18.480
And it backpatches the address
so that the next time you come

00:30:18.480 --> 00:30:20.070
to the code, it does the
same thing again.

00:30:20.070 --> 00:30:23.330
Assuming that the next time you
run, you're going to have

00:30:23.330 --> 00:30:25.580
the same hidden classes, the
same types of objects, which

00:30:25.580 --> 00:30:28.320
is an optimistic but usually
valid assumption.

00:30:28.320 --> 00:30:32.740
It does the same thing for the
access of the array element

00:30:32.740 --> 00:30:35.990
and for the [? lot ?]
operation.

00:30:35.990 --> 00:30:39.880
And you'll see that each of
the ICs, all they are is

00:30:39.880 --> 00:30:44.640
specialized code that know how
to do the specific operation

00:30:44.640 --> 00:30:47.820
for a given set of object
types that are input.

00:30:51.690 --> 00:30:53.470
This makes a big difference
in performance.

00:30:53.470 --> 00:30:56.200
And this is why you need to
understand how some of this

00:30:56.200 --> 00:30:58.550
stuff works with hidden classes,
because if you get it

00:30:58.550 --> 00:31:01.750
wrong, you don't actually get
the performance improvement

00:31:01.750 --> 00:31:04.830
that you will see or should see
when using ICs and then,

00:31:04.830 --> 00:31:06.480
later, the optimizing
compiler.

00:31:06.480 --> 00:31:08.790
So if you're running the sample
code that I showed at

00:31:08.790 --> 00:31:13.000
the beginning to generate primes
without ICs, you get an

00:31:13.000 --> 00:31:15.710
execution time that's
over 600 seconds.

00:31:15.710 --> 00:31:18.220
When you turn ICs on--

00:31:18.220 --> 00:31:20.030
don't have the optimizing
compiler on yet--

00:31:20.030 --> 00:31:22.070
it makes a big difference.

00:31:22.070 --> 00:31:26.295
So this is about a 20 times
speed improvement.

00:31:29.480 --> 00:31:31.700
Now I'd like to introduce a
concept that we'll also come

00:31:31.700 --> 00:31:32.590
back to later.

00:31:32.590 --> 00:31:33.865
Monomorphic better
than polymorphic.

00:31:33.865 --> 00:31:35.360
It sounds pretty complicated.

00:31:35.360 --> 00:31:38.040
It isn't really.

00:31:38.040 --> 00:31:41.790
Monomorphic operations are
operations that always work on

00:31:41.790 --> 00:31:45.800
objects with the same
hidden classes.

00:31:45.800 --> 00:31:49.900
So the first time you execute an
IC, we look at the argument

00:31:49.900 --> 00:31:51.000
types for the operation.

00:31:51.000 --> 00:31:52.230
We look at the hidden classes.

00:31:52.230 --> 00:31:53.900
And we remember them.

00:31:53.900 --> 00:31:55.770
And if the next time, through
those hidden classes, are the

00:31:55.770 --> 00:31:58.020
same, it's monomorphic.

00:31:58.020 --> 00:32:01.090
And if the next time they're
the same, it's still

00:32:01.090 --> 00:32:01.530
monomorphic.

00:32:01.530 --> 00:32:03.200
And it stays that way.

00:32:03.200 --> 00:32:06.300
If at any time we see different
hidden classes for

00:32:06.300 --> 00:32:10.880
the arguments to an operation
then it becomes polymorphic.

00:32:10.880 --> 00:32:13.470
And it turns out that
monomorphic operations are

00:32:13.470 --> 00:32:14.135
easier to optimize.

00:32:14.135 --> 00:32:16.860
Or the code that we generate is
better than for polymorphic

00:32:16.860 --> 00:32:18.220
operations.

00:32:18.220 --> 00:32:21.020
So here's an example.

00:32:21.020 --> 00:32:25.260
Let's say we have a function
add that adds two things.

00:32:25.260 --> 00:32:29.480
And if I call that with two
integer arguments, it's

00:32:29.480 --> 00:32:31.150
monomorphic.

00:32:31.150 --> 00:32:34.680
However, if I call it again with
two string arguments, I

00:32:34.680 --> 00:32:36.870
use the same operation--
this plus operation--

00:32:36.870 --> 00:32:39.950
to work both on integers
and on strings.

00:32:39.950 --> 00:32:41.790
And at that moment, it
becomes polymorphic.

00:32:41.790 --> 00:32:45.180
And it becomes more difficult
for V8 to generate good,

00:32:45.180 --> 00:32:47.710
really efficient code for
that plus operation.

00:32:47.710 --> 00:32:51.820
So the speed trap to avoid here
is, wherever possible,

00:32:51.820 --> 00:32:59.420
don't try to mix operations or
objects of different types in

00:32:59.420 --> 00:33:01.470
operations at a particular
place in your code.

00:33:01.470 --> 00:33:04.540
Prefer monomorphic code
to polymorphic code

00:33:04.540 --> 00:33:05.790
wherever you can.

00:33:09.240 --> 00:33:12.030
I'd like to talk about the
optimizing compiler.

00:33:12.030 --> 00:33:14.080
We talked about the full
compiler, generates pretty

00:33:14.080 --> 00:33:17.070
good code, gets executing
as fast as possible.

00:33:17.070 --> 00:33:20.420
The optimizing compiler comes
back later for the code that's

00:33:20.420 --> 00:33:22.885
really hot and recompiles
the hot functions.

00:33:26.720 --> 00:33:27.570
Why does it do this?

00:33:27.570 --> 00:33:30.850
Well, we've gathered information
about the types of

00:33:30.850 --> 00:33:35.560
the objects that we're operating
on through the ICs.

00:33:35.560 --> 00:33:38.920
And the optimizing compiler can
take that information and

00:33:38.920 --> 00:33:42.820
make decisions about how to
optimize the code better.

00:33:42.820 --> 00:33:45.350
What happens is the optimizing
compiler takes that type

00:33:45.350 --> 00:33:46.900
information from the ICs.

00:33:46.900 --> 00:33:50.470
And it speculatively inlines a
version of the operation based

00:33:50.470 --> 00:33:54.940
on history, what it's seen
before in the ICs.

00:33:54.940 --> 00:33:59.600
And it also means that it can
inline function calls that are

00:33:59.600 --> 00:34:00.600
monomorphic.

00:34:00.600 --> 00:34:01.760
This includes constructors.

00:34:01.760 --> 00:34:06.050
This is actually a new feature
that we've added recently.

00:34:09.620 --> 00:34:13.670
By enabling inlining, by
inlining this operation in the

00:34:13.670 --> 00:34:16.230
optimize code, other
optimizations become possible.

00:34:16.230 --> 00:34:18.320
And that's what the optimizing
compiler will actually do.

00:34:18.320 --> 00:34:21.590
We'll go over this inline code
and find more opportunities to

00:34:21.590 --> 00:34:23.810
make it faster.

00:34:23.810 --> 00:34:24.650
Let's see how that works.

00:34:24.650 --> 00:34:27.820
Again, a warning, here's
assembly code.

00:34:27.820 --> 00:34:32.739
It's a very similar process to
the full code generator.

00:34:32.739 --> 00:34:35.000
We generate a little piece
of code for each of the

00:34:35.000 --> 00:34:35.909
expressions.

00:34:35.909 --> 00:34:39.280
But this time, you'll notice,
as we generate each piece of

00:34:39.280 --> 00:34:41.590
code, there's no call
at the end.

00:34:41.590 --> 00:34:44.449
And in fact, when we're done,
it's straight line code.

00:34:48.850 --> 00:34:52.566
So let's compare the performance
using the

00:34:52.566 --> 00:34:57.070
optimizing compiler with the two
runs that we did before.

00:34:57.070 --> 00:34:59.250
You'll see that with the
optimizing compiler, we're

00:34:59.250 --> 00:35:01.350
even fast-- we're about
50 times faster than

00:35:01.350 --> 00:35:02.600
the original code.

00:35:04.850 --> 00:35:07.730
One thing that's really useful
is actually to find out which

00:35:07.730 --> 00:35:10.210
functions are being
optimized by the

00:35:10.210 --> 00:35:13.460
optimizing compiler in V8.

00:35:13.460 --> 00:35:16.090
So there's an option you can
pass to the DHL that

00:35:16.090 --> 00:35:16.860
will do just that.

00:35:16.860 --> 00:35:19.050
It'll output the information
about which

00:35:19.050 --> 00:35:20.300
functions get optimized.

00:35:23.460 --> 00:35:25.920
However, there are certain
circumstances in which the

00:35:25.920 --> 00:35:29.070
optimizing compiler can't
optimize a function.

00:35:29.070 --> 00:35:30.940
This is called bailing out.

00:35:30.940 --> 00:35:33.100
Or that's what we call
it, bailing out.

00:35:33.100 --> 00:35:35.100
And the reason is there are
certain language features that

00:35:35.100 --> 00:35:39.790
are just not supported yet by
the optimizing compiler.

00:35:39.790 --> 00:35:43.380
The most obvious example
is try catch.

00:35:43.380 --> 00:35:45.810
So if you have a function that
contains a try catch block,

00:35:45.810 --> 00:35:49.830
the optimizing compiler, right
now, can't optimize that.

00:35:49.830 --> 00:35:51.590
We hope to change that
in the future.

00:35:51.590 --> 00:35:54.980
But until then, there's
a work around.

00:35:54.980 --> 00:35:57.490
If you have performance
sensitive code that you'd like

00:35:57.490 --> 00:36:01.130
to access from try
catch block, wrap

00:36:01.130 --> 00:36:02.670
it in its own function.

00:36:02.670 --> 00:36:03.370
Here's an example.

00:36:03.370 --> 00:36:05.850
We have a function that's
performance sensitive.

00:36:05.850 --> 00:36:09.060
We call that from the try piece
of a try catch block in

00:36:09.060 --> 00:36:11.670
another function.

00:36:11.670 --> 00:36:15.230
And by doing that, it allows
the optimizing compiler to

00:36:15.230 --> 00:36:18.020
optimize the performance
sensitive function, even

00:36:18.020 --> 00:36:20.722
though it can't optimize
the try catch block.

00:36:23.320 --> 00:36:26.830
If you want to find out which
routines cannot be optimized

00:36:26.830 --> 00:36:29.790
by the optimizing compiler and
why, there's an option you can

00:36:29.790 --> 00:36:32.570
pass through the debugging shell
called trace bailout.

00:36:32.570 --> 00:36:37.950
And that'll actually tell you
the functions that could not

00:36:37.950 --> 00:36:39.200
be compiled and why.

00:36:41.500 --> 00:36:45.110
The last thing I'd like to talk
about is deoptimization.

00:36:45.110 --> 00:36:48.100
So the optimizing compiler
is pretty good

00:36:48.100 --> 00:36:50.180
at generating code.

00:36:50.180 --> 00:36:51.690
But there's a catch.

00:36:51.690 --> 00:36:54.890
The optimizations that it
does are speculative.

00:36:54.890 --> 00:36:57.910
It makes the optimistic
assumption that what it has

00:36:57.910 --> 00:37:01.630
seen in the past is going to be
just like what it's going

00:37:01.630 --> 00:37:04.140
to see in the future.

00:37:04.140 --> 00:37:07.170
And that usually pays off,
because usually your code

00:37:07.170 --> 00:37:09.730
keeps running like
it has before.

00:37:09.730 --> 00:37:13.820
However, as with all optimistic
assumptions, that

00:37:13.820 --> 00:37:14.700
may not be the case.

00:37:14.700 --> 00:37:18.310
So when you're driving down the
Autobahn in Germany and

00:37:18.310 --> 00:37:21.680
you're doing 200 kilometers an
hour, sometimes you're working

00:37:21.680 --> 00:37:24.690
under the optimistic assumption
that you're not

00:37:24.690 --> 00:37:26.920
going to be caught going
over the speed limit.

00:37:26.920 --> 00:37:29.000
Remember, I told you there are
some stretches of the Autobahn

00:37:29.000 --> 00:37:30.340
with a speed limit.

00:37:30.340 --> 00:37:32.380
And you'll see out of the corner
of your eye, a red

00:37:32.380 --> 00:37:36.370
flash from two of these things
on the side of the road.

00:37:36.370 --> 00:37:38.590
And you've just been caught in
a speed trap, because your

00:37:38.590 --> 00:37:41.550
optimistic assumption that you
were not going to be caught

00:37:41.550 --> 00:37:43.650
speeding was wrong.

00:37:43.650 --> 00:37:44.080
And what do you do?

00:37:44.080 --> 00:37:45.050
You slam on the brakes.

00:37:45.050 --> 00:37:46.660
You slow down to the
speed limit.

00:37:46.660 --> 00:37:50.055
And you probably drive that
way for a while, slower.

00:37:52.620 --> 00:37:54.270
There's a similar process
that happens in

00:37:54.270 --> 00:37:56.480
optimized code in V8.

00:37:56.480 --> 00:37:59.440
Invalid assumptions lead
to deoptimization.

00:37:59.440 --> 00:38:01.410
When one of the assumptions is
no longer true, when one of

00:38:01.410 --> 00:38:03.990
the hidden classes that you
get for an argument to an

00:38:03.990 --> 00:38:07.470
operation is not what you
expected, then the specialized

00:38:07.470 --> 00:38:09.540
code we generated is
no longer valid.

00:38:09.540 --> 00:38:10.720
And we have to deoptimize.

00:38:10.720 --> 00:38:11.750
What does that mean?

00:38:11.750 --> 00:38:14.170
That means we throw way the
optimize code, because we know

00:38:14.170 --> 00:38:16.630
the assumptions we made are just
simply no longer valid.

00:38:16.630 --> 00:38:19.660
We resume execution in the
right place in the full

00:38:19.660 --> 00:38:21.450
compiler code.

00:38:21.450 --> 00:38:23.260
So we can continue
our execution.

00:38:23.260 --> 00:38:25.740
But now it's at a slower speed,
because we're using the

00:38:25.740 --> 00:38:28.650
version of code that is
good, but not great.

00:38:28.650 --> 00:38:32.600
And a reoptimization of the
function might happen later,

00:38:32.600 --> 00:38:34.920
because we're going to continue
to gather type

00:38:34.920 --> 00:38:39.160
information in the ICs in
the full compiler code.

00:38:39.160 --> 00:38:42.150
But for the short term, you're
going to run more slowly.

00:38:42.150 --> 00:38:45.770
And what that means is that
deoptimization is something

00:38:45.770 --> 00:38:46.530
you want to avoid.

00:38:46.530 --> 00:38:49.210
And one way to do that is to
make sure that you don't

00:38:49.210 --> 00:38:52.910
introduce hidden class changes
at a late time

00:38:52.910 --> 00:38:53.850
running your code.

00:38:53.850 --> 00:38:57.740
If you have types, object types
that you run in optimize

00:38:57.740 --> 00:39:01.420
code, and V8 chooses to optimize
that code, and then

00:39:01.420 --> 00:39:04.720
you later introduce new types,
that optimize code will

00:39:04.720 --> 00:39:05.590
deoptimize.

00:39:05.590 --> 00:39:08.860
And if you do that too
often, it has a cost.

00:39:08.860 --> 00:39:13.090
You can tell the debugging shell
to output the routines,

00:39:13.090 --> 00:39:15.470
the functions that it optimizes
on by passing the

00:39:15.470 --> 00:39:18.340
trace deopt option to
the debug shell.

00:39:18.340 --> 00:39:21.560
And it'll output which one it
deoptimized on and why.

00:39:24.110 --> 00:39:28.400
Now most of you are doing web
development, I assume.

00:39:28.400 --> 00:39:31.770
And therefore, you probably
want to be able to look at

00:39:31.770 --> 00:39:35.290
your code in Chrome, as well
as directly in the DHL.

00:39:35.290 --> 00:39:40.190
You can pass these options
that I've mentioned also

00:39:40.190 --> 00:39:43.090
directly to Chrome using
the js flags option.

00:39:43.090 --> 00:39:47.460
And the output will all show
up in standard out when

00:39:47.460 --> 00:39:49.080
running Chrome.

00:39:49.080 --> 00:39:51.315
OK, so that was the
be prepared part.

00:39:51.315 --> 00:39:56.150
You now understand a little
bit about how V8 works.

00:39:56.150 --> 00:39:58.630
Let's talk now about identifying
and understanding

00:39:58.630 --> 00:40:00.710
problems using that knowledge.

00:40:00.710 --> 00:40:02.020
What does that mean for V8?

00:40:02.020 --> 00:40:04.020
First of all, ensure the problem
that you're looking at

00:40:04.020 --> 00:40:05.680
is a JavaScript problem.

00:40:05.680 --> 00:40:08.160
And this is sometimes
a little bit tricky.

00:40:08.160 --> 00:40:11.910
You could use the dev tools in
Chrome to figure out where

00:40:11.910 --> 00:40:14.000
you're spending time in
your web application.

00:40:14.000 --> 00:40:15.170
It may look like JavaScript.

00:40:15.170 --> 00:40:17.740
But be careful it might be the
case that there's also DOM

00:40:17.740 --> 00:40:18.940
interaction.

00:40:18.940 --> 00:40:22.320
So a really good way to do that
is, if you can take that

00:40:22.320 --> 00:40:24.920
code that you think is the
performance bottleneck, pull

00:40:24.920 --> 00:40:27.720
it out, and run it in the DHL,
that means it's pure

00:40:27.720 --> 00:40:28.250
JavaScript.

00:40:28.250 --> 00:40:32.090
Because the V8 project is just
JavaScript, it doesn't have--

00:40:32.090 --> 00:40:32.990
it's integrated into Chrome.

00:40:32.990 --> 00:40:36.230
But it, in itself, is just
the JavaScript execution

00:40:36.230 --> 00:40:37.080
environment.

00:40:37.080 --> 00:40:40.330
So if you can take that code and
run it with the DHL, then

00:40:40.330 --> 00:40:41.140
you're pretty--

00:40:41.140 --> 00:40:43.130
then you can analyze the
problems of JavaScript only

00:40:43.130 --> 00:40:45.600
performance problem.

00:40:45.600 --> 00:40:48.710
Collect metrics, measure
where you're spending

00:40:48.710 --> 00:40:50.760
your time in the code.

00:40:50.760 --> 00:40:54.780
And then locate the bottlenecks
and fix them.

00:40:54.780 --> 00:40:57.770
So remember the example that we
had at the beginning, the

00:40:57.770 --> 00:41:00.140
prime number generator.

00:41:00.140 --> 00:41:03.820
If you run it in the shell and
pass an additional argument,

00:41:03.820 --> 00:41:10.190
the dash dash prof argument, it
will run the program while

00:41:10.190 --> 00:41:13.560
also sampling the execution
profile.

00:41:13.560 --> 00:41:16.140
And it'll write a log that you
can then analyze with another

00:41:16.140 --> 00:41:19.160
tool to see where you're
spending your time.

00:41:19.160 --> 00:41:21.520
Before we look at that output,
where we're spending the time,

00:41:21.520 --> 00:41:24.750
I'd like to go over briefly
again where we're spending the

00:41:24.750 --> 00:41:26.530
time-- or what we're doing
in the program.

00:41:26.530 --> 00:41:28.210
There's a couple important
functions here

00:41:28.210 --> 00:41:29.020
in the prime generator.

00:41:29.020 --> 00:41:31.250
First, we add a prime.

00:41:31.250 --> 00:41:33.950
There's a function to add a
prime to the existing list.

00:41:33.950 --> 00:41:35.360
There's a function that
actually tests whether

00:41:35.360 --> 00:41:40.090
candidate number is divisible or
is divisible by one of the

00:41:40.090 --> 00:41:41.550
existing primes.

00:41:41.550 --> 00:41:44.180
And then there's the main
routine, which does the high

00:41:44.180 --> 00:41:45.480
level algorithm.

00:41:45.480 --> 00:41:48.240
It starts at one, goes up,
checks that number, whether

00:41:48.240 --> 00:41:50.570
it's divisible by an
existing prime.

00:41:50.570 --> 00:41:53.060
If not, it adds it to the prime
list, otherwise it goes

00:41:53.060 --> 00:41:54.030
to the next number.

00:41:54.030 --> 00:41:56.010
So what's our expectation?

00:41:56.010 --> 00:41:57.460
The prediction is that we're
going to spend most of the

00:41:57.460 --> 00:41:58.330
time in main.

00:41:58.330 --> 00:42:00.720
And the reason for that is all
properties and functions are

00:42:00.720 --> 00:42:02.180
monomorphic.

00:42:02.180 --> 00:42:03.650
I wrote the code
to be that way.

00:42:03.650 --> 00:42:05.540
All numeric operations
are smis.

00:42:05.540 --> 00:42:08.670
We do a pretty good job
at optimizing those.

00:42:08.670 --> 00:42:11.790
All the functions could
be inlined.

00:42:11.790 --> 00:42:13.390
And there are no deoptimizations
or bailouts.

00:42:13.390 --> 00:42:16.390
So my expectation is V8 is going
to do a really good job

00:42:16.390 --> 00:42:17.520
of optimizing this code.

00:42:17.520 --> 00:42:19.910
OK, so let's take a look at the
output and see where we

00:42:19.910 --> 00:42:22.430
were spending our time.

00:42:22.430 --> 00:42:27.040
So this is the output of
the tick processor.

00:42:27.040 --> 00:42:28.600
It takes this output log
that's written with

00:42:28.600 --> 00:42:30.510
performance data.

00:42:30.510 --> 00:42:31.830
And it prints it in
a pretty format.

00:42:31.830 --> 00:42:33.500
You see there's two sections
of the output here.

00:42:33.500 --> 00:42:35.180
I've actually abridged this.

00:42:35.180 --> 00:42:36.290
It's much longer.

00:42:36.290 --> 00:42:38.500
But these are the important
parts for our profile here.

00:42:38.500 --> 00:42:39.510
There's a JavaScript section.

00:42:39.510 --> 00:42:42.160
This is the time we're spending
in generated code.

00:42:42.160 --> 00:42:46.820
This is JavaScript code
executing in either the full

00:42:46.820 --> 00:42:48.740
compiler code or
optimize code.

00:42:48.740 --> 00:42:52.570
And then there's the C++
section, which is--

00:42:52.570 --> 00:42:54.660
it's often the case that you'll
have C++ symbols in the

00:42:54.660 --> 00:42:57.560
profile, because there's some
operations that we can't do in

00:42:57.560 --> 00:42:58.070
generated code.

00:42:58.070 --> 00:42:59.970
So we have to call out.

00:42:59.970 --> 00:43:04.310
And as expected, we spend
a lot of time in main.

00:43:04.310 --> 00:43:05.650
But it's actually about 25%.

00:43:05.650 --> 00:43:06.770
You'll see there's three
columns here.

00:43:06.770 --> 00:43:10.740
You see how many ticks you're
spending in that routine, in

00:43:10.740 --> 00:43:11.815
this function.

00:43:11.815 --> 00:43:14.560
And you'll see what the
percentage is of the overall

00:43:14.560 --> 00:43:16.010
execution time.

00:43:16.010 --> 00:43:17.400
But in this case
it's only 25%.

00:43:17.400 --> 00:43:20.570
That's weird because I
expected a lot more.

00:43:20.570 --> 00:43:22.740
V8 should do a really good
job on this code.

00:43:22.740 --> 00:43:24.720
If you look at the other items
that show up in this profile,

00:43:24.720 --> 00:43:25.410
this is weird.

00:43:25.410 --> 00:43:28.260
We're spending time
doing a binary op

00:43:28.260 --> 00:43:29.990
stub with an oddball.

00:43:29.990 --> 00:43:31.440
An oddball, remember, I told
you those are things like

00:43:31.440 --> 00:43:33.530
true, undefined, and null.

00:43:33.530 --> 00:43:34.220
We don't have that
in our code.

00:43:34.220 --> 00:43:35.540
That's kind of strange.

00:43:35.540 --> 00:43:36.590
And we're spending
a lot of time in

00:43:36.590 --> 00:43:38.400
library code doing modulo.

00:43:38.400 --> 00:43:40.340
And that's kind of strange.

00:43:40.340 --> 00:43:42.020
We should be able to inline
that as well.

00:43:42.020 --> 00:43:42.850
I didn't expect that.

00:43:42.850 --> 00:43:44.100
And then here's another one
that's kind of weird.

00:43:44.100 --> 00:43:46.490
We're doing a conversion
from a number--

00:43:46.490 --> 00:43:47.840
extracting--

00:43:47.840 --> 00:43:50.830
we're taking a number
and boxing it.

00:43:50.830 --> 00:43:55.950
And we really should be
generating very good code for

00:43:55.950 --> 00:43:57.180
this program.

00:43:57.180 --> 00:43:58.740
We're spending way too much time
doing something that's

00:43:58.740 --> 00:44:01.170
not executing the JavaScript.

00:44:01.170 --> 00:44:02.310
We're calling out
to libraries.

00:44:02.310 --> 00:44:05.200
Something is very wrong
with this code.

00:44:05.200 --> 00:44:08.140
So can you spot the bug?

00:44:08.140 --> 00:44:13.140
The hint is, is that our array
is only of length prime count.

00:44:13.140 --> 00:44:17.070
And we've actually exceeded the
end of the array in our

00:44:17.070 --> 00:44:18.030
calculations.

00:44:18.030 --> 00:44:20.770
And in both the C++ and
JavaScript version, it doesn't

00:44:20.770 --> 00:44:22.980
make a difference
in the results.

00:44:22.980 --> 00:44:26.350
And this is the thing that
you've got to watch out for,

00:44:26.350 --> 00:44:29.600
is that even though you don't
see that there's a problem in

00:44:29.600 --> 00:44:31.810
the results, the program's
a lot slower

00:44:31.810 --> 00:44:32.460
than it needs to be.

00:44:32.460 --> 00:44:33.310
So let's fix that.

00:44:33.310 --> 00:44:37.790
Let's actually not do an
out-of-bounds array access.

00:44:37.790 --> 00:44:42.470
And we'll re-run the profile
with the fix.

00:44:42.470 --> 00:44:45.000
And you'll see this time, this
is what we were expecting.

00:44:45.000 --> 00:44:50.450
That small change now makes us
generate much better code

00:44:50.450 --> 00:44:52.960
because we're not accessing
outside of the array, getting

00:44:52.960 --> 00:44:55.490
an undefined object-- this
oddball-- that we're trying to

00:44:55.490 --> 00:44:57.530
do math on.

00:44:57.530 --> 00:45:00.750
And now we're spending over
99% of our time in main.

00:45:00.750 --> 00:45:01.760
This is what we expected.

00:45:01.760 --> 00:45:04.840
So let's see actually how big of
a difference this makes on

00:45:04.840 --> 00:45:05.660
the profile.

00:45:05.660 --> 00:45:09.130
And when we run the code against
the C++ code again,

00:45:09.130 --> 00:45:10.580
look at that.

00:45:10.580 --> 00:45:14.130
C++ code, three seconds,
JavaScript, 1.8 seconds--

00:45:14.130 --> 00:45:18.452
we're 60% faster.

00:45:18.452 --> 00:45:22.520
Well, I forgot to optimize
the C++ code.

00:45:22.520 --> 00:45:26.870
So when you do that, C++
is still faster.

00:45:26.870 --> 00:45:28.960
But it's 17% faster.

00:45:28.960 --> 00:45:31.010
It's ball park.

00:45:31.010 --> 00:45:32.460
I have to take all of this
with a grain of salt.

00:45:32.460 --> 00:45:34.370
I chose an example where
I knew V8 would do a

00:45:34.370 --> 00:45:36.600
pretty darn good job.

00:45:36.600 --> 00:45:41.680
More and more, we're optimizing
more cases that

00:45:41.680 --> 00:45:45.240
makes V8 faster in
more situations.

00:45:45.240 --> 00:45:47.940
So I expect in the future, we'll
get closer and closer.

00:45:47.940 --> 00:45:50.500
But my point here is that
you need to make sure

00:45:50.500 --> 00:45:51.650
to take a look at--

00:45:51.650 --> 00:45:54.140
spend the time optimizing your
code to know where you're

00:45:54.140 --> 00:45:56.480
spending your time, because
you can actually make your

00:45:56.480 --> 00:45:58.850
code very fast.

00:45:58.850 --> 00:46:02.680
So fix what matters.

00:46:02.680 --> 00:46:05.960
We did a lot of time analyzing
our existing profile, tweaking

00:46:05.960 --> 00:46:08.280
it, knowing how V8 works.

00:46:08.280 --> 00:46:10.940
The last thing I'd like to point
out is, make sure you

00:46:10.940 --> 00:46:13.640
don't forget to optimize
your algorithm.

00:46:13.640 --> 00:46:16.710
So I have a new version of the
program here, where instead of

00:46:16.710 --> 00:46:19.790
iterating over all the prime
numbers, I only iterate to the

00:46:19.790 --> 00:46:21.860
square root of the candidate,
which is sufficient to

00:46:21.860 --> 00:46:26.480
actually test for whether it can
be divided by one of the

00:46:26.480 --> 00:46:27.320
prime numbers.

00:46:27.320 --> 00:46:29.995
And if I run that result--

00:46:29.995 --> 00:46:32.150
if I run that in the--

00:46:32.150 --> 00:46:34.537
I time that, then you'll
see that now I'm

00:46:34.537 --> 00:46:38.050
under 5/100 of a second.

00:46:38.050 --> 00:46:39.660
And if we compare that with the
original version, which

00:46:39.660 --> 00:46:45.940
was 15 seconds, that's
350 times speed up.

00:46:45.940 --> 00:46:50.740
So, in summary, keep your
eyes on the road.

00:46:50.740 --> 00:46:51.330
Be prepared.

00:46:51.330 --> 00:46:54.140
Learn a little bit about
how V8 works.

00:46:54.140 --> 00:46:58.170
Identify and understand the
crux of your problem.

00:46:58.170 --> 00:47:00.000
And fix the thing
that matters.

00:47:00.000 --> 00:47:01.640
You don't have a whole lot
of time to do performance

00:47:01.640 --> 00:47:02.520
optimization.

00:47:02.520 --> 00:47:05.880
Make sure that every
minute counts.

00:47:05.880 --> 00:47:07.260
And my friend Michael is fine.

00:47:07.260 --> 00:47:10.660
He had taught me how to tie a
special knot, which freed my

00:47:10.660 --> 00:47:12.530
hands while he was hanging.

00:47:12.530 --> 00:47:16.320
I was able to call on my cell
phone the mountain rescue.

00:47:16.320 --> 00:47:17.950
Michael regained consciousness,
and I could

00:47:17.950 --> 00:47:19.040
lower him down.

00:47:19.040 --> 00:47:21.600
The helicopter came and took
us off the mountain.

00:47:21.600 --> 00:47:26.600
So even though he had a couple
broken ribs, he's fine.

00:47:26.600 --> 00:47:27.400
Thank you.

00:47:27.400 --> 00:47:34.553
[APPLAUSE]

