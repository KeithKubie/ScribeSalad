WEBVTT
Kind: captions
Language: en

00:00:00.107 --> 00:00:01.977
All right.

00:00:01.977 --> 00:00:04.161
So let's get started.

00:00:04.161 --> 00:00:06.990
So we're still talking about
conditional expectation, right?

00:00:06.990 --> 00:00:10.505
And so today we'll finish conditional
expectation as a topic in its own right,

00:00:10.505 --> 00:00:13.759
which of course, doesn't mean you can
then forget it because everything

00:00:13.759 --> 00:00:16.350
in this course is about
thinking conditionally.

00:00:16.350 --> 00:00:20.520
But as its own topic,
we'll finish that today.

00:00:20.520 --> 00:00:23.944
So I wanted to start with just
a couple quick examples of conditional

00:00:23.944 --> 00:00:27.199
expectation where you're
conditioning on a random variable.

00:00:27.199 --> 00:00:29.648
Last time we were talking about
conditioning on an event versus

00:00:29.648 --> 00:00:31.310
conditioning on a random variable.

00:00:31.310 --> 00:00:35.720
So we'll do a couple quick examples,
then derive some properties,

00:00:35.720 --> 00:00:38.270
and then do some more difficult examples.

00:00:38.270 --> 00:00:44.352
But just to start with a couple easy
examples just to help get the notation and

00:00:44.352 --> 00:00:45.882
concepts in mind.

00:00:45.882 --> 00:00:49.496
So, here is a simple example.

00:00:49.496 --> 00:00:54.750
Let's just start with a normal,
x is standard normal.

00:00:55.800 --> 00:01:01.830
And let's let y = x squared, okay?

00:01:01.830 --> 00:01:04.713
And then suppose we want E(Y given X).

00:01:08.842 --> 00:01:10.801
This is just a practice,
you know what does the concept mean?

00:01:10.801 --> 00:01:15.030
E(Y given X) is E(X squared given X).

00:01:15.030 --> 00:01:17.900
This notation means we get
to treat x as known and

00:01:17.900 --> 00:01:21.040
then we try to give our best
prediction for x squared.

00:01:21.040 --> 00:01:25.362
Best is in the sense of
minimizing mean squared error.

00:01:25.362 --> 00:01:27.880
But in a certain sense,
it's the best prediction.

00:01:27.880 --> 00:01:30.562
If we know X, we know X squared, so

00:01:30.562 --> 00:01:35.847
obviously our best prediction would
be X squared, which equals Y.

00:01:35.847 --> 00:01:40.225
Okay, so now that's a very easy
calculation, but if we didn't get X

00:01:40.225 --> 00:01:45.220
squared here, then there's something
very suspicious about this, right?

00:01:45.220 --> 00:01:49.590
We get to know X and somehow predicting
something else doesn't make sense.

00:01:49.590 --> 00:01:51.190
So this should be very very clear.

00:01:52.320 --> 00:01:55.270
Now let's see what would happen
if we went the other way around.

00:01:55.270 --> 00:02:00.890
Same example, but now let's do E(X
given Y) instead of E( Y given X).

00:02:02.340 --> 00:02:04.470
So that's E (X given X squared).

00:02:05.990 --> 00:02:07.530
So we get to observe X squared.

00:02:07.530 --> 00:02:11.610
Now we treat X squared as known,
but we don't know X.

00:02:11.610 --> 00:02:14.102
Okay what do you think this is?

00:02:14.102 --> 00:02:15.292
Zero, why?

00:02:18.364 --> 00:02:20.210
Negative, yeah.

00:02:20.210 --> 00:02:23.140
This is just 0 and
you can do some big calculation, but

00:02:23.140 --> 00:02:26.810
you shouldn't have to cuz you just think
about what's the conditional distribution.

00:02:28.210 --> 00:02:33.582
Since if we know, if we get to
observe that in fact X squared

00:02:33.582 --> 00:02:38.400
= a, so we're treating it as knowns so
I'm just going to call it a,

00:02:38.400 --> 00:02:43.650
that we get to know a,
then we know that x is plus or

00:02:43.650 --> 00:02:48.302
minus the square root of a, but
by symmetry those are equally likely.

00:02:48.302 --> 00:02:51.260
All right, this is only giving us
information about the magnitude,

00:02:51.260 --> 00:02:54.280
it's not giving us any
information about the sign.

00:02:54.280 --> 00:02:58.320
Since the normal is symmetric,
then it's equally likely.

00:02:58.320 --> 00:03:02.770
So this is equally likely to be square
root of a or minus square root of a.

00:03:02.770 --> 00:03:04.080
Those are equally likely.

00:03:04.080 --> 00:03:07.164
If you average square root of a and
minus square root of a you'll get zero.

00:03:11.823 --> 00:03:15.820
So this doesn't say that X and
X squared are independent, right?

00:03:15.820 --> 00:03:17.890
We saw before that they're uncorrelated.

00:03:19.110 --> 00:03:21.250
But they're definitely not independent.

00:03:21.250 --> 00:03:26.530
But this just says that X squared doesn't
help very much with predicting X.

00:03:27.810 --> 00:03:29.790
Just as a number in this sense, right.

00:03:29.790 --> 00:03:32.830
We know the magnitude but
we don't know anything about the sign so

00:03:32.830 --> 00:03:34.900
we just have to guess one number and
we may as well say zero.

00:03:36.390 --> 00:03:40.800
All right, let's do another example,
just another quick example.

00:03:42.440 --> 00:03:45.870
Okay, so suppose we have a stick and
we break off,

00:03:45.870 --> 00:03:49.110
we have these stick
breaking type problems.

00:03:49.110 --> 00:03:53.683
We have a stick,
let's say it has length 1 and

00:03:53.683 --> 00:03:59.684
break off a random piece, and
by random here I mean uniform.

00:04:04.113 --> 00:04:06.805
So we break off a piece,
throw out the other piece.

00:04:06.805 --> 00:04:09.824
So now we only have one random piece
then break that piece again, okay?

00:04:11.140 --> 00:04:12.553
So break off another piece.

00:04:16.422 --> 00:04:20.191
And suppose we want the expected value, or

00:04:20.191 --> 00:04:27.040
the conditional expectation, for
the length of the second piece.

00:04:27.040 --> 00:04:31.526
So in terms of the picture,
what we're doing is we're first picking x.

00:04:31.526 --> 00:04:35.500
I have to put it somewhere for
the sake of the picture.

00:04:35.500 --> 00:04:39.810
That's x, but let's assume that
x is uniform between 0 and 1.

00:04:39.810 --> 00:04:45.960
I'm just translating what I just
said into probability notation.

00:04:45.960 --> 00:04:47.240
So that's the first break point.

00:04:47.240 --> 00:04:51.562
So we break the stick here, and we keep
this part, throw out the other piece.

00:04:51.562 --> 00:04:55.310
And then,
now we just have this piece from 0 to x,

00:04:55.310 --> 00:04:57.430
then pick a random break
point in this piece.

00:04:57.430 --> 00:05:00.920
Let's say there, that's y.

00:05:00.920 --> 00:05:05.000
Okay, and the question is then,
what's the length of this piece, right,

00:05:05.000 --> 00:05:09.430
or the distribution, or the conditional
expectation, that kind of thing.

00:05:09.430 --> 00:05:14.342
So to write that out conditionally,
we would just write y given x is

00:05:14.342 --> 00:05:20.310
uniform (0, x).

00:05:20.310 --> 00:05:25.085
So this notation would not make any
sense if I didn't write given x here,

00:05:25.085 --> 00:05:28.600
right, because I just wanna
specify a distribution.

00:05:28.600 --> 00:05:33.985
But what this notation means, it's just
shorthand for saying that if we know that

00:05:33.985 --> 00:05:38.360
big X equals little x, then it's going
to be uniform between 0 and little x.

00:05:38.360 --> 00:05:40.470
And this is just short hand for that.

00:05:40.470 --> 00:05:43.370
But you can always think of it back
in terms of conditioning on big

00:05:43.370 --> 00:05:44.310
X equals little x.

00:05:44.310 --> 00:05:47.823
So that's just short hand saying
if we get to treat x as known,

00:05:47.823 --> 00:05:50.875
then we're picking a random
point from here to here.

00:05:50.875 --> 00:05:52.000
All right, so that's the setup.

00:05:53.110 --> 00:05:58.055
Okay, now let's compute

00:05:58.055 --> 00:06:01.884
E(Y given X=x).

00:06:01.884 --> 00:06:05.347
So that's going to be
a function of little x.

00:06:05.347 --> 00:06:08.803
This just says that we know
the first break point is here,

00:06:08.803 --> 00:06:10.680
call this point little x.

00:06:10.680 --> 00:06:14.913
This one is anywhere from zero
to little x uniformly, so

00:06:14.913 --> 00:06:17.894
on average it would be little x over 2.

00:06:20.052 --> 00:06:24.392
And so E(Y given capital X)= capital X /2

00:06:24.392 --> 00:06:28.740
because we just changed
lowercase x to big X.

00:06:29.750 --> 00:06:32.433
And as I said, you can just think
of this as short hand for this.

00:06:32.433 --> 00:06:36.690
It's easier to write this and to work with
it once you understand what it means.

00:06:36.690 --> 00:06:38.520
But it's not essentially
a different concept.

00:06:40.190 --> 00:06:41.668
Okay so that's a random variable, right?

00:06:41.668 --> 00:06:45.140
E(Y given X) is a random variable and
it's a function of capital X.

00:06:46.960 --> 00:06:50.080
And let's just quickly see
what happens if we then take,

00:06:50.080 --> 00:06:54.220
so this is a random variable,
we can then ask, what's its expectation?

00:06:55.630 --> 00:07:00.817
So if we now take E(E(Y given X)),

00:07:03.712 --> 00:07:05.573
That makes perfect sense to do that,
right?

00:07:05.573 --> 00:07:08.600
Because that's a random variable,
I can take its expectation.

00:07:10.340 --> 00:07:13.596
Expected value of x is one-half,
cuz that's uniform zero-one.

00:07:13.596 --> 00:07:16.925
So one-half of one-half is one-fourth.

00:07:18.274 --> 00:07:21.736
And I also said at the very end last time,
we didn't prove it yet, but

00:07:21.736 --> 00:07:25.290
we'll prove it today that just in
general not just for this problem.

00:07:25.290 --> 00:07:27.580
E(E (Y given X)) is just E(Y).

00:07:28.800 --> 00:07:33.020
So that would be a quick way to
get the expected value of that

00:07:33.020 --> 00:07:35.822
second piece after we break twice.

00:07:35.822 --> 00:07:38.385
And one-fourth seems pretty intuitive,
right?

00:07:38.385 --> 00:07:41.497
Because on average, you're taking half
the stick and then half the stick again.

00:07:41.497 --> 00:07:45.945
So that seems reasonable, but as we've
seen many times our intuitions could be

00:07:45.945 --> 00:07:47.955
wrong, but
in this case it's pretty intuitive.

00:07:47.955 --> 00:07:50.985
And that actually proves that that's true,
at least once we know that

00:07:50.985 --> 00:07:55.550
this equals this, which I stated but
we haven't proven yet, okay?

00:07:55.550 --> 00:07:59.275
So those are just a couple
of quick examples.

00:07:59.275 --> 00:08:01.410
So now let's talk about
kind of the general.

00:08:02.700 --> 00:08:07.060
Properties of conditional expectation.

00:08:07.060 --> 00:08:12.390
There's like three or four main properties
and once you understand those few

00:08:12.390 --> 00:08:16.480
properties then you can derive all kinds
of stuff about conditional expectation.

00:08:16.480 --> 00:08:18.620
So these are very, very useful properties.

00:08:22.110 --> 00:08:24.230
I'll even write useful properties.

00:08:24.230 --> 00:08:26.208
Although we wouldn't do
them if they were useless.

00:08:26.208 --> 00:08:27.372
Okay.

00:08:27.372 --> 00:08:32.131
Property one, similar to what we
were just doing over there, but

00:08:32.131 --> 00:08:36.210
I just want to kind of write
that as a general statement.

00:08:37.600 --> 00:08:44.580
If we have E of, let's say,
each of X times Y, given X.

00:08:46.850 --> 00:08:51.040
Now we know that if we have a constant
in front, we can take it out.

00:08:51.040 --> 00:08:51.660
Right.

00:08:51.660 --> 00:08:55.330
Well in this case we're
treating X as known, so

00:08:55.330 --> 00:08:56.960
from our point this is capital X.

00:08:56.960 --> 00:08:59.310
So this h of X is random variable.

00:08:59.310 --> 00:09:00.690
h is just any function.

00:09:00.690 --> 00:09:03.840
Could be X cubed, E to the X, whatever.

00:09:03.840 --> 00:09:07.120
It's a function of X, we're treating
X as known, so we know h of X so

00:09:07.120 --> 00:09:11.400
we can take it out,
because we're treating it as a constant.

00:09:11.400 --> 00:09:16.870
So that just becomes h of X,
E of Y, given X.

00:09:16.870 --> 00:09:19.210
So that's really what we
implicitly were doing up here,

00:09:19.210 --> 00:09:23.010
I just took out the X squared,
and we're left with a 1 inside,

00:09:23.010 --> 00:09:27.010
the expected value of 1 given anything
is 1, cuz it's always 1, okay?

00:09:27.010 --> 00:09:29.060
So that's called taking out what's known.

00:09:38.555 --> 00:09:44.173
Okay, so we use that a lot to simplify
when we see a function of X there and

00:09:44.173 --> 00:09:46.860
we're conditioning on X.

00:09:46.860 --> 00:09:47.999
We can take it out.

00:09:47.999 --> 00:09:48.659
That's good.

00:09:48.659 --> 00:09:55.019
Okay, and secondly,
E of Y given X equals E of Y,

00:09:55.019 --> 00:09:58.910
if X, and Y are independent.

00:10:02.582 --> 00:10:04.110
This is not if and only if.

00:10:04.110 --> 00:10:06.630
We just saw an example over there,

00:10:06.630 --> 00:10:11.680
where E of X given X squared is zero,
we now that they're not independent,

00:10:11.680 --> 00:10:15.280
but if they are independent then we
can just get rid of the condition.

00:10:15.280 --> 00:10:19.860
That's just clear from the definition,
right, because the definition

00:10:19.860 --> 00:10:24.270
of this says that we work with
the conditional distribution given X.

00:10:24.270 --> 00:10:27.170
The conditional distribution of
Y given X is no different from

00:10:27.170 --> 00:10:29.220
the unconditional one,
because they're independent.

00:10:29.220 --> 00:10:34.050
So being given X doesn't help at all for
predicting Y.

00:10:34.050 --> 00:10:35.160
So then, that's just true.

00:10:36.950 --> 00:10:38.240
Okay.

00:10:38.240 --> 00:10:44.170
Third one is the one we we just stated,
E of E of Y given X equal E of Y.

00:10:44.170 --> 00:10:52.520
So we have the conditional expectation.

00:10:52.520 --> 00:10:55.640
Take its expectation and
just get the unconditional expectation.

00:10:57.930 --> 00:11:00.495
This one needs some proof.

00:11:00.495 --> 00:11:05.190
[COUGH]
This one goes by different names,

00:11:05.190 --> 00:11:06.440
depending on where you look.

00:11:08.886 --> 00:11:13.943
But I'll call it either iterated
expectation or in this department,

00:11:13.943 --> 00:11:18.840
we like to call it Adam's Law for
Reasons that we might get to later.

00:11:21.060 --> 00:11:24.840
Anyway whatever you call it
it's an extremely useful fact.

00:11:27.040 --> 00:11:31.290
Its main use is not to say
that this equals this,

00:11:31.290 --> 00:11:33.690
maybe I should have written it
the other way around, this equals this.

00:11:33.690 --> 00:11:38.570
It's more useful the other way around
just like in law of total-, and

00:11:38.570 --> 00:11:41.800
why do we care about
conditional probability?

00:11:41.800 --> 00:11:45.570
Well, one reason is just
that we gather evidence and

00:11:45.570 --> 00:11:47.480
we condition on the evidence, right?

00:11:47.480 --> 00:11:50.899
But the other reason is even we want
unconditional probability, then we keep

00:11:50.899 --> 00:11:54.980
using the law of total probability, and
reduce it down to conditional, right?

00:11:54.980 --> 00:11:56.392
This is an analogous to that,

00:11:56.392 --> 00:12:00.510
this is actually a generalization
of the law of total probability.

00:12:00.510 --> 00:12:04.940
So it's says we want the expected value
of Y, but we don't know how to do it,

00:12:04.940 --> 00:12:10.830
we can try to cleverly choose X to
make the problem simpler, where

00:12:10.830 --> 00:12:15.120
E of Y given X is simpler to work with,
and then take the expected value of that.

00:12:16.250 --> 00:12:19.810
That's basically what we did over here,
E of Y given X, I could immediately just

00:12:19.810 --> 00:12:24.760
write down that's X over 2, right,
cuz we know that conditional distribution.

00:12:24.760 --> 00:12:30.560
It's harder to just say right away, what's
the unconditional distribution of Y,

00:12:30.560 --> 00:12:33.360
right, cuz it has the conditional
structure built in.

00:12:33.360 --> 00:12:36.699
So that's an extremely useful property.

00:12:38.110 --> 00:12:39.880
We'll prove this in a few minutes.

00:12:39.880 --> 00:12:42.920
Just want to state one more property,
I think.

00:12:46.968 --> 00:12:51.635
And that one is that if we
take Y minus E of Y given X,

00:12:51.635 --> 00:12:57.082
that's a natural thing to look
at because we're thinking

00:12:57.082 --> 00:13:02.990
of this as the prediction,
that is we're using X to predict Y.

00:13:02.990 --> 00:13:06.220
E of Y given X is our prediction.

00:13:06.220 --> 00:13:10.090
So, Y minus that is just how far
off is the prediction, right?

00:13:10.090 --> 00:13:15.390
That's the actual value of Y,
minus the predicted value of Y, okay?

00:13:15.390 --> 00:13:20.230
And then the statement is that if we
multiply this by any function of X,

00:13:22.060 --> 00:13:26.040
you'll always get 0, h is any function
of x, h of x is any function of x.

00:13:28.730 --> 00:13:33.950
In words, this says that, This thing,

00:13:33.950 --> 00:13:39.176
Y minus E of Y, given X,
which in statistics is called a residual.

00:13:39.176 --> 00:13:43.340
It's just what's left over
after you try to predict Y and

00:13:43.340 --> 00:13:47.775
then the difference is uncorrelated
with any function of X.

00:13:55.988 --> 00:14:00.388
Because if we computed
the co-variance of these two things,

00:14:00.388 --> 00:14:04.954
I'll just write out the co-variance,
Y minus E of Y, given X,

00:14:04.954 --> 00:14:07.762
just the definition of co-variance.

00:14:10.465 --> 00:14:15.760
The co-variance would be exactly
this thing that we wrote here, E of,

00:14:15.760 --> 00:14:19.230
I'm just writing the same thing again.

00:14:19.230 --> 00:14:23.166
E of Y minus E of Y, given X, h of x, and

00:14:23.166 --> 00:14:27.720
then minus, definition of co-variance.

00:14:27.720 --> 00:14:31.788
Expected value of this times this,
minus E of this, E of this, right?

00:14:31.788 --> 00:14:37.180
So it's minus E of Y minus E of Y,
given X.

00:14:37.180 --> 00:14:39.810
Looks complicated, but
it will simplify, E of h of X.

00:14:39.810 --> 00:14:42.670
Just writing down what the co-variance is.

00:14:42.670 --> 00:14:45.380
But this thing is 0.

00:14:45.380 --> 00:14:51.520
We know that's 0, right, just by
iterated expectation and linearity.

00:14:51.520 --> 00:14:55.120
That's E of Y minus E of Y,
so this part is just 0.

00:14:55.120 --> 00:14:56.410
So we only have this term.

00:14:57.440 --> 00:15:00.930
So in other words what that shows is
that this is actually the covariance of

00:15:00.930 --> 00:15:02.780
this and this and it says it's 0.

00:15:02.780 --> 00:15:03.650
We haven't shown that yet.

00:15:05.610 --> 00:15:11.970
So let me draw a picture to show
geometrically what this says,

00:15:11.970 --> 00:15:16.562
and then I think we'll prove this property

00:15:16.562 --> 00:15:21.902
assuming the third one,
then we'll prove the third one, okay?

00:15:21.902 --> 00:15:28.790
All right, so first, here's a picture,
and whether this picture makes sense or

00:15:28.790 --> 00:15:33.030
not kind of depends on how much
linear algebra you've had.

00:15:33.030 --> 00:15:37.430
So, if you haven't had much then
you can ignore the picture.

00:15:37.430 --> 00:15:40.550
But if you have, then this picture
will help with your intuition for

00:15:41.580 --> 00:15:44.300
some of these properties, okay?

00:15:44.300 --> 00:15:47.060
So the picture is like this.

00:15:47.060 --> 00:15:50.930
We start with Y, and
we're representing it as a point.

00:15:50.930 --> 00:15:54.480
So the whole, not the whole idea, but a
big part of the idea of linear algebra is

00:15:54.480 --> 00:15:58.250
you start treating vectors
in an abstract way, right?

00:15:58.250 --> 00:16:02.503
Where a vector could be a function,
It could be a cow.

00:16:02.503 --> 00:16:03.885
It could be anything.

00:16:03.885 --> 00:16:06.150
Well, it doesn't matter what it is.

00:16:06.150 --> 00:16:10.200
All that matters is the axioms that
you have certain operations, right?

00:16:10.200 --> 00:16:15.001
So if you have an operation on cows that
satisfies the axioms of a vector space,

00:16:15.001 --> 00:16:19.560
then you treat them as vectors and
you need to just work with them, right?

00:16:19.560 --> 00:16:23.070
And so it's an axiomatic thing.

00:16:23.070 --> 00:16:26.850
And a big strength of
that approach is that

00:16:26.850 --> 00:16:31.230
we all have at least some intuition for
what goes on in r2 and

00:16:31.230 --> 00:16:35.670
r3, right, in Euclidean space,
in the plane, and things like that.

00:16:35.670 --> 00:16:39.230
It's harder when you have infinite
dimensional spaces, or even four or

00:16:39.230 --> 00:16:42.590
five dimensional spaces, it's harder
to figure out what's going on, like.

00:16:42.590 --> 00:16:46.180
But a lot of the geometric
intuition still applies.

00:16:46.180 --> 00:16:49.250
Okay, so we're thinking of this
as a random variable, which,

00:16:49.250 --> 00:16:52.850
remember, formally speaking,
a random variable is a function, but

00:16:52.850 --> 00:16:59.510
we are treating that function as if
it's just a point or a vector, okay.

00:16:59.510 --> 00:17:04.380
And then in our picture,
I'm gonna draw a plane, and

00:17:04.380 --> 00:17:08.290
it's not literally a plane, but
we're just visualizing it as a plane.

00:17:08.290 --> 00:17:13.450
This plane consists of all
possible functions of x.

00:17:15.585 --> 00:17:18.565
So it's a collection of random variables.

00:17:18.565 --> 00:17:20.235
It's a plane through the origin.

00:17:20.235 --> 00:17:21.838
It's not really a plane, but

00:17:21.838 --> 00:17:25.374
it goes through the origin because
one function of X is just zero.

00:17:25.374 --> 00:17:28.465
So every constant is contained in here.

00:17:28.465 --> 00:17:32.925
And X is in here somewhere, and X squared
is in here, and E to the X is in here.

00:17:32.925 --> 00:17:35.055
Any function of X, that's this plane.

00:17:36.095 --> 00:17:40.384
Okay, now what we're doing geometrically
when we do conditional expectation

00:17:40.384 --> 00:17:41.350
is a projection.

00:17:42.440 --> 00:17:49.231
So we're taking Y and we're going,
project it down into the plane, E (Y|X).

00:17:49.231 --> 00:17:52.480
E (Y|X) is a function of X, right.

00:17:52.480 --> 00:17:53.770
I keep emphasizing that.

00:17:53.770 --> 00:17:57.042
So E (Y|X) is in this plane.

00:17:57.042 --> 00:18:03.620
E(Y|X) is defined to be the point in
this plane that's closest to Y, okay?

00:18:05.010 --> 00:18:07.991
So that tells us why is it true,

00:18:07.991 --> 00:18:12.933
if Y is already function of X,
then E(Y|X) = Y.

00:18:12.933 --> 00:18:14.522
Because that says if it's
already in the plane,

00:18:14.522 --> 00:18:16.280
you don't need to project it anywhere.

00:18:16.280 --> 00:18:20.260
But if Y is not already a function of X,
then you're projecting it down to

00:18:20.260 --> 00:18:23.450
whatever function of X is
closest in a certain sense.

00:18:24.520 --> 00:18:30.248
The inner product of X,Y is E(X,Y).

00:18:30.248 --> 00:18:34.940
That's just for those of you who've seen
inner products before, that's what it is.

00:18:34.940 --> 00:18:38.110
The inner product is just a fancy word for
a dot product, right?

00:18:38.110 --> 00:18:41.491
You've all seen dot products in LSU and
for r2 and r3 and

00:18:41.491 --> 00:18:44.930
that's just the generalization
of that concept.

00:18:44.930 --> 00:18:47.500
You can check that this has
the properties of an inner product.

00:18:51.740 --> 00:18:57.020
The only assumption here is that
we're working with functions of X.

00:18:57.020 --> 00:19:01.640
All our random variables we want
to assume have finite variance.

00:19:01.640 --> 00:19:05.610
So implicitly assuming finite
variance in this picture.

00:19:05.610 --> 00:19:11.090
Okay, so anyway, we project Y to
E(Y) given X, and then just thinking

00:19:11.090 --> 00:19:16.465
geometrically if we want
this residual vector,

00:19:16.465 --> 00:19:22.105
Y-E(Y|X) that's just gonna
be a vector like this,

00:19:22.105 --> 00:19:25.890
right, the vector from here to here.

00:19:25.890 --> 00:19:29.200
Okay, and that, just from projection,

00:19:29.200 --> 00:19:33.560
you know how if I have a point above
this table, and I wanna project it down,

00:19:33.560 --> 00:19:36.630
I'm gonna go perpendicularly
down til I hit the table, right?

00:19:36.630 --> 00:19:37.685
So that's perpendicular.

00:19:37.685 --> 00:19:43.270
So all this is saying, all number (4)
says in this picture is that this

00:19:43.270 --> 00:19:49.040
vector from here to here is
perpendicular to the plane, right?

00:19:49.040 --> 00:19:54.410
So take any function of X and
this residual is gonna be perpendicular.

00:19:54.410 --> 00:19:59.670
So that's what it says geometrically.

00:19:59.670 --> 00:20:02.800
And let's see,
what does this statement say?

00:20:02.800 --> 00:20:05.850
E(E(Y|X)).

00:20:05.850 --> 00:20:09.709
So it's just,

00:20:09.709 --> 00:20:14.890
This is a function of X and we're taking
its average and we say we got E(Y).

00:20:14.890 --> 00:20:16.510
I'll talk more about the intuition for

00:20:16.510 --> 00:20:22.890
this one later when we also get to
the version of this for variance.

00:20:22.890 --> 00:20:27.740
But first, let's prove number (4),
assuming number (3).

00:20:27.740 --> 00:20:29.804
Then we'll prove number (3).

00:20:29.804 --> 00:20:33.755
So that's just a picture to keep in mind,
okay?

00:20:33.755 --> 00:20:37.614
That's not a proof, though, so
we still need to prove these things.

00:20:37.614 --> 00:20:39.588
So let's just calculate that.

00:20:43.019 --> 00:20:50.380
That proof of (4), I just wanna
calculate it and see if we get 0.

00:20:50.380 --> 00:20:52.140
Hopefully, we will.

00:20:52.140 --> 00:20:54.655
Okay, proof of (4).

00:20:58.334 --> 00:21:02.386
So let's just take this thing and
use linearity.

00:21:02.386 --> 00:21:04.276
So I'm not gonna rewrite
that whole expression, but

00:21:04.276 --> 00:21:05.720
I'm just gonna use linearity.

00:21:05.720 --> 00:21:09.620
I'm just gonna look at
what I'm gonna distribute,

00:21:09.620 --> 00:21:11.866
this time this minus this time this.

00:21:11.866 --> 00:21:20.162
So it's E(Yh(x))-

00:21:20.162 --> 00:21:27.672
E(Y|x)h(X)).

00:21:27.672 --> 00:21:32.300
I'm just rewriting the same
thing except splitting it

00:21:32.300 --> 00:21:35.126
into two terms using linearity.

00:21:35.126 --> 00:21:41.046
Okay, now let's just try to see what could

00:21:41.046 --> 00:21:46.378
we do with this to try to simplify it.

00:21:46.378 --> 00:21:48.260
This looks as simple as we can get it.

00:21:48.260 --> 00:21:50.000
So just leave that alone.

00:21:50.000 --> 00:21:52.210
Let's try to simplify this part.

00:21:52.210 --> 00:21:53.970
E of something.

00:21:53.970 --> 00:21:59.700
Well, I kind of like really wanna apply
Adam's law, cuz I have this E(E),

00:21:59.700 --> 00:22:03.830
but then there's like this h(X) here,
okay?

00:22:03.830 --> 00:22:05.230
So I can't directly apply it.

00:22:05.230 --> 00:22:09.754
So what do you think we
should do with h(X)?

00:22:09.754 --> 00:22:11.388
&gt;&gt; [INAUDIBLE]
&gt;&gt; Here we know X, so

00:22:11.388 --> 00:22:13.490
let's actually put it back.

00:22:14.640 --> 00:22:16.912
So that's called putting
back what's known,

00:22:16.912 --> 00:22:20.784
but it follows from taking out what's
known that you can put back what's known,

00:22:23.576 --> 00:22:27.098
Right, we're treating that as known so

00:22:27.098 --> 00:22:31.880
I can write it here,
write it there, it's fine okay?

00:22:31.880 --> 00:22:40.000
So now so we have E(E(h(x)Y|X)), right?

00:22:41.440 --> 00:22:46.120
Now it's exactly, well, I should
have put it back over here, right,

00:22:46.120 --> 00:22:47.447
move it over there.

00:22:47.447 --> 00:22:49.550
That should be Y times h(x).

00:22:49.550 --> 00:22:54.698
So that's of the form where we
can apply Adam's law now, right?

00:22:54.698 --> 00:23:02.969
So that's E(Yh(x))- E(Yh(x)) = 0.

00:23:07.178 --> 00:23:10.662
Okay, so it's really just linearity,
taking out what's known or

00:23:10.662 --> 00:23:14.490
putting back what's known,
and iterated expectation.

00:23:14.490 --> 00:23:19.660
That proves property (4),
assuming iterated expectation.

00:23:19.660 --> 00:23:22.320
Okay, so now we really need to check that

00:23:22.320 --> 00:23:25.280
this iterated expectation
formula is correct.

00:23:26.320 --> 00:23:32.998
Okay, so let's do that.

00:23:32.998 --> 00:23:37.148
Okay, so just to simplify notation,

00:23:37.148 --> 00:23:41.180
let's do it in the discrete case.

00:23:41.180 --> 00:23:45.408
Continuous case is analogous.

00:23:45.408 --> 00:23:50.044
Proof of (3) discrete case just to

00:23:50.044 --> 00:23:54.412
simplify our notation And let's let,

00:23:57.629 --> 00:24:02.200
So we're trying to find
E of E of Y given X, so

00:24:02.200 --> 00:24:06.047
let's give it a name, g of X, okay?

00:24:06.047 --> 00:24:08.607
So we're gonna let E of Y given X.

00:24:08.607 --> 00:24:12.235
Remember, it's a function
of X as I keep saying, so

00:24:12.235 --> 00:24:14.717
we may as well give it a name, g of X.

00:24:14.717 --> 00:24:18.675
So really all we're trying to do here,
that's just E of g of X,

00:24:18.675 --> 00:24:21.234
that's all we're trying to do, okay.

00:24:21.234 --> 00:24:22.961
So we need to find the E of g of X, and

00:24:22.961 --> 00:24:25.240
show that that just reduces to E of Y,
right.

00:24:26.631 --> 00:24:33.509
Okay, so let's just do that, E of g of X,
well, we've dealt with things that

00:24:33.509 --> 00:24:39.158
looks like E of g of X many times
before already, just LOTUS, right.

00:24:39.158 --> 00:24:42.581
So lets just write down discrete LOTUS,
in the continuous case,

00:24:42.581 --> 00:24:44.647
we could write down continuous LOTUS.

00:24:48.510 --> 00:24:53.847
So by LOTUS,
that's just the sum over X of,

00:24:57.866 --> 00:25:02.341
g of X times the probability
that X = little x.

00:25:05.383 --> 00:25:09.191
Now, let's write down
what's g of little x.

00:25:09.191 --> 00:25:15.239
g of little x is E of Y given, this is
how we define conditional expectation,

00:25:16.595 --> 00:25:23.120
Is that, We started by conditioning on
big X = little x, call that g of X.

00:25:23.120 --> 00:25:26.320
Then we changed little x to
big X to get g of capital X.

00:25:26.320 --> 00:25:28.140
So that's just what g of little x is.

00:25:29.810 --> 00:25:32.150
Okay, so I just used the definition.

00:25:32.150 --> 00:25:35.810
So far all I've done is used LOTUS,
used the definition.

00:25:35.810 --> 00:25:41.060
Now, again, let's just use
the definition of this, okay?

00:25:41.060 --> 00:25:43.658
Cuz I don't like memorizing proofs or
anything, and

00:25:43.658 --> 00:25:45.282
I don't remember how to do this.

00:25:45.282 --> 00:25:50.877
So all I'm gonna do is just plug into
the definition and hope it works, okay?

00:25:50.877 --> 00:25:56.472
So, let's just see, what's the definition
of this thing, E of Y given X = x?

00:25:56.472 --> 00:25:59.752
Well, again, I don't like memorizing
definitions any more than I like

00:25:59.752 --> 00:26:02.818
memorizing proofs, but
I know the definition of expectation, and

00:26:02.818 --> 00:26:05.163
then conditional just
means make it conditional.

00:26:05.163 --> 00:26:09.040
So I'm just gonna write down
that the definition, just y.

00:26:09.040 --> 00:26:13.572
Right, if we're unconditional,
we would just do P of Y = y here, right?

00:26:13.572 --> 00:26:19.135
That would just be E of Y, but it's
conditional, so we just put given X = x.

00:26:20.947 --> 00:26:21.649
All right, and

00:26:21.649 --> 00:26:27.727
then we have this probability X = x here,
Which is outside of that sum.

00:26:27.727 --> 00:26:33.833
But actually, if we want,
we can bring it inside of the sum, okay?

00:26:33.833 --> 00:26:39.043
So, because this depends on X and
we're summing over Y.

00:26:40.930 --> 00:26:48.364
So somehow, we have to reduce
this down to, So if we want,

00:26:48.364 --> 00:26:52.830
we can bring this in here because this is
a function of X and we're summing over Y.

00:26:52.830 --> 00:26:56.819
So somehow we're hoping that this
will reduce down to just the expected

00:26:56.819 --> 00:26:57.486
value of Y.

00:26:57.486 --> 00:27:03.734
So somehow we have to get rid of all of
these xs here somehow have to go away.

00:27:03.734 --> 00:27:09.392
So a very, very common trick when
we're dealing with a double sum or

00:27:09.392 --> 00:27:13.760
a double integral is to swap
the order of summation or

00:27:13.760 --> 00:27:17.054
swap the order of integration, okay?

00:27:17.054 --> 00:27:23.018
Especially in the discrete case that
as long as the sum converge absolutely,

00:27:23.018 --> 00:27:25.968
it's a completely valid thing to do.

00:27:25.968 --> 00:27:29.133
You just rearranging
the whole a + b is b + x.

00:27:29.133 --> 00:27:31.496
So I'm gonna add up the same
thing in a different order.

00:27:31.496 --> 00:27:35.377
So I'm just gonna say sum over y first and
then sum over x.

00:27:35.377 --> 00:27:37.916
That's the same thing as summing
over x and then summing over y.

00:27:37.916 --> 00:27:39.289
We're just rearranging terms.

00:27:39.289 --> 00:27:41.623
We're just adding in a different order.

00:27:41.623 --> 00:27:49.159
Okay, and then, that's y p times y = y.

00:27:49.159 --> 00:27:52.546
Let me write it this way, X = x.

00:27:52.546 --> 00:27:57.588
I can write it this way because
remember that's the joint PMF.

00:27:57.588 --> 00:28:01.441
But remember the joint PMF is the
conditional PMF times the marginal PMF,

00:28:01.441 --> 00:28:03.133
that's the marginal, right?

00:28:03.133 --> 00:28:08.174
That's the marginal PMF of X,
that's the condition PMF of Y given X.

00:28:08.174 --> 00:28:12.053
So we multiply this thing times this
thing, that's just the joint PMF, so

00:28:12.053 --> 00:28:13.724
we may as well write it that way.

00:28:14.851 --> 00:28:19.053
Okay, so, Now,

00:28:19.053 --> 00:28:24.124
notice since I swapped the order of
summation, something good happens,

00:28:24.124 --> 00:28:28.727
which is that this y doesn't depend on x,
so we can pull this y out.

00:28:28.727 --> 00:28:31.150
So that y goes right there, okay?

00:28:31.150 --> 00:28:35.745
So that's the sum over y of y.

00:28:35.745 --> 00:28:41.669
So just imagine pulling this y out and
let's just stare at this sum here.

00:28:41.669 --> 00:28:46.261
We have the joint PMF and
we're summing up over all x.

00:28:46.261 --> 00:28:48.773
Well, that's exactly how
we got the marginal, right?

00:28:48.773 --> 00:28:53.728
To get a marginal from a joint, we just
took the joint PMF and we sum up over X,

00:28:53.728 --> 00:28:58.700
we'll get the marginal of Y, if we sum
over Y, we'll get the marginal of X.

00:28:58.700 --> 00:29:01.839
In this case, we're summing up over X.

00:29:01.839 --> 00:29:04.062
Just like remember those
2x2 tables we were drawing?

00:29:04.062 --> 00:29:07.838
Just add up a row or add up a column
we get to get the marginal?

00:29:07.838 --> 00:29:12.301
So we're summing up over x, that gives
us the marginal distribution of Y.

00:29:12.301 --> 00:29:16.109
So therefore,
by definition that's just E of Y.

00:29:19.326 --> 00:29:22.990
So really the only trick here was
to write this as a double sum and

00:29:22.990 --> 00:29:27.782
then swap the order of summation which is
often a useful trick and proving things.

00:29:27.782 --> 00:29:31.858
Other than that, I would just plugged
into LOTUS, plugged into the definition.

00:29:31.858 --> 00:29:35.874
And just used what's a conditional
distribution and marginal and

00:29:35.874 --> 00:29:39.395
joint distribution which we
talked about before, okay?

00:29:39.395 --> 00:29:46.708
So that is the proof of this property,
and I want to do some more examples.

00:29:50.457 --> 00:29:59.281
First, one more, One more
definition of a conditional thing.

00:29:59.281 --> 00:30:03.377
So definition of conditional variance,
cuz we have conditional expectation, and

00:30:03.377 --> 00:30:06.503
I think this would be a good time
to get to conditional variance.

00:30:08.945 --> 00:30:11.822
It's defined analogously.

00:30:13.809 --> 00:30:15.758
So the variance of Y given X.

00:30:17.940 --> 00:30:20.489
Lets just try to think intuitively.

00:30:20.489 --> 00:30:26.411
Either we could write
it as E of Y squared.

00:30:26.411 --> 00:30:30.694
Usually the way we do variances,
E of Y squared- the square of E of Y.

00:30:30.694 --> 00:30:34.785
So let's just write down the same thing,
except make everything given x, right.

00:30:34.785 --> 00:30:39.433
Because this says, we get to treat
X as known, given that information,

00:30:39.433 --> 00:30:41.657
what's the variance of Y, okay?

00:30:41.657 --> 00:30:46.911
So a natural thing to do
would be E of Y squared

00:30:46.911 --> 00:30:55.046
given x- E of Y given X squared,
Which is correct.

00:30:55.046 --> 00:30:58.759
But remember we also define
variance a different way,

00:30:58.759 --> 00:31:02.566
that was the expected square
difference from the mean.

00:31:02.566 --> 00:31:05.966
So let's try to also write
that down that definition.

00:31:05.966 --> 00:31:10.343
If we define it the other way,

00:31:10.343 --> 00:31:14.028
we did like E of Y- E of Y.

00:31:14.028 --> 00:31:18.810
If it was just unconditional, we would
do Y- its mean and square that thing.

00:31:18.810 --> 00:31:22.094
However, we're trying to
make it conditional, so

00:31:22.094 --> 00:31:27.239
we're gonna put Y -, we get to treat X as
known, so instead of E of Y, we're using

00:31:27.239 --> 00:31:31.666
E of Y given X to make it conditional,
and we're squaring this thing.

00:31:34.303 --> 00:31:39.643
Now if I just close the parentheses here,
that would be wrong.

00:31:39.643 --> 00:31:43.487
And you could immediately see that would
be wrong just by thinking about what kind

00:31:43.487 --> 00:31:44.800
of object this is.

00:31:44.800 --> 00:31:47.150
If I just put closed parentheses here,

00:31:47.150 --> 00:31:49.900
then that's just gonna be a number
cuz this is random variable.

00:31:49.900 --> 00:31:51.755
Taking its expected out,
we'll get a number.

00:31:51.755 --> 00:31:55.821
But actually this equation or
just this expression makes

00:31:55.821 --> 00:32:00.064
it clear that variance in y given
x should be a function of x.

00:32:00.064 --> 00:32:02.368
As we're treating x as known, okay?

00:32:02.368 --> 00:32:05.126
And then what's the variance
of y as a function of x.

00:32:05.126 --> 00:32:07.450
That means we need another given Xhere.

00:32:10.302 --> 00:32:15.432
So all this is saying is like throughout
this problem, everything is given x.

00:32:15.432 --> 00:32:18.128
So we can't forget one of the given xs,

00:32:18.128 --> 00:32:21.819
everything is based on
the assumption that we know x.

00:32:21.819 --> 00:32:25.716
Okay, so I just wrote that
these two things are equal,

00:32:25.716 --> 00:32:28.525
we didn't prove that these are equal.

00:32:28.525 --> 00:32:32.142
We kind of hoped that there will be
something kind of strange if they were

00:32:32.142 --> 00:32:32.757
not equal.

00:32:32.757 --> 00:32:37.777
Cuz intuitively, we're just doing
variance except everything is given x.

00:32:37.777 --> 00:32:41.848
So it should work out, but
it should still be checked.

00:32:41.848 --> 00:32:46.278
It's good practice, so I'll probably
put this on the next strategic

00:32:46.278 --> 00:32:50.346
practice cuz it is good practice
to check that this equals this.

00:32:50.346 --> 00:32:55.721
Just practice with, because at this point
we reduced it to conditional expectation,

00:32:55.721 --> 00:33:00.375
so you an just use the properties of
conditional expectation, all right?

00:33:00.375 --> 00:33:04.711
So that's variance and then, okay,

00:33:04.711 --> 00:33:09.859
now we have one more property, property 5,

00:33:09.859 --> 00:33:14.478
I'll write it up there, easier to see.

00:33:14.478 --> 00:33:18.475
These are four properties of
conditional expectation, and

00:33:18.475 --> 00:33:23.265
it would be sad not to get at least
one property of conditional variance.

00:33:23.265 --> 00:33:28.034
So the property is that the variance
of y equals the expected value of

00:33:28.034 --> 00:33:33.738
the conditional variance, plus the
variance of the conditional expectation.

00:33:40.337 --> 00:33:44.046
So it's a pretty cool-looking formula,
right?

00:33:44.046 --> 00:33:46.843
This is the unconditional variance of Y.

00:33:46.843 --> 00:33:49.405
And somehow we want to like,
so imagine we're trying,

00:33:49.405 --> 00:33:53.127
we have this quantity y and we want it's
variance and we don't know how to get it.

00:33:53.127 --> 00:33:58.533
So we kinda want to do some condition on
something to make the problem easier.

00:33:58.533 --> 00:34:04.807
So the condition on x, but then should
we do the variance of y given x first?

00:34:04.807 --> 00:34:07.413
Or should we take
the conditional expectation and

00:34:07.413 --> 00:34:09.093
then take the variance of that?

00:34:09.093 --> 00:34:10.516
Not so obvious, right?

00:34:10.516 --> 00:34:16.651
This says two ways you could do this,
add them together.

00:34:16.651 --> 00:34:25.225
This property is called
Eve's Law because it's EVVE.

00:34:25.225 --> 00:34:32.422
That actually should be EVVE but
we abbreviate to Eve, Eve's law, okay?

00:34:32.422 --> 00:34:39.610
So, that explains some of
the etymology here for Adam's law.

00:34:39.610 --> 00:34:42.213
Especially when you see
the proof of Eve's law,

00:34:42.213 --> 00:34:45.017
which is also very very good
practice to prove this.

00:34:45.017 --> 00:34:47.131
So, I'm going to put this on
the next strategic practice, too.

00:34:47.131 --> 00:34:49.179
You should try it yourself first,

00:34:49.179 --> 00:34:53.351
then you can study the proof that I
will put in the strategic practice.

00:34:53.351 --> 00:34:58.604
Let me explain the intuition of this
a little bit and then, we'll do an example

00:34:58.604 --> 00:35:03.788
of how to use Adam's law and Eve's law
together to get the mean and variance.

00:35:03.788 --> 00:35:08.779
So here's kind of an intuitive picture.

00:35:08.779 --> 00:35:13.408
Imagine we have different
groups of people, okay?

00:35:13.408 --> 00:35:19.365
Just to have a simple picture in mind,
let's say we have three groups, okay?

00:35:19.365 --> 00:35:24.085
And then there's lots of
people inside each group.

00:35:24.085 --> 00:35:30.562
And then, just have a concrete example
in mind, maybe think of y as height,

00:35:30.562 --> 00:35:37.360
so you have some population of people
which consists of three subpopulations.

00:35:37.360 --> 00:35:40.154
You wanna know the mean and
the variance for

00:35:40.154 --> 00:35:44.817
the heights of people in this population,
or make up your own example.

00:35:44.817 --> 00:35:47.513
So these are the three subpopulations and

00:35:47.513 --> 00:35:51.678
each subpopulation may have its
own mean and variance, right?

00:35:51.678 --> 00:35:54.118
But you want the overall, okay?

00:35:54.118 --> 00:35:58.152
So it's kinda hard to think about
this entire population all at once.

00:35:58.152 --> 00:36:02.117
It's much easier to think about
each subpopulation, all right?

00:36:02.117 --> 00:36:06.624
So notice that there are two
types of variability going on.

00:36:06.624 --> 00:36:14.990
One is that different subpopulations
may have differences in height, right?

00:36:14.990 --> 00:36:17.830
So we have differences
between populations,

00:36:17.830 --> 00:36:21.552
then you have variability
within each population, right?

00:36:21.552 --> 00:36:27.184
So within each population, unless everyone
in that subpopulation is the same height,

00:36:27.184 --> 00:36:30.076
you have variability
within each of these and

00:36:30.076 --> 00:36:32.908
you have variability between them, okay?

00:36:32.908 --> 00:36:37.176
So if you want, I'm thinking of
x in this case, it'll be like,

00:36:37.176 --> 00:36:39.644
this wold be x = 1, x = 2, x = 3.

00:36:39.644 --> 00:36:44.495
So x takes three values, x just says
which, if you take a random person from

00:36:44.495 --> 00:36:48.576
this population,
which sub-population are they in, okay?

00:36:48.576 --> 00:36:50.732
So that would be the x.

00:36:50.732 --> 00:36:53.924
So if we do e of y given x equals 1,

00:36:53.924 --> 00:36:59.168
that was just be the mean for
this population, right?

00:36:59.168 --> 00:37:04.249
So really, what this says is,
this term here is

00:37:04.249 --> 00:37:09.852
saying look at the average
within each population.

00:37:09.852 --> 00:37:14.527
And then take the average,
take the variance of those numbers, right?

00:37:14.527 --> 00:37:17.511
So that's really looking
between populations.

00:37:17.511 --> 00:37:21.365
And this is saying look
within each population,

00:37:21.365 --> 00:37:24.850
this one's within, this one's between.

00:37:24.850 --> 00:37:28.517
This says look within each population,
take its variance and

00:37:28.517 --> 00:37:30.289
then average those numbers.

00:37:30.289 --> 00:37:36.943
This one says look, Replace

00:37:36.943 --> 00:37:41.370
each population by just its average height
and take the variance of those, okay?

00:37:41.370 --> 00:37:45.513
So it is pretty intuitive that there
are those two types of variabilities, but

00:37:45.513 --> 00:37:49.370
what's kind of cool is that this just
says you can just add them, right?

00:37:49.370 --> 00:37:52.236
Intuitively there's two
types of variability, but

00:37:52.236 --> 00:37:56.703
it's pretty nice that to get the overall
variance, you just add those two things.

00:37:56.703 --> 00:38:01.325
It sounds too good to be true,
but that's how it works.

00:38:04.630 --> 00:38:07.234
Okay, so let me do an example.

00:38:11.281 --> 00:38:18.346
All right, so imagine that we're studying
prevalence of a certain disease and

00:38:18.346 --> 00:38:23.092
the fraction of people, so
you have some country, or

00:38:23.092 --> 00:38:28.261
let's say some state that
consists of different cities,

00:38:28.261 --> 00:38:34.823
and different cities have different
prevalences of the disease, okay?

00:38:34.823 --> 00:38:38.793
So, this is just an example.

00:38:38.793 --> 00:38:45.020
So, suppose that you pick
a sample of basically,

00:38:45.020 --> 00:38:49.184
here is how you do your sampling.

00:38:49.184 --> 00:38:53.479
Sometimes this is done in practice cuz
like, I guess if you've been studying

00:38:53.479 --> 00:38:57.447
the entire state ideally ,maybe you
would get a simple random sample,

00:38:57.447 --> 00:39:01.699
of people from the state and you want to
see how many of them have the disease.

00:39:01.699 --> 00:39:05.898
Or maybe rather than using simple random
sample you stratify in certain ways

00:39:05.898 --> 00:39:06.495
and so on.

00:39:06.495 --> 00:39:10.206
They can get into it in a sampling
class which is not our topic here.

00:39:10.206 --> 00:39:13.682
But sometimes for practical or
other reasons the way

00:39:13.682 --> 00:39:18.111
that these kind of things work is,
you pick a random city, right?

00:39:18.111 --> 00:39:23.366
And then go into the city, collect the
sample from the city, it's easier, right?

00:39:23.366 --> 00:39:27.911
And then we wanna make some conclusions.

00:39:27.911 --> 00:39:31.605
All right, so
just to try to formalize that,

00:39:31.605 --> 00:39:36.092
what I'm saying is we pick
a random city in some state.

00:39:38.584 --> 00:39:42.905
And then pick random sample
of people in that city.

00:39:46.726 --> 00:39:53.406
Of people in that city, And

00:39:53.406 --> 00:39:57.788
then, you test each of those people for
the disease that you're studying.

00:39:57.788 --> 00:40:02.150
Let's say this is a random
sample consisting of n people.

00:40:02.150 --> 00:40:05.690
So n is our sample size
which we treat as fixed.

00:40:07.400 --> 00:40:11.120
Okay, so pick a random city, then go to
the city, get n people, test them all for

00:40:11.120 --> 00:40:15.750
the disease and let X equal number of
people with the disease in the sample.

00:40:21.080 --> 00:40:27.087
And let's let Q = dp, true proportion

00:40:27.087 --> 00:40:33.100
of people infected in the random city.

00:40:34.340 --> 00:40:37.660
Proportion of people in the random city.

00:40:39.260 --> 00:40:41.400
So that is once we've
selected the random city,

00:40:41.400 --> 00:40:44.210
then Q is just literally how many people

00:40:44.210 --> 00:40:47.660
in that city have the disease divided
by the number of people in that city.

00:40:47.660 --> 00:40:51.560
But I'm using a capital letter cuz
initially it's a random variable,

00:40:51.560 --> 00:40:55.090
because different cities have different
prevalences of the disease, and

00:40:55.090 --> 00:40:57.800
we're picking a random city,
so that's a random variable.

00:40:57.800 --> 00:40:59.990
So you can think of this as
a random probability, right?

00:40:59.990 --> 00:41:01.500
Cuz this is gonna be
a number between 0 and

00:41:01.500 --> 00:41:05.930
1, which is the proportion of people who
have the disease, but the city is random.

00:41:10.524 --> 00:41:13.140
Okay, so who have the disease.

00:41:17.226 --> 00:41:20.218
By city with the disease,
I mean people with the disease,

00:41:20.218 --> 00:41:22.400
not the cities with the disease.

00:41:22.400 --> 00:41:26.489
So there are a lot of questions we could,
this is a pretty general.

00:41:26.489 --> 00:41:31.190
So you can see how this kind of setup has
lots of applications in epidemiology.

00:41:31.190 --> 00:41:32.700
But it doesn't have to be disease.

00:41:32.700 --> 00:41:35.039
It could be political opinions or
whatever you want.

00:41:35.039 --> 00:41:37.215
It's just it's just that we have.

00:41:37.215 --> 00:41:40.195
That is it's similar to what
I was just saying here.

00:41:40.195 --> 00:41:44.185
In that we're assuming that we have
variability between different cities have

00:41:44.185 --> 00:41:48.687
different political opinions or
different disease characteristics.

00:41:48.687 --> 00:41:50.927
And within each city there's
also variation, right?

00:41:50.927 --> 00:41:54.307
So we have those two types of variation,
how do we deal with that?

00:41:54.307 --> 00:41:57.273
Okay, so there are lots of things
we could ask about this setup.

00:41:57.273 --> 00:42:01.288
But for right now, let's just find
the mean and the variance of X.

00:42:08.348 --> 00:42:13.676
To do that, though we need some assumption

00:42:13.676 --> 00:42:18.270
about the distribution of Q, okay.

00:42:18.270 --> 00:42:22.540
So the most commonly
used choice in practice

00:42:22.540 --> 00:42:25.588
would be to pick a beta distribution.

00:42:25.588 --> 00:42:30.389
So we're gonna assume that Q is Beta a,
b where a and b are known.

00:42:32.248 --> 00:42:36.106
Because a Beta as we were just
saying when we were doing the Beta

00:42:36.106 --> 00:42:38.045
it's a very flexible family.

00:42:38.045 --> 00:42:42.170
It takes continuous values between 0 and
1.

00:42:42.170 --> 00:42:43.980
We know Q has to be between 0 and 1.

00:42:43.980 --> 00:42:47.268
And we know the Beta is a conjugate
prior for the binomial, so

00:42:47.268 --> 00:42:49.020
it has a lot of nice properties.

00:42:49.020 --> 00:42:51.980
So it's mathematically convenient but

00:42:51.980 --> 00:42:55.641
it's also a pretty flexible
family to work with.

00:42:55.641 --> 00:43:01.738
By playing around with a and b,
you could get a variety of distributions

00:43:01.738 --> 00:43:06.921
that hopefully would accurately
reflect what you wanna do,

00:43:06.921 --> 00:43:10.697
as far as what
the distribution of Q is like.

00:43:10.697 --> 00:43:12.890
So we'll assume a beta.

00:43:12.890 --> 00:43:16.820
You can assume something else if you want
and then do a similar calculation but

00:43:16.820 --> 00:43:19.419
the Beta would be the most
popular choice here, and

00:43:19.419 --> 00:43:21.640
also happens to be convenient, okay.

00:43:21.640 --> 00:43:24.960
So now, so that's Q.

00:43:24.960 --> 00:43:28.780
We're also implicitly, I man it's
basically set in words here, but

00:43:28.780 --> 00:43:32.830
we're implicitly assuming x
given Q is binomial n, Q.

00:43:34.910 --> 00:43:40.247
That is once we know that
the true value of what proportion

00:43:40.247 --> 00:43:46.815
of people in that city have the disease,
then we're doing binomial.

00:43:46.815 --> 00:43:49.549
Hypergeometric might be
a little bit better.

00:43:49.549 --> 00:43:55.760
But we're either assumed sampling with
replacement or that the n is small enough

00:43:55.760 --> 00:44:01.730
compared to the population size that
it is essentially binomial, okay.

00:44:01.730 --> 00:44:06.120
So now we're all set to find what we want.

00:44:06.120 --> 00:44:13.555
E of x, so it's very, very natural here
to use conditional expectation, right?

00:44:13.555 --> 00:44:19.090
Cuz the whole problem was set up in a way
where conditional on which city you're in.

00:44:19.090 --> 00:44:22.593
Then we have a good sense of what's going
on unconditionally then you have to kinda

00:44:22.593 --> 00:44:25.510
combine all these different cities
that's harder to think about.

00:44:25.510 --> 00:44:28.180
It's easier if you kind of
zoom in on one city first.

00:44:28.180 --> 00:44:30.415
So that suggests, okay,
just condition on Q.

00:44:30.415 --> 00:44:33.424
So this is gonna be E of E of X given Q.

00:44:36.903 --> 00:44:40.794
E of X given Q, well given Q,
we just have a binomial n, Q,

00:44:40.794 --> 00:44:44.760
expected value of binomial of n,
Q will be n, Q.

00:44:44.760 --> 00:44:48.858
So that's just E(nQ),
n is just a constant.

00:44:48.858 --> 00:44:53.272
So then it's just na/(a+b) because

00:44:53.272 --> 00:44:57.980
a Beta ab has expected value a/(a+b).

00:44:57.980 --> 00:45:01.960
So it's a quick calculation at
that point once you condition.

00:45:03.140 --> 00:45:04.557
All right, so now lets do the variants.

00:45:07.779 --> 00:45:11.639
So again, we're gonna do this
by thinking conditionally.

00:45:11.639 --> 00:45:16.460
We have a between cities and
a within city term.

00:45:16.460 --> 00:45:22.190
Eaves Law says this is the expected
value of the variants of X given Q.

00:45:23.640 --> 00:45:29.244
Plus the variance of
the expected value of X given Q.

00:45:29.244 --> 00:45:36.298
Then we just have to work out
what are these two things

00:45:39.679 --> 00:45:43.894
Okay, so for the first term,
the variance of X given Q,

00:45:43.894 --> 00:45:47.840
of given Q is just a binomial,
and we know that this,

00:45:47.840 --> 00:45:53.270
if we treat Q as a constant,
this has variance, n, Q, 1-Q, right?

00:45:53.270 --> 00:45:58.900
And the n, so let's just write that down.

00:45:58.900 --> 00:46:04.024
So it's just the expected value of
the variance of X given Q is just nQ 1- Q.

00:46:04.024 --> 00:46:10.638
And then, For the other term,

00:46:10.638 --> 00:46:14.798
the variance of X given Q, I just get
that from the binomial, all right.

00:46:14.798 --> 00:46:18.969
For the other term,
if the variance of E of X given Q, well,

00:46:18.969 --> 00:46:21.812
we just said that E of X given Q, is n,Q.

00:46:21.812 --> 00:46:23.775
So I just want the variance of n,Q.

00:46:24.890 --> 00:46:29.640
N comes out as a squared, so just give
me n squared times the variance of Q.

00:46:32.190 --> 00:46:34.680
Now we just have to
compute those two things.

00:46:35.720 --> 00:46:40.570
And for the Beta distribution,
those things are actually both

00:46:41.580 --> 00:46:46.430
pretty easy because when
we see this Q(1-Q),

00:46:46.430 --> 00:46:52.060
that kinda reminds you of what
the Beta looks like, right?

00:46:52.060 --> 00:46:56.650
So to compute those two things,

00:46:58.891 --> 00:47:01.387
Let's just do those on the side,

00:47:01.387 --> 00:47:06.390
we just need to compute those two
quantities and then we're done.

00:47:06.390 --> 00:47:10.135
So we need to know the expected value,

00:47:10.135 --> 00:47:15.765
the end comes out here, so
all we need is E of Q(1-Q).

00:47:15.765 --> 00:47:20.550
Okay, so let's just do that, just for a
quick practice with a Beta and with LOTUS.

00:47:23.801 --> 00:47:28.620
Well, one thing we could do is just
say this is E of Q- E of Q squared.

00:47:28.620 --> 00:47:31.805
And we already know E of Q and
we could get E of Q squared.

00:47:31.805 --> 00:47:33.322
That parts really fine.

00:47:33.322 --> 00:47:35.820
But let's just do it directly using LOTUS.

00:47:37.680 --> 00:47:41.770
So I'm just gonna write down,
LOTUS, right?

00:47:41.770 --> 00:47:43.019
So this is just Q.

00:47:43.019 --> 00:47:46.925
I'm going to change
capital Q to lower case q.

00:47:46.925 --> 00:47:49.860
Q(1-Q), and
then we integrate the beta density.

00:47:49.860 --> 00:47:54.600
And let's just simplify the beta
density has Q to the a-1, but

00:47:54.600 --> 00:47:56.060
we are multiplying by q.

00:47:56.060 --> 00:47:57.754
So now it's q to the a.

00:47:57.754 --> 00:48:01.412
And then has a 1-Q to the b-1, but

00:48:01.412 --> 00:48:06.780
we also have this 1-Q, so
that becomes to the b.

00:48:06.780 --> 00:48:10.670
Dq times the normalizing
constant of the beta,

00:48:10.670 --> 00:48:15.440
which is gamma a plus b over gamma of a,
gamma of b.

00:48:15.440 --> 00:48:20.380
Well, it looks like this

00:48:20.380 --> 00:48:24.920
complicated thing until you realize that
is just another beta integral, right?

00:48:24.920 --> 00:48:29.470
So, this is just gamma of
a+b over gamma a gamma b.

00:48:29.470 --> 00:48:34.580
And then we just have to multiply and
divide by whatever we need

00:48:34.580 --> 00:48:39.100
in order to make this exactly
the integral of a beta PDF.

00:48:39.100 --> 00:48:44.510
So I'm just imagining putting in
the normalizing constant of the beta,

00:48:44.510 --> 00:48:50.450
which in this case is a beta of a+1,
b+1, okay.

00:48:50.450 --> 00:48:54.617
So this is gonna be gamma of a+1,

00:48:54.617 --> 00:49:00.376
gamma of b+1, divided by gamma of a+b+2.

00:49:03.654 --> 00:49:07.933
Times one because I'm multiplying and
dividing by this thing so

00:49:07.933 --> 00:49:12.040
that this is exactly integral
of the beta density.

00:49:12.040 --> 00:49:13.510
And then, right?

00:49:13.510 --> 00:49:18.710
Okay, so now let's just simplify this
thing that looks ugly with the gammas.

00:49:18.710 --> 00:49:21.150
But hopefully we can simplify it.

00:49:21.150 --> 00:49:25.790
If we remember the fact that
gamma of x+1=x gamma of x,

00:49:25.790 --> 00:49:29.680
just use that fact a bunch of times.

00:49:29.680 --> 00:49:32.540
So gamma of a+1 is a gamma of a.

00:49:33.640 --> 00:49:35.890
So this gamma of a is going to cancel.

00:49:35.890 --> 00:49:37.570
That's b gamma of b.

00:49:37.570 --> 00:49:42.318
So there's going to be a b there and
then, in the denominator,

00:49:42.318 --> 00:49:46.383
gamma of a+b.

00:49:46.383 --> 00:49:52.290
Gamma of a+b+2 is a+b+1
times gamma of a+b+1.

00:49:52.290 --> 00:49:59.220
But gamma of a+b+1 is
a plus b gamma of a+b.

00:49:59.220 --> 00:50:02.270
So that cancels.

00:50:02.270 --> 00:50:04.580
So we just get this expression
in terms of a and b.

00:50:04.580 --> 00:50:08.120
And similarly,
you can get the variance of q.

00:50:08.120 --> 00:50:13.178
Kind of the nice way to write
the variance of a beta is mu,

00:50:13.178 --> 00:50:18.500
1-mu over a+b+1 where mu
is the mean of the beta,

00:50:18.500 --> 00:50:21.515
so mu = a over a+b.

00:50:21.515 --> 00:50:24.680
You check this in exactly the same way,
okay?

00:50:24.680 --> 00:50:27.120
So then we're done with, I mean,
you can do some algebra to simplify,

00:50:27.120 --> 00:50:31.480
if I just plug those things in,
and then that's the answer.

00:50:31.480 --> 00:50:33.360
Okay, so that's all for today.

