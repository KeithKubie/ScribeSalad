WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.000
Hello, and welcome to the sixth office hours.

00:00:03.000 --> 00:00:06.000
This will be the last office hours. Let's get started.

00:00:06.000 --> 00:00:08.000
The first question comes from MJL.

00:00:08.000 --> 00:00:13.000
He wants to know how Graph SLAM deals with non-distinguishable landmarks.

00:00:13.000 --> 00:00:15.000
That's called the correspondence problem.

00:00:15.000 --> 00:00:17.000
It actually turns out to be the harder of the two problems.

00:00:17.000 --> 00:00:21.000
I gave you the problem of how to solve for known correspondence,

00:00:21.000 --> 00:00:24.000
which becomes a continuance optimization problem,

00:00:24.000 --> 00:00:27.000
but there is also a discrete problem here, which is does this lane marker correspond

00:00:27.000 --> 00:00:31.000
with this guy over here or to that guy over here? There are solutions.

00:00:31.000 --> 00:00:35.000
One of the best ones is called "ransack" where you randomly assign correspondences

00:00:35.000 --> 00:00:39.000
for three or four landmarks, solve the set of equations and then look

00:00:39.000 --> 00:00:43.000
for the best nearby matches and then fill them in.

00:00:43.000 --> 00:00:46.000
You repeat this so you can get rid of the local minima.

00:00:46.000 --> 00:00:51.000
In general, if your robot is very accurate, then just picking the nearest landmark is a good heuristic.

00:00:51.000 --> 00:00:54.000
But if you go through a huge cycle, you might just not connect,

00:00:54.000 --> 00:00:57.000
and there might be multiple ways to connect, and then you can use this ransack method

00:00:57.000 --> 00:01:00.000
to try multiple choices. &amp;gt;&amp;gt;Okay. Thanks.

00:01:00.000 --> 00:01:04.000
The next question comes from Marcello.

00:01:04.000 --> 00:01:08.000
He wants to know in a real environment we don't know the number of landmarks.

00:01:08.000 --> 00:01:12.000
In the unit it seems like we were always pretending like we knew.

00:01:12.000 --> 00:01:17.000
In, for example, the mind mapping video that you showed, how do we deal with

00:01:17.000 --> 00:01:20.000
encountering all these new landmarks?

00:01:20.000 --> 00:01:23.000
Do we not get the same problem that we had with out position measurements

00:01:23.000 --> 00:01:26.000
where this matrix just becomes unwieldy?

00:01:26.000 --> 00:01:30.000
Marcello, that's a great question, and there are many different answers I can give you.

00:01:30.000 --> 00:01:36.000
One is if we really had point landmarks the way I described them, like tree trucks or corners of rooms,

00:01:36.000 --> 00:01:39.000
you can just grow the matrix using the functions I provided to you.

00:01:39.000 --> 00:01:42.000
For every new landmark you just put a new row and a new column there.

00:01:42.000 --> 00:01:44.000
That's basically it.

00:01:44.000 --> 00:01:48.000
However, the more interesting version of your question is what is a landmark?

00:01:48.000 --> 00:01:53.000
In our mine mapping, for example, we don't make distinct features like ??? landmark.

00:01:53.000 --> 00:01:57.000
Instead what we've been doing is taking little small local maps

00:01:57.000 --> 00:02:00.000
that are defined over 5 meters of robot motion.

00:02:00.000 --> 00:02:03.000
We make these maps the basic entities.

00:02:03.000 --> 00:02:06.000
Now, it turns out there aren't any landmarks in the traditional sense,

00:02:06.000 --> 00:02:10.000
but they still have a location and you can still match them and see how they fit together.

00:02:10.000 --> 00:02:15.000
In matching them, you can make a constraint that's very much like the graph-like constraint

00:02:15.000 --> 00:02:18.000
that is like range and bearing or x and y distance.

00:02:18.000 --> 00:02:20.000
You can toss them into the same set of equations.

00:02:20.000 --> 00:02:23.000
That works really like a charm.

00:02:23.000 --> 00:02:27.000
Great. Sounds sort of like when you're stitching together those panoramic photos.

00:02:27.000 --> 00:02:32.000
Yeah. There is an entire field of people who stitch together these local images into global ones,

00:02:32.000 --> 00:02:35.000
including image stitching, panoramic stitching, and so on.

00:02:35.000 --> 00:02:39.000
They use very different methods like the 3D reconstruction of the boat Titanic

00:02:39.000 --> 00:02:44.000
that sank a hundred years ago that is done with local stitches that is being stitched together this way.

00:02:44.000 --> 00:02:48.000
If you go back all the way to Gauss 200 years ago when he invented the squares method

00:02:48.000 --> 00:02:52.000
it was basically his attempt to map the land

00:02:52.000 --> 00:02:56.000
and get these local constraints together of measurement points to make

00:02:56.000 --> 00:02:59.000
a reasonable map of our land.

00:02:59.000 --> 00:03:01.000
That's what this all dates back to.

00:03:01.000 --> 00:03:06.000
In fact, he basically invented Graph SLAM 200 years ago. He just didn't know about it.

00:03:06.000 --> 00:03:12.000
The next question comes from Emil, and he is talking about how we found all these

00:03:12.000 --> 00:03:16.000
great ways of helping our robot make intelligent decisions.

00:03:16.000 --> 00:03:19.000
But there has to be some situations where we've just hard-coded some things

00:03:19.000 --> 00:03:21.000
into, like, the Google self-driving car.

00:03:21.000 --> 00:03:24.000
Can you talk about any of those exceptions that have been hard coded in?

00:03:24.000 --> 00:03:29.000
My aspiration usually is to have no exceptions and try to come up with a single framework.

00:03:29.000 --> 00:03:32.000
The reason is in my experience every time we have an if, then, else rule

00:03:32.000 --> 00:03:35.000
where you say this is the exception and this one isn't

00:03:35.000 --> 00:03:38.000
at that border you introduce brittleness.

00:03:38.000 --> 00:03:42.000
You often get the wrong behavior because most exceptions aren't clear-cut.

00:03:42.000 --> 00:03:46.000
When I talked to my students at Stanford or my team at Google,

00:03:46.000 --> 00:03:49.000
I try to get rid of any possible if, then, else statements.

00:03:49.000 --> 00:03:51.000
Now, having said this of course there are exceptions.

00:03:51.000 --> 00:03:54.000
There are motorcycles. There are cars.

00:03:54.000 --> 00:03:59.000
It turns out cars stay in lanes, but in California--probably like the way it is in India--

00:03:59.000 --> 00:04:03.000
motorcycles tend to be like between lanes and sneak between cars.

00:04:03.000 --> 00:04:05.000
We sometimes have special rules for this.

00:04:05.000 --> 00:04:12.000
For example, we have rules that say certain crosswalks have more likely pedestrians than other crosswalks.

00:04:12.000 --> 00:04:18.000
Our car will behave differently for these crosswalks and react differently to people on the side of the street.

00:04:18.000 --> 00:04:21.000
There is a good number of those exceptions.

00:04:21.000 --> 00:04:23.000
The truth is the real world is messy.

00:04:23.000 --> 00:04:26.000
You have to really go through those one after another and try to address them.

00:04:26.000 --> 00:04:32.000
Have said this, from the mathematic perspective the fewer you have in your code the better.

00:04:32.000 --> 00:04:35.000
All right. The next question comes from Quartz.

00:04:35.000 --> 00:04:38.000
He wants to know how we use SLAM in a changing environment,

00:04:38.000 --> 00:04:41.000
and whether there is a way to forget previous landmarks and acquire new ones.

00:04:41.000 --> 00:04:47.000
Quartz is a great name. It must be non-American keyword, I guess. That's what it looks like.

00:04:47.000 --> 00:04:50.000
Changing environments--there's a very simple fix to it,

00:04:50.000 --> 00:04:56.000
which is as we added uncertainty to the robot position in our system of equations,

00:04:56.000 --> 00:04:59.000
you can do exactly the same track for landmark positions.

00:04:59.000 --> 00:05:03.000
It's a little bit cumbersome, but you could say let's make a landmark position at time T

00:05:03.000 --> 00:05:07.000
and one at time T plus 1, and the one at T plus 1 has added uncertainty,

00:05:07.000 --> 00:05:10.000
very much like the way the robot moved, but there is no motion, say.

00:05:10.000 --> 00:05:15.000
The you marginalize out the estimate of time T using the same math we talked about,

00:05:15.000 --> 00:05:21.000
and you get a new set of constraints that basically encompasses a landmark with more uncertainty.

00:05:21.000 --> 00:05:25.000
You can even toss in things like estimates of where the landmark moves by putting

00:05:25.000 --> 00:05:28.000
the velocity of the landmarks into the graph SLAM formulas

00:05:28.000 --> 00:05:32.000
and it actually carries through, it turns out. I just didn't do this.

00:05:32.000 --> 00:05:35.000
That's one way to deal with dynamic environments.

00:05:35.000 --> 00:05:39.000
The next one comes from MJL again.

00:05:39.000 --> 00:05:43.000
As a robot moves, its location uncertainty is going to increase.

00:05:43.000 --> 00:05:49.000
Is there any way to pull out this uncertainty from our omega matrix?

00:05:49.000 --> 00:05:55.000
Yes, there is. It turns out the omega matrix is the inverse covariance matrix.

00:05:55.000 --> 00:05:59.000
I didn't really talk much about this, but it is really the inverse covariance matrix.

00:05:59.000 --> 00:06:04.000
If you just invert that matrix, you get the full covariance for all of the landmarks and the robot.

00:06:04.000 --> 00:06:08.000
If you care about, say, just one landmark, you just take the corresponding

00:06:08.000 --> 00:06:11.000
columns and rows of the matrix.

00:06:11.000 --> 00:06:14.000
The next one comes from George.

00:06:14.000 --> 00:06:18.000
He wants to know what are some interesting trends in SLAM research these days.

00:06:18.000 --> 00:06:21.000
Do you think there is any good problems that you could recommend

00:06:21.000 --> 00:06:23.000
a young researcher getting involved with?

00:06:23.000 --> 00:06:27.000
Tons of good problems. There are some really fantastic working coming out of

00:06:27.000 --> 00:06:32.000
University of Washington by Steve Seitz on taking very large photo collections

00:06:32.000 --> 00:06:37.000
and tossing them into a big optimizer to build a 3D map.

00:06:37.000 --> 00:06:40.000
This is a project that is now at various universities.

00:06:40.000 --> 00:06:44.000
People go to Flickr or other online photo sites--Picassa--

00:06:44.000 --> 00:06:47.000
and they extract those photos that tourists have taken

00:06:47.000 --> 00:06:50.000
and establish correspondence, say, for buildings and so on,

00:06:50.000 --> 00:06:55.000
and then reconstruct how this object looked in dense reconstruction.

00:06:55.000 --> 00:07:01.000
That's in computer vision--often called structure from motion--and we call it SLAM in robotics.

00:07:01.000 --> 00:07:04.000
Anything having to do with dense data, like with going to Google maps, for example,

00:07:04.000 --> 00:07:09.000
and get oblique shots and ground shots from street view and aerial shots

00:07:09.000 --> 00:07:14.000
from an aerial probe or from a satellite and rectify this into a 3D model.

00:07:14.000 --> 00:07:16.000
These are basically unsolved problems.

00:07:16.000 --> 00:07:18.000
There is some really good progress, but at the moment you have bridges

00:07:18.000 --> 00:07:21.000
and underpasses and occlusion.

00:07:21.000 --> 00:07:23.000
There is a ton of opportunity.

00:07:23.000 --> 00:07:25.000
You can actually take your cell phone camera or your camera

00:07:25.000 --> 00:07:28.000
and just go through your environment and try to make a full model of your kitchen.

00:07:28.000 --> 00:07:30.000
That in itself is very, very hard.

00:07:30.000 --> 00:07:33.000
Then if you add the fact that the world might be dynamic,

00:07:33.000 --> 00:07:36.000
like objects might be deformable, like this piece of paper over here.

00:07:36.000 --> 00:07:40.000
If you want to model this in 3D, that's even harder.

00:07:40.000 --> 00:07:44.000
That's a fantastic research area that will be with us for the next, at least, 2 decades.

00:07:44.000 --> 00:07:50.000
The last question comes from Katembe.

00:07:50.000 --> 00:07:53.000
He wants to know about using landmark correlation.

00:07:53.000 --> 00:07:59.000
For example in our model of omega we assumed that 2 landmarks couldn't see each other,

00:07:59.000 --> 00:08:02.000
but in reality sometime we have some correlation between landmarks.

00:08:02.000 --> 00:08:04.000
For example, street lights come at regular intervals.

00:08:04.000 --> 00:08:07.000
Do we ever implement this, and if we did would it help?

00:08:07.000 --> 00:08:11.000
It would absolutely help. Any information you can bring to bear is good.

00:08:11.000 --> 00:08:14.000
This question is like the same question as having a multi-robot situation

00:08:14.000 --> 00:08:18.000
where multiple robots interact and move around, and they can see each other.

00:08:18.000 --> 00:08:23.000
In seeing each other, you insert a constraint that is between these two robots.

00:08:23.000 --> 00:08:25.000
If you had landmarks that either could sense each other--

00:08:25.000 --> 00:08:29.000
maybe you have wifi beacons, and they can sense each other's strength and ability

00:08:29.000 --> 00:08:36.000
or if you have external knowledge like the street view, this is super informative.

00:08:36.000 --> 00:08:41.000
The formalism falls apart when there is negative information.

00:08:41.000 --> 00:08:46.000
For example, there shall be no street lamp within a 100 foot radius of the current street lamp.

00:08:46.000 --> 00:08:52.000
The reason is these negative constraints are very hard to express in a graph-like fashion.

00:08:52.000 --> 00:08:55.000
Positive information, like this one is this far away from this guy,

00:08:55.000 --> 00:08:57.000
is much easier to express.

00:08:57.000 --> 00:09:03.000
But, yeah, in general any information you can bring to bear will help you solve these really hard problems.

00:09:03.000 --> 00:09:05.000
All right. That was the last question.

00:09:05.000 --> 00:09:10.000
Since this is the last office hours I want to say a big thank you to you, Sebastian.

00:09:10.000 --> 00:09:12.000
Thank you for you. &amp;gt;&amp;gt;And a huge thank you to the students.

00:09:12.000 --> 00:09:18.000
It's been really amazing working in the forums and helping you out with this course for the last 7 weeks.

00:09:18.000 --> 00:09:21.000
I know I've learned a lot, and I hope you guys have too.

00:09:21.000 --> 00:09:23.000
And I learned a lot. I really love your questions.

00:09:23.000 --> 00:09:27.000
I love you interact. I love hanging out in the forum in the evenings.

00:09:27.000 --> 00:09:31.000
I hope you guys learned a lot, and I hope these office hours and the course

00:09:31.000 --> 00:09:36.000
enrich your lives and empower you to do things you've never done before.

