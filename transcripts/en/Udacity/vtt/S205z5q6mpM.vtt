WEBVTT
Kind: captions
Language: en

00:00:00.034 --> 00:00:03.106
Now allocating and transferring memory is pretty straight forward.

00:00:03.106 --> 00:00:06.283
The interesting part of GPU computing is defining the computation

00:00:06.283 --> 00:00:07.911
that actually happens on the GPU.

00:00:07.911 --> 00:00:11.615
We structure that computation as a series of one or more kernels.

00:00:11.615 --> 00:00:16.050
Now as we said earlier, the GPU has lots of parallel computation units.

00:00:16.050 --> 00:00:19.922
When you write kernels, those kernels need to take advantage of that hardware parallelism.

00:00:19.922 --> 00:00:23.394
So how do they do that? And here is the big idea.

00:00:23.394 --> 00:00:26.087
It is one of the very core concepts of CUDA.

00:00:26.087 --> 00:00:31.199
As a programmer, when you write a kernel, you write what looks like a serial program.

00:00:31.199 --> 00:00:35.473
You write this program as if it runs on a single thread.

00:00:35.473 --> 00:00:41.018
Then when you call the kernel from the CPU, you tell it how many threads to launch,

00:00:41.018 --> 00:00:44.147
and each of those threads will run this kernel.

00:00:44.147 --> 00:00:48.140
It is perfectly okay to write a kernel and then tell the GPU.

00:00:48.140 --> 00:00:51.318
Okay, when you start running this kernel, launch 100,000.

00:00:51.318 --> 00:00:56.365
Launch a million. Launch 10 million threads, each of which will run this kernel code.

00:00:56.365 --> 00:01:02.230
You can and will kick off an enormous amount of computation each time you launch a kernel.

00:01:02.230 --> 00:01:06.467
Now, we haven't covered this yet, but you might be able to make a good guess.

00:01:06.467 --> 00:01:09.803
Given this programming model, what is the GPU good at?

00:01:09.803 --> 00:01:11.172
Check all that apply.

00:01:11.172 --> 00:01:14.140
Launching a small number of threads efficiently.

00:01:14.140 --> 00:01:16.377
Launching a large number of threads efficiently.

00:01:16.377 --> 00:01:18.538
Running one thread very quickly.

00:01:18.538 --> 00:01:21.644
Running one thread that does lots of work in parallel.

00:01:21.644 --> 00:01:24.575
Or running a large number of threads in parallel.

