Speaker 1:          00:00          The Joe Rogan experience. So what do you picture like, cause we have to look at Boston dynamics robots. Cause you said walking around. Yeah, I'd like to get to a sense of how you think about, and maybe I can talk about too where the technology is of what that artificial intelligence looks like in 20 years. In 30 years, they'll surprise you. So you have a sense that it has a humanlike form.

Speaker 2:          00:28          No, I have a sense that it's going to take on the form the same way the automobile has. If you go back and look at it like CTE has a CT, Fletcher has a um, beautiful old patina pickup truck. What do you say it was from like 58 or some shit 60 anyway. Old Ass cool. Heavy metal, you know those sweeping round curves, those old school pickup trucks had now look at that and look at a Tesla roadster. What in the fuck happened when the fuck happened? I'll tell you what happened. They got better and better and better at it. They figured out the most effective shape. If you want a motherfucker to boot that, that, that little car. Have you seen that video where they have the Tesla roadster in a drag race or in a race against a Nissan Gtr? It's a simulated video, but it's based on the actual horsepower of each car.

Speaker 2:          01:19          I don't know if you've ever driven a Nissan Gtr, but it is a fucking insane car. It's insane. This is a, um, a CGI version of what it would look like if these two cars raised against each other. So the car on the, the Nissan Gtr do it from the beginning, their coast. Look how fast this thing pulls away. The Nissan GTR is fucking insanely fast man. Insanely fast. But this Tesla is so on another level, it's so in the future that it's not even close. As the video gets further and further, you see how ridiculous it is? It's essentially lapping that car. It's going to go

Speaker 1:          01:57          look how far away it is. Bye. See Ya. So the, you're saying the human races will be the Nissan here. Exactly. Then

Speaker 2:          02:03          we're not even going to be the Nissan. We're going to be CT Fletcher's pickup truck. This is the future. There's not gonna be any limitations in terms of bipedal form or wings or not having wings. If you can walk on it. I mean there's not gonna be any of that shit there and we might have a propulsion system or it might, it's not going to be us. And they might, they might design some sort of organic propulsion system like the way squid have and shit. Who the fuck knows?

Speaker 1:          02:28          They could also operate in the space of language and ideas. So for example, I don't know if you're familiar with, you know, open Ai, it's a company they created a system called gpt to which does language modeling. This is something in machine learning where you basically unsupervised let the system just read a bunch of texts and then learns to generate new texts and they've created this system called gpt to that is able to generate very realistic texts. A very realistic sounding text, not sounding, but when you read it, it makes, it seems like a person. It seems like a person. And the question there is, it raises a really interesting question. So talking about AI existing in our world, it, it paints a picture of a world in five, 10 years plus where most of the texts on the Internet is generated by Ai. And it's very difficult to know who's real and who's not.

Speaker 1:          03:23          And one of the interesting things, I'd be curious from your perspective to get what your thoughts I, what open AI did is they didn't release the code for the full system. They only released a much weaker version of it publicly. So they only demonstrated it. And so they felt that it was their responsibility to hold back. Prior to that date, everybody in the community, including them, had open sourced everything. But they felt that now at this point, part of it whiffs for publicity they wanted to raise the question is, when do we hold back on these systems when they're so strong, when they're so good at generating texts? For example, in this case or at deep fakes at uh, generating fake Joe Rogan faces. Jamie just did one you showed me earlier, Donald Trump's head. Yeah, it's crazy. And this is something that Jamie can do. He's not even a video editor.

Speaker 1:          04:16          Yeah. We were talking about it before the show. We could go crazy if you want. It is one of those things where you go, where is this going to be in five years? Because five years ago we didn't have anything like this. Five years ago was a joke. Right, exactly. And then now it's still in the gray area between joke and something that could be at scale transformed the way we communicate. Do you ever go to Kyle Donovan's Instagram page? Of course, one of the best look at that's made, it's killing me. It's killing me. This is, and that it looks so much like I'm really talking and it looks like what I would look like if I was fat and it could, you know, of course that's really good and that it could be improved significantly and it can make you say anything. So there's a lot of variants of this.

Speaker 1:          05:06          Yeah. We can take, like for example, uh, full disclosure, I downloaded your face the entire like have a data set or your face. I'm sure other hackers do as how dare you. Yeah. So, uh, for this exact purpose, I mean, if I'm thinking like this and I'm very busy, then there's other people doing exactly this for sure. Because you happen, your podcasts happens to be one of the biggest data sets in the world of people talking and really high quality audio with high quality 10 80 p for most, for a few hundred episodes of people's faces. The lighting could be better, not quite as we're making it degraded. Hackers and the Mike gets in, it blocks part of your face from the top. And that's right. So the best guest of the ones where they keep the mic love the defect stuff I've been using removes the microphone within about a thousand iterations. It does. It instantly,

Speaker 2:          05:58          it gets the, gets rid of it paints over the face. Wow. Yeah. So, so you could basically make Joe Rogan say anything that, I think this is just one step before they finagle us into having a nuclear war against each other so they could take over the earth. What they're going to do is they're gonna design artificial intelligence that survives off of nuclear waste. And so then they encourage these stupid assholes to, uh, go into a war with North Korea and Russia and we blow each other up, but we leave behind all this precious radioactive material that they use to them fashion, their new world. And we'd come a thousand years from now and it's just fucking beautiful and pristine with artificial life everywhere. No more, no more biological. It was too messy. Are you saying the current president is artificial life? I didn't say that. Okay. Which is that with that, cause you're saying start nuclear war?

Speaker 2:          06:46          No, I don't think so. He said there's, imagine if they did do that, they would have to started with him in the 70s I mean he's been around for a long time and talking about being president for a long time, maybe electronics have been playing the long game and they got him to the position and then they get to use all this grand scale of time. It's not really long game seventies well you know all about that Internet research agency. Right. You know about that? Uh, that's the Russian company that, uh, they're responsible for all these different Facebook pages where they would make people fight against each other. It was really, it's really kind of interesting. Um, Sam Harris had a podcast on it with, um, Renee, how do I say her name? Renee de Resta. And uh, then she came on our podcast and talked about it as well.

Speaker 2:          07:32          And they were, they were pitting these people against each other. Like they would have a, a pro Texas secession rally and directly across the street from a pro Muslim rally. And they would do it on purpose and they would have these people meet there and get angry at each other and they would, they would pretend to be a black lives matter page. They would pretend to be a white southern pride page and they were just trying to make people angry at people. Now that's human driven manipulation. Yeah. Now imagine this is my biggest way of AI is what Jack is working on is that algorithm driven manipulation of people unintentional trying to do good, but like those people, uh, Jack needs to do some Jujitsu. I used to be, it needs to be some open minded, uh, you know, uh, like really understand society transparency to where they can talk to us is uh, uh, to the people in general how they're thinking about, uh, uh, managing these conversations. Because you talk about these groups, very small number of Russians are able to control very large amounts of other people's opinions and arguments. Yeah. An algorithm can do that. 10 X, Oh yeah. More and more of us will go on Twitter and Facebook and, sure. Yeah, for sure. I think it's coming. I think, um, once people figured out how to manipulate that effectively and really

Speaker 1:          08:56          create like an army of fake bots that will assume stances on a variety of different issues and just argue into infinity, we were not going to know. We're not going to know who's real and who's not. Well, it'll change the nature of our communication online. I think it might, it might have affects this. This is the problem, the future. It's hard to predict the future. It might have affects where we'll stop taking anything online. Seriously. Yeah. And we might get retract back to communicating in person more. I mean, there, there could be effects that we're not anticipating totally. And there might be some, at some ways in virtual reality we can authenticate our identity butter. So it will change the nature of communication. I think the more, the more you can generate fake text, uh, than the more the will distrust the information online. And the way that changes society is totally an open question.

Speaker 1:          09:53          We don't know. But your, um, what are your thoughts about the open AI? Do you think they should release or hold back on it? Because this is, we're talking about Ai. So artificial life, there's stuff you're concerned about. Some company will create it. The question is what does the responsibility of that, uh, short video where it looks like when it, this type of small paragraph in here hit a button. It says how open AI rights, what was it today? What did say Jimmy and signature stories. Okay, so you give it a desserty across the UK economy at least 80 billion since, and then many industry actually believe so much time. So they just, it just fills in those things. Yeah. So basically you give it, you start the text, oh well can say, uh, Joe Rogan experience is the greatest podcast ever. And then let it finish the rest and it'll start explaining stuff about why it's the greatest podcast.

Speaker 1:          10:47          Is it accurate? Oh look at this, it says a move that threatens to push many of our most talented young brains out of the country, not to campuses in the developing world. This is a particularly costly blow research by Oxford University warns that the UK would have to spend nearly 1 trillion on post-Brexit infrastructure. That's crazy that that's all done by an AI that's like spelling this out in this very convincing argument. The thing is the, the way it actually works, algorithmic is fascinating cause this January is generating it one character at a time. It has, as far as, you know, you don't want to discriminate against the AI, but as far as we understand, it doesn't have any understanding of what it is to have, what it's doing. If any ideas it's expressing, it's simply stealing idea. It's like the largest scale plagiarizer of all time. Right. It's basically just pulling out ideas from elsewhere in an automated way. And the question is, you could argue us humans are exactly that were just really good plagiarize years of what our parents taught us of what our previous so on. Uh, yeah, we are for sure. Yeah. So

Speaker 2:          11:53          the, the question is whether you hold that back, they, their decision was to say, uh, let's hold it. Let's not release it. That scares me to not release it. Yeah. Yeah. You know why it scares me. It scares me that they would think that that's like this mindset that they, they sensed the inevitable, the inevitable, meaning that someone's gonna come along with a version of this, it's going to be used for evil, but it bothers him that much. That seems so, it seems almost irresponsible for the technology to prevail for the technology to, to continue to be more and more powerful. Yeah. They scared of it. They're scared of it getting out, right. Yeah. That's scares the shit out of me. Like if they're scared of it, they're the people that make it and there they are called open Ai. I mean, this is the idea behind the group where everybody kind of agrees that you're going to use the brightest minds and have this open source.

Speaker 2:          12:47          Everybody can understand it and everybody work at it and you don't miss out on any genius contributions. And they're like, no, no, no, no, no more. And there obviously their system currently is not that dangerous. They're not dangerous. Well not, yes, not that dangerous that if you just saw that, that it can do that. But if you think through like what that would actually create, I mean, it's possible. It will be dangerous, but it's not the, the point is they're doing it. They try to do it early. Right. To raise the question, what do we do here? Because yeah, what do we do? Because they're directly going to be able to improve this. Now. Like if, if there, if we can generate basically a 10 times more content of your face saying a bunch of stuff, uh, what does that, what do we do with that?

Speaker 2:          13:33          If, if a Jamie all of a sudden on the side develops a much better generator and has your face, does an offshoot podcast essentially fake Joe Rogan experience and what do we do to, does he release that? You know, does he, because now we can have, uh, basically generated content and a much larger scale that will just be completely fake. Well, I think what they're worried about is not just generating content that's faked or they're worried about manipulation of opinion. Right? Right. If they have all these people that are like that, that little sentence that led to that enormous paragraph in that video was just a sentence that showed a certain amount of outrage and then it led him, Phil let the AI fill in the blanks. Yes, you could do that with fucking anything. Like you could just set those things loose. If they're that good and that convincing and they're that logical man, this is, this is not real. I'll just tell you, Ben Shapiro all creates Ai, creates fake Ben Shapiro. Get the sound. Sorry.

Speaker 3:          14:39          She has boards. How Other? This is a fake Ben Shapiro with this technology, they can make me say anything such as, for example, I love socialism. Healthcare is a right, not just a privilege. It ending will solve crime.

Speaker 2:          14:52          Facts. Care about your feelings. I support Bernie Sanders. Okay. Yeah. Yeah. That's crazy. It's crude, but it's crude, but it's on the way. Yeah, it's on the way. It's all in the way and we have to. This is the time to talk about it. This is the time to think about it. One of the funny things about Kyle Donovan's Instagram was that it's obviously fake. That's one of the funny things about it. It's like South Park's animation. It's like the animation sucks. That's half the reason why it's so funny cause they're just like the circles. You know, these weird looking creature things. Then we went and won the Canadians when their heads pop off at the top. And, and, uh, my, my hope is this kind of technology will ultimately just be used from memes as opposed to something that's going to get wars. Putin is going to be, he's going to be a bang and Mother Teresa on the White House desk in a video. We're going to be outraged. We're going really go to war over this shit.