WEBVTT
Kind: captions
Language: en

00:00:00.380 --> 00:00:03.650
You are now ready to connect the graph
Laplacian, its eigenvalues and

00:00:03.650 --> 00:00:05.840
eigenvectors and graph partitioning.

00:00:05.840 --> 00:00:07.950
But first some handy facts.

00:00:07.950 --> 00:00:09.930
I'll just state these without proof.

00:00:09.930 --> 00:00:13.080
If you need that,
please see the paper by Pothen et al,

00:00:13.080 --> 00:00:15.050
posted in the instructors notes.

00:00:15.050 --> 00:00:18.090
The first key fact is that
the Laplacian is symmetric.

00:00:18.090 --> 00:00:20.040
This follows from its definition.

00:00:20.040 --> 00:00:23.260
An important consequence of
this fact is the second fact.

00:00:23.260 --> 00:00:27.462
The eigen values of the Laplacian
will be real-valued and non-negative.

00:00:27.462 --> 00:00:30.820
I say real-valued as
opposed to complex-valued.

00:00:30.820 --> 00:00:33.530
The Laplacian's eigen vectors
will also be real-valued.

00:00:33.530 --> 00:00:35.620
And we can define them to be orthogonal.

00:00:35.620 --> 00:00:38.190
If you've forgotten what
an eigenvalue and eigonvector are,

00:00:38.190 --> 00:00:39.920
here's a quick reminder.

00:00:39.920 --> 00:00:42.520
Eigenvalues and eigenvectors are paired.

00:00:42.520 --> 00:00:45.570
Let's let land to i and
Q sub i be an eigenvalue and

00:00:45.570 --> 00:00:48.720
an eigenvector respectively of L of G.

00:00:48.720 --> 00:00:52.900
And the following holds,
multiply L of G by it's eigenvector

00:00:52.900 --> 00:00:55.540
gives you a scaled version
of the eigenvector.

00:00:55.540 --> 00:00:57.900
The scaling factor is the eigenvalue.

00:00:57.900 --> 00:01:04.708
You can also write this differently in
matrix form, L(G) Q = Q times lambda.

00:01:04.708 --> 00:01:07.180
Q and lambda are matrices.

00:01:07.180 --> 00:01:11.530
In particular, the columns of Q
are the eigenvectors of L(G).

00:01:11.530 --> 00:01:16.530
Lamb dot is a diagonal matrix where all
the eigen values sit on the diagonal.

00:01:16.530 --> 00:01:18.710
What about this orthogonal bit?

00:01:18.710 --> 00:01:21.750
Orthogonality tells us that
the dot product between any

00:01:21.750 --> 00:01:24.650
pair of eigen vectors will be
zero if they're different.

00:01:24.650 --> 00:01:26.520
Or one if they're the same.

00:01:26.520 --> 00:01:28.030
In more compact matrix notation,

00:01:28.030 --> 00:01:31.590
Q transposed times Q is
the identity matrix.

00:01:31.590 --> 00:01:34.400
Now what about this
non-negative eigen values bit?

00:01:34.400 --> 00:01:38.040
That tells us that all the eigen
values are at least zero.

00:01:38.040 --> 00:01:42.500
Now a common convention is to assume
that we can sort the eigen values So

00:01:42.500 --> 00:01:43.890
let's do that too.

00:01:43.890 --> 00:01:46.110
We'll let the eigenvalues
with the smaller indices,

00:01:46.110 --> 00:01:48.240
be the smaller eigenvalues.

00:01:48.240 --> 00:01:51.010
So in this case,
lambda0 is the smallest eigenvalue, and

00:01:51.010 --> 00:01:53.210
lambda1 is the second smallest.

00:01:53.210 --> 00:01:56.490
Now here's a third fact which
I find especially interesting.

00:01:56.490 --> 00:01:59.200
It says that the graph G has
K connected components if and

00:01:59.200 --> 00:02:03.431
only if the K smallest
values are identically zero.

00:02:03.431 --> 00:02:05.700
This is a fact due to Fiedler.

00:02:05.700 --> 00:02:08.610
And when I first learned this fact,
I was like, wow..

00:02:08.610 --> 00:02:14.550
I mean omg wow, like seriously,
as in srsly seriously.

00:02:15.560 --> 00:02:17.050
It's a cool fact because it says,

00:02:17.050 --> 00:02:20.580
the graph laplacian spectrum,
meaning it's eigen values,

00:02:20.580 --> 00:02:24.500
tells us something about the underlying
connectivity of the graph.

00:02:24.500 --> 00:02:26.560
Here's one more important fact.

00:02:26.560 --> 00:02:29.730
Let's say you have a graph that's
been partitioned into two pieces,

00:02:29.730 --> 00:02:33.520
one piece is the plus piece, and
the other piece is the minus piece.

00:02:33.520 --> 00:02:36.852
Let's let v plus be the set of
vertices in the plus piece and

00:02:36.852 --> 00:02:41.348
v minus the set of vertices in the minus
piece, now this is all graph language.

00:02:41.348 --> 00:02:43.510
What about the linear algebra side?

00:02:43.510 --> 00:02:47.190
Let’s define a vector x with
respect to this partition.

00:02:47.190 --> 00:02:50.790
Each entry of x will correspond
to a particular vertex.

00:02:50.790 --> 00:02:55.260
We’ll assign that entry a positive
one if the vertex lies in V plus and

00:02:55.260 --> 00:02:58.020
a minus one if the vertex is in V minus.

00:02:58.020 --> 00:03:01.030
Now, suppose you want to count
the number of edges that are being

00:03:01.030 --> 00:03:02.850
cut in the graph.

00:03:02.850 --> 00:03:05.330
This leads us to our fourth fact.

00:03:05.330 --> 00:03:07.986
The number of cut edges is this product.

00:03:07.986 --> 00:03:11.570
One-fourth x transpose L times x.

00:03:11.570 --> 00:03:13.500
This fact is also very nice.

00:03:13.500 --> 00:03:16.050
It says that if you want
to minimize edge cuts,

00:03:16.050 --> 00:03:18.860
you should try minimizing this product.

00:03:18.860 --> 00:03:21.780
Okay, so
let's quickly summarize the four facts.

00:03:21.780 --> 00:03:23.740
Take a moment to digest them.

00:03:23.740 --> 00:03:26.868
Once you've done so, you're ready for
the spectral partitioning algorithm.

