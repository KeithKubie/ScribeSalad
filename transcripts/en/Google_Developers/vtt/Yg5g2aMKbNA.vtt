WEBVTT
Kind: captions
Language: en

00:00:05.559 --> 00:00:06.850
PARISA TABRIZ: All right, cool.

00:00:06.850 --> 00:00:09.560
So hello everyone.

00:00:09.560 --> 00:00:10.210
Welcome.

00:00:10.210 --> 00:00:11.680
This is really exciting.

00:00:11.680 --> 00:00:13.745
I am I'm very happy to
see so many people that

00:00:13.745 --> 00:00:15.570
are interested in security.

00:00:15.570 --> 00:00:17.010
So my name's Parisa.

00:00:17.010 --> 00:00:19.130
Peter, thanks for the
awesome introduction.

00:00:19.130 --> 00:00:23.090
And I get the honor of being
the master of ceremonies,

00:00:23.090 --> 00:00:26.300
and to kick off our
security themed evening.

00:00:26.300 --> 00:00:30.070
So we titled this event web
security, attack, defend,

00:00:30.070 --> 00:00:31.160
and profit.

00:00:31.160 --> 00:00:33.300
And myself and the
next three speakers

00:00:33.300 --> 00:00:35.660
are going to each
touch on those topics.

00:00:35.660 --> 00:00:37.090
So I work at Google.

00:00:37.090 --> 00:00:40.460
And some of you may be
familiar with our company

00:00:40.460 --> 00:00:42.855
motto, which is, don't be evil.

00:00:42.855 --> 00:00:46.690
On the security team we
extend that to, don't be evil,

00:00:46.690 --> 00:00:49.150
but do know evil.

00:00:49.150 --> 00:00:51.630
And I'm going to
use this short intro

00:00:51.630 --> 00:00:53.310
to talk a little bit
about why I think

00:00:53.310 --> 00:00:55.160
it's really important
for developers

00:00:55.160 --> 00:00:59.760
to occasionally embrace
the attacker mindset.

00:00:59.760 --> 00:01:03.100
So I've worked at Google for
a little over seven years.

00:01:03.100 --> 00:01:05.190
Currently I manage the
Chrome security team.

00:01:05.190 --> 00:01:08.840
But when I started at
Google I was an engineer

00:01:08.840 --> 00:01:12.400
in what we call the
hired hacker team.

00:01:12.400 --> 00:01:14.850
And we had this broad
mission of doing whatever

00:01:14.850 --> 00:01:18.200
we could to improve the security
of Google's web applications.

00:01:18.200 --> 00:01:20.610
At the time, Google was
just a web app company.

00:01:20.610 --> 00:01:23.640
Today we dabble in other things.

00:01:23.640 --> 00:01:25.760
So one of the core
functions of this team

00:01:25.760 --> 00:01:31.170
was to do information security
consulting, security design,

00:01:31.170 --> 00:01:32.500
penetration testing.

00:01:32.500 --> 00:01:35.190
And these are just
fancy ways of saying,

00:01:35.190 --> 00:01:37.500
our job was to
break the software

00:01:37.500 --> 00:01:41.000
that all of the other Google
engineers were building.

00:01:41.000 --> 00:01:43.320
We were trying to find holes.

00:01:43.320 --> 00:01:47.220
Ways to exploit the apps
that the people doing then

00:01:47.220 --> 00:01:50.500
didn't think was possible or
didn't necessarily intend,

00:01:50.500 --> 00:01:53.700
with the long term goal
of actually finding ways

00:01:53.700 --> 00:01:55.730
to defend against that.

00:01:55.730 --> 00:02:00.020
So in particular, we would try
to achieve some goal like theft

00:02:00.020 --> 00:02:05.760
of information or assets, being
able to hijack some account

00:02:05.760 --> 00:02:09.020
credentials and log into
an account we didn't own,

00:02:09.020 --> 00:02:11.842
because this is a thread
we were and still are

00:02:11.842 --> 00:02:13.050
most worried about at Google.

00:02:15.610 --> 00:02:19.740
So as a developer, all of
you build applications.

00:02:19.740 --> 00:02:21.970
This is a picture
from prior event.

00:02:21.970 --> 00:02:23.790
And you all are
good people, and you

00:02:23.790 --> 00:02:26.480
have the purest of intentions.

00:02:26.480 --> 00:02:30.340
You create useful and
delightful applications

00:02:30.340 --> 00:02:33.230
that make the world and
internet a better place.

00:02:33.230 --> 00:02:35.510
And honestly, you
have my admiration.

00:02:35.510 --> 00:02:37.390
Because it is so
much harder to build

00:02:37.390 --> 00:02:40.520
robust and secure applications,
and software, than it

00:02:40.520 --> 00:02:42.620
is to break them and find holes.

00:02:42.620 --> 00:02:45.230
So you have my admiration
and my gratitude.

00:02:45.230 --> 00:02:49.180
But the world is not only
filled with your kind.

00:02:49.180 --> 00:02:52.700
And there are bad
guys, and bad girls,

00:02:52.700 --> 00:02:56.020
that want to break your
applications and abuse holes

00:02:56.020 --> 00:03:00.340
in your software, and attack
your users for personal profit

00:03:00.340 --> 00:03:00.997
or gain.

00:03:00.997 --> 00:03:02.830
And these are the people
that I worry about.

00:03:02.830 --> 00:03:06.430
I worry about them
both as a user myself,

00:03:06.430 --> 00:03:09.840
and on behalf of the users
of the software projects

00:03:09.840 --> 00:03:12.240
that I'm involved with.

00:03:12.240 --> 00:03:16.050
So to pull from my
copious knowledge

00:03:16.050 --> 00:03:18.500
of ancient Chinese
military strategy,

00:03:18.500 --> 00:03:22.200
I'm going to quote a
famous general, Sun Tzu,

00:03:22.200 --> 00:03:25.950
and say, "To know your enemy,
you must become your enemy."

00:03:25.950 --> 00:03:28.620
So if my personal experience
working in software

00:03:28.620 --> 00:03:34.210
is worth anything, it's
that having experience

00:03:34.210 --> 00:03:37.100
in breaking software and knowing
how to practically exploit

00:03:37.100 --> 00:03:42.450
software will make you a better
developer of secure software.

00:03:42.450 --> 00:03:45.190
It's one of the strongest
foundations you can have.

00:03:45.190 --> 00:03:48.300
And I know that everybody here
wants to build secure software.

00:03:48.300 --> 00:03:55.010
So take the black hat on, and
embrace the attacker mindset

00:03:55.010 --> 00:03:57.120
for a moment.

00:03:57.120 --> 00:04:01.660
So as I said, to
start the night off,

00:04:01.660 --> 00:04:04.190
I want you to think about
breaking the software you use.

00:04:04.190 --> 00:04:06.040
Breaking to suffer you write.

00:04:06.040 --> 00:04:07.400
Find the holes.

00:04:07.400 --> 00:04:08.980
Find the weaknesses.

00:04:08.980 --> 00:04:10.640
And think of ways to exploit it.

00:04:10.640 --> 00:04:13.040
Because I can assure
you that if you're

00:04:13.040 --> 00:04:15.615
working on anything that's
successful or interesting,

00:04:15.615 --> 00:04:17.240
other people will be
trying to do that.

00:04:17.240 --> 00:04:20.060
So you may as well.

00:04:20.060 --> 00:04:24.180
Only after you've totally tried
to break a piece of software

00:04:24.180 --> 00:04:26.520
can you really have
confidence in its robustness

00:04:26.520 --> 00:04:28.930
and its security.

00:04:28.930 --> 00:04:31.210
So we have a training
for engineers at Google

00:04:31.210 --> 00:04:32.850
that encourages this
attacker mindset.

00:04:32.850 --> 00:04:36.180
And we often start off with
a non-software example.

00:04:36.180 --> 00:04:39.840
I want to start us
off in the same way.

00:04:39.840 --> 00:04:45.460
Suppose I tasked you with trying
to rip off a vending machine.

00:04:45.460 --> 00:04:48.470
This vending machine, it's
in a large and crowded area.

00:04:48.470 --> 00:04:50.360
We'll say it's an airport.

00:04:50.360 --> 00:04:52.040
And I want you to get
out as many snacks

00:04:52.040 --> 00:04:55.010
as you can for as little cost.

00:04:55.010 --> 00:04:56.630
And do it without
getting caught.

00:04:56.630 --> 00:04:59.414
So what would you do?

00:04:59.414 --> 00:05:01.304
AUDIENCE: Walk up with a key.

00:05:01.304 --> 00:05:02.720
PARISA TABRIZ:
Walk up with a key.

00:05:02.720 --> 00:05:04.974
Where are you
getting a key from?

00:05:04.974 --> 00:05:06.830
AUDIENCE: [INAUDIBLE]
it might change,

00:05:06.830 --> 00:05:08.770
but social engineer
somebody else [INAUDIBLE].

00:05:08.770 --> 00:05:09.520
PARISA TABRIZ: OK.

00:05:09.520 --> 00:05:10.760
Social engineering.

00:05:10.760 --> 00:05:11.590
I like it.

00:05:11.590 --> 00:05:15.590
Usually abusing the weakest
link, which unfortunately

00:05:15.590 --> 00:05:20.480
sometimes is the
human, is successful.

00:05:20.480 --> 00:05:21.420
So good answer.

00:05:21.420 --> 00:05:22.442
What else?

00:05:22.442 --> 00:05:23.828
AUDIENCE: Use a brick.

00:05:23.828 --> 00:05:24.749
[LAUGHTER]

00:05:24.749 --> 00:05:25.540
PARISA TABRIZ: Yes.

00:05:25.540 --> 00:05:28.547
The sledgehammer attack
is often effective.

00:05:28.547 --> 00:05:30.380
I want something a
little bit more stealthy.

00:05:30.380 --> 00:05:31.879
AUDIENCE: Tell
security that there's

00:05:31.879 --> 00:05:33.040
a bomb inside the airport.

00:05:33.040 --> 00:05:33.790
PARISA TABRIZ: Oh.

00:05:33.790 --> 00:05:37.313
Let's-- I saw one hand.

00:05:37.313 --> 00:05:40.540
AUDIENCE: Dress up as
a maintenance person,

00:05:40.540 --> 00:05:42.899
turn the machine on its side.

00:05:42.899 --> 00:05:43.940
Take out the [INAUDIBLE].

00:05:43.940 --> 00:05:45.690
PARISA TABRIZ: How do
you turn the machine on?

00:05:45.690 --> 00:05:46.830
AUDIENCE: No, on its side.

00:05:46.830 --> 00:05:50.090
PARISA TABRIZ: Oh, turn
the machine on-- OK.

00:05:50.090 --> 00:05:52.130
Sure.

00:05:52.130 --> 00:05:54.241
We'll do-- Yeah.

00:05:54.241 --> 00:05:55.157
AUDIENCE: Make a coin.

00:05:55.157 --> 00:05:57.310
Make a counterfeit coin.

00:05:57.310 --> 00:05:58.290
PARISA TABRIZ: OK.

00:05:58.290 --> 00:06:00.220
Counterfeit coin, I like.

00:06:00.220 --> 00:06:06.660
I actually have an image that--
this is my favorite attack.

00:06:06.660 --> 00:06:09.440
If you search
online, there is tons

00:06:09.440 --> 00:06:12.620
of resources on how to
hack into vending machines.

00:06:12.620 --> 00:06:15.190
So there's resources
for how to abuse

00:06:15.190 --> 00:06:16.380
the mechanical components.

00:06:16.380 --> 00:06:20.040
And you can look up
the specific manual

00:06:20.040 --> 00:06:22.630
for all of these different
vending machines.

00:06:22.630 --> 00:06:27.330
You can find ways to abuse
the programming logic.

00:06:27.330 --> 00:06:30.410
And even the
electrical components.

00:06:30.410 --> 00:06:33.530
So, I have not
verified any of these.

00:06:33.530 --> 00:06:35.400
I have no guarantee
that squirting salt

00:06:35.400 --> 00:06:37.840
water in the coin
slot of a soda machine

00:06:37.840 --> 00:06:39.470
will create an
electrical current that

00:06:39.470 --> 00:06:40.470
can result in free soda.

00:06:40.470 --> 00:06:42.803
I'm kind of doubting that
one, but this is the internet.

00:06:42.803 --> 00:06:44.570
So who knows what to believe?

00:06:44.570 --> 00:06:46.870
So someone suggested
counterfeit coins.

00:06:46.870 --> 00:06:50.430
And this is actually one
of my favorite approaches.

00:06:50.430 --> 00:06:54.650
It involves currency where
there is similar blanks,

00:06:54.650 --> 00:06:58.490
or minting techniques, used for
multiple different currencies.

00:06:58.490 --> 00:07:00.180
International currencies.

00:07:00.180 --> 00:07:03.280
This is a picture of
the two Euro coin,

00:07:03.280 --> 00:07:09.010
which is worth
approximately $2.70.

00:07:09.010 --> 00:07:10.680
US dollars.

00:07:10.680 --> 00:07:13.620
And here are a
couple of pictures

00:07:13.620 --> 00:07:16.820
of coins that have successfully
fooled vending machines,

00:07:16.820 --> 00:07:19.201
and are worth vastly less.

00:07:19.201 --> 00:07:21.575
So we have the Thai baht at
about an eighth of the value.

00:07:21.575 --> 00:07:23.710
The Mexican peso,
the Philippine peso.

00:07:23.710 --> 00:07:27.470
There's actually a lot more
that have a very similar blank.

00:07:27.470 --> 00:07:30.660
Coincidentally, I actually
was in Germany last week,

00:07:30.660 --> 00:07:34.650
and I only realized
at the end of my trip

00:07:34.650 --> 00:07:37.650
that someone had actually
given me a Thai baht, probably

00:07:37.650 --> 00:07:39.480
as change at some
point during my trip.

00:07:39.480 --> 00:07:42.960
Because I tried
paying for a snack,

00:07:42.960 --> 00:07:46.790
and the cashier gave me
this really nasty look like,

00:07:46.790 --> 00:07:47.790
this is not a two Euro.

00:07:47.790 --> 00:07:51.840
So I can attest from first
hand that these attacks,

00:07:51.840 --> 00:07:55.580
if not successful on a vending
machine, at least worked on me.

00:07:55.580 --> 00:07:59.290
So, to be clear, I'm not
advocating that you go and rip

00:07:59.290 --> 00:08:01.620
off vending machines.

00:08:01.620 --> 00:08:04.440
Happily I think we have tons
of food if you're hungry,

00:08:04.440 --> 00:08:07.050
and tons of booze.

00:08:07.050 --> 00:08:10.150
And apologies to people
on the live stream.

00:08:10.150 --> 00:08:14.060
But thinking through
possible ways

00:08:14.060 --> 00:08:17.300
to attack a system,
whether it's a vending

00:08:17.300 --> 00:08:21.340
machine or a piece of
software, will certainly

00:08:21.340 --> 00:08:23.500
help you build in
better defenses

00:08:23.500 --> 00:08:26.450
to some of those
threats and attacks.

00:08:26.450 --> 00:08:28.080
And that's what
I'm encouraging you

00:08:28.080 --> 00:08:32.309
to do as you build software.

00:08:32.309 --> 00:08:34.627
So I don't know
if anybody in here

00:08:34.627 --> 00:08:35.960
actually makes vending machines.

00:08:35.960 --> 00:08:38.679
I assume you care
about web applications.

00:08:38.679 --> 00:08:41.309
So we want to talk about
hacking web applications.

00:08:41.309 --> 00:08:45.552
Has anyone heard of any common
types of web security bugs?

00:08:45.552 --> 00:08:47.280
AUDIENCE: SQL injection.

00:08:47.280 --> 00:08:48.830
PARISA TABRIZ: SQL injection.

00:08:48.830 --> 00:08:49.660
Anything else?

00:08:49.660 --> 00:08:52.200
Cross site scripting.

00:08:52.200 --> 00:08:52.880
CSRF.

00:08:52.880 --> 00:08:54.650
What does CSRF stand for?

00:08:54.650 --> 00:08:56.690
AUDIENCE: Cross site
request forgery.

00:08:56.690 --> 00:08:58.440
PARISA TABRIZ: Cross
site request forgery.

00:08:58.440 --> 00:09:00.490
Awesome.

00:09:00.490 --> 00:09:00.990
DDOS.

00:09:00.990 --> 00:09:03.511
Distributed denial
of service attack.

00:09:03.511 --> 00:09:04.010
Cool.

00:09:04.010 --> 00:09:05.285
Any others?

00:09:05.285 --> 00:09:06.500
AUDIENCE: SSL.

00:09:06.500 --> 00:09:08.140
PARISA TABRIZ: SSL
is a security thing.

00:09:08.140 --> 00:09:09.728
Maybe attacks to SSL?

00:09:09.728 --> 00:09:10.644
AUDIENCE: [INAUDIBLE].

00:09:13.010 --> 00:09:13.760
PARISA TABRIZ: OK.

00:09:13.760 --> 00:09:15.970
We've got lots.

00:09:15.970 --> 00:09:19.320
I'm hearing lots of
things that are right,

00:09:19.320 --> 00:09:21.230
or technologies
that can be abused.

00:09:21.230 --> 00:09:23.640
So cross site scripting
is one that you're

00:09:23.640 --> 00:09:26.180
going to hear a
couple times tonight.

00:09:26.180 --> 00:09:30.300
It is the most common
type of web vulnerability.

00:09:30.300 --> 00:09:33.130
It's the most common type
of reported vulnerability,

00:09:33.130 --> 00:09:35.720
security bug, today.

00:09:35.720 --> 00:09:39.704
And I say that with my
experience at Google.

00:09:39.704 --> 00:09:42.370
So it's the most common security
bug we find in Google software.

00:09:42.370 --> 00:09:46.340
It's also the most common bug
that's reported or disclosed

00:09:46.340 --> 00:09:47.600
across industry today.

00:09:47.600 --> 00:09:52.540
It's taken over buffer overflows
as the most common bug.

00:09:52.540 --> 00:09:53.880
So the textbook definition.

00:09:53.880 --> 00:09:59.150
Cross site scripting, it's
commonly abbreviated as XSS.

00:09:59.150 --> 00:10:01.220
It's a vulnerability
that enables attackers

00:10:01.220 --> 00:10:06.050
to execute malicious code within
the context of a vulnerable web

00:10:06.050 --> 00:10:06.810
application.

00:10:06.810 --> 00:10:10.370
So you get attacker gets
remote code execution

00:10:10.370 --> 00:10:14.402
in a victim's session
of some web app.

00:10:14.402 --> 00:10:15.860
So this is the
textbook definition.

00:10:18.600 --> 00:10:22.420
Here are a bunch of headlines
that I found really quickly.

00:10:22.420 --> 00:10:25.874
I cannot think of a single
application that I have used

00:10:25.874 --> 00:10:28.290
that has not been vulnerable
at some point to a cross site

00:10:28.290 --> 00:10:30.840
scripting bug.

00:10:30.840 --> 00:10:32.410
This applies to
Google software, it

00:10:32.410 --> 00:10:35.780
applies to lots of other
services that I use.

00:10:35.780 --> 00:10:40.654
And Tim, our next
presenter, is actually

00:10:40.654 --> 00:10:42.320
going to give you a
little bit more data

00:10:42.320 --> 00:10:44.070
as to the scope of this problem.

00:10:44.070 --> 00:10:49.330
But it's really an important
bug to understand, and to think

00:10:49.330 --> 00:10:52.140
about when you're
building web apps.

00:10:52.140 --> 00:10:56.680
So I gave you the textbook
definition of XSS.

00:10:56.680 --> 00:10:59.230
And maybe some of you are
already familiar with this bug,

00:10:59.230 --> 00:11:01.120
or have actually
thought about ways

00:11:01.120 --> 00:11:03.450
to mitigate it in
apps you've run.

00:11:03.450 --> 00:11:06.040
But the best way
to truly understand

00:11:06.040 --> 00:11:08.250
the damage this
vulnerability can cause

00:11:08.250 --> 00:11:09.975
is really to practice
finding them.

00:11:09.975 --> 00:11:11.350
So just this
morning, we actually

00:11:11.350 --> 00:11:13.790
launched two things which I
want to point everybody to,

00:11:13.790 --> 00:11:17.670
and I encourage you to check
out after this event tonight.

00:11:17.670 --> 00:11:21.550
Because they will really help
hone your hacking skills.

00:11:21.550 --> 00:11:24.255
So the first is
interactive guide on XSS.

00:11:27.030 --> 00:11:29.780
We'll see if links work.

00:11:29.780 --> 00:11:31.200
They do.

00:11:31.200 --> 00:11:36.780
So the URL on the slides, and of
course we'll share the slides,

00:11:36.780 --> 00:11:39.010
will bring you to
this nice write up

00:11:39.010 --> 00:11:41.460
of cross site scripting.

00:11:41.460 --> 00:11:46.310
And you not only get a more
comprehensive description

00:11:46.310 --> 00:11:48.640
of what cross site
scripting is, but really

00:11:48.640 --> 00:11:52.090
nice interactive demos
where you can actually

00:11:52.090 --> 00:11:56.100
try this out and see how it
works in little applications.

00:11:56.100 --> 00:12:01.550
So you have this fake search
engine called Bobazillion.

00:12:01.550 --> 00:12:05.860
And one of the most common ways
that a cross site scripting

00:12:05.860 --> 00:12:09.210
flaw ends up being introduced
into a web application

00:12:09.210 --> 00:12:13.100
is if the application is
handling user input, which

00:12:13.100 --> 00:12:16.210
is untrusted input, and
not actually performing

00:12:16.210 --> 00:12:21.460
the correct sanitization or
escaping before it actually

00:12:21.460 --> 00:12:25.080
includes this input
in the response page.

00:12:25.080 --> 00:12:28.120
So this first
example is actually

00:12:28.120 --> 00:12:31.020
trying to guide you through
finding a cross site scripting

00:12:31.020 --> 00:12:34.070
flaw as a user would type
input into a search engine.

00:12:38.101 --> 00:12:38.600
OK.

00:12:47.650 --> 00:12:50.590
So check out that.

00:12:50.590 --> 00:12:52.210
Go learn XSS.

00:12:52.210 --> 00:12:54.600
And once you learn
all about XSS,

00:12:54.600 --> 00:12:57.150
you can check out this
other really fun thing

00:12:57.150 --> 00:13:00.940
that we launched this morning,
which is the XSS war game.

00:13:03.750 --> 00:13:05.450
I'll read off the
top. "Welcome recruit!

00:13:05.450 --> 00:13:06.450
Cross site scripting
bugs are one

00:13:06.450 --> 00:13:08.824
of the most common and dangerous
types of vulnerabilities

00:13:08.824 --> 00:13:10.960
in web applications."

00:13:10.960 --> 00:13:11.725
La-la-la.

00:13:11.725 --> 00:13:14.370
"At Google, we know very well
how important these bugs.

00:13:14.370 --> 00:13:17.060
In fact, Google is so serious
about finding and fixing XSS,

00:13:17.060 --> 00:13:20.150
we are paying mercenaries
up to $7,500."

00:13:20.150 --> 00:13:21.270
So this is true.

00:13:21.270 --> 00:13:23.520
Tim's going to talk about
this again in the next talk,

00:13:23.520 --> 00:13:27.920
but we reward researchers that
report cross site scripting

00:13:27.920 --> 00:13:29.750
bugs, as well as a
bunch of other bugs.

00:13:29.750 --> 00:13:32.860
And this is a great way
to practice finding them.

00:13:32.860 --> 00:13:35.653
So, this is the first level.

00:13:35.653 --> 00:13:37.930
And we'll actually
open this as well.

00:13:37.930 --> 00:13:42.440
And you guys will all help me
go through the first level.

00:13:42.440 --> 00:13:43.590
So cross site scripting.

00:13:43.590 --> 00:13:46.560
We talked about them being the
most common and dangerous bugs.

00:13:46.560 --> 00:13:49.380
In this training, you
will learn about this.

00:13:49.380 --> 00:13:52.610
So if we go to level
one, "This level

00:13:52.610 --> 00:13:54.790
demonstrates a
common cause of XSS,

00:13:54.790 --> 00:13:56.840
where user input is directly
included in the page

00:13:56.840 --> 00:13:57.932
without proper escaping.

00:13:57.932 --> 00:13:59.890
Interact with the vulnerable
application window

00:13:59.890 --> 00:14:01.800
below, and find a way
to make it execute

00:14:01.800 --> 00:14:03.507
JavaScript of your choosing.

00:14:03.507 --> 00:14:05.590
You can take actions inside
the vulnerable window,

00:14:05.590 --> 00:14:07.800
or directly edit its URL bar."

00:14:07.800 --> 00:14:09.560
So your objective
for this mission

00:14:09.560 --> 00:14:14.560
is to inject a script to pop up
a JavaScript alert in the frame

00:14:14.560 --> 00:14:15.200
below.

00:14:15.200 --> 00:14:18.170
Typically, as a
security researcher,

00:14:18.170 --> 00:14:20.520
you're trying to demonstrate,
hey, there's a bug

00:14:20.520 --> 00:14:23.872
and I'm able to
actually execute code,

00:14:23.872 --> 00:14:25.080
we'll use the alert function.

00:14:25.080 --> 00:14:27.230
Because it's just a
very easy indication

00:14:27.230 --> 00:14:29.040
that you're able to
perform something.

00:14:29.040 --> 00:14:30.990
So that alert function
is a common way

00:14:30.990 --> 00:14:32.114
to demonstrate a bug.

00:14:32.114 --> 00:14:33.530
Once you show the
alert, you'll be

00:14:33.530 --> 00:14:35.000
able to advance
to the next level.

00:14:35.000 --> 00:14:35.500
OK.

00:14:35.500 --> 00:14:37.870
So this actually looks
very similar to the demo

00:14:37.870 --> 00:14:39.280
that I just showed.

00:14:39.280 --> 00:14:41.220
We have some user input
here, and then we're

00:14:41.220 --> 00:14:42.900
going to click Search.

00:14:42.900 --> 00:14:46.000
And your goal is to
find the alert box.

00:14:46.000 --> 00:14:48.260
Anybody have a solution?

00:14:48.260 --> 00:14:49.960
Raise your hand.

00:14:49.960 --> 00:14:50.812
Yes.

00:14:50.812 --> 00:14:53.200
AUDIENCE: Send my
[INAUDIBLE] alerts.

00:14:53.200 --> 00:14:54.380
PARISA TABRIZ: OK.

00:14:54.380 --> 00:14:57.100
So like this?

00:14:57.100 --> 00:14:57.600
OK.

00:14:57.600 --> 00:15:00.810
And then you want
me to click Search?

00:15:00.810 --> 00:15:03.360
OK.

00:15:03.360 --> 00:15:04.320
Anybody else?

00:15:04.320 --> 00:15:05.570
I need a hand.

00:15:05.570 --> 00:15:06.537
Yeah.

00:15:06.537 --> 00:15:07.491
AUDIENCE: [INAUDIBLE].

00:15:12.440 --> 00:15:14.730
PARISA TABRIZ: Oops.

00:15:14.730 --> 00:15:17.020
Script, alert.

00:15:17.020 --> 00:15:19.220
You tell me if this looks right.

00:15:19.220 --> 00:15:19.720
Like this?

00:15:19.720 --> 00:15:20.220
Oops.

00:15:23.080 --> 00:15:24.076
Is that what you want?

00:15:24.076 --> 00:15:25.900
AUDIENCE: [INAUDIBLE].

00:15:25.900 --> 00:15:28.360
PARISA TABRIZ: OK.

00:15:28.360 --> 00:15:30.270
We have a winner.

00:15:30.270 --> 00:15:30.770
OK.

00:15:33.910 --> 00:15:35.550
I could have passed something.

00:15:35.550 --> 00:15:36.610
We alert undefined.

00:15:36.610 --> 00:15:37.110
Good job.

00:15:40.100 --> 00:15:40.600
OK.

00:15:40.600 --> 00:15:46.250
So, with the help
of our friends--

00:15:46.250 --> 00:15:49.906
I don't know your
name-- but everybody

00:15:49.906 --> 00:15:51.030
has passed the first level.

00:15:51.030 --> 00:15:54.437
And we can advance
to the next level.

00:15:54.437 --> 00:15:56.270
And we're not going to
go through all these,

00:15:56.270 --> 00:15:58.860
but they get increasingly
more challenging,

00:15:58.860 --> 00:16:00.940
and it's a really
good way to practice

00:16:00.940 --> 00:16:03.800
finding XSS and
understanding really

00:16:03.800 --> 00:16:06.050
how complex these
bugs can actually be.

00:16:06.050 --> 00:16:07.960
It's simple in theory,
but it's really hard

00:16:07.960 --> 00:16:10.400
to eradicate them from web apps.

00:16:10.400 --> 00:16:11.350
So check that out.

00:16:11.350 --> 00:16:13.750
It's really fun.

00:16:13.750 --> 00:16:15.810
And we'll go back to this.

00:16:18.580 --> 00:16:25.780
Once you really master
XSS, you can check out

00:16:25.780 --> 00:16:26.920
this interactive code lab.

00:16:26.920 --> 00:16:29.295
This is actually a couple of
years old, but still totally

00:16:29.295 --> 00:16:30.210
relevant.

00:16:30.210 --> 00:16:31.700
It's called Gruyere.

00:16:31.700 --> 00:16:34.230
And it also has crested
scripting bugs, as well

00:16:34.230 --> 00:16:37.270
as a bunch of the other
types of common bugs

00:16:37.270 --> 00:16:39.235
that you may have
heard mentioned

00:16:39.235 --> 00:16:40.610
by people in the
audience before.

00:16:40.610 --> 00:16:45.300
So there's cross site
request forgery, or CSRF.

00:16:45.300 --> 00:16:50.320
There is some off bypass errors
in this bug, some mixed content

00:16:50.320 --> 00:16:50.820
bugs.

00:16:50.820 --> 00:16:52.790
Lots of different
common security bugs.

00:16:52.790 --> 00:16:55.600
And the training will
not only describe

00:16:55.600 --> 00:16:57.150
what the type of
vulnerability is,

00:16:57.150 --> 00:17:00.380
but it will guide you through
exercises to find the bugs,

00:17:00.380 --> 00:17:03.080
and also figure out
how to fix them.

00:17:03.080 --> 00:17:05.290
Last book for anybody
who can tell me

00:17:05.290 --> 00:17:08.300
why this is called Gruyere.

00:17:08.300 --> 00:17:09.480
yes.

00:17:09.480 --> 00:17:12.470
AUDIENCE: It's a type of cheese.

00:17:12.470 --> 00:17:14.819
PARISA TABRIZ: Yes, it's a
type of cheese, but-- yeah,

00:17:14.819 --> 00:17:16.335
in the blue shirt.

00:17:16.335 --> 00:17:17.251
AUDIENCE: [INAUDIBLE].

00:17:19.839 --> 00:17:20.630
PARISA TABRIZ: Yes.

00:17:20.630 --> 00:17:23.910
So, Gruyere is a
delicious cheese,

00:17:23.910 --> 00:17:26.524
and it's also known for having
lots of little tiny holes.

00:17:30.780 --> 00:17:35.830
I was afraid I was going to get
electronically zapped for going

00:17:35.830 --> 00:17:37.410
outside the speaker zone.

00:17:37.410 --> 00:17:40.860
So check this out.

00:17:40.860 --> 00:17:46.090
This is going to help as
well hone your hacking skill.

00:17:46.090 --> 00:17:48.480
Those are some excellent
resources to start.

00:17:48.480 --> 00:17:50.140
After that, you
should be well suited

00:17:50.140 --> 00:17:52.800
to start hacking on your own
software, or the software

00:17:52.800 --> 00:17:54.780
that you use.

00:17:54.780 --> 00:17:57.700
And all of this is-- I
mean have fun with it,

00:17:57.700 --> 00:18:03.170
but also it's going to help you
build better software in terms

00:18:03.170 --> 00:18:04.520
of defense.

00:18:04.520 --> 00:18:06.170
And potentially
even profit, which

00:18:06.170 --> 00:18:09.870
is what we're going to hear
about from our next speaker.

00:18:09.870 --> 00:18:14.630
So I'm going to leave you with
much more qualified hands.

00:18:14.630 --> 00:18:16.450
My three colleagues
at Google are

00:18:16.450 --> 00:18:18.230
going to be speaking tonight.

00:18:18.230 --> 00:18:20.870
Tim, Eduardo, and Joel.

00:18:20.870 --> 00:18:21.850
Tim's up first.

00:18:21.850 --> 00:18:24.600
Tim works at Google, and
among many other things,

00:18:24.600 --> 00:18:28.730
he makes sure that
security bugs get

00:18:28.730 --> 00:18:31.379
fixed, which is
actually really hard.

00:18:31.379 --> 00:18:32.920
It's one thing to
find the bugs, it's

00:18:32.920 --> 00:18:34.742
another thing to get them fixed.

00:18:34.742 --> 00:18:36.950
So he spends his time working
with internal engineers

00:18:36.950 --> 00:18:39.580
at Google, and also external
security researchers

00:18:39.580 --> 00:18:42.440
that find and report bugs to us.

00:18:42.440 --> 00:18:46.831
And before Google, Tim worked
in Australian department

00:18:46.831 --> 00:18:47.330
of defense.

00:18:47.330 --> 00:18:50.100
So he has come from
far away lands too,

00:18:50.100 --> 00:18:51.580
to join us in the Bay Area.

00:18:51.580 --> 00:18:55.120
So I'm going to
give it up to Tim.

00:18:55.120 --> 00:18:56.020
Enjoy.

00:18:56.020 --> 00:18:58.470
[APPLAUSE]

