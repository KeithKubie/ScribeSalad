WEBVTT
Kind: captions
Language: en

00:00:01.204 --> 00:00:03.620
VYACHESLAV EGOROV: Can you
hear me, because I'm not sure--

00:00:03.620 --> 00:00:04.610
OK, I can hear myself.

00:00:04.610 --> 00:00:06.770
So that's good.

00:00:06.770 --> 00:00:09.830
I was so stressed
configuring the resolution,

00:00:09.830 --> 00:00:12.590
so I didn't hear how
they introduced me.

00:00:12.590 --> 00:00:15.470
So my name is Vyacheslav.

00:00:15.470 --> 00:00:17.420
I work on the Dart VM team.

00:00:17.420 --> 00:00:19.890
And I'm here to give a slightly
different talk from what

00:00:19.890 --> 00:00:24.560
you have been listening to for
the past two or three hours,

00:00:24.560 --> 00:00:25.820
I guess.

00:00:25.820 --> 00:00:31.220
Originally, I wanted to give
the talk title like that.

00:00:31.220 --> 00:00:33.560
But I figured out
that it will take

00:00:33.560 --> 00:00:36.830
around one hour, if not two.

00:00:36.830 --> 00:00:41.220
So let's limit ourselves to
some small domain, like mobile,

00:00:41.220 --> 00:00:44.690
which is kind of quite hot,
as you have figured out

00:00:44.690 --> 00:00:47.330
from the previous talks,
that Flutter is everywhere.

00:00:47.330 --> 00:00:49.360
And if Flutter is
everywhere, the Dart

00:00:49.360 --> 00:00:52.800
is everywhere as well, so.

00:00:52.800 --> 00:00:56.660
This is a talk about Dart VM,
because I work on Dart VM.

00:00:56.660 --> 00:00:59.890
But before we actually get
into nitty gritty details,

00:00:59.890 --> 00:01:02.210
it's good to establish
what Dart VM actually is.

00:01:02.210 --> 00:01:04.940
Because when you
talk to people, you

00:01:04.940 --> 00:01:07.100
discover that they don't
know what Dart VM is.

00:01:07.100 --> 00:01:10.360
And when they deploy a
Flutter app, is Dart VM--

00:01:10.360 --> 00:01:11.450
is it used, even?

00:01:11.450 --> 00:01:14.032
No, maybe not.

00:01:14.032 --> 00:01:15.740
In reality, there are
a lot of components

00:01:15.740 --> 00:01:17.840
that Dart VM provides.

00:01:17.840 --> 00:01:19.520
And I put some of
them on the slide.

00:01:19.520 --> 00:01:21.980
I tried to fit as
much as I could.

00:01:21.980 --> 00:01:24.020
But I'm sure I
have omitted some.

00:01:24.020 --> 00:01:29.990
And they can be split into
three groups, roughly.

00:01:29.990 --> 00:01:32.730
The runtime components--
like garbage collection,

00:01:32.730 --> 00:01:34.170
for example.

00:01:34.170 --> 00:01:37.730
Then there is some compilers
that provide compilation

00:01:37.730 --> 00:01:40.450
to native code.

00:01:40.450 --> 00:01:44.390
I put Interpreter also in the
compiler for certain reasons.

00:01:44.390 --> 00:01:47.329
And then there are developer
productivity components,

00:01:47.329 --> 00:01:48.870
which provide things
like hot reload,

00:01:48.870 --> 00:01:50.960
debugging, and profiling.

00:01:50.960 --> 00:01:54.020
And depending on how you mix
and match these components

00:01:54.020 --> 00:01:56.550
together, you get
different results.

00:01:56.550 --> 00:02:01.270
For example, if you have
this artisanally-crafted,

00:02:01.270 --> 00:02:04.420
iPhone-like looking
thing there, and you

00:02:04.420 --> 00:02:10.479
are developing a mobile
application using Flutter, then

00:02:10.479 --> 00:02:14.360
in the development mode
or so-called slow mode,

00:02:14.360 --> 00:02:18.106
you have some runtime and
compilation components

00:02:18.106 --> 00:02:19.730
and the developer
experience components

00:02:19.730 --> 00:02:21.960
all running on the host device.

00:02:21.960 --> 00:02:25.550
So that's how we provide this
high-fidelity hot reload,

00:02:25.550 --> 00:02:27.960
for example, because the
device can do everything.

00:02:27.960 --> 00:02:29.120
It can reload the code.

00:02:29.120 --> 00:02:32.420
It can JIT it or execute
it on the interpreter,

00:02:32.420 --> 00:02:35.450
depending whether you are
running on Android or iOS.

00:02:35.450 --> 00:02:37.950
And you can profile it
as well, for example.

00:02:37.950 --> 00:02:42.330
So everything is
running on the device.

00:02:42.330 --> 00:02:45.140
If you are releasing your
application to the users,

00:02:45.140 --> 00:02:48.230
like through the app
stores, then what you do

00:02:48.230 --> 00:02:50.750
is that, on the host, on
you development machine,

00:02:50.750 --> 00:02:53.810
you compile it-- using, again,
some components from the Dart

00:02:53.810 --> 00:02:56.960
VM runtime system and some
components from the Dart VM

00:02:56.960 --> 00:02:58.850
compilation pipelines.

00:02:58.850 --> 00:03:01.130
And then you ship
Dart VM runtime,

00:03:01.130 --> 00:03:02.810
which still contains
garbage collector

00:03:02.810 --> 00:03:06.500
and other auxiliary components,
plus the ahead-of-time compiled

00:03:06.500 --> 00:03:08.960
code to the host devices.

00:03:08.960 --> 00:03:10.700
So the Dart VM is
still in the picture,

00:03:10.700 --> 00:03:15.620
even if you are releasing
your application to the users.

00:03:15.620 --> 00:03:19.550
So ultimately, that means
that with all your questions

00:03:19.550 --> 00:03:23.680
about optimizing
Dart code for users,

00:03:23.680 --> 00:03:26.871
you have to come to the
Dart VM people and ask them.

00:03:26.871 --> 00:03:28.370
So what if you have
such a question?

00:03:28.370 --> 00:03:30.750
What should you do?

00:03:30.750 --> 00:03:33.052
Well, I have two answers
to this question.

00:03:33.052 --> 00:03:35.510
The first answer is that you
should always use Observatory,

00:03:35.510 --> 00:03:36.010
right?

00:03:36.010 --> 00:03:40.190
There are some great tutorials
for how to do it on the site.

00:03:40.190 --> 00:03:41.930
And there are other
talks about this

00:03:41.930 --> 00:03:44.690
from the previous Dart cons.

00:03:44.690 --> 00:03:46.099
So you should watch them.

00:03:46.099 --> 00:03:48.140
And another is that you
should always talk to us.

00:03:48.140 --> 00:03:50.780
If you see something suspicious
in the VM, you just come to us.

00:03:50.780 --> 00:03:52.220
And we fix it for you.

00:03:52.220 --> 00:03:54.650
That's our modus operandi.

00:03:54.650 --> 00:04:00.070
And I actually wanted to
finish the talk here, because--

00:04:00.070 --> 00:04:01.370
well, that's it.

00:04:01.370 --> 00:04:03.080
That's all that you
have to know, really.

00:04:03.080 --> 00:04:05.450
But when I did the dry
run, somehow Philip

00:04:05.450 --> 00:04:08.450
was not very impressed
by that suggestion.

00:04:08.450 --> 00:04:10.250
So I will keep on
trucking and tell you

00:04:10.250 --> 00:04:12.630
more interesting stuff.

00:04:12.630 --> 00:04:14.990
So the reason why I really
wanted to finish it here

00:04:14.990 --> 00:04:19.310
is that I don't want to
promulgate this idea that I

00:04:19.310 --> 00:04:21.440
can give you 10 suggestions.

00:04:21.440 --> 00:04:26.660
And then you go, and replace
all your forEach invocations

00:04:26.660 --> 00:04:30.170
with a for loop in you code,
and suddenly, everything

00:04:30.170 --> 00:04:31.850
is going to be fixed.

00:04:31.850 --> 00:04:33.620
The performance is
not a cargo cult,

00:04:33.620 --> 00:04:35.930
where you can just follow
some suggestions blindly.

00:04:35.930 --> 00:04:38.129
You need to understand
what you are doing.

00:04:38.129 --> 00:04:39.920
And you need to understand
your application

00:04:39.920 --> 00:04:42.210
as much as you understand
the underlying platform.

00:04:42.210 --> 00:04:43.920
And this is very important.

00:04:43.920 --> 00:04:45.350
So that's why I
really don't want

00:04:45.350 --> 00:04:49.820
to limit this talk to
just some suggestions.

00:04:49.820 --> 00:04:51.740
And another reason
is that, if you

00:04:51.740 --> 00:04:55.040
look at the timeline of
Dart, and if you listen

00:04:55.040 --> 00:04:57.560
to the talks that were
given here before,

00:04:57.560 --> 00:05:04.510
you should have figured out
that, in the past two years,

00:05:04.510 --> 00:05:07.160
there was a paradigm shift
in the Dart language.

00:05:07.160 --> 00:05:08.750
And it's not a small
paradigm shift.

00:05:08.750 --> 00:05:10.130
It's a really big
paradigm shift.

00:05:10.130 --> 00:05:11.970
[LAUGHTER]

00:05:11.970 --> 00:05:16.430
And it obviously has certain
consequences on the performance

00:05:16.430 --> 00:05:19.460
of the Dart language.

00:05:19.460 --> 00:05:21.296
There is such thing
as strong mode.

00:05:21.296 --> 00:05:23.170
And there is the
limitations on the integers.

00:05:23.170 --> 00:05:25.550
And there is the changes
to the infrastructure.

00:05:25.550 --> 00:05:34.220
So let's look at how Dart
operated seven years ago.

00:05:34.220 --> 00:05:36.620
If you go back in time and
you watch some presentations

00:05:36.620 --> 00:05:38.240
about Dart when
it was announced,

00:05:38.240 --> 00:05:40.490
you will discover that
there is such statements,

00:05:40.490 --> 00:05:43.250
that "by default,
type annotations have

00:05:43.250 --> 00:05:45.240
no effect and no cost."

00:05:45.240 --> 00:05:48.050
And this is a certainly
valid statement.

00:05:48.050 --> 00:05:52.880
But it turns out that cost
is a very complicated thing.

00:05:52.880 --> 00:05:54.380
Like, they don't have a cost?

00:05:54.380 --> 00:05:56.780
And what the original
authors meant here

00:05:56.780 --> 00:05:59.960
is that it doesn't
cost you anything

00:05:59.960 --> 00:06:04.154
to check certain values
of a certain type,

00:06:04.154 --> 00:06:05.570
because there is
no need to check.

00:06:05.570 --> 00:06:08.690
Everything just keeps on
trucking without any checks.

00:06:08.690 --> 00:06:11.690
But it turns out that you
cannot actually do any useful

00:06:11.690 --> 00:06:14.850
optimizations ahead of time
if you cannot trust your type

00:06:14.850 --> 00:06:16.320
annotations.

00:06:16.320 --> 00:06:22.580
So this is a valid Dart
code from the Dart 1

00:06:22.580 --> 00:06:25.810
And you have a cat
and you have a dog.

00:06:25.810 --> 00:06:27.856
And both of them can woof.

00:06:27.856 --> 00:06:28.855
It's a very strange cat.

00:06:31.370 --> 00:06:35.360
And you write a function
which expects to do with dogs,

00:06:35.360 --> 00:06:37.790
and the cat sneaks in.

00:06:37.790 --> 00:06:39.920
And everything works
just fine, because that's

00:06:39.920 --> 00:06:41.040
how Dart 1 operates.

00:06:41.040 --> 00:06:47.440
It doesn't force you to write
meaningful type annotations.

00:06:47.440 --> 00:06:50.990
And it can work without
it, reasonably efficient.

00:06:50.990 --> 00:06:52.940
But it turns out that
this is confusing

00:06:52.940 --> 00:06:56.300
in the ahead-of-time compilation
context, like, for example,

00:06:56.300 --> 00:06:56.830
iOS.

00:06:56.830 --> 00:06:59.340
Or like when you
deploy Flutter, you're

00:06:59.340 --> 00:07:02.870
forced to do the
ahead-of-time compilation.

00:07:02.870 --> 00:07:06.500
So we came up with a
solution that for Dart 1

00:07:06.500 --> 00:07:09.630
allows the ahead-of-time
compiled code executed

00:07:09.630 --> 00:07:12.880
relatively efficiently.

00:07:12.880 --> 00:07:13.897
Here's a solution.

00:07:13.897 --> 00:07:15.480
I promised the talk
will be different.

00:07:15.480 --> 00:07:17.720
So I put some ARM
assembly on the slides.

00:07:20.450 --> 00:07:22.770
Let me try to explain it a
little bit easier than ARM

00:07:22.770 --> 00:07:23.270
assembly.

00:07:23.270 --> 00:07:27.350
So this pig nose here is
actually not that pig nose.

00:07:27.350 --> 00:07:30.650
It's a power socket.

00:07:30.650 --> 00:07:34.580
And into power socket, you
can plug different plugs.

00:07:34.580 --> 00:07:37.555
And that's what
switchable calls are,

00:07:37.555 --> 00:07:40.550
in the ahead-of-time
compiler in Dart.

00:07:40.550 --> 00:07:44.870
So for each invocation in your
ahead-of-time compiled code,

00:07:44.870 --> 00:07:49.550
we generate two slots some
way, or in some auxiliary data

00:07:49.550 --> 00:07:56.690
structure, where one slot
contains the piece of code

00:07:56.690 --> 00:07:59.570
that will be called when
you reach this invocation.

00:07:59.570 --> 00:08:01.440
And there is some
metadata on the site.

00:08:01.440 --> 00:08:03.990
And these two slots can
be updated independently

00:08:03.990 --> 00:08:05.550
as the application is running.

00:08:05.550 --> 00:08:07.670
And it allows the
ahead-of-time compiled code

00:08:07.670 --> 00:08:11.447
to adapt to what's actually
happening in your application,

00:08:11.447 --> 00:08:13.780
whether it's the cats that
are woofing or it's the dogs.

00:08:13.780 --> 00:08:17.340
Or it may be some
seagulls, and so on.

00:08:17.340 --> 00:08:19.500
So here's how it works.

00:08:19.500 --> 00:08:22.940
So first, when you just
start your application--

00:08:22.940 --> 00:08:25.234
all the methods,
they know nothing.

00:08:25.234 --> 00:08:27.650
All the dynamically-dispatched
methods, they know nothing.

00:08:27.650 --> 00:08:29.640
And then as the application
runs-- for example,

00:08:29.640 --> 00:08:31.580
if it saw only cats woofing--

00:08:31.580 --> 00:08:36.650
then it would just put enough
information in these slots

00:08:36.650 --> 00:08:39.110
to do a direct invocation.

00:08:39.110 --> 00:08:43.400
And if you suddenly
get some dogs woofing,

00:08:43.400 --> 00:08:47.000
then it will switch what
it does in those slots

00:08:47.000 --> 00:08:52.040
to do a call that searches some
list for the invocation target,

00:08:52.040 --> 00:08:54.140
and so on and so forth.

00:08:54.140 --> 00:08:57.080
There is even a
case when if there

00:08:57.080 --> 00:09:01.670
is too much different strange
animals going around, then

00:09:01.670 --> 00:09:04.640
it will use some sort of
a hash table on the site,

00:09:04.640 --> 00:09:07.710
and use the search
in the hash table.

00:09:07.710 --> 00:09:12.470
So this approach allows
you to reduce the overhead

00:09:12.470 --> 00:09:14.630
of each individual dispatch.

00:09:14.630 --> 00:09:18.090
But you can see that the
call is still present there.

00:09:18.090 --> 00:09:21.950
And this means that across
these code boundaries,

00:09:21.950 --> 00:09:24.740
you cannot eliminate
any redundancies,

00:09:24.740 --> 00:09:27.590
which might or might not be
important for your application,

00:09:27.590 --> 00:09:29.600
right?

00:09:29.600 --> 00:09:31.580
For some applications,
you really need to--

00:09:31.580 --> 00:09:33.620
for some types of
code, you really

00:09:33.620 --> 00:09:37.640
need to know what is being
called in each particular call

00:09:37.640 --> 00:09:41.010
site to produce the
most efficient code.

00:09:41.010 --> 00:09:43.970
A good example of
such code is code

00:09:43.970 --> 00:09:47.120
that does a lot of mathematics.

00:09:47.120 --> 00:09:48.770
I don't know how
common mathematics is.

00:09:48.770 --> 00:09:53.030
But it definitely sometimes
occurs in the code.

00:09:53.030 --> 00:09:56.990
And it's not limited
to the double math.

00:09:56.990 --> 00:09:58.940
It can be also just
some bitwise math

00:09:58.940 --> 00:10:01.480
as well, when you are
unpacking some protobuf

00:10:01.480 --> 00:10:04.580
or some binary format.

00:10:04.580 --> 00:10:09.290
So I wrote this code here
doing some harmonic series.

00:10:09.290 --> 00:10:11.750
Doesn't really matter
what it's doing.

00:10:11.750 --> 00:10:13.850
It's doing a lot of math.

00:10:13.850 --> 00:10:16.010
And then I wrote
some benchmark that

00:10:16.010 --> 00:10:21.260
just translates in the loop
and says how long it takes.

00:10:21.260 --> 00:10:26.270
And then I put it in the debug
mode Flutter on my Nexus 5X.

00:10:28.970 --> 00:10:32.840
And in debug mode, it
took 3,000 milliseconds.

00:10:32.840 --> 00:10:36.050
OK, this number does not
tell us anything, because we

00:10:36.050 --> 00:10:38.010
don't have any expectations.

00:10:38.010 --> 00:10:39.770
Here's a question--
how long do we

00:10:39.770 --> 00:10:41.780
think the release mode takes?

00:10:41.780 --> 00:10:44.420
Because release mode is the one
that doesn't have a slow mode

00:10:44.420 --> 00:10:45.800
banner.

00:10:45.800 --> 00:10:48.230
Like, let's say, is
it two times faster?

00:10:48.230 --> 00:10:51.180
Is it three times faster?

00:10:51.180 --> 00:10:52.130
No?

00:10:52.130 --> 00:10:54.980
OK, it's actually four
times slower, approximately.

00:10:54.980 --> 00:10:55.950
[LAUGHTER]

00:10:55.950 --> 00:10:59.850
So that's a little
bit upsetting, right.

00:10:59.850 --> 00:11:01.580
You remove the slow mode banner.

00:11:01.580 --> 00:11:05.150
And suddenly it runs slower.

00:11:05.150 --> 00:11:07.322
If you take the observatory--

00:11:07.322 --> 00:11:08.780
remember, observatory
is a friend--

00:11:08.780 --> 00:11:12.860
and we try to connect it to
the debug mode Flutter run.

00:11:12.860 --> 00:11:14.330
it brings this
line in, that when

00:11:14.330 --> 00:11:17.180
you run the application that
you can go to this address.

00:11:17.180 --> 00:11:20.600
And you will get
an observatory UI.

00:11:20.600 --> 00:11:23.600
It looks like this.

00:11:23.600 --> 00:11:25.620
Observatory has a lot of tools.

00:11:25.620 --> 00:11:27.980
And I'm not going to walk
you through all of them.

00:11:27.980 --> 00:11:30.980
But right there,
there is the tool

00:11:30.980 --> 00:11:33.500
that is really useful
for figuring out

00:11:33.500 --> 00:11:34.760
performance problems.

00:11:34.760 --> 00:11:37.840
Let me zoom in for you.

00:11:37.840 --> 00:11:40.110
It's a CPU profile.

00:11:40.110 --> 00:11:42.740
So if you go there, you will
see that most of the time

00:11:42.740 --> 00:11:46.520
is spent in this function
that does our computation

00:11:46.520 --> 00:11:49.010
of harmonic series.

00:11:49.010 --> 00:11:50.750
And if you start
clicking on the links,

00:11:50.750 --> 00:11:54.440
sooner or later you will be
able to reach the disassembly

00:11:54.440 --> 00:11:57.170
for this function.

00:11:57.170 --> 00:12:02.041
And I recommend learning a
little bit of ARM assembly,

00:12:02.041 --> 00:12:02.540
maybe.

00:12:02.540 --> 00:12:03.440
I don't know.

00:12:03.440 --> 00:12:07.961
But there are a lot of just
human-readable English language

00:12:07.961 --> 00:12:08.460
here.

00:12:08.460 --> 00:12:11.870
So for example, if you
see diff and add and add

00:12:11.870 --> 00:12:14.570
that obviously tells you that
some division and addition

00:12:14.570 --> 00:12:16.110
is going on there.

00:12:16.110 --> 00:12:18.290
So this is the loop
for our benchmark.

00:12:18.290 --> 00:12:20.300
And you see that
the JIT compiler--

00:12:20.300 --> 00:12:23.710
because the debug mode on
Android devices is using

00:12:23.710 --> 00:12:26.300
the JIT mode of the VM--

00:12:26.300 --> 00:12:28.160
was able to figure
out what we are doing

00:12:28.160 --> 00:12:31.310
and produce a relatively
tight loop, where

00:12:31.310 --> 00:12:34.630
all the operations
on the double values

00:12:34.630 --> 00:12:36.710
are performed directly
with registers.

00:12:36.710 --> 00:12:39.050
And everything is very
nice and beautiful.

00:12:41.600 --> 00:12:43.340
And actually, if
you have a profile

00:12:43.340 --> 00:12:45.830
like that where you just see
your computational kernel

00:12:45.830 --> 00:12:48.650
and all time is spent in it,
it's usually a good sign.

00:12:48.650 --> 00:12:51.020
There might be some code
quality issues inside.

00:12:51.020 --> 00:12:52.730
But it's a good
sign that it's not

00:12:52.730 --> 00:12:57.575
going into some strange
runtime routines and so on.

00:12:57.575 --> 00:13:00.200
Now we want to figure out what's
happening in the release build

00:13:00.200 --> 00:13:00.950
of Flutter, right?

00:13:00.950 --> 00:13:02.135
Why is it taking slower?

00:13:05.090 --> 00:13:07.190
So you cannot profile
the release build,

00:13:07.190 --> 00:13:11.570
because it doesn't include
any development tools,

00:13:11.570 --> 00:13:14.480
because you just want to
ship it to the people and you

00:13:14.480 --> 00:13:16.470
don't want to ship
development tools with it.

00:13:16.470 --> 00:13:20.030
But there is a mode in Flutter
called profile mode, which

00:13:20.030 --> 00:13:24.520
is exactly release mode plus the
observatory and all required VM

00:13:24.520 --> 00:13:26.990
side components.

00:13:26.990 --> 00:13:30.630
And it brings the link, just
like debug mode brings the link

00:13:30.630 --> 00:13:33.330
to the observatory.

00:13:33.330 --> 00:13:36.110
So if you go to that link
and look at the CPU profile,

00:13:36.110 --> 00:13:40.160
you discover that situation
in the ahead-of-time compiled

00:13:40.160 --> 00:13:43.160
build is not very beautiful.

00:13:43.160 --> 00:13:44.990
There is the
computational kernel

00:13:44.990 --> 00:13:48.110
and then there are methods
of double being called,

00:13:48.110 --> 00:13:51.360
which means something
bad really happened.

00:13:51.360 --> 00:13:53.765
And if you look at
the assembly code,

00:13:53.765 --> 00:13:56.140
then you will see that it's
coaling just directly methods

00:13:56.140 --> 00:13:58.160
on double, nothing is in lines.

00:13:58.160 --> 00:14:01.790
And the reason why nothing is
in line is because in Dart 1,

00:14:01.790 --> 00:14:04.640
you cannot really guarantee
that the thing that is called

00:14:04.640 --> 00:14:05.920
a double is a double, right?

00:14:05.920 --> 00:14:10.166
It can be a dog, which is going
to woof when you add to it,

00:14:10.166 --> 00:14:12.200
or meow when you divide it.

00:14:12.200 --> 00:14:18.800
So the VM cannot really
produce any tighter code.

00:14:18.800 --> 00:14:22.730
So, OK, this statement
maybe is not very true

00:14:22.730 --> 00:14:28.492
if we are looking in the current
context for where Dart is used.

00:14:28.492 --> 00:14:30.410
But strong mode to
the rescue, right?

00:14:30.410 --> 00:14:32.740
Strong mode is going
to fix everything--

00:14:32.740 --> 00:14:34.410
maybe.

00:14:34.410 --> 00:14:37.306
I'm cautiously highly excited.

00:14:37.306 --> 00:14:39.690
[LAUGHTER]

00:14:39.690 --> 00:14:42.710
So if you take Flutter
from the tip of the tree

00:14:42.710 --> 00:14:44.660
and then build
some stuff manually

00:14:44.660 --> 00:14:47.090
and do some magic
invocations, you

00:14:47.090 --> 00:14:55.160
can try running Flutter with
the completely new Dart 2

00:14:55.160 --> 00:14:56.930
compilation pipeline.

00:14:56.930 --> 00:14:59.935
And-- da-dum!

00:14:59.935 --> 00:15:02.720
It actually runs
faster, almost as fast

00:15:02.720 --> 00:15:04.530
as the JIT version is running.

00:15:04.530 --> 00:15:06.860
And it's an ahead-of-time
compiled version.

00:15:06.860 --> 00:15:12.100
So things are getting
really quite a bit faster.

00:15:12.100 --> 00:15:15.650
Just a reminder--
the AOT version 1

00:15:15.650 --> 00:15:22.269
took around four
times slower, right?

00:15:22.269 --> 00:15:23.810
And if we look at
it in the profiler,

00:15:23.810 --> 00:15:26.720
we discover that now
it spends, again, most

00:15:26.720 --> 00:15:28.700
of the time in the
computational kernel.

00:15:28.700 --> 00:15:31.820
And everything is in line
into it, everything is good.

00:15:31.820 --> 00:15:34.200
And when we look at the
generated code again,

00:15:34.200 --> 00:15:38.180
we see that there is some
directly-performed double

00:15:38.180 --> 00:15:39.240
operations.

00:15:39.240 --> 00:15:40.530
So that's good.

00:15:40.530 --> 00:15:42.440
But there is some
strange code which

00:15:42.440 --> 00:15:45.070
looks very ugly after
them, which was not

00:15:45.070 --> 00:15:47.150
present in the JIT version.

00:15:47.150 --> 00:15:49.830
So this can also be tracked
down to what's happening.

00:15:49.830 --> 00:15:51.590
We just need to type
in this command.

00:15:51.590 --> 00:15:55.950
[LAUGHTER]

00:15:55.950 --> 00:16:00.360
And you can see the
intermediate representation

00:16:00.360 --> 00:16:02.150
that our optimizing
compiler is using,

00:16:02.150 --> 00:16:04.620
and figure out that there
is some work in progress

00:16:04.620 --> 00:16:05.120
happening.

00:16:05.120 --> 00:16:08.300
We're going to fix it.

00:16:08.300 --> 00:16:10.200
OK, so what's the
moral of this story?

00:16:13.460 --> 00:16:17.480
You should expect potentially
drastic changes in the AOT

00:16:17.480 --> 00:16:19.710
performance
characteristics in Dart 2,

00:16:19.710 --> 00:16:21.590
once we ship that completely.

00:16:21.590 --> 00:16:24.620
And I think they
will be for the best.

00:16:24.620 --> 00:16:28.500
So everything will become
much better than it is now.

00:16:28.500 --> 00:16:30.050
And that's the
reason why I don't

00:16:30.050 --> 00:16:33.230
want to give you any advice
now about the performance,

00:16:33.230 --> 00:16:35.720
because things will change
so drastically that all

00:16:35.720 --> 00:16:39.750
my advice from today is
completely invalid tomorrow.

00:16:39.750 --> 00:16:41.650
But I will still
give you some advice.

00:16:41.650 --> 00:16:43.670
And I think this
is the kind of--

00:16:43.670 --> 00:16:47.600
how will I run performance
studies myself?

00:16:47.600 --> 00:16:49.910
So it's very important.

00:16:49.910 --> 00:16:52.760
If you care about performance,
performance is not an act.

00:16:52.760 --> 00:16:54.650
Like, you do today performance.

00:16:54.650 --> 00:16:56.350
And tomorrow you forget.

00:16:56.350 --> 00:16:58.100
And you go on vacation.

00:16:58.100 --> 00:16:59.970
Performance is a
continuous process.

00:16:59.970 --> 00:17:02.900
So if you are running tests,
you should run benchmarks

00:17:02.900 --> 00:17:05.960
in the same system where you're
running tests continuously.

00:17:05.960 --> 00:17:09.500
So it's very important
to understand

00:17:09.500 --> 00:17:11.180
what you are actually doing.

00:17:11.180 --> 00:17:14.390
So you should understand
things in abstract ways.

00:17:14.390 --> 00:17:18.530
Like, for example, if you
have a loop from zero to N,

00:17:18.530 --> 00:17:20.085
it will take you linear time.

00:17:20.085 --> 00:17:22.460
If you have two loop from zero
to N nested in each other,

00:17:22.460 --> 00:17:24.500
it's a quadratic--
so on and so forth.

00:17:24.500 --> 00:17:28.390
You should understand
that taking a substring--

00:17:28.390 --> 00:17:31.270
in the worst case it
will be, for example,

00:17:31.270 --> 00:17:34.250
linear by the length of the
substring in time and space,

00:17:34.250 --> 00:17:35.550
and so on and so forth.

00:17:35.550 --> 00:17:39.170
So you need to understand
abstract costs of operations.

00:17:39.170 --> 00:17:42.320
You also need to
try to figure out

00:17:42.320 --> 00:17:44.450
the implementation of
things a little bit,

00:17:44.450 --> 00:17:50.000
like on the outer layers, and
understand the concrete costs

00:17:50.000 --> 00:17:51.260
of individual operations.

00:17:51.260 --> 00:17:52.870
Because somewhere
it looks like you

00:17:52.870 --> 00:17:54.470
are doing something
that is linear,

00:17:54.470 --> 00:17:56.000
but maybe underlying
implementation

00:17:56.000 --> 00:17:57.590
makes it quadratic.

00:17:57.590 --> 00:17:59.360
That's a real case.

00:17:59.360 --> 00:18:03.320
Now, if we are talking
about GC, for example,

00:18:03.320 --> 00:18:07.220
sometimes people don't
understand really how GCs work,

00:18:07.220 --> 00:18:09.774
which is not surprising
because GC is very convoluted.

00:18:09.774 --> 00:18:11.690
And even people who
implement GCs don't always

00:18:11.690 --> 00:18:14.120
understand how they work.

00:18:14.120 --> 00:18:16.790
But there is this
interesting thing

00:18:16.790 --> 00:18:21.440
that you pay most, in terms
of the GC time for objects

00:18:21.440 --> 00:18:24.040
that are middle--

00:18:24.040 --> 00:18:27.366
they're not dying young and
they're not dying very old.

00:18:27.366 --> 00:18:28.490
They're kind of in between.

00:18:28.490 --> 00:18:30.780
And you pay most for those.

00:18:30.780 --> 00:18:35.030
And as I said-- for example,
I showed this call side

00:18:35.030 --> 00:18:38.330
optimization that we
do in the AT compiler.

00:18:38.330 --> 00:18:40.490
So you can see from
that that, for example,

00:18:40.490 --> 00:18:43.040
the monomorphic
call side is much

00:18:43.040 --> 00:18:45.749
faster than polymorphic
or megamorphic call side.

00:18:45.749 --> 00:18:47.540
So if you structure
your code in such a way

00:18:47.540 --> 00:18:50.280
that you can avoid polymorphism,
that usually is good.

00:18:50.280 --> 00:18:51.530
And it's good in any language.

00:18:51.530 --> 00:18:55.730
It's not even limited to Dart.

00:18:55.730 --> 00:18:58.280
So once you kind of understood
all of these things,

00:18:58.280 --> 00:19:00.830
you start by applying
some abstract algorithmic

00:19:00.830 --> 00:19:02.600
optimizations.

00:19:02.600 --> 00:19:06.770
And just try to
reduce the complexity,

00:19:06.770 --> 00:19:09.110
reduce the amount of
stuff that you're doing.

00:19:09.110 --> 00:19:13.190
And then you start applying some
engine-specific optimizations,

00:19:13.190 --> 00:19:16.790
which you derive by talking
to VM people, for example.

00:19:16.790 --> 00:19:21.210
OK, so-- not really.

00:19:21.210 --> 00:19:26.730
So I mostly focused on
the compiler in this talk,

00:19:26.730 --> 00:19:30.480
right, because that's
what I do most of my days.

00:19:30.480 --> 00:19:36.350
But VM is not really
limited to just compiler.

00:19:36.350 --> 00:19:38.970
For example, there is
a garbage collector.

00:19:38.970 --> 00:19:43.860
And VM uses a combination
of Young Space Scavenger

00:19:43.860 --> 00:19:45.720
and Parallel Mark
Sweep, as if it's

00:19:45.720 --> 00:19:47.550
telling somebody
something-- unless you

00:19:47.550 --> 00:19:50.146
have read the big book
about garbage collection.

00:19:50.146 --> 00:19:52.770
So I'm going to show you how the
garbage collection works, very

00:19:52.770 --> 00:19:57.450
quickly, and why some people say
that this is good for Flutter.

00:19:57.450 --> 00:20:00.515
So in new space--

00:20:03.230 --> 00:20:05.350
OK, no new space,
let's say, like that.

00:20:05.350 --> 00:20:07.260
So when you allocate
objects, what happens

00:20:07.260 --> 00:20:09.570
is that we have some sort
of continuous memory buffer,

00:20:09.570 --> 00:20:10.699
and a pointer in it.

00:20:10.699 --> 00:20:12.240
And when you allocate
things, it just

00:20:12.240 --> 00:20:15.980
goes and puts stuff in this
buffer, one by one, [INAUDIBLE]

00:20:15.980 --> 00:20:16.830
and again.

00:20:16.830 --> 00:20:19.830
And when you create a
closure it's also an object.

00:20:19.830 --> 00:20:21.510
So it needs to be allocated.

00:20:21.510 --> 00:20:24.465
And eventually it fills it up.

00:20:24.465 --> 00:20:25.840
A surprising
thing-- that we need

00:20:25.840 --> 00:20:29.640
to allocate an object when
you return a newly-created

00:20:29.640 --> 00:20:32.670
double from a function.

00:20:32.670 --> 00:20:36.870
And then when you've filled
up this buffer, GC comes.

00:20:36.870 --> 00:20:38.580
The young space GC comes.

00:20:38.580 --> 00:20:40.620
And what it does,
it says, I have

00:20:40.620 --> 00:20:43.170
some other continuous buffer.

00:20:43.170 --> 00:20:46.440
And I have pointers,
like some routes,

00:20:46.440 --> 00:20:49.646
like static variables
and stack pointers.

00:20:49.646 --> 00:20:52.020
And I look at what they're
pointing to-- these things are

00:20:52.020 --> 00:20:53.320
going to survive.

00:20:53.320 --> 00:20:56.040
And then I start copying
everything that survives,

00:20:56.040 --> 00:20:59.250
and traversing the graph
and copying and copying.

00:20:59.250 --> 00:21:00.959
And eventually I've
copied everything.

00:21:00.959 --> 00:21:03.250
So everything that is not
copied just dies immediately.

00:21:03.250 --> 00:21:05.970
There is no reason
to traverse anything.

00:21:05.970 --> 00:21:08.640
And what was copied survives.

00:21:08.640 --> 00:21:10.680
And the allocation
will go there.

00:21:10.680 --> 00:21:14.430
And when this one fills up, it
happens again in the other way.

00:21:14.430 --> 00:21:18.602
So you use the previously
emptied buffer to copy into it,

00:21:18.602 --> 00:21:19.560
and so on and so forth.

00:21:19.560 --> 00:21:22.380
This is what Scavenger is doing.

00:21:22.380 --> 00:21:24.720
Then there is a
mark sweep thing.

00:21:24.720 --> 00:21:26.820
In reality, you
have young space,

00:21:26.820 --> 00:21:29.430
which Scavenger
manages and compacts

00:21:29.430 --> 00:21:32.130
all the time by copying.

00:21:32.130 --> 00:21:36.452
And periodically, you promote
things that survive too long.

00:21:36.452 --> 00:21:38.160
Like, if it survived
several collections,

00:21:38.160 --> 00:21:40.493
you don't want to copy it
back and forth back and forth,

00:21:40.493 --> 00:21:41.220
again and again.

00:21:41.220 --> 00:21:44.160
So you promote it in
some other old space,

00:21:44.160 --> 00:21:48.390
which is managed by a much more
expansive garbage collection

00:21:48.390 --> 00:21:52.371
algorithm, which traverses
the whole graph of objects.

00:21:52.371 --> 00:21:54.120
I'm not going to
illustrate how that works

00:21:54.120 --> 00:21:56.850
because it will take too long.

00:21:56.850 --> 00:21:59.220
So one thing you should
have figured here

00:21:59.220 --> 00:22:02.370
is that there is a relatively
fast scavenge phase,

00:22:02.370 --> 00:22:06.030
but they're also expansive
mark sweep, potentially,

00:22:06.030 --> 00:22:10.170
when the old space fills up.

00:22:10.170 --> 00:22:15.030
So recently, we have implemented
something called idle time

00:22:15.030 --> 00:22:19.290
GC, which is a collaborative
way of scheduling the GC where

00:22:19.290 --> 00:22:23.460
the Flutter engine framework
sends signals to the VM

00:22:23.460 --> 00:22:26.970
and allows to time
the GC in such a way

00:22:26.970 --> 00:22:30.450
that the longer GCs that
operate on the whole heap,

00:22:30.450 --> 00:22:35.370
they fit into the time when
there is no animation going on.

00:22:35.370 --> 00:22:36.560
So the jank is reduced.

00:22:39.450 --> 00:22:43.000
Then we also implemented
compaction, which we didn't

00:22:43.000 --> 00:22:45.030
have for a very long time.

00:22:45.030 --> 00:22:47.280
Like, if you go
back in the slides,

00:22:47.280 --> 00:22:49.740
you see that the old
space, unlike new space,

00:22:49.740 --> 00:22:50.980
is fragmented.

00:22:50.980 --> 00:22:54.150
There are holes
between objects, which

00:22:54.150 --> 00:22:56.470
means the allocation in
an old space takes time.

00:22:56.470 --> 00:23:00.490
There is unused space,
and so on and so forth.

00:23:00.490 --> 00:23:04.710
So the compaction allows to
reclaim this unused space

00:23:04.710 --> 00:23:08.580
between objects and reduce
fragmentation and improve

00:23:08.580 --> 00:23:10.410
allocation space
in an old space.

00:23:10.410 --> 00:23:12.510
And it works very well
with an idle time GC

00:23:12.510 --> 00:23:15.480
because the compaction
is a costly procedure.

00:23:15.480 --> 00:23:18.150
But you can schedule it in such
a way that you cannot actually

00:23:18.150 --> 00:23:20.570
see it on the animations.

00:23:20.570 --> 00:23:26.910
OK, we have some work in
progress for 64-bit systems,

00:23:26.910 --> 00:23:29.310
compressed pointers.

00:23:29.310 --> 00:23:33.447
As you know, in 64-bit systems--
like iPhone is a 64-bit system.

00:23:33.447 --> 00:23:35.280
Or if you're running
Dart on a server, which

00:23:35.280 --> 00:23:41.680
I encourage you to do, they
usually run on 64-bit servers.

00:23:41.680 --> 00:23:43.440
The pointers are 64-bit.

00:23:43.440 --> 00:23:46.800
And of course, if the
majority of your heap

00:23:46.800 --> 00:23:51.330
consists of pointers,
that's a lot of space there.

00:23:51.330 --> 00:23:52.830
The compressed
pointers allow you

00:23:52.830 --> 00:23:56.940
to compress the
pointers to 32 bits

00:23:56.940 --> 00:24:00.240
and reduce the memory footprint.

00:24:00.240 --> 00:24:02.044
Our preliminary
measurements show

00:24:02.044 --> 00:24:03.960
that, for example, in
the Dart to GS compiler,

00:24:03.960 --> 00:24:06.660
compiling some very
big applications,

00:24:06.660 --> 00:24:11.610
you can save like 30% of memory
and make it faster, actually,

00:24:11.610 --> 00:24:14.711
because the GC time is reduced.

00:24:14.711 --> 00:24:16.210
So this is the real
thank-you slide.

00:24:16.210 --> 00:24:18.266
So thank you for your attention.

00:24:18.266 --> 00:24:22.050
[APPLAUSE]

00:24:22.050 --> 00:24:24.380
Before I get kicked
out from the stage,

00:24:24.380 --> 00:24:27.080
I would like you to invite
to talk to us-- to me,

00:24:27.080 --> 00:24:30.800
in particular, and anybody
from the VM team who is here.

00:24:30.800 --> 00:24:34.010
I cannot see because of this
light going into my eyes,

00:24:34.010 --> 00:24:36.200
but I ask--

00:24:36.200 --> 00:24:39.270
everybody from the VM,
can you raise the hands?

00:24:39.270 --> 00:24:40.690
And stand up even, yeah.

00:24:40.690 --> 00:24:42.020
Can you stand up?

00:24:42.020 --> 00:24:42.740
Please, stand up.

00:24:42.740 --> 00:24:44.510
Don't be shy.

00:24:44.510 --> 00:24:46.850
Yes, so there are some
people from the VM team.

00:24:46.850 --> 00:24:49.020
Come talk to them and to me.

00:24:49.020 --> 00:24:50.270
Yes, thank you.

00:24:50.270 --> 00:24:53.320
[APPLAUSE]

