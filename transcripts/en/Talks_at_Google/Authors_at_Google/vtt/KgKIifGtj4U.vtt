WEBVTT
Kind: captions
Language: en

00:00:01.102 --> 00:00:02.560
MATTHEW STEPKA:
I'm Matthew Stepka.

00:00:03.730 --> 00:00:05.810
I'm head of Social
Impact at Google.

00:00:05.810 --> 00:00:08.230
Social Impact is working on
how technology makes society

00:00:08.230 --> 00:00:09.070
better.

00:00:09.070 --> 00:00:12.030
And in particular, we work
a lot in civic innovation,

00:00:12.030 --> 00:00:15.230
working on how we can built
tools for people to better

00:00:15.230 --> 00:00:17.150
engage in their
communities, as well as

00:00:17.150 --> 00:00:20.000
making cities run better,
operate better with real time

00:00:20.000 --> 00:00:23.100
data and open platforms,
everything from transportation

00:00:23.100 --> 00:00:24.660
to public health.

00:00:24.660 --> 00:00:27.000
Today we have two
authors with us.

00:00:27.000 --> 00:00:29.540
We have Stephen Goldsmith who
is the head of Innovations

00:00:29.540 --> 00:00:32.547
and American Government at
the Harvard Kennedy School,

00:00:32.547 --> 00:00:34.380
as well as Susan Crawford,
who is a visiting

00:00:34.380 --> 00:00:37.060
professor at Harvard Law, and
previously a senior leader

00:00:37.060 --> 00:00:38.250
in the Obama administration.

00:00:38.250 --> 00:00:40.070
They [INAUDIBLE] with
a new book, which is

00:00:40.070 --> 00:00:42.860
called-- and I have read
it-- "Responsive Cities."

00:00:42.860 --> 00:00:44.571
So please join me
in welcoming them

00:00:44.571 --> 00:00:46.570
to have a discussion about
what cities is about.

00:00:46.570 --> 00:00:48.690
To be honest, from
my perspective,

00:00:48.690 --> 00:00:51.280
cities are the platform for
change and civic innovation.

00:00:51.280 --> 00:00:52.980
It's the place where we see
the most courage and the most

00:00:52.980 --> 00:00:54.270
activity, both
from the ground up,

00:00:54.270 --> 00:00:56.603
as well as from very courageous
mayors around the world.

00:00:56.603 --> 00:00:59.170
And at the same time, it's
where we have a very dire need

00:00:59.170 --> 00:01:00.250
to make things better.

00:01:00.250 --> 00:01:02.750
There's been a great movement--
and we just got off the Code

00:01:02.750 --> 00:01:04.590
for America summit
just recently.

00:01:04.590 --> 00:01:07.420
There's a lot of enthusiasm
both from youth and young people

00:01:07.420 --> 00:01:08.380
of all ages.

00:01:08.380 --> 00:01:10.830
And also you have people
from the mayors and leaders

00:01:10.830 --> 00:01:12.289
have really showed
a lot of courage

00:01:12.289 --> 00:01:14.538
to make these changes happen,
even though they may not

00:01:14.538 --> 00:01:15.530
understand technology.

00:01:15.530 --> 00:01:17.696
They may be a little
intimidated by the whole thing.

00:01:17.696 --> 00:01:20.520
But it makes a bit difference
when they get involved.

00:01:20.520 --> 00:01:22.920
And this book does a great
job chronicling this movement,

00:01:22.920 --> 00:01:25.380
starting from Boston and the
early days of getting people

00:01:25.380 --> 00:01:27.431
involved, by going all
around world actually.

00:01:27.431 --> 00:01:28.680
This is becoming a phenomenon.

00:01:28.680 --> 00:01:30.180
And I think it's a great read.

00:01:30.180 --> 00:01:31.096
It's very interesting.

00:01:31.096 --> 00:01:32.742
I'd love to hear more
about your ideas.

00:01:32.742 --> 00:01:34.450
STEPHEN GOLDSMITH:
Thanks for joining us.

00:01:34.450 --> 00:01:35.900
We're going to use this deck.

00:01:35.900 --> 00:01:37.920
We're going to run
through it quickly.

00:01:37.920 --> 00:01:40.700
We are rigorously bipartisan.

00:01:40.700 --> 00:01:42.490
So Susan worked in
the Obama White House.

00:01:42.490 --> 00:01:43.590
I worked in the
Bush White House.

00:01:43.590 --> 00:01:44.430
Susan teaches law.

00:01:44.430 --> 00:01:45.510
I teach public policy.

00:01:46.286 --> 00:01:47.660
When you buy the
book, you'll see

00:01:47.660 --> 00:01:50.905
in the back we have exactly
the same number of Republican

00:01:50.905 --> 00:01:53.494
and Democrat endorsers
on the back of the book.

00:01:53.494 --> 00:01:55.660
We're going to split the
time 50-50 and then Susan--

00:01:55.660 --> 00:01:58.620
I get the last rebuttal,
because I'll need it.

00:01:58.620 --> 00:02:01.920
So look, let me just talk to you
a little bit about what we're

00:02:01.920 --> 00:02:04.090
doing and then go
through the book quickly.

00:02:05.444 --> 00:02:06.860
AUDIENCE: You hit
the right arrow.

00:02:06.860 --> 00:02:08.901
STEPHEN GOLDSMITH: I assume
it's like this, yeah.

00:02:10.979 --> 00:02:13.460
I've been in government
for a long time.

00:02:13.460 --> 00:02:17.960
And government doesn't
use its data very well.

00:02:17.960 --> 00:02:18.890
But it's beginning to.

00:02:18.890 --> 00:02:21.850
So we've looked at
trends in the US

00:02:21.850 --> 00:02:23.350
and a little bit
around the country,

00:02:23.350 --> 00:02:26.360
trying to figure out what
the future's government is

00:02:26.360 --> 00:02:27.975
in this technology revolution.

00:02:27.975 --> 00:02:29.990
And I think Susan
and I both believe

00:02:29.990 --> 00:02:33.310
that we're on the cusp of
a massive change in the way

00:02:33.310 --> 00:02:35.260
government produces
public goods,

00:02:35.260 --> 00:02:37.210
and the way it engages
with its community.

00:02:37.210 --> 00:02:39.850
So let's run through this really
quickly with some concepts.

00:02:42.410 --> 00:02:43.990
You all know all these things.

00:02:43.990 --> 00:02:46.030
But this opportunity
for massive change

00:02:46.030 --> 00:02:50.690
comes from the confluence
of all these initiatives.

00:02:50.690 --> 00:02:52.940
Because from the
city level-- it's

00:02:52.940 --> 00:02:55.920
not been that many
years from the time

00:02:55.920 --> 00:02:59.296
that city workers carried
paper around in their cars

00:02:59.296 --> 00:03:01.170
to the time that they
now carry smart phones.

00:03:01.170 --> 00:03:05.590
So the ubiquity of the mobile
devices-- obviously the cloud

00:03:05.590 --> 00:03:07.910
computing movement
is relatively new.

00:03:07.910 --> 00:03:10.660
But maybe the best way
to think about this--

00:03:10.660 --> 00:03:14.290
and you're all in it, so
you may not realize it.

00:03:14.290 --> 00:03:18.650
But I was working for Mike
Bloomberg as deputy mayor

00:03:18.650 --> 00:03:22.050
one day, and I was responsible,
driving innovation.

00:03:22.050 --> 00:03:24.412
So I turned around--
we sat in an open room.

00:03:24.412 --> 00:03:25.370
Nobody had any offices.

00:03:25.370 --> 00:03:27.500
I turned around to him-- I
got the best innovative idea.

00:03:27.500 --> 00:03:28.930
It'll drive the most
change in city government.

00:03:28.930 --> 00:03:29.763
He says, what is it?

00:03:29.763 --> 00:03:31.840
I said well, just
eliminate paper by the time

00:03:31.840 --> 00:03:33.100
you're through being mayor.

00:03:33.100 --> 00:03:36.600
And he looks at me like, is
this really the best you can do?

00:03:36.600 --> 00:03:38.980
Is this the most creative
thing-- but the whole goal

00:03:38.980 --> 00:03:42.400
was to take this inaccessible
amount of information,

00:03:42.400 --> 00:03:45.855
generally equated with
running transactions,

00:03:45.855 --> 00:03:48.230
and take it into digits, and
the digits into information,

00:03:48.230 --> 00:03:49.930
and the information into
changing the way that we

00:03:49.930 --> 00:03:50.980
manufacture government.

00:03:50.980 --> 00:03:53.820
And so all of these
things are on their way.

00:03:53.820 --> 00:03:56.680
So the first thing that,
in terms of breakthroughs

00:03:56.680 --> 00:03:59.575
that might be worth
mentioning-- remember,

00:03:59.575 --> 00:04:01.700
my perspective is mostly
a government perspective--

00:04:01.700 --> 00:04:05.940
is government performance,
generally up till recently,

00:04:05.940 --> 00:04:10.330
has been a definition of
how you run faster in place.

00:04:10.330 --> 00:04:12.470
So your job in government
is to manufacture

00:04:12.470 --> 00:04:13.662
a set of activities.

00:04:13.662 --> 00:04:14.870
You produce those activities.

00:04:14.870 --> 00:04:16.025
The definition of
performance is you

00:04:16.025 --> 00:04:17.920
do more and more
activities, irrespective of

00:04:17.920 --> 00:04:21.149
whether those activities
actually produce the results.

00:04:21.149 --> 00:04:24.810
And you get caught
up in this treadmill.

00:04:24.810 --> 00:04:28.062
And this is just an
example focusing on data.

00:04:28.062 --> 00:04:29.520
There's lots of
different examples.

00:04:29.520 --> 00:04:33.680
But this is one
from New York City,

00:04:33.680 --> 00:04:36.590
from the deputy mayor who was
in charge of this, Linda Gibbs.

00:04:36.590 --> 00:04:39.700
And she had an agency
earlier in her career

00:04:39.700 --> 00:04:41.510
that was an agency for homeless.

00:04:41.510 --> 00:04:45.075
And the way they measured their
efficiency in homeless services

00:04:45.075 --> 00:04:47.950
is how many beds they provided
for those who are homeless.

00:04:47.950 --> 00:04:50.390
So she walked in
one day and said

00:04:50.390 --> 00:04:52.770
how you define public value?

00:04:52.770 --> 00:04:54.460
Because that's the
world we're in.

00:04:54.460 --> 00:04:55.990
We produce public value.

00:04:55.990 --> 00:04:57.910
How do you define
probably value?

00:04:57.910 --> 00:04:59.946
And they said our
definition of public value

00:04:59.946 --> 00:05:02.260
is the number of homeless
beds that we produce.

00:05:02.260 --> 00:05:03.646
And she said no, no.

00:05:03.646 --> 00:05:05.020
That's the definition
of failure.

00:05:05.020 --> 00:05:06.900
The definition of
success is the number

00:05:06.900 --> 00:05:08.900
of people who would be
homeless that we prevent,

00:05:08.900 --> 00:05:10.220
as a result of our work.

00:05:10.220 --> 00:05:12.276
So now you can think
about this for a second,

00:05:12.276 --> 00:05:13.650
particularly in
the world of data

00:05:13.650 --> 00:05:16.459
across many different
agencies, and say well this

00:05:16.459 --> 00:05:18.000
is a good definition
of public value,

00:05:18.000 --> 00:05:19.660
but one that requires
much more data,

00:05:19.660 --> 00:05:21.250
like why are some
people homeless?

00:05:21.250 --> 00:05:24.080
Which providers work with
which types of homeless Folks

00:05:24.080 --> 00:05:25.920
How do we intervene,
and when do we

00:05:25.920 --> 00:05:27.455
intervene, with what activities?

00:05:27.455 --> 00:05:29.080
And this-- I don't
want to go on and on

00:05:29.080 --> 00:05:30.590
about how government operates.

00:05:30.590 --> 00:05:33.937
But you can imagine that if
your definition of public value

00:05:33.937 --> 00:05:35.520
is preventing
homelessness, and you're

00:05:35.520 --> 00:05:37.610
trying to look at what
makes a difference,

00:05:37.610 --> 00:05:41.227
that the use of data across the
system, not just the agency,

00:05:41.227 --> 00:05:42.185
makes a big difference.

00:05:43.220 --> 00:05:47.880
And just other examples--
think about activities.

00:05:47.880 --> 00:05:49.380
It used to be, just
a few years ago,

00:05:49.380 --> 00:05:52.570
that if you wanted to
improve traffic congestion,

00:05:52.570 --> 00:05:54.380
you added highways
or lane miles.

00:05:55.490 --> 00:05:58.660
But that's not necessarily
the way to improve congestion.

00:05:58.660 --> 00:06:01.600
One way might be to use
the internet of things,

00:06:01.600 --> 00:06:03.170
if you will, and
capture, like we

00:06:03.170 --> 00:06:07.050
did in New York City, a lot
of data from E-ZPass readers.

00:06:07.050 --> 00:06:12.330
And GPS's in taxicabs
automatically connect

00:06:12.330 --> 00:06:16.310
that to the traffic signals
and reset the traffic signals,

00:06:16.310 --> 00:06:19.050
based on the actual speed
of traffic at that moment.

00:06:20.390 --> 00:06:24.100
So instead of the
activity being lane miles,

00:06:24.100 --> 00:06:28.340
the public goal is to produce
a smoothness of traffic

00:06:28.340 --> 00:06:29.610
and reduction in congestion.

00:06:29.610 --> 00:06:31.990
So we begin to think about
how massive amounts of data

00:06:31.990 --> 00:06:35.010
dramatically change
the way folks operate.

00:06:35.010 --> 00:06:37.380
Now the next step
in that, obviously,

00:06:37.380 --> 00:06:43.850
is-- so I've been in
government a long time.

00:06:43.850 --> 00:06:47.180
And we used to think that the
way we measured performance

00:06:47.180 --> 00:06:49.725
is how many potholes
we filled, how quickly.

00:06:50.930 --> 00:06:54.850
So this means that we can fill
the same pothole over and over

00:06:54.850 --> 00:06:57.240
again, very, very
quickly, and that

00:06:57.240 --> 00:06:58.890
would be an accomplishment.

00:06:58.890 --> 00:07:01.770
But what if we could predict
where the pothole would be?

00:07:01.770 --> 00:07:03.890
Because there is
an underlying steam

00:07:03.890 --> 00:07:05.880
line, or some other problem.

00:07:05.880 --> 00:07:09.340
Or in this case--
there's a longer case

00:07:09.340 --> 00:07:12.100
behind this in the book--
what if we could actually

00:07:12.100 --> 00:07:15.360
predict where the next fire
is going to be-- predict it

00:07:15.360 --> 00:07:21.110
from crime reports, and code
enforcement reports, and tax

00:07:21.110 --> 00:07:24.890
delinquencies, and
foreclosures of mortgages.

00:07:24.890 --> 00:07:25.920
And then we would know.

00:07:25.920 --> 00:07:27.060
And we did this experiment.

00:07:27.060 --> 00:07:29.680
Many of you know the story of
Mike Flowers in New York City.

00:07:29.680 --> 00:07:31.140
We did this in New York City.

00:07:31.140 --> 00:07:33.719
It increased by 1,000
times the predictability

00:07:33.719 --> 00:07:35.260
of which buildings
are actually going

00:07:35.260 --> 00:07:38.221
to burn, inside these tens
of thousands of complaints

00:07:38.221 --> 00:07:38.720
that we get.

00:07:38.720 --> 00:07:40.570
So now we have a
government that moves

00:07:40.570 --> 00:07:42.500
from being reactive
to proactive,

00:07:42.500 --> 00:07:44.090
to solving problems
before they occur.

00:07:44.090 --> 00:07:47.050
And you begin to get an idea
that the data upon which we sit

00:07:47.050 --> 00:07:49.360
provides for an
opportunity for massive,

00:07:49.360 --> 00:07:51.940
I mean massive, changes
in the way we do-- just

00:07:51.940 --> 00:07:53.350
think 80-20 rules.

00:07:53.350 --> 00:07:56.640
Today government manufactures
the exact same widget

00:07:56.640 --> 00:07:59.090
for everybody, no matter
whether they need it.

00:07:59.090 --> 00:08:02.360
And it doesn't
allocate its resources

00:08:02.360 --> 00:08:03.880
in the best possible way.

00:08:03.880 --> 00:08:07.730
More stories and we've
chronicled them in the book.

00:08:07.730 --> 00:08:13.510
Policing obviously, parole
violations-- even today

00:08:13.510 --> 00:08:16.351
in this country there are
probation officers and parole

00:08:16.351 --> 00:08:16.850
officers.

00:08:16.850 --> 00:08:18.600
They have huge caseloads.

00:08:18.600 --> 00:08:21.016
They allocate their time
across these caseloads.

00:08:22.300 --> 00:08:24.670
They do very little,
as Philadelphia is now

00:08:24.670 --> 00:08:27.990
doing, of using the data to
predict which offenders need

00:08:27.990 --> 00:08:29.770
what types of attention,
which offenders

00:08:29.770 --> 00:08:31.570
need no attention,
which offenders need

00:08:31.570 --> 00:08:33.039
what sort of support services.

00:08:33.039 --> 00:08:35.390
And then re-calibrating
the assignment

00:08:35.390 --> 00:08:37.870
of the cases, the
provision of the services,

00:08:37.870 --> 00:08:39.370
and making a
substantial difference.

00:08:39.370 --> 00:08:41.960
And Philadelphia's done this
in a really dramatic way.

00:08:41.960 --> 00:08:43.309
It's kind of like homelessness.

00:08:43.309 --> 00:08:44.610
How do you make a difference?

00:08:44.610 --> 00:08:45.950
How do you calibrate your cases?

00:08:45.950 --> 00:08:48.570
How do you spend time
on your outliers?

00:08:48.570 --> 00:08:52.330
So one thing that we've done in
the book is looked at big data

00:08:52.330 --> 00:08:56.100
predictive analytics inside
the enterprise of government.

00:08:56.100 --> 00:08:59.370
But one risk of
this, of course, is

00:08:59.370 --> 00:09:04.170
that it makes the-- so the
definition of professionalism

00:09:04.170 --> 00:09:07.990
in government is that I get
trained in a very technical set

00:09:07.990 --> 00:09:10.530
of skills, inside an agency.

00:09:10.530 --> 00:09:12.430
So then I really know
what's in the best

00:09:12.430 --> 00:09:13.513
interest of the community.

00:09:13.513 --> 00:09:14.680
Now I've got big data.

00:09:14.680 --> 00:09:17.370
So now I really know what's in
everybody else's best interest.

00:09:17.370 --> 00:09:19.280
I don't have to
listen to them at all.

00:09:19.280 --> 00:09:22.460
Well, this is a very narrow
sense of professionalism.

00:09:22.460 --> 00:09:25.700
So the next question becomes how
to-- and the one that you all

00:09:25.700 --> 00:09:28.890
are engaged in dramatically--
is how does one

00:09:28.890 --> 00:09:31.110
use the data that's out
there, the social media

00:09:31.110 --> 00:09:33.880
data, the big data, the open
data movement, to connect

00:09:33.880 --> 00:09:37.990
citizens to their communities
and vice versa, so we're

00:09:37.990 --> 00:09:40.690
socializing the problem
solving and increasing

00:09:40.690 --> 00:09:42.400
a new sense of citizenship.

00:09:42.400 --> 00:09:45.154
And for that answer I
give you Susan Crawford.

00:09:45.154 --> 00:09:47.070
SUSAN CRAWFORD: So this
is a more nascent area

00:09:47.070 --> 00:09:49.700
of this development, that
we're seeing the opportunity

00:09:49.700 --> 00:09:55.080
using fiber data and algorithms
and sensors to bring citizens

00:09:55.080 --> 00:09:58.860
in to the work of government.

00:09:58.860 --> 00:10:02.920
The open data movement
has been a big focus

00:10:02.920 --> 00:10:06.600
of activities and interests
since the beginning

00:10:06.600 --> 00:10:11.060
of talk about new responsive
forms of government.

00:10:11.060 --> 00:10:14.700
And something the book
focuses on a great deal

00:10:14.700 --> 00:10:17.420
is the power, these days, to
use the massive amounts of data

00:10:17.420 --> 00:10:20.130
that Steve's talking
about to make patterns

00:10:20.130 --> 00:10:23.590
visual to citizens and make
problems visible to them

00:10:23.590 --> 00:10:25.640
in ways that were
impossible before.

00:10:25.640 --> 00:10:27.950
So you could
display, on a screen,

00:10:27.950 --> 00:10:31.450
where a citizen's input
might be most valuable

00:10:31.450 --> 00:10:33.980
and ensure that you're
getting their input in a way

00:10:33.980 --> 00:10:35.950
that the government
could then respond to.

00:10:37.100 --> 00:10:41.880
Third party use of data and
driving towards useful apps,

00:10:41.880 --> 00:10:45.870
using open data, is a pretty
faddish subject at the moment.

00:10:45.870 --> 00:10:49.130
But it seems to be
generating great interest,

00:10:49.130 --> 00:10:52.032
particularly in places
like Chicago, where they've

00:10:52.032 --> 00:10:53.490
opened up enormous
amounts of data,

00:10:53.490 --> 00:10:56.060
just starting a few
years ago, and are seeing

00:10:56.060 --> 00:10:59.100
their civic hacker community
and startup community

00:10:59.100 --> 00:11:01.116
use it extremely
interesting ways.

00:11:01.116 --> 00:11:02.490
Same thing's
happened in England.

00:11:03.850 --> 00:11:09.390
Not as much as we'd like to see,
so far of third party use that

00:11:09.390 --> 00:11:14.270
has big payoffs, in the
terms of commercial payoffs

00:11:14.270 --> 00:11:16.300
for those uses.

00:11:16.300 --> 00:11:18.800
But something we found
in working on the book

00:11:18.800 --> 00:11:22.190
is that open data can
often drive collaboration

00:11:22.190 --> 00:11:24.250
inside government,
even more than it

00:11:24.250 --> 00:11:26.170
drives for citizen engagement.

00:11:26.170 --> 00:11:28.390
But this is a
nascent opportunity

00:11:28.390 --> 00:11:29.670
for the use of data.

00:11:29.670 --> 00:11:32.450
A story told in the book
that's quite dramatic

00:11:32.450 --> 00:11:35.950
is the evolution of the
Citizens Connect app

00:11:35.950 --> 00:11:40.190
in Boston, brought about by
the Boston Office of New Urban

00:11:40.190 --> 00:11:43.290
Mechanics, where citizens
using a handheld device

00:11:43.290 --> 00:11:46.500
were able to essentially
phone in about

00:11:46.500 --> 00:11:49.075
problems in their neighborhood
with geolocated pictures.

00:11:50.290 --> 00:11:52.410
What we learned in
telling this story

00:11:52.410 --> 00:11:56.110
is that citizens felt that
when they were using an app

00:11:56.110 --> 00:11:58.964
to report in, they felt
that they were helping.

00:11:58.964 --> 00:12:00.380
When they use the
phone line, they

00:12:00.380 --> 00:12:01.900
feel like they're complaining.

00:12:01.900 --> 00:12:04.852
And this is all so new so far.

00:12:04.852 --> 00:12:06.560
We know there's so
many more ways that we

00:12:06.560 --> 00:12:09.460
could be engaging with citizens
and collecting data that then

00:12:09.460 --> 00:12:12.680
goes directly into a
311, that 311 really

00:12:12.680 --> 00:12:15.660
can be a platform for
engagement, in a rich way.

00:12:15.660 --> 00:12:17.790
New York is driving
in this direction.

00:12:17.790 --> 00:12:19.390
Boston is too.

00:12:19.390 --> 00:12:22.520
And obviously, lots of
ways to engage citizens

00:12:22.520 --> 00:12:24.080
in creating and using that data.

00:12:25.130 --> 00:12:27.360
So it doesn't have to always
be the government that's

00:12:27.360 --> 00:12:28.980
producing the
services, but citizens

00:12:28.980 --> 00:12:32.310
can be helping to ensure that
their parks and neighborhoods

00:12:32.310 --> 00:12:33.655
are safer and more interesting.

00:12:34.980 --> 00:12:37.690
And a tremendously
interesting development

00:12:37.690 --> 00:12:42.260
is that of using intermediaries
between government and citizens

00:12:42.260 --> 00:12:46.067
to ensure that voices are being
amplified in the citizen group

00:12:46.067 --> 00:12:47.900
and that government is
capable of listening.

00:12:47.900 --> 00:12:49.860
Chicago has a
particularly good example

00:12:49.860 --> 00:12:52.440
of this in the Smart
Chicago Collaborative

00:12:52.440 --> 00:12:57.120
that has been funded by
foundation support in Chicago

00:12:57.120 --> 00:13:01.030
and has a users group ready
to go, testing new apps,

00:13:01.030 --> 00:13:05.480
and ensuring that
people in the community

00:13:05.480 --> 00:13:08.630
are aware of what the local
government is attempting

00:13:08.630 --> 00:13:11.550
to move forward on,
and also serving

00:13:11.550 --> 00:13:14.490
as a test bed for new steps
that Chicago City Hall wants

00:13:14.490 --> 00:13:15.280
to take.

00:13:15.280 --> 00:13:17.100
The Smart Chicago
Collaborative is a model

00:13:17.100 --> 00:13:20.840
we believe that could be
echoed across many cities,

00:13:20.840 --> 00:13:23.470
in a very useful way, to
amplify voice and serve

00:13:23.470 --> 00:13:27.705
as a conduit between
City Hall and citizens.

00:13:29.670 --> 00:13:31.430
We don't have
enough of this yet.

00:13:31.430 --> 00:13:35.260
But residents forcing
responsiveness using data

00:13:35.260 --> 00:13:41.600
seems like a very fruitful area
for development for the future.

00:13:41.600 --> 00:13:44.580
In the city the
District of Columbia,

00:13:44.580 --> 00:13:47.420
grade.dc.gov is
allowing for feedback

00:13:47.420 --> 00:13:50.770
on the grumpy DMV person
at the head of the line,

00:13:50.770 --> 00:13:53.535
so that perhaps management
will move that person out

00:13:53.535 --> 00:13:58.410
if they're in the wrong
job for their proclivities.

00:13:58.410 --> 00:14:02.070
So far limited
engagement in this tool,

00:14:02.070 --> 00:14:05.940
but we are looking
forward to more

00:14:05.940 --> 00:14:08.700
of these kinds of applications
that take in data from lots

00:14:08.700 --> 00:14:13.220
of different directions and feed
it into government services.

00:14:13.220 --> 00:14:17.060
Frankly, we see an enormous
community engagement

00:14:17.060 --> 00:14:19.200
at the grassroots
level, enormous energy

00:14:19.200 --> 00:14:20.730
inside City Hall.

00:14:20.730 --> 00:14:24.330
The trick now is to
combine these two pools

00:14:24.330 --> 00:14:26.560
and ensure the City
Hall's actually

00:14:26.560 --> 00:14:28.730
listening and acting
on what's happening.

00:14:28.730 --> 00:14:31.000
There are a lot of hopes
and dreams for this.

00:14:31.000 --> 00:14:34.190
But not as much action
as we should be seeing.

00:14:34.190 --> 00:14:35.800
The ultimate goal
of all of this is

00:14:35.800 --> 00:14:37.880
to create public value
that gives people

00:14:37.880 --> 00:14:41.720
a sense that there's good going
on behind the walls of City

00:14:41.720 --> 00:14:46.500
Hall and that there's a reason
for them to vote the next time

00:14:46.500 --> 00:14:50.440
and for dual engagement
between citizens and City Hall

00:14:50.440 --> 00:14:52.190
to produce solutions together.

00:14:52.190 --> 00:14:54.380
A renewed sense of
citizenship, more touch

00:14:54.380 --> 00:14:58.030
points between citizens and
their government, we think

00:14:58.030 --> 00:15:00.600
will create a thick
mesh of civic goods

00:15:00.600 --> 00:15:03.140
that are valuable for
everyone concerned.

00:15:03.140 --> 00:15:05.440
Because cities, as Matt
said at the outset,

00:15:05.440 --> 00:15:07.255
are seeing such
challenges, and seeing

00:15:07.255 --> 00:15:10.590
so many people move into them,
and such scarce resources,

00:15:10.590 --> 00:15:13.200
that we can only move forward
with citizens and government

00:15:13.200 --> 00:15:16.020
working together and
co-producing solutions.

00:15:16.020 --> 00:15:18.650
Moving from complaint
center to citizen as partner

00:15:18.650 --> 00:15:20.180
is the big shift here.

00:15:20.180 --> 00:15:23.320
And again, I think we're
just at the beginning.

00:15:23.320 --> 00:15:25.500
And hopes and dreams are strong.

00:15:26.740 --> 00:15:29.220
Useful shared
data-- another area

00:15:29.220 --> 00:15:33.670
where could be possible
for citizens again,

00:15:33.670 --> 00:15:38.440
using 311 as a platform, to
understand where problems are.

00:15:38.440 --> 00:15:40.490
And here's a very
important insight.

00:15:40.490 --> 00:15:43.590
Showing your work,
as a government,

00:15:43.590 --> 00:15:44.890
creates civic trust.

00:15:44.890 --> 00:15:48.620
And using 311 is an opportunity
to display what government

00:15:48.620 --> 00:15:50.760
is up to and have a
feeling that there's

00:15:50.760 --> 00:15:53.580
energy and, from
the citizen side,

00:15:53.580 --> 00:15:56.260
real focus on problems
that matter to them.

00:15:56.260 --> 00:15:58.160
We think it's a very
encouraging direction.

00:15:59.730 --> 00:16:03.150
But in order to act on
the citizen-created data

00:16:03.150 --> 00:16:06.320
and the input coming in from
the citizens with voice,

00:16:06.320 --> 00:16:09.460
you're going to need
employees within City Hall who

00:16:09.460 --> 00:16:11.820
are empowered and have
autonomy and agency.

00:16:11.820 --> 00:16:14.251
And to talk about that,
here's Steve again.

00:16:14.251 --> 00:16:15.750
When I was deputy
mayor of New York,

00:16:15.750 --> 00:16:19.140
we had a 311 reported to me,
an open data reported to me.

00:16:19.140 --> 00:16:22.370
And open data was how much
data could you get up,

00:16:22.370 --> 00:16:24.560
so that people could
see it, irrespective of

00:16:24.560 --> 00:16:27.200
whether the data was
in any usable format

00:16:27.200 --> 00:16:30.160
for the average person to be
able to make a difference.

00:16:30.160 --> 00:16:32.340
And then the 311,
as Susan mentioned,

00:16:32.340 --> 00:16:35.150
was a platform for people--
it was not a platform.

00:16:35.150 --> 00:16:36.880
It was a call center
for people to call

00:16:36.880 --> 00:16:38.110
to complain about government.

00:16:38.110 --> 00:16:40.230
So we got 20 million
calls a year,

00:16:40.230 --> 00:16:41.840
probably
disproportionately loaded

00:16:41.840 --> 00:16:46.630
by those who have a
strong voice and access.

00:16:46.630 --> 00:16:49.380
And then we took this map.

00:16:49.380 --> 00:16:54.050
And each yellow dot there
visualizes the number of people

00:16:54.050 --> 00:16:56.430
complaining about
something at that spot.

00:16:56.430 --> 00:16:59.030
And then we created
the easy to use

00:16:59.030 --> 00:17:01.180
interface and trained
the community boards.

00:17:01.180 --> 00:17:03.790
And they could drill down
behind these yellow dots

00:17:03.790 --> 00:17:05.409
and see all of the detail.

00:17:05.409 --> 00:17:06.700
When did the complaint come in?

00:17:06.700 --> 00:17:08.079
How long did it take?

00:17:08.079 --> 00:17:09.349
What was the complaint about?

00:17:09.349 --> 00:17:10.724
And so what happened
then, if you

00:17:10.724 --> 00:17:13.589
think about the world in
which you all operate,

00:17:13.589 --> 00:17:17.220
there's a mass of information
in these neighborhoods

00:17:17.220 --> 00:17:19.180
that's going on via
tweets or social media

00:17:19.180 --> 00:17:21.480
or person-to-person
conversations.

00:17:21.480 --> 00:17:23.001
And when they could
see these dots,

00:17:23.001 --> 00:17:24.500
and they could drill
down into them,

00:17:24.500 --> 00:17:25.990
they started to
provide solutions.

00:17:25.990 --> 00:17:29.180
Like you know why so
many people, older folks,

00:17:29.180 --> 00:17:32.160
were hit or nearly hit
at this intersection?

00:17:32.160 --> 00:17:34.907
Well, it was because
your walk signs

00:17:34.907 --> 00:17:36.990
are timed wrong, because
there's a pharmacy on one

00:17:36.990 --> 00:17:39.800
side of the street and there's
an old folks home on the other.

00:17:39.800 --> 00:17:44.350
So people live in neighborhoods.

00:17:44.350 --> 00:17:46.570
They don't live in
the vertical agencies

00:17:46.570 --> 00:17:48.180
of City Hall or state agencies.

00:17:48.180 --> 00:17:49.380
They don't live in the
Transportation Department.

00:17:49.380 --> 00:17:51.046
They don't live in
the Parks Department.

00:17:51.046 --> 00:17:53.090
They live in these
neighborhoods.

00:17:53.090 --> 00:17:54.120
And they see solutions.

00:17:54.120 --> 00:17:56.800
So that brings us
to the last point

00:17:56.800 --> 00:17:59.399
of the presentation, which
is that-- and I think

00:17:59.399 --> 00:18:01.440
the struggle that many of
you will see day-to-day

00:18:01.440 --> 00:18:05.490
in your work-- is that
government is not organized

00:18:05.490 --> 00:18:07.960
to allow its employees to
exercise their discretion

00:18:07.960 --> 00:18:09.080
to solve problems.

00:18:09.080 --> 00:18:10.600
The way we've
organized government

00:18:10.600 --> 00:18:13.205
is to make sure that we prevent
the abuse of discretion.

00:18:13.205 --> 00:18:15.920
And the way we've prevented
the abuse of discretion

00:18:15.920 --> 00:18:18.160
is we've prevented
the use of discretion.

00:18:18.160 --> 00:18:20.270
So good employees
cannot be good.

00:18:20.270 --> 00:18:23.150
Bad employees have a difficult
time being difficult-- I mean,

00:18:23.150 --> 00:18:23.807
being bad.

00:18:23.807 --> 00:18:25.640
But the really good
employees can't be good.

00:18:25.640 --> 00:18:27.780
So how do we give discretion?

00:18:27.780 --> 00:18:32.430
And without going--
and here again,

00:18:32.430 --> 00:18:35.190
if this building
looks like City Hall,

00:18:35.190 --> 00:18:37.087
we've got agencies
going up and down,

00:18:37.087 --> 00:18:38.670
so that people are
working vertically.

00:18:38.670 --> 00:18:43.090
And then we've got labor
contracts and the like.

00:18:43.090 --> 00:18:45.677
And so people are housed
in these little cells.

00:18:45.677 --> 00:18:47.510
And they can't get out
to solve the problem.

00:18:47.510 --> 00:18:50.080
So we're trying to
look at the use of data

00:18:50.080 --> 00:18:53.280
to break through these
barriers, to socialize ideas.

00:18:54.440 --> 00:18:56.259
And then one of
the things that was

00:18:56.259 --> 00:18:58.800
most interesting about Susan's
presentation and the worksheet

00:18:58.800 --> 00:19:00.920
in the book about
Boston is the following.

00:19:00.920 --> 00:19:02.990
So we think, those
of us who have

00:19:02.990 --> 00:19:05.539
been in public administration,
that you can't give somebody

00:19:05.539 --> 00:19:07.080
discretion and hold
them accountable.

00:19:07.080 --> 00:19:10.700
Because our government's
organized in these paper-based,

00:19:10.700 --> 00:19:14.440
file-driven processes.

00:19:14.440 --> 00:19:17.260
So that if you give a person--
let's use a real example.

00:19:17.260 --> 00:19:20.580
And I complained to the health
commissioner in New York City

00:19:20.580 --> 00:19:26.440
that we were giving ridiculous
infractions to restaurants

00:19:26.440 --> 00:19:28.250
for fines for minor things.

00:19:28.250 --> 00:19:31.060
I used to gout and meet
with folks in Queens.

00:19:31.060 --> 00:19:32.640
I met with two
restaurant owners who

00:19:32.640 --> 00:19:35.090
said I've got thousands
of dollars in fines

00:19:35.090 --> 00:19:37.820
because my cheese is
three degrees too warm.

00:19:37.820 --> 00:19:40.322
So then you go to the health
commissioner and go really,

00:19:40.322 --> 00:19:41.530
do we really have to do this?

00:19:41.530 --> 00:19:42.640
They were cooking
with their cheese.

00:19:42.640 --> 00:19:43.740
It was a warm day.

00:19:43.740 --> 00:19:45.260
It was pasteurized
cheese, anyway.

00:19:45.260 --> 00:19:46.310
It doesn't make any difference.

00:19:46.310 --> 00:19:48.435
And I still remember the
health commissioner going,

00:19:48.435 --> 00:19:51.126
well we can't give-- how do we
give that inspector discretion

00:19:51.126 --> 00:19:52.625
and not give this
person discretion?

00:19:52.625 --> 00:19:54.660
And then what if they
misuse their discretion?

00:19:54.660 --> 00:19:57.120
But that's yesterday's format.

00:19:57.120 --> 00:20:00.750
Today we know-- they have
smart phones or tablets.

00:20:00.750 --> 00:20:01.800
There are GPS.

00:20:01.800 --> 00:20:03.800
We know how long they've
been in the restaurant.

00:20:03.800 --> 00:20:05.870
We know how many
infractions they've written.

00:20:05.870 --> 00:20:08.530
We know who the outliers are
writing too many or too few

00:20:08.530 --> 00:20:09.360
or for what type.

00:20:09.360 --> 00:20:11.052
And we can hold
people accountable

00:20:11.052 --> 00:20:13.010
and give them the
discretion, at the same time.

00:20:13.010 --> 00:20:15.330
And this also is
augmented, as you

00:20:15.330 --> 00:20:20.160
can tell from San Francisco
with the integration of Yelp

00:20:20.160 --> 00:20:21.990
findings with
restaurant findings,

00:20:21.990 --> 00:20:23.720
that the information
from the public

00:20:23.720 --> 00:20:26.210
tends to hold people
accountable as well.

00:20:26.210 --> 00:20:28.010
So we think we can
increase discretion.

00:20:29.990 --> 00:20:32.900
We can personalize
the relationship

00:20:32.900 --> 00:20:34.730
between citizens and
their government.

00:20:34.730 --> 00:20:41.010
And then, just to bring this
to a head, this just basically

00:20:41.010 --> 00:20:44.200
is a too complicated slide about
the life of a child welfare

00:20:44.200 --> 00:20:47.897
worker, who needs
to make a decision,

00:20:47.897 --> 00:20:49.355
doesn't have access
to information.

00:20:49.355 --> 00:20:50.654
The information is everywhere.

00:20:50.654 --> 00:20:51.570
It's in the community.

00:20:51.570 --> 00:20:52.230
It's in the school.

00:20:52.230 --> 00:20:53.450
It's in the police department.

00:20:53.450 --> 00:20:54.741
It's in the welfare department.

00:20:54.741 --> 00:20:56.109
It's in the sibling's school.

00:20:56.109 --> 00:20:57.650
And how do we bring
all that together

00:20:57.650 --> 00:21:01.140
in a geocoded device
that makes a difference?

00:21:01.140 --> 00:21:05.650
Last in the book, and
last comment for today,

00:21:05.650 --> 00:21:08.860
is I know many of you
have these great ideas

00:21:08.860 --> 00:21:10.910
and then they run up
against government.

00:21:10.910 --> 00:21:13.500
And our experience
is that if you really

00:21:13.500 --> 00:21:15.442
want to transform
government, you

00:21:15.442 --> 00:21:17.650
need to have an innovative
leader, somebody committed

00:21:17.650 --> 00:21:19.670
to using data to make a change.

00:21:19.670 --> 00:21:20.760
Chicago is a leader.

00:21:22.630 --> 00:21:26.220
And many of these offices have
chief innovation officers,

00:21:26.220 --> 00:21:28.600
new urban mechanics
offices, somebody

00:21:28.600 --> 00:21:30.770
devoted to the enterprise.

00:21:30.770 --> 00:21:34.350
Indiana has a data
analytics office

00:21:34.350 --> 00:21:38.460
in its performance
office, a great agency led

00:21:38.460 --> 00:21:40.165
by the governor in
its O and B office.

00:21:41.570 --> 00:21:45.810
And similarly, Boston
here as well, visualized.

00:21:45.810 --> 00:21:49.390
The other issue that
Susan showed earlier

00:21:49.390 --> 00:21:51.820
is that data badly
visualized is worthless.

00:21:51.820 --> 00:21:54.420
Data well visualized
drives action.

00:21:54.420 --> 00:21:57.190
This is how Boston visualizes
its performance scorecard.

00:21:58.360 --> 00:22:00.705
We recognize there
are lots of obstacles.

00:22:02.210 --> 00:22:03.900
There are privacy
obstacles that need

00:22:03.900 --> 00:22:05.745
to be addressed
that are legitimate.

00:22:06.830 --> 00:22:09.250
There are legal issues
that need to be addressed.

00:22:11.020 --> 00:22:13.800
And our view is-- and there's
an imagination problem

00:22:13.800 --> 00:22:14.650
inside government.

00:22:14.650 --> 00:22:17.300
But leadership can
change all of these.

00:22:17.300 --> 00:22:20.145
And then the last
slide is the following.

00:22:21.310 --> 00:22:24.030
So we start with a government
that is activity based.

00:22:24.030 --> 00:22:26.530
And we're trying to get to a
government that's result based.

00:22:26.530 --> 00:22:28.670
And what the data
will allow us to do

00:22:28.670 --> 00:22:30.780
is find evidence of what works.

00:22:30.780 --> 00:22:34.050
The data will also allow us,
and the social media tools,

00:22:34.050 --> 00:22:37.490
to enhance the
voice of those who

00:22:37.490 --> 00:22:39.970
don't feel that their
government listens to them,

00:22:39.970 --> 00:22:41.630
and who are generally
disrespected.

00:22:41.630 --> 00:22:44.480
So communities of
color, communities

00:22:44.480 --> 00:22:49.130
that are underserved-- with the
proliferation of smart phones

00:22:49.130 --> 00:22:50.930
they can have an active voice.

00:22:50.930 --> 00:22:53.490
And we're looking at ways
that data and social media

00:22:53.490 --> 00:22:55.070
can produce better voice.

00:22:55.070 --> 00:22:57.390
So we have open share data
with officials that listen,

00:22:57.390 --> 00:22:59.100
personalized
relationships between you

00:22:59.100 --> 00:23:01.890
and your government, empowered
employees, the co-production

00:23:01.890 --> 00:23:03.140
of solutions with communities.

00:23:04.170 --> 00:23:07.800
All of this is a virtual
cycle-- a virtual circle

00:23:07.800 --> 00:23:11.070
that will produce trust as
we become more responsive.

00:23:11.070 --> 00:23:13.260
So this is our site.

00:23:13.260 --> 00:23:14.060
This is our book.

00:23:14.060 --> 00:23:16.700
We're convinced that we're on
the wave of a movement that

00:23:16.700 --> 00:23:19.900
is powered in large
part by you all.

00:23:19.900 --> 00:23:22.915
And that it's our job to
convince public officials

00:23:22.915 --> 00:23:24.290
to use the data
that's out there.

00:23:24.290 --> 00:23:28.120
And if they do, massive changes
in the way we deliver services,

00:23:28.120 --> 00:23:30.510
increased sense of
responsiveness and trust

00:23:30.510 --> 00:23:33.310
in government, which
is badly lacking today.

00:23:33.310 --> 00:23:35.460
MALE SPEAKER: Stories
about these leaders

00:23:35.460 --> 00:23:37.430
that have transformed
government in a number

00:23:37.430 --> 00:23:38.750
of different places.

00:23:38.750 --> 00:23:43.180
So if you want to pass
around that mic and people

00:23:43.180 --> 00:23:43.859
have questions.

00:23:43.859 --> 00:23:45.650
I'll start with one
while that's happening.

00:23:46.800 --> 00:23:49.650
Your book is focused on
people and the stories

00:23:49.650 --> 00:23:51.010
of these heroes.

00:23:51.010 --> 00:23:53.960
Have some sort of
broader numbers

00:23:53.960 --> 00:23:56.510
come together about
what's the impact of jobs,

00:23:56.510 --> 00:23:57.690
or cost savings.

00:23:57.690 --> 00:23:59.940
Googlers-- we're obsessed
about how do you measure it?

00:23:59.940 --> 00:24:01.040
What's the data?

00:24:01.040 --> 00:24:03.460
What's are the stats so far
on how these initiatives are

00:24:03.460 --> 00:24:04.460
transforming government?

00:24:05.257 --> 00:24:06.840
STEPHEN GOLDSMITH:
I think it's easier

00:24:06.840 --> 00:24:14.870
to measure results
inside an area.

00:24:14.870 --> 00:24:22.180
So Philadelphia Parole
Department-- a 35%

00:24:22.180 --> 00:24:25.004
increase in parolees,
better results

00:24:25.004 --> 00:24:26.670
with the same number
of parole officers,

00:24:26.670 --> 00:24:31.570
by using data to triage the
cases and organize what works.

00:24:31.570 --> 00:24:35.807
Indiana has picked infant
mortality-- integrate the data,

00:24:35.807 --> 00:24:37.390
drive it to the child
welfare workers,

00:24:37.390 --> 00:24:38.360
figure out how to prevent it.

00:24:38.360 --> 00:24:39.610
They're looking at the causes.

00:24:39.610 --> 00:24:43.090
And have already begun to
see reductions in that area.

00:24:43.090 --> 00:24:48.680
So it's really not very
difficult to show results

00:24:48.680 --> 00:24:50.720
in a particular area.

00:24:50.720 --> 00:24:54.727
The problem is evangelizing
that information

00:24:54.727 --> 00:24:56.310
to the point where
you actually change

00:24:56.310 --> 00:24:57.935
the way government
works, more broadly.

00:24:58.830 --> 00:25:02.250
So the fire example
in New York City,

00:25:02.250 --> 00:25:06.040
which identified 300 buildings
very likely to burn down,

00:25:06.040 --> 00:25:08.110
and we went and
mitigated those 300.

00:25:08.110 --> 00:25:10.890
And we either removed
people, added the sprinklers,

00:25:10.890 --> 00:25:16.300
stopped the illegal
activities-- pretty definable.

00:25:16.300 --> 00:25:21.600
But that was done by a
skunk works, on its own.

00:25:21.600 --> 00:25:24.402
So I think the data--
each agency area is good.

00:25:24.402 --> 00:25:25.742
SUSAN CRAWFORD: That's right.

00:25:25.742 --> 00:25:27.700
FEMALE SPEAKER: So it
seems like this is really

00:25:27.700 --> 00:25:29.105
taking off at the city level.

00:25:30.500 --> 00:25:33.850
These larger cities are having
a lot of success using big data.

00:25:33.850 --> 00:25:36.350
Why don't you think--
at least in my view,

00:25:36.350 --> 00:25:40.130
it seems like this isn't taking
off at a federal level yet.

00:25:40.130 --> 00:25:42.490
Why do you see less
adoption at a federal level

00:25:42.490 --> 00:25:43.470
of the use of big data?

00:25:43.470 --> 00:25:46.730
And what can people do to try
to foster that in the future?

00:25:46.730 --> 00:25:48.260
STEPHEN GOLDSMITH: Because Susan
left the Obama administration,

00:25:48.260 --> 00:25:48.759
probably.

00:25:48.759 --> 00:25:50.292
MALE SPEAKER: That's very kind.

00:25:50.292 --> 00:25:52.000
SUSAN CRAWFORD: Well
the mayors of cities

00:25:52.000 --> 00:25:54.541
are in this position of having
to deliver services every day.

00:25:54.541 --> 00:25:57.370
So they see the impact of what
they're up to, constantly.

00:25:57.370 --> 00:26:00.180
And they're under real
pressure to do things

00:26:00.180 --> 00:26:02.190
on the ground with
fewer resources.

00:26:02.190 --> 00:26:04.000
So when someone
walks in and says

00:26:04.000 --> 00:26:07.454
I can help you do that with
less money by using data

00:26:07.454 --> 00:26:08.870
and target your
resources, there's

00:26:08.870 --> 00:26:12.025
an immediate openness to that
at a mayoral level that may not

00:26:12.025 --> 00:26:13.150
exist at the federal level.

00:26:13.150 --> 00:26:15.570
Because you're so
many levels away

00:26:15.570 --> 00:26:17.580
from actual service delivery.

00:26:17.580 --> 00:26:22.170
Also, the CIO operations in
each agency of government

00:26:22.170 --> 00:26:24.010
are problematic
at the city level.

00:26:24.010 --> 00:26:25.990
They're really awful
at the federal level.

00:26:25.990 --> 00:26:28.510
And there, they're often just
protecting their machines,

00:26:28.510 --> 00:26:30.615
and shielding the
data from being used.

00:26:31.910 --> 00:26:35.467
Which really is antithetical
to the kind of innovation

00:26:35.467 --> 00:26:36.300
we're talking about.

00:26:36.300 --> 00:26:37.782
So it's just harder to do.

00:26:37.782 --> 00:26:39.740
There are lots of efforts
at the federal level.

00:26:39.740 --> 00:26:42.370
But we're sprinkling
in innovators.

00:26:42.370 --> 00:26:43.727
18th and F is like that.

00:26:43.727 --> 00:26:45.810
The new Government Digital
Services is doing this.

00:26:45.810 --> 00:26:48.960
We're trying to add a
culture of innovation.

00:26:48.960 --> 00:26:50.701
It's easier to do this
at the city level.

00:26:50.701 --> 00:26:52.700
And it gets harder and
harder as you get bigger.

00:26:56.620 --> 00:26:59.360
STEPHEN GOLDSMITH: Just picking
up on a comment from Susan.

00:26:59.360 --> 00:27:02.540
So one way to
think about this is

00:27:02.540 --> 00:27:05.380
that responsiveness
and trust are

00:27:05.380 --> 00:27:08.870
more likely to be
produced when you're

00:27:08.870 --> 00:27:11.560
in retail government instead
of wholesale government.

00:27:11.560 --> 00:27:14.250
So if you have a
relationship with a customer,

00:27:14.250 --> 00:27:16.570
you tend to perform better.

00:27:16.570 --> 00:27:19.710
And if you create a
data feedback loop,

00:27:19.710 --> 00:27:25.870
where your work is
appreciated, or vice versa

00:27:25.870 --> 00:27:29.540
when the transfer of the person
from [INAUDIBLE], that that

00:27:29.540 --> 00:27:30.370
makes a difference.

00:27:30.370 --> 00:27:33.180
So one of the things we've
been trying to imagine

00:27:33.180 --> 00:27:36.390
is that the data movement,
by both increasing voice

00:27:36.390 --> 00:27:39.510
and increasing the
connections between workers

00:27:39.510 --> 00:27:42.770
and the communities they
serve, will be reinforcing.

00:27:42.770 --> 00:27:45.032
And so in the app
that Susan showed,

00:27:45.032 --> 00:27:46.740
I don't think they've
turned this on yet.

00:27:46.740 --> 00:27:49.920
But you can finish my story,
because you told it to me.

00:27:49.920 --> 00:27:52.870
But the idea that the
worker who fills the pothole

00:27:52.870 --> 00:27:56.000
can send the picture back to the
person who made the complaint.

00:27:56.000 --> 00:27:58.875
That's an exciting thing for
both of those individuals.

00:27:58.875 --> 00:28:00.250
SUSAN CRAWFORD:
Yeah, absolutely.

00:28:00.250 --> 00:28:02.690
And this then feeds
into all of our themes.

00:28:02.690 --> 00:28:05.200
Because then the employee
might have much more discretion

00:28:05.200 --> 00:28:07.150
in the field to prioritizes
his work streams.

00:28:07.150 --> 00:28:09.510
So he's feeling ebullient
and ready to go.

00:28:09.510 --> 00:28:12.680
And the citizen now sees that it
was Al that filled the pothole

00:28:12.680 --> 00:28:14.700
and feels a sense of
connection with them.

00:28:14.700 --> 00:28:18.750
So these feedback loops we think
will have emergent effects.

00:28:18.750 --> 00:28:20.980
And really, complex things
are going to happen.

00:28:20.980 --> 00:28:23.620
Because people will
become much more aware

00:28:23.620 --> 00:28:26.455
of the personalities and
services in their area.

00:28:26.455 --> 00:28:27.830
MALE SPEAKER: And
how many people

00:28:27.830 --> 00:28:30.706
are going to be living in cities
over the next 10, 20 years?

00:28:30.706 --> 00:28:32.080
SUSAN CRAWFORD:
Almost everybody.

00:28:32.080 --> 00:28:35.480
2/3 of all the world's citizens
will be in cities by 2050.

00:28:35.480 --> 00:28:38.120
And in 1950, only
1/3 of citizens were.

00:28:38.120 --> 00:28:39.757
So it's a big change.

00:28:39.757 --> 00:28:42.090
MALE SPEAKER: Do do you
remember a couple years ago when

00:28:42.090 --> 00:28:45.800
we had that meeting that you
threw at Harvard that Rajiv

00:28:45.800 --> 00:28:48.580
Bhatia was there, who was
our public health open data

00:28:48.580 --> 00:28:50.170
guy San Francisco.

00:28:50.170 --> 00:28:52.780
He did an amazing job
of bringing information

00:28:52.780 --> 00:28:55.470
across agencies together
and created that Sustainable

00:28:55.470 --> 00:28:56.710
Communities Index.

00:28:56.710 --> 00:28:58.830
So one of the points
is that open data

00:28:58.830 --> 00:29:00.190
tends to be across agencies.

00:29:00.190 --> 00:29:01.490
It's not siloed.

00:29:01.490 --> 00:29:03.450
He got into a lot
of trouble for that.

00:29:03.450 --> 00:29:05.650
And in fact, actually
got run out of office.

00:29:05.650 --> 00:29:08.430
Because his superiors
realized this

00:29:08.430 --> 00:29:09.890
enabled him to
become an activist.

00:29:09.890 --> 00:29:11.710
He was able to use
a health marker.

00:29:11.710 --> 00:29:15.916
He took transportation data,
and building performance data,

00:29:15.916 --> 00:29:17.790
and then give it a good
or bad health rating.

00:29:17.790 --> 00:29:19.110
And the health
department said you

00:29:19.110 --> 00:29:20.680
can't rate the whole
city based on health.

00:29:20.680 --> 00:29:21.888
And he said no, I'm a doctor.

00:29:21.888 --> 00:29:22.544
I can.

00:29:22.544 --> 00:29:24.710
And he also got in trouble
because when he hooked up

00:29:24.710 --> 00:29:28.484
the Yelp data and the
restaurant inspector data,

00:29:28.484 --> 00:29:30.400
the restaurant inspectors
didn't like the fact

00:29:30.400 --> 00:29:31.790
that all their
behavior was open.

00:29:31.790 --> 00:29:34.380
So this points out that it
was a very difficult thing

00:29:34.380 --> 00:29:35.000
to accomplish.

00:29:35.000 --> 00:29:37.230
And there wasn't a lot in the
governmental structure here

00:29:37.230 --> 00:29:38.870
that was really
going to support him.

00:29:38.870 --> 00:29:41.970
So your thoughts on that,
and also the role of-- you

00:29:41.970 --> 00:29:44.860
talked about an outside
agency, like in Chicago,

00:29:44.860 --> 00:29:47.050
it was outside
advocacy for this,

00:29:47.050 --> 00:29:49.700
that is not part of the
City Hall mechanism.

00:29:51.292 --> 00:29:53.000
STEPHEN GOLDSMITH:
That was 10 questions.

00:29:53.000 --> 00:29:53.370
SUSAN CRAWFORD: Right.

00:29:53.370 --> 00:29:54.360
STEPHEN GOLDSMITH: At
least 10 questions.

00:29:54.360 --> 00:29:55.330
MALE SPEAKER: Well
two things-- one,

00:29:55.330 --> 00:29:57.538
people who are actually
trying to bring about change,

00:29:57.538 --> 00:29:58.655
often it's a buzz saw.

00:29:58.655 --> 00:30:00.030
STEPHEN GOLDSMITH:
No, no, right.

00:30:00.030 --> 00:30:02.300
I think the questions
were all good.

00:30:04.990 --> 00:30:08.240
So let me decouple
them for a second.

00:30:08.240 --> 00:30:15.250
So I think the use of
data is a powerful way

00:30:15.250 --> 00:30:18.940
to address social injustice,
and particularly in the it

00:30:18.940 --> 00:30:21.700
unevenness of services that
are provided in cities.

00:30:21.700 --> 00:30:25.580
So that the power of that
also is the backlash to it

00:30:25.580 --> 00:30:26.940
inside City Hall.

00:30:26.940 --> 00:30:30.100
And there's no doubt
but that that's true.

00:30:30.100 --> 00:30:35.150
But what's interesting about
the Smart Chicago effort

00:30:35.150 --> 00:30:37.470
is that since
Chicago's committed

00:30:37.470 --> 00:30:41.840
to putting its data all in a
very, very robust open data

00:30:41.840 --> 00:30:45.110
platform, if there's an
intermediary, that intermediary

00:30:45.110 --> 00:30:47.250
can map where all the
services were going.

00:30:47.250 --> 00:30:51.595
I remember one day one when
Mike Bloomberg and City Council

00:30:51.595 --> 00:30:54.680
were involved in a huge fight
about which social services got

00:30:54.680 --> 00:30:55.620
cut.

00:30:55.620 --> 00:30:58.120
And one of the people
in City Hall said,

00:30:58.120 --> 00:31:01.490
can you show us the
total number of services

00:31:01.490 --> 00:31:03.490
in each community, versus
every other community?

00:31:03.490 --> 00:31:04.656
And the answer was well, no.

00:31:04.656 --> 00:31:05.740
We can't do that at all.

00:31:05.740 --> 00:31:07.730
But we probably could have,
had we thought about it.

00:31:07.730 --> 00:31:09.605
So I think there's a
social justice movement.

00:31:09.605 --> 00:31:11.310
The other problem--
two other issues

00:31:11.310 --> 00:31:13.530
in response to your
question, though.

00:31:13.530 --> 00:31:15.155
So that may be helpful
to the mayor who

00:31:15.155 --> 00:31:15.980
is interested in that.

00:31:15.980 --> 00:31:17.240
It may not be so helpful
to the mayor who's

00:31:17.240 --> 00:31:18.240
not interesting in that.

00:31:18.240 --> 00:31:20.300
And most people are not
interested in disclosing

00:31:20.300 --> 00:31:21.490
their problems.

00:31:21.490 --> 00:31:27.500
But the reason that
we've highlighted

00:31:27.500 --> 00:31:29.690
a few people in the
book is because they're

00:31:29.690 --> 00:31:33.480
committed to the use of data
to change their organizations.

00:31:33.480 --> 00:31:37.870
Those people cannot be located
exclusively in the agencies

00:31:37.870 --> 00:31:40.150
or they'll get shut down,
like your health example.

00:31:40.150 --> 00:31:42.120
But if you're committed
to it at the top,

00:31:42.120 --> 00:31:43.750
then I think you can
see it across it.

00:31:43.750 --> 00:31:45.887
And that's where I
think the hope is.

00:31:45.887 --> 00:31:46.762
SUSAN CRAWFORD: Yeah.

00:31:46.820 --> 00:31:49.070
STEPHEN GOLDSMITH: You still
look totally unconvinced.

00:31:49.070 --> 00:31:49.540
SUSAN CRAWFORD: You want more?

00:31:49.540 --> 00:31:50.456
MALE SPEAKER: Puzzled.

00:31:51.120 --> 00:31:56.410
MALE SPEAKER: No, it's-- that
organization in Chicago--

00:31:56.410 --> 00:31:58.960
so one way you bring about
change is someone at the top is

00:31:58.960 --> 00:31:59.460
committed.

00:31:59.460 --> 00:32:01.429
Another is there's
some outside entity

00:32:01.429 --> 00:32:02.970
that taking all of
this data actually

00:32:02.970 --> 00:32:04.790
just exerts agency on its own--

00:32:04.790 --> 00:32:05.650
STEPHEN GOLDSMITH:
Right, or both.

00:32:05.650 --> 00:32:07.020
MALE SPEAKER: --and
starts pushing back on it.

00:32:07.020 --> 00:32:08.520
SUSAN CRAWFORD: And
so Smart Chicago

00:32:08.520 --> 00:32:11.260
did that job of
showing where services

00:32:11.260 --> 00:32:13.350
were concentrated in Chicago.

00:32:13.350 --> 00:32:15.170
Because the City Hall
didn't want to do it.

00:32:15.170 --> 00:32:17.289
They wanted to stay out
of telling that story.

00:32:17.289 --> 00:32:18.330
And Smart Chicago did it.

00:32:18.330 --> 00:32:21.260
There's very close
collaboration between them.

00:32:21.260 --> 00:32:24.920
So they're in such cahoots,
at the moment in Chicago,

00:32:24.920 --> 00:32:27.970
that they're not pushing against
what's going on in City Hall.

00:32:27.970 --> 00:32:30.890
But they could, in
the future, which

00:32:30.890 --> 00:32:32.780
would be interesting,
and valuable.

00:32:33.125 --> 00:32:34.500
MALE SPEAKER: So
I had a question

00:32:34.500 --> 00:32:38.780
about this notion of-- besides
services and service delivery--

00:32:38.780 --> 00:32:40.590
fixing the democracy
model, as well.

00:32:40.590 --> 00:32:42.710
So how do we actually
make decisions better?

00:32:42.710 --> 00:32:45.120
They're informed by
data and information.

00:32:45.120 --> 00:32:47.640
And what's the right
role for technology,

00:32:47.640 --> 00:32:50.240
and maybe for Google in
particular, from your opinion,

00:32:50.240 --> 00:32:51.770
in that situation?

00:32:51.770 --> 00:32:54.050
SUSAN CRAWFORD: Never to
allow a policy decision

00:32:54.050 --> 00:32:56.720
to be made without
data, to visualize

00:32:56.720 --> 00:33:00.830
that data to ensure that the
decision makers are actually

00:33:00.830 --> 00:33:01.570
fact driven.

00:33:01.570 --> 00:33:04.610
We've got a problem in that
many major decisions are

00:33:04.610 --> 00:33:07.934
made by five guys in a room
after a lot of public comment.

00:33:07.934 --> 00:33:10.350
But the public comment isn't
quantified, isn't understood.

00:33:11.560 --> 00:33:14.010
Even taking our
regulatory structure

00:33:14.010 --> 00:33:16.400
and parsing through who
said what about what

00:33:16.400 --> 00:33:18.750
and how that links to
what the decisions are,

00:33:18.750 --> 00:33:20.270
we can't even do that.

00:33:20.270 --> 00:33:22.370
So we're at a very early stage.

00:33:22.370 --> 00:33:28.210
Google could help dramatically
with a standard for rule making

00:33:28.210 --> 00:33:30.150
across agencies,
at the city level

00:33:30.150 --> 00:33:32.980
and at federal level,
could help with standards

00:33:32.980 --> 00:33:37.040
for visualization,
and encourage people

00:33:37.040 --> 00:33:39.962
to have-- inside every
rule-making agency--

00:33:39.962 --> 00:33:41.170
to be able to work with data.

00:33:41.170 --> 00:33:44.390
We've got a lot of data literacy
going on inside agencies

00:33:44.390 --> 00:33:45.390
as well.

00:33:45.390 --> 00:33:47.890
So you guys can do a
tremendous amount, actually,

00:33:47.890 --> 00:33:49.360
to make things more data driven.

00:33:49.360 --> 00:33:54.956
We really are not there,
at the moment, in my view.

00:33:54.956 --> 00:33:56.830
STEPHEN GOLDSMITH: I
was trying to figure out

00:33:56.830 --> 00:34:00.365
how to get more community
input for proposed regulations.

00:34:01.450 --> 00:34:04.110
And the federal
agencies and many states

00:34:04.110 --> 00:34:06.420
put their proposed
rules up online.

00:34:06.420 --> 00:34:09.262
But what happens is the
rules are done by the time

00:34:09.262 --> 00:34:10.595
they ask for community feedback.

00:34:11.335 --> 00:34:13.710
It's like suddenly you want
do [INAUDIBLE] at a community

00:34:13.710 --> 00:34:15.320
meeting and people yell
at you for four hours.

00:34:15.320 --> 00:34:17.508
Then you go do what you
would have done anyway, just

00:34:17.508 --> 00:34:18.299
like an experience.

00:34:19.690 --> 00:34:22.230
So the question
then becomes how do

00:34:22.230 --> 00:34:23.679
you take the problem
you're trying

00:34:23.679 --> 00:34:27.400
to solve, before
you have configured

00:34:27.400 --> 00:34:30.301
the professional
solution, and socialize

00:34:30.301 --> 00:34:31.550
the problem with the question.

00:34:32.630 --> 00:34:34.620
And that, in large
part, depends on how

00:34:34.620 --> 00:34:38.650
you express and
visualize the question,

00:34:38.650 --> 00:34:40.790
and then sort the
response, as part

00:34:40.790 --> 00:34:42.469
of a true democratic
process that

00:34:42.469 --> 00:34:45.102
then informs the bureaucracy.

00:34:45.102 --> 00:34:46.560
And I think that
what we've done is

00:34:46.560 --> 00:34:51.530
we've left so much social media
information on the table that

00:34:51.530 --> 00:34:53.510
could inform those decisions.

00:34:53.510 --> 00:34:57.200
But then just last, it's
really, truly iterative.

00:34:57.200 --> 00:35:01.686
I want to-- this is a
story from many years.

00:35:01.686 --> 00:35:03.935
When I first got elected
mayor, I went to an opening--

00:35:03.935 --> 00:35:05.434
this will just take
a second-- but I

00:35:05.434 --> 00:35:08.639
went to an opening of a park
that my predecessor had done.

00:35:08.639 --> 00:35:10.430
I cut the ribbon,
because I'm a politician.

00:35:10.430 --> 00:35:12.800
So it was cut on mine--
so I went out there.

00:35:12.800 --> 00:35:14.100
And everybody was mad.

00:35:14.100 --> 00:35:15.844
And I said you got a new park.

00:35:15.844 --> 00:35:16.510
Why are you mad?

00:35:16.510 --> 00:35:18.510
And they said because old folks
live on this side of the park.

00:35:18.510 --> 00:35:20.370
And you got the
basketball courts at night

00:35:20.370 --> 00:35:21.690
on their side of the park.

00:35:21.690 --> 00:35:23.060
And you could have put it on
the other side of the park.

00:35:23.060 --> 00:35:24.090
And you designed this park.

00:35:24.090 --> 00:35:25.360
So then I said I'm doing
this all differently.

00:35:25.360 --> 00:35:26.130
I raised a lot of money.

00:35:26.130 --> 00:35:26.910
I'm going to redo your parks.

00:35:26.910 --> 00:35:27.630
And I went to a meeting.

00:35:27.630 --> 00:35:28.770
And I had the first meeting.

00:35:28.770 --> 00:35:29.970
And I said I'm going
to redo your park.

00:35:29.970 --> 00:35:30.310
What do you want there?

00:35:30.310 --> 00:35:32.000
And they went and looked at me
like, we're not park planners.

00:35:32.000 --> 00:35:33.920
What do you expect us to say?

00:35:33.920 --> 00:35:37.620
So the answer was we had to
configure a set of options,

00:35:37.620 --> 00:35:40.695
visualize those options, ask
for the input in a sincere way,

00:35:40.695 --> 00:35:43.730
then form-- and so I think
that iterative process, using

00:35:43.730 --> 00:35:45.724
social media, may be the
way to think about it.

00:35:47.321 --> 00:35:49.320
MALE SPEAKER: So there
are 12 ballot initiatives

00:35:49.320 --> 00:35:50.760
on the SF ballot this November.

00:35:50.760 --> 00:35:52.370
And two of them
apparently concern

00:35:52.370 --> 00:35:54.540
whether soccer fields
should have artificial turf

00:35:54.540 --> 00:35:56.960
or not in certain
parts of the city.

00:35:56.960 --> 00:36:00.300
That's one example of a
responsive democratic process

00:36:00.300 --> 00:36:02.310
going somewhat astray, arguably.

00:36:02.310 --> 00:36:04.140
And maybe there are
bigger questions

00:36:04.140 --> 00:36:06.630
that we should be
debating as a city that

00:36:06.630 --> 00:36:08.460
go beyond soccer field surfaces.

00:36:08.460 --> 00:36:10.290
So how do you build
in that mechanism

00:36:10.290 --> 00:36:13.330
for channeling real concerns
that citizens actually

00:36:13.330 --> 00:36:17.069
have into the democratic
evaluation process?

00:36:17.069 --> 00:36:19.110
STEPHEN GOLDSMITH: I don't
even know what to say.

00:36:22.600 --> 00:36:25.540
Well, I'll give an answer.

00:36:25.540 --> 00:36:27.940
But I think actually
your question is worth

00:36:27.940 --> 00:36:30.780
a lot of thought-- more thought.

00:36:31.910 --> 00:36:38.430
I envision a situation
where the responsiveness

00:36:38.430 --> 00:36:42.340
is microtargeted, where
it's got two definitions.

00:36:42.340 --> 00:36:44.510
One is you register
for the information

00:36:44.510 --> 00:36:46.020
you want personally
from your city,

00:36:46.020 --> 00:36:48.780
so you're getting that without
having to bang on the city.

00:36:48.780 --> 00:36:51.730
The second is that
your community now

00:36:51.730 --> 00:36:55.710
has enough information and
it gets questions in advance

00:36:55.710 --> 00:36:59.205
about OK, we got money
to do your sidewalks.

00:36:59.205 --> 00:37:00.830
Which sidewalks do
you want done first?

00:37:00.830 --> 00:37:03.590
What improvements do
you want in your area?

00:37:03.590 --> 00:37:05.430
And then you share that
with your neighbors.

00:37:05.430 --> 00:37:09.750
And so I'm envisioning that, if
we can be more response-- one

00:37:09.750 --> 00:37:10.280
other issue.

00:37:11.420 --> 00:37:13.510
Prior to all this
information, it really

00:37:13.510 --> 00:37:15.380
was very difficult
for a bureaucrat

00:37:15.380 --> 00:37:18.130
to actively engage
a large community.

00:37:18.130 --> 00:37:19.350
There's only so many people.

00:37:19.350 --> 00:37:20.330
The people who come
to the meetings

00:37:20.330 --> 00:37:21.410
are not necessary
the right people.

00:37:21.410 --> 00:37:23.595
All they do is yell and
they show off to each other.

00:37:23.595 --> 00:37:26.380
That's an off the
record kind of comment.

00:37:26.380 --> 00:37:27.940
They're all-- it's
a performance art.

00:37:27.940 --> 00:37:30.080
It's really not an engagement.

00:37:30.080 --> 00:37:32.290
So the extent to
which we can deepen

00:37:32.290 --> 00:37:33.950
that, socializing
those problems,

00:37:33.950 --> 00:37:39.650
we ought to be at least able
to defuse some of those-- I

00:37:39.650 --> 00:37:42.600
have to resort to an
initiative to get the attention

00:37:42.600 --> 00:37:44.710
about the artificiality
of my soccer fields.

00:37:45.524 --> 00:37:47.690
MALE SPEAKER: Do you think
then this responsive city

00:37:47.690 --> 00:37:50.625
leads to less yelling
at those town meetings?

00:37:50.625 --> 00:37:53.190
Or does it change the
dynamics of political debate

00:37:53.190 --> 00:37:53.807
in some way?

00:37:53.807 --> 00:37:55.390
SUSAN CRAWFORD: Well,
here's something

00:37:55.390 --> 00:37:58.535
I know to be true, that when you
put a shared screen up in front

00:37:58.535 --> 00:38:00.660
of a group of people who
otherwise might be yelling

00:38:00.660 --> 00:38:02.785
at each other, the emotional
heat really goes down.

00:38:02.785 --> 00:38:04.784
And I've seen this over
and over and over again.

00:38:04.784 --> 00:38:06.890
And where that shared
screen has data on it

00:38:06.890 --> 00:38:09.550
that people have already
agreed is relevant and true,

00:38:09.550 --> 00:38:11.710
then you get them
in fact-finding

00:38:11.710 --> 00:38:15.150
and problem-solving mode--
problem solving mode.

00:38:15.150 --> 00:38:17.310
They think of
themselves as a team,

00:38:17.310 --> 00:38:19.270
coming from different
constituencies.

00:38:19.270 --> 00:38:21.990
So to the extent that
big data visualized well,

00:38:21.990 --> 00:38:25.790
plus stakeholder
engagement that's genuine,

00:38:25.790 --> 00:38:28.680
where they are confident that
the decision maker is going

00:38:28.680 --> 00:38:31.940
to respond, I think there's
a lot of responsiveness

00:38:31.940 --> 00:38:34.250
that's possible there.

00:38:34.250 --> 00:38:36.550
But you still want to give
people the channel to yell,

00:38:36.550 --> 00:38:37.290
if they want to.

00:38:37.290 --> 00:38:37.710
MALE SPEAKER: It's politics.

00:38:37.710 --> 00:38:40.130
SUSAN CRAWFORD: But this is
an additional channel that

00:38:40.130 --> 00:38:42.960
is problem solving,
joint problem solving.

00:38:42.960 --> 00:38:45.340
MALE SPEAKER: So we talked
a lot about big data

00:38:45.340 --> 00:38:47.320
and digital technology,
and I think--

00:38:47.320 --> 00:38:49.550
and all the great
outcomes that can produce.

00:38:49.550 --> 00:38:51.240
And one of the
questions that I ask

00:38:51.240 --> 00:38:54.260
is as we move toward
digitizing services,

00:38:54.260 --> 00:38:56.690
do we run the risk
of exacerbating

00:38:56.690 --> 00:38:58.922
the digital divide or
increasing inequality?

00:38:58.922 --> 00:39:00.380
And given your
experience, I'm just

00:39:00.380 --> 00:39:01.780
wondering how do you think
through that problem?

00:39:01.780 --> 00:39:03.400
And what we do to
mitigate against that?

00:39:03.400 --> 00:39:04.940
SUSAN CRAWFORD: Well,
I'd take it as a given

00:39:04.940 --> 00:39:06.730
that the responsive
city only functions

00:39:06.730 --> 00:39:09.100
when there is ubiquitous
access that's cheap,

00:39:09.100 --> 00:39:12.790
and people don't have to think
about the latency-- anything.

00:39:12.790 --> 00:39:14.490
It should just be in the air.

00:39:14.490 --> 00:39:17.630
So for me, fiber is
at the bottom of this,

00:39:17.630 --> 00:39:21.757
and ensuring that every
city has competitive, cheap,

00:39:21.757 --> 00:39:22.840
connectivity is essential.

00:39:22.840 --> 00:39:25.340
STEPHEN GOLDSMITH: This is a
totally unsolicited endorsement

00:39:25.340 --> 00:39:26.007
of Google Fiber.

00:39:26.007 --> 00:39:27.673
SUSAN CRAWFORD: Right,
exactly, exactly.

00:39:27.673 --> 00:39:29.360
But where we really
need help though

00:39:29.360 --> 00:39:31.660
is in literacy
efforts, where people

00:39:31.660 --> 00:39:34.070
don't feel embarrassed
or ashamed or afraid

00:39:34.070 --> 00:39:35.490
to use these tools.

00:39:35.490 --> 00:39:37.880
And there we're at
a terrible deficit.

00:39:37.880 --> 00:39:39.780
So access alone isn't enough.

00:39:39.780 --> 00:39:42.520
We've got to help people
become conversant with it.

00:39:42.520 --> 00:39:45.350
This should be part of the
elementary school curriculum.

00:39:45.350 --> 00:39:47.030
You're in there,
using the tools.

00:39:47.030 --> 00:39:49.602
STEPHEN GOLDSMITH: So I
actually agree with Susan.

00:39:49.602 --> 00:39:51.560
But I actually think the
answer is emphatically

00:39:51.560 --> 00:39:53.855
the opposite of the
implication in the question.

00:39:56.110 --> 00:39:57.200
It's a friendly response.

00:39:57.200 --> 00:40:07.140
So government doesn't fairly
distribute its resources today.

00:40:08.190 --> 00:40:13.490
And years ago, I used to be in
the-- as a district attorney,

00:40:13.490 --> 00:40:16.320
I used to be in the child
support enforcement business.

00:40:16.320 --> 00:40:17.340
This was a long time.

00:40:17.340 --> 00:40:19.790
And two experiences are still
sharp in my mind in response

00:40:19.790 --> 00:40:20.990
to your question.

00:40:20.990 --> 00:40:24.300
One was that we started out
just representing welfare moms.

00:40:24.300 --> 00:40:26.010
Because that was
the federal law.

00:40:26.010 --> 00:40:30.090
And they got OK services.

00:40:30.090 --> 00:40:33.700
Then the law expanded for us
to represent middle class moms.

00:40:33.700 --> 00:40:36.355
And the noise level from
the quality of our services

00:40:36.355 --> 00:40:37.230
went up dramatically.

00:40:37.230 --> 00:40:38.350
They knew how to get to us.

00:40:38.350 --> 00:40:39.266
They knew who to call.

00:40:39.266 --> 00:40:40.480
They knew how to articulate.

00:40:40.480 --> 00:40:42.390
They knew how to get attention.

00:40:42.390 --> 00:40:46.710
So it's not like in a
pre-internet, digital divide

00:40:46.710 --> 00:40:50.160
world that resources
are even to begin with.

00:40:50.160 --> 00:40:58.070
Secondly if we think
smart devices--

00:40:58.070 --> 00:41:00.860
if we think about the
ubiquity of smart devices,

00:41:00.860 --> 00:41:05.270
I think that we can move to
more equitable distribution

00:41:05.270 --> 00:41:07.670
of resources, where
we give people voice.

00:41:07.670 --> 00:41:09.420
Or maybe they don't
even have to be smart.

00:41:09.420 --> 00:41:12.940
Maybe they could just be SMSing
us through their old phones.

00:41:12.940 --> 00:41:15.660
But they can have
a voice that we

00:41:15.660 --> 00:41:17.550
can listen to and
pay attention to.

00:41:17.550 --> 00:41:19.260
And then if we add
a few other things,

00:41:19.260 --> 00:41:22.240
like rate your public
employee, text back whether

00:41:22.240 --> 00:41:24.470
they're-- then I think we
can begin to equate it.

00:41:24.470 --> 00:41:26.630
So it's just a
long way of saying

00:41:26.630 --> 00:41:29.180
I think the system
is imbalanced today.

00:41:29.180 --> 00:41:31.810
I bet of the 20 million phone
calls I got in New York City,

00:41:31.810 --> 00:41:33.720
as deputy mayor in
our call center,

00:41:33.720 --> 00:41:36.360
they couldn't have been
equally distributed

00:41:36.360 --> 00:41:37.980
across ethnic groups.

00:41:37.980 --> 00:41:40.980
They had to be totally
to the people who

00:41:40.980 --> 00:41:43.320
knew how to call,
complain in English.

00:41:43.320 --> 00:41:48.076
MALE SPEAKER: So more peaceful
debate, maybe more equality,

00:41:48.076 --> 00:41:48.950
delivery of services.

00:41:48.950 --> 00:41:49.960
SUSAN CRAWFORD: Or maybe not.

00:41:49.960 --> 00:41:50.959
It's a compared to what.

00:41:51.221 --> 00:41:53.220
MALE SPEAKER: They're at
least that supposition.

00:41:54.805 --> 00:41:56.430
What problem can't this solve?

00:41:56.430 --> 00:41:58.570
And I ask that not
because you're saying

00:41:58.570 --> 00:41:59.570
this is a silver bullet.

00:41:59.570 --> 00:42:01.040
But just thinking
honestly, whenever

00:42:01.040 --> 00:42:03.090
you're trying to solve a hard
problem, you want to see well,

00:42:03.090 --> 00:42:04.006
what can't we take on?

00:42:04.006 --> 00:42:05.820
What do we have
to do in parallel?

00:42:05.820 --> 00:42:07.760
STEPHEN GOLDSMITH: Well, Susan
can tell you what we can't do.

00:42:07.760 --> 00:42:09.760
I'll make one more comment
about what we can do.

00:42:10.492 --> 00:42:12.450
MALE SPEAKER: Are you
the politician or is she?

00:42:12.450 --> 00:42:13.960
STEPHEN GOLDSMITH:
I'm a politician.

00:42:13.960 --> 00:42:15.170
She's a statesman.

00:42:15.170 --> 00:42:20.850
So look, I've got
$5,000 to spend.

00:42:20.850 --> 00:42:23.200
And I can spend it
equally distributed over

00:42:23.200 --> 00:42:25.350
a set of identical widgets.

00:42:25.350 --> 00:42:28.400
Or I can look at outliers
and pay attention

00:42:28.400 --> 00:42:30.910
to which restaurant is
most likely to poison you

00:42:30.910 --> 00:42:34.080
with their bacteria and which
ones have never done that.

00:42:34.080 --> 00:42:36.340
Which builder is going
to build a bad house?

00:42:36.340 --> 00:42:37.824
What landlord's
going to do this?

00:42:37.824 --> 00:42:39.990
Where are you most likely
to have a health outbreak?

00:42:39.990 --> 00:42:43.340
I can reorganize the
distribution of public services

00:42:43.340 --> 00:42:45.310
in a dramatic way that
makes me both responsive

00:42:45.310 --> 00:42:46.460
and more effective.

00:42:46.460 --> 00:42:47.690
And that's all data driven.

00:42:47.690 --> 00:42:49.150
And we could never
do that before.

00:42:49.150 --> 00:42:53.150
So I think that the data
revolution has massive effect.

00:42:53.150 --> 00:42:54.400
MALE SPEAKER: Sky's the limit.

00:42:54.400 --> 00:42:55.360
STEPHEN GOLDSMITH:
It's unlimited.

00:42:55.360 --> 00:42:56.040
SUSAN CRAWFORD: Yeah, right.

00:42:56.040 --> 00:42:57.450
MALE SPEAKER: OK,
Susan, you want

00:42:57.450 --> 00:42:59.870
to leave us with the last thing
before I see somebody looking

00:42:59.870 --> 00:43:00.780
in at us and [INAUDIBLE]
to kick us out?

00:43:00.780 --> 00:43:01.115
SUSAN CRAWFORD:
Well, you can just

00:43:01.115 --> 00:43:02.948
tell that Steve Goldsmith
was a great mayor.

00:43:02.948 --> 00:43:05.260
And there's no substitute
for a visionary mayor who

00:43:05.260 --> 00:43:06.969
can convince his
citizens that tomorrow's

00:43:06.969 --> 00:43:08.385
going to be better
than yesterday.

00:43:08.385 --> 00:43:09.905
No data is going to do that.

00:43:09.905 --> 00:43:12.300
That personality is
extremely important.

00:43:12.300 --> 00:43:15.820
And also humans
aren't going away.

00:43:15.820 --> 00:43:18.140
And they are not going
to be supplanted.

00:43:18.140 --> 00:43:22.610
You're still going to need the
responsiveness of policy that's

00:43:22.610 --> 00:43:24.400
not created
automatically by data.

00:43:24.400 --> 00:43:25.760
It doesn't arise by magic.

00:43:25.760 --> 00:43:28.240
So all the wise decisions
about allocations

00:43:28.240 --> 00:43:30.935
of resources,
priorities for a city,

00:43:30.935 --> 00:43:32.560
how the city's going
to position itself

00:43:32.560 --> 00:43:35.280
in the global marketplace, that
doesn't happen through data

00:43:35.280 --> 00:43:36.168
alone.

00:43:36.168 --> 00:43:38.939
MALE SPEAKER: OK, on that
note, thank our speakers.

00:43:38.939 --> 00:43:39.730
SUSAN CRAWFORD: OK.

00:43:39.730 --> 00:43:40.330
MALE SPEAKER: Thank
you guys for coming.

00:43:40.330 --> 00:43:41.230
SUSAN CRAWFORD: Thank you.

00:43:41.230 --> 00:43:41.830
Oh, books.

00:43:41.830 --> 00:43:44.120
[APPLAUSE]

