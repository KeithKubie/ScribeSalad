WEBVTT
Kind: captions
Language: en

00:00:00.499 --> 00:00:02.410
ALEX: It's all happening
on your laptop.

00:00:02.410 --> 00:00:06.557
So essentially, this sort
of thing that you've trained

00:00:06.557 --> 00:00:07.890
is all sitting on your computer.

00:00:07.890 --> 00:00:09.780
So it is an interesting
kind of fork

00:00:09.780 --> 00:00:13.770
in the road, where I could
imagine a world where

00:00:13.770 --> 00:00:17.637
if that kind of classifier I
had made for my kid's drawing,

00:00:17.637 --> 00:00:19.470
would that be something
that I could kind of

00:00:19.470 --> 00:00:22.740
grab and share and post?

00:00:22.740 --> 00:00:25.842
And so I think that that idea
of you owning a little model

00:00:25.842 --> 00:00:27.300
that you've made
was very much what

00:00:27.300 --> 00:00:28.860
we wanted to go for
with teachable machine.

00:00:28.860 --> 00:00:30.450
But we haven't quite
gotten to that.

00:00:30.450 --> 00:00:33.278
That's almost the second
phase of that, hopefully.

00:00:36.484 --> 00:00:37.866
SPEAKER 1: Thanks, Alex.

00:00:37.866 --> 00:00:42.184
[APPLAUSE]

00:00:42.184 --> 00:00:44.350
SPEAKER 2: Well, the next
speaker is Patrick Hebron.

00:00:44.350 --> 00:00:47.500
He is an Associate Professor
at the New York University

00:00:47.500 --> 00:00:51.070
and has worked with Creative
Labs, as well as with Adobe

00:00:51.070 --> 00:00:54.100
on the implications of machine
learning for creative work,

00:00:54.100 --> 00:00:56.550
and has also published
a book around machine

00:00:56.550 --> 00:00:59.180
learning for design.

00:00:59.180 --> 00:01:00.825
PATRICK HEBRON: Hey.

00:01:00.825 --> 00:01:02.700
I want to thank the
organizers for having me.

00:01:02.700 --> 00:01:05.050
It's really an honor to be here.

00:01:05.050 --> 00:01:06.185
OK.

00:01:06.185 --> 00:01:06.684
Whoops.

00:01:10.350 --> 00:01:12.300
So this talk's about
making machine learning

00:01:12.300 --> 00:01:14.190
tools more accessible.

00:01:14.190 --> 00:01:16.770
But it's not about dumbing
them down for lay audiences

00:01:16.770 --> 00:01:20.455
or about creating toy
interfaces for toy problems.

00:01:20.455 --> 00:01:22.080
Obviously, there's
a lot of differences

00:01:22.080 --> 00:01:24.510
between human and
machine learners,

00:01:24.510 --> 00:01:27.240
but we all have ample
experience with, perhaps,

00:01:27.240 --> 00:01:29.580
the most fundamental
element of machine learning,

00:01:29.580 --> 00:01:32.790
which is that we know how
to learn from experience.

00:01:32.790 --> 00:01:35.010
And in fact, the most
challenging thing

00:01:35.010 --> 00:01:37.530
about learning how
to teach someone else

00:01:37.530 --> 00:01:39.360
is kind of remembering
how you came

00:01:39.360 --> 00:01:41.730
to know something yourself.

00:01:41.730 --> 00:01:45.720
This metacognitive ability is
really a very precious and hard

00:01:45.720 --> 00:01:46.940
won skill.

00:01:46.940 --> 00:01:49.930
Obviously, it's very much in
the wheel house of educators,

00:01:49.930 --> 00:01:52.380
but it's also a key component
of all of our interactions

00:01:52.380 --> 00:01:55.500
with other people.

00:01:55.500 --> 00:01:57.720
When we teach our
children to ride bikes,

00:01:57.720 --> 00:02:00.390
we don't rattle off exact
programmatic procedures.

00:02:00.390 --> 00:02:04.560
We, instead, demonstrate, watch
as they approximate the action,

00:02:04.560 --> 00:02:08.130
and help to direct the child's
focus to overlooked aspects

00:02:08.130 --> 00:02:09.654
of the task.

00:02:09.654 --> 00:02:11.070
Machine learning
tools should help

00:02:11.070 --> 00:02:13.104
us to do exactly those
things for machines,

00:02:13.104 --> 00:02:14.520
so that they can,
in turn, help us

00:02:14.520 --> 00:02:17.550
to solve problems that are
too complex to be addressed

00:02:17.550 --> 00:02:19.580
by conventional code.

00:02:19.580 --> 00:02:21.360
And also tools that
help us to sharpen

00:02:21.360 --> 00:02:24.210
these kinds of
metacognitive abilities

00:02:24.210 --> 00:02:26.377
will not only help us to
build more useful machines,

00:02:26.377 --> 00:02:27.751
but they'll help
us to understand

00:02:27.751 --> 00:02:29.880
ourselves more deeply
and engage with the world

00:02:29.880 --> 00:02:31.560
more effectively.

00:02:31.560 --> 00:02:34.470
So when I say accessible, I
mean that machine learning tools

00:02:34.470 --> 00:02:37.710
should be able to service the
extension of every human's

00:02:37.710 --> 00:02:40.230
kind of innate
capacity to both learn

00:02:40.230 --> 00:02:42.120
and teach from experience.

00:02:42.120 --> 00:02:44.240
Machine learning is
a tool for everyone.

00:02:44.240 --> 00:02:48.400
But in its current form, that's
not really all that obvious.

00:02:48.400 --> 00:02:49.950
Presently, machine
learning tools

00:02:49.950 --> 00:02:52.800
requires some programming
skills, some understanding

00:02:52.800 --> 00:02:54.561
of the fundamental
techniques in machine

00:02:54.561 --> 00:02:57.060
learning, the underlying math,
and probably also some DevOps

00:02:57.060 --> 00:02:57.960
skills.

00:02:57.960 --> 00:03:00.660
And so in combination, this
presents a really very high

00:03:00.660 --> 00:03:03.050
barrier to entry.

00:03:03.050 --> 00:03:04.800
The first generations
of tools have

00:03:04.800 --> 00:03:08.280
been focused on aiding
expert practitioners

00:03:08.280 --> 00:03:10.380
to manage high performance
pipelines at really

00:03:10.380 --> 00:03:11.940
very granular levels.

00:03:11.940 --> 00:03:14.400
And they've also
abstracted the demands

00:03:14.400 --> 00:03:16.740
of machine learning into
conventional programmatic

00:03:16.740 --> 00:03:19.620
structures, even
though, in many ways,

00:03:19.620 --> 00:03:23.100
there is a kind of incongruity
between the deductive mentality

00:03:23.100 --> 00:03:26.700
of conventional code and the
inductive mentality of machine

00:03:26.700 --> 00:03:29.250
learning.

00:03:29.250 --> 00:03:32.610
The skill that I think is
not really yet accentuated

00:03:32.610 --> 00:03:34.350
in machine learning tools--

00:03:34.350 --> 00:03:39.390
aside from the things that
Alex was just talking about--

00:03:39.390 --> 00:03:41.820
is that these tools
don't accentuate

00:03:41.820 --> 00:03:45.240
the skill of curriculum design
or the process of curating

00:03:45.240 --> 00:03:47.900
a learner's experience
of a complex concept

00:03:47.900 --> 00:03:50.730
and bringing forward
its meaningful elements.

00:03:50.730 --> 00:03:54.810
In my teaching work, I've found
that often a person's math

00:03:54.810 --> 00:03:56.910
and programming background
is in a lot of ways

00:03:56.910 --> 00:03:59.940
not the best predictor of
how they will take to machine

00:03:59.940 --> 00:04:03.470
learning work or applied
machine learning work,

00:04:03.470 --> 00:04:06.540
and that, in many cases, the
most captivating projects

00:04:06.540 --> 00:04:11.400
come from students who are
clear writers or designers.

00:04:11.400 --> 00:04:14.430
And I think this is because
what makes a machine learning

00:04:14.430 --> 00:04:17.519
project successful is
the student's ability

00:04:17.519 --> 00:04:19.649
to articulate a
learning problem, how

00:04:19.649 --> 00:04:21.690
a particular concept
can be demonstrated

00:04:21.690 --> 00:04:23.550
through a particular
presentation of data.

00:04:26.230 --> 00:04:29.380
And this was actually--

00:04:29.380 --> 00:04:32.060
wait, it doesn't
look so good but--

00:04:32.060 --> 00:04:36.190
this was actually published
just a few days ago.

00:04:36.190 --> 00:04:40.930
As mechanisms for neural
architecture and parameter

00:04:40.930 --> 00:04:45.060
search become more
robust, then the sort

00:04:45.060 --> 00:04:46.810
of current skills in
machine learning work

00:04:46.810 --> 00:04:49.810
kind of become somewhat
less vital to applied work.

00:04:49.810 --> 00:04:53.020
And the skill of articulating
a learning problem

00:04:53.020 --> 00:04:54.760
becomes all the more.

00:04:54.760 --> 00:04:59.170
I think this is sort
of analogous to perhaps

00:04:59.170 --> 00:05:01.870
in the first 20 years
of computer science,

00:05:01.870 --> 00:05:04.900
to be a programmer, you really
had to basically understand

00:05:04.900 --> 00:05:06.550
how to implement a compiler.

00:05:06.550 --> 00:05:10.150
And as we've moved towards
higher level languages,

00:05:10.150 --> 00:05:12.310
that's no longer necessary.

00:05:12.310 --> 00:05:14.890
I think we can sort of
see the type of work that

00:05:14.890 --> 00:05:17.140
goes into designing a
neural network today

00:05:17.140 --> 00:05:21.750
as being that kind of sort
of compiler design aspect.

00:05:21.750 --> 00:05:24.490
And so the sort of
more central skill

00:05:24.490 --> 00:05:28.420
will become curriculum
design, if you will.

00:05:28.420 --> 00:05:31.000
So hopefully this kind of next
generation of machine learning

00:05:31.000 --> 00:05:34.930
tools will be able to
serve two audiences.

00:05:34.930 --> 00:05:38.890
It will help novices in the
sort of conventional aspects

00:05:38.890 --> 00:05:40.650
of programming and
machine learning

00:05:40.650 --> 00:05:43.480
to be able to
experiment and explore.

00:05:43.480 --> 00:05:46.570
And at the same time,
it can also, I think,

00:05:46.570 --> 00:05:49.300
help expert practitioners
to sort of work

00:05:49.300 --> 00:05:52.270
within a framework that is more
natural to machine learning

00:05:52.270 --> 00:05:57.130
rather than sort of being built
upon the conventional code

00:05:57.130 --> 00:05:57.730
mentality.

00:06:00.560 --> 00:06:03.190
Traditionally, a
programming language

00:06:03.190 --> 00:06:06.160
is treated as distinct from
IDEs and other tools that are

00:06:06.160 --> 00:06:08.340
essential to writing software.

00:06:08.340 --> 00:06:12.250
These delineations were
probably already pretty outdated

00:06:12.250 --> 00:06:14.650
with the advent of
graphical computing.

00:06:14.650 --> 00:06:17.890
But in the machine learning age,
they're becoming even more so.

00:06:17.890 --> 00:06:20.350
And I think one place
where we can already

00:06:20.350 --> 00:06:22.630
see the need for a kind of
a more holistic programming

00:06:22.630 --> 00:06:25.960
environment is in the efforts
of DeepMind, and OpenAI,

00:06:25.960 --> 00:06:30.010
and others to build simulation
environments for training

00:06:30.010 --> 00:06:31.990
reinforcement learning systems.

00:06:31.990 --> 00:06:35.950
These are sort of game or
design or physics kinds

00:06:35.950 --> 00:06:38.770
of environments and
becoming more and more

00:06:38.770 --> 00:06:44.200
central in this graphical and
physical context to building

00:06:44.200 --> 00:06:46.630
machine learning systems.

00:06:46.630 --> 00:06:50.260
Of course, Jupyter Notebooks,
Matlab, Mathematica, Swift

00:06:50.260 --> 00:06:52.810
Processing, and Scratch,
and web development tools

00:06:52.810 --> 00:06:54.310
have already kind
of started to blur

00:06:54.310 --> 00:06:58.930
these distinctions between
the text editor and a more

00:06:58.930 --> 00:07:00.560
cohesive environment.

00:07:00.560 --> 00:07:02.630
But there's a long way to go.

00:07:05.450 --> 00:07:08.900
The purpose of this is not
only to make the interface more

00:07:08.900 --> 00:07:13.790
palatable to the human user,
but also to sort of bridge

00:07:13.790 --> 00:07:17.120
the gap between the
computer's understanding

00:07:17.120 --> 00:07:21.020
and kind of experiential nature
and, of course, the humans.

00:07:21.020 --> 00:07:22.850
So deeper mechanisms
for communication

00:07:22.850 --> 00:07:25.494
shouldn't be tacked on to
the existing interfaces

00:07:25.494 --> 00:07:27.410
or auxiliary libraries,
they should be brought

00:07:27.410 --> 00:07:29.390
into the center of our tools.

00:07:29.390 --> 00:07:31.850
And we should also take
this paradigmatic shift

00:07:31.850 --> 00:07:33.620
that's brought about
by machine learning

00:07:33.620 --> 00:07:36.750
as cause to rethink
numerous aspects of software

00:07:36.750 --> 00:07:37.250
development.

00:07:37.250 --> 00:07:41.470
If we're making one change,
why not make a bunch?

00:07:41.470 --> 00:07:41.970
OK.

00:07:41.970 --> 00:07:45.000
So I'd like to show you a little
bit of a project I've been

00:07:45.000 --> 00:07:48.870
working on and treat it kind
of as an example of how these

00:07:48.870 --> 00:07:51.240
kinds of ideas might
be implemented .

00:07:51.240 --> 00:07:52.680
Some of the stuff
we'll talk about

00:07:52.680 --> 00:07:54.180
are things I've
already implemented.

00:07:54.180 --> 00:07:56.800
Some of them are sort
of longer term horizons.

00:07:56.800 --> 00:07:58.680
And I'd be happy
to show any of you

00:07:58.680 --> 00:08:00.390
where the current software is.

00:08:00.390 --> 00:08:02.639
But for the purpose
of this discussion,

00:08:02.639 --> 00:08:04.430
don't want to sort of
focus on that divide,

00:08:04.430 --> 00:08:08.340
and instead talk about
this as a whole vision.

00:08:08.340 --> 00:08:10.470
So I call it Foil.

00:08:10.470 --> 00:08:13.770
And it's supposed to be kind
of a combination of machine

00:08:13.770 --> 00:08:15.750
learning and creative
coding platform.

00:08:15.750 --> 00:08:18.180
And it's an attempt to close
the loop between programming,

00:08:18.180 --> 00:08:19.910
machine learning,
and design tools

00:08:19.910 --> 00:08:24.510
in a single platform that can
integrate all of those aspects

00:08:24.510 --> 00:08:26.310
that we've talked
about and that's

00:08:26.310 --> 00:08:29.340
a pathway for novice to expert.

00:08:29.340 --> 00:08:32.940
It envisions a multi-tier
approach in which lower level

00:08:32.940 --> 00:08:35.760
features can be used directly
by more experienced users

00:08:35.760 --> 00:08:38.580
or could be composited
together to be

00:08:38.580 --> 00:08:41.820
used by less experienced users.

00:08:41.820 --> 00:08:43.799
And as users gain
experience, the idea

00:08:43.799 --> 00:08:49.440
is that these components are not
impenetrable, but instead can

00:08:49.440 --> 00:08:51.870
be kind of inspected
under the hood.

00:08:51.870 --> 00:08:54.510
So I think we see
some of this going on

00:08:54.510 --> 00:08:58.650
with TensorFlows estimators and,
of course, Keras, and so forth.

00:08:58.650 --> 00:09:00.540
And I guess one
extension of that

00:09:00.540 --> 00:09:03.300
would be to think about
graphical representations,

00:09:03.300 --> 00:09:05.390
too, there.

00:09:05.390 --> 00:09:09.770
So this is its kind of expert
mode or current statements,

00:09:09.770 --> 00:09:13.110
which is roughly equivalent
to Jupyter Notebooks,

00:09:13.110 --> 00:09:16.190
but trying to sort of integrate
all of these components

00:09:16.190 --> 00:09:19.070
into one place.

00:09:19.070 --> 00:09:21.590
This is sort of the jumping
off point for the higher level

00:09:21.590 --> 00:09:23.340
functionality I'll
talk about in a moment.

00:09:25.729 --> 00:09:28.270
So one of the most intimidating
things about entering machine

00:09:28.270 --> 00:09:32.020
learning work is the process
of gaining an intuition

00:09:32.020 --> 00:09:34.930
for the role that certain
mathematical operations play

00:09:34.930 --> 00:09:38.590
in mechanizing inductive
learning processes.

00:09:38.590 --> 00:09:41.920
It was great to see Alex
mention Seymour Papert.

00:09:41.920 --> 00:09:44.380
And I won't make a
specific mention here,

00:09:44.380 --> 00:09:49.870
but he's sort of the spiritual
guide of all of this.

00:09:49.870 --> 00:09:53.020
So I think that
really the challenge

00:09:53.020 --> 00:09:55.480
of gaining this
intuition is really not

00:09:55.480 --> 00:09:59.950
just limited to those who are
mathematically uninitiated.

00:09:59.950 --> 00:10:02.010
And one way to
support this claim

00:10:02.010 --> 00:10:06.010
is to look at the, more or less,
300-year gap between Leibniz's

00:10:06.010 --> 00:10:08.170
first mention of the
chain rule in calculus

00:10:08.170 --> 00:10:11.980
and the advent of the back
propagation algorithm.

00:10:11.980 --> 00:10:15.970
So that is to say that
even with an understanding

00:10:15.970 --> 00:10:19.360
of the underlying mechanics
and mathematical tools,

00:10:19.360 --> 00:10:21.940
it's not always obvious that
a particular application

00:10:21.940 --> 00:10:26.620
of those tools will yield
a useful result when

00:10:26.620 --> 00:10:29.330
applied to a system that's too
complex to compute mentally.

00:10:32.190 --> 00:10:34.530
So to overcome
this challenge, we

00:10:34.530 --> 00:10:38.010
need to lower the barrier
to experimentation.

00:10:38.010 --> 00:10:40.460
And of course, unguided
experimentation

00:10:40.460 --> 00:10:43.820
is, in many cases, unlikely
to arrive from scratch

00:10:43.820 --> 00:10:46.050
at the kind of
complex formations we

00:10:46.050 --> 00:10:48.420
see in modern neural networks.

00:10:48.420 --> 00:10:52.680
But when an experimenter starts
from known mechanisms and moves

00:10:52.680 --> 00:10:57.516
outward, as guided by
their project interests,

00:10:57.516 --> 00:10:58.890
then it becomes
possible for them

00:10:58.890 --> 00:11:04.080
to explore this space in kind
of a more organic matter.

00:11:04.080 --> 00:11:06.090
And I think with
the current tools,

00:11:06.090 --> 00:11:09.000
this is somewhat
challenging, because a lot

00:11:09.000 --> 00:11:11.670
of the examples that we
would seek to learn from

00:11:11.670 --> 00:11:14.460
have been sort of
codified by experts

00:11:14.460 --> 00:11:17.926
in a very obscure
kind of way, at least

00:11:17.926 --> 00:11:20.050
from the point of view of
someone just entering it.

00:11:23.300 --> 00:11:24.900
In terms of
architectural components,

00:11:24.900 --> 00:11:28.310
I think it's important to take
sort of a multi-tier approach

00:11:28.310 --> 00:11:31.034
and provide novices with
extremely high-level building

00:11:31.034 --> 00:11:33.200
blocks that address the
basic categories of learning

00:11:33.200 --> 00:11:34.640
problems.

00:11:34.640 --> 00:11:37.100
Early in their experimentation,
it's sort of unlikely

00:11:37.100 --> 00:11:39.710
that they will have cause
to need something other

00:11:39.710 --> 00:11:43.070
than these kind of
generalized one size

00:11:43.070 --> 00:11:45.590
fits all building blocks,
because they haven't yet

00:11:45.590 --> 00:11:50.900
encountered the sort of
deviations from that.

00:11:50.900 --> 00:11:54.350
And so a high-level
interface with lightly

00:11:54.350 --> 00:11:57.380
customized templates and
under the hood automations

00:11:57.380 --> 00:12:00.920
will allow novices
to sort of explore

00:12:00.920 --> 00:12:05.070
this idea of how to kind of
frame a learning problem.

00:12:05.070 --> 00:12:08.030
And then as they
gain expertise, they

00:12:08.030 --> 00:12:11.330
might have cause to start
digging deeper and, of course,

00:12:11.330 --> 00:12:16.490
inspecting these components and
going to sort of lower levels.

00:12:16.490 --> 00:12:18.440
I guess we could sort
of call this the Keras

00:12:18.440 --> 00:12:22.520
layer and the TensorFlow layer.

00:12:22.520 --> 00:12:27.389
And so as they gain intuition
and kind of an understanding

00:12:27.389 --> 00:12:29.680
of how machine learning works,
through this perspective

00:12:29.680 --> 00:12:32.140
of, let's call it,
curriculum design,

00:12:32.140 --> 00:12:35.900
then, there may be
eventually kind of a cause

00:12:35.900 --> 00:12:39.880
to understand at the lower
level what's going on

00:12:39.880 --> 00:12:41.980
in the operations
and start to begin

00:12:41.980 --> 00:12:45.520
to think about how to customize
those things for themselves.

00:12:45.520 --> 00:12:48.042
Then as an extension of
these building blocks,

00:12:48.042 --> 00:12:49.500
the tool ultimately,
I think, needs

00:12:49.500 --> 00:12:51.090
to provide a really
extensive Model

00:12:51.090 --> 00:12:54.430
Zoo and the infrastructure
for users to share models.

00:12:54.430 --> 00:12:58.710
So think of this in three
kind of tiers as well.

00:12:58.710 --> 00:13:01.530
The first being that we would
have specified and trained

00:13:01.530 --> 00:13:03.600
models, meaning ones
that can be sort of

00:13:03.600 --> 00:13:05.370
just pulled directly
off the shelf

00:13:05.370 --> 00:13:07.185
and used for, say,
image recognition

00:13:07.185 --> 00:13:08.900
and task or something like that.

00:13:08.900 --> 00:13:11.010
A specified and
an untrained model

00:13:11.010 --> 00:13:15.090
would be one where the
architecture is prespecified

00:13:15.090 --> 00:13:21.300
to a particular input image
dimensions and so forth,

00:13:21.300 --> 00:13:23.220
but would be untrained.

00:13:23.220 --> 00:13:25.920
And then, at the
most general, would

00:13:25.920 --> 00:13:28.890
be kind of an unspecified
and untrained model, which

00:13:28.890 --> 00:13:31.710
would be, for instance,
say, a multilayer perceptron

00:13:31.710 --> 00:13:34.950
architecture that
could be specified

00:13:34.950 --> 00:13:37.050
to any particular
kind of problem.

00:13:40.540 --> 00:13:43.840
Then similarly, given, of
course, the primacy of data

00:13:43.840 --> 00:13:44.490
in--

00:13:44.490 --> 00:13:46.720
whoops, sorry-- given
the primacy of data

00:13:46.720 --> 00:13:49.570
in constructing machine learning
systems, the development tools,

00:13:49.570 --> 00:13:52.150
I think, should also
provide building blocks

00:13:52.150 --> 00:13:55.110
to facilitate the loading
and manipulating of data.

00:13:55.110 --> 00:13:58.300
Array manipulation's one of
the most common tasks performed

00:13:58.300 --> 00:14:00.280
by computer scientists,
but it's also

00:14:00.280 --> 00:14:03.970
one of the greatest sources
of frustrations for novices.

00:14:03.970 --> 00:14:06.580
And even seasoned
developers find it very time

00:14:06.580 --> 00:14:11.650
consuming to understand someone
else's ad hoc code for slicing

00:14:11.650 --> 00:14:13.630
complex data.

00:14:13.630 --> 00:14:16.360
And depending on what the user
wants to learn from the data,

00:14:16.360 --> 00:14:18.779
or what tasks she wants
to perform through it,

00:14:18.779 --> 00:14:20.320
the question of how
to slice the data

00:14:20.320 --> 00:14:22.390
and what neural
architecture to use

00:14:22.390 --> 00:14:24.700
are very much interrelated
considerations.

00:14:24.700 --> 00:14:28.660
And so for this reason, it's
important for the components

00:14:28.660 --> 00:14:32.350
in data manipulation to be
closely aligned with the tool's

00:14:32.350 --> 00:14:35.340
architectural building blocks.

00:14:35.340 --> 00:14:36.960
At the highest level,
the tools should

00:14:36.960 --> 00:14:43.020
provide interactive mechanisms
for selecting files selecting

00:14:43.020 --> 00:14:45.240
from files or media streams.

00:14:45.240 --> 00:14:48.330
At sort of a more
slightly lower level,

00:14:48.330 --> 00:14:53.320
it should be loaders for common
file types and data sets.

00:14:53.320 --> 00:14:55.470
And then at the lowest
level, of course,

00:14:55.470 --> 00:14:58.470
you don't want to inhibit
current methodologies,

00:14:58.470 --> 00:15:01.080
and so you should also
give programmatic tools

00:15:01.080 --> 00:15:03.850
for accessing the file system
and manipulating arrays

00:15:03.850 --> 00:15:06.460
in the conventional sense.

00:15:06.460 --> 00:15:09.310
Within this, I think
it also makes sense

00:15:09.310 --> 00:15:13.780
to support data set maintenance.

00:15:13.780 --> 00:15:16.420
So you would have
kind of Watchdogs

00:15:16.420 --> 00:15:20.860
that could look for changes
to remote or local file

00:15:20.860 --> 00:15:23.410
directories and perform
automatic retraining of models

00:15:23.410 --> 00:15:25.250
when updates occur.

00:15:25.250 --> 00:15:28.330
And then, finally, sort
of embedded directly

00:15:28.330 --> 00:15:30.060
within this kind
of environment, you

00:15:30.060 --> 00:15:34.360
would include crowdsourced tools
for either data acquisition

00:15:34.360 --> 00:15:36.500
or for cleaning.

00:15:36.500 --> 00:15:37.000
OK.

00:15:37.000 --> 00:15:38.541
So the next idea I
want to talk about

00:15:38.541 --> 00:15:40.330
is something I call directives.

00:15:40.330 --> 00:15:44.980
And so the idea is that in
a conventional programming

00:15:44.980 --> 00:15:48.150
language, the developer starts
with a nearly blank slate

00:15:48.150 --> 00:15:51.700
and needs to conceive of a set
of interrelated abstractions

00:15:51.700 --> 00:15:55.240
in order to address some kind of
desired programmatic behavior.

00:15:55.240 --> 00:15:57.890
This open-endedness is, of
course, a really great thing.

00:15:57.890 --> 00:16:01.150
But it also now requires
us to navigate on our own

00:16:01.150 --> 00:16:03.760
each component decision
in relation to each other

00:16:03.760 --> 00:16:05.500
and in relation to the whole.

00:16:05.500 --> 00:16:07.930
So directives are a mechanism
for helping developers

00:16:07.930 --> 00:16:10.330
to structure their thinking
without imposing any one

00:16:10.330 --> 00:16:12.960
specific abstraction on it.

00:16:12.960 --> 00:16:15.060
In the most basic
sense, directives

00:16:15.060 --> 00:16:16.590
are comprised by
a set of widgets

00:16:16.590 --> 00:16:19.200
for soliciting multimedia
inputs and presenting

00:16:19.200 --> 00:16:21.544
multimedia outputs to the user.

00:16:21.544 --> 00:16:23.460
The author of the directive
uses these widgets

00:16:23.460 --> 00:16:26.730
to compose a kind of decision
tree or guided process

00:16:26.730 --> 00:16:29.340
through which the user can
respond to each decision point

00:16:29.340 --> 00:16:32.580
in the most appropriate
modality for the task at hand.

00:16:32.580 --> 00:16:35.850
Visual information can
be communicated visually.

00:16:35.850 --> 00:16:38.720
And textual information can
be communicated textually.

00:16:38.720 --> 00:16:41.300
When a specific numeric value
is needed from the user,

00:16:41.300 --> 00:16:44.820
a slider could be presented so
that the user can experiment

00:16:44.820 --> 00:16:47.910
within a specific numeric range
and see its effect applied

00:16:47.910 --> 00:16:50.580
immediately and in context.

00:16:50.580 --> 00:16:53.520
Rather than offering one kind
of preordained mental model,

00:16:53.520 --> 00:16:56.550
by offering these in sort of
a Directive Zoo, if you will,

00:16:56.550 --> 00:16:58.890
it would provide
developers with a range

00:16:58.890 --> 00:17:02.830
of possible abstractions for a
variety of component problems.

00:17:02.830 --> 00:17:05.460
And alternately, of course, you
can write your own directives.

00:17:05.460 --> 00:17:07.920
And the process of
doing so, I think,

00:17:07.920 --> 00:17:10.380
is sort of analogous
to the sense

00:17:10.380 --> 00:17:14.250
in which kind of properly
formulating a question

00:17:14.250 --> 00:17:16.380
is half the work
of answering it.

00:17:19.544 --> 00:17:22.819
So directives are meant to
facilitate software development

00:17:22.819 --> 00:17:25.849
processes as kind of a
crowdsourced design pattern,

00:17:25.849 --> 00:17:28.460
but they're also something that
can be employed within user

00:17:28.460 --> 00:17:30.470
facing applications
to facilitate

00:17:30.470 --> 00:17:32.690
interactions with train
models or other features

00:17:32.690 --> 00:17:34.022
of an application.

00:17:34.022 --> 00:17:35.480
In this sense,
directives are meant

00:17:35.480 --> 00:17:37.940
to serve as a way
of kind of blurring

00:17:37.940 --> 00:17:41.480
the distinction between the acts
of writing and using software.

00:17:41.480 --> 00:17:43.140
In the context of
writing it, it helped

00:17:43.140 --> 00:17:45.514
to make it a more manageable
experience for the developer

00:17:45.514 --> 00:17:48.050
by breaking the process
into smaller tasks.

00:17:48.050 --> 00:17:50.600
And in a user
facing context, they

00:17:50.600 --> 00:17:52.880
provide a more natural
format for the kinds

00:17:52.880 --> 00:17:54.500
of multimodal
interactions that we'll

00:17:54.500 --> 00:17:57.320
need to have with
intelligent applications.

00:17:57.320 --> 00:18:00.290
Directives could be
written explicitly as code.

00:18:00.290 --> 00:18:04.460
Or, as shown here, they could
be created using directive

00:18:04.460 --> 00:18:06.630
making directives.

00:18:06.630 --> 00:18:09.120
That would ask questions
like what should the user

00:18:09.120 --> 00:18:13.470
do next, a very meta approach.

00:18:13.470 --> 00:18:15.110
Directives would
also be something

00:18:15.110 --> 00:18:19.050
that could be configured to do
data collection under the hood

00:18:19.050 --> 00:18:21.420
in order to feed a learning
decision tree, much

00:18:21.420 --> 00:18:23.550
like the digital
version of the game

00:18:23.550 --> 00:18:26.480
20 Questions which
is shown here.

00:18:26.480 --> 00:18:28.110
This, I think in
a way, could bring

00:18:28.110 --> 00:18:31.590
sort of a new way of looking
at the value of open source

00:18:31.590 --> 00:18:33.480
software, which
is that by sharing

00:18:33.480 --> 00:18:36.040
these kinds of processes
with other users

00:18:36.040 --> 00:18:38.880
and allowing them
to engage with them,

00:18:38.880 --> 00:18:41.580
their data is informing
the learning decision tree

00:18:41.580 --> 00:18:45.680
and, therefore, making
your shared software

00:18:45.680 --> 00:18:48.800
that much more effective.

00:18:48.800 --> 00:18:52.010
So the last group of
things I want to talk about

00:18:52.010 --> 00:19:03.270
is the integration of creative
coding or design tool elements

00:19:03.270 --> 00:19:05.350
where we've moved through
machine learning well

00:19:05.350 --> 00:19:07.780
beyond the confines
of keyboards and mouse

00:19:07.780 --> 00:19:10.930
into a machine's ability
to understand images

00:19:10.930 --> 00:19:13.000
and audio streams and videos.

00:19:13.000 --> 00:19:16.300
And these forms of media are
very critical to the training

00:19:16.300 --> 00:19:18.220
of machine learning
systems and also

00:19:18.220 --> 00:19:20.620
to our subsequent
interactions with them.

00:19:20.620 --> 00:19:23.560
And our programming tools today
provide very little assistance

00:19:23.560 --> 00:19:24.250
with this.

00:19:24.250 --> 00:19:25.630
To build a data
set, we generally

00:19:25.630 --> 00:19:29.290
kind of are working somewhere
between the operating systems

00:19:29.290 --> 00:19:35.680
file, file system conventional
design tools, some ad hoc code.

00:19:35.680 --> 00:19:39.250
And so I think both in
terms of curating data sets

00:19:39.250 --> 00:19:43.505
and in terms of things like
visualizing training metrics,

00:19:43.505 --> 00:19:46.750
it makes a lot of sense to start
kind of embedding these things

00:19:46.750 --> 00:19:49.930
into the tool itself.

00:19:49.930 --> 00:19:52.940
In the interest of time, let
me sort of get to the point.

00:19:52.940 --> 00:19:57.250
OK, so I think there are three
areas where this is relevant.

00:19:57.250 --> 00:19:59.270
The first is what
I've just mentioned,

00:19:59.270 --> 00:20:02.260
which is to facilitate
the input process,

00:20:02.260 --> 00:20:04.000
that we would be
curating data sets

00:20:04.000 --> 00:20:07.840
and so forth through this kind
of integrated design tool.

00:20:07.840 --> 00:20:11.950
The second is in sort of
the integration of whatever

00:20:11.950 --> 00:20:16.040
applications we're building
with these trained models

00:20:16.040 --> 00:20:17.830
so that once, you know--

00:20:17.830 --> 00:20:22.450
sorry-- a lot of the tools
today would either kind of

00:20:22.450 --> 00:20:25.480
go with a RESTful service or
perhaps a messaging protocol

00:20:25.480 --> 00:20:28.360
to bridge independent
systems like OSC.

00:20:28.360 --> 00:20:31.210
These are, of course,
great solutions, but as

00:20:31.210 --> 00:20:34.960
higher bandwidth
systems come into play--

00:20:34.960 --> 00:20:38.560
like in this case a
Realtime slam implementation

00:20:38.560 --> 00:20:41.560
or a mapping of rooms--

00:20:41.560 --> 00:20:43.630
it makes sense to
start to integrate

00:20:43.630 --> 00:20:45.850
this kind of
functionality natively

00:20:45.850 --> 00:20:48.250
into an environment in
which we can build user

00:20:48.250 --> 00:20:52.710
facing applications, so that
people could build things,

00:20:52.710 --> 00:20:58.250
use oppose estimation model
to connect skeletal control

00:20:58.250 --> 00:21:02.630
in the character in their game,
or an image segmentation model

00:21:02.630 --> 00:21:06.800
to build sort of their
own image editing tool.

00:21:06.800 --> 00:21:07.300
Sorry.

00:21:07.300 --> 00:21:07.800
OK.

00:21:07.800 --> 00:21:12.280
So finally just to complete
the loop, developers--

00:21:12.280 --> 00:21:15.490
also, as we have talked about
with the reinforcement learning

00:21:15.490 --> 00:21:18.150
thing and DeepMind
and OpenAI, the sort

00:21:18.150 --> 00:21:21.310
of output of these
applications can then

00:21:21.310 --> 00:21:23.440
become kind of new
training input.

00:21:23.440 --> 00:21:26.050
So that we could
look at user action

00:21:26.050 --> 00:21:28.357
histories to kind
of learn models

00:21:28.357 --> 00:21:30.190
where we try to predict
what they would want

00:21:30.190 --> 00:21:35.950
to do next or use a physics
environment to build training

00:21:35.950 --> 00:21:40.580
inputs for a
reinforcement model.

00:21:40.580 --> 00:21:43.850
So finally, I'll just
conclude by saying

00:21:43.850 --> 00:21:49.190
that the revolution
in personal computers

00:21:49.190 --> 00:21:52.430
only occurred when the tools,
desktop publishing, and so

00:21:52.430 --> 00:21:55.760
forth, became accessible
and kind of made

00:21:55.760 --> 00:21:59.450
the need for computers
relevant to the everyday person

00:21:59.450 --> 00:22:01.157
to build something
for themselves.

00:22:01.157 --> 00:22:03.740
I think that this is very much
the case with machine learning.

00:22:03.740 --> 00:22:06.830
Until we are able to
use these tools to solve

00:22:06.830 --> 00:22:12.380
our own unique problems,
we are at the behest

00:22:12.380 --> 00:22:14.240
of prebuilt services.

00:22:14.240 --> 00:22:15.740
And so it's very
important for tools

00:22:15.740 --> 00:22:19.655
to be able to connect with
people's individual needs.

00:22:19.655 --> 00:22:20.645
Thanks.

00:22:20.645 --> 00:22:24.110
[APPLAUSE]

00:22:36.020 --> 00:22:36.830
AUDIENCE: Hi.

00:22:36.830 --> 00:22:37.770
Thank you for that.

00:22:37.770 --> 00:22:42.930
I wondered whether you had any
thoughts on two things, really,

00:22:42.930 --> 00:22:44.960
one which is forgetting.

00:22:44.960 --> 00:22:47.270
Because a lot of
what makes us human

00:22:47.270 --> 00:22:51.950
is also to be able to forget
either methodologies for riding

00:22:51.950 --> 00:22:56.810
a bike that didn't work out
for us, or people, or events,

00:22:56.810 --> 00:22:59.540
or spaces, and whether
there is a role in machine

00:22:59.540 --> 00:23:03.800
learning for the idea
of forgetting things.

00:23:03.800 --> 00:23:06.740
And the other element
of that is whether--

00:23:06.740 --> 00:23:11.240
again, as humans, we're
really terrible at quite a lot

00:23:11.240 --> 00:23:12.260
of different things.

00:23:12.260 --> 00:23:16.190
And a joke that's doing
the rounds on Twitter

00:23:16.190 --> 00:23:20.330
is a concerned teacher, should
I throw myself off a bridge?

00:23:20.330 --> 00:23:25.060
Machine learning says, yes,
because the data says yes.

00:23:25.060 --> 00:23:29.420
So where in machine learning
and programmatically speaking

00:23:29.420 --> 00:23:35.270
do we place decision making
ethics and even identification

00:23:35.270 --> 00:23:37.700
that something actually
should never be?

00:23:37.700 --> 00:23:40.422
You shouldn't be
doing this at all.

00:23:40.422 --> 00:23:41.380
PATRICK HEBRON: Thanks.

00:23:41.380 --> 00:23:43.640
That's a great question.

00:23:43.640 --> 00:23:47.120
I mean I am certainly
of the opinion

00:23:47.120 --> 00:23:51.230
that this is 100% about
humans and that these

00:23:51.230 --> 00:23:53.970
are tools to extend our reach.

00:23:53.970 --> 00:23:56.360
It's in a very
different form, perhaps,

00:23:56.360 --> 00:23:58.490
than sort of previous tools.

00:23:58.490 --> 00:24:03.200
I guess we could compare it to
various previous revolutions,

00:24:03.200 --> 00:24:08.450
the Industrial Revolution, but,
perhaps, the better comparison

00:24:08.450 --> 00:24:11.230
would be to compare it to
the domestication of animals,

00:24:11.230 --> 00:24:13.850
perhaps.

00:24:13.850 --> 00:24:16.370
But it will go on beyond that.

00:24:16.370 --> 00:24:19.340
And I think we don't really
know quite yet whether it's

00:24:19.340 --> 00:24:20.820
that or something much more.

00:24:20.820 --> 00:24:21.320
Right?

00:24:21.320 --> 00:24:24.260
The question of whether we
achieve general intelligence

00:24:24.260 --> 00:24:27.590
in machines in any
near-term sort of

00:24:27.590 --> 00:24:29.420
will dictate whether
we're talking

00:24:29.420 --> 00:24:31.430
more about the
domestication of animals,

00:24:31.430 --> 00:24:35.660
or something perhaps
much uglier than that.

00:24:35.660 --> 00:24:37.880
And so, you know,
that I guess will

00:24:37.880 --> 00:24:40.909
decide some of the history
in relation to your question.

00:24:40.909 --> 00:24:42.950
But I think for the time
being, and without being

00:24:42.950 --> 00:24:47.110
able to know where we
will be in that respect,

00:24:47.110 --> 00:24:49.280
the kinds of things that
we should be focused on

00:24:49.280 --> 00:24:55.472
are ways in which people
can tack this on to tasks

00:24:55.472 --> 00:24:56.930
that they might
have used, perhaps,

00:24:56.930 --> 00:25:00.530
computer science for
previously, but in domains

00:25:00.530 --> 00:25:03.110
where basically sort
of explicit procedure

00:25:03.110 --> 00:25:04.725
is just not effective.

00:25:07.575 --> 00:25:09.980
Oh, and as far
as, yeah, oh well.

00:25:09.980 --> 00:25:12.330
Shall I address the
forgetting or leave it there?

00:25:12.330 --> 00:25:13.330
SPEAKER 1: Yeah, please.

00:25:15.430 --> 00:25:20.860
PATRICK HEBRON: Yeah, I mean,
so the task of creating a data

00:25:20.860 --> 00:25:25.120
set sort of depends on, again,
sort of what mechanisms occur

00:25:25.120 --> 00:25:27.160
in the near term, whether
we sort of get down

00:25:27.160 --> 00:25:31.360
to zero shot or one shot kind
of learning mechanisms where

00:25:31.360 --> 00:25:33.550
we need far fewer examples.

00:25:33.550 --> 00:25:35.950
Obviously, it sort of
plays a big role in

00:25:35.950 --> 00:25:38.180
whether the curation
of a data set

00:25:38.180 --> 00:25:43.000
is something where an individual
can kind of go in and manicure

00:25:43.000 --> 00:25:46.030
things in that way.

00:25:46.030 --> 00:25:49.600
Of course, there are a
number of mechanisms on, say,

00:25:49.600 --> 00:25:50.560
transfer learning.

00:25:50.560 --> 00:25:53.170
And also in the project
that Alex showed,

00:25:53.170 --> 00:25:56.410
they are using the nearest
neighbors so that in the end,

00:25:56.410 --> 00:26:00.760
the number of examples that
is needed is very small.

00:26:00.760 --> 00:26:02.820
So I mean it's a really
interesting question.

00:26:02.820 --> 00:26:05.140
And I think I haven't thought
it through sufficiently.

00:26:05.140 --> 00:26:11.710
But I guess I could just say
that ideally, this kind of tool

00:26:11.710 --> 00:26:15.250
sort of puts it in a much
larger group of people's hands.

00:26:15.250 --> 00:26:21.880
And therefore, it is kind of not
so enclave to a people with one

00:26:21.880 --> 00:26:23.830
very specialized
skill to kind of make

00:26:23.830 --> 00:26:27.160
these decisions for all
of us, but instead that

00:26:27.160 --> 00:26:30.130
as each of our sort
of own personal tool,

00:26:30.130 --> 00:26:33.760
we can start to make
the curation of what

00:26:33.760 --> 00:26:38.165
we want to remember or
forget for ourselves.

00:26:38.165 --> 00:26:39.814
SPEAKER 1: Question here?

00:26:39.814 --> 00:26:40.480
AUDIENCE: Sorry.

00:26:40.480 --> 00:26:42.990
Me again.

00:26:42.990 --> 00:26:45.330
I think your work has
interesting parallels

00:26:45.330 --> 00:26:51.180
with end user programming,
end user software engineering,

00:26:51.180 --> 00:26:55.530
and end user development
for straightforward software

00:26:55.530 --> 00:26:58.770
or straightforward programs.

00:26:58.770 --> 00:27:03.180
I think that work has been
around a number of years.

00:27:03.180 --> 00:27:09.270
And it rests on making
programming environments easier

00:27:09.270 --> 00:27:11.290
for novices.

00:27:11.290 --> 00:27:14.890
But also, it uses
an understanding

00:27:14.890 --> 00:27:21.070
of what novices and end
users without a background

00:27:21.070 --> 00:27:22.850
in programming struggle with.

00:27:22.850 --> 00:27:23.350
Right?

00:27:23.350 --> 00:27:25.360
So we know that there
are certain things

00:27:25.360 --> 00:27:28.390
in computational thinking
that are really, really

00:27:28.390 --> 00:27:30.520
difficult to grasp.

00:27:30.520 --> 00:27:34.610
What do you think
those challenges

00:27:34.610 --> 00:27:36.160
are for machine learning?

00:27:36.160 --> 00:27:42.070
What are the tricky things that
ordinary users will trip upon

00:27:42.070 --> 00:27:44.952
and that they need
particular support with?

00:27:44.952 --> 00:27:45.910
PATRICK HEBRON: Thanks.

00:27:45.910 --> 00:27:48.140
That's a great question.

00:27:48.140 --> 00:27:51.670
So to go back to the
beginning of your point

00:27:51.670 --> 00:27:53.790
that those kinds
of mechanisms exist

00:27:53.790 --> 00:27:56.010
in conventional
programming context,

00:27:56.010 --> 00:28:00.280
I think one place where that
can be a little misguided in how

00:28:00.280 --> 00:28:04.660
people kind of approach the
simplification is to elucidate

00:28:04.660 --> 00:28:06.640
an individual mechanism
in programming,

00:28:06.640 --> 00:28:09.700
like say a
conditional or a loop,

00:28:09.700 --> 00:28:12.910
and kind of go into depth
about sort of exposing that.

00:28:12.910 --> 00:28:15.820
But as programmers,
I think what we've

00:28:15.820 --> 00:28:18.520
come to realize is that,
ultimately, the thing that

00:28:18.520 --> 00:28:21.700
makes programming complicated
is not understanding how

00:28:21.700 --> 00:28:25.850
an individual for-loop
works, but about how many,

00:28:25.850 --> 00:28:28.090
many of these little
granular building

00:28:28.090 --> 00:28:30.419
blocks all kind of
have to work together

00:28:30.419 --> 00:28:31.585
in this very complex system.

00:28:31.585 --> 00:28:32.085
Right?

00:28:32.085 --> 00:28:34.240
And so that's the real
skill in programming

00:28:34.240 --> 00:28:37.060
is learning how to sort of
put all of these little pieces

00:28:37.060 --> 00:28:38.000
together.

00:28:38.000 --> 00:28:42.820
So my purpose in thinking
about this directives concept

00:28:42.820 --> 00:28:45.850
is to try to address
that in a way.

00:28:45.850 --> 00:28:50.200
Which is to say that it's not
about learning any one building

00:28:50.200 --> 00:28:53.130
block, but instead
about the big curation.

00:28:53.130 --> 00:28:55.610
And so the attempt
with directives

00:28:55.610 --> 00:28:59.380
to kind of think about a way of
not specializing around any one

00:28:59.380 --> 00:29:02.710
use case, but sort of
creating a mechanism

00:29:02.710 --> 00:29:06.460
by which we can guide ourselves,
or guide other people,

00:29:06.460 --> 00:29:09.990
through complicated processes,
not any one specific process,

00:29:09.990 --> 00:29:14.120
but that we have, if you will,
a platform for doing that.

00:29:14.120 --> 00:29:16.450
So just to sort of
wrap up the answer.

00:29:16.450 --> 00:29:19.030
I think in machine
learning, probably

00:29:19.030 --> 00:29:24.340
it is in spirit the same issue
as it is in conventional code.

00:29:24.340 --> 00:29:27.520
Which is that it's not sort
of the issue of understanding

00:29:27.520 --> 00:29:29.500
any one little
specific mechanism,

00:29:29.500 --> 00:29:31.480
but understanding how
they all act together.

00:29:31.480 --> 00:29:31.980
Right?

00:29:31.980 --> 00:29:35.500
So understanding a perceptron,
like a linear neuron

00:29:35.500 --> 00:29:39.190
is perhaps not too challenging.

00:29:39.190 --> 00:29:43.660
But it doesn't quite
scale up to understand

00:29:43.660 --> 00:29:46.960
why this sort of works when
you're dealing with many layers

00:29:46.960 --> 00:29:49.915
with millions of
connections between them.

00:29:53.622 --> 00:29:54.913
SPEAKER 1: Thank you very much.

00:29:54.913 --> 00:29:57.228
[APPLAUSE]

00:30:00.010 --> 00:30:01.580
SPEAKER 2: So the
last speaker is--

00:30:01.580 --> 00:30:04.450
and I am going to pronounce
it right Cennydd--

00:30:04.450 --> 00:30:05.540
excellent.

00:30:05.540 --> 00:30:07.750
Cennydd is a designer
and an author.

00:30:07.750 --> 00:30:12.820
And he has been looking
particularly at future ethics.

00:30:12.820 --> 00:30:16.620
He's been advising different
companies like Samsung--

