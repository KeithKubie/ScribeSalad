WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.430
[MUSIC PLAYING]

00:00:05.269 --> 00:00:07.810
DOUGLAS ECK: It's almost a full
room at 2:30 in the afternoon

00:00:07.810 --> 00:00:10.040
on a Friday, so that's awesome.

00:00:10.040 --> 00:00:11.080
My name's Doug.

00:00:11.080 --> 00:00:14.190
I'm going to talk to you
about Magenta, a project

00:00:14.190 --> 00:00:18.304
that we're doing in Google Brain
that's focused on music and art

00:00:18.304 --> 00:00:19.220
with machine learning.

00:00:19.220 --> 00:00:21.449
So I hope there
are some questions.

00:00:21.449 --> 00:00:23.990
I'll try to blaze through this
and leave a little bit of time

00:00:23.990 --> 00:00:25.420
for questions at the end.

00:00:25.420 --> 00:00:29.460
I'm going to talk about two
different projects, both

00:00:29.460 --> 00:00:31.090
of them under the
umbrella of Magenta.

00:00:31.090 --> 00:00:34.440
One has to do with drawing,
and one has to do with sound.

00:00:34.440 --> 00:00:37.100
But I want to give a little
idea, first, what Magenta is

00:00:37.100 --> 00:00:39.390
and why we're doing
what we're doing.

00:00:39.390 --> 00:00:41.530
Fundamentally, we're
asking the question,

00:00:41.530 --> 00:00:44.090
can we use deep learning
and reinforcement learning

00:00:44.090 --> 00:00:46.200
to do something creative.

00:00:46.200 --> 00:00:48.580
And by this, I really mean
furthering our own creativity

00:00:48.580 --> 00:00:49.440
as people.

00:00:49.440 --> 00:00:52.690
I don't mean pushing a button,
and standing back, and watching

00:00:52.690 --> 00:00:53.650
the computer make art.

00:00:53.650 --> 00:00:55.580
I think that's less
interesting than actually

00:00:55.580 --> 00:00:58.480
having a cool new piece of
technology to work with.

00:00:58.480 --> 00:01:00.990
There are two things that
we're doing concretely.

00:01:00.990 --> 00:01:03.460
One of them is an open
source project on GitHub.

00:01:03.460 --> 00:01:05.526
It's part of TensorFlow,
TensorFlow Magenta.

00:01:05.526 --> 00:01:07.400
And we're trying to
engage a number of people

00:01:07.400 --> 00:01:09.880
to work with us, all
of you in the room,

00:01:09.880 --> 00:01:12.670
including creative coders,
including musicians, including

00:01:12.670 --> 00:01:14.125
artists, and
including developers.

00:01:14.125 --> 00:01:16.000
And at the same time,
it's a research effort.

00:01:16.000 --> 00:01:18.333
So part of our mission in
Google Brain on the Brain team

00:01:18.333 --> 00:01:20.510
is to publish papers and
to work with academics.

00:01:20.510 --> 00:01:23.260
And we're pushing all the stuff
out, not only at open source,

00:01:23.260 --> 00:01:25.050
but in the research world.

00:01:25.050 --> 00:01:26.050
We have a blog.

00:01:26.050 --> 00:01:29.600
If you want to remember one URL,
it's magenta.tensorflow.org.

00:01:29.600 --> 00:01:32.530
It's also at g.co/magenta, but
it's fine to do it this way.

00:01:32.530 --> 00:01:34.790
And that'll link you to our
code and to other things.

00:01:34.790 --> 00:01:37.420
So please check it out.

00:01:37.420 --> 00:01:39.850
Now, there are a
number questions

00:01:39.850 --> 00:01:44.200
you can ask about creativity,
and about art, and about music,

00:01:44.200 --> 00:01:46.317
and how they all work together.

00:01:46.317 --> 00:01:47.900
I've thought about
this problem a lot.

00:01:47.900 --> 00:01:50.210
And I've come to the
conclusion that there's

00:01:50.210 --> 00:01:52.170
a role that technology
plays, and there's

00:01:52.170 --> 00:01:54.540
a role that artists
play, and that we

00:01:54.540 --> 00:01:57.819
need to really carefully
understand that interaction.

00:01:57.819 --> 00:01:59.860
Also, I want to point out
that this has been true

00:01:59.860 --> 00:02:01.510
since we've been doing art.

00:02:01.510 --> 00:02:05.390
A cave painting requires
a piece of charcoal.

00:02:05.390 --> 00:02:09.750
Musical instruments are highly
evolved pieces of technology.

00:02:09.750 --> 00:02:13.330
And so I think of us at
Magenta more like the person

00:02:13.330 --> 00:02:16.520
on the left, who's Les Paul,
one of the people credited

00:02:16.520 --> 00:02:17.960
with creating the
electric guitar,

00:02:17.960 --> 00:02:19.940
and less like the
people on the right.

00:02:19.940 --> 00:02:20.960
That's St. Vincent.

00:02:20.960 --> 00:02:22.430
But you can think
of Jimi Hendrix.

00:02:22.430 --> 00:02:23.805
You can think of
any artist who's

00:02:23.805 --> 00:02:26.440
pushing the boundaries
of the electric guitar.

00:02:26.440 --> 00:02:27.910
And I bring this
up because I think

00:02:27.910 --> 00:02:29.830
it's important to
understand what people

00:02:29.830 --> 00:02:31.320
do with technology and art.

00:02:31.320 --> 00:02:31.900
They push it.

00:02:31.900 --> 00:02:32.490
They drive it.

00:02:32.490 --> 00:02:33.790
They break it.

00:02:33.790 --> 00:02:36.852
Jimi Hendrix came along and
made the guitar distort.

00:02:36.852 --> 00:02:38.560
Maybe some of you in
the crowd are aware,

00:02:38.560 --> 00:02:41.110
but the goal of
the electric guitar

00:02:41.110 --> 00:02:44.000
was to create a loud
acoustic guitar.

00:02:44.000 --> 00:02:47.240
And distortion of the
amplifier was a failure case.

00:02:47.240 --> 00:02:49.250
In the engineering world,
it was a fall over.

00:02:49.250 --> 00:02:51.510
Yet people come along-- this
is true for film cameras

00:02:51.510 --> 00:02:53.289
as well too, overexposing film.

00:02:53.289 --> 00:02:54.830
Any piece of technology
you think of,

00:02:54.830 --> 00:02:56.800
you're going to find
people breaking it as part

00:02:56.800 --> 00:02:57.590
of the artistic process.

00:02:57.590 --> 00:02:58.310
And I love that.

00:02:58.310 --> 00:03:00.384
So for me, success
for Magenta would

00:03:00.384 --> 00:03:02.550
be if someone does something
in five years with what

00:03:02.550 --> 00:03:05.662
we built that we had no idea
was coming, none whatsoever.

00:03:05.662 --> 00:03:07.120
So I want you to
have that in mind,

00:03:07.120 --> 00:03:08.953
that what we're thinking
about is furthering

00:03:08.953 --> 00:03:10.900
the creative process
like all technology that

00:03:10.900 --> 00:03:14.480
came before that's
used artistically.

00:03:14.480 --> 00:03:17.520
Very quick tour, given the
time we have, is deep learning.

00:03:17.520 --> 00:03:18.710
Deep learning is deep.

00:03:18.710 --> 00:03:20.450
See how deep the stack is.

00:03:20.450 --> 00:03:22.230
Weighted connections
in a neural network

00:03:22.230 --> 00:03:25.250
are being trained in order
to predict something.

00:03:25.250 --> 00:03:27.690
It's also worth noting
that these models naturally

00:03:27.690 --> 00:03:30.740
extract nice features,
nice filters from data,

00:03:30.740 --> 00:03:32.400
making it possible
for us to focus

00:03:32.400 --> 00:03:35.330
on the use of machine learning
for creative processes.

00:03:35.330 --> 00:03:37.600
So we don't have to
build these things in.

00:03:37.600 --> 00:03:39.100
By the way, this slide is great.

00:03:39.100 --> 00:03:43.390
It's from Zeiler and Fergus,
a great research paper

00:03:43.390 --> 00:03:46.472
from about five years ago.

00:03:46.472 --> 00:03:48.430
I also want to point out,
for those of you that

00:03:48.430 --> 00:03:50.582
are paying attention
to deep learning,

00:03:50.582 --> 00:03:52.290
deep learning, in some
sense, is not new.

00:03:52.290 --> 00:03:55.060
We've had neural networks since
at least the 1980s, arguably

00:03:55.060 --> 00:03:57.760
the 1960s.

00:03:57.760 --> 00:04:00.560
But they haven't always shown
themselves to be the most--

00:04:00.560 --> 00:04:03.070
you know, the best
models for the job.

00:04:03.070 --> 00:04:05.870
One explanation for this
is that neural networks

00:04:05.870 --> 00:04:06.912
are really good at scale.

00:04:06.912 --> 00:04:08.869
They're really good when
you have a lot of data

00:04:08.869 --> 00:04:10.330
or when you have large models.

00:04:10.330 --> 00:04:13.261
And so as we move with more
compute power, what we find

00:04:13.261 --> 00:04:15.010
is that neural networks
end up winning out

00:04:15.010 --> 00:04:18.649
over other technologies, which
I think is, in its own right,

00:04:18.649 --> 00:04:21.470
interesting and worthy of
discussion, but not here,

00:04:21.470 --> 00:04:23.790
because we have to move on.

00:04:23.790 --> 00:04:26.530
All right, let's jump
into our first project.

00:04:26.530 --> 00:04:29.410
This project was led by David
Ha, a Google Brain resident,

00:04:29.410 --> 00:04:31.010
extremely creative guy.

00:04:31.010 --> 00:04:33.940
And this project is about
teaching a machine learning

00:04:33.940 --> 00:04:36.044
model to learn to draw.

00:04:36.044 --> 00:04:37.460
And these are some
of the pictures

00:04:37.460 --> 00:04:39.180
that this machine
learning model drew.

00:04:39.180 --> 00:04:40.490
Just a show of hands,
how many people

00:04:40.490 --> 00:04:43.031
have seen the Sketch-RNN stuff
or are familiar with the Quick

00:04:43.031 --> 00:04:43.710
Draw data.

00:04:43.710 --> 00:04:44.710
All right, that's great.

00:04:44.710 --> 00:04:47.190
OK, so we're going to see
a little bit more of that.

00:04:47.190 --> 00:04:49.481
Some of the Quick Draw guys
are sitting right over here

00:04:49.481 --> 00:04:51.990
if you want to give them
a shout out for the game

00:04:51.990 --> 00:04:53.210
and for the data.

00:04:53.210 --> 00:04:53.760
Awesome work.

00:04:53.760 --> 00:04:57.106
[APPLAUSE]

00:04:59.500 --> 00:05:02.520
On our part, in Magenta, we
trained models on Quick Draw.

00:05:02.520 --> 00:05:04.590
And we just released a
bunch of source code.

00:05:04.590 --> 00:05:06.940
And you can train
your own models.

00:05:06.940 --> 00:05:08.860
We even have a nice
Jupyter Notebook.

00:05:08.860 --> 00:05:12.030
The call to action there is to
go to magenta.tensorflow.org.

00:05:12.030 --> 00:05:12.852
Jump into our blog.

00:05:12.852 --> 00:05:14.060
You'll find the blog posting.

00:05:14.060 --> 00:05:15.600
It's easy enough
to find our GitHub.

00:05:15.600 --> 00:05:16.600
And you can play around.

00:05:16.600 --> 00:05:18.300
You can decide--
like we did here,

00:05:18.300 --> 00:05:20.890
you can draw some flamingos
in, like, three lines of code.

00:05:20.890 --> 00:05:22.200
And it's kind of fun to do.

00:05:22.200 --> 00:05:25.750
So please check that out
and give us feedback.

00:05:25.750 --> 00:05:28.000
I want to talk a little bit
about the machine learning

00:05:28.000 --> 00:05:29.110
in this project.

00:05:29.110 --> 00:05:30.800
Fundamentally, what
we're working with

00:05:30.800 --> 00:05:32.990
are a kind of machine
learning technology

00:05:32.990 --> 00:05:34.152
called an autoencoder.

00:05:34.152 --> 00:05:35.610
And there's a couple
of basic ideas

00:05:35.610 --> 00:05:37.310
that I want everybody
to understand.

00:05:37.310 --> 00:05:39.580
What we're doing is
we're taking some input--

00:05:39.580 --> 00:05:42.894
in this case, it's strokes as
drawn by someone on a screen--

00:05:42.894 --> 00:05:44.810
and we're building some
sort of neural network

00:05:44.810 --> 00:05:47.900
that can encode them into
some other representation.

00:05:47.900 --> 00:05:49.920
And in general,
that representation

00:05:49.920 --> 00:05:54.070
is not larger, but smaller
than the source representation.

00:05:54.070 --> 00:05:56.400
So the model is forced
to try to pull out

00:05:56.400 --> 00:05:59.070
the important
regularities in the data,

00:05:59.070 --> 00:06:01.520
because it's not big enough
to memorize the data.

00:06:01.520 --> 00:06:03.310
And so that Z in
the middle, think

00:06:03.310 --> 00:06:05.102
of that as your reduced
representation that

00:06:05.102 --> 00:06:06.976
has pulled out all the
important bits that it

00:06:06.976 --> 00:06:08.350
needs to try to recreate these.

00:06:08.350 --> 00:06:12.440
And it's going to drive a
decoder to recreate the output.

00:06:12.440 --> 00:06:15.350
In our case, the input
are stroke-based drawings

00:06:15.350 --> 00:06:19.370
done by people when they
play the game, Quick Draw.

00:06:19.370 --> 00:06:22.850
And we encode them using a
recurrent neural network that

00:06:22.850 --> 00:06:25.330
is actually moving through
the sequence of strokes,

00:06:25.330 --> 00:06:27.440
trying to predict
the next stroke,

00:06:27.440 --> 00:06:29.679
and actually moving backwards
from the end sequence,

00:06:29.679 --> 00:06:31.720
trying to predict the
sequences in reverse order.

00:06:31.720 --> 00:06:34.130
It's called a bi-directional
recurrent neural network

00:06:34.130 --> 00:06:36.140
or a bi-directional LSTM.

00:06:36.140 --> 00:06:37.830
And the whole job
of that network

00:06:37.830 --> 00:06:40.970
is to create this vector,
the Z I was talking about,

00:06:40.970 --> 00:06:42.670
or if you're Canadian, Zed.

00:06:42.670 --> 00:06:47.565
And this vector is going to be
used to condition the decoding.

00:06:47.565 --> 00:06:49.190
So we have this
embedding, this number,

00:06:49.190 --> 00:06:51.840
the string of numbers in latent
space that we can sample from,

00:06:51.840 --> 00:06:53.590
that we can add some
noise to and generate

00:06:53.590 --> 00:06:54.995
new instances of data.

00:06:54.995 --> 00:06:57.120
That will then be driven
through the decoder, which

00:06:57.120 --> 00:06:59.280
is, in this case, another
recurrent neural network,

00:06:59.280 --> 00:07:01.940
though only going in one
direction, from left to right.

00:07:01.940 --> 00:07:05.400
And it's going to drive
a mixture of Gaussians,

00:07:05.400 --> 00:07:09.005
so a mixture of possible places
where the pen would land next.

00:07:09.005 --> 00:07:11.380
And if, for some of you, that's
word salad, that's great.

00:07:11.380 --> 00:07:12.130
It's fun word salad.

00:07:12.130 --> 00:07:13.410
And if some of you
understand it better,

00:07:13.410 --> 00:07:14.576
jump off and read our paper.

00:07:14.576 --> 00:07:16.530
You can grab the paper
from tensorflow--

00:07:16.530 --> 00:07:20.280
magenta.tensorflow.org.

00:07:20.280 --> 00:07:22.660
So the most important
thing in machine learning

00:07:22.660 --> 00:07:23.870
is having data.

00:07:23.870 --> 00:07:26.951
And the Quick draw team, A,
designed a brilliant game.

00:07:26.951 --> 00:07:28.700
Thanks to Jonas, who's
sitting over there,

00:07:28.700 --> 00:07:30.810
and the rest of the
people in Creative Lab

00:07:30.810 --> 00:07:34.310
for drawing a really fun game
to play along with, and also,

00:07:34.310 --> 00:07:37.590
for releasing the data for
machine learning researchers

00:07:37.590 --> 00:07:41.492
to work with, and also for
you to play with and enjoy.

00:07:41.492 --> 00:07:43.200
So everything that we
did in this project

00:07:43.200 --> 00:07:45.680
relies on having that
data and running that data

00:07:45.680 --> 00:07:48.270
through generative models.

00:07:48.270 --> 00:07:50.440
I also want to give a shout
out to a related project

00:07:50.440 --> 00:07:52.997
from the handwriting
team, AutoDraw,

00:07:52.997 --> 00:07:55.080
which is doing, in some
sense, the reverse of what

00:07:55.080 --> 00:07:55.780
we're trying to do.

00:07:55.780 --> 00:07:57.230
We're trying to
generate new drawings.

00:07:57.230 --> 00:07:58.690
This one is trying
to take your drawing

00:07:58.690 --> 00:08:00.720
and find the nearest
matching icon or some nearest

00:08:00.720 --> 00:08:01.955
matching drawing done
by a professional.

00:08:01.955 --> 00:08:04.180
So it's another really cool
thing that you can try.

00:08:04.180 --> 00:08:07.200
Just hit autodraw.com.

00:08:07.200 --> 00:08:08.990
Now I want to do a demo.

00:08:08.990 --> 00:08:10.740
So can we switch over
to this demo screen?

00:08:13.630 --> 00:08:17.279
This demo was built by David.

00:08:17.279 --> 00:08:18.820
And what I'm going
to do is I'm going

00:08:18.820 --> 00:08:21.360
to draw something on the left.

00:08:21.360 --> 00:08:24.010
And then we're going to sample
from the model nine times.

00:08:24.010 --> 00:08:25.570
And remember, the model
has some noise in it.

00:08:25.570 --> 00:08:26.515
It's not completely
deterministic,

00:08:26.515 --> 00:08:28.680
so we're going to get
nine different drawings.

00:08:28.680 --> 00:08:30.580
This is a model that's
trained on rain.

00:08:30.580 --> 00:08:33.320
And so let's take and just
draw a raindrop, all right?

00:08:33.320 --> 00:08:36.030
You'll see my raindrop
appearing nine times.

00:08:36.030 --> 00:08:38.130
And I did a nice,
big, round raindrop.

00:08:38.130 --> 00:08:39.909
And now I'm going
to let the model go.

00:08:39.909 --> 00:08:41.640
And it's going to
make rain happen.

00:08:41.640 --> 00:08:43.140
And you can see
some of the variety,

00:08:43.140 --> 00:08:44.806
the kind of natural
variety in the model

00:08:44.806 --> 00:08:50.367
that comes from sampling
from it multiple times.

00:08:50.367 --> 00:08:52.700
You could also just say, hey,
let's draw rain like this.

00:08:52.700 --> 00:08:54.750
Because some people
draw rain like this.

00:08:54.750 --> 00:08:57.520
And notice the model
kind of follows my lead.

00:08:57.520 --> 00:09:01.170
And it draws rain
like I did, right?

00:09:01.170 --> 00:09:02.675
Or-- and this is my favorite.

00:09:02.675 --> 00:09:05.050
When David did this for me,
I thought it was pretty cool.

00:09:05.050 --> 00:09:08.330
If you draw a cloud,
right, in your mind's eye,

00:09:08.330 --> 00:09:11.360
what's going to happen
when I let that cloud go?

00:09:11.360 --> 00:09:13.324
It's going to rain, right?

00:09:13.324 --> 00:09:14.490
I just think that's so cool.

00:09:14.490 --> 00:09:17.780
[APPLAUSE]

00:09:20.140 --> 00:09:23.540
And I also like some of the
more complicated drawings.

00:09:23.540 --> 00:09:26.270
Like, I actually don't know
how to draw a cruise ship.

00:09:26.270 --> 00:09:28.960
I've never actually been on
a cruise ship, I don't think.

00:09:28.960 --> 00:09:31.020
And I don't want food poisoning.

00:09:31.020 --> 00:09:32.997
And there's-- so
I'll just do that.

00:09:32.997 --> 00:09:35.330
And then Quick Draw will fill
it in with different kinds

00:09:35.330 --> 00:09:39.240
of cruise ships-- or
Sketch-RNN based on Quick Draw.

00:09:39.240 --> 00:09:40.830
So that's kind of fun too.

00:09:40.830 --> 00:09:42.570
And finally, let's do one more.

00:09:42.570 --> 00:09:45.070
It's fun to use that
time on these demos.

00:09:45.070 --> 00:09:47.140
We can't leave without a cat.

00:09:47.140 --> 00:09:51.180
And so I'm going to show you
what this temperature dial does

00:09:51.180 --> 00:09:51.750
down here.

00:09:51.750 --> 00:09:53.440
We're sampling from this model.

00:09:53.440 --> 00:09:55.550
So we have this
Zed, and we're going

00:09:55.550 --> 00:09:58.170
to use a little bit of math
to draw a new version of Zed

00:09:58.170 --> 00:09:59.630
and then generate from it.

00:09:59.630 --> 00:10:01.230
And we can actually
change a parameter

00:10:01.230 --> 00:10:04.061
that makes the drawings follow
lower probabilities instead

00:10:04.061 --> 00:10:05.060
of higher probabilities.

00:10:05.060 --> 00:10:07.220
So we can kind of flatten
out the probabilities.

00:10:07.220 --> 00:10:09.510
And that makes it seem like the
temperature's been turned up,

00:10:09.510 --> 00:10:10.400
like it's a little hotter.

00:10:10.400 --> 00:10:11.980
It's a little bit
less predictable.

00:10:11.980 --> 00:10:13.210
So if I draw--

00:10:13.210 --> 00:10:16.540
at low temperature, if
I draw my best cat--

00:10:16.540 --> 00:10:20.160
I'll just give
myself two cat ears--

00:10:20.160 --> 00:10:23.600
the model should draw some
nice, round cat faces,

00:10:23.600 --> 00:10:25.674
and maybe even draw some
whiskers if we're lucky.

00:10:25.674 --> 00:10:27.840
Yeah, you're kind of getting
archetypical cats there

00:10:27.840 --> 00:10:29.520
at low temperature.

00:10:29.520 --> 00:10:32.510
Now, I can control this
with this temperature

00:10:32.510 --> 00:10:33.740
and turn it up a little bit.

00:10:33.740 --> 00:10:38.080
And we'll start to see the
cat looking a little bit

00:10:38.080 --> 00:10:39.010
less round.

00:10:39.010 --> 00:10:42.340
So that looks like the cat that
I draw, the one in the middle.

00:10:42.340 --> 00:10:45.520
I was always given-- you
know, like at art time,

00:10:45.520 --> 00:10:47.520
they were sending you off
to play with the piano

00:10:47.520 --> 00:10:48.478
or something like that.

00:10:48.478 --> 00:10:49.565
This is not my area.

00:10:49.565 --> 00:10:51.440
OK, can we switch back
to the slides, please?

00:10:51.440 --> 00:10:53.710
That's the demo for Sketch-RNN.

00:10:57.220 --> 00:11:00.150
It's also fun just to see
samples from this model.

00:11:00.150 --> 00:11:02.310
Here we sampled
unconditionally, just

00:11:02.310 --> 00:11:04.720
drew samples from the model
at different temperatures.

00:11:04.720 --> 00:11:06.975
So is the color
of the icons get--

00:11:06.975 --> 00:11:08.680
as the color of the
art gets more red,

00:11:08.680 --> 00:11:10.763
that indicates that it's
sampled at a higher, kind

00:11:10.763 --> 00:11:12.070
of crazier temperature.

00:11:12.070 --> 00:11:15.490
And even in these fast talks,
it's fun to just kind of look

00:11:15.490 --> 00:11:17.194
at this art.

00:11:17.194 --> 00:11:18.610
The low temperature
ones, I think,

00:11:18.610 --> 00:11:23.932
are really nice, simple views
of how people draw yoga.

00:11:23.932 --> 00:11:26.390
You can actually try to recreate
some of these if you want,

00:11:26.390 --> 00:11:27.750
and probably get away with it.

00:11:27.750 --> 00:11:29.749
But don't try the high
temperature ones at home.

00:11:29.749 --> 00:11:33.135
Hot yoga is dangerous.

00:11:33.135 --> 00:11:35.010
I mean, they're just
really funny to look at.

00:11:35.010 --> 00:11:38.490
So it's fun to sample from
the model unconditionally,

00:11:38.490 --> 00:11:41.012
and it's also fun to do
conditional generation.

00:11:41.012 --> 00:11:41.970
This is very different.

00:11:41.970 --> 00:11:43.969
Now what we're doing is
we're taking a drawing--

00:11:43.969 --> 00:11:46.710
those four drawings on the
left were done by David.

00:11:46.710 --> 00:11:50.180
And we ran them through
the model and decoded them.

00:11:50.180 --> 00:11:52.410
So you see, on the right,
the reconstructions.

00:11:52.410 --> 00:11:55.540
But we remembered the Zeds
in the middle, the Zs,

00:11:55.540 --> 00:11:56.680
out latent space.

00:11:56.680 --> 00:11:59.790
And now we can just interpolate
through our latent space

00:11:59.790 --> 00:12:02.380
and generate drawings
for all of the spaces

00:12:02.380 --> 00:12:03.570
that we don't know about.

00:12:03.570 --> 00:12:05.954
And I think it's quite good
the way the model moves

00:12:05.954 --> 00:12:07.120
from these different shapes.

00:12:07.120 --> 00:12:11.177
So each of those reconstructions
are in the corners.

00:12:11.177 --> 00:12:13.010
And the color is following
the color mapping

00:12:13.010 --> 00:12:13.886
between those colors.

00:12:13.886 --> 00:12:15.301
And you get an
idea that the model

00:12:15.301 --> 00:12:16.850
has a nice, smooth
representation

00:12:16.850 --> 00:12:19.852
of how faces are drawn.

00:12:19.852 --> 00:12:21.810
Also, I want to point
out that the model is not

00:12:21.810 --> 00:12:23.250
memorizing data.

00:12:23.250 --> 00:12:26.230
We purposely restrict the
size of the representation

00:12:26.230 --> 00:12:28.889
to force it to generalize, and
we had a little bit of noise.

00:12:28.889 --> 00:12:29.930
And I think this is cool.

00:12:29.930 --> 00:12:30.790
It's a benefit.

00:12:30.790 --> 00:12:33.670
So for example, if you
look on the left-hand side,

00:12:33.670 --> 00:12:35.440
the human drawings
that are basically

00:12:35.440 --> 00:12:38.550
good examples of the
class cat are more or less

00:12:38.550 --> 00:12:40.230
reproduced by the model.

00:12:40.230 --> 00:12:44.160
On the right, we drew
an eight-legged pig,

00:12:44.160 --> 00:12:46.722
which is reconstructed
as a four-legged pig.

00:12:46.722 --> 00:12:48.680
Because that's what the
model knows about pigs.

00:12:48.680 --> 00:12:50.665
It knows that pigs
have four legs--

00:12:50.665 --> 00:12:52.290
before you call me
out for some version

00:12:52.290 --> 00:12:54.250
of "nose," for some version of
"pigs," and for some version

00:12:54.250 --> 00:12:55.100
of "four legs."

00:12:55.100 --> 00:12:57.360
Also, if you draw a truck
and pass it through the pig

00:12:57.360 --> 00:13:00.200
classifier, you get kind of
a pig truck, which I think

00:13:00.200 --> 00:13:01.200
is really cool.

00:13:01.200 --> 00:13:04.060
Like, if you were asked
to draw a pig truck,

00:13:04.060 --> 00:13:05.910
could you do a
better job than that?

00:13:05.910 --> 00:13:07.860
That's really good, right?

00:13:07.860 --> 00:13:09.660
Three-eyed cats,
they don't exist.

00:13:09.660 --> 00:13:11.090
There's no chakra for our cats.

00:13:11.090 --> 00:13:13.631
And if you do something like
run a toothbrush through the cat

00:13:13.631 --> 00:13:15.326
classifier, you don't get a cat.

00:13:15.326 --> 00:13:16.450
You don't get a toothbrush.

00:13:16.450 --> 00:13:17.533
You kind of get gibberish.

00:13:17.533 --> 00:13:20.480
So the model really is honing
in on something about drawing.

00:13:20.480 --> 00:13:21.660
So that's a lot of fun.

00:13:21.660 --> 00:13:23.701
I foresee a lot of possible
creative applications

00:13:23.701 --> 00:13:25.090
of this going forward.

00:13:25.090 --> 00:13:27.880
Lovely if people want
to hack our code.

00:13:27.880 --> 00:13:29.100
Oh, this is the last thing.

00:13:29.100 --> 00:13:31.087
If you're into math,
if you're math geek,

00:13:31.087 --> 00:13:32.170
just look at this formula.

00:13:32.170 --> 00:13:33.370
Do the algebra.

00:13:33.370 --> 00:13:35.095
This is math done
on the embeddings.

00:13:35.095 --> 00:13:36.470
I'm not even going
to explain it.

00:13:36.470 --> 00:13:37.447
Just look at it.

00:13:43.280 --> 00:13:43.780
[APPLAUSE]

00:13:43.780 --> 00:13:46.000
Yeah, wait long
enough, they applaud.

00:13:46.000 --> 00:13:47.390
It's pretty cool, right?

00:13:50.570 --> 00:13:52.836
So I love the idea that
the space is well enough

00:13:52.836 --> 00:13:54.210
conditioned that
you can actually

00:13:54.210 --> 00:13:55.920
move around numerically
in the space

00:13:55.920 --> 00:13:57.850
and get meaningful results.

00:13:57.850 --> 00:14:00.900
You can build pig heads from
pig bodies and subtractions

00:14:00.900 --> 00:14:03.010
of cat heads and cat
bodies, et cetera.

00:14:03.010 --> 00:14:05.130
No pigs were harmed.

00:14:05.130 --> 00:14:07.320
OK, I'm going to move on
to project number two.

00:14:07.320 --> 00:14:08.820
Project number two
is called NSynth.

00:14:08.820 --> 00:14:13.520
We also released this this
week, or some part of it.

00:14:13.520 --> 00:14:15.950
And what we wanted to do was
learn a music synthesizer.

00:14:15.950 --> 00:14:18.930
We wanted to actually make
new sounds and sounds that

00:14:18.930 --> 00:14:21.890
have captured some of
the underlying richness

00:14:21.890 --> 00:14:23.780
and variance of musical
sounds that we work

00:14:23.780 --> 00:14:25.620
with all the time as musicians.

00:14:25.620 --> 00:14:27.120
People have been
doing this forever.

00:14:27.120 --> 00:14:30.600
We're certainly not the only
use of software to make sounds.

00:14:30.600 --> 00:14:32.780
Here's an analog synthesizer--

00:14:32.780 --> 00:14:34.785
lots of knobs, fun to play with.

00:14:34.785 --> 00:14:36.410
We're trying to do
is use deep learning

00:14:36.410 --> 00:14:38.160
and see if we can get
a particular feeling

00:14:38.160 --> 00:14:41.550
and a particular
interpretability to the sounds

00:14:41.550 --> 00:14:43.020
that we're making.

00:14:43.020 --> 00:14:45.330
This work also, I want
to point out, is really,

00:14:45.330 --> 00:14:48.380
I thought, a great collaboration
between the Deep Mind

00:14:48.380 --> 00:14:53.167
team in London and the
Brain team in Mountain View.

00:14:53.167 --> 00:14:55.750
Sandra Dieleman was one of the
authors on the original WaveNet

00:14:55.750 --> 00:14:57.458
paper, which I'll talk
about in a second.

00:14:57.458 --> 00:14:59.300
He was a fantastic
collaborator with us.

00:14:59.300 --> 00:15:01.466
And this project would not
have happened without it.

00:15:01.466 --> 00:15:05.540
And I love that kind
of cross-collaboration.

00:15:05.540 --> 00:15:08.720
So in terms of what you can
learn outside of this talk,

00:15:08.720 --> 00:15:12.990
we have two postings on our
blog at magenta.tensorflow.org

00:15:12.990 --> 00:15:15.659
that point to this really
wonderful AI experiment that

00:15:15.659 --> 00:15:17.200
came from Creative
Lab that I'm going

00:15:17.200 --> 00:15:18.610
to show you in a few minutes.

00:15:18.610 --> 00:15:20.260
And we also-- for those of you--

00:15:20.260 --> 00:15:23.710
all right, show of hands, who
knows what Ableton Live is?

00:15:23.710 --> 00:15:25.740
All right, all of
you might consider

00:15:25.740 --> 00:15:27.454
going to our open
source and downloading

00:15:27.454 --> 00:15:28.620
the plugin for Ableton Live.

00:15:28.620 --> 00:15:32.320
And you can drive your own
music with these samples.

00:15:32.320 --> 00:15:32.820
It's fun.

00:15:32.820 --> 00:15:33.410
It's cool.

00:15:33.410 --> 00:15:35.120
So give that a look.

00:15:35.120 --> 00:15:36.752
All right, so
first, to understand

00:15:36.752 --> 00:15:38.960
what we're trying to do,
let's look back at the paper

00:15:38.960 --> 00:15:40.850
from last year called WaveNet.

00:15:40.850 --> 00:15:42.330
It's a paper that's
trying to learn

00:15:42.330 --> 00:15:44.070
to generate audio from audio.

00:15:44.070 --> 00:15:47.530
It's actually learning on the
raw PCM, Pulse-Code Modulation,

00:15:47.530 --> 00:15:52.530
the raw speaker cone position
sampled 16,000 times a second.

00:15:52.530 --> 00:15:55.370
And it's trying to predict
the next sample conditioned

00:15:55.370 --> 00:15:57.705
on about the last two
seconds of samples.

00:15:57.705 --> 00:16:00.080
And what it uses is something
called dilated convolution.

00:16:00.080 --> 00:16:01.580
So you see the arrows.

00:16:01.580 --> 00:16:03.810
They get spread further
and further apart.

00:16:03.810 --> 00:16:06.070
It's almost like they're
being dilated in time so

00:16:06.070 --> 00:16:08.890
that the next prediction
is conditioned

00:16:08.890 --> 00:16:11.240
not only on the
sample that came last,

00:16:11.240 --> 00:16:14.294
but some samples, or some
representations of samples,

00:16:14.294 --> 00:16:16.210
that happened further
and further in the past.

00:16:16.210 --> 00:16:20.250
And this allows WaveNet to be
able to make predictions that

00:16:20.250 --> 00:16:23.040
have a little bit of coherence.

00:16:23.040 --> 00:16:25.680
However there are some
limitations to this coherence.

00:16:25.680 --> 00:16:27.450
Because the model
doesn't have anything

00:16:27.450 --> 00:16:30.190
to condition it to allow
it to be more stable,

00:16:30.190 --> 00:16:32.770
it really has a hard
time doing something

00:16:32.770 --> 00:16:35.880
that is coherent over
more than about maybe

00:16:35.880 --> 00:16:38.240
a fourth to a half of a second.

00:16:38.240 --> 00:16:40.345
So let's play Dizzy, please.

00:16:43.000 --> 00:16:46.360
[MUSIC PLAYING]

00:16:52.620 --> 00:16:55.634
The model's learning to
play Dizzy Gillespie trained

00:16:55.634 --> 00:16:57.800
on Dizzy Gillespie only and
get something out of it.

00:16:57.800 --> 00:17:00.502
Let's play Metallica.

00:17:00.502 --> 00:17:03.918
[MUSIC PLAYING]

00:17:11.730 --> 00:17:14.069
And then, in the
bottom, we trained

00:17:14.069 --> 00:17:17.060
on individual musical notes
from a data set that we released

00:17:17.060 --> 00:17:18.740
in open source called NSynth.

00:17:18.740 --> 00:17:19.650
The whole project's
called NSynth,

00:17:19.650 --> 00:17:22.275
and so is the data set, because
we wanted to confuse everybody.

00:17:22.275 --> 00:17:26.510
And so the model sees only
individual musical notes.

00:17:26.510 --> 00:17:28.089
And if it's trained--

00:17:28.089 --> 00:17:30.040
if a WaveNet is
trained on this data,

00:17:30.040 --> 00:17:33.210
it's not quite capable of
producing a single note.

00:17:33.210 --> 00:17:33.970
It wanders around.

00:17:33.970 --> 00:17:35.220
So please play the second one.

00:17:38.630 --> 00:17:42.060
[HIGH SUSTAINED NOTE]

00:17:46.412 --> 00:17:48.120
It's definitely learning
about harmonics.

00:17:48.120 --> 00:17:49.060
Let's go ahead and
play the first one too.

00:17:49.060 --> 00:17:50.360
It's fun.

00:17:50.360 --> 00:17:53.674
[LOW NOTE]

00:17:53.674 --> 00:17:55.570
[DEEP BASS]

00:17:55.570 --> 00:17:56.880
I like that bass.

00:17:56.880 --> 00:18:00.370
So what we see is that the
NSynth data trained on WaveNet

00:18:00.370 --> 00:18:02.220
alone does some cool things.

00:18:02.220 --> 00:18:03.980
But it doesn't give
us our desired goal,

00:18:03.980 --> 00:18:06.720
which is to have
coherent musical notes.

00:18:06.720 --> 00:18:10.250
So what we decided to do
was add an autoencoder

00:18:10.250 --> 00:18:12.350
to WaveNet so that we
can constrain and help

00:18:12.350 --> 00:18:15.860
it understand how sound
is unfolding in time.

00:18:15.860 --> 00:18:18.640
So this basic diagram
should look familiar.

00:18:18.640 --> 00:18:19.640
You have some input.

00:18:19.640 --> 00:18:23.360
Now it's not a cat or a
pig, it's an input waveform.

00:18:23.360 --> 00:18:25.337
We're going to
encode that in time

00:18:25.337 --> 00:18:27.670
using a kind of convolutional
model that's not a WaveNet

00:18:27.670 --> 00:18:31.210
but is also using deep
dilated convolutions.

00:18:31.210 --> 00:18:33.315
That's going to give us
some sort of embedding.

00:18:33.315 --> 00:18:35.690
And in this case, the embedding
actually unfolds in time.

00:18:35.690 --> 00:18:40.055
So it's 16 values that change
every few milliseconds.

00:18:40.055 --> 00:18:41.680
And then, we're going
to have a WaveNet

00:18:41.680 --> 00:18:43.926
decoder, the same
WaveNet that we just saw.

00:18:43.926 --> 00:18:45.300
And the WaveNet
is actually going

00:18:45.300 --> 00:18:47.520
to have the input audio
available when it's training.

00:18:47.520 --> 00:18:50.620
But it's also going to see
this conditioning information

00:18:50.620 --> 00:18:51.660
from our Zed.

00:18:51.660 --> 00:18:54.230
And if it wants to take
advantage of it, it can.

00:18:54.230 --> 00:18:56.560
And in fact, it does,
to great effect.

00:18:56.560 --> 00:18:59.700
So now what we can do is
encode an entire note,

00:18:59.700 --> 00:19:01.100
and we can then decode from it.

00:19:01.100 --> 00:19:04.720
So let's listen to
the original bass.

00:19:04.720 --> 00:19:06.151
[BASS NOTE]

00:19:06.151 --> 00:19:08.139
Now, if we run that
bass through our model

00:19:08.139 --> 00:19:09.680
and decode it in
the same way that we

00:19:09.680 --> 00:19:12.020
ran the cat through our
model and looked at the cat,

00:19:12.020 --> 00:19:15.220
it sounds like the
bass on the bottom.

00:19:15.220 --> 00:19:16.564
[BASS NOTE]

00:19:16.564 --> 00:19:18.230
So it's hard to hear
with the fan noise.

00:19:18.230 --> 00:19:19.580
It's a little bit distorted.

00:19:19.580 --> 00:19:20.740
Sometimes we get clicks.

00:19:20.740 --> 00:19:23.410
But more or less, it captures
the sound of the bass.

00:19:23.410 --> 00:19:26.760
Now let's hear the
original flute.

00:19:26.760 --> 00:19:29.778
[FLUTE NOTE]

00:19:29.778 --> 00:19:32.484
And now let's hear
the WaveNet flute.

00:19:32.484 --> 00:19:35.436
[FLUTE NOTE]

00:19:35.436 --> 00:19:36.255
So it's close.

00:19:36.255 --> 00:19:37.730
So now you're
asking, why would you

00:19:37.730 --> 00:19:41.090
want to reconstruct noisy
versions of these samples?

00:19:41.090 --> 00:19:44.180
Because now, because we're
living in this embedding space,

00:19:44.180 --> 00:19:46.160
we have this reduced
representation,

00:19:46.160 --> 00:19:48.640
we can do exactly what we did
with the images of the cats

00:19:48.640 --> 00:19:49.890
or the images of the people.

00:19:49.890 --> 00:19:52.810
We can move between
sounds we know and listen

00:19:52.810 --> 00:19:55.810
to what the model does in
spaces that we don't know.

00:19:55.810 --> 00:19:59.390
So let's listen to what bass
and flute sounds like, original.

00:19:59.390 --> 00:20:02.500
[BASS AND FLUTE]

00:20:02.500 --> 00:20:04.640
It sounds like a bass
and a flute, right?

00:20:04.640 --> 00:20:05.800
That's what the average is.

00:20:05.800 --> 00:20:07.383
You just average the
signals together.

00:20:07.383 --> 00:20:10.520
Now let's listen to bass
and flute from NSynth.

00:20:10.520 --> 00:20:14.088
[BASS AND FLUTE]

00:20:14.088 --> 00:20:16.130
Let's play that again.

00:20:16.130 --> 00:20:20.710
[BASS AND FLUTE]

00:20:20.710 --> 00:20:23.320
I invite you to go to our blog
and listen to the examples

00:20:23.320 --> 00:20:24.510
there with headphones.

00:20:24.510 --> 00:20:26.280
But what it does,
in my mind's eye,

00:20:26.280 --> 00:20:30.170
is makes a really big
bass flute, right?

00:20:30.170 --> 00:20:32.342
Like physically, that's
what it sounds like.

00:20:32.342 --> 00:20:33.800
In the interest of
time, let's just

00:20:33.800 --> 00:20:37.261
go ahead and play
flute plus organ.

00:20:37.261 --> 00:20:40.392
[FLUTE AND ORGAN]

00:20:40.392 --> 00:20:42.850
I think even without hearing
the organ, you kind of get it.

00:20:42.850 --> 00:20:44.920
And let's hear flute
plus organ from NSynth.

00:20:44.920 --> 00:20:48.672
[FLUTE AND ORGAN]

00:20:48.672 --> 00:20:50.380
Again, it kind of
grabbed the flute sound

00:20:50.380 --> 00:20:52.840
and modulated it with
an organ-like sound.

00:20:52.840 --> 00:20:56.910
I'm going to move on from these
now, in the interest of time.

00:20:56.910 --> 00:20:58.920
These are what the
embeddings look like.

00:20:58.920 --> 00:21:01.520
So I told you these are
temporal embeddings.

00:21:01.520 --> 00:21:03.120
They actually unfold in time.

00:21:03.120 --> 00:21:05.250
And there are 16 of
them, so we gave each one

00:21:05.250 --> 00:21:06.075
a different color.

00:21:06.075 --> 00:21:08.200
And then, now, we're looking
at bass, glockenspiel,

00:21:08.200 --> 00:21:10.450
and flugelhorn, column-wise.

00:21:10.450 --> 00:21:12.459
And you're seeing
the original waveform

00:21:12.459 --> 00:21:14.375
shown in a kind of special
spectral reputation

00:21:14.375 --> 00:21:16.387
where time unfolds
left to right.

00:21:16.387 --> 00:21:17.970
And then, you're
seeing the embeddings

00:21:17.970 --> 00:21:20.452
that were used to generate
the reconstructions.

00:21:20.452 --> 00:21:22.160
I wanted just to give
you this basic idea

00:21:22.160 --> 00:21:25.310
that what we're really providing
are those embeddings, those 16

00:21:25.310 --> 00:21:26.735
values changing over time.

00:21:26.735 --> 00:21:28.110
And then, the
WaveNet is learning

00:21:28.110 --> 00:21:31.420
how to take advantage of them.

00:21:31.420 --> 00:21:32.170
Now, let's go to--

00:21:32.170 --> 00:21:34.330
I'm going to go to-- please
switch to the demo again, demo

00:21:34.330 --> 00:21:35.100
computer, please.

00:21:44.930 --> 00:21:48.660
OK, so the Creative
Lab team also

00:21:48.660 --> 00:21:50.530
just released this
NSynth music instrument.

00:21:50.530 --> 00:21:53.380
You can play with it online.

00:21:53.380 --> 00:21:55.870
We have a link to
it from our blog.

00:21:55.870 --> 00:21:57.311
You can also get at it--

00:21:57.311 --> 00:21:59.060
oh, I'm sorry, what I
see up on the screen

00:21:59.060 --> 00:21:59.952
is our internal link.

00:21:59.952 --> 00:22:01.160
You'll find it from our blog.

00:22:01.160 --> 00:22:01.909
It's easy to find.

00:22:01.909 --> 00:22:03.791
Look for NSynth Sound Maker.

00:22:03.791 --> 00:22:05.540
And here, you can play
with this yourself.

00:22:05.540 --> 00:22:06.040
So--

00:22:06.040 --> 00:22:09.500
[PLAYING NOTES]

00:22:09.500 --> 00:22:11.282
--that's our bass
reconstruction.

00:22:11.282 --> 00:22:13.740
Compare that to the original
upright bass by clicking here.

00:22:13.740 --> 00:22:16.420
[UPRIGHT BASS]

00:22:16.420 --> 00:22:17.580
And here's a clarinet.

00:22:17.580 --> 00:22:19.476
[CLARINET]

00:22:19.476 --> 00:22:21.560
And then, we can move
through the space and--

00:22:21.560 --> 00:22:26.250
[PLAYING NOTES]

00:22:26.250 --> 00:22:29.920
--we can sit in areas
that are blending

00:22:29.920 --> 00:22:33.110
the clarinet and the bass in,
I think, interesting ways.

00:22:33.110 --> 00:22:34.740
They're not all
beautiful, but they're

00:22:34.740 --> 00:22:35.745
all kind of interesting.

00:22:35.745 --> 00:22:36.370
[PLAYING NOTES]

00:22:36.370 --> 00:22:37.170
We can try different samples.

00:22:37.170 --> 00:22:38.150
I love this interface.

00:22:38.150 --> 00:22:40.000
Again, cheers to the
Creative Lab team.

00:22:40.000 --> 00:22:40.620
[GOOSE]

00:22:40.620 --> 00:22:41.510
[COW]

00:22:41.510 --> 00:22:43.164
We can do a cow.

00:22:43.164 --> 00:22:43.844
[THUNDER]

00:22:43.844 --> 00:22:45.135
I didn't mean to move past cow.

00:22:45.135 --> 00:22:46.430
Who would want to do that?

00:22:46.430 --> 00:22:48.470
So we have a cow.

00:22:48.470 --> 00:22:50.050
Let's do a vibraphone cow.

00:22:50.050 --> 00:22:52.510
So here's our cow.

00:22:52.510 --> 00:22:54.861
[COW]

00:22:54.861 --> 00:22:55.360
Right?

00:22:55.360 --> 00:22:56.930
There's our cow.

00:22:56.930 --> 00:22:57.544
[COW]

00:22:57.544 --> 00:22:58.960
Yeah, you're
clapping, aren't you?

00:22:58.960 --> 00:23:00.790
Because you know this is why--

00:23:00.790 --> 00:23:03.280
they pay us to do this work.

00:23:03.280 --> 00:23:05.840
I just want to point that
out, that we get paid.

00:23:05.840 --> 00:23:07.256
[APPLAUSE]

00:23:07.256 --> 00:23:08.760
[PLAYING NOTES]

00:23:08.760 --> 00:23:11.266
And now we bring
the vibraphone in.

00:23:11.266 --> 00:23:14.239
And we've actually got a really
interesting sound, right?

00:23:14.239 --> 00:23:16.530
Like, it's getting it's
pitchiness from the vibraphone,

00:23:16.530 --> 00:23:18.930
but it's totally
modulated by cow.

00:23:18.930 --> 00:23:20.490
So you have this cow modulator.

00:23:20.490 --> 00:23:24.124
So I invite you to lose--

00:23:24.124 --> 00:23:26.760
if you have an auditory
system that works at all,

00:23:26.760 --> 00:23:28.440
I promise you, you
can lose easily

00:23:28.440 --> 00:23:30.398
an hour by just throwing
on a set of headphones

00:23:30.398 --> 00:23:34.270
and playing around with this,
unless you're "Hacker News."

00:23:34.270 --> 00:23:37.140
And then, you're negative about
everything, but that's OK.

00:23:37.140 --> 00:23:42.347
Let's go back to the
slides again, please.

00:23:42.347 --> 00:23:44.180
We also released a data
set for those of you

00:23:44.180 --> 00:23:46.750
that want of your machine
learning yourself.

00:23:46.750 --> 00:23:50.310
We have about 300,000
individual instrument sounds

00:23:50.310 --> 00:23:53.050
that we generated from different
sample packs everywhere.

00:23:53.050 --> 00:23:54.770
And we also released
them in a format

00:23:54.770 --> 00:23:57.020
that has a bunch of the
metadata attached to it.

00:23:57.020 --> 00:23:59.020
So you can know
what the genre was,

00:23:59.020 --> 00:24:01.470
some of the note-like qualities
like bright, and dark,

00:24:01.470 --> 00:24:02.490
and multiphonic.

00:24:02.490 --> 00:24:04.320
And so this opens the
door for doing things

00:24:04.320 --> 00:24:06.387
like training conditional
models, models that

00:24:06.387 --> 00:24:08.220
know about these values,
so you can use them

00:24:08.220 --> 00:24:11.410
to condition your generation.

00:24:11.410 --> 00:24:13.220
You can use these for
anything you want to.

00:24:13.220 --> 00:24:14.720
Add it's out there
and open source.

00:24:14.720 --> 00:24:16.450
And we hope that it
fuels more research

00:24:16.450 --> 00:24:19.290
in music-related deep learning.

00:24:19.290 --> 00:24:22.130
I want to close now and have
plenty of time for questions.

00:24:22.130 --> 00:24:23.380
I'm in love with this quote.

00:24:23.380 --> 00:24:25.021
Who's heard of Brian Eno?

00:24:25.021 --> 00:24:26.270
If you didn't raise your hand.

00:24:26.270 --> 00:24:30.520
Homework-- go learn about
Brain Eno, fantastic musician.

00:24:30.520 --> 00:24:32.487
And I just think this
captures what we're

00:24:32.487 --> 00:24:33.570
trying to do with Magenta.

00:24:33.570 --> 00:24:35.778
I like it so much that I'm
actually going to read it.

00:24:35.778 --> 00:24:39.020
"Whatever you now find weird,
ugly, uncomfortable, and nasty

00:24:39.020 --> 00:24:42.250
about a new medium will
surely become its signature.

00:24:42.250 --> 00:24:45.280
CD distortion, the
jitteriness of digital video,

00:24:45.280 --> 00:24:47.090
the crap sound of 8-bit--

00:24:47.090 --> 00:24:49.950
the distorted guitar sound
is the sound of something

00:24:49.950 --> 00:24:53.200
too loud for the medium
supposed to carry it."

00:24:53.200 --> 00:24:54.610
And I love that thought.

00:24:54.610 --> 00:24:56.810
I love the idea of trying
to build a new medium

00:24:56.810 --> 00:24:59.170
with the understanding
that it's a medium that's

00:24:59.170 --> 00:25:00.150
meant to be broken.

00:25:00.150 --> 00:25:01.710
Like, we want
artists and musicians

00:25:01.710 --> 00:25:04.409
to try to break these things, to
try to do new things with them.

00:25:04.409 --> 00:25:06.450
And I think that's a really
wonderful interaction

00:25:06.450 --> 00:25:08.320
between technology and art.

00:25:08.320 --> 00:25:11.932
And it's one that I think
is just, A, it's fun, and B,

00:25:11.932 --> 00:25:12.641
it's cool, right?

00:25:12.641 --> 00:25:14.140
I don't know what
to say, all right?

00:25:14.140 --> 00:25:15.770
So there's your
quote to close with.

00:25:15.770 --> 00:25:16.860
Here's my call to action.

00:25:16.860 --> 00:25:17.640
What can you do?

00:25:17.640 --> 00:25:21.320
Have a look at TensorFlow,
magenta.tensorflow.org.

00:25:21.320 --> 00:25:22.376
There's our blog.

00:25:22.376 --> 00:25:24.250
There's our data,
discussion lists in GitHub.

00:25:24.250 --> 00:25:26.160
You'll also find links
off to the great work

00:25:26.160 --> 00:25:28.769
by Creative Lab, including
links to the data sets.

00:25:28.769 --> 00:25:31.060
Or you just look on Reddit,
and you'll find them there.

00:25:31.060 --> 00:25:34.210
And now, I managed to actually
save some time for questions.

00:25:34.210 --> 00:25:35.610
So I hope you have questions.

00:25:35.610 --> 00:25:36.200
I'm going to stop here.

00:25:36.200 --> 00:25:38.330
And I thank you very much for
your attention on a hot Friday

00:25:38.330 --> 00:25:38.830
afternoon.

00:25:38.830 --> 00:25:40.730
[APPLAUSE]

00:25:41.930 --> 00:25:45.280
[MUSIC PLAYING]

