WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.868
[MUSIC PLAYING]

00:00:06.080 --> 00:00:07.750
DAVID CHALMERS:
Thanks for coming out.

00:00:07.750 --> 00:00:09.490
It's good to be here.

00:00:09.490 --> 00:00:15.500
As Eric said, I am a philosopher
thinking about consciousness.

00:00:15.500 --> 00:00:19.640
Coming from a background
in the sciences and math,

00:00:19.640 --> 00:00:25.010
it always struck me that the
most interesting and hardest

00:00:25.010 --> 00:00:27.560
unsolved problem
in the sciences was

00:00:27.560 --> 00:00:29.690
the problem of consciousness.

00:00:29.690 --> 00:00:34.200
And way back 25 years ago
when I was in grad school,

00:00:34.200 --> 00:00:37.490
it seemed to be the
best way to come at this

00:00:37.490 --> 00:00:40.520
from a big picture perspective
was to go into philosophy

00:00:40.520 --> 00:00:43.960
and think about the foundational
issues that arise in thinking

00:00:43.960 --> 00:00:46.440
about consciousness from any
number of different angles,

00:00:46.440 --> 00:00:48.320
including the angles
of neuroscience

00:00:48.320 --> 00:00:52.093
and psychology and AI.

00:00:52.093 --> 00:00:53.510
In this talk, I'm
going to present

00:00:53.510 --> 00:00:55.730
a slightly different
perspective on the problem

00:00:55.730 --> 00:00:58.100
after laying out some
background, the perspective

00:00:58.100 --> 00:01:03.830
of what I call the
meta-problem of consciousness.

00:01:03.830 --> 00:01:06.080
I always liked the idea
that you approach a problem

00:01:06.080 --> 00:01:11.330
by stepping one level up,
taking the metaperspective.

00:01:11.330 --> 00:01:15.660
I love this quote, "Anything
you can do, I can do meta."

00:01:15.660 --> 00:01:17.593
I have no idea what
the origins was.

00:01:17.593 --> 00:01:19.010
I like the fact
this is attributed

00:01:19.010 --> 00:01:21.932
to Rudolf Carnap, one of
my favorite philosophers.

00:01:21.932 --> 00:01:23.390
But anyone who
knows Carnap's work,

00:01:23.390 --> 00:01:25.280
it's completely
implausible he would ever

00:01:25.280 --> 00:01:26.790
say anything so frivolous.

00:01:26.790 --> 00:01:29.300
It's also being attributed
to my thesis advisor, Doug

00:01:29.300 --> 00:01:31.580
Hofstadter, author of
"Godel, Escher, Bach"

00:01:31.580 --> 00:01:34.880
and a big fan of
the metaperspective.

00:01:34.880 --> 00:01:38.370
But he assures me he
never said it either.

00:01:38.370 --> 00:01:40.550
But the metaperspective
on anything

00:01:40.550 --> 00:01:43.700
is stepping up a level.

00:01:43.700 --> 00:01:46.490
The meta-problem,
as I think about it,

00:01:46.490 --> 00:01:48.650
is it's called the
meta-problem because it's

00:01:48.650 --> 00:01:50.900
a problem about a problem.

00:01:50.900 --> 00:01:53.620
A metatheory is a
theory about a theory.

00:01:53.620 --> 00:01:55.370
Meta-problem is a
problem about a problem.

00:01:55.370 --> 00:01:57.890
In particular, it's the
problem of explaining

00:01:57.890 --> 00:02:02.390
why we think there is a
problem about consciousness.

00:02:02.390 --> 00:02:03.780
So there's a
first-order problem,

00:02:03.780 --> 00:02:05.150
the problem of consciousness.

00:02:05.150 --> 00:02:07.460
Today, I'm going to focus
on a problem about it.

00:02:07.460 --> 00:02:12.000
But I'll start by introducing
the first-order problem itself.

00:02:12.000 --> 00:02:15.230
The first-order problem is
what we call the hard problem

00:02:15.230 --> 00:02:16.990
of consciousness.

00:02:16.990 --> 00:02:21.650
It's the problem of explaining
why and how physical processes

00:02:21.650 --> 00:02:27.740
should give rise to
conscious experience.

00:02:27.740 --> 00:02:31.340
You've got all of these
neurons firing in your brain,

00:02:31.340 --> 00:02:34.850
bringing about all kinds
of sophisticated behavior.

00:02:34.850 --> 00:02:37.280
We can get it to be
[INAUDIBLE] explaining

00:02:37.280 --> 00:02:39.003
our various
responses, but there's

00:02:39.003 --> 00:02:41.420
this big question about how
it feels from the first person

00:02:41.420 --> 00:02:42.200
point of view.

00:02:42.200 --> 00:02:44.360
That's the subjective
experience.

00:02:44.360 --> 00:02:47.150
I like this illustration of the
hard problem of consciousness.

00:02:47.150 --> 00:02:50.750
It seems to show someone's
hair catching fire,

00:02:50.750 --> 00:02:53.090
but I guess it's a
metaphorical illustration

00:02:53.090 --> 00:02:56.120
of the subjective perspective.

00:02:56.120 --> 00:02:58.460
So the hard problem is
concerned with what philosophers

00:02:58.460 --> 00:03:00.440
call phenomenal consciousness.

00:03:00.440 --> 00:03:03.740
The word consciousness
is ambiguous 1,000 ways.

00:03:03.740 --> 00:03:05.450
But phenomenal
consciousness is what

00:03:05.450 --> 00:03:09.170
it's like to be a subject from
the first person point of view.

00:03:09.170 --> 00:03:12.200
So a system is
phenomenally conscious

00:03:12.200 --> 00:03:14.120
if there's something
it's like to be it.

00:03:14.120 --> 00:03:16.850
A mental state is
phenomenally conscious

00:03:16.850 --> 00:03:18.770
if there's something
it's like to be in it.

00:03:18.770 --> 00:03:21.200
So the thought is there
are some systems--

00:03:21.200 --> 00:03:23.810
so there's something it's
like to be that system.

00:03:23.810 --> 00:03:26.160
There's something
it's like to be me.

00:03:26.160 --> 00:03:29.060
I presume there's something
it's like to be you.

00:03:29.060 --> 00:03:32.780
But presumably, there's nothing
it's like to be this lectern.

00:03:32.780 --> 00:03:36.500
As far as we know, the lectern
does not have a first person

00:03:36.500 --> 00:03:38.380
perspective.

00:03:38.380 --> 00:03:43.580
This phrase was made famous by
my colleague, Tom Nagel at NYU,

00:03:43.580 --> 00:03:47.120
who back in 1974 wrote an
article called "What Is It Like

00:03:47.120 --> 00:03:49.220
To Be A Bat?".

00:03:49.220 --> 00:03:51.260
And the general idea
was, well, it's very hard

00:03:51.260 --> 00:03:55.183
to know what it's like to be
a bat from the third person

00:03:55.183 --> 00:03:57.350
point of view, just looking
at it as a human who has

00:03:57.350 --> 00:03:59.000
different kinds of experience.

00:03:59.000 --> 00:04:00.800
But presumably, very
plausibly, there

00:04:00.800 --> 00:04:03.240
is something it's
like to be a bat.

00:04:03.240 --> 00:04:04.350
The bat is conscious.

00:04:04.350 --> 00:04:06.980
It's having subjective
experiences, just of a kind

00:04:06.980 --> 00:04:10.770
very different from ours.

00:04:10.770 --> 00:04:14.880
In human subjective
experience, consciousness

00:04:14.880 --> 00:04:19.180
divides into any number of
different kinds or aspects,

00:04:19.180 --> 00:04:23.320
like different tracks of the
inner movie of consciousness.

00:04:23.320 --> 00:04:26.790
We have visual experiences
like the experience of, say,

00:04:26.790 --> 00:04:31.830
these colors, blue and red and
green from the first person

00:04:31.830 --> 00:04:33.040
point of view and of depth.

00:04:33.040 --> 00:04:35.560
There are sensory experiences
like the experience

00:04:35.560 --> 00:04:40.370
of my voice, experiences
of taste and smell.

00:04:40.370 --> 00:04:42.660
They're experiences
of your body.

00:04:42.660 --> 00:04:47.370
Feeling pain or orgasms
or hunger or a tickle

00:04:47.370 --> 00:04:49.920
or something, they all have
some distinctive first person

00:04:49.920 --> 00:04:50.730
quality.

00:04:50.730 --> 00:04:54.300
Mental images like
recalled visual images,

00:04:54.300 --> 00:04:58.140
emotional experiences
like a experience

00:04:58.140 --> 00:04:59.408
of happiness or anger.

00:04:59.408 --> 00:05:01.200
And indeed, we all seem
to have this stream

00:05:01.200 --> 00:05:03.150
of a current thought
or at the very least,

00:05:03.150 --> 00:05:05.580
we're kind of chattering
away to ourselves

00:05:05.580 --> 00:05:07.620
and reflecting and deciding.

00:05:07.620 --> 00:05:11.280
All of these are aspects of
subjective experience, things

00:05:11.280 --> 00:05:15.130
we experience from the
first person point of view.

00:05:15.130 --> 00:05:19.030
And I think these
subjective experiences

00:05:19.030 --> 00:05:23.090
are, at least on
the face of it, data

00:05:23.090 --> 00:05:25.370
for the science of
consciousness to explain.

00:05:25.370 --> 00:05:27.710
These are just facts
about us that we're having

00:05:27.710 --> 00:05:29.570
these subjective experiences.

00:05:29.570 --> 00:05:31.880
If we ignore them,
we're ignoring the data.

00:05:31.880 --> 00:05:34.190
So if you catalog
the data that, say,

00:05:34.190 --> 00:05:36.317
the science of consciousness
needs to explain,

00:05:36.317 --> 00:05:38.150
there are certainly
facts about our behavior

00:05:38.150 --> 00:05:39.525
and how we respond
in situations.

00:05:39.525 --> 00:05:43.190
There are facts about
how our brain is working.

00:05:43.190 --> 00:05:45.995
There are also facts about
how subjective experiences,

00:05:45.995 --> 00:05:49.550
and on the face of
it, they're data.

00:05:49.550 --> 00:05:50.990
And it's these
data that pose what

00:05:50.990 --> 00:05:53.630
I call the hard problem
of consciousness.

00:05:53.630 --> 00:05:56.720
But this gets contrasted
with the easy problems,

00:05:56.720 --> 00:05:59.850
the so-called easy
problems of consciousness,

00:05:59.850 --> 00:06:02.570
which are the
problems of explaining

00:06:02.570 --> 00:06:06.560
behavioral and
cognitive functions.

00:06:06.560 --> 00:06:08.810
Objective things you can
measure from the third person

00:06:08.810 --> 00:06:11.630
point of view typically
tied to behavior.

00:06:11.630 --> 00:06:15.993
Perceptual discrimination
of a stimulus,

00:06:15.993 --> 00:06:18.410
I can discriminate two different
things in my environment.

00:06:18.410 --> 00:06:20.570
I can say, that's
red, and that's green.

00:06:20.570 --> 00:06:23.690
I can integrate the information
about the color and the shape.

00:06:23.690 --> 00:06:25.610
I can use it to
control my behavior.

00:06:25.610 --> 00:06:28.010
Walk towards the red one
rather than the green one.

00:06:28.010 --> 00:06:32.570
I can report it, say
that's red, and so on.

00:06:32.570 --> 00:06:36.400
Those are all data too
for science to explain.

00:06:36.400 --> 00:06:39.820
But we've got a bead on how
to explain though they don't

00:06:39.820 --> 00:06:42.450
seem to pose as big a problem.

00:06:42.450 --> 00:06:43.330
Why?

00:06:43.330 --> 00:06:47.380
We explain those easy
problems by finding

00:06:47.380 --> 00:06:51.760
a mechanism, typically a neural
or computational mechanism that

00:06:51.760 --> 00:06:55.630
performs the relevant
function to explain

00:06:55.630 --> 00:06:59.490
how it is that I get to say
there's a red thing over there

00:06:59.490 --> 00:07:00.360
or walk towards it.

00:07:00.360 --> 00:07:05.580
Well, you find the mechanisms
involving perceptual processes

00:07:05.580 --> 00:07:09.500
and action processes in my brain
that leads to that behavior.

00:07:09.500 --> 00:07:12.570
Find the right mechanism that
performs the function you've

00:07:12.570 --> 00:07:14.800
explained what needs
to be explained

00:07:14.800 --> 00:07:17.970
with the easy problems
of consciousness.

00:07:17.970 --> 00:07:20.940
But for the hard problem,
for subjective experience,

00:07:20.940 --> 00:07:25.260
it's just not clear that
this standard method works.

00:07:25.260 --> 00:07:28.260
It looks like explaining
all that behavior still

00:07:28.260 --> 00:07:30.900
leaves open a further question.

00:07:30.900 --> 00:07:34.170
Why does all that give
you subjective experience?

00:07:34.170 --> 00:07:40.290
Explain the reacting, the
responding, the controlling,

00:07:40.290 --> 00:07:43.083
the reporting, and so on.

00:07:43.083 --> 00:07:44.500
It still leaves
open the question,

00:07:44.500 --> 00:07:48.640
why is all that accompanied
by subjective experience.

00:07:48.640 --> 00:07:52.600
Why doesn't it go on in the
dark without consciousness,

00:07:52.600 --> 00:07:53.482
so to speak?

00:07:53.482 --> 00:07:55.690
There seems to be what the
philosopher Joe Levine has

00:07:55.690 --> 00:07:58.330
called a gap here,
an explanatory gap,

00:07:58.330 --> 00:08:01.060
between physical processes
and subjective experience.

00:08:01.060 --> 00:08:03.790
At least our standard
kinds of explanation,

00:08:03.790 --> 00:08:07.180
which work really well for
the easy problems of behavior

00:08:07.180 --> 00:08:09.970
and so on, don't obviously
give you a connection

00:08:09.970 --> 00:08:14.890
to the subjective
aspects of experience.

00:08:14.890 --> 00:08:17.560
And there's been a vast amount
of discussion of these things

00:08:17.560 --> 00:08:18.430
over--

00:08:18.430 --> 00:08:20.040
I mean, well, for
centuries, really.

00:08:20.040 --> 00:08:21.730
But it's been
particularly active

00:08:21.730 --> 00:08:24.910
in recent decades,
philosophers, scientists,

00:08:24.910 --> 00:08:27.400
all kinds of different views.

00:08:27.400 --> 00:08:30.790
Philosophically, you can divide
approaches to the hard problem

00:08:30.790 --> 00:08:33.070
into at least two classes.

00:08:33.070 --> 00:08:35.500
One is an approach on
which consciousness

00:08:35.500 --> 00:08:38.230
is taken to be somehow
irreducible and primitive.

00:08:38.230 --> 00:08:41.240
We can't explain it in
more basic physical terms,

00:08:41.240 --> 00:08:42.860
so we take it as a
kind of primitive.

00:08:42.860 --> 00:08:46.150
And that might lead to dualist
theories of consciousness

00:08:46.150 --> 00:08:48.040
where consciousness is
somehow separate from

00:08:48.040 --> 00:08:49.720
and interacts with the brain.

00:08:49.720 --> 00:08:51.850
Recently very popular
has been the class

00:08:51.850 --> 00:08:55.060
of panpsychist theories
of consciousness.

00:08:55.060 --> 00:08:57.680
I know Galen Strawson was
here a while back talking.

00:08:57.680 --> 00:09:00.070
He very much favors
panpsychist theories

00:09:00.070 --> 00:09:02.530
where consciousness is
something basic in the universe

00:09:02.530 --> 00:09:03.640
underlying matter.

00:09:03.640 --> 00:09:06.580
And indeed, there are idealist
theories where consciousness

00:09:06.580 --> 00:09:09.460
underlies the whole universe.

00:09:09.460 --> 00:09:12.760
So these are all extremely
speculative but interesting

00:09:12.760 --> 00:09:15.040
views that I've explored myself.

00:09:15.040 --> 00:09:19.075
There are also a reductionist
theories of consciousness from

00:09:19.075 --> 00:09:21.700
functionalist approaches, where
consciousness is just basically

00:09:21.700 --> 00:09:26.230
taken to be a giant
algorithm or computation,

00:09:26.230 --> 00:09:27.970
biological approaches
to consciousness--

00:09:27.970 --> 00:09:29.740
my colleague Ned Block
was here, I know,

00:09:29.740 --> 00:09:33.540
talking about
neurobiology-based approaches,

00:09:33.540 --> 00:09:35.390
where it's not the
algorithm that matters,

00:09:35.390 --> 00:09:38.080
but the biology it's
implemented in--

00:09:38.080 --> 00:09:40.360
and indeed, the kind
of quantum approaches

00:09:40.360 --> 00:09:43.120
that people like Roger
Penrose and Stuart Hameroff

00:09:43.120 --> 00:09:44.920
have made famous.

00:09:44.920 --> 00:09:47.050
I think there's interesting
things to say about all

00:09:47.050 --> 00:09:48.460
of these approaches.

00:09:48.460 --> 00:09:50.500
I think that right
now, at least,

00:09:50.500 --> 00:09:52.990
most of the reductionist
approaches leave a gap.

00:09:52.990 --> 00:09:55.450
But the non-reductionist
approaches

00:09:55.450 --> 00:09:58.480
have other problems in
seeing how it all works.

00:09:58.480 --> 00:10:02.540
Today, I'm going to take a
different kind of approach,

00:10:02.540 --> 00:10:04.810
this approach through
the meta-problem.

00:10:04.810 --> 00:10:08.580
One way to motivate this is to--

00:10:08.580 --> 00:10:10.900
I often get asked, well,
you're a philosopher.

00:10:10.900 --> 00:10:11.400
It's fine.

00:10:11.400 --> 00:10:15.252
You get to think about these
things like the hard problem

00:10:15.252 --> 00:10:15.960
of consciousness.

00:10:15.960 --> 00:10:22.000
How can I, as a scientist or an
engineer or an AI researcher--

00:10:22.000 --> 00:10:25.758
how can I do something
to contribute,

00:10:25.758 --> 00:10:28.050
to help get this at this hard
problem of consciousness?

00:10:28.050 --> 00:10:30.810
Is this just a problem
for philosophy?

00:10:30.810 --> 00:10:33.300
For me to work on it
as a AI researcher,

00:10:33.300 --> 00:10:36.660
I need something I
can operationalize,

00:10:36.660 --> 00:10:38.820
something I can work
with and try to program.

00:10:38.820 --> 00:10:40.380
And as it stands,
it's just not clear

00:10:40.380 --> 00:10:44.375
how to do that with
the hard problem.

00:10:44.375 --> 00:10:45.750
If you're a
neuroscientist, there

00:10:45.750 --> 00:10:47.560
are some things you can do.

00:10:47.560 --> 00:10:50.040
You can work with humans
and look at their brains

00:10:50.040 --> 00:10:52.975
and look for the neural
correlates of consciousness,

00:10:52.975 --> 00:10:55.350
the bits of the brain that go
along with being conscious.

00:10:55.350 --> 00:10:56.970
Because at least
with humans, we can

00:10:56.970 --> 00:10:59.790
take as a plausible
background assumption

00:10:59.790 --> 00:11:01.350
that the system is conscious.

00:11:01.350 --> 00:11:02.610
For AI, we can't even do that.

00:11:02.610 --> 00:11:04.860
We don't know which AI systems
we're working with that

00:11:04.860 --> 00:11:05.443
are conscious.

00:11:05.443 --> 00:11:08.040
We need some
operational criteria.

00:11:08.040 --> 00:11:11.400
In AI, we mostly work on
modeling things like behavior

00:11:11.400 --> 00:11:12.720
and objective functioning.

00:11:12.720 --> 00:11:15.640
For consciousness, those
are the easy problems.

00:11:15.640 --> 00:11:19.120
So how does someone coming
from this perspective

00:11:19.120 --> 00:11:22.700
make a connection to the hard
problem of consciousness?

00:11:22.700 --> 00:11:26.410
Well, one approach is to
work on certain problems

00:11:26.410 --> 00:11:28.960
among the easy problems
of behavior that

00:11:28.960 --> 00:11:31.930
shed particular light
on the hard problem.

00:11:31.930 --> 00:11:36.880
And that's going to be the
approach that I look at today.

00:11:36.880 --> 00:11:40.410
So the key idea
here is there are

00:11:40.410 --> 00:11:42.210
certain behavioral
functions that

00:11:42.210 --> 00:11:45.390
seem to have a
particularly close relation

00:11:45.390 --> 00:11:48.480
to the hard problem
of consciousness.

00:11:48.480 --> 00:11:52.050
In particular, we say
things about consciousness.

00:11:52.050 --> 00:11:54.690
We make what philosophers
call phenomenal reports,

00:11:54.690 --> 00:11:58.800
verbal reports of
conscious experiences.

00:11:58.800 --> 00:12:02.040
So I'll say things
like, I'm conscious,

00:12:02.040 --> 00:12:05.180
I'm feeling pain
right now, and so on.

00:12:05.180 --> 00:12:06.930
Maybe the consciousness
and the pain

00:12:06.930 --> 00:12:09.280
are subjective experiences.

00:12:09.280 --> 00:12:12.090
But the reports, the
utterances, I am conscious,

00:12:12.090 --> 00:12:14.280
well that's a bit of behavior.

00:12:14.280 --> 00:12:17.965
In principle, explaining those
is among the easy problems.

00:12:17.965 --> 00:12:20.580
It's objectively
measurable response.

00:12:20.580 --> 00:12:25.050
We can find a mechanism in
the brain that produces it.

00:12:25.050 --> 00:12:27.540
And among our
phenomenal reports,

00:12:27.540 --> 00:12:30.420
there's the special class
we can call the problem

00:12:30.420 --> 00:12:34.500
reports, reports expressing
our sense that consciousness

00:12:34.500 --> 00:12:35.970
poses a problem.

00:12:35.970 --> 00:12:38.340
Now admittedly, not everyone
makes these reports.

00:12:38.340 --> 00:12:41.450
But they seem to be fairly
widespread, especially

00:12:41.450 --> 00:12:43.200
among philosophers and
scientists thinking

00:12:43.200 --> 00:12:44.020
about these things.

00:12:44.020 --> 00:12:47.040
But furthermore, it's a
sense that it's fairly easy

00:12:47.040 --> 00:12:50.070
to find a very wide
class of people

00:12:50.070 --> 00:12:53.260
who think about consciousness.

00:12:53.260 --> 00:12:56.640
People say things like, there
is a problem of consciousness,

00:12:56.640 --> 00:12:57.907
a hard problem.

00:12:57.907 --> 00:12:59.490
On the face of it,
explaining behavior

00:12:59.490 --> 00:13:01.440
doesn't explain consciousness.

00:13:01.440 --> 00:13:03.960
Consciousness
seems non-physical.

00:13:03.960 --> 00:13:07.320
How would you ever explain the
subjective experience of red

00:13:07.320 --> 00:13:08.610
and so on?

00:13:08.610 --> 00:13:10.350
It's an objective
fact about us--

00:13:10.350 --> 00:13:12.580
at least about some of us--

00:13:12.580 --> 00:13:15.510
that we make those reports.

00:13:15.510 --> 00:13:19.390
And that's a fact
about human behavior.

00:13:19.390 --> 00:13:22.100
So the meta-problem
of consciousness then,

00:13:22.100 --> 00:13:25.980
at a second approximation,
is roughly the problem

00:13:25.980 --> 00:13:29.190
of explaining these
problem reports,

00:13:29.190 --> 00:13:32.490
explaining, you might say, the
conviction that we're conscious

00:13:32.490 --> 00:13:34.860
and that consciousness
is puzzling.

00:13:34.860 --> 00:13:37.590
And what's nice about this is
that although the hard problem

00:13:37.590 --> 00:13:40.540
is this airy fairy problem
about subjective experience

00:13:40.540 --> 00:13:42.720
that's hard to pin
down, this is a puzzle

00:13:42.720 --> 00:13:45.100
ultimately about behavior.

00:13:45.100 --> 00:13:47.130
So this is an easy
problem, one that

00:13:47.130 --> 00:13:50.010
ought to be open to those
standard methods of explanation

00:13:50.010 --> 00:13:54.170
in the cognitive
and brain sciences.

00:13:54.170 --> 00:13:57.350
So there's a research program.

00:13:57.350 --> 00:13:58.770
There's a research program here.

00:13:58.770 --> 00:14:00.380
So I like to think
of the meta-problem

00:14:00.380 --> 00:14:01.400
as something we
could play that role.

00:14:01.400 --> 00:14:03.548
I talked about earlier,
if you're an AI researcher

00:14:03.548 --> 00:14:05.090
thinking about this,
the meta-problem

00:14:05.090 --> 00:14:07.670
is an easy problem, a
problem about behavior,

00:14:07.670 --> 00:14:09.477
that's closely tied
to the hard problem.

00:14:09.477 --> 00:14:11.810
So it's something we might
be able to make some progress

00:14:11.810 --> 00:14:14.780
on using standard methods
of thinking about algorithms

00:14:14.780 --> 00:14:16.970
and computations or
thinking about brain

00:14:16.970 --> 00:14:19.520
processes and
behavior while still

00:14:19.520 --> 00:14:21.320
shedding some light,
at least indirectly,

00:14:21.320 --> 00:14:22.290
on the hard problem.

00:14:22.290 --> 00:14:24.710
It's more tractable
than the hard problem.

00:14:24.710 --> 00:14:27.255
But solving it ought to shed
light on the hard problem.

00:14:27.255 --> 00:14:29.630
And today, I'm just going to
kind of lay out the research

00:14:29.630 --> 00:14:32.540
program and talk about some ways
in which it might potentially

00:14:32.540 --> 00:14:35.450
shed some light.

00:14:35.450 --> 00:14:36.980
This is interesting
to a philosopher

00:14:36.980 --> 00:14:39.080
because it looks like
an instance of what

00:14:39.080 --> 00:14:41.440
people sometimes call
genealogical analysis.

00:14:41.440 --> 00:14:43.010
It goes back to
Friedrich Nietzsche

00:14:43.010 --> 00:14:45.275
on the genealogy of morals.

00:14:45.275 --> 00:14:47.150
Instead of thinking
about what's good or bad,

00:14:47.150 --> 00:14:49.310
let's look at where our
sense of good or bad

00:14:49.310 --> 00:14:54.080
came from, the genealogy of it
all in evolution or in culture

00:14:54.080 --> 00:14:56.030
or in religion.

00:14:56.030 --> 00:14:58.820
And people think a
genealogical approach

00:14:58.820 --> 00:15:01.440
to God, instead of thinking
about does God exist or not,

00:15:01.440 --> 00:15:03.740
let's look at where our
belief in God came from.

00:15:03.740 --> 00:15:05.540
Maybe there's some
evolutionary reason

00:15:05.540 --> 00:15:08.480
for why people believe in God.

00:15:08.480 --> 00:15:10.700
This often leads, not
always, but often leads

00:15:10.700 --> 00:15:14.710
to a kind of debunking of our
beliefs about those domains.

00:15:14.710 --> 00:15:18.200
Explain why we believe in
God in evolutionary terms,

00:15:18.200 --> 00:15:19.850
no need for the God
hypothesis anymore.

00:15:19.850 --> 00:15:25.520
Explain how moral beliefs and
evolutionary terms, maybe no

00:15:25.520 --> 00:15:27.570
need to take morality
quite so seriously.

00:15:27.570 --> 00:15:30.950
So some people, at least, are
inclined to take an approach

00:15:30.950 --> 00:15:32.730
like this with
consciousness too.

00:15:32.730 --> 00:15:35.180
If you think about the
meta-problem explaining

00:15:35.180 --> 00:15:37.010
our beliefs about
consciousness, that

00:15:37.010 --> 00:15:42.350
might ultimately debunk our
beliefs about consciousness.

00:15:42.350 --> 00:15:45.260
This leads to a philosophical
view, which has recently

00:15:45.260 --> 00:15:48.680
attracted a lot of interest,
a philosophical view

00:15:48.680 --> 00:15:52.340
called illusionism, which is
the view that consciousness

00:15:52.340 --> 00:15:55.030
itself is an illusion.

00:15:55.030 --> 00:15:58.850
Or maybe that the problem of
consciousness is an illusion.

00:15:58.850 --> 00:16:03.600
Explain the illusion, and
we dissolve the problem.

00:16:03.600 --> 00:16:05.540
I take that in terms
of the meta-problem,

00:16:05.540 --> 00:16:08.810
that view roughly comes
to solve the meta-problem.

00:16:08.810 --> 00:16:11.930
It will dissolve
the hard problem.

00:16:11.930 --> 00:16:14.270
Explain why it is that
we say all these things

00:16:14.270 --> 00:16:18.470
about consciousness, why we
say, I am conscious, why we say,

00:16:18.470 --> 00:16:19.860
consciousness is puzzling.

00:16:19.860 --> 00:16:23.840
If you can explain all
that in algorithmic terms,

00:16:23.840 --> 00:16:26.325
then you'll remove
the underlying problem

00:16:26.325 --> 00:16:27.950
because you'll have
explained why we're

00:16:27.950 --> 00:16:29.743
puzzled in the first place.

00:16:29.743 --> 00:16:31.160
Actually, walking
over here today,

00:16:31.160 --> 00:16:33.170
I noticed that just a
couple of blocks away,

00:16:33.170 --> 00:16:35.780
we have the Museum
of Illusions, so I'm

00:16:35.780 --> 00:16:37.500
going to check
that out later on.

00:16:37.500 --> 00:16:39.290
But if illusionism
is right, added

00:16:39.290 --> 00:16:40.850
to all those
perceptual illusions

00:16:40.850 --> 00:16:43.280
is going to be the problem
of consciousness itself.

00:16:43.280 --> 00:16:46.250
It's roughly an
illusion thrown up

00:16:46.250 --> 00:16:49.018
by having a weird
kind of self model

00:16:49.018 --> 00:16:50.560
with a certain kind
of algorithm that

00:16:50.560 --> 00:16:54.260
attributes to ourselves special
properties that we don't have.

00:16:54.260 --> 00:16:59.000
So one line on the meta-problem
is the illusionist line.

00:16:59.000 --> 00:17:02.210
Solve the meta-problem, you'll
get to treat consciousness

00:17:02.210 --> 00:17:03.590
as an illusion.

00:17:03.590 --> 00:17:07.190
That's actually a view
that has many antecedents

00:17:07.190 --> 00:17:09.349
in the history of philosophy,
one way or another.

00:17:09.349 --> 00:17:12.560
Even Immanuel Kant and his
great critique of pure reason

00:17:12.560 --> 00:17:15.680
had a section where he talked
about the self or the soul

00:17:15.680 --> 00:17:17.240
as a transcendental illusion.

00:17:17.240 --> 00:17:20.650
We seem to have this
indivisible soul.

00:17:20.650 --> 00:17:22.400
But that's the kind
of illusion thrown out

00:17:22.400 --> 00:17:24.710
by our cognitive processes.

00:17:24.710 --> 00:17:27.290
The Australian
philosophers, Ullin Place

00:17:27.290 --> 00:17:29.120
and David Armstrong,
had versions

00:17:29.120 --> 00:17:32.750
of this that I might
touch on a bit later.

00:17:32.750 --> 00:17:36.440
Daniel Dennett, a leading
reductionist thinker

00:17:36.440 --> 00:17:38.235
about consciousness
has been pushing

00:17:38.235 --> 00:17:39.860
for the last couple
of decades the idea

00:17:39.860 --> 00:17:43.850
that consciousness involves a
certain kind of user illusion.

00:17:43.850 --> 00:17:46.700
And most recently, the British
philosopher, Keith Frankish,

00:17:46.700 --> 00:17:49.820
has been really
pushing illusionism

00:17:49.820 --> 00:17:51.950
as a theory of consciousness.

00:17:51.950 --> 00:17:57.080
He has a book centering
around a paper

00:17:57.080 --> 00:18:00.290
by Keith Frankish on illusionism
as a theory of consciousness

00:18:00.290 --> 00:18:02.390
that I recommend to you.

00:18:02.390 --> 00:18:04.627
So one way to go
with the meta-problem

00:18:04.627 --> 00:18:05.960
is the direction of illusionism.

00:18:05.960 --> 00:18:07.880
But one nice thing
about-- many people

00:18:07.880 --> 00:18:10.950
find illusionism
completely unbelievable.

00:18:10.950 --> 00:18:13.500
They find, how could it be that
consciousness is an illusion?

00:18:13.500 --> 00:18:15.500
Look, we just have these
subjective experiences.

00:18:15.500 --> 00:18:16.890
It's a data about our nature.

00:18:16.890 --> 00:18:20.370
And I confess, I've got some
sympathy with that reaction.

00:18:20.370 --> 00:18:22.490
So I'm not an
illusionist myself.

00:18:22.490 --> 00:18:24.260
I'm a realist
about consciousness

00:18:24.260 --> 00:18:27.200
in the philosopher's sense,
where a realist about something

00:18:27.200 --> 00:18:30.560
is someone who believes
that thing is real.

00:18:30.560 --> 00:18:32.240
I think consciousness is real.

00:18:32.240 --> 00:18:33.788
I think it's not an illusion.

00:18:33.788 --> 00:18:35.330
I think that solving
the meta-problem

00:18:35.330 --> 00:18:37.540
does not dissolve
the hard problem.

00:18:37.540 --> 00:18:40.040
But the nice thing about the
meta-problem is you can proceed

00:18:40.040 --> 00:18:41.930
on it--

00:18:41.930 --> 00:18:44.360
to some extent, at least
in initial neutrality--

00:18:44.360 --> 00:18:47.330
on that question, is
consciousness real or is it

00:18:47.330 --> 00:18:49.060
an illusion.

00:18:49.060 --> 00:18:51.410
It's a basic problem about
our objective functioning

00:18:51.410 --> 00:18:52.490
in these reports.

00:18:52.490 --> 00:18:54.620
What explains those?

00:18:54.620 --> 00:18:57.320
There's a neutral
research program here

00:18:57.320 --> 00:18:59.438
that both realists,
illusionists,

00:18:59.438 --> 00:19:01.730
people of all kinds of
different views of consciousness

00:19:01.730 --> 00:19:02.623
can explain.

00:19:02.623 --> 00:19:04.040
And then we can
come back and look

00:19:04.040 --> 00:19:06.250
at the philosophical
consequences.

00:19:06.250 --> 00:19:08.390
So I'm not an illusionist.

00:19:08.390 --> 00:19:10.160
I think consciousness is real.

00:19:10.160 --> 00:19:13.190
I've got to say, I do feel
the temptation of illusionism.

00:19:13.190 --> 00:19:16.280
I find it really intriguing and
in some ways attractive view.

00:19:16.280 --> 00:19:18.950
It's just fundamentally
unbelievable.

00:19:18.950 --> 00:19:21.350
Nevertheless, I think
that the meta-problem

00:19:21.350 --> 00:19:23.930
should be a tractable problem.

00:19:23.930 --> 00:19:26.990
Solving it, at the
very least, will

00:19:26.990 --> 00:19:29.843
shed much light on the hard
problem of consciousness

00:19:29.843 --> 00:19:31.010
even if it doesn't solve it.

00:19:31.010 --> 00:19:32.870
If you can explain
our conviction

00:19:32.870 --> 00:19:35.240
that we're conscious,
somehow the source,

00:19:35.240 --> 00:19:37.610
the roots of our conviction
that we are conscious,

00:19:37.610 --> 00:19:40.190
must have something to do
with consciousness especially

00:19:40.190 --> 00:19:42.440
if consciousness is real.

00:19:42.440 --> 00:19:45.170
So I think it's very
much a good research

00:19:45.170 --> 00:19:47.030
program for people to explain.

00:19:47.030 --> 00:19:50.570
So then I'll move on
now to just outlining

00:19:50.570 --> 00:19:53.180
the research program a little
bit more and then talk a bit

00:19:53.180 --> 00:19:55.962
about potential
solutions and on impact

00:19:55.962 --> 00:19:57.920
on theories of consciousness
before wrapping up

00:19:57.920 --> 00:20:03.145
with a little bit more
about illusionism.

00:20:03.145 --> 00:20:06.740
So this meta-problem, which
I've been pushing recently,

00:20:06.740 --> 00:20:10.250
opens up a tractable
empirical research program

00:20:10.250 --> 00:20:12.980
for everyone, reductionists,
non-reductionists,

00:20:12.980 --> 00:20:14.980
illusionists, non-illusionists.

00:20:14.980 --> 00:20:17.060
We can try to solve
it and then think

00:20:17.060 --> 00:20:22.100
about the philosophical
consequences.

00:20:22.100 --> 00:20:23.850
Now what is the meta-problem?

00:20:23.850 --> 00:20:26.490
Well, the way I'm
going to put it is it's

00:20:26.490 --> 00:20:31.350
the problem of topic-neutrally
explaining problem intuitions

00:20:31.350 --> 00:20:34.690
or else explaining why
that can't be done.

00:20:34.690 --> 00:20:39.610
And I'll unpack all the
pieces of that right now.

00:20:39.610 --> 00:20:41.670
First, starting with
problem intuitions.

00:20:41.670 --> 00:20:43.170
What are problem intuitions?

00:20:43.170 --> 00:20:45.810
Well, there are
the things we say.

00:20:45.810 --> 00:20:48.367
There are things we think I say.

00:20:48.367 --> 00:20:49.700
Consciousness seems irreducible.

00:20:49.700 --> 00:20:51.492
I might think consciousness
is irreducible.

00:20:51.492 --> 00:20:54.780
People might be disposed,
have a tendency to say

00:20:54.780 --> 00:20:55.800
or think those things.

00:20:55.800 --> 00:20:58.800
Problem intuitions all take
to be roughly, that tendency.

00:20:58.800 --> 00:21:02.880
We have dispositions to say
and think certain things

00:21:02.880 --> 00:21:04.510
about consciousness.

00:21:04.510 --> 00:21:07.020
What are the core
problem intuitions?

00:21:07.020 --> 00:21:09.000
Well, I think they
break down into a number

00:21:09.000 --> 00:21:10.423
of different kinds.

00:21:10.423 --> 00:21:12.840
There is the intuition that
consciousness is non-physical.

00:21:12.840 --> 00:21:15.420
We might think of that as
a metaphysical intuition

00:21:15.420 --> 00:21:17.205
about the nature
of consciousness.

00:21:17.205 --> 00:21:19.590
There are intuitions
about explanation.

00:21:19.590 --> 00:21:22.200
Consciousness is
hard to explain,

00:21:22.200 --> 00:21:25.420
explaining behavior doesn't
explain consciousness.

00:21:25.420 --> 00:21:27.913
There are intuitions about
knowledge of consciousness.

00:21:27.913 --> 00:21:30.330
Some of you may know the famous
thought experiment of Mary

00:21:30.330 --> 00:21:32.520
in the black and
white room who knows

00:21:32.520 --> 00:21:35.550
all about the objective
nature of color vision

00:21:35.550 --> 00:21:38.177
and so on, but still doesn't
know what it's like to see red.

00:21:38.177 --> 00:21:39.510
She sees red for the first time.

00:21:39.510 --> 00:21:41.382
She learns something new.

00:21:41.382 --> 00:21:43.590
That's an intuition about
knowledge of consciousness.

00:21:43.590 --> 00:21:46.620
There are what philosophers call
modal intuitions about what's

00:21:46.620 --> 00:21:48.690
possible or imaginable.

00:21:48.690 --> 00:21:51.750
One famous case is
the case of a zombie,

00:21:51.750 --> 00:21:55.440
a creature who is physically
identical to you and me

00:21:55.440 --> 00:21:56.190
but not conscious.

00:21:56.190 --> 00:21:59.190
Or maybe an AI system, which is
functionally identical to you

00:21:59.190 --> 00:22:00.450
and me, but not conscious.

00:22:00.450 --> 00:22:03.190
That at least seems
conceivable to many people.

00:22:03.190 --> 00:22:06.150
So this is the
philosophical zombie.

00:22:06.150 --> 00:22:09.510
Unlike the zombies and movies,
which have weird behaviors

00:22:09.510 --> 00:22:12.840
and go after brains and so
on, the philosophical zombie

00:22:12.840 --> 00:22:15.600
is a creature that seems,
at least behaviorally, may

00:22:15.600 --> 00:22:17.640
be physically like
a normal human,

00:22:17.640 --> 00:22:20.190
but doesn't have any
conscious experiences.

00:22:20.190 --> 00:22:23.340
All the physical states,
none of the mental states.

00:22:23.340 --> 00:22:25.860
And it seems to many people
that's at least conceivable.

00:22:25.860 --> 00:22:26.730
We're not zombies.

00:22:26.730 --> 00:22:28.680
I don't think anyone
here is a zombie--

00:22:28.680 --> 00:22:29.460
I hope.

00:22:29.460 --> 00:22:33.060
But nonetheless, it seems that
we can make sense of the idea.

00:22:33.060 --> 00:22:34.680
And one way to pose
the hard problem

00:22:34.680 --> 00:22:36.600
is, why are we not zombies.

00:22:36.600 --> 00:22:38.310
So this imagined
ability of zombies

00:22:38.310 --> 00:22:41.530
is one of the intuitions
that gets the problem going.

00:22:41.530 --> 00:22:43.590
And then you can go on
and catalog more and more

00:22:43.590 --> 00:22:46.140
intuitions about the
distribution of conscious,

00:22:46.140 --> 00:22:49.110
maybe the intuition that
robots won't be conscious.

00:22:49.110 --> 00:22:51.390
That's an optional one, I think.

00:22:51.390 --> 00:22:54.600
Or consciousness matters
morally in certain ways,

00:22:54.600 --> 00:22:57.130
and the list goes on.

00:22:57.130 --> 00:22:59.700
So I think there is an
interdisciplinary research

00:22:59.700 --> 00:23:03.660
program here of working on those
intuitions about consciousness

00:23:03.660 --> 00:23:05.400
and trying to explain them.

00:23:05.400 --> 00:23:08.430
Experimental psychology and
experimental philosophy--

00:23:08.430 --> 00:23:09.840
a newly active area--

00:23:09.840 --> 00:23:12.960
can study people's intuitions
about consciousness.

00:23:12.960 --> 00:23:15.690
We can work on models of these
things, computational models

00:23:15.690 --> 00:23:18.752
or neurobiological models, of
these intuitions and reports.

00:23:18.752 --> 00:23:20.460
And indeed, I think
there's a lot of room

00:23:20.460 --> 00:23:22.350
for philosophical analysis.

00:23:22.350 --> 00:23:24.750
And there's just starting
to be a program of people

00:23:24.750 --> 00:23:28.170
doing these things
in all these fields.

00:23:28.170 --> 00:23:29.670
I mean, it is an
empirical question,

00:23:29.670 --> 00:23:31.905
how widely these
intuitions are shared.

00:23:31.905 --> 00:23:33.780
You might be sitting
there thinking, come on,

00:23:33.780 --> 00:23:35.550
I don't have of
these intuitions.

00:23:35.550 --> 00:23:37.210
Maybe this is just you.

00:23:37.210 --> 00:23:39.613
My sense is-- from the
psychological study to date--

00:23:39.613 --> 00:23:42.030
it seems that some of these
intuitions about consciousness

00:23:42.030 --> 00:23:45.990
are at least very widely
shared, at least as dispositions

00:23:45.990 --> 00:23:50.500
or intuitions, although they are
often overridden on reflection.

00:23:50.500 --> 00:23:53.300
But the current data on
this is somewhat limited.

00:23:53.300 --> 00:23:57.240
Although there is a lot of
empirical work on intuitions

00:23:57.240 --> 00:23:59.890
about the mind concerning
things like belief,

00:23:59.890 --> 00:24:01.890
like when do kids get the
idea that your beliefs

00:24:01.890 --> 00:24:04.470
about the world can
be false, concerning

00:24:04.470 --> 00:24:06.810
the way your self
persists through time--

00:24:06.810 --> 00:24:09.615
could you exist after
the death of your body--

00:24:09.615 --> 00:24:10.990
where consciousness
is concerned,

00:24:10.990 --> 00:24:12.900
there's work on the
distribution of consciousness.

00:24:12.900 --> 00:24:14.100
Could a robot be conscious?

00:24:14.100 --> 00:24:15.525
Could a group be conscious?

00:24:15.525 --> 00:24:17.400
Here's a book by Paul
Bloom, "Decartes' Baby"

00:24:17.400 --> 00:24:19.620
that catalogs a lot of
this interesting work,

00:24:19.620 --> 00:24:22.260
making the case that many
children are intuitive

00:24:22.260 --> 00:24:22.980
dualists.

00:24:22.980 --> 00:24:25.410
Thinks they're
naturally inclined

00:24:25.410 --> 00:24:28.920
to think there's something
non-physical about the mind.

00:24:28.920 --> 00:24:30.330
So far, most of
this work has not

00:24:30.330 --> 00:24:33.570
been so much on these
core problem intuitions

00:24:33.570 --> 00:24:35.820
about consciousness,
but there's work

00:24:35.820 --> 00:24:37.170
developing in this direction.

00:24:37.170 --> 00:24:40.800
Sara Gottlieb and Tania Lombrozo
have a very recent article

00:24:40.800 --> 00:24:43.080
called "Can Science
Explain The Human

00:24:43.080 --> 00:24:45.960
Mind" on people's
judgments about when

00:24:45.960 --> 00:24:48.840
various mental phenomena
are hard to explain.

00:24:48.840 --> 00:24:51.240
And they seem to find that
yes, subjective experience

00:24:51.240 --> 00:24:54.910
and things to which people have
privileged first person access

00:24:54.910 --> 00:24:58.103
seem to pose the
problem big time.

00:24:58.103 --> 00:25:00.270
So there's the beginning
of a research program here.

00:25:00.270 --> 00:25:03.600
I think there's
room for a lot more.

00:25:03.600 --> 00:25:05.490
The topic neutrality part--

00:25:05.490 --> 00:25:08.640
when I say we're looking for
a topic neutral explanation

00:25:08.640 --> 00:25:10.670
of problem intuitions,
that's roughly

00:25:10.670 --> 00:25:13.660
to say an explanation that
doesn't mention consciousness

00:25:13.660 --> 00:25:14.160
itself.

00:25:14.160 --> 00:25:15.900
It's put in neutral terms.

00:25:15.900 --> 00:25:18.115
It's neutral on the
existence of consciousness.

00:25:18.115 --> 00:25:19.740
The most obvious one
would be something

00:25:19.740 --> 00:25:22.450
like an algorithmic explanation.

00:25:22.450 --> 00:25:25.070
Now here is the algorithm
the brain is executing

00:25:25.070 --> 00:25:27.680
that generates our conviction
that we're conscious

00:25:27.680 --> 00:25:30.260
and our reports
about consciousness.

00:25:30.260 --> 00:25:33.020
There may be some time between
an algorithm and consciousness,

00:25:33.020 --> 00:25:34.910
but to specify
the algorithm, you

00:25:34.910 --> 00:25:38.250
don't need to make claims
about consciousness.

00:25:38.250 --> 00:25:40.940
So the algorithmic version
of the meta-problem

00:25:40.940 --> 00:25:44.320
is roughly find the algorithm
that generates our problem

00:25:44.320 --> 00:25:44.900
intuition.

00:25:44.900 --> 00:25:49.370
So that's, I think, in
principle a research program

00:25:49.370 --> 00:25:52.970
that maybe an AI
researchers in combination

00:25:52.970 --> 00:25:54.890
with psychologists--

00:25:54.890 --> 00:25:58.430
the psychologist could help
isolate data about the way

00:25:58.430 --> 00:26:00.950
that the human beings are
doing it, how these things are

00:26:00.950 --> 00:26:01.940
generated in humans.

00:26:01.940 --> 00:26:03.830
And the AI researcher
can try and see

00:26:03.830 --> 00:26:06.585
about implementing that
algorithm in machines

00:26:06.585 --> 00:26:07.460
and see what results.

00:26:07.460 --> 00:26:09.380
And I'll talk about a
little bit of research

00:26:09.380 --> 00:26:12.780
in this direction
in just a moment.

00:26:12.780 --> 00:26:16.040
OK now I want to say something
about potential solutions

00:26:16.040 --> 00:26:16.670
to the problem.

00:26:16.670 --> 00:26:19.650
Like I said, this is a
big research program.

00:26:19.650 --> 00:26:22.340
I don't claim to have the
solution to the meta-problem.

00:26:22.340 --> 00:26:25.240
I've got some ideas, but I'm
not going to try and lay out

00:26:25.240 --> 00:26:27.000
a major solution.

00:26:27.000 --> 00:26:28.640
So here are a few
things, which I

00:26:28.640 --> 00:26:32.233
think might be part of a
solution to the problem,

00:26:32.233 --> 00:26:33.650
many of which have
got antecedents

00:26:33.650 --> 00:26:38.120
here and there in scientific
and philosophical discussion.

00:26:38.120 --> 00:26:40.850
Some promising ideas include
retrospective models,

00:26:40.850 --> 00:26:43.760
phenomenal concepts,
introspective opacity,

00:26:43.760 --> 00:26:45.480
the sense of acquaintance.

00:26:45.480 --> 00:26:47.910
Let me just say something
about a few of these.

00:26:47.910 --> 00:26:50.000
One starting idea
that almost anyone

00:26:50.000 --> 00:26:54.450
is going to have here is
somehow models of ourselves

00:26:54.450 --> 00:26:57.340
are playing a central role here.

00:26:57.340 --> 00:27:03.110
Human beings have models of
the world, naive physics, naive

00:27:03.110 --> 00:27:05.840
psychology, models of
other people, and so on.

00:27:05.840 --> 00:27:07.470
We also have models
of ourselves.

00:27:07.470 --> 00:27:09.980
It makes sense for us to
have models of ourselves

00:27:09.980 --> 00:27:11.790
and our own mental processes.

00:27:11.790 --> 00:27:15.290
This is something that the
psychologist Michael Graziano

00:27:15.290 --> 00:27:16.430
has written a lot on.

00:27:16.430 --> 00:27:20.040
We have internal models of
our own cognitive processes,

00:27:20.040 --> 00:27:23.520
including those tied
to consciousness.

00:27:23.520 --> 00:27:26.560
And somehow something about
our introspective models

00:27:26.560 --> 00:27:29.890
explains our sense, A, that we
are conscious and B, that this

00:27:29.890 --> 00:27:31.940
is distinctively problematic.

00:27:31.940 --> 00:27:35.120
And I think anyone thinking
about the meta-problem,

00:27:35.120 --> 00:27:36.940
this has got to be at
least the first step.

00:27:36.940 --> 00:27:39.040
We have these
introspective models.

00:27:39.040 --> 00:27:41.350
If you were an illusionist,
they'll be false models.

00:27:41.350 --> 00:27:43.930
If you're a realist, they
needn't be false models.

00:27:43.930 --> 00:27:47.170
But at the very least,
these introspective models

00:27:47.170 --> 00:27:49.090
are involved, which is fine.

00:27:49.090 --> 00:27:51.050
But the devil's in the details.

00:27:51.050 --> 00:27:53.890
How do they work to
generate this problem?

00:27:53.890 --> 00:27:55.510
A number of
philosophers have argued

00:27:55.510 --> 00:27:58.150
we have special concepts
of consciousness,

00:27:58.150 --> 00:28:02.080
introspective concepts of these
special subjective states.

00:28:02.080 --> 00:28:04.420
People call these phenomenal
concepts, concepts

00:28:04.420 --> 00:28:06.180
of phenomenal consciousness.

00:28:06.180 --> 00:28:08.500
And one thing that's
special is these concepts

00:28:08.500 --> 00:28:13.510
are somehow independent
of our physical concepts.

00:28:13.510 --> 00:28:17.050
They explain we've got one
set of physical concepts

00:28:17.050 --> 00:28:19.098
for modeling the external world.

00:28:19.098 --> 00:28:20.890
We've got one set of
introspective concepts

00:28:20.890 --> 00:28:22.030
from modeling our own mind.

00:28:22.030 --> 00:28:23.260
And these concepts,
just by virtue

00:28:23.260 --> 00:28:24.968
of the way they're
designed, are somewhat

00:28:24.968 --> 00:28:26.110
independent of each other.

00:28:26.110 --> 00:28:29.440
And that partly explains
why consciousness

00:28:29.440 --> 00:28:33.580
seems to be independent of the
physical world intuitively.

00:28:33.580 --> 00:28:36.850
So maybe that independence
of phenomenal concepts

00:28:36.850 --> 00:28:40.385
could go some distance to
explaining our problem reports.

00:28:40.385 --> 00:28:44.083
So I think there's got to be
something to this as well.

00:28:44.083 --> 00:28:46.000
At the same time, I don't
this goes nearly far

00:28:46.000 --> 00:28:49.810
enough because we have concepts
of many aspects of the mind,

00:28:49.810 --> 00:28:53.140
not just of the subjective
experiential past but things we

00:28:53.140 --> 00:28:56.020
believe and things we desire.

00:28:56.020 --> 00:28:59.490
And so when I believe that
Paris is the capital of France,

00:28:59.490 --> 00:29:01.210
that's part of my
internal self model.

00:29:01.210 --> 00:29:04.710
But that doesn't seem to
generate the hard problem

00:29:04.710 --> 00:29:07.550
in nearly the same way in which
the experience of red does.

00:29:07.550 --> 00:29:09.870
So a lot more needs to
be said about what's

00:29:09.870 --> 00:29:13.860
going on in cases like
having the experience of red

00:29:13.860 --> 00:29:16.050
and having the sense that
that generates a gap.

00:29:16.050 --> 00:29:21.010
So it doesn't generalize to
everything about the mind.

00:29:21.010 --> 00:29:23.230
Some people have
thought that what

00:29:23.230 --> 00:29:26.200
we might call introspective
opacity plays a role,

00:29:26.200 --> 00:29:29.490
that when we introspect
what's going on in our minds,

00:29:29.490 --> 00:29:32.340
we don't have access to the
underlying physical states.

00:29:32.340 --> 00:29:34.710
We don't see the
neurons in our brains.

00:29:34.710 --> 00:29:37.300
We don't see that
consciousness is physical.

00:29:37.300 --> 00:29:39.870
So we see it as non-physical.

00:29:39.870 --> 00:29:42.723
Most recently, the
physicist Max Tegmark

00:29:42.723 --> 00:29:45.140
has argued in this direction,
saying somehow consciousness

00:29:45.140 --> 00:29:46.380
is substrate-independent.

00:29:46.380 --> 00:29:47.820
We don't see the substrate.

00:29:47.820 --> 00:29:52.800
So then we think maybe it can
float free of the substrate.

00:29:52.800 --> 00:29:56.580
Armstrong made an analogy
with the case of someone

00:29:56.580 --> 00:29:59.070
in a circus where--

00:29:59.070 --> 00:30:03.390
the headless person illusion
where someone's there

00:30:03.390 --> 00:30:07.740
with a veil across their head,
and you don't see their head.

00:30:07.740 --> 00:30:09.360
So you see them
as having no head.

00:30:09.360 --> 00:30:14.260
Here is a 19th century booth
at a circus, so-called headless

00:30:14.260 --> 00:30:14.760
woman.

00:30:14.760 --> 00:30:15.810
There's a veil over her head.

00:30:15.810 --> 00:30:16.755
You don't see the
head so somehow,

00:30:16.755 --> 00:30:18.570
it looks-- at least for a
moment-- like the person

00:30:18.570 --> 00:30:19.600
doesn't have a head.

00:30:19.600 --> 00:30:23.550
So Armstrong says maybe that's
how it is with consciousness.

00:30:23.550 --> 00:30:28.320
You don't see it as physical,
so you see it as non-physical.

00:30:28.320 --> 00:30:32.128
But still the question comes up,
how do we make this inference.

00:30:32.128 --> 00:30:34.170
There's something that's
special goes on in cases

00:30:34.170 --> 00:30:37.530
like color and taste and so on.

00:30:37.530 --> 00:30:41.640
The color experience seems to
attribute primitive properties

00:30:41.640 --> 00:30:43.862
to objects like
redness, greenness,

00:30:43.862 --> 00:30:46.320
and so on, when, in fact, in
the external world at the very

00:30:46.320 --> 00:30:49.710
least, they have complex
reducible properties.

00:30:49.710 --> 00:30:53.340
Somehow, our internal
models of color treat colors

00:30:53.340 --> 00:30:56.070
like red and green as if
they are primitive things.

00:30:56.070 --> 00:31:00.180
It turns out to be useful to
have these models of things.

00:31:00.180 --> 00:31:02.040
We treat certain
things as primitive,

00:31:02.040 --> 00:31:03.750
even though they're reducible.

00:31:03.750 --> 00:31:06.090
And it sure seems that
when we experience colors,

00:31:06.090 --> 00:31:09.930
we experience greenness
as a primitive quality

00:31:09.930 --> 00:31:12.600
even though it may be a
very, very complex reducible

00:31:12.600 --> 00:31:13.470
property.

00:31:13.470 --> 00:31:15.750
That's something about
our model of colors.

00:31:15.750 --> 00:31:18.450
The philosopher
Wolfgang Schwartz

00:31:18.450 --> 00:31:22.200
tried to make an analogy with
sensor variables in image

00:31:22.200 --> 00:31:23.690
processing.

00:31:23.690 --> 00:31:26.440
You've got some visual senses
and a camera or something

00:31:26.440 --> 00:31:27.690
you need to process the image.

00:31:27.690 --> 00:31:30.180
Well, you've got
some sensor variables

00:31:30.180 --> 00:31:33.760
to represent the sensory inputs
that the various sensors are

00:31:33.760 --> 00:31:34.260
getting.

00:31:34.260 --> 00:31:36.480
And you might treat them
as a primitive dimension

00:31:36.480 --> 00:31:38.770
because that's the most
useful way to treat them.

00:31:38.770 --> 00:31:41.830
You don't treat them as certain
amounts of lights or photons

00:31:41.830 --> 00:31:42.330
firing.

00:31:42.330 --> 00:31:43.780
You don't need to
know about that.

00:31:43.780 --> 00:31:46.710
You use these sensor
variables and treat them

00:31:46.710 --> 00:31:48.720
as a primitive dimension.

00:31:48.720 --> 00:31:51.210
And all that will play into
a model of these things as

00:31:51.210 --> 00:31:53.310
primitive, maybe
taking that idea

00:31:53.310 --> 00:31:55.415
and extending it
to introspection.

00:31:57.930 --> 00:31:59.400
These conscious
states are somehow

00:31:59.400 --> 00:32:03.560
like sensor variables in
our model of the mind.

00:32:03.560 --> 00:32:05.400
And somehow, these
internal models

00:32:05.400 --> 00:32:07.530
give us the sense
of being acquainted

00:32:07.530 --> 00:32:09.840
with primitive
concrete qualities

00:32:09.840 --> 00:32:12.230
and of our awareness of them.

00:32:12.230 --> 00:32:13.480
This is still just laying out.

00:32:13.480 --> 00:32:15.147
I don't think this
is still yet actually

00:32:15.147 --> 00:32:16.200
explaining a whole lot.

00:32:16.200 --> 00:32:18.360
But it's laying out--
it's narrowing down

00:32:18.360 --> 00:32:20.730
what it is that
we need to explain

00:32:20.730 --> 00:32:22.140
to solve the meta-problem.

00:32:22.140 --> 00:32:24.110
But just to put the
pieces together,

00:32:24.110 --> 00:32:25.110
here's a little summary.

00:32:25.110 --> 00:32:27.360
One thing I like about this
summary is you can read it

00:32:27.360 --> 00:32:31.290
in either an illusionist
tone of voice,

00:32:31.290 --> 00:32:33.600
as an account of the
illusion of consciousness--

00:32:33.600 --> 00:32:36.570
so this is how false
introspective models work--

00:32:36.570 --> 00:32:39.930
or in a realist tone
of voice, as an account

00:32:39.930 --> 00:32:45.060
of our true correct
models of consciousness.

00:32:45.060 --> 00:32:47.670
But we can set it out in a way
which is neutral on the two

00:32:47.670 --> 00:32:49.045
and then try and
figure out later

00:32:49.045 --> 00:32:51.140
whether these
models are correct,

00:32:51.140 --> 00:32:53.280
as the realist
says, or incorrect,

00:32:53.280 --> 00:32:54.990
as the illusionist says.

00:32:54.990 --> 00:32:57.930
We have introspective
models deploying

00:32:57.930 --> 00:33:01.890
introspective concepts
of our internal states

00:33:01.890 --> 00:33:06.160
that are largely independent
of our physical concepts.

00:33:06.160 --> 00:33:08.490
These concepts are
introspectively opaque,

00:33:08.490 --> 00:33:11.910
not revealing any of the
underlying mechanisms.

00:33:11.910 --> 00:33:13.560
Our perceptual
models perceptually

00:33:13.560 --> 00:33:17.840
attribute primitive perceptual
qualities to the world.

00:33:17.840 --> 00:33:20.900
And our introspective
models attribute

00:33:20.900 --> 00:33:24.170
primitive mental relations
to those qualities.

00:33:24.170 --> 00:33:27.320
These models produce the
sense of acquaintance,

00:33:27.320 --> 00:33:32.480
both with those qualities
and with our awareness

00:33:32.480 --> 00:33:33.950
of those qualities.

00:33:33.950 --> 00:33:36.350
Like I said, this is not a
solution to the meta-problem,

00:33:36.350 --> 00:33:38.480
but it's trying, at
least, to pin down

00:33:38.480 --> 00:33:41.210
some parts of the roots
of those intuitions

00:33:41.210 --> 00:33:44.480
and to narrow down what
needs to be explained.

00:33:44.480 --> 00:33:46.010
To go further,
you want, I think,

00:33:46.010 --> 00:33:49.130
to test these explanations,
both with psychological studies

00:33:49.130 --> 00:33:51.373
to see if this is
plausibly what's

00:33:51.373 --> 00:33:53.540
going on in humans-- this
is the kind of thing which

00:33:53.540 --> 00:33:56.750
is the basis of our intuitions--
and computational models

00:33:56.750 --> 00:33:59.300
to see if, for example, we
could program this kind of thing

00:33:59.300 --> 00:34:02.270
into an AI system and see
if it can generate somehow

00:34:02.270 --> 00:34:06.770
qualitatively similar
reports and intuitions.

00:34:06.770 --> 00:34:10.350
You might think that last thing
is a bit far fetched right now,

00:34:10.350 --> 00:34:12.830
but I know of at least one
instance of this research

00:34:12.830 --> 00:34:17.699
program, which has been put
into play by Luke Muehlhauser

00:34:17.699 --> 00:34:21.440
and [INAUDIBLE] two researchers
at Open Philanthropy very

00:34:21.440 --> 00:34:26.230
interested in AI
and consciousness.

00:34:26.230 --> 00:34:28.407
They actually built--
they took some ideas

00:34:28.407 --> 00:34:29.949
about the meta-problem
from something

00:34:29.949 --> 00:34:31.690
I'd written about it
and from something

00:34:31.690 --> 00:34:36.610
that the philosopher Francois
Kammerer had written about it.

00:34:36.610 --> 00:34:40.199
A couple of basic ideas about
where problem intuitions might

00:34:40.199 --> 00:34:40.699
come from.

00:34:40.699 --> 00:34:44.480
And they tried to build them
into a computational model.

00:34:47.270 --> 00:34:50.030
They built a little
software agent,

00:34:50.030 --> 00:34:53.570
which had certain axioms about
colors and how they work.

00:34:53.570 --> 00:34:55.880
There's the red and there's
green and certain axioms

00:34:55.880 --> 00:35:01.290
about their own subjective
experiences of colors.

00:35:01.290 --> 00:35:04.570
And then they combined it
with a little theorem prover.

00:35:04.570 --> 00:35:07.420
And they saw what did this
little software agent come up

00:35:07.420 --> 00:35:07.920
with.

00:35:07.920 --> 00:35:09.950
And it came up with
claims like, hey, well,

00:35:09.950 --> 00:35:13.280
my experiences of
color are distinct from

00:35:13.280 --> 00:35:15.630
any physical state, and so on.

00:35:15.630 --> 00:35:17.120
OK they cut a few corners.

00:35:17.120 --> 00:35:23.750
This is not a yet truly a
convincing sophisticated model

00:35:23.750 --> 00:35:26.040
of everything going
on in the human mind.

00:35:26.040 --> 00:35:29.490
But it shows that there's
a research program here

00:35:29.490 --> 00:35:32.300
of trying to find
the algorithmic basis

00:35:32.300 --> 00:35:33.290
of these states.

00:35:33.290 --> 00:35:35.990
And I think as more
sophisticated models develop,

00:35:35.990 --> 00:35:38.120
we might be able to use
these to kind of provide

00:35:38.120 --> 00:35:41.420
a way in for AI researchers
in thinking about this topic.

00:35:41.420 --> 00:35:43.580
Of course, there
is the question,

00:35:43.580 --> 00:35:46.370
you model all this stuff
better and better in a machine,

00:35:46.370 --> 00:35:49.735
then is the machine actually
going to be conscious

00:35:49.735 --> 00:35:51.110
or is it just
going to have found

00:35:51.110 --> 00:35:55.020
self models that replicate
what's going on in humans.

00:35:55.020 --> 00:36:00.930
So some people have proposed an
artificial consciousness test.

00:36:00.930 --> 00:36:03.450
Aaron Sloman, Susan
Schneider, Ed Turner

00:36:03.450 --> 00:36:06.540
have suggested somehow
that if a machine seems

00:36:06.540 --> 00:36:09.270
to be puzzled about
consciousness in roughly

00:36:09.270 --> 00:36:11.400
the ways that we are,
maybe that's actually

00:36:11.400 --> 00:36:13.560
a sign that it's conscious.

00:36:13.560 --> 00:36:16.980
So if a machine
actually looks to us

00:36:16.980 --> 00:36:21.072
as if it's puzzled by
consciousness, is that a sign

00:36:21.072 --> 00:36:21.780
of consciousness?

00:36:21.780 --> 00:36:24.060
These people-- this is
suggested as a kind of Turing

00:36:24.060 --> 00:36:25.730
test for machine consciousness.

00:36:25.730 --> 00:36:27.828
Find machines which are
conscious like we are.

00:36:27.828 --> 00:36:29.370
Of course, the
opposing point of view

00:36:29.370 --> 00:36:31.745
is going to be no, the machine
is not actually conscious.

00:36:31.745 --> 00:36:35.040
It's just like machine that
studied up for the Turing test

00:36:35.040 --> 00:36:36.670
by reading the talk
like a human book.

00:36:36.670 --> 00:36:39.690
It's like, damn,
do I really need

00:36:39.690 --> 00:36:41.280
to convince those
humans that I'm

00:36:41.280 --> 00:36:46.320
conscious by replicating all
those ill-conceived confusions

00:36:46.320 --> 00:36:47.260
about consciousness.

00:36:47.260 --> 00:36:50.715
Well I guess I can
do it if I need to.

00:36:50.715 --> 00:36:52.840
Anyway, I'm not going to
settle this question here.

00:36:52.840 --> 00:36:54.215
But I do think
that if we somehow

00:36:54.215 --> 00:36:58.433
find machines being puzzled,
it won't surprise me

00:36:58.433 --> 00:37:00.600
that once we actually have
serious AI systems, which

00:37:00.600 --> 00:37:03.900
engagement in natural language
and modeling of themselves

00:37:03.900 --> 00:37:07.622
and the world, they might well
find themselves saying things

00:37:07.622 --> 00:37:09.080
like, yeah, I know
in principle I'm

00:37:09.080 --> 00:37:15.020
just a set of silicon circuits,
but I feel like so much more.

00:37:15.020 --> 00:37:18.860
I think that might tell us
something about consciousness.

00:37:18.860 --> 00:37:21.950
Let me just say a little
bit about theories

00:37:21.950 --> 00:37:23.240
of consciousness.

00:37:23.240 --> 00:37:25.490
I do think a solution
to the meta-problem

00:37:25.490 --> 00:37:27.110
and a solution to
the hard problem

00:37:27.110 --> 00:37:29.120
ought to be closely connected.

00:37:29.120 --> 00:37:31.135
The illusionist has
solved the meta-problem.

00:37:31.135 --> 00:37:32.510
You'll dissolve
the hard problem.

00:37:32.510 --> 00:37:34.400
But even if you're
not an illusionist

00:37:34.400 --> 00:37:37.896
about consciousness, there
ought to be some link.

00:37:37.896 --> 00:37:39.520
So here's a thesis.

00:37:39.520 --> 00:37:44.320
Whatever explains consciousness
should also partly explain

00:37:44.320 --> 00:37:47.692
our judgments, now reports
about consciousness.

00:37:47.692 --> 00:37:49.150
The rationale here
is it would just

00:37:49.150 --> 00:37:52.270
be very strange if these
things were independent,

00:37:52.270 --> 00:37:57.330
if the basis of consciousness
played no role in our judgments

00:37:57.330 --> 00:37:59.460
about consciousness.

00:37:59.460 --> 00:38:02.640
So they can use this as a
way of evaluating or testing

00:38:02.640 --> 00:38:04.710
theories of consciousness.

00:38:04.710 --> 00:38:08.190
For theory of consciousness
says mechanism M

00:38:08.190 --> 00:38:11.520
is the basis of consciousness,
that M should also

00:38:11.520 --> 00:38:15.840
partly explain our judgments
about consciousness.

00:38:15.840 --> 00:38:18.715
Whatever the basis is ought
to explain the reports.

00:38:18.715 --> 00:38:19.590
And you can use this.

00:38:19.590 --> 00:38:23.610
You can bring this to bear
on various extant theories

00:38:23.610 --> 00:38:24.390
of consciousness.

00:38:24.390 --> 00:38:27.630
Here's one famous current
theory of consciousness,

00:38:27.630 --> 00:38:29.460
integrated information
theory developed

00:38:29.460 --> 00:38:36.330
by Giulio Tononi and colleagues
at the University of Wisconsin.

00:38:36.330 --> 00:38:38.760
Tononi says the basis
of consciousness

00:38:38.760 --> 00:38:42.330
is integrated information, a
certain kind of integration

00:38:42.330 --> 00:38:45.480
of information for
which to and he has

00:38:45.480 --> 00:38:47.580
a measure that he calls phi.

00:38:47.580 --> 00:38:51.030
Basically, when your phi is high
enough, you get consciousness.

00:38:51.030 --> 00:38:54.507
A consciousness is
high phi, and there's

00:38:54.507 --> 00:38:55.590
a mathematical definition.

00:38:55.590 --> 00:38:57.960
But I won't go into it here.

00:38:57.960 --> 00:39:00.060
But it's a really
interesting theory.

00:39:00.060 --> 00:39:02.550
So here's a-- basically
it analyzes a network

00:39:02.550 --> 00:39:05.050
property of systems of units.

00:39:05.050 --> 00:39:07.080
And it's got a
informational measure

00:39:07.080 --> 00:39:09.870
called phi that's supposed
to go with consciousness.

00:39:09.870 --> 00:39:13.350
Question, if
integrated information

00:39:13.350 --> 00:39:14.940
is the basis of
consciousness, It

00:39:14.940 --> 00:39:18.630
ought to explain problem
reports, at least in principle.

00:39:18.630 --> 00:39:20.260
Challenge, how does that work?

00:39:20.260 --> 00:39:22.140
And it's at least far
from obvious to me

00:39:22.140 --> 00:39:25.830
how integrated information will
explain the problem reports.

00:39:25.830 --> 00:39:29.280
It seems pretty
dissociated from them.

00:39:29.280 --> 00:39:32.280
On Tononi's view, you
can have simulations

00:39:32.280 --> 00:39:36.090
of systems with high
phi that have zero phi.

00:39:36.090 --> 00:39:38.640
They'll go about making
exactly the same reports

00:39:38.640 --> 00:39:40.170
but without
consciousness at all.

00:39:40.170 --> 00:39:43.140
So phi is at least
somewhat dissociable.

00:39:43.140 --> 00:39:48.185
You get systems with very high
phi, but no tendency to report.

00:39:48.185 --> 00:39:49.310
Maybe that's less worrying.

00:39:49.310 --> 00:39:51.300
Anyway, here's a
challenge for this theory,

00:39:51.300 --> 00:39:52.470
for other theories.

00:39:52.470 --> 00:39:55.170
Explain, not just how high
phi gives you consciousness,

00:39:55.170 --> 00:39:58.200
but how it plays a central
role in the algorithms that

00:39:58.200 --> 00:40:00.570
generate problem reports.

00:40:00.570 --> 00:40:02.970
Something similar goes
for many other theories,

00:40:02.970 --> 00:40:07.100
biological theories, quantum
theories, global workspace,

00:40:07.100 --> 00:40:08.820
and so on.

00:40:08.820 --> 00:40:11.150
But let me just wrap
up by saying something

00:40:11.150 --> 00:40:13.700
about the issue of
illusionism that I was

00:40:13.700 --> 00:40:15.950
talking about near the start.

00:40:15.950 --> 00:40:17.900
Again, you might be
inclined to think

00:40:17.900 --> 00:40:20.870
that this approach through
the meta-problem tends,

00:40:20.870 --> 00:40:23.090
at least very naturally,
to lead to illusionism.

00:40:23.090 --> 00:40:25.730
And I think it can be-- it
certainly provides, I think,

00:40:25.730 --> 00:40:29.750
some motivation for illusionism,
the view that consciousness

00:40:29.750 --> 00:40:32.690
doesn't exist, we
just think it does.

00:40:32.690 --> 00:40:35.630
On this view, again, a
solution to the meta-problem

00:40:35.630 --> 00:40:38.940
dissolves the hard problem.

00:40:38.940 --> 00:40:41.420
So here's one way of putting
the case for illusion.

00:40:41.420 --> 00:40:44.930
If there is a solution
to the meta-problem,

00:40:44.930 --> 00:40:48.410
then there is an explanation of
our beliefs about consciousness

00:40:48.410 --> 00:40:50.240
that's independent
of consciousness.

00:40:50.240 --> 00:40:52.557
There's an algorithm
that explains our beliefs

00:40:52.557 --> 00:40:53.390
about consciousness.

00:40:53.390 --> 00:40:54.765
It doesn't mention
consciousness.

00:40:54.765 --> 00:40:57.860
Arguably, it could be in
place without consciousness.

00:40:57.860 --> 00:41:00.740
Arguably, that
kind of explanation

00:41:00.740 --> 00:41:04.100
could debunk our beliefs about
consciousness the same way

00:41:04.100 --> 00:41:08.960
that perhaps explaining beliefs
about God in evolutionary terms

00:41:08.960 --> 00:41:10.690
might debunk belief in God.

00:41:10.690 --> 00:41:12.950
It certainly doesn't prove
that God doesn't exist.

00:41:12.950 --> 00:41:15.450
You might think that if you can
explain our beliefs in terms

00:41:15.450 --> 00:41:18.980
of evolution, it somehow
removes the justification

00:41:18.980 --> 00:41:21.300
or the rational basis
for those beliefs.

00:41:21.300 --> 00:41:23.120
So something like
that, I think, can be

00:41:23.120 --> 00:41:24.940
applied to consciousness too.

00:41:24.940 --> 00:41:27.140
And there's a lot to
be said about analyzing

00:41:27.140 --> 00:41:30.552
the extent to which this
might debunk the beliefs.

00:41:30.552 --> 00:41:32.510
On the other hand, the
case against illusionism

00:41:32.510 --> 00:41:35.447
is very, very strong
for many people.

00:41:35.447 --> 00:41:37.780
And the underlying worry is
that some of the illusionism

00:41:37.780 --> 00:41:39.800
is completely unbelievable.

00:41:39.800 --> 00:41:42.230
It's just a manifest
fact about ourselves

00:41:42.230 --> 00:41:46.280
that we have conscious
experience, we experience red,

00:41:46.280 --> 00:41:48.170
we feel pain, and so on.

00:41:48.170 --> 00:41:51.500
To deny those things
is to deny the data.

00:41:51.500 --> 00:41:53.857
No, the dielectric
here is complicated.

00:41:53.857 --> 00:41:55.940
The illusionist will come
back and say, yes, but I

00:41:55.940 --> 00:41:58.790
can explain why illusionism
is unbelievable.

00:41:58.790 --> 00:42:01.380
These models we have, these
self models of consciousness,

00:42:01.380 --> 00:42:03.470
are so strong that
they were just

00:42:03.470 --> 00:42:05.360
wired into us by evolution.

00:42:05.360 --> 00:42:07.250
They're not models
we can get rid of.

00:42:07.250 --> 00:42:10.280
So my view predicts that
my view is unbelievable.

00:42:10.280 --> 00:42:11.750
And the question is, what--

00:42:11.750 --> 00:42:15.640
the dialectical situation
is complex and interesting.

00:42:15.640 --> 00:42:19.430
But maybe I could just wrap
up with two expressions

00:42:19.430 --> 00:42:23.420
of absurdity on either side of
this question, the illusionist

00:42:23.420 --> 00:42:28.970
and the anti-illusionist,
both finding absurdity

00:42:28.970 --> 00:42:31.350
in the other person's views.

00:42:31.350 --> 00:42:34.850
Here's Galen Strawson,
who was here.

00:42:34.850 --> 00:42:37.940
Galen's view is very much that
illusionism is totally absurd.

00:42:37.940 --> 00:42:40.160
In fact, he thinks it's
the most absurd view

00:42:40.160 --> 00:42:41.770
that anyone has ever held.

00:42:41.770 --> 00:42:43.980
There occurred in
the 20th century,

00:42:43.980 --> 00:42:47.330
the most remarkable episode
in the whole history of ideas,

00:42:47.330 --> 00:42:50.360
the whole history of human
thought, a number of thinkers

00:42:50.360 --> 00:42:51.950
denied the existence
of something

00:42:51.950 --> 00:42:55.270
we know with certainty
to exist, consciousness.

00:42:55.270 --> 00:42:57.980
He thinks this is just a sign
of incredible philosophical

00:42:57.980 --> 00:43:00.390
pathology.

00:43:00.390 --> 00:43:02.970
Here's the rationalist
philosopher, Eliezer Yudkowsky,

00:43:02.970 --> 00:43:06.510
and something he wrote a
few years ago on zombies

00:43:06.510 --> 00:43:10.650
and consciousness and
the epiphenomenalist view

00:43:10.650 --> 00:43:12.990
that consciousness plays
no causal role, where

00:43:12.990 --> 00:43:16.505
he was engaging some stuff I
wrote a couple of decades ago.

00:43:16.505 --> 00:43:17.880
He said, "this
zombie argument"--

00:43:17.880 --> 00:43:20.463
the idea we can imagine zombies
physically like us but without

00:43:20.463 --> 00:43:23.340
consciousness-- "may be a
candidate for the most deranged

00:43:23.340 --> 00:43:26.460
idea in all of philosophy.

00:43:26.460 --> 00:43:29.340
The causally closed
cognitive system

00:43:29.340 --> 00:43:34.020
of trauma's internal narrative
is malfunctioning, in a way,

00:43:34.020 --> 00:43:37.620
not by necessity but just in
our own universe miraculously

00:43:37.620 --> 00:43:40.185
happens to be correct."

00:43:40.185 --> 00:43:42.060
And here he is expressing
this debunking idea

00:43:42.060 --> 00:43:44.550
that on this view,
there's an algorithm that

00:43:44.550 --> 00:43:46.570
generates these intuitions
about consciousness.

00:43:46.570 --> 00:43:47.610
And that's all physical.

00:43:47.610 --> 00:43:50.830
And there's also this further
layer of non-physical stuff.

00:43:50.830 --> 00:43:55.800
And just by massive coincidence,
the physical algorithm

00:43:55.800 --> 00:43:58.910
is a correct model of
the non-physical stuff.

00:43:58.910 --> 00:44:02.400
That's a form of debunking here.

00:44:02.400 --> 00:44:04.810
It would take a miracle for
this view to be correct.

00:44:04.810 --> 00:44:07.170
So I think both of
these views are onto--

00:44:07.170 --> 00:44:09.270
these objections
are onto something.

00:44:09.270 --> 00:44:11.880
And to make progress
on this on either side,

00:44:11.880 --> 00:44:15.020
we need to find a way of
getting past these absurdities.

00:44:15.020 --> 00:44:16.770
You might say, well,
there's middle ground

00:44:16.770 --> 00:44:19.500
between very strong
illusionism and very strong

00:44:19.500 --> 00:44:20.880
epiphenomenalism.

00:44:20.880 --> 00:44:23.880
It tends to slide back
to the same problems.

00:44:23.880 --> 00:44:27.000
Other forms of
illusionism, weaker forms

00:44:27.000 --> 00:44:29.340
don't help much with
the hard problem.

00:44:29.340 --> 00:44:32.340
Other forms of realism
are still subject to this.

00:44:32.340 --> 00:44:35.700
It takes a miracle for this
view to be correct critique.

00:44:35.700 --> 00:44:39.768
So I think to get
beyond absurdity here,

00:44:39.768 --> 00:44:41.310
both sides need to
do something more.

00:44:41.310 --> 00:44:44.970
The illusionist needs to do more
to explain how having a mind

00:44:44.970 --> 00:44:49.740
could be like this, even
though it's not at all the way

00:44:49.740 --> 00:44:51.210
that it seems.

00:44:51.210 --> 00:44:54.230
They need to find some
way to recapture the data.

00:44:54.230 --> 00:44:56.990
Realists need to
explain how it is

00:44:56.990 --> 00:45:00.110
that these meta-problem
processes are not completely

00:45:00.110 --> 00:45:01.760
independent of consciousness.

00:45:01.760 --> 00:45:04.730
Realists need to explain
how meta-problem processes,

00:45:04.730 --> 00:45:07.190
the ones that generate
these intuitions

00:45:07.190 --> 00:45:09.950
and reports and convictions
about consciousness,

00:45:09.950 --> 00:45:13.010
are essentially grounded in
consciousness even if it's

00:45:13.010 --> 00:45:16.940
possible somehow for them or
conceivable for them to occur

00:45:16.940 --> 00:45:19.610
without consciousness.

00:45:19.610 --> 00:45:22.680
Anyway so that's just to
lay out a research program.

00:45:22.680 --> 00:45:25.130
I think a solution to
the meta-problem that

00:45:25.130 --> 00:45:29.240
meets these ambitions
might just possibly solve

00:45:29.240 --> 00:45:31.100
the hard problem
of consciousness

00:45:31.100 --> 00:45:34.560
or at the very least shed
significant light on it.

00:45:34.560 --> 00:45:36.500
In the meantime,
the meta-problem

00:45:36.500 --> 00:45:39.260
is a potentially tractable
research project for everyone,

00:45:39.260 --> 00:45:40.800
and might I recommend
to all of you.

00:45:40.800 --> 00:45:41.553
Thanks.

00:45:41.553 --> 00:45:45.004
[APPLAUSE]

00:45:48.085 --> 00:45:49.460
AUDIENCE: Yes, I
just want to say

00:45:49.460 --> 00:45:53.510
I think it's very interesting,
this concept of, we have

00:45:53.510 --> 00:45:57.380
these collection
of mental models

00:45:57.380 --> 00:46:02.600
and that this collection of
mental models is consciousness,

00:46:02.600 --> 00:46:03.860
basically.

00:46:03.860 --> 00:46:05.660
Consciousness defines
the collection

00:46:05.660 --> 00:46:07.160
of these mental
models that we have.

00:46:07.160 --> 00:46:08.600
And the problem
with consciousness

00:46:08.600 --> 00:46:12.530
is that we don't understand
the physical phenomenon that

00:46:12.530 --> 00:46:15.470
causes these mental
models or that

00:46:15.470 --> 00:46:17.880
stimulates these mental models.

00:46:17.880 --> 00:46:23.120
So we just have this belief
that it's ephemeral or not real

00:46:23.120 --> 00:46:25.770
or something like that.

00:46:25.770 --> 00:46:28.730
And if you take that view,
then what's interesting

00:46:28.730 --> 00:46:34.310
is that you could simulate
these mental models like robot

00:46:34.310 --> 00:46:36.980
could simulate
these mental models.

00:46:36.980 --> 00:46:41.390
And you could simulate
consciousness as well.

00:46:41.390 --> 00:46:44.703
And even if the underlying
physical phenomena that fuels

00:46:44.703 --> 00:46:46.120
these mental models
is different--

00:46:46.120 --> 00:46:49.610
robots have different
sensors, et cetera--

00:46:49.610 --> 00:46:53.390
you could still get the
same consciousness effect

00:46:53.390 --> 00:46:54.478
in both cases.

00:46:54.478 --> 00:46:56.270
DAVID CHALMERS: Yeah,
I think that's right.

00:46:56.270 --> 00:46:59.270
Or at the very least,
it looks like you

00:46:59.270 --> 00:47:01.880
ought to be able to get the same
models, at least, in a robot.

00:47:01.880 --> 00:47:05.798
If the models themselves are
something algorithmic and ought

00:47:05.798 --> 00:47:07.340
to be, you ought to
be able to design

00:47:07.340 --> 00:47:09.380
a robot that has, at the
very least, let's say,

00:47:09.380 --> 00:47:12.845
isomorphic models and some
sense that is conscious.

00:47:12.845 --> 00:47:14.720
Of course, it's a further
question-- at least

00:47:14.720 --> 00:47:16.512
by my [? lights-- ?]
whether then the robot

00:47:16.512 --> 00:47:17.397
will be conscious.

00:47:17.397 --> 00:47:18.980
And that was the
question I alluded to

00:47:18.980 --> 00:47:21.170
in talking about the
artificial consciousness test.

00:47:21.170 --> 00:47:23.712
But you might think that would
at least be very good evidence

00:47:23.712 --> 00:47:24.890
that the robot is conscious.

00:47:24.890 --> 00:47:27.602
If it's got a model of
consciousness just like ours,

00:47:27.602 --> 00:47:29.060
it seems very
plausible there ought

00:47:29.060 --> 00:47:31.820
to be a very strong link
between having a model like that

00:47:31.820 --> 00:47:33.180
and being conscious.

00:47:33.180 --> 00:47:36.487
I think probably something
like Ned Block-- who was here

00:47:36.487 --> 00:47:38.570
arguing against machine
consciousness-- would say,

00:47:38.570 --> 00:47:40.415
no, no, the model is not enough.

00:47:40.415 --> 00:47:42.290
The model has to be
built of the right stuff.

00:47:42.290 --> 00:47:43.650
So it's gotta be
built of biology.

00:47:43.650 --> 00:47:44.010
And so on.

00:47:44.010 --> 00:47:45.500
But at by my
[? light, ?] I think

00:47:45.500 --> 00:47:49.633
if I had found an AI system
that had a very serious version

00:47:49.633 --> 00:47:51.050
of our model of
consciousness, I'd

00:47:51.050 --> 00:47:55.590
take that as a very good reason
to believe it's conscious.

00:47:55.590 --> 00:47:58.020
AUDIENCE: In the
IIT theory, is there

00:47:58.020 --> 00:48:01.890
a estimate or plausible estimate
for what the value of phi

00:48:01.890 --> 00:48:05.700
is for people and
for other systems?

00:48:05.700 --> 00:48:07.770
DAVID CHALMERS: Basically, no.

00:48:07.770 --> 00:48:14.590
It's extremely hard to measure
in systems of any size at all.

00:48:14.590 --> 00:48:16.530
Because the way it's
defined, it involves

00:48:16.530 --> 00:48:20.350
taking a sum over every
possible partition of a system.

00:48:20.350 --> 00:48:23.460
It turns out A, it's hard
to measure in the brain

00:48:23.460 --> 00:48:26.112
because you've got to involve
the causal dependencies set

00:48:26.112 --> 00:48:27.570
between different
units on neurons.

00:48:27.570 --> 00:48:30.120
But even for a pure
algorithmic system,

00:48:30.120 --> 00:48:34.560
you've got a neural network
laid out in front of you.

00:48:34.560 --> 00:48:36.630
It's computationally
intractable to measure

00:48:36.630 --> 00:48:39.690
the fire of one of those once
I get to bigger than 15 units

00:48:39.690 --> 00:48:40.798
or so.

00:48:40.798 --> 00:48:43.090
So Tononi would like to say
this is an empirical theory

00:48:43.090 --> 00:48:44.700
and in principle
empirically testable.

00:48:44.700 --> 00:48:46.500
But there's the in principle.

00:48:46.500 --> 00:48:50.220
It's extremely difficult
to measure phi.

00:48:50.220 --> 00:48:57.420
Some people, Scott Aaronson
the computer scientist,

00:48:57.420 --> 00:48:59.770
has tried to put forward
counterexamples to the theory,

00:48:59.770 --> 00:49:01.800
which were basically
very, very simple

00:49:01.800 --> 00:49:05.340
systems like matrix
multipliers that

00:49:05.340 --> 00:49:06.600
multiply two large matrices.

00:49:06.600 --> 00:49:09.060
Turn out to have
enormous phi, phi

00:49:09.060 --> 00:49:11.160
as big as you like if the
matrices are big enough

00:49:11.160 --> 00:49:13.530
and therefore by Tononi's
theory will not just

00:49:13.530 --> 00:49:15.880
be conscious, but as
conscious as a human being.

00:49:15.880 --> 00:49:18.090
And Aaronson put this
forward as a reductio ad

00:49:18.090 --> 00:49:20.040
absurdum of the IIT theory.

00:49:20.040 --> 00:49:23.130
I think Tononi basically bit
the bullet and said, oh yeah,

00:49:23.130 --> 00:49:25.590
those matrix
multipliers are actually

00:49:25.590 --> 00:49:28.920
having some high degree
of consciousness.

00:49:28.920 --> 00:49:31.620
So I think IIT is probably
at least missing a few pieces

00:49:31.620 --> 00:49:33.550
if it's going to be developed.

00:49:33.550 --> 00:49:36.170
But it's a research program too.

00:49:36.170 --> 00:49:39.200
AUDIENCE: You mentioned belief
as an example of something

00:49:39.200 --> 00:49:42.080
where there's another
mental quality,

00:49:42.080 --> 00:49:46.440
but people don't seem to
have the same sense that it

00:49:46.440 --> 00:49:47.630
is very hard to explain.

00:49:47.630 --> 00:49:50.270
In fact, it almost
seems too easy

00:49:50.270 --> 00:49:52.790
where people-- like a
belief about something

00:49:52.790 --> 00:49:55.010
sort of feels like
just how things are.

00:49:55.010 --> 00:49:57.650
But you have to
reflect on a belief

00:49:57.650 --> 00:49:59.240
to notice it as a belief.

00:49:59.240 --> 00:50:02.150
Do you think there
is also or has there

00:50:02.150 --> 00:50:05.160
been research related
to this question

00:50:05.160 --> 00:50:08.000
into why is that different?

00:50:08.000 --> 00:50:10.540
It seems like another angle
of attack on this problem.

00:50:10.540 --> 00:50:13.675
It's just like, why doesn't this
generate the same hard problem.

00:50:13.675 --> 00:50:14.550
DAVID CHALMERS: Yeah.

00:50:14.550 --> 00:50:15.967
In terms-- I'm not
sure if there's

00:50:15.967 --> 00:50:19.700
been research from the
perspective of the meta-problem

00:50:19.700 --> 00:50:20.670
or of theory of mind.

00:50:20.670 --> 00:50:23.003
Certainly, people have thought,
in their own right, what

00:50:23.003 --> 00:50:25.582
is the difference in
belief and experience

00:50:25.582 --> 00:50:26.790
that makes them so different.

00:50:26.790 --> 00:50:30.580
This goes way back to
David Hume, a philosopher

00:50:30.580 --> 00:50:34.730
a few centuries ago who said
basically, perception is vivid.

00:50:34.730 --> 00:50:36.620
Impression of
impressions and ideas.

00:50:36.620 --> 00:50:39.320
And impressions like
experiencing colors

00:50:39.320 --> 00:50:43.010
are vivid in force and
vivacity, and ideas are merely

00:50:43.010 --> 00:50:45.127
a faint copy or something.

00:50:45.127 --> 00:50:46.460
But that's just the first order.

00:50:46.460 --> 00:50:48.500
And then there are
contemporary versions

00:50:48.500 --> 00:50:51.020
of this kind of thing, far more
sophisticated ways of saying

00:50:51.020 --> 00:50:52.080
a similar thing.

00:50:52.080 --> 00:50:55.878
But yeah, you could, in
principle, explore that

00:50:55.878 --> 00:50:56.920
through the meta-problem.

00:50:56.920 --> 00:50:59.920
Why does it seem to us that
perception is so much more

00:50:59.920 --> 00:51:01.000
vivid?

00:51:01.000 --> 00:51:03.340
What about our
models of the mind

00:51:03.340 --> 00:51:05.950
makes perception seem so
much more vivid than belief

00:51:05.950 --> 00:51:09.940
and makes beliefs seem
structural and empty

00:51:09.940 --> 00:51:12.250
whereas perception
is so full of light?

00:51:12.250 --> 00:51:13.750
But no, I don't
know of work on that

00:51:13.750 --> 00:51:16.190
from the meta-problem
perspective.

00:51:16.190 --> 00:51:18.190
Like I said, there's
not that much work

00:51:18.190 --> 00:51:20.290
on these introspective
models directly.

00:51:20.290 --> 00:51:22.390
There is work on theory
of mind about beliefs.

00:51:22.390 --> 00:51:25.642
Tends to be about
models of other people.

00:51:25.642 --> 00:51:27.600
It may be there's something
I could dig through

00:51:27.600 --> 00:51:30.017
in my literature on belief
that says something about that.

00:51:30.017 --> 00:51:31.230
It's a good place to push.

00:51:31.230 --> 00:51:31.938
AUDIENCE: Thanks.

00:51:31.938 --> 00:51:33.840
AUDIENCE: I wanted to
bring up Kurt Godel.

00:51:33.840 --> 00:51:37.530
You mentioned your advisor
wrote "Godel, Escher, Bach".

00:51:37.530 --> 00:51:39.930
There's something that
seems very like Godel--

00:51:39.930 --> 00:51:43.960
Godelian or whatever about
this whole discussion in that--

00:51:43.960 --> 00:51:48.420
so Godel showed that
given a set of axioms

00:51:48.420 --> 00:51:50.490
in mathematics,
that it would either

00:51:50.490 --> 00:51:55.020
be consistent or
complete but not both.

00:51:55.020 --> 00:52:00.660
And it seems like
when Daniel Dennett--

00:52:00.660 --> 00:52:03.870
Daniel Dennett seems to have a
set of axioms where he cannot

00:52:03.870 --> 00:52:06.540
construct consciousness
from them.

00:52:06.540 --> 00:52:08.910
He seems to be very much
in this consistent camp,

00:52:08.910 --> 00:52:12.390
like he wants to have
a consistent framework

00:52:12.390 --> 00:52:15.690
but is OK with the
incompleteness.

00:52:15.690 --> 00:52:18.210
And I wonder if a
similar approach

00:52:18.210 --> 00:52:20.400
could be taken with
consciousness where

00:52:20.400 --> 00:52:22.860
we could, in fact,
prove that consciousness

00:52:22.860 --> 00:52:26.760
is independent of Daniel
Dennett's set of axioms,

00:52:26.760 --> 00:52:28.250
the same way they proved--

00:52:28.250 --> 00:52:30.990
after Godel, they proved
the Continuum Hypothesis was

00:52:30.990 --> 00:52:33.900
independent of ZF set
theory, and then they

00:52:33.900 --> 00:52:38.620
added the axiom of choice,
made it ZFC set theory.

00:52:38.620 --> 00:52:42.900
So I wonder if we could show
that in Daniel Dennett's world,

00:52:42.900 --> 00:52:47.010
we are essentially zombies or
we are either zombies or not.

00:52:47.010 --> 00:52:48.270
It doesn't matter.

00:52:48.270 --> 00:52:50.370
Either statement could be true.

00:52:50.370 --> 00:52:53.280
And then find what is
the minimum axiom that

00:52:53.280 --> 00:52:55.800
has to be added to
Dennett's axioms

00:52:55.800 --> 00:52:57.813
in order to make
consciousness true.

00:52:57.813 --> 00:52:58.980
DAVID CHALMERS: Interesting.

00:52:58.980 --> 00:53:00.240
I thought for a
moment this was going

00:53:00.240 --> 00:53:01.823
to go in a different
direction and you

00:53:01.823 --> 00:53:05.927
were going to say Dennett is
consistent but incomplete.

00:53:05.927 --> 00:53:06.510
AUDIENCE: Yes.

00:53:06.510 --> 00:53:08.360
DAVID CHALMERS: He doesn't have
consciousness in his picture.

00:53:08.360 --> 00:53:09.330
I'm complete.

00:53:09.330 --> 00:53:10.365
I've got consciousness--

00:53:10.365 --> 00:53:10.650
AUDIENCE: Yes.

00:53:10.650 --> 00:53:11.070
DAVID CHALMERS:
--but inconsistent.

00:53:11.070 --> 00:53:12.737
That's why I say all
these crazy theory.

00:53:12.737 --> 00:53:14.270
AUDIENCE: Right, yeah.

00:53:14.270 --> 00:53:16.805
DAVID CHALMERS: And you're
faced with the choice of not

00:53:16.805 --> 00:53:18.930
having consciousness and
being incomplete or having

00:53:18.930 --> 00:53:21.120
consciousness and somehow
getting this hard problem

00:53:21.120 --> 00:53:24.120
and being forced into, at
least, puzzles and paradoxes.

00:53:24.120 --> 00:53:26.100
But the way you put it
was friendlier to me.

00:53:30.370 --> 00:53:32.492
Yeah, certainly,

00:53:32.492 --> 00:53:34.200
Doug Hofstadter himself
has written a lot

00:53:34.200 --> 00:53:37.020
on analogies between
the Godelian paradoxes

00:53:37.020 --> 00:53:38.950
and the MindBody problem.

00:53:38.950 --> 00:53:41.220
And he thinks always
our self models

00:53:41.220 --> 00:53:44.710
are always doomed to be
incomplete in the Godelian way.

00:53:44.710 --> 00:53:47.250
He thinks that that might be
somehow part of the explanation

00:53:47.250 --> 00:53:49.807
of our puzzlement, at
least about consciousness.

00:53:49.807 --> 00:53:51.390
Someone like Roger
Penrose, of course,

00:53:51.390 --> 00:53:55.140
takes this much more
seriously literally.

00:53:55.140 --> 00:53:59.190
He thinks that the
computational aspects

00:53:59.190 --> 00:54:00.960
of computational
systems are always going

00:54:00.960 --> 00:54:03.090
to be limited in the Godel way.

00:54:03.090 --> 00:54:06.100
He thinks human beings
are not so limited.

00:54:06.100 --> 00:54:10.312
He thinks we've got mathematical
capacities to prove theorems,

00:54:10.312 --> 00:54:12.270
to see the truth of
certain mathematical claims

00:54:12.270 --> 00:54:16.060
that no formal system
could ever have.

00:54:16.060 --> 00:54:18.330
So he thinks that
we somehow go beyond

00:54:18.330 --> 00:54:19.372
the incomplete Godelian--

00:54:19.372 --> 00:54:21.455
I don't know if he actually
thinks we're complete,

00:54:21.455 --> 00:54:23.370
but at least we're not
incomplete in the way

00:54:23.370 --> 00:54:26.130
that finite computational
systems are incomplete.

00:54:26.130 --> 00:54:29.160
And furthermore, he
thinks that extra thing

00:54:29.160 --> 00:54:31.440
that humans have is
tied to consciousness.

00:54:31.440 --> 00:54:33.330
I never quite saw
how that last step

00:54:33.330 --> 00:54:36.690
goes, even if we didn't have
these special non-algorithmic

00:54:36.690 --> 00:54:39.030
capacities to see the truth
of mathematical theorems,

00:54:39.030 --> 00:54:41.400
how would that be
tied to consciousness.

00:54:41.400 --> 00:54:46.350
But at the very least, there
are structural analogies

00:54:46.350 --> 00:54:47.880
to be drawn between
those two cases,

00:54:47.880 --> 00:54:49.588
about incompleteness
of certain theories.

00:54:49.588 --> 00:54:51.540
How literally we should
take the analogies,

00:54:51.540 --> 00:54:54.128
I'd have to think about it.

00:54:54.128 --> 00:54:55.920
AUDIENCE: Has there
been some consideration

00:54:55.920 --> 00:54:59.610
that the problem of
understanding consciousness

00:54:59.610 --> 00:55:02.880
inherently must be difficult
because we address the problem

00:55:02.880 --> 00:55:04.810
using consciousness?

00:55:04.810 --> 00:55:08.160
I'm reminded of the halting
problem in computer science

00:55:08.160 --> 00:55:10.050
where we say that
in the general case,

00:55:10.050 --> 00:55:13.140
a program cannot be written to
tell whether another program

00:55:13.140 --> 00:55:15.510
will halt because what
if you ran it on itself.

00:55:15.510 --> 00:55:19.510
It can't be broad enough to
include its own execution.

00:55:19.510 --> 00:55:21.570
So I wonder if there
is a similar corollary

00:55:21.570 --> 00:55:24.210
in consciousness where
we use consciousness

00:55:24.210 --> 00:55:27.120
to think about consciousness
and so therefore, we

00:55:27.120 --> 00:55:32.760
may not have enough equipment
there to be able to unpack it.

00:55:32.760 --> 00:55:34.860
DAVID CHALMERS:
Yeah, it's tricky.

00:55:34.860 --> 00:55:36.930
People say it's like,
you use a ruler.

00:55:36.930 --> 00:55:37.950
To measure a ruler--

00:55:37.950 --> 00:55:40.242
well, I can do this ruler to
measure many other things.

00:55:40.242 --> 00:55:42.060
But it can't measure itself.

00:55:42.060 --> 00:55:43.020
It's not [INAUDIBLE].

00:55:43.020 --> 00:55:44.687
Well, on the other
hand, you can measure

00:55:44.687 --> 00:55:46.770
one ruler using another ruler.

00:55:46.770 --> 00:55:49.020
Maybe you can measure one
consciousness using another.

00:55:49.020 --> 00:55:51.030
The brain-- [INAUDIBLE] the
brain can't study the brain.

00:55:51.030 --> 00:55:52.905
But the brain actually
does a pretty good job

00:55:52.905 --> 00:55:55.420
of studying the brain.

00:55:55.420 --> 00:55:58.333
There are some self-referential
paradoxes there.

00:55:58.333 --> 00:56:00.000
And I think that,
again, is at the heart

00:56:00.000 --> 00:56:01.707
of Hofstadter's approach.

00:56:01.707 --> 00:56:03.540
But I think we'd have
to look for very, very

00:56:03.540 --> 00:56:07.050
specific conditions under which
systems can't study themselves.

00:56:07.050 --> 00:56:11.190
I did always like the idea that
if the mind was simple enough

00:56:11.190 --> 00:56:13.740
that we could understand
it, we would be too

00:56:13.740 --> 00:56:16.750
simple to understand the mind.

00:56:16.750 --> 00:56:19.250
So maybe something like that
could be true of consciousness.

00:56:19.250 --> 00:56:20.130
On the other hand,
I actually think

00:56:20.130 --> 00:56:22.850
that if you start thinking
that consciousness can go along

00:56:22.850 --> 00:56:25.552
with very simple systems,
I think at the very least,

00:56:25.552 --> 00:56:28.010
we ought to be able to study
consciousness in other systems

00:56:28.010 --> 00:56:29.970
simpler than ourselves.

00:56:29.970 --> 00:56:33.110
And boy, if I could solve the
hard problem even in dogs,

00:56:33.110 --> 00:56:33.857
I'd be satisfied.

00:56:33.857 --> 00:56:34.357
Yeah?

00:56:34.357 --> 00:56:37.160
AUDIENCE: Hey, so I have
a question about how

00:56:37.160 --> 00:56:41.150
the meta-problem research
program might proceed,

00:56:41.150 --> 00:56:43.410
sort of related to
the last question.

00:56:43.410 --> 00:56:48.323
So certainly things we believe
about our own consciousness,

00:56:48.323 --> 00:56:50.240
even if we all say them,
probably some of them

00:56:50.240 --> 00:56:51.440
are false.

00:56:51.440 --> 00:56:55.970
Our brain has a tendency to
hide what reality is like.

00:56:55.970 --> 00:56:57.600
If you look at
visual perception,

00:56:57.600 --> 00:57:00.140
there's what's called
lightness constancy.

00:57:00.140 --> 00:57:02.860
Our brain subtracts out the
lighting in the environments

00:57:02.860 --> 00:57:07.070
so we actually see more reliably
what the color of objects are.

00:57:07.070 --> 00:57:09.830
Like these viral examples
of the black and gold dress

00:57:09.830 --> 00:57:10.903
is an example of this.

00:57:10.903 --> 00:57:13.070
And when you're presented
with an explanation of it,

00:57:13.070 --> 00:57:14.540
it's like, huh?

00:57:14.540 --> 00:57:15.680
My brain does that?

00:57:15.680 --> 00:57:18.290
It's not something
we have access to.

00:57:18.290 --> 00:57:19.453
Or Yani Laurel--

00:57:19.453 --> 00:57:20.870
DAVID CHALMERS:
Laurel Yani, yeah.

00:57:20.870 --> 00:57:22.040
AUDIENCE: --illusion
is another one

00:57:22.040 --> 00:57:24.310
where when you hear the
explanation, the scientists

00:57:24.310 --> 00:57:27.080
that understand it, our
own introspection doesn't

00:57:27.080 --> 00:57:27.900
include that.

00:57:27.900 --> 00:57:31.442
So how do you
proceed with trying

00:57:31.442 --> 00:57:32.900
to get at what
consciousness really

00:57:32.900 --> 00:57:37.820
is versus what our whatever
simplified or distorted view

00:57:37.820 --> 00:57:38.730
might be?

00:57:38.730 --> 00:57:40.730
DAVID CHALMERS: Yeah, I
think well one view here

00:57:40.730 --> 00:57:45.320
would be that we never have
access to the mechanisms that

00:57:45.320 --> 00:57:47.930
generate consciousness,
but we still

00:57:47.930 --> 00:57:50.120
have access to the
conscious states themselves.

00:57:50.120 --> 00:57:52.470
Actually, Karl Lashley
said this decades ago.

00:57:52.470 --> 00:57:55.400
He said no process of the
brain is ever conscious.

00:57:55.400 --> 00:57:58.910
The processes that get you to
the states are never conscious.

00:57:58.910 --> 00:58:00.880
The states they get
you to are conscious.

00:58:00.880 --> 00:58:03.020
So take your experience
of the dress.

00:58:03.020 --> 00:58:07.290
For me, it was white and gold.

00:58:07.290 --> 00:58:08.040
So I knew that.

00:58:08.040 --> 00:58:11.582
Each of us was
certain that I am--

00:58:11.582 --> 00:58:13.790
I was certain that I was
experiencing white and gold.

00:58:13.790 --> 00:58:15.290
Maybe you were
certainly you were

00:58:15.290 --> 00:58:16.740
experiencing blue and black.

00:58:16.740 --> 00:58:17.150
AUDIENCE: I forget which it was.

00:58:17.150 --> 00:58:18.725
All I remember is I was right.

00:58:18.725 --> 00:58:20.210
[LAUGHTER]

00:58:20.210 --> 00:58:23.090
DAVID CHALMERS: You were
sure that, yeah, those idiots

00:58:23.090 --> 00:58:27.285
can't be looking at this right.

00:58:27.285 --> 00:58:29.410
I think the natural way to
describe this, at least,

00:58:29.410 --> 00:58:31.520
is that each of us
was certain what kind

00:58:31.520 --> 00:58:34.700
of conscious experience we were
having, but what we had no idea

00:58:34.700 --> 00:58:37.000
about was the mechanisms
by which we got there.

00:58:37.000 --> 00:58:39.290
So the mechanisms are
completely opaque.

00:58:39.290 --> 00:58:41.510
But the states themselves
were at least prima

00:58:41.510 --> 00:58:42.483
facie transparent.

00:58:42.483 --> 00:58:44.150
I think that would
be the standard view.

00:58:44.150 --> 00:58:46.258
Even a realist
about consciousness

00:58:46.258 --> 00:58:47.050
could go with that.

00:58:47.050 --> 00:58:48.425
They'd say we know
what conscious

00:58:48.425 --> 00:58:50.720
states where we know what
those conscious states are.

00:58:50.720 --> 00:58:53.390
We don't know the processes
by which they are generated.

00:58:53.390 --> 00:58:55.640
The illusionist, I think,
wants to go much further

00:58:55.640 --> 00:58:58.590
and say, well it seems
to you that you know what

00:58:58.590 --> 00:58:59.840
conscious state you're having.

00:58:59.840 --> 00:59:03.760
It seem to you that you're
experiencing yellow and gold.

00:59:03.760 --> 00:59:06.140
Sorry, yellow and
white, whatever it was.

00:59:06.140 --> 00:59:06.890
Gold and white.

00:59:06.890 --> 00:59:08.240
AUDIENCE: Black and
gold is what I remember.

00:59:08.240 --> 00:59:09.770
DAVID CHALMERS: No, black
and blue, I think, and--

00:59:09.770 --> 00:59:10.395
AUDIENCE: Blue?

00:59:10.395 --> 00:59:13.005
DAVID CHALMERS:
--gold and white.

00:59:13.005 --> 00:59:15.130
It seems to you you're
experiencing gold and white.

00:59:15.130 --> 00:59:17.930
But, in fact, that too is
just something thrown up

00:59:17.930 --> 00:59:18.780
by another model.

00:59:18.780 --> 00:59:20.978
The yellow gold was
a perceptual model.

00:59:20.978 --> 00:59:22.520
Then there was an
introspective model

00:59:22.520 --> 00:59:25.400
that said you are experiencing
gold and white when maybe,

00:59:25.400 --> 00:59:26.678
in fact, you're just a zombie.

00:59:26.678 --> 00:59:28.220
Or who knows what's
actually going on

00:59:28.220 --> 00:59:29.090
in your conscious state.

00:59:29.090 --> 00:59:30.500
So the illusionist
view, I think,

00:59:30.500 --> 00:59:33.500
has to somehow take this further
and say, not just the processes

00:59:33.500 --> 00:59:35.570
that generate the
conscious states, but maybe

00:59:35.570 --> 00:59:38.190
the conscious states themselves
are somehow opaque to us.

00:59:42.130 --> 00:59:44.950
AUDIENCE: It feels
like some discussion

00:59:44.950 --> 00:59:49.090
of generality of a problem is
missing from this discussion.

00:59:49.090 --> 00:59:53.110
The matrix multiplier example
of having high phi is still--

00:59:53.110 --> 00:59:54.670
it's not a general thing.

00:59:54.670 --> 00:59:58.120
Is there someone exploring
the space, the intersection

00:59:58.120 --> 01:00:01.300
of generality and complexity
that leads to consciousness

01:00:01.300 --> 01:00:03.280
as an emergent behavior?

01:00:03.280 --> 01:00:05.230
DAVID CHALMERS: When
you say generality,

01:00:05.230 --> 01:00:07.300
there's the idea that a theory
should be general, that it

01:00:07.300 --> 01:00:08.508
should apply to every system.

01:00:08.508 --> 01:00:09.640
You mean mechanisms?

01:00:09.640 --> 01:00:11.300
AUDIENCE: Generality
of the agent.

01:00:11.300 --> 01:00:13.780
If I can write an
arbitrarily complex program

01:00:13.780 --> 01:00:16.300
to play tic-tac-toe and all
it will ever be able to do

01:00:16.300 --> 01:00:18.370
is play tic-tac-toe,
it has no outputs

01:00:18.370 --> 01:00:20.560
to express anything else.

01:00:20.560 --> 01:00:21.480
DAVID CHALMERS: Yeah.

01:00:21.480 --> 01:00:25.300
So general in the sense
of AGI, artificial general

01:00:25.300 --> 01:00:26.620
intelligence.

01:00:26.620 --> 01:00:28.240
Some aspects of
consciousness seem

01:00:28.240 --> 01:00:31.060
to be domain general
like for example,

01:00:31.060 --> 01:00:33.678
maybe insofar as belief
and reasoning is conscious.

01:00:33.678 --> 01:00:34.720
Those are domain general.

01:00:34.720 --> 01:00:37.680
But much of perception doesn't
seem especially domain general.

01:00:37.680 --> 01:00:38.180
Right?

01:00:38.180 --> 01:00:39.850
Color is very domain.

01:00:39.850 --> 01:00:41.650
Taste is very domain specific.

01:00:41.650 --> 01:00:42.670
So it's still conscious.

01:00:42.670 --> 01:00:46.540
AUDIENCE: But if my agent can't
express problem statements,

01:00:46.540 --> 01:00:48.940
like if I don't give it an
output by which it can express

01:00:48.940 --> 01:00:50.315
problem statements,
you can never

01:00:50.315 --> 01:00:52.653
come to a conclusion
about its consciousness.

01:00:52.653 --> 01:00:54.820
DAVID CHALMERS: I'd like
to distinguish intelligence

01:00:54.820 --> 01:00:56.560
and consciousness
and even be able to--

01:00:56.560 --> 01:01:00.665
even natural language and
being able to address a problem

01:01:00.665 --> 01:01:02.290
statement and analyze
a problem, that's

01:01:02.290 --> 01:01:06.700
already a very advanced
form of intelligence.

01:01:06.700 --> 01:01:09.770
I think it is very
plausible that a mouse has

01:01:09.770 --> 01:01:12.670
got some kind of consciousness,
even though it's got no ability

01:01:12.670 --> 01:01:16.270
to address problem statements,
and many of its capacities

01:01:16.270 --> 01:01:17.860
may be very specialized.

01:01:17.860 --> 01:01:20.530
It's still much more general
than a simple neural network

01:01:20.530 --> 01:01:22.030
that can only do one thing.

01:01:22.030 --> 01:01:23.360
A mouse can do many things.

01:01:23.360 --> 01:01:26.318
But I'm not sure that
I see an essential--

01:01:26.318 --> 01:01:28.360
I certainly see a connection
between intelligence

01:01:28.360 --> 01:01:29.110
and generality.

01:01:29.110 --> 01:01:32.740
We want to say somehow a
high degree of generality is

01:01:32.740 --> 01:01:34.640
required for high intelligence.

01:01:34.640 --> 01:01:37.640
I'm not sure there's the same
connection for consciousness.

01:01:37.640 --> 01:01:40.390
I think consciousness can
be extremely domain-specific

01:01:40.390 --> 01:01:43.750
as a taste and maybe vision are.

01:01:43.750 --> 01:01:45.580
Or it can be domain-general.

01:01:45.580 --> 01:01:47.740
So maybe those two across
cut each other a bit.

01:01:51.410 --> 01:01:55.280
AUDIENCE: So it seems to me
like the meta-problem as it's

01:01:55.280 --> 01:01:58.970
formulated implies some
amount of separation

01:01:58.970 --> 01:02:03.230
or epiphenomenalism between
consciousness and brain states.

01:02:03.230 --> 01:02:07.580
And one thing that I
think underlies a lot

01:02:07.580 --> 01:02:09.770
of people's motivation
to do science

01:02:09.770 --> 01:02:13.370
is that it has causal import.

01:02:13.370 --> 01:02:16.340
Like predicting
behaviors is clearly

01:02:16.340 --> 01:02:18.330
a functionally
useful thing to do,

01:02:18.330 --> 01:02:20.960
and if you can predict
all of behavior

01:02:20.960 --> 01:02:23.030
without having to
explain consciousness,

01:02:23.030 --> 01:02:25.820
their motivation for
explaining consciousness sort

01:02:25.820 --> 01:02:28.940
of evaporates and it
feels like, yeah, well,

01:02:28.940 --> 01:02:31.190
what's the point of
even thinking about

01:02:31.190 --> 01:02:34.880
that because it's just not
going to do anything for me.

01:02:34.880 --> 01:02:37.105
What do you say to someone
when they say that to you?

01:02:37.105 --> 01:02:38.480
DAVID CHALMERS:
What is the thing

01:02:38.480 --> 01:02:39.605
that they said to me again?

01:02:39.605 --> 01:02:42.590
AUDIENCE: That maybe
consciousness exists,

01:02:42.590 --> 01:02:43.500
maybe it doesn't.

01:02:43.500 --> 01:02:46.130
But if I can explain
all of human behavior

01:02:46.130 --> 01:02:48.200
and all of the behavior
of the world in general

01:02:48.200 --> 01:02:50.840
without recourse
to such concepts,

01:02:50.840 --> 01:02:52.520
then I've done
everything that there

01:02:52.520 --> 01:02:55.250
is that's useful, like
explaining consciousness

01:02:55.250 --> 01:02:57.680
isn't a useful thing to do.

01:02:57.680 --> 01:03:00.003
And thus, I'm not interested
in this, and it may--

01:03:00.003 --> 01:03:00.920
DAVID CHALMERS: I see.

01:03:00.920 --> 01:03:02.253
AUDIENCE: --as well not be real.

01:03:03.798 --> 01:03:06.090
DAVID CHALMERS: I think
epiphenomenalism could be true.

01:03:06.090 --> 01:03:07.920
I certainly don't have any
commitment to it, though.

01:03:07.920 --> 01:03:10.050
It's quite possible that
consciousness has a role

01:03:10.050 --> 01:03:13.420
to play in generating behavior
that we don't yet understand.

01:03:13.420 --> 01:03:16.440
And maybe thinking hard
about the meta-problem

01:03:16.440 --> 01:03:18.977
can help us get
clearer on those roles.

01:03:18.977 --> 01:03:21.060
I think if you've got any
sympathy to panpsychism,

01:03:21.060 --> 01:03:22.435
maybe consciousness
is intimately

01:03:22.435 --> 01:03:24.390
involved with how
physical processes get

01:03:24.390 --> 01:03:26.590
going in the first place.

01:03:26.590 --> 01:03:28.290
And there are people
who want to pursue

01:03:28.290 --> 01:03:30.210
interactionist ideas
where consciousness

01:03:30.210 --> 01:03:31.600
interacts with the brain.

01:03:31.600 --> 01:03:33.540
Or if you're a
reductionist, consciousness

01:03:33.540 --> 01:03:35.520
may be just a matter
of the right algorithm.

01:03:35.520 --> 01:03:37.770
In all those views,
consciousness

01:03:37.770 --> 01:03:39.130
may have some role to play.

01:03:39.130 --> 01:03:40.920
But just say it
turns out that you

01:03:40.920 --> 01:03:43.950
can explain all of behavior,
including these problems,

01:03:43.950 --> 01:03:47.340
without bringing
in consciousness.

01:03:47.340 --> 01:03:49.380
Does that mean that
consciousness is not

01:03:49.380 --> 01:03:51.330
something we should care about
and not something that matters?

01:03:51.330 --> 01:03:52.890
I don't think that would follow.

01:03:52.890 --> 01:03:55.307
Maybe it wouldn't matter for
certain engineering purposes,

01:03:55.307 --> 01:03:58.220
say you want to build
a useful system.

01:03:58.220 --> 01:04:01.020
But at least in my
view, consciousness

01:04:01.020 --> 01:04:02.740
is really the only
thing that matters.

01:04:02.740 --> 01:04:05.230
It's the thing that
makes life worth living.

01:04:05.230 --> 01:04:08.710
It's what gives our lives
meaning and value and so on.

01:04:08.710 --> 01:04:11.910
So it might turn out
that consciousness is not

01:04:11.910 --> 01:04:14.460
that useful for
explaining other stuff.

01:04:14.460 --> 01:04:17.400
But if it's the source
of intrinsic significance

01:04:17.400 --> 01:04:19.510
in the world, then
understanding consciousness

01:04:19.510 --> 01:04:22.420
would still be absolutely
essential to understanding

01:04:22.420 --> 01:04:22.920
ourselves.

01:04:22.920 --> 01:04:25.800
Furthermore, if it comes
to developing other systems

01:04:25.800 --> 01:04:30.090
like AI systems or dealing with
non-human animals and so on,

01:04:30.090 --> 01:04:31.480
we absolutely want to know.

01:04:31.480 --> 01:04:34.665
We need to know whether they're
conscious because if they're

01:04:34.665 --> 01:04:36.540
conscious, they presumably
have moral status.

01:04:36.540 --> 01:04:41.040
If they can suffer, then it's
very bad to mistreat them.

01:04:41.040 --> 01:04:42.930
If they're not conscious,
then you might--

01:04:42.930 --> 01:04:45.570
I think it's very plausible--
treat non-conscious systems,

01:04:45.570 --> 01:04:47.160
we can treat how we like.

01:04:47.160 --> 01:04:49.170
And it doesn't really
matter morally.

01:04:49.170 --> 01:04:52.350
So the question of whether an
AI system is conscious or not

01:04:52.350 --> 01:04:55.260
is going to be absolutely vital
for how we interact with it

01:04:55.260 --> 01:04:57.120
and how we build our society.

01:04:57.120 --> 01:04:59.120
That's not a question of
engineering usefulness.

01:04:59.120 --> 01:05:01.020
It's a question of
connecting with our most

01:05:01.020 --> 01:05:02.382
fundamental values.

01:05:02.382 --> 01:05:03.840
AUDIENCE: Yeah, I
completely agree.

01:05:03.840 --> 01:05:06.400
I just-- I haven't
found that formulation

01:05:06.400 --> 01:05:09.650
to be very convincing
to others necessarily.

01:05:09.650 --> 01:05:11.760
AUDIENCE: Hi, thanks
so much for coming

01:05:11.760 --> 01:05:14.490
and chatting with us today.

01:05:14.490 --> 01:05:17.550
I'm really interested in
some of your earlier work,

01:05:17.550 --> 01:05:20.340
the extended mind
[? distributed ?] cognition.

01:05:20.340 --> 01:05:22.410
And you're at a company
speaking with a bunch

01:05:22.410 --> 01:05:25.105
of people who do an incredibly
cognitively demanding task.

01:05:25.105 --> 01:05:25.980
DAVID CHALMERS: Yeah.

01:05:25.980 --> 01:05:29.310
AUDIENCE: Most of the literature
that I've read on this topic

01:05:29.310 --> 01:05:31.230
uses relatively
simple examples saying

01:05:31.230 --> 01:05:35.130
like it's difficult
to think just

01:05:35.130 --> 01:05:38.310
inside your head on these
relatively simple things.

01:05:38.310 --> 01:05:40.740
And if you take a look at
the programs that we build,

01:05:40.740 --> 01:05:44.140
on a mundane day-to-day basis,
they're millions of lines long.

01:05:44.140 --> 01:05:46.590
I've read people in
the past say something

01:05:46.590 --> 01:05:49.860
like the Boeing 777 was
the most complicated thing

01:05:49.860 --> 01:05:52.740
that human beings have ever
made, and I think most of us

01:05:52.740 --> 01:05:55.440
would look at that and
say, we got that beat.

01:05:55.440 --> 01:05:57.990
The things that large
internet companies do,

01:05:57.990 --> 01:06:00.393
the size, the complexity
of that is staggering.

01:06:00.393 --> 01:06:02.310
And yet if we close our
eyes, everyone in here

01:06:02.310 --> 01:06:04.518
is going to say, I'm going
to have difficulty writing

01:06:04.518 --> 01:06:07.080
a 10 line program in my head.

01:06:07.080 --> 01:06:09.270
So I've just sort
of, as an open,

01:06:09.270 --> 01:06:12.600
I'd be very interested in
hearing your thoughts about how

01:06:12.600 --> 01:06:16.500
the activity of programming
connects to the extended mind

01:06:16.500 --> 01:06:17.075
ideas.

01:06:17.075 --> 01:06:18.700
DAVID CHALMERS: Yeah,
so this, I guess,

01:06:18.700 --> 01:06:21.300
is a reference to
something that I

01:06:21.300 --> 01:06:23.010
got started in
about 20 years ago

01:06:23.010 --> 01:06:25.110
with my colleague, Andy Clark.

01:06:25.110 --> 01:06:28.710
We wrote an article called
"The Extended Mind" about how

01:06:28.710 --> 01:06:31.890
processes in the mind can
extend outside the brain

01:06:31.890 --> 01:06:33.870
when we become
coupled to our tools.

01:06:33.870 --> 01:06:35.700
And actually, our
central example

01:06:35.700 --> 01:06:39.780
back then in the mid-90s was a
notebook, someone writing stuff

01:06:39.780 --> 01:06:40.390
in a notebook.

01:06:40.390 --> 01:06:42.870
And even then, we knew
about the internet,

01:06:42.870 --> 01:06:44.940
and we had some
internet examples.

01:06:44.940 --> 01:06:46.835
I guess this company
didn't exist yet in '95.

01:06:49.735 --> 01:06:51.360
But now, of course,
our minds have just

01:06:51.360 --> 01:06:52.620
become more and more extended.

01:06:52.620 --> 01:06:57.000
And smartphones came
along a few years later,

01:06:57.000 --> 01:06:59.912
and everyone is coupled
very, very closely

01:06:59.912 --> 01:07:02.370
to their phones and their other
devices that couple of them

01:07:02.370 --> 01:07:05.900
very, very closely
to the internet.

01:07:05.900 --> 01:07:08.970
Now it's suddenly the case
that a whole lot of my memory

01:07:08.970 --> 01:07:13.860
is now offloaded onto the
servers of your company

01:07:13.860 --> 01:07:18.680
somewhere or other, whether
it's in the mail systems

01:07:18.680 --> 01:07:23.270
or navigation mapping
systems or other systems.

01:07:23.270 --> 01:07:26.810
Yeah, most of my navigation
has been offloaded to maps.

01:07:26.810 --> 01:07:29.420
And much of my memory
[INAUDIBLE] has been offloaded.

01:07:29.420 --> 01:07:31.020
Well, maybe that's in my phone.

01:07:31.020 --> 01:07:37.400
But other bits of my memory are
offloaded into my file system

01:07:37.400 --> 01:07:40.880
on some cloud service.

01:07:40.880 --> 01:07:45.750
So certainly, yeah,
vast amounts of my mind

01:07:45.750 --> 01:07:48.735
are now existing in the cloud.

01:07:48.735 --> 01:07:51.110
And if I were somehow to lose
access to those completely,

01:07:51.110 --> 01:07:56.480
then I'd lose an awful
lot of my capacities.

01:07:56.480 --> 01:08:00.930
So I think now we are now
extending into the cloud

01:08:00.930 --> 01:08:02.573
thanks to you guys and others.

01:08:02.573 --> 01:08:04.490
The question's specifically
about programming.

01:08:07.010 --> 01:08:10.053
Programming is a kind of active
interaction with our devices.

01:08:10.053 --> 01:08:11.720
I mean, I think
programming is something

01:08:11.720 --> 01:08:13.500
that takes a little bit longer.

01:08:13.500 --> 01:08:17.420
It's a longer timescale so the
core cases of the extended mind

01:08:17.420 --> 01:08:20.420
involve automatic use
of our devices, which

01:08:20.420 --> 01:08:22.130
are always ready to hand.

01:08:22.130 --> 01:08:24.529
We can use them to
get information,

01:08:24.529 --> 01:08:27.899
to act in the moment,
which is the kind of thing

01:08:27.899 --> 01:08:30.220
that the brain does.

01:08:30.220 --> 01:08:33.029
So insofar as programming
is a slower process--

01:08:33.029 --> 01:08:35.760
and I remember from
my programming days,

01:08:35.760 --> 01:08:42.710
all the endless hours
of debugging and so on--

01:08:42.710 --> 01:08:44.850
then it's at least going
to be a slower timescale

01:08:44.850 --> 01:08:45.960
for the extended mind.

01:08:45.960 --> 01:08:49.740
But still, Feynman talked
about writing this way.

01:08:49.740 --> 01:08:55.149
Someone looked at Feynman's
work and a bunch of notes

01:08:55.149 --> 01:08:57.670
he had about a physics
problem he was thinking about.

01:08:57.670 --> 01:08:59.700
And someone said to
him, oh it's nice you

01:08:59.700 --> 01:09:02.220
have this record of your work.

01:09:02.220 --> 01:09:05.479
And Feynman said, that's
not a record of my work.

01:09:05.479 --> 01:09:07.000
That's the work.

01:09:07.000 --> 01:09:08.337
That is the thinking.

01:09:08.337 --> 01:09:09.670
I was writing it down and so on.

01:09:09.670 --> 01:09:11.710
I think, at least
my recollection

01:09:11.710 --> 01:09:14.710
from my programming days,
is that when you're actually

01:09:14.710 --> 01:09:19.090
writing a program, it's not like
you just do a bunch of thinking

01:09:19.090 --> 01:09:21.399
and then code your thoughts.

01:09:21.399 --> 01:09:24.210
The programming is to some
very considerable extent

01:09:24.210 --> 01:09:25.460
your thinking.

01:09:25.460 --> 01:09:27.146
So is that the sort
of thing you're--

01:09:27.146 --> 01:09:28.229
AUDIENCE: Yes, absolutely.

01:09:28.229 --> 01:09:34.029
[INTERPOSING VOICES] If we, I
think as people that program,

01:09:34.029 --> 01:09:38.939
start to reflect on what we do,
and very few of us actually--

01:09:38.939 --> 01:09:40.960
if you're the tech
lead of a system,

01:09:40.960 --> 01:09:43.021
maybe you've got
it in your head.

01:09:43.021 --> 01:09:45.479
But you would agree that most
of the people on the team who

01:09:45.479 --> 01:09:47.020
have come more
recently only have

01:09:47.020 --> 01:09:48.370
a chunk of it in their head.

01:09:48.370 --> 01:09:50.649
And yet, they're somehow
still able to contribute.

01:09:50.649 --> 01:09:51.691
DAVID CHALMERS: Oh, yeah.

01:09:51.691 --> 01:09:54.430
This is now
distributed cognition.

01:09:54.430 --> 01:09:56.380
The extended mind,
the extended cognition

01:09:56.380 --> 01:10:01.600
starts with an individual and
then extends their capacities

01:10:01.600 --> 01:10:05.030
out using their tools or their
devices or even other people.

01:10:05.030 --> 01:10:07.060
So maybe my partner
serves as my memory,

01:10:07.060 --> 01:10:09.102
but it's still centered
on an individual.

01:10:09.102 --> 01:10:10.810
But then there's the
closely related case

01:10:10.810 --> 01:10:12.550
of distributed
cognition, where you

01:10:12.550 --> 01:10:16.630
have a team of people who are
doing something and making

01:10:16.630 --> 01:10:19.450
joint decisions and carrying out
joint actions in an absolutely

01:10:19.450 --> 01:10:20.020
seamless way.

01:10:20.020 --> 01:10:21.700
And I take it at a
company like this,

01:10:21.700 --> 01:10:23.575
there are going to be
any number of instances

01:10:23.575 --> 01:10:24.950
of distributed cognition.

01:10:24.950 --> 01:10:27.340
I don't know whether
the company as a whole

01:10:27.340 --> 01:10:30.080
has one giant
Google mind or maybe

01:10:30.080 --> 01:10:33.490
there's just a near infinite
number of separate Google

01:10:33.490 --> 01:10:38.523
minds for all the individual
teams and divisions.

01:10:38.523 --> 01:10:40.690
But I think probably some
anthropologist has already

01:10:40.690 --> 01:10:43.120
done a definitive
analysis of distributed

01:10:43.120 --> 01:10:44.720
cognition in this company.

01:10:44.720 --> 01:10:46.740
But if they haven't,
they certainly need to.

01:10:46.740 --> 01:10:48.180
AUDIENCE: Thank you.

01:10:48.180 --> 01:10:51.530
[APPLAUSE]

