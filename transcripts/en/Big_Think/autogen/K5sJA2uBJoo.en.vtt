WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.200
I see no obstacle to computers

00:00:03.200 --> 00:00:03.210
I see no obstacle to computers
 

00:00:03.210 --> 00:00:06.590
I see no obstacle to computers
eventually becoming conscious in some

00:00:06.590 --> 00:00:06.600
eventually becoming conscious in some
 

00:00:06.600 --> 00:00:09.549
eventually becoming conscious in some
sense that'll be a fascinating

00:00:09.549 --> 00:00:09.559
sense that'll be a fascinating
 

00:00:09.559 --> 00:00:12.140
sense that'll be a fascinating
experience on as a physicist I want to

00:00:12.140 --> 00:00:12.150
experience on as a physicist I want to
 

00:00:12.150 --> 00:00:14.450
experience on as a physicist I want to
know if those computers do physics the

00:00:14.450 --> 00:00:14.460
know if those computers do physics the
 

00:00:14.460 --> 00:00:16.760
know if those computers do physics the
same way humans do physics and there's

00:00:16.760 --> 00:00:16.770
same way humans do physics and there's
 

00:00:16.770 --> 00:00:19.099
same way humans do physics and there's
no doubt that those machines will be

00:00:19.099 --> 00:00:19.109
no doubt that those machines will be
 

00:00:19.109 --> 00:00:24.710
no doubt that those machines will be
able to evolve computationally

00:00:24.710 --> 00:00:24.720
able to evolve computationally
 

00:00:24.720 --> 00:00:26.269
able to evolve computationally
potentially to faster rate than humans

00:00:26.269 --> 00:00:26.279
potentially to faster rate than humans
 

00:00:26.279 --> 00:00:31.150
potentially to faster rate than humans
and in the long term the the ultimate

00:00:31.150 --> 00:00:31.160
and in the long term the the ultimate
 

00:00:31.160 --> 00:00:33.350
and in the long term the the ultimate
highest forms of consciousness on the

00:00:33.350 --> 00:00:33.360
highest forms of consciousness on the
 

00:00:33.360 --> 00:00:37.010
highest forms of consciousness on the
planet may not be purely biological but

00:00:37.010 --> 00:00:37.020
planet may not be purely biological but
 

00:00:37.020 --> 00:00:39.200
planet may not be purely biological but
that's not necessarily a bad thing we

00:00:39.200 --> 00:00:39.210
that's not necessarily a bad thing we
 

00:00:39.210 --> 00:00:41.270
that's not necessarily a bad thing we
always present computers as if they

00:00:41.270 --> 00:00:41.280
always present computers as if they
 

00:00:41.280 --> 00:00:45.040
always present computers as if they
don't have capabilities of empathy or

00:00:45.040 --> 00:00:45.050
don't have capabilities of empathy or
 

00:00:45.050 --> 00:00:47.450
don't have capabilities of empathy or
emotion but I would think that any

00:00:47.450 --> 00:00:47.460
emotion but I would think that any
 

00:00:47.460 --> 00:00:49.670
emotion but I would think that any
intelligent machine would ultimately

00:00:49.670 --> 00:00:49.680
intelligent machine would ultimately
 

00:00:49.680 --> 00:00:51.860
intelligent machine would ultimately
have experience that it's a learning

00:00:51.860 --> 00:00:51.870
have experience that it's a learning
 

00:00:51.870 --> 00:00:53.240
have experience that it's a learning
machine and ultimately it would learn

00:00:53.240 --> 00:00:53.250
machine and ultimately it would learn
 

00:00:53.250 --> 00:00:54.860
machine and ultimately it would learn
from its experience like like a

00:00:54.860 --> 00:00:54.870
from its experience like like a
 

00:00:54.870 --> 00:00:57.229
from its experience like like a
biological conscious being and therefore

00:00:57.229 --> 00:00:57.239
biological conscious being and therefore
 

00:00:57.239 --> 00:00:58.760
biological conscious being and therefore
it's hard for me to believe that it

00:00:58.760 --> 00:00:58.770
it's hard for me to believe that it
 

00:00:58.770 --> 00:01:02.599
it's hard for me to believe that it
would not be able to have many of the

00:01:02.599 --> 00:01:02.609
would not be able to have many of the
 

00:01:02.609 --> 00:01:04.160
would not be able to have many of the
characteristics that we now associate

00:01:04.160 --> 00:01:04.170
characteristics that we now associate
 

00:01:04.170 --> 00:01:04.850
characteristics that we now associate
with being human

00:01:04.850 --> 00:01:04.860
with being human
 

00:01:04.860 --> 00:01:07.670
with being human
Elon Musk and others who are expressed

00:01:07.670 --> 00:01:07.680
Elon Musk and others who are expressed
 

00:01:07.680 --> 00:01:09.109
Elon Musk and others who are expressed
concern is Stephen Hawking our friends

00:01:09.109 --> 00:01:09.119
concern is Stephen Hawking our friends
 

00:01:09.119 --> 00:01:12.050
concern is Stephen Hawking our friends
of mine and I understand their potential

00:01:12.050 --> 00:01:12.060
of mine and I understand their potential
 

00:01:12.060 --> 00:01:15.020
of mine and I understand their potential
concerns but I'm frankly not as

00:01:15.020 --> 00:01:15.030
concerns but I'm frankly not as
 

00:01:15.030 --> 00:01:16.700
concerns but I'm frankly not as
concerned about AI in the near term

00:01:16.700 --> 00:01:16.710
concerned about AI in the near term
 

00:01:16.710 --> 00:01:18.830
concerned about AI in the near term
it'll very least as many many of my

00:01:18.830 --> 00:01:18.840
it'll very least as many many of my
 

00:01:18.840 --> 00:01:20.870
it'll very least as many many of my
friends and colleagues are it's far less

00:01:20.870 --> 00:01:20.880
friends and colleagues are it's far less
 

00:01:20.880 --> 00:01:22.820
friends and colleagues are it's far less
powerful than people imagine I mean if

00:01:22.820 --> 00:01:22.830
powerful than people imagine I mean if
 

00:01:22.830 --> 00:01:24.830
powerful than people imagine I mean if
you try to get a robot to fold laundry

00:01:24.830 --> 00:01:24.840
you try to get a robot to fold laundry
 

00:01:24.840 --> 00:01:26.719
you try to get a robot to fold laundry
and I've just been told you can't even

00:01:26.719 --> 00:01:26.729
and I've just been told you can't even
 

00:01:26.729 --> 00:01:28.819
and I've just been told you can't even
get full robots to fold laundry if

00:01:28.819 --> 00:01:28.829
get full robots to fold laundry if
 

00:01:28.829 --> 00:01:30.140
get full robots to fold laundry if
someone just wrote me they were

00:01:30.140 --> 00:01:30.150
someone just wrote me they were
 

00:01:30.150 --> 00:01:31.789
someone just wrote me they were
surprised when I said an elevator is an

00:01:31.789 --> 00:01:31.799
surprised when I said an elevator is an
 

00:01:31.799 --> 00:01:33.710
surprised when I said an elevator is an
old example of the fact that when you

00:01:33.710 --> 00:01:33.720
old example of the fact that when you
 

00:01:33.720 --> 00:01:35.390
old example of the fact that when you
get an elevator you're it's a primitive

00:01:35.390 --> 00:01:35.400
get an elevator you're it's a primitive
 

00:01:35.400 --> 00:01:37.840
get an elevator you're it's a primitive
form of a computer and you're and you're

00:01:37.840 --> 00:01:37.850
form of a computer and you're and you're
 

00:01:37.850 --> 00:01:40.550
form of a computer and you're and you're
giving up the control of the fact that

00:01:40.550 --> 00:01:40.560
giving up the control of the fact that
 

00:01:40.560 --> 00:01:41.690
giving up the control of the fact that
it's gonna take you where you want to go

00:01:41.690 --> 00:01:41.700
it's gonna take you where you want to go
 

00:01:41.700 --> 00:01:44.359
it's gonna take you where you want to go
cars are the same thing machines are

00:01:44.359 --> 00:01:44.369
cars are the same thing machines are
 

00:01:44.369 --> 00:01:46.670
cars are the same thing machines are
useful because they're tools that help

00:01:46.670 --> 00:01:46.680
useful because they're tools that help
 

00:01:46.680 --> 00:01:49.690
useful because they're tools that help
us do what we want to do and I think

00:01:49.690 --> 00:01:49.700
us do what we want to do and I think
 

00:01:49.700 --> 00:01:51.740
us do what we want to do and I think
computational machines are exempt are

00:01:51.740 --> 00:01:51.750
computational machines are exempt are
 

00:01:51.750 --> 00:01:54.249
computational machines are exempt are
good examples of that one has to be very

00:01:54.249 --> 00:01:54.259
good examples of that one has to be very
 

00:01:54.259 --> 00:01:58.190
good examples of that one has to be very
careful in creating machines to not

00:01:58.190 --> 00:01:58.200
careful in creating machines to not
 

00:01:58.200 --> 00:01:59.899
careful in creating machines to not
assume they're more capable than they

00:01:59.899 --> 00:01:59.909
assume they're more capable than they
 

00:01:59.909 --> 00:02:03.170
assume they're more capable than they
are that's true in cars that's true in

00:02:03.170 --> 00:02:03.180
are that's true in cars that's true in
 

00:02:03.180 --> 00:02:04.429
are that's true in cars that's true in
vehicles that we make that's true and

00:02:04.429 --> 00:02:04.439
vehicles that we make that's true and
 

00:02:04.439 --> 00:02:05.899
vehicles that we make that's true and
weapons we create that's true in

00:02:05.899 --> 00:02:05.909
weapons we create that's true in
 

00:02:05.909 --> 00:02:09.559
weapons we create that's true in
defensive mechanisms we create and so to

00:02:09.559 --> 00:02:09.569
defensive mechanisms we create and so to
 

00:02:09.569 --> 00:02:13.220
defensive mechanisms we create and so to
me the dangers of AI would are mostly

00:02:13.220 --> 00:02:13.230
me the dangers of AI would are mostly
 

00:02:13.230 --> 00:02:13.940
me the dangers of AI would are mostly
due to the

00:02:13.940 --> 00:02:13.950
due to the
 

00:02:13.950 --> 00:02:16.369
due to the
that people may assume the devices they

00:02:16.369 --> 00:02:16.379
that people may assume the devices they
 

00:02:16.379 --> 00:02:18.589
that people may assume the devices they
create are more capable than they are

00:02:18.589 --> 00:02:18.599
create are more capable than they are
 

00:02:18.599 --> 00:02:19.970
create are more capable than they are
and don't need more control and

00:02:19.970 --> 00:02:19.980
and don't need more control and
 

00:02:19.980 --> 00:02:21.680
and don't need more control and
monitoring I guess I find the

00:02:21.680 --> 00:02:21.690
monitoring I guess I find the
 

00:02:21.690 --> 00:02:23.330
monitoring I guess I find the
opportunities to be far more exciting

00:02:23.330 --> 00:02:23.340
opportunities to be far more exciting
 

00:02:23.340 --> 00:02:25.369
opportunities to be far more exciting
than the dangers the unknown is always

00:02:25.369 --> 00:02:25.379
than the dangers the unknown is always
 

00:02:25.379 --> 00:02:34.150
than the dangers the unknown is always
dangerous but ultimately machines and

00:02:34.150 --> 00:02:34.160
 

00:02:34.160 --> 00:02:38.150
computational machines are improving our

00:02:38.150 --> 00:02:38.160
computational machines are improving our
 

00:02:38.160 --> 00:02:41.210
computational machines are improving our
lives in many ways we of course have to

00:02:41.210 --> 00:02:41.220
lives in many ways we of course have to
 

00:02:41.220 --> 00:02:44.900
lives in many ways we of course have to
realize that the rate at which machines

00:02:44.900 --> 00:02:44.910
realize that the rate at which machines
 

00:02:44.910 --> 00:02:48.830
realize that the rate at which machines
are evolving in capability may far

00:02:48.830 --> 00:02:48.840
are evolving in capability may far
 

00:02:48.840 --> 00:02:51.020
are evolving in capability may far
exceed the rate at which society is able

00:02:51.020 --> 00:02:51.030
exceed the rate at which society is able
 

00:02:51.030 --> 00:02:52.940
exceed the rate at which society is able
to deal with them the fact that of

00:02:52.940 --> 00:02:52.950
to deal with them the fact that of
 

00:02:52.950 --> 00:02:54.620
to deal with them the fact that of
teenagers aren't talking to each other

00:02:54.620 --> 00:02:54.630
teenagers aren't talking to each other
 

00:02:54.630 --> 00:02:56.479
teenagers aren't talking to each other
all but always looking at their phones

00:02:56.479 --> 00:02:56.489
all but always looking at their phones
 

00:02:56.489 --> 00:02:58.069
all but always looking at their phones
not just teenagers I was just in a

00:02:58.069 --> 00:02:58.079
not just teenagers I was just in a
 

00:02:58.079 --> 00:03:00.229
not just teenagers I was just in a
restaurant here in New York the this

00:03:00.229 --> 00:03:00.239
restaurant here in New York the this
 

00:03:00.239 --> 00:03:01.640
restaurant here in New York the this
afternoon and half the people we're not

00:03:01.640 --> 00:03:01.650
afternoon and half the people we're not
 

00:03:01.650 --> 00:03:03.259
afternoon and half the people we're not
talking to people they were with but

00:03:03.259 --> 00:03:03.269
talking to people they were with but
 

00:03:03.269 --> 00:03:05.000
talking to people they were with but
we're staring at their phones well that

00:03:05.000 --> 00:03:05.010
we're staring at their phones well that
 

00:03:05.010 --> 00:03:07.309
we're staring at their phones well that
may be not a good thing for it's a

00:03:07.309 --> 00:03:07.319
may be not a good thing for it's a
 

00:03:07.319 --> 00:03:09.199
may be not a good thing for it's a
silent er action and people may have to

00:03:09.199 --> 00:03:09.209
silent er action and people may have to
 

00:03:09.209 --> 00:03:11.569
silent er action and people may have to
come to terms with that but I don't

00:03:11.569 --> 00:03:11.579
come to terms with that but I don't
 

00:03:11.579 --> 00:03:13.039
come to terms with that but I don't
think people view their phones as a

00:03:13.039 --> 00:03:13.049
think people view their phones as a
 

00:03:13.049 --> 00:03:15.410
think people view their phones as a
danger they view their phones as a tool

00:03:15.410 --> 00:03:15.420
danger they view their phones as a tool
 

00:03:15.420 --> 00:03:18.860
danger they view their phones as a tool
that in many ways allow them to do what

00:03:18.860 --> 00:03:18.870
that in many ways allow them to do what
 

00:03:18.870 --> 00:03:22.940
that in many ways allow them to do what
they would otherwise do more effectively

