WEBVTT
Kind: captions
Language: en

00:00:00.310 --> 00:00:03.540
So what do these concept of depth and
defocus imply here?

00:00:03.540 --> 00:00:07.230
So here basically,
now I'm showing you this whole image.

00:00:07.230 --> 00:00:11.000
Because of the fact that things
that are at different distances and

00:00:11.000 --> 00:00:12.850
the fact that you have optics, and

00:00:12.850 --> 00:00:17.170
the sensor itself, any image I take
will have this artifact, right?

00:00:17.170 --> 00:00:20.657
These objects are a little bit further
away, they are out of focus and

00:00:20.657 --> 00:00:23.560
this frame here,
this part obviously that's in focus.

00:00:23.560 --> 00:00:26.740
So, only a few specific planes,
depending on the camera and

00:00:26.740 --> 00:00:29.670
the aperture and
stuff like that would be in focus.

00:00:29.670 --> 00:00:34.810
So this is in essence is the artifact
of a traditional camera system.

00:00:34.810 --> 00:00:38.570
We will always have scenes
at different depths.

00:00:38.570 --> 00:00:40.870
All of them will have different focus.

00:00:40.870 --> 00:00:44.980
And of course, the question comes up
is can you actually compute the depth

00:00:44.980 --> 00:00:48.170
just from knowing this focus planes
that are different in this image.

00:00:48.170 --> 00:00:50.810
So depth from defocus
basically is attempts to infer

00:00:50.810 --> 00:00:53.660
depth by analyzing the local scale.

00:00:53.660 --> 00:00:57.700
That is, how is, much is the dif,
difference in the frame itself or

00:00:57.700 --> 00:01:00.900
difference in the focus itself
in local parts of the image, and

00:01:00.900 --> 00:01:02.860
use that to compute a defocus blur.

00:01:02.860 --> 00:01:06.135
And if I actually can figure out
the defocus blur, I can actually kind of

00:01:06.135 --> 00:01:09.970
claim knowing the lens that I have,
how far a certain object is.

00:01:09.970 --> 00:01:11.860
That's what basically you
saw in the last example.

00:01:11.860 --> 00:01:15.350
The more I moved the object,
I got a different blur out of it.

00:01:15.350 --> 00:01:17.930
Now, if I could actually create
a relationship between this,

00:01:17.930 --> 00:01:19.860
I could actually start computing depth.

00:01:19.860 --> 00:01:23.260
We saw examples of that when we talked
about computing depth from images in

00:01:23.260 --> 00:01:24.570
the lecture on stereo.

00:01:24.570 --> 00:01:25.540
But the bottom line is,

00:01:25.540 --> 00:01:28.410
this is an extremely difficult and
ill-posed problem.

00:01:28.410 --> 00:01:32.610
because we actually have a tougher time
of actually figuring out the calibration

00:01:32.610 --> 00:01:36.420
that will allow us to figure out how
much defocus blur exists in different

00:01:36.420 --> 00:01:40.380
parts of the image, that will allow
us to then actually compute how far

00:01:40.380 --> 00:01:42.210
those objects are in that image.

