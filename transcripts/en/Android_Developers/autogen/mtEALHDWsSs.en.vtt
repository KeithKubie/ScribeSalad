WEBVTT
Kind: captions
Language: en

00:03:18.865 --> 00:03:22.281
SPEAKER: Testing testing 
testing, this is a captioning 

00:04:59.527 --> 00:05:01.527
test.  Nicolas Geoffray

00:18:03.239 --> 00:18:05.328
welcome back Chet Haase!

00:18:08.886 --> 00:18:11.074
[ Applause ]. 
SPEAKER: Morning, from the very 

00:18:11.469 --> 00:18:14.144
much less than full room.  I 
assume that people had fun at 

00:18:14.145 --> 00:18:17.665
the party last night, and that 
those people are not here.  

00:18:17.666 --> 00:18:19.929
Welcome back to the conference. 
So favorite things you have seen

00:18:20.438 --> 00:18:22.438
so far?
Shout it

00:18:29.349 --> 00:18:33.237
out.
I owe you $10.  We will make 

00:18:34.868 --> 00:18:40.860
that $5.  Motion layout, low 
latency audio, the coding of C++

00:18:41.138 --> 00:18:45.597
in the quick talk, it was braver
brave and worked out well.

00:18:45.598 --> 00:18:48.726
And he was the DJ last night, 
too.

00:18:48.727 --> 00:18:50.727
Anything else? Custom linting,

00:18:58.724 --> 00:19:05.136
all right.
GSI, generic system images, 

00:19:05.510 --> 00:19:07.986
lightning talks.  Did it work? 
Did people have a problem with 

00:19:07.987 --> 00:19:11.473
it, no? I think the yeses win.  
Sorry, we're going to ignore 

00:19:11.474 --> 00:19:13.497
you.  What are you looking 

00:19:17.429 --> 00:19:21.685
forward to today?
Well, we solved that one.  You 

00:19:21.954 --> 00:19:26.503
are beginning to regret that.  
Anything else? Vitals?

00:19:26.504 --> 00:19:29.154
Text, firesides, that will be 
interesting.

00:19:29.155 --> 00:19:34.799
All right.
Well, the only change that know 

00:19:34.990 --> 00:19:38.167
-- I know about the schedule, 
there was an awkward thing with 

00:19:38.434 --> 00:19:41.480
the talk that was supposed to 
happen about now.  Jake had to 

00:19:41.481 --> 00:19:48.297
go home, apparently babies, 
unlike software, occasionally 

00:19:48.559 --> 00:19:49.888
shift early.
[ Laughter ].

00:19:49.889 --> 00:19:54.091
So he made a quick departure 
last night on to a plane and 

00:19:54.092 --> 00:19:57.308
went home.  We have a different 
talk for you this morning on the

00:19:57.309 --> 00:20:00.574
schedule.  Hopefully you noticed
that, if you really wanted to 

00:20:00.876 --> 00:20:03.263
see Jake, I'm going to 
disappoint you and you are 

00:20:03.750 --> 00:20:06.219
welcome to see the other talk 
about other screen form factors 

00:20:06.220 --> 00:20:09.170
in the other room.  Otherwise, 
let me bring on the next 

00:20:09.411 --> 00:20:11.411
speakers for the next

00:20:18.724 --> 00:20:24.368
talk.
Romain Guy. 

00:20:24.369 --> 00:20:26.621
SPEAKER: Did you call me a 
disappointment? We are part of 

00:20:27.158 --> 00:20:31.140
the content section committee 
for this event, and somehow we 

00:20:31.448 --> 00:20:35.949
ended up with no talk to give, 
so we had to do something about 

00:20:36.351 --> 00:20:38.224
it. 
SPEAKER: Unbelievably 

00:20:38.225 --> 00:20:42.604
complicated to arrange this.  
His wife was in on it and it 

00:20:42.926 --> 00:20:47.445
worked out.  
SPEAKER: Now we are here. 

00:20:47.446 --> 00:20:49.446
SPEAKER: And infinity we will 
give a talk and there

00:20:52.611 --> 00:20:56.633
is a team and engineers at the 
team that know all about R8 and 

00:20:56.634 --> 00:20:59.446
D8, you have the opportunity to 
talk about it in the Android 

00:20:59.447 --> 00:21:04.559
studio office hours, Madison in 
particular, and JVG.  So check 

00:21:05.142 --> 00:21:12.464
them out, sorry, Jeffrey van 
Gough in the studio area.  Ware 

00:21:12.717 --> 00:21:14.710
we're going to talk about 
something completely different. 

00:21:14.711 --> 00:21:19.911
We're going to talk about trash.
Why are we going to talk about 

00:21:20.409 --> 00:21:24.860
trash? Okay, so there's a common
phrase in software, garbage 

00:21:25.294 --> 00:21:28.947
in/garbage out, but nobody ever 
says how fast.  We're going to 

00:21:28.948 --> 00:21:34.401
talk about that today.  And why?
Back at I/O, we gave a talk, 

00:21:34.680 --> 00:21:37.250
modern Android development, I 
have to apologize for the 

00:21:37.787 --> 00:21:40.783
glasses, the sun was right 
there, annoying, couldn't see a 

00:21:41.688 --> 00:21:46.663
thing.  The glasses didn't help 
and it did not make us look any 

00:21:46.989 --> 00:21:48.989
better.
So Android had certain 

00:21:49.727 --> 00:21:53.545
development practices way back 
then, and Android and devices 

00:21:53.855 --> 00:21:57.129
and ecosystems have changed and 
we are recommending different 

00:21:57.366 --> 00:22:00.199
practices, all the stuff you 
knew about Android development 

00:22:00.200 --> 00:22:03.166
may not necessarily be true 
today.  One of the things we 

00:22:03.788 --> 00:22:07.202
talked about in particular is a 
lot about memory and garbage 

00:22:08.018 --> 00:22:09.939
collection, we are 
recommendations there.  So for 

00:22:09.940 --> 00:22:13.697
example, we said back in the 
Dalvik days, it was optimized 

00:22:14.150 --> 00:22:16.582
for size and meant to fit in a 
small area, didn't have a lot of

00:22:17.858 --> 00:22:23.773
area to do things like  like 
AOT, the optimizations were not 

00:22:24.031 --> 00:22:29.370
optimal, the allocations CLEBZs
collections were expensive, 

00:22:29.785 --> 00:22:32.293
causing jank, heat fragmentation
was a problem and the 

00:22:33.076 --> 00:22:35.449
recommendation was not to 
allocate anything ever if you 

00:22:35.739 --> 00:22:39.172
could possibly help it.
And use primitive types 

00:22:39.427 --> 00:22:42.185
everywhere, because objects are 
expensive because you are 

00:22:42.518 --> 00:22:45.475
allocating them, avoid auto 
boxing. 

00:22:45.476 --> 00:22:48.642
SPEAKER: I need to correct you. 
You said avoid allocations 

00:22:49.100 --> 00:22:50.748
whenever possible? That's the 
whole point.  

00:22:50.749 --> 00:22:52.749
SPEAKER: Yeah, but but

00:22:55.370 --> 00:22:58.359
but... 
but they take up space.  That is

00:22:58.360 --> 00:23:03.181
1K to 2K? Anyway, it is 
memory-related.

00:23:03.182 --> 00:23:07.099
So the recommendation instead 
was to pay attention to ART, it 

00:23:07.364 --> 00:23:10.245
turns out that ART is optimized 
for performance and getting 

00:23:11.119 --> 00:23:14.024
faster with every release 
because the platform was built 

00:23:18.466 --> 00:23:24.799
to opt miles -- optimize more 
and more.  We do AOT, find the 

00:23:25.032 --> 00:23:28.037
hotspots, they can run faster 
next time you go through the 

00:23:28.561 --> 00:23:30.704
loop.  Applications and 
collections are faster, we will 

00:23:31.031 --> 00:23:36.384
go into detail about this.  We 
can defragment the heat and com 

00:23:36.385 --> 00:23:39.421
PAECKT -- compact as we go, and 
there's a larger object heat 

00:23:39.422 --> 00:23:44.036
that makes the allocations 
faster than they used to be.  So

00:23:44.979 --> 00:23:46.979
the recommendations are to 
allocate, it is not that big of 

00:23:47.066 --> 00:23:49.836
a deal, be concerned for inner 
loop situations and that you are

00:23:50.146 --> 00:23:53.267
actually causing the device to 
do stuff, you are causing 

00:23:53.757 --> 00:23:56.355
battery and CPU usage.  So you 
want to be aware of these 

00:23:56.523 --> 00:23:59.560
things, but maybe they are not 
such a big deal that they should

00:24:00.256 --> 00:24:03.516
affect your APIs and your 
development patterns the way 

00:24:03.813 --> 00:24:07.010
they used to.
  However, that was a lot of 

00:24:07.011 --> 00:24:09.142
terse information stuffed into a
short amount of time.  We 

00:24:09.420 --> 00:24:13.401
thought, maybe we should do this
talk to explain ourselves a 

00:24:15.487 --> 00:24:18.996
little bit completely and say 
why is this the case, what has 

00:24:19.491 --> 00:24:22.464
ART done to make life better? 
The original idea of the talk is

00:24:22.736 --> 00:24:28.791
we said this stuff, but would it
be nice to write dem tow o 

00:24:29.847 --> 00:24:32.971
applications and write bench 
marks on this is why and these 

00:24:33.235 --> 00:24:36.931
are the canonical results that 
show the premise.  That is hard,

00:24:37.335 --> 00:24:39.993
garbage collection in ART is 
concurrent, there is stuff 

00:24:40.242 --> 00:24:43.064
happening in the background all 
the time.  If you want to 

00:24:43.298 --> 00:24:45.858
trigger that thing right now, 
you will not be able to.  So we 

00:24:47.184 --> 00:24:50.145
made an attempt to write some 
demo applications, you will see 

00:24:50.464 --> 00:24:53.341
the results here.  But we don't 
have enough canonical 

00:24:53.494 --> 00:24:56.056
deterministic data to show you. 
Instead, we will show you the 

00:24:56.331 --> 00:24:59.820
background of why it is 
difficult to write these things 

00:24:59.821 --> 00:25:02.618
because everything is happening 
magically for you in the 

00:25:02.835 --> 00:25:04.188
background.
  First, we will talk about 

00:25:04.189 --> 00:25:08.217
memory.  We see a couple simple 
lines of code here.  We have a 

00:25:08.456 --> 00:25:11.964
primitive type, Fu, set it to 
five, we will allocate an object

00:25:12.226 --> 00:25:15.277
here.  There are different kinds
of memory in the system and 

00:25:15.694 --> 00:25:17.957
different implications.  If we 
have a primitive type, it may 

00:25:18.221 --> 00:25:22.005
show up in the stack or 
registers.  Dalvik was a 

00:25:22.633 --> 00:25:24.791
register-based allocation 
system, so it actually popped it

00:25:24.792 --> 00:25:27.019
in over there. And whether it 
shows up in the stack or the 

00:25:27.318 --> 00:25:30.487
register, you can think of it as
free.  It is allocated at 

00:25:30.765 --> 00:25:33.556
compiler time, it says, when I 
run this line of code, here is 

00:25:33.557 --> 00:25:36.599
where I'm going to stick this 
thing.  It didn't need to find 

00:25:36.879 --> 00:25:39.709
space, it knows that it has 
space on the stack.  So you can 

00:25:40.171 --> 00:25:44.197
think of that as limited, sorry,
limitness storage space, as well

00:25:44.362 --> 00:25:47.887
as the registers.  It will find 
a cubbyhole to stash that thing.

00:25:48.244 --> 00:25:51.110
It is free.  And however, when 
you allocate any other, sort of,

00:25:51.111 --> 00:25:55.545
thing, when you say new object, 
then it needs to find space for 

00:25:55.885 --> 00:25:57.935
it in the heap.  That means it 
needs to figure out where it is 

00:25:58.229 --> 00:26:01.735
going to fit among the other 
things that already occupy the 

00:26:02.146 --> 00:26:04.595
heap and will find space down 
there.  So that's the basic 

00:26:05.640 --> 00:26:08.416
memory system of runtime and the
computer overall.

00:26:08.417 --> 00:26:12.906
So the idea of garbage 
collection, well, we've all been

00:26:12.907 --> 00:26:16.778
doing garbage collection even 
before higher level languages, 

00:26:16.779 --> 00:26:19.923
like Java and Kotlin.  If you 
are writing C++ code, you can do

00:26:20.702 --> 00:26:24.575
an allocation like this, you can
write the code that uses the 

00:26:25.038 --> 00:26:27.038
object you allocated.  If you 
don't do anything else, you just

00:26:27.424 --> 00:26:30.586
leaked an object.  You are 
taking up space in memory 

00:26:31.267 --> 00:26:33.267
somewhere that eventually is 
going to cause you to run out of

00:26:33.348 --> 00:26:37.801
memory.  Right? So what you need
to do is to free the object.  So

00:26:39.687 --> 00:26:43.313
you delete the thing and reclaim
the memory, manual garbage 

00:26:43.674 --> 00:26:46.730
collection here.  Sometimes you 
forget that you free it over 

00:26:47.886 --> 00:26:50.286
here and in this place you 
continue using that object and 

00:26:50.562 --> 00:26:53.779
then you crash, maybe.  So very 
non-deterministic system, you 

00:26:53.780 --> 00:26:57.516
are responsible for managing 
your own garbage, your own 

00:26:59.896 --> 00:27:02.540
allocations and collectionsism .
Tends

00:27:05.670 --> 00:27:09.558
to be tedious and error-prone.  
We have languages

00:27:12.944 --> 00:27:15.317
like Java, you write the 
language that uses that and it 

00:27:15.318 --> 00:27:18.611
is freed.  If you continue using
it, you have a reference to this

00:27:18.612 --> 00:27:21.410
object and that means it is 
freed without freeing it too 

00:27:21.699 --> 00:27:24.345
soon.  The system knows what is 
going on, you don't have to 

00:27:24.617 --> 00:27:29.451
manage this thing and scientist 
it is doing it for you.  If it 

00:27:29.622 --> 00:27:34.303
is doing it for you, there are 
questionings s that occur, and 

00:27:34.436 --> 00:27:37.123
there is no crash.  There are 
things that occur to you, how 

00:27:37.399 --> 00:27:40.008
long does it take for the system
to do this? I know how long the 

00:27:40.009 --> 00:27:42.808
statement was going to take in 
C++, how long is it going to 

00:27:43.228 --> 00:27:46.190
take for this system to 
automatically find space in the 

00:27:46.732 --> 00:27:50.964
heap for me? How long does it 
take to walk the heap, find the 

00:27:50.965 --> 00:27:54.427
spot, put this thing, and 
allocate the space? How long duz

00:27:55.002 --> 00:27:59.195
it take to allocate the objects,
when the reference goes away, 

00:27:59.452 --> 00:28:01.756
how long does it take to collect
these things.  And what impact 

00:28:02.586 --> 00:28:05.911
is there system-wide? When we 
are returning this garbage 

00:28:06.090 --> 00:28:08.675
collector thread, this heavy 
thing in the background, what 

00:28:09.034 --> 00:28:11.896
impact does that have on Jenk on
the UI thread or whatever.

00:28:11.897 --> 00:28:14.247
And when do these things 
actually happen?

00:28:14.248 --> 00:28:16.562
And also, how efficient is that 
heap usage?

00:28:16.563 --> 00:28:23.534
Right, it is not just going to 
malwick theseing CHUNCHG chunks 

00:28:23.803 --> 00:28:28.031
for the thing, it is allocating 
space and sorting around.  On 

00:28:28.217 --> 00:28:31.594
Dalvik, it is fragmenting the 
heap over time, you have a lot 

00:28:31.595 --> 00:28:34.061
of memory available, but you 
cannot access it anymore.  So 

00:28:34.385 --> 00:28:37.623
how efficient is that and how 
much memory are you taking in 

00:28:37.831 --> 00:28:39.544
the system to do all of this 
stuff? 

00:28:39.545 --> 00:28:43.538
SPEAKER: We will start by 
looking at how Dalvik collects 

00:28:43.800 --> 00:28:47.054
garbage.  It was the one thing 
that we were using until Android

00:28:47.358 --> 00:28:50.468
KitKat and was replaced with 
ART.  So this is a picture of 

00:28:51.230 --> 00:28:53.959
the heap, everything in white is
allocated, we have a few holes, 

00:28:53.960 --> 00:28:59.759
we are trying to allocate this 
blue object.  Dalvik will walk 

00:29:00.028 --> 00:29:04.371
through the heap, find a spot 
where it fits, and once it finds

00:29:04.372 --> 00:29:07.822
one, it will slide it there.  
Things are more complicated when

00:29:08.033 --> 00:29:11.193
it is time to collect objects.  
So there are four phases, the 

00:29:11.370 --> 00:29:14.807
first one, Dalvik has to pause 
all the threads in the 

00:29:15.160 --> 00:29:18.304
application to find the root 
set.  So root sets are local 

00:29:19.328 --> 00:29:23.375
variables, threads, studied 
variables.  They are just the 

00:29:23.982 --> 00:29:26.388
roots of all the allocations 
that can be reached in the 

00:29:26.566 --> 00:29:29.777
application.  That takeakes a 
lot of time and your application

00:29:30.523 --> 00:29:34.205
cannot do anything.  And the 
second is concurrent, the app is

00:29:34.206 --> 00:29:37.474
running again, and from the 
roots, Dalvik will find the 

00:29:37.746 --> 00:29:40.733
objects that can be reached and 
will mark them as such.  And 

00:29:41.310 --> 00:29:44.681
unfortunately, since the second 
phase is concurrent, the 

00:29:45.766 --> 00:29:47.842
allocations can be triggered 
during that time.  So for this 

00:29:47.843 --> 00:29:52.039
instance, we are allocating 
another object.  And so we need 

00:29:52.451 --> 00:29:55.847
to pause the application again 
and find the reachable objects 

00:29:56.092 --> 00:29:58.282
again, all of the threads are 
parsed.

00:29:58.283 --> 00:30:02.244
And so finally, we can knock all
of the objects that are not 

00:30:02.245 --> 00:30:04.245
reachable and they are 

00:30:06.386 --> 00:30:08.686
candidates for garbage 
collection and they are put into

00:30:09.416 --> 00:30:11.599
the heap.  If we want to 
allocate something in the heap 

00:30:11.823 --> 00:30:14.983
and the heap is pretty much full
and we have an object that is 

00:30:18.537 --> 00:30:21.204
marked for allocation, Dalvik 
will go through the heap, 

00:30:21.590 --> 00:30:25.799
realize there is no memory 
available, and will target the 

00:30:26.025 --> 00:30:30.352
file log.  Anytime you see this,
there's a log on the individual 

00:30:31.230 --> 00:30:33.611
lot cat, you can see the 
messages.  So run the 

00:30:33.924 --> 00:30:36.598
collection, get to this memory, 
and then we can run through the 

00:30:37.089 --> 00:30:42.844
typical allocation mechanism.
However, sometimes the heap is 

00:30:43.107 --> 00:30:50.335
full.  There are no objects that
can be collected, everyone one 

00:30:50.336 --> 00:30:54.420
is reachable, Dalvik cannot find
anything.  And two things can 

00:30:54.678 --> 00:30:59.145
happen, the heap will grow or 
the application will crash.  And

00:30:59.146 --> 00:31:02.681
it is the error you see in a lot
of applications, especially on 

00:31:03.216 --> 00:31:06.274
older devices.  This happens 
when you are allocating large 

00:31:06.275 --> 00:31:10.741
objectz.  I remember a lot of 
developers in the early days 

00:31:11.437 --> 00:31:16.592
find bugs against bit map 
factory, because auto malware 

00:31:17.144 --> 00:31:22.213
happened during the decoding of 
bit maps, and there was a link 

00:31:23.706 --> 00:31:25.982
in the factory because bit map 
objects are big and it is hard 

00:31:26.334 --> 00:31:29.997
to find space for them.  There 
is no leak in the factory 

00:31:30.319 --> 00:31:32.134
whatsoever. 
SPEAKER: So we wrote a simple 

00:31:32.135 --> 00:31:36.058
demo application to show off how
some of this stuff with heap's 

00:31:36.350 --> 00:31:41.556
fragmentation works.  So in the 
demo, we allocate chunks of 

00:31:41.816 --> 00:31:44.068
memory to max heap.  The heap 
starts very small, if you cannot

00:31:44.069 --> 00:31:46.755
allocate an object, it is going 
to grow that over and over and 

00:31:47.469 --> 00:31:51.131
over until it reaches the max 
possible.  So for this demo, we 

00:31:52.054 --> 00:31:56.441
allocate the 1MG chunks, there 
are 400MG free, it will allocate

00:31:56.586 --> 00:32:01.857
these chunks until it grows the 
heap.  You get the error, we 

00:32:02.033 --> 00:32:04.143
catch the error, the heap is 
full. 

00:32:04.144 --> 00:32:06.345
SPEAKER: This is the only 
situation where you do a try 

00:32:06.346 --> 00:32:10.559
catch in the ought  out of 
memory error, don't do that in 

00:32:10.842 --> 00:32:14.341
the application. 
SPEAKER: Come we  -- and we say 

00:32:14.611 --> 00:32:19.435
there is 1MB free, we will 
fragment the heap and free a 

00:32:20.069 --> 00:32:24.319
bunch of chunks.  We allocated 
and freed every other one. 

00:32:24.320 --> 00:32:27.744
SPEAKER: Go through the 
reference, set it to null, and 

00:32:27.954 --> 00:32:30.611
set it to GCU so the memory goes
away. 

00:32:30.612 --> 00:32:34.406
SPEAKER: And we get this result,
the fragmented heap size is 

00:32:36.196 --> 00:32:43.454
200MB, we have space to allocate
a 2MB object, we have 200MB 

00:32:43.455 --> 00:32:48.352
free.  So what can be the 
problem? So we press the button 

00:32:48.648 --> 00:32:51.036
and it says nope, we cannot fit 
that in there.  If you look at 

00:32:51.352 --> 00:32:54.525
the log, we have depressing 
things here -- 

00:32:54.526 --> 00:32:56.596
SPEAKER: The best error message 
in all of computer science. 

00:32:56.597 --> 00:33:02.145
SPEAKER: This is beautiful.  It 
says, okay, you have 200MB free 

00:33:02.587 --> 00:33:05.200
out of 400 and we're forcing a 
collection so we can make room 

00:33:05.687 --> 00:33:08.929
for a 2MB chunk, we are trying 
really hard to do that and we 

00:33:09.188 --> 00:33:16.677
ran out of memory.  We cannot 
find space for 2MB out of 200, 

00:33:16.678 --> 00:33:22.567
because aapparently Dalvik is 
bad at math.  You cannot find 

00:33:22.568 --> 00:33:26.005
them contiguous and they cannot 
compact the heap.  So we cannot 

00:33:26.518 --> 00:33:31.332
shove stuff to the side to make 
room for a larger object.

00:33:31.333 --> 00:33:36.039
So ART came along in Lollipop, 
it is a platform for 

00:33:36.320 --> 00:33:39.698
optimization, it no longer had 
the memory constraints that 

00:33:39.838 --> 00:33:43.284
Dalvik did so they can build in 
the fundamentals that they are 

00:33:43.889 --> 00:33:49.311
are improving over time.  Out of
the box, much faster allocation 

00:33:49.674 --> 00:33:53.163
times and faster run time, the 
ability to do ahead of time 

00:33:53.522 --> 00:33:57.111
compilations, we are running 
binary code all the time and not

00:33:57.771 --> 00:34:05.250
jitting things to see how we can
speed things up SQULNCHLTHS  -- 

00:34:05.251 --> 00:34:08.226
SPEAKER: When we talk about 
faster allocation in the talk, 

00:34:08.227 --> 00:34:11.562
it is the time for the run time.
Not the constructors, it has 

00:34:11.838 --> 00:34:14.311
nothing to do with your code, it
is only in the run time itself. 

00:34:14.648 --> 00:34:18.888
SPEAKER: All right.  So how did 
our allocation work? 

00:34:18.889 --> 00:34:27.216
SPEAKER: In ART, we introduced 
the Rust Adock, we replaced it 

00:34:27.482 --> 00:34:33.753
for DL, which stands for dud
dley, the person that wrote it. 

00:34:34.016 --> 00:34:36.725
SPEAKER: That's what happens 
when you write a nice algorithm,

00:34:36.726 --> 00:34:41.124
people name it after you. 
SPEAKER: It is the kind of 

00:34:41.759 --> 00:34:46.729
person that makes me feel 
inadequate at -- as an engineer.

00:34:46.730 --> 00:34:49.871
So it is the function call in it
the native code.  This is what 

00:34:50.134 --> 00:34:56.372
you work on in C++, the 
algorithm we are using.  Dalvik 

00:34:56.888 --> 00:34:58.888
is relying on that.  And

00:35:01.618 --> 00:35:03.618
the main benefit is we can do

00:35:06.182 --> 00:35:09.099
thread aware, and we will look 
at it in detail.  And a lot of 

00:35:09.100 --> 00:35:12.024
the tweaks that have been done, 
so small allocations are grouped

00:35:12.827 --> 00:35:16.097
together, to reduce 
fragmentation, and we allow 

00:35:16.098 --> 00:35:20.168
large allocations on pages, 
typically four KB on modern OS 

00:35:20.748 --> 00:35:22.748
and gives you better 

00:35:25.943 --> 00:35:27.943
performance.
And the garbage

00:35:31.974 --> 00:35:33.974
collector has to collect logs.  
And overall,

00:35:40.857 --> 00:35:44.878
allocations are four to five 
times faster.  You can do 

00:35:44.879 --> 00:35:46.879
something really really really 

00:35:49.899 --> 00:35:52.562
expensive in your constructor 
and you are still five times 

00:35:53.181 --> 00:35:57.733
faster than dlmalloc. 
SPEAKER: And the other very 

00:35:58.000 --> 00:36:01.012
important thing with ART is the 
ability to deal with large 

00:36:01.270 --> 00:36:04.766
objects in a better way.  So you
have this normalize object, it 

00:36:05.029 --> 00:36:07.942
will find space for it in the 
heap over here.  And what 

00:36:07.943 --> 00:36:12.713
happens if you have this large 
object, we mean an array of 

00:36:12.965 --> 00:36:16.743
primitives or string.
And these are the types chosen 

00:36:17.218 --> 00:36:19.221
because we can guarantee these 
objects will not have a 

00:36:19.435 --> 00:36:21.435
reference to something else.  
They can live on their 

00:36:25.557 --> 00:36:26.996
own. 
SPEAKER: 12KB. 

00:36:26.997 --> 00:36:30.294
SPEAKER: That's the heuristic 
for now, right now it is 12K, 

00:36:30.581 --> 00:36:35.022
the primitive types are string. 
Where would we put this? In 

00:36:35.281 --> 00:36:39.222
Dalvik, we put it where exactly?
In this fragmented heap, there 

00:36:39.223 --> 00:36:41.896
is no space.  In ART, it is 
simpler.  The

00:36:44.911 --> 00:36:48.905
complicated mechanism looks like
this, we shove it like this, we 

00:36:50.139 --> 00:36:52.557
malloc a space in there and 
shove it in. 

00:36:52.558 --> 00:36:55.581
We allocate a space in there, 
you are part of the heap, and it

00:36:56.491 --> 00:36:58.672
is living on its own somewhere. 
Very fast, very easy.

00:36:58.673 --> 00:37:01.453
And it is also a moving 
collector, so we can actually 

00:37:01.658 --> 00:37:05.552
compact things.
And so we no longer have the 

00:37:06.431 --> 00:37:08.604
fragmentation problem.  However,
it does this in the

00:37:13.086 --> 00:37:15.497
background. 
So it is more complicated.  My 

00:37:15.856 --> 00:37:18.729
understanding was that if your 
application goes into the 

00:37:19.052 --> 00:37:22.861
background, then eventually this
very expensive operation, it can

00:37:23.482 --> 00:37:27.321
take up to 100MS, can compact 
the heap.  We don't want to run 

00:37:27.577 --> 00:37:30.722
it in the fore ground, we are 
going to Jenk your app, we will 

00:37:30.723 --> 00:37:33.126
wait until it is in the 
background, the user is doing 

00:37:33.520 --> 00:37:38.650
something else, not paying 
attention, we are compacting the

00:37:38.984 --> 00:37:43.306
heap for you.  I will show the 
same fragmentation crash error, 

00:37:43.711 --> 00:37:49.322
I will show how it crashes on 
KitKat using dav -- Dalvik and 

00:37:49.479 --> 00:37:52.719
it will crash on the releases 
until we can do it in the fore 

00:37:52.887 --> 00:37:57.597
ground in a later release in O. 
And this was a cool demo, ran it

00:37:58.006 --> 00:38:02.622
on L, and it didn't crash.  It 
will defrag in the background, 

00:38:03.040 --> 00:38:05.049
but also in the fore ground if 
it has to.  That's what you 

00:38:05.050 --> 00:38:10.965
want.  So if you need that 
memory now,p  wouldn't it be 

00:38:11.461 --> 00:38:14.655
nice if it doesn't crash? 
SPEAKER: And this is a 

00:38:15.031 --> 00:38:17.840
replacement for the GC file log 
from before. 

00:38:17.841 --> 00:38:21.129
SPEAKER: And it says you need 
space for this large object, we 

00:38:21.130 --> 00:38:25.172
will compact things and then put
it a where we need to.  So on L 

00:38:25.487 --> 00:38:27.726
and above, we run the same 
fragmentation

00:38:31.861 --> 00:38:39.564
demo, we malloc to the maximum 
heap size, one MB free, and then

00:38:40.190 --> 00:38:44.021
we try to find space for the 2MB
block, compact the heap, and it 

00:38:44.022 --> 00:38:45.857
puts it in.  
Very simple. 

00:38:45.858 --> 00:38:50.232
SPEAKER: So another improvement,
so remember with the Dalvik GC, 

00:38:50.506 --> 00:38:53.910
we had two phases, including two
pauses for your application.  

00:38:54.327 --> 00:38:58.108
The pauses water  were bad 
because it was not doing 

00:38:58.372 --> 00:39:00.505
anything at that time.  And what
is worse, the pauses can be 

00:39:00.863 --> 00:39:06.696
expensive.  So on average, some 
of the two pauses were two 

00:39:07.045 --> 00:39:10.645
milliseconds.  And even when it 
was 10, it was pretty good.  We 

00:39:10.646 --> 00:39:14.569
have done a lot of performance 
work over the year and I have 

00:39:14.570 --> 00:39:19.809
seen these pauses work sometimes
over 100 milliseconds.  So no 

00:39:19.997 --> 00:39:23.386
matter how good the UI is, it 
will Jenk.  If the user is 

00:39:23.387 --> 00:39:26.201
trying to scroll, it is not 
going to work well.  So one of 

00:39:26.500 --> 00:39:30.391
the things that ART does, it 
removes one of the pauses.  So 

00:39:31.512 --> 00:39:35.469
the first step, the marking the 
root set, finding the roots that

00:39:35.798 --> 00:39:40.414
are reachable in the heap St. A 
concurrent phase.  It doesn't 

00:39:40.827 --> 00:39:44.974
pause the application anymore.  
And the other pause we have left

00:39:44.975 --> 00:39:52.868
is a lot faster.  Instead of 10 
milliseconds, we have 3 mill  

00:39:53.233 --> 00:39:58.956
milliseconds.  It will pause, 
and if GCT happens during 

00:39:59.501 --> 00:40:04.382
scrolling, you can reach 60FPS 
without Jenk.

00:40:04.383 --> 00:40:08.082
What was introduced in ART is 
the concept of the fast 

00:40:08.472 --> 00:40:11.782
collection of the young 
generation, keep track of the 

00:40:12.050 --> 00:40:16.795
objects that were allocated 
since the last major garbage 

00:40:16.796 --> 00:40:19.234
collection, those are temporary 
objects, and we look at them 

00:40:19.547 --> 00:40:26.018
first.  If we allocate memory by
looking at the subject first 

00:40:26.314 --> 00:40:30.833
because they are short-lived, we
don't go through the heap. 

00:40:30.834 --> 00:40:36.049
SPEAKER: This has an important 
implication for Android 

00:40:36.240 --> 00:40:40.457
development, all of a sudden, we
made object allocation and 

00:40:40.458 --> 00:40:42.934
collection much easier. 
SPEAKER: It is not free, just 

00:40:42.935 --> 00:40:43.749
less expensive. 
SPEAKER: Yes. 

00:40:43.750 --> 00:40:47.694
SPEAKER: We will introduce the 
heap that we talked about, you 

00:40:47.956 --> 00:40:51.726
have less fragmentation.  And 
one of the benefits of that, 

00:40:52.016 --> 00:40:54.580
because we don't fragment the 
heap, we don't have to grow the 

00:40:54.973 --> 00:40:57.633
heap as much in all the 
processes.  And of course, we 

00:40:57.910 --> 00:40:59.910
don't have

00:41:04.389 --> 00:41:09.824
the GCFORALLOC and the faster 
run time, and we can reduce the 

00:41:09.825 --> 00:41:13.653
GPAC which has nothing to do 
with the garbage collector.

00:41:13.916 --> 00:41:17.117
Marshmallow, I was joking 
yesterday that it is a boring 

00:41:17.470 --> 00:41:24.013
release, I cannot remember what 
was Marshmallow.  Here it is, 

00:41:24.274 --> 00:41:27.350
optimizations. 
SPEAKER: Things got faster.  

00:41:28.255 --> 00:41:33.374
Fine-grain details, things got 
faster.

00:41:33.631 --> 00:41:36.370
N, things got faster, allocation
in particular, they rewrote all 

00:41:36.371 --> 00:41:40.151
the thing, the cool stuff in 
assembly, and that still helps s

00:41:41.300 --> 00:41:46.036
in software.  Now we are up to 
10 times faster in allocation 

00:41:46.037 --> 00:41:47.769
costs when you compare it to 
Dalvik.

00:41:47.770 --> 00:41:54.424
And now we are in Oreo, they 
rewrote the whole thing.  We 

00:41:54.425 --> 00:41:58.182
introduced the concurrent heap 
compaction collector, and we can

00:41:58.419 --> 00:42:04.518
compact in the fore ground, not 
just when we do the GC for Alloc

00:42:04.985 --> 00:42:07.910
in the space, but it is moving 
stuff around and optimizing what

00:42:08.172 --> 00:42:11.343
the heap looks like so 
allocations are faster and 

00:42:11.572 --> 00:42:14.831
easier over all.  So 
defragmentation in the fore 

00:42:14.832 --> 00:42:18.740
ground, you are not resizing the
heap as often because the heap 

00:42:19.128 --> 00:42:26.324
is always -- we are culling the 
things out of it.  There are 

00:42:27.387 --> 00:42:35.899
fewer GCs FORALLOC because we 
are not in the situation.  So 

00:42:36.173 --> 00:42:39.666
what about the applications and 
services in the fore ground? 

00:42:40.286 --> 00:42:44.054
System, play, UI.  We cannot 
defragment those until it is in 

00:42:44.455 --> 00:42:47.632
a bad situation.  Wouldn't it be
nice to be in the fore ground so

00:42:47.901 --> 00:42:53.045
those are optimized? If we can 
do it for them, we are getting 

00:42:53.227 --> 00:42:57.109
system-wide savings on the heap 
size for all of those 

00:42:57.849 --> 00:43:00.308
applications.  Smaller heaps for
all means less memory.  And the 

00:43:01.001 --> 00:43:04.511
entire device had a 30 percent 
savings on memory requirements.

00:43:04.699 --> 00:43:09.106
And so we can take a look at how
compaction works.  In general, 

00:43:09.107 --> 00:43:12.321
we have these two 56K buckets 
that are assigned per thread.  

00:43:12.613 --> 00:43:16.894
That means again, huge savings 
in not having to lock down all 

00:43:16.895 --> 00:43:19.623
the threads to do the 
allocations in collections.  A 

00:43:19.624 --> 00:43:22.903
thread, if it needs memory, it 
is responsible for itself.

00:43:22.904 --> 00:43:26.938
So a thread says, okay, I need 
memory, it is handed one of 

00:43:26.939 --> 00:43:31.045
these buckets, it allocated it 
in there.  And over time, the 

00:43:32.244 --> 00:43:37.534
thing is defragmented, there's a
heuristic if it is less than 70 

00:43:38.852 --> 00:43:41.556
or 75 percent utliization, we 
can collect it and empty it.  So

00:43:41.557 --> 00:43:45.372
we see the T1-3 regions here, we
don't have a lot going on here. 

00:43:45.646 --> 00:43:49.228
We can take the memory in there,
all of the allocations and shove

00:43:49.513 --> 00:43:52.829
them somewhere else in the heap,
empty out the buckets, and that 

00:43:53.117 --> 00:43:56.643
allows something that is super 
efficient, thread local bump 

00:43:57.091 --> 00:44:00.249
allocatur.  And all we have to 
do is move the pointer.  We 

00:44:00.714 --> 00:44:02.930
don't have to walk the heap to 
find where the free space it, we

00:44:03.281 --> 00:44:06.261
put the next object in the next 
available space and we know 

00:44:06.262 --> 00:44:09.389
where that is according to the 
pointer.  It turns out all of 

00:44:09.390 --> 00:44:12.576
this stuff put together, we are 
now 18 times faster than Dalvik 

00:44:13.158 --> 00:44:16.194
for these allocations.  So we 
can see how these allocations 

00:44:16.195 --> 00:44:19.195
work in practice.  You can see 
all of these little colored 

00:44:19.448 --> 00:44:22.558
objects, we are making space for
them in the different threads 

00:44:24.790 --> 00:44:34.723
that need these allocations.  In
T1, we zeoed it out and we 

00:44:35.000 --> 00:44:38.296
advance the pointer, the pointer
tells us where to put the next 

00:44:38.572 --> 00:44:40.963
one and the one after that and 
so on.  Very fast and easy 

00:44:41.505 --> 00:44:43.796
compared to what we were doing 
before.  On the graph, you can 

00:44:43.959 --> 00:44:47.985
see the comparison of where we 
were at with Dalvik in 

00:44:48.513 --> 00:44:52.067
allocation costs, depending on 
in O, with bump pointer and 

00:44:52.597 --> 00:44:54.597
assembly allocations

00:44:58.942 --> 00:45:01.522
instead.
Where are we going now? It is 

00:45:01.786 --> 00:45:04.529
important to note that the young
generation stuff that we talked 

00:45:04.790 --> 00:45:08.579
about as being so awesome is 
currently gone. 

00:45:08.580 --> 00:45:11.970
SPEAKER: But it is in O stream. 
It will be in the future 

00:45:12.380 --> 00:45:14.167
release. 
SPEAKER: So there are trade offs

00:45:14.168 --> 00:45:17.110
here, we believe it is better 
overall.  All of the benefits 

00:45:17.860 --> 00:45:24.365
you get from the garbage 
collector and O compensates for 

00:45:25.313 --> 00:45:28.977
the older not being there.  Look
for those in a future release. 

00:45:29.117 --> 00:45:31.142
SPEAKER: And object pools, this 
is a technique that we have 

00:45:32.271 --> 00:45:35.572
recommended using in the past, 
we use it ourselves extensively 

00:45:35.904 --> 00:45:40.912
inside the platform.  The wisdom
is reusing an object has to be 

00:45:41.524 --> 00:45:43.864
faster than allocating and 
collecting them all the time.  

00:45:44.279 --> 00:45:47.604
You can see the performance 
graphs, the X axis is the size 

00:45:47.879 --> 00:45:51.399
of the object that you are 
creating or using.  And in red, 

00:45:51.676 --> 00:45:53.676
it is the time it takes to 
handle the objects with the 

00:45:54.040 --> 00:45:57.538
pool, and to allocate and 
collect the objects.  And until 

00:45:57.539 --> 00:46:01.444
N, using a pool is basically 
always a win compared to the 

00:46:01.848 --> 00:46:03.996
garbage collector.
But with O, we all the 

00:46:04.272 --> 00:46:09.901
implements we've done and this 
thread allocator, synchronized 

00:46:10.162 --> 00:46:14.135
pools of objects are generally 
slower.

00:46:14.136 --> 00:46:18.294
And if you have a pool of object
that is only on one thread, that

00:46:18.589 --> 00:46:21.578
thread only, you are actually 
doing the positioning that ART 

00:46:21.852 --> 00:46:29.280
does for you in O   You might 
not see those savings.  In O, 

00:46:29.281 --> 00:46:32.395
you should have a synchronized 
pool of object and you are 

00:46:34.037 --> 00:46:35.073
probably better off without the 
pool. 

00:46:35.074 --> 00:46:38.630
SPEAKER: And there's a certain 
memory size of object where 

00:46:38.961 --> 00:46:41.740
these graphs cross.  This is in 
a benchmark application that is 

00:46:42.028 --> 00:46:44.940
hammering it and maximizing the 
bandwidth.  So the general 

00:46:44.941 --> 00:46:48.409
advice is that you really 
shouldn't use that, especially 

00:46:48.410 --> 00:46:51.528
the synchronized pool approach, 
because A, it is error-prone and

00:46:52.178 --> 00:46:57.950
tedious to manage, and B, it is 
slower in general.  That 

00:46:58.281 --> 00:47:01.597
synchronization access tends to 
be slow e er than what we can do

00:47:02.252 --> 00:47:03.981
now. 
SPEAKER: The point of O is we 

00:47:03.982 --> 00:47:07.883
don't have the lock in anymore 
for the allocations. 

00:47:07.884 --> 00:47:11.743
SPEAKER: So, what are the 
recommendations now? Creating 

00:47:12.215 --> 00:47:14.349
garbage is okay.
I wouldn't go out of your way to

00:47:14.874 --> 00:47:18.321
create garbage, it is still 
taking time.  You are requiring 

00:47:18.322 --> 00:47:21.489
us to take time to allocate 
objects as well as later collect

00:47:22.036 --> 00:47:26.016
them.  And you are taking up 
battery and CPU and you are 

00:47:26.472 --> 00:47:28.472
causing -- 
SPEAKER: And don't do that, 

00:47:28.881 --> 00:47:34.275
Chet, you should see his desk.  
It is pretty disgusting. 

00:47:34.276 --> 00:47:37.653
SPEAKER: I like to be a counter 
example.  Creating this stuff is

00:47:37.654 --> 00:47:41.626
okay, and so is collecting it.  
Use the types and the objects 

00:47:41.973 --> 00:47:45.258
that you need F. It makes sense 
for the architecture, the APIs, 

00:47:46.563 --> 00:47:51.890
for the libraries for the code, 
use those.  We are not pushing 

00:47:52.170 --> 00:47:55.858
everyone to use end to end bit 
flags everywhere.  Instead, go 

00:47:56.797 --> 00:48:00.013
ahead and alCAILT icate when you
need to for the use case.  

00:48:00.014 --> 00:48:03.253
However, GC is overhead. 
SPEAKER: We will demo that that 

00:48:03.761 --> 00:48:05.567
showcases that. 
SPEAKER: And make the right 

00:48:05.568 --> 00:48:07.593
choices for you.
  And, in general, the framework

00:48:08.366 --> 00:48:11.056
programmers, we still are your 
interloop.  So we still take the

00:48:11.325 --> 00:48:15.510
old practices, because why would
we allocate if we didn't need to

00:48:15.842 --> 00:48:18.942
if we can make your inner loop 
faster.  So be aware of the 

00:48:19.193 --> 00:48:25.012
inner loop situations, 
otherwise, it  do the right 

00:48:25.198 --> 00:48:28.065
thing for your code.
  Wrote a simple application to 

00:48:28.834 --> 00:48:31.234
showcase the Jenk you can see 
because of allocations and 

00:48:31.492 --> 00:48:33.492
collections.
  During the on-draw I would 

00:48:33.528 --> 00:48:36.490
call out to a method to run some
stuff.

00:48:36.491 --> 00:48:39.354
And, in this case, we're going 
to test auto boxing.  So we have

00:48:39.894 --> 00:48:45.418
an array of 100,000 float object
objects, capital F.  It is not 

00:48:45.690 --> 00:48:48.452
the primitive float, it is the 
capital F, we are allocating 

00:48:48.453 --> 00:48:51.380
these objects on-the-fly.  This 
is what the method looks like 

00:48:51.815 --> 00:48:54.829
that runs on every frame, walks 
the length of the array and 

00:48:55.477 --> 00:48:58.113
takes a primitive float and 
stuffs it into the array that 

00:48:58.407 --> 00:49:02.364
causes an auto box, so these 
tiny allocations goes into the 

00:49:02.635 --> 00:49:05.406
array.  A lot of them over time,
because of the auto boxing 

00:49:05.407 --> 00:49:08.956
thing, it is going to cause a 
bunch of allocations and we need

00:49:09.176 --> 00:49:10.670
to collect them over time as 
well.

00:49:10.671 --> 00:49:14.345
So, if we take a look at the 
demo.  We will pop out.

00:49:14.346 --> 00:49:16.346
All right.
So we're 

00:49:18.863 --> 00:49:22.481
running on K here, run this 
animation, we should take a look

00:49:22.482 --> 00:49:29.678
at the log here.
We run the auto box, we are 

00:49:29.679 --> 00:49:33.647
coming -- calling out to the 
method.  If you look at the log,

00:49:33.648 --> 00:49:38.919
so we are taking allocation 
times of 28, 24, sort of in 

00:49:38.920 --> 00:49:44.332
general, high-20s milliseconds 
and we're causing a lot of GC, 

00:49:44.630 --> 00:49:47.276
because that is what happens 
when you do this thing.  We can 

00:49:47.433 --> 00:49:50.363
pause this, pop over and see 
what it looks like on O, run the

00:49:50.364 --> 00:49:52.364
animation here.  We enable the 

00:49:57.509 --> 00:50:00.240
log for O.
We do the auto boxing, and zoom 

00:50:00.537 --> 00:50:03.387
in on this.  And the allocation 
times are obviously much less 

00:50:03.588 --> 00:50:08.306
than they were before, and also 
more importantly, there are no 

00:50:08.583 --> 00:50:14.152
GC FOR ALLOCS.  We are not 
triggering the 

00:50:18.887 --> 00:50:23.899
Jenk-inducing ALLOC in this 
case.  There's something similar

00:50:23.900 --> 00:50:27.207
for bit maps. 
We will look at the KitKat log. 

00:50:27.208 --> 00:50:30.873
In this, you are allocating bit 
maps.  Again, we're getting a 

00:50:31.171 --> 00:50:34.906
lot of Jenk there.  If we zoom 
in on the log, the allocations 

00:50:35.193 --> 00:50:37.859
for these large objects, a 
thousand by a thousand bit map, 

00:50:37.860 --> 00:50:42.864
you are taking in 12 or then 
milliseconds each time and you 

00:50:42.865 --> 00:50:48.302
are constantly triggering these 
GC FOR ALLOCs because you need 

00:50:48.303 --> 00:50:51.725
to make memory for the new one.
If you pop over to the O log, we

00:50:51.726 --> 00:50:55.790
will stop this, go over here on 
the animation, do the bit map 

00:50:56.115 --> 00:51:00.221
test, and now we have allocation
times of, well, zero, 1.

00:51:00.222 --> 00:51:06.989
Because again, all that it is 
doing is an Malloc, shoving it 

00:51:07.204 --> 00:51:11.090
in and it is easy to allocate 
and collect when it needs it.

00:51:12.429 --> 00:51:14.429
 Stop that.

00:51:21.705 --> 00:51:23.719
All right.
This is the bit map test, 

00:51:23.981 --> 00:51:25.981
allocating a thousand by a 
thousand bit map.  You can see 

00:51:26.065 --> 00:51:29.433
the results that we did.  
SPEAKER: All right.

00:51:29.434 --> 00:51:33.911
So this is a demo to stress test
to the garbage collector and see

00:51:34.388 --> 00:51:41.176
what overhead we get.  This is a
ray tracer using rendering that 

00:51:41.177 --> 00:51:43.079
I -- 
SPEAKER: You can tell it is a 

00:51:43.080 --> 00:51:45.822
rendering because it is a 
checker board. 

00:51:45.823 --> 00:51:49.921
SPEAKER: That's right.  And I 
brought it over to Android.  I 

00:51:50.321 --> 00:51:53.792
will not run you through the 
code, but this is Kotlin, and it

00:51:54.013 --> 00:51:58.377
does a lot of allocations.  I 
have a data class, it contains 

00:51:58.785 --> 00:52:03.635
three floats, XYZ, those are 
primitives.  Not the capital F 

00:52:04.429 --> 00:52:09.966
objects from Java.  I observed 
the hundreds of lines of code.  

00:52:09.967 --> 00:52:16.228
It is math on the object, we 
have float equal X, we do 

00:52:16.530 --> 00:52:18.880
division and additions.  And the
way these functions are 

00:52:20.423 --> 00:52:24.363
implemented might float through 
is immutable.  Every time I add 

00:52:24.766 --> 00:52:28.649
or multiply, I create a new 
object.  So these are small 

00:52:29.702 --> 00:52:33.998
objects and for every pixel to 
render, we have hundreds of 

00:52:34.262 --> 00:52:39.037
thousands or millions of these 
3s.  So we exercise the GC.  We 

00:52:39.294 --> 00:52:43.438
create two system images, one on
KitKat, one on O, both running 

00:52:43.439 --> 00:52:48.779
on the emulator, running the 
same hardware, on Nexus, with 

00:52:49.043 --> 00:52:53.096
the same number of cores and the
host machine.  The difference is

00:52:53.500 --> 00:52:57.624
the garbage collector.  And what
I will press next, both demoes 

00:52:57.837 --> 00:53:02.263
will run at the same time.  At 
the top is O, bottom is KitKat. 

00:53:02.264 --> 00:53:04.820
See if you can spot the 

00:53:19.605 --> 00:53:23.482
difference in performance.
It takes 47 seconds for KitKat 

00:53:24.133 --> 00:53:26.983
to render the first dial. 
SPEAKER: But it is a good dial. 

00:53:26.984 --> 00:53:30.371
SPEAKER: And we are running the 
exact same application, the 

00:53:30.823 --> 00:53:32.753
difference is the garbage 
collector.

00:53:32.754 --> 00:53:37.883
So on O, rendering one dial 
takes 100 to 500MS, and on K, it

00:53:38.285 --> 00:53:42.993
takes 40 to 50 seconds.  So two 
orders of magnitude slower.  If 

00:53:42.994 --> 00:53:46.866
we look at the logs on KitKat, 
this is what you see.  A bunch 

00:53:47.224 --> 00:53:52.196
of GC file logs, and I grabbed 
logs for 10 seconds' worth of 

00:53:52.610 --> 00:53:56.250
computations.  You can see that 
we are constantly stopping all 

00:53:56.251 --> 00:53:58.784
the threads and blocking the 
applications all the time.  

00:53:58.785 --> 00:54:02.320
Nothing is getting done.
That's a lot of GCs, and you can

00:54:02.572 --> 00:54:08.051
see every time the GC takes 3 to
5 milliseconds.

00:54:08.052 --> 00:54:13.690
So if we can look at systrace on
O, even though things are 

00:54:14.324 --> 00:54:17.041
better, they are not quite 
perfect.

00:54:17.042 --> 00:54:20.775
So this is sys trace here, you 
can see what the CPUs are doing.

00:54:20.776 --> 00:54:24.151
And from the far, it looks like 
they are busy.  They have few 

00:54:24.289 --> 00:54:28.293
worker threads that are are 
computing this 3D scene.  

00:54:28.294 --> 00:54:31.379
There's a lot of cases where the
CPUs are not doing anything, 

00:54:31.645 --> 00:54:33.645
there are holes in the pipe.
So if we look at the app

00:54:37.853 --> 00:54:40.242
itself, we see two interesting 
things.  

00:54:40.243 --> 00:54:43.367
We have the threads that are 
doing the work, and from time to

00:54:44.254 --> 00:54:49.422
time, the pause, and you can 
probably not read this, but it 

00:54:49.677 --> 00:54:52.125
is full suspend check and you 
are not doing any computation.  

00:54:52.126 --> 00:54:55.293
And the reason is that we have 
this thread, the heap test 

00:54:55.772 --> 00:54:59.872
demon.  It is the concurrent 
garbage collector.  So even 

00:55:00.623 --> 00:55:03.481
though we are doing garbage 
collection and allocating so 

00:55:09.304 --> 00:55:16.110
many orbital smany objects, it 
takes so much timetime.  It is 

00:55:16.111 --> 00:55:18.111
blocking anyway.  
It is not pausing because we 

00:55:18.243 --> 00:55:20.986
have to pause them, it is not 
for the algorithms, because the 

00:55:21.415 --> 00:55:23.593
GC is still busy.
  And I was running more threads

00:55:23.975 --> 00:55:30.147
and running into rough situation
situationssituations, I had so 

00:55:30.148 --> 00:55:33.609
many threads that they are 
starting the GC thread.  And as 

00:55:33.610 --> 00:55:38.808
a result, we are only getting 
about 30 to 40 percent CPU 

00:55:39.903 --> 00:55:42.935
utliization.  We don't have all 
the power on the device.  So 

00:55:42.936 --> 00:55:48.437
what you saw on O is three times
faster than that, if it was not 

00:55:48.438 --> 00:55:51.003
allocating as much.
And so one of the things we will

00:55:51.279 --> 00:55:54.694
talk about, we have four minutes
left.  You have to be careful 

00:55:54.907 --> 00:55:58.353
when you create benchmarks, 
because the garbage collector 

00:55:58.816 --> 00:56:01.571
can affect the results of your 
benchmark once, well, not really

00:56:01.874 --> 00:56:05.642
the benchmark itself, but the 
algorithm you are benchmarking. 

00:56:06.289 --> 00:56:09.730
Once it is inside the 
application, it behaves 

00:56:09.731 --> 00:56:16.057
differently.  I will skip this. 
With  when you have a CPU, you 

00:56:16.319 --> 00:56:25.989
have the gold cores.  And everyb
core has a nil 1 cache, every 2 

00:56:25.990 --> 00:56:31.358
core, and there's an L3 cache 
shared by all the cores.  When 

00:56:31.743 --> 00:56:36.766
you want to access data, I have 
a float array.  The first time 

00:56:36.767 --> 00:56:41.120
we assess the float, the CPU 
looks at the L1 cache, sees if 

00:56:41.317 --> 00:56:51.288
it is there, goes to the L 2, if
it is not there then to the L3

00:56:51.749 --> 00:56:54.047
and the program.  And it is more
and more expensive as you go up 

00:56:54.589 --> 00:57:02.345
the chain.  So the L1 takes a 
new nano seconds, 2 is 4 times 

00:57:02.346 --> 00:57:05.177
that amount, 3 is 10 times 
slower, and so on.

00:57:05.178 --> 00:57:07.178
And I wrote a demo that 
allocates the list

00:57:12.488 --> 00:57:17.055
of flow arrayarrays.  Each is 
16MB, represented by the red 

00:57:17.872 --> 00:57:23.707
lines, and I built a benchmark 
using that.  If I look at all of

00:57:24.445 --> 00:57:29.767
those arrays of floats, this is 
what it looks like in RAM.  They

00:57:29.768 --> 00:57:34.472
are neatly stacked together in 
RAM, and I'm using a width of 64

00:57:35.472 --> 00:57:40.436
bytes here for a reason we will 
see in a minute.  And then I 

00:57:40.437 --> 00:57:45.521
wrote a simple algorithm, I go 
through the array, I wrote 

00:57:45.949 --> 00:57:48.573
computations, we will see what 
happens to memory.  So when we 

00:57:48.837 --> 00:57:52.186
access the first float array in 
the list, it is not in the 

00:57:52.187 --> 00:57:54.647
cache, it is in the RAM, and/or

00:58:01.365 --> 00:58:04.293
L1, or the 2 or 3.
  And they are not going to 

00:58:04.663 --> 00:58:07.689
fetch only one byte, but 64 
bytes at a time.  By fetching 

00:58:08.211 --> 00:58:11.280
the first array, we fetch the 
next three at the same time.

00:58:11.281 --> 00:58:15.738
So when I want to read the 
arrays, nothing happens because 

00:58:15.739 --> 00:58:18.517
they are in the L1 cache.
So this is pretty efficient.  

00:58:18.950 --> 00:58:24.494
And then we run our computation.
And in the test app, I have the 

00:58:24.650 --> 00:58:27.329
initialization of the arrays so 
we can allocate other stuff.  

00:58:27.330 --> 00:58:30.777
And I'm doing this to basically 
replicate what happens when the 

00:58:31.754 --> 00:58:36.642
GC moves things around or you 
have fragmentation in the app, 

00:58:36.882 --> 00:58:40.313
and for any number of reasons 
that you are seen before, they 

00:58:40.640 --> 00:58:44.008
are not next to one another in 
RAM.  So I'm representing this 

00:58:44.009 --> 00:58:49.121
with a bunch of gray lines.  If 
you run the algorithm again, we 

00:58:49.383 --> 00:58:52.180
fetch the first array.  And 
instead of fetching the other 

00:58:53.271 --> 00:58:57.994
did I tell  data that we want, 
it is put in the L1.  And in the

00:58:58.441 --> 00:59:02.404
next array, it is not in the L1,
we have to go back to memory and

00:59:02.585 --> 00:59:05.344
get it.  We are running the same
algorithm, but now we have to do

00:59:05.345 --> 00:59:06.816
more.  The CPU has to do more 
work.

00:59:06.817 --> 00:59:13.380
And we can re-create the same 
thing by spacing out the arrays 

00:59:14.271 --> 00:59:19.213
more so we will not find them in
the L2 or L3 and force the CPU 

00:59:19.214 --> 00:59:22.333
to do more work.  If we run the 
different variants of the 

00:59:22.663 --> 00:59:27.333
algorithm, all we did is change 
the way we alquate the objects, 

00:59:27.633 --> 00:59:29.724
running the same computations.  
When everyone is stored together

00:59:30.892 --> 00:59:35.981
in RAM, the algorithm takes 
about 150 milliseconds on the 

00:59:36.382 --> 00:59:39.103
pixel thread.  That the no 
thresh.  And when I space out 

00:59:39.990 --> 00:59:42.800
the allocations so we cannot 
find the data we want in the L1,

00:59:43.068 --> 00:59:48.980
we almost twice as slow and 
running the same computations, 

00:59:49.242 --> 00:59:53.329
but the CPU is busy and fetching
data in RAM.  If I space out the

00:59:53.330 --> 00:59:57.665
computations more so we find it 
in the L2, it is 5 times slower.

00:59:58.073 --> 01:00:00.779
The same exact algorithm.  So if
you write benchmarks, that is 

01:00:01.056 --> 01:00:03.188
really good.  You should 
probably do that.  Be very 

01:00:03.338 --> 01:00:07.793
careful, be aware of the fact 
that the numbers getting to 

01:00:08.171 --> 01:00:10.956
benchmark might be very 
different than the numbers you 

01:00:10.957 --> 01:00:14.630
get in the app running on your 
user's devices.

01:00:14.631 --> 01:00:18.787
And, yeah, you are actually 
benchmarking the CPU access 

01:00:19.388 --> 01:00:21.427
patterns.
And with that, we are done.  We 

01:00:21.428 --> 01:00:23.159
have six seconds left. 
SPEAKER: Very important thing, 

01:00:23.160 --> 01:00:25.160
if you are interested in what we
talked about today, it there's a

01:00:25.729 --> 01:00:30.466
deeper version of this as well 
as the runtime improvements by 

01:00:30.916 --> 01:00:33.752
engineers on the ART team.  So 
check that out, it is at the 

01:00:34.027 --> 01:00:37.802
same time as the fireside chat 
at 11:10.  Please go and see 

01:00:38.078 --> 01:00:41.627
that talk as well.  And that's 
it.  Thank you.  

01:00:41.628 --> 01:00:43.628
SPEAKER: 

01:00:50.658 --> 01:00:52.658
Thanks. 
SPEAKER: [ Applause ]

01:01:01.093 --> 01:01:03.093
.
Coming up next: Use Android Text

01:05:34.951 --> 01:05:36.951
Like a Pro by Siyamed Sinir.
GZ

01:11:50.900 --> 01:11:51.338
name is Siyamed Sinir, I work on
Android text.  And today, I 

01:11:51.339 --> 01:11:55.405
would like to talk about why 
improving your text measurement 

01:11:51.339 --> 01:11:55.272
performance is important for 
your overall apps performance.

01:11:51.339 --> 01:11:55.139
In order to do this, I wanted to
gather some numbers and, 

01:11:51.339 --> 01:11:55.272
therefore, I wrote a simple 
sample app that has a feed and 

01:11:51.339 --> 01:11:55.539
is similar to the applications 
we use every day.  It has a list

01:11:51.339 --> 01:11:55.605
of items, image, and some text. 
And when we look at the text, as

01:11:51.339 --> 01:11:55.605
you can see in the picture, the 
user name and the title for each

01:11:51.339 --> 01:11:55.405
feed item is what we call single
style text.  And the content 

01:11:51.339 --> 01:11:55.005
contains a text that has 
different colors, text sizes, 

01:11:51.339 --> 01:11:54.205
fonts, etc.
  One important point here that 

01:11:51.339 --> 01:11:55.205
I would like to emphasize, on 
our platform right now, the 

01:11:51.339 --> 01:11:55.339
hyphenation is turned on by 
default.  However, in this app, 

01:11:51.339 --> 01:11:55.272
as you can see, there is no 
identificationation applied -- 

01:11:51.339 --> 01:11:55.472
identificationation applied, and
Android runs in correct words 

01:11:51.339 --> 01:11:55.472
side by side, it cannot do any 
hyphenation.  So when you look 

01:11:51.339 --> 01:11:55.605
at each feed item, it has a very
simple structure, a linear layer

01:11:51.339 --> 01:11:55.339
at top, the image layer, and 
fields for title and content.  

01:11:51.339 --> 01:11:55.539
I'm pretty sure it is the same 
or similar to one of your app's 

01:11:51.339 --> 01:11:53.739
existing design or layout 
structure.

01:11:51.339 --> 01:11:55.472
And what I wanted to see was, 
for each field item, what is the

01:11:51.339 --> 01:11:55.539
percentage of the time spent on 
text versus the whole layout.  

01:11:51.339 --> 01:11:54.939
So what I did, I wrote a 
benchmark where I called the 

01:11:51.339 --> 01:11:55.339
linear layout measure, on one 
end, and meanwhile I recorded 

01:11:51.339 --> 01:11:55.205
all the parameters that were 
passed to the different text 

01:11:51.339 --> 01:11:55.472
fields, and I assimilated the 
same thing on those text fields.

01:11:51.339 --> 01:11:53.150
Because of the layout here, the 
TextViews at the top were 

01:11:53.151 --> 01:11:55.151
getting two calls

01:12:02.564 --> 01:12:07.188
each.
In order to have consistent 

01:12:07.459 --> 01:12:09.459
numbers or

01:13:19.095 --> 01:13:24.051
And just turning the hyphenation
off, and turning off hyphenation

01:13:24.052 --> 01:13:29.079
did not have any affect on the 
UI.  Finally, I wanted to check 

01:13:29.080 --> 01:13:33.325
how the had beenumbers would 
improve, if I wanted a new API 

01:13:33.326 --> 01:13:38.696
that I added on Android P and 
AndroidX, for computed text. 

01:13:43.694 --> 01:13:48.377
These numbers were crazy, 4 
milliseconds becomes 20X.  It is

01:13:49.261 --> 01:13:56.647
almost a 2X improvement.
And now I want to describe how 

01:13:57.052 --> 01:13:59.052
predicted text

01:14:02.498 --> 01:14:04.674
works.
I want to show what kind of 

01:14:05.673 --> 01:14:09.283
things we did while doing the 
computed text.  We asked 

01:14:09.846 --> 01:14:14.441
questions, like why text 
measurement is so expensive, and

01:14:14.442 --> 01:14:18.757
since almost at the beginning, 
we did the text performance, and

01:14:19.252 --> 01:14:21.768
as you understand from the 
number, 98, it is always going 

01:14:23.987 --> 01:14:27.431
to be a bottleneck.  Therefore, 
we tried to see, can we move all

01:14:35.883 --> 01:14:41.044
of it and provide an API.  And 
when the system calls measure on

01:14:41.045 --> 01:14:44.826
text field, it does the 
preliminary work and identifies 

01:14:44.827 --> 01:14:48.754
the width and height of the text
edit it contains and according 

01:14:48.755 --> 01:14:53.543
to the parameters that are 
passed to on measure, and the 

01:14:53.748 --> 01:14:57.066
numbers that it finds, it 
creates a layout.  All of these 

01:14:57.471 --> 01:15:00.375
processes goes into our native 
code.  Because we have to use 

01:15:00.376 --> 01:15:02.376
some open source libraries such 
as 

01:15:08.511 --> 01:15:13.148
freetype to measure our text.
And 90 percent of our time is 

01:15:13.543 --> 01:15:17.347
spent on the native code.
And when we process a string 

01:15:17.348 --> 01:15:21.115
like this to our native code, 
what it does is it divides it 

01:15:21.116 --> 01:15:25.157
into words, and then for each 
word, it applies text shaping.

01:15:26.293 --> 01:15:29.772
It finds the font that can 
render the collector and tries 

01:15:30.038 --> 01:15:33.707
to bring those collectcollectors
in the work together.  And then 

01:15:33.708 --> 01:15:36.451
we check out much time this 
takes, compared to all the time 

01:15:36.452 --> 01:15:42.417
that is spent on the native 
code.  It is again more than 90 

01:15:43.313 --> 01:15:45.865
percent.  So text measurement, 
taking the 90 percent of the old

01:15:46.601 --> 01:15:49.679
measurement, native code taking 
ninety percent of the text, and 

01:15:49.680 --> 01:15:54.773
shaping taking more than 90 
percent of the native code means

01:15:55.150 --> 01:16:00.224
that most of the measurement 
time for this app is spent on 

01:16:00.225 --> 01:16:03.010
text shaping.  
The system applies to the same 

01:16:03.366 --> 01:16:05.950
rules for all of the words, for 
each word that is measured, it 

01:16:06.666 --> 01:16:09.032
caches them.
One of the reasons to cache them

01:16:09.809 --> 01:16:12.842
is, just after the measure or 
layout, there will be a draw 

01:16:13.236 --> 01:16:15.236
operation, and the draw will 
need the

01:16:17.952 --> 01:16:20.121
same information.
Then it applies line breaking 

01:16:20.528 --> 01:16:25.975
and identif hyphenation.  Some 
one question here is, why does 

01:16:26.238 --> 01:16:29.623
hyphenation, turning it off, 
improve the performance twice? 

01:16:30.805 --> 01:16:34.663
It is mainly because of, 
whenever it tries to hyphenate, 

01:16:34.664 --> 01:16:37.508
it has to apply text shaping for
more words.

01:16:37.509 --> 01:16:45.581
Let's say that, in here, it the 
the example is divided into X 

01:16:45.910 --> 01:16:50.449
and ample.  It has to do two 
more shaping on two more words.

01:16:51.217 --> 01:16:55.962
So the next creation is, if we 
were to move this expansive 

01:16:56.244 --> 01:17:00.166
measurement background thread, 
what we would need.  The first 

01:17:02.618 --> 01:17:08.717
issue we encountered was, before
P, was acquiring giant 

01:17:09.125 --> 01:17:13.972
synchronization locks.  We fixed
it on Android P, we made it  the

01:17:14.237 --> 01:17:20.942
locks smaller.  Can we use the 
layout classes for such a goal? 

01:17:21.263 --> 01:17:24.445
There were two issues.  Layout 
classes needed a width to be 

01:17:24.721 --> 01:17:27.976
provided to them so they can do 
their calculations.  And that 

01:17:28.294 --> 01:17:31.518
width, you would not have that 
width before measuring.  So it 

01:17:31.943 --> 01:17:37.245
was a chicken and egg problem.
The other one is the layout 

01:17:37.739 --> 01:17:42.030
objects are just reprints for 
the text it contains, like a 

01:17:42.593 --> 01:17:48.848
cache on the Java site, and they
don't know about the previously 

01:17:49.875 --> 01:17:55.212
calculated layout objects, they 
know how many legss layers there

01:17:56.128 --> 01:17:59.427
are, the start and end, and the 
coordinates.

01:17:59.428 --> 01:18:03.394
So we wondered, what if we 
created the construct? First of 

01:18:03.667 --> 01:18:06.956
all, it doesn't need a width.  
Second, it should be able to 

01:18:06.957 --> 01:18:08.957
create it on a background

01:18:12.053 --> 01:18:15.306
thread safely. And it needs 
strong references to the native 

01:18:15.702 --> 01:18:18.188
layout word objects. This is 
important, in terms of layout, 

01:18:18.189 --> 01:18:23.945
if you were to create a layout, 
before you need it, then maybe 

01:18:23.946 --> 01:18:28.434
when it is time to measure or 
render it, you will use the 

01:18:28.435 --> 01:18:36.818
layout objects, they will be in 
the cache and there was no far  

01:18:36.819 --> 01:18:38.477
guarantee you would have steady 
improvement.  

01:18:38.478 --> 01:18:44.447
We wanted to extend this 
construct, because with  we want

01:18:44.648 --> 01:18:48.600
it to be compatible with the 
current APIs and also your 

01:18:49.277 --> 01:18:51.397
applications.
Since it is mostly interested in

01:18:51.959 --> 01:18:55.915
how the text will look, this 
construct needed some parameters

01:18:56.193 --> 01:19:01.550
that will change the next 
styling, such as the text size, 

01:19:01.878 --> 01:19:03.878
color, local,

01:19:06.205 --> 01:19:08.272
and etc.
  One important thing is, that 

01:19:09.072 --> 01:19:11.544
was the reason why previously 
those native objects were being 

01:19:11.794 --> 01:19:15.015
cached and edited.  And it is 
the amount of memory that they 

01:19:15.318 --> 01:19:18.529
use.
And right now, when we use 

01:19:20.382 --> 01:19:24.819
PrecomputedTextPrecomputedText, 
you spend 20KB for 500 

01:19:26.822 --> 01:19:29.283
characters.
  Even though it is spanable, 

01:19:29.284 --> 01:19:35.971
with a mutable interface, every 
calculation that the text does 

01:19:35.972 --> 01:19:38.222
is done at the construction 
type.  You should

01:19:41.639 --> 01:19:45.608
not be calling set span or 
remove span functions, with 

01:19:45.609 --> 01:19:48.419
styling information that will 
change how the text will look, 

01:19:48.420 --> 01:19:53.277
otherwise you will get an 
exception.  That will invalidate

01:19:54.008 --> 01:19:56.810
all of the computation and it 
will be useless.

01:19:56.811 --> 01:20:02.359
And then we look at the 
parameters that PrecomputedText 

01:20:02.753 --> 01:20:05.944
required.  Since most of the 
text styling information is 

01:20:06.136 --> 01:20:09.634
right now encapsulated in the 
text pane, it requires the text 

01:20:09.809 --> 01:20:16.478
pane as a mandatory constructor 
argument.  The others are break 

01:20:18.759 --> 01:20:20.990
strategy and text direction you 
will know from the static layout

01:20:28.038 --> 01:20:29.935
builder.
You will be designing the text 

01:20:29.936 --> 01:20:36.056
styling in the XML, you want the
helper function where you can 

01:20:36.327 --> 01:20:39.095
create the PrecomputedText 
parameters using the text field.

01:20:39.387 --> 01:20:43.910
However, at this point, I would 
like to emphasize that TextView 

01:20:44.547 --> 01:20:50.068
is not required to create a 
PrecomputedText per am, it is a 

01:20:50.380 --> 01:20:54.007
helper function, and it will 
make more sense when we go over 

01:20:54.284 --> 01:20:58.774
how to use PrecomputedText with 
RecyclerView.

01:20:58.775 --> 01:21:00.775
Since version 25, re

01:21:05.131 --> 01:21:11.257
RecyclerView has a prefetch 
feature.  And not only during on

01:21:11.258 --> 01:21:17.492
the unbind folder, you will call
set text and the recycle view 

01:21:17.493 --> 01:21:20.389
will measure the whole layout 
that you just created.  And we 

01:21:20.390 --> 01:21:26.473
know that the measurement part 
of the TextViews are expensive. 

01:21:26.474 --> 01:21:33.178
When you use RecyclerView with 
PrecomputedText, you will change

01:21:33.588 --> 01:21:35.588
set text to set text

01:21:38.284 --> 01:21:40.514
feature, and what 
PrecomputedText will do, before 

01:21:40.515 --> 01:21:44.770
the item is shown on the screen,
go to the background thread, do 

01:21:44.771 --> 01:21:48.184
the text measurement and it will
show the PrecomputedText.  And 

01:21:48.185 --> 01:21:50.772
when the computation is ready, 
it will switch back to the right

01:21:50.773 --> 01:22:00.015
thread and it will call set text
with this PrecomputedText that 

01:22:00.016 --> 01:22:02.016
makes the measurement part much 
faster than the

01:22:10.021 --> 01:22:13.134
previous case.
SPEAKER: You just change it to 

01:22:13.135 --> 01:22:17.460
be set text feature and some 
configuration for para computed 

01:22:17.814 --> 01:22:21.221
text.  And here, what you tell 
the system, please run this task

01:22:21.496 --> 01:22:27.109
on the background thread, and 
para compute my text with this 

01:22:27.278 --> 01:22:31.043
sequence, my data, and this 
display configuration

01:22:31.679 --> 01:22:36.519
configuration.  And this becomes
very handy to complete the para 

01:22:37.273 --> 01:22:42.437
computed text per ams. 
And one point here, if you are 

01:22:43.226 --> 01:22:45.918
changing the text styling 
according to the data you have, 

01:22:47.194 --> 01:22:49.194
you have all of the spanables 
before calling

01:22:55.551 --> 01:23:01.405
this function.
So you can turn off hyphenation 

01:23:04.949 --> 01:23:08.297
in your app globally.  This is 
simple, and you saw the affect, 

01:23:09.230 --> 01:23:14.986
it increases the measurement 
performance by 2X.  And first, 

01:23:15.247 --> 01:23:21.667
we define a new style and turn 
off hyphenation for that style. 

01:23:21.923 --> 01:23:30.174
We use the my bails style for 
load cases, and in version 21, 

01:23:30.420 --> 01:23:34.133
we extend the base TextView 
style from the 

01:23:34.936 --> 01:23:40.096
material.textview.  And finally,
on your team, you set Android 

01:23:40.348 --> 01:23:42.348
TextView style to be your

01:23:47.963 --> 01:23:50.740
new style.
And before I summarize, I will 

01:23:51.031 --> 01:23:55.389
turn off hyphenation in your app
globally so your measurement can

01:23:55.529 --> 01:23:58.772
be faster.  And it is not only 
going to be a text measurement, 

01:23:59.195 --> 01:24:01.311
the whole screen measurement, 
depending on how much text you 

01:24:01.576 --> 01:24:05.836
have, will be almost twice as 
much faster.  And then, please 

01:24:05.837 --> 01:24:10.067
check the PrecomputedText API, 
and if you are using 

01:24:10.335 --> 01:24:15.169
RecyclerView, please apply the 
PrecomputedText and RecyclerView

01:24:15.497 --> 01:24:18.950
prefetch code that I showed to 
you so you get a more smooth 

01:24:19.154 --> 01:24:22.100
scrolling experience for your 
users.

01:24:22.101 --> 01:24:24.101
This is my talk, thank you very 
much for

01:24:32.964 --> 01:24:34.964
listening.

01:26:27.718 --> 01:26:29.718
Coming up next: Files for Miles:

01:29:26.281 --> 01:29:27.456
Where to Store Them All? By Jeff
Sharkey SPEAKER: Hey, everyone, 

01:29:27.457 --> 01:29:32.022
I'm Jeff Sharkey, I'm a software
engineer on the framework team, 

01:29:32.023 --> 01:29:35.110
and we're going to be digging 
into files on Android and all of

01:29:35.111 --> 01:29:37.844
the places that Android gives 
you to store those files.  So 

01:29:37.845 --> 01:29:41.344
today we will start by looking 
at common locations that Android

01:29:42.121 --> 01:29:44.580
offers.
  The first broad category is 

01:29:45.432 --> 01:29:48.302
internal storage.  And this 
storage can be classified as 

01:29:48.879 --> 01:29:53.800
safe and secure, because it is 
something that the Android OS 

01:29:53.801 --> 01:29:56.412
protects and part of the 
application sandbox model we 

01:29:56.413 --> 01:29:59.677
offer.  You have probably 
covered these directories 

01:30:00.137 --> 01:30:02.360
before, like context file, it is
a great place

01:30:06.969 --> 01:30:13.377
to store things.  
We will get into get cash dir, 

01:30:13.717 --> 01:30:16.577
and the file space is not 
counted against the application.

01:30:16.578 --> 01:30:20.536
Android reserves the right to go
in there and delete the files if

01:30:20.537 --> 01:30:23.943
the user needs the disk space 
elsewhere.  It is a trade off 

01:30:23.944 --> 01:30:32.259
and a two-way street.  Another 
directory, get- no back up files

01:30:32.872 --> 01:30:35.847
dir, if you want to migrate 
between devices.  It is a great 

01:30:35.848 --> 01:30:40.048
-- if the device goes through a 
back up and a restore phase, 

01:30:40.049 --> 01:30:43.556
those files in the directory, 
they will thought  not be 

01:30:43.557 --> 01:30:46.881
carried across the back up.  You
can use it for that.  

01:30:46.882 --> 01:30:55.744
And finally, get code cash dir, 
for jitted and optimized code.  

01:30:56.503 --> 01:30:58.503
It will delete under two 
conditions, when the application

01:30:58.691 --> 01:31:06.105
is updated via Play Store, or 
whenever the OS itself has an 

01:31:06.264 --> 01:31:09.331
upgrade, from the release to the
pre-release, it will clear the 

01:31:09.987 --> 01:31:12.929
directory.  And another broad 
category of locations is 

01:31:13.272 --> 01:31:15.703
external storage.  When we think
of that, it is more of a shared 

01:31:16.123 --> 01:31:18.572
area and it is unprotected.
And the reason I just

01:31:22.613 --> 01:31:25.312
mention that is data showed in 
that location, you may write it 

01:31:25.517 --> 01:31:28.499
there, and other applications 
can request the storage 

01:31:28.770 --> 01:31:30.969
permission on Android and they 
can write the data or modify it 

01:31:31.293 --> 01:31:34.958
without you knowing about it.  
So it is something that we 

01:31:35.576 --> 01:31:37.576
definitely discourage storing 
sensitive contents in that 

01:31:37.870 --> 01:31:39.969
location.  If you need to store 
data there, consider finding a 

01:31:40.243 --> 01:31:44.609
way to prevent and to verify the
integrity of that data if you 

01:31:44.994 --> 01:31:49.821
need to trust it.  The 
directories here, similar to 

01:31:50.828 --> 01:31:55.258
internal storage.  External 
media dirs are scanned by media 

01:31:55.546 --> 01:31:58.755
store on the device.  It is a 
good place to store photos or 

01:31:59.196 --> 01:32:03.555
videos included in the user's 
gallery application.  Get 

01:32:06.017 --> 01:32:13.100
OBBDIRS, OBB stands for opaque 
binary blocks, they are large 

01:32:13.546 --> 01:32:16.370
blocks for Google Play.  And 
data in those locations are 

01:32:16.789 --> 01:32:19.875
counted toward the app's code 
size rather than data size.  So 

01:32:20.159 --> 01:32:22.569
far, we have talked about 
internal and external storage.  

01:32:22.840 --> 01:32:25.764
And these are all great places 
for you to store data that 

01:32:25.947 --> 01:32:29.515
belongs to your app.  Be but you
might find yourself creating 

01:32:30.053 --> 01:32:32.906
data that belongs to the user 
that the user may want to store 

01:32:33.190 --> 01:32:35.275
in a different location.  And 
that's a great place to use the 

01:32:35.576 --> 01:32:38.601
storage access framework.
And there are two intents that 

01:32:38.602 --> 01:32:41.518
work great there, intent action 
open document and create 

01:32:41.655 --> 01:32:44.275
document.  These have been 
around in the platform since the

01:32:44.653 --> 01:32:48.538
KitKat release, you can think of
them as an open and a saved 

01:32:48.811 --> 01:32:50.865
dialogue box for the user.  It 
really offers a great 

01:32:51.232 --> 01:32:53.458
experience, because the user has
control over exactly where those

01:32:53.792 --> 01:32:59.101
files are stored on the device.
It givesthem the freedom to 

01:32:59.495 --> 01:33:02.252
choose any of those locations, 
and opens the door for cloud 

01:33:03.156 --> 01:33:08.122
storage for  providers.  You 
don't have to integrate an SDK, 

01:33:08.390 --> 01:33:11.009
you can launch the intent and 
the user can select where they 

01:33:11.010 --> 01:33:14.229
want the file to be stored.  
There are great talks, I 

01:33:14.478 --> 01:33:17.876
encourage you to search around 
online, there is great content 

01:33:18.381 --> 01:33:21.200
that goes more in depth.  We 
talked about basic locations, 

01:33:21.201 --> 01:33:24.999
let's do a deep dive on two 
scientific advanced locations 

01:33:25.000 --> 01:33:29.654
today.  One is direct boot, and 
the second we will dig into is 

01:33:29.655 --> 01:33:32.831
cached data.  The first is 
direct boot that you may not 

01:33:33.085 --> 01:33:37.335
have encountered before.  And it
is worth starting out, we built 

01:33:37.595 --> 01:33:41.274
the direct boot feature to solve
an important problem.  When 

01:33:41.599 --> 01:33:47.280
before the end release, when we 
encrypted an Android device, if 

01:33:47.281 --> 01:33:52.005
the user re-booted it, no apps 
can run until the user entered 

01:33:52.485 --> 01:33:54.848
their credentials, a pin, a 
pattern, and password.  In the 

01:33:55.462 --> 01:33:58.199
end releases, we created two 
storage areas, they are 

01:33:58.200 --> 01:34:01.574
encrypted but with two different
keys.  And we call these areas 

01:34:01.575 --> 01:34:07.832
the device protected area and 
the credential protecteded area.

01:34:08.226 --> 01:34:11.787
The device protected area is 
available by virtue of the 

01:34:12.336 --> 01:34:17.876
device proving it has not been 
tampered with.  When the device 

01:34:18.976 --> 01:34:23.088
boots up, it verifies it has not
been tampered with and unlocked 

01:34:23.089 --> 01:34:29.834
the protected storage.  When the
user enters the pin, pattern, or

01:34:29.835 --> 01:34:32.103
password, it is available for 
applications to use.  If you 

01:34:32.429 --> 01:34:35.984
have not encountered these APIs 
before, all of your data by 

01:34:35.985 --> 01:34:40.391
default as an app developer is 
stored in a credential-protected

01:34:40.954 --> 01:34:43.067
area.  If you find a place where
you would like to run before the

01:34:43.471 --> 01:34:47.187
user has unlocked their device, 
that is where it might be useful

01:34:47.345 --> 01:34:49.345
to store small bits of 
information out in that 

01:34:50.103 --> 01:34:52.676
device-protected area so that 
your app can be useful while the

01:34:52.677 --> 01:34:57.936
device is locked.  And then you 
might ask the question, how do 

01:34:58.468 --> 01:35:00.621
you gain access to the storage 
area? 

01:35:04.481 --> 01:35:07.378
Context.get-files.dir offers 
that's area.  And there's a 

01:35:07.379 --> 01:35:11.477
method on context, create device
protected storage context, 

01:35:11.478 --> 01:35:13.969
that's a little bit of a 
mouthful.  It returns another 

01:35:14.465 --> 01:35:17.664
different context where the file
APIs, referring to internal 

01:35:17.876 --> 01:35:20.899
storage, on that returned 
context point at the device 

01:35:22.038 --> 01:35:25.140
protected storage.  So let's 
take a look at some code 

01:35:25.428 --> 01:35:29.651
examples of how you might 
integrate with those APIs.  If 

01:35:30.051 --> 01:35:33.883
you want to become device 
direct-boot aware, is to think 

01:35:34.723 --> 01:35:38.074
about what data you want to keep
on credential protected storage 

01:35:38.636 --> 01:35:42.316
or migrated.  So a lot of you 
are writing code like this, 

01:35:42.317 --> 01:35:45.495
during the initial upgrade step,
how to migrate data back and 

01:35:45.496 --> 01:35:48.065
forth.  The first thing you will
do in starting the application 

01:35:48.334 --> 01:35:54.426
is to ask, is the user unlocked?
Has the pin, pattern, or 

01:35:54.887 --> 01:35:57.605
password been offered? So you 
can check, is the current user 

01:35:58.088 --> 01:36:00.601
unlocked? Assuming they are, 
that means you have access to 

01:36:00.602 --> 01:36:03.252
the device and the credentialed 
storage. And here, you can see 

01:36:03.908 --> 01:36:08.694
there are two move methods at 
helpers.  You can move the 

01:36:08.968 --> 01:36:11.545
preferences and databases back 
and forth.  The reason we 

01:36:11.546 --> 01:36:16.057
provide these helper methods is 
often times shared preferences 

01:36:16.058 --> 01:36:18.812
and databases can actually be 
made up of multiple files on 

01:36:19.198 --> 01:36:23.668
disk and some of that data may 
be cached in memory.  By calling

01:36:23.872 --> 01:36:28.333
the helper methods, we ensure 
that all of the data is moved 

01:36:29.075 --> 01:36:31.670
and any in-memory caches are not
invalidated along the way.  When

01:36:32.005 --> 01:36:35.851
you think about data you want to
migrate, one thing we say is 

01:36:36.379 --> 01:36:38.369
only move the data you need to 
provide the user experience 

01:36:38.370 --> 01:36:41.135
while the device is locked.  So 
if you are building the alarm 

01:36:41.830 --> 01:36:44.412
clock app, we will move the 
user's next alarm time into that

01:36:45.353 --> 01:36:47.802
device-protected area to make 
sure that the alarm clock will 

01:36:48.070 --> 01:36:53.806
go off if the user's device is 
currently locked.  Another 

01:36:54.160 --> 01:36:57.745
strategy, if you have 
off-tokens, we recommend that 

01:36:58.221 --> 01:37:02.626
people create a second type of 
authtoken for your full server. 

01:37:02.937 --> 01:37:07.788
One ask a full access token, we 
recommend keeping that in the 

01:37:09.605 --> 01:37:12.978
credential-protected area and 
creating a simple, limited in 

01:37:13.522 --> 01:37:17.798
scope token auth token and only 
storing that in the device 

01:37:18.058 --> 01:37:24.114
protected area.  And maybe when 
it talks to your server in the 

01:37:24.623 --> 01:37:28.575
back end, it has three messages 
and cannot do operations beyond 

01:37:28.831 --> 01:37:34.216
that.  It gets the user's 
experience when you need to, 

01:37:34.767 --> 01:37:36.425
without accessing the richer 
information in the cloud.  So we

01:37:36.426 --> 01:37:39.757
have talked, if it is unlocked, 
we can migrate data back and 

01:37:41.081 --> 01:37:44.363
forth.  And the else clause 
here, there's a run time 

01:37:44.751 --> 01:37:48.159
broadcast that is here, for user
unlocked, to run the code when 

01:37:48.160 --> 01:37:51.457
the user enters that pin, 
pattern, or password.

01:37:51.458 --> 01:37:56.352
And the middle code snippet 
here, the move methods, they 

01:37:56.586 --> 01:37:59.033
work in both directions.  If you
move the data out into the 

01:37:59.208 --> 01:38:04.256
device proteched  protected 
area, you can move it into the 

01:38:04.257 --> 01:38:06.981
credentialed area.  And on the 
bottom of the screen, if you are

01:38:07.435 --> 01:38:09.735
wondering if a particular file 
is going to be encrypted at REST

01:38:10.038 --> 01:38:13.632
by the operating system, you can
quickly check for that as well. 

01:38:14.018 --> 01:38:19.823
There's a storage manager, is 
encrypted API.  That can be 

01:38:20.262 --> 01:38:26.076
helpful when you are rollering  
rolling your own encryption.  

01:38:26.340 --> 01:38:30.685
And the second dive is cached 
data on the OS.  This is data 

01:38:31.044 --> 01:38:34.591
that you can regenerate or 
redownload later on if it 

01:38:36.746 --> 01:38:39.841
happens to be deleted.  This is 
a two-way street, the OS will 

01:38:40.139 --> 01:38:43.841
not count the data that you use 
in that area against the app, 

01:38:44.090 --> 01:38:47.465
but we reserve the right to 
delete that data if the user 

01:38:47.836 --> 01:38:49.956
needs the disk space for 
something else they are doing.  

01:38:49.957 --> 01:38:53.884
Something we improved in the O 
release, we rewrote the 

01:38:54.093 --> 01:38:57.098
algorithms used internally.  A 
big question we got from you, 

01:38:57.373 --> 01:39:00.104
from developers, is how much 
cached space is appropriate to 

01:39:00.491 --> 01:39:07.402
use? Can I use 500MB, is that 
too much, is 50MB too much? Now 

01:39:08.020 --> 01:39:13.564
we offer explicit guideguidance.
There's an API to figure out a 

01:39:14.972 --> 01:39:17.722
cached quota for your 
application, that the device 

01:39:17.980 --> 01:39:21.651
thinks is reasonable for the app
to use.  And it adjusts it over 

01:39:22.071 --> 01:39:24.434
time.  If the user spends a lot 
of time in the application, we 

01:39:24.720 --> 01:39:27.739
will increase the number so you 
can offer a better user 

01:39:27.740 --> 01:39:31.607
experience to your users.
And another thing we did in the 

01:39:32.232 --> 01:39:35.246
O release, we rewrote the 
implementation of how that data 

01:39:36.136 --> 01:39:38.492
is cleared.  Before the O 
release, we list all of the 

01:39:38.770 --> 01:39:42.607
cached files on the OS, sort 
them by modified time and delete

01:39:42.874 --> 01:39:47.828
the oldest files.  There are 
ways to gameify the system, by 

01:39:48.226 --> 01:39:52.943
setting the time out to the year
2038.  So we fixed that.  In O 

01:39:53.444 --> 01:39:57.543
and future releases, the OS will
delete data fromp appessibility 

01:39:58.536 --> 01:40:03.256
Partners s most over the the 
quota first.  If your app is in 

01:40:03.257 --> 01:40:05.684
the cached quota that the OS 
recommended, you can be 

01:40:06.026 --> 01:40:08.629
confident that the data is there
and will remain available as the

01:40:08.630 --> 01:40:11.403
user starts filling up their 
disk.

01:40:11.404 --> 01:40:19.385
And soso let's look at code 
snippets.  If you are 

01:40:19.967 --> 01:40:23.342
integrating with a common class,
it is easy to connect the two 

01:40:23.679 --> 01:40:28.883
things together.  We can ask for
the recommended cached quota 

01:40:29.139 --> 01:40:33.142
bytes and plug it in to trim how
much size it is using.  If you 

01:40:33.760 --> 01:40:35.958
have multiple types of caches, 
it is up to you to decide how 

01:40:36.616 --> 01:40:40.611
you want to fractionally account
or distribute the cache against 

01:40:40.612 --> 01:40:44.784
the internals of your app.  The 
second code snippet, if you are 

01:40:46.572 --> 01:40:49.044
rolling your own caching, 
there's get cache size bytes, a 

01:40:49.408 --> 01:40:52.098
fast way to ask the question, 
how much cached space the app is

01:40:52.657 --> 01:40:55.628
using.  It is an optimized call 
that will return and

01:41:00.035 --> 01:41:02.035
it should  it is faster than you
iterating over the disk usage to

01:41:02.484 --> 01:41:04.722
figure out how much space you 
are using.

01:41:04.723 --> 01:41:07.202
And another feature of the O 
release is the ability to have 

01:41:07.410 --> 01:41:12.669
cached bihaviors.  We heard from
developers that it is useful, 

01:41:13.062 --> 01:41:18.134
you may download multiple files,
it should be treated as a unit 

01:41:18.429 --> 01:41:22.270
or a group.  You can download a 
movie and a sub titles file that

01:41:22.271 --> 01:41:25.310
goes with it.  If you store both
in the cached directly, if one 

01:41:25.743 --> 01:41:28.247
of them is deleted, the other 
file is not useful and valuable.

01:41:28.248 --> 01:41:33.479
So the cached behavior allows 
you to tell us, as the OS, if we

01:41:33.761 --> 01:41:36.443
need disk space, we should 
delete both of these at the same

01:41:36.787 --> 01:41:40.888
time.  So we talked about the 
common storage locations, we 

01:41:41.170 --> 01:41:45.479
will talk about how we can work 
together, both the OS helping 

01:41:45.480 --> 01:41:47.876
you as developers.  And the 
biggest thing we offered in the 

01:41:48.365 --> 01:41:51.528
O release is helping you get the
disk space that you need.  

01:41:51.529 --> 01:41:57.012
Before the O release, in if you 
wanted to do a large download, 

01:41:57.281 --> 01:42:00.779
and if you looked at the free 
disk space, you may only see 

01:42:01.037 --> 01:42:04.474
500MB for free.  It may look 
like the download was 

01:42:04.753 --> 01:42:09.840
impossible.  There is a new a.m.
tin the  API in the O release, 

01:42:12.365 --> 01:42:15.079
it will delete cached files for 
the operation to succeed in the 

01:42:15.351 --> 01:42:19.689
application.  If there isn't 
enough disk space, there are new

01:42:20.019 --> 01:42:23.847
intents to launch to get the 
user involved, to pick items and

01:42:24.116 --> 01:42:28.280
things they can do to help free 
up the disk space.  How to use 

01:42:28.545 --> 01:42:31.898
the API? The very top of the 
slide, this is a way that you 

01:42:32.180 --> 01:42:37.179
are writing code today.  You 
will do a simple check, a 

01:42:37.180 --> 01:42:44.738
download size, Java.I/O.file/get
usable space.  That's an 

01:42:44.739 --> 01:42:47.735
operation that looks like it is 
not possible to succeed.  If you

01:42:48.355 --> 01:42:51.211
convert the code using the 
snippet on the slide, if you 

01:42:51.510 --> 01:42:55.237
call storage manager.get 
allocated bytes.API, it will 

01:42:55.636 --> 01:43:00.236
return not just the free space, 
but the space that the OS is 

01:43:00.457 --> 01:43:03.987
willing to free up on your 
behalf.  So in this case it may 

01:43:04.295 --> 01:43:08.296
look like, if we have enough 
space, we can actually open the 

01:43:08.651 --> 01:43:12.503
file output stream and now there
is an API, allocate bytes.  And 

01:43:12.504 --> 01:43:16.243
this will actually claim that 
disk space for your application,

01:43:16.581 --> 01:43:19.246
deep underneath, it will use the
F allocate system call to make 

01:43:20.565 --> 01:43:22.565
sure that the blocks

01:43:23.898 --> 01:43:27.895
belong to the application and 
you have the space guaranteed to

01:43:29.863 --> 01:43:31.863
you.
  And the else block here, if 

01:43:32.002 --> 01:43:34.746
there is not enough space, we 
can ask the user for help to 

01:43:35.011 --> 01:43:39.419
free up the disk space.
Sharing content, we covered this

01:43:39.701 --> 01:43:43.594
before.  How can we work 
together there? Use content URIs

01:43:43.857 --> 01:43:48.075
when you are sharing between 
applications, never use file U 

01:43:48.076 --> 01:43:51.298
RRBS  RIs.  In sharing the 
application, you do not have the

01:43:51.771 --> 01:43:55.214
permissions that you need to 
access the files on disk.  If 

01:43:55.575 --> 01:44:01.633
you use content URIs, the OS can
make sure that they can open the

01:44:01.634 --> 01:44:04.890
content.  If you find yourself 
in this position, the file 

01:44:05.223 --> 01:44:08.001
provider is a great way to 
convert between the two with a 

01:44:08.263 --> 01:44:11.118
single line of code, every place
to convert from file to content.

01:44:11.380 --> 01:44:14.614
And over the years, because this
is an important thing to pay 

01:44:14.876 --> 01:44:20.118
attention to, we built strict 
mode APIs to detect these places

01:44:20.405 --> 01:44:24.386
in your app where you are 
accidentally sharing file URIs 

01:44:24.387 --> 01:44:26.744
and in a more recent release, 
you can detect where you are 

01:44:27.013 --> 01:44:31.527
sharing a content URI and you 
are forgetting the read or right

01:44:31.747 --> 01:44:35.051
to go along with that intent.  
Those are two URIs that are 

01:44:35.243 --> 01:44:37.519
helpful to look at.
And native code, that is another

01:44:37.816 --> 01:44:42.356
area to think about.
And we strongly recommend that 

01:44:42.641 --> 01:44:48.954
you look at opening files up in 
higher-level managed code, in 

01:44:49.114 --> 01:44:53.456
Java or Kotlin, and passing the 
file descriptor down into the 

01:44:53.707 --> 01:44:57.187
native code.  Opening a managed 
code gives the OS an opportunity

01:44:57.490 --> 01:45:02.926
to notice, inspect, and correct 
things.  It can look for strict 

01:45:02.927 --> 01:45:05.999
mode violations.  If you open up
the managed code, it may notice 

01:45:06.272 --> 01:45:10.439
that the thread you are running 
on is causing a block or Jenk in

01:45:10.711 --> 01:45:13.388
your app.  We are going to start
using this more in future 

01:45:13.873 --> 01:45:17.536
Android release sreleases.  So 
open the file in

01:45:21.597 --> 01:45:27.598
Java, past the integer, to the 
code.  Don't move it past the 

01:45:27.599 --> 01:45:30.913
file itself.  And you can do 
this with parcel file 

01:45:31.439 --> 01:45:35.886
descriptor, you can open up the 
file on disk, for read/write, 

01:45:37.019 --> 01:45:42.425
and there's detach FD that 
returns the integer that is 

01:45:43.096 --> 01:45:46.838
ready to cross against the J&amp;I 
boundary.

01:45:46.839 --> 01:45:50.027
And another method that is a tip
or trick that is useful.  If you

01:45:50.415 --> 01:45:54.942
find yourself crossing against 
J&amp;I to do a handful of system 

01:45:55.866 --> 01:45:58.858
calls, look at 
Android.system.OS, there are 

01:45:59.170 --> 01:46:01.622
several calls for you to use in 
Java today.  We added that a 

01:46:02.052 --> 01:46:07.561
couple releases ago, so you may 
be able to FIMEGD  find that you

01:46:07.856 --> 01:46:14.818
can do the sis calls in Java and
you can get rid of the J&amp;I in 

01:46:14.819 --> 01:46:16.528
the application. 
SPEAKER: And working with media,

01:46:16.529 --> 01:46:22.577
we recommend that you use media 
store if you are looking to find

01:46:22.968 --> 01:46:27.011
the files on your device.  You 
might be tempted to build your 

01:46:27.421 --> 01:46:30.894
own index, that can be wasteful 
in terms of CPU and battery for 

01:46:31.153 --> 01:46:34.637
the user. And we are working on 
improving media store and really

01:46:34.638 --> 01:46:38.973
adding functionality there.  So 
stay tuned over the next couple 

01:46:39.272 --> 01:46:43.660
releases.  And another note, 
open files, open the content of 

01:46:43.661 --> 01:46:46.183
the media through content 
resolver.  There are columns 

01:46:49.101 --> 01:46:53.848
across the operating system 
called _ data, they return a raw

01:46:54.192 --> 01:46:58.223
system file path.  You may 
notice that a couple of the _ 

01:46:59.589 --> 01:47:01.938
data columns have been 
deprecated in previous releases.

01:47:02.146 --> 01:47:06.071
That is going to continue, you 
may notice those columns 

01:47:06.343 --> 01:47:11.535
deprecated over time.  We want 
people to merge over to content 

01:47:12.148 --> 01:47:14.594
URIs as a best practice.  Thank 
you for your time, in digging 

01:47:15.686 --> 01:47:18.779
into the nitty-gritty areas of 
storage.  I will be in the Q&amp;A 

01:47:18.780 --> 01:47:23.789
storage after if you have 
equations -- questions for me.  

01:47:23.790 --> 01:47:25.790
Thank you for your time.

01:48:12.544 --> 01:48:14.544
[ Applause ]
Coming up next: Deep Dive into 

01:49:26.944 --> 01:49:30.144
the ART Runtime by Nicolas 
Geoffray, David Sehr.

01:49:26.944 --> 01:49:29.055
. 
SPEAKER: Everyone, the next 

01:49:29.365 --> 01:49:31.365
session will begin in 10 

01:49:39.041 --> 01:49:41.041
minutes.

01:59:36.780 --> 01:59:41.763
SPEAKER: Hello, everyone.
I'm Nicholas from the Android 

01:59:42.057 --> 01:59:45.172
platform team, thanks for being 
here.  I'm impressed that there 

01:59:45.950 --> 01:59:49.664
are people showing up.  The 
Android fireside chat was kind 

01:59:50.042 --> 01:59:52.042
of scaring me, everyone just 
avoided

01:59:56.650 --> 01:59:59.071
the session.
It is great to have you here, 

01:59:59.072 --> 02:00:02.202
this talk is about ART.  There's
a change in the schedule this 

02:00:02.461 --> 02:00:05.973
morning, you may have attended 
Chet's talk.  Who went to Chet's

02:00:07.043 --> 02:00:08.827
talk?
Okay.

02:00:08.828 --> 02:00:14.616
How was it, was it good?
Yeah, were you excited?

02:00:14.617 --> 02:00:16.617
18X, allocation

02:00:19.674 --> 02:00:21.674
times?
So there's a part of this talk, 

02:00:22.423 --> 02:00:24.720
that was supposed to be on 
garbage collection, and my 

02:00:25.506 --> 02:00:28.976
colleague, David, was planning 
on giving. But we are not going 

02:00:28.977 --> 02:00:34.672
to re-hash the same thing.
So I will put long pauses, 

02:00:34.962 --> 02:00:39.462
awkward ones, I hope, during the
talk so I can fit it to 40 

02:00:39.735 --> 02:00:45.098
minutes.  So bear with me.
So, given that we're celebrating

02:00:45.530 --> 02:00:49.831
10 years of Android, I thought 
it would be a good idea to think

02:00:50.725 --> 02:00:54.402
about what we've done the last 
10 years, and how the Android 

02:00:54.692 --> 02:00:57.206
run time, the thing that we 
worked on for a couple of years 

02:01:00.643 --> 02:01:02.643
now evolved.  So here we

02:01:05.519 --> 02:01:07.519
are.
So some of you went to Chet's 

02:01:07.689 --> 02:01:10.983
talk, so I guess you already 
know what an Android runtime is 

02:01:11.252 --> 02:01:16.812
in the Android stack.  But in 
case you don't, it is the little

02:01:16.959 --> 02:01:20.622
layer here between the Android 
framework, the Android operating

02:01:20.963 --> 02:01:26.701
system, and the actual 
underlying Kernel.

02:01:26.702 --> 02:01:31.732
The runtime runs both the 
Android framework, and all the 

02:01:32.007 --> 02:01:34.007
apps, so everything between Java
that we

02:01:39.331 --> 02:01:41.601
execute.
And being core in the platform, 

02:01:41.602 --> 02:01:44.657
it is responsible for a ton of 
things, like the user experience

02:01:45.004 --> 02:01:49.511
could be very bad if the run 
time was more efficient.  You 

02:01:49.785 --> 02:01:55.586
saw it this morning with how the
GC was sort of, kind of, poor in

02:01:57.036 --> 02:01:59.036
the

02:02:04.628 --> 02:02:06.851
Dalvik days.
  I will show you that the 

02:02:07.113 --> 02:02:11.254
runtime versions, the itRAISHZ 
itRAISHZ -- iterations over the 

02:02:11.504 --> 02:02:16.296
past, what do we need to improve
for this year? Like I said, ART 

02:02:16.297 --> 02:02:21.097
runtime is possible for a bunch 
of things.  And role performance

02:02:21.405 --> 02:02:25.244
is one clear one, how fast we 
can execute Java code.  And 

02:02:25.681 --> 02:02:29.555
clearly, it is also responsible 
for Jenk, the 16 milliseconds 

02:02:29.862 --> 02:02:33.457
window, if the runtime is not 
able to execute the Java code of

02:02:33.874 --> 02:02:38.176
the app, then we will miss the 
frame and produce a lot of Jenk.

02:02:38.964 --> 02:02:41.965
The applications start-up, 
there's a lot of Java code that 

02:02:42.594 --> 02:02:45.553
needs to be executed during the 
application start-up.  If the 

02:02:45.859 --> 02:02:48.432
run time is slow, the start-up 
will be slow.

02:02:52.898 --> 02:02:58.947
Boot times, a lot of code 
executes during boot.  Battery 

02:02:59.196 --> 02:03:02.855
time, if you are slow, we will 
tank the battery.  And install 

02:03:03.143 --> 02:03:07.331
time is something that we care 
about.  When we get an APK, the 

02:03:07.756 --> 02:03:10.340
platform will optimize it and 
that could take a long time, 

02:03:10.511 --> 02:03:12.706
depending on how we implement 
it.

02:03:12.707 --> 02:03:15.158
And we don't want that long time
to happen, because we want you 

02:03:15.391 --> 02:03:21.830
to use the app right away.
And the other tool, which is 

02:03:23.582 --> 02:03:24.785
memory-relatememory-related, is 
disk space. 

02:03:24.786 --> 02:03:31.822
It is how much space is the 
runtime taking for its own opt  

02:03:32.089 --> 02:03:36.691
optimizations, and RAM.  Java 
being Java, is there an 

02:03:36.943 --> 02:03:39.019
allocation that the runtime 
needs to handle.  If it doesn't 

02:03:39.193 --> 02:03:41.193
do it well, it can take a lot of

02:03:45.365 --> 02:03:47.922
RAM.
So this is essentially, there 

02:03:48.217 --> 02:03:54.652
has been three incarnations of 
the Android runtime.

02:03:54.653 --> 02:03:58.072
The first one was Dalvik, it was
the first implementation that 

02:04:00.243 --> 02:04:04.190
shipped with Android.
And Dalvik's purpose, or 

02:04:04.469 --> 02:04:08.037
Dalvik's main focus was how do 
we save RAM? And the reason 

02:04:08.038 --> 02:04:12.577
being, back in the day, 10 years
ago, the RAM we had on the 

02:04:12.983 --> 02:04:16.738
phones we're shipping was even 
less than 200MB.  And that was 

02:04:17.035 --> 02:04:21.973
very little if you want to 
execute the whole Android stack.

02:04:22.251 --> 02:04:26.397
So everything Dalvik was doing 
was about, okay, how it  do we 

02:04:26.657 --> 02:04:36.099
save on RAM? So you cannot 
generate any code, JIT or AOT is

02:04:36.100 --> 02:04:39.786
how we generate code.  It 
interprets the text code, what 

02:04:40.490 --> 02:04:43.832
is sent to Android for execution
over the app.  Eventually, you 

02:04:44.750 --> 02:04:50.017
get a Just in Time compiler so 
you can generate native code.  

02:04:50.018 --> 02:04:53.818
But again, it was very limited 
to what it could do, because RAM

02:04:54.125 --> 02:05:01.510
was the main focus.
And, as you see, this was 

02:05:02.656 --> 02:05:05.767
tailored for apps not allocate 
objects.  If you have been to 

02:05:06.197 --> 02:05:09.356
the talk this morning, things 
have changed.  But, back in the 

02:05:09.572 --> 02:05:14.425
day, the recommendation was, 
like, please avoid allocations.

02:05:14.839 --> 02:05:20.918
And this worked well for, I 
think, five years, until KitKat.

02:05:21.166 --> 02:05:26.126
But there was, like, a point 
where, like, Dalvik could not 

02:05:26.332 --> 02:05:30.225
keep up.  Phones were getting 
bigger -- phones were getting 

02:05:30.845 --> 02:05:38.801
more performant, more RAM, like 
the -- that was 2013 or 2014, 

02:05:39.476 --> 02:05:44.003
the 1GB, 2GB of RAM.
And apps were also getting 

02:05:44.589 --> 02:05:46.589
bigger.
So initially apps were supposed 

02:05:46.872 --> 02:05:49.841
to be like this small layer 
between the UI and the 

02:05:49.842 --> 02:05:53.270
framework, but apps started 
doing a lot of more and more 

02:05:54.062 --> 02:06:00.398
things.  So that 16 millisecond 
window I talked for rendering a 

02:06:00.399 --> 02:06:03.219
frame, more was being executed 
there.  So we have to do 

02:06:03.220 --> 02:06:08.496
something about it.  And the 
answer happened in Lollipop with

02:06:08.946 --> 02:06:10.946
ART,

02:06:13.343 --> 02:06:17.918
which introduced ahead-of-time 
compilation, and most of the 

02:06:17.919 --> 02:06:22.526
things were ahead-of-time 
compiled, we were executing 

02:06:22.527 --> 02:06:26.505
native code for the app.  And 
that is 20X faster than 

02:06:26.824 --> 02:06:30.406
interpretation.
And we also introduced, like, a 

02:06:32.100 --> 02:06:35.607
state-of-the-art GC, what you 
find in regular runtimes of 

02:06:35.608 --> 02:06:38.662
being precise.  That means we 
are not going to be confused by 

02:06:39.003 --> 02:06:42.626
an integer that looks like an 
object.

02:06:42.627 --> 02:06:47.728
But also generations, so that 
the GC pauses we need to do in 

02:06:48.554 --> 02:06:52.895
the UI thread will be very 
short.  So pauses will actually 

02:06:53.287 --> 02:07:02.452
end up creating Jenk.
The third incarnation is like an

02:07:02.453 --> 02:07:07.655
evolution of art, it happened in
two releases, like Android 

02:07:09.212 --> 02:07:14.539
Nougat and Oreo.  In Nougat, we 
introduced profile-guided 

02:07:15.677 --> 02:07:19.907
compilation.  I will explain a 
bit later what it is.  But it 

02:07:19.908 --> 02:07:27.838
drastically helped on scaling 
ARTART's ahead-of-time 

02:07:27.839 --> 02:07:32.567
technology to be more optimized 
for the platform.

02:07:32.568 --> 02:07:37.825
The profile guide compilation, 
the way it works, it has a 

02:07:38.158 --> 02:07:42.950
hybrid, just-in-time, 
out-of-time compiler.  We are 

02:07:43.491 --> 02:07:46.584
trying to use the best of both 
worlds to optimize the platform.

02:07:46.889 --> 02:07:50.568
And in O, after all of the 
optimizations in N, in O, we 

02:07:50.807 --> 02:07:56.221
focused on the garbage collector
and implemented a band new one, 

02:07:56.690 --> 02:07:58.690
which makes the pause

02:08:00.564 --> 02:08:07.053
even shorter on the UI thread.  
We call it concurrent GC.  And 

02:08:07.054 --> 02:08:12.844
now all the GCC happens on a 
different thread.  It is not 

02:08:13.382 --> 02:08:16.609
affecting the execution of the 
app.

02:08:16.610 --> 02:08:20.220
All right.  So before I dive 
into our details, I want to show

02:08:20.938 --> 02:08:23.831
this, the state of the Android 
distribution today.

02:08:23.832 --> 02:08:31.137
And, in case you are still 
optimizing for Dalvik and you 

02:08:31.515 --> 02:08:38.942
still care about this annoying 
GCFORALLOC, there is still this 

02:08:39.223 --> 02:08:42.575
10 percent, 10 percent is 
KitKat, Jellybean, about 10 

02:08:42.851 --> 02:08:47.436
percent of devices are running 
KitKat.  So my recommendation is

02:08:47.863 --> 02:08:54.362
it matters, 10 percent is 20 
million users, a big number.

02:08:54.363 --> 02:08:58.579
So it still matters.  And give 
it a couple years, and hopefully

02:08:58.580 --> 02:09:04.388
in two years, that will be gone 
and Dalvik can be part of

02:09:09.631 --> 02:09:13.484
this museum.
All right.  So things ART 

02:09:13.767 --> 02:09:18.783
matters for.  I have put eight 
boxes, they look nice, and we do

02:09:18.784 --> 02:09:22.691
matter a lot for this.  If we do
get it wrong, things will go bad

02:09:23.029 --> 02:09:31.891
on your device.
Role performance I talked about.

02:09:32.705 --> 02:09:36.529
That's Dalvik's execution, Jenk,
application start-up, battery, 

02:09:36.530 --> 02:09:41.655
disk space, RAM, boot times, I'm
repeating myself.  This is what 

02:09:41.656 --> 02:09:44.337
is really important, what makes 
the user experience okay so you 

02:09:44.547 --> 02:09:46.547
can enjoy the

02:09:48.355 --> 02:09:51.082
apps.
So I'm going to go over the 

02:09:53.123 --> 02:09:55.556
releases I talked about, the 
different incarnations of the 

02:09:55.557 --> 02:10:02.195
Android runtime to show what it 
brings to the -- so what makes 

02:10:02.490 --> 02:10:06.945
ART today.  Because ART has a 
lot -- like I said, it has a lot

02:10:06.946 --> 02:10:12.890
of evolutions.  And we also took
good things from Dalvik.  I'm 

02:10:13.329 --> 02:10:15.345
missing the major ones here, 
because the list is too long.  

02:10:15.662 --> 02:10:21.060
And obviously, the major thing 
that Dalvik architecture brought

02:10:21.061 --> 02:10:26.656
was RAM savings.
And, for that, Dalvik introduced

02:10:26.657 --> 02:10:31.772
-- Dalvik on the Android 
platform introduced the Zygote, 

02:10:31.773 --> 02:10:36.083
which is the parent process that
creates all of the other 

02:10:37.719 --> 02:10:39.982
processes.
And because it is the parent 

02:10:40.316 --> 02:10:44.365
process, you have the option of 
that parent process starting up 

02:10:44.366 --> 02:10:51.878
or allocating a lot of memory 
for the apps to use, and that 

02:10:51.879 --> 02:10:54.751
memory can be shared with the 
other apps.

02:10:54.752 --> 02:10:58.152
And that is super important, 
that means that every app 

02:10:58.414 --> 02:11:04.073
doesn't need to allocate this 
memory that it would need to 

02:11:04.381 --> 02:11:11.661
actually execute in ART.
Today, I surround a couple dozen

02:11:12.088 --> 02:11:18.280
MB that we save per app, and 
that the zygote allocates and 

02:11:18.561 --> 02:11:25.873
shares with the other apps.
And then Lollipop was the major 

02:11:25.874 --> 02:11:32.809
shift when we introduced 
ahead-of-time compilation.  

02:11:32.810 --> 02:11:36.630
Ahead-of-time compilation 
happens with an SSA compiler, 

02:11:36.631 --> 02:11:40.748
that's a compiler buzzword that 
is -- a state of the art 

02:11:41.012 --> 02:11:44.029
compiler that does a lot of 
optimizations and makes your 

02:11:44.030 --> 02:11:48.748
code up to 20X faster.
And we introduce the 

02:11:49.695 --> 02:11:53.240
ahead-of-time compiler that 
helped a lot on reducing Jenk, 

02:11:53.381 --> 02:11:57.927
now the code was compiled, not 
needing to be interpreted very 

02:12:00.229 --> 02:12:04.088
fast, reducing application 
startup, the same argument, and 

02:12:04.089 --> 02:12:08.506
saving battery.  The execution 
being 20X faster, you can 

02:12:08.775 --> 02:12:13.224
imagine that it is not a point 
of saving 20X times on battery, 

02:12:13.965 --> 02:12:17.389
but things are faster and we 
don't need to execute on the CPU

02:12:18.056 --> 02:12:21.341
anymore.
We also save on boottimes.  The 

02:12:21.782 --> 02:12:26.553
whole Android OS is ahead of 
time compiled and does not need 

02:12:27.100 --> 02:12:32.755
to be interpreted at boot.  So 
things are faster at boot.

02:12:32.756 --> 02:12:41.501
And we also introduced the 
international GC, which reduced 

02:12:43.380 --> 02:12:53.117
the pauses for Alloc in Dalvik.
  And

02:12:53.451 --> 02:12:57.315
in Oreo, we introduced 
profile-guided compilation, and 

02:12:58.452 --> 02:13:01.589
that helps with all of the 
optimizations that we do.  It 

02:13:02.110 --> 02:13:07.936
helps a lot of these metrics.  
It helps on Jenk, like less 

02:13:08.286 --> 02:13:13.142
code, less compiled, and the 
things that we care about are 

02:13:13.415 --> 02:13:18.463
optimized so the UI thread needs
to run less code.  And it helps 

02:13:18.464 --> 02:13:20.464
on the application

02:13:22.426 --> 02:13:26.130
application, we're able to know 
what matters at start-up so 

02:13:26.131 --> 02:13:32.355
that, when we recompiled the 
app, we recompiled it with 

02:13:33.845 --> 02:13:35.937
optimizations that optimize 
start-up.  You will have some 

02:13:36.202 --> 02:13:41.343
battery.  Again, we're saving on
the amount of things we 

02:13:42.123 --> 02:13:46.614
interpreted.
It will have some div space.  

02:13:47.348 --> 02:13:50.446
Instead of compiling the entire 
app, which is what Lollipop was 

02:13:50.836 --> 02:13:54.538
doing, now we are only compiling
the hard parts of the app.  That

02:13:54.837 --> 02:13:58.909
means 10 to 20 percent of the 
dex code.  So 80 percent just 

02:13:58.910 --> 02:14:03.529
doesn't get compiled.  That's a 
lot of savings.

02:14:03.530 --> 02:14:08.230
It saves on RAM, having a 
concurrent GC means we can do a 

02:14:08.913 --> 02:14:13.778
lot of defrag of the heaps of 
the app, so we save that on the 

02:14:14.043 --> 02:14:18.058
fragmentation that we had on the
previous GC.

02:14:18.059 --> 02:14:23.630
And profile guided compilation 
helps on the boot times.  

02:14:23.631 --> 02:14:29.425
Remember the optimizing aches 
dialogue, we didn't need to AOT 

02:14:29.690 --> 02:14:32.531
compile at boot all of the apps 
to make sure that the device was

02:14:32.886 --> 02:14:36.461
reasonable and performant.  We 
were able to just, okay, we take

02:14:36.462 --> 02:14:42.829
the OTA, we are going to jit all
the apps, when the user wants 

02:14:43.365 --> 02:14:46.483
it, and then eventually we will 
do profile-guided compilation of

02:14:46.712 --> 02:14:51.288
the apps when the user is not 
using their phone.

02:14:51.289 --> 02:14:56.089
And then, finally, it helps on 
install times.  Instead of 

02:14:56.249 --> 02:14:59.118
waiting for the compiler to 
compile the entire app when you 

02:14:59.666 --> 02:15:04.271
install, now it doesn't compile 
at all.  We rely on JIT the 

02:15:04.272 --> 02:15:08.610
first time the app was being 
used.

02:15:08.611 --> 02:15:17.621
And, lastly, I wanted to mention
Pie.  The time we developed Pie 

02:15:17.882 --> 02:15:21.286
was at the same time at Android 
Go, which was a great effort in 

02:15:21.563 --> 02:15:25.026
the Android platform.  And we --
the work we did was mostly to 

02:15:25.257 --> 02:15:27.949
save on disk space and RAM, 
because Android Go

02:15:32.484 --> 02:15:38.849
is 5 or 12GB of the memory.  So 
most of our efforts were focused

02:15:39.666 --> 02:15:44.546
on improving RAM and disk space.
So in that release, we 

02:15:45.424 --> 02:15:48.941
introduced compact dex, which is
a compact version of the dex 

02:15:49.163 --> 02:15:53.308
format.  That saves on RAM, 
because the less you need to put

02:15:53.536 --> 02:15:59.347
into the memory of the dex code,
the more you are saving, 

02:15:59.762 --> 02:16:03.212
obviously.
Also, when the APK has

02:16:06.696 --> 02:16:12.166
uncompressed text stored, we 
will not uncompress it on disk.

02:16:12.673 --> 02:16:18.369
So before, before we used to 
uncompress it to do 

02:16:18.674 --> 02:16:20.889
optimizations on the dex file 
you cannot do on the APK because

02:16:20.890 --> 02:16:26.200
it is signed.  So before pi, we 
uncompress it, do optimizations,

02:16:27.111 --> 02:16:30.568
and rely on them on the first 
few iterations before we do 

02:16:31.285 --> 02:16:36.493
profile-guided compilation.  Now
we get the option, give it to 

02:16:36.494 --> 02:16:40.309
the developer, if the developer 
wants to save on disk space, 

02:16:40.570 --> 02:16:43.926
then put the dex file 
uncompressed in DPK.  We are not

02:16:44.357 --> 02:16:47.268
going to uncompress it on 
device, we have one version of 

02:16:47.269 --> 02:16:51.955
the dex code and not a 
compressed version of the APK 

02:16:52.305 --> 02:16:58.386
and an uncompressed one on disk.
All right.  That was a lot of 

02:16:58.687 --> 02:17:04.808
optimizations.  I wanted to 
focus on one, which is raw 

02:17:05.010 --> 02:17:08.002
execution performance.  What you
saw this morning was pretty cool

02:17:08.464 --> 02:17:14.067
with 18X, this is even cooler.
So obviously, the faster ART 

02:17:14.708 --> 02:17:18.229
runs, the more we are saving on 
battery on application on 

02:17:18.230 --> 02:17:21.474
start-up and making the UI 
smooth.  It matters, all of the 

02:17:22.730 --> 02:17:27.619
opt  optimizations we do.
And, over the releases, we have 

02:17:28.157 --> 02:17:30.677
kept improving the performance 
by looking at actual 

02:17:30.951 --> 02:17:34.017
applications.  In this case, it 
is the Google sheets.  And every

02:17:34.324 --> 02:17:37.984
release we worked on, okay, how 
do we improve the Google sheets 

02:17:37.985 --> 02:17:42.810
app.  And the Google sheets app,
or the sheets team, helped us to

02:17:43.094 --> 02:17:46.421
build benchmarks how long it 
takes to do

02:17:50.066 --> 02:17:56.525
sheets manipulation.
Here, hire is better, blow  blue

02:17:56.526 --> 02:18:01.073
is Dalvik, it is a score of one,
relative to Dalvik in terms of 

02:18:01.074 --> 02:18:07.551
performance.  Red is Lollipop, 
where we introduced ART.  And 

02:18:07.552 --> 02:18:14.451
this is where we are today.  We 
went into a 4X improvement when 

02:18:14.734 --> 02:18:22.664
we went to ART, to a 10X today 
or a 26X on benchmark.  We are 

02:18:23.014 --> 02:18:27.685
happy with those numbers.  We 
didn't look just at sheets, we 

02:18:29.185 --> 02:18:31.939
tried to look at what happened 
to other apps.

02:18:31.940 --> 02:18:39.245
So a couple years ago, we also 
worked with the Chrome and 

02:18:39.590 --> 02:18:41.961
YouTube team to see what they 
should optimize.  And there 

02:18:42.230 --> 02:18:44.950
again, after the fact, even 
though we were not focused on 

02:18:45.174 --> 02:18:51.898
optimizing those benchmarks, we 
saw that we had this 4 to 6X 

02:18:52.244 --> 02:18:54.686
improvement with what we've 
done.

02:18:54.687 --> 02:19:00.495
So there are two examples, the 
JavaScript benchmark suite that 

02:19:01.648 --> 02:19:10.487
we imported for R purposes.  And
again, 2 to 4X, 3.5X for those 

02:19:11.470 --> 02:19:16.540
benchmarks, up to 6X in Pie.
And

02:19:19.950 --> 02:19:23.722
ExoPlayer, that's the video 
persister, driving the YouTube 

02:19:23.894 --> 02:19:27.714
app on Android.  And again, 
around 2X for the introduction 

02:19:28.675 --> 02:19:36.214
of ART and 4X today in Pie.
And while I have your attention 

02:19:37.538 --> 02:19:42.683
on performance, I have a 
shamless call to do.  We are 

02:19:43.062 --> 02:19:46.042
always super interested in 
improving code you think is 

02:19:46.043 --> 02:19:48.797
important.
So if, on your side, you like us

02:19:49.370 --> 02:19:53.488
to show off how we improved 
performance of your app, please 

02:19:53.489 --> 02:19:57.800
come talk to us, there's the 
office hours from 1:00 to 6:00 

02:19:58.211 --> 02:20:01.018
this afternoon, and we would be 
really interested in knowing 

02:20:01.019 --> 02:20:03.327
what you think we should care 
about performance.

02:20:03.328 --> 02:20:05.328
And we can show that off

02:20:08.120 --> 02:20:10.409
here.
All right.

02:20:10.410 --> 02:20:16.158
So the question, then, is as we 
get to this level of 

02:20:17.013 --> 02:20:19.013
improvements, how?

02:20:20.978 --> 02:20:24.404
I mentioned that ART has a 
modern compiler implementation, 

02:20:24.821 --> 02:20:28.484
SSA.  And thanks to the modern 
SSA compilation, there's a bunch

02:20:28.485 --> 02:20:31.733
of optimizations where we are 
able to do now.

02:20:31.734 --> 02:20:37.670
If you look at the compiler, 
things can look 

02:20:41.003 --> 02:20:45.887
familiar, with the debt 
coordination.  I will not go 

02:20:45.888 --> 02:20:52.841
overall  all of them.  I will 
focus on an example that shows 

02:20:52.842 --> 02:20:57.473
how the optimizations matter, 
especially on Kotlin that puts a

02:20:57.648 --> 02:21:01.707
lot of abstractions to help on 
the produck tubty of the user, 

02:21:01.708 --> 02:21:05.986
and makes it challenging for the
runtime to optimize.

02:21:05.987 --> 02:21:09.918
All right.
So we will take the simple 

02:21:10.508 --> 02:21:16.143
method.  Very simple, it is a 
function that takes one argument

02:21:16.144 --> 02:21:19.464
and returns a length.
When we run

02:21:27.695 --> 02:21:32.549
that to our dex serve, this is 
the code that you get.  Pretty 

02:21:32.813 --> 02:21:35.993
straightforward, if you are not 
familiar with dex code, you 

02:21:35.994 --> 02:21:42.843
create the string, and then 
Kotlin having Nonnullable types,

02:21:42.844 --> 02:21:46.122
it will make sure that the 
string is not null when it is 

02:21:46.123 --> 02:21:50.564
passed to the function, so it 
adds the helper method and 

02:21:50.905 --> 02:21:53.377
checking that the perimeter is 
not null.

02:21:53.378 --> 02:21:58.690
Then invoke field tool of the 
length method on the argument 

02:22:02.756 --> 02:22:05.360
and return that.
Kotlin comes with the built-in 

02:22:05.628 --> 02:22:08.651
library, so that's where you can
find implementations of those 

02:22:09.028 --> 02:22:13.628
helper methods.  For that case, 
it is only a simple method that,

02:22:13.629 --> 02:22:19.561
okay, is the argument null? Yes.
Then I will throw, calling in 

02:22:19.562 --> 02:22:25.866
another helper, or R will return
and go back to the method.

02:22:25.867 --> 02:22:31.914
So method calls are pretty 
expensive.  So the first thing 

02:22:32.198 --> 02:22:36.715
that ART will do is try to 
in-line that very small method 

02:22:36.716 --> 02:22:43.253
within the caller.
Here the compiler is in line 

02:22:43.254 --> 02:22:47.419
with the place that it is 
called.  For simplicity's 

02:22:47.691 --> 02:22:50.249
reason, it looks like the text 
code, it is the format of the 

02:22:50.476 --> 02:22:52.476
compiler, but I will not show 

02:22:55.026 --> 02:22:59.366
that to you.
Compile code is in line, which 

02:22:59.626 --> 02:23:04.565
helps with the performance.
There is more that we can do, 

02:23:05.019 --> 02:23:10.018
the compiler sees, oh, wait, 
that throw

02:23:14.837 --> 02:23:16.958
parameter is null and it always 

02:23:20.086 --> 02:23:23.541
-- throws.  There's a couple 
things you can do with that 

02:23:23.542 --> 02:23:27.483
information.
The first is call layout, where 

02:23:27.745 --> 02:23:31.324
you can put together the regular
flow of the method.  So things 

02:23:31.622 --> 02:23:35.078
that rarely happen, you put it 
at the very end of the method, 

02:23:35.486 --> 02:23:40.367
it does not affect the flow of 
the execution.

02:23:40.368 --> 02:23:46.949
So we just switched the 
compilers in from, hey, are 

02:23:46.950 --> 02:23:48.950
these zero, and we jump to the 
end of the

02:23:53.815 --> 02:23:56.099
method.
So the jump is another picture

02:24:00.139 --> 02:24:02.825
now.
The second optimization, we're 

02:24:03.073 --> 02:24:05.695
going to move things that the 
regular flow does not care 

02:24:06.910 --> 02:24:11.577
about.  In this case, let me 
just go back if I can.  In this 

02:24:11.951 --> 02:24:18.151
case, the construction of the 
string that iss being passed to 

02:24:18.152 --> 02:24:21.685
the helper was the first thing 
you executed in the method.  But

02:24:21.962 --> 02:24:28.520
you only need that if you end up
calling the helper.  So-soo we 

02:24:28.842 --> 02:24:31.102
move the construction of the 
string before the helper.  

02:24:31.103 --> 02:24:35.589
Meaning, we don't need to 
execute examine.

02:24:35.590 --> 02:24:40.375
So in the end, we started with a
method that was calling a 

02:24:40.645 --> 02:24:45.342
string, a helper, doing it's 
thing, returning the length, to 

02:24:45.343 --> 02:24:49.479
a method that is checking if it 
is null, if it is, jump to an 

02:24:49.480 --> 02:24:52.347
expressive jump somewhere.  If 
it is not, we will continue the 

02:24:52.784 --> 02:24:56.487
flow and return the length of 
the method, the length of the 

02:25:00.959 --> 02:25:03.507
string, sorry.
All right.

02:25:03.508 --> 02:25:08.205
So that was raw performance.  I 
have two other things to talk 

02:25:08.814 --> 02:25:12.146
about, actually, just one, 
because I have to talk about 

02:25:12.729 --> 02:25:15.581
application start-up and garbage
collection.  I will not re-do 

02:25:16.173 --> 02:25:19.621
the garbage collection side, 
Chet did a great job this 

02:25:19.903 --> 02:25:23.865
morning.
So, with application start-up, 

02:25:24.088 --> 02:25:26.088
it has been a major focus since 

02:25:29.833 --> 02:25:31.833
we introduced 

02:25:35.071 --> 02:25:38.563
profile-guided compilation.  
That happened in nougat.  

02:25:39.793 --> 02:25:42.865
Profile-guided compilation, when
the app is installed, we compile

02:25:43.596 --> 02:25:49.418
it in a quick way.  We are not 
going to go to full IOT 

02:25:49.711 --> 02:25:52.406
compilation, very little 
optimizations that do not affect

02:25:52.709 --> 02:25:55.207
install time.  So we are 
optimizing install time.  The 

02:25:55.800 --> 02:26:01.296
app is installed, then you run 
it.  The app is being executed, 

02:26:01.297 --> 02:26:08.177
with interpretation, and then 
method gets hot, and then JIT 

02:26:08.437 --> 02:26:10.645
kicks in and compiles the 
methods.

02:26:10.646 --> 02:26:15.615
The JIT knows what those hot 
methods are, so we are going to 

02:26:15.616 --> 02:26:23.182
jump to a profile file to sub 
methods. So when your device is 

02:26:24.080 --> 02:26:27.478
idle, the user is not using it, 
it is charging, 100 percent 

02:26:28.298 --> 02:26:32.470
charged, and then we have this, 
what we call, profile-guided 

02:26:32.827 --> 02:26:35.552
demon that is just like, okay, 
then you walk over all the 

02:26:36.050 --> 02:26:41.947
profiles and recompile the app.
And compile them, compile only 

02:26:41.948 --> 02:26:45.409
the things that matter based on 
that profile.

02:26:45.410 --> 02:26:52.102
And you have this loop where the
next time you run the app, we 

02:26:52.370 --> 02:26:57.079
will use the optimized version 
of the compile code.  And then 

02:26:57.505 --> 02:27:04.328
we will run it what is IOTed, 
maybe some methods are missed, 

02:27:04.731 --> 02:27:09.044
you reinterpret them, re-update 
the profile, and the demon kicks

02:27:09.477 --> 02:27:14.036
in, the profile was updated, let
me recompile the app.

02:27:14.037 --> 02:27:19.377
So it is a virtuous loop of 
getting better and better over 

02:27:20.127 --> 02:27:22.715
time.
And why is that helping on the 

02:27:22.968 --> 02:27:24.968
application 

02:27:26.817 --> 02:27:28.348
start-up?
The things that we compile in 

02:27:28.349 --> 02:27:33.031
the app in the profile are 
optimized towards this.  We are 

02:27:34.044 --> 02:27:37.515
going to compile the start-up 
methods.  So no need to 

02:27:37.774 --> 02:27:42.904
interpret them, things that are 
executed at start-up will get 

02:27:43.298 --> 02:27:47.069
compiled.
We're going to layout the dex 

02:27:47.070 --> 02:27:50.561
and the compile code.  So things
that execute at start-up would 

02:27:50.850 --> 02:27:53.908
be next to each other.
So now you don't need to jump 

02:27:54.202 --> 02:27:58.309
over the entire dex file to get 
access to the method.  And that 

02:27:58.578 --> 02:28:03.450
is very important.  Like I said,
apps got bigger.  So if you need

02:28:03.451 --> 02:28:08.019
to bring up the entire dex file,
for start-up, that is a lot of 

02:28:08.860 --> 02:28:12.053
time waiting on I/O.  So we try 
to reduce that by putting 

02:28:12.379 --> 02:28:14.819
everything in start-up in the 
beginning and then the rest at 

02:28:17.242 --> 02:28:22.681
the end.
Profile-guided compilation 

02:28:23.231 --> 02:28:29.051
generates an application image. 
Other runtimes will call this a 

02:28:29.498 --> 02:28:34.191
snap shot.  It is a 
representation of Java classes 

02:28:35.191 --> 02:28:39.471
that we put in that image, it is
a file, and that avoids us to 

02:28:40.297 --> 02:28:45.169
actually load the classes at run
time again.  So there's a 

02:28:45.170 --> 02:28:49.659
pre-formatted number of classes 
with a class order, and when we 

02:28:50.226 --> 02:28:54.690
start-up, you take the class 
order, all of the classes are 

02:28:54.988 --> 02:28:57.829
populated, and we are done.  You
don't need to do code 

02:29:02.021 --> 02:29:04.449
clustering anymore.
We are going to try to 

02:29:05.302 --> 02:29:10.823
preinitialize classes, so Java 
says classes need to be 

02:29:10.824 --> 02:29:13.681
initialized before executed.  
With profile guided compilation,

02:29:13.949 --> 02:29:19.107
we need to initialize anything 
we can to prevent that from 

02:29:19.108 --> 02:29:21.680
being executed before we start 
the app.  And finally, I said 

02:29:22.080 --> 02:29:26.239
we're not going to compile code 
that doesn't get executed.  That

02:29:26.240 --> 02:29:32.895
helps a lot.  Because then your 
old file is very small, your 

02:29:33.202 --> 02:29:36.798
compile file is very small.  So 
there's not a lot you need to 

02:29:36.799 --> 02:29:38.799
bring up in memory to actually

02:29:42.945 --> 02:29:46.095
compute.
What do we gain from all those 

02:29:47.565 --> 02:29:52.108
optimizationoptimizations?
Well, they can be -- we always 

02:29:52.990 --> 02:29:56.153
gain doing those optimizations. 
Depending on the app, it can be 

02:29:56.494 --> 02:30:01.701
10 percent or 30 percent.
And that is usually around how 

02:30:02.782 --> 02:30:07.258
many Java code do you have when 
you start your app.  Typically, 

02:30:07.956 --> 02:30:11.182
camera has a lot of native code,
that is on the low end of 10 

02:30:11.183 --> 02:30:13.972
percent improvement.
And in this example, you see 

02:30:14.130 --> 02:30:21.482
docs and maps, that are very 
Java-heavy, go from 30 percent 

02:30:21.820 --> 02:30:23.820
of app start-up

02:30:28.965 --> 02:30:32.072
improvement.
And this is numbers that we got 

02:30:32.073 --> 02:30:39.838
from the maps team, who got that
from actual users, or actual 

02:30:40.175 --> 02:30:45.717
data that comes from the field.
And when the maps team graphs 

02:30:46.000 --> 02:30:51.123
what is going on, how come -- 
had they installed, things were,

02:30:51.491 --> 02:30:56.313
like, a one second of apps 
start-up to, over time, things 

02:30:56.314 --> 02:30:59.415
are faster.  How does that 
happen? And every time they 

02:30:59.680 --> 02:31:04.897
update the app, it is the same 
trend.  It starts pretty high, 

02:31:05.380 --> 02:31:10.477
and then it goes low.
And the answer is profile guided

02:31:11.113 --> 02:31:15.675
compilation.  You are clearly 
seeing that, over time, things 

02:31:19.153 --> 02:31:27.673
get better.
Today, in Pie, when we talked 

02:31:27.959 --> 02:31:30.078
about I/O last year was the 
introduction of profiles in the 

02:31:30.079 --> 02:31:36.343
cloud.  And that's how we're 
making the entire ecosystem send

02:31:36.344 --> 02:31:44.701
us profiles, like actually 
execution of profiles for users,

02:31:44.702 --> 02:31:49.181
so we can bring the profiles to 
new users of the app, so you 

02:31:49.424 --> 02:31:54.465
don't get a -- the start of one 
second ends up 750 milliseconds,

02:31:54.466 --> 02:31:57.978
they get the 750 right away, 
because they get the profile at 

02:31:58.288 --> 02:32:00.288
the point of

02:32:01.967 --> 02:32:03.967
the of 

02:32:06.303 --> 02:32:09.352
install. .
  Garbage collection, I'm not 

02:32:09.621 --> 02:32:11.621
going over it. 

02:32:13.410 --> 02:32:16.510
Maybe I can just put back a 
number that we're all

02:32:25.234 --> 02:32:27.870
very proud of, here we are, 
that's the last.  So this is 

02:32:28.572 --> 02:32:31.881
resuming what Chet talked about 
this morning.  It is all the 

02:32:32.866 --> 02:32:39.351
technology that we've used over 
time for building a GC.  So you 

02:32:39.352 --> 02:32:41.352
see in KitKat,

02:32:43.348 --> 02:32:49.845
we have this concurrent mark 
suite that was part of the GC 

02:32:49.846 --> 02:32:55.964
that was concurrent.  And it 
stayed until Nougat, in Oreo, 

02:32:55.965 --> 02:33:01.451
the concurrent collector.  The 
allocation in KitKat, it was the

02:33:02.467 --> 02:33:05.126
bottleneck, it needs to lock to 
allocate something.  The 

02:33:05.127 --> 02:33:11.094
introduction of a new GC in 
Lollipop meant that we can 

02:33:11.095 --> 02:33:13.719
allocate within the thread and 
not need the lock.  

02:33:13.720 --> 02:33:15.720
That improves the performance of

02:33:18.225 --> 02:33:20.842
allocation.
The -- when you allocate the 

02:33:21.248 --> 02:33:29.010
objects that are short lived, 
and that's the motoof Java Java,

02:33:29.401 --> 02:33:36.587
feel free to allocate Java, it 
is moved by the GC in Java.  

02:33:37.335 --> 02:33:41.458
Pre-KitKat, that is not the 
case, you have a very high cost 

02:33:41.459 --> 02:33:44.418
by allocating temporary objects.
Lollipop is when we introduced a

02:33:44.680 --> 02:33:51.320
new GC, and the -- you didn't 
pay that cost at all.  Like 

02:33:51.572 --> 02:33:54.756
allocating a short-lived object,
we had generations, things were 

02:33:55.084 --> 02:34:01.006
moved pretty quickly.  And 
there's an app series for Oreo, 

02:34:02.974 --> 02:34:05.460
when we introduced concurrent 
collector, we removed the 

02:34:05.617 --> 02:34:07.899
generations out of the 
collector.  We are fixing that 

02:34:07.900 --> 02:34:12.854
today, it is in the AOSP, the 
improvement of the generations. 

02:34:13.184 --> 02:34:15.184
And hopefully it will be there 
in the device

02:34:18.767 --> 02:34:21.016
soon.
And fragmentation, fragmentation

02:34:21.273 --> 02:34:27.239
is a big problem in Android, 
because if you are not able to 

02:34:27.500 --> 02:34:31.096
allocate, the app will be 
killed.  So doing compassion of 

02:34:31.817 --> 02:34:35.731
the memory, so that things are 
not fragmented is super 

02:34:35.732 --> 02:34:42.102
important.  KitKat did a bit, 
but very little, and Lollipop in

02:34:43.201 --> 02:34:46.274
marshmallow , we did it when the
app was running in the 

02:34:46.683 --> 02:34:50.374
background.  We reclaim the 
memory.  But Oreo, it is 

02:34:50.375 --> 02:34:54.917
important that we compact all 
the time so the memory is there 

02:34:54.918 --> 02:34:57.970
and available all the time.

02:35:01.326 --> 02:35:04.415
And the number I was looking 
for, the allocation speed, a 

02:35:04.416 --> 02:35:11.411
very low number in Dalvik, to an
18X improvement in Oreo and

02:35:14.448 --> 02:35:17.339
Pie.
And here are the reasons -- the 

02:35:17.731 --> 02:35:23.496
reasons that we got improved, 
Lollipop added a custom 

02:35:24.671 --> 02:35:33.293
allocator, and in Marshmallow, 
we had erfeweratomic operations 

02:35:33.565 --> 02:35:36.634
that have a cost.  And all of 
that implementation of the 

02:35:36.989 --> 02:35:44.923
allocation path was moved to an 
assembly code in nougat that 

02:35:45.192 --> 02:35:50.485
made things faster, and then we 
implemented the pointer in 

02:35:50.950 --> 02:35:55.175
allocation.  And the only thing 
we allocate is to increment a 

02:35:55.499 --> 02:35:58.669
pointer.
All right.  With that, this is 

02:35:59.871 --> 02:36:03.042
the recommendation that Chet 
has.

02:36:03.043 --> 02:36:06.448
So I will give the same.
Creating garbage is

02:36:10.087 --> 02:36:12.439
okay today.
You can use a tag to allocate 

02:36:12.778 --> 02:36:19.937
the objects that you need.
GC is still overhead, so be 

02:36:20.351 --> 02:36:27.343
mindful that if you allocate 
allocate a lot of objects, GC 

02:36:27.344 --> 02:36:32.745
needs to run, but it is less of 
a problem since Dalvik.

02:36:32.746 --> 02:36:34.746
And, with that, thank you.

02:36:42.578 --> 02:36:44.198
[ Applause ].
SPEAKER: I will be in the office

02:36:44.199 --> 02:36:49.315
hours at 1:00PM.  Feel free to 
come and chat there.

02:36:56.349 --> 02:36:57.916
. 
SPEAKER: Everyone, please give a

02:36:57.917 --> 02:37:04.793
warm welcome to dan Galpin. 
SPEAKER: We have lunch going on 

02:37:05.012 --> 02:37:09.720
right now, we are on a different
schedule today.  So once again, 

02:37:09.721 --> 02:37:12.558
lunch is where it was yesterday,
downstairs.  And we're going to 

02:37:12.559 --> 02:37:18.645
start our sessions at 1:05.  We 
are trying to smash as much

02:37:26.851 --> 02:37:28.851
--.

02:37:32.506 --> 02:37:34.506
 #

03:47:41.651 --> 03:47:43.651
Coming up next: Android Emulator

03:54:39.426 --> 03:54:40.508
Deep Dive by Frank Yang, Yahan 
Zhou SPEAKER: Good afternoon, 

03:54:40.509 --> 03:54:47.256
welcome to the Android deep 
dive.  I'm Yahan, this is 

03:54:49.927 --> 03:54:54.781
fraFrank and we are software 
engineers from the Android team.

03:54:55.035 --> 03:55:00.075
Back in 2015 in the previous 
Android dev summit, we announced

03:55:01.246 --> 03:55:08.061
Android Emulator.  
So if you remember here is what 

03:55:08.857 --> 03:55:13.595
it looks like in 2015.  And it 
is 2018 now, so things have 

03:55:14.190 --> 03:55:19.461
progressed quite quickly, and we
have a new Emulator with a newer

03:55:19.947 --> 03:55:23.424
look.
So if you look at the details, 

03:55:23.425 --> 03:55:25.425
there's a few differences that 
you might have

03:55:30.790 --> 03:55:36.531
noticed.
First, there's a frameless skin 

03:55:36.716 --> 03:55:40.643
, and it gives you a better UI 
experience.

03:55:40.644 --> 03:55:44.164
And secondly, you might have 
noticed that, in the expanded 

03:55:44.711 --> 03:55:51.904
panel, there is a much longer 
feature list, with new features 

03:55:52.076 --> 03:55:54.076
such as screen

03:55:56.739 --> 03:56:00.448
recording and support, snap 
shot, and Google Play Store.  I 

03:56:00.449 --> 03:56:06.562
will go over all these features 
in this talk one by one.

03:56:06.563 --> 03:56:12.184
From 2015 to 2018, we have 
developed quite a lot of stuff 

03:56:12.185 --> 03:56:15.641
in the Android Emulator, and we 
are focused on two areas.

03:56:15.642 --> 03:56:20.271
One is the performance 
improvement of the Emulator, the

03:56:20.272 --> 03:56:24.721
other is the new features.
And we are focusing on the 

03:56:24.973 --> 03:56:30.188
improvng your day-to-day 
developing experience as far as 

03:56:31.031 --> 03:56:33.031
CI server testing use

03:56:35.592 --> 03:56:40.118
cases.
So, first things first, let's 

03:56:40.119 --> 03:56:43.657
get into performance.  The first
thing we want to focus on about 

03:56:45.817 --> 03:56:49.154
performance is HyperVisor 
support.  So just a background 

03:56:49.155 --> 03:56:52.937
about Hypervisors, if you are 
running the Android Emulator at 

03:56:52.938 --> 03:56:56.471
the lowest level, you have your 
computer hardware.

03:56:56.472 --> 03:56:59.711
On top of that, you have your 
operating system, and the 

03:56:59.855 --> 03:57:02.628
highest level, there

03:57:07.411 --> 03:57:10.465
is the Android OS.  Between the 
OS and the operating system, 

03:57:10.466 --> 03:57:15.591
there's the hardware which 
translates the Android CPU 

03:57:15.592 --> 03:57:21.812
commands into your OS series of 
commands.  

03:57:21.813 --> 03:57:25.103
That's the a part that we do the
CPU acceleration.  If you don't 

03:57:25.404 --> 03:57:27.404
have a

03:57:29.057 --> 03:57:31.995
HyperVisor, you can run the 
emulator, but everything is 

03:57:32.510 --> 03:57:35.776
super slow and the emulator 
becomes super sluggish.

03:57:35.777 --> 03:57:41.182
So, in 2015, here is the list of
the hardware that we support.  

03:57:41.584 --> 03:57:46.588
On Linux, we have KVM, and on 
Windows and Mac, we support HAXM

03:57:48.029 --> 03:57:52.023
with Intel CPU.  So 
unfortunately, back in the days,

03:57:52.289 --> 03:57:58.676
if you are using a CPU on a 
Windows machine, we have no 

03:57:58.889 --> 03:58:02.120
support for this combination.  
So we got a lot of request from 

03:58:03.196 --> 03:58:09.915
A&amp;D users, to add support for 
them.  So it is 2018 now, things

03:58:10.307 --> 03:58:14.003
progress pretty fast, and 
obviously, we have new 

03:58:14.409 --> 03:58:18.591
HyperVisors approach.  So this 
supports a new version of HAXM, 

03:58:20.138 --> 03:58:24.182
7.3.2, which is the previous 
version and it gives you better 

03:58:24.453 --> 03:58:28.203
performance.
And then we added 

03:58:29.141 --> 03:58:33.308
HyperVisor.framework support for
Mac users which, in most 

03:58:33.475 --> 03:58:38.571
situations, is faster than the 
HAXM on Mac.

03:58:38.572 --> 03:58:43.224
And, at last, we support 
hypervisor framework,

03:58:48.514 --> 03:58:54.157
known as HyperV on Windows.  So 
the combination of NDN and 

03:58:54.158 --> 03:59:00.350
Windows is supportive,  .  So 
here is the HyperVisor 

03:59:00.683 --> 03:59:03.059
performance.
And the next thing we want to go

03:59:03.325 --> 03:59:05.325
into

03:59:07.289 --> 03:59:15.077
will be the ADP performance.  So
the Oreo background, you move 

03:59:15.078 --> 03:59:18.016
from the computer, on to the 
device when you are deploying, 

03:59:18.017 --> 03:59:21.927
you are doing this ADB push 
command which copies and 

03:59:21.928 --> 03:59:25.630
transfers the app from one end 
to the other.

03:59:25.631 --> 03:59:31.959
So here, we are showing the 
chart for ADB push time on a 

03:59:32.589 --> 03:59:35.475
physical device on two different
Google apps: The Google photo 

03:59:35.752 --> 03:59:39.994
app, and Google center checker 
app.  And they are both on 

03:59:39.995 --> 03:59:44.134
physical devices.  And you can 
see what the first thing was, 

03:59:44.135 --> 03:59:47.943
that if you are using a USB 
cable and you are pushing the 

03:59:48.305 --> 03:59:52.260
Google photo app, it takes 
approximately eight

03:59:55.824 --> 04:00:00.415
seconds.
 If you are using a USB cable, 

04:00:00.416 --> 04:00:03.575
it goes a lot faster, and it 
takes approximately four 

04:00:05.246 --> 04:00:08.602
seconds.  So you can observe 
similar momentum when pushing a 

04:00:08.603 --> 04:00:11.727
similar app, like the Google 
check

04:00:15.387 --> 04:00:18.495
up.
USBKs are faster than USBK2s.  

04:00:18.496 --> 04:00:20.552
So that's for the physical 
device.  How about the 

04:00:20.553 --> 04:00:24.826
performance on the Emulator?
So here's a chart.  If you do 

04:00:25.275 --> 04:00:29.518
the app push on Emulator, the 
Google photo apps take 

04:00:29.785 --> 04:00:38.353
approximately 0.5 seconds, which
is a lot faster than USB2 or 

04:00:38.354 --> 04:00:42.284
USB3.
And this other chart on an 

04:00:43.142 --> 04:00:47.385
Android Oreo device. And it 
turns out that the OS version 

04:00:47.658 --> 04:00:50.357
matters a lot as well when we 
are doing the app push.

04:00:50.358 --> 04:00:56.802
So we've got a chart on the 
nearer Android Pie device.  If 

04:00:57.283 --> 04:01:01.520
you are working on a physical 
device, the ADP push is a lot 

04:01:02.047 --> 04:01:08.638
faster on either USB2 or 3.
And Emulator still gives you a 

04:01:08.639 --> 04:01:14.450
very fast and a very constant 
performance.

04:01:14.451 --> 04:01:22.382
So, in short, if you are going 
to the emulator, you are not 

04:01:22.383 --> 04:01:25.237
going have any worries about USB
cables or

04:01:28.570 --> 04:01:31.696
Android versions.  You can 
always get the best and 

04:01:32.097 --> 04:01:37.169
consistent performance.
The next topic, we are going to 

04:01:37.556 --> 04:01:42.755
Quick Boot and snap Shots.  We 
are showing demoes.  And with 

04:01:43.142 --> 04:01:45.142
that, we will have 

04:01:50.373 --> 04:01:52.759
Frank. 
SPEAKER: Thank you, Yahan.  A 

04:01:53.803 --> 04:01:57.309
top concern of Android Studio 
users is time to deploy the app,

04:01:57.310 --> 04:02:00.852
whether it be on a physical 
device or emulator.  And people 

04:02:02.444 --> 04:02:06.015
are used to the workflow where 
they are inside studio, want to 

04:02:06.263 --> 04:02:10.920
deploy the app, and they want to
wait for the Emulator to boot up

04:02:10.921 --> 04:02:15.141
again.  We tried to address this
in 2017 and in 2018.

04:02:15.142 --> 04:02:18.160
The first way we tried to 
address this is through snap 

04:02:19.070 --> 04:02:21.995
shots.
We call this quick boot.

04:02:21.996 --> 04:02:26.089
With quick boot, the device 
state is completely saved when 

04:02:26.472 --> 04:02:29.684
you take a snap shot.  And when 
you take a snap shot when you 

04:02:30.429 --> 04:02:34.427
exit the emulator and you resume
from that snap shot when you 

04:02:34.625 --> 04:02:38.057
start the emulator again.
So, in a sense, it is kind of 

04:02:38.429 --> 04:02:41.936
like sleeping and resuming a 
real device.  And we've also 

04:02:42.937 --> 04:02:46.710
made improvements in recent 
emulator Canary versions to make

04:02:46.952 --> 04:02:50.747
it even closer to that.  So the 
demo I'm going to show you here 

04:02:52.103 --> 04:02:56.787
is I have two ABDs set up in the
ABD manager.  One of them is 

04:02:57.067 --> 04:02:59.486
called API 28, and we're going 
to be using quick boot with 

04:02:59.487 --> 04:03:04.145
that.  And a second one is 
called API28 cold boot, and 

04:03:04.486 --> 04:03:07.091
we're going to cold boot that.  
So for our benefit, people 

04:03:07.484 --> 04:03:12.499
haven't seen this already.  I'm 
going to cold boot one of these 

04:03:12.500 --> 04:03:16.596
ABDs.  You will see that it 
starts out as a black screen, 

04:03:16.854 --> 04:03:23.678
takes a while to show the Google
logo but, with quick boot, the 

04:03:24.630 --> 04:03:28.346
Emulator pops up right here.  
You will notice that the log cat

04:03:28.347 --> 04:03:33.535
started up, and we can interact 
with it immediately, just as the

04:03:33.790 --> 04:03:36.954
Cold Boot emulator has just 
started up.

04:03:36.955 --> 04:03:42.366
So we are going to get rid of 
the Cold Boot emulator for now 

04:03:42.701 --> 04:03:45.765
and move to the next part of the
demo.  In addition to Quick Boot

04:03:46.372 --> 04:03:52.376
in July of 2018, we extended the
snap shots feature to be more 

04:03:52.829 --> 04:03:56.333
general.  So with quick boot, 
you can only have one snap shot 

04:03:56.334 --> 04:04:01.245
being saved and loaded at any 
one tile.  Time.  That is 

04:04:01.742 --> 04:04:08.852
usefulx , but maybe you want to 
test different device 

04:04:09.012 --> 04:04:12.426
configurations and state and so 
forth.  Before now, we didn't 

04:04:12.427 --> 04:04:16.866
have a good way to do that.  In 
the latest Emulator stable 

04:04:17.938 --> 04:04:22.821
version, 27.3.10, released July 
2018, we are giving you a 

04:04:22.996 --> 04:04:27.320
generic snap shots UI.  In this 
generic snap shots UI, you can 

04:04:27.670 --> 04:04:32.465
save and load snap shots 
arbitrarily.  So for example, I 

04:04:32.770 --> 04:04:34.770
can immediately 

04:04:36.211 --> 04:04:40.983
resume one of these snap shots 
to stop watch running, and a 

04:04:40.984 --> 04:04:47.078
stop watch is running.  I can 
edit any one of these snap shos 

04:04:47.079 --> 04:04:51.772
and add notes.
And the description is saved and

04:04:52.087 --> 04:04:59.838
also displayed over here.
I can also take new snap shots 

04:05:00.106 --> 04:05:08.184
with the take snap shot button.
So these are some examples of 

04:05:08.887 --> 04:05:11.624
what we have been doing with 
snap shots in trying to make 

04:05:11.625 --> 04:05:16.334
your life easier when you are 
deloying apps and testing them. 

04:05:16.631 --> 04:05:19.684
I would also like, at this 
point, go over some improvements

04:05:20.074 --> 04:05:24.358
we made to the quick boot 
mechanism itself in recent 

04:05:25.166 --> 04:05:28.835
emulator canaries.  The version 
of the Emulator running right 

04:05:29.101 --> 04:05:35.744
now is 28.0.15.  And the recent 
Emulator car nary, we tried to 

04:05:36.150 --> 04:05:39.936
listen to your concern about 
extremely long saving time for 

04:05:40.307 --> 04:05:43.722
the Emulator when you are 
closing it.  Now if you want to 

04:05:44.196 --> 04:05:47.024
save the Emulator, actually, 
wait, we will set up the stop 

04:05:47.922 --> 04:05:53.848
watch again.  It is saved, trust
me, it is.

04:05:53.849 --> 04:06:00.280
Yes, it was saved.
So we have employed new 

04:06:00.581 --> 04:06:04.794
technologies, like file backing 
of the guest RAM in order to 

04:06:04.795 --> 04:06:10.183
speed this process up.
And in addition, we have also 

04:06:10.680 --> 04:06:13.792
added some console commands that
are useful for CI users when 

04:06:14.050 --> 04:06:17.882
using snap shots.
One very common workflow is to 

04:06:18.207 --> 04:06:21.640
reset the device to a particular
previous state, and then run 

04:06:21.890 --> 04:06:30.692
your test in  and reset the 
device again.  To that end, we 

04:06:31.121 --> 04:06:35.407
added this command called, in 
the console, it is called ABD 

04:06:36.008 --> 04:06:39.731
snap shot remap 0.
So assuming that you are using a

04:06:39.990 --> 04:06:43.077
default setting, it is like you 
are auto saving the current 

04:06:43.402 --> 04:06:46.037
device state all the time.  So 
right now, we are on the second 

04:06:46.038 --> 04:06:49.556
-- we are up 40 seconds. 
So the 1st time you run this, it

04:06:50.890 --> 04:06:56.226
will save it around then.  The 
next time you run it, it will 

04:06:56.681 --> 04:06:59.839
quickly rewind there.  So this 
happens quite quickly because 

04:06:59.840 --> 04:07:03.699
all the rest of the Emulator UI 
and all of that is set up, it is

04:07:03.700 --> 04:07:06.041
just a device state that is 
changing.

04:07:06.042 --> 04:07:11.844
So you can just keep doing this,
like rewinding very quickly, you

04:07:11.845 --> 04:07:15.662
can be unany state of the device
and just keep going back to that

04:07:16.249 --> 04:07:21.061
one state very quickly with this
command.

04:07:21.062 --> 04:07:25.291
And another feature that we have
been working on in recent 

04:07:25.926 --> 04:07:28.100
Emulator canaries is launching 
multiple instances of the same 

04:07:30.638 --> 04:07:36.838
ABD.
So let me just set this up 

04:07:38.004 --> 04:07:41.771
again.
Okay, zero seck  seconds.

04:07:41.772 --> 04:07:45.775
So before, when you are using 
the Emulator.  If you want to 

04:07:46.156 --> 04:07:50.024
test multiple different device 
dates and launch them all at the

04:07:50.222 --> 04:07:53.554
same time in parallel, your 
options are pretty limited.  You

04:07:53.555 --> 04:07:57.853
have to create a bunch of ABDs 
that reflect the different 

04:07:58.243 --> 04:08:01.347
device settings and launch them 
all in parallel, or you could 

04:08:01.601 --> 04:08:08.654
start two instances of the same 
ABD -- couldn't -- because you 

04:08:08.882 --> 04:08:12.477
got the same message that the 
ABD is in use.  We have a 

04:08:12.878 --> 04:08:18.261
command for that now, read only.
Where  I will show you the 

04:08:18.262 --> 04:08:23.301
command here.
Okay.

04:08:23.302 --> 04:08:29.384
Actually, it is missing, but I 
will type it again.

04:08:29.385 --> 04:08:32.346
So it is called dash read dash 
only.  So when you run this 

04:08:32.616 --> 04:08:36.225
command, the emulator will 
start, but the start all 

04:08:36.526 --> 04:08:40.005
changes.  I am starting it in 
the background to make it easy 

04:08:40.260 --> 04:08:44.708
to start many of them.
So I have just started a second 

04:08:45.095 --> 04:08:52.386
one, it is actually overlapped 
on the first.  A third one u , a

04:08:52.387 --> 04:08:58.531
fourth one.  So you have these 
ABDs that are running 

04:08:59.297 --> 04:09:04.612
independently, but off the same 
ABD name, because I used API 28 

04:09:04.881 --> 04:09:07.805
for each of them.  And I'm 
cleaning up the FPS and memory 

04:09:07.994 --> 04:09:14.289
stats.  Why are some of these 
only 200 or 300MB of resident 

04:09:14.563 --> 04:09:18.381
memory? That goes back to using 
a file mapping for the guest 

04:09:18.803 --> 04:09:21.029
RAM.  In this case, the parts of
the guest memory that they share

04:09:21.030 --> 04:09:25.327
in common that they have not 
modified yet will be shared and 

04:09:25.594 --> 04:09:30.982
will not occupy proportional 
size or resident memory or 

04:09:30.983 --> 04:09:35.931
what-have-you.
So this is called copy on write.

04:09:35.932 --> 04:09:41.070
And we hope that this makes your
experience developing apps and 

04:09:41.985 --> 04:09:45.811
testing them more streamlined.
Thank you.

04:09:45.812 --> 04:09:52.751
Now back to Yahan, back to the 
slides. 

04:09:52.752 --> 04:09:56.963
YAHAN ZHOU: I think it is 
obvious to see the comparison if

04:09:57.235 --> 04:10:00.688
you are using the quick boot 
feature versus if you are doing 

04:10:00.949 --> 04:10:05.212
the cold boot.
So, in the cold boot, if it 

04:10:05.482 --> 04:10:10.920
takes you more than 20 seconds 
to do the save on your machine 

04:10:11.164 --> 04:10:17.601
as you are demoing today, and on
Quick Boot, it is usually about 

04:10:17.602 --> 04:10:20.523
one second.
So back to Frank for the next 

04:10:20.834 --> 04:10:23.431
demo.  
SPEAKER: Uh-huh, back to the 

04:10:24.299 --> 04:10:28.271
demo.
So the next part starts out with

04:10:28.548 --> 04:10:33.380
we also improved the GPU 
performance of the emulator in 

04:10:33.913 --> 04:10:36.895
recent versions and in recent 
years.  We worked a lot to bring

04:10:37.208 --> 04:10:43.733
open GL ES2 support very 
conformant and to support open 

04:10:43.987 --> 04:10:47.027
EL GS3.
So this end, we created some 

04:10:47.343 --> 04:10:50.063
benchmark demo apps that 
showcase what the emulator is 

04:10:51.657 --> 04:10:54.745
capable of.
So I am starting this test over 

04:10:55.907 --> 04:11:00.308
here.
And so you can run the realtime 

04:11:00.887 --> 04:11:04.721
3D applications like this that 
are competitive with real device

04:11:05.928 --> 04:11:08.091
performance.
But, before we go any further, I

04:11:08.415 --> 04:11:12.954
would like to go back to Yahan 
in the slides to go over another

04:11:14.272 --> 04:11:16.272
interesting feature.  

04:11:19.383 --> 04:11:26.245
SPEAKER: All right.  So, coming 
back to the Snapshot support.  

04:11:26.246 --> 04:11:32.283
If you remember in 2010, the 
emulator, before 2.0, we had the

04:11:33.435 --> 04:11:37.994
quick boot feature and snap shot
tutorial.  At the time, the 

04:11:38.425 --> 04:11:42.867
emulator supports snap shots for
RAM, Disk, and CPU.  The missing

04:11:43.240 --> 04:11:46.640
part here was GPU-based snap 
shots.

04:11:46.641 --> 04:11:53.253
So this eventually led us to 
choose between hardware GPU 

04:11:53.661 --> 04:11:56.721
emulation and the quick boot 
feature.

04:11:56.722 --> 04:12:01.715
If you choose the hardware GPU 
emulation, you getty pretty nice

04:12:01.716 --> 04:12:07.867
runtime performance.  But your 
boot time is a slow boot.  If 

04:12:08.227 --> 04:12:11.741
you choose the quick boot 
feature, your boot time will be 

04:12:11.742 --> 04:12:14.727
fast, but you will have no run 
time hardware GPU support, which

04:12:14.728 --> 04:12:18.700
means the runtime performance 
will suffer.

04:12:18.701 --> 04:12:24.158
So this is in 2010, and people 
have had to choose between the 

04:12:24.535 --> 04:12:27.464
two.  And it is 2018 now, and we
have better versions of 

04:12:29.446 --> 04:12:33.157
everything, including the 
hardware GPU snap shot support. 

04:12:33.903 --> 04:12:37.028
This allows our users to choose 
both the quick boot feature as 

04:12:37.415 --> 04:12:41.510
well as hardware GPU emulation 
simultaneously.

04:12:41.511 --> 04:12:46.369
So if you look at what was 
happening behind the scenes for 

04:12:47.321 --> 04:12:53.072
this hardware GPU snap shot 
support, here is the emulator 

04:12:53.335 --> 04:12:59.612
GPU stack.  At the highest 
level, you have the Android OS, 

04:13:00.096 --> 04:13:05.655
which issues GPU commands.
At the lowest level, you have 

04:13:06.414 --> 04:13:10.065
your hardware graphics card, 

04:13:16.346 --> 04:13:19.182
which sets the commands.  And we
have the emulator, called the 

04:13:19.390 --> 04:13:24.379
translator.  And the translator 
will translate the GPU commands 

04:13:24.380 --> 04:13:28.309
from Android into your hardware 
GPU.

04:13:28.310 --> 04:13:32.128
And when we are doing the GPU 
snapshot support, we put all of 

04:13:32.439 --> 04:13:36.581
the logic into the translator 
layer so that if you serialize 

04:13:36.582 --> 04:13:41.158
this own state and dump them 
into your snap shot saved file.

04:13:41.494 --> 04:13:44.764
So one big question here was the
hardware states, which is

04:13:48.307 --> 04:13:55.404
eventually over to the emulator 
and different renderrors render 

04:13:55.736 --> 04:13:59.535
differently.
So to use the hardware state, we

04:13:59.797 --> 04:14:06.896
standard the APIs to fetch the 
hardware space from the hardware

04:14:08.041 --> 04:14:10.295
to the translator layer, and 
then we serialize all of them 

04:14:10.910 --> 04:14:14.346
and wrap it into the snap shot 
file.  In this case  in this 

04:14:14.347 --> 04:14:19.521
case, we can save and recover 
the whole emulated hardware GPU 

04:14:23.996 --> 04:14:25.124
state.
So -- 

04:14:25.125 --> 04:14:27.125
SPEAKER: All right, thank you

04:14:29.662 --> 04:14:34.512
Yahan.  In this demo, I will 
demonstrate that the GPU state 

04:14:34.513 --> 04:14:39.405
is snap shotted in its entirely.
We did not do something special,

04:14:39.780 --> 04:14:43.754
it can resume 3D apps like this 
almost immediately with the 

04:14:44.294 --> 04:14:47.128
snapshot load feature.
All right.

04:14:47.129 --> 04:14:51.095
And you can, for those of you 
who don't know already, you can 

04:14:51.723 --> 04:14:57.723
rotate the emulator in rotation,
using the rotation buttons.  

04:14:57.996 --> 04:15:01.479
Back to the slides I would like 
show a brief presentation.

04:15:01.480 --> 04:15:04.654
All right.  So I know that many 
of you know this already, but 

04:15:04.801 --> 04:15:08.370
for the benefit of people thin 
audience who don't know yet, I 

04:15:08.637 --> 04:15:12.681
would like to recap on some of 
the basic ways to use the 

04:15:12.682 --> 04:15:16.398
command line to launch the 
emulator, which can include 

04:15:16.788 --> 04:15:21.073
useful options if you are 
running a CI server, or power 

04:15:21.264 --> 04:15:24.929
user.
  So the emulator and the 

04:15:25.883 --> 04:15:32.550
Android SDK folder, Android 
SDK/emulator.  And in the 

04:15:33.694 --> 04:15:39.877
directory, you have to give the 
ABD command line option, may be 

04:15:39.878 --> 04:15:42.845
different than what is displayed
in the ABD manager.  If you want

04:15:43.531 --> 04:15:46.144
to know the exact sequence of 
characters to input there, then 

04:15:46.532 --> 04:15:48.532
you run 

04:15:50.833 --> 04:15:54.058
emulator-listABDs.
Second, how it  do you control 

04:15:54.476 --> 04:16:01.023
quick boot.  Sometimes you don't
want to use snap shots or save 

04:16:01.024 --> 04:16:03.024
your changes

04:16:06.805 --> 04:16:12.099
on exit.
So the first snap shot is to 

04:16:12.318 --> 04:16:15.678
attempt to load the current 
state on the device, cold boot.

04:16:16.364 --> 04:16:21.005
  The second, quick boot, it 
dischards changes to the snap 

04:16:21.006 --> 04:16:24.992
shot for CI use cases and if you
want the consistent start up 

04:16:25.263 --> 04:16:27.649
experience and want to wipe it 
clean when they are done with 

04:16:27.941 --> 04:16:32.372
it.  In this, you enter no snap 
shot save on the command line.  

04:16:33.288 --> 04:16:37.695
And all of the changes to the 
snap shot will be discarded when

04:16:38.279 --> 04:16:43.778
you exit the emulator.  Finally,
if snap shots are not your 

04:16:43.779 --> 04:16:47.406
thing, you can add no snap shot 
to your command line.  That will

04:16:48.238 --> 04:16:52.633
bring the Emulator back to the 
way it was before.

04:16:52.634 --> 04:16:59.243
And to recap, in the demo I gave
earlier, in launching multiple 

04:16:59.475 --> 04:17:02.978
instances of the ABD, that's the
read only option.

04:17:02.979 --> 04:17:07.088
That option will control whether
you are allowed to run multiple 

04:17:07.331 --> 04:17:10.179
instances of the same ABD or 
not.  When you are running in 

04:17:10.180 --> 04:17:14.497
that mode, all of the changes to
both the guest virtual disk and 

04:17:14.671 --> 04:17:18.015
to the snap shot, whatever you 
do, it is discarded when you 

04:17:18.308 --> 04:17:21.161
exit.
So invoke this, you would run 

04:17:22.079 --> 04:17:29.549
emulator-ABD, the AB it  D name,
followed by read-only.  I put in

04:17:30.013 --> 04:17:35.257
an ampersand, you don't have to,
but convenient for demo purposes

04:17:36.217 --> 04:17:40.535
here.
All right.  Now, I want to talk 

04:17:40.879 --> 04:17:43.772
about some of the command line 
options super some of the 

04:17:44.396 --> 04:17:48.593
features that we have introduced
recently to the emulator.

04:17:48.594 --> 04:17:51.720
In particular, screen record.  
Screen record is a feature where

04:17:52.042 --> 04:17:55.112
you can record the contents of 
the emulator to a video file, 

04:17:55.380 --> 04:17:58.576
and then play them back using 
your favorite app.

04:17:58.577 --> 04:18:02.541
This is great for CI users who 
want to be able to easily record

04:18:03.103 --> 04:18:06.885
what is going on when running 
tests on their app, and to 

04:18:07.154 --> 04:18:11.825
easily send reproductions of 
bugs to stakeholders.

04:18:11.826 --> 04:18:16.613
So the first set of commands 
concerns how to start and stop 

04:18:16.883 --> 04:18:18.883
the screen recording.

04:18:22.459 --> 04:18:27.457
 ADBADBemu screenrecord start, 
followed by the path to the 

04:18:27.627 --> 04:18:30.708
file, will start the recording. 
And it is important that you 

04:18:33.389 --> 04:18:36.141
provide the absolute path.  
Otherwise, you might not get it 

04:18:36.348 --> 04:18:39.129
saved.  It is a little 
confusing.  Sorry, working on 

04:18:39.130 --> 04:18:43.890
it.
The second command, ABDemu 

04:18:44.166 --> 04:18:47.150
screen record stop, it stops 
recording and there's a menu to 

04:18:47.456 --> 04:18:52.237
save the file.  So after you to 
it do do that, you can access 

04:18:53.016 --> 04:18:55.471
the file. And the third one 
concerns if you don't want the 

04:18:55.800 --> 04:18:59.288
whole video recording part, you 
can just instead take a 

04:18:59.841 --> 04:19:02.619
screenshot.  In this use case, 
the console command is screen 

04:19:02.865 --> 04:19:06.569
record screenshot, followed by a
path to the directory where you 

04:19:06.570 --> 04:19:09.841
want the screenshots to be 
saved.

04:19:09.842 --> 04:19:15.874
Now, let's go to the demo where 
I will demonstrate the screen 

04:19:17.249 --> 04:19:23.014
recording commands.
So we are in Emulator right now,

04:19:23.015 --> 04:19:30.883
and let's try to find a 
different app to record, we will

04:19:31.196 --> 04:19:36.588
start up the camera.  So while

04:19:40.458 --> 04:19:47.646
that is going on, I'm going to 
run this, so ADB emu, screen 

04:19:47.897 --> 04:19:54.898
record, start, users, user name,
documents, they have summit, 

04:19:57.784 --> 04:19:59.685
demo.webm.
So while it is recording, we 

04:19:59.686 --> 04:20:03.554
will just move around in here a 
little bit to make something 

04:20:05.854 --> 04:20:07.854
happen.
And we will stop the

04:20:16.343 --> 04:20:21.153
recording.
And that is kind of it  -- I 

04:20:21.979 --> 04:20:23.979
accidentally typed ADB there.  
So we will do another

04:20:29.184 --> 04:20:32.335
recording.
All right.  So the video is 

04:20:32.602 --> 04:20:35.879
saved, and you can open it in 
your favorite web

04:20:39.751 --> 04:20:42.828
browser.
Okay.

04:20:42.829 --> 04:20:50.425
Let's see, there we go.
So it is a Web M file, it will 

04:20:50.853 --> 04:20:54.994
work in most major browsers.
Second, there's always an UI for

04:20:55.319 --> 04:20:59.617
recording these screens.
It is in the extended controls 

04:20:59.879 --> 04:21:04.366
under the screen record tab.  So
in the screen record tab, it 

04:21:04.937 --> 04:21:07.495
starts with a single button, 
start recording.  So once we are

04:21:07.883 --> 04:21:12.451
starting recording, we will move
around a little bit, go to 

04:21:13.166 --> 04:21:17.658
recent, swipe away, and stop.
And now once you are done 

04:21:17.847 --> 04:21:20.013
recording, you don't have to 
save it to a file.  You can 

04:21:20.596 --> 04:21:24.415
preview it directly in the 
extended controls UI.

04:21:24.416 --> 04:21:29.381
So it is just a video of what we
just did.

04:21:29.382 --> 04:21:31.812
Go to recent, swipe away the 
apps, go back to the home 

04:21:32.086 --> 04:21:34.571
screen.  But you can still save 
it wherever you want.

04:21:34.572 --> 04:21:42.795
So let's just save this as demo 
two.  And that, similarly, works

04:21:47.083 --> 04:21:49.869
in the browser.
Okay, so that's one of the 

04:21:51.523 --> 04:21:55.219
features that we've added in 
2017 and 2018 is screen 

04:21:56.017 --> 04:22:00.279
recording to make your CI use 
cases better.

04:22:00.280 --> 04:22:05.551
Another feature that we've been 
doing a lot of work on and it is

04:22:05.888 --> 04:22:10.852
pretty exciting is AR core 
support.  Now, AR core support 

04:22:11.120 --> 04:22:14.393
consists of a few mage 
components: The first one, as 

04:22:14.684 --> 04:22:18.870
you may have seen already, is 
the virtual scene camera.  With 

04:22:19.385 --> 04:22:24.161
the virtual scene camera, we 
render a virtual environment, 

04:22:25.429 --> 04:22:29.581
which is suitable to image 
recognition and model placement 

04:22:29.817 --> 04:22:34.001
in AR apps.
So I will demonstrate a few of 

04:22:34.261 --> 04:22:39.935
them here.  In the back ground, 
in Android Studio, I have opened

04:22:39.936 --> 04:22:46.439
the augmented image, AR score 
sample.  This is available in 

04:22:47.314 --> 04:22:51.994
scene form Android S it  DK from
GitHub.  And what AR core 

04:22:52.326 --> 04:22:57.164
provides, and it is not just for
the emulator, but integrations 

04:22:57.165 --> 04:23:03.908
in studio as well.  So, for 
example, there's this scene form

04:23:05.248 --> 04:23:09.354
plugin for Android Studio where 
we can view models that are 

04:23:10.357 --> 04:23:13.560
meant for recent error core 
apps.  In addition, we can 

04:23:13.561 --> 04:23:17.269
change all the material 
properties we want in studio.  

04:23:17.698 --> 04:23:24.035
So this is the lower left frame,
and I might just say, lower the 

04:23:24.036 --> 04:23:26.036
red tint

04:23:30.305 --> 04:23:32.967
a bit.
I guess that did not change the 

04:23:33.280 --> 04:23:37.236
color very much, so I will 
change blue to zero as well.

04:23:37.237 --> 04:23:43.804
So once you save these files, 
the model should get reloaded.  

04:23:44.450 --> 04:23:52.107
And you will see that it is 
mostly green now.  And the 

04:23:52.292 --> 04:23:58.084
workflow, we can edit the model 
and deploy it to the device 

04:23:58.375 --> 04:24:00.375
while we wait,

04:24:02.780 --> 04:24:07.301
I guess.
All right.  So, in this app, we 

04:24:07.661 --> 04:24:12.806
are looking for images to 
recognize.  Another feature that

04:24:13.713 --> 04:24:17.047
we have added to the emulator 
for AR core support is the 

04:24:17.323 --> 04:24:21.088
ability to load augmented 
images, this is in the extended 

04:24:21.558 --> 04:24:25.066
controls panel under the camera 
tab.  We can choose different 

04:24:25.449 --> 04:24:30.181
posters to appear inside the 
virtual scene, and I have set 

04:24:30.182 --> 04:24:34.395
this JPEG of the earth to appear
on the table and the wall.  So 

04:24:34.396 --> 04:24:39.495
once you travel inside the scene
with this, and turn, face the 

04:24:39.496 --> 04:24:44.538
wall, we are starting to detect 
the image and it shows up there.

04:24:44.818 --> 04:24:53.194
So this show physical s if you 
are a developer of AR apps, you 

04:24:53.195 --> 04:24:59.406
have an end to end workflow and 
you can do it with scene camera.

04:24:59.977 --> 04:25:06.098
So that's pretty cool.  Finally,
another feature I would like to 

04:25:06.099 --> 04:25:09.019
mention that I will call out, 
unless you haven't seen it 

04:25:09.313 --> 04:25:16.186
before, is improved support for 
updating GMS core in Google Play

04:25:17.269 --> 04:25:20.739
services.  It is important to 
app developers because you have 

04:25:21.018 --> 04:25:25.373
to test how the app will run 
with different versions of core.

04:25:25.645 --> 04:25:29.379
If you see the image in the 
controls panel, there's a tab, 

04:25:29.665 --> 04:25:32.480
Google Play, and inside it, 
there's a button that shows the 

04:25:32.481 --> 04:25:36.858
current GMS core version and a 
button to up late it.  Once you 

04:25:37.186 --> 04:25:40.045
press update, you will be take n
tothe Play Store and be given 

04:25:40.046 --> 04:25:46.170
the option to update it.  I hap 
happen to have it updated 

04:25:46.171 --> 04:25:48.772
already, it is the latest 
version.  If a new version does 

04:25:48.773 --> 04:25:55.195
come out, it would say update.
I would also like to talk about 

04:25:55.196 --> 04:25:59.812
the integration of the Play 
Store and the Emulator in 

04:25:59.813 --> 04:26:03.605
general.
So this can be useful for app 

04:26:04.388 --> 04:26:06.656
developers who would like to 
test their app in more 

04:26:07.910 --> 04:26:11.315
end-to-end scenarios.  If your 
app requires other apps to be 

04:26:11.831 --> 04:26:15.161
installed in order for it to 
work, you can download them from

04:26:15.162 --> 04:26:18.396
the Play Store directly.  Also, 
you can look at your app in the 

04:26:18.527 --> 04:26:21.691
marketplace and see how users 
are reacting to it right there 

04:26:21.976 --> 04:26:26.371
and from different device sizes 
in different form factors.  And 

04:26:26.951 --> 04:26:31.171
so that concludes the feature 
demoes.  So back to Yahan in the

04:26:33.316 --> 04:26:35.389
slides. 
SPEAKER: All right.

04:26:35.390 --> 04:26:41.281
So here is the summary of the 
features we talked about today. 

04:26:41.282 --> 04:26:46.067
You might have noticed that 
there are two channels of the 

04:26:46.288 --> 04:26:50.994
emulator out there.  The first 
is the stable channel that you 

04:26:51.156 --> 04:26:56.425
normally get.  The latest update
is from July 2018.  The second 

04:26:56.850 --> 04:27:01.785
channel is the canary channel, 
which is less stable, but has 

04:27:02.493 --> 04:27:04.715
all of the cutting-edge features
we have in the emulator, and it 

04:27:05.594 --> 04:27:08.469
is released weekly.  Feel free 
to try it out.  In the stable 

04:27:09.699 --> 04:27:15.537
channel, we have this feature, 
this is already released, 

04:27:16.774 --> 04:27:19.758
including HyperVisor support, 
quick boot feature, generic snap

04:27:19.759 --> 04:27:25.706
shot SFEECHer, the Play Store, 
the screen recording, and the AR

04:27:25.999 --> 04:27:29.956
core and the virtual sensor 
support.  If you are trying out 

04:27:30.228 --> 04:27:34.824
the canary channel emulator, you
have a few more steps, including

04:27:35.219 --> 04:27:40.173
the faster quick boot feature, 
as we have shown in today's 

04:27:40.437 --> 04:27:44.779
demo, as well as the 
multiinstance support.

04:27:44.780 --> 04:27:49.840
And for those of you who are 
curious on how to switch the 

04:27:50.222 --> 04:27:53.038
channel, you can create the 
instruction.  In the Android 

04:27:53.554 --> 04:27:57.205
Studio, you can turn on your 
preference page.  In the update,

04:27:57.206 --> 04:28:00.908
you have your channel switch 
right there.

04:28:00.909 --> 04:28:05.536
And after that, you go to the 
emulator download page and use 

04:28:05.537 --> 04:28:08.784
the newer version available for 
download.

04:28:08.785 --> 04:28:12.095
So I believe that concludes our 
talk.

04:28:12.096 --> 04:28:16.882
So we will be QAing in the 
laundry, so thanks for attend

04:28:17.776 --> 04:28:19.776
attending.  Thank you.

04:28:25.157 --> 04:28:27.157
[ Applause ] 1QU #

04:28:35.899 --> 04:28:37.899
St.

04:42:04.334 --> 04:42:06.334
Coming up next: Vitals: Past, 

04:44:28.712 --> 04:44:32.112
Present &amp; Future by Fergus 
Hurley, Riccardo Govoni.

04:44:28.712 --> 04:44:30.980
C  SPEAKER: Hey, everyone.  
Thank you very much for joining

04:44:37.738 --> 04:44:38.776
today.
I'm Fergus Hurley and I'm 

04:44:38.777 --> 04:44:41.512
excited to talk to you about the
past, present, and future of 

04:44:45.760 --> 04:44:53.291
Android V  vitlsals, Google's 
initiative to improve the 

04:44:53.292 --> 04:44:56.057
stability and performance of 
devices.  We are doing a lot to 

04:44:56.458 --> 04:45:00.409
help this, in the play console, 
we have section, Android Vitals.

04:45:00.410 --> 04:45:02.763
That's where we report to you 
different performance metrics we

04:45:03.044 --> 04:45:05.044
are going to cover in this

04:45:12.955 --> 04:45:15.439
talk.
How we empower this is 

04:45:15.440 --> 04:45:18.928
interesting, hundreds of 
thousands of users share their 

04:45:19.262 --> 04:45:22.327
diagnostics data, and we share 
that data in a privacy-compliant

04:45:23.578 --> 04:45:27.328
way within the product.  I will 
start by going through lessons 

04:45:28.103 --> 04:45:31.972
we learned over the last 18 
months as we launched vitals 

04:45:32.135 --> 04:45:34.429
from top developers out there 
that are big and small that have

04:45:35.200 --> 04:45:38.946
actually used Android Vitals and
gotten a lot of success from 

04:45:40.282 --> 04:45:43.157
using them.
So hands up here if you want 

04:45:43.158 --> 04:45:45.842
less one-star ratings? If you 
don't have your hand up, you 

04:45:46.414 --> 04:45:50.831
might be in the wrong 
conference, unfortunately.

04:45:50.832 --> 04:45:53.671
But most people want to avoid 
them.  What we found when we 

04:45:53.970 --> 04:45:58.022
looked at the review corpus on 
Google play, which is pretty 

04:45:58.771 --> 04:46:04.013
large, is that 40 percent of all
one-star reviews were extracted 

04:46:04.689 --> 04:46:08.496
and talking about stability in 
bugs.  Over the past year, the 

04:46:09.296 --> 04:46:11.296
percentage of users talking 

04:46:13.881 --> 04:46:16.252
about stability has gone down 18
percent.  We are going to talk 

04:46:16.436 --> 04:46:18.436
about the developers that 
contributed to this

04:46:22.447 --> 04:46:26.409
reduction.
The emerge dragons team has used

04:46:27.260 --> 04:46:30.240
Android Vitals to pin point 
where there is an issue with 

04:46:30.241 --> 04:46:34.633
their application and this 
resulted in them reducng their 

04:46:34.634 --> 04:46:40.970
one-star reviews by 50 percent.
The very popular Reddit app used

04:46:40.971 --> 04:46:45.077
Android Vitals to be able to 
reduce their crash rate by 75 

04:46:45.356 --> 04:46:47.667
percent.  They did this because 
they were able to see the 

04:46:48.091 --> 04:46:51.603
category benchmarks in the play 
console Android Vitals section. 

04:46:51.860 --> 04:46:54.862
And they were able to make the 
case with their leadership that 

04:46:54.863 --> 04:46:58.269
they had room for improvement, 
and then when they actually 

04:46:58.428 --> 04:47:01.576
improved their metric, they were
able to show leadership, hey, we

04:47:01.882 --> 04:47:05.058
have actually done what we set 
up to do and we are one of the 

04:47:05.059 --> 04:47:14.341
most stable apps out there.
The logo team signed up for the 

04:47:15.410 --> 04:47:19.590
anomaly emails, and they got 
notified when there was an issue

04:47:19.591 --> 04:47:23.656
in their application.  They had 
a huge spike caused by an SDK 

04:47:23.657 --> 04:47:25.929
they were using in their 
application.  And even though 

04:47:26.079 --> 04:47:28.786
you might be building an amazing
product yourself and think it is

04:47:28.787 --> 04:47:31.939
stable, I'm sure you have used 
third party libraries and some 

04:47:32.362 --> 04:47:35.731
of them can introduce issues in 
your application.  You want to 

04:47:35.927 --> 04:47:40.733
become aware of that as soon as 
possible.  And anomaly alerts 

04:47:40.734 --> 04:47:44.307
distable it, and then they 
shifted it to a new fix that 

04:47:44.740 --> 04:47:49.302
reduced their ANR rate down to 
0.25 

04:47:52.403 --> 04:47:54.749
percent.
The AVA English team, pretty 

04:47:55.163 --> 04:47:57.748
small and they don't have 
infinite resources to spend on 

04:47:57.998 --> 04:48:00.760
performance.  We don't think you
should spend all of your time 

04:48:01.031 --> 04:48:03.791
focusing on performance, either.
But you have to keep an eye on 

04:48:03.792 --> 04:48:08.389
performance all the time and it 
might make sense for you to just

04:48:08.729 --> 04:48:13.177
focus on improving the 
performance of the application 

04:48:13.178 --> 04:48:16.837
and hold off on the new 
features, maybe as part of

04:48:20.205 --> 04:48:26.880
the '19Q1 planning.  This team 
did that and reduced their ANR 

04:48:26.881 --> 04:48:30.811
rate by 97 percent as a result.
This, and a bunch of other 

04:48:30.812 --> 04:48:33.973
things, resulted in them being 
able to increase their star 

04:48:34.365 --> 04:48:43.565
rating to 4.6 stars.  You cannot
get a 4.6 star reading if you 

04:48:43.566 --> 04:48:46.179
just focus on vitals, but you 
will never get a terrible one if

04:48:46.599 --> 04:48:50.120
you focus on vitals.
  We looked at individual app 

04:48:50.412 --> 04:48:53.642
users using vitals.  We also 
looked at, of the top thousand 

04:48:54.630 --> 04:48:59.843
apps on play, we looked at their
engagement in the vitals 

04:49:00.293 --> 04:49:03.244
section.  And the developers who
engaged most in the vitals 

04:49:03.467 --> 04:49:06.818
section, the top 10 percent, 
they reduced their crash rate by

04:49:07.096 --> 04:49:09.899
50 percent over that time 
period.  And this isn't just 

04:49:09.900 --> 04:49:13.452
good for those developers and 
those apps, they are good for 

04:49:13.886 --> 04:49:17.435
Android end users that resulted 
in $3 billion more stable 

04:49:18.064 --> 04:49:20.064
installs on the

04:49:22.584 --> 04:49:24.584
platform.
So we talked about stability, 

04:49:24.755 --> 04:49:28.968
and another major area that we 
just talked about when they 

04:49:29.254 --> 04:49:32.831
leave one star reviews is 
resource usage issues.  And this

04:49:33.264 --> 04:49:35.264
is

04:49:38.268 --> 04:49:40.268
battery, network, memory, etc. 
We have a lot

04:49:44.461 --> 04:49:49.910
interrelated.  One is excessive 
network usage in the background

04:49:51.989 --> 04:49:55.752
background.  It is consuming the
data plan and wasting the 

04:49:56.638 --> 04:50:01.014
battery.  We have two metrics to
help in this area, wake ups and 

04:50:02.359 --> 04:50:05.210
wake locks.  And the team 
focused on their wake ups rate, 

04:50:05.519 --> 04:50:09.609
and they said they wouldn't have
even noticed or fixed their 

04:50:10.003 --> 04:50:13.433
excessive wake ups issues 
without using Android Vitals, we

04:50:13.707 --> 04:50:17.275
have a lot of insights in your 
battery usage that few other 

04:50:17.658 --> 04:50:21.698
tools can help you with, and 
they reduced their wake up rate 

04:50:21.699 --> 04:50:25.697
by 70 percent.
Now we're going to jump over to 

04:50:26.176 --> 04:50:30.957
how you can actually increase 
your 5-star reviews.  And what 

04:50:31.252 --> 04:50:35.905
we find is over the past year, 
we've had more users mentioning 

04:50:36.079 --> 04:50:40.090
speed, design, and usability, 
which is what 70 percent of the 

04:50:40.359 --> 04:50:43.828
five-star reviews talk about 
when we are able to find topics

04:50:48.136 --> 04:50:50.136
in 

04:50:51.516 --> 04:50:56.437
them.
The mercado Libre team, number 

04:50:57.604 --> 04:51:00.549
one for eCommerce in Latin 
America, they built a new 

04:51:00.813 --> 04:51:04.845
feature in the application, 
requiring them to ask for a 

04:51:05.650 --> 04:51:08.823
certain permission, resulting in
a bad user experience where 

04:51:09.037 --> 04:51:12.114
users had a high denial rate of 
this permission.  They would see

04:51:12.675 --> 04:51:16.429
it in Android Vitals and 
redesigned that feature to give 

04:51:16.774 --> 04:51:21.596
users an explanation of why they
needed it, that permission, and 

04:51:22.105 --> 04:51:25.049
only ask when the users actually
needed that for that specific 

04:51:25.453 --> 04:51:30.099
feature and not early on in the 
process.

04:51:30.100 --> 04:51:35.851
And Mercado Libre team is pretty
big. And what they found useful 

04:51:35.852 --> 04:51:39.900
is the ability to keep track on 
many of the metrics and to see 

04:51:40.273 --> 04:51:44.979
that -- the start-up time, 
there's was a regression in 

04:51:45.263 --> 04:51:48.776
reduces and that caused the 
start-up time of the application

04:51:49.940 --> 04:51:53.442
long.  They found out the team 
that caused the issue and worked

04:51:53.753 --> 04:51:55.753
to debug that 

04:52:01.369 --> 04:52:06.049
issue.
This team used the monitoric ing

04:52:06.467 --> 04:52:13.033
tool to get deep am  insights.
And it does not cover in the 

04:52:13.307 --> 04:52:16.601
application where the issues 
might occur, so that's why we 

04:52:17.020 --> 04:52:19.668
encourage you to use Firebase 
performance monitoring as well 

04:52:20.017 --> 04:52:22.742
to understand where the specific
issues are occurring.  They 

04:52:22.963 --> 04:52:26.609
figured out that the log in and 
sign up flow is taking too long 

04:52:26.610 --> 04:52:30.276
and they decided to re-write 
that part of the application.

04:52:30.685 --> 04:52:39.485
So what's in vitals today?
So vitals consists of five 

04:52:39.486 --> 04:52:43.226
performance areas that you will 
agree are things you don't like 

04:52:43.491 --> 04:52:46.573
have happen when using apps, you
don't want it to crash, drain 

04:52:46.871 --> 04:52:51.399
your battery, slow in rendering,
requesting permissions you don't

04:52:51.400 --> 04:52:55.690
need, and slow to start.
And so we have 15 metrics 

04:52:55.938 --> 04:52:57.938
covering these

04:52:59.369 --> 04:53:05.502
these five performance areas 
today.  And we showed you an OS 

04:53:05.777 --> 04:53:11.813
version, your APK breakdown, 
device breakdown and, where 

04:53:12.082 --> 04:53:15.560
relevant, we provide other 
information as well when it is 

04:53:16.291 --> 04:53:18.291
possible.
And a new feature that we 

04:53:18.734 --> 04:53:24.273
launched at I/O this year is 
category benchmarks where you 

04:53:24.541 --> 04:53:28.150
can see, compared to other apps 
in your category, where you 

04:53:28.745 --> 04:53:32.541
stack up compared to your peers 
across every metric.  We give 

04:53:32.542 --> 04:53:37.901
you the 25th, 75th, and 50th 
percentile break down for the 

04:53:38.339 --> 04:53:40.383
category benchmarks and that 
helps you to understand, this 

04:53:40.612 --> 04:53:44.509
metric I'm doing okay on, and 
this one I'm actually falling 

04:53:44.758 --> 04:53:48.349
way behind and need to invest 
there.

04:53:48.350 --> 04:53:52.392
I mentioned the anomaly alert 
emails earlier.

04:53:52.393 --> 04:53:55.711
These are available in the 
console today, you have to opt 

04:53:55.979 --> 04:53:57.979
in to receive them.  So I 
encourage you, if you are not 

04:53:58.234 --> 04:54:01.380
opted in already, to sign up 
today and I encourage the rest 

04:54:01.381 --> 04:54:04.825
of your team to sign up as well.
And this is where we notify you 

04:54:05.085 --> 04:54:08.362
when there's a significant 
change in the ANR crash rate of 

04:54:09.167 --> 04:54:13.366
your application, where you have
a spike in the clusters, or 

04:54:13.641 --> 04:54:17.292
across the core vitals that 
we're going to talk about right 

04:54:17.719 --> 04:54:19.868
now.
There are 15 Android vital 

04:54:20.133 --> 04:54:23.594
metrics, it is a lot of metrics.
We think all of them are 

04:54:23.595 --> 04:54:25.595
important to deliver the best 
possible user experience, but 

04:54:25.748 --> 04:54:28.893
some of them are more important 
than others.  As talked about 

04:54:29.633 --> 04:54:32.260
earlier, the leading 
contribution to one star 

04:54:35.763 --> 04:54:38.530
reviews are civility and baltry 
issues. 

04:54:38.531 --> 04:54:43.514
THROOPS are four vitals across 
those, crash and ANR

04:54:47.511 --> 04:54:50.491
rate, and stuck partial wake 
locks and excessive wakeups in 

04:54:50.492 --> 04:54:54.868
the battery area.  For each core
or vital, we give you a bad 

04:54:54.869 --> 04:54:57.131
behavior threshold.  If you are 
above that threshold, you are 

04:54:57.132 --> 04:55:03.860
sort of failing the class.  That
bad behavior threshold is 

04:55:03.861 --> 04:55:08.348
looking at how it maps, the 
bottom 25 percent of apps are 

04:55:08.349 --> 04:55:10.349
above this rate, and that's 
where the bad

04:55:15.239 --> 04:55:18.829
behavior is.
We launched the pre-launch 

04:55:19.039 --> 04:55:23.137
report a couple years ago, this 
is when you upload your APK, we 

04:55:23.701 --> 04:55:27.247
would generate a report within 
an hour of how your application 

04:55:28.952 --> 04:55:30.952
performs across those different 
10 Android devices that you have

04:55:31.178 --> 04:55:34.763
in the test lab when a robot is 
navigating your application for 

04:55:35.125 --> 04:55:37.952
10 minutes.  It gives you a 
report showing a screenshot 

04:55:38.148 --> 04:55:40.367
clustering and a bunch of 
insights into accessibility 

04:55:40.657 --> 04:55:44.513
issues and privacy issues and 
also flags crashes.

04:55:44.514 --> 04:55:48.035
One we recently did is we 
enabled you, when you look at a 

04:55:48.310 --> 04:55:54.469
crash cluster in the vitels 
section is to see if we have a 

04:55:54.991 --> 04:56:00.019
pre-launch crash report that we 
detected that matches the 

04:56:00.672 --> 04:56:03.687
pre-launch crash report.  And 
there are not the same privacy 

04:56:03.979 --> 04:56:05.979
restrictions in place as there 
are with the data from the 

04:56:06.205 --> 04:56:09.683
field, of course.
And so here, we can be able to 

04:56:09.961 --> 04:56:12.627
show you the video of the robot 
interacting with your 

04:56:12.628 --> 04:56:15.190
application so you can quickly 
reproduce that issue yourself 

04:56:15.191 --> 04:56:19.803
and we provide a lot more log 
and detailed information.

04:56:19.804 --> 04:56:22.525
We also did the reverse.  So we 
have the ability to be able to 

04:56:22.854 --> 04:56:25.615
see when you are looking at a 
pre-launch report, is this a 

04:56:25.977 --> 04:56:29.255
crash that is already happening 
in the field, or is this one 

04:56:30.166 --> 04:56:34.947
that was introduced with my 
latest APK and has not reached 

04:56:35.234 --> 04:56:37.986
users yet? 
SPEAKER: We have over 100 

04:56:38.437 --> 04:56:41.695
developers using Android Vitals 
today.  Hands up here, who is 

04:56:42.359 --> 04:56:44.388
using Android Vitals? Cool, 
great.  Thank you guys for using

04:56:45.719 --> 04:56:49.398
it.
And one of the things that I 

04:56:49.933 --> 04:56:52.334
found most interesting about 
this project is that we have 

04:56:52.335 --> 04:56:57.102
expanded the number of users who
are using performance metrics, 

04:56:57.103 --> 04:56:59.609
or what we call engineering 
metrics.

04:56:59.610 --> 04:57:04.746
So I was previously working on 
apps with another team at 

04:57:05.091 --> 04:57:08.369
Google, and we did that external
to Google before. And one of the

04:57:08.370 --> 04:57:11.937
thing tat I struggled with is 
understanding how these metrics 

04:57:12.334 --> 04:57:15.737
are doing.  We had to have the 
latest version of the code, and 

04:57:15.999 --> 04:57:18.639
to be able to run the profilers 
and we made it so it is really 

04:57:18.940 --> 04:57:21.718
easy for all the people in your 
company to get access to these 

04:57:22.739 --> 04:57:25.570
performance metrics and be able 
to see how you are doing 

04:57:25.854 --> 04:57:29.086
relative to the other people and
make a case for investing here, 

04:57:29.370 --> 04:57:33.437
versus the other features.  I 
have shown some case studies 

04:57:33.438 --> 04:57:37.098
from different titles here, as 
you would expect, you have an 

04:57:37.099 --> 04:57:40.239
Android engineer, a head of 
mobile engineering and a product

04:57:40.240 --> 04:57:44.360
manager using it.  And now we 
have lead performance managers 

04:57:44.912 --> 04:57:49.785
using metrics, you have a CTO 
and COOs using engineering 

04:57:50.050 --> 04:57:57.040
metrics.  I encourage you and 
your teams to use these with 

04:57:57.318 --> 04:57:59.823
your senior leadership and with 
the wider team.  And if you 

04:58:00.381 --> 04:58:04.439
don't, you are probably going to
get left behind.  Because 

04:58:05.542 --> 04:58:07.884
quality across the whole Android
ecosystem is improving.

04:58:07.885 --> 04:58:10.813
So you would say, that is great,
it is impacting the other 

04:58:11.085 --> 04:58:16.356
developers, not me, my app is 
awesome, even if it has a high 

04:58:16.938 --> 04:58:20.157
crash rate.  I don't believe 
you.  We looked at the data of 

04:58:20.545 --> 04:58:25.004
users with a high crash rate 
versus a lower or medium crash 

04:58:25.155 --> 04:58:32.094
rate.  If they have a higher 
crash rate for the same app 

04:58:33.179 --> 04:58:37.812
leave 52 percent more reviews 
than a low or medium one.

04:58:37.813 --> 04:58:41.563
So I encourage you to use it if 
you are not.

04:58:41.564 --> 04:58:43.969
So what is the future of Android
Vitals?

04:58:43.970 --> 04:58:46.622
Well, we have built a lot of 
features, as you can tell so 

04:58:47.217 --> 04:58:49.217
far.
And so really the feature of 

04:58:50.014 --> 04:58:52.263
Android Vitals is you guys are 
using the product.

04:58:52.264 --> 04:58:55.392
And so, what we're going to do 
is right it now, we're going to 

04:58:55.657 --> 04:58:58.697
try something different.  I want
everyone to stand up, and talk 

04:58:58.929 --> 04:59:04.661
to the people beside you, so try
to find -- there you go.  Yep.

04:59:05.495 --> 04:59:08.498
And find someone beside you who 
hopefully you have not worked 

04:59:09.027 --> 04:59:11.679
with and just introduce yourself
and we're going to take two 

04:59:11.971 --> 04:59:14.337
minutes for one person to talk 
about their vitals and how they 

04:59:14.338 --> 04:59:17.393
are approaching it, and who in 
their company uses it, what are 

04:59:17.394 --> 04:59:20.700
the best practices involved, and
then switch the role for two 

04:59:20.932 --> 04:59:23.658
minutes.  I will give you two 
minutes now, and then we will 

04:59:32.781 --> 04:59:34.781
switch over.

05:00:59.777 --> 05:01:02.759
SPEAKER: If you haven't had the 
other person talk, switch over 

05:01:03.002 --> 05:01:05.002
and we will have one

05:01:12.547 --> 05:01:14.547
more minute.

05:02:03.564 --> 05:02:05.564
SPEAKER: Thank you very 

05:02:12.989 --> 05:02:17.602
much, everyone.
I hope you learned something 

05:02:17.603 --> 05:02:23.599
from the people you talked to, 
and made a new friend as well.

05:02:23.871 --> 05:02:29.032
So I would encourage you to talk
to other people about how they 

05:02:29.033 --> 05:02:31.033
are approaching their vitals.  
There's lot of documentation 

05:02:31.275 --> 05:02:35.952
online to help you as well, and 
we will be at the booth outside 

05:02:35.953 --> 05:02:38.217
afterwards on the right hand 
side when you walk out of this 

05:02:38.478 --> 05:02:43.444
room if you have any questions 
as well.  One of the things that

05:02:43.717 --> 05:02:46.735
you probably realize talking to 
the person is that one of the 

05:02:47.353 --> 05:02:52.209
biggest problems with vitals 
today is actionability, we heard

05:02:52.210 --> 05:02:56.029
you and your feedback, and we 
appreciate that.  And I want to 

05:02:56.306 --> 05:02:58.498
show you that is something we 
are working hard to improve and 

05:02:58.744 --> 05:03:02.872
we have more to come on that in 
the future.  We do believe that 

05:03:03.210 --> 05:03:06.228
the data is valid in terms of 
telling you the direction to go 

05:03:06.229 --> 05:03:09.185
as in, like, you are doing good 
or bad versus other people.  And

05:03:09.472 --> 05:03:12.665
we think we can do better in 
terms of helping you be more 

05:03:13.095 --> 05:03:15.516
efficient at fixing the problem.
But that is a really hard 

05:03:15.517 --> 05:03:19.074
problem, and we are working on 
changes to the whole OS it elf

05:03:20.039 --> 05:03:22.608
itself. 
Those things take a while to 

05:03:23.280 --> 05:03:25.451
propagate across the Android 
user base and to be able to have

05:03:25.713 --> 05:03:28.520
enough data to share back with 
you within the console is 

05:03:28.706 --> 05:03:31.097
something we are working on.  I 
want to thank you all very much 

05:03:31.407 --> 05:03:35.085
for joining us today, and best 
of luck with improving your 

05:03:35.801 --> 05:03:41.380
vitals.  I hope I get to share 
your vitals' success stories in 

05:03:42.256 --> 05:03:44.256
our talk next year.  Thank you.

05:03:52.937 --> 05:03:54.937
[ Applause ]

05:04:34.131 --> 05:04:36.301
.
Coming up next: Re-stitching 

05:05:58.101 --> 05:06:00.767
Plaid with Kotlin by Florina 
Muntenescu.

05:05:58.101 --> 05:06:00.101
SPEAKER: Hello, 

05:06:04.258 --> 05:06:06.865
everyone.
I'm Florina Muntenescu, a 

05:06:08.637 --> 05:06:12.277
developer advocate at Google.  
For the past few months, me are 

05:06:12.667 --> 05:06:16.936
working on bringing Plaid in 
fashion, it was brought by a 

05:06:17.122 --> 05:06:20.968
colleague of a way of showcasing
material design.  We are seeing 

05:06:21.356 --> 05:06:23.356
the state of the

05:06:26.419 --> 05:06:33.470
app in 2016 in Plaid glory days.
We see animations and 

05:06:33.912 --> 05:06:36.248
VectorDrawables and a lot of 
these made the app shine and 

05:06:36.818 --> 05:06:41.671
improved the user experience.
So Plaid takes data from three 

05:06:41.672 --> 05:06:44.734
different sources.
And, well, these sources from 

05:06:45.658 --> 05:06:50.049
2016 until now, well, some of 
them were deprecated.

05:06:50.050 --> 05:06:53.861
So that meant that, out of three
sources, we were left with one 

05:06:54.840 --> 05:06:58.451
and a little bit.
So, from all of these nice, 

05:06:58.838 --> 05:07:03.471
fancy UI features that we had, 
we were left with almost nothing

05:07:03.836 --> 05:07:06.208
and with a pretty boring 
application.

05:07:06.209 --> 05:07:09.277
So we decided we didn't want to 
leave it like this, and we said 

05:07:09.710 --> 05:07:13.211
that we wanted to fix this 
broken functionality.

05:07:13.212 --> 05:07:17.085
But apart from this, we also 
knew that we wanted to go 

05:07:17.523 --> 05:07:20.506
towards something that a modular
and expenseable from the 

05:07:20.767 --> 05:07:23.518
architecture point of view.  But
the thing is that Plaid was 

05:07:24.033 --> 05:07:28.798
developed as an UI sample, not 
as an architecture sample.

05:07:28.799 --> 05:07:34.870
So you won't be surprised to see
all the dependencies in the code

05:07:34.871 --> 05:07:39.153
and, well, code that was 
actually a bit behind, because 

05:07:39.928 --> 05:07:43.424
Nick started building this in 
2014.  At that time, we didn't 

05:07:43.696 --> 05:07:46.373
have the guide to that 
architecture that we released 

05:07:46.515 --> 05:07:49.799
last year.  And also, although 
we have Kotlin, we doesn't 

05:07:50.161 --> 05:07:54.315
really use it.  So we knew that 
we wanted to rebuild Plaid and 

05:07:54.316 --> 05:07:57.118
in the right way.
So to have it in a good state 

05:07:57.526 --> 05:08:00.619
for any future changes that we 
wanted it build.

05:08:00.620 --> 05:08:04.885
So in this talk, I wanted to 
tell you what we've learned and 

05:08:04.886 --> 05:08:06.886
how we managed

05:08:08.700 --> 05:08:10.700
to leverage calls in our 

05:08:13.026 --> 05:08:17.885
app.  We released this guide to 
the app architecture, and it is 

05:08:17.886 --> 05:08:22.401
still quite vague.  So we have 
these main classes, some idea 

05:08:22.402 --> 05:08:26.070
for how we should architect our 
app, but we wanted to create 

05:08:26.071 --> 05:08:30.118
clear guidelines.  So we defined
main types of classes in our app

05:08:30.371 --> 05:08:35.570
and we also defined a set of 
rules for each one of these 

05:08:35.741 --> 05:08:40.057
classes.  So we defined a remote
data source, whose role is 

05:08:40.294 --> 05:08:42.876
actually just to store the 
request data, fetch the data 

05:08:43.139 --> 05:08:48.405
from the API service.  And 
that's it.

05:08:48.406 --> 05:08:50.680
We could request information and
return the response received.

05:08:50.681 --> 05:08:55.134
  Next, we would have a local 
data source, whose role is just 

05:08:55.536 --> 05:09:01.209
to store data on disk.  So you 
can either do this in shared 

05:09:01.445 --> 05:09:04.195
preferences, or in the database.
Next, we would have the 

05:09:04.590 --> 05:09:09.935
repository whose role is to 
fetch and store data.  And, 

05:09:09.936 --> 05:09:12.602
optionally, it could also do 
in-memory cache.  So the 

05:09:13.176 --> 05:09:17.030
repository will be the class 
that mediates between the local 

05:09:17.031 --> 05:09:23.707
and the remote data source.
Because the business logic was 

05:09:23.708 --> 05:09:27.800
quite complex, we decided to add
another layer: Use cases.  So 

05:09:28.027 --> 05:09:31.688
the role of the use cases is 
just to process databased on 

05:09:31.689 --> 05:09:36.457
business logic.  This will be 
small, lightweight classes that 

05:09:36.458 --> 05:09:40.678
can be reused.  So the use cases
depend on repositories and/or 

05:09:40.679 --> 05:09:44.033
other use cases.
And next, we would have a 

05:09:44.213 --> 05:09:47.920
ViewModel.  So the ViewModel's 
role is to expose data to be 

05:09:48.390 --> 05:09:51.822
displayed by the UI, and also to
trigger actions based on the 

05:09:52.098 --> 05:09:55.322
user's actions.
And the ViewModel would depend 

05:09:55.906 --> 05:09:59.487
on use cases.
As an input, the ViewModel would

05:09:59.817 --> 05:10:04.539
give IDs.  It would give IDs in 
the case where it is a model for

05:10:04.540 --> 05:10:08.778
a detail screen, for example, 
and it would give the user's 

05:10:09.185 --> 05:10:12.264
actions an an input.  And 
output, it would return a 

05:10:12.655 --> 05:10:14.655
LiveData.
And next in the UI, we would 

05:10:15.881 --> 05:10:18.744
work with activities in XML.  So
the role of these is just to 

05:10:19.128 --> 05:10:22.590
display the data and to forward 
actions to the ViewModel.

05:10:22.591 --> 05:10:27.682
As an input, they would get the 
optional ID and the user's 

05:10:29.025 --> 05:10:32.706
actions.
So we looked at our application,

05:10:32.966 --> 05:10:38.034
or the architecture, and we 
divided it into three layers: 

05:10:38.035 --> 05:10:41.939
The data, domain, and UI.  When 
we decided to be more 

05:10:41.940 --> 05:10:46.080
opinionated in the way that we 
use the libraries we are using. 

05:10:46.081 --> 05:10:50.655
We knew that the LiveData really
shines when it is used with an 

05:10:50.951 --> 05:10:53.310
activity or a fragment.  We 
decided to really keep the 

05:10:53.678 --> 05:10:57.556
LiveData only between the 
ViewModel and the UI, and that's

05:10:57.557 --> 05:11:01.051
it.
And even more, was of the nice 

05:11:01.466 --> 05:11:04.389
integration between LiveData and
data binding, we decided to use 

05:11:05.005 --> 05:11:09.405
data binding in our XMLs.
But again, still with all of 

05:11:09.406 --> 05:11:11.983
these constraints and all of 
these guidelines that we've set,

05:11:12.346 --> 05:11:15.634
there are so many ways in which 
we can actually implement this 

05:11:15.930 --> 05:11:20.512
kind of architecture.  And we 
knew that Kotlin and the Kotlin 

05:11:20.984 --> 05:11:23.286
language features will help us 
improve this even more.  And 

05:11:23.565 --> 05:11:29.706
more precisely, what we 
particularly like are the 

05:11:29.707 --> 05:11:31.850
functional constructs that 
Kotlin supports.  And one of the

05:11:33.088 --> 05:11:35.703
first decisions that we have to 
make is to handle asynchronous 

05:11:36.142 --> 05:11:40.306
operations.  And we decided to 
work with coroutines as the 

05:11:41.092 --> 05:11:45.108
backbone of our app, with 
coroutines, it is easy to launch

05:11:45.388 --> 05:11:49.415
a Coroutine and handle the 
response.  And more precisely, 

05:11:50.052 --> 05:11:52.777
what we liked is the fact that 
coroutines have a scope.  So, 

05:11:53.269 --> 05:11:56.157
for example, let's say that you 
are opening the activity, you 

05:11:56.158 --> 05:11:58.699
are triggering a network 
request, you want to make sure 

05:11:59.006 --> 05:12:01.597
that when you are pressing back 
and exiting that activity, you 

05:12:02.288 --> 05:12:04.929
are also cancelling that network
request.

05:12:04.930 --> 05:12:08.244
So this scoping of it the 
coroutines is something that we 

05:12:08.677 --> 05:12:10.581
liked.
So this meant that we decided 

05:12:10.582 --> 05:12:13.142
that, in the ViewModel, would be
the place where we are launching

05:12:13.459 --> 05:12:16.904
and we are cancelling coroutines
and we are also making that 

05:12:17.241 --> 05:12:19.536
transition between coroutines 
and LiveData.

05:12:19.537 --> 05:12:23.964
But then, for all the other 
layers above the ViewModel, we 

05:12:23.965 --> 05:12:28.943
would use suspension functions.
And these suspension functions 

05:12:29.338 --> 05:12:34.794
would return a result class.
So, more precisely, this result 

05:12:35.586 --> 05:12:37.984
will have two types: Success or 
error.

05:12:37.985 --> 05:12:42.979
And this is because we wanted to
make sure we are not throwing 

05:12:43.177 --> 05:12:46.229
exceptions here and, there but 
that the errors represent a 

05:12:46.620 --> 05:12:51.460
state.  So what is interesting 
in Kotlin is that if you want to

05:12:51.461 --> 05:12:56.658
be able to ectend the class, you
have to market  mark it as open.

05:12:57.236 --> 05:13:01.306
This means that classes are 
final by default and you have to

05:13:01.584 --> 05:13:04.990
be intentional when using 
inheritance.  That means that 

05:13:05.258 --> 05:13:08.178
Kotlin supports the idea, the 
best practice of favoring 

05:13:09.482 --> 05:13:12.857
composition versus inheritance. 
But we can do better than using 

05:13:13.418 --> 05:13:16.195
open classes.  We can use a 
sealed class, because with a 

05:13:16.986 --> 05:13:20.834
sealed class, we can restrict 
the class hierarchies.  That 

05:13:21.099 --> 05:13:25.134
means we cannot extend the class
outside this file.

05:13:25.135 --> 05:13:28.726
So a lot of times when we would 
use this result class, we would 

05:13:28.994 --> 05:13:31.315
typically use it

05:13:36.824 --> 05:13:41.229
inside a with, it has smart 
casts, when there's a success, 

05:13:41.230 --> 05:13:44.140
you do something, when it is an 
error, you do something else.

05:13:44.966 --> 05:13:48.133
But every time we were using it,
we wanted to make sure that we 

05:13:48.418 --> 05:13:53.249
were always handing every case 
and making sure that by mistake 

05:13:53.522 --> 05:13:56.327
we are not handling something, 
we wanted the compiler to tell 

05:13:56.873 --> 05:14:01.456
us that, hey, you forgot 
something, you forgot to handle 

05:14:01.457 --> 05:14:04.981
the error case.  This meant that
the when needs to be exhaustive.

05:14:04.982 --> 05:14:08.872
But when is exhaustive only when
used as an expression.

05:14:08.873 --> 05:14:16.004
So we added, we created the 
exhaustive property.  So more 

05:14:17.199 --> 05:14:20.324
precisely, we created an 
extension property where we are 

05:14:21.203 --> 05:14:24.443
returning the object.
Here's another problem that we 

05:14:24.444 --> 05:14:28.574
have.
So we have a comment class and a

05:14:28.762 --> 05:14:31.259
comment with replies.  So the 
difference between these two, 

05:14:31.260 --> 05:14:34.435
and the fact that the comment 
also holds the information about

05:14:34.436 --> 05:14:37.878
the user that posted the 
comment.  So it will have the 

05:14:38.341 --> 05:14:41.607
display name and the portrait 
url, and the comment with 

05:14:42.180 --> 05:14:45.631
replies is pretty much a tree 
structure that holds the replies

05:14:45.906 --> 05:14:49.806
of the comment and the replies 
of the replies and such.  What 

05:14:49.976 --> 05:14:52.981
we had to do was to build a 
comment out of the comment with 

05:14:52.982 --> 05:14:58.300
replies and a user object.
So you said, okay, that is easy,

05:14:58.301 --> 05:15:02.152
create a new constructor that 
gets the parameter, the user, 

05:15:02.506 --> 05:15:06.407
and the comment with replies and
that is it.  But the thing is, 

05:15:06.677 --> 05:15:11.673
we didn't really like this 
because the classes were in two 

05:15:12.001 --> 05:15:14.390
different layers, why should the
comment know about the comment 

05:15:17.554 --> 05:15:21.066
with replies, why shouldn't it 
know about the user? Why should 

05:15:21.531 --> 05:15:26.200
we need to changes this.htm? So 
what weep ended up using is an 

05:15:26.463 --> 05:15:30.110
extension function.  So more 
preciseprecisely, we built an 

05:15:30.313 --> 05:15:36.257
extension function to the 
comment with replies, and that 

05:15:36.258 --> 05:15:39.574
will create a comment.  So when 
you are building an extension 

05:15:39.575 --> 05:15:44.092
function, you only have access 
to the public fields.  So this 

05:15:44.093 --> 05:15:49.282
means that we're not, by 
mistake, accessing or changing 

05:15:49.283 --> 05:15:52.545
any private implementation and 
it allows us to keep our classes

05:15:53.148 --> 05:15:56.254
focused on what they do without 
extending them.

05:15:56.255 --> 05:15:59.786
And so it meant that we didn't 
have to college the public API 

05:16:00.222 --> 05:16:04.898
and we would avoid accessing 
private implementation details.

05:16:05.248 --> 05:16:08.438
So what I like about data 
classes is the fact that they 

05:16:08.821 --> 05:16:14.514
are value objects, this shines 
when used in tests.  So for 

05:16:14.780 --> 05:16:19.531
example, we had an out vote flag
in the comment.  So when we 

05:16:19.762 --> 05:16:25.884
checked the test to see if it 
was up voted, it would have it 

05:16:26.267 --> 05:16:29.549
to false, would upload the 
comment and check whether the 

05:16:29.814 --> 05:16:34.082
expected result is similar to 
the initial comment, but with 

05:16:36.437 --> 05:16:39.736
that up voted flag to true.  And
because the comment has so many 

05:16:40.142 --> 05:16:43.188
fields, it is easy to make 
mistakes and what is actually 

05:16:43.189 --> 05:16:47.684
important here, the fact that 
the up voted flag has changed.  

05:16:47.943 --> 05:16:52.761
With Kotlin, you can use the 
copy method.  We create a copy 

05:16:53.412 --> 05:16:56.849
of the orbital and -- that it is
called on, and we are setting 

05:16:56.850 --> 05:17:00.276
the flag, the flag that we are 
actually changing.

05:17:00.277 --> 05:17:08.036
And that's it.  The code is more
concise and more readable, more 

05:17:08.432 --> 05:17:10.442
comprehensible.
So let's take another example.  

05:17:10.715 --> 05:17:14.809
So we had another, in the app, 
we are working with a remote 

05:17:15.082 --> 05:17:19.848
data source to post a comment.  
And here, we would expose the 

05:17:20.809 --> 05:17:23.797
suspension function that return 
a result.  And inside this 

05:17:24.432 --> 05:17:28.441
method, we would create a new 
comment request, which would 

05:17:28.625 --> 05:17:31.742
trigger that request in the 
back-end, we would await for the

05:17:31.743 --> 05:17:35.108
response, and then we would 
handle the response, building 

05:17:35.510 --> 05:17:39.733
the results success, or the 
result  result of error, 

05:17:39.919 --> 05:17:43.415
depending on what is needed.  If
you look at this code, this is 

05:17:43.572 --> 05:17:47.501
actually not enough.  In the 
case when your device is 

05:17:47.939 --> 05:17:50.866
offline, this code will crash.  
So what we had to do is to run 

05:17:51.542 --> 05:17:55.267
up every request inside a 
tricatch, and we had a lot of 

05:17:56.576 --> 05:17:59.495
requests.  So we saw that we 
keep on adding and adding this 

05:17:59.991 --> 05:18:06.004
tricatch everywhere, and then 
our methods were loaded so we 

05:18:06.751 --> 05:18:09.384
couldn't really focus on what 
really mattered on building the 

05:18:09.385 --> 05:18:11.233
response, triggering the 
request.

05:18:11.234 --> 05:18:16.126
So what we did is create a 
top-level function.  So this 

05:18:19.538 --> 05:18:22.380
would  would be a suspending 
function with a Lambda or the 

05:18:22.735 --> 05:18:26.317
error message.  Here, it would 
trigger the code, wrap it inside

05:18:26.577 --> 05:18:31.177
a tricatch, in the case of an 
exception or result of error, 

05:18:31.431 --> 05:18:34.826
based on the error we passed in.
So this means that in the null 

05:18:35.128 --> 05:18:40.648
data source, we could just 
create a safe API call and then 

05:18:40.928 --> 05:18:44.281
put the call that matters for us
inside another function.

05:18:44.282 --> 05:18:48.895
The code became more readable 
and easy to understand.

05:18:48.896 --> 05:18:52.735
So this safe API call, I was 
saying that it has the call as a

05:18:53.344 --> 05:18:56.722
first parameter and the error 
message as a second one.  In 

05:18:57.311 --> 05:19:02.156
Kotlin, if you -- if the last 
parameter of a method is a lam 

05:19:02.157 --> 05:19:05.216
it Lambda, it means that you can
use it as a trailing Lambda.  

05:19:05.544 --> 05:19:08.807
That meant that when you are 
calling this, instead of passing

05:19:08.808 --> 05:19:11.709
these two parameters, we can 
just pass the error members of 

05:19:11.930 --> 05:19:16.083
the jury as a parameter of the 
function and then use the 

05:19:16.521 --> 05:19:19.192
trailing syntax to call the 
method.

05:19:19.193 --> 05:19:23.642
So like this, the code becomes 
more concise.  But it is more 

05:19:23.950 --> 05:19:27.754
readable, so when we looked at 
this, it felt like what matters 

05:19:28.032 --> 05:19:31.450
here the most is the error 
message, which is not really

05:19:35.689 --> 05:19:40.194
the case.  What mattered is we 
get the first comment.  So 

05:19:40.195 --> 05:19:45.121
although the code is more 
concise, it doesn't mean more 

05:19:45.884 --> 05:19:50.686
readable.  So brevity is not 
necessarily a good thing.  If 

05:19:50.687 --> 05:19:54.145
Kotlin offers all of these 
features, be mindful and think 

05:19:54.146 --> 05:19:56.629
of whether you need all of 
these, and use them in the right

05:19:57.143 --> 05:20:00.827
places.  This is another 
example.

05:20:00.828 --> 05:20:06.119
So, as soon as we were switching
to Kotlin, in the activities, 

05:20:06.120 --> 05:20:10.245
the first thing that we did is 
make all of the views latant, 

05:20:11.677 --> 05:20:14.467
becausewy  we didn't want all of
the nullability.  We looked at 

05:20:14.468 --> 05:20:19.283
the code and saw that we 
shouldn't do this.  Some views 

05:20:19.602 --> 05:20:23.521
are no result views, or only 
inflated when specific 

05:20:23.897 --> 05:20:27.171
conditions are met.
So actually nullability was 

05:20:27.172 --> 05:20:30.120
good, nullability can be 
meaningful.  Nullability was 

05:20:30.402 --> 05:20:33.358
telling us that something is 
missing and that we should 

05:20:33.629 --> 05:20:36.456
really handle it.
So,

05:20:40.063 --> 05:20:45.226
overall, all of these features 
from Kotlin, like coroutines can

05:20:45.476 --> 05:20:48.587
help us shape our app.  And 
together, with the guide to app 

05:20:48.588 --> 05:20:52.449
architecture, help us build this
maintainable, this safer and 

05:20:52.450 --> 05:20:56.136
faster to develop architecture 
that we wanted to have.

05:20:56.137 --> 05:20:58.137
Thank you.

05:21:06.852 --> 05:21:08.852
[ Applause ] 

05:23:13.324 --> 05:23:15.324
1Y50IRK9SDS

05:27:59.223 --> 05:28:01.223
[ Applause ] 
Coming up next: Getting the Most

05:34:36.287 --> 05:34:40.553
from the New Multi-Camera API by
Emilie Roberts, Oscar Wahltinez,

05:34:36.287 --> 05:34:38.287
Vinit Modi  . 
SPEAKER: Hi, everyone, welcome 

05:34:38.858 --> 05:34:40.934
to this session on the new 
multi-camera

05:34:48.723 --> 05:34:58.549
API.  I'm vinit ModModi. 

05:34:58.948 --> 05:35:03.989
I will give an update on the 
state of camera.  Most camera 

05:35:03.990 --> 05:35:09.090
apps focus on the native camera 
app that ships with the device. 

05:35:09.091 --> 05:35:13.010
More than twice the amount of 
usage occurs on the apps that 

05:35:13.011 --> 05:35:15.579
you build.  And it is extremely 
important that you support the

05:35:18.999 --> 05:35:20.999
new features that are available 
in the new

05:35:23.312 --> 05:35:28.227
Android APIs.  When we speak to 
a lot of developers, the number 

05:35:28.228 --> 05:35:34.606
one question is the state of 
camera 2 API and where we are 

05:35:34.607 --> 05:35:37.680
going forward.  Starting with 
Android P, you will find that 

05:35:37.681 --> 05:35:39.759
almost new devices will support

05:35:45.813 --> 05:35:52.184
camera 2 and HALv3.  You will 
see that the characteristics are

05:35:52.712 --> 05:35:56.120
unlimited, like a point and 
shoot, a full, with advanced 

05:35:56.797 --> 05:36:05.168
capabilities, and level 3, with 
YUV processing and raw.

05:36:05.169 --> 05:36:08.314
We are working with several 
manufacturers to open new APIs 

05:36:10.718 --> 05:36:17.626
at launch.
We're excited that the pixel 3 

05:36:18.536 --> 05:36:23.531
and the HAUWEI20 series support 
the API.

05:36:23.532 --> 05:36:25.532
Why is this so important? Prior

05:36:28.570 --> 05:36:34.126
to Android P, as developers, you
get access to one of the center

05:36:38.744 --> 05:36:41.808
sensors and the native app the 
whole capability.  We have the 

05:36:42.201 --> 05:36:46.896
native camera app, with the 
sensor and the logical camera, 

05:36:46.897 --> 05:36:49.717
an abstraction of all of the 
physical sensors that allow you 

05:36:49.718 --> 05:36:53.557
to take advantage of the 
hardware.

05:36:53.558 --> 05:36:56.760
There are several use cases and 
possibilities with the new 

05:36:56.761 --> 05:37:01.240
multi-camera API.  Today, Oscar 
is going to talk about optical 

05:37:01.846 --> 05:37:08.275
zoom and Emilie is going to 

05:37:18.098 --> 05:37:21.703
cover bouquet. 
SPEAKER: I'm in thethe. 

05:37:21.704 --> 05:37:24.480
SPEAKER: I'm on the developer 
relations team, and we will 

05:37:24.967 --> 05:37:26.967
start with the live

05:37:28.177 --> 05:37:33.878
demo.  What could go wrong.  Are
we on?

05:37:42.786 --> 05:37:44.786
Nope.

05:38:07.362 --> 05:38:10.736
Here we are implementing the 
multicamera zoom.  We are 

05:38:11.020 --> 05:38:15.219
swapping, at the UI layer, the 
two camera streams and not doing

05:38:15.220 --> 05:38:20.681
any kind of zoom or cropping.  
And you can see it is 

05:38:20.929 --> 05:38:23.029
instantaneous, and this is just 
a single session.

05:38:23.030 --> 05:38:31.336
And I'm swapping the two camera 
streams.

05:38:31.337 --> 05:38:35.342
And I have the same thing here 
on the pixel phone, and the main

05:38:35.601 --> 05:38:40.832
idea is that you can see it is 
working on -- if it works

05:38:50.595 --> 05:38:53.029
again.
Had this been working, you would

05:38:53.312 --> 05:38:56.149
see the same demo.
[ Laughter ].

05:38:56.150 --> 05:38:58.150
In any case.  We will go back to
the

05:39:00.771 --> 05:39:03.794
same slides.
The idea is that the single 

05:39:04.126 --> 05:39:09.889
camera session, to the streams, 
we are going to swap between the

05:39:10.815 --> 05:39:16.252
streamsstreams and show you how 
it was built.  We have the same 

05:39:16.253 --> 05:39:23.260
running on both devices, a feat 
to have them on both devices 

05:39:23.261 --> 05:39:26.224
something that is tied to the 
hardware and the camera.

05:39:26.225 --> 05:39:31.599
So we will talk about how we can
use multiple cameras 

05:39:32.096 --> 05:39:34.967
simultaneously, the basic 
guarantee provided by the API is

05:39:35.700 --> 05:39:40.044
that you can use two streams at 
the same time.

05:39:40.045 --> 05:39:43.486
Recall the guaranteed stream 
configurations for single camera

05:39:44.098 --> 05:39:51.364
devices.  It is a set of rules 
based on higher level, target 

05:39:51.617 --> 05:39:55.794
type, and size.  If we use the 
multi-camera APIs correctly, we 

05:39:56.300 --> 05:39:58.854
can get an exception to these 
rules.

05:39:58.855 --> 05:40:04.832
We will illustrate it with an 
example.  We have a single YUV 

05:40:04.833 --> 05:40:09.238
stream of maximum size.  As to 
the previous table, devices with

05:40:09.858 --> 05:40:13.679
minimum hardware level will be 
able to use a single stream 

05:40:13.680 --> 05:40:16.456
without configuration.  If we 
use the multi-camera APIs, we 

05:40:17.539 --> 05:40:22.756
can use two streams of 
equivalent configuration from 

05:40:22.757 --> 05:40:24.757
the underlying physical

05:40:27.150 --> 05:40:30.283
cameras.
Let's walk through what we are 

05:40:30.567 --> 05:40:35.188
going to do to implement the app
we demoed earlier.  We broke it 

05:40:35.346 --> 05:40:39.518
into five steps.  Are you ready?
Step number one, find the 

05:40:39.519 --> 05:40:42.043
physical cameras.  We start by 
defining pairs of physical

05:40:47.389 --> 05:40:51.320
cameras that can be operated 
simultaneously.

05:40:51.321 --> 05:40:58.574
Using the subject, we look for 
test capabilities.  If logical 

05:40:58.869 --> 05:41:02.033
multicamera is one of them, we 
know this device is a logical 

05:41:02.302 --> 05:41:07.250
camera.  And now that we found a
logical camera, we store it, we 

05:41:08.072 --> 05:41:12.737
will need the ID for later, we 
will see.  We get the physical 

05:41:13.068 --> 05:41:19.261
cameras associated with it.
And then we can move on to the 

05:41:19.262 --> 05:41:23.501
next step.
Here are some steps for what I 

05:41:24.193 --> 05:41:26.193
just described.  You take the 

05:41:29.230 --> 05:41:32.266
logical camera, you call get 
physical camera IDs, and we 

05:41:32.630 --> 05:41:35.015
create the physical cameras 
associated with the eligible 

05:41:36.374 --> 05:41:39.013
camera group.
On to the next step: Open 

05:41:40.069 --> 05:41:44.930
logical camera.
The second step is nothing new, 

05:41:45.112 --> 05:41:49.609
open the camera.  Recall the 
camera ID we set earlier, that 

05:41:49.877 --> 05:41:53.642
is the only one we use to pass 
to the camera manager.

05:41:53.643 --> 05:42:00.256
To reiterate, we only open the 
logical camera.  This triggers 

05:42:00.716 --> 05:42:03.957
whether the device is ready.
We have now opened logical 

05:42:04.295 --> 05:42:07.474
camera.
In the next step, we will create

05:42:07.749 --> 05:42:11.085
the applicable configuration 
updates.  They are used to 

05:42:11.762 --> 05:42:14.538
create the camera session.  For 
each desired target, we may have

05:42:15.515 --> 05:42:20.543
a physical camera from the list 
we found earlier if we want to 

05:42:20.544 --> 05:42:23.993
retrieve frames from a specific 
camera.  We will go into more 

05:42:24.550 --> 05:42:29.043
details.  We create the output 
configuration object, using the 

05:42:29.519 --> 05:42:33.370
desired output target.  If we 
want to associate that output as

05:42:33.628 --> 05:42:39.336
a specific physical camera, then
we pass the AD in the set 

05:42:39.793 --> 05:42:41.793
physical camera ID API.  If

05:42:43.822 --> 05:42:47.139
we want to use eligible camera, 
we can skip this step.  We also 

05:42:47.140 --> 05:42:49.538
may is have a configuration of 
both.

05:42:49.539 --> 05:42:53.141
So, at the end of the day, we 
have a list of configurations, 

05:42:53.538 --> 05:42:56.311
some of which are associated 
with physical cameras, and some 

05:42:56.755 --> 05:42:59.809
of which logical camera.  The 
goal is to put all of the 

05:42:59.810 --> 05:43:04.565
configurations into a single 
session  session configuration. 

05:43:05.030 --> 05:43:10.983
Each configuration as an output 
target and a physical camera ID.

05:43:11.238 --> 05:43:14.355
Now we create the capture 
session.

05:43:14.356 --> 05:43:17.727
How do we create the capture 
session using the new session 

05:43:18.995 --> 05:43:22.443
configuration object?
We start off with our list of 

05:43:23.118 --> 05:43:24.637
output configurations that we 
just created.

05:43:24.638 --> 05:43:29.261
With that, we instantiate 
assessing configuration, which 

05:43:29.543 --> 05:43:32.126
includes the capture session 
callback.

05:43:32.127 --> 05:43:36.021
From that callback, we are going
to give the instance of the 

05:43:36.403 --> 05:43:40.436
creative camera session.
We take that session 

05:43:40.766 --> 05:43:43.118
configuration object, and the 
camera device, which we got from

05:43:43.373 --> 05:43:46.909
a step number two when we opened
the logical camera, and we send 

05:43:46.910 --> 05:43:50.112
that framework to the request to
create a new session with the 

05:43:51.535 --> 05:43:54.995
desired configuration.
The callback provided in the 

05:43:54.996 --> 05:43:56.872
session configuration object 
will be triggered now, and then 

05:43:56.873 --> 05:44:01.859
we will have our camera session 
ready to be used.

05:44:01.860 --> 05:44:03.860
Last step, capture

05:44:05.964 --> 05:44:07.682
requests.
Once that has happened, we can 

05:44:07.683 --> 05:44:09.831
start getting frames out of the 
cameras.

05:44:09.832 --> 05:44:13.562
For example, you want to capture
a frame from two physical 

05:44:20.502 --> 05:44:24.322
cameras simultaneously.  We take
the session we created earlier 

05:44:24.323 --> 05:44:27.621
and the pair of output targets, 
and each is associated with a 

05:44:27.966 --> 05:44:30.389
specific camera ID.
We create a capture request that

05:44:31.299 --> 05:44:35.485
we don't normally do, in this 
case, we send to output preview.

05:44:35.970 --> 05:44:39.710
We attach the output targets to 
it that we normally do.  And now

05:44:39.711 --> 05:44:44.297
we dispatch the capture request,
nothing different here, except 

05:44:44.298 --> 05:44:47.696
in this case the output services
will receive image data from 

05:44:47.996 --> 05:44:50.816
each of the associated physical 
cameras and the capture request 

05:44:51.149 --> 05:44:56.627
callback will trigger only once.
So again, it is just like any 

05:44:56.628 --> 05:45:00.411
capture request, the big 
difference is that the 

05:45:00.563 --> 05:45:05.650
completion callback will give me
back two start exposure time 

05:45:05.992 --> 05:45:08.808
stamps instead of just a single 
value from normal capture 

05:45:10.623 --> 05:45:12.799
requests.
So to recap, this is how I 

05:45:12.800 --> 05:45:16.328
implemented the optical zoom 
demo.  We found the physical 

05:45:16.536 --> 05:45:19.445
cameras, we opened the logical 
camera that is part of the 

05:45:19.725 --> 05:45:23.853
group, we created the output 
configurations, we planted the 

05:45:23.854 --> 05:45:26.777
list, created the capture 
session, and then we distached 

05:45:26.778 --> 05:45:28.778
the capture

05:45:30.284 --> 05:45:32.570
requests.
One more topic I wanted to touch

05:45:32.956 --> 05:45:38.933
on is lens distortion.
A classical example of lens 

05:45:39.189 --> 05:45:43.043
distortion is the fish eye lens,
this is for illustration 

05:45:43.288 --> 05:45:48.208
purposes only.
All lenses have some amount of 

05:45:48.925 --> 05:45:55.025
disdistortion.  For logical 
cameras, that is minimal and 

05:45:55.684 --> 05:45:59.942
corrected by the drivers.  For 
physical cameras, the distortion

05:46:00.447 --> 05:46:03.185
can be significant.  The 
physical lens distortion is 

05:46:03.499 --> 05:46:09.225
described in a set of radial and
tangential coefficients, using 

05:46:10.550 --> 05:46:13.535
the lends distortion key.  The 
commentation has a lot more 

05:46:13.854 --> 05:46:15.854
details if you are interested.
The good news is that

05:46:18.815 --> 05:46:21.235
there's a way to correct 
distortion without doing a lot 

05:46:21.236 --> 05:46:24.476
of math, you can set the 
correction mode on a capture 

05:46:24.749 --> 05:46:28.817
request.  And off means that no 
distortion is applied.  

05:46:28.818 --> 05:46:34.834
We may need to use this if you 
want to do things like 

05:46:35.554 --> 05:46:40.353
synchronization, we may touch 
oon it later.  And fast meanses 

05:46:40.890 --> 05:46:44.130
the corrections are applied 
while meeting the target frame 

05:46:44.650 --> 05:46:46.650
rate.
High quality means that the 

05:46:46.727 --> 05:46:51.729
distortion is corrected as much 
as it allows, potentially at the

05:46:52.057 --> 05:46:58.430
cost of frame rate.  If we do 
not specify a correction mode, 

05:46:58.891 --> 05:47:01.707
it is fast or high quality, to 
the implementation details which

05:47:02.228 --> 05:47:06.914
is default.  You can see which 
is applied to your capture 

05:47:08.386 --> 05:47:11.665
request.  We will demonstrate 
how this is set to high quality,

05:47:12.004 --> 05:47:15.517
probably what we want for a 
still ImageCapture.

05:47:15.518 --> 05:47:20.597
Assuming that we are restoring 
the camera captureception, we 

05:47:21.621 --> 05:47:23.621
instang  

05:47:27.266 --> 05:47:30.437
instantiate it.  And then we 
determine if the high quality 

05:47:30.438 --> 05:47:33.745
distortion mode is available.
And now that we know that we 

05:47:33.746 --> 05:47:40.362
have high-quality correction for
the distortion, we settled on 

05:47:40.363 --> 05:47:43.826
the capture request, and we do 
what we always do, pass the 

05:47:44.094 --> 05:47:46.094
capture

05:47:51.939 --> 05:47:54.414
request.
For more sample code and 

05:47:54.686 --> 05:47:58.063
caconical details, take a look 
at the blog post.  We covered 

05:47:58.064 --> 05:48:01.535
this and some more, we posted 
earlier this week, and now we 

05:48:04.595 --> 05:48:10.700
will hand it over to Emilie. 
SPEAKER: Thanks, Oscar. 

05:48:15.828 --> 05:48:22.263
I'm emilie Roberts, and I will 
use this on

05:48:26.662 --> 05:48:31.729
the bokeh effect.  And the first
has no camera at all, I will 

05:48:31.730 --> 05:48:37.637
show the mechanisms for creating
the bokeh effect.  When you get 

05:48:37.638 --> 05:48:41.378
into the dual cam, we can focus 
on the multicamera aspects and 

05:48:41.379 --> 05:48:47.193
not worry about the bokeh 
effect.  It will be published, 

05:48:47.194 --> 05:48:50.019
open source, don't worry about 
scribbling too much code.  So 

05:48:50.020 --> 05:48:52.020
can we go to this

05:48:58.075 --> 05:49:01.944
phone?
Okay, so we have -- I didn't set

05:49:02.381 --> 05:49:04.381
this up properly.  We will do 

05:49:11.691 --> 05:49:16.387
the single cam bokeh effect, you
can see on the screen, cutting 

05:49:16.648 --> 05:49:19.847
me out, bump up the final 
result, it is pasting the 

05:49:20.166 --> 05:49:23.318
portrait mode in there.  This is
a rough cut portrait mode. And I

05:49:24.204 --> 05:49:30.045
have an optimization on this, 
let's see how that goes.

05:49:30.046 --> 05:49:34.206
I will show you the output steps
here.

05:49:34.207 --> 05:49:37.937
So it is trying to do a better 
job of finding the fore ground, 

05:49:37.938 --> 05:49:40.458
it didn't do too bad.  It is 
generating the fore ground 

05:49:40.459 --> 05:49:43.570
image, the background, which is 
just 

05:49:46.945 --> 05:49:49.409
let us down, pasting on the 
final result.

05:49:49.410 --> 05:49:51.410
So that is not too bad for a 

05:49:54.113 --> 05:49:59.689
single cam.
Let's try the dual cam demo.  

05:49:59.690 --> 05:50:02.596
With these stage lights, I'm not
sure.  C'mon.

05:50:02.597 --> 05:50:07.006
Hey, not too bad.  We are doing 
good.

05:50:07.007 --> 05:50:12.945
So you can see a depth map was 
created in the bottom left-hand 

05:50:13.399 --> 05:50:17.212
corner that is detecting me in 
the fore ground, and the rest of

05:50:17.476 --> 05:50:21.160
you are a little bit faded out, 
you can see that closer folks 

05:50:21.161 --> 05:50:24.464
are in gray and the black to the
back.  You can see the lights 

05:50:24.670 --> 05:50:27.284
wreaking havoc, I will show you 
the final result.  There's a few

05:50:27.846 --> 05:50:30.230
optimizations that can happen.  
But it is working pretty well.  

05:50:30.585 --> 05:50:34.234
So again, this is using the two 
front cameras on the pixel two. 

05:50:34.598 --> 05:50:36.598
You can see the two streams 
going at 

05:50:40.197 --> 05:50:45.250
once, oops.
Will this connect back up? Both 

05:50:45.529 --> 05:50:48.916
streams at once, the wide and 
the normal angle going at the 

05:50:48.917 --> 05:50:51.693
same time.  Can we head to the 
slides, please.  Let's talk 

05:50:51.973 --> 05:50:56.250
about how we do that, there we 
are.  So we had the normal 

05:50:56.501 --> 05:51:00.739
camera and the wide angle 
running at the same time.  We're

05:51:01.260 --> 05:51:05.479
going to publish this probably 
on GitHub, open source, so you 

05:51:05.875 --> 05:51:08.870
can dig into it and help 
optimize it and make it better. 

05:51:09.118 --> 05:51:13.936
So the single cam, the floating 
head bokeh effect I call it.  

05:51:14.118 --> 05:51:16.940
We're going to take a photo, 
face detect, two copies, we have

05:51:18.038 --> 05:51:21.654
background, fore ground, do 
fancy background effects, and 

05:51:22.344 --> 05:51:28.251
paste the floating head back 
where it belongs.  Face detect 

05:51:28.533 --> 05:51:32.943
is built into the camera 2 API, 
easy to implement.  We will 

05:51:32.944 --> 05:51:35.938
check the camera characteristics
to see if the camera supports 

05:51:36.391 --> 05:51:39.642
face detect.  If it does, you 
find the mode you want.  There 

05:51:39.643 --> 05:51:43.434
is off, and then simple, and 
full, depending on your camera 

05:51:44.382 --> 05:51:48.443
device.  And then when we make 
our camera capture request, we 

05:51:48.704 --> 05:51:52.926
will include that in the 
request.  When you get our 

05:51:53.196 --> 05:51:56.837
results, you can see if the mode
was set.  If you found any 

05:51:57.711 --> 05:52:00.503
faces, in this example, I 
searched for the first face that

05:52:00.504 --> 05:52:05.382
it finds is the one that I use. 
We can use this to expand 

05:52:05.766 --> 05:52:12.296
multiple faces.  And face detect
grabs the face.  So I bumped up 

05:52:12.687 --> 05:52:15.980
the bounds a little bit so it is
more of a head getting chopped 

05:52:16.456 --> 05:52:19.671
off, that sounds bad, a head 
pasted on to the background.

05:52:19.672 --> 05:52:24.552
And let's talk about the fun 
background effects.

05:52:26.272 --> 05:52:28.272
You can do what you want, using 

05:52:31.586 --> 05:52:35.568
render script, we did a blur.  
Because it is a multi-camera 

05:52:36.079 --> 05:52:39.637
talk, some have a zoom, you can 
do a background with another 

05:52:39.851 --> 05:52:44.110
camera and zoom it out of focus 
so you can do an optical blur 

05:52:44.111 --> 05:52:48.133
and save you the software step.
And in this demo, we did a 

05:52:49.285 --> 05:52:51.635
custom software sepia effect 
using render script.  If you are

05:52:51.780 --> 05:52:57.711
using multicam, a lot of cams 
have built in effects, like mono

05:52:58.408 --> 05:53:03.086
chrome that you can query and 
capture.  If you are not used 

05:53:03.262 --> 05:53:06.209
render script, it looks like 
this.  For the blur effect, we 

05:53:06.426 --> 05:53:11.431
care about the three middle 
lines and there's a built-in 

05:53:11.432 --> 05:53:15.875
script intrinsic blur, pretty 
handy, and it basically works 

05:53:16.140 --> 05:53:18.670
outside of the box.
In this case, it blurred outside

05:53:18.929 --> 05:53:23.063
of the box because the box is 
not blurry, ha.  This is a 

05:53:24.562 --> 05:53:27.406
custom render script script for 
the sepia effect.  You can see 

05:53:28.759 --> 05:53:32.511
in the first three lines, we are
taking the input red, green, and

05:53:32.912 --> 05:53:37.411
blue channels, muting the 
colors, making them yellow, and 

05:53:37.679 --> 05:53:40.720
setting those to the output 
channels.

05:53:40.721 --> 05:53:46.404
Okay, so we have the background,
a cool effect on it, what do we 

05:53:46.776 --> 05:53:51.849
do with the fore ground? We have
the face cut out and we apply 

05:53:52.572 --> 05:53:55.577
the border dev with the linear 
gradient so when we paste it, 

05:53:55.979 --> 05:53:59.817
there is not the harsh line.  
And ta-da, we paste it on, 

05:54:00.294 --> 05:54:03.241
things look pretty good.
There's a couple of 

05:54:03.622 --> 05:54:08.457
optimizations.  One you saw, 
which is with the grab Cut 

05:54:08.873 --> 05:54:12.188
algorithm, built into open CV, 
the computer vision library for 

05:54:12.189 --> 05:54:17.010
the depth map demo later on.  
And basically, I found the -- I 

05:54:17.901 --> 05:54:23.295
chose a rectangle a bit lang  
larger to guess where the body 

05:54:23.296 --> 05:54:28.953
might be, and then you have the 
magic wand tool in the photo 

05:54:29.103 --> 05:54:32.224
editor to shrink it down.  And 
then we can add in multiple 

05:54:32.393 --> 05:54:34.127
faces.
  Now, the moment you have all 

05:54:34.128 --> 05:54:38.432
been waiting for, we will talk 
about dual cam bokeh with the 

05:54:38.615 --> 05:54:41.732
depth map.  We're going to use 
two cameras simultaneously, and 

05:54:41.911 --> 05:54:46.157
we're going to create a depth 
mapmap, the hard part, which is 

05:54:46.158 --> 05:54:50.221
why I highlighted that in bold. 
We will use the same mechanism 

05:54:50.222 --> 05:54:53.879
we talked about.  How does this 
work? First of all, the double 

05:54:54.150 --> 05:55:01.268
capture.  So this, on the left, 
is me hanging out with my pets. 

05:55:01.269 --> 05:55:04.882
The left is the normal camera, 
the pixel 3, and the right is 

05:55:05.632 --> 05:55:08.974
the wide-angle shot.
To do that, just as Oscar one 

05:55:09.242 --> 05:55:12.363
walked through, we set up 
multiple output configurations. 

05:55:12.633 --> 05:55:16.918
For each lens, we set up, here, 
we have the preview surface and 

05:55:17.054 --> 05:55:21.314
the image reader for the normal 
lens.  We use set physical 

05:55:21.485 --> 05:55:24.747
camera ID to the normal lens and
we do the same thing for the 

05:55:25.337 --> 05:55:30.092
wide angle lens.  So we end up 
with four output configurations 

05:55:30.312 --> 05:55:32.312
we are putting into our con

05:55:35.818 --> 05:55:38.893
figeration.  From there, it is a
matter of choosing output 

05:55:39.157 --> 05:55:42.155
targets for the capture.  We 
want the photos, so we want the 

05:55:43.258 --> 05:55:46.757
image reader from the normal or 
wide-angle lens.

05:55:46.758 --> 05:55:50.525
Okay, so we have our images, and
now we have to do a bunch of 

05:55:50.526 --> 05:55:55.860
math and magic and make that 
boket effect happen.  I want to 

05:55:57.163 --> 05:55:59.781
give a brief introduction to 
stereo vision before we get into

05:56:00.077 --> 05:56:08.187
the code.  Looking at these 
slighted  slides y , I got 

05:56:08.900 --> 05:56:11.720
bored.  I like geometry, and I 
started asking, what does P 

05:56:11.968 --> 05:56:14.852
stand for, anyway? Obviously it 
is a pile of chocolate.  P 

05:56:15.566 --> 05:56:18.633
stands for pile of chocolate, 
this is what we are focusing on 

05:56:18.789 --> 05:56:22.096
for the rest of the demo.  And 
camera one is a little bit 

05:56:22.324 --> 05:56:25.916
boring, camera two.  So as here,
we are going to replace with a 

05:56:25.917 --> 05:56:30.533
character, this is my friend, 
pepper the shark, and this is 

05:56:30.992 --> 05:56:34.451
hippo, that are going to help us
talk about stereo vision.  So 

05:56:34.844 --> 05:56:40.945
left camera normal lens is 
pepper the shark, and right is 

05:56:41.394 --> 05:56:48.213
Suzie lou, the hippopotamus.  
And they are zeroing in on that 

05:56:48.470 --> 05:56:53.808
chocolate.  And the skewed 
rectangles there, the 2D 

05:56:53.963 --> 05:56:57.450
surface, the image that the 
cameras are going to capture.  

05:56:57.901 --> 05:57:02.902
The 2D representation of the 
real-live 3D object we have.  

05:57:03.432 --> 05:57:09.475
Let's look at what that look 
like.  The shark eye view is on 

05:57:12.734 --> 05:57:18.542
the almond, and the hippo is on 
the crunch.  They have this 2D 

05:57:18.543 --> 05:57:21.783
representation and we will take 
their separate views and combine

05:57:22.078 --> 05:57:24.855
them so we get a little more 
information than the 2D view and

05:57:25.157 --> 05:57:28.448
create a great depth map.  So we
have that, again, the normal 

05:57:28.449 --> 05:57:31.612
view, the wide-angle view, in 
this case, they are both normal.

05:57:31.873 --> 05:57:34.768
The left and the right hand, the
overlay on each other, and you 

05:57:34.980 --> 05:57:38.105
get that 3D ruler effect from 
elementary school that you hope 

05:57:38.394 --> 05:57:42.754
you got to enjoy as a child.
And, from there, we can create a

05:57:43.070 --> 05:57:47.217
depth map, which allows you to 
do really cool things, like 

05:57:48.099 --> 05:57:52.855
awesome bouket effects, know how
far away the chocolate is so you

05:57:53.115 --> 05:57:57.510
can reach out and grab it.
Okay, so those two cameras, 

05:57:57.511 --> 05:58:00.068
those two pictures are at a 
different orientation from each 

05:58:00.348 --> 05:58:04.954
other and they are separated in 
space.  So we need to get those 

05:58:04.955 --> 05:58:08.469
on top of each other.  This is 
what we call the camera 

05:58:08.663 --> 05:58:11.691
extrinsics, how the cameras 
relate to each other.  So we 

05:58:12.477 --> 05:58:15.380
need to rotate and translate the
images so they appear on top of 

05:58:16.001 --> 05:58:19.103
each other.  Normally we say -- 
we normally give the rotation 

05:58:19.514 --> 05:58:22.453
and translation parameters in 
camera in relation to world.  So

05:58:22.454 --> 05:58:25.825
instead of camera one to world, 
we will have shark to world, and

05:58:25.826 --> 05:58:29.818
hippo to world.  But when we are
doing stereo vision, we need to 

05:58:30.222 --> 05:58:35.405
worry about shark to hippo.  How
are the cameras related to each 

05:58:35.406 --> 05:58:41.099
other.  Like a good engineer, I 
need to switch helpo hippo to 

05:58:41.373 --> 05:58:45.597
world and I have a pathway, 
shark to world to hippo.

05:58:45.598 --> 05:58:48.406
You can see the math on 
Wikipedia, and it looks 

05:58:48.407 --> 05:58:53.108
something like this.  To get the
rotation matrix, we will reverse

05:58:53.529 --> 05:58:57.637
it for camera two and 
cross-multiply it with camera 

05:58:57.887 --> 05:59:01.583
one.  And we will take the inner
product and subtract.

05:59:01.584 --> 05:59:08.378
You can read all about it on 
Wikipedia or other sources.  If 

05:59:08.379 --> 05:59:12.688
you are working on this 
yourself, work on the 

05:59:13.645 --> 05:59:17.007
translation matrix from pixel 3 
from the normal to the wide 

05:59:17.199 --> 05:59:20.245
camera.  What do you notice 
about this? The 9 millimeter 

05:59:20.516 --> 05:59:23.314
separation between the cameras 
looks just about right.  If you 

05:59:23.579 --> 05:59:26.765
look at the phone, you know 
there's a good, what is the 

05:59:27.014 --> 05:59:31.889
American, a good -- anyway.  
There's a good nine millimeters 

05:59:32.738 --> 05:59:35.892
between those cameras, that 
makes sense.  What I didn't 

05:59:36.313 --> 05:59:39.976
notice, it cost me about a week 
of time, it is in the Y 

05:59:40.243 --> 05:59:44.795
coordinates.  The cameras are on
top of each other.  So while I'm

05:59:45.451 --> 05:59:49.799
working on this phone, looking 
at the cameras beside each 

05:59:50.075 --> 05:59:56.280
other, I assumed that they are 
horizontally displayed, but it 

05:59:56.560 --> 06:00:00.875
assumes that they are right next
to each other.  And camera 

06:00:01.306 --> 06:00:04.136
sensors are often optimized for 
landscape, which makes sense.  

06:00:04.588 --> 06:00:09.026
If you do it wrong, your depth 
maps don't work, you pull your 

06:00:09.627 --> 06:00:12.115
hair out and have a great week 
like I did.  Just a note when 

06:00:12.116 --> 06:00:15.847
implementing this.  So you have 
the camera extrinsics, how to 

06:00:15.848 --> 06:00:21.797
get the pictures from the camera
on top of each other.  

06:00:21.798 --> 06:00:24.068
Intrinsics are properties of the
cameras themselves.  We have a 

06:00:24.338 --> 06:00:26.605
normal and a wide angle lens and
they have different properties. 

06:00:26.871 --> 06:00:30.349
So there are two things, the 
camera characteristics, the 

06:00:30.732 --> 06:00:35.518
focal length, the principal 
access, if that is skewed, this 

06:00:35.787 --> 06:00:43.800
appears often in the three by 
three matrix, and distortion.  

06:00:44.061 --> 06:00:48.759
The lens, you are going to get a
little bit of distortion going 

06:00:48.760 --> 06:00:53.050
on that we need to consider as 
we are mapping the two images 

06:00:53.363 --> 06:00:58.985
together.  And another note, we 
will use the distortion 

06:00:59.210 --> 06:01:02.236
properties of the lens.  But the
camera undistorted it for

06:01:07.196 --> 06:01:11.689
you.  
We will undistort it and 

06:01:11.690 --> 06:01:14.528
redistort it, turn it off if you
want to do depth maps.  That is 

06:01:14.850 --> 06:01:19.134
easy for the request, make sure 
the distortion mode is off.  

06:01:19.461 --> 06:01:24.597
Okay, here are the four things. 
Rotation, translation, the 

06:01:25.509 --> 06:01:27.651
camera characteristics matrix 
and the lens distortion.  How do

06:01:28.034 --> 06:01:31.370
you get these properties? Easy. 
You take an afternoon, print out

06:01:31.901 --> 06:01:36.163
a checker board, has anyone done
this before? It is fun.

06:01:36.164 --> 06:01:40.546
Camera calibration.  Take a 
series of shots with both the 

06:01:40.818 --> 06:01:43.918
cameras, run a bunch of 
algorithms, figure out these 

06:01:44.222 --> 06:01:47.159
four camera characteristics and 
then you can start making depth 

06:01:47.456 --> 06:01:53.757
maps from the cameras.  You can 
tell from my cheerful face that 

06:01:54.203 --> 06:01:58.210
it is not that fun, don't do it,
it is no good.  Luckily in the 

06:01:58.694 --> 06:02:02.216
camera 2 multicamera APIs, we 
have these great fields: 

06:02:05.611 --> 06:02:07.611
Rotation, calibration, 
translation, and distortion.  

06:02:07.827 --> 06:02:12.169
You can get it out the API which
is wonderful.  If you are 

06:02:12.170 --> 06:02:14.894
implementing this yourself, so 
the camera characteristics, the 

06:02:15.255 --> 06:02:18.204
focal length, and the access 
information comes in five 

06:02:18.494 --> 06:02:21.285
parameters.  This is in the 
Android documentation.  But to 

06:02:22.087 --> 06:02:25.683
create that three by three 
matrix, you have to follow the 

06:02:26.075 --> 06:02:28.616
documentation and plugin the 
numbers.

06:02:28.617 --> 06:02:31.915
Another thing that might throw 
you off are the distortion 

06:02:32.399 --> 06:02:37.438
coefficients, the five values, 
and the open CB value library 

06:02:37.582 --> 06:02:40.758
uses them differently than out 
of the API.  You need to 

06:02:41.026 --> 06:02:47.412
remember it is 0-1, 342.  If you
use them in the 01234 order, 

06:02:48.481 --> 06:02:52.205
when you undistort your images, 
they lack like look like they 

06:02:52.488 --> 06:02:56.773
are in a whirl pool.  So there 
is something wrong with the 

06:02:57.095 --> 06:02:59.141
coefficients.
  After the parameters, we 

06:02:59.773 --> 06:03:03.272
prepare the images to do a depth
map comparison.  This is me in 

06:03:03.555 --> 06:03:08.487
my kitchen, yes or no if I don't
know if you can see, but from 

06:03:08.926 --> 06:03:14.027
the ceiling, there's a curve 
going down, the distortion 

06:03:14.270 --> 06:03:16.912
effects we are talking about 
with the distortion correction 

06:03:16.913 --> 06:03:22.881
off.  And when you are comparing
two images, the straight and 

06:03:23.288 --> 06:03:26.798
curved lines need to line up.  
We call that rectifying and we 

06:03:26.799 --> 06:03:28.799
use the camera characteristicses

06:03:31.924 --> 06:03:35.096
characteristicsesx to do that.  
All of the functions are in the 

06:03:35.798 --> 06:03:41.027
open CV library.  The first is 
stereo rectify, it gives a set 

06:03:42.427 --> 06:03:45.650
of parameters to define these 
calculations.  We pass in the 

06:03:46.061 --> 06:03:50.530
values we got from the API, the 
camera matrix, the distortion 

06:03:50.716 --> 06:03:53.409
coefficients, the rotation and 
translation that we calculated 

06:03:53.596 --> 06:03:58.239
before.  We get these parameters
out, we call undistort rectify 

06:03:58.424 --> 06:04:02.787
map, which gives us a map 
telling us how we can take two 

06:04:03.046 --> 06:04:06.223
images from these cameras and 
map them to each other.  And the

06:04:07.131 --> 06:04:10.060
remap function does just this.  
So lets see what that gives us. 

06:04:11.824 --> 06:04:17.798
.  On the left again, from the 
normal cam, front cam of the  

06:04:18.144 --> 06:04:23.628
the pixel three and the wide 
angle lens.  You can see that 

06:04:23.629 --> 06:04:28.918
the lines are lined up, the crop
is right, the roof lines, the 

06:04:28.919 --> 06:04:32.569
door lines are straight, there 
is no whacky distortion, from 

06:04:32.832 --> 06:04:35.285
where you are sitting, you 
probably have to look closely to

06:04:35.286 --> 06:04:38.292
notice that the left-hand 
picture is a little bit closer 

06:04:38.744 --> 06:04:41.421
to the left-hand side of the 
frame.  So there are actually --

06:04:41.689 --> 06:04:46.023
they are offset by a little bit 
which is what you would expect 

06:04:46.408 --> 06:04:49.508
if you had two cameras nine 
millimeters apart.

06:04:49.509 --> 06:04:53.113
So we have the images, we have 
undistorted it and rectified 

06:04:53.668 --> 06:04:56.903
them and we are close to 
creating the depth maps, we call

06:04:56.904 --> 06:05:02.691
the depth map function.  We use 
stereo BM, or stereo SGBM.  One 

06:05:02.692 --> 06:05:05.447
has a few more parameters than 
the other.  When you play with 

06:05:05.723 --> 06:05:08.449
the open source demo, you can 
see how these parameters work 

06:05:08.450 --> 06:05:12.031
and play around with it.
Optimize them.

06:05:12.032 --> 06:05:15.344
Commit your changes.
Help make that better.

06:05:15.345 --> 06:05:19.675
We call compute and make the 
step map.  When you do this, you

06:05:19.676 --> 06:05:22.850
get an amazing photo, something 
like this.

06:05:22.851 --> 06:05:26.730
And actually, sometimes it looks
a lot better than that.  This is

06:05:26.916 --> 06:05:30.511
not quite what we want to work 
with.  We want to filter that, 

06:05:31.075 --> 06:05:33.940
in this case, using the weighted
least squares filter, that 

06:05:34.257 --> 06:05:38.608
smooths it out and gives more 
useful depth map.  So the darker

06:05:39.270 --> 06:05:43.547
pixels are farther back, and the
whiter are the closer ones.  It 

06:05:43.548 --> 06:05:47.205
is hard to see, you can see the 
shark's snout and the hippo's 

06:05:47.360 --> 06:05:50.741
snout are a little bit grayed 
out, so it is actually working 

06:05:50.742 --> 06:05:53.881
to some extent there.  This is 
what we call the filter, it is 

06:05:53.882 --> 06:05:57.090
also included in the open CV 
libraries in the contributor 

06:05:57.558 --> 06:06:00.435
modules.  So it is all open 
source.

06:06:00.436 --> 06:06:02.436
And it is really cool when you 
get a depth map that

06:06:05.577 --> 06:06:07.971
isS per feck, it is 
exhilarating.  So here we have 

06:06:07.972 --> 06:06:11.762
the depth map.  
What do we do with it? We can 

06:06:11.978 --> 06:06:15.886
apply it as a mask on top of it,
and the black areas we want to 

06:06:16.170 --> 06:06:19.544
fade out and we want to 
highlight the fore ground.

06:06:19.545 --> 06:06:22.638
That is pretty easy to do with a
porter

06:06:26.755 --> 06:06:31.711
def, and the result is something
like this.

06:06:31.712 --> 06:06:37.520
So, Indeed, the fore ground is 
more present and the background 

06:06:38.282 --> 06:06:43.361
is faded out.  I have high 
standards, I see a translucent 

06:06:44.112 --> 06:06:47.595
floating shark over my shoulder,
my face is grayed out, my eye 

06:06:48.038 --> 06:06:53.199
ball is missing, I will put a 
red X through it, not quite good

06:06:53.661 --> 06:06:57.837
enough, but we want a depth map 
more like this.  We will put a 

06:06:58.168 --> 06:07:01.039
hard threshold on it and decide,
fore ground, background, that is

06:07:01.872 --> 06:07:07.018
it.  In either apps, you may 
want to do something similar, 

06:07:07.552 --> 06:07:10.429
but it could be a smoother 
curve.  To do that, we can use 

06:07:10.858 --> 06:07:15.486
the open CV function threshold.
We give it some cutoff value for

06:07:15.487 --> 06:07:21.202
the app, it is somewhere around 
80 to 140 out of 255, and that 

06:07:21.469 --> 06:07:25.488
is just that limit where 
something is considered fore 

06:07:25.890 --> 06:07:28.191
ground or background.  I wanted 
to note this in case you are 

06:07:28.501 --> 06:07:32.961
implementing any of this.  When 
we applied the mask, you need to

06:07:33.337 --> 06:07:35.337
turn the black pixles to

06:07:38.013 --> 06:07:40.013
transparent, this converts all 
of them to

06:07:45.731 --> 06:07:48.906
transparency.  We are almost 
there.  In the middle picture, 

06:07:48.907 --> 06:07:51.940
my eye is a bit blacked out.  
Just remember that for three 

06:07:51.941 --> 06:07:54.893
more slides or so.
So we have the initial picture, 

06:07:54.894 --> 06:08:00.843
we have the depth map, we do 
this hard threshold on it, and 

06:08:01.100 --> 06:08:03.372
we can again create our 
background just like we did in 

06:08:03.373 --> 06:08:08.299
the first demo, blur it out, 
mono, monoChrome it, and cut out

06:08:09.630 --> 06:08:13.373
that fore ground.  We have all 
the pieces we need to paste it 

06:08:13.374 --> 06:08:17.806
on.  This is our amazing, final 
portrait shot.

06:08:17.807 --> 06:08:20.608
Which -- that is pretty good.  
I'm proud of it.

06:08:20.609 --> 06:08:23.091
So we will talk about an 
optimization.  And remember the 

06:08:23.092 --> 06:08:27.840
eye ball thing I was talking 
about? So anything kind of 

06:08:28.857 --> 06:08:30.863
gleaming and shining can get 
messed up in this current 

06:08:31.087 --> 06:08:36.523
iteration of the application, or
bright lights can throw off the 

06:08:36.771 --> 06:08:39.590
depth map.  I did one 
optimization, we have the face 

06:08:39.591 --> 06:08:42.697
detect region.  I'm pretty sure 
I want the face in the fore 

06:08:42.964 --> 06:08:47.696
ground.  So I used it and cut it
out and said anything in the 

06:08:47.697 --> 06:08:51.801
face is going to be the fore 
ground.  So that protects it, 

06:08:52.302 --> 06:08:55.018
like my teeth and my eye from 
the masking out effect.

06:08:55.019 --> 06:09:00.805
I don't know if you noticed, we 
will go back, my fuzzy red hair 

06:09:01.075 --> 06:09:05.307
and the red couch, it kind of 
blended in.  So we can use grab 

06:09:05.696 --> 06:09:08.808
cut to do a little bit better 
job of figuring out exactly what

06:09:08.809 --> 06:09:12.870
is in the fore ground.
So thanks a lot, we really hope 

06:09:13.132 --> 06:09:17.270
that this gave you a deep dive 
into using camera 2 and the 

06:09:17.271 --> 06:09:22.808
multi-camera APIs, and gave you 
exciteg and creative ideas.  We 

06:09:22.809 --> 06:09:26.718
want to hear your ideas, see 
them in the apps, and know what 

06:09:27.040 --> 06:09:29.858
features you are looking for.  
We think they are great and we 

06:09:30.073 --> 06:09:33.257
want to keep pushing the camera 
ecosystem forward and keep doing

06:09:33.258 --> 06:09:36.462
more and more stuff 
ecosystem-wide.

06:09:36.463 --> 06:09:40.688
Thanks so much again and please 
do come to the camera sandbox if

06:09:40.689 --> 06:09:44.374
you want to ask us any 
questions, follow-ups, try this 

06:09:44.580 --> 06:09:48.694
app, see if it works, look 
forward soon to being open 

06:09:48.695 --> 06:09:50.695
source.  Thanks a lot.

06:09:53.319 --> 06:09:55.779
[ Applause ].
 SPEAKER: Now that leads us to 

06:09:56.503 --> 06:10:00.472
our final snack time of the 
summit.  We have coffee and 

06:10:01.069 --> 06:10:03.185
snacks and coffee and fruit and 
cheese and stuff like that for 

06:10:03.362 --> 06:10:07.879
you all.  But a few things I 
want said ed to call your 

06:10:08.175 --> 06:10:11.551
attention to, please rate the 
sessions so we have a QR code 

06:10:11.832 --> 06:10:14.875
that will come up here 
momentarily, they are 

06:10:15.171 --> 06:10:18.763
incredible.  The team is just 
amazing.  So this is how you 

06:10:18.764 --> 06:10:21.975
tell us how good of a job we 
have been doing.  Let us know 

06:10:21.976 --> 06:10:26.068
what you think of our speakers, 
our sessions, one other thing.  

06:10:26.292 --> 06:10:32.966
If youmissed sessions, all 
sessions from yesterday are 

06:10:33.315 --> 06:10:35.885
online, and by the end of today,
every single session from today 

06:10:36.140 --> 06:10:39.436
is going to be online.  So you 
can go home and binge watch all 

06:10:39.437 --> 06:10:41.929
of the things you didn't get to 
see.

06:10:41.930 --> 06:10:44.948
And, finally, come back and make
sure to come back.  We have 

06:10:45.293 --> 06:10:50.068
great sessions coming on later, 
and in both rooms, we are not 

06:10:50.069 --> 06:10:53.247
quite done yet.  And enjoy your 
snack break.

06:11:02.244 --> 06:11:04.244
[ Applause ] 

06:44:38.050 --> 06:44:40.470
SPEAKER: [ Applause ]. 
&gt;&gt;&gt; Hello, everyone.  Welcome to

06:44:40.738 --> 06:44:46.718
the deep dive into Android 
Studio profilers session.  I'm 

06:44:46.983 --> 06:44:50.935
David Herman SPEAKER: I'm 
Shukang Zhou.  We are developers

06:44:51.814 --> 06:44:54.374
in the Android Studio. 
SPEAKER: We wanted to guv you an

06:44:54.646 --> 06:44:58.094
outline of what to expect in 
this talk.  Instead of a high 

06:44:58.370 --> 06:45:01.484
overview, we will narrowly focus
on a few features that we think 

06:45:01.485 --> 06:45:08.286
can help you get a better handle
on any code base.  We will drop 

06:45:08.287 --> 06:45:11.338
some tips and tricks along the 
way.  We are going to be 

06:45:11.339 --> 06:45:15.219
profiling a real app, Santa 
Tracker.  It is an app by Google

06:45:16.438 --> 06:45:20.701
which allows users to track 
Santa on his course around the 

06:45:21.579 --> 06:45:27.436
world on Christmas Eve.  The app
also contains games and a couple

06:45:27.601 --> 06:45:32.971
of other extras.  We are -- they
release a new app every year.  

06:45:33.238 --> 06:45:35.548
We're using the one that is 
publicly available on GitHub.

06:45:35.935 --> 06:45:39.449
Finally, I want to mention two 
talks about profilers that are 

06:45:39.862 --> 06:45:42.717
previously given this year, one 
at Google I/O that did talk 

06:45:43.179 --> 06:45:48.608
about profilers at a higher lef,
also introducing what is new in 

06:45:48.891 --> 06:45:52.590
Android Studio o3.2, and the 
other at the Android gamedev 

06:45:52.862 --> 06:45:57.268
summit about profiling your game
.  That talk focuses on 

06:45:57.269 --> 06:46:02.302
performance, native code, 
related tools, things like that.

06:46:02.958 --> 06:46:08.902
You can find those vade  -- 
videos on YouTube.  If you are 

06:46:09.248 --> 06:46:12.072
watching this online, we 
included the links in the 

06:46:12.360 --> 06:46:14.901
description below.  If this is 
your first time coming and 

06:46:15.065 --> 06:46:18.442
learning about profilers, you 
are just curious, here's a quick

06:46:18.443 --> 06:46:21.832
overview.
The studio profilers feature is 

06:46:22.825 --> 06:46:26.950
divided into four main 
profilers, one for CPU, one for 

06:46:26.951 --> 06:46:29.744
memory, one for network, and one
for battery.

06:46:29.745 --> 06:46:33.200
There's also an event profiler 
that is on the top of -- that is

06:46:33.553 --> 06:46:37.110
always on the top, which lets 
you see things like user events,

06:46:37.385 --> 06:46:41.473
such as taps, keyboard events, 
screen rotations, and life cycle

06:46:42.100 --> 06:46:47.108
events.  So when your fragments 
and activities start and stop.  

06:46:47.490 --> 06:46:50.628
That's enough talking, let's 
jump into the demo. 

06:46:50.629 --> 06:46:53.977
SPEAKER: Okay.
Let's start the demo.

06:46:53.978 --> 06:46:57.719
So first, we want to click on 
this button.  I can launch the 

06:46:57.933 --> 06:47:00.813
app, and I will start the 
profilers.

06:47:00.814 --> 06:47:06.765
And so today, we are using 
Android Studio 3.4, canary 3, 

06:47:06.766 --> 06:47:11.202
because that's the latest 
version of what we have.

06:47:11.203 --> 06:47:17.375
Since the canary release is not 
a stable release yet, so there 

06:47:17.631 --> 06:47:22.514
might be some bugs, please bear 
with us if anything interesting 

06:47:22.786 --> 06:47:26.632
happens today.  The app we are 
using today, the Santa tracker, 

06:47:27.078 --> 06:47:30.477
contains only Java code.  So the
Java apps will be the focus of 

06:47:30.746 --> 06:47:38.879
today's talk.
So, as you can see, in the we 

06:47:38.880 --> 06:47:40.880
have four

06:47:43.095 --> 06:47:47.697
profilers: CPU and energy.  You 
can click on any one of them to 

06:47:47.698 --> 06:47:50.380
get more data.  
We will jump to the CPU 

06:47:50.962 --> 06:47:55.656
profiler.  Here, as you can see,
in the CPU profiler, you can see

06:47:55.922 --> 06:48:01.510
the CPU utilization and the 
thread state.  They are useful 

06:48:01.902 --> 06:48:06.698
to tell you when your app 
becomes CPU bundled.

06:48:06.699 --> 06:48:11.383
And if you are examining two 
related threads, one trick is 

06:48:11.384 --> 06:48:13.934
here, you can reorder the 
threads any way

06:48:17.566 --> 06:48:21.702
you want.
To know further data information

06:48:21.973 --> 06:48:26.281
about which path of your code is
executing or how they are 

06:48:26.673 --> 06:48:31.625
executing, you need CPU 
recordings.

06:48:31.626 --> 06:48:38.178
And let me get a little bit more
space.  So, as you can see here,

06:48:38.179 --> 06:48:41.633
there are four types of CPU 
recordings.  So we will go to 

06:48:41.634 --> 06:48:45.026
the first one, called Java 
methods.  We will get a quick 

06:48:45.309 --> 06:48:50.712
recording of this one.
So during this type of CPU 

06:48:51.107 --> 06:48:57.142
recording, the Java virtual 
machine is theoretically we 

06:48:57.685 --> 06:49:00.292
collect the core stacks of all 
the Java threads in your 

06:49:00.880 --> 06:49:05.419
process.
And then it will present the 

06:49:05.690 --> 06:49:09.320
stacks in the -- in this part, 
which we called the recording 

06:49:09.688 --> 06:49:12.571
details -- the details of the 
recording.

06:49:12.572 --> 06:49:16.628
And, after the recording is 
done, the entire recording is 

06:49:18.537 --> 06:49:23.032
automatically selected and if 
unit to  -- you want to take a 

06:49:23.295 --> 06:49:26.773
closer look, there's a button 
called zoom tool selection.

06:49:26.774 --> 06:49:30.690
So if I click on it, it will 
fill the entire screen.  And if 

06:49:31.862 --> 06:49:37.208
you want to just see a sub range
of the recording, you can select

06:49:37.209 --> 06:49:40.579
using the mouse.  If you want to
select the entire recording, you

06:49:40.844 --> 06:49:44.607
can click on this small clock 
icon here.

06:49:44.608 --> 06:49:46.608
And,

06:49:50.313 --> 06:49:53.619
a very specific point.  In that 
case, you can do a single click 

06:49:53.620 --> 06:49:55.620
in this area and you can 
automatically select something 

06:49:55.826 --> 06:49:59.540
here.
Now let's take a look at the 

06:50:00.014 --> 06:50:05.191
call stacks here, and let's 
select this range that might be 

06:50:05.512 --> 06:50:11.397
more interesting.
So, as you can see, the profiler

06:50:11.659 --> 06:50:16.214
will color the cost from the 
Android platform in orange, the 

06:50:16.704 --> 06:50:22.535
method from the Java language in
plu,- blue, and it will color 

06:50:22.724 --> 06:50:26.372
any of your code in the library 
to green.  So if you want to 

06:50:26.373 --> 06:50:30.174
know what method from your code 
is running, you will be looking 

06:50:30.321 --> 06:50:34.412
for the green stuff.  So here we
see some green stuff here and 

06:50:35.250 --> 06:50:40.526
here, you can see, this is an 
on-call method from the village 

06:50:40.527 --> 06:50:45.762
view class.  And if it is not --
if you see the code base, you 

06:50:47.200 --> 06:50:50.579
can easily see the shield is 
responsible to draw the cloud 

06:50:50.850 --> 06:50:52.850
that is on this 

06:50:56.918 --> 06:50:58.386
screen.
So another thing I want to talk 

06:50:58.387 --> 06:51:05.861
about the sampling is you can do
some justm customization about 

06:51:05.862 --> 06:51:07.862
the recording time.  You can 
click the edit configuration

06:51:11.787 --> 06:51:17.226
entry, you can create the 
customized CPU configuration.  

06:51:17.227 --> 06:51:19.227
For this Java method recording 
type,

06:51:23.184 --> 06:51:28.259
rue can change the inter  
intervales.  The more quickly 

06:51:28.527 --> 06:51:32.190
you select samples, the more 
quickly the data will be 

06:51:32.191 --> 06:51:37.243
represent said ed to you.  That 
will incur more overicide. Head.

06:51:37.916 --> 06:51:41.406
Depending on the use case, you 
want several tries until you 

06:51:41.634 --> 06:51:45.791
find the sweet shot.  As we have
seen, the sample Java method is 

06:51:46.052 --> 06:51:50.876
very useful to get a very 
high-level picture of which part

06:51:50.877 --> 06:51:54.614
of the code it is running.  In 
some other scenarios, if you 

06:51:54.615 --> 06:52:00.178
want to focus on a smaller area,
the second type of the 

06:52:00.510 --> 06:52:04.141
recording, trace Java method, 
will be more interesting.

06:52:04.142 --> 06:52:06.142
So let

06:52:08.505 --> 06:52:13.106
me collect another trace.
So in this type of CPU 

06:52:13.466 --> 06:52:19.301
recording, the Java virtual 
machine is selecting the  -- 

06:52:19.820 --> 06:52:24.280
collecting the data every time 
it executes a method.  So 

06:52:24.545 --> 06:52:27.370
there's a lot more data being 

06:52:34.883 --> 06:52:37.556
collected.
And so I wanted to understand 

06:52:37.956 --> 06:52:41.831
what method from my code is 
running, then you wanted to look

06:52:42.318 --> 06:52:46.939
for the screen stuff here.  You 
can see that there's a lot of 

06:52:47.153 --> 06:52:52.737
things, you want to zoom in.  
You can use the WAS keys to zoom

06:52:53.894 --> 06:52:58.328
in.  So the W is the zoom in, 
you can see with the key I'm 

06:52:58.549 --> 06:53:01.712
pressing.  The S is zoom out, 
the D is moving to the right, 

06:53:02.022 --> 06:53:05.162
and A is moving to the left.
So if you are gamer, you 

06:53:05.462 --> 06:53:15.161
probably know this.
So if you zoom in, let's see 

06:53:15.992 --> 06:53:20.567
what are the green stuff.
So a big one is the one that we 

06:53:20.856 --> 06:53:25.196
just saw observe, the methods 
from the village view.  And they

06:53:25.455 --> 06:53:30.364
are responsible for drawing the 
clouds.  And here is the method 

06:53:31.491 --> 06:53:35.140
from the snowflake view class, 
they are responsible to draw all

06:53:35.423 --> 06:53:39.589
of the snow flakes that are 
floating around.  If you look 

06:53:39.979 --> 06:53:43.162
closely, there are many tiny 
green lines here.

06:53:43.163 --> 06:53:49.001
So you can further zoom in, you 
can further zoom in, you can see

06:53:49.272 --> 06:53:52.980
-- I will zoom in.
So you can see that this is the 

06:53:53.633 --> 06:53:56.914
method from the snowflake class,
and this is also from the snow 

06:53:56.915 --> 06:54:02.712
flake class, this is also from 
the snow flake class.  So let

06:54:05.141 --> 06:54:07.141
let's -- you may

06:54:09.551 --> 06:54:14.974
want to see what data  source 
this goes.  So you can jump to 

06:54:14.975 --> 06:54:18.419
the source code.
You can see in the snow flake 

06:54:18.420 --> 06:54:23.193
class, on this method, we are 
doing some calculation about the

06:54:23.194 --> 06:54:31.050
velocity about the angle, about 
the size, and then we draw and 

06:54:31.826 --> 06:54:34.860
it is very clear that every line
of this screen will execute the 

06:54:35.043 --> 06:54:40.725
method.  That is why we are 
seeing so many calls into this 

06:54:44.957 --> 06:54:47.099
method.
So ass as

06:54:50.768 --> 06:54:57.969
So ass as you can se you can 
see, you can see what is 

06:54:57.970 --> 06:55:01.452
executed and how often it is 
executed.

06:55:01.453 --> 06:55:03.633
And another thing I want to talk

06:55:07.755 --> 06:55:12.622
about here is the chats here.  
The first is the call chat, that

06:55:12.623 --> 06:55:17.324
is representing all of the call 
stacks during the CPU recording.

06:55:17.597 --> 06:55:22.532
So it is -- the things to the 
left, well, we will select the 

06:55:22.533 --> 06:55:26.999
entire range so you can see.
So the call stacks on the left, 

06:55:27.410 --> 06:55:29.535
it is what happens first in this
recording.  So the things to the

06:55:30.467 --> 06:55:34.369
right, they will happen later in
this recording.  In the frame 

06:55:34.627 --> 06:55:38.947
chart, it is similar to the call
stack, but it is upside down.  

06:55:38.948 --> 06:55:43.580
So the root is on the bottom, 
and also, identify call stacks 

06:55:43.866 --> 06:55:49.277
aggregated here.
So it is very easy to see the 

06:55:49.481 --> 06:55:51.679
total time the method has been 
executed.  The

06:55:56.429 --> 06:56:01.595
top-down, it has exactly the 
same data as the frame chart.  

06:56:01.596 --> 06:56:03.310
It is just represented in a 
different view.

06:56:03.311 --> 06:56:06.901
What is nice about this view is 
you can sort these methods by 

06:56:06.902 --> 06:56:11.996
the time.  So the sales time is 
the sime executing by this 

06:56:12.424 --> 06:56:16.601
method itself, the children is 
executed by the sub routines 

06:56:16.731 --> 06:56:21.687
called by this method, and the 
total time is a combination of 

06:56:21.688 --> 06:56:26.852
the two.
Bottom-up is looking at the call

06:56:28.576 --> 06:56:32.115
stack upwards to the caller, 
basically from the method to 

06:56:32.373 --> 06:56:34.373
another 

06:56:39.102 --> 06:56:43.182
function, to that call. 
So you can see it is very useful

06:56:43.183 --> 06:56:47.653
to see where this method is 
called and how much time this 

06:56:47.916 --> 06:56:54.269
method has executed when it is 
called by that specific color.

06:56:54.661 --> 06:56:56.706
And there is a third type of CPU

06:57:01.600 --> 06:57:07.776
recording that is called related
functions, C or C++ functions.  

06:57:07.777 --> 06:57:10.652
We will do another trace here.  
And if you remember, I just said

06:57:11.073 --> 06:57:15.838
that this app, the Santa 
tracker, it contains Java, only 

06:57:15.839 --> 06:57:20.413
code.  So therefore the call 
stacks, assuming it is corrected

06:57:20.671 --> 06:57:26.371
by this type of recording, it is
not very interesting.  They are 

06:57:26.615 --> 06:57:30.728
mostly the system calls, and 
some of them are in the Android 

06:57:31.427 --> 06:57:36.162
framework native code.  If your 
app has any native components, 

06:57:36.649 --> 06:57:39.999
this type of recording will be 
very handy.

06:57:40.000 --> 06:57:44.324
There is another type of CPU 
recording called trace system 

06:57:44.325 --> 06:57:48.613
cost, and before I go into the 
details of that, I will head 

06:57:48.890 --> 06:57:50.890
back the

06:57:53.846 --> 06:57:56.547
demo back to Dave. 
SPEAKER: CPU recordings are very

06:57:57.380 --> 06:57:59.380
useful.  Sometimes there's an 
exact function, or maybe a 

06:58:00.065 --> 06:58:05.411
couple ofphic  functions you 
want to analyze and it is a 

06:58:06.218 --> 06:58:09.399
little bit imprecise to record, 
do something in the app, stop 

06:58:10.047 --> 06:58:12.761
recording and zoom and search 
for it.  We provide a very 

06:58:13.047 --> 06:58:15.047
simple solution for

06:58:16.331 --> 06:58:20.275
this.  And I added the code in. 
So we will talk about it.  The 

06:58:20.276 --> 06:58:23.575
debug class is a part of the 
Android API, and the debug class

06:58:23.939 --> 06:58:27.743
and many of it's methods have 
been in the Android API since 

06:58:27.744 --> 06:58:30.409
the first version, including 
these two.  

06:58:30.410 --> 06:58:34.818
What the start tracing method 
function does is it asks the 

06:58:34.819 --> 06:58:39.010
system to take a trace, save it 
with the file name, and it saves

06:58:39.143 --> 06:58:44.877
it later so you can pull it up 
on the device later.  We will do

06:58:44.878 --> 06:58:47.711
all of that work for you.
So if you are doing this 

06:58:47.966 --> 06:58:50.662
manually, you probably would be 
very careful about the name that

06:58:50.857 --> 06:58:54.543
you chose, if you are doing 
multiple chases, you would 

06:58:54.544 --> 06:58:57.288
choose unique names so they 
didn't override each other.  In 

06:58:57.289 --> 06:59:03.847
our case, the name is not going 
to show up in studio, so call it

06:59:05.204 --> 06:59:08.345
CHARFBT  whatever you want.  I 
will put a recording around the 

06:59:08.623 --> 06:59:11.544
function.  So in this case, 
there's an activity in the Santa

06:59:12.206 --> 06:59:16.624
Tracker, the CD quiz which loads
files from the disk.  That's 

06:59:17.578 --> 06:59:21.772
really good if you want to know 
how long it is going to take, if

06:59:22.365 --> 06:59:25.253
it is suspicious, we want to 
take a look.  When you call the 

06:59:25.732 --> 06:59:28.558
start method tracing function, 
it is going it to do a trace of 

06:59:28.837 --> 06:59:32.737
your code.  This more expensive,
precise detailed one.  I would 

06:59:32.995 --> 06:59:37.046
be careful, I wouldn't do this 
around a large amount of code, 

06:59:37.317 --> 06:59:41.622
just to make sure it doesn't 
take longer than you would which

06:59:41.623 --> 06:59:45.231
is down here.  We willexpect.
We will go to the city quiz,  

06:59:45.232 --> 06:59:47.875
see what happens.  Before I do 
this, I want you to keep your 

06:59:47.876 --> 06:59:51.179
eye over here in the session 
panel.  I will hit play.

06:59:51.180 --> 06:59:55.751
It is going to run in, it is 
automatically recorded, you 

06:59:56.022 --> 06:59:59.834
don't have to do anything, that 
is awesome.  Let me back utout. 

07:00:00.598 --> 07:00:03.577
As you can see here, there is 
nothing new. 

07:00:08.187 --> 07:00:10.662
This is what Shukang was showing
you before. 

07:00:10.663 --> 07:00:13.229
And I think this is a good 
moment to call out the life 

07:00:13.511 --> 07:00:16.406
cycle events I talked about in 
the beginning of the talk.  As 

07:00:16.703 --> 07:00:20.840
you can see, we are doing a load
here.  We left the previous 

07:00:21.291 --> 07:00:24.324
activity and we are into a new 
activity.  If you put your mouse

07:00:24.508 --> 07:00:30.447
over an activity, as of Android 
Studio 3.3, we will include the 

07:00:31.209 --> 07:00:34.442
fragments that are active during
that time.  That may be useful 

07:00:34.737 --> 07:00:37.745
for you.  But we are in this 
space where we are loading 

07:00:37.746 --> 07:00:41.302
before we entered the activity. 
And there's another really great

07:00:41.303 --> 07:00:44.842
feature I want to show you here,
this filter button.  When I 

07:00:44.843 --> 07:00:48.352
press the filter button, it 
brings up a search box, what I 

07:00:48.682 --> 07:00:52.860
type into it.  And I happen to 
know that JSON has a function 

07:00:53.188 --> 07:00:55.908
called read literal, let me type
that in.  And one thing you 

07:00:56.286 --> 07:01:00.354
might notice here is that part 
of my call chart dimmed out.  

07:01:00.869 --> 07:01:03.771
And all parts of here are not 
dimmed, they are the normal 

07:01:03.772 --> 07:01:06.832
color.  I will zoom in and find 
where that is.  So you can see 

07:01:07.143 --> 07:01:10.065
instances of the read literal 
function.  And basically, if my 

07:01:10.531 --> 07:01:13.456
function is an exact match, it 
will bold.  If it is a function 

07:01:14.020 --> 07:01:16.468
that calls either into that 
function or is called out of 

07:01:16.469 --> 07:01:19.198
that function indirectly, the 
color will be left the same, and

07:01:19.954 --> 07:01:23.312
otherwise it will dim.  And it 
is really useful to sort of get 

07:01:23.885 --> 07:01:26.599
a good overview of how much time
you are spending in your code on

07:01:26.864 --> 07:01:29.440
the function that you care about
versus what you don't have to 

07:01:30.073 --> 07:01:34.102
pay attention to.  All of the 
CPU detail views support this.  

07:01:34.387 --> 07:01:38.026
So the flame chart has the 
similar dimming, the top will 

07:01:38.243 --> 07:01:40.945
strip out the functions that 
were dimmed.  If you are trying 

07:01:41.218 --> 07:01:44.156
to inspect some sort of method 
and you are narrowing down on 

07:01:44.642 --> 07:01:47.802
it, please give the filter 
option a try and see if you can 

07:01:48.281 --> 07:01:50.346
sort of focus on what you are 
looking at. And the last thing 

07:01:51.286 --> 07:01:53.709
to call attention to here is all
of the traces that you have 

07:01:53.977 --> 07:01:58.065
done, if you mouse over them, 
there's a save button here, so 

07:01:58.276 --> 07:02:01.212
you can export your traces.  If 
you do this, you can give it to 

07:02:02.089 --> 07:02:05.511
a co-worker, attach it to a bug,
useful things like that.  If 

07:02:05.900 --> 07:02:10.378
someone gives you a trace file 
or you are loading it, you can 

07:02:10.936 --> 07:02:14.837
hit the plus button over here 
and load it from file.  Okay, 

07:02:15.615 --> 07:02:18.568
cool.  
SPEAKER: So now I'm going to 

07:02:18.569 --> 07:02:23.200
talk about the last type of CPU 
recording, the trace system 

07:02:23.201 --> 07:02:28.936
cost.  And the trace system 
cost, this feature was 

07:02:30.268 --> 07:02:34.833
introduced in Android Studio 
3.2.  It collects fine-grain 

07:02:35.132 --> 07:02:38.261
system events related to app 
performance so you can 

07:02:38.619 --> 07:02:40.820
investigate how your app 
interacts with the system 

07:02:42.607 --> 07:02:44.607
resource.

07:02:46.071 --> 07:02:48.071
So let's create the system

07:02:56.691 --> 07:02:58.691
trace.
So I'm using the click to zoom 

07:02:58.911 --> 07:03:02.377
button here, it is easy to see. 
And one thing I want to show you

07:03:02.641 --> 07:03:07.610
here, the first thing I want to 
show you is in this thread state

07:03:08.146 --> 07:03:10.146
view.  If you

07:03:11.789 --> 07:03:16.503
click the range, I will zoom to 
that collection again.  I will 

07:03:16.504 --> 07:03:20.009
click here.
So here, as you can see, you can

07:03:20.269 --> 07:03:24.453
use your mouse, you can hover 
over and see this thread space. 

07:03:27.425 --> 07:03:33.234
It is running, and it is runable
and running again.  We are 

07:03:33.677 --> 07:03:38.832
collecting every CPU scheduling 
operation.  At these levels of 

07:03:40.286 --> 07:03:43.326
details, it is easy for you to 
figure out where your thread 

07:03:43.499 --> 07:03:47.285
becomes blocked.  And that could
be useful if you have some 

07:03:47.987 --> 07:03:50.565
threading issues.
And another thing that I want to

07:03:51.354 --> 07:04:00.330
show using the trace system 
calls is to investigate slow UI 

07:04:00.331 --> 07:04:03.441
chunk.
So slow UI rendering, also 

07:04:03.442 --> 07:04:09.606
called Jenk by some people.  As 
you may know, that's the UI, the

07:04:09.607 --> 07:04:14.126
Android UI, it does the work in 
two phases: The first phase 

07:04:14.465 --> 07:04:18.053
happens in the main thread.  It 
determines what is on the 

07:04:18.232 --> 07:04:20.232
screen, including the

07:04:22.992 --> 07:04:27.348
layout and the source.  It 
executes all of the UI elements,

07:04:27.819 --> 07:04:30.921
such as all of the view classes 
in your app.

07:04:30.922 --> 07:04:34.346
So after the main thread 
generates the what, they are 

07:04:34.574 --> 07:04:39.085
passed to the native render 
thread.  The render thread will 

07:04:39.086 --> 07:04:44.539
be figured out how to draw them.
And then the how is passed to 

07:04:45.139 --> 07:04:49.156
the surface finger system 
process, and the hardware that 

07:04:49.361 --> 07:04:51.355
is actually performing the 
joins.

07:04:51.356 --> 07:04:54.863
So that is giving that 
background, so you can see under

07:04:55.795 --> 07:05:01.590
the frame area, we have -- if 
you pronounce the main thread, 

07:05:02.925 --> 07:05:07.604
the render is the render thread.
So let me zoom out a little bit.

07:05:08.660 --> 07:05:14.487
So you can see here this -- this
the first phase, and 

07:05:14.800 --> 07:05:18.866
corresponding the second phase 
will be here.

07:05:18.867 --> 07:05:26.235
If you are targeting a smooth 
UI, the smooth animation at 60 

07:05:26.524 --> 07:05:31.989
frames per second, which is 16 
milliseconds, roughly 16 

07:05:32.807 --> 07:05:35.986
milliseconds per frame.  The two
phases combine together should 

07:05:36.303 --> 07:05:39.993
be under 16 frames.  If it is 
longer than that, then the 

07:05:39.994 --> 07:05:46.226
profiler will color that frame. 
So, you know, this is something 

07:05:47.512 --> 07:05:50.725
--.
  So if you zoom out more, you 

07:05:50.871 --> 07:05:53.851
can see a lot of frames, I think
that

07:05:57.712 --> 07:06:03.393
everyone today is red, so 
exceeding the 16MS threshold.

07:06:03.624 --> 07:06:07.790
One factor is that we are using 
the emulator.  Because the way 

07:06:08.111 --> 07:06:12.319
the emulator interarcts with the
system, you are going to see 

07:06:12.320 --> 07:06:20.418
more red frames from the actual 
device.  Before today's talk, I 

07:06:23.019 --> 07:06:25.200
have collected another trace 
using a physical device.  I have

07:06:25.687 --> 07:06:28.900
exported that trace as a file.  
And now I want to import that 

07:06:29.154 --> 07:06:33.211
trace to show you.
So, as Dave said before, we can 

07:06:33.587 --> 07:06:35.587
use this to import

07:06:42.907 --> 07:06:49.417
the trace.  
And because when you trace the 

07:06:49.418 --> 07:06:53.728
system course, you need to tell 
the profiler which process you 

07:06:54.070 --> 07:06:57.865
want to look at.  So if you want
to look at the static tracker, 

07:06:58.220 --> 07:07:01.899
as you know, the Linux from the 
system point of view, every 

07:07:03.291 --> 07:07:08.016
process or every thread that 
your name is no longer than 15 

07:07:08.975 --> 07:07:13.399
characters.  That is why this is
the Santa tracker.debug, for 

07:07:13.400 --> 07:07:16.332
some reason, it thinks this is a
name.  If you select this one, 

07:07:16.642 --> 07:07:19.138
you are going to import this 
trace.  And here, you can see 

07:07:19.139 --> 07:07:23.078
from the actual device, most of 
the frames will be in gray, and 

07:07:23.862 --> 07:07:28.100
that indicates they under 16MS 
threshold.  Some of the frames 

07:07:28.397 --> 07:07:30.397
are in the red, because they are
over

07:07:35.535 --> 07:07:39.590
that threshold.
And you may wonder how does the 

07:07:39.591 --> 07:07:43.307
system or the profiler know how 
long the phases are taking.  

07:07:43.308 --> 07:07:48.300
That is from the trace in point.
So Android platform engineers 

07:07:48.677 --> 07:07:52.878
have added building tracing 
points into the sum of the 

07:07:53.272 --> 07:07:56.663
critical tasks in Android 
system.

07:07:56.664 --> 07:08:01.046
So, I mean, the example here is 
if you click the main thread 

07:08:01.322 --> 07:08:05.610
here, these events are showing 
from the trace events here.

07:08:05.611 --> 07:08:07.611
So if I zoom

07:08:09.859 --> 07:08:17.771
in here, you will see this -- 
theseeral trace event called 

07:08:17.772 --> 07:08:21.259
choreographer two frame.  That's
the first phase in the UI 

07:08:21.512 --> 07:08:23.838
rendering, it happens in the 
main thread.  If you click the 

07:08:23.839 --> 07:08:29.510
render thread, you can see there
that it is called a jaw frame.  

07:08:29.511 --> 07:08:32.838
That is the second phase.  You 
can see that there are other 

07:08:32.839 --> 07:08:38.053
tracing points in the system.  
They are all built in the 

07:08:38.054 --> 07:08:42.855
system, they are available on 
any Android phones because they 

07:08:42.856 --> 07:08:46.400
are building.  They are useful 
to get timing information for 

07:08:46.401 --> 07:08:49.969
specific tasks, and actually you
can have your own trace point, 

07:08:49.970 --> 07:08:57.966
too.  I'm going to demo that 
here.  So today, here, if we go 

07:08:57.967 --> 07:09:03.265
to the top of the app, we have 
the cloud, we have the snow 

07:09:03.266 --> 07:09:08.772
flakes.  I want to know how long
my code is spent drawing them.

07:09:09.000 --> 07:09:11.753
So for the cloud, I go to the 

07:09:15.749 --> 07:09:19.967
village view.
So there should be an on draw 

07:09:20.239 --> 07:09:24.203
method.  So at the beginning of 
the method, I add the 

07:09:25.838 --> 07:09:27.838
instrumentation, the trace

07:09:29.360 --> 07:09:33.081
begin section, you need a 
stream.  And at the end of the 

07:09:33.348 --> 07:09:41.973
method, we end the trace event. 
For the snow flock  flakes, it 

07:09:41.974 --> 07:09:45.901
goes to the view, the on draw 
method.  I want to point out the

07:09:46.169 --> 07:09:51.023
section name, you should pick a 
name that makes sense to you so 

07:09:51.024 --> 07:09:55.755
you can recognize when you are 
doing the CPU recording.  Here, 

07:09:55.756 --> 07:10:00.633
we are doing the snow flake, 
Android summit 2018.  That makes

07:10:01.041 --> 07:10:06.183
sense for today's demo.
And so now, I will add the 

07:10:06.619 --> 07:10:13.064
manual instrumentation as we 
view this app and reprofile it.

07:10:13.257 --> 07:10:17.289
So while we are waiting for the 
build, you may be wondering, if 

07:10:17.723 --> 07:10:24.811
I want to know how long those 
two methods are taking, use the 

07:10:25.730 --> 07:10:28.752
trace Java methods.  That's what
we were talking about moments 

07:10:30.182 --> 07:10:32.182
ago.
So trace Java method is very 

07:10:32.348 --> 07:10:37.559
powerful, it is very easy to 
use, but it has significant 

07:10:37.900 --> 07:10:41.321
overhead because the Java 
virtual machine is collecting 

07:10:41.602 --> 07:10:44.747
data, every time when the 
execution enters the method and 

07:10:44.999 --> 07:10:49.271
every time when the execution 
acts on the methods.  So if you 

07:10:49.786 --> 07:10:54.159
have a lot of frequent, small 
methods, that overhead can 

07:10:54.445 --> 07:10:58.515
quickly add up and become very 
expensive.  If you use the 

07:10:58.728 --> 07:11:01.946
manual instrumentation, for 
example, like the trace -- using

07:11:02.193 --> 07:11:06.927
the trace API, you will have the
full console of where and when 

07:11:06.928 --> 07:11:11.718
to collect data.
So if you use that wisely, the 

07:11:11.719 --> 07:11:16.574
overhead will be much smaller 
and, as a result, the data you 

07:11:17.767 --> 07:11:21.244
cleck  collected will be more 
accurate.  So let's verify the 

07:11:21.515 --> 07:11:27.790
instrumentation you have.  You 
go to the CPU profiler.  We 

07:11:28.579 --> 07:11:30.579
collect the trace

07:11:37.803 --> 07:11:43.285
system calls.
And so here, this is the view 

07:11:43.701 --> 07:11:46.586
thread that is responsible for 
all UI elements.  And if

07:11:55.134 --> 07:11:59.255
you keep zooming, you can see 
the village view, who is joining

07:11:59.814 --> 07:12:01.814
the clouds, and this is a

07:12:08.501 --> 07:12:13.807
snowflake -- what is responsible
for drawing the snow flakes.  

07:12:14.791 --> 07:12:19.242
This is the trace system called 
CPU recording.  You may hear a 

07:12:19.243 --> 07:12:25.557
very similar tool, sis trace.  
And my Google co-worker gave a 

07:12:26.330 --> 07:12:28.378
lightning talk yesterday on the 
sis trace.  So it is an 

07:12:28.659 --> 07:12:33.766
extremely powerful tool, but the
learning curve of the sis trace 

07:12:33.767 --> 07:12:37.767
is a little bit steeper than the
Android Studio profiler.  So you

07:12:38.065 --> 07:12:40.774
may choose the tools that best

07:12:44.682 --> 07:12:48.361
suits your needs.  So I will 
hand over the demo back to 

07:12:49.329 --> 07:12:50.854
David.  
SPEAKER: All right.

07:12:50.855 --> 07:12:54.498
So let's leave the CPU profiler 
behind and jump over to the 

07:12:54.499 --> 07:12:57.619
memory profiler.
First of all, I want to draw 

07:12:57.877 --> 07:13:01.585
everyone's attention to this 
allocation tracking pull-down.  

07:13:01.844 --> 07:13:08.477
Some quick history here, in 
Android Studio 3.0, when 

07:13:09.811 --> 07:13:13.208
targeting devices with O or 
newer, we collected a call stack

07:13:13.451 --> 07:13:17.947
for every single allocation that
your app made.  We did it 

07:13:17.948 --> 07:13:21.207
because it would be convenient 
to use to have that history, 

07:13:21.478 --> 07:13:24.615
however, some of our users 
reported that profilers were 

07:13:24.925 --> 07:13:27.643
slowing their app down.  After 
we investigated, it turned out 

07:13:27.863 --> 07:13:34.032
to be this feature.  So starting
in Android 3.3, we now give you 

07:13:34.033 --> 07:13:38.240
the option to configure this.
And let me go ahead and look 

07:13:38.702 --> 07:13:43.238
here.  So we have none, sampled,
and full.  None disables the 

07:13:43.520 --> 07:13:47.402
feature, null enables it, and 
sample attempts to collect a 

07:13:47.669 --> 07:13:51.334
subset of the allocations that 
would sort of gives you a 

07:13:51.335 --> 07:13:53.335
general look for how your

07:13:56.355 --> 07:13:58.372
ach's memory behavior is, 
without affecting the 

07:13:58.373 --> 07:14:01.025
performance as much.
And now, that being said, 

07:14:01.359 --> 07:14:05.099
without or not full affects your
app depends on the host machine 

07:14:05.100 --> 07:14:09.263
you are running on, whether you 
are targeting the device, or the

07:14:09.264 --> 07:14:15.621
code.  If your app code has a 
lot of small allocations on it, 

07:14:15.622 --> 07:14:18.929
like Santa tracker does, it can 
be slow.  But I recommend 

07:14:19.207 --> 07:14:23.923
playing with the features.  I 
will go and turn full on.

07:14:23.924 --> 07:14:28.001
So notice once I turned on full,
the allocation indicator started

07:14:28.332 --> 07:14:31.979
showing up.  I wanted some 
interesting things to happen so 

07:14:31.980 --> 07:14:33.980
I will rotate the

07:14:37.134 --> 07:14:39.120
device.
So I will rotate it back.  We 

07:14:39.121 --> 07:14:41.888
will go and take a look here.  
So all I need to do at any point

07:14:42.163 --> 07:14:46.026
is just to drag across, and I 
will be able to see all of the 

07:14:46.310 --> 07:14:48.432
allocations and the 
de-allocations that happened 

07:14:48.801 --> 07:14:52.461
during that range.  This can be 
a lightweight way to sort of get

07:14:52.462 --> 07:14:55.220
a quick look at what your memory
is doing.  There is an 

07:14:55.643 --> 07:15:00.424
allocation and a de-allocation 
count.  Sometimes you might find

07:15:00.939 --> 07:15:03.835
memory leaks just doing this. 
And the other nice thing is, if 

07:15:04.371 --> 07:15:06.678
you have this on and you are 
doing other stuff, you can go 

07:15:06.679 --> 07:15:09.750
back in time and select a range 
and still see what is going on 

07:15:09.933 --> 07:15:14.164
in memory.  I will go ahead here
and turn it back off again.

07:15:14.165 --> 07:15:19.070
And you will notice that the 
allocation indicated that it 

07:15:19.071 --> 07:15:22.258
stopped tracking by doing an 
empty circle.  If I did sample 

07:15:22.259 --> 07:15:27.344
mode, it would put a half-filled
circle.  Now, looking at these 

07:15:27.646 --> 07:15:31.154
objects, once I click on it, you
can see every single one that is

07:15:31.155 --> 07:15:35.326
currently allocated as well as 
the -- where it was allocated.  

07:15:35.327 --> 07:15:39.391
This is very useful to get your 
handle on a code base.  You can 

07:15:39.554 --> 07:15:41.554
click on this and see where the 
different objects are coming 

07:15:41.816 --> 07:15:46.575
from.  That being said, it might
not help you understand why a 

07:15:46.576 --> 07:15:51.930
memory leak happened, what is 
holding on to my memory.  If I  

07:15:52.205 --> 07:15:54.391
you want to get that 
information, you have to go over

07:15:54.695 --> 07:15:59.154
here to this icon and click the 
heap done.  So what I'm going to

07:15:59.507 --> 07:16:03.353
do here, just to let you know, I
could not find a leaking 

07:16:03.596 --> 07:16:06.541
activity or fragment in the 
Santa tracker app.

07:16:06.542 --> 07:16:11.013
So, full disclosure, I added 
one.  And what I did is I added 

07:16:12.287 --> 07:16:16.182
a memory leak to this penguin 
swim game here.  So actually we 

07:16:16.507 --> 07:16:21.704
will go ahead and go into the 
app, or the activity, and leave 

07:16:21.962 --> 07:16:26.795
it.  And let me actually do 
another heap dump.

07:16:26.796 --> 07:16:29.406
All right.
So we're about to get a bunch of

07:16:29.684 --> 07:16:32.755
heat dump information here.  I 
know that the fragment inside 

07:16:33.153 --> 07:16:37.472
this activity is called swim 
fragment.  Just like CPU, we 

07:16:37.473 --> 07:16:39.473
have the filter

07:16:46.089 --> 07:16:50.598
button here.  
And I can filter the different 

07:16:50.808 --> 07:16:53.976
objects and sure enough, the 
swimming fragment is still 

07:16:54.468 --> 07:16:57.001
alive.  I will click on it, 
select the active instance, and 

07:16:57.295 --> 07:17:02.906
there's a lot going on here.  So
I will take a moment  moment to 

07:17:03.371 --> 07:17:06.743
explain a little bit and take a 
moment to absorb it.  I want to 

07:17:07.186 --> 07:17:15.522
explain what the depth idea is. 
So imagine all of your Java 

07:17:16.112 --> 07:17:19.108
collector lives in this heap.  
There are special objects that 

07:17:19.403 --> 07:17:23.772
live outside of the circle, 
called GC roots.  When you 

07:17:24.154 --> 07:17:27.358
create a new thread, you create 
the GC root, or the static 

07:17:28.800 --> 07:17:33.773
variables are an instance.  So 
what ends up happening, you in a

07:17:34.256 --> 07:17:36.995
thread might create an instance 
of some class that creates inert

07:17:39.224 --> 07:17:41.224
another instance of another 
class and you are creating this 

07:17:41.496 --> 07:17:47.752
long chainf of objects and each 
item in that chain has further 

07:17:48.101 --> 07:17:51.175
and further depth from the GC 
root.  You may have heard that 

07:17:51.493 --> 07:17:56.125
cycles are not a problem to the 
garbage collector.  I can point 

07:17:56.292 --> 07:17:59.908
at you, you at you, you at me.  
If we cannot all be reached, 

07:18:00.246 --> 07:18:04.744
that is removed from the GC.  So
one of the things to note, if 

07:18:05.177 --> 07:18:09.321
you take a heap dump, you might 
see a scary amount of things 

07:18:09.497 --> 07:18:12.702
holding on -- in my instance, a 
lot of these are harmless.  A 

07:18:12.897 --> 07:18:16.015
lot of them are potentially just
cycles.  And one way that you 

07:18:17.307 --> 07:18:25.261
can kind of know, it is a good 
heuristicheuristic, the depth is

07:18:26.102 --> 07:18:29.428
greater than your own depth.  So
imagine the garbage collector 

07:18:29.429 --> 07:18:32.864
root points to you, you create a
child instance and one of the 

07:18:32.865 --> 07:18:37.730
things you do, you give it your 
this pointer, it is pointing 

07:18:38.197 --> 07:18:41.362
back at you, you are pointing at
me, you are my child and know 

07:18:41.363 --> 07:18:45.586
who my parent is.  My depth is 
going to be added on to this 

07:18:45.818 --> 07:18:52.472
pointer's depth.
So that's why some of these -- 

07:18:52.473 --> 07:18:55.714
you are noticing it here, but it
is not an issue. And you are 

07:18:56.213 --> 07:19:00.962
seeing columns where the depth 
is blank.  There is flow way to 

07:19:00.963 --> 07:19:06.150
reach these at the moment from 
any garbage collection root T. 

07:19:06.151 --> 07:19:09.607
Will be cleaned up, even though 
it is in the heap dump right 

07:19:09.935 --> 07:19:14.457
now, you don't have to where he 
worry about it now.  Just ignore

07:19:15.222 --> 07:19:18.370
it.  And just a concrete 
example, I will look here at the

07:19:18.371 --> 07:19:22.088
code which is not the cause of 
our memory leak.  Our depth is 

07:19:22.697 --> 07:19:27.291
one, and this item's depth is 
two.  So what this is saying, 

07:19:27.594 --> 07:19:31.158
somewhere there is an instance 
of a score view class and that 

07:19:31.546 --> 07:19:35.597
score view class has a variable 
called share/click/listener 

07:19:35.911 --> 07:19:40.226
whose value is me.
And we will go ahead and take a 

07:19:41.616 --> 07:19:47.715
look at swumming fragment.  And 
I can search for the score view.

07:19:47.949 --> 07:19:52.184
And before when I say this, 
there has to be a score view 

07:19:52.588 --> 07:19:56.735
that points at me, and it is 
inside the swimming fragment.  

07:19:56.736 --> 07:20:00.167
If I jump to it, I create one 
and I pass in the this pointer. 

07:20:00.433 --> 07:20:06.196
So that is explaining why 
there's a cycle there, I don't 

07:20:06.197 --> 07:20:09.988
have to worry about it and it is
explaining why it is showing up 

07:20:10.165 --> 07:20:14.631
in the heap dump.  And there's 
lot of this dollar sign zero 

07:20:14.853 --> 07:20:18.298
symbols.  What is going on here,
you are going to see it a lot, 

07:20:18.749 --> 07:20:21.770
you know what the this pointer 
is.  If you are an inner class, 

07:20:22.072 --> 07:20:26.689
or a nested class and you need 
access to the outer class's 

07:20:27.395 --> 07:20:32.141
fields, the compiler generates a
synthetic variable and instead 

07:20:32.142 --> 07:20:36.031
of calling it this, because that
is taken, it is this dollar sign

07:20:36.032 --> 07:20:39.724
zero.  That means that it is the
this, the one level out of my 

07:20:40.013 --> 07:20:43.226
scope.  And anytime you create 
an inner class that has a 

07:20:43.421 --> 07:20:47.329
reference to the outer class, or
you create a closure and an 

07:20:48.020 --> 07:20:50.781
anonymous class instance, it is 
going to have that.  If you are 

07:20:51.635 --> 07:20:54.721
using Lambdas in your code or 
anonymous classes, you will see 

07:20:55.060 --> 07:21:02.268
a lot of zeros.  This has a 
depth of zero, with a GC root, 

07:21:02.921 --> 07:21:04.955
that is suspicious.  We will 
look at the source.  And I might

07:21:05.297 --> 07:21:10.702
look at this and say, where  I 
wrote this long running class.  

07:21:10.703 --> 07:21:13.964
It is not static, it is final, 
and it will hold a reference to 

07:21:13.965 --> 07:21:16.551
the parent class.  That's what 
is going on here, and this 

07:21:17.147 --> 07:21:21.877
long-running task, I created it,
but I forgot to cancel it.  We 

07:21:22.151 --> 07:21:25.888
will look here, sure enough, I 
left it out, for no if reason.  

07:21:26.143 --> 07:21:31.172
I will uncomment it there and we
will re-launch.  So what we're 

07:21:31.685 --> 07:21:35.296
going to do now is, I will make 
sure it is saved.  There we go.

07:21:35.559 --> 07:21:39.381
What we're going to do now is 
reboot it just to make sure 

07:21:40.607 --> 07:21:43.943
that, in fact, the swimming 
fragment was released.  One of 

07:21:44.231 --> 07:21:48.244
the things to keep an eye out 
for when you are hunting for 

07:21:48.560 --> 07:21:51.840
memory leaks is static variables
or singleton classes that are 

07:21:52.183 --> 07:21:55.409
holding on to your class, or 
registering yourself with a 

07:21:56.048 --> 07:21:59.849
listener and for getting to 
remove it, or any inner classes 

07:21:59.850 --> 07:22:03.922
that, for some reason, may not 
end up stopping and they are 

07:22:04.191 --> 07:22:07.962
running even though the activity
is trying to exit.  Are we 

07:22:07.963 --> 07:22:10.340
profiling here? Yes.  We still 
going.

07:22:10.341 --> 07:22:13.613
And then another thing I want to
mention is it is not always 

07:22:13.836 --> 07:22:16.877
going to be this easy.  You are 
not going have this obvious 

07:22:17.238 --> 07:22:21.217
culprit.  So, in that case, you 
are going to want to -- I would 

07:22:22.039 --> 07:22:24.130
say just try to get to know the 
code, look for those things that

07:22:24.131 --> 07:22:27.782
I talked about, we will go ahead
and enter.

07:22:27.783 --> 07:22:30.969
And we will wait here while I 
talk.

07:22:30.970 --> 07:22:34.538
And, you know, if you cleaned it
up, even if you didn't find it 

07:22:34.744 --> 07:22:37.810
in the heap dump, it is going to
be the source of truth.  It is 

07:22:38.493 --> 07:22:40.493
going to be the thing that

07:22:44.042 --> 07:22:46.615
gar  guarantees your memory is 
reclaimed.  So I will go back 

07:22:46.616 --> 07:22:50.873
into the memory profiler, click 
on the garbage collector.  You 

07:22:51.153 --> 07:22:55.053
may have noticed these garbage 
collected events, automatically 

07:22:55.054 --> 07:22:58.289
at the bottom.  So for example, 
there's a lot there.  That's 

07:22:58.756 --> 07:23:01.793
where the garbage collector 
decided to collect on its own.  

07:23:02.264 --> 07:23:07.487
And you can click the garbage 
collection button to manually 

07:23:07.806 --> 07:23:11.364
cause it to get run.
And now we still see swimming 

07:23:11.734 --> 07:23:14.909
fragment here.  We will see if 
the depth is actually -- as you 

07:23:15.213 --> 07:23:19.646
can see, the swimming fragment 
is showing up I could be 

07:23:20.021 --> 07:23:23.356
nervous, but the depth column is
blank.  And everything else is 

07:23:23.566 --> 07:23:27.346
waiting to be picked up by the 
GC.  You can press the garbage 

07:23:27.508 --> 07:23:31.104
collector a few more times.  And
one trick I like to do is rotate

07:23:31.386 --> 07:23:35.399
the phone, rotate it again.  And
every time you rotate an Android

07:23:35.770 --> 07:23:40.666
phone, a lot of fun things 
happen, it tells the GC a lot of

07:23:41.052 --> 07:23:45.426
things are going on.  We will 
see the heap dump and assume 

07:23:45.982 --> 07:23:49.172
that it is truly well and 
collected.  I wish it came with 

07:23:49.423 --> 07:23:53.403
a drum role, and  roll, and it 
is gone.  If you are looking at 

07:23:53.675 --> 07:23:58.201
the heap dump, you are not 
necessarily hunting memory leak,

07:23:58.414 --> 07:24:02.349
you might not know a major class
to look out for.  There's the 

07:24:03.250 --> 07:24:05.680
concept of shallow size and 
retain size.  Shallow size is 

07:24:05.961 --> 07:24:10.672
the size of a single instance of
some class that it have been 

07:24:11.113 --> 07:24:13.702
allocated.  And retain size is 
all of the things that it is 

07:24:13.981 --> 07:24:20.044
holding on to.  So what you may 
want to do is hunt, sort the 

07:24:20.349 --> 07:24:22.584
shallow and retain size and 
investigate to see if there is a

07:24:24.003 --> 07:24:26.922
suspicious memory thing there, 
you can clean up your design and

07:24:27.523 --> 07:24:32.065
remove memory there earlier.
So that ends the demo, and back 

07:24:32.066 --> 07:24:36.631
to Shukang.  Let's go to the 
slides.  

07:24:36.632 --> 07:24:42.288
SPEAKER: So to recap, in today's
demo, we showed you how to use 

07:24:42.577 --> 07:24:46.539
CPU and memory profiler to get a
better understanding of the code

07:24:46.913 --> 07:24:50.788
base for the Santa Tracker app. 
To be honest, Dave and I don't 

07:24:51.727 --> 07:24:55.918
know much about it before we are
preparing for this talk.  And we

07:24:56.171 --> 07:25:02.551
also have shown that we don't 
only use profilers to diagonal 

07:25:02.552 --> 07:25:05.197
performance issues, we use them 
to help us understand the 

07:25:05.492 --> 07:25:09.828
performance of this app.
And as we said before, there are

07:25:10.286 --> 07:25:13.499
also network and energy 
profilers in Android Studio, but

07:25:13.793 --> 07:25:17.843
unfortunately we don't have time
to cover them today.  So these 

07:25:18.264 --> 07:25:22.632
refer to our online documents 
and talks to learn more.

07:25:22.633 --> 07:25:26.456
So we hope we have learned some 
tricks and tips from our demo 

07:25:26.911 --> 07:25:31.374
today.  We hope that you  they 
are useful when you approach 

07:25:32.038 --> 07:25:36.250
your own code base with Android 
Studio builders at your side.  

07:25:36.251 --> 07:25:38.251
Thank you for attending our 

07:25:47.009 --> 07:25:49.009
talk.
  [ Applause ]

07:25:51.922 --> 07:25:55.773
  SPEAKER: The next session will
begin in 10 

07:26:04.458 --> 07:26:06.722
minutes.
Coming up next: Testing Android 

07:28:38.075 --> 07:28:42.208
Apps at Scale with Nitrogen by 
Stephan Linzner, Vishal Sethia.

07:28:38.075 --> 07:28:40.075
#

07:34:50.093 --> 07:34:52.093
Stephan Linzner, and back with 
me

07:34:57.895 --> 07:35:00.349
is Vishal Sethia.
And we develop products for 

07:35:00.635 --> 07:35:02.635
everyone, and that means we have
to test for everyone.  So let me

07:35:02.831 --> 07:35:07.794
tell you a little bit about how 
the development test happens at 

07:35:08.863 --> 07:35:14.018
Google.  Before I start, I want 
to talk about the scale that we 

07:35:15.814 --> 07:35:19.263
do on Android development at 
Google.  We have 100-plus 

07:35:19.264 --> 07:35:24.232
Android apps, including the user
apps such as Google photos, 

07:35:25.149 --> 07:35:29.486
maps, YouTube, Gmail, search.  
We have 200 billion lines of 

07:35:29.923 --> 07:35:34.798
code, and run 20,000 Android 
builds every day and have a 

07:35:35.112 --> 07:35:41.516
staggering 27 million test 
innovationss -- invocations per 

07:35:42.195 --> 07:35:45.727
day.  How do we create these 
high quality app and maintain 

07:35:46.142 --> 07:35:48.142
that quality over such a

07:35:50.623 --> 07:35:56.578
long time?
An a typical developer workflow 

07:35:56.847 --> 07:35:59.862
looks like this.  We have a 
strong code review culture, code

07:36:00.396 --> 07:36:05.188
reviews are very, very thorough 
and, before you can actually 

07:36:05.365 --> 07:36:10.877
submit your change or pull 
request, you have to get at 

07:36:11.299 --> 07:36:15.659
lease reviewed by one of your 
peers.  And another important 

07:36:23.126 --> 07:36:29.156
thing is all development happens
at head.  We have a large repo 

07:36:29.436 --> 07:36:33.739
that allows us to search for and
use code and create large-scale 

07:36:34.029 --> 07:36:36.740
changes.  And we also have a 
very strong testing culture.  At

07:36:37.083 --> 07:36:41.053
Google, if you have a change, 
you have to have tests.

07:36:41.054 --> 07:36:45.112
And even more importantly, all 
of those tests have to pass 

07:36:45.570 --> 07:36:51.137
before you submit your change.
To run tests, you use a 

07:36:52.137 --> 07:36:56.311
large-scale distributed CI 
system, which not only runs your

07:36:56.860 --> 07:37:00.798
tests, but all of the testss 
from code that depends on your 

07:37:01.067 --> 07:37:04.372
change. Another thing that is 
very unique about Google is we 

07:37:04.716 --> 07:37:07.430
have a strong engineering 
productivity culture.  That 

07:37:07.756 --> 07:37:11.570
means we have dedicated teams 
that only work on infrastructure

07:37:11.571 --> 07:37:14.927
tools and APIs to make 
developers 

07:37:18.885 --> 07:37:22.295
productive.
We are part of such a team, and 

07:37:22.527 --> 07:37:27.022
we have been working on testing 
Android apps, or Android app 

07:37:27.303 --> 07:37:32.145
testing, at Google.
So I want to take you a walk 

07:37:32.500 --> 07:37:36.663
down memory lane what we have 
done at Google to scale Android 

07:37:37.422 --> 07:37:40.158
testing.
In 2011, a lot of teams at 

07:37:40.498 --> 07:37:47.023
Google actually started to build
for Android because Android was 

07:37:47.024 --> 07:37:55.214
becoming more and more popular. 
They were using a standard tool 

07:37:55.658 --> 07:38:03.132
chain, ant and eclase.  And we 
support said ed the internal 

07:38:03.463 --> 07:38:06.803
build system.  A problem that 
was obvious early on is the need

07:38:06.804 --> 07:38:09.700
for scalable testing.  We 
started off very simple by 

07:38:10.062 --> 07:38:12.683
building a small host-like test 
runner that would run on the 

07:38:12.848 --> 07:38:21.299
host.  And, in fact, it was a J 
unit three test suite, list the 

07:38:22.155 --> 07:38:26.494
APK, list the tests, and give it
on the instrument test runner on

07:38:26.495 --> 07:38:30.372
the device to execute the test. 
And once we have that, we built 

07:38:30.373 --> 07:38:33.383
it into a continuous integration
system.  One of the key 

07:38:33.753 --> 07:38:37.283
decisions we made early on was 
to use emulators, we called them

07:38:37.590 --> 07:38:43.645
virtual devices, to run tests 
alts at scale because it makes 

07:38:43.646 --> 07:38:48.741
more sense because you can scale
a data center, but not a USB hub

07:38:51.463 --> 07:38:56.790
so easily.  So we wrote this 
Python script, 200 lines of 

07:38:57.489 --> 07:39:00.204
code, you probably have been 
there, that boots the emulator 

07:39:00.537 --> 07:39:04.771
for us that allows us to run the
tests and shout it down 

07:39:05.317 --> 07:39:08.025
afterwards.  While we were 
working on infrastructure, our 

07:39:09.347 --> 07:39:11.614
engineers started to write 
tests, and they wrote a lot of 

07:39:11.615 --> 07:39:21.560
them.  A key problem here is 
around functional UI testing. 

07:39:22.205 --> 07:39:26.960
In the early days, you had 
low-level framework APIs, you 

07:39:28.275 --> 07:39:33.574
are monitors to track 
activities, or wait until idle 

07:39:33.575 --> 07:39:38.694
sink  sync.  And even though 
these APIs were easy to use, 

07:39:41.081 --> 07:39:45.995
developers struggle a lot 
writing reliable UI tests.  We 

07:39:48.424 --> 07:39:50.445
thought that maybe we can find 
something better, and we did

07:39:54.771 --> 07:40:01.208
in the community Robotium, and 
we used them until 2012.  It had

07:40:03.561 --> 07:40:06.924
issues bes with the API surface,
and it did not solve

07:40:10.463 --> 07:40:16.666
synchronization.  We used 
Espresso, we wanted something 

07:40:17.307 --> 07:40:21.492
easy for developers and handled 
the complex instrumentation 

07:40:21.868 --> 07:40:24.648
testing from the developer.  We 
had a decent set-up for 

07:40:24.649 --> 07:40:28.863
instrumentation tests, but we 
have to solve the unit testing 

07:40:29.139 --> 07:40:32.535
problem.  At the time, all of 
the unit tests, you ran them on 

07:40:32.806 --> 07:40:38.117
the device.  But that is 
expensive and they tend to be 

07:40:38.719 --> 07:40:46.380
slower than running on the JVM. 
So we reached for a solution, 

07:40:46.780 --> 07:40:51.566
which at the time was 
RobolectricRobolectric.  It 

07:40:51.567 --> 07:40:55.719
allowed for fast local 
development and is still one of 

07:40:55.720 --> 07:40:59.198
the most popular frameworks for 
unit testing in Google.  In 

07:40:59.467 --> 07:41:01.903
2014, we build a lot of 
experience in testing 

07:41:05.186 --> 07:41:08.140
APIs, but we were seeing that 
the community was struggling 

07:41:08.141 --> 07:41:10.494
from the same problems that we 
did.  

07:41:10.495 --> 07:41:13.677
So we bundled all of the 
libraries together in the 

07:41:13.678 --> 07:41:17.970
Android testing support library 
, the default library for 

07:41:18.285 --> 07:41:20.842
developers writing 
instrumentation tests.

07:41:20.843 --> 07:41:25.767
Fast forward to today, we 
launched AndroidX test 1.0.  It 

07:41:26.028 --> 07:41:29.612
is not only the first stable 
release, it is the first time 

07:41:30.047 --> 07:41:34.669
where we ship unified APIs that 
allow you to write tests once 

07:41:34.953 --> 07:41:39.816
and run them anywhere.
And, by the way, we just 

07:41:39.817 --> 07:41:45.152
achieved a major milestone at 
Google.  We run 10 billion unit 

07:41:45.673 --> 07:41:48.459
and instrumentation tests every 
year on our infrastructure.

07:41:48.460 --> 07:41:54.231
And so, looking back at those 
seven years, what will go 

07:41:55.108 --> 07:41:59.162
differently? There's a couple of
things I want to mention here.  

07:41:59.458 --> 07:42:03.215
So we can probably design for 
any build system.  We made some 

07:42:03.594 --> 07:42:08.293
key decisions early on that 
tightly coupled us to Google's 

07:42:08.548 --> 07:42:12.443
internal build system.  But this
was a problem, even at Google, 

07:42:12.866 --> 07:42:15.949
not everyone is using Google's 
internal build system, and we 

07:42:16.236 --> 07:42:18.428
were not able to host that 
infrastructure with them, and 

07:42:18.709 --> 07:42:22.008
not with the community and we 
could not open source it.

07:42:22.009 --> 07:42:25.855
Similarly, we did not build some
of the tools -- some of the 

07:42:26.140 --> 07:42:29.202
tools that we built were not 
cross-platform, they worked on 

07:42:29.500 --> 07:42:35.294
Linux, but not Mac and Windows.
And another thing we would do 

07:42:35.583 --> 07:42:38.128
differently, and 
retrospectively, it is not a 

07:42:38.388 --> 07:42:41.676
good thing that we started out 
small and scaled up our testing.

07:42:42.734 --> 07:42:47.573
While the apps grew and the 
ecosystem grew, there were more 

07:42:48.610 --> 07:42:51.575
and more requirements.  We 
usually built them into the 

07:42:51.972 --> 07:42:54.509
infrastructure, but we did not 
have a mechanism for teams to 

07:42:54.778 --> 07:42:58.058
customize the infrastructure.  
We suffered from hide code 

07:42:58.316 --> 07:43:01.090
complexity t was hard to 
maintain and some features would

07:43:01.318 --> 07:43:06.468
thought could not be removed and
they were not used anymore.  The

07:43:07.341 --> 07:43:11.173
other thing to mention is 
configuration, the hosting 

07:43:11.174 --> 07:43:16.436
infrastructure was getting 
configuration from many sources,

07:43:16.437 --> 07:43:19.001
flags, system environment 
variables and config files.  

07:43:19.698 --> 07:43:22.052
This made it hard to track down 
bugs in the infrastructure 

07:43:22.201 --> 07:43:26.399
itself.  So about a year ago, 
our team sat down with app teams

07:43:26.597 --> 07:43:32.119
in Google and we wanted to learn
about the past and the future 

07:43:32.120 --> 07:43:35.420
and especially how the Android 
testing landscape had changed. 

07:43:36.499 --> 07:43:41.803
And so what we came up with to 
solve  solve some of the 

07:43:42.083 --> 07:43:46.257
problems out of the discussion 
was project nitrogen.  It was a 

07:43:46.749 --> 07:43:53.069
new unified testing platform 
that we first talked about at UI

07:43:56.005 --> 07:43:59.294
UAT I/O this year that will ship
in 2019.  Project Nitrogen is 

07:44:00.339 --> 07:44:03.430
used by a small number of apps 
in Google and we are slowly 

07:44:03.767 --> 07:44:06.805
scaling it up to some of the 
bugest in the world.  The reason

07:44:06.946 --> 07:44:11.045
we are doing this is because we 
want to battle test it first 

07:44:11.315 --> 07:44:14.462
before we ship it to you.  But 
the point is we want to give all

07:44:14.463 --> 07:44:18.329
of the infrastructure that we 
use to run 10 billion tests to 

07:44:18.739 --> 07:44:22.645
you.  So nitrogen solves many 
problems, but two of the key 

07:44:22.974 --> 07:44:26.279
issues that we are trying to 
solve with nitrogen is, first, 

07:44:27.192 --> 07:44:31.849
we want to create a unified 
entry point into Android 

07:44:32.135 --> 07:44:35.444
development.  And secondly, we 
want to be able to write tests 

07:44:35.715 --> 07:44:41.181
with a unified API and move them
between layers.  If you think 

07:44:42.622 --> 07:44:47.822
about Android testing today, it 
looks like this you. Have.  You 

07:44:48.134 --> 07:44:54.392
have tools on the left, such as 
Android studioStudio, Gradle, a 

07:44:56.270 --> 07:45:01.846
CI system, and Bazel.  On the 
right, you have run times you 

07:45:02.169 --> 07:45:06.332
want to run on.  We call run 
time devices on Nitrogen.  You 

07:45:06.628 --> 07:45:09.915
want to run tests on a simulated
device, or a virtual or physical

07:45:10.389 --> 07:45:15.735
device, or on a remote device 
that runs on a device lab, such 

07:45:16.154 --> 07:45:18.618
as Firebase.  And in order to do
so, we have many different entry

07:45:19.623 --> 07:45:27.560
points, it looks like this.  You
have a configuration for every 

07:45:27.561 --> 07:45:30.682
tool, you have different roles 
and tasks and it is a nightmare 

07:45:31.161 --> 07:45:35.521
to maintain.  What we see in 
Google, it is so hard to move 

07:45:36.897 --> 07:45:40.192
from one to another, they would 
go from one test to another.  So

07:45:40.461 --> 07:45:45.315
what we want to do with nitrogen
is to have a unified entry 

07:45:45.591 --> 07:45:53.301
point.  And nitrogen itself is a
stand-alone binary, or tool, and

07:45:54.134 --> 07:45:56.471
infrastructure developers can 
use to customize their 

07:45:56.725 --> 07:46:00.585
infrastructure.  And obviously, 
there are all of these other 

07:46:01.026 --> 07:46:03.801
developers that don't work on 
infrastructure and work in 

07:46:04.408 --> 07:46:08.209
actual lab code.  We want to 
provide integrations into all of

07:46:08.210 --> 07:46:11.415
the tools on the left hand side 
to make it easy to run tests.

07:46:11.824 --> 07:46:16.616
And, at that point, if you have 
a single entry point and a 

07:46:16.899 --> 07:46:21.515
unified test, it fits very well 
within your developer workflow, 

07:46:21.864 --> 07:46:27.896
because you can do local, fast 
iterative development on a 

07:46:28.255 --> 07:46:30.956
simulated device.  And before 
you submit the change, you can 

07:46:31.321 --> 07:46:36.498
run on an emulator matrix.  And 
lastly, in post-submit, you can 

07:46:36.988 --> 07:46:40.545
run on a remote device, a 
physical device, in Firebase 

07:46:41.027 --> 07:46:45.398
test lab.  And that is what we 
are trying to do with nitrogen.

07:46:45.736 --> 07:46:49.055
Nitrogen allows you to run tests
at scale.

07:46:49.056 --> 07:46:54.714
It is highly configurable, it 
was build with customization and

07:46:55.639 --> 07:47:01.993
extensibilityextensibility in 
mind.  You can execute unit 

07:47:01.994 --> 07:47:06.510
tests, it improves reporting 
and, therefore, debugging.  And 

07:47:06.511 --> 07:47:10.954
one of the most exciting things 
is it ships with its virtual 

07:47:10.955 --> 07:47:14.217
device management solution that 
manages devices for you.

07:47:14.218 --> 07:47:18.027
And that is actually something I
think a

07:47:21.228 --> 07:47:24.602
lot of the community has been 
asking us for quite a while.  So

07:47:24.603 --> 07:47:27.908
Nitrogen is cross-platform, and 
we build it from the ground up 

07:47:27.909 --> 07:47:35.779
with all the experience that we 
have, seven years in host side 

07:47:35.780 --> 07:47:41.537
in that infrastructure.  It 
supports Mac, , Windows, and 

07:47:41.829 --> 07:47:46.530
Linux, and it is written in 
Kotlin, and we write it in a way

07:47:48.469 --> 07:47:52.183
that it will be viable for the 
next seven years.

07:47:52.184 --> 07:47:54.184
And

07:47:56.199 --> 07:48:01.634
Nitrogen is a stand alone tool. 
It can be integrated into any 

07:48:01.903 --> 07:48:08.790
system.  We are working on 
integrations for Gradle and 

07:48:10.791 --> 07:48:15.764
basilbasil Bazel.  We are 
working on test execution and 

07:48:15.765 --> 07:48:20.257
support will be there from the 
start.  On the device side, we 

07:48:20.258 --> 07:48:26.967
are planning to have support for
simulated, virtual, and physical

07:48:27.550 --> 07:48:31.503
devices, and device labs, such 
as Firebase.  And you can even 

07:48:31.504 --> 07:48:35.411
add your custom devices if you 
have custom hardware.

07:48:35.412 --> 07:48:38.790
So let's switch gears a little 
bit and talk a little bit about 

07:48:39.061 --> 07:48:43.572
the high level architecture of 
nitrogen.  So nitrogen is 

07:48:43.573 --> 07:48:48.320
basically split into two parts: 
We have a host side 

07:48:48.592 --> 07:48:52.814
infrastructure that is all the 
code that runs on the host, ask 

07:48:52.815 --> 07:48:57.376
we've done something new.  We 
have an on-device infrastructure

07:48:57.377 --> 07:49:00.824
which means that we have moved 
some of our infrastructure on to

07:49:00.825 --> 07:49:06.708
the device, which is a much 
saner environment to reason 

07:49:06.967 --> 07:49:10.560
about, and the device is the 
main abstraction that we use in 

07:49:10.726 --> 07:49:16.648
nitrogen for different run 
times.  So the host site runner 

07:49:17.177 --> 07:49:19.363
is mostly responsible for 
finding the device for you, 

07:49:19.636 --> 07:49:25.400
setting up the device for test 
execution, and then requesting a

07:49:25.665 --> 07:49:30.724
test run.  It can be easily 
configured with a proto buffer 

07:49:31.013 --> 07:49:34.931
configuration, and it allows you
to customize things like the 

07:49:34.932 --> 07:49:38.964
test executor and the whole test
harness.

07:49:38.965 --> 07:49:43.836
To decouple the host from the 
device, we have a new 

07:49:44.103 --> 07:49:47.869
orchestrater service.  You can 
think of it as the brain

07:49:51.179 --> 07:49:55.988
is responsible for discovery, 
filtering, and sorting, and 

07:49:57.236 --> 07:49:59.458
execution.
And an orchestrater service is 

07:49:59.459 --> 07:50:04.951
just a GRPC service that can be 
implemented by any device.  And 

07:50:05.497 --> 07:50:09.107
we, in fact, use GRPC to 
communicate between the host and

07:50:09.108 --> 07:50:13.178
the device, which does not give 
us performance and speed.  It 

07:50:13.391 --> 07:50:16.425
gives us a lot of stability and 
it allows us to stream test 

07:50:16.708 --> 07:50:21.632
results back to the host in 
realtime.  We also have a lot of

07:50:21.633 --> 07:50:26.354
extension points.  So we will 
have host plugins that allow you

07:50:26.773 --> 07:50:31.621
to run code on a host, and we 
will also have device plugins 

07:50:32.023 --> 07:50:36.140
that allow you to run code on 
the device.  So let's dive into 

07:50:37.178 --> 07:50:45.520
each of these sections.
As I mentioned before, we use a 

07:50:45.912 --> 07:50:49.749
single proto configuration with 
a declarative set of protos.  

07:50:50.665 --> 07:50:56.584
This allows you to find devices,
the text features, so you can 

07:50:57.039 --> 07:51:00.114
find APKs that you want to 
install, and it can declare your

07:51:01.044 --> 07:51:05.279
host and device plugins.  We 
initially will have support for 

07:51:05.696 --> 07:51:10.554
single device executers, 
parallel device executers, to 

07:51:11.057 --> 07:51:14.456
run on multiple devices in 
parallel.  And we will also have

07:51:14.862 --> 07:51:19.823
a new multi-device executor, 
which will allow you to do 

07:51:20.432 --> 07:51:22.980
things like orchestrating a test
run between a device and a 

07:51:23.232 --> 07:51:27.834
device, or a device and a watch,
which is something that we 

07:51:28.118 --> 07:51:33.545
increasingly see as a 
requirement.  The good news is: 

07:51:33.546 --> 07:51:38.248
If you are just an app 
developer, you don't have to 

07:51:38.249 --> 07:51:40.859
deal with any of this 
configuration, because it is 

07:51:41.239 --> 07:51:44.866
built in in the tool 
integration.  But if you are an 

07:51:45.183 --> 07:51:47.018
infrastructure developer, this 
is where it is really 

07:51:47.019 --> 07:51:51.838
interesting for you.  Because 
you can customize every single 

07:51:53.450 --> 07:51:56.139
bit of Nitrogen.
Let's talk a little bit about 

07:51:56.596 --> 07:51:59.058
plugins.
So host plugins are plugins that

07:51:59.059 --> 07:52:04.108
can execute code on the host.  
Plugins that we've already built

07:52:04.607 --> 07:52:09.775
are the Android plugin, theythey
encapsulate all the code that 

07:52:09.776 --> 07:52:14.438
allows us to run Android tests 
on the device.  We have a data 

07:52:14.439 --> 07:52:18.939
plugin that allows us to stage 
data on the device, or a 

07:52:19.230 --> 07:52:23.106
descriptor plugin that allows us
to execute fixer scripts on the 

07:52:23.444 --> 07:52:27.209
device.  And you can have your 
custom plugins.  Custom plugins 

07:52:27.455 --> 07:52:32.331
can have their own 
configuration, and with host 

07:52:34.017 --> 07:52:36.937
plugins, you can run before the 
test suite starts, and after the

07:52:37.232 --> 07:52:41.549
test suite is finished.  The 
reason we do it this way is we 

07:52:41.550 --> 07:52:46.597
want to avoid the chattyness 
between the host and the device.

07:52:46.873 --> 07:52:51.244
If you look at the after all 
method, you will also get access

07:52:51.780 --> 07:52:55.512
to the host test suite result, 
which is great if you want to do

07:52:55.713 --> 07:53:01.700
any post-processing of your test
results.  And you can submit an 

07:53:01.983 --> 07:53:06.187
added reQuestback to us if you 
want to attach new artifacts to 

07:53:07.223 --> 07:53:12.595
the test suite result.  Device 
plugins, on the other hand, like

07:53:12.820 --> 07:53:18.165
the name says, are running on an
actual device, which is a much 

07:53:21.103 --> 07:53:25.600
more sane environment to reason 
about.  Most of the host side 

07:53:25.601 --> 07:53:28.791
code that we use to configure 
the device is moved to the 

07:53:29.320 --> 07:53:38.206
device with a device plugin.  So
plugins we have built are a 

07:53:38.471 --> 07:53:41.923
lockhead plugin, a screenshot 
plugin that talks screenshots in

07:53:42.175 --> 07:53:46.990
case the tests fail, or a 
permission plugin was pretty 

07:53:47.404 --> 07:53:52.068
awesome.  You can grant and 
revoke run time permissions, 

07:53:52.365 --> 07:53:55.045
which was not able before, and 
you can obviously also have your

07:53:55.345 --> 07:54:00.490
custom plugins.
So the difference from the 

07:54:01.289 --> 07:54:04.991
device plugin to host plugin is 
that it runs on a device.

07:54:04.992 --> 07:54:10.349
But this allows us to do things 
like that.  We can give you a 

07:54:10.930 --> 07:54:12.930
call-back before the single test
method

07:54:15.696 --> 07:54:19.682
is executed, and after it is 
finished.  This is great, we can

07:54:19.929 --> 07:54:22.832
avoid the chattyness between the
host and the device, and it 

07:54:23.094 --> 07:54:29.075
gives you a lot of control.  And
if you think about it, I don't 

07:54:29.584 --> 07:54:34.197
know how you set up your test 
features now, but you generally 

07:54:34.652 --> 07:54:38.064
have something like add before 
class, or add after class.  If 

07:54:38.491 --> 07:54:42.813
you want something reusable, you
will probably reach for a J unit

07:54:42.814 --> 07:54:46.226
rule, or there is some things 
that you can't do with these 

07:54:46.387 --> 07:54:49.216
APIs, and then you have to have 
your custom runner.  And I think

07:54:49.492 --> 07:54:57.626
the great thing about this is, 
we give you a whole new way of 

07:54:57.627 --> 07:55:05.070
writing plugins that run on the 
device and allow you to execute 

07:55:05.340 --> 07:55:08.650
code on it.  We will move to 
execution.  As I was saying, we 

07:55:08.917 --> 07:55:11.202
move the execution to the actual
device.

07:55:11.203 --> 07:55:16.051
And we created a whole new 
orchestrater service and 

07:55:16.327 --> 07:55:18.481
protocol.
What this does, it standardizes 

07:55:18.875 --> 07:55:23.867
the communication between the 
host and the device and it can 

07:55:24.147 --> 07:55:26.643
be implemented by any device, 
which means if you have a custom

07:55:27.405 --> 07:55:33.065
device, you can implement the 
same protocol, and you can still

07:55:33.450 --> 07:55:40.271
integrate with the host site 
easily.  On Android, it is 

07:55:40.830 --> 07:55:45.856
implemented by the Android test 
orc  orchestrater.  Once you 

07:55:46.098 --> 07:55:49.189
request the test run on the 
host, it will go and discover 

07:55:49.669 --> 07:55:53.475
all the tests, apply any filters
and sorting that you want, and 

07:55:54.265 --> 07:56:01.177
then it will do either isolated 
or batched test execution.

07:56:01.178 --> 07:56:04.318
It will also call all of your 
device plugins, and it will 

07:56:04.733 --> 07:56:10.213
stream results back in realtime 
to the host.

07:56:10.214 --> 07:56:16.706
So the last thing that I want to
talk about is reporting.  So 

07:56:17.067 --> 07:56:19.967
with nitrogen, we will give you 
unified and consistent 

07:56:20.368 --> 07:56:26.148
reporting.  As I'm sure many of 
you have seen this command at 

07:56:26.438 --> 07:56:32.625
the top, what it does is it runs
an instrumentation test from the

07:56:32.902 --> 07:56:38.312
command line.  If you use the 
dash R option, you will get an 

07:56:38.505 --> 07:56:41.589
output like this.  As you can 
see, it is not very human 

07:56:43.258 --> 07:56:46.185
readablereadable, I would say, 
and it is also quite chatty, 

07:56:46.186 --> 07:56:49.762
because this is just showing a 
sungal test.  

07:56:49.763 --> 07:56:53.334
And this is showing a passing 
test.  If it fails, the only 

07:56:53.649 --> 07:56:57.079
thing that it gives you an 
addition is a stacktrace.  So 

07:56:57.362 --> 07:57:02.857
there is not really a lot of 
information or actionable data 

07:57:03.244 --> 07:57:09.165
here to why the test failed.
And with nitrogen, we want to 

07:57:09.166 --> 07:57:14.612
move to something like this, a 
structure data format, which 

07:57:15.114 --> 07:57:17.849
gives you access to the 
properties of the test case, the

07:57:17.850 --> 07:57:24.291
status of the test, and a list 
of art  artifacts collected 

07:57:24.552 --> 07:57:26.552
during the test run.  Things 
like screenshots,

07:57:31.558 --> 07:57:36.025
video, lock, and any custom 
artifacts that you run in your 

07:57:36.026 --> 07:57:38.471
post-processing.
Again, this will also be 

07:57:39.246 --> 07:57:41.407
integrated in Android Studio, 
and we will surface this in the 

07:57:41.855 --> 07:57:45.424
Android Studio UI if you run 
tests.

07:57:45.425 --> 07:57:52.132
The last thing before I wrap up 
what, I wanted to mention we 

07:57:52.316 --> 07:57:59.073
have support for custom reports.
You can do J unit XML, or the 

07:57:59.307 --> 07:58:01.307
custom report that integrates 
better with your own 

07:58:02.155 --> 07:58:04.155
infrastructure. And with that, I
want to hand over to 

07:58:09.456 --> 07:58:13.449
Vishal who is going to talk 
about device management.

07:58:13.450 --> 07:58:15.450
[ Applause ]. 
SPEAKER: Running any kind of 

07:58:15.842 --> 07:58:18.152
Android UI test generally 
happens on devices.  There are 

07:58:18.571 --> 07:58:21.894
two device tests where you can 
run the test, the physical or 

07:58:22.095 --> 07:58:26.699
the watchful device.  
Regardsless, they each have 

07:58:26.700 --> 07:58:30.888
their own sets of pros and cons.
Let's do a quick show of hands. 

07:58:30.889 --> 07:58:33.347
How many people around here have
set up something like this, 

07:58:33.741 --> 07:58:38.106
testing on physical devices? It 
looks like quite a few.

07:58:38.107 --> 07:58:44.042
So a follow-up question.  How 
easy was it to manage them?

07:58:44.043 --> 07:58:45.926
Hard.
And another follow-up question. 

07:58:45.927 --> 07:58:50.505
Did you end up using a file 
testing machine next to it? I 

07:58:50.798 --> 07:58:53.939
hope not.  I have a funny story 
to share that happened a few 

07:58:54.206 --> 07:58:56.528
years at Google when one of the 
teams decided they wanted to 

07:58:56.815 --> 07:58:59.533
test their stuff on physical 
devices.  They procured a bunch 

07:59:00.413 --> 07:59:05.305
of devices, it  glued them to 
the wall, and integrated with 

07:59:05.843 --> 07:59:08.471
the CI infrastructure.  
Everything was running well 

07:59:08.761 --> 07:59:13.251
until one fine day when the 
engineers came back on a Monday 

07:59:14.968 --> 07:59:18.923
morning and things timed out.  
If you were to guess what went 

07:59:19.236 --> 07:59:23.794
wrong, what would your guess be?
Okay, so it turned out to be an 

07:59:24.542 --> 07:59:28.433
air conditioned problem.
So what happened is the air 

07:59:28.710 --> 07:59:30.849
conditioners in the building in 
San Francisco went bad, and 

07:59:31.127 --> 07:59:33.351
because the air conditioners 
went back, the facilities 

07:59:33.621 --> 07:59:36.696
decided they wanted to switch 
off the air conditioners so they

07:59:36.697 --> 07:59:40.009
can fix it, but tests were 
running on those devices and the

07:59:40.305 --> 07:59:44.672
heat produced in the devices 
caused the glue to peel off from

07:59:45.263 --> 07:59:48.531
the wall and all the devices 
fell to the ground.  Managing 

07:59:48.532 --> 07:59:51.699
physical devices are hard.  I 
want to give a huge shout out to

07:59:51.967 --> 07:59:57.094
the fair base test lab team that
makes testing on Firebase so 

07:59:57.504 --> 08:00:02.292
much easier for you folks. How 
do we solve this at Google? The 

08:00:02.651 --> 08:00:04.913
virtual device infrastructure, 
the testing environment we use 

08:00:05.173 --> 08:00:08.298
is very stable.  The number on 
the right is the stability ratio

08:00:08.299 --> 08:00:12.559
of our test environment, it is 
99.9999 percent.

08:00:12.560 --> 08:00:15.871
The continuous integration, the 
virtual device infrastructure 

08:00:16.615 --> 08:00:19.579
that we use has the ability to 
run locally, or in a CI 

08:00:19.903 --> 08:00:22.458
environment.  And it supports 
over 500 different device 

08:00:24.650 --> 08:00:28.685
configurations.  Let's see what 
is the current state at Google. 

08:00:28.686 --> 08:00:34.010
It used be over 100 first party 
apps, such as Google photos, 

08:00:34.484 --> 08:00:38.311
search, YouTube, and so on.  
Just in 2018, it had a 

08:00:38.705 --> 08:00:43.967
staggering 2.4 billion 
invocations, that number is 

08:00:44.403 --> 08:00:48.860
growing year over year.  There 
are 28,000 targets using this 

08:00:48.861 --> 08:00:53.396
infrastructure.  Having a great 
infrastructure is a must for 

08:00:54.219 --> 08:01:00.426
volatile apps.  How does this 
fit in with Nitrogen? If you 

08:01:00.427 --> 08:01:08.545
remember from slides presented 
earlier, NIFEP  nitrogen has the

08:01:08.546 --> 08:01:13.803
concept of device protide 
viders, the virtual device 

08:01:15.981 --> 08:01:19.534
provider, which launches the 
device, returns the concept back

08:01:20.018 --> 08:01:25.069
to nitrogen and executes the 
test.  Ask  once the test is 

08:01:25.070 --> 08:01:30.342
done t , it starts the device.  
You get a stable environment 

08:01:30.604 --> 08:01:33.819
launched by nitrogen, runs the 
test, and shuts it down.  And 

08:01:34.824 --> 08:01:37.119
while designing this 
infrastructure, there are four 

08:01:37.120 --> 08:01:39.668
things that we kept in mind.  
The virtual device 

08:01:40.455 --> 08:01:42.720
infrastructure needs to be 
simple to use, it needs to be 

08:01:43.652 --> 08:01:48.525
extremely stable, and you should
be reproducible, regardless of 

08:01:48.526 --> 08:01:53.051
the environment running in, 
locally or in the CI 

08:01:53.602 --> 08:01:55.822
infrastructure, and it needs to 
be fast.  We will dig into it 

08:01:56.153 --> 08:02:03.493
deeper as to how we achieved 
each of these four goals.

08:02:03.494 --> 08:02:06.505
So the virtual device 
infrastructure has a very simple

08:02:07.128 --> 08:02:11.828
protocol configuration.  What 
does that mean? It is a config 

08:02:11.829 --> 08:02:14.562
file where you can add the 
characteristics of the device.  

08:02:14.832 --> 08:02:17.924
What is the horizontal scheme 
resolution, the vertical screen 

08:02:18.200 --> 08:02:21.903
resolution, the memory of the 
device? So for each of the 

08:02:23.131 --> 08:02:26.325
device types, like nexus and 
pixel, the device management 

08:02:26.577 --> 08:02:29.514
solution has pre-baked in all of
these device configurations, you

08:02:29.741 --> 08:02:32.836
don't have to figure out the 
different resolutions for each 

08:02:32.837 --> 08:02:36.778
of these devices.  It supports 
over 500 different device config

08:02:37.744 --> 08:02:42.137
RAISHZ figerations. Because it 
is a file, it is a matter of 

08:02:42.368 --> 08:02:47.172
adding or removing changes to 
the configuration file.  It

08:02:51.154 --> 08:02:54.823
has several different -- and 
launching it is as simple as 

08:02:55.164 --> 08:02:57.572
calling the device binary and 
specifying the name of the 

08:02:57.837 --> 08:03:03.406
device.  If you want to launch a
pixel two, device equals pucks  

08:03:03.824 --> 08:03:08.956
pixel two and the API level.  
You don't have to worry about 

08:03:09.439 --> 08:03:11.439
specifying configurations and 
things like that.  That makes it

08:03:11.892 --> 08:03:13.971
very simple.
  And stability, this is one of 

08:03:13.972 --> 08:03:17.747
the biggest problems most of the
Android app developers face, you

08:03:17.748 --> 08:03:21.996
are running the test and an ANR 
pops up and it might not be the 

08:03:21.997 --> 08:03:25.611
app you are testing.  We had the
same problem internally as well.

08:03:25.812 --> 08:03:27.812
How did we solve this?

08:03:31.009 --> 08:03:36.770
Well, sorry, Android has a nifty
service to suppress ANRs when it

08:03:36.771 --> 08:03:41.827
sees them.  This is the same 
service that Android monkey 

08:03:42.111 --> 08:03:45.207
uses.  This increases the 
stability of the tests.  One 

08:03:45.208 --> 08:03:48.988
thing consider  I forgot to say,
when we started with this 

08:03:49.274 --> 08:03:52.511
infrastructure, the stability 
was 95 percent.  That is no good

08:03:52.828 --> 08:03:56.661
when you are running things at 
scale.  The first thing we saw 

08:03:56.662 --> 08:03:59.671
is ANRs, once we fixed it, the 
stability increased.  But not to

08:03:59.958 --> 08:04:03.452
the level we wanted.
  The next thing that we saw is 

08:04:03.859 --> 08:04:06.792
we booted up the device, but the
screen is not unlocked.  And if 

08:04:06.960 --> 08:04:11.265
the screen is not unlocked, all 
the key elements that you inject

08:04:11.266 --> 08:04:15.428
do not reach the app.  If they 
don't reach the app, they are 

08:04:15.429 --> 08:04:18.773
not getting tested, and your 
tests are starting to fail.  And

08:04:19.177 --> 08:04:22.644
when the device boots up, the 
screen is not locked.

08:04:22.645 --> 08:04:29.688
So the careen is screen is not 
unlocked.  And Google added an 

08:04:30.077 --> 08:04:34.365
API where you can dismiss the 
key guard to unlock the screen. 

08:04:34.594 --> 08:04:39.084
So every time you call the 
device, we will call to unlock 

08:04:39.085 --> 08:04:44.375
the screen.  A few years ago, 
Android changed the file system 

08:04:44.628 --> 08:04:53.050
from via FFS, another file 
system, to EXT4. 

08:04:54.967 --> 08:05:00.646
EXT4 was prone to discorruption 
during shut down.  So if we did 

08:05:00.647 --> 08:05:04.787
not correctly shout it down, the
subsequent -- (indiscernible) --

08:05:05.096 --> 08:05:08.806
of the device would fail, 
leading to test flakyness.  How 

08:05:09.093 --> 08:05:13.435
did we solve this problem? We 
called in SSH to disk image that

08:05:13.702 --> 08:05:16.358
was unmounted, and this 
guaranteed, when the disk was 

08:05:16.749 --> 08:05:21.579
unmounted, it had no diserrors, 
if there are no disk errors, the

08:05:22.004 --> 08:05:27.556
subsequent boot would come up 
fine, this increased the 

08:05:27.836 --> 08:05:29.590
stability of the test 
environment.  But that is no 

08:05:29.591 --> 08:05:33.577
good.  When you are running on 
2.4 billion 

08:05:36.739 --> 08:05:40.113
innovations, a one-person 
failure is a huge number.  

08:05:40.114 --> 08:05:45.200
There's a bunch of optimizations
we did for the stability.  I 

08:05:45.201 --> 08:05:48.197
will not talk about all of them,
but there's one final thing to 

08:05:48.198 --> 08:05:52.829
talk about.
Launch the device, it will set 

08:05:53.104 --> 08:05:55.825
up a boot saying that the device
is booted up.  But for whatever 

08:05:56.268 --> 08:05:59.359
reason, the launcher dudsdoes 
not kick in.  How did we solve 

08:05:59.360 --> 08:06:03.976
that problem? We had to send out
an intent to the launcher, if it

08:06:04.387 --> 08:06:09.198
was lost, if it wasn't launched 
then we started the launcher and

08:06:09.532 --> 08:06:13.149
we would return the control back
to nitrogen that would run the 

08:06:13.537 --> 08:06:18.454
tests.  Doing a bunch of 
optimizations like this helped 

08:06:19.567 --> 08:06:25.948
us to get to 99.9999 percent 
stability.  The next big pillar 

08:06:26.248 --> 08:06:31.202
we had in mind is reap 
reproducibility.  In the CI 

08:06:31.609 --> 08:06:35.209
environment, if the test failed,
there is no way to debug it 

08:06:35.514 --> 08:06:39.001
locally.  So the virtual device 
environment we built, we have to

08:06:39.264 --> 08:06:41.772
make sure the environment is 
reproducible regardless of what 

08:06:42.454 --> 08:06:45.199
they are running.  So the 
management solution helps you to

08:06:45.518 --> 08:06:48.994
run things locally or on the 
cloud.  And one of the big 

08:06:49.391 --> 08:06:54.202
things about this environment is
the device starts in a clean, 

08:06:54.617 --> 08:06:59.182
pristine state.  So there is no 
state carried forward with 

08:06:59.891 --> 08:07:02.924
different invocations, making 
sure the state is stable and not

08:07:03.283 --> 08:07:07.958
failed because of the device 
itself.  Android Shell.  There 

08:07:08.559 --> 08:07:13.529
are several teams within Google 
that indicate when you are 

08:07:13.882 --> 08:07:17.084
writing native code.  To test 
the native code, we wanted to 

08:07:17.467 --> 08:07:23.095
boot up on devices.  And booting
up on devices were slow.  On 

08:07:23.543 --> 08:07:27.055
nougat, it takes 10 minutes.  
And this is slowing it down 

08:07:27.212 --> 08:07:30.575
tremendously.  This made us go 
back to the drawing board to see

08:07:30.826 --> 08:07:33.425
what can we do to decrease the 
time it takes to boot up

08:07:37.655 --> 08:07:40.849
those devices.
So we ended up going and 

08:07:41.267 --> 08:07:44.405
creating a miniboot mode in 
virtual device.  What does 

08:07:46.614 --> 08:07:50.601
miniboot mode mean? You don't 
need the Android stack to be up 

08:07:50.602 --> 08:07:54.705
and running, you need the Linux 
kernel, if it is up and running,

08:07:55.047 --> 08:08:01.252
you can test the native APIs.  
We added it to the device 

08:08:01.542 --> 08:08:07.040
launcher, comes up in less than 
30 seconds, allowing them to 

08:08:08.204 --> 08:08:16.555
test the native code quickly.
 Because we were running things 

08:08:16.868 --> 08:08:19.974
at scale, we were looking at 
where we were spenting our time.

08:08:19.975 --> 08:08:26.209
25 percent of the time was spent
booting up the emulator, 

08:08:26.432 --> 08:08:28.593
installing the app, and 20 
percent of the time was spent in

08:08:28.594 --> 08:08:35.774
running the test itself.
Android made a change between 

08:08:36.014 --> 08:08:38.014
lollipop and

08:08:39.630 --> 08:08:44.260
nuugat, they wanted an error at 
time compilation.  

08:08:44.261 --> 08:08:48.139
And because the stacks were so 
huge, we ended up -- you have 

08:08:48.514 --> 08:08:53.677
the same device and ach on the 
test that is being tested and 

08:08:53.678 --> 08:09:00.113
the same Dex2O at every session.
What if we moved this as a 

08:09:01.183 --> 08:09:06.420
single action on the Bazel bell 
graph and reused the old file 

08:09:07.167 --> 08:09:11.653
that was generated for the test 
runs? This reduced the install 

08:09:11.654 --> 08:09:15.967
time from 3 minutes to under a 
minute.

08:09:15.968 --> 08:09:21.054
When the emulator team presented
about snapshots, you can boot it

08:09:21.351 --> 08:09:25.687
up, and shut it down, when you 
restart it, it restarts back 

08:09:26.068 --> 08:09:29.384
from the same state.  We 
integrated the snap shot feature

08:09:29.655 --> 08:09:34.041
into virtual device launcher, 
you boot it up, take a snap 

08:09:34.308 --> 08:09:38.633
shot, shut it down and reuse it 
when the test runs. This reduced

08:09:38.929 --> 08:09:42.663
test run times by 30 percent.  
When you run tests at 2.4

08:09:46.509 --> 08:09:49.475
invocations, it yields a huge 
number of -- you save huge 

08:09:49.695 --> 08:09:52.666
amounts of CPU resources.
One of the other features

08:09:56.493 --> 08:10:00.017
we wanted to work next year is 

08:10:03.160 --> 08:10:05.856
snapshots.
And this, we come to the end of 

08:10:05.857 --> 08:10:09.987
the talk, with nitrogen, you can
run the test at scale in a 

08:10:11.895 --> 08:10:16.638
completely stable environment 
with the different pillars. This

08:10:16.639 --> 08:10:19.175
is the stabilization platform to
help you test.  In this talk, we

08:10:19.451 --> 08:10:26.036
did a lot of technical stuff 
like activity controller, you 

08:10:26.457 --> 08:10:28.662
don't have to worry about all of
those things, they are 

08:10:29.210 --> 08:10:33.157
incorporated in Nitrogen and the
virtual device management 

08:10:33.431 --> 08:10:34.898
solution, you just have to use 
this.

08:10:34.899 --> 08:10:40.063
So we are hoping to release 
nitrogen alpha in Q1 of next 

08:10:40.064 --> 08:10:43.841
year, and the virtual device 
management solution is going to 

08:10:44.528 --> 08:10:48.265
be released the same time as 
well.  Firebase test lab is 

08:10:49.136 --> 08:10:51.203
actually integrating with 
nitrogen as well to run your 

08:10:51.658 --> 08:10:55.374
tests.  And one of the things 
that Steven pointed out earlier 

08:10:58.097 --> 08:11:03.190
about integration with Android 
Studio, imagine you are sitting 

08:11:05.688 --> 08:11:10.430
in Android Studio, you launch 
the device from there  the tests

08:11:10.578 --> 08:11:14.722
and it give gives you the 
results.

08:11:14.723 --> 08:11:16.723
That's it.  Thank you very 

08:11:22.467 --> 08:11:22.959
much.
[ Applause ]. 

08:11:22.960 --> 08:11:28.110
SPEAKER: Well, hey, everyone.
I wanted to thank you all for 

08:11:28.396 --> 08:11:34.356
coming and attending the Android
Dev Summit.  It is really, 

08:11:34.993 --> 08:11:39.550
really amazing to do this again.
We want to know what you think, 

08:11:39.551 --> 08:11:42.649
this is really important.  All 
of you will get a survey in your

08:11:43.589 --> 08:11:47.296
inbox.  Please fill it out, 
because it is -- we so much want

08:11:47.297 --> 08:11:51.049
to make this event amazing, 
should we ever do it again, we 

08:11:51.418 --> 08:11:55.962
really want to know what worked 
and didn't work, what you liked,

08:11:56.742 --> 08:12:00.660
didn't like.  And the second 
thing is, we are going to -- we 

08:12:00.661 --> 08:12:04.436
have these QR codes that we can 
put up one more time hopefully. 

08:12:04.733 --> 08:12:08.110
And these are how you rate the 
sessions.  We want to know what 

08:12:08.382 --> 08:12:12.612
sessions you loved, what 
sessions you liked, what 

08:12:12.974 --> 08:12:14.974
sessions you sat through because
they were there in the same room

08:12:15.231 --> 08:12:22.200
and you were kind of comfort  
comfortable in your seat.  

08:12:22.201 --> 08:12:26.231
Please fill out the surveys, I 
know it is a lot of work, but we

08:12:26.232 --> 08:12:30.482
appreciate  appreciate that.  If
you miss anything, all of the 

08:12:30.703 --> 08:12:32.703
talks are up right

08:12:34.585 --> 08:12:39.935
now on the Android developer's 
YouTube channel.  From yesterday

08:12:40.213 --> 08:12:45.091
and most of them from today are 
already going up.  And by the 

08:12:45.424 --> 08:12:48.436
end of tonight, all of them are 
on the channel.  You can go home

08:12:48.766 --> 08:12:53.501
tonight, if you have not enough 
Android Dev Summit by now, you 

08:12:53.994 --> 08:12:57.076
can have more from the comfort 
of your very own history museum.

08:12:57.613 --> 08:13:02.103
And finally, we have a little 
bit of a final reel here of some

08:13:02.366 --> 08:13:08.734
of what was going on here that 
we should share to you as you 

08:13:08.735 --> 08:13:11.387
think about wandering out here 
and going back to the real 

08:13:11.791 --> 08:13:14.197
world.  So thank you so much for
coming again.

08:13:23.021 --> 08:13:25.021
[ Applause ]

