WEBVTT
Kind: captions
Language: en

00:00:00.120 --> 00:00:03.700
Have you ever wanted to see what goes on inside a robot's mind?

00:00:03.840 --> 00:00:07.660
[INTRO MUSIC]

00:00:08.100 --> 00:00:09.920
Hey guys, Amy here for DNews.

00:00:09.920 --> 00:00:12.820
We see robots make decisions for themselves every day.

00:00:12.820 --> 00:00:15.080
Think about an autopilot system in an airplane.

00:00:15.100 --> 00:00:17.880
These systems can take information about the environment around them

00:00:17.880 --> 00:00:19.740
and have the plane function accordingly.

00:00:19.740 --> 00:00:22.780
But what actually happens inside that robotic thought process?

00:00:22.780 --> 00:00:27.160
A team of scientists and grad students at MIT wanted to get a glimpse inside the robot brain

00:00:27.160 --> 00:00:31.620
and so they developed a way to visually represent what goes on when a machine makes a decision.

00:00:31.780 --> 00:00:35.440
In their experiment, the decision was a pretty straightforward one: how to cross a room without

00:00:35.440 --> 00:00:36.850
hitting a pacing human.

00:00:36.850 --> 00:00:40.600
The visualization system they developed is called measurable virtual reality.

00:00:40.600 --> 00:00:45.760
It uses an array of 18 motion-capture cameras on the ceiling to track multiple simultaneous movements.

00:00:45.800 --> 00:00:49.460
Computer software then rendered the robotic processes that we can't see,

00:00:49.460 --> 00:00:52.560
projecting the information visually on the ground in the test space.

00:00:52.560 --> 00:00:54.900
That rendering was the robot's thought process.

00:00:54.900 --> 00:00:58.700
A large pink dot marked the robot's perception of the pedestrian's position.

00:00:58.700 --> 00:01:03.300
A series of lines crossing the floor represented the possible routes the robot was considering taking.

00:01:03.440 --> 00:01:07.500
These routes were colour coded, the green line marking the optimal route across the room.

00:01:07.500 --> 00:01:10.380
But the environment was always changing, and here's where it gets interesting.

00:01:10.380 --> 00:01:15.800
The pink dot behind the pedestrian moved as he paced, and the route lines shifted in response to these changes.

00:01:15.880 --> 00:01:19.220
The robot understood the changes to the room and changed its possible routes.

00:01:19.260 --> 00:01:23.780
This visualization of a robot's thought process is really neat, but thereâ€™s a practical side to it, too.

00:01:23.820 --> 00:01:26.520
The researchers realized that in projecting the robots' thoughts they

00:01:26.520 --> 00:01:31.140
could see underlying problems in algorithms and make the necessary fixes much faster.

00:01:31.160 --> 00:01:36.400
It's the kind of insight into robotic minds that could lead to better autopilot systems and drones in the future.

00:01:36.520 --> 00:01:39.960
Because there's no shortage of uncertainty for robots to deal with in the real world,

00:01:39.960 --> 00:01:43.660
so helping give them better brains to process those uncertainties could only be an improvement.

00:01:43.660 --> 00:01:47.260
And maybe we'll see a consumer spinoff version of this visualization system that will let

00:01:47.270 --> 00:01:50.190
us see what Roombas are thinking as they vacuum a room.

00:01:50.190 --> 00:01:53.610
How much fun would you guys have with a Roomba that showed you exactly what it was thinking

00:01:53.620 --> 00:01:55.240
as it moved throughout your house?

00:01:55.240 --> 00:01:59.380
Let us know in the comments below or you can catch me on Twitter as @astVintageSpace.

00:01:59.380 --> 00:02:02.120
And don't forget to subscribe for more DNews every day of the week.

