WEBVTT
Kind: captions
Language: en

00:00:00.700 --> 00:00:04.649
Okay, so
we'll finish up Markov chains today, and

00:00:04.649 --> 00:00:08.430
welcome to our Pen
ultimate Stat 110 lecture.

00:00:08.430 --> 00:00:13.985
So remind me what we were doing well last
time, we were talking about reversible.

00:00:13.985 --> 00:00:17.687
Well a lot of things got Markov chains,
but most importantly last time,

00:00:17.687 --> 00:00:20.250
we're talking about
reversible Markov chains.

00:00:20.250 --> 00:00:25.290
We did the example, a random walk
on an undirected network, right?

00:00:25.290 --> 00:00:29.850
And there's another important example
of reversible MArkov chains is

00:00:29.850 --> 00:00:34.410
birth-death chains, which I think
you can read about on the handout.

00:00:34.410 --> 00:00:38.538
It's worth working it through, but
I wanted to talk about one kind of

00:00:38.538 --> 00:00:43.690
generalization while we're still
talking about reversible Markov chains.

00:00:43.690 --> 00:00:48.760
So just to remind you from last time, and
then we'll try to extend it a little bit.

00:00:48.760 --> 00:00:54.650
We were looking at random undirected
graph or undirected network.

00:00:54.650 --> 00:00:57.909
It looks something like,
I'm just gonna draw a picture.

00:00:57.909 --> 00:01:03.709
You have a bunch of nodes and
some of them have edges between them and

00:01:03.709 --> 00:01:07.040
they're not one way arrows, right?

00:01:07.040 --> 00:01:12.877
They're bidirectional, so you can go,
let say from 1 to 2 and 2 to 4 and

00:01:12.877 --> 00:01:17.992
1 to 4 and 3 to 4 and
maybe there's a 5 here that can goes to 3.

00:01:17.992 --> 00:01:22.720
And so whatever we wanna draw,
we have a picture that looks like this.

00:01:22.720 --> 00:01:27.460
And if we want, we can add loops which
we didn't worry about last time.

00:01:27.460 --> 00:01:33.340
But it's no big deal, we could have
an edge connecting it, a node to itself.

00:01:33.340 --> 00:01:36.360
The only thing we have to be careful about
there is there are different conventions

00:01:36.360 --> 00:01:39.200
for what does this
contribute to the degree.

00:01:39.200 --> 00:01:43.020
So remember the degree of each node
is just the number of edges and

00:01:43.020 --> 00:01:46.350
some people like to count the degree
in different ways for this.

00:01:46.350 --> 00:01:47.984
Well let's just assume this counts as 1.

00:01:47.984 --> 00:01:52.803
So in this picture node 1 has degree 3,
cuz there's this edge to itself,

00:01:52.803 --> 00:01:55.530
and then two edges that are going out.

00:01:55.530 --> 00:01:59.805
We got a picture that looks like this,
and we proved last time that

00:01:59.805 --> 00:02:05.032
the stationary probability of any node
is proportional to its degree, right?

00:02:05.032 --> 00:02:10.470
And that is, we don't have to do
any matrix calculations at all.

00:02:10.470 --> 00:02:12.840
If we want the stationary
distribution of the Markov chain,

00:02:12.840 --> 00:02:15.126
which is just randomly wandering
around on this network.

00:02:15.126 --> 00:02:19.200
All we have to do is list out
the vector of all the degrees.

00:02:19.200 --> 00:02:26.282
This has degree 3, this has degree 2, and
just count the number of edges, right?

00:02:26.282 --> 00:02:29.444
And then normalize that vector,
so that multiply by a constant so

00:02:29.444 --> 00:02:32.850
that it adds up to 1, and
then that's the stationary distribution.

00:02:32.850 --> 00:02:35.520
We proved that last time
using reversibility.

00:02:35.520 --> 00:02:39.594
So now I wanted to extend
that a little bit and say,

00:02:39.594 --> 00:02:45.705
well what would actually happen if we,
so we were assuming last time that,

00:02:45.705 --> 00:02:50.880
let's say you're here at state 4 and
you see three choices.

00:02:50.880 --> 00:02:52.648
We assume they're all equally likely,
right?

00:02:52.648 --> 00:02:54.190
So one-third, one-third, one-third.

00:02:54.190 --> 00:02:59.110
So a natural question is
what happens if certain

00:02:59.110 --> 00:03:04.060
edges are more likely for
some reason, right?

00:03:04.060 --> 00:03:06.498
That they're unequal weights, so

00:03:06.498 --> 00:03:10.328
to handle that all we need to
do is put down some weights.

00:03:10.328 --> 00:03:17.560
So let's call this w12, I'm just gonna
put little weights on the edges.

00:03:17.560 --> 00:03:21.286
This is w11,
w14 I'm not gonna fill them all in.

00:03:21.286 --> 00:03:27.420
In general, let's say we have wij,
Greater than or

00:03:27.420 --> 00:03:29.530
equal to 0, we call that an edge weight.

00:03:32.431 --> 00:03:37.936
And let's assume that wij = 0,

00:03:37.936 --> 00:03:43.842
if there's no edge there, right?

00:03:43.842 --> 00:03:46.705
That just means you can't get
from i to j in one step, so

00:03:46.705 --> 00:03:48.210
we just give that weight 0.

00:03:48.210 --> 00:03:50.940
And then the other ones,

00:03:50.940 --> 00:03:57.060
which is just let's say it's greater or
equal to well.

00:03:57.060 --> 00:04:01.548
We can assume it's strictly greater that
if they are actually is an edge, but

00:04:01.548 --> 00:04:05.359
it doesn't actually matter,
as long as we avoid dividing by 0.

00:04:05.359 --> 00:04:11.010
And then our key assumption is that
wij = wji, that's an assumption.

00:04:11.010 --> 00:04:15.861
Another way to say that is because we're

00:04:15.861 --> 00:04:21.149
talking about random undirected network.

00:04:21.149 --> 00:04:23.770
And I only wrote one number here, w12.

00:04:23.770 --> 00:04:27.100
Maybe w12 is 3, it's just some number.

00:04:27.100 --> 00:04:30.727
But I'm not allowed to write one number
that applies going this direction,

00:04:30.727 --> 00:04:34.421
and another number that applies this
direction, so the same number, okay?

00:04:34.421 --> 00:04:40.984
So we may as well just express that
as a symmetry condition, wij = eji.

00:04:40.984 --> 00:04:46.557
And now the way the random walk proceeds
is that, so here's our random walk,

00:04:46.557 --> 00:04:52.850
analogous to what we did before, except
we're generalizing with these weights.

00:04:52.850 --> 00:04:58.466
All we do is we say, okay,
suppose that we are at state 4, and

00:04:58.466 --> 00:05:05.607
then I see there's 3 different possible
edges, and each one has its weight.

00:05:05.607 --> 00:05:07.560
And we look at these three choices and

00:05:07.560 --> 00:05:11.025
then we just choose proportional
to the weights, right?

00:05:11.025 --> 00:05:14.125
So if we let all the weights be 1, then
we do one-third, one-third, one-third,

00:05:14.125 --> 00:05:18.745
but maybe w24 is relatively larger, right?

00:05:18.745 --> 00:05:19.821
It's just proportional.

00:05:19.821 --> 00:05:21.745
So from state i,

00:05:26.134 --> 00:05:34.706
Go to j with probability
proportional to wij.

00:05:34.706 --> 00:05:43.630
Looks like an alpha, that's
proportionality symbol to wij, okay?

00:05:43.630 --> 00:05:47.565
So if wij is 0,
then obviously it says we don't go there.

00:05:47.565 --> 00:05:50.284
So we look at all
the available choices and

00:05:50.284 --> 00:05:54.569
choose what probability's
proportional to the weights we see.

00:05:54.569 --> 00:05:59.544
So that's the generalization
of the problem, and

00:05:59.544 --> 00:06:02.910
let's solve in an analogous way.

00:06:02.910 --> 00:06:06.225
This is still gonna be reversible, so

00:06:06.225 --> 00:06:11.530
we wanna write down reversibility
equation siqij = sjqji.

00:06:11.530 --> 00:06:15.876
Okay, let's first write down what's qij?

00:06:15.876 --> 00:06:17.652
So if ij is actually an edge,

00:06:17.652 --> 00:06:21.280
if it's not an edge the probability
is 0 going from i to j.

00:06:21.280 --> 00:06:24.680
If it is an edge,
that is there is an edge there,

00:06:27.172 --> 00:06:32.249
Then by definition qij,
the transition probability

00:06:32.249 --> 00:06:37.322
from state i to state j by
definition is just the weight

00:06:37.322 --> 00:06:41.520
divided by the sum of
the possible weights.

00:06:41.520 --> 00:06:45.050
That is the sum of the weights
of the possible steps, right?

00:06:45.050 --> 00:06:51.178
Code proportional, so this'll be the
denominator will just be the sum of wik,

00:06:51.178 --> 00:06:56.290
over all k, All right?

00:06:56.290 --> 00:07:01.202
And we're assuming that the denominator is
non-zero, because we have to be able to

00:07:01.202 --> 00:07:04.400
do something, so
we don't all weight 0, all right?

00:07:04.400 --> 00:07:09.659
So that's the random walk,
but notice that then

00:07:09.659 --> 00:07:15.556
it's true that if we, so
in the case without weights,

00:07:15.556 --> 00:07:20.320
just think of all these wijs as one,
right?

00:07:20.320 --> 00:07:23.610
And so then this is just one over
the degree of i in that case.

00:07:23.610 --> 00:07:29.370
And in that case, the stationary
distribution proportional to degrees.

00:07:29.370 --> 00:07:33.943
So the analogue of that is that instead
of the degree we're looking at the sum of

00:07:33.943 --> 00:07:34.790
the weights.

00:07:34.790 --> 00:07:40.767
That is from state i, we look at all
these weights and we add them up, right?

00:07:40.767 --> 00:07:49.303
So okay, if we do that notice that,
If we take the sum of,

00:07:49.303 --> 00:07:54.914
I'm just gonna multiply by
this denominator here, right?

00:07:54.914 --> 00:07:59.143
So I'll take this thing,
sum of overall k, Of w i j,

00:07:59.143 --> 00:08:03.550
that's the generalization of
degree to the weighted case.

00:08:03.550 --> 00:08:06.749
And if we multiply by q i j,

00:08:09.893 --> 00:08:16.380
Then that just cancels the denominator,
which is why I chose that, [LAUGH] okay?

00:08:16.380 --> 00:08:21.589
That's w i j, but
by assumption, w i j = w j i,

00:08:21.589 --> 00:08:29.343
so that would be the same thing as if
we did it the other way around, and

00:08:29.343 --> 00:08:34.596
did the sum over all k of w,
this should be w i k.

00:08:34.596 --> 00:08:36.495
So it's summing over all,
k is a dummy variable.

00:08:36.495 --> 00:08:38.750
Sum over all k, w i k.

00:08:38.750 --> 00:08:43.998
And here we (sum over all k, w j k)q j i

00:08:45.538 --> 00:08:49.380
That's the reversibility equation.

00:08:49.380 --> 00:08:54.162
So therefore, the stationary distribution,

00:08:54.162 --> 00:08:58.704
S i,
the stationary probability of state i,

00:08:58.704 --> 00:09:04.576
is proportional to this
generalized degree, w i k over k.

00:09:05.989 --> 00:09:09.425
This is proportionality, but
if we wanna know what it's equal to,

00:09:09.425 --> 00:09:11.910
we would just divide by
the sum of this over all i.

00:09:13.960 --> 00:09:19.520
So this is completely analogous to what
we did last time, but it's good practice.

00:09:19.520 --> 00:09:24.582
And all we did was just multiply
both sides by this denominator,

00:09:24.582 --> 00:09:27.406
and used the symmetry, w i j = w j i.

00:09:27.406 --> 00:09:34.733
Then we get the stationary distribution
without needing to do any matrices.

00:09:34.733 --> 00:09:37.786
So I don't know if this seems
like a small generalization or

00:09:37.786 --> 00:09:40.300
a large generalization of
what we did last time.

00:09:41.400 --> 00:09:43.734
It's a generalization of
what we did last time.

00:09:46.110 --> 00:09:53.950
Actually, this is completely general,
reversible Markov chain.

00:09:53.950 --> 00:09:56.690
So this is actually a complete
generalization, in the sense that if we

00:09:56.690 --> 00:10:01.620
have any reversible Markov chain,
we can actually interpret it this way.

00:10:01.620 --> 00:10:07.440
So In a sense, this is the entire
theory of reversible Markov chains.

00:10:07.440 --> 00:10:12.948
Not exactly, because,
if you have a reversible Markov chain,

00:10:12.948 --> 00:10:18.010
and you know what the S i is,
then you're in good shape.

00:10:18.010 --> 00:10:19.570
But if you don't know that,

00:10:19.570 --> 00:10:22.720
it may not be obvious to figure
out what are the stationary.

00:10:22.720 --> 00:10:28.100
What is the S i, such that S i,
q i j equals S j, q j i, okay?

00:10:28.100 --> 00:10:32.689
But it's a theorem that any
reversible Markov chain can be

00:10:32.689 --> 00:10:34.850
represented in this form.

00:10:36.940 --> 00:10:40.786
So just to quickly see why that's true.

00:10:44.062 --> 00:10:48.920
So any reversible chain can
be thought of this way.

00:10:48.920 --> 00:10:53.470
It may not be obvious to figure out
how to come up with the w i j's and

00:10:53.470 --> 00:10:54.430
stuff like that.

00:10:54.430 --> 00:10:59.201
But at least in principle,
it can be written this way,

00:10:59.201 --> 00:11:02.539
any reversible chain is of this form.

00:11:11.511 --> 00:11:13.300
So why is that true?

00:11:13.300 --> 00:11:16.180
Well, we just need to define the w i j's.

00:11:16.180 --> 00:11:23.320
It's pretty obvious what network we should
use, just the nodes are the states,

00:11:23.320 --> 00:11:28.520
and we put edges whenever
q i j is positive, right?

00:11:28.520 --> 00:11:32.449
And all we need to do is just say,
what are the weights?

00:11:34.080 --> 00:11:39.836
So to do that, let's just say okay,

00:11:39.836 --> 00:11:43.001
let w i j = S i, q i j.

00:11:43.001 --> 00:11:46.870
That's the thing that we wanted, right?

00:11:46.870 --> 00:11:50.927
But S i j, q i j, right now I'm
assuming it's reversible, and

00:11:50.927 --> 00:11:54.772
I wanna show that the Markov
chain can be viewed in this way.

00:11:56.170 --> 00:12:00.440
So I'm assuming we already have the S and
the q, and I wanna define the weights,

00:12:00.440 --> 00:12:05.320
such that the Markov chain just
is this particular random walk..

00:12:05.320 --> 00:12:12.041
So if we define the weight i j to be S i,
q i j, but since it's reversible,

00:12:12.041 --> 00:12:18.260
that's the same thing as S j,
q j i, so that would be our w j i.

00:12:18.260 --> 00:12:22.160
So we will have this condition hold.

00:12:22.160 --> 00:12:26.494
And all we have to do to check
that this works is to show that,

00:12:26.494 --> 00:12:32.064
if we define the weights this way, and
just do this particular random walk.

00:12:32.064 --> 00:12:36.497
Let's show that it has the transition
probablies that we want,

00:12:36.497 --> 00:12:37.830
which are the q i j.

00:12:37.830 --> 00:12:40.510
So in other words,
we're assuming we have q i j,

00:12:40.510 --> 00:12:42.470
that's our Markov chain
that we're interested in.

00:12:42.470 --> 00:12:45.450
And we're assuming that it's reversible,
so this holds.

00:12:45.450 --> 00:12:49.235
And we're showing that it can
be written in this way, right?

00:12:49.235 --> 00:12:53.715
Well, do do that, at this point, all
we have to do is check that this chain,

00:12:53.715 --> 00:12:58.055
which is random walk on this network,
with the weights defined this way,

00:12:58.055 --> 00:13:01.980
has the transition probabilities
that we want, right?

00:13:01.980 --> 00:13:04.590
Which are q i j by definition, okay?

00:13:04.590 --> 00:13:07.310
So what are the transition
probabilities here?

00:13:07.310 --> 00:13:11.787
Well, I'll just write it as,
what's the probability of X n+1,

00:13:11.787 --> 00:13:15.017
if this X process is random
walk on this network.

00:13:15.017 --> 00:13:20.850
X n+1 = j given X n = i, that's
the transition probability that we have.

00:13:21.880 --> 00:13:26.540
Well, by definition, how do we find
the transition probability from i to j?

00:13:26.540 --> 00:13:29.710
Well, that says okay, we're at state i,
we look around everywhere,

00:13:29.710 --> 00:13:31.050
where are the available edges?

00:13:31.050 --> 00:13:33.206
We look at all their weights, and

00:13:33.206 --> 00:13:36.983
we choose to go to j with
probability proportional to w i j.

00:13:36.983 --> 00:13:38.690
That's the definition of the random walk.

00:13:38.690 --> 00:13:43.726
So the probability is w i j over

00:13:43.726 --> 00:13:48.366
the sum of w i k over all of k.

00:13:48.366 --> 00:13:51.530
That's just the definition of how
we did the random walk, right?

00:13:51.530 --> 00:13:56.131
Now if we plug in what's w i j,

00:13:56.131 --> 00:13:59.259
w i j is S i, q i j, and

00:13:59.259 --> 00:14:04.239
we divide by the sum of S i, q i k.

00:14:04.239 --> 00:14:07.994
I'm just plugging in how we defined,
we defined the weights in this way,

00:14:07.994 --> 00:14:09.760
I'm plugging in the definition.

00:14:10.930 --> 00:14:16.001
Now let's just simplify this So
this S i in

00:14:16.001 --> 00:14:22.030
the denominator does not depend on k,
so we can take that out of the sum.

00:14:22.030 --> 00:14:24.410
I'm assuming that the S i's are positive.

00:14:24.410 --> 00:14:28.785
It's not a very interesting chain if
some stationery probabilities zero,

00:14:28.785 --> 00:14:33.314
then we should have just restricted
the space, and not included them anyway.

00:14:33.314 --> 00:14:36.250
So I'm assuming we're not
dividing by zero here.

00:14:36.250 --> 00:14:42.019
S i's cancel, so this is just q
i j divided by the sum q i k.

00:14:42.019 --> 00:14:46.210
All right, well, what's the sum of q i k?

00:14:48.470 --> 00:14:52.270
It's 1, that should be quick, as it says.

00:14:53.780 --> 00:14:55.174
Why is that 1?

00:14:56.440 --> 00:15:01.348
Because it's a Markov chain, so
you have to go from i to somewhere,

00:15:01.348 --> 00:15:04.930
so that's 1, so that's just q i j.

00:15:06.040 --> 00:15:07.096
So in other words,

00:15:07.096 --> 00:15:11.322
this chain that we constructed has
the desired transition probabilities.

00:15:11.322 --> 00:15:16.727
Okay, so
this is the quintessential prototypical

00:15:16.727 --> 00:15:20.880
example of a reversible Markov chain.

00:15:20.880 --> 00:15:23.781
It's a random walk on and
undirected network,

00:15:23.781 --> 00:15:26.763
where possibly we put some
weights on the edges.

00:15:28.642 --> 00:15:31.270
So that's the reversible case.

00:15:31.270 --> 00:15:37.556
And I wanted to do one example
of a non-reversible chain.

00:15:37.556 --> 00:15:42.230
That non-reversible, in general,
is gonna be much more difficult, right?

00:15:42.230 --> 00:15:47.150
In the reversible case, it just really
has a lot of really nice properties,

00:15:47.150 --> 00:15:51.260
both intuitively, cuz you think about
time running backwards and forwards.

00:15:51.260 --> 00:15:56.225
And practically, you can avoid matrix
stuff a lot of times, things like that.

00:15:56.225 --> 00:16:04.616
Non-reversible We can still think of it
as random walk on a network with weights,

00:16:04.616 --> 00:16:10.180
except that we have arrows,
maybe one way arrows or two way arrows.

00:16:10.180 --> 00:16:14.060
And you can have different
weights in both directions.

00:16:14.060 --> 00:16:18.740
That extra generality makes it much,
much, much harder, okay?

00:16:18.740 --> 00:16:27.420
So just wanna do one example
of a non-reversible chain.

00:16:27.420 --> 00:16:33.611
Non-reversible example.

00:16:36.540 --> 00:16:43.171
Okay, and then that example is Google,

00:16:43.171 --> 00:16:48.632
Google Chain, more precisely,

00:16:48.632 --> 00:16:51.762
Google PageRank.

00:16:54.956 --> 00:17:01.607
Google PageRank, which was the algorithm
that Google originally used,

00:17:01.607 --> 00:17:07.717
and still is using some form of,
is based exactly on a Markov chain,

00:17:07.717 --> 00:17:12.100
and it happens to be
a non-reversible chain.

00:17:12.100 --> 00:17:16.210
And I want to tell you
about what that chain is,

00:17:16.210 --> 00:17:20.350
how it's useful, where that came from.

00:17:20.350 --> 00:17:26.500
Okay, so this is just one example, but
this is a very big, important example.

00:17:26.500 --> 00:17:27.895
Has anyone here heard of Google?

00:17:27.895 --> 00:17:32.620
&gt;&gt; [LAUGH]
&gt;&gt; Okay, well if not, Google for it, and

00:17:32.620 --> 00:17:35.555
you'll find a lot of stuff there.

00:17:35.555 --> 00:17:38.760
&gt;&gt; [LAUGH]
&gt;&gt; It's a search engine.

00:17:38.760 --> 00:17:41.050
And, it's all based on MAakov chains.

00:17:41.050 --> 00:17:45.090
So I basically wanna
explain how that works.

00:17:45.090 --> 00:17:50.180
So, well,
you can kind of guess that what the chain,

00:17:50.180 --> 00:17:55.140
the states are gonna be, webpages, right?

00:17:55.140 --> 00:18:00.650
And the links are gonna be links,
right, hyperlinks.

00:18:00.650 --> 00:18:05.700
That is, we have the entire World Wide
Web, and some pages link to other pages,

00:18:05.700 --> 00:18:08.576
and that's gonna form a Markov chain.

00:18:08.576 --> 00:18:11.810
We're gonna look at the stationary
distribution of that chain and

00:18:11.810 --> 00:18:13.130
see what we can say.

00:18:13.130 --> 00:18:14.710
It's not gonna be reversible, so

00:18:14.710 --> 00:18:17.330
we can't just write down the stationary
distribution as easily as there.

00:18:17.330 --> 00:18:21.410
But we can still talk about how
could you try to compute that thing.

00:18:21.410 --> 00:18:25.670
Especially, considering
how large the web is.

00:18:25.670 --> 00:18:27.870
Okay, so just for
the sake of having a picture,

00:18:28.870 --> 00:18:33.160
let's assume that the World Wide Web
only has four pages.

00:18:34.450 --> 00:18:39.240
Which is an underestimate, but at least
I can draw something conceptually.

00:18:39.240 --> 00:18:40.960
So, there's only four pages on the web.

00:18:40.960 --> 00:18:43.220
I just made up a little example.

00:18:43.220 --> 00:18:48.310
So, we have four webpages,
numbered one through four, and

00:18:48.310 --> 00:18:51.840
as I said, we're gonna draw
arrows that just represent links.

00:18:51.840 --> 00:18:54.280
So, it's just this example that I made up.

00:18:54.280 --> 00:18:57.430
Page number 1 links to page number 3,
that is, if you go to this web page,

00:18:57.430 --> 00:19:00.390
you see a link that takes
you to this web page.

00:19:00.390 --> 00:19:05.010
Okay, page 1 links to page 2,
page 2 links back to page 1.

00:19:05.010 --> 00:19:08.670
Page 3 is not so nice,
they don't link back to page 1.

00:19:08.670 --> 00:19:14.325
Page 2 links to page 3 and
page 3 only links to page 4.

00:19:15.680 --> 00:19:17.370
Page 4 has no links on it.

00:19:17.370 --> 00:19:18.958
Not every web page links to other pages.

00:19:18.958 --> 00:19:20.820
It may just be that page, all right?

00:19:20.820 --> 00:19:25.599
So that's an oversimplification
of the web, but

00:19:25.599 --> 00:19:29.024
this gives you something to think.

00:19:29.024 --> 00:19:33.103
If you understand conceptually really
well what's going on with four pages,

00:19:33.103 --> 00:19:37.056
then you could imagine, in principle,
there could be billions of pages and

00:19:37.056 --> 00:19:39.675
you're just imaging a gigantic version.

00:19:39.675 --> 00:19:41.775
It's not a very complicated
link structure, but

00:19:41.775 --> 00:19:46.620
basically you just have web pages
linking to each other ,okay, so

00:19:46.620 --> 00:19:50.020
I wanna basically explain
what this algorithm does.

00:19:50.020 --> 00:19:52.720
Just to put it in context.

00:19:52.720 --> 00:19:57.780
I'll talk a little bit about
the earlier history of search engines.

00:19:57.780 --> 00:20:05.530
Google was started in 1998 by Brin and
Page, who were Stanford grad students.

00:20:05.530 --> 00:20:10.230
They ended up dropping out
to work full time on Google.

00:20:12.440 --> 00:20:16.150
The name is kind of convenient,
Brin and Page.

00:20:16.150 --> 00:20:21.230
Larry Page is kind of convenient for
him that Page is in the name PageRank,

00:20:21.230 --> 00:20:23.190
but it's also a pretty natural name.

00:20:23.190 --> 00:20:25.830
Right?
Because this is a way for

00:20:25.830 --> 00:20:28.210
ranking web pages.

00:20:28.210 --> 00:20:32.540
The basic problem is,
suppose you search for

00:20:32.540 --> 00:20:37.560
a certain thing you're interested in,
okay, and there might be millions or

00:20:37.560 --> 00:20:43.080
even billions of pages on the web
that contain that topic, right?

00:20:44.530 --> 00:20:49.947
So the fundamental question and
the insight that made Google way,

00:20:49.947 --> 00:20:54.795
way better than any of the other
alternatives at that time.

00:20:54.795 --> 00:20:59.756
I mean, now you can debate whether
their still the best or not, but

00:20:59.756 --> 00:21:01.615
at the time it was a huge,

00:21:01.615 --> 00:21:06.766
way beyond any of their competitors
in terms of the ranking, right?

00:21:06.766 --> 00:21:09.940
Because you don't have time to search
through a million, you're searching for

00:21:09.940 --> 00:21:13.220
chess and there's a million pages, you
don't have time to go through all of them.

00:21:13.220 --> 00:21:16.294
The question is,
which page should come up first, second,

00:21:16.294 --> 00:21:18.175
third, it's the ranking, right?

00:21:18.175 --> 00:21:22.496
All pages that match your query,
what order should those be displayed in?

00:21:22.496 --> 00:21:23.396
Okay?

00:21:23.396 --> 00:21:30.340
So the earlier websites took pretty
crude naive approaches to that question.

00:21:30.340 --> 00:21:35.290
For example, I mean some of the earlier
search engines were basically trying

00:21:35.290 --> 00:21:38.020
to be human curated, like a museum.

00:21:38.020 --> 00:21:41.610
You have someone who recommends
this page is really good, right?

00:21:41.610 --> 00:21:44.070
And obviously that doesn't scale so

00:21:44.070 --> 00:21:48.440
well when the web has billions and
billions of pages now.

00:21:48.440 --> 00:21:50.960
It didn't scale so well.

00:21:50.960 --> 00:21:53.850
And then, I don't know, so
maybe what else could they have done,

00:21:53.850 --> 00:21:57.590
like alphabetical or something like,
it's kind of useless.

00:21:57.590 --> 00:21:59.970
In some of the early search engines,

00:22:01.690 --> 00:22:06.450
the ordering was based on how many
times the page used that word, right.

00:22:06.450 --> 00:22:11.360
So if I'm looking for chess,
then a page that mentions chess 100 times

00:22:11.360 --> 00:22:14.840
must be much better than a page
that only mentions chess once.

00:22:15.880 --> 00:22:18.720
Okay, well obviously that
opens itself up to abuse.

00:22:18.720 --> 00:22:21.750
Right?
You can just list the dictionary on your

00:22:21.750 --> 00:22:23.740
site like repeated many times.

00:22:23.740 --> 00:22:27.580
But one thing, even if you're not
trying to abuse the system, just

00:22:27.580 --> 00:22:31.060
using the same word over and over again
doesn't mean that is the most reliable,

00:22:31.060 --> 00:22:34.100
insightful, useful page on that topic.

00:22:34.100 --> 00:22:34.601
Okay, so

00:22:34.601 --> 00:22:38.880
the earliest sites were not really using
the network structure of the web at all.

00:22:41.630 --> 00:22:46.490
Possibly AltaVista was one of
the first search engines that

00:22:46.490 --> 00:22:51.660
actually at least tried to do something
with the actual structure of the web.

00:22:51.660 --> 00:22:55.206
And so at some point it was
realized that actually,

00:22:55.206 --> 00:22:58.300
right, this is the worldwide
web is a network, and

00:22:58.300 --> 00:23:02.300
the structure of that network is valuable
information for doing these rankings.

00:23:02.300 --> 00:23:06.940
Okay, so then they started basically
saying that a page is important if

00:23:06.940 --> 00:23:11.440
a lot of other pages link to it, right?

00:23:11.440 --> 00:23:13.220
Which was a big improvement.

00:23:14.650 --> 00:23:17.740
The problems with that, well first of
all it's very easy to abuse that, right?

00:23:17.740 --> 00:23:22.030
Can easily just create thousands of
dummy pages linking to your page, but

00:23:22.030 --> 00:23:26.950
even aside from the abuse question,
it's like just because a certain page

00:23:26.950 --> 00:23:31.130
has a lot of other pages linking to it
that doesn't necessarily mean that it's

00:23:31.130 --> 00:23:35.900
that important if those pages that
link to it are garbage, right?

00:23:35.900 --> 00:23:41.030
So the insight of PageRank
was that the importance

00:23:41.030 --> 00:23:45.720
of a page should be based not just on
how many other pages link to it, but

00:23:45.720 --> 00:23:49.920
how important those pages are, right?

00:23:49.920 --> 00:23:51.900
So that's the key idea.

00:23:51.900 --> 00:23:54.320
So we have to try to make
that mathematical and

00:23:54.320 --> 00:23:56.490
then show how that
relates to Markov chains.

00:23:56.490 --> 00:24:01.663
But just intuitively, the importance of
a page as we want to rank the We wanna

00:24:01.663 --> 00:24:06.339
give each page a score for
how important it is, right?

00:24:06.339 --> 00:24:09.435
And rank them in order of
importance in this sense.

00:24:09.435 --> 00:24:13.280
Importance of page should be based,

00:24:13.280 --> 00:24:17.372
not only on which page is linking to it,

00:24:17.372 --> 00:24:22.718
the number of pages, and
the importance of each one

00:24:28.049 --> 00:24:33.179
Well, that sounds like a circular
definition that we define

00:24:33.179 --> 00:24:38.713
importance in terms of importance,
but that's okay actually,

00:24:38.713 --> 00:24:43.843
because that just suggests
an Eigenvector value equation,

00:24:43.843 --> 00:24:47.486
which will interpret it as a Markov chain.

00:24:47.486 --> 00:24:52.378
So if we let Si,
just think of S as standing for score.

00:24:52.378 --> 00:24:56.967
That is,
we're gonna give each web page a score.

00:24:56.967 --> 00:24:59.685
And let me just index it with j.

00:24:59.685 --> 00:25:02.248
So that's the score of the jth web page.

00:25:02.248 --> 00:25:06.417
And so, Brin and Paige Said, they defined,

00:25:06.417 --> 00:25:14.014
they said we wanna give each page a score,
such that SSJ equals the sum of Si, qij.

00:25:14.014 --> 00:25:21.259
And I'll tell you qij is,
summed over all i.

00:25:21.259 --> 00:25:25.430
qij, well,
they pointed out basically, I mean,

00:25:25.430 --> 00:25:30.765
a simple thing to do would just be
to let this score of the jth page be

00:25:30.765 --> 00:25:36.695
the sum of all the scores of all,
summed over all i that link to j, right?

00:25:36.695 --> 00:25:41.667
So in other words, if you're thinking
of a link, an incoming link,

00:25:41.667 --> 00:25:47.526
as recommending that page and add up all
the scores of the recommenders, right?

00:25:47.526 --> 00:25:52.644
Except the problem with that is that,
some pages may only have like one

00:25:52.644 --> 00:25:57.591
outgoing link and other pages may
have a thousand outgoing links and

00:25:57.591 --> 00:26:03.618
it seems a little unfair to count those
kind of as equal recommendations, right?

00:26:03.618 --> 00:26:07.352
So it's like imagine that a certain
page has a certain budget for

00:26:07.352 --> 00:26:12.192
how much stuff it can recommend, and so
if it recommends 1,000 pages by having

00:26:12.192 --> 00:26:16.089
1,000 links, then each of those
should be diluted, right?

00:26:16.089 --> 00:26:18.757
So that's what this qij is gonna do.

00:26:18.757 --> 00:26:24.032
So we're gonna let our matrix Q
just be the matrix we would get

00:26:24.032 --> 00:26:29.108
if we think of this as a Markov
chain just for this example.

00:26:29.108 --> 00:26:33.920
And we think of a Markov chain where
we're just randomly following links.

00:26:33.920 --> 00:26:39.007
So in this example I made up,
from page one you can go to page two or

00:26:39.007 --> 00:26:42.509
page three, assume equal probabilities.

00:26:42.509 --> 00:26:49.638
So it would do 0 1/2 1/2 0 it
goes to page two or page three.

00:26:49.638 --> 00:26:54.418
From page two you can go to page one or
page three.

00:26:54.418 --> 00:27:00.001
So from page 2 you can go to 1 or
3 so 1/2 0, 1/2 0.

00:27:00.001 --> 00:27:03.175
From page 3 you can only go to page 4.

00:27:03.175 --> 00:27:07.559
So that's just gonna be 0, 0, 0, 1.

00:27:07.559 --> 00:27:11.719
Page 4 is kind of annoying, right?

00:27:11.719 --> 00:27:16.697
They don't recommend anything,
they're just their own thing.

00:27:16.697 --> 00:27:21.854
But we actually want to
have a Markov chain here.

00:27:21.854 --> 00:27:26.619
So we assume that from page 4,
you can go anywhere on the web with

00:27:26.619 --> 00:27:31.299
equal probability, so
I'm gonna just change this to 1/4,

00:27:31.299 --> 00:27:34.683
1/4, that's if it links to everything.

00:27:34.683 --> 00:27:39.447
Okay, so you define Q in this way,
where doing all the links,

00:27:39.447 --> 00:27:42.574
but you're making each row sum up to 1.

00:27:42.574 --> 00:27:47.215
And if there's a page that has no
links then just make it 1 over

00:27:47.215 --> 00:27:50.090
the number of pages in the entire web.

00:27:51.410 --> 00:27:55.550
So this has a pretty natural
interpretation that you might call,

00:27:55.550 --> 00:27:58.108
that is what you imagine is you have, and

00:27:58.108 --> 00:28:03.074
this is kind of what they were thinking
about that part of the motivation I think

00:28:03.074 --> 00:28:07.844
that helped them as you imagine someone
randomly surfing the web, right?

00:28:07.844 --> 00:28:08.919
So what do you do?

00:28:08.919 --> 00:28:12.748
Well, you're Read a page for a while and
then you're done with that page.

00:28:12.748 --> 00:28:15.779
And if you're really bored,
just start clicking random links, right?

00:28:15.779 --> 00:28:20.290
Click a random link, it's a lot
of fun to do on Wikipedia, right?

00:28:20.290 --> 00:28:23.490
There was a good XKCD about that, right?

00:28:23.490 --> 00:28:27.750
Click a random link,
you keep clicking random links, right?

00:28:27.750 --> 00:28:29.297
Just randomly surfing the web.

00:28:29.297 --> 00:28:31.885
That's kind of a natural
thing to think about.

00:28:31.885 --> 00:28:37.647
And then, now what happens if you
reach a page that has no links,

00:28:37.647 --> 00:28:42.144
but you're not ready to
stop surfing the web yet?

00:28:42.144 --> 00:28:44.291
You don't give up in despair.

00:28:44.291 --> 00:28:47.931
Then the assumption is then
you just open a new window and

00:28:47.931 --> 00:28:50.574
just go to another random page, right?

00:28:50.574 --> 00:28:54.695
So then you can random walk instead of
being, you don't really wanna be trapped

00:28:54.695 --> 00:28:58.213
on that page forever just because
it doesn't have any links right?

00:28:58.213 --> 00:29:01.450
So that's what this chain is doing.

00:29:01.450 --> 00:29:07.638
Okay, so then this equation
should make some sense, right?

00:29:07.638 --> 00:29:13.429
The importance is based on the importance
of the pages that link to it.

00:29:13.429 --> 00:29:17.457
qij is zero, unless there's
actually a link from i to j.

00:29:17.457 --> 00:29:22.259
So you're only adding up the terms
where there actually is a link there.

00:29:22.259 --> 00:29:27.090
And then the qij's may not all be equal,
because of this dilution thing, all right?

00:29:27.090 --> 00:29:32.111
So in matrix notation now,
that just says that s,

00:29:32.111 --> 00:29:37.506
which is s is the vector of
all the page ranks, right?

00:29:37.506 --> 00:29:40.110
It is equal to s times Q.

00:29:44.007 --> 00:29:50.021
Ie, what does that say?

00:29:50.021 --> 00:29:52.490
That equation looks familiar, right?

00:29:52.490 --> 00:29:56.998
It says that s is
the stationary distribution.

00:29:56.998 --> 00:30:01.450
S is the stationary distribution for
this random web-surfing chain.

00:30:05.879 --> 00:30:10.120
Random web surfing,
random web surfing chain.

00:30:12.228 --> 00:30:18.186
Okay, so this has a natural interpretation
in terms of stationary distributions

00:30:18.186 --> 00:30:23.279
as well that is intuitively we think
of the stationary distribution as

00:30:23.279 --> 00:30:29.430
giving the long-run probabilities of
being in different states, right?

00:30:29.430 --> 00:30:34.448
Which says,
I'll just clarify that if s is normalized.

00:30:34.448 --> 00:30:40.140
Of course, if you have any solution to
this just divide by a constant to make,

00:30:40.140 --> 00:30:45.413
as long as you have non-negative
numbers here, so if s is normalized.

00:30:45.413 --> 00:30:48.222
So we just solve this matrix equation,
right?

00:30:48.222 --> 00:30:52.991
This is some gigantic
linear system of equations

00:30:52.991 --> 00:30:56.490
that is billions of pages, right?

00:30:56.490 --> 00:31:01.764
So if there are 10 billion web pages
then Q is gonna be a 10 billion by 10

00:31:01.764 --> 00:31:07.238
billion matrix, so this is an immensely
difficult computational problem.

00:31:07.238 --> 00:31:10.989
But in principle, all you're doing
is solving this linear system, and

00:31:10.989 --> 00:31:14.433
normalizing it, and
then that's the stationary distribution,

00:31:14.433 --> 00:31:16.782
by definition of stationary distribution.

00:31:16.782 --> 00:31:20.993
So in terms of the interpretation of
stationary distribution is the long run

00:31:20.993 --> 00:31:23.375
fraction of time being in a certain state.

00:31:23.375 --> 00:31:29.311
What this is saying is that, if you
imagine just randomly surfing the web for

00:31:29.311 --> 00:31:34.874
ages and ages and ages, and in the long
run this says that the importance

00:31:34.874 --> 00:31:41.100
of a page is the long run fraction of
time that you spend at that page, right.

00:31:41.100 --> 00:31:42.538
So that's kind of intuitive, right.

00:31:42.538 --> 00:31:44.493
The pages that are more important,

00:31:44.493 --> 00:31:48.019
you'll find yourself spending
more time there in the long run.

00:31:48.019 --> 00:31:51.538
So that's what it's doing.

00:31:51.538 --> 00:31:58.130
Okay, so you can interpret this is
a Markov chain, as I just said.

00:31:59.230 --> 00:32:00.760
But you might object.

00:32:00.760 --> 00:32:03.407
Well really this is just an eigenvalue,
eigenvector thing.

00:32:03.407 --> 00:32:07.643
It's just a matrix equation, and
do we really have to give it this

00:32:07.643 --> 00:32:12.357
probability interpretation and
really interpret it as a Markov chain?

00:32:12.357 --> 00:32:16.907
And so I wanted to show you something
about why is that actually a useful way to

00:32:16.907 --> 00:32:18.080
think of it.

00:32:18.080 --> 00:32:19.630
One reason is what I just said.

00:32:19.630 --> 00:32:24.220
That intuitively it makes sense to think
of these long run fraction of time for

00:32:24.220 --> 00:32:25.640
randomly surfing the web.

00:32:25.640 --> 00:32:28.630
So this gives a nice extra
interpretation to this.

00:32:28.630 --> 00:32:32.710
But I also wanna show you how
this helps with the computation.

00:32:32.710 --> 00:32:35.980
Because the computation
is immensely difficult.

00:32:35.980 --> 00:32:38.860
If you try to solve,
you know the usual method for

00:32:38.860 --> 00:32:42.530
solving matrix equations is
Gaussian elimination, right?

00:32:42.530 --> 00:32:44.350
You do all these row operations.

00:32:44.350 --> 00:32:49.170
Two times row one, plus row three,
and swap rows, and multiply rows.

00:32:49.170 --> 00:32:50.690
Right?
All that thing.

00:32:50.690 --> 00:32:56.560
The complexity of Gaussian elimination
if you have m linear equations and

00:32:56.560 --> 00:32:59.930
m variables is of the order of m cubed.

00:32:59.930 --> 00:33:03.110
It's a cubic complexity.

00:33:03.110 --> 00:33:10.380
You may be happy that that's polynomial
time but in practice it's not so

00:33:10.380 --> 00:33:15.450
good if m is like 10 billion and
if you have the order

00:33:15.450 --> 00:33:20.900
of 10 billion that's 10 to the 10,
cube it, that's 10 to the 30.

00:33:20.900 --> 00:33:21.910
10 to the 30.

00:33:21.910 --> 00:33:27.050
So you'd have order 10 to
the 30th operations to perform.

00:33:27.050 --> 00:33:31.180
You don't wanna do that,
even on a fast computer.

00:33:32.180 --> 00:33:35.000
Okay, so I wanna show you how
Markov chains not only gives you

00:33:35.000 --> 00:33:38.410
a nice interpretation here,
it actually helps with the computation.

00:33:38.410 --> 00:33:44.890
Which is as far as I know, at least how
Google was originally doing this and

00:33:44.890 --> 00:33:48.950
I'm sure they've refined things,
but in spirit it should be similar.

00:33:49.970 --> 00:33:51.050
That the basic principle.

00:33:52.220 --> 00:33:58.430
So to give this the full Markov
chain interpretation, we wanna,

00:33:58.430 --> 00:34:02.410
and connect this back with what we were
doing, we wanna say is this irreducible?

00:34:02.410 --> 00:34:07.150
Does this have a stationary, how do we
know the stationary distribution exists?

00:34:07.150 --> 00:34:09.870
And how do we know to convert it to
the stationary and things like that.

00:34:09.870 --> 00:34:14.565
So actually, what Google uses or
used in the original, Brin and Page,

00:34:14.565 --> 00:34:19.820
while they were still grad students,
wrote a paper with the idea for Google.

00:34:19.820 --> 00:34:22.970
And then they started
actually the company.

00:34:22.970 --> 00:34:26.480
So the paper that they wrote
actually gives the ideas.

00:34:26.480 --> 00:34:31.478
And what they said in that paper is,
they set up an equation like this,

00:34:31.478 --> 00:34:36.565
but then they said actually we're
going to use another chain instead,

00:34:36.565 --> 00:34:38.797
which I'll call G for Google.

00:34:38.797 --> 00:34:41.838
But here's the actual Google chain.

00:34:41.838 --> 00:34:48.665
The Google chain is alpha times
this one that we just did.

00:34:48.665 --> 00:34:50.970
It's mixing together two Markov chains.

00:34:50.970 --> 00:34:57.722
Alpha times Q, so Q is the matrix
we just defined based on the web,

00:34:57.722 --> 00:35:03.630
+ (1- alpha) times J over M,

00:35:04.650 --> 00:35:08.200
where M is the number of pages.

00:35:10.280 --> 00:35:16.310
So in other words Q is an m by m matrix,
and J is the matrix of all ones.

00:35:17.680 --> 00:35:20.170
So I want to explain why did they do this.

00:35:21.400 --> 00:35:26.140
And alpha is a number between 0 and 1.

00:35:26.140 --> 00:35:29.194
Just a constant.

00:35:29.194 --> 00:35:32.541
So think of alpha as a probability,
because it's a number between 0 and 1.

00:35:32.541 --> 00:35:37.259
So what this is saying is imagine
that you have this person randomly

00:35:37.259 --> 00:35:39.880
surfing the web like we were saying.

00:35:39.880 --> 00:35:41.570
And with probability alpha,

00:35:41.570 --> 00:35:46.020
so they flip a coin that has
probability alpha of heads each time.

00:35:46.020 --> 00:35:47.360
If the coin lands heads,

00:35:47.360 --> 00:35:51.830
they just click a random link on
the page that they were on, right?

00:35:51.830 --> 00:35:53.890
That is they actually use the Q chain.

00:35:53.890 --> 00:35:57.980
But if the coin lands tails,
they use this chain instead.

00:35:57.980 --> 00:36:02.242
Notice J over M is a valid
Markov transition matrix, right,

00:36:02.242 --> 00:36:06.096
cuz the row sums are 1,
and it's all non-negative.

00:36:06.096 --> 00:36:10.758
So with probability alpha,
just follow the link.

00:36:10.758 --> 00:36:14.810
With probably 1- alpha,
we do what's called teleportation.

00:36:14.810 --> 00:36:16.790
Teleportation is just a fancy word for

00:36:16.790 --> 00:36:19.490
saying, don't follow
the link structure anymore.

00:36:19.490 --> 00:36:23.310
Now, just go to a random,
uniformly random page.

00:36:23.310 --> 00:36:26.703
So this term is the teleportation.

00:36:29.829 --> 00:36:34.800
All that means is, with probability alpha,
just follow the link structure.

00:36:34.800 --> 00:36:40.180
With probably 1- alpha, just open up
a new window in your web browser and

00:36:40.180 --> 00:36:42.290
go to a completely random
page at that point.

00:36:42.290 --> 00:36:45.840
Of course, alpha has to be chosen.

00:36:47.670 --> 00:36:53.901
The original paper suggested alpha = 0.85.

00:36:53.901 --> 00:36:56.860
Now, that's like Google's magic number,
0.85.

00:36:56.860 --> 00:37:01.452
And there's been a lot of speculation and
discussion on why did they use .85?

00:37:03.490 --> 00:37:06.900
And I don't know whether
they still use 0.85.

00:37:06.900 --> 00:37:09.310
That was the original
value that they proposed.

00:37:09.310 --> 00:37:12.312
So 85% of the time you're
just following random links,

00:37:12.312 --> 00:37:15.205
15% of the time you're
teleporting to random pages.

00:37:17.551 --> 00:37:22.465
The reason, not specifically for
this 0.85, but the reason for adding

00:37:22.465 --> 00:37:27.530
this extra term is that this makes things
really, well, one reason is it makes

00:37:27.530 --> 00:37:32.975
things really nice in terms of the theory
that we developed for stationary issues.

00:37:32.975 --> 00:37:37.050
But the actual web, you know,

00:37:38.630 --> 00:37:42.070
if we just had this part, we don't know
whether it's irreducible, you know.

00:37:42.070 --> 00:37:47.880
Can you get from anywhere on the web
to anywhere just by clicking links?

00:37:47.880 --> 00:37:52.830
Well, I guess if you have this
page it would help a lot but

00:37:54.270 --> 00:37:57.750
it may take ages to get
from one page to another.

00:37:57.750 --> 00:38:01.760
And this is kind of allowing there to
be some small probability of getting

00:38:01.760 --> 00:38:03.350
from anywhere to anywhere in one step.

00:38:03.350 --> 00:38:07.893
So this guarantees irreducibility for
one thing.

00:38:11.886 --> 00:38:15.778
And we have other result about,

00:38:15.778 --> 00:38:21.689
the nice case is when some
power of the transition

00:38:21.689 --> 00:38:26.670
matrix has all entries positive.

00:38:26.670 --> 00:38:31.570
In this case, notice this is
extremely tiny, tiny, right?

00:38:31.570 --> 00:38:35.616
If alpha is 0.85, this is 0.15.

00:38:35.616 --> 00:38:37.900
M may be 10 billion.

00:38:37.900 --> 00:38:41.660
So you're adding some tiny number,
but at least everything's positive.

00:38:41.660 --> 00:38:43.550
You don't have zeroes anymore.

00:38:43.550 --> 00:38:53.820
So, no zeroes in transition matrix G.

00:38:53.820 --> 00:38:56.100
So, that has some advantages.

00:38:56.100 --> 00:38:59.150
And in particular we know
that all the results about...

00:38:59.150 --> 00:39:04.150
Even though it's not a reversible chain,
because the arrows may be going

00:39:04.150 --> 00:39:10.120
in one direction for
the web, the results from

00:39:10.120 --> 00:39:15.950
last time that I stated, that there
exists geostationary distribution.

00:39:15.950 --> 00:39:16.670
It's unique.

00:39:16.670 --> 00:39:18.560
The chain will converge to it.

00:39:18.560 --> 00:39:20.300
All this nice stuff applies.

00:39:22.460 --> 00:39:24.040
Okay, so we have this thing.

00:39:24.040 --> 00:39:26.806
Now, how do we actually compute?

00:39:26.806 --> 00:39:31.828
Because, since it's non-reversible,
we can't just write down a simple

00:39:31.828 --> 00:39:36.390
equation and immediately write
down the stationary distribution.

00:39:36.390 --> 00:39:40.950
The stationary distribution,
is something very very complicated here.

00:39:40.950 --> 00:39:44.310
But on the other hand,
if we go back to the definition and

00:39:44.310 --> 00:39:49.246
try to solve this matrix equation, then
we're trying to do Gaussian elimination

00:39:49.246 --> 00:39:52.130
with ten billion or 100 billion equations.

00:39:52.130 --> 00:39:53.940
It's not so good, right?

00:39:55.080 --> 00:39:59.930
So, the idea for computation is to

00:39:59.930 --> 00:40:04.250
use the fact that the chain converges
to the stationary distribution.

00:40:04.250 --> 00:40:10.121
So use convergence to
stationary distribution

00:40:10.121 --> 00:40:15.460
to stationarity to actually to solve.

00:40:15.460 --> 00:40:18.190
We don't need to solve it exactly, right?

00:40:18.190 --> 00:40:22.825
All we really need is and
approximate solution to this.

00:40:22.825 --> 00:40:26.990
Okay, so we know that if we run this,
this defines a Markov chain, right?

00:40:26.990 --> 00:40:31.480
Either you follow the link structure,
or you teleport each time.

00:40:31.480 --> 00:40:33.850
Follow that, run that chain for
a long time.

00:40:33.850 --> 00:40:36.710
It's gonna converge to the stationary
distribution no matter what

00:40:36.710 --> 00:40:38.410
the starting point was, right?

00:40:38.410 --> 00:40:41.770
Start with any distribution you want.

00:40:41.770 --> 00:40:42.940
Run the chain for a long.

00:40:44.070 --> 00:40:46.010
There's some very
difficult mathematical and

00:40:46.010 --> 00:40:49.940
computational questions about how
long should you run the chain for.

00:40:49.940 --> 00:40:54.080
And those are not really well understood
for a chain as complicated as this.

00:40:54.080 --> 00:40:58.830
So in practice, what people will do
is just run it as long as they can or

00:40:58.830 --> 00:41:01.780
run it until it looks
like it has stabilized.

00:41:01.780 --> 00:41:04.100
And you don't know for
sure that if you then ran it another week,

00:41:04.100 --> 00:41:05.500
it would change to something else.

00:41:05.500 --> 00:41:07.540
But if it looks like it's stabilized,

00:41:07.540 --> 00:41:11.350
then just take that as
your approximate solution.

00:41:11.350 --> 00:41:15.390
Okay, so
how do we actually run this chain though?

00:41:15.390 --> 00:41:17.860
The computation it looks like
it's going to be extremely,

00:41:17.860 --> 00:41:22.420
extremely difficult because of
these matrices are so large.

00:41:22.420 --> 00:41:26.860
It's actually much simpler than it
looks and I just want to show you why.

00:41:28.180 --> 00:41:34.410
So let's be t be our
initial probability vector.

00:41:34.410 --> 00:41:37.340
That is if you want t could just be 1 and
then all 0s.

00:41:37.340 --> 00:41:42.634
That just says always start out at page 1,
right,

00:41:42.634 --> 00:41:48.120
or let t be 1 over m, 1 over m all the way
through that it starts on a random page.

00:41:48.120 --> 00:41:52.200
We need some starting distribution
to start out the chain.

00:41:52.200 --> 00:41:56.030
So that's the initial,
in other words, this is the PMF,

00:41:56.030 --> 00:41:59.690
at times 0, written as a row vector.

00:41:59.690 --> 00:42:02.150
So initial probability vector.

00:42:02.150 --> 00:42:07.050
Okay, so we proved before that if we
want the probability distribution

00:42:07.050 --> 00:42:11.130
after one step, all we have to do
is multiply on the right by G.

00:42:11.130 --> 00:42:11.750
Right?
So

00:42:11.750 --> 00:42:16.290
t times G is going to be
the distribution after one step.

00:42:16.290 --> 00:42:16.840
Right?

00:42:16.840 --> 00:42:17.720
We did that before.

00:42:19.460 --> 00:42:22.810
And then if we want the distribution after
two steps, we multiply this by G, so

00:42:22.810 --> 00:42:26.510
we can get tG squared,
tG cubed, and so on, all right?

00:42:26.510 --> 00:42:27.179
Okay.
So,

00:42:27.179 --> 00:42:32.305
let's just quickly see what is
t times G actually look like?

00:42:32.305 --> 00:42:39.162
So t times G,
I'm just gonna multiply this by t,

00:42:39.162 --> 00:42:45.540
this is alpha t q plus 1
minus alpha t J over M.

00:42:45.540 --> 00:42:49.990
And actually this is not so
complicated because

00:42:49.990 --> 00:42:54.820
when you think about what Q looks like, Q,

00:42:56.630 --> 00:43:02.400
that's this chain that captures the link
structure of the entire web, right?

00:43:02.400 --> 00:43:05.876
What do you think that matrix looks like,
intuitively?

00:43:05.876 --> 00:43:07.420
&gt;&gt; A lot of 0s.

00:43:07.420 --> 00:43:11.550
&gt;&gt; It's a lot of zeroes,
this is like 10 billion by 10 billion, or

00:43:11.550 --> 00:43:16.460
100 billion by 100 billion But, right,
a typical page might have, I don't know,

00:43:16.460 --> 00:43:19.260
three links or ten links or
even 100 links.

00:43:19.260 --> 00:43:24.070
You're not gonna have many pages that
have tens of thousands of links, or

00:43:24.070 --> 00:43:25.540
millions of links, right?

00:43:25.540 --> 00:43:28.170
But this is a 10 billion by 10 billion,
okay?

00:43:28.170 --> 00:43:29.960
So this is dominated by 0s.

00:43:29.960 --> 00:43:32.959
So in other words,
you would say it's very sparse.

00:43:34.570 --> 00:43:37.060
That is sparse, meaning mostly zeros.

00:43:41.282 --> 00:43:46.345
Now, Google has a lot of very, very,
very good computer scientists working on

00:43:46.345 --> 00:43:51.485
some of the data storage computational
issues of the, what data structure would

00:43:51.485 --> 00:43:56.810
you use to store this matrix and keep
track of where all the zeros are, right?

00:43:56.810 --> 00:44:00.890
In other words, how do you efficiently
keep track of where the zeros are and

00:44:00.890 --> 00:44:04.220
where the non-zero terms
are because it's mostly zeros?

00:44:04.220 --> 00:44:09.470
But at least intuitively this
matrix has so many zeros in it and

00:44:09.470 --> 00:44:12.430
having a lot of zeros makes it a lot
easier to do matrix multiplication, right?

00:44:12.430 --> 00:44:16.220
You do need to be clever in keeping
track of where the zeros are.

00:44:16.220 --> 00:44:19.880
But it helps a lot with
doing this multiplication.

00:44:19.880 --> 00:44:21.270
Now let's look at this other term.

00:44:23.670 --> 00:44:26.370
Let's think about t times J.

00:44:28.980 --> 00:44:36.710
So remember t, t is just some vector
of probabilities that add up to 1.

00:44:36.710 --> 00:44:37.440
Right?

00:44:37.440 --> 00:44:40.180
And then J is a very simple matrix.

00:44:40.180 --> 00:44:41.720
J is just all 1's.

00:44:41.720 --> 00:44:45.080
So I'm gonna take this vector t,
and I'm gonna multiply it by J.

00:44:45.080 --> 00:44:48.808
And then I just,
the matrix multiplication,

00:44:48.808 --> 00:44:53.010
tt is a real vectors are going row,
dot it with a column.

00:44:53.010 --> 00:44:57.150
But you do a dot product with all ones,
that just says add up the entries of t.

00:44:57.150 --> 00:45:02.290
Well if you add up the entries of t,
you get 1, right?

00:45:03.720 --> 00:45:06.140
Because t is a probability vector.

00:45:06.140 --> 00:45:09.623
So t times J is just all 1s.

00:45:16.627 --> 00:45:20.470
Cuz you're just going t,
add up the elements of t.

00:45:20.470 --> 00:45:22.810
t elements add up to what?

00:45:22.810 --> 00:45:24.720
That's very easy, just all ones.

00:45:24.720 --> 00:45:29.300
So that term is easy, so
actually this is not as bad as it looks.

00:45:29.300 --> 00:45:34.200
Now that we have t times G,
we use that as the new t.

00:45:34.200 --> 00:45:36.870
This is after running it for one step.

00:45:36.870 --> 00:45:43.950
Then we do tG squared, that is we
do tg times G, which is tG squared.

00:45:46.560 --> 00:45:50.890
Well we do that in the same way, which is
tG is now playing the role of t and we

00:45:50.890 --> 00:45:54.920
multiply this by G and that's not typical
to do for the same reasons I just said.

00:45:54.920 --> 00:45:59.130
So then we have tG squared,
tG cubed, and so

00:45:59.130 --> 00:46:04.850
on, run this for a very long time,
that is tG to some large

00:46:04.850 --> 00:46:10.066
power that corresponds to running this
chain for a large number of steps, right?

00:46:10.066 --> 00:46:17.190
So then, in the limit, if you do tG to
the n, meaning you ran it for n steps,

00:46:18.900 --> 00:46:23.330
and you let n go to infinity, that's gonna
converge to the stationary distribution.

00:46:23.330 --> 00:46:27.430
The stationary distribution
is the page rank vector.

00:46:27.430 --> 00:46:29.850
So then you have page rank, okay?

00:46:29.850 --> 00:46:37.660
So, and that's actually computationally, a
lot easier to do, just run this chain, in

00:46:37.660 --> 00:46:43.600
this way rather than trying to solve the
ten billion by ten billion matrix system.

00:46:43.600 --> 00:46:48.430
And it has this nice interpretation in
terms of randomly clicking links and

00:46:48.430 --> 00:46:51.420
randomly teleporting every now and then.

00:46:51.420 --> 00:46:54.110
All right, so
that's the essence of Google PageRank.

00:46:54.110 --> 00:46:55.930
And that's the end of Markov chains.

00:46:55.930 --> 00:46:58.185
So I'll see you on Friday.

