WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.302
[MUSIC PLAYING]

00:00:07.648 --> 00:00:10.230
SPEAKER: Please join me in
welcoming, to the stage, Mr.

00:00:10.230 --> 00:00:10.830
Quentin Hardy.

00:00:13.740 --> 00:00:17.030
QUENTIN HARDY: Well, let's get
right to the real wattage here.

00:00:19.860 --> 00:00:22.670
We have a lot to cover today
because Niall Ferguson has

00:00:22.670 --> 00:00:25.809
written very interesting books
about networks and power,

00:00:25.809 --> 00:00:28.350
something of interest to more
than a few people in this room,

00:00:28.350 --> 00:00:31.880
I'm sure, inherently,
and considering

00:00:31.880 --> 00:00:34.340
current events, which
we will touch on

00:00:34.340 --> 00:00:35.870
towards the end of our talk.

00:00:35.870 --> 00:00:38.780
Let's go about 40
minutes and then, please,

00:00:38.780 --> 00:00:41.870
if you have any questions, come
to the mike, bring them up.

00:00:41.870 --> 00:00:45.410
It's great if it's interactive.

00:00:45.410 --> 00:00:47.240
I'll say a couple
of opening remarks

00:00:47.240 --> 00:00:50.150
that struck me in
reading this book.

00:00:50.150 --> 00:00:54.317
You really, what you take
from it more than anything,

00:00:54.317 --> 00:00:55.900
and we should talk
about this as well,

00:00:55.900 --> 00:00:58.760
is how much you learn
about the present

00:00:58.760 --> 00:01:03.710
by looking carefully at the
past, and how important it is,

00:01:03.710 --> 00:01:06.290
even in building cutting-edge
technology, to have

00:01:06.290 --> 00:01:08.990
with you the lessons of
the past and a grounding

00:01:08.990 --> 00:01:13.520
in previous experiences
and human events

00:01:13.520 --> 00:01:17.000
because one thing you can
say about the future is,

00:01:17.000 --> 00:01:20.900
it's going to show up
consisting 99% of the past.

00:01:20.900 --> 00:01:24.170
And if you don't take
those lessons, woe betide.

00:01:24.170 --> 00:01:26.790
Now, the question
becomes quickly,

00:01:26.790 --> 00:01:29.030
how does one look at the past?

00:01:29.030 --> 00:01:30.830
From the kind of
relationships that we're

00:01:30.830 --> 00:01:34.970
seeing in traditional histories,
those of hierarchies of power,

00:01:34.970 --> 00:01:38.150
the kings and their
armies, that was one way,

00:01:38.150 --> 00:01:41.160
but it's become a very
insufficient means of analysis.

00:01:41.160 --> 00:01:43.550
And we quickly move
through Marxist histories,

00:01:43.550 --> 00:01:46.160
focusing on social and
economic strata, that

00:01:46.160 --> 00:01:48.800
became particularly apparent
as work standardized

00:01:48.800 --> 00:01:51.500
and wealth grew in the
Industrial Revolution,

00:01:51.500 --> 00:01:53.210
and it became very
much a standard means

00:01:53.210 --> 00:01:54.740
of analysis of the world.

00:01:54.740 --> 00:01:57.590
More recently, hidden
social histories

00:01:57.590 --> 00:02:00.170
of feminist and
marginalized groups,

00:02:00.170 --> 00:02:03.290
which tend to be stories of
repression and resistance

00:02:03.290 --> 00:02:07.100
and overcoming, reflect
the growing empowerment

00:02:07.100 --> 00:02:08.870
of these groups, and
their getting a voice

00:02:08.870 --> 00:02:10.880
in the world, and
their own efforts

00:02:10.880 --> 00:02:13.010
to recapture these
stories and place them

00:02:13.010 --> 00:02:16.010
in a proper context
of human experience.

00:02:16.010 --> 00:02:19.550
Then, we come more recently
to science-enamored areas

00:02:19.550 --> 00:02:22.970
like big history, which look
at people as a biological event

00:02:22.970 --> 00:02:25.250
within the existence
of the universe,

00:02:25.250 --> 00:02:28.490
or Cliodynamics, which attempts
to make history as predictive

00:02:28.490 --> 00:02:30.140
as a Google search.

00:02:30.140 --> 00:02:33.950
Explaining our fates through the
prisms of geography or disease

00:02:33.950 --> 00:02:37.460
or its ecosystem influences
is another popular means

00:02:37.460 --> 00:02:39.620
of analysis at this point.

00:02:39.620 --> 00:02:41.960
In most of these
cases, though, you

00:02:41.960 --> 00:02:46.460
tend to have systems focusing
on the primacy of conflict

00:02:46.460 --> 00:02:50.870
and power relationships,
usually in fairly stark terms.

00:02:50.870 --> 00:02:54.080
Our guest today, Niall
Ferguson, has become interested

00:02:54.080 --> 00:02:56.060
in a somewhat different
and very timely

00:02:56.060 --> 00:02:58.280
approach to historical analysis.

00:02:58.280 --> 00:03:00.590
Professor Ferguson is
the author of 16 books

00:03:00.590 --> 00:03:03.170
and currently Milbank Family
Senior Fellow at the Hoover

00:03:03.170 --> 00:03:04.584
Institution.

00:03:04.584 --> 00:03:06.500
He wanted to examine
history through the prism

00:03:06.500 --> 00:03:10.490
of human networks which is to
say lattices of understanding

00:03:10.490 --> 00:03:13.430
and information and,
yes, power, along

00:03:13.430 --> 00:03:15.920
with the primacy of key
nodes in the connections

00:03:15.920 --> 00:03:19.070
and influence that cause
some networks to succeed over

00:03:19.070 --> 00:03:20.060
others.

00:03:20.060 --> 00:03:22.100
As he himself says
in his new book,

00:03:22.100 --> 00:03:25.370
"The Square and the Tower,"
is not an either/or way

00:03:25.370 --> 00:03:26.880
of approaching history.

00:03:26.880 --> 00:03:31.010
Traditional and
nontraditional hierarchies,

00:03:31.010 --> 00:03:33.680
or towers in this
context, are also

00:03:33.680 --> 00:03:37.340
social networks, the squares
in which people exchange

00:03:37.340 --> 00:03:39.530
information and relationships.

00:03:39.530 --> 00:03:41.780
And successful
networks often take

00:03:41.780 --> 00:03:44.960
on aspects of their
time's systems of power.

00:03:44.960 --> 00:03:47.540
But his network-based
analysis of history

00:03:47.540 --> 00:03:51.620
focuses on distinctive ways
that information was shared,

00:03:51.620 --> 00:03:54.080
often towards a particular end.

00:03:54.080 --> 00:03:56.610
The book looks at this
in the time of Luther,

00:03:56.610 --> 00:03:59.600
the Republic of Letters, and
the rise of European nationalism

00:03:59.600 --> 00:04:02.600
enlightenment, and in several
other examples, many of them

00:04:02.600 --> 00:04:04.580
more recent.

00:04:04.580 --> 00:04:06.770
And while, as I
said, hierarchies

00:04:06.770 --> 00:04:09.560
are a type of network, they
tend to be rigid and highly

00:04:09.560 --> 00:04:12.200
codified and concerned
with formal concentration

00:04:12.200 --> 00:04:15.680
in management of power,
whereas social networks are

00:04:15.680 --> 00:04:18.800
somewhat looser, more
diffuse, and mutable.

00:04:18.800 --> 00:04:20.600
If any of you are
seeing parallels

00:04:20.600 --> 00:04:22.340
in this topic and
current events,

00:04:22.340 --> 00:04:24.530
you have come to
the right place.

00:04:24.530 --> 00:04:26.270
But in some ways,
this is also a book

00:04:26.270 --> 00:04:29.600
about the tensions, information,
and power over the past 600

00:04:29.600 --> 00:04:30.470
years.

00:04:30.470 --> 00:04:32.300
And it seems
appropriate to begin

00:04:32.300 --> 00:04:35.450
by talking in terms of
historical events, in order,

00:04:35.450 --> 00:04:37.970
as I say, to better
inform the present.

00:04:37.970 --> 00:04:40.220
That is, we will use the
past to look at how recent

00:04:40.220 --> 00:04:41.810
advancement in
networked society,

00:04:41.810 --> 00:04:45.410
primarily the internet, web
2.0, and massive data capture

00:04:45.410 --> 00:04:47.450
and analysis, are
now challenging

00:04:47.450 --> 00:04:50.450
traditional hierarchies
in ways occasionally seen

00:04:50.450 --> 00:04:52.130
in history before.

00:04:52.130 --> 00:04:54.980
So let me begin by
asking, what led

00:04:54.980 --> 00:04:58.130
you to seek this new framework
for historical analysis?

00:04:58.130 --> 00:05:01.286
NIALL FERGUSON: Well, thanks,
Quentin, for inviting me here.

00:05:01.286 --> 00:05:06.560
It's great to find that a free
talk has an audience, even

00:05:06.560 --> 00:05:09.440
on a beautiful sunny day
like this in California.

00:05:09.440 --> 00:05:13.960
I had worked, without
quite realizing it,

00:05:13.960 --> 00:05:17.875
on networks for much of
my career as a historian.

00:05:17.875 --> 00:05:21.280
I had, for example, written a
book about financial networks,

00:05:21.280 --> 00:05:23.710
looking at the rise of
the Rothschild family,

00:05:23.710 --> 00:05:26.680
and specifically German-Jewish
financial networks, which I

00:05:26.680 --> 00:05:28.000
talk about a bit in this book.

00:05:28.000 --> 00:05:31.060
And I'd also written a book
about the British Empire which

00:05:31.060 --> 00:05:33.640
was partly a book
about networks too

00:05:33.640 --> 00:05:36.130
because, although we
tend to think of empires

00:05:36.130 --> 00:05:38.890
as very hierarchical things,
actually the British Empire

00:05:38.890 --> 00:05:44.270
was built by networks of traders
and missionaries and the like.

00:05:44.270 --> 00:05:46.510
And so I had been
doing this for years.

00:05:46.510 --> 00:05:49.690
My natural proclivity
was not to go and study

00:05:49.690 --> 00:05:52.710
kings and presidents
and field marshals,

00:05:52.710 --> 00:05:56.770
but was to go and study more
informal social networks.

00:05:56.770 --> 00:05:58.360
But then I realized,
as I was writing

00:05:58.360 --> 00:06:01.420
a biography of Henry
Kissinger, who in some ways

00:06:01.420 --> 00:06:04.620
is a super networker
in his career,

00:06:04.620 --> 00:06:08.230
that I didn't have a formal
understanding of networks.

00:06:08.230 --> 00:06:10.720
So I thought, hey, I'm
moving to Stanford,

00:06:10.720 --> 00:06:12.640
leaving behind the
stuffy east coast

00:06:12.640 --> 00:06:15.610
and coming to a university
right next to Silicon Valley.

00:06:15.610 --> 00:06:17.050
I'd better do my homework.

00:06:17.050 --> 00:06:21.250
So the idea was, I'm going to
study some network science,

00:06:21.250 --> 00:06:23.260
get a little bit more
familiar with concepts

00:06:23.260 --> 00:06:25.210
that many of the people
in this room live

00:06:25.210 --> 00:06:28.870
and breathe, and then try
and apply those concepts

00:06:28.870 --> 00:06:30.310
to historical study.

00:06:30.310 --> 00:06:32.080
A few historians
had been doing this,

00:06:32.080 --> 00:06:34.360
and I try and cite most
of them in the book,

00:06:34.360 --> 00:06:35.740
but it's quite patchy.

00:06:35.740 --> 00:06:38.210
History tends to lag
behind all disciplines.

00:06:38.210 --> 00:06:41.650
So although sociologists and,
heaven knows, neuroscientists,

00:06:41.650 --> 00:06:43.150
and economists, and
others have been

00:06:43.150 --> 00:06:45.970
talking about
networks for decades,

00:06:45.970 --> 00:06:48.730
we're kind of
catching up belatedly.

00:06:48.730 --> 00:06:51.040
The other reason for
doing it, I have to admit,

00:06:51.040 --> 00:06:54.110
was that after I came here,
which is nearly two years ago

00:06:54.110 --> 00:06:57.640
now, I was very struck by how
uninterested people in Silicon

00:06:57.640 --> 00:07:00.010
Valley were in history.

00:07:00.010 --> 00:07:02.500
Like history begins with
the Google IPO, dude.

00:07:02.500 --> 00:07:04.870
Everything before
that is the Stone Age,

00:07:04.870 --> 00:07:06.780
and we so don't
need to study it.

00:07:06.780 --> 00:07:09.580
So part of the point of the
book is to say to people here,

00:07:09.580 --> 00:07:11.500
actually, you may never
have studied history

00:07:11.500 --> 00:07:13.490
and you may think it's
all completely boring,

00:07:13.490 --> 00:07:16.160
but it's highly relevant
to what you're doing.

00:07:16.160 --> 00:07:18.670
And I think the book makes
a reasonable case for that,

00:07:18.670 --> 00:07:23.080
partly because I think it saw
the crisis coming that began

00:07:23.080 --> 00:07:24.760
in the election of 2016.

00:07:24.760 --> 00:07:27.280
And in that sense, I think
the book is quite a good guide

00:07:27.280 --> 00:07:29.140
to where we are now.

00:07:29.140 --> 00:07:30.760
QUENTIN HARDY:
Actually, you've made

00:07:30.760 --> 00:07:32.470
me jump ahead to
this week's interview

00:07:32.470 --> 00:07:36.480
in the Washington
Post where you said,

00:07:36.480 --> 00:07:41.370
you saw two years ago that
there was a crisis coming

00:07:41.370 --> 00:07:44.670
in tech and politics.

00:07:44.670 --> 00:07:45.969
What informed that?

00:07:45.969 --> 00:07:47.260
NIALL FERGUSON: It was deja vu.

00:07:47.260 --> 00:07:47.970
To be honest.

00:07:47.970 --> 00:07:52.450
I mean, I've been in New
York from around 2002-3

00:07:52.450 --> 00:07:54.330
when I moved from
the UK to the US,

00:07:54.330 --> 00:07:57.720
and I had encountered
the same moods

00:07:57.720 --> 00:08:00.900
that I encountered in Silicon
Valley a couple of years ago,

00:08:00.900 --> 00:08:03.480
the mood of, we are the
masters of the universe.

00:08:03.480 --> 00:08:05.130
Resistance is futile.

00:08:05.130 --> 00:08:08.010
And you, little professor of
history, you just run along.

00:08:08.010 --> 00:08:09.870
There's nothing
you have to offer.

00:08:09.870 --> 00:08:12.861
That was very much the
pre-crisis mood on Wall Street,

00:08:12.861 --> 00:08:14.860
and I wrote a book called
"The Ascent of Money,"

00:08:14.860 --> 00:08:17.960
which was published just
before Lehman Brothers blew up.

00:08:17.960 --> 00:08:20.530
It was written 2005-6-7.

00:08:20.530 --> 00:08:22.650
And the point of
that book was to say,

00:08:22.650 --> 00:08:25.140
massive financial
crisis is coming,

00:08:25.140 --> 00:08:28.747
and you'd better understand
why, and you'll only

00:08:28.747 --> 00:08:30.830
understand why if you know
some financial history.

00:08:30.830 --> 00:08:33.700
So when I got here, I thought,
wow, this is so familiar.

00:08:33.700 --> 00:08:36.270
These people running
the big tech companies,

00:08:36.270 --> 00:08:39.780
with some notable exceptions,
do have the same attitude

00:08:39.780 --> 00:08:41.789
that the Goldman Sachs
and Morgan Stanley

00:08:41.789 --> 00:08:45.030
people had circa 2004-5-6.

00:08:45.030 --> 00:08:49.590
So my hunch was, this is the
kind of hubris that is nearly

00:08:49.590 --> 00:08:53.400
always followed by nemesis,
and pretty quickly, it

00:08:53.400 --> 00:08:56.940
became clear to me that
the 2016 election was

00:08:56.940 --> 00:08:58.590
going to be that nemesis.

00:08:58.590 --> 00:09:01.890
And the kind of ways in which
the network platforms were

00:09:01.890 --> 00:09:04.770
being used in the
election, those

00:09:04.770 --> 00:09:06.990
were obviously problematic.

00:09:06.990 --> 00:09:09.240
Whether you look at the
way the Russians were

00:09:09.240 --> 00:09:12.690
able to instrumentalize them,
or the way that the platforms

00:09:12.690 --> 00:09:15.420
themselves incentivized
fake news and extreme

00:09:15.420 --> 00:09:18.240
views, even before
Trump's victory,

00:09:18.240 --> 00:09:19.620
I could see trouble coming.

00:09:19.620 --> 00:09:22.304
And that spurred me
on to write the book.

00:09:22.304 --> 00:09:23.220
QUENTIN HARDY: Mm-hmm.

00:09:23.220 --> 00:09:27.870
Now, we'll return to our
putative hubris shortly.

00:09:27.870 --> 00:09:31.710
But let's talk a little
bit about network theory,

00:09:31.710 --> 00:09:34.980
generally, since you were
able to apply as in 2016.

00:09:34.980 --> 00:09:38.290
You had seen certain
patterns going back--

00:09:38.290 --> 00:09:42.000
well, the big start for
you is probably Gutenberg.

00:09:42.000 --> 00:09:46.200
Talk generally about what
network theory in history

00:09:46.200 --> 00:09:49.974
means, and what you saw in
terms of Gutenberg and Luther.

00:09:49.974 --> 00:09:51.640
NIALL FERGUSON: Well,
the general point,

00:09:51.640 --> 00:09:54.180
which will be obvious
to people here,

00:09:54.180 --> 00:09:57.090
is that any
historical phenomenon,

00:09:57.090 --> 00:10:00.120
any organization
of human beings,

00:10:00.120 --> 00:10:02.400
has some network architecture.

00:10:02.400 --> 00:10:06.570
And everybody is a node, and
their relationships are edges,

00:10:06.570 --> 00:10:08.250
and it doesn't really
matter what it is.

00:10:08.250 --> 00:10:11.490
You ought to be able to plot
that if you have the data.

00:10:11.490 --> 00:10:14.520
And this is a pretty
powerful tool just in itself,

00:10:14.520 --> 00:10:16.530
and not one that has
tended to be used much.

00:10:16.530 --> 00:10:18.480
As you mentioned,
for years, people

00:10:18.480 --> 00:10:22.100
tended to think of social
change in terms of classes.

00:10:22.100 --> 00:10:24.240
A class is a very
blunt instrument

00:10:24.240 --> 00:10:26.130
for historical study.

00:10:26.130 --> 00:10:28.830
It worked for Marx, but the
fact that historians are still

00:10:28.830 --> 00:10:31.950
using that framework so
long after Marx wrote

00:10:31.950 --> 00:10:34.470
is odd, when in
fact, you can capture

00:10:34.470 --> 00:10:36.680
much more about
any social movement

00:10:36.680 --> 00:10:37.680
by graphing the network.

00:10:37.680 --> 00:10:38.450
Point one.

00:10:38.450 --> 00:10:41.790
QUENTIN HARDY: It's interesting
to talk about the proletariat.

00:10:41.790 --> 00:10:44.880
It's equally interesting to
talk about certain Vietnamese

00:10:44.880 --> 00:10:49.359
and Cambodians in cafes in
Paris in the '40s and '50s,

00:10:49.359 --> 00:10:50.400
forming communist cadres.

00:10:50.400 --> 00:10:51.900
NIALL FERGUSON: And
the revolutions,

00:10:51.900 --> 00:10:53.358
and this is a point
the book makes,

00:10:53.358 --> 00:10:56.850
that were so powerful
in the 20th century,

00:10:56.850 --> 00:10:59.265
beginning in the Russian
Revolution in 1917,

00:10:59.265 --> 00:11:03.120
are actually better understood
as the results of networks

00:11:03.120 --> 00:11:06.960
of revolutionaries, than
of great historical forces

00:11:06.960 --> 00:11:10.870
propelling one class up
and the other class down.

00:11:10.870 --> 00:11:15.300
The big insight for me
came from a paper published

00:11:15.300 --> 00:11:19.410
by a guy named Dittmar, who
was working at the London

00:11:19.410 --> 00:11:20.370
School of Economics.

00:11:20.370 --> 00:11:22.980
And Dittmar's paper,
which I cite in the book,

00:11:22.980 --> 00:11:26.820
says, if we compare the impact
of the personal computer

00:11:26.820 --> 00:11:32.310
and the internet on the late
20th century/early 21st century

00:11:32.310 --> 00:11:35.640
with the impact of the
printing press on Europe

00:11:35.640 --> 00:11:38.070
in the 16th and
17th century, there

00:11:38.070 --> 00:11:40.062
are some striking similarities.

00:11:40.062 --> 00:11:41.520
And he has a couple
of great charts

00:11:41.520 --> 00:11:44.580
which I reproduced showing
that the impact of the printing

00:11:44.580 --> 00:11:49.800
press on the price of content
and the volume of content

00:11:49.800 --> 00:11:53.430
is comparable in
its size and shape

00:11:53.430 --> 00:11:56.010
to the impact of the personal
computer and the internet.

00:11:56.010 --> 00:11:58.260
The big difference-- I mean,
there are a whole bunch--

00:11:58.260 --> 00:12:00.510
but the big one is,
it happens faster

00:12:00.510 --> 00:12:03.690
in our time, roughly an
order of magnitude faster.

00:12:03.690 --> 00:12:06.930
But the same processes
seem to be at work,

00:12:06.930 --> 00:12:09.660
and so the key
analogy in the book

00:12:09.660 --> 00:12:13.260
is that if you want to find
a time like our own time,

00:12:13.260 --> 00:12:17.160
it's much better to go back
to that period 500 years ago

00:12:17.160 --> 00:12:20.400
than to expect to find
good analogies in, say,

00:12:20.400 --> 00:12:22.660
the 19th and 20th century.

00:12:22.660 --> 00:12:25.850
And that's because of the
way communications technology

00:12:25.850 --> 00:12:29.430
changed between the printing
press and the internet

00:12:29.430 --> 00:12:33.480
because most of the innovations
of the 19th and 20th century

00:12:33.480 --> 00:12:36.330
favored centralized control
because they had a hub

00:12:36.330 --> 00:12:39.780
and spoke architecture--
railroads, telegraphs,

00:12:39.780 --> 00:12:41.200
and so forth.

00:12:41.200 --> 00:12:44.400
And so there's a period where
hierarchical structures are

00:12:44.400 --> 00:12:47.400
very powerful, and
distributed network structures

00:12:47.400 --> 00:12:50.860
are very weak, and that period
is the 19th and 20th century.

00:12:50.860 --> 00:12:55.020
And most people, if they study
any history, in my experience,

00:12:55.020 --> 00:12:56.700
have studied the 20th century.

00:12:56.700 --> 00:13:00.845
They know the 1930s, but
if you only know the 1930s,

00:13:00.845 --> 00:13:02.220
there's a tendency
for everything

00:13:02.220 --> 00:13:04.110
to look like the 1930s.

00:13:04.110 --> 00:13:05.880
Part of the point
of this book is,

00:13:05.880 --> 00:13:07.770
this is nothing like the 1930s.

00:13:07.770 --> 00:13:11.910
If you want to understand why
we have tremendous polarization

00:13:11.910 --> 00:13:15.900
in online networks, if you want
to understand why crazy stuff

00:13:15.900 --> 00:13:18.990
goes viral, and seems to
go viral more readily than

00:13:18.990 --> 00:13:22.710
sensible stuff, look at the 16th
and 17th centuries because I

00:13:22.710 --> 00:13:26.290
think the Reformation is a
perfect kind of analogy--

00:13:26.290 --> 00:13:28.380
not perfect, but it's
a pretty good analogy--

00:13:28.380 --> 00:13:30.900
for what we're
experiencing today.

00:13:30.900 --> 00:13:34.350
So combining network
science, which tells you

00:13:34.350 --> 00:13:36.750
that if you create any
decent-sized social network,

00:13:36.750 --> 00:13:38.460
there will be homophily.

00:13:38.460 --> 00:13:40.590
There will be self-segregation.

00:13:40.590 --> 00:13:44.460
And you also can see that
in any social network.

00:13:44.460 --> 00:13:47.310
Stuff will go viral and it
will go viral more rapidly,

00:13:47.310 --> 00:13:48.300
the denser the network.

00:13:48.300 --> 00:13:50.590
If you combine
that with history,

00:13:50.590 --> 00:13:52.770
then I think you have quite
a powerful set of tools

00:13:52.770 --> 00:13:54.470
for understanding the present.

00:13:54.470 --> 00:13:55.800
I mean, I do applied history.

00:13:55.800 --> 00:13:58.950
My main goal in writing
history is not just

00:13:58.950 --> 00:14:02.880
to indulge myself in
nostalgia for bygone ages.

00:14:02.880 --> 00:14:05.400
My interest is in
trying to illuminate

00:14:05.400 --> 00:14:10.320
our present predicament and the
plausible futures that we face.

00:14:10.320 --> 00:14:14.040
And I found that applying this
combination of network science

00:14:14.040 --> 00:14:18.150
and history is a pretty good way
of thinking about where we are.

00:14:18.150 --> 00:14:21.840
And it hasn't proved
unsuccessful in anticipating

00:14:21.840 --> 00:14:24.870
the crisis that we
now find ourselves in.

00:14:24.870 --> 00:14:28.110
Cambridge Analytica is
just part of a gathering

00:14:28.110 --> 00:14:30.600
crisis around the power of
the technology platform.

00:14:30.600 --> 00:14:32.183
QUENTIN HARDY: Another
element of this

00:14:32.183 --> 00:14:35.070
that I like about the advent
of a powerful communications

00:14:35.070 --> 00:14:39.360
technology-- what happened
with print and the Reformation

00:14:39.360 --> 00:14:43.320
and what seems to be happening
now-- is, in both cases,

00:14:43.320 --> 00:14:47.100
certain powerful and
seemingly extrinsic factors

00:14:47.100 --> 00:14:49.410
give new life to the medium.

00:14:49.410 --> 00:14:52.080
The printing press comes
along just as Constantinople

00:14:52.080 --> 00:14:55.140
falls, flooding Europe
with all these texts

00:14:55.140 --> 00:14:57.150
which people want to translate.

00:14:57.150 --> 00:15:00.090
Just as the bourgeoisie
are rising and being

00:15:00.090 --> 00:15:03.120
able to read in your vernacular
is an interesting thing,

00:15:03.120 --> 00:15:05.580
not so long after the
new world is discovered.

00:15:05.580 --> 00:15:08.490
So there's all this stuff to
read about all these voyages,

00:15:08.490 --> 00:15:12.270
which also creates an industry
in piracy, not sea piracy,

00:15:12.270 --> 00:15:13.710
but book piracy.

00:15:13.710 --> 00:15:16.650
Columbus's narrative
of his travels

00:15:16.650 --> 00:15:20.350
appear in 10 different versions
around Europe within a year.

00:15:20.350 --> 00:15:22.030
Everybody's just
wild to read this.

00:15:22.030 --> 00:15:24.870
So the act of reading becomes
important at a whole new level.

00:15:24.870 --> 00:15:25.995
NIALL FERGUSON: Absolutely.

00:15:25.995 --> 00:15:29.250
QUENTIN HARDY: And the church
tries to control information

00:15:29.250 --> 00:15:29.860
in a new way.

00:15:29.860 --> 00:15:32.310
The first book burning is 1510.

00:15:32.310 --> 00:15:33.450
It's too late.

00:15:33.450 --> 00:15:34.740
They don't understand.

00:15:34.740 --> 00:15:37.680
Like, you can't keep up
with the velocity here.

00:15:37.680 --> 00:15:42.360
And the last step is Luther, the
first bestselling author, 1519.

00:15:42.360 --> 00:15:44.490
5,000 copies in a year.

00:15:44.490 --> 00:15:45.657
Oh, my god, what a home run.

00:15:45.657 --> 00:15:47.323
NIALL FERGUSON: Doesn't
sound like much,

00:15:47.323 --> 00:15:49.489
but it is enormous by the
standards of the time.

00:15:49.489 --> 00:15:51.030
QUENTIN HARDY: Fast
forward to today,

00:15:51.030 --> 00:15:55.240
where you've got technology,
and in particular,

00:15:55.240 --> 00:16:00.090
the internet coming around
just as the Berlin Wall falls,

00:16:00.090 --> 00:16:02.640
free markets appear
to be triumphant

00:16:02.640 --> 00:16:05.040
as a global dominant idea--

00:16:05.040 --> 00:16:09.660
you get into this very peculiar
space of Fukuyama's history

00:16:09.660 --> 00:16:12.360
ending, but that's
a different story--

00:16:12.360 --> 00:16:16.620
and the idea of individual
empowerment arising.

00:16:16.620 --> 00:16:20.130
World War II ends and 180
countries are created,

00:16:20.130 --> 00:16:21.890
and they all get sovereignty.

00:16:21.890 --> 00:16:24.510
So you've got these new ideas
about how the world ought

00:16:24.510 --> 00:16:30.840
to work, combined with these
very, very rapid new forms

00:16:30.840 --> 00:16:32.760
of information sharing
and information

00:16:32.760 --> 00:16:35.740
consumption in both cases.

00:16:35.740 --> 00:16:38.430
Now, that's really interesting.

00:16:38.430 --> 00:16:40.710
The bad news is, the
wars of the Reformation

00:16:40.710 --> 00:16:42.180
killed a third of Germany.

00:16:42.180 --> 00:16:45.120
There's an enormous amount
of turmoil associated

00:16:45.120 --> 00:16:46.950
with changes of power.

00:16:46.950 --> 00:16:51.330
Do you think we are headed for
not a similar level of crises,

00:16:51.330 --> 00:16:53.970
but some kind of turmoil
in the social order?

00:16:53.970 --> 00:16:55.696
Is that the lesson
of history Here

00:16:55.696 --> 00:16:57.570
NIALL FERGUSON: I think
the lesson of history

00:16:57.570 --> 00:17:01.590
is that polarization
processes don't necessarily

00:17:01.590 --> 00:17:06.270
stop themselves, that you can
think this country is very

00:17:06.270 --> 00:17:10.410
polarized today, and
you can go on Twitter

00:17:10.410 --> 00:17:13.410
and look at the extraordinary
vehemence with which people

00:17:13.410 --> 00:17:16.020
debate political
issues, but don't think

00:17:16.020 --> 00:17:19.890
it couldn't get worse because
this is nothing compared

00:17:19.890 --> 00:17:23.700
with what this country did
to itself in the 19th century

00:17:23.700 --> 00:17:25.930
over the central
issue of slavery.

00:17:25.930 --> 00:17:29.160
So I think if one
takes the analogy

00:17:29.160 --> 00:17:34.290
that you sketched there, a
couple of further points arise.

00:17:34.290 --> 00:17:38.160
Number one, the
printing revolution

00:17:38.160 --> 00:17:41.940
did indeed coincide
with other variables

00:17:41.940 --> 00:17:46.290
that rendered the Roman
Catholic hierarchy vulnerable.

00:17:46.290 --> 00:17:47.710
You mentioned an
important point.

00:17:47.710 --> 00:17:50.490
There's not much intellectual
property rights protection

00:17:50.490 --> 00:17:53.260
in 16th and 17th
century printing.

00:17:53.260 --> 00:17:57.630
It's a super distributed network
with each printer really doing

00:17:57.630 --> 00:18:00.600
his own thing in
each German town.

00:18:00.600 --> 00:18:03.540
So it's kind of early
internet rather than

00:18:03.540 --> 00:18:06.460
current internet, this network.

00:18:06.460 --> 00:18:10.380
But what's very striking
is that in both cases,

00:18:10.380 --> 00:18:14.430
people are optimistic about
what the new technology will do.

00:18:14.430 --> 00:18:18.330
So Luther himself thinks that
the printing press will really

00:18:18.330 --> 00:18:21.270
help improve Christianity
because everybody is going

00:18:21.270 --> 00:18:23.310
to be able to read the
Bible in the vernacular

00:18:23.310 --> 00:18:25.380
and have a direct
relationship with God,

00:18:25.380 --> 00:18:28.410
and the priesthood of all
believers will be possible.

00:18:28.410 --> 00:18:31.290
So it's a little bit
like the optimists

00:18:31.290 --> 00:18:35.310
about the internet in the
1990s saying, ad nauseam,

00:18:35.310 --> 00:18:38.310
if everybody is connected, then
everything will be awesome,

00:18:38.310 --> 00:18:41.190
and this has been
said in multiple ways.

00:18:41.190 --> 00:18:43.770
John Perry Barlow said, in
the '90s, with his declaration

00:18:43.770 --> 00:18:45.540
of the independence
of cyberspace,

00:18:45.540 --> 00:18:49.200
and Mark Zuckerberg has
said it repeatedly--

00:18:49.200 --> 00:18:50.850
until relatively
recently-- we're

00:18:50.850 --> 00:18:52.050
building a global community.

00:18:52.050 --> 00:18:53.430
We'll solve all the
world's problems

00:18:53.430 --> 00:18:54.660
and everything will be awesome.

00:18:54.660 --> 00:18:56.190
So you start out
with the technology

00:18:56.190 --> 00:19:00.300
and it just seems, intuitively,
this has to be good.

00:19:00.300 --> 00:19:01.830
And then what do you find?

00:19:01.830 --> 00:19:04.470
Well, in the 16th
century, as you mentioned,

00:19:04.470 --> 00:19:09.490
very quickly, the new technology
allows severe polarization

00:19:09.490 --> 00:19:09.990
to happen--

00:19:09.990 --> 00:19:11.310
QUENTIN HARDY: And
those in the tower

00:19:11.310 --> 00:19:12.390
want to reassert themselves.

00:19:12.390 --> 00:19:14.640
NIALL FERGUSON: And the
church says, whoa, whoa, whoa,

00:19:14.640 --> 00:19:15.360
stop all this.

00:19:15.360 --> 00:19:17.820
People like me from northern
Europe say to Luther,

00:19:17.820 --> 00:19:19.180
you're absolutely right.

00:19:19.180 --> 00:19:21.180
But you haven't gone
nearly far enough.

00:19:21.180 --> 00:19:22.180
You need to meet Calvin.

00:19:22.180 --> 00:19:23.763
And then the people
in southern Europe

00:19:23.763 --> 00:19:25.740
go, you are all
heretics, and we are

00:19:25.740 --> 00:19:28.180
going to burn your ass
as well as your books.

00:19:28.180 --> 00:19:31.710
And so the whole thing
escalates into 130 years

00:19:31.710 --> 00:19:35.910
of extraordinary bloodshed that
culminates in the 30 Years War.

00:19:35.910 --> 00:19:38.220
When I look at
where we are now, I

00:19:38.220 --> 00:19:42.416
worry that we've created
engines of polarization online.

00:19:42.416 --> 00:19:43.540
And it ain't just Facebook.

00:19:43.540 --> 00:19:44.500
It ain't just Twitter.

00:19:44.500 --> 00:19:47.760
It's YouTube, and you know
it, and the problem is that

00:19:47.760 --> 00:19:50.490
they're designed to polarize .

00:19:50.490 --> 00:19:54.030
They're designed to move
people along the spectrum

00:19:54.030 --> 00:19:56.499
from more moderate to
more extreme opinions.

00:19:56.499 --> 00:19:58.165
QUENTIN HARDY: Those
are neutral, Niall.

00:19:58.165 --> 00:19:59.655
They're not designed--

00:19:59.655 --> 00:20:01.730
NIALL FERGUSON: This
wasn't meant to happen,

00:20:01.730 --> 00:20:04.650
but nor was Martin
Luther setting out

00:20:04.650 --> 00:20:07.080
to start 130 years
of religious war.

00:20:07.080 --> 00:20:08.105
That was not the plan.

00:20:08.105 --> 00:20:08.760
QUENTIN HARDY: Fair.

00:20:08.760 --> 00:20:10.385
NIALL FERGUSON: The
only law in history

00:20:10.385 --> 00:20:11.970
is the law of
unintended consequences.

00:20:11.970 --> 00:20:14.880
And here we, I think,
need to be quite careful

00:20:14.880 --> 00:20:18.870
because what worries me
in the current climate

00:20:18.870 --> 00:20:24.450
is that what is already verbal
violence may not stop there

00:20:24.450 --> 00:20:28.350
because there is a history
of crossing from the verbal

00:20:28.350 --> 00:20:29.940
to the actual.

00:20:29.940 --> 00:20:31.920
The American Civil
War was prefigured

00:20:31.920 --> 00:20:36.780
by roughly 20 years of ferocious
debate on the whole gamut

00:20:36.780 --> 00:20:39.000
of issues from slavery
itself to states' rights

00:20:39.000 --> 00:20:41.740
to the nature of
racial difference.

00:20:41.740 --> 00:20:44.100
It's certainly towards
the end of this process

00:20:44.100 --> 00:20:45.690
that actual violence begins.

00:20:45.690 --> 00:20:48.210
Or take another good example.

00:20:48.210 --> 00:20:51.150
Islam is the religion
that's been most affected

00:20:51.150 --> 00:20:52.330
by the internet.

00:20:52.330 --> 00:20:55.440
I don't think anybody would have
predicted that at the outset,

00:20:55.440 --> 00:20:57.270
but that's what happened.

00:20:57.270 --> 00:21:00.120
And it's because the
internet coincided

00:21:00.120 --> 00:21:03.270
with two great waves
of fundamentalism

00:21:03.270 --> 00:21:05.890
in the Sunni and Shia
worlds, circa 1979,

00:21:05.890 --> 00:21:08.100
just as the internet
is getting going.

00:21:08.100 --> 00:21:10.680
And since then,
what's happened is,

00:21:10.680 --> 00:21:13.230
the different networks
that have evolved

00:21:13.230 --> 00:21:17.190
have become very powerful
tools of propounding

00:21:17.190 --> 00:21:19.860
what we'll call fundamentalist
or literalist versions

00:21:19.860 --> 00:21:21.050
of Islam.

00:21:21.050 --> 00:21:22.440
That already is violent.

00:21:22.440 --> 00:21:25.170
A huge proportion of
what we call terrorism

00:21:25.170 --> 00:21:27.360
is currently conducted
around the world

00:21:27.360 --> 00:21:29.640
by various kinds
of Islamist groups,

00:21:29.640 --> 00:21:32.820
notoriously Islamic state
Boko Haram and so forth.

00:21:32.820 --> 00:21:36.240
So I think it's already the case
that our networked world has

00:21:36.240 --> 00:21:39.450
become violent, at
least in one domain.

00:21:39.450 --> 00:21:41.190
There is no reason
why it should not

00:21:41.190 --> 00:21:43.800
become violent in the
realm of secular politics.

00:21:43.800 --> 00:21:45.915
That's my big worry.

00:21:45.915 --> 00:21:47.527
QUENTIN HARDY: You're
not a fatalist.

00:21:47.527 --> 00:21:49.860
You think it's in the hands
of the people in the moment.

00:21:49.860 --> 00:21:50.984
NIALL FERGUSON: Absolutely.

00:21:50.984 --> 00:21:52.710
QUENTIN HARDY: And
the tools are neutral.

00:21:52.710 --> 00:21:55.380
And most of the online
groups, it really

00:21:55.380 --> 00:22:00.790
is notable that most of the
online political groups so far,

00:22:00.790 --> 00:22:03.150
and this would go to some
elements of social media

00:22:03.150 --> 00:22:08.730
as well, are better
at tearing things down

00:22:08.730 --> 00:22:12.690
than programmatically building
new things, with the exception

00:22:12.690 --> 00:22:17.020
of things like Wikipedia,
where the group knows the rules

00:22:17.020 --> 00:22:21.930
and can contribute in
a very formalized way.

00:22:21.930 --> 00:22:28.200
But for the most part, something
like an Al-Qaeda can destroy,

00:22:28.200 --> 00:22:32.280
but it cannot get the mail
delivered particularly well,

00:22:32.280 --> 00:22:34.890
or deliver basic needs
particularly well,

00:22:34.890 --> 00:22:36.990
or establish a durable
society particularly well.

00:22:36.990 --> 00:22:38.531
NIALL FERGUSON: I
mean, Islamic state

00:22:38.531 --> 00:22:40.680
turned out to be very
bad at being a state,

00:22:40.680 --> 00:22:42.990
but it's very good at
being an online network,

00:22:42.990 --> 00:22:45.990
and as an online network,
it's very good at radicalizing

00:22:45.990 --> 00:22:46.590
young people.

00:22:46.590 --> 00:22:47.550
QUENTIN HARDY: So
doesn't that also mean

00:22:47.550 --> 00:22:49.300
it exhausts itself over time?

00:22:49.300 --> 00:22:50.440
It's not sustainable.

00:22:50.440 --> 00:22:51.315
NIALL FERGUSON: Well.

00:22:51.315 --> 00:22:53.850
I'd love to see evidence that
the network was shrinking.

00:22:53.850 --> 00:22:55.920
I don't see it at this point.

00:22:55.920 --> 00:22:58.740
If anything, look at what
just happened in France.

00:22:58.740 --> 00:23:02.650
The network is growing, as
far as we can measure it.

00:23:02.650 --> 00:23:06.120
There is something of a plateau
in terms of terrorist attacks

00:23:06.120 --> 00:23:08.520
and casualties over,
the last three years

00:23:08.520 --> 00:23:13.470
or so but there's no decline, no
meaningful statistical decline,

00:23:13.470 --> 00:23:17.310
if you look at the data from
the START folks at Maryland.

00:23:17.310 --> 00:23:19.890
So I don't see it.

00:23:19.890 --> 00:23:20.880
I'd love to see it.

00:23:20.880 --> 00:23:24.240
I would love to believe
that the radical ideologies

00:23:24.240 --> 00:23:26.250
of the present will
burn themselves out.

00:23:26.250 --> 00:23:29.220
But the bad news is, if one
looks at the 20th century

00:23:29.220 --> 00:23:31.650
experience, that
Bolshevism, which

00:23:31.650 --> 00:23:34.800
was the extreme
version of Marxism,

00:23:34.800 --> 00:23:37.530
took a very long
time to burn out.

00:23:37.530 --> 00:23:42.820
I mean, 1917 to 1991 is
a pretty long period.

00:23:42.820 --> 00:23:45.870
And during that period,
Soviet communism

00:23:45.870 --> 00:23:48.780
remained a very powerful
disruptive force

00:23:48.780 --> 00:23:51.420
in the third world,
right into the 1980s.

00:23:51.420 --> 00:23:53.340
It really wasn't
until the mid '80s

00:23:53.340 --> 00:23:57.130
that you started to see this
thing running out of steam.

00:23:57.130 --> 00:24:00.300
So let's not assume that
things burn themselves

00:24:00.300 --> 00:24:03.000
out too quickly just out of
a sort of Steve Pinkerish

00:24:03.000 --> 00:24:06.030
optimism that the world just
has to be getting better.

00:24:06.030 --> 00:24:07.650
It feels like it's
getting better.

00:24:07.650 --> 00:24:09.132
Make it get better.

00:24:09.132 --> 00:24:11.340
QUENTIN HARDY: Not to get
all Pollyanna about things,

00:24:11.340 --> 00:24:14.880
but it is healthy to remember
that in the long view

00:24:14.880 --> 00:24:19.170
of history, 1914
to 1989 is probably

00:24:19.170 --> 00:24:22.410
one long conflict about
unwinding colonialism,

00:24:22.410 --> 00:24:24.090
in some form or
other, with Bolshevism

00:24:24.090 --> 00:24:26.370
playing an act in that as well.

00:24:26.370 --> 00:24:28.980
NIALL FERGUSON: And
rebuilding new empires that

00:24:28.980 --> 00:24:31.290
claim to be against
imperialism, one

00:24:31.290 --> 00:24:33.757
Russian and the other American.

00:24:33.757 --> 00:24:36.090
Just to make sure your narrative
doesn't get too simple.

00:24:36.090 --> 00:24:37.714
QUENTIN HARDY: They're
still contending

00:24:37.714 --> 00:24:41.940
in cyberspace and elsewhere.

00:24:41.940 --> 00:24:45.600
I mean, the scale
of human losses,

00:24:45.600 --> 00:24:49.170
70 to 100 million people,
just in the big wars.

00:24:49.170 --> 00:24:53.040
So we may have passed the
crisis point actually,

00:24:53.040 --> 00:24:53.790
and not know it.

00:24:53.790 --> 00:24:55.634
We're not living in
that era of violence

00:24:55.634 --> 00:24:57.300
that our parents and
their parents knew.

00:24:57.300 --> 00:25:01.410
NIALL FERGUSON: Well, that's
certainly right, Quentin.

00:25:01.410 --> 00:25:04.560
Unfortunately, I have to keep
immersing myself in the 1970s

00:25:04.560 --> 00:25:06.590
to finish the
Kissinger biography,

00:25:06.590 --> 00:25:10.230
and each time I go back to the
material relating to the United

00:25:10.230 --> 00:25:12.412
States and the world
in the early 1970s,

00:25:12.412 --> 00:25:14.661
I'm reminded of how much
worse that time was than now.

00:25:14.661 --> 00:25:14.790
I mean, it's much, much worse.

00:25:14.790 --> 00:25:17.820
QUENTIN HARDY: '68 to '71,
2,000 bombings in America.

00:25:17.820 --> 00:25:20.550
NIALL FERGUSON: There's much
more warfare around the world.

00:25:20.550 --> 00:25:22.008
In most parts of
the world, there's

00:25:22.008 --> 00:25:23.580
some kind of conflict going on.

00:25:23.580 --> 00:25:25.345
Homicide rates are
higher in the US.

00:25:25.345 --> 00:25:27.470
There's a lot more really
violent student protests.

00:25:27.470 --> 00:25:30.550
Today's snowflakes, even
on the Berkeley campus,

00:25:30.550 --> 00:25:33.099
are like such losers compared
with the people who were

00:25:33.099 --> 00:25:34.640
running the anti-war
demonstrations--

00:25:34.640 --> 00:25:35.950
QUENTIN HARDY: Do
not get personal!

00:25:35.950 --> 00:25:36.545
NIALL FERGUSON: --in the
late '60s and the 1970s.

00:25:36.545 --> 00:25:37.590
But it's true, right?

00:25:37.590 --> 00:25:40.830
So when we tell ourselves
things are really terrible,

00:25:40.830 --> 00:25:43.280
what we should
definitely say is,

00:25:43.280 --> 00:25:47.160
but they're actually not
as bad as they were then.

00:25:47.160 --> 00:25:51.390
But the reason that I hesitate
to go full Steve Pinker is

00:25:51.390 --> 00:25:56.250
that-- and this is a really
vital point that's been made

00:25:56.250 --> 00:26:00.060
most vehemently by Nassim
Taleb, but I think it's right--

00:26:00.060 --> 00:26:02.010
given the capacity
for destruction

00:26:02.010 --> 00:26:06.090
that we have created, not
least with nuclear weapons,

00:26:06.090 --> 00:26:09.330
it does not take much
to completely destroy

00:26:09.330 --> 00:26:10.170
the argument.

00:26:10.170 --> 00:26:12.480
It only takes one
nuclear exchange

00:26:12.480 --> 00:26:17.220
to render the entire thesis all
the better angels of our nature

00:26:17.220 --> 00:26:18.780
and enlightenment now are wrong.

00:26:18.780 --> 00:26:21.090
QUENTIN HARDY: The cost of
violence has collapsed also.

00:26:21.090 --> 00:26:22.380
NIALL FERGUSON: And it's
only a matter of months

00:26:22.380 --> 00:26:24.171
ago that the President
of the United States

00:26:24.171 --> 00:26:26.220
was talking about fire
and fury in connection

00:26:26.220 --> 00:26:28.300
with the nuclear
program in North Korea.

00:26:28.300 --> 00:26:30.780
So I think one thing
I've learned from history

00:26:30.780 --> 00:26:33.300
is, don't be a trend follower.

00:26:33.300 --> 00:26:36.460
Don't just assume that the
future is a projection forward

00:26:36.460 --> 00:26:40.410
of that nice line you just
identified in the data

00:26:40.410 --> 00:26:43.110
because history has all kinds
of non-linear qualities.

00:26:43.110 --> 00:26:45.660
There were plenty
of people in 1911

00:26:45.660 --> 00:26:47.370
who thought Norman
Angel was right

00:26:47.370 --> 00:26:49.567
when he said war had
become a great illusion.

00:26:49.567 --> 00:26:51.150
And three years
later, the biggest war

00:26:51.150 --> 00:26:53.100
that had ever
happened broke out,

00:26:53.100 --> 00:26:55.770
to the surprise of
nearly all people.

00:26:55.770 --> 00:26:59.190
One thing that I did
get very fascinated by,

00:26:59.190 --> 00:27:02.550
around 10 years ago, was
the total unexpectedness,

00:27:02.550 --> 00:27:06.750
even to sophisticated players,
of the outbreak World War I.

00:27:06.750 --> 00:27:10.050
Historians write about it
like it was very predictable.

00:27:10.050 --> 00:27:12.270
Oh, this thing had its
origins in the 1870s.

00:27:12.270 --> 00:27:14.396
Oh, no, it had its
origins in 1815.

00:27:14.396 --> 00:27:16.020
But it didn't have
its origins anywhere

00:27:16.020 --> 00:27:19.200
if you were actually there at
the time in the summer of 1914.

00:27:19.200 --> 00:27:22.020
For most people, it's
a complete surprise

00:27:22.020 --> 00:27:23.880
that they're suddenly
in a massive war.

00:27:23.880 --> 00:27:27.060
And it's also surprising that it
lasts four and a quarter years

00:27:27.060 --> 00:27:29.530
and kills more than
10 million people.

00:27:29.530 --> 00:27:33.090
So we have to remember, at
any historical moment in time,

00:27:33.090 --> 00:27:37.050
we can't predict, with
any model, the future,

00:27:37.050 --> 00:27:40.290
and we need to be
aware of scenarios that

00:27:40.290 --> 00:27:43.590
seem really low probability, but
could have very high impacts,

00:27:43.590 --> 00:27:45.450
the so-called black swans.

00:27:45.450 --> 00:27:47.310
I've come to the
conclusion that if you're

00:27:47.310 --> 00:27:49.920
interested in those
black swans, history

00:27:49.920 --> 00:27:51.930
is your best guide
because it will

00:27:51.930 --> 00:27:54.600
help you think
about scenarios that

00:27:54.600 --> 00:27:58.470
are totally outlandish in terms
of your own lived experience.

00:27:58.470 --> 00:28:00.390
Most people in this
room are pretty young.

00:28:00.390 --> 00:28:03.720
Looking around, I'm the
oldest guy in the room,

00:28:03.720 --> 00:28:07.800
but this means your data set,
your personal history data set,

00:28:07.800 --> 00:28:09.455
is laughably small.

00:28:09.455 --> 00:28:11.580
And you shouldn't really
be running any experiments

00:28:11.580 --> 00:28:12.960
with such a small data set.

00:28:12.960 --> 00:28:15.927
History basically says, let's
have a really large data set.

00:28:15.927 --> 00:28:18.510
Let's include the experience of
all the people who ever lived,

00:28:18.510 --> 00:28:21.210
who vastly outnumber
the living, and then

00:28:21.210 --> 00:28:23.680
let's think about what
might happen next.

00:28:23.680 --> 00:28:25.230
QUENTIN HARDY: Now,
let's open it up

00:28:25.230 --> 00:28:26.770
to questions in just a minute.

00:28:26.770 --> 00:28:30.750
But I also wanted to
refer to the reassertion

00:28:30.750 --> 00:28:32.700
of existing power,
which also happens

00:28:32.700 --> 00:28:34.140
in these moments of crises.

00:28:34.140 --> 00:28:36.130
We didn't touch on
the 19th century,

00:28:36.130 --> 00:28:41.310
but really starting with
the Congress of Vienna,

00:28:41.310 --> 00:28:43.320
and then moving through
these industrial,

00:28:43.320 --> 00:28:48.240
as you put it, very
centripetal industrial forces,

00:28:48.240 --> 00:28:51.570
there was a return to
centralized control.

00:28:51.570 --> 00:28:55.230
Today, we see a
call to regulate.

00:28:55.230 --> 00:28:59.160
We see a call for
authoritarian states

00:28:59.160 --> 00:29:02.850
to use the new
systems of technology

00:29:02.850 --> 00:29:06.060
to keep an even tighter
handle on population.

00:29:06.060 --> 00:29:09.060
Are we moving to a phase
of even greater control

00:29:09.060 --> 00:29:10.810
by a few incumbent powers?

00:29:10.810 --> 00:29:13.710
NIALL FERGUSON: Well, it's
already happened in the sense

00:29:13.710 --> 00:29:17.940
that in China, the square
and the tower are one.

00:29:17.940 --> 00:29:19.620
That's to say, the
network platforms

00:29:19.620 --> 00:29:22.500
that evolved in China,
Baidu, Alibaba, Tencent,

00:29:22.500 --> 00:29:25.290
are in a close
relationship, shall we

00:29:25.290 --> 00:29:28.270
say, with the Communist
Party that runs the country,

00:29:28.270 --> 00:29:32.850
and data on those platforms are
essentially available on demand

00:29:32.850 --> 00:29:34.200
to Xi Jinping.

00:29:34.200 --> 00:29:37.500
So we already have an
answer to that question

00:29:37.500 --> 00:29:39.600
for a really large
proportion of humanity.

00:29:39.600 --> 00:29:45.420
The second problem is that
in Europe, because there

00:29:45.420 --> 00:29:47.610
are no major technology
companies there,

00:29:47.610 --> 00:29:51.000
they've embarked on the
regulatory process ahead

00:29:51.000 --> 00:29:52.500
of the United States.

00:29:52.500 --> 00:29:54.420
And the future of tech
companies in Europe

00:29:54.420 --> 00:29:59.850
is higher taxation, tighter
regulation, and hefty fines,

00:29:59.850 --> 00:30:02.250
and the responsibilities
being put on tech companies

00:30:02.250 --> 00:30:04.650
for, in effect, censorship.

00:30:04.650 --> 00:30:08.160
If you let hate speech be on
the platform for any period

00:30:08.160 --> 00:30:09.840
of time, we're going
to clobber you,

00:30:09.840 --> 00:30:12.840
and that is a responsibility
that no major company

00:30:12.840 --> 00:30:14.760
can really want to have.

00:30:14.760 --> 00:30:19.180
The US is the unresolved
puzzle, and I'll say two things.

00:30:19.180 --> 00:30:23.730
Number one, unlike in the
age of the printing press,

00:30:23.730 --> 00:30:27.870
hierarchy evolved in
itself and of itself

00:30:27.870 --> 00:30:32.700
in Silicon Valley, that what
never happened to the printing

00:30:32.700 --> 00:30:34.860
press was centralization
and the emergence

00:30:34.860 --> 00:30:37.532
of giant network platforms.

00:30:37.532 --> 00:30:39.240
And that's why very
few billionaires were

00:30:39.240 --> 00:30:41.130
produced by the printing press.

00:30:41.130 --> 00:30:45.210
It stayed a distributed
network, and not

00:30:45.210 --> 00:30:47.940
many people sought to make
money, sought to monetize

00:30:47.940 --> 00:30:49.590
print data through advertising.

00:30:49.590 --> 00:30:52.590
Advertising, they're in
newspapers and magazines,

00:30:52.590 --> 00:30:54.520
but books don't
carry advertisements,

00:30:54.520 --> 00:30:56.830
and public libraries don't
carry advertisements.

00:30:56.830 --> 00:30:59.670
So the evolution of print
technology was different.

00:30:59.670 --> 00:31:02.280
Our technology
evolved very rapidly

00:31:02.280 --> 00:31:05.280
in the direction of
monetizing of data,

00:31:05.280 --> 00:31:10.170
and that led to the emergence
of these network platforms,

00:31:10.170 --> 00:31:12.120
of which Google is one.

00:31:12.120 --> 00:31:16.200
And I think in that sense, the
hierarchy has already formed.

00:31:16.200 --> 00:31:18.030
The question is,
what's the relationship

00:31:18.030 --> 00:31:20.062
between the Silicon
Valley hierarchy

00:31:20.062 --> 00:31:21.770
and the federal
government in Washington?

00:31:21.770 --> 00:31:23.520
And that's the question
that's going to be

00:31:23.520 --> 00:31:25.902
answered in the coming months.

00:31:25.902 --> 00:31:28.110
And I think it's very hard
to predict, at this point,

00:31:28.110 --> 00:31:29.340
quite what the answer will be.

00:31:29.340 --> 00:31:31.140
QUENTIN HARDY: You talk
to people on both sides.

00:31:31.140 --> 00:31:32.940
How would you characterize
their feeling?

00:31:32.940 --> 00:31:35.665
Mutual incomprehension?

00:31:35.665 --> 00:31:37.290
NIALL FERGUSON: A
little bit, because I

00:31:37.290 --> 00:31:41.160
think Washington is full
of people who don't even

00:31:41.160 --> 00:31:43.120
use the technology.

00:31:43.120 --> 00:31:46.410
I mean, the striking thing to me
is how many eminent legislators

00:31:46.410 --> 00:31:47.494
are totally clueless.

00:31:47.494 --> 00:31:48.660
QUENTIN HARDY: I was struck.

00:31:48.660 --> 00:31:51.780
Christopher Wiley was
testifying about his work

00:31:51.780 --> 00:31:54.390
at Cambridge Analytica
and Parliament,

00:31:54.390 --> 00:31:56.880
and he actually, in
an aside, started

00:31:56.880 --> 00:31:59.020
moaning about talking to
government regulators.

00:31:59.020 --> 00:32:02.700
I have to keep explaining to
them how this stuff works.

00:32:02.700 --> 00:32:05.490
And they're asking questions
no database engineer would ever

00:32:05.490 --> 00:32:06.480
ask me.

00:32:06.480 --> 00:32:07.929
Sorry, kid, you know?

00:32:07.929 --> 00:32:10.220
NIALL FERGUSON: I think there
is mutual incomprehension

00:32:10.220 --> 00:32:13.650
in the sense that there
has been a great--

00:32:13.650 --> 00:32:15.330
I've been struck by
it, in Washington,

00:32:15.330 --> 00:32:17.040
when I talk to
people, that there

00:32:17.040 --> 00:32:20.520
is a kind of a duh
response to much

00:32:20.520 --> 00:32:23.200
of what one says
about what's happened.

00:32:23.200 --> 00:32:25.170
But I think at the
same time, there's

00:32:25.170 --> 00:32:28.020
a lack of political knowledge,
a lack of political awareness

00:32:28.020 --> 00:32:30.000
in some of the companies.

00:32:30.000 --> 00:32:33.540
Not Google so much
because I think

00:32:33.540 --> 00:32:37.800
I have to give credit to your
recently departed chairman,

00:32:37.800 --> 00:32:42.540
Eric Schmidt, who incidentally
read this book in manuscripts

00:32:42.540 --> 00:32:45.480
and helped me get stuff
right that I probably

00:32:45.480 --> 00:32:49.080
wouldn't have got right,
just in my own reading.

00:32:49.080 --> 00:32:51.780
But he, I think, understood
that the big tech companies

00:32:51.780 --> 00:32:56.070
have to have a relationship
with government.

00:32:56.070 --> 00:32:59.490
Others have been more aloof,
and I think one reason that

00:32:59.490 --> 00:33:02.640
Facebook is in trouble at the
moment is that it didn't think

00:33:02.640 --> 00:33:05.130
it needed to stoop to-- hah!--

00:33:05.130 --> 00:33:07.560
meet the mere President
of the United States.

00:33:07.560 --> 00:33:10.440
That kind of hubris does
almost always lead to nemesis.

00:33:10.440 --> 00:33:12.930
But as I said, it's not clear
how this plays out, given

00:33:12.930 --> 00:33:14.839
the mutual incomprehension.

00:33:14.839 --> 00:33:16.380
We have a whole
bunch of options that

00:33:16.380 --> 00:33:19.410
are going to be discussed
in the coming months.

00:33:19.410 --> 00:33:21.340
Antitrust is one.

00:33:21.340 --> 00:33:23.820
Regulate them as
utilities is another.

00:33:23.820 --> 00:33:26.460
Change the legal standings
so that there can

00:33:26.460 --> 00:33:28.320
be more litigation is a third.

00:33:28.320 --> 00:33:30.120
I wish I knew which
one it would be,

00:33:30.120 --> 00:33:32.100
but I'm pretty
confident of one thing.

00:33:32.100 --> 00:33:35.490
The status quo is over
or in its last inning,

00:33:35.490 --> 00:33:37.740
and things will look a lot
different a couple of years

00:33:37.740 --> 00:33:38.050
from now.

00:33:38.050 --> 00:33:38.925
QUENTIN HARDY: Right.

00:33:38.925 --> 00:33:42.400
Well, I will not speculate on
other companies' characters

00:33:42.400 --> 00:33:46.342
or motives, but I will welcome
questions from the floor.

00:33:46.342 --> 00:33:47.800
Speak up to the
microphone, please.

00:33:51.540 --> 00:33:53.500
AUDIENCE: It's such an
honor to hear you speak.

00:33:53.500 --> 00:33:54.875
I've read a couple
of your books,

00:33:54.875 --> 00:33:57.670
and I've never encountered
an author who's

00:33:57.670 --> 00:34:00.517
like-- every single book that
he writes, I'm interested in.

00:34:00.517 --> 00:34:02.600
QUENTIN HARDY: So far, so
good with this question.

00:34:02.600 --> 00:34:06.129
NIALL FERGUSON: You're going
to say the word "but" now.

00:34:06.129 --> 00:34:07.420
AUDIENCE: I have two questions.

00:34:07.420 --> 00:34:10.840
One is, I think it's
really ironic that now

00:34:10.840 --> 00:34:13.486
that information is so
easily disseminated, right,

00:34:13.486 --> 00:34:14.860
and everything is
so distributed,

00:34:14.860 --> 00:34:18.070
that you see the
banking elites have more

00:34:18.070 --> 00:34:20.409
power than ever, right, what's
happening in the European

00:34:20.409 --> 00:34:21.229
Union.

00:34:21.229 --> 00:34:23.020
We're talking about
one world currency now,

00:34:23.020 --> 00:34:23.894
and things like that.

00:34:23.894 --> 00:34:28.659
So using your framework of
networking and power hierarchy,

00:34:28.659 --> 00:34:31.300
do you predict any future
trends that you see?

00:34:31.300 --> 00:34:35.920
Like do you continue to see the
global elites having more power

00:34:35.920 --> 00:34:37.690
and complete
domination of humanity,

00:34:37.690 --> 00:34:41.500
or do you see maybe something
like blockchain technology,

00:34:41.500 --> 00:34:44.550
cryptocurrency, something
distributed, finally

00:34:44.550 --> 00:34:46.719
taking them down, right?

00:34:46.719 --> 00:34:48.290
So that's my first question.

00:34:48.290 --> 00:34:50.139
And the second
question is, when you

00:34:50.139 --> 00:34:53.230
do researches on books
such as the Rothschilds,

00:34:53.230 --> 00:34:57.040
right, I mean, it's really hard
to really paint an accurate

00:34:57.040 --> 00:35:00.010
picture of what the real power
hierarchy is in this world,

00:35:00.010 --> 00:35:02.440
right, just because nobody
really knows who owns what

00:35:02.440 --> 00:35:04.270
and who calls the shots, right?

00:35:04.270 --> 00:35:08.260
So I was wondering if you have
gained very special access

00:35:08.260 --> 00:35:12.700
to some of these systems or
some of these people in order

00:35:12.700 --> 00:35:14.620
to do your work?

00:35:14.620 --> 00:35:16.120
NIALL FERGUSON: Two
great questions.

00:35:16.120 --> 00:35:17.703
There's quite a line
behind you so I'm

00:35:17.703 --> 00:35:19.600
going to give pretty
brief answers so that we

00:35:19.600 --> 00:35:22.060
can get through as many as
we can in the 15 minutes

00:35:22.060 --> 00:35:23.590
we have left.

00:35:23.590 --> 00:35:28.030
I think the financial
elites successfully

00:35:28.030 --> 00:35:34.180
withstood the financial
crisis by essentially going

00:35:34.180 --> 00:35:38.170
hand in glove with the
federal government,

00:35:38.170 --> 00:35:42.160
and making sure that the
regulatory cost of doing that

00:35:42.160 --> 00:35:43.900
was kept to a minimum.

00:35:43.900 --> 00:35:46.270
Look at the complexity of
Dodd-Frank which, in any case,

00:35:46.270 --> 00:35:48.610
is probably going
to be scrapped.

00:35:48.610 --> 00:35:53.650
The price that they paid for the
bailouts has been pretty small,

00:35:53.650 --> 00:35:57.100
and if anything, it's entrenched
the position of the surviving

00:35:57.100 --> 00:35:58.180
banks.

00:35:58.180 --> 00:36:00.130
What are the two
challenges they face?

00:36:00.130 --> 00:36:05.410
Number one, populism-- the
disgust of middle America, not

00:36:05.410 --> 00:36:07.870
to mention provincial Britain
and many other places,

00:36:07.870 --> 00:36:10.480
with that outcome is
real, and it isn't

00:36:10.480 --> 00:36:12.550
over as a political force.

00:36:12.550 --> 00:36:16.750
Number two, I think, and this
goes to the blockchain point,

00:36:16.750 --> 00:36:20.350
that they still haven't really
got a handle on what could be

00:36:20.350 --> 00:36:22.300
the next financial revolution.

00:36:22.300 --> 00:36:24.550
The disparaging remarks
of certain bankers

00:36:24.550 --> 00:36:27.340
I'll not name about Bitcoin--

00:36:27.340 --> 00:36:28.630
it's tulip mania.

00:36:28.630 --> 00:36:30.740
I can't take this
seriously-- betrayed,

00:36:30.740 --> 00:36:33.280
I think, some ignorance
as well as some fear.

00:36:33.280 --> 00:36:34.960
So I think there is a challenge.

00:36:34.960 --> 00:36:39.310
I think blockchain is a
real potentially disruptive

00:36:39.310 --> 00:36:40.410
technology.

00:36:40.410 --> 00:36:42.140
I hate to use the
word disruptive,

00:36:42.140 --> 00:36:43.870
but I think it
does at least have

00:36:43.870 --> 00:36:49.030
the promise of some
re-decentralization

00:36:49.030 --> 00:36:49.920
of the internet.

00:36:49.920 --> 00:36:51.970
But it's very early
days, and my hunch

00:36:51.970 --> 00:36:54.212
is that the use case that
matters is not money.

00:36:54.212 --> 00:36:56.795
And we'll look back and say, do
you remember all that nonsense

00:36:56.795 --> 00:36:57.989
about cryptocurrency?

00:36:57.989 --> 00:37:00.280
We should have realized that
blockchain wouldn't really

00:37:00.280 --> 00:37:02.530
provide a new form of money.

00:37:02.530 --> 00:37:04.510
Finally, you can't
write a history

00:37:04.510 --> 00:37:08.080
of an institution like
the Rothschild banks

00:37:08.080 --> 00:37:10.330
without access to
the archives, and I

00:37:10.330 --> 00:37:14.090
did get that access at a time
when it was quite restricted.

00:37:14.090 --> 00:37:18.400
It's now pretty open, since my
book was published in the '90s.

00:37:18.400 --> 00:37:20.980
Now, scholars can go to the
Rothschild archive in London

00:37:20.980 --> 00:37:24.160
and have pretty much unlimited
access to what is there.

00:37:24.160 --> 00:37:27.370
And my view is that that's a
very good thing because this

00:37:27.370 --> 00:37:30.490
was a powerful important
institution, probably

00:37:30.490 --> 00:37:33.010
more powerful than any
financial institution today,

00:37:33.010 --> 00:37:34.790
in the 19th century.

00:37:34.790 --> 00:37:36.880
But its power has
been exaggerated often

00:37:36.880 --> 00:37:39.670
by conspiracy theorists,
and it's very healthy

00:37:39.670 --> 00:37:41.830
to let the daylight
of serious scholarship

00:37:41.830 --> 00:37:46.210
in and show that they had
power, but not the kind of power

00:37:46.210 --> 00:37:49.210
that the anti-Semites
used to claim.

00:37:49.210 --> 00:37:51.460
QUENTIN HARDY: I'll just
footnote what he said quickly

00:37:51.460 --> 00:37:53.020
about blockchain.

00:37:53.020 --> 00:37:55.120
I, think symbolically
and psychologically,

00:37:55.120 --> 00:37:58.510
it's certainly interesting
because the dominant power

00:37:58.510 --> 00:38:00.220
form is the nation state.

00:38:00.220 --> 00:38:03.550
And it likes to express itself
in controlling violence,

00:38:03.550 --> 00:38:06.070
in printing money, and
in printing stamps, which

00:38:06.070 --> 00:38:09.670
are all statements about
where the border ends, right?

00:38:09.670 --> 00:38:11.080
The police go to here.

00:38:11.080 --> 00:38:13.440
If we have to go past the
border, we go to the army.

00:38:13.440 --> 00:38:15.070
A stamp costs this much.

00:38:15.070 --> 00:38:16.990
If you go past the
border, it costs more.

00:38:16.990 --> 00:38:18.640
This currency is good to here.

00:38:18.640 --> 00:38:21.070
You need somebody else's
currency past that.

00:38:21.070 --> 00:38:23.830
And email has
pretty much hollowed

00:38:23.830 --> 00:38:26.650
out the need for stamps.

00:38:26.650 --> 00:38:29.357
I think state controlled
violence is still

00:38:29.357 --> 00:38:31.690
its own thing, although there
are these insurgent groups

00:38:31.690 --> 00:38:33.040
doing their thing.

00:38:33.040 --> 00:38:35.230
And blockchain is
attacking currency

00:38:35.230 --> 00:38:38.684
on a transnational basis,
so that these things

00:38:38.684 --> 00:38:40.600
are presented in a way
that seem like a threat

00:38:40.600 --> 00:38:41.470
to the nation state.

00:38:41.470 --> 00:38:45.730
The dominant form
is provocative.

00:38:45.730 --> 00:38:46.792
Next question.

00:38:46.792 --> 00:38:48.250
AUDIENCE: Thanks
for coming, Niall.

00:38:48.250 --> 00:38:50.590
Recently, I watched on
YouTube a phenomenal debate

00:38:50.590 --> 00:38:54.460
you had about a year ago with
Fareed Zakaria at the Munk

00:38:54.460 --> 00:38:57.690
Debates on the end of the
liberal world order, which was

00:38:57.690 --> 00:38:59.160
the proposition you supported.

00:38:59.160 --> 00:39:00.910
What I don't understand,
is that something

00:39:00.910 --> 00:39:02.420
you still agree with today?

00:39:02.420 --> 00:39:05.500
And in particular, what does
your research on networks

00:39:05.500 --> 00:39:08.434
inform about that possibility?

00:39:08.434 --> 00:39:09.850
NIALL FERGUSON: I
lost the debate,

00:39:09.850 --> 00:39:13.630
as those of you who watch
it will see, but imagine

00:39:13.630 --> 00:39:16.930
trying to say that the liberal
international order is doomed

00:39:16.930 --> 00:39:19.510
in Toronto, where everybody
thinks that they're liberal,

00:39:19.510 --> 00:39:21.010
international, and orderly.

00:39:21.010 --> 00:39:23.380
So I never had a
chance in that fight.

00:39:23.380 --> 00:39:25.270
But of course,
I've been entirely

00:39:25.270 --> 00:39:28.300
right in terms of what
subsequently happened

00:39:28.300 --> 00:39:30.760
because here we are, in a
trade war between the biggest

00:39:30.760 --> 00:39:32.950
economies in the world,
the US and China.

00:39:32.950 --> 00:39:36.460
And it's real and it's
serious, and it could escalate.

00:39:36.460 --> 00:39:40.600
I think there's no question
that the high tide of free trade

00:39:40.600 --> 00:39:41.720
is behind us.

00:39:41.720 --> 00:39:44.920
The high tide of very free
migration is behind us.

00:39:44.920 --> 00:39:47.730
And the high tide of very free
capital movements is behind us.

00:39:47.730 --> 00:39:51.210
So my argument then, that
globalization overreached

00:39:51.210 --> 00:39:53.960
and that the backlash against
it is going to dial it back,

00:39:53.960 --> 00:39:56.050
I would stand by.

00:39:56.050 --> 00:39:59.290
And I think that one shouldn't
freak out about this because it

00:39:59.290 --> 00:40:02.560
doesn't mean the end of trade
and the end of migration

00:40:02.560 --> 00:40:04.420
and the end of free
capital movement.

00:40:04.420 --> 00:40:07.600
It just, I think, involves a
dialing back of those things.

00:40:07.600 --> 00:40:11.050
They had overshot
in so many ways.

00:40:11.050 --> 00:40:17.110
So I don't look back and say,
when I think about that debate,

00:40:17.110 --> 00:40:17.980
I was so wrong.

00:40:17.980 --> 00:40:20.200
Dear Fareed, I take it all back.

00:40:20.200 --> 00:40:24.210
Actually, I'm going to write him
an email saying, I was right.

00:40:24.210 --> 00:40:26.740
Where's my damn apology?

00:40:26.740 --> 00:40:27.910
Can we rerun the debate?

00:40:27.910 --> 00:40:29.200
I want a rematch.

00:40:32.480 --> 00:40:33.716
AUDIENCE: Hi, Niall.

00:40:33.716 --> 00:40:35.340
I watched a previous
talk that you gave

00:40:35.340 --> 00:40:36.681
about networks and hierarchies.

00:40:36.681 --> 00:40:39.180
Unfortunately, I haven't had a
chance to read this book yet,

00:40:39.180 --> 00:40:40.950
although I enjoyed
your other ones.

00:40:40.950 --> 00:40:44.980
And in it, I believe, and I
could be misunderstanding this,

00:40:44.980 --> 00:40:47.790
that you mentioned that a
lot of times, networks occur.

00:40:47.790 --> 00:40:50.310
They kind of come out of left
wing, and a lot of times,

00:40:50.310 --> 00:40:52.260
hierarchies will come
and then co-opt them.

00:40:52.260 --> 00:40:54.430
And then the network
will kind of cease to be,

00:40:54.430 --> 00:40:55.990
and they've kind
of co-opted this.

00:40:55.990 --> 00:40:56.490
I'm curious.

00:40:56.490 --> 00:41:00.580
If that's correct, then, and you
believe it to be, in this case,

00:41:00.580 --> 00:41:03.286
and you two already
touched on this somewhat,

00:41:03.286 --> 00:41:04.910
it's a little bit
different now in that

00:41:04.910 --> 00:41:07.040
there's these massive
tech companies, right?

00:41:07.040 --> 00:41:08.140
It's not completely
decentralized,

00:41:08.140 --> 00:41:10.181
as like before, we're
talking about communication

00:41:10.181 --> 00:41:11.610
and the internet, what have you.

00:41:11.610 --> 00:41:12.560
I'm curious.

00:41:12.560 --> 00:41:14.570
In this sense, is
the hierarchy that

00:41:14.570 --> 00:41:17.360
might come in to co-opt
this whole network,

00:41:17.360 --> 00:41:20.300
is this traditional
government or is

00:41:20.300 --> 00:41:22.790
this the private sector
in the form of goals

00:41:22.790 --> 00:41:24.415
and what have you?

00:41:24.415 --> 00:41:25.280
Just curious.

00:41:25.280 --> 00:41:27.488
NIALL FERGUSON: Yeah, this
is very much the right way

00:41:27.488 --> 00:41:28.450
of thinking about it.

00:41:28.450 --> 00:41:32.630
The book argues that
because social networks are

00:41:32.630 --> 00:41:36.260
complex systems with
emergent properties--

00:41:36.260 --> 00:41:38.630
they can undergo phased
transitions-- they themselves

00:41:38.630 --> 00:41:40.430
can quite quickly go
from a distributed

00:41:40.430 --> 00:41:42.410
architecture to a
centralized architecture,

00:41:42.410 --> 00:41:43.910
all by themselves.

00:41:43.910 --> 00:41:46.400
But what commonly
happens, historically,

00:41:46.400 --> 00:41:50.600
is that the revolutionary
network ends up

00:41:50.600 --> 00:41:53.450
in some way being co-opted
by the established hierarchy.

00:41:53.450 --> 00:41:54.740
It happened to Napoleon.

00:41:54.740 --> 00:41:58.490
I mean, he ends up saying,
hey, can I be crowned emperor?

00:41:58.490 --> 00:41:59.940
I like the outfit.

00:41:59.940 --> 00:42:05.000
And so most hierarchies,
and if they're to survive,

00:42:05.000 --> 00:42:08.630
have to have the skill of
absorbing the new network.

00:42:08.630 --> 00:42:11.480
And I think that's a fairly
clear and recurrent theme

00:42:11.480 --> 00:42:12.740
of the book.

00:42:12.740 --> 00:42:19.400
In our own time, I think it's
been an easy thing, in China,

00:42:19.400 --> 00:42:23.000
to simply take the square
that formed in the big tech

00:42:23.000 --> 00:42:25.520
companies and say,
seamlessly, you're

00:42:25.520 --> 00:42:28.790
going to be part of
the party hierarchy.

00:42:28.790 --> 00:42:31.820
And the pyramidal structure
of the Communist Party

00:42:31.820 --> 00:42:34.580
lends itself to
that pretty well.

00:42:34.580 --> 00:42:36.860
I think in the case
of the United States,

00:42:36.860 --> 00:42:38.510
it was happening.

00:42:38.510 --> 00:42:41.990
The National Security Agency was
co-opting the tech companies,

00:42:41.990 --> 00:42:44.070
and then Snowden
blew the whistle.

00:42:44.070 --> 00:42:47.540
Now, I keep asking people in
the intelligence community,

00:42:47.540 --> 00:42:51.350
did that really change
everything and stop it, or is

00:42:51.350 --> 00:42:54.430
it all still going on
and we just don't know?

00:42:54.430 --> 00:42:56.620
And they all look
at me and they say,

00:42:56.620 --> 00:42:58.250
but you don't have
security clearance,

00:42:58.250 --> 00:42:59.670
so I can't tell you that.

00:42:59.670 --> 00:43:00.659
So I don't know.

00:43:00.659 --> 00:43:02.950
I don't know, but that's the
process I'm talking about.

00:43:06.310 --> 00:43:08.580
AUDIENCE: Thanks very
much for the talk.

00:43:08.580 --> 00:43:12.220
I really appreciate this
notion that basically there

00:43:12.220 --> 00:43:14.990
are concepts that historians
will use to reason

00:43:14.990 --> 00:43:16.410
about bodies of people.

00:43:16.410 --> 00:43:19.700
You reference Marxism
using class based thinking,

00:43:19.700 --> 00:43:22.820
and ideally you would basically
be able to look at network data

00:43:22.820 --> 00:43:25.550
and discover the
communities of people

00:43:25.550 --> 00:43:28.650
that were most predictive of the
outcomes that you cared about.

00:43:28.650 --> 00:43:32.000
And I guess there's a sense
that historians could basically

00:43:32.000 --> 00:43:34.490
take those concepts and use
those to reason and to make

00:43:34.490 --> 00:43:36.420
predictions, and to
build theory on top of,

00:43:36.420 --> 00:43:38.790
and ideally, make
falsifiable theories.

00:43:38.790 --> 00:43:41.310
So I guess I wonder if there's
actually a promise there,

00:43:41.310 --> 00:43:43.714
if you think this can
be grounded inside

00:43:43.714 --> 00:43:45.380
of the massive amount
of data that we've

00:43:45.380 --> 00:43:46.915
been able to collect.

00:43:46.915 --> 00:43:48.290
NIALL FERGUSON:
I think there is.

00:43:48.290 --> 00:43:52.040
I'm skeptical that
we'll ever really get

00:43:52.040 --> 00:43:55.940
to predicting history because
I think the process is

00:43:55.940 --> 00:43:59.340
so complex that
one can't model it,

00:43:59.340 --> 00:44:02.220
and therefore, one can only
predict in rather circumscribed

00:44:02.220 --> 00:44:03.850
contexts.

00:44:03.850 --> 00:44:06.270
I mean, even predicting
something very circumscribed,

00:44:06.270 --> 00:44:08.880
like what the economy
will do next year,

00:44:08.880 --> 00:44:13.050
turns out to be super difficult.
And as for politics, well,

00:44:13.050 --> 00:44:15.580
you remember the
predictions of 2016

00:44:15.580 --> 00:44:17.850
and how most people
in the business

00:44:17.850 --> 00:44:20.290
of political
prediction were wrong.

00:44:20.290 --> 00:44:24.740
What I would say is that if
you take a thesis like Quentin

00:44:24.740 --> 00:44:27.720
proposed, that any radical
ideological movement will,

00:44:27.720 --> 00:44:30.600
at some point, burn
out, that, I think,

00:44:30.600 --> 00:44:33.390
you could really investigate
using network science

00:44:33.390 --> 00:44:34.680
and history.

00:44:34.680 --> 00:44:36.750
It's fascinating to
me that nobody has yet

00:44:36.750 --> 00:44:40.410
done a serious network-based
analysis of either

00:44:40.410 --> 00:44:44.310
the communist revolution in
Russia, or the rise of Hitler.

00:44:44.310 --> 00:44:46.860
I know more about the latter
because I started my career

00:44:46.860 --> 00:44:49.080
as a historian of
interwar Germany.

00:44:49.080 --> 00:44:52.510
It is amazing that we still are
explaining the rise of Hitler

00:44:52.510 --> 00:44:57.390
with the statistical
techniques of the 1980s.

00:44:57.390 --> 00:44:59.910
Nobody has really
taken any steps forward

00:44:59.910 --> 00:45:01.590
to understand that better.

00:45:01.590 --> 00:45:03.090
And one project I
have at the moment

00:45:03.090 --> 00:45:05.260
at the Hoover
Institution is to try

00:45:05.260 --> 00:45:08.730
to take data on the Nazi
party and the Nazi vote,

00:45:08.730 --> 00:45:12.090
and understand this phenomenon
as something that went viral,

00:45:12.090 --> 00:45:15.000
that was very pernicious
indeed, and try

00:45:15.000 --> 00:45:16.299
to understand its dynamic.

00:45:16.299 --> 00:45:18.090
QUENTIN HARDY: That
would be one area where

00:45:18.090 --> 00:45:20.880
I would say in most
historical analysis,

00:45:20.880 --> 00:45:23.340
you'd have a data quality
problem, but thank you,

00:45:23.340 --> 00:45:25.072
German bureaucrats.

00:45:25.072 --> 00:45:26.280
It's a data-rich environment.

00:45:26.280 --> 00:45:28.571
NIALL FERGUSON: We have very
good data on this process.

00:45:28.571 --> 00:45:33.030
Now, the bad news is that the
Nazi experiment wasn't left--

00:45:33.030 --> 00:45:34.412
oh, did I say bad news?

00:45:34.412 --> 00:45:36.120
The good news is that
the Nazi experiment

00:45:36.120 --> 00:45:38.560
wasn't left to run its course.

00:45:38.560 --> 00:45:43.650
It was annihilated by massive
aerial bombardment and ground

00:45:43.650 --> 00:45:44.670
forces.

00:45:44.670 --> 00:45:48.840
So we actually can
never know how long

00:45:48.840 --> 00:45:51.030
the half life of Nazism
was because it was

00:45:51.030 --> 00:45:53.400
destroyed by exogenous forces.

00:45:53.400 --> 00:45:56.160
But I think we can at least
understand how it grew,

00:45:56.160 --> 00:45:58.426
and the dynamics of its rise.

00:45:58.426 --> 00:46:00.300
With the Russian case,
we have something more

00:46:00.300 --> 00:46:02.790
to go on because although
external pressure has played

00:46:02.790 --> 00:46:06.090
a part, I suspect the truth
of the Soviet collapse

00:46:06.090 --> 00:46:07.620
was that it was internal.

00:46:07.620 --> 00:46:09.245
AUDIENCE: So to make
sure I understand,

00:46:09.245 --> 00:46:12.570
you're proposing that we think
of Nazism as this meme that

00:46:12.570 --> 00:46:14.070
infects some body
of people, and you

00:46:14.070 --> 00:46:16.140
can predict how
far it will cascade

00:46:16.140 --> 00:46:18.731
across your social graph,
and what it's length of time

00:46:18.731 --> 00:46:19.230
will be.

00:46:19.230 --> 00:46:20.896
QUENTIN HARDY: Over
time, it gathers you

00:46:20.896 --> 00:46:22.205
power, influence and charisma,

00:46:22.205 --> 00:46:22.830
AUDIENCE: Yeah.

00:46:22.830 --> 00:46:24.538
That's right, and I
suppose as a function

00:46:24.538 --> 00:46:27.770
of tracking many other similar
memes and the populations

00:46:27.770 --> 00:46:30.570
that we see today, that
we have similar data for.

00:46:30.570 --> 00:46:32.370
NIALL FERGUSON: So
there are people

00:46:32.370 --> 00:46:36.330
who work on this kind of
problem in the recent past,

00:46:36.330 --> 00:46:41.700
like Nicholas Christakis,
or Laszlo Barabasi.

00:46:41.700 --> 00:46:45.210
And my basic suggestion is,
we take these methods which

00:46:45.210 --> 00:46:48.750
look at cascades, social
and political contagion,

00:46:48.750 --> 00:46:51.420
and apply them to what
was perhaps the biggest

00:46:51.420 --> 00:46:55.140
catastrophe of them all, that
the most advanced society

00:46:55.140 --> 00:46:57.540
in Europe that was
Germany in the 1920s

00:46:57.540 --> 00:47:01.560
produces the most
disastrously murderous regime.

00:47:01.560 --> 00:47:04.260
I still think that's one
of the big questions.

00:47:04.260 --> 00:47:06.090
And what's exciting
about network science

00:47:06.090 --> 00:47:07.800
is that it gives
us some new tools

00:47:07.800 --> 00:47:12.090
to work with to try to
understand that process better.

00:47:12.090 --> 00:47:13.590
Will we get to the
point that we can

00:47:13.590 --> 00:47:17.820
predict the course of
comparable extremist movements?

00:47:17.820 --> 00:47:18.842
Probably not.

00:47:18.842 --> 00:47:20.550
But I think we'll
understand a little bit

00:47:20.550 --> 00:47:22.550
better what to look for.

00:47:22.550 --> 00:47:25.140
And I'm excited by
that prospect because I

00:47:25.140 --> 00:47:28.650
think we have
enough data to chart

00:47:28.650 --> 00:47:31.290
the course of the movement,
and understand what

00:47:31.290 --> 00:47:33.000
things accelerated that course.

00:47:33.000 --> 00:47:37.590
Why was it some places and not
others that went for Hitler?

00:47:37.590 --> 00:47:39.180
Those sorts of
questions seemed to me

00:47:39.180 --> 00:47:41.914
to be ideally suited
to this approach.

00:47:41.914 --> 00:47:43.830
QUENTIN HARDY: How hard
is our 1 o'clock stop?

00:47:43.830 --> 00:47:44.880
AUDIENCE: We can go for--

00:47:44.880 --> 00:47:47.340
QUENTIN HARDY: OK, if
you can take them, great.

00:47:47.340 --> 00:47:49.980
NIALL FERGUSON: At some point,
there's an editor in London,

00:47:49.980 --> 00:47:53.250
as we speak, sending desperate
messages to me, like,

00:47:53.250 --> 00:47:54.270
are you nearly done?

00:47:54.270 --> 00:47:54.990
QUENTIN HARDY:
Where's my column?

00:47:54.990 --> 00:47:57.150
NIALL FERGUSON: This is
the day I write my column.

00:47:57.150 --> 00:48:00.510
But I'm having fun,
so let's keep going.

00:48:00.510 --> 00:48:01.620
My phone's on silent.

00:48:01.620 --> 00:48:03.310
AUDIENCE: OK, that's good.

00:48:03.310 --> 00:48:05.910
So this is maybe a bit
of a naive question,

00:48:05.910 --> 00:48:09.030
but as you were saying,
people generally

00:48:09.030 --> 00:48:11.430
tend to view the
future through the lens

00:48:11.430 --> 00:48:14.580
of their own experience
or very recent history.

00:48:14.580 --> 00:48:17.820
I mean, do you see in your
study of history, any evidence

00:48:17.820 --> 00:48:23.340
that the proclivity of humans
to learn the lessons of history

00:48:23.340 --> 00:48:25.530
has increased over
time, or are we

00:48:25.530 --> 00:48:28.920
just doomed to repeat the same
mistakes over and over again?

00:48:28.920 --> 00:48:32.070
NIALL FERGUSON: Great historians
have reflected on this problem.

00:48:32.070 --> 00:48:34.200
One of my favorite
observations was

00:48:34.200 --> 00:48:37.860
AJP Taylor's, that men
only learn from history

00:48:37.860 --> 00:48:39.600
how to make new mistakes.

00:48:39.600 --> 00:48:41.340
That kind of council
of despair was

00:48:41.340 --> 00:48:44.340
quite common amongst the
older generation of historians

00:48:44.340 --> 00:48:46.720
when I was an undergraduate.

00:48:46.720 --> 00:48:51.750
And I'm much more, I guess
I'm more of a positivist.

00:48:51.750 --> 00:48:53.700
I think it's worth a try.

00:48:53.700 --> 00:48:56.860
One thing's very
sure, very clear.

00:48:56.860 --> 00:48:58.800
People who don't know
any history at all

00:48:58.800 --> 00:49:03.600
are very likely to make
obvious avoidable mistakes.

00:49:03.600 --> 00:49:06.420
And we've run this experiment
in the US government

00:49:06.420 --> 00:49:10.050
for multiple
generations, and I think

00:49:10.050 --> 00:49:13.140
we are now in the position to
say that this hypothesis is

00:49:13.140 --> 00:49:16.020
good, and having people taking
major strategic decisions who

00:49:16.020 --> 00:49:20.317
don't know anything about
history is a terrible idea.

00:49:20.317 --> 00:49:22.650
QUENTIN HARDY: You don't favor
going with your gut, huh?

00:49:22.650 --> 00:49:24.090
NIALL FERGUSON: Well,
you know, let's just

00:49:24.090 --> 00:49:26.190
put it this way-- the
track record's terrible.

00:49:26.190 --> 00:49:31.050
And what's fascinating is that
even the recent past, the US

00:49:31.050 --> 00:49:32.970
government's bad
at learning from.

00:49:32.970 --> 00:49:36.510
So I heard a great paper
by a military historian

00:49:36.510 --> 00:49:38.220
recently on the
lessons of Vietnam.

00:49:38.220 --> 00:49:41.760
And one very good observation
he made in that paper

00:49:41.760 --> 00:49:44.880
was that even really obvious
lessons of what had gone wrong

00:49:44.880 --> 00:49:47.310
in Vietnam were not
learned, and we still

00:49:47.310 --> 00:49:50.110
rotate troops out of combat
zones after six months,

00:49:50.110 --> 00:49:54.500
and we still ensure
that no memory forms,

00:49:54.500 --> 00:49:57.990
even at the short time,
in a short time span.

00:49:57.990 --> 00:50:00.180
So I think it's clear
that not knowing history

00:50:00.180 --> 00:50:02.070
is a major handicap
for decision makers.

00:50:02.070 --> 00:50:05.930
It's also clear, though, that
if you have a theory of history

00:50:05.930 --> 00:50:10.230
that says the arc of
history bends my way,

00:50:10.230 --> 00:50:13.680
then you will do bad things
with great certainty.

00:50:13.680 --> 00:50:17.580
And I almost fear those people
more than the ignoramuses.

00:50:17.580 --> 00:50:20.460
The people who think that
history is on their side

00:50:20.460 --> 00:50:23.880
have probably done more
damage than the ignoramuses

00:50:23.880 --> 00:50:25.180
over the long run.

00:50:25.180 --> 00:50:29.010
So when anybody uses the phrase
"arc of history" in a speech,

00:50:29.010 --> 00:50:30.930
you should really
be very wary indeed.

00:50:30.930 --> 00:50:33.330
There is no arc of history.

00:50:33.330 --> 00:50:34.220
It doesn't exist.

00:50:34.220 --> 00:50:35.130
QUENTIN HARDY:
Beware any god that

00:50:35.130 --> 00:50:36.480
agrees with you all the time.

00:50:36.480 --> 00:50:38.310
NIALL FERGUSON: Right.

00:50:38.310 --> 00:50:39.990
I think a state
of uncertainty is

00:50:39.990 --> 00:50:42.180
what a good historical
scholarship gives you,

00:50:42.180 --> 00:50:45.150
a sense that there are a bunch
of options you haven't even

00:50:45.150 --> 00:50:46.880
considered.

00:50:46.880 --> 00:50:49.860
And here, I'll go back
to Taylor's observation

00:50:49.860 --> 00:50:53.340
that the study of history
is a bit like learning

00:50:53.340 --> 00:50:55.590
to appreciate music.

00:50:55.590 --> 00:51:00.080
Another way of putting it
was RG Collingwood who said,

00:51:00.080 --> 00:51:03.140
the thing about a
historian is that he's

00:51:03.140 --> 00:51:06.440
like an experienced woodsman.

00:51:06.440 --> 00:51:10.490
He'll see the tiger in the
grass where the unwary traveler

00:51:10.490 --> 00:51:11.480
won't.

00:51:11.480 --> 00:51:13.510
And I love that image
of being able to see

00:51:13.510 --> 00:51:15.260
the tiger in the grass
because you've just

00:51:15.260 --> 00:51:18.290
been wandering around the
woods most of your life.

00:51:20.850 --> 00:51:22.977
AUDIENCE: Given all that,
you're still optimistic.

00:51:25.445 --> 00:51:27.070
NIALL FERGUSON: Look,
I'm from Glasgow,

00:51:27.070 --> 00:51:29.510
where pessimism is
the default setting,

00:51:29.510 --> 00:51:31.900
and I moved to
northern California

00:51:31.900 --> 00:51:33.430
in the hope of finding a cure.

00:51:35.950 --> 00:51:38.580
QUENTIN HARDY: We'll check
back on you later on that one.

00:51:38.580 --> 00:51:39.370
AUDIENCE: Hi.

00:51:39.370 --> 00:51:44.500
Thank you very much for this
exciting electrifying talk.

00:51:44.500 --> 00:51:49.030
So I have two questions which
have been partially covered

00:51:49.030 --> 00:51:53.970
by the previous question,
but it's very interesting,

00:51:53.970 --> 00:51:55.430
I think, to discuss.

00:51:55.430 --> 00:51:59.470
So the first one is about
history and education

00:51:59.470 --> 00:52:01.360
and society.

00:52:01.360 --> 00:52:06.310
So I come from Greece, which
is a country which, in a sense,

00:52:06.310 --> 00:52:08.350
has been stuck in history.

00:52:08.350 --> 00:52:14.530
So everybody learns ancient
and medieval history very well,

00:52:14.530 --> 00:52:16.840
new history also very well.

00:52:16.840 --> 00:52:23.160
But people also have
similar short sightedness

00:52:23.160 --> 00:52:26.140
and short memory, and they
make the same mistakes

00:52:26.140 --> 00:52:28.360
that their parents did.

00:52:28.360 --> 00:52:30.460
So I think these were
covered partially

00:52:30.460 --> 00:52:34.030
by saying that it's also the
establishment that makes sure

00:52:34.030 --> 00:52:37.600
that no memory is created,
and people don't really

00:52:37.600 --> 00:52:43.000
have this extra intellect to
try to learn from history.

00:52:43.000 --> 00:52:45.040
And I would like to ask
you, as an educator,

00:52:45.040 --> 00:52:47.560
how we could fix this.

00:52:47.560 --> 00:52:49.550
So that's my first question.

00:52:49.550 --> 00:52:53.630
The second question
is about two things.

00:52:53.630 --> 00:52:56.800
One is the parallel with
the printing revolution,

00:52:56.800 --> 00:53:01.700
and the other is about optimism,
pessimism, and skepticism.

00:53:01.700 --> 00:53:04.780
So these do remind me a
lot of another book that

00:53:04.780 --> 00:53:08.650
has been recently released,
the "How to Fix the Future."

00:53:08.650 --> 00:53:11.927
I'm not sure if you have read
that one by Andrew Keene.

00:53:11.927 --> 00:53:13.010
NIALL FERGUSON: I haven't.

00:53:13.010 --> 00:53:18.920
AUDIENCE: So in the
similar concepts

00:53:18.920 --> 00:53:25.090
I discussed and how people
are on the optimism side,

00:53:25.090 --> 00:53:26.560
technology will
solve everything,

00:53:26.560 --> 00:53:27.710
we don't need to worry.

00:53:27.710 --> 00:53:33.620
On the pessimism side, it's
going to destroy everything.

00:53:33.620 --> 00:53:35.260
AI will rule us all.

00:53:35.260 --> 00:53:37.180
We'll be exterminated,
and things like that.

00:53:37.180 --> 00:53:38.930
And then the maybe
people in between

00:53:38.930 --> 00:53:41.410
will say that no,
we have history.

00:53:41.410 --> 00:53:43.000
We can study it,
and you can see how

00:53:43.000 --> 00:53:46.180
to go to a good
enough future for us,

00:53:46.180 --> 00:53:51.820
rather than hope that
things all just--

00:53:51.820 --> 00:53:54.380
let things take their own road.

00:53:54.380 --> 00:53:59.080
So my question
is, I would assume

00:53:59.080 --> 00:54:02.930
that you are more on
the maybe category,

00:54:02.930 --> 00:54:12.160
and how probably you see
networks of different actors

00:54:12.160 --> 00:54:17.410
forming and actually trying
to create the future that

00:54:17.410 --> 00:54:20.069
would be the optimal for us.

00:54:20.069 --> 00:54:22.110
NIALL FERGUSON: I'm
conscious that at some point,

00:54:22.110 --> 00:54:25.270
people have to get back to
their desks, so I'll be brief.

00:54:25.270 --> 00:54:28.740
I think, when it comes
to teaching history,

00:54:28.740 --> 00:54:33.360
there needs to be a focus
on the lessons of history.

00:54:33.360 --> 00:54:36.420
If one doesn't make that
explicit in the classroom,

00:54:36.420 --> 00:54:38.400
then I think it's
very easy for people

00:54:38.400 --> 00:54:43.720
to infer wrong assumptions
about what they're studying.

00:54:43.720 --> 00:54:45.900
And so I'm pressing
for history to be

00:54:45.900 --> 00:54:48.870
more explicit about the
implications for the present

00:54:48.870 --> 00:54:52.470
of what you just studied because
that too seldom is explicit,

00:54:52.470 --> 00:54:54.600
whether in high schools
or in universities,

00:54:54.600 --> 00:54:58.160
whether in Greece, in
Britain, or the United States.

00:54:58.160 --> 00:55:00.270
I haven't read how
to fix the future.

00:55:00.270 --> 00:55:03.810
I think the first
thing one should do

00:55:03.810 --> 00:55:07.020
is remember that there's no such
thing as the future, singular.

00:55:07.020 --> 00:55:09.400
There are multiple futures,
and both the futures

00:55:09.400 --> 00:55:12.330
that you sketch there,
the "It'll all be awesome

00:55:12.330 --> 00:55:14.250
and we'll solve all
problems" future,

00:55:14.250 --> 00:55:16.970
the kind of singularity
version, and the "we're all

00:55:16.970 --> 00:55:21.720
doomed, it's going to be like
a science fiction nightmare," I

00:55:21.720 --> 00:55:23.460
mean, both those are
plausible futures.

00:55:23.460 --> 00:55:25.043
I don't know what
probabilities you're

00:55:25.043 --> 00:55:27.300
going to attach
to those futures,

00:55:27.300 --> 00:55:29.720
but the business, it seems
to me, of applied history

00:55:29.720 --> 00:55:32.730
is to say that there
are a bunch of futures.

00:55:32.730 --> 00:55:33.610
We get to choose.

00:55:33.610 --> 00:55:35.220
We have agency.

00:55:35.220 --> 00:55:36.750
And the challenge
here is to make

00:55:36.750 --> 00:55:42.660
sure the techno optimists don't
build a future that turns out

00:55:42.660 --> 00:55:45.270
to have the unintended
consequence that the pessimists

00:55:45.270 --> 00:55:46.130
feared.

00:55:46.130 --> 00:55:49.290
That's, I think, quite plausible
because I think that resembles,

00:55:49.290 --> 00:55:51.900
closely, past episodes.

00:55:51.900 --> 00:55:54.807
You don't set out to create
weapons of mass destruction

00:55:54.807 --> 00:55:56.640
when you're doing the
Industrial Revolution.

00:55:56.640 --> 00:55:59.250
Actually, the goal is
to make cheap shirts.

00:55:59.250 --> 00:56:00.374
Let's make clothes cheap.

00:56:00.374 --> 00:56:02.040
That's really the
Industrial Revolution.

00:56:02.040 --> 00:56:05.520
But it turns out to also
make artillery vastly more

00:56:05.520 --> 00:56:06.600
destructive.

00:56:06.600 --> 00:56:08.970
And I think that's
the main lesson

00:56:08.970 --> 00:56:13.560
I would take from my 25 or
30 years of historical study.

00:56:13.560 --> 00:56:16.440
There is a powerful law of
unintended consequences ,

00:56:16.440 --> 00:56:19.590
and those people who are too
optimistic, too confident,

00:56:19.590 --> 00:56:21.429
about what it is
that they're doing,

00:56:21.429 --> 00:56:23.970
those people who really believe
the arc of history is bending

00:56:23.970 --> 00:56:26.594
their way and it will solve all
problems and everything will be

00:56:26.594 --> 00:56:30.420
awesome, those people often are
the ones who produce the most

00:56:30.420 --> 00:56:33.461
disruptive technologies
without meaning to.

00:56:33.461 --> 00:56:35.460
QUENTIN HARDY: At the
risk of skirting banality,

00:56:35.460 --> 00:56:38.700
the future is what we
collectively will do today,

00:56:38.700 --> 00:56:41.130
and likewise, what we
collectively will do today

00:56:41.130 --> 00:56:42.890
will always recast the past.

00:56:42.890 --> 00:56:47.015
There will be data, but we
will read it differently.

00:56:47.015 --> 00:56:49.010
NIALL FERGUSON:
Everybody is acting

00:56:49.010 --> 00:56:52.160
on the basis of an implicit
or explicit historical model

00:56:52.160 --> 00:56:54.110
of how the world works.

00:56:54.110 --> 00:56:56.180
There are just those people
who know that they're

00:56:56.180 --> 00:56:58.930
doing applied history,
and those who are

00:56:58.930 --> 00:57:00.290
unaware that they're doing it.

00:57:00.290 --> 00:57:03.740
But nobody doesn't
have some theory

00:57:03.740 --> 00:57:06.680
in their head of
how the world works,

00:57:06.680 --> 00:57:10.310
and how their actions are likely
to influence their futures.

00:57:10.310 --> 00:57:12.900
And that seems to me to
be part of the point here.

00:57:12.900 --> 00:57:17.120
One's trying to get people
out of bad models of thinking

00:57:17.120 --> 00:57:20.000
about the world, I mean,
the bad model that says,

00:57:20.000 --> 00:57:22.726
well, it's Allah's
will, it's God's will.

00:57:22.726 --> 00:57:24.350
There's nothing much
I can do about it.

00:57:24.350 --> 00:57:27.016
And when it all goes wrong, it's
probably the fault of the Jews.

00:57:27.016 --> 00:57:29.602
I mean, that is not a great way
of thinking about the world--

00:57:29.602 --> 00:57:31.810
QUENTIN HARDY: We've run
that experiment a few times.

00:57:31.810 --> 00:57:33.890
NIALL FERGUSON: You'd be
amazed how many people

00:57:33.890 --> 00:57:35.600
think about the world this way.

00:57:35.600 --> 00:57:38.770
One can find them online,
including on YouTube.

00:57:38.770 --> 00:57:39.941
[LAUGHTER]

00:57:39.941 --> 00:57:41.190
AUDIENCE: Thank you very much.

00:57:41.190 --> 00:57:43.250
QUENTIN HARDY: My dude.

00:57:43.250 --> 00:57:45.410
I need another hour.

00:57:45.410 --> 00:57:47.270
SPEAKER: All right,
well, thank you Quentin.

00:57:47.270 --> 00:57:48.410
Thank you, Niall.

00:57:48.410 --> 00:57:49.920
Thank you everyone for coming.

00:57:49.920 --> 00:57:51.540
Let's give them a
round of applause.

00:57:51.540 --> 00:57:56.390
[APPLAUSE]

