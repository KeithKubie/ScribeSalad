WEBVTT
Kind: captions
Language: en

00:00:01.880 --> 00:00:06.650
&gt;&gt;Male Presenter: Welcome, everyone. Welcome.
I really appreciate everybody coming out to

00:00:06.650 --> 00:00:10.140
see Daniel today. I've had the pleasure of
spending some time with him today and it's

00:00:10.140 --> 00:00:19.080
been a lot of fun. When I first read "Daemon,"
a friend of mine who recommended it and said,

00:00:19.080 --> 00:00:22.400
"This is a book for you and you have to read
this book."

00:00:22.400 --> 00:00:27.230
And I'm a voracious reader and I'm a little
picky. And when I read it, I just, I was blown

00:00:27.230 --> 00:00:34.800
away at the writing and of how this technology
can affect people's lives and change them.

00:00:34.800 --> 00:00:39.740
And with the most recent book of "Kill Decision,"
we've had the gracious opportunity for Daniel

00:00:39.740 --> 00:00:46.150
to be here today. So, with that, I present
to you Daniel Suarez and "Kill Decision."

00:00:46.150 --> 00:00:47.570
[applause]

00:00:47.570 --> 00:00:53.450
&gt;&gt;Dan: It's very nice of you. I'm happy to
see this is my second visit here and there's

00:00:53.450 --> 00:00:57.350
more people here this time. So, that means
it's getting better.

00:00:57.350 --> 00:00:58.350
[laughter]

00:00:58.350 --> 00:01:02.690
But I think a lot of people, well, some people,
who read my books think that I have a very

00:01:02.690 --> 00:01:10.359
dark vision of technology. I really don't.
I really love technology. And because I write

00:01:10.359 --> 00:01:16.909
thrillers, I have to go to the bad neighborhood
of technology to make an exciting story.

00:01:16.909 --> 00:01:19.960
I was talking about this earlier that if I
wrote a thriller that started out in a really

00:01:19.960 --> 00:01:24.759
happy place and it got happier, that would
be like the worst thriller ever. So, I'm typically

00:01:24.759 --> 00:01:30.600
taking ideas that I think are cool or that
I think is really cool, and, of course, realistic,

00:01:30.600 --> 00:01:33.189
and trying to do some devious things with
them.

00:01:33.189 --> 00:01:37.450
But I don't want people to think that that's
a reflection of how I think technology must

00:01:37.450 --> 00:01:44.090
go. As a matter of fact, I think it will be
technology that, in many ways, helps us solve

00:01:44.090 --> 00:01:49.929
the many serious problems we have. Oh, I have
a microphone now, so I can probably tone it

00:01:49.929 --> 00:01:59.100
down. But basically, I love tech. And I worked
for almost 20 years designing big data systems.

00:01:59.100 --> 00:02:03.180
And that's really where I come from in writing
my stories, is a great love for technology.

00:02:03.180 --> 00:02:07.380
That's why I take great care to try to make
it accurate. And for those who've read my

00:02:07.380 --> 00:02:10.470
stories, they know I do a lot of research
and I try to get things right, even though

00:02:10.470 --> 00:02:17.300
there might be some errata occasionally. But
from a narrative point of view, you need conflict.

00:02:17.300 --> 00:02:19.920
And that's why I introduce it.

00:02:19.920 --> 00:02:21.110
[pause]

00:02:21.110 --> 00:02:26.220
Now, with this book, "Kill Decision," what
I was interested in was the question of what's

00:02:26.220 --> 00:02:32.500
called "lethal autonomy." This is a military
term for basically algorithms making a decision

00:02:32.500 --> 00:02:38.470
about whether to kill. And again, this is
science fiction in a way, but it's very much

00:02:38.470 --> 00:02:42.800
in the discussion right now with the people
who are building and deploying these systems.

00:02:42.800 --> 00:02:47.670
I mean, we have predator drones and reaper
drones. Human beings are still making the

00:02:47.670 --> 00:02:54.020
decision there. But there is no technological
impediment to algorithms making these decisions

00:02:54.020 --> 00:02:58.480
right now. And in fact, right now in the world
there are two systems that are deployed, that

00:02:58.480 --> 00:03:00.620
are capable of making that decision.

00:03:00.620 --> 00:03:04.920
One is a sniper station in the DMZ between
North and South Korea. And another one is

00:03:04.920 --> 00:03:10.140
a system on the border of the Gaza Strip.
Now, both of these systems have that feature

00:03:10.140 --> 00:03:15.710
turned off, but they have that capability.
And that surprises some people to say, "Wow,

00:03:15.710 --> 00:03:17.880
really? That already happened? That's already
possible?"

00:03:17.880 --> 00:03:22.570
And it very much is. And that's why I thought
it was such an important thing to write about.

00:03:22.570 --> 00:03:28.240
And again, with my books, I really try to
take complex technological issues that affect

00:03:28.240 --> 00:03:33.120
people, put them in a thrilling story so that
more people can understand what the issues

00:03:33.120 --> 00:03:36.340
are 'cause they're very, very rarely black
and white.

00:03:36.340 --> 00:03:41.340
They're usually quite nuanced. Usually within
a new technology there's something that is

00:03:41.340 --> 00:03:46.260
tremendously useful and compelling. I do think
drones are that--autonomous drones. I think

00:03:46.260 --> 00:03:51.740
there's so many terrific uses for civilian
autonomous drones, whether it's search and

00:03:51.740 --> 00:03:57.900
rescue or environmental monitoring, or delivering
medical supplies into areas beset by banditry

00:03:57.900 --> 00:03:59.260
on roads, or you name it.

00:03:59.260 --> 00:04:03.010
There's a whole bunch of things. And plus,
they're fun. I really like messing around

00:04:03.010 --> 00:04:08.400
with drones myself. So, I like this technology.
And then, of course, then I go off and write

00:04:08.400 --> 00:04:13.080
a book about killer robots. So, but you have
to make it thrilling.

00:04:13.080 --> 00:04:18.630
So now, in this one, I was really concerned
with that fundamental question of whether

00:04:18.630 --> 00:04:27.040
it is not just ethically, but from a very
practical point of view, a good idea to make

00:04:27.040 --> 00:04:31.790
machines--even though we can do it--to make
machines that would kill people, even if they're

00:04:31.790 --> 00:04:36.470
enemies of ours. And in particular, and that's
why I've called the book "Kill Decision" of

00:04:36.470 --> 00:04:40.070
course, 'cause that's really the fundamental
thing we're talking about here.

00:04:40.070 --> 00:04:44.410
And what I was concerned about was the corrosive
effect that might have, as expedient as it

00:04:44.410 --> 00:04:51.310
might be, on representative government. Because
I'm concerned about how it might focus and

00:04:51.310 --> 00:04:57.390
centralize control of a very crucial thing
in very few unseen hands. Because right now,

00:04:57.390 --> 00:05:01.320
if you wanna have conflict with somebody,
have a war with somebody, you need the buy-in

00:05:01.320 --> 00:05:02.320
of other human beings.

00:05:02.320 --> 00:05:07.060
And, of course, other human beings, especially
free human beings, have opinions and they

00:05:07.060 --> 00:05:10.850
do or don't act depending on whether they
agree with you. And I don't think you have

00:05:10.850 --> 00:05:15.270
that same thing when it comes to autonomous
machines. In particular, in this story, I

00:05:15.270 --> 00:05:17.660
don't have Terminator-like creatures running
around.

00:05:17.660 --> 00:05:22.120
They're not aware of what's going on. It's
one of the reasons why I chose an insect-level

00:05:22.120 --> 00:05:26.990
intelligence. I wanted to use something that
was very technologically possible with the

00:05:26.990 --> 00:05:33.930
technology we have now. And I wanted to show
it is messy and inaccurate, but in the main,

00:05:33.930 --> 00:05:38.020
effective if you don't worry too much about
making a mess.

00:05:38.020 --> 00:05:43.560
So, again, that's a very different type of
deployment of military force than what we're

00:05:43.560 --> 00:05:48.150
facing now. And it's so imminent that I really
wanted to weave it into a story that people

00:05:48.150 --> 00:05:52.630
would read right now, before we cross that
Rubicon, basically, and make that choice.

00:05:52.630 --> 00:05:54.530
'Cause I think it's gonna be very difficult
to come back.

00:05:54.530 --> 00:05:59.770
So, again, even though I like technology very
much, there's certain aspects that I think

00:05:59.770 --> 00:06:05.000
we have to be mindful. I like to think of
it as trying to avoid ice bergs, even though

00:06:05.000 --> 00:06:08.520
we're going to be climbing this ocean. We
need to be mindful of the ice bergs. And that's

00:06:08.520 --> 00:06:14.460
really what I try to do. I try to make it
fun and interesting and exciting and all that.

00:06:14.460 --> 00:06:20.880
One thing I was thinking about, though, Asimov's
Three Laws of Robotics, I think it was 1942.

00:06:20.880 --> 00:06:24.770
Man, we threw that out fast. That was like,
we're just getting to the point when we're

00:06:24.770 --> 00:06:28.790
building robots and it wasn't like ten minutes
later, somebody said, "And let's give it a

00:06:28.790 --> 00:06:31.020
gun." It's like, and that's with 70 years
warning.

00:06:31.020 --> 00:06:35.520
So, they go, "Wow. Man, we really messed that
up." So, it's not quite out of the bag completely

00:06:35.520 --> 00:06:42.480
yet. But again, I'm just trying to bring people
into thinking about it in different ways.

00:06:42.480 --> 00:06:44.090
[pause]

00:06:44.090 --> 00:06:49.840
Now, one of the things I did in this book
was look at intelligence. Probably people

00:06:49.840 --> 00:06:55.389
in this room deal with this professionally,
question of AI. I started looking at this,

00:06:55.389 --> 00:06:58.250
again, to try to make it real in this book,
"Kill Decision."

00:06:58.250 --> 00:07:03.750
And I immediately started looking at social
insects and how they exchange information.

00:07:03.750 --> 00:07:08.560
And part of that made me realize how many
different types of intelligence there are

00:07:08.560 --> 00:07:14.410
in the world today, that human beings have
a very different type of intelligence from

00:07:14.410 --> 00:07:20.300
ants, but ants routinely solve very complex
problems, like the traveling salesman problem.

00:07:20.300 --> 00:07:25.090
And finding out how that happens, how they
used what's called "stigmergic propagation"

00:07:25.090 --> 00:07:30.380
to change their environment and basically
record onto the real world by laying down

00:07:30.380 --> 00:07:34.530
pheromones, record what an individual knows
so that the other individual agents in that

00:07:34.530 --> 00:07:40.020
system can find it and react to it, like the
neurons in the brain reacting.

00:07:40.020 --> 00:07:46.680
And it just made me more aware of how humanity
really is just part of this fabric. When I

00:07:46.680 --> 00:07:52.419
then did research on ravens, because I have
use for ravens in this story, that's another

00:07:52.419 --> 00:07:56.991
type of intelligence that is very impressive.
And again, in the case of ravens, there's

00:07:56.991 --> 00:08:02.600
a lot of evidence that ravens have been interacting
with us as an intelligent species, not just

00:08:02.600 --> 00:08:05.410
separate of us, that we're a special species
with them.

00:08:05.410 --> 00:08:10.580
And again, all of this informed what I was
writing about when it came to machines because

00:08:10.580 --> 00:08:15.520
what you realize is that intelligence, very
capable intelligence, you really don't need

00:08:15.520 --> 00:08:22.270
a general AI to accomplish that and to create
agents that go out and interact with us and

00:08:22.270 --> 00:08:32.810
make changes in the world. Now actually, I
guess I didn't prepare a very long talk.

00:08:32.810 --> 00:08:36.210
So, I was thinking we could open it up for
questions. And I know some questions have

00:08:36.210 --> 00:08:41.520
come along. I'm happy to answer questions
both about this book and previous ones for

00:08:41.520 --> 00:08:42.710
anybody who has them.

00:08:42.710 --> 00:08:43.710
[pause]

00:08:43.710 --> 00:08:48.070
&gt;&gt;Male Presenter: So, what we have, we have
the Dory page if you wanna go to go slash

00:08:48.070 --> 00:08:52.520
Daniel Suarez. We have lots of questions there.
I'm sure we're gonna have a lot of questions

00:08:52.520 --> 00:09:00.250
here. But one of the questions that I do wanna
ask is Daniel had the opportunity to demo

00:09:00.250 --> 00:09:03.180
Glass and Chauffeur today.

00:09:03.180 --> 00:09:09.380
And so, most of you have read his first book.
He predicts, basically, Glass and Chauffeur.

00:09:09.380 --> 00:09:11.220
And based on your observations--

00:09:11.220 --> 00:09:12.220
[laughter]

00:09:12.220 --> 00:09:13.220
predicts.

00:09:13.220 --> 00:09:14.440
&gt;&gt;Daniel: Yeah, I'm sure some people would
argue--.

00:09:14.440 --> 00:09:19.730
&gt;&gt;Male Presenter: I use that word, not "predicts"
because of the book, but what are your thoughts

00:09:19.730 --> 00:09:20.730
on that?

00:09:20.730 --> 00:09:26.500
&gt;&gt;Daniel: I thought they were cool as hell.
And nobody got hurt today, which was an added

00:09:26.500 --> 00:09:27.500
bonus.

00:09:27.500 --> 00:09:28.500
[laughter]

00:09:28.500 --> 00:09:32.950
For those who haven't read the books, of course
my automated vehicles harm people. And the

00:09:32.950 --> 00:09:36.960
HUD Glass is there to basically give you the
dirt on who you're looking at and what might

00:09:36.960 --> 00:09:38.320
be their weakness and so forth.

00:09:38.320 --> 00:09:42.700
And I'm sure that app is coming, but today
was very--. That's why I thought it was funny

00:09:42.700 --> 00:09:45.790
when they asked me, "Hey, what apps do you
envision?" And I started going through in

00:09:45.790 --> 00:09:51.580
my mental Rolodex, thinking, "Oh, can't do
that one. No. Not. I'm a troubled person."

00:09:51.580 --> 00:09:54.779
That's when I said, "You don't want to make
anything I'm thinking of."

00:09:54.779 --> 00:09:55.779
[laughter]

00:09:55.779 --> 00:10:00.790
But no. I thought it was great as a form factor.
What I loved most about it was how unobtrusive

00:10:00.790 --> 00:10:05.580
it was. You're just doing whatever and then
you encounter something you don't know, what

00:10:05.580 --> 00:10:09.440
I typically do is look up and go, "Hmm." And
there's the screen right there where you look

00:10:09.440 --> 00:10:10.910
up. So, I thought that was pretty cool.

00:10:10.910 --> 00:10:12.660
&gt;&gt;Male Presenter: And Chauffeur?

00:10:12.660 --> 00:10:16.980
&gt;&gt;Daniel: Chauffeur, of course, Rick and I,
we were hoping to get them to change lanes

00:10:16.980 --> 00:10:22.660
and do donuts and all that other stuff that
automated cars must do. They must. But apparently

00:10:22.660 --> 00:10:26.390
it's capable of doing those things, but they
wouldn't do it. We still enjoyed it though.

00:10:26.390 --> 00:10:28.150
It was a better driver than I am.

00:10:28.150 --> 00:10:31.480
&gt;&gt;Male Presenter: Excellent. We have a live
question.

00:10:31.480 --> 00:10:33.070
&gt;&gt;Male #1: Hi. My name is John Wiley.

00:10:33.070 --> 00:10:34.070
&gt;&gt;Daniel: Hi, John.

00:10:34.070 --> 00:10:37.450
&gt;&gt;Male #1: And I design Search. And you write
books.

00:10:37.450 --> 00:10:38.450
&gt;&gt;Daniel: I do.

00:10:38.450 --> 00:10:42.740
&gt;&gt;Male #1: And I'm wondering if you could
talk a little bit about the feedback loop

00:10:42.740 --> 00:10:48.940
here that happens because you are creating
stories about technology that are near term.

00:10:48.940 --> 00:10:49.940
&gt;&gt;Daniel: Very near.

00:10:49.940 --> 00:10:52.779
&gt;&gt;Male #1: And I'm reading your stories and
I'm trying to make some of that technology

00:10:52.779 --> 00:10:58.400
come true. Not the bad parts of it, but that's
the thing. Technology doesn't judge, right?

00:10:58.400 --> 00:11:00.110
It can be used for good and bad.

00:11:00.110 --> 00:11:01.110
&gt;&gt;Daniel: Right.

00:11:01.110 --> 00:11:06.600
&gt;&gt;Male #1: And so there's this continual back
and forth, I think, between the lots of us

00:11:06.600 --> 00:11:13.310
who read technological thrillers or science
fiction. And we set out to create the future.

00:11:13.310 --> 00:11:14.310
&gt;&gt;Daniel: Yeah.

00:11:14.310 --> 00:11:17.640
&gt;&gt;Male #1: And then that influences the stories
that y'all create 'cause it goes back and

00:11:17.640 --> 00:11:18.640
forth.

00:11:18.640 --> 00:11:19.640
&gt;&gt;Daniel: Exactly.

00:11:19.640 --> 00:11:20.640
&gt;&gt;Male #1: So, I'm wondering--.

00:11:20.640 --> 00:11:21.640
&gt;&gt;Daniel: Who pushes the frontier?

00:11:21.640 --> 00:11:23.710
&gt;&gt;Male #1: So, I'd like to hear about it from
your side of it. I'm out there trying to create

00:11:23.710 --> 00:11:28.330
some of these things and so is everyone here.
And you could tell us a little bit about your

00:11:28.330 --> 00:11:30.000
perspective from the alpha ship.

00:11:30.000 --> 00:11:34.779
&gt;&gt;Daniel: Absolutely. I would say that I have
the easier job of the two in this relationship

00:11:34.779 --> 00:11:39.230
because a lot of what I'll do, and again,
I was having this conversation earlier about

00:11:39.230 --> 00:11:43.490
how I arrived at using certain technologies
at certain parts of my stories. And generally,

00:11:43.490 --> 00:11:48.810
when I start out writing a story, I'll think
there is at its heart some technology or trend

00:11:48.810 --> 00:11:50.370
that I'm interested in.

00:11:50.370 --> 00:11:57.410
And then, I immediately create these mental
slots of must-haves to make that happen narratively,

00:11:57.410 --> 00:12:01.490
whether it's some specific technology that
can project sound into the middle of the air.

00:12:01.490 --> 00:12:06.839
And then I proceed to do this voracious search
to find what's out there. And then, I'll find

00:12:06.839 --> 00:12:11.350
something that's either close or dead on and
then I'll try to assemble existing technologies

00:12:11.350 --> 00:12:12.510
in ways and make that happen.

00:12:12.510 --> 00:12:18.030
So, that's how I use what you guys do to try
to push it just a little further. 'Cause typically,

00:12:18.030 --> 00:12:23.080
what I'm doing is taking stuff that is very
real and again, trying to combine it in new

00:12:23.080 --> 00:12:27.611
ways that maybe people hadn't thought of and
just push it back a little further. And then,

00:12:27.611 --> 00:12:31.950
of course, then you guys go and invent new
stuff hopefully, if it's compelling.

00:12:31.950 --> 00:12:36.959
And again, it's not just me. I'm just one
ant doing this and there's lots of other writers.

00:12:36.959 --> 00:12:42.810
You read it and it gives you ideas. And then
it continues that cycle. And so, it's just

00:12:42.810 --> 00:12:48.120
constantly edging further back. But I think
in many ways, we do both have the same job

00:12:48.120 --> 00:12:53.519
in that technology must tell a story to people,
to have a narrative where they can see how

00:12:53.519 --> 00:12:57.269
it relates to them and what compels them to
use it.

00:12:57.269 --> 00:13:01.050
So in that sense, I think we have a very similar
job. You just have the harder one where you

00:13:01.050 --> 00:13:06.250
actually have to do it. I think my, the hardest
part of my job is restraining myself so I

00:13:06.250 --> 00:13:12.750
just don't go too far. So mostly when I write,
the first draft will go too far and I'll always

00:13:12.750 --> 00:13:18.260
reign it back 'cause I want it to be as near
term as possible so people can relate to it.

00:13:18.260 --> 00:13:23.660
And I must admit, people like you can relate
to it because I'm a technologist and it's

00:13:23.660 --> 00:13:27.930
important to me to get stuff right. So, where
I'm exceeding the limits a bit and pushing

00:13:27.930 --> 00:13:32.240
it back, I want us to know that. I want you
to know that I know what the foundation is.

00:13:32.240 --> 00:13:35.029
I know where we are and I'm pushing it back
a little.

00:13:35.029 --> 00:13:40.280
And I've gotten some really useful feedback
from engineers and people, usually in a great

00:13:40.280 --> 00:13:45.899
way. And it helps my work a lot. That's why
I've started giving galleys early on to engineers

00:13:45.899 --> 00:13:52.930
who I know will really tell me what they think.
So helpful for me. So, I think it's definitely

00:13:52.930 --> 00:13:56.450
a positive feedback loop. So I hope that answers
your question. Good.

00:13:56.450 --> 00:14:00.290
&gt;&gt;Male Presenter: All right. So we're gonna
go through a couple Dory questions. If you

00:14:00.290 --> 00:14:03.839
do have any questions here in the building,
of course, just go up to the mic and we'll

00:14:03.839 --> 00:14:09.430
let you speak. So, the first Dory question
is, "I'd like to hear your experience about

00:14:09.430 --> 00:14:15.140
getting published, how epublishing has affected
your relationship with agents, editors and

00:14:15.140 --> 00:14:16.140
publishers."

00:14:16.140 --> 00:14:21.970
&gt;&gt;Daniel: Yeah, that's a great question. In
some ways, I'm a poster child for self-publishing

00:14:21.970 --> 00:14:26.240
because I did the thing that everybody told
me wasn't possible. And it's not because I

00:14:26.240 --> 00:14:30.160
thought, "Oh, I'm gonna do it." I just wanted
to do it. I wanted to write a book. Now, I

00:14:30.160 --> 00:14:32.110
wrote "Daemon" from 2002 to 2004.

00:14:32.110 --> 00:14:37.420
And it took a little while to get it out there
'cause I went right down Main Street. I tried

00:14:37.420 --> 00:14:42.570
to get an agent for about a year. And I read
all sorts of books on it. It's like I'd write

00:14:42.570 --> 00:14:47.279
customized career letters and try to identify
the literary agent who covers the area that

00:14:47.279 --> 00:14:51.140
you write in. I tried that for about a year
and the response that I got from a couple

00:14:51.140 --> 00:14:54.570
of agents was my book was too technical.

00:14:54.570 --> 00:14:58.459
People aren't interested that much in tech.
And I totally did not agree with that. As

00:14:58.459 --> 00:15:03.660
a matter of fact, I think technology and some
literacy with technology is a new form of

00:15:03.660 --> 00:15:08.541
literacy today. I mean, most young people,
they grok technology. They get it. They use

00:15:08.541 --> 00:15:13.010
it and I just didn't agree with that. And,
of course, publishing is hidebound industry.

00:15:13.010 --> 00:15:16.950
I'm told that all the time by people in publishing
in New York 'cause "well, we're kind of a

00:15:16.950 --> 00:15:21.690
traditional industry." And everybody knows
it. Everybody's got technology, but how they

00:15:21.690 --> 00:15:26.709
integrate it into these hundred year old systems
they have, that's the indigestion I think

00:15:26.709 --> 00:15:33.180
they're having. But then, when I went to self-publish,
I took a look at the various vanity presses

00:15:33.180 --> 00:15:37.680
'cause there was a bit of a stigma at the
time to the extent that there still is a bit.

00:15:37.680 --> 00:15:42.550
I think a lot of that's gone away. But if
you self-published, that's like printing a

00:15:42.550 --> 00:15:47.450
book. It's like you printed something. I then
started taking a look at it because I was

00:15:47.450 --> 00:15:51.360
a logistics guy, right? I designed logistics
systems and I started thinking, "Well, vanity

00:15:51.360 --> 00:15:54.860
press gotta get rid of all these middle men."
And I'm a technological guy.

00:15:54.860 --> 00:15:59.560
I'm gonna type set this book myself. I'm gonna
make sure that all the kerning is right. I

00:15:59.560 --> 00:16:05.339
mean, you know, I'm an anal retentive guy.
Design the cover in Photoshop. Found Lightning

00:16:05.339 --> 00:16:10.040
Source, which was basically the back end,
well, basically this is a company that's owned

00:16:10.040 --> 00:16:12.550
by, I'm trying to remember the name of it.

00:16:12.550 --> 00:16:17.330
But they're a distributor that all the main
publishers use. Ingram. Thank you very much.

00:16:17.330 --> 00:16:22.140
Ingram is used by all the mainstream publishers
to do their back list titles that don't sell

00:16:22.140 --> 00:16:25.741
a lot. And I thought, "Hey, I could do that."
You have to be a company to use them, but

00:16:25.741 --> 00:16:28.940
I have a company. So basically, I just made
this happen.

00:16:28.940 --> 00:16:33.100
I willed it into existence. And I got it out
there. And I got it to people like Rick and

00:16:33.100 --> 00:16:38.130
other people whose work I was interested in.
And it just took off. We started to get an

00:16:38.130 --> 00:16:42.540
audience--mostly technologists--people like
you who really help me. Thank God for that.

00:16:42.540 --> 00:16:47.660
I thank you all. But interestingly enough,
here we are a few years later.

00:16:47.660 --> 00:16:52.220
And I'm like a dinosaur now. That's like,
"Wow. You really printed on paper? What were

00:16:52.220 --> 00:16:57.170
you thinking?" And then you see it's like
60-page novellas. It's like people are churning

00:16:57.170 --> 00:17:02.529
them out. It's like it just grew like crazy.
So now, I'm like the old school. I did it

00:17:02.529 --> 00:17:06.329
the old school way. And I was thinking at
the time, when I finally--.

00:17:06.329 --> 00:17:09.549
And by the way, how I finally got an agent
was Wired Magazine printed an article about

00:17:09.549 --> 00:17:14.360
my book. That blew up and suddenly every agent
who wouldn't talk to me was calling me saying,

00:17:14.360 --> 00:17:19.370
"Oh, you're awesome. You're great." And I
finally found--. Actually, what I kept asking

00:17:19.370 --> 00:17:22.040
every agent who called me, 'cause I was making
money on every book sold.

00:17:22.040 --> 00:17:26.260
And of course we were selling it online. I
didn't have to do anything. Fulfillment was

00:17:26.260 --> 00:17:30.690
taken care of. Very scalable. And I'd say,
"Well, what can you do for me now? I don't

00:17:30.690 --> 00:17:36.419
need an agent now. I'm selling books." And
the one agent called me, who eventually became

00:17:36.419 --> 00:17:40.760
my agent at the time, Sagalyn, they said,
"Yeah, we can get you into foreign countries

00:17:40.760 --> 00:17:45.350
and we can get translations and we can get
audiobooks done and have you reach these other

00:17:45.350 --> 00:17:46.730
audiences all around the world."

00:17:46.730 --> 00:17:49.830
And I thought, "Well, that's a pretty damn
good answer." But not many people were saying

00:17:49.830 --> 00:17:55.910
that. So that's why eventually took the deal
with Dutton and Penguin. And my experience

00:17:55.910 --> 00:17:59.750
with them, as traditional as they are, is
they were terrific. They were really great

00:17:59.750 --> 00:18:01.650
to work with. They had some good suggestions.

00:18:01.650 --> 00:18:07.411
And for those who took a look at the self-published
version versus the paperback release, was

00:18:07.411 --> 00:18:12.419
only one major difference. And that was the
first chapter. And I had a different first

00:18:12.419 --> 00:18:16.980
chapter, a more technical one, in the self-published
version. [laughter] And the only suggestion

00:18:16.980 --> 00:18:20.470
they had 'cause I was like adamant, "I'm not
gonna change a damn thing."

00:18:20.470 --> 00:18:25.200
That's it. And they said, "Well, here's the
thing. If you put a different chapter in as

00:18:25.200 --> 00:18:30.120
the first one that was, consider it taking
the barbed wire fence from around your book

00:18:30.120 --> 00:18:33.991
so that people who are not technical can get
into the story. You can be as technical as

00:18:33.991 --> 00:18:36.580
you want later." I actually thought that was
a pretty good suggestion.

00:18:36.580 --> 00:18:40.520
So, that's why I took that suggestion. And
as it turns out, it worked out well. I kinda

00:18:40.520 --> 00:18:47.270
like it better now actually. But, so it wasn't
bad. It really wasn't. But again, it continues

00:18:47.270 --> 00:18:54.140
to change. So, what would I do now if I was
trying to break into publishing? I would absolutely

00:18:54.140 --> 00:18:58.700
self-publish. I would e-publish. I'd use social
media to try to build my audience from around

00:18:58.700 --> 00:19:00.140
the world, where ever they are.

00:19:00.140 --> 00:19:06.299
It's a little different since 2004. But part
of that is that now there's a lot more noise

00:19:06.299 --> 00:19:10.630
in some ways. So, when I was doing this, if
I self-published, sure there was some stigma,

00:19:10.630 --> 00:19:14.370
but if it was any good, people typically found
the time to read it. Now there's a flood of

00:19:14.370 --> 00:19:18.120
material coming out. So in many ways, it's
like all these websites coming out when the

00:19:18.120 --> 00:19:19.120
web took off.

00:19:19.120 --> 00:19:22.530
It's like you can get out there. You can get
your blog to try and get eyeballs. So, I don't

00:19:22.530 --> 00:19:27.320
know. I think it's a mix. It's just different.
I don't think it's any easier or any harder.

00:19:27.320 --> 00:19:29.600
It's just constantly changing. So, anyway.

00:19:29.600 --> 00:19:31.990
&gt;&gt;Male Presenter: Awesome. All right. Another
live question.

00:19:31.990 --> 00:19:37.110
&gt;&gt;Male #2: So, you talked a little bit about
how you try to make your novels as realistic

00:19:37.110 --> 00:19:41.160
as possible. Can you talk about like where
you do the other thing where you deliberately

00:19:41.160 --> 00:19:46.660
know that something's deliberately a technical
problem, but you decide to deliberately ignore

00:19:46.660 --> 00:19:47.790
it just to make the story better?

00:19:47.790 --> 00:19:52.280
&gt;&gt;Daniel: Yeah. I love this question actually,
'cause--. I was telling my wife one time that

00:19:52.280 --> 00:19:58.030
typically, if I wanna put a character in a
bad situation, I'll put them in an impossible

00:19:58.030 --> 00:20:02.040
situation, like something people couldn't
possible survive from. And then, I'll sit

00:20:02.040 --> 00:20:04.080
and noodle and try to think how to get them
out of it.

00:20:04.080 --> 00:20:07.750
And if it's impossible, I'll take away one
of the variables and I'll keep trying to back

00:20:07.750 --> 00:20:12.540
end into it. Sometimes, you get to a point
in the story where you do, for the sake of

00:20:12.540 --> 00:20:18.760
the story, have to make some concession. I
try to make that as rare as possible. I'm

00:20:18.760 --> 00:20:21.800
trying to think of an example where I did
that on purpose.

00:20:21.800 --> 00:20:27.510
'Cause, of course, there's fictitious elements
to--. I think the perfect example is the Razorbacks

00:20:27.510 --> 00:20:32.559
in "Daemon." They were talking about a Kawasaki
Ninja motorcycle with twin Katanas running

00:20:32.559 --> 00:20:40.270
around killing people. I had written one chapter
in the sequel and it was, took place at like

00:20:40.270 --> 00:20:44.610
two in the morning at some Missouri Texaco
station.

00:20:44.610 --> 00:20:49.480
Somebody's standing there and then these motorcycles
come in and start using credit card fobs to

00:20:49.480 --> 00:20:54.419
refuel themselves. And I thought, "That's
completely possible." But it seemed a little

00:20:54.419 --> 00:20:56.150
unlikely. So, I took it out.

00:20:56.150 --> 00:20:57.150
[laughter]

00:20:57.150 --> 00:21:02.790
And my editor thought, "Dude, come on." Plus,
it didn't really serve the story, but I thought

00:21:02.790 --> 00:21:07.610
visually it was cool. But not terribly possible.
I mean, first of all, a bunch of robots having

00:21:07.610 --> 00:21:12.070
credit cards, gas credit cards, I thought
that was funny.

00:21:12.070 --> 00:21:13.070
[laughter]

00:21:13.070 --> 00:21:16.960
It didn't really serve the story. I hope that
answered your question.

00:21:16.960 --> 00:21:23.120
&gt;&gt;Male Presenter: Roy Merritt as well during
the siege of the compound. The first book,

00:21:23.120 --> 00:21:26.850
you know? I mean, him going to room to room
to room to room.

00:21:26.850 --> 00:21:27.850
&gt;&gt;Daniel: Yep.

00:21:27.850 --> 00:21:29.530
&gt;&gt;Male Presenter: That's another example of
just--.

00:21:29.530 --> 00:21:32.809
&gt;&gt;Daniel: Well, that's a perfect example of
putting somebody in an impossible situation.

00:21:32.809 --> 00:21:33.919
&gt;&gt;Male Presenter: Yeah.

00:21:33.919 --> 00:21:38.160
&gt;&gt;Daniel: And yeah. And certain iterations,
he did not go, survive as far. That's where

00:21:38.160 --> 00:21:42.380
my gaming skills come in handy 'cause I treat
him like a gaming character. And he died many

00:21:42.380 --> 00:21:43.380
times in that hallway.

00:21:43.380 --> 00:21:44.380
[laughter]

00:21:44.380 --> 00:21:46.179
But that ain't gonna work. I had to change
it.

00:21:46.179 --> 00:21:50.960
&gt;&gt;Male Presenter: We have another Dory question.
Any news on the Daemon movie?

00:21:50.960 --> 00:21:58.960
&gt;&gt;Daniel: Ah, the Daemon movie. They've done
a number of scripts, Paramount has. I haven't

00:21:58.960 --> 00:22:04.340
seen anything recently. So, is that really
good? Is that really bad? I don't know. Hollywood's

00:22:04.340 --> 00:22:05.700
like a black box to me.

00:22:05.700 --> 00:22:12.120
And it's like I hear stuff happening. I don't
know what it is. So, but I think this is very

00:22:12.120 --> 00:22:15.620
common. I've had this conversation with other
novelists and I think there's a couple of

00:22:15.620 --> 00:22:23.400
novelists who have pull in Hollywood. JK Rowling,
Dan Brown. I think I've just done the list

00:22:23.400 --> 00:22:24.400
right there.

00:22:24.400 --> 00:22:25.400
[laughter]

00:22:25.400 --> 00:22:29.180
So, it's like--. I love it. You have meetings
with people in Hollywood. It's like, "Oh,

00:22:29.180 --> 00:22:33.950
you're really popular. Yeah, that's great.
We'll call you when we need you." You try

00:22:33.950 --> 00:22:38.480
to think, "Hey, what are you doing with the
technology?" But they're spending a lot of

00:22:38.480 --> 00:22:39.480
money on what they're doing.

00:22:39.480 --> 00:22:40.480
&gt;&gt;Male Presenter: Yeah.

00:22:40.480 --> 00:22:41.600
&gt;&gt;Daniel: Just gotta be great.

00:22:41.600 --> 00:22:45.550
&gt;&gt;Male Presenter: So, the next question is,
"You mention you're an avid gamer."

00:22:45.550 --> 00:22:46.550
&gt;&gt;Daniel: Yeah.

00:22:46.550 --> 00:22:51.500
&gt;&gt;Male Presenter: And I don't know if you
wanna keep your anonymity online of what you

00:22:51.500 --> 00:22:56.330
play or characters that you play online, but
the question did come up. "What games do you

00:22:56.330 --> 00:22:57.330
play?"

00:22:57.330 --> 00:23:03.480
&gt;&gt;Daniel: Way too much Skyrim lately. I have
an 81st level. Of course, I maxed out on that

00:23:03.480 --> 00:23:07.611
thing. But interestingly enough, that is a
game that is not a massively multi-player

00:23:07.611 --> 00:23:13.980
online game. And that's only because if I
do something like Call of Duty, some munchkin

00:23:13.980 --> 00:23:16.160
just whacks me instantly. I swear to God.

00:23:16.160 --> 00:23:21.270
I can't survive more than 20 seconds. I feel
like I'm this old guy who has old reflexes.

00:23:21.270 --> 00:23:26.630
I don't know whether they're aim bots or what,
but I, and the constant stream of abuse doesn't

00:23:26.630 --> 00:23:28.400
exactly help.

00:23:28.400 --> 00:23:29.420
[laughter]

00:23:29.420 --> 00:23:34.410
It's like I'm on the bus and I'm 12 years
old again. Yeah, you. Jesus, you know? You're

00:23:34.410 --> 00:23:41.020
killing me. Is that not enough for you? But
so, Skyrim was cool for me because of Bethesda.

00:23:41.020 --> 00:23:46.320
Here, they created this really rich world
and I just found myself wandering around occasionally

00:23:46.320 --> 00:23:49.160
and instead of killing things, I would like
look around at the view. I mean, that's a

00:23:49.160 --> 00:23:54.400
hell of a job. And it's like I almost, like,
"Oh, do I have a camera? Could I take a picture?"

00:23:54.400 --> 00:23:57.120
I mean, it's an awesome game. I really love
it.

00:23:57.120 --> 00:23:58.720
&gt;&gt;Male #3: Any MMO? [inaudible]

00:23:58.720 --> 00:24:04.170
&gt;&gt;Daniel: Oh, OK. That's good to know. That's
good to know. See, here's the thing. I never

00:24:04.170 --> 00:24:09.340
felt compelled to do that before. So that's
why I don't know that, that F12. That's good

00:24:09.340 --> 00:24:11.900
to know. Although, I'm playing it on the Xbox.

00:24:11.900 --> 00:24:14.540
&gt;&gt;Male Presenter: Is there MMOs you play?

00:24:14.540 --> 00:24:21.919
&gt;&gt;Daniel: Not lately, man. Not lately. I'm
trying to think. I've dabbled in some--[indistinct

00:24:21.919 --> 00:24:28.070
] Online, stuff like that. But part of it
is that I really wanna play a game that is

00:24:28.070 --> 00:24:33.210
not so open-ended now. And it's because I
have deadlines. And I can get really into

00:24:33.210 --> 00:24:34.210
games.

00:24:34.210 --> 00:24:35.210
&gt;&gt;Male Presenter: Yeah.

00:24:35.210 --> 00:24:39.510
&gt;&gt;Daniel: So, if I play a game that I know
is gonna be 80 hours, generally enough--.

00:24:39.510 --> 00:24:44.470
But a lot of games, I like Sandbox Games because
you can go in and out of them without feeling

00:24:44.470 --> 00:24:48.040
compelled. And, of course, there's this thing
now in Massively Multi-player games where

00:24:48.040 --> 00:24:51.000
I--just guessing--nobody get mad at me.

00:24:51.000 --> 00:24:55.650
I'll bet there are psychologists working there
thinking, "How can we get that Pavlovian reflex

00:24:55.650 --> 00:25:01.230
going where you need that sword?" And this
whole idea that you're gonna get this downloadable

00:25:01.230 --> 00:25:05.559
content, this DLC content, that you can a
blue sword for nine dollars. It's like, "Oh,

00:25:05.559 --> 00:25:07.830
my God. Really?" It's a virtual object.

00:25:07.830 --> 00:25:11.090
You're not gonna go questing before you go
buy it. That whole dynamic freaks me out.

00:25:11.090 --> 00:25:15.521
I don't think it's, I don't think it's gonna
improve story or experience. And again, you

00:25:15.521 --> 00:25:20.860
look at something like Skyrim--very compelling,
self-contained, really well envisioned. And

00:25:20.860 --> 00:25:23.560
with the Radient Quest system, there's not
one story.

00:25:23.560 --> 00:25:27.190
They went for the swarming theory of story.
So, if you're going on a quest, you don't

00:25:27.190 --> 00:25:30.980
like, just screw that. I'm gonna find one
I like and apparently they can keep generating

00:25:30.980 --> 00:25:32.960
them. I thought it was a really compelling
model.

00:25:32.960 --> 00:25:33.980
&gt;&gt;Male Presenter: Excellent.

00:25:33.980 --> 00:25:36.360
&gt;&gt;Daniel: So, that's what I do with games.
Yes. Hey.

00:25:36.360 --> 00:25:40.790
&gt;&gt;Female #1: Hey, Dan. So, have you read Neil
Stephenson's "Reamde?" And what did you think

00:25:40.790 --> 00:25:41.790
about it?

00:25:41.790 --> 00:25:46.220
&gt;&gt;Daniel: I haven't yet. I haven't. It's sitting
in my stack. I've read most of his books.

00:25:46.220 --> 00:25:47.990
The whole Baroque trilogy, "Diamond Age,"
and of course the "Cryptonomicon," "Snow Crash."

00:25:47.990 --> 00:25:53.340
&gt;&gt;Female #1: He went along with what you're
just talking about, about the [inaudible ].

00:25:53.340 --> 00:25:59.890
&gt;&gt;Daniel: Oh, really? So, he and I share the
same opinion? That's cool. No? [laughs] No,

00:25:59.890 --> 00:26:03.390
I'm looking forward to reading it. And I don't
know how he does that. He punches out like

00:26:03.390 --> 00:26:08.140
a thousand page book like every year and a
half. It's like, yeah.

00:26:08.140 --> 00:26:09.600
&gt;&gt;Male #4: Long.

00:26:09.600 --> 00:26:14.610
&gt;&gt;Daniel: That's pretty amazing. Yeah, that's
pretty amazing. But I will read it.

00:26:14.610 --> 00:26:19.309
&gt;&gt;Male Presenter: All right. So, this is a
Google Glass/Chauffeur question. You predicted,

00:26:19.309 --> 00:26:24.900
or you've talked, you had Google, or the idea
of the Glass and Chauffeur.

00:26:24.900 --> 00:26:26.490
&gt;&gt;Daniel: I had an idea.

00:26:26.490 --> 00:26:27.620
&gt;&gt;Male Presenter: Yeah.

00:26:27.620 --> 00:26:28.620
&gt;&gt;Daniel: Yeah.

00:26:28.620 --> 00:26:32.260
&gt;&gt;Male Presenter: What other futurist, technological
predictions do you think about?

00:26:32.260 --> 00:26:36.710
&gt;&gt;Daniel: Well, obviously the one that this
book is based on--

00:26:36.710 --> 00:26:37.710
&gt;&gt;Male Presenter: Sure.

00:26:37.710 --> 00:26:42.970
&gt;&gt;Daniel: concerns me a lot. Let's think.
Aside from these obvious ones that crawl around

00:26:42.970 --> 00:26:47.840
the world. No, I can't talk about that because
I'm working on that now.

00:26:47.840 --> 00:26:49.120
&gt;&gt;Male Presenter: Oh, the next book?

00:26:49.120 --> 00:26:51.140
&gt;&gt;Daniel: Yeah. I'm working on a forth book
now.

00:26:51.140 --> 00:26:52.150
&gt;&gt;Male Presenter: Is it "Daemon?"

00:26:52.150 --> 00:26:53.610
&gt;&gt;Daniel: No, no. It's not.

00:26:53.610 --> 00:26:54.820
&gt;&gt;Male Presenter: It's totally different.

00:26:54.820 --> 00:26:56.060
&gt;&gt;Daniel: It's totally different.

00:26:56.060 --> 00:26:57.060
&gt;&gt;Male Presenter: OK.

00:26:57.060 --> 00:27:01.559
&gt;&gt;Daniel: Yeah. I'm trying to think of something
that I can actually talk about without ruining

00:27:01.559 --> 00:27:04.680
the next book here. Let me, can I ponder that
one?

00:27:04.680 --> 00:27:09.539
&gt;&gt;Male Presenter: Yeah. Absolutely. We can
come back to it. That's not a problem.

00:27:09.539 --> 00:27:10.539
&gt;&gt;Daniel: All right. What's that?

00:27:10.539 --> 00:27:11.539
&gt;&gt;Female #2: [indistinct ].

00:27:11.539 --> 00:27:12.539
&gt;&gt;Daniel: Oh, oh. I'm sorry.

00:27:12.539 --> 00:27:13.539
&gt;&gt;Male Presenter: I'm sorry.

00:27:13.539 --> 00:27:14.539
&gt;&gt;Daniel: It's very interesting.

00:27:14.539 --> 00:27:15.910
&gt;&gt;Male Presenter: Go ahead. I'm sorry.

00:27:15.910 --> 00:27:21.789
&gt;&gt;Male #5: Hi. There's an organization called
Code Pink, which I think you might have heard.

00:27:21.789 --> 00:27:22.789
Code Pink.

00:27:22.789 --> 00:27:24.150
&gt;&gt;Daniel: I'm sorry.

00:27:24.150 --> 00:27:27.130
&gt;&gt;Male #5: It's an organization called Code
Pink.

00:27:27.130 --> 00:27:28.130
&gt;&gt;Daniel: Oh, Code Pink. Yes, absolutely.

00:27:28.130 --> 00:27:32.309
&gt;&gt;Male #5: So, one of the things they do is,
for those of you who don't know, is they got

00:27:32.309 --> 00:27:38.880
on and tell people how the negative impacts
of automation, like drones systems that are

00:27:38.880 --> 00:27:45.170
coming out. So, in your opinion, what do you
think that, what are they doing right and

00:27:45.170 --> 00:27:51.340
what are they doing wrong in terms of communication
of these impacts of technology? Is there any

00:27:51.340 --> 00:27:52.340
advice?

00:27:52.340 --> 00:27:54.230
&gt;&gt;Daniel: Code Pink specifically, or the people
who are building?

00:27:54.230 --> 00:27:55.490
&gt;&gt;Male #5: Similar organizations.

00:27:55.490 --> 00:28:03.779
&gt;&gt;Daniel: OK. I would say being concerned
about it, they're doing right. I'm not saying

00:28:03.779 --> 00:28:08.640
they're Luddites, but having a Luddite reaction
against this I think is really just not gonna

00:28:08.640 --> 00:28:10.510
help. Drones are gonna happen.

00:28:10.510 --> 00:28:15.159
Automation's gonna happen. There's a confluence
of things here. There's the processing power,

00:28:15.159 --> 00:28:18.850
memory, just the material. The price point
has gone down so much and given it so much

00:28:18.850 --> 00:28:24.870
capability, it will be used. It's just ingesting
that as a society and especially developing

00:28:24.870 --> 00:28:27.540
a framework of law around it what I think
we need to do.

00:28:27.540 --> 00:28:33.820
So, for instance, you could picket murder,
but murder's illegal. We already agree to

00:28:33.820 --> 00:28:39.169
that. We set up institutions to help contain
and control that. I think that's what we need

00:28:39.169 --> 00:28:46.440
when it comes to automation. We need to basically
create an extension, an appendix, of the legal

00:28:46.440 --> 00:28:49.400
system that we have for humans for automation.

00:28:49.400 --> 00:28:53.860
And that would, I think, help everyone, including
manufacturers, because if you're a manufacturer

00:28:53.860 --> 00:28:59.080
in automation, sorry some feedback. If you're
manufacturing automated systems, you're gonna

00:28:59.080 --> 00:29:03.801
want to know what the legal framework is so
that you can release your product and not

00:29:03.801 --> 00:29:05.890
have to recall it or be liable.

00:29:05.890 --> 00:29:09.510
So basically, laying out that legal framework
is, I think, the very next thing we have to

00:29:09.510 --> 00:29:14.880
do. I value the fact that they might protest
and they might care in that it increases the

00:29:14.880 --> 00:29:19.549
conversation. But I think that's what we need
to have and then compel our leaders to act

00:29:19.549 --> 00:29:21.970
about it. So, that's what I would say to that
question.

00:29:21.970 --> 00:29:24.419
&gt;&gt;Male #6: Hi, Joseph Smarr.

00:29:24.419 --> 00:29:25.890
&gt;&gt;Daniel: Hi, Joseph.

00:29:25.890 --> 00:29:30.790
&gt;&gt;Male #6: I'm sure that, besides geeks like
us, you're books have made a few lightbulbs

00:29:30.790 --> 00:29:35.010
and warning bells go off in other people's
brains. I'm just curious if you have any amusing

00:29:35.010 --> 00:29:40.400
anecdotes to share about being called up by
government or military people or companies

00:29:40.400 --> 00:29:44.309
of other sorts--just places where they've
wanted to learn more, talk to you, and any

00:29:44.309 --> 00:29:48.460
strange rabbit holes you found yourself tumbling
down as a result of being so intellectually

00:29:48.460 --> 00:29:49.460
provocative?

00:29:49.460 --> 00:29:52.909
&gt;&gt;Daniel: Yes. Actually, I have. I love this
question. The problem is trying to answer

00:29:52.909 --> 00:29:53.980
it 'cause--.

00:29:53.980 --> 00:29:54.980
[laughter]

00:29:54.980 --> 00:30:02.320
Well, no. I wouldn't have to kill you. I'm
not saying. I'm not saying. No, it's just

00:30:02.320 --> 00:30:06.550
one of these things where there was a point
in time where I was giving a speech at a certain

00:30:06.550 --> 00:30:11.670
place, thinking, "What the hell? How the hell
did I wind up here?"

00:30:11.670 --> 00:30:12.670
[laughter]

00:30:12.670 --> 00:30:16.489
I mean, seriously. It was one of those things
where if two years earlier you had said, "Guess

00:30:16.489 --> 00:30:18.320
what you're gonna be doing?" You're like--.

00:30:18.320 --> 00:30:19.320
[laughter]

00:30:19.320 --> 00:30:22.539
And the other thing I thought was, "If I'm
the expert on this, we are all screwed."

00:30:22.539 --> 00:30:23.539
[laughter]

00:30:23.539 --> 00:30:29.360
What is it really? 'Cause when people are
showing up to your talk in armored columns,

00:30:29.360 --> 00:30:33.169
it's like wow. Come on. That's just crazy.
That's nuts. But that happens 'cause they

00:30:33.169 --> 00:30:37.299
have to move around town, too, is what I found
out.

00:30:37.299 --> 00:30:42.670
So, I was heartened by the fact, 'cause I
go to DEFCON regularly, and I notice people

00:30:42.670 --> 00:30:47.200
like Jim Christy a few years back, instead
of arresting hackers constantly started thinking,

00:30:47.200 --> 00:30:51.760
"Hey, let's hire them." And what I've noticed
from the people I've talked to in the defense

00:30:51.760 --> 00:30:55.049
establishment is quite a few of them are actually
pretty cool and open-minded.

00:30:55.049 --> 00:31:02.370
And also smart. Which made me feel better.
Like, they, the automatic response is, "Let's

00:31:02.370 --> 00:31:06.211
not build something to destroy something."
They said they wanna understand and they're

00:31:06.211 --> 00:31:09.870
open-minded. And so, that much I can tell
you, that the conversations I've had with

00:31:09.870 --> 00:31:16.299
people who've approached me of that ilk have
been pretty positive by and large. So, I hope

00:31:16.299 --> 00:31:17.299
that answers your question.

00:31:17.299 --> 00:31:21.011
&gt;&gt;Male Presenter: So, I'm gonna open it up
to the VC. Is there any questions on VC right

00:31:21.011 --> 00:31:22.290
now?

00:31:22.290 --> 00:31:23.570
[pause]

00:31:23.570 --> 00:31:27.790
&gt;&gt;Daniel: Doesn't sound like it.

00:31:27.790 --> 00:31:29.890
&gt;&gt;Male Presenter: No, it sounds like not.
So, we'll go back to, we'll go back to a Dory

00:31:29.890 --> 00:31:33.549
question. And this is not, so they're not
all softball questions.

00:31:33.549 --> 00:31:34.770
&gt;&gt;Daniel: All right.

00:31:34.770 --> 00:31:38.670
&gt;&gt;Male Presenter: Some of the criticisms of
your book, that your book has received in

00:31:38.670 --> 00:31:43.279
the past and also this book, is due to this
technical parts of the book. The Washington

00:31:43.279 --> 00:31:47.950
Post recently had a review specifically calling
this out at "Kill Decision." How do you respond?

00:31:47.950 --> 00:31:51.279
&gt;&gt;Daniel: The Washington Post said what about
"Kill Decision?"

00:31:51.279 --> 00:31:55.679
&gt;&gt;Male Presenter: It was technical and how
it was a little too technical and that it

00:31:55.679 --> 00:31:59.130
would've been nice if some of the technical
explanations would've been in there.

00:31:59.130 --> 00:32:05.830
&gt;&gt;Daniel: Yeah, yeah. I know. I guess part
of it is that being a technical person, I've

00:32:05.830 --> 00:32:10.070
tried to write it at a level that I think
people, most people, can get to it. And the

00:32:10.070 --> 00:32:14.809
only thing I can say in defense of myself
in that regard is that I, very often, get

00:32:14.809 --> 00:32:20.940
email from a 50-year old housewife or a grandmother
or somebody who's reading it because they're

00:32:20.940 --> 00:32:22.971
son or grandson is reading it.

00:32:22.971 --> 00:32:25.571
And they were concerned about what they're
reading. And then they get sucked into it

00:32:25.571 --> 00:32:30.149
and they say, "I had no idea. This is really
cool. And now I understand better what my

00:32:30.149 --> 00:32:35.570
son is doing or whatever." So to the extent
that I might challenge some readers who might

00:32:35.570 --> 00:32:38.260
not know about that, I don't know. I think
that's good.

00:32:38.260 --> 00:32:43.779
And I definitely, definitely do not wanna
dumb things down for people. I make is accessible,

00:32:43.779 --> 00:32:46.711
but I just don't see the point of dumbing
it down.

00:32:46.711 --> 00:32:47.711
[applause]

00:32:47.711 --> 00:32:48.770
Just saying, "And then cool stuff happens."

00:32:48.770 --> 00:32:49.770
[laughter]

00:32:49.770 --> 00:32:50.770
It doesn't work for me.

00:32:50.770 --> 00:32:53.860
&gt;&gt;Male Presenter: I think one of the things
you've said previously is that you have to,

00:32:53.860 --> 00:32:59.440
the people are still using SQL injection,
then there's something wrong.

00:32:59.440 --> 00:33:02.409
&gt;&gt;Daniel: Yeah. Yes, exactly. You're still
susceptible to those attacks. By the way,

00:33:02.409 --> 00:33:06.140
I did have a friend tell me one time, this
is early on, he said, "You're helping the

00:33:06.140 --> 00:33:12.570
terrorists." Really? Pretty dumb terrorists.
These are pretty old attacks. And I think

00:33:12.570 --> 00:33:13.929
you have that vulnerability.

00:33:13.929 --> 00:33:19.200
&gt;&gt;Male Presenter: All right. So another Dory
question and then we'll get to a live question.

00:33:19.200 --> 00:33:21.670
Actually, let's do the live question first.

00:33:21.670 --> 00:33:23.150
&gt;&gt;Daniel: Yeah, let's do the live. He takes
precedence.

00:33:23.150 --> 00:33:26.440
&gt;&gt;Male #7: So, my question, so you spent a
lot of time writing about drones and stuff.

00:33:26.440 --> 00:33:27.440
&gt;&gt;Daniel: Yes.

00:33:27.440 --> 00:33:29.610
&gt;&gt;Male #7: Did you go out and buy your own
RC aircraft at all?

00:33:29.610 --> 00:33:34.210
&gt;&gt;Daniel: Well, I started doing that. I joined
DIY Drones and what I realized, looking at

00:33:34.210 --> 00:33:38.480
my deadlines, especially with what people
were doing, I thought, "This is like one of

00:33:38.480 --> 00:33:42.399
those things. I'm gonna spend three months
messing around and it's gonna be fun, but

00:33:42.399 --> 00:33:44.300
I'm gonna be at the entry level at that point.

00:33:44.300 --> 00:33:49.510
I'm gonna know how to program it to do way
points and all that stuff." I am now gonna

00:33:49.510 --> 00:33:53.140
get more involved in it because now I have
more time. But what I quickly started doing

00:33:53.140 --> 00:33:56.350
was reaching out to people who were doing
really, really interesting things. And you

00:33:56.350 --> 00:34:00.690
probably saw this, but there were some guys
who were at BlackHat and they all sat at DEFCON.

00:34:00.690 --> 00:34:07.940
They built this flying hacking platform that
was a GSM tower that could hijack phone calls.

00:34:07.940 --> 00:34:13.039
I'm, it was basically a gunnery drone, a marine
gunnery drone from the '70s or something.

00:34:13.039 --> 00:34:17.319
And they bought it cheap. I think they built
the whole thing for two thousand bucks. They

00:34:17.319 --> 00:34:18.349
had a 22-pound pay load.

00:34:18.349 --> 00:34:21.880
Maybe it was a 16-pound pay load. They found
the smallest computers they could. They basically

00:34:21.880 --> 00:34:28.789
put a laptop up in the air and they were sucking
up phone calls. And even if you encrypt, and

00:34:28.789 --> 00:34:33.760
this is civilian encryption, even in you have
civilian encryption on your phone, the encryption

00:34:33.760 --> 00:34:36.129
is supposedly happening at the cell tower.

00:34:36.129 --> 00:34:40.039
So, it would go to them in the clear. And
they were demonstrating all this and half

00:34:40.039 --> 00:34:45.260
the audience were Feds. [laughter] But that's
the only thing. I don't know how many of you

00:34:45.260 --> 00:34:48.809
have been to these. I love to spot the Fed
contest. That's hilarious. You get a t-shirt

00:34:48.809 --> 00:34:51.429
if you spot a Fed, it's fun.

00:34:51.429 --> 00:34:52.429
[laughter]

00:34:52.429 --> 00:34:57.910
But going to those people who have spent several
years, I found much more rewarding because

00:34:57.910 --> 00:35:03.039
I got where I needed to be much quicker. But
now I'm gonna go back and start making that

00:35:03.039 --> 00:35:07.910
journey. I won't say where I live, but where
I live it's a little problematic to have a

00:35:07.910 --> 00:35:13.029
drone and fly it around. It's one of those
things. So, I'll have to go out in the desert

00:35:13.029 --> 00:35:15.549
and mess around with it, but I will. Yeah.

00:35:15.549 --> 00:35:21.089
&gt;&gt;Male Presenter: Did you have a question?
I'm sorry. OK. So, we'll go back to the Dory

00:35:21.089 --> 00:35:29.210
question. All three of your books make, would
make amazing graphic novels. Other authors

00:35:29.210 --> 00:35:33.880
have moved into this medium, most notably
Stephen King and Dark Tower series. Any plans

00:35:33.880 --> 00:35:35.819
for this in the future?

00:35:35.819 --> 00:35:41.250
&gt;&gt;Daniel: Well, this in some ways folds back
into the question of are there any differences

00:35:41.250 --> 00:35:44.869
between self-publishing and publishing with
a major company because, of course, now that

00:35:44.869 --> 00:35:48.690
the rights are owned by major companies, I
would have to phone in those companies to

00:35:48.690 --> 00:35:51.660
see whether they're interested. So that's
the trade-off.

00:35:51.660 --> 00:35:57.039
So, I got access to markets I might not have
otherwise. Now, of course, if and when a film

00:35:57.039 --> 00:36:01.729
comes out--I'm sure that will happen--but
would I consider that for future things? I

00:36:01.729 --> 00:36:07.309
would. I would. But only I think as a companion.
I would very often like to do a novel and

00:36:07.309 --> 00:36:10.421
then have the graphic novel as a companion.

00:36:10.421 --> 00:36:14.230
A while back, I can't remember where I read
this, but I thought it was quite compelling,

00:36:14.230 --> 00:36:20.269
but the idea of reading a book. Again, I experienced
this as a child when I read "Lord of the Rings"

00:36:20.269 --> 00:36:26.849
at a pretty young age, was the idea of imagining
something and making it very personal. I think

00:36:26.849 --> 00:36:31.009
that's really cool. And again, I don't want
to denigrate graphic novels 'cause I enjoy

00:36:31.009 --> 00:36:32.240
them, too.

00:36:32.240 --> 00:36:37.559
But I wouldn't want to just do one or the
other. I wanna do both. But anyway, the idea

00:36:37.559 --> 00:36:41.450
of imagining something, I think, is kind of
cool. It makes it a very personal thing.

00:36:41.450 --> 00:36:47.700
&gt;&gt;Male Presenter: Excellent. Is Barack Obama
and George W Bush's use of drones criminal?

00:36:47.700 --> 00:36:51.359
&gt;&gt;Daniel: Wow, man. Now we're talking.

00:36:51.359 --> 00:36:52.359
[laughter]

00:36:52.359 --> 00:36:55.990
Wow. Yeah, so OK. Let's see. This is being
videotaped.

00:36:55.990 --> 00:36:56.990
[laughter]

00:36:56.990 --> 00:37:04.989
All right. I'm gonna try to say, this is why
we need a settled body of law on this topic,

00:37:04.989 --> 00:37:12.450
so that we can determine that. Because, honestly,
in talking to some very powerful people at

00:37:12.450 --> 00:37:17.279
one point, I remember thinking, "Gosh, these
guys are just really normal." And then I tried

00:37:17.279 --> 00:37:23.039
to think about what pressures people might
be under and this is how law is such an advantage

00:37:23.039 --> 00:37:27.839
because I don't think we have law designed
specifically for the use of remotely piloted

00:37:27.839 --> 00:37:29.499
weapons right now.

00:37:29.499 --> 00:37:32.779
We don't. There is an organization. I'm gonna
try to remember their name correctly. I think

00:37:32.779 --> 00:37:37.809
it's the International Committee, what is
it? Remote control. I have it. It's like the

00:37:37.809 --> 00:37:42.819
International Committee for the Control of
Robotic Warfare, or something like that. I

00:37:42.819 --> 00:37:45.049
think it's called ICRACK, whatever that stands
for.

00:37:45.049 --> 00:37:52.240
You can Google it. But, I know. It's an unfortunate
acronym. But what they're trying to do is

00:37:52.240 --> 00:37:58.319
lay down a set of principles that I think
are quite reasonable. And under that, that

00:37:58.319 --> 00:38:02.670
statement of principles, would it be criminal?
Well, the remotely piloted weapons, I don't

00:38:02.670 --> 00:38:07.729
think so. But I would encourage us as a society
to determine that.

00:38:07.729 --> 00:38:12.200
And I think it should be something that we
determine, not some lawyer in a cubicle or

00:38:12.200 --> 00:38:17.829
a hole somewhere. I think it needs to be a
public discussion because really, the implications

00:38:17.829 --> 00:38:23.859
it has to representative government are very
dire. Again, the idea of the application of

00:38:23.859 --> 00:38:29.440
lethal force, especially in a military context,
representing the nation state should be something

00:38:29.440 --> 00:38:30.509
that needs buy in.

00:38:30.509 --> 00:38:35.920
For instance, if you were to tell me that
two branches of government needed to approve,

00:38:35.920 --> 00:38:39.980
you know what I'm saying? You just need more
than one person making these decisions. And

00:38:39.980 --> 00:38:44.030
then there's the context. And there's crossing
borders. All of these are legal questions

00:38:44.030 --> 00:38:45.760
that I don't think are settled.

00:38:45.760 --> 00:38:50.369
Because they're not settled, I think it's
hard to say that it's illegal, but we damn

00:38:50.369 --> 00:38:54.349
well better find out soon and determine that.
So, that would be my answer.

00:38:54.349 --> 00:38:56.640
&gt;&gt;Male #8: So actually, I have an immediate
follow-up to that point.

00:38:56.640 --> 00:38:57.640
&gt;&gt;Daniel: Sure.

00:38:57.640 --> 00:39:02.279
&gt;&gt;Male #8: How would you contrast that to
the thrillers of the '60s and the '70s, where

00:39:02.279 --> 00:39:08.829
the President has immediate launch decision
for thermonuclear warheads and there's nobody

00:39:08.829 --> 00:39:10.279
else in the loop?

00:39:10.279 --> 00:39:11.279
&gt;&gt;Daniel: I would--.

00:39:11.279 --> 00:39:12.279
&gt;&gt;Male #8: Can you contrast that, thanks?

00:39:12.279 --> 00:39:16.950
&gt;&gt;Daniel: I would contrast it in this, first
of all, it's a miracle we're still here is

00:39:16.950 --> 00:39:21.650
all I can say. I think about it. I grew up
during the Cold War and I remember thinking,

00:39:21.650 --> 00:39:25.619
you see these films about drop and roll and
stuff like that. You just ignore it after

00:39:25.619 --> 00:39:30.729
a while, that threat. But, that said, when
it comes to one person making that decision,

00:39:30.729 --> 00:39:35.050
I think that was driven by the fact that,
what did we have? Thirty minutes notice if

00:39:35.050 --> 00:39:36.050
somebody had launched--.

00:39:36.050 --> 00:39:37.050
&gt;&gt;Male #9: [ inaudible ].

00:39:37.050 --> 00:39:41.690
&gt;&gt;Daniel: Yeah. And I think that's what was
driving it. And what were the consequences,

00:39:41.690 --> 00:39:46.759
total, complete nuclear annihilation now?
In this case, we're talking about autonomous

00:39:46.759 --> 00:39:48.990
systems that might be assassinating people.

00:39:48.990 --> 00:39:53.020
I don't think the consequences for mankind,
in general, of those things getting out of

00:39:53.020 --> 00:39:57.640
hand are anywhere near as dire, even if somebody's
trying to get at somebody for some reason

00:39:57.640 --> 00:40:03.869
as some sort of preemptive attack. I just
don't, I mean, those were very special circumstances--complete

00:40:03.869 --> 00:40:05.359
annihilation of the species.

00:40:05.359 --> 00:40:10.950
And that's not what we're facing here. So
I think this does lend itself to having a

00:40:10.950 --> 00:40:15.020
legal process by which somebody has to approve
and there has to be a written record of who

00:40:15.020 --> 00:40:18.989
authorized what. We cannot have autonomous
systems making these decisions. And of course

00:40:18.989 --> 00:40:24.380
now, just having one or two people, it can't
only be one branch of government either 'cause

00:40:24.380 --> 00:40:27.069
again, the idea of separation of powers.

00:40:27.069 --> 00:40:32.069
That is key. It's a key element. You can't
just cut that out. And who decided to cut

00:40:32.069 --> 00:40:37.410
it out? All those things. So, you create this
impression of absolute urgency. We must do

00:40:37.410 --> 00:40:39.920
it now. I'm not convinced that that's the
case here.

00:40:39.920 --> 00:40:44.219
Now, if you tell me you have a situation of
absolute urgency when it comes to the Soviets

00:40:44.219 --> 00:40:49.109
launching missiles against us, well that sounds
pretty urgent. Thank God we all survived it.

00:40:49.109 --> 00:40:53.160
But that's not the case here. I would say
this is very different, very different case.

00:40:53.160 --> 00:40:57.199
&gt;&gt;Male #10: My role at Google is that I automate
our defenses to being attacked.

00:40:57.199 --> 00:40:58.199
[laughter]

00:40:58.199 --> 00:40:59.527
&gt;&gt;Daniel: I would imagine you mean that in
a a cyber context.

00:40:59.527 --> 00:41:04.519
&gt;&gt;Male #10: We don't really have time to,
yeah. it's a related context. And we don't

00:41:04.519 --> 00:41:06.749
really want to waste the time of having a
human get involved.

00:41:06.749 --> 00:41:07.749
&gt;&gt;Daniel: Very. Yeah.

00:41:07.749 --> 00:41:11.900
&gt;&gt;Male #10: So, machines are a lot faster.
And so, you can imagine in the case of like,

00:41:11.900 --> 00:41:15.630
nuclear launch against the US, like do you
really want to wake up the President in the

00:41:15.630 --> 00:41:18.309
middle of the night and say, "Hey, you have
five minutes to decide whether to end the

00:41:18.309 --> 00:41:19.309
world?"

00:41:19.309 --> 00:41:20.309
&gt;&gt;Daniel: Yeah.

00:41:20.309 --> 00:41:23.190
&gt;&gt;Male #10: Or do you want to actually send
that decision over to a computer because maybe

00:41:23.190 --> 00:41:27.599
the computer can have the algorithm thought
out in advance of, "Is this actually a real

00:41:27.599 --> 00:41:29.269
event? What is the right thing to do?"

00:41:29.269 --> 00:41:36.170
&gt;&gt;Daniel: Have you not seen "Forbes?" The--.
You're talking about thermonuclear war, or

00:41:36.170 --> 00:41:37.509
are you talking about some other type of attack?

00:41:37.509 --> 00:41:42.609
&gt;&gt;Male #10: Well, just in general. Like, I
realize your books are about the risks of

00:41:42.609 --> 00:41:46.589
automating technology, but what do you think
about the risks of trusting humans?

00:41:46.589 --> 00:41:51.349
&gt;&gt;Daniel: I'm much more comfortable with the
idea of algorithms informing humans. 'Cause

00:41:51.349 --> 00:41:58.980
here's the thing. Automating things, again,
things change. Conditions change. And anybody

00:41:58.980 --> 00:42:03.549
who's designed systems knows that inertia
starts to gather around systems.

00:42:03.549 --> 00:42:09.940
And that portions of any system of any considerable
complexity become black boxes. And people

00:42:09.940 --> 00:42:13.609
start to trust what comes out of them. And
sometimes, those people leave and other people

00:42:13.609 --> 00:42:17.720
come in and use it in a different context.
That's where automation starts to concern

00:42:17.720 --> 00:42:23.859
me, is its ability to persist past the point
from which it was originally designed.

00:42:23.859 --> 00:42:28.270
And I would take some of the algorithms used
on Wall Street as an example there. I mean,

00:42:28.270 --> 00:42:32.910
here you've got quants who might have been
looking at a statistical model in a different

00:42:32.910 --> 00:42:37.661
context, trying to learn about risk and then
people from the sales force say, "Hey, can

00:42:37.661 --> 00:42:41.469
I borrow that to try," 'cause it boils risk
down to a number.

00:42:41.469 --> 00:42:45.089
And then it just spins out of control and
people start using it really where it should

00:42:45.089 --> 00:42:49.020
not have been used. But I don't know if that
answers your question. You want to bring it

00:42:49.020 --> 00:42:51.489
back to nuclear annihilation, what was it?

00:42:51.489 --> 00:42:57.839
&gt;&gt;Male #10: No, no. That's fine. Basically
it's similar to like, Chauffeur. Chauffeur

00:42:57.839 --> 00:43:02.309
doesn't have to be a perfect driver, but if
it's better than a human driver, that's pretty

00:43:02.309 --> 00:43:03.309
impressive.

00:43:03.309 --> 00:43:07.109
&gt;&gt;Daniel: It is. It is. You'd want a failsafe,
obviously, and you'll have it. They have that

00:43:07.109 --> 00:43:11.640
red button. And there's a driver in the seat
right now. But when it comes to cyber war

00:43:11.640 --> 00:43:16.309
and things like that, I agree 'cause all of
that's happening at a very rapid pace.

00:43:16.309 --> 00:43:20.339
But again, I would imagine as it starts to
escalate, human would be notified and they

00:43:20.339 --> 00:43:25.509
would be able to either pull the plug. So,
it's not like after the explosion goes off

00:43:25.509 --> 00:43:29.890
in the real world. That's a very different
case. You start to roll things back. So, I

00:43:29.890 --> 00:43:31.470
hope that answers your question.

00:43:31.470 --> 00:43:32.979
&gt;&gt;Male #10: Yeah, thanks.

00:43:32.979 --> 00:43:37.940
&gt;&gt;Male Presenter: All right. How much of David
Brin's "Transparent Society" inspire or inform

00:43:37.940 --> 00:43:41.949
the social structure you used by the Dark
Net, particularly in "Freedom TM?"

00:43:41.949 --> 00:43:50.680
&gt;&gt;Daniel: Yeah. Actually, I enjoyed that book
to some extent I would say. The idea of transparency,

00:43:50.680 --> 00:43:55.660
the idea that some, if someone touches my
data then I'll know it, that intrigued me

00:43:55.660 --> 00:44:00.579
that it's a fish bowl. We can see each other.
'Cause I mean, our data is consumed many times

00:44:00.579 --> 00:44:02.529
a day by various entities.

00:44:02.529 --> 00:44:08.760
Yeah, his book compelled me a bit in that
degree. The whole question of privacy and

00:44:08.760 --> 00:44:13.440
anonymity, I struggle with it sometimes, too,
because there's a part of me that thinks we

00:44:13.440 --> 00:44:18.769
need two internets. A big part of me actually
thinks we need two internets. One for anonymity

00:44:18.769 --> 00:44:21.989
and one for critical infrastructure, in which
you don't have any anonymity.

00:44:21.989 --> 00:44:27.950
And so that's the one that you run your financial
system on, that you operate your dam sluices

00:44:27.950 --> 00:44:33.209
from and your power grid. But if you want
to have free speech and play games and stuff,

00:44:33.209 --> 00:44:39.420
I think anonymity's OK. But when it comes
to transparency, I do agree with him that

00:44:39.420 --> 00:44:44.150
it needs to be a two-way street. So, quite
a bit I'd say. Quite a bit. Thank you so much

00:44:44.150 --> 00:44:45.150
for coming, guys. I really appreciate it.

00:44:45.150 --> 00:44:45.200
[applause]

