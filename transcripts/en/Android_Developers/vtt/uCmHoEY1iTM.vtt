WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.380
[MUSIC PLAYING]

00:00:02.380 --> 00:00:04.320
Let's be honest, you're
an awesome engineer

00:00:04.320 --> 00:00:07.330
with an awesome app, and you
are using threading to the max.

00:00:07.330 --> 00:00:09.584
Sadly though, managing all
those individual threads

00:00:09.584 --> 00:00:11.000
and assigning work
between them is

00:00:11.000 --> 00:00:12.670
causing you to lose your hair.

00:00:12.670 --> 00:00:14.650
My name is Colt
McAnlis, and please,

00:00:14.650 --> 00:00:16.090
don't join the bald club.

00:00:16.090 --> 00:00:17.787
Instead use the
thread pools class

00:00:17.787 --> 00:00:20.120
which is an ideal primitive
for breaking up lots of work

00:00:20.120 --> 00:00:21.840
into little buckets.

00:00:21.840 --> 00:00:23.400
See, historically,
it was commonplace

00:00:23.400 --> 00:00:26.620
that applications would use
a dedicated thread model.

00:00:26.620 --> 00:00:29.080
That is, one thread that only
deals with database rights,

00:00:29.080 --> 00:00:31.413
while a separate thread only
handles streaming of music,

00:00:31.413 --> 00:00:33.420
and a third one only
handles networking.

00:00:33.420 --> 00:00:36.390
These setups are OK because
the amount of work per thread

00:00:36.390 --> 00:00:38.410
isn't that large,
and it's OK to handle

00:00:38.410 --> 00:00:40.110
this work in sequential order.

00:00:40.110 --> 00:00:43.270
But there reaches a point where
this model starts to fall over.

00:00:43.270 --> 00:00:46.060
Say, for example, that you've
got 40 bitmaps to decode,

00:00:46.060 --> 00:00:49.270
and each decode takes like
four milliseconds or something.

00:00:49.270 --> 00:00:52.300
Putting all of this work on
a single dedicated thread

00:00:52.300 --> 00:00:55.410
is a bad idea, since it'll take
80 milliseconds total to get

00:00:55.410 --> 00:00:57.810
all that work done in
a sequential fashion.

00:00:57.810 --> 00:00:59.990
On the other hand, if
you created 10 threads

00:00:59.990 --> 00:01:01.940
and let each one
decode four bitmaps,

00:01:01.940 --> 00:01:04.455
then you'd end up only
taking 16 milliseconds total.

00:01:04.455 --> 00:01:06.330
But then, of course,
you run into the problem

00:01:06.330 --> 00:01:09.120
of how to properly pass the work
around between those threads,

00:01:09.120 --> 00:01:12.162
schedule that work, and then
managing of those threads.

00:01:12.162 --> 00:01:14.620
Before you start stressing out
about writing all that code,

00:01:14.620 --> 00:01:15.760
don't worry.

00:01:15.760 --> 00:01:19.050
This is exactly what
ThreadPoolExecuter primitive

00:01:19.050 --> 00:01:19.770
is for.

00:01:19.770 --> 00:01:21.580
Basically, this
class will just let

00:01:21.580 --> 00:01:24.390
you spin up a number of
threads and toss blocks of work

00:01:24.390 --> 00:01:25.490
to execute on it.

00:01:25.490 --> 00:01:28.010
ThreadPoolExecuter handles
all of the heavy lifting

00:01:28.010 --> 00:01:30.290
of spinning up the
threads, load balancing

00:01:30.290 --> 00:01:32.220
work across those
threads, and even killing

00:01:32.220 --> 00:01:34.740
those threads when they
have been idle for a while.

00:01:34.740 --> 00:01:36.660
Basically, it handles
all the heavy lifting

00:01:36.660 --> 00:01:38.950
of super parallel
processing on your behalf.

00:01:38.950 --> 00:01:40.680
All you have to do
is split up the work.

00:01:40.680 --> 00:01:42.810
But there's a small caveat here.

00:01:42.810 --> 00:01:45.390
How many threads should
your thread pool have?

00:01:45.390 --> 00:01:46.950
I mean, technically
speaking, you

00:01:46.950 --> 00:01:49.241
have the ability to create
as many threads as you want.

00:01:49.241 --> 00:01:50.830
But that's not ideal.

00:01:50.830 --> 00:01:53.280
See, CPUs can only
execute a certain number

00:01:53.280 --> 00:01:54.660
of threads in parallel.

00:01:54.660 --> 00:01:57.130
Once you get above that
number, then the CPU

00:01:57.130 --> 00:01:58.600
has to start deciding
which threads

00:01:58.600 --> 00:02:00.840
get the next free block
of processor time,

00:02:00.840 --> 00:02:03.190
based on how important
they are, which

00:02:03.190 --> 00:02:06.260
means that if you keep
eventually adding threads,

00:02:06.260 --> 00:02:09.090
you'll hit a break-even
point, where your computation

00:02:09.090 --> 00:02:11.300
isn't getting any faster,
even though the number

00:02:11.300 --> 00:02:14.580
of threads that you have
has increased significantly.

00:02:14.580 --> 00:02:17.240
And it's also important to
note that each of these threads

00:02:17.240 --> 00:02:18.570
aren't free.

00:02:18.570 --> 00:02:21.340
Each thread costs you about
64k of memory in minimum,

00:02:21.340 --> 00:02:22.990
and that adds up
quickly, especially

00:02:22.990 --> 00:02:24.790
in situations where
the call stacks can

00:02:24.790 --> 00:02:26.620
start growing pretty large.

00:02:26.620 --> 00:02:28.720
As such, your app needs
to find a sweet spot

00:02:28.720 --> 00:02:31.570
between the number of cores and
the point of diminishing return

00:02:31.570 --> 00:02:33.360
with the number of threads.

00:02:33.360 --> 00:02:36.060
Thankfully, once again, the
ThreadPoolExecuter class

00:02:36.060 --> 00:02:37.490
has got you covered.

00:02:37.490 --> 00:02:39.070
When creating your
thread pool, you

00:02:39.070 --> 00:02:41.270
can specify the number
of initial threads

00:02:41.270 --> 00:02:43.310
and the number of
maximum threads.

00:02:43.310 --> 00:02:45.280
As the workload in the
thread pool changes,

00:02:45.280 --> 00:02:47.900
it'll scale the number of
alive threads to match.

00:02:47.900 --> 00:02:50.610
Oh, and a quick note--
the value returned from

00:02:50.610 --> 00:02:52.920
get available processors
may not reflect

00:02:52.920 --> 00:02:54.920
the number of physical
cores in the device.

00:02:54.920 --> 00:02:57.970
See, some devices have
CPUs that will deactivate

00:02:57.970 --> 00:03:00.420
one or more cores, depending
on the system load,

00:03:00.420 --> 00:03:01.360
to save battery.

00:03:01.360 --> 00:03:04.370
So if your device has two CPUs,
but one of them is asleep,

00:03:04.370 --> 00:03:06.144
this value could return one.

00:03:06.144 --> 00:03:07.810
And, of course, thread
pools won't solve

00:03:07.810 --> 00:03:09.602
all of your threading problems.

00:03:09.602 --> 00:03:11.060
As mentioned earlier,
unless you're

00:03:11.060 --> 00:03:13.610
dealing with lots and lots
of work packets all the time,

00:03:13.610 --> 00:03:15.570
this thing's kind of overkill.

00:03:15.570 --> 00:03:18.260
It's best to use things like
HandlerThreads or AsyncTask

00:03:18.260 --> 00:03:21.050
loaders for specific
types of work blocks

00:03:21.050 --> 00:03:22.750
and only throw the
massive computing

00:03:22.750 --> 00:03:24.730
problems at the thread pool.

00:03:24.730 --> 00:03:26.780
And for you power
users out there,

00:03:26.780 --> 00:03:29.740
remember that Renderscript
might be a better alternative

00:03:29.740 --> 00:03:32.150
to large-scale parallel
work on Android devices,

00:03:32.150 --> 00:03:35.200
but that's a whole
separate set of videos

00:03:35.200 --> 00:03:36.910
that we haven't gotten into yet.

00:03:36.910 --> 00:03:40.140
And don't forget that Systrace
is an amazingly powerful tool

00:03:40.140 --> 00:03:41.690
that lets you
visualize how work is

00:03:41.690 --> 00:03:43.800
flowing through the threads
in your application.

00:03:43.800 --> 00:03:46.350
It's a great way to validate
that things are working

00:03:46.350 --> 00:03:49.830
as intended and also see all
the other crazy threads that

00:03:49.830 --> 00:03:52.471
are being worked on by
other parts of your app.

00:03:52.471 --> 00:03:54.470
And that's the trick with
performance, isn't it?

00:03:54.470 --> 00:03:56.010
I mean, you can
make assumptions.

00:03:56.010 --> 00:03:58.230
But things don't always
work the way you think,

00:03:58.230 --> 00:04:00.240
which is why you need to check
out the rest of the Android

00:04:00.240 --> 00:04:01.406
Performance Patterns videos.

00:04:01.406 --> 00:04:04.460
And don't forget to join our
Google+ community to ask a lot

00:04:04.460 --> 00:04:06.760
of hard threading
questions as well.

00:04:06.760 --> 00:04:10.220
So keep calm, profile your
code, and always remember

00:04:10.220 --> 00:04:10.770
perf matters.

00:04:10.770 --> 00:04:13.820
[MUSIC PLAYING]

