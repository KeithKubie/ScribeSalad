WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:02.090
So how do we do recognition?

00:00:02.090 --> 00:00:03.700
Well, actually it's
pretty straightforward.

00:00:03.700 --> 00:00:08.340
I have some new novel x comes in,
some new novel face image.

00:00:08.340 --> 00:00:09.230
All right?

00:00:09.230 --> 00:00:11.780
All I do is I project
it into the subspace.

00:00:11.780 --> 00:00:12.510
What does that mean?

00:00:12.510 --> 00:00:13.780
Just like before.

00:00:13.780 --> 00:00:15.540
I subtract off the means and

00:00:15.540 --> 00:00:20.250
I compute the dot product,
the coefficients W1 through Wk.

00:00:20.250 --> 00:00:24.390
By the way, I can then do something
that's optional put here.

00:00:24.390 --> 00:00:28.050
Supposed I'm not really sure that
what you gave me was a face image.

00:00:29.260 --> 00:00:35.430
Well, what I can do is, I could
reconstruct using those coefficients.

00:00:35.430 --> 00:00:37.210
And now here's the thing.

00:00:37.210 --> 00:00:41.370
If you gave me some other 10,000
dimensional vector, right?

00:00:41.370 --> 00:00:42.610
You know, three guys on a bicycle.

00:00:43.940 --> 00:00:48.250
And I try to make that image
by just summing up a hundred

00:00:48.250 --> 00:00:51.410
eigenvectors from the face space.

00:00:51.410 --> 00:00:53.320
How well do you think I can
reconstruct that image?

00:00:54.540 --> 00:00:55.860
Not so well.

00:00:55.860 --> 00:00:59.200
The only images I can
reconstruct well are faces.

00:00:59.200 --> 00:01:05.530
So I could do the reconstruction and
compare them and say, aha, bad choice.

00:01:05.530 --> 00:01:07.460
This is not a face image.

00:01:07.460 --> 00:01:09.310
It also means, by the way,
if I'm looking for

00:01:09.310 --> 00:01:12.030
faces in a picture, I might do that.

00:01:12.030 --> 00:01:13.310
In fact, in the original, Turk and

00:01:13.310 --> 00:01:15.550
Pentland, they actually
did detection that way.

00:01:15.550 --> 00:01:19.090
There are now better ways to
just detect raw faces, but

00:01:19.090 --> 00:01:24.250
the ability to reconstruct is
a way of knowing that yep,

00:01:24.250 --> 00:01:26.140
I actually have what I was looking for.

00:01:26.140 --> 00:01:28.580
I'm going to use, to see if I can
restructure, do some tracking, but

00:01:28.580 --> 00:01:30.260
hang on, that's for,
that's for the next lecture.

00:01:30.260 --> 00:01:32.340
But for the recognition part,
it's optional.

00:01:32.340 --> 00:01:34.440
Let's assume it really is a face.

00:01:34.440 --> 00:01:37.170
Well, then, all we can do is,
we can say, all right.

00:01:37.170 --> 00:01:39.180
You gave me these W's, right?

00:01:39.180 --> 00:01:40.382
1 through k.

00:01:40.382 --> 00:01:46.560
Let me find in my list, the one that's
closest in of, of those k numbers.

00:01:46.560 --> 00:01:50.540
I might use a Euclidean distance, some
other distance metric, but basically,

00:01:50.540 --> 00:01:55.270
I have a description of
a new face coming in, and

00:01:55.270 --> 00:01:59.000
I just see which of the descriptions
in my database is closest.

00:01:59.000 --> 00:02:03.882
And that's why you can think of this
somewhat as a generative model.

00:02:03.882 --> 00:02:07.310
There, there's actually more detail to
use it in a more probabilistic way.

00:02:07.310 --> 00:02:09.560
We'll actually talk a little
bit about that in the tracking.

00:02:09.560 --> 00:02:10.747
But the idea is that,

00:02:10.747 --> 00:02:14.453
each one of these descriptions
gives me a probability if you will.

00:02:14.453 --> 00:02:18.286
Or likelihood of what this
person's face might look like,

00:02:18.286 --> 00:02:22.383
because it assumes that this has
captured most of the variation, and it,

00:02:22.383 --> 00:02:24.786
the other stuff doesn't matter too much.

00:02:24.786 --> 00:02:28.790
And if I, if a new one comes in,
I can just compare them.

00:02:28.790 --> 00:02:33.340
And if I get closer, that's more likely,
and that's why it's a generative model.

