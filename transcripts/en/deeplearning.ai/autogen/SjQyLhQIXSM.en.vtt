WEBVTT
Kind: captions
Language: en

00:00:00.179 --> 00:00:02.570
 
I've noticed that almost all the really

00:00:02.570 --> 00:00:02.580
I've noticed that almost all the really
 

00:00:02.580 --> 00:00:04.849
I've noticed that almost all the really
good machine learning practitioners tend

00:00:04.849 --> 00:00:04.859
good machine learning practitioners tend
 

00:00:04.859 --> 00:00:05.749
good machine learning practitioners tend
to have a very sophisticated

00:00:05.749 --> 00:00:05.759
to have a very sophisticated
 

00:00:05.759 --> 00:00:08.540
to have a very sophisticated
understanding of buyers invariant but in

00:00:08.540 --> 00:00:08.550
understanding of buyers invariant but in
 

00:00:08.550 --> 00:00:10.280
understanding of buyers invariant but in
various one of those concepts as easy to

00:00:10.280 --> 00:00:10.290
various one of those concepts as easy to
 

00:00:10.290 --> 00:00:12.650
various one of those concepts as easy to
learn but difficult to master even if

00:00:12.650 --> 00:00:12.660
learn but difficult to master even if
 

00:00:12.660 --> 00:00:15.110
learn but difficult to master even if
you think you've seen the basic content

00:00:15.110 --> 00:00:15.120
you think you've seen the basic content
 

00:00:15.120 --> 00:00:17.359
you think you've seen the basic content
advisor variants is often more nuanced

00:00:17.359 --> 00:00:17.369
advisor variants is often more nuanced
 

00:00:17.369 --> 00:00:19.670
advisor variants is often more nuanced
to attend you'd expect in the deep

00:00:19.670 --> 00:00:19.680
to attend you'd expect in the deep
 

00:00:19.680 --> 00:00:22.010
to attend you'd expect in the deep
learning error another trend is that

00:00:22.010 --> 00:00:22.020
learning error another trend is that
 

00:00:22.020 --> 00:00:23.990
learning error another trend is that
there's an less discussion of what's

00:00:23.990 --> 00:00:24.000
there's an less discussion of what's
 

00:00:24.000 --> 00:00:26.089
there's an less discussion of what's
called the bias-variance tradeoff you

00:00:26.089 --> 00:00:26.099
called the bias-variance tradeoff you
 

00:00:26.099 --> 00:00:26.810
called the bias-variance tradeoff you
might have heard of this thing called

00:00:26.810 --> 00:00:26.820
might have heard of this thing called
 

00:00:26.820 --> 00:00:29.150
might have heard of this thing called
the bias-variance tradeoff but in a deep

00:00:29.150 --> 00:00:29.160
the bias-variance tradeoff but in a deep
 

00:00:29.160 --> 00:00:31.130
the bias-variance tradeoff but in a deep
learning arrow that less of a trade-off

00:00:31.130 --> 00:00:31.140
learning arrow that less of a trade-off
 

00:00:31.140 --> 00:00:32.749
learning arrow that less of a trade-off
so it's still tougher biases with

00:00:32.749 --> 00:00:32.759
so it's still tougher biases with
 

00:00:32.759 --> 00:00:34.790
so it's still tougher biases with
overall variance but just talk less

00:00:34.790 --> 00:00:34.800
overall variance but just talk less
 

00:00:34.800 --> 00:00:37.580
overall variance but just talk less
about the bias-variance tradeoff let's

00:00:37.580 --> 00:00:37.590
about the bias-variance tradeoff let's
 

00:00:37.590 --> 00:00:39.670
about the bias-variance tradeoff let's
see what this means

00:00:39.670 --> 00:00:39.680
see what this means
 

00:00:39.680 --> 00:00:41.750
see what this means
let's see you know data set that looks

00:00:41.750 --> 00:00:41.760
let's see you know data set that looks
 

00:00:41.760 --> 00:00:43.700
let's see you know data set that looks
like this if you fit a straight line to

00:00:43.700 --> 00:00:43.710
like this if you fit a straight line to
 

00:00:43.710 --> 00:00:47.209
like this if you fit a straight line to
the data maybe a logistic regression fit

00:00:47.209 --> 00:00:47.219
the data maybe a logistic regression fit
 

00:00:47.219 --> 00:00:49.459
the data maybe a logistic regression fit
to that this is not a very good fit to

00:00:49.459 --> 00:00:49.469
to that this is not a very good fit to
 

00:00:49.469 --> 00:00:51.380
to that this is not a very good fit to
the data and so there's a cluster of

00:00:51.380 --> 00:00:51.390
the data and so there's a cluster of
 

00:00:51.390 --> 00:00:54.439
the data and so there's a cluster of
high bias or we say that this is under

00:00:54.439 --> 00:00:54.449
high bias or we say that this is under
 

00:00:54.449 --> 00:00:57.920
high bias or we say that this is under
fitting the data on the opposite end if

00:00:57.920 --> 00:00:57.930
fitting the data on the opposite end if
 

00:00:57.930 --> 00:01:00.380
fitting the data on the opposite end if
you fit an incredibly complex classifier

00:01:00.380 --> 00:01:00.390
you fit an incredibly complex classifier
 

00:01:00.390 --> 00:01:02.869
you fit an incredibly complex classifier
and maybe a big neural network or you

00:01:02.869 --> 00:01:02.879
and maybe a big neural network or you
 

00:01:02.879 --> 00:01:05.810
and maybe a big neural network or you
network with a while the fit engineers

00:01:05.810 --> 00:01:05.820
network with a while the fit engineers
 

00:01:05.820 --> 00:01:10.399
network with a while the fit engineers
maybe you can fit the data perfectly but

00:01:10.399 --> 00:01:10.409
maybe you can fit the data perfectly but
 

00:01:10.409 --> 00:01:11.990
maybe you can fit the data perfectly but
that doesn't look like a great big key

00:01:11.990 --> 00:01:12.000
that doesn't look like a great big key
 

00:01:12.000 --> 00:01:13.429
that doesn't look like a great big key
there so there's a cost v of high

00:01:13.429 --> 00:01:13.439
there so there's a cost v of high
 

00:01:13.439 --> 00:01:16.820
there so there's a cost v of high
variance and this is on overfitting the

00:01:16.820 --> 00:01:16.830
variance and this is on overfitting the
 

00:01:16.830 --> 00:01:18.920
variance and this is on overfitting the
data and there might be some classifier

00:01:18.920 --> 00:01:18.930
data and there might be some classifier
 

00:01:18.930 --> 00:01:20.780
data and there might be some classifier
in the teen with a medium level of

00:01:20.780 --> 00:01:20.790
in the teen with a medium level of
 

00:01:20.790 --> 00:01:23.030
in the teen with a medium level of
complexity that you know maybe exceeds

00:01:23.030 --> 00:01:23.040
complexity that you know maybe exceeds
 

00:01:23.040 --> 00:01:25.609
complexity that you know maybe exceeds
the curve like that that looks like a

00:01:25.609 --> 00:01:25.619
the curve like that that looks like a
 

00:01:25.619 --> 00:01:27.289
the curve like that that looks like a
much more reasonable fit to the data and

00:01:27.289 --> 00:01:27.299
much more reasonable fit to the data and
 

00:01:27.299 --> 00:01:29.480
much more reasonable fit to the data and
so that's a call that you know just

00:01:29.480 --> 00:01:29.490
so that's a call that you know just
 

00:01:29.490 --> 00:01:31.109
so that's a call that you know just
right right somewhere in between

00:01:31.109 --> 00:01:31.119
right right somewhere in between
 

00:01:31.119 --> 00:01:34.620
right right somewhere in between
so in a 2d example like this with just

00:01:34.620 --> 00:01:34.630
so in a 2d example like this with just
 

00:01:34.630 --> 00:01:37.230
so in a 2d example like this with just
two features x1 and x2 you can plot the

00:01:37.230 --> 00:01:37.240
two features x1 and x2 you can plot the
 

00:01:37.240 --> 00:01:39.539
two features x1 and x2 you can plot the
data and visualize bias and variance in

00:01:39.539 --> 00:01:39.549
data and visualize bias and variance in
 

00:01:39.549 --> 00:01:41.969
data and visualize bias and variance in
high dimensional problems you can't plot

00:01:41.969 --> 00:01:41.979
high dimensional problems you can't plot
 

00:01:41.979 --> 00:01:43.620
high dimensional problems you can't plot
the data and visualize the decision

00:01:43.620 --> 00:01:43.630
the data and visualize the decision
 

00:01:43.630 --> 00:01:45.959
the data and visualize the decision
boundary instead there are a couple

00:01:45.959 --> 00:01:45.969
boundary instead there are a couple
 

00:01:45.969 --> 00:01:47.520
boundary instead there are a couple
different metrics that we'll look at to

00:01:47.520 --> 00:01:47.530
different metrics that we'll look at to
 

00:01:47.530 --> 00:01:49.889
different metrics that we'll look at to
try to understand bias and variance so

00:01:49.889 --> 00:01:49.899
try to understand bias and variance so
 

00:01:49.899 --> 00:01:52.260
try to understand bias and variance so
continuing our example of cat picture

00:01:52.260 --> 00:01:52.270
continuing our example of cat picture
 

00:01:52.270 --> 00:01:54.300
continuing our example of cat picture
complication where that's a positive

00:01:54.300 --> 00:01:54.310
complication where that's a positive
 

00:01:54.310 --> 00:01:56.840
complication where that's a positive
example and there's a negative example

00:01:56.840 --> 00:01:56.850
example and there's a negative example
 

00:01:56.850 --> 00:01:59.459
example and there's a negative example
the two key numbers to look at to

00:01:59.459 --> 00:01:59.469
the two key numbers to look at to
 

00:01:59.469 --> 00:02:01.649
the two key numbers to look at to
understand bias and variance will be the

00:02:01.649 --> 00:02:01.659
understand bias and variance will be the
 

00:02:01.659 --> 00:02:04.410
understand bias and variance will be the
training set error and the death set or

00:02:04.410 --> 00:02:04.420
training set error and the death set or
 

00:02:04.420 --> 00:02:07.199
training set error and the death set or
the developments etc so for the sake of

00:02:07.199 --> 00:02:07.209
the developments etc so for the sake of
 

00:02:07.209 --> 00:02:08.969
the developments etc so for the sake of
argument let's say that you're

00:02:08.969 --> 00:02:08.979
argument let's say that you're
 

00:02:08.979 --> 00:02:10.350
argument let's say that you're
recognizing cats and pictures is

00:02:10.350 --> 00:02:10.360
recognizing cats and pictures is
 

00:02:10.360 --> 00:02:12.479
recognizing cats and pictures is
something that people can do nearly

00:02:12.479 --> 00:02:12.489
something that people can do nearly
 

00:02:12.489 --> 00:02:15.059
something that people can do nearly
perfectly right and so let's say your

00:02:15.059 --> 00:02:15.069
perfectly right and so let's say your
 

00:02:15.069 --> 00:02:19.430
perfectly right and so let's say your
training set error is on one percent and

00:02:19.430 --> 00:02:19.440
training set error is on one percent and
 

00:02:19.440 --> 00:02:22.830
training set error is on one percent and
your death set error is for the sake of

00:02:22.830 --> 00:02:22.840
your death set error is for the sake of
 

00:02:22.840 --> 00:02:26.009
your death set error is for the sake of
argument let's say is 11 percent so in

00:02:26.009 --> 00:02:26.019
argument let's say is 11 percent so in
 

00:02:26.019 --> 00:02:27.960
argument let's say is 11 percent so in
this example you're doing very well on

00:02:27.960 --> 00:02:27.970
this example you're doing very well on
 

00:02:27.970 --> 00:02:30.770
this example you're doing very well on
the training set but you're doing

00:02:30.770 --> 00:02:30.780
the training set but you're doing
 

00:02:30.780 --> 00:02:33.960
the training set but you're doing
relatively poorly on the development set

00:02:33.960 --> 00:02:33.970
relatively poorly on the development set
 

00:02:33.970 --> 00:02:36.390
relatively poorly on the development set
so this looks like you might have over

00:02:36.390 --> 00:02:36.400
so this looks like you might have over
 

00:02:36.400 --> 00:02:38.849
so this looks like you might have over
fit the training set there's some how

00:02:38.849 --> 00:02:38.859
fit the training set there's some how
 

00:02:38.859 --> 00:02:40.860
fit the training set there's some how
you're not generalizing well to this

00:02:40.860 --> 00:02:40.870
you're not generalizing well to this
 

00:02:40.870 --> 00:02:42.569
you're not generalizing well to this
hold on cross validation services

00:02:42.569 --> 00:02:42.579
hold on cross validation services
 

00:02:42.579 --> 00:02:45.180
hold on cross validation services
development set and so if you have an

00:02:45.180 --> 00:02:45.190
development set and so if you have an
 

00:02:45.190 --> 00:02:48.559
development set and so if you have an
example like this we would say this has

00:02:48.559 --> 00:02:48.569
example like this we would say this has
 

00:02:48.569 --> 00:02:51.660
example like this we would say this has
high variance so by looking at the

00:02:51.660 --> 00:02:51.670
high variance so by looking at the
 

00:02:51.670 --> 00:02:53.220
high variance so by looking at the
training set error and the development

00:02:53.220 --> 00:02:53.230
training set error and the development
 

00:02:53.230 --> 00:02:55.349
training set error and the development
set error here you would be able to

00:02:55.349 --> 00:02:55.359
set error here you would be able to
 

00:02:55.359 --> 00:02:57.479
set error here you would be able to
render a diagnosis of your algorithm

00:02:57.479 --> 00:02:57.489
render a diagnosis of your algorithm
 

00:02:57.489 --> 00:03:01.289
render a diagnosis of your algorithm
having high variance now let's say that

00:03:01.289 --> 00:03:01.299
having high variance now let's say that
 

00:03:01.299 --> 00:03:03.180
having high variance now let's say that
you measure your training setting of

00:03:03.180 --> 00:03:03.190
you measure your training setting of
 

00:03:03.190 --> 00:03:05.729
you measure your training setting of
deadside error and you get a different

00:03:05.729 --> 00:03:05.739
deadside error and you get a different
 

00:03:05.739 --> 00:03:07.349
deadside error and you get a different
result let's say that your training set

00:03:07.349 --> 00:03:07.359
result let's say that your training set
 

00:03:07.359 --> 00:03:10.349
result let's say that your training set
error is 15 percent I'm writing your

00:03:10.349 --> 00:03:10.359
error is 15 percent I'm writing your
 

00:03:10.359 --> 00:03:12.839
error is 15 percent I'm writing your
training so ever the top row and your

00:03:12.839 --> 00:03:12.849
training so ever the top row and your
 

00:03:12.849 --> 00:03:16.140
training so ever the top row and your
death set error is 16 percent in this

00:03:16.140 --> 00:03:16.150
death set error is 16 percent in this
 

00:03:16.150 --> 00:03:21.180
death set error is 16 percent in this
case assuming that humans achieve you

00:03:21.180 --> 00:03:21.190
case assuming that humans achieve you
 

00:03:21.190 --> 00:03:24.059
case assuming that humans achieve you
know roughly zero percent error that

00:03:24.059 --> 00:03:24.069
know roughly zero percent error that
 

00:03:24.069 --> 00:03:25.589
know roughly zero percent error that
humans can look at these pictures and

00:03:25.589 --> 00:03:25.599
humans can look at these pictures and
 

00:03:25.599 --> 00:03:28.379
humans can look at these pictures and
just tell this cat or not then it looks

00:03:28.379 --> 00:03:28.389
just tell this cat or not then it looks
 

00:03:28.389 --> 00:03:29.849
just tell this cat or not then it looks
like the algorithm is not even doing

00:03:29.849 --> 00:03:29.859
like the algorithm is not even doing
 

00:03:29.859 --> 00:03:32.520
like the algorithm is not even doing
very well on the training set so if it's

00:03:32.520 --> 00:03:32.530
very well on the training set so if it's
 

00:03:32.530 --> 00:03:34.259
very well on the training set so if it's
not even fitting the training data as

00:03:34.259 --> 00:03:34.269
not even fitting the training data as
 

00:03:34.269 --> 00:03:37.229
not even fitting the training data as
seen by well then this is under sitting

00:03:37.229 --> 00:03:37.239
seen by well then this is under sitting
 

00:03:37.239 --> 00:03:39.449
seen by well then this is under sitting
the data and so this algorithm has high

00:03:39.449 --> 00:03:39.459
the data and so this algorithm has high
 

00:03:39.459 --> 00:03:40.750
the data and so this algorithm has high
bias

00:03:40.750 --> 00:03:40.760
bias
 

00:03:40.760 --> 00:03:43.360
bias
but in contrast is actually generalizing

00:03:43.360 --> 00:03:43.370
but in contrast is actually generalizing
 

00:03:43.370 --> 00:03:45.850
but in contrast is actually generalizing
at a reasonable level to detect entrance

00:03:45.850 --> 00:03:45.860
at a reasonable level to detect entrance
 

00:03:45.860 --> 00:03:47.530
at a reasonable level to detect entrance
performance or death sided only want to

00:03:47.530 --> 00:03:47.540
performance or death sided only want to
 

00:03:47.540 --> 00:03:48.850
performance or death sided only want to
send word since the forms in the

00:03:48.850 --> 00:03:48.860
send word since the forms in the
 

00:03:48.860 --> 00:03:51.160
send word since the forms in the
training set so dude album has a problem

00:03:51.160 --> 00:03:51.170
training set so dude album has a problem
 

00:03:51.170 --> 00:03:53.530
training set so dude album has a problem
of high bias because was not even

00:03:53.530 --> 00:03:53.540
of high bias because was not even
 

00:03:53.540 --> 00:03:54.039
of high bias because was not even
training

00:03:54.039 --> 00:03:54.049
training
 

00:03:54.049 --> 00:03:55.630
training
it's not even fitting the training set

00:03:55.630 --> 00:03:55.640
it's not even fitting the training set
 

00:03:55.640 --> 00:03:58.449
it's not even fitting the training set
well the dissimilar to the left most

00:03:58.449 --> 00:03:58.459
well the dissimilar to the left most
 

00:03:58.459 --> 00:04:01.210
well the dissimilar to the left most
plots we had on the previous line now

00:04:01.210 --> 00:04:01.220
plots we had on the previous line now
 

00:04:01.220 --> 00:04:04.119
plots we had on the previous line now
here's another example let's say that

00:04:04.119 --> 00:04:04.129
here's another example let's say that
 

00:04:04.129 --> 00:04:06.580
here's another example let's say that
you have 15 percent rating set error so

00:04:06.580 --> 00:04:06.590
you have 15 percent rating set error so
 

00:04:06.590 --> 00:04:08.710
you have 15 percent rating set error so
that's pretty high bias but when you

00:04:08.710 --> 00:04:08.720
that's pretty high bias but when you
 

00:04:08.720 --> 00:04:10.930
that's pretty high bias but when you
evaluates on a death set it does even

00:04:10.930 --> 00:04:10.940
evaluates on a death set it does even
 

00:04:10.940 --> 00:04:13.479
evaluates on a death set it does even
worse maybe it does know 30 percent in

00:04:13.479 --> 00:04:13.489
worse maybe it does know 30 percent in
 

00:04:13.489 --> 00:04:15.250
worse maybe it does know 30 percent in
this case I would diagnose this

00:04:15.250 --> 00:04:15.260
this case I would diagnose this
 

00:04:15.260 --> 00:04:18.430
this case I would diagnose this
algorithm as having high bias because

00:04:18.430 --> 00:04:18.440
algorithm as having high bias because
 

00:04:18.440 --> 00:04:19.719
algorithm as having high bias because
it's not doing that well on the training

00:04:19.719 --> 00:04:19.729
it's not doing that well on the training
 

00:04:19.729 --> 00:04:25.240
it's not doing that well on the training
set and high variance so this is you

00:04:25.240 --> 00:04:25.250
set and high variance so this is you
 

00:04:25.250 --> 00:04:27.189
set and high variance so this is you
know really the worst of both worlds oh

00:04:27.189 --> 00:04:27.199
know really the worst of both worlds oh
 

00:04:27.199 --> 00:04:30.430
know really the worst of both worlds oh
and one last example if you have you

00:04:30.430 --> 00:04:30.440
and one last example if you have you
 

00:04:30.440 --> 00:04:34.270
and one last example if you have you
know 0.5 training set error and 1% deaf

00:04:34.270 --> 00:04:34.280
know 0.5 training set error and 1% deaf
 

00:04:34.280 --> 00:04:36.490
know 0.5 training set error and 1% deaf
set error then maybe your users are

00:04:36.490 --> 00:04:36.500
set error then maybe your users are
 

00:04:36.500 --> 00:04:38.290
set error then maybe your users are
quite happy that you have a can cause

00:04:38.290 --> 00:04:38.300
quite happy that you have a can cause
 

00:04:38.300 --> 00:04:40.000
quite happy that you have a can cause
fire but only want to send ever then

00:04:40.000 --> 00:04:40.010
fire but only want to send ever then
 

00:04:40.010 --> 00:04:42.850
fire but only want to send ever then
this will have a low bias and low

00:04:42.850 --> 00:04:42.860
this will have a low bias and low
 

00:04:42.860 --> 00:04:46.690
this will have a low bias and low
variance one subtlety that I'll just

00:04:46.690 --> 00:04:46.700
variance one subtlety that I'll just
 

00:04:46.700 --> 00:04:48.279
variance one subtlety that I'll just
briefly mention that we'll leave to a

00:04:48.279 --> 00:04:48.289
briefly mention that we'll leave to a
 

00:04:48.289 --> 00:04:51.400
briefly mention that we'll leave to a
later video to discuss in detail is that

00:04:51.400 --> 00:04:51.410
later video to discuss in detail is that
 

00:04:51.410 --> 00:04:53.110
later video to discuss in detail is that
this analysis is predicated on the

00:04:53.110 --> 00:04:53.120
this analysis is predicated on the
 

00:04:53.120 --> 00:04:55.830
this analysis is predicated on the
assumption that human level performance

00:04:55.830 --> 00:04:55.840
assumption that human level performance
 

00:04:55.840 --> 00:04:59.260
assumption that human level performance
gets nearly zero percent error or more

00:04:59.260 --> 00:04:59.270
gets nearly zero percent error or more
 

00:04:59.270 --> 00:05:01.710
gets nearly zero percent error or more
generally get the optimal error

00:05:01.710 --> 00:05:01.720
generally get the optimal error
 

00:05:01.720 --> 00:05:04.540
generally get the optimal error
sometimes called Bayes error for that

00:05:04.540 --> 00:05:04.550
sometimes called Bayes error for that
 

00:05:04.550 --> 00:05:07.779
sometimes called Bayes error for that
sort of Bayesian optimal error is nearly

00:05:07.779 --> 00:05:07.789
sort of Bayesian optimal error is nearly
 

00:05:07.789 --> 00:05:11.170
sort of Bayesian optimal error is nearly
zero percent I don't want to go into

00:05:11.170 --> 00:05:11.180
zero percent I don't want to go into
 

00:05:11.180 --> 00:05:13.120
zero percent I don't want to go into
detail on this in this particular video

00:05:13.120 --> 00:05:13.130
detail on this in this particular video
 

00:05:13.130 --> 00:05:15.550
detail on this in this particular video
but it turns out that is the optimal

00:05:15.550 --> 00:05:15.560
but it turns out that is the optimal
 

00:05:15.560 --> 00:05:16.870
but it turns out that is the optimal
error or the Bayes error were much

00:05:16.870 --> 00:05:16.880
error or the Bayes error were much
 

00:05:16.880 --> 00:05:19.450
error or the Bayes error were much
higher say there were fifteen percent

00:05:19.450 --> 00:05:19.460
higher say there were fifteen percent
 

00:05:19.460 --> 00:05:22.750
higher say there were fifteen percent
then you look at this classifier fifteen

00:05:22.750 --> 00:05:22.760
then you look at this classifier fifteen
 

00:05:22.760 --> 00:05:24.490
then you look at this classifier fifteen
percent is actually perfectly reasonable

00:05:24.490 --> 00:05:24.500
percent is actually perfectly reasonable
 

00:05:24.500 --> 00:05:25.900
percent is actually perfectly reasonable
for training set and you wouldn't say

00:05:25.900 --> 00:05:25.910
for training set and you wouldn't say
 

00:05:25.910 --> 00:05:27.670
for training set and you wouldn't say
that's high bias and won't set pretty

00:05:27.670 --> 00:05:27.680
that's high bias and won't set pretty
 

00:05:27.680 --> 00:05:31.810
that's high bias and won't set pretty
low variance so the case of how to

00:05:31.810 --> 00:05:31.820
low variance so the case of how to
 

00:05:31.820 --> 00:05:34.180
low variance so the case of how to
analyze bias and variance when no

00:05:34.180 --> 00:05:34.190
analyze bias and variance when no
 

00:05:34.190 --> 00:05:36.879
analyze bias and variance when no
classifier can do very well for example

00:05:36.879 --> 00:05:36.889
classifier can do very well for example
 

00:05:36.889 --> 00:05:41.260
classifier can do very well for example
if you have really blurry images so that

00:05:41.260 --> 00:05:41.270
if you have really blurry images so that
 

00:05:41.270 --> 00:05:43.390
if you have really blurry images so that
you know even a human or just no system

00:05:43.390 --> 00:05:43.400
you know even a human or just no system
 

00:05:43.400 --> 00:05:46.930
you know even a human or just no system
could possibly do very well then maybe

00:05:46.930 --> 00:05:46.940
could possibly do very well then maybe
 

00:05:46.940 --> 00:05:49.890
could possibly do very well then maybe
Bayes error is much higher and then

00:05:49.890 --> 00:05:49.900
Bayes error is much higher and then
 

00:05:49.900 --> 00:05:51.749
Bayes error is much higher and then
details to how this analysis of change

00:05:51.749 --> 00:05:51.759
details to how this analysis of change
 

00:05:51.759 --> 00:05:54.420
details to how this analysis of change
but leaving aside this subtlety for now

00:05:54.420 --> 00:05:54.430
but leaving aside this subtlety for now
 

00:05:54.430 --> 00:05:57.570
but leaving aside this subtlety for now
the takeaway is that by looking at your

00:05:57.570 --> 00:05:57.580
the takeaway is that by looking at your
 

00:05:57.580 --> 00:06:00.570
the takeaway is that by looking at your
training set error you can get a sense

00:06:00.570 --> 00:06:00.580
training set error you can get a sense
 

00:06:00.580 --> 00:06:03.090
training set error you can get a sense
of how well you are fitting at least the

00:06:03.090 --> 00:06:03.100
of how well you are fitting at least the
 

00:06:03.100 --> 00:06:05.340
of how well you are fitting at least the
training data and so that tells you if

00:06:05.340 --> 00:06:05.350
training data and so that tells you if
 

00:06:05.350 --> 00:06:07.469
training data and so that tells you if
you have a bias problem and then looking

00:06:07.469 --> 00:06:07.479
you have a bias problem and then looking
 

00:06:07.479 --> 00:06:10.260
you have a bias problem and then looking
at how much higher your ever goes when

00:06:10.260 --> 00:06:10.270
at how much higher your ever goes when
 

00:06:10.270 --> 00:06:12.120
at how much higher your ever goes when
you go from the training set to the DEF

00:06:12.120 --> 00:06:12.130
you go from the training set to the DEF
 

00:06:12.130 --> 00:06:15.450
you go from the training set to the DEF
set that should give you a sense of how

00:06:15.450 --> 00:06:15.460
set that should give you a sense of how
 

00:06:15.460 --> 00:06:17.340
set that should give you a sense of how
bad is the variance problems are you

00:06:17.340 --> 00:06:17.350
bad is the variance problems are you
 

00:06:17.350 --> 00:06:18.840
bad is the variance problems are you
doing a good job generalizing from the

00:06:18.840 --> 00:06:18.850
doing a good job generalizing from the
 

00:06:18.850 --> 00:06:21.060
doing a good job generalizing from the
training set to the death set that gives

00:06:21.060 --> 00:06:21.070
training set to the death set that gives
 

00:06:21.070 --> 00:06:23.790
training set to the death set that gives
you a sense of your areas all this is

00:06:23.790 --> 00:06:23.800
you a sense of your areas all this is
 

00:06:23.800 --> 00:06:25.350
you a sense of your areas all this is
under the assumption that the Bayes

00:06:25.350 --> 00:06:25.360
under the assumption that the Bayes
 

00:06:25.360 --> 00:06:27.629
under the assumption that the Bayes
error is quite small and that your train

00:06:27.629 --> 00:06:27.639
error is quite small and that your train
 

00:06:27.639 --> 00:06:29.129
error is quite small and that your train
and your death sets are drawn from the

00:06:29.129 --> 00:06:29.139
and your death sets are drawn from the
 

00:06:29.139 --> 00:06:31.110
and your death sets are drawn from the
same distribution if those assumptions

00:06:31.110 --> 00:06:31.120
same distribution if those assumptions
 

00:06:31.120 --> 00:06:33.090
same distribution if those assumptions
are violated that the most sophisticated

00:06:33.090 --> 00:06:33.100
are violated that the most sophisticated
 

00:06:33.100 --> 00:06:34.770
are violated that the most sophisticated
analysis you could do which we'll talk

00:06:34.770 --> 00:06:34.780
analysis you could do which we'll talk
 

00:06:34.780 --> 00:06:37.620
analysis you could do which we'll talk
about in the later video now on the

00:06:37.620 --> 00:06:37.630
about in the later video now on the
 

00:06:37.630 --> 00:06:40.379
about in the later video now on the
previous slide you saw what high bias

00:06:40.379 --> 00:06:40.389
previous slide you saw what high bias
 

00:06:40.389 --> 00:06:42.779
previous slide you saw what high bias
high variance look like and again she

00:06:42.779 --> 00:06:42.789
high variance look like and again she
 

00:06:42.789 --> 00:06:44.339
high variance look like and again she
had a sense of what it could cost dialog

00:06:44.339 --> 00:06:44.349
had a sense of what it could cost dialog
 

00:06:44.349 --> 00:06:47.310
had a sense of what it could cost dialog
by what does high bias and high variance

00:06:47.310 --> 00:06:47.320
by what does high bias and high variance
 

00:06:47.320 --> 00:06:49.200
by what does high bias and high variance
look like it's kind of the worst of both

00:06:49.200 --> 00:06:49.210
look like it's kind of the worst of both
 

00:06:49.210 --> 00:06:52.080
look like it's kind of the worst of both
worlds so you remember we said that a

00:06:52.080 --> 00:06:52.090
worlds so you remember we said that a
 

00:06:52.090 --> 00:06:53.700
worlds so you remember we said that a
classifier like this the linear

00:06:53.700 --> 00:06:53.710
classifier like this the linear
 

00:06:53.710 --> 00:06:56.339
classifier like this the linear
classifier has high bias because under

00:06:56.339 --> 00:06:56.349
classifier has high bias because under
 

00:06:56.349 --> 00:06:59.310
classifier has high bias because under
fits the data so this would be a

00:06:59.310 --> 00:06:59.320
fits the data so this would be a
 

00:06:59.320 --> 00:07:01.560
fits the data so this would be a
qualifier that is mostly linear and

00:07:01.560 --> 00:07:01.570
qualifier that is mostly linear and
 

00:07:01.570 --> 00:07:04.290
qualifier that is mostly linear and
therefore under fit the data we're

00:07:04.290 --> 00:07:04.300
therefore under fit the data we're
 

00:07:04.300 --> 00:07:06.180
therefore under fit the data we're
drawing this in purple but if somehow

00:07:06.180 --> 00:07:06.190
drawing this in purple but if somehow
 

00:07:06.190 --> 00:07:08.870
drawing this in purple but if somehow
your classifier does some weird things

00:07:08.870 --> 00:07:08.880
your classifier does some weird things
 

00:07:08.880 --> 00:07:13.110
your classifier does some weird things
then is actually overfitting parts of

00:07:13.110 --> 00:07:13.120
then is actually overfitting parts of
 

00:07:13.120 --> 00:07:15.330
then is actually overfitting parts of
the data as well so the classifier that

00:07:15.330 --> 00:07:15.340
the data as well so the classifier that
 

00:07:15.340 --> 00:07:18.149
the data as well so the classifier that
I drew in purple has both high bias and

00:07:18.149 --> 00:07:18.159
I drew in purple has both high bias and
 

00:07:18.159 --> 00:07:20.790
I drew in purple has both high bias and
high variance where there's high bias

00:07:20.790 --> 00:07:20.800
high variance where there's high bias
 

00:07:20.800 --> 00:07:22.320
high variance where there's high bias
because by being a mostly linear

00:07:22.320 --> 00:07:22.330
because by being a mostly linear
 

00:07:22.330 --> 00:07:25.140
because by being a mostly linear
classifier is just not fitting you know

00:07:25.140 --> 00:07:25.150
classifier is just not fitting you know
 

00:07:25.150 --> 00:07:28.740
classifier is just not fitting you know
this quadratic right shade that well but

00:07:28.740 --> 00:07:28.750
this quadratic right shade that well but
 

00:07:28.750 --> 00:07:30.600
this quadratic right shade that well but
by having too much flexibility in the

00:07:30.600 --> 00:07:30.610
by having too much flexibility in the
 

00:07:30.610 --> 00:07:33.029
by having too much flexibility in the
middle it somehow gets this example in

00:07:33.029 --> 00:07:33.039
middle it somehow gets this example in
 

00:07:33.039 --> 00:07:35.790
middle it somehow gets this example in
this example over since those two

00:07:35.790 --> 00:07:35.800
this example over since those two
 

00:07:35.800 --> 00:07:37.680
this example over since those two
examples as well so this cost that kind

00:07:37.680 --> 00:07:37.690
examples as well so this cost that kind
 

00:07:37.690 --> 00:07:40.050
examples as well so this cost that kind
of has high bias because it was mostly

00:07:40.050 --> 00:07:40.060
of has high bias because it was mostly
 

00:07:40.060 --> 00:07:41.969
of has high bias because it was mostly
linear between either maybe a curve

00:07:41.969 --> 00:07:41.979
linear between either maybe a curve
 

00:07:41.979 --> 00:07:44.129
linear between either maybe a curve
function a quadratic function and it has

00:07:44.129 --> 00:07:44.139
function a quadratic function and it has
 

00:07:44.139 --> 00:07:45.870
function a quadratic function and it has
high variance because had too much

00:07:45.870 --> 00:07:45.880
high variance because had too much
 

00:07:45.880 --> 00:07:48.300
high variance because had too much
flexibility to fit here those two

00:07:48.300 --> 00:07:48.310
flexibility to fit here those two
 

00:07:48.310 --> 00:07:50.820
flexibility to fit here those two
mislabel all those alive examples in the

00:07:50.820 --> 00:07:50.830
mislabel all those alive examples in the
 

00:07:50.830 --> 00:07:52.860
mislabel all those alive examples in the
middle as well in case this seems

00:07:52.860 --> 00:07:52.870
middle as well in case this seems
 

00:07:52.870 --> 00:07:55.529
middle as well in case this seems
contrived well it is this example is a

00:07:55.529 --> 00:07:55.539
contrived well it is this example is a
 

00:07:55.539 --> 00:07:57.330
contrived well it is this example is a
little bit contrived in two dimensions

00:07:57.330 --> 00:07:57.340
little bit contrived in two dimensions
 

00:07:57.340 --> 00:07:59.730
little bit contrived in two dimensions
but we're getting high dimensional input

00:07:59.730 --> 00:07:59.740
but we're getting high dimensional input
 

00:07:59.740 --> 00:08:02.040
but we're getting high dimensional input
you actually do get things with high

00:08:02.040 --> 00:08:02.050
you actually do get things with high
 

00:08:02.050 --> 00:08:03.900
you actually do get things with high
buyers in some regions in high barians

00:08:03.900 --> 00:08:03.910
buyers in some regions in high barians
 

00:08:03.910 --> 00:08:06.029
buyers in some regions in high barians
in some regions and so it is also to get

00:08:06.029 --> 00:08:06.039
in some regions and so it is also to get
 

00:08:06.039 --> 00:08:08.370
in some regions and so it is also to get
consoles like this high dimensional

00:08:08.370 --> 00:08:08.380
consoles like this high dimensional
 

00:08:08.380 --> 00:08:10.860
consoles like this high dimensional
inputs that seem less contrived

00:08:10.860 --> 00:08:10.870
inputs that seem less contrived
 

00:08:10.870 --> 00:08:13.409
inputs that seem less contrived
so to summarize you've seen how by

00:08:13.409 --> 00:08:13.419
so to summarize you've seen how by
 

00:08:13.419 --> 00:08:15.749
so to summarize you've seen how by
looking at your algorithms ever on the

00:08:15.749 --> 00:08:15.759
looking at your algorithms ever on the
 

00:08:15.759 --> 00:08:17.879
looking at your algorithms ever on the
training set and your algorithms error

00:08:17.879 --> 00:08:17.889
training set and your algorithms error
 

00:08:17.889 --> 00:08:20.370
training set and your algorithms error
on the dev set you can try to diagnose

00:08:20.370 --> 00:08:20.380
on the dev set you can try to diagnose
 

00:08:20.380 --> 00:08:22.320
on the dev set you can try to diagnose
whether has problems high barriers or

00:08:22.320 --> 00:08:22.330
whether has problems high barriers or
 

00:08:22.330 --> 00:08:24.480
whether has problems high barriers or
high variance or maybe both or maybe

00:08:24.480 --> 00:08:24.490
high variance or maybe both or maybe
 

00:08:24.490 --> 00:08:26.730
high variance or maybe both or maybe
neither and depending on whether your

00:08:26.730 --> 00:08:26.740
neither and depending on whether your
 

00:08:26.740 --> 00:08:28.409
neither and depending on whether your
algorithm suffers from bias or variance

00:08:28.409 --> 00:08:28.419
algorithm suffers from bias or variance
 

00:08:28.419 --> 00:08:29.969
algorithm suffers from bias or variance
it turns out that they're different

00:08:29.969 --> 00:08:29.979
it turns out that they're different
 

00:08:29.979 --> 00:08:32.459
it turns out that they're different
things you could try so in the next

00:08:32.459 --> 00:08:32.469
things you could try so in the next
 

00:08:32.469 --> 00:08:34.889
things you could try so in the next
video I want to present you a what I

00:08:34.889 --> 00:08:34.899
video I want to present you a what I
 

00:08:34.899 --> 00:08:36.870
video I want to present you a what I
call a basic recipe for machine learning

00:08:36.870 --> 00:08:36.880
call a basic recipe for machine learning
 

00:08:36.880 --> 00:08:39.420
call a basic recipe for machine learning
that lets you most automatically try to

00:08:39.420 --> 00:08:39.430
that lets you most automatically try to
 

00:08:39.430 --> 00:08:41.430
that lets you most automatically try to
improve your algorithm depending on

00:08:41.430 --> 00:08:41.440
improve your algorithm depending on
 

00:08:41.440 --> 00:08:43.529
improve your algorithm depending on
whether as high buyers or hide there's

00:08:43.529 --> 00:08:43.539
whether as high buyers or hide there's
 

00:08:43.539 --> 00:08:47.850
whether as high buyers or hide there's
issues so let's go on to the next video

