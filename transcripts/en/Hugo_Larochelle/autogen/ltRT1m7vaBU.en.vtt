WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.149
 
in this video we'll mention an

00:00:02.149 --> 00:00:02.159
in this video we'll mention an
 

00:00:02.159 --> 00:00:03.830
in this video we'll mention an
alternative to maximum likelihood

00:00:03.830 --> 00:00:03.840
alternative to maximum likelihood
 

00:00:03.840 --> 00:00:05.900
alternative to maximum likelihood
training of conditional random fields

00:00:05.900 --> 00:00:05.910
training of conditional random fields
 

00:00:05.910 --> 00:00:10.580
training of conditional random fields
known as sort of likelihood so we've

00:00:10.580 --> 00:00:10.590
known as sort of likelihood so we've
 

00:00:10.590 --> 00:00:13.339
known as sort of likelihood so we've
seen in the previous video that we could

00:00:13.339 --> 00:00:13.349
seen in the previous video that we could
 

00:00:13.349 --> 00:00:17.210
seen in the previous video that we could
get an expression for the negative log

00:00:17.210 --> 00:00:17.220
get an expression for the negative log
 

00:00:17.220 --> 00:00:20.599
get an expression for the negative log
likelihood gradients with respect to the

00:00:20.599 --> 00:00:20.609
likelihood gradients with respect to the
 

00:00:20.609 --> 00:00:23.269
likelihood gradients with respect to the
parameters which allows us to then you

00:00:23.269 --> 00:00:23.279
parameters which allows us to then you
 

00:00:23.279 --> 00:00:25.370
parameters which allows us to then you
know get away an expression to compute

00:00:25.370 --> 00:00:25.380
know get away an expression to compute
 

00:00:25.380 --> 00:00:27.439
know get away an expression to compute
for performing gradient descent and

00:00:27.439 --> 00:00:27.449
for performing gradient descent and
 

00:00:27.449 --> 00:00:29.210
for performing gradient descent and
perform minimize the negative log

00:00:29.210 --> 00:00:29.220
perform minimize the negative log
 

00:00:29.220 --> 00:00:30.980
perform minimize the negative log
likelihood so perform maximum likelihood

00:00:30.980 --> 00:00:30.990
likelihood so perform maximum likelihood
 

00:00:30.990 --> 00:00:32.900
likelihood so perform maximum likelihood
training of our conditional random field

00:00:32.900 --> 00:00:32.910
training of our conditional random field
 

00:00:32.910 --> 00:00:35.209
training of our conditional random field
however it did involve an expectation

00:00:35.209 --> 00:00:35.219
however it did involve an expectation
 

00:00:35.219 --> 00:00:41.000
however it did involve an expectation
over the label or the target vector Y

00:00:41.000 --> 00:00:41.010
over the label or the target vector Y
 

00:00:41.010 --> 00:00:44.209
over the label or the target vector Y
and while it might only involve a few

00:00:44.209 --> 00:00:44.219
and while it might only involve a few
 

00:00:44.219 --> 00:00:46.340
and while it might only involve a few
variables it still requires performing

00:00:46.340 --> 00:00:46.350
variables it still requires performing
 

00:00:46.350 --> 00:00:48.020
variables it still requires performing
an inference of what the marginal

00:00:48.020 --> 00:00:48.030
an inference of what the marginal
 

00:00:48.030 --> 00:00:50.900
an inference of what the marginal
distribution over the subset of labels

00:00:50.900 --> 00:00:50.910
distribution over the subset of labels
 

00:00:50.910 --> 00:00:53.930
distribution over the subset of labels
that are involved in the gradient might

00:00:53.930 --> 00:00:53.940
that are involved in the gradient might
 

00:00:53.940 --> 00:00:55.939
that are involved in the gradient might
be so we have to perform that inference

00:00:55.939 --> 00:00:55.949
be so we have to perform that inference
 

00:00:55.949 --> 00:01:01.180
be so we have to perform that inference
and unless we have a graph which is

00:01:01.180 --> 00:01:01.190
and unless we have a graph which is
 

00:01:01.190 --> 00:01:05.600
and unless we have a graph which is
linear chain or a tree this this

00:01:05.600 --> 00:01:05.610
linear chain or a tree this this
 

00:01:05.610 --> 00:01:09.560
linear chain or a tree this this
approximate inference so estimating this

00:01:09.560 --> 00:01:09.570
approximate inference so estimating this
 

00:01:09.570 --> 00:01:12.370
approximate inference so estimating this
marginal Diskin ditional distribution

00:01:12.370 --> 00:01:12.380
marginal Diskin ditional distribution
 

00:01:12.380 --> 00:01:14.600
marginal Diskin ditional distribution
it's just an approximation it might

00:01:14.600 --> 00:01:14.610
it's just an approximation it might
 

00:01:14.610 --> 00:01:17.120
it's just an approximation it might
actually be very bad in practice so some

00:01:17.120 --> 00:01:17.130
actually be very bad in practice so some
 

00:01:17.130 --> 00:01:19.670
actually be very bad in practice so some
people have explored instead an

00:01:19.670 --> 00:01:19.680
people have explored instead an
 

00:01:19.680 --> 00:01:21.789
people have explored instead an
alternative which is to just do without

00:01:21.789 --> 00:01:21.799
alternative which is to just do without
 

00:01:21.799 --> 00:01:23.600
alternative which is to just do without
maximum likelihood training and just

00:01:23.600 --> 00:01:23.610
maximum likelihood training and just
 

00:01:23.610 --> 00:01:25.940
maximum likelihood training and just
change the last function to be used for

00:01:25.940 --> 00:01:25.950
change the last function to be used for
 

00:01:25.950 --> 00:01:29.230
change the last function to be used for
training the conditional random field I

00:01:29.230 --> 00:01:29.240
training the conditional random field I
 

00:01:29.240 --> 00:01:31.550
training the conditional random field I
just want to mention one such approach

00:01:31.550 --> 00:01:31.560
just want to mention one such approach
 

00:01:31.560 --> 00:01:35.090
just want to mention one such approach
which is known as pseudo likelihood so

00:01:35.090 --> 00:01:35.100
which is known as pseudo likelihood so
 

00:01:35.100 --> 00:01:38.060
which is known as pseudo likelihood so
the idea is that instead of trying to

00:01:38.060 --> 00:01:38.070
the idea is that instead of trying to
 

00:01:38.070 --> 00:01:40.429
the idea is that instead of trying to
maximize the probability of the whole Y

00:01:40.429 --> 00:01:40.439
maximize the probability of the whole Y
 

00:01:40.439 --> 00:01:43.870
maximize the probability of the whole Y
vector given the input we might want to

00:01:43.870 --> 00:01:43.880
vector given the input we might want to
 

00:01:43.880 --> 00:01:48.020
vector given the input we might want to
maximize instead each of the conditional

00:01:48.020 --> 00:01:48.030
maximize instead each of the conditional
 

00:01:48.030 --> 00:01:52.069
maximize instead each of the conditional
of each YK given everything else so all

00:01:52.069 --> 00:01:52.079
of each YK given everything else so all
 

00:01:52.079 --> 00:01:54.289
of each YK given everything else so all
otherwise and the input so one

00:01:54.289 --> 00:01:54.299
otherwise and the input so one
 

00:01:54.299 --> 00:01:57.560
otherwise and the input so one
specifically will minimize the negative

00:01:57.560 --> 00:01:57.570
specifically will minimize the negative
 

00:01:57.570 --> 00:02:01.819
specifically will minimize the negative
sum of the log of the probability of the

00:02:01.819 --> 00:02:01.829
sum of the log of the probability of the
 

00:02:01.829 --> 00:02:05.209
sum of the log of the probability of the
true label at position K given all other

00:02:05.209 --> 00:02:05.219
true label at position K given all other
 

00:02:05.219 --> 00:02:07.550
true label at position K given all other
labels at position 1 up to K minus 1

00:02:07.550 --> 00:02:07.560
labels at position 1 up to K minus 1
 

00:02:07.560 --> 00:02:12.290
labels at position 1 up to K minus 1
then k plus 1 up to capital K so you can

00:02:12.290 --> 00:02:12.300
then k plus 1 up to capital K so you can
 

00:02:12.300 --> 00:02:13.809
then k plus 1 up to capital K so you can
think of it as try to

00:02:13.809 --> 00:02:13.819
think of it as try to
 

00:02:13.819 --> 00:02:17.930
think of it as try to
in turn each YK not just from X but from

00:02:17.930 --> 00:02:17.940
in turn each YK not just from X but from
 

00:02:17.940 --> 00:02:20.800
in turn each YK not just from X but from
all other elements in the vector Y

00:02:20.800 --> 00:02:20.810
all other elements in the vector Y
 

00:02:20.810 --> 00:02:24.530
all other elements in the vector Y
what's nice is that for this expression

00:02:24.530 --> 00:02:24.540
what's nice is that for this expression
 

00:02:24.540 --> 00:02:27.199
what's nice is that for this expression
we can usually tractive lis compute the

00:02:27.199 --> 00:02:27.209
we can usually tractive lis compute the
 

00:02:27.209 --> 00:02:29.030
we can usually tractive lis compute the
exact gradients for optimizing that

00:02:29.030 --> 00:02:29.040
exact gradients for optimizing that
 

00:02:29.040 --> 00:02:32.300
exact gradients for optimizing that
objective so and that's because each of

00:02:32.300 --> 00:02:32.310
objective so and that's because each of
 

00:02:32.310 --> 00:02:34.100
objective so and that's because each of
these conditionals essentially just

00:02:34.100 --> 00:02:34.110
these conditionals essentially just
 

00:02:34.110 --> 00:02:36.559
these conditionals essentially just
require that we normalize over all

00:02:36.559 --> 00:02:36.569
require that we normalize over all
 

00:02:36.569 --> 00:02:40.280
require that we normalize over all
values of Y k and usually y ki will take

00:02:40.280 --> 00:02:40.290
values of Y k and usually y ki will take
 

00:02:40.290 --> 00:02:42.979
values of Y k and usually y ki will take
a fairly small number of values so it's

00:02:42.979 --> 00:02:42.989
a fairly small number of values so it's
 

00:02:42.989 --> 00:02:44.600
a fairly small number of values so it's
going to be similar to performing a

00:02:44.600 --> 00:02:44.610
going to be similar to performing a
 

00:02:44.610 --> 00:02:46.820
going to be similar to performing a
regular softmax computation and a

00:02:46.820 --> 00:02:46.830
regular softmax computation and a
 

00:02:46.830 --> 00:02:49.220
regular softmax computation and a
regular neural network though now this

00:02:49.220 --> 00:02:49.230
regular neural network though now this
 

00:02:49.230 --> 00:02:51.110
regular neural network though now this
probability will be influenced not just

00:02:51.110 --> 00:02:51.120
probability will be influenced not just
 

00:02:51.120 --> 00:02:53.150
probability will be influenced not just
by the input but also by other label

00:02:53.150 --> 00:02:53.160
by the input but also by other label
 

00:02:53.160 --> 00:02:55.820
by the input but also by other label
values and the other label values are

00:02:55.820 --> 00:02:55.830
values and the other label values are
 

00:02:55.830 --> 00:02:58.100
values and the other label values are
actually going to be the true label

00:02:58.100 --> 00:02:58.110
actually going to be the true label
 

00:02:58.110 --> 00:03:04.400
actually going to be the true label
values in the target vector and another

00:03:04.400 --> 00:03:04.410
values in the target vector and another
 

00:03:04.410 --> 00:03:06.140
values in the target vector and another
thing that's nice is that each of these

00:03:06.140 --> 00:03:06.150
thing that's nice is that each of these
 

00:03:06.150 --> 00:03:08.720
thing that's nice is that each of these
conditionals for the conditional random

00:03:08.720 --> 00:03:08.730
conditionals for the conditional random
 

00:03:08.730 --> 00:03:10.940
conditionals for the conditional random
field is typically only really gonna

00:03:10.940 --> 00:03:10.950
field is typically only really gonna
 

00:03:10.950 --> 00:03:13.490
field is typically only really gonna
depend on a few of the other target

00:03:13.490 --> 00:03:13.500
depend on a few of the other target
 

00:03:13.500 --> 00:03:15.350
depend on a few of the other target
variables and that's because of the

00:03:15.350 --> 00:03:15.360
variables and that's because of the
 

00:03:15.360 --> 00:03:17.509
variables and that's because of the
local markov property of a conditional

00:03:17.509 --> 00:03:17.519
local markov property of a conditional
 

00:03:17.519 --> 00:03:19.100
local markov property of a conditional
random field if we look at its markup

00:03:19.100 --> 00:03:19.110
random field if we look at its markup
 

00:03:19.110 --> 00:03:23.210
random field if we look at its markup
network then we know that the property

00:03:23.210 --> 00:03:23.220
network then we know that the property
 

00:03:23.220 --> 00:03:25.729
network then we know that the property
of YK given everything else reduces to

00:03:25.729 --> 00:03:25.739
of YK given everything else reduces to
 

00:03:25.739 --> 00:03:28.100
of YK given everything else reduces to
the property of YK given only its

00:03:28.100 --> 00:03:28.110
the property of YK given only its
 

00:03:28.110 --> 00:03:30.080
the property of YK given only its
neighbors so it's actually going to be a

00:03:30.080 --> 00:03:30.090
neighbors so it's actually going to be a
 

00:03:30.090 --> 00:03:31.970
neighbors so it's actually going to be a
much simpler expression than just this

00:03:31.970 --> 00:03:31.980
much simpler expression than just this
 

00:03:31.980 --> 00:03:34.520
much simpler expression than just this
depending on the graph structure on the

00:03:34.520 --> 00:03:34.530
depending on the graph structure on the
 

00:03:34.530 --> 00:03:39.199
depending on the graph structure on the
mark of network so that being said with

00:03:39.199 --> 00:03:39.209
mark of network so that being said with
 

00:03:39.209 --> 00:03:41.330
mark of network so that being said with
still to make prediction we would still

00:03:41.330 --> 00:03:41.340
still to make prediction we would still
 

00:03:41.340 --> 00:03:43.699
still to make prediction we would still
normally need to compute the marginal

00:03:43.699 --> 00:03:43.709
normally need to compute the marginal
 

00:03:43.709 --> 00:03:45.650
normally need to compute the marginal
distribution which might still be

00:03:45.650 --> 00:03:45.660
distribution which might still be
 

00:03:45.660 --> 00:03:47.870
distribution which might still be
intractable so it makes training more

00:03:47.870 --> 00:03:47.880
intractable so it makes training more
 

00:03:47.880 --> 00:03:49.940
intractable so it makes training more
tractable but at test time we'll make a

00:03:49.940 --> 00:03:49.950
tractable but at test time we'll make a
 

00:03:49.950 --> 00:03:52.250
tractable but at test time we'll make a
prediction if you wanna use prediction

00:03:52.250 --> 00:03:52.260
prediction if you wanna use prediction
 

00:03:52.260 --> 00:03:54.140
prediction if you wanna use prediction
based on the marginals we still have to

00:03:54.140 --> 00:03:54.150
based on the marginals we still have to
 

00:03:54.150 --> 00:03:56.319
based on the marginals we still have to
do some approximate inference so that

00:03:56.319 --> 00:03:56.329
do some approximate inference so that
 

00:03:56.329 --> 00:04:00.440
do some approximate inference so that
doesn't entirely solve our problem so

00:04:00.440 --> 00:04:00.450
doesn't entirely solve our problem so
 

00:04:00.450 --> 00:04:01.940
doesn't entirely solve our problem so
notice that the reason we have to do

00:04:01.940 --> 00:04:01.950
notice that the reason we have to do
 

00:04:01.950 --> 00:04:04.220
notice that the reason we have to do
this and that this isn't a problem here

00:04:04.220 --> 00:04:04.230
this and that this isn't a problem here
 

00:04:04.230 --> 00:04:06.500
this and that this isn't a problem here
is that here we are conditioning on the

00:04:06.500 --> 00:04:06.510
is that here we are conditioning on the
 

00:04:06.510 --> 00:04:09.170
is that here we are conditioning on the
true labels so we don't have to infer

00:04:09.170 --> 00:04:09.180
true labels so we don't have to infer
 

00:04:09.180 --> 00:04:11.330
true labels so we don't have to infer
what the other labels might be we

00:04:11.330 --> 00:04:11.340
what the other labels might be we
 

00:04:11.340 --> 00:04:12.949
what the other labels might be we
actually know them at training time so

00:04:12.949 --> 00:04:12.959
actually know them at training time so
 

00:04:12.959 --> 00:04:14.539
actually know them at training time so
we exploiting that at training time but

00:04:14.539 --> 00:04:14.549
we exploiting that at training time but
 

00:04:14.549 --> 00:04:17.090
we exploiting that at training time but
at test time we can't and I should say

00:04:17.090 --> 00:04:17.100
at test time we can't and I should say
 

00:04:17.100 --> 00:04:18.770
at test time we can't and I should say
that in practice we often find that

00:04:18.770 --> 00:04:18.780
that in practice we often find that
 

00:04:18.780 --> 00:04:19.849
that in practice we often find that
pseudo likelihood

00:04:19.849 --> 00:04:19.859
pseudo likelihood
 

00:04:19.859 --> 00:04:22.790
pseudo likelihood
works less well so it gives models are

00:04:22.790 --> 00:04:22.800
works less well so it gives models are
 

00:04:22.800 --> 00:04:24.770
works less well so it gives models are
not as good as models that are trained

00:04:24.770 --> 00:04:24.780
not as good as models that are trained
 

00:04:24.780 --> 00:04:26.620
not as good as models that are trained
by maximum likelihood

00:04:26.620 --> 00:04:26.630
by maximum likelihood
 

00:04:26.630 --> 00:04:30.280
by maximum likelihood
and there's some theory for backing up

00:04:30.280 --> 00:04:30.290
and there's some theory for backing up
 

00:04:30.290 --> 00:04:33.160
and there's some theory for backing up
why we should observe this so we're not

00:04:33.160 --> 00:04:33.170
why we should observe this so we're not
 

00:04:33.170 --> 00:04:36.430
why we should observe this so we're not
necessarily suggests someone uses sort

00:04:36.430 --> 00:04:36.440
necessarily suggests someone uses sort
 

00:04:36.440 --> 00:04:38.620
necessarily suggests someone uses sort
of likelihood except perhaps on a very

00:04:38.620 --> 00:04:38.630
of likelihood except perhaps on a very
 

00:04:38.630 --> 00:04:41.260
of likelihood except perhaps on a very
very complicated model but it's good to

00:04:41.260 --> 00:04:41.270
very complicated model but it's good to
 

00:04:41.270 --> 00:04:42.970
very complicated model but it's good to
know that there are alternatives to

00:04:42.970 --> 00:04:42.980
know that there are alternatives to
 

00:04:42.980 --> 00:04:46.060
know that there are alternatives to
conditional random fields then training

00:04:46.060 --> 00:04:46.070
conditional random fields then training
 

00:04:46.070 --> 00:04:49.240
conditional random fields then training
them by maximum likelihood and certain

00:04:49.240 --> 00:04:49.250
them by maximum likelihood and certain
 

00:04:49.250 --> 00:04:51.640
them by maximum likelihood and certain
alternatives will be sort of nicer in

00:04:51.640 --> 00:04:51.650
alternatives will be sort of nicer in
 

00:04:51.650 --> 00:04:53.830
alternatives will be sort of nicer in
terms of the computations that are

00:04:53.830 --> 00:04:53.840
terms of the computations that are
 

00:04:53.840 --> 00:04:56.040
terms of the computations that are
required for for training them and

00:04:56.040 --> 00:04:56.050
required for for training them and
 

00:04:56.050 --> 00:04:58.330
required for for training them and
training conditional random fields in

00:04:58.330 --> 00:04:58.340
training conditional random fields in
 

00:04:58.340 --> 00:05:00.010
training conditional random fields in
general is a very active field of

00:05:00.010 --> 00:05:00.020
general is a very active field of
 

00:05:00.020 --> 00:05:02.980
general is a very active field of
research but with all we've seen and the

00:05:02.980 --> 00:05:02.990
research but with all we've seen and the
 

00:05:02.990 --> 00:05:05.200
research but with all we've seen and the
this video and the previous ones that

00:05:05.200 --> 00:05:05.210
this video and the previous ones that
 

00:05:05.210 --> 00:05:08.110
this video and the previous ones that
should give you a head start for looking

00:05:08.110 --> 00:05:08.120
should give you a head start for looking
 

00:05:08.120 --> 00:05:11.050
should give you a head start for looking
at that literature more

