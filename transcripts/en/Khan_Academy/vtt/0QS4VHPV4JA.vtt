WEBVTT
Kind: captions
Language: en

00:00:00.660 --> 00:00:04.522
Here's a simulation created
by Khan Academy user TETF.

00:00:04.522 --> 00:00:07.327
I can assume that's
pronounced tet f.

00:00:07.327 --> 00:00:08.910
And what it allows
us to do is give us

00:00:08.910 --> 00:00:12.610
an intuition as to why
we divide by n minus 1

00:00:12.610 --> 00:00:15.120
when we calculate
our sample variance

00:00:15.120 --> 00:00:18.310
and why that gives us an
unbiased estimate of population

00:00:18.310 --> 00:00:19.330
variance.

00:00:19.330 --> 00:00:21.750
So the way this starts
off, and I encourage

00:00:21.750 --> 00:00:23.650
you to go try this
out yourself, is

00:00:23.650 --> 00:00:25.420
that you can construct
a distribution.

00:00:25.420 --> 00:00:28.970
It says build a population
by clicking in the blue area.

00:00:28.970 --> 00:00:32.810
So here, we are actually
creating a population.

00:00:32.810 --> 00:00:37.450
So every time I click, it
increases the population size.

00:00:37.450 --> 00:00:39.100
And I'm just
randomly doing this,

00:00:39.100 --> 00:00:42.890
and I encourage you to go
onto this scratch pad-- it's

00:00:42.890 --> 00:00:44.940
on the Khan Academy
Computer Science--

00:00:44.940 --> 00:00:47.260
and try to do it yourself.

00:00:47.260 --> 00:00:50.680
So here I could
stop at some point.

00:00:50.680 --> 00:00:52.460
So I've constructed
a population.

00:00:52.460 --> 00:00:54.790
I can throw out some
random points up here.

00:00:54.790 --> 00:00:56.484
So this is our
population, and as you

00:00:56.484 --> 00:00:58.400
saw while I was doing
that, it was calculating

00:00:58.400 --> 00:00:59.650
parameters for the population.

00:00:59.650 --> 00:01:01.600
It was calculating
the population

00:01:01.600 --> 00:01:05.360
mean at 204.09 and
also the population

00:01:05.360 --> 00:01:08.540
standard deviation, which is
derived from the population

00:01:08.540 --> 00:01:09.120
variance.

00:01:09.120 --> 00:01:11.720
This is the square root of
the population variance,

00:01:11.720 --> 00:01:13.600
and it's at 63.8.

00:01:13.600 --> 00:01:16.780
It was also pop plotting the
population variance down here.

00:01:16.780 --> 00:01:19.630
You see it's 63.8, which
is the standard deviation,

00:01:19.630 --> 00:01:23.280
and it's a little harder to
see, but it says it's squared.

00:01:23.280 --> 00:01:24.850
These are these numbers squared.

00:01:24.850 --> 00:01:32.894
So essentially, 63.8 squared
is the population variance.

00:01:32.894 --> 00:01:34.810
So that's interesting
by itself, but it really

00:01:34.810 --> 00:01:36.490
doesn't tell us a
lot so far about

00:01:36.490 --> 00:01:38.790
why we divide by n minus 1.

00:01:38.790 --> 00:01:40.540
And this is the
interesting part.

00:01:40.540 --> 00:01:42.209
We can now start
to take samples,

00:01:42.209 --> 00:01:44.250
and we can decide what
sample size we want to do.

00:01:44.250 --> 00:01:47.020
I'll start with really small
samples, so the smallest

00:01:47.020 --> 00:01:49.699
possible sample that
makes any sense.

00:01:49.699 --> 00:01:51.740
So I'm going to start with
a really small sample.

00:01:51.740 --> 00:01:53.740
And what they're going to do--
what the simulation is going

00:01:53.740 --> 00:01:55.520
to do-- is every
time I take a sample,

00:01:55.520 --> 00:01:57.430
it's going to
calculate the variance.

00:01:57.430 --> 00:02:00.300
So the numerator is going to
be the sum of each of my data

00:02:00.300 --> 00:02:03.190
points in my sample
minus my sample mean,

00:02:03.190 --> 00:02:04.700
and I'm going to square it.

00:02:04.700 --> 00:02:08.590
And then it's going to
divide it by n plus a,

00:02:08.590 --> 00:02:09.810
and it's going to vary a.

00:02:09.810 --> 00:02:12.540
It's going to divide it
by anywhere between n

00:02:12.540 --> 00:02:18.274
plus negative 3, so n minus
3, all the way to n plus a.

00:02:18.274 --> 00:02:20.690
And we're going to do it in
many, many, many, many, times.

00:02:20.690 --> 00:02:23.148
We're going to essentially take
the mean of those variances

00:02:23.148 --> 00:02:26.990
for any a and figure out which
gives us the best estimate.

00:02:26.990 --> 00:02:28.910
So if I just generate
one sample right

00:02:28.910 --> 00:02:35.490
over there, when we see kind
of this curve, when we have

00:02:35.490 --> 00:02:37.840
high values of a, we
are underestimating.

00:02:37.840 --> 00:02:40.130
When we have lower
values of a, we

00:02:40.130 --> 00:02:43.290
are overestimating the
population variance,

00:02:43.290 --> 00:02:45.910
but that was just
for one sample,

00:02:45.910 --> 00:02:47.260
not really that meaningful.

00:02:47.260 --> 00:02:48.840
It's one sample of size two.

00:02:48.840 --> 00:02:50.690
Let's generate a
bunch of samples

00:02:50.690 --> 00:02:53.475
and then average them
over many of them.

00:02:53.475 --> 00:02:55.850
And you see when you look at
many, many, many, many, many

00:02:55.850 --> 00:02:58.890
examples, something
interesting is happening.

00:02:58.890 --> 00:03:01.170
When you look at the
mean of those samples,

00:03:01.170 --> 00:03:03.260
when you average together
those curves from all

00:03:03.260 --> 00:03:06.400
of those samples, you see
that our best estimate is

00:03:06.400 --> 00:03:09.210
when a is pretty
close to negative 1,

00:03:09.210 --> 00:03:13.400
is when this is n plus
negative 1 or n minus 1.

00:03:13.400 --> 00:03:15.350
Anything less than
negative 1-- if we

00:03:15.350 --> 00:03:19.960
did negative n minus
1.05 or n minus 1.5--

00:03:19.960 --> 00:03:22.810
we start overestimating
the variance.

00:03:22.810 --> 00:03:27.760
Anything less than
negative 1, so if we

00:03:27.760 --> 00:03:33.750
have n plus 0, if we divide
by n or if we have n plus 0.05

00:03:33.750 --> 00:03:37.620
or whatever it
might be, we start

00:03:37.620 --> 00:03:40.075
underestimating the
population variance.

00:03:40.075 --> 00:03:42.200
And you can do this for
samples of different sizes.

00:03:42.200 --> 00:03:44.690
Let me try a sample size 6.

00:03:44.690 --> 00:03:46.970
And here you go once
again, as I press--

00:03:46.970 --> 00:03:49.520
I'm just keeping Generate
Sample pressed down--

00:03:49.520 --> 00:03:52.350
as we generate more and
more and more samples--

00:03:52.350 --> 00:03:55.030
and for all the a's we
essentially take the average

00:03:55.030 --> 00:03:57.670
across those samples
for the variance

00:03:57.670 --> 00:03:59.480
depending on how
we calculate it--

00:03:59.480 --> 00:04:05.320
you'll see that once again, our
best estimate is pretty darn

00:04:05.320 --> 00:04:06.430
close to negative 1.

00:04:06.430 --> 00:04:10.970
And if you were to get this to
millions of samples generated,

00:04:10.970 --> 00:04:13.270
you'll see that your
best estimate is

00:04:13.270 --> 00:04:20.430
when a is negative 1 or when
you're dividing by n minus 1.

00:04:20.430 --> 00:04:23.620
So once again, thanks
TETF, tet f, for this.

00:04:23.620 --> 00:04:25.580
I think it's a really
interesting way

00:04:25.580 --> 00:04:29.770
to think about why we
divide by n minus 1.

