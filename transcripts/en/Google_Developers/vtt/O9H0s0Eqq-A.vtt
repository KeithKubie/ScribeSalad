WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:00.370
 

00:00:00.370 --> 00:00:01.495
Alexis Moussine-Pouchkine: Hi, everybody.

00:00:01.495 --> 00:00:03.480
We're here at Devoxx 2014.

00:00:03.480 --> 00:00:04.601
And I'm here with Martin.

00:00:04.601 --> 00:00:05.476
MARTIN GORNER: Hello.

00:00:05.476 --> 00:00:06.601
INTERVIEWER: Hello, Martin.

00:00:06.601 --> 00:00:09.620
And Martin has an
interesting session

00:00:09.620 --> 00:00:12.140
here at the conference,
which is called something

00:00:12.140 --> 00:00:15.150
like "Nobody Does MapReduce
Anymore at Google."

00:00:15.150 --> 00:00:17.200
So Google kind of
invented MapReduce,

00:00:17.200 --> 00:00:19.970
and now you tell us,
just a few years later,

00:00:19.970 --> 00:00:22.800
when everybody is using it
in various implementations

00:00:22.800 --> 00:00:25.224
that this was a bad
idea, in fact, right?

00:00:25.224 --> 00:00:26.890
MARTIN GORNER: Well,
the MapReduce paper

00:00:26.890 --> 00:00:28.710
was published in 2004.

00:00:28.710 --> 00:00:30.860
That's 10 years ago.

00:00:30.860 --> 00:00:35.320
You can imagine that the train
has been moving since then.

00:00:35.320 --> 00:00:37.890
But actually, yes,
the title of the talk

00:00:37.890 --> 00:00:39.830
is a little bit provocative.

00:00:39.830 --> 00:00:43.840
There is still a lot
of MapReduce going on.

00:00:43.840 --> 00:00:47.770
The reality is that
it would be, I think,

00:00:47.770 --> 00:00:50.710
a bad idea to launch
MapReduce as a service

00:00:50.710 --> 00:00:55.260
today because what
we are using in-house

00:00:55.260 --> 00:00:58.250
is much more powerful than that.

00:00:58.250 --> 00:01:00.870
And that's actually what we
will be releasing shortly.

00:01:00.870 --> 00:01:03.510
It's called Google
Cloud Dataflow.

00:01:03.510 --> 00:01:06.140
INTERVIEWER: So Dataflow.

00:01:06.140 --> 00:01:08.310
So this is based on another
paper, which, I believe,

00:01:08.310 --> 00:01:09.600
is called FlumeJava.

00:01:09.600 --> 00:01:10.140
MARTIN GORNER: Yes, exactly.

00:01:10.140 --> 00:01:12.306
INTERVIEWER: And it's a
higher level of abstraction.

00:01:12.306 --> 00:01:14.130
So maybe MapReduce
is just one way

00:01:14.130 --> 00:01:17.840
to implement whatever
you express in Dataflow.

00:01:17.840 --> 00:01:19.960
So walk us through
what Dataflow is.

00:01:19.960 --> 00:01:23.242
Maybe for the developer, it's
about dealing with data, right?

00:01:23.242 --> 00:01:24.200
MARTIN GORNER: Exactly.

00:01:24.200 --> 00:01:27.470
What you want to do is
crunch huge amounts of data.

00:01:27.470 --> 00:01:29.860
And when you do
this for a living,

00:01:29.860 --> 00:01:33.650
you realize that even
for small problems,

00:01:33.650 --> 00:01:36.060
one MapReduce stage
is usually not enough.

00:01:36.060 --> 00:01:39.234
You want to have at least two of
them or maybe five of them in--

00:01:39.234 --> 00:01:40.900
INTERVIEWER: The
pipeline of MapReduces.

00:01:40.900 --> 00:01:42.190
MARTIN GORNER: In
a different graph.

00:01:42.190 --> 00:01:42.940
Not just a pipeline.

00:01:42.940 --> 00:01:43.830
It could be a graph.

00:01:43.830 --> 00:01:44.420
INTERVIEWER: A graph, yes.

00:01:44.420 --> 00:01:45.836
MARTIN GORNER: But
two MapReduces,

00:01:45.836 --> 00:01:48.080
merging the results,
going into a third one,

00:01:48.080 --> 00:01:50.450
and then doing something
else with the data again.

00:01:50.450 --> 00:01:54.630
And this, if you try to
implement it using MapReduce,

00:01:54.630 --> 00:01:57.040
you end up with
a lot of plumbing

00:01:57.040 --> 00:01:59.750
because you need to handle all
those intermediate results.

00:01:59.750 --> 00:02:02.270
You need to actually deploy
your MapReduce clusters,

00:02:02.270 --> 00:02:04.080
and all that.

00:02:04.080 --> 00:02:06.640
So there is a better way.

00:02:06.640 --> 00:02:11.360
And the way we are suggesting
to developers to do it

00:02:11.360 --> 00:02:14.900
today is to use a
very small number

00:02:14.900 --> 00:02:19.200
of high-level primitives--
in Java, for example--

00:02:19.200 --> 00:02:23.260
and define the computation
using those primitives.

00:02:23.260 --> 00:02:27.540
Those primitives work
on parallel collections

00:02:27.540 --> 00:02:32.240
and are executed lazily, which
means that the code you write

00:02:32.240 --> 00:02:35.940
is simply used by the
system to infer an execution

00:02:35.940 --> 00:02:38.270
graph in memory.

00:02:38.270 --> 00:02:41.470
Once we have that graph,
we can optimize it,

00:02:41.470 --> 00:02:46.260
and we can deploy the
optimal cluster topology

00:02:46.260 --> 00:02:49.790
for actually running
your computation.

00:02:49.790 --> 00:02:52.632
Deploy it, run it, tear it down.

00:02:52.632 --> 00:02:54.340
Of course, you still
get all the benefits

00:02:54.340 --> 00:02:58.910
of MapReduce, which means it's
a parallel execution framework.

00:02:58.910 --> 00:03:02.780
The life cycle of the
nodes is handled for you.

00:03:02.780 --> 00:03:06.710
Catastrophic events, like a
node dying unexpectedly or not

00:03:06.710 --> 00:03:07.320
responding.

00:03:07.320 --> 00:03:09.020
That's handled for you.

00:03:09.020 --> 00:03:13.460
You really only focus on
the math, the computation

00:03:13.460 --> 00:03:15.040
you want to do on your data.

00:03:15.040 --> 00:03:17.030
INTERVIEWER: So walk
us through, briefly,

00:03:17.030 --> 00:03:19.110
what the API looks
like as a developer.

00:03:19.110 --> 00:03:21.050
How do I develop and use this?

00:03:21.050 --> 00:03:23.286
What is my input,
output, operations?

00:03:23.286 --> 00:03:25.390
What does the API look like?

00:03:25.390 --> 00:03:29.890
MARTIN GORNER: So the basic
piece of data you act on

00:03:29.890 --> 00:03:30.860
is a P-collection.

00:03:30.860 --> 00:03:33.070
That's a parallel collection.

00:03:33.070 --> 00:03:37.240
It's an immutable
collection of data.

00:03:37.240 --> 00:03:40.240
And then you use
primitives to work on it.

00:03:40.240 --> 00:03:44.670
The most basic
primitive is parallelDO,

00:03:44.670 --> 00:03:47.420
a parallel operation,
a function you provide.

00:03:47.420 --> 00:03:49.615
That's the equivalent
of Map or Reduce

00:03:49.615 --> 00:03:52.690
in the MapReduce paradigm.

00:03:52.690 --> 00:03:59.450
And then the second important
primitive is a group by key.

00:03:59.450 --> 00:04:02.160
So normally, when
you do a parallelDO,

00:04:02.160 --> 00:04:03.690
you do computations
on your data,

00:04:03.690 --> 00:04:06.330
and you also assign
keys to your data.

00:04:06.330 --> 00:04:08.430
So the output is
key value pairs.

00:04:08.430 --> 00:04:11.700
And then, again in the
MapReduce paradigm,

00:04:11.700 --> 00:04:15.020
you have a group by key,
which is called a shuffle

00:04:15.020 --> 00:04:18.500
stage, which will put all
the data with the same key

00:04:18.500 --> 00:04:21.640
together and apply another,
usually an aggregation

00:04:21.640 --> 00:04:23.000
on those data.

00:04:23.000 --> 00:04:26.830
So parallel collections,
parallelDO group by key.

00:04:26.830 --> 00:04:28.460
And then a third
primitive, which

00:04:28.460 --> 00:04:31.700
is an associative parallelDO
that has a lot of good stuff

00:04:31.700 --> 00:04:34.870
that can happen when your
parallelDO is associated.

00:04:34.870 --> 00:04:38.110
So with those three
primitives, it's

00:04:38.110 --> 00:04:42.100
enough to describe most of the
computations you want to do.

00:04:42.100 --> 00:04:46.750
And then FlumeJava also
adds primitives-- well,

00:04:46.750 --> 00:04:49.320
not primitives, but
functions, helper functions,

00:04:49.320 --> 00:04:51.490
which are already
implemented on top of those,

00:04:51.490 --> 00:04:57.130
like counting or adjoin,
or a top operation.

00:04:57.130 --> 00:04:57.890
INTERVIEWER: OK.

00:04:57.890 --> 00:05:00.190
So you mentioned FlumeJava.

00:05:00.190 --> 00:05:03.019
That's the paper that was
published around 2010, I think.

00:05:03.019 --> 00:05:03.810
MARTIN GORNER: Yes.

00:05:03.810 --> 00:05:05.351
INTERVIEWER: It's
based on experience

00:05:05.351 --> 00:05:08.050
Google has running this type
of technology in production.

00:05:08.050 --> 00:05:12.422
But what we're offering here
is a product called Dataflow.

00:05:12.422 --> 00:05:13.880
And that's a service
we're offering

00:05:13.880 --> 00:05:17.770
because you want to focus, as a
developer, on that level of API

00:05:17.770 --> 00:05:22.150
you just described and leave to
Google everything else, which

00:05:22.150 --> 00:05:25.310
is setting up the environment,
the network, the nodes,

00:05:25.310 --> 00:05:28.040
and spinning out the
resources in the most

00:05:28.040 --> 00:05:30.450
efficient and fastest way
to provide a result back.

00:05:30.450 --> 00:05:31.408
MARTIN GORNER: Exactly.

00:05:31.408 --> 00:05:37.930
And the beauty of it is that if
you have a complex computation,

00:05:37.930 --> 00:05:42.030
which actually results in
a fairly complex network

00:05:42.030 --> 00:05:45.540
topology for your
processing cluster,

00:05:45.540 --> 00:05:47.690
if there is something
you need to change,

00:05:47.690 --> 00:05:49.720
it's a couple of
lines in your code.

00:05:49.720 --> 00:05:51.720
And you hit Enter,
and that cluster

00:05:51.720 --> 00:05:54.730
gets redeployed with
a different topology.

00:05:54.730 --> 00:05:58.020
That's really how we want
to manage a compute cluster.

00:05:58.020 --> 00:06:00.150
You don't want to be
there changing the nodes

00:06:00.150 --> 00:06:03.140
and rewiring them because
you need to compute something

00:06:03.140 --> 00:06:04.420
slightly differently.

00:06:04.420 --> 00:06:05.250
INTERVIEWER: Yeah.

00:06:05.250 --> 00:06:08.540
So the other thing is
the data you work on,

00:06:08.540 --> 00:06:10.440
is this like read-only data?

00:06:10.440 --> 00:06:12.310
You have a batch of data?

00:06:12.310 --> 00:06:15.000
Or can you have some
sort of streaming?

00:06:15.000 --> 00:06:16.600
Or is there anything--

00:06:16.600 --> 00:06:19.350
MARTIN GORNER: Well, that's
the second, I would say,

00:06:19.350 --> 00:06:24.840
magic strong point of
Dataflow is that once

00:06:24.840 --> 00:06:27.100
you have your
computation described

00:06:27.100 --> 00:06:30.040
in using the
high-level primitives,

00:06:30.040 --> 00:06:33.030
to turn this into a
streaming computation,

00:06:33.030 --> 00:06:35.640
what you do is that you change
your inputs and outputs.

00:06:35.640 --> 00:06:38.084
Instead of reading from a
file, you read from a stream.

00:06:38.084 --> 00:06:38.750
INTERVIEWER: OK.

00:06:38.750 --> 00:06:40.416
MARTIN GORNER: You
add one line of code,

00:06:40.416 --> 00:06:44.400
which is please now work
with this time window.

00:06:44.400 --> 00:06:45.910
And that's it.

00:06:45.910 --> 00:06:50.630
This cluster becomes a real-time
data processing cluster

00:06:50.630 --> 00:06:56.070
that does everything the batch
processing cluster was doing.

00:06:56.070 --> 00:06:59.020
There's still node life cycle,
nodes dying, and all that.

00:06:59.020 --> 00:07:00.850
All this is handled for you.

00:07:00.850 --> 00:07:05.000
But now it can
also automatically

00:07:05.000 --> 00:07:07.150
scale with the volume of data.

00:07:07.150 --> 00:07:09.350
And if you think
about it inside,

00:07:09.350 --> 00:07:15.520
it uses parallel sets of nodes
for executing your parallelDOs.

00:07:15.520 --> 00:07:17.780
It can figure out how many
nodes to put in parallel

00:07:17.780 --> 00:07:20.240
to actually sustain the flow.

00:07:20.240 --> 00:07:24.600
And those parallel
processing groups of nodes,

00:07:24.600 --> 00:07:27.540
they're all actually
put together

00:07:27.540 --> 00:07:29.810
in a complex execution graph.

00:07:29.810 --> 00:07:31.690
But you don't have
to worry about that.

00:07:31.690 --> 00:07:33.760
There's an optimizer
that worries about that.

00:07:33.760 --> 00:07:36.240
And there is an
executor that worries

00:07:36.240 --> 00:07:38.400
about putting the whole
thing on autopilot.

00:07:38.400 --> 00:07:40.400
INTERVIEWER: I like
all those things

00:07:40.400 --> 00:07:42.580
I don't have to worry about.

00:07:42.580 --> 00:07:46.542
So when can I, when can
folks start using this?

00:07:46.542 --> 00:07:49.610
This is Dataflow, that's
a service, a product,

00:07:49.610 --> 00:07:52.139
Google Cloud is offering soon?

00:07:52.139 --> 00:07:53.680
MARTIN GORNER: So
we've been using it

00:07:53.680 --> 00:07:57.080
for many years at Google,
which means that it's not

00:07:57.080 --> 00:08:04.070
a completely
non-baked technology.

00:08:04.070 --> 00:08:07.290
And in the session today,
you will see a live demo.

00:08:07.290 --> 00:08:08.080
INTERVIEWER: OK.

00:08:08.080 --> 00:08:09.310
MARTIN GORNER: So
that's the status.

00:08:09.310 --> 00:08:10.250
INTERVIEWER: So, yeah.

00:08:10.250 --> 00:08:11.750
That's a good plug
for your session,

00:08:11.750 --> 00:08:13.720
for people to watch
this on [INAUDIBLE]

00:08:13.720 --> 00:08:15.330
as soon as it's published.

00:08:15.330 --> 00:08:15.450
MARTIN GORNER: Indeed.

00:08:15.450 --> 00:08:15.910
INTERVIEWER: So, Martin.

00:08:15.910 --> 00:08:17.701
I think that's all the
time we have for it.

00:08:17.701 --> 00:08:20.170
So thanks for doing this, and
good luck with the session.

00:08:20.170 --> 00:08:22.319
And folks, keep an
eye on Cloud Dataflow.

00:08:22.319 --> 00:08:23.360
MARTIN GORNER: Thank you.

00:08:23.360 --> 00:08:24.910
INTERVIEWER: Thanks, everyone.

00:08:24.910 --> 00:08:41.844
 

