WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:03.000
we've talked about using facial points as

00:00:04.839 --> 00:00:06.839
features descriptors

00:00:07.029 --> 00:00:12.419
Indicators whether there's a facial expression or not as you can see you can just look at let's say the angle

00:00:13.240 --> 00:00:18.270
Here and compare that with the angle here, and they are very useful

00:00:18.270 --> 00:00:23.100
They're very powerful, but they can't decode everything for instance if you have a little dimple

00:00:23.650 --> 00:00:28.320
in the mouth there's no real movement of the the

00:00:28.900 --> 00:00:30.900
of facial point

00:00:31.630 --> 00:00:33.630
It's just [that]

00:00:34.450 --> 00:00:39.869
This mouth Corner is sort of pulling inwards, so [you] don't get a geometric

00:00:40.390 --> 00:00:42.719
variation you do get changes in appearance

00:00:45.399 --> 00:00:51.809
It's these kinds of features [that] we're looking at when we're looking at appearance features. So they're [very] good at looking at

00:00:52.329 --> 00:00:54.329
first when I open a frown and

00:00:54.969 --> 00:00:57.719
So actually when I smile the corner of my mouth

00:00:58.629 --> 00:01:02.969
will look very different from a neutral position, [so]

00:01:04.479 --> 00:01:07.979
The question, then is how are we going [to] encode?

00:01:08.770 --> 00:01:10.770
disappearance and we want to

00:01:11.290 --> 00:01:18.809
minimize the variation in our you know features and our scripted that's caused by things that are irrelevant to expression such as

00:01:19.689 --> 00:01:21.610
lighting or

00:01:21.610 --> 00:01:23.020
Identity and

00:01:23.020 --> 00:01:29.369
We want to maximize the variation or features that are relevant to facial expression and in our case

00:01:29.369 --> 00:01:30.579
That's quite open edges

00:01:30.579 --> 00:01:36.389
so we want to sort of encode edges in a very cheap way and a very interesting and

00:01:36.850 --> 00:01:40.680
highly successful feature for that is called the local binary Pattern

00:01:41.079 --> 00:01:44.309
Local binary Pattern looks at nine pixels at a time

00:01:44.530 --> 00:01:49.320
So it looks at a little block of three by three pixels

00:01:49.320 --> 00:01:53.489
And it's particularly interested at the Central pixel

00:01:54.009 --> 00:01:59.489
So let's say that the pixel value of our central pixel is eight

00:01:59.490 --> 00:02:02.610
And it has eight pixels around it, and it's nine block

00:02:02.610 --> 00:02:03.909
Let's put in some numbers

00:02:03.909 --> 00:02:09.689
And that make some sense a local binary pattern is now going to turn this

00:02:09.940 --> 00:02:15.449
Set of nine by nine pixels into a single value, and it'll do that by first

00:02:16.660 --> 00:02:23.219
Comparing every neighboring pixel with the Central pixel this is the intensity value or the luminosity value

00:02:23.220 --> 00:02:29.070
We're not looking at color although. You could do this three dimensions, but normally people [just] look at it in

00:02:29.800 --> 00:02:37.649
Grayscale values, so we're going to compare every neighbor of this center pixel with the center, and if it's greater than or

00:02:38.560 --> 00:02:39.750
equal to the Center

00:02:39.750 --> 00:02:45.899
We will assign a [1] and if it's smaller than that will assign a zero so 12 is bigger than 8

00:02:45.900 --> 00:02:52.020
So that's a 1 15 is bigger 1 18 is bigger 3 is smaller than 8 as is 2 and?

00:02:52.390 --> 00:02:55.800
[1/8] is equal to 8 so that's a 1 again and 5 is smaller

00:02:55.800 --> 00:02:57.800
And then we're going to turn these 8

00:02:58.090 --> 00:03:05.640
bits basically because they can only have a 1 or a 0 value you're going to turn those into one byte 1 1 1

00:03:06.040 --> 00:03:08.040
0 0 0

00:03:08.860 --> 00:03:16.380
1 0 as long as we're consistent we can turn any ordering of these numbers into one

00:03:16.930 --> 00:03:19.739
String of numbers which we then turn into a decimal number

00:03:20.260 --> 00:03:26.999
Which we will be using to train our system the nice thing about these local binary patterns is

00:03:27.489 --> 00:03:29.489
That it is

00:03:29.890 --> 00:03:32.309
illumination Invariant if you change

00:03:32.739 --> 00:03:37.679
The lighting on the scene all these pixel values will go up

00:03:37.680 --> 00:03:41.820
But the relative difference [between] the pixels will remain the same

00:03:42.730 --> 00:03:47.009
32 will still be bigger than 28, so your binary Pattern will remain the same

00:03:48.700 --> 00:03:54.450
Irrespective of illumination variation in general, so that's a shadow now as long as we're talking about

00:03:55.180 --> 00:03:59.820
Constant you do get aberrations. You do get difficult situations at

00:04:00.430 --> 00:04:02.580
The point where you have a cast shadow

00:04:02.860 --> 00:04:08.580
But I'm only at the location of that cast shadow because we're usually looking at [3X3] pixels

00:04:08.680 --> 00:04:13.680
this is not a big problem because what we're now going to do is we're going to take a face and

00:04:14.680 --> 00:04:20.970
It's our big smiley face think I'd be better in drawing faces by now after 10 years of working this area

00:04:20.970 --> 00:04:22.970
But I'm not we're going to divide

00:04:23.260 --> 00:04:25.260
this area into a

00:04:25.600 --> 00:04:26.800
number

00:04:26.800 --> 00:04:30.370
of blocks the [moment] [I'm] choosing 4x4 and

00:04:31.580 --> 00:04:36.490
this local binary pattern it's centered on a single pixel and then compares with its neighbors, so

00:04:36.590 --> 00:04:43.539
Basically we have to do this for every pixel in this block and each of those will result in a different

00:04:43.970 --> 00:04:51.159
decimal number for this block here you might get values of 2 3 4 2 8 8

00:04:51.830 --> 00:04:58.060
13 12 ETC, and if there's enough pixels in that block if the block is big enough

00:04:58.099 --> 00:05:04.539
We will actually turn these values into a histogram so basically looking at the statistics

00:05:04.599 --> 00:05:11.109
How many times did 13 come up? How many times did 12 come up because there's only 256 different values in?

00:05:11.659 --> 00:05:19.479
this block you actually get quite robust statistics in practice we use something what's called uniform local binary patterns and

00:05:20.030 --> 00:05:22.030
They only have 59 different

00:05:22.969 --> 00:05:28.749
Possible values rather than 256 so you get really quite robust statistics the other thing that

00:05:29.330 --> 00:05:34.359
Local binary Patterns and code is edges as I said we're interested in Edge

00:05:34.909 --> 00:05:39.129
detectors in the Edges that Sort of show you the outline of

00:05:39.740 --> 00:05:41.479
the mouth or the

00:05:41.479 --> 00:05:43.479
Eyelid and as you can see

00:05:43.849 --> 00:05:45.620
Here you've got three ones

00:05:45.620 --> 00:05:51.279
then a set of zeros and one and a zero basically what that means is that you have a

00:05:51.740 --> 00:05:56.440
Transition here from a [1] to a [0] you've got a transition here from 0 to 1

00:05:56.779 --> 00:05:59.139
from 1 to 0 again f of 0 1 those

00:05:59.719 --> 00:06:02.979
Transitions are edges so we now very clearly

00:06:03.560 --> 00:06:06.729
indicate where you've got a transition from A

00:06:07.069 --> 00:06:10.209
Light area in the face to a dark area in the face

00:06:10.370 --> 00:06:16.690
Which is exactly what an edge is so we've turned a possibly very high dimensional

00:06:17.120 --> 00:06:23.829
Space [that] was based purely on pixel intensities into a low dimensional space that only

00:06:24.289 --> 00:06:26.289
encodes relative

00:06:26.659 --> 00:06:28.778
intensity values and in doing so

00:06:29.419 --> 00:06:36.669
Encodes edges so we now have got an illumination invariant descriptor of Edges when you think about it

00:06:37.460 --> 00:06:42.930
Facial expression recognition is actually action Detection. You're not necessarily

00:06:43.240 --> 00:06:46.350
[you're] not really interested in the static smile

00:06:46.509 --> 00:06:52.379
You're interested in the fact that I'm you know went from a neutral face to smiling. So you're looking at differences

00:06:52.380 --> 00:06:57.779
You're looking at actions movements and all these descriptors the appearance descriptors

00:06:57.780 --> 00:07:02.489
They only describe the edges in one frame [its] static

00:07:02.680 --> 00:07:09.989
So what you really want to do is you want [to] see how these [pixels] change over time one way of doing that is

00:07:10.330 --> 00:07:15.090
you could actually extend this block to become a cube and

00:07:15.910 --> 00:07:17.800
you would get

00:07:17.800 --> 00:07:21.120
comparisons between the center of that Cube

00:07:22.210 --> 00:07:27.570
Somewhere down there and all its neighbors you would have to ^

00:07:28.449 --> 00:07:31.799
26 different Possible by values

00:07:32.320 --> 00:07:35.129
And that's just saying that as it goes back into 3D

00:07:35.130 --> 00:07:42.570
That's time communities exactly, so if we're now going to look at not at a single frame, but at a set of frames

00:07:42.570 --> 00:07:48.659
Let's say three frames, so then this is our y direction. This is our

00:07:49.510 --> 00:07:51.510
x direction this is our

00:07:51.820 --> 00:07:56.459
Horizontal and vertical space, it's just a normal image, and then this is time

00:07:57.070 --> 00:08:01.260
Basically saying that this is the first frame. That's the second frame

00:08:01.260 --> 00:08:07.829
And that's your third frame you can now look at the differences not just within [one] frame between the Central pixel

00:08:07.830 --> 00:08:10.169
but also the difference between this pixel and

00:08:11.080 --> 00:08:14.849
The pixel at the same location in the next frame or the pixel

00:08:15.400 --> 00:08:22.409
In the next frame, but a little bit up you should get a cube of pixels around this central pixel 9 in front

00:08:22.960 --> 00:08:26.699
9 in Back and 8 surrounding it in the in the current frame

00:08:27.400 --> 00:08:30.060
That's a total of 26 different neighbors

00:08:30.159 --> 00:08:37.619
So you get 2 to the power of 26 different possible values, and that's a lot instead you can do a little trick, so

00:08:38.140 --> 00:08:43.079
you can say I'm still interested in the changes over time but

00:08:43.719 --> 00:08:50.099
[it] might not be interested in just every possible change. I just want to look at 3 or token all planes

00:08:50.100 --> 00:08:52.560
That's it called the first

00:08:53.139 --> 00:08:59.219
Orthogonal plane of course being just the xy your normal image, and then you take a slice through

00:08:59.560 --> 00:09:02.669
X and t so there's a horizontal slice

00:09:02.670 --> 00:09:04.209
and you take a

00:09:04.209 --> 00:09:10.828
Slice through the vertical and time, so that's a vertical slice there that one is orthogonal to

00:09:11.560 --> 00:09:14.399
The x and t and of course it's orthogonal

00:09:15.370 --> 00:09:16.839
to the

00:09:16.839 --> 00:09:22.768
Normal xy plane, so [that's] why it's called three orthogonal planes in each of the network codes either

00:09:23.380 --> 00:09:24.760
Edges in

00:09:24.760 --> 00:09:28.469
Space in just your normal 2d image or an edge in

00:09:29.199 --> 00:09:33.509
x and time or an edge in one in time and if you do this

00:09:34.089 --> 00:09:38.939
You get 3 times 2 to the power of 8 solutions?

00:09:38.940 --> 00:09:42.359
Which is a lot smaller than 2 to the power of 26?

00:09:42.360 --> 00:09:47.339
and you still perfectly encode movements actions of edges over time and

00:09:48.190 --> 00:09:51.269
If you do this, you will get significant performance increases

00:09:55.460 --> 00:10:01.210
Illegal patterns get their own code and all the illegal

00:10:02.540 --> 00:10:06.309
Patterns get meshed together into the 59th

