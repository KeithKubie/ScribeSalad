WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:03.460
So what I'd like to do is actually step
through a concrete counterexample that

00:00:03.460 --> 00:00:07.250
really does show that a particular
way of doing this kind of training

00:00:07.250 --> 00:00:12.430
can fail in the worst case and this
is an example due to Lehman Baird and

00:00:12.430 --> 00:00:15.365
it's devious and clever.

00:00:15.365 --> 00:00:17.065
&gt;&gt; Hm, I like devious and clever.

00:00:17.065 --> 00:00:18.245
&gt;&gt; So here's a really simple MDP.

00:00:18.245 --> 00:00:19.045
You ready?

00:00:19.045 --> 00:00:22.335
It's got six states and
then a seventh absorbing state.

00:00:22.335 --> 00:00:23.185
&gt;&gt; Okay.
&gt;&gt; For each state,

00:00:23.185 --> 00:00:24.655
there's exactly one action.

00:00:24.655 --> 00:00:26.365
There's no stochasticity.

00:00:26.365 --> 00:00:28.255
There's no rewards of any kind.

00:00:28.255 --> 00:00:29.205
They're all zero.

00:00:29.205 --> 00:00:31.405
So this is a really simple example,
right?

00:00:31.405 --> 00:00:33.695
&gt;&gt; Sure,
that seems pretty straightforward.

00:00:33.695 --> 00:00:37.215
&gt;&gt; All right, so then what is the
optimal value function and policy for

00:00:37.215 --> 00:00:38.700
this example?

00:00:38.700 --> 00:00:41.400
&gt;&gt; The optimal value function or
optimal policy?

00:00:41.400 --> 00:00:42.260
&gt;&gt; I asked for both.

00:00:42.260 --> 00:00:44.590
&gt;&gt; There is no optimal policy,
it doesn't matter what you do.

00:00:44.590 --> 00:00:46.130
You just have to do one thing.

00:00:46.130 --> 00:00:49.720
&gt;&gt; There's only one policy and
it is optimal by definition of optimal.

00:00:49.720 --> 00:00:54.490
&gt;&gt; In the value function, the proper
value function would be zero everywhere.

00:00:54.490 --> 00:00:56.360
&gt;&gt; Zero's everywhere, right,

00:00:56.360 --> 00:00:59.510
because there's no
&gt;&gt; Rewards anywhere.

00:00:59.510 --> 00:01:02.200
So right so
this is super duper simple and

00:01:02.200 --> 00:01:03.590
if we had to learn this
using Q learning or

00:01:03.590 --> 00:01:07.020
something like that presumably this
would actually learn quite quickly.

00:01:07.020 --> 00:01:09.960
What we're going to do though
to make life difficult

00:01:09.960 --> 00:01:12.490
is we're going to do this in
a function approximation setting,

00:01:12.490 --> 00:01:16.545
linear function approximation with
this following set of features.

00:01:16.545 --> 00:01:20.210
So, there's there's the seven states
in the picture and associated with each

00:01:20.210 --> 00:01:24.280
state is a feature vector and there's
eight features that are part of that.

00:01:25.310 --> 00:01:29.110
Feature zero one, two, three, four,
five, six, seven, feature zero

00:01:29.110 --> 00:01:33.890
is one for all the states and seven for
this for the repeating state.

00:01:33.890 --> 00:01:36.110
And interestingly, we have it set up so

00:01:36.110 --> 00:01:40.330
that these other features are actually
completely indicative of which states

00:01:40.330 --> 00:01:44.680
you're in, so
state one has feature one being true.

00:01:44.680 --> 00:01:46.965
State two has feature two being true.

00:01:46.965 --> 00:01:49.125
State three has feature
three being true.

00:01:49.125 --> 00:01:49.630
Or at least.

00:01:49.630 --> 00:01:51.695
[LAUGH] And by true I mean two.

00:01:51.695 --> 00:01:52.245
I guess.

00:01:52.245 --> 00:01:53.335
&gt;&gt; Two.

00:01:53.335 --> 00:01:53.975
Yeah.
&gt;&gt; And so

00:01:53.975 --> 00:01:56.415
that's kind of the representation here.

00:01:56.415 --> 00:01:58.055
So state six looks like one.

00:01:58.055 --> 00:01:59.045
And then zeros is everywhere.

00:01:59.045 --> 00:02:02.577
Except for feature six which has a 2 and
then a 0, right?

00:02:02.577 --> 00:02:06.247
So this feature representation is
actually really close to being

00:02:06.247 --> 00:02:06.972
just a table.

00:02:06.972 --> 00:02:07.707
&gt;&gt; Yeah.

00:02:07.707 --> 00:02:10.937
&gt;&gt; So I'm going to say near tabular
in the sense that if we get rid of

00:02:10.937 --> 00:02:14.767
this first feature there's going to be
one weight that represents the value for

00:02:14.767 --> 00:02:18.410
state one and one weight that
represents a value for state two and so

00:02:18.410 --> 00:02:21.230
forth and one weight that represent
the value for state seven and so

00:02:21.230 --> 00:02:22.860
it's exactly just a table.

00:02:22.860 --> 00:02:26.010
One weight or one table entry per state.

00:02:26.010 --> 00:02:26.610
&gt;&gt; All right.

00:02:26.610 --> 00:02:31.080
&gt;&gt; And all we've done is kind of made it
a little bit more by having this extra

00:02:31.080 --> 00:02:33.810
feature that we ought to be
able to just ignore, right.

00:02:33.810 --> 00:02:35.710
And we should be able to
represent things pretty well.

00:02:35.710 --> 00:02:38.030
So in fact,
I think that it's worth asking.

00:02:38.030 --> 00:02:41.460
Can we represent the optimal
value function using this

00:02:41.460 --> 00:02:42.390
set of weights right?

00:02:42.390 --> 00:02:46.690
So if our parameters are W0 through W7,
is there a way to set them so

00:02:46.690 --> 00:02:51.240
that the value function that we get is
the actual value function for this MDP?

00:02:51.240 --> 00:02:52.266
&gt;&gt; Sure there is one easy one.

00:02:52.266 --> 00:02:53.050
&gt;&gt; And what's that?

00:02:53.050 --> 00:02:54.000
&gt;&gt; Set them all to zero.

00:02:54.000 --> 00:02:54.500
&gt;&gt; Right.

