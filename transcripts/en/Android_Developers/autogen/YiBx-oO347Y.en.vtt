WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.880
 
hi everyone my name is Rishi and one of

00:00:01.880 --> 00:00:01.890
hi everyone my name is Rishi and one of
 

00:00:01.890 --> 00:00:04.400
hi everyone my name is Rishi and one of
the engineering directors in the Android

00:00:04.400 --> 00:00:04.410
the engineering directors in the Android
 

00:00:04.410 --> 00:00:07.550
the engineering directors in the Android
and and the Play teams I honestly feel

00:00:07.550 --> 00:00:07.560
and and the Play teams I honestly feel
 

00:00:07.560 --> 00:00:09.169
and and the Play teams I honestly feel
like I lucked into one of the coolest

00:00:09.169 --> 00:00:09.179
like I lucked into one of the coolest
 

00:00:09.179 --> 00:00:11.330
like I lucked into one of the coolest
jobs at Google and there's a lot of

00:00:11.330 --> 00:00:11.340
jobs at Google and there's a lot of
 

00:00:11.340 --> 00:00:13.120
jobs at Google and there's a lot of
activity going on in the space I

00:00:13.120 --> 00:00:13.130
activity going on in the space I
 

00:00:13.130 --> 00:00:15.650
activity going on in the space I
promised myself a beer every time

00:00:15.650 --> 00:00:15.660
promised myself a beer every time
 

00:00:15.660 --> 00:00:17.650
promised myself a beer every time
someone mentioned AI or machine learning

00:00:17.650 --> 00:00:17.660
someone mentioned AI or machine learning
 

00:00:17.660 --> 00:00:19.910
someone mentioned AI or machine learning
and it seems like at the end of the day

00:00:19.910 --> 00:00:19.920
and it seems like at the end of the day
 

00:00:19.920 --> 00:00:21.710
and it seems like at the end of the day
I'm going to be very very drunk at the

00:00:21.710 --> 00:00:21.720
I'm going to be very very drunk at the
 

00:00:21.720 --> 00:00:25.540
I'm going to be very very drunk at the
rate of things things are going today so

00:00:25.540 --> 00:00:25.550
rate of things things are going today so
 

00:00:25.550 --> 00:00:27.950
rate of things things are going today so
it's no secret that if you've been

00:00:27.950 --> 00:00:27.960
it's no secret that if you've been
 

00:00:27.960 --> 00:00:30.320
it's no secret that if you've been
following our narrative in the last

00:00:30.320 --> 00:00:30.330
following our narrative in the last
 

00:00:30.330 --> 00:00:32.330
following our narrative in the last
couple of iOS a few Hardware

00:00:32.330 --> 00:00:32.340
couple of iOS a few Hardware
 

00:00:32.340 --> 00:00:35.750
couple of iOS a few Hardware
announcements that Google's heavily

00:00:35.750 --> 00:00:35.760
announcements that Google's heavily
 

00:00:35.760 --> 00:00:38.060
announcements that Google's heavily
banking on AI and machine learning is

00:00:38.060 --> 00:00:38.070
banking on AI and machine learning is
 

00:00:38.070 --> 00:00:39.979
banking on AI and machine learning is
one of the core pillars of a product

00:00:39.979 --> 00:00:39.989
one of the core pillars of a product
 

00:00:39.989 --> 00:00:43.970
one of the core pillars of a product
development and and there is a reason

00:00:43.970 --> 00:00:43.980
development and and there is a reason
 

00:00:43.980 --> 00:00:44.450
development and and there is a reason
for that

00:00:44.450 --> 00:00:44.460
for that
 

00:00:44.460 --> 00:00:46.670
for that
you have heard our CEO mentioned before

00:00:46.670 --> 00:00:46.680
you have heard our CEO mentioned before
 

00:00:46.680 --> 00:00:48.380
you have heard our CEO mentioned before
that we used to be a mobile first

00:00:48.380 --> 00:00:48.390
that we used to be a mobile first
 

00:00:48.390 --> 00:00:51.380
that we used to be a mobile first
company and now we are an AI first

00:00:51.380 --> 00:00:51.390
company and now we are an AI first
 

00:00:51.390 --> 00:00:52.939
company and now we are an AI first
company and I wanted to give you some

00:00:52.939 --> 00:00:52.949
company and I wanted to give you some
 

00:00:52.949 --> 00:00:56.450
company and I wanted to give you some
context into how we evolved into that

00:00:56.450 --> 00:00:56.460
context into how we evolved into that
 

00:00:56.460 --> 00:00:59.750
context into how we evolved into that
vision so come to think about it in

00:00:59.750 --> 00:00:59.760
vision so come to think about it in
 

00:00:59.760 --> 00:01:03.590
vision so come to think about it in
retrospect it is easy to to imagine what

00:01:03.590 --> 00:01:03.600
retrospect it is easy to to imagine what
 

00:01:03.600 --> 00:01:05.870
retrospect it is easy to to imagine what
it meant to be a mobile first product a

00:01:05.870 --> 00:01:05.880
it meant to be a mobile first product a
 

00:01:05.880 --> 00:01:08.060
it meant to be a mobile first product a
mobile first product that it is a

00:01:08.060 --> 00:01:08.070
mobile first product that it is a
 

00:01:08.070 --> 00:01:09.620
mobile first product that it is a
product that is fundamentally designed

00:01:09.620 --> 00:01:09.630
product that is fundamentally designed
 

00:01:09.630 --> 00:01:12.649
product that is fundamentally designed
for a small screen it is fundamentally

00:01:12.649 --> 00:01:12.659
for a small screen it is fundamentally
 

00:01:12.659 --> 00:01:15.230
for a small screen it is fundamentally
designed for a for a product that has

00:01:15.230 --> 00:01:15.240
designed for a for a product that has
 

00:01:15.240 --> 00:01:17.330
designed for a for a product that has
always on connectivity it is

00:01:17.330 --> 00:01:17.340
always on connectivity it is
 

00:01:17.340 --> 00:01:19.460
always on connectivity it is
fundamentally designed for low power

00:01:19.460 --> 00:01:19.470
fundamentally designed for low power
 

00:01:19.470 --> 00:01:24.020
fundamentally designed for low power
usage and so on and so forth so we

00:01:24.020 --> 00:01:24.030
usage and so on and so forth so we
 

00:01:24.030 --> 00:01:27.560
usage and so on and so forth so we
believe that products of tomorrow will

00:01:27.560 --> 00:01:27.570
believe that products of tomorrow will
 

00:01:27.570 --> 00:01:30.560
believe that products of tomorrow will
will take some of these other things for

00:01:30.560 --> 00:01:30.570
will take some of these other things for
 

00:01:30.570 --> 00:01:31.130
will take some of these other things for
granted

00:01:31.130 --> 00:01:31.140
granted
 

00:01:31.140 --> 00:01:33.890
granted
so products of today for example it's

00:01:33.890 --> 00:01:33.900
so products of today for example it's
 

00:01:33.900 --> 00:01:36.080
so products of today for example it's
hard to imagine an app that is not

00:01:36.080 --> 00:01:36.090
hard to imagine an app that is not
 

00:01:36.090 --> 00:01:38.870
hard to imagine an app that is not
designed with some of the principles I

00:01:38.870 --> 00:01:38.880
designed with some of the principles I
 

00:01:38.880 --> 00:01:40.550
designed with some of the principles I
mentioned in the mobile first column

00:01:40.550 --> 00:01:40.560
mentioned in the mobile first column
 

00:01:40.560 --> 00:01:43.100
mentioned in the mobile first column
five years down I think products are

00:01:43.100 --> 00:01:43.110
five years down I think products are
 

00:01:43.110 --> 00:01:44.840
five years down I think products are
tomorrow will have to have some of these

00:01:44.840 --> 00:01:44.850
tomorrow will have to have some of these
 

00:01:44.850 --> 00:01:47.539
tomorrow will have to have some of these
other columns other factors in the AI

00:01:47.539 --> 00:01:47.549
other columns other factors in the AI
 

00:01:47.549 --> 00:01:50.630
other columns other factors in the AI
first column so products of tomorrow we

00:01:50.630 --> 00:01:50.640
first column so products of tomorrow we
 

00:01:50.640 --> 00:01:53.630
first column so products of tomorrow we
believe will be required to learn and

00:01:53.630 --> 00:01:53.640
believe will be required to learn and
 

00:01:53.640 --> 00:01:55.609
believe will be required to learn and
adapt will be expected to learn and

00:01:55.609 --> 00:01:55.619
adapt will be expected to learn and
 

00:01:55.619 --> 00:01:57.649
adapt will be expected to learn and
adapt from from user behavior

00:01:57.649 --> 00:01:57.659
adapt from from user behavior
 

00:01:57.659 --> 00:01:59.569
adapt from from user behavior
we believe that products of tomorrow

00:01:59.569 --> 00:01:59.579
we believe that products of tomorrow
 

00:01:59.579 --> 00:02:04.090
we believe that products of tomorrow
should assist the user in their

00:02:04.090 --> 00:02:04.100
should assist the user in their
 

00:02:04.100 --> 00:02:07.210
should assist the user in their
in a day better we believe that products

00:02:07.210 --> 00:02:07.220
in a day better we believe that products
 

00:02:07.220 --> 00:02:09.370
in a day better we believe that products
of tomorrow should be conversational and

00:02:09.370 --> 00:02:09.380
of tomorrow should be conversational and
 

00:02:09.380 --> 00:02:12.550
of tomorrow should be conversational and
assistant so products of tomorrow should

00:02:12.550 --> 00:02:12.560
assistant so products of tomorrow should
 

00:02:12.560 --> 00:02:15.280
assistant so products of tomorrow should
be able to figure out if they don't know

00:02:15.280 --> 00:02:15.290
be able to figure out if they don't know
 

00:02:15.290 --> 00:02:16.839
be able to figure out if they don't know
anything and they should be able to ask

00:02:16.839 --> 00:02:16.849
anything and they should be able to ask
 

00:02:16.849 --> 00:02:19.380
anything and they should be able to ask
the user for the right information

00:02:19.380 --> 00:02:19.390
the user for the right information
 

00:02:19.390 --> 00:02:21.790
the user for the right information
products of tomorrow should also be

00:02:21.790 --> 00:02:21.800
products of tomorrow should also be
 

00:02:21.800 --> 00:02:24.160
products of tomorrow should also be
context aware they should be aware of

00:02:24.160 --> 00:02:24.170
context aware they should be aware of
 

00:02:24.170 --> 00:02:25.750
context aware they should be aware of
the state of the environment they should

00:02:25.750 --> 00:02:25.760
the state of the environment they should
 

00:02:25.760 --> 00:02:27.490
the state of the environment they should
be aware of the state of the user and

00:02:27.490 --> 00:02:27.500
be aware of the state of the user and
 

00:02:27.500 --> 00:02:29.440
be aware of the state of the user and
they should be using that information to

00:02:29.440 --> 00:02:29.450
they should be using that information to
 

00:02:29.450 --> 00:02:32.500
they should be using that information to
make that product better and last but

00:02:32.500 --> 00:02:32.510
make that product better and last but
 

00:02:32.510 --> 00:02:34.089
make that product better and last but
not the least products of tomorrow

00:02:34.089 --> 00:02:34.099
not the least products of tomorrow
 

00:02:34.099 --> 00:02:36.190
not the least products of tomorrow
should be trustworthy in a fundamental

00:02:36.190 --> 00:02:36.200
should be trustworthy in a fundamental
 

00:02:36.200 --> 00:02:38.350
should be trustworthy in a fundamental
way and that's not just about safety

00:02:38.350 --> 00:02:38.360
way and that's not just about safety
 

00:02:38.360 --> 00:02:41.500
way and that's not just about safety
security and privacy but also being able

00:02:41.500 --> 00:02:41.510
security and privacy but also being able
 

00:02:41.510 --> 00:02:44.110
security and privacy but also being able
to deliver performance that is reliable

00:02:44.110 --> 00:02:44.120
to deliver performance that is reliable
 

00:02:44.120 --> 00:02:48.520
to deliver performance that is reliable
on day one and undo it day hundred so

00:02:48.520 --> 00:02:48.530
on day one and undo it day hundred so
 

00:02:48.530 --> 00:02:50.530
on day one and undo it day hundred so
with that in mind machine learning is a

00:02:50.530 --> 00:02:50.540
with that in mind machine learning is a
 

00:02:50.540 --> 00:02:52.840
with that in mind machine learning is a
fundamental set of algorithms that help

00:02:52.840 --> 00:02:52.850
fundamental set of algorithms that help
 

00:02:52.850 --> 00:02:56.289
fundamental set of algorithms that help
our products and our platforms get

00:02:56.289 --> 00:02:56.299
our products and our platforms get
 

00:02:56.299 --> 00:02:59.410
our products and our platforms get
closer to that vision I see here on this

00:02:59.410 --> 00:02:59.420
closer to that vision I see here on this
 

00:02:59.420 --> 00:03:00.850
closer to that vision I see here on this
slide that machine learning is the

00:03:00.850 --> 00:03:00.860
slide that machine learning is the
 

00:03:00.860 --> 00:03:03.550
slide that machine learning is the
science and the art of making machines

00:03:03.550 --> 00:03:03.560
science and the art of making machines
 

00:03:03.560 --> 00:03:05.890
science and the art of making machines
learn your product shouldn't just be

00:03:05.890 --> 00:03:05.900
learn your product shouldn't just be
 

00:03:05.900 --> 00:03:08.259
learn your product shouldn't just be
great on day one but should be even

00:03:08.259 --> 00:03:08.269
great on day one but should be even
 

00:03:08.269 --> 00:03:10.180
great on day one but should be even
better on day hundred and machine

00:03:10.180 --> 00:03:10.190
better on day hundred and machine
 

00:03:10.190 --> 00:03:13.930
better on day hundred and machine
learning will help you get there so as a

00:03:13.930 --> 00:03:13.940
learning will help you get there so as a
 

00:03:13.940 --> 00:03:16.900
learning will help you get there so as a
running example I picked a picton app

00:03:16.900 --> 00:03:16.910
running example I picked a picton app
 

00:03:16.910 --> 00:03:19.930
running example I picked a picton app
that a hypothetical app that will take a

00:03:19.930 --> 00:03:19.940
that a hypothetical app that will take a
 

00:03:19.940 --> 00:03:22.390
that a hypothetical app that will take a
picture of an animal and lets you

00:03:22.390 --> 00:03:22.400
picture of an animal and lets you
 

00:03:22.400 --> 00:03:26.770
picture of an animal and lets you
classify it as a dog or a cat and in in

00:03:26.770 --> 00:03:26.780
classify it as a dog or a cat and in in
 

00:03:26.780 --> 00:03:29.050
classify it as a dog or a cat and in in
the world of yesterday you would develop

00:03:29.050 --> 00:03:29.060
the world of yesterday you would develop
 

00:03:29.060 --> 00:03:31.330
the world of yesterday you would develop
this system by designing a bunch of

00:03:31.330 --> 00:03:31.340
this system by designing a bunch of
 

00:03:31.340 --> 00:03:33.759
this system by designing a bunch of
heuristics based on human knowledge of

00:03:33.759 --> 00:03:33.769
heuristics based on human knowledge of
 

00:03:33.769 --> 00:03:36.220
heuristics based on human knowledge of
what separates a dog and a cat and you

00:03:36.220 --> 00:03:36.230
what separates a dog and a cat and you
 

00:03:36.230 --> 00:03:38.199
what separates a dog and a cat and you
would just encode that knowledge in a

00:03:38.199 --> 00:03:38.209
would just encode that knowledge in a
 

00:03:38.209 --> 00:03:42.759
would just encode that knowledge in a
bunch of rules but real world is much

00:03:42.759 --> 00:03:42.769
bunch of rules but real world is much
 

00:03:42.769 --> 00:03:44.770
bunch of rules but real world is much
messier than that and very unpredictable

00:03:44.770 --> 00:03:44.780
messier than that and very unpredictable
 

00:03:44.780 --> 00:03:47.559
messier than that and very unpredictable
so your sort of rules might work for ten

00:03:47.559 --> 00:03:47.569
so your sort of rules might work for ten
 

00:03:47.569 --> 00:03:49.210
so your sort of rules might work for ten
images twenty images a hundred images

00:03:49.210 --> 00:03:49.220
images twenty images a hundred images
 

00:03:49.220 --> 00:03:52.270
images twenty images a hundred images
but as I as you start to gather hundreds

00:03:52.270 --> 00:03:52.280
but as I as you start to gather hundreds
 

00:03:52.280 --> 00:03:53.979
but as I as you start to gather hundreds
of thousands of images all kinds of

00:03:53.979 --> 00:03:53.989
of thousands of images all kinds of
 

00:03:53.989 --> 00:03:56.949
of thousands of images all kinds of
corners cases pile up and it becomes

00:03:56.949 --> 00:03:56.959
corners cases pile up and it becomes
 

00:03:56.959 --> 00:03:58.750
corners cases pile up and it becomes
really hard and intractable for a

00:03:58.750 --> 00:03:58.760
really hard and intractable for a
 

00:03:58.760 --> 00:04:01.990
really hard and intractable for a
rule-based system to evolve so before I

00:04:01.990 --> 00:04:02.000
rule-based system to evolve so before I
 

00:04:02.000 --> 00:04:04.300
rule-based system to evolve so before I
think this took this new gig on Iran

00:04:04.300 --> 00:04:04.310
think this took this new gig on Iran
 

00:04:04.310 --> 00:04:06.039
think this took this new gig on Iran
searching discovery for the Playstore

00:04:06.039 --> 00:04:06.049
searching discovery for the Playstore
 

00:04:06.049 --> 00:04:08.680
searching discovery for the Playstore
for four years and even our abscess tag

00:04:08.680 --> 00:04:08.690
for four years and even our abscess tag
 

00:04:08.690 --> 00:04:11.920
for four years and even our abscess tag
started with a rule based way and as our

00:04:11.920 --> 00:04:11.930
started with a rule based way and as our
 

00:04:11.930 --> 00:04:14.949
started with a rule based way and as our
product started to grow it became harder

00:04:14.949 --> 00:04:14.959
product started to grow it became harder
 

00:04:14.959 --> 00:04:16.240
product started to grow it became harder
and harder to

00:04:16.240 --> 00:04:16.250
and harder to
 

00:04:16.250 --> 00:04:19.449
and harder to
over time and so machine learning comes

00:04:19.449 --> 00:04:19.459
over time and so machine learning comes
 

00:04:19.459 --> 00:04:22.390
over time and so machine learning comes
to the rescue so compared to rule based

00:04:22.390 --> 00:04:22.400
to the rescue so compared to rule based
 

00:04:22.400 --> 00:04:24.490
to the rescue so compared to rule based
systems machine learning systems take a

00:04:24.490 --> 00:04:24.500
systems machine learning systems take a
 

00:04:24.500 --> 00:04:26.740
systems machine learning systems take a
completely different approach to solving

00:04:26.740 --> 00:04:26.750
completely different approach to solving
 

00:04:26.750 --> 00:04:28.900
completely different approach to solving
some of the same problems so here I show

00:04:28.900 --> 00:04:28.910
some of the same problems so here I show
 

00:04:28.910 --> 00:04:31.420
some of the same problems so here I show
a simple schematic of something called a

00:04:31.420 --> 00:04:31.430
a simple schematic of something called a
 

00:04:31.430 --> 00:04:33.250
a simple schematic of something called a
neural network it's called a neural

00:04:33.250 --> 00:04:33.260
neural network it's called a neural
 

00:04:33.260 --> 00:04:35.440
neural network it's called a neural
network because it mimics the processing

00:04:35.440 --> 00:04:35.450
network because it mimics the processing
 

00:04:35.450 --> 00:04:38.920
network because it mimics the processing
our brain and and try to achieve it with

00:04:38.920 --> 00:04:38.930
our brain and and try to achieve it with
 

00:04:38.930 --> 00:04:42.130
our brain and and try to achieve it with
software systems so the way this works

00:04:42.130 --> 00:04:42.140
software systems so the way this works
 

00:04:42.140 --> 00:04:45.880
software systems so the way this works
is given a picture and given millions of

00:04:45.880 --> 00:04:45.890
is given a picture and given millions of
 

00:04:45.890 --> 00:04:48.460
is given a picture and given millions of
such pictures it will take the pixels of

00:04:48.460 --> 00:04:48.470
such pictures it will take the pixels of
 

00:04:48.470 --> 00:04:50.470
such pictures it will take the pixels of
that picture and then follow through

00:04:50.470 --> 00:04:50.480
that picture and then follow through
 

00:04:50.480 --> 00:04:53.620
that picture and then follow through
with layers of computation computation

00:04:53.620 --> 00:04:53.630
with layers of computation computation
 

00:04:53.630 --> 00:04:55.330
with layers of computation computation
to allow us to predict at the end

00:04:55.330 --> 00:04:55.340
to allow us to predict at the end
 

00:04:55.340 --> 00:04:58.870
to allow us to predict at the end
whether it was a cat or a dog it doesn't

00:04:58.870 --> 00:04:58.880
whether it was a cat or a dog it doesn't
 

00:04:58.880 --> 00:05:01.420
whether it was a cat or a dog it doesn't
start with hard-coded set of rules that

00:05:01.420 --> 00:05:01.430
start with hard-coded set of rules that
 

00:05:01.430 --> 00:05:03.909
start with hard-coded set of rules that
embed our knowledge about cats and dogs

00:05:03.909 --> 00:05:03.919
embed our knowledge about cats and dogs
 

00:05:03.919 --> 00:05:06.970
embed our knowledge about cats and dogs
he said it learns or relies on millions

00:05:06.970 --> 00:05:06.980
he said it learns or relies on millions
 

00:05:06.980 --> 00:05:09.610
he said it learns or relies on millions
of samples and data and with every

00:05:09.610 --> 00:05:09.620
of samples and data and with every
 

00:05:09.620 --> 00:05:11.860
of samples and data and with every
sample it gets better and better and

00:05:11.860 --> 00:05:11.870
sample it gets better and better and
 

00:05:11.870 --> 00:05:16.630
sample it gets better and better and
better at doing doing their job so back

00:05:16.630 --> 00:05:16.640
better at doing doing their job so back
 

00:05:16.640 --> 00:05:20.950
better at doing doing their job so back
in 2001 a 2011 on some of the standard

00:05:20.950 --> 00:05:20.960
in 2001 a 2011 on some of the standard
 

00:05:20.960 --> 00:05:23.020
in 2001 a 2011 on some of the standard
data sets around computer vision around

00:05:23.020 --> 00:05:23.030
data sets around computer vision around
 

00:05:23.030 --> 00:05:25.810
data sets around computer vision around
recognizing objects in images we had

00:05:25.810 --> 00:05:25.820
recognizing objects in images we had
 

00:05:25.820 --> 00:05:28.990
recognizing objects in images we had
around 26 percent error rate compared

00:05:28.990 --> 00:05:29.000
around 26 percent error rate compared
 

00:05:29.000 --> 00:05:31.750
around 26 percent error rate compared
that to error rate with humans about 5

00:05:31.750 --> 00:05:31.760
that to error rate with humans about 5
 

00:05:31.760 --> 00:05:34.120
that to error rate with humans about 5
percent so you could imagine that at

00:05:34.120 --> 00:05:34.130
percent so you could imagine that at
 

00:05:34.130 --> 00:05:37.030
percent so you could imagine that at
that time we would be lucky if we could

00:05:37.030 --> 00:05:37.040
that time we would be lucky if we could
 

00:05:37.040 --> 00:05:38.920
that time we would be lucky if we could
classify a picture as indoor versus

00:05:38.920 --> 00:05:38.930
classify a picture as indoor versus
 

00:05:38.930 --> 00:05:41.130
classify a picture as indoor versus
outdoor but we weren't too good at

00:05:41.130 --> 00:05:41.140
outdoor but we weren't too good at
 

00:05:41.140 --> 00:05:43.540
outdoor but we weren't too good at
reliably recognizing what's in the

00:05:43.540 --> 00:05:43.550
reliably recognizing what's in the
 

00:05:43.550 --> 00:05:47.500
reliably recognizing what's in the
picture so today these systems based on

00:05:47.500 --> 00:05:47.510
picture so today these systems based on
 

00:05:47.510 --> 00:05:49.330
picture so today these systems based on
deep neural networks are even better

00:05:49.330 --> 00:05:49.340
deep neural networks are even better
 

00:05:49.340 --> 00:05:51.520
deep neural networks are even better
than human level performance it's a

00:05:51.520 --> 00:05:51.530
than human level performance it's a
 

00:05:51.530 --> 00:05:53.460
than human level performance it's a
three percent error rate and

00:05:53.460 --> 00:05:53.470
three percent error rate and
 

00:05:53.470 --> 00:05:55.600
three percent error rate and
perceptually it feels like we are now

00:05:55.600 --> 00:05:55.610
perceptually it feels like we are now
 

00:05:55.610 --> 00:05:58.300
perceptually it feels like we are now
able to see the world through machines

00:05:58.300 --> 00:05:58.310
able to see the world through machines
 

00:05:58.310 --> 00:06:01.150
able to see the world through machines
and that enables a whole lot of other

00:06:01.150 --> 00:06:01.160
and that enables a whole lot of other
 

00:06:01.160 --> 00:06:02.770
and that enables a whole lot of other
things other cool things we could do

00:06:02.770 --> 00:06:02.780
things other cool things we could do
 

00:06:02.780 --> 00:06:06.130
things other cool things we could do
with software systems it is not just

00:06:06.130 --> 00:06:06.140
with software systems it is not just
 

00:06:06.140 --> 00:06:08.409
with software systems it is not just
about labeling pictures is a cat or a

00:06:08.409 --> 00:06:08.419
about labeling pictures is a cat or a
 

00:06:08.419 --> 00:06:11.350
about labeling pictures is a cat or a
dog but we can automatically caption

00:06:11.350 --> 00:06:11.360
dog but we can automatically caption
 

00:06:11.360 --> 00:06:14.230
dog but we can automatically caption
them it's really human sounding captions

00:06:14.230 --> 00:06:14.240
them it's really human sounding captions
 

00:06:14.240 --> 00:06:16.840
them it's really human sounding captions
so I show some of the examples here the

00:06:16.840 --> 00:06:16.850
so I show some of the examples here the
 

00:06:16.850 --> 00:06:18.640
so I show some of the examples here the
left-hand side table picture says a

00:06:18.640 --> 00:06:18.650
left-hand side table picture says a
 

00:06:18.650 --> 00:06:21.520
left-hand side table picture says a
close-up of a child holding a stuffed

00:06:21.520 --> 00:06:21.530
close-up of a child holding a stuffed
 

00:06:21.530 --> 00:06:24.400
close-up of a child holding a stuffed
animal so if you think about it there

00:06:24.400 --> 00:06:24.410
animal so if you think about it there
 

00:06:24.410 --> 00:06:26.380
animal so if you think about it there
are many primitives that goes

00:06:26.380 --> 00:06:26.390
are many primitives that goes
 

00:06:26.390 --> 00:06:28.630
are many primitives that goes
to a label like that we not only detect

00:06:28.630 --> 00:06:28.640
to a label like that we not only detect
 

00:06:28.640 --> 00:06:31.600
to a label like that we not only detect
that there is a young child and a

00:06:31.600 --> 00:06:31.610
that there is a young child and a
 

00:06:31.610 --> 00:06:33.580
that there is a young child and a
stuffed animal in the picture we detect

00:06:33.580 --> 00:06:33.590
stuffed animal in the picture we detect
 

00:06:33.590 --> 00:06:36.220
stuffed animal in the picture we detect
that the child is holding the the animal

00:06:36.220 --> 00:06:36.230
that the child is holding the the animal
 

00:06:36.230 --> 00:06:38.290
that the child is holding the the animal
and that it's a close-up so there are

00:06:38.290 --> 00:06:38.300
and that it's a close-up so there are
 

00:06:38.300 --> 00:06:40.480
and that it's a close-up so there are
multiple layers of intelligence built

00:06:40.480 --> 00:06:40.490
multiple layers of intelligence built
 

00:06:40.490 --> 00:06:43.900
multiple layers of intelligence built
into a caption like that there are many

00:06:43.900 --> 00:06:43.910
into a caption like that there are many
 

00:06:43.910 --> 00:06:45.730
into a caption like that there are many
you know cool examples here let's really

00:06:45.730 --> 00:06:45.740
you know cool examples here let's really
 

00:06:45.740 --> 00:06:48.010
you know cool examples here let's really
showcase how the technology has evolved

00:06:48.010 --> 00:06:48.020
showcase how the technology has evolved
 

00:06:48.020 --> 00:06:50.980
showcase how the technology has evolved
over time this scientist in me would

00:06:50.980 --> 00:06:50.990
over time this scientist in me would
 

00:06:50.990 --> 00:06:53.680
over time this scientist in me would
cringe if I hadn't put even a single

00:06:53.680 --> 00:06:53.690
cringe if I hadn't put even a single
 

00:06:53.690 --> 00:06:56.140
cringe if I hadn't put even a single
example of a mislabel you can see that

00:06:56.140 --> 00:06:56.150
example of a mislabel you can see that
 

00:06:56.150 --> 00:06:59.080
example of a mislabel you can see that
the bottom row says a man flying through

00:06:59.080 --> 00:06:59.090
the bottom row says a man flying through
 

00:06:59.090 --> 00:07:01.390
the bottom row says a man flying through
the air riding a snowboard and it's

00:07:01.390 --> 00:07:01.400
the air riding a snowboard and it's
 

00:07:01.400 --> 00:07:03.820
the air riding a snowboard and it's
clearly not that so AI systems today are

00:07:03.820 --> 00:07:03.830
clearly not that so AI systems today are
 

00:07:03.830 --> 00:07:05.950
clearly not that so AI systems today are
much better well compared to where they

00:07:05.950 --> 00:07:05.960
much better well compared to where they
 

00:07:05.960 --> 00:07:07.480
much better well compared to where they
used to be but they're still not perfect

00:07:07.480 --> 00:07:07.490
used to be but they're still not perfect
 

00:07:07.490 --> 00:07:10.750
used to be but they're still not perfect
and any product you design with AI in

00:07:10.750 --> 00:07:10.760
and any product you design with AI in
 

00:07:10.760 --> 00:07:14.110
and any product you design with AI in
mind has to be aware of that so the

00:07:14.110 --> 00:07:14.120
mind has to be aware of that so the
 

00:07:14.120 --> 00:07:16.000
mind has to be aware of that so the
types of problems Americans saw like I

00:07:16.000 --> 00:07:16.010
types of problems Americans saw like I
 

00:07:16.010 --> 00:07:18.340
types of problems Americans saw like I
want to give you a quick flavor for the

00:07:18.340 --> 00:07:18.350
want to give you a quick flavor for the
 

00:07:18.350 --> 00:07:20.200
want to give you a quick flavor for the
types of use cases you might be able to

00:07:20.200 --> 00:07:20.210
types of use cases you might be able to
 

00:07:20.210 --> 00:07:23.980
types of use cases you might be able to
power with ml and AI so the first

00:07:23.980 --> 00:07:23.990
power with ml and AI so the first
 

00:07:23.990 --> 00:07:25.750
power with ml and AI so the first
example is classification and it's

00:07:25.750 --> 00:07:25.760
example is classification and it's
 

00:07:25.760 --> 00:07:27.940
example is classification and it's
similar to what I showed before into a

00:07:27.940 --> 00:07:27.950
similar to what I showed before into a
 

00:07:27.950 --> 00:07:30.490
similar to what I showed before into a
picture label it as a cat or a dog take

00:07:30.490 --> 00:07:30.500
picture label it as a cat or a dog take
 

00:07:30.500 --> 00:07:33.010
picture label it as a cat or a dog take
a song label it as a pop song or a rock

00:07:33.010 --> 00:07:33.020
a song label it as a pop song or a rock
 

00:07:33.020 --> 00:07:35.980
a song label it as a pop song or a rock
song or take a nap and label it as a

00:07:35.980 --> 00:07:35.990
song or take a nap and label it as a
 

00:07:35.990 --> 00:07:38.500
song or take a nap and label it as a
harmful app or not these are some of the

00:07:38.500 --> 00:07:38.510
harmful app or not these are some of the
 

00:07:38.510 --> 00:07:42.070
harmful app or not these are some of the
examples of of classification take an

00:07:42.070 --> 00:07:42.080
examples of of classification take an
 

00:07:42.080 --> 00:07:46.500
examples of of classification take an
item and label it within a namespace

00:07:46.500 --> 00:07:46.510
item and label it within a namespace
 

00:07:46.510 --> 00:07:49.240
item and label it within a namespace
another example is prediction so here I

00:07:49.240 --> 00:07:49.250
another example is prediction so here I
 

00:07:49.250 --> 00:07:53.470
another example is prediction so here I
show YouTube next recommendations for

00:07:53.470 --> 00:07:53.480
show YouTube next recommendations for
 

00:07:53.480 --> 00:07:55.480
show YouTube next recommendations for
videos to watch if you watch this video

00:07:55.480 --> 00:07:55.490
videos to watch if you watch this video
 

00:07:55.490 --> 00:07:57.850
videos to watch if you watch this video
so machine learning systems are getting

00:07:57.850 --> 00:07:57.860
so machine learning systems are getting
 

00:07:57.860 --> 00:08:00.400
so machine learning systems are getting
really really better at predicting user

00:08:00.400 --> 00:08:00.410
really really better at predicting user
 

00:08:00.410 --> 00:08:03.670
really really better at predicting user
activity if you watch this video given

00:08:03.670 --> 00:08:03.680
activity if you watch this video given
 

00:08:03.680 --> 00:08:05.440
activity if you watch this video given
the knowledge of other users who have

00:08:05.440 --> 00:08:05.450
the knowledge of other users who have
 

00:08:05.450 --> 00:08:07.090
the knowledge of other users who have
watched the same video before are you

00:08:07.090 --> 00:08:07.100
watched the same video before are you
 

00:08:07.100 --> 00:08:09.400
watched the same video before are you
able to reliably predict which app

00:08:09.400 --> 00:08:09.410
able to reliably predict which app
 

00:08:09.410 --> 00:08:10.960
able to reliably predict which app
they're gonna which video they're gonna

00:08:10.960 --> 00:08:10.970
they're gonna which video they're gonna
 

00:08:10.970 --> 00:08:17.140
they're gonna which video they're gonna
use next and the third example sorry how

00:08:17.140 --> 00:08:17.150
use next and the third example sorry how
 

00:08:17.150 --> 00:08:20.760
use next and the third example sorry how
do I go back yeah is it's perception so

00:08:20.760 --> 00:08:20.770
do I go back yeah is it's perception so
 

00:08:20.770 --> 00:08:23.110
do I go back yeah is it's perception so
machine learning systems are getting

00:08:23.110 --> 00:08:23.120
machine learning systems are getting
 

00:08:23.120 --> 00:08:24.730
machine learning systems are getting
better at not just labeling and

00:08:24.730 --> 00:08:24.740
better at not just labeling and
 

00:08:24.740 --> 00:08:26.830
better at not just labeling and
predicting but also being able to

00:08:26.830 --> 00:08:26.840
predicting but also being able to
 

00:08:26.840 --> 00:08:29.260
predicting but also being able to
understand the world through images

00:08:29.260 --> 00:08:29.270
understand the world through images
 

00:08:29.270 --> 00:08:31.300
understand the world through images
through sound through audio and -

00:08:31.300 --> 00:08:31.310
through sound through audio and -
 

00:08:31.310 --> 00:08:33.969
through sound through audio and -
natural language processing here I show

00:08:33.969 --> 00:08:33.979
natural language processing here I show
 

00:08:33.979 --> 00:08:35.980
natural language processing here I show
an example of assistant integration and

00:08:35.980 --> 00:08:35.990
an example of assistant integration and
 

00:08:35.990 --> 00:08:36.490
an example of assistant integration and
I know

00:08:36.490 --> 00:08:36.500
I know
 

00:08:36.500 --> 00:08:38.140
I know
you'll be hearing about that through the

00:08:38.140 --> 00:08:38.150
you'll be hearing about that through the
 

00:08:38.150 --> 00:08:41.409
you'll be hearing about that through the
day so few examples of where Google's

00:08:41.409 --> 00:08:41.419
day so few examples of where Google's
 

00:08:41.419 --> 00:08:44.230
day so few examples of where Google's
used ml technology over the few years so

00:08:44.230 --> 00:08:44.240
used ml technology over the few years so
 

00:08:44.240 --> 00:08:46.720
used ml technology over the few years so
Google has a wide array of products some

00:08:46.720 --> 00:08:46.730
Google has a wide array of products some
 

00:08:46.730 --> 00:08:49.900
Google has a wide array of products some
of these products 7a products are used

00:08:49.900 --> 00:08:49.910
of these products 7a products are used
 

00:08:49.910 --> 00:08:52.300
of these products 7a products are used
by billion plus monthly active users a

00:08:52.300 --> 00:08:52.310
by billion plus monthly active users a
 

00:08:52.310 --> 00:08:54.820
by billion plus monthly active users a
day and many of them fundamentally used

00:08:54.820 --> 00:08:54.830
day and many of them fundamentally used
 

00:08:54.830 --> 00:08:58.480
day and many of them fundamentally used
machine learning an example here is

00:08:58.480 --> 00:08:58.490
machine learning an example here is
 

00:08:58.490 --> 00:09:01.240
machine learning an example here is
google lens this is one of the you know

00:09:01.240 --> 00:09:01.250
google lens this is one of the you know
 

00:09:01.250 --> 00:09:03.580
google lens this is one of the you know
the recent examples of machine learning

00:09:03.580 --> 00:09:03.590
the recent examples of machine learning
 

00:09:03.590 --> 00:09:04.990
the recent examples of machine learning
has fundamentally changed the way

00:09:04.990 --> 00:09:05.000
has fundamentally changed the way
 

00:09:05.000 --> 00:09:08.380
has fundamentally changed the way
products behave today so you are able to

00:09:08.380 --> 00:09:08.390
products behave today so you are able to
 

00:09:08.390 --> 00:09:11.320
products behave today so you are able to
not only detect landmarks but are able

00:09:11.320 --> 00:09:11.330
not only detect landmarks but are able
 

00:09:11.330 --> 00:09:13.300
not only detect landmarks but are able
to do that in real time in the

00:09:13.300 --> 00:09:13.310
to do that in real time in the
 

00:09:13.310 --> 00:09:16.800
to do that in real time in the
viewfinder of the camera and in perceive

00:09:16.800 --> 00:09:16.810
viewfinder of the camera and in perceive
 

00:09:16.810 --> 00:09:20.310
viewfinder of the camera and in perceive
the real-time imagery through machines

00:09:20.310 --> 00:09:20.320
the real-time imagery through machines
 

00:09:20.320 --> 00:09:22.830
the real-time imagery through machines
next example is machine learn

00:09:22.830 --> 00:09:22.840
next example is machine learn
 

00:09:22.840 --> 00:09:26.410
next example is machine learn
recommendations Kobe mentioned that ml

00:09:26.410 --> 00:09:26.420
recommendations Kobe mentioned that ml
 

00:09:26.420 --> 00:09:28.510
recommendations Kobe mentioned that ml
is used heavily for recommendations on

00:09:28.510 --> 00:09:28.520
is used heavily for recommendations on
 

00:09:28.520 --> 00:09:29.140
is used heavily for recommendations on
the app store

00:09:29.140 --> 00:09:29.150
the app store
 

00:09:29.150 --> 00:09:32.260
the app store
here I show example from YouTube so

00:09:32.260 --> 00:09:32.270
here I show example from YouTube so
 

00:09:32.270 --> 00:09:34.620
here I show example from YouTube so
given your video watch history what

00:09:34.620 --> 00:09:34.630
given your video watch history what
 

00:09:34.630 --> 00:09:38.220
given your video watch history what
videos make the most sense for you

00:09:38.220 --> 00:09:38.230
videos make the most sense for you
 

00:09:38.230 --> 00:09:41.010
videos make the most sense for you
another example is Google Translate

00:09:41.010 --> 00:09:41.020
another example is Google Translate
 

00:09:41.020 --> 00:09:43.450
another example is Google Translate
where you can look at the picture in

00:09:43.450 --> 00:09:43.460
where you can look at the picture in
 

00:09:43.460 --> 00:09:45.640
where you can look at the picture in
real time detect not only the text in

00:09:45.640 --> 00:09:45.650
real time detect not only the text in
 

00:09:45.650 --> 00:09:47.680
real time detect not only the text in
the picture they take the language it's

00:09:47.680 --> 00:09:47.690
the picture they take the language it's
 

00:09:47.690 --> 00:09:50.200
the picture they take the language it's
in and able to recognize that all in

00:09:50.200 --> 00:09:50.210
in and able to recognize that all in
 

00:09:50.210 --> 00:09:52.110
in and able to recognize that all in
real time

00:09:52.110 --> 00:09:52.120
real time
 

00:09:52.120 --> 00:09:55.360
real time
another example is smart reply in Gmail

00:09:55.360 --> 00:09:55.370
another example is smart reply in Gmail
 

00:09:55.370 --> 00:09:58.360
another example is smart reply in Gmail
and inbox we can process the text of the

00:09:58.360 --> 00:09:58.370
and inbox we can process the text of the
 

00:09:58.370 --> 00:10:01.300
and inbox we can process the text of the
message and are able to predict what the

00:10:01.300 --> 00:10:01.310
message and are able to predict what the
 

00:10:01.310 --> 00:10:03.940
message and are able to predict what the
likely response is going to be so for

00:10:03.940 --> 00:10:03.950
likely response is going to be so for
 

00:10:03.950 --> 00:10:05.500
likely response is going to be so for
someone like me running from meeting to

00:10:05.500 --> 00:10:05.510
someone like me running from meeting to
 

00:10:05.510 --> 00:10:07.270
someone like me running from meeting to
meeting trying to respond to image

00:10:07.270 --> 00:10:07.280
meeting trying to respond to image
 

00:10:07.280 --> 00:10:10.630
meeting trying to respond to image
through messages on the staircase this

00:10:10.630 --> 00:10:10.640
through messages on the staircase this
 

00:10:10.640 --> 00:10:14.050
through messages on the staircase this
sort of feature is super useful and last

00:10:14.050 --> 00:10:14.060
sort of feature is super useful and last
 

00:10:14.060 --> 00:10:16.120
sort of feature is super useful and last
not but not the least this is an example

00:10:16.120 --> 00:10:16.130
not but not the least this is an example
 

00:10:16.130 --> 00:10:18.550
not but not the least this is an example
where it's not a user facing application

00:10:18.550 --> 00:10:18.560
where it's not a user facing application
 

00:10:18.560 --> 00:10:24.040
where it's not a user facing application
at all but our ability to to optimize

00:10:24.040 --> 00:10:24.050
at all but our ability to to optimize
 

00:10:24.050 --> 00:10:26.350
at all but our ability to to optimize
back-end processing in data centers

00:10:26.350 --> 00:10:26.360
back-end processing in data centers
 

00:10:26.360 --> 00:10:29.260
back-end processing in data centers
using deep mind AI from our office in

00:10:29.260 --> 00:10:29.270
using deep mind AI from our office in
 

00:10:29.270 --> 00:10:31.750
using deep mind AI from our office in
London we are able to reduce our power

00:10:31.750 --> 00:10:31.760
London we are able to reduce our power
 

00:10:31.760 --> 00:10:33.940
London we are able to reduce our power
usage in Google's data centers by up to

00:10:33.940 --> 00:10:33.950
usage in Google's data centers by up to
 

00:10:33.950 --> 00:10:40.329
usage in Google's data centers by up to
40% so Google not only builds some of

00:10:40.329 --> 00:10:40.339
40% so Google not only builds some of
 

00:10:40.339 --> 00:10:42.220
40% so Google not only builds some of
these products but we also have some of

00:10:42.220 --> 00:10:42.230
these products but we also have some of
 

00:10:42.230 --> 00:10:44.590
these products but we also have some of
the most used platforms in the world

00:10:44.590 --> 00:10:44.600
the most used platforms in the world
 

00:10:44.600 --> 00:10:47.170
the most used platforms in the world
today and it's not sufficient for our

00:10:47.170 --> 00:10:47.180
today and it's not sufficient for our
 

00:10:47.180 --> 00:10:49.170
today and it's not sufficient for our
own products to get better with

00:10:49.170 --> 00:10:49.180
own products to get better with
 

00:10:49.180 --> 00:10:52.170
own products to get better with
IML we also want to empower all of you

00:10:52.170 --> 00:10:52.180
IML we also want to empower all of you
 

00:10:52.180 --> 00:10:54.990
IML we also want to empower all of you
to use AI and ml in your own products as

00:10:54.990 --> 00:10:55.000
to use AI and ml in your own products as
 

00:10:55.000 --> 00:10:59.220
to use AI and ml in your own products as
well so to do that we open sourced some

00:10:59.220 --> 00:10:59.230
well so to do that we open sourced some
 

00:10:59.230 --> 00:11:01.290
well so to do that we open sourced some
of the fundamental parts of our ml stack

00:11:01.290 --> 00:11:01.300
of the fundamental parts of our ml stack
 

00:11:01.300 --> 00:11:02.280
of the fundamental parts of our ml stack
through tensorflow

00:11:02.280 --> 00:11:02.290
through tensorflow
 

00:11:02.290 --> 00:11:05.250
through tensorflow
a couple of years ago and this is a

00:11:05.250 --> 00:11:05.260
a couple of years ago and this is a
 

00:11:05.260 --> 00:11:07.650
a couple of years ago and this is a
repository in github that any one of you

00:11:07.650 --> 00:11:07.660
repository in github that any one of you
 

00:11:07.660 --> 00:11:10.980
repository in github that any one of you
can you know download and use it's

00:11:10.980 --> 00:11:10.990
can you know download and use it's
 

00:11:10.990 --> 00:11:13.080
can you know download and use it's
getting huge traction in the developer

00:11:13.080 --> 00:11:13.090
getting huge traction in the developer
 

00:11:13.090 --> 00:11:15.600
getting huge traction in the developer
community already just in two years this

00:11:15.600 --> 00:11:15.610
community already just in two years this
 

00:11:15.610 --> 00:11:18.480
community already just in two years this
graph shows the github stars for

00:11:18.480 --> 00:11:18.490
graph shows the github stars for
 

00:11:18.490 --> 00:11:20.220
graph shows the github stars for
tensorflow compared to other such

00:11:20.220 --> 00:11:20.230
tensorflow compared to other such
 

00:11:20.230 --> 00:11:22.530
tensorflow compared to other such
repositories out there and it had just

00:11:22.530 --> 00:11:22.540
repositories out there and it had just
 

00:11:22.540 --> 00:11:24.710
repositories out there and it had just
you know it's been exceedingly popular

00:11:24.710 --> 00:11:24.720
you know it's been exceedingly popular
 

00:11:24.720 --> 00:11:31.380
you know it's been exceedingly popular
and getting used more and more we are

00:11:31.380 --> 00:11:31.390
and getting used more and more we are
 

00:11:31.390 --> 00:11:33.030
and getting used more and more we are
not going to stop there though so

00:11:33.030 --> 00:11:33.040
not going to stop there though so
 

00:11:33.040 --> 00:11:33.780
not going to stop there though so
tensorflow

00:11:33.780 --> 00:11:33.790
tensorflow
 

00:11:33.790 --> 00:11:35.970
tensorflow
when it was open sourced a couple of

00:11:35.970 --> 00:11:35.980
when it was open sourced a couple of
 

00:11:35.980 --> 00:11:37.590
when it was open sourced a couple of
years ago it was fundamentally designed

00:11:37.590 --> 00:11:37.600
years ago it was fundamentally designed
 

00:11:37.600 --> 00:11:40.740
years ago it was fundamentally designed
for server use case and at i/o this year

00:11:40.740 --> 00:11:40.750
for server use case and at i/o this year
 

00:11:40.750 --> 00:11:42.420
for server use case and at i/o this year
we announced that we are taking it to

00:11:42.420 --> 00:11:42.430
we announced that we are taking it to
 

00:11:42.430 --> 00:11:45.060
we announced that we are taking it to
work on device so tensorflow Lite which

00:11:45.060 --> 00:11:45.070
work on device so tensorflow Lite which
 

00:11:45.070 --> 00:11:46.770
work on device so tensorflow Lite which
is going to be a fast and efficient

00:11:46.770 --> 00:11:46.780
is going to be a fast and efficient
 

00:11:46.780 --> 00:11:48.870
is going to be a fast and efficient
version a pencil flow going to be open

00:11:48.870 --> 00:11:48.880
version a pencil flow going to be open
 

00:11:48.880 --> 00:11:52.050
version a pencil flow going to be open
sourced this quarter will be instance of

00:11:52.050 --> 00:11:52.060
sourced this quarter will be instance of
 

00:11:52.060 --> 00:11:54.890
sourced this quarter will be instance of
tensorflow that runs on android devices

00:11:54.890 --> 00:11:54.900
tensorflow that runs on android devices
 

00:11:54.900 --> 00:11:58.560
tensorflow that runs on android devices
and last but not the least we are not

00:11:58.560 --> 00:11:58.570
and last but not the least we are not
 

00:11:58.570 --> 00:12:00.930
and last but not the least we are not
only making it possible for use to you

00:12:00.930 --> 00:12:00.940
only making it possible for use to you
 

00:12:00.940 --> 00:12:03.120
only making it possible for use to you
to use ml libraries but we are also

00:12:03.120 --> 00:12:03.130
to use ml libraries but we are also
 

00:12:03.130 --> 00:12:05.580
to use ml libraries but we are also
making it possible for you to directly

00:12:05.580 --> 00:12:05.590
making it possible for you to directly
 

00:12:05.590 --> 00:12:08.070
making it possible for you to directly
access Google's intelligent api's so

00:12:08.070 --> 00:12:08.080
access Google's intelligent api's so
 

00:12:08.080 --> 00:12:10.260
access Google's intelligent api's so
example here is detecting faces and

00:12:10.260 --> 00:12:10.270
example here is detecting faces and
 

00:12:10.270 --> 00:12:12.630
example here is detecting faces and
emotions in faces through Google's cloud

00:12:12.630 --> 00:12:12.640
emotions in faces through Google's cloud
 

00:12:12.640 --> 00:12:15.090
emotions in faces through Google's cloud
ml api's and some of the same api's are

00:12:15.090 --> 00:12:15.100
ml api's and some of the same api's are
 

00:12:15.100 --> 00:12:19.650
ml api's and some of the same api's are
available on device as well so that's it

00:12:19.650 --> 00:12:19.660
available on device as well so that's it
 

00:12:19.660 --> 00:12:21.690
available on device as well so that's it
I'll be available for taking some of the

00:12:21.690 --> 00:12:21.700
I'll be available for taking some of the
 

00:12:21.700 --> 00:12:23.190
I'll be available for taking some of the
questions later down the day and I know

00:12:23.190 --> 00:12:23.200
questions later down the day and I know
 

00:12:23.200 --> 00:12:26.280
questions later down the day and I know
we have a deeper dive on ml during the

00:12:26.280 --> 00:12:26.290
we have a deeper dive on ml during the
 

00:12:26.290 --> 00:12:35.180
we have a deeper dive on ml during the
day thank you

00:12:35.180 --> 00:12:35.190
 
 

00:12:35.190 --> 00:12:37.250
 
you

