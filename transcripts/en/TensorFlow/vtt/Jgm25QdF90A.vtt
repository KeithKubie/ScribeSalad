WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.630
[MUSIC PLAYING]

00:00:03.630 --> 00:00:05.830
BILL LUAN: Good
afternoon, everyone.

00:00:05.830 --> 00:00:09.300
Welcome to the Google I/O
session of Introducing Google

00:00:09.300 --> 00:00:10.650
Coral.

00:00:10.650 --> 00:00:12.030
My name is Bill Luan.

00:00:12.030 --> 00:00:15.690
I'm a program manager
at Google's Coral team.

00:00:15.690 --> 00:00:18.170
On behalf of all
my team members,

00:00:18.170 --> 00:00:20.910
warm welcome to
all of you and many

00:00:20.910 --> 00:00:23.560
of you watching online
around the world.

00:00:23.560 --> 00:00:26.320
Thank you for joining us.

00:00:26.320 --> 00:00:28.800
Before I start to talk
about the Coral product,

00:00:28.800 --> 00:00:31.080
let's take a quick
look at the industry

00:00:31.080 --> 00:00:33.750
trend, which
demonstrates to us why

00:00:33.750 --> 00:00:35.970
Coral will be important to us.

00:00:35.970 --> 00:00:39.540
The growth of the smart
devices and the so-called IoT--

00:00:39.540 --> 00:00:41.280
the internet of things--

00:00:41.280 --> 00:00:45.600
has grown tremendously over
the past number of years.

00:00:45.600 --> 00:00:49.260
And it represents one of the
biggest growth opportunity

00:00:49.260 --> 00:00:51.400
in the years to come.

00:00:51.400 --> 00:00:55.950
Per many industry trend
forecasts over the internet,

00:00:55.950 --> 00:00:58.860
such as this one
you can see, you

00:00:58.860 --> 00:01:01.020
can see many of those
similar on the internet.

00:01:01.020 --> 00:01:06.880
The growth of the non-IoT
devices, such as PCs, laptops,

00:01:06.880 --> 00:01:11.040
mobile phones, tablets, and
so on, in the next five to six

00:01:11.040 --> 00:01:15.930
years will grow from about
11 billion installed units

00:01:15.930 --> 00:01:20.540
globally to around 12 billion
over the next five to six years

00:01:20.540 --> 00:01:25.840
time span, representing
about 14% growth rate.

00:01:25.840 --> 00:01:29.850
However, the IoT smart
devices, the growth

00:01:29.850 --> 00:01:34.110
rate from the current install
base about 8 billion units

00:01:34.110 --> 00:01:38.790
worldwide will grow to 21
billion in the same period,

00:01:38.790 --> 00:01:44.820
representing a much larger
growth rate of more than 150%.

00:01:44.820 --> 00:01:48.870
So this really tells us
where the growth opportunity

00:01:48.870 --> 00:01:51.750
and opportunities for
innovation for all of us,

00:01:51.750 --> 00:01:56.760
for developers around the
world, where that lies ahead.

00:01:56.760 --> 00:02:01.360
Namely, they are in
the smart devices.

00:02:01.360 --> 00:02:04.320
So in the smart
devices users continue

00:02:04.320 --> 00:02:09.630
to grow the interest in smart
devices in terms of innovation,

00:02:09.630 --> 00:02:12.182
and the development
will continue to grow.

00:02:12.182 --> 00:02:13.640
There are several
key factors which

00:02:13.640 --> 00:02:18.130
will drive this trend
continue forward.

00:02:18.130 --> 00:02:20.350
Because number one,
due to the increase

00:02:20.350 --> 00:02:23.080
of the interest around
the world in terms of AI,

00:02:23.080 --> 00:02:25.240
machine learning,
the advancement

00:02:25.240 --> 00:02:28.760
of key research in
AI continues to grow

00:02:28.760 --> 00:02:30.570
over the last several years.

00:02:30.570 --> 00:02:33.050
In fact, the number
of research papers

00:02:33.050 --> 00:02:34.820
has published in
the last few years

00:02:34.820 --> 00:02:38.630
in machine learning is more than
the total number of such papers

00:02:38.630 --> 00:02:41.940
in the last decade combined.

00:02:41.940 --> 00:02:45.990
So more AI capabilities
will make the application

00:02:45.990 --> 00:02:48.840
of AI machine learning on
devices more practical,

00:02:48.840 --> 00:02:51.360
feasible, as machine
learning models become

00:02:51.360 --> 00:02:55.860
more accurate, faster,
performance better,

00:02:55.860 --> 00:02:59.680
industries will have an interest
to continue to use them.

00:02:59.680 --> 00:03:04.400
So as more devices at the
edge require machine learning,

00:03:04.400 --> 00:03:06.250
we really need to
have a solution

00:03:06.250 --> 00:03:10.000
to bring the machine learning
onto the device at the edge.

00:03:10.000 --> 00:03:12.790
We need a technology,
especially a hardware,

00:03:12.790 --> 00:03:16.090
to bring the machine learning
acceleration, that capability

00:03:16.090 --> 00:03:17.600
right on the device.

00:03:17.600 --> 00:03:21.940
So in a nutshell, smart
devices growth demands

00:03:21.940 --> 00:03:25.420
bring machine learning to
the edge to the device.

00:03:25.420 --> 00:03:28.280
And we need a solution for that.

00:03:28.280 --> 00:03:32.300
So let me introduce to you
what Google has made for you--

00:03:32.300 --> 00:03:34.160
for developers
around the world--

00:03:34.160 --> 00:03:39.880
to answer this industry demand
what will make that possible.

00:03:39.880 --> 00:03:42.610
Introducing Coral from Google.

00:03:42.610 --> 00:03:45.580
It is a new exciting
technology platform

00:03:45.580 --> 00:03:48.160
to enable developers
all around the world

00:03:48.160 --> 00:03:51.960
to build on-device machine
learning acceleration AI

00:03:51.960 --> 00:03:56.600
applications with ease
and with high efficiency.

00:03:56.600 --> 00:04:00.280
So with this introduction
session what you will learn

00:04:00.280 --> 00:04:03.580
is about what the Coral
product line offers.

00:04:03.580 --> 00:04:06.320
What are machine
learning capabilities

00:04:06.320 --> 00:04:10.450
you can build with the Coral
platform and the technology.

00:04:10.450 --> 00:04:14.320
And third, what are
the use cases in terms

00:04:14.320 --> 00:04:17.230
of deploying machine
learning with applications

00:04:17.230 --> 00:04:19.339
in a lot of industry use.

00:04:19.339 --> 00:04:22.270
So I'm going to go through all
these with my instruction here.

00:04:24.840 --> 00:04:28.280
Coral is designed as
a-- make it easier

00:04:28.280 --> 00:04:31.700
to bring machine
learning on the device,

00:04:31.700 --> 00:04:34.380
make it easier for you
to develop applications.

00:04:34.380 --> 00:04:40.040
It is a platform to make
prototyping tool production

00:04:40.040 --> 00:04:42.770
with high speed,
with efficiency.

00:04:42.770 --> 00:04:46.790
It is a platform to develop
on-device machine learning.

00:04:46.790 --> 00:04:52.580
It offers a group of components
of hardware components

00:04:52.580 --> 00:04:57.050
to bring unique high-performance
machine learning capability

00:04:57.050 --> 00:04:59.490
right onto the Edge devices.

00:04:59.490 --> 00:05:03.980
It also offers a complete
set of software tool change

00:05:03.980 --> 00:05:05.990
to enable you to
develop applications

00:05:05.990 --> 00:05:09.320
in AI machine
learning with ease.

00:05:09.320 --> 00:05:12.410
In addition to that,
Coral also offers a set

00:05:12.410 --> 00:05:15.140
of ready-to-be-used machine
learning models for you

00:05:15.140 --> 00:05:17.045
to quickly deploy onto devices.

00:05:19.800 --> 00:05:21.410
So a lot of you may curious.

00:05:21.410 --> 00:05:22.940
Why it is called Coral?

00:05:22.940 --> 00:05:25.520
How that has anything
to do with AI?

00:05:25.520 --> 00:05:28.940
Well, if you look at the nature
of coral in the natural world,

00:05:28.940 --> 00:05:32.870
coral really do represent
a community of vibrant,

00:05:32.870 --> 00:05:35.820
teeming with life, inclusive,
very open community.

00:05:35.820 --> 00:05:36.320
Right?

00:05:36.320 --> 00:05:38.870
The living organism
together, they're

00:05:38.870 --> 00:05:42.420
working together to
contribute to a common good.

00:05:42.420 --> 00:05:44.210
And that's exactly
what we inspire,

00:05:44.210 --> 00:05:47.730
want to make a platform for
the industry, for all of you.

00:05:50.350 --> 00:05:52.870
Coral's inspiration
and mission is

00:05:52.870 --> 00:05:57.760
to provide a vibrant
platform for all of you

00:05:57.760 --> 00:06:01.000
to collaborate and to
develop applications to bring

00:06:01.000 --> 00:06:03.990
AI applications to the device.

00:06:03.990 --> 00:06:06.900
We want to enable
developers everywhere

00:06:06.900 --> 00:06:10.290
to turning AI ideas to
business solutions from idea

00:06:10.290 --> 00:06:13.650
to prototyping to large
scale production deployment

00:06:13.650 --> 00:06:16.280
with ease and simplicity.

00:06:16.280 --> 00:06:19.640
And finally, we want to
encourage everybody joining

00:06:19.640 --> 00:06:24.500
a community-wide effort
to contribute and to learn

00:06:24.500 --> 00:06:27.470
and to share machine
learning models together.

00:06:27.470 --> 00:06:32.660
So that's where the name
of the Coral came from.

00:06:32.660 --> 00:06:36.800
So why do we want to talk about
the benefits of the machine

00:06:36.800 --> 00:06:38.353
learning on device?

00:06:38.353 --> 00:06:39.770
So let's take a
quick look at what

00:06:39.770 --> 00:06:41.770
are the key points
of machine learning

00:06:41.770 --> 00:06:43.920
on device in terms of benefits.

00:06:43.920 --> 00:06:47.120
Number one, it is a high
performance benefit.

00:06:47.120 --> 00:06:51.500
Because everything is
computed on the device right

00:06:51.500 --> 00:06:52.970
on the device locally there.

00:06:52.970 --> 00:06:56.120
You do not need to send
the data back to the cloud.

00:06:56.120 --> 00:06:56.900
Right?

00:06:56.900 --> 00:06:59.480
So high performance,
everything on the local

00:06:59.480 --> 00:07:03.010
allow you to do things
much more efficiently.

00:07:03.010 --> 00:07:06.540
Also it's very important-- very
key-- in many applications,

00:07:06.540 --> 00:07:09.670
you want the data to
stay on the device,

00:07:09.670 --> 00:07:13.230
especially in business
application scenarios.

00:07:13.230 --> 00:07:17.310
Some user privacy data
cannot be sent to a server,

00:07:17.310 --> 00:07:18.960
cannot be sent to the cloud.

00:07:18.960 --> 00:07:21.000
We want a technology
to enable you

00:07:21.000 --> 00:07:25.030
to make that solution
available to your customers.

00:07:25.030 --> 00:07:27.430
And also because
data stays local.

00:07:30.040 --> 00:07:33.030
All the information coming from
the sensors right on the device

00:07:33.030 --> 00:07:35.860
can be accessed
and used to compute

00:07:35.860 --> 00:07:38.200
for your machine learning
results right there, rather

00:07:38.200 --> 00:07:41.140
than you have to send the data
to the cloud, to the server,

00:07:41.140 --> 00:07:42.880
to compute and
send the data back.

00:07:42.880 --> 00:07:43.450
Right?

00:07:43.450 --> 00:07:44.992
So this is another
way to look at it.

00:07:44.992 --> 00:07:46.930
It's a much better performance.

00:07:46.930 --> 00:07:50.560
Because auditing every
data is locally available.

00:07:50.560 --> 00:07:52.000
Next is works offline.

00:07:52.000 --> 00:07:55.450
There's many scenarios--
the internet of things,

00:07:55.450 --> 00:07:56.860
the smart devices--

00:07:56.860 --> 00:07:59.380
they may or may not have
internet connection.

00:07:59.380 --> 00:08:03.367
In fact, in most cases they
don't have a cloud connection.

00:08:03.367 --> 00:08:05.200
So you still want to
have a machine learning

00:08:05.200 --> 00:08:07.240
capability in that scenario.

00:08:07.240 --> 00:08:10.960
And a offline on-device
machine learning capability

00:08:10.960 --> 00:08:13.640
will make that happen for you.

00:08:13.640 --> 00:08:17.080
And lastly, it is much
more power efficient.

00:08:17.080 --> 00:08:19.030
Lot of Edge devices are small.

00:08:19.030 --> 00:08:21.250
They don't have
large power supply.

00:08:21.250 --> 00:08:25.090
And they require high
efficiency in terms of computing

00:08:25.090 --> 00:08:26.683
computation on the device.

00:08:26.683 --> 00:08:29.100
Because you don't have to send
the data back to the cloud,

00:08:29.100 --> 00:08:31.720
and of course, you
save the bandwidth.

00:08:31.720 --> 00:08:36.970
You save the power to send the
data so use a Wi-Fi on network.

00:08:36.970 --> 00:08:38.830
So the benefits of
machine learning

00:08:38.830 --> 00:08:42.929
is very strong on-device,
machine learning very strong.

00:08:42.929 --> 00:08:45.880
So let's take a quick look
at the Coral product line.

00:08:45.880 --> 00:08:48.240
What do we offer
to the industry?

00:08:48.240 --> 00:08:51.180
Coral product line offers
both hardware components

00:08:51.180 --> 00:08:52.710
and software components.

00:08:52.710 --> 00:08:55.260
On the hardware side
it offers development

00:08:55.260 --> 00:08:58.350
on board, which is a single
border computer allow you

00:08:58.350 --> 00:09:01.350
to prototype developer
applications.

00:09:01.350 --> 00:09:04.530
Also, Coral offers
a number of sensors

00:09:04.530 --> 00:09:06.930
to allow you to build
applications using

00:09:06.930 --> 00:09:08.760
the sensory data in
terms of imaging,

00:09:08.760 --> 00:09:11.120
video, environmental
sensors, making

00:09:11.120 --> 00:09:13.590
those available as a
part of the input of data

00:09:13.590 --> 00:09:16.120
to your application.

00:09:16.120 --> 00:09:17.920
And also in the
software side, we

00:09:17.920 --> 00:09:21.400
provide a complete set
of software tool change

00:09:21.400 --> 00:09:25.390
from operating system
to SDK to machine

00:09:25.390 --> 00:09:28.600
learning modules allow you to
easily use them and quickly

00:09:28.600 --> 00:09:31.150
build your application.

00:09:31.150 --> 00:09:34.080
In addition to that, we provide
a detailed comprehensive set

00:09:34.080 --> 00:09:37.980
of contents in terms of
documentation, examples,

00:09:37.980 --> 00:09:40.420
online guide, data
Sheets, et cetera.

00:09:40.420 --> 00:09:43.860
All of those were made available
online at the Coral website

00:09:43.860 --> 00:09:46.560
to all of you.

00:09:46.560 --> 00:09:50.370
So now we know what to the
Coral product suite contains.

00:09:50.370 --> 00:09:52.560
Let's take a look
little bit more detail

00:09:52.560 --> 00:09:56.150
in terms of the
hardware components.

00:09:56.150 --> 00:09:57.600
So Coral hardware product.

00:09:57.600 --> 00:10:00.900
We offer a suite
of hardware to you

00:10:00.900 --> 00:10:03.730
in terms of prototyping and
developing applications.

00:10:03.730 --> 00:10:06.210
The first one is
called Coral Dev Board.

00:10:06.210 --> 00:10:08.640
As you can see on
the picture here,

00:10:08.640 --> 00:10:11.020
it retails for about $150.

00:10:11.020 --> 00:10:13.590
It's a single-board computer
with operating system

00:10:13.590 --> 00:10:17.920
on board and machine learning
capability right on the device.

00:10:17.920 --> 00:10:22.920
The second one is a USB key,
what we call USB accelerator.

00:10:22.920 --> 00:10:26.220
It has the Edge TPO machine
learning acceleration chip

00:10:26.220 --> 00:10:27.300
right on the device.

00:10:27.300 --> 00:10:30.090
You can put this USB
into any Linux machine

00:10:30.090 --> 00:10:32.670
and to be able to bring machine
learning capability right

00:10:32.670 --> 00:10:34.530
on to those devices.

00:10:34.530 --> 00:10:35.710
And I have those with me.

00:10:35.710 --> 00:10:38.460
And I want to show
you the relative size

00:10:38.460 --> 00:10:40.140
dimension of that.

00:10:40.140 --> 00:10:42.990
So this is the Coral Deb Board.

00:10:42.990 --> 00:10:45.100
It's very small, as you can see.

00:10:45.100 --> 00:10:47.250
It is a single board
computer with all

00:10:47.250 --> 00:10:51.450
the necessary input/output
of the connectors on that.

00:10:51.450 --> 00:10:54.030
This is the USB key,
it's even smaller.

00:10:54.030 --> 00:10:57.040
It's just typical to any
USB key you would use.

00:10:57.040 --> 00:11:00.420
So these are the two
current computer platforms

00:11:00.420 --> 00:11:03.970
you use to develop applications.

00:11:03.970 --> 00:11:07.230
In addition to that, we also
offer a couple of sensors,

00:11:07.230 --> 00:11:11.250
as I said, to take sensing data
from the field for your machine

00:11:11.250 --> 00:11:13.440
learning application to consume.

00:11:13.440 --> 00:11:16.830
Number one is a five-megapixel
autofocus camera,

00:11:16.830 --> 00:11:19.490
what we call a Coral camera.

00:11:19.490 --> 00:11:22.030
Second, we just
released a few days ago

00:11:22.030 --> 00:11:26.230
a new environmental sensor,
which is this one here.

00:11:26.230 --> 00:11:27.570
As you can see, very small.

00:11:27.570 --> 00:11:30.490
And it has a digital
display on that.

00:11:30.490 --> 00:11:34.330
It allow you to take the
input from temperature,

00:11:34.330 --> 00:11:37.620
humidity, and light and so on.

00:11:37.620 --> 00:11:40.200
These input sensors, you
can use that and build it

00:11:40.200 --> 00:11:41.520
for your applications.

00:11:41.520 --> 00:11:44.160
Now with these you
do the prototype.

00:11:44.160 --> 00:11:45.880
But when you deploy
these devices

00:11:45.880 --> 00:11:49.650
into largest scale
production environment,

00:11:49.650 --> 00:11:52.050
we allow you to enable
you to take the sun

00:11:52.050 --> 00:11:54.010
module from the Dev Board.

00:11:54.010 --> 00:11:57.630
In other words, this piece of
circuit board can snap off.

00:11:57.630 --> 00:11:59.590
You can embed into your product.

00:11:59.590 --> 00:12:02.940
And this is for volume
large scale deployment.

00:12:02.940 --> 00:12:07.200
And the individual unit price,
as you can see, for about $115.

00:12:07.200 --> 00:12:11.450
And we offer discount
for volume deployment.

00:12:11.450 --> 00:12:15.780
Very soon in the next quarter we
will offer a PCI-E connector--

00:12:15.780 --> 00:12:19.610
a base connector-- which you can
plug into any PC or industrial

00:12:19.610 --> 00:12:22.910
PC and industry devices
that accept a PCI-E

00:12:22.910 --> 00:12:25.880
connector to allow you to bring
machine learning capability

00:12:25.880 --> 00:12:29.150
into those devices.

00:12:29.150 --> 00:12:31.810
So those on the
left, are what you

00:12:31.810 --> 00:12:35.160
need to do prototyping for your
machine learning application.

00:12:35.160 --> 00:12:36.720
The one on the right--

00:12:36.720 --> 00:12:40.990
the one on the right is
for large scale deployment.

00:12:40.990 --> 00:12:44.140
Of course, the cameras and
environment of sensors,

00:12:44.140 --> 00:12:46.670
you could have used for both
prototyping and the larger

00:12:46.670 --> 00:12:51.210
scale deployment so
they stay in the middle.

00:12:51.210 --> 00:12:53.940
All right, let's talk
about the Google Edge TPU.

00:12:53.940 --> 00:12:56.680
This is the center-- the
core of this platform--

00:12:56.680 --> 00:13:00.090
bringing machine learning
capabilities onto the device.

00:13:00.090 --> 00:13:03.740
So the Edge TPU is a small,
application-specific circular

00:13:03.740 --> 00:13:06.690
chip that Google
designed specifically

00:13:06.690 --> 00:13:10.170
for optimizing machine
learning on the device.

00:13:10.170 --> 00:13:13.140
It is designed to
take TensorFlow Lite

00:13:13.140 --> 00:13:14.930
machine learning modules.

00:13:14.930 --> 00:13:19.155
And it supports 8-bit quantile
TensorFlow model and running

00:13:19.155 --> 00:13:22.130
on-device with a
high efficiency.

00:13:22.130 --> 00:13:24.730
It consumes only
two watts power.

00:13:24.730 --> 00:13:26.980
And it runs very fast.

00:13:26.980 --> 00:13:28.540
The picture you
see in the middle

00:13:28.540 --> 00:13:31.010
represents its relative
size to a penny.

00:13:31.010 --> 00:13:32.620
So it's a tiny chip.

00:13:32.620 --> 00:13:35.410
And with the same
module of this size,

00:13:35.410 --> 00:13:39.290
you can easily embed
into many, many devices.

00:13:39.290 --> 00:13:43.200
So how fast this Edge TPU goes?

00:13:43.200 --> 00:13:46.950
Well, in a general time,
what we publish online,

00:13:46.950 --> 00:13:50.070
the performance
speed of the Edge TPU

00:13:50.070 --> 00:13:55.000
runs computation at about four
trillion operations per second.

00:13:55.000 --> 00:13:59.070
So in general terms, it's
a Four TOPS, if you will.

00:13:59.070 --> 00:14:01.530
You may ask, well,
how fast it actually

00:14:01.530 --> 00:14:04.060
runs machine learning model?

00:14:04.060 --> 00:14:06.770
Take a look at this
comparison table.

00:14:06.770 --> 00:14:12.080
We benchmark couple of
very common mostly used

00:14:12.080 --> 00:14:16.880
vision machine learning models,
such as MobileNet, Inception.

00:14:16.880 --> 00:14:20.410
We're running the dev
board or the Edge TPU USB

00:14:20.410 --> 00:14:24.920
on both of these running against
powerful CPU or embedded CPU,

00:14:24.920 --> 00:14:29.710
powerful desktop CPU such
as the Xenon 64-bit CPU

00:14:29.710 --> 00:14:32.450
or the ARM CPU in
the embedded world.

00:14:32.450 --> 00:14:35.570
As you can see in this
table, in comparison,

00:14:35.570 --> 00:14:39.770
the machine learning capability
speed of the Edge TPU

00:14:39.770 --> 00:14:42.650
runs only a fraction
of the time necessary

00:14:42.650 --> 00:14:46.670
compared to the desktop
CPU and the embedded CPU.

00:14:46.670 --> 00:14:49.260
So it's much, much faster.

00:14:49.260 --> 00:14:50.780
Now some of you say, well, OK.

00:14:50.780 --> 00:14:52.460
These are just
benchmark numbers.

00:14:52.460 --> 00:14:53.460
Do you have an example--

00:14:53.460 --> 00:14:55.790
real world example--
you can show me?

00:14:55.790 --> 00:14:57.200
And I say yes.

00:14:57.200 --> 00:15:00.440
Let me borrow an example
from one of our beta users

00:15:00.440 --> 00:15:05.240
who posted this in our
Coral beta online forum.

00:15:05.240 --> 00:15:09.960
He said, I'm building an app
monitoring online traffic

00:15:09.960 --> 00:15:11.080
in real time.

00:15:11.080 --> 00:15:13.450
You know, watching
10, 20 cars real time.

00:15:13.450 --> 00:15:15.600
I just take the mobile
net out of the box

00:15:15.600 --> 00:15:17.300
without much tweaking.

00:15:17.300 --> 00:15:20.220
And I used the Coral
product, I being

00:15:20.220 --> 00:15:23.580
able to achieve about 48
frame per second performance.

00:15:23.580 --> 00:15:26.640
That is very comparable
to a 30 frame per second

00:15:26.640 --> 00:15:32.790
using a GTX 980 GPU plus
a CPU in similar gear.

00:15:32.790 --> 00:15:35.490
Now for those of you
who build game machines,

00:15:35.490 --> 00:15:39.090
you know to build
HTX 980 GPU plus CPU,

00:15:39.090 --> 00:15:43.960
you're talking about-- what?
$500 to $1,000 cost of gear.

00:15:43.960 --> 00:15:47.540
But with the Coral Dev
Board, it's only 150.

00:15:47.540 --> 00:15:50.230
You'll be able to
achieve the same results.

00:15:50.230 --> 00:15:55.050
So this really tells you
the cost and the performance

00:15:55.050 --> 00:15:56.890
advantage of the Coral product.

00:15:59.247 --> 00:16:01.580
So now let's talk about the
Dev Board a little bit more,

00:16:01.580 --> 00:16:03.470
since most of you
are engineers, you'll

00:16:03.470 --> 00:16:05.090
want to see the
technical spec of it.

00:16:05.090 --> 00:16:06.718
Let me go through a little bit.

00:16:06.718 --> 00:16:09.260
So first of all, the Dev Board,
as you can see in the picture

00:16:09.260 --> 00:16:13.550
or in my hand, it is a
prototype development board

00:16:13.550 --> 00:16:18.020
allow you to directly develop
on-board on-device machine

00:16:18.020 --> 00:16:20.810
learning capability
in applications.

00:16:20.810 --> 00:16:22.050
It's a full computer.

00:16:22.050 --> 00:16:23.360
It has the CPU.

00:16:23.360 --> 00:16:24.440
It has GPU.

00:16:24.440 --> 00:16:27.620
It has online memory, and
also runs a Linux operating

00:16:27.620 --> 00:16:31.300
system on this device.

00:16:31.300 --> 00:16:32.870
It uses a modular design--

00:16:32.870 --> 00:16:34.040
what do we call SOM--

00:16:34.040 --> 00:16:36.710
S-O-M-- system module
design, meaning again,

00:16:36.710 --> 00:16:39.740
you can snap off this
SOM circuit board

00:16:39.740 --> 00:16:42.040
and deploy into
your own product.

00:16:42.040 --> 00:16:46.460
By module design, make it easier
from prototype to deployment.

00:16:46.460 --> 00:16:49.190
It has many I/O
connectors allow you

00:16:49.190 --> 00:16:53.300
to connect to many accessories
during the development,

00:16:53.300 --> 00:16:56.350
make everything
really, really easy.

00:16:56.350 --> 00:16:58.770
So here's a picture
of the Dev Board.

00:16:58.770 --> 00:17:02.460
As you can see, it contains all
the necessary I/O ports for you

00:17:02.460 --> 00:17:06.960
to connect the two
devices, such as HDMI

00:17:06.960 --> 00:17:10.859
to connected to display;
USB connectors to connect

00:17:10.859 --> 00:17:14.380
the cameras, keyboard,
monitors, and so on;

00:17:14.380 --> 00:17:16.750
as well as ethernet connectors.

00:17:16.750 --> 00:17:19.829
It also, of course, has Wi-Fi
and Bluetooth to connect

00:17:19.829 --> 00:17:23.730
to internet through the Wi-Fi.

00:17:23.730 --> 00:17:24.230
OK.

00:17:24.230 --> 00:17:27.680
Let's talk a little bit
technical spec in detail.

00:17:27.680 --> 00:17:33.830
The CPU, it uses a NXP
quad-core on CPU chip.

00:17:33.830 --> 00:17:36.370
As you can see, the
product is very fast--

00:17:36.370 --> 00:17:40.700
853 is a very high
speed CPU chip.

00:17:40.700 --> 00:17:42.470
It also supported GPU.

00:17:42.470 --> 00:17:44.720
And it has a onboard
encrypted chip,

00:17:44.720 --> 00:17:48.430
allow you to securely
connect to Google cloud.

00:17:48.430 --> 00:17:54.530
It has a one-gig onboard RAM,
as well as 8-gig flash memory.

00:17:54.530 --> 00:17:57.140
So enough space for you to
deploy your application.

00:17:57.140 --> 00:18:00.560
It supports Wi-Fi, Bluetooth,
and takes a five volts

00:18:00.560 --> 00:18:02.930
standard power supply.

00:18:02.930 --> 00:18:06.590
In terms of connectors,
it supports both USB 2.0

00:18:06.590 --> 00:18:11.540
and USB 3.0 speed connections,
with support of both USB Type C

00:18:11.540 --> 00:18:14.500
and Type A connectors.

00:18:14.500 --> 00:18:18.610
Under audio and video
category, as you can see,

00:18:18.610 --> 00:18:22.210
it supports all the AV necessary
connections, especially

00:18:22.210 --> 00:18:30.080
the full size HDMI 2.0 connector
for a full 1080p video display.

00:18:30.080 --> 00:18:35.630
It has a micro SD card allow you
to bring more software onboard.

00:18:35.630 --> 00:18:38.060
Has a gigabyte network support.

00:18:38.060 --> 00:18:42.480
And it has a GPIO 40-pin
for I/O connection.

00:18:42.480 --> 00:18:45.750
It supports a special version
of the Debian Linux, what

00:18:45.750 --> 00:18:49.920
do we call Mendel, because it is
specialized to support Edge TPU

00:18:49.920 --> 00:18:51.510
functions.

00:18:51.510 --> 00:18:53.040
And the machine
learning models is

00:18:53.040 --> 00:18:56.640
supporting most of the common
vision machine learning models

00:18:56.640 --> 00:18:58.890
such as MobileNet,
Inception, which

00:18:58.890 --> 00:19:02.040
works great on small
devices, mobile devices.

00:19:05.040 --> 00:19:09.110
I want to talk about especially
this GPIO connection.

00:19:09.110 --> 00:19:11.360
For many of you who
are makers, you're

00:19:11.360 --> 00:19:14.690
used to making projects
using Raspberry Pi, right?

00:19:14.690 --> 00:19:18.530
Raspberry Pi has this
40-ping GPIO connector.

00:19:18.530 --> 00:19:19.900
With the Developer Board--

00:19:19.900 --> 00:19:23.250
Dev Board-- you can do
exactly the same thing.

00:19:23.250 --> 00:19:26.990
It's compatible to
Raspberry Pi 40-ping GPIO.

00:19:26.990 --> 00:19:29.090
So for all the things
you have done in the past

00:19:29.090 --> 00:19:34.790
connecting to external lights,
switches, using GPIO ports,

00:19:34.790 --> 00:19:37.820
or using the post width
modulation to control step

00:19:37.820 --> 00:19:42.110
motors, everything you've done
in the past with Raspberry Pi,

00:19:42.110 --> 00:19:47.300
you can do it with the Dev
Board very, very easily.

00:19:47.300 --> 00:19:49.760
So how do you use
Dev Board in terms

00:19:49.760 --> 00:19:51.620
of development and deployment?

00:19:51.620 --> 00:19:53.970
Conceptually it's very
easy, as I explained.

00:19:53.970 --> 00:19:57.500
I'm sure you're
already seeing this.

00:19:57.500 --> 00:19:59.930
So doing the prototyping,
you use the Dev Board

00:19:59.930 --> 00:20:01.520
to enable all these connectors.

00:20:01.520 --> 00:20:04.940
You can connect to switches,
sensors, temperature gauges,

00:20:04.940 --> 00:20:06.180
whatever you want.

00:20:06.180 --> 00:20:07.520
You can connect to a monitor.

00:20:07.520 --> 00:20:08.930
You can connect to a keyboard.

00:20:08.930 --> 00:20:11.450
You do development right there,
because its operating system

00:20:11.450 --> 00:20:13.640
ringing on the device.

00:20:13.640 --> 00:20:17.210
When you're done, you
take off the SOM module

00:20:17.210 --> 00:20:19.310
and unplug from the Dev Board.

00:20:19.310 --> 00:20:21.690
And you can buy many, many
SOM modules, as I said.

00:20:21.690 --> 00:20:22.190
Right?

00:20:22.190 --> 00:20:25.310
You can deploy the SOM
module into whatever product

00:20:25.310 --> 00:20:28.100
you are making, such as,
say, smart refrigerator,

00:20:28.100 --> 00:20:29.270
smart washing machine.

00:20:29.270 --> 00:20:31.880
Depends on the
application you develop.

00:20:31.880 --> 00:20:33.570
So this is really easy.

00:20:33.570 --> 00:20:38.880
It's prototyping and deployment
in one in a product package.

00:20:38.880 --> 00:20:39.990
OK?

00:20:39.990 --> 00:20:40.490
All right.

00:20:40.490 --> 00:20:41.573
We talked about Dev Board.

00:20:41.573 --> 00:20:43.800
Let me also touch briefly
the second product,

00:20:43.800 --> 00:20:47.000
which is the Coral
USB Accelerator, which

00:20:47.000 --> 00:20:49.370
is this little thing here.

00:20:49.370 --> 00:20:53.300
Again, it's a small
USB key you can

00:20:53.300 --> 00:20:59.460
plug into any USB slot
on any Linux machine.

00:20:59.460 --> 00:21:03.650
It has a onboard Edge TPU, bring
the machine learning capability

00:21:03.650 --> 00:21:06.050
right onto any
device you plug into.

00:21:06.050 --> 00:21:09.590
And also supports not only
the Debian Linux, but also

00:21:09.590 --> 00:21:11.870
the Raspberry Linux,
which is similar

00:21:11.870 --> 00:21:14.450
or the same way used
on Raspberry Pi.

00:21:14.450 --> 00:21:17.840
So you can plug this
and take this key

00:21:17.840 --> 00:21:20.150
and work with Raspberry Pi.

00:21:20.150 --> 00:21:22.910
So it opens up a bit
of more opportunities

00:21:22.910 --> 00:21:25.620
for you to do the development.

00:21:25.620 --> 00:21:27.800
So the Coral Accelerator
advantages, number one,

00:21:27.800 --> 00:21:30.620
as you would imagine, bring
on-device machine learning

00:21:30.620 --> 00:21:32.900
into many more machines.

00:21:32.900 --> 00:21:34.730
You can plug into a
laptop if you want,

00:21:34.730 --> 00:21:38.396
if the laptop runs
special version of Linux.

00:21:38.396 --> 00:21:41.420
And you can plug
into Raspberry Pi.

00:21:41.420 --> 00:21:43.480
It's compatible
with many hardware

00:21:43.480 --> 00:21:45.840
what the Raspberry Pi
supports in the past.

00:21:45.840 --> 00:21:49.550
So not only PCs, but
laptops, Raspberry Pi,

00:21:49.550 --> 00:21:50.900
and industrial systems.

00:21:50.900 --> 00:21:54.140
The [INAUDIBLE] box
supports a USB plug.

00:21:54.140 --> 00:21:56.090
You just plug this
key, and you will

00:21:56.090 --> 00:21:59.670
be able to deploy your
machine learning applications.

00:21:59.670 --> 00:22:04.700
So the Coral USB Accelerator
is a low-cost, convenient way

00:22:04.700 --> 00:22:08.340
to experiment in building
prototypes in AR.

00:22:08.340 --> 00:22:08.840
OK.

00:22:08.840 --> 00:22:10.280
So we talked about hardware.

00:22:10.280 --> 00:22:12.650
Let me also talk about
the software side--

00:22:12.650 --> 00:22:15.560
the complete suite of
toolchain that Coral

00:22:15.560 --> 00:22:18.650
provides to you to enable
you to do machine learning

00:22:18.650 --> 00:22:19.735
applications.

00:22:22.470 --> 00:22:25.500
So software components,
let's take a look

00:22:25.500 --> 00:22:29.370
from components level
what Coral software pieces

00:22:29.370 --> 00:22:31.180
and hardware work together.

00:22:31.180 --> 00:22:33.300
So on the Coral Dev
Board, not only Linux

00:22:33.300 --> 00:22:35.500
machine, if you will,
and to the bottom layer

00:22:35.500 --> 00:22:37.050
you have the hardware.

00:22:37.050 --> 00:22:40.950
And you have the Mendel
Linux running on top of that.

00:22:40.950 --> 00:22:44.520
They talk to the operating
system, talks to hardware.

00:22:44.520 --> 00:22:50.250
And Coral, we developed a
C/C++ library API direct access

00:22:50.250 --> 00:22:53.770
to the operating system
and the hardware.

00:22:53.770 --> 00:22:56.110
And so this allow you
to have direct access

00:22:56.110 --> 00:22:57.940
to everything the
operating system be

00:22:57.940 --> 00:23:00.320
able to control for you.

00:23:00.320 --> 00:23:03.320
Let's say you have a
machine learning model.

00:23:03.320 --> 00:23:04.430
It's a TensorFlow model--

00:23:04.430 --> 00:23:05.990
TensorFlow Lite model.

00:23:05.990 --> 00:23:10.790
We provide a Edge TPU
compiler allow you to compile,

00:23:10.790 --> 00:23:13.850
take a TensorFlow
Lite model, compiled

00:23:13.850 --> 00:23:18.620
into a binary format that is
compatible to the Edge TPU.

00:23:18.620 --> 00:23:26.060
So if you have an application,
you can access the C/C+ API

00:23:26.060 --> 00:23:28.940
and running the machine learning
model right on the device

00:23:28.940 --> 00:23:32.880
and access to the
layers of hardware.

00:23:32.880 --> 00:23:36.410
However, we realized that
many, many machine learning

00:23:36.410 --> 00:23:40.080
programmers, like you,
have been using Python.

00:23:40.080 --> 00:23:45.960
So Coral software also provide
a Python library, or Python SDK.

00:23:45.960 --> 00:23:48.480
It is a high level
wrapper allow you

00:23:48.480 --> 00:23:52.530
to using Python programming
language to easily access

00:23:52.530 --> 00:23:54.645
all the features I was
just talking about,

00:23:54.645 --> 00:23:56.520
be able to access the
machine learning model,

00:23:56.520 --> 00:23:58.170
be able to access hardware.

00:23:58.170 --> 00:24:01.900
And you can write a Python
code to I/O control and so on.

00:24:01.900 --> 00:24:05.190
So this is a
complete environment

00:24:05.190 --> 00:24:07.340
with multiple components
working together

00:24:07.340 --> 00:24:09.420
that we put in the
product for you

00:24:09.420 --> 00:24:12.990
to enable you to
do AI development.

00:24:12.990 --> 00:24:16.950
So Python API is very simple.

00:24:16.950 --> 00:24:19.660
For many of you who have
programmed in Python,

00:24:19.660 --> 00:24:22.620
we publish this on the
Coral website by the way,

00:24:22.620 --> 00:24:26.340
the basic classes of
all the Python API

00:24:26.340 --> 00:24:29.100
that you would use for
developing machine learning

00:24:29.100 --> 00:24:30.480
applications.

00:24:30.480 --> 00:24:32.580
I would say pay attention
to the middle two.

00:24:32.580 --> 00:24:35.430
Those are probably the one
that you would use the most.

00:24:35.430 --> 00:24:37.290
One is object detection.

00:24:37.290 --> 00:24:39.900
One is object classification.

00:24:39.900 --> 00:24:42.960
And the base engine
base class for them

00:24:42.960 --> 00:24:44.670
is one called a
classification engine,

00:24:44.670 --> 00:24:46.140
one is called a
detection engine.

00:24:46.140 --> 00:24:48.210
So it's very simple.

00:24:48.210 --> 00:24:51.930
The last one you see here,
what do we call the imprinting

00:24:51.930 --> 00:24:55.192
engine, it is something
for transfer learning,

00:24:55.192 --> 00:24:57.150
which I'm going to talk
about in a few minutes.

00:24:57.150 --> 00:24:59.520
This is something allow
you to efficiently develop

00:24:59.520 --> 00:25:03.270
a customized machine learning
model in the Python API library

00:25:03.270 --> 00:25:03.770
we provided.

00:25:03.770 --> 00:25:06.837
It also supports that.

00:25:06.837 --> 00:25:08.420
So let's take a quick
look at example.

00:25:08.420 --> 00:25:11.030
How would you use the
Python code, actually,

00:25:11.030 --> 00:25:14.180
to interact with the machine
learning module that the models

00:25:14.180 --> 00:25:16.820
that we supply?

00:25:16.820 --> 00:25:21.680
So if I say I want to develop
a program using the object

00:25:21.680 --> 00:25:24.740
detection model,
in Python code you

00:25:24.740 --> 00:25:27.050
would simply
initialize the engine

00:25:27.050 --> 00:25:29.870
using the DetectionEngine
that base class.

00:25:29.870 --> 00:25:34.490
The basic class of the group
members, the member functions,

00:25:34.490 --> 00:25:38.030
you use and to get to the
data and initiate and talk

00:25:38.030 --> 00:25:40.140
to the machine learning module.

00:25:40.140 --> 00:25:42.050
So you initiate engine here.

00:25:42.050 --> 00:25:44.180
You also need to load
the so-called label file,

00:25:44.180 --> 00:25:47.420
because if you want to
detect a bunch of objects,

00:25:47.420 --> 00:25:49.270
you want to identify
them with labels,

00:25:49.270 --> 00:25:51.220
you load the label file.

00:25:51.220 --> 00:25:53.640
And then let's say you want
to feed the machine learning

00:25:53.640 --> 00:25:57.050
model-- object detection model--
with Image, you load the Image

00:25:57.050 --> 00:25:57.830
file.

00:25:57.830 --> 00:25:59.630
And of course, for
most of you who

00:25:59.630 --> 00:26:03.260
have played it machine
learning models in Vision,

00:26:03.260 --> 00:26:06.920
you know you can
identify object in photo,

00:26:06.920 --> 00:26:09.440
or you can identify
objects in a video screen.

00:26:09.440 --> 00:26:12.225
In that case, it will
be a vector of tensors.

00:26:12.225 --> 00:26:17.300
But here I'm using a simple
example of just using an image.

00:26:17.300 --> 00:26:21.110
And then the code to interact
with the machine learning model

00:26:21.110 --> 00:26:22.300
is very simple.

00:26:22.300 --> 00:26:23.390
A simple line.

00:26:23.390 --> 00:26:28.100
From the engine, a member class,
you just say detect with image.

00:26:28.100 --> 00:26:31.190
And you pass the
parameters to this image.

00:26:31.190 --> 00:26:33.800
And the returned results,
the answer come back

00:26:33.800 --> 00:26:38.640
from this call, you can use it,
such as draw a bounding box,

00:26:38.640 --> 00:26:42.680
specify color, draw you binding
box, released to the stuff

00:26:42.680 --> 00:26:44.850
that you are detecting.

00:26:44.850 --> 00:26:46.690
So it's very simple.

00:26:46.690 --> 00:26:50.470
We supply a group of machine
learning models for you to use.

00:26:50.470 --> 00:26:53.500
Coral include them
in the product suite.

00:26:53.500 --> 00:26:54.870
We put them on a website.

00:26:54.870 --> 00:26:56.830
They are free for
you to download.

00:26:56.830 --> 00:27:00.200
They are pre-compiled
TensorFlow Lite models there

00:27:00.200 --> 00:27:02.220
for you to use.

00:27:02.220 --> 00:27:05.230
They can be readily run
without any further compiling.

00:27:05.230 --> 00:27:09.440
And you just simply download
them into the hardware.

00:27:09.440 --> 00:27:11.090
The Edge TPU module--

00:27:11.090 --> 00:27:12.980
the Python module--
it is already

00:27:12.980 --> 00:27:15.320
installed on the Deb Board.

00:27:15.320 --> 00:27:16.760
So you don't need
to do anything.

00:27:16.760 --> 00:27:20.100
You're ready to use your
Python programming code.

00:27:20.100 --> 00:27:22.080
The example I just showed
you, you can do that.

00:27:22.080 --> 00:27:26.240
However, if you use the USB, you
want to put on a Linux machine,

00:27:26.240 --> 00:27:31.100
you will need to manually
install this Python module.

00:27:31.100 --> 00:27:33.340
The Python API are
pre-installed, as I mentioned.

00:27:33.340 --> 00:27:33.840
Right.

00:27:33.840 --> 00:27:35.740
So that's what you need to do.

00:27:35.740 --> 00:27:38.630
I do want to mention,
though, a lot of those models

00:27:38.630 --> 00:27:41.480
we supply for free
online for you to use--

00:27:41.480 --> 00:27:44.300
those are for
noncommercial use only.

00:27:44.300 --> 00:27:46.200
That means if you
want to build a model,

00:27:46.200 --> 00:27:47.960
let's say you want
to sell for money,

00:27:47.960 --> 00:27:50.210
then you would need
to make your own model

00:27:50.210 --> 00:27:53.990
rather than use a open
source free model that

00:27:53.990 --> 00:27:55.630
is a non-commercial use.

00:27:55.630 --> 00:27:56.950
OK?

00:27:56.950 --> 00:28:00.130
The supplied models include the
categories of, as I mentioned,

00:28:00.130 --> 00:28:03.430
image classification,
object detection,

00:28:03.430 --> 00:28:06.290
as well as one called
weight-imprinting.

00:28:06.290 --> 00:28:09.840
That's, again, use for
transferred learning.

00:28:09.840 --> 00:28:12.730
And I'm going to talk
about it in a minute.

00:28:12.730 --> 00:28:15.600
So here are some examples
of the models that we

00:28:15.600 --> 00:28:18.000
make available for you online.

00:28:18.000 --> 00:28:20.940
And here are the image
classification models,

00:28:20.940 --> 00:28:22.020
as you can see.

00:28:22.020 --> 00:28:25.440
We support pretty much all the
popular image classification

00:28:25.440 --> 00:28:27.913
models from MobileNet
to Inception

00:28:27.913 --> 00:28:29.580
and the different
versions of MobileNet,

00:28:29.580 --> 00:28:31.860
the different
versions of Inception.

00:28:31.860 --> 00:28:33.900
The difference between
them are the type

00:28:33.900 --> 00:28:36.970
of objects they are
be able to identify.

00:28:36.970 --> 00:28:39.630
For example, if you want
to develop an application

00:28:39.630 --> 00:28:41.610
to tell the difference
between different birds

00:28:41.610 --> 00:28:45.750
or different plants, you will
pick the corresponding model

00:28:45.750 --> 00:28:47.860
to use.

00:28:47.860 --> 00:28:48.430
OK.

00:28:48.430 --> 00:28:52.160
With that, let me run a
couple of demos for you.

00:28:52.160 --> 00:28:56.170
First demo I'm going to show
you is a object detection model.

00:28:56.170 --> 00:28:58.210
And the second demo
I'm going to show you

00:28:58.210 --> 00:29:01.090
is a object
classification model.

00:29:01.090 --> 00:29:05.560
So with that, videographer,
please switch the display

00:29:05.560 --> 00:29:07.770
to the camera here.

00:29:07.770 --> 00:29:10.950
So on the table
here, as you can see,

00:29:10.950 --> 00:29:14.940
I have this demo built
with this conveyor belt.

00:29:14.940 --> 00:29:17.430
I'm simulating
real-time traffic.

00:29:17.430 --> 00:29:21.180
Over here there's a
camera points to it.

00:29:21.180 --> 00:29:24.540
As you can see on the
screen, the camera

00:29:24.540 --> 00:29:27.330
feeds into this Coral Dev Board.

00:29:27.330 --> 00:29:31.160
In real time it identifies
the number of objects.

00:29:31.160 --> 00:29:33.160
It shows it's a car.

00:29:33.160 --> 00:29:35.610
It also shows a so-called
confidence score--

00:29:35.610 --> 00:29:38.730
how confident the model
thinks it is a automobile.

00:29:38.730 --> 00:29:40.380
But on a conveyor
belt, as you can see,

00:29:40.380 --> 00:29:42.850
I also have people
or pedestrians.

00:29:42.850 --> 00:29:45.000
But what I'm going to do
now is I'm going to "wink"

00:29:45.000 --> 00:29:46.150
make this movie.

00:29:46.150 --> 00:29:46.890
OK.

00:29:46.890 --> 00:29:48.870
So I'm going to
turn on the power.

00:29:48.870 --> 00:29:53.370
And I'm going to crank up the
speed to make that running.

00:29:53.370 --> 00:29:57.030
Now in real time
world, as this moving,

00:29:57.030 --> 00:29:59.040
you take a look on the screen.

00:29:59.040 --> 00:30:01.230
The machine learning
object detection

00:30:01.230 --> 00:30:03.350
is continually happening.

00:30:03.350 --> 00:30:07.740
It continuously identifies
the correct car or pedestrian,

00:30:07.740 --> 00:30:09.630
or there's a traffic
light as well.

00:30:09.630 --> 00:30:10.290
Right?

00:30:10.290 --> 00:30:12.540
So you can see the
Coral performance

00:30:12.540 --> 00:30:16.567
is very high be able to do
that as the scene going.

00:30:16.567 --> 00:30:18.900
Now I want you to pay attention
to the lower left corner

00:30:18.900 --> 00:30:21.900
on the screen, or upper
left corner of the screen,

00:30:21.900 --> 00:30:24.960
shows the frame
per second speed.

00:30:24.960 --> 00:30:26.910
It runs last time I
saw it was like 50

00:30:26.910 --> 00:30:28.510
to 70 frames per second.

00:30:28.510 --> 00:30:30.490
It is a very high
speed performance.

00:30:30.490 --> 00:30:34.140
Now, if I crank up the speed to
make it go a little bit faster,

00:30:34.140 --> 00:30:36.870
you can see the machine
learning in terms

00:30:36.870 --> 00:30:40.350
of object identification
capturing is still going on.

00:30:40.350 --> 00:30:40.950
Right?

00:30:40.950 --> 00:30:44.010
It continues to be able
to identify automobile

00:30:44.010 --> 00:30:46.240
in this fast-moving environment.

00:30:46.240 --> 00:30:48.240
So this is really
demonstrating the power

00:30:48.240 --> 00:30:52.310
of object detection running
right on this Coral device.

00:30:52.310 --> 00:30:53.070
OK?

00:30:53.070 --> 00:30:56.970
So that's the first demo.

00:30:56.970 --> 00:30:58.540
[APPLAUSE]

00:30:58.540 --> 00:30:59.040
Thank you.

00:30:59.040 --> 00:31:01.800
Yes, you can clap.

00:31:01.800 --> 00:31:05.250
I hope you guys be able to
make a lot more interesting

00:31:05.250 --> 00:31:07.110
applications just like that.

00:31:07.110 --> 00:31:10.800
Bring the power of Coral
into your imagination,

00:31:10.800 --> 00:31:12.090
into your innovation.

00:31:12.090 --> 00:31:12.600
All right.

00:31:12.600 --> 00:31:15.960
Next one is showing
object classification.

00:31:15.960 --> 00:31:18.720
So over here I have
another Dev Board.

00:31:18.720 --> 00:31:20.730
And the output of that--

00:31:20.730 --> 00:31:23.760
display, please switch to
the output of this camera.

00:31:27.510 --> 00:31:30.530
So what I'm going to do,
I have several food items

00:31:30.530 --> 00:31:31.850
on the table.

00:31:31.850 --> 00:31:35.930
And I'm going to let this camera
identify the different type

00:31:35.930 --> 00:31:37.470
of an object.

00:31:37.470 --> 00:31:42.250
So let's say I put a
hamburger over here.

00:31:42.250 --> 00:31:45.370
And as you can see on
the upper left corner,

00:31:45.370 --> 00:31:48.910
it tries to identify the object
with some confidence score.

00:31:48.910 --> 00:31:50.680
Depends on the
lighting condition,

00:31:50.680 --> 00:31:52.426
hopefully you will
see hamburger.

00:31:55.580 --> 00:31:56.080
Yeah.

00:31:56.080 --> 00:31:58.805
You need to aim at the right
angle and with the light.

00:31:58.805 --> 00:31:59.680
Let's try this donut.

00:32:02.450 --> 00:32:03.260
Does it say donut?

00:32:03.260 --> 00:32:04.430
It showed up as donut?

00:32:04.430 --> 00:32:05.390
OK.

00:32:05.390 --> 00:32:07.310
We can also try a sandwich.

00:32:14.200 --> 00:32:15.180
OK?

00:32:15.180 --> 00:32:18.360
Lastly, I'm going to
try something exotic.

00:32:18.360 --> 00:32:20.910
Let's say sushi.

00:32:20.910 --> 00:32:21.740
OK.

00:32:21.740 --> 00:32:27.050
So this is how you could make
object classification work

00:32:27.050 --> 00:32:30.920
by simply running one of the
object classification model

00:32:30.920 --> 00:32:32.300
right on device.

00:32:32.300 --> 00:32:34.490
Again, none of these
are connect to internet.

00:32:34.490 --> 00:32:37.400
None of the data is being
sent to the cloud or a server.

00:32:37.400 --> 00:32:40.910
Everything competition
happening right on the device.

00:32:40.910 --> 00:32:41.720
OK?

00:32:41.720 --> 00:32:42.410
Great.

00:32:42.410 --> 00:32:43.450
Thank you.

00:32:43.450 --> 00:32:45.710
[APPLAUSE]

00:32:45.710 --> 00:32:46.210
All right.

00:32:46.210 --> 00:32:47.590
Let's switch back to the slides.

00:32:51.040 --> 00:32:53.710
So now we talk
about how do you use

00:32:53.710 --> 00:32:59.080
a Coral supplied pre-compiled
model to deploy that.

00:32:59.080 --> 00:33:02.120
But what if you want to
build something on your own?

00:33:02.120 --> 00:33:03.560
You want to
customize your model.

00:33:03.560 --> 00:33:06.640
Well, this is where
transfer learning comes in.

00:33:06.640 --> 00:33:10.230
Transfer learning, it is
helping you saving time

00:33:10.230 --> 00:33:13.370
in terms of building
your own model.

00:33:13.370 --> 00:33:17.510
And basically it takes
a pre-trained model that

00:33:17.510 --> 00:33:19.730
is compatible with Edge TPU.

00:33:19.730 --> 00:33:23.690
And you only take that
for your related task

00:33:23.690 --> 00:33:26.650
by using your own
customized data.

00:33:26.650 --> 00:33:29.120
In a concept, a
neural network has

00:33:29.120 --> 00:33:31.190
many layers deep of neurons.

00:33:31.190 --> 00:33:31.700
OK?

00:33:31.700 --> 00:33:33.620
If you want to train
this whole model--

00:33:33.620 --> 00:33:35.570
in fact, I heard it from
one of my colleagues

00:33:35.570 --> 00:33:37.880
who developed a model
from ground level up--

00:33:37.880 --> 00:33:43.190
takes more than 4,000 GPUs
to train a vision model.

00:33:43.190 --> 00:33:45.420
And it takes days.

00:33:45.420 --> 00:33:48.470
However, if you instead
of training everything,

00:33:48.470 --> 00:33:51.310
you only need to
modify the top layer.

00:33:51.310 --> 00:33:53.510
This is what a transfer
learning concept is.

00:33:53.510 --> 00:33:56.210
Because the lower
layer, those neurons

00:33:56.210 --> 00:33:58.850
are trying to detect,
say, different colors,

00:33:58.850 --> 00:34:01.250
different shapes, different
lighting conditions.

00:34:01.250 --> 00:34:04.310
They can be used for you
to help you identify things

00:34:04.310 --> 00:34:05.030
that you care.

00:34:05.030 --> 00:34:06.863
Let's say you want to
build a model identify

00:34:06.863 --> 00:34:08.253
different apples.

00:34:08.253 --> 00:34:09.920
You don't need to
train the whole model.

00:34:09.920 --> 00:34:13.980
You take a classification model,
you only modify the top layer.

00:34:13.980 --> 00:34:16.670
And by training with
your own customized data

00:34:16.670 --> 00:34:18.320
with many different apples.

00:34:18.320 --> 00:34:22.330
So this is what
transfer learning does.

00:34:22.330 --> 00:34:25.540
So the code to do
transfer learning also

00:34:25.540 --> 00:34:29.710
in a Python environment on
Coral is very, very simple too.

00:34:29.710 --> 00:34:32.650
Basically, you prepare
to do transfer learning,

00:34:32.650 --> 00:34:34.449
you set up a Docker container.

00:34:34.449 --> 00:34:36.722
You specify what
model you want to use.

00:34:36.722 --> 00:34:38.139
In this case, I'm
showing example,

00:34:38.139 --> 00:34:41.340
I'm using a MobileNet
version one.

00:34:41.340 --> 00:34:44.449
And if you want to
train a few top layers,

00:34:44.449 --> 00:34:46.760
the single command you
want to use simply--

00:34:46.760 --> 00:34:48.130
start training.

00:34:48.130 --> 00:34:50.540
And again, you
give the parameter

00:34:50.540 --> 00:34:52.840
as the name of the model.

00:34:52.840 --> 00:34:54.590
But if you want to
train the entire model,

00:34:54.590 --> 00:34:56.750
you can do that too,
is you add one more

00:34:56.750 --> 00:34:59.480
additional flag that says,
training, whole model, flag

00:34:59.480 --> 00:35:01.840
true.

00:35:01.840 --> 00:35:05.620
So once you run that code
in a console on your system,

00:35:05.620 --> 00:35:08.230
basically, the console
will showing you

00:35:08.230 --> 00:35:11.770
the progress of training in
terms of the steps it takes

00:35:11.770 --> 00:35:15.140
and in terms of the number
of how much time it takes.

00:35:15.140 --> 00:35:17.320
So it's very simple
for you to do

00:35:17.320 --> 00:35:21.650
that in the environment--
in a Linux environment.

00:35:21.650 --> 00:35:24.260
So with that, let me do
another demo for you.

00:35:24.260 --> 00:35:25.990
It is called the
teachable machine.

00:35:25.990 --> 00:35:28.420
We are going to publish
this as open source for you

00:35:28.420 --> 00:35:31.070
to do the same in
the near future.

00:35:31.070 --> 00:35:33.910
But basically what you see
here, I'm going to show you,

00:35:33.910 --> 00:35:37.370
I'm going to teach it make a
machine to remember things.

00:35:37.370 --> 00:35:40.780
So the video camera,
videographer, we

00:35:40.780 --> 00:35:43.830
need to have an image of this.

00:35:43.830 --> 00:35:46.490
So on the desk
here what you see,

00:35:46.490 --> 00:35:48.590
it is actually it
was built based

00:35:48.590 --> 00:35:52.500
on this USB with a Raspberry Pi.

00:35:52.500 --> 00:35:54.650
So more than Dev Board,
you could use Raspberry Pi

00:35:54.650 --> 00:35:56.250
to build the application.

00:35:56.250 --> 00:36:00.060
So here with this little bit
of demo, and it has a camera

00:36:00.060 --> 00:36:01.700
points up.

00:36:01.700 --> 00:36:04.820
And I have some
different objects.

00:36:04.820 --> 00:36:08.255
So if I hit a button to take--

00:36:08.255 --> 00:36:10.630
every time I hit a button, it
takes and image, let's say,

00:36:10.630 --> 00:36:15.280
of this hamburger, it
remembers several images

00:36:15.280 --> 00:36:16.770
of this hamburger.

00:36:16.770 --> 00:36:21.490
Now if I take a
different object and take

00:36:21.490 --> 00:36:26.610
a different group of photos
of the second object,

00:36:26.610 --> 00:36:29.170
it remembers the images.

00:36:29.170 --> 00:36:31.780
And I'm going to take ice
cream on the green button.

00:36:37.010 --> 00:36:41.990
And lastly, maybe I'll take
this donut with the red button.

00:36:44.810 --> 00:36:46.870
So what happens in
the background here,

00:36:46.870 --> 00:36:50.080
the program runs doing
a transfer learning,

00:36:50.080 --> 00:36:52.650
taking existing object
classification model,

00:36:52.650 --> 00:36:57.460
but to replace the last layer
with the image that just taken.

00:36:57.460 --> 00:36:58.810
Now watch this.

00:36:58.810 --> 00:37:02.000
If I put this hamburger back,
the yellow light turns on.

00:37:02.000 --> 00:37:03.610
It remembers.

00:37:03.610 --> 00:37:07.857
If I put the ice cream,
the green light turns on.

00:37:07.857 --> 00:37:09.190
I hope you can see on the video.

00:37:09.190 --> 00:37:10.170
Yes.

00:37:10.170 --> 00:37:16.490
And if I take this donut,
the blue light turns on.

00:37:16.490 --> 00:37:18.060
Now more than that.

00:37:18.060 --> 00:37:20.590
Moment ago, I trained
with this green ice cream.

00:37:20.590 --> 00:37:21.090
Right?

00:37:21.090 --> 00:37:22.110
The green light.

00:37:22.110 --> 00:37:26.200
If I put a yellow ice
cream, it remembers too.

00:37:26.200 --> 00:37:28.980
Because it's a machine learning
model more than just the color,

00:37:28.980 --> 00:37:30.660
and also identify the shape.

00:37:30.660 --> 00:37:32.850
Because this shape and
this shape is different,

00:37:32.850 --> 00:37:34.740
the model is
faster, smart enough

00:37:34.740 --> 00:37:36.940
to know the difference
between the object.

00:37:36.940 --> 00:37:38.760
So again, this is
one of the examples

00:37:38.760 --> 00:37:43.380
you could use to building
things with the capability

00:37:43.380 --> 00:37:46.790
of classification right on the
device without the internet,

00:37:46.790 --> 00:37:49.780
and to build even with a
small USB key like that.

00:37:49.780 --> 00:37:50.280
Right?

00:37:50.280 --> 00:37:51.984
Very powerful stuff.

00:37:51.984 --> 00:37:54.200
[APPLAUSE]

00:37:54.200 --> 00:37:55.530
Thank you.

00:37:55.530 --> 00:37:56.030
OK.

00:37:56.030 --> 00:37:58.400
Let's switch back to the slides.

00:37:58.400 --> 00:38:00.410
So the ramifications
of this is huge.

00:38:00.410 --> 00:38:00.980
Right?

00:38:00.980 --> 00:38:03.530
Imagine in an
industrial environment,

00:38:03.530 --> 00:38:05.450
you want to identify things.

00:38:05.450 --> 00:38:08.750
You want to tell good widgets
from bad widgets in assembly

00:38:08.750 --> 00:38:10.460
line, for example.

00:38:10.460 --> 00:38:13.190
You don't have a time to
train the assembly line--

00:38:13.190 --> 00:38:14.720
the auto-sorting machine.

00:38:14.720 --> 00:38:17.900
You could use transfer learning
and learn the different objects

00:38:17.900 --> 00:38:19.800
on the fly, just like that.

00:38:19.800 --> 00:38:21.090
So it's very powerful.

00:38:21.090 --> 00:38:25.130
You can use this in building
just endless of applications

00:38:25.130 --> 00:38:27.980
using such capability.

00:38:27.980 --> 00:38:28.480
All right.

00:38:28.480 --> 00:38:30.410
So we talk about
transfer learning.

00:38:30.410 --> 00:38:32.740
We talk about building
your own customized model.

00:38:32.740 --> 00:38:34.630
Let me get into a bit
more detail of how

00:38:34.630 --> 00:38:37.960
do you use the Coral models.

00:38:37.960 --> 00:38:38.740
OK.

00:38:38.740 --> 00:38:41.890
So we talk about we supplied
a set of pre-compiled model

00:38:41.890 --> 00:38:42.640
for you.

00:38:42.640 --> 00:38:44.780
This is actually
case number one.

00:38:44.780 --> 00:38:46.180
User case number one.

00:38:46.180 --> 00:38:47.420
It's very simple.

00:38:47.420 --> 00:38:50.590
You simply download the
Coral model we supply to you.

00:38:50.590 --> 00:38:52.030
You don't need to compile again.

00:38:52.030 --> 00:38:54.700
You simply download
and put on the device.

00:38:54.700 --> 00:38:55.480
OK.

00:38:55.480 --> 00:38:58.030
The second scenario is,
you take the existing

00:38:58.030 --> 00:38:59.420
model, pre-trained.

00:38:59.420 --> 00:39:02.470
However, you use transfer
learning to customize it

00:39:02.470 --> 00:39:04.000
with your own data.

00:39:04.000 --> 00:39:06.820
However, after you've done
that, it's not compatible yet

00:39:06.820 --> 00:39:07.930
with the Coral board.

00:39:07.930 --> 00:39:09.260
You need to compile.

00:39:09.260 --> 00:39:12.190
So you use Coral-supplied
Coral compiler.

00:39:12.190 --> 00:39:13.570
And you compile it.

00:39:13.570 --> 00:39:15.640
The net result of the
TensorFlow Lite file.

00:39:15.640 --> 00:39:19.780
You download to the
Edge TPU Coral hardware.

00:39:19.780 --> 00:39:21.400
And you'll be able to run there.

00:39:21.400 --> 00:39:24.250
Now I want to say for right
now, the Coral compiler

00:39:24.250 --> 00:39:26.860
is only runs on
Google Cloud Platform.

00:39:26.860 --> 00:39:29.410
But very soon we will
make this compiler

00:39:29.410 --> 00:39:32.980
a standalone executable,
make it downloadable

00:39:32.980 --> 00:39:36.780
on the internet for
you guys to use.

00:39:36.780 --> 00:39:38.640
So the user case is
you want to build

00:39:38.640 --> 00:39:41.160
the entire module by yourself.

00:39:41.160 --> 00:39:43.680
This is like you really
want the customization.

00:39:43.680 --> 00:39:45.780
The existing model
doesn't satisfy you,

00:39:45.780 --> 00:39:47.050
you can do that too.

00:39:47.050 --> 00:39:49.260
So in that case, you will need--

00:39:49.260 --> 00:39:52.450
starting with the TensorFlow
and building a model from there.

00:39:52.450 --> 00:39:55.860
So let me talk about the
steps involved with there.

00:39:55.860 --> 00:39:58.830
The workflow of creating
your own customized model

00:39:58.830 --> 00:40:00.240
is the following.

00:40:00.240 --> 00:40:01.950
TensorFlow model,
as you all know,

00:40:01.950 --> 00:40:04.640
it's a 32-bit
floating point model.

00:40:04.640 --> 00:40:05.250
Right?

00:40:05.250 --> 00:40:07.320
And that is now
usable for Coral,

00:40:07.320 --> 00:40:11.340
because Coral device require
TensorFlow Lite, because it

00:40:11.340 --> 00:40:14.040
runs on the Edge, needs
very little memory.

00:40:14.040 --> 00:40:16.110
So TensorFlow model will work.

00:40:16.110 --> 00:40:18.150
You take the TensorFlow model.

00:40:18.150 --> 00:40:20.760
You convert it into
number one step.

00:40:20.760 --> 00:40:24.790
You convert it into training
with a quantized version.

00:40:24.790 --> 00:40:26.790
So there's a training
process called

00:40:26.790 --> 00:40:29.180
quantized-aware training.

00:40:29.180 --> 00:40:31.350
You convert your
TensorFlow model

00:40:31.350 --> 00:40:34.410
into a quantized
TensorFlow model.

00:40:34.410 --> 00:40:36.360
So basically convert a
32-bit floating point

00:40:36.360 --> 00:40:39.890
base to an 8-bit
integer-based model.

00:40:39.890 --> 00:40:45.160
After that, you export this
model with TensorFlow model

00:40:45.160 --> 00:40:49.870
into a TensorFlow frozen graph,
which is typically .pb PDF

00:40:49.870 --> 00:40:51.300
file.

00:40:51.300 --> 00:40:53.440
But this file is
not usable either.

00:40:53.440 --> 00:40:56.710
It's not quite ready to
be deployed on Coral.

00:40:56.710 --> 00:40:58.690
What you need to
do next step is you

00:40:58.690 --> 00:41:04.530
need to convert this thing
into a TensorFlow Lite model,

00:41:04.530 --> 00:41:07.830
and with a TensorFlow
Lite converter.

00:41:07.830 --> 00:41:13.100
And after that you compile
using the TensorFlow Edge TPU

00:41:13.100 --> 00:41:16.080
TensorFlow compiler and
making to a binary that's

00:41:16.080 --> 00:41:18.840
compatible with the Edge TPU.

00:41:18.840 --> 00:41:21.010
And then after you've
done that, you deploy.

00:41:21.010 --> 00:41:24.300
So this is a process
of a flow you

00:41:24.300 --> 00:41:27.760
will use in your environment.

00:41:27.760 --> 00:41:32.280
So to build, we talk about
how this platform provides you

00:41:32.280 --> 00:41:34.320
to building the applications.

00:41:34.320 --> 00:41:36.720
We said at the very
beginning we want

00:41:36.720 --> 00:41:39.300
Coral to be a platform
of an ecosystem

00:41:39.300 --> 00:41:40.650
for everybody together.

00:41:40.650 --> 00:41:42.510
So really this is
a platform for you

00:41:42.510 --> 00:41:46.590
to use to innovate and to share
with the community globally

00:41:46.590 --> 00:41:47.700
altogether.

00:41:47.700 --> 00:41:49.800
With that, I want to show
you an example of one

00:41:49.800 --> 00:41:52.980
of our retail partners
called Gravity Link.

00:41:52.980 --> 00:41:54.210
They built this app--

00:41:54.210 --> 00:41:55.350
a very cool app.

00:41:55.350 --> 00:41:58.650
You can use your mobile phone
to download the app directly

00:41:58.650 --> 00:42:01.020
into the Coral Dev Board.

00:42:01.020 --> 00:42:04.220
And you can find more
details at this link below.

00:42:04.220 --> 00:42:08.040
Or you just simply search
Model Play at Google Play.

00:42:08.040 --> 00:42:09.820
You can download and try.

00:42:09.820 --> 00:42:12.640
So this is the idea of we want
all developers to contribute

00:42:12.640 --> 00:42:15.210
to this ecosystem,
building tools, building

00:42:15.210 --> 00:42:18.480
models, building applications,
share with the industry.

00:42:18.480 --> 00:42:22.130
And this is what the
Coral ecosystem is for.

00:42:22.130 --> 00:42:24.410
With that, let me
ending by saying,

00:42:24.410 --> 00:42:27.620
what are the potential areas
you could develop for AI?

00:42:27.620 --> 00:42:28.550
Look at this.

00:42:28.550 --> 00:42:31.470
There's consumer electronics,
of course; appliance;

00:42:31.470 --> 00:42:33.860
there's a lot of opportunities
for you to develop there.

00:42:33.860 --> 00:42:36.200
Industrial warehousing,
monitoring the devices,

00:42:36.200 --> 00:42:39.840
monitoring the assembly line.

00:42:39.840 --> 00:42:41.300
This is another area.

00:42:41.300 --> 00:42:41.900
Robots.

00:42:41.900 --> 00:42:42.760
Robotics.

00:42:42.760 --> 00:42:45.920
Both the industry and
consumer is a field.

00:42:45.920 --> 00:42:47.210
Automobiles.

00:42:47.210 --> 00:42:50.070
Automotive industry
is also a field.

00:42:50.070 --> 00:42:52.520
And as all of you here
at Google I/O keynote,

00:42:52.520 --> 00:42:57.510
medical application, medical
devices, is another area.

00:42:57.510 --> 00:42:58.910
And finally, education.

00:42:58.910 --> 00:43:01.160
Education aids and research.

00:43:01.160 --> 00:43:04.490
You can use machine learning--
on-device machine learning

00:43:04.490 --> 00:43:07.510
using Coral that
you can innovate.

00:43:07.510 --> 00:43:09.190
So there's a lot of
things you could do.

00:43:09.190 --> 00:43:09.690
Right?

00:43:09.690 --> 00:43:11.920
And all the information
I've talked about today,

00:43:11.920 --> 00:43:13.933
they are summarized
at our Coral website.

00:43:13.933 --> 00:43:15.850
If you don't remember
anything, remember this.

00:43:15.850 --> 00:43:19.280
It's called
Coral.withGoogle.com.

00:43:19.280 --> 00:43:24.080
Our documentation, our samples,
models, everything's there.

00:43:24.080 --> 00:43:26.270
So there's more references
I put in my slides,

00:43:26.270 --> 00:43:28.130
you can look at later.

00:43:28.130 --> 00:43:31.010
There's a reference to the
Mendel Linux, reference

00:43:31.010 --> 00:43:32.750
to the TensorFlow
Lite, how do you

00:43:32.750 --> 00:43:34.720
do quantization-aware training.

00:43:34.720 --> 00:43:37.050
And all this information
is very important.

00:43:37.050 --> 00:43:40.190
I do want to call out, on
Stack Overflow, we have a tag.

00:43:40.190 --> 00:43:41.890
You can join the
online community,

00:43:41.890 --> 00:43:43.780
participate in
discussions, answer

00:43:43.780 --> 00:43:46.310
other developer's questions,
or look at the answers there.

00:43:46.310 --> 00:43:48.800
I want you monitoring
or help each other

00:43:48.800 --> 00:43:51.000
using this online community.

00:43:51.000 --> 00:43:52.500
And I want to give a shout out.

00:43:52.500 --> 00:43:55.380
We have a Coral code
app for those of you

00:43:55.380 --> 00:43:58.500
would like to experiment
using Coral at I/O,

00:43:58.500 --> 00:44:00.030
you can go there today.

00:44:00.030 --> 00:44:03.480
Our Dev Load team colleagues
are helping everybody

00:44:03.480 --> 00:44:05.570
going the coding app.

00:44:05.570 --> 00:44:08.860
So with that, a quick
summary and a call to action.

00:44:08.860 --> 00:44:10.920
After you here
today, number one.

00:44:10.920 --> 00:44:12.440
Review our Coral product.

00:44:12.440 --> 00:44:14.380
Learn more about
TensorFlow Lite.

00:44:14.380 --> 00:44:16.450
Using Coral Board to experiment.

00:44:16.450 --> 00:44:20.540
And then building your
own customized models.

00:44:20.540 --> 00:44:24.190
And finally, building
model from ground level up.

00:44:24.190 --> 00:44:27.280
We want all of you
taking Coral Platform,

00:44:27.280 --> 00:44:29.960
putting in your imagination,
putting in your innovation,

00:44:29.960 --> 00:44:33.610
bring AI to the industry to
the consumers everywhere.

00:44:33.610 --> 00:44:36.430
So with that, on behalf
of our Coral team,

00:44:36.430 --> 00:44:39.130
thank you all very much
for coming to this session.

00:44:39.130 --> 00:44:40.500
Thank you.

00:44:40.500 --> 00:44:43.850
[MUSIC PLAYING]

