WEBVTT
Kind: captions
Language: en

00:00:01.320 --> 00:00:03.170
DAN RUSSELL: Good afternoon,
everybody.

00:00:03.170 --> 00:00:05.790
Welcome to this episode
of Authors at Google.

00:00:05.790 --> 00:00:07.130
I'm Dan Russell.

00:00:07.130 --> 00:00:10.710
And I'm the host for our guest
today, Jeff Johnson.

00:00:10.710 --> 00:00:15.360
And I know Jeff because back in
the mid '80s we were both

00:00:15.360 --> 00:00:17.320
at an institution
known a Xerox.

00:00:17.320 --> 00:00:22.490
I was at PARC and Jeff was at
Office Information Systems.

00:00:22.490 --> 00:00:26.580
That means, he got to work on
the Xerox Star which if you go

00:00:26.580 --> 00:00:29.980
down to the Computer History
Museum, you can find.

00:00:29.980 --> 00:00:33.200
It was a fantastic,
groundbreaking system that

00:00:33.200 --> 00:00:35.780
commercialized a lot of the
ideas that later showed up in

00:00:35.780 --> 00:00:38.200
things like, oh, the
Macintosh, and

00:00:38.200 --> 00:00:39.480
other kinds of systems.

00:00:39.480 --> 00:00:41.020
You've actually used--

00:00:41.020 --> 00:00:43.330
may or may not know it-- you've
actually used a lot of

00:00:43.330 --> 00:00:46.220
the work that Jeff has
done over the years.

00:00:46.220 --> 00:00:49.970
He's also not just a user
experience person, but he

00:00:49.970 --> 00:00:55.240
programs in Java, Mesa-- does
anybody remember Mesa--

00:00:55.240 --> 00:00:59.300
C++, even things like APL.

00:00:59.300 --> 00:01:02.080
So he's a remarkable guy who's
probably best known for his

00:01:02.080 --> 00:01:03.520
bloopers series of books.

00:01:03.520 --> 00:01:07.950
And you can come and check out
some of them up here later.

00:01:07.950 --> 00:01:10.850
The one I first saw was "GUI
Bloopers." But then there were

00:01:10.850 --> 00:01:14.140
"Web Bloopers," and "Web
Bloopers 2.0." Which are sort

00:01:14.140 --> 00:01:17.500
of catalogs of all the mistakes
that we make and we

00:01:17.500 --> 00:01:18.240
should learn from.

00:01:18.240 --> 00:01:19.980
So these are really interesting
books if you are

00:01:19.980 --> 00:01:22.410
all interested in user
experience design.

00:01:22.410 --> 00:01:25.850
So Jeff's talk is a part of the
growing user experience

00:01:25.850 --> 00:01:28.150
education effort that's
being led by the

00:01:28.150 --> 00:01:29.720
infrastructure team.

00:01:29.720 --> 00:01:32.110
And we're going to be having
more tech talks in this series

00:01:32.110 --> 00:01:33.350
so please stay tuned.

00:01:33.350 --> 00:01:35.380
If you like this one, we're
going to have more.

00:01:35.380 --> 00:01:39.940
And you'll enjoy your
participation in that.

00:01:39.940 --> 00:01:41.730
Also notice that we're
coordinating--

00:01:41.730 --> 00:01:45.390
well Cindy, who's sitting back
over there with her hand up is

00:01:45.390 --> 00:01:48.480
coordinating a workshop
and tutorial here--

00:01:48.480 --> 00:01:49.920
well somewhere here
at Google--

00:01:49.920 --> 00:01:54.930
on February 7 where Jeff and
Austin Henderson will be

00:01:54.930 --> 00:01:58.980
talking about returning the
notion of the conceptual

00:01:58.980 --> 00:02:00.660
design models.

00:02:00.660 --> 00:02:04.040
That will be open for
registration on GLearn I guess

00:02:04.040 --> 00:02:06.870
in a week or so,
real soon now.

00:02:06.870 --> 00:02:08.910
And there's space
for 50 Googlers.

00:02:08.910 --> 00:02:11.600
So sign up soon if
you like that.

00:02:11.600 --> 00:02:15.880
Jeff's book will be available
in the back, $15, cash or

00:02:15.880 --> 00:02:17.080
credit card.

00:02:17.080 --> 00:02:20.160
So if you like his talk, you're
going to love his book.

00:02:20.160 --> 00:02:23.330
So please join me in welcoming
Jeff Johnson to talk to us

00:02:23.330 --> 00:02:26.730
about how to design with
minds in mind.

00:02:26.730 --> 00:02:27.980
Jeff.

00:02:33.269 --> 00:02:35.700
JEFF JOHNSON: Thank you.

00:02:35.700 --> 00:02:40.820
So thanks to Cindy Yepez and
Robin Jeffries for arranging

00:02:40.820 --> 00:02:42.690
this talk, and to Dan
for hosting it.

00:02:46.200 --> 00:02:48.895
How many of you design
user interfaces?

00:02:51.500 --> 00:02:52.190
Good number.

00:02:52.190 --> 00:02:52.750
Goo.

00:02:52.750 --> 00:02:56.650
Well those of you who do that,
how many of you ever looked at

00:02:56.650 --> 00:02:59.600
or seen user interface design
guidelines like the ones I'm

00:02:59.600 --> 00:03:01.450
displaying now?

00:03:01.450 --> 00:03:05.030
These were developed by and
written, published by Ben

00:03:05.030 --> 00:03:07.110
Shneiderman in 1987.

00:03:07.110 --> 00:03:13.940
And all subsequent issues of his
book up to now remain much

00:03:13.940 --> 00:03:15.190
more or less the same.

00:03:18.590 --> 00:03:20.910
How many of you have seen
guidelines like these when

00:03:20.910 --> 00:03:24.160
you're designing user
interfaces?

00:03:24.160 --> 00:03:28.320
OK so now we'll look at some
similar guidelines that were

00:03:28.320 --> 00:03:30.690
published by Nielson
and Molich.

00:03:30.690 --> 00:03:34.420
They were intending these to be
used for website design and

00:03:34.420 --> 00:03:36.110
website evaluation.

00:03:36.110 --> 00:03:38.720
Now I'm not going to go through
the guidelines in

00:03:38.720 --> 00:03:41.200
detail, because that's not
the subject of this talk.

00:03:41.200 --> 00:03:45.210
But I will point out that
there's similarity between

00:03:45.210 --> 00:03:48.440
these guidelines and those that
have been put forward by

00:03:48.440 --> 00:03:50.050
Ben Shneiderman.

00:03:50.050 --> 00:03:54.910
So the question is, did Nielson
and Molich plagiarize

00:03:54.910 --> 00:03:57.900
the earlier guidelines
by Ben Schneiderman?

00:03:57.900 --> 00:04:01.590
And then subsequently, did
Debbie Stone and her

00:04:01.590 --> 00:04:02.470
colleagues--

00:04:02.470 --> 00:04:05.640
in the book that they published
in 2005, has a

00:04:05.640 --> 00:04:07.050
similar set of guidelines--

00:04:07.050 --> 00:04:10.150
did they plagiarize?

00:04:10.150 --> 00:04:15.740
What was the reason that these
guidelines were much the same

00:04:15.740 --> 00:04:19.040
in these different
publications?

00:04:19.040 --> 00:04:23.310
Well I'm going to argue that the
reason is not plagiarism.

00:04:23.310 --> 00:04:27.320
The reason is that user
interface guidelines

00:04:27.320 --> 00:04:30.010
are based on us.

00:04:30.010 --> 00:04:31.820
They're based on how we work.

00:04:31.820 --> 00:04:33.360
That's where those guidelines
come from.

00:04:37.270 --> 00:04:43.280
Now I used to be in the
guidelines business, or

00:04:43.280 --> 00:04:44.590
actually anti guidelines.

00:04:44.590 --> 00:04:50.180
So when I wrote "GUI Bloopers"
and its sequels, I was sort of

00:04:50.180 --> 00:04:52.320
in the, don't do this.

00:04:52.320 --> 00:04:54.280
Do this instead.

00:04:54.280 --> 00:04:58.760
But I didn't really explain
it in those books why.

00:04:58.760 --> 00:05:02.280
And I found that user interface
designers typically

00:05:02.280 --> 00:05:06.470
are not satisfied with just
being told, thou shalt.

00:05:06.470 --> 00:05:09.340
Or even, thou shalt not.

00:05:09.340 --> 00:05:14.180
They like to know
why thou shalt.

00:05:14.180 --> 00:05:15.820
Why shalt thou?

00:05:15.820 --> 00:05:21.830
And so the other problem is that
it's difficult to follow

00:05:21.830 --> 00:05:25.270
those guidelines if
you're a designer.

00:05:25.270 --> 00:05:26.660
Let's go back and look
at some of those

00:05:26.660 --> 00:05:29.710
guidelines for a second.

00:05:29.710 --> 00:05:32.750
First step to goal
should be clear.

00:05:32.750 --> 00:05:34.180
What does that mean?

00:05:34.180 --> 00:05:36.030
That's pretty vague.

00:05:36.030 --> 00:05:37.310
First step is fairly clear.

00:05:37.310 --> 00:05:42.270
But what does it mean for the
first step should be clear?

00:05:42.270 --> 00:05:43.110
What is clear?

00:05:43.110 --> 00:05:44.060
What makes something clear?

00:05:44.060 --> 00:05:45.930
When is something not clear?

00:05:45.930 --> 00:05:50.620
So the point is that guidelines
are not rote

00:05:50.620 --> 00:05:52.990
recipes that you can
just follow without

00:05:52.990 --> 00:05:56.670
any background knowledge.

00:05:56.670 --> 00:05:58.900
Applying user interface
guidelines effectively

00:05:58.900 --> 00:06:03.020
requires understanding their
scientific basis.

00:06:03.020 --> 00:06:06.880
Understanding where the rules
came from so that you can

00:06:06.880 --> 00:06:08.740
balance the trade offs
that occur when there

00:06:08.740 --> 00:06:09.620
are competing rules.

00:06:09.620 --> 00:06:12.570
If somebody says to
you, make it fast.

00:06:12.570 --> 00:06:14.570
Make it high-res.

00:06:14.570 --> 00:06:17.330
Well maybe you can't do
both of those things.

00:06:17.330 --> 00:06:19.600
So you have to choose or
you have to find some

00:06:19.600 --> 00:06:21.940
kind of trade off.

00:06:21.940 --> 00:06:25.240
It helps to understand where the
rules came from in order

00:06:25.240 --> 00:06:28.040
to be able to apply them.

00:06:28.040 --> 00:06:29.900
So I wrote this book that
was about that.

00:06:29.900 --> 00:06:33.730
That's basically about how the
human perceptual cognitive

00:06:33.730 --> 00:06:38.140
processor works, or I should
say processors--

00:06:38.140 --> 00:06:40.420
I'll get to that later.

00:06:40.420 --> 00:06:45.080
How it works and where do these
design rules come from,

00:06:45.080 --> 00:06:47.010
that's what the book "Designing
With the Mind in

00:06:47.010 --> 00:06:49.520
Min" is about.

00:06:49.520 --> 00:06:51.280
Books have chapters.

00:06:51.280 --> 00:06:55.840
So some of the chapters
deal with perception.

00:06:55.840 --> 00:07:00.550
I'm listing here on this slide
the perception chapters.

00:07:00.550 --> 00:07:04.970
And then there are some
chapters on cognition.

00:07:04.970 --> 00:07:07.670
I'm not going to talk about
everything that's in the book.

00:07:07.670 --> 00:07:10.040
It takes about two days to give
a tutorial that covers

00:07:10.040 --> 00:07:11.510
the entire book.

00:07:11.510 --> 00:07:12.940
And we have an hour.

00:07:12.940 --> 00:07:16.930
So I'm just going to cover a few
of the facts about human

00:07:16.930 --> 00:07:20.320
perception and cognition
in this talk, and

00:07:20.320 --> 00:07:21.710
show you some examples.

00:07:21.710 --> 00:07:24.840
So the first one is that we
perceive what we expect.

00:07:24.840 --> 00:07:27.490
What you are perceiving
right now is not

00:07:27.490 --> 00:07:30.700
what is really here.

00:07:30.700 --> 00:07:33.310
What you're perceiving
right now is biased

00:07:33.310 --> 00:07:36.620
heavily by many things.

00:07:36.620 --> 00:07:39.350
The main things that I'm going
to talk about right that bias

00:07:39.350 --> 00:07:45.580
your perception are the past,
the present, and the future.

00:07:45.580 --> 00:07:48.430
The past is your experience.

00:07:48.430 --> 00:07:51.230
The present is the current
context, everything else

00:07:51.230 --> 00:07:54.450
that's going on right now
in this situation.

00:07:54.450 --> 00:07:56.190
And the future is your goals.

00:07:56.190 --> 00:07:57.490
What are you planning to do?

00:07:57.490 --> 00:07:58.920
What are you trying to do?

00:07:58.920 --> 00:08:02.660
All of those things heavily
bias your perception.

00:08:02.660 --> 00:08:05.980
Your perception is almost in no
way reflective of what is

00:08:05.980 --> 00:08:08.390
actually out there
in the world.

00:08:08.390 --> 00:08:10.090
I'll put it that strongly.

00:08:10.090 --> 00:08:13.100
So I'm going to show
you some examples.

00:08:13.100 --> 00:08:14.530
How many of you are
familiar with the

00:08:14.530 --> 00:08:17.580
art of Jackson Pollock?

00:08:17.580 --> 00:08:19.390
So here's Jackson Pollock.

00:08:19.390 --> 00:08:21.590
He's landed a great gig.

00:08:21.590 --> 00:08:28.440
He gets money for throwing
paint onto canvases,

00:08:28.440 --> 00:08:30.820
splattering paint on canvases.

00:08:30.820 --> 00:08:34.799
What a great gig, I wish I could
get a gig like that.

00:08:34.799 --> 00:08:38.659
OK so I'm going to show you
a Jackson Pollock image, a

00:08:38.659 --> 00:08:39.909
Jackson Pollock painting.

00:08:45.840 --> 00:08:48.510
Everyone see the splatter
painting?

00:08:48.510 --> 00:08:52.680
OK so now I'm going to show
you something else.

00:08:52.680 --> 00:08:56.080
I'm going to show you
a dog sniffing the

00:08:56.080 --> 00:09:00.480
ground next to a tree.

00:09:00.480 --> 00:09:01.730
It's a Dalmatian.

00:09:04.827 --> 00:09:06.430
Does everyone see
the Dalmatian?

00:09:09.080 --> 00:09:10.330
So there's the dog.

00:09:12.790 --> 00:09:14.290
There's the tree.

00:09:14.290 --> 00:09:15.190
He's sniffing the ground.

00:09:15.190 --> 00:09:17.960
His tail's in the air, hind
feet, front feet.

00:09:20.940 --> 00:09:23.870
This is actually a famous image
by a guy named RC James.

00:09:27.120 --> 00:09:30.130
I could basically tell you what
you were going to see by

00:09:30.130 --> 00:09:32.240
showing you pictures of Jackson
Pollock painting and

00:09:32.240 --> 00:09:32.900
things like that.

00:09:32.900 --> 00:09:35.040
And then telling you
you were going to

00:09:35.040 --> 00:09:36.790
see a splatter painting.

00:09:36.790 --> 00:09:40.340
So basically the past influenced
your perception.

00:09:40.340 --> 00:09:42.590
Now I've told you it was
a Dalmatian, and then I

00:09:42.590 --> 00:09:43.290
showed it to you.

00:09:43.290 --> 00:09:46.640
And how many see the Dalmatian
by the way?

00:09:46.640 --> 00:09:47.490
It's about everyone.

00:09:47.490 --> 00:09:50.370
And now the interesting thing
is, if you ever see this

00:09:50.370 --> 00:09:53.940
picture again you'll never not
see the Dalmatian, ever again.

00:09:56.600 --> 00:10:00.170
So what does this have to do
with computer system design?

00:10:00.170 --> 00:10:05.770
Well let's assume that we have
a multi-page dialogue box,

00:10:05.770 --> 00:10:07.390
otherwise known as a wizard.

00:10:07.390 --> 00:10:08.870
So it's a multi-step
dialogue box.

00:10:08.870 --> 00:10:11.050
It doesn't matter what's
on the pages.

00:10:11.050 --> 00:10:15.580
So if you watch someone using a
wizard and a usability test,

00:10:15.580 --> 00:10:18.190
what you'll see is fairly
predictable.

00:10:18.190 --> 00:10:21.450
So basically they read what's
on page one, whatever it is.

00:10:21.450 --> 00:10:24.100
They fill out what whatever
fields are there.

00:10:24.100 --> 00:10:25.500
And they click Next.

00:10:28.630 --> 00:10:29.860
And it goes to page two.

00:10:29.860 --> 00:10:33.130
And so then they read on
whatever's on page two.

00:10:33.130 --> 00:10:34.820
And they fill out any fields.

00:10:34.820 --> 00:10:39.650
And they click Next and
it goes to page three.

00:10:39.650 --> 00:10:43.720
And then they fill it out, and
then they go to page four.

00:10:43.720 --> 00:10:45.962
And then they click
the Back button.

00:10:45.962 --> 00:10:48.000
And it goes back
to page three.

00:10:48.000 --> 00:10:52.440
And they say, why did it do
that, I clicked Next?

00:10:52.440 --> 00:10:56.590
And you say, no I was watching
you, you clicked Back.

00:10:56.590 --> 00:10:59.770
And they say, no I didn't
I clicked Next.

00:10:59.770 --> 00:11:01.990
And you say no, I was paying
attention to what you were

00:11:01.990 --> 00:11:03.850
doing and you clicked
the Back button.

00:11:03.850 --> 00:11:05.680
And then you take
the page four.

00:11:05.680 --> 00:11:09.350
And they, oh, the back button is
in the opposite place than

00:11:09.350 --> 00:11:12.370
it was on all the
other buttons.

00:11:12.370 --> 00:11:14.040
Of course they didn't notice
that because they weren't

00:11:14.040 --> 00:11:16.560
paying attention to the position
of the buttons.

00:11:16.560 --> 00:11:19.590
They were paying attention to
their task of whatever it was,

00:11:19.590 --> 00:11:22.720
buying an airline ticket,
reserving a hotel room,

00:11:22.720 --> 00:11:24.340
whatever it was.

00:11:24.340 --> 00:11:30.110
So their perception was based on
their past experience, not

00:11:30.110 --> 00:11:33.130
only with this dialog box, pages
one, two, and three, but

00:11:33.130 --> 00:11:37.550
with all previous wizards that
they've used before.

00:11:37.550 --> 00:11:41.210
So that biased their
perception.

00:11:41.210 --> 00:11:45.950
Now let's talk about current
context biasing perception.

00:11:45.950 --> 00:11:48.980
Here we have two symbols.

00:11:48.980 --> 00:11:49.680
They're identical.

00:11:49.680 --> 00:11:51.340
They're the same symbol.

00:11:51.340 --> 00:11:56.120
But depending on what context I
put them in, your eyes will

00:11:56.120 --> 00:11:59.140
perceive them, or more
accurately your brain, will

00:11:59.140 --> 00:12:03.190
perceive them as an H that's
kind of crooked or an A that's

00:12:03.190 --> 00:12:06.755
open at the top,
automatically.

00:12:10.960 --> 00:12:15.200
Or let's move away from the
domain of letters to the

00:12:15.200 --> 00:12:17.290
domain of graphics.

00:12:17.290 --> 00:12:19.350
So we have a line here.

00:12:19.350 --> 00:12:21.680
This is called the Muller-Lyer
Illusion.

00:12:21.680 --> 00:12:24.200
So we can take that line
and duplicate it.

00:12:24.200 --> 00:12:27.380
So now there are two of them,
exactly the same line.

00:12:27.380 --> 00:12:30.470
And then we put these on them
and now even though you know

00:12:30.470 --> 00:12:34.420
that it's the same line, your
eye sees the top one as longer

00:12:34.420 --> 00:12:36.570
than the bottom one.

00:12:36.570 --> 00:12:38.390
And you can't actually
stop yourself from

00:12:38.390 --> 00:12:39.640
seeing it that way.

00:12:42.650 --> 00:12:47.080
So this is context affecting
perception.

00:12:47.080 --> 00:12:51.880
Now here's the interesting thing
is that the brain is

00:12:51.880 --> 00:12:54.410
multi modal.

00:12:54.410 --> 00:12:56.230
As you know you have
many senses.

00:12:56.230 --> 00:13:00.770
And the context can
be cross model.

00:13:00.770 --> 00:13:12.840
The content influence, the
biasing of perception by

00:13:12.840 --> 00:13:16.500
sensory input can be from other
sensory modalities.

00:13:16.500 --> 00:13:19.110
So there's a famous effect
called the McGurk effect,

00:13:19.110 --> 00:13:21.030
which I'm just now going
to show you.

00:13:21.030 --> 00:13:23.890
Which is that based on what
you're looking at-- by the

00:13:23.890 --> 00:13:25.720
way, let me ask you this
question, how many

00:13:25.720 --> 00:13:26.970
of you can lip read?

00:13:31.000 --> 00:13:36.390
Well in fact you all can lip
read as you're about to see.

00:13:36.390 --> 00:13:40.270
Now I want you to listen to
what this man is saying.

00:13:40.270 --> 00:13:43.970
And I have to give credit to
some unidentified blogger on

00:13:43.970 --> 00:13:46.240
YouTube who put this
video on YouTube.

00:13:46.240 --> 00:13:48.700
It's probably the best
demonstration of this that

00:13:48.700 --> 00:13:51.250
I've seen and it's
unidentified.

00:13:51.250 --> 00:13:53.140
So I don't know who to credit.

00:13:53.140 --> 00:13:58.234
But I want you to watch
this video.

00:13:58.234 --> 00:13:59.802
MALE SPEAKER: Bah bah.

00:13:59.802 --> 00:14:02.134
Bah bah.

00:14:02.134 --> 00:14:03.126
Bah bah.

00:14:03.126 --> 00:14:04.614
Bah bah.

00:14:04.614 --> 00:14:05.606
Bah bah.

00:14:05.606 --> 00:14:08.582
Bah bah.

00:14:08.582 --> 00:14:10.566
Bah bah.

00:14:10.566 --> 00:14:11.558
Bah bah.

00:14:11.558 --> 00:14:13.542
Bah bah.

00:14:13.542 --> 00:14:15.030
Bah bah.

00:14:15.030 --> 00:14:16.050
Bah bah.

00:14:16.050 --> 00:14:18.640
JEFF JOHNSON: He's saying
the same sound.

00:14:18.640 --> 00:14:21.090
MALE SPEAKER: Bah bah.

00:14:21.090 --> 00:14:23.540
Bah bah.

00:14:23.540 --> 00:14:25.010
Bah bah.

00:14:25.010 --> 00:14:27.460
Bah bah.

00:14:27.460 --> 00:14:29.910
Bah bah.

00:14:29.910 --> 00:14:31.870
Bah bah.

00:14:31.870 --> 00:14:32.860
Bah bah.

00:14:32.860 --> 00:14:33.530
JEFF JOHNSON: You hear a
different sound depending on

00:14:33.530 --> 00:14:35.461
which guy you look at all.

00:14:35.461 --> 00:14:37.916
MALE SPEAKER: Bah bah.

00:14:37.916 --> 00:14:39.880
Bah bah.

00:14:39.880 --> 00:14:41.844
Bah bah.

00:14:41.844 --> 00:14:43.317
Bah bah.

00:14:43.317 --> 00:14:44.790
Bah bah.

00:14:44.790 --> 00:14:46.263
Bah bah.

00:14:46.263 --> 00:14:49.710
Bah bah.

00:14:49.710 --> 00:14:53.880
JEFF JOHNSON: That's an example
of your hearing being

00:14:53.880 --> 00:14:55.890
biased by what you're seeing.

00:14:55.890 --> 00:14:58.030
You can actually all lip read
and you didn't know it.

00:15:03.910 --> 00:15:07.600
And as I said earlier, the
future also biases your

00:15:07.600 --> 00:15:12.790
perception, your goals, what
you're intending to do.

00:15:12.790 --> 00:15:15.710
People, especially adults, tend
not to notice things that

00:15:15.710 --> 00:15:18.070
are unrelated to their goals.

00:15:18.070 --> 00:15:22.440
Our mind is designed to notice
the things that are related to

00:15:22.440 --> 00:15:24.960
what we're trying to do.

00:15:24.960 --> 00:15:29.050
So I'm going to show you the
contents of a toolbox.

00:15:29.050 --> 00:15:31.930
And I want you to tell me if
there are scissors in the

00:15:31.930 --> 00:15:33.390
toolbox, OK?

00:15:38.080 --> 00:15:40.240
Were there scissors?

00:15:40.240 --> 00:15:40.950
OK.

00:15:40.950 --> 00:15:42.200
Was there a wrench?

00:15:47.280 --> 00:15:50.180
Some people saw the wrench.

00:15:50.180 --> 00:15:54.050
So there is a game you
can play in your

00:15:54.050 --> 00:15:57.050
house if you have guests.

00:15:57.050 --> 00:15:58.380
I'll describe it quickly.

00:15:58.380 --> 00:16:00.340
Which is if you're sitting in
your living room and your

00:16:00.340 --> 00:16:02.290
guests are with you in the
living room, you can send them

00:16:02.290 --> 00:16:03.420
into the kitchen.

00:16:03.420 --> 00:16:06.120
And probably in your kitchen
somewhere you have a drawer

00:16:06.120 --> 00:16:08.000
that has random kitchen
stuff in it.

00:16:08.000 --> 00:16:09.330
I know I do.

00:16:09.330 --> 00:16:11.760
And you can tell them,
go to that drawer.

00:16:11.760 --> 00:16:13.480
It's the third one down from
the left next to the

00:16:13.480 --> 00:16:14.400
refrigerator.

00:16:14.400 --> 00:16:16.580
And get me the turkey baster.

00:16:16.580 --> 00:16:17.960
And bring it back.

00:16:17.960 --> 00:16:21.760
And then when they come back,
you say, was there a meat

00:16:21.760 --> 00:16:22.790
thermometer in the drawer?

00:16:22.790 --> 00:16:25.310
And they will have no idea.

00:16:25.310 --> 00:16:27.800
Most adults will have no idea.

00:16:27.800 --> 00:16:30.090
A six-year-old actually will
probably have a pretty good

00:16:30.090 --> 00:16:32.770
idea of all the other stuff in
the drawer if you can get them

00:16:32.770 --> 00:16:35.390
to come back in the first place
because of all the cool

00:16:35.390 --> 00:16:36.560
stuff that was in the drawer.

00:16:36.560 --> 00:16:40.020
But that's because their brain
isn't quite as goal directed

00:16:40.020 --> 00:16:42.570
as the adult's is.

00:16:42.570 --> 00:16:47.010
So in terms of website design
for example, if I put you on

00:16:47.010 --> 00:16:48.810
the home page of the
University of

00:16:48.810 --> 00:16:50.930
Canterbury's website.

00:16:50.930 --> 00:16:54.440
And I say I want you to find me
somewhere in this website a

00:16:54.440 --> 00:16:59.240
map of the campus that shows
the computer science

00:16:59.240 --> 00:17:04.910
department and where it is, your
behavior at that point is

00:17:04.910 --> 00:17:05.890
very predictable.

00:17:05.890 --> 00:17:13.010
What will happen is, your eyes
will start moving randomly

00:17:13.010 --> 00:17:17.010
around the screen
very quickly.

00:17:17.010 --> 00:17:22.079
Your eyes move 10 times a
second, tenths of a second per

00:17:22.079 --> 00:17:23.540
saccadic eye movement.

00:17:23.540 --> 00:17:25.819
Your eyes are moving very
quickly all the time in almost

00:17:25.819 --> 00:17:26.540
random motion.

00:17:26.540 --> 00:17:30.740
But because I gave you the goal
of looking for a map of

00:17:30.740 --> 00:17:33.380
the computer science department
on this website,

00:17:33.380 --> 00:17:36.510
your eyes will spend a lot of
time over these places, where

00:17:36.510 --> 00:17:40.680
it says departments, the word
departments, the campus map.

00:17:40.680 --> 00:17:44.230
And maybe also your eyes will
zero in on the search box

00:17:44.230 --> 00:17:46.160
because you're starting to
think about maybe typing

00:17:46.160 --> 00:17:48.850
something in there and looking
for search box.

00:17:48.850 --> 00:17:53.220
But you will probably exit the
page without ever noticing

00:17:53.220 --> 00:17:57.140
that you've been randomly
selected to win $100.

00:17:57.140 --> 00:17:59.140
Because nobody asked you
to look for that.

00:18:02.130 --> 00:18:04.470
Now I'm going to talk
about color vision.

00:18:04.470 --> 00:18:09.110
The human color vision system
is very unlike a camera.

00:18:09.110 --> 00:18:15.370
A digital camera is depicted
by this graph on the right.

00:18:15.370 --> 00:18:18.320
So on the right essentially what
we have is the spectrum

00:18:18.320 --> 00:18:20.090
across the bottom
of the graph.

00:18:20.090 --> 00:18:22.130
And what we have is,
in a camera--

00:18:22.130 --> 00:18:25.290
we have on the plate at the
back of the camera.

00:18:25.290 --> 00:18:29.520
We have a bunch of photo
sensitive unit.

00:18:29.520 --> 00:18:31.100
Cells you can call them.

00:18:31.100 --> 00:18:34.740
And a pixel is made
up of three cells.

00:18:34.740 --> 00:18:37.440
One that you would call
a red sensor.

00:18:37.440 --> 00:18:38.640
One you call a green sensor.

00:18:38.640 --> 00:18:40.260
And one you call
a blue sensor.

00:18:40.260 --> 00:18:45.700
The red sensors are sensitive
to light in a certain range.

00:18:45.700 --> 00:18:48.650
The green sensors are sensitive
to light in a

00:18:48.650 --> 00:18:49.470
certain range.

00:18:49.470 --> 00:18:51.440
And the blue have
a certain range.

00:18:51.440 --> 00:18:58.290
And notice those ranges overlap
a little bit and the

00:18:58.290 --> 00:19:01.100
amplitudes or the maximum
sensitivity of the three kinds

00:19:01.100 --> 00:19:03.860
of sensors are approximately
the same.

00:19:03.860 --> 00:19:06.050
It's designed that way.

00:19:06.050 --> 00:19:09.800
That isn't how the human eye
works at all in terms of color

00:19:09.800 --> 00:19:10.840
perception.

00:19:10.840 --> 00:19:13.490
The human eye has--

00:19:13.490 --> 00:19:15.390
well let me ask you
this question.

00:19:15.390 --> 00:19:18.470
How many of you remember from
high school or college that we

00:19:18.470 --> 00:19:26.370
have rods and cones and the
cones are for our color

00:19:26.370 --> 00:19:30.030
perception and the rods are for
black and white and sort

00:19:30.030 --> 00:19:31.430
of brightness?

00:19:31.430 --> 00:19:33.610
How many of you remember that?

00:19:33.610 --> 00:19:35.560
Well you can sort
of forget it.

00:19:35.560 --> 00:19:37.430
Because it's only partly true.

00:19:40.250 --> 00:19:47.140
The rods really we don't use
them very much in modern

00:19:47.140 --> 00:19:48.330
industrial society.

00:19:48.330 --> 00:19:52.270
They were designed for
use when we lived

00:19:52.270 --> 00:19:53.210
mostly in the dark.

00:19:53.210 --> 00:19:57.000
And let me ask you this, how
long ago was it that people

00:19:57.000 --> 00:19:59.770
lived their lives mostly
in the dark

00:19:59.770 --> 00:20:01.020
unless it was daytime?

00:20:05.010 --> 00:20:06.690
About 100 years ago.

00:20:06.690 --> 00:20:08.540
It was only about
100 years ago.

00:20:08.540 --> 00:20:13.860
So our ancestors, and all of
the animal ancestors before

00:20:13.860 --> 00:20:20.610
them, basically had these rods
which were designed to help us

00:20:20.610 --> 00:20:24.240
see in situations
of low light.

00:20:24.240 --> 00:20:28.210
But in the modern world in which
we live, where it's lit

00:20:28.210 --> 00:20:31.175
most of the time even at
night, our rods are

00:20:31.175 --> 00:20:32.340
completely maxed out.

00:20:32.340 --> 00:20:35.560
So they're screaming all the
time providing very much

00:20:35.560 --> 00:20:36.460
little information.

00:20:36.460 --> 00:20:38.840
You rods in your head right
now, in your eyes, are

00:20:38.840 --> 00:20:43.090
probably just going, ahhhh, like
that and not giving you

00:20:43.090 --> 00:20:44.090
much useful information.

00:20:44.090 --> 00:20:49.430
So let's forget about them for
the rest of this talk.

00:20:49.430 --> 00:20:51.965
Basically what happens
is you've got cones.

00:20:55.620 --> 00:20:58.110
They're called red, green,
and blue by biologists.

00:20:58.110 --> 00:21:00.720
But that's actually sort
of misleading.

00:21:00.720 --> 00:21:03.940
Because the red sensors are
sensitive over almost the

00:21:03.940 --> 00:21:06.770
entire range of what we
call visible light.

00:21:06.770 --> 00:21:09.750
The green ones are also
sensitive over almost the

00:21:09.750 --> 00:21:14.060
entire range, but not as
sensitive to light overall as

00:21:14.060 --> 00:21:15.030
the red ones.

00:21:15.030 --> 00:21:18.280
And the blue ones are hardly
sensitive to light at all, for

00:21:18.280 --> 00:21:20.090
those people who
have blue ones.

00:21:20.090 --> 00:21:22.130
Some people have
defective ones.

00:21:26.420 --> 00:21:30.470
So the human visual system
does not work the

00:21:30.470 --> 00:21:31.420
way a camera works.

00:21:31.420 --> 00:21:36.810
A camera visual system
essentially works by addition.

00:21:36.810 --> 00:21:41.090
Every pixel is the sum of the
red, green, and blue response

00:21:41.090 --> 00:21:43.540
to the light that's hitting
that pixel.

00:21:43.540 --> 00:21:46.390
That's the RGB value that
you're familiar with.

00:21:46.390 --> 00:21:48.820
The human visual system
can't work that way.

00:21:48.820 --> 00:21:54.330
Because how could it work that
way if the sensitivity ranges

00:21:54.330 --> 00:21:57.220
of the three kinds of cones
overlap so much?

00:21:57.220 --> 00:21:58.850
It could not work by addition.

00:21:58.850 --> 00:22:00.650
So it doesn't.

00:22:00.650 --> 00:22:01.900
It works by subtraction.

00:22:04.480 --> 00:22:07.330
So there are basically three
channels of information coming

00:22:07.330 --> 00:22:09.310
from your cones to your head.

00:22:09.310 --> 00:22:12.810
One of them is yellow minus
screen, or green minus yellow.

00:22:12.810 --> 00:22:14.390
I can't remember
exactly which.

00:22:14.390 --> 00:22:16.670
And the other one
is blue minus--

00:22:16.670 --> 00:22:19.740
sorry one is red minus
green and the other

00:22:19.740 --> 00:22:22.970
one's blue minus yellow.

00:22:22.970 --> 00:22:25.950
And then there's a third one,
which is such a complicated

00:22:25.950 --> 00:22:29.120
function of additions and
subtractions that produces

00:22:29.120 --> 00:22:31.090
brightness from the cones.

00:22:31.090 --> 00:22:33.710
So the cones are producing the
brightness information as well

00:22:33.710 --> 00:22:38.920
as the color information.

00:22:38.920 --> 00:22:43.180
And they are doing it by
subtraction not addition.

00:22:43.180 --> 00:22:47.330
Which makes our visual system
almost insensitive to absolute

00:22:47.330 --> 00:22:48.580
brightness levels.

00:22:50.620 --> 00:22:53.770
So if I take this illustration
which a college classmate of

00:22:53.770 --> 00:22:56.250
mine Edward Adelson produced.

00:22:56.250 --> 00:22:58.230
And you see the checkerboard.

00:22:58.230 --> 00:23:00.280
Can you see the there are
certain squares in the

00:23:00.280 --> 00:23:02.340
checkerboard marked a and b?

00:23:02.340 --> 00:23:04.530
Can you see that?

00:23:04.530 --> 00:23:08.130
What if I were to tell you that
the a square is the same

00:23:08.130 --> 00:23:11.450
shade of gray as the b square?

00:23:11.450 --> 00:23:14.560
It's the same shade.

00:23:14.560 --> 00:23:18.480
So I'll demonstrate that to you
by taking a piece out of

00:23:18.480 --> 00:23:20.270
each one with Photoshop
and putting it over

00:23:20.270 --> 00:23:21.900
there on the right.

00:23:21.900 --> 00:23:23.220
Now but you still don't
believe me.

00:23:23.220 --> 00:23:24.770
You think I cheated.

00:23:24.770 --> 00:23:28.530
So I'll take the image.

00:23:28.530 --> 00:23:29.670
Blow it up.

00:23:29.670 --> 00:23:31.750
And then I'll cover up that.

00:23:31.750 --> 00:23:36.820
Cover up that piece, that piece,
that piece, that piece,

00:23:36.820 --> 00:23:40.350
that piece, and that piece.

00:23:40.350 --> 00:23:43.490
So the human eye is really not
designed for detecting

00:23:43.490 --> 00:23:44.720
absolute brightness levels.

00:23:44.720 --> 00:23:49.360
It's designed for detecting
differences, edges, changes.

00:23:49.360 --> 00:23:51.230
That's what it's designed for.

00:23:51.230 --> 00:23:54.850
So what that means is that
humans have trouble

00:23:54.850 --> 00:23:57.950
discriminating certain
kinds of color pairs.

00:23:57.950 --> 00:24:03.530
So for example if two colors are
both pale, people may not

00:24:03.530 --> 00:24:05.590
be able to see the difference
between them depending on

00:24:05.590 --> 00:24:08.310
exactly how their
cones function.

00:24:10.860 --> 00:24:14.350
And also by the way on the kind
of display that they're

00:24:14.350 --> 00:24:15.460
looking at.

00:24:15.460 --> 00:24:17.160
Like for example I'm
looking at this on

00:24:17.160 --> 00:24:18.990
my Macintosh screen.

00:24:18.990 --> 00:24:22.740
And you're looking at it on
a projection display.

00:24:22.740 --> 00:24:26.980
And then there's also
these monitors here.

00:24:26.980 --> 00:24:33.340
And all of those can influence
how you see the two colors and

00:24:33.340 --> 00:24:35.540
whether you tell the difference
between them.

00:24:35.540 --> 00:24:38.400
So all you color designers out
there, you graphic designers

00:24:38.400 --> 00:24:41.000
who think you're in total
control of the color that your

00:24:41.000 --> 00:24:43.130
users are seeing, forget it.

00:24:43.130 --> 00:24:45.490
You are not in control.

00:24:45.490 --> 00:24:46.950
Their eyes are in control.

00:24:46.950 --> 00:24:49.090
And the displays that they're
using are in control.

00:24:51.690 --> 00:24:54.560
Similarly, people have trouble
discriminating color patches

00:24:54.560 --> 00:24:55.410
that are small.

00:24:55.410 --> 00:24:59.630
So if you have two color patches
that are very small

00:24:59.630 --> 00:25:01.550
and the colors are close to each
other people aren't going

00:25:01.550 --> 00:25:02.810
to be able to tell
the difference.

00:25:02.810 --> 00:25:06.680
But if you make the same color
patches larger, it'll be

00:25:06.680 --> 00:25:08.390
easier for people to
tell the difference

00:25:08.390 --> 00:25:10.610
between those two colors.

00:25:10.610 --> 00:25:12.940
So what does that say if you're
making a graph and

00:25:12.940 --> 00:25:15.360
you're putting the legend over
on the right or underneath the

00:25:15.360 --> 00:25:18.370
graph with little dots that show
you the different colors

00:25:18.370 --> 00:25:19.540
of the different lines?

00:25:19.540 --> 00:25:21.790
Make those legend dots big.

00:25:21.790 --> 00:25:24.210
Don't make them little
tiny squares.

00:25:24.210 --> 00:25:25.350
Because people won't
be able see the

00:25:25.350 --> 00:25:26.600
difference between them.

00:25:30.430 --> 00:25:34.020
Comparing colors is also
easier when patches are

00:25:34.020 --> 00:25:36.740
together than when they're
separated, especially if eye

00:25:36.740 --> 00:25:38.290
movement is involved.

00:25:38.290 --> 00:25:41.310
Because if I'm eye movement is
involved in the comparison,

00:25:41.310 --> 00:25:43.240
then memory is involved
in the comparison.

00:25:43.240 --> 00:25:45.720
So if I move these two together
it's easier to tell

00:25:45.720 --> 00:25:48.330
that they're different than
if they're separated.

00:25:48.330 --> 00:25:52.630
So if we look at ITN.net,
which is a website for

00:25:52.630 --> 00:25:57.160
ordering airplane tickets and
hotel reservations, and we see

00:25:57.160 --> 00:26:01.280
that they have said that they're
showing me what step

00:26:01.280 --> 00:26:02.960
of their process they're on.

00:26:02.960 --> 00:26:05.890
And they're trying to show me
that they're on step one.

00:26:05.890 --> 00:26:08.700
But they're using pale yellow
to mark the steps.

00:26:08.700 --> 00:26:09.940
So we're on step one.

00:26:09.940 --> 00:26:11.240
Now we're on step two.

00:26:11.240 --> 00:26:12.560
Can you see that change?

00:26:12.560 --> 00:26:14.150
Some of you can probably
see it and some of

00:26:14.150 --> 00:26:15.530
you probably can't.

00:26:15.530 --> 00:26:18.790
And it also will depend on the
display that you're using.

00:26:18.790 --> 00:26:20.630
Some people have color
blindness.

00:26:20.630 --> 00:26:24.440
So about 8% of males and about
a 0.5% of females have some

00:26:24.440 --> 00:26:26.660
kind of color vision
deficiency.

00:26:26.660 --> 00:26:31.530
Now color blindness does not
mean people can't see colors.

00:26:31.530 --> 00:26:33.360
The term color blindness
is misleading.

00:26:33.360 --> 00:26:35.770
What color blindness means is
that there are certain pairs

00:26:35.770 --> 00:26:38.530
of colors that people cannot
just tell apart.

00:26:38.530 --> 00:26:41.250
So for example a friend of mine
who's red green color

00:26:41.250 --> 00:26:43.340
blind cannot tell
the difference

00:26:43.340 --> 00:26:44.500
between these two lines.

00:26:44.500 --> 00:26:45.750
To him they look the same.

00:26:49.240 --> 00:26:51.880
Now just out of curiosity is
there anyone in this room for

00:26:51.880 --> 00:26:53.730
whom these two lines
look the same?

00:26:56.340 --> 00:26:59.120
We're looking for the
8% number here.

00:26:59.120 --> 00:27:02.930
OK so there's one.

00:27:02.930 --> 00:27:04.090
Now think about that.

00:27:04.090 --> 00:27:05.220
Think about that for a second.

00:27:05.220 --> 00:27:08.100
If you create a graph
in which different--

00:27:08.100 --> 00:27:13.330
let's say it's stock values over
time, Apple, Google, and

00:27:13.330 --> 00:27:16.730
various other stocks--

00:27:16.730 --> 00:27:19.430
and the lines cross.

00:27:19.430 --> 00:27:22.060
It's not just that the person
is not going to be able to

00:27:22.060 --> 00:27:24.670
tell which one is which.

00:27:24.670 --> 00:27:28.600
Wherever they cross they won't
even know which one goes on

00:27:28.600 --> 00:27:31.280
from that point.

00:27:31.280 --> 00:27:34.450
So it's really a serious
issue for people

00:27:34.450 --> 00:27:35.110
who are color blind.

00:27:35.110 --> 00:27:36.830
So you really have
to be careful.

00:27:36.830 --> 00:27:39.180
My friend who is colorblind also
can't tell the difference

00:27:39.180 --> 00:27:40.750
between these two lines.

00:27:40.750 --> 00:27:45.010
Now he's classified as
red green colorblind.

00:27:45.010 --> 00:27:50.990
But this line I would
call blue.

00:27:50.990 --> 00:27:52.870
The other one I would
call purple.

00:27:52.870 --> 00:27:54.730
But he still can't tell
the difference

00:27:54.730 --> 00:27:57.320
between these two lines.

00:27:57.320 --> 00:28:00.290
And this one, one is black
or dark brown and the

00:28:00.290 --> 00:28:02.100
other one is red.

00:28:07.520 --> 00:28:09.140
He can't tell the difference
between either

00:28:09.140 --> 00:28:10.390
of these two pairs.

00:28:12.820 --> 00:28:15.570
So you really have
to be careful.

00:28:15.570 --> 00:28:17.530
I don't want you to go out of
this room and say, Jeff

00:28:17.530 --> 00:28:20.280
Johnson says don't use color
in our user interfaces.

00:28:20.280 --> 00:28:22.820
Because that would
be pretty boring.

00:28:22.820 --> 00:28:25.900
What I'm saying is don't rely
solely on color to convey

00:28:25.900 --> 00:28:26.980
information.

00:28:26.980 --> 00:28:29.850
If you're conveying information
with color, use

00:28:29.850 --> 00:28:32.130
other cues that are redundant
with that.

00:28:32.130 --> 00:28:38.550
So for example, I would really
improve ITN.net's display by

00:28:38.550 --> 00:28:41.630
in addition to using a brighter,
more saturated

00:28:41.630 --> 00:28:47.330
yellow to mark the current step,
I would also bold the

00:28:47.330 --> 00:28:50.720
box and the word
and the number.

00:28:50.720 --> 00:28:53.060
Now how they improved it without
actually asking me.

00:28:53.060 --> 00:28:55.960
They never consulted with
me unfortunately.

00:28:55.960 --> 00:28:57.970
But that's fine.

00:28:57.970 --> 00:29:02.770
They improved it this way,
by making the step--

00:29:02.770 --> 00:29:08.970
sort of inverting its color and
putting the sort of blue

00:29:08.970 --> 00:29:10.220
area around it.

00:29:10.220 --> 00:29:11.270
Now that's just as good.

00:29:11.270 --> 00:29:14.670
So basically people are going
to be able to, regardless of

00:29:14.670 --> 00:29:18.590
what their color vision problem
is or what kind of

00:29:18.590 --> 00:29:20.600
monitor they're using, they're
going to be able to tell what

00:29:20.600 --> 00:29:21.540
step they're on.

00:29:21.540 --> 00:29:24.810
Now peripheral vision.

00:29:24.810 --> 00:29:27.890
Human peripheral vision
is very bad.

00:29:27.890 --> 00:29:29.410
It's very poor.

00:29:29.410 --> 00:29:30.920
There's an error message
on this screen.

00:29:30.920 --> 00:29:32.170
Does everyone see it?

00:29:36.330 --> 00:29:37.400
It's right there.

00:29:37.400 --> 00:29:43.020
This is an actual screen, a
login screen, of a web app

00:29:43.020 --> 00:29:46.030
that a client company
of mine created.

00:29:46.030 --> 00:29:47.970
This is an actual screen.

00:29:47.970 --> 00:29:50.890
And that's where the error
messages were displayed.

00:29:50.890 --> 00:29:54.940
And so in usability testing
here's what we saw.

00:29:54.940 --> 00:29:56.850
User types in ID.

00:29:56.850 --> 00:29:58.590
They type in pin number.

00:29:58.590 --> 00:30:02.570
And in some cases we gave them
incorrect IDs and pin numbers,

00:30:02.570 --> 00:30:05.480
so that they would get
an error message.

00:30:05.480 --> 00:30:10.220
And what happens is the user
types the ID, the pin number.

00:30:10.220 --> 00:30:13.220
And they hit login.

00:30:13.220 --> 00:30:15.620
And the screen re-displays.

00:30:15.620 --> 00:30:17.980
And the fields are blank.

00:30:17.980 --> 00:30:23.400
And the user goes, what?

00:30:23.400 --> 00:30:25.620
Why did the screen re-display?

00:30:25.620 --> 00:30:28.670
Why are the fields blank?

00:30:28.670 --> 00:30:30.240
I don't get it.

00:30:30.240 --> 00:30:31.490
I must have hit cancel.

00:30:34.540 --> 00:30:38.730
So they fill in the ID again,
which is still wrong and the

00:30:38.730 --> 00:30:42.190
pin number or one of
the two is wrong.

00:30:42.190 --> 00:30:44.600
And the screen re-displays
again.

00:30:44.600 --> 00:30:47.250
And they go, huh?

00:30:47.250 --> 00:30:48.060
Am I nuts?

00:30:48.060 --> 00:30:49.460
That time I was paying
attention.

00:30:49.460 --> 00:30:51.720
That time I know I hit
the login button.

00:30:51.720 --> 00:30:54.090
What is going on here?

00:30:54.090 --> 00:30:57.450
Oh, why didn't I see that
error message before?

00:31:00.320 --> 00:31:03.320
Here's why.

00:31:03.320 --> 00:31:05.910
There are actually three reasons
why they didn't see

00:31:05.910 --> 00:31:07.070
that error message before.

00:31:07.070 --> 00:31:10.890
And they all combined to make
peripheral vision of humans,

00:31:10.890 --> 00:31:14.220
and actually almost all
mammals, horrible.

00:31:17.710 --> 00:31:23.260
Reason number one is that what
we're seeing now in this graph

00:31:23.260 --> 00:31:25.650
is the distribution of rods and
cones across the retina.

00:31:28.600 --> 00:31:30.530
Now as I said earlier,
we can pretty much

00:31:30.530 --> 00:31:31.970
forget about the rods.

00:31:31.970 --> 00:31:34.460
But you can see that there's
non in the middle.

00:31:34.460 --> 00:31:36.160
There are no rods
in the middle.

00:31:36.160 --> 00:31:42.990
And then a little bit away
from the middle, they are

00:31:42.990 --> 00:31:43.660
pretty dense.

00:31:43.660 --> 00:31:48.190
And then the density falls off
as you get to the periphery.

00:31:48.190 --> 00:31:51.210
Cones on the other hand, are
very dense in the middle.

00:31:51.210 --> 00:31:55.870
That is to say there are 158,000
cone cells per square

00:31:55.870 --> 00:31:59.640
millimeter in your fovea,
in the center

00:31:59.640 --> 00:32:01.110
of your visual field.

00:32:01.110 --> 00:32:05.150
Now to give you an idea how big
a visual field is I want

00:32:05.150 --> 00:32:07.750
everyone to hold their arm
out at arm's length and

00:32:07.750 --> 00:32:09.870
hold your thumb up.

00:32:09.870 --> 00:32:10.980
And look at your thumbnail.

00:32:10.980 --> 00:32:13.390
Look directly at
your thumbnail.

00:32:13.390 --> 00:32:19.640
Your thumbnail spans the size of
your fovea on your retina.

00:32:19.640 --> 00:32:21.570
And the rest is periphery.

00:32:21.570 --> 00:32:23.340
Everything else is periphery.

00:32:23.340 --> 00:32:26.240
So your thumbnail is 1%.

00:32:26.240 --> 00:32:28.280
We've heard a lot recently
in the news about

00:32:28.280 --> 00:32:30.110
the 99% and the 1%.

00:32:30.110 --> 00:32:32.370
Here's another one.

00:32:32.370 --> 00:32:36.390
The 1% of your visual field in
the middle when you're looking

00:32:36.390 --> 00:32:37.570
directly at something.

00:32:37.570 --> 00:32:40.660
The 1% is the fovea.

00:32:40.660 --> 00:32:41.780
And that's high-res.

00:32:41.780 --> 00:32:43.910
Everything else is low-res.

00:32:43.910 --> 00:32:47.970
Everything else is low-res.

00:32:47.970 --> 00:32:49.740
And there are three reasons why

00:32:49.740 --> 00:32:51.940
everything else is low-res.

00:32:51.940 --> 00:32:55.880
Reason one is the density of the
cone cells in the middle

00:32:55.880 --> 00:32:59.140
is 158,000 per square
millimeter.

00:32:59.140 --> 00:33:03.400
And in the periphery, not very
far from the center, it falls

00:33:03.400 --> 00:33:07.270
off to 9,000 per square
millimeter.

00:33:07.270 --> 00:33:11.360
Now 9,000 is a lot per
square millimeter,

00:33:11.360 --> 00:33:15.750
but it's not 158,000.

00:33:15.750 --> 00:33:17.690
That make sense?

00:33:17.690 --> 00:33:23.340
That's reason one, high density
pixels in the middle,

00:33:23.340 --> 00:33:26.700
low density pixels
everywhere else.

00:33:26.700 --> 00:33:32.710
The other reason is that in your
retina, every cone cell

00:33:32.710 --> 00:33:39.450
in the fovea sends a fiber out
to the optic nerve that goes

00:33:39.450 --> 00:33:41.100
back to your visual cortex.

00:33:41.100 --> 00:33:44.965
Every nerve cell in the
fovea sends one fiber.

00:33:44.965 --> 00:33:48.580
The optic nerve that leaves
your eye that goes back to

00:33:48.580 --> 00:33:54.600
your visual cortex is a cable
with millions of fibers in it.

00:33:54.600 --> 00:33:58.480
Every cell in the middle of
your visual field, in that

00:33:58.480 --> 00:34:02.100
middle 1% sends a fiber out.

00:34:02.100 --> 00:34:04.500
In the periphery, which is
everything else on the other

00:34:04.500 --> 00:34:13.790
99% of your retina, three or
four cone cells combine to

00:34:13.790 --> 00:34:16.025
send one fiber.

00:34:18.540 --> 00:34:21.790
So what does that mean in
computer geek speak?

00:34:21.790 --> 00:34:25.620
It means the data coming from
the middle is uncompressed.

00:34:25.620 --> 00:34:30.656
And it's compressed with data
loss everywhere else.

00:34:30.656 --> 00:34:34.360
So you can think of it
as you got a TIFF in

00:34:34.360 --> 00:34:36.810
that middle 1%, high-res.

00:34:36.810 --> 00:34:42.600
And you've got a JPEG everywhere
else, low-res JPEG.

00:34:42.600 --> 00:34:45.560
And reason number three is that
when you get back to the

00:34:45.560 --> 00:34:48.000
visual cortex at the back of the
brain, which is called the

00:34:48.000 --> 00:34:52.699
occipital cortex,
there's a map.

00:34:52.699 --> 00:34:57.650
The occipital cortex forms
a map of the retina.

00:34:57.650 --> 00:35:03.320
But half of that map is devoted
to processing from the

00:35:03.320 --> 00:35:09.360
1% fovea area and the other
half is for the rest.

00:35:09.360 --> 00:35:11.440
So think about it that way.

00:35:11.440 --> 00:35:13.720
Your brain, your eyes--

00:35:13.720 --> 00:35:16.170
by the way biologists consider
your eyes to be part of your

00:35:16.170 --> 00:35:18.740
brain, but anyway.

00:35:18.740 --> 00:35:22.240
Your visual system is set
up unlike a camera in

00:35:22.240 --> 00:35:24.040
almost every way.

00:35:24.040 --> 00:35:26.450
Because a camera has its pixels
distributed evenly

00:35:26.450 --> 00:35:29.330
across its plate.

00:35:29.330 --> 00:35:33.080
The human eye has high
resolution in the middle and

00:35:33.080 --> 00:35:35.260
low resolution almost
everywhere else.

00:35:35.260 --> 00:35:38.330
So let me tell you, the
resolution of the human eye at

00:35:38.330 --> 00:35:43.540
the fovea is approximately 300
dots per inch at arm's length.

00:35:43.540 --> 00:35:47.845
If I print something on your
thumbnail at 300 dots per

00:35:47.845 --> 00:35:51.420
inch, if you have normal vision,
you can see the dots.

00:35:54.300 --> 00:36:00.990
What is the resolution of your
visual field at the edge?

00:36:00.990 --> 00:36:03.450
Guesses?

00:36:03.450 --> 00:36:04.700
How many dots per inch?

00:36:11.350 --> 00:36:14.590
It's measured in
dots per foot.

00:36:14.590 --> 00:36:16.980
The answer is three.

00:36:16.980 --> 00:36:20.320
The effective size of a pixel
at the edge of your visual

00:36:20.320 --> 00:36:23.710
field is approximately
the size of a

00:36:23.710 --> 00:36:26.230
cabbage at arm's length.

00:36:26.230 --> 00:36:28.370
Now everyone is rolling their
eyes and looking around the

00:36:28.370 --> 00:36:31.300
room and saying I see everything
in high-res.

00:36:31.300 --> 00:36:32.750
Your eyes move three
times a second.

00:36:32.750 --> 00:36:33.690
You can't control it.

00:36:33.690 --> 00:36:38.260
It takes a tenth of a second
for an eye movement.

00:36:38.260 --> 00:36:41.270
And by the way your vision
shuts off during those

00:36:41.270 --> 00:36:42.250
saccadic eye movements.

00:36:42.250 --> 00:36:44.550
But you don't see the
world in blinks.

00:36:44.550 --> 00:36:46.960
Here's an interesting exercise
you can do later.

00:36:46.960 --> 00:36:48.990
Which is, stand in front
of a mirror.

00:36:48.990 --> 00:36:50.700
Put your face right
on the mirror.

00:36:50.700 --> 00:36:51.680
And look at your left eye.

00:36:51.680 --> 00:36:52.710
Then look at your right eye.

00:36:52.710 --> 00:36:53.590
Then look at your left eye.

00:36:53.590 --> 00:36:54.870
Then look at your right eye.

00:36:54.870 --> 00:36:56.360
You will never see
your eyes move.

00:36:56.360 --> 00:36:58.470
But somebody standing there
watching you will see your

00:36:58.470 --> 00:36:59.870
eyes move back and forth.

00:36:59.870 --> 00:37:01.140
But you will not.

00:37:01.140 --> 00:37:04.650
What you will see is, you're
looking at your left eye.

00:37:04.650 --> 00:37:07.380
You're looking at right eye with
no time in the middle.

00:37:07.380 --> 00:37:10.380
That's because during saccadic
eye movements

00:37:10.380 --> 00:37:11.780
the brain shuts down.

00:37:11.780 --> 00:37:14.810
But it also is takes those two
pieces of video and stitches

00:37:14.810 --> 00:37:17.240
them together in time.

00:37:17.240 --> 00:37:18.935
So you never notice the little
black intervals.

00:37:22.620 --> 00:37:28.310
So if we look at this website
of Airborne.com, this login

00:37:28.310 --> 00:37:31.640
page, one of the things we see
is that there's an error

00:37:31.640 --> 00:37:34.330
message here in red over
on the upper left

00:37:34.330 --> 00:37:36.620
underneath the title.

00:37:36.620 --> 00:37:39.540
But it turns out people also
have trouble seeing that error

00:37:39.540 --> 00:37:44.270
message, because they pressed
a login button.

00:37:44.270 --> 00:37:46.940
Well now we know why.

00:37:46.940 --> 00:37:52.620
Because if we show what the
eye sees when a person has

00:37:52.620 --> 00:37:55.600
clicked the login button before
they move their eye at

00:37:55.600 --> 00:37:59.030
all, before the eye moves.

00:37:59.030 --> 00:38:01.870
This is what they see.

00:38:01.870 --> 00:38:05.470
This is what the eye sees at the
moment the login button is

00:38:05.470 --> 00:38:07.900
clicked, before the eye
moves anywhere else.

00:38:07.900 --> 00:38:11.200
And remember eye movement
is somewhat random.

00:38:11.200 --> 00:38:15.430
It is actually guided by goals
and many other things.

00:38:15.430 --> 00:38:20.310
But one of the things that can
make it move somewhere is

00:38:20.310 --> 00:38:21.840
movement or change.

00:38:21.840 --> 00:38:25.890
And the problem is there was
some red stuff in the upper

00:38:25.890 --> 00:38:28.550
left before and now there's
still some red stuff.

00:38:28.550 --> 00:38:31.320
So the eye doesn't really
see a change.

00:38:31.320 --> 00:38:34.270
So there's no reason for the
eye to actually move to the

00:38:34.270 --> 00:38:35.130
upper left.

00:38:35.130 --> 00:38:37.160
Therefore it's not going to
see that error message.

00:38:37.160 --> 00:38:40.050
Or at least there's a
probability that the eye will

00:38:40.050 --> 00:38:42.200
not see that error message.

00:38:42.200 --> 00:38:45.080
I think that the probability
that the eye will see this

00:38:45.080 --> 00:38:48.410
error message is higher than it
was in that previous one.

00:38:48.410 --> 00:38:51.490
But it's still not guaranteed.

00:38:51.490 --> 00:38:53.800
And of course this is why you
get in usability test--

00:38:53.800 --> 00:38:56.650
programmers in the back room
watching the usability test

00:38:56.650 --> 00:38:57.670
and saying, what's
wrong with you?

00:38:57.670 --> 00:38:58.240
Don't you see it?

00:38:58.240 --> 00:39:00.190
It's right there
on the screen.

00:39:00.190 --> 00:39:01.240
No because they're human.

00:39:01.240 --> 00:39:02.610
They don't see it.

00:39:02.610 --> 00:39:04.660
Because their eye was not
given a reason to

00:39:04.660 --> 00:39:05.910
move in that direction.

00:39:09.640 --> 00:39:14.380
So in terms of user interface
design, how do you make sure

00:39:14.380 --> 00:39:16.240
that error messages
can be seen, or

00:39:16.240 --> 00:39:17.690
information can be seen?

00:39:17.690 --> 00:39:19.240
Well put it where users
are looking if

00:39:19.240 --> 00:39:20.140
you can predict that.

00:39:20.140 --> 00:39:22.480
Put it near the error
if there's an error.

00:39:22.480 --> 00:39:24.650
Use red for errors.

00:39:24.650 --> 00:39:27.000
Or use an error symbol, like
one of these error symbols.

00:39:30.220 --> 00:39:31.680
Now here's an example of that.

00:39:31.680 --> 00:39:36.460
So for example at AOL.com, if
you sign up basically for

00:39:36.460 --> 00:39:38.030
their service there's
a long form.

00:39:38.030 --> 00:39:39.770
I haven't shown you
the whole form.

00:39:39.770 --> 00:39:41.980
You go down to fill out all
the stuff on the form.

00:39:41.980 --> 00:39:43.080
And then you clicked done.

00:39:43.080 --> 00:39:46.000
And if you've got a password
that they don't like for some

00:39:46.000 --> 00:39:48.080
reason, they will
send you back.

00:39:48.080 --> 00:39:50.970
They will scroll you back to
this place on the page.

00:39:50.970 --> 00:39:53.640
They put an error
symbol there.

00:39:53.640 --> 00:39:56.940
They tell you how good
your password was.

00:39:56.940 --> 00:39:58.770
They put an error message,
which is in red.

00:39:58.770 --> 00:40:01.050
They highlight the
field you're in.

00:40:01.050 --> 00:40:02.300
And they put the cursor there.

00:40:02.300 --> 00:40:03.550
You are not going
to miss that.

00:40:07.260 --> 00:40:10.170
Now there is some heavy
artillery that you can use to

00:40:10.170 --> 00:40:12.550
make sure people are going to
see error messages or other

00:40:12.550 --> 00:40:14.350
kinds of information.

00:40:14.350 --> 00:40:16.060
But you have to use
it carefully.

00:40:16.060 --> 00:40:18.840
You can pop up things and
error dialog boxes in

00:40:18.840 --> 00:40:21.090
front of the user.

00:40:21.090 --> 00:40:22.710
Some people hate that.

00:40:22.710 --> 00:40:25.750
Other people turn off pop
ups in their browser.

00:40:25.750 --> 00:40:30.490
So there's certain situations
in which that's not a useful

00:40:30.490 --> 00:40:31.320
thing to do.

00:40:31.320 --> 00:40:33.440
There's audio you can beep.

00:40:33.440 --> 00:40:35.730
But of course imagine a room
like this where everyone's got

00:40:35.730 --> 00:40:36.910
their computer and they're
all beeping.

00:40:36.910 --> 00:40:37.970
Whose is beeping?

00:40:37.970 --> 00:40:38.600
I can't tell.

00:40:38.600 --> 00:40:41.120
So audio is limited.

00:40:41.120 --> 00:40:44.230
Then there's flashing or
wiggling brief briefly but not

00:40:44.230 --> 00:40:45.430
continuously.

00:40:45.430 --> 00:40:49.615
If you flash or wiggle
constantly, some people will

00:40:49.615 --> 00:40:52.000
get epileptic seizures and other
people will not look at

00:40:52.000 --> 00:40:55.590
it because they assume
it's a ad.

00:40:55.590 --> 00:40:57.550
So for example, this is
something you're going to see

00:40:57.550 --> 00:40:59.640
more and more of in the future,
and you are starting

00:40:59.640 --> 00:41:01.630
to see more and more of
it in various places.

00:41:01.630 --> 00:41:03.670
Which is if you want to get
somebody's attention with an

00:41:03.670 --> 00:41:06.670
error message you wiggle it.

00:41:06.670 --> 00:41:09.360
That error message went one
pixel up, one pixel down, one

00:41:09.360 --> 00:41:11.480
pick left, one pixel right,
and then stopped.

00:41:11.480 --> 00:41:14.720
Stopping is very important.

00:41:14.720 --> 00:41:17.500
That will attract your eye.

00:41:17.500 --> 00:41:19.270
Why?

00:41:19.270 --> 00:41:22.200
Because it might be a leopard.

00:41:22.200 --> 00:41:24.750
Right?

00:41:24.750 --> 00:41:26.160
Your eye does not know
what that is.

00:41:26.160 --> 00:41:29.090
It just knows that there's
movement in the periphery.

00:41:29.090 --> 00:41:32.320
So it yanks the fovea right
over there because

00:41:32.320 --> 00:41:33.570
it might be a leopard.

00:41:42.270 --> 00:41:49.340
So blinking is a poor
substitution for wiggling if

00:41:49.340 --> 00:41:50.700
you can't wiggle.

00:41:50.700 --> 00:41:54.690
But it's better than nothing.

00:41:54.690 --> 00:41:57.940
But again the important
thing is to stop.

00:41:57.940 --> 00:41:59.680
OK I'm going to talk about
cognition now.

00:41:59.680 --> 00:42:03.320
I'm going to switch gears and
talk about cognition.

00:42:03.320 --> 00:42:04.960
Short term versus long
term memory.

00:42:04.960 --> 00:42:13.210
When I was in graduate school
cognitive psychologists

00:42:13.210 --> 00:42:15.310
believed there were places in
the brain where they was short

00:42:15.310 --> 00:42:17.170
term memory and there was other
places the brain where

00:42:17.170 --> 00:42:18.640
there was long term memory.

00:42:18.640 --> 00:42:21.550
And different brain structures
accounted for them.

00:42:21.550 --> 00:42:24.420
And they had models of short
term memory and models of long

00:42:24.420 --> 00:42:25.200
term memory.

00:42:25.200 --> 00:42:29.260
That's not the view anymore, now
that people can actually

00:42:29.260 --> 00:42:31.470
study the brain in
operation using

00:42:31.470 --> 00:42:34.070
magnetic resonance imagery.

00:42:34.070 --> 00:42:36.670
Now we know that short term
and long term memory are

00:42:36.670 --> 00:42:39.900
actually just two
characteristics of the same

00:42:39.900 --> 00:42:41.175
memory system operating.

00:42:43.820 --> 00:42:49.260
And short term memory is now
much more closely tied and

00:42:49.260 --> 00:42:53.520
interpreted as being tied to
perception and attention than

00:42:53.520 --> 00:42:58.940
it was in my graduate
school days.

00:42:58.940 --> 00:43:06.640
So short term memory is a
representation of your

00:43:06.640 --> 00:43:08.160
conscious mind.

00:43:08.160 --> 00:43:09.760
It's what you're attending
to right now.

00:43:09.760 --> 00:43:13.080
So short term memory
is not a place.

00:43:13.080 --> 00:43:17.360
It's not a place where things go
from perception and things

00:43:17.360 --> 00:43:20.210
are hauled in from
long term memory.

00:43:20.210 --> 00:43:23.080
It's not like an accumulator
in a computer.

00:43:23.080 --> 00:43:25.000
That's not what short
term memory is.

00:43:25.000 --> 00:43:28.750
Short term memory
is the stuff--

00:43:28.750 --> 00:43:29.860
think of it this way.

00:43:29.860 --> 00:43:33.860
Your memory system is
this huge warehouse.

00:43:33.860 --> 00:43:36.080
And everything in there
is old and dusty and

00:43:36.080 --> 00:43:37.340
covered with cobwebs.

00:43:37.340 --> 00:43:39.570
And occasionally something
new is shoved

00:43:39.570 --> 00:43:41.340
in through the doors.

00:43:41.340 --> 00:43:43.460
And while it's being shoved
into the doors it's

00:43:43.460 --> 00:43:45.650
illuminated because
the door is open.

00:43:45.650 --> 00:43:48.400
And then the door slams shut
and the stuff comes in.

00:43:48.400 --> 00:43:50.340
And it goes dark just like
everything else.

00:43:50.340 --> 00:43:52.990
Except that there are four
searchlights in the ceiling.

00:43:52.990 --> 00:43:56.310
And they can look at four
things at once.

00:43:56.310 --> 00:43:57.850
Four, not seven.

00:43:57.850 --> 00:44:02.150
How many remember the magical
number seven plus or minus two

00:44:02.150 --> 00:44:03.300
from your school days.

00:44:03.300 --> 00:44:05.840
That is now known to
be an overestimate.

00:44:05.840 --> 00:44:08.780
The actual capacity of
short term memory--

00:44:08.780 --> 00:44:11.720
and when I say capacity I
don't mean it's a place.

00:44:11.720 --> 00:44:12.880
It's not a bucket.

00:44:12.880 --> 00:44:16.130
But you have four searchlights
that can look at four things

00:44:16.130 --> 00:44:17.280
at the same time.

00:44:17.280 --> 00:44:18.330
Some people have five.

00:44:18.330 --> 00:44:19.850
But most people it's four.

00:44:19.850 --> 00:44:21.090
Four, plus or minus one.

00:44:21.090 --> 00:44:23.410
For dogs it's one, plus
or minus one.

00:44:28.980 --> 00:44:31.900
And so those four things that
those four searchlights can be

00:44:31.900 --> 00:44:34.430
looking at at any time are
things like goals, numbers,

00:44:34.430 --> 00:44:37.040
words, objects.

00:44:37.040 --> 00:44:40.730
If a search light is pulled away
from what it was looking

00:44:40.730 --> 00:44:45.270
at then the whole thing is lost
from short term memory.

00:44:45.270 --> 00:44:48.900
So short term memory is again--
it's not a place.

00:44:48.900 --> 00:44:53.110
It is what you're attending
to right now.

00:44:53.110 --> 00:44:56.860
So that's why you can have the
situation of sitting in your

00:44:56.860 --> 00:44:59.840
living room reading and then
hearing the cat meow.

00:44:59.840 --> 00:45:01.310
And saying, oh I have
to feed the cat.

00:45:01.310 --> 00:45:03.530
And getting up to go and
to feed the cat.

00:45:03.530 --> 00:45:05.350
And then having the phone ring
and then having your brother

00:45:05.350 --> 00:45:06.670
talk to you on the phone.

00:45:06.670 --> 00:45:09.130
Then you finish talking to your
brother on the phone and

00:45:09.130 --> 00:45:11.140
go sit down and go
back reading.

00:45:11.140 --> 00:45:14.400
Then the cat meows again
and you go oh, I

00:45:14.400 --> 00:45:15.500
forgot to feed the cat.

00:45:15.500 --> 00:45:18.960
Because your brother's call
pulled one of the search

00:45:18.960 --> 00:45:22.010
lights off your goal
of feeding the cat.

00:45:25.740 --> 00:45:27.980
So here's a short term
memory test.

00:45:27.980 --> 00:45:29.230
Memorize those numbers.

00:45:33.110 --> 00:45:35.690
Say your phone number
backwards.

00:45:35.690 --> 00:45:37.765
Say your phone number
backwards.

00:45:41.738 --> 00:45:43.130
Go ahead.

00:45:43.130 --> 00:45:45.170
You do it?

00:45:45.170 --> 00:45:46.420
OK, what were the numbers?

00:45:49.020 --> 00:45:50.270
Anyone know?

00:45:52.880 --> 00:45:54.130
OK, memorize these numbers.

00:45:58.620 --> 00:46:03.840
Now, if you notice something
about those numbers namely

00:46:03.840 --> 00:46:07.350
that they are the first seven
digits of pi, it now is not

00:46:07.350 --> 00:46:08.460
seven things to remember.

00:46:08.460 --> 00:46:11.030
It's one thing to remember.

00:46:11.030 --> 00:46:13.300
And your brain can do
it much more easily.

00:46:13.300 --> 00:46:14.550
Memorize these numbers.

00:46:17.580 --> 00:46:19.590
That's probably three bits.

00:46:19.590 --> 00:46:25.950
It's like odd numbers starting
at, ending at.

00:46:25.950 --> 00:46:27.200
Memorize those words.

00:46:30.140 --> 00:46:31.390
What are they?

00:46:35.340 --> 00:46:36.490
Not bad.

00:46:36.490 --> 00:46:39.390
Memorize those words.

00:46:39.390 --> 00:46:41.500
Same number of words.

00:46:41.500 --> 00:46:44.260
Same number of words,
one chunk.

00:46:44.260 --> 00:46:48.440
So if we go to this website
and we look at what it's

00:46:48.440 --> 00:46:50.980
showing us, it's showing
us search results.

00:46:50.980 --> 00:46:54.020
So somebody has done a
search and they're

00:46:54.020 --> 00:46:55.120
looking at the results.

00:46:55.120 --> 00:46:57.130
And here are the results
down here.

00:46:57.130 --> 00:47:02.890
And the website is nice because
it's giving us a way

00:47:02.890 --> 00:47:05.800
to fill in advanced search
options if we want to adjust

00:47:05.800 --> 00:47:06.600
our search.

00:47:06.600 --> 00:47:08.970
But there's something important
it's not showing us.

00:47:08.970 --> 00:47:10.220
What is that?

00:47:13.160 --> 00:47:14.960
What did we search for?

00:47:14.960 --> 00:47:17.020
And of course I'm going to
defend the programmer now and

00:47:17.020 --> 00:47:20.300
I'm going to say, well you only
put it in 10 seconds ago,

00:47:20.300 --> 00:47:21.425
what's wrong with you?

00:47:21.425 --> 00:47:24.210
Can't you remember something
for 10 seconds?

00:47:24.210 --> 00:47:27.360
No, because I'm human.

00:47:27.360 --> 00:47:30.570
I have four searchlights
in my brain.

00:47:30.570 --> 00:47:32.750
Maybe some of you are lucky
and you have five.

00:47:32.750 --> 00:47:36.470
But got a certain number
of searchlights.

00:47:36.470 --> 00:47:41.260
And they were totally pulled
away from my search terms by

00:47:41.260 --> 00:47:42.240
the search results.

00:47:42.240 --> 00:47:45.930
Because all my attention is
focused there trying to figure

00:47:45.930 --> 00:47:48.260
out, are those results
relevant to what

00:47:48.260 --> 00:47:49.510
I was looking for?

00:47:56.860 --> 00:48:00.960
Now long term memory is
that warehouse I was

00:48:00.960 --> 00:48:02.640
talking about earlier.

00:48:02.640 --> 00:48:04.810
And the memories in their--

00:48:04.810 --> 00:48:09.130
memories are also tied to
perception in the current view

00:48:09.130 --> 00:48:10.900
of cognitive psychologists.

00:48:10.900 --> 00:48:12.010
Think of it this way.

00:48:12.010 --> 00:48:16.670
If I look at his face, let's
say I look at Dan's face.

00:48:16.670 --> 00:48:20.150
What happens in my visual system
is starting at the

00:48:20.150 --> 00:48:23.910
visual cortex and moving forward
in my brain, millions

00:48:23.910 --> 00:48:25.230
of neurons fire.

00:48:25.230 --> 00:48:28.320
A huge pattern of
neurons fire.

00:48:28.320 --> 00:48:34.950
And that pattern is my
recognition of Dan's face.

00:48:34.950 --> 00:48:37.690
That's my memory
of Dan's face.

00:48:37.690 --> 00:48:43.260
And if I look at Ben, a
different set of neurons fire.

00:48:43.260 --> 00:48:46.920
It's very much similar because
he's human and he's human and

00:48:46.920 --> 00:48:51.990
he's you know about the
same age I guess.

00:48:51.990 --> 00:48:53.270
But they're not the same.

00:48:53.270 --> 00:48:55.660
And so I'm not going to--

00:48:55.660 --> 00:48:58.020
the thing is the human brain
can tell the difference

00:48:58.020 --> 00:49:00.800
between this pattern of a
million neurons and that

00:49:00.800 --> 00:49:03.700
pattern of a new million
neurons firing.

00:49:03.700 --> 00:49:07.350
And if I run into him-- if I run
into Dan on the street in

00:49:07.350 --> 00:49:12.150
San Francisco, another set
of neurons will fire.

00:49:12.150 --> 00:49:16.710
And it will be very similar
because he's the same guy.

00:49:16.710 --> 00:49:20.120
But it won't be the same because
we're in San Francisco

00:49:20.120 --> 00:49:20.840
and not in this room.

00:49:20.840 --> 00:49:24.370
And remember how we learned
earlier how context impacts

00:49:24.370 --> 00:49:26.830
perception.

00:49:26.830 --> 00:49:30.410
And so I might recognize Dan
on the street in Francisco.

00:49:30.410 --> 00:49:32.370
And I might not.

00:49:32.370 --> 00:49:35.820
Especially let's say if
he shaved his beard.

00:49:35.820 --> 00:49:39.970
Or what if I run into Dan's twin
brother on the streets of

00:49:39.970 --> 00:49:41.140
San Francisco.

00:49:41.140 --> 00:49:43.910
And I say, whoa, hi Dan.

00:49:43.910 --> 00:49:46.220
And his brother goes, what are
you some kind of pervert?

00:49:46.220 --> 00:49:47.860
Get away from me.

00:49:47.860 --> 00:49:49.260
Right?

00:49:49.260 --> 00:49:54.140
So here's the important thing
is that a huge pattern of

00:49:54.140 --> 00:49:55.630
neurons fires.

00:49:55.630 --> 00:49:57.190
That is recognition.

00:49:57.190 --> 00:49:58.840
That's what recognition is.

00:50:03.650 --> 00:50:06.970
And so experiences trigger
patterns corresponding to

00:50:06.970 --> 00:50:08.570
features in your brain.

00:50:08.570 --> 00:50:12.090
Your brain is a feature
recognition machine.

00:50:12.090 --> 00:50:13.920
That's what your brain is.

00:50:13.920 --> 00:50:16.740
And so similar experiences
trigger the same pattern.

00:50:16.740 --> 00:50:18.890
That's recognition.

00:50:18.890 --> 00:50:22.810
Recall, in contrast to
recognition, is something

00:50:22.810 --> 00:50:23.660
completely different.

00:50:23.660 --> 00:50:25.110
Imagine what recall is.

00:50:25.110 --> 00:50:29.790
Recall is a particular pattern
in your brain of millions of

00:50:29.790 --> 00:50:36.100
neurons becoming activated in
the absence of the stimulus

00:50:36.100 --> 00:50:38.670
that produce it in
the first place.

00:50:38.670 --> 00:50:40.350
That's hard.

00:50:40.350 --> 00:50:42.680
Your brain is actually not
designed for that.

00:50:42.680 --> 00:50:43.930
It's designed for recognition.

00:50:47.170 --> 00:50:51.380
Getting a particular pattern
of neurons to fire again,

00:50:51.380 --> 00:50:53.920
evoking a memory in the absence
of the stimulus that

00:50:53.920 --> 00:50:56.380
originally produced
it, is difficult.

00:50:56.380 --> 00:51:00.590
That's why recognition is
easy and recall is hard.

00:51:00.590 --> 00:51:04.940
And that's also why the fact
that these patterns are big

00:51:04.940 --> 00:51:09.320
collections of features is why
long term memory is error

00:51:09.320 --> 00:51:10.440
prone, impressionist, free

00:51:10.440 --> 00:51:13.080
associative, and easily biased.

00:51:13.080 --> 00:51:15.400
So for example, features
may get dropped from

00:51:15.400 --> 00:51:16.680
a particular memory.

00:51:16.680 --> 00:51:19.690
So you may have seen
a whale shark when

00:51:19.690 --> 00:51:21.010
you're out on the trip.

00:51:21.010 --> 00:51:23.470
And 20 years from now, you and
your brother argue about

00:51:23.470 --> 00:51:25.920
whether you saw a whale
or a shark.

00:51:25.920 --> 00:51:28.710
Because features got dropped
from that memory.

00:51:31.380 --> 00:51:32.770
So here's a long term
memory test.

00:51:35.930 --> 00:51:37.485
Was there a roll of tape
in the toolbox?

00:51:40.420 --> 00:51:42.270
Good.

00:51:42.270 --> 00:51:44.295
What was your last
phone number?

00:51:44.295 --> 00:51:46.990
The one before you have now.

00:51:46.990 --> 00:51:49.130
Anyone remember it?

00:51:49.130 --> 00:51:50.280
You do?

00:51:50.280 --> 00:51:52.610
Oh that's good.

00:51:52.610 --> 00:51:55.280
Was this a Pollock painting
or a Dalmatian?

00:51:55.280 --> 00:51:57.750
You'll never ever
see the Pollock

00:51:57.750 --> 00:52:00.750
painting in this again.

00:52:00.750 --> 00:52:02.370
So you shouldn't be
burdening long

00:52:02.370 --> 00:52:04.460
term memory as a designer.

00:52:04.460 --> 00:52:07.420
So for example here's an
instruction that a designer

00:52:07.420 --> 00:52:09.670
gave to a user.

00:52:09.670 --> 00:52:12.370
Which is kind of funny because
the designer knew that they

00:52:12.370 --> 00:52:15.780
were asking the user to do
something that users can't do.

00:52:15.780 --> 00:52:18.320
Change your pin to a number
that is easy to remember.

00:52:18.320 --> 00:52:19.380
That's part one.

00:52:19.380 --> 00:52:20.380
Part two.

00:52:20.380 --> 00:52:23.390
A pin can be 6 to 10 digits and
cannot start with zero.

00:52:23.390 --> 00:52:26.000
Your pin must be numeric.

00:52:26.000 --> 00:52:27.400
They have just given
you instructions

00:52:27.400 --> 00:52:28.650
that you cannot follow.

00:52:30.860 --> 00:52:31.890
And they know it.

00:52:31.890 --> 00:52:34.450
Because at the bottom it
says, remember please

00:52:34.450 --> 00:52:35.880
write down your pin.

00:52:35.880 --> 00:52:38.180
Put it on a yellow sticky
underneath your computer so

00:52:38.180 --> 00:52:41.040
that any guy can come
in and steal it.

00:52:46.840 --> 00:52:49.930
Having your brain keep track
of features, keeping those

00:52:49.930 --> 00:52:54.750
searchlights trained on certain
objects in your in

00:52:54.750 --> 00:52:56.410
your memory is work.

00:52:56.410 --> 00:52:58.660
It actually takes calories.

00:52:58.660 --> 00:53:02.430
And so your brain does it
as little as possible.

00:53:02.430 --> 00:53:06.350
So your brain tracks only
features crucial to the task.

00:53:06.350 --> 00:53:09.320
So that causes something called
change blindness.

00:53:09.320 --> 00:53:13.860
So if I show you that this
picture and then I change it,

00:53:13.860 --> 00:53:16.290
I want you to tell me if
there's any change.

00:53:16.290 --> 00:53:17.540
What has changed?

00:53:22.520 --> 00:53:23.770
What changed?

00:53:26.136 --> 00:53:30.620
OK, let me change it in a
different way so that I remove

00:53:30.620 --> 00:53:31.870
the pause in between.

00:53:35.910 --> 00:53:38.480
OK.

00:53:38.480 --> 00:53:41.300
So your brain is going to
focus on the people.

00:53:41.300 --> 00:53:43.390
Because you're human, your brain
will focus on the people

00:53:43.390 --> 00:53:44.850
and their food and the
beer probably.

00:53:47.410 --> 00:53:49.530
And so people say things like,
well he had a mustache in the

00:53:49.530 --> 00:53:51.290
first one and he didn't have a
mustache in the second one, or

00:53:51.290 --> 00:53:52.170
something like that.

00:53:52.170 --> 00:53:56.740
But no, it's things that are
irrelevant to what you're

00:53:56.740 --> 00:53:58.960
interested in that you aren't
going to notice.

00:54:04.120 --> 00:54:05.950
So I'm getting close
to the end.

00:54:05.950 --> 00:54:07.310
I'm like two slides
from the end.

00:54:07.310 --> 00:54:11.140
So as I said earlier,
recognition is easy.

00:54:11.140 --> 00:54:14.100
Recall is hard.

00:54:14.100 --> 00:54:16.550
We recognize things
extremely quickly.

00:54:22.380 --> 00:54:26.010
It doesn't take you very long,
especially if you're out in

00:54:26.010 --> 00:54:29.650
the wilderness, to notice
something like that.

00:54:29.650 --> 00:54:33.530
Because otherwise you wouldn't
be passing your genes on.

00:54:33.530 --> 00:54:35.990
I took this picture
by the way.

00:54:35.990 --> 00:54:37.455
Talk about getting into
the vehicle quickly.

00:54:45.010 --> 00:54:50.070
So Lucy walking around on the
African savanna 4 million

00:54:50.070 --> 00:54:53.540
years ago had to be able to
recognize objects very quickly

00:54:53.540 --> 00:54:54.790
otherwise we wouldn't be here.

00:54:59.350 --> 00:55:01.050
It doesn't take you very
long to recognize

00:55:01.050 --> 00:55:03.295
this face, these faces.

00:55:05.890 --> 00:55:09.650
And even more tellingly, it
doesn't take you very long to

00:55:09.650 --> 00:55:14.080
recognize that you don't
recognize these faces.

00:55:14.080 --> 00:55:17.790
And what this shows is that when
I was in graduate school,

00:55:17.790 --> 00:55:19.490
people thought of the
brain as a computer.

00:55:19.490 --> 00:55:22.190
And they were trying to figure
out what are the algorithms

00:55:22.190 --> 00:55:24.920
that the brain uses to
do face recognition.

00:55:24.920 --> 00:55:28.160
And so they said back in
those days, it can't

00:55:28.160 --> 00:55:29.580
be, is it this one?

00:55:29.580 --> 00:55:30.030
No.

00:55:30.030 --> 00:55:30.480
Is it this one?

00:55:30.480 --> 00:55:30.710
No.

00:55:30.710 --> 00:55:31.370
Is it this one?

00:55:31.370 --> 00:55:31.790
No.

00:55:31.790 --> 00:55:33.930
Can't be that because
it's way too fast.

00:55:33.930 --> 00:55:36.910
So they said, it has to be
something like, is it in this

00:55:36.910 --> 00:55:38.940
half of the database or is it in
this half of the database?

00:55:38.940 --> 00:55:39.540
It's in this half.

00:55:39.540 --> 00:55:40.100
OK.

00:55:40.100 --> 00:55:41.600
Take that and split
that in two.

00:55:41.600 --> 00:55:42.630
Is it in this half or
that half of the

00:55:42.630 --> 00:55:45.460
database, binary search.

00:55:45.460 --> 00:55:45.810
No.

00:55:45.810 --> 00:55:47.030
It's way too fast for that.

00:55:47.030 --> 00:55:49.580
Face recognition is
way too fast.

00:55:49.580 --> 00:55:51.770
So they came up with all these
algorithms back when I was in

00:55:51.770 --> 00:55:53.430
graduate school about
how the face

00:55:53.430 --> 00:55:55.020
recognition can be so fast.

00:55:55.020 --> 00:55:57.210
And now we know why
it's so fast.

00:55:57.210 --> 00:56:01.440
It's because the brain
does not search.

00:56:01.440 --> 00:56:07.460
The brain is a content
addressable

00:56:07.460 --> 00:56:11.210
holographic memory device.

00:56:11.210 --> 00:56:13.690
It's a recognition machine.

00:56:13.690 --> 00:56:15.740
Like I said, those big
patterns go off.

00:56:15.740 --> 00:56:19.290
So it's basically face
recognition and also

00:56:19.290 --> 00:56:21.740
recognition that you don't
recognize a face is almost

00:56:21.740 --> 00:56:24.260
instantaneous.

00:56:24.260 --> 00:56:25.310
It's not searching.

00:56:25.310 --> 00:56:26.560
There is no search.

00:56:31.670 --> 00:56:35.990
Similarly people can recognize
very sophisticated patterns

00:56:35.990 --> 00:56:42.460
like for example, Kasparov
versus Karpov, 1986.

00:56:42.460 --> 00:56:44.530
If you're a chess master
you'll recognize that.

00:56:44.530 --> 00:56:45.780
If you're not, you won't.

00:56:51.330 --> 00:56:55.350
Finally, I guess I'll talk
about performing learned

00:56:55.350 --> 00:56:59.430
routines versus new behaviors.

00:56:59.430 --> 00:57:02.980
Performing learned routines is
easy, like riding a bicycle

00:57:02.980 --> 00:57:05.610
after months of practice,
driving to the same workplace

00:57:05.610 --> 00:57:08.525
after many years, and using
a touch pad after a

00:57:08.525 --> 00:57:09.870
few years of practice.

00:57:09.870 --> 00:57:12.980
Now the reason that's easy
is it's automatic.

00:57:12.980 --> 00:57:16.650
Cognitive psychologists make a
distinction between what are

00:57:16.650 --> 00:57:20.580
called automatic processing
and controlled processing.

00:57:20.580 --> 00:57:24.520
Automatic processing uses
lots of different

00:57:24.520 --> 00:57:25.760
parts of your brain.

00:57:25.760 --> 00:57:28.390
It doesn't use up short
term memory.

00:57:28.390 --> 00:57:31.580
So it's not using up those
four searchlights.

00:57:31.580 --> 00:57:34.160
It's what we computer scientists
would call compiled

00:57:34.160 --> 00:57:36.830
mode or parallel processing.

00:57:36.830 --> 00:57:38.720
There are many processors.

00:57:38.720 --> 00:57:42.690
You can multitask automatic
things.

00:57:42.690 --> 00:57:45.210
So one way I think of it is that
every part of the brain

00:57:45.210 --> 00:57:48.040
is a brain.

00:57:48.040 --> 00:57:50.250
And so things that are automatic
and running in

00:57:50.250 --> 00:57:53.310
compiled mode essentially,
you can do many of

00:57:53.310 --> 00:57:54.100
them at the same time.

00:57:54.100 --> 00:57:58.100
That's why I can walk and chew
gum at the same time, or I can

00:57:58.100 --> 00:58:01.410
be whistling a tune that I've
very familiar with.

00:58:01.410 --> 00:58:05.870
But try to do that with
something new, following a new

00:58:05.870 --> 00:58:08.110
cooking recipe, driving
somewhere you've never been,

00:58:08.110 --> 00:58:10.950
writing with your non-dominant
hand, switching from Mac to

00:58:10.950 --> 00:58:13.390
Windows PC or vice versa.

00:58:13.390 --> 00:58:15.220
That's controlled.

00:58:15.220 --> 00:58:17.780
That consumes short term
memory and attention.

00:58:17.780 --> 00:58:19.420
It's what we computer scientists
would call

00:58:19.420 --> 00:58:22.660
interpreted mode or
serial processing.

00:58:22.660 --> 00:58:24.680
There's only one processor
there.

00:58:24.680 --> 00:58:27.410
It's called the attention.

00:58:27.410 --> 00:58:30.690
There's only one processor
and you cannot multitask.

00:58:30.690 --> 00:58:36.880
So you can only do one novel
thing at a time.

00:58:36.880 --> 00:58:39.340
You can multitask a novel
thing with an automatic

00:58:39.340 --> 00:58:42.140
things, any number of them.

00:58:42.140 --> 00:58:44.680
So let's just do a test.

00:58:44.680 --> 00:58:48.540
Recite the alphabet A to
M. Go ahead recite the

00:58:48.540 --> 00:58:52.080
alphabet A to M. Easy.

00:58:52.080 --> 00:58:58.130
Recite backwards, M to A. That's
controlled, requires

00:58:58.130 --> 00:59:01.520
short term memory, requires
attention.

00:59:01.520 --> 00:59:05.136
Hum the first measure of
"Twinkle Twinkle Little Star."

00:59:05.136 --> 00:59:06.386
Go ahead, do it.

00:59:08.810 --> 00:59:10.060
Hum it backwards.

00:59:12.360 --> 00:59:16.090
Control processing requires
short term memory, requires

00:59:16.090 --> 00:59:19.340
attention, full attention.

00:59:19.340 --> 00:59:23.720
So all of the things that
I showed you is why user

00:59:23.720 --> 00:59:27.290
interface design is a skill not
something anyone can do by

00:59:27.290 --> 00:59:30.330
following user interface
guidelines.

00:59:30.330 --> 00:59:32.730
And that's why knowing the
cognitive basis helps us

00:59:32.730 --> 00:59:35.280
prioritize and recognize
which rules to

00:59:35.280 --> 00:59:38.490
follow in each situation.

00:59:38.490 --> 00:59:42.830
Now I'll take any questions
that anyone has for

00:59:42.830 --> 00:59:45.438
as long as you want.

00:59:45.438 --> 00:59:47.426
[APPLAUSE]

00:59:47.426 --> 00:59:48.676
JEFF JOHNSON: Thanks.

00:59:53.400 --> 00:59:54.260
Yes?

00:59:54.260 --> 00:59:56.265
MALE SPEAKER: So this model of
short term and long term

00:59:56.265 --> 00:59:58.668
memory that you were discussing,
how is this

00:59:58.668 --> 01:00:00.880
consistent with the fact that
there's a phenomenon where

01:00:00.880 --> 01:00:05.396
people go unconscious in
accidents or concussions lost

01:00:05.396 --> 01:00:07.112
memory of the four or five
minutes preceding the

01:00:07.112 --> 01:00:11.335
accident, people take Versed
and not lay down

01:00:11.335 --> 01:00:12.810
the memory as well?

01:00:15.810 --> 01:00:17.880
So that model seemed, or that
close result seemed to

01:00:17.880 --> 01:00:20.203
[INAUDIBLE] the old model of
it being a different short

01:00:20.203 --> 01:00:21.010
term memory [INAUDIBLE].

01:00:21.010 --> 01:00:25.650
JEFF JOHNSON: Yeah one of the
things that had been noticed

01:00:25.650 --> 01:00:28.340
when I was in graduate school
was that people come back from

01:00:28.340 --> 01:00:31.220
combat situations with certain
parts of their brain shot away

01:00:31.220 --> 01:00:33.830
or auto accidents or whatever.

01:00:33.830 --> 01:00:36.230
Some of them can remember
new things.

01:00:36.230 --> 01:00:38.460
And others can't.

01:00:38.460 --> 01:00:41.200
And another phenomenon like
the ones you described.

01:00:41.200 --> 01:00:43.740
And so that's why they sort of
thought there had to do these

01:00:43.740 --> 01:00:47.120
certain places where there was
short term memory and other

01:00:47.120 --> 01:00:48.300
places where there was
long term memory.

01:00:48.300 --> 01:00:53.240
And what they now know or now
believe is that there are

01:00:53.240 --> 01:00:57.510
certain areas of the brain that
are essentially gateways.

01:00:57.510 --> 01:01:03.030
They're sort of bottlenecks
for information.

01:01:03.030 --> 01:01:07.790
And if those are shot away or
damaged, then the ability for

01:01:07.790 --> 01:01:11.800
the brain to sort of generate
and compare these patterns

01:01:11.800 --> 01:01:15.950
becomes destroyed.

01:01:15.950 --> 01:01:22.170
So that's basically it.

01:01:22.170 --> 01:01:25.500
It's now thought of as instead
of that short term memory

01:01:25.500 --> 01:01:27.190
here, let's say in
the hippocampus.

01:01:27.190 --> 01:01:29.090
Because that's where they used
to think it was when I was in

01:01:29.090 --> 01:01:31.480
graduate school.

01:01:31.480 --> 01:01:35.390
Is that the hippocampus
is somehow--

01:01:35.390 --> 01:01:38.310
well remember I said earlier
that the human brain can

01:01:38.310 --> 01:01:40.190
compare patterns and can
tell whether it's

01:01:40.190 --> 01:01:42.270
seen a pattern before.

01:01:42.270 --> 01:01:46.840
They don't know why that is, but
maybe it's possible that

01:01:46.840 --> 01:01:50.720
the hippocampus is involved in
that, in that comparison.

01:01:50.720 --> 01:01:59.220
So I guess what I'm saying is
that now the understanding of

01:01:59.220 --> 01:02:03.490
short term memory versus long
term memory is not as cut and

01:02:03.490 --> 01:02:08.490
dry as it was back in the '70s,
when they thought that

01:02:08.490 --> 01:02:10.430
short term memory is in the
hippocampus and long term

01:02:10.430 --> 01:02:13.800
memory is in the cerebral cortex
or something like that.

01:02:13.800 --> 01:02:15.530
I don't know if that answers
your question.

01:02:15.530 --> 01:02:18.170
MALE SPEAKER: Well it doesn't
explain those phenomena, but

01:02:18.170 --> 01:02:19.540
maybe I have to look
deeper for that.

01:02:19.540 --> 01:02:20.000
I understand that.

01:02:20.000 --> 01:02:22.280
JEFF JOHNSON: So say exactly
what the phenomena was.

01:02:22.280 --> 01:02:23.521
MALE SPEAKER: The phenomena
that somebody in the car

01:02:23.521 --> 01:02:26.900
accident doesn't remember three
minutes before the car

01:02:26.900 --> 01:02:31.050
accident, which normally would
have been laid down in short

01:02:31.050 --> 01:02:32.940
term memory or long term,
whatever you want to call it.

01:02:32.940 --> 01:02:36.200
JEFF JOHNSON: Right and so there
is some process by which

01:02:36.200 --> 01:02:39.570
stuff comes in from perception
and gets put

01:02:39.570 --> 01:02:42.680
into long term memory.

01:02:42.680 --> 01:02:45.670
I mean one of the things that
we know now which is kind of

01:02:45.670 --> 01:02:46.210
interesting.

01:02:46.210 --> 01:02:49.120
If you're a musician, they know
now that it's better to

01:02:49.120 --> 01:02:52.830
practice for 15 minutes and then
sleep than to practice

01:02:52.830 --> 01:02:53.730
for eight hours.

01:02:53.730 --> 01:02:56.700
Because the sleep has something
to do with the stuff

01:02:56.700 --> 01:02:58.620
you practice getting
laid down.

01:03:03.210 --> 01:03:05.988
So I don't know if I can answer
your question fully.

01:03:05.988 --> 01:03:09.860
MALE SPEAKER: Peripheral
vision-- sometimes people talk

01:03:09.860 --> 01:03:13.006
about athletes like pro
quarterbacks having great

01:03:13.006 --> 01:03:14.700
peripheral vision.

01:03:14.700 --> 01:03:19.080
Has that been tested
[INAUDIBLE]?

01:03:19.080 --> 01:03:21.180
JEFF JOHNSON: Well I wouldn't
doubt it since there's all

01:03:21.180 --> 01:03:23.580
sorts of genetic variation
and there's a lot of

01:03:23.580 --> 01:03:25.390
randomness in our genes.

01:03:25.390 --> 01:03:31.940
And so that's why for example
those people 4 million years

01:03:31.940 --> 01:03:34.690
ago who could actually see the
leopard coming at them are the

01:03:34.690 --> 01:03:35.520
ones who survived.

01:03:35.520 --> 01:03:37.740
And those who didn't see
the leopard, maybe the

01:03:37.740 --> 01:03:40.510
neanderthals, are not.

01:03:40.510 --> 01:03:41.710
[INTERPOSING VOICES]

01:03:41.710 --> 01:03:50.290
JEFF JOHNSON: Not that I know
of but one thing that--

01:03:50.290 --> 01:03:53.810
have ever heard of
the "Door" study?

01:03:53.810 --> 01:03:56.570
Go to YouTube and type
in the "Door" study.

01:03:56.570 --> 01:03:59.910
So that's a situation where
it's not really peripheral

01:03:59.910 --> 01:04:02.430
vision, it's more has to do
with change blindness.

01:04:02.430 --> 01:04:08.780
But basically if you get someone
in a situation where

01:04:08.780 --> 01:04:10.390
you change out a person
in front of.

01:04:10.390 --> 01:04:12.150
They're interacting with a
person and you change the

01:04:12.150 --> 01:04:15.220
person out.

01:04:15.220 --> 01:04:16.190
A lot of people don't notice.

01:04:16.190 --> 01:04:17.950
But some people do.

01:04:17.950 --> 01:04:19.950
And they don't know yet
whether there's any

01:04:19.950 --> 01:04:23.070
systematic-ness to that or
whether it's just random.

01:04:23.070 --> 01:04:26.926
MALE SPEAKER: I was wondering,
do you recommend--

01:04:26.926 --> 01:04:31.770
should some user interfaces or
types of interactions rely

01:04:31.770 --> 01:04:37.560
more on long term memory and
others have to be designed for

01:04:37.560 --> 01:04:40.310
a situation where someone has
to keep track of something

01:04:40.310 --> 01:04:42.334
right then?

01:04:42.334 --> 01:04:45.860
How do we apply this
in that way?

01:04:45.860 --> 01:04:49.910
JEFF JOHNSON: OK so it's
certainly the case that some

01:04:49.910 --> 01:04:53.080
user interfaces are designed
to be walk up and use.

01:04:53.080 --> 01:04:56.610
Or at least to be used in a
situation where it's been a

01:04:56.610 --> 01:04:59.040
year since you walked up
and used it before.

01:04:59.040 --> 01:05:00.840
And so you're not going
to remember details.

01:05:00.840 --> 01:05:05.710
Like for example, recovering
files from a backup system,

01:05:05.710 --> 01:05:07.990
how often are you going
to have to do that?

01:05:07.990 --> 01:05:10.650
So that user interface is
probably going to have to be

01:05:10.650 --> 01:05:14.270
designed differently from the
user interface for handling

01:05:14.270 --> 01:05:16.960
your email, which you do
every morning for half

01:05:16.960 --> 01:05:19.030
an hour or an hour.

01:05:19.030 --> 01:05:27.860
So people who design walk up and
use interfaces really have

01:05:27.860 --> 01:05:30.650
a different sort of mindset,
design mindset, than the

01:05:30.650 --> 01:05:33.880
people who are designing user
interfaces that are going to

01:05:33.880 --> 01:05:35.710
be used by which people
who have a lot of

01:05:35.710 --> 01:05:37.360
experience and training.

01:05:37.360 --> 01:05:41.350
I'm not sure that exactly gets
on your question which was--

01:05:41.350 --> 01:05:47.150
MALE SPEAKER: Yeah, I think
that ties into it.

01:05:47.150 --> 01:05:53.430
JEFF JOHNSON: Yeah,
the thing is air

01:05:53.430 --> 01:05:55.610
traffic control for example.

01:05:55.610 --> 01:06:02.070
Intense information overload all
the time, and also extreme

01:06:02.070 --> 01:06:04.420
danger if you screw up.

01:06:04.420 --> 01:06:11.770
So that user interface has to
really support making sure

01:06:11.770 --> 01:06:12.760
that you can see things.

01:06:12.760 --> 01:06:14.790
So peripheral vision
for example.

01:06:14.790 --> 01:06:21.670
If there are planes over here,
but you're looking over here,

01:06:21.670 --> 01:06:23.105
they have to somehow
get your attention.

01:06:26.810 --> 01:06:29.510
Actually a lot of people these
days are thinking about user

01:06:29.510 --> 01:06:35.440
interfaces for security guards
at airports and places like

01:06:35.440 --> 01:06:36.850
that, security checkpoints.

01:06:36.850 --> 01:06:39.590
Because think about that job.

01:06:39.590 --> 01:06:43.630
Nothing happens for months or
even years at a time and then

01:06:43.630 --> 01:06:44.400
something happens.

01:06:44.400 --> 01:06:46.600
And you have to be attentive.

01:06:46.600 --> 01:06:49.760
But it's hard to be attentive
when you've been bored for

01:06:49.760 --> 01:06:51.250
three years.

01:06:51.250 --> 01:06:54.750
So how do you design a user
interface to make sure that

01:06:54.750 --> 01:06:59.050
someone notices something is
happening now when nothing has

01:06:59.050 --> 01:07:03.700
happened for the last
three years?

01:07:03.700 --> 01:07:06.000
So there's a lot of attention
being paid to

01:07:06.000 --> 01:07:09.280
that particular problem.

01:07:09.280 --> 01:07:10.860
OK, thank you.

