WEBVTT
Kind: captions
Language: en

00:00:10.550 --> 00:00:11.820
DAN GALPIN: All right.

00:00:11.820 --> 00:00:13.320
Thank you to
everyone-- you got up

00:00:13.320 --> 00:00:15.990
so early this beautiful
Friday morning

00:00:15.990 --> 00:00:18.720
after the fabulous
party we had last night.

00:00:18.720 --> 00:00:21.092
And for everyone who
is attending virtually,

00:00:21.092 --> 00:00:22.800
you know, I'm sorry
you missed out on it,

00:00:22.800 --> 00:00:24.670
but I'm sure there's
plenty of footage and video

00:00:24.670 --> 00:00:26.310
and all this kind
of stuff from that.

00:00:26.310 --> 00:00:28.037
Because it was pretty
fun, and I'm sure

00:00:28.037 --> 00:00:29.370
people are a little bleary-eyed.

00:00:29.370 --> 00:00:33.410
So thank you to those
hardcore native developers

00:00:33.410 --> 00:00:38.067
who came out here, and
let's see if this works.

00:00:40.690 --> 00:00:41.190
I got lucky.

00:00:41.190 --> 00:00:45.010
All right, so NDK
performance in an ART world.

00:00:45.010 --> 00:00:48.420
How many people here
are NDK developers?

00:00:48.420 --> 00:00:49.000
All right.

00:00:49.000 --> 00:00:49.750
This is good.

00:00:49.750 --> 00:00:50.050
This is good.

00:00:50.050 --> 00:00:51.425
I'm excited to
see so many people

00:00:51.425 --> 00:00:53.110
out there who are doing this.

00:00:53.110 --> 00:00:55.040
This is a labor of
love for me, this talk,

00:00:55.040 --> 00:00:56.360
so I'm really glad
you guys are here.

00:00:56.360 --> 00:00:58.443
And you know, there's a
lot of Android development

00:00:58.443 --> 00:01:00.560
where you get to just
blissfully ignore

00:01:00.560 --> 00:01:02.650
a lot of what's going on
in the operating system.

00:01:02.650 --> 00:01:04.446
You know, "take the blue pill."

00:01:04.446 --> 00:01:06.320
You don't really need
to know what's going on

00:01:06.320 --> 00:01:08.580
and how the Matrix
is formed-- you just

00:01:08.580 --> 00:01:13.240
get to go and code in a
nice, beautiful environment

00:01:13.240 --> 00:01:14.460
in managed code.

00:01:14.460 --> 00:01:17.200
But today, we're actually
going to take the red pill.

00:01:17.200 --> 00:01:20.090
We're going to get a little
bit inside to how things work.

00:01:20.090 --> 00:01:21.380
And I hope it's fun.

00:01:21.380 --> 00:01:24.540
And whether or not it's useful
or not, you can tell me,

00:01:24.540 --> 00:01:27.587
but at least hopefully we'll
all learn something from this.

00:01:27.587 --> 00:01:29.670
And of course, when I'm
talking about native code,

00:01:29.670 --> 00:01:32.750
I'm referring specifically to
unmanaged code that does not

00:01:32.750 --> 00:01:33.750
use the Android runtime.

00:01:33.750 --> 00:01:35.791
And one of the primary
reasons that people end up

00:01:35.791 --> 00:01:37.690
creating this code
is that they already

00:01:37.690 --> 00:01:39.010
have a bunch of working C code.

00:01:39.010 --> 00:01:41.140
You know, when you have
a lot of code that works,

00:01:41.140 --> 00:01:43.030
you create new code,
you just create bugs.

00:01:43.030 --> 00:01:44.380
No one wants to do that.

00:01:44.380 --> 00:01:47.540
Now, of course, your
legacy code might not

00:01:47.540 --> 00:01:51.030
include support for really
awesome multiprocessing,

00:01:51.030 --> 00:01:54.182
or might not have support
for NEON Intrinsics.

00:01:54.182 --> 00:01:56.640
So even though it's awesome
that you have this legacy code,

00:01:56.640 --> 00:01:58.098
you're not always
guaranteed to get

00:01:58.098 --> 00:02:00.980
the best performance with it.

00:02:00.980 --> 00:02:02.720
That being said,
performance-- there's

00:02:02.720 --> 00:02:05.178
a lot of people who write NDK
code for performance reasons.

00:02:05.178 --> 00:02:07.876
How many people are doing it for
performance reasons out there?

00:02:07.876 --> 00:02:09.500
How about cross-platform
compatibility?

00:02:09.500 --> 00:02:11.310
Let me just have
a show of hands.

00:02:11.310 --> 00:02:14.062
OK, so it's about the same.

00:02:14.062 --> 00:02:16.270
And a lot of that means, to
get the best performance,

00:02:16.270 --> 00:02:18.520
you need to know about things
like the number of types

00:02:18.520 --> 00:02:21.120
of cores, thermals
in the design.

00:02:21.120 --> 00:02:22.870
Like, there's a lot
of different variables

00:02:22.870 --> 00:02:25.860
to actually making sure you
have the best performance.

00:02:25.860 --> 00:02:28.089
But oftentimes, native
code is your only option.

00:02:28.089 --> 00:02:29.630
And of course,
reach-- you want to be

00:02:29.630 --> 00:02:31.100
able to hit multiple platforms.

00:02:31.100 --> 00:02:34.310
And C++ is just getting
better and better at isolating

00:02:34.310 --> 00:02:37.100
the operating system for
you, which is awesome.

00:02:37.100 --> 00:02:41.180
And finally, the NDK
has a few capabilities

00:02:41.180 --> 00:02:43.375
that aren't yet available
inside of the runtime.

00:02:43.375 --> 00:02:45.250
Now what I'm excited
about is that, actually,

00:02:45.250 --> 00:02:51.520
if you look-- when I wrote this
talk, to get low-latency audio,

00:02:51.520 --> 00:02:53.280
you had to use OpenSL.

00:02:53.280 --> 00:02:55.820
And if you want to get the
absolute lowest-latency audio,

00:02:55.820 --> 00:02:57.490
you still need to
use that, but I'm

00:02:57.490 --> 00:02:59.472
really excited
that in Android N,

00:02:59.472 --> 00:03:00.930
we actually are
now allowing people

00:03:00.930 --> 00:03:05.140
to use Java to get pretty darn
good latency on their devices.

00:03:05.140 --> 00:03:07.430
And of course, it's the
only way to access Vulkan,

00:03:07.430 --> 00:03:08.820
the graphics API, right now.

00:03:08.820 --> 00:03:09.810
And that just makes
a lot of sense.

00:03:09.810 --> 00:03:11.510
If you've ever seen
how verbose Vulkan is,

00:03:11.510 --> 00:03:13.660
you definitely don't want to
be making that many JNI calls

00:03:13.660 --> 00:03:14.680
if you don't have to.

00:03:14.680 --> 00:03:17.100
Not that it doesn't work.

00:03:17.100 --> 00:03:20.234
So this is probably review
for you, a lot of you,

00:03:20.234 --> 00:03:21.400
since you're all NDK people.

00:03:21.400 --> 00:03:22.570
What exactly is it?

00:03:22.570 --> 00:03:24.650
You know, it's a combination
of tools and headers

00:03:24.650 --> 00:03:26.580
that allow Android development.

00:03:26.580 --> 00:03:28.390
You know, all applications
are eventually

00:03:28.390 --> 00:03:30.930
tied to managed code running
in the Android runtime,

00:03:30.930 --> 00:03:33.400
and the Android framework
itself is written largely

00:03:33.400 --> 00:03:34.460
in managed code.

00:03:34.460 --> 00:03:37.890
Your libraries are ultimately
loaded into this framework,

00:03:37.890 --> 00:03:39.840
typically from within
Java code, and they all

00:03:39.840 --> 00:03:42.761
get to talk to a stable
application binary interface,

00:03:42.761 --> 00:03:45.260
which then, of course, talks
to the native system libraries.

00:03:45.260 --> 00:03:47.270
And this is important,
because a lot of people

00:03:47.270 --> 00:03:49.870
are like, well, why can't I just
use all those other libraries

00:03:49.870 --> 00:03:50.495
that are there?

00:03:50.495 --> 00:03:52.950
And people have done
this, and that's

00:03:52.950 --> 00:03:54.400
why compatibility breaks.

00:03:54.400 --> 00:03:56.150
And we're actually--
one of the things

00:03:56.150 --> 00:03:58.190
that we've added to
N is, if you actually

00:03:58.190 --> 00:04:01.080
try to use any of those
internal libraries,

00:04:01.080 --> 00:04:02.230
they will not work anymore.

00:04:02.230 --> 00:04:03.880
We actually have
separate link spaces.

00:04:03.880 --> 00:04:05.310
So there's good and
bad news to this.

00:04:05.310 --> 00:04:06.851
The bad news is
you're actually going

00:04:06.851 --> 00:04:09.490
to have to put things
like libpng into your app.

00:04:09.490 --> 00:04:12.170
The good news is when you
put them into your app,

00:04:12.170 --> 00:04:15.925
you are guaranteed to get your
version of libpng on Android N

00:04:15.925 --> 00:04:16.487
and above.

00:04:16.487 --> 00:04:18.070
While in previous
versions of Android,

00:04:18.070 --> 00:04:19.278
that was not always the case.

00:04:19.278 --> 00:04:22.750
So I think, in a way, it
solves a lot of problems.

00:04:22.750 --> 00:04:25.100
All right.

00:04:25.100 --> 00:04:26.820
So it's grown over the years.

00:04:26.820 --> 00:04:29.370
And you know, it
started off in Cupcake,

00:04:29.370 --> 00:04:32.040
and we added, you know,
media features and gaming

00:04:32.040 --> 00:04:37.000
features and the ability to do
fully native applications-- you

00:04:37.000 --> 00:04:38.440
know, lots of cool stuff.

00:04:38.440 --> 00:04:41.050
Recently, however, we've
actually gone even further.

00:04:41.050 --> 00:04:43.460
We've actually put RenderScript,
finally, into the NDK,

00:04:43.460 --> 00:04:45.390
so there are bindings for that.

00:04:45.390 --> 00:04:47.930
We've continued to expand
graphics with Vulkan.

00:04:47.930 --> 00:04:50.140
And we've added a couple
of really interesting ones

00:04:50.140 --> 00:04:51.690
in the latest
versions of the NDK--

00:04:51.690 --> 00:04:53.272
we've added Trace,
Choreographer,

00:04:53.272 --> 00:04:53.980
and Multinetwork.

00:04:53.980 --> 00:04:56.320
And at least I'm going to
talk a little bit about Trace

00:04:56.320 --> 00:04:58.940
and Choreographer in this one.

00:04:58.940 --> 00:05:00.700
So in addition,
the NDK toolchain,

00:05:00.700 --> 00:05:02.970
which is separate from
platform releases,

00:05:02.970 --> 00:05:05.460
has its own set of
12 major releases

00:05:05.460 --> 00:05:06.670
and many minor releases.

00:05:06.670 --> 00:05:09.170
12 just came out this week,
if you haven't seen it.

00:05:09.170 --> 00:05:10.669
And here are some
of the highlights.

00:05:10.669 --> 00:05:14.050
We added STL pretty early
on, and then we fixed it.

00:05:14.050 --> 00:05:16.840
We added more platforms,
like x86 and MIPS.

00:05:16.840 --> 00:05:21.860
We had the Clang compiler in 8c
and the misunderstood ARM7 FP

00:05:21.860 --> 00:05:26.660
in 9d, which we are actually
taking out of NDK level 12.

00:05:26.660 --> 00:05:31.219
So 64-bit in 10, and in 11, we
finally transitioned to Clang

00:05:31.219 --> 00:05:33.010
as our primary compiler,
and we've actually

00:05:33.010 --> 00:05:35.310
deprecated the use of GCC.

00:05:35.310 --> 00:05:38.550
In the middle there, we moved
to LLDB as our primary debugger.

00:05:38.550 --> 00:05:40.530
But again, this talk
isn't just about the NDK.

00:05:40.530 --> 00:05:42.630
It's also about ART.

00:05:42.630 --> 00:05:44.910
So what I did was, I
was really curious.

00:05:44.910 --> 00:05:47.080
Like, ART is a totally
different beast

00:05:47.080 --> 00:05:48.480
than our previous runtime.

00:05:48.480 --> 00:05:51.750
So how does it affect the NDK?

00:05:51.750 --> 00:05:55.110
And so what I did is, I went
through the Perf-JNI article.

00:05:55.110 --> 00:05:58.529
I mean, probably everyone's read
this Perf-JNI article, right?

00:05:58.529 --> 00:06:00.070
Or if you haven't,
you really should.

00:06:00.070 --> 00:06:02.420
Because the real question
I wanted to know was,

00:06:02.420 --> 00:06:07.870
do these tips actually
make sense in an ART world?

00:06:07.870 --> 00:06:10.610
And we're going to keep
a scorecard for both ART

00:06:10.610 --> 00:06:12.770
and Dalvik for each
one of these tips.

00:06:12.770 --> 00:06:14.690
And so let's go through them.

00:06:14.690 --> 00:06:16.539
And we're going to
benchmark these.

00:06:16.539 --> 00:06:18.580
I actually benchmarked
these with Google Caliper,

00:06:18.580 --> 00:06:19.455
which is pretty cool.

00:06:19.455 --> 00:06:21.650
It's actually what we use
inside of our CTS tests

00:06:21.650 --> 00:06:24.035
for all of our benchmarking,
so it's about as good

00:06:24.035 --> 00:06:24.660
as you can get.

00:06:24.660 --> 00:06:26.235
We use it a lot
internally at Google

00:06:26.235 --> 00:06:27.640
for doing all sorts
of benchmarking.

00:06:27.640 --> 00:06:30.130
So if you ever want to set it
up, it's actually pretty cool.

00:06:30.130 --> 00:06:31.380
You'll learn a little
bit about Android just

00:06:31.380 --> 00:06:32.320
setting this thing up.

00:06:32.320 --> 00:06:34.695
Hopefully, we'll make it more
user-friendly at some point

00:06:34.695 --> 00:06:35.410
in the future.

00:06:35.410 --> 00:06:38.970
And so the basics.

00:06:38.970 --> 00:06:42.000
When you're using JNI to
reference managed objects,

00:06:42.000 --> 00:06:44.490
you're actually taking
advantage of reflection.

00:06:44.490 --> 00:06:46.280
They named it, of
course, because it

00:06:46.280 --> 00:06:49.410
describes the ability for code
to inspect itself at runtime.

00:06:49.410 --> 00:06:52.300
Now to access a class field,
we take the object reference

00:06:52.300 --> 00:06:55.210
for the class and use reflection
to request a Field ID, My Name.

00:06:55.210 --> 00:07:00.580
OK, and from our developer
training, here's what it says.

00:07:00.580 --> 00:07:04.330
It is important to cache
class references, Field IDs,

00:07:04.330 --> 00:07:06.330
and Method IDs, because
they're guaranteed valid

00:07:06.330 --> 00:07:07.780
until the class is unloaded.

00:07:07.780 --> 00:07:09.560
And that rarely happens.

00:07:09.560 --> 00:07:11.740
And it's really easy
to catch if it does.

00:07:11.740 --> 00:07:14.910
So let's look at our first
performance suggestion

00:07:14.910 --> 00:07:17.330
and how it holds up under art.

00:07:17.330 --> 00:07:18.900
So a nice way to
cache these IDs,

00:07:18.900 --> 00:07:20.610
which nicely solves
the unload problem,

00:07:20.610 --> 00:07:22.900
is just to put it in
the static initializer.

00:07:22.900 --> 00:07:26.040
So there you go, you [? call ?]
like this one, nativeInit.

00:07:26.040 --> 00:07:28.254
Inside of that, you
get all your Field IDs.

00:07:28.254 --> 00:07:30.170
So as you see, I'm making
a native call inside

00:07:30.170 --> 00:07:32.461
of my static initializer,
which is kind of slick, right

00:07:32.461 --> 00:07:33.690
after unloading the library.

00:07:33.690 --> 00:07:36.640
And now those IDs
are good forever.

00:07:36.640 --> 00:07:38.740
So it's really nice if
a class gets unloaded,

00:07:38.740 --> 00:07:42.550
the static initializer
will get called again.

00:07:42.550 --> 00:07:44.300
And here's how it benchmarks.

00:07:44.300 --> 00:07:46.650
And it turns out,
now this is a Nexus 5

00:07:46.650 --> 00:07:48.170
running KitKat in Marshmallow.

00:07:48.170 --> 00:07:50.440
But as we can see, both
GetFieldID and GetIntField

00:07:50.440 --> 00:07:52.150
are actually slower in ART.

00:07:52.150 --> 00:07:54.910
In other words, the advice
to cache Field and Method IDs

00:07:54.910 --> 00:07:57.170
is actually more important
in the world of ART

00:07:57.170 --> 00:07:58.680
than it was in the
world of Dalvik.

00:07:58.680 --> 00:08:00.887
And we'll see a trend here.

00:08:00.887 --> 00:08:02.970
And the difference in the
cost of [? GetItField ?]

00:08:02.970 --> 00:08:05.460
is a little surprising.

00:08:05.460 --> 00:08:07.510
Both run times actually
change the state

00:08:07.510 --> 00:08:08.560
of the internal thread.

00:08:08.560 --> 00:08:11.960
And that's actually what costs
a bit of performance here,

00:08:11.960 --> 00:08:13.780
although ART actually
clarifies what

00:08:13.780 --> 00:08:17.070
it's doing with Scoped Object
Access rather than Scoped JNI

00:08:17.070 --> 00:08:17.957
thread state.

00:08:17.957 --> 00:08:19.790
And what we're seeing
is a couple of things.

00:08:19.790 --> 00:08:23.110
One is that ART is pretty
complicated by comparison

00:08:23.110 --> 00:08:24.150
to Dalvik.

00:08:24.150 --> 00:08:25.570
And it's got a
lot more going on.

00:08:25.570 --> 00:08:27.611
The garbage collector is
much more sophisticated.

00:08:27.611 --> 00:08:29.330
It's much higher performance.

00:08:29.330 --> 00:08:31.680
And the other thing is it's
just being really defensive.

00:08:31.680 --> 00:08:34.380
There were definitely
times in Dalvik

00:08:34.380 --> 00:08:36.650
where you could
cause it to deadlock.

00:08:36.650 --> 00:08:39.530
And it's very, very difficult
to make ART do that.

00:08:39.530 --> 00:08:41.669
So that's the beautiful
thing about all this work.

00:08:41.669 --> 00:08:43.925
But it does cost us a little
in actual performance.

00:08:43.925 --> 00:08:45.850
So this is something to note.

00:08:45.850 --> 00:08:47.680
Also, I love this use
of the preprocessor

00:08:47.680 --> 00:08:49.860
to prevent all this
duplicated code.

00:08:49.860 --> 00:08:52.330
OK, as far as caching
Field Method IDs go,

00:08:52.330 --> 00:08:53.510
it's a big win on Dalvik.

00:08:53.510 --> 00:08:55.340
It's even a bigger win on ART.

00:08:55.340 --> 00:08:57.550
So let's look at our second
performance suggestion,

00:08:57.550 --> 00:08:58.970
and we'll see how it holds up.

00:08:58.970 --> 00:09:00.630
If possible, it
is usually faster

00:09:00.630 --> 00:09:03.270
to operate with UTF-16 strings.

00:09:03.270 --> 00:09:05.760
Android does usually not require
a copy in GetStringChars,

00:09:05.760 --> 00:09:07.330
whereas Get blah blah blah.

00:09:07.330 --> 00:09:08.920
OK, I don't have to
read that to you.

00:09:08.920 --> 00:09:12.050
Basically, it makes sense if
we don't have to copy strings,

00:09:12.050 --> 00:09:13.950
it's going to be faster, right.

00:09:13.950 --> 00:09:15.960
So here are the two
calls to get a string.

00:09:15.960 --> 00:09:17.820
You can either get
the UCS string,

00:09:17.820 --> 00:09:21.710
which is a 16-bit standard
format for the managed

00:09:21.710 --> 00:09:22.490
side of things.

00:09:22.490 --> 00:09:26.830
And UTF, which is, of course,
what a lot of our native code

00:09:26.830 --> 00:09:27.680
expects.

00:09:27.680 --> 00:09:30.730
And we would expect that if
there's no conversion going on,

00:09:30.730 --> 00:09:33.730
that actually the UTF
would outperform the UCS.

00:09:33.730 --> 00:09:36.290
OK, so let's take a look at
how this actually benchmarks.

00:09:36.290 --> 00:09:38.210
And this was a little
surprising to me

00:09:38.210 --> 00:09:41.420
because this was a short
15 character string.

00:09:41.420 --> 00:09:44.190
And it turns out that
it was actually faster

00:09:44.190 --> 00:09:48.910
to send the 8-bit decoded
string across instead

00:09:48.910 --> 00:09:51.504
of the 16-bit string on ART.

00:09:51.504 --> 00:09:52.920
On Dalvik, you can
see it actually

00:09:52.920 --> 00:09:54.860
benches the way you
kind of expect it to.

00:09:54.860 --> 00:09:57.130
But even then, it's
very, very close.

00:09:57.130 --> 00:09:59.095
And it was a little
bit of a surprise.

00:09:59.095 --> 00:10:00.970
And so I was like, OK,
I've got to understand

00:10:00.970 --> 00:10:02.310
why this is happening.

00:10:02.310 --> 00:10:05.669
So basically, I was
like, let's first of all,

00:10:05.669 --> 00:10:08.210
try a longer string and see if
it actually behaves correctly.

00:10:08.210 --> 00:10:09.730
So with a longer
string, we actually

00:10:09.730 --> 00:10:12.790
see, yes, this actually
benches out the way we expect.

00:10:12.790 --> 00:10:14.350
But it's a little surprising.

00:10:14.350 --> 00:10:17.340
So let's look at the code and
see what actually is going on.

00:10:17.340 --> 00:10:19.700
So you can see
inside of ART, there

00:10:19.700 --> 00:10:22.710
is this line called
IsMoveableObject.

00:10:22.710 --> 00:10:24.970
And it sometimes
gets to return a copy

00:10:24.970 --> 00:10:26.900
and sometimes returns
the original string.

00:10:26.900 --> 00:10:29.927
And IsMoveableObject is actually
kind of an expensive call.

00:10:29.927 --> 00:10:31.510
So what ends up
happening is that this

00:10:31.510 --> 00:10:34.500
is actually a for loop
inside of here, that

00:10:34.500 --> 00:10:36.920
goes inside this fine
continuous space from object.

00:10:36.920 --> 00:10:38.910
And that's actually
what takes the time.

00:10:38.910 --> 00:10:43.980
So ultimately on ART, for a
lot of normal string sizes,

00:10:43.980 --> 00:10:46.640
you might actually be better
just sending in the UTF-8

00:10:46.640 --> 00:10:47.530
today.

00:10:47.530 --> 00:10:49.450
Now of course, this is
all subject to change.

00:10:49.450 --> 00:10:51.110
And maybe they'll watch this
and be like, oh god, we've

00:10:51.110 --> 00:10:51.810
got to fix that.

00:10:51.810 --> 00:10:55.040
But at least today, it
doesn't matter all that much,

00:10:55.040 --> 00:10:55.830
as it turns out.

00:10:55.830 --> 00:10:58.570
So that was a little
bit surprising.

00:10:58.570 --> 00:11:00.180
And again, this is
a micro-benchmark.

00:11:00.180 --> 00:11:02.346
So it certainly isn't going
to help prevent garbage.

00:11:02.346 --> 00:11:06.082
[AUDIO OUT]

00:11:11.924 --> 00:11:12.590
Is this working?

00:11:12.590 --> 00:11:13.150
All right.

00:11:13.150 --> 00:11:15.274
Fortunately, for all you
people on the live stream,

00:11:15.274 --> 00:11:16.880
I've got a microphone.

00:11:16.880 --> 00:11:19.950
So on our JNI tip scorecard,
it's probably a decent idea

00:11:19.950 --> 00:11:21.260
to do it on both.

00:11:21.260 --> 00:11:26.250
But it's definitely,
definitely better on Dalvik.

00:11:26.250 --> 00:11:29.080
Finally, let's get
one more tip here.

00:11:29.080 --> 00:11:32.132
And this is actually
me paraphrasing

00:11:32.132 --> 00:11:34.340
because I couldn't come up
with a quote that was even

00:11:34.340 --> 00:11:35.840
close to being good enough.

00:11:35.840 --> 00:11:38.315
This is actually a very,
very good thing, though,

00:11:38.315 --> 00:11:39.190
actually paraphrased.

00:11:39.190 --> 00:11:40.436
Because this is important.

00:11:40.436 --> 00:11:42.060
Because you want to
reduce JNI overhead

00:11:42.060 --> 00:11:44.319
and actually using region
calls to copy data,

00:11:44.319 --> 00:11:45.860
if you're going to
end up copying it.

00:11:45.860 --> 00:11:48.300
And the finality is
it actually saves you

00:11:48.300 --> 00:11:49.840
quite a bit of performance.

00:11:49.840 --> 00:11:51.340
So here are the two
native functions

00:11:51.340 --> 00:11:52.940
that copy data from
string into a buffer.

00:11:52.940 --> 00:11:54.606
One of them does it
using the old school

00:11:54.606 --> 00:11:57.610
way of doing Get,
Copy, and Release.

00:11:57.610 --> 00:12:00.340
And the other one does it using
GetStringRegion, which is all

00:12:00.340 --> 00:12:01.610
done at once, which is cool.

00:12:01.610 --> 00:12:03.289
You're eliminating
some JNI calls.

00:12:03.289 --> 00:12:05.330
And as you would expect--
oh, and the other thing

00:12:05.330 --> 00:12:07.330
I was going to point out
here is that I actually

00:12:07.330 --> 00:12:09.130
passed the length of
the string in as well.

00:12:09.130 --> 00:12:11.450
Now I could, of course,
just pass the object

00:12:11.450 --> 00:12:14.624
from the runtime and query it.

00:12:14.624 --> 00:12:16.540
But obviously, that would
be another JNI call.

00:12:16.540 --> 00:12:17.998
That would be a
huge waste of time.

00:12:17.998 --> 00:12:20.129
And it turns out that
it's 20 to 30 times faster

00:12:20.129 --> 00:12:21.920
just to pass an additional
parameter rather

00:12:21.920 --> 00:12:23.504
than making another JNI call.

00:12:23.504 --> 00:12:24.920
So as a general
rule, you're going

00:12:24.920 --> 00:12:27.730
to always want to have
more parameters calling

00:12:27.730 --> 00:12:31.670
into your native functions,
if you can possibly avoid ever

00:12:31.670 --> 00:12:34.790
making a call back
into the runtime.

00:12:34.790 --> 00:12:35.940
OK.

00:12:35.940 --> 00:12:37.710
So here's how it
actually benchmarks

00:12:37.710 --> 00:12:39.650
for copying string data.

00:12:39.650 --> 00:12:44.060
And once again, this is
what we would expect,

00:12:44.060 --> 00:12:48.470
that the GetStringRegion is
extremely close, actually,

00:12:48.470 --> 00:12:50.670
between the two VMs
on the same hardware.

00:12:50.670 --> 00:12:53.990
And GetStringChars is definitely
slower than both of them.

00:12:53.990 --> 00:12:55.490
So region is
definitely a good one.

00:12:55.490 --> 00:12:57.970
We'll put that on our scorecard.

00:12:57.970 --> 00:13:01.010
So sharing structured data
between managed and unmanaged

00:13:01.010 --> 00:13:02.567
code in the fastest
possible ways

00:13:02.567 --> 00:13:04.150
isn't as easy as
sharing a soft drink.

00:13:04.150 --> 00:13:05.560
You basically have two options.

00:13:05.560 --> 00:13:08.630
You either use arrays
or direct byte buffers.

00:13:08.630 --> 00:13:10.910
And it really comes
down to your use case.

00:13:10.910 --> 00:13:12.490
Arrays are useful
if you're primarily

00:13:12.490 --> 00:13:16.000
going to be accessing the
data from managed code.

00:13:16.000 --> 00:13:18.342
But here's what our tips say
about direct byte buffers.

00:13:21.470 --> 00:13:26.260
OK, this seems like a rather
uncommitted statement.

00:13:26.260 --> 00:13:28.200
Like you'd think we could
do better than this.

00:13:28.200 --> 00:13:32.780
Is it actually slow, like
on both of our run times,

00:13:32.780 --> 00:13:33.660
on a real device?

00:13:33.660 --> 00:13:36.201
Well, this is why I was like,
I've got to benchmark this one,

00:13:36.201 --> 00:13:36.720
too.

00:13:36.720 --> 00:13:40.370
And actually, it's not
terribly surprising,

00:13:40.370 --> 00:13:43.070
but we see about two times
the raw JNI costs in order

00:13:43.070 --> 00:13:46.580
to get the direct buffer
address access rather

00:13:46.580 --> 00:13:49.190
than just using the
standard stuff that's

00:13:49.190 --> 00:13:50.510
built into the runtime.

00:13:50.510 --> 00:13:53.880
But you notice something
really interesting here

00:13:53.880 --> 00:13:55.840
about this one.

00:13:55.840 --> 00:13:59.330
And that if we actually go to
read back from the byte buffer,

00:13:59.330 --> 00:14:01.820
it's actually three
times as expensive

00:14:01.820 --> 00:14:05.740
to read from Dalvik
compared to using ART.

00:14:05.740 --> 00:14:08.280
And this makes no sense.

00:14:08.280 --> 00:14:10.450
We've seen in every
other call, we've

00:14:10.450 --> 00:14:15.960
seen that Dalvik does this
much, much faster than ART.

00:14:15.960 --> 00:14:17.146
So what's going on here?

00:14:17.146 --> 00:14:19.020
Let's take a look at
what's going on actually

00:14:19.020 --> 00:14:20.280
inside the code.

00:14:20.280 --> 00:14:23.050
So basically, here's
what this looks like.

00:14:23.050 --> 00:14:25.967
As you'd expect, this is
our direct byte buffer.

00:14:25.967 --> 00:14:28.300
We can see that a regular
byte buffer is actually backed

00:14:28.300 --> 00:14:30.730
by a Java array, while
a direct buffer is

00:14:30.730 --> 00:14:32.340
backed by a memory block.

00:14:32.340 --> 00:14:35.834
And so far, that's
exactly what we'd expect.

00:14:35.834 --> 00:14:38.000
And here's how we start
actually reading an integer.

00:14:38.000 --> 00:14:39.458
We can already see
that direct byte

00:14:39.458 --> 00:14:42.030
buffer has an additional
level of indirection.

00:14:42.030 --> 00:14:44.530
And based on the profiling I've
done, that probably costs us

00:14:44.530 --> 00:14:46.810
about five nanoseconds.

00:14:46.810 --> 00:14:48.302
And now we're somewhere.

00:14:48.302 --> 00:14:49.760
Here's our ByteArray
implementation

00:14:49.760 --> 00:14:51.730
and our MemoryBlock
implementation

00:14:51.730 --> 00:14:53.720
both conveniently
in the same class.

00:14:53.720 --> 00:14:57.860
And our MemoryBlock
version actually uses JNI.

00:14:57.860 --> 00:14:59.810
So that explains why
direct is so much slower.

00:14:59.810 --> 00:15:02.250
It's actually doing
a full JNI call just

00:15:02.250 --> 00:15:03.650
to access this memory.

00:15:03.650 --> 00:15:05.870
But why is ART so much faster?

00:15:05.870 --> 00:15:08.230
Well, here's what that
native code calls into.

00:15:08.230 --> 00:15:10.460
But it still doesn't tell
us why ART is faster.

00:15:10.460 --> 00:15:12.330
The real magic
actually happens when

00:15:12.330 --> 00:15:14.440
the JNI function is declared.

00:15:14.440 --> 00:15:16.570
Because JNI overhead
is pretty high.

00:15:16.570 --> 00:15:19.330
The runtime actually
short cuts it

00:15:19.330 --> 00:15:22.410
into a fast mode
in certain cases.

00:15:22.410 --> 00:15:25.050
So inside of ART's native
code, we declare the JNI call

00:15:25.050 --> 00:15:26.970
with an exclamation
point to make it clear

00:15:26.970 --> 00:15:29.450
that this is a potentially
dangerous function.

00:15:29.450 --> 00:15:32.040
And now the thread gets to stay
in running mode without having

00:15:32.040 --> 00:15:33.830
to switch to native.

00:15:33.830 --> 00:15:35.810
So looking back at our
graph, our direct call

00:15:35.810 --> 00:15:37.980
is about half the speed
of our byte buffer call.

00:15:37.980 --> 00:15:40.670
And this is partially because
the version of the runtime

00:15:40.670 --> 00:15:42.140
is actually using another trick.

00:15:42.140 --> 00:15:44.315
It's really an inline intrinsic.

00:15:44.315 --> 00:15:46.440
So we're never going to
get the kind of performance

00:15:46.440 --> 00:15:49.144
out of our native call as
we will even without most

00:15:49.144 --> 00:15:50.560
of the overhead
compared to what's

00:15:50.560 --> 00:15:52.530
going on inside the runtime.

00:15:52.530 --> 00:15:54.900
And partially because we
have a little bit of overhead

00:15:54.900 --> 00:15:56.400
even in this kind of fast mode.

00:15:56.400 --> 00:15:59.430
And this is about 60 nanoseconds
of overhead on a Nexus 5.

00:15:59.430 --> 00:16:00.520
So it's not huge.

00:16:00.520 --> 00:16:02.400
I mean, these are
tiny, tiny amounts.

00:16:02.400 --> 00:16:04.950
You have to remember that
almost every single call you

00:16:04.950 --> 00:16:08.020
make in Android ends up
going through one of these

00:16:08.020 --> 00:16:09.699
eventually.

00:16:09.699 --> 00:16:11.240
So the question is,
is there anything

00:16:11.240 --> 00:16:13.400
we can do to avoid having
to make a call into JNI

00:16:13.400 --> 00:16:14.670
for each Int we want to read?

00:16:14.670 --> 00:16:16.160
And it turns out, there is.

00:16:16.160 --> 00:16:17.920
We can copy the
entire array at once

00:16:17.920 --> 00:16:20.830
and then get the
Int individually.

00:16:20.830 --> 00:16:23.410
And now we're going to do some
pretty expensive stuff here.

00:16:23.410 --> 00:16:24.300
So it only makes
sense if you're going

00:16:24.300 --> 00:16:25.590
to be reading a lot
of structured data

00:16:25.590 --> 00:16:26.570
from the byte buffer.

00:16:26.570 --> 00:16:29.350
As always, you'll want to
profile just to make sure.

00:16:29.350 --> 00:16:32.230
But once again, you
can see that this is

00:16:32.230 --> 00:16:34.800
pretty awesome in terms of ART.

00:16:34.800 --> 00:16:38.576
All right, so that was the
really, really scientific part

00:16:38.576 --> 00:16:39.950
where I did lots
of benchmarking.

00:16:39.950 --> 00:16:42.074
Let's get into actually
doing some fun stuff that's

00:16:42.074 --> 00:16:43.920
maybe more practical.

00:16:43.920 --> 00:16:46.250
So this slide
mostly demonstrates

00:16:46.250 --> 00:16:48.070
why I'm not a design advocate.

00:16:48.070 --> 00:16:50.730
But there are a lot of choices
to be made when using the NDK,

00:16:50.730 --> 00:16:54.860
as well some updates
I'd like to highlight.

00:16:54.860 --> 00:16:59.240
So we have a couple
of samples here.

00:16:59.240 --> 00:17:02.250
And I wanted to show
you them, let's see,

00:17:02.250 --> 00:17:05.720
on this phone I have up here.

00:17:05.720 --> 00:17:10.200
And this is actually running
the End Developer Preview.

00:17:10.200 --> 00:17:12.710
And there is a really
cool NDK sample

00:17:12.710 --> 00:17:14.319
we have up here
called More Teapots.

00:17:14.319 --> 00:17:16.050
And you can see that
in a normal mode,

00:17:16.050 --> 00:17:17.760
it runs at 60 frames per second.

00:17:17.760 --> 00:17:20.829
This thing uses geometry and
instancing to get actually

00:17:20.829 --> 00:17:26.760
pretty decent performance
running even with fairly,

00:17:26.760 --> 00:17:31.310
fairly a lot of teapots
flying around, basically.

00:17:31.310 --> 00:17:34.725
And if we switch
over to the laptop,

00:17:34.725 --> 00:17:36.850
you can see I've actually
taken a Systrace of this.

00:17:36.850 --> 00:17:40.800
Now how many people here
have actually used Systrace?

00:17:40.800 --> 00:17:42.180
I want to see a show of hands.

00:17:42.180 --> 00:17:45.880
Because Systrace is like my
favorite tool ever, almost.

00:17:45.880 --> 00:17:47.710
It is pretty awesome.

00:17:47.710 --> 00:17:50.050
And it's kind of hard
to understand completely

00:17:50.050 --> 00:17:52.680
what's going on when you're
just looking at it here.

00:17:52.680 --> 00:17:56.780
So basically you can see that
inside of my More Teapots

00:17:56.780 --> 00:17:59.650
application, I've
got Thread 9491.

00:17:59.650 --> 00:18:02.990
And inside of that, I
can see EGL swap buffers

00:18:02.990 --> 00:18:05.920
with damaged K char
and a Q buffer.

00:18:05.920 --> 00:18:09.610
And then if we look also
inside of our SurfaceFlinger,

00:18:09.610 --> 00:18:12.820
we can actually see that there's
a thread that's tied to that

00:18:12.820 --> 00:18:16.470
as well that's responsible
for updating that Surface.

00:18:16.470 --> 00:18:18.660
But we can do a lot better.

00:18:18.660 --> 00:18:21.630
And let me show you a little
bit of what we can do.

00:18:21.630 --> 00:18:23.390
OK, back to the
slides for a second.

00:18:29.169 --> 00:18:31.210
Oh, I did want to go over
a few more things here.

00:18:31.210 --> 00:18:32.520
But I'll do that later.

00:18:32.520 --> 00:18:35.420
So what we can do to
start off is, let's get

00:18:35.420 --> 00:18:36.610
rid of that ugly name.

00:18:36.610 --> 00:18:38.900
We can actually name our
threads-- in this case,

00:18:38.900 --> 00:18:43.170
the code is actually
attaching to the runtime.

00:18:43.170 --> 00:18:45.190
So you can see here
that we actually

00:18:45.190 --> 00:18:47.680
are using this
AttachCurrentThread

00:18:47.680 --> 00:18:49.460
with AttachArgs.

00:18:49.460 --> 00:18:54.032
And if we do that-- and let's
see if we can switch back to,

00:18:54.032 --> 00:18:56.960
let me see, back to the laptop.

00:18:56.960 --> 00:18:59.540
And I'll show you
two things here.

00:18:59.540 --> 00:19:02.390
One is that I've
actually added something

00:19:02.390 --> 00:19:03.700
called Too Many Teapots.

00:19:03.700 --> 00:19:06.910
So this is like, instead of
512, which the regular demo has,

00:19:06.910 --> 00:19:10.970
we're now looking at one that's
rendering 4,096 teapots, which

00:19:10.970 --> 00:19:16.454
is actually way too much for
this poor, sad Nexus XP to do.

00:19:16.454 --> 00:19:18.370
And you'll see a couple
of things interesting.

00:19:18.370 --> 00:19:22.290
One is that we now see that
CPU 4 here is actually active.

00:19:22.290 --> 00:19:24.650
And that's really, really bad.

00:19:24.650 --> 00:19:27.370
Because CPU 4, it turns out,
is one of the high performance

00:19:27.370 --> 00:19:29.870
CPUs that just
absolutely will cause

00:19:29.870 --> 00:19:31.330
the device to
thermally throttle,

00:19:31.330 --> 00:19:33.329
relatively quickly,
especially if someone has it

00:19:33.329 --> 00:19:36.720
inside a nice
insulating case, which

00:19:36.720 --> 00:19:39.169
of course, a lot of people do.

00:19:39.169 --> 00:19:40.960
In fact, I did this
with and without cases.

00:19:40.960 --> 00:19:42.702
And I got about 10%
better frame rates

00:19:42.702 --> 00:19:43.910
once I took it out of a case.

00:19:43.910 --> 00:19:46.570
That should give you an idea
of how these things actually

00:19:46.570 --> 00:19:48.210
matter.

00:19:48.210 --> 00:19:49.960
But the really cool
thing, as you can see,

00:19:49.960 --> 00:19:53.600
if we go down here, it
should be here, maybe.

00:19:53.600 --> 00:19:55.946
If it's not in this one,
it'll be in the next one.

00:19:55.946 --> 00:19:57.570
This is supposed to
have a name thread.

00:20:01.090 --> 00:20:04.270
This is the challenge with
getting Systrace is sometimes

00:20:04.270 --> 00:20:06.700
I miss things.

00:20:06.700 --> 00:20:09.700
But in any case, this will
actually show the thread name,

00:20:09.700 --> 00:20:11.100
I swear.

00:20:11.100 --> 00:20:13.280
OK, let me show you a
couple of other things

00:20:13.280 --> 00:20:15.028
on the actual device itself.

00:20:18.930 --> 00:20:20.510
So this is the too
many teapots demo.

00:20:20.510 --> 00:20:24.715
As you can see, it's running
at about 12 frames a second,

00:20:24.715 --> 00:20:25.965
which is really not very good.

00:20:25.965 --> 00:20:28.230
But let's say we
absolutely wanted

00:20:28.230 --> 00:20:34.820
to put 4,096 highly occluding
teapots into our game running

00:20:34.820 --> 00:20:37.112
at some reasonable resolution.

00:20:37.112 --> 00:20:39.690
How would we actually use
what's built into the NDK

00:20:39.690 --> 00:20:40.760
to help us with that?

00:20:40.760 --> 00:20:42.259
So we can switch
back to the slides.

00:20:42.259 --> 00:20:44.840
I'll talk a little bit about
that and what we can do.

00:20:44.840 --> 00:20:46.340
First of all, we
want to know what's

00:20:46.340 --> 00:20:47.870
going on with performance.

00:20:47.870 --> 00:20:50.510
So one of the cool things
that we've actually done

00:20:50.510 --> 00:20:54.300
is we've actually created
a native trace API.

00:20:54.300 --> 00:20:57.500
And this has actually been
in the platform ever since N.

00:20:57.500 --> 00:21:01.160
So we've had begin
and end sections

00:21:01.160 --> 00:21:03.620
for several versions, which
allows you to actually annotate

00:21:03.620 --> 00:21:07.422
these Systraces, but now we
actually have a native API

00:21:07.422 --> 00:21:08.130
to do it for you.

00:21:08.130 --> 00:21:11.580
So we can actually see not
just like the KHR swap buffers

00:21:11.580 --> 00:21:14.160
thing, but actually
individual sections of what's

00:21:14.160 --> 00:21:16.520
going on in our engine, which
is really, really awesome.

00:21:16.520 --> 00:21:18.750
And then you just do
an ATrace_beginSection,

00:21:18.750 --> 00:21:19.770
ATrace_endSection.

00:21:19.770 --> 00:21:20.890
It's pretty lightweight.

00:21:20.890 --> 00:21:24.010
It's a lot lighter weight
than doing a log statement.

00:21:24.010 --> 00:21:27.090
And you'll actually
see all of these things

00:21:27.090 --> 00:21:30.559
show up in the graph
really, really nicely.

00:21:30.559 --> 00:21:32.350
Now one of things that
we do really, really

00:21:32.350 --> 00:21:35.320
easily is to reduce the
size of our render target.

00:21:35.320 --> 00:21:38.240
Now what's cool is that
actually using the asset manager

00:21:38.240 --> 00:21:39.830
APIs that are
built into the NDK,

00:21:39.830 --> 00:21:42.040
we can actually get the
density of the screen.

00:21:42.040 --> 00:21:45.260
And that's useful
because, obviously, we

00:21:45.260 --> 00:21:47.570
might want to say our
application doesn't

00:21:47.570 --> 00:21:51.400
need to render in anything
higher density than HDPI.

00:21:51.400 --> 00:21:54.150
But that's nice because it
still actually preserves

00:21:54.150 --> 00:21:55.050
the screen size.

00:21:55.050 --> 00:21:57.350
It means that we're
actually really truly

00:21:57.350 --> 00:21:59.320
giving the user a
decent experience

00:21:59.320 --> 00:22:01.370
by using density as our target.

00:22:01.370 --> 00:22:05.440
So let's switch back
to the phone here.

00:22:05.440 --> 00:22:07.900
And I can show off the
first thing we can do here.

00:22:07.900 --> 00:22:09.530
So this is just
scaling the target.

00:22:09.530 --> 00:22:12.411
And obviously that's not a
very good user experience here,

00:22:12.411 --> 00:22:14.410
but that's actually scaling
it based on density.

00:22:14.410 --> 00:22:21.600
So I'm actually now rendering
the screen at old school HDPI,

00:22:21.600 --> 00:22:23.830
just by using the density
metric there to scale.

00:22:23.830 --> 00:22:25.330
But obviously,
that's not very good.

00:22:25.330 --> 00:22:28.490
But we can do something better.

00:22:28.490 --> 00:22:30.490
I can see we're getting
a good performance gain.

00:22:30.490 --> 00:22:32.790
We're about 25
frames a second here.

00:22:32.790 --> 00:22:34.916
However, we can actually
make it even faster

00:22:34.916 --> 00:22:36.790
and actually make it a
better user experience

00:22:36.790 --> 00:22:39.440
all at the same time
and by taking advantage

00:22:39.440 --> 00:22:42.430
of the compositing engine inside
of SurfaceFlinger to do some

00:22:42.430 --> 00:22:44.679
of the work for us and
actually save some memory

00:22:44.679 --> 00:22:45.720
bandwidth in the process.

00:22:52.880 --> 00:22:57.730
Yeah, let me switch back to
the slide here for one moment.

00:22:57.730 --> 00:23:00.210
OK, so this is what
we actually do.

00:23:00.210 --> 00:23:04.020
So once we've gotten the ratio
that we want, all we have to do

00:23:04.020 --> 00:23:06.604
is call a native window,
get the right format,

00:23:06.604 --> 00:23:09.270
because you don't want to change
the format of our native window

00:23:09.270 --> 00:23:10.100
when we do this.

00:23:10.100 --> 00:23:12.175
And then we can call
setBuffersGeometry.

00:23:12.175 --> 00:23:14.300
And this is pretty cool
because what it'll actually

00:23:14.300 --> 00:23:17.840
do for us is it'll automatically
scale that render target for us

00:23:17.840 --> 00:23:21.269
and make things a lot happier
and a lot more friendly.

00:23:21.269 --> 00:23:23.560
And actually when you're
looking at this in the device,

00:23:23.560 --> 00:23:26.600
unless you're looking carefully,
it's really, really difficult

00:23:26.600 --> 00:23:27.940
to notice what's going on here.

00:23:27.940 --> 00:23:30.080
So we can switch
back to the phone,

00:23:30.080 --> 00:23:31.920
and you can see what
I'm talking about.

00:23:31.920 --> 00:23:36.824
So now once again, this is using
the internal compositing engine

00:23:36.824 --> 00:23:37.990
to actually scale things up.

00:23:37.990 --> 00:23:40.250
And you see, we're actually
doing better than we were even

00:23:40.250 --> 00:23:42.208
rendering in just a little
corner of the window

00:23:42.208 --> 00:23:44.777
because it's actually
using less fill.

00:23:44.777 --> 00:23:46.360
And the other thing
that's really cool

00:23:46.360 --> 00:23:49.350
about this is the
FPS is actually

00:23:49.350 --> 00:23:51.270
being rendered using
a pop-up window.

00:23:51.270 --> 00:23:52.780
And that pop-up
window is actually

00:23:52.780 --> 00:23:54.679
running at the full
device resolution.

00:23:54.679 --> 00:23:56.220
So that text that
you're seeing there

00:23:56.220 --> 00:23:59.440
is actually rendered at
the super high DPI stuff.

00:23:59.440 --> 00:24:01.120
And only the
background is actually

00:24:01.120 --> 00:24:03.140
being rendered at
our lower resolution.

00:24:03.140 --> 00:24:05.440
And the compositing engine
on a device like this

00:24:05.440 --> 00:24:07.180
can do enough windows
that we're actually

00:24:07.180 --> 00:24:08.550
getting the benefit of that.

00:24:08.550 --> 00:24:10.480
So we have a HUD running
at really high res

00:24:10.480 --> 00:24:12.480
and we have a background
running at a lower res.

00:24:12.480 --> 00:24:17.870
And you can barely tell because
our eyes seeing characters

00:24:17.870 --> 00:24:20.080
with a bunch of jaggies is
really noticeable to us.

00:24:20.080 --> 00:24:21.871
But seeing a background
with a little lower

00:24:21.871 --> 00:24:23.000
resolution-- not so bad.

00:24:23.000 --> 00:24:24.250
This is actually a cool trick.

00:24:24.250 --> 00:24:25.708
I don't think I've
ever seen anyone

00:24:25.708 --> 00:24:27.380
use this in a shipping app.

00:24:27.380 --> 00:24:29.992
But it can be done and
it works pretty well.

00:24:29.992 --> 00:24:31.700
The one trick about
this one is it really

00:24:31.700 --> 00:24:34.080
helps to be in immersive
mode when you're doing this

00:24:34.080 --> 00:24:39.510
because the pull-downs
for the notification

00:24:39.510 --> 00:24:41.920
and for the system
buttons at the bottom

00:24:41.920 --> 00:24:43.300
actually also take windows.

00:24:43.300 --> 00:24:46.030
So by going into immersive mode,
you actually free the system up

00:24:46.030 --> 00:24:49.600
to have more windows to use
for your app in the compositor.

00:24:49.600 --> 00:24:53.000
OK, so we can actually go
back to the slides now.

00:24:56.310 --> 00:24:58.620
So another thing we
could do is actually

00:24:58.620 --> 00:25:00.890
say, let's try to
cap the frame rate.

00:25:00.890 --> 00:25:03.760
And we've actually added an
API called Choreographer.

00:25:03.760 --> 00:25:05.060
And Choreographer is great.

00:25:05.060 --> 00:25:06.950
It actually gives you
a callback whenever

00:25:06.950 --> 00:25:08.210
there's [INAUDIBLE] coming in.

00:25:08.210 --> 00:25:11.560
And up until N, it
was only available

00:25:11.560 --> 00:25:13.800
inside of managed code.

00:25:13.800 --> 00:25:17.660
But inside of N, we're
now opening it up for use

00:25:17.660 --> 00:25:19.640
in all of your code
inside native code.

00:25:19.640 --> 00:25:21.930
And there's a great
example of this, actually.

00:25:21.930 --> 00:25:24.380
But let me actually show
you what that looks like.

00:25:24.380 --> 00:25:28.020
We can switch back
to the device here.

00:25:28.020 --> 00:25:30.250
Where is this one called?

00:25:30.250 --> 00:25:33.080
Maybe I don't have
it on that screen.

00:25:33.080 --> 00:25:35.190
Yeah, here we are.

00:25:35.190 --> 00:25:37.160
And so now this is actually
using Choreographer

00:25:37.160 --> 00:25:39.860
to lock things as close to 30
frames a second as possible.

00:25:39.860 --> 00:25:41.930
And you can see there,
it's like 28, 29.

00:25:41.930 --> 00:25:43.200
We're still getting some jank.

00:25:43.200 --> 00:25:44.722
And you can see
that it's probably

00:25:44.722 --> 00:25:45.680
running on the threads.

00:25:45.680 --> 00:25:47.410
We're overheating
pretty quickly there.

00:25:47.410 --> 00:25:49.200
But that's another
great thing you can do.

00:25:49.200 --> 00:25:50.616
What's awesome
about Choreographer

00:25:50.616 --> 00:25:52.907
is a lot of people are
like, their app or game

00:25:52.907 --> 00:25:54.740
doesn't need to run at
60 frames per second.

00:25:54.740 --> 00:25:57.170
And they'd much rather
save the user battery life,

00:25:57.170 --> 00:25:59.650
not have the phone
overheat in their hand.

00:25:59.650 --> 00:26:04.120
Users that actually respond on
comments are like, all right,

00:26:04.120 --> 00:26:07.400
I played this game
and I was burning up,

00:26:07.400 --> 00:26:09.320
and I had no battery
left an hour later.

00:26:09.320 --> 00:26:10.700
And one easy thing
to do is say--

00:26:10.700 --> 00:26:13.180
you can even make a slider,
saying, what are the frames,

00:26:13.180 --> 00:26:15.580
do you want to limit the
frames per second of your game?

00:26:15.580 --> 00:26:18.330
And for a lot of games,
that actually is huge.

00:26:18.330 --> 00:26:21.350
And Choreographer allows you
to do that in an extremely,

00:26:21.350 --> 00:26:23.147
extremely power-efficient way.

00:26:23.147 --> 00:26:25.730
And what we're actually doing
in the code-- we can switch back

00:26:25.730 --> 00:26:31.630
to the slides
here-- is basically

00:26:31.630 --> 00:26:33.910
we're getting a frame callback.

00:26:33.910 --> 00:26:36.150
And then we're simply,
every other frame callback,

00:26:36.150 --> 00:26:36.979
we're swapping.

00:26:36.979 --> 00:26:38.270
So it's pretty straightforward.

00:26:38.270 --> 00:26:41.704
This is not the most
intelligent way of doing this

00:26:41.704 --> 00:26:42.870
because you will get jitter.

00:26:42.870 --> 00:26:45.411
If we're not actually able to
render at 30 frames per second,

00:26:45.411 --> 00:26:46.340
this is kind of awful.

00:26:46.340 --> 00:26:48.256
But as long as we're
actually able to do this,

00:26:48.256 --> 00:26:49.870
this actually works pretty well.

00:26:49.870 --> 00:26:52.370
And it's actually not that hard
to make it more complicated.

00:26:52.370 --> 00:26:54.411
This is just the sample
that we ended up writing.

00:26:54.411 --> 00:26:56.460
What's cool is if you
do go to that QR code,

00:26:56.460 --> 00:26:57.610
that sample is live today.

00:26:57.610 --> 00:26:58.100
And it's cool.

00:26:58.100 --> 00:27:00.120
It actually uses Choreographer,
if you're on the latest

00:27:00.120 --> 00:27:01.050
version of Android.

00:27:01.050 --> 00:27:04.040
It uses EGL extensions on
a couple of older versions.

00:27:04.040 --> 00:27:07.040
It actually goes down
to the Java version

00:27:07.040 --> 00:27:08.920
of the API on earlier versions.

00:27:08.920 --> 00:27:11.540
So you actually can see how
to do it all the way back to I

00:27:11.540 --> 00:27:14.670
think 16 or something like
that, which is pretty nice.

00:27:14.670 --> 00:27:16.270
So the sample is cool.

00:27:16.270 --> 00:27:17.450
It's a little complicated.

00:27:17.450 --> 00:27:18.950
I mean, it's not
using more teapots.

00:27:18.950 --> 00:27:20.040
It's just a single teapot.

00:27:22.710 --> 00:27:25.020
All right, so I showed you that.

00:27:25.020 --> 00:27:25.907
And there we are.

00:27:25.907 --> 00:27:27.990
We've got a little bit of
performance clawed back.

00:27:27.990 --> 00:27:29.865
We're getting around 30
frames per second now

00:27:29.865 --> 00:27:32.560
when we're not overheating
under the WolfVision here.

00:27:32.560 --> 00:27:34.760
And this is even better
than we did with just

00:27:34.760 --> 00:27:36.020
reducing the render target.

00:27:36.020 --> 00:27:40.000
And we haven't had to add
a single non-native call

00:27:40.000 --> 00:27:41.077
to do any of this.

00:27:41.077 --> 00:27:43.410
Mind you, every single thing
that you were watching here

00:27:43.410 --> 00:27:46.920
has been entirely
inside of the NDK,

00:27:46.920 --> 00:27:49.840
which I'm very pleased about.

00:27:49.840 --> 00:27:51.850
And I'm sure that our
developers are, too.

00:27:51.850 --> 00:27:54.900
And let me show you one other
little thing that you can do

00:27:54.900 --> 00:27:58.250
and that you might want to
do and why you might not

00:27:58.250 --> 00:28:02.250
want to do that on
N. So how many of you

00:28:02.250 --> 00:28:04.720
have heard about what we've
done with sustained performance

00:28:04.720 --> 00:28:05.930
mode?

00:28:05.930 --> 00:28:09.150
So sustained performance mode
is a feature mostly intended

00:28:09.150 --> 00:28:12.770
for things like VR that
really, really require--

00:28:12.770 --> 00:28:14.020
you don't want to drop frames.

00:28:14.020 --> 00:28:15.600
You don't want the
device to overheat.

00:28:15.600 --> 00:28:17.516
And so basically what
they do is they actually

00:28:17.516 --> 00:28:19.600
try to put the device
in a mode where

00:28:19.600 --> 00:28:21.630
it's never going to overheat.

00:28:21.630 --> 00:28:26.800
Now the problem is, at that
rate under the conditions

00:28:26.800 --> 00:28:29.450
they test on, you're not going
to get the highest performance.

00:28:29.450 --> 00:28:31.360
So what I've done
is I've actually

00:28:31.360 --> 00:28:34.274
taken a version of the app
that actually uses that API.

00:28:34.274 --> 00:28:35.940
This has got all the
other optimizations

00:28:35.940 --> 00:28:37.773
I've put in other than
the Choreographer one

00:28:37.773 --> 00:28:39.380
because it just
gets too horrible.

00:28:39.380 --> 00:28:42.550
And you can see, we're now
getting sustained performance.

00:28:42.550 --> 00:28:44.716
It will never
overheat running this.

00:28:44.716 --> 00:28:45.840
You can run this for hours.

00:28:45.840 --> 00:28:47.960
But we're about 15
frames a second.

00:28:47.960 --> 00:28:49.730
So you do give up a lot.

00:28:49.730 --> 00:28:52.357
But if you absolutely need
sustained performance,

00:28:52.357 --> 00:28:54.440
you can do that, especially
if you're doing things

00:28:54.440 --> 00:28:56.330
like pro audio, where you're
really, really worried

00:28:56.330 --> 00:28:57.150
about glitching.

00:28:57.150 --> 00:28:59.300
This actually does pretty well.

00:28:59.300 --> 00:29:01.280
So that's another
option for you.

00:29:01.280 --> 00:29:03.010
Again, it's just a new window.

00:29:03.010 --> 00:29:06.120
This is the first
actual call through JNI

00:29:06.120 --> 00:29:08.960
that I've had to
make in all of this.

00:29:08.960 --> 00:29:11.360
But as you can see, you
lose a lot of performance.

00:29:11.360 --> 00:29:14.192
You really do have
to make a call there.

00:29:14.192 --> 00:29:15.650
OK, we can go back
to the deck now.

00:29:19.520 --> 00:29:22.870
All right, so there are
a lot of big choices

00:29:22.870 --> 00:29:24.610
to also make when using the NDK.

00:29:24.610 --> 00:29:27.210
Do you use Clang or GCC?

00:29:27.210 --> 00:29:29.550
Do you use HardFP, 64-bit?

00:29:29.550 --> 00:29:30.890
And I wasn't sure.

00:29:30.890 --> 00:29:33.260
So I went and did
more benchmarking.

00:29:33.260 --> 00:29:35.770
This was like a bear to
prepare for this thing.

00:29:35.770 --> 00:29:38.500
So let's talk about performance.

00:29:38.500 --> 00:29:42.320
If you look at Clang
versus GCC in 32-bit mode,

00:29:42.320 --> 00:29:44.100
it's pretty much the same.

00:29:44.100 --> 00:29:47.500
Like, sometimes, it's
exactly the same.

00:29:47.500 --> 00:29:50.610
Literally, the Whetstone number
is identical between these two.

00:29:50.610 --> 00:29:53.900
And they're within a percent
or so of any of the other two,

00:29:53.900 --> 00:29:55.280
which is kind of what we expect.

00:29:55.280 --> 00:29:57.900
And if you actually run your
code and run benchmarks on it

00:29:57.900 --> 00:30:00.940
and you see anything different,
report it to our compiler team.

00:30:00.940 --> 00:30:03.390
There's actually a place
where you can file issues

00:30:03.390 --> 00:30:04.720
on our NDK site.

00:30:04.720 --> 00:30:07.610
Let us know, because the
team is really, really,

00:30:07.610 --> 00:30:10.020
very, very aggressive
about trying to make

00:30:10.020 --> 00:30:13.050
the compiler perform well.

00:30:13.050 --> 00:30:18.120
In 64-bit world, it's
actually also just as close.

00:30:18.120 --> 00:30:19.875
GCC sometimes outperforms Clang.

00:30:19.875 --> 00:30:21.500
Clang sometimes outperforms GCC.

00:30:21.500 --> 00:30:23.440
But it is completely
not noticeable.

00:30:23.440 --> 00:30:26.139
These are very
competitive compilers.

00:30:26.139 --> 00:30:27.680
However, when we
look at build times,

00:30:27.680 --> 00:30:29.050
this is our Zooshi application.

00:30:29.050 --> 00:30:31.830
And this is kind of crazy,
because Zooshi actually

00:30:31.830 --> 00:30:35.505
has tons of assets that
get built along with it.

00:30:35.505 --> 00:30:37.150
And I didn't even pull them out.

00:30:37.150 --> 00:30:38.160
I simply just said,
all right, I'm

00:30:38.160 --> 00:30:39.160
going to do this the dumb way.

00:30:39.160 --> 00:30:40.360
I'm just going to
build it from scratch.

00:30:40.360 --> 00:30:41.400
Have it build all its assets.

00:30:41.400 --> 00:30:42.941
Go through all of
its resource stuff.

00:30:42.941 --> 00:30:48.080
And it was 1.4 times
the speed of GCC.

00:30:48.080 --> 00:30:51.880
And you can see why our
internal Android team really

00:30:51.880 --> 00:30:54.404
wanted to switch to Clang,
because I don't know if you've

00:30:54.404 --> 00:30:55.820
ever heard of the
kind of machines

00:30:55.820 --> 00:30:58.319
that it takes to actually build
Android, the whole platform,

00:30:58.319 --> 00:30:59.620
but it's a lot of code.

00:30:59.620 --> 00:31:03.600
So if you can improve your
compile speed by 1.4, 1.5,

00:31:03.600 --> 00:31:06.780
1.6 times, that's a
huge productivity gain.

00:31:06.780 --> 00:31:08.780
But also, there's
great sanitizers

00:31:08.780 --> 00:31:11.200
that are built into Clang
that the team loves.

00:31:11.200 --> 00:31:13.420
And actually the error
messages are kind of cool.

00:31:13.420 --> 00:31:17.230
Although, GCC is making massive,
massive improvements there.

00:31:17.230 --> 00:31:20.720
But this is still,
honestly, it's huge for me.

00:31:20.720 --> 00:31:24.640
Now there's a big thing
about HardFP on ARM7.

00:31:24.640 --> 00:31:26.670
How many people have
actually heard of this?

00:31:26.670 --> 00:31:28.860
How many people actually use it?

00:31:28.860 --> 00:31:31.950
OK, all I can say is every
time I've tried to use it,

00:31:31.950 --> 00:31:34.079
I've run into bugs.

00:31:34.079 --> 00:31:35.620
I've run into things
that don't work.

00:31:35.620 --> 00:31:38.580
It's a really, really,
really hacky thing.

00:31:38.580 --> 00:31:41.970
And it's not used internally
by the platform at all.

00:31:41.970 --> 00:31:43.650
And because of
that, our Tools team

00:31:43.650 --> 00:31:46.220
made the decision
to eliminate it.

00:31:46.220 --> 00:31:49.410
So it is not in NDK r12.

00:31:49.410 --> 00:31:52.860
Basically, if you're making
a whole bunch of calls

00:31:52.860 --> 00:31:55.790
to math libraries, this
is where you'll actually

00:31:55.790 --> 00:31:58.387
get hit by this.

00:31:58.387 --> 00:32:00.720
What this is actually doing,
it's not actually not using

00:32:00.720 --> 00:32:01.980
hardware floating point.

00:32:01.980 --> 00:32:04.940
It simply has to do with the way
floating point parameters are

00:32:04.940 --> 00:32:06.795
passed in function calls.

00:32:06.795 --> 00:32:08.920
So if you look at the
assembly that gets generated,

00:32:08.920 --> 00:32:10.980
it's a little more expensive.

00:32:10.980 --> 00:32:13.220
But the truth is, if
function call overhead

00:32:13.220 --> 00:32:15.662
is your problem in your
application and your floating

00:32:15.662 --> 00:32:17.120
point intensive
application, you've

00:32:17.120 --> 00:32:20.290
probably done something wrong.

00:32:20.290 --> 00:32:23.330
Hopefully, you aren't
actually making a call

00:32:23.330 --> 00:32:25.200
to do something extremely,
extremely simple

00:32:25.200 --> 00:32:26.410
that you can just inline.

00:32:26.410 --> 00:32:27.920
And that's the hope.

00:32:27.920 --> 00:32:30.690
And most of the important math
functions will get inlined.

00:32:30.690 --> 00:32:32.741
However, we know there
is some code that's

00:32:32.741 --> 00:32:34.490
going to lose performance
because of this.

00:32:34.490 --> 00:32:36.410
But honestly, once
we actually started

00:32:36.410 --> 00:32:37.900
looking at the
problems with bugs

00:32:37.900 --> 00:32:40.200
that people were having and
the fact that the platform

00:32:40.200 --> 00:32:42.533
team wasn't using it-- and
when the platform doesn't use

00:32:42.533 --> 00:32:44.440
something on
Android, it generally

00:32:44.440 --> 00:32:46.540
doesn't get nearly as well
tested as it should be.

00:32:46.540 --> 00:32:48.769
So it's really, really
important for us to do that.

00:32:48.769 --> 00:32:51.060
That's what's so great about
what we've done with Clang

00:32:51.060 --> 00:32:52.920
is that Clang is actually used.

00:32:52.920 --> 00:32:54.780
You're getting the
exact same toolchain

00:32:54.780 --> 00:32:56.770
for almost the first
time ever that's

00:32:56.770 --> 00:32:58.790
used to build the platform.

00:32:58.790 --> 00:33:00.540
And it's being very,
very well maintained.

00:33:00.540 --> 00:33:02.331
It's also the same
version of the toolchain

00:33:02.331 --> 00:33:04.280
that we're using inside
Google Data Centers.

00:33:04.280 --> 00:33:06.529
And if you know the way we
test stuff in data centers,

00:33:06.529 --> 00:33:08.010
is we roll it out to 10%.

00:33:08.010 --> 00:33:08.860
See what's going on.

00:33:08.860 --> 00:33:10.190
See if we hit any bugs.

00:33:10.190 --> 00:33:10.900
Pull it back.

00:33:10.900 --> 00:33:12.270
Change, do fixes.

00:33:12.270 --> 00:33:14.810
And so we actually get to take
advantage of all the stuff

00:33:14.810 --> 00:33:17.050
that they're doing to make
the data centers rock.

00:33:17.050 --> 00:33:19.470
So it's actually really,
really good, I think,

00:33:19.470 --> 00:33:22.780
that we're actually all united
around making one compiler

00:33:22.780 --> 00:33:24.330
work really, really well.

00:33:24.330 --> 00:33:26.087
And not that GCC
is dropping away.

00:33:26.087 --> 00:33:28.670
If you do need it, if your code
doesn't compile, first of all,

00:33:28.670 --> 00:33:31.640
let us know if you have a
problem compiling with Clang,

00:33:31.640 --> 00:33:33.010
and we'll try to fix it.

00:33:33.010 --> 00:33:41.452
And second of all, we are going
to keep GCC around for a while.

00:33:41.452 --> 00:33:42.410
So it's not going away.

00:33:42.410 --> 00:33:44.076
We're just not updating
to new versions.

00:33:44.076 --> 00:33:49.230
If you're expecting to get
GCC 5, 4.9 is pretty much it.

00:33:49.230 --> 00:33:52.830
So one final thing is if you
really want high performance,

00:33:52.830 --> 00:33:57.200
definitely look at
doing a 64-bit ABI.

00:33:57.200 --> 00:34:00.370
And really, I was
actually not 100%

00:34:00.370 --> 00:34:04.379
sold on this because you do end
up using a little more memory.

00:34:04.379 --> 00:34:06.170
And that does, of
course, mean you're using

00:34:06.170 --> 00:34:07.461
a little more memory bandwidth.

00:34:07.461 --> 00:34:10.770
But the extra registers that
you get that the compiler can

00:34:10.770 --> 00:34:14.170
optimize around for
64-bit completely makes up

00:34:14.170 --> 00:34:17.940
for any memory inefficiencies
is has, almost all of the time.

00:34:17.940 --> 00:34:19.729
And we ran these
benchmarks a lot.

00:34:19.729 --> 00:34:21.520
We found a whole bunch
of other benchmarks.

00:34:21.520 --> 00:34:23.520
In general, if you have
something that's really,

00:34:23.520 --> 00:34:27.429
really performance sensitive,
consider doing a 64-bit ABI.

00:34:27.429 --> 00:34:30.170
Consider, if it's not
too big, just include it.

00:34:30.170 --> 00:34:32.290
Of course, you can
include multiple ABIs

00:34:32.290 --> 00:34:35.110
in multiple libraries
into any Android APK.

00:34:35.110 --> 00:34:37.150
Or you can use
multi-APK to distribute

00:34:37.150 --> 00:34:40.159
multiple different
versions of your app.

00:34:40.159 --> 00:34:43.690
And again, it just works better.

00:34:43.690 --> 00:34:45.940
And the best thing about
it is you already get

00:34:45.940 --> 00:34:50.230
hard floating point when
you're running in on v8.

00:34:50.230 --> 00:34:52.179
Finally x86 native.

00:34:52.179 --> 00:34:55.550
The x86 emulation that is in
a bunch of Android devices

00:34:55.550 --> 00:34:59.740
that allows them to run
arm code is awesome.

00:34:59.740 --> 00:35:02.460
The fact that it
performs this well on,

00:35:02.460 --> 00:35:05.810
admittedly, meaningless
benchmarks is pretty good.

00:35:05.810 --> 00:35:07.800
But you can see like
with Whetstone, you

00:35:07.800 --> 00:35:10.520
can be giving up easily
two-thirds of your performance

00:35:10.520 --> 00:35:12.794
by not having an x86 build.

00:35:12.794 --> 00:35:15.210
And so if you want to target
devices like the Nexus player

00:35:15.210 --> 00:35:18.160
and like the Zen phone,
which are both pretty awesome

00:35:18.160 --> 00:35:20.660
devices, definitely
consider actually

00:35:20.660 --> 00:35:22.280
doing a native x86 version.

00:35:22.280 --> 00:35:24.780
At least test it
because it really

00:35:24.780 --> 00:35:28.700
makes a huge difference
in terms of battery life.

00:35:28.700 --> 00:35:33.640
OK, so the Android runtime
does a lot of things

00:35:33.640 --> 00:35:35.510
to make everything run fast.

00:35:35.510 --> 00:35:37.110
On Android L and
M, it uses actually

00:35:37.110 --> 00:35:38.580
ahead-of-time
compilation to bring

00:35:38.580 --> 00:35:39.954
the performance
of byte code much

00:35:39.954 --> 00:35:41.540
closer to native performance.

00:35:41.540 --> 00:35:43.130
And on N, of course,
it uses a blend

00:35:43.130 --> 00:35:46.810
of just-in-time and
ahead-of-time compilation.

00:35:46.810 --> 00:35:49.540
And once again, it deals much,
much better with garbage.

00:35:49.540 --> 00:35:53.580
And what we're seeing with ART,
is that a lot of times, you

00:35:53.580 --> 00:35:56.170
don't actually need to
even go into native land.

00:35:56.170 --> 00:35:58.770
Again, if all you're concerned
about is performance,

00:35:58.770 --> 00:36:00.880
ART is actually doing
amazing, amazing stuff.

00:36:00.880 --> 00:36:02.421
And you don't have
to worry about all

00:36:02.421 --> 00:36:04.250
of these kinds of things.

00:36:04.250 --> 00:36:06.212
So it's complicated,
as I said before.

00:36:06.212 --> 00:36:08.670
That means that it's a little
more expensive to actually do

00:36:08.670 --> 00:36:09.850
a JNI call.

00:36:09.850 --> 00:36:11.750
And again, we have to
do synchronization.

00:36:11.750 --> 00:36:15.000
And that's what's causing us
to actually have these delays.

00:36:15.000 --> 00:36:17.960
So what's next?

00:36:17.960 --> 00:36:21.200
Basically, here are two
links you can go to.

00:36:21.200 --> 00:36:24.420
One of them, of course,
takes us into our NDK page.

00:36:24.420 --> 00:36:27.740
We actually have NDK docs
online, which is amazing.

00:36:27.740 --> 00:36:28.740
And we're updating them.

00:36:28.740 --> 00:36:31.073
We have people who are actually
assigned to this project

00:36:31.073 --> 00:36:32.340
to make it awesome.

00:36:32.340 --> 00:36:34.439
Secondly, we have
great NDK samples.

00:36:34.439 --> 00:36:36.230
And we're putting more
online all the time.

00:36:36.230 --> 00:36:38.313
So if there's anything you
want that we don't have

00:36:38.313 --> 00:36:40.200
a sample for, an API
that's not covered,

00:36:40.200 --> 00:36:42.150
let us know we'll build samples.

00:36:42.150 --> 00:36:45.500
[MUSIC PLAYING]

