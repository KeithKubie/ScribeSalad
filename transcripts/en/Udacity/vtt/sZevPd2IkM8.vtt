WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:03.370
So, now that we've got utility fine,
and we've got this pi star to fine,

00:00:03.370 --> 00:00:07.510
we can actually do an even better
job of writing out pi star.

00:00:07.510 --> 00:00:09.010
And let me do that.

00:00:09.010 --> 00:00:10.810
All right, so
does this equation make sense, Michael?

00:00:10.810 --> 00:00:14.830
&gt;&gt; Let's see, so the policy,
is that a star again, or is that a K.

00:00:14.830 --> 00:00:16.079
&gt;&gt; That's a star.

00:00:16.079 --> 00:00:17.110
So it's the optimal policy.

00:00:17.110 --> 00:00:18.750
&gt;&gt; All right.

00:00:18.750 --> 00:00:23.840
The optimal action to take at a state
is, well, look over all the actions,

00:00:23.840 --> 00:00:28.870
and sum up overall the next states,
the transition probability,

00:00:28.870 --> 00:00:33.460
so that's the probability
we end up in state s prime.

00:00:33.460 --> 00:00:35.890
And now we have the utility of s prime,

00:00:35.890 --> 00:00:38.650
the problem being that
that's not defined.

00:00:38.650 --> 00:00:39.590
&gt;&gt; Well, it sort of is,

00:00:39.590 --> 00:00:42.717
we defined it immediately above,
at least with respect to some policy.

00:00:44.240 --> 00:00:46.280
&gt;&gt; But
that's concerning because we don't know.

00:00:46.280 --> 00:00:49.497
The policy that you want to put in there
is gotta be the policy that you're

00:00:49.497 --> 00:00:50.625
trying to find.

00:00:50.625 --> 00:00:54.805
&gt;&gt; Right, so in fact implicitly
what I mean here is pi star.

00:00:54.805 --> 00:00:59.660
So, in fact, let me write that down that
whenever you see me write from now on,

00:01:01.130 --> 00:01:06.560
the utility of a state,
I'm almost always going to actually mean

00:01:06.560 --> 00:01:10.420
the utility of the state if
I follow the optimal policy.

00:01:10.420 --> 00:01:13.581
We might call this the true
utility of the state.

00:01:13.581 --> 00:01:15.190
&gt;&gt; I see.
&gt;&gt; So I'm just going to write this off

00:01:15.190 --> 00:01:17.960
to the side here as something for
you to remember.

00:01:17.960 --> 00:01:21.940
So this this says then that the optimal
policy is the one that, for

00:01:21.940 --> 00:01:27.180
every state, returns the action
that maximizes my expected utility.

00:01:27.180 --> 00:01:29.780
&gt;&gt; With regard to the optimal policy,
it feels rather circular.

00:01:29.780 --> 00:01:33.280
&gt;&gt; It is rather circular, but
you're a computationalist.

00:01:33.280 --> 00:01:34.650
You're a big fan of recursion.

00:01:34.650 --> 00:01:37.640
We just went through a whole exercise
where we figured out the geometric

00:01:37.640 --> 00:01:39.870
series by effectively doing recursion.

00:01:39.870 --> 00:01:42.170
&gt;&gt; It's a similar kind of situation,
for this?

00:01:42.170 --> 00:01:42.820
&gt;&gt; It kind of is.

00:01:42.820 --> 00:01:44.480
So, let me write one
more equation down and

00:01:44.480 --> 00:01:47.680
then you'll be one step
closer to actually seeing it.

00:01:47.680 --> 00:01:50.520
Of course, if we're in an infinite
horizon with a discounted state,

00:01:50.520 --> 00:01:53.780
even though you're one step closer
you won't actually be any closer.

00:01:53.780 --> 00:01:55.450
Well let's worry about
that when we get there.

00:01:55.450 --> 00:01:57.900
So let me write one more equation down.

00:01:57.900 --> 00:01:59.020
&gt;&gt; We're never going to get there.

00:01:59.020 --> 00:01:59.945
It's infinitely long.

00:01:59.945 --> 00:02:01.800
&gt;&gt; [LAUGH] Yeah.

00:02:01.800 --> 00:02:03.160
&gt;&gt; Wait are you
demonstrating something with

00:02:03.160 --> 00:02:05.055
this lesson by making
it infinitely long?

00:02:05.055 --> 00:02:08.310
&gt;&gt; [LAUGH] I'm certainly demonstrating
something with this lesson.

00:02:08.310 --> 00:02:09.220
I don't know what it is.

00:02:09.220 --> 00:02:10.639
So let me write this next equation down.

00:02:10.639 --> 00:02:14.600
So then the true utility
of a state s is then,

00:02:14.600 --> 00:02:17.630
I'm just basically going to
unroll the equation for utility.

00:02:17.630 --> 00:02:22.700
It's the reward that I get for
being in that state, plus I'm now

00:02:22.700 --> 00:02:26.910
going to discount all of the reward that
I'm going to get from that point on.

00:02:28.030 --> 00:02:28.750
Got it?

00:02:28.750 --> 00:02:31.620
&gt;&gt; All right, so
once we go to our new state s prime,

00:02:31.620 --> 00:02:34.420
we're going to look at
the utility of that state.

00:02:34.420 --> 00:02:37.842
Okay, that's sort of fine,
modular recursion.

00:02:37.842 --> 00:02:40.150
We're going to look at overall actions,

00:02:40.150 --> 00:02:42.500
which action gives us
the highest value of that.

00:02:42.500 --> 00:02:45.250
Oh I see, that's kind of like
the pi star expression just above.

00:02:45.250 --> 00:02:45.750
&gt;&gt; Yup.

00:02:46.770 --> 00:02:48.920
All right, so once we figure that out,

00:02:48.920 --> 00:02:52.250
we know what action we're going
to take in state s prime.

00:02:52.250 --> 00:02:54.310
We're going to discount that,
because why?

00:02:54.310 --> 00:02:58.340
Because I guess that just
kind of ups the gamma

00:02:58.340 --> 00:03:00.520
factor on all the rewards in the future.

00:03:00.520 --> 00:03:01.020
&gt;&gt; Right.

00:03:01.020 --> 00:03:03.080
&gt;&gt; And then we're going to add
to that our immediate reward.

00:03:04.440 --> 00:03:06.790
Yes, okay I think I follow that.

00:03:06.790 --> 00:03:08.858
&gt;&gt; In some sense all I've done is
I kept substituting pieces back

00:03:08.858 --> 00:03:09.507
into one another.

00:03:09.507 --> 00:03:12.752
So the true utility being in a state
is the reward you get in that state,

00:03:12.752 --> 00:03:15.887
plus the discount of all the reward
you're going to get at that point,

00:03:15.887 --> 00:03:18.967
which, of course, is defined as
the utility you're going to get for

00:03:18.967 --> 00:03:22.162
the states that you see, but
each one of those is defined similarly.

00:03:22.162 --> 00:03:26.182
And so the utility you will get for
s double prime say will also be further

00:03:26.182 --> 00:03:30.537
discounted but since it's multiplied
by gamma that will be gamma squared and

00:03:30.537 --> 00:03:33.016
then s triple prime will be gamma cubed,
and

00:03:33.016 --> 00:03:36.935
so that's basically just unrolling
this notion of utility up here.

00:03:36.935 --> 00:03:39.375
&gt;&gt; Okay so now it seems like all
the pieces are in one place.

00:03:39.375 --> 00:03:40.185
&gt;&gt; Right.

00:03:40.185 --> 00:03:42.845
And so it would be nice if we were done.

00:03:42.845 --> 00:03:45.770
And I'm going to say that we're
not just one step closer, but

00:03:45.770 --> 00:03:50.130
you can see an oncoming light and
it is not an oncoming train, okay.

00:03:50.130 --> 00:03:50.680
So
&gt;&gt; Yeah,

00:03:50.680 --> 00:03:52.070
this seems like a really
important equation.

00:03:52.070 --> 00:03:54.390
&gt;&gt; It is, in fact, it's so
important, it's got a name.

00:03:54.390 --> 00:03:55.910
You want to guess what the name is?

00:03:55.910 --> 00:03:58.120
&gt;&gt; Bill
&gt;&gt; That's actually very close.

00:03:58.120 --> 00:03:59.760
It's Bellman Equation.

00:03:59.760 --> 00:04:03.156
&gt;&gt; Bellman equation
&gt;&gt; Esquire.

00:04:03.156 --> 00:04:07.960
This equation was invented by a guy
named Bellman, and it turns out to be in

00:04:07.960 --> 00:04:12.856
some sense the key equation for
solving MDPs and reinforcement learning.

00:04:12.856 --> 00:04:14.410
&gt;&gt; Wow.

00:04:14.410 --> 00:04:16.610
&gt;&gt; And it's actually even more
[INAUDIBLE] than it looks.

00:04:16.610 --> 00:04:21.680
But basically, this is the fundamental
recursive equation that defines

00:04:21.680 --> 00:04:24.730
the true value of being
in some particular state.

00:04:24.730 --> 00:04:27.770
And it accounts for everything
that we care about in the MDP.

00:04:27.770 --> 00:04:31.723
The utilities themselves deal with
the policy that we want to have,

00:04:31.723 --> 00:04:35.260
the gammas are discount, and
all the rewards are here.

00:04:35.260 --> 00:04:37.128
The transition matrix is here,
and the actions or

00:04:37.128 --> 00:04:38.610
all the actions we're going to take.

00:04:38.610 --> 00:04:43.790
So basically the whole MDP is
referenced inside of here and allows

00:04:43.790 --> 00:04:47.670
us by determining utilities, to always
know what's the best action to take.

00:04:47.670 --> 00:04:49.610
What's the one that's going to
maximize the utility?

00:04:49.610 --> 00:04:52.480
So if we can figure out
the answer to this equation,

00:04:52.480 --> 00:04:57.150
the utilities of all the states, we per
force know what the optimal policy is.

00:04:57.150 --> 00:04:58.490
It becomes very easy.

00:04:58.490 --> 00:05:01.550
So we've sort of taken all
that neat stuff about NDPs and

00:05:01.550 --> 00:05:02.920
stuck it in a single equation.

00:05:02.920 --> 00:05:05.040
Bellman was a very smart guy.

00:05:06.050 --> 00:05:10.080
&gt;&gt; So was he the same Bellman
from the curse of dimensionality?

00:05:10.080 --> 00:05:10.930
&gt;&gt; Yes.

00:05:10.930 --> 00:05:13.190
&gt;&gt; Cool.
&gt;&gt; There can be only one Bellman.

00:05:13.190 --> 00:05:14.800
&gt;&gt; [LAUGH]
&gt;&gt; Actually,

00:05:14.800 --> 00:05:15.580
are there any more Bellmans?

00:05:15.580 --> 00:05:18.610
I don't think so, I think that they
retired, like retiring a jersey.

00:05:18.610 --> 00:05:20.310
They retired his name.

00:05:20.310 --> 00:05:22.530
I could've sworn that I saw one
at the last hotel that I went to.

00:05:22.530 --> 00:05:23.980
&gt;&gt; It was probably the same one.

00:05:23.980 --> 00:05:24.700
Oh, I get it.

00:05:24.700 --> 00:05:26.450
Hotel, Bellman, that's really good.

00:05:26.450 --> 00:05:27.140
&gt;&gt; Very good.

00:05:27.140 --> 00:05:27.880
&gt;&gt; Okay good.

00:05:27.880 --> 00:05:30.670
Well, so now that we've killed
that as much as we could,

00:05:30.670 --> 00:05:32.460
let's see if we can actually
solve this equation,

00:05:32.460 --> 00:05:36.310
which since this is clearly the key
equation since it has a name, okay?

00:05:36.310 --> 00:05:37.070
&gt;&gt; Yeah, that would be cool.

00:05:37.070 --> 00:05:39.040
Especially because it looks like,
if you could solve this,

00:05:39.040 --> 00:05:40.695
you could solve it, right?

00:05:40.695 --> 00:05:41.440
because then you have u.

00:05:41.440 --> 00:05:43.350
You could just plug the u in and
get the u out.

00:05:43.350 --> 00:05:44.320
&gt;&gt; Right.
And once you have the u in, and

00:05:44.320 --> 00:05:47.080
you get the u out,
then you got the policy.

00:05:47.080 --> 00:05:48.310
&gt;&gt; Right.
&gt;&gt; For u.

00:05:48.310 --> 00:05:49.635
&gt;&gt; It's always been for u.

00:05:49.635 --> 00:05:51.390
&gt;&gt; [LAUGH] It's for us,
Michael, it's for us.

