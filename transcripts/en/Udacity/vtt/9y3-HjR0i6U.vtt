WEBVTT
Kind: captions
Language: en

00:00:00.470 --> 00:00:02.920
Let's consider now
a little more carefully

00:00:02.920 --> 00:00:06.020
how we map trading to an RL problem.

00:00:06.020 --> 00:00:10.860
So first of all the environment
here is really the market.

00:00:10.860 --> 00:00:16.329
Our state that we're going to consider
includes things like market features,

00:00:16.329 --> 00:00:19.280
prices, whether we're holding the stock.

00:00:19.280 --> 00:00:21.690
I'll list a few of
those items right here.

00:00:21.690 --> 00:00:25.940
Our actions are things like buy and
sell, and

00:00:25.940 --> 00:00:30.220
potentially do nothing is
also an allowable action.

00:00:30.220 --> 00:00:32.659
So let's think about
this in the context of

00:00:32.659 --> 00:00:36.150
trying to learn how to
trade a particular stock.

00:00:36.150 --> 00:00:38.890
So we've got this
historical time series, and

00:00:38.890 --> 00:00:40.900
let's say this vertical line is today.

00:00:41.920 --> 00:00:46.830
Now we can look back over time
to infer the state of the stock.

00:00:46.830 --> 00:00:50.950
So what are the Ballinger Band
values and things like that.

00:00:50.950 --> 00:00:55.540
Now we process that and
decide what's our action.

00:00:55.540 --> 00:00:58.630
Let's suppose that we decide to buy.

00:00:58.630 --> 00:01:01.750
So once we buy, we're now holding long.

00:01:01.750 --> 00:01:02.880
That's part of our state.

00:01:03.900 --> 00:01:08.160
We go forward, we're now on a new
state where the price has gone up.

00:01:08.160 --> 00:01:11.960
We're holding long, let's suppose
we decide to sell at that point.

00:01:13.030 --> 00:01:14.440
So we've had two actions,

00:01:14.440 --> 00:01:19.600
well we've been in two states in
state one we were not holding.

00:01:19.600 --> 00:01:23.170
We executed the action by,
went forward in time,

00:01:23.170 --> 00:01:27.640
we're holding along now, and
then we execute the action sell.

00:01:27.640 --> 00:01:32.710
Note that we made money here and
that's our reward, r.

00:01:32.710 --> 00:01:34.540
So just to recap for a moment.

00:01:34.540 --> 00:01:40.605
The policy that we learn tells us what
to do at each time we evaluate state,

00:01:40.605 --> 00:01:42.365
and we're going to learn
that we haven't talked yet

00:01:42.365 --> 00:01:43.965
about how we learned the policy.

00:01:43.965 --> 00:01:47.675
But we're going to learn the policy
by looking at how we accrue money or

00:01:47.675 --> 00:01:50.125
don't based on the actions
we take in the environment.

