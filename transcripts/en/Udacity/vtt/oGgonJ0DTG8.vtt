WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.000
Now it's called search traditionally, but I think "exploration" is a better name for it.

00:00:06.000 --> 00:00:10.000
We start out at home, and in this case our home is where we have two glasses.

00:00:10.000 --> 00:00:15.000
Zero and zero are the values for how full the glasses are.

00:00:15.000 --> 00:00:17.000
Then we start to explore.

00:00:17.000 --> 00:00:21.000
One way we could explore is to fill one of the glasses

00:00:21.000 --> 00:00:25.000
Then we're at this state--say we're at 0 and 4--

00:00:25.000 --> 00:00:29.000
but we know that there are other actions in which we could explore in other directions.

00:00:29.000 --> 00:00:35.000
Now we could take one of the other states and explore from there in other directions.

00:00:35.000 --> 00:00:41.000
We have lots of choices going forward of this huge space that we're exploring.

00:00:41.000 --> 00:00:45.000
Now, somewhere out in this space--and we don't know which direction it is--

00:00:45.000 --> 00:00:53.000
is this goal state, which has 6 and then actually any amount in the other glass.

00:00:53.000 --> 00:00:59.000
We're trying to reach that, and we're distinguishing this part of the state space as a goal.

00:00:59.000 --> 00:01:06.000
So I drew this as one, but really it's a collection of states in that every state that has 6 on one side

00:01:06.000 --> 00:01:12.000
and anything on the other should be considered part of this collection of goals.

00:01:12.000 --> 00:01:15.000
We're trying to search forwards towards that.

00:01:15.000 --> 00:01:20.000
One reason I like to call it an exploration problem is because we can think of going forward,

00:01:20.000 --> 00:01:26.000
exploring a new land, and part of that exploration is that we've got a frontier.

00:01:26.000 --> 00:01:30.000
Here's all the states that are the farthest out that we've gone.

00:01:30.000 --> 00:01:33.000
If we want to make progress towards the goal,

00:01:33.000 --> 00:01:37.000
then we're probably going to have to step from one of the frontier nodes farther out.

00:01:37.000 --> 00:01:43.000
We've separated the set of all possible states into the goal state, the frontier states,

00:01:43.000 --> 00:01:46.000
and the previously explored states.

00:01:46.000 --> 00:01:53.000
Then you can see that the way to make progress is to say let's take one of the frontier states

00:01:53.000 --> 00:01:57.000
and expand that, and we have the advantage here of being a computer

00:01:57.000 --> 00:01:59.000
that an individual explorer doesn't have.

00:01:59.000 --> 00:02:02.000
An individual explorer has to take one path,

00:02:02.000 --> 00:02:05.000
and if they decide they've gone in the wrong direction, they have to go all the way back.

00:02:05.000 --> 00:02:09.000
A computer can store lots of states in memory.

00:02:09.000 --> 00:02:17.000
Computer exploration is more like a collection of explorers all collectively expanding the frontier.

00:02:17.000 --> 00:02:23.000
Our next move can be to say we'll take one of these explorers, say the one in this state here,

00:02:23.000 --> 00:02:25.000
and say now tell me what's next.

00:02:25.000 --> 00:02:28.000
You've got 6 actions from there. Where do they go to?

00:02:28.000 --> 00:02:34.000
Maybe some of them explore the world and generate new states that we haven't seen before.

00:02:34.000 --> 00:02:39.000
Maybe some of them go to a state that we already know is on the frontier.

00:02:39.000 --> 00:02:44.000
Maybe some of them regress backwards into previously explored territory.

00:02:44.000 --> 00:02:49.000
But we can keep on going, expanding out our frontier until eventually

00:02:49.000 --> 00:02:52.000
the frontier keeps on expanding.

00:02:52.000 --> 00:02:55.000
When it overlaps the goal, then we've got a solution.

00:02:55.000 --> 00:03:01.000
Now, in exploration problems like this, there are two problems that we have to worry about.

00:03:01.000 --> 00:03:08.000
One problem is that there is no solution at all, that the goals are not connected to the to start state.

00:03:08.000 --> 00:03:11.000
So there's no path from here to there.

00:03:11.000 --> 00:03:15.000
Then what we want to do is do the exploration we need and report back that it's impossible.

00:03:15.000 --> 00:03:17.000
We want to find out that it's impossible.

00:03:17.000 --> 00:03:23.000
Then the other problem is if there is some path that eventually makes it to the goal,

00:03:23.000 --> 00:03:26.000
We want to make sure that we find that in a reasonable amount of time.

00:03:26.000 --> 00:03:30.000
That means we want to be efficient about the way we explore the space.

00:03:30.000 --> 00:03:34.000
It also means that we don't want to get stuck in an infinite loop.

00:03:34.000 --> 00:03:39.000
Now, if there is a finite number of states and they are connected,

00:03:39.000 --> 00:03:41.000
then we should be able to find the path.

00:03:41.000 --> 00:03:47.000
But if we aren't clever, we may miss the solution even though it's possible to find it.

00:03:47.000 --> 00:03:54.000
For example, if we had a strategy that says first I'm going to explore in this direction--

00:03:54.000 --> 00:03:58.000
say this is pouring from cup x into cup y--

00:03:58.000 --> 00:04:04.000
and then I go in this direction, pouring from cup y back in to cup x,

00:04:04.000 --> 00:04:08.000
and then I pour the water back again--so I'm continually just taking water

00:04:08.000 --> 00:04:11.000
and pouring it between two different cups back and forth,

00:04:11.000 --> 00:04:16.000
those are all legal steps to take, but I'm ending up with an infinitely long path

00:04:16.000 --> 00:04:18.000
and I'm not making any progress.

00:04:18.000 --> 00:04:22.000
We'd like to come up with a strategy for exploration,

00:04:22.000 --> 00:04:28.000
and the strategy corresponds to deciding which path to expand next.

00:04:28.000 --> 00:04:31.000
Strategy is always there's some path--let's say this one--

00:04:31.000 --> 00:04:34.000
and we say that's the one we're going to explore from next.

00:04:34.000 --> 00:04:38.000
To avoid this type of infinite loop, here's some possibilities.

00:04:38.000 --> 00:04:42.000
One possibility would be don't reverse an action.

00:04:42.000 --> 00:04:49.000
If you come from state A to state B, don't allow the action that goes immediately back to state A.

00:04:49.000 --> 00:04:54.000
Another strategy would be to say always take the shortest path first.

00:04:54.000 --> 00:04:56.000
Out of all the paths that you've built so far,

00:04:56.000 --> 00:04:59.000
when we go to choose which one we're going to expand next,

00:04:59.000 --> 00:05:02.000
always choose one of the shortest ones.

00:05:02.000 --> 00:05:07.000
That way we might start to build up an infinitely long path,

00:05:07.000 --> 00:05:12.000
but at least we won't continue it. First we'll do another one before we do that one.

00:05:12.000 --> 00:05:15.000
Then another strategy would be don't re-explore.

00:05:15.000 --> 00:05:20.000
That is, if we're on the frontier--let's say we're here on the frontier--

00:05:20.000 --> 00:05:26.000
and we have a move that moves us back out of the frontier into the previously explored zone,

00:05:26.000 --> 00:05:28.000
then we should not allow that path.

00:05:28.000 --> 00:05:33.000
My question is check all the strategies that would eventually lead us to the goal.

00:05:33.000 --> 00:05:36.000
Don't worry about the efficiency of getting to the goal,

00:05:36.000 --> 09:59:59.000
but which one will eventually get us there and won't get stuck in an infinite loop.

