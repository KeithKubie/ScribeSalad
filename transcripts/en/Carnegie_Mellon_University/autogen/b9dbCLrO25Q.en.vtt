WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.690
going to lead off this morning with the

00:00:02.690 --> 00:00:02.700
going to lead off this morning with the
 

00:00:02.700 --> 00:00:05.720
going to lead off this morning with the
recipient last night of the inaugural

00:00:05.720 --> 00:00:05.730
recipient last night of the inaugural
 

00:00:05.730 --> 00:00:08.750
recipient last night of the inaugural
K&amp;L gates professorship of ethics and

00:00:08.750 --> 00:00:08.760
K&amp;L gates professorship of ethics and
 

00:00:08.760 --> 00:00:11.230
K&amp;L gates professorship of ethics and
computational technologies Elinor Bosch

00:00:11.230 --> 00:00:11.240
computational technologies Elinor Bosch
 

00:00:11.240 --> 00:00:13.820
computational technologies Elinor Bosch
ela is the director of the community

00:00:13.820 --> 00:00:13.830
ela is the director of the community
 

00:00:13.830 --> 00:00:16.460
ela is the director of the community
robotics education and technology

00:00:16.460 --> 00:00:16.470
robotics education and technology
 

00:00:16.470 --> 00:00:19.279
robotics education and technology
empowerment lab for those of you who

00:00:19.279 --> 00:00:19.289
empowerment lab for those of you who
 

00:00:19.289 --> 00:00:20.870
empowerment lab for those of you who
were here last night you heard him refer

00:00:20.870 --> 00:00:20.880
were here last night you heard him refer
 

00:00:20.880 --> 00:00:22.310
were here last night you heard him refer
to the create lab now you know what the

00:00:22.310 --> 00:00:22.320
to the create lab now you know what the
 

00:00:22.320 --> 00:00:25.490
to the create lab now you know what the
acronym stands for which is focused on

00:00:25.490 --> 00:00:25.500
acronym stands for which is focused on
 

00:00:25.500 --> 00:00:27.170
acronym stands for which is focused on
the development of community-based

00:00:27.170 --> 00:00:27.180
the development of community-based
 

00:00:27.180 --> 00:00:29.689
the development of community-based
social and educational robotics and

00:00:29.689 --> 00:00:29.699
social and educational robotics and
 

00:00:29.699 --> 00:00:31.580
social and educational robotics and
really transforming people's lives

00:00:31.580 --> 00:00:31.590
really transforming people's lives
 

00:00:31.590 --> 00:00:33.860
really transforming people's lives
through community engagement to identify

00:00:33.860 --> 00:00:33.870
through community engagement to identify
 

00:00:33.870 --> 00:00:36.139
through community engagement to identify
the challenges that people face in their

00:00:36.139 --> 00:00:36.149
the challenges that people face in their
 

00:00:36.149 --> 00:00:38.240
the challenges that people face in their
lives and the ways that robotic and AI

00:00:38.240 --> 00:00:38.250
lives and the ways that robotic and AI
 

00:00:38.250 --> 00:00:41.720
lives and the ways that robotic and AI
technologies can really address respond

00:00:41.720 --> 00:00:41.730
technologies can really address respond
 

00:00:41.730 --> 00:00:44.690
technologies can really address respond
and spawned to those challenges and then

00:00:44.690 --> 00:00:44.700
and spawned to those challenges and then
 

00:00:44.700 --> 00:00:46.940
and spawned to those challenges and then
support people's abilities to achieve

00:00:46.940 --> 00:00:46.950
support people's abilities to achieve
 

00:00:46.950 --> 00:00:49.400
support people's abilities to achieve
their goals and over the years the

00:00:49.400 --> 00:00:49.410
their goals and over the years the
 

00:00:49.410 --> 00:00:50.900
their goals and over the years the
create labs programs have engaged over

00:00:50.900 --> 00:00:50.910
create labs programs have engaged over
 

00:00:50.910 --> 00:00:53.750
create labs programs have engaged over
40,000 people globally so the reach is

00:00:53.750 --> 00:00:53.760
40,000 people globally so the reach is
 

00:00:53.760 --> 00:00:55.639
40,000 people globally so the reach is
not simply here in the community not

00:00:55.639 --> 00:00:55.649
not simply here in the community not
 

00:00:55.649 --> 00:00:57.889
not simply here in the community not
simply on campus not even simply in the

00:00:57.889 --> 00:00:57.899
simply on campus not even simply in the
 

00:00:57.899 --> 00:00:59.750
simply on campus not even simply in the
United States but reaches around the

00:00:59.750 --> 00:00:59.760
United States but reaches around the
 

00:00:59.760 --> 00:01:02.930
United States but reaches around the
globe ILA's been a CMU faculty member

00:01:02.930 --> 00:01:02.940
globe ILA's been a CMU faculty member
 

00:01:02.940 --> 00:01:05.030
globe ILA's been a CMU faculty member
since 1997 is the author of four books

00:01:05.030 --> 00:01:05.040
since 1997 is the author of four books
 

00:01:05.040 --> 00:01:07.609
since 1997 is the author of four books
dozens of articles and holds 13 patents

00:01:07.609 --> 00:01:07.619
dozens of articles and holds 13 patents
 

00:01:07.619 --> 00:01:09.920
dozens of articles and holds 13 patents
some of which were part of what led him

00:01:09.920 --> 00:01:09.930
some of which were part of what led him
 

00:01:09.930 --> 00:01:13.580
some of which were part of what led him
to have a brief I believe career as a

00:01:13.580 --> 00:01:13.590
to have a brief I believe career as a
 

00:01:13.590 --> 00:01:15.830
to have a brief I believe career as a
startup entrepreneur he's been named a

00:01:15.830 --> 00:01:15.840
startup entrepreneur he's been named a
 

00:01:15.840 --> 00:01:17.719
startup entrepreneur he's been named a
Kavli fellow by the National Academy of

00:01:17.719 --> 00:01:17.729
Kavli fellow by the National Academy of
 

00:01:17.729 --> 00:01:19.609
Kavli fellow by the National Academy of
Sciences and in fact has been inducted

00:01:19.609 --> 00:01:19.619
Sciences and in fact has been inducted
 

00:01:19.619 --> 00:01:21.289
Sciences and in fact has been inducted
into the I want to make sure I get this

00:01:21.289 --> 00:01:21.299
into the I want to make sure I get this
 

00:01:21.299 --> 00:01:23.330
into the I want to make sure I get this
right the June Harless West Virginia

00:01:23.330 --> 00:01:23.340
right the June Harless West Virginia
 

00:01:23.340 --> 00:01:26.510
right the June Harless West Virginia
Hall of Fame so I think probably a

00:01:26.510 --> 00:01:26.520
Hall of Fame so I think probably a
 

00:01:26.520 --> 00:01:28.600
Hall of Fame so I think probably a
distinction that is unique in this room

00:01:28.600 --> 00:01:28.610
distinction that is unique in this room
 

00:01:28.610 --> 00:01:31.819
distinction that is unique in this room
following ILA's remarks he'll be joined

00:01:31.819 --> 00:01:31.829
following ILA's remarks he'll be joined
 

00:01:31.829 --> 00:01:34.069
following ILA's remarks he'll be joined
for a brief conversation by Tom Simon

00:01:34.069 --> 00:01:34.079
for a brief conversation by Tom Simon
 

00:01:34.079 --> 00:01:36.560
for a brief conversation by Tom Simon
Knight senior writer for Wired who was

00:01:36.560 --> 00:01:36.570
Knight senior writer for Wired who was
 

00:01:36.570 --> 00:01:38.060
Knight senior writer for Wired who was
previously the San Francisco bureau

00:01:38.060 --> 00:01:38.070
previously the San Francisco bureau
 

00:01:38.070 --> 00:01:40.219
previously the San Francisco bureau
chief at MIT Technology Review and has

00:01:40.219 --> 00:01:40.229
chief at MIT Technology Review and has
 

00:01:40.229 --> 00:01:42.679
chief at MIT Technology Review and has
written and edited technology coverage

00:01:42.679 --> 00:01:42.689
written and edited technology coverage
 

00:01:42.689 --> 00:01:45.289
written and edited technology coverage
at the New Scientist magazine and now in

00:01:45.289 --> 00:01:45.299
at the New Scientist magazine and now in
 

00:01:45.299 --> 00:01:47.300
at the New Scientist magazine and now in
his current position at Wired he covers

00:01:47.300 --> 00:01:47.310
his current position at Wired he covers
 

00:01:47.310 --> 00:01:49.100
his current position at Wired he covers
artificial intelligence and its effects

00:01:49.100 --> 00:01:49.110
artificial intelligence and its effects
 

00:01:49.110 --> 00:01:51.920
artificial intelligence and its effects
on the world without further ado Eleanor

00:01:51.920 --> 00:01:51.930
on the world without further ado Eleanor
 

00:01:51.930 --> 00:01:57.060
on the world without further ado Eleanor
Rosch

00:01:57.060 --> 00:01:57.070
 

00:01:57.070 --> 00:01:59.170
well thank you David for the wonderful

00:01:59.170 --> 00:01:59.180
well thank you David for the wonderful
 

00:01:59.180 --> 00:02:02.220
well thank you David for the wonderful
introduction and good morning all

00:02:02.220 --> 00:02:02.230
introduction and good morning all
 

00:02:02.230 --> 00:02:06.160
introduction and good morning all
to loosen my jaw and set the stage some

00:02:06.160 --> 00:02:06.170
to loosen my jaw and set the stage some
 

00:02:06.170 --> 00:02:09.249
to loosen my jaw and set the stage some
true stories first true story I'm

00:02:09.249 --> 00:02:09.259
true stories first true story I'm
 

00:02:09.259 --> 00:02:11.520
true stories first true story I'm
sitting in a room there's ministers of

00:02:11.520 --> 00:02:11.530
sitting in a room there's ministers of
 

00:02:11.530 --> 00:02:14.440
sitting in a room there's ministers of
Transportation and ministers of defense

00:02:14.440 --> 00:02:14.450
Transportation and ministers of defense
 

00:02:14.450 --> 00:02:16.660
Transportation and ministers of defense
ministers of sports from various

00:02:16.660 --> 00:02:16.670
ministers of sports from various
 

00:02:16.670 --> 00:02:18.520
ministers of sports from various
countries in the room and the

00:02:18.520 --> 00:02:18.530
countries in the room and the
 

00:02:18.530 --> 00:02:20.430
countries in the room and the
editor-in-chief of one of the biggest

00:02:20.430 --> 00:02:20.440
editor-in-chief of one of the biggest
 

00:02:20.440 --> 00:02:23.050
editor-in-chief of one of the biggest
journalism newspaper companies in the

00:02:23.050 --> 00:02:23.060
journalism newspaper companies in the
 

00:02:23.060 --> 00:02:25.810
journalism newspaper companies in the
world gets up and says we've been had by

00:02:25.810 --> 00:02:25.820
world gets up and says we've been had by
 

00:02:25.820 --> 00:02:28.210
world gets up and says we've been had by
ourselves when we published the first

00:02:28.210 --> 00:02:28.220
ourselves when we published the first
 

00:02:28.220 --> 00:02:31.540
ourselves when we published the first
story outing fake news I went online to

00:02:31.540 --> 00:02:31.550
story outing fake news I went online to
 

00:02:31.550 --> 00:02:34.150
story outing fake news I went online to
see our fake news story and on our

00:02:34.150 --> 00:02:34.160
see our fake news story and on our
 

00:02:34.160 --> 00:02:36.640
see our fake news story and on our
online version of our website there's

00:02:36.640 --> 00:02:36.650
online version of our website there's
 

00:02:36.650 --> 00:02:37.960
online version of our website there's
our fake news story in the middle and

00:02:37.960 --> 00:02:37.970
our fake news story in the middle and
 

00:02:37.970 --> 00:02:40.600
our fake news story in the middle and
above it and below it there was fake

00:02:40.600 --> 00:02:40.610
above it and below it there was fake
 

00:02:40.610 --> 00:02:44.670
above it and below it there was fake
news because we were selling Adwords and

00:02:44.670 --> 00:02:44.680
news because we were selling Adwords and
 

00:02:44.680 --> 00:02:47.350
news because we were selling Adwords and
the people who bought and won the

00:02:47.350 --> 00:02:47.360
the people who bought and won the
 

00:02:47.360 --> 00:02:48.970
the people who bought and won the
auction happened - the fake news

00:02:48.970 --> 00:02:48.980
auction happened - the fake news
 

00:02:48.980 --> 00:02:52.360
auction happened - the fake news
purveyors immediately and and he said

00:02:52.360 --> 00:02:52.370
purveyors immediately and and he said
 

00:02:52.370 --> 00:02:55.870
purveyors immediately and and he said
you know this is our own fault we don't

00:02:55.870 --> 00:02:55.880
you know this is our own fault we don't
 

00:02:55.880 --> 00:02:58.060
you know this is our own fault we don't
even know how to compensate our own

00:02:58.060 --> 00:02:58.070
even know how to compensate our own
 

00:02:58.070 --> 00:03:00.580
even know how to compensate our own
investigative journalism without being

00:03:00.580 --> 00:03:00.590
investigative journalism without being
 

00:03:00.590 --> 00:03:02.229
investigative journalism without being
part of a community that we're trying to

00:03:02.229 --> 00:03:02.239
part of a community that we're trying to
 

00:03:02.239 --> 00:03:05.830
part of a community that we're trying to
say is a disaster immediately gets up

00:03:05.830 --> 00:03:05.840
say is a disaster immediately gets up
 

00:03:05.840 --> 00:03:08.410
say is a disaster immediately gets up
the CEO of the biggest behavioral

00:03:08.410 --> 00:03:08.420
the CEO of the biggest behavioral
 

00:03:08.420 --> 00:03:10.810
the CEO of the biggest behavioral
analyst company in the world and says I

00:03:10.810 --> 00:03:10.820
analyst company in the world and says I
 

00:03:10.820 --> 00:03:11.920
analyst company in the world and says I
completely agree with that he just said

00:03:11.920 --> 00:03:11.930
completely agree with that he just said
 

00:03:11.930 --> 00:03:15.250
completely agree with that he just said
that was me I did the article on top and

00:03:15.250 --> 00:03:15.260
that was me I did the article on top and
 

00:03:15.260 --> 00:03:16.360
that was me I did the article on top and
I did the article on the bottom and

00:03:16.360 --> 00:03:16.370
I did the article on the bottom and
 

00:03:16.370 --> 00:03:20.199
I did the article on the bottom and
guess what I have a team of machine

00:03:20.199 --> 00:03:20.209
guess what I have a team of machine
 

00:03:20.209 --> 00:03:22.690
guess what I have a team of machine
learning people who are amazing at what

00:03:22.690 --> 00:03:22.700
learning people who are amazing at what
 

00:03:22.700 --> 00:03:24.910
learning people who are amazing at what
they do my computer's do hundreds of

00:03:24.910 --> 00:03:24.920
they do my computer's do hundreds of
 

00:03:24.920 --> 00:03:28.030
they do my computer's do hundreds of
millions of a/b comparisons a day and we

00:03:28.030 --> 00:03:28.040
millions of a/b comparisons a day and we
 

00:03:28.040 --> 00:03:29.979
millions of a/b comparisons a day and we
know this is a direct quote how to

00:03:29.979 --> 00:03:29.989
know this is a direct quote how to
 

00:03:29.989 --> 00:03:32.910
know this is a direct quote how to
maximize dopamine response by people and

00:03:32.910 --> 00:03:32.920
maximize dopamine response by people and
 

00:03:32.920 --> 00:03:35.610
maximize dopamine response by people and
we know how to make a system that

00:03:35.610 --> 00:03:35.620
we know how to make a system that
 

00:03:35.620 --> 00:03:38.620
we know how to make a system that
maximizes this and engages you and

00:03:38.620 --> 00:03:38.630
maximizes this and engages you and
 

00:03:38.630 --> 00:03:40.210
maximizes this and engages you and
causes you to click through and it makes

00:03:40.210 --> 00:03:40.220
causes you to click through and it makes
 

00:03:40.220 --> 00:03:43.750
causes you to click through and it makes
me money and I admit that it's not

00:03:43.750 --> 00:03:43.760
me money and I admit that it's not
 

00:03:43.760 --> 00:03:45.880
me money and I admit that it's not
completely ethical but it really works

00:03:45.880 --> 00:03:45.890
completely ethical but it really works
 

00:03:45.890 --> 00:03:48.160
completely ethical but it really works
well and I challenge any of you in this

00:03:48.160 --> 00:03:48.170
well and I challenge any of you in this
 

00:03:48.170 --> 00:03:49.539
well and I challenge any of you in this
room to come up with a better way for me

00:03:49.539 --> 00:03:49.549
room to come up with a better way for me
 

00:03:49.549 --> 00:03:50.650
room to come up with a better way for me
to make as much money and I'll switch

00:03:50.650 --> 00:03:50.660
to make as much money and I'll switch
 

00:03:50.660 --> 00:03:56.310
to make as much money and I'll switch
right away another story a few years ago

00:03:56.310 --> 00:03:56.320
right away another story a few years ago
 

00:03:56.320 --> 00:04:00.130
right away another story a few years ago
gentleman came back from war and started

00:04:00.130 --> 00:04:00.140
gentleman came back from war and started
 

00:04:00.140 --> 00:04:06.390
gentleman came back from war and started
a a bar Irish themed pub in Atlanta and

00:04:06.390 --> 00:04:06.400
a a bar Irish themed pub in Atlanta and
 

00:04:06.400 --> 00:04:08.590
a a bar Irish themed pub in Atlanta and
it was a transitional neighborhood where

00:04:08.590 --> 00:04:08.600
it was a transitional neighborhood where
 

00:04:08.600 --> 00:04:10.270
it was a transitional neighborhood where
gentrification was happening

00:04:10.270 --> 00:04:10.280
gentrification was happening
 

00:04:10.280 --> 00:04:12.610
gentrification was happening
but there were people homeless folks on

00:04:12.610 --> 00:04:12.620
but there were people homeless folks on
 

00:04:12.620 --> 00:04:14.830
but there were people homeless folks on
the sidewalk and he didn't like this

00:04:14.830 --> 00:04:14.840
the sidewalk and he didn't like this
 

00:04:14.840 --> 00:04:16.660
the sidewalk and he didn't like this
homeless presence on the sidewalk in

00:04:16.660 --> 00:04:16.670
homeless presence on the sidewalk in
 

00:04:16.670 --> 00:04:18.580
homeless presence on the sidewalk in
front of his pub so he built the world's

00:04:18.580 --> 00:04:18.590
front of his pub so he built the world's
 

00:04:18.590 --> 00:04:24.129
front of his pub so he built the world's
first bum bot bu m bo T robot controlled

00:04:24.129 --> 00:04:24.139
first bum bot bu m bo T robot controlled
 

00:04:24.139 --> 00:04:25.840
first bum bot bu m bo T robot controlled
by him that would threaten people on

00:04:25.840 --> 00:04:25.850
by him that would threaten people on
 

00:04:25.850 --> 00:04:27.220
by him that would threaten people on
this on the sidewalk with a

00:04:27.220 --> 00:04:27.230
this on the sidewalk with a
 

00:04:27.230 --> 00:04:29.020
this on the sidewalk with a
high-pressure water cannon and a

00:04:29.020 --> 00:04:29.030
high-pressure water cannon and a
 

00:04:29.030 --> 00:04:31.510
high-pressure water cannon and a
spotlight and a speaker and it made the

00:04:31.510 --> 00:04:31.520
spotlight and a speaker and it made the
 

00:04:31.520 --> 00:04:34.210
spotlight and a speaker and it made the
news stories and the stories in the news

00:04:34.210 --> 00:04:34.220
news stories and the stories in the news
 

00:04:34.220 --> 00:04:36.390
news stories and the stories in the news
which fascinated me were about the

00:04:36.390 --> 00:04:36.400
which fascinated me were about the
 

00:04:36.400 --> 00:04:39.370
which fascinated me were about the
empowerment he had as a maker inventing

00:04:39.370 --> 00:04:39.380
empowerment he had as a maker inventing
 

00:04:39.380 --> 00:04:42.640
empowerment he had as a maker inventing
a whole new innovative product now fast

00:04:42.640 --> 00:04:42.650
a whole new innovative product now fast
 

00:04:42.650 --> 00:04:44.909
a whole new innovative product now fast
forward about seven years last year

00:04:44.909 --> 00:04:44.919
forward about seven years last year
 

00:04:44.919 --> 00:04:47.380
forward about seven years last year
nightscope started having this wonderful

00:04:47.380 --> 00:04:47.390
nightscope started having this wonderful
 

00:04:47.390 --> 00:04:49.659
nightscope started having this wonderful
robot night scope which is a security

00:04:49.659 --> 00:04:49.669
robot night scope which is a security
 

00:04:49.669 --> 00:04:52.120
robot night scope which is a security
guard that you can rent and have roam

00:04:52.120 --> 00:04:52.130
guard that you can rent and have roam
 

00:04:52.130 --> 00:04:55.080
guard that you can rent and have roam
around your establishment night scope

00:04:55.080 --> 00:04:55.090
around your establishment night scope
 

00:04:55.090 --> 00:04:57.880
around your establishment night scope
was purchased by an establishment in San

00:04:57.880 --> 00:04:57.890
was purchased by an establishment in San
 

00:04:57.890 --> 00:05:00.670
was purchased by an establishment in San
Francisco because the sidewalk in front

00:05:00.670 --> 00:05:00.680
Francisco because the sidewalk in front
 

00:05:00.680 --> 00:05:01.930
Francisco because the sidewalk in front
of the establishment has so many

00:05:01.930 --> 00:05:01.940
of the establishment has so many
 

00:05:01.940 --> 00:05:04.060
of the establishment has so many
homeless people on it and so now we have

00:05:04.060 --> 00:05:04.070
homeless people on it and so now we have
 

00:05:04.070 --> 00:05:05.500
homeless people on it and so now we have
a commercial robot used by an

00:05:05.500 --> 00:05:05.510
a commercial robot used by an
 

00:05:05.510 --> 00:05:07.810
a commercial robot used by an
establishment to actually keep people

00:05:07.810 --> 00:05:07.820
establishment to actually keep people
 

00:05:07.820 --> 00:05:10.840
establishment to actually keep people
away from their sidewalk this is where

00:05:10.840 --> 00:05:10.850
away from their sidewalk this is where
 

00:05:10.850 --> 00:05:13.900
away from their sidewalk this is where
the story can't be made up it's too good

00:05:13.900 --> 00:05:13.910
the story can't be made up it's too good
 

00:05:13.910 --> 00:05:16.930
the story can't be made up it's too good
to be fake the establishment that bought

00:05:16.930 --> 00:05:16.940
to be fake the establishment that bought
 

00:05:16.940 --> 00:05:19.270
to be fake the establishment that bought
nightscope and used it to make sure

00:05:19.270 --> 00:05:19.280
nightscope and used it to make sure
 

00:05:19.280 --> 00:05:21.130
nightscope and used it to make sure
homeless didn't congregate on the

00:05:21.130 --> 00:05:21.140
homeless didn't congregate on the
 

00:05:21.140 --> 00:05:22.510
homeless didn't congregate on the
sidewalk in front of their establishment

00:05:22.510 --> 00:05:22.520
sidewalk in front of their establishment
 

00:05:22.520 --> 00:05:24.790
sidewalk in front of their establishment
was the Society for the Prevention of

00:05:24.790 --> 00:05:24.800
was the Society for the Prevention of
 

00:05:24.800 --> 00:05:28.120
was the Society for the Prevention of
Cruelty to Animals no kidding

00:05:28.120 --> 00:05:28.130
Cruelty to Animals no kidding
 

00:05:28.130 --> 00:05:31.860
Cruelty to Animals no kidding
go look this up so the SPCA used a robot

00:05:31.860 --> 00:05:31.870
go look this up so the SPCA used a robot
 

00:05:31.870 --> 00:05:34.270
go look this up so the SPCA used a robot
to intimidate people on the sidewalk

00:05:34.270 --> 00:05:34.280
to intimidate people on the sidewalk
 

00:05:34.280 --> 00:05:37.870
to intimidate people on the sidewalk
until by the way San Francisco City

00:05:37.870 --> 00:05:37.880
until by the way San Francisco City
 

00:05:37.880 --> 00:05:43.990
until by the way San Francisco City
Council made that illegal another one we

00:05:43.990 --> 00:05:44.000
Council made that illegal another one we
 

00:05:44.000 --> 00:05:46.029
Council made that illegal another one we
talked a great deal about war and robots

00:05:46.029 --> 00:05:46.039
talked a great deal about war and robots
 

00:05:46.039 --> 00:05:48.700
talked a great deal about war and robots
and whether robots should in a situation

00:05:48.700 --> 00:05:48.710
and whether robots should in a situation
 

00:05:48.710 --> 00:05:50.890
and whether robots should in a situation
where there's a war going on make

00:05:50.890 --> 00:05:50.900
where there's a war going on make
 

00:05:50.900 --> 00:05:52.620
where there's a war going on make
decisions about taking human life and

00:05:52.620 --> 00:05:52.630
decisions about taking human life and
 

00:05:52.630 --> 00:05:55.000
decisions about taking human life and
it's an excellent and important argument

00:05:55.000 --> 00:05:55.010
it's an excellent and important argument
 

00:05:55.010 --> 00:05:55.960
it's an excellent and important argument
to have and there's some outstanding

00:05:55.960 --> 00:05:55.970
to have and there's some outstanding
 

00:05:55.970 --> 00:05:59.610
to have and there's some outstanding
books on the subject

00:05:59.610 --> 00:05:59.620
 

00:05:59.620 --> 00:06:03.130
meanwhile in South Korea one of the

00:06:03.130 --> 00:06:03.140
meanwhile in South Korea one of the
 

00:06:03.140 --> 00:06:04.480
meanwhile in South Korea one of the
biggest electronics manufacturers in the

00:06:04.480 --> 00:06:04.490
biggest electronics manufacturers in the
 

00:06:04.490 --> 00:06:06.880
biggest electronics manufacturers in the
world made a machine gun activated

00:06:06.880 --> 00:06:06.890
world made a machine gun activated
 

00:06:06.890 --> 00:06:08.320
world made a machine gun activated
turret that's completely autonomous

00:06:08.320 --> 00:06:08.330
turret that's completely autonomous
 

00:06:08.330 --> 00:06:10.450
turret that's completely autonomous
users near-infrared to actually identify

00:06:10.450 --> 00:06:10.460
users near-infrared to actually identify
 

00:06:10.460 --> 00:06:12.790
users near-infrared to actually identify
people and shoot at them and it's used

00:06:12.790 --> 00:06:12.800
people and shoot at them and it's used
 

00:06:12.800 --> 00:06:15.100
people and shoot at them and it's used
today to guard some actual retail

00:06:15.100 --> 00:06:15.110
today to guard some actual retail
 

00:06:15.110 --> 00:06:16.690
today to guard some actual retail
establishments and it's already

00:06:16.690 --> 00:06:16.700
establishments and it's already
 

00:06:16.700 --> 00:06:19.810
establishments and it's already
installed today on the DMZ and it's not

00:06:19.810 --> 00:06:19.820
installed today on the DMZ and it's not
 

00:06:19.820 --> 00:06:21.250
installed today on the DMZ and it's not
one odd actor there are multiple

00:06:21.250 --> 00:06:21.260
one odd actor there are multiple
 

00:06:21.260 --> 00:06:22.719
one odd actor there are multiple
companies now doing this in South Korea

00:06:22.719 --> 00:06:22.729
companies now doing this in South Korea
 

00:06:22.729 --> 00:06:25.410
companies now doing this in South Korea
as well as in the Middle East

00:06:25.410 --> 00:06:25.420
as well as in the Middle East
 

00:06:25.420 --> 00:06:27.610
as well as in the Middle East
now go back a few years ago let's talk

00:06:27.610 --> 00:06:27.620
now go back a few years ago let's talk
 

00:06:27.620 --> 00:06:30.760
now go back a few years ago let's talk
about drones Los Angeles is testing

00:06:30.760 --> 00:06:30.770
about drones Los Angeles is testing
 

00:06:30.770 --> 00:06:32.350
about drones Los Angeles is testing
drones for one of the first times a few

00:06:32.350 --> 00:06:32.360
drones for one of the first times a few
 

00:06:32.360 --> 00:06:34.590
drones for one of the first times a few
years ago they had to join up in the sky

00:06:34.590 --> 00:06:34.600
years ago they had to join up in the sky
 

00:06:34.600 --> 00:06:36.700
years ago they had to join up in the sky
cameras down and the police were having

00:06:36.700 --> 00:06:36.710
cameras down and the police were having
 

00:06:36.710 --> 00:06:39.400
cameras down and the police were having
a blast flying this thing around just

00:06:39.400 --> 00:06:39.410
a blast flying this thing around just
 

00:06:39.410 --> 00:06:41.830
a blast flying this thing around just
like your kids except when they're

00:06:41.830 --> 00:06:41.840
like your kids except when they're
 

00:06:41.840 --> 00:06:43.150
like your kids except when they're
flying this thing around just playing

00:06:43.150 --> 00:06:43.160
flying this thing around just playing
 

00:06:43.160 --> 00:06:46.030
flying this thing around just playing
with it they noticed pot they noticed

00:06:46.030 --> 00:06:46.040
with it they noticed pot they noticed
 

00:06:46.040 --> 00:06:47.470
with it they noticed pot they noticed
the whole marijuana plantation behind

00:06:47.470 --> 00:06:47.480
the whole marijuana plantation behind
 

00:06:47.480 --> 00:06:49.120
the whole marijuana plantation behind
somebody's walls they went oh look at

00:06:49.120 --> 00:06:49.130
somebody's walls they went oh look at
 

00:06:49.130 --> 00:06:49.330
somebody's walls they went oh look at
that

00:06:49.330 --> 00:06:49.340
that
 

00:06:49.340 --> 00:06:53.050
that
what so they go in and make arrests and

00:06:53.050 --> 00:06:53.060
what so they go in and make arrests and
 

00:06:53.060 --> 00:06:54.550
what so they go in and make arrests and
it goes all the way up to the state

00:06:54.550 --> 00:06:54.560
it goes all the way up to the state
 

00:06:54.560 --> 00:06:56.440
it goes all the way up to the state
Supreme Court because the question is

00:06:56.440 --> 00:06:56.450
Supreme Court because the question is
 

00:06:56.450 --> 00:06:59.020
Supreme Court because the question is
they didn't have any right to search

00:06:59.020 --> 00:06:59.030
they didn't have any right to search
 

00:06:59.030 --> 00:07:01.600
they didn't have any right to search
they didn't have a warrant well what the

00:07:01.600 --> 00:07:01.610
they didn't have a warrant well what the
 

00:07:01.610 --> 00:07:03.340
they didn't have a warrant well what the
court said in the end was you know what

00:07:03.340 --> 00:07:03.350
court said in the end was you know what
 

00:07:03.350 --> 00:07:06.430
court said in the end was you know what
now that there are drones our assumption

00:07:06.430 --> 00:07:06.440
now that there are drones our assumption
 

00:07:06.440 --> 00:07:08.230
now that there are drones our assumption
to the right of privacy by having a high

00:07:08.230 --> 00:07:08.240
to the right of privacy by having a high
 

00:07:08.240 --> 00:07:10.720
to the right of privacy by having a high
wall around our house actually no longer

00:07:10.720 --> 00:07:10.730
wall around our house actually no longer
 

00:07:10.730 --> 00:07:13.060
wall around our house actually no longer
applies because drones are commonly

00:07:13.060 --> 00:07:13.070
applies because drones are commonly
 

00:07:13.070 --> 00:07:15.610
applies because drones are commonly
available and they go above things so

00:07:15.610 --> 00:07:15.620
available and they go above things so
 

00:07:15.620 --> 00:07:16.840
available and they go above things so
you don't get your right to privacy

00:07:16.840 --> 00:07:16.850
you don't get your right to privacy
 

00:07:16.850 --> 00:07:18.460
you don't get your right to privacy
assumed unless you happen to have a roof

00:07:18.460 --> 00:07:18.470
assumed unless you happen to have a roof
 

00:07:18.470 --> 00:07:22.810
assumed unless you happen to have a roof
over your marijuana plantation so it's

00:07:22.810 --> 00:07:22.820
over your marijuana plantation so it's
 

00:07:22.820 --> 00:07:24.870
over your marijuana plantation so it's
kind of fascinating that the legal

00:07:24.870 --> 00:07:24.880
kind of fascinating that the legal
 

00:07:24.880 --> 00:07:27.790
kind of fascinating that the legal
ramification was to change the rights we

00:07:27.790 --> 00:07:27.800
ramification was to change the rights we
 

00:07:27.800 --> 00:07:30.100
ramification was to change the rights we
have around privacy because of the piece

00:07:30.100 --> 00:07:30.110
have around privacy because of the piece
 

00:07:30.110 --> 00:07:31.240
have around privacy because of the piece
of technology that was boundary

00:07:31.240 --> 00:07:31.250
of technology that was boundary
 

00:07:31.250 --> 00:07:35.020
of technology that was boundary
technology and fast forward to a couple

00:07:35.020 --> 00:07:35.030
technology and fast forward to a couple
 

00:07:35.030 --> 00:07:36.340
technology and fast forward to a couple
months ago I was in a meeting with the

00:07:36.340 --> 00:07:36.350
months ago I was in a meeting with the
 

00:07:36.350 --> 00:07:37.540
months ago I was in a meeting with the
Minister of Transportation and where the

00:07:37.540 --> 00:07:37.550
Minister of Transportation and where the
 

00:07:37.550 --> 00:07:39.280
Minister of Transportation and where the
biggest countries in the world and we

00:07:39.280 --> 00:07:39.290
biggest countries in the world and we
 

00:07:39.290 --> 00:07:40.210
biggest countries in the world and we
were taking questions from the audience

00:07:40.210 --> 00:07:40.220
were taking questions from the audience
 

00:07:40.220 --> 00:07:42.160
were taking questions from the audience
about drones and people were saying

00:07:42.160 --> 00:07:42.170
about drones and people were saying
 

00:07:42.170 --> 00:07:43.600
about drones and people were saying
questions like well what's the

00:07:43.600 --> 00:07:43.610
questions like well what's the
 

00:07:43.610 --> 00:07:44.710
questions like well what's the
regulatory infrastructure you're gonna

00:07:44.710 --> 00:07:44.720
regulatory infrastructure you're gonna
 

00:07:44.720 --> 00:07:46.690
regulatory infrastructure you're gonna
put in place to allow drones to fly and

00:07:46.690 --> 00:07:46.700
put in place to allow drones to fly and
 

00:07:46.700 --> 00:07:49.120
put in place to allow drones to fly and
the answer from the minister was we have

00:07:49.120 --> 00:07:49.130
the answer from the minister was we have
 

00:07:49.130 --> 00:07:50.010
the answer from the minister was we have
no idea

00:07:50.010 --> 00:07:50.020
no idea
 

00:07:50.020 --> 00:07:51.910
no idea
somebody else has what about tort and

00:07:51.910 --> 00:07:51.920
somebody else has what about tort and
 

00:07:51.920 --> 00:07:53.260
somebody else has what about tort and
liability how we're gonna deal with

00:07:53.260 --> 00:07:53.270
liability how we're gonna deal with
 

00:07:53.270 --> 00:07:56.740
liability how we're gonna deal with
insurance around drones answer we have

00:07:56.740 --> 00:07:56.750
insurance around drones answer we have
 

00:07:56.750 --> 00:07:59.410
insurance around drones answer we have
no clue nearly every question the

00:07:59.410 --> 00:07:59.420
no clue nearly every question the
 

00:07:59.420 --> 00:08:00.940
no clue nearly every question the
audience asked the answer that was

00:08:00.940 --> 00:08:00.950
audience asked the answer that was
 

00:08:00.950 --> 00:08:02.110
audience asked the answer that was
received by the audience from the

00:08:02.110 --> 00:08:02.120
received by the audience from the
 

00:08:02.120 --> 00:08:03.430
received by the audience from the
Minister of Transportation for that

00:08:03.430 --> 00:08:03.440
Minister of Transportation for that
 

00:08:03.440 --> 00:08:07.570
Minister of Transportation for that
country was we have no idea okay one

00:08:07.570 --> 00:08:07.580
country was we have no idea okay one
 

00:08:07.580 --> 00:08:09.280
country was we have no idea okay one
final true story for you let's go to

00:08:09.280 --> 00:08:09.290
final true story for you let's go to
 

00:08:09.290 --> 00:08:10.260
final true story for you let's go to
cars

00:08:10.260 --> 00:08:10.270
cars
 

00:08:10.270 --> 00:08:13.810
cars
remember the cute Google car it had no

00:08:13.810 --> 00:08:13.820
remember the cute Google car it had no
 

00:08:13.820 --> 00:08:15.790
remember the cute Google car it had no
steering wheel you remember that it was

00:08:15.790 --> 00:08:15.800
steering wheel you remember that it was
 

00:08:15.800 --> 00:08:18.970
steering wheel you remember that it was
steering free why I think we need to

00:08:18.970 --> 00:08:18.980
steering free why I think we need to
 

00:08:18.980 --> 00:08:21.040
steering free why I think we need to
revisit that question because it is very

00:08:21.040 --> 00:08:21.050
revisit that question because it is very
 

00:08:21.050 --> 00:08:22.660
revisit that question because it is very
relevant to what you've been hearing

00:08:22.660 --> 00:08:22.670
relevant to what you've been hearing
 

00:08:22.670 --> 00:08:24.610
relevant to what you've been hearing
about in the news today so the reason

00:08:24.610 --> 00:08:24.620
about in the news today so the reason
 

00:08:24.620 --> 00:08:25.720
about in the news today so the reason
they had no steering wheel is kind of

00:08:25.720 --> 00:08:25.730
they had no steering wheel is kind of
 

00:08:25.730 --> 00:08:28.020
they had no steering wheel is kind of
interesting they took a bunch of pre I

00:08:28.020 --> 00:08:28.030
interesting they took a bunch of pre I
 

00:08:28.030 --> 00:08:30.840
interesting they took a bunch of pre I
Toyota Priuses and put the self-driving

00:08:30.840 --> 00:08:30.850
Toyota Priuses and put the self-driving
 

00:08:30.850 --> 00:08:33.820
Toyota Priuses and put the self-driving
software in it in early days we have to

00:08:33.820 --> 00:08:33.830
software in it in early days we have to
 

00:08:33.830 --> 00:08:35.260
software in it in early days we have to
give come up with some floral form for

00:08:35.260 --> 00:08:35.270
give come up with some floral form for
 

00:08:35.270 --> 00:08:37.450
give come up with some floral form for
it right and

00:08:37.450 --> 00:08:37.460
it right and
 

00:08:37.460 --> 00:08:39.130
it right and
then they trained Google employees to

00:08:39.130 --> 00:08:39.140
then they trained Google employees to
 

00:08:39.140 --> 00:08:40.900
then they trained Google employees to
use these cars and they put cameras in

00:08:40.900 --> 00:08:40.910
use these cars and they put cameras in
 

00:08:40.910 --> 00:08:42.160
use these cars and they put cameras in
them to watch the Google employees and

00:08:42.160 --> 00:08:42.170
them to watch the Google employees and
 

00:08:42.170 --> 00:08:45.640
them to watch the Google employees and
see what they do and the engineers then

00:08:45.640 --> 00:08:45.650
see what they do and the engineers then
 

00:08:45.650 --> 00:08:47.740
see what they do and the engineers then
reviewed the video footage of this and

00:08:47.740 --> 00:08:47.750
reviewed the video footage of this and
 

00:08:47.750 --> 00:08:50.320
reviewed the video footage of this and
they were gobsmacked there would be an

00:08:50.320 --> 00:08:50.330
they were gobsmacked there would be an
 

00:08:50.330 --> 00:08:52.120
they were gobsmacked there would be an
engineer who on their first day on the

00:08:52.120 --> 00:08:52.130
engineer who on their first day on the
 

00:08:52.130 --> 00:08:53.620
engineer who on their first day on the
highway from San Francisco down to

00:08:53.620 --> 00:08:53.630
highway from San Francisco down to
 

00:08:53.630 --> 00:08:55.900
highway from San Francisco down to
Mountain View or in the Google

00:08:55.900 --> 00:08:55.910
Mountain View or in the Google
 

00:08:55.910 --> 00:08:58.750
Mountain View or in the Google
self-driving car cameras there and their

00:08:58.750 --> 00:08:58.760
self-driving car cameras there and their
 

00:08:58.760 --> 00:09:00.910
self-driving car cameras there and their
babies in the backseat in a little car

00:09:00.910 --> 00:09:00.920
babies in the backseat in a little car
 

00:09:00.920 --> 00:09:02.110
babies in the backseat in a little car
seat and you know what they're doing

00:09:02.110 --> 00:09:02.120
seat and you know what they're doing
 

00:09:02.120 --> 00:09:04.930
seat and you know what they're doing
they're like this the entire time it's

00:09:04.930 --> 00:09:04.940
they're like this the entire time it's
 

00:09:04.940 --> 00:09:07.320
they're like this the entire time it's
so cute the whole time on the highway

00:09:07.320 --> 00:09:07.330
so cute the whole time on the highway
 

00:09:07.330 --> 00:09:10.660
so cute the whole time on the highway
there was one guy memorably who spilled

00:09:10.660 --> 00:09:10.670
there was one guy memorably who spilled
 

00:09:10.670 --> 00:09:14.680
there was one guy memorably who spilled
his coffee so for 10 minutes he was like

00:09:14.680 --> 00:09:14.690
his coffee so for 10 minutes he was like
 

00:09:14.690 --> 00:09:17.890
his coffee so for 10 minutes he was like
this on the floor trying to clean the

00:09:17.890 --> 00:09:17.900
this on the floor trying to clean the
 

00:09:17.900 --> 00:09:19.540
this on the floor trying to clean the
floor while the cars on the highway

00:09:19.540 --> 00:09:19.550
floor while the cars on the highway
 

00:09:19.550 --> 00:09:21.970
floor while the cars on the highway
barreling down the road so what did

00:09:21.970 --> 00:09:21.980
barreling down the road so what did
 

00:09:21.980 --> 00:09:23.740
barreling down the road so what did
Google do they had a meeting and they

00:09:23.740 --> 00:09:23.750
Google do they had a meeting and they
 

00:09:23.750 --> 00:09:26.560
Google do they had a meeting and they
panicked they said holy buckets people

00:09:26.560 --> 00:09:26.570
panicked they said holy buckets people
 

00:09:26.570 --> 00:09:28.450
panicked they said holy buckets people
who we trained who are Google engineers

00:09:28.450 --> 00:09:28.460
who we trained who are Google engineers
 

00:09:28.460 --> 00:09:30.490
who we trained who are Google engineers
carefully selected for their raw

00:09:30.490 --> 00:09:30.500
carefully selected for their raw
 

00:09:30.500 --> 00:09:33.160
carefully selected for their raw
intelligence of superiority are doing

00:09:33.160 --> 00:09:33.170
intelligence of superiority are doing
 

00:09:33.170 --> 00:09:35.400
intelligence of superiority are doing
what their completely trusting the car

00:09:35.400 --> 00:09:35.410
what their completely trusting the car
 

00:09:35.410 --> 00:09:38.200
what their completely trusting the car
well then the answer is obvious we had

00:09:38.200 --> 00:09:38.210
well then the answer is obvious we had
 

00:09:38.210 --> 00:09:39.220
well then the answer is obvious we had
to get rid of the steering wheel we

00:09:39.220 --> 00:09:39.230
to get rid of the steering wheel we
 

00:09:39.230 --> 00:09:42.430
to get rid of the steering wheel we
can't trust people at all that's why

00:09:42.430 --> 00:09:42.440
can't trust people at all that's why
 

00:09:42.440 --> 00:09:43.690
can't trust people at all that's why
there was no steering wheel in the

00:09:43.690 --> 00:09:43.700
there was no steering wheel in the
 

00:09:43.700 --> 00:09:46.810
there was no steering wheel in the
little cute Google car now fast forward

00:09:46.810 --> 00:09:46.820
little cute Google car now fast forward
 

00:09:46.820 --> 00:09:48.160
little cute Google car now fast forward
to the accidents you've heard about it

00:09:48.160 --> 00:09:48.170
to the accidents you've heard about it
 

00:09:48.170 --> 00:09:50.730
to the accidents you've heard about it
over the last few years dude in Tesla

00:09:50.730 --> 00:09:50.740
over the last few years dude in Tesla
 

00:09:50.740 --> 00:09:53.920
over the last few years dude in Tesla
watching Harry Potter am I getting this

00:09:53.920 --> 00:09:53.930
watching Harry Potter am I getting this
 

00:09:53.930 --> 00:09:55.900
watching Harry Potter am I getting this
right watching a Harry Potter movie or

00:09:55.900 --> 00:09:55.910
right watching a Harry Potter movie or
 

00:09:55.910 --> 00:09:57.730
right watching a Harry Potter movie or
listening to a Harry Potter audio drive

00:09:57.730 --> 00:09:57.740
listening to a Harry Potter audio drive
 

00:09:57.740 --> 00:09:59.740
listening to a Harry Potter audio drive
running into the side of a truck that if

00:09:59.740 --> 00:09:59.750
running into the side of a truck that if
 

00:09:59.750 --> 00:10:01.410
running into the side of a truck that if
he was looking up he would have seen

00:10:01.410 --> 00:10:01.420
he was looking up he would have seen
 

00:10:01.420 --> 00:10:04.920
he was looking up he would have seen
person in car running into a bicycle

00:10:04.920 --> 00:10:04.930
person in car running into a bicycle
 

00:10:04.930 --> 00:10:07.240
person in car running into a bicycle
where the safety driver is clearly not

00:10:07.240 --> 00:10:07.250
where the safety driver is clearly not
 

00:10:07.250 --> 00:10:08.350
where the safety driver is clearly not
paying attention for the couple of

00:10:08.350 --> 00:10:08.360
paying attention for the couple of
 

00:10:08.360 --> 00:10:11.410
paying attention for the couple of
seconds before the crash in a funny way

00:10:11.410 --> 00:10:11.420
seconds before the crash in a funny way
 

00:10:11.420 --> 00:10:13.510
seconds before the crash in a funny way
Google was right there attempted

00:10:13.510 --> 00:10:13.520
Google was right there attempted
 

00:10:13.520 --> 00:10:15.370
Google was right there attempted
solution was removing the steering wheel

00:10:15.370 --> 00:10:15.380
solution was removing the steering wheel
 

00:10:15.380 --> 00:10:19.120
solution was removing the steering wheel
a very extremely point of view the back

00:10:19.120 --> 00:10:19.130
a very extremely point of view the back
 

00:10:19.130 --> 00:10:21.400
a very extremely point of view the back
step was let's not bother with that

00:10:21.400 --> 00:10:21.410
step was let's not bother with that
 

00:10:21.410 --> 00:10:22.660
step was let's not bother with that
actual let's just leave it there and

00:10:22.660 --> 00:10:22.670
actual let's just leave it there and
 

00:10:22.670 --> 00:10:24.580
actual let's just leave it there and
make sure people know as Eric showed in

00:10:24.580 --> 00:10:24.590
make sure people know as Eric showed in
 

00:10:24.590 --> 00:10:26.410
make sure people know as Eric showed in
his video when people should just take

00:10:26.410 --> 00:10:26.420
his video when people should just take
 

00:10:26.420 --> 00:10:28.510
his video when people should just take
over like that as if people have the

00:10:28.510 --> 00:10:28.520
over like that as if people have the
 

00:10:28.520 --> 00:10:31.840
over like that as if people have the
sudden attention to jump into a

00:10:31.840 --> 00:10:31.850
sudden attention to jump into a
 

00:10:31.850 --> 00:10:34.530
sudden attention to jump into a
high-stress situation and react quickly

00:10:34.530 --> 00:10:34.540
high-stress situation and react quickly
 

00:10:34.540 --> 00:10:36.790
high-stress situation and react quickly
which by the way is the opposite of how

00:10:36.790 --> 00:10:36.800
which by the way is the opposite of how
 

00:10:36.800 --> 00:10:40.750
which by the way is the opposite of how
pilots work with auto pilots so what

00:10:40.750 --> 00:10:40.760
pilots work with auto pilots so what
 

00:10:40.760 --> 00:10:43.900
pilots work with auto pilots so what
wasn't in the news in that case is how

00:10:43.900 --> 00:10:43.910
wasn't in the news in that case is how
 

00:10:43.910 --> 00:10:46.000
wasn't in the news in that case is how
hard it is for all of these cars to see

00:10:46.000 --> 00:10:46.010
hard it is for all of these cars to see
 

00:10:46.010 --> 00:10:49.000
hard it is for all of these cars to see
bicycles but a human on a bicycle and

00:10:49.000 --> 00:10:49.010
bicycles but a human on a bicycle and
 

00:10:49.010 --> 00:10:51.040
bicycles but a human on a bicycle and
our nice thick legs make it obvious that

00:10:51.040 --> 00:10:51.050
our nice thick legs make it obvious that
 

00:10:51.050 --> 00:10:53.410
our nice thick legs make it obvious that
we are there but bicycles are a bunch of

00:10:53.410 --> 00:10:53.420
we are there but bicycles are a bunch of
 

00:10:53.420 --> 00:10:55.120
we are there but bicycles are a bunch of
little thin frames and the lighter goes

00:10:55.120 --> 00:10:55.130
little thin frames and the lighter goes
 

00:10:55.130 --> 00:10:57.160
little thin frames and the lighter goes
right through them and by the way all

00:10:57.160 --> 00:10:57.170
right through them and by the way all
 

00:10:57.170 --> 00:10:58.900
right through them and by the way all
those sensors the robots have are noisy

00:10:58.900 --> 00:10:58.910
those sensors the robots have are noisy
 

00:10:58.910 --> 00:11:00.699
those sensors the robots have are noisy
so when you have little frames

00:11:00.699 --> 00:11:00.709
so when you have little frames
 

00:11:00.709 --> 00:11:02.230
so when you have little frames
reflecting a little bit of light that's

00:11:02.230 --> 00:11:02.240
reflecting a little bit of light that's
 

00:11:02.240 --> 00:11:05.320
reflecting a little bit of light that's
noise if we were to actually see the

00:11:05.320 --> 00:11:05.330
noise if we were to actually see the
 

00:11:05.330 --> 00:11:07.300
noise if we were to actually see the
bicycles we'd be on a part of the curve

00:11:07.300 --> 00:11:07.310
bicycles we'd be on a part of the curve
 

00:11:07.310 --> 00:11:09.670
bicycles we'd be on a part of the curve
that Eric showed where we'd have a huge

00:11:09.670 --> 00:11:09.680
that Eric showed where we'd have a huge
 

00:11:09.680 --> 00:11:11.560
that Eric showed where we'd have a huge
number of false positives so we avoid

00:11:11.560 --> 00:11:11.570
number of false positives so we avoid
 

00:11:11.570 --> 00:11:13.870
number of false positives so we avoid
that by hoping to see their legs but

00:11:13.870 --> 00:11:13.880
that by hoping to see their legs but
 

00:11:13.880 --> 00:11:16.750
that by hoping to see their legs but
that means person walking with a bicycle

00:11:16.750 --> 00:11:16.760
that means person walking with a bicycle
 

00:11:16.760 --> 00:11:19.030
that means person walking with a bicycle
is walking with an invisible stick and

00:11:19.030 --> 00:11:19.040
is walking with an invisible stick and
 

00:11:19.040 --> 00:11:22.090
is walking with an invisible stick and
that's a problem so these are all true

00:11:22.090 --> 00:11:22.100
that's a problem so these are all true
 

00:11:22.100 --> 00:11:24.790
that's a problem so these are all true
examples and I want us to put on our

00:11:24.790 --> 00:11:24.800
examples and I want us to put on our
 

00:11:24.800 --> 00:11:27.340
examples and I want us to put on our
physicians hats and be a physician for a

00:11:27.340 --> 00:11:27.350
physicians hats and be a physician for a
 

00:11:27.350 --> 00:11:29.170
physicians hats and be a physician for a
second and say that these are symptoms

00:11:29.170 --> 00:11:29.180
second and say that these are symptoms
 

00:11:29.180 --> 00:11:31.210
second and say that these are symptoms
and the question I want to ask is what

00:11:31.210 --> 00:11:31.220
and the question I want to ask is what
 

00:11:31.220 --> 00:11:33.610
and the question I want to ask is what
are these the symptoms of and I have a

00:11:33.610 --> 00:11:33.620
are these the symptoms of and I have a
 

00:11:33.620 --> 00:11:35.620
are these the symptoms of and I have a
kind of hypothetical proposition for you

00:11:35.620 --> 00:11:35.630
kind of hypothetical proposition for you
 

00:11:35.630 --> 00:11:37.930
kind of hypothetical proposition for you
about what these are because I believe

00:11:37.930 --> 00:11:37.940
about what these are because I believe
 

00:11:37.940 --> 00:11:39.940
about what these are because I believe
these are all symptoms of one thing and

00:11:39.940 --> 00:11:39.950
these are all symptoms of one thing and
 

00:11:39.950 --> 00:11:42.130
these are all symptoms of one thing and
they're one odd thing that I don't think

00:11:42.130 --> 00:11:42.140
they're one odd thing that I don't think
 

00:11:42.140 --> 00:11:44.009
they're one odd thing that I don't think
we've spent enough time talking about I

00:11:44.009 --> 00:11:44.019
we've spent enough time talking about I
 

00:11:44.019 --> 00:11:46.829
we've spent enough time talking about I
believe these are symptoms of alienation

00:11:46.829 --> 00:11:46.839
believe these are symptoms of alienation
 

00:11:46.839 --> 00:11:49.300
believe these are symptoms of alienation
we're creating a world in which we are

00:11:49.300 --> 00:11:49.310
we're creating a world in which we are
 

00:11:49.310 --> 00:11:51.850
we're creating a world in which we are
alienating ourselves from the reality

00:11:51.850 --> 00:11:51.860
alienating ourselves from the reality
 

00:11:51.860 --> 00:11:54.069
alienating ourselves from the reality
we're constructing and there's three

00:11:54.069 --> 00:11:54.079
we're constructing and there's three
 

00:11:54.079 --> 00:11:55.720
we're constructing and there's three
ways in which I believe we're doing this

00:11:55.720 --> 00:11:55.730
ways in which I believe we're doing this
 

00:11:55.730 --> 00:11:57.850
ways in which I believe we're doing this
alienation I want to talk about that now

00:11:57.850 --> 00:11:57.860
alienation I want to talk about that now
 

00:11:57.860 --> 00:11:59.620
alienation I want to talk about that now
the first one relates to robotics itself

00:11:59.620 --> 00:11:59.630
the first one relates to robotics itself
 

00:11:59.630 --> 00:12:02.350
the first one relates to robotics itself
AI and robotics fundamentally was born

00:12:02.350 --> 00:12:02.360
AI and robotics fundamentally was born
 

00:12:02.360 --> 00:12:03.850
AI and robotics fundamentally was born
out of the desire to do

00:12:03.850 --> 00:12:03.860
out of the desire to do
 

00:12:03.860 --> 00:12:07.030
out of the desire to do
mimesis to mimic humanity it was all

00:12:07.030 --> 00:12:07.040
mimesis to mimic humanity it was all
 

00:12:07.040 --> 00:12:08.290
mimesis to mimic humanity it was all
about this question of what makes us

00:12:08.290 --> 00:12:08.300
about this question of what makes us
 

00:12:08.300 --> 00:12:10.480
about this question of what makes us
tick and how do we cognitively create

00:12:10.480 --> 00:12:10.490
tick and how do we cognitively create
 

00:12:10.490 --> 00:12:13.329
tick and how do we cognitively create
systems that tick the way we do how do

00:12:13.329 --> 00:12:13.339
systems that tick the way we do how do
 

00:12:13.339 --> 00:12:16.269
systems that tick the way we do how do
we replicate the human miracle in

00:12:16.269 --> 00:12:16.279
we replicate the human miracle in
 

00:12:16.279 --> 00:12:20.650
we replicate the human miracle in
machine form and that's mimesis it's a

00:12:20.650 --> 00:12:20.660
machine form and that's mimesis it's a
 

00:12:20.660 --> 00:12:22.900
machine form and that's mimesis it's a
one-to-one replacement of the human

00:12:22.900 --> 00:12:22.910
one-to-one replacement of the human
 

00:12:22.910 --> 00:12:24.579
one-to-one replacement of the human
intelligence with something new and

00:12:24.579 --> 00:12:24.589
intelligence with something new and
 

00:12:24.589 --> 00:12:26.380
intelligence with something new and
maybe that's why they called it AI which

00:12:26.380 --> 00:12:26.390
maybe that's why they called it AI which
 

00:12:26.390 --> 00:12:28.300
maybe that's why they called it AI which
I agree 100% with Eric is kind of a bad

00:12:28.300 --> 00:12:28.310
I agree 100% with Eric is kind of a bad
 

00:12:28.310 --> 00:12:30.880
I agree 100% with Eric is kind of a bad
name for it the word artificial throws

00:12:30.880 --> 00:12:30.890
name for it the word artificial throws
 

00:12:30.890 --> 00:12:35.650
name for it the word artificial throws
us off fundamentally the first form of

00:12:35.650 --> 00:12:35.660
us off fundamentally the first form of
 

00:12:35.660 --> 00:12:36.970
us off fundamentally the first form of
alienation I'm going to talk about is

00:12:36.970 --> 00:12:36.980
alienation I'm going to talk about is
 

00:12:36.980 --> 00:12:39.639
alienation I'm going to talk about is
the alienation from mimesis itself AI

00:12:39.639 --> 00:12:39.649
the alienation from mimesis itself AI
 

00:12:39.649 --> 00:12:41.980
the alienation from mimesis itself AI
the reality what it is today

00:12:41.980 --> 00:12:41.990
the reality what it is today
 

00:12:41.990 --> 00:12:45.189
the reality what it is today
has alienated us from that very idea of

00:12:45.189 --> 00:12:45.199
has alienated us from that very idea of
 

00:12:45.199 --> 00:12:48.400
has alienated us from that very idea of
a one-to-one relationship or one to one

00:12:48.400 --> 00:12:48.410
a one-to-one relationship or one to one
 

00:12:48.410 --> 00:12:50.949
a one-to-one relationship or one to one
replacement hypothesis from person to

00:12:50.949 --> 00:12:50.959
replacement hypothesis from person to
 

00:12:50.959 --> 00:12:53.380
replacement hypothesis from person to
artificial person we don't aren't making

00:12:53.380 --> 00:12:53.390
artificial person we don't aren't making
 

00:12:53.390 --> 00:12:56.650
artificial person we don't aren't making
artificial people by any stretch in fact

00:12:56.650 --> 00:12:56.660
artificial people by any stretch in fact
 

00:12:56.660 --> 00:12:58.780
artificial people by any stretch in fact
if I look at the most successful AI

00:12:58.780 --> 00:12:58.790
if I look at the most successful AI
 

00:12:58.790 --> 00:13:01.510
if I look at the most successful AI
systems today that I boast about and I

00:13:01.510 --> 00:13:01.520
systems today that I boast about and I
 

00:13:01.520 --> 00:13:03.970
systems today that I boast about and I
am proud of they have nothing to do with

00:13:03.970 --> 00:13:03.980
am proud of they have nothing to do with
 

00:13:03.980 --> 00:13:05.890
am proud of they have nothing to do with
they don't work like people they don't

00:13:05.890 --> 00:13:05.900
they don't work like people they don't
 

00:13:05.900 --> 00:13:07.600
they don't work like people they don't
smell like people they don't behave like

00:13:07.600 --> 00:13:07.610
smell like people they don't behave like
 

00:13:07.610 --> 00:13:09.850
smell like people they don't behave like
people but they solve world problems I'm

00:13:09.850 --> 00:13:09.860
people but they solve world problems I'm
 

00:13:09.860 --> 00:13:11.590
people but they solve world problems I'm
gonna give you two quick examples to

00:13:11.590 --> 00:13:11.600
gonna give you two quick examples to
 

00:13:11.600 --> 00:13:13.060
gonna give you two quick examples to
give you a sense of how different these

00:13:13.060 --> 00:13:13.070
give you a sense of how different these
 

00:13:13.070 --> 00:13:15.730
give you a sense of how different these
systems are how alienated from human

00:13:15.730 --> 00:13:15.740
systems are how alienated from human
 

00:13:15.740 --> 00:13:19.390
systems are how alienated from human
mimesis first system I love done by

00:13:19.390 --> 00:13:19.400
mimesis first system I love done by
 

00:13:19.400 --> 00:13:20.740
mimesis first system I love done by
Steve Smith right here in Carnegie

00:13:20.740 --> 00:13:20.750
Steve Smith right here in Carnegie
 

00:13:20.750 --> 00:13:24.370
Steve Smith right here in Carnegie
Mellon University East Liberty all the

00:13:24.370 --> 00:13:24.380
Mellon University East Liberty all the
 

00:13:24.380 --> 00:13:26.380
Mellon University East Liberty all the
traffic lights in this neighborhood have

00:13:26.380 --> 00:13:26.390
traffic lights in this neighborhood have
 

00:13:26.390 --> 00:13:28.630
traffic lights in this neighborhood have
cameras on them now and instead of

00:13:28.630 --> 00:13:28.640
cameras on them now and instead of
 

00:13:28.640 --> 00:13:31.180
cameras on them now and instead of
having regular metric counters that

00:13:31.180 --> 00:13:31.190
having regular metric counters that
 

00:13:31.190 --> 00:13:32.920
having regular metric counters that
decide how long the green light red

00:13:32.920 --> 00:13:32.930
decide how long the green light red
 

00:13:32.930 --> 00:13:35.530
decide how long the green light red
light episodes last these cameras look

00:13:35.530 --> 00:13:35.540
light episodes last these cameras look
 

00:13:35.540 --> 00:13:37.350
light episodes last these cameras look
at pedestrians and they look at cars and

00:13:37.350 --> 00:13:37.360
at pedestrians and they look at cars and
 

00:13:37.360 --> 00:13:40.240
at pedestrians and they look at cars and
they optimize beautifully across a

00:13:40.240 --> 00:13:40.250
they optimize beautifully across a
 

00:13:40.250 --> 00:13:43.030
they optimize beautifully across a
network of dozens of lights the exact

00:13:43.030 --> 00:13:43.040
network of dozens of lights the exact
 

00:13:43.040 --> 00:13:44.920
network of dozens of lights the exact
pacing of the red and green lights in

00:13:44.920 --> 00:13:44.930
pacing of the red and green lights in
 

00:13:44.930 --> 00:13:46.990
pacing of the red and green lights in
such a way as to minimize idle time in

00:13:46.990 --> 00:13:47.000
such a way as to minimize idle time in
 

00:13:47.000 --> 00:13:49.510
such a way as to minimize idle time in
cars and maximize pedestrian throughput

00:13:49.510 --> 00:13:49.520
cars and maximize pedestrian throughput
 

00:13:49.520 --> 00:13:51.850
cars and maximize pedestrian throughput
which you get is much much faster

00:13:51.850 --> 00:13:51.860
which you get is much much faster
 

00:13:51.860 --> 00:13:54.340
which you get is much much faster
pedestrian walking and much much less

00:13:54.340 --> 00:13:54.350
pedestrian walking and much much less
 

00:13:54.350 --> 00:13:55.900
pedestrian walking and much much less
particulate matter in the air from

00:13:55.900 --> 00:13:55.910
particulate matter in the air from
 

00:13:55.910 --> 00:13:58.150
particulate matter in the air from
idling it actually works something

00:13:58.150 --> 00:13:58.160
idling it actually works something
 

00:13:58.160 --> 00:13:59.920
idling it actually works something
extraordinary like I think 40 percent

00:13:59.920 --> 00:13:59.930
extraordinary like I think 40 percent
 

00:13:59.930 --> 00:14:02.680
extraordinary like I think 40 percent
reduction in local pollution just from

00:14:02.680 --> 00:14:02.690
reduction in local pollution just from
 

00:14:02.690 --> 00:14:05.410
reduction in local pollution just from
idling of cars I mean ridiculously cool

00:14:05.410 --> 00:14:05.420
idling of cars I mean ridiculously cool
 

00:14:05.420 --> 00:14:07.540
idling of cars I mean ridiculously cool
results but this is an intelligent

00:14:07.540 --> 00:14:07.550
results but this is an intelligent
 

00:14:07.550 --> 00:14:10.330
results but this is an intelligent
network of cameras responsive to people

00:14:10.330 --> 00:14:10.340
network of cameras responsive to people
 

00:14:10.340 --> 00:14:12.700
network of cameras responsive to people
and pedestrians is that a human is it

00:14:12.700 --> 00:14:12.710
and pedestrians is that a human is it
 

00:14:12.710 --> 00:14:14.740
and pedestrians is that a human is it
replacing a human job no it has nothing

00:14:14.740 --> 00:14:14.750
replacing a human job no it has nothing
 

00:14:14.750 --> 00:14:16.480
replacing a human job no it has nothing
to do with any task that a human had

00:14:16.480 --> 00:14:16.490
to do with any task that a human had
 

00:14:16.490 --> 00:14:18.070
to do with any task that a human had
been sitting there doing there are no

00:14:18.070 --> 00:14:18.080
been sitting there doing there are no
 

00:14:18.080 --> 00:14:19.900
been sitting there doing there are no
gnome is sitting there hitting lights

00:14:19.900 --> 00:14:19.910
gnome is sitting there hitting lights
 

00:14:19.910 --> 00:14:22.240
gnome is sitting there hitting lights
turning lights green and red this is a

00:14:22.240 --> 00:14:22.250
turning lights green and red this is a
 

00:14:22.250 --> 00:14:25.030
turning lights green and red this is a
whole new category of action I'll give

00:14:25.030 --> 00:14:25.040
whole new category of action I'll give
 

00:14:25.040 --> 00:14:26.620
whole new category of action I'll give
you one more example that comes out of

00:14:26.620 --> 00:14:26.630
you one more example that comes out of
 

00:14:26.630 --> 00:14:28.300
you one more example that comes out of
the old lab of Jeff Schneider and a

00:14:28.300 --> 00:14:28.310
the old lab of Jeff Schneider and a
 

00:14:28.310 --> 00:14:29.440
the old lab of Jeff Schneider and a
number of other people at Carnegie

00:14:29.440 --> 00:14:29.450
number of other people at Carnegie
 

00:14:29.450 --> 00:14:31.900
number of other people at Carnegie
Mellon which is the ability to do

00:14:31.900 --> 00:14:31.910
Mellon which is the ability to do
 

00:14:31.910 --> 00:14:33.990
Mellon which is the ability to do
behavioral analytics to discover

00:14:33.990 --> 00:14:34.000
behavioral analytics to discover
 

00:14:34.000 --> 00:14:36.610
behavioral analytics to discover
dangerous situations they did a very

00:14:36.610 --> 00:14:36.620
dangerous situations they did a very
 

00:14:36.620 --> 00:14:38.140
dangerous situations they did a very
famous piece of work about seven years

00:14:38.140 --> 00:14:38.150
famous piece of work about seven years
 

00:14:38.150 --> 00:14:40.540
famous piece of work about seven years
ago looking at purchasing habits in drug

00:14:40.540 --> 00:14:40.550
ago looking at purchasing habits in drug
 

00:14:40.550 --> 00:14:42.520
ago looking at purchasing habits in drug
stores and they were able to create

00:14:42.520 --> 00:14:42.530
stores and they were able to create
 

00:14:42.530 --> 00:14:45.220
stores and they were able to create
systems that can in advance predict the

00:14:45.220 --> 00:14:45.230
systems that can in advance predict the
 

00:14:45.230 --> 00:14:47.020
systems that can in advance predict the
onset of pandemics in the United States

00:14:47.020 --> 00:14:47.030
onset of pandemics in the United States
 

00:14:47.030 --> 00:14:50.740
onset of pandemics in the United States
like the cold virus by changes in

00:14:50.740 --> 00:14:50.750
like the cold virus by changes in
 

00:14:50.750 --> 00:14:52.270
like the cold virus by changes in
purchasing habits and drug stores

00:14:52.270 --> 00:14:52.280
purchasing habits and drug stores
 

00:14:52.280 --> 00:14:55.210
purchasing habits and drug stores
there was nobody doing that at the CDC

00:14:55.210 --> 00:14:55.220
there was nobody doing that at the CDC
 

00:14:55.220 --> 00:14:56.110
there was nobody doing that at the CDC
like that

00:14:56.110 --> 00:14:56.120
like that
 

00:14:56.120 --> 00:14:57.640
like that
because it couldn't be done it's a big

00:14:57.640 --> 00:14:57.650
because it couldn't be done it's a big
 

00:14:57.650 --> 00:14:59.320
because it couldn't be done it's a big
data analytics problem and they did it

00:14:59.320 --> 00:14:59.330
data analytics problem and they did it
 

00:14:59.330 --> 00:15:01.570
data analytics problem and they did it
and they took the same system and today

00:15:01.570 --> 00:15:01.580
and they took the same system and today
 

00:15:01.580 --> 00:15:03.640
and they took the same system and today
they use it for human sex trafficking so

00:15:03.640 --> 00:15:03.650
they use it for human sex trafficking so
 

00:15:03.650 --> 00:15:05.680
they use it for human sex trafficking so
they're able to actually find elements

00:15:05.680 --> 00:15:05.690
they're able to actually find elements
 

00:15:05.690 --> 00:15:06.850
they're able to actually find elements
of human sex trafficking around the

00:15:06.850 --> 00:15:06.860
of human sex trafficking around the
 

00:15:06.860 --> 00:15:09.490
of human sex trafficking around the
world by simply taking all of the

00:15:09.490 --> 00:15:09.500
world by simply taking all of the
 

00:15:09.500 --> 00:15:11.050
world by simply taking all of the
communication media in the internet and

00:15:11.050 --> 00:15:11.060
communication media in the internet and
 

00:15:11.060 --> 00:15:12.910
communication media in the internet and
analyzing them at massive speed that

00:15:12.910 --> 00:15:12.920
analyzing them at massive speed that
 

00:15:12.920 --> 00:15:14.590
analyzing them at massive speed that
does not replace anybody who's doing

00:15:14.590 --> 00:15:14.600
does not replace anybody who's doing
 

00:15:14.600 --> 00:15:17.319
does not replace anybody who's doing
that work that way instead

00:15:17.319 --> 00:15:17.329
that work that way instead
 

00:15:17.329 --> 00:15:19.569
that work that way instead
it's not mimesis but a whole new way of

00:15:19.569 --> 00:15:19.579
it's not mimesis but a whole new way of
 

00:15:19.579 --> 00:15:20.889
it's not mimesis but a whole new way of
thinking about computational

00:15:20.889 --> 00:15:20.899
thinking about computational
 

00:15:20.899 --> 00:15:22.739
thinking about computational
intelligence applied to a real problem

00:15:22.739 --> 00:15:22.749
intelligence applied to a real problem
 

00:15:22.749 --> 00:15:25.629
intelligence applied to a real problem
now the second problem the second kind

00:15:25.629 --> 00:15:25.639
now the second problem the second kind
 

00:15:25.639 --> 00:15:27.910
now the second problem the second kind
of alienation alienation from failure

00:15:27.910 --> 00:15:27.920
of alienation alienation from failure
 

00:15:27.920 --> 00:15:31.090
of alienation alienation from failure
and this is a really big problem we have

00:15:31.090 --> 00:15:31.100
and this is a really big problem we have
 

00:15:31.100 --> 00:15:33.189
and this is a really big problem we have
an intuition for how humans fail and

00:15:33.189 --> 00:15:33.199
an intuition for how humans fail and
 

00:15:33.199 --> 00:15:35.199
an intuition for how humans fail and
with natural intelligence we understand

00:15:35.199 --> 00:15:35.209
with natural intelligence we understand
 

00:15:35.209 --> 00:15:36.639
with natural intelligence we understand
what failure looks like and what success

00:15:36.639 --> 00:15:36.649
what failure looks like and what success
 

00:15:36.649 --> 00:15:38.559
what failure looks like and what success
looks like and I just explained to you

00:15:38.559 --> 00:15:38.569
looks like and I just explained to you
 

00:15:38.569 --> 00:15:39.970
looks like and I just explained to you
success does not look anything like

00:15:39.970 --> 00:15:39.980
success does not look anything like
 

00:15:39.980 --> 00:15:42.189
success does not look anything like
human success in the regime of robots

00:15:42.189 --> 00:15:42.199
human success in the regime of robots
 

00:15:42.199 --> 00:15:44.739
human success in the regime of robots
and AI but guess what failure looks

00:15:44.739 --> 00:15:44.749
and AI but guess what failure looks
 

00:15:44.749 --> 00:15:46.389
and AI but guess what failure looks
nothing like human failure either and

00:15:46.389 --> 00:15:46.399
nothing like human failure either and
 

00:15:46.399 --> 00:15:49.210
nothing like human failure either and
yet we have biases that make us try and

00:15:49.210 --> 00:15:49.220
yet we have biases that make us try and
 

00:15:49.220 --> 00:15:50.259
yet we have biases that make us try and
suit

00:15:50.259 --> 00:15:50.269
suit
 

00:15:50.269 --> 00:15:52.900
suit
the robot failure into the close of

00:15:52.900 --> 00:15:52.910
the robot failure into the close of
 

00:15:52.910 --> 00:15:54.400
the robot failure into the close of
human failure I'll give you a couple of

00:15:54.400 --> 00:15:54.410
human failure I'll give you a couple of
 

00:15:54.410 --> 00:15:56.229
human failure I'll give you a couple of
examples from two friends of mine Sewer

00:15:56.229 --> 00:15:56.239
examples from two friends of mine Sewer
 

00:15:56.239 --> 00:15:57.850
examples from two friends of mine Sewer
Russell has an example he uses he shows

00:15:57.850 --> 00:15:57.860
Russell has an example he uses he shows
 

00:15:57.860 --> 00:16:00.340
Russell has an example he uses he shows
a picture and in the picture there's

00:16:00.340 --> 00:16:00.350
a picture and in the picture there's
 

00:16:00.350 --> 00:16:03.729
a picture and in the picture there's
some people and there's a market and he

00:16:03.729 --> 00:16:03.739
some people and there's a market and he
 

00:16:03.739 --> 00:16:06.039
some people and there's a market and he
uses one of the online image analysis

00:16:06.039 --> 00:16:06.049
uses one of the online image analysis
 

00:16:06.049 --> 00:16:08.049
uses one of the online image analysis
tools and it spits out a sentence it

00:16:08.049 --> 00:16:08.059
tools and it spits out a sentence it
 

00:16:08.059 --> 00:16:09.609
tools and it spits out a sentence it
says a group of people buying vegetables

00:16:09.609 --> 00:16:09.619
says a group of people buying vegetables
 

00:16:09.619 --> 00:16:11.530
says a group of people buying vegetables
at a fruit stand and the people in the

00:16:11.530 --> 00:16:11.540
at a fruit stand and the people in the
 

00:16:11.540 --> 00:16:12.850
at a fruit stand and the people in the
onions look at this and go wow that's

00:16:12.850 --> 00:16:12.860
onions look at this and go wow that's
 

00:16:12.860 --> 00:16:15.280
onions look at this and go wow that's
awesome that AI system really knows

00:16:15.280 --> 00:16:15.290
awesome that AI system really knows
 

00:16:15.290 --> 00:16:17.379
awesome that AI system really knows
what's going on in that picture then you

00:16:17.379 --> 00:16:17.389
what's going on in that picture then you
 

00:16:17.389 --> 00:16:19.239
what's going on in that picture then you
zoom in on the picture there's no group

00:16:19.239 --> 00:16:19.249
zoom in on the picture there's no group
 

00:16:19.249 --> 00:16:21.639
zoom in on the picture there's no group
of people it's one person there's no

00:16:21.639 --> 00:16:21.649
of people it's one person there's no
 

00:16:21.649 --> 00:16:23.439
of people it's one person there's no
fruit stand it's a bunch of green leaves

00:16:23.439 --> 00:16:23.449
fruit stand it's a bunch of green leaves
 

00:16:23.449 --> 00:16:26.769
fruit stand it's a bunch of green leaves
and yet to you the human observer when

00:16:26.769 --> 00:16:26.779
and yet to you the human observer when
 

00:16:26.779 --> 00:16:28.079
and yet to you the human observer when
you look at that picture you'll love it

00:16:28.079 --> 00:16:28.089
you look at that picture you'll love it
 

00:16:28.089 --> 00:16:30.759
you look at that picture you'll love it
rod Brooks doesn't even better one he

00:16:30.759 --> 00:16:30.769
rod Brooks doesn't even better one he
 

00:16:30.769 --> 00:16:34.090
rod Brooks doesn't even better one he
shows a picture and the computer says a

00:16:34.090 --> 00:16:34.100
shows a picture and the computer says a
 

00:16:34.100 --> 00:16:35.350
shows a picture and the computer says a
group of children playing frisbee on

00:16:35.350 --> 00:16:35.360
group of children playing frisbee on
 

00:16:35.360 --> 00:16:39.600
group of children playing frisbee on
grass and then he asks the same system

00:16:39.600 --> 00:16:39.610
grass and then he asks the same system
 

00:16:39.610 --> 00:16:41.350
grass and then he asks the same system
because it is a good four children

00:16:41.350 --> 00:16:41.360
because it is a good four children
 

00:16:41.360 --> 00:16:42.369
because it is a good four children
playing frisbee on grass that one

00:16:42.369 --> 00:16:42.379
playing frisbee on grass that one
 

00:16:42.379 --> 00:16:44.439
playing frisbee on grass that one
actually gets it right so then he asked

00:16:44.439 --> 00:16:44.449
actually gets it right so then he asked
 

00:16:44.449 --> 00:16:46.659
actually gets it right so then he asked
the system so can six months olds play

00:16:46.659 --> 00:16:46.669
the system so can six months olds play
 

00:16:46.669 --> 00:16:49.329
the system so can six months olds play
frisbee it has no idea do frisbees taste

00:16:49.329 --> 00:16:49.339
frisbee it has no idea do frisbees taste
 

00:16:49.339 --> 00:16:52.600
frisbee it has no idea do frisbees taste
good no clue how far do fizz bees fly no

00:16:52.600 --> 00:16:52.610
good no clue how far do fizz bees fly no
 

00:16:52.610 --> 00:16:56.229
good no clue how far do fizz bees fly no
idea that sentence is there because a

00:16:56.229 --> 00:16:56.239
idea that sentence is there because a
 

00:16:56.239 --> 00:16:58.359
idea that sentence is there because a
statistical analysis that made that

00:16:58.359 --> 00:16:58.369
statistical analysis that made that
 

00:16:58.369 --> 00:17:00.489
statistical analysis that made that
sentence a construct associated with

00:17:00.489 --> 00:17:00.499
sentence a construct associated with
 

00:17:00.499 --> 00:17:02.470
sentence a construct associated with
that picture it doesn't mean that the

00:17:02.470 --> 00:17:02.480
that picture it doesn't mean that the
 

00:17:02.480 --> 00:17:03.850
that picture it doesn't mean that the
computer has any clue what any of the

00:17:03.850 --> 00:17:03.860
computer has any clue what any of the
 

00:17:03.860 --> 00:17:06.429
computer has any clue what any of the
individual words in the sentence mean or

00:17:06.429 --> 00:17:06.439
individual words in the sentence mean or
 

00:17:06.439 --> 00:17:07.960
individual words in the sentence mean or
what the semantics of that sentence are

00:17:07.960 --> 00:17:07.970
what the semantics of that sentence are
 

00:17:07.970 --> 00:17:10.299
what the semantics of that sentence are
in that particular case and maybe it

00:17:10.299 --> 00:17:10.309
in that particular case and maybe it
 

00:17:10.309 --> 00:17:12.370
in that particular case and maybe it
does and maybe it doesn't but we the

00:17:12.370 --> 00:17:12.380
does and maybe it doesn't but we the
 

00:17:12.380 --> 00:17:14.590
does and maybe it doesn't but we the
observers have no idea if it does or it

00:17:14.590 --> 00:17:14.600
observers have no idea if it does or it
 

00:17:14.600 --> 00:17:17.199
observers have no idea if it does or it
doesn't and yet our failing as humans is

00:17:17.199 --> 00:17:17.209
doesn't and yet our failing as humans is
 

00:17:17.209 --> 00:17:19.710
doesn't and yet our failing as humans is
to imbue upon that computer meaning

00:17:19.710 --> 00:17:19.720
to imbue upon that computer meaning
 

00:17:19.720 --> 00:17:21.699
to imbue upon that computer meaning
because it's using human language so

00:17:21.699 --> 00:17:21.709
because it's using human language so
 

00:17:21.709 --> 00:17:23.740
because it's using human language so
certainly it understands same problem I

00:17:23.740 --> 00:17:23.750
certainly it understands same problem I
 

00:17:23.750 --> 00:17:25.360
certainly it understands same problem I
have with my colleagues who put eyes and

00:17:25.360 --> 00:17:25.370
have with my colleagues who put eyes and
 

00:17:25.370 --> 00:17:27.789
have with my colleagues who put eyes and
ears and a smile on their robot and then

00:17:27.789 --> 00:17:27.799
ears and a smile on their robot and then
 

00:17:27.799 --> 00:17:30.610
ears and a smile on their robot and then
when it smiles you in view upon it at

00:17:30.610 --> 00:17:30.620
when it smiles you in view upon it at
 

00:17:30.620 --> 00:17:33.220
when it smiles you in view upon it at
effect when that effect is literally

00:17:33.220 --> 00:17:33.230
effect when that effect is literally
 

00:17:33.230 --> 00:17:36.190
effect when that effect is literally
Hollywood so that's the second kind of

00:17:36.190 --> 00:17:36.200
Hollywood so that's the second kind of
 

00:17:36.200 --> 00:17:39.130
Hollywood so that's the second kind of
failure alienation from failure the last

00:17:39.130 --> 00:17:39.140
failure alienation from failure the last
 

00:17:39.140 --> 00:17:42.030
failure alienation from failure the last
one is actually the worst one in a way

00:17:42.030 --> 00:17:42.040
one is actually the worst one in a way
 

00:17:42.040 --> 00:17:45.730
one is actually the worst one in a way
when I got my PhD we used to deal a lot

00:17:45.730 --> 00:17:45.740
when I got my PhD we used to deal a lot
 

00:17:45.740 --> 00:17:46.900
when I got my PhD we used to deal a lot
with something called non monotonic

00:17:46.900 --> 00:17:46.910
with something called non monotonic
 

00:17:46.910 --> 00:17:48.910
with something called non monotonic
reasoning humans make assumptions to

00:17:48.910 --> 00:17:48.920
reasoning humans make assumptions to
 

00:17:48.920 --> 00:17:50.860
reasoning humans make assumptions to
make the world something we can deal

00:17:50.860 --> 00:17:50.870
make the world something we can deal
 

00:17:50.870 --> 00:17:53.380
make the world something we can deal
with we ignore irrelevant detail and

00:17:53.380 --> 00:17:53.390
with we ignore irrelevant detail and
 

00:17:53.390 --> 00:17:55.240
with we ignore irrelevant detail and
think about relevant detail and then we

00:17:55.240 --> 00:17:55.250
think about relevant detail and then we
 

00:17:55.250 --> 00:17:56.350
think about relevant detail and then we
change our minds if something becomes

00:17:56.350 --> 00:17:56.360
change our minds if something becomes
 

00:17:56.360 --> 00:17:57.549
change our minds if something becomes
relevant that we thought was irrelevant

00:17:57.549 --> 00:17:57.559
relevant that we thought was irrelevant
 

00:17:57.559 --> 00:17:59.710
relevant that we thought was irrelevant
like oh my car is not starting and I'm

00:17:59.710 --> 00:17:59.720
like oh my car is not starting and I'm
 

00:17:59.720 --> 00:18:00.790
like oh my car is not starting and I'm
late for an appointment now I have to

00:18:00.790 --> 00:18:00.800
late for an appointment now I have to
 

00:18:00.800 --> 00:18:01.950
late for an appointment now I have to
start worrying about my car not starting

00:18:01.950 --> 00:18:01.960
start worrying about my car not starting
 

00:18:01.960 --> 00:18:04.000
start worrying about my car not starting
but I don't spend all morning worrying

00:18:04.000 --> 00:18:04.010
but I don't spend all morning worrying
 

00:18:04.010 --> 00:18:05.680
but I don't spend all morning worrying
about that until it becomes a real thing

00:18:05.680 --> 00:18:05.690
about that until it becomes a real thing
 

00:18:05.690 --> 00:18:09.010
about that until it becomes a real thing
so we sometimes call that things like

00:18:09.010 --> 00:18:09.020
so we sometimes call that things like
 

00:18:09.020 --> 00:18:10.360
so we sometimes call that things like
the closed world assumption we make an

00:18:10.360 --> 00:18:10.370
the closed world assumption we make an
 

00:18:10.370 --> 00:18:11.770
the closed world assumption we make an
assumption that the world is what it is

00:18:11.770 --> 00:18:11.780
assumption that the world is what it is
 

00:18:11.780 --> 00:18:13.540
assumption that the world is what it is
and it's kind of static until we have to

00:18:13.540 --> 00:18:13.550
and it's kind of static until we have to
 

00:18:13.550 --> 00:18:15.669
and it's kind of static until we have to
change our mind well the problem is we

00:18:15.669 --> 00:18:15.679
change our mind well the problem is we
 

00:18:15.679 --> 00:18:16.870
change our mind well the problem is we
make that assumption about technology

00:18:16.870 --> 00:18:16.880
make that assumption about technology
 

00:18:16.880 --> 00:18:19.360
make that assumption about technology
when I see the boundaries of efficacy

00:18:19.360 --> 00:18:19.370
when I see the boundaries of efficacy
 

00:18:19.370 --> 00:18:21.580
when I see the boundaries of efficacy
that a computer has I assume that's what

00:18:21.580 --> 00:18:21.590
that a computer has I assume that's what
 

00:18:21.590 --> 00:18:22.930
that a computer has I assume that's what
a computer can do that's what AI is

00:18:22.930 --> 00:18:22.940
a computer can do that's what AI is
 

00:18:22.940 --> 00:18:24.820
a computer can do that's what AI is
capable of and I will always be wrong

00:18:24.820 --> 00:18:24.830
capable of and I will always be wrong
 

00:18:24.830 --> 00:18:27.460
capable of and I will always be wrong
because AI is dynamic it is not static

00:18:27.460 --> 00:18:27.470
because AI is dynamic it is not static
 

00:18:27.470 --> 00:18:29.260
because AI is dynamic it is not static
and what it can do tomorrow is different

00:18:29.260 --> 00:18:29.270
and what it can do tomorrow is different
 

00:18:29.270 --> 00:18:31.540
and what it can do tomorrow is different
from what it can do today and our

00:18:31.540 --> 00:18:31.550
from what it can do today and our
 

00:18:31.550 --> 00:18:35.950
from what it can do today and our
ability as a human populace to make hay

00:18:35.950 --> 00:18:35.960
ability as a human populace to make hay
 

00:18:35.960 --> 00:18:37.720
ability as a human populace to make hay
of that does not exist we don't

00:18:37.720 --> 00:18:37.730
of that does not exist we don't
 

00:18:37.730 --> 00:18:39.820
of that does not exist we don't
understand how to think about a system

00:18:39.820 --> 00:18:39.830
understand how to think about a system
 

00:18:39.830 --> 00:18:41.530
understand how to think about a system
whose capabilities change every day and

00:18:41.530 --> 00:18:41.540
whose capabilities change every day and
 

00:18:41.540 --> 00:18:43.690
whose capabilities change every day and
that's a fundamental problem is that we

00:18:43.690 --> 00:18:43.700
that's a fundamental problem is that we
 

00:18:43.700 --> 00:18:45.540
that's a fundamental problem is that we
have a static model of a dynamic system

00:18:45.540 --> 00:18:45.550
have a static model of a dynamic system
 

00:18:45.550 --> 00:18:50.440
have a static model of a dynamic system
so diagnosis if we are being alienated

00:18:50.440 --> 00:18:50.450
so diagnosis if we are being alienated
 

00:18:50.450 --> 00:18:52.360
so diagnosis if we are being alienated
from this technology in the case of

00:18:52.360 --> 00:18:52.370
from this technology in the case of
 

00:18:52.370 --> 00:18:54.280
from this technology in the case of
success in the case of failure and by

00:18:54.280 --> 00:18:54.290
success in the case of failure and by
 

00:18:54.290 --> 00:18:55.630
success in the case of failure and by
our inability to understand how it's

00:18:55.630 --> 00:18:55.640
our inability to understand how it's
 

00:18:55.640 --> 00:18:58.570
our inability to understand how it's
moving what is the diagnosis well the

00:18:58.570 --> 00:18:58.580
moving what is the diagnosis well the
 

00:18:58.580 --> 00:18:59.919
moving what is the diagnosis well the
diagnosis is very simple where AI

00:18:59.919 --> 00:18:59.929
diagnosis is very simple where AI
 

00:18:59.929 --> 00:19:01.960
diagnosis is very simple where AI
illiterate and by we I don't mean the

00:19:01.960 --> 00:19:01.970
illiterate and by we I don't mean the
 

00:19:01.970 --> 00:19:05.890
illiterate and by we I don't mean the
wonderful lawmakers and colleagues that

00:19:05.890 --> 00:19:05.900
wonderful lawmakers and colleagues that
 

00:19:05.900 --> 00:19:07.330
wonderful lawmakers and colleagues that
I have in this room I mean the human

00:19:07.330 --> 00:19:07.340
I have in this room I mean the human
 

00:19:07.340 --> 00:19:08.980
I have in this room I mean the human
population I mean those who have to

00:19:08.980 --> 00:19:08.990
population I mean those who have to
 

00:19:08.990 --> 00:19:10.540
population I mean those who have to
engage in civic discourse nationally

00:19:10.540 --> 00:19:10.550
engage in civic discourse nationally
 

00:19:10.550 --> 00:19:13.090
engage in civic discourse nationally
internationally so we're a I literate

00:19:13.090 --> 00:19:13.100
internationally so we're a I literate
 

00:19:13.100 --> 00:19:15.910
internationally so we're a I literate
and it matters now compared to twenty

00:19:15.910 --> 00:19:15.920
and it matters now compared to twenty
 

00:19:15.920 --> 00:19:17.169
and it matters now compared to twenty
years ago because AI is actually

00:19:17.169 --> 00:19:17.179
years ago because AI is actually
 

00:19:17.179 --> 00:19:20.169
years ago because AI is actually
changing the world to its elections to

00:19:20.169 --> 00:19:20.179
changing the world to its elections to
 

00:19:20.179 --> 00:19:21.880
changing the world to its elections to
it marketing and all the other ways in

00:19:21.880 --> 00:19:21.890
it marketing and all the other ways in
 

00:19:21.890 --> 00:19:24.160
it marketing and all the other ways in
which a changes the world and it's funny

00:19:24.160 --> 00:19:24.170
which a changes the world and it's funny
 

00:19:24.170 --> 00:19:26.080
which a changes the world and it's funny
if you look at you know very very fast

00:19:26.080 --> 00:19:26.090
if you look at you know very very fast
 

00:19:26.090 --> 00:19:28.390
if you look at you know very very fast
financial trades they change the world

00:19:28.390 --> 00:19:28.400
financial trades they change the world
 

00:19:28.400 --> 00:19:30.010
financial trades they change the world
but at least in a little way we were all

00:19:30.010 --> 00:19:30.020
but at least in a little way we were all
 

00:19:30.020 --> 00:19:31.930
but at least in a little way we were all
read about it on marketplace the

00:19:31.930 --> 00:19:31.940
read about it on marketplace the
 

00:19:31.940 --> 00:19:33.669
read about it on marketplace the
difference is these new AI systems they

00:19:33.669 --> 00:19:33.679
difference is these new AI systems they
 

00:19:33.679 --> 00:19:35.440
difference is these new AI systems they
change what humans do on mass they

00:19:35.440 --> 00:19:35.450
change what humans do on mass they
 

00:19:35.450 --> 00:19:37.330
change what humans do on mass they
change our behavior so they're pushing

00:19:37.330 --> 00:19:37.340
change our behavior so they're pushing
 

00:19:37.340 --> 00:19:40.419
change our behavior so they're pushing
back hard I think the mistake got made a

00:19:40.419 --> 00:19:40.429
back hard I think the mistake got made a
 

00:19:40.429 --> 00:19:42.070
back hard I think the mistake got made a
few years ago when we invented the

00:19:42.070 --> 00:19:42.080
few years ago when we invented the
 

00:19:42.080 --> 00:19:44.250
few years ago when we invented the
phrase stem we really really missed

00:19:44.250 --> 00:19:44.260
phrase stem we really really missed
 

00:19:44.260 --> 00:19:47.070
phrase stem we really really missed
big time we invented the word stem we

00:19:47.070 --> 00:19:47.080
big time we invented the word stem we
 

00:19:47.080 --> 00:19:48.720
big time we invented the word stem we
said all our kids have to learn stem

00:19:48.720 --> 00:19:48.730
said all our kids have to learn stem
 

00:19:48.730 --> 00:19:51.900
said all our kids have to learn stem
stem is what matters and we excluded the

00:19:51.900 --> 00:19:51.910
stem is what matters and we excluded the
 

00:19:51.910 --> 00:19:54.630
stem is what matters and we excluded the
humanities completely when what ratters

00:19:54.630 --> 00:19:54.640
humanities completely when what ratters
 

00:19:54.640 --> 00:19:57.540
humanities completely when what ratters
is social science applied to the

00:19:57.540 --> 00:19:57.550
is social science applied to the
 

00:19:57.550 --> 00:19:59.250
is social science applied to the
computer science that we do it's the

00:19:59.250 --> 00:19:59.260
computer science that we do it's the
 

00:19:59.260 --> 00:20:00.510
computer science that we do it's the
combination of the two that lets us

00:20:00.510 --> 00:20:00.520
combination of the two that lets us
 

00:20:00.520 --> 00:20:02.550
combination of the two that lets us
understand the world and yet stem

00:20:02.550 --> 00:20:02.560
understand the world and yet stem
 

00:20:02.560 --> 00:20:05.100
understand the world and yet stem
excluded that divisive lis it also took

00:20:05.100 --> 00:20:05.110
excluded that divisive lis it also took
 

00:20:05.110 --> 00:20:07.020
excluded that divisive lis it also took
all of these disciplines and created

00:20:07.020 --> 00:20:07.030
all of these disciplines and created
 

00:20:07.030 --> 00:20:08.580
all of these disciplines and created
silos for them science technology

00:20:08.580 --> 00:20:08.590
silos for them science technology
 

00:20:08.590 --> 00:20:10.200
silos for them science technology
engineering math as if they're

00:20:10.200 --> 00:20:10.210
engineering math as if they're
 

00:20:10.210 --> 00:20:12.570
engineering math as if they're
individual areas of learning that we can

00:20:12.570 --> 00:20:12.580
individual areas of learning that we can
 

00:20:12.580 --> 00:20:14.670
individual areas of learning that we can
optimize and then we know what to do and

00:20:14.670 --> 00:20:14.680
optimize and then we know what to do and
 

00:20:14.680 --> 00:20:16.650
optimize and then we know what to do and
we don't because knowing anything about

00:20:16.650 --> 00:20:16.660
we don't because knowing anything about
 

00:20:16.660 --> 00:20:18.690
we don't because knowing anything about
those four alone and not

00:20:18.690 --> 00:20:18.700
those four alone and not
 

00:20:18.700 --> 00:20:20.940
those four alone and not
transdisciplinary doesn't allow us to

00:20:20.940 --> 00:20:20.950
transdisciplinary doesn't allow us to
 

00:20:20.950 --> 00:20:23.220
transdisciplinary doesn't allow us to
understand the changes in robotics so

00:20:23.220 --> 00:20:23.230
understand the changes in robotics so
 

00:20:23.230 --> 00:20:25.920
understand the changes in robotics so
I'm at the final part of my talk I've

00:20:25.920 --> 00:20:25.930
I'm at the final part of my talk I've
 

00:20:25.930 --> 00:20:27.360
I'm at the final part of my talk I've
told you about the problems the

00:20:27.360 --> 00:20:27.370
told you about the problems the
 

00:20:27.370 --> 00:20:29.550
told you about the problems the
questions what's our treatment and I

00:20:29.550 --> 00:20:29.560
questions what's our treatment and I
 

00:20:29.560 --> 00:20:32.340
questions what's our treatment and I
believe our treatment is actually that

00:20:32.340 --> 00:20:32.350
believe our treatment is actually that
 

00:20:32.350 --> 00:20:33.900
believe our treatment is actually that
we have to future-proof ourself to the

00:20:33.900 --> 00:20:33.910
we have to future-proof ourself to the
 

00:20:33.910 --> 00:20:36.030
we have to future-proof ourself to the
dynamism of AI itself we have to

00:20:36.030 --> 00:20:36.040
dynamism of AI itself we have to
 

00:20:36.040 --> 00:20:38.400
dynamism of AI itself we have to
future-proof our population to the idea

00:20:38.400 --> 00:20:38.410
future-proof our population to the idea
 

00:20:38.410 --> 00:20:40.230
future-proof our population to the idea
that artificial intelligence is a moving

00:20:40.230 --> 00:20:40.240
that artificial intelligence is a moving
 

00:20:40.240 --> 00:20:44.550
that artificial intelligence is a moving
entity and that it will change and I'll

00:20:44.550 --> 00:20:44.560
entity and that it will change and I'll
 

00:20:44.560 --> 00:20:46.200
entity and that it will change and I'll
give you an example Eric talked in his

00:20:46.200 --> 00:20:46.210
give you an example Eric talked in his
 

00:20:46.210 --> 00:20:48.690
give you an example Eric talked in his
keynote speech yesterday about not just

00:20:48.690 --> 00:20:48.700
keynote speech yesterday about not just
 

00:20:48.700 --> 00:20:49.740
keynote speech yesterday about not just
the fact that these systems have

00:20:49.740 --> 00:20:49.750
the fact that these systems have
 

00:20:49.750 --> 00:20:51.060
the fact that these systems have
computational bias but in fact

00:20:51.060 --> 00:20:51.070
computational bias but in fact
 

00:20:51.070 --> 00:20:53.250
computational bias but in fact
Microsoft's working on ways to overcome

00:20:53.250 --> 00:20:53.260
Microsoft's working on ways to overcome
 

00:20:53.260 --> 00:20:55.860
Microsoft's working on ways to overcome
that by us that's excellent but I

00:20:55.860 --> 00:20:55.870
that by us that's excellent but I
 

00:20:55.870 --> 00:20:58.140
that by us that's excellent but I
challenge you to show the fluency in the

00:20:58.140 --> 00:20:58.150
challenge you to show the fluency in the
 

00:20:58.150 --> 00:21:00.210
challenge you to show the fluency in the
public to then ask the next question

00:21:00.210 --> 00:21:00.220
public to then ask the next question
 

00:21:00.220 --> 00:21:02.280
public to then ask the next question
which is how will those corrective

00:21:02.280 --> 00:21:02.290
which is how will those corrective
 

00:21:02.290 --> 00:21:04.590
which is how will those corrective
techniques be tested and audited how

00:21:04.590 --> 00:21:04.600
techniques be tested and audited how
 

00:21:04.600 --> 00:21:05.820
techniques be tested and audited how
will we know if they work or not

00:21:05.820 --> 00:21:05.830
will we know if they work or not
 

00:21:05.830 --> 00:21:07.530
will we know if they work or not
how can the public know that they don't

00:21:07.530 --> 00:21:07.540
how can the public know that they don't
 

00:21:07.540 --> 00:21:09.540
how can the public know that they don't
have the literacy the fluency that we

00:21:09.540 --> 00:21:09.550
have the literacy the fluency that we
 

00:21:09.550 --> 00:21:11.550
have the literacy the fluency that we
need for that so fundamentally I think

00:21:11.550 --> 00:21:11.560
need for that so fundamentally I think
 

00:21:11.560 --> 00:21:14.850
need for that so fundamentally I think
we need the same kind of fluency for AI

00:21:14.850 --> 00:21:14.860
we need the same kind of fluency for AI
 

00:21:14.860 --> 00:21:17.490
we need the same kind of fluency for AI
for civic discourse that today we have

00:21:17.490 --> 00:21:17.500
for civic discourse that today we have
 

00:21:17.500 --> 00:21:19.410
for civic discourse that today we have
around say government people know how

00:21:19.410 --> 00:21:19.420
around say government people know how
 

00:21:19.420 --> 00:21:22.080
around say government people know how
the separation of power works in the

00:21:22.080 --> 00:21:22.090
the separation of power works in the
 

00:21:22.090 --> 00:21:23.580
the separation of power works in the
United States they know how elections

00:21:23.580 --> 00:21:23.590
United States they know how elections
 

00:21:23.590 --> 00:21:25.230
United States they know how elections
work they know what the electoral

00:21:25.230 --> 00:21:25.240
work they know what the electoral
 

00:21:25.240 --> 00:21:27.560
work they know what the electoral
college is everybody needs to have that

00:21:27.560 --> 00:21:27.570
college is everybody needs to have that
 

00:21:27.570 --> 00:21:30.300
college is everybody needs to have that
undergirding of knowledge so that we can

00:21:30.300 --> 00:21:30.310
undergirding of knowledge so that we can
 

00:21:30.310 --> 00:21:31.500
undergirding of knowledge so that we can
have civic discourse so we can make

00:21:31.500 --> 00:21:31.510
have civic discourse so we can make
 

00:21:31.510 --> 00:21:33.330
have civic discourse so we can make
decisions as a community we don't have

00:21:33.330 --> 00:21:33.340
decisions as a community we don't have
 

00:21:33.340 --> 00:21:35.190
decisions as a community we don't have
that undergirding of knowledge about AI

00:21:35.190 --> 00:21:35.200
that undergirding of knowledge about AI
 

00:21:35.200 --> 00:21:38.430
that undergirding of knowledge about AI
and that's a fundamental problem so in

00:21:38.430 --> 00:21:38.440
and that's a fundamental problem so in
 

00:21:38.440 --> 00:21:40.410
and that's a fundamental problem so in
conclusion what I'm saying is that we

00:21:40.410 --> 00:21:40.420
conclusion what I'm saying is that we
 

00:21:40.420 --> 00:21:43.710
conclusion what I'm saying is that we
need fluency and what that means is we

00:21:43.710 --> 00:21:43.720
need fluency and what that means is we
 

00:21:43.720 --> 00:21:46.140
need fluency and what that means is we
need to recombine a juxtaposition of AI

00:21:46.140 --> 00:21:46.150
need to recombine a juxtaposition of AI
 

00:21:46.150 --> 00:21:48.810
need to recombine a juxtaposition of AI
in humanity we need people to understand

00:21:48.810 --> 00:21:48.820
in humanity we need people to understand
 

00:21:48.820 --> 00:21:51.420
in humanity we need people to understand
what humanity is what are the ways in

00:21:51.420 --> 00:21:51.430
what humanity is what are the ways in
 

00:21:51.430 --> 00:21:52.890
what humanity is what are the ways in
which AI is actually what I'm gonna call

00:21:52.890 --> 00:21:52.900
which AI is actually what I'm gonna call
 

00:21:52.900 --> 00:21:54.480
which AI is actually what I'm gonna call
alien intelligence so I'll give you a

00:21:54.480 --> 00:21:54.490
alien intelligence so I'll give you a
 

00:21:54.490 --> 00:21:56.160
alien intelligence so I'll give you a
new moniker I'll keep the same acronym

00:21:56.160 --> 00:21:56.170
new moniker I'll keep the same acronym
 

00:21:56.170 --> 00:21:57.840
new moniker I'll keep the same acronym
to make it easy so there's

00:21:57.840 --> 00:21:57.850
to make it easy so there's
 

00:21:57.850 --> 00:21:59.820
to make it easy so there's
I'm gonna say it's alien intelligence

00:21:59.820 --> 00:21:59.830
I'm gonna say it's alien intelligence
 

00:21:59.830 --> 00:22:01.980
I'm gonna say it's alien intelligence
but I think we need the population to

00:22:01.980 --> 00:22:01.990
but I think we need the population to
 

00:22:01.990 --> 00:22:03.779
but I think we need the population to
understand how alien that intelligence

00:22:03.779 --> 00:22:03.789
understand how alien that intelligence
 

00:22:03.789 --> 00:22:06.450
understand how alien that intelligence
is how unrelated to the human form or

00:22:06.450 --> 00:22:06.460
is how unrelated to the human form or
 

00:22:06.460 --> 00:22:09.060
is how unrelated to the human form or
the human failings and I'm gonna give

00:22:09.060 --> 00:22:09.070
the human failings and I'm gonna give
 

00:22:09.070 --> 00:22:10.860
the human failings and I'm gonna give
you an example and pose you with a final

00:22:10.860 --> 00:22:10.870
you an example and pose you with a final
 

00:22:10.870 --> 00:22:13.680
you an example and pose you with a final
challenge the example I'll give you that

00:22:13.680 --> 00:22:13.690
challenge the example I'll give you that
 

00:22:13.690 --> 00:22:15.870
challenge the example I'll give you that
we've nailed recently is climate change

00:22:15.870 --> 00:22:15.880
we've nailed recently is climate change
 

00:22:15.880 --> 00:22:18.000
we've nailed recently is climate change
climate change is social and it's

00:22:18.000 --> 00:22:18.010
climate change is social and it's
 

00:22:18.010 --> 00:22:20.520
climate change is social and it's
systemic and what the world has managed

00:22:20.520 --> 00:22:20.530
systemic and what the world has managed
 

00:22:20.530 --> 00:22:22.020
systemic and what the world has managed
to do is come up with markers for

00:22:22.020 --> 00:22:22.030
to do is come up with markers for
 

00:22:22.030 --> 00:22:24.659
to do is come up with markers for
changes in climate the world has figured

00:22:24.659 --> 00:22:24.669
changes in climate the world has figured
 

00:22:24.669 --> 00:22:26.250
changes in climate the world has figured
out ways to systematize the

00:22:26.250 --> 00:22:26.260
out ways to systematize the
 

00:22:26.260 --> 00:22:27.960
out ways to systematize the
understanding of how climate change

00:22:27.960 --> 00:22:27.970
understanding of how climate change
 

00:22:27.970 --> 00:22:29.820
understanding of how climate change
affects the world both in terms of

00:22:29.820 --> 00:22:29.830
affects the world both in terms of
 

00:22:29.830 --> 00:22:31.770
affects the world both in terms of
access to clean water access to air

00:22:31.770 --> 00:22:31.780
access to clean water access to air
 

00:22:31.780 --> 00:22:34.620
access to clean water access to air
climate induced refugees political

00:22:34.620 --> 00:22:34.630
climate induced refugees political
 

00:22:34.630 --> 00:22:36.240
climate induced refugees political
changes due to climate and of course

00:22:36.240 --> 00:22:36.250
changes due to climate and of course
 

00:22:36.250 --> 00:22:38.549
changes due to climate and of course
nutritional gaps due to climate we know

00:22:38.549 --> 00:22:38.559
nutritional gaps due to climate we know
 

00:22:38.559 --> 00:22:40.049
nutritional gaps due to climate we know
how to visualize this we know how to

00:22:40.049 --> 00:22:40.059
how to visualize this we know how to
 

00:22:40.059 --> 00:22:42.690
how to visualize this we know how to
quantify this and because we can do all

00:22:42.690 --> 00:22:42.700
quantify this and because we can do all
 

00:22:42.700 --> 00:22:44.940
quantify this and because we can do all
that we can look 40 years hence show you

00:22:44.940 --> 00:22:44.950
that we can look 40 years hence show you
 

00:22:44.950 --> 00:22:46.470
that we can look 40 years hence show you
the ways in which boundaries are being

00:22:46.470 --> 00:22:46.480
the ways in which boundaries are being
 

00:22:46.480 --> 00:22:49.049
the ways in which boundaries are being
pushed in irreversible ways and as a

00:22:49.049 --> 00:22:49.059
pushed in irreversible ways and as a
 

00:22:49.059 --> 00:22:50.700
pushed in irreversible ways and as a
result what do we have we have the SDGs

00:22:50.700 --> 00:22:50.710
result what do we have we have the SDGs
 

00:22:50.710 --> 00:22:52.260
result what do we have we have the SDGs
the strategic development goes from a UN

00:22:52.260 --> 00:22:52.270
the strategic development goes from a UN
 

00:22:52.270 --> 00:22:53.909
the strategic development goes from a UN
we have very explicit and clear

00:22:53.909 --> 00:22:53.919
we have very explicit and clear
 

00:22:53.919 --> 00:22:55.860
we have very explicit and clear
boundaries along which governments can

00:22:55.860 --> 00:22:55.870
boundaries along which governments can
 

00:22:55.870 --> 00:22:57.990
boundaries along which governments can
actually act together because they can

00:22:57.990 --> 00:22:58.000
actually act together because they can
 

00:22:58.000 --> 00:23:00.330
actually act together because they can
see the possible future that's poor if

00:23:00.330 --> 00:23:00.340
see the possible future that's poor if
 

00:23:00.340 --> 00:23:02.580
see the possible future that's poor if
we don't do the right thing so that is

00:23:02.580 --> 00:23:02.590
we don't do the right thing so that is
 

00:23:02.590 --> 00:23:03.990
we don't do the right thing so that is
how we've dealt with climate change

00:23:03.990 --> 00:23:04.000
how we've dealt with climate change
 

00:23:04.000 --> 00:23:05.669
how we've dealt with climate change
there's a systematized approach that has

00:23:05.669 --> 00:23:05.679
there's a systematized approach that has
 

00:23:05.679 --> 00:23:08.310
there's a systematized approach that has
quantified the externalities of how

00:23:08.310 --> 00:23:08.320
quantified the externalities of how
 

00:23:08.320 --> 00:23:11.880
quantified the externalities of how
climate change affects humanity we need

00:23:11.880 --> 00:23:11.890
climate change affects humanity we need
 

00:23:11.890 --> 00:23:15.510
climate change affects humanity we need
this for AI if you take other ways in

00:23:15.510 --> 00:23:15.520
this for AI if you take other ways in
 

00:23:15.520 --> 00:23:16.830
this for AI if you take other ways in
which we've changed human behavior like

00:23:16.830 --> 00:23:16.840
which we've changed human behavior like
 

00:23:16.840 --> 00:23:18.870
which we've changed human behavior like
the opioid drug epidemic we're starting

00:23:18.870 --> 00:23:18.880
the opioid drug epidemic we're starting
 

00:23:18.880 --> 00:23:20.250
the opioid drug epidemic we're starting
to quantify that because it's having

00:23:20.250 --> 00:23:20.260
to quantify that because it's having
 

00:23:20.260 --> 00:23:22.440
to quantify that because it's having
such a massive impact on society like in

00:23:22.440 --> 00:23:22.450
such a massive impact on society like in
 

00:23:22.450 --> 00:23:23.970
such a massive impact on society like in
West Virginia where I do a great deal of

00:23:23.970 --> 00:23:23.980
West Virginia where I do a great deal of
 

00:23:23.980 --> 00:23:26.130
West Virginia where I do a great deal of
work but we need precisely this

00:23:26.130 --> 00:23:26.140
work but we need precisely this
 

00:23:26.140 --> 00:23:28.049
work but we need precisely this
quantified systematized understanding

00:23:28.049 --> 00:23:28.059
quantified systematized understanding
 

00:23:28.059 --> 00:23:31.049
quantified systematized understanding
for the externalities the ways in which

00:23:31.049 --> 00:23:31.059
for the externalities the ways in which
 

00:23:31.059 --> 00:23:33.870
for the externalities the ways in which
AI changes society so we can show the

00:23:33.870 --> 00:23:33.880
AI changes society so we can show the
 

00:23:33.880 --> 00:23:36.090
AI changes society so we can show the
boundary conditions and the knees and

00:23:36.090 --> 00:23:36.100
boundary conditions and the knees and
 

00:23:36.100 --> 00:23:38.000
boundary conditions and the knees and
the curves where we have to act as a

00:23:38.000 --> 00:23:38.010
the curves where we have to act as a
 

00:23:38.010 --> 00:23:42.690
the curves where we have to act as a
unified whole planet to enforce the

00:23:42.690 --> 00:23:42.700
unified whole planet to enforce the
 

00:23:42.700 --> 00:23:44.340
unified whole planet to enforce the
changes that cause us to stay within a

00:23:44.340 --> 00:23:44.350
changes that cause us to stay within a
 

00:23:44.350 --> 00:23:46.470
changes that cause us to stay within a
regime of controlled is acceptable that

00:23:46.470 --> 00:23:46.480
regime of controlled is acceptable that
 

00:23:46.480 --> 00:23:49.500
regime of controlled is acceptable that
means democracy that means personal

00:23:49.500 --> 00:23:49.510
means democracy that means personal
 

00:23:49.510 --> 00:23:52.580
means democracy that means personal
agency that means personal dignity and

00:23:52.580 --> 00:23:52.590
agency that means personal dignity and
 

00:23:52.590 --> 00:23:57.419
agency that means personal dignity and
my final point is mulready said AI is

00:23:57.419 --> 00:23:57.429
my final point is mulready said AI is
 

00:23:57.429 --> 00:23:59.850
my final point is mulready said AI is
dynamic fundamentally this means if we

00:23:59.850 --> 00:23:59.860
dynamic fundamentally this means if we
 

00:23:59.860 --> 00:24:02.430
dynamic fundamentally this means if we
don't do this if we don't create for AI

00:24:02.430 --> 00:24:02.440
don't do this if we don't create for AI
 

00:24:02.440 --> 00:24:05.220
don't do this if we don't create for AI
the same systematized approach with

00:24:05.220 --> 00:24:05.230
the same systematized approach with
 

00:24:05.230 --> 00:24:06.659
the same systematized approach with
essentially strategic goals as we have

00:24:06.659 --> 00:24:06.669
essentially strategic goals as we have
 

00:24:06.669 --> 00:24:09.570
essentially strategic goals as we have
for climate change we are otherwise

00:24:09.570 --> 00:24:09.580
for climate change we are otherwise
 

00:24:09.580 --> 00:24:11.450
for climate change we are otherwise
basically lobsters in a pod

00:24:11.450 --> 00:24:11.460
basically lobsters in a pod
 

00:24:11.460 --> 00:24:13.970
basically lobsters in a pod
warm water and the water will gradually

00:24:13.970 --> 00:24:13.980
warm water and the water will gradually
 

00:24:13.980 --> 00:24:16.039
warm water and the water will gradually
warm and will accommodate to those

00:24:16.039 --> 00:24:16.049
warm and will accommodate to those
 

00:24:16.049 --> 00:24:18.350
warm and will accommodate to those
changes ever so gradually and we will

00:24:18.350 --> 00:24:18.360
changes ever so gradually and we will
 

00:24:18.360 --> 00:24:20.690
changes ever so gradually and we will
change and by the time the water boils

00:24:20.690 --> 00:24:20.700
change and by the time the water boils
 

00:24:20.700 --> 00:24:22.159
change and by the time the water boils
we'll have changed quite thoroughly and

00:24:22.159 --> 00:24:22.169
we'll have changed quite thoroughly and
 

00:24:22.169 --> 00:24:30.110
we'll have changed quite thoroughly and
quite irreversibly thank you thank you

00:24:30.110 --> 00:24:30.120
quite irreversibly thank you thank you
 

00:24:30.120 --> 00:24:31.610
quite irreversibly thank you thank you
for a great thank you for a great talk

00:24:31.610 --> 00:24:31.620
for a great thank you for a great talk
 

00:24:31.620 --> 00:24:33.500
for a great thank you for a great talk
Gila let's sit down we have a few

00:24:33.500 --> 00:24:33.510
Gila let's sit down we have a few
 

00:24:33.510 --> 00:24:38.120
Gila let's sit down we have a few
minutes here so your talk reminded me of

00:24:38.120 --> 00:24:38.130
minutes here so your talk reminded me of
 

00:24:38.130 --> 00:24:40.250
minutes here so your talk reminded me of
something you said on stage yesterday at

00:24:40.250 --> 00:24:40.260
something you said on stage yesterday at
 

00:24:40.260 --> 00:24:42.740
something you said on stage yesterday at
one point you said that you were

00:24:42.740 --> 00:24:42.750
one point you said that you were
 

00:24:42.750 --> 00:24:44.659
one point you said that you were
convinced that artificial intelligence

00:24:44.659 --> 00:24:44.669
convinced that artificial intelligence
 

00:24:44.669 --> 00:24:47.450
convinced that artificial intelligence
would change our conception of humanity

00:24:47.450 --> 00:24:47.460
would change our conception of humanity
 

00:24:47.460 --> 00:24:49.310
would change our conception of humanity
and I wondered if you could expand on

00:24:49.310 --> 00:24:49.320
and I wondered if you could expand on
 

00:24:49.320 --> 00:24:53.899
and I wondered if you could expand on
that yes I think there's two things that

00:24:53.899 --> 00:24:53.909
that yes I think there's two things that
 

00:24:53.909 --> 00:24:55.700
that yes I think there's two things that
artificial intelligence does to us that

00:24:55.700 --> 00:24:55.710
artificial intelligence does to us that
 

00:24:55.710 --> 00:24:57.980
artificial intelligence does to us that
it's dangerous if it's doing it to us

00:24:57.980 --> 00:24:57.990
it's dangerous if it's doing it to us
 

00:24:57.990 --> 00:25:00.049
it's dangerous if it's doing it to us
and we're not recognizing that first of

00:25:00.049 --> 00:25:00.059
and we're not recognizing that first of
 

00:25:00.059 --> 00:25:03.440
and we're not recognizing that first of
all it changes our sense of what humans

00:25:03.440 --> 00:25:03.450
all it changes our sense of what humans
 

00:25:03.450 --> 00:25:06.590
all it changes our sense of what humans
are unique at and what we derive dignity

00:25:06.590 --> 00:25:06.600
are unique at and what we derive dignity
 

00:25:06.600 --> 00:25:08.230
are unique at and what we derive dignity
from the pleasure of dignity from

00:25:08.230 --> 00:25:08.240
from the pleasure of dignity from
 

00:25:08.240 --> 00:25:10.669
from the pleasure of dignity from
secondly artificial intelligence changes

00:25:10.669 --> 00:25:10.679
secondly artificial intelligence changes
 

00:25:10.679 --> 00:25:12.200
secondly artificial intelligence changes
our sense of what's possible

00:25:12.200 --> 00:25:12.210
our sense of what's possible
 

00:25:12.210 --> 00:25:14.180
our sense of what's possible
you know we're distracted so much by

00:25:14.180 --> 00:25:14.190
you know we're distracted so much by
 

00:25:14.190 --> 00:25:15.889
you know we're distracted so much by
stories of things like immortality and

00:25:15.889 --> 00:25:15.899
stories of things like immortality and
 

00:25:15.899 --> 00:25:18.200
stories of things like immortality and
the singularity precisely because they

00:25:18.200 --> 00:25:18.210
the singularity precisely because they
 

00:25:18.210 --> 00:25:20.180
the singularity precisely because they
redefine our sense of who we might be

00:25:20.180 --> 00:25:20.190
redefine our sense of who we might be
 

00:25:20.190 --> 00:25:24.169
redefine our sense of who we might be
one day I have had CEOs visit me here

00:25:24.169 --> 00:25:24.179
one day I have had CEOs visit me here
 

00:25:24.179 --> 00:25:26.419
one day I have had CEOs visit me here
who've popped a handful of pills during

00:25:26.419 --> 00:25:26.429
who've popped a handful of pills during
 

00:25:26.429 --> 00:25:29.480
who've popped a handful of pills during
lunch at Alibaba and I've jokingly asked

00:25:29.480 --> 00:25:29.490
lunch at Alibaba and I've jokingly asked
 

00:25:29.490 --> 00:25:31.039
lunch at Alibaba and I've jokingly asked
this one gentleman what are you doing

00:25:31.039 --> 00:25:31.049
this one gentleman what are you doing
 

00:25:31.049 --> 00:25:32.180
this one gentleman what are you doing
and he said oh I'm part of this life

00:25:32.180 --> 00:25:32.190
and he said oh I'm part of this life
 

00:25:32.190 --> 00:25:34.340
and he said oh I'm part of this life
extension program for immortality and he

00:25:34.340 --> 00:25:34.350
extension program for immortality and he
 

00:25:34.350 --> 00:25:36.649
extension program for immortality and he
was serious and when I jokingly asked

00:25:36.649 --> 00:25:36.659
was serious and when I jokingly asked
 

00:25:36.659 --> 00:25:37.880
was serious and when I jokingly asked
him so how do you deal with financial

00:25:37.880 --> 00:25:37.890
him so how do you deal with financial
 

00:25:37.890 --> 00:25:41.120
him so how do you deal with financial
planning for that hahaha he gave me the

00:25:41.120 --> 00:25:41.130
planning for that hahaha he gave me the
 

00:25:41.130 --> 00:25:42.680
planning for that hahaha he gave me the
card of his financial planner I said oh

00:25:42.680 --> 00:25:42.690
card of his financial planner I said oh
 

00:25:42.690 --> 00:25:44.389
card of his financial planner I said oh
I have a great guy and he does immortal

00:25:44.389 --> 00:25:44.399
I have a great guy and he does immortal
 

00:25:44.399 --> 00:25:49.460
I have a great guy and he does immortal
planning seriously that's the humanity

00:25:49.460 --> 00:25:49.470
planning seriously that's the humanity
 

00:25:49.470 --> 00:25:51.159
planning seriously that's the humanity
concept he has has completely changed

00:25:51.159 --> 00:25:51.169
concept he has has completely changed
 

00:25:51.169 --> 00:25:55.340
concept he has has completely changed
you know that's not a Bill Gates who

00:25:55.340 --> 00:25:55.350
you know that's not a Bill Gates who
 

00:25:55.350 --> 00:25:57.380
you know that's not a Bill Gates who
wants to think about his legacy in terms

00:25:57.380 --> 00:25:57.390
wants to think about his legacy in terms
 

00:25:57.390 --> 00:25:58.970
wants to think about his legacy in terms
of positive impact on the world that's

00:25:58.970 --> 00:25:58.980
of positive impact on the world that's
 

00:25:58.980 --> 00:26:00.200
of positive impact on the world that's
somebody who believes he's gonna live

00:26:00.200 --> 00:26:00.210
somebody who believes he's gonna live
 

00:26:00.210 --> 00:26:02.299
somebody who believes he's gonna live
forever and that's the world we now live

00:26:02.299 --> 00:26:02.309
forever and that's the world we now live
 

00:26:02.309 --> 00:26:04.310
forever and that's the world we now live
in is with people that have that mindset

00:26:04.310 --> 00:26:04.320
in is with people that have that mindset
 

00:26:04.320 --> 00:26:06.889
in is with people that have that mindset
and have levers of power okay and you

00:26:06.889 --> 00:26:06.899
and have levers of power okay and you
 

00:26:06.899 --> 00:26:08.840
and have levers of power okay and you
have worked with AI and robotics for a

00:26:08.840 --> 00:26:08.850
have worked with AI and robotics for a
 

00:26:08.850 --> 00:26:10.130
have worked with AI and robotics for a
long time and think about the

00:26:10.130 --> 00:26:10.140
long time and think about the
 

00:26:10.140 --> 00:26:11.539
long time and think about the
consequences has that changed your

00:26:11.539 --> 00:26:11.549
consequences has that changed your
 

00:26:11.549 --> 00:26:14.269
consequences has that changed your
understanding of humanity or your sense

00:26:14.269 --> 00:26:14.279
understanding of humanity or your sense
 

00:26:14.279 --> 00:26:16.220
understanding of humanity or your sense
of yourself I'm guessing you don't take

00:26:16.220 --> 00:26:16.230
of yourself I'm guessing you don't take
 

00:26:16.230 --> 00:26:19.519
of yourself I'm guessing you don't take
pills to your ever no I don't I think we

00:26:19.519 --> 00:26:19.529
pills to your ever no I don't I think we
 

00:26:19.529 --> 00:26:20.240
pills to your ever no I don't I think we
need to make room for the next

00:26:20.240 --> 00:26:20.250
need to make room for the next
 

00:26:20.250 --> 00:26:24.919
need to make room for the next
generation in general yes I think my own

00:26:24.919 --> 00:26:24.929
generation in general yes I think my own
 

00:26:24.929 --> 00:26:25.510
generation in general yes I think my own
sense

00:26:25.510 --> 00:26:25.520
sense
 

00:26:25.520 --> 00:26:27.960
sense
self has changed tremendously I think I

00:26:27.960 --> 00:26:27.970
self has changed tremendously I think I
 

00:26:27.970 --> 00:26:34.450
self has changed tremendously I think I
recognize that that we are less good at

00:26:34.450 --> 00:26:34.460
recognize that that we are less good at
 

00:26:34.460 --> 00:26:36.070
recognize that that we are less good at
understanding what we should be doing in

00:26:36.070 --> 00:26:36.080
understanding what we should be doing in
 

00:26:36.080 --> 00:26:38.410
understanding what we should be doing in
the world than we used to then I used to

00:26:38.410 --> 00:26:38.420
the world than we used to then I used to
 

00:26:38.420 --> 00:26:40.180
the world than we used to then I used to
believe I used to believe it was very

00:26:40.180 --> 00:26:40.190
believe I used to believe it was very
 

00:26:40.190 --> 00:26:42.160
believe I used to believe it was very
clear how we should have a quick career

00:26:42.160 --> 00:26:42.170
clear how we should have a quick career
 

00:26:42.170 --> 00:26:43.330
clear how we should have a quick career
and how we should kind of forge a

00:26:43.330 --> 00:26:43.340
and how we should kind of forge a
 

00:26:43.340 --> 00:26:45.970
and how we should kind of forge a
direction and have impact now what I see

00:26:45.970 --> 00:26:45.980
direction and have impact now what I see
 

00:26:45.980 --> 00:26:47.350
direction and have impact now what I see
is a world that's changing around us

00:26:47.350 --> 00:26:47.360
is a world that's changing around us
 

00:26:47.360 --> 00:26:48.870
is a world that's changing around us
quite rapidly and dramatically I

00:26:48.870 --> 00:26:48.880
quite rapidly and dramatically I
 

00:26:48.880 --> 00:26:51.070
quite rapidly and dramatically I
remember 20 30 years ago feeling like

00:26:51.070 --> 00:26:51.080
remember 20 30 years ago feeling like
 

00:26:51.080 --> 00:26:52.110
remember 20 30 years ago feeling like
the world's getting more peaceful

00:26:52.110 --> 00:26:52.120
the world's getting more peaceful
 

00:26:52.120 --> 00:26:54.970
the world's getting more peaceful
polaric polarizations decreasing things

00:26:54.970 --> 00:26:54.980
polaric polarizations decreasing things
 

00:26:54.980 --> 00:26:56.350
polaric polarizations decreasing things
are kind of looking good my kids are

00:26:56.350 --> 00:26:56.360
are kind of looking good my kids are
 

00:26:56.360 --> 00:26:58.390
are kind of looking good my kids are
gonna have a better life than me I don't

00:26:58.390 --> 00:26:58.400
gonna have a better life than me I don't
 

00:26:58.400 --> 00:26:59.950
gonna have a better life than me I don't
really feel that way anymore I feel like

00:26:59.950 --> 00:26:59.960
really feel that way anymore I feel like
 

00:26:59.960 --> 00:27:01.870
really feel that way anymore I feel like
we have a pathway that's rocky and we

00:27:01.870 --> 00:27:01.880
we have a pathway that's rocky and we
 

00:27:01.880 --> 00:27:03.040
we have a pathway that's rocky and we
have to do everything we can to keep

00:27:03.040 --> 00:27:03.050
have to do everything we can to keep
 

00:27:03.050 --> 00:27:04.690
have to do everything we can to keep
ourselves from actually ending up in a

00:27:04.690 --> 00:27:04.700
ourselves from actually ending up in a
 

00:27:04.700 --> 00:27:06.490
ourselves from actually ending up in a
words worse place than we are in today

00:27:06.490 --> 00:27:06.500
words worse place than we are in today
 

00:27:06.500 --> 00:27:09.370
words worse place than we are in today
right okay and you spoke at the end

00:27:09.370 --> 00:27:09.380
right okay and you spoke at the end
 

00:27:09.380 --> 00:27:10.930
right okay and you spoke at the end
there about trying to look to the future

00:27:10.930 --> 00:27:10.940
there about trying to look to the future
 

00:27:10.940 --> 00:27:14.470
there about trying to look to the future
and think about how am i changing what

00:27:14.470 --> 00:27:14.480
and think about how am i changing what
 

00:27:14.480 --> 00:27:16.240
and think about how am i changing what
it's being useful exercise and you

00:27:16.240 --> 00:27:16.250
it's being useful exercise and you
 

00:27:16.250 --> 00:27:18.190
it's being useful exercise and you
indeed write a whole book that kind of

00:27:18.190 --> 00:27:18.200
indeed write a whole book that kind of
 

00:27:18.200 --> 00:27:19.900
indeed write a whole book that kind of
see that approach robot futures in the

00:27:19.900 --> 00:27:19.910
see that approach robot futures in the
 

00:27:19.910 --> 00:27:22.000
see that approach robot futures in the
East chapter you you wrote a little

00:27:22.000 --> 00:27:22.010
East chapter you you wrote a little
 

00:27:22.010 --> 00:27:25.600
East chapter you you wrote a little
fictional skit looking ahead we were

00:27:25.600 --> 00:27:25.610
fictional skit looking ahead we were
 

00:27:25.610 --> 00:27:27.010
fictional skit looking ahead we were
talking about one of those earlier which

00:27:27.010 --> 00:27:27.020
talking about one of those earlier which
 

00:27:27.020 --> 00:27:29.020
talking about one of those earlier which
you title it mediocracy can you just

00:27:29.020 --> 00:27:29.030
you title it mediocracy can you just
 

00:27:29.030 --> 00:27:30.880
you title it mediocracy can you just
introduce us to that yeah there's one

00:27:30.880 --> 00:27:30.890
introduce us to that yeah there's one
 

00:27:30.890 --> 00:27:33.160
introduce us to that yeah there's one
that I called mediocracy the idea behind

00:27:33.160 --> 00:27:33.170
that I called mediocracy the idea behind
 

00:27:33.170 --> 00:27:36.610
that I called mediocracy the idea behind
that title was the story story with this

00:27:36.610 --> 00:27:36.620
that title was the story story with this
 

00:27:36.620 --> 00:27:38.170
that title was the story story with this
idea that a company has an inventory

00:27:38.170 --> 00:27:38.180
idea that a company has an inventory
 

00:27:38.180 --> 00:27:41.470
idea that a company has an inventory
excess inventory of 50,000 green lawn

00:27:41.470 --> 00:27:41.480
excess inventory of 50,000 green lawn
 

00:27:41.480 --> 00:27:43.990
excess inventory of 50,000 green lawn
chairs and the way you deal with that in

00:27:43.990 --> 00:27:44.000
chairs and the way you deal with that in
 

00:27:44.000 --> 00:27:45.850
chairs and the way you deal with that in
this conceptualized future twenty years

00:27:45.850 --> 00:27:45.860
this conceptualized future twenty years
 

00:27:45.860 --> 00:27:48.450
this conceptualized future twenty years
from now I didn't realize it was now is

00:27:48.450 --> 00:27:48.460
from now I didn't realize it was now is
 

00:27:48.460 --> 00:27:50.860
from now I didn't realize it was now is
you run your behavioral analytic system

00:27:50.860 --> 00:27:50.870
you run your behavioral analytic system
 

00:27:50.870 --> 00:27:52.900
you run your behavioral analytic system
create this book marketing copy for

00:27:52.900 --> 00:27:52.910
create this book marketing copy for
 

00:27:52.910 --> 00:27:54.010
create this book marketing copy for
every individual human being on earth

00:27:54.010 --> 00:27:54.020
every individual human being on earth
 

00:27:54.020 --> 00:27:56.110
every individual human being on earth
that maximizes the chance that they want

00:27:56.110 --> 00:27:56.120
that maximizes the chance that they want
 

00:27:56.120 --> 00:27:58.390
that maximizes the chance that they want
to buy a green lawn chair and you

00:27:58.390 --> 00:27:58.400
to buy a green lawn chair and you
 

00:27:58.400 --> 00:28:01.330
to buy a green lawn chair and you
overnight sell your inventory and it's

00:28:01.330 --> 00:28:01.340
overnight sell your inventory and it's
 

00:28:01.340 --> 00:28:02.560
overnight sell your inventory and it's
interesting cuz the tails backing you

00:28:02.560 --> 00:28:02.570
interesting cuz the tails backing you
 

00:28:02.570 --> 00:28:05.530
interesting cuz the tails backing you
the dog you're no longer building and

00:28:05.530 --> 00:28:05.540
the dog you're no longer building and
 

00:28:05.540 --> 00:28:07.480
the dog you're no longer building and
selling product that people need you're

00:28:07.480 --> 00:28:07.490
selling product that people need you're
 

00:28:07.490 --> 00:28:08.920
selling product that people need you're
simply controlling the need of people

00:28:08.920 --> 00:28:08.930
simply controlling the need of people
 

00:28:08.930 --> 00:28:11.440
simply controlling the need of people
with a giant universal remote to make

00:28:11.440 --> 00:28:11.450
with a giant universal remote to make
 

00:28:11.450 --> 00:28:12.730
with a giant universal remote to make
sure they buy whatever you have excess

00:28:12.730 --> 00:28:12.740
sure they buy whatever you have excess
 

00:28:12.740 --> 00:28:14.890
sure they buy whatever you have excess
inventory of and then the point I made

00:28:14.890 --> 00:28:14.900
inventory of and then the point I made
 

00:28:14.900 --> 00:28:18.040
inventory of and then the point I made
was that if we look not just at consumer

00:28:18.040 --> 00:28:18.050
was that if we look not just at consumer
 

00:28:18.050 --> 00:28:20.830
was that if we look not just at consumer
choice but voter choice what happens

00:28:20.830 --> 00:28:20.840
choice but voter choice what happens
 

00:28:20.840 --> 00:28:22.720
choice but voter choice what happens
when people are able to create highly

00:28:22.720 --> 00:28:22.730
when people are able to create highly
 

00:28:22.730 --> 00:28:25.720
when people are able to create highly
bespoke copy for each individual person

00:28:25.720 --> 00:28:25.730
bespoke copy for each individual person
 

00:28:25.730 --> 00:28:27.730
bespoke copy for each individual person
then maximizes the chance they vote for

00:28:27.730 --> 00:28:27.740
then maximizes the chance they vote for
 

00:28:27.740 --> 00:28:28.930
then maximizes the chance they vote for
the candidate who is paying the most

00:28:28.930 --> 00:28:28.940
the candidate who is paying the most
 

00:28:28.940 --> 00:28:31.960
the candidate who is paying the most
money for that marketing well this is

00:28:31.960 --> 00:28:31.970
money for that marketing well this is
 

00:28:31.970 --> 00:28:33.910
money for that marketing well this is
now happening I called it mediocracy

00:28:33.910 --> 00:28:33.920
now happening I called it mediocracy
 

00:28:33.920 --> 00:28:36.490
now happening I called it mediocracy
because at some point personal agency

00:28:36.490 --> 00:28:36.500
because at some point personal agency
 

00:28:36.500 --> 00:28:37.780
because at some point personal agency
has been reduced to the point where it's

00:28:37.780 --> 00:28:37.790
has been reduced to the point where it's
 

00:28:37.790 --> 00:28:38.490
has been reduced to the point where it's
hard

00:28:38.490 --> 00:28:38.500
hard
 

00:28:38.500 --> 00:28:40.560
hard
to any longer call the system democracy

00:28:40.560 --> 00:28:40.570
to any longer call the system democracy
 

00:28:40.570 --> 00:28:42.750
to any longer call the system democracy
it's difficult to use that word with a

00:28:42.750 --> 00:28:42.760
it's difficult to use that word with a
 

00:28:42.760 --> 00:28:44.640
it's difficult to use that word with a
straight face when in fact people's

00:28:44.640 --> 00:28:44.650
straight face when in fact people's
 

00:28:44.650 --> 00:28:47.040
straight face when in fact people's
political choices are not really being

00:28:47.040 --> 00:28:47.050
political choices are not really being
 

00:28:47.050 --> 00:28:48.990
political choices are not really being
controlled directly by their brain but

00:28:48.990 --> 00:28:49.000
controlled directly by their brain but
 

00:28:49.000 --> 00:28:51.510
controlled directly by their brain but
bias system that consists of their brain

00:28:51.510 --> 00:28:51.520
bias system that consists of their brain
 

00:28:51.520 --> 00:28:53.880
bias system that consists of their brain
and very carefully customized marketing

00:28:53.880 --> 00:28:53.890
and very carefully customized marketing
 

00:28:53.890 --> 00:28:55.110
and very carefully customized marketing
copy okay

00:28:55.110 --> 00:28:55.120
copy okay
 

00:28:55.120 --> 00:28:57.930
copy okay
so it's kind of it's an unequal fight

00:28:57.930 --> 00:28:57.940
so it's kind of it's an unequal fight
 

00:28:57.940 --> 00:29:00.360
so it's kind of it's an unequal fight
right you have this big analytic

00:29:00.360 --> 00:29:00.370
right you have this big analytic
 

00:29:00.370 --> 00:29:02.970
right you have this big analytic
machinery working against your you know

00:29:02.970 --> 00:29:02.980
machinery working against your you know
 

00:29:02.980 --> 00:29:06.150
machinery working against your you know
small biological system what what can we

00:29:06.150 --> 00:29:06.160
small biological system what what can we
 

00:29:06.160 --> 00:29:07.770
small biological system what what can we
do about that have you any thoughts

00:29:07.770 --> 00:29:07.780
do about that have you any thoughts
 

00:29:07.780 --> 00:29:09.570
do about that have you any thoughts
about how we can level the playing field

00:29:09.570 --> 00:29:09.580
about how we can level the playing field
 

00:29:09.580 --> 00:29:12.270
about how we can level the playing field
and allow us to continue to be you know

00:29:12.270 --> 00:29:12.280
and allow us to continue to be you know
 

00:29:12.280 --> 00:29:15.180
and allow us to continue to be you know
real actors in in reality I loved

00:29:15.180 --> 00:29:15.190
real actors in in reality I loved
 

00:29:15.190 --> 00:29:17.010
real actors in in reality I loved
Sunday's talks yesterday in his

00:29:17.010 --> 00:29:17.020
Sunday's talks yesterday in his
 

00:29:17.020 --> 00:29:19.920
Sunday's talks yesterday in his
spotlight speech I love the idea of

00:29:19.920 --> 00:29:19.930
spotlight speech I love the idea of
 

00:29:19.930 --> 00:29:21.270
spotlight speech I love the idea of
redress I think actually that's a really

00:29:21.270 --> 00:29:21.280
redress I think actually that's a really
 

00:29:21.280 --> 00:29:24.390
redress I think actually that's a really
important point I think the general data

00:29:24.390 --> 00:29:24.400
important point I think the general data
 

00:29:24.400 --> 00:29:26.790
important point I think the general data
privacy protection regulations that

00:29:26.790 --> 00:29:26.800
privacy protection regulations that
 

00:29:26.800 --> 00:29:28.650
privacy protection regulations that
Europe is putting in place or something

00:29:28.650 --> 00:29:28.660
Europe is putting in place or something
 

00:29:28.660 --> 00:29:30.090
Europe is putting in place or something
we should be emulating in the US I

00:29:30.090 --> 00:29:30.100
we should be emulating in the US I
 

00:29:30.100 --> 00:29:32.910
we should be emulating in the US I
believe we have to create really deep

00:29:32.910 --> 00:29:32.920
believe we have to create really deep
 

00:29:32.920 --> 00:29:35.670
believe we have to create really deep
understanding of the ethics of AI in

00:29:35.670 --> 00:29:35.680
understanding of the ethics of AI in
 

00:29:35.680 --> 00:29:38.100
understanding of the ethics of AI in
humanity basically from lower school

00:29:38.100 --> 00:29:38.110
humanity basically from lower school
 

00:29:38.110 --> 00:29:39.240
humanity basically from lower school
middle school high school all the way

00:29:39.240 --> 00:29:39.250
middle school high school all the way
 

00:29:39.250 --> 00:29:41.160
middle school high school all the way
through college so that the next

00:29:41.160 --> 00:29:41.170
through college so that the next
 

00:29:41.170 --> 00:29:43.320
through college so that the next
generation of engineers politicians and

00:29:43.320 --> 00:29:43.330
generation of engineers politicians and
 

00:29:43.330 --> 00:29:45.420
generation of engineers politicians and
civic leaders actually understand this

00:29:45.420 --> 00:29:45.430
civic leaders actually understand this
 

00:29:45.430 --> 00:29:48.480
civic leaders actually understand this
boundary technology and I think we need

00:29:48.480 --> 00:29:48.490
boundary technology and I think we need
 

00:29:48.490 --> 00:29:50.130
boundary technology and I think we need
disclosure you know the forms we signed

00:29:50.130 --> 00:29:50.140
disclosure you know the forms we signed
 

00:29:50.140 --> 00:29:52.740
disclosure you know the forms we signed
today the opt-ins are complete joke so I

00:29:52.740 --> 00:29:52.750
today the opt-ins are complete joke so I
 

00:29:52.750 --> 00:29:54.090
today the opt-ins are complete joke so I
think we need fundamentally to rethink

00:29:54.090 --> 00:29:54.100
think we need fundamentally to rethink
 

00:29:54.100 --> 00:29:56.310
think we need fundamentally to rethink
how we disclose the ways in which were

00:29:56.310 --> 00:29:56.320
how we disclose the ways in which were
 

00:29:56.320 --> 00:29:58.500
how we disclose the ways in which were
manipulated online the idea that the

00:29:58.500 --> 00:29:58.510
manipulated online the idea that the
 

00:29:58.510 --> 00:29:59.820
manipulated online the idea that the
biggest marketer can get up and actually

00:29:59.820 --> 00:29:59.830
biggest marketer can get up and actually
 

00:29:59.830 --> 00:30:03.450
biggest marketer can get up and actually
talk about dopamine in the in the view

00:30:03.450 --> 00:30:03.460
talk about dopamine in the in the view
 

00:30:03.460 --> 00:30:05.610
talk about dopamine in the in the view
of the public and not feel embarrassed

00:30:05.610 --> 00:30:05.620
of the public and not feel embarrassed
 

00:30:05.620 --> 00:30:07.410
of the public and not feel embarrassed
about doing that is remarkable that's

00:30:07.410 --> 00:30:07.420
about doing that is remarkable that's
 

00:30:07.420 --> 00:30:10.350
about doing that is remarkable that's
drug design it's exactly the same as

00:30:10.350 --> 00:30:10.360
drug design it's exactly the same as
 

00:30:10.360 --> 00:30:12.630
drug design it's exactly the same as
designing drugs for addiction and it's

00:30:12.630 --> 00:30:12.640
designing drugs for addiction and it's
 

00:30:12.640 --> 00:30:14.520
designing drugs for addiction and it's
become okay to talk about that right

00:30:14.520 --> 00:30:14.530
become okay to talk about that right
 

00:30:14.530 --> 00:30:17.070
become okay to talk about that right
okay and and you spoke about this this

00:30:17.070 --> 00:30:17.080
okay and and you spoke about this this
 

00:30:17.080 --> 00:30:19.440
okay and and you spoke about this this
failure of intuition that people tend to

00:30:19.440 --> 00:30:19.450
failure of intuition that people tend to
 

00:30:19.450 --> 00:30:21.360
failure of intuition that people tend to
have for artificial systems you know we

00:30:21.360 --> 00:30:21.370
have for artificial systems you know we
 

00:30:21.370 --> 00:30:22.950
have for artificial systems you know we
have a tendency to anthropomorphize and

00:30:22.950 --> 00:30:22.960
have a tendency to anthropomorphize and
 

00:30:22.960 --> 00:30:27.180
have a tendency to anthropomorphize and
project a little bit do you have an idea

00:30:27.180 --> 00:30:27.190
project a little bit do you have an idea
 

00:30:27.190 --> 00:30:30.180
project a little bit do you have an idea
of how we can change that Tennessee at a

00:30:30.180 --> 00:30:30.190
of how we can change that Tennessee at a
 

00:30:30.190 --> 00:30:33.360
of how we can change that Tennessee at a
large scale like can we maybe we just

00:30:33.360 --> 00:30:33.370
large scale like can we maybe we just
 

00:30:33.370 --> 00:30:35.190
large scale like can we maybe we just
haven't had enough time to learn an

00:30:35.190 --> 00:30:35.200
haven't had enough time to learn an
 

00:30:35.200 --> 00:30:37.680
haven't had enough time to learn an
intuition for how these machines operate

00:30:37.680 --> 00:30:37.690
intuition for how these machines operate
 

00:30:37.690 --> 00:30:40.170
intuition for how these machines operate
or fail as you might I actually think

00:30:40.170 --> 00:30:40.180
or fail as you might I actually think
 

00:30:40.180 --> 00:30:41.880
or fail as you might I actually think
that's something that's on some of you

00:30:41.880 --> 00:30:41.890
that's something that's on some of you
 

00:30:41.890 --> 00:30:43.650
that's something that's on some of you
the journalists and I think you can do

00:30:43.650 --> 00:30:43.660
the journalists and I think you can do
 

00:30:43.660 --> 00:30:45.450
the journalists and I think you can do
an outstanding job of that I believe you

00:30:45.450 --> 00:30:45.460
an outstanding job of that I believe you
 

00:30:45.460 --> 00:30:46.710
an outstanding job of that I believe you
know sometimes I talk and people say

00:30:46.710 --> 00:30:46.720
know sometimes I talk and people say
 

00:30:46.720 --> 00:30:48.150
know sometimes I talk and people say
well we can't make everybody a computer

00:30:48.150 --> 00:30:48.160
well we can't make everybody a computer
 

00:30:48.160 --> 00:30:50.540
well we can't make everybody a computer
scientists I think there's a huge

00:30:50.540 --> 00:30:50.550
scientists I think there's a huge
 

00:30:50.550 --> 00:30:52.880
scientists I think there's a huge
huge area in the middle between making

00:30:52.880 --> 00:30:52.890
huge area in the middle between making
 

00:30:52.890 --> 00:30:54.650
huge area in the middle between making
CBD computer scientists and leaving them

00:30:54.650 --> 00:30:54.660
CBD computer scientists and leaving them
 

00:30:54.660 --> 00:30:56.180
CBD computer scientists and leaving them
illiterate I think there's really

00:30:56.180 --> 00:30:56.190
illiterate I think there's really
 

00:30:56.190 --> 00:30:57.920
illiterate I think there's really
outstanding ways in which you can teach

00:30:57.920 --> 00:30:57.930
outstanding ways in which you can teach
 

00:30:57.930 --> 00:30:59.420
outstanding ways in which you can teach
people the teach people the failings of

00:30:59.420 --> 00:30:59.430
people the teach people the failings of
 

00:30:59.430 --> 00:31:01.520
people the teach people the failings of
these machines show them how the

00:31:01.520 --> 00:31:01.530
these machines show them how the
 

00:31:01.530 --> 00:31:04.130
these machines show them how the
computational bias for instance causes

00:31:04.130 --> 00:31:04.140
computational bias for instance causes
 

00:31:04.140 --> 00:31:06.890
computational bias for instance causes
errors in decision making and we can I

00:31:06.890 --> 00:31:06.900
errors in decision making and we can I
 

00:31:06.900 --> 00:31:09.770
errors in decision making and we can I
think teach a lot that stops far short

00:31:09.770 --> 00:31:09.780
think teach a lot that stops far short
 

00:31:09.780 --> 00:31:11.240
think teach a lot that stops far short
of having to force upon them getting a

00:31:11.240 --> 00:31:11.250
of having to force upon them getting a
 

00:31:11.250 --> 00:31:13.010
of having to force upon them getting a
PhD in the subject right so I think it's

00:31:13.010 --> 00:31:13.020
PhD in the subject right so I think it's
 

00:31:13.020 --> 00:31:15.410
PhD in the subject right so I think it's
education and I think it's investigative

00:31:15.410 --> 00:31:15.420
education and I think it's investigative
 

00:31:15.420 --> 00:31:17.390
education and I think it's investigative
journalism that can do that of course

00:31:17.390 --> 00:31:17.400
journalism that can do that of course
 

00:31:17.400 --> 00:31:19.100
journalism that can do that of course
the irony is we have rapidly falling

00:31:19.100 --> 00:31:19.110
the irony is we have rapidly falling
 

00:31:19.110 --> 00:31:20.870
the irony is we have rapidly falling
funding for investigative journalism so

00:31:20.870 --> 00:31:20.880
funding for investigative journalism so
 

00:31:20.880 --> 00:31:23.450
funding for investigative journalism so
instead we have people who don't get

00:31:23.450 --> 00:31:23.460
instead we have people who don't get
 

00:31:23.460 --> 00:31:25.100
instead we have people who don't get
monetized like the old Huffington Post

00:31:25.100 --> 00:31:25.110
monetized like the old Huffington Post
 

00:31:25.110 --> 00:31:29.600
monetized like the old Huffington Post
writers mmm okay and you also talked

00:31:29.600 --> 00:31:29.610
writers mmm okay and you also talked
 

00:31:29.610 --> 00:31:30.890
writers mmm okay and you also talked
about another failure you talked about

00:31:30.890 --> 00:31:30.900
about another failure you talked about
 

00:31:30.900 --> 00:31:32.590
about another failure you talked about
was this this failure from the Mises

00:31:32.590 --> 00:31:32.600
was this this failure from the Mises
 

00:31:32.600 --> 00:31:35.810
was this this failure from the Mises
field started out trying to do that and

00:31:35.810 --> 00:31:35.820
field started out trying to do that and
 

00:31:35.820 --> 00:31:38.330
field started out trying to do that and
and hasn't managed it can we get back to

00:31:38.330 --> 00:31:38.340
and hasn't managed it can we get back to
 

00:31:38.340 --> 00:31:40.580
and hasn't managed it can we get back to
it do we want to is it something that we

00:31:40.580 --> 00:31:40.590
it do we want to is it something that we
 

00:31:40.590 --> 00:31:43.370
it do we want to is it something that we
should desire it's an interesting

00:31:43.370 --> 00:31:43.380
should desire it's an interesting
 

00:31:43.380 --> 00:31:45.320
should desire it's an interesting
question you know I have colleagues who

00:31:45.320 --> 00:31:45.330
question you know I have colleagues who
 

00:31:45.330 --> 00:31:46.820
question you know I have colleagues who
are trying to make quite literally

00:31:46.820 --> 00:31:46.830
are trying to make quite literally
 

00:31:46.830 --> 00:31:48.560
are trying to make quite literally
babies the idea is if I make an

00:31:48.560 --> 00:31:48.570
babies the idea is if I make an
 

00:31:48.570 --> 00:31:51.040
babies the idea is if I make an
artificial baby then I can raise it and

00:31:51.040 --> 00:31:51.050
artificial baby then I can raise it and
 

00:31:51.050 --> 00:31:54.320
artificial baby then I can raise it and
it'll become human in ethical normative

00:31:54.320 --> 00:31:54.330
it'll become human in ethical normative
 

00:31:54.330 --> 00:31:56.930
it'll become human in ethical normative
behavior there's a whole hypothetical

00:31:56.930 --> 00:31:56.940
behavior there's a whole hypothetical
 

00:31:56.940 --> 00:31:59.870
behavior there's a whole hypothetical
there that people hew toward I don't

00:31:59.870 --> 00:31:59.880
there that people hew toward I don't
 

00:31:59.880 --> 00:32:02.090
there that people hew toward I don't
know in a value judgment sense that we

00:32:02.090 --> 00:32:02.100
know in a value judgment sense that we
 

00:32:02.100 --> 00:32:03.800
know in a value judgment sense that we
need to do mimesis I don't know that we

00:32:03.800 --> 00:32:03.810
need to do mimesis I don't know that we
 

00:32:03.810 --> 00:32:05.570
need to do mimesis I don't know that we
need to replace people one-to-one the

00:32:05.570 --> 00:32:05.580
need to replace people one-to-one the
 

00:32:05.580 --> 00:32:07.130
need to replace people one-to-one the
biological desire to understand how

00:32:07.130 --> 00:32:07.140
biological desire to understand how
 

00:32:07.140 --> 00:32:08.300
biological desire to understand how
humans work is is absolutely

00:32:08.300 --> 00:32:08.310
humans work is is absolutely
 

00:32:08.310 --> 00:32:09.950
humans work is is absolutely
outstandingly important and interesting

00:32:09.950 --> 00:32:09.960
outstandingly important and interesting
 

00:32:09.960 --> 00:32:11.870
outstandingly important and interesting
and we should always go toward that

00:32:11.870 --> 00:32:11.880
and we should always go toward that
 

00:32:11.880 --> 00:32:13.670
and we should always go toward that
cognitive orthotics will benefit from

00:32:13.670 --> 00:32:13.680
cognitive orthotics will benefit from
 

00:32:13.680 --> 00:32:15.800
cognitive orthotics will benefit from
that so our ability to help people have

00:32:15.800 --> 00:32:15.810
that so our ability to help people have
 

00:32:15.810 --> 00:32:18.050
that so our ability to help people have
quality of life as they grow old is

00:32:18.050 --> 00:32:18.060
quality of life as they grow old is
 

00:32:18.060 --> 00:32:19.580
quality of life as they grow old is
going to be directly impacted by our

00:32:19.580 --> 00:32:19.590
going to be directly impacted by our
 

00:32:19.590 --> 00:32:21.920
going to be directly impacted by our
ability to do that it's not so much that

00:32:21.920 --> 00:32:21.930
ability to do that it's not so much that
 

00:32:21.930 --> 00:32:23.870
ability to do that it's not so much that
the fact that hewed away from a basis is

00:32:23.870 --> 00:32:23.880
the fact that hewed away from a basis is
 

00:32:23.880 --> 00:32:28.220
the fact that hewed away from a basis is
bad as it is we have a tendency to

00:32:28.220 --> 00:32:28.230
bad as it is we have a tendency to
 

00:32:28.230 --> 00:32:30.350
bad as it is we have a tendency to
assume that that robot replaces a human

00:32:30.350 --> 00:32:30.360
assume that that robot replaces a human
 

00:32:30.360 --> 00:32:32.630
assume that that robot replaces a human
when in fact it's utterly alien to us

00:32:32.630 --> 00:32:32.640
when in fact it's utterly alien to us
 

00:32:32.640 --> 00:32:35.840
when in fact it's utterly alien to us
and unless we train people to understand

00:32:35.840 --> 00:32:35.850
and unless we train people to understand
 

00:32:35.850 --> 00:32:38.030
and unless we train people to understand
that I don't think they'll ever have the

00:32:38.030 --> 00:32:38.040
that I don't think they'll ever have the
 

00:32:38.040 --> 00:32:41.750
that I don't think they'll ever have the
the skin to accept that okay and we have

00:32:41.750 --> 00:32:41.760
the skin to accept that okay and we have
 

00:32:41.760 --> 00:32:43.520
the skin to accept that okay and we have
time for more question I'm gonna borrow

00:32:43.520 --> 00:32:43.530
time for more question I'm gonna borrow
 

00:32:43.530 --> 00:32:45.200
time for more question I'm gonna borrow
one from you yesterday on this stage you

00:32:45.200 --> 00:32:45.210
one from you yesterday on this stage you
 

00:32:45.210 --> 00:32:46.310
one from you yesterday on this stage you
said that everyone had to answer three

00:32:46.310 --> 00:32:46.320
said that everyone had to answer three
 

00:32:46.320 --> 00:32:48.350
said that everyone had to answer three
questions we have time for just one of

00:32:48.350 --> 00:32:48.360
questions we have time for just one of
 

00:32:48.360 --> 00:32:52.190
questions we have time for just one of
them so one of your questions was think

00:32:52.190 --> 00:32:52.200
them so one of your questions was think
 

00:32:52.200 --> 00:32:53.960
them so one of your questions was think
10 years into the future what is

00:32:53.960 --> 00:32:53.970
10 years into the future what is
 

00:32:53.970 --> 00:32:54.980
10 years into the future what is
something that you were very excited

00:32:54.980 --> 00:32:54.990
something that you were very excited
 

00:32:54.990 --> 00:32:57.530
something that you were very excited
about hey I'm making possible that would

00:32:57.530 --> 00:32:57.540
about hey I'm making possible that would
 

00:32:57.540 --> 00:33:00.170
about hey I'm making possible that would
would improve the world in some way

00:33:00.170 --> 00:33:00.180
would improve the world in some way
 

00:33:00.180 --> 00:33:01.460
would improve the world in some way
maybe you could take us out on a high

00:33:01.460 --> 00:33:01.470
maybe you could take us out on a high
 

00:33:01.470 --> 00:33:07.660
maybe you could take us out on a high
note in here that's a great question so

00:33:07.660 --> 00:33:07.670
 

00:33:07.670 --> 00:33:10.100
actually the quality of life of an

00:33:10.100 --> 00:33:10.110
actually the quality of life of an
 

00:33:10.110 --> 00:33:11.720
actually the quality of life of an
individual human is probably the thing

00:33:11.720 --> 00:33:11.730
individual human is probably the thing
 

00:33:11.730 --> 00:33:13.160
individual human is probably the thing
that I'm most excited about and so when

00:33:13.160 --> 00:33:13.170
that I'm most excited about and so when
 

00:33:13.170 --> 00:33:14.690
that I'm most excited about and so when
I look at everything from exoskeletal

00:33:14.690 --> 00:33:14.700
I look at everything from exoskeletal
 

00:33:14.700 --> 00:33:16.640
I look at everything from exoskeletal
structures that would allow somebody to

00:33:16.640 --> 00:33:16.650
structures that would allow somebody to
 

00:33:16.650 --> 00:33:20.570
structures that would allow somebody to
walk who were they to fall it would be a

00:33:20.570 --> 00:33:20.580
walk who were they to fall it would be a
 

00:33:20.580 --> 00:33:22.340
walk who were they to fall it would be a
huge change in quality of life but if

00:33:22.340 --> 00:33:22.350
huge change in quality of life but if
 

00:33:22.350 --> 00:33:24.200
huge change in quality of life but if
this system allows them to walk use

00:33:24.200 --> 00:33:24.210
this system allows them to walk use
 

00:33:24.210 --> 00:33:26.510
this system allows them to walk use
their musculature and if they start

00:33:26.510 --> 00:33:26.520
their musculature and if they start
 

00:33:26.520 --> 00:33:28.820
their musculature and if they start
falling it catches them you know I love

00:33:28.820 --> 00:33:28.830
falling it catches them you know I love
 

00:33:28.830 --> 00:33:30.470
falling it catches them you know I love
that idea I love the idea of extending

00:33:30.470 --> 00:33:30.480
that idea I love the idea of extending
 

00:33:30.480 --> 00:33:32.210
that idea I love the idea of extending
people's personal sense of agency and

00:33:32.210 --> 00:33:32.220
people's personal sense of agency and
 

00:33:32.220 --> 00:33:34.310
people's personal sense of agency and
empowerment and you can apply that in

00:33:34.310 --> 00:33:34.320
empowerment and you can apply that in
 

00:33:34.320 --> 00:33:35.690
empowerment and you can apply that in
this biological sense of you know

00:33:35.690 --> 00:33:35.700
this biological sense of you know
 

00:33:35.700 --> 00:33:38.570
this biological sense of you know
muscular exoskeletons and you can apply

00:33:38.570 --> 00:33:38.580
muscular exoskeletons and you can apply
 

00:33:38.580 --> 00:33:41.200
muscular exoskeletons and you can apply
this in a core cognitive orthotic sense

00:33:41.200 --> 00:33:41.210
this in a core cognitive orthotic sense
 

00:33:41.210 --> 00:33:44.570
this in a core cognitive orthotic sense
the idea that you can have cognitive

00:33:44.570 --> 00:33:44.580
the idea that you can have cognitive
 

00:33:44.580 --> 00:33:46.550
the idea that you can have cognitive
systems that work with a human not to

00:33:46.550 --> 00:33:46.560
systems that work with a human not to
 

00:33:46.560 --> 00:33:49.040
systems that work with a human not to
replace their thinking but to help them

00:33:49.040 --> 00:33:49.050
replace their thinking but to help them
 

00:33:49.050 --> 00:33:50.960
replace their thinking but to help them
keep thinking even as they're thinking

00:33:50.960 --> 00:33:50.970
keep thinking even as they're thinking
 

00:33:50.970 --> 00:33:53.720
keep thinking even as they're thinking
degrades I think is powerfully important

00:33:53.720 --> 00:33:53.730
degrades I think is powerfully important
 

00:33:53.730 --> 00:33:56.330
degrades I think is powerfully important
to our own ability to age gracefully and

00:33:56.330 --> 00:33:56.340
to our own ability to age gracefully and
 

00:33:56.340 --> 00:33:58.580
to our own ability to age gracefully and
aged well so to me that's the thing

00:33:58.580 --> 00:33:58.590
aged well so to me that's the thing
 

00:33:58.590 --> 00:34:01.100
aged well so to me that's the thing
where I believe those technologies based

00:34:01.100 --> 00:34:01.110
where I believe those technologies based
 

00:34:01.110 --> 00:34:02.360
where I believe those technologies based
on the cognitive side and on the

00:34:02.360 --> 00:34:02.370
on the cognitive side and on the
 

00:34:02.370 --> 00:34:04.880
on the cognitive side and on the
muscular skeletal side actually will

00:34:04.880 --> 00:34:04.890
muscular skeletal side actually will
 

00:34:04.890 --> 00:34:06.500
muscular skeletal side actually will
come of age in the next 10 to 15 years

00:34:06.500 --> 00:34:06.510
come of age in the next 10 to 15 years
 

00:34:06.510 --> 00:34:08.870
come of age in the next 10 to 15 years
and it's a sea change right I could go

00:34:08.870 --> 00:34:08.880
and it's a sea change right I could go
 

00:34:08.880 --> 00:34:10.820
and it's a sea change right I could go
for a walk with my great-grandfather a

00:34:10.820 --> 00:34:10.830
for a walk with my great-grandfather a
 

00:34:10.830 --> 00:34:14.750
for a walk with my great-grandfather a
hike up a trail at Yosemite which would

00:34:14.750 --> 00:34:14.760
hike up a trail at Yosemite which would
 

00:34:14.760 --> 00:34:17.270
hike up a trail at Yosemite which would
be unthinkable today and that I think is

00:34:17.270 --> 00:34:17.280
be unthinkable today and that I think is
 

00:34:17.280 --> 00:34:19.190
be unthinkable today and that I think is
very inspiring wonderful

00:34:19.190 --> 00:34:19.200
very inspiring wonderful
 

00:34:19.200 --> 00:34:20.810
very inspiring wonderful
ok the nice thing about the positive ELA

00:34:20.810 --> 00:34:20.820
ok the nice thing about the positive ELA
 

00:34:20.820 --> 00:34:24.070
ok the nice thing about the positive ELA
thank you so much

00:34:24.070 --> 00:34:24.080
 

00:34:24.080 --> 00:34:30.570
[Applause]

00:34:30.570 --> 00:34:30.580
 

00:34:30.580 --> 00:34:33.849
[Music]

