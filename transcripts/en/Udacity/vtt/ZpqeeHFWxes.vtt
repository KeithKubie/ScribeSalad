WEBVTT
Kind: captions
Language: en

00:00:00.170 --> 00:00:03.150
So let's discuss the performance
of multi-threading and

00:00:03.150 --> 00:00:07.040
how can it be better than simply
running things one at a time.

00:00:07.040 --> 00:00:10.660
So if we have a processor with
no multi-threading support,

00:00:10.660 --> 00:00:13.320
then this is how to threads might run.

00:00:13.320 --> 00:00:16.620
These are cycles going
in this direction, so

00:00:16.620 --> 00:00:19.060
each notch here is a cycle.

00:00:19.060 --> 00:00:22.320
And we have four instructions
that can execute in this cycle.

00:00:22.320 --> 00:00:24.300
So this is what might happen.

00:00:24.300 --> 00:00:30.080
A green thread might be using this,
and this slot in this cycle.

00:00:30.080 --> 00:00:34.220
And the other two issue slots are not
used because the processor has no

00:00:34.220 --> 00:00:37.570
ready instructions to dispatch
to execution in this cycle.

00:00:37.570 --> 00:00:41.630
Let's say there is a data dependence so
next cycle one instruction can wake up.

00:00:42.795 --> 00:00:48.290
And then let's say that in the next
cycle we can have three instructions go,

00:00:48.290 --> 00:00:51.850
but then let's say that all of
the instructions are now waiting for

00:00:51.850 --> 00:00:52.720
something to happen.

00:00:52.720 --> 00:00:56.800
So let's say for a few cycles
we don't get much happening.

00:00:56.800 --> 00:01:00.550
Then, when it happens,
we get to execute, let's say, all four.

00:01:00.550 --> 00:01:03.590
And then maybe another cycle with two,
et cetera.

00:01:03.590 --> 00:01:06.170
So things can be like this, basically.

00:01:06.170 --> 00:01:09.940
Much of the time we
are running with a less than

00:01:09.940 --> 00:01:12.620
fully utilized processor pipeline.

00:01:12.620 --> 00:01:15.880
Let's say that at this point
we get an interrupt, and

00:01:15.880 --> 00:01:19.120
because there is another
thread that is read to run,

00:01:19.120 --> 00:01:22.790
we now get many cycles of
the operating system doing its thing.

00:01:22.790 --> 00:01:25.100
So it's also going to utilize
the pipeline in some way.

00:01:25.100 --> 00:01:30.350
But it spends many cycles basically
figuring out which thread to run next.

00:01:30.350 --> 00:01:34.240
Eventually decides that it's
going to be the blue thread and

00:01:34.240 --> 00:01:38.050
begins executing instructions from
that thread on the processor.

00:01:38.050 --> 00:01:40.810
So this is where we return
from the interrupt and

00:01:40.810 --> 00:01:42.580
start executing a new thread.

00:01:42.580 --> 00:01:45.720
Because let's say we have
these two threads ready to go.

00:01:45.720 --> 00:01:50.480
So the blue thread in a similar
way will be using the processor.

00:01:50.480 --> 00:01:53.660
Partially, let's say it
has a level one miss,

00:01:53.660 --> 00:01:56.170
takes a while to get
the thing from level two.

00:01:56.170 --> 00:01:59.810
Meanwhile, maybe it's able to
do something for a while, but

00:01:59.810 --> 00:02:01.880
eventually runs out of things to do.

00:02:01.880 --> 00:02:06.090
And then for example starts
doing something again, and

00:02:06.090 --> 00:02:08.070
let's say this whole cycle is used.

00:02:08.070 --> 00:02:11.215
So this is what might happen
in a processor with no

00:02:11.215 --> 00:02:12.870
multi-threading support.

00:02:12.870 --> 00:02:17.980
In that case really, the overhead that
you created by having to switch between

00:02:17.980 --> 00:02:22.170
threads, is probably larger than the
gains we are getting from running them.

00:02:22.170 --> 00:02:25.290
We we're better off just running
a single thread that does the work

00:02:25.290 --> 00:02:27.040
of both of these threads.

00:02:27.040 --> 00:02:32.870
So really, a single processor with no
multi-threading Is capable of doing this

00:02:32.870 --> 00:02:36.610
with a good operating system,
not because it's better for

00:02:36.610 --> 00:02:42.090
performance to break work into
multiple threads, but because we want

00:02:42.090 --> 00:02:45.920
to be able to simultaneously run several
applications and make progress in them.

00:02:45.920 --> 00:02:50.130
So that for example if you're playing
games and playing music at the same

00:02:50.130 --> 00:02:53.920
time, we alternate between the game and
the music player.

00:02:53.920 --> 00:02:57.840
Fast enough for you to not be able to
tell that they are really executing one

00:02:57.840 --> 00:02:59.240
at a time on your one core.

00:03:00.990 --> 00:03:04.700
If you have a chip multiprocessor,
we get to do something like this.

00:03:04.700 --> 00:03:09.440
Now we have two cores, each of
which pretty much gets to execute.

00:03:09.440 --> 00:03:13.460
One thread, so it's faster,
of course, than this, and

00:03:13.460 --> 00:03:19.130
we can benefit truly from being able
to write multi-threaded programs.

00:03:19.130 --> 00:03:24.630
But, you have to have two cores for
it, so the cost is about twice.

00:03:24.630 --> 00:03:26.044
The cost of a single core here.

00:03:26.044 --> 00:03:31.610
So with fine-grain multi-threading,
what we have is really one core,

00:03:31.610 --> 00:03:35.860
but with separate sets of registers for
these threads and some scheduling logic.

00:03:35.860 --> 00:03:39.690
With fine-grain multi-threading every
cycle we can switch between threads.

00:03:39.690 --> 00:03:41.810
So what happens is,

00:03:41.810 --> 00:03:45.610
the green thread gets exactly
same behavior in the first cycle.

00:03:45.610 --> 00:03:47.940
In the second cycle we
do the blue thread.

00:03:47.940 --> 00:03:51.580
So we get the behavior of
it's first cycle here.

00:03:51.580 --> 00:03:55.660
Then we do some of the work
from the green thread again.

00:03:55.660 --> 00:03:59.110
Then from the blue thread,
third cycle of the green thread,

00:03:59.110 --> 00:04:01.110
third cycle of the blue thread.

00:04:01.110 --> 00:04:04.350
And now, we would be running the green
thread except that there is nothing

00:04:04.350 --> 00:04:05.490
to run there.

00:04:05.490 --> 00:04:08.720
But what happens is the blue
thread has something to do.

00:04:08.720 --> 00:04:12.020
So we spend another cycle
on the blue thread and

00:04:12.020 --> 00:04:14.540
then the green thread is
still somewhere here.

00:04:14.540 --> 00:04:18.730
There is nothing ready to run but
these operations are going on.

00:04:18.730 --> 00:04:22.200
So the blue thread gets
one more cycle here.

00:04:22.200 --> 00:04:25.480
At this point,
the blue thread has nothing to do, but

00:04:25.480 --> 00:04:28.000
the green one now has something to do.

00:04:28.000 --> 00:04:32.960
So, we end up doing the work of the
green thread and then for another cycle.

00:04:32.960 --> 00:04:37.620
Then let's say neither of the threads
can do something, but then the blue

00:04:37.620 --> 00:04:41.110
thread is able to do this because
it's been three cycles since here.

00:04:43.130 --> 00:04:49.970
And then again, and as you can see,
we get done faster than here because we

00:04:49.970 --> 00:04:53.446
are able to eliminate some of the cycles
where we were not able to do anything.

00:04:53.446 --> 00:04:58.810
So, fine-grain multi-threading
benefits from the fact that when there

00:04:58.810 --> 00:05:03.130
is a long period of idleness in one
thread, for example, due a cache miss,

00:05:03.130 --> 00:05:07.030
you might be able to run still
instructions from the other thread.

00:05:07.030 --> 00:05:09.910
And finally,
let's see what happens in SMT.

00:05:09.910 --> 00:05:10.760
In SMT,

00:05:10.760 --> 00:05:14.630
we are able to mix instructions from
different threads in the same cycle.

00:05:14.630 --> 00:05:17.090
So what we will get is the.

00:05:17.090 --> 00:05:19.250
Green one get's this.

00:05:19.250 --> 00:05:22.480
The blue one also wants to use
the bottom slot, and let's say there

00:05:22.480 --> 00:05:26.250
is a unit there, for example,
the load unit that you have to use here.

00:05:26.250 --> 00:05:30.120
But we can still run
this in the same cycle.

00:05:30.120 --> 00:05:32.970
Next cycle the green thread does this.

00:05:32.970 --> 00:05:36.200
The blue one wants to now do this,
this, and this.

00:05:36.200 --> 00:05:38.280
And we can let's say do this too.

00:05:38.280 --> 00:05:42.280
But let's say there is a dependence from
this to this so we can only do this one.

00:05:42.280 --> 00:05:44.830
Next cycle,
the green thread can do this, and

00:05:44.830 --> 00:05:47.880
from the blue thread we can maybe
do this instruction, or maybe not.

00:05:47.880 --> 00:05:51.400
So let's say we can't because
maybe this one depends also

00:05:51.400 --> 00:05:54.140
on the one that we haven't done,
or the next one.

00:05:54.140 --> 00:05:57.020
Now, however, there is some period
of idleness in the green thread, and

00:05:57.020 --> 00:06:01.160
now the blue thread gets to make up for
missing out on some things, so

00:06:01.160 --> 00:06:05.860
it's able to maybe do this, and
this dependent instruction.

00:06:05.860 --> 00:06:08.610
And, at this point, the green thread
is ready to run something, so

00:06:08.610 --> 00:06:12.120
we can choose whether to run
the green or the blue one.

00:06:12.120 --> 00:06:14.460
Let's say that the green thread
has a higher priority, so

00:06:14.460 --> 00:06:17.610
we always try to do instructions
from the green thread.

00:06:17.610 --> 00:06:20.730
And only fill the gaps
with the blue ones.

00:06:20.730 --> 00:06:22.250
Now we've done this,

00:06:22.250 --> 00:06:26.010
next cycle we still do whatever
we can from the green thread.

00:06:26.010 --> 00:06:27.940
We now can do this.

00:06:27.940 --> 00:06:31.490
And now we only have
the blue thread left to do.

00:06:31.490 --> 00:06:34.050
If the green thread has more
stuff to do, we can do this.

00:06:34.050 --> 00:06:40.850
So as you can see, with SMT,
we get to populate unused slots

00:06:40.850 --> 00:06:45.280
in what would otherwise be a full
speed execution of the green threads.

00:06:45.280 --> 00:06:47.840
So that the blue thread
gets to make progress

00:06:47.840 --> 00:06:50.930
while the green thread really
is not suffering for it.

00:06:50.930 --> 00:06:53.070
And we can do that for
more than just two threads.

00:06:53.070 --> 00:06:55.580
So for
example if we had four threads we might

00:06:55.580 --> 00:06:58.430
be able to actually do another thread.

00:06:58.430 --> 00:07:02.282
At a slightly slower pace than blue
while we are also doing this, so

00:07:02.282 --> 00:07:06.520
with SMT what we are doing,
we are really using underutilized

00:07:06.520 --> 00:07:11.120
issue slots in our out of
order super scaling processor.

00:07:11.120 --> 00:07:14.378
The hardware cost to
do this is very small.

00:07:14.378 --> 00:07:18.050
Our fetch stage needs to be slightly
more complicated to allow us to

00:07:18.050 --> 00:07:19.840
fetch from one or the other PC.

00:07:21.040 --> 00:07:25.080
And a register file needs to be slightly
more complicated because really there

00:07:25.080 --> 00:07:27.830
are now two sets of
architectural registers.

00:07:27.830 --> 00:07:31.060
But other than that the whole
complicated out of order engine

00:07:31.060 --> 00:07:32.390
stays the same.

00:07:32.390 --> 00:07:35.703
So let's say this is going to
cost us something like 5% of

00:07:35.703 --> 00:07:38.850
the cost of a no
multi-threaded processor.

00:07:38.850 --> 00:07:43.550
This here, again after we do
registry naming and everything else,

00:07:43.550 --> 00:07:46.280
the process scheduler
stays just the same.

00:07:46.280 --> 00:07:49.730
We just need to put instructions
from multiple threads

00:07:49.730 --> 00:07:53.210
in the instruction window, so
that they could be scheduled from there.

00:07:53.210 --> 00:07:54.640
And now also when we commit,

00:07:54.640 --> 00:07:57.640
we have to figure out which instruction
belongs to which commit and so

00:07:57.640 --> 00:08:01.830
on, so the cost is slightly larger than
fine grain, but still not very large.

00:08:01.830 --> 00:08:06.850
Because again most of the complicated
preservation stations and

00:08:06.850 --> 00:08:11.350
execution units, and everything else,
stays pretty much unmodified.

00:08:11.350 --> 00:08:15.849
So this is going to have performance
that is maybe very, very close to a CMP.

00:08:17.000 --> 00:08:22.000
Two threads here, two threads here maybe
making almost as much progress, but

00:08:22.000 --> 00:08:24.800
at a very small fraction of this cost.

