WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.402
[MUSIC PLAYING]

00:00:04.687 --> 00:00:05.770
EMILY GLANZ: Hi, everyone.

00:00:05.770 --> 00:00:07.960
Thanks for joining us today.

00:00:07.960 --> 00:00:11.580
I'm Emily, a software engineer
on Google's federated learning

00:00:11.580 --> 00:00:12.175
team.

00:00:12.175 --> 00:00:13.300
DANIEL RAMAGE: And I'm Dan.

00:00:13.300 --> 00:00:15.510
I'm a research scientist
and the team lead.

00:00:15.510 --> 00:00:17.998
We'll be talking to day about
Federated Learning-- machine

00:00:17.998 --> 00:00:19.290
learning on decentralized data.

00:00:22.420 --> 00:00:25.660
The goal of federated learning
is to enable edge devices to do

00:00:25.660 --> 00:00:28.210
state-of-the-art machine
learning without centralizing

00:00:28.210 --> 00:00:32.530
data and with privacy by
default. And, with privacy,

00:00:32.530 --> 00:00:35.920
what we mean is that we have an
aspiration that app developers,

00:00:35.920 --> 00:00:39.070
centralized servers, and
models themselves learn common

00:00:39.070 --> 00:00:40.630
patterns only.

00:00:40.630 --> 00:00:44.550
That's really what
we mean by privacy.

00:00:44.550 --> 00:00:49.230
In today's talk, we'll talk
about decentralized data, what

00:00:49.230 --> 00:00:51.060
it means to work with
decentralized data

00:00:51.060 --> 00:00:52.270
in a centralized fashion.

00:00:52.270 --> 00:00:54.540
That's what we call
federated computation.

00:00:54.540 --> 00:00:58.170
We'll talk a bit about
learning on decentralized data.

00:00:58.170 --> 00:01:00.670
And then we'll give
you an introduction

00:01:00.670 --> 00:01:02.670
to TensorFlow Federated,
which is a way that you

00:01:02.670 --> 00:01:06.360
can experiment with federated
computations in simulation

00:01:06.360 --> 00:01:08.190
today.

00:01:08.190 --> 00:01:11.700
Along the way, we'll introduce
a few privacy principles,

00:01:11.700 --> 00:01:15.090
like ephemeral reports,
and privacy technologies,

00:01:15.090 --> 00:01:18.494
like federated model averaging
that embody those principles.

00:01:22.210 --> 00:01:24.330
All right, let's start
with decentralized data.

00:01:26.982 --> 00:01:29.500
A lot of data is
born at the edge,

00:01:29.500 --> 00:01:33.880
with billions of phones and
IoT devices that generate data.

00:01:33.880 --> 00:01:37.645
That data can enable better
products and smarter models.

00:01:40.260 --> 00:01:42.470
You saw in yesterday's
keynote a lot of ways

00:01:42.470 --> 00:01:44.120
that that data can
be used locally

00:01:44.120 --> 00:01:47.000
at the edge, with
on-device inference,

00:01:47.000 --> 00:01:51.050
such as the automatic captioning
and next generation assistant.

00:01:51.050 --> 00:01:55.400
On-device inference offers
improvements to latency,

00:01:55.400 --> 00:01:59.300
lets things work offline, often
has battery life advantages,

00:01:59.300 --> 00:02:02.390
and can also have some
substantial privacy advantages

00:02:02.390 --> 00:02:04.010
because a server
doesn't need to be

00:02:04.010 --> 00:02:05.660
in the loop for
every interaction you

00:02:05.660 --> 00:02:08.300
have with that
locally-generated data.

00:02:08.300 --> 00:02:10.500
But if you don't have
a server in the loop,

00:02:10.500 --> 00:02:12.770
how do you answer
analytics questions?

00:02:12.770 --> 00:02:16.880
How do you continue to improve
models based on the data

00:02:16.880 --> 00:02:20.300
that those edge devices have?

00:02:20.300 --> 00:02:22.580
That's really what we'll be
looking at in the context

00:02:22.580 --> 00:02:25.280
of federated learning.

00:02:25.280 --> 00:02:27.410
And the app we'll
be focusing on today

00:02:27.410 --> 00:02:30.650
is Gboard, which is
Google's mobile keyboard.

00:02:30.650 --> 00:02:33.110
People don't think much
about their keyboards,

00:02:33.110 --> 00:02:35.480
but they spend hours
on it each day.

00:02:35.480 --> 00:02:39.020
And typing on a mobile
keyboard is 40% slower

00:02:39.020 --> 00:02:40.977
than on a physical one.

00:02:40.977 --> 00:02:42.810
It is easier to share
cute stickers, though.

00:02:46.440 --> 00:02:48.990
Gboard uses
machine-learned models

00:02:48.990 --> 00:02:52.410
for almost every aspect
of the typing experience.

00:02:52.410 --> 00:02:55.260
Tap typing, gesture typing
both depend on models

00:02:55.260 --> 00:02:58.860
because fingers are a little
bit wider than the key targets,

00:02:58.860 --> 00:03:01.470
and you can't just
rely on people hitting

00:03:01.470 --> 00:03:03.420
exactly the right keystrokes.

00:03:03.420 --> 00:03:06.840
Similarly, auto-corrections
and predictions

00:03:06.840 --> 00:03:09.660
are powered by learned
models, as well as voice

00:03:09.660 --> 00:03:13.030
to text and other aspects
of the experience.

00:03:13.030 --> 00:03:15.270
All these models run
on device, of course,

00:03:15.270 --> 00:03:17.400
because your keyboard
needs to be able to work

00:03:17.400 --> 00:03:18.720
offline and quickly.

00:03:22.870 --> 00:03:24.885
For the last few
years, our team has

00:03:24.885 --> 00:03:26.260
been working with
the Gboard team

00:03:26.260 --> 00:03:29.530
to experiment with
decentralized data.

00:03:29.530 --> 00:03:32.740
Gboard aims to be the best and
most privacy forward keyboard

00:03:32.740 --> 00:03:33.830
available.

00:03:33.830 --> 00:03:36.010
And one of the ways that
we're aiming to do that

00:03:36.010 --> 00:03:40.040
is by making use of an on-device
cache of local interactions.

00:03:40.040 --> 00:03:43.360
This would be things like touch
points, type text, context,

00:03:43.360 --> 00:03:44.320
and more.

00:03:44.320 --> 00:03:47.950
This data is used exclusively
for federated learning

00:03:47.950 --> 00:03:49.098
and computation.

00:03:52.990 --> 00:03:53.740
EMILY GLANZ: Cool.

00:03:53.740 --> 00:03:56.890
Let's jump in to
federated computation.

00:03:56.890 --> 00:03:58.790
Federated computation
is basically

00:03:58.790 --> 00:04:02.280
a MapReduce for
decentralized data

00:04:02.280 --> 00:04:04.920
with privacy-preserving
aggregation built in.

00:04:08.370 --> 00:04:10.940
Let's introduce some
of the key concepts

00:04:10.940 --> 00:04:16.730
of federated computations using
a simpler example than Gboard.

00:04:16.730 --> 00:04:18.950
So here we have our clients.

00:04:18.950 --> 00:04:21.320
This is a set of devices--

00:04:21.320 --> 00:04:26.620
some things like cell phones,
or sensors, et cetera.

00:04:26.620 --> 00:04:28.660
Each device has its own data.

00:04:28.660 --> 00:04:31.990
In this case, let's imagine
it's the maximum temperature

00:04:31.990 --> 00:04:35.870
that that device
saw that day, which

00:04:35.870 --> 00:04:38.860
gets us to our first
privacy technology--

00:04:38.860 --> 00:04:41.130
on-device data sets.

00:04:41.130 --> 00:04:43.980
Each device keeps
the raw data local,

00:04:43.980 --> 00:04:47.040
and this comes with
some obligations.

00:04:47.040 --> 00:04:50.040
Each device is responsible
for data asset management

00:04:50.040 --> 00:04:53.490
locally, with things
like expiring old data

00:04:53.490 --> 00:04:56.925
and ensuring that the data is
encrypted when it's not in use.

00:05:00.390 --> 00:05:03.520
So how do we get the
average maximum temperature

00:05:03.520 --> 00:05:04.955
experienced by our devices?

00:05:07.460 --> 00:05:09.590
Let's imagine we
had a way to only

00:05:09.590 --> 00:05:12.770
communicate the average
of all client data items

00:05:12.770 --> 00:05:14.330
to the server.

00:05:14.330 --> 00:05:16.850
Conceptually, we'd like
to compute an aggregate

00:05:16.850 --> 00:05:21.380
over the distributed data in a
secure and private way, which

00:05:21.380 --> 00:05:23.150
we'll build up to
throughout this talk.

00:05:26.210 --> 00:05:28.190
So now let's walk
through an example

00:05:28.190 --> 00:05:31.340
where the engineer wants to
answer a specific question

00:05:31.340 --> 00:05:34.940
of the decentralized data,
like what fraction of users

00:05:34.940 --> 00:05:39.290
saw a daily high over
70 degrees Fahrenheit.

00:05:39.290 --> 00:05:40.960
The first step would
be for the engineer

00:05:40.960 --> 00:05:42.640
to input this threshold
to the server.

00:05:45.190 --> 00:05:47.010
Next, this threshold
would then be

00:05:47.010 --> 00:05:50.190
broadcast to the subset
of available devices

00:05:50.190 --> 00:05:52.170
the server has
chosen to participate

00:05:52.170 --> 00:05:56.620
in this round of
federated computation.

00:05:56.620 --> 00:06:00.210
This threshold is then compared
to the local temperature data

00:06:00.210 --> 00:06:01.920
to compute a value.

00:06:01.920 --> 00:06:04.380
And this is going
to be a 1 or a 0,

00:06:04.380 --> 00:06:06.450
depending on whether the
temperature was greater

00:06:06.450 --> 00:06:09.260
than that threshold.

00:06:09.260 --> 00:06:09.760
Cool.

00:06:09.760 --> 00:06:11.960
So these values would
then be aggregated

00:06:11.960 --> 00:06:14.570
using an aggregation operator.

00:06:14.570 --> 00:06:16.670
In this case, it's
a federated mean,

00:06:16.670 --> 00:06:20.420
which encodes a protocol for
computing the average value

00:06:20.420 --> 00:06:23.620
over the participating devices.

00:06:23.620 --> 00:06:28.000
The server is responsible
for collating device reports

00:06:28.000 --> 00:06:30.827
throughout the round and
emitting this aggregate, which

00:06:30.827 --> 00:06:32.785
contains the answer to
the engineer's question.

00:06:35.470 --> 00:06:39.400
So this demonstrates our
second privacy technology

00:06:39.400 --> 00:06:41.640
of federated aggregation.

00:06:41.640 --> 00:06:45.010
The server is combining
reports from multiple devices

00:06:45.010 --> 00:06:49.150
and only persisting
the aggregate, which

00:06:49.150 --> 00:06:53.440
now leads into our first privacy
principle of only an aggregate.

00:06:53.440 --> 00:06:56.680
Performing that federated
aggregation only

00:06:56.680 --> 00:07:00.040
makes the final aggregate
data, those sums and averages

00:07:00.040 --> 00:07:03.790
over the device reports,
available to the engineer,

00:07:03.790 --> 00:07:06.775
without giving them access to
an individual report itself.

00:07:09.660 --> 00:07:11.720
So this now ties into
our second privacy

00:07:11.720 --> 00:07:14.630
principle of ephemeral reports.

00:07:14.630 --> 00:07:17.330
We don't need to keep
those per-device messages

00:07:17.330 --> 00:07:19.460
after they've been
aggregated, so what

00:07:19.460 --> 00:07:22.290
we collect only stays around
for as long as we need it

00:07:22.290 --> 00:07:23.880
and can be
immediately discarded.

00:07:26.750 --> 00:07:28.730
In practice, what
we've just shown

00:07:28.730 --> 00:07:31.380
is a round of computation.

00:07:31.380 --> 00:07:34.160
This server will repeat
this process multiple times

00:07:34.160 --> 00:07:38.350
to get a better estimate
to the engineer's question.

00:07:38.350 --> 00:07:41.760
It repeats this multiple times
because some devices may not

00:07:41.760 --> 00:07:44.460
be available at the
time of computation

00:07:44.460 --> 00:07:47.300
or some of the devices may have
dropped out during this round.

00:07:51.200 --> 00:07:52.760
DANIEL RAMAGE: So
what's different

00:07:52.760 --> 00:07:57.020
between federated computation
and decentralized computation

00:07:57.020 --> 00:07:59.230
in the data center with
things like MapReduce?

00:07:59.230 --> 00:08:00.860
Federal computation
has challenges

00:08:00.860 --> 00:08:03.320
that go beyond what
we usually experience

00:08:03.320 --> 00:08:05.880
in distributed computation.

00:08:05.880 --> 00:08:09.320
Edge devices like phones tend
to have limited communication

00:08:09.320 --> 00:08:11.060
bandwidth, even when
they're connected

00:08:11.060 --> 00:08:13.540
to a home Wi-Fi network.

00:08:13.540 --> 00:08:16.520
They're also intermittently
available because the devices

00:08:16.520 --> 00:08:20.000
will generally participate only
if they are idle, charging,

00:08:20.000 --> 00:08:22.262
and on an unmetered network.

00:08:22.262 --> 00:08:23.720
And because each
compute node keeps

00:08:23.720 --> 00:08:26.720
the only copy of its
data, the data itself

00:08:26.720 --> 00:08:29.390
has intermittent availability.

00:08:29.390 --> 00:08:31.462
Finally, devices
participate only

00:08:31.462 --> 00:08:33.920
with the user's permission,
depending on an app's policies.

00:08:37.260 --> 00:08:40.700
Another difference is that
in a federated setting,

00:08:40.700 --> 00:08:43.650
it is much more distributed
than a traditional data

00:08:43.650 --> 00:08:45.950
center distributed computation.

00:08:45.950 --> 00:08:48.380
So to give you a sense of
orders of magnitude, usually

00:08:48.380 --> 00:08:49.963
in a data center,
you might be looking

00:08:49.963 --> 00:08:51.770
at thousands or maybe
tens of thousands

00:08:51.770 --> 00:08:55.190
of compute nodes, where
this federated setting might

00:08:55.190 --> 00:08:57.840
have something like a
billion compute nodes.

00:08:57.840 --> 00:08:59.450
Maybe something
like 10 million are

00:08:59.450 --> 00:09:01.280
available at any given time.

00:09:01.280 --> 00:09:02.900
Something like
1,000 are selected

00:09:02.900 --> 00:09:04.280
for a given round
of computation,

00:09:04.280 --> 00:09:06.050
and maybe 50 drop out.

00:09:06.050 --> 00:09:08.330
That's just kind of a
rough sense of the scales

00:09:08.330 --> 00:09:12.360
that we're interested
in supporting.

00:09:12.360 --> 00:09:13.860
And, of course, as
Emily mentioned,

00:09:13.860 --> 00:09:15.780
privacy preserving
aggregation is kind of

00:09:15.780 --> 00:09:17.280
fundamental to the
way that we think

00:09:17.280 --> 00:09:19.850
about federated computation.

00:09:19.850 --> 00:09:22.533
So when you posed this
set of differences,

00:09:22.533 --> 00:09:24.200
what does it actually
look like when you

00:09:24.200 --> 00:09:27.750
run a computation in practice?

00:09:27.750 --> 00:09:30.420
This is a graph of
the round completion

00:09:30.420 --> 00:09:35.730
rate by hour over the course of
three days for a Gboard model

00:09:35.730 --> 00:09:37.830
that was trained in
the United States.

00:09:37.830 --> 00:09:42.540
You see this periodic structure
of peaks and troughs, which

00:09:42.540 --> 00:09:45.965
represent day versus night.

00:09:45.965 --> 00:09:48.090
Because devices are only
participating when they're

00:09:48.090 --> 00:09:49.800
otherwise idle
and charging, this

00:09:49.800 --> 00:09:53.810
represents that the peaks
of down completion rate

00:09:53.810 --> 00:09:55.900
are when more devices
are plugged in,

00:09:55.900 --> 00:09:58.050
which is usually when
they're charging on someone's

00:09:58.050 --> 00:10:00.000
nightstand as they sleep.

00:10:00.000 --> 00:10:02.970
Rounds complete faster when
more devices are available.

00:10:02.970 --> 00:10:04.800
And the device availability
can change over

00:10:04.800 --> 00:10:06.430
the course of the day.

00:10:06.430 --> 00:10:10.620
That, in turn, implies a
dynamic data availability

00:10:10.620 --> 00:10:13.230
because the data itself
might be slightly

00:10:13.230 --> 00:10:16.140
different from the users
who plug in phones at night

00:10:16.140 --> 00:10:18.270
versus the day,
which is something

00:10:18.270 --> 00:10:20.850
that we'll get back to when we
talk about federated learning

00:10:20.850 --> 00:10:24.330
in particular.

00:10:24.330 --> 00:10:27.210
Let's take a more in-depth
example of what a federated

00:10:27.210 --> 00:10:29.850
computation looks like--

00:10:29.850 --> 00:10:34.610
the relative typing frequencies
of common words in Gboard.

00:10:34.610 --> 00:10:38.900
Typing frequencies are actually
useful for improving the Gboard

00:10:38.900 --> 00:10:40.520
experience in a few ways.

00:10:40.520 --> 00:10:43.250
If someone has typed
the letters H-I, "hi"

00:10:43.250 --> 00:10:46.460
is much, much more likely
than "hieroglyphic."

00:10:46.460 --> 00:10:48.620
And so knowing those
relative word frequencies

00:10:48.620 --> 00:10:52.430
allows the Gboard team to
make the product better.

00:10:52.430 --> 00:10:56.950
How would we be compute these
relative typing frequencies

00:10:56.950 --> 00:10:59.180
as a federated computation?

00:10:59.180 --> 00:11:03.870
Instead of the engineers
specifying a single threshold.

00:11:03.870 --> 00:11:05.360
Now, what they
would be specifying

00:11:05.360 --> 00:11:07.340
is something like
a snippet of code

00:11:07.340 --> 00:11:10.750
that's going to be running
on each edge device.

00:11:10.750 --> 00:11:15.460
And in practice, that will often
be something that's actually

00:11:15.460 --> 00:11:18.260
in TensorFlow,
but for here, I've

00:11:18.260 --> 00:11:20.610
written it as
Python X pseudocode.

00:11:20.610 --> 00:11:24.680
So think of that device
data as each device's record

00:11:24.680 --> 00:11:28.910
of what was typed in recent
sessions on the phone.

00:11:28.910 --> 00:11:30.860
So for each word in
that device data,

00:11:30.860 --> 00:11:33.520
if the word is in one of
the common words we're

00:11:33.520 --> 00:11:36.110
trying to count, we'll
increase its count

00:11:36.110 --> 00:11:38.720
when the local device updates.

00:11:38.720 --> 00:11:42.230
That little program is what
would be shipped to the edge

00:11:42.230 --> 00:11:46.100
and run locally to
compute a little map that

00:11:46.100 --> 00:11:50.090
says that perhaps this phone
typed the word "hello" 18 times

00:11:50.090 --> 00:11:53.270
and "world" 0 times.

00:11:53.270 --> 00:11:56.380
That update would then
be encoded as a vector.

00:11:56.380 --> 00:11:58.190
Here, the first
element of the vector

00:11:58.190 --> 00:11:59.840
would represent the
count for "hello"

00:11:59.840 --> 00:12:01.880
and the second one for
the count for "world,"

00:12:01.880 --> 00:12:04.190
which would then be
combined and summed

00:12:04.190 --> 00:12:07.220
using the federated aggregation
operators that Emily mentioned

00:12:07.220 --> 00:12:09.200
before.

00:12:09.200 --> 00:12:12.383
At the server, the engineer
would see the counts

00:12:12.383 --> 00:12:14.800
from all the devices that have
participated in that round,

00:12:14.800 --> 00:12:17.320
not from any single
device, which

00:12:17.320 --> 00:12:19.600
brings up a third
privacy principle

00:12:19.600 --> 00:12:21.430
of focused collection.

00:12:21.430 --> 00:12:23.440
Devices report
only what is needed

00:12:23.440 --> 00:12:25.430
for this specific computation.

00:12:25.430 --> 00:12:27.880
There's a lot more richness
in the on-device data

00:12:27.880 --> 00:12:29.440
set that's not being shared.

00:12:29.440 --> 00:12:31.690
And if the analyst wanted
to ask a different question,

00:12:31.690 --> 00:12:33.670
for example, counting a
different set of words,

00:12:33.670 --> 00:12:35.966
they would run a
different computation.

00:12:39.700 --> 00:12:42.390
This would then repeat
over multiple rounds,

00:12:42.390 --> 00:12:45.060
getting the aggregate counts
higher and higher, which

00:12:45.060 --> 00:12:47.970
in turn would give us
better and better estimates

00:12:47.970 --> 00:12:50.550
of the relative frequencies
of the words typed

00:12:50.550 --> 00:12:51.913
across the population.

00:12:55.685 --> 00:12:56.560
EMILY GLANZ: Awesome.

00:12:56.560 --> 00:12:59.350
Let's talk about our
third privacy technology

00:12:59.350 --> 00:13:01.840
of secure aggregation.

00:13:01.840 --> 00:13:05.050
In the previous example,
we saw how this server only

00:13:05.050 --> 00:13:09.520
needs to emit the sum of
vectors reported by the devices.

00:13:09.520 --> 00:13:12.850
The server could compute this
sum from the device reports

00:13:12.850 --> 00:13:15.610
directly, but we've
been researching ways

00:13:15.610 --> 00:13:18.490
to provide even
stronger guarantees.

00:13:18.490 --> 00:13:22.300
Can we make it so the
server itself cannot inspect

00:13:22.300 --> 00:13:24.250
individual reports?

00:13:24.250 --> 00:13:27.880
That is, how do we enforce
that only in aggregate privacy

00:13:27.880 --> 00:13:33.000
principle we saw from before in
our technical implementation?

00:13:33.000 --> 00:13:35.700
Secure aggregation is
an optional extension

00:13:35.700 --> 00:13:39.210
to the client/server protocol
that embodies this privacy

00:13:39.210 --> 00:13:40.480
principle.

00:13:40.480 --> 00:13:43.540
Here's how it works.

00:13:43.540 --> 00:13:45.780
So this is a simplified
overview that

00:13:45.780 --> 00:13:48.750
demonstrates the key idea
of how a server can compute

00:13:48.750 --> 00:13:51.300
a sum without being
able to decrypt

00:13:51.300 --> 00:13:53.400
the individual messages.

00:13:53.400 --> 00:13:56.610
In practice, handling phones
that have dropped partway

00:13:56.610 --> 00:13:59.460
is also required
by this protocol.

00:13:59.460 --> 00:14:01.550
See the paper for details.

00:14:01.550 --> 00:14:02.050
Awesome.

00:14:02.050 --> 00:14:03.870
So let's jump into this.

00:14:03.870 --> 00:14:06.310
Through coordination
by the server,

00:14:06.310 --> 00:14:10.500
two devices are going to agree
upon a pair of large masks

00:14:10.500 --> 00:14:13.470
that when summed add to 0.

00:14:13.470 --> 00:14:16.230
Each device will add these
masks to their vectors

00:14:16.230 --> 00:14:19.460
before reporting.

00:14:19.460 --> 00:14:21.290
All devices that
are participating

00:14:21.290 --> 00:14:22.700
in this round of
computation will

00:14:22.700 --> 00:14:24.440
exchange these zero-sum pairs.

00:14:28.300 --> 00:14:32.500
Reports will be completely
masked by these values,

00:14:32.500 --> 00:14:35.170
such that we see that
these added pairs now

00:14:35.170 --> 00:14:40.310
make each individual report
themselves look randomized.

00:14:40.310 --> 00:14:43.260
But when aggregated together,
the pairs cancel out,

00:14:43.260 --> 00:14:46.890
and we're left with only
the sum we were looking for.

00:14:46.890 --> 00:14:48.390
In practice, again,
this protocol

00:14:48.390 --> 00:14:50.600
is more complicated
to handle dropout.

00:14:53.910 --> 00:14:57.190
So we showed you what you can
do with federated computation.

00:14:57.190 --> 00:15:00.170
But what about the much more
complex workflows associated

00:15:00.170 --> 00:15:01.170
with federated learning?

00:15:03.830 --> 00:15:05.760
Before we jump into
federated learning,

00:15:05.760 --> 00:15:07.760
let's look at the
typical workflow

00:15:07.760 --> 00:15:10.550
a model engineer who's
performing machine learning

00:15:10.550 --> 00:15:12.170
would go through.

00:15:12.170 --> 00:15:14.910
Typically, they'll have
some data in the cloud

00:15:14.910 --> 00:15:18.290
where they start training and
evaluation jobs, potentially

00:15:18.290 --> 00:15:21.740
in grids to experiment with
different hyperparameters,

00:15:21.740 --> 00:15:24.080
and they'll monitor how well
these different jobs are

00:15:24.080 --> 00:15:25.568
performing.

00:15:25.568 --> 00:15:27.110
They'll end up with
a model that will

00:15:27.110 --> 00:15:29.570
be a good fit for the
distribution of cloud data

00:15:29.570 --> 00:15:32.650
that's available.

00:15:32.650 --> 00:15:34.410
So how does this
workflow translate

00:15:34.410 --> 00:15:36.840
into a federated
learning workflow?

00:15:36.840 --> 00:15:39.330
Well, the model
engineer might still

00:15:39.330 --> 00:15:41.700
have some data in the
cloud, but now this

00:15:41.700 --> 00:15:46.520
is proxy data that's similar
to the on-device data.

00:15:46.520 --> 00:15:50.000
This proxy data might be useful
for training and evaluating

00:15:50.000 --> 00:15:52.400
in advance, but our
main training loop

00:15:52.400 --> 00:15:56.340
is now going to take place
on our decentralized data.

00:15:56.340 --> 00:15:58.700
The model engineer
will still do things

00:15:58.700 --> 00:16:01.700
that are typical of a
machine learning workflow,

00:16:01.700 --> 00:16:05.180
like starting and
stopping tasks, trying out

00:16:05.180 --> 00:16:07.910
different learning rates or
different hyperparameters,

00:16:07.910 --> 00:16:12.510
and monitoring their performance
as training is occurring.

00:16:12.510 --> 00:16:15.980
If the model performs well on
that decentralized data set,

00:16:15.980 --> 00:16:21.480
the model engineer now has
a good release candidate.

00:16:21.480 --> 00:16:23.340
They'll evaluate this
release candidate

00:16:23.340 --> 00:16:26.190
using whatever validation
techniques they typically

00:16:26.190 --> 00:16:29.190
use before deploying to users.

00:16:29.190 --> 00:16:32.025
These are things you can do
with ModelValidator and TFX.

00:16:34.880 --> 00:16:38.420
They'll distribute this final
model for on-device inference

00:16:38.420 --> 00:16:41.870
with TensorFlow Lite
after validation,

00:16:41.870 --> 00:16:45.290
perhaps with a rollout
or A/B testing.

00:16:45.290 --> 00:16:47.240
This deployment
workflow is a step

00:16:47.240 --> 00:16:50.150
that comes after federated
learning once they

00:16:50.150 --> 00:16:52.700
have a model that works well.

00:16:52.700 --> 00:16:54.560
Note that the model
does not continue

00:16:54.560 --> 00:16:57.170
to train after it's been
deployed for inference

00:16:57.170 --> 00:16:59.690
on device unless the
model engineer is

00:16:59.690 --> 00:17:04.220
doing something more advanced,
like on-device personalization.

00:17:04.220 --> 00:17:07.515
So how does this federated
learning part work itself?

00:17:10.450 --> 00:17:12.790
If a device is
idle and charging,

00:17:12.790 --> 00:17:14.680
it will check into the server.

00:17:14.680 --> 00:17:16.720
And most of the time,
it's going to be told

00:17:16.720 --> 00:17:19.790
to go away and come back later.

00:17:19.790 --> 00:17:24.300
But some of the time, the
server will have work to do.

00:17:24.300 --> 00:17:27.569
The initial model as dictated
by the model engineer

00:17:27.569 --> 00:17:30.210
is going to be
sent to the phone.

00:17:30.210 --> 00:17:34.770
For the initial model, usually
0s or a random initialization

00:17:34.770 --> 00:17:36.180
is sufficient.

00:17:36.180 --> 00:17:38.880
Or if they have some of
that relevant proxy data

00:17:38.880 --> 00:17:41.760
in the cloud, they can also
use a pre-trained model.

00:17:44.290 --> 00:17:47.230
The client computes an
update to the model using

00:17:47.230 --> 00:17:49.390
their own local training data.

00:17:49.390 --> 00:17:51.610
Only this update is
then sent to the server

00:17:51.610 --> 00:17:55.990
to be aggregated,
not the raw data.

00:17:55.990 --> 00:17:59.290
Other devices are
participating in this round,

00:17:59.290 --> 00:18:03.410
as well, performing their own
local updates to the model.

00:18:03.410 --> 00:18:06.860
Some of the clients may drop out
before reporting their update,

00:18:06.860 --> 00:18:10.140
but this is OK.

00:18:10.140 --> 00:18:13.710
The server will aggregate
user updates into a new model

00:18:13.710 --> 00:18:16.590
by averaging the model
updates, optionally

00:18:16.590 --> 00:18:19.380
using secure aggregation.

00:18:19.380 --> 00:18:23.460
The updates are ephemeral and
will be discarded after use.

00:18:23.460 --> 00:18:26.280
The engineer will be
monitoring the performance

00:18:26.280 --> 00:18:29.640
of federated training
through metrics

00:18:29.640 --> 00:18:32.005
that are themselves aggregated
along with the model.

00:18:34.550 --> 00:18:36.980
Training rounds will
continue if the engineer is

00:18:36.980 --> 00:18:38.960
happy with model performance.

00:18:38.960 --> 00:18:42.230
A different subset of devices
is chosen by the server

00:18:42.230 --> 00:18:46.220
and given the new
model parameters.

00:18:46.220 --> 00:18:48.670
This is an iterative
process and will continue

00:18:48.670 --> 00:18:52.260
through many training rounds.

00:18:52.260 --> 00:18:56.910
So what we've just described is
our fourth privacy technology

00:18:56.910 --> 00:18:59.490
of federated model averaging.

00:18:59.490 --> 00:19:01.770
Our diagram showed
federated averaging

00:19:01.770 --> 00:19:03.750
as the flavor of
aggregation performed

00:19:03.750 --> 00:19:07.740
by the server for
distributed machine learning.

00:19:07.740 --> 00:19:09.720
Federated averaging
works by computing

00:19:09.720 --> 00:19:13.650
a data-weighted average
of the model updates

00:19:13.650 --> 00:19:18.100
from many steps of gradient
descent on the device.

00:19:18.100 --> 00:19:21.550
Other federization optimization
techniques could be used.

00:19:24.980 --> 00:19:27.100
DANIEL RAMAGE: So
what's different

00:19:27.100 --> 00:19:30.010
between federated learning
and traditional distributed

00:19:30.010 --> 00:19:31.730
learning inside a data center?

00:19:31.730 --> 00:19:33.460
Well, it's all the
differences that we

00:19:33.460 --> 00:19:36.610
saw with federated computation
plus some additional ones that

00:19:36.610 --> 00:19:38.090
are learning specific.

00:19:38.090 --> 00:19:41.710
For example, the data
sets in a data center

00:19:41.710 --> 00:19:43.750
are usually balanced in size.

00:19:43.750 --> 00:19:47.680
Most compute nodes will
have a roughly equal size

00:19:47.680 --> 00:19:49.150
slice of the data.

00:19:49.150 --> 00:19:53.770
In the federated setting, each
device has one users' data,

00:19:53.770 --> 00:19:56.530
and some users might use
Gboard much more than others,

00:19:56.530 --> 00:19:59.960
and therefore those data set
sizes might be very different.

00:19:59.960 --> 00:20:02.500
Similarly, the data in
federated computation

00:20:02.500 --> 00:20:04.340
is very self-correlated.

00:20:04.340 --> 00:20:07.450
It's not a representative
sample of all users' typing.

00:20:07.450 --> 00:20:10.090
Each device has only
one user's data in it.

00:20:10.090 --> 00:20:13.750
And many distributed training
algorithms in the data center

00:20:13.750 --> 00:20:16.420
make an assumption
that every compute node

00:20:16.420 --> 00:20:20.290
gets a representative
sample of the full data set.

00:20:20.290 --> 00:20:23.110
And, third, that variable
data availability

00:20:23.110 --> 00:20:25.790
that I mentioned earlier--

00:20:25.790 --> 00:20:29.050
because the people whose
phones are plugged in at night

00:20:29.050 --> 00:20:31.970
versus plugged in during the
day might actually be different,

00:20:31.970 --> 00:20:35.080
for example, night shift workers
versus day shift workers,

00:20:35.080 --> 00:20:36.790
we might actually
have different kinds

00:20:36.790 --> 00:20:38.623
of data available at
different times of day,

00:20:38.623 --> 00:20:40.540
which is a potential
source of bias when

00:20:40.540 --> 00:20:44.980
we're training federated models
and an active area of research.

00:20:44.980 --> 00:20:49.480
What's exciting is the fact
that federated model averaging

00:20:49.480 --> 00:20:53.020
actually works well for a
variety of state-of-the-art

00:20:53.020 --> 00:20:55.810
models despite
these differences.

00:20:55.810 --> 00:20:58.570
That's an empirical result.
When we started this line

00:20:58.570 --> 00:21:01.570
of research, we didn't know
if that would be true or if it

00:21:01.570 --> 00:21:05.170
would apply widely to the kinds
of state-of-the-art models that

00:21:05.170 --> 00:21:10.000
teams like Gboard are
interested in pursuing.

00:21:10.000 --> 00:21:14.750
The fact that it does work
well in practice is great news.

00:21:14.750 --> 00:21:16.750
So when does federated
learning apply?

00:21:16.750 --> 00:21:19.090
When is it most applicable?

00:21:19.090 --> 00:21:21.280
It's when the
on-device data is more

00:21:21.280 --> 00:21:24.790
relevant than the server-side
proxy data or its privacy

00:21:24.790 --> 00:21:27.700
sensitive or large in ways that
would make it not make sense

00:21:27.700 --> 00:21:28.870
to upload.

00:21:28.870 --> 00:21:31.390
And, importantly,
it works best when

00:21:31.390 --> 00:21:34.360
the labels for your
machine-learned algorithm

00:21:34.360 --> 00:21:38.090
can be inferred naturally
from user interaction.

00:21:38.090 --> 00:21:44.750
So what does that naturally
inferred label look like?

00:21:44.750 --> 00:21:47.440
Let's take a look at some
examples from Gboard.

00:21:47.440 --> 00:21:51.340
Language modeling is one of
the most essential models

00:21:51.340 --> 00:21:54.220
that powers a bunch
of Gboard experiences.

00:21:54.220 --> 00:21:55.780
The key idea in
language modeling

00:21:55.780 --> 00:22:00.760
is to predict the next word
based on typed text so far.

00:22:00.760 --> 00:22:03.443
And this, of course, powers
the prediction strip,

00:22:03.443 --> 00:22:05.860
but it also powers other aspects
of the typing experience.

00:22:05.860 --> 00:22:08.020
Gboard uses the
language model also

00:22:08.020 --> 00:22:11.470
to help understand as you're tap
typing or gesture typing which

00:22:11.470 --> 00:22:14.050
words are more likely.

00:22:14.050 --> 00:22:18.780
The model input in this case
is the type in sequence so far,

00:22:18.780 --> 00:22:22.000
and the output is whatever
word the user had typed next.

00:22:22.000 --> 00:22:23.930
That's what we mean
by self-labeling.

00:22:23.930 --> 00:22:25.420
If you take a
sequence of text, you

00:22:25.420 --> 00:22:30.340
can use every prefix of that
text to predict the next word.

00:22:30.340 --> 00:22:32.830
And so that gives a series
of training examples

00:22:32.830 --> 00:22:35.720
as result of people's natural
use of the keyboard itself.

00:22:39.630 --> 00:22:41.940
The Gboard team ran
dozens of experiments

00:22:41.940 --> 00:22:44.310
in order to replace their
prediction strip language

00:22:44.310 --> 00:22:47.670
model with a new one based on
a more modern recurrent neural

00:22:47.670 --> 00:22:52.410
network architecture, described
in the paper linked below.

00:22:52.410 --> 00:22:56.640
On the left, we see a
server-trained recurrent neural

00:22:56.640 --> 00:22:59.620
network compared to
the old Gboard model,

00:22:59.620 --> 00:23:02.130
and on the right, a
federated model compared

00:23:02.130 --> 00:23:03.510
to that same baseline.

00:23:03.510 --> 00:23:06.040
Now, these two model
architectures are identical.

00:23:06.040 --> 00:23:08.820
The only difference is that one
is trained in the data center

00:23:08.820 --> 00:23:11.700
using the best available
server-side proxy data

00:23:11.700 --> 00:23:15.990
and the other was trained
with federated learning.

00:23:15.990 --> 00:23:19.830
Note that the newer architecture
is better in both cases,

00:23:19.830 --> 00:23:21.480
but the federated
model actually does

00:23:21.480 --> 00:23:24.570
even better than
the server model,

00:23:24.570 --> 00:23:27.660
and that's because the
decentralized data better

00:23:27.660 --> 00:23:30.480
represents what
people actually type.

00:23:30.480 --> 00:23:35.530
On the x-axis here for
the federated model,

00:23:35.530 --> 00:23:37.830
we see the training
round, which is

00:23:37.830 --> 00:23:39.720
how many rounds of
computation did it

00:23:39.720 --> 00:23:43.140
take to hit a given
accuracy on the y-axis?

00:23:43.140 --> 00:23:46.740
And the model tends to converge
after about 1,000 rounds, which

00:23:46.740 --> 00:23:49.890
is something like a
week on wall clock time.

00:23:49.890 --> 00:23:51.930
That's longer than
in the data center,

00:23:51.930 --> 00:23:55.650
where the x-axis
measures the step of SGD,

00:23:55.650 --> 00:23:58.560
where we get to a similar
quality in about a day or two.

00:23:58.560 --> 00:24:00.570
But that week long
time frame is still

00:24:00.570 --> 00:24:02.760
practical for machine
learning engineers

00:24:02.760 --> 00:24:06.780
to do their job because they can
start many models in parallel

00:24:06.780 --> 00:24:08.992
and work productively
in this setting,

00:24:08.992 --> 00:24:10.700
even though it takes
a little bit longer.

00:24:13.660 --> 00:24:16.990
What's the impact of that
relatively small difference?

00:24:16.990 --> 00:24:18.280
It's actually pretty big.

00:24:18.280 --> 00:24:20.070
The next word
prediction accuracy

00:24:20.070 --> 00:24:22.920
improves by 25% relative.

00:24:22.920 --> 00:24:25.740
And it actually
makes the prediction

00:24:25.740 --> 00:24:29.010
strip itself more useful.

00:24:29.010 --> 00:24:30.690
Users click it about 10% more.

00:24:36.023 --> 00:24:38.440
Another example that the Gboard
team has been working with

00:24:38.440 --> 00:24:41.260
is emoji prediction.

00:24:41.260 --> 00:24:44.800
Software keyboards have
a nice emoji interface

00:24:44.800 --> 00:24:46.180
that you can find,
but many users

00:24:46.180 --> 00:24:50.960
don't know to look there
or find it inconvenient.

00:24:50.960 --> 00:24:53.560
And so Gboard has
introduced the ability

00:24:53.560 --> 00:24:56.380
to predict emoji right in line
on the prediction strip, just

00:24:56.380 --> 00:24:57.640
like next words.

00:24:57.640 --> 00:24:59.470
And the federated
model was able to learn

00:24:59.470 --> 00:25:02.380
that the fire emoji is
an appropriate completion

00:25:02.380 --> 00:25:04.720
for this party is lit.

00:25:04.720 --> 00:25:08.020
Now, on the bottom,
you can see a histogram

00:25:08.020 --> 00:25:10.720
of just the overall
frequency of emojis

00:25:10.720 --> 00:25:15.370
that people tend to type, which
has the laugh/cry emoji much

00:25:15.370 --> 00:25:16.370
more represented.

00:25:16.370 --> 00:25:19.360
So this is how you know
that the context really

00:25:19.360 --> 00:25:20.860
matters for emoji.

00:25:20.860 --> 00:25:24.632
We wouldn't want to make that
laugh cry emoji just the one

00:25:24.632 --> 00:25:25.840
that we suggest all the time.

00:25:30.410 --> 00:25:34.970
And this model ends up
with 7% more accurate emoji

00:25:34.970 --> 00:25:36.050
predictions.

00:25:36.050 --> 00:25:40.010
And Gboard users actually click
the prediction strip 4% more.

00:25:40.010 --> 00:25:42.450
And I think, most
importantly, there

00:25:42.450 --> 00:25:45.590
are 11% more users who've
discovered the joy of including

00:25:45.590 --> 00:25:48.440
emoji in their texts, and
untold numbers of users

00:25:48.440 --> 00:25:50.960
who are receiving those
wonderfully emojiful texts.

00:25:54.470 --> 00:25:57.800
So far, we've focused on
the text entry aspects,

00:25:57.800 --> 00:26:00.950
but there are other components
to where federated learning can

00:26:00.950 --> 00:26:04.760
apply, such as action
prediction in the UI itself.

00:26:04.760 --> 00:26:08.150
Gboard isn't really
just used for typing.

00:26:08.150 --> 00:26:11.180
A key feature is
enabling communication.

00:26:11.180 --> 00:26:13.820
So much of what people
type is in messaging apps,

00:26:13.820 --> 00:26:16.220
and those apps can
become more lively

00:26:16.220 --> 00:26:18.260
when you share the perfect GIF.

00:26:18.260 --> 00:26:21.380
So just helping people
discover great GIFs

00:26:21.380 --> 00:26:25.280
to search for and share from
the keyboard at the right times

00:26:25.280 --> 00:26:26.870
without getting
in the way is one

00:26:26.870 --> 00:26:31.270
of Gboard's differentiating
product features.

00:26:31.270 --> 00:26:34.780
This model was
trained to predict

00:26:34.780 --> 00:26:39.130
from the context so far, a
query suggestion for a GIF

00:26:39.130 --> 00:26:42.910
or a sticker, a search or emoji,
and whether that suggestion is

00:26:42.910 --> 00:26:45.390
actually worth showing
to the user at this time.

00:26:50.083 --> 00:26:51.500
An earlier iteration
of this model

00:26:51.500 --> 00:26:55.330
is described at the
paper linked below.

00:26:55.330 --> 00:26:59.320
This model actually
resulted in a 47% reduction

00:26:59.320 --> 00:27:03.760
in unhelpful suggestions,
while simultaneously increasing

00:27:03.760 --> 00:27:06.850
the overall rate of emoji,
GIF and sticker shares

00:27:06.850 --> 00:27:10.567
by being able to better
indicate when a GIF search would

00:27:10.567 --> 00:27:13.150
be appropriate, and that's what
you can see in that animation.

00:27:13.150 --> 00:27:15.067
As someone types "good
night," that little "g"

00:27:15.067 --> 00:27:17.260
turns into a little
GIF icon, which

00:27:17.260 --> 00:27:19.350
indicates that a good
GIF is ready to share.

00:27:25.480 --> 00:27:27.940
One final example that I'd
like to give from Gboard

00:27:27.940 --> 00:27:30.500
is the problem of
discovering new words.

00:27:30.500 --> 00:27:34.720
So what words are people typing
that Gboard doesn't know?

00:27:34.720 --> 00:27:36.460
It can be really
hard to type a word

00:27:36.460 --> 00:27:39.220
that the keyboard doesn't
know because it will often

00:27:39.220 --> 00:27:41.920
auto-correct to something
that it does know.

00:27:41.920 --> 00:27:45.850
And Gboard engineers can use
the top typed unknown words

00:27:45.850 --> 00:27:47.650
to improve the
typing experience.

00:27:47.650 --> 00:27:50.620
They might add new common
words to the dictionary

00:27:50.620 --> 00:27:53.730
in the next model release
after manual review

00:27:53.730 --> 00:27:55.480
or they might find out
what kinds of typos

00:27:55.480 --> 00:27:58.270
are common, suggesting
possible fixes to other aspects

00:27:58.270 --> 00:28:01.070
of the typing experience.

00:28:01.070 --> 00:28:04.820
Here is a sample of words
that people tend to type

00:28:04.820 --> 00:28:06.530
that Gboard doesn't know.

00:28:06.530 --> 00:28:08.330
How did we get
this list of words

00:28:08.330 --> 00:28:10.280
if we're not sharing
the raw data?

00:28:10.280 --> 00:28:13.400
We actually trained
a recurrent network

00:28:13.400 --> 00:28:16.280
to predict the sequence
of characters people

00:28:16.280 --> 00:28:20.360
type when they're typing words
that the keyboard doesn't know.

00:28:20.360 --> 00:28:23.600
And that model, just like the
next word prediction model,

00:28:23.600 --> 00:28:28.490
is able to be used to sample
out letter by letter words.

00:28:28.490 --> 00:28:31.790
We then take that model in the
data center, and we ask it.

00:28:31.790 --> 00:28:33.140
We just generate from it.

00:28:33.140 --> 00:28:35.210
We generate millions
and millions of samples

00:28:35.210 --> 00:28:38.480
from that model that are
representative of words

00:28:38.480 --> 00:28:41.690
that people are typing
out in the wild.

00:28:41.690 --> 00:28:44.080
And if we break these
down a little bit,

00:28:44.080 --> 00:28:45.780
there is a mix of things.

00:28:45.780 --> 00:28:48.410
There's abbreviations,
like "really" and "sorry"

00:28:48.410 --> 00:28:50.030
missing their vowels.

00:28:50.030 --> 00:28:53.840
There's extra letters added
to "hahah" and "ewwww,"

00:28:53.840 --> 00:28:55.430
often for emphasis.

00:28:55.430 --> 00:28:57.950
There are typos that
are common enough

00:28:57.950 --> 00:29:02.480
that they show up even though
Gboard likes to auto-correct

00:29:02.480 --> 00:29:03.700
away from those.

00:29:03.700 --> 00:29:05.210
There are new names.

00:29:05.210 --> 00:29:09.110
And we also see examples of
non-English words being typed

00:29:09.110 --> 00:29:11.900
in an English language keyboard,
which is what this was--

00:29:11.900 --> 00:29:15.230
English in the US was what
this was trained against.

00:29:15.230 --> 00:29:19.100
Those non-English words
actually indicate another way

00:29:19.100 --> 00:29:20.900
that Gboard might improve.

00:29:20.900 --> 00:29:22.640
Gboard has, of
course, an experience

00:29:22.640 --> 00:29:24.590
for typing in
multiple languages.

00:29:24.590 --> 00:29:28.520
And perhaps there's ways that
that multilingual experience

00:29:28.520 --> 00:29:33.650
or switching language more
easily could be improved.

00:29:37.090 --> 00:29:39.940
This also brings us to our
fourth privacy principle,

00:29:39.940 --> 00:29:43.510
which is don't memorize
individuals' data.

00:29:43.510 --> 00:29:47.380
We're careful in this case
to use only models aggregated

00:29:47.380 --> 00:29:50.830
over lots of users and trained
only on out of vocabulary

00:29:50.830 --> 00:29:54.040
words that have a particular
flavor, such as not having

00:29:54.040 --> 00:29:55.330
a sequence of digits.

00:29:55.330 --> 00:30:00.340
We definitely don't
want the model

00:30:00.340 --> 00:30:03.130
we've trained in federated
learning to be able to memorize

00:30:03.130 --> 00:30:05.350
someone's credit card number.

00:30:05.350 --> 00:30:08.470
And we're looking
further at techniques

00:30:08.470 --> 00:30:13.420
that can provide other kinds of
even stronger and more provable

00:30:13.420 --> 00:30:15.640
privacy properties.

00:30:15.640 --> 00:30:18.730
One of those is
differential privacy.

00:30:18.730 --> 00:30:22.950
This is the statistical science
of learning common patterns

00:30:22.950 --> 00:30:26.500
in the data set without
memorizing individual examples.

00:30:26.500 --> 00:30:29.370
This is a field that's been
around for a number of years

00:30:29.370 --> 00:30:33.960
and it is very complementary
to federated learning.

00:30:33.960 --> 00:30:35.850
The main idea is
that when you're

00:30:35.850 --> 00:30:38.910
training a model with federated
learning or in the data center,

00:30:38.910 --> 00:30:43.890
you're going to use
appropriately calibrated noise

00:30:43.890 --> 00:30:48.420
that can obscure an
individual's impact on the model

00:30:48.420 --> 00:30:50.550
that you've learned.

00:30:50.550 --> 00:30:53.640
This is something that
you can experiment

00:30:53.640 --> 00:30:57.510
with a little bit today in the
TensorFlow privacy project,

00:30:57.510 --> 00:31:00.870
which I've linked here, for
more traditional data center

00:31:00.870 --> 00:31:03.150
settings, where you might
have all the data available

00:31:03.150 --> 00:31:08.040
and you'd like to be able to
use an optimizer that adds

00:31:08.040 --> 00:31:10.110
the right kind of noise
to be able to guarantee

00:31:10.110 --> 00:31:13.827
this property, that individual
examples aren't memorized.

00:31:13.827 --> 00:31:16.410
The combination of differential
privacy and federated learning

00:31:16.410 --> 00:31:17.460
is still very fresh.

00:31:17.460 --> 00:31:19.405
Google is working to
bring this to production,

00:31:19.405 --> 00:31:21.030
and so I'm giving
you kind of a preview

00:31:21.030 --> 00:31:24.640
of some of these early results.

00:31:24.640 --> 00:31:27.060
Let me give you a flavor of
how this works with privacy

00:31:27.060 --> 00:31:28.650
technology number five--

00:31:28.650 --> 00:31:30.810
differentially private
model averaging,

00:31:30.810 --> 00:31:34.410
which is described in the
ICLR paper linked here.

00:31:34.410 --> 00:31:38.820
The main idea is that in every
round of federated learning,

00:31:38.820 --> 00:31:42.150
just like what Emily
described for a normal round,

00:31:42.150 --> 00:31:44.070
an initial model will
be sent to the device,

00:31:44.070 --> 00:31:47.452
and that model will be
trained on that device's data.

00:31:47.452 --> 00:31:49.410
But here's where the
first difference comes in.

00:31:49.410 --> 00:31:51.570
Rather than sending
that model update back

00:31:51.570 --> 00:31:55.410
to the server for aggregation,
the device first clips

00:31:55.410 --> 00:31:57.690
the update, which is
to say it makes sure

00:31:57.690 --> 00:32:00.590
that the model update is
limited to a maximum size.

00:32:00.590 --> 00:32:03.510
And by maximum size, we actually
mean in a technical sense

00:32:03.510 --> 00:32:07.830
the L2 ball of in
parameter space.

00:32:07.830 --> 00:32:11.760
Then the server will add noise
when combining the device

00:32:11.760 --> 00:32:13.470
updates for that round.

00:32:13.470 --> 00:32:14.940
How much noise?

00:32:14.940 --> 00:32:17.910
It's noise that's roughly on
the same order of magnitude

00:32:17.910 --> 00:32:22.430
as the maximum size that any
one user is going to send.

00:32:22.430 --> 00:32:26.310
With those two properties
combined and properly tuned,

00:32:26.310 --> 00:32:31.920
it means that any particular
aspect of the updated

00:32:31.920 --> 00:32:35.370
model from that round might
be because some user's

00:32:35.370 --> 00:32:37.710
contribution suggested
that the model go

00:32:37.710 --> 00:32:40.770
that direction or it might be
because of the random noise.

00:32:40.770 --> 00:32:44.340
That gives kind of an
intuitive notion of plausible

00:32:44.340 --> 00:32:47.550
deniability about whether
or not any change was

00:32:47.550 --> 00:32:50.130
due to a user versus the
noise, but it actually

00:32:50.130 --> 00:32:52.920
provides even a more
stronger formal property

00:32:52.920 --> 00:32:57.600
that the model that you learn
with differentially private

00:32:57.600 --> 00:33:00.960
model averaging will be
approximately the same model

00:33:00.960 --> 00:33:04.500
whether or not any
one user was actually

00:33:04.500 --> 00:33:06.120
participating in training.

00:33:06.120 --> 00:33:08.800
And a consequence of
that is that if there

00:33:08.800 --> 00:33:10.470
is something only
one user has typed,

00:33:10.470 --> 00:33:11.680
this model can't learn it.

00:33:15.870 --> 00:33:17.940
We've created a
production system

00:33:17.940 --> 00:33:19.870
for federated computation
here at Google,

00:33:19.870 --> 00:33:24.510
which is what has been used by
the Gboard team in the examples

00:33:24.510 --> 00:33:26.220
that I've talked about today.

00:33:26.220 --> 00:33:28.920
You can learn more
about this in the paper

00:33:28.920 --> 00:33:32.100
we published at SysML this year,
"Towards Federated Learning

00:33:32.100 --> 00:33:32.790
at Scale--

00:33:32.790 --> 00:33:34.390
System Design."

00:33:34.390 --> 00:33:39.340
Now, this system is still
being used internally.

00:33:39.340 --> 00:33:42.685
It's not yet a system that
we expect external developers

00:33:42.685 --> 00:33:44.310
to be able to use,
but that's something

00:33:44.310 --> 00:33:47.622
that we're certainly very
interested in supporting.

00:33:51.465 --> 00:33:52.340
EMILY GLANZ: Awesome.

00:33:52.340 --> 00:33:55.820
We're excited to share our
community projects that

00:33:55.820 --> 00:33:58.220
allows all to develop
the building blocks

00:33:58.220 --> 00:34:00.140
of federated computations.

00:34:00.140 --> 00:34:04.620
And this is
TensorFlow Federated.

00:34:04.620 --> 00:34:11.100
TFF offers two APIs, the
Federated Learning or FL API,

00:34:11.100 --> 00:34:15.239
and the Federated
Core, or FC API.

00:34:15.239 --> 00:34:18.480
The FL API comes
with implementations

00:34:18.480 --> 00:34:21.780
of federated training
and evaluation

00:34:21.780 --> 00:34:25.320
that can be applied to
your existing Keras models

00:34:25.320 --> 00:34:27.630
so you can experiment
with federated learning

00:34:27.630 --> 00:34:29.790
in simulation.

00:34:29.790 --> 00:34:33.900
The FC API allows you to
build your own federated

00:34:33.900 --> 00:34:35.679
computations.

00:34:35.679 --> 00:34:39.989
And TFF also comes with a
local runtime for simulations.

00:34:43.520 --> 00:34:47.179
So, earlier, we showed you
how federated computation

00:34:47.179 --> 00:34:48.800
works conceptually.

00:34:48.800 --> 00:34:52.469
Here's what this
looks like in TFF.

00:34:52.469 --> 00:34:55.710
So we're going to refer
to these sensor readings

00:34:55.710 --> 00:35:00.050
collectively as a
federated value.

00:35:00.050 --> 00:35:05.260
And each federated value has
a type, both the placement--

00:35:05.260 --> 00:35:07.620
so this is at clients--

00:35:07.620 --> 00:35:12.290
and the actual type of the data
items themselves, or a float32.

00:35:15.460 --> 00:35:18.490
The server also has
a federated type.

00:35:18.490 --> 00:35:20.950
And, this time, we've
dropped the curly braces

00:35:20.950 --> 00:35:27.050
to indicate that this is
one value and not many,

00:35:27.050 --> 00:35:30.260
which gets us into our
next concept is distributed

00:35:30.260 --> 00:35:32.840
aggregation protocol that
runs between the clients

00:35:32.840 --> 00:35:34.080
and this server.

00:35:34.080 --> 00:35:37.310
So in this case, it's
the TFF federated mean.

00:35:37.310 --> 00:35:40.070
So this is a federated
operator that you

00:35:40.070 --> 00:35:42.860
can think of as a function,
even though its inputs

00:35:42.860 --> 00:35:46.000
and its outputs live
in different places.

00:35:46.000 --> 00:35:49.300
A federated op represents
an abstract specification

00:35:49.300 --> 00:35:52.540
of a distributed
communication protocol.

00:35:52.540 --> 00:35:56.290
So TFF provides a library
of these federated operators

00:35:56.290 --> 00:35:58.120
that represent the
common building

00:35:58.120 --> 00:36:02.460
types of federated protocols.

00:36:02.460 --> 00:36:06.900
So now I'm going to run through
a brief code example using TFF.

00:36:06.900 --> 00:36:09.000
I'm not going to
go too in-depth,

00:36:09.000 --> 00:36:11.232
so it might look a
little confusing.

00:36:11.232 --> 00:36:12.690
But at the end,
I'm going to put up

00:36:12.690 --> 00:36:16.570
a link to a site that
provides more tutorials,

00:36:16.570 --> 00:36:19.480
and more walkthrough
is of the code.

00:36:19.480 --> 00:36:22.110
So this section of code that
I have highlighted right now

00:36:22.110 --> 00:36:26.320
declares our federated type
that represents our input.

00:36:26.320 --> 00:36:29.080
So you can see we're
defining both the placement,

00:36:29.080 --> 00:36:32.940
so this is at the TFF
clients, and that each data

00:36:32.940 --> 00:36:36.840
item is a tf.float32.

00:36:36.840 --> 00:36:39.030
Next, we're passing
this as an argument

00:36:39.030 --> 00:36:41.940
to this special function
decorator that declares

00:36:41.940 --> 00:36:46.220
this a federated computation.

00:36:46.220 --> 00:36:50.030
And here we're invoking
our federated operator.

00:36:50.030 --> 00:36:53.270
In this case, it's that
tff.federated_mean on those

00:36:53.270 --> 00:36:54.035
sensor readings.

00:36:56.830 --> 00:36:59.020
So now let's jump
back to that example

00:36:59.020 --> 00:37:03.160
where the model engineer had
that specific question of what

00:37:03.160 --> 00:37:05.980
fraction of sensors saw
readings that were greater

00:37:05.980 --> 00:37:07.760
than that certain threshold.

00:37:07.760 --> 00:37:10.190
So this is what that
looks like in TFF.

00:37:10.190 --> 00:37:13.270
Our first federated
operator in this case is

00:37:13.270 --> 00:37:17.320
the tff.federated_broadcast
that's responsible

00:37:17.320 --> 00:37:21.140
for broadcasting that
threshold to the devices.

00:37:21.140 --> 00:37:25.010
Our next federated operator is
the tff.federated_map that you

00:37:25.010 --> 00:37:28.280
can think of as the
map step in MapReduce.

00:37:28.280 --> 00:37:31.040
That gets those 1s
and 0s representing

00:37:31.040 --> 00:37:35.750
whether their local values are
greater than that threshold.

00:37:35.750 --> 00:37:39.410
And, finally, we perform a
federated aggregation so that

00:37:39.410 --> 00:37:42.605
tff.federated_mean, to get
the result back at the server.

00:37:46.530 --> 00:37:49.850
So let's look at
this, again, in code.

00:37:49.850 --> 00:37:52.390
We're, again,
declaring our inputs.

00:37:52.390 --> 00:37:55.280
Let's pretend we've already
declared our readings type

00:37:55.280 --> 00:37:58.860
and now we're also defining
our threshold type.

00:37:58.860 --> 00:38:01.650
This time, it has a
placement at the server,

00:38:01.650 --> 00:38:04.860
and we're indicating that there
is only one value with that

00:38:04.860 --> 00:38:09.250
all_equal=True, and
it's a tf.float32.

00:38:09.250 --> 00:38:11.980
So we're again passing that
into that function decorator

00:38:11.980 --> 00:38:15.520
to declare this a
federated computation.

00:38:15.520 --> 00:38:18.580
We're invoking all those
federated operators

00:38:18.580 --> 00:38:20.360
in the appropriate order.

00:38:20.360 --> 00:38:22.630
So we have that
tff.federated_broadcast

00:38:22.630 --> 00:38:24.940
that's working on the threshold.

00:38:24.940 --> 00:38:27.070
We're performing
our mapping step

00:38:27.070 --> 00:38:31.150
that's taking a computation
I'll talk about in a second

00:38:31.150 --> 00:38:33.250
and applying it to the
readings in that threshold

00:38:33.250 --> 00:38:36.410
that we just broadcast.

00:38:36.410 --> 00:38:38.390
And this chunk of
code represents

00:38:38.390 --> 00:38:41.900
the local computation each
device will be performing,

00:38:41.900 --> 00:38:45.170
where they're comparing their
own data item to the threshold

00:38:45.170 --> 00:38:45.995
that they received.

00:38:48.630 --> 00:38:51.450
So I know that was a
fast brief introduction

00:38:51.450 --> 00:38:53.730
to coding with TFF.

00:38:53.730 --> 00:38:57.420
Please visit this site,
tensorflow.org/federated,

00:38:57.420 --> 00:39:00.100
to get more hands-on
with the code.

00:39:00.100 --> 00:39:03.300
And if you like links,
we have one more link

00:39:03.300 --> 00:39:06.180
to look at all the ideas
we've introduced today

00:39:06.180 --> 00:39:08.490
about federated learning.

00:39:08.490 --> 00:39:14.810
Please check out our comic book
at federated.withgoogle.com.

00:39:14.810 --> 00:39:17.970
We were fortunate enough to work
with two incredibly talented

00:39:17.970 --> 00:39:21.830
comic book artists to illustrate
these comics as graphic art.

00:39:21.830 --> 00:39:22.860
And it even has corgis.

00:39:22.860 --> 00:39:23.652
That's pretty cool.

00:39:27.940 --> 00:39:30.260
DANIEL RAMAGE: All right,
so in today's talk,

00:39:30.260 --> 00:39:34.700
we covered decentralized data,
federated computation, how

00:39:34.700 --> 00:39:38.840
we can use federated computation
building blocks to do learning,

00:39:38.840 --> 00:39:42.110
and gave you a quick
introduction to the TensorFlow

00:39:42.110 --> 00:39:46.970
Federated project, which you
can use to experiment with how

00:39:46.970 --> 00:39:51.050
federated learning might work on
data sets that you have already

00:39:51.050 --> 00:39:55.250
in the server in
simulation today.

00:39:55.250 --> 00:39:57.890
We expect that you
might have seen,

00:39:57.890 --> 00:39:59.600
the TF Lite team
has also announced

00:39:59.600 --> 00:40:01.880
that training is a big
part of their roadmap,

00:40:01.880 --> 00:40:03.800
and that's something
that we are also

00:40:03.800 --> 00:40:06.320
really excited about
for being able to enable

00:40:06.320 --> 00:40:09.260
external developers to
run the kinds of things

00:40:09.260 --> 00:40:13.440
that we're running
internally sometime soon.

00:40:13.440 --> 00:40:16.730
We also introduced privacy
technologies, on-device data

00:40:16.730 --> 00:40:20.055
sets, federated aggregation,
secure aggregation,

00:40:20.055 --> 00:40:22.430
federated model averaging,
and the differentially private

00:40:22.430 --> 00:40:25.820
version of that, which embodies
some privacy principles of only

00:40:25.820 --> 00:40:28.790
an aggregate, ephemeral
reports, focused collection,

00:40:28.790 --> 00:40:31.910
and not memorizing
individuals' data.

00:40:31.910 --> 00:40:35.090
So we hope we've given you a
flavor of the kinds of things

00:40:35.090 --> 00:40:38.210
that federated learning
and computation can do.

00:40:38.210 --> 00:40:41.750
To learn more, check
out the comic book

00:40:41.750 --> 00:40:44.270
and play a little bit
with TensorFlow Federated

00:40:44.270 --> 00:40:47.450
for a preview of how you
can write your own kinds

00:40:47.450 --> 00:40:49.010
of federated computations.

00:40:49.010 --> 00:40:50.030
Thank you very much.

00:40:50.030 --> 00:40:51.230
[APPLAUSE]

00:40:51.230 --> 00:40:54.580
[MUSIC PLAYING]

