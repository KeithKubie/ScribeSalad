WEBVTT
Kind: captions
Language: en

00:00:02.600 --> 00:00:07.040
welcome Russ I'm really glad you
could join us here today thank you thank

00:00:07.040 --> 00:00:12.769
you Andrew so you know today you're the
director of research at Apple and you

00:00:12.769 --> 00:00:17.450
also have a faculty and professor role
at Carnegie Mellon University so I'd love to

00:00:17.450 --> 00:00:22.579
hear a bit about your personal story how
did you end up doing this you know deep

00:00:22.579 --> 00:00:27.619
learning work that you do yeah it's it's
actually does some extent it was I

00:00:27.619 --> 00:00:33.860
started in deploying to some extent by
luck I did my master's degree at Toronto

00:00:33.860 --> 00:00:37.310
and then I took a year off I was
actually working in the financial sector

00:00:37.310 --> 00:00:42.440
it's a bit surprising and at that time I
wasn't quite sure where they want to go

00:00:42.440 --> 00:00:46.070
for my PhD or not and then something
happened something surprising happened I

00:00:46.070 --> 00:00:52.700
was going to work one morning and I bump
into Jack Hinton and Jeff told me hey I

00:00:52.700 --> 00:00:57.410
have this terrific idea come to my
office I'll show you and so we basically

00:00:57.410 --> 00:01:02.000
work together and he started telling me
about you know these Boltzmann machines

00:01:02.000 --> 00:01:06.770
and contrastive divergence and some of
some of the tricks which I didn't at

00:01:06.770 --> 00:01:11.570
that time quite understand what he was
talking about but that really really

00:01:11.570 --> 00:01:16.190
excited that was very exciting and
really excited me and then basically

00:01:16.190 --> 00:01:23.180
within three months I started my PhD
with Jeff so so that was that was kind

00:01:23.180 --> 00:01:29.479
of like the beginning because that was
back in 2005-2006 and this is where you

00:01:29.479 --> 00:01:33.500
know some of the regional deploying
algorithms using restrictive Boltzmann

00:01:33.500 --> 00:01:38.900
and supervised spec training were kind
of popping up and so you know that's

00:01:38.900 --> 00:01:43.880
that's how I started it was really you
know that one particular morning when I

00:01:43.880 --> 00:01:49.400
bumped into Jeff completely changed my
my future career moving forward and then

00:01:49.400 --> 00:01:54.380
in fact you were a co-author on you know
one of the very early papers on

00:01:54.380 --> 00:01:58.070
restricted Boltzmann machines there
really helped with this resurgence of

00:01:58.070 --> 00:02:02.390
neural networks and deep learning tell
me a bit more what that was like you're

00:02:02.390 --> 00:02:06.920
working on that seven oh yeah this was
this was actually a really this was

00:02:06.920 --> 00:02:12.040
exciting year I was a first year it was
my first year as a PhD student and

00:02:12.040 --> 00:02:17.390
Jeff and I we're trying to explore these
ideas of using restricted Boltzmann's

00:02:17.390 --> 00:02:23.030
and and using pre-training tricks to
train multiple layers and specifically

00:02:23.030 --> 00:02:26.990
we will try to focus on autoencoders you
know how do we do an only an extension

00:02:26.990 --> 00:02:32.120
of PCA effectively and it was very
exciting because we've got these systems

00:02:32.120 --> 00:02:37.040
to work on em these digits which was
exciting but then the next steps for us

00:02:37.040 --> 00:02:42.020
were to really see whether we can extend
these models to dealing with phases so

00:02:42.020 --> 00:02:46.430
remember we had this automated phases
data set and then we started looking at

00:02:46.430 --> 00:02:49.820
can we do compression for document so we
started looking in all these different

00:02:49.820 --> 00:02:58.100
data you know real-valued count binary
and throughout you know a year it was I

00:02:58.100 --> 00:03:04.570
was a first-year PhD students it was a
big learning experience for me but and

00:03:04.570 --> 00:03:09.710
really within six or seven months we
were able to get really interesting

00:03:09.710 --> 00:03:12.680
results and really good results
something that we you know we were able

00:03:12.680 --> 00:03:16.040
to train these very deep autoencoders
this is something that you couldn't do

00:03:16.040 --> 00:03:22.550
at that time using sort of traditional
optimization techniques and then it's

00:03:22.550 --> 00:03:28.420
you know it turns out it's a really
really exciting paper for us that was

00:03:28.420 --> 00:03:34.160
that was super exciting year because it
was a lot of learning for me but at the

00:03:34.160 --> 00:03:39.830
same time the results turn out to be you
know really really impressive for what

00:03:39.830 --> 00:03:44.750
we were trying to do so in the early
days of this resurgence of deep learning

00:03:44.750 --> 00:03:49.640
or a lot of the activity was centered on
restricted Boltzmann machines and then

00:03:49.640 --> 00:03:54.769
people see machines as a there's still a
lot of exciting research they're being

00:03:54.769 --> 00:03:59.720
done including some in your group but
what's happening with both machines yeah

00:03:59.720 --> 00:04:04.550
that's it that's a very good question I
think that in the early days the way

00:04:04.550 --> 00:04:08.450
that we were using restricted Boltzmann
machines is you sort of can imagine

00:04:08.450 --> 00:04:12.050
training a stack of these restricted
both machines that would allow you to

00:04:12.050 --> 00:04:16.580
learn effectively one layer at a time
and there's a good theory behind you

00:04:16.580 --> 00:04:19.489
know when you add a particular layer it
improves the variation bound and so

00:04:19.489 --> 00:04:23.479
forth under certain conditions so there
was a theoretical justification and

00:04:23.479 --> 00:04:26.840
these models were working
well in terms of being able to

00:04:26.840 --> 00:04:32.960
pre-trained these systems and then
around 2009/2010 once the computer

00:04:32.960 --> 00:04:38.990
started showing up you know GPUs then a
lot of us started realizing that

00:04:38.990 --> 00:04:45.070
actually directly optimizing these deep
neural networks was you know was giving

00:04:45.070 --> 00:04:49.460
similar results or even better results
so just standard back problems out the

00:04:49.460 --> 00:04:52.550
pre-training or restricted Boltzmann
machine that's right that's right

00:04:52.550 --> 00:04:56.210
and that's sort of over you know three
or four years and it was exciting to the

00:04:56.210 --> 00:04:58.850
whole community because people thought
that wow you can actually train these

00:04:58.850 --> 00:05:04.669
deep models using these pre training
mechanisms and then you know with more

00:05:04.669 --> 00:05:07.789
compute people start realizing that you
can just basically do standard back

00:05:07.789 --> 00:05:12.830
propagation something that we couldn't
do back in 2005 or you know 2004 because

00:05:12.830 --> 00:05:19.930
it would take us months to do it on CPUs
and so that was that was a big change

00:05:19.930 --> 00:05:24.530
the other thing that I think that we
haven't really figured out what to do

00:05:24.530 --> 00:05:28.520
with you know both machines and deep
Boltzmann machines I believe they're

00:05:28.520 --> 00:05:32.090
very powerful models because you can
think of them as generative models you

00:05:32.090 --> 00:05:36.349
know they try to model complex
distributions in the data but when we

00:05:36.349 --> 00:05:40.490
start looking at learning algorithms
learning algorithms right now they

00:05:40.490 --> 00:05:44.210
require using you know Markov chain
Monte Carlo in variational learning and

00:05:44.210 --> 00:05:51.380
such which is not a scalable as back
propagation algorithm so so we get have

00:05:51.380 --> 00:05:56.449
to figure out more efficient ways of
training these models and also the use

00:05:56.449 --> 00:06:02.479
of convolution it's something that's
fairly difficult to integrate into these

00:06:02.479 --> 00:06:07.610
models I remember some of your work on
on using provost ik max pooling for sort

00:06:07.610 --> 00:06:13.970
of building these generative models of
different objects and using these ideas

00:06:13.970 --> 00:06:17.750
of convolution was also very very
exciting but at the same time it's still

00:06:17.750 --> 00:06:22.070
extremely hard to train these models so
it's unlikely Israel yes how much these

00:06:22.070 --> 00:06:28.190
work right and so we still have to
figure out water I on the on the other

00:06:28.190 --> 00:06:31.669
side some of the recent work using
variational encoders for example which

00:06:31.669 --> 00:06:36.110
could be viewed as directed versions of
Boltzmann machines we have figured out a

00:06:36.110 --> 00:06:40.640
ways of of training these models was a
work by Maxwell and in there there

00:06:40.640 --> 00:06:45.979
Kingma on using you know we pair with
relation tricks and now we can use back

00:06:45.979 --> 00:06:51.050
propagation algorithm within the
stochastic system which is which is

00:06:51.050 --> 00:06:55.340
driving a lot of progress right now but
we haven't quite figured out how to do

00:06:55.340 --> 00:07:00.500
that in in the case of Boltzmann machine
so so that's a very interesting

00:07:00.500 --> 00:07:04.550
perspective I actually wasn't aware of
which was in an earlier era where

00:07:04.550 --> 00:07:09.979
computers were slower that the RPM you
know the pre-training was really

00:07:09.979 --> 00:07:15.620
important as only fast the computation
that that drove switching to standing

00:07:15.620 --> 00:07:19.849
back from you know in terms of the
evolution of the community is thinking

00:07:19.849 --> 00:07:23.210
in deep learning another topic I know
you spent a lot of time thinking about

00:07:23.210 --> 00:07:29.510
this the generative unsupervised versus
supervised approaches do share bit about

00:07:29.510 --> 00:07:33.320
how you're thinking about that has
evolved over time yeah I think that's a

00:07:33.320 --> 00:07:38.450
that's a really I feel like it's a very
important topic particularly if we think

00:07:38.450 --> 00:07:44.719
about unsupervised or semi-supervised or
generative generative models because to

00:07:44.719 --> 00:07:48.469
some extent a lot of successes that
we've seen there recently is due to

00:07:48.469 --> 00:07:53.750
supervised learning and back in the
early days unsupervised learning was was

00:07:53.750 --> 00:07:57.110
primarily viewed as unsupervised pre
training because we didn't know how to

00:07:57.110 --> 00:08:03.349
train these multi-layer systems and even
today if you're working in a settings

00:08:03.349 --> 00:08:06.950
where you have lots and lots of
unlabeled data and a small fraction of

00:08:06.950 --> 00:08:10.070
labeled examples you know these
unsupervised pre training models so

00:08:10.070 --> 00:08:15.830
building these generative models can
help you know for for supervised die so

00:08:15.830 --> 00:08:20.210
I think that a lot of us in the
community you know it's kind of less it

00:08:20.210 --> 00:08:24.260
was the belief when I started doing my
PhD was all about generative models and

00:08:24.260 --> 00:08:28.490
try to learn these stacks of ball
because that was the only way for us to

00:08:28.490 --> 00:08:35.570
train these systems today there is a lot
of work right now on generative modeling

00:08:35.570 --> 00:08:38.150
you know if you look at generative
adversarial Network

00:08:38.150 --> 00:08:41.839
if you look at variation within quarters
the energy models is something that my

00:08:41.839 --> 00:08:47.540
lab is working on right now as well I
think it's it's very exciting research

00:08:47.540 --> 00:08:52.400
but we haven't perhaps we haven't quite
figured it out again for many of you who

00:08:52.400 --> 00:08:56.300
are thinking about getting in the
deploying field this is one area that's

00:08:56.300 --> 00:09:00.440
I think we you know will make a lot of
progress and hopefully in the near

00:09:00.440 --> 00:09:03.830
future so unsupervised early
unsupervised learning right head laying

00:09:03.830 --> 00:09:06.560
oh maybe you can think of it as
unsupervised learning or semi-supervised

00:09:06.560 --> 00:09:13.580
learning where you have I give you some
hints or some examples of what what

00:09:13.580 --> 00:09:18.529
different things mean and I throw you
lots and lots of unlabeled data so you

00:09:18.529 --> 00:09:22.130
know thank you very important insight
that in an earlier era of deep learning

00:09:22.130 --> 00:09:26.089
where computers just slower the
restricted Boltzmann machine and deep

00:09:26.089 --> 00:09:29.720
Boltzmann stream that was needed for
initializing the neural network weights

00:09:29.720 --> 00:09:33.820
but as computers got faster straight
backprop then start to work much better

00:09:33.820 --> 00:09:37.700
so you know one of the topic that I know
you've spent a lot of time thinking

00:09:37.700 --> 00:09:43.880
about is the supervised learning versus
generative models unsupervised learning

00:09:43.880 --> 00:09:50.060
approaches so how has your tell me a bit
about how you're thinking on that debate

00:09:50.060 --> 00:09:55.880
has evolved over time I think that we
all believe that we should be able to to

00:09:55.880 --> 00:10:00.380
make progress there it's just it's just
you know you know all the work on

00:10:00.380 --> 00:10:04.760
Boltzmann machines variational t
encoders yes you can think a lot of

00:10:04.760 --> 00:10:10.370
these models as generative models but we
haven't quite figured out you know how

00:10:10.370 --> 00:10:16.730
to you know really make them work and
how can you make use of logic almost and

00:10:16.730 --> 00:10:23.870
even if even for I see a lot of an IT
sector you know companies have lots and

00:10:23.870 --> 00:10:26.630
lots of data
lots of unlabeled data there's a lots of

00:10:26.630 --> 00:10:32.360
efforts for going through annotations
because that's the only way for us to to

00:10:32.360 --> 00:10:36.470
make progress right now and it seems
like you know we should be able to make

00:10:36.470 --> 00:10:40.220
use of unlabeled data because it's you
know it's just abundance of it and and

00:10:40.220 --> 00:10:45.820
we haven't quite figured out how to do
yet so you mentioned for people wanting

00:10:45.820 --> 00:10:49.950
to enter deep learning research you know
unsupervised learning the exciting area

00:10:49.950 --> 00:10:54.519
today there are a lot of people wanting
to enter a deep learning either research

00:10:54.519 --> 00:10:59.500
or applied work so for this global
community either researcher of my work

00:10:59.500 --> 00:11:04.899
what advice would you have yes I think
that one of one of the key advisors I

00:11:04.899 --> 00:11:11.500
think I should give is people entering
that field I would encourage them to

00:11:11.500 --> 00:11:16.600
just try different things and not be
afraid to try new things and not be

00:11:16.600 --> 00:11:21.190
afraid to try to innovate I can give you
one example which is when I was a

00:11:21.190 --> 00:11:25.600
graduate student you know we were
looking at neural nets and he's a highly

00:11:25.600 --> 00:11:30.610
non convex systems that are hard to
optimize and I remember talking to my

00:11:30.610 --> 00:11:35.410
friends with in the optimization
community and the feedback was always

00:11:35.410 --> 00:11:39.700
that well there is no way you can solve
these problems because these are non

00:11:39.700 --> 00:11:44.740
convex we don't understand optimization
how could you ever even do that you know

00:11:44.740 --> 00:11:49.770
compared to doing comics optimization
and it was surprising because in our lab

00:11:49.770 --> 00:11:55.029
you know we never really cared that much
about those specific problems we just

00:11:55.029 --> 00:11:58.870
were thinking about how can we optimize
and whether we can get interesting

00:11:58.870 --> 00:12:04.360
results and that effectively was driving
the community so we're not were you know

00:12:04.360 --> 00:12:09.070
we were we were not scared maybe to some
extent because we didn't maybe because

00:12:09.070 --> 00:12:13.959
we were lacking actually the theory
behind optimization but but I would

00:12:13.959 --> 00:12:18.700
encourage people to just try and not be
afraid to try to tackle hard problems

00:12:18.700 --> 00:12:23.110
yeah and I remember you once said don't
learn to code just into high level you

00:12:23.110 --> 00:12:26.320
know deep learning frameworks but
actually understand yes that's right I

00:12:26.320 --> 00:12:29.410
think that bolon it's one of the things
that I try to do it when I teach you

00:12:29.410 --> 00:12:34.240
deep learning class is is is one of the
for one of the homeworks I'm asking

00:12:34.240 --> 00:12:37.959
people to actually code backpropagation
algorithm for convolutional neural

00:12:37.959 --> 00:12:43.959
networks and it's you know it's painful
but but at the same time if you do it

00:12:43.959 --> 00:12:49.870
once you really understand how these
systems operate and how they work and

00:12:49.870 --> 00:12:53.740
how you can efficiently implement them
on on on GPU and I think it's it's

00:12:53.740 --> 00:12:58.019
important for
you too when you go into research or

00:12:58.019 --> 00:13:01.529
industry you have a really good
understanding of what these systems are

00:13:01.529 --> 00:13:07.019
doing so it's it's important I think you
know since you have both academic

00:13:07.019 --> 00:13:11.459
experience that's professor and
corporate experience I'm curious if

00:13:11.459 --> 00:13:15.899
someone's sensitive learning what are
their pros and cons of doing a PhD

00:13:15.899 --> 00:13:20.519
versus joining a company yeah I think
that's that's actually a very good

00:13:20.519 --> 00:13:26.670
question in my particular lab I have a
mix of students some students want to go

00:13:26.670 --> 00:13:31.589
and take an academic route some students
want to go and take an industry route

00:13:31.589 --> 00:13:37.980
and it's it's becoming very challenging
because you can do amazing research in

00:13:37.980 --> 00:13:42.360
industry and and you can also do amazing
research in academia but in terms of

00:13:42.360 --> 00:13:50.490
pros and cons in academia I feel like
you have more freedom to work on long

00:13:50.490 --> 00:13:56.639
term problems or if you think about some
crazy problem you can work on it so you

00:13:56.639 --> 00:14:01.679
have a little bit more more freedom at
the same time the research that you're

00:14:01.679 --> 00:14:07.410
doing industry is also very exciting
because in many cases you can with your

00:14:07.410 --> 00:14:13.199
research you can impact millions of
users if you develop you know a core AI

00:14:13.199 --> 00:14:18.899
technology and and obviously within the
industry you have much more resources in

00:14:18.899 --> 00:14:26.550
terms of compute and be able to you know
do really amazing things so there are

00:14:26.550 --> 00:14:30.509
pluses and minuses that it really
depends on on what you want to do and

00:14:30.509 --> 00:14:35.309
right now it's interesting very
interesting environment where academics

00:14:35.309 --> 00:14:39.959
move to industry and then you know focus
on industry move to academia but not as

00:14:39.959 --> 00:14:45.959
much and so it's it's you know it's it's
it's a very it's very exciting times it

00:14:45.959 --> 00:14:49.230
sounds like your academic machine
learning is great and corporate machine

00:14:49.230 --> 00:14:53.100
learning is great and the most important
thing is just jumping right either one

00:14:53.100 --> 00:14:56.549
just jump in so it really depends on
your own your preferences because you

00:14:56.549 --> 00:15:00.790
can do amazing research in either place
so you've mentioned

00:15:00.790 --> 00:15:04.930
supervised learning as one exciting
frontier for research are there other

00:15:04.930 --> 00:15:09.400
areas that you consider exciting
frontiers for research yeah absolutely I

00:15:09.400 --> 00:15:13.150
think that what I see now community
right now in particularly deep learning

00:15:13.150 --> 00:15:19.330
community is there are a few trends one
particular area that I think is really

00:15:19.330 --> 00:15:24.490
exciting is the area of deep
reinforcement learning because we were

00:15:24.490 --> 00:15:29.530
able to figure out how we can train Ages
in virtual worlds and this is something

00:15:29.530 --> 00:15:34.120
that's in just the last couple of years
you see a lot a lot of progress of how

00:15:34.120 --> 00:15:37.870
can we scale these systems how can we
develop new algorithms how can we get

00:15:37.870 --> 00:15:43.090
ages to communicate to each other with
each other and and it's I think that

00:15:43.090 --> 00:15:47.470
that area is and generally the the
settings where you're interacting with

00:15:47.470 --> 00:15:55.270
the environment is super exciting the
other area that I think is really

00:15:55.270 --> 00:15:58.960
exciting as well is the area of
reasoning and natural language

00:15:58.960 --> 00:16:05.200
understanding so can we build dialogue
based systems can we build systems that

00:16:05.200 --> 00:16:11.230
can reason that can read text and be
able to you know answer questions

00:16:11.230 --> 00:16:16.090
intelligently I think this is something
that a lot of research is is focusing on

00:16:16.090 --> 00:16:23.170
right now and then there's not a sort of
sub-aerial so is this area of being able

00:16:23.170 --> 00:16:27.820
to learn from fewer examples so
typically you know people think of it as

00:16:27.820 --> 00:16:35.530
one short learning or transfer learning
a setting where you know you you learn

00:16:35.530 --> 00:16:39.610
something about the world and I throw
you a new task at you and you can solve

00:16:39.610 --> 00:16:44.140
this task very quickly much like humans
do without requiring lots and lots of

00:16:44.140 --> 00:16:49.240
labeled examples and so this is
something that's a lot of us in the

00:16:49.240 --> 00:16:53.650
community are trying to figure out how
we can how we can do that and how can we

00:16:53.650 --> 00:16:58.270
have come closer to human-like
human-like learning abilities Thank You

00:16:58.270 --> 00:17:01.810
Russ for sharing all the comments and
inside so there's especially if you say

00:17:01.810 --> 00:17:07.270
hearing the story of your early days
dude thanks Andrea yeah thanks for

00:17:07.270 --> 00:17:09.720
having me

