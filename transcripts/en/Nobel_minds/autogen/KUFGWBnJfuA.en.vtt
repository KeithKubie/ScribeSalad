WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:01.850
so just in case you thought we haven't

00:00:01.850 --> 00:00:01.860
so just in case you thought we haven't
 

00:00:01.860 --> 00:00:03.619
so just in case you thought we haven't
been ambitious enough in our coverage so

00:00:03.619 --> 00:00:03.629
been ambitious enough in our coverage so
 

00:00:03.629 --> 00:00:05.210
been ambitious enough in our coverage so
far we're going to end the morning with

00:00:05.210 --> 00:00:05.220
far we're going to end the morning with
 

00:00:05.220 --> 00:00:07.010
far we're going to end the morning with
the discussion on the question of how

00:00:07.010 --> 00:00:07.020
the discussion on the question of how
 

00:00:07.020 --> 00:00:12.950
the discussion on the question of how
will a I change the world so to moderate

00:00:12.950 --> 00:00:12.960
will a I change the world so to moderate
 

00:00:12.960 --> 00:00:16.609
will a I change the world so to moderate
that we have the brave Lila Janna who is

00:00:16.609 --> 00:00:16.619
that we have the brave Lila Janna who is
 

00:00:16.619 --> 00:00:21.019
that we have the brave Lila Janna who is
the founder of samasource and I'd like

00:00:21.019 --> 00:00:21.029
the founder of samasource and I'd like
 

00:00:21.029 --> 00:00:22.310
the founder of samasource and I'd like
to introduce her and her panelists

00:00:22.310 --> 00:00:22.320
to introduce her and her panelists
 

00:00:22.320 --> 00:00:31.669
to introduce her and her panelists
please so we have Joel macchia who's an

00:00:31.669 --> 00:00:31.679
please so we have Joel macchia who's an
 

00:00:31.679 --> 00:00:33.530
please so we have Joel macchia who's an
economic historian from Northwestern

00:00:33.530 --> 00:00:33.540
economic historian from Northwestern
 

00:00:33.540 --> 00:00:36.080
economic historian from Northwestern
University Jewell Raziq who is the

00:00:36.080 --> 00:00:36.090
University Jewell Raziq who is the
 

00:00:36.090 --> 00:00:37.190
University Jewell Raziq who is the
president of the International

00:00:37.190 --> 00:00:37.200
president of the International
 

00:00:37.200 --> 00:00:39.470
president of the International
Association of universities we have

00:00:39.470 --> 00:00:39.480
Association of universities we have
 

00:00:39.480 --> 00:00:41.330
Association of universities we have
Cynthia Brazell from the MIT Media Lab

00:00:41.330 --> 00:00:41.340
Cynthia Brazell from the MIT Media Lab
 

00:00:41.340 --> 00:00:44.779
Cynthia Brazell from the MIT Media Lab
and also the founder of Gebo Inc social

00:00:44.779 --> 00:00:44.789
and also the founder of Gebo Inc social
 

00:00:44.789 --> 00:00:46.819
and also the founder of Gebo Inc social
robotics company and Michael Leavitt

00:00:46.819 --> 00:00:46.829
robotics company and Michael Leavitt
 

00:00:46.829 --> 00:00:49.279
robotics company and Michael Leavitt
who's the 2013 Nobel laureate in

00:00:49.279 --> 00:00:49.289
who's the 2013 Nobel laureate in
 

00:00:49.289 --> 00:00:52.160
who's the 2013 Nobel laureate in
chemistry from Stanford University

00:00:52.160 --> 00:00:52.170
chemistry from Stanford University
 

00:00:52.170 --> 00:00:59.900
chemistry from Stanford University
I recognize that we're the panel just

00:00:59.900 --> 00:00:59.910
I recognize that we're the panel just
 

00:00:59.910 --> 00:01:01.310
I recognize that we're the panel just
before lunch so we're going to try to

00:01:01.310 --> 00:01:01.320
before lunch so we're going to try to
 

00:01:01.320 --> 00:01:03.110
before lunch so we're going to try to
keep this very lively and interesting

00:01:03.110 --> 00:01:03.120
keep this very lively and interesting
 

00:01:03.120 --> 00:01:06.080
keep this very lively and interesting
and make it a conversation most of the

00:01:06.080 --> 00:01:06.090
and make it a conversation most of the
 

00:01:06.090 --> 00:01:08.570
and make it a conversation most of the
discussion around AI focuses on how it

00:01:08.570 --> 00:01:08.580
discussion around AI focuses on how it
 

00:01:08.580 --> 00:01:10.810
discussion around AI focuses on how it
pushes the boundary on innovation and

00:01:10.810 --> 00:01:10.820
pushes the boundary on innovation and
 

00:01:10.820 --> 00:01:12.649
pushes the boundary on innovation and
technological progress

00:01:12.649 --> 00:01:12.659
technological progress
 

00:01:12.659 --> 00:01:15.380
technological progress
I would love us to talk about how it

00:01:15.380 --> 00:01:15.390
I would love us to talk about how it
 

00:01:15.390 --> 00:01:17.090
I would love us to talk about how it
affects people living at the bottom of

00:01:17.090 --> 00:01:17.100
affects people living at the bottom of
 

00:01:17.100 --> 00:01:18.770
affects people living at the bottom of
the pyramid people who are not wearing

00:01:18.770 --> 00:01:18.780
the pyramid people who are not wearing
 

00:01:18.780 --> 00:01:20.690
the pyramid people who are not wearing
Apple watches people who are not working

00:01:20.690 --> 00:01:20.700
Apple watches people who are not working
 

00:01:20.700 --> 00:01:22.789
Apple watches people who are not working
for unicorns in places like Silicon

00:01:22.789 --> 00:01:22.799
for unicorns in places like Silicon
 

00:01:22.799 --> 00:01:25.490
for unicorns in places like Silicon
Valley or Sweden let's talk about how

00:01:25.490 --> 00:01:25.500
Valley or Sweden let's talk about how
 

00:01:25.500 --> 00:01:28.580
Valley or Sweden let's talk about how
these advances will impact them and

00:01:28.580 --> 00:01:28.590
these advances will impact them and
 

00:01:28.590 --> 00:01:29.810
these advances will impact them and
Michael let's start with you and I

00:01:29.810 --> 00:01:29.820
Michael let's start with you and I
 

00:01:29.820 --> 00:01:31.640
Michael let's start with you and I
apologize in advance we're going to try

00:01:31.640 --> 00:01:31.650
apologize in advance we're going to try
 

00:01:31.650 --> 00:01:34.249
apologize in advance we're going to try
to keep our remarks to a minute or so so

00:01:34.249 --> 00:01:34.259
to keep our remarks to a minute or so so
 

00:01:34.259 --> 00:01:35.810
to keep our remarks to a minute or so so
I apologize in advance for possibly

00:01:35.810 --> 00:01:35.820
I apologize in advance for possibly
 

00:01:35.820 --> 00:01:38.270
I apologize in advance for possibly
interrupting a Nobel laureate so in

00:01:38.270 --> 00:01:38.280
interrupting a Nobel laureate so in
 

00:01:38.280 --> 00:01:40.310
interrupting a Nobel laureate so in
keeping with the likeness I wanted to

00:01:40.310 --> 00:01:40.320
keeping with the likeness I wanted to
 

00:01:40.320 --> 00:01:42.020
keeping with the likeness I wanted to
start with a joke I heard recently from

00:01:42.020 --> 00:01:42.030
start with a joke I heard recently from
 

00:01:42.030 --> 00:01:44.690
start with a joke I heard recently from
my daughter-in-law this is a list for

00:01:44.690 --> 00:01:44.700
my daughter-in-law this is a list for
 

00:01:44.700 --> 00:01:46.639
my daughter-in-law this is a list for
the school trip which could be at any

00:01:46.639 --> 00:01:46.649
the school trip which could be at any
 

00:01:46.649 --> 00:01:49.310
the school trip which could be at any
school in the world right now camera not

00:01:49.310 --> 00:01:49.320
school in the world right now camera not
 

00:01:49.320 --> 00:01:52.249
school in the world right now camera not
needed it's on the smartphone torch not

00:01:52.249 --> 00:01:52.259
needed it's on the smartphone torch not
 

00:01:52.259 --> 00:01:54.740
needed it's on the smartphone torch not
needed so your smartphone compass not

00:01:54.740 --> 00:01:54.750
needed so your smartphone compass not
 

00:01:54.750 --> 00:01:57.260
needed so your smartphone compass not
needed on your smartphone map music

00:01:57.260 --> 00:01:57.270
needed on your smartphone map music
 

00:01:57.270 --> 00:02:00.560
needed on your smartphone map music
alarm clock games newspapers guidebooks

00:02:00.560 --> 00:02:00.570
alarm clock games newspapers guidebooks
 

00:02:00.570 --> 00:02:03.800
alarm clock games newspapers guidebooks
television finally a good mood not

00:02:03.800 --> 00:02:03.810
television finally a good mood not
 

00:02:03.810 --> 00:02:05.330
television finally a good mood not
needed because everyone is very in their

00:02:05.330 --> 00:02:05.340
needed because everyone is very in their
 

00:02:05.340 --> 00:02:08.930
needed because everyone is very in their
smartphone so what is needed a charger I

00:02:08.930 --> 00:02:08.940
smartphone so what is needed a charger I
 

00:02:08.940 --> 00:02:10.880
smartphone so what is needed a charger I
think

00:02:10.880 --> 00:02:10.890
think
 

00:02:10.890 --> 00:02:17.180
think
has changed the world I'm done that's a

00:02:17.180 --> 00:02:17.190
has changed the world I'm done that's a
 

00:02:17.190 --> 00:02:20.630
has changed the world I'm done that's a
great point Joey you had you had similar

00:02:20.630 --> 00:02:20.640
great point Joey you had you had similar
 

00:02:20.640 --> 00:02:23.630
great point Joey you had you had similar
comments this morning yeah I mean we

00:02:23.630 --> 00:02:23.640
comments this morning yeah I mean we
 

00:02:23.640 --> 00:02:26.240
comments this morning yeah I mean we
talked a great deal about inequality in

00:02:26.240 --> 00:02:26.250
talked a great deal about inequality in
 

00:02:26.250 --> 00:02:29.000
talked a great deal about inequality in
this world and every comma mist which

00:02:29.000 --> 00:02:29.010
this world and every comma mist which
 

00:02:29.010 --> 00:02:31.699
this world and every comma mist which
recognizes how bad it is but we also

00:02:31.699 --> 00:02:31.709
recognizes how bad it is but we also
 

00:02:31.709 --> 00:02:34.059
recognizes how bad it is but we also
have to understand and in some ways

00:02:34.059 --> 00:02:34.069
have to understand and in some ways
 

00:02:34.069 --> 00:02:39.500
have to understand and in some ways
technology is a great equalizer and that

00:02:39.500 --> 00:02:39.510
technology is a great equalizer and that
 

00:02:39.510 --> 00:02:41.930
technology is a great equalizer and that
in that regard very few things have

00:02:41.930 --> 00:02:41.940
in that regard very few things have
 

00:02:41.940 --> 00:02:44.839
in that regard very few things have
changed the developing world as much as

00:02:44.839 --> 00:02:44.849
changed the developing world as much as
 

00:02:44.849 --> 00:02:47.449
changed the developing world as much as
the cell phone because the cell phone

00:02:47.449 --> 00:02:47.459
the cell phone because the cell phone
 

00:02:47.459 --> 00:02:49.759
the cell phone because the cell phone
allowed it allowed people to build

00:02:49.759 --> 00:02:49.769
allowed it allowed people to build
 

00:02:49.769 --> 00:02:52.069
allowed it allowed people to build
networks of communication without the

00:02:52.069 --> 00:02:52.079
networks of communication without the
 

00:02:52.079 --> 00:02:55.009
networks of communication without the
expensive infrastructure of setting up

00:02:55.009 --> 00:02:55.019
expensive infrastructure of setting up
 

00:02:55.019 --> 00:02:57.789
expensive infrastructure of setting up
an landline phone system and the way

00:02:57.789 --> 00:02:57.799
an landline phone system and the way
 

00:02:57.799 --> 00:03:02.080
an landline phone system and the way
cell phones have changed places like

00:03:02.080 --> 00:03:02.090
cell phones have changed places like
 

00:03:02.090 --> 00:03:05.630
cell phones have changed places like
Africa or southern Asia is impossible to

00:03:05.630 --> 00:03:05.640
Africa or southern Asia is impossible to
 

00:03:05.640 --> 00:03:07.940
Africa or southern Asia is impossible to
imagine for somebody living in the

00:03:07.940 --> 00:03:07.950
imagine for somebody living in the
 

00:03:07.950 --> 00:03:09.080
imagine for somebody living in the
developed world because they are

00:03:09.080 --> 00:03:09.090
developed world because they are
 

00:03:09.090 --> 00:03:11.899
developed world because they are
everywhere people do banking people find

00:03:11.899 --> 00:03:11.909
everywhere people do banking people find
 

00:03:11.909 --> 00:03:14.270
everywhere people do banking people find
jobs people find employees people find

00:03:14.270 --> 00:03:14.280
jobs people find employees people find
 

00:03:14.280 --> 00:03:18.259
jobs people find employees people find
plumbers everything is done on a cell

00:03:18.259 --> 00:03:18.269
plumbers everything is done on a cell
 

00:03:18.269 --> 00:03:21.409
plumbers everything is done on a cell
phone and in that regard it's really we

00:03:21.409 --> 00:03:21.419
phone and in that regard it's really we
 

00:03:21.419 --> 00:03:22.909
phone and in that regard it's really we
all really should think long and hard

00:03:22.909 --> 00:03:22.919
all really should think long and hard
 

00:03:22.919 --> 00:03:26.830
all really should think long and hard
about how much technology is an

00:03:26.830 --> 00:03:26.840
about how much technology is an
 

00:03:26.840 --> 00:03:29.150
about how much technology is an
equalizing factor not only between

00:03:29.150 --> 00:03:29.160
equalizing factor not only between
 

00:03:29.160 --> 00:03:30.559
equalizing factor not only between
developing and under developing

00:03:30.559 --> 00:03:30.569
developing and under developing
 

00:03:30.569 --> 00:03:32.780
developing and under developing
countries but you know the news is you

00:03:32.780 --> 00:03:32.790
countries but you know the news is you
 

00:03:32.790 --> 00:03:34.670
countries but you know the news is you
know that they're the richest man in

00:03:34.670 --> 00:03:34.680
know that they're the richest man in
 

00:03:34.680 --> 00:03:36.229
know that they're the richest man in
America or the second richest men as

00:03:36.229 --> 00:03:36.239
America or the second richest men as
 

00:03:36.239 --> 00:03:38.599
America or the second richest men as
somebody called sheldon adel stone he

00:03:38.599 --> 00:03:38.609
somebody called sheldon adel stone he
 

00:03:38.609 --> 00:03:42.110
somebody called sheldon adel stone he
and i have exactly the same smartphone

00:03:42.110 --> 00:03:42.120
and i have exactly the same smartphone
 

00:03:42.120 --> 00:03:44.960
and i have exactly the same smartphone
and there is nothing that he can do in

00:03:44.960 --> 00:03:44.970
and there is nothing that he can do in
 

00:03:44.970 --> 00:03:47.330
and there is nothing that he can do in
spending twenty eight million dollars to

00:03:47.330 --> 00:03:47.340
spending twenty eight million dollars to
 

00:03:47.340 --> 00:03:49.159
spending twenty eight million dollars to
get a better smartphone we have the same

00:03:49.159 --> 00:03:49.169
get a better smartphone we have the same
 

00:03:49.169 --> 00:03:52.039
get a better smartphone we have the same
smartphone technology is a great

00:03:52.039 --> 00:03:52.049
smartphone technology is a great
 

00:03:52.049 --> 00:03:54.710
smartphone technology is a great
equalizer of both within countries and

00:03:54.710 --> 00:03:54.720
equalizer of both within countries and
 

00:03:54.720 --> 00:03:57.500
equalizer of both within countries and
between countries and in that regard i

00:03:57.500 --> 00:03:57.510
between countries and in that regard i
 

00:03:57.510 --> 00:03:59.420
between countries and in that regard i
am a great optimist because as i see

00:03:59.420 --> 00:03:59.430
am a great optimist because as i see
 

00:03:59.430 --> 00:04:02.089
am a great optimist because as i see
technology going forward i see many of

00:04:02.089 --> 00:04:02.099
technology going forward i see many of
 

00:04:02.099 --> 00:04:04.280
technology going forward i see many of
the gaps not all unfortunately but many

00:04:04.280 --> 00:04:04.290
the gaps not all unfortunately but many
 

00:04:04.290 --> 00:04:06.920
the gaps not all unfortunately but many
of the gaps between rich and poor slowly

00:04:06.920 --> 00:04:06.930
of the gaps between rich and poor slowly
 

00:04:06.930 --> 00:04:10.220
of the gaps between rich and poor slowly
shrinking and that is the best news i

00:04:10.220 --> 00:04:10.230
shrinking and that is the best news i
 

00:04:10.230 --> 00:04:12.979
shrinking and that is the best news i
think of the essentially so you work

00:04:12.979 --> 00:04:12.989
think of the essentially so you work
 

00:04:12.989 --> 00:04:14.809
think of the essentially so you work
with professors across the developing

00:04:14.809 --> 00:04:14.819
with professors across the developing
 

00:04:14.819 --> 00:04:16.670
with professors across the developing
world do you agree with the statement i

00:04:16.670 --> 00:04:16.680
world do you agree with the statement i
 

00:04:16.680 --> 00:04:18.500
world do you agree with the statement i
mean we still have millions of people

00:04:18.500 --> 00:04:18.510
mean we still have millions of people
 

00:04:18.510 --> 00:04:20.509
mean we still have millions of people
who don't have access to electricity at

00:04:20.509 --> 00:04:20.519
who don't have access to electricity at
 

00:04:20.519 --> 00:04:21.020
who don't have access to electricity at
home

00:04:21.020 --> 00:04:21.030
home
 

00:04:21.030 --> 00:04:23.030
home
who don't have access to highest

00:04:23.030 --> 00:04:23.040
who don't have access to highest
 

00:04:23.040 --> 00:04:24.980
who don't have access to highest
bandwidth or smartphones tell us what

00:04:24.980 --> 00:04:24.990
bandwidth or smartphones tell us what
 

00:04:24.990 --> 00:04:27.170
bandwidth or smartphones tell us what
you think well III think it is a

00:04:27.170 --> 00:04:27.180
you think well III think it is a
 

00:04:27.180 --> 00:04:30.140
you think well III think it is a
question of how it changes depending on

00:04:30.140 --> 00:04:30.150
question of how it changes depending on
 

00:04:30.150 --> 00:04:32.000
question of how it changes depending on
what conditions are we talking about I

00:04:32.000 --> 00:04:32.010
what conditions are we talking about I
 

00:04:32.010 --> 00:04:34.100
what conditions are we talking about I
want to go back to what Gandhi used to

00:04:34.100 --> 00:04:34.110
want to go back to what Gandhi used to
 

00:04:34.110 --> 00:04:36.350
want to go back to what Gandhi used to
say what he calls the seven social

00:04:36.350 --> 00:04:36.360
say what he calls the seven social
 

00:04:36.360 --> 00:04:38.600
say what he calls the seven social
blunders that we need to be mindful of

00:04:38.600 --> 00:04:38.610
blunders that we need to be mindful of
 

00:04:38.610 --> 00:04:40.460
blunders that we need to be mindful of
three of which i think is related to

00:04:40.460 --> 00:04:40.470
three of which i think is related to
 

00:04:40.470 --> 00:04:42.800
three of which i think is related to
discussion today one it's when he says

00:04:42.800 --> 00:04:42.810
discussion today one it's when he says
 

00:04:42.810 --> 00:04:45.500
discussion today one it's when he says
we do we do science without humanity as

00:04:45.500 --> 00:04:45.510
we do we do science without humanity as
 

00:04:45.510 --> 00:04:48.080
we do we do science without humanity as
we escalate humanity using science it's

00:04:48.080 --> 00:04:48.090
we escalate humanity using science it's
 

00:04:48.090 --> 00:04:50.510
we escalate humanity using science it's
I'm concerned about the livelihood of

00:04:50.510 --> 00:04:50.520
I'm concerned about the livelihood of
 

00:04:50.520 --> 00:04:52.880
I'm concerned about the livelihood of
people at large we are not talking about

00:04:52.880 --> 00:04:52.890
people at large we are not talking about
 

00:04:52.890 --> 00:04:55.340
people at large we are not talking about
just a group of persons we are talking a

00:04:55.340 --> 00:04:55.350
just a group of persons we are talking a
 

00:04:55.350 --> 00:04:57.620
just a group of persons we are talking a
whole population what we call the bottom

00:04:57.620 --> 00:04:57.630
whole population what we call the bottom
 

00:04:57.630 --> 00:05:00.260
whole population what we call the bottom
billions are the affected by science

00:05:00.260 --> 00:05:00.270
billions are the affected by science
 

00:05:00.270 --> 00:05:02.570
billions are the affected by science
without humanity the second issue is

00:05:02.570 --> 00:05:02.580
without humanity the second issue is
 

00:05:02.580 --> 00:05:05.270
without humanity the second issue is
perhaps knowledge without wisdom the

00:05:05.270 --> 00:05:05.280
perhaps knowledge without wisdom the
 

00:05:05.280 --> 00:05:07.670
perhaps knowledge without wisdom the
earlier panel talked about with them and

00:05:07.670 --> 00:05:07.680
earlier panel talked about with them and
 

00:05:07.680 --> 00:05:09.410
earlier panel talked about with them and
I like the word they need to be factored

00:05:09.410 --> 00:05:09.420
I like the word they need to be factored
 

00:05:09.420 --> 00:05:12.410
I like the word they need to be factored
in when we talk about technology where

00:05:12.410 --> 00:05:12.420
in when we talk about technology where
 

00:05:12.420 --> 00:05:14.510
in when we talk about technology where
is wisdom is this all this technology we

00:05:14.510 --> 00:05:14.520
is wisdom is this all this technology we
 

00:05:14.520 --> 00:05:16.630
is wisdom is this all this technology we
may have knowledge but this wisdom

00:05:16.630 --> 00:05:16.640
may have knowledge but this wisdom
 

00:05:16.640 --> 00:05:18.770
may have knowledge but this wisdom
embedded in that technology at the same

00:05:18.770 --> 00:05:18.780
embedded in that technology at the same
 

00:05:18.780 --> 00:05:21.410
embedded in that technology at the same
time and is certainly an issue that is

00:05:21.410 --> 00:05:21.420
time and is certainly an issue that is
 

00:05:21.420 --> 00:05:23.990
time and is certainly an issue that is
very lated to AI in in this particular

00:05:23.990 --> 00:05:24.000
very lated to AI in in this particular
 

00:05:24.000 --> 00:05:26.330
very lated to AI in in this particular
context and last but not least as we see

00:05:26.330 --> 00:05:26.340
context and last but not least as we see
 

00:05:26.340 --> 00:05:28.850
context and last but not least as we see
more science being funded by private

00:05:28.850 --> 00:05:28.860
more science being funded by private
 

00:05:28.860 --> 00:05:31.070
more science being funded by private
sector the whole issue of business

00:05:31.070 --> 00:05:31.080
sector the whole issue of business
 

00:05:31.080 --> 00:05:36.290
sector the whole issue of business
winner affects the outcome or the goal

00:05:36.290 --> 00:05:36.300
winner affects the outcome or the goal
 

00:05:36.300 --> 00:05:38.390
winner affects the outcome or the goal
of science and the goal of business may

00:05:38.390 --> 00:05:38.400
of science and the goal of business may
 

00:05:38.400 --> 00:05:40.130
of science and the goal of business may
not necessarily be the same and

00:05:40.130 --> 00:05:40.140
not necessarily be the same and
 

00:05:40.140 --> 00:05:42.410
not necessarily be the same and
therefore we want to know whether

00:05:42.410 --> 00:05:42.420
therefore we want to know whether
 

00:05:42.420 --> 00:05:45.110
therefore we want to know whether
effects do influence the way science

00:05:45.110 --> 00:05:45.120
effects do influence the way science
 

00:05:45.120 --> 00:05:46.970
effects do influence the way science
develop depending on the funding

00:05:46.970 --> 00:05:46.980
develop depending on the funding
 

00:05:46.980 --> 00:05:49.580
develop depending on the funding
depending on the kind of negotiation

00:05:49.580 --> 00:05:49.590
depending on the kind of negotiation
 

00:05:49.590 --> 00:05:52.010
depending on the kind of negotiation
that we do at the same time so in the

00:05:52.010 --> 00:05:52.020
that we do at the same time so in the
 

00:05:52.020 --> 00:05:53.600
that we do at the same time so in the
developing countries we discuss this

00:05:53.600 --> 00:05:53.610
developing countries we discuss this
 

00:05:53.610 --> 00:05:55.670
developing countries we discuss this
quite a lot example when we talk about

00:05:55.670 --> 00:05:55.680
quite a lot example when we talk about
 

00:05:55.680 --> 00:05:57.710
quite a lot example when we talk about
science without ethics this year we

00:05:57.710 --> 00:05:57.720
science without ethics this year we
 

00:05:57.720 --> 00:06:00.080
science without ethics this year we
celebrate the 70th anniversary of the

00:06:00.080 --> 00:06:00.090
celebrate the 70th anniversary of the
 

00:06:00.090 --> 00:06:01.460
celebrate the 70th anniversary of the
explosion of the atomic bomb in

00:06:01.460 --> 00:06:01.470
explosion of the atomic bomb in
 

00:06:01.470 --> 00:06:03.830
explosion of the atomic bomb in
Hiroshima and Nagasaki there is already

00:06:03.830 --> 00:06:03.840
Hiroshima and Nagasaki there is already
 

00:06:03.840 --> 00:06:06.500
Hiroshima and Nagasaki there is already
a question for us where is humanity when

00:06:06.500 --> 00:06:06.510
a question for us where is humanity when
 

00:06:06.510 --> 00:06:08.840
a question for us where is humanity when
we develop that particular bomb and how

00:06:08.840 --> 00:06:08.850
we develop that particular bomb and how
 

00:06:08.850 --> 00:06:10.880
we develop that particular bomb and how
come it is repeated twice one in

00:06:10.880 --> 00:06:10.890
come it is repeated twice one in
 

00:06:10.890 --> 00:06:13.160
come it is repeated twice one in
Hiroshima and one in Agra sake what

00:06:13.160 --> 00:06:13.170
Hiroshima and one in Agra sake what
 

00:06:13.170 --> 00:06:14.420
Hiroshima and one in Agra sake what
happened to science at that particular

00:06:14.420 --> 00:06:14.430
happened to science at that particular
 

00:06:14.430 --> 00:06:17.270
happened to science at that particular
point in time we'll talk about knowledge

00:06:17.270 --> 00:06:17.280
point in time we'll talk about knowledge
 

00:06:17.280 --> 00:06:19.430
point in time we'll talk about knowledge
with wisdom the whole idea of climate

00:06:19.430 --> 00:06:19.440
with wisdom the whole idea of climate
 

00:06:19.440 --> 00:06:23.330
with wisdom the whole idea of climate
change and global warming the cop21 is

00:06:23.330 --> 00:06:23.340
change and global warming the cop21 is
 

00:06:23.340 --> 00:06:25.040
change and global warming the cop21 is
there a disconnect between science and

00:06:25.040 --> 00:06:25.050
there a disconnect between science and
 

00:06:25.050 --> 00:06:26.900
there a disconnect between science and
wisdom at a particular point is

00:06:26.900 --> 00:06:26.910
wisdom at a particular point is
 

00:06:26.910 --> 00:06:28.490
wisdom at a particular point is
something that the question that we need

00:06:28.490 --> 00:06:28.500
something that the question that we need
 

00:06:28.500 --> 00:06:30.530
something that the question that we need
to ask so these are issues that I think

00:06:30.530 --> 00:06:30.540
to ask so these are issues that I think
 

00:06:30.540 --> 00:06:32.120
to ask so these are issues that I think
which is important I'm gonna I think

00:06:32.120 --> 00:06:32.130
which is important I'm gonna I think
 

00:06:32.130 --> 00:06:33.500
which is important I'm gonna I think
this is a great transition into

00:06:33.500 --> 00:06:33.510
this is a great transition into
 

00:06:33.510 --> 00:06:35.850
this is a great transition into
Cynthia's work she's known mostly as

00:06:35.850 --> 00:06:35.860
Cynthia's work she's known mostly as
 

00:06:35.860 --> 00:06:37.320
Cynthia's work she's known mostly as
robot assist but we were talking a

00:06:37.320 --> 00:06:37.330
robot assist but we were talking a
 

00:06:37.330 --> 00:06:39.619
robot assist but we were talking a
little bit about her work on education

00:06:39.619 --> 00:06:39.629
little bit about her work on education
 

00:06:39.629 --> 00:06:42.659
little bit about her work on education
I'd like to restrict my comments to

00:06:42.659 --> 00:06:42.669
I'd like to restrict my comments to
 

00:06:42.669 --> 00:06:44.790
I'd like to restrict my comments to
thinking about a profound positive

00:06:44.790 --> 00:06:44.800
thinking about a profound positive
 

00:06:44.800 --> 00:06:47.610
thinking about a profound positive
impact that AI can have particularly we

00:06:47.610 --> 00:06:47.620
impact that AI can have particularly we
 

00:06:47.620 --> 00:06:49.830
impact that AI can have particularly we
speak about education for all and I just

00:06:49.830 --> 00:06:49.840
speak about education for all and I just
 

00:06:49.840 --> 00:06:50.969
speak about education for all and I just
wanted to highlight one particular

00:06:50.969 --> 00:06:50.979
wanted to highlight one particular
 

00:06:50.979 --> 00:06:52.830
wanted to highlight one particular
project because I think it brings it all

00:06:52.830 --> 00:06:52.840
project because I think it brings it all
 

00:06:52.840 --> 00:06:56.520
project because I think it brings it all
into two-color we know that personal

00:06:56.520 --> 00:06:56.530
into two-color we know that personal
 

00:06:56.530 --> 00:06:58.200
into two-color we know that personal
tutoring is much more effective for

00:06:58.200 --> 00:06:58.210
tutoring is much more effective for
 

00:06:58.210 --> 00:06:59.730
tutoring is much more effective for
learning outcomes than the sort of

00:06:59.730 --> 00:06:59.740
learning outcomes than the sort of
 

00:06:59.740 --> 00:07:01.920
learning outcomes than the sort of
lecture hall style of information and

00:07:01.920 --> 00:07:01.930
lecture hall style of information and
 

00:07:01.930 --> 00:07:05.399
lecture hall style of information and
with AI with the ability to track how

00:07:05.399 --> 00:07:05.409
with AI with the ability to track how
 

00:07:05.409 --> 00:07:07.379
with AI with the ability to track how
children engage with digital materials

00:07:07.379 --> 00:07:07.389
children engage with digital materials
 

00:07:07.389 --> 00:07:09.149
children engage with digital materials
we have a eyes that can create

00:07:09.149 --> 00:07:09.159
we have a eyes that can create
 

00:07:09.159 --> 00:07:10.860
we have a eyes that can create
personalized models in terms of

00:07:10.860 --> 00:07:10.870
personalized models in terms of
 

00:07:10.870 --> 00:07:12.809
personalized models in terms of
understanding what children understand

00:07:12.809 --> 00:07:12.819
understanding what children understand
 

00:07:12.819 --> 00:07:13.950
understanding what children understand
what do they understand what is that

00:07:13.950 --> 00:07:13.960
what do they understand what is that
 

00:07:13.960 --> 00:07:15.749
what do they understand what is that
point of information or knowledge

00:07:15.749 --> 00:07:15.759
point of information or knowledge
 

00:07:15.759 --> 00:07:17.519
point of information or knowledge
they're on the cusp of understanding so

00:07:17.519 --> 00:07:17.529
they're on the cusp of understanding so
 

00:07:17.529 --> 00:07:18.629
they're on the cusp of understanding so
you can start to deliver a highly

00:07:18.629 --> 00:07:18.639
you can start to deliver a highly
 

00:07:18.639 --> 00:07:20.999
you can start to deliver a highly
personalized learning experience so

00:07:20.999 --> 00:07:21.009
personalized learning experience so
 

00:07:21.009 --> 00:07:22.649
personalized learning experience so
right now I'm involved in a project

00:07:22.649 --> 00:07:22.659
right now I'm involved in a project
 

00:07:22.659 --> 00:07:24.240
right now I'm involved in a project
called the curious learning initiative

00:07:24.240 --> 00:07:24.250
called the curious learning initiative
 

00:07:24.250 --> 00:07:26.480
called the curious learning initiative
that involves multiple institutions

00:07:26.480 --> 00:07:26.490
that involves multiple institutions
 

00:07:26.490 --> 00:07:29.700
that involves multiple institutions
where we are creating an open platform

00:07:29.700 --> 00:07:29.710
where we are creating an open platform
 

00:07:29.710 --> 00:07:31.709
where we are creating an open platform
and a platform for education

00:07:31.709 --> 00:07:31.719
and a platform for education
 

00:07:31.719 --> 00:07:33.240
and a platform for education
specifically for the most

00:07:33.240 --> 00:07:33.250
specifically for the most
 

00:07:33.250 --> 00:07:35.790
specifically for the most
under-resourced children because of the

00:07:35.790 --> 00:07:35.800
under-resourced children because of the
 

00:07:35.800 --> 00:07:38.189
under-resourced children because of the
proliferation of Technology of the

00:07:38.189 --> 00:07:38.199
proliferation of Technology of the
 

00:07:38.199 --> 00:07:40.170
proliferation of Technology of the
affordability of the scalability we're

00:07:40.170 --> 00:07:40.180
affordability of the scalability we're
 

00:07:40.180 --> 00:07:41.790
affordability of the scalability we're
actually able to deploy and study these

00:07:41.790 --> 00:07:41.800
actually able to deploy and study these
 

00:07:41.800 --> 00:07:43.320
actually able to deploy and study these
systems in the most extreme learning

00:07:43.320 --> 00:07:43.330
systems in the most extreme learning
 

00:07:43.330 --> 00:07:45.119
systems in the most extreme learning
situations we're talking about villages

00:07:45.119 --> 00:07:45.129
situations we're talking about villages
 

00:07:45.129 --> 00:07:47.490
situations we're talking about villages
in Ethiopia so far from schools that the

00:07:47.490 --> 00:07:47.500
in Ethiopia so far from schools that the
 

00:07:47.500 --> 00:07:48.959
in Ethiopia so far from schools that the
children can't go to school we're

00:07:48.959 --> 00:07:48.969
children can't go to school we're
 

00:07:48.969 --> 00:07:50.999
children can't go to school we're
talking about school classes in South

00:07:50.999 --> 00:07:51.009
talking about school classes in South
 

00:07:51.009 --> 00:07:52.230
talking about school classes in South
Africa where the student to teacher

00:07:52.230 --> 00:07:52.240
Africa where the student to teacher
 

00:07:52.240 --> 00:07:54.809
Africa where the student to teacher
ratio is 80 to 100 or even in

00:07:54.809 --> 00:07:54.819
ratio is 80 to 100 or even in
 

00:07:54.819 --> 00:07:56.700
ratio is 80 to 100 or even in
impoverished areas in the United States

00:07:56.700 --> 00:07:56.710
impoverished areas in the United States
 

00:07:56.710 --> 00:07:58.469
impoverished areas in the United States
we're not every child can go to

00:07:58.469 --> 00:07:58.479
we're not every child can go to
 

00:07:58.479 --> 00:07:59.850
we're not every child can go to
preschool because they don't have enough

00:07:59.850 --> 00:07:59.860
preschool because they don't have enough
 

00:07:59.860 --> 00:08:01.230
preschool because they don't have enough
preschool sites it's done by lottery

00:08:01.230 --> 00:08:01.240
preschool sites it's done by lottery
 

00:08:01.240 --> 00:08:03.240
preschool sites it's done by lottery
we've been studying how this technology

00:08:03.240 --> 00:08:03.250
we've been studying how this technology
 

00:08:03.250 --> 00:08:04.890
we've been studying how this technology
can be deployed in these systems with

00:08:04.890 --> 00:08:04.900
can be deployed in these systems with
 

00:08:04.900 --> 00:08:06.480
can be deployed in these systems with
extremely positive results for for us

00:08:06.480 --> 00:08:06.490
extremely positive results for for us
 

00:08:06.490 --> 00:08:08.339
extremely positive results for for us
the killer app right now is literacy so

00:08:08.339 --> 00:08:08.349
the killer app right now is literacy so
 

00:08:08.349 --> 00:08:09.360
the killer app right now is literacy so
we think about the spreading of the

00:08:09.360 --> 00:08:09.370
we think about the spreading of the
 

00:08:09.370 --> 00:08:10.740
we think about the spreading of the
internet and technology literacy is

00:08:10.740 --> 00:08:10.750
internet and technology literacy is
 

00:08:10.750 --> 00:08:13.050
internet and technology literacy is
really becoming critical and education

00:08:13.050 --> 00:08:13.060
really becoming critical and education
 

00:08:13.060 --> 00:08:14.670
really becoming critical and education
is absolutely becoming as much of a

00:08:14.670 --> 00:08:14.680
is absolutely becoming as much of a
 

00:08:14.680 --> 00:08:17.339
is absolutely becoming as much of a
fundamental right as food clothing and

00:08:17.339 --> 00:08:17.349
fundamental right as food clothing and
 

00:08:17.349 --> 00:08:20.610
fundamental right as food clothing and
shelter so a lot of opportunity here and

00:08:20.610 --> 00:08:20.620
shelter so a lot of opportunity here and
 

00:08:20.620 --> 00:08:22.350
shelter so a lot of opportunity here and
I think all of the technological trends

00:08:22.350 --> 00:08:22.360
I think all of the technological trends
 

00:08:22.360 --> 00:08:24.209
I think all of the technological trends
we now have a corpus of children

00:08:24.209 --> 00:08:24.219
we now have a corpus of children
 

00:08:24.219 --> 00:08:26.129
we now have a corpus of children
learning with this technology across all

00:08:26.129 --> 00:08:26.139
learning with this technology across all
 

00:08:26.139 --> 00:08:27.749
learning with this technology across all
of these countries that we can learn how

00:08:27.749 --> 00:08:27.759
of these countries that we can learn how
 

00:08:27.759 --> 00:08:29.159
of these countries that we can learn how
they engage with this technology how

00:08:29.159 --> 00:08:29.169
they engage with this technology how
 

00:08:29.169 --> 00:08:30.420
they engage with this technology how
they learned in these different contexts

00:08:30.420 --> 00:08:30.430
they learned in these different contexts
 

00:08:30.430 --> 00:08:32.459
they learned in these different contexts
so huge wealth of scientific opportunity

00:08:32.459 --> 00:08:32.469
so huge wealth of scientific opportunity
 

00:08:32.469 --> 00:08:34.709
so huge wealth of scientific opportunity
as well and what we're finding is it's a

00:08:34.709 --> 00:08:34.719
as well and what we're finding is it's a
 

00:08:34.719 --> 00:08:36.630
as well and what we're finding is it's a
highly social process it's not the case

00:08:36.630 --> 00:08:36.640
highly social process it's not the case
 

00:08:36.640 --> 00:08:38.790
highly social process it's not the case
of children with their nose and a tablet

00:08:38.790 --> 00:08:38.800
of children with their nose and a tablet
 

00:08:38.800 --> 00:08:40.290
of children with their nose and a tablet
they're sharing they're talking it's

00:08:40.290 --> 00:08:40.300
they're sharing they're talking it's
 

00:08:40.300 --> 00:08:41.880
they're sharing they're talking it's
children bringing natural learning

00:08:41.880 --> 00:08:41.890
children bringing natural learning
 

00:08:41.890 --> 00:08:44.519
children bringing natural learning
processes supported by technology in a

00:08:44.519 --> 00:08:44.529
processes supported by technology in a
 

00:08:44.529 --> 00:08:45.930
processes supported by technology in a
way that's leading to positive learning

00:08:45.930 --> 00:08:45.940
way that's leading to positive learning
 

00:08:45.940 --> 00:08:47.710
way that's leading to positive learning
outcomes why you see huge

00:08:47.710 --> 00:08:47.720
outcomes why you see huge
 

00:08:47.720 --> 00:08:49.900
outcomes why you see huge
huge tremendous potential for education

00:08:49.900 --> 00:08:49.910
huge tremendous potential for education
 

00:08:49.910 --> 00:08:52.809
huge tremendous potential for education
for all with with a I I'd like us to to

00:08:52.809 --> 00:08:52.819
for all with with a I I'd like us to to
 

00:08:52.819 --> 00:08:54.639
for all with with a I I'd like us to to
talk a little bit about this issue of

00:08:54.639 --> 00:08:54.649
talk a little bit about this issue of
 

00:08:54.649 --> 00:08:57.069
talk a little bit about this issue of
science and empathy Michael you're a

00:08:57.069 --> 00:08:57.079
science and empathy Michael you're a
 

00:08:57.079 --> 00:08:59.170
science and empathy Michael you're a
scientist how do you think we should

00:08:59.170 --> 00:08:59.180
scientist how do you think we should
 

00:08:59.180 --> 00:09:00.999
scientist how do you think we should
think about empathy in the scientific

00:09:00.999 --> 00:09:01.009
think about empathy in the scientific
 

00:09:01.009 --> 00:09:02.920
think about empathy in the scientific
context and especially as we're as we're

00:09:02.920 --> 00:09:02.930
context and especially as we're as we're
 

00:09:02.930 --> 00:09:04.840
context and especially as we're as we're
developing some of these new systems you

00:09:04.840 --> 00:09:04.850
developing some of these new systems you
 

00:09:04.850 --> 00:09:06.340
developing some of these new systems you
know in Silicon Valley we tend to think

00:09:06.340 --> 00:09:06.350
know in Silicon Valley we tend to think
 

00:09:06.350 --> 00:09:08.889
know in Silicon Valley we tend to think
about the bottom line or increasing

00:09:08.889 --> 00:09:08.899
about the bottom line or increasing
 

00:09:08.899 --> 00:09:10.179
about the bottom line or increasing
innovation empathy doesn't usually

00:09:10.179 --> 00:09:10.189
innovation empathy doesn't usually
 

00:09:10.189 --> 00:09:12.519
innovation empathy doesn't usually
factor into those discussions very early

00:09:12.519 --> 00:09:12.529
factor into those discussions very early
 

00:09:12.529 --> 00:09:14.350
factor into those discussions very early
on in the process so I would say that

00:09:14.350 --> 00:09:14.360
on in the process so I would say that
 

00:09:14.360 --> 00:09:17.439
on in the process so I would say that
I'm going to talk about this not a lot

00:09:17.439 --> 00:09:17.449
I'm going to talk about this not a lot
 

00:09:17.449 --> 00:09:19.329
I'm going to talk about this not a lot
of Silicon Valley is applied science I'm

00:09:19.329 --> 00:09:19.339
of Silicon Valley is applied science I'm
 

00:09:19.339 --> 00:09:21.280
of Silicon Valley is applied science I'm
gonna think about this in terms of basic

00:09:21.280 --> 00:09:21.290
gonna think about this in terms of basic
 

00:09:21.290 --> 00:09:25.179
gonna think about this in terms of basic
science and I think my guess is that

00:09:25.179 --> 00:09:25.189
science and I think my guess is that
 

00:09:25.189 --> 00:09:27.220
science and I think my guess is that
many many basic sciences the successful

00:09:27.220 --> 00:09:27.230
many many basic sciences the successful
 

00:09:27.230 --> 00:09:33.340
many many basic sciences the successful
ones pretty much maybe not autistic but

00:09:33.340 --> 00:09:33.350
ones pretty much maybe not autistic but
 

00:09:33.350 --> 00:09:35.740
ones pretty much maybe not autistic but
not necessarily socially very skilled

00:09:35.740 --> 00:09:35.750
not necessarily socially very skilled
 

00:09:35.750 --> 00:09:38.319
not necessarily socially very skilled
being a geek really makes a difference

00:09:38.319 --> 00:09:38.329
being a geek really makes a difference
 

00:09:38.329 --> 00:09:40.540
being a geek really makes a difference
essentially if we focus on something

00:09:40.540 --> 00:09:40.550
essentially if we focus on something
 

00:09:40.550 --> 00:09:42.429
essentially if we focus on something
which you could hope you can't hardly

00:09:42.429 --> 00:09:42.439
which you could hope you can't hardly
 

00:09:42.439 --> 00:09:44.740
which you could hope you can't hardly
explain to anybody and if you did they

00:09:44.740 --> 00:09:44.750
explain to anybody and if you did they
 

00:09:44.750 --> 00:09:46.420
explain to anybody and if you did they
wouldn't really be at all interested so

00:09:46.420 --> 00:09:46.430
wouldn't really be at all interested so
 

00:09:46.430 --> 00:09:48.610
wouldn't really be at all interested so
in some senses in basic science you're

00:09:48.610 --> 00:09:48.620
in some senses in basic science you're
 

00:09:48.620 --> 00:09:50.650
in some senses in basic science you're
out there on the frontier picking away

00:09:50.650 --> 00:09:50.660
out there on the frontier picking away
 

00:09:50.660 --> 00:09:52.990
out there on the frontier picking away
for bits of information that make no

00:09:52.990 --> 00:09:53.000
for bits of information that make no
 

00:09:53.000 --> 00:09:55.329
for bits of information that make no
sense at all when you get them I think

00:09:55.329 --> 00:09:55.339
sense at all when you get them I think
 

00:09:55.339 --> 00:09:57.819
sense at all when you get them I think
in my case I'm probably super autistic

00:09:57.819 --> 00:09:57.829
in my case I'm probably super autistic
 

00:09:57.829 --> 00:10:00.790
in my case I'm probably super autistic
but I got married when I was 20 and now

00:10:00.790 --> 00:10:00.800
but I got married when I was 20 and now
 

00:10:00.800 --> 00:10:03.340
but I got married when I was 20 and now
I have six grandchildren and a wife and

00:10:03.340 --> 00:10:03.350
I have six grandchildren and a wife and
 

00:10:03.350 --> 00:10:05.259
I have six grandchildren and a wife and
three children that made a huge

00:10:05.259 --> 00:10:05.269
three children that made a huge
 

00:10:05.269 --> 00:10:07.030
three children that made a huge
difference but I do think that this is

00:10:07.030 --> 00:10:07.040
difference but I do think that this is
 

00:10:07.040 --> 00:10:09.790
difference but I do think that this is
one of the problems that very often a

00:10:09.790 --> 00:10:09.800
one of the problems that very often a
 

00:10:09.800 --> 00:10:11.559
one of the problems that very often a
basic scientist can't even say when it's

00:10:11.559 --> 00:10:11.569
basic scientist can't even say when it's
 

00:10:11.569 --> 00:10:13.619
basic scientist can't even say when it's
going to be good for he doesn't know and

00:10:13.619 --> 00:10:13.629
going to be good for he doesn't know and
 

00:10:13.629 --> 00:10:16.329
going to be good for he doesn't know and
I think we have to realize and this goes

00:10:16.329 --> 00:10:16.339
I think we have to realize and this goes
 

00:10:16.339 --> 00:10:17.949
I think we have to realize and this goes
back to what you were saying a lot of

00:10:17.949 --> 00:10:17.959
back to what you were saying a lot of
 

00:10:17.959 --> 00:10:19.629
back to what you were saying a lot of
the ethics here comes from thinking you

00:10:19.629 --> 00:10:19.639
the ethics here comes from thinking you
 

00:10:19.639 --> 00:10:21.639
the ethics here comes from thinking you
know what's going to happen but if you

00:10:21.639 --> 00:10:21.649
know what's going to happen but if you
 

00:10:21.649 --> 00:10:23.619
know what's going to happen but if you
look at this so many things that have

00:10:23.619 --> 00:10:23.629
look at this so many things that have
 

00:10:23.629 --> 00:10:26.199
look at this so many things that have
happened happen in an unexpected way

00:10:26.199 --> 00:10:26.209
happened happen in an unexpected way
 

00:10:26.209 --> 00:10:28.299
happened happen in an unexpected way
maybe the trends are predictable but

00:10:28.299 --> 00:10:28.309
maybe the trends are predictable but
 

00:10:28.309 --> 00:10:29.710
maybe the trends are predictable but
exactly what happens the extremely

00:10:29.710 --> 00:10:29.720
exactly what happens the extremely
 

00:10:29.720 --> 00:10:33.369
exactly what happens the extremely
unexpected I think that I think actually

00:10:33.369 --> 00:10:33.379
unexpected I think that I think actually
 

00:10:33.379 --> 00:10:35.439
unexpected I think that I think actually
basic science is there also in the world

00:10:35.439 --> 00:10:35.449
basic science is there also in the world
 

00:10:35.449 --> 00:10:37.059
basic science is there also in the world
there's been a big move away from basic

00:10:37.059 --> 00:10:37.069
there's been a big move away from basic
 

00:10:37.069 --> 00:10:38.980
there's been a big move away from basic
science so most countries are not

00:10:38.980 --> 00:10:38.990
science so most countries are not
 

00:10:38.990 --> 00:10:40.569
science so most countries are not
talking about translational research

00:10:40.569 --> 00:10:40.579
talking about translational research
 

00:10:40.579 --> 00:10:42.939
talking about translational research
applied research and that's very

00:10:42.939 --> 00:10:42.949
applied research and that's very
 

00:10:42.949 --> 00:10:44.230
applied research and that's very
dangerous because if you know where

00:10:44.230 --> 00:10:44.240
dangerous because if you know where
 

00:10:44.240 --> 00:10:45.970
dangerous because if you know where
you're going you're not going to find

00:10:45.970 --> 00:10:45.980
you're going you're not going to find
 

00:10:45.980 --> 00:10:46.990
you're going you're not going to find
something really interesting and

00:10:46.990 --> 00:10:47.000
something really interesting and
 

00:10:47.000 --> 00:10:48.100
something really interesting and
someone's you've got to say to somebody

00:10:48.100 --> 00:10:48.110
someone's you've got to say to somebody
 

00:10:48.110 --> 00:10:49.840
someone's you've got to say to somebody
go ahead and do something that no one

00:10:49.840 --> 00:10:49.850
go ahead and do something that no one
 

00:10:49.850 --> 00:10:51.639
go ahead and do something that no one
really understands and finds it so I

00:10:51.639 --> 00:10:51.649
really understands and finds it so I
 

00:10:51.649 --> 00:10:55.780
really understands and finds it so I
think the empathy is an employee's a

00:10:55.780 --> 00:10:55.790
think the empathy is an employee's a
 

00:10:55.790 --> 00:10:56.590
think the empathy is an employee's a
company at issue

00:10:56.590 --> 00:10:56.600
company at issue
 

00:10:56.600 --> 00:10:57.940
company at issue
and

00:10:57.940 --> 00:10:57.950
and
 

00:10:57.950 --> 00:11:00.310
and
I don't even know how apathetic I and my

00:11:00.310 --> 00:11:00.320
I don't even know how apathetic I and my
 

00:11:00.320 --> 00:11:02.290
I don't even know how apathetic I and my
wife would probably say very not

00:11:02.290 --> 00:11:02.300
wife would probably say very not
 

00:11:02.300 --> 00:11:05.320
wife would probably say very not
empathetic that's why I have a wife at

00:11:05.320 --> 00:11:05.330
empathetic that's why I have a wife at
 

00:11:05.330 --> 00:11:11.980
empathetic that's why I have a wife at
least you're self-aware would anybody

00:11:11.980 --> 00:11:11.990
least you're self-aware would anybody
 

00:11:11.990 --> 00:11:17.140
least you're self-aware would anybody
else like to comment on that not on

00:11:17.140 --> 00:11:17.150
else like to comment on that not on
 

00:11:17.150 --> 00:11:19.210
else like to comment on that not on
Michaels empathy or lack thereof but on

00:11:19.210 --> 00:11:19.220
Michaels empathy or lack thereof but on
 

00:11:19.220 --> 00:11:25.030
Michaels empathy or lack thereof but on
the general topic I think there is an

00:11:25.030 --> 00:11:25.040
the general topic I think there is an
 

00:11:25.040 --> 00:11:27.610
the general topic I think there is an
active dialogue going on now so I I'm an

00:11:27.610 --> 00:11:27.620
active dialogue going on now so I I'm an
 

00:11:27.620 --> 00:11:30.070
active dialogue going on now so I I'm an
innovator I create technologies but

00:11:30.070 --> 00:11:30.080
innovator I create technologies but
 

00:11:30.080 --> 00:11:33.850
innovator I create technologies but
really around what are the values of

00:11:33.850 --> 00:11:33.860
really around what are the values of
 

00:11:33.860 --> 00:11:35.620
really around what are the values of
humanistic values that we apply when we

00:11:35.620 --> 00:11:35.630
humanistic values that we apply when we
 

00:11:35.630 --> 00:11:38.200
humanistic values that we apply when we
create these technologies and I think as

00:11:38.200 --> 00:11:38.210
create these technologies and I think as
 

00:11:38.210 --> 00:11:40.240
create these technologies and I think as
we understand now that we have super

00:11:40.240 --> 00:11:40.250
we understand now that we have super
 

00:11:40.250 --> 00:11:42.060
we understand now that we have super
computers in our pockets and so forth

00:11:42.060 --> 00:11:42.070
computers in our pockets and so forth
 

00:11:42.070 --> 00:11:45.010
computers in our pockets and so forth
really trying to understand how can

00:11:45.010 --> 00:11:45.020
really trying to understand how can
 

00:11:45.020 --> 00:11:46.480
really trying to understand how can
these systems to be deployed in a way

00:11:46.480 --> 00:11:46.490
these systems to be deployed in a way
 

00:11:46.490 --> 00:11:47.620
these systems to be deployed in a way
how can they be designed in a way that

00:11:47.620 --> 00:11:47.630
how can they be designed in a way that
 

00:11:47.630 --> 00:11:50.620
how can they be designed in a way that
really promotes human flourishing really

00:11:50.620 --> 00:11:50.630
really promotes human flourishing really
 

00:11:50.630 --> 00:11:52.270
really promotes human flourishing really
to think beyond the kind of efficacy in

00:11:52.270 --> 00:11:52.280
to think beyond the kind of efficacy in
 

00:11:52.280 --> 00:11:54.160
to think beyond the kind of efficacy in
the utility to really think about how it

00:11:54.160 --> 00:11:54.170
the utility to really think about how it
 

00:11:54.170 --> 00:11:56.320
the utility to really think about how it
impacts real people's lives versus the

00:11:56.320 --> 00:11:56.330
impacts real people's lives versus the
 

00:11:56.330 --> 00:11:58.570
impacts real people's lives versus the
few specialists or scientists or whatnot

00:11:58.570 --> 00:11:58.580
few specialists or scientists or whatnot
 

00:11:58.580 --> 00:12:00.370
few specialists or scientists or whatnot
to really think about everyone and I

00:12:00.370 --> 00:12:00.380
to really think about everyone and I
 

00:12:00.380 --> 00:12:02.380
to really think about everyone and I
hear much more of that open dialogue

00:12:02.380 --> 00:12:02.390
hear much more of that open dialogue
 

00:12:02.390 --> 00:12:03.370
hear much more of that open dialogue
happening now which i think is

00:12:03.370 --> 00:12:03.380
happening now which i think is
 

00:12:03.380 --> 00:12:06.280
happening now which i think is
absolutely critical so you know as an

00:12:06.280 --> 00:12:06.290
absolutely critical so you know as an
 

00:12:06.290 --> 00:12:08.860
absolutely critical so you know as an
economist you always worry about one

00:12:08.860 --> 00:12:08.870
economist you always worry about one
 

00:12:08.870 --> 00:12:10.840
economist you always worry about one
thing and that is that much of the

00:12:10.840 --> 00:12:10.850
thing and that is that much of the
 

00:12:10.850 --> 00:12:12.160
thing and that is that much of the
direction in which science and

00:12:12.160 --> 00:12:12.170
direction in which science and
 

00:12:12.170 --> 00:12:16.060
direction in which science and
technology are going are determined by

00:12:16.060 --> 00:12:16.070
technology are going are determined by
 

00:12:16.070 --> 00:12:19.930
technology are going are determined by
market forces and they're a real

00:12:19.930 --> 00:12:19.940
market forces and they're a real
 

00:12:19.940 --> 00:12:21.910
market forces and they're a real
question that we really have to ask

00:12:21.910 --> 00:12:21.920
question that we really have to ask
 

00:12:21.920 --> 00:12:26.020
question that we really have to ask
ourselves is do we really wish to rely

00:12:26.020 --> 00:12:26.030
ourselves is do we really wish to rely
 

00:12:26.030 --> 00:12:29.980
ourselves is do we really wish to rely
on what markets decide in terms of where

00:12:29.980 --> 00:12:29.990
on what markets decide in terms of where
 

00:12:29.990 --> 00:12:32.140
on what markets decide in terms of where
science and technology are going and

00:12:32.140 --> 00:12:32.150
science and technology are going and
 

00:12:32.150 --> 00:12:34.990
science and technology are going and
they're very good reasons to think that

00:12:34.990 --> 00:12:35.000
they're very good reasons to think that
 

00:12:35.000 --> 00:12:36.820
they're very good reasons to think that
that may not be the case that and this

00:12:36.820 --> 00:12:36.830
that may not be the case that and this
 

00:12:36.830 --> 00:12:39.550
that may not be the case that and this
is the classic case in which markets

00:12:39.550 --> 00:12:39.560
is the classic case in which markets
 

00:12:39.560 --> 00:12:43.360
is the classic case in which markets
needs nudging from politicians from

00:12:43.360 --> 00:12:43.370
needs nudging from politicians from
 

00:12:43.370 --> 00:12:46.270
needs nudging from politicians from
public opinions from people outside the

00:12:46.270 --> 00:12:46.280
public opinions from people outside the
 

00:12:46.280 --> 00:12:48.130
public opinions from people outside the
market selasa first Exorcist

00:12:48.130 --> 00:12:48.140
market selasa first Exorcist
 

00:12:48.140 --> 00:12:50.740
market selasa first Exorcist
and so on and so forth and so weary it

00:12:50.740 --> 00:12:50.750
and so on and so forth and so weary it
 

00:12:50.750 --> 00:12:53.170
and so on and so forth and so weary it
really matters that a lot of research

00:12:53.170 --> 00:12:53.180
really matters that a lot of research
 

00:12:53.180 --> 00:12:56.200
really matters that a lot of research
should go into things like malaria

00:12:56.200 --> 00:12:56.210
should go into things like malaria
 

00:12:56.210 --> 00:12:59.050
should go into things like malaria
schistosomiasis and diseases like that

00:12:59.050 --> 00:12:59.060
schistosomiasis and diseases like that
 

00:12:59.060 --> 00:13:01.090
schistosomiasis and diseases like that
and affect millions of people in poor

00:13:01.090 --> 00:13:01.100
and affect millions of people in poor
 

00:13:01.100 --> 00:13:03.310
and affect millions of people in poor
countries rather than on the research on

00:13:03.310 --> 00:13:03.320
countries rather than on the research on
 

00:13:03.320 --> 00:13:06.580
countries rather than on the research on
Botox for you know wealthy American

00:13:06.580 --> 00:13:06.590
Botox for you know wealthy American
 

00:13:06.590 --> 00:13:09.790
Botox for you know wealthy American
women but that is unfortunately where a

00:13:09.790 --> 00:13:09.800
women but that is unfortunately where a
 

00:13:09.800 --> 00:13:11.510
women but that is unfortunately where a
lot of money is

00:13:11.510 --> 00:13:11.520
lot of money is
 

00:13:11.520 --> 00:13:13.670
lot of money is
or impotence drugs for wealthy American

00:13:13.670 --> 00:13:13.680
or impotence drugs for wealthy American
 

00:13:13.680 --> 00:13:23.960
or impotence drugs for wealthy American
men to be to shake but the main point is

00:13:23.960 --> 00:13:23.970
men to be to shake but the main point is
 

00:13:23.970 --> 00:13:25.699
men to be to shake but the main point is
that I said it with some regret because

00:13:25.699 --> 00:13:25.709
that I said it with some regret because
 

00:13:25.709 --> 00:13:27.440
that I said it with some regret because
I'm an economist and roughly speaking

00:13:27.440 --> 00:13:27.450
I'm an economist and roughly speaking
 

00:13:27.450 --> 00:13:29.389
I'm an economist and roughly speaking
I'm trained to believe in markets but

00:13:29.389 --> 00:13:29.399
I'm trained to believe in markets but
 

00:13:29.399 --> 00:13:31.490
I'm trained to believe in markets but
it's important to be able to step aside

00:13:31.490 --> 00:13:31.500
it's important to be able to step aside
 

00:13:31.500 --> 00:13:34.519
it's important to be able to step aside
and say in this particular case we

00:13:34.519 --> 00:13:34.529
and say in this particular case we
 

00:13:34.529 --> 00:13:36.530
and say in this particular case we
should not rely on market and then the

00:13:36.530 --> 00:13:36.540
should not rely on market and then the
 

00:13:36.540 --> 00:13:38.269
should not rely on market and then the
question of course is well who should we

00:13:38.269 --> 00:13:38.279
question of course is well who should we
 

00:13:38.279 --> 00:13:41.449
question of course is well who should we
rely on and unfortunately I think the

00:13:41.449 --> 00:13:41.459
rely on and unfortunately I think the
 

00:13:41.459 --> 00:13:43.820
rely on and unfortunately I think the
quality of our public servants

00:13:43.820 --> 00:13:43.830
quality of our public servants
 

00:13:43.830 --> 00:13:45.769
quality of our public servants
particularly I'm afraid United States

00:13:45.769 --> 00:13:45.779
particularly I'm afraid United States
 

00:13:45.779 --> 00:13:48.590
particularly I'm afraid United States
these days hasn't always lived up to the

00:13:48.590 --> 00:13:48.600
these days hasn't always lived up to the
 

00:13:48.600 --> 00:13:51.350
these days hasn't always lived up to the
expectations that we need to supplement

00:13:51.350 --> 00:13:51.360
expectations that we need to supplement
 

00:13:51.360 --> 00:13:53.660
expectations that we need to supplement
the market and so we have really the

00:13:53.660 --> 00:13:53.670
the market and so we have really the
 

00:13:53.670 --> 00:13:55.880
the market and so we have really the
choice between two rather and attractive

00:13:55.880 --> 00:13:55.890
choice between two rather and attractive
 

00:13:55.890 --> 00:13:58.100
choice between two rather and attractive
alternatives one of them is the markets

00:13:58.100 --> 00:13:58.110
alternatives one of them is the markets
 

00:13:58.110 --> 00:14:00.710
alternatives one of them is the markets
dictum with a you know backed up by

00:14:00.710 --> 00:14:00.720
dictum with a you know backed up by
 

00:14:00.720 --> 00:14:03.889
dictum with a you know backed up by
money and the other is politicians who

00:14:03.889 --> 00:14:03.899
money and the other is politicians who
 

00:14:03.899 --> 00:14:07.880
money and the other is politicians who
are worrying about votes and neither of

00:14:07.880 --> 00:14:07.890
are worrying about votes and neither of
 

00:14:07.890 --> 00:14:10.370
are worrying about votes and neither of
those unfortunately are perfect and so

00:14:10.370 --> 00:14:10.380
those unfortunately are perfect and so
 

00:14:10.380 --> 00:14:12.230
those unfortunately are perfect and so
we will not get the best of all possible

00:14:12.230 --> 00:14:12.240
we will not get the best of all possible
 

00:14:12.240 --> 00:14:14.570
we will not get the best of all possible
worlds ladies and gentlemen we'll just

00:14:14.570 --> 00:14:14.580
worlds ladies and gentlemen we'll just
 

00:14:14.580 --> 00:14:21.740
worlds ladies and gentlemen we'll just
muddle through some pessimism from the

00:14:21.740 --> 00:14:21.750
muddle through some pessimism from the
 

00:14:21.750 --> 00:14:23.660
muddle through some pessimism from the
art from the tech optimists this is

00:14:23.660 --> 00:14:23.670
art from the tech optimists this is
 

00:14:23.670 --> 00:14:26.840
art from the tech optimists this is
surprising so I think the question that

00:14:26.840 --> 00:14:26.850
surprising so I think the question that
 

00:14:26.850 --> 00:14:28.579
surprising so I think the question that
was raised was very relevant to to

00:14:28.579 --> 00:14:28.589
was raised was very relevant to to
 

00:14:28.589 --> 00:14:30.139
was raised was very relevant to to
developing countries that you want to do

00:14:30.139 --> 00:14:30.149
developing countries that you want to do
 

00:14:30.149 --> 00:14:32.150
developing countries that you want to do
science the kinds of science that we do

00:14:32.150 --> 00:14:32.160
science the kinds of science that we do
 

00:14:32.160 --> 00:14:33.740
science the kinds of science that we do
normally comes in from what the

00:14:33.740 --> 00:14:33.750
normally comes in from what the
 

00:14:33.750 --> 00:14:36.050
normally comes in from what the
developed country does we always look at

00:14:36.050 --> 00:14:36.060
developed country does we always look at
 

00:14:36.060 --> 00:14:38.300
developed country does we always look at
what is quote unquote current in the

00:14:38.300 --> 00:14:38.310
what is quote unquote current in the
 

00:14:38.310 --> 00:14:40.010
what is quote unquote current in the
world at large and we try to imitate

00:14:40.010 --> 00:14:40.020
world at large and we try to imitate
 

00:14:40.020 --> 00:14:42.410
world at large and we try to imitate
them you know sometimes resources are a

00:14:42.410 --> 00:14:42.420
them you know sometimes resources are a
 

00:14:42.420 --> 00:14:43.579
them you know sometimes resources are a
big problem

00:14:43.579 --> 00:14:43.589
big problem
 

00:14:43.589 --> 00:14:45.650
big problem
as you can see malaria dysentery

00:14:45.650 --> 00:14:45.660
as you can see malaria dysentery
 

00:14:45.660 --> 00:14:48.889
as you can see malaria dysentery
diarrhea these are age-old diseases

00:14:48.889 --> 00:14:48.899
diarrhea these are age-old diseases
 

00:14:48.899 --> 00:14:51.230
diarrhea these are age-old diseases
which is still proliferating in many

00:14:51.230 --> 00:14:51.240
which is still proliferating in many
 

00:14:51.240 --> 00:14:53.360
which is still proliferating in many
developing countries you know and I'm so

00:14:53.360 --> 00:14:53.370
developing countries you know and I'm so
 

00:14:53.370 --> 00:14:55.880
developing countries you know and I'm so
happy that the Nobel laureate for for

00:14:55.880 --> 00:14:55.890
happy that the Nobel laureate for for
 

00:14:55.890 --> 00:14:59.030
happy that the Nobel laureate for for
physic Physiology and medicine this year

00:14:59.030 --> 00:14:59.040
physic Physiology and medicine this year
 

00:14:59.040 --> 00:15:01.310
physic Physiology and medicine this year
goes to a person to work on a team in

00:15:01.310 --> 00:15:01.320
goes to a person to work on a team in
 

00:15:01.320 --> 00:15:04.190
goes to a person to work on a team in
artemisinin a natural product that comes

00:15:04.190 --> 00:15:04.200
artemisinin a natural product that comes
 

00:15:04.200 --> 00:15:08.000
artemisinin a natural product that comes
from herbs for malaria control I mean

00:15:08.000 --> 00:15:08.010
from herbs for malaria control I mean
 

00:15:08.010 --> 00:15:09.560
from herbs for malaria control I mean
these are the kind of research letting

00:15:09.560 --> 00:15:09.570
these are the kind of research letting
 

00:15:09.570 --> 00:15:12.380
these are the kind of research letting
this relevant cotton code for developing

00:15:12.380 --> 00:15:12.390
this relevant cotton code for developing
 

00:15:12.390 --> 00:15:14.420
this relevant cotton code for developing
countries to move ahead unless we get

00:15:14.420 --> 00:15:14.430
countries to move ahead unless we get
 

00:15:14.430 --> 00:15:16.490
countries to move ahead unless we get
this done technology will be secondary

00:15:16.490 --> 00:15:16.500
this done technology will be secondary
 

00:15:16.500 --> 00:15:20.660
this done technology will be secondary
to us I also add that there are new

00:15:20.660 --> 00:15:20.670
to us I also add that there are new
 

00:15:20.670 --> 00:15:22.490
to us I also add that there are new
models of fundraising that are happening

00:15:22.490 --> 00:15:22.500
models of fundraising that are happening
 

00:15:22.500 --> 00:15:24.730
models of fundraising that are happening
now crowdfunding being one of them

00:15:24.730 --> 00:15:24.740
now crowdfunding being one of them
 

00:15:24.740 --> 00:15:26.650
now crowdfunding being one of them
right now people as individuals can kind

00:15:26.650 --> 00:15:26.660
right now people as individuals can kind
 

00:15:26.660 --> 00:15:28.270
right now people as individuals can kind
of vote with their pocketbook in terms

00:15:28.270 --> 00:15:28.280
of vote with their pocketbook in terms
 

00:15:28.280 --> 00:15:29.530
of vote with their pocketbook in terms
of what projects they deemed to be

00:15:29.530 --> 00:15:29.540
of what projects they deemed to be
 

00:15:29.540 --> 00:15:32.170
of what projects they deemed to be
interesting and important and it often

00:15:32.170 --> 00:15:32.180
interesting and important and it often
 

00:15:32.180 --> 00:15:34.510
interesting and important and it often
gives young startups the bill or

00:15:34.510 --> 00:15:34.520
gives young startups the bill or
 

00:15:34.520 --> 00:15:35.890
gives young startups the bill or
nonprofits to kind of get a foothold

00:15:35.890 --> 00:15:35.900
nonprofits to kind of get a foothold
 

00:15:35.900 --> 00:15:38.410
nonprofits to kind of get a foothold
going and then hopefully they can scale

00:15:38.410 --> 00:15:38.420
going and then hopefully they can scale
 

00:15:38.420 --> 00:15:41.620
going and then hopefully they can scale
and raise the money from there so this

00:15:41.620 --> 00:15:41.630
and raise the money from there so this
 

00:15:41.630 --> 00:15:43.060
and raise the money from there so this
is a space that I do think needs a lot

00:15:43.060 --> 00:15:43.070
is a space that I do think needs a lot
 

00:15:43.070 --> 00:15:46.390
is a space that I do think needs a lot
of innovation but I think democratizing

00:15:46.390 --> 00:15:46.400
of innovation but I think democratizing
 

00:15:46.400 --> 00:15:48.850
of innovation but I think democratizing
that process is one potential step

00:15:48.850 --> 00:15:48.860
that process is one potential step
 

00:15:48.860 --> 00:15:51.670
that process is one potential step
that's that's helping we have a question

00:15:51.670 --> 00:15:51.680
that's that's helping we have a question
 

00:15:51.680 --> 00:15:53.890
that's that's helping we have a question
from the audience this is taking the

00:15:53.890 --> 00:15:53.900
from the audience this is taking the
 

00:15:53.900 --> 00:15:55.090
from the audience this is taking the
conversation in a slightly different

00:15:55.090 --> 00:15:55.100
conversation in a slightly different
 

00:15:55.100 --> 00:15:57.130
conversation in a slightly different
direction but perhaps we can end on this

00:15:57.130 --> 00:15:57.140
direction but perhaps we can end on this
 

00:15:57.140 --> 00:16:00.100
direction but perhaps we can end on this
more funny note will a I make people

00:16:00.100 --> 00:16:00.110
more funny note will a I make people
 

00:16:00.110 --> 00:16:06.970
more funny note will a I make people
lazy Michael so I you know people before

00:16:06.970 --> 00:16:06.980
lazy Michael so I you know people before
 

00:16:06.980 --> 00:16:10.660
lazy Michael so I you know people before
stood the gps's would make us unable to

00:16:10.660 --> 00:16:10.670
stood the gps's would make us unable to
 

00:16:10.670 --> 00:16:13.230
stood the gps's would make us unable to
travel nothing quite the reverse I

00:16:13.230 --> 00:16:13.240
travel nothing quite the reverse I
 

00:16:13.240 --> 00:16:15.460
travel nothing quite the reverse I
really like learning new ways to go to

00:16:15.460 --> 00:16:15.470
really like learning new ways to go to
 

00:16:15.470 --> 00:16:17.710
really like learning new ways to go to
places and I don't see any reason why I

00:16:17.710 --> 00:16:17.720
places and I don't see any reason why I
 

00:16:17.720 --> 00:16:22.180
places and I don't see any reason why I
actually make us lazy I think that smart

00:16:22.180 --> 00:16:22.190
actually make us lazy I think that smart
 

00:16:22.190 --> 00:16:23.770
actually make us lazy I think that smart
phones are actually quite stimulating

00:16:23.770 --> 00:16:23.780
phones are actually quite stimulating
 

00:16:23.780 --> 00:16:27.550
phones are actually quite stimulating
and you know I think that we might I

00:16:27.550 --> 00:16:27.560
and you know I think that we might I
 

00:16:27.560 --> 00:16:30.310
and you know I think that we might I
mean a bigger dangerous to get by a car

00:16:30.310 --> 00:16:30.320
mean a bigger dangerous to get by a car
 

00:16:30.320 --> 00:16:33.100
mean a bigger dangerous to get by a car
while you cross the road to an email but

00:16:33.100 --> 00:16:33.110
while you cross the road to an email but
 

00:16:33.110 --> 00:16:36.550
while you cross the road to an email but
you know otherwise I don't think so an

00:16:36.550 --> 00:16:36.560
you know otherwise I don't think so an
 

00:16:36.560 --> 00:16:40.540
you know otherwise I don't think so an
economist I do not recognize words like

00:16:40.540 --> 00:16:40.550
economist I do not recognize words like
 

00:16:40.550 --> 00:16:41.050
economist I do not recognize words like
lazy

00:16:41.050 --> 00:16:41.060
lazy
 

00:16:41.060 --> 00:16:46.510
lazy
I only know leisure preference the fact

00:16:46.510 --> 00:16:46.520
I only know leisure preference the fact
 

00:16:46.520 --> 00:16:49.360
I only know leisure preference the fact
of the matter is that in my lifetime and

00:16:49.360 --> 00:16:49.370
of the matter is that in my lifetime and
 

00:16:49.370 --> 00:16:51.370
of the matter is that in my lifetime and
gives you an idea of how long we've been

00:16:51.370 --> 00:16:51.380
gives you an idea of how long we've been
 

00:16:51.380 --> 00:16:53.980
gives you an idea of how long we've been
around it was one of the revolutionary

00:16:53.980 --> 00:16:53.990
around it was one of the revolutionary
 

00:16:53.990 --> 00:16:55.240
around it was one of the revolutionary
changes were introduced we're

00:16:55.240 --> 00:16:55.250
changes were introduced we're
 

00:16:55.250 --> 00:16:57.190
changes were introduced we're
calculating machine I'm not talking

00:16:57.190 --> 00:16:57.200
calculating machine I'm not talking
 

00:16:57.200 --> 00:16:58.750
calculating machine I'm not talking
computers I'm just basically machine and

00:16:58.750 --> 00:16:58.760
computers I'm just basically machine and
 

00:16:58.760 --> 00:17:02.140
computers I'm just basically machine and
allows you to multiply divide add and

00:17:02.140 --> 00:17:02.150
allows you to multiply divide add and
 

00:17:02.150 --> 00:17:05.079
allows you to multiply divide add and
subtract and people always said well if

00:17:05.079 --> 00:17:05.089
subtract and people always said well if
 

00:17:05.089 --> 00:17:06.670
subtract and people always said well if
you introduce machines will people not

00:17:06.670 --> 00:17:06.680
you introduce machines will people not
 

00:17:06.680 --> 00:17:09.520
you introduce machines will people not
lose their knowledge of erasmus ik and

00:17:09.520 --> 00:17:09.530
lose their knowledge of erasmus ik and
 

00:17:09.530 --> 00:17:11.890
lose their knowledge of erasmus ik and
now we have computers that allow us to

00:17:11.890 --> 00:17:11.900
now we have computers that allow us to
 

00:17:11.900 --> 00:17:13.329
now we have computers that allow us to
run regressions and dukkha and do

00:17:13.329 --> 00:17:13.339
run regressions and dukkha and do
 

00:17:13.339 --> 00:17:15.280
run regressions and dukkha and do
computer program programming and so so

00:17:15.280 --> 00:17:15.290
computer program programming and so so
 

00:17:15.290 --> 00:17:17.620
computer program programming and so so
don't we lose the ability to think and

00:17:17.620 --> 00:17:17.630
don't we lose the ability to think and
 

00:17:17.630 --> 00:17:20.440
don't we lose the ability to think and
the answer is no I don't think AI makes

00:17:20.440 --> 00:17:20.450
the answer is no I don't think AI makes
 

00:17:20.450 --> 00:17:24.670
the answer is no I don't think AI makes
us lazy what AI will do it will take our

00:17:24.670 --> 00:17:24.680
us lazy what AI will do it will take our
 

00:17:24.680 --> 00:17:27.100
us lazy what AI will do it will take our
energies and channel them in more

00:17:27.100 --> 00:17:27.110
energies and channel them in more
 

00:17:27.110 --> 00:17:29.440
energies and channel them in more
productive more effective directions

00:17:29.440 --> 00:17:29.450
productive more effective directions
 

00:17:29.450 --> 00:17:31.540
productive more effective directions
because somebody's gonna do the grudge

00:17:31.540 --> 00:17:31.550
because somebody's gonna do the grudge
 

00:17:31.550 --> 00:17:34.720
because somebody's gonna do the grudge
work for us that I think is a big step

00:17:34.720 --> 00:17:34.730
work for us that I think is a big step
 

00:17:34.730 --> 00:17:35.900
work for us that I think is a big step
forward

00:17:35.900 --> 00:17:35.910
forward
 

00:17:35.910 --> 00:17:38.540
forward
scenery doesn't make people lazy it just

00:17:38.540 --> 00:17:38.550
scenery doesn't make people lazy it just
 

00:17:38.550 --> 00:17:41.540
scenery doesn't make people lazy it just
redirects their energy usually in more

00:17:41.540 --> 00:17:41.550
redirects their energy usually in more
 

00:17:41.550 --> 00:17:43.790
redirects their energy usually in more
productive ways in that sense I am a

00:17:43.790 --> 00:17:43.800
productive ways in that sense I am a
 

00:17:43.800 --> 00:17:46.070
productive ways in that sense I am a
great optimist in that sense I really

00:17:46.070 --> 00:17:46.080
great optimist in that sense I really
 

00:17:46.080 --> 00:17:50.720
great optimist in that sense I really
feel but who directs is an issue I mean

00:17:50.720 --> 00:17:50.730
feel but who directs is an issue I mean
 

00:17:50.730 --> 00:17:52.700
feel but who directs is an issue I mean
we talk about hand phones smart phones

00:17:52.700 --> 00:17:52.710
we talk about hand phones smart phones
 

00:17:52.710 --> 00:17:54.860
we talk about hand phones smart phones
fine but there was a study that shows

00:17:54.860 --> 00:17:54.870
fine but there was a study that shows
 

00:17:54.870 --> 00:17:56.780
fine but there was a study that shows
you know in a particular country there's

00:17:56.780 --> 00:17:56.790
you know in a particular country there's
 

00:17:56.790 --> 00:17:58.850
you know in a particular country there's
more people who have hand phones than

00:17:58.850 --> 00:17:58.860
more people who have hand phones than
 

00:17:58.860 --> 00:18:01.520
more people who have hand phones than
public toilets so public solid is still

00:18:01.520 --> 00:18:01.530
public toilets so public solid is still
 

00:18:01.530 --> 00:18:03.320
public toilets so public solid is still
an issue in that particular country but

00:18:03.320 --> 00:18:03.330
an issue in that particular country but
 

00:18:03.330 --> 00:18:04.520
an issue in that particular country but
then there are a lot of people with hand

00:18:04.520 --> 00:18:04.530
then there are a lot of people with hand
 

00:18:04.530 --> 00:18:06.020
then there are a lot of people with hand
phones so we don't see the balance at

00:18:06.020 --> 00:18:06.030
phones so we don't see the balance at
 

00:18:06.030 --> 00:18:08.210
phones so we don't see the balance at
all it's where technology is taking

00:18:08.210 --> 00:18:08.220
all it's where technology is taking
 

00:18:08.220 --> 00:18:09.800
all it's where technology is taking
that's where the basic human needs are

00:18:09.800 --> 00:18:09.810
that's where the basic human needs are
 

00:18:09.810 --> 00:18:12.200
that's where the basic human needs are
not even taking into account as far as

00:18:12.200 --> 00:18:12.210
not even taking into account as far as
 

00:18:12.210 --> 00:18:16.190
not even taking into account as far as
technology is concerned so I mean I I

00:18:16.190 --> 00:18:16.200
technology is concerned so I mean I I
 

00:18:16.200 --> 00:18:18.560
technology is concerned so I mean I I
agree that the opportunity is the

00:18:18.560 --> 00:18:18.570
agree that the opportunity is the
 

00:18:18.570 --> 00:18:19.700
agree that the opportunity is the
affordability and scalability of

00:18:19.700 --> 00:18:19.710
affordability and scalability of
 

00:18:19.710 --> 00:18:21.200
affordability and scalability of
technology that hopefully over time that

00:18:21.200 --> 00:18:21.210
technology that hopefully over time that
 

00:18:21.210 --> 00:18:23.030
technology that hopefully over time that
will correct itself and I do think it

00:18:23.030 --> 00:18:23.040
will correct itself and I do think it
 

00:18:23.040 --> 00:18:24.590
will correct itself and I do think it
needs to be an intentional design choice

00:18:24.590 --> 00:18:24.600
needs to be an intentional design choice
 

00:18:24.600 --> 00:18:27.530
needs to be an intentional design choice
as we create these technologies to make

00:18:27.530 --> 00:18:27.540
as we create these technologies to make
 

00:18:27.540 --> 00:18:29.660
as we create these technologies to make
sure again they support our human values

00:18:29.660 --> 00:18:29.670
sure again they support our human values
 

00:18:29.670 --> 00:18:31.550
sure again they support our human values
and I do think people are inherently

00:18:31.550 --> 00:18:31.560
and I do think people are inherently
 

00:18:31.560 --> 00:18:33.680
and I do think people are inherently
we're curious we seek out meaning in our

00:18:33.680 --> 00:18:33.690
we're curious we seek out meaning in our
 

00:18:33.690 --> 00:18:35.210
we're curious we seek out meaning in our
lives I don't think it's gonna make us

00:18:35.210 --> 00:18:35.220
lives I don't think it's gonna make us
 

00:18:35.220 --> 00:18:37.760
lives I don't think it's gonna make us
lazy I think we are driven by these

00:18:37.760 --> 00:18:37.770
lazy I think we are driven by these
 

00:18:37.770 --> 00:18:39.590
lazy I think we are driven by these
things that lead to a rich fulfilling

00:18:39.590 --> 00:18:39.600
things that lead to a rich fulfilling
 

00:18:39.600 --> 00:18:41.660
things that lead to a rich fulfilling
life and I think we will leverage these

00:18:41.660 --> 00:18:41.670
life and I think we will leverage these
 

00:18:41.670 --> 00:18:43.760
life and I think we will leverage these
technologies to facilitate our ability

00:18:43.760 --> 00:18:43.770
technologies to facilitate our ability
 

00:18:43.770 --> 00:18:48.380
technologies to facilitate our ability
to do so great so I will ask us to end

00:18:48.380 --> 00:18:48.390
to do so great so I will ask us to end
 

00:18:48.390 --> 00:18:51.650
to do so great so I will ask us to end
with just one line kind of summary of

00:18:51.650 --> 00:18:51.660
with just one line kind of summary of
 

00:18:51.660 --> 00:18:54.170
with just one line kind of summary of
your view on how a I will impact

00:18:54.170 --> 00:18:54.180
your view on how a I will impact
 

00:18:54.180 --> 00:18:56.900
your view on how a I will impact
humanity and think of it in terms of a

00:18:56.900 --> 00:18:56.910
humanity and think of it in terms of a
 

00:18:56.910 --> 00:18:58.760
humanity and think of it in terms of a
tweet so maybe a hundred and forty

00:18:58.760 --> 00:18:58.770
tweet so maybe a hundred and forty
 

00:18:58.770 --> 00:19:03.800
tweet so maybe a hundred and forty
characters max I'm not a tweeter but I

00:19:03.800 --> 00:19:03.810
characters max I'm not a tweeter but I
 

00:19:03.810 --> 00:19:07.400
characters max I'm not a tweeter but I
would just say that technology is a

00:19:07.400 --> 00:19:07.410
would just say that technology is a
 

00:19:07.410 --> 00:19:09.220
would just say that technology is a
great opportunity just go with it I

00:19:09.220 --> 00:19:09.230
great opportunity just go with it I
 

00:19:09.230 --> 00:19:12.170
great opportunity just go with it I
would say that technology needs to be

00:19:12.170 --> 00:19:12.180
would say that technology needs to be
 

00:19:12.180 --> 00:19:13.460
would say that technology needs to be
intentionally designed to promote human

00:19:13.460 --> 00:19:13.470
intentionally designed to promote human
 

00:19:13.470 --> 00:19:14.240
intentionally designed to promote human
flourishing

00:19:14.240 --> 00:19:14.250
flourishing
 

00:19:14.250 --> 00:19:16.910
flourishing
I would agree also that but needs to be

00:19:16.910 --> 00:19:16.920
I would agree also that but needs to be
 

00:19:16.920 --> 00:19:19.190
I would agree also that but needs to be
balanced where the human concentration

00:19:19.190 --> 00:19:19.200
balanced where the human concentration
 

00:19:19.200 --> 00:19:22.580
balanced where the human concentration
becomes an important issue and for all

00:19:22.580 --> 00:19:22.590
becomes an important issue and for all
 

00:19:22.590 --> 00:19:24.760
becomes an important issue and for all
of those who think that the low-hanging

00:19:24.760 --> 00:19:24.770
of those who think that the low-hanging
 

00:19:24.770 --> 00:19:27.380
of those who think that the low-hanging
fruits of Technology have been picked

00:19:27.380 --> 00:19:27.390
fruits of Technology have been picked
 

00:19:27.390 --> 00:19:29.300
fruits of Technology have been picked
and that we've made all the easy

00:19:29.300 --> 00:19:29.310
and that we've made all the easy
 

00:19:29.310 --> 00:19:30.980
and that we've made all the easy
invention and now it gets harder and

00:19:30.980 --> 00:19:30.990
invention and now it gets harder and
 

00:19:30.990 --> 00:19:34.550
invention and now it gets harder and
harder my prediction is you ain't seen

00:19:34.550 --> 00:19:34.560
harder my prediction is you ain't seen
 

00:19:34.560 --> 00:19:37.029
harder my prediction is you ain't seen
nothing yet

00:19:37.029 --> 00:19:37.039
nothing yet
 

00:19:37.039 --> 00:19:40.580
nothing yet
thank you so much

