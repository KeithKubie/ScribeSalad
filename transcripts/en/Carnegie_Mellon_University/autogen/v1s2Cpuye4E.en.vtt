WEBVTT
Kind: captions
Language: en

00:00:04.370 --> 00:00:08.210
I'm here at Davos 2016 this is my first

00:00:08.210 --> 00:00:08.220
I'm here at Davos 2016 this is my first
 

00:00:08.220 --> 00:00:09.860
I'm here at Davos 2016 this is my first
time in Davos and I'm really excited to

00:00:09.860 --> 00:00:09.870
time in Davos and I'm really excited to
 

00:00:09.870 --> 00:00:11.990
time in Davos and I'm really excited to
be here at forums like these where we

00:00:11.990 --> 00:00:12.000
be here at forums like these where we
 

00:00:12.000 --> 00:00:14.570
be here at forums like these where we
have CEOs and we have heads of state

00:00:14.570 --> 00:00:14.580
have CEOs and we have heads of state
 

00:00:14.580 --> 00:00:16.400
have CEOs and we have heads of state
it's really important that privacy be

00:00:16.400 --> 00:00:16.410
it's really important that privacy be
 

00:00:16.410 --> 00:00:18.710
it's really important that privacy be
part of our discussion I study human

00:00:18.710 --> 00:00:18.720
part of our discussion I study human
 

00:00:18.720 --> 00:00:20.689
part of our discussion I study human
factors in security and privacy we're

00:00:20.689 --> 00:00:20.699
factors in security and privacy we're
 

00:00:20.699 --> 00:00:22.759
factors in security and privacy we're
doing research to understand how

00:00:22.759 --> 00:00:22.769
doing research to understand how
 

00:00:22.769 --> 00:00:24.710
doing research to understand how
security and privacy impact people and

00:00:24.710 --> 00:00:24.720
security and privacy impact people and
 

00:00:24.720 --> 00:00:26.929
security and privacy impact people and
how to build tools that people can

00:00:26.929 --> 00:00:26.939
how to build tools that people can
 

00:00:26.939 --> 00:00:28.820
how to build tools that people can
actually use right now when we talk to

00:00:28.820 --> 00:00:28.830
actually use right now when we talk to
 

00:00:28.830 --> 00:00:30.650
actually use right now when we talk to
consumers they say yeah I don't

00:00:30.650 --> 00:00:30.660
consumers they say yeah I don't
 

00:00:30.660 --> 00:00:32.749
consumers they say yeah I don't
understand online advertising I bought a

00:00:32.749 --> 00:00:32.759
understand online advertising I bought a
 

00:00:32.759 --> 00:00:34.549
understand online advertising I bought a
pair of shoes yesterday and now today

00:00:34.549 --> 00:00:34.559
pair of shoes yesterday and now today
 

00:00:34.559 --> 00:00:36.830
pair of shoes yesterday and now today
all the ads I get her for shoes and

00:00:36.830 --> 00:00:36.840
all the ads I get her for shoes and
 

00:00:36.840 --> 00:00:38.420
all the ads I get her for shoes and
that's really creepy I don't understand

00:00:38.420 --> 00:00:38.430
that's really creepy I don't understand
 

00:00:38.430 --> 00:00:39.979
that's really creepy I don't understand
how they know that about me we're going

00:00:39.979 --> 00:00:39.989
how they know that about me we're going
 

00:00:39.989 --> 00:00:42.110
how they know that about me we're going
to have more and more devices collecting

00:00:42.110 --> 00:00:42.120
to have more and more devices collecting
 

00:00:42.120 --> 00:00:44.479
to have more and more devices collecting
data about us from all different kinds

00:00:44.479 --> 00:00:44.489
data about us from all different kinds
 

00:00:44.489 --> 00:00:46.430
data about us from all different kinds
of sources our research suggests that

00:00:46.430 --> 00:00:46.440
of sources our research suggests that
 

00:00:46.440 --> 00:00:49.520
of sources our research suggests that
putting users in control is part of the

00:00:49.520 --> 00:00:49.530
putting users in control is part of the
 

00:00:49.530 --> 00:00:51.770
putting users in control is part of the
solution so at carnegie mellon we're

00:00:51.770 --> 00:00:51.780
solution so at carnegie mellon we're
 

00:00:51.780 --> 00:00:53.930
solution so at carnegie mellon we're
building a personal privacy assistant

00:00:53.930 --> 00:00:53.940
building a personal privacy assistant
 

00:00:53.940 --> 00:00:56.299
building a personal privacy assistant
and the idea is that it will run on your

00:00:56.299 --> 00:00:56.309
and the idea is that it will run on your
 

00:00:56.309 --> 00:00:58.639
and the idea is that it will run on your
smartphone or your SmartWatch and it

00:00:58.639 --> 00:00:58.649
smartphone or your SmartWatch and it
 

00:00:58.649 --> 00:01:01.580
smartphone or your SmartWatch and it
will have a listen in the air for these

00:01:01.580 --> 00:01:01.590
will have a listen in the air for these
 

00:01:01.590 --> 00:01:03.529
will have a listen in the air for these
privacy policies that these sensors have

00:01:03.529 --> 00:01:03.539
privacy policies that these sensors have
 

00:01:03.539 --> 00:01:05.539
privacy policies that these sensors have
and provide you with controls this is

00:01:05.539 --> 00:01:05.549
and provide you with controls this is
 

00:01:05.549 --> 00:01:14.260
and provide you with controls this is
putting the power back to the consumer

00:01:14.260 --> 00:01:14.270
 

00:01:14.270 --> 00:01:16.329
you

