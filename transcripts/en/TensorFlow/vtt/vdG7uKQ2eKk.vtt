WEBVTT
Kind: captions
Language: en

00:00:00.213 --> 00:00:02.414
♪ (music) ♪

00:00:06.164 --> 00:00:07.531
Hello, everyone.

00:00:10.508 --> 00:00:14.116
First, thanks everyone for coming
to attend the Dev Summit.

00:00:14.116 --> 00:00:16.334
And second, thanks
for staying around this long.

00:00:16.334 --> 00:00:18.170
I know it's been a very long day.

00:00:18.170 --> 00:00:21.332
And there has been a lot of information
that we've been throwing at you.

00:00:21.332 --> 00:00:24.382
But we've got much, much more
and many more announcements to come.

00:00:24.382 --> 00:00:26.663
So please stick with me.

00:00:26.663 --> 00:00:28.635
My name is Clemens, and this is Raz.

00:00:28.635 --> 00:00:31.337
We're going to talk about
TensorFlow Extended today.

00:00:31.337 --> 00:00:34.722
But before we do this,
I'm going to do a quick survey.

00:00:34.722 --> 00:00:36.558
Can I get a quick show of hands?

00:00:36.558 --> 00:00:40.514
How many of you do machine learning
in a research or academic setting?

00:00:41.744 --> 00:00:42.785
Okay.

00:00:42.785 --> 00:00:43.887
Quite a big number.

00:00:43.887 --> 00:00:47.206
Now how many of you do
machine learning in a production setting?

00:00:47.206 --> 00:00:48.184
Okay.

00:00:48.184 --> 00:00:49.458
That looks about half-half.

00:00:49.458 --> 00:00:51.937
Obviously, also a lot of overlap.

00:00:51.937 --> 00:00:55.414
So for those of you who do
machine learning in a production setting,

00:00:55.414 --> 00:00:57.823
how many of you have
agreed with this statement?

00:00:59.053 --> 00:01:00.718
Yeah? Some? Okay.

00:01:00.718 --> 00:01:02.868
I see a lot of hands coming up.

00:01:02.868 --> 00:01:05.204
So everyone that I speak with
who's doing machine learning

00:01:05.204 --> 00:01:07.469
in production agrees with this statement:

00:01:07.469 --> 00:01:10.879
"Doing machine learning
in production is hard," and it's too hard.

00:01:10.879 --> 00:01:13.629
Because after all, we actually want
to democratize machine learning

00:01:13.629 --> 00:01:17.309
and get more and more people
to allow them to deploy machine learning

00:01:17.309 --> 00:01:18.868
in their products.

00:01:19.368 --> 00:01:22.996
One of the main reasons why
it's still hard is because in addition

00:01:22.996 --> 00:01:24.877
to the actual machine learning.

00:01:24.877 --> 00:01:28.476
So this small orange box
where you actually use TensorFlow,

00:01:28.476 --> 00:01:31.258
you may use Keras 
to put together your layers

00:01:31.258 --> 00:01:33.006
and train your model.

00:01:33.006 --> 00:01:35.397
You need to worry about so much more.

00:01:35.397 --> 00:01:37.854
There's all of these other things
that you have to worry about

00:01:37.854 --> 00:01:40.984
to actually deploy machine
learning in a production setting

00:01:40.984 --> 00:01:43.709
and serve it within your product.

00:01:43.709 --> 00:01:45.320
Now the good news
is that this is exactly

00:01:45.320 --> 00:01:47.447
what TensorFlow Extended is about.

00:01:47.447 --> 00:01:49.971
TFX in [inaudible] Google
is an [inaudible] machine learning

00:01:49.971 --> 00:01:54.876
platform that allows our developers
to go all the way from data to production

00:01:54.876 --> 00:01:57.538
and serving machine learning models

00:01:57.538 --> 00:01:59.938
as fast as possible.

00:01:59.938 --> 00:02:03.227
Now before we introduce TFX,

00:02:03.227 --> 00:02:05.597
we saw that going through this process

00:02:05.597 --> 00:02:10.234
of writing some of these components,
some of them didn't exist before.

00:02:10.234 --> 00:02:12.320
Gluing them together
and actually getting to

00:02:12.320 --> 00:02:15.707
a launch took anywhere
between six to nine months,

00:02:15.707 --> 00:02:18.069
sometimes even a year.

00:02:18.069 --> 00:02:21.457
Once we've deployed TFX
and allow developers to use it,

00:02:21.457 --> 00:02:24.971
in many cases, people can use
this platform and get up and running

00:02:24.971 --> 00:02:29.528
with it in a day and actually get to
a deployable model in production

00:02:29.528 --> 00:02:33.632
in the order of weeks or in just a month.

00:02:33.632 --> 00:02:37.575
Now, TFX is a very large
system and platform that consists

00:02:37.575 --> 00:02:39.937
of a lot of components
and a lot of services

00:02:39.937 --> 00:02:44.503
so unfortunately I can't talk about
all of this in the next 25 minutes.

00:02:44.503 --> 00:02:48.350
So we're only going to be able to
cover a small part of it but we're talking

00:02:48.350 --> 00:02:52.640
about the things that we've already
open sourced and made available to you.

00:02:52.640 --> 00:02:56.022
First, we're going to talk
about TensorFlow Transform

00:02:56.022 --> 00:02:58.787
and show you how to apply
transformations on your data

00:02:58.787 --> 00:03:02.660
consistently between training and serving.

00:03:02.660 --> 00:03:06.426
Next, Raz is going to introduce you
to a new product that we're open sourcing

00:03:06.426 --> 00:03:08.862
called TensorFlow Model Analysis.

00:03:08.862 --> 00:03:12.840
We're going to give a demo of how
all of this works together end to end

00:03:13.630 --> 00:03:16.555
and then make a broader announcement
of our plans for TensorFlow Extended

00:03:16.555 --> 00:03:19.691
and sharing it the community.

00:03:19.691 --> 00:03:23.130
Let's jump into
TensorFlow Transform first.

00:03:23.130 --> 00:03:26.630
So, a typical ML pipeline 
that you may see in the wild

00:03:26.630 --> 00:03:28.390
is during training,

00:03:28.390 --> 00:03:33.076
you usually have a distributed data
pipeline that applies transformations

00:03:33.076 --> 00:03:34.789
to your data.

00:03:34.789 --> 00:03:37.559
Because usually you train
in a large amount of data,

00:03:37.559 --> 00:03:39.902
this needs to be distributed,

00:03:39.902 --> 00:03:42.902
and you're on this pipeline

00:03:42.902 --> 00:03:45.707
and sometimes materialize
the output before you actually

00:03:45.707 --> 00:03:47.481
put it into your trainer.

00:03:47.481 --> 00:03:49.103
Now at serving time,

00:03:49.103 --> 00:03:54.001
we need to find a way to somehow
replay those exact transformations online.

00:03:54.001 --> 00:03:58.039
As a new request comes in,
it needs to be sent to your model.

00:03:58.039 --> 00:04:00.021
There's a couple of challenges with this.

00:04:00.021 --> 00:04:04.733
The first one is, usually those two
things are very different code paths.

00:04:04.733 --> 00:04:08.328
The data distribution systems
that you would use for batch processing

00:04:08.328 --> 00:04:12.144
are very different from the libraries
and tools that you would use to--

00:04:12.144 --> 00:04:15.983
in real time transform data
to make a request to your model.

00:04:15.983 --> 00:04:18.553
Now we have two different code paths.

00:04:18.553 --> 00:04:22.926
Second, in many cases,
it's very hard to keep those two in sync.

00:04:22.926 --> 00:04:24.719
I'm sure a lot of you have seen this.

00:04:24.719 --> 00:04:28.811
You change your batch processing pipeline
and introduce a new feature or change

00:04:28.811 --> 00:04:32.356
how it behaves and you somehow
need to make sure that the code

00:04:32.356 --> 00:04:35.730
that they actually use in your
production system is changed

00:04:35.730 --> 00:04:39.081
at the same time and is kept in sync.

00:04:39.081 --> 00:04:42.285
The third problem is,
sometimes you actually want to deploy

00:04:42.285 --> 00:04:46.842
your TensorFlow machine learning
model in many different environments.

00:04:46.842 --> 00:04:49.767
You want to deploy it in a mobile device;
you want to deploy in a server;

00:04:49.767 --> 00:04:52.675
maybe you want to put it on a car;
now suddenly you have

00:04:52.675 --> 00:04:55.063
three different environments
where you have to apply

00:04:55.063 --> 00:04:57.257
these transformations,
and maybe there's different languages

00:04:57.257 --> 00:04:59.585
that you use for those,
and it's also very hard

00:04:59.585 --> 00:05:01.215
to keep those in sync.

00:05:03.585 --> 00:05:07.273
And this introduces something
that we call training serving skew,

00:05:07.273 --> 00:05:10.225
where the transformations that you do
at training time may be different

00:05:10.225 --> 00:05:14.769
from the ones in serving time,
which usually leads to bad quality

00:05:14.769 --> 00:05:17.034
of your serving model.

00:05:17.034 --> 00:05:20.379
TensorFlow Transform addresses this
by helping you write

00:05:20.379 --> 00:05:24.262
your data processing job 
at training time,

00:05:24.262 --> 00:05:28.072
so actually help you create those 
data pipelines to do those

00:05:28.072 --> 00:05:30.651
transformations, and at the same time,

00:05:30.651 --> 00:05:33.811
it emits a TensorFlow graph that can be

00:05:33.811 --> 00:05:37.760
in line with your training model
and also your serving model.

00:05:37.760 --> 00:05:43.055
Now what this does is,
it actually hermetically seals the model,

00:05:43.055 --> 00:05:46.015
and your model takes
a raw data request as input,

00:05:46.015 --> 00:05:48.099
and all of the transformations
are actually happening

00:05:48.099 --> 00:05:50.382
within the TensorFlow graph.

00:05:50.382 --> 00:05:55.133
This is a lot of advantages,
one of them is that you no longer

00:05:55.133 --> 00:05:59.199
have any code in your serving
environment that does these

00:05:59.199 --> 00:06:03.220
transformations because they're all
being done in the TensorFlow graph.

00:06:03.220 --> 00:06:06.489
Another one is wherever you
deploy this TensorFlow model,

00:06:06.489 --> 00:06:09.813
all of those transformations
are applied in a consistent way.

00:06:09.813 --> 00:06:12.863
No matter where this
graph is being evaluated.

00:06:12.863 --> 00:06:15.273
Let's see how that looks like.

00:06:15.273 --> 00:06:17.853
This is a code snippet 
of a pre-processing function

00:06:17.853 --> 00:06:20.141
that you would write with TF Transform.

00:06:20.141 --> 00:06:23.067
I'm just going to walk you
through what happens here

00:06:23.067 --> 00:06:25.508
and what we need to do for this.

00:06:25.508 --> 00:06:28.427
First thing we do
is normalize this feature.

00:06:28.427 --> 00:06:30.988
As all of you know, 
in order to re-normalize a feature

00:06:30.988 --> 00:06:33.885
we need to compute the mean
and the standard deviation,

00:06:33.885 --> 00:06:36.835
and to actually apply this transformation,
we need to subtract by the mean

00:06:36.835 --> 00:06:39.188
and divide by the center of deviation.

00:06:39.188 --> 00:06:42.749
So what has to happen is,
for the input feature X,

00:06:42.749 --> 00:06:46.244
we have to compute these
statistics which is a trivial task.

00:06:46.244 --> 00:06:50.124
If the data fits into a single
machine, you can do it easily.

00:06:50.124 --> 00:06:54.678
It's a non-trivial task if you have
a gigantic training data set

00:06:54.678 --> 00:06:56.908
and actually have to compute
these metrics...

00:06:56.908 --> 00:06:58.746
...effectively.

00:06:58.746 --> 00:07:01.438
Once we have these metrics
we can actually apply this transformation

00:07:01.438 --> 00:07:03.135
to the feature.

00:07:03.135 --> 00:07:07.848
This is to show you that the output
of this transformation can then be,

00:07:07.848 --> 00:07:10.058
again, multiplied with another tensor--

00:07:10.058 --> 00:07:13.978
which is just a regular
TensorFlow transformation.

00:07:13.978 --> 00:07:17.990
And then in order to bucketize a feature,
you also again need to compute

00:07:17.990 --> 00:07:21.710
the bucket boundaries to actually
apply this transformation.

00:07:21.710 --> 00:07:26.236
And again, this is a distributed data job
to compute those metrics for the result

00:07:26.236 --> 00:07:28.256
of an already transformed feature.

00:07:28.256 --> 00:07:32.488
This is another benefit to then 
actually apply this transformation.

00:07:34.198 --> 00:07:37.577
The next examples just show you
that in the same function it can apply

00:07:37.577 --> 00:07:42.359
any other tensor in tensor [inaudible]
function and there's also some

00:07:42.359 --> 00:07:47.579
of what we call mappers in TF transform
that don't require this analyze phase.

00:07:47.579 --> 00:07:51.044
So, N-grams doesn't require us
to actually run a data pipeline

00:07:51.044 --> 00:07:53.540
to compute anything.

00:07:53.540 --> 00:07:56.778
Now what happens here 
is that these orange boxes

00:07:56.778 --> 00:07:59.068
are what we call analyzers.

00:07:59.068 --> 00:08:04.040
We realize those as actual data pipelines
that compute those metrics over your data.

00:08:04.040 --> 00:08:07.555
They're implemented using Apache Beam.

00:08:07.555 --> 00:08:09.889
And we're going to talk
about this more later.

00:08:09.889 --> 00:08:14.369
But what this allows us to do is actually
run this distributor data pipeline

00:08:14.369 --> 00:08:15.561
in different environments.

00:08:15.561 --> 00:08:18.163
There's different runners
for Apache Beam.

00:08:18.163 --> 00:08:21.822
And all of the transforms are just simple
instance to instance transformations

00:08:21.822 --> 00:08:23.721
using pure TensorFlow code.

00:08:25.441 --> 00:08:27.968
What happens when you
run TensorFlow Transform

00:08:27.968 --> 00:08:31.150
is that we actually run these
analyze phases,

00:08:31.150 --> 00:08:34.401
compute the results
of those analyze phases,

00:08:34.401 --> 00:08:38.103
and then inject the result 
as a constant in the TensorFlow graph--

00:08:38.103 --> 00:08:41.074
so this is on the right--
and in this graph,

00:08:41.074 --> 00:08:45.261
it's a hermetic TensorFlow graph
that applies all the transformations,

00:08:45.261 --> 00:08:48.362
and it can be in-lined
in your serving graph.

00:08:48.362 --> 00:08:50.505
So now your serving graph
has the transform graph

00:08:50.505 --> 00:08:53.802
as part of it and can play through
all of these transforms

00:08:53.802 --> 00:08:56.588
wherever you want to deploy
this TensorFlow model.

00:08:59.358 --> 00:09:01.732
What can be done
with TensorFlow Transform?

00:09:01.732 --> 00:09:05.362
At training time for the batch processing,
really anything that you can do

00:09:05.362 --> 00:09:07.580
with a distributed data pipeline.

00:09:07.580 --> 00:09:10.998
So there's a lot of flexibility here
with types of statistics you can compute.

00:09:10.998 --> 00:09:13.790
We provide a lot 
of utility functions for you,

00:09:13.790 --> 00:09:17.370
but you can also 
write custom data pipelines.

00:09:17.370 --> 00:09:20.910
And at serving time because we generate
a TensorFlow graph that applies

00:09:20.910 --> 00:09:24.245
these transformations-- 
we're limited to what you can do

00:09:24.245 --> 00:09:27.422
with a TensorFlow graph, 
but for all of you who know TensorFlow,

00:09:27.422 --> 00:09:29.902
there's a lot of flexibility
in there as well.

00:09:29.902 --> 00:09:32.453
Anything that you can do
in a TensorFlow graph,

00:09:32.453 --> 00:09:36.060
you can do with your transformations.

00:09:36.060 --> 00:09:39.025
Some of the common use cases
that we've seen, the ones on the left

00:09:39.025 --> 00:09:43.044
I just spoke about, you can scale
a continuous value to the <i>C-score</i>

00:09:43.044 --> 00:09:47.365
which is minimalization 
or to a value between 0 and 1.

00:09:47.365 --> 00:09:50.168
You can bucketize a continuous value.

00:09:50.168 --> 00:09:54.251
If you have text features,
you can apply Bag of Words or N-grams,

00:09:54.251 --> 00:09:56.490
or for feature crosses,
you can actually cross

00:09:56.490 --> 00:10:01.415
those strings and then generate
vocabs of the result of those crosses.

00:10:01.415 --> 00:10:04.433
As mentioned before, 
TF Transform is extremely powerful

00:10:04.433 --> 00:10:07.548
in actually being able to chain together
these transforms so you can apply

00:10:07.548 --> 00:10:11.494
transform under result
of a transform and so on.

00:10:11.494 --> 00:10:14.126
Another particular interesting
transform is actually applying

00:10:14.126 --> 00:10:15.984
another TensorFlow model.

00:10:15.984 --> 00:10:19.032
You've heard about the saved model before?

00:10:19.032 --> 00:10:22.034
If you have a saved model that
you can apply as a transformation,

00:10:22.034 --> 00:10:23.735
you can use this until you've transformed.

00:10:23.735 --> 00:10:25.704
Let's say you have an image
and you want to apply

00:10:25.704 --> 00:10:28.835
an inception model as it transforms
and then use the output of that

00:10:28.835 --> 00:10:31.855
inception model maybe to combine it
with some other feature

00:10:31.855 --> 00:10:34.313
or use it as an input feature
to your model.

00:10:34.313 --> 00:10:36.726
You can use any other
TensorFlow model

00:10:36.726 --> 00:10:39.835
that ends up being in-lined
in your transform graph

00:10:39.835 --> 00:10:42.446
and also in-lined in your serving graph.

00:10:44.416 --> 00:10:46.966
All of this is available today
and you can go check it out

00:10:46.966 --> 00:10:49.270
on <i>github.com/tensorflow/transform</i>.

00:10:49.270 --> 00:10:51.753
With this I'm going to hand it
over to Raz who's going to talk

00:10:51.753 --> 00:10:53.643
about TensorFlow Model Analysis.

00:10:55.703 --> 00:10:57.333
Alright, thanks Clemens.

00:10:58.323 --> 00:10:59.446
Hi, everyone.

00:10:59.446 --> 00:11:02.416
I'm really excited to talk about

00:11:02.416 --> 00:11:04.476
TensorFlow Model Analysis today.

00:11:04.476 --> 00:11:06.898
We're going to talk
a little bit about metrics.

00:11:09.418 --> 00:11:11.231
Let's see, next slide.

00:11:11.801 --> 00:11:14.241
Alright, so we can already
get metrics today right?

00:11:14.241 --> 00:11:16.922
We use TensorBoard.
TensorBoard's awesome.

00:11:16.922 --> 00:11:19.826
You saw an earlier presentation
today about TensorBoard.

00:11:19.826 --> 00:11:23.197
It's a great tool--
while you're training,

00:11:23.197 --> 00:11:25.878
you can watch your metics, right?

00:11:25.878 --> 00:11:29.288
If your training isn't going well,
you can save yourself

00:11:29.288 --> 00:11:31.377
a couple of hours of your life, right?

00:11:31.377 --> 00:11:34.034
Terminate the training, fix some things...

00:11:34.034 --> 00:11:35.947
Let's say you have 
your trained model already.

00:11:35.947 --> 00:11:38.212
Are we done with metics? Is that it?

00:11:38.212 --> 00:11:41.647
Is there any more to be said
about metics after we're done training?

00:11:41.647 --> 00:11:44.689
Well, of course, there is.

00:11:44.689 --> 00:11:48.559
We want to know how well
our trained model actually does

00:11:48.559 --> 00:11:50.490
for our target population.

00:11:52.020 --> 00:11:55.624
I would argue that we want to
do this in a distributed fashion

00:11:55.624 --> 00:11:56.818
over the entire data set.

00:11:56.818 --> 00:11:58.148
Why wouldn't we just sample?

00:11:58.148 --> 00:12:02.051
Why wouldn't we just save
more hours of our lives, right?

00:12:02.051 --> 00:12:05.457
And just sample,
make things fast and easy.

00:12:05.457 --> 00:12:08.158
Let's say you start with a large data set.

00:12:08.158 --> 00:12:09.827
Now you're going to slice that data set.

00:12:09.827 --> 00:12:13.248
You're going to say, "I'm going 
to look at people at noon time."

00:12:13.248 --> 00:12:15.267
Right? That's a feature.

00:12:15.267 --> 00:12:18.871
&gt;From Chicago, my hometown.

00:12:18.871 --> 00:12:20.988
Running on this particular device.

00:12:20.988 --> 00:12:24.459
Each of these slices reduce the size

00:12:24.459 --> 00:12:28.549
of your evaluation dataset by a factor.

00:12:28.549 --> 00:12:30.441
This is an exponential decline.

00:12:30.441 --> 00:12:34.638
By the time you're looking at
the experience for a particular...

00:12:35.388 --> 00:12:38.840
...set of users, you're not
left with very much data.

00:12:38.840 --> 00:12:42.767
And the error bars on your
performance measures, they're huge.

00:12:42.767 --> 00:12:45.817
I mean, how do you know that
the noise doesn't exceed your signal

00:12:45.817 --> 00:12:47.078
by that point, right?

00:12:47.078 --> 00:12:50.279
So really you want to start
with your larger dataset

00:12:50.279 --> 00:12:52.249
before you start slicing.

00:12:54.449 --> 00:12:57.497
Let's talk about a particular metric.

00:12:57.497 --> 00:12:58.564
I'm not sure--

00:12:58.564 --> 00:13:00.746
Who's heard of the <i>ROC Curve?</i>

00:13:00.746 --> 00:13:05.160
It's kind of an unknown thing
in machine learning these days.

00:13:05.160 --> 00:13:06.236
Okay.

00:13:07.426 --> 00:13:09.947
We have our ROC Curve,
and I'm going to talk about a concept

00:13:09.947 --> 00:13:12.073
that you may or may not be familiar with

00:13:12.073 --> 00:13:14.114
which is <i>ML Fairness</i>.

00:13:14.114 --> 00:13:15.656
So what is fairness?

00:13:16.736 --> 00:13:19.520
Fairness is a complicated topic.

00:13:19.520 --> 00:13:24.190
Fairness is basically how well
does our machine learning model do

00:13:24.190 --> 00:13:27.957
for different segments
of our population, okay?

00:13:29.187 --> 00:13:32.092
You don't just have one ROC Curve,

00:13:32.092 --> 00:13:35.052
you have an ROC Curve for every segment.

00:13:35.052 --> 00:13:38.550
You have an ROC Curve
for every group of users.

00:13:38.550 --> 00:13:41.858
Who here would run their business

00:13:41.858 --> 00:13:44.228
based on their top line metrics?

00:13:44.228 --> 00:13:46.663
No one! Right? That's crazy.

00:13:46.663 --> 00:13:49.558
You have to slice your metrics;
you have to go in and dive in

00:13:49.558 --> 00:13:52.912
and find out how things
are going so that lucky user,

00:13:52.912 --> 00:13:55.710
that black curve
on the top, great experience.

00:13:55.710 --> 00:13:57.912
That unlucky user, the blue curve?

00:13:57.912 --> 00:14:00.131
Not such a great experience.

00:14:02.141 --> 00:14:05.717
When can our models be
unfair to various users?

00:14:07.817 --> 00:14:11.700
One instance is if you simply
don't have a lot of data

00:14:11.700 --> 00:14:14.222
from which to draw your inferences.

00:14:14.222 --> 00:14:15.338
Right?

00:14:15.338 --> 00:14:18.439
We use Stochastic optimizers,

00:14:18.439 --> 00:14:21.299
and if we re-train the model,

00:14:21.299 --> 00:14:23.931
it does something different
every time, slightly.

00:14:23.931 --> 00:14:26.384
You're going to get a high variance
for some users just because

00:14:26.384 --> 00:14:28.158
you don't have a lot of data there.

00:14:28.158 --> 00:14:31.403
We may be incorporating data
from multiple data sources.

00:14:31.403 --> 00:14:34.532
Some data sources are more
biased than others.

00:14:34.532 --> 00:14:37.155
So some users just get
the short end of the deal, right?

00:14:37.155 --> 00:14:40.257
Whereas other users 
get the ideal experience.

00:14:40.257 --> 00:14:42.308
Our labels could be wrong. Right?

00:14:42.308 --> 00:14:45.933
All of these things can happen.

00:14:45.933 --> 00:14:47.699
Here's TensorFlow Model Analysis.

00:14:47.699 --> 00:14:52.612
You're looking here at the UI hosted
within a Jupyter Notebook.

00:14:52.612 --> 00:14:55.042
On the X-axis, we have our loss.

00:14:55.042 --> 00:14:58.571
You can see there's some
natural variance in the metrics.

00:14:58.571 --> 00:15:00.802
We're not always going to
get spot on the same precision

00:15:00.802 --> 00:15:04.329
and recall for every
segment of population.

00:15:04.329 --> 00:15:07.382
But sometimes you'll see...
what about those guys

00:15:07.382 --> 00:15:11.728
at the top there experiencing 
the highest amount of loss?

00:15:11.728 --> 00:15:14.122
Do they have something in common?

00:15:14.122 --> 00:15:15.226
We want to know this.

00:15:15.226 --> 00:15:17.199
Sometimes our users that...

00:15:19.159 --> 00:15:20.899
...get the poorest experience,

00:15:20.899 --> 00:15:24.217
they're sometimes 
our most vocal users, right?

00:15:25.667 --> 00:15:27.760
We all know this.

00:15:27.760 --> 00:15:30.826
I'd like to invite you 
to come visit <i>ml-fairness.com</i>.

00:15:30.826 --> 00:15:33.190
There's a deep literature about

00:15:33.190 --> 00:15:36.360
the mathematical side of ML Fairness.

00:15:36.360 --> 00:15:38.693
Once you've figured out how
to measure fairness,

00:15:38.693 --> 00:15:41.392
there's a deep literature
about what to do about it.

00:15:43.452 --> 00:15:47.871
How does TensorFlow Model Analysis
actually give you these sliced metrics?

00:15:47.871 --> 00:15:50.780
How did you go about 
getting these metrics?

00:15:50.780 --> 00:15:53.769
Today you export 
a saved model for serving.

00:15:53.769 --> 00:15:55.729
It's kind of a familiar thing.

00:15:56.839 --> 00:15:58.515
TensorFlow Model Analysis is simple.

00:15:58.515 --> 00:16:01.116
As it's simple, it's similar.

00:16:01.116 --> 00:16:04.413
You export a saved model for evaluation.

00:16:04.413 --> 00:16:06.913
Why are these models different?
Why export two?

00:16:06.913 --> 00:16:11.509
Well the eval graph that 
we serialize as a saved model

00:16:11.509 --> 00:16:14.000
has some additional annotations

00:16:14.000 --> 00:16:16.420
that allow our evaluation batch job

00:16:16.420 --> 00:16:19.777
to find the features, 
to find the prediction, to find the label.

00:16:19.777 --> 00:16:23.599
We don't want those things mixed in
with our serving graphs

00:16:23.599 --> 00:16:26.033
so you export a second one.

00:16:27.063 --> 00:16:28.163
So this is the <i>GitHub</i>.

00:16:28.163 --> 00:16:31.363
We just opened it, I think
last night at 4.30 pm.

00:16:31.363 --> 00:16:32.564
Check it out.

00:16:33.484 --> 00:16:36.232
We've been using it internally
for quite some time now.

00:16:36.232 --> 00:16:38.434
Now it's available externally as well.

00:16:39.884 --> 00:16:42.416
The GitHub has an example

00:16:42.416 --> 00:16:44.896
that kind of puts it all together

00:16:44.896 --> 00:16:48.056
so that you can try all these components
that we're talking about

00:16:48.056 --> 00:16:49.069
from your local machine.

00:16:49.069 --> 00:16:51.069
You don't have to get
an account anywhere.

00:16:51.069 --> 00:16:53.664
You just get cloned
and run the scripts

00:16:53.664 --> 00:16:54.948
and run the code lab.

00:16:54.948 --> 00:16:57.013
This is the Chicago Taxi Example.

00:16:57.013 --> 00:17:01.646
So we're using public data from--
publicly available data

00:17:01.646 --> 00:17:06.317
to determine which riders 
will tip their driver

00:17:06.317 --> 00:17:09.179
and which riders, shall we say,

00:17:09.179 --> 00:17:11.539
don't have enough money to tip today.

00:17:13.309 --> 00:17:16.232
What does fairness mean in this context?

00:17:16.232 --> 00:17:18.719
So our model is going 
to make some predictions.

00:17:21.249 --> 00:17:25.652
We may want to slice these
predictions by time of day.

00:17:25.652 --> 00:17:28.192
During rush hour we're going 
to have a lot of data so hopefully

00:17:28.192 --> 00:17:32.166
our model's going to be fair
if that data is not biased.

00:17:32.166 --> 00:17:35.813
At the very least it's not
going to have a lot of variance.

00:17:35.813 --> 00:17:38.467
But how's it going to do
at 4 a.m. in the morning?

00:17:38.467 --> 00:17:40.416
Maybe not so well.

00:17:40.416 --> 00:17:43.097
How's it going to do when the bars close?

00:17:43.097 --> 00:17:44.326
An interesting question.

00:17:44.326 --> 00:17:47.138
I don't know yet,
but I challenge you to find out.

00:17:48.898 --> 00:17:52.874
So this is what you can run
using your local scripts.

00:17:55.364 --> 00:17:57.598
We start with our raw data.

00:17:57.598 --> 00:18:00.579
We run the TF Transform;
the TF Transform emits

00:18:00.579 --> 00:18:04.038
a transform function
and our transformed examples.

00:18:04.038 --> 00:18:06.124
We train our model.

00:18:06.124 --> 00:18:09.746
Our model, again, emits two
saved models as we talked about.

00:18:09.746 --> 00:18:12.176
One for serving and one for eval.

00:18:12.176 --> 00:18:15.711
And we try this all locally,
just run scripts and play with the stuff.

00:18:17.191 --> 00:18:21.224
Clemens talked 
a little bit about transform.

00:18:21.224 --> 00:18:24.256
Here we see that we want 
to take our dense features,

00:18:24.256 --> 00:18:27.392
and we want to scale them
to a particular Z-Score.

00:18:27.392 --> 00:18:29.502
And we don't want to do that
batch by batch

00:18:29.502 --> 00:18:31.937
because the mean for each batch
is going to differ,

00:18:31.937 --> 00:18:33.488
and there's going to be fluctuations.

00:18:33.488 --> 00:18:35.573
We may want to do that
across the entire data set.

00:18:35.573 --> 00:18:39.858
We may want to normalize
these things across the entire data set.

00:18:41.768 --> 00:18:45.208
We build a vocabulary; we bucket
for the wide part of our model,

00:18:45.208 --> 00:18:50.386
and we emit our transform function,
and into the trainer we go.

00:18:50.386 --> 00:18:52.881
You heard earlier today
about TF Estimators,

00:18:52.881 --> 00:18:55.957
and here is a wide and deep estimator

00:18:55.957 --> 00:18:58.507
that takes our transformed features

00:18:58.507 --> 00:19:01.158
and emits to saved models.

00:19:01.158 --> 00:19:04.060
Now we're in TensorFlow Model Analysis,

00:19:04.060 --> 00:19:07.390
which reads in the saved model

00:19:07.390 --> 00:19:10.357
and runs it against all of the raw data.

00:19:10.357 --> 00:19:13.998
We called render slicing metrics
from the Jupyter Notebook,

00:19:13.998 --> 00:19:15.457
and you see the UI.

00:19:15.457 --> 00:19:18.734
The thing to notice here
is that this UI is immersive, right?

00:19:18.734 --> 00:19:21.029
It's not just a static picture
that you can look at and go,

00:19:21.029 --> 00:19:24.018
"Huh" and then walk away from.

00:19:24.018 --> 00:19:28.332
It lets you see your errors broken down

00:19:28.332 --> 00:19:31.832
by bucket or broken down by feature,

00:19:31.832 --> 00:19:34.019
and it lets you drill in
and ask questions

00:19:34.019 --> 00:19:39.110
and be curious about how your models
are actually treating various subsets

00:19:39.110 --> 00:19:40.240
of your population.

00:19:40.240 --> 00:19:43.233
Those subsets may be
the lucrative subsets

00:19:43.233 --> 00:19:44.850
you really want to drill in.

00:19:47.900 --> 00:19:50.024
And then you want to serve
your models so our demo--

00:19:50.024 --> 00:19:52.924
our example has a one-liner here

00:19:52.924 --> 00:19:57.704
that you can run to serve your model.

00:20:02.304 --> 00:20:03.531
Make a client request--

00:20:03.531 --> 00:20:05.351
the thing to notice here
is that we're making

00:20:05.351 --> 00:20:09.289
a GRPC request to that server.

00:20:09.289 --> 00:20:12.383
We're taking our feature
tensors, we're serializing them

00:20:12.383 --> 00:20:14.853
into the GRPC request,
sending them to the server

00:20:14.853 --> 00:20:17.231
and back comes probability.

00:20:19.641 --> 00:20:21.292
But that's not quite enough, right?

00:20:21.292 --> 00:20:25.080
We've heard a little bit
of feedback about this server.

00:20:25.080 --> 00:20:27.330
The thing that we've heard
is that GRPC is cool,

00:20:28.350 --> 00:20:30.031
but REST is really cool.

00:20:33.011 --> 00:20:34.263
I tried.

00:20:36.953 --> 00:20:39.220
This is actually one
of the top feature requests

00:20:39.220 --> 00:20:43.220
on GitHub for model serving.

00:20:45.370 --> 00:20:49.203
You can now pack your tensors
into a JSON object,

00:20:49.203 --> 00:20:51.101
send that JSON object to the server

00:20:51.101 --> 00:20:52.802
and get a response back to [inaudible].

00:20:52.802 --> 00:20:57.290
Much more convenience
and I'm very excited to say

00:20:57.290 --> 00:21:00.621
that it'll be released very soon.

00:21:00.621 --> 00:21:01.733
Very soon.

00:21:05.063 --> 00:21:07.057
I see the excitement out there.

00:21:08.037 --> 00:21:09.572
Back to the end to end.

00:21:11.192 --> 00:21:15.772
You can try all of these pieces
end to end all on your local machine.

00:21:16.582 --> 00:21:19.902
Because they're using Apache Beam
direct runners, and direct runners

00:21:19.902 --> 00:21:24.239
allow you to take your distributive job
and to run them all locally.

00:21:24.239 --> 00:21:29.309
Now if you swap in
Apache Beam's data flow runner,

00:21:29.309 --> 00:21:33.264
you can now run against
the entire data set in the cloud.

00:21:33.264 --> 00:21:37.060
The example also shows you
how to run the big job

00:21:37.060 --> 00:21:40.504
against the cloud version as well.

00:21:40.504 --> 00:21:44.668
We're currently working
with a community to develop

00:21:44.668 --> 00:21:47.928
a runner for Apache Flink,
a runner for Spark.

00:21:47.928 --> 00:21:52.153
Stay tuned to the TensorFlow blog

00:21:52.153 --> 00:21:53.703
and to our GitHub...

00:21:56.793 --> 00:22:01.203
...and you can find the example
at <i>tensorflow/model-analysis</i>

00:22:02.603 --> 00:22:04.218
and back to Clemens.

00:22:04.888 --> 00:22:06.447
Thank you, Raz.

00:22:07.157 --> 00:22:08.957
(applause)

00:22:11.840 --> 00:22:14.110
Alright, so we've heard
about Transform.

00:22:14.110 --> 00:22:16.425
We've heard how to train models,
how to use model analysis

00:22:16.425 --> 00:22:18.046
and how to serve them.

00:22:19.186 --> 00:22:20.986
But I hear you say you want more.

00:22:20.986 --> 00:22:23.492
Right? Is that enough?

00:22:23.492 --> 00:22:25.057
You want more? Alright.

00:22:25.057 --> 00:22:26.307
You want more.

00:22:26.907 --> 00:22:29.315
And I can think of why you want more.

00:22:29.315 --> 00:22:31.902
Maybe you read the paper
we published last year and presented

00:22:31.902 --> 00:22:34.817
at KDD about TensorFlow Extended.

00:22:35.567 --> 00:22:37.988
In this paper we laid out
this broad vision of how

00:22:37.988 --> 00:22:42.067
this platform works within Google
and all of the features that it has

00:22:42.067 --> 00:22:44.136
and all the impact 
that we have by using it.

00:22:45.166 --> 00:22:48.976
Figure one, which allows
these boxes and describes

00:22:48.976 --> 00:22:51.097
what TensorFLow Extended actually is.

00:22:51.097 --> 00:22:53.915
Although, overly simplified,
this is still much more

00:22:53.915 --> 00:22:55.874
than we've discussed today.

00:22:56.794 --> 00:22:59.746
Today, we spoke about
these four components

00:22:59.746 --> 00:23:01.449
of TensorFlow Extended.

00:23:01.449 --> 00:23:05.474
Now it's important to highlight
that this is not yet an end to end

00:23:05.474 --> 00:23:07.683
machine learning platform.

00:23:07.683 --> 00:23:10.461
This is just a very small piece of TFX.

00:23:10.461 --> 00:23:13.300
These are the libraries
that we've open-sourced

00:23:13.300 --> 00:23:14.829
for you to use.

00:23:14.829 --> 00:23:17.817
But we haven't yet
released the entire platform.

00:23:17.817 --> 00:23:20.211
We're working very hard
on this because we've seen

00:23:20.211 --> 00:23:22.408
the profound impact 
that it had internally--

00:23:22.408 --> 00:23:24.406
how people could start
using this platform

00:23:24.406 --> 00:23:28.882
into applying machine learning
in production using TFX.

00:23:28.882 --> 00:23:30.847
And we've been working
very hard to actually make

00:23:30.847 --> 00:23:34.228
more of these components available to you.

00:23:34.228 --> 00:23:37.698
So in the next phase, we're actually
looking into our data components

00:23:37.698 --> 00:23:39.854
and looking to make those
available to users

00:23:39.854 --> 00:23:43.314
that you can analyze your data,
visualize the distributions,

00:23:43.314 --> 00:23:45.598
and detect anomalies
because it's an important part

00:23:45.598 --> 00:23:47.514
of any machine learning pipeline

00:23:47.514 --> 00:23:51.767
to detect changes and shifts
in your data and anomalies.

00:23:51.767 --> 00:23:55.121
After this we're actually looking
into some of the horizontal pieces

00:23:55.121 --> 00:23:57.877
that helped tie all of these
components together

00:23:57.877 --> 00:24:00.725
because if they're only
single libraries, you still have

00:24:00.725 --> 00:24:02.751
to glue them together yourself.

00:24:02.751 --> 00:24:04.696
You still have to use them individually.

00:24:04.696 --> 00:24:08.188
They have well-defined interfaces,
but you still have to combine them

00:24:08.188 --> 00:24:09.539
by yourself.

00:24:09.539 --> 00:24:12.242
Internally we have a shared 
configuration framework that allows you

00:24:12.242 --> 00:24:16.698
to configure the entire pipeline
and a nice integrated fountain

00:24:16.698 --> 00:24:19.788
that allows you to monitor
the status of these pipelines

00:24:19.788 --> 00:24:24.063
and see progress and inspect
the different artifacts

00:24:24.063 --> 00:24:26.690
that have been produced
by all of the components.

00:24:26.690 --> 00:24:28.882
So this is something 
that we're also looking to release

00:24:28.882 --> 00:24:30.164
later this year.

00:24:30.164 --> 00:24:31.659
And I think you get the idea.

00:24:31.659 --> 00:24:36.222
Eventually we want to make
all of this available to the community

00:24:36.222 --> 00:24:39.062
because internally, 
hundreds of teams use this

00:24:39.062 --> 00:24:41.061
to improve our product.

00:24:41.061 --> 00:24:43.710
We really believe that this
will be as transformative

00:24:43.710 --> 00:24:46.400
to the community
as it is at Google.

00:24:46.400 --> 00:24:50.044
And we're working very hard
to release more of these technologies

00:24:50.044 --> 00:24:52.395
into the entire platform
to see what you can do

00:24:52.395 --> 00:24:55.772
with them for your products
and for your companies.

00:24:55.772 --> 00:24:59.691
Keep watching the TensorFlow blog posts
for a more detailed announcement

00:24:59.691 --> 00:25:02.190
about TFX and our future plans.

00:25:03.170 --> 00:25:05.201
And as mentioned, you can already use

00:25:05.201 --> 00:25:07.071
some of these components today.

00:25:07.071 --> 00:25:08.381
Transform is released.

00:25:08.381 --> 00:25:10.511
Model Analysis was 
just released yesterday,

00:25:10.511 --> 00:25:13.360
Serving is also released,

00:25:13.360 --> 00:25:16.220
and the end-to-end example is available

00:25:16.220 --> 00:25:20.637
under the shortlink and you can find it
on the model analysis [inaudible].

00:25:20.637 --> 00:25:24.548
So with this, thank you
from both myself and Raz,

00:25:24.548 --> 00:25:27.261
and I'm going to ask you
to join me in welcoming

00:25:27.261 --> 00:25:32.208
a special external guest, Patrick Brand,
who's joining us from Coca-Cola,

00:25:32.208 --> 00:25:34.880
who's going to talk
about applied AI at Coca-Cola.

00:25:34.880 --> 00:25:36.080
Thank you.

00:25:36.080 --> 00:25:37.443
(applause)

00:25:37.443 --> 00:25:40.883
♪ (music) ♪

