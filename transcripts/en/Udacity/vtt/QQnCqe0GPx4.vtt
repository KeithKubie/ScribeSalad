WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:05.160
All right, so Dec-POMDPs give us a way
to optimally trade off acting and

00:00:05.160 --> 00:00:09.010
coordinating and communicating,
and I think we can now move on to

00:00:09.010 --> 00:00:11.400
the topic of coaching, so
communicating and coaching.

00:00:11.400 --> 00:00:14.880
So let's imagine instead of
the scenario we talked about before,

00:00:14.880 --> 00:00:17.890
where we had an agent that
himself wanted an apple and

00:00:17.890 --> 00:00:22.820
wanted to somehow use communication to
help bring about a positive outcome.

00:00:22.820 --> 00:00:27.450
Let's look more particularly at this
case of, okay, agent 1 needs agent 2 to

00:00:27.450 --> 00:00:30.670
learn a particular task,
like how to fetch an apple, all right.

00:00:30.670 --> 00:00:34.300
And so what we're going to try to
do is figure out how can agent 1

00:00:34.300 --> 00:00:36.190
convey the task to agent 2.

00:00:36.190 --> 00:00:39.030
If agent 2 has its own reward function,
it has its own task.

00:00:39.030 --> 00:00:42.870
So we're going to try to create
a a task or reward function for

00:00:42.870 --> 00:00:47.660
agent 2 in some way that is
consistent with agent 1's goals.

00:00:47.660 --> 00:00:48.390
&gt;&gt; Okay, so two things.

00:00:48.390 --> 00:00:52.730
One, so when you said, we're going to
try to create, you mean like agent 1

00:00:52.730 --> 00:00:55.500
should try to create a reward
function for agent 2, right?

00:00:55.500 --> 00:00:56.240
&gt;&gt; Yeah.
&gt;&gt; Okay.

00:00:56.240 --> 00:00:59.620
&gt;&gt; Or to convince agent 2 to create
such a reward function on its own.

00:00:59.620 --> 00:01:03.270
&gt;&gt; Okay, and so second, I think
the first thing agent 1 should do

00:01:03.270 --> 00:01:07.610
is not tell agent 2 that he's trying
to teach him to fetch things.

00:01:07.610 --> 00:01:09.280
I think he should probably.

00:01:09.280 --> 00:01:11.570
&gt;&gt; Yeah, fetch is not going to happen.

00:01:11.570 --> 00:01:14.930
&gt;&gt; Right, you should probably
use another nicer word.

00:01:14.930 --> 00:01:16.120
But okay, I think I'm with you.

00:01:16.120 --> 00:01:16.677
&gt;&gt; Yeah, that's why I said get.

00:01:16.677 --> 00:01:18.455
&gt;&gt; Yeah, except you said fetch.

00:01:18.455 --> 00:01:20.040
[LAUGH]
&gt;&gt; Yeah,

00:01:20.040 --> 00:01:21.410
it felt like fetch was a good word.

00:01:21.410 --> 00:01:23.380
All right, yes, okay, so
I agree with you on that.

00:01:23.380 --> 00:01:24.750
&gt;&gt; Okay, good.
So okay, so

00:01:24.750 --> 00:01:26.128
then I think I've got the task.

00:01:26.128 --> 00:01:31.526
I want to somehow get agent to
get a reward function that will

00:01:31.526 --> 00:01:36.494
get it to solve some task that
I wanted to solve or him.

00:01:36.494 --> 00:01:40.235
&gt;&gt; Yeah, exactly, and so there's a bunch
of different ways of thinking about

00:01:40.235 --> 00:01:43.742
this, but we're going to dive into
a particular one that I think is really

00:01:43.742 --> 00:01:47.790
interesting and actually quite useful
called inverse reinforcement learning.

00:01:47.790 --> 00:01:48.443
&gt;&gt; What, okay.

00:01:48.443 --> 00:01:50.457
&gt;&gt; All right, so
let me set this up for you.

00:01:50.457 --> 00:01:50.957
&gt;&gt; All right.

