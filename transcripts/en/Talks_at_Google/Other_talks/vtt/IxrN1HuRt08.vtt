WEBVTT
Kind: captions
Language: en

00:00:02.465 --> 00:00:03.590
MALE SPEAKER: Hi, everyone.

00:00:03.590 --> 00:00:05.630
Thanks for coming
out this afternoon.

00:00:05.630 --> 00:00:08.660
So we have two special
speakers today as you can see,

00:00:08.660 --> 00:00:11.710
one guest and one
fellow Googler.

00:00:11.710 --> 00:00:13.520
Hal Varian immediately
to my right

00:00:13.520 --> 00:00:16.230
is Google's chief economist
and has worked with Google

00:00:16.230 --> 00:00:18.280
since 2002.

00:00:18.280 --> 00:00:20.030
Hal has contributed
to Google projects

00:00:20.030 --> 00:00:23.460
on auction design,
econometric analysis, finance,

00:00:23.460 --> 00:00:26.250
corporate strategy,
and public policy.

00:00:26.250 --> 00:00:29.520
He's also an Emeritus Professor
in Business and Economics

00:00:29.520 --> 00:00:32.070
and Information Management at
the University of California

00:00:32.070 --> 00:00:34.000
Berkeley.

00:00:34.000 --> 00:00:36.742
That's also where
he earned his PhD.

00:00:36.742 --> 00:00:38.200
Before coming to
Google, Hal taught

00:00:38.200 --> 00:00:40.590
at some of the world's most
prestigious universities,

00:00:40.590 --> 00:00:43.840
including the University
of Michigan, MIT, Oxford,

00:00:43.840 --> 00:00:47.520
Stanford, and of
course, Berkeley.

00:00:47.520 --> 00:00:50.790
Alvin Roth, our special guest,
is the Craig and Susan McCaw

00:00:50.790 --> 00:00:53.630
Professor of Economics
at Stanford University

00:00:53.630 --> 00:00:55.240
and the Gund
Professor of Economics

00:00:55.240 --> 00:00:58.830
and Business Administration
Emeritus at Harvard.

00:00:58.830 --> 00:01:01.200
Professor Roth is an
expert in game theory,

00:01:01.200 --> 00:01:04.569
experimental economics,
and market design.

00:01:04.569 --> 00:01:10.040
In 2012, he and Lloyd S. Shapley
were awarded the Nobel Memorial

00:01:10.040 --> 00:01:11.870
Prize in Economics for
their contributions

00:01:11.870 --> 00:01:14.860
to stable allocations
and market design.

00:01:14.860 --> 00:01:16.890
And their work
isn't just theory.

00:01:16.890 --> 00:01:18.970
It's been put to real
world use in areas ranging

00:01:18.970 --> 00:01:21.712
from health care to education
as Professor Roth discusses

00:01:21.712 --> 00:01:24.170
in his new book, which we're
here to talk about today, "Who

00:01:24.170 --> 00:01:26.160
Gets What-- and Why."

00:01:26.160 --> 00:01:28.640
So without further ado,
please give a warm welcome

00:01:28.640 --> 00:01:30.710
to Dr. Hal Varian
and Dr. Alvin Roth.

00:01:35.930 --> 00:01:39.910
HAL VARIAN: Welcome to
the Hal and Al show.

00:01:39.910 --> 00:01:43.530
By the way, I didn't tell you,
but since Jon Stewart's retired

00:01:43.530 --> 00:01:44.650
there is an opening.

00:01:44.650 --> 00:01:46.970
And I thought maybe we could
do a little rehearsal--

00:01:46.970 --> 00:01:47.390
ALVIN ROTH: Good idea.

00:01:47.390 --> 00:01:48.270
HAL VARIAN: --for that position.

00:01:48.270 --> 00:01:49.740
And one of us will
be the interviewer.

00:01:49.740 --> 00:01:50.990
And one of us will be the guest.

00:01:50.990 --> 00:01:52.140
ALVIN ROTH: We can
figure out afterwards.

00:01:52.140 --> 00:01:54.260
HAL VARIAN: We'll let the
audience vote afterwards

00:01:54.260 --> 00:01:56.670
on which role is appropriate.

00:01:56.670 --> 00:01:59.320
But as you just heard,
Al is here today

00:01:59.320 --> 00:02:03.330
because he wants to talk about
his new book, "Who Gets What--

00:02:03.330 --> 00:02:04.800
and Why."

00:02:04.800 --> 00:02:07.450
And I have to say, it's
a pretty broad title.

00:02:07.450 --> 00:02:07.950
Right?

00:02:07.950 --> 00:02:11.240
You could say, that's all
of economics should exist

00:02:11.240 --> 00:02:11.740
[INAUDIBLE].

00:02:11.740 --> 00:02:14.090
So tell me what's
unique about your book.

00:02:14.090 --> 00:02:15.860
ALVIN ROTH: Well,
it has a subtitle,

00:02:15.860 --> 00:02:19.870
which is "The New Economics of
Matchmaking and Market Design."

00:02:19.870 --> 00:02:23.910
And so I try to talk about
matching markets and markets

00:02:23.910 --> 00:02:24.600
more broadly.

00:02:24.600 --> 00:02:27.540
A little bit, I think of it as a
field guide the markets the way

00:02:27.540 --> 00:02:29.690
you'd use a field
guide to birds to let

00:02:29.690 --> 00:02:32.480
you know that there are more
than red breasted robins

00:02:32.480 --> 00:02:34.110
in the world.

00:02:34.110 --> 00:02:36.289
I think that outside of
Silicon Valley people

00:02:36.289 --> 00:02:37.830
have a very different
view of markets

00:02:37.830 --> 00:02:40.830
than we have in the Valley.

00:02:40.830 --> 00:02:45.540
Because of course, markets
are ancient human artifacts

00:02:45.540 --> 00:02:47.650
probably older than agriculture.

00:02:47.650 --> 00:02:49.690
But often, we tend to
think of markets the way

00:02:49.690 --> 00:02:52.320
we think of languages, which
are also human artifacts,

00:02:52.320 --> 00:02:56.075
but which we can't
intervene in very much.

00:02:56.075 --> 00:02:57.200
You know, we speak English.

00:02:57.200 --> 00:03:00.160
But we speak it the way we
received it pretty much.

00:03:00.160 --> 00:03:03.079
But of course, companies
like Google make markets.

00:03:03.079 --> 00:03:04.870
There are a lot of
market making companies.

00:03:04.870 --> 00:03:06.703
And there are a lot of
markets in the world.

00:03:06.703 --> 00:03:11.220
So markets, unlike
languages, have proprietors,

00:03:11.220 --> 00:03:14.290
have interested active
groups of users,

00:03:14.290 --> 00:03:17.050
and are susceptible to design.

00:03:17.050 --> 00:03:19.250
We can change markets
when they're not

00:03:19.250 --> 00:03:20.250
working the way we want.

00:03:20.250 --> 00:03:22.210
And we can invent
new ones when we

00:03:22.210 --> 00:03:24.172
see markets that are missing.

00:03:24.172 --> 00:03:26.630
HAL VARIAN: And just to fill
in the little for the audience

00:03:26.630 --> 00:03:30.240
is this idea that you could
design economic mechanisms,

00:03:30.240 --> 00:03:35.340
like markets, and like
matching and other processes.

00:03:35.340 --> 00:03:38.050
I guess Lyle Hurwitz
was really the guy who

00:03:38.050 --> 00:03:41.405
first promulgated that,
at least in current times.

00:03:41.405 --> 00:03:42.780
ALVIN ROTH: I
think that's right.

00:03:42.780 --> 00:03:44.905
Although, my guess is the
guy who first promulgated

00:03:44.905 --> 00:03:49.190
it was trading in stone tools
back before the beginning.

00:03:49.190 --> 00:03:49.910
HAL VARIAN: Yes.

00:03:49.910 --> 00:03:51.940
And a very interesting
development

00:03:51.940 --> 00:03:55.450
in the last 10 or 15 years
has been the development

00:03:55.450 --> 00:03:57.730
of algorithmic
mechanism design, which

00:03:57.730 --> 00:04:00.760
is a way to combine
computer science

00:04:00.760 --> 00:04:04.630
considerations like
computability and so

00:04:04.630 --> 00:04:07.100
on with the economic
considerations which

00:04:07.100 --> 00:04:08.922
are incentives.

00:04:08.922 --> 00:04:11.380
And this has actually, I think,
been very, very stimulating

00:04:11.380 --> 00:04:13.210
to both fields.

00:04:13.210 --> 00:04:17.240
And as an economist, you focused
a lot on the incentive issues.

00:04:17.240 --> 00:04:20.970
But have you also dealt with the
computational side of things?

00:04:20.970 --> 00:04:21.829
Or is that--

00:04:21.829 --> 00:04:22.787
ALVIN ROTH: Oh, no, no.

00:04:22.787 --> 00:04:24.050
I have.

00:04:24.050 --> 00:04:27.330
One of the chapters in the book
is devoted to kidney exchange.

00:04:27.330 --> 00:04:30.620
And as that market
has developed,

00:04:30.620 --> 00:04:35.610
we're looking more and more
at long chains and things

00:04:35.610 --> 00:04:37.099
that turn out to
be computationally

00:04:37.099 --> 00:04:37.890
difficult problems.

00:04:37.890 --> 00:04:40.680
So they're incomplete problems.

00:04:40.680 --> 00:04:44.490
They are also just hard,
even though solvable,

00:04:44.490 --> 00:04:47.124
because you're dealing
with integer programs that

00:04:47.124 --> 00:04:49.040
have more constraints
than you can write down.

00:04:49.040 --> 00:04:50.980
So you have to generate
them on the fly.

00:04:50.980 --> 00:04:53.010
And when you try calling
things like CPLEX,

00:04:53.010 --> 00:04:54.440
you run into memory problems.

00:04:54.440 --> 00:04:58.620
So you have to do column
generation or a row generation.

00:04:58.620 --> 00:05:02.770
So yes, we think a lot about
the computational problems that

00:05:02.770 --> 00:05:05.652
arise in organizing some of
the markets we deal with.

00:05:05.652 --> 00:05:06.360
HAL VARIAN: Yeah.

00:05:06.360 --> 00:05:08.560
It's been a very
stimulating field

00:05:08.560 --> 00:05:12.020
for both sets of researchers.

00:05:12.020 --> 00:05:16.865
In fact, there's a conference,
a whole fall specialization

00:05:16.865 --> 00:05:20.190
at the Math Sciences Research
Institute at Berkeley,

00:05:20.190 --> 00:05:22.370
which is devoted to
exactly this topic,

00:05:22.370 --> 00:05:24.730
getting the computer
engineers, computer sciences,

00:05:24.730 --> 00:05:29.340
together along with economist
to study a lot of these markets,

00:05:29.340 --> 00:05:35.270
both the theory of what can be
done and what can be achieved

00:05:35.270 --> 00:05:39.860
and the practice of actually
implementing some of the stuff.

00:05:39.860 --> 00:05:42.510
ALVIN ROTH: You know, again
I hardly have to say here,

00:05:42.510 --> 00:05:46.860
but as markets have moved
more and more to the internet,

00:05:46.860 --> 00:05:48.650
the problem just to
implementing them

00:05:48.650 --> 00:05:52.460
often falls to computer
engineers or various sorts.

00:05:52.460 --> 00:05:55.250
And so there's going to be
natural, inevitable contact

00:05:55.250 --> 00:05:59.490
between people who think of how
the participants in the market

00:05:59.490 --> 00:06:01.090
will use it and
the engineers who

00:06:01.090 --> 00:06:03.194
think how to make it
happen on the internet.

00:06:03.194 --> 00:06:05.110
HAL VARIAN: So how did
you get into this area?

00:06:05.110 --> 00:06:07.970
When you started, there
really weren't many people.

00:06:07.970 --> 00:06:11.760
I guess, it was the
original Gale, Shapley paper

00:06:11.760 --> 00:06:13.620
the lot has subsequently
been built on.

00:06:13.620 --> 00:06:18.840
But it wasn't something that
was in every curriculum the way

00:06:18.840 --> 00:06:19.795
it is now.

00:06:19.795 --> 00:06:21.420
ALVIN ROTH: Well, I
started by thinking

00:06:21.420 --> 00:06:22.530
about particular markets.

00:06:22.530 --> 00:06:25.730
And the first one that
I studied for many years

00:06:25.730 --> 00:06:27.810
before I got an
opportunity to redesigned

00:06:27.810 --> 00:06:32.010
it was the market for new
doctors in the United States.

00:06:32.010 --> 00:06:35.400
And that market had a
lot of market failures

00:06:35.400 --> 00:06:39.680
prior to the 1950s
when they invented

00:06:39.680 --> 00:06:42.590
a centralized clearinghouse
that essentially anticipated

00:06:42.590 --> 00:06:45.750
the paper that Gale and
Shapley wrote 10 years later.

00:06:49.550 --> 00:06:51.670
That market worked
very well for reasons

00:06:51.670 --> 00:06:53.400
that we now understand
much better.

00:06:53.400 --> 00:06:56.020
But over the years,
it developed problems.

00:06:56.020 --> 00:06:59.430
Because in the
1950s, when it began,

00:06:59.430 --> 00:07:01.250
it was a sort of simple market.

00:07:01.250 --> 00:07:04.760
Simple in part, because
just about every graduate

00:07:04.760 --> 00:07:07.810
of an American medical
school in 1950 was a man.

00:07:07.810 --> 00:07:11.290
But by 1970s, there were
10% women graduates.

00:07:11.290 --> 00:07:12.980
And today, there are 50%.

00:07:12.980 --> 00:07:17.640
And so medical graduates,
they're very busy.

00:07:17.640 --> 00:07:19.800
And one of things they can
do is marry each other.

00:07:19.800 --> 00:07:23.590
And they started looking for
two jobs, not just for one.

00:07:23.590 --> 00:07:25.410
It turns out looking
for two jobs is

00:07:25.410 --> 00:07:28.270
a theoretically and
computationally more difficult

00:07:28.270 --> 00:07:30.170
problem than
looking for one job.

00:07:30.170 --> 00:07:33.690
So matching married
couples to pairs of jobs

00:07:33.690 --> 00:07:38.290
became the question
I was asked to help

00:07:38.290 --> 00:07:41.390
when I was asked to direct a
redesign of that marketplace.

00:07:41.390 --> 00:07:42.819
HAL VARIAN: The grand challenge.

00:07:42.819 --> 00:07:44.110
ALVIN ROTH: It was a challenge.

00:07:44.110 --> 00:07:46.160
HAL VARIAN: So why
don't you outline,

00:07:46.160 --> 00:07:48.860
let's say, the Gale
Shapley example just

00:07:48.860 --> 00:07:51.130
as a very simple case,
a starting problem,

00:07:51.130 --> 00:07:53.880
so people can get an idea of
what this matching process

00:07:53.880 --> 00:07:54.920
looks like.

00:07:54.920 --> 00:07:57.330
And then maybe say a
word or two about how it

00:07:57.330 --> 00:07:59.425
can be extended to other cases.

00:07:59.425 --> 00:08:00.050
ALVIN ROTH: OK.

00:08:00.050 --> 00:08:03.750
Well, Gale and Shapley
wrote a prescient paper

00:08:03.750 --> 00:08:09.800
called "College Admissions and
the Stability of Marriage."

00:08:09.800 --> 00:08:12.705
So it had a funny title.

00:08:12.705 --> 00:08:15.330
And what they said is they said,
think of a problem of marriage

00:08:15.330 --> 00:08:17.954
where-- they didn't quite put it
this way, but supposing you're

00:08:17.954 --> 00:08:21.950
trying to organize a centralized
clearinghouse to marry people.

00:08:21.950 --> 00:08:25.870
And you're not a
central planner.

00:08:25.870 --> 00:08:28.090
You can't simply decide
who marries whom.

00:08:28.090 --> 00:08:31.260
You can only make suggestions
about who should marry whom.

00:08:31.260 --> 00:08:33.169
And what will
ultimately determine

00:08:33.169 --> 00:08:34.669
who marries whom
are the preferences

00:08:34.669 --> 00:08:38.320
of the married people, who
each have the right to marry

00:08:38.320 --> 00:08:40.882
each other if they so choose.

00:08:40.882 --> 00:08:42.340
They said what you
would like to do

00:08:42.340 --> 00:08:45.110
then is you'd like to create a
stable matching if you could,

00:08:45.110 --> 00:08:48.720
which is a matching that has the
property that there are no man

00:08:48.720 --> 00:08:51.344
and woman not married to each
other who would both prefer

00:08:51.344 --> 00:08:52.510
to be married to each other.

00:08:52.510 --> 00:08:55.290
So your aim is to suggest
a stable matching.

00:08:55.290 --> 00:08:57.646
Because if you suggest
an unstable matching,

00:08:57.646 --> 00:08:58.770
they'll be a blocking pair.

00:08:58.770 --> 00:09:01.280
They'll be a man and a woman
not married to each other

00:09:01.280 --> 00:09:03.310
who would prefer
to marry each other

00:09:03.310 --> 00:09:05.480
and who won't have to
accept your suggestion.

00:09:05.480 --> 00:09:07.034
Instead of doing
what you propose,

00:09:07.034 --> 00:09:08.200
they could marry each other.

00:09:08.200 --> 00:09:10.616
HAL VARIAN: So in other words,
anybody that I would rather

00:09:10.616 --> 00:09:11.622
have wouldn't want me.

00:09:11.622 --> 00:09:13.080
ALVIN ROTH: That's
a characteristic

00:09:13.080 --> 00:09:14.430
of a stable matching.

00:09:14.430 --> 00:09:16.890
And they constructed
an algorithm

00:09:16.890 --> 00:09:19.690
that produces a stable
matching no matter

00:09:19.690 --> 00:09:22.950
what the preferences of
the men and the women are.

00:09:22.950 --> 00:09:25.570
And there are two
versions of the algorithm.

00:09:25.570 --> 00:09:27.280
One has the men proposing.

00:09:27.280 --> 00:09:29.240
And one has the women proposing.

00:09:29.240 --> 00:09:31.760
And so the man proposing
algorithm goes like this.

00:09:31.760 --> 00:09:33.750
At the first step
of the algorithm,

00:09:33.750 --> 00:09:36.880
each man proposes to
his first choice woman.

00:09:36.880 --> 00:09:41.187
And every woman who has
received acceptable proposals--

00:09:41.187 --> 00:09:43.020
if you receive an
unacceptable proposal that

00:09:43.020 --> 00:09:44.870
is someone who you would
rather not be married to.

00:09:44.870 --> 00:09:46.060
You'd rather be single.

00:09:46.060 --> 00:09:47.200
You reject them.

00:09:47.200 --> 00:09:50.340
But also if you've received
multiple acceptable proposals,

00:09:50.340 --> 00:09:52.670
you hold onto the
one you like best,

00:09:52.670 --> 00:09:55.620
the one you prefer the
most and reject the rest.

00:09:55.620 --> 00:09:57.854
But you don't immediately
accept the proposal

00:09:57.854 --> 00:09:58.770
that you don't reject.

00:09:58.770 --> 00:10:01.170
This is a deferred
acceptance algorithm.

00:10:01.170 --> 00:10:03.250
Acceptance will only
happen at the end.

00:10:03.250 --> 00:10:04.530
So what happens?

00:10:04.530 --> 00:10:06.700
All the men who have
just been rejected,

00:10:06.700 --> 00:10:10.550
they propose to their next
choice woman, their next most

00:10:10.550 --> 00:10:11.660
preferred woman.

00:10:11.660 --> 00:10:13.590
And every woman who's
gotten the proposal,

00:10:13.590 --> 00:10:15.920
now looks at the new proposals
that she gets together

00:10:15.920 --> 00:10:19.240
with any proposal, which she
may have held previously,

00:10:19.240 --> 00:10:22.540
keeps the one she likes
best, rejects the rest.

00:10:22.540 --> 00:10:24.960
And this continues
until no more rejections

00:10:24.960 --> 00:10:26.310
are issued, which it must do.

00:10:26.310 --> 00:10:28.230
Because it's a finite problem.

00:10:28.230 --> 00:10:31.730
And no man proposes
twice to the same woman.

00:10:31.730 --> 00:10:33.640
And when no more
rejections are issued,

00:10:33.640 --> 00:10:35.690
now the proposals are accepted.

00:10:35.690 --> 00:10:40.430
And each woman is married to the
man, if any, whose proposal she

00:10:40.430 --> 00:10:41.480
has not rejected.

00:10:41.480 --> 00:10:44.180
She might be holding
on to one proposal.

00:10:44.180 --> 00:10:47.310
And what Gale and Shapley
observed is that that matching,

00:10:47.310 --> 00:10:49.110
regardless of what
the preferences were

00:10:49.110 --> 00:10:51.290
that were the input, is stable.

00:10:51.290 --> 00:10:53.610
It can't be that there
are a man and a woman who

00:10:53.610 --> 00:10:57.880
would prefer to each other
to who they're matched to.

00:10:57.880 --> 00:11:02.820
And the reason, of course,
is that if a man is matched

00:11:02.820 --> 00:11:05.900
to his third choice woman, he
knows that his second choice

00:11:05.900 --> 00:11:07.350
woman doesn't prefer him.

00:11:07.350 --> 00:11:09.180
Because he already
proposed to her.

00:11:09.180 --> 00:11:11.090
And she rejected him
when she got a proposal

00:11:11.090 --> 00:11:12.740
that she preferred.

00:11:12.740 --> 00:11:15.480
So that was where they left it.

00:11:15.480 --> 00:11:17.052
And later, when we
started to think

00:11:17.052 --> 00:11:18.760
about this as centralized
clearinghouses,

00:11:18.760 --> 00:11:20.714
we said, you know,
this really depends

00:11:20.714 --> 00:11:21.880
on knowing the preferences--

00:11:21.880 --> 00:11:22.260
HAL VARIAN: Right.

00:11:22.260 --> 00:11:23.718
ALVIN ROTH: --of
the men and women.

00:11:23.718 --> 00:11:26.530
And one of the things
that you can show

00:11:26.530 --> 00:11:31.720
is that the men can do
no better than to state

00:11:31.720 --> 00:11:33.140
their true preferences.

00:11:33.140 --> 00:11:35.970
But that the women situation,
when the men are proposing,

00:11:35.970 --> 00:11:38.610
is more complicated.

00:11:38.610 --> 00:11:40.580
HAL VARIAN: I think,
isn't there a Jane Austen

00:11:40.580 --> 00:11:41.599
novel with that plot?

00:11:41.599 --> 00:11:42.890
ALVIN ROTH: Several, I believe.

00:11:42.890 --> 00:11:44.780
HAL VARIAN: Something
along that line, at least,

00:11:44.780 --> 00:11:46.113
I think I've encountered before.

00:11:46.113 --> 00:11:50.260
But Gale and Shapley,
to my recollection,

00:11:50.260 --> 00:11:51.885
did not cite Jane
Austen in that paper.

00:11:51.885 --> 00:11:53.301
ALVIN ROTH: Well,
they didn't deal

00:11:53.301 --> 00:11:54.510
with the incentive problem.

00:11:54.510 --> 00:11:57.682
They took what, for
better or for worse,

00:11:57.682 --> 00:11:59.890
for many years became the
computer science approach--

00:11:59.890 --> 00:12:00.598
HAL VARIAN: Right

00:12:00.598 --> 00:12:03.110
ALVIN ROTH: --which is that the
person organizing the market

00:12:03.110 --> 00:12:04.551
knows the preferences.

00:12:04.551 --> 00:12:06.050
HAL VARIAN: And
many of you may know

00:12:06.050 --> 00:12:10.410
that a very common exercise
in your first computer science

00:12:10.410 --> 00:12:15.950
or programming class is to write
the code for this algorithm.

00:12:15.950 --> 00:12:18.810
But without looking at the
incentives-- [INAUDIBLE].

00:12:18.810 --> 00:12:21.070
Before we talk about
the incentives,

00:12:21.070 --> 00:12:23.180
give us a few more
examples of where

00:12:23.180 --> 00:12:26.690
this two-sided matching market
or multi-sided matching market

00:12:26.690 --> 00:12:28.430
might be relevant.

00:12:28.430 --> 00:12:30.530
ALVIN ROTH: Well,
so as I said, we've

00:12:30.530 --> 00:12:33.540
helped build clearinghouses for
a variety of medical and health

00:12:33.540 --> 00:12:34.350
care marketplaces.

00:12:34.350 --> 00:12:38.820
But my colleagues and I are also
helping reform school choice

00:12:38.820 --> 00:12:40.790
in a number of American cities.

00:12:40.790 --> 00:12:48.410
And you can easily have
school choice mechanisms that

00:12:48.410 --> 00:12:51.417
don't work as well as a
deferred acceptance algorithm

00:12:51.417 --> 00:12:52.000
clearinghouse.

00:12:52.000 --> 00:12:56.140
And so in recent years, we've
helped redesign the processes

00:12:56.140 --> 00:12:58.060
for putting children
into schools in New York

00:12:58.060 --> 00:13:00.440
and in Boston and New
Orleans and in Denver

00:13:00.440 --> 00:13:01.890
and some other cities.

00:13:01.890 --> 00:13:05.050
And a clearinghouse
that operates

00:13:05.050 --> 00:13:06.550
like a deferred
acceptance algorithm

00:13:06.550 --> 00:13:09.960
solves a couple of problems
that school choice systems often

00:13:09.960 --> 00:13:10.610
have.

00:13:10.610 --> 00:13:14.330
One is making it safe for
children and their families

00:13:14.330 --> 00:13:17.650
to reveal their preferences
to the school district.

00:13:17.650 --> 00:13:20.550
For many years, New
York City, the way

00:13:20.550 --> 00:13:23.652
you applied for a
school was you who

00:13:23.652 --> 00:13:24.860
submitted to rank order list.

00:13:24.860 --> 00:13:27.318
This is my first choice, my
second choice, my third choice.

00:13:27.318 --> 00:13:30.530
And then that list was Xeroxed
and sent to the schools.

00:13:30.530 --> 00:13:31.870
And that was your application.

00:13:31.870 --> 00:13:34.320
What that meant was if I
applied to your school,

00:13:34.320 --> 00:13:36.640
you might be able to
see that I had applied

00:13:36.640 --> 00:13:38.650
and you are my third choice.

00:13:38.650 --> 00:13:40.480
And you could, as
a school principal,

00:13:40.480 --> 00:13:44.150
adopt an admissions policy that
says, we're a popular school.

00:13:44.150 --> 00:13:46.700
We're only going
to admit people who

00:13:46.700 --> 00:13:49.305
list us as their first choice.

00:13:49.305 --> 00:13:51.180
So that would mean that,
although it appeared

00:13:51.180 --> 00:13:52.650
that I had lots of
choices of schools,

00:13:52.650 --> 00:13:53.858
I might really have very few.

00:13:53.858 --> 00:13:55.910
Because of the schools
I wanted, only the ones

00:13:55.910 --> 00:13:58.340
that I listed first
would consider me.

00:13:58.340 --> 00:14:01.710
Similarly, Boston had a
system of school choice

00:14:01.710 --> 00:14:05.369
where they tried to give
as many people as possible

00:14:05.369 --> 00:14:06.160
their first choice.

00:14:06.160 --> 00:14:08.580
And when more people
wanted a particular school

00:14:08.580 --> 00:14:10.690
as their first choice
than they could fit in,

00:14:10.690 --> 00:14:13.400
they used a priority
system to break ties.

00:14:13.400 --> 00:14:16.820
If an older sibling went to
the same school, you could go.

00:14:16.820 --> 00:14:18.850
But the trouble with
that mechanism-- which

00:14:18.850 --> 00:14:21.795
was very benign in intent,
they'd give as many people as

00:14:21.795 --> 00:14:23.170
possible their
first choice, then

00:14:23.170 --> 00:14:25.750
as many people as possible their
second choice and so forth--

00:14:25.750 --> 00:14:27.630
was if you didn't get
your first choice,

00:14:27.630 --> 00:14:29.780
your second choice might
already have all its seats

00:14:29.780 --> 00:14:31.650
filled with people
who had listed it

00:14:31.650 --> 00:14:32.720
as their first choice.

00:14:32.720 --> 00:14:34.730
So that even though
you had high priority

00:14:34.730 --> 00:14:37.370
at your second choice-- an
older child who already went

00:14:37.370 --> 00:14:39.920
to the school, which
means if you had listed it

00:14:39.920 --> 00:14:41.860
as your first choice--
you would've gotten in.

00:14:41.860 --> 00:14:44.068
If you listed it as your
second choice, you wouldn't.

00:14:44.068 --> 00:14:46.110
So when we use the deferred
acceptance algorithm

00:14:46.110 --> 00:14:48.530
with students proposing,
that solves that problem.

00:14:48.530 --> 00:14:51.370
Because if you don't get
into your first choice, when

00:14:51.370 --> 00:14:53.020
you apply to your
second choice, they

00:14:53.020 --> 00:14:54.560
haven't filled all
their seats yet.

00:14:54.560 --> 00:14:57.740
They've rejected some
applications and kept others.

00:14:57.740 --> 00:14:59.430
But they haven't accepted those.

00:14:59.430 --> 00:15:01.770
And if you have very high
priority at your second choice

00:15:01.770 --> 00:15:03.686
school, you go right to
the top of their list.

00:15:03.686 --> 00:15:05.530
And they reject someone else.

00:15:05.530 --> 00:15:11.690
So it's safe for you to tell
the city what your choices are.

00:15:11.690 --> 00:15:14.390
Your chance of getting
your second choice school

00:15:14.390 --> 00:15:16.460
if you get rejected
by your first choice

00:15:16.460 --> 00:15:18.510
is just as large
as it would have

00:15:18.510 --> 00:15:20.844
been if you had listed that
school as your first choice.

00:15:20.844 --> 00:15:22.218
HAL VARIAN: And
it's interesting.

00:15:22.218 --> 00:15:24.700
Both of these examples, the
school admission problem

00:15:24.700 --> 00:15:26.900
and the residence
assignment problem,

00:15:26.900 --> 00:15:30.410
have this side
constraint that it's

00:15:30.410 --> 00:15:32.720
good to have husband and
wife in the same location.

00:15:32.720 --> 00:15:34.590
It's good to have older
siblings and younger

00:15:34.590 --> 00:15:36.460
siblings in the same school.

00:15:36.460 --> 00:15:38.510
So the same
complications presumably

00:15:38.510 --> 00:15:41.469
arise if you're trying to
solve that full problem.

00:15:41.469 --> 00:15:42.510
ALVIN ROTH: So not quite.

00:15:42.510 --> 00:15:45.060
In most cities, the
school choice problem

00:15:45.060 --> 00:15:46.560
is simpler than the
couples problem.

00:15:46.560 --> 00:15:46.760
HAL VARIAN: I see.

00:15:46.760 --> 00:15:49.280
ALVIN ROTH: Because we're
dealing with older siblings who

00:15:49.280 --> 00:15:50.155
are already in place.

00:15:50.155 --> 00:15:50.946
HAL VARIAN: Ah, OK.

00:15:50.946 --> 00:15:52.495
ALVIN ROTH: Now
twins are a problem.

00:15:52.495 --> 00:15:53.190
HAL VARIAN: Yup.

00:15:53.190 --> 00:15:56.466
ALVIN ROTH: And in New
Orleans, it's common for people

00:15:56.466 --> 00:15:57.840
to change schools
at every grade.

00:15:57.840 --> 00:15:59.830
In most cities,
you change schools

00:15:59.830 --> 00:16:01.990
at kindergarten, sixth
grade, and ninth grade.

00:16:01.990 --> 00:16:05.140
So the couple's problem
for siblings isn't so bad.

00:16:05.140 --> 00:16:07.710
But in New Orleans, you might
have a first and third grader

00:16:07.710 --> 00:16:10.290
and you want to move them
both to a different school.

00:16:10.290 --> 00:16:12.510
So they look like
the couples problem.

00:16:12.510 --> 00:16:14.620
HAL VARIAN: So the
stable marriage idea

00:16:14.620 --> 00:16:15.790
is very attractive.

00:16:15.790 --> 00:16:17.240
But it doesn't always exist.

00:16:17.240 --> 00:16:19.250
In the two-sided case it exists.

00:16:19.250 --> 00:16:21.440
But tell us about
the roommate problem.

00:16:21.440 --> 00:16:22.520
ALVIN ROTH: Well, in
the roommate problem

00:16:22.520 --> 00:16:24.050
and in the couples problem
it might not exist.

00:16:24.050 --> 00:16:24.350
HAL VARIAN: And the couples.

00:16:24.350 --> 00:16:25.010
Yes, right.

00:16:25.010 --> 00:16:27.815
ALVIN ROTH: But Gale and
Shapley, in their '62 paper,

00:16:27.815 --> 00:16:29.690
they said, you know,
there's a big difference

00:16:29.690 --> 00:16:32.350
between defining what's
a stable matching

00:16:32.350 --> 00:16:33.560
and knowing that one exists.

00:16:33.560 --> 00:16:35.310
And what the deferred
acceptance algorithm

00:16:35.310 --> 00:16:38.820
allowed them to prove was in
two-sided matching, when you

00:16:38.820 --> 00:16:41.557
know who are the men
and who are the women

00:16:41.557 --> 00:16:43.640
and who are the doctors
and who are the hospitals,

00:16:43.640 --> 00:16:45.227
you can always find
a stable matching.

00:16:45.227 --> 00:16:47.560
But they gave an example to
show that it wouldn't always

00:16:47.560 --> 00:16:48.176
be so easy.

00:16:48.176 --> 00:16:50.550
And they said think of the
problem of matching roommates.

00:16:50.550 --> 00:16:53.530
So you have a bunch
of people, any of whom

00:16:53.530 --> 00:16:55.420
can be a roommate
with any other.

00:16:55.420 --> 00:16:57.330
This, incidentally,
is a little bit

00:16:57.330 --> 00:16:59.690
like the problem we face
with kidney exchange.

00:16:59.690 --> 00:17:01.390
But that's a different problem.

00:17:01.390 --> 00:17:03.220
And we face it in
a different way.

00:17:03.220 --> 00:17:06.095
But what they said about
roommates is so your job,

00:17:06.095 --> 00:17:07.970
you're the housing office
at some university.

00:17:07.970 --> 00:17:10.040
You get preferences
for roommates.

00:17:10.040 --> 00:17:11.569
You have to fill double rooms.

00:17:11.569 --> 00:17:13.710
And consider the
case of four people,

00:17:13.710 --> 00:17:18.280
where person one's first
choice roommate is person two.

00:17:18.280 --> 00:17:21.210
Person two's first choice
roommate is person three.

00:17:21.210 --> 00:17:24.829
Person three's first choice
roommate is person one.

00:17:24.829 --> 00:17:28.260
And person one, two, and,
three, their last choice

00:17:28.260 --> 00:17:29.432
is person four.

00:17:29.432 --> 00:17:31.140
And it turns out in
this example it's not

00:17:31.140 --> 00:17:32.460
going to matter what person--

00:17:32.460 --> 00:17:34.209
HAL VARIAN: He was my
roommate in college.

00:17:34.209 --> 00:17:34.980
I remember him.

00:17:34.980 --> 00:17:35.390
ALVIN ROTH: That's funny.

00:17:35.390 --> 00:17:36.511
He told me the same thing.

00:17:39.590 --> 00:17:41.820
But what you can see is
there's no stable matching.

00:17:41.820 --> 00:17:44.930
Because whoever you
match with person four,

00:17:44.930 --> 00:17:47.490
that person, the person who is
the roommate of person four,

00:17:47.490 --> 00:17:49.770
is the first choice
of someone else.

00:17:49.770 --> 00:17:52.710
And so whoever is
roomed with person four,

00:17:52.710 --> 00:17:54.675
together with whoever
regards that person

00:17:54.675 --> 00:17:56.550
as his first choice,
they're a blocking pair.

00:17:56.550 --> 00:17:58.050
They would both
rather be rooming

00:17:58.050 --> 00:18:02.450
with each other than the
matching that you've designed.

00:18:02.450 --> 00:18:05.841
So that shows that stable
matchings might not always

00:18:05.841 --> 00:18:06.340
exist.

00:18:06.340 --> 00:18:07.840
And, indeed, one
of the first things

00:18:07.840 --> 00:18:09.910
I observed about the
problem with couples

00:18:09.910 --> 00:18:12.500
was that when you have couples
in the medical labor market,

00:18:12.500 --> 00:18:14.674
stable matching might
not always exist.

00:18:14.674 --> 00:18:16.340
And one of the
differences between being

00:18:16.340 --> 00:18:19.000
an economic theorist and
being a market designer

00:18:19.000 --> 00:18:23.280
was when I first observe this,
I was still a game theorist

00:18:23.280 --> 00:18:24.582
just observing the market.

00:18:24.582 --> 00:18:26.040
And it was enough
for me to observe

00:18:26.040 --> 00:18:27.956
that therefore the problem
of matching couples

00:18:27.956 --> 00:18:29.350
was a hard problem.

00:18:29.350 --> 00:18:34.030
And that made for a great
paper and full stop.

00:18:34.030 --> 00:18:37.940
So when one day my phone
rang and on the other end

00:18:37.940 --> 00:18:40.650
was the Director of the National
Resident Matching Program

00:18:40.650 --> 00:18:43.050
and he said, we're
having these problems,

00:18:43.050 --> 00:18:45.020
would you redesign
the match for us,

00:18:45.020 --> 00:18:47.050
I knew that it was
no longer going

00:18:47.050 --> 00:18:48.910
to be enough to say
that's a hard problem.

00:18:48.910 --> 00:18:52.950
It was going to become
my hard problem.

00:18:52.950 --> 00:18:56.400
And so designing markets
has changed my taste

00:18:56.400 --> 00:18:58.254
in economic theory in
much the way, I think,

00:18:58.254 --> 00:19:00.670
that it's going to change the
taste of computer scientists

00:19:00.670 --> 00:19:02.227
in algorithmic theory.

00:19:02.227 --> 00:19:04.560
HAL VARIAN: It's like, you
proved the bumblebee couldn't

00:19:04.560 --> 00:19:06.243
fly, now what?

00:19:06.243 --> 00:19:06.970
ALVIN ROTH: Yeah.

00:19:06.970 --> 00:19:08.303
HAL VARIAN: But it's got to fly.

00:19:08.303 --> 00:19:10.750
Actually another paper
of yours that I handled

00:19:10.750 --> 00:19:14.640
when I was editor of "The
American Economic Review"

00:19:14.640 --> 00:19:17.740
that really appealed to
me was a sorority paper.

00:19:17.740 --> 00:19:18.240
Right?

00:19:18.240 --> 00:19:21.850
Because there was a
very explicit algorithm

00:19:21.850 --> 00:19:26.040
that was used to match
sororities and pledges.

00:19:26.040 --> 00:19:28.786
But it had some really
fundamental faults.

00:19:28.786 --> 00:19:30.660
Maybe you could say a
word or two about that.

00:19:30.660 --> 00:19:31.990
ALVIN ROTH: Well,
so let me actually

00:19:31.990 --> 00:19:34.130
take that as an opportunity
to talk about market failure.

00:19:34.130 --> 00:19:35.830
Because one of the
things marketplaces

00:19:35.830 --> 00:19:38.000
have to do for markets
is make them thick.

00:19:38.000 --> 00:19:40.250
And one way you get
markets to be thick

00:19:40.250 --> 00:19:43.520
is to agree on a time, hopefully
inefficient time, at which

00:19:43.520 --> 00:19:44.706
the marketplace can happen.

00:19:44.706 --> 00:19:46.330
But a lot of markets,
and this happened

00:19:46.330 --> 00:19:48.288
with the medical market,
they start to unravel.

00:19:48.288 --> 00:19:51.470
They go earlier and earlier.

00:19:51.470 --> 00:19:53.480
And today, if you
know someone who's

00:19:53.480 --> 00:19:55.880
graduating from law
school, they likely

00:19:55.880 --> 00:19:59.099
arranged their job perhaps
two years in advance,

00:19:59.099 --> 00:20:01.640
particularly if they're going
to clerk for an appellate judge

00:20:01.640 --> 00:20:02.612
or something like that.

00:20:02.612 --> 00:20:04.820
Well, it turns out sorority
and fraternity recruiting

00:20:04.820 --> 00:20:07.530
is called rush for
just this reason.

00:20:07.530 --> 00:20:10.060
It used to be that in
the 1800s that sororities

00:20:10.060 --> 00:20:13.350
and fraternities were social
clubs for college seniors.

00:20:13.350 --> 00:20:15.530
And then, in an
effort to recruit

00:20:15.530 --> 00:20:18.080
more attractive candidates,
some of the fraternities

00:20:18.080 --> 00:20:22.010
and sororities started to
rush and recruit earlier.

00:20:22.010 --> 00:20:25.700
And today, of course, colleges,
sororities, and fraternities

00:20:25.700 --> 00:20:26.480
recruit freshman.

00:20:26.480 --> 00:20:28.410
They can hardly go any earlier.

00:20:28.410 --> 00:20:32.570
Although, at the beginning of
the last century when there

00:20:32.570 --> 00:20:34.940
was a lot less mobility
about colleges, rush actually

00:20:34.940 --> 00:20:36.780
extended into high school years.

00:20:36.780 --> 00:20:38.530
You'd know who was
coming to your college.

00:20:38.530 --> 00:20:41.660
And you could rush
them before they came.

00:20:41.660 --> 00:20:44.384
But different fraternities
and sororities

00:20:44.384 --> 00:20:46.050
develop different
ways of handling that.

00:20:46.050 --> 00:20:48.420
And the sororities
have an organization

00:20:48.420 --> 00:20:51.165
that specifies-- doesn't
completely specify,

00:20:51.165 --> 00:20:53.290
computer scientists would
not be happy with the way

00:20:53.290 --> 00:20:54.540
they describe their algorithm.

00:20:54.540 --> 00:20:57.810
Because you can create events
in which it's undefined.

00:20:57.810 --> 00:21:01.540
But they have an
algorithm for recruiting.

00:21:01.540 --> 00:21:03.310
And it's an
interesting algorithm.

00:21:03.310 --> 00:21:07.289
And it starts with
parties of short duration

00:21:07.289 --> 00:21:09.080
that everyone is supposed
to be invited to.

00:21:09.080 --> 00:21:11.050
And so you get invited
to a first party.

00:21:11.050 --> 00:21:14.330
But then the sororities could
invite some young women back

00:21:14.330 --> 00:21:15.400
to a second party.

00:21:15.400 --> 00:21:17.776
And young women can't
accept every invitation.

00:21:17.776 --> 00:21:19.650
They have a limit on
how many they can go to.

00:21:19.650 --> 00:21:21.737
So there's information
about preferences

00:21:21.737 --> 00:21:22.820
exchanged through parties.

00:21:22.820 --> 00:21:25.640
And then finally, there's
a matching algorithm.

00:21:25.640 --> 00:21:27.090
Preferences are submitted.

00:21:27.090 --> 00:21:31.560
And it has serious problems
that has been heavily gamed.

00:21:31.560 --> 00:21:35.270
So when you study how
sororities attract--

00:21:35.270 --> 00:21:38.420
it's been heavily gamed in
part, because universities

00:21:38.420 --> 00:21:41.810
and the Pan-Hellenic
Council sometimes

00:21:41.810 --> 00:21:46.040
tries to allocate equally
the number of pledges

00:21:46.040 --> 00:21:48.790
to sororities independent
of their capacity.

00:21:48.790 --> 00:21:51.650
And that causes problems.

00:21:51.650 --> 00:21:54.910
It means that the outcomes
that they try to enforce

00:21:54.910 --> 00:21:55.900
are unstable.

00:21:55.900 --> 00:21:58.731
There may be blocking pairs
of young women and sororities

00:21:58.731 --> 00:22:00.480
who would like to be
matched to each other

00:22:00.480 --> 00:22:03.010
and who could be
matched to each other.

00:22:03.010 --> 00:22:06.732
So that changes the way
sorority recruitment goes.

00:22:06.732 --> 00:22:08.440
HAL VARIAN: And that
was really a failure

00:22:08.440 --> 00:22:10.216
on the incentive side.

00:22:10.216 --> 00:22:11.004
ALVIN ROTH: Yeah.

00:22:11.004 --> 00:22:11.670
HAL VARIAN: So--

00:22:11.670 --> 00:22:13.100
ALVIN ROTH: And stability
is related to incentive.

00:22:13.100 --> 00:22:14.190
HAL VARIAN: And
stability, yes, yes.

00:22:14.190 --> 00:22:16.010
ALVIN ROTH: Stability
speaks to incentives

00:22:16.010 --> 00:22:19.260
to recontract or to
go outside the system

00:22:19.260 --> 00:22:23.120
and get your match outside
the official marketplace.

00:22:23.120 --> 00:22:24.852
So one of things
marketplaces have to do

00:22:24.852 --> 00:22:26.040
is attract participants.

00:22:26.040 --> 00:22:28.130
They have to make
the market thick.

00:22:28.130 --> 00:22:31.490
HAL VARIAN: So when I first
came to Google back in 2002,

00:22:31.490 --> 00:22:33.830
I asked Eric Schmidt
what I should work on.

00:22:33.830 --> 00:22:36.320
He said, why don't you take
a look at this ad auction.

00:22:36.320 --> 00:22:38.250
I think it might make
us a little money.

00:22:38.250 --> 00:22:41.500
And the ad auction started
in February of 2002.

00:22:41.500 --> 00:22:46.320
And I arrived in May of 2002
and looked at the ad auction.

00:22:46.320 --> 00:22:49.070
I was convinced, oh, this
is so straightforward.

00:22:49.070 --> 00:22:50.850
It must be in the
literature somewhere.

00:22:50.850 --> 00:22:52.474
And I looked through
all the literature

00:22:52.474 --> 00:22:54.880
I could find on
auctions and so on.

00:22:54.880 --> 00:22:58.550
And a year or two later,
I discovered actually

00:22:58.550 --> 00:23:01.390
the basics were in your
book, the Roth and Sotomayor

00:23:01.390 --> 00:23:04.860
book, which was a
kind of compendium,

00:23:04.860 --> 00:23:07.110
everything that was known
about the assignment problem

00:23:07.110 --> 00:23:09.900
and two-sided matching
problems in that book.

00:23:09.900 --> 00:23:12.900
And there in the
chapter on incentives,

00:23:12.900 --> 00:23:14.810
there was a description
of a problem

00:23:14.810 --> 00:23:17.040
of assigning workers to jobs.

00:23:17.040 --> 00:23:20.790
And it turned out that problem
was very similar to assigning

00:23:20.790 --> 00:23:23.284
advertisers to slots.

00:23:23.284 --> 00:23:24.950
You know, there were
little differences.

00:23:24.950 --> 00:23:28.300
In fact, it was a more general
problem as it turns out.

00:23:28.300 --> 00:23:32.140
But if you read that
chapter creatively,

00:23:32.140 --> 00:23:36.950
you can see the connection to
what happened with the Google

00:23:36.950 --> 00:23:37.970
ad auction.

00:23:37.970 --> 00:23:39.620
So there's some
hidden connections

00:23:39.620 --> 00:23:41.420
that I think most
people aren't aware of.

00:23:41.420 --> 00:23:42.720
You probably would
have never guessed

00:23:42.720 --> 00:23:43.490
that would be an application.

00:23:43.490 --> 00:23:45.948
ALVIN ROTH: If you read that
chapter and you're Hal Varian,

00:23:45.948 --> 00:23:47.180
you can see the connection.

00:23:47.180 --> 00:23:48.750
HAL VARIAN: Well,
it does require

00:23:48.750 --> 00:23:51.080
a little bit of the insight
to see the connection.

00:23:51.080 --> 00:23:52.996
And the first time I
read it, I didn't see it.

00:23:52.996 --> 00:23:54.867
But after two or
three times, I got it.

00:23:54.867 --> 00:23:56.450
ALVIN ROTH: But when
we wrote in 1990,

00:23:56.450 --> 00:23:58.241
which surely weren't
thinking about Google.

00:23:58.241 --> 00:23:59.290
HAL VARIAN: Yes, yes.

00:23:59.290 --> 00:24:00.230
And there's lots more.

00:24:00.230 --> 00:24:04.020
I mean, if you think about it,
if you look at the tech world,

00:24:04.020 --> 00:24:06.890
not that you're a
west coaster, there

00:24:06.890 --> 00:24:08.480
are lots and lots
of applications.

00:24:08.480 --> 00:24:11.230
Matching up drivers with
passengers is what Uber does.

00:24:11.230 --> 00:24:16.670
Matching up short-term renters
with rooms is what Airbnb does

00:24:16.670 --> 00:24:21.750
and many, many other
applications of that sort.

00:24:21.750 --> 00:24:24.280
A lot of activity in this area.

00:24:24.280 --> 00:24:28.140
And again, I think they start
with these basic fundamental,

00:24:28.140 --> 00:24:29.359
simple algorithms.

00:24:29.359 --> 00:24:31.150
But then there are
always these edge cases.

00:24:31.150 --> 00:24:34.000
And there are always the
constraints and issues

00:24:34.000 --> 00:24:36.880
that arise on top
of that that make

00:24:36.880 --> 00:24:38.482
things difficult and exciting.

00:24:38.482 --> 00:24:39.440
ALVIN ROTH: Absolutely.

00:24:39.440 --> 00:24:42.160
And market design
is about details.

00:24:42.160 --> 00:24:44.050
But there are also some
general principles.

00:24:44.050 --> 00:24:48.055
And as you say, these
are matching markets.

00:24:48.055 --> 00:24:49.930
A lot of people, maybe
not here, but a lot of

00:24:49.930 --> 00:24:51.857
people when they
think about markets,

00:24:51.857 --> 00:24:54.440
think about commodity markets,
markets in which you don't care

00:24:54.440 --> 00:24:55.606
who you're transacting with.

00:24:55.606 --> 00:24:58.680
When you buy shares of stock
on the New York Stock Exchange,

00:24:58.680 --> 00:25:00.840
you don't care who
you're buying from.

00:25:00.840 --> 00:25:02.650
And they don't care
who they're selling to.

00:25:02.650 --> 00:25:05.960
But as you say, Airbnb
is as a matching market.

00:25:05.960 --> 00:25:10.430
You have to match a
traveler with a host.

00:25:10.430 --> 00:25:13.040
And there are lots
of markets where,

00:25:13.040 --> 00:25:14.580
even when prices
are important, they

00:25:14.580 --> 00:25:16.856
don't decide who gets what.

00:25:16.856 --> 00:25:19.230
The way I put it in the book
is that matching markets are

00:25:19.230 --> 00:25:22.130
markets in which you can't
simply choose what you want,

00:25:22.130 --> 00:25:23.805
you also have to be chosen.

00:25:23.805 --> 00:25:25.680
HAL VARIAN: And you look
at Google, in a way,

00:25:25.680 --> 00:25:27.780
we're matching up
people with questions

00:25:27.780 --> 00:25:28.950
with people with answers.

00:25:28.950 --> 00:25:31.930
I mean, maybe we give
them the answers directly.

00:25:31.930 --> 00:25:34.750
Maybe we send them to a site
where they can find the answer.

00:25:34.750 --> 00:25:37.670
So we're doing questions
and answers matching.

00:25:37.670 --> 00:25:41.670
And then we're also doing buyers
and sellers on the ad side.

00:25:41.670 --> 00:25:46.180
There's a lot of interest these
days emanating from Europe

00:25:46.180 --> 00:25:49.790
about multi-sided
platforms, where they're

00:25:49.790 --> 00:25:52.500
talking not necessarily
markets, per se,

00:25:52.500 --> 00:25:54.140
but places where
people can meet up.

00:25:54.140 --> 00:25:56.160
And this would include
Facebook as an example.

00:25:56.160 --> 00:25:58.580
Because you're matching
you and your friends

00:25:58.580 --> 00:26:00.670
and potential friends and so on.

00:26:00.670 --> 00:26:02.912
Do you encounter
that issue, I mean,

00:26:02.912 --> 00:26:04.870
where you're talking more
about platforms which

00:26:04.870 --> 00:26:08.470
is an industrial organization
sort of topic as opposed

00:26:08.470 --> 00:26:11.210
to markets as
narrowly construed?

00:26:11.210 --> 00:26:13.630
ALVIN ROTH: Oh, again, I
think of markets very broadly.

00:26:13.630 --> 00:26:14.870
HAL VARIAN: Pretty broadly.

00:26:14.870 --> 00:26:16.286
ALVIN ROTH: So
absolutely, I think

00:26:16.286 --> 00:26:19.130
that the things we talk about
platforms-- in the book,

00:26:19.130 --> 00:26:21.580
I talk about things
that are often

00:26:21.580 --> 00:26:25.890
thought about as platforms,
like for instance credit cards

00:26:25.890 --> 00:26:32.610
and smartphone operating
systems and things like that.

00:26:32.610 --> 00:26:34.222
So the same reason
there are just

00:26:34.222 --> 00:26:36.430
a few credit cards is the
reason why they're are just

00:26:36.430 --> 00:26:38.120
a few smartphone
operating systems.

00:26:38.120 --> 00:26:41.350
Because you want an operating
system that has a lot of apps.

00:26:41.350 --> 00:26:43.820
And the app developers
want operating system

00:26:43.820 --> 00:26:45.870
that has a lot of users.

00:26:45.870 --> 00:26:46.370
Yeah.

00:26:46.370 --> 00:26:49.630
ALVIN ROTH: So I think of
it as being part and parcel

00:26:49.630 --> 00:26:50.950
of making a market thick.

00:26:50.950 --> 00:26:51.658
HAL VARIAN: Yeah.

00:26:51.658 --> 00:26:53.700
And when you think about
Google, again, we've

00:26:53.700 --> 00:26:56.350
got the people, the
questions, and the answers.

00:26:56.350 --> 00:26:59.530
And we've also got the
content generators.

00:26:59.530 --> 00:27:02.570
And so you want to look
at the whole ecosystem

00:27:02.570 --> 00:27:04.620
and try to figure
out how can I develop

00:27:04.620 --> 00:27:09.320
a system that sort of satisfies
all the parties involved.

00:27:09.320 --> 00:27:11.420
And of course, there are
inevitably trade offs.

00:27:11.420 --> 00:27:15.540
In fact, let me go back to the
very simple stable marriage

00:27:15.540 --> 00:27:16.755
problem.

00:27:16.755 --> 00:27:18.380
You talked about the
case where the men

00:27:18.380 --> 00:27:20.190
are doing the proposing.

00:27:20.190 --> 00:27:21.550
But, hey, there's another side.

00:27:21.550 --> 00:27:22.950
The women could
do the proposing.

00:27:22.950 --> 00:27:24.324
So what's the
difference between?

00:27:24.324 --> 00:27:26.500
Do you get the same
outcome, different outcomes?

00:27:26.500 --> 00:27:28.226
ALVIN ROTH: Well,
in small markets

00:27:28.226 --> 00:27:29.350
you get different outcomes.

00:27:29.350 --> 00:27:32.620
And the difference
matters systematically.

00:27:32.620 --> 00:27:35.920
The men like better
the stable matching

00:27:35.920 --> 00:27:37.290
that results when men propose.

00:27:37.290 --> 00:27:39.830
And the women like
better the outcome that

00:27:39.830 --> 00:27:41.370
results when women propose.

00:27:41.370 --> 00:27:43.400
Now it turns out
in large markets

00:27:43.400 --> 00:27:46.070
or in markets with different
numbers of people on each side,

00:27:46.070 --> 00:27:47.940
those differences go
away pretty quickly.

00:27:47.940 --> 00:27:51.440
So when we look at most of
the markets we deal with,

00:27:51.440 --> 00:27:55.834
the set of stable
matchings is very small.

00:27:55.834 --> 00:27:58.000
So it turns out you can
always get a stable matching

00:27:58.000 --> 00:27:59.427
in these two-sided markets.

00:27:59.427 --> 00:28:01.260
But there's a sense in
which it's very hard.

00:28:01.260 --> 00:28:03.880
Having to get a stable
matching pretty much

00:28:03.880 --> 00:28:07.000
determines the outcome
in many of these markets.

00:28:07.000 --> 00:28:09.200
HAL VARIAN: So we
talked about some

00:28:09.200 --> 00:28:13.500
of the existing players in
this matching world, the Ubers

00:28:13.500 --> 00:28:16.850
and Airbnbs, and others.

00:28:16.850 --> 00:28:21.030
Have you talked to any
interesting startups

00:28:21.030 --> 00:28:22.730
that are not widely known yet?

00:28:22.730 --> 00:28:23.729
I know one.

00:28:23.729 --> 00:28:24.770
I'll tell you about mine.

00:28:24.770 --> 00:28:25.610
But I want to hear
from you first.

00:28:25.610 --> 00:28:27.318
ALVIN ROTH: I've talked
to some startups.

00:28:27.318 --> 00:28:29.860
But I also think about markets
that might now lend themselves

00:28:29.860 --> 00:28:32.919
to startups that could
use some help in matching.

00:28:32.919 --> 00:28:34.710
One of the startups I
mentioned int he book

00:28:34.710 --> 00:28:37.900
is a company called
BandwidthX that's

00:28:37.900 --> 00:28:41.650
trying to match up travelers
and their smartphones

00:28:41.650 --> 00:28:44.690
with unused Wi-Fi.

00:28:44.690 --> 00:28:47.162
This would be seamless as
far as you were concerned.

00:28:47.162 --> 00:28:48.620
But sometimes your
smartphone would

00:28:48.620 --> 00:28:50.895
connect to the Wi-Fi
in my apartment

00:28:50.895 --> 00:28:52.760
while I'm here and
things like that.

00:28:52.760 --> 00:28:56.510
And so the contract
would be with the cable

00:28:56.510 --> 00:28:58.827
provider things like that.

00:28:58.827 --> 00:29:01.160
But among the matching markets
I'm a little bit thinking

00:29:01.160 --> 00:29:05.610
about these days as I read
about refugee resettlement,

00:29:05.610 --> 00:29:07.810
it turns out refugee
resettlement policies

00:29:07.810 --> 00:29:11.330
are a little bit like early
days computer science.

00:29:11.330 --> 00:29:14.520
They don't always take account
of people's preferences.

00:29:14.520 --> 00:29:17.690
So mostly we're reading
about refugees in Europe,

00:29:17.690 --> 00:29:20.500
in Calais trying
to get to England.

00:29:20.500 --> 00:29:21.990
But here in the
United States, we

00:29:21.990 --> 00:29:25.720
have a policy that we
try to resettle people

00:29:25.720 --> 00:29:28.220
sort of broadly across the
country with the idea that

00:29:28.220 --> 00:29:30.670
helps assimilation and
doesn't put too much

00:29:30.670 --> 00:29:32.039
of a burden on communities.

00:29:32.039 --> 00:29:34.330
But of course, once someone
comes to the United States,

00:29:34.330 --> 00:29:36.830
they can get on a bus and
go wherever they want.

00:29:36.830 --> 00:29:40.400
So it so it turns out that
there's a thriving community

00:29:40.400 --> 00:29:43.070
of Somali immigrants in Maine.

00:29:43.070 --> 00:29:46.340
Not because the Maine climate
is a lot like Somalia,

00:29:46.340 --> 00:29:48.800
but because there's already
a thriving community there.

00:29:48.800 --> 00:29:52.650
And so people are prepared to
give up the housing subsidies

00:29:52.650 --> 00:29:55.500
that we offer them in far places
in order to go to the places

00:29:55.500 --> 00:29:56.432
they want to be.

00:29:56.432 --> 00:29:58.640
So I think that as we think
about things like refugee

00:29:58.640 --> 00:30:01.056
resettlement, we have to think
not just about individuals,

00:30:01.056 --> 00:30:03.749
but about communities and
about what they would like.

00:30:03.749 --> 00:30:06.040
HAL VARIAN: There was a great
story in "The Wall Street

00:30:06.040 --> 00:30:09.400
Journal" several years ago
about Cambodian doughnut shops.

00:30:09.400 --> 00:30:12.582
It turned out that
something like 25% or 30%

00:30:12.582 --> 00:30:14.040
of the doughnut
shops in California

00:30:14.040 --> 00:30:16.260
are run by Cambodians.

00:30:16.260 --> 00:30:20.405
And it all started with one
guy brought his brother over.

00:30:20.405 --> 00:30:22.130
And the brother had a son.

00:30:22.130 --> 00:30:24.320
And so they expanded
into this industry.

00:30:24.320 --> 00:30:26.470
But the punchline
of the argument

00:30:26.470 --> 00:30:29.769
was that Cambodians really
didn't eat doughnuts, which

00:30:29.769 --> 00:30:32.310
is maybe a good thing to do if
you're running a doughnut shop

00:30:32.310 --> 00:30:33.760
if you don't really like them.

00:30:33.760 --> 00:30:34.700
ALVIN ROTH: But
that's a common--

00:30:34.700 --> 00:30:35.460
HAL VARIAN: Common occurrence.

00:30:35.460 --> 00:30:37.376
ALVIN ROTH: --pattern
of emigration in the US.

00:30:37.376 --> 00:30:40.840
So there are concentrations
of Koreans in dry cleaning,

00:30:40.840 --> 00:30:42.790
of Indians in motels.

00:30:42.790 --> 00:30:44.980
And it has to do with
coming over and having

00:30:44.980 --> 00:30:47.674
a cousin who will take care
of you while you get settled.

00:30:47.674 --> 00:30:49.340
And in the course of
taking care of you,

00:30:49.340 --> 00:30:50.381
you work in his business.

00:30:50.381 --> 00:30:52.495
And he tells you how
to contact suppliers

00:30:52.495 --> 00:30:53.990
and how to deal with customers.

00:30:53.990 --> 00:30:55.744
And then you can set up.

00:30:55.744 --> 00:30:56.410
HAL VARIAN: Yup.

00:30:56.410 --> 00:30:57.350
Yup.

00:30:57.350 --> 00:31:00.640
Tell us a bit about
your kidney exchange.

00:31:00.640 --> 00:31:04.200
I think that's a very exciting
and interesting story.

00:31:04.200 --> 00:31:06.720
ALVIN ROTH: So organ
transplantation

00:31:06.720 --> 00:31:09.790
is a fascinating area.

00:31:09.790 --> 00:31:12.970
But it's also a critical
health care need.

00:31:12.970 --> 00:31:16.050
Right now, there are 100,000
people in the United States

00:31:16.050 --> 00:31:18.400
on a waiting list for
a deceased donor organ.

00:31:18.400 --> 00:31:20.874
So those of you who have
California driver's licenses

00:31:20.874 --> 00:31:23.290
if you look at your license,
you might see whether there's

00:31:23.290 --> 00:31:24.831
a little pink dot
on it or not, which

00:31:24.831 --> 00:31:27.060
will have to do with
whether you registered

00:31:27.060 --> 00:31:29.140
to be a deceased organ
donor when you've

00:31:29.140 --> 00:31:30.320
got your driver's license.

00:31:30.320 --> 00:31:31.270
And you can still do that.

00:31:31.270 --> 00:31:32.811
If it's not on your
driver's license,

00:31:32.811 --> 00:31:37.910
there's a website at--
I forget the name now.

00:31:37.910 --> 00:31:41.497
It's part of the California
government website.

00:31:41.497 --> 00:31:42.580
donatelife.gov.california.

00:31:47.047 --> 00:31:48.880
But the aren't enough
deceased donor organs.

00:31:48.880 --> 00:31:50.879
Even if you all registered,
there aren't enough.

00:31:50.879 --> 00:31:54.600
Because it's very hard to die
in a way that makes your organs

00:31:54.600 --> 00:31:55.100
donatable.

00:31:57.746 --> 00:31:59.410
HAL VARIAN: Well,
that's a relief.

00:31:59.410 --> 00:32:01.249
ALVIN ROTH: Well,
transplantation

00:32:01.249 --> 00:32:02.040
is a funny subject.

00:32:02.040 --> 00:32:03.710
There's good news and
bad news mixed in.

00:32:03.710 --> 00:32:05.880
So the bad news is there
aren't enough donors.

00:32:05.880 --> 00:32:09.110
The good news is traffic
fatalities in the United States

00:32:09.110 --> 00:32:13.050
have really dropped
since we were young.

00:32:13.050 --> 00:32:14.270
But kidneys are unusual.

00:32:14.270 --> 00:32:17.150
Because you each
have two kidneys.

00:32:17.150 --> 00:32:19.930
And if you're healthy,
you can remain healthy

00:32:19.930 --> 00:32:21.160
with just one kidney.

00:32:21.160 --> 00:32:25.420
And that means that if you new
someone, if you love someone

00:32:25.420 --> 00:32:27.300
who is dying of
kidney failure, you

00:32:27.300 --> 00:32:29.830
might be able to donate
a kidney to them.

00:32:29.830 --> 00:32:31.757
And donating a kidney
has two parts to it.

00:32:31.757 --> 00:32:34.090
First, you have to be healthy
enough to donate a kidney.

00:32:34.090 --> 00:32:36.940
But second, your kidney
has to match them.

00:32:36.940 --> 00:32:39.260
Not everyone can take
everyone else's kidney.

00:32:39.260 --> 00:32:41.440
And often, that
second part fails.

00:32:41.440 --> 00:32:43.250
And that's where kidney
exchange comes in.

00:32:43.250 --> 00:32:45.459
It could be that you love
someone who needs a kidney.

00:32:45.459 --> 00:32:47.333
And you're healthy enough
to donate a kidney.

00:32:47.333 --> 00:32:48.960
But you can't donate it to them.

00:32:48.960 --> 00:32:50.620
And I'm in the same situation.

00:32:50.620 --> 00:32:53.460
But maybe you can donate
a kidney to my patient.

00:32:53.460 --> 00:32:55.290
And I can donate a
kidney to your patient.

00:32:55.290 --> 00:32:57.700
And so that's a simple exchange.

00:32:57.700 --> 00:32:59.200
It doesn't involve any money.

00:32:59.200 --> 00:33:01.170
Because it turns out
it's against the law

00:33:01.170 --> 00:33:03.480
to pay money for a kidney
in the United States

00:33:03.480 --> 00:33:06.580
and almost everywhere in the
world, the single exception

00:33:06.580 --> 00:33:08.470
being the Islamic
Republic of Iran,

00:33:08.470 --> 00:33:10.255
where there's a cash
market for kidneys,

00:33:10.255 --> 00:33:11.717
a monetary market for kidneys.

00:33:11.717 --> 00:33:13.800
For the rest of the world,
you can't buy a kidney.

00:33:13.800 --> 00:33:17.010
But you can exchange kidneys.

00:33:17.010 --> 00:33:19.420
There's an amendment to the
National Organ Transplant Act

00:33:19.420 --> 00:33:21.044
that makes it clear
that this is legal.

00:33:21.044 --> 00:33:23.920
But we had already started
kidney exchange in the United

00:33:23.920 --> 00:33:25.450
States before that.

00:33:25.450 --> 00:33:28.910
And over the years we've
gone from simple exchanges,

00:33:28.910 --> 00:33:31.330
like the one I just
described between two pairs,

00:33:31.330 --> 00:33:34.740
to very complicated exchanges
that may involve long chains.

00:33:34.740 --> 00:33:37.200
And some of these are
reported in newspapers.

00:33:37.200 --> 00:33:40.960
And you see sets of pictures
of 60 people in them

00:33:40.960 --> 00:33:45.690
or more, which means 30
donors and 30 transplants.

00:33:45.690 --> 00:33:49.150
So this is where the
computationally difficult

00:33:49.150 --> 00:33:51.370
optimization problems come in.

00:33:51.370 --> 00:33:53.020
But so far, we're
able to solve them.

00:33:53.020 --> 00:33:56.180
And kidney exchange
in the United States

00:33:56.180 --> 00:33:59.950
has become a standard form of
transportation still growing.

00:33:59.950 --> 00:34:03.110
About 10% of the
living donor kidney

00:34:03.110 --> 00:34:06.520
transplants in the United States
are now done through exchange.

00:34:06.520 --> 00:34:09.280
My computer science and
economics colleagues and I

00:34:09.280 --> 00:34:12.730
have worked with a variety
of exchanges and hospitals.

00:34:12.730 --> 00:34:15.880
And it's spreading
around the world as well.

00:34:15.880 --> 00:34:17.069
So that's been a lot of fun.

00:34:17.069 --> 00:34:18.860
HAL VARIAN: So there
is a constraint there.

00:34:18.860 --> 00:34:21.080
And it's different than the
brother, sister, husband,

00:34:21.080 --> 00:34:22.110
wife kind of constraint.

00:34:22.110 --> 00:34:25.940
And I know you've thought
about this issue of repugnance,

00:34:25.940 --> 00:34:28.614
that people are
opposed at this idea,

00:34:28.614 --> 00:34:31.802
they find it distasteful that
somebody might sell a body part

00:34:31.802 --> 00:34:32.760
or something like that.

00:34:32.760 --> 00:34:34.710
ALVIN ROTH: And it's a
felony in the United States.

00:34:34.710 --> 00:34:35.219
HAL VARIAN: A felony.

00:34:35.219 --> 00:34:36.820
ALVIN ROTH: So the National
Organ Transplant Act

00:34:36.820 --> 00:34:39.159
makes it a felony for you
to sell me your kidney

00:34:39.159 --> 00:34:42.480
or for me to buy your kidney.

00:34:42.480 --> 00:34:44.239
So I got interested
in the question

00:34:44.239 --> 00:34:45.380
of repugnant transactions.

00:34:45.380 --> 00:34:48.080
Because of course,
there are 100,000 people

00:34:48.080 --> 00:34:50.949
waiting for kidneys
in the United States.

00:34:50.949 --> 00:34:52.350
Thousands die each year.

00:34:52.350 --> 00:34:56.679
It's not that this
is a costless wait.

00:34:56.679 --> 00:34:59.264
So it's interesting
that everywhere

00:34:59.264 --> 00:35:01.180
in the world, just about,
it's against the law

00:35:01.180 --> 00:35:02.440
to buy and sell kidneys.

00:35:02.440 --> 00:35:04.290
At the same time, there
are black markets.

00:35:04.290 --> 00:35:07.300
There are people
desperate to buy kidneys.

00:35:07.300 --> 00:35:09.190
And there are people
willing to sell them.

00:35:09.190 --> 00:35:12.530
But black markets, in which you
have to deal with criminals,

00:35:12.530 --> 00:35:15.760
because they're against the law,
often work very, very badly.

00:35:15.760 --> 00:35:19.450
So they give few
guarantees and little

00:35:19.450 --> 00:35:22.410
post operative care to the
donor or sellers and things

00:35:22.410 --> 00:35:23.040
like that.

00:35:23.040 --> 00:35:28.440
But there's lively debate among
surgeons and among patients

00:35:28.440 --> 00:35:31.050
and among other people about
whether this is a good law

00:35:31.050 --> 00:35:33.200
or not.

00:35:33.200 --> 00:35:35.830
Without presuming to
answer that question,

00:35:35.830 --> 00:35:37.711
I can't help but be
impressed by noticing

00:35:37.711 --> 00:35:40.210
that this is something that's
illegal just about everywhere.

00:35:40.210 --> 00:35:43.120
So I started to get interested
in the question of what

00:35:43.120 --> 00:35:46.130
I call repugnant transactions,
which are transactions

00:35:46.130 --> 00:35:47.875
that some people would
like to engage in

00:35:47.875 --> 00:35:50.290
and other people think
they shouldn't, even

00:35:50.290 --> 00:35:53.030
though those people
may not directly

00:35:53.030 --> 00:35:55.070
be harmed by the transaction.

00:35:55.070 --> 00:35:57.390
So there are a lot of
examples from the profound

00:35:57.390 --> 00:35:58.200
to the trivial.

00:35:58.200 --> 00:36:02.450
For instance, I just had
lunch at Google cafeteria.

00:36:02.450 --> 00:36:04.350
And one thing I can
tell you with confidence

00:36:04.350 --> 00:36:06.530
is they never serve horse meat.

00:36:06.530 --> 00:36:08.320
Because it turns out
it's against the law

00:36:08.320 --> 00:36:11.450
to serve horse meat for human
consumption in California.

00:36:11.450 --> 00:36:14.590
And that's not an ancient
cowboy law from the time

00:36:14.590 --> 00:36:16.880
when a horse was a
man's best friend.

00:36:16.880 --> 00:36:19.840
That's the result of
a 1998 referendum.

00:36:19.840 --> 00:36:22.260
It turns out there were
sufficient petitions

00:36:22.260 --> 00:36:23.900
to get that on the ballot.

00:36:23.900 --> 00:36:26.040
And Californians voted for it.

00:36:26.040 --> 00:36:28.630
And of course, it's not
because no one in California

00:36:28.630 --> 00:36:29.730
wants to ear horse meat.

00:36:29.730 --> 00:36:32.810
It's because some people in
California do want to eat horse

00:36:32.810 --> 00:36:35.410
meat and other people
think they shouldn't.

00:36:35.410 --> 00:36:40.750
There's no law against eating
cockroaches in California.

00:36:40.750 --> 00:36:42.595
HAL VARIAN: Or New York.

00:36:42.595 --> 00:36:43.960
ALVIN ROTH: Or New York.

00:36:43.960 --> 00:36:45.335
HAL VARIAN: Now
were you around--

00:36:45.335 --> 00:36:47.460
the Harvard Faculty Club
used to serve horse meat--

00:36:47.460 --> 00:36:47.870
ALVIN ROTH: It did.

00:36:47.870 --> 00:36:49.030
HAL VARIAN: --when
I visited there.

00:36:49.030 --> 00:36:50.220
And you could have it.

00:36:50.220 --> 00:36:53.839
It was put in place, as I
remember, in World War--

00:36:53.839 --> 00:36:54.880
ALVIN ROTH: World War II.

00:36:54.880 --> 00:36:54.950
HAL VARIAN: --World War II?

00:36:54.950 --> 00:36:55.450
ALVIN ROTH: Or
World War I maybe.

00:36:55.450 --> 00:36:58.074
HAL VARIAN: I think it was World
War I. Because the horses were

00:36:58.074 --> 00:37:03.490
used to World War I.
And the beef was being

00:37:03.490 --> 00:37:05.100
sent to the soldiers and so on.

00:37:05.100 --> 00:37:06.840
And so it was a
patriotic measure.

00:37:06.840 --> 00:37:09.610
But Harvard being Harvard,
it never took it off.

00:37:09.610 --> 00:37:15.110
So I think it was 1970, 19--
yeah, it was a 60 years.

00:37:15.110 --> 00:37:17.150
For 60 years at least,
you could eat horse meat

00:37:17.150 --> 00:37:18.150
at the Harvard Faculty Club.

00:37:18.150 --> 00:37:20.250
But I think even that's
gone, these old traditions.

00:37:20.250 --> 00:37:21.208
ALVIN ROTH: It is gone.

00:37:21.208 --> 00:37:23.042
And it's gone for-- I
don't know exactly why

00:37:23.042 --> 00:37:24.207
at the Harvard Faculty Club.

00:37:24.207 --> 00:37:26.480
But in fact, although it's
only illegal in California,

00:37:26.480 --> 00:37:29.000
you can't eat horse meat
anywhere in the United States.

00:37:29.000 --> 00:37:31.000
It's not illegal,
but you can't get it.

00:37:31.000 --> 00:37:33.340
And the reason you
can't get it is Congress

00:37:33.340 --> 00:37:36.065
on several occasions tried
to pass a law against eating

00:37:36.065 --> 00:37:37.380
horse meat and failed.

00:37:37.380 --> 00:37:39.760
But you can't eat any
meat in the United States

00:37:39.760 --> 00:37:42.820
unless it is graded grade A,
fit for human consumption,

00:37:42.820 --> 00:37:44.660
by the US Department
of Agriculture.

00:37:44.660 --> 00:37:47.465
And Congress for many years
now has withheld funds

00:37:47.465 --> 00:37:48.840
for the Department
of Agriculture

00:37:48.840 --> 00:37:50.270
to inspect horse meat.

00:37:50.270 --> 00:37:53.486
So there is no USDA
grade A horse meat

00:37:53.486 --> 00:37:54.360
in the United States.

00:37:54.360 --> 00:37:57.850
Although, it would be perfectly
legal for you to eat it.

00:37:57.850 --> 00:37:59.520
But there are more
profound kinds

00:37:59.520 --> 00:38:01.510
of repugnant transactions.

00:38:01.510 --> 00:38:04.230
Think about same sex marriage.

00:38:04.230 --> 00:38:06.960
I think of that as a sort
of prototypical repugnant

00:38:06.960 --> 00:38:07.490
transaction.

00:38:07.490 --> 00:38:08.930
Some people wanted
to marry each other.

00:38:08.930 --> 00:38:11.388
And other people, who weren't
involved and weren't planning

00:38:11.388 --> 00:38:14.350
to necessarily marry
themselves, other people thought

00:38:14.350 --> 00:38:16.570
they shouldn't, so a
repugnant transaction.

00:38:16.570 --> 00:38:18.580
And in the last 12
years, we've gone

00:38:18.580 --> 00:38:21.480
from having that legal in
no American state to being

00:38:21.480 --> 00:38:23.200
legal in every American state.

00:38:23.200 --> 00:38:24.770
So repugnance can change.

00:38:24.770 --> 00:38:27.370
But it's not that as
we get more modern,

00:38:27.370 --> 00:38:29.710
old repugnances
necessarily die away.

00:38:29.710 --> 00:38:32.300
There are things that used
to be not so repugnant that

00:38:32.300 --> 00:38:33.820
are now repugnant.

00:38:33.820 --> 00:38:35.770
We used to sell slaves
in the United States.

00:38:35.770 --> 00:38:37.130
We don't do that anymore.

00:38:37.130 --> 00:38:39.340
And the most common
way of buying passage

00:38:39.340 --> 00:38:41.410
across the Atlantic
Ocean to North America

00:38:41.410 --> 00:38:44.590
used to be to sell
yourself into a five year

00:38:44.590 --> 00:38:46.300
contract of
indentured servitude,

00:38:46.300 --> 00:38:49.000
of voluntary slavery
for a fixed term.

00:38:49.000 --> 00:38:50.540
And we don't do that anymore.

00:38:50.540 --> 00:38:53.485
So there are things
that used to be

00:38:53.485 --> 00:38:56.110
not so repugnant that we didn't
do them that are now repugnant.

00:38:56.110 --> 00:38:58.520
There used to be
things that were

00:38:58.520 --> 00:39:00.150
repugnant that are no longer.

00:39:00.150 --> 00:39:02.510
And it's possible
that our understanding

00:39:02.510 --> 00:39:07.150
of how to elicit organ donations
may start to be in flux.

00:39:07.150 --> 00:39:10.252
It's certainly a topic
of lively conversation.

00:39:10.252 --> 00:39:11.960
HAL VARIAN: To change
gears a little bit,

00:39:11.960 --> 00:39:13.600
there's another
interesting market

00:39:13.600 --> 00:39:16.440
that's being developed now
by some of your colleagues

00:39:16.440 --> 00:39:17.440
at Stanford.

00:39:17.440 --> 00:39:19.900
That's the incentive
market for spectrum,

00:39:19.900 --> 00:39:24.450
where they're trying to get
spectrum from TV stations

00:39:24.450 --> 00:39:29.670
to sell in to the government
as an intermediary, who then

00:39:29.670 --> 00:39:33.000
repackages that
spectrum, moves the TV

00:39:33.000 --> 00:39:34.560
stations to different
frequencies,

00:39:34.560 --> 00:39:38.130
and then sells the freed up
spectrum to the mobile phone

00:39:38.130 --> 00:39:38.630
carriers.

00:39:38.630 --> 00:39:41.140
And so this is a very
big efficiency from this.

00:39:41.140 --> 00:39:43.430
Because there are
stations, TV stations,

00:39:43.430 --> 00:39:45.290
that have very tiny
audiences where

00:39:45.290 --> 00:39:48.080
the spectrum their utilizing
would be immensely more

00:39:48.080 --> 00:39:54.040
valuable from the point of view
of mobile telephony and mobile

00:39:54.040 --> 00:39:55.550
data use.

00:39:55.550 --> 00:39:57.377
Have you been involved
with that at all?

00:39:57.377 --> 00:39:59.710
ALVIN ROTH: Well, Paul Milgrom
and some of my colleagues

00:39:59.710 --> 00:40:00.710
are deeply involved in that.

00:40:00.710 --> 00:40:01.910
So I hear a lot about it.

00:40:01.910 --> 00:40:04.950
One of the important
market design

00:40:04.950 --> 00:40:07.399
features that you mentioned
in passing there has

00:40:07.399 --> 00:40:08.690
to do with the property rights.

00:40:08.690 --> 00:40:11.230
What is it that the
television stations were given

00:40:11.230 --> 00:40:12.420
and that they own?

00:40:12.420 --> 00:40:16.054
And what the Federal
Communications Commission

00:40:16.054 --> 00:40:17.720
decided is that what
they had been given

00:40:17.720 --> 00:40:21.231
was a bandwidth, but not
particular frequencies.

00:40:21.231 --> 00:40:21.980
HAL VARIAN: Right.

00:40:21.980 --> 00:40:26.390
ALVIN ROTH: And so that means
that when the FCC buys back

00:40:26.390 --> 00:40:28.970
some spectrum from
some TV stations,

00:40:28.970 --> 00:40:32.570
they can then compactify
the remaining TV station so

00:40:32.570 --> 00:40:34.280
that the rest of the
spectrum could be

00:40:34.280 --> 00:40:35.572
used efficiently in other ways.

00:40:35.572 --> 00:40:36.446
HAL VARIAN: Yup, yup.

00:40:36.446 --> 00:40:38.800
ALVIN ROTH: And that was an
interesting property rights

00:40:38.800 --> 00:40:40.900
decision that has this
very nice consequence

00:40:40.900 --> 00:40:43.390
that we can make more
efficient use of spectrum now.

00:40:43.390 --> 00:40:45.380
You could imagine
that they would

00:40:45.380 --> 00:40:47.260
have decided that what
the TV stations owned

00:40:47.260 --> 00:40:49.554
was the particular band
on which they broadcast.

00:40:49.554 --> 00:40:50.970
And that would
make it much harder

00:40:50.970 --> 00:40:53.190
to repurpose the spectrum.

00:40:53.190 --> 00:40:54.960
And of course in the
old days, TV stations

00:40:54.960 --> 00:40:59.710
were given their spectrum
through political processes.

00:40:59.710 --> 00:41:01.210
They didn't bid for them.

00:41:01.210 --> 00:41:04.612
And they originally
had analog spectrum.

00:41:04.612 --> 00:41:06.820
Then they were given different
spectrum that was more

00:41:06.820 --> 00:41:09.030
suited to digital purposes.

00:41:09.030 --> 00:41:12.030
And many TV companies, therefore
broadcasting companies,

00:41:12.030 --> 00:41:15.600
now own both kinds of spectrum,
even though there only making

00:41:15.600 --> 00:41:17.802
active use of one.

00:41:17.802 --> 00:41:18.510
HAL VARIAN: Yeah.

00:41:18.510 --> 00:41:22.270
And also there's an interesting
computational problem

00:41:22.270 --> 00:41:23.530
in doing that repacking.

00:41:23.530 --> 00:41:26.660
Because at one point, people
were somewhat skeptical

00:41:26.660 --> 00:41:29.370
that it could be done
in a time frame that

00:41:29.370 --> 00:41:32.080
was appropriate for
this auction process.

00:41:32.080 --> 00:41:34.620
But it turns out there have
been made great advances there.

00:41:34.620 --> 00:41:36.460
And doing their
repacking of spectrum

00:41:36.460 --> 00:41:37.965
is now pretty straightforward.

00:41:37.965 --> 00:41:38.715
ALVIN ROTH: Right.

00:41:38.715 --> 00:41:42.912
And a lot of this has to do
with machine learning things.

00:41:42.912 --> 00:41:43.620
HAL VARIAN: Yeah.

00:41:43.620 --> 00:41:45.078
ALVIN ROTH: So
Kevin Leighton Brown

00:41:45.078 --> 00:41:47.024
is one of the people
who is involved in this.

00:41:47.024 --> 00:41:47.690
HAL VARIAN: Yup.

00:41:47.690 --> 00:41:49.760
We're going to be
coming up-- at Google,

00:41:49.760 --> 00:41:52.060
we're quite interested
in this 3.5 gigahertz

00:41:52.060 --> 00:41:54.250
spectrum, which is
going to be coming

00:41:54.250 --> 00:41:56.030
available in the next few years.

00:41:56.030 --> 00:41:58.442
And it will be kind
of Wi-Fi on steroids.

00:41:58.442 --> 00:41:59.400
So it's high frequency.

00:41:59.400 --> 00:42:01.580
You can pack a lot
of data into it.

00:42:01.580 --> 00:42:05.630
But by the same token, it has
very poor propagation policies.

00:42:05.630 --> 00:42:07.970
So the question is
what kind of market

00:42:07.970 --> 00:42:10.790
or what kind of, let's say,
platform or arrangement

00:42:10.790 --> 00:42:13.190
is appropriate for
utilizing that spectrum?

00:42:13.190 --> 00:42:15.970
Because it would be something
that we could really

00:42:15.970 --> 00:42:19.840
increase wireless access
quite dramatically

00:42:19.840 --> 00:42:22.550
at much lower cost.

00:42:22.550 --> 00:42:23.920
Well, I've talked enough here.

00:42:23.920 --> 00:42:26.745
I'd like to take some
questions from the audience.

00:42:26.745 --> 00:42:29.782
Do we have any questions
out there for Al?

00:42:29.782 --> 00:42:30.740
ALVIN ROTH: Or for Hal?

00:42:30.740 --> 00:42:31.840
HAL VARIAN: Or for Hal?

00:42:31.840 --> 00:42:32.910
Yeah, yeah.

00:42:32.910 --> 00:42:37.554
It's only a little
aspirated consonant away.

00:42:37.554 --> 00:42:38.400
Yeah?

00:42:38.400 --> 00:42:40.600
AUDIENCE: I noticed that
your degrees were in OR.

00:42:40.600 --> 00:42:43.940
And I wondered how did you
make the transition from OR

00:42:43.940 --> 00:42:44.786
to economics?

00:42:44.786 --> 00:42:46.160
And is that a
natural transition?

00:42:46.160 --> 00:42:47.580
Obviously, game
theory shows up there.

00:42:47.580 --> 00:42:48.320
ALVIN ROTH: OK.

00:42:48.320 --> 00:42:51.544
So how did I make the
transition from OR to economics?

00:42:51.544 --> 00:42:52.960
I'll answer the
question two ways.

00:42:52.960 --> 00:42:55.330
Because in some moods I
feel like I never transited.

00:42:55.330 --> 00:42:57.770
I just stayed doing
what I was doing,

00:42:57.770 --> 00:43:01.500
and the disciplinary
boundaries shifted around me.

00:43:01.500 --> 00:43:03.790
So I did get my degree
in Operations Research.

00:43:03.790 --> 00:43:06.940
I wanted to help make
things work better.

00:43:06.940 --> 00:43:09.730
But the things that
I was interested in

00:43:09.730 --> 00:43:12.130
were multi-user systems.

00:43:12.130 --> 00:43:13.950
So I started to
study game theory.

00:43:13.950 --> 00:43:17.540
And it looked like game theory,
when I got my PhD in 1974,

00:43:17.540 --> 00:43:19.470
it looked like game
theory was going to thrive

00:43:19.470 --> 00:43:21.070
in Operations Research.

00:43:21.070 --> 00:43:23.730
But the game theory
in 1974 didn't yet

00:43:23.730 --> 00:43:25.630
have an engineering
aspect to it.

00:43:25.630 --> 00:43:28.460
So it didn't initially thrive
in Operations Research.

00:43:28.460 --> 00:43:29.800
It thrived in economics.

00:43:29.800 --> 00:43:32.190
So that's the part of the
story that says I just

00:43:32.190 --> 00:43:33.980
stay doing what I was doing.

00:43:33.980 --> 00:43:35.990
And now that we've
developed an engineering

00:43:35.990 --> 00:43:39.880
part of game theory,
market design,

00:43:39.880 --> 00:43:41.940
it's something that
crosses boundaries.

00:43:41.940 --> 00:43:46.240
When my colleagues and I
teach a three quarter sequence

00:43:46.240 --> 00:43:48.470
in market design at
Stanford our students

00:43:48.470 --> 00:43:50.090
come not just from
economics, but also

00:43:50.090 --> 00:43:52.190
from the Department
of Management Science

00:43:52.190 --> 00:43:55.390
and Engineering, which
is where OR settled down

00:43:55.390 --> 00:43:57.710
and from computer science
and from the business school.

00:43:57.710 --> 00:43:59.250
So I think of market
design as being

00:43:59.250 --> 00:44:02.530
something that is inherently
multi-disciplinary.

00:44:07.190 --> 00:44:10.520
AUDIENCE: Thank you
so much for coming.

00:44:10.520 --> 00:44:14.610
My question has to do
with the kidney exchange.

00:44:14.610 --> 00:44:17.380
I read that many of those
chains, the longer ones,

00:44:17.380 --> 00:44:20.547
require an altruistic first
give in order for them

00:44:20.547 --> 00:44:21.380
to all fall in line.

00:44:21.380 --> 00:44:21.690
ALVIN ROTH: Yup.

00:44:21.690 --> 00:44:24.065
AUDIENCE: I was wondering if
there was other markets that

00:44:24.065 --> 00:44:26.642
require an amount of
altruism or that first person

00:44:26.642 --> 00:44:28.100
to say they don't
have a preference

00:44:28.100 --> 00:44:30.930
or will give something in
order to make the chain work.

00:44:30.930 --> 00:44:34.540
ALVIN ROTH: Well, it's true that
to do a non-simultaneous chain,

00:44:34.540 --> 00:44:37.340
we like to start with a
non-directed donor, someone

00:44:37.340 --> 00:44:40.920
who doesn't have a patient
who needs a kidney.

00:44:40.920 --> 00:44:45.550
That way each patient donor
pair that gives a kidney

00:44:45.550 --> 00:44:46.650
first gets a kidney.

00:44:46.650 --> 00:44:48.950
So that if there's a
break in the chain,

00:44:48.950 --> 00:44:51.630
it doesn't cause a
disastrous outcome

00:44:51.630 --> 00:44:56.350
for some pair that's given a
kidney, but didn't get one.

00:44:56.350 --> 00:45:00.210
I think that when
housing markets are

00:45:00.210 --> 00:45:02.170
either very hot or
very cold, you often

00:45:02.170 --> 00:45:04.120
see chains in real estate.

00:45:04.120 --> 00:45:09.460
So let's think of housing
markets that are very cold,

00:45:09.460 --> 00:45:13.040
so not something you guys in
Silicon Valley know about.

00:45:13.040 --> 00:45:14.880
But when it's hard
to sell a house,

00:45:14.880 --> 00:45:17.750
house contracts often
have contingent agreements

00:45:17.750 --> 00:45:21.220
which say I'm going to buy
your house unconditioned that I

00:45:21.220 --> 00:45:25.420
can sell my house in a timely
way for a certain amount.

00:45:25.420 --> 00:45:27.660
And then you wait and see
whether I sell my house.

00:45:27.660 --> 00:45:29.710
And I might, of
course, have an offer

00:45:29.710 --> 00:45:32.680
to buy my house from someone
who needs to sell his house.

00:45:32.680 --> 00:45:35.970
So the chains form
when someone-- so that

00:45:35.970 --> 00:45:38.510
was the kind of market when we
sold our house in Boston when

00:45:38.510 --> 00:45:39.984
we moved out here in 2012.

00:45:39.984 --> 00:45:41.900
And the chain is broken
when someone moves out

00:45:41.900 --> 00:45:44.395
from California and
has cash in their hand

00:45:44.395 --> 00:45:45.770
and doesn't need
to sell a house.

00:45:45.770 --> 00:45:47.145
They've already
sold their house.

00:45:47.145 --> 00:45:49.520
And indeed, we moved
here from Boston

00:45:49.520 --> 00:45:51.630
and didn't need to sell a house.

00:45:51.630 --> 00:45:54.169
Now, in a very hot
market, it could sometimes

00:45:54.169 --> 00:45:54.960
work the other way.

00:45:54.960 --> 00:45:58.184
You say before I sell my house,
I want to find a house to buy,

00:45:58.184 --> 00:45:59.850
so I'm sure that I
have a place to live.

00:45:59.850 --> 00:46:01.730
Because houses are
going so quickly.

00:46:01.730 --> 00:46:04.090
And so someone who's selling
their house here and moving

00:46:04.090 --> 00:46:05.290
to Boston doesn't need that.

00:46:05.290 --> 00:46:08.419
And they're the end of a chain
or the beginning of a chain.

00:46:08.419 --> 00:46:09.710
HAL VARIAN: That's interesting.

00:46:09.710 --> 00:46:11.400
And this point about
having an altruist

00:46:11.400 --> 00:46:13.180
really helps in design.

00:46:13.180 --> 00:46:16.230
Another case where this
happens is in matching grants.

00:46:16.230 --> 00:46:18.960
So I'm trying to raise
money for some cause.

00:46:18.960 --> 00:46:21.020
And I say, well, for
every dollar you give,

00:46:21.020 --> 00:46:21.820
I'll give a dollar.

00:46:21.820 --> 00:46:23.275
So I'll do this matching grant.

00:46:23.275 --> 00:46:26.730
And I wrote a couple papers
on this some time ago.

00:46:26.730 --> 00:46:28.740
But I dug into the
history a little bit.

00:46:28.740 --> 00:46:32.630
And guess who came
up with the market

00:46:32.630 --> 00:46:34.880
design of matching grants?

00:46:34.880 --> 00:46:36.089
ALVIN ROTH: Peggy Guggenheim.

00:46:36.089 --> 00:46:38.004
HAL VARIAN: You're off
by a few hundred years.

00:46:38.004 --> 00:46:39.230
It was Benjamin Franklin.

00:46:39.230 --> 00:46:41.590
Benjamin Franklin was the
first market engineer.

00:46:41.590 --> 00:46:43.620
Because he came up--
he's very proud of this.

00:46:43.620 --> 00:46:45.005
It's in his autobiography.

00:46:45.005 --> 00:46:46.380
You can read the
chapter where he

00:46:46.380 --> 00:46:49.370
describes how he came
up with this idea

00:46:49.370 --> 00:46:50.410
and how well it worked.

00:46:50.410 --> 00:46:52.060
So a lot of his
projects were actually

00:46:52.060 --> 00:46:56.680
financed by this
kind of matching.

00:46:56.680 --> 00:46:58.070
Question?

00:46:58.070 --> 00:47:00.670
AUDIENCE: So clearly
employer-employee matching

00:47:00.670 --> 00:47:04.290
has been very successful
in the medical industry.

00:47:04.290 --> 00:47:07.600
And I can imagine reasons why
that is, like all residents

00:47:07.600 --> 00:47:09.760
graduating at the
same time of the year.

00:47:09.760 --> 00:47:13.280
Are there other markets that
you think it could also work in

00:47:13.280 --> 00:47:19.790
and what's blocking more
fields of employment

00:47:19.790 --> 00:47:21.370
from using similar systems?

00:47:21.370 --> 00:47:22.909
ALVIN ROTH: That's
a good question.

00:47:22.909 --> 00:47:24.450
So there are certainly
other markets.

00:47:24.450 --> 00:47:26.366
But they tend to have
the same characteristics

00:47:26.366 --> 00:47:28.912
that you mentioned of
the medical market, which

00:47:28.912 --> 00:47:30.370
is first of all,
lots of people are

00:47:30.370 --> 00:47:31.750
graduating at the same time.

00:47:31.750 --> 00:47:34.880
Second, they are all going
into the same kind of job.

00:47:34.880 --> 00:47:37.310
So lots of MBA students
graduate at the same time.

00:47:37.310 --> 00:47:39.570
But the set of employers
who employ MBA students

00:47:39.570 --> 00:47:41.770
is much bigger than the
set of employers who

00:47:41.770 --> 00:47:44.755
employ new medical graduates.

00:47:44.755 --> 00:47:49.044
The employers are all
residency programs basically.

00:47:49.044 --> 00:47:52.680
So there are lots of
two-sided matching markets

00:47:52.680 --> 00:47:56.470
that are having problems and
that might well work well

00:47:56.470 --> 00:47:57.860
with centralized clearinghouse.

00:47:57.860 --> 00:48:00.520
But markets the are
simply having problems

00:48:00.520 --> 00:48:02.715
don't necessarily lend
themselves to redesign.

00:48:02.715 --> 00:48:04.090
Sometimes they're
having problems

00:48:04.090 --> 00:48:07.440
because of conflicting
interests in the parties.

00:48:07.440 --> 00:48:08.570
So there's some congestion.

00:48:08.570 --> 00:48:11.320
And in, for instance, college
admissions in the United

00:48:11.320 --> 00:48:16.630
States, it's now pretty easy
to file a lot of applications

00:48:16.630 --> 00:48:17.250
to college.

00:48:17.250 --> 00:48:18.675
And of course,
college admissions

00:48:18.675 --> 00:48:19.550
are matching markets.

00:48:19.550 --> 00:48:21.320
They're not commodity markets.

00:48:21.320 --> 00:48:23.270
Stanford doesn't choose
its freshman class

00:48:23.270 --> 00:48:27.090
by raising the tuition
until supply equals demand.

00:48:27.090 --> 00:48:30.460
There are all these other
market institutions.

00:48:30.460 --> 00:48:32.200
And Stanford
probably doesn't have

00:48:32.200 --> 00:48:34.560
to worry too much if you
apply to Stanford about how

00:48:34.560 --> 00:48:35.270
much you're interested.

00:48:35.270 --> 00:48:36.330
Because there are
a lot of people.

00:48:36.330 --> 00:48:37.820
Everyone who applies
to Stanford is at least

00:48:37.820 --> 00:48:39.420
potentially interested in going.

00:48:39.420 --> 00:48:42.930
But there are lots of American
Colleges and Universities

00:48:42.930 --> 00:48:45.990
that have to think hard not just
about how much they like you,

00:48:45.990 --> 00:48:48.990
but about how much
you like of them.

00:48:48.990 --> 00:48:51.529
Will they be able to be
successful in recruiting you?

00:48:51.529 --> 00:48:53.070
And there was a
time, of course, when

00:48:53.070 --> 00:48:56.360
it was harder to apply to many
colleges before the common app,

00:48:56.360 --> 00:48:59.060
say, where the mere fact
that you would apply to them

00:48:59.060 --> 00:49:00.870
was a pretty strong
indication of interest.

00:49:00.870 --> 00:49:02.930
And that has gone
away a little bit.

00:49:02.930 --> 00:49:08.410
So I think there's some
room to explore ways

00:49:08.410 --> 00:49:09.820
to help break that congestion.

00:49:09.820 --> 00:49:11.590
And one of the markets
we've done that in

00:49:11.590 --> 00:49:13.750
is the market for
new PhD economists.

00:49:13.750 --> 00:49:15.450
And the American
Economic Association

00:49:15.450 --> 00:49:17.590
has developed a
signaling mechanism

00:49:17.590 --> 00:49:19.990
where new PhD
economists can apply

00:49:19.990 --> 00:49:21.680
to all the available jobs.

00:49:21.680 --> 00:49:23.350
And the Department
of Economics that

00:49:23.350 --> 00:49:24.870
wants to hire an
assistant professor

00:49:24.870 --> 00:49:28.080
can get 600 applications.

00:49:28.080 --> 00:49:30.360
And we go to these
meetings in January

00:49:30.360 --> 00:49:32.010
where we interview people.

00:49:32.010 --> 00:49:34.870
But even a hardworking
junior recruiting team

00:49:34.870 --> 00:49:37.180
could only interview
20 or 25 people.

00:49:37.180 --> 00:49:39.580
So what the American
Economic Association now

00:49:39.580 --> 00:49:44.210
allows you to do is to send
two signals of interest,

00:49:44.210 --> 00:49:46.770
with the idea being that you
can lots of applications,

00:49:46.770 --> 00:49:48.870
but could only send two signals.

00:49:48.870 --> 00:49:50.720
An employer who gets
one of your signals

00:49:50.720 --> 00:49:52.595
should take a look again
and think maybe they

00:49:52.595 --> 00:49:53.620
should interview you.

00:49:53.620 --> 00:49:57.060
And I have some colleagues
at Stanford, Muriel Niederle

00:49:57.060 --> 00:50:00.830
and Soo Lee, the who did a
study of an online dating market

00:50:00.830 --> 00:50:01.710
of this sort.

00:50:01.710 --> 00:50:05.410
And dating markets
are also congested.

00:50:05.410 --> 00:50:07.590
People with attractive
pictures and profiles

00:50:07.590 --> 00:50:09.486
might get more emails
than they can answer.

00:50:09.486 --> 00:50:11.610
And people who aren't
getting their emails answered

00:50:11.610 --> 00:50:15.130
might send more and more
emails to more and more people

00:50:15.130 --> 00:50:17.130
so that there's less
and less information.

00:50:17.130 --> 00:50:21.800
And so what they did is they had
a dating site where they gave

00:50:21.800 --> 00:50:24.342
people two virtual roses a day.

00:50:24.342 --> 00:50:26.300
So you could send as many
emails as you wanted,

00:50:26.300 --> 00:50:28.800
but only two of them
could have roses attached.

00:50:28.800 --> 00:50:31.660
And what they observed was
that messages with roses

00:50:31.660 --> 00:50:34.860
were more successful in
leading to subsequent contacts

00:50:34.860 --> 00:50:35.620
than not.

00:50:35.620 --> 00:50:37.780
So I think a lot of
markets can't really

00:50:37.780 --> 00:50:40.250
use the solution that
the doctors have used,

00:50:40.250 --> 00:50:42.740
but still have to deal
with problems of congestion

00:50:42.740 --> 00:50:47.922
and thickness in ways that
the clearinghouse solves

00:50:47.922 --> 00:50:48.880
for the medical market.

00:50:51.839 --> 00:50:52.380
AUDIENCE: OK.

00:50:52.380 --> 00:50:54.240
So I gave you a softball
question at the beginning.

00:50:54.240 --> 00:50:56.000
I'll give you a
hardball question now.

00:50:56.000 --> 00:50:57.400
ALVIN ROTH: Hal will answer it.

00:50:57.400 --> 00:50:58.220
AUDIENCE: OK, good.

00:50:58.220 --> 00:50:59.090
Either one of you.

00:50:59.090 --> 00:51:01.720
As you were describing the
Gale and Shapley setup,

00:51:01.720 --> 00:51:03.700
I was thinking in
my mind about how

00:51:03.700 --> 00:51:06.712
you can change the assumptions
and how faulty the assumptions

00:51:06.712 --> 00:51:08.420
were in some ways,
like there's a barrier

00:51:08.420 --> 00:51:11.030
synchronization for
marriage or the fact

00:51:11.030 --> 00:51:15.090
that people know
their own utility

00:51:15.090 --> 00:51:17.800
function for what a
good match is just

00:51:17.800 --> 00:51:19.000
seemed like faulty models.

00:51:19.000 --> 00:51:22.220
So I could ask which
of these you think

00:51:22.220 --> 00:51:23.440
is a better thing to follow.

00:51:23.440 --> 00:51:25.070
But I'll ask a
harder question even,

00:51:25.070 --> 00:51:28.730
which is mathematicians
would identify

00:51:28.730 --> 00:51:30.940
a few problems like
the Riemann hypothesis

00:51:30.940 --> 00:51:34.330
or the twin prime conjecture
as the big unsolved problems.

00:51:34.330 --> 00:51:36.434
Computer scientist
would say p equals np.

00:51:36.434 --> 00:51:38.600
What would a person in your
field, in market design,

00:51:38.600 --> 00:51:40.560
say are the biggest
unsolved problems that

00:51:40.560 --> 00:51:42.592
could be framed mathematically?

00:51:42.592 --> 00:51:44.050
ALVIN ROTH: That's
a good question.

00:51:44.050 --> 00:51:45.750
I don't have a
ready answer for it.

00:51:45.750 --> 00:51:47.870
And one reason I don't
have a ready answer

00:51:47.870 --> 00:51:51.930
is I think of market design more
as an engineering kind of thing

00:51:51.930 --> 00:51:54.240
than as a mathematical
kind of thing.

00:51:54.240 --> 00:51:56.740
So when you think about what
are the big unsolved problems--

00:51:56.740 --> 00:51:58.450
and let me go back
to the beginning part

00:51:58.450 --> 00:52:01.660
of your question, maybe
the softer ball part.

00:52:01.660 --> 00:52:04.050
You say each of our
models has assumptions

00:52:04.050 --> 00:52:06.260
that may not be exactly right.

00:52:06.260 --> 00:52:08.370
And that's certainly true.

00:52:08.370 --> 00:52:09.880
Markets are complex.

00:52:09.880 --> 00:52:11.690
People have large
strategy spaces.

00:52:11.690 --> 00:52:14.810
When we make models, we try
to take a piece of the market

00:52:14.810 --> 00:52:17.760
that we think is the most
important piece and model

00:52:17.760 --> 00:52:20.460
what's going on there
and build something

00:52:20.460 --> 00:52:21.690
informed by that model.

00:52:21.690 --> 00:52:23.240
But you have to
constantly be aware

00:52:23.240 --> 00:52:24.920
that all the things
you left out may

00:52:24.920 --> 00:52:27.920
be impinging on the
boundaries of your model.

00:52:27.920 --> 00:52:32.440
So when you prove a
theorem, it's true forever.

00:52:32.440 --> 00:52:34.700
You know, Pythagoras's
theorem tells us

00:52:34.700 --> 00:52:37.680
about right triangles,
ancient and modern and here

00:52:37.680 --> 00:52:39.310
and in China.

00:52:39.310 --> 00:52:40.695
It really nails right triangles.

00:52:40.695 --> 00:52:42.320
But when you look at
bridges, you know,

00:52:42.320 --> 00:52:44.590
the Romans built some
great bridges, so great

00:52:44.590 --> 00:52:46.000
that they're still standing.

00:52:46.000 --> 00:52:48.490
But when we build bridges today,
we build them differently.

00:52:48.490 --> 00:52:51.540
And I don't know that we solved
any particular outstanding

00:52:51.540 --> 00:52:52.430
problem on bridges.

00:52:52.430 --> 00:52:54.720
But over time, we got
better at building bridges,

00:52:54.720 --> 00:52:58.300
because of all sorts of things,
better materials, better

00:52:58.300 --> 00:52:59.380
designs.

00:52:59.380 --> 00:53:01.880
And the underlying physics
is the same as it always was.

00:53:01.880 --> 00:53:04.270
But our bridges don't look
like the Roman bridges.

00:53:04.270 --> 00:53:06.080
So I think the
things we're building

00:53:06.080 --> 00:53:10.350
and the flaws in our models are
things that some of those flaws

00:53:10.350 --> 00:53:12.430
are important and
some are not now.

00:53:12.430 --> 00:53:13.570
That will change over time.

00:53:13.570 --> 00:53:16.000
Because markets are
little bit like bridges.

00:53:16.000 --> 00:53:18.057
When you build a bridge,
people start to use it.

00:53:18.057 --> 00:53:19.640
And that changes the
traffic patterns.

00:53:19.640 --> 00:53:23.492
And then you might need better
roads and bigger bridges.

00:53:23.492 --> 00:53:25.075
And that's the way
it is with markets.

00:53:28.410 --> 00:53:30.020
Marketplaces have
a lot of problems.

00:53:30.020 --> 00:53:31.430
They have to make market thick.

00:53:31.430 --> 00:53:33.250
They have to deal
with congestion.

00:53:33.250 --> 00:53:36.160
They have to make things safe,
and simple, and untrustworthy.

00:53:36.160 --> 00:53:38.280
And how to do
those in each case,

00:53:38.280 --> 00:53:41.269
these are all often
outstanding problems.

00:53:41.269 --> 00:53:42.810
But they may have
different solutions

00:53:42.810 --> 00:53:44.660
in different environments.

00:53:44.660 --> 00:53:47.750
So I don't think there is going
to be a Riemann hypothesis

00:53:47.750 --> 00:53:50.360
or something so
central that forever

00:53:50.360 --> 00:53:52.500
after people will be
able to point to it.

00:53:52.500 --> 00:53:55.750
Because as Hal already
mentioned and as we discussed,

00:53:55.750 --> 00:53:57.710
some of the cool
things about, say,

00:53:57.710 --> 00:54:00.540
Gale and Shapley's deferred
acceptance algorithm

00:54:00.540 --> 00:54:03.710
no longer apply to the
more complicated models

00:54:03.710 --> 00:54:06.210
that we're dealing with even
in things like medical matching

00:54:06.210 --> 00:54:10.870
when we start to have married
couples, things like that.

00:54:10.870 --> 00:54:14.230
So again, I could put
the question back to you.

00:54:14.230 --> 00:54:16.520
Maybe I'd understand
better if you told me

00:54:16.520 --> 00:54:18.260
what engineering
problems you think

00:54:18.260 --> 00:54:20.384
of having the status of
the Riemann hypothesis.

00:54:20.384 --> 00:54:22.800
I think of engineering problems
as being more incremental.

00:54:22.800 --> 00:54:24.750
Over time, we get
to do things better.

00:54:24.750 --> 00:54:26.360
And that's good.

00:54:26.360 --> 00:54:28.470
HAL VARIAN: I think
that's a great wrap up.

00:54:28.470 --> 00:54:29.670
Our time is up.

00:54:29.670 --> 00:54:31.160
Thanks so much for coming, Al.

00:54:31.160 --> 00:54:32.650
ALVIN ROTH: Well, thank you.

00:54:32.650 --> 00:54:37.200
[APPLAUSE]

