WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:01.880 align:start position:0%
 
one<00:00:00.390><c> of</c><00:00:00.539><c> the</c><00:00:00.630><c> things</c><00:00:00.840><c> that</c><00:00:01.050><c> might</c><00:00:01.260><c> help</c><00:00:01.560><c> speed</c>

00:00:01.880 --> 00:00:01.890 align:start position:0%
one of the things that might help speed
 

00:00:01.890 --> 00:00:04.039 align:start position:0%
one of the things that might help speed
up<00:00:01.920><c> your</c><00:00:02.070><c> learning</c><00:00:02.340><c> algorithm</c><00:00:02.970><c> is</c><00:00:03.210><c> to</c><00:00:03.720><c> slowly</c>

00:00:04.039 --> 00:00:04.049 align:start position:0%
up your learning algorithm is to slowly
 

00:00:04.049 --> 00:00:06.230 align:start position:0%
up your learning algorithm is to slowly
reduce<00:00:04.620><c> your</c><00:00:04.830><c> learning</c><00:00:05.190><c> rate</c><00:00:05.310><c> over</c><00:00:05.670><c> time</c><00:00:05.700><c> we</c>

00:00:06.230 --> 00:00:06.240 align:start position:0%
reduce your learning rate over time we
 

00:00:06.240 --> 00:00:08.720 align:start position:0%
reduce your learning rate over time we
call<00:00:06.450><c> this</c><00:00:06.600><c> learning</c><00:00:07.259><c> rate</c><00:00:07.440><c> decay</c><00:00:07.890><c> let's</c><00:00:08.550><c> see</c>

00:00:08.720 --> 00:00:08.730 align:start position:0%
call this learning rate decay let's see
 

00:00:08.730 --> 00:00:11.089 align:start position:0%
call this learning rate decay let's see
how<00:00:08.940><c> you</c><00:00:09.000><c> can</c><00:00:09.210><c> implement</c><00:00:09.510><c> this</c><00:00:09.900><c> let's</c><00:00:10.710><c> start</c><00:00:10.830><c> -</c>

00:00:11.089 --> 00:00:11.099 align:start position:0%
how you can implement this let's start -
 

00:00:11.099 --> 00:00:12.860 align:start position:0%
how you can implement this let's start -
an<00:00:11.219><c> example</c><00:00:11.490><c> of</c><00:00:12.000><c> why</c><00:00:12.210><c> you</c><00:00:12.240><c> might</c><00:00:12.570><c> want</c><00:00:12.809><c> to</c>

00:00:12.860 --> 00:00:12.870 align:start position:0%
an example of why you might want to
 

00:00:12.870 --> 00:00:14.720 align:start position:0%
an example of why you might want to
implement<00:00:13.259><c> learning</c><00:00:13.920><c> rate</c><00:00:14.099><c> decay</c>

00:00:14.720 --> 00:00:14.730 align:start position:0%
implement learning rate decay
 

00:00:14.730 --> 00:00:17.210 align:start position:0%
implement learning rate decay
suppose<00:00:15.360><c> you're</c><00:00:15.570><c> implementing</c><00:00:16.020><c> mini</c><00:00:16.949><c> batch</c>

00:00:17.210 --> 00:00:17.220 align:start position:0%
suppose you're implementing mini batch
 

00:00:17.220 --> 00:00:19.130 align:start position:0%
suppose you're implementing mini batch
gradient<00:00:17.550><c> descent</c><00:00:17.789><c> with</c><00:00:18.330><c> a</c><00:00:18.359><c> reasonably</c><00:00:18.869><c> small</c>

00:00:19.130 --> 00:00:19.140 align:start position:0%
gradient descent with a reasonably small
 

00:00:19.140 --> 00:00:21.310 align:start position:0%
gradient descent with a reasonably small
mini<00:00:19.560><c> batch</c><00:00:19.830><c> maybe</c><00:00:20.160><c> a</c><00:00:20.250><c> mini</c><00:00:20.460><c> batch</c><00:00:20.670><c> has</c><00:00:20.939><c> just</c>

00:00:21.310 --> 00:00:21.320 align:start position:0%
mini batch maybe a mini batch has just
 

00:00:21.320 --> 00:00:25.939 align:start position:0%
mini batch maybe a mini batch has just
64<00:00:22.320><c> 128</c><00:00:23.039><c> examples</c><00:00:23.580><c> then</c><00:00:24.269><c> as</c><00:00:24.570><c> you</c><00:00:24.750><c> iterate</c><00:00:24.949><c> your</c>

00:00:25.939 --> 00:00:25.949 align:start position:0%
64 128 examples then as you iterate your
 

00:00:25.949 --> 00:00:28.580 align:start position:0%
64 128 examples then as you iterate your
steps<00:00:26.670><c> will</c><00:00:26.939><c> be</c><00:00:27.060><c> a</c><00:00:27.090><c> little</c><00:00:27.330><c> bit</c><00:00:27.449><c> noisy</c><00:00:27.630><c> and</c><00:00:28.199><c> it</c>

00:00:28.580 --> 00:00:28.590 align:start position:0%
steps will be a little bit noisy and it
 

00:00:28.590 --> 00:00:31.099 align:start position:0%
steps will be a little bit noisy and it
will<00:00:28.769><c> tend</c><00:00:29.070><c> toward</c><00:00:29.580><c> this</c><00:00:29.789><c> minimum</c><00:00:30.330><c> over</c><00:00:30.810><c> here</c>

00:00:31.099 --> 00:00:31.109 align:start position:0%
will tend toward this minimum over here
 

00:00:31.109 --> 00:00:34.130 align:start position:0%
will tend toward this minimum over here
but<00:00:31.800><c> it</c><00:00:32.340><c> won't</c><00:00:32.550><c> exactly</c><00:00:33.000><c> converge</c><00:00:33.630><c> but</c><00:00:33.930><c> your</c>

00:00:34.130 --> 00:00:34.140 align:start position:0%
but it won't exactly converge but your
 

00:00:34.140 --> 00:00:35.810 align:start position:0%
but it won't exactly converge but your
algorithm<00:00:34.500><c> might</c><00:00:34.649><c> just</c><00:00:34.860><c> end</c><00:00:34.980><c> up</c><00:00:35.160><c> wandering</c>

00:00:35.810 --> 00:00:35.820 align:start position:0%
algorithm might just end up wandering
 

00:00:35.820 --> 00:00:39.950 align:start position:0%
algorithm might just end up wandering
around<00:00:36.649><c> and</c><00:00:37.649><c> never</c><00:00:38.160><c> really</c><00:00:38.579><c> converge</c><00:00:39.030><c> because</c>

00:00:39.950 --> 00:00:39.960 align:start position:0%
around and never really converge because
 

00:00:39.960 --> 00:00:42.020 align:start position:0%
around and never really converge because
you're<00:00:40.320><c> using</c><00:00:40.559><c> some</c><00:00:40.950><c> fixed</c><00:00:41.340><c> value</c><00:00:41.700><c> for</c><00:00:41.760><c> alpha</c>

00:00:42.020 --> 00:00:42.030 align:start position:0%
you're using some fixed value for alpha
 

00:00:42.030 --> 00:00:44.869 align:start position:0%
you're using some fixed value for alpha
and<00:00:42.829><c> there's</c><00:00:43.829><c> just</c><00:00:44.070><c> some</c><00:00:44.250><c> noise</c><00:00:44.489><c> in</c><00:00:44.760><c> your</c>

00:00:44.869 --> 00:00:44.879 align:start position:0%
and there's just some noise in your
 

00:00:44.879 --> 00:00:47.450 align:start position:0%
and there's just some noise in your
different<00:00:45.180><c> mini</c><00:00:45.329><c> batches</c><00:00:45.680><c> but</c><00:00:46.680><c> if</c><00:00:46.980><c> you</c><00:00:47.250><c> were</c>

00:00:47.450 --> 00:00:47.460 align:start position:0%
different mini batches but if you were
 

00:00:47.460 --> 00:00:51.709 align:start position:0%
different mini batches but if you were
to<00:00:48.379><c> slowly</c><00:00:49.379><c> reduce</c><00:00:50.340><c> your</c><00:00:51.210><c> learning</c><00:00:51.570><c> rate</c>

00:00:51.709 --> 00:00:51.719 align:start position:0%
to slowly reduce your learning rate
 

00:00:51.719 --> 00:00:53.930 align:start position:0%
to slowly reduce your learning rate
alpha<00:00:51.870><c> then</c><00:00:52.710><c> during</c><00:00:53.129><c> the</c><00:00:53.280><c> initial</c><00:00:53.670><c> phases</c>

00:00:53.930 --> 00:00:53.940 align:start position:0%
alpha then during the initial phases
 

00:00:53.940 --> 00:00:55.939 align:start position:0%
alpha then during the initial phases
while<00:00:54.600><c> your</c><00:00:54.840><c> learning</c><00:00:55.140><c> rate</c><00:00:55.320><c> alpha</c><00:00:55.469><c> still</c>

00:00:55.939 --> 00:00:55.949 align:start position:0%
while your learning rate alpha still
 

00:00:55.949 --> 00:00:58.160 align:start position:0%
while your learning rate alpha still
lasts<00:00:56.190><c> you</c><00:00:56.430><c> can</c><00:00:56.579><c> still</c><00:00:56.789><c> have</c><00:00:56.940><c> it</c><00:00:56.969><c> to</c><00:00:57.270><c> be</c><00:00:57.420><c> fast</c>

00:00:58.160 --> 00:00:58.170 align:start position:0%
lasts you can still have it to be fast
 

00:00:58.170 --> 00:01:01.189 align:start position:0%
lasts you can still have it to be fast
learning<00:00:58.530><c> but</c><00:00:59.280><c> then</c><00:00:59.430><c> as</c><00:00:59.670><c> alpha</c><00:01:00.090><c> gets</c><00:01:00.780><c> smaller</c>

00:01:01.189 --> 00:01:01.199 align:start position:0%
learning but then as alpha gets smaller
 

00:01:01.199 --> 00:01:04.179 align:start position:0%
learning but then as alpha gets smaller
your<00:01:02.129><c> steps</c><00:01:02.460><c> you</c><00:01:02.640><c> take</c><00:01:02.879><c> would</c><00:01:03.120><c> be</c><00:01:03.149><c> slower</c><00:01:03.629><c> and</c>

00:01:04.179 --> 00:01:04.189 align:start position:0%
your steps you take would be slower and
 

00:01:04.189 --> 00:01:07.730 align:start position:0%
your steps you take would be slower and
smaller<00:01:05.189><c> and</c><00:01:05.549><c> so</c><00:01:06.180><c> you</c><00:01:06.240><c> end</c><00:01:06.510><c> up</c><00:01:06.720><c> oscillating</c><00:01:07.530><c> in</c>

00:01:07.730 --> 00:01:07.740 align:start position:0%
smaller and so you end up oscillating in
 

00:01:07.740 --> 00:01:10.910 align:start position:0%
smaller and so you end up oscillating in
a<00:01:08.189><c> tighter</c><00:01:08.490><c> region</c><00:01:09.150><c> around</c><00:01:09.659><c> this</c><00:01:10.229><c> minimum</c>

00:01:10.910 --> 00:01:10.920 align:start position:0%
a tighter region around this minimum
 

00:01:10.920 --> 00:01:14.090 align:start position:0%
a tighter region around this minimum
rather<00:01:11.220><c> than</c><00:01:11.490><c> one</c><00:01:11.729><c> ring</c><00:01:12.170><c> far</c><00:01:13.170><c> away</c><00:01:13.530><c> even</c><00:01:13.830><c> as</c>

00:01:14.090 --> 00:01:14.100 align:start position:0%
rather than one ring far away even as
 

00:01:14.100 --> 00:01:16.100 align:start position:0%
rather than one ring far away even as
training<00:01:14.520><c> goes</c><00:01:14.700><c> on</c><00:01:14.939><c> and</c><00:01:15.150><c> on</c><00:01:15.270><c> so</c><00:01:15.630><c> the</c><00:01:15.840><c> intuition</c>

00:01:16.100 --> 00:01:16.110 align:start position:0%
training goes on and on so the intuition
 

00:01:16.110 --> 00:01:19.490 align:start position:0%
training goes on and on so the intuition
behind<00:01:16.670><c> slowly</c><00:01:17.670><c> reducing</c><00:01:18.509><c> alpha</c><00:01:18.750><c> is</c><00:01:19.229><c> that</c>

00:01:19.490 --> 00:01:19.500 align:start position:0%
behind slowly reducing alpha is that
 

00:01:19.500 --> 00:01:21.320 align:start position:0%
behind slowly reducing alpha is that
maybe<00:01:20.040><c> during</c><00:01:20.340><c> the</c><00:01:20.430><c> initial</c><00:01:20.909><c> steps</c><00:01:21.210><c> of</c>

00:01:21.320 --> 00:01:21.330 align:start position:0%
maybe during the initial steps of
 

00:01:21.330 --> 00:01:23.570 align:start position:0%
maybe during the initial steps of
learning<00:01:21.540><c> you</c><00:01:22.200><c> can</c><00:01:22.380><c> afford</c><00:01:22.680><c> to</c><00:01:22.860><c> take</c><00:01:23.040><c> much</c>

00:01:23.570 --> 00:01:23.580 align:start position:0%
learning you can afford to take much
 

00:01:23.580 --> 00:01:26.170 align:start position:0%
learning you can afford to take much
bigger<00:01:23.850><c> steps</c><00:01:24.270><c> but</c><00:01:25.170><c> then</c><00:01:25.350><c> as</c><00:01:25.560><c> learning</c>

00:01:26.170 --> 00:01:26.180 align:start position:0%
bigger steps but then as learning
 

00:01:26.180 --> 00:01:29.510 align:start position:0%
bigger steps but then as learning
approaches<00:01:27.500><c> convergence</c><00:01:28.500><c> then</c><00:01:29.040><c> having</c><00:01:29.460><c> a</c>

00:01:29.510 --> 00:01:29.520 align:start position:0%
approaches convergence then having a
 

00:01:29.520 --> 00:01:31.340 align:start position:0%
approaches convergence then having a
slower<00:01:29.820><c> learning</c><00:01:30.240><c> rate</c><00:01:30.420><c> allows</c><00:01:30.750><c> you</c><00:01:30.960><c> to</c><00:01:31.140><c> take</c>

00:01:31.340 --> 00:01:31.350 align:start position:0%
slower learning rate allows you to take
 

00:01:31.350 --> 00:01:34.100 align:start position:0%
slower learning rate allows you to take
smaller<00:01:31.890><c> steps</c><00:01:32.100><c> so</c><00:01:33.090><c> here's</c><00:01:33.540><c> how</c><00:01:33.750><c> you</c><00:01:33.780><c> can</c>

00:01:34.100 --> 00:01:34.110 align:start position:0%
smaller steps so here's how you can
 

00:01:34.110 --> 00:01:36.890 align:start position:0%
smaller steps so here's how you can
implement<00:01:34.500><c> learning</c><00:01:35.189><c> rate</c><00:01:35.579><c> decay</c><00:01:36.000><c> recall</c>

00:01:36.890 --> 00:01:36.900 align:start position:0%
implement learning rate decay recall
 

00:01:36.900 --> 00:01:42.859 align:start position:0%
implement learning rate decay recall
that<00:01:37.229><c> one</c><00:01:37.560><c> epoch</c><00:01:38.130><c> is</c><00:01:38.689><c> one</c><00:01:39.689><c> class</c><00:01:41.720><c> through</c><00:01:42.720><c> the</c>

00:01:42.859 --> 00:01:42.869 align:start position:0%
that one epoch is one class through the
 

00:01:42.869 --> 00:01:46.789 align:start position:0%
that one epoch is one class through the
data<00:01:44.270><c> right</c><00:01:45.270><c> so</c><00:01:45.570><c> if</c><00:01:45.810><c> you</c><00:01:45.960><c> have</c><00:01:46.229><c> them</c><00:01:46.500><c> a</c>

00:01:46.789 --> 00:01:46.799 align:start position:0%
data right so if you have them a
 

00:01:46.799 --> 00:01:50.840 align:start position:0%
data right so if you have them a
training<00:01:47.610><c> set</c><00:01:47.939><c> as</c><00:01:48.750><c> follows</c><00:01:49.470><c> maybe</c><00:01:50.310><c> break</c><00:01:50.640><c> it</c>

00:01:50.840 --> 00:01:50.850 align:start position:0%
training set as follows maybe break it
 

00:01:50.850 --> 00:01:56.389 align:start position:0%
training set as follows maybe break it
up<00:01:50.970><c> into</c><00:01:51.240><c> different</c><00:01:52.049><c> mini</c><00:01:52.890><c> batches</c><00:01:54.560><c> then</c><00:01:55.560><c> once</c>

00:01:56.389 --> 00:01:56.399 align:start position:0%
up into different mini batches then once
 

00:01:56.399 --> 00:01:58.100 align:start position:0%
up into different mini batches then once
the<00:01:56.549><c> first</c><00:01:56.820><c> pass</c><00:01:57.119><c> through</c><00:01:57.390><c> the</c><00:01:57.540><c> training</c><00:01:57.899><c> set</c>

00:01:58.100 --> 00:01:58.110 align:start position:0%
the first pass through the training set
 

00:01:58.110 --> 00:02:01.130 align:start position:0%
the first pass through the training set
is<00:01:58.350><c> called</c><00:01:58.619><c> the</c><00:01:58.979><c> first</c><00:01:59.640><c> epoch</c><00:02:00.060><c> and</c><00:02:00.390><c> then</c><00:02:00.960><c> the</c>

00:02:01.130 --> 00:02:01.140 align:start position:0%
is called the first epoch and then the
 

00:02:01.140 --> 00:02:04.789 align:start position:0%
is called the first epoch and then the
second<00:02:01.649><c> pass</c><00:02:01.799><c> is</c><00:02:02.100><c> the</c><00:02:02.640><c> second</c><00:02:03.030><c> epoch</c><00:02:03.420><c> and</c><00:02:03.799><c> so</c>

00:02:04.789 --> 00:02:04.799 align:start position:0%
second pass is the second epoch and so
 

00:02:04.799 --> 00:02:07.310 align:start position:0%
second pass is the second epoch and so
on<00:02:04.979><c> so</c><00:02:05.640><c> one</c><00:02:05.939><c> thing</c><00:02:06.119><c> you</c><00:02:06.240><c> could</c><00:02:06.360><c> do</c><00:02:06.570><c> is</c><00:02:06.869><c> set</c><00:02:07.110><c> your</c>

00:02:07.310 --> 00:02:07.320 align:start position:0%
on so one thing you could do is set your
 

00:02:07.320 --> 00:02:10.609 align:start position:0%
on so one thing you could do is set your
learning<00:02:07.710><c> rate</c><00:02:07.860><c> alpha</c><00:02:08.300><c> to</c><00:02:09.300><c> be</c><00:02:09.450><c> equal</c><00:02:09.810><c> to</c><00:02:09.840><c> one</c>

00:02:10.609 --> 00:02:10.619 align:start position:0%
learning rate alpha to be equal to one
 

00:02:10.619 --> 00:02:13.230 align:start position:0%
learning rate alpha to be equal to one
over<00:02:11.030><c> one</c><00:02:12.030><c> plus</c><00:02:12.090><c> a</c><00:02:12.690><c> per</c><00:02:12.989><c> hour</c>

00:02:13.230 --> 00:02:13.240 align:start position:0%
over one plus a per hour
 

00:02:13.240 --> 00:02:18.390 align:start position:0%
over one plus a per hour
originally<00:02:13.810><c> called</c><00:02:14.050><c> the</c><00:02:14.260><c> decay</c><00:02:14.740><c> rate</c><00:02:17.400><c> times</c>

00:02:18.390 --> 00:02:18.400 align:start position:0%
originally called the decay rate times
 

00:02:18.400 --> 00:02:22.980 align:start position:0%
originally called the decay rate times
the<00:02:19.080><c> epoch</c><00:02:20.430><c> num</c><00:02:21.430><c> and</c><00:02:21.760><c> there's</c><00:02:22.660><c> going</c><00:02:22.840><c> to</c><00:02:22.900><c> be</c>

00:02:22.980 --> 00:02:22.990 align:start position:0%
the epoch num and there's going to be
 

00:02:22.990 --> 00:02:25.680 align:start position:0%
the epoch num and there's going to be
times<00:02:23.680><c> some</c><00:02:23.950><c> initial</c><00:02:24.460><c> learning</c><00:02:25.030><c> rate</c><00:02:25.420><c> alpha</c>

00:02:25.680 --> 00:02:25.690 align:start position:0%
times some initial learning rate alpha
 

00:02:25.690 --> 00:02:26.820 align:start position:0%
times some initial learning rate alpha
zero

00:02:26.820 --> 00:02:26.830 align:start position:0%
zero
 

00:02:26.830 --> 00:02:29.040 align:start position:0%
zero
note<00:02:27.430><c> that</c><00:02:27.460><c> the</c><00:02:27.730><c> decay</c><00:02:28.120><c> rate</c><00:02:28.150><c> here</c><00:02:28.600><c> it</c><00:02:28.720><c> becomes</c>

00:02:29.040 --> 00:02:29.050 align:start position:0%
note that the decay rate here it becomes
 

00:02:29.050 --> 00:02:31.080 align:start position:0%
note that the decay rate here it becomes
another<00:02:29.320><c> hyper</c><00:02:29.650><c> parameter</c><00:02:30.250><c> which</c><00:02:30.790><c> you</c><00:02:30.820><c> might</c>

00:02:31.080 --> 00:02:31.090 align:start position:0%
another hyper parameter which you might
 

00:02:31.090 --> 00:02:33.000 align:start position:0%
another hyper parameter which you might
need<00:02:31.240><c> to</c><00:02:31.420><c> tune</c><00:02:31.690><c> so</c><00:02:32.350><c> here's</c><00:02:32.740><c> a</c><00:02:32.770><c> concrete</c>

00:02:33.000 --> 00:02:33.010 align:start position:0%
need to tune so here's a concrete
 

00:02:33.010 --> 00:02:36.810 align:start position:0%
need to tune so here's a concrete
example<00:02:33.340><c> um</c><00:02:34.060><c> if</c><00:02:34.870><c> you</c><00:02:35.200><c> take</c><00:02:35.470><c> several</c><00:02:35.890><c> epochs</c><00:02:36.490><c> so</c>

00:02:36.810 --> 00:02:36.820 align:start position:0%
example um if you take several epochs so
 

00:02:36.820 --> 00:02:39.800 align:start position:0%
example um if you take several epochs so
several<00:02:37.180><c> passes</c><00:02:37.630><c> through</c><00:02:37.840><c> your</c><00:02:37.990><c> data</c><00:02:38.170><c> if</c>

00:02:39.800 --> 00:02:39.810 align:start position:0%
several passes through your data if
 

00:02:39.810 --> 00:02:42.420 align:start position:0%
several passes through your data if
alpha<00:02:40.810><c> zero</c><00:02:41.140><c> is</c><00:02:41.320><c> equal</c><00:02:41.590><c> to</c><00:02:41.650><c> zero</c><00:02:41.770><c> point</c><00:02:42.010><c> two</c>

00:02:42.420 --> 00:02:42.430 align:start position:0%
alpha zero is equal to zero point two
 

00:02:42.430 --> 00:02:47.040 align:start position:0%
alpha zero is equal to zero point two
and<00:02:42.640><c> the</c><00:02:43.510><c> decay</c><00:02:44.050><c> rate</c><00:02:44.080><c> is</c><00:02:44.680><c> equal</c><00:02:45.610><c> to</c><00:02:45.760><c> one</c><00:02:46.050><c> then</c>

00:02:47.040 --> 00:02:47.050 align:start position:0%
and the decay rate is equal to one then
 

00:02:47.050 --> 00:02:50.370 align:start position:0%
and the decay rate is equal to one then
doing<00:02:47.530><c> your</c><00:02:47.620><c> first</c><00:02:48.070><c> epoch</c><00:02:48.550><c> alpha</c><00:02:49.390><c> will</c><00:02:49.630><c> be</c><00:02:49.660><c> 1</c>

00:02:50.370 --> 00:02:50.380 align:start position:0%
doing your first epoch alpha will be 1
 

00:02:50.380 --> 00:02:55.380 align:start position:0%
doing your first epoch alpha will be 1
over<00:02:52.290><c> 1</c><00:02:53.290><c> plus</c><00:02:53.560><c> 1</c><00:02:53.830><c> times</c><00:02:54.190><c> alpha</c><00:02:54.550><c> 0</c><00:02:55.060><c> so</c><00:02:55.270><c> your</c>

00:02:55.380 --> 00:02:55.390 align:start position:0%
over 1 plus 1 times alpha 0 so your
 

00:02:55.390 --> 00:02:58.910 align:start position:0%
over 1 plus 1 times alpha 0 so your
learning<00:02:55.720><c> rate</c><00:02:56.910><c> will</c><00:02:57.910><c> be</c><00:02:58.060><c> zero</c><00:02:58.330><c> point</c><00:02:58.510><c> one</c>

00:02:58.910 --> 00:02:58.920 align:start position:0%
learning rate will be zero point one
 

00:02:58.920 --> 00:03:01.830 align:start position:0%
learning rate will be zero point one
that's<00:02:59.920><c> just</c><00:03:00.040><c> your</c><00:03:00.430><c> evaluating</c><00:03:01.120><c> this</c><00:03:01.300><c> formula</c>

00:03:01.830 --> 00:03:01.840 align:start position:0%
that's just your evaluating this formula
 

00:03:01.840 --> 00:03:03.780 align:start position:0%
that's just your evaluating this formula
when<00:03:02.410><c> the</c><00:03:02.530><c> decay</c><00:03:02.860><c> rate</c><00:03:02.890><c> is</c><00:03:03.190><c> equal</c><00:03:03.280><c> to</c><00:03:03.400><c> 1</c><00:03:03.610><c> and</c>

00:03:03.780 --> 00:03:03.790 align:start position:0%
when the decay rate is equal to 1 and
 

00:03:03.790 --> 00:03:06.270 align:start position:0%
when the decay rate is equal to 1 and
the<00:03:03.850><c> epochal</c><00:03:04.270><c> on</c><00:03:04.510><c> this</c><00:03:04.690><c> one</c><00:03:04.900><c> on</c><00:03:05.770><c> the</c><00:03:05.950><c> second</c>

00:03:06.270 --> 00:03:06.280 align:start position:0%
the epochal on this one on the second
 

00:03:06.280 --> 00:03:09.060 align:start position:0%
the epochal on this one on the second
you<00:03:06.430><c> pop</c><00:03:06.670><c> your</c><00:03:07.270><c> learning</c><00:03:08.200><c> rate</c><00:03:08.350><c> the</c><00:03:08.530><c> case</c><00:03:08.770><c> to</c>

00:03:09.060 --> 00:03:09.070 align:start position:0%
you pop your learning rate the case to
 

00:03:09.070 --> 00:03:14.790 align:start position:0%
you pop your learning rate the case to
0.67<00:03:09.910><c> on</c><00:03:10.570><c> the</c><00:03:10.870><c> third</c><00:03:11.640><c> 0.5</c><00:03:12.640><c> on</c><00:03:13.060><c> the</c><00:03:13.150><c> fourth</c><00:03:13.800><c> 0.4</c>

00:03:14.790 --> 00:03:14.800 align:start position:0%
0.67 on the third 0.5 on the fourth 0.4
 

00:03:14.800 --> 00:03:16.020 align:start position:0%
0.67 on the third 0.5 on the fourth 0.4
and<00:03:15.040><c> so</c><00:03:15.580><c> on</c>

00:03:16.020 --> 00:03:16.030 align:start position:0%
and so on
 

00:03:16.030 --> 00:03:17.670 align:start position:0%
and so on
fearful<00:03:16.360><c> evaluate</c><00:03:16.900><c> well</c><00:03:17.050><c> these</c><00:03:17.230><c> values</c>

00:03:17.670 --> 00:03:17.680 align:start position:0%
fearful evaluate well these values
 

00:03:17.680 --> 00:03:19.440 align:start position:0%
fearful evaluate well these values
yourself<00:03:18.010><c> and</c><00:03:18.190><c> get</c><00:03:18.310><c> a</c><00:03:18.340><c> sense</c><00:03:18.580><c> that</c><00:03:18.880><c> you</c><00:03:19.390><c> know</c>

00:03:19.440 --> 00:03:19.450 align:start position:0%
yourself and get a sense that you know
 

00:03:19.450 --> 00:03:22.320 align:start position:0%
yourself and get a sense that you know
as<00:03:19.660><c> a</c><00:03:19.690><c> function</c><00:03:20.200><c> of</c><00:03:20.380><c> your</c><00:03:20.500><c> epoch</c><00:03:21.190><c> number</c><00:03:21.700><c> your</c>

00:03:22.320 --> 00:03:22.330 align:start position:0%
as a function of your epoch number your
 

00:03:22.330 --> 00:03:24.330 align:start position:0%
as a function of your epoch number your
learning<00:03:22.690><c> rate</c><00:03:22.870><c> gradually</c><00:03:23.650><c> decreases</c>

00:03:24.330 --> 00:03:24.340 align:start position:0%
learning rate gradually decreases
 

00:03:24.340 --> 00:03:27.630 align:start position:0%
learning rate gradually decreases
whereas<00:03:25.120><c> this</c><00:03:25.410><c> according</c><00:03:26.410><c> to</c><00:03:26.530><c> this</c><00:03:26.680><c> formula</c>

00:03:27.630 --> 00:03:27.640 align:start position:0%
whereas this according to this formula
 

00:03:27.640 --> 00:03:31.740 align:start position:0%
whereas this according to this formula
up<00:03:28.540><c> on</c><00:03:28.990><c> top</c><00:03:29.230><c> so</c><00:03:29.950><c> if</c><00:03:30.190><c> you</c><00:03:30.370><c> wish</c><00:03:30.580><c> to</c><00:03:30.760><c> use</c><00:03:31.030><c> learning</c>

00:03:31.740 --> 00:03:31.750 align:start position:0%
up on top so if you wish to use learning
 

00:03:31.750 --> 00:03:34.680 align:start position:0%
up on top so if you wish to use learning
rate<00:03:31.960><c> decay</c><00:03:32.320><c> what</c><00:03:32.980><c> you</c><00:03:33.070><c> can</c><00:03:33.280><c> do</c><00:03:33.460><c> is</c><00:03:33.850><c> try</c><00:03:34.630><c> to</c>

00:03:34.680 --> 00:03:34.690 align:start position:0%
rate decay what you can do is try to
 

00:03:34.690 --> 00:03:36.840 align:start position:0%
rate decay what you can do is try to
provide<00:03:35.050><c> your</c><00:03:35.290><c> values</c><00:03:35.800><c> of</c><00:03:36.070><c> both</c><00:03:36.250><c> hyper</c>

00:03:36.840 --> 00:03:36.850 align:start position:0%
provide your values of both hyper
 

00:03:36.850 --> 00:03:39.930 align:start position:0%
provide your values of both hyper
parameter<00:03:37.480><c> alpha</c><00:03:37.690><c> 0</c><00:03:38.470><c> as</c><00:03:38.710><c> well</c><00:03:39.040><c> as</c><00:03:39.220><c> of</c><00:03:39.460><c> this</c>

00:03:39.930 --> 00:03:39.940 align:start position:0%
parameter alpha 0 as well as of this
 

00:03:39.940 --> 00:03:42.270 align:start position:0%
parameter alpha 0 as well as of this
decay<00:03:40.360><c> rate</c><00:03:40.600><c> hyper</c><00:03:40.870><c> parameter</c><00:03:41.440><c> and</c><00:03:41.650><c> then</c><00:03:42.100><c> try</c>

00:03:42.270 --> 00:03:42.280 align:start position:0%
decay rate hyper parameter and then try
 

00:03:42.280 --> 00:03:44.670 align:start position:0%
decay rate hyper parameter and then try
to<00:03:42.340><c> find</c><00:03:42.670><c> a</c><00:03:42.760><c> value</c><00:03:42.970><c> that</c><00:03:43.360><c> works</c><00:03:43.630><c> well</c><00:03:44.050><c> other</c>

00:03:44.670 --> 00:03:44.680 align:start position:0%
to find a value that works well other
 

00:03:44.680 --> 00:03:46.350 align:start position:0%
to find a value that works well other
than<00:03:44.980><c> this</c><00:03:45.130><c> formula</c><00:03:45.700><c> for</c><00:03:45.880><c> learning</c><00:03:46.210><c> rate</c>

00:03:46.350 --> 00:03:46.360 align:start position:0%
than this formula for learning rate
 

00:03:46.360 --> 00:03:47.910 align:start position:0%
than this formula for learning rate
decay<00:03:46.690><c> there</c><00:03:46.960><c> are</c><00:03:47.020><c> a</c><00:03:47.050><c> few</c><00:03:47.200><c> other</c><00:03:47.440><c> ways</c><00:03:47.650><c> that</c>

00:03:47.910 --> 00:03:47.920 align:start position:0%
decay there are a few other ways that
 

00:03:47.920 --> 00:03:50.790 align:start position:0%
decay there are a few other ways that
people<00:03:47.980><c> use</c><00:03:48.330><c> for</c><00:03:49.330><c> example</c><00:03:49.420><c> this</c><00:03:50.020><c> is</c><00:03:50.200><c> called</c>

00:03:50.790 --> 00:03:50.800 align:start position:0%
people use for example this is called
 

00:03:50.800 --> 00:03:53.370 align:start position:0%
people use for example this is called
exponential<00:03:51.430><c> decay</c><00:03:51.910><c> where</c><00:03:52.240><c> alpha</c><00:03:52.720><c> is</c><00:03:52.960><c> equal</c>

00:03:53.370 --> 00:03:53.380 align:start position:0%
exponential decay where alpha is equal
 

00:03:53.380 --> 00:03:59.430 align:start position:0%
exponential decay where alpha is equal
to<00:03:53.520><c> some</c><00:03:54.520><c> number</c><00:03:55.830><c> less</c><00:03:56.830><c> than</c><00:03:56.860><c> 1</c><00:03:57.310><c> such</c><00:03:58.300><c> as</c><00:03:58.480><c> 0.9</c><00:03:59.140><c> 5</c>

00:03:59.430 --> 00:03:59.440 align:start position:0%
to some number less than 1 such as 0.9 5
 

00:03:59.440 --> 00:04:04.920 align:start position:0%
to some number less than 1 such as 0.9 5
times<00:04:00.370><c> epoch</c><00:04:01.090><c> num</c><00:04:02.430><c> times</c><00:04:03.430><c> alpha</c><00:04:03.880><c> 0</c><00:04:04.210><c> so</c><00:04:04.660><c> this</c>

00:04:04.920 --> 00:04:04.930 align:start position:0%
times epoch num times alpha 0 so this
 

00:04:04.930 --> 00:04:09.120 align:start position:0%
times epoch num times alpha 0 so this
will<00:04:05.820><c> exponentially</c><00:04:07.440><c> quickly</c><00:04:08.440><c> decay</c><00:04:08.950><c> your</c>

00:04:09.120 --> 00:04:09.130 align:start position:0%
will exponentially quickly decay your
 

00:04:09.130 --> 00:04:11.460 align:start position:0%
will exponentially quickly decay your
learning<00:04:09.459><c> rate</c><00:04:09.640><c> other</c><00:04:10.480><c> formulas</c><00:04:11.050><c> that</c><00:04:11.080><c> people</c>

00:04:11.460 --> 00:04:11.470 align:start position:0%
learning rate other formulas that people
 

00:04:11.470 --> 00:04:14.520 align:start position:0%
learning rate other formulas that people
use<00:04:11.650><c> are</c><00:04:11.980><c> things</c><00:04:12.220><c> like</c><00:04:12.459><c> alpha</c><00:04:13.060><c> equals</c><00:04:13.750><c> some</c>

00:04:14.520 --> 00:04:14.530 align:start position:0%
use are things like alpha equals some
 

00:04:14.530 --> 00:04:17.080 align:start position:0%
use are things like alpha equals some
constant<00:04:14.760><c> over</c>

00:04:17.080 --> 00:04:17.090 align:start position:0%
constant over
 

00:04:17.090 --> 00:04:21.380 align:start position:0%
constant over
EPOC<00:04:18.090><c> numb</c><00:04:18.710><c> square</c><00:04:19.710><c> root</c><00:04:19.920><c> times</c><00:04:20.670><c> alpha</c><00:04:21.030><c> zero</c>

00:04:21.380 --> 00:04:21.390 align:start position:0%
EPOC numb square root times alpha zero
 

00:04:21.390 --> 00:04:25.430 align:start position:0%
EPOC numb square root times alpha zero
or<00:04:22.640><c> some</c><00:04:23.640><c> constants</c><00:04:24.300><c> cave</c><00:04:24.600><c> another</c><00:04:25.170><c> hyper</c>

00:04:25.430 --> 00:04:25.440 align:start position:0%
or some constants cave another hyper
 

00:04:25.440 --> 00:04:30.110 align:start position:0%
or some constants cave another hyper
counter<00:04:25.980><c> over</c><00:04:26.820><c> dr.mini</c><00:04:27.780><c> Bosch</c><00:04:28.110><c> number</c><00:04:29.120><c> P</c>

00:04:30.110 --> 00:04:30.120 align:start position:0%
counter over dr.mini Bosch number P
 

00:04:30.120 --> 00:04:32.660 align:start position:0%
counter over dr.mini Bosch number P
square<00:04:30.960><c> root</c><00:04:31.140><c> 2</c><00:04:31.260><c> times</c><00:04:31.620><c> alpha</c><00:04:31.890><c> zero</c><00:04:32.430><c> and</c>

00:04:32.660 --> 00:04:32.670 align:start position:0%
square root 2 times alpha zero and
 

00:04:32.670 --> 00:04:35.440 align:start position:0%
square root 2 times alpha zero and
sometimes<00:04:33.390><c> you</c><00:04:33.540><c> also</c><00:04:33.690><c> see</c><00:04:34.110><c> people</c><00:04:34.260><c> use</c><00:04:35.130><c> a</c>

00:04:35.440 --> 00:04:35.450 align:start position:0%
sometimes you also see people use a
 

00:04:35.450 --> 00:04:37.880 align:start position:0%
sometimes you also see people use a
learning<00:04:36.450><c> rate</c><00:04:36.600><c> that</c><00:04:36.900><c> decreases</c><00:04:37.530><c> and</c>

00:04:37.880 --> 00:04:37.890 align:start position:0%
learning rate that decreases and
 

00:04:37.890 --> 00:04:40.910 align:start position:0%
learning rate that decreases and
discrete<00:04:38.310><c> stats</c><00:04:38.610><c> where</c><00:04:38.910><c> for</c><00:04:39.590><c> some</c><00:04:40.590><c> number</c><00:04:40.860><c> of</c>

00:04:40.910 --> 00:04:40.920 align:start position:0%
discrete stats where for some number of
 

00:04:40.920 --> 00:04:43.040 align:start position:0%
discrete stats where for some number of
steps<00:04:41.040><c> you</c><00:04:41.310><c> have</c><00:04:41.430><c> some</c><00:04:41.760><c> learning</c><00:04:42.330><c> rate</c><00:04:42.720><c> and</c>

00:04:43.040 --> 00:04:43.050 align:start position:0%
steps you have some learning rate and
 

00:04:43.050 --> 00:04:45.140 align:start position:0%
steps you have some learning rate and
then<00:04:43.620><c> after</c><00:04:43.920><c> a</c><00:04:43.950><c> while</c><00:04:44.160><c> you</c><00:04:44.220><c> decrease</c><00:04:44.940><c> it</c><00:04:45.120><c> by</c>

00:04:45.140 --> 00:04:45.150 align:start position:0%
then after a while you decrease it by
 

00:04:45.150 --> 00:04:47.330 align:start position:0%
then after a while you decrease it by
one<00:04:45.480><c> half</c><00:04:45.720><c> after</c><00:04:46.140><c> a</c><00:04:46.170><c> while</c><00:04:46.320><c> by</c><00:04:46.590><c> one</c><00:04:46.800><c> half</c><00:04:47.040><c> after</c>

00:04:47.330 --> 00:04:47.340 align:start position:0%
one half after a while by one half after
 

00:04:47.340 --> 00:04:49.540 align:start position:0%
one half after a while by one half after
a<00:04:47.490><c> while</c><00:04:47.700><c> by</c><00:04:48.210><c> one</c><00:04:48.450><c> half</c><00:04:48.690><c> and</c><00:04:48.930><c> so</c><00:04:49.110><c> this</c><00:04:49.320><c> is</c><00:04:49.470><c> a</c>

00:04:49.540 --> 00:04:49.550 align:start position:0%
a while by one half and so this is a
 

00:04:49.550 --> 00:04:56.780 align:start position:0%
a while by one half and so this is a
discrete<00:04:51.230><c> staircase</c><00:04:55.130><c> so</c><00:04:56.130><c> so</c><00:04:56.340><c> far</c><00:04:56.550><c> we've</c>

00:04:56.780 --> 00:04:56.790 align:start position:0%
discrete staircase so so far we've
 

00:04:56.790 --> 00:04:59.390 align:start position:0%
discrete staircase so so far we've
talked<00:04:57.030><c> about</c><00:04:57.210><c> some</c><00:04:57.690><c> using</c><00:04:58.530><c> some</c><00:04:58.800><c> you</c><00:04:59.280><c> know</c>

00:04:59.390 --> 00:04:59.400 align:start position:0%
talked about some using some you know
 

00:04:59.400 --> 00:05:03.200 align:start position:0%
talked about some using some you know
formula<00:05:00.590><c> to</c><00:05:01.590><c> govern</c><00:05:01.980><c> how</c><00:05:02.220><c> alpha</c><00:05:02.700><c> the</c><00:05:02.910><c> learning</c>

00:05:03.200 --> 00:05:03.210 align:start position:0%
formula to govern how alpha the learning
 

00:05:03.210 --> 00:05:05.750 align:start position:0%
formula to govern how alpha the learning
rate<00:05:03.330><c> changes</c><00:05:03.780><c> over</c><00:05:04.050><c> time</c><00:05:04.230><c> one</c><00:05:05.220><c> other</c><00:05:05.460><c> thing</c>

00:05:05.750 --> 00:05:05.760 align:start position:0%
rate changes over time one other thing
 

00:05:05.760 --> 00:05:08.120 align:start position:0%
rate changes over time one other thing
that<00:05:05.790><c> people</c><00:05:06.120><c> sometimes</c><00:05:06.480><c> do</c><00:05:06.870><c> is</c><00:05:07.080><c> nanyo</c><00:05:07.650><c> decay</c>

00:05:08.120 --> 00:05:08.130 align:start position:0%
that people sometimes do is nanyo decay
 

00:05:08.130 --> 00:05:10.700 align:start position:0%
that people sometimes do is nanyo decay
and<00:05:08.430><c> so</c><00:05:09.150><c> if</c><00:05:09.480><c> you're</c><00:05:09.660><c> training</c><00:05:09.900><c> just</c><00:05:10.260><c> one</c><00:05:10.470><c> model</c>

00:05:10.700 --> 00:05:10.710 align:start position:0%
and so if you're training just one model
 

00:05:10.710 --> 00:05:13.340 align:start position:0%
and so if you're training just one model
at<00:05:10.980><c> a</c><00:05:11.070><c> time</c><00:05:11.310><c> and</c><00:05:11.550><c> the</c><00:05:11.970><c> dual</c><00:05:12.210><c> model</c><00:05:12.540><c> takes</c><00:05:13.080><c> many</c>

00:05:13.340 --> 00:05:13.350 align:start position:0%
at a time and the dual model takes many
 

00:05:13.350 --> 00:05:16.070 align:start position:0%
at a time and the dual model takes many
hours<00:05:13.770><c> or</c><00:05:13.920><c> even</c><00:05:13.980><c> many</c><00:05:14.400><c> days</c><00:05:14.730><c> to</c><00:05:15.090><c> Train</c><00:05:15.390><c> what</c>

00:05:16.070 --> 00:05:16.080 align:start position:0%
hours or even many days to Train what
 

00:05:16.080 --> 00:05:17.570 align:start position:0%
hours or even many days to Train what
some<00:05:16.290><c> people</c><00:05:16.410><c> will</c><00:05:16.680><c> do</c><00:05:16.830><c> is</c><00:05:17.040><c> just</c><00:05:17.280><c> wash</c><00:05:17.550><c> your</c>

00:05:17.570 --> 00:05:17.580 align:start position:0%
some people will do is just wash your
 

00:05:17.580 --> 00:05:20.330 align:start position:0%
some people will do is just wash your
model<00:05:18.180><c> as</c><00:05:18.330><c> this</c><00:05:18.540><c> training</c><00:05:18.900><c> over</c><00:05:19.380><c> your</c><00:05:19.950><c> a</c><00:05:20.040><c> large</c>

00:05:20.330 --> 00:05:20.340 align:start position:0%
model as this training over your a large
 

00:05:20.340 --> 00:05:22.850 align:start position:0%
model as this training over your a large
number<00:05:20.580><c> of</c><00:05:20.730><c> days</c><00:05:20.970><c> and</c><00:05:21.270><c> then</c><00:05:21.720><c> annually</c><00:05:22.200><c> say</c><00:05:22.620><c> oh</c>

00:05:22.850 --> 00:05:22.860 align:start position:0%
number of days and then annually say oh
 

00:05:22.860 --> 00:05:24.650 align:start position:0%
number of days and then annually say oh
it<00:05:23.340><c> looks</c><00:05:23.520><c> like</c><00:05:23.730><c> the</c><00:05:23.880><c> learning</c><00:05:24.000><c> rate</c><00:05:24.330><c> slowed</c>

00:05:24.650 --> 00:05:24.660 align:start position:0%
it looks like the learning rate slowed
 

00:05:24.660 --> 00:05:26.180 align:start position:0%
it looks like the learning rate slowed
down<00:05:24.900><c> I'm</c><00:05:25.140><c> going</c><00:05:25.320><c> to</c><00:05:25.380><c> decrease</c><00:05:25.710><c> out</c><00:05:25.980><c> for</c><00:05:26.160><c> a</c>

00:05:26.180 --> 00:05:26.190 align:start position:0%
down I'm going to decrease out for a
 

00:05:26.190 --> 00:05:28.100 align:start position:0%
down I'm going to decrease out for a
little<00:05:26.370><c> bit</c><00:05:26.550><c> of</c><00:05:27.150><c> course</c><00:05:27.420><c> this</c><00:05:27.600><c> works</c><00:05:27.840><c> this</c>

00:05:28.100 --> 00:05:28.110 align:start position:0%
little bit of course this works this
 

00:05:28.110 --> 00:05:30.530 align:start position:0%
little bit of course this works this
manually<00:05:28.770><c> controlling</c><00:05:29.250><c> alpha</c><00:05:29.760><c> really</c><00:05:30.120><c> tuning</c>

00:05:30.530 --> 00:05:30.540 align:start position:0%
manually controlling alpha really tuning
 

00:05:30.540 --> 00:05:32.900 align:start position:0%
manually controlling alpha really tuning
alpha<00:05:30.900><c> by</c><00:05:31.080><c> hand</c><00:05:31.380><c> all</c><00:05:31.590><c> by</c><00:05:32.130><c> hour</c><00:05:32.370><c> day</c><00:05:32.550><c> by</c><00:05:32.730><c> day</c>

00:05:32.900 --> 00:05:32.910 align:start position:0%
alpha by hand all by hour day by day
 

00:05:32.910 --> 00:05:35.210 align:start position:0%
alpha by hand all by hour day by day
this<00:05:33.720><c> works</c><00:05:34.020><c> only</c><00:05:34.290><c> if</c><00:05:34.530><c> you're</c><00:05:34.650><c> training</c><00:05:34.920><c> only</c>

00:05:35.210 --> 00:05:35.220 align:start position:0%
this works only if you're training only
 

00:05:35.220 --> 00:05:37.460 align:start position:0%
this works only if you're training only
a<00:05:35.250><c> small</c><00:05:35.580><c> number</c><00:05:35.610><c> of</c><00:05:35.970><c> models</c><00:05:36.360><c> but</c><00:05:37.050><c> sometimes</c>

00:05:37.460 --> 00:05:37.470 align:start position:0%
a small number of models but sometimes
 

00:05:37.470 --> 00:05:39.560 align:start position:0%
a small number of models but sometimes
people<00:05:37.830><c> do</c><00:05:37.980><c> that</c><00:05:38.130><c> as</c><00:05:38.340><c> well</c><00:05:38.550><c> so</c><00:05:39.090><c> now</c><00:05:39.270><c> you</c><00:05:39.330><c> have</c><00:05:39.540><c> a</c>

00:05:39.560 --> 00:05:39.570 align:start position:0%
people do that as well so now you have a
 

00:05:39.570 --> 00:05:41.540 align:start position:0%
people do that as well so now you have a
few<00:05:39.810><c> more</c><00:05:39.990><c> options</c><00:05:40.200><c> so</c><00:05:40.620><c> how</c><00:05:40.740><c> to</c><00:05:40.800><c> control</c><00:05:41.310><c> the</c>

00:05:41.540 --> 00:05:41.550 align:start position:0%
few more options so how to control the
 

00:05:41.550 --> 00:05:44.240 align:start position:0%
few more options so how to control the
learning<00:05:41.910><c> rate</c><00:05:42.090><c> alpha</c><00:05:42.560><c> now</c><00:05:43.560><c> in</c><00:05:43.890><c> case</c><00:05:44.100><c> you're</c>

00:05:44.240 --> 00:05:44.250 align:start position:0%
learning rate alpha now in case you're
 

00:05:44.250 --> 00:05:45.890 align:start position:0%
learning rate alpha now in case you're
thinking<00:05:44.640><c> wow</c><00:05:44.970><c> this</c><00:05:45.210><c> is</c><00:05:45.330><c> a</c><00:05:45.390><c> lot</c><00:05:45.600><c> of</c><00:05:45.630><c> hyper</c>

00:05:45.890 --> 00:05:45.900 align:start position:0%
thinking wow this is a lot of hyper
 

00:05:45.900 --> 00:05:47.630 align:start position:0%
thinking wow this is a lot of hyper
parameters<00:05:46.470><c> how</c><00:05:46.680><c> that</c><00:05:46.860><c> select</c><00:05:47.160><c> amongst</c><00:05:47.430><c> all</c>

00:05:47.630 --> 00:05:47.640 align:start position:0%
parameters how that select amongst all
 

00:05:47.640 --> 00:05:49.580 align:start position:0%
parameters how that select amongst all
these<00:05:47.940><c> different</c><00:05:48.360><c> options</c><00:05:48.780><c> I</c><00:05:48.960><c> would</c><00:05:49.320><c> say</c>

00:05:49.580 --> 00:05:49.590 align:start position:0%
these different options I would say
 

00:05:49.590 --> 00:05:51.410 align:start position:0%
these different options I would say
don't<00:05:49.860><c> worry</c><00:05:49.950><c> about</c><00:05:50.070><c> it</c><00:05:50.340><c> for</c><00:05:50.460><c> now</c><00:05:50.490><c> in</c><00:05:50.880><c> next</c>

00:05:51.410 --> 00:05:51.420 align:start position:0%
don't worry about it for now in next
 

00:05:51.420 --> 00:05:52.910 align:start position:0%
don't worry about it for now in next
week<00:05:51.690><c> we'll</c><00:05:51.930><c> talk</c><00:05:51.960><c> more</c><00:05:52.380><c> about</c><00:05:52.440><c> how</c><00:05:52.650><c> to</c>

00:05:52.910 --> 00:05:52.920 align:start position:0%
week we'll talk more about how to
 

00:05:52.920 --> 00:05:55.600 align:start position:0%
week we'll talk more about how to
systematically<00:05:53.670><c> choose</c><00:05:54.090><c> hyper</c><00:05:54.660><c> parameters</c>

00:05:55.600 --> 00:05:55.610 align:start position:0%
systematically choose hyper parameters
 

00:05:55.610 --> 00:05:59.120 align:start position:0%
systematically choose hyper parameters
for<00:05:56.610><c> me</c><00:05:56.790><c> I</c><00:05:57.060><c> would</c><00:05:57.630><c> say</c><00:05:57.870><c> that</c><00:05:57.900><c> learning</c><00:05:58.650><c> rate</c><00:05:58.800><c> is</c>

00:05:59.120 --> 00:05:59.130 align:start position:0%
for me I would say that learning rate is
 

00:05:59.130 --> 00:06:00.950 align:start position:0%
for me I would say that learning rate is
usually<00:05:59.580><c> lower</c><00:05:59.820><c> down</c><00:06:00.090><c> or</c><00:06:00.360><c> the</c><00:06:00.480><c> list</c><00:06:00.660><c> of</c><00:06:00.810><c> things</c>

00:06:00.950 --> 00:06:00.960 align:start position:0%
usually lower down or the list of things
 

00:06:00.960 --> 00:06:03.530 align:start position:0%
usually lower down or the list of things
I<00:06:01.200><c> try</c><00:06:01.500><c> setting</c><00:06:02.160><c> alpha</c><00:06:02.490><c> just</c><00:06:03.060><c> a</c><00:06:03.120><c> fixed</c><00:06:03.420><c> value</c>

00:06:03.530 --> 00:06:03.540 align:start position:0%
I try setting alpha just a fixed value
 

00:06:03.540 --> 00:06:05.480 align:start position:0%
I try setting alpha just a fixed value
of<00:06:03.750><c> alpha</c><00:06:03.930><c> and</c><00:06:04.170><c> getting</c><00:06:04.500><c> that</c><00:06:04.680><c> to</c><00:06:04.740><c> be</c><00:06:05.100><c> wealthy</c>

00:06:05.480 --> 00:06:05.490 align:start position:0%
of alpha and getting that to be wealthy
 

00:06:05.490 --> 00:06:07.370 align:start position:0%
of alpha and getting that to be wealthy
and<00:06:05.520><c> has</c><00:06:05.700><c> a</c><00:06:05.730><c> huge</c><00:06:06.060><c> in</c><00:06:06.210><c> time</c><00:06:06.420><c> learning</c><00:06:07.230><c> rate</c>

00:06:07.370 --> 00:06:07.380 align:start position:0%
and has a huge in time learning rate
 

00:06:07.380 --> 00:06:09.560 align:start position:0%
and has a huge in time learning rate
decay<00:06:07.680><c> does</c><00:06:07.980><c> help</c><00:06:08.360><c> sometimes</c><00:06:09.360><c> it</c><00:06:09.450><c> can</c><00:06:09.540><c> really</c>

00:06:09.560 --> 00:06:09.570 align:start position:0%
decay does help sometimes it can really
 

00:06:09.570 --> 00:06:11.180 align:start position:0%
decay does help sometimes it can really
help<00:06:09.930><c> speed</c><00:06:10.260><c> up</c><00:06:10.290><c> training</c><00:06:10.770><c> but</c><00:06:10.920><c> it</c><00:06:11.040><c> is</c><00:06:11.160><c> a</c>

00:06:11.180 --> 00:06:11.190 align:start position:0%
help speed up training but it is a
 

00:06:11.190 --> 00:06:13.910 align:start position:0%
help speed up training but it is a
little<00:06:11.400><c> bit</c><00:06:11.580><c> lower</c><00:06:11.760><c> down</c><00:06:12.000><c> my</c><00:06:12.600><c> list</c><00:06:12.870><c> when</c><00:06:13.230><c> in</c>

00:06:13.910 --> 00:06:13.920 align:start position:0%
little bit lower down my list when in
 

00:06:13.920 --> 00:06:16.070 align:start position:0%
little bit lower down my list when in
terms<00:06:14.130><c> of</c><00:06:14.250><c> the</c><00:06:14.370><c> things</c><00:06:14.580><c> I</c><00:06:14.730><c> would</c><00:06:14.790><c> try</c><00:06:15.120><c> but</c><00:06:15.720><c> next</c>

00:06:16.070 --> 00:06:16.080 align:start position:0%
terms of the things I would try but next
 

00:06:16.080 --> 00:06:17.480 align:start position:0%
terms of the things I would try but next
we<00:06:16.200><c> want</c><00:06:16.440><c> to</c><00:06:16.470><c> talk</c><00:06:16.650><c> about</c><00:06:16.770><c> hyper</c><00:06:17.040><c> parameter</c>

00:06:17.480 --> 00:06:17.490 align:start position:0%
we want to talk about hyper parameter
 

00:06:17.490 --> 00:06:19.790 align:start position:0%
we want to talk about hyper parameter
tuning<00:06:17.850><c> you</c><00:06:18.240><c> see</c><00:06:18.480><c> more</c><00:06:18.720><c> systematic</c><00:06:19.380><c> ways</c><00:06:19.530><c> to</c>

00:06:19.790 --> 00:06:19.800 align:start position:0%
tuning you see more systematic ways to
 

00:06:19.800 --> 00:06:21.620 align:start position:0%
tuning you see more systematic ways to
organize<00:06:20.280><c> all</c><00:06:20.520><c> of</c><00:06:20.700><c> these</c><00:06:20.820><c> hyper</c><00:06:21.060><c> parameters</c>

00:06:21.620 --> 00:06:21.630 align:start position:0%
organize all of these hyper parameters
 

00:06:21.630 --> 00:06:23.540 align:start position:0%
organize all of these hyper parameters
and<00:06:21.810><c> how</c><00:06:22.260><c> to</c><00:06:22.320><c> efficiently</c><00:06:22.830><c> search</c><00:06:23.100><c> amongst</c>

00:06:23.540 --> 00:06:23.550 align:start position:0%
and how to efficiently search amongst
 

00:06:23.550 --> 00:06:26.300 align:start position:0%
and how to efficiently search amongst
them<00:06:23.700><c> so</c><00:06:23.930><c> that's</c><00:06:24.930><c> it</c><00:06:25.200><c> for</c><00:06:25.530><c> learning</c><00:06:25.890><c> rate</c><00:06:26.280><c> is</c>

00:06:26.300 --> 00:06:26.310 align:start position:0%
them so that's it for learning rate is
 

00:06:26.310 --> 00:06:29.000 align:start position:0%
them so that's it for learning rate is
hey<00:06:26.670><c> um</c><00:06:26.940><c> finally</c><00:06:27.900><c> I</c><00:06:28.170><c> want</c><00:06:28.470><c> to</c><00:06:28.500><c> also</c><00:06:28.680><c> want</c><00:06:28.920><c> to</c>

00:06:29.000 --> 00:06:29.010 align:start position:0%
hey um finally I want to also want to
 

00:06:29.010 --> 00:06:30.640 align:start position:0%
hey um finally I want to also want to
talk<00:06:29.190><c> a</c><00:06:29.220><c> little</c><00:06:29.340><c> bit</c><00:06:29.580><c> about</c><00:06:29.730><c> local</c>

00:06:30.640 --> 00:06:30.650 align:start position:0%
talk a little bit about local
 

00:06:30.650 --> 00:06:32.439 align:start position:0%
talk a little bit about local
optimal<00:06:31.130><c> and</c><00:06:31.340><c> saddle</c><00:06:31.790><c> points</c><00:06:32.120><c> in</c><00:06:32.300><c> new</c>

00:06:32.439 --> 00:06:32.449 align:start position:0%
optimal and saddle points in new
 

00:06:32.449 --> 00:06:34.150 align:start position:0%
optimal and saddle points in new
networks<00:06:32.930><c> so</c><00:06:33.410><c> you</c><00:06:33.500><c> can</c><00:06:33.650><c> have</c><00:06:33.740><c> a</c><00:06:33.800><c> little</c><00:06:34.040><c> bit</c>

00:06:34.150 --> 00:06:34.160 align:start position:0%
networks so you can have a little bit
 

00:06:34.160 --> 00:06:36.010 align:start position:0%
networks so you can have a little bit
better<00:06:34.280><c> intuition</c><00:06:34.729><c> about</c><00:06:35.300><c> the</c><00:06:35.660><c> types</c><00:06:35.870><c> of</c>

00:06:36.010 --> 00:06:36.020 align:start position:0%
better intuition about the types of
 

00:06:36.020 --> 00:06:38.379 align:start position:0%
better intuition about the types of
optimization<00:06:36.680><c> problems</c><00:06:37.130><c> your</c><00:06:37.639><c> optimization</c>

00:06:38.379 --> 00:06:38.389 align:start position:0%
optimization problems your optimization
 

00:06:38.389 --> 00:06:40.150 align:start position:0%
optimization problems your optimization
algorithm<00:06:39.020><c> is</c><00:06:39.139><c> trying</c><00:06:39.440><c> to</c><00:06:39.560><c> solve</c><00:06:39.800><c> when</c><00:06:40.039><c> you're</c>

00:06:40.150 --> 00:06:40.160 align:start position:0%
algorithm is trying to solve when you're
 

00:06:40.160 --> 00:06:41.320 align:start position:0%
algorithm is trying to solve when you're
trying<00:06:40.340><c> to</c><00:06:40.400><c> train</c><00:06:40.550><c> these</c><00:06:40.699><c> in</c><00:06:40.820><c> your</c><00:06:40.940><c> network</c>

00:06:41.320 --> 00:06:41.330 align:start position:0%
trying to train these in your network
 

00:06:41.330 --> 00:06:45.520 align:start position:0%
trying to train these in your network
let's<00:06:41.900><c> go</c><00:06:42.080><c> onto</c><00:06:42.229><c> the</c><00:06:42.440><c> next</c><00:06:42.620><c> video</c><00:06:42.800><c> to</c><00:06:43.009><c> see</c><00:06:43.340><c> that</c>

