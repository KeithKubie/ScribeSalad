WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.210 align:start position:0%
 
why<00:00:00.750><c> does</c><00:00:00.960><c> your</c><00:00:01.110><c> neural</c><00:00:01.350><c> network</c><00:00:01.380><c> need</c><00:00:01.979><c> a</c>

00:00:02.210 --> 00:00:02.220 align:start position:0%
why does your neural network need a
 

00:00:02.220 --> 00:00:04.730 align:start position:0%
why does your neural network need a
nonlinear<00:00:02.850><c> activation</c><00:00:03.240><c> function</c><00:00:03.780><c> turns</c><00:00:04.560><c> out</c>

00:00:04.730 --> 00:00:04.740 align:start position:0%
nonlinear activation function turns out
 

00:00:04.740 --> 00:00:06.079 align:start position:0%
nonlinear activation function turns out
that<00:00:04.950><c> for</c><00:00:05.160><c> your</c><00:00:05.279><c> neural</c><00:00:05.490><c> network</c><00:00:05.759><c> to</c><00:00:05.910><c> compute</c>

00:00:06.079 --> 00:00:06.089 align:start position:0%
that for your neural network to compute
 

00:00:06.089 --> 00:00:08.150 align:start position:0%
that for your neural network to compute
interesting<00:00:06.810><c> functions</c><00:00:07.290><c> you</c><00:00:07.560><c> do</c><00:00:07.770><c> need</c><00:00:08.010><c> to</c>

00:00:08.150 --> 00:00:08.160 align:start position:0%
interesting functions you do need to
 

00:00:08.160 --> 00:00:09.980 align:start position:0%
interesting functions you do need to
take<00:00:08.340><c> a</c><00:00:08.400><c> nonlinear</c><00:00:09.090><c> activation</c><00:00:09.480><c> function</c>

00:00:09.980 --> 00:00:09.990 align:start position:0%
take a nonlinear activation function
 

00:00:09.990 --> 00:00:12.950 align:start position:0%
take a nonlinear activation function
less<00:00:10.650><c> you</c><00:00:10.830><c> want</c><00:00:11.070><c> so</c><00:00:11.309><c> just</c><00:00:11.790><c> the</c><00:00:12.000><c> for</c><00:00:12.690><c> prop</c>

00:00:12.950 --> 00:00:12.960 align:start position:0%
less you want so just the for prop
 

00:00:12.960 --> 00:00:15.980 align:start position:0%
less you want so just the for prop
equations<00:00:13.650><c> for</c><00:00:14.280><c> the</c><00:00:14.370><c> neural</c><00:00:14.639><c> network</c><00:00:14.990><c> why</c>

00:00:15.980 --> 00:00:15.990 align:start position:0%
equations for the neural network why
 

00:00:15.990 --> 00:00:18.019 align:start position:0%
equations for the neural network why
don't<00:00:16.170><c> we</c><00:00:16.289><c> just</c><00:00:16.500><c> get</c><00:00:16.800><c> rid</c><00:00:17.010><c> of</c><00:00:17.070><c> this</c><00:00:17.340><c> get</c><00:00:17.820><c> rid</c><00:00:17.850><c> of</c>

00:00:18.019 --> 00:00:18.029 align:start position:0%
don't we just get rid of this get rid of
 

00:00:18.029 --> 00:00:22.150 align:start position:0%
don't we just get rid of this get rid of
the<00:00:18.150><c> function</c><00:00:18.510><c> G</c><00:00:18.810><c> and</c><00:00:19.020><c> set</c><00:00:19.859><c> a1</c><00:00:20.220><c> equals</c><00:00:21.090><c> Z</c><00:00:21.600><c> 1</c><00:00:21.840><c> or</c>

00:00:22.150 --> 00:00:22.160 align:start position:0%
the function G and set a1 equals Z 1 or
 

00:00:22.160 --> 00:00:25.910 align:start position:0%
the function G and set a1 equals Z 1 or
alternatively<00:00:23.160><c> you</c><00:00:23.970><c> could</c><00:00:24.119><c> say</c><00:00:24.359><c> that</c><00:00:24.630><c> G</c><00:00:25.410><c> of</c><00:00:25.439><c> Z</c>

00:00:25.910 --> 00:00:25.920 align:start position:0%
alternatively you could say that G of Z
 

00:00:25.920 --> 00:00:28.279 align:start position:0%
alternatively you could say that G of Z
is<00:00:26.189><c> equal</c><00:00:26.699><c> to</c><00:00:26.910><c> Z</c><00:00:27.150><c> right</c><00:00:27.510><c> sometimes</c><00:00:27.960><c> this</c><00:00:28.140><c> is</c>

00:00:28.279 --> 00:00:28.289 align:start position:0%
is equal to Z right sometimes this is
 

00:00:28.289 --> 00:00:31.460 align:start position:0%
is equal to Z right sometimes this is
called<00:00:28.320><c> the</c><00:00:28.760><c> linear</c><00:00:29.760><c> activation</c><00:00:30.720><c> function</c>

00:00:31.460 --> 00:00:31.470 align:start position:0%
called the linear activation function
 

00:00:31.470 --> 00:00:33.290 align:start position:0%
called the linear activation function
maybe<00:00:32.130><c> a</c><00:00:32.219><c> better</c><00:00:32.430><c> name</c><00:00:32.669><c> for</c><00:00:32.700><c> it</c><00:00:32.910><c> would</c><00:00:33.059><c> be</c><00:00:33.090><c> the</c>

00:00:33.290 --> 00:00:33.300 align:start position:0%
maybe a better name for it would be the
 

00:00:33.300 --> 00:00:35.420 align:start position:0%
maybe a better name for it would be the
identity<00:00:33.780><c> activation</c><00:00:34.469><c> function</c><00:00:34.890><c> because</c><00:00:35.280><c> it</c>

00:00:35.420 --> 00:00:35.430 align:start position:0%
identity activation function because it
 

00:00:35.430 --> 00:00:38.270 align:start position:0%
identity activation function because it
was<00:00:35.550><c> just</c><00:00:35.730><c> outputs</c><00:00:36.450><c> whatever</c><00:00:36.870><c> was</c><00:00:37.079><c> input</c><00:00:37.280><c> for</c>

00:00:38.270 --> 00:00:38.280 align:start position:0%
was just outputs whatever was input for
 

00:00:38.280 --> 00:00:39.260 align:start position:0%
was just outputs whatever was input for
the<00:00:38.340><c> purpose</c><00:00:38.700><c> of</c><00:00:38.820><c> this</c>

00:00:39.260 --> 00:00:39.270 align:start position:0%
the purpose of this
 

00:00:39.270 --> 00:00:44.000 align:start position:0%
the purpose of this
what<00:00:40.050><c> if</c><00:00:40.230><c> a2</c><00:00:40.860><c> was</c><00:00:41.730><c> just</c><00:00:41.969><c> equal</c><00:00:42.329><c> to</c><00:00:42.450><c> z2</c><00:00:42.840><c> it</c><00:00:43.710><c> turns</c>

00:00:44.000 --> 00:00:44.010 align:start position:0%
what if a2 was just equal to z2 it turns
 

00:00:44.010 --> 00:00:46.400 align:start position:0%
what if a2 was just equal to z2 it turns
out<00:00:44.190><c> if</c><00:00:44.309><c> you</c><00:00:44.399><c> do</c><00:00:44.579><c> this</c><00:00:44.789><c> then</c><00:00:45.270><c> this</c><00:00:45.660><c> model</c><00:00:45.960><c> is</c>

00:00:46.400 --> 00:00:46.410 align:start position:0%
out if you do this then this model is
 

00:00:46.410 --> 00:00:50.720 align:start position:0%
out if you do this then this model is
just<00:00:46.940><c> computing</c><00:00:47.940><c> Y</c><00:00:48.660><c> or</c><00:00:49.260><c> Y</c><00:00:49.440><c> hat</c><00:00:49.710><c> as</c><00:00:50.039><c> a</c><00:00:50.100><c> linear</c>

00:00:50.720 --> 00:00:50.730 align:start position:0%
just computing Y or Y hat as a linear
 

00:00:50.730 --> 00:00:54.380 align:start position:0%
just computing Y or Y hat as a linear
function<00:00:51.270><c> of</c><00:00:51.300><c> your</c><00:00:51.719><c> input</c><00:00:52.079><c> features</c><00:00:53.180><c> x2</c><00:00:54.180><c> take</c>

00:00:54.380 --> 00:00:54.390 align:start position:0%
function of your input features x2 take
 

00:00:54.390 --> 00:00:57.160 align:start position:0%
function of your input features x2 take
the<00:00:54.510><c> first</c><00:00:54.780><c> two</c><00:00:54.930><c> equations</c><00:00:55.440><c> if</c><00:00:55.680><c> you</c><00:00:56.219><c> have</c><00:00:56.489><c> that</c>

00:00:57.160 --> 00:00:57.170 align:start position:0%
the first two equations if you have that
 

00:00:57.170 --> 00:01:05.960 align:start position:0%
the first two equations if you have that
a1<00:00:58.170><c> is</c><00:00:58.440><c> equal</c><00:00:58.829><c> to</c><00:00:59.449><c> z1</c><00:01:00.500><c> is</c><00:01:01.500><c> equal</c><00:01:02.250><c> to</c><00:01:03.290><c> w1</c><00:01:04.670><c> X</c><00:01:05.670><c> plus</c>

00:01:05.960 --> 00:01:05.970 align:start position:0%
a1 is equal to z1 is equal to w1 X plus
 

00:01:05.970 --> 00:01:12.710 align:start position:0%
a1 is equal to z1 is equal to w1 X plus
B<00:01:06.210><c> and</c><00:01:07.460><c> if</c><00:01:08.460><c> then</c><00:01:08.909><c> a2</c><00:01:09.210><c> is</c><00:01:09.960><c> equal</c><00:01:10.260><c> to</c><00:01:10.680><c> z2</c><00:01:11.189><c> is</c><00:01:11.720><c> equal</c>

00:01:12.710 --> 00:01:12.720 align:start position:0%
B and if then a2 is equal to z2 is equal
 

00:01:12.720 --> 00:01:22.090 align:start position:0%
B and if then a2 is equal to z2 is equal
to<00:01:13.490><c> W</c><00:01:14.490><c> 2</c><00:01:16.070><c> a1</c><00:01:18.409><c> plus</c><00:01:19.409><c> B</c><00:01:20.420><c> then</c><00:01:21.420><c> if</c><00:01:21.600><c> you</c><00:01:21.659><c> take</c><00:01:21.810><c> the</c>

00:01:22.090 --> 00:01:22.100 align:start position:0%
to W 2 a1 plus B then if you take the
 

00:01:22.100 --> 00:01:24.910 align:start position:0%
to W 2 a1 plus B then if you take the
definition<00:01:22.490><c> of</c><00:01:22.580><c> a</c><00:01:22.790><c> 1</c><00:01:23.299><c> and</c><00:01:23.990><c> plug</c><00:01:24.470><c> it</c><00:01:24.590><c> in</c><00:01:24.710><c> there</c>

00:01:24.910 --> 00:01:24.920 align:start position:0%
definition of a 1 and plug it in there
 

00:01:24.920 --> 00:01:30.930 align:start position:0%
definition of a 1 and plug it in there
you<00:01:25.640><c> find</c><00:01:25.939><c> that</c><00:01:26.210><c> a</c><00:01:26.450><c> 2</c><00:01:26.509><c> is</c><00:01:27.470><c> equal</c><00:01:27.920><c> to</c><00:01:27.950><c> W</c><00:01:28.549><c> 2</c><00:01:29.409><c> times</c>

00:01:30.930 --> 00:01:30.940 align:start position:0%
you find that a 2 is equal to W 2 times
 

00:01:30.940 --> 00:01:38.740 align:start position:0%
you find that a 2 is equal to W 2 times
W<00:01:31.940><c> 1</c><00:01:32.420><c> X</c><00:01:32.830><c> plus</c><00:01:33.830><c> B</c><00:01:34.220><c> 1</c><00:01:34.820><c> a</c><00:01:35.799><c> bit</c><00:01:36.880><c> right</c><00:01:37.880><c> so</c><00:01:38.210><c> this</c><00:01:38.390><c> is</c><00:01:38.540><c> on</c>

00:01:38.740 --> 00:01:38.750 align:start position:0%
W 1 X plus B 1 a bit right so this is on
 

00:01:38.750 --> 00:01:46.690 align:start position:0%
W 1 X plus B 1 a bit right so this is on
a<00:01:39.190><c> 1</c><00:01:40.509><c> plus</c><00:01:41.509><c> B</c><00:01:41.780><c> 2</c><00:01:41.810><c> and</c><00:01:42.399><c> so</c><00:01:43.399><c> this</c><00:01:43.610><c> simplifies</c><00:01:43.940><c> to</c><00:01:45.700><c> W</c>

00:01:46.690 --> 00:01:46.700 align:start position:0%
a 1 plus B 2 and so this simplifies to W
 

00:01:46.700 --> 00:01:59.490 align:start position:0%
a 1 plus B 2 and so this simplifies to W
2<00:01:46.909><c> W</c><00:01:47.600><c> 1</c><00:01:47.630><c> X</c><00:01:49.659><c> plus</c><00:01:51.369><c> W</c><00:01:52.369><c> 2</c><00:01:52.930><c> B</c><00:01:53.930><c> 1</c><00:01:54.759><c> plus</c><00:01:55.759><c> B</c><00:01:56.000><c> 2</c><00:01:57.460><c> so</c><00:01:58.460><c> this</c><00:01:58.640><c> is</c>

00:01:59.490 --> 00:01:59.500 align:start position:0%
2 W 1 X plus W 2 B 1 plus B 2 so this is
 

00:01:59.500 --> 00:02:06.700 align:start position:0%
2 W 1 X plus W 2 B 1 plus B 2 so this is
just<00:02:02.200><c> let's</c><00:02:03.200><c> call</c><00:02:03.409><c> this</c><00:02:03.619><c> w</c><00:02:04.340><c> prime</c><00:02:05.140><c> B</c><00:02:06.140><c> prime</c><00:02:06.440><c> so</c>

00:02:06.700 --> 00:02:06.710 align:start position:0%
just let's call this w prime B prime so
 

00:02:06.710 --> 00:02:10.150 align:start position:0%
just let's call this w prime B prime so
this<00:02:06.890><c> is</c><00:02:06.979><c> just</c><00:02:07.100><c> equal</c><00:02:07.429><c> to</c><00:02:07.640><c> W</c><00:02:08.390><c> prime</c><00:02:08.600><c> X</c><00:02:08.950><c> plus</c><00:02:09.950><c> B</c>

00:02:10.150 --> 00:02:10.160 align:start position:0%
this is just equal to W prime X plus B
 

00:02:10.160 --> 00:02:10.690 align:start position:0%
this is just equal to W prime X plus B
Prime

00:02:10.690 --> 00:02:10.700 align:start position:0%
Prime
 

00:02:10.700 --> 00:02:12.729 align:start position:0%
Prime
if<00:02:11.030><c> you</c><00:02:11.600><c> were</c><00:02:11.780><c> to</c><00:02:11.930><c> use</c><00:02:12.080><c> linear</c><00:02:12.470><c> activation</c>

00:02:12.729 --> 00:02:12.739 align:start position:0%
if you were to use linear activation
 

00:02:12.739 --> 00:02:15.670 align:start position:0%
if you were to use linear activation
functions<00:02:13.459><c> or</c><00:02:13.850><c> we</c><00:02:14.150><c> go</c><00:02:14.600><c> to</c><00:02:14.660><c> call</c><00:02:14.930><c> them</c><00:02:15.080><c> identity</c>

00:02:15.670 --> 00:02:15.680 align:start position:0%
functions or we go to call them identity
 

00:02:15.680 --> 00:02:18.670 align:start position:0%
functions or we go to call them identity
activation<00:02:16.220><c> functions</c><00:02:16.640><c> then</c><00:02:17.600><c> the</c><00:02:17.870><c> new</c>

00:02:18.670 --> 00:02:18.680 align:start position:0%
activation functions then the new
 

00:02:18.680 --> 00:02:20.949 align:start position:0%
activation functions then the new
network<00:02:18.950><c> is</c><00:02:19.280><c> just</c><00:02:19.459><c> outputting</c><00:02:20.090><c> a</c><00:02:20.299><c> linear</c>

00:02:20.949 --> 00:02:20.959 align:start position:0%
network is just outputting a linear
 

00:02:20.959 --> 00:02:24.370 align:start position:0%
network is just outputting a linear
function<00:02:21.410><c> of</c><00:02:21.440><c> the</c><00:02:21.860><c> input</c><00:02:22.250><c> and</c><00:02:23.200><c> we'll</c><00:02:24.200><c> talk</c>

00:02:24.370 --> 00:02:24.380 align:start position:0%
function of the input and we'll talk
 

00:02:24.380 --> 00:02:26.560 align:start position:0%
function of the input and we'll talk
about<00:02:24.530><c> deep</c><00:02:24.980><c> networks</c><00:02:25.580><c> later</c><00:02:25.790><c> neural</c>

00:02:26.560 --> 00:02:26.570 align:start position:0%
about deep networks later neural
 

00:02:26.570 --> 00:02:28.569 align:start position:0%
about deep networks later neural
networks<00:02:26.959><c> with</c><00:02:27.170><c> many</c><00:02:27.410><c> many</c><00:02:27.620><c> layers</c><00:02:27.860><c> many</c><00:02:28.370><c> many</c>

00:02:28.569 --> 00:02:28.579 align:start position:0%
networks with many many layers many many
 

00:02:28.579 --> 00:02:30.550 align:start position:0%
networks with many many layers many many
hidden<00:02:28.730><c> layers</c><00:02:28.880><c> and</c><00:02:29.299><c> it</c><00:02:29.360><c> turns</c><00:02:29.570><c> out</c><00:02:29.750><c> that</c><00:02:29.810><c> if</c>

00:02:30.550 --> 00:02:30.560 align:start position:0%
hidden layers and it turns out that if
 

00:02:30.560 --> 00:02:33.580 align:start position:0%
hidden layers and it turns out that if
you<00:02:31.220><c> use</c><00:02:31.610><c> a</c><00:02:31.880><c> linear</c><00:02:32.180><c> activation</c><00:02:32.780><c> function</c><00:02:33.260><c> or</c>

00:02:33.580 --> 00:02:33.590 align:start position:0%
you use a linear activation function or
 

00:02:33.590 --> 00:02:35.050 align:start position:0%
you use a linear activation function or
alternatively<00:02:34.280><c> if</c><00:02:34.489><c> you</c><00:02:34.579><c> don't</c><00:02:34.760><c> have</c><00:02:34.940><c> an</c>

00:02:35.050 --> 00:02:35.060 align:start position:0%
alternatively if you don't have an
 

00:02:35.060 --> 00:02:37.000 align:start position:0%
alternatively if you don't have an
activation<00:02:35.450><c> function</c><00:02:35.600><c> then</c><00:02:36.560><c> no</c><00:02:36.739><c> matter</c><00:02:36.890><c> how</c>

00:02:37.000 --> 00:02:37.010 align:start position:0%
activation function then no matter how
 

00:02:37.010 --> 00:02:38.800 align:start position:0%
activation function then no matter how
many<00:02:37.340><c> layers</c><00:02:37.519><c> your</c><00:02:38.209><c> neural</c><00:02:38.450><c> network</c><00:02:38.510><c> has</c>

00:02:38.800 --> 00:02:38.810 align:start position:0%
many layers your neural network has
 

00:02:38.810 --> 00:02:41.590 align:start position:0%
many layers your neural network has
always<00:02:39.530><c> doing</c><00:02:39.859><c> is</c><00:02:40.010><c> just</c><00:02:40.220><c> computing</c><00:02:40.790><c> a</c><00:02:40.940><c> linear</c>

00:02:41.590 --> 00:02:41.600 align:start position:0%
always doing is just computing a linear
 

00:02:41.600 --> 00:02:43.599 align:start position:0%
always doing is just computing a linear
activation<00:02:42.109><c> function</c><00:02:42.530><c> so</c><00:02:43.160><c> you</c><00:02:43.220><c> might</c><00:02:43.430><c> as</c><00:02:43.579><c> well</c>

00:02:43.599 --> 00:02:43.609 align:start position:0%
activation function so you might as well
 

00:02:43.609 --> 00:02:46.960 align:start position:0%
activation function so you might as well
not<00:02:43.940><c> have</c><00:02:44.000><c> any</c><00:02:44.329><c> hidden</c><00:02:44.540><c> layers</c><00:02:45.820><c> some</c><00:02:46.820><c> of</c><00:02:46.910><c> the</c>

00:02:46.960 --> 00:02:46.970 align:start position:0%
not have any hidden layers some of the
 

00:02:46.970 --> 00:02:49.780 align:start position:0%
not have any hidden layers some of the
cases<00:02:47.420><c> that</c><00:02:47.560><c> briefly</c><00:02:48.560><c> mentioned</c><00:02:49.040><c> it</c><00:02:49.519><c> turns</c>

00:02:49.780 --> 00:02:49.790 align:start position:0%
cases that briefly mentioned it turns
 

00:02:49.790 --> 00:02:52.000 align:start position:0%
cases that briefly mentioned it turns
out<00:02:50.030><c> that</c><00:02:50.329><c> if</c><00:02:50.540><c> you</c><00:02:50.630><c> have</c><00:02:50.810><c> a</c><00:02:50.840><c> linear</c><00:02:51.260><c> activation</c>

00:02:52.000 --> 00:02:52.010 align:start position:0%
out that if you have a linear activation
 

00:02:52.010 --> 00:02:54.490 align:start position:0%
out that if you have a linear activation
function<00:02:52.670><c> here</c><00:02:53.000><c> and</c><00:02:53.180><c> a</c><00:02:53.660><c> sigmoid</c><00:02:54.109><c> function</c>

00:02:54.490 --> 00:02:54.500 align:start position:0%
function here and a sigmoid function
 

00:02:54.500 --> 00:02:57.009 align:start position:0%
function here and a sigmoid function
here<00:02:54.829><c> then</c><00:02:55.489><c> this</c><00:02:55.730><c> model</c><00:02:55.970><c> is</c><00:02:56.450><c> no</c><00:02:56.780><c> more</c>

00:02:57.009 --> 00:02:57.019 align:start position:0%
here then this model is no more
 

00:02:57.019 --> 00:02:58.990 align:start position:0%
here then this model is no more
expressive<00:02:57.500><c> than</c><00:02:57.890><c> standard</c><00:02:58.790><c> logistic</c>

00:02:58.990 --> 00:02:59.000 align:start position:0%
expressive than standard logistic
 

00:02:59.000 --> 00:03:02.680 align:start position:0%
expressive than standard logistic
regression<00:02:59.950><c> without</c><00:03:00.950><c> any</c><00:03:01.280><c> hidden</c><00:03:01.850><c> layer</c><00:03:02.180><c> so</c><00:03:02.630><c> I</c>

00:03:02.680 --> 00:03:02.690 align:start position:0%
regression without any hidden layer so I
 

00:03:02.690 --> 00:03:04.420 align:start position:0%
regression without any hidden layer so I
won't<00:03:02.870><c> bother</c><00:03:03.019><c> to</c><00:03:03.290><c> prove</c><00:03:03.470><c> that</c><00:03:03.650><c> but</c><00:03:03.950><c> you</c><00:03:04.310><c> could</c>

00:03:04.420 --> 00:03:04.430 align:start position:0%
won't bother to prove that but you could
 

00:03:04.430 --> 00:03:06.550 align:start position:0%
won't bother to prove that but you could
try<00:03:04.549><c> to</c><00:03:04.670><c> do</c><00:03:04.880><c> so</c><00:03:05.060><c> if</c><00:03:05.180><c> you</c><00:03:05.209><c> want</c><00:03:05.420><c> but</c><00:03:06.260><c> to</c><00:03:06.380><c> take</c>

00:03:06.550 --> 00:03:06.560 align:start position:0%
try to do so if you want but to take
 

00:03:06.560 --> 00:03:09.670 align:start position:0%
try to do so if you want but to take
home<00:03:06.799><c> is</c><00:03:07.100><c> that</c><00:03:07.310><c> a</c><00:03:07.549><c> linear</c><00:03:08.049><c> hidden</c><00:03:09.049><c> layer</c><00:03:09.230><c> is</c>

00:03:09.670 --> 00:03:09.680 align:start position:0%
home is that a linear hidden layer is
 

00:03:09.680 --> 00:03:12.699 align:start position:0%
home is that a linear hidden layer is
more<00:03:10.310><c> or</c><00:03:10.400><c> less</c><00:03:10.459><c> useless</c><00:03:11.150><c> because</c><00:03:11.420><c> on</c><00:03:11.840><c> the</c>

00:03:12.699 --> 00:03:12.709 align:start position:0%
more or less useless because on the
 

00:03:12.709 --> 00:03:15.039 align:start position:0%
more or less useless because on the
composition<00:03:13.100><c> of</c><00:03:13.609><c> two</c><00:03:13.940><c> linear</c><00:03:14.150><c> functions</c><00:03:14.450><c> is</c><00:03:15.019><c> a</c>

00:03:15.039 --> 00:03:15.049 align:start position:0%
composition of two linear functions is a
 

00:03:15.049 --> 00:03:17.860 align:start position:0%
composition of two linear functions is a
sailfin<00:03:15.530><c> linear</c><00:03:15.799><c> function</c><00:03:16.160><c> so</c><00:03:16.660><c> unless</c><00:03:17.660><c> you</c>

00:03:17.860 --> 00:03:17.870 align:start position:0%
sailfin linear function so unless you
 

00:03:17.870 --> 00:03:20.199 align:start position:0%
sailfin linear function so unless you
throw<00:03:18.260><c> a</c><00:03:18.290><c> non-linearity</c><00:03:19.280><c> in</c><00:03:19.400><c> there</c><00:03:19.640><c> then</c>

00:03:20.199 --> 00:03:20.209 align:start position:0%
throw a non-linearity in there then
 

00:03:20.209 --> 00:03:21.970 align:start position:0%
throw a non-linearity in there then
you're<00:03:20.390><c> not</c><00:03:20.510><c> computing</c><00:03:21.140><c> more</c><00:03:21.380><c> interesting</c>

00:03:21.970 --> 00:03:21.980 align:start position:0%
you're not computing more interesting
 

00:03:21.980 --> 00:03:24.039 align:start position:0%
you're not computing more interesting
functions<00:03:22.459><c> even</c><00:03:22.730><c> as</c><00:03:23.000><c> you</c><00:03:23.150><c> go</c><00:03:23.329><c> deeper</c><00:03:23.750><c> in</c><00:03:23.930><c> the</c>

00:03:24.039 --> 00:03:24.049 align:start position:0%
functions even as you go deeper in the
 

00:03:24.049 --> 00:03:27.220 align:start position:0%
functions even as you go deeper in the
network<00:03:24.489><c> there</c><00:03:25.489><c> is</c><00:03:25.549><c> just</c><00:03:26.000><c> one</c><00:03:26.450><c> place</c><00:03:26.840><c> where</c>

00:03:27.220 --> 00:03:27.230 align:start position:0%
network there is just one place where
 

00:03:27.230 --> 00:03:29.050 align:start position:0%
network there is just one place where
you<00:03:27.380><c> might</c><00:03:27.560><c> use</c><00:03:27.859><c> a</c><00:03:27.890><c> linear</c><00:03:28.400><c> activation</c>

00:03:29.050 --> 00:03:29.060 align:start position:0%
you might use a linear activation
 

00:03:29.060 --> 00:03:32.160 align:start position:0%
you might use a linear activation
function<00:03:29.510><c> G</c><00:03:30.260><c> of</c><00:03:30.380><c> Z</c><00:03:30.560><c> equals</c><00:03:30.919><c> Z</c>

00:03:32.160 --> 00:03:32.170 align:start position:0%
function G of Z equals Z
 

00:03:32.170 --> 00:03:34.980 align:start position:0%
function G of Z equals Z
and<00:03:32.260><c> that's</c><00:03:32.560><c> if</c><00:03:32.830><c> you</c><00:03:33.040><c> are</c><00:03:33.720><c> doing</c><00:03:34.720><c> machine</c>

00:03:34.980 --> 00:03:34.990 align:start position:0%
and that's if you are doing machine
 

00:03:34.990 --> 00:03:37.440 align:start position:0%
and that's if you are doing machine
learning<00:03:35.050><c> on</c><00:03:35.590><c> a</c><00:03:35.650><c> regression</c><00:03:36.130><c> problem</c><00:03:36.730><c> so</c><00:03:37.000><c> if</c><00:03:37.150><c> y</c>

00:03:37.440 --> 00:03:37.450 align:start position:0%
learning on a regression problem so if y
 

00:03:37.450 --> 00:03:40.589 align:start position:0%
learning on a regression problem so if y
is<00:03:38.230><c> a</c><00:03:38.290><c> real</c><00:03:38.770><c> number</c><00:03:39.220><c> so</c><00:03:39.550><c> for</c><00:03:39.730><c> example</c><00:03:40.150><c> if</c>

00:03:40.589 --> 00:03:40.599 align:start position:0%
is a real number so for example if
 

00:03:40.599 --> 00:03:42.059 align:start position:0%
is a real number so for example if
you're<00:03:40.840><c> trying</c><00:03:41.020><c> to</c><00:03:41.260><c> predict</c><00:03:41.680><c> housing</c><00:03:41.860><c> prices</c>

00:03:42.059 --> 00:03:42.069 align:start position:0%
you're trying to predict housing prices
 

00:03:42.069 --> 00:03:45.990 align:start position:0%
you're trying to predict housing prices
so<00:03:42.849><c> why</c><00:03:43.209><c> is</c><00:03:43.270><c> a</c><00:03:43.780><c> there's</c><00:03:44.650><c> not</c><00:03:44.830><c> 0</c><00:03:45.190><c> 1</c><00:03:45.489><c> but</c><00:03:45.760><c> is</c><00:03:45.880><c> a</c>

00:03:45.990 --> 00:03:46.000 align:start position:0%
so why is a there's not 0 1 but is a
 

00:03:46.000 --> 00:03:49.290 align:start position:0%
so why is a there's not 0 1 but is a
real<00:03:46.239><c> number</c><00:03:46.420><c> you</c><00:03:46.840><c> know</c><00:03:46.989><c> anywhere</c><00:03:47.410><c> from</c><00:03:48.300><c> zero</c>

00:03:49.290 --> 00:03:49.300 align:start position:0%
real number you know anywhere from zero
 

00:03:49.300 --> 00:03:51.300 align:start position:0%
real number you know anywhere from zero
dollars<00:03:49.750><c> is</c><00:03:49.959><c> a</c><00:03:49.989><c> price</c><00:03:50.260><c> of</c><00:03:50.440><c> homes</c><00:03:50.650><c> up</c><00:03:51.040><c> to</c>

00:03:51.300 --> 00:03:51.310 align:start position:0%
dollars is a price of homes up to
 

00:03:51.310 --> 00:03:54.540 align:start position:0%
dollars is a price of homes up to
however<00:03:52.060><c> expensive</c><00:03:52.900><c> right</c><00:03:53.350><c> how's</c><00:03:54.160><c> the</c><00:03:54.310><c> scale</c>

00:03:54.540 --> 00:03:54.550 align:start position:0%
however expensive right how's the scale
 

00:03:54.550 --> 00:03:56.990 align:start position:0%
however expensive right how's the scale
I<00:03:54.580><c> guess</c><00:03:54.850><c> maybe</c><00:03:55.060><c> houses</c><00:03:55.480><c> can</c><00:03:55.660><c> be</c><00:03:55.690><c> you</c><00:03:56.440><c> know</c>

00:03:56.990 --> 00:03:57.000 align:start position:0%
I guess maybe houses can be you know
 

00:03:57.000 --> 00:03:59.360 align:start position:0%
I guess maybe houses can be you know
potentially<00:03:58.000><c> millions</c><00:03:58.360><c> of</c><00:03:58.540><c> dollars</c><00:03:58.900><c> so</c>

00:03:59.360 --> 00:03:59.370 align:start position:0%
potentially millions of dollars so
 

00:03:59.370 --> 00:04:04.050 align:start position:0%
potentially millions of dollars so
however<00:04:01.230><c> however</c><00:04:02.230><c> much</c><00:04:02.560><c> houses</c><00:04:03.010><c> cost</c><00:04:03.760><c> in</c><00:04:03.940><c> your</c>

00:04:04.050 --> 00:04:04.060 align:start position:0%
however however much houses cost in your
 

00:04:04.060 --> 00:04:08.490 align:start position:0%
however however much houses cost in your
data<00:04:04.209><c> set</c><00:04:04.480><c> but</c><00:04:04.660><c> if</c><00:04:04.780><c> Y</c><00:04:05.670><c> takes</c><00:04:06.670><c> on</c><00:04:07.170><c> these</c><00:04:08.170><c> real</c>

00:04:08.490 --> 00:04:08.500 align:start position:0%
data set but if Y takes on these real
 

00:04:08.500 --> 00:04:12.300 align:start position:0%
data set but if Y takes on these real
values<00:04:09.360><c> then</c><00:04:10.360><c> it</c><00:04:10.540><c> might</c><00:04:10.780><c> be</c><00:04:10.959><c> ok</c><00:04:11.410><c> to</c><00:04:12.100><c> have</c><00:04:12.190><c> a</c>

00:04:12.300 --> 00:04:12.310 align:start position:0%
values then it might be ok to have a
 

00:04:12.310 --> 00:04:14.400 align:start position:0%
values then it might be ok to have a
linear<00:04:12.610><c> activation</c><00:04:12.850><c> function</c><00:04:13.540><c> here</c><00:04:13.840><c> so</c><00:04:14.170><c> that</c>

00:04:14.400 --> 00:04:14.410 align:start position:0%
linear activation function here so that
 

00:04:14.410 --> 00:04:19.590 align:start position:0%
linear activation function here so that
your<00:04:14.860><c> output</c><00:04:15.510><c> Y</c><00:04:16.510><c> hat</c><00:04:16.840><c> is</c><00:04:17.200><c> also</c><00:04:17.979><c> a</c><00:04:18.519><c> real</c><00:04:19.389><c> number</c>

00:04:19.590 --> 00:04:19.600 align:start position:0%
your output Y hat is also a real number
 

00:04:19.600 --> 00:04:21.599 align:start position:0%
your output Y hat is also a real number
going<00:04:20.079><c> anywhere</c><00:04:20.440><c> from</c><00:04:20.650><c> minus</c><00:04:21.070><c> infinity</c><00:04:21.160><c> to</c>

00:04:21.599 --> 00:04:21.609 align:start position:0%
going anywhere from minus infinity to
 

00:04:21.609 --> 00:04:25.909 align:start position:0%
going anywhere from minus infinity to
plus<00:04:22.000><c> infinity</c><00:04:23.460><c> but</c><00:04:24.460><c> then</c><00:04:24.610><c> the</c><00:04:24.760><c> hidden</c><00:04:24.970><c> units</c>

00:04:25.909 --> 00:04:25.919 align:start position:0%
plus infinity but then the hidden units
 

00:04:25.919 --> 00:04:27.990 align:start position:0%
plus infinity but then the hidden units
should<00:04:26.919><c> not</c><00:04:27.100><c> use</c><00:04:27.370><c> them</c><00:04:27.520><c> your</c><00:04:27.669><c> activation</c>

00:04:27.990 --> 00:04:28.000 align:start position:0%
should not use them your activation
 

00:04:28.000 --> 00:04:31.100 align:start position:0%
should not use them your activation
functions<00:04:28.600><c> they</c><00:04:28.780><c> could</c><00:04:28.960><c> use</c><00:04:29.110><c> value</c><00:04:29.590><c> or</c><00:04:30.040><c> 10</c><00:04:30.880><c> H</c>

00:04:31.100 --> 00:04:31.110 align:start position:0%
functions they could use value or 10 H
 

00:04:31.110 --> 00:04:34.469 align:start position:0%
functions they could use value or 10 H
or<00:04:32.110><c> Li</c><00:04:32.290><c> Q</c><00:04:32.500><c> value</c><00:04:32.800><c> or</c><00:04:32.979><c> maybe</c><00:04:33.130><c> something</c><00:04:33.490><c> else</c><00:04:33.610><c> so</c>

00:04:34.469 --> 00:04:34.479 align:start position:0%
or Li Q value or maybe something else so
 

00:04:34.479 --> 00:04:36.030 align:start position:0%
or Li Q value or maybe something else so
the<00:04:34.630><c> one</c><00:04:34.840><c> place</c><00:04:35.080><c> you</c><00:04:35.350><c> might</c><00:04:35.500><c> use</c><00:04:35.710><c> a</c><00:04:35.740><c> linear</c>

00:04:36.030 --> 00:04:36.040 align:start position:0%
the one place you might use a linear
 

00:04:36.040 --> 00:04:38.490 align:start position:0%
the one place you might use a linear
activation<00:04:36.340><c> function</c><00:04:37.030><c> is</c><00:04:37.900><c> usually</c><00:04:38.289><c> in</c><00:04:38.470><c> the</c>

00:04:38.490 --> 00:04:38.500 align:start position:0%
activation function is usually in the
 

00:04:38.500 --> 00:04:42.600 align:start position:0%
activation function is usually in the
output<00:04:39.100><c> layer</c><00:04:39.310><c> but</c><00:04:40.240><c> other</c><00:04:40.450><c> than</c><00:04:40.630><c> that</c><00:04:41.430><c> using</c><00:04:42.430><c> a</c>

00:04:42.600 --> 00:04:42.610 align:start position:0%
output layer but other than that using a
 

00:04:42.610 --> 00:04:46.260 align:start position:0%
output layer but other than that using a
linear<00:04:43.360><c> activation</c><00:04:43.660><c> function</c><00:04:44.350><c> in</c><00:04:44.590><c> a</c><00:04:45.270><c> hidden</c>

00:04:46.260 --> 00:04:46.270 align:start position:0%
linear activation function in a hidden
 

00:04:46.270 --> 00:04:48.690 align:start position:0%
linear activation function in a hidden
layer<00:04:46.830><c> except</c><00:04:47.830><c> for</c><00:04:47.979><c> some</c><00:04:48.130><c> very</c><00:04:48.340><c> special</c>

00:04:48.690 --> 00:04:48.700 align:start position:0%
layer except for some very special
 

00:04:48.700 --> 00:04:51.360 align:start position:0%
layer except for some very special
circumstances<00:04:49.660><c> relating</c><00:04:50.650><c> to</c><00:04:50.890><c> compression</c>

00:04:51.360 --> 00:04:51.370 align:start position:0%
circumstances relating to compression
 

00:04:51.370 --> 00:04:53.580 align:start position:0%
circumstances relating to compression
that<00:04:51.700><c> won't</c><00:04:51.940><c> want</c><00:04:52.060><c> to</c><00:04:52.120><c> talk</c><00:04:52.270><c> about</c><00:04:52.419><c> using</c><00:04:53.410><c> the</c>

00:04:53.580 --> 00:04:53.590 align:start position:0%
that won't want to talk about using the
 

00:04:53.590 --> 00:04:55.200 align:start position:0%
that won't want to talk about using the
linear<00:04:53.919><c> activation</c><00:04:54.100><c> function</c><00:04:54.729><c> is</c><00:04:54.940><c> extremely</c>

00:04:55.200 --> 00:04:55.210 align:start position:0%
linear activation function is extremely
 

00:04:55.210 --> 00:04:57.300 align:start position:0%
linear activation function is extremely
rare<00:04:55.750><c> oh</c><00:04:55.990><c> and</c><00:04:56.530><c> of</c><00:04:56.620><c> course</c><00:04:56.830><c> they're</c><00:04:57.010><c> actually</c>

00:04:57.300 --> 00:04:57.310 align:start position:0%
rare oh and of course they're actually
 

00:04:57.310 --> 00:04:59.100 align:start position:0%
rare oh and of course they're actually
predicting<00:04:57.669><c> housing</c><00:04:57.880><c> prices</c><00:04:58.060><c> as</c><00:04:58.660><c> you</c><00:04:58.810><c> saw</c><00:04:58.990><c> in</c>

00:04:59.100 --> 00:04:59.110 align:start position:0%
predicting housing prices as you saw in
 

00:04:59.110 --> 00:05:01.230 align:start position:0%
predicting housing prices as you saw in
the<00:04:59.200><c> week</c><00:04:59.410><c> 1</c><00:04:59.620><c> video</c><00:04:59.800><c> because</c><00:05:00.669><c> housing</c><00:05:01.000><c> prices</c>

00:05:01.230 --> 00:05:01.240 align:start position:0%
the week 1 video because housing prices
 

00:05:01.240 --> 00:05:03.450 align:start position:0%
the week 1 video because housing prices
are<00:05:01.539><c> all</c><00:05:01.690><c> non-negative</c><00:05:01.900><c> perhaps</c><00:05:02.890><c> even</c><00:05:03.100><c> then</c>

00:05:03.450 --> 00:05:03.460 align:start position:0%
are all non-negative perhaps even then
 

00:05:03.460 --> 00:05:05.790 align:start position:0%
are all non-negative perhaps even then
you<00:05:04.060><c> can</c><00:05:04.240><c> use</c><00:05:04.390><c> a</c><00:05:04.419><c> rare</c><00:05:04.780><c> loop</c><00:05:04.960><c> activation</c>

00:05:05.790 --> 00:05:05.800 align:start position:0%
you can use a rare loop activation
 

00:05:05.800 --> 00:05:08.430 align:start position:0%
you can use a rare loop activation
function<00:05:06.220><c> so</c><00:05:06.820><c> that</c><00:05:07.030><c> your</c><00:05:07.180><c> outputs</c><00:05:07.570><c> Y</c><00:05:07.780><c> hat</c><00:05:08.080><c> are</c>

00:05:08.430 --> 00:05:08.440 align:start position:0%
function so that your outputs Y hat are
 

00:05:08.440 --> 00:05:12.029 align:start position:0%
function so that your outputs Y hat are
all<00:05:09.190><c> greater</c><00:05:09.760><c> than</c><00:05:09.880><c> or</c><00:05:10.030><c> equal</c><00:05:10.360><c> to</c><00:05:10.479><c> 0</c><00:05:10.810><c> so</c><00:05:11.050><c> I</c><00:05:11.830><c> hope</c>

00:05:12.029 --> 00:05:12.039 align:start position:0%
all greater than or equal to 0 so I hope
 

00:05:12.039 --> 00:05:14.010 align:start position:0%
all greater than or equal to 0 so I hope
that<00:05:12.100><c> gives</c><00:05:12.340><c> you</c><00:05:12.460><c> a</c><00:05:12.520><c> sense</c><00:05:12.760><c> of</c><00:05:12.970><c> why</c><00:05:13.180><c> having</c><00:05:13.930><c> a</c>

00:05:14.010 --> 00:05:14.020 align:start position:0%
that gives you a sense of why having a
 

00:05:14.020 --> 00:05:16.170 align:start position:0%
that gives you a sense of why having a
nonlinear<00:05:14.710><c> activation</c><00:05:15.340><c> function</c><00:05:15.880><c> is</c><00:05:16.120><c> a</c>

00:05:16.170 --> 00:05:16.180 align:start position:0%
nonlinear activation function is a
 

00:05:16.180 --> 00:05:19.590 align:start position:0%
nonlinear activation function is a
critical<00:05:16.780><c> part</c><00:05:16.990><c> of</c><00:05:17.320><c> neural</c><00:05:18.039><c> networks</c><00:05:18.600><c> next</c>

00:05:19.590 --> 00:05:19.600 align:start position:0%
critical part of neural networks next
 

00:05:19.600 --> 00:05:21.029 align:start position:0%
critical part of neural networks next
we're<00:05:19.900><c> going</c><00:05:20.020><c> to</c><00:05:20.110><c> start</c><00:05:20.470><c> to</c><00:05:20.800><c> talk</c><00:05:20.979><c> about</c>

00:05:21.029 --> 00:05:21.039 align:start position:0%
we're going to start to talk about
 

00:05:21.039 --> 00:05:24.330 align:start position:0%
we're going to start to talk about
gradient<00:05:22.000><c> descent</c><00:05:22.450><c> and</c><00:05:23.200><c> to</c><00:05:23.440><c> do</c><00:05:23.590><c> that</c><00:05:23.770><c> to</c><00:05:24.100><c> set</c>

00:05:24.330 --> 00:05:24.340 align:start position:0%
gradient descent and to do that to set
 

00:05:24.340 --> 00:05:26.219 align:start position:0%
gradient descent and to do that to set
up<00:05:24.460><c> discussion</c><00:05:24.940><c> for</c><00:05:25.360><c> gradient</c><00:05:25.660><c> descent</c><00:05:25.960><c> in</c>

00:05:26.219 --> 00:05:26.229 align:start position:0%
up discussion for gradient descent in
 

00:05:26.229 --> 00:05:28.320 align:start position:0%
up discussion for gradient descent in
the<00:05:26.650><c> next</c><00:05:26.890><c> video</c><00:05:27.160><c> I</c><00:05:27.430><c> want</c><00:05:27.640><c> to</c><00:05:27.669><c> show</c><00:05:27.850><c> you</c><00:05:27.910><c> how</c><00:05:28.300><c> to</c>

00:05:28.320 --> 00:05:28.330 align:start position:0%
the next video I want to show you how to
 

00:05:28.330 --> 00:05:30.960 align:start position:0%
the next video I want to show you how to
estimate<00:05:29.110><c> how</c><00:05:29.350><c> to</c><00:05:29.410><c> compute</c><00:05:29.860><c> the</c><00:05:30.310><c> slope</c><00:05:30.550><c> of</c><00:05:30.850><c> the</c>

00:05:30.960 --> 00:05:30.970 align:start position:0%
estimate how to compute the slope of the
 

00:05:30.970 --> 00:05:33.150 align:start position:0%
estimate how to compute the slope of the
derivative<00:05:31.150><c> of</c><00:05:31.690><c> individual</c><00:05:32.560><c> activation</c>

00:05:33.150 --> 00:05:33.160 align:start position:0%
derivative of individual activation
 

00:05:33.160 --> 00:05:35.070 align:start position:0%
derivative of individual activation
functions<00:05:33.580><c> so</c><00:05:34.270><c> let's</c><00:05:34.450><c> go</c><00:05:34.600><c> on</c><00:05:34.720><c> to</c><00:05:34.840><c> the</c><00:05:34.930><c> next</c>

00:05:35.070 --> 00:05:35.080 align:start position:0%
functions so let's go on to the next
 

00:05:35.080 --> 00:05:37.440 align:start position:0%
functions so let's go on to the next
video

