1
00:00:00,030 --> 00:00:02,580
The following is a conversation
with Serratia of all.

2
00:00:02,940 --> 00:00:07,770
He's an educator and entertainer,
a rapper, and an entrepreneur.

3
00:00:08,280 --> 00:00:09,960
He's the founder of school of Ai,

4
00:00:10,200 --> 00:00:13,980
which is an online education platform
and community that makes topics and data

5
00:00:13,981 --> 00:00:17,730
science, machine learning,
AI accessible to everyone.

6
00:00:18,270 --> 00:00:22,380
He's one of the most unique, eccentric
and creative educators on the Internet,

7
00:00:22,710 --> 00:00:27,060
constantly innovating and reinventing
himself. Many people love them,

8
00:00:27,450 --> 00:00:28,320
some people don't.

9
00:00:28,800 --> 00:00:32,370
But the inspiring thing about Sarraj is
that he doesn't let the critic stopped

10
00:00:32,371 --> 00:00:35,670
them. He just learns from
the criticism and improves.

11
00:00:36,300 --> 00:00:39,420
You should go to his youtube channel
and subscribe for many accessible

12
00:00:39,421 --> 00:00:42,750
introductory videos and AI.
Unlike cause youtube videos,

13
00:00:42,751 --> 00:00:47,070
this conversation was a relaxed low
key chat about his personal story,

14
00:00:47,280 --> 00:00:49,020
his process,
and his vision.

15
00:00:49,650 --> 00:00:53,810
This conversation is part or
the artificial intelligence
podcasts. If you enjoy,

16
00:00:54,090 --> 00:00:55,830
subscribe on Youtube,
iTunes,

17
00:00:55,831 --> 00:01:00,480
or simply connect with me on Twitter at
[inaudible] Friedman, spelledF , r I, d.

18
00:01:00,870 --> 00:01:03,960
And now here's my conversation with Siraj,

19
00:01:04,990 --> 00:01:07,230
Jay z or Kanye,
Kanye.

20
00:01:08,190 --> 00:01:13,140
Anybody better than Kanye in terms of
producing music in terms of the full

21
00:01:13,200 --> 00:01:16,860
package,
I mean her as a full package,

22
00:01:16,861 --> 00:01:19,170
probably Kendrick Lamar.
Okay.

23
00:01:20,040 --> 00:01:24,510
You're one of the most unapologetically
unique personalities in the Ai Community.

24
00:01:24,511 --> 00:01:29,511
So I want to talk to you today a little
bit less about AI and a little bit more

25
00:01:31,471 --> 00:01:36,471
about what I think inspires thousands
of people if not more about you Raj,

26
00:01:39,330 --> 00:01:42,210
which is the lack of fear and
trying something different.

27
00:01:42,240 --> 00:01:47,240
Even if you fail and you
openly and publicly are
searching for yourself and try

28
00:01:48,331 --> 00:01:50,880
to define who you are as an individual,
as a person.

29
00:01:50,910 --> 00:01:55,910
And I think the way you're doing that
openly sort of online in video form and

30
00:01:58,260 --> 00:02:03,260
trying crazy things going all out in the
most confident way of scene is pretty

31
00:02:04,801 --> 00:02:06,000
inspiring.
And it,

32
00:02:06,150 --> 00:02:11,150
I think too many people in this world
in general are just afraid to do that,

33
00:02:11,881 --> 00:02:14,490
to be fragile,
to put themselves out there,

34
00:02:15,000 --> 00:02:19,830
especially the internet, especially
youtube. In the face of criticism,

35
00:02:19,831 --> 00:02:24,720
scrutiny. So many people love
you, are inspired by you,

36
00:02:24,900 --> 00:02:29,700
but some people criticize
you. Um, looking at,

37
00:02:29,701 --> 00:02:32,190
uh,
you machine learning subreddit,

38
00:02:33,810 --> 00:02:35,250
how do you take such criticism,

39
00:02:35,280 --> 00:02:39,330
especially when you put so much of
yourself in the content that you put out?

40
00:02:40,110 --> 00:02:41,820
When I first started it definitely hurt.

41
00:02:42,540 --> 00:02:47,130
I would post pretty much all my videos
to reiterate what you said. Yes.

42
00:02:47,160 --> 00:02:50,760
In the machine learning sub
reddit, but generally, yeah,

43
00:02:51,360 --> 00:02:55,500
it was mostly negative feedback
and um, yeah, I mean it,

44
00:02:55,810 --> 00:03:00,070
it legitimately hurt,
but I think what got me to

45
00:03:00,190 --> 00:03:04,210
keep going despite that was
that I felt like this field,

46
00:03:04,300 --> 00:03:08,650
the techniques, um, in AI
were more significant than me.

47
00:03:08,680 --> 00:03:12,130
It's not about me. Like I can be the
gesture, you know, I can be the joker,

48
00:03:12,340 --> 00:03:16,270
I can be that martyr that people can
make fun of as long as people get it,

49
00:03:16,570 --> 00:03:20,710
that this is a very important technology
and we can use it to make huge impacts

50
00:03:20,711 --> 00:03:24,220
in society. As long as people get that,
I don't care what people say about me.

51
00:03:24,490 --> 00:03:28,390
Over time I've become more and more
numb to the haters. We're at this point,

52
00:03:28,530 --> 00:03:33,530
I feel like pretty much
like oblivious finally.

53
00:03:33,690 --> 00:03:35,820
Well hold on a second. So
that, that's a beautiful thing.

54
00:03:35,860 --> 00:03:40,860
It's about the idea that you're trying
to spread about the sort of inspire and

55
00:03:40,861 --> 00:03:44,460
just open the eyes and the door to people
that don't know anything about machine

56
00:03:44,461 --> 00:03:46,950
learning. Get them into
it, get them excited,

57
00:03:46,980 --> 00:03:48,660
whether you're young or old or whatever.

58
00:03:49,020 --> 00:03:52,680
But you're also trying to find yourself
like all of us are and doing it pretty

59
00:03:52,681 --> 00:03:55,680
publicly. So in that sense, criticism,

60
00:03:56,340 --> 00:03:58,860
I know criticism hurts
me a lot when people,

61
00:03:59,010 --> 00:04:03,720
cause I am trying to put myself out there
and I'm putting my ugly face and voice

62
00:04:03,721 --> 00:04:07,140
that I hate listening to out there.
And it hurts when somebody says,

63
00:04:07,141 --> 00:04:10,290
this guy's an idiot that that doesn't,

64
00:04:11,370 --> 00:04:15,450
you're saying at this point it
gets better. It gets better.

65
00:04:15,930 --> 00:04:20,760
It does get better because if you
keep putting out value to society,

66
00:04:20,820 --> 00:04:23,580
eventually you'll have
more lovers than haters.

67
00:04:24,030 --> 00:04:26,940
And the lovers just outweigh the haters.
Okay.

68
00:04:26,941 --> 00:04:31,410
So your trajectory up to this point,
it's been, let's say unconventional.

69
00:04:32,430 --> 00:04:34,580
You've pretty much made your way,
uh,

70
00:04:34,590 --> 00:04:38,190
your own way and ignored
what others have said.

71
00:04:38,670 --> 00:04:40,320
Or at least you know,
the,

72
00:04:40,680 --> 00:04:43,890
the folks who may be pushed you to
go towards the more conventional way.

73
00:04:44,520 --> 00:04:47,820
And you've been pretty honest about it.
So let's, let's go to the beginning.

74
00:04:47,850 --> 00:04:49,680
Tell me where you grew up.

75
00:04:50,330 --> 00:04:54,620
I was born in Houston, Houston,
Texas. My parents are from India.

76
00:04:55,370 --> 00:04:57,350
I was born in,
obviously in Houston.

77
00:04:58,430 --> 00:05:01,610
Spent 18 years there before I
moved to New York for college.

78
00:05:02,930 --> 00:05:07,820
Right. Columbia. But Columbia, what's
it like growing up? I mean, is it,

79
00:05:07,821 --> 00:05:09,770
uh,
so I grew up in Jewish parents.

80
00:05:09,771 --> 00:05:13,160
There's a lot of pressure to
do certain kinds of things,
right. And doctor, lawyer,

81
00:05:13,161 --> 00:05:14,480
scientist.
Uh,

82
00:05:14,600 --> 00:05:17,290
what were your parents doing and what
were they pushing you into doing?

83
00:05:17,570 --> 00:05:20,270
So Jewish in Indian
parents are pretty similar.

84
00:05:20,390 --> 00:05:23,270
I've learned that after having gone to
Columbia, met a lot of Jewish people,

85
00:05:23,271 --> 00:05:26,870
may a lot of Jewish friends in
San Francisco as well in and La.

86
00:05:27,110 --> 00:05:31,960
So there were similar in that they're like
scientists, engineer, lawyer, you know,

87
00:05:31,961 --> 00:05:36,940
you need to marry, marry a good
Indian girl or Jewish girl, you know,

88
00:05:37,000 --> 00:05:40,050
just to point out the
similarity yet again. But, um,

89
00:05:40,090 --> 00:05:44,140
it was very much conservative.
Do what you're told,

90
00:05:44,170 --> 00:05:48,520
don't question things too much, get
a stable job and uh, go to a really,

91
00:05:48,521 --> 00:05:51,160
really good school because we're
not going to pay for your college.

92
00:05:51,161 --> 00:05:55,180
So you need to really get a full
ride to Columbia or some good school,

93
00:05:55,181 --> 00:05:57,980
which I did. So that thankful
he pulled that off. So

94
00:05:57,980 --> 00:06:01,220
what was your value system?
What, uh, what do you, what,

95
00:06:01,221 --> 00:06:05,960
what did you find gave you meaning
and you're in the early days?

96
00:06:06,450 --> 00:06:10,700
I, so one of the interesting
things is you've grown a lot.

97
00:06:10,730 --> 00:06:15,050
You've developed a lie, you've evolved
a lot. It's clear from just your path.

98
00:06:15,650 --> 00:06:16,730
Uh,
I,

99
00:06:16,731 --> 00:06:20,060
I've read that you've changed your name
and then gone back and you struggle with

100
00:06:20,061 --> 00:06:22,370
your identity and some
very interesting ways.

101
00:06:22,371 --> 00:06:26,360
But let's start at the sort of the
beginning who were trying to be, how,

102
00:06:26,420 --> 00:06:27,830
how we try to fit in.

103
00:06:31,390 --> 00:06:35,560
So growing up in Houston,
which was not inside of a city,

104
00:06:35,561 --> 00:06:39,550
but it was more like the farm
lands, it's like majority, you know,

105
00:06:39,590 --> 00:06:44,540
Caucasian white people.
And, um, yeah, I was like,

106
00:06:44,600 --> 00:06:47,480
we were the only Indian
family in the area.

107
00:06:47,840 --> 00:06:52,100
So I felt kind of like
an outsider growing up.

108
00:06:52,400 --> 00:06:55,490
So that, that, that feeling of being,

109
00:06:55,491 --> 00:06:57,950
feeling a little alienated
from other people,

110
00:06:59,000 --> 00:07:02,690
I think that helped my creativity and to
be able to look at things from both an

111
00:07:02,691 --> 00:07:04,940
insiders and an outsider's perspective,

112
00:07:05,240 --> 00:07:09,980
and to put those two perspectives together
to create some new idea or thought or

113
00:07:09,981 --> 00:07:14,870
path forward. I definitely felt alienated
and in my, what I was trying to be in,

114
00:07:14,871 --> 00:07:16,610
what I was trying to do was to fit in.

115
00:07:16,910 --> 00:07:20,930
So what that meant in the context
of Houston and Texas was like,

116
00:07:20,931 --> 00:07:25,370
I want it to be more,
let's just say white anglicised,

117
00:07:25,430 --> 00:07:28,040
American, white, Christian. You know,

118
00:07:28,041 --> 00:07:33,041
those values that everybody around me
held that my family didn't necessarily

119
00:07:33,681 --> 00:07:36,710
hold.
I want it to be more like that.

120
00:07:36,830 --> 00:07:40,430
So I wanted to be loved and liked.
What point

121
00:07:41,550 --> 00:07:45,200
did you change your name? You try changing
your name to become more England size.

122
00:07:45,810 --> 00:07:49,200
When I was 18, so right when I got my
letter to Columbia, the acceptance letter,

123
00:07:49,230 --> 00:07:51,540
I legally changed it
against my parents' wishes.

124
00:07:51,960 --> 00:07:55,870
And in fact they offered me money not
to change it. Um, you told them? Yeah,

125
00:07:55,910 --> 00:07:57,900
the discussion and we had this discussion,

126
00:07:58,320 --> 00:08:01,890
like I'm changing my name to
Jason Scott rebel because, uh,

127
00:08:02,160 --> 00:08:05,640
I feel like it would be easier just to,
for everything to,

128
00:08:06,510 --> 00:08:09,030
for whatever reason I felt like that,
like that at the time.

129
00:08:09,180 --> 00:08:13,290
And to get a job to get accepted
by people too, you know,

130
00:08:14,520 --> 00:08:19,020
um, do a bunch of things. So I
did it and when I got to Columbia,

131
00:08:19,080 --> 00:08:21,570
that's what I, the name I went by. Um,

132
00:08:21,600 --> 00:08:25,830
but just to like put things into even
even more extreme perspective that I don't

133
00:08:25,831 --> 00:08:28,410
think I've said before. Not only
did I change my name, but I like,

134
00:08:28,710 --> 00:08:33,570
I wore green contacts and I dyed my hair
a little brown and I told people that I

135
00:08:33,571 --> 00:08:36,090
was, um, you know, half Brazilian.

136
00:08:36,840 --> 00:08:40,380
I really didn't like my ancestry,
my ethnicity,

137
00:08:42,770 --> 00:08:46,460
and uh, I just felt like I
want it to be something else.

138
00:08:46,461 --> 00:08:49,670
I'm going to reinvent myself.
So that could be like more,

139
00:08:50,470 --> 00:08:53,950
I mean this is the coolest theme that
continues with you is really interesting.

140
00:08:53,951 --> 00:08:55,470
Did you have a vision of that?

141
00:08:55,680 --> 00:09:00,680
Of being half Brazilian or was
this a off the cuff I had a vision.

142
00:09:02,730 --> 00:09:05,490
So like you're,
you have like Steve Jobs,

143
00:09:05,491 --> 00:09:09,870
you have an intention behind that person.
You see yourself as,

144
00:09:11,310 --> 00:09:14,910
yeah. Yeah. More I think more social

145
00:09:16,900 --> 00:09:20,360
cause I was pretty introverted
in high school, more popular,

146
00:09:20,390 --> 00:09:24,650
more liked and a funner,
a better dancer.

147
00:09:25,130 --> 00:09:25,963
And

148
00:09:26,470 --> 00:09:29,660
how did it feel being that, you know,
that's a big step just going to college,

149
00:09:29,700 --> 00:09:34,360
leaving parents, parents behind. What did
it feel like to a show up in New York?

150
00:09:36,150 --> 00:09:40,250
It was super exciting.
The first two,

151
00:09:40,251 --> 00:09:41,330
three months,

152
00:09:42,110 --> 00:09:47,110
we're super exciting and new and people
I felt pretty accepted and that's not

153
00:09:47,391 --> 00:09:51,500
because I was, you know, looking back
half Brazilian or whatever. I just,

154
00:09:51,501 --> 00:09:52,400
I'd never known

155
00:09:54,000 --> 00:09:56,900
what a culture like
Columbia could be like. I,

156
00:09:56,920 --> 00:10:00,750
I'd never been in that kind of scenario
where everyone's pretty, you know,

157
00:10:01,140 --> 00:10:05,760
educated and has a more worldly view,
you know,

158
00:10:05,980 --> 00:10:07,380
to,
to give you one example,

159
00:10:07,740 --> 00:10:10,580
in my public high school and I went
to a pretty good public high schools,

160
00:10:10,630 --> 00:10:14,490
giant public high school feeder school
for a lot of people in the area.

161
00:10:15,000 --> 00:10:17,940
I remember in our history class senior
year, the teacher asks a question,

162
00:10:17,941 --> 00:10:20,870
is anyone watching the g 20 summit
or know what that is? You're,

163
00:10:20,880 --> 00:10:22,500
are you familiar with the judgment?
And so,

164
00:10:22,620 --> 00:10:25,380
and my class was like IB
international baccalaureate,

165
00:10:25,381 --> 00:10:27,180
which is kind of like a piece,
like an advance.

166
00:10:27,210 --> 00:10:29,220
It's like the advanced program
of that public high school.

167
00:10:29,221 --> 00:10:31,950
So it was like the smartest kids in
the high school. Nobody accepted me,

168
00:10:31,951 --> 00:10:33,660
raise my hand because no one.

169
00:10:33,960 --> 00:10:37,990
And that's when I realized like does no
one care about what's happening outside

170
00:10:37,991 --> 00:10:40,950
of the u s you know,
but whereas in Colombia,

171
00:10:41,010 --> 00:10:43,560
everybody knew obviously what that was.
And so that was cool.

172
00:10:43,800 --> 00:10:45,360
So I did feel more accepted.

173
00:10:45,390 --> 00:10:48,510
It's not because I don't think it was
because I had changed my name or anything,

174
00:10:48,540 --> 00:10:52,110
but I had to learn that. So I changed
it back. By the way, I changed my back.

175
00:10:52,200 --> 00:10:57,110
My name legally backs your name Sir Roger
Hall, which is my original name. Yeah.

176
00:10:57,420 --> 00:11:00,390
One of that happen pretty quickly.
Oh,

177
00:11:00,391 --> 00:11:02,460
it happened four years later.

178
00:11:03,360 --> 00:11:07,600
So when I moved to San
Francisco after I left Colombia.

179
00:11:07,980 --> 00:11:10,110
Was that with intention behind it as well?
Well

180
00:11:10,140 --> 00:11:10,921
that was intention.

181
00:11:10,921 --> 00:11:14,790
I had a startup at the time called lucid
robotics and we were building a seven

182
00:11:14,791 --> 00:11:18,690
degree of freedom autonomous robot to
help older people with als to pick things

183
00:11:18,691 --> 00:11:22,290
up off the floor, controlled by an iPad
via remote, you know, camera vision,

184
00:11:22,620 --> 00:11:26,850
object detection, touch the object.
And then autonomous grasping.

185
00:11:27,390 --> 00:11:31,650
This is like 2014. So I was like
deep learning wasn't like really,

186
00:11:32,670 --> 00:11:35,610
um,
feasible for on device.

187
00:11:36,960 --> 00:11:41,820
Would you use deep learning?
No, of course. Yeah, you
would have a robotic arm. Uh,

188
00:11:41,821 --> 00:11:44,550
for autonomous. I mean
opening, I had the, uh,

189
00:11:44,760 --> 00:11:49,090
the grasping demo,
which was cool simulation,

190
00:11:49,170 --> 00:11:53,980
a version of DRL, which was kind of
right, but for product, if you want

191
00:11:53,980 --> 00:11:57,250
to go product, most, uh,
most industrial robotics,

192
00:11:57,251 --> 00:12:02,230
most manipulation is not going to use RL,
at least from what I've seen.

193
00:12:02,260 --> 00:12:04,090
I mean,
not Pieter Abbeel is trying to get,

194
00:12:04,600 --> 00:12:08,860
trying to start applying our own that
space. But you look at Boston Dynamics,

195
00:12:08,861 --> 00:12:13,060
he look at, uh, uh, was Rodney
Brooks is rethink robotics.

196
00:12:13,120 --> 00:12:16,420
There's no RL insight.
It's interesting.

197
00:12:16,421 --> 00:12:20,130
If you waited a little longer and see
how a deep learning version of that would

198
00:12:20,131 --> 00:12:25,120
have worked out, you ever
think about getting back into
the startup world? I mean,

199
00:12:25,121 --> 00:12:28,240
you're in a startup now in a sense
that you're creating your own,

200
00:12:28,990 --> 00:12:32,830
whatever you want to call it, whether
it's a youtube channel or a media empire,

201
00:12:32,860 --> 00:12:37,390
it's somewhere in between, right? The hope
is to create an accredited university,

202
00:12:38,320 --> 00:12:39,190
accredited university.

203
00:12:39,191 --> 00:12:44,191
So what do you think is broken or is not
broken about the university education

204
00:12:46,541 --> 00:12:51,250
system too expensive as money, money.
What about the actual experience?

205
00:12:51,251 --> 00:12:53,260
Say it was all free.
Say it was all the same.

206
00:12:53,590 --> 00:12:57,340
Do you think you think
you can be improved upon?

207
00:12:57,341 --> 00:13:02,341
So you've been teaching a lot of very
large number of people through uh,

208
00:13:03,190 --> 00:13:05,800
through online,
through video forum.

209
00:13:06,370 --> 00:13:10,330
Do you think that's more
effective as audacity model?

210
00:13:10,400 --> 00:13:13,240
What's Sebastian through and as
explored and you have explored,

211
00:13:13,810 --> 00:13:15,640
do you think there is a,

212
00:13:16,210 --> 00:13:19,510
it's more effective than
a classroom education?

213
00:13:20,450 --> 00:13:21,770
I do think it's more effective,

214
00:13:21,950 --> 00:13:26,270
but there are still people who are going
to want to get a bachelor's degree.

215
00:13:26,570 --> 00:13:30,320
Like, you know, certificates
have their place, right?

216
00:13:30,620 --> 00:13:32,960
Bootcamps training programs,
they all have their place.

217
00:13:32,990 --> 00:13:37,310
But the idea of a four year degree
isn't going away anytime soon.

218
00:13:37,430 --> 00:13:42,430
So that needs to be upgraded to Internet
status and that needs to be made free

219
00:13:43,280 --> 00:13:45,890
and to have that same
student support quality.

220
00:13:45,891 --> 00:13:49,430
And I'm talking about the full spectrum
of student support and not just um,

221
00:13:49,490 --> 00:13:52,640
support for a specific module of a course,
but mental health,

222
00:13:52,850 --> 00:13:57,770
like the full spectrum of what a school
like MIT provides needs to be made

223
00:13:57,800 --> 00:13:59,450
freely available online.

224
00:14:00,250 --> 00:14:03,560
Is that where school of Ai Fits
in? Yeah, it's just school.

225
00:14:03,570 --> 00:14:07,810
The guys building a global large
community of people. Right.

226
00:14:08,530 --> 00:14:09,790
So you think that's,

227
00:14:09,820 --> 00:14:14,820
there's a future in which school of AI
gets accredited status where you can get

228
00:14:14,861 --> 00:14:18,550
degrees and so on. That's,
that's my, that's my dream.

229
00:14:20,230 --> 00:14:22,120
I've heard,
you mentioned somewhere,

230
00:14:22,121 --> 00:14:26,180
I read mentioned somewhere that you
want to essentially be a movie star,

231
00:14:27,020 --> 00:14:30,080
right?
In that kind of swim in that realm.

232
00:14:30,710 --> 00:14:35,710
Is that still a dream of yours to exist
in some kind of a height and status and

233
00:14:38,870 --> 00:14:40,820
realm of movie stars?

234
00:14:41,190 --> 00:14:44,670
So definitely when I started there
was a need for external validation.

235
00:14:44,671 --> 00:14:48,720
It wasn't all internal like, oh, I
educated them, I feel good. It was also,

236
00:14:49,260 --> 00:14:53,320
I want to loved by the
audience and I wanted to,

237
00:14:53,400 --> 00:14:57,230
and I felt like by becoming famous,
that would be something that I could feel.

238
00:14:57,560 --> 00:14:59,870
And I felt like, you know, I've
been doing this for three years now,

239
00:14:59,871 --> 00:15:04,460
which is not that long, but three years
now I feel validated externally by now.

240
00:15:04,520 --> 00:15:09,260
Like why now? I'm good. So, so
why do I want to be movie stars?

241
00:15:09,261 --> 00:15:13,070
So the reason I mentioned that is it's
not for more, um, external validation,

242
00:15:13,071 --> 00:15:16,640
like my name on the billboards. Like I'm,
I'm good. Like if I stay this famous,

243
00:15:16,641 --> 00:15:19,910
but I can continue to do this goal of
getting like a accredited, you know,

244
00:15:19,911 --> 00:15:23,600
university, I will be happy. And like
having, you know, a few close friends,

245
00:15:23,900 --> 00:15:26,870
you know, living in La, I'm good. Like
I don't need to be more famous anymore.

246
00:15:26,960 --> 00:15:30,530
Like I, I felt it. Why do I want to be
a movie star? So let me correct you.

247
00:15:30,531 --> 00:15:33,020
I did want to be in a movie earlier,

248
00:15:33,200 --> 00:15:38,200
but now what it is is I want to either
have a Netflix show or just join the

249
00:15:38,361 --> 00:15:43,160
mainstream in some ways. So I can
propagate this message to the youth,

250
00:15:43,490 --> 00:15:46,370
which is the future of Ai.
So to give you one example,

251
00:15:46,460 --> 00:15:51,460
last week I was at a party at a club
in La called Dalilah's and Drake's dad

252
00:15:53,691 --> 00:15:56,070
shows up and Drake is there as
well. And like, I didn't even know.

253
00:15:56,071 --> 00:15:59,120
He strikes out and we were
like chatting and I was like,

254
00:15:59,540 --> 00:16:03,470
and then like one guy was
like, hey, hey you Indian. I
was like, yeah. He's like, hi,

255
00:16:03,471 --> 00:16:07,340
you cool. I was like, wow, that's all it
takes. But like they were like a crew,

256
00:16:07,341 --> 00:16:09,050
like they all knew each other.
A bunch of rappers,

257
00:16:09,060 --> 00:16:12,710
Atlanta Mbos are pulling up SUVs and
I'm sitting here trying to whisper sweet

258
00:16:12,740 --> 00:16:17,150
nothings about data and algorithms into
the ears of these rappers because if and

259
00:16:17,151 --> 00:16:20,090
Jaden Smith, the reason I went there
is because I heard a rap, Jaden Smith,

260
00:16:20,210 --> 00:16:21,230
he's will Smith's son.

261
00:16:21,440 --> 00:16:24,560
He made a rap called Calabasas
freestyle and this is so nerdy.

262
00:16:24,561 --> 00:16:27,890
I know exactly the time marker
at the two 45 minute mark,

263
00:16:27,920 --> 00:16:29,900
he mentioned the word neural net

264
00:16:31,640 --> 00:16:35,990
and the full line was that's what the
neural net will become when the AI is

265
00:16:35,991 --> 00:16:36,800
sentient.

266
00:16:36,800 --> 00:16:40,790
And so that's when I saw hope because
Jane not 2 million views on that music

267
00:16:40,791 --> 00:16:43,790
video. The youth listen to
Jayden and hip hop has, you know,

268
00:16:43,791 --> 00:16:47,390
just their past rock music as the number
one listened to genre in the United

269
00:16:47,390 --> 00:16:51,770
States. I did not know that. And that's
similar to something as powerful.

270
00:16:51,830 --> 00:16:55,220
That's powerful. So if I can
be, I don't need to be the guy,

271
00:16:55,250 --> 00:16:58,250
I don't need to be the rapper like I was
just doing it because no one else was

272
00:16:58,251 --> 00:17:00,530
doing it.
If I can be the advisor to the guy,

273
00:17:00,710 --> 00:17:05,710
like I'm trying to get this stuff into
the ears of these influential mainstream

274
00:17:05,751 --> 00:17:08,450
rappers in and if not
that's not going to work.

275
00:17:08,451 --> 00:17:12,050
Then I'll try Netflix show like something
like something's radical needs to

276
00:17:12,051 --> 00:17:17,051
happen to get people who care about
like totally not unrelated topics like

277
00:17:18,921 --> 00:17:23,921
fashion and music and art
and beauty culture news and
focus it on data literacy.

278
00:17:29,300 --> 00:17:33,530
Technical literacy because that's
where the jobs of the future are.

279
00:17:33,950 --> 00:17:38,540
And that's how we're going to
stay competitive as a country.

280
00:17:38,570 --> 00:17:39,560
But I have a global view.

281
00:17:39,770 --> 00:17:44,770
So every country and everybody needs to
be competitive and impacting society.

282
00:17:45,890 --> 00:17:50,100
So like we really got to bring this
down to the Kim Kardashian level.

283
00:17:51,190 --> 00:17:54,160
I like this a data literacy.
You know,

284
00:17:54,280 --> 00:17:58,720
the Kardashians are several orders
of magnitude more famous than any AI

285
00:17:58,721 --> 00:18:03,100
researcher, almost any scientists
in the world. And so it's,

286
00:18:03,850 --> 00:18:08,850
it's nice that you're thinking basically
how to break any aspect of this into

287
00:18:10,091 --> 00:18:12,370
the mainstream,
into the real mainstream.

288
00:18:13,480 --> 00:18:17,860
And it sounds like you're not
constrained to anyone medium or anyone.

289
00:18:18,250 --> 00:18:23,250
Path is basically anything and you're
just creating all kinds of crazy things to

290
00:18:23,591 --> 00:18:27,280
try to get there. So where
did rap come from? You uh,

291
00:18:27,281 --> 00:18:30,640
you started making rap videos,
you have rap videos.

292
00:18:31,440 --> 00:18:34,300
I bought a bunch of different topics.
Pretty good rhymes,

293
00:18:34,660 --> 00:18:39,340
but it is nevertheless about AI,
which is hard to do. It's not,

294
00:18:39,580 --> 00:18:43,660
it's like a, it's a difficult dance
you're playing, right? Cause, uh,

295
00:18:44,110 --> 00:18:47,200
cause rap is,
you can educate me more,

296
00:18:47,201 --> 00:18:52,201
but there's a rap is more
about not giving a damn.

297
00:18:53,290 --> 00:18:58,290
So not caring and in a certain
there's a coolness to just like,

298
00:19:00,290 --> 00:19:01,090
uh,

299
00:19:01,090 --> 00:19:06,090
not giving a damn about anything and
in your apps or is that kind of you are

300
00:19:06,731 --> 00:19:10,740
giving a damn about
something and it's pretty uh,

301
00:19:10,780 --> 00:19:15,160
sort of technical and scientific, which
currently has a weight of being nerdy,

302
00:19:15,190 --> 00:19:19,220
so it's not cool. So you're
basically going up hill. Yeah.

303
00:19:19,510 --> 00:19:22,000
So what,
what inspired you?

304
00:19:22,600 --> 00:19:26,230
What made you brave enough to
put out the first one? Actually

305
00:19:27,080 --> 00:19:29,880
that's a good question.
And the people at the youtube space,

306
00:19:29,881 --> 00:19:34,260
we're like laughing and also looking
at each other. Like what does he do?

307
00:19:34,390 --> 00:19:35,250
Talk to you about?

308
00:19:35,790 --> 00:19:38,190
Cause I made at the youtube space
as a part of this creator camp.

309
00:19:38,390 --> 00:19:40,710
The first one alone la.
Yeah. In La a long time ago.

310
00:19:40,800 --> 00:19:45,540
Like three years ago when I first
started, well, produce, it's well written.

311
00:19:45,670 --> 00:19:49,510
I mean the whole thing. So you didn't
just, it wasn't like off the cuff,

312
00:19:49,840 --> 00:19:52,750
it was well done. So he said, okay.

313
00:19:52,751 --> 00:19:57,370
So let's take me through the genesis.
Like what were your thoughts?

314
00:19:57,610 --> 00:19:59,290
What were your hopes?
What was your vision for it?

315
00:19:59,650 --> 00:20:04,000
I've always liked my favorite subject
growing up in school as much as technology

316
00:20:04,001 --> 00:20:07,000
is, that wasn't really a subject
growing up in school was English,

317
00:20:07,180 --> 00:20:12,180
like wordplay and how to communicate and
put words together for maximum impact.

318
00:20:12,850 --> 00:20:15,520
And I've always had,
um, when I, when, when,

319
00:20:15,670 --> 00:20:20,020
whenever I was studying for tests or
anything like mnemonic devices like rhymes

320
00:20:20,170 --> 00:20:21,520
helped me memorize things.

321
00:20:21,760 --> 00:20:25,360
So what's the perfect
medium for rhyming rap?

322
00:20:25,990 --> 00:20:30,890
The perfect medium that is also
relevant to youth, the youth. So yeah,

323
00:20:31,490 --> 00:20:32,840
just putting together,
you know,

324
00:20:33,830 --> 00:20:38,270
like how can I simplify all of neural
network architecture into like two lines

325
00:20:38,300 --> 00:20:42,920
of English input times away, add a bias,
activate. Obviously there's more to it.

326
00:20:45,020 --> 00:20:49,810
Yeah. But it's easy. Remember it
rhymes and then you add a beat to it.

327
00:20:49,811 --> 00:20:53,320
And there there's your, there's your way
of studying and once you're out a test,

328
00:20:53,850 --> 00:20:56,260
you're in a test,
you can just remember it much easier.

329
00:20:56,560 --> 00:21:00,670
So it's a pneumonic device.
So I felt like that was my,

330
00:21:01,540 --> 00:21:05,740
um, drive. And I was thinking,
well, if I, if I would like it,

331
00:21:05,850 --> 00:21:08,890
I guess I made the bet that
there are other people who would

332
00:21:10,540 --> 00:21:13,660
do this as well because I would always
make wraps just in my head about,

333
00:21:14,220 --> 00:21:16,990
you know,
gps or like robots.

334
00:21:16,991 --> 00:21:20,530
Like I'd make songs and I
know he's like super weird,

335
00:21:21,590 --> 00:21:24,720
but also like I'm also
used to being weird. I'm,

336
00:21:24,721 --> 00:21:26,990
I'm used to being abnormal and not normal.

337
00:21:27,380 --> 00:21:30,890
And I think part of it was like
having a chip on my shoulder of like,

338
00:21:31,040 --> 00:21:34,640
I'm going to bring my abnormal reality
into the mainstream and change culture

339
00:21:35,000 --> 00:21:36,770
because I've got nothing
to lose and I've got,

340
00:21:36,830 --> 00:21:39,590
I'll only be here for like a hundred years
and like, let's just see what happens.

341
00:21:40,520 --> 00:21:44,360
So the thing is, you
know, that rep got, again,

342
00:21:44,780 --> 00:21:49,550
a lot of love, but it also got, you know,
like the usual haters, right? Right.

343
00:21:50,120 --> 00:21:53,390
Because you are really making yourself
fragile. You'd try and do something,

344
00:21:53,810 --> 00:21:57,650
you know from your perspective from the,
you're been in society,

345
00:21:57,651 --> 00:21:59,690
you're not supposed to do that.
Right.

346
00:21:59,691 --> 00:22:04,070
So you're totally doing what you're not
supposed to be doing. And a as weird.

347
00:22:04,100 --> 00:22:07,310
And so people are reacting in that way.

348
00:22:08,240 --> 00:22:13,240
So what was your feeling like because
you did more and they've gotten better.

349
00:22:14,230 --> 00:22:15,990
Yeah, they keep getting
better. That's the point. I'm,

350
00:22:15,991 --> 00:22:20,710
I'm approximate the day when nobody
says cringey on the top comments.

351
00:22:20,711 --> 00:22:23,610
I will be happy we're getting
there. I'm getting there. Yeah.

352
00:22:23,650 --> 00:22:26,470
Like every time it gets better.
Like I take all that feedback.

353
00:22:26,471 --> 00:22:31,270
Like I also know that people who are
commenting, cause I'm like uh, uh,

354
00:22:31,390 --> 00:22:34,930
a comment analysis machine. I read
everything. I read all that data,

355
00:22:34,931 --> 00:22:36,220
I look at audience retention,

356
00:22:36,221 --> 00:22:39,910
I look at the jokes that I made a at
that point and see did it go up or down

357
00:22:40,090 --> 00:22:44,040
based on that. And I've, it's
all a big feedback loop. You
know, for me, you look at

358
00:22:44,140 --> 00:22:45,200
criticism,
what,

359
00:22:45,340 --> 00:22:50,340
what do you in that in the full context
you're able to see the criticism is just

360
00:22:51,850 --> 00:22:55,510
one person saying a thing, one
another data point, another data.

361
00:22:55,590 --> 00:22:59,380
Well you know, like my latest music video
I've spent the most money on for sure,

362
00:23:01,270 --> 00:23:05,590
but I spent 10 k, 10 k on it
and it's all done. Thank you.

363
00:23:05,710 --> 00:23:10,210
So production value, way better than
ever before. Lyrical VA value that. Um,

364
00:23:10,600 --> 00:23:13,990
the, the, the musical value,
the beat best I've ever done,

365
00:23:14,170 --> 00:23:17,410
the lyrical valued now that's
where I know I need to work on.

366
00:23:17,411 --> 00:23:21,370
So it's like I'm moving up
all these metrics and I know
what to work on the next

367
00:23:21,400 --> 00:23:25,510
source. Like lyrically, I tried to fit
an entire AI lecture into this last,

368
00:23:26,050 --> 00:23:28,480
I did fit an entire
electric into the last Rep.

369
00:23:28,720 --> 00:23:31,810
Now I know that it doesn't have
to be an entire AI lecture.

370
00:23:31,960 --> 00:23:34,480
It's more about how it sounds and,

371
00:23:34,540 --> 00:23:37,530
and people will pick out like one line.
Yeah,

372
00:23:37,690 --> 00:23:40,260
they're not gonna memorize the entire
thing. They'll pick out one line.

373
00:23:40,261 --> 00:23:44,050
And so you really got to focus on
making that one line both impactful,

374
00:23:44,051 --> 00:23:46,310
educational and easy to remember.

375
00:23:46,311 --> 00:23:49,890
A catchy and then the rest can just kind
of be filler and like Yo, yeah, yeah.

376
00:23:49,940 --> 00:23:50,570
Whatever.

377
00:23:50,570 --> 00:23:53,870
What about, have you tried thinking
of going like the na's route,

378
00:23:54,110 --> 00:23:56,600
like a gong less produced,

379
00:23:57,800 --> 00:24:02,150
more like using a dark
room with a mic versus,

380
00:24:02,210 --> 00:24:06,440
there's like, there's a bunch of, I mean,
it looks like a rap video. You recent one,

381
00:24:06,700 --> 00:24:11,360
like, you know those girls and there's
a, it's well produced. Thanks. Have you,

382
00:24:11,361 --> 00:24:16,040
have you thought about just doing
like, I dunno, yeah, Nas on Mike.

383
00:24:16,430 --> 00:24:19,550
That's a great song. I Love Nas in, I,

384
00:24:19,740 --> 00:24:24,380
I right now I find too much fun
making the youtube videos, like, yeah.

385
00:24:24,440 --> 00:24:27,170
And I'm also like,
I feel compelled to do it

386
00:24:30,100 --> 00:24:34,450
for all of this year. Um, but
when I reach a certain metric,

387
00:24:34,451 --> 00:24:36,650
I will,
I might look into that.

388
00:24:36,680 --> 00:24:39,470
Do you have a number in your head?
They chasing? I do have a number.

389
00:24:39,500 --> 00:24:44,290
You want to share that number? 1
million? It's arbitrary. Oh, yeah, yeah,

390
00:24:44,300 --> 00:24:47,660
yeah. I know. It's awkward for me if
people don't know you have, I mean,

391
00:24:47,661 --> 00:24:52,280
you're approaching 600,000
subscribers. Yeah. I mean,

392
00:24:52,281 --> 00:24:57,010
is there a, you're probably one of
the most popular youtube channels, uh,

393
00:24:57,011 --> 00:25:01,720
of on a technical topic. Well, that's not
true. There's, um, there's a number file,

394
00:25:01,730 --> 00:25:06,190
computer files, uh, three ground.

395
00:25:06,230 --> 00:25:10,510
Yeah. Uh, but you're in that I'm
up there. Yeah. Here in Europe.

396
00:25:10,820 --> 00:25:15,240
You certainly the only one
wrapping, I mean the, one of
the cool things while you,

397
00:25:15,250 --> 00:25:15,980
like I said,

398
00:25:15,980 --> 00:25:19,310
keep harboring on this
cause it's inspiring to me I
think is inspiring to a lot

399
00:25:19,311 --> 00:25:22,640
of people is that you're chasing,
you're not,

400
00:25:22,700 --> 00:25:27,410
you're not trying to fit into anything.
You're, you're trying to be trying,

401
00:25:27,411 --> 00:25:30,410
you are unique and you try to
be yourself essentially. Yup.

402
00:25:30,620 --> 00:25:34,760
As you try to become more who
you are and becoming unique,

403
00:25:34,790 --> 00:25:38,720
discovering that you're,
that sound,

404
00:25:38,721 --> 00:25:42,050
that voice,
who do you find yourself becoming?

405
00:25:42,051 --> 00:25:45,650
How have you changed in the three years
that you've been working on your channel?

406
00:25:47,870 --> 00:25:51,920
Not In terms of content, but in terms of
who you are when you look in the mirror.

407
00:25:52,790 --> 00:25:56,930
I think I've become more humble,
more patient,

408
00:25:59,970 --> 00:26:01,380
more patient for sure.

409
00:26:01,860 --> 00:26:06,480
More patient with people that I
work with or tend to work with

410
00:26:08,270 --> 00:26:09,560
more empathetic,

411
00:26:10,670 --> 00:26:13,550
kinder and

412
00:26:15,050 --> 00:26:19,250
that's more patient, more empathetic,
kinder. Those are the big three.

413
00:26:19,930 --> 00:26:24,410
What, what, did you have a temper
before? No, I didn't have a temper.

414
00:26:24,411 --> 00:26:26,680
I had, uh, I,

415
00:26:26,810 --> 00:26:31,280
I wasn't very patient with
like to work with people.

416
00:26:31,281 --> 00:26:34,960
That's how I worked by myself for so long
cause I wanted to move so fast and he

417
00:26:34,990 --> 00:26:36,020
always had to be like my way.

418
00:26:36,560 --> 00:26:38,900
It's not like I was like angry if
someone that I just said, all right,

419
00:26:38,901 --> 00:26:40,220
we're not gonna work together.
Thank you.

420
00:26:40,780 --> 00:26:43,590
So like I look back at like you'd ask
city, I'm like, oh, I could have nicer.

421
00:26:44,670 --> 00:26:49,080
I always have to have in my way.
They were trying for sure. Good team,

422
00:26:49,260 --> 00:26:51,660
good people. Yeah. You
[inaudible] is a good team.

423
00:26:52,260 --> 00:26:57,220
Uh, so yeah, working with others,
you know, it's tough to create,

424
00:26:57,250 --> 00:26:58,200
especially when you're perfection,

425
00:26:58,290 --> 00:27:00,880
especially when you do the kind
of output the you're doing.

426
00:27:01,150 --> 00:27:05,200
It's hard to create with others.
So have you found,

427
00:27:05,650 --> 00:27:08,980
you said you've gotten better at it.
Have you found a magic formula,

428
00:27:09,310 --> 00:27:13,780
but how you're able to collaborate
with somebody else or, um,

429
00:27:13,910 --> 00:27:16,750
is it mostly, is, is most of
the content, most of the idea,

430
00:27:16,751 --> 00:27:21,751
most of the core of what you're
doing still just you on Mike.

431
00:27:23,280 --> 00:27:26,850
I have compromised a little bit
like I know how to compromise now.

432
00:27:27,030 --> 00:27:28,260
It's not just always my way.

433
00:27:28,860 --> 00:27:32,850
It's for the greater good like educating
people and as long as we're all on that,

434
00:27:33,580 --> 00:27:36,210
you know, we all have the same
goal. Like we can work together.

435
00:27:37,320 --> 00:27:40,210
You want to give me an example?
Yeah.

436
00:27:40,230 --> 00:27:44,580
Sort of working with someone who

437
00:27:46,740 --> 00:27:49,350
wants to fund my movement,
you know, with his,

438
00:27:49,530 --> 00:27:52,710
with his own funds and we
have, you know, it was,

439
00:27:52,711 --> 00:27:55,650
it was kind of hard to like work together
at first because we came at things

440
00:27:55,651 --> 00:27:57,000
from such different angles.

441
00:27:57,001 --> 00:28:00,450
Like I have a specialty and
that's social media velocity.

442
00:28:00,451 --> 00:28:03,000
I can make content really
fast and he has an angle,

443
00:28:03,001 --> 00:28:07,080
which is academic rigor and creating a,

444
00:28:07,200 --> 00:28:12,200
being able to create a very rigorous
curriculum that can be analyzed and tested

445
00:28:16,380 --> 00:28:20,820
by authorities.
And just like trying to combine those two.

446
00:28:21,540 --> 00:28:25,350
It's been hard as rough, but like,
and it's been only like a month now,

447
00:28:25,351 --> 00:28:26,610
but like it's working out.

448
00:28:26,890 --> 00:28:31,000
Let's talk about that. The rate of
which you output content is incredible.

449
00:28:31,440 --> 00:28:35,140
It's pretty rich. And, um, you know,
there's a lot going on in the videos.

450
00:28:35,141 --> 00:28:38,540
There's a lot of content,
but in terms of rigor,

451
00:28:38,541 --> 00:28:42,850
sometimes your videos can lack rigor,
right? Just because you're so focused.

452
00:28:43,030 --> 00:28:44,140
I mean,
at least from my perspective,

453
00:28:44,141 --> 00:28:47,890
you can maybe speak to it is still
focused on the creative art of it,

454
00:28:48,790 --> 00:28:50,360
that sometimes,
uh,

455
00:28:50,470 --> 00:28:55,070
that's probably what your creative
processes like is more, uh,

456
00:28:55,150 --> 00:28:59,330
treating it like a rap video
versus sort of dealed school, uh,

457
00:28:59,410 --> 00:29:03,580
lecture. Yeah. So, uh, do,
do you ever think about that?

458
00:29:03,581 --> 00:29:08,320
Do you ever consider slowing down,
uh, or even slowing down here?

459
00:29:08,321 --> 00:29:12,850
I'll give you two examples. So one is
sort of the angel rang, which you can,

460
00:29:13,320 --> 00:29:16,720
I could never see a Sarraj doing an ain't
drink style video where it's just like

461
00:29:16,721 --> 00:29:21,280
you a very plain, you know,
nothing really going on.

462
00:29:21,940 --> 00:29:25,510
Or have you ever considered
taking, you know what? I'm

463
00:29:27,880 --> 00:29:31,780
sorry. Three blue one brown,
is it three? Yeah, three blue
on Brown, you know, taking,

464
00:29:31,900 --> 00:29:35,110
he takes sometimes over a month,
right to do one video.

465
00:29:35,620 --> 00:29:37,240
Have you ever considered doing that?

466
00:29:38,530 --> 00:29:39,341
I've considered it,

467
00:29:39,341 --> 00:29:44,341
but I am a now a slave to the youtube
algorithm and I have a certain subscriber

468
00:29:47,231 --> 00:29:51,520
growth that I wanted to continue and it
would be quite a risk to take some time

469
00:29:52,300 --> 00:29:52,901
away from that.

470
00:29:52,901 --> 00:29:56,860
And other youtubers have faced similar
issues and it's part of the reason why so

471
00:29:56,861 --> 00:30:01,861
many top youtubers are burning out because
the algorithm kind of doesn't allow

472
00:30:01,991 --> 00:30:02,860
you to take a break.

473
00:30:03,010 --> 00:30:07,600
Like either you keep submitting content
at the pace you have or will stop

474
00:30:07,720 --> 00:30:11,080
sending new subscribers
your way. Hmm. Not that,

475
00:30:12,100 --> 00:30:15,880
I mean it's a valid question like,
you know, why not just do that?

476
00:30:15,881 --> 00:30:19,300
But I think I don't want to risk that
is one risk. I don't want to take,

477
00:30:19,600 --> 00:30:23,050
like I'm on a very steady
growth trajectory right now.

478
00:30:23,350 --> 00:30:27,580
The videos work well enough. I want to
improve them at the rate that I am. Yes.

479
00:30:27,581 --> 00:30:32,350
I could slow down, make less and
increase the quality even more.

480
00:30:32,740 --> 00:30:35,830
But I think I'm really going to try
to do both quality and quantity.

481
00:30:36,370 --> 00:30:39,850
You maybe you can split because
I actually don't know this stuff

482
00:30:41,260 --> 00:30:45,610
at all. Uh, some of it just seems
like a, what does it, alchemy, yeah,

483
00:30:45,700 --> 00:30:50,560
the youtube game is so much a part of
my existence, my life, my dopamine,

484
00:30:51,040 --> 00:30:56,040
my reward signals are so attuned
to views and likes and comments.

485
00:30:58,330 --> 00:31:01,960
Interesting that I can't imagine
not doing this. Yeah. You know,

486
00:31:01,990 --> 00:31:05,950
I'm sure after I hit a million, like
I'm going to be like, whew, all right,

487
00:31:05,951 --> 00:31:09,370
time to stop. And then it's like,
what, what else do I do now? But like,

488
00:31:09,610 --> 00:31:12,310
I really am gonna you know,

489
00:31:13,060 --> 00:31:18,060
I'm always going to be
educating storytelling about
AI and data and technology

490
00:31:19,300 --> 00:31:22,550
is just like, what is the next
medium after youtube? I don't know.

491
00:31:23,200 --> 00:31:27,610
Like you said Netflix or
something like Netflix would
be sick. Yeah. Yeah. Netflix,

492
00:31:27,611 --> 00:31:31,100
if you're watching, you know, with,
you know who it is right here. Uh,

493
00:31:31,150 --> 00:31:35,110
do you think you could walk away
from Youtube for, uh, six months?

494
00:31:37,580 --> 00:31:40,460
Uh, I wonder ultimately for your
happiness, for your wellbeing,

495
00:31:40,461 --> 00:31:44,060
for your success as an
educator and sort of,

496
00:31:44,061 --> 00:31:48,710
I'm a person that's putting
a AI into the stratosphere,

497
00:31:48,711 --> 00:31:51,950
trying to make a famous,
what's the best move?

498
00:31:52,130 --> 00:31:56,570
What do you think is the best move
was the 2018 is about rap videos.

499
00:31:57,200 --> 00:32:01,760
So this year is like focus on youtube
into almost entirely and like,

500
00:32:01,820 --> 00:32:04,760
you know, trying to figure out the, the,

501
00:32:04,761 --> 00:32:09,761
the not just not focusing on youtube as
a medium of distribution but in general

502
00:32:09,891 --> 00:32:14,891
focus on increasing the academic rigor
of my content as well to you know,

503
00:32:15,200 --> 00:32:16,670
trying to develop this university.

504
00:32:17,780 --> 00:32:18,120
Yeah.

505
00:32:18,120 --> 00:32:20,430
Focus afterwards is um,

506
00:32:22,450 --> 00:32:26,350
try to get, yeah, like a Netflix
show I think would be ideal.

507
00:32:27,870 --> 00:32:31,920
Let's talk some specifics. Uh, who's the
target audience? The youtube channel.

508
00:32:32,190 --> 00:32:37,190
So it could be a young people who
don't have any programming or a machine

509
00:32:38,071 --> 00:32:41,240
learning experience could be programmers
who just don't have any machine

510
00:32:41,241 --> 00:32:41,991
learning experience.

511
00:32:41,991 --> 00:32:46,750
It could be research sceneries
or as a deep mind open Ai.

512
00:32:46,770 --> 00:32:49,700
So people who are like actively
publishing in Europe and so on.

513
00:32:50,120 --> 00:32:52,340
Who Do you have in mind when
you're making the videos?

514
00:32:52,390 --> 00:32:53,530
So that keeps evolving.

515
00:32:53,950 --> 00:32:58,120
When I started it was like I wanted the
developer market of which there were at

516
00:32:58,121 --> 00:33:00,830
the time, three years ago,
10 million developers. So,

517
00:33:00,831 --> 00:33:03,880
and most of them are
concentrated on get hub, right.

518
00:33:04,510 --> 00:33:08,920
So and now get hub has a 29
million registered accounts.

519
00:33:09,320 --> 00:33:12,390
So it's grown a lot. But at the
time before I started out, you know,

520
00:33:12,410 --> 00:33:17,400
I had a shroom trip to admit that publicly
where I was like crying my eyes out.

521
00:33:17,401 --> 00:33:19,890
I was with some random Tinder date and
I just had this revelation like looking

522
00:33:19,891 --> 00:33:22,320
up at the sky. She was like, I
was like, I've got to do this.

523
00:33:22,860 --> 00:33:25,400
No one else is going to do
this as I've got to do this.

524
00:33:25,401 --> 00:33:28,590
Cause trims kind of give you this
ancient truth. We can talk about that.

525
00:33:28,650 --> 00:33:31,800
I'm read this book by Michael Pollan
on psychedelics. Really Great Book,

526
00:33:32,070 --> 00:33:34,710
author of Omnivore's dilemma.
To get back to this though,

527
00:33:34,980 --> 00:33:37,950
so the goal when I started the youtube
channel was to win the hearts and minds

528
00:33:37,951 --> 00:33:41,250
of developers everywhere. Yeah. And I've
learned a bit of that game at Tulio,

529
00:33:41,251 --> 00:33:43,830
which was my last job because
I was a developer educator.

530
00:33:43,920 --> 00:33:46,350
So I learned that you know how to do this.

531
00:33:47,070 --> 00:33:52,070
So I kind of applied that at scale and
I feel like I did that more or less,

532
00:33:53,341 --> 00:33:56,640
maybe two years in,
I kinda of Sorta to saturate that market.

533
00:33:57,030 --> 00:33:58,620
Obviously I don't have
10 million subscribers,

534
00:33:58,621 --> 00:34:02,640
but I saturated the market of developers
who are also interested in video

535
00:34:02,641 --> 00:34:06,780
content and are also interested in me.
So that, and so that's when I was like,

536
00:34:06,781 --> 00:34:10,500
okay, now I'm not just
developers, but people, um,

537
00:34:10,770 --> 00:34:15,750
develop not just developers who, AI
developers or like programming developers,

538
00:34:15,751 --> 00:34:20,730
but like other types of engineers.
So people generally in stem,

539
00:34:20,880 --> 00:34:25,170
science, technology, engineering,
mathematics. Now I feel like,

540
00:34:25,200 --> 00:34:28,740
and especially having lived in La for
now four months and like kind of seeing

541
00:34:28,741 --> 00:34:31,500
what the scene is like outside
of the Silicon Valley bubble.

542
00:34:31,840 --> 00:34:35,490
It's like people who don't code
at all and don't care. So, but,

543
00:34:35,491 --> 00:34:38,310
but they are interested in technology.

544
00:34:38,311 --> 00:34:42,690
They have some interest in
technology broadly. That's my,

545
00:34:42,930 --> 00:34:45,500
that's what my target audiences, you
know, those are the kind of things,

546
00:34:45,530 --> 00:34:48,020
but listen to podcasts actually,
you know,

547
00:34:48,800 --> 00:34:51,740
it's like there's just curious
about ideas. They don't want to.

548
00:34:52,190 --> 00:34:57,020
So probably no math or no, actually you
know people love number file, right?

549
00:34:57,260 --> 00:34:57,800
Yeah,

550
00:34:57,800 --> 00:35:02,800
and I'm pretty sure a very
large percentage of them
don't understand most of

551
00:35:03,201 --> 00:35:07,340
what's being talked about. Yeah. Like
at a, at a core mathematical level,

552
00:35:07,341 --> 00:35:10,400
but what they're enjoying is the,

553
00:35:11,280 --> 00:35:15,590
the seeming beauty of how
everything just fits together. Yeah.

554
00:35:15,600 --> 00:35:17,480
Being explained and they just enjoy that.

555
00:35:17,481 --> 00:35:21,380
That there is a law structure
to the universe. What does that,

556
00:35:21,381 --> 00:35:23,690
do you have an understanding why
people are into a number of file?

557
00:35:24,300 --> 00:35:27,120
I do have an understanding.
It's not what you would think.

558
00:35:27,420 --> 00:35:31,050
I do have an understanding of very data
driven understanding as a creator who

559
00:35:31,051 --> 00:35:34,050
looks at my analytics and looks
at my audiences demographics.

560
00:35:34,590 --> 00:35:36,810
A lot of people want an
Avatar that looks like them.

561
00:35:37,140 --> 00:35:41,040
A lot of people are like the sound of
a person and how it makes them feel.

562
00:35:41,310 --> 00:35:45,660
It's not even about the
content, it's about, it's about
the intonation, it's about

563
00:35:47,260 --> 00:35:49,780
the medium that they're using.

564
00:35:49,781 --> 00:35:53,830
Like sometimes just having a pen and
paper while not as efficient as say some

565
00:35:53,831 --> 00:35:57,130
online tool. Sometimes just like seeing
that and seeing the market board.

566
00:35:57,131 --> 00:35:57,910
That's enough for them.

567
00:35:57,910 --> 00:36:00,650
So Daniel Shiffman is one example
of a creator who does as well.

568
00:36:00,651 --> 00:36:03,250
A friend of mine, the coding
train on Youtube, great channel.

569
00:36:04,330 --> 00:36:08,380
But other than like those things he does,

570
00:36:08,800 --> 00:36:12,970
he's a really good storyteller or they
are really, really good storytellers.

571
00:36:13,330 --> 00:36:14,680
And that's what it comes down to.

572
00:36:14,681 --> 00:36:18,950
Like grant three blue one brown is a
coherent story from start to finish. No,

573
00:36:18,980 --> 00:36:21,880
no matter how long the content is,
it has a start,

574
00:36:21,881 --> 00:36:26,140
middle and end and people like that that
the sequential aspect of that as you've

575
00:36:26,141 --> 00:36:30,430
all Noah Harari said in his book as
you've probably read, we are storytellers.

576
00:36:30,431 --> 00:36:34,150
We think we imagined we dream,
we remember in stories.

577
00:36:34,510 --> 00:36:36,850
So as long as we can
wrap math into a story,

578
00:36:37,450 --> 00:36:39,490
we can get more people interested in it.

579
00:36:39,610 --> 00:36:42,220
And in terms of like getting to this
audience who doesn't care about code,

580
00:36:42,490 --> 00:36:44,050
I'm never going to stop
talking about math.

581
00:36:44,170 --> 00:36:46,990
Math is the value that I bring to society.

582
00:36:47,170 --> 00:36:51,190
I know that from a data driven approach,
right? As long as math is prevalent.

583
00:36:51,191 --> 00:36:53,260
Cause that's the thing that I
can bring that not everybody,

584
00:36:53,960 --> 00:36:56,050
not every rapper in
whatever can bring math.

585
00:36:56,350 --> 00:37:00,010
I can talk about math and I can make
it cool. So it's going to be math,

586
00:37:00,011 --> 00:37:02,680
like don't work with Dick
Talks about chess, right?

587
00:37:03,450 --> 00:37:07,260
Yeah, exactly. I think it will take
me in chess. Popular. They did.

588
00:37:07,320 --> 00:37:11,950
I'm sure it's a math and AI in technically
I was gonna stick with you for a

589
00:37:12,010 --> 00:37:12,843
while.

590
00:37:12,880 --> 00:37:15,610
Yeah, absolutely.
Absolutely. And to be honest,

591
00:37:15,611 --> 00:37:20,611
I'm feeling disillusioned
with differentiable blocks
as the future and SGD like

592
00:37:20,971 --> 00:37:25,250
stochastic gradient descent as the future
of Ai. But I'm sure a lot of people do.

593
00:37:25,580 --> 00:37:27,380
Yeah. You know, it's, it's amazing.

594
00:37:27,381 --> 00:37:29,870
And obviously it's doing
a much of amazing things,

595
00:37:30,620 --> 00:37:34,790
but it's not the future of Agi. So,
but for now I'm sticking with that.

596
00:37:34,940 --> 00:37:35,990
You're going to have like angry,

597
00:37:35,991 --> 00:37:40,991
frustrated reps about the state
of a neural networks today.

598
00:37:42,100 --> 00:37:46,290
It's almost like a, so like Tupac rapping
about like the problems, you know,

599
00:37:46,340 --> 00:37:51,050
racial problems in society.
You'd be rapping like a Jeff Hinton,

600
00:37:51,140 --> 00:37:53,160
the backpropagation.
Okay.

601
00:37:53,500 --> 00:37:55,110
That'd be sick. That's a great idea. See,

602
00:37:55,111 --> 00:37:59,250
I'm not the only one who's going to be
a ramper about Ai. Exactly. Yeah. Yeah.

603
00:37:59,520 --> 00:38:02,700
Quoting, hinting at the beginning
and then like dropping a beat.

604
00:38:05,230 --> 00:38:10,000
Well, if you need any guitar tracks,
uh, I'd love that lamb down. Okay.

605
00:38:10,001 --> 00:38:14,950
So, uh, how's your process of creating
two videos changed over the years?

606
00:38:14,951 --> 00:38:19,600
What's that process like? I think it's
fascinating for a lot of people who, uh,

607
00:38:19,630 --> 00:38:20,710
who are educators.

608
00:38:21,160 --> 00:38:25,690
I know that a lot of people are
quite terrible and making videos. Uh,

609
00:38:25,691 --> 00:38:30,310
and uh, you're quite good and, and
the, the whole production of it.

610
00:38:30,311 --> 00:38:32,380
So what's that process been like?

611
00:38:32,410 --> 00:38:36,130
What's it converged to and what advice
do you have on how to do it well,

612
00:38:37,190 --> 00:38:42,110
so I no longer do it all myself.
I have a team now. Awesome. Yeah.

613
00:38:42,111 --> 00:38:47,111
I haven't edited her and an animator
who help and so I'll kind of lay out the

614
00:38:48,260 --> 00:38:53,090
idea, the story, the
concepts. I'll write it.

615
00:38:53,180 --> 00:38:56,750
I write every word like I'm never
going to have someone write for me.

616
00:38:57,080 --> 00:38:59,120
To me that's the most disingenuous,

617
00:38:59,121 --> 00:39:03,710
dishonest thing you could do is to have
someone else write the words that you

618
00:39:03,711 --> 00:39:07,850
speak. Not to call anybody
in particular, but,

619
00:39:08,930 --> 00:39:12,660
but so, so I'll, I'll write it, I'll
write the script and then there,

620
00:39:12,770 --> 00:39:16,580
and then I'll also tell them like what
the animation should look like and what

621
00:39:16,581 --> 00:39:20,930
the assets are going to be.
I'll also make the memes, um,

622
00:39:20,960 --> 00:39:24,890
but the editor will kind of stitch things
together and the animator will at the

623
00:39:24,891 --> 00:39:26,480
animations.
How do you,

624
00:39:27,170 --> 00:39:28,160
the editor,

625
00:39:28,520 --> 00:39:32,420
how do you put your vision
into their head and share that?

626
00:39:32,421 --> 00:39:35,150
Is that part of the sacrifice of the
collaboration that you talk about?

627
00:39:35,240 --> 00:39:37,970
Yeah. Yeah. So when I first started,

628
00:39:37,971 --> 00:39:42,530
there were certain little things that I
could do because I was editing them that

629
00:39:42,560 --> 00:39:46,580
and because my turnaround is so fast
as well, that I could just do, um,

630
00:39:46,610 --> 00:39:48,530
and my editor could do that as well.

631
00:39:48,531 --> 00:39:51,830
It's just the turnaround is so fast that,

632
00:39:51,890 --> 00:39:55,820
but he's getting better and we've worked
together for maybe eight months now and

633
00:39:55,821 --> 00:39:59,720
he's reliable and he's getting
better. So, but yeah, like you know,

634
00:39:59,721 --> 00:40:01,520
when it comes to like
take this equation's,

635
00:40:01,521 --> 00:40:03,770
split it up and like take these variables.

636
00:40:03,771 --> 00:40:05,570
Obviously you need some
domain knowledge there.

637
00:40:06,590 --> 00:40:11,590
So you just got to find a really great
editor and turn them into a unicorn

638
00:40:13,490 --> 00:40:16,310
by giving them a domain
knowledge through experience. Uh,

639
00:40:16,311 --> 00:40:17,570
what's it mean to be a unicorn?

640
00:40:17,780 --> 00:40:20,840
A Unicorn isn't a person who's
really good at editing and AI.

641
00:40:21,770 --> 00:40:26,330
Oh, I see. So you're almost
educating them. Yeah. And the, wow.

642
00:40:26,980 --> 00:40:30,020
So you're growing all together. Is
this in person or remote? Remote.

643
00:40:30,950 --> 00:40:32,780
He can do a remote too.
Yeah.

644
00:40:33,920 --> 00:40:38,450
What's the hardest part of the whole
process for you from start to finish?

645
00:40:38,451 --> 00:40:42,290
Is it the idea stage? The
writing. The script is shooting,

646
00:40:43,880 --> 00:40:46,850
like standing in front
of a camera and saying,

647
00:40:47,610 --> 00:40:49,010
do you have to ramp up for it?

648
00:40:49,240 --> 00:40:53,310
We've got to ramp up. You got to turn,
turn my swag on, turn the energy level.

649
00:40:53,360 --> 00:40:57,200
Is that a lot of energy in those videos?
So what, uh, what's that process like?

650
00:40:57,201 --> 00:40:58,490
How many takes you,
you know,

651
00:40:58,491 --> 00:41:02,450
I want you to videos some youtube
recently made me feel a lot better.

652
00:41:03,080 --> 00:41:08,070
Actually, because sometimes I'll do like,
like even for an Intro, like for uh,

653
00:41:08,270 --> 00:41:12,590
for this conversation, I'll do an intro
for like a minute about you. Right, right.

654
00:41:13,100 --> 00:41:15,120
And I'll probably do three takes of it.
Yeah.

655
00:41:15,320 --> 00:41:18,920
And I used to feel bad about that
cause I, I screwed up, you know,

656
00:41:19,700 --> 00:41:24,700
but I saw some youtube would do like
40 takes of like a three minute video,

657
00:41:25,250 --> 00:41:26,690
like some crazy number.

658
00:41:27,050 --> 00:41:31,460
Do you find yourself doing having to do
a lot of takes because you have really

659
00:41:31,461 --> 00:41:35,900
complex material, like give a lot
of different storylines flowing?

660
00:41:36,200 --> 00:41:36,630
Yeah,

661
00:41:36,630 --> 00:41:39,340
I do. I do. I do several
takes for sure. Uh,

662
00:41:39,390 --> 00:41:42,750
it's rare that I can do it all in
one take. Usually like, you know,

663
00:41:42,751 --> 00:41:47,751
maybe somewhere to 30 seconds to two
minutes and I'll mess up and they'll have

664
00:41:47,821 --> 00:41:51,390
to restart from that point.
And Yeah.

665
00:41:51,460 --> 00:41:55,180
Yeah. Just you use a use a teleprompter
or do you use, do you remember?

666
00:41:55,181 --> 00:41:59,770
I use a teleprompter. Yeah. Just getting
into like Stephen King details here.

667
00:41:59,771 --> 00:42:00,850
How do you write out a script?

668
00:42:00,860 --> 00:42:05,760
You just take like a
loose notes or do you go

669
00:42:06,000 --> 00:42:10,220
by word word by word?
So it's kind of an essay.

670
00:42:10,890 --> 00:42:13,950
It's an essay. I'm writing essays
every week, like three essays.

671
00:42:13,980 --> 00:42:16,590
If I were to take all my
scripts that I made up till now,

672
00:42:16,810 --> 00:42:20,010
they would be like five books
worth of Innosight. Yeah. As books.

673
00:42:20,130 --> 00:42:21,330
Do you remember a time when

674
00:42:21,850 --> 00:42:23,680
you took way too long in a video?

675
00:42:23,681 --> 00:42:27,790
Like it was way harder than
you thought you anticipated?

676
00:42:28,680 --> 00:42:30,340
And do you remember what
that video might be?

677
00:42:31,560 --> 00:42:36,260
Huh? Neuro ordinary differential
equations. The nips paper.

678
00:42:36,261 --> 00:42:37,094
The neuro,
sorry.

679
00:42:37,160 --> 00:42:41,480
No rips paper that a cause that

680
00:42:43,410 --> 00:42:48,280
the actual optimization step with the
three integrals, I still didn't know

681
00:42:48,360 --> 00:42:51,720
fully get it. That's a good question.
Actually. When you do a video,

682
00:42:53,020 --> 00:42:57,270
especially some of the trickier
concepts, do you, I mean,

683
00:42:57,280 --> 00:43:01,050
they're difficult to fully get,
even if you teach a course,

684
00:43:01,051 --> 00:43:03,510
even if teach of course,
multiple times on a topic,

685
00:43:04,020 --> 00:43:08,700
you learn something new every
time you find yourself. I mean,

686
00:43:08,720 --> 00:43:12,600
Jewish degree, do you try to fully get a
topic before you're doing a video on it?

687
00:43:13,850 --> 00:43:15,560
How much do I know it when I say it?

688
00:43:15,710 --> 00:43:19,070
I've really gotten better at
this over the years. Like so, um,

689
00:43:19,100 --> 00:43:23,120
I remember like the first year there was
one video. What was deep mines thing?

690
00:43:23,121 --> 00:43:28,080
It was like the DNC, the differential
neural computer. Honestly, I've,

691
00:43:28,100 --> 00:43:32,330
I felt like I knew 50% of that
when I made that video like that.

692
00:43:32,390 --> 00:43:35,110
That was crazy. I don't know if you ever
looked into this architecture. Yeah.

693
00:43:35,480 --> 00:43:38,540
Now I like at least 90,

694
00:43:39,260 --> 00:43:41,540
90% understand it.

695
00:43:42,000 --> 00:43:46,530
Do you uh, have a goal when you add
memes or humor? Keep People's attention?

696
00:43:48,000 --> 00:43:48,360
You know what,

697
00:43:48,360 --> 00:43:51,210
one of the interesting things
you mentioned and maybe
you can dig into a little

698
00:43:51,211 --> 00:43:55,350
bit. You have like a, an analog, like
a data analytics view of this thing.

699
00:43:56,460 --> 00:44:00,660
I do. So like audience retention.
Yeah. So Do, I'm sure you have like a,

700
00:44:00,990 --> 00:44:05,990
almost like a sixth sense now of what
things get an audience to keep their eyes

701
00:44:06,961 --> 00:44:10,800
on, on. Of course you probably always
learning and nobody really knows.

702
00:44:11,190 --> 00:44:11,980
Like how do you mean

703
00:44:11,980 --> 00:44:14,500
no,
what worked and what didn't.

704
00:44:15,760 --> 00:44:18,730
If I retention drops at a certain point,

705
00:44:19,390 --> 00:44:23,560
whatever I said or showed or displayed,
they're not good. If it increased,

706
00:44:23,860 --> 00:44:27,370
that's good. That's good. And you start
to build it up and you can monitor that.

707
00:44:27,490 --> 00:44:29,360
Yeah.
So what kind of things

708
00:44:29,360 --> 00:44:32,280
have you learned? If you
can, if you can simplify

709
00:44:32,280 --> 00:44:35,820
into words, what are people, um,

710
00:44:37,290 --> 00:44:40,640
I mean you already mentioned like certain
ways of talking that people just find

711
00:44:40,660 --> 00:44:44,430
appealing. This is the type of video
where people like whisper into the mic,

712
00:44:44,820 --> 00:44:48,840
I need to look contagious tomorrow. Yes,
I'm on. Great. What the heck is that?

713
00:44:49,250 --> 00:44:52,920
It creeped me out. Gen Z loves
this younger than me. Yeah.

714
00:44:52,921 --> 00:44:57,120
It's just like a relaxing, you know,
it's like one form of this, you know,

715
00:44:57,121 --> 00:44:59,730
different types of love and
affection that we all need.

716
00:44:59,731 --> 00:45:03,180
This is like more of the intimacy.
It fulfills a need,

717
00:45:03,270 --> 00:45:06,060
a very human need of like
being close with someone.

718
00:45:06,450 --> 00:45:10,830
Obviously with Vr we can increase that,
but it's one step of wow, I've never,

719
00:45:10,860 --> 00:45:15,750
so I've looked into it for just like a
few minutes and never as a really nice

720
00:45:15,810 --> 00:45:19,650
explanation of it. That makes so
much sense. The whispering brings us,

721
00:45:19,651 --> 00:45:23,520
it does a feeling of closeness to it
even more so than just listening to the

722
00:45:23,521 --> 00:45:27,870
person directly as powerful. So you get,
so stuff like that, what have you learned?

723
00:45:28,200 --> 00:45:33,060
What people connect and they want
to keep watching relevancy matters.

724
00:45:33,120 --> 00:45:38,070
So you want your jokes should matter.
Your meme should be relevant. Your

725
00:45:40,250 --> 00:45:42,450
you got to stay with the Times
you gotta be in pop culture.

726
00:45:42,451 --> 00:45:47,451
You gotta be watching Pewdie Pie and
bunch of other popular creators and know

727
00:45:47,461 --> 00:45:52,290
where the pulse is in terms of pop
culture and be able to relate AI to it.

728
00:45:53,310 --> 00:45:55,050
And so that's a fulltime job.

729
00:45:57,190 --> 00:46:02,010
How hard is it creating the memes? You
know, it comes, it becomes second nature.

730
00:46:02,011 --> 00:46:05,610
Now that I make them, I used to just
Google them and like find relevant,

731
00:46:05,611 --> 00:46:07,110
like Lstm meme,
find one.

732
00:46:07,140 --> 00:46:11,710
Now I actually write them myself and
so there I have more control. Yeah,

733
00:46:11,711 --> 00:46:14,490
she's better and they're
funnier as well. Yeah, I and I,

734
00:46:14,491 --> 00:46:19,491
and you can't use 2018 memes like memes
or are changing now the Pekichu meme is

735
00:46:19,801 --> 00:46:21,480
in,
but like watch it go out next month.

736
00:46:21,720 --> 00:46:24,160
It's like things I care about
that nobody knows. But like I'm,

737
00:46:24,330 --> 00:46:29,040
I'm really into mammalogy and
like you and Ilan Musk, so you're,

738
00:46:29,160 --> 00:46:31,920
yeah. Yeah. Apparently he's into it.

739
00:46:32,580 --> 00:46:35,540
Have you noticed changes
in the Youtube in um,

740
00:46:35,670 --> 00:46:39,390
in youtube was a medium since he started.
He said,

741
00:46:39,870 --> 00:46:41,130
we get you a month by month.

742
00:46:41,430 --> 00:46:46,140
I mean a lot is changing right
from Manas monetization to uh,

743
00:46:46,470 --> 00:46:49,290
just the number of people that are
producing content to the algorithm behind

744
00:46:49,291 --> 00:46:52,860
youtube.
The have you actually,

745
00:46:52,861 --> 00:46:54,630
because you have your finger to the pulse,

746
00:46:54,660 --> 00:46:59,440
have you noticed substantive
changes they can speak to? Uh,

747
00:46:59,460 --> 00:47:02,880
definitely not enough creator
support. Definitely. I mean,

748
00:47:02,881 --> 00:47:04,380
I could complain about Youtube all day,

749
00:47:04,970 --> 00:47:08,550
so it's mostly complaints is mostly
not been in the positive direction.

750
00:47:08,551 --> 00:47:12,770
He would say no, I love Youtube because
they've given me a platform I could,

751
00:47:12,800 --> 00:47:14,190
I wouldn't be,
you know,

752
00:47:14,191 --> 00:47:17,040
I wouldn't have the influence that I
do be able to reach to many people.

753
00:47:17,050 --> 00:47:20,580
I do as I do without youtube. So I
deeply appreciate youtube. In fact,

754
00:47:20,581 --> 00:47:23,790
I'm going to, I'm a contractor,
like I get youtube ad revenue.

755
00:47:23,820 --> 00:47:27,780
I met in a way I worked for youtube,
so they're great.

756
00:47:27,870 --> 00:47:29,710
However they could be better.

757
00:47:30,010 --> 00:47:33,280
And I've seen that happen to other
creators and everybody has their list of

758
00:47:33,281 --> 00:47:35,020
complaints.
For me specifically,

759
00:47:35,021 --> 00:47:40,021
one that I would say is
like better resources for
educators and they're working

760
00:47:40,451 --> 00:47:45,400
on, and I know, but it could be better.
Are they transparent with the algorithm,

761
00:47:46,190 --> 00:47:48,850
you know? No. Do you think they should be?

762
00:47:51,070 --> 00:47:54,400
Wow. I think they should
be, but it wouldn't.

763
00:47:54,820 --> 00:47:57,310
They couldn't be because it
would break their business model.

764
00:47:57,311 --> 00:48:01,630
They need a new business model
that wasn't entirely ad based. Uh,

765
00:48:01,660 --> 00:48:04,120
so people will start to try
to manipulate it. Exactly.

766
00:48:04,630 --> 00:48:08,050
So somebody who was starting a youtube
channel now with zero subscribers,

767
00:48:08,290 --> 00:48:10,660
you have close to 600,000.

768
00:48:11,500 --> 00:48:14,720
You're trying to do a million by the
end of the year. He has dual. So I know,

769
00:48:14,830 --> 00:48:18,130
you know, I I, I think 800 k's doable.

770
00:48:18,460 --> 00:48:22,960
But by February or March for sure.
March for sure of next year.

771
00:48:23,320 --> 00:48:27,130
1 million. 1 million. Yeah. Do
people know you're aiming for this?

772
00:48:27,970 --> 00:48:32,500
I think some people do. I don't really
try to talk about it too much. I mean,

773
00:48:32,501 --> 00:48:36,670
people love that kind of cause they
love to help that, right? Yeah. It's,

774
00:48:36,830 --> 00:48:39,280
it's cool to have goals
like that. I think, uh,

775
00:48:39,880 --> 00:48:42,820
people love to help you
strive for that kind of thing.

776
00:48:42,820 --> 00:48:47,470
1 million is a really cool number,
especially for an AI channel. So yeah. Uh,

777
00:48:47,710 --> 00:48:51,280
I think I'm one of the
subscribers, so thank you. I'm
a subscriber to you as well.

778
00:48:51,310 --> 00:48:53,470
Awesome. So you, uh,

779
00:48:53,500 --> 00:48:55,810
so what advice would you give to
somebody just starting out today?

780
00:48:55,840 --> 00:49:00,130
Zero zero subscribers or
maybe advice to yourself.

781
00:49:00,160 --> 00:49:04,000
You're starting out then icology, do it.
What kind of content would you create?

782
00:49:05,140 --> 00:49:08,800
What have you learned if you
time traveled to the beginning?

783
00:49:09,430 --> 00:49:12,010
Just try out different types of videos,
like trial,

784
00:49:12,011 --> 00:49:16,000
just to craziest most random ideas,
as many as you can,

785
00:49:16,030 --> 00:49:19,570
and then look at the data and
reiterate with what works,

786
00:49:20,170 --> 00:49:25,170
what a topic in deep learning or AI do
you see is at least in the beginning,

787
00:49:25,331 --> 00:49:27,180
you've connected with beginners a lot.
What,

788
00:49:27,320 --> 00:49:30,990
what topic do they struggle with
the most? Like, what's the thing,

789
00:49:30,991 --> 00:49:34,060
what's the entry point that
people struggle with and
how do you recommend they

790
00:49:34,061 --> 00:49:37,990
overcome it? Well, it
always tends to be the math.

791
00:49:38,560 --> 00:49:43,120
So usually anything having to
do with either linear Algebra,

792
00:49:43,690 --> 00:49:47,290
calculus,
probability theory or statistics,

793
00:49:47,291 --> 00:49:49,870
the four pillars of deep learning,

794
00:49:51,610 --> 00:49:53,230
those are the four.
So how would you,

795
00:49:53,231 --> 00:49:57,820
what would you recommend they
do to overcome? At this point,

796
00:49:57,880 --> 00:50:02,880
there exists free content from many
resources on the web for all of these

797
00:50:03,401 --> 00:50:06,880
things. It doesn't exist together
as a cohesive curriculum,

798
00:50:07,060 --> 00:50:08,530
like basically everything you need.

799
00:50:08,740 --> 00:50:12,490
But it does exist across different
courses on different platforms.

800
00:50:13,630 --> 00:50:18,630
And so what I've done is I've created
like medic curriculums on get hub that I

801
00:50:18,641 --> 00:50:19,510
promote with youtube.

802
00:50:19,840 --> 00:50:23,260
And then they like curriculums consisting
of different courses which other

803
00:50:23,261 --> 00:50:24,160
people have done as well.

804
00:50:24,430 --> 00:50:28,550
And so that's kind of acting as a
pathway for people without a path.

805
00:50:28,790 --> 00:50:32,720
So I can provide path as a service
learning path as a service.

806
00:50:34,190 --> 00:50:37,400
Well, we'll put what a
topic, if you can look back,

807
00:50:37,401 --> 00:50:42,401
was the hardest for you to put together
a video about [inaudible] technically

808
00:50:42,651 --> 00:50:45,830
for you. I mean, you mentioned
you, you mentioned some,

809
00:50:45,831 --> 00:50:48,320
but sort of something that

810
00:50:50,780 --> 00:50:55,780
you get to learn a lot for or maybe you
grew a lot from in doing quantum machine

811
00:50:59,181 --> 00:51:04,100
learning. I hadn't seen that one from
you. Cool. Yeah, I did it with d wave.

812
00:51:05,360 --> 00:51:07,880
That was pretty, uh, interesting.

813
00:51:07,881 --> 00:51:11,420
Started me down the rabbit hole of
quantum mechanics and I still don't

814
00:51:11,421 --> 00:51:14,180
understand it. There's a whole
movement of a, I know that MIT,

815
00:51:14,190 --> 00:51:18,110
this quantum machine learning people, I
still, I don't, I don't know anything.

816
00:51:18,111 --> 00:51:19,850
So I do know about quantum mechanics.

817
00:51:19,851 --> 00:51:24,740
I don't know nothing about quantum
computing or quantum machine hunting.

818
00:51:24,741 --> 00:51:29,240
Certainly don't, is that, is
that something you're excited
about? What's, you know,

819
00:51:29,241 --> 00:51:32,480
quantum computing in general?
Is that something you're
excited about? Absolutely.

820
00:51:32,720 --> 00:51:34,130
Absolutely.
There's,

821
00:51:34,280 --> 00:51:37,670
there's a lot of promising research
happening right now at MIT and other

822
00:51:37,671 --> 00:51:42,671
institutions specifically for speeding
up a matrix matrix multiplications on

823
00:51:43,371 --> 00:51:46,150
quantum resistors. What
you, I guess you would,

824
00:51:46,280 --> 00:51:49,780
you call him cubits. Yep. But, um,

825
00:51:50,330 --> 00:51:52,790
that's really cool
because if we can do that,

826
00:51:53,160 --> 00:51:57,910
I don't even need gps anymore.

827
00:51:59,030 --> 00:52:02,900
But variational auto encoder sends me
very popular with the quantum community.

828
00:52:03,440 --> 00:52:08,420
And simulated annealing, but there
needs to be more problems that are,

829
00:52:08,480 --> 00:52:11,270
it's applied to, but graph problems
basically like in graph theory,

830
00:52:11,271 --> 00:52:15,080
traffic optimization, traffic traffic,
like optimization is one that, you know,

831
00:52:15,081 --> 00:52:16,640
they did with Volkswagen.

832
00:52:16,990 --> 00:52:20,120
So Volkswagen actually paid
them for this and it worked.

833
00:52:22,340 --> 00:52:24,350
But interesting.
So there's actual applications that,

834
00:52:24,351 --> 00:52:29,160
is that a real world applications of this.
See what topic in AI with top,

835
00:52:29,170 --> 00:52:31,250
again,
computing is most exciting to you today.

836
00:52:33,830 --> 00:52:37,070
I really liked the idea of
AI applied to healthcare,

837
00:52:37,220 --> 00:52:39,740
specifically genetic enhancement.
Hmm.

838
00:52:40,010 --> 00:52:45,010
And brain enhancement and thinking
and taking the idea of Alphago,

839
00:52:45,410 --> 00:52:50,410
of thinking in an alien way and combining
that with human intelligence to create

840
00:52:51,531 --> 00:52:53,900
an intelligence that is greater
than the sum of its parts.

841
00:52:54,080 --> 00:52:55,370
What do you mean alien way?

842
00:52:55,371 --> 00:52:58,830
So outside of the capabilities
of the human brain kind of. Yeah.

843
00:52:59,960 --> 00:53:04,960
So like move 37 the move that
shock least Sudo in that it was,

844
00:53:05,391 --> 00:53:08,630
it seemed like a bad move at first, but
it turned out to be a better move. Right.

845
00:53:08,631 --> 00:53:13,631
And so this went against the grain of
2000 plus years of human theory and to go,

846
00:53:14,090 --> 00:53:15,890
you know, what, what, what
moves should be played.

847
00:53:15,891 --> 00:53:18,290
So this was an alien way of
thinking that was not only alien,

848
00:53:18,320 --> 00:53:22,850
it was alien and better. Right? So those
two together is a unique benefit of AI.

849
00:53:22,851 --> 00:53:27,420
So when we combine that, what does
the AI deep, what does the AI,

850
00:53:27,421 --> 00:53:29,400
human deep blue moment,
what does that look like?

851
00:53:29,580 --> 00:53:33,330
And I think it's going to be in
something related to healthcare,

852
00:53:33,360 --> 00:53:36,400
probably drug discovery in the next
five years. If I were to make a bet,

853
00:53:37,650 --> 00:53:40,290
well that that is one of the things
that where you could really transform

854
00:53:40,291 --> 00:53:42,630
society. That's really interesting
that you thinking about that.

855
00:53:43,790 --> 00:53:47,900
Who in deep learning community do you
look up to sort of this researchers is

856
00:53:47,901 --> 00:53:52,901
somebody that maybe early on inspired
you or continues to inspires you?

857
00:53:53,871 --> 00:53:58,790
I know you mentioned Trask um,
a few other really good bloggers,

858
00:53:59,330 --> 00:54:02,450
but is there somebody a,
the stands out besides those folks?

859
00:54:03,200 --> 00:54:07,820
Yes. Oriol Vin Y'alls. Yeah,
at deep mind. He's so cool.

860
00:54:07,940 --> 00:54:11,110
Neural conversational model.
All of this work in sequence.

861
00:54:11,111 --> 00:54:15,560
The sequence modeling and just Alpha
Star and Alpha fall and basically

862
00:54:15,561 --> 00:54:18,170
everything. Cool. I, you mentioned that

863
00:54:18,290 --> 00:54:21,910
the road by Cormac Mccarthy
is one of your favorite books.

864
00:54:22,690 --> 00:54:27,550
It takes place in a post
apocalyptic America. So a,

865
00:54:27,551 --> 00:54:29,560
if human civilization destroys itself,

866
00:54:29,630 --> 00:54:33,950
do you think AI will be part
of that destruction? Yeah,

867
00:54:33,951 --> 00:54:38,951
but not in the way that it's going
to make decisions for itself and uh,

868
00:54:40,220 --> 00:54:43,880
consciously decide that humans need
to be this steroid and then, you know,

869
00:54:43,881 --> 00:54:44,760
do whatever it takes,

870
00:54:44,761 --> 00:54:49,040
it's going to be in the way that a human
or a group of humans decides to exploit

871
00:54:49,041 --> 00:54:54,041
other humans using AI and
they do something nefarious
that involves some kind of

872
00:54:56,750 --> 00:55:00,740
your biochemical attack or propaganda

873
00:55:00,980 --> 00:55:04,820
as an empowering tool for destruction
that humans are doing anyway.

874
00:55:04,850 --> 00:55:09,740
So empowering the evil that is inside
us humans. Yeah. But are you, uh,

875
00:55:09,770 --> 00:55:13,580
you've taught a bunch of topics and
AI, right? Do you have a concern,

876
00:55:14,270 --> 00:55:18,160
existential threats or any kind of
threats of AI in the near term or the long

877
00:55:18,161 --> 00:55:21,100
term? Is this something you think about?
Is that something that concerns you?

878
00:55:21,101 --> 00:55:24,740
Is it does some percent of
the population general public,

879
00:55:25,370 --> 00:55:28,850
at least the those, you know Sam
Harris, even Ilan mosque and so on.

880
00:55:29,580 --> 00:55:32,910
Yeah. I definitely felt when
I first started like that,

881
00:55:32,940 --> 00:55:36,060
the existential threat was
that AI was too concentrated.

882
00:55:36,330 --> 00:55:40,820
The knowledge of AI was too concentrated
and the best way to get a desperate,

883
00:55:40,821 --> 00:55:44,060
as Elon Musk has said and he
quoted Lord Acton on this,

884
00:55:44,090 --> 00:55:48,530
was to ensure that all of that power is
centralized, so spreading the education,

885
00:55:48,531 --> 00:55:50,840
the knowledge of Ai, that data
to the compute, the algorithms.

886
00:55:51,860 --> 00:55:56,150
That has been my goal so far to prevent
that existential threat in terms of

887
00:55:58,080 --> 00:55:58,561
an AI,

888
00:55:58,561 --> 00:56:02,760
consciously deciding human humanity needs
to be wiped out and then being able to

889
00:56:02,761 --> 00:56:06,210
execute that. I don't feel
it's, I just really don't,

890
00:56:08,910 --> 00:56:11,880
I guess you could say his faith. I have
faith that that's not going to happen.

891
00:56:12,030 --> 00:56:13,380
It's going to be, if
it, if it does happen,

892
00:56:13,381 --> 00:56:17,100
it's going to be because of humans and
then we decide to do something. Right.

893
00:56:17,610 --> 00:56:20,730
Yeah. I share your, the
centralized controls, one of the,

894
00:56:21,120 --> 00:56:26,120
we assume as form tribes and those traps
can be destructive in that same way we

895
00:56:26,681 --> 00:56:30,180
need to distribute the
control of Ai Algorithm.

896
00:56:30,181 --> 00:56:35,140
So no one tribe gets to,
uh, is to monopolize it. So,

897
00:56:35,141 --> 00:56:35,974
uh,

898
00:56:38,950 --> 00:56:39,783
what

899
00:56:41,410 --> 00:56:42,790
kind of educator,

900
00:56:42,820 --> 00:56:47,820
artist human being would you like
to grow to be in the next 10 years?

901
00:56:49,030 --> 00:56:50,890
What do you think that
trajectory looks like?

902
00:56:51,190 --> 00:56:55,630
You mentioned focusing on youtube
this year may be something,

903
00:56:56,260 --> 00:56:59,710
who knows what something like
Netflix in the coming years,

904
00:56:59,711 --> 00:57:04,300
but if you look 10 years from now,
what do you see yourself as?

905
00:57:05,590 --> 00:57:09,640
Well, I have some ideas on
that. It's just I'm not,

906
00:57:10,120 --> 00:57:12,730
I don't have the authority,
I'm saying this out loud,

907
00:57:12,760 --> 00:57:14,170
but it's what goes on my head.

908
00:57:14,171 --> 00:57:17,980
I don't yet have the authority to put
that out there into human consciousness,

909
00:57:17,981 --> 00:57:22,690
like a fashion line that uses technology
and learning technologies specifically

910
00:57:22,691 --> 00:57:23,950
to adapt to its user.

911
00:57:25,560 --> 00:57:30,270
A quick a fashion line for engineers by
engineers. Huh? Wow. Yeah, that'd be sick.

912
00:57:30,271 --> 00:57:34,860
Right? So one step at a time here
before I build this media empire.

913
00:57:35,760 --> 00:57:37,740
But it's all about education in the end.
You know,

914
00:57:37,741 --> 00:57:41,970
we're trying to make these
things cool and relevant.

915
00:57:42,030 --> 00:57:44,310
So these are just mediums.
They're all different.

916
00:57:44,610 --> 00:57:48,240
Keys of the piano of there are different
instruments in the orchestra of

917
00:57:48,720 --> 00:57:52,770
education and some of these instruments
haven't been utilized before yet in the

918
00:57:52,771 --> 00:57:55,440
way that they should be.
Like Netflix, like music,

919
00:57:55,470 --> 00:57:59,850
hip hop music specifically and fashion
even can be a tool for education.

920
00:58:00,060 --> 00:58:02,100
Just that relevancy to get
into vogue and you know,

921
00:58:02,101 --> 00:58:05,250
these magazines that puts it into
their head into human consciousness,

922
00:58:05,640 --> 00:58:10,470
but fashion, art, music, fashion,
music after Netflix, fashion line,

923
00:58:10,740 --> 00:58:13,800
uh, maybe an album. And uh,

924
00:58:16,770 --> 00:58:19,710
then I mean obviously like a book as well.

925
00:58:19,770 --> 00:58:22,710
And then just content in
different forms of content,

926
00:58:22,740 --> 00:58:25,650
creating content around storytelling,
around technology

927
00:58:27,390 --> 00:58:28,650
and then maybe even a product.

928
00:58:28,651 --> 00:58:31,080
And if I do a product that's going
to be something related to genetic

929
00:58:31,081 --> 00:58:34,050
enhancement, um, or you know,

930
00:58:34,051 --> 00:58:37,500
maybe some kind of APP for the brain
computer interface that is being developed

931
00:58:37,530 --> 00:58:39,690
by a friend of mine.

932
00:58:40,950 --> 00:58:45,750
Listen, you're one of the most
unique and ambitious people I know,

933
00:58:45,751 --> 00:58:48,650
which is why I wanted to
talk to you today. And, uh,

934
00:58:48,680 --> 00:58:51,350
I think I speak for the
rest of the world that, uh,

935
00:58:51,800 --> 00:58:56,450
except all the haters that, uh, we
can't wait to see what you do next.

936
00:58:56,480 --> 00:58:58,760
Thanks so much for talking
today, man. Thank you Lex.

