WEBVTT
Kind: captions
Language: en

00:00:02.490 --> 00:00:03.860
MALE SPEAKER: Hello, everyone.

00:00:03.860 --> 00:00:05.160
Welcome back.

00:00:05.160 --> 00:00:08.189
We have two more sessions
left today.

00:00:08.189 --> 00:00:11.340
The first one here is
Understanding Your Players

00:00:11.340 --> 00:00:14.760
Using Near Real Time
Game Analytics.

00:00:14.760 --> 00:00:17.170
And this is going to be Michael
Manoochehri from

00:00:17.170 --> 00:00:18.660
Google, that search
company you've

00:00:18.660 --> 00:00:21.340
probably never heard of.

00:00:21.340 --> 00:00:25.720
And then we also have, from
Staq, Luca joining us to talk

00:00:25.720 --> 00:00:29.780
about how they've used Google
BigQuery to build their game

00:00:29.780 --> 00:00:31.215
analytics solution.

00:00:31.215 --> 00:00:32.840
So they're going to be starting
here in just a

00:00:32.840 --> 00:00:36.180
second, but then the last
session that starts at 4:30 is

00:00:36.180 --> 00:00:40.060
going to be How EA Builds Mobile
Game Servers On Google

00:00:40.060 --> 00:00:40.700
App Engine.

00:00:40.700 --> 00:00:43.700
So hope you can all stick around
for both of these, and

00:00:43.700 --> 00:00:44.725
welcome, guys.

00:00:44.725 --> 00:00:46.656
LUCA MARTINETTI: Hello.

00:00:46.656 --> 00:00:48.745
Can you hear me?

00:00:48.745 --> 00:00:49.220
Hi.

00:00:49.220 --> 00:00:50.740
I am Luca Martinetti.

00:00:50.740 --> 00:00:53.200
I'm the CTO of Staq.

00:00:53.200 --> 00:00:59.190
Staq is a brand new startup
that started in TechStars.

00:00:59.190 --> 00:01:00.950
Today, it's a three-man army.

00:01:00.950 --> 00:01:05.710
It's me and these two guys here,
Massimo and Francesco.

00:01:05.710 --> 00:01:06.640
We had a big vision.

00:01:06.640 --> 00:01:09.470
We tried to build a game
management platform, and I'll

00:01:09.470 --> 00:01:12.120
try to explain a little
bit better what we

00:01:12.120 --> 00:01:15.710
believe this means.

00:01:15.710 --> 00:01:19.440
Today, I'll be talking about how
to understand your players

00:01:19.440 --> 00:01:23.340
using analytics, and how to
do that in real time.

00:01:23.340 --> 00:01:28.660
And I have to say thank you,
Google, for having us here.

00:01:28.660 --> 00:01:34.300
That's because we use a big
chunk of their analytics

00:01:34.300 --> 00:01:35.760
offering, BigQuery.

00:01:38.920 --> 00:01:42.140
So you are a game developer,
so you'll probably want to

00:01:42.140 --> 00:01:42.880
build a game.

00:01:42.880 --> 00:01:45.210
You're here to build a game.

00:01:45.210 --> 00:01:48.360
And what I'll say is no.

00:01:48.360 --> 00:01:49.230
No more.

00:01:49.230 --> 00:01:51.220
No more games.

00:01:51.220 --> 00:01:53.650
You're not shipping
boxes anymore.

00:01:53.650 --> 00:01:55.810
The market is so changed.

00:01:55.810 --> 00:01:59.710
What you're actually doing is
you're building a service.

00:01:59.710 --> 00:02:03.720
Building a service
is very different

00:02:03.720 --> 00:02:04.860
from shipping a product.

00:02:04.860 --> 00:02:09.639
It has a complete different set
of challenges and requires

00:02:09.639 --> 00:02:14.995
different state of mind and
different procedures.

00:02:18.370 --> 00:02:22.170
Building a service means that
it's always on 24/7.

00:02:22.170 --> 00:02:26.270
Somebody's always interactive
with your game and generating

00:02:26.270 --> 00:02:28.470
events, generating data.

00:02:28.470 --> 00:02:30.830
At a certain point, if
you're successful--

00:02:30.830 --> 00:02:34.060
and that's a problem you want to
have-- you understand that

00:02:34.060 --> 00:02:38.920
you're sitting on a giant
data fire hose.

00:02:38.920 --> 00:02:41.200
Spoiler--

00:02:41.200 --> 00:02:44.250
in this fire hose, there are so
many interesting things you

00:02:44.250 --> 00:02:48.076
want to learn, you want
to try to grasp.

00:02:48.076 --> 00:02:52.530
In order to do that, we believe
you should set up a

00:02:52.530 --> 00:02:55.820
process made of three steps.

00:02:55.820 --> 00:02:59.870
Measure something, so collect
the data, try to understand

00:02:59.870 --> 00:03:02.550
something you don't know
before, and react.

00:03:02.550 --> 00:03:06.580
React in a way that can make
your game better or your

00:03:06.580 --> 00:03:07.900
monetizaton stream better.

00:03:07.900 --> 00:03:10.246
So actually your life better.

00:03:13.650 --> 00:03:19.410
Yeah, the three guys there are
us, looking at the big screen,

00:03:19.410 --> 00:03:22.470
and this is the flow we want
to enable at Staq.

00:03:22.470 --> 00:03:27.870
So starting from an event that
could be in an upper trace,

00:03:27.870 --> 00:03:32.750
try to understand something new
through analytics and data

00:03:32.750 --> 00:03:36.280
analysis, and then react somehow
with a promotion or

00:03:36.280 --> 00:03:39.900
with a discount, with a game
change, and so on.

00:03:42.860 --> 00:03:48.080
So today, trying to explain a
little bit more in detail how

00:03:48.080 --> 00:03:52.580
to collect data in the right
way, and how important it is

00:03:52.580 --> 00:03:56.870
to have a way of running queries
very efficiently.

00:03:56.870 --> 00:04:00.090
Because these are, at the end,
the two important steps that

00:04:00.090 --> 00:04:03.320
will enable all the rest
of the process.

00:04:03.320 --> 00:04:05.950
So collecting data, what you
want to collect, what you want

00:04:05.950 --> 00:04:07.200
to measure.

00:04:08.950 --> 00:04:09.800
It depends.

00:04:09.800 --> 00:04:10.290
It depends.

00:04:10.290 --> 00:04:11.540
There are so many options.

00:04:14.660 --> 00:04:16.940
Some of those are game-specific,
some are common

00:04:16.940 --> 00:04:18.910
to different kind of games.

00:04:18.910 --> 00:04:21.760
What is important is that you
should try to collect a piece

00:04:21.760 --> 00:04:25.230
of information that happens in
a certain point in time that

00:04:25.230 --> 00:04:25.920
is an event.

00:04:25.920 --> 00:04:29.500
That's the JSON schema
that we use.

00:04:29.500 --> 00:04:34.030
What's happening here is that
at this timestamp, in this

00:04:34.030 --> 00:04:37.940
[INAUDIBLE] game, this was this
warrior that was at level

00:04:37.940 --> 00:04:44.030
seven, and with these two and
a big sword was raging and

00:04:44.030 --> 00:04:47.440
hitting somebody, and
create some damage.

00:04:47.440 --> 00:04:51.920
So this is a typical event you
want to collect from, again.

00:04:51.920 --> 00:04:58.780
And using Staq, you're not
enforced to any specific

00:04:58.780 --> 00:05:04.090
schema, and we'll talk about
that more in detail later.

00:05:04.090 --> 00:05:08.110
So you start collecting these
guys, and you figure out that

00:05:08.110 --> 00:05:09.510
you have tons of data.

00:05:09.510 --> 00:05:10.790
What does it mean?

00:05:10.790 --> 00:05:11.225
It depends.

00:05:11.225 --> 00:05:14.750
It depends greatly on the
traffic you have, on how much

00:05:14.750 --> 00:05:18.200
your instrument in your game.

00:05:18.200 --> 00:05:21.480
But if you're successful,
if your player base is

00:05:21.480 --> 00:05:25.410
significant, at a certain point,
you'll have to manage

00:05:25.410 --> 00:05:27.580
gigabytes per hour.

00:05:27.580 --> 00:05:32.420
This means that many of the
solutions that classical

00:05:32.420 --> 00:05:37.540
architecture with a MySQL
database are not good anymore.

00:05:37.540 --> 00:05:39.640
Not good anymore for
the amount of

00:05:39.640 --> 00:05:41.770
data and the velocity.

00:05:41.770 --> 00:05:46.710
And there are some caveats, some
very important things you

00:05:46.710 --> 00:05:47.680
have to consider.

00:05:47.680 --> 00:05:51.520
And this is the biggest one,
that you cannot pre-aggregate.

00:05:51.520 --> 00:05:58.250
It means that you cannot
take just some piece of

00:05:58.250 --> 00:05:59.960
information, increment
counters.

00:05:59.960 --> 00:06:03.680
You need to keep the raw
data, all of it.

00:06:03.680 --> 00:06:04.670
Why?

00:06:04.670 --> 00:06:06.710
Because at a certain point,
you'll come up with new

00:06:06.710 --> 00:06:12.210
questions that you didn't have
beforehand, or you have new

00:06:12.210 --> 00:06:16.480
data points that will make
extremely different the story

00:06:16.480 --> 00:06:18.600
of a player, for example.

00:06:18.600 --> 00:06:22.400
Say you're using an advertising
network, and at a

00:06:22.400 --> 00:06:25.420
certain point in time, you
receive the list of the

00:06:25.420 --> 00:06:28.310
players you bought from
that specific channel.

00:06:28.310 --> 00:06:30.660
So you need to reconcile
this data with

00:06:30.660 --> 00:06:32.670
your history of events.

00:06:32.670 --> 00:06:37.330
So you need a system that can
handle tons of data in the raw

00:06:37.330 --> 00:06:42.200
form because that will allow you
to ask new questions over

00:06:42.200 --> 00:06:45.330
time and integrate the new data
points when they come.

00:06:52.590 --> 00:06:57.200
I'll talk about the kind of data
we're also building to

00:06:57.200 --> 00:07:00.440
offer our analytics
platform and the

00:07:00.440 --> 00:07:03.870
tech solution we chose.

00:07:03.870 --> 00:07:06.830
We're so proud of what we're
building that we chose this

00:07:06.830 --> 00:07:10.210
double buzz word, the
real-real-time.

00:07:10.210 --> 00:07:12.330
That means two time real time.

00:07:12.330 --> 00:07:13.370
Why that?

00:07:13.370 --> 00:07:16.930
Because we ended up choosing
to use two different data

00:07:16.930 --> 00:07:21.810
stores for answering
the same questions.

00:07:21.810 --> 00:07:24.730
We're building a system that
allows you to run the very

00:07:24.730 --> 00:07:27.760
same exact queries on two
different databases that have

00:07:27.760 --> 00:07:31.820
some different performance
profiles and allows you to

00:07:31.820 --> 00:07:35.450
have always the freshest data
available, and at the same

00:07:35.450 --> 00:07:39.800
time, run analyses and run the
same queries on all your

00:07:39.800 --> 00:07:42.180
historical data set.

00:07:42.180 --> 00:07:44.820
So if your game has been around
for one year, you want

00:07:44.820 --> 00:07:46.910
to be able to answer a
question about what's

00:07:46.910 --> 00:07:50.110
happening now and
how this trend

00:07:50.110 --> 00:07:53.960
developed in the last year.

00:07:53.960 --> 00:07:56.510
We're building on top
of two technologies

00:07:56.510 --> 00:07:57.870
that are very different.

00:07:57.870 --> 00:08:01.035
One of that is a database
that is called MemSQL.

00:08:01.035 --> 00:08:04.570
That is an in-memory
version of MySQL.

00:08:04.570 --> 00:08:05.800
It's a startup as well.

00:08:05.800 --> 00:08:09.190
It's here in San Francisco,
a YC startup.

00:08:09.190 --> 00:08:12.160
That is pretty cool, because
it keeps all the data in

00:08:12.160 --> 00:08:16.320
memory and allows you to do
very fast aggregation.

00:08:16.320 --> 00:08:19.690
At the same time, we're using
this excellent product from

00:08:19.690 --> 00:08:21.360
Google that is called
BigQuery.

00:08:21.360 --> 00:08:26.720
That is a database as service,
you could say, for analytics

00:08:26.720 --> 00:08:31.740
that allows you to run queries
real fast on gigabytes of

00:08:31.740 --> 00:08:35.210
data, or terabytes, without
having to manage the whole

00:08:35.210 --> 00:08:36.460
infrastructure.

00:08:39.059 --> 00:08:42.140
Our design goal was to be
awesome fast on the latest

00:08:42.140 --> 00:08:43.250
buffer of data.

00:08:43.250 --> 00:08:45.990
So it depends on the size of
your game, but it could be the

00:08:45.990 --> 00:08:50.300
last day or last week's, and be
really, really fast on all

00:08:50.300 --> 00:08:51.550
the historical analysis.

00:08:54.580 --> 00:08:57.840
What we love about BigQuery is
that, as I was saying, it

00:08:57.840 --> 00:08:59.110
offers us a service.

00:08:59.110 --> 00:09:02.890
And if you're a three-man
company, like us, not having

00:09:02.890 --> 00:09:07.330
to manage a big cluster,
like an Hadoop

00:09:07.330 --> 00:09:09.220
cluster, for example.

00:09:09.220 --> 00:09:13.860
Even if it runs on a cloud
provider, it's a big win,

00:09:13.860 --> 00:09:19.500
because you just take a service
and you know it will

00:09:19.500 --> 00:09:23.630
be working, at night, 3:00 AM.

00:09:23.630 --> 00:09:27.080
It allows you to do fast ad
hoc queries on large data

00:09:27.080 --> 00:09:30.230
sets, and that's a very nice
feature that is called nested

00:09:30.230 --> 00:09:35.220
fields that allows us to
manage the TOCs that we

00:09:35.220 --> 00:09:38.660
associate with every event.

00:09:38.660 --> 00:09:43.220
So it's a little bit broader in
the data definition than a

00:09:43.220 --> 00:09:47.010
row of a table in a database.

00:09:47.010 --> 00:09:50.570
It's as fast that sometimes you
don't understand how much

00:09:50.570 --> 00:09:53.310
data you're touching, and the
pricing model is actually

00:09:53.310 --> 00:09:57.440
based on the amount of data
your queries are touching.

00:09:57.440 --> 00:10:02.740
So I was running a demo
a few months ago,

00:10:02.740 --> 00:10:03.690
and that's what happened.

00:10:03.690 --> 00:10:08.560
I ran a query on two terabytes
of data, and I said, what?

00:10:08.560 --> 00:10:10.810
Because that's what you
see in the bill.

00:10:10.810 --> 00:10:14.830
So it's so fast that you really
don't understand how

00:10:14.830 --> 00:10:19.670
much data you're touching
in a single query.

00:10:19.670 --> 00:10:23.125
And so we love it,
and when the bill

00:10:23.125 --> 00:10:26.088
came, I was like this.

00:10:26.088 --> 00:10:29.230
Let me introduce Michael, and
then we'll talk more about the

00:10:29.230 --> 00:10:30.940
query, and I'll continue
later.

00:10:30.940 --> 00:10:31.430
MICHAEL MANOOCHEHRI: Awesome.

00:10:31.430 --> 00:10:32.410
Thank you, Luca.

00:10:32.410 --> 00:10:34.530
Can you guys all hear me?

00:10:34.530 --> 00:10:34.850
Yeah?

00:10:34.850 --> 00:10:36.580
That sounds like a yes.

00:10:36.580 --> 00:10:39.840
Yeah, so I'm going to do my best
"Futurama" Fry impression

00:10:39.840 --> 00:10:42.350
and say I don't know if I'm
happy to see grumpy cat or sad

00:10:42.350 --> 00:10:45.620
that it was used in the same
sentence as BigQuery.

00:10:45.620 --> 00:10:49.820
But anyway, I'll talk a little
bit about how to integrate the

00:10:49.820 --> 00:10:52.030
BigQuery API into your
application.

00:10:52.030 --> 00:10:55.380
For those of you who don't know,
BigQuery is an API that

00:10:55.380 --> 00:10:57.090
lets you ask questions
about large data

00:10:57.090 --> 00:10:58.780
sets, your own data.

00:10:58.780 --> 00:11:00.970
I'm not going to get too deep
into the technical details.

00:11:00.970 --> 00:11:04.250
I'm actually going to show
you how it works.

00:11:04.250 --> 00:11:08.160
BigQuery is an API in which you
can send messages to it in

00:11:08.160 --> 00:11:12.940
JSON format and then retrieve
query results in JSON as well,

00:11:12.940 --> 00:11:15.660
which makes it really easy to
incorporate into your existing

00:11:15.660 --> 00:11:16.390
applications.

00:11:16.390 --> 00:11:19.000
And what I really like about the
Staq story is they've got

00:11:19.000 --> 00:11:20.250
their existing application.

00:11:20.250 --> 00:11:23.340
I think you build mostly in the
cloud, and it's easy to

00:11:23.340 --> 00:11:24.980
integrate BigQuery
with that system.

00:11:24.980 --> 00:11:28.200
So they really understand the
kind of modern data pipeline

00:11:28.200 --> 00:11:31.240
where you have a particular
technology for collecting data

00:11:31.240 --> 00:11:34.250
in real time very quickly, and
being able to ask questions

00:11:34.250 --> 00:11:37.150
about that real time data that's
coming in, and then

00:11:37.150 --> 00:11:40.390
asking quick questions about
historical data or aggregate

00:11:40.390 --> 00:11:42.420
data that takes a
different tool.

00:11:42.420 --> 00:11:44.280
And so what Staq's done really
well is integrate two

00:11:44.280 --> 00:11:47.650
different tools on top
of their web stack.

00:11:47.650 --> 00:11:49.750
The best way to show you, if
you've never seen BigQuery

00:11:49.750 --> 00:11:53.310
before, is how it works
and how to integrate.

00:11:53.310 --> 00:11:55.710
I have an example here.

00:11:55.710 --> 00:11:58.310
I tried to build the simplest--
let me see if I can

00:11:58.310 --> 00:11:59.400
make this a little
bit bigger--

00:11:59.400 --> 00:12:04.300
the simplest application
that I could using

00:12:04.300 --> 00:12:07.210
the BigQuery API.

00:12:07.210 --> 00:12:10.040
All of the Google APIs that are
built on our modern stack

00:12:10.040 --> 00:12:12.230
have client libraries
in many languages.

00:12:12.230 --> 00:12:16.010
We've got Ruby, and Java, and
JavaScript, and Python, PHP,

00:12:16.010 --> 00:12:16.990
just about everything
you need.

00:12:16.990 --> 00:12:18.980
And we have open source projects
of people building

00:12:18.980 --> 00:12:21.370
other things because it's
just a RESTful API.

00:12:21.370 --> 00:12:22.370
It's easy to integrate.

00:12:22.370 --> 00:12:26.760
So this is an example of some
code I wrote just really

00:12:26.760 --> 00:12:33.950
quickly using BigQuery with
the JavaScript API.

00:12:33.950 --> 00:12:36.140
And what I'm doing here-- and
I'm just showing you sort of

00:12:36.140 --> 00:12:39.280
what it looks like, how little
code you need to run a query

00:12:39.280 --> 00:12:41.180
on a very massive data set.

00:12:41.180 --> 00:12:46.490
In this case, I have a client ID
and a project ID that I got

00:12:46.490 --> 00:12:48.620
from the Google Developers
Console.

00:12:48.620 --> 00:12:50.320
This is something you can
kind of read about on

00:12:50.320 --> 00:12:51.230
the BigQuery website.

00:12:51.230 --> 00:12:53.460
I don't have a lot of time
to get into that part.

00:12:53.460 --> 00:12:55.350
And I've integrated it into
this application.

00:12:55.350 --> 00:12:58.840
I've chosen a scope for
authorization of the API.

00:12:58.840 --> 00:13:02.050
And simply, what I'm doing is
I'm just running a query, and

00:13:02.050 --> 00:13:03.660
that query will come
from a box.

00:13:03.660 --> 00:13:05.380
And I'll show you this
application in a second.

00:13:05.380 --> 00:13:08.040
And then visualizing that data,
the response from that

00:13:08.040 --> 00:13:09.440
query, with a chart.

00:13:09.440 --> 00:13:13.310
So let me show you
how this works.

00:13:13.310 --> 00:13:16.970
Oh, are we offline?

00:13:16.970 --> 00:13:18.970
We might actually be offline.

00:13:18.970 --> 00:13:20.250
LUCA MARTINETTI: Offline demo?

00:13:23.094 --> 00:13:23.570
Let's try again.

00:13:23.570 --> 00:13:26.080
MICHAEL MANOOCHEHRI: One moment,
please, while we make

00:13:26.080 --> 00:13:27.233
sure the network's right.

00:13:27.233 --> 00:13:28.580
LUCA MARTINETTI:
What happened?

00:13:28.580 --> 00:13:30.710
We can try just switch
to Wi-Fi.

00:13:30.710 --> 00:13:32.042
What do you think?

00:13:32.042 --> 00:13:36.881
MICHAEL MANOOCHEHRI: All right,
let's give that a shot.

00:13:36.881 --> 00:13:37.380
Great.

00:13:37.380 --> 00:13:39.730
Yeah, it looks like we had
a network [? conflict. ?]

00:13:39.730 --> 00:13:40.160
OK.

00:13:40.160 --> 00:13:42.410
So is what the app looks like.

00:13:42.410 --> 00:13:43.050
It's really simple.

00:13:43.050 --> 00:13:46.300
It has an authorization
button.

00:13:46.300 --> 00:13:47.340
I've actually run
through this.

00:13:47.340 --> 00:13:49.880
It's doing an OAuth 2.0
authorization, but as you saw,

00:13:49.880 --> 00:13:51.680
the client library's taking
care of a lot of the

00:13:51.680 --> 00:13:53.000
complexity.

00:13:53.000 --> 00:13:55.090
And now here's a query.

00:13:55.090 --> 00:13:56.980
I'm going to use a sample
that we have in

00:13:56.980 --> 00:13:58.370
our public data samples.

00:13:58.370 --> 00:14:00.350
When you sign up for BigQuery,
we have a collection of really

00:14:00.350 --> 00:14:02.430
large data sets for
you to try it out.

00:14:02.430 --> 00:14:04.890
And so what I'm doing here is
I'm sending it a SQL-like

00:14:04.890 --> 00:14:08.340
query, and what's great about
BigQuery, it combines a lot of

00:14:08.340 --> 00:14:12.300
the best of technologies from
big data applications.

00:14:12.300 --> 00:14:15.430
So when you're dealing with
gigabytes and terabytes of

00:14:15.430 --> 00:14:20.090
data, often you turn to
MapReduce-based tools like

00:14:20.090 --> 00:14:25.140
Hadoop, data warehousing tools
like Hive, or you're using a

00:14:25.140 --> 00:14:28.090
NoSQL data source, something
like Mongo.

00:14:28.090 --> 00:14:30.130
BigQuery doesn't use a
MapReduce-based paradigm.

00:14:30.130 --> 00:14:32.890
We actually have a different
kind of execution model.

00:14:32.890 --> 00:14:36.380
Basically we store your data in
a columnar format, and then

00:14:36.380 --> 00:14:41.130
we do most of the actual
aggregation in memory across a

00:14:41.130 --> 00:14:42.360
very large cluster.

00:14:42.360 --> 00:14:44.150
So actually what you're getting
with BigQuery is our

00:14:44.150 --> 00:14:45.730
own infrastructure.

00:14:45.730 --> 00:14:48.010
But what's cool about it is you
can ask questions, not by

00:14:48.010 --> 00:14:51.615
writing MapReduce functions, but
in a SQL-like language, so

00:14:51.615 --> 00:14:53.220
it makes it very easy
to iterate.

00:14:53.220 --> 00:14:55.830
So in this example, in this
application that you just saw

00:14:55.830 --> 00:14:58.100
the code for, I'm going
to ask a question

00:14:58.100 --> 00:15:01.450
about our GitHub timeline.

00:15:01.450 --> 00:15:03.880
The GitHub timeline data, by the
way, is a public data set

00:15:03.880 --> 00:15:08.930
that GitHub provides of any
repository that's public.

00:15:08.930 --> 00:15:12.540
So here, I'm asking what are
the top five languages that

00:15:12.540 --> 00:15:13.980
get the most events?

00:15:13.980 --> 00:15:14.790
So let's just run that.

00:15:14.790 --> 00:15:16.690
Hopefully everything
will work fine.

00:15:16.690 --> 00:15:19.540
In fact, I'm going to pull up
in the developer console so

00:15:19.540 --> 00:15:23.670
you can see what the response
looks like.

00:15:23.670 --> 00:15:26.040
So here's an example.

00:15:26.040 --> 00:15:27.210
That was a very quick query.

00:15:27.210 --> 00:15:28.660
This is actually a fairly
large data set.

00:15:28.660 --> 00:15:30.470
There's 30 million
records in here.

00:15:30.470 --> 00:15:33.080
And almost instantly, it
returned this table, and this

00:15:33.080 --> 00:15:35.670
is what the response looks
like on the JSON side.

00:15:35.670 --> 00:15:37.960
I don't know if you can see
that, but it's basically just

00:15:37.960 --> 00:15:39.810
a JSON representation of
the table you see.

00:15:39.810 --> 00:15:41.040
So it's very easy
to integrate.

00:15:41.040 --> 00:15:42.550
You saw that small
amount of code.

00:15:42.550 --> 00:15:44.870
I'm able to build a dashboard
that's querying this really

00:15:44.870 --> 00:15:47.640
interesting data set to show you
how you can integrate this

00:15:47.640 --> 00:15:49.330
into your applications.

00:15:49.330 --> 00:15:51.190
But let's talk about doing
this with games.

00:15:51.190 --> 00:15:54.390
What kind of queries are really
good for game things?

00:15:54.390 --> 00:15:57.040
I was thinking about some
queries that might appeal to

00:15:57.040 --> 00:16:00.170
some people coming to GDC, and
when you talk about games,

00:16:00.170 --> 00:16:03.030
you're often talking about
cohort analysis.

00:16:03.030 --> 00:16:05.970
So here's another example of a
public data set that we have.

00:16:05.970 --> 00:16:06.720
Hopefully you can see this.

00:16:06.720 --> 00:16:09.710
I'll make it a little bit bigger
so you can see it.

00:16:09.710 --> 00:16:12.670
We're going to look at the
Wikipedia revision

00:16:12.670 --> 00:16:13.720
history data sets.

00:16:13.720 --> 00:16:15.670
So this is a very large
data set that we have.

00:16:15.670 --> 00:16:16.930
It's 35 gigs.

00:16:16.930 --> 00:16:19.860
It's got 300 million records.

00:16:19.860 --> 00:16:21.630
And let me see if I can
actually zoom in

00:16:21.630 --> 00:16:24.172
a little bit here.

00:16:24.172 --> 00:16:25.230
Is that a little bit better?

00:16:25.230 --> 00:16:27.000
Can you see that, everyone?

00:16:27.000 --> 00:16:28.850
So basically, there's 35 gigs.

00:16:28.850 --> 00:16:29.790
It's pretty big.

00:16:29.790 --> 00:16:32.060
It's got 300 million records,
and the data kind

00:16:32.060 --> 00:16:32.880
of looks like this.

00:16:32.880 --> 00:16:34.390
It's got a title.

00:16:34.390 --> 00:16:36.440
It has a timestamp.

00:16:36.440 --> 00:16:39.380
And a contributor ID, like who
revised the article, what

00:16:39.380 --> 00:16:40.770
their contributor's name was.

00:16:40.770 --> 00:16:43.380
So I was thinking about some
queries we could run to kind

00:16:43.380 --> 00:16:46.220
of demonstrate what a cohort
analysis would look like, and

00:16:46.220 --> 00:16:47.950
so I have some examples here.

00:16:47.950 --> 00:16:49.980
The first thing, I was thinking
about people's names,

00:16:49.980 --> 00:16:52.410
and I realized people like to
name themselves "Wikipedia,"

00:16:52.410 --> 00:16:54.360
like to name themselves like
"Wikipedia Mage" and

00:16:54.360 --> 00:16:56.870
"Wikipedia Wizard," much like
some of the gamers that you

00:16:56.870 --> 00:16:58.290
have on social media.

00:16:58.290 --> 00:17:00.510
So the first query I thought of
was this cohort analysis.

00:17:00.510 --> 00:17:04.560
I wanted to see what usernames
contained these strings.

00:17:04.560 --> 00:17:10.630
So I wrote us a very simple
SQL-like query here, and it

00:17:10.630 --> 00:17:12.060
should go pretty quickly.

00:17:12.060 --> 00:17:16.190
So in seven seconds, it did a
full table scan of all 300

00:17:16.190 --> 00:17:20.170
million records, and it found
some matches that look a lot

00:17:20.170 --> 00:17:24.829
like "mage." And you can
see images in there.

00:17:24.829 --> 00:17:25.950
So that was very quick.

00:17:25.950 --> 00:17:29.880
There's 283,000 records.

00:17:29.880 --> 00:17:31.650
I wanted to do an
ad hoc analysis.

00:17:31.650 --> 00:17:33.250
I wanted to iterate quickly.

00:17:33.250 --> 00:17:35.440
Now if I was doing this with
MapReduce, I'd have to write a

00:17:35.440 --> 00:17:36.330
new MapReduce function.

00:17:36.330 --> 00:17:37.360
I'd have to do a new workflow.

00:17:37.360 --> 00:17:39.630
It takes time.

00:17:39.630 --> 00:17:41.880
What I want to do is just ask
these quick questions on this

00:17:41.880 --> 00:17:44.360
huge data set very quickly.

00:17:44.360 --> 00:17:45.570
The first thing I want
to do is get rid

00:17:45.570 --> 00:17:47.410
of those image results.

00:17:47.410 --> 00:17:50.890
So I'm going to do a regular
expression match, which

00:17:50.890 --> 00:17:52.040
BigQuery supports.

00:17:52.040 --> 00:17:55.360
So what I'm doing here is I'm
running the same query--

00:17:55.360 --> 00:17:56.420
and actually, let me
take this out.

00:17:56.420 --> 00:17:58.340
I'll do this in a second.

00:17:58.340 --> 00:18:01.090
So I'm running the same query,
but what I'm doing here is I'm

00:18:01.090 --> 00:18:03.470
saying instead of the contain
string, I'll do a regular

00:18:03.470 --> 00:18:06.450
expression match on "wizard"
or "mage."

00:18:06.450 --> 00:18:08.660
So I'm going to run this again,
and hopefully what will

00:18:08.660 --> 00:18:11.690
happen is that I'll see the
real user names that don't

00:18:11.690 --> 00:18:14.320
have the word "image." So we
have Pharaoh of the Wizards,

00:18:14.320 --> 00:18:15.680
and Wizard191.

00:18:15.680 --> 00:18:17.790
So now I'm getting somewhere,
like I'm building a cohort

00:18:17.790 --> 00:18:21.090
analysis where I'm actually
looking at a

00:18:21.090 --> 00:18:22.920
particular type of user.

00:18:22.920 --> 00:18:25.690
Now what I want to do is bucket
my results by a time.

00:18:25.690 --> 00:18:28.860
I want to see who's doing what
on a particular day.

00:18:28.860 --> 00:18:32.240
Again, this is going over 35
gigs, and imagine doing this

00:18:32.240 --> 00:18:34.160
on something like MySQL
Datastore or

00:18:34.160 --> 00:18:34.730
something like that.

00:18:34.730 --> 00:18:37.100
It would take a long time, but
I'm doing these queries in

00:18:37.100 --> 00:18:38.310
four seconds.

00:18:38.310 --> 00:18:42.000
So I'll do another
quick query.

00:18:42.000 --> 00:18:44.940
Let's see, I'll run another
sample that's similar.

00:18:44.940 --> 00:18:47.450
Now let's add a time bucket,
and I'll just run through

00:18:47.450 --> 00:18:48.490
these really quick.

00:18:48.490 --> 00:18:51.610
What I'm going to do here is
I'm going to say, use the

00:18:51.610 --> 00:18:55.720
function call UTC USEC TO_DAY,
which means it'll take any

00:18:55.720 --> 00:18:59.150
timestamp it sees and bucket
it in a 24-hour period.

00:18:59.150 --> 00:19:02.330
Basically what I'm doing is I'm
saying, give me events in

00:19:02.330 --> 00:19:03.320
a particular day.

00:19:03.320 --> 00:19:04.810
Segment my data like that.

00:19:04.810 --> 00:19:06.070
So let's run this again.

00:19:06.070 --> 00:19:09.310
What you're going to see here
is something that looks like

00:19:09.310 --> 00:19:12.610
the same data, but events
happening per day, Wikipedia

00:19:12.610 --> 00:19:14.030
revisions happening per day.

00:19:14.030 --> 00:19:16.790
So that, again, took just six
seconds, and now you can see

00:19:16.790 --> 00:19:19.980
Wizardman had done a revision
on that day.

00:19:19.980 --> 00:19:22.720
By the way, these are
Unix timestamps.

00:19:22.720 --> 00:19:24.070
That's why they're these
big integers

00:19:24.070 --> 00:19:25.630
in microsecond format.

00:19:25.630 --> 00:19:27.140
Wizardman did something
on this day.

00:19:27.140 --> 00:19:28.310
Pharaoh of the Wizards did
something to this.

00:19:28.310 --> 00:19:29.340
And now I'm getting somewhere.

00:19:29.340 --> 00:19:32.480
I'm seeing what activity's
happening per day.

00:19:32.480 --> 00:19:34.670
And now I want to do something
a little bit different.

00:19:34.670 --> 00:19:40.630
I want to do something where I
can actually segment them as

00:19:40.630 --> 00:19:42.390
are they wizards or
are they mages?

00:19:42.390 --> 00:19:43.890
So I've added a conditional.

00:19:43.890 --> 00:19:45.620
I don't know if you can see that
there, but I've added a

00:19:45.620 --> 00:19:49.070
conditional statement that
actually segments by what type

00:19:49.070 --> 00:19:51.560
of player or what type
of user are they.

00:19:51.560 --> 00:19:53.420
Are they the wizard player
or the mage player?

00:19:53.420 --> 00:19:56.750
So in just a few seconds, I
should get that as well, and

00:19:56.750 --> 00:19:58.780
basically what this is going to
do is break that up by day.

00:19:58.780 --> 00:20:02.570
And it's going to say how many
wizards are doing something,

00:20:02.570 --> 00:20:03.770
how many mages are
doing something.

00:20:03.770 --> 00:20:07.360
So here you can see, a wizard
interacted this day,

00:20:07.360 --> 00:20:10.680
interacted that way, and I'm
able to break them up into

00:20:10.680 --> 00:20:13.660
different mages, wizards,
warriors, what have you, based

00:20:13.660 --> 00:20:14.620
just on their username.

00:20:14.620 --> 00:20:18.180
And finally, let's do a final
kind of wrap it up query.

00:20:18.180 --> 00:20:19.520
We're going to put this
all together.

00:20:19.520 --> 00:20:21.810
We're going to group things
by wizards and mages.

00:20:21.810 --> 00:20:23.080
We're going to add
a time bucket.

00:20:23.080 --> 00:20:25.520
We're going to format
the timestamp.

00:20:25.520 --> 00:20:28.300
So in just a few queries--

00:20:28.300 --> 00:20:29.630
you can write these
very quickly and

00:20:29.630 --> 00:20:30.760
iterate very quickly--

00:20:30.760 --> 00:20:32.660
but I've just done a really
interesting cohort where I've

00:20:32.660 --> 00:20:34.570
said, break it down by day.

00:20:34.570 --> 00:20:38.040
Mages are revising only 15 times
a day, while people with

00:20:38.040 --> 00:20:41.700
"wizard" in their username
are revising 185, and

00:20:41.700 --> 00:20:42.890
so on, and so forth.

00:20:42.890 --> 00:20:44.180
You can imagine taking
this data and

00:20:44.180 --> 00:20:45.360
really breaking it down.

00:20:45.360 --> 00:20:46.870
You could see what type
of players you have.

00:20:46.870 --> 00:20:47.780
What are they doing.

00:20:47.780 --> 00:20:49.980
What's their behavior.

00:20:49.980 --> 00:20:53.100
Real quick, we've listened to
our developers, and we really

00:20:53.100 --> 00:20:55.990
care a lot about what guys like
Luca are doing at Staq.

00:20:55.990 --> 00:20:59.000
One thing that they've asked
us for is more features to

00:20:59.000 --> 00:21:01.740
help them do things on
larger data sets.

00:21:01.740 --> 00:21:04.360
Traditionally, the way that
BigQuery has designed it, it

00:21:04.360 --> 00:21:07.760
really didn't do big joins on
different size data sets.

00:21:07.760 --> 00:21:10.880
You could do a large data set
join to a lookup table.

00:21:10.880 --> 00:21:13.620
But we've just a few weeks ago
released something we call Big

00:21:13.620 --> 00:21:15.630
JOIN, which does allow
you to do these

00:21:15.630 --> 00:21:17.560
very, very large joins.

00:21:17.560 --> 00:21:19.760
We've done terabytes to
gigabyte data sets.

00:21:19.760 --> 00:21:23.660
Very useful for year's worth of
activity joined with data

00:21:23.660 --> 00:21:26.550
coming from something else,
like purchases.

00:21:26.550 --> 00:21:30.220
And I was able to ask the Staq
team to generate a fake data

00:21:30.220 --> 00:21:32.880
set, but something like the
data that you saw Luca

00:21:32.880 --> 00:21:36.720
provide, which is kind of like
what their events look like.

00:21:36.720 --> 00:21:38.835
So let me show you a little
bit about that.

00:21:38.835 --> 00:21:41.830
Their events data looks
something like this where you

00:21:41.830 --> 00:21:44.390
might have a particular
user ID.

00:21:44.390 --> 00:21:45.370
It's just some hash.

00:21:45.370 --> 00:21:47.830
A timestamp, like you saw,
they did something,

00:21:47.830 --> 00:21:48.790
and then the event.

00:21:48.790 --> 00:21:52.020
So in this case, this data says
that a player started at

00:21:52.020 --> 00:21:53.930
a certain time, started
playing the game.

00:21:53.930 --> 00:21:56.480
Another event might be
an in-app purchase.

00:21:56.480 --> 00:21:59.100
So what if I want to ask a
question-- this particular

00:21:59.100 --> 00:22:01.190
data set, by the way,
is 6 gigabytes.

00:22:01.190 --> 00:22:04.390
It's about, let's see, 30
million records, right?

00:22:04.390 --> 00:22:05.620
30 million events.

00:22:05.620 --> 00:22:08.430
And I'm going to join this data
with another data set

00:22:08.430 --> 00:22:10.080
that's even bigger,
something like 10

00:22:10.080 --> 00:22:13.505
gigs, 47 million records.

00:22:13.505 --> 00:22:17.360
I'm going to show a join, a big
join, on that, and see how

00:22:17.360 --> 00:22:18.490
fast it can go.

00:22:18.490 --> 00:22:23.190
And what I'm going to do is I'm
going to look for players

00:22:23.190 --> 00:22:29.180
who started a session yesterday
or the day before,

00:22:29.180 --> 00:22:33.600
and then bought something, had
an in-app purchase today or

00:22:33.600 --> 00:22:34.530
the next day.

00:22:34.530 --> 00:22:36.800
So this is a large
kind of a join.

00:22:36.800 --> 00:22:39.130
It looks a lot like a join you
would see in a relational

00:22:39.130 --> 00:22:42.620
database, and this is
joining data from 10

00:22:42.620 --> 00:22:43.900
gigabytes to 6 gigabytes.

00:22:43.900 --> 00:22:46.100
And let's see how long
this takes to run.

00:22:46.100 --> 00:22:48.490
In here, as I mentioned, I'm
looking for in-app purchase

00:22:48.490 --> 00:22:50.730
events that happen
in a certain day.

00:22:50.730 --> 00:22:53.230
I'm looking for the count and
the total amount of money.

00:22:53.230 --> 00:22:55.990
And that just took seven
seconds, so I've just did this

00:22:55.990 --> 00:22:57.810
huge join, that's something that
you would normally do a

00:22:57.810 --> 00:23:00.330
MapReduce job in, in
just seven seconds,

00:23:00.330 --> 00:23:01.930
which is pretty fantastic.

00:23:01.930 --> 00:23:04.140
And here, you've got the
aggregate queries, the count

00:23:04.140 --> 00:23:07.770
of purchases, the amount of
money, and which user it was.

00:23:07.770 --> 00:23:10.580
So this is the kind of cohort
analysis you can do, and you

00:23:10.580 --> 00:23:12.970
can integrate this into your
own applications using the

00:23:12.970 --> 00:23:14.300
BigQuery API.

00:23:14.300 --> 00:23:16.430
I'll leave you with one more
thing before I hand it back to

00:23:16.430 --> 00:23:17.420
Luca, and this is something
you can try

00:23:17.420 --> 00:23:19.310
right now on your laptops.

00:23:19.310 --> 00:23:22.370
To show this off without having
you actually develop

00:23:22.370 --> 00:23:24.940
something or log into our
console to actually start

00:23:24.940 --> 00:23:27.240
writing code yourself, you can
play with this using something

00:23:27.240 --> 00:23:30.150
we call the BigQuery Tour, and
this is sort of a cartoon

00:23:30.150 --> 00:23:32.670
exploration of two really bigger
data sets than I've

00:23:32.670 --> 00:23:33.590
shown you today.

00:23:33.590 --> 00:23:36.570
One is data from weather
stations all around the world

00:23:36.570 --> 00:23:37.520
since 1929.

00:23:37.520 --> 00:23:38.960
It's a pretty large data set.

00:23:38.960 --> 00:23:43.840
And an even bigger data set is
a Wikipedia page views data

00:23:43.840 --> 00:23:46.650
set, which is a really
interesting one.

00:23:46.650 --> 00:23:50.450
Let's look at what the top page
views were for last year.

00:23:50.450 --> 00:23:54.350
Today's the 26th, so let's see
what happened March 26.

00:23:54.350 --> 00:23:56.880
Any guesses of what the
top Wikipedia page

00:23:56.880 --> 00:23:59.050
viewed was a year ago?

00:23:59.050 --> 00:23:59.670
Think about it.

00:23:59.670 --> 00:24:00.630
I'll show you.

00:24:00.630 --> 00:24:01.110
So I'm going to run this.

00:24:01.110 --> 00:24:02.410
This is doing the same thing.

00:24:02.410 --> 00:24:04.800
This is an app built on
the API, no caching.

00:24:04.800 --> 00:24:06.640
It's hitting BigQuery's
API live.

00:24:06.640 --> 00:24:07.730
It's crunching, and crunching.

00:24:07.730 --> 00:24:09.600
That's actually what BigQuery
looks like inside of Google.

00:24:09.600 --> 00:24:10.520
I don't know if you know that.

00:24:10.520 --> 00:24:12.180
We do have ping pong balls.

00:24:12.180 --> 00:24:15.480
So in 10 seconds we've analyzed
83 gigs of data.

00:24:15.480 --> 00:24:17.010
Very quick.

00:24:17.010 --> 00:24:18.620
Let's see what the
results are.

00:24:18.620 --> 00:24:21.480
Looks like "Hunger Games!" I
guess "Hunger Games" had just

00:24:21.480 --> 00:24:23.450
come out, so everything is
"Hunger Games." Except for

00:24:23.450 --> 00:24:26.180
number four, Ludwig
Mies van der Rohe.

00:24:26.180 --> 00:24:30.780
Does anyone know why he might
have had one of the fourth

00:24:30.780 --> 00:24:33.980
largest Wikipedia page views?

00:24:33.980 --> 00:24:36.740
It was his birthday, but we also
had a Google Doodle, and

00:24:36.740 --> 00:24:38.670
whenever there's a Google
Doodle, the Wikipedia page

00:24:38.670 --> 00:24:39.910
views are enormous
on that day.

00:24:39.910 --> 00:24:42.080
So that's actually
what happened.

00:24:42.080 --> 00:24:43.340
So there you go.

00:24:43.340 --> 00:24:44.900
You could also look at the
queries through this.

00:24:44.900 --> 00:24:46.330
It's really great.

00:24:46.330 --> 00:24:52.840
You can get to this by going to
cloud.google.com/bigquery,

00:24:52.840 --> 00:24:54.690
and you can just play
with it yourself.

00:24:54.690 --> 00:24:57.340
Or just Google search for
"BigQuery Tour." It's probably

00:24:57.340 --> 00:24:58.820
going to be the first hit.

00:24:58.820 --> 00:24:59.540
So that's it.

00:24:59.540 --> 00:25:00.700
That's what BigQuery does.

00:25:00.700 --> 00:25:02.490
I'm going to pass it back to
Luca, and he can show you how

00:25:02.490 --> 00:25:04.832
to integrate it into
a real app.

00:25:04.832 --> 00:25:07.170
LUCA MARTINETTI: All right.

00:25:07.170 --> 00:25:08.970
OK.

00:25:08.970 --> 00:25:10.270
Yeah, the cat.

00:25:14.240 --> 00:25:19.620
So after collecting these
events, the second step is try

00:25:19.620 --> 00:25:22.770
to understand something that
you don't know, and this

00:25:22.770 --> 00:25:25.540
analysis can be of very
different kinds.

00:25:25.540 --> 00:25:28.450
There are the standard
metrics that every

00:25:28.450 --> 00:25:30.310
single game app needs.

00:25:30.310 --> 00:25:34.960
So daily active user, monthly
active user, revenues per

00:25:34.960 --> 00:25:38.070
user, per paying user, and
return rates, so how long my

00:25:38.070 --> 00:25:43.080
players are staying with me in
next day, 7 days, and 30 days.

00:25:43.080 --> 00:25:46.190
And also these, let's say, easy
metrics, these standard

00:25:46.190 --> 00:25:50.990
metrics, have some challenges
when I'm talking about

00:25:50.990 --> 00:25:52.550
monetization.

00:25:52.550 --> 00:25:55.950
For example, when I'm dealing
with in-app purchases, one of

00:25:55.950 --> 00:26:00.500
the biggest problems that
we're facing are fake

00:26:00.500 --> 00:26:01.660
transactions.

00:26:01.660 --> 00:26:02.870
What does it mean?

00:26:02.870 --> 00:26:06.190
It means that for very large
studios, if you don't do

00:26:06.190 --> 00:26:09.100
server-side verification
of the receipts.

00:26:09.100 --> 00:26:15.070
So if the purchase that again
is reporting to you is real,

00:26:15.070 --> 00:26:18.510
you see just 1 in 100
transactions that is an

00:26:18.510 --> 00:26:19.980
actual, real transaction.

00:26:19.980 --> 00:26:23.580
And it's not as bad that you're
giving away virtual

00:26:23.580 --> 00:26:25.760
goods, because you're not paying
for that, but your

00:26:25.760 --> 00:26:31.490
metrics will be barely usable
with all that noise.

00:26:31.490 --> 00:26:32.630
What has happened?

00:26:32.630 --> 00:26:36.330
Because the devices are not
secure, and if your user base

00:26:36.330 --> 00:26:39.670
is large enough, somebody will
spend time, nights, and hack

00:26:39.670 --> 00:26:44.640
the game to get that great sword
for free, and you start

00:26:44.640 --> 00:26:46.790
getting fake events.

00:26:46.790 --> 00:26:49.440
Solution for that is having
server-side receipt

00:26:49.440 --> 00:26:50.170
verification.

00:26:50.170 --> 00:26:55.660
So with the Apple App Store, for
example, with Google Play,

00:26:55.660 --> 00:27:01.730
they expose an API, so you're
not only at this point running

00:27:01.730 --> 00:27:03.030
the game on the device.

00:27:03.030 --> 00:27:04.580
You need a server-side part.

00:27:04.580 --> 00:27:08.670
And that's something that Staq
provides out of the box.

00:27:08.670 --> 00:27:13.930
What I want to show you, it's a
demo of these basic metrics.

00:27:13.930 --> 00:27:18.100
And obviously [LAUGHS]

00:27:18.100 --> 00:27:19.700
hope everything goes well.

00:27:19.700 --> 00:27:23.360
I don't always test my code, so
I will do it on stage now.

00:27:23.360 --> 00:27:26.850
So live coding.

00:27:26.850 --> 00:27:31.600
This is the dashboard of Staq,
and what I do now is create a

00:27:31.600 --> 00:27:37.930
new application that I've
called GDC_demo01.

00:27:37.930 --> 00:27:42.250
And creating this application,
I will get an app ID.

00:27:42.250 --> 00:27:45.240
All right, let's
switch to that.

00:27:45.240 --> 00:27:47.920
I should see some nice zeroes.

00:27:47.920 --> 00:27:54.420
And what I do is take this app
ID and just paste it into this

00:27:54.420 --> 00:27:58.270
small Python script that is a
simulator that we call our

00:27:58.270 --> 00:28:03.540
REST API, simulating some
events, some users logging in

00:28:03.540 --> 00:28:07.310
and some purchases.

00:28:07.310 --> 00:28:09.075
So let's start it.

00:28:09.075 --> 00:28:10.290
We have connection.

00:28:10.290 --> 00:28:12.100
It's not very popular yet.

00:28:12.100 --> 00:28:13.762
Don't have any user.

00:28:13.762 --> 00:28:15.030
OK.

00:28:15.030 --> 00:28:18.360
I can see real time users
coming, and those are

00:28:18.360 --> 00:28:19.600
generating some events.

00:28:19.600 --> 00:28:23.020
I see some events flowing in in
real time, so some sessions

00:28:23.020 --> 00:28:24.350
are started.

00:28:24.350 --> 00:28:25.510
If these guys--

00:28:25.510 --> 00:28:27.660
yeah, somebody bought
something.

00:28:27.660 --> 00:28:33.510
I see the revenue's going up,
and I see the basic metrics in

00:28:33.510 --> 00:28:34.450
real-real time.

00:28:34.450 --> 00:28:36.290
So that's what I was talking
about before.

00:28:36.290 --> 00:28:40.490
The last buffer, it's all
in-memory, so we're able to

00:28:40.490 --> 00:28:43.060
have all these metrics, and also
custom metrics that I'll

00:28:43.060 --> 00:28:47.890
show later, really, really
fast on your data.

00:28:47.890 --> 00:28:52.560
And this was really quick to set
up, so if you have a game,

00:28:52.560 --> 00:28:55.480
you just plug in our SDK.

00:28:55.480 --> 00:28:58.820
We have, as I was saying, REST
APIs, and we also provide

00:28:58.820 --> 00:29:03.440
Unity, JavaScript, iOS,
and an Android will be

00:29:03.440 --> 00:29:05.780
out very, very soon.

00:29:05.780 --> 00:29:10.640
And this is part of a story,
so understanding how much

00:29:10.640 --> 00:29:12.890
money you're making
in a reliable way.

00:29:12.890 --> 00:29:15.880
But that's not all.

00:29:15.880 --> 00:29:17.946
That's not enough.

00:29:17.946 --> 00:29:19.910
You need to ask new questions.

00:29:19.910 --> 00:29:21.920
You need to understand
something that is

00:29:21.920 --> 00:29:23.170
specific for your game.

00:29:25.560 --> 00:29:28.120
As Michael was saying, are
mages spending more than

00:29:28.120 --> 00:29:30.630
warriors if you're doing
RPG, for example?

00:29:30.630 --> 00:29:35.290
Or are mages that reach level
seven and use this specific

00:29:35.290 --> 00:29:42.880
sword performing better than
this other class of players?

00:29:42.880 --> 00:29:45.550
And this can be very
arbitrary.

00:29:45.550 --> 00:29:47.220
So why are they not buying
the dead bird?

00:29:47.220 --> 00:29:48.030
Why?

00:29:48.030 --> 00:29:48.965
So cute.

00:29:48.965 --> 00:29:52.720
It's this item for "Team
Fortress 2." It's only $12.

00:29:52.720 --> 00:29:54.210
Why are they not buying that?

00:29:54.210 --> 00:29:56.710
I think they're actually
buying it.

00:29:56.710 --> 00:29:59.300
So there are so many questions
that are really specific to

00:29:59.300 --> 00:30:04.500
your game, and you need a quick
and effective way to go

00:30:04.500 --> 00:30:06.810
against the raw data.

00:30:06.810 --> 00:30:10.830
And I want to show something
that is even more difficult

00:30:10.830 --> 00:30:11.830
than what I did before.

00:30:11.830 --> 00:30:17.155
So again, demo gods,
please help us.

00:30:17.155 --> 00:30:23.680
I have this small HTML5 game
that I found online from a guy

00:30:23.680 --> 00:30:24.790
in Belgium.

00:30:24.790 --> 00:30:25.800
It is a beat box.

00:30:25.800 --> 00:30:28.929
[PERCUSSION SOUNDS]

00:30:28.929 --> 00:30:33.310
LUCA MARTINETTI: And what I'm
going to do now is just plug

00:30:33.310 --> 00:30:35.820
the Staq API in that and start
tracking some events.

00:30:35.820 --> 00:30:38.340
So let me load it up.

00:30:47.600 --> 00:30:53.296
It's just HTML5, so just a few
JavaScript files and CSS.

00:30:53.296 --> 00:30:55.970
It runs on the canvas.

00:30:55.970 --> 00:31:01.500
What I did is just adding the
JavaScript client of Staq of

00:31:01.500 --> 00:31:03.570
the REST API that's
a few lines long.

00:31:03.570 --> 00:31:05.690
It's very, very simple.

00:31:05.690 --> 00:31:12.910
And what I'm doing now, it's
finding where the event of

00:31:12.910 --> 00:31:17.895
somebody eating the
button goes.

00:31:17.895 --> 00:31:19.515
And it goes here.

00:31:22.440 --> 00:31:25.700
Let me paste some code
that I have ready.

00:31:25.700 --> 00:31:27.097
Where is that?

00:31:27.097 --> 00:31:28.347
Here.

00:31:32.650 --> 00:31:35.310
So I have an integer
that is the ID.

00:31:35.310 --> 00:31:38.740
Can you read it, or
is it too small?

00:31:38.740 --> 00:31:40.200
How is the size of the font?

00:31:40.200 --> 00:31:41.300
Is it too small?

00:31:41.300 --> 00:31:41.980
AUDIENCE: [INAUDIBLE]

00:31:41.980 --> 00:31:42.320
fine.

00:31:42.320 --> 00:31:42.910
LUCA MARTINETTI: That's fine?

00:31:42.910 --> 00:31:42.980
OK.

00:31:42.980 --> 00:31:47.850
So I have an integer that is
the triangle I've been

00:31:47.850 --> 00:31:52.400
clicking on, and I just did the
small map of the colors.

00:31:52.400 --> 00:31:54.900
So what I'm doing in-- oops.

00:31:54.900 --> 00:31:56.150
Copy that--

00:32:02.650 --> 00:32:06.940
so what I'm doing is creating
an event, and the

00:32:06.940 --> 00:32:07.730
event looks like this.

00:32:07.730 --> 00:32:10.540
As a timestamp, it's the custom
event that I'm calling

00:32:10.540 --> 00:32:13.060
"beat." Maybe I can zoom
in a little bit.

00:32:15.850 --> 00:32:17.480
It's an event that I'm
calling "beat."

00:32:17.480 --> 00:32:21.780
As a value, it takes the color
of the ID I'm clicking on, and

00:32:21.780 --> 00:32:24.120
I'm just adding two metadata.

00:32:24.120 --> 00:32:29.110
One is the tile ID itself, and
I'm setting a flag that says

00:32:29.110 --> 00:32:32.070
"green" if the ID is 12 or 15.

00:32:32.070 --> 00:32:36.710
So this is how the ID is
of the different tiles.

00:32:36.710 --> 00:32:39.680
What I need is just create the
event, and I have to put the

00:32:39.680 --> 00:32:41.130
application ID here.

00:32:41.130 --> 00:32:42.540
Oops, where was that?

00:32:47.610 --> 00:32:51.240
Let me create a new application,
call it

00:32:51.240 --> 00:32:57.995
GDC_beat01.

00:32:57.995 --> 00:33:02.865
Now get an app ID, copy
that, switch to that.

00:33:05.610 --> 00:33:09.450
Oops, other side.

00:33:09.450 --> 00:33:12.364
And I paste it.

00:33:12.364 --> 00:33:13.825
OK, here we go.

00:33:16.600 --> 00:33:27.460
What I'll do is git commit,
gods help me--

00:33:36.710 --> 00:33:40.920
and I'm pushing this
small demo.

00:33:40.920 --> 00:33:45.171
Do a little dance, do
a little dance.

00:33:45.171 --> 00:33:47.740
I never test my code.

00:33:47.740 --> 00:33:51.290
Yeah, if you have iPhones and
iPads video, it would be nice

00:33:51.290 --> 00:33:53.675
if you could go to this
URL that I'll

00:33:53.675 --> 00:33:55.976
give you in one second.

00:33:55.976 --> 00:33:59.600
That's live publishing--

00:33:59.600 --> 00:34:00.850
come on, go there.

00:34:04.060 --> 00:34:05.360
MICHAEL MANOOCHEHRI: It
works on laptops, too.

00:34:05.360 --> 00:34:08.654
LUCA MARTINETTI: Demo gods,
are you helping me today?

00:34:11.370 --> 00:34:12.130
OK.

00:34:12.130 --> 00:34:16.930
In the meantime, I'll give
you the address.

00:34:21.590 --> 00:34:23.659
Cleaning up, installing.

00:34:23.659 --> 00:34:24.995
So it's happening.

00:34:24.995 --> 00:34:26.245
Sorry for that.

00:34:28.920 --> 00:34:32.079
I haven't found a faster way of
deploying my application.

00:34:40.830 --> 00:34:42.170
OK, here we go.

00:34:42.170 --> 00:34:53.170
So if we go to this URL here,
beat.staq.io, please do that.

00:34:53.170 --> 00:34:53.940
It's not [INAUDIBLE] beat.

00:34:53.940 --> 00:34:56.600
Do you have iPhones
or iPads video?

00:34:56.600 --> 00:35:00.280
I have an iPad, maybe.

00:35:00.280 --> 00:35:02.380
And just load the page.

00:35:05.690 --> 00:35:06.535
OK, seven.

00:35:06.535 --> 00:35:08.490
Seven of you guys are
on the page now.

00:35:08.490 --> 00:35:09.840
I can see that.

00:35:09.840 --> 00:35:10.720
Are you sending beats?

00:35:10.720 --> 00:35:11.585
[INAUDIBLE]?

00:35:11.585 --> 00:35:13.180
Are you playing?

00:35:13.180 --> 00:35:14.810
I can't hear you very loud.

00:35:14.810 --> 00:35:15.640
Turn up the volume.

00:35:15.640 --> 00:35:17.020
MICHAEL MANOOCHEHRI: I want
to hear some more, too.

00:35:17.020 --> 00:35:19.485
LUCA MARTINETTI: Want
to hear some more.

00:35:19.485 --> 00:35:19.900
MICHAEL MANOOCHEHRI:
We need big data.

00:35:19.900 --> 00:35:22.740
LUCA MARTINETTI:
Is it loading?

00:35:22.740 --> 00:35:30.900
This should be working on
iPhones and Androids as well.

00:35:30.900 --> 00:35:31.330
But not--

00:35:31.330 --> 00:35:37.240
[PERCUSSION SOUNDS]

00:35:37.240 --> 00:35:39.670
LUCA MARTINETTI:
Is it working?

00:35:39.670 --> 00:35:40.000
OK.

00:35:40.000 --> 00:35:43.370
So you see the events flowing in
real time, and that's kind

00:35:43.370 --> 00:35:45.410
of interesting, but not
super interesting.

00:35:45.410 --> 00:35:49.330
So what I want to do, while you
bang on it, it's show you

00:35:49.330 --> 00:35:51.380
that we can do custom queries.

00:35:51.380 --> 00:35:56.680
So with the SQL syntax that I
was saying will be the same

00:35:56.680 --> 00:36:00.410
for real time exploration for
all the historical data.

00:36:00.410 --> 00:36:11.750
I can just say, SELECT COUNT the
distinct event ID from my

00:36:11.750 --> 00:36:20.350
table where the event will be
"beat." And I want to do that

00:36:20.350 --> 00:36:21.800
on the last minutes.

00:36:25.920 --> 00:36:27.460
Yeah, you banged on it 2,000--

00:36:27.460 --> 00:36:29.750
oh, almost 3,000 times.

00:36:29.750 --> 00:36:31.580
OK, nice.

00:36:31.580 --> 00:36:34.450
And since I'm storing the raw
data, and I'm against the raw

00:36:34.450 --> 00:36:36.250
data, I can go down
to the second.

00:36:36.250 --> 00:36:39.734
So if I'm lucky--

00:36:39.734 --> 00:36:41.980
come on, guy.

00:36:41.980 --> 00:36:43.370
Yeah.

00:36:43.370 --> 00:36:44.960
That's very fresh data.

00:36:44.960 --> 00:36:46.630
That's what's happening
in real time.

00:36:46.630 --> 00:36:50.288
So if you stop playing-- stop
playing, guys, stop playing.

00:36:50.288 --> 00:36:52.184
[LAUGHTER]

00:36:52.184 --> 00:36:53.746
LUCA MARTINETTI: Stop it.

00:36:53.746 --> 00:36:55.600
You'll miss my demo.

00:36:55.600 --> 00:36:57.860
This will go down.

00:36:57.860 --> 00:36:58.820
Here we go.

00:36:58.820 --> 00:37:03.850
And at the same time, I add some
value that was a string

00:37:03.850 --> 00:37:09.140
that I put with each single beat
that was the color, and I

00:37:09.140 --> 00:37:15.280
say group by string.

00:37:21.710 --> 00:37:23.372
Here we go.

00:37:23.372 --> 00:37:27.350
All this mess here is the
different colors that you're

00:37:27.350 --> 00:37:31.090
clicking on in real time.

00:37:31.090 --> 00:37:34.800
So let's go green, everybody.

00:37:34.800 --> 00:37:37.100
Let's start eating only
the green ones.

00:37:37.100 --> 00:37:41.100
[PERCUSSION SOUNDS]

00:37:41.100 --> 00:37:44.275
LUCA MARTINETTI: We should see
only the greens going up.

00:37:46.850 --> 00:37:50.640
So imagine this is some real
data, and I'm showing, for

00:37:50.640 --> 00:37:55.410
example, wins versus losses
for two specific classes.

00:37:55.410 --> 00:37:59.580
So what I'm doing, I'm slicing
data in real time.

00:37:59.580 --> 00:38:02.610
And this is quite nice because
I can go on different

00:38:02.610 --> 00:38:06.400
resolutions in terms of time.

00:38:06.400 --> 00:38:10.950
This is down by the second,
so it's more interactive.

00:38:10.950 --> 00:38:14.640
But what is useful is that
I can see this data in my

00:38:14.640 --> 00:38:15.990
dashboard, like all the rest.

00:38:15.990 --> 00:38:22.790
So I can just pin this query and
see is our beats by color,

00:38:22.790 --> 00:38:25.670
and I'll just add this
to my summary.

00:38:25.670 --> 00:38:30.700
So when I go on my dashboard on
my Summary page, I'll have

00:38:30.700 --> 00:38:34.640
it here like any other metrics
that are built in.

00:38:34.640 --> 00:38:40.450
We'll enable more data
exploration without coding for

00:38:40.450 --> 00:38:44.180
non-technical user with a query
builder, but the idea is

00:38:44.180 --> 00:38:50.350
that since we're creating our
product on top of two very

00:38:50.350 --> 00:38:53.800
powerful big data technologies,
we can go down

00:38:53.800 --> 00:38:56.750
to the single event
every single time.

00:38:56.750 --> 00:39:00.680
So adding features, slicing,
will be very,

00:39:00.680 --> 00:39:02.820
very easy in the future.

00:39:02.820 --> 00:39:07.580
I was imagining this to be more
loud than that, and I had

00:39:07.580 --> 00:39:08.640
a "Harlem Shake" here.

00:39:08.640 --> 00:39:10.191
["HARLEM SHAKE" PLAYING]

00:39:10.191 --> 00:39:13.490
LUCA MARTINETTI: Having the beat
in the real time on top

00:39:13.490 --> 00:39:15.880
of that, but you're
so shy, guys.

00:39:15.880 --> 00:39:18.324
I was imagining all banging
on their iPads.

00:39:18.324 --> 00:39:21.216
But that's fine.

00:39:27.200 --> 00:39:30.600
So this was asking new question,
asking custom

00:39:30.600 --> 00:39:35.510
question, to your data and try
to understand something.

00:39:35.510 --> 00:39:38.610
Credit for the game goes
to this guy here.

00:39:38.610 --> 00:39:40.730
Thank you.

00:39:40.730 --> 00:39:42.800
The last step will be change
something, having

00:39:42.800 --> 00:39:44.860
the option to react.

00:39:44.860 --> 00:39:47.200
Once you understand something,
change it.

00:39:47.200 --> 00:39:49.730
It can be a game design change
because you understand your

00:39:49.730 --> 00:39:52.720
players are stuck at a certain
level or spending too much

00:39:52.720 --> 00:39:57.460
time on a certain puzzle, or
it can be something like

00:39:57.460 --> 00:40:01.760
reengaging players for a
specific cohort or trying some

00:40:01.760 --> 00:40:05.750
hypothesis, like running a test
against a specific subset

00:40:05.750 --> 00:40:06.670
and see how it goes.

00:40:06.670 --> 00:40:10.820
This is something that I will
not show you today.

00:40:10.820 --> 00:40:14.530
We're launching our beta, so if
you're interested in trying

00:40:14.530 --> 00:40:17.260
Staq, please come talk to me.

00:40:17.260 --> 00:40:20.740
Thanks again for Google for
having us, and if you have any

00:40:20.740 --> 00:40:22.380
questions, we're
here to answer.

00:40:22.380 --> 00:40:23.220
Thank you.

00:40:23.220 --> 00:40:31.188
[APPLAUSE]

00:40:31.188 --> 00:40:32.950
LUCA MARTINETTI:
Any questions?

00:40:32.950 --> 00:40:34.600
MICHAEL MANOOCHEHRI: If you
guys have any questions,

00:40:34.600 --> 00:40:35.780
please come up to the
microphone so we

00:40:35.780 --> 00:40:38.965
can hear your question.

00:40:38.965 --> 00:40:40.930
LUCA MARTINETTI: No questions?

00:40:40.930 --> 00:40:41.620
OK.

00:40:41.620 --> 00:40:42.340
Was very clear?

00:40:42.340 --> 00:40:44.780
MICHAEL MANOOCHEHRI:
Yeah, I hope so.

00:40:44.780 --> 00:40:45.150
So great.

00:40:45.150 --> 00:40:46.970
So like you said, if you want
more information about either

00:40:46.970 --> 00:40:52.040
of these products, staq.io and
developers.google.com/bigquery.

00:40:52.040 --> 00:40:54.400
And it's easy to reach us there
as well, at least on the

00:40:54.400 --> 00:40:55.300
Google side.

00:40:55.300 --> 00:40:56.990
Join our Google+
page, the Cloud

00:40:56.990 --> 00:40:58.860
Platform Developers page.

00:40:58.860 --> 00:41:01.340
And we were asked to tell you
guys, please fill out your

00:41:01.340 --> 00:41:02.450
mobile survey feedback.

00:41:02.450 --> 00:41:04.390
The GDC is really interested
in that, as well.

00:41:07.160 --> 00:41:07.240
Great.

00:41:07.240 --> 00:41:09.550
We'll be up here until
the next session, so

00:41:09.550 --> 00:41:10.040
thank you very much.

00:41:10.040 --> 00:41:12.640
LUCA MARTINETTI: Just standing
and staring at you.

00:41:12.640 --> 00:41:13.890
No pressure.

