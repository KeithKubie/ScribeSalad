WEBVTT
Kind: captions
Language: en

00:00:05.200 --> 00:00:10.400
I think developments in artificial intelligence
do pose a strong challenge for humanity.

00:00:10.400 --> 00:00:16.960
I think at a very fundamental level people
don't quite understand what artificial intelligence

00:00:16.960 --> 00:00:22.090
is yet it's used as a buzzword that's going
to solve every single problem.

00:00:22.090 --> 00:00:28.101
You sort of have either the very binary sort
of treatment of - it's all wonderful, it's

00:00:28.101 --> 00:00:30.270
all great, and it's going to solve every problem.

00:00:30.270 --> 00:00:32.840
Or you have "robot armies are going to kill
everyone."

00:00:32.840 --> 00:00:38.180
I think the first challenge that we have is
even the vocabulary that we use to talk about

00:00:38.180 --> 00:00:43.750
developments in AI. see a lot of people in
Asia - and also elsewhere in the world to

00:00:43.750 --> 00:00:50.010
be fair - who use words like "algorithms,"
"big data," "analytics," "artificial intelligence,"

00:00:50.010 --> 00:00:52.340
to all mean pretty much the same thing.

00:00:52.340 --> 00:00:57.960
They use them as interchangeable synonyms,
and I think that does all of these technologies

00:00:57.960 --> 00:01:01.050
a disservice because they're not necessarily
the same thing.

00:01:01.050 --> 00:01:03.870
You can have automation that is not AI-driven.

00:01:03.870 --> 00:01:07.100
You can also have AI that is not just about
automation.

00:01:07.100 --> 00:01:14.110
So I think it's a technology or a set of technologies
that on some level are very very opaque and

00:01:14.110 --> 00:01:19.960
inscrutable, yet they're being talked about
as if it's the most common, obvious, everyday,

00:01:19.960 --> 00:01:21.270
ubiquitous thing.

00:01:21.270 --> 00:01:26.429
Really what we're trying to do is look at
the impact of AI, specifically on Asian countries,

00:01:26.429 --> 00:01:34.319
and I think even within Asia it's not a monolithic
thing of - "all of Asia is going to be treated

00:01:34.319 --> 00:01:36.329
the same way or is going to react the same
way."

00:01:36.329 --> 00:01:41.520
I think within Asia you have countries that
are going to be early adopters of AI, that

00:01:41.520 --> 00:01:45.149
are very geared up to advance technologies.

00:01:45.149 --> 00:01:52.360
So countries like Korea, Japan, Hong Kong,
Singapore are probably going to be a little

00:01:52.360 --> 00:01:53.360
better equipped.

00:01:53.360 --> 00:01:58.299
And I think a lot of the poorer developing,
emerging economies are not quite there yet.

00:01:58.299 --> 00:02:03.070
I don't think they quite understand what's
going to hit them, when it does.

00:02:03.070 --> 00:02:06.929
And I think there's a huge role for academia
to play in all of this.

00:02:06.929 --> 00:02:13.830
To make sure that in the way that it develops
that it's something that has an ethical backbone,

00:02:13.830 --> 00:02:18.579
that is implemented responsibly, that has
all the right stakeholders involved in the

00:02:18.579 --> 00:02:23.019
decisionmaking about how these technologies
are deployed.

00:02:23.019 --> 00:02:27.049
And I think that really needs to be a very,
very robust conversation.

00:02:27.049 --> 00:02:33.230
It's not the technology companies setting
the standards and governments and academics

00:02:33.230 --> 00:02:36.030
and social scientists having no say in how
this happens.

