WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:01.819
 
one of the most exciting developments

00:00:01.819 --> 00:00:01.829
one of the most exciting developments
 

00:00:01.829 --> 00:00:04.610
one of the most exciting developments
were sequences sequence models has been

00:00:04.610 --> 00:00:04.620
were sequences sequence models has been
 

00:00:04.620 --> 00:00:07.130
were sequences sequence models has been
the rise of very accurate speech

00:00:07.130 --> 00:00:07.140
the rise of very accurate speech
 

00:00:07.140 --> 00:00:09.740
the rise of very accurate speech
recognition we're nearing the end of the

00:00:09.740 --> 00:00:09.750
recognition we're nearing the end of the
 

00:00:09.750 --> 00:00:11.209
recognition we're nearing the end of the
course but I want to take just a couple

00:00:11.209 --> 00:00:11.219
course but I want to take just a couple
 

00:00:11.219 --> 00:00:13.999
course but I want to take just a couple
videos to give you a sense of how these

00:00:13.999 --> 00:00:14.009
videos to give you a sense of how these
 

00:00:14.009 --> 00:00:16.580
videos to give you a sense of how these
sequences sequence models are applied to

00:00:16.580 --> 00:00:16.590
sequences sequence models are applied to
 

00:00:16.590 --> 00:00:19.939
sequences sequence models are applied to
audio data such as to speech so what is

00:00:19.939 --> 00:00:19.949
audio data such as to speech so what is
 

00:00:19.949 --> 00:00:22.189
audio data such as to speech so what is
the speech recognition problem you're

00:00:22.189 --> 00:00:22.199
the speech recognition problem you're
 

00:00:22.199 --> 00:00:26.230
the speech recognition problem you're
given an audio clip X and your job is to

00:00:26.230 --> 00:00:26.240
given an audio clip X and your job is to
 

00:00:26.240 --> 00:00:30.099
given an audio clip X and your job is to
automatically find a text transcript Y

00:00:30.099 --> 00:00:30.109
automatically find a text transcript Y
 

00:00:30.109 --> 00:00:33.650
automatically find a text transcript Y
so an audio clip if you plot it looks

00:00:33.650 --> 00:00:33.660
so an audio clip if you plot it looks
 

00:00:33.660 --> 00:00:36.380
so an audio clip if you plot it looks
like this the horizontal axis here is

00:00:36.380 --> 00:00:36.390
like this the horizontal axis here is
 

00:00:36.390 --> 00:00:39.110
like this the horizontal axis here is
time and what a microphone does is it

00:00:39.110 --> 00:00:39.120
time and what a microphone does is it
 

00:00:39.120 --> 00:00:41.930
time and what a microphone does is it
really measures ministy changes in air

00:00:41.930 --> 00:00:41.940
really measures ministy changes in air
 

00:00:41.940 --> 00:00:44.840
really measures ministy changes in air
pressure and the way you're hearing my

00:00:44.840 --> 00:00:44.850
pressure and the way you're hearing my
 

00:00:44.850 --> 00:00:47.270
pressure and the way you're hearing my
voice right now is that your ear is

00:00:47.270 --> 00:00:47.280
voice right now is that your ear is
 

00:00:47.280 --> 00:00:49.459
voice right now is that your ear is
detecting little changes in air pressure

00:00:49.459 --> 00:00:49.469
detecting little changes in air pressure
 

00:00:49.469 --> 00:00:52.310
detecting little changes in air pressure
probably generated either by your

00:00:52.310 --> 00:00:52.320
probably generated either by your
 

00:00:52.320 --> 00:00:56.060
probably generated either by your
speakers or by a headset and then audio

00:00:56.060 --> 00:00:56.070
speakers or by a headset and then audio
 

00:00:56.070 --> 00:00:58.430
speakers or by a headset and then audio
clip like this plots you know basically

00:00:58.430 --> 00:00:58.440
clip like this plots you know basically
 

00:00:58.440 --> 00:01:03.439
clip like this plots you know basically
air pressure against time and if this

00:01:03.439 --> 00:01:03.449
air pressure against time and if this
 

00:01:03.449 --> 00:01:06.560
air pressure against time and if this
audio clip is of me saying the quick

00:01:06.560 --> 00:01:06.570
audio clip is of me saying the quick
 

00:01:06.570 --> 00:01:09.140
audio clip is of me saying the quick
brown fox then hopefully a speech

00:01:09.140 --> 00:01:09.150
brown fox then hopefully a speech
 

00:01:09.150 --> 00:01:11.120
brown fox then hopefully a speech
recognition algorithm can input that

00:01:11.120 --> 00:01:11.130
recognition algorithm can input that
 

00:01:11.130 --> 00:01:13.820
recognition algorithm can input that
audio clip and output that transcript

00:01:13.820 --> 00:01:13.830
audio clip and output that transcript
 

00:01:13.830 --> 00:01:16.429
audio clip and output that transcript
and because even the human ear doesn't

00:01:16.429 --> 00:01:16.439
and because even the human ear doesn't
 

00:01:16.439 --> 00:01:19.160
and because even the human ear doesn't
process raw waveforms but the human ear

00:01:19.160 --> 00:01:19.170
process raw waveforms but the human ear
 

00:01:19.170 --> 00:01:21.469
process raw waveforms but the human ear
has physical structures that measures

00:01:21.469 --> 00:01:21.479
has physical structures that measures
 

00:01:21.479 --> 00:01:24.380
has physical structures that measures
the amounts of intensity of different

00:01:24.380 --> 00:01:24.390
the amounts of intensity of different
 

00:01:24.390 --> 00:01:27.530
the amounts of intensity of different
frequencies there is a common

00:01:27.530 --> 00:01:27.540
frequencies there is a common
 

00:01:27.540 --> 00:01:30.260
frequencies there is a common
pre-processing step for audio data is to

00:01:30.260 --> 00:01:30.270
pre-processing step for audio data is to
 

00:01:30.270 --> 00:01:33.620
pre-processing step for audio data is to
run your raw audio clip and generate a

00:01:33.620 --> 00:01:33.630
run your raw audio clip and generate a
 

00:01:33.630 --> 00:01:36.260
run your raw audio clip and generate a
spectrogram so this is a plot where the

00:01:36.260 --> 00:01:36.270
spectrogram so this is a plot where the
 

00:01:36.270 --> 00:01:40.190
spectrogram so this is a plot where the
horizontal axis is time and the vertical

00:01:40.190 --> 00:01:40.200
horizontal axis is time and the vertical
 

00:01:40.200 --> 00:01:44.149
horizontal axis is time and the vertical
axis is frequencies and the intensity of

00:01:44.149 --> 00:01:44.159
axis is frequencies and the intensity of
 

00:01:44.159 --> 00:01:46.069
axis is frequencies and the intensity of
different colors shows the amount of

00:01:46.069 --> 00:01:46.079
different colors shows the amount of
 

00:01:46.079 --> 00:01:49.039
different colors shows the amount of
energy so how loud is the sound at

00:01:49.039 --> 00:01:49.049
energy so how loud is the sound at
 

00:01:49.049 --> 00:01:50.899
energy so how loud is the sound at
different frequencies at different times

00:01:50.899 --> 00:01:50.909
different frequencies at different times
 

00:01:50.909 --> 00:01:55.249
different frequencies at different times
and so these types of spectrograms

00:01:55.249 --> 00:01:55.259
and so these types of spectrograms
 

00:01:55.259 --> 00:01:57.020
and so these types of spectrograms
or you might also hear people talk about

00:01:57.020 --> 00:01:57.030
or you might also hear people talk about
 

00:01:57.030 --> 00:02:01.399
or you might also hear people talk about
filter Bank outputs is often commonly

00:02:01.399 --> 00:02:01.409
filter Bank outputs is often commonly
 

00:02:01.409 --> 00:02:03.709
filter Bank outputs is often commonly
applied pre-processing step before audio

00:02:03.709 --> 00:02:03.719
applied pre-processing step before audio
 

00:02:03.719 --> 00:02:06.310
applied pre-processing step before audio
is passed into a learning algorithm and

00:02:06.310 --> 00:02:06.320
is passed into a learning algorithm and
 

00:02:06.320 --> 00:02:10.639
is passed into a learning algorithm and
the human ear does a computation pretty

00:02:10.639 --> 00:02:10.649
the human ear does a computation pretty
 

00:02:10.649 --> 00:02:11.520
the human ear does a computation pretty
similar to the

00:02:11.520 --> 00:02:11.530
similar to the
 

00:02:11.530 --> 00:02:14.309
similar to the
pre-processing step so one of the most

00:02:14.309 --> 00:02:14.319
pre-processing step so one of the most
 

00:02:14.319 --> 00:02:17.190
pre-processing step so one of the most
exciting trends in speech recognition is

00:02:17.190 --> 00:02:17.200
exciting trends in speech recognition is
 

00:02:17.200 --> 00:02:20.550
exciting trends in speech recognition is
that once upon a time speech recognition

00:02:20.550 --> 00:02:20.560
that once upon a time speech recognition
 

00:02:20.560 --> 00:02:23.940
that once upon a time speech recognition
systems used to be built using phonemes

00:02:23.940 --> 00:02:23.950
systems used to be built using phonemes
 

00:02:23.950 --> 00:02:28.229
systems used to be built using phonemes
and these were I want to say hand

00:02:28.229 --> 00:02:28.239
and these were I want to say hand
 

00:02:28.239 --> 00:02:31.440
and these were I want to say hand
engineered basic units of sound so the

00:02:31.440 --> 00:02:31.450
engineered basic units of sound so the
 

00:02:31.450 --> 00:02:33.300
engineered basic units of sound so the
quick brown fox would be represented as

00:02:33.300 --> 00:02:33.310
quick brown fox would be represented as
 

00:02:33.310 --> 00:02:35.340
quick brown fox would be represented as
phonemes I'm going to simplify a bit but

00:02:35.340 --> 00:02:35.350
phonemes I'm going to simplify a bit but
 

00:02:35.350 --> 00:02:38.430
phonemes I'm going to simplify a bit but
you say there has a duck and sound and

00:02:38.430 --> 00:02:38.440
you say there has a duck and sound and
 

00:02:38.440 --> 00:02:42.720
you say there has a duck and sound and
quick as a cup and what a sound and

00:02:42.720 --> 00:02:42.730
quick as a cup and what a sound and
 

00:02:42.730 --> 00:02:45.360
quick as a cup and what a sound and
linguist used to write out these basic

00:02:45.360 --> 00:02:45.370
linguist used to write out these basic
 

00:02:45.370 --> 00:02:46.890
linguist used to write out these basic
units of sound and try the Greek

00:02:46.890 --> 00:02:46.900
units of sound and try the Greek
 

00:02:46.900 --> 00:02:49.470
units of sound and try the Greek
language down into these basic units of

00:02:49.470 --> 00:02:49.480
language down into these basic units of
 

00:02:49.480 --> 00:02:52.710
language down into these basic units of
cell so Brown right these aren't the

00:02:52.710 --> 00:02:52.720
cell so Brown right these aren't the
 

00:02:52.720 --> 00:02:54.870
cell so Brown right these aren't the
official phonemes which are written with

00:02:54.870 --> 00:02:54.880
official phonemes which are written with
 

00:02:54.880 --> 00:02:58.080
official phonemes which are written with
more complicated notation but but

00:02:58.080 --> 00:02:58.090
more complicated notation but but
 

00:02:58.090 --> 00:03:00.030
more complicated notation but but
linguist used to hypothesize that

00:03:00.030 --> 00:03:00.040
linguist used to hypothesize that
 

00:03:00.040 --> 00:03:02.729
linguist used to hypothesize that
writing down audio in terms of these

00:03:02.729 --> 00:03:02.739
writing down audio in terms of these
 

00:03:02.739 --> 00:03:04.890
writing down audio in terms of these
basic units of sound called phonemes

00:03:04.890 --> 00:03:04.900
basic units of sound called phonemes
 

00:03:04.900 --> 00:03:07.170
basic units of sound called phonemes
would be the best way to do speech

00:03:07.170 --> 00:03:07.180
would be the best way to do speech
 

00:03:07.180 --> 00:03:10.229
would be the best way to do speech
recognition but with end-to-end deep

00:03:10.229 --> 00:03:10.239
recognition but with end-to-end deep
 

00:03:10.239 --> 00:03:12.180
recognition but with end-to-end deep
learning we're finding that phony

00:03:12.180 --> 00:03:12.190
learning we're finding that phony
 

00:03:12.190 --> 00:03:14.910
learning we're finding that phony
representations are no longer necessary

00:03:14.910 --> 00:03:14.920
representations are no longer necessary
 

00:03:14.920 --> 00:03:18.270
representations are no longer necessary
but instead you can build systems that

00:03:18.270 --> 00:03:18.280
but instead you can build systems that
 

00:03:18.280 --> 00:03:20.720
but instead you can build systems that
input an audio clip and directly

00:03:20.720 --> 00:03:20.730
input an audio clip and directly
 

00:03:20.730 --> 00:03:22.890
input an audio clip and directly
outputting the transcript without

00:03:22.890 --> 00:03:22.900
outputting the transcript without
 

00:03:22.900 --> 00:03:25.560
outputting the transcript without
needing to use a hand engineer absent

00:03:25.560 --> 00:03:25.570
needing to use a hand engineer absent
 

00:03:25.570 --> 00:03:26.069
needing to use a hand engineer absent
ations

00:03:26.069 --> 00:03:26.079
ations
 

00:03:26.079 --> 00:03:29.009
ations
like these one of the things that made

00:03:29.009 --> 00:03:29.019
like these one of the things that made
 

00:03:29.019 --> 00:03:32.160
like these one of the things that made
this possible was going to much larger

00:03:32.160 --> 00:03:32.170
this possible was going to much larger
 

00:03:32.170 --> 00:03:36.690
this possible was going to much larger
data sense so so academic data sets on

00:03:36.690 --> 00:03:36.700
data sense so so academic data sets on
 

00:03:36.700 --> 00:03:40.590
data sense so so academic data sets on
speech recognition might be as a 300

00:03:40.590 --> 00:03:40.600
speech recognition might be as a 300
 

00:03:40.600 --> 00:03:44.340
speech recognition might be as a 300
hours and in academia of the thousand

00:03:44.340 --> 00:03:44.350
hours and in academia of the thousand
 

00:03:44.350 --> 00:03:47.190
hours and in academia of the thousand
our data sets of trance Drive audio

00:03:47.190 --> 00:03:47.200
our data sets of trance Drive audio
 

00:03:47.200 --> 00:03:49.259
our data sets of trance Drive audio
would be considered reasonable size so a

00:03:49.259 --> 00:03:49.269
would be considered reasonable size so a
 

00:03:49.269 --> 00:03:51.330
would be considered reasonable size so a
lot of research has been done a lot of

00:03:51.330 --> 00:03:51.340
lot of research has been done a lot of
 

00:03:51.340 --> 00:03:52.920
lot of research has been done a lot of
research papers have been written on

00:03:52.920 --> 00:03:52.930
research papers have been written on
 

00:03:52.930 --> 00:03:55.289
research papers have been written on
data sense there are several thousand

00:03:55.289 --> 00:03:55.299
data sense there are several thousand
 

00:03:55.299 --> 00:03:58.680
data sense there are several thousand
dollars but the best commercial systems

00:03:58.680 --> 00:03:58.690
dollars but the best commercial systems
 

00:03:58.690 --> 00:04:02.160
dollars but the best commercial systems
are now trained on over 10,000 hours and

00:04:02.160 --> 00:04:02.170
are now trained on over 10,000 hours and
 

00:04:02.170 --> 00:04:03.720
are now trained on over 10,000 hours and
sometimes over a hundred thousand

00:04:03.720 --> 00:04:03.730
sometimes over a hundred thousand
 

00:04:03.730 --> 00:04:07.259
sometimes over a hundred thousand
dollars of audio and is really moving to

00:04:07.259 --> 00:04:07.269
dollars of audio and is really moving to
 

00:04:07.269 --> 00:04:10.199
dollars of audio and is really moving to
much larger audio data set transcribe

00:04:10.199 --> 00:04:10.209
much larger audio data set transcribe
 

00:04:10.209 --> 00:04:13.440
much larger audio data set transcribe
audio DSS with both x and y together

00:04:13.440 --> 00:04:13.450
audio DSS with both x and y together
 

00:04:13.450 --> 00:04:15.780
audio DSS with both x and y together
with deep learning algorithms that has

00:04:15.780 --> 00:04:15.790
with deep learning algorithms that has
 

00:04:15.790 --> 00:04:17.670
with deep learning algorithms that has
driven a lot of progress in speech

00:04:17.670 --> 00:04:17.680
driven a lot of progress in speech
 

00:04:17.680 --> 00:04:20.969
driven a lot of progress in speech
recognition so how do you build a speech

00:04:20.969 --> 00:04:20.979
recognition so how do you build a speech
 

00:04:20.979 --> 00:04:23.790
recognition so how do you build a speech
recognition system in the last video we

00:04:23.790 --> 00:04:23.800
recognition system in the last video we
 

00:04:23.800 --> 00:04:25.250
recognition system in the last video we
talked about the attention

00:04:25.250 --> 00:04:25.260
talked about the attention
 

00:04:25.260 --> 00:04:28.220
talked about the attention
so one thing you could do is actually do

00:04:28.220 --> 00:04:28.230
so one thing you could do is actually do
 

00:04:28.230 --> 00:04:30.920
so one thing you could do is actually do
that where on the horizontal axis you

00:04:30.920 --> 00:04:30.930
that where on the horizontal axis you
 

00:04:30.930 --> 00:04:33.200
that where on the horizontal axis you
take in different time frames of the

00:04:33.200 --> 00:04:33.210
take in different time frames of the
 

00:04:33.210 --> 00:04:35.810
take in different time frames of the
audio input and then you have an

00:04:35.810 --> 00:04:35.820
audio input and then you have an
 

00:04:35.820 --> 00:04:37.700
audio input and then you have an
attention model we tried to output the

00:04:37.700 --> 00:04:37.710
attention model we tried to output the
 

00:04:37.710 --> 00:04:41.090
attention model we tried to output the
transcript like the quick brown fox or

00:04:41.090 --> 00:04:41.100
transcript like the quick brown fox or
 

00:04:41.100 --> 00:04:43.490
transcript like the quick brown fox or
whatever was said one other method that

00:04:43.490 --> 00:04:43.500
whatever was said one other method that
 

00:04:43.500 --> 00:04:46.220
whatever was said one other method that
seems to work well is to use the CDC

00:04:46.220 --> 00:04:46.230
seems to work well is to use the CDC
 

00:04:46.230 --> 00:04:48.680
seems to work well is to use the CDC
costs of speech recognition CT c stands

00:04:48.680 --> 00:04:48.690
costs of speech recognition CT c stands
 

00:04:48.690 --> 00:04:50.590
costs of speech recognition CT c stands
for connectionist temporal

00:04:50.590 --> 00:04:50.600
for connectionist temporal
 

00:04:50.600 --> 00:04:53.360
for connectionist temporal
classification and is due to Alex gray

00:04:53.360 --> 00:04:53.370
classification and is due to Alex gray
 

00:04:53.370 --> 00:04:55.880
classification and is due to Alex gray
San Diego Fernandez Faustina Gomez and

00:04:55.880 --> 00:04:55.890
San Diego Fernandez Faustina Gomez and
 

00:04:55.890 --> 00:04:58.010
San Diego Fernandez Faustina Gomez and
urine schmidhuber so here's the idea

00:04:58.010 --> 00:04:58.020
urine schmidhuber so here's the idea
 

00:04:58.020 --> 00:05:00.350
urine schmidhuber so here's the idea
let's say the audio clip was was of

00:05:00.350 --> 00:05:00.360
let's say the audio clip was was of
 

00:05:00.360 --> 00:05:03.260
let's say the audio clip was was of
someone saying the quick brown fox we're

00:05:03.260 --> 00:05:03.270
someone saying the quick brown fox we're
 

00:05:03.270 --> 00:05:05.660
someone saying the quick brown fox we're
going to use a we're going to use the

00:05:05.660 --> 00:05:05.670
going to use a we're going to use the
 

00:05:05.670 --> 00:05:07.670
going to use a we're going to use the
neural network structured like this with

00:05:07.670 --> 00:05:07.680
neural network structured like this with
 

00:05:07.680 --> 00:05:10.670
neural network structured like this with
an equal number of input X's and output

00:05:10.670 --> 00:05:10.680
an equal number of input X's and output
 

00:05:10.680 --> 00:05:13.580
an equal number of input X's and output
Y's and I've drawn a simple of one

00:05:13.580 --> 00:05:13.590
Y's and I've drawn a simple of one
 

00:05:13.590 --> 00:05:16.280
Y's and I've drawn a simple of one
uni-directional for only RNN for this

00:05:16.280 --> 00:05:16.290
uni-directional for only RNN for this
 

00:05:16.290 --> 00:05:18.860
uni-directional for only RNN for this
but in practice this will usually be a

00:05:18.860 --> 00:05:18.870
but in practice this will usually be a
 

00:05:18.870 --> 00:05:20.540
but in practice this will usually be a
bi-directional LS TM or bi-directional

00:05:20.540 --> 00:05:20.550
bi-directional LS TM or bi-directional
 

00:05:20.550 --> 00:05:24.080
bi-directional LS TM or bi-directional
gru and usually a deeper model but

00:05:24.080 --> 00:05:24.090
gru and usually a deeper model but
 

00:05:24.090 --> 00:05:26.180
gru and usually a deeper model but
notice that the number of time steps

00:05:26.180 --> 00:05:26.190
notice that the number of time steps
 

00:05:26.190 --> 00:05:29.180
notice that the number of time steps
here is very large and in speech

00:05:29.180 --> 00:05:29.190
here is very large and in speech
 

00:05:29.190 --> 00:05:31.730
here is very large and in speech
recognition usually the number of input

00:05:31.730 --> 00:05:31.740
recognition usually the number of input
 

00:05:31.740 --> 00:05:33.860
recognition usually the number of input
time steps is much bigger than the

00:05:33.860 --> 00:05:33.870
time steps is much bigger than the
 

00:05:33.870 --> 00:05:36.290
time steps is much bigger than the
number of output time steps so for

00:05:36.290 --> 00:05:36.300
number of output time steps so for
 

00:05:36.300 --> 00:05:38.600
number of output time steps so for
example if you have 10 seconds of audio

00:05:38.600 --> 00:05:38.610
example if you have 10 seconds of audio
 

00:05:38.610 --> 00:05:40.940
example if you have 10 seconds of audio
and your features come at a hundred

00:05:40.940 --> 00:05:40.950
and your features come at a hundred
 

00:05:40.950 --> 00:05:44.720
and your features come at a hundred
Hertz so under samples per second then a

00:05:44.720 --> 00:05:44.730
Hertz so under samples per second then a
 

00:05:44.730 --> 00:05:46.880
Hertz so under samples per second then a
10-second audio clip would end up with a

00:05:46.880 --> 00:05:46.890
10-second audio clip would end up with a
 

00:05:46.890 --> 00:05:49.820
10-second audio clip would end up with a
thousand inputs right so this 100 Hertz

00:05:49.820 --> 00:05:49.830
thousand inputs right so this 100 Hertz
 

00:05:49.830 --> 00:05:51.890
thousand inputs right so this 100 Hertz
times 10 seconds ends up with a thousand

00:05:51.890 --> 00:05:51.900
times 10 seconds ends up with a thousand
 

00:05:51.900 --> 00:05:55.100
times 10 seconds ends up with a thousand
inputs but your output might not have a

00:05:55.100 --> 00:05:55.110
inputs but your output might not have a
 

00:05:55.110 --> 00:05:57.260
inputs but your output might not have a
thousand alphabets might not have a

00:05:57.260 --> 00:05:57.270
thousand alphabets might not have a
 

00:05:57.270 --> 00:06:00.850
thousand alphabets might not have a
thousand characters so what did you do

00:06:00.850 --> 00:06:00.860
thousand characters so what did you do
 

00:06:00.860 --> 00:06:05.750
thousand characters so what did you do
the ctc cost function allows the RNN to

00:06:05.750 --> 00:06:05.760
the ctc cost function allows the RNN to
 

00:06:05.760 --> 00:06:09.560
the ctc cost function allows the RNN to
generate an output like this TTT does a

00:06:09.560 --> 00:06:09.570
generate an output like this TTT does a
 

00:06:09.570 --> 00:06:11.150
generate an output like this TTT does a
special character called a blank

00:06:11.150 --> 00:06:11.160
special character called a blank
 

00:06:11.160 --> 00:06:12.770
special character called a blank
character which in the writers are

00:06:12.770 --> 00:06:12.780
character which in the writers are
 

00:06:12.780 --> 00:06:18.200
character which in the writers are
underscore here each blank e-e-e blank

00:06:18.200 --> 00:06:18.210
underscore here each blank e-e-e blank
 

00:06:18.210 --> 00:06:22.820
underscore here each blank e-e-e blank
blank blank and then maybe a space right

00:06:22.820 --> 00:06:22.830
blank blank and then maybe a space right
 

00:06:22.830 --> 00:06:26.030
blank blank and then maybe a space right
like this so that's a space and then

00:06:26.030 --> 00:06:26.040
like this so that's a space and then
 

00:06:26.040 --> 00:06:34.700
like this so that's a space and then
blank blank blank QQ q blank blank and

00:06:34.700 --> 00:06:34.710
 
 

00:06:34.710 --> 00:06:38.210
 
this is considered a correct output for

00:06:38.210 --> 00:06:38.220
this is considered a correct output for
 

00:06:38.220 --> 00:06:41.540
this is considered a correct output for
the first part of the space quick with

00:06:41.540 --> 00:06:41.550
the first part of the space quick with
 

00:06:41.550 --> 00:06:44.629
the first part of the space quick with
the cue and the basic rule for the CTC

00:06:44.629 --> 00:06:44.639
the cue and the basic rule for the CTC
 

00:06:44.639 --> 00:06:46.909
the cue and the basic rule for the CTC
cost function is to collapse repeated

00:06:46.909 --> 00:06:46.919
cost function is to collapse repeated
 

00:06:46.919 --> 00:06:52.100
cost function is to collapse repeated
characters not separated by blank so to

00:06:52.100 --> 00:06:52.110
characters not separated by blank so to
 

00:06:52.110 --> 00:06:54.620
characters not separated by blank so to
be clearer I'm using this underscore to

00:06:54.620 --> 00:06:54.630
be clearer I'm using this underscore to
 

00:06:54.630 --> 00:06:57.290
be clearer I'm using this underscore to
denote the special blank character and

00:06:57.290 --> 00:06:57.300
denote the special blank character and
 

00:06:57.300 --> 00:07:00.200
denote the special blank character and
that's different than the space

00:07:00.200 --> 00:07:00.210
that's different than the space
 

00:07:00.210 --> 00:07:02.770
that's different than the space
character so there is a space here

00:07:02.770 --> 00:07:02.780
character so there is a space here
 

00:07:02.780 --> 00:07:05.749
character so there is a space here
between the and quick so I should upload

00:07:05.749 --> 00:07:05.759
between the and quick so I should upload
 

00:07:05.759 --> 00:07:09.140
between the and quick so I should upload
a space but by collapsing repeated

00:07:09.140 --> 00:07:09.150
a space but by collapsing repeated
 

00:07:09.150 --> 00:07:10.820
a space but by collapsing repeated
characters not separated by blank

00:07:10.820 --> 00:07:10.830
characters not separated by blank
 

00:07:10.830 --> 00:07:15.460
characters not separated by blank
it actually collapsed the sequence into

00:07:15.460 --> 00:07:15.470
 
 

00:07:15.470 --> 00:07:17.930
 
t-h-e

00:07:17.930 --> 00:07:17.940
t-h-e
 

00:07:17.940 --> 00:07:25.279
t-h-e
and then space and Q and this allows the

00:07:25.279 --> 00:07:25.289
and then space and Q and this allows the
 

00:07:25.289 --> 00:07:29.180
and then space and Q and this allows the
your network to have a thousand outputs

00:07:29.180 --> 00:07:29.190
your network to have a thousand outputs
 

00:07:29.190 --> 00:07:31.249
your network to have a thousand outputs
by repeating characters a lot of times

00:07:31.249 --> 00:07:31.259
by repeating characters a lot of times
 

00:07:31.259 --> 00:07:33.080
by repeating characters a lot of times
or inserting a bunch of blank characters

00:07:33.080 --> 00:07:33.090
or inserting a bunch of blank characters
 

00:07:33.090 --> 00:07:36.520
or inserting a bunch of blank characters
and still end up with a much shorter

00:07:36.520 --> 00:07:36.530
and still end up with a much shorter
 

00:07:36.530 --> 00:07:39.740
and still end up with a much shorter
output text transcript so this phrase

00:07:39.740 --> 00:07:39.750
output text transcript so this phrase
 

00:07:39.750 --> 00:07:41.570
output text transcript so this phrase
here the quick brown fox including

00:07:41.570 --> 00:07:41.580
here the quick brown fox including
 

00:07:41.580 --> 00:07:45.200
here the quick brown fox including
spaces as she has 19 characters and if

00:07:45.200 --> 00:07:45.210
spaces as she has 19 characters and if
 

00:07:45.210 --> 00:07:47.450
spaces as she has 19 characters and if
somehow the new network is forced

00:07:47.450 --> 00:07:47.460
somehow the new network is forced
 

00:07:47.460 --> 00:07:49.909
somehow the new network is forced
upwards of thousand characters by

00:07:49.909 --> 00:07:49.919
upwards of thousand characters by
 

00:07:49.919 --> 00:07:52.520
upwards of thousand characters by
allowing the network to insert blanks

00:07:52.520 --> 00:07:52.530
allowing the network to insert blanks
 

00:07:52.530 --> 00:07:54.110
allowing the network to insert blanks
and repeated characters and can still

00:07:54.110 --> 00:07:54.120
and repeated characters and can still
 

00:07:54.120 --> 00:07:56.750
and repeated characters and can still
represent this 19 character output which

00:07:56.750 --> 00:07:56.760
represent this 19 character output which
 

00:07:56.760 --> 00:08:02.029
represent this 19 character output which
is 1000 outputs values of Y so this

00:08:02.029 --> 00:08:02.039
is 1000 outputs values of Y so this
 

00:08:02.039 --> 00:08:05.360
is 1000 outputs values of Y so this
paper by Alex grace as well as by dues

00:08:05.360 --> 00:08:05.370
paper by Alex grace as well as by dues
 

00:08:05.370 --> 00:08:08.060
paper by Alex grace as well as by dues
deep speech speech recognition system

00:08:08.060 --> 00:08:08.070
deep speech speech recognition system
 

00:08:08.070 --> 00:08:11.270
deep speech speech recognition system
which I was involved in use this idea to

00:08:11.270 --> 00:08:11.280
which I was involved in use this idea to
 

00:08:11.280 --> 00:08:13.010
which I was involved in use this idea to
build effective speech recognition

00:08:13.010 --> 00:08:13.020
build effective speech recognition
 

00:08:13.020 --> 00:08:16.040
build effective speech recognition
systems so I hope that gives you a rough

00:08:16.040 --> 00:08:16.050
systems so I hope that gives you a rough
 

00:08:16.050 --> 00:08:18.950
systems so I hope that gives you a rough
sense of how speech recognition models

00:08:18.950 --> 00:08:18.960
sense of how speech recognition models
 

00:08:18.960 --> 00:08:22.070
sense of how speech recognition models
were attention line models work and CTC

00:08:22.070 --> 00:08:22.080
were attention line models work and CTC
 

00:08:22.080 --> 00:08:24.020
were attention line models work and CTC
models work and present two different

00:08:24.020 --> 00:08:24.030
models work and present two different
 

00:08:24.030 --> 00:08:26.089
models work and present two different
options for how to go about building

00:08:26.089 --> 00:08:26.099
options for how to go about building
 

00:08:26.099 --> 00:08:28.939
options for how to go about building
these systems now today building a

00:08:28.939 --> 00:08:28.949
these systems now today building a
 

00:08:28.949 --> 00:08:31.640
these systems now today building a
effective or a production scale speech

00:08:31.640 --> 00:08:31.650
effective or a production scale speech
 

00:08:31.650 --> 00:08:33.949
effective or a production scale speech
recognition system is a pretty

00:08:33.949 --> 00:08:33.959
recognition system is a pretty
 

00:08:33.959 --> 00:08:36.409
recognition system is a pretty
significant effort it requires a very

00:08:36.409 --> 00:08:36.419
significant effort it requires a very
 

00:08:36.419 --> 00:08:38.779
significant effort it requires a very
large data set but what I like to do in

00:08:38.779 --> 00:08:38.789
large data set but what I like to do in
 

00:08:38.789 --> 00:08:41.000
large data set but what I like to do in
the next video share of you how you can

00:08:41.000 --> 00:08:41.010
the next video share of you how you can
 

00:08:41.010 --> 00:08:43.670
the next video share of you how you can
build a trigger word detection system or

00:08:43.670 --> 00:08:43.680
build a trigger word detection system or
 

00:08:43.680 --> 00:08:45.650
build a trigger word detection system or
a keyword detection system which is

00:08:45.650 --> 00:08:45.660
a keyword detection system which is
 

00:08:45.660 --> 00:08:47.630
a keyword detection system which is
actually much easier and condemned

00:08:47.630 --> 00:08:47.640
actually much easier and condemned
 

00:08:47.640 --> 00:08:50.060
actually much easier and condemned
even a smaller or more reasonable amount

00:08:50.060 --> 00:08:50.070
even a smaller or more reasonable amount
 

00:08:50.070 --> 00:08:52.400
even a smaller or more reasonable amount
of data so let's talk about that in the

00:08:52.400 --> 00:08:52.410
of data so let's talk about that in the
 

00:08:52.410 --> 00:08:54.920
of data so let's talk about that in the
next video

