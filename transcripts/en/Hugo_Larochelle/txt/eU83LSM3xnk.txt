Speaker 1:          00:00          In this video, we'll discuss two other operations that are useful to have in a a convolutional neural network, full solving, harder object recognition problems. So the architecture that have been described so far where we have convolutional layers followed by a pooling layers and supplanting pulling sub sampling layers that alternate before we reach some output layer, uh, gives a neural network that actually works really well for somewhat simple problem like Henry [inaudible] character recognition. Uh, in fact, such architectures I've been used for reading, uh, checks in the u s uh, with a lot of success. Uh, but it turns out that when we apply it on a harder problem like object recognition of the type that we find in the Caltech one on one data set, for instance, uh, we have a lot of background variations and a lot of variations with respect to the appearance of the objects. Uh, and we have colored images and so on. It turns out that these types of networks actually perform, uh, not so well with this particular architecture. Uh, compared to other more standard approaches in computer vision. Uh, but to get better performance, we actually need to introduce to other operations, which we'll describe in this video.

Speaker 1:          01:21          The first operation is very simple. It's called the rectification layer. Uh, and it consists of taking the previous layer and just computing it's absolute value and that becomes the new layer. Uh, we will usually do this a rectification right after the convolutional layer operation. And one advantage that it has is that it introduces variants in Varian, sorry to the sign of the unit or the previous layer. And so, uh, for instance, if, uh, we have a feature map that computes the activation of something like, uh, you know, uh, uh, uh, filter of connections that looks something like this. So that's looking for a high intensity here and low intensity here. Um, well if we have an edge that if we applied this filter around the neck, which has high activation here and low activation here, it's actually going to have a large but negative sign when we performed the convolution and compute the pre activation. So by taking the absolute value, it means that we will now lose the information about whether the polarity of the edge was high intensity, low intensity or low intensity. High intensity will confuse the two. And if we think that detecting certain objects is actually in Varian to the polarity of the intensity of the pixels across edges, then this is a kind of operation that should be useful and for object where the actual color of the object might not be that informative. For instance, we can imagine something like this. This is actually useful.

Speaker 2:          03:04          Yeah.

Speaker 1:          03:05          And is, and the second operation we'll introduce is call a local contrast normalizations. So we have a layer that just computes that, uh, the local contrast normalization. I give the full equations here, but I think I'll just describe intuitively means, cause, uh, just the description should make it clear what, uh, it's performing. So we just take the previous input, uh, the previous layer, and then we subtract some local average, which is computed locally in some neighborhood and a, and we can also compute the average across the channels of the layer. So this is illustrated by this sort of,

Speaker 3:          03:45          uh, uh, little, uh, uh,

Speaker 1:          03:48          three Vq here, uh, that goes across the filter maps. So we might have a, an average debt is computer across,

Speaker 3:          03:56          uh, uh,

Speaker 1:          03:58          feature maps or I guess, uh, input channels. If we're considering this to be there, the previous layer, we training it as a input channels and then we just take the local average and subtract. So that's what I'm calling v I j. K. And then next we'll actually divided by a local standard deviation. So we are taking whatever value that we sent. Uh, we centered using this local average and then divided by e d a local standard deviation, which, so we just take our centered values. We take the squared, uh, use the same weighting that we use for the local averaging here. A, we take the sum of the squared and then, uh, applied the square root on top of the, of that song. Uh, so this, this is a standard deviation because we were taking the sum average of the square difference with the, uh, with the average. And it's local because it's only computed at some neighborhood index by p and Q here where we see that, yeah, applied the offset here. So we divide by that. The Max with C is just to make sure that if we have a standard deviation of zero, we don't actually divide by zero and, uh, get uh, uh, numerical problems.

Speaker 2:          05:11          Okay.

Speaker 1:          05:11          So, um, what this is doing is that, uh, it reduces the units activation if its neighbors in the local neighborhood, uh, are also very active. And so it sort of encouraging competition,

Speaker 3:          05:25          uh,

Speaker 1:          05:26          within a neighborhood of a, of a single feature map and or even the cross a feature map if we're allowing to take all local average across feature maps, then we actually also encouraging competition across feature maps so that these different features perhaps tried to, uh, learn instead things that are, uh, that are different. And, uh, one thing you can also do is that it can introduce some, a normalization which respect to local changes in the illumination because with essentially just change the scaling of the intensity of the pixels. And so by dividing by this, uh, um, at the standard deviation, we essentially get to cancel out the impact of the elimination, uh, in the computation of the original feature map. Okay. So that's another operation that's very useful for convolutional neural networks.

Speaker 1:          06:22          So these two operations here, uh, are usually introduced between the convolution and the pooling. So we introduced them right here and uh, to finish up other types of preprocessing that's useful directly on the images is to, well first convert them to gray scale. If we think that color information is not useful for detecting the objects were interested in detecting, um, often all the images are resized to the same economical size. So 150 by 150 something that's often used. And then we use zero panning for images that are not squared so that they cannot be. So when we're resizing one or respect the aspect ratio of the original image, so we apply some zero padding to get the same aspect ratio. Um, often we remove the intra image means. So the mean of the pixels within, they give an image and divide by the standard deviation. Also of that image. So that will also make us more invariant to eliminations, variations in the illumination in the images. And often we also applied local contrast normalization so that we get, uh, also, uh, some amount of invariance to local variation in the, um, in the elimination in the scene where the image was taken. So those are the other two types of layers that we often add as well as pre processing that are useful to get a good system. Uh, object recognition, object recognition system for using a convolutional neural network.