WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.460
[GOOGLE LOGO MUSIC PLAYING]

00:00:04.060 --> 00:00:05.310
JEROME DOCHEZ: Good afternoon.

00:00:05.310 --> 00:00:05.840
Welcome.

00:00:05.840 --> 00:00:07.410
My name is Jerome
Dochez, and I'm

00:00:07.410 --> 00:00:09.280
the build system lead at Google.

00:00:09.280 --> 00:00:09.780
LEO SEI: Hi.

00:00:09.780 --> 00:00:10.280
I'm Leo Sei.

00:00:10.280 --> 00:00:12.720
I'm a product manager
on the Android team.

00:00:12.720 --> 00:00:14.428
XAVIER DUCROHET: And
I'm Xavier Ducrohet.

00:00:14.428 --> 00:00:15.940
I'm a lead for the
developer tools.

00:00:15.940 --> 00:00:16.440
OK.

00:00:16.440 --> 00:00:19.220
Let's start with what
we worked on last year.

00:00:19.220 --> 00:00:22.720
So the very first thing
that we did was we've

00:00:22.720 --> 00:00:24.560
been working on
namespaced resources.

00:00:24.560 --> 00:00:26.970
Jerome and I actually
stood here last year.

00:00:26.970 --> 00:00:29.570
And we talked a lot about
namespaced resources.

00:00:29.570 --> 00:00:32.630
And sadly, it has
not shipped yet.

00:00:32.630 --> 00:00:34.520
We have gotten a lot
of feedback from you.

00:00:34.520 --> 00:00:35.870
And we're very happy for that.

00:00:35.870 --> 00:00:37.700
Thank you.

00:00:37.700 --> 00:00:41.520
And as we kept working on it,
we realized a couple of things.

00:00:41.520 --> 00:00:46.880
The first one is we needed more
features from Gradle in order

00:00:46.880 --> 00:00:51.210
to efficiently process ARs that
are not namespaced-enabled,

00:00:51.210 --> 00:00:53.950
but you still want to consume
in a namespaced module.

00:00:53.950 --> 00:00:55.700
So we've been working
with the Gradle team

00:00:55.700 --> 00:00:57.210
very closely over the last year.

00:00:57.210 --> 00:01:00.200
And we got that done, so
it's now available in Gradle.

00:01:00.200 --> 00:01:01.850
The second thing
that we realized

00:01:01.850 --> 00:01:05.030
is that Studio
needed a lot of work.

00:01:05.030 --> 00:01:08.060
Studio has its own
understanding of resources.

00:01:08.060 --> 00:01:10.430
It passes all your files
as you change them.

00:01:10.430 --> 00:01:11.970
It builds its own index.

00:01:11.970 --> 00:01:17.030
And that is used for code
completion, resource references

00:01:17.030 --> 00:01:19.380
for navigation, as
well as rendering.

00:01:19.380 --> 00:01:21.530
And so we needed to
update these to be

00:01:21.530 --> 00:01:24.440
able to handle both
the namespaced projects

00:01:24.440 --> 00:01:27.200
and non-namespaced projects.

00:01:27.200 --> 00:01:29.420
And then you're all
aware of Project Marble.

00:01:29.420 --> 00:01:31.490
In the last six months, we've
been working mostly on quality

00:01:31.490 --> 00:01:32.520
and not on new features.

00:01:32.520 --> 00:01:34.710
And so all of that
was put on hold.

00:01:34.710 --> 00:01:36.860
And so as soon as
Marble is done,

00:01:36.860 --> 00:01:39.050
then we'll keep working
on that, and we'll

00:01:39.050 --> 00:01:42.870
be able to hopefully ship
namespaced resources soon.

00:01:42.870 --> 00:01:45.440
In the meantime, we have
made some small improvements

00:01:45.440 --> 00:01:47.540
to the resource
pipeline processing.

00:01:47.540 --> 00:01:49.850
One of them, for example,
in library resources,

00:01:49.850 --> 00:01:52.940
we directly generate the
R class as class files

00:01:52.940 --> 00:01:54.650
rather than Java
code that needs to be

00:01:54.650 --> 00:01:59.510
compiled in order to reduce the
strain on the Java compilation.

00:01:59.510 --> 00:02:01.010
We have a few more
changes that have

00:02:01.010 --> 00:02:04.730
been going in master
very recently that we'll

00:02:04.730 --> 00:02:08.210
be shipping probably in 3.6.

00:02:08.210 --> 00:02:09.259
JEROME DOCHEZ: All right.

00:02:09.259 --> 00:02:11.134
Let's talk a little bit
about multi-threading

00:02:11.134 --> 00:02:13.030
in the Android Gradle plug-in.

00:02:13.030 --> 00:02:15.820
So for a few years,
we've encouraged users

00:02:15.820 --> 00:02:19.030
to go modular because
some modules can

00:02:19.030 --> 00:02:20.770
be built in parallel.

00:02:20.770 --> 00:02:22.270
That's true because
all interactions

00:02:22.270 --> 00:02:25.060
between some modules have
to be done through files.

00:02:25.060 --> 00:02:27.560
So there's no side
effects, no side channels.

00:02:27.560 --> 00:02:28.670
So it's really good.

00:02:28.670 --> 00:02:30.420
Unfortunately, that's
not true when you're

00:02:30.420 --> 00:02:31.890
talking about a single module.

00:02:31.890 --> 00:02:34.060
So basically what
happens is that Gradle

00:02:34.060 --> 00:02:37.540
has to run every single
task sequentially.

00:02:37.540 --> 00:02:40.690
So obviously, we've
tried to optimize things

00:02:40.690 --> 00:02:43.090
by using executive
services and trying

00:02:43.090 --> 00:02:46.000
to shard the implementation
of some of our tasks.

00:02:46.000 --> 00:02:49.360
But you know, it doesn't
really fix the entire issue.

00:02:49.360 --> 00:02:52.090
And on top of that, we
have executive services.

00:02:52.090 --> 00:02:54.430
Other plug-ins, they have
other executive services.

00:02:54.430 --> 00:02:57.140
[INAUDIBLE] has its
own executive services.

00:02:57.140 --> 00:03:00.280
So the result is that we tend
to overwhelm the build machines

00:03:00.280 --> 00:03:02.830
when we run builds, so
that's really not good.

00:03:02.830 --> 00:03:06.430
So to solve this problem,
we've worked with Gradle

00:03:06.430 --> 00:03:10.300
on a new API, which
is called the workers.

00:03:10.300 --> 00:03:13.060
The workers are
side effect free,

00:03:13.060 --> 00:03:15.820
because you have to basically
cellulize all the input

00:03:15.820 --> 00:03:17.910
parameters to every work item.

00:03:17.910 --> 00:03:19.990
And it's going to be
de-cellulized when the work

00:03:19.990 --> 00:03:21.470
item is going to execute.

00:03:21.470 --> 00:03:24.020
So that means that if you
change the parameters after you

00:03:24.020 --> 00:03:28.520
do the submission, the submittee
will never see those changes.

00:03:28.520 --> 00:03:31.330
So there is no side effect.

00:03:31.330 --> 00:03:34.360
Gradle can also
much better maintain

00:03:34.360 --> 00:03:38.460
the number of threads being
used and the workload so

00:03:38.460 --> 00:03:40.990
you sure that you're not going
to theoretically overwhelm

00:03:40.990 --> 00:03:42.670
the machine anymore.

00:03:42.670 --> 00:03:44.920
And on top of that,
it's relatively easy

00:03:44.920 --> 00:03:48.470
to retrofit clusters
to use workers.

00:03:48.470 --> 00:03:50.320
So we've been quite
busy doing this.

00:03:50.320 --> 00:03:52.690
But let's look at
how this impacts

00:03:52.690 --> 00:03:55.790
the build by using workers.

00:03:55.790 --> 00:03:57.620
So here we've got
a single module.

00:03:57.620 --> 00:03:59.770
It has three tasks,
A, and you've

00:03:59.770 --> 00:04:03.910
got B and C, which depends on
A. So on top of these graphics,

00:04:03.910 --> 00:04:06.550
it's what's happening today when
you don't use workers, right?

00:04:06.550 --> 00:04:07.967
So you've got the
three tasks that

00:04:07.967 --> 00:04:10.120
have to execute sequentially.

00:04:10.120 --> 00:04:12.790
Now, when you use
a worker, you can

00:04:12.790 --> 00:04:14.518
see that the task B
is spawning a worker,

00:04:14.518 --> 00:04:16.810
as soon as the worker is
being spawned, because there's

00:04:16.810 --> 00:04:18.860
no side effect
possible any longer,

00:04:18.860 --> 00:04:21.850
Gradle is capable of electing
a new task for execution.

00:04:21.850 --> 00:04:26.020
So here at Task C, you can start
executing on a different thread

00:04:26.020 --> 00:04:28.240
as the worker for
B is completing.

00:04:28.240 --> 00:04:29.710
So obviously, it's
very positive.

00:04:29.710 --> 00:04:34.570
Because T2 in this particular
case is much before T1.

00:04:34.570 --> 00:04:36.237
So now, if you do
more and more of this,

00:04:36.237 --> 00:04:37.737
you can imagine
that now it is going

00:04:37.737 --> 00:04:39.190
to be more and
more threads being

00:04:39.190 --> 00:04:41.680
used throughout the build.

00:04:41.680 --> 00:04:45.430
Unfortunately, you can end
up in a situation which

00:04:45.430 --> 00:04:46.930
is not exactly what you wanted.

00:04:46.930 --> 00:04:50.860
In particular, workers are
an implementation detail

00:04:50.860 --> 00:04:52.240
of your task implementation.

00:04:52.240 --> 00:04:55.000
So basically, that means
that there is no declaration.

00:04:55.000 --> 00:04:56.830
Gradle does not
know if your task is

00:04:56.830 --> 00:05:00.050
going to be using workers or if
it's not going to be workers.

00:05:00.050 --> 00:05:03.060
So it cannot select your
task just because it seems

00:05:03.060 --> 00:05:04.790
it's going to be faster.

00:05:04.790 --> 00:05:06.730
So in this particular
case, it decided

00:05:06.730 --> 00:05:09.880
to schedule Task C before
Task B. Nothing prevents it

00:05:09.880 --> 00:05:11.030
from doing that.

00:05:11.030 --> 00:05:12.820
And when that happened,
well, we fall back

00:05:12.820 --> 00:05:14.260
into where we started, really.

00:05:14.260 --> 00:05:16.390
Because the Task
C executed first,

00:05:16.390 --> 00:05:21.430
because there's no other
possible parallelism

00:05:21.430 --> 00:05:22.210
that can happen.

00:05:22.210 --> 00:05:24.740
The Task B will have to wait
for Task C to be finished.

00:05:24.740 --> 00:05:26.282
And then the workers
will be spawned.

00:05:26.282 --> 00:05:28.570
But at that point, there's
nothing less, nothing else

00:05:28.570 --> 00:05:29.110
to be run.

00:05:29.110 --> 00:05:31.750
So basically, you end up in
exactly the same situation

00:05:31.750 --> 00:05:32.720
as you started from.

00:05:32.720 --> 00:05:34.480
So it's not that great, right?

00:05:34.480 --> 00:05:40.030
So to fix this is basically
to switch all of your tasks

00:05:40.030 --> 00:05:41.590
to use workers.

00:05:41.590 --> 00:05:43.210
Because at that
point, if you go back

00:05:43.210 --> 00:05:46.300
to Task B being generated
or executed first,

00:05:46.300 --> 00:05:48.820
you can see that
the Task C being

00:05:48.820 --> 00:05:53.320
scheduled as soon as the
worker for the Task B starts.

00:05:53.320 --> 00:05:55.150
Because you have a
worker C, it really

00:05:55.150 --> 00:05:58.180
does not impact the
overall build time.

00:05:58.180 --> 00:06:03.010
But if Gradle decides that it
wants to schedule Task C first,

00:06:03.010 --> 00:06:06.040
you can see now
that the Task B will

00:06:06.040 --> 00:06:10.930
complete a lot earlier than
what we've seen before, right?

00:06:10.930 --> 00:06:14.830
So this is very
brief description.

00:06:14.830 --> 00:06:17.350
But basically, what is
important to realize

00:06:17.350 --> 00:06:21.790
is that, if you have yourself
tasks that you wrote,

00:06:21.790 --> 00:06:24.610
if you have yourself
a plug-in, you really,

00:06:24.610 --> 00:06:26.350
really should
consider switching all

00:06:26.350 --> 00:06:28.540
of your tasks to use workers.

00:06:28.540 --> 00:06:31.480
We have converted 90% of
the Gradle plug-in tasks

00:06:31.480 --> 00:06:32.570
to workers.

00:06:32.570 --> 00:06:35.160
So that means we are ready
to play well with each other

00:06:35.160 --> 00:06:36.160
and also with ourselves.

00:06:36.160 --> 00:06:39.370
Because we've seen that
as we were switching

00:06:39.370 --> 00:06:41.170
some of our tasks to
workers, we actually

00:06:41.170 --> 00:06:44.920
accelerated over all real
time, especially for projects

00:06:44.920 --> 00:06:47.320
that have a very few
number of modules,

00:06:47.320 --> 00:06:49.160
or even like a single module.

00:06:49.160 --> 00:06:52.960
So we can stop making
things small and parallel.

00:06:52.960 --> 00:06:57.130
Its on by default in 3.5, so
you don't have to do anything

00:06:57.130 --> 00:06:58.708
except if you use Kotlin.

00:06:58.708 --> 00:07:00.250
If you use Kotlin,
and in particular,

00:07:00.250 --> 00:07:03.130
if you use annotations
processors,

00:07:03.130 --> 00:07:06.610
you need to turn it
on for KAPT to be

00:07:06.610 --> 00:07:08.660
able to leverage the feature.

00:07:08.660 --> 00:07:10.910
I suspect it is going to be
on by default pretty soon.

00:07:10.910 --> 00:07:12.535
But so far, you have
to do it manually.

00:07:15.787 --> 00:07:16.620
XAVIER DUCROHET: OK.

00:07:16.620 --> 00:07:18.990
So one other thing
that we've worked a lot

00:07:18.990 --> 00:07:21.030
is artifact transform.

00:07:21.030 --> 00:07:26.040
So artifact transform-- our
way to process dependencies.

00:07:26.040 --> 00:07:28.030
During configuration
of a project,

00:07:28.030 --> 00:07:30.100
we don't have access to
the dependency graphs,

00:07:30.100 --> 00:07:31.960
so we don't know how
many artifacts you're

00:07:31.960 --> 00:07:34.620
going to be consuming
because it takes time

00:07:34.620 --> 00:07:36.090
to resolve the dependencies.

00:07:36.090 --> 00:07:41.910
And so we cannot create a per
task dependency task in case we

00:07:41.910 --> 00:07:45.660
want to process dependencies to
do extract ARs, or predicting,

00:07:45.660 --> 00:07:47.410
or things like that.

00:07:47.410 --> 00:07:50.220
So this is a new API that
was introduced, actually,

00:07:50.220 --> 00:07:53.770
a little while back that
we've been using since 3.0.

00:07:53.770 --> 00:07:56.070
We worked very closely
with Gradle again.

00:07:56.070 --> 00:07:58.230
And we've been using
that in 3.0 in order

00:07:58.230 --> 00:08:00.090
to extract AR in a
more efficient way

00:08:00.090 --> 00:08:01.820
than we used to do before.

00:08:01.820 --> 00:08:04.320
Unfortunately, the API
was not enough to enable

00:08:04.320 --> 00:08:08.180
us to do things like
predicting and desugaring.

00:08:08.180 --> 00:08:10.420
And there's a couple
of reasons for that.

00:08:10.420 --> 00:08:13.530
One of them, it did not to
allow incremental inputs.

00:08:13.530 --> 00:08:16.320
It did not really
support caching.

00:08:16.320 --> 00:08:19.320
And the other thing is that the
[INAUDIBLE] was not very good.

00:08:19.320 --> 00:08:23.730
It used to run just before
the output of the transform

00:08:23.730 --> 00:08:27.300
was needed, rather than
work as soon as the input

00:08:27.300 --> 00:08:29.230
of the transform was ready.

00:08:29.230 --> 00:08:31.280
So in terms of predicting,
that [INAUDIBLE]

00:08:31.280 --> 00:08:33.833
is going to give us
a lot of benefits.

00:08:33.833 --> 00:08:35.250
So we've been
starting to use that

00:08:35.250 --> 00:08:36.500
for predicting and desugaring.

00:08:36.500 --> 00:08:38.292
And I'm going to show
you a little bit what

00:08:38.292 --> 00:08:39.220
that looks like.

00:08:39.220 --> 00:08:42.090
So this is a Chrome
trace output.

00:08:42.090 --> 00:08:45.210
Jerome will talk about this
output in a little bit.

00:08:45.210 --> 00:08:47.220
And what we have
here is a project

00:08:47.220 --> 00:08:49.770
with about 100 modules
running on a machine

00:08:49.770 --> 00:08:51.240
with a lot of calls.

00:08:51.240 --> 00:08:53.490
And every little
square is basically

00:08:53.490 --> 00:08:55.915
a task happening in
one of the modules.

00:08:55.915 --> 00:08:58.290
And so what you can see here,
without artifact transform,

00:08:58.290 --> 00:09:00.670
is in order for us to
schedule predicting,

00:09:00.670 --> 00:09:04.050
we're going to have to wait
until all the modules are ready

00:09:04.050 --> 00:09:06.600
and have been built for
us to have a task that

00:09:06.600 --> 00:09:09.925
consume all of those
outputs and then start

00:09:09.925 --> 00:09:10.800
doing the predicting.

00:09:10.800 --> 00:09:13.540
And in fact, we do it with
indexing of the main app.

00:09:13.540 --> 00:09:16.140
And so you can see this
task here [INAUDIBLE],,

00:09:16.140 --> 00:09:18.960
that's taking a lot
of time, and also

00:09:18.960 --> 00:09:21.480
during a time where we can't
do that much processing.

00:09:21.480 --> 00:09:26.310
Because it's very at the end
of the project in the app, when

00:09:26.310 --> 00:09:28.330
all you're doing is
basically packaging,

00:09:28.330 --> 00:09:31.010
and text merging, and
doing a few things.

00:09:31.010 --> 00:09:33.810
So with transforms,
we can schedule that,

00:09:33.810 --> 00:09:36.330
or Gradle schedule that
for us much earlier.

00:09:36.330 --> 00:09:39.570
And as soon as a module
generates its [INAUDIBLE],,

00:09:39.570 --> 00:09:42.360
it can schedule the
predicting library.

00:09:42.360 --> 00:09:44.760
And it can be cached on its own.

00:09:44.760 --> 00:09:47.760
So you have much more
caching granularity

00:09:47.760 --> 00:09:51.060
because you don't cache
the whole task that

00:09:51.060 --> 00:09:52.530
does all the predicting.

00:09:52.530 --> 00:09:55.265
So just on this module,
on this project--

00:09:55.265 --> 00:09:56.640
sorry-- with 100
modules, you can

00:09:56.640 --> 00:09:58.620
see that a clean build
is improved by 15%

00:09:58.620 --> 00:10:01.983
by this introduction.

00:10:01.983 --> 00:10:03.900
Another thing that we've
been working on a lot

00:10:03.900 --> 00:10:05.168
is lazy task configuration.

00:10:05.168 --> 00:10:06.960
We've been working on
it for quite a while.

00:10:06.960 --> 00:10:10.430
But we've basically made
everything lazy, well, mostly.

00:10:10.430 --> 00:10:13.790
And we wanted to show you
the impact that it can have.

00:10:13.790 --> 00:10:16.080
So on the left side, you
have the same exact module,

00:10:16.080 --> 00:10:19.542
you know, 100 module projects.

00:10:19.542 --> 00:10:21.750
And you can see that if you
run it without lazy task,

00:10:21.750 --> 00:10:24.030
we configure almost
19,000 tasks.

00:10:24.030 --> 00:10:25.890
That's a lot of
tasks to configure.

00:10:25.890 --> 00:10:28.440
And on the right side
with the right flag on,

00:10:28.440 --> 00:10:31.590
we only configure about
3,000, 2,400 of which

00:10:31.590 --> 00:10:33.960
are actually needed
by the build.

00:10:33.960 --> 00:10:36.720
And there's a little bit
under 800 actually created

00:10:36.720 --> 00:10:37.230
[INAUDIBLE].

00:10:37.230 --> 00:10:39.832
This is a bug that we need
to fix in our plug-in.

00:10:39.832 --> 00:10:41.290
A few of them
actually are need it.

00:10:41.290 --> 00:10:42.850
Some of them are not.

00:10:42.850 --> 00:10:45.180
And when you look in
detail at the time,

00:10:45.180 --> 00:10:47.640
you can see that configuration
goes from 1.8 seconds

00:10:47.640 --> 00:10:49.860
to about one second.

00:10:49.860 --> 00:10:52.800
But then you also have
some of that time lost back

00:10:52.800 --> 00:10:54.600
in the graph calculation.

00:10:54.600 --> 00:10:56.400
So what's happening
is that, as Gradle

00:10:56.400 --> 00:10:59.040
build a task, graph of
all the tasks to execute,

00:10:59.040 --> 00:11:02.460
it realized that, well, it
needs to configure those.

00:11:02.460 --> 00:11:05.370
But overall, we are
still gaining about 25%

00:11:05.370 --> 00:11:07.010
configuration time
on this project.

00:11:10.783 --> 00:11:13.200
JEROME DOCHEZ: So another thing
that we talked about a lot

00:11:13.200 --> 00:11:16.530
last year was incremental
and additional processing.

00:11:16.530 --> 00:11:20.040
So again, with Gradle, we worked
on implementing and the ability

00:11:20.040 --> 00:11:22.410
to have incremental
compilation even when

00:11:22.410 --> 00:11:25.830
there is annotation
processors on the class pass.

00:11:25.830 --> 00:11:26.940
This has been delivered.

00:11:26.940 --> 00:11:30.642
So now we have the ability
to run incremental.

00:11:30.642 --> 00:11:32.850
Obviously, this is dependent
on annotation processors

00:11:32.850 --> 00:11:34.140
to play well.

00:11:34.140 --> 00:11:37.560
And here we have a list
of the top 10 annotation

00:11:37.560 --> 00:11:42.210
processors as we see being used
through our performance data.

00:11:42.210 --> 00:11:44.370
And we've already
converted six of them,

00:11:44.370 --> 00:11:47.410
and we're still working on
the four remaining ones.

00:11:47.410 --> 00:11:51.570
We will continue monitoring this
list of most used annotation

00:11:51.570 --> 00:11:53.430
processors, at least
open source ones.

00:11:53.430 --> 00:11:56.190
And we will try to convert
them as much as we can.

00:11:56.190 --> 00:11:57.690
But you have to
be careful, again,

00:11:57.690 --> 00:12:00.390
that if you have your own
annotation processors,

00:12:00.390 --> 00:12:05.010
it's very important that
you make the effort to make

00:12:05.010 --> 00:12:06.600
it incremental capable.

00:12:06.600 --> 00:12:09.850
Usually, it's not
very complicated.

00:12:09.850 --> 00:12:11.910
One thing that we also
did as part of this work

00:12:11.910 --> 00:12:15.360
is to make sure we blame
correctly the annotation

00:12:15.360 --> 00:12:17.850
processors which
are being configured

00:12:17.850 --> 00:12:21.810
and that are not incremental
capable so that if you are

00:12:21.810 --> 00:12:23.940
a provider of an
annotation processor,

00:12:23.940 --> 00:12:25.710
you will get-- start
in getting some,

00:12:25.710 --> 00:12:29.490
you know, maybe angry
emails from your users that,

00:12:29.490 --> 00:12:33.060
why is your annotation processor
not capable of handling

00:12:33.060 --> 00:12:36.698
incremental compilation yet?

00:12:36.698 --> 00:12:38.490
So if you see things
which are open source,

00:12:38.490 --> 00:12:39.450
please talk to the author.

00:12:39.450 --> 00:12:41.033
If you [INAUDIBLE]
which are in house,

00:12:41.033 --> 00:12:42.930
you will have to fix
it yourself, obviously.

00:12:42.930 --> 00:12:45.510
We also have a page on our
documentation that lists all

00:12:45.510 --> 00:12:48.480
of the annotation processors
that were converted on this

00:12:48.480 --> 00:12:51.300
list-- there are some other ones
which are not in the top 10--

00:12:51.300 --> 00:12:52.830
the version at
which they started

00:12:52.830 --> 00:12:54.990
being incremental capable.

00:12:54.990 --> 00:12:58.927
And we also list the ones
in the plans that we have.

00:12:58.927 --> 00:13:00.510
Feel free to send
us email if you want

00:13:00.510 --> 00:13:01.635
us to add some stuff there.

00:13:01.635 --> 00:13:04.320
But it's basically the reference
about what's available today.

00:13:07.580 --> 00:13:11.050
And since we are at it, we
also added support for Kotlin,

00:13:11.050 --> 00:13:11.720
obviously.

00:13:11.720 --> 00:13:15.130
So now if you use Kotlin and
you have annotation processors,

00:13:15.130 --> 00:13:19.450
we also have the ability to
run KAPT in incremental mode.

00:13:19.450 --> 00:13:22.060
It's dependent, obviously, on
the same annotation processors

00:13:22.060 --> 00:13:25.030
being incremental, but as
you can see on those graphs,

00:13:25.030 --> 00:13:27.260
the numbers are
pretty impressive.

00:13:27.260 --> 00:13:30.430
We are really continuing to
push forward incrementality

00:13:30.430 --> 00:13:33.250
as being a very important
feature of the Kotlin plug-in.

00:13:35.827 --> 00:13:36.660
XAVIER DUCROHET: OK.

00:13:36.660 --> 00:13:38.340
So one other thing
that we did is

00:13:38.340 --> 00:13:40.830
we tried to improve
the performance of sync

00:13:40.830 --> 00:13:41.820
inside Studio.

00:13:41.820 --> 00:13:45.030
A lot of the time spent when
you import a project is actually

00:13:45.030 --> 00:13:46.690
spent in Gradle.

00:13:46.690 --> 00:13:49.557
And so if you look at the
old thing that we had before,

00:13:49.557 --> 00:13:52.140
the first thing that we need to
do is build that model, right?

00:13:52.140 --> 00:13:55.320
We need to query Gradle in order
to know which module you have,

00:13:55.320 --> 00:13:57.150
what are the
properties, and what's

00:13:57.150 --> 00:13:59.620
the dependency between module
and external libraries?

00:13:59.620 --> 00:14:03.832
And so we have to call Gradle,
which configure the projects.

00:14:03.832 --> 00:14:05.040
Because we need dependencies.

00:14:05.040 --> 00:14:06.430
We resolve the dependency.

00:14:06.430 --> 00:14:08.900
And then we query that model.

00:14:08.900 --> 00:14:12.330
The model query is
actually very quick.

00:14:12.330 --> 00:14:15.370
And then, well, Android relies
a lot on generated source code,

00:14:15.370 --> 00:14:15.930
right?

00:14:15.930 --> 00:14:19.630
Your R class, AIDL,
[INAUDIBLE] script.

00:14:19.630 --> 00:14:22.470
So we always call into another
build that configures again,

00:14:22.470 --> 00:14:24.570
resolve dependency, and
then run some tests.

00:14:24.570 --> 00:14:27.240
So we worked closely
again with Gradle

00:14:27.240 --> 00:14:29.640
in order to contribute
some changes to the tooling

00:14:29.640 --> 00:14:32.240
API of Gradle in order to be
able to do both in the same

00:14:32.240 --> 00:14:32.740
build.

00:14:32.740 --> 00:14:34.770
So now we can do only
one single configuration.

00:14:34.770 --> 00:14:36.770
We can do one
dependency resolution.

00:14:36.770 --> 00:14:37.770
Then we query the model.

00:14:37.770 --> 00:14:39.210
And during the
query of the model,

00:14:39.210 --> 00:14:42.810
as we query it and we process
it inside our plug-in,

00:14:42.810 --> 00:14:44.610
we accumulate the
list of tasks that

00:14:44.610 --> 00:14:48.150
represent generating sources,
and then we scatter them,

00:14:48.150 --> 00:14:50.640
and then Gradle
will run them after.

00:14:50.640 --> 00:14:51.810
We also did a change here.

00:14:51.810 --> 00:14:56.230
Because Studio now is able to
create virtual classes for R,

00:14:56.230 --> 00:14:56.730
right?

00:14:56.730 --> 00:14:59.430
So as I mentioned
earlier, Studio

00:14:59.430 --> 00:15:03.160
is passing your resource
file as you edit them.

00:15:03.160 --> 00:15:04.900
And it always knows
what's going on.

00:15:04.900 --> 00:15:06.750
And so it's creating
some virtual R classes

00:15:06.750 --> 00:15:09.000
so that it doesn't have
to rely on the build.

00:15:09.000 --> 00:15:10.560
So if you add a
string to your file,

00:15:10.560 --> 00:15:12.893
you don't have to build in
order to update your R class.

00:15:12.893 --> 00:15:14.910
It's just on virtually for you.

00:15:14.910 --> 00:15:18.480
And so since we do that, we
don't have to build it anymore.

00:15:18.480 --> 00:15:21.190
So as you're seeing
the post-sync build,

00:15:21.190 --> 00:15:24.003
which is now integrated, it
just does not run that task.

00:15:24.003 --> 00:15:25.920
And therefore, you have
a faster sync as well.

00:15:30.407 --> 00:15:31.990
LEO SEI: So another
thing we launched,

00:15:31.990 --> 00:15:34.450
as you may have heard,
is apply changes.

00:15:34.450 --> 00:15:36.940
And this enables you
to make small edits

00:15:36.940 --> 00:15:39.870
and deploy while keeping
your app in its state.

00:15:39.870 --> 00:15:41.830
It's actually pretty
fast because it does not

00:15:41.830 --> 00:15:43.780
restart the app.

00:15:43.780 --> 00:15:47.400
But unlike Instant Run,
which some of you may know,

00:15:47.400 --> 00:15:49.270
it does not modify the build.

00:15:49.270 --> 00:15:52.090
Instead, it really finds
the classes on the fly

00:15:52.090 --> 00:15:54.310
and use some new
runtime instrumentation

00:15:54.310 --> 00:15:56.698
from the platform.

00:15:56.698 --> 00:15:58.990
Because it depends on this
new runtime instrumentation,

00:15:58.990 --> 00:16:04.360
it's only available for devices
running Android 8 and above.

00:16:04.360 --> 00:16:06.610
It works best when you're
making really small changes

00:16:06.610 --> 00:16:10.150
inside a class or making
small edit to our resources.

00:16:10.150 --> 00:16:11.710
But as you may have
heard from Tour

00:16:11.710 --> 00:16:15.190
earlier today, this project also
brought a lot of improvement

00:16:15.190 --> 00:16:15.970
for every build.

00:16:19.900 --> 00:16:22.290
We also looked at the
build output window

00:16:22.290 --> 00:16:24.240
and tried to improve it.

00:16:24.240 --> 00:16:27.420
We improved the UI and
also the underlying parser

00:16:27.420 --> 00:16:29.370
to really make sure
that all of your

00:16:29.370 --> 00:16:33.810
build errors show up as
a node in this window.

00:16:33.810 --> 00:16:35.940
We extract the
relevant information

00:16:35.940 --> 00:16:38.550
to make sure that you have
a file information, line

00:16:38.550 --> 00:16:41.320
pointers, the
details on the error.

00:16:41.320 --> 00:16:44.670
And we improved the UI a
little bit to expand the tree,

00:16:44.670 --> 00:16:48.270
scroll, and select the
error node automatically.

00:16:48.270 --> 00:16:49.980
This is a small
change, but we hope

00:16:49.980 --> 00:16:51.484
it will make your life easier.

00:16:51.484 --> 00:16:53.180
[APPLAUSE]

00:16:53.180 --> 00:16:54.900
So as you can see, we've been--

00:16:54.900 --> 00:16:56.730
yeah, go for build
output window.

00:16:59.832 --> 00:17:01.540
So as you can see,
we've been pretty busy

00:17:01.540 --> 00:17:05.140
adding a lot of new stuff
to the build system.

00:17:05.140 --> 00:17:09.400
But I cannot talk about build
without mentioning build speed.

00:17:09.400 --> 00:17:11.560
So let me deep dive
into this a bit,

00:17:11.560 --> 00:17:15.579
because it's really one
of our top priorities.

00:17:15.579 --> 00:17:17.890
First, let me set the stage.

00:17:17.890 --> 00:17:19.510
To measure build
speed internally,

00:17:19.510 --> 00:17:21.160
we use a set of benchmarks.

00:17:21.160 --> 00:17:24.130
We use some open source project,
like Santa Tracker minSDK

00:17:24.130 --> 00:17:27.819
15 and 28 for multi-dexing,
and another one

00:17:27.819 --> 00:17:30.250
called Tachyomi and Signal.

00:17:30.250 --> 00:17:32.930
But those are small-ish.

00:17:32.930 --> 00:17:35.620
So we really wanted to
test on large projects.

00:17:35.620 --> 00:17:39.400
So we generated two projects,
one with about 100 modules,

00:17:39.400 --> 00:17:43.630
97 to be precise, and 50
of everything per module--

00:17:43.630 --> 00:17:47.260
so 50 classes, 50
layouts, et cetera.

00:17:47.260 --> 00:17:51.220
We also created an equivalent
project of the same size

00:17:51.220 --> 00:17:54.760
but all squeezed
into one module.

00:17:54.760 --> 00:17:59.722
And both of those projects
have 200 external dependencies.

00:17:59.722 --> 00:18:01.930
And every time we make a
change to the build plug-in,

00:18:01.930 --> 00:18:05.420
we run those projects
on various scenarios.

00:18:05.420 --> 00:18:09.180
So let me walk you
through some of those.

00:18:09.180 --> 00:18:11.070
One scenario is to
make a code change.

00:18:11.070 --> 00:18:14.652
So we change a little bit of
code and rebuild the project.

00:18:14.652 --> 00:18:16.110
On the open source
project, you can

00:18:16.110 --> 00:18:20.760
see some improvement ranging
from 24% to 36% improvement,

00:18:20.760 --> 00:18:26.650
between 3.1 and 3.5.

00:18:26.650 --> 00:18:29.780
When we looked at the
two very large projects--

00:18:29.780 --> 00:18:31.000
and here the legend is large.

00:18:31.000 --> 00:18:32.890
100 is the one with
the 100 module,

00:18:32.890 --> 00:18:34.660
and large one is the
one where everything

00:18:34.660 --> 00:18:37.010
is squeezed into one module.

00:18:37.010 --> 00:18:41.860
You can see that we improved
by between 50% and 80%.

00:18:41.860 --> 00:18:45.740
In other words, here we
divided the build speed by two

00:18:45.740 --> 00:18:48.340
on the large project
with a lot of modules

00:18:48.340 --> 00:18:52.600
and by five on the
single module one.

00:18:52.600 --> 00:18:56.260
The big improvement in 3.4
here is largely related

00:18:56.260 --> 00:18:58.910
to the javac incrementality
that was added--

00:18:58.910 --> 00:19:01.340
or that was improved.

00:19:01.340 --> 00:19:01.840
All right.

00:19:01.840 --> 00:19:04.510
Another scenario we ran is
making change to resources,

00:19:04.510 --> 00:19:06.650
because that happens.

00:19:06.650 --> 00:19:08.990
And so here again on
the open source project,

00:19:08.990 --> 00:19:11.215
we can see improvement
ranging from 26% to 53%.

00:19:14.970 --> 00:19:17.110
And in the large
project, we also

00:19:17.110 --> 00:19:21.190
see good improvements
ranging in the 30-ish%.

00:19:21.190 --> 00:19:24.640
So those are two important
scenarios, editing a source

00:19:24.640 --> 00:19:25.780
code or editing resources.

00:19:25.780 --> 00:19:29.110
There's others that we ran on.

00:19:29.110 --> 00:19:30.610
And when you aggregate
the scenarios

00:19:30.610 --> 00:19:33.070
that I just showed
you, we saw an average

00:19:33.070 --> 00:19:38.940
build speed improvement
by 35% between 3.1 and 35.

00:19:38.940 --> 00:19:39.440
All right.

00:19:39.440 --> 00:19:41.050
So so far we're happy,

00:19:41.050 --> 00:19:45.760
But-- but-- we also look
at real build speed.

00:19:45.760 --> 00:19:50.030
That's the one that's
experienced by all of you.

00:19:50.030 --> 00:19:52.480
And we do this by aggregating
data out of all of you

00:19:52.480 --> 00:19:54.790
or the ones of you
that share with us

00:19:54.790 --> 00:19:57.438
when you opt into sharing
usage statistics with us.

00:19:57.438 --> 00:19:58.730
And so here's a shameless plug.

00:19:58.730 --> 00:20:00.950
If you do not, please opt in.

00:20:00.950 --> 00:20:02.920
It's aggregated and
it helps us a ton.

00:20:02.920 --> 00:20:05.840
And it's in the system settings.

00:20:05.840 --> 00:20:08.140
So when we aggregate
those data, we

00:20:08.140 --> 00:20:10.510
see that the median
build speed increased

00:20:10.510 --> 00:20:15.300
by 25% in the last year-ish.

00:20:15.300 --> 00:20:17.250
Note, though, that
this is not really

00:20:17.250 --> 00:20:20.160
showing the improvement from
3.4, which just went stable

00:20:20.160 --> 00:20:22.530
a couple of weeks
ago, as well as 3.5,

00:20:22.530 --> 00:20:24.818
which just went beta yesterday.

00:20:28.433 --> 00:20:30.100
So now I show you
some graph going down,

00:20:30.100 --> 00:20:31.440
some graph going up.

00:20:31.440 --> 00:20:33.730
You may start wondering why.

00:20:33.730 --> 00:20:36.490
Well, the reason is that, while
our benchmark projects are

00:20:36.490 --> 00:20:40.675
pretty static, your real
projects are growing.

00:20:40.675 --> 00:20:41.800
You're adding line of code.

00:20:41.800 --> 00:20:42.717
You're adding feeders.

00:20:42.717 --> 00:20:44.442
You're adding new
Gradle plug-in.

00:20:44.442 --> 00:20:46.150
And this growth impacts
your build speed.

00:20:48.952 --> 00:20:50.410
So if you're trying
to reconciliate

00:20:50.410 --> 00:20:52.250
this graph's going down
and up, let me walk you

00:20:52.250 --> 00:20:53.500
through a real life example.

00:20:56.510 --> 00:20:59.470
Looking at Spotify, in
the last year and a half,

00:20:59.470 --> 00:21:01.750
the project grew
by 25% when you're

00:21:01.750 --> 00:21:08.200
looking at line of code and
230% when looking at modules.

00:21:08.200 --> 00:21:10.450
That's about 3x the growth
in a year and a half.

00:21:10.450 --> 00:21:12.410
It's huge.

00:21:12.410 --> 00:21:14.740
At the same time, clean
builds slowed down by 38%.

00:21:17.540 --> 00:21:19.750
So I'm going to normalize
using line of code growth.

00:21:19.750 --> 00:21:22.660
And it's still a slow
down by 10% on build--

00:21:22.660 --> 00:21:23.410
not great.

00:21:23.410 --> 00:21:24.830
I admit it.

00:21:24.830 --> 00:21:27.208
This shows some of
the current limits

00:21:27.208 --> 00:21:29.500
that our pipeline have when
we're dealing with hundreds

00:21:29.500 --> 00:21:31.810
and hundreds of
modules, especially

00:21:31.810 --> 00:21:33.250
around resource pipeline.

00:21:33.250 --> 00:21:35.840
But it's something
we're working on.

00:21:35.840 --> 00:21:38.890
And note, also, here that
this is not showing anything

00:21:38.890 --> 00:21:44.080
from 3.4 and 3.5.

00:21:44.080 --> 00:21:46.450
But the clean build doesn't
necessarily represent

00:21:46.450 --> 00:21:48.760
your day-to-day builds.

00:21:48.760 --> 00:21:50.410
When you build
multiple times a day,

00:21:50.410 --> 00:21:54.720
hopefully a lot of those
builds are incremental.

00:21:54.720 --> 00:21:58.660
And so if you look again at
the Spotify change, the Spotify

00:21:58.660 --> 00:22:04.330
project, the incremental build
actually got faster by 37%.

00:22:04.330 --> 00:22:07.850
And if I normalize again on
the growth from line of code,

00:22:07.850 --> 00:22:10.150
it was actually 2 times faster--

00:22:10.150 --> 00:22:11.185
not too bad.

00:22:11.185 --> 00:22:14.140
It actually shows that
making sure everything that

00:22:14.140 --> 00:22:18.335
can be incremental actually
is is really important.

00:22:21.660 --> 00:22:24.380
And as I've mentioned, when
we add cachability to the mix,

00:22:24.380 --> 00:22:25.765
it's even better.

00:22:25.765 --> 00:22:27.890
And so what you see here,
with a lot of improvement

00:22:27.890 --> 00:22:30.520
we made to cachability
to the task,

00:22:30.520 --> 00:22:34.610
the Spotify build cached
this time improved by 50%

00:22:34.610 --> 00:22:36.500
while the project was growing.

00:22:36.500 --> 00:22:39.620
So again, to normalize with
the gross of line of code,

00:22:39.620 --> 00:22:42.682
that's about three times
faster if their project had not

00:22:42.682 --> 00:22:43.640
grown in the same time.

00:22:47.430 --> 00:22:49.490
So hopefully all
those graphs show you

00:22:49.490 --> 00:22:52.280
that we are working
very hard to keep

00:22:52.280 --> 00:22:56.550
improving build speed and
help you get more productive.

00:22:56.550 --> 00:22:59.750
And the first and best tip
to get your build speed down

00:22:59.750 --> 00:23:03.950
is to upgrade to the latest
Android Gradle plug-in version.

00:23:03.950 --> 00:23:06.350
But we know we still
have a lot of work

00:23:06.350 --> 00:23:09.260
to do, mainly around
configuration time, resource

00:23:09.260 --> 00:23:12.140
processing, especially as I
mentioned on those projects

00:23:12.140 --> 00:23:15.080
with lots and lots of
modules, and continue

00:23:15.080 --> 00:23:16.490
to improve parallelism.

00:23:19.740 --> 00:23:21.330
But that's not all.

00:23:21.330 --> 00:23:25.140
We know that many of you
use additional custom Gradle

00:23:25.140 --> 00:23:26.370
plug-in.

00:23:26.370 --> 00:23:28.840
And we want to help there, too.

00:23:28.840 --> 00:23:31.590
So for that, we're working
on a build speed attribution

00:23:31.590 --> 00:23:33.900
tool in Android Studio.

00:23:33.900 --> 00:23:36.510
The goal is to help you
understand which plug-in

00:23:36.510 --> 00:23:40.560
and which task are actually
affecting your build speed most

00:23:40.560 --> 00:23:42.368
and what you can do about it.

00:23:42.368 --> 00:23:44.910
Because sometimes you're using
a plug-in that we don't write.

00:23:44.910 --> 00:23:48.450
So we want to help you tell
the plug-in owner, if it's

00:23:48.450 --> 00:23:50.520
you or someone else,
what's going wrong

00:23:50.520 --> 00:23:52.740
and what they can do to help.

00:23:52.740 --> 00:23:55.050
And this will be in
Android Studio very soon.

00:23:57.315 --> 00:23:58.440
XAVIER DUCROHET: All right.

00:23:58.440 --> 00:24:01.800
So we're going to talk about
some tips and some tools

00:24:01.800 --> 00:24:04.740
about helping you better
configure your project.

00:24:04.740 --> 00:24:06.240
So the first thing
I want to mention

00:24:06.240 --> 00:24:09.180
is that configuration
should really be fast.

00:24:09.180 --> 00:24:12.660
I talked to developers a lot,
with developers telling me

00:24:12.660 --> 00:24:15.998
that the configuration
is fairly slow.

00:24:15.998 --> 00:24:17.790
I actually talked to
a developer just today

00:24:17.790 --> 00:24:21.480
telling me 150 module, almost
10 second configuration.

00:24:21.480 --> 00:24:23.460
And this is really
not in line with what

00:24:23.460 --> 00:24:24.430
the baseline should be.

00:24:24.430 --> 00:24:24.930
All right.

00:24:24.930 --> 00:24:26.710
So we wanted to
look at, how fast

00:24:26.710 --> 00:24:28.260
should configuration should be?

00:24:28.260 --> 00:24:30.630
So using the same
project, a project that's

00:24:30.630 --> 00:24:34.285
about 100 modules,
and those modules

00:24:34.285 --> 00:24:35.910
don't do a lot of
configuration, right?

00:24:35.910 --> 00:24:37.785
There's only one plug-in,
the Android plugin.

00:24:37.785 --> 00:24:40.175
And it mostly set up some
dependencies and nothing else.

00:24:40.175 --> 00:24:42.300
So when we look at
configuration using build scans,

00:24:42.300 --> 00:24:44.220
we see that the
configuration takes

00:24:44.220 --> 00:24:48.450
about a second, which adds
up to about 10 milliseconds

00:24:48.450 --> 00:24:49.390
per module.

00:24:49.390 --> 00:24:51.967
Now, of course, the task graph
computation is there, too.

00:24:51.967 --> 00:24:53.550
But depending on
what you're building,

00:24:53.550 --> 00:24:55.140
you may not do all of it.

00:24:55.140 --> 00:24:58.830
But here, for large, for
building the whole app,

00:24:58.830 --> 00:25:02.140
we see about under two
second configuration.

00:25:02.140 --> 00:25:05.820
So if you have 200 modules,
you should see four seconds.

00:25:05.820 --> 00:25:08.980
If you're already seeing 5,
10 seconds, and you have 10,

00:25:08.980 --> 00:25:11.610
20 modules, clearly
something's happening.

00:25:11.610 --> 00:25:15.030
And it's actually hard
right now to figure out

00:25:15.030 --> 00:25:16.590
exactly what's happening.

00:25:16.590 --> 00:25:18.330
But be aware that
basically every code

00:25:18.330 --> 00:25:21.060
that you put in your DSL,
all right, because it's code,

00:25:21.060 --> 00:25:24.090
will add time.

00:25:24.090 --> 00:25:27.790
And there isn't a whole lot
of way to make that faster.

00:25:27.790 --> 00:25:31.410
The best way to do it is
just run a JVM profiler

00:25:31.410 --> 00:25:32.910
and see exactly
what's happening.

00:25:32.910 --> 00:25:34.590
You may be using
some plug-ins that

00:25:34.590 --> 00:25:37.740
do things that they shouldn't
be doing, that are just slow.

00:25:37.740 --> 00:25:40.980
And of course, I mean, there's
a few obvious candidates, right?

00:25:40.980 --> 00:25:44.940
Don't resolve dependencies
during configuration.

00:25:44.940 --> 00:25:47.085
Don't configure all
the tasks [? early. ?]

00:25:47.085 --> 00:25:48.960
But really, the only
way to do that if you're

00:25:48.960 --> 00:25:51.570
using a third party plug-in
is to profile it somehow.

00:25:54.300 --> 00:25:57.460
So in terms of speed, to
increase your build speed,

00:25:57.460 --> 00:26:03.000
we still recommend
doing several modules.

00:26:03.000 --> 00:26:05.130
And Jerome talked a
lot about workers,

00:26:05.130 --> 00:26:07.170
how you can get
parallelism for worker.

00:26:07.170 --> 00:26:10.660
But he also showed that workers
have some limitation, right?

00:26:10.660 --> 00:26:13.470
You have to spawn
them from your task.

00:26:13.470 --> 00:26:16.050
And while you're doing that,
you can't run any other tasks.

00:26:16.050 --> 00:26:18.500
And so you're always going
to get better parallelism

00:26:18.500 --> 00:26:19.470
from multiple modules.

00:26:19.470 --> 00:26:21.820
So you should still
try to go there.

00:26:21.820 --> 00:26:24.090
In addition to that, we see
more and more developers

00:26:24.090 --> 00:26:26.250
actually using caching,
distributed caching

00:26:26.250 --> 00:26:27.480
or local caching.

00:26:27.480 --> 00:26:30.420
And so imagine if you
have a few local changes.

00:26:30.420 --> 00:26:33.450
And then you rebase your changes
on top of some changes coming

00:26:33.450 --> 00:26:34.420
from upstream.

00:26:34.420 --> 00:26:37.123
If you have a single module, if
you have some Java files that

00:26:37.123 --> 00:26:39.540
have changed, you're going to
have to rerun the whole Java

00:26:39.540 --> 00:26:40.530
compilation.

00:26:40.530 --> 00:26:42.750
If you have 100
modules and you only

00:26:42.750 --> 00:26:44.670
have a couple,
maybe three, four,

00:26:44.670 --> 00:26:47.640
five modules that are
touched, all the other modules

00:26:47.640 --> 00:26:50.940
are a good candidate to
actually get the output directly

00:26:50.940 --> 00:26:51.840
from the cache.

00:26:51.840 --> 00:26:53.370
So you have better
cache granularity

00:26:53.370 --> 00:26:55.645
and more likely to get
faster builds from that.

00:26:55.645 --> 00:26:58.020
And then the other aspect of
it is compilation avoidance.

00:26:58.020 --> 00:27:00.240
None of the projects we
showed in your benchmarks

00:27:00.240 --> 00:27:02.890
actually used
compilation avoidance.

00:27:02.890 --> 00:27:04.390
But it is a very useful tool.

00:27:04.390 --> 00:27:06.373
So I want to run
through a scenario that

00:27:06.373 --> 00:27:08.540
explains a little bit what
compilation avoidance is.

00:27:08.540 --> 00:27:10.350
Because we still
see some developer

00:27:10.350 --> 00:27:12.790
not really understanding
what's going on.

00:27:12.790 --> 00:27:14.220
So let's say you
have an app that

00:27:14.220 --> 00:27:17.100
depends on Library 1 that
depends on Library 2 that

00:27:17.100 --> 00:27:18.150
depends on Library 3.

00:27:18.150 --> 00:27:20.525
And so we want to see the
impact of compilation avoidance

00:27:20.525 --> 00:27:23.940
when Library 2 declares
its dependency on Library 3

00:27:23.940 --> 00:27:24.848
one way or the other.

00:27:24.848 --> 00:27:26.640
And so we're going to
look at it by looking

00:27:26.640 --> 00:27:28.220
at a bunch of tasks--

00:27:28.220 --> 00:27:31.140
compilation tasks, dexing--
whether they're using Java 7

00:27:31.140 --> 00:27:33.090
or Java 8, it actually
has a difference--

00:27:33.090 --> 00:27:34.770
and then packaging--

00:27:34.770 --> 00:27:37.920
all of that when you do a
code change on Library 3.

00:27:37.920 --> 00:27:40.365
So by default, of course, if
you do a change on Library 3,

00:27:40.365 --> 00:27:42.240
Library 3 is going to
have to run its dexing,

00:27:42.240 --> 00:27:43.620
whether its Java 7 or Java 8.

00:27:43.620 --> 00:27:45.100
And then at the
end, you're going

00:27:45.100 --> 00:27:46.350
to have to package everything.

00:27:46.350 --> 00:27:48.690
And none of the library are
involved in the packaging.

00:27:48.690 --> 00:27:51.820
So it's only affecting
that particular module.

00:27:51.820 --> 00:27:54.940
So let's say you do a code
implementation change.

00:27:54.940 --> 00:27:56.700
So you just go in
the Library 3 module

00:27:56.700 --> 00:27:59.212
and you just change the
content of a method.

00:27:59.212 --> 00:28:02.250
Gradle will do compilation
avoidance for you

00:28:02.250 --> 00:28:02.940
automatically.

00:28:02.940 --> 00:28:05.760
So it will detect that the
API Library 3 did not change,

00:28:05.760 --> 00:28:08.310
and you will not recompile
either Library 2,

00:28:08.310 --> 00:28:09.780
Library 1 obligation.

00:28:09.780 --> 00:28:11.007
It works out of the box.

00:28:11.007 --> 00:28:13.590
It doesn't really matter whether
you use API or implementation

00:28:13.590 --> 00:28:14.340
for dependencies.

00:28:14.340 --> 00:28:15.460
It just works.

00:28:15.460 --> 00:28:15.960
Great.

00:28:15.960 --> 00:28:18.930
That's kind of like, really,
your best case scenario.

00:28:18.930 --> 00:28:22.080
Now, if you do a
change in Library 3

00:28:22.080 --> 00:28:25.770
that adds a public method,
and I'm talking here

00:28:25.770 --> 00:28:28.230
about adding it without
actually using it,

00:28:28.230 --> 00:28:34.800
and you have declared Library
3 as an API of Library 2,

00:28:34.800 --> 00:28:36.983
then you're going to
recompile everything.

00:28:36.983 --> 00:28:38.400
So you're going
to run compilation

00:28:38.400 --> 00:28:40.333
on Library 2,
Library 1, and app.

00:28:40.333 --> 00:28:42.250
Of course, the output
is going to be the same.

00:28:42.250 --> 00:28:44.790
So at least in the
case of Java 7,

00:28:44.790 --> 00:28:46.890
you don't need to run dex again.

00:28:46.890 --> 00:28:49.332
Because Gradle will look at
the input of dex and will say,

00:28:49.332 --> 00:28:51.540
well, it's exactly the same
thing that I had before--

00:28:51.540 --> 00:28:53.100
nothing to do.

00:28:53.100 --> 00:28:55.200
However, for Java
8, that's different.

00:28:55.200 --> 00:28:59.750
The desugaring process has
to look at the dependencies.

00:28:59.750 --> 00:29:01.940
So when it process
Library 1, it has

00:29:01.940 --> 00:29:06.440
to go and look at Library 2 and
Library 3, what their API is.

00:29:06.440 --> 00:29:09.980
Is it using some language
feature that it did to desugar

00:29:09.980 --> 00:29:12.170
and, therefore, it impact
the output of Library 1.

00:29:12.170 --> 00:29:14.210
So you have to redo everything.

00:29:14.210 --> 00:29:16.700
Now, if you change the
dependency from Library 2

00:29:16.700 --> 00:29:18.870
to Library 3 using
implementation,

00:29:18.870 --> 00:29:20.180
you save a little bit.

00:29:20.180 --> 00:29:22.280
Basically, what
you're doing is you're

00:29:22.280 --> 00:29:23.900
telling the consumer
of Library 2

00:29:23.900 --> 00:29:25.740
that Library 3 is
hidden from them.

00:29:25.740 --> 00:29:29.150
So app and Library 1 do
not see Library 3 at all.

00:29:29.150 --> 00:29:33.510
So automatically, you don't run
the Java compilation on them.

00:29:33.510 --> 00:29:36.080
However, right now we
still do predicting seeing

00:29:36.080 --> 00:29:38.390
in the case of desugaring.

00:29:38.390 --> 00:29:42.300
That is actually a [INAUDIBLE]
that we need to fix.

00:29:42.300 --> 00:29:44.390
But once you do that,
then you will also not

00:29:44.390 --> 00:29:47.060
run dexing, which is important.

00:29:47.060 --> 00:29:49.190
Because, especially
in the case of Java 8,

00:29:49.190 --> 00:29:50.810
when you use Java 8
language features,

00:29:50.810 --> 00:29:52.760
we have to run it very often.

00:29:52.760 --> 00:29:55.190
It's extremely hard to
try to reduce the cases

00:29:55.190 --> 00:29:57.500
where you're not
doing predicting.

00:29:57.500 --> 00:30:00.068
We are doing it very often,
as soon as an API change.

00:30:00.068 --> 00:30:01.610
And here, I'm not
necessarily talking

00:30:01.610 --> 00:30:04.430
about an API that matters to
app and Library 1 and Library 2,

00:30:04.430 --> 00:30:04.930
right?

00:30:04.930 --> 00:30:08.080
You could have a public class
with a public method that's

00:30:08.080 --> 00:30:10.185
you only use internally
in Library 3.

00:30:10.185 --> 00:30:12.560
And it's still going to go
and trigger a bunch of changes

00:30:12.560 --> 00:30:14.373
in your consuming modules.

00:30:14.373 --> 00:30:16.040
So compilation avoidance
is very useful.

00:30:16.040 --> 00:30:17.210
Start using it.

00:30:17.210 --> 00:30:19.670
It's going to get better
as we improve the plug-in.

00:30:19.670 --> 00:30:23.600
And it's really going to
make your build faster.

00:30:23.600 --> 00:30:26.523
Some caveats to
parallelization--

00:30:26.523 --> 00:30:28.190
we see some developers
telling us, yeah,

00:30:28.190 --> 00:30:30.298
I have 10, 20 modules.

00:30:30.298 --> 00:30:32.090
And then they say,
well, I have one big app

00:30:32.090 --> 00:30:34.190
module with 90% of my code.

00:30:34.190 --> 00:30:35.060
That's not helping.

00:30:35.060 --> 00:30:38.430
You should really make as
small modules as you can.

00:30:38.430 --> 00:30:40.555
And then, as Leo
mentioned earlier,

00:30:40.555 --> 00:30:41.930
our resource
pipeline is not very

00:30:41.930 --> 00:30:43.410
efficient for machine module.

00:30:43.410 --> 00:30:47.690
In fact, if you see
the chart that it

00:30:47.690 --> 00:30:52.490
shows for resource change for
large module with one module

00:30:52.490 --> 00:30:55.130
and with 100 module, the hundred
a little bit slower than one

00:30:55.130 --> 00:30:57.260
module, that's not priority.

00:30:57.260 --> 00:31:00.140
As we start working on in space
again on additional changes

00:31:00.140 --> 00:31:03.500
to our resource pipeline, we'll
get much better performance

00:31:03.500 --> 00:31:04.850
in between module builds.

00:31:07.678 --> 00:31:08.720
JEROME DOCHEZ: All right.

00:31:08.720 --> 00:31:12.140
So how can you understand
your build performance?

00:31:12.140 --> 00:31:14.290
I mean, we all know that
the Android build system

00:31:14.290 --> 00:31:17.230
is a very open environment.

00:31:17.230 --> 00:31:18.230
You are not constrained.

00:31:18.230 --> 00:31:19.522
You can have your own plug-ins.

00:31:19.522 --> 00:31:21.560
You can have your own
annotation processors.

00:31:21.560 --> 00:31:23.520
You can write code in
the build of the huddle.

00:31:23.520 --> 00:31:25.500
So all these things
compound to each other.

00:31:25.500 --> 00:31:27.655
And eventually, it's
very difficult for us

00:31:27.655 --> 00:31:29.030
to deliver something
that we know

00:31:29.030 --> 00:31:32.130
will perform well because you
can customize it to no end.

00:31:32.130 --> 00:31:34.160
So you need tools to
be able to understand

00:31:34.160 --> 00:31:35.168
how these things work.

00:31:35.168 --> 00:31:36.710
And so you've got
already a few tools

00:31:36.710 --> 00:31:38.840
that are provided by Gradle.

00:31:38.840 --> 00:31:40.880
The Gradle scan is one of them.

00:31:40.880 --> 00:31:42.630
It's very effective.

00:31:42.630 --> 00:31:46.160
It will give you information
about why the tasks run,

00:31:46.160 --> 00:31:47.810
what were the dependencies.

00:31:47.810 --> 00:31:50.180
All these kinds of information
will be given to you.

00:31:50.180 --> 00:31:51.680
One of the only
caveats that it has

00:31:51.680 --> 00:31:54.290
is that it forces you to upload
some information to the Gradle

00:31:54.290 --> 00:31:57.980
servers, so this information,
content, things like file pass,

00:31:57.980 --> 00:32:00.630
file names, varient names,
and stuff like that.

00:32:00.630 --> 00:32:03.800
So we understand that not
everyone wants to send this

00:32:03.800 --> 00:32:05.872
to the external world.

00:32:05.872 --> 00:32:07.580
So therefore, there
are some other tools.

00:32:07.580 --> 00:32:10.903
The profiler is another
simpler tool that you can use.

00:32:10.903 --> 00:32:12.320
It will still give
you information

00:32:12.320 --> 00:32:16.850
about why your task ran
and all that kind of stuff.

00:32:16.850 --> 00:32:18.350
It's not to be a visual.

00:32:18.350 --> 00:32:19.800
But it is still interesting.

00:32:19.800 --> 00:32:22.220
And is still something
you should consider using.

00:32:22.220 --> 00:32:25.100
But to help you further,
we developed an ability

00:32:25.100 --> 00:32:29.630
to have contrasts being
generated out of your builds.

00:32:29.630 --> 00:32:33.800
So what we do now is that we
are capable of generating these.

00:32:33.800 --> 00:32:38.060
And we can display very
visually all the tasks that

00:32:38.060 --> 00:32:40.122
are being scheduled per thread.

00:32:40.122 --> 00:32:41.830
So you can see here
on the left-hand side

00:32:41.830 --> 00:32:43.100
are the thread numbers.

00:32:43.100 --> 00:32:44.210
You can see the task here.

00:32:44.210 --> 00:32:46.127
You've got, for instance,
the task in magenta,

00:32:46.127 --> 00:32:47.990
which is the merged resources.

00:32:47.990 --> 00:32:49.730
You can even see
the workers, which

00:32:49.730 --> 00:32:54.530
are spawned for that
particular task executing.

00:32:54.530 --> 00:32:56.480
And by the way, you
can see here visually

00:32:56.480 --> 00:32:59.450
that, as soon as the task is
done spawning the workers,

00:32:59.450 --> 00:33:03.020
the next task can start,
which is the process

00:33:03.020 --> 00:33:04.730
application manifest in green.

00:33:04.730 --> 00:33:07.510
So you can see how
here, very visually,

00:33:07.510 --> 00:33:10.895
then your task can be
running in parallel,

00:33:10.895 --> 00:33:12.020
even using a single module.

00:33:12.020 --> 00:33:13.610
Because here there's
only one module.

00:33:13.610 --> 00:33:16.370
On blue here,
you've got threads.

00:33:16.370 --> 00:33:20.990
These are threads which are just
using the executive services.

00:33:20.990 --> 00:33:22.850
So this gives you
a very good visual

00:33:22.850 --> 00:33:27.800
again about how we
use the JVM resources.

00:33:27.800 --> 00:33:29.270
You can even go a little deeper.

00:33:29.270 --> 00:33:32.210
For instance, here you can
see that the task execution

00:33:32.210 --> 00:33:34.520
span is this magenta color.

00:33:34.520 --> 00:33:36.730
You can see that there
is the up-to-date check.

00:33:36.730 --> 00:33:39.530
That's the time that
Gradle will spend

00:33:39.530 --> 00:33:42.060
to figure out the files
which are out-of-date.

00:33:42.060 --> 00:33:44.040
Then you've got the
task implementation,

00:33:44.040 --> 00:33:46.040
which is the all phases.

00:33:46.040 --> 00:33:48.800
So that's really the
code of the task itself.

00:33:48.800 --> 00:33:50.840
And then we even--
further down, we

00:33:50.840 --> 00:33:54.458
kind of split it even further
to get to different phases.

00:33:54.458 --> 00:33:56.000
So that gives us a
lot of information

00:33:56.000 --> 00:33:58.380
about how those tasks
are implemented.

00:33:58.380 --> 00:34:00.530
So this is for all
tasks, obviously.

00:34:00.530 --> 00:34:04.670
If you were to run this Chrome
trace with a different plug-in

00:34:04.670 --> 00:34:07.340
or with your own tasks, you
would see your tasks as well,

00:34:07.340 --> 00:34:09.554
but it will not be as
descriptive as this.

00:34:09.554 --> 00:34:11.929
Nevertheless, it would be
still very interesting visually

00:34:11.929 --> 00:34:14.610
to figure out where those
tasks belong and so on.

00:34:14.610 --> 00:34:16.940
So now if you face yourself
with the impression

00:34:16.940 --> 00:34:21.389
that your build is slow,
which I'm sure is 99% of you,

00:34:21.389 --> 00:34:24.350
we would really recommend
that if you want to file a bug

00:34:24.350 --> 00:34:25.991
or tell us that
the build is slow

00:34:25.991 --> 00:34:27.949
and it should be improved,
that you provide us,

00:34:27.949 --> 00:34:30.590
at the very least,
this contrast so

00:34:30.590 --> 00:34:33.199
that we can visually look
into what's going on.

00:34:33.199 --> 00:34:35.120
There is no PII information.

00:34:35.120 --> 00:34:36.219
We don't have file names.

00:34:36.219 --> 00:34:37.219
We don't have task name.

00:34:37.219 --> 00:34:38.420
We don't have variant names.

00:34:38.420 --> 00:34:41.929
There's nothing in there that
should be of any concern.

00:34:41.929 --> 00:34:43.460
This is the same
data that we use.

00:34:43.460 --> 00:34:45.630
That's the data that we
upload to our server.

00:34:45.630 --> 00:34:48.739
So if you opted in to a server
that we took to the data

00:34:48.739 --> 00:34:51.770
that Leo used to do all
these graphs earlier,

00:34:51.770 --> 00:34:54.600
you don't share anything else.

00:34:54.600 --> 00:34:56.300
So to have the trace
enabled, you just

00:34:56.300 --> 00:34:59.240
need to add this property.

00:34:59.240 --> 00:35:00.860
And then you will
find a JSON file

00:35:00.860 --> 00:35:03.410
inside the build on the
[INAUDIBLE] profile.

00:35:03.410 --> 00:35:05.960
That JSON file, you
can use it in Chrome.

00:35:05.960 --> 00:35:08.840
You can load the Chrome
tracing facility in Chrome.

00:35:08.840 --> 00:35:10.520
And then you can load that file.

00:35:10.520 --> 00:35:12.860
And then you will see
exactly what I just displayed

00:35:12.860 --> 00:35:14.360
in the previous slides.

00:35:14.360 --> 00:35:17.480
Again, this is super
visual, very useful.

00:35:17.480 --> 00:35:20.170
It taught us a few things when
we started looking at this,

00:35:20.170 --> 00:35:21.120
even ourselves.

00:35:21.120 --> 00:35:24.050
So I totally recommend that if
you have a very sophisticated

00:35:24.050 --> 00:35:25.250
build, you try this.

00:35:25.250 --> 00:35:29.240
Because you might get some
few surprises here and there.

00:35:29.240 --> 00:35:31.730
And with that, I'd like to
thank you for coming today.

00:35:31.730 --> 00:35:34.780
[GOOGLE LOGO MUSIC PLAYING]

