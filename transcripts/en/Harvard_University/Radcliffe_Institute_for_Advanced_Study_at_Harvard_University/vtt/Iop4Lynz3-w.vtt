WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.832
[MUSIC PLAYING]

00:00:02.832 --> 00:00:05.082
- Good afternoon, everyone.

00:00:05.082 --> 00:00:07.540
I'm Tomiko Brown-Nagin, the
dean of the Radcliffe Institute

00:00:07.540 --> 00:00:09.880
for Advanced Study
here, at Harvard.

00:00:09.880 --> 00:00:13.510
Welcome to the annual Kim
and Judy Davis Dean's Lecture

00:00:13.510 --> 00:00:15.160
in the Social Sciences.

00:00:15.160 --> 00:00:19.150
This year, featuring
Dr. Alondra Nelson,

00:00:19.150 --> 00:00:21.580
president of the Social
Science Research Council

00:00:21.580 --> 00:00:25.720
and professor of sociology
at Columbia University.

00:00:25.720 --> 00:00:28.870
I'm delighted to have
Alondra here with us today,

00:00:28.870 --> 00:00:31.330
and thrilled that all of
us have the opportunity

00:00:31.330 --> 00:00:33.160
to hear from her.

00:00:33.160 --> 00:00:36.490
Let me extend a special welcome
to Kim Davis and members

00:00:36.490 --> 00:00:38.890
of the Radcliffe Institute
Leadership Society,

00:00:38.890 --> 00:00:41.590
as well as our generous
annual donors, who

00:00:41.590 --> 00:00:44.330
make the work of the
Institute possible.

00:00:44.330 --> 00:00:46.690
Thank you for your support

00:00:46.690 --> 00:00:49.870
Alondra Nelson is
an acclaimed scholar

00:00:49.870 --> 00:00:52.780
and distinguished
leader both in academia

00:00:52.780 --> 00:00:55.090
and in the world of policy.

00:00:55.090 --> 00:00:57.970
She's also a respected
public intellectual,

00:00:57.970 --> 00:01:01.000
who frequently devotes
her intellectual firepower

00:01:01.000 --> 00:01:05.230
to advancing racial
and social justice.

00:01:05.230 --> 00:01:07.780
Alondra pushes her
fellow social scientists

00:01:07.780 --> 00:01:11.920
to be similarly engaged with the
world, encouraging researchers,

00:01:11.920 --> 00:01:15.310
to quote Alondra, "ask
the hard questions

00:01:15.310 --> 00:01:16.840
about the public good.

00:01:16.840 --> 00:01:19.720
Reach new audiences,
and communicate

00:01:19.720 --> 00:01:23.350
effectively and emphatically."

00:01:23.350 --> 00:01:26.770
Alondra's own scholarly work
in women and gender studies,

00:01:26.770 --> 00:01:28.810
as well as
African-American studies,

00:01:28.810 --> 00:01:32.980
sits at the intersection of
science, technology, medicine,

00:01:32.980 --> 00:01:34.720
and inequality.

00:01:34.720 --> 00:01:37.420
She investigates
how science shapes

00:01:37.420 --> 00:01:41.530
the world we inhabit, exploring
questions of identity,

00:01:41.530 --> 00:01:43.780
collective action,
and our engagement

00:01:43.780 --> 00:01:47.510
with scientific
conceptualizations of race,

00:01:47.510 --> 00:01:50.950
ethnicity, gender,
and much more.

00:01:50.950 --> 00:01:53.680
Alondra's latest
book, The Social Life

00:01:53.680 --> 00:01:57.400
of DNA, Race, Reparations,
and Reconciliation

00:01:57.400 --> 00:02:01.150
After the Genome, results
from a decade plus

00:02:01.150 --> 00:02:05.170
of ethnographic research
on direct to consumer

00:02:05.170 --> 00:02:08.229
genetic ancestry testing.

00:02:08.229 --> 00:02:12.310
Beginning in the early 2000s,
long before ancestry tests

00:02:12.310 --> 00:02:17.520
became mainstream, let alone
advertised as holiday gifts,

00:02:17.520 --> 00:02:22.420
Alondra set out to learn
why people take them

00:02:22.420 --> 00:02:24.820
and what they might
tell us about who we are

00:02:24.820 --> 00:02:28.180
and who others think we are.

00:02:28.180 --> 00:02:31.630
In particular, she wondered
why African-Americans

00:02:31.630 --> 00:02:36.760
were among the earliest
adopters of this new technology.

00:02:36.760 --> 00:02:40.120
The Social Life of
DNA explains how

00:02:40.120 --> 00:02:42.910
individual genetic
information gathered

00:02:42.910 --> 00:02:48.190
from take-at-home tests became
a socio-political catalyst.

00:02:48.190 --> 00:02:50.920
Newly accessible genetic
data have not only

00:02:50.920 --> 00:02:54.490
been used for ancestral
roots seeking, but also

00:02:54.490 --> 00:02:58.420
to expose aspects
of societal amnesia

00:02:58.420 --> 00:03:01.630
around American slavery.

00:03:01.630 --> 00:03:04.990
Some African-Americans turned
to the test to reckon with,

00:03:04.990 --> 00:03:08.860
to quote Alondra, "the
unfinished business of slavery

00:03:08.860 --> 00:03:12.280
and its lasting shadows
of racial discrimination

00:03:12.280 --> 00:03:14.560
and economic inequality."

00:03:14.560 --> 00:03:19.270
Yet, as she cautions, "DNA
can offer an avenue towards

00:03:19.270 --> 00:03:23.800
recognition but cannot
stand in for reconciliation,

00:03:23.800 --> 00:03:28.030
which encompasses voice,
acknowledgment, mourning,

00:03:28.030 --> 00:03:31.730
forgiveness, and healing."

00:03:31.730 --> 00:03:34.460
Alondra's earlier
award winning book,

00:03:34.460 --> 00:03:38.180
titled Body and Soul, the Black
Panther Party and the Fight

00:03:38.180 --> 00:03:41.930
Against Medical Discrimination,
examines a related set

00:03:41.930 --> 00:03:44.990
of issues through the lens
of the little known health

00:03:44.990 --> 00:03:47.630
activism of the Black Panthers.

00:03:47.630 --> 00:03:51.770
In Body And Soul, Alondra
tells the fascinating history

00:03:51.770 --> 00:03:54.710
of the Black Panthers'
community clinics,

00:03:54.710 --> 00:03:58.520
including the country's first
grassroots genetic screening

00:03:58.520 --> 00:04:03.560
program, which was set up to
test for sickle cell anemia.

00:04:03.560 --> 00:04:06.770
Currently, Alondra is
at work on a new book

00:04:06.770 --> 00:04:11.330
on science and technology policy
in the Obama Administration.

00:04:11.330 --> 00:04:14.700
And it is the subject
of her talk today.

00:04:14.700 --> 00:04:18.410
Alondra began her teaching
career at Yale University

00:04:18.410 --> 00:04:20.779
after earning a PhD
in American Studies

00:04:20.779 --> 00:04:22.670
from New York University.

00:04:22.670 --> 00:04:25.190
Since 2009, she's
been on the faculty

00:04:25.190 --> 00:04:27.860
at Columbia, where
she's also served

00:04:27.860 --> 00:04:31.700
as director of the Institute
for Research on Women, Gender,

00:04:31.700 --> 00:04:33.140
and Sexuality.

00:04:33.140 --> 00:04:36.740
Inaugural dean of social
science and founding

00:04:36.740 --> 00:04:40.670
co-chair of the Precision
Medicine and Society Program,

00:04:40.670 --> 00:04:44.350
she also spearheaded Columbia
University's participation

00:04:44.350 --> 00:04:48.650
in the Obama Administration's
collaborative to advance equity

00:04:48.650 --> 00:04:50.650
through research.

00:04:50.650 --> 00:04:53.930
Today, as president of the
Social Science Research

00:04:53.930 --> 00:04:58.760
Council, Alondra leads national
and international efforts

00:04:58.760 --> 00:05:01.190
to advance research
for the public good

00:05:01.190 --> 00:05:04.160
and works to mobilize
scholarship and resources

00:05:04.160 --> 00:05:08.660
to tackle pressing questions
with implications for policy,

00:05:08.660 --> 00:05:11.480
equity, science, and much more.

00:05:11.480 --> 00:05:15.530
It's hard to imagine a better
person for this critical work

00:05:15.530 --> 00:05:17.210
and for today's lecture.

00:05:17.210 --> 00:05:20.210
And now, please join me in
welcoming Alondra Nelson

00:05:20.210 --> 00:05:20.900
to the stage.

00:05:20.900 --> 00:05:23.774
[APPLAUSE]

00:05:31.917 --> 00:05:34.680
- Thank you so much,
Dean Brown-Nagin, again,

00:05:34.680 --> 00:05:38.670
for that incredibly
generous introduction.

00:05:38.670 --> 00:05:41.220
And special greetings
to a few people.

00:05:41.220 --> 00:05:45.090
I was so happy to have so
many dear friends here.

00:05:45.090 --> 00:05:48.570
I want to thank, as
I begin, Kim Davis.

00:05:48.570 --> 00:05:50.910
I'm delighted to be here
under the auspices of the Kim

00:05:50.910 --> 00:05:53.250
and Judy Davis Dean's Lecture.

00:05:53.250 --> 00:05:55.800
I want to send special greetings
to Daniel Carpenter, who

00:05:55.800 --> 00:05:58.425
I know plays a special role here
at the Radcliffe in the Social

00:05:58.425 --> 00:05:59.120
Sciences.

00:05:59.120 --> 00:06:01.560
And I have to say, those of
you who study bureaucracy

00:06:01.560 --> 00:06:04.810
or the state, as I am trying
to do for the very first time,

00:06:04.810 --> 00:06:06.990
we would be completely
lost without Daniel

00:06:06.990 --> 00:06:12.300
and without his work on the FDA
and other regulatory capture

00:06:12.300 --> 00:06:14.040
and the like.

00:06:14.040 --> 00:06:16.020
Greetings to Marina
Whitman, who is

00:06:16.020 --> 00:06:19.200
a member of the SSRC
advisory board visiting

00:06:19.200 --> 00:06:21.750
committee, who's here and,
I think, a Radcliffe alum.

00:06:21.750 --> 00:06:24.840
And also to two of the
most important mentors

00:06:24.840 --> 00:06:28.070
in my life, Evelyn Hammonds
and Patricia Williams,

00:06:28.070 --> 00:06:30.720
who I'm delighted to see
and who have supported me,

00:06:30.720 --> 00:06:32.330
quite literally, for decades.

00:06:32.330 --> 00:06:34.830
I think I wouldn't have tenure
without either of them, truth

00:06:34.830 --> 00:06:36.210
be told.

00:06:36.210 --> 00:06:39.090
So I've been busy doing
administrative work.

00:06:39.090 --> 00:06:42.298
But I think one must
always do our research.

00:06:42.298 --> 00:06:44.340
It's the thing that brings
us to graduate school.

00:06:44.340 --> 00:06:48.000
It's the questions that
we have about the world.

00:06:48.000 --> 00:06:50.970
So I'm working at a more glacial
pace than would be desired.

00:06:50.970 --> 00:06:52.620
But I am working,
nonetheless, and have

00:06:52.620 --> 00:06:54.453
been spending about the
last year and a half

00:06:54.453 --> 00:06:58.410
talking to staffers in
the Obama Administration,

00:06:58.410 --> 00:07:00.780
starting mostly with
junior staffers who

00:07:00.780 --> 00:07:02.910
worked, many of them,
across the whole eight

00:07:02.910 --> 00:07:07.480
years of the administration,
and continuing forward.

00:07:07.480 --> 00:07:09.340
So I'm going to
tell you a story--

00:07:09.340 --> 00:07:12.240
I think that'll be a wistful
story for some of you--

00:07:12.240 --> 00:07:16.500
about the recent past and
give you some ideas about--

00:07:16.500 --> 00:07:18.795
it's too soon to, I think,
make any proclamations

00:07:18.795 --> 00:07:20.670
about the legacy of the
Obama Administration.

00:07:20.670 --> 00:07:22.260
But I just want to
make some gestures

00:07:22.260 --> 00:07:23.910
about what I think
was particularly

00:07:23.910 --> 00:07:27.240
important with regards to
that administration's work

00:07:27.240 --> 00:07:29.560
with science and technology.

00:07:29.560 --> 00:07:32.190
So I told you it'd
be a little wistful.

00:07:32.190 --> 00:07:33.120
Here are two images.

00:07:33.120 --> 00:07:37.080
One of the very
first magazine covers

00:07:37.080 --> 00:07:40.380
of the Obama era, Paging
Dr. Obama, obviously,

00:07:40.380 --> 00:07:42.930
a Time cover about the
Affordable Care Act

00:07:42.930 --> 00:07:45.450
and all of the controversy
and political debate

00:07:45.450 --> 00:07:46.810
that would come with it.

00:07:46.810 --> 00:07:50.010
And his very last cover
from Popular Science,

00:07:50.010 --> 00:07:52.590
in which he did an
interview summing up

00:07:52.590 --> 00:07:55.290
his work in the administration,
in particular, talking

00:07:55.290 --> 00:07:56.670
about science.

00:07:56.670 --> 00:08:00.660
So in that arc, from the
beginning to the end,

00:08:00.660 --> 00:08:03.390
it's easy to gather
data, if one looks,

00:08:03.390 --> 00:08:05.490
about how this was
probably one of the most

00:08:05.490 --> 00:08:10.380
extraordinary experiments in
federal science and technology

00:08:10.380 --> 00:08:11.400
policy.

00:08:11.400 --> 00:08:13.830
And I'm going to offer you
a few data points, to begin,

00:08:13.830 --> 00:08:15.400
for why that's the case.

00:08:15.400 --> 00:08:17.610
But my talk will
really be about what

00:08:17.610 --> 00:08:20.700
is a hidden facet of this
work, the ethical framing

00:08:20.700 --> 00:08:23.160
that I think is important.

00:08:23.160 --> 00:08:27.420
So this is Obama pictured
with his science advisor, John

00:08:27.420 --> 00:08:29.730
Holdren, your colleague here.

00:08:29.730 --> 00:08:32.669
And it's really probably not
since the influential tenure

00:08:32.669 --> 00:08:35.640
of Vannevar Bush in the US
Office of Scientific Research

00:08:35.640 --> 00:08:38.370
and Development in
the mid 20th century,

00:08:38.370 --> 00:08:41.640
during President Franklin
Roosevelt's tenure,

00:08:41.640 --> 00:08:43.830
that science had played
such a powerful role

00:08:43.830 --> 00:08:46.290
in a presidential
administration.

00:08:46.290 --> 00:08:51.360
So Holdren was not only director
of the Obama Office of Science

00:08:51.360 --> 00:08:56.490
and Technology Policy, he
held two other hats besides.

00:08:56.490 --> 00:09:00.420
He was co-chair of the
Presidential Council on Science

00:09:00.420 --> 00:09:02.820
and Technology,
PCAST, in addition to

00:09:02.820 --> 00:09:06.960
being OSTP director, and led
a national council, as well.

00:09:06.960 --> 00:09:09.940
So it's little clear to see
here than it is on my screen.

00:09:09.940 --> 00:09:14.760
So this is the configuration
of the Obama Science OSTP.

00:09:14.760 --> 00:09:16.980
Holdren held the
top three roles--

00:09:16.980 --> 00:09:18.960
OSTP director.

00:09:18.960 --> 00:09:21.840
He was a co-chair of the
President's Council of Advisors

00:09:21.840 --> 00:09:24.945
on Science and Technology,
or PCAST, as well as

00:09:24.945 --> 00:09:28.665
the Chair of the National
Science and Technology Council.

00:09:28.665 --> 00:09:30.540
So in other administrations,
different people

00:09:30.540 --> 00:09:32.040
had held all of these roles.

00:09:32.040 --> 00:09:34.180
Holdren held them
simultaneously.

00:09:34.180 --> 00:09:37.350
You'll also see that
the OSTP built out

00:09:37.350 --> 00:09:41.040
lots of different work
that included the STEM

00:09:41.040 --> 00:09:45.090
fields, energy science,
climate science, cybersecurity,

00:09:45.090 --> 00:09:46.200
and the like.

00:09:46.200 --> 00:09:49.950
And a phrase that came up often
in folks that I talked to,

00:09:49.950 --> 00:09:52.860
who worked in the OSTP, was
that science touches everything.

00:09:52.860 --> 00:09:56.790
So this was a kind of
ethos of the Obama OSTP.

00:09:56.790 --> 00:10:00.000
Part of the reason why Holdren
and other people working

00:10:00.000 --> 00:10:02.280
in the administration
would be dual hatted

00:10:02.280 --> 00:10:05.400
or tri-hatted it in their
positions in the administration

00:10:05.400 --> 00:10:07.260
was because they felt
like there needed

00:10:07.260 --> 00:10:10.230
to be an expansive and
capacious way to how they

00:10:10.230 --> 00:10:12.850
thought about doing their work.

00:10:12.850 --> 00:10:14.580
So PCAST, this
Presidential Council

00:10:14.580 --> 00:10:17.100
of Advisors on Science
and Technology,

00:10:17.100 --> 00:10:18.630
were external advisors.

00:10:18.630 --> 00:10:22.350
These included folks like
Eric Schmidt of Alphabet,

00:10:22.350 --> 00:10:26.970
Rick Levin, then president of
Yale who went on to Coursera.

00:10:26.970 --> 00:10:29.790
And you can see
that in their work,

00:10:29.790 --> 00:10:33.250
they did some of the work that
gave framing and shape to some

00:10:33.250 --> 00:10:36.220
of the important initiatives
of the Obama Office of Science

00:10:36.220 --> 00:10:37.420
and Technology Policy.

00:10:37.420 --> 00:10:42.680
So big data, K to 12 STEM
education, health care,

00:10:42.680 --> 00:10:46.600
and health care information,
data informatics, and the like.

00:10:46.600 --> 00:10:50.020
So Holdren would
co-chair this entity

00:10:50.020 --> 00:10:53.140
with Eric Lander
and Harold Varmus.

00:10:53.140 --> 00:10:55.900
More generally, the
Obama Administration

00:10:55.900 --> 00:10:58.420
appointed many
prominent scientists

00:10:58.420 --> 00:11:01.060
to his administration
and to advisory boards,

00:11:01.060 --> 00:11:03.790
including five Nobel
laureates and 28 members

00:11:03.790 --> 00:11:06.370
of the National Academies
of Sciences, Engineering,

00:11:06.370 --> 00:11:07.670
and Medicine.

00:11:07.670 --> 00:11:11.110
Moreover, this PCAST
was more active than any

00:11:11.110 --> 00:11:14.650
of their predecessor
bodies in the three

00:11:14.650 --> 00:11:17.020
prior presidential
administrations.

00:11:17.020 --> 00:11:20.050
So they, over eight years,
published 36 publications,

00:11:20.050 --> 00:11:21.190
like these here.

00:11:21.190 --> 00:11:25.120
By comparison,
there were about 12

00:11:25.120 --> 00:11:28.120
in the former W.
Bush Administration.

00:11:28.120 --> 00:11:30.730
There were 46 meetings
over eight years.

00:11:30.730 --> 00:11:34.390
By comparison, there were 30,
21, and 20 in the prior three

00:11:34.390 --> 00:11:35.680
administrations.

00:11:35.680 --> 00:11:37.450
And for the first
time, members of PCAST

00:11:37.450 --> 00:11:38.800
were given security clearances.

00:11:38.800 --> 00:11:42.520
So they could offer
advice to the president

00:11:42.520 --> 00:11:44.740
and his administration
on cybersecurity

00:11:44.740 --> 00:11:49.090
and other important,
sensitive issues.

00:11:49.090 --> 00:11:53.530
So this was one facet of the
way that the Obama science

00:11:53.530 --> 00:11:56.020
apparatus-- the way
federal science under Obama

00:11:56.020 --> 00:11:59.590
was distinctive in the way
that it was put together.

00:11:59.590 --> 00:12:02.020
Also distinctive was that
over the course of the eight

00:12:02.020 --> 00:12:06.040
years of his presidency, Obama
published 13 journal articles.

00:12:06.040 --> 00:12:08.690
Many of these were
advocacy articles.

00:12:08.690 --> 00:12:10.510
They're not putting
us all to shame.

00:12:10.510 --> 00:12:11.920
They were commentaries.

00:12:11.920 --> 00:12:14.380
So Harvard Law Review,
New England Journal

00:12:14.380 --> 00:12:17.560
of Medicine, Journal of the
American Medical Association,

00:12:17.560 --> 00:12:19.910
Nature and Science,
just to name a few.

00:12:19.910 --> 00:12:21.885
So these are just
examples from late

00:12:21.885 --> 00:12:23.260
in his administration,
where he's

00:12:23.260 --> 00:12:25.540
trying to make the case
for all that they did.

00:12:25.540 --> 00:12:26.560
He's tired.

00:12:26.560 --> 00:12:29.530
He's saying these are all
the things that we did,

00:12:29.530 --> 00:12:31.840
including, notably, the
commentary from the Harvard Law

00:12:31.840 --> 00:12:35.110
Review on criminal justice
and the important work

00:12:35.110 --> 00:12:39.010
that his OSTP would do
around forensic science.

00:12:39.010 --> 00:12:40.780
This would be the
last paper that he

00:12:40.780 --> 00:12:47.500
would publish in Science, making
the case for energy policy,

00:12:47.500 --> 00:12:50.380
certainly in the weeks
before the Paris Climate

00:12:50.380 --> 00:12:52.670
Accord would fall apart.

00:12:52.670 --> 00:12:56.080
Then there was the euphoria
of the Obama Administration.

00:12:56.080 --> 00:12:57.318
That was also distinctive.

00:12:57.318 --> 00:12:59.860
So he brought to the White House
for the first time the White

00:12:59.860 --> 00:13:01.570
House Science Fairs.

00:13:01.570 --> 00:13:05.110
They ran to really
celebrate the winners

00:13:05.110 --> 00:13:08.680
of local and regional STEM
and science competitions

00:13:08.680 --> 00:13:10.290
in K to 12.

00:13:10.290 --> 00:13:12.850
And they ran from 2010 to 2017.

00:13:12.850 --> 00:13:16.060
And they, since, are
no longer going strong.

00:13:16.060 --> 00:13:20.530
So here's young Obama
with not so much gray hair

00:13:20.530 --> 00:13:22.390
with a young boy
with a projectile.

00:13:22.390 --> 00:13:27.400
Older Obama holding a model
of a flu bug in his hand

00:13:27.400 --> 00:13:29.890
at one of the later
science fairs.

00:13:29.890 --> 00:13:32.080
So he would inaugurate
them working

00:13:32.080 --> 00:13:35.440
with a gentleman named Kumar
Garg, who worked for eight

00:13:35.440 --> 00:13:38.080
years in the Obama OSTP.

00:13:38.080 --> 00:13:40.540
And this would be
distinctive, as well.

00:13:40.540 --> 00:13:44.770
So we got a sense of how
distinctive the Obama

00:13:44.770 --> 00:13:46.180
approach to science was.

00:13:46.180 --> 00:13:50.845
Because with the establishment
of the Trump Administration,

00:13:50.845 --> 00:13:52.060
it became very clear.

00:13:52.060 --> 00:13:54.880
So just to think about
the staffers in the OSTP,

00:13:54.880 --> 00:13:58.000
at its height, there
were 143 staffers.

00:13:58.000 --> 00:14:01.150
And when the Trump
Administration

00:14:01.150 --> 00:14:04.330
was established and
came to the White House,

00:14:04.330 --> 00:14:05.560
there were about 30 staffers.

00:14:05.560 --> 00:14:07.430
And I think now,
there are about 40.

00:14:07.430 --> 00:14:11.650
So it also gives you a scale
of the investment and staffing.

00:14:11.650 --> 00:14:13.630
What I want to suggest
to you this afternoon

00:14:13.630 --> 00:14:17.770
is that there's a less
obvious impact, or influence,

00:14:17.770 --> 00:14:20.530
or something distinctive
about the Obama OSTP,

00:14:20.530 --> 00:14:24.290
and this particular federal
approach to science,

00:14:24.290 --> 00:14:27.190
which was a kind
of ethical framing.

00:14:27.190 --> 00:14:30.700
So I'm taking this up as
a way to frame a larger

00:14:30.700 --> 00:14:34.420
project, which is a book project
that will be about moonshots.

00:14:34.420 --> 00:14:37.330
I'm working on moonshots in
the Obama Administration.

00:14:37.330 --> 00:14:40.210
That will include the BRAIN
Initiative, white papers

00:14:40.210 --> 00:14:45.130
and initiatives on Big Data and
AI, the first national Nudge

00:14:45.130 --> 00:14:47.140
unit, Social and
Behavioral Research Team,

00:14:47.140 --> 00:14:49.200
taking place in the White House.

00:14:49.200 --> 00:14:51.200
Precision Medicine, which
I'll talk about today,

00:14:51.200 --> 00:14:52.200
and the Cancer Moonshot.

00:14:55.380 --> 00:14:57.040
And in discussing
this, as I said,

00:14:57.040 --> 00:15:00.520
I'll draw on some of the
interviews I conducted,

00:15:00.520 --> 00:15:04.960
as well as content analysis,
my own experience, and one

00:15:04.960 --> 00:15:08.320
of the ethical framing
performances of the Big

00:15:08.320 --> 00:15:12.040
Data and AI, as well as
quite a few of Obama's

00:15:12.040 --> 00:15:15.700
speeches, as you'll see in
his own presentation of self

00:15:15.700 --> 00:15:18.730
with regards to
ethics in science.

00:15:18.730 --> 00:15:21.100
So the moonshot,
of course, comes

00:15:21.100 --> 00:15:24.550
from a famous speech at Rice
University in Houston, Texas,

00:15:24.550 --> 00:15:26.650
September, 1962.

00:15:26.650 --> 00:15:28.450
John F. Kennedy
ascended a podium

00:15:28.450 --> 00:15:33.340
in front of a large crowd
gathered at a stadium, at Rice.

00:15:33.340 --> 00:15:37.030
And he really made
the case for the goal

00:15:37.030 --> 00:15:42.490
of sending rockets and
men to the moon, the goal

00:15:42.490 --> 00:15:45.460
of technological innovation,
and the aspiration

00:15:45.460 --> 00:15:48.070
to use federal funding
and federal human capital

00:15:48.070 --> 00:15:51.640
to do this in a limited
time frame of two years.

00:15:51.640 --> 00:15:55.390
He says "but why,
some say, the moon?

00:15:55.390 --> 00:15:56.950
Why climb the highest mountain?

00:15:56.950 --> 00:15:59.380
We choose to go to the
moon in this decade,

00:15:59.380 --> 00:16:03.370
not because it will be easy,
but because it will be hard."

00:16:03.370 --> 00:16:05.590
The moonshot, of course,
has been taken up

00:16:05.590 --> 00:16:07.240
in other parlance.

00:16:07.240 --> 00:16:11.710
Of course, one of the Obama big
initiatives launched in 2016

00:16:11.710 --> 00:16:17.380
with Vice President Joe Biden
leading it is a $1.8 billion

00:16:17.380 --> 00:16:22.150
investment in cancer research,
called the Cancer Moonshot.

00:16:22.150 --> 00:16:24.820
It's also the case that
the moonshot, today,

00:16:24.820 --> 00:16:29.100
is understood as being any
kind of ambitious project.

00:16:29.100 --> 00:16:31.960
The moonshot is used
to talk about what

00:16:31.960 --> 00:16:35.860
was called Google X, now
X, an incubator project

00:16:35.860 --> 00:16:40.120
for innovative science
and technology.

00:16:40.120 --> 00:16:44.020
But it should be noted here that
the Google Moonshot are really

00:16:44.020 --> 00:16:50.350
about a problem to a project
to design to a particular kind

00:16:50.350 --> 00:16:52.157
of outcome.

00:16:52.157 --> 00:16:53.740
That makes them a
little bit different

00:16:53.740 --> 00:16:57.070
from the federally funded ones.

00:16:57.070 --> 00:17:01.120
So I want to suggest to you
that throughout the course

00:17:01.120 --> 00:17:03.700
of this administration, and
even in his time as senator,

00:17:03.700 --> 00:17:07.240
that President Obama very
much understood, I think,

00:17:07.240 --> 00:17:07.780
two things.

00:17:07.780 --> 00:17:09.400
And we see them as
well in his memoir.

00:17:09.400 --> 00:17:11.619
Sort of the sense
that science was

00:17:11.619 --> 00:17:14.619
going to be important to his
administration, for reasons

00:17:14.619 --> 00:17:17.290
that I will say a
little bit more about.

00:17:17.290 --> 00:17:21.040
But I think in his person
and also in his presentation

00:17:21.040 --> 00:17:23.770
of self, as I said, it
was very important for him

00:17:23.770 --> 00:17:29.470
to always give voice to the
ways in which science had failed

00:17:29.470 --> 00:17:33.850
and had been used
for pernicious ways.

00:17:33.850 --> 00:17:36.880
So this is him from
a speech in 2016.

00:17:36.880 --> 00:17:39.460
He's the first sitting
president to visit Hiroshima,

00:17:39.460 --> 00:17:42.730
notably not to make an
apology, but to give a speech.

00:17:42.730 --> 00:17:46.750
In this speech, he says,
"technological progress

00:17:46.750 --> 00:17:49.240
without an equivalent
progress in human institutions

00:17:49.240 --> 00:17:50.230
can doom us.

00:17:50.230 --> 00:17:53.380
The scientific revolution that
led to the splitting of an atom

00:17:53.380 --> 00:17:58.150
requires a moral
revolution, as well."

00:17:58.150 --> 00:18:01.360
Early in his administration,
you may recall,

00:18:01.360 --> 00:18:03.700
he was asked to
be a commencement

00:18:03.700 --> 00:18:05.028
speaker at Notre Dame.

00:18:05.028 --> 00:18:06.820
And it was highly
controversial, because he

00:18:06.820 --> 00:18:11.920
was an explicitly pro-life
candidate and also

00:18:11.920 --> 00:18:15.130
a candidate who was
committed to advancing,

00:18:15.130 --> 00:18:17.800
to a limited degree,
stem cell research, which

00:18:17.800 --> 00:18:20.830
was a contrast with the prior
administration of George W.

00:18:20.830 --> 00:18:22.000
Bush.

00:18:22.000 --> 00:18:25.210
So part of what he says
in his speech that day,

00:18:25.210 --> 00:18:28.520
in May of 2009, is "let us be
sure that all of our health

00:18:28.520 --> 00:18:31.420
care policies are grounded
not only in sound science

00:18:31.420 --> 00:18:35.280
but also in clear ethics."

00:18:35.280 --> 00:18:38.820
So I want to demonstrate
today that the sort

00:18:38.820 --> 00:18:44.250
of ethical terrain that Obama
and his administration endeavor

00:18:44.250 --> 00:18:49.380
to work around and through
is dealing with the past

00:18:49.380 --> 00:18:51.570
and really having to
reckon with the past.

00:18:51.570 --> 00:18:53.820
They have to overcome
citizen skepticism related

00:18:53.820 --> 00:18:56.310
to the history of
experimental abuse.

00:18:56.310 --> 00:19:00.540
They have to establish
ethical regulations, in part,

00:19:00.540 --> 00:19:03.390
so new science, new
moonshots can go forward.

00:19:03.390 --> 00:19:05.220
And they have to
generate a perception

00:19:05.220 --> 00:19:06.420
of ethical forethought.

00:19:06.420 --> 00:19:08.430
That the moonshots that
they are proceeding with

00:19:08.430 --> 00:19:12.670
have been thought about, that
these are considered moves.

00:19:12.670 --> 00:19:15.300
And in this way, they are
distinctive from someone

00:19:15.300 --> 00:19:18.870
like Vannevar Bush, who
I mentioned earlier.

00:19:18.870 --> 00:19:21.690
In the historical archive,
in the secondary literature

00:19:21.690 --> 00:19:24.380
about Bush and about
the Manhattan Project

00:19:24.380 --> 00:19:27.720
and the formation of what
would become the atom bomb,

00:19:27.720 --> 00:19:30.330
there are, I think,
poignant reflections

00:19:30.330 --> 00:19:35.280
on this from folks
like Oppenheimer,

00:19:35.280 --> 00:19:37.350
only a few years later.

00:19:37.350 --> 00:19:40.800
What was striking to me about
the historical record on Bush

00:19:40.800 --> 00:19:44.430
is that there was never a
sense in his conversations

00:19:44.430 --> 00:19:47.340
and in his work,
and certainly, not

00:19:47.340 --> 00:19:51.028
in this masterful biography
from Pascal Zachary,

00:19:51.028 --> 00:19:53.070
that they thought they
should had to ask anybody.

00:19:53.070 --> 00:19:56.260
That there was any
sense of accountability

00:19:56.260 --> 00:19:58.290
on the part of Bush,
although it might have not

00:19:58.290 --> 00:20:01.410
been true of others on the
Manhattan Project team,

00:20:01.410 --> 00:20:04.210
that there was anyone that had
to be engaged in this process.

00:20:04.210 --> 00:20:06.810
And moreover, in some
cases in the biography,

00:20:06.810 --> 00:20:10.500
Zachary writes about Bush
being asked whether or not

00:20:10.500 --> 00:20:12.420
there should be any kind
of what we might call

00:20:12.420 --> 00:20:14.850
today ethical engagement
or conversation about

00:20:14.850 --> 00:20:16.530
whether or not
this would proceed,

00:20:16.530 --> 00:20:18.870
and found it
utterly unnecessary.

00:20:18.870 --> 00:20:21.240
So part of what we're seeing
here, I want to suggest,

00:20:21.240 --> 00:20:25.650
is the creation and
extension of an ethical frame

00:20:25.650 --> 00:20:27.510
that a few decades
prior, and certainly

00:20:27.510 --> 00:20:30.300
a few presidential
administrations prior,

00:20:30.300 --> 00:20:31.362
did not exist.

00:20:31.362 --> 00:20:32.820
And I'm going to
track this for you

00:20:32.820 --> 00:20:35.380
in a few ways, this afternoon.

00:20:35.380 --> 00:20:38.850
First, beginning with the
formation of the ELSI Program

00:20:38.850 --> 00:20:44.300
that emerges alongside the
Human Genome Project in 1990.

00:20:44.300 --> 00:20:47.440
So the Human Genome
Project begins.

00:20:47.440 --> 00:20:49.980
And soon after, there
is a working group

00:20:49.980 --> 00:20:52.990
that would become a project
on the ethical, legal,

00:20:52.990 --> 00:20:56.700
and social implications
of that project.

00:20:56.700 --> 00:21:02.520
Its original mandate included
identifying and defining

00:21:02.520 --> 00:21:06.120
issues that were related to the
Human Genome Project, policies

00:21:06.120 --> 00:21:08.400
for addressing
them, with 3% to 5%

00:21:08.400 --> 00:21:12.810
of the annual Human
Genome Project budget.

00:21:12.810 --> 00:21:16.470
And this has been
discussed in some quarters

00:21:16.470 --> 00:21:19.530
as the largest ethics
project in human history.

00:21:22.350 --> 00:21:24.770
So I want to bring
to our attention

00:21:24.770 --> 00:21:27.538
that initially,
the ELSI project--

00:21:27.538 --> 00:21:29.330
the Ethical, Legal,
and Social Implications

00:21:29.330 --> 00:21:30.740
of the Human Genome Project--

00:21:30.740 --> 00:21:33.170
was actually quite
broad and capacious.

00:21:33.170 --> 00:21:35.420
That it covered a
lot of territory

00:21:35.420 --> 00:21:37.010
that it would not
cover in the end,

00:21:37.010 --> 00:21:40.820
highlighting a little bit
here, for you Privacy and fair

00:21:40.820 --> 00:21:42.590
use of genetic
information with respect

00:21:42.590 --> 00:21:45.920
to employers and insurers, but
also direct marketers, banks,

00:21:45.920 --> 00:21:48.920
credit raters, law enforcement
agencies, and many others.

00:21:48.920 --> 00:21:51.680
The availability of large
amounts of genetic information

00:21:51.680 --> 00:21:53.990
and largely
unprotected databanks,

00:21:53.990 --> 00:21:58.220
possible discriminatory
misuse of genetic information,

00:21:58.220 --> 00:22:01.160
and the fact that the use
of genetic information

00:22:01.160 --> 00:22:05.390
and genetic screening could
exacerbate the creation

00:22:05.390 --> 00:22:07.940
of a genetic underclass.

00:22:07.940 --> 00:22:11.780
But by 1991, the scope of ELSI
is significantly narrowed.

00:22:11.780 --> 00:22:14.540
So the issues here are
privacy and fair use

00:22:14.540 --> 00:22:17.270
of personal genetic information,
genetics in the workplace,

00:22:17.270 --> 00:22:18.710
and genetic education.

00:22:22.310 --> 00:22:25.760
So you continue to see articles
like this in the Human Genome

00:22:25.760 --> 00:22:29.780
News, which was the official
newsletter of the project.

00:22:29.780 --> 00:22:33.920
But what we might call the more
radical interpretations of what

00:22:33.920 --> 00:22:36.080
ELSI might have
been, and its ability

00:22:36.080 --> 00:22:38.990
to not only be downstream,
as critics of ELSI

00:22:38.990 --> 00:22:41.330
would come to say,
but also anticipatory

00:22:41.330 --> 00:22:47.450
in thinking about how
genetic data might be used

00:22:47.450 --> 00:22:51.980
in the marketplace, for
example, for purposes of bias

00:22:51.980 --> 00:22:56.790
and discrimination are shaved
off of the scope of this work.

00:22:56.790 --> 00:22:59.780
So even though the work narrows
from this initial mission,

00:22:59.780 --> 00:23:04.490
from this to this,
it also expands.

00:23:04.490 --> 00:23:07.040
So by the early
aughts, ELSI has gone

00:23:07.040 --> 00:23:10.430
from being a project
that runs in parallel,

00:23:10.430 --> 00:23:13.250
an ethical analog to the
Human Genome Project,

00:23:13.250 --> 00:23:16.730
to also being part
of a conversation

00:23:16.730 --> 00:23:18.020
about nanotechnology.

00:23:18.020 --> 00:23:20.750
So it's expanding from
the Human Genome Project

00:23:20.750 --> 00:23:22.700
to nanotechnology.

00:23:22.700 --> 00:23:25.430
Paul Rabanow and Gaiman
Bennett, in 2012,

00:23:25.430 --> 00:23:29.600
publish a fascinating, poetic,
sometimes confusing book--

00:23:29.600 --> 00:23:31.970
but a very interesting
book on their engagement

00:23:31.970 --> 00:23:36.950
and trying to be an ELSI
partner for synthetic biology

00:23:36.950 --> 00:23:39.200
as it's emerging,
a few years later,

00:23:39.200 --> 00:23:41.730
in the early 20th century.

00:23:41.730 --> 00:23:44.900
So what we can track
if we follow even

00:23:44.900 --> 00:23:47.210
the narrow ELSI is
a sort of expansion

00:23:47.210 --> 00:23:51.020
of an ELSI frame from
the Human Genome Project

00:23:51.020 --> 00:23:53.930
to nanotech synthetic
biology and other forms.

00:23:53.930 --> 00:23:56.732
So those of you who work
in the life sciences

00:23:56.732 --> 00:23:58.940
know that there's pretty
much the ELSI of everything.

00:23:58.940 --> 00:24:03.110
Any project that you
do can and often must,

00:24:03.110 --> 00:24:05.660
depending on who's funding
it, have an ELSI component.

00:24:05.660 --> 00:24:07.160
And I want to argue
that by the time

00:24:07.160 --> 00:24:09.200
we get to the Obama
administration,

00:24:09.200 --> 00:24:11.990
there's been a full
sail ethical turn,

00:24:11.990 --> 00:24:15.680
such that to do federal
science means to be expected

00:24:15.680 --> 00:24:17.510
to have some forms
of accountability

00:24:17.510 --> 00:24:20.300
and to be able to at
least perform answers

00:24:20.300 --> 00:24:25.100
to certain questions about
the implications of moonshots.

00:24:27.930 --> 00:24:31.720
So ELSI is one
origin or one pillar

00:24:31.720 --> 00:24:33.730
of why I think this
ethical framing comes

00:24:33.730 --> 00:24:36.940
to be prominent in the
Obama administration.

00:24:36.940 --> 00:24:39.430
And another is
the administration

00:24:39.430 --> 00:24:40.690
that preceded it.

00:24:40.690 --> 00:24:43.900
So here's Obama pictured
again with John Holdren.

00:24:43.900 --> 00:24:48.040
Holdren, whom he appoints
before he becomes president-- so

00:24:48.040 --> 00:24:51.430
to give you a comparison,
George W. Bush

00:24:51.430 --> 00:24:55.513
didn't nominate and then have
appointed his first director

00:24:55.513 --> 00:24:57.430
of the Office of Science
and Technology Policy

00:24:57.430 --> 00:25:00.200
until almost a year
into the administration.

00:25:00.200 --> 00:25:02.830
And we know, of course,
that President Trump did not

00:25:02.830 --> 00:25:07.040
nominate someone until well a
year into his administration.

00:25:07.040 --> 00:25:11.200
So it was really uncommon
for someone to be nominated

00:25:11.200 --> 00:25:15.917
before a new president
even takes office.

00:25:15.917 --> 00:25:17.500
And it's certainly
the case that, as I

00:25:17.500 --> 00:25:19.570
said, early in his
administration, indeed,

00:25:19.570 --> 00:25:22.630
here in his inaugural
address, Obama

00:25:22.630 --> 00:25:27.280
places front and center his
commitment to restoring science

00:25:27.280 --> 00:25:31.070
to its rightful place
in his administration.

00:25:31.070 --> 00:25:33.500
Part of what that
meant was a reaction

00:25:33.500 --> 00:25:36.620
to what they understood
Obama and many of his science

00:25:36.620 --> 00:25:38.290
advisors to have been--

00:25:38.290 --> 00:25:41.720
a politicized
bioethics that emerged

00:25:41.720 --> 00:25:46.640
by conservative ideologues
during the Bush administration.

00:25:46.640 --> 00:25:50.060
For them, that was really summed
up in the case of Terry Shiavo.

00:25:50.060 --> 00:25:52.040
You'll see on her
gravestone, here,

00:25:52.040 --> 00:25:56.450
that was commissioned
by her husband.

00:25:56.450 --> 00:26:00.530
She departed this earth
on February 25, 1990,

00:26:00.530 --> 00:26:03.890
and was at peace in March, 2005.

00:26:03.890 --> 00:26:06.860
So between 1990 and
2005, of course,

00:26:06.860 --> 00:26:10.580
there is a contest
between her husband, who

00:26:10.580 --> 00:26:12.680
said that to abide
by her wishes would

00:26:12.680 --> 00:26:17.690
be to allow her to depart
this earth in February,

00:26:17.690 --> 00:26:21.140
1990, and her parents, who
insisted on keeping her

00:26:21.140 --> 00:26:22.340
in a vegetative state.

00:26:22.340 --> 00:26:25.460
And then all around, a
raging public discourse

00:26:25.460 --> 00:26:27.380
about the right to
life and the way

00:26:27.380 --> 00:26:29.780
in which this
controversy was abducted

00:26:29.780 --> 00:26:33.150
into that conversation.

00:26:33.150 --> 00:26:36.680
So as a senator,
Senator Obama is already

00:26:36.680 --> 00:26:40.760
engaged in trying
to think about how

00:26:40.760 --> 00:26:43.790
to think about the relationship
between religion and science

00:26:43.790 --> 00:26:45.650
or religion and reason.

00:26:45.650 --> 00:26:50.450
This is a speech that he gives
in 2006, in Washington DC,

00:26:50.450 --> 00:26:53.262
in an ecumenical
religious forum.

00:26:53.262 --> 00:26:55.470
He says, "I do not believe
that religious people have

00:26:55.470 --> 00:26:57.200
a monopoly on morality.

00:26:57.200 --> 00:27:00.290
I would rather have someone
who is grounded in morality

00:27:00.290 --> 00:27:03.620
and ethics, and who is also
secular, affirm their morality,

00:27:03.620 --> 00:27:06.410
and ethics, and values without
pretending they're something

00:27:06.410 --> 00:27:08.850
that they're not."

00:27:08.850 --> 00:27:12.730
So part of a group of people, a
group scholars-- bioethicists,

00:27:12.730 --> 00:27:14.860
in particular--

00:27:14.860 --> 00:27:18.580
galvanize around a project that
they call Science Progress.

00:27:18.580 --> 00:27:20.800
And some of them
would personally

00:27:20.800 --> 00:27:24.670
identify in
contradistinction to those

00:27:24.670 --> 00:27:29.410
who were the bioethicists,
who understood themselves

00:27:29.410 --> 00:27:32.740
to be conservative, as
progressive bioethicists.

00:27:32.740 --> 00:27:36.190
So two exhibits, A and
B, from that time period

00:27:36.190 --> 00:27:39.400
are these books edited
by Jonathan Marino,

00:27:39.400 --> 00:27:41.560
a prominent
bioethicist who teaches

00:27:41.560 --> 00:27:45.010
at the University of
Pennsylvania, at present.

00:27:45.010 --> 00:27:48.940
But at the time, he was a
senior fellow and the founder

00:27:48.940 --> 00:27:51.250
of the Science Progress
Project at the Center

00:27:51.250 --> 00:27:53.480
for American Progress.

00:27:53.480 --> 00:27:55.590
And here, you see the
kind of ELSI frame

00:27:55.590 --> 00:27:59.740
and a bioethics frame expanding
broadly just in these two

00:27:59.740 --> 00:28:00.790
edited collections.

00:28:00.790 --> 00:28:03.370
So you have more than
the life sciences, here.

00:28:03.370 --> 00:28:07.090
They're talking about progress
in bioethics and ethics frames

00:28:07.090 --> 00:28:09.760
around electronic medical
records, solar energy,

00:28:09.760 --> 00:28:13.220
broadband, neuroscience, and
organizational innovation.

00:28:13.220 --> 00:28:16.660
So the expansion of
this ethical framing

00:28:16.660 --> 00:28:19.720
is happening here,
among other places.

00:28:19.720 --> 00:28:23.890
The Science Progress Project was
launched under the presidency

00:28:23.890 --> 00:28:27.400
of John Podesta, who
had been chief of staff

00:28:27.400 --> 00:28:29.410
under the Clinton
Administration,

00:28:29.410 --> 00:28:34.510
and was allowing these
bioethicists to galvanize

00:28:34.510 --> 00:28:38.500
and create programming and
strategy around what they would

00:28:38.500 --> 00:28:42.460
want to do when the
administration of George W.

00:28:42.460 --> 00:28:46.300
Bush and the conservative
bioethicists who were advising

00:28:46.300 --> 00:28:49.300
him would move on.

00:28:49.300 --> 00:28:51.910
So what's interesting
here are, I

00:28:51.910 --> 00:28:56.277
think, claims that are
not always associated

00:28:56.277 --> 00:28:56.860
with the left.

00:28:56.860 --> 00:29:00.100
So Science Progress
understood that coming out

00:29:00.100 --> 00:29:04.180
of the era of social movements
of the '60s and '70s,

00:29:04.180 --> 00:29:07.090
that science had to
be participatory.

00:29:07.090 --> 00:29:09.070
That it was
inherently political.

00:29:09.070 --> 00:29:12.250
It was a project of progressive
science policy, as I said.

00:29:12.250 --> 00:29:14.410
And they also
understood or wanted

00:29:14.410 --> 00:29:17.362
to assert that one could
combine ethics and innovation

00:29:17.362 --> 00:29:19.570
and ethics and reason, and
that these things were not

00:29:19.570 --> 00:29:21.220
diametrically opposed.

00:29:21.220 --> 00:29:22.960
And this was part
of the particularly

00:29:22.960 --> 00:29:27.100
progressive framing that
they wanted to advance.

00:29:27.100 --> 00:29:32.830
So I should say that Marino,
the co-editor of both

00:29:32.830 --> 00:29:35.200
of these volumes, the leader
of the Science Progress

00:29:35.200 --> 00:29:38.260
Project at the Center
for American Progress,

00:29:38.260 --> 00:29:41.080
would be a member of
Obama's transition team

00:29:41.080 --> 00:29:43.300
from 2008 to 2009.

00:29:43.300 --> 00:29:47.440
John Podesta, who played a
role here, as well, by 2014,

00:29:47.440 --> 00:29:49.060
is working in the
Obama White House

00:29:49.060 --> 00:29:52.540
and is working on many
of the moonshot launches,

00:29:52.540 --> 00:29:56.770
including the launches of
the AI and Big Data projects

00:29:56.770 --> 00:30:00.030
that happen around that time.

00:30:00.030 --> 00:30:01.650
So as I mentioned,
it's also the case

00:30:01.650 --> 00:30:06.600
that Senator Obama
was engaged in issues

00:30:06.600 --> 00:30:08.290
around genetics and ethics.

00:30:08.290 --> 00:30:13.170
So in 2006 and also
in 2007, he introduces

00:30:13.170 --> 00:30:16.815
with Republican Senator
Richard Burr of North Carolina

00:30:16.815 --> 00:30:19.170
the Genomics and
Personalized Medicine Act

00:30:19.170 --> 00:30:22.140
both of 2006 and 2007.

00:30:22.140 --> 00:30:24.090
And versions of
this act would be

00:30:24.090 --> 00:30:28.140
introduced by other legislators
after Obama entered the White

00:30:28.140 --> 00:30:30.090
House.

00:30:30.090 --> 00:30:33.870
But this was very much front
and center for him and his time,

00:30:33.870 --> 00:30:36.300
in his few years in the Senate.

00:30:36.300 --> 00:30:42.210
So what this act endeavored
to, in its words,

00:30:42.210 --> 00:30:44.070
"improve access
to and utilization

00:30:44.070 --> 00:30:46.530
of valid, reliable
genetic tests,

00:30:46.530 --> 00:30:48.690
and to secure the
promise of personalized

00:30:48.690 --> 00:30:52.290
medicine for all Americans."

00:30:52.290 --> 00:30:54.990
So while neither
President Obama's bill

00:30:54.990 --> 00:30:57.720
nor the subsequent versions
from him and other legislators

00:30:57.720 --> 00:31:03.150
were ever enacted,
much of what was here

00:31:03.150 --> 00:31:06.540
was ultimately incorporated
into the 21st Century Cures

00:31:06.540 --> 00:31:12.570
Act that was signed by President
Obama, in December of 2016,

00:31:12.570 --> 00:31:14.730
towards the end
of his presidency.

00:31:14.730 --> 00:31:16.860
In this 21st Century
Cures Act, some of you

00:31:16.860 --> 00:31:19.430
might know, include not
only the $1.8 billion

00:31:19.430 --> 00:31:21.450
for the Cancer Moonshot
that I mentioned,

00:31:21.450 --> 00:31:24.840
but also $1.5 billion
for precision medicine,

00:31:24.840 --> 00:31:29.020
for its infrastructure, and
for the larger project of it.

00:31:29.020 --> 00:31:33.580
Notably, Obama would note
that it was important to him

00:31:33.580 --> 00:31:37.330
that ethical
guardrails were placed

00:31:37.330 --> 00:31:42.520
around the issue of
personalized medicine

00:31:42.520 --> 00:31:44.360
before it could move forward.

00:31:44.360 --> 00:31:46.663
So here is a report
from the GINA Act,

00:31:46.663 --> 00:31:49.330
which I'll say a little bit more
about-- the Genetic Information

00:31:49.330 --> 00:31:51.820
Nondiscrimination Act of 2008.

00:31:51.820 --> 00:31:55.000
And his reaction to it,
according to a staffer,

00:31:55.000 --> 00:31:56.980
was that Obama
said that he wanted

00:31:56.980 --> 00:32:00.857
to do the genomics bill,
this act of 2006 and 2007.

00:32:00.857 --> 00:32:02.440
But that he didn't
want to go anywhere

00:32:02.440 --> 00:32:03.890
with it until GINA passes.

00:32:03.890 --> 00:32:05.530
Sort of the sense
that we had to have

00:32:05.530 --> 00:32:08.230
some sort of protective
regulations in place before one

00:32:08.230 --> 00:32:09.670
could move forward.

00:32:09.670 --> 00:32:11.950
So the GINA Act, of
course, in short,

00:32:11.950 --> 00:32:14.050
was signed into
law by George Bush

00:32:14.050 --> 00:32:17.167
and enacted in November, 2009.

00:32:17.167 --> 00:32:19.250
It protects against the
use of genetic information

00:32:19.250 --> 00:32:22.030
to discriminate in the
provision of health care

00:32:22.030 --> 00:32:26.950
and also with regards
to employment.

00:32:26.950 --> 00:32:32.207
So moving forward
to January, 2015,

00:32:32.207 --> 00:32:34.540
when President Obama, in the
State of the Union address,

00:32:34.540 --> 00:32:38.110
would announce a $215
million investment.

00:32:38.110 --> 00:32:42.310
Later, by 2016, as I've just
mentioned, in this 21st Century

00:32:42.310 --> 00:32:47.220
Cures Act, the total investment
would be $1.5 billion

00:32:47.220 --> 00:32:49.420
to launch this
Precision Medicine Act.

00:32:49.420 --> 00:32:51.550
So he said, "tonight, I'm
launching a new Precision

00:32:51.550 --> 00:32:54.340
Medicine Initiative to bring
us closer to curing diseases

00:32:54.340 --> 00:32:56.320
like cancer and diabetes."

00:32:56.320 --> 00:32:58.780
And I want to also
highlight this second part.

00:32:58.780 --> 00:33:01.300
"And to give us all access to
the personalized information

00:33:01.300 --> 00:33:03.910
we need to keep ourselves
and our families healthier."

00:33:03.910 --> 00:33:06.790
So on the one hand is
research investment.

00:33:06.790 --> 00:33:11.170
On the other hand, a recognition
that will become clearer as I

00:33:11.170 --> 00:33:14.650
go on about the role
that he's trying

00:33:14.650 --> 00:33:17.200
to create for the individual,
citizen, consumer,

00:33:17.200 --> 00:33:21.373
patient in a Precision
Medicine Initiative.

00:33:21.373 --> 00:33:23.290
So in brief, the Precision
Medicine Initiative

00:33:23.290 --> 00:33:25.660
is a research endeavor
that aims to understand

00:33:25.660 --> 00:33:28.330
how a person's genetics,
environment, and lifestyle can

00:33:28.330 --> 00:33:31.600
help to determine the best
approach to prevent or treat

00:33:31.600 --> 00:33:32.740
disease.

00:33:32.740 --> 00:33:36.130
Short term goals,
as announced by NIH,

00:33:36.130 --> 00:33:37.780
include expanding
precision medicine

00:33:37.780 --> 00:33:40.900
in the area of cancer
research and to increase

00:33:40.900 --> 00:33:43.480
knowledge of genetics and
the biology of cancer.

00:33:43.480 --> 00:33:46.270
A long term goal, bringing
precision medicine

00:33:46.270 --> 00:33:50.800
to all areas of health and
health care on a large scale.

00:33:50.800 --> 00:33:53.470
But all of this faced
some of the hurdles

00:33:53.470 --> 00:33:54.760
that I mentioned, previously.

00:33:54.760 --> 00:33:57.160
So just to repeat
these, they needed

00:33:57.160 --> 00:33:59.200
to overcome citizen
skepticism related

00:33:59.200 --> 00:34:01.510
to the history of
experimental abuse.

00:34:01.510 --> 00:34:03.760
They needed to establish
some ethical regulations.

00:34:03.760 --> 00:34:08.260
And the GINA Act of 2008 was
a first step in doing this.

00:34:08.260 --> 00:34:10.150
And also to generate
a perception

00:34:10.150 --> 00:34:11.739
of ethical forethought.

00:34:11.739 --> 00:34:16.420
So I'm going to talk a little
bit about one and three, now.

00:34:16.420 --> 00:34:21.429
So Obama announces
on January 15, 2015,

00:34:21.429 --> 00:34:23.980
in the State of the Union
address, the Precision Medicine

00:34:23.980 --> 00:34:25.270
Initiative.

00:34:25.270 --> 00:34:28.150
And about two weeks later,
he has a launch event

00:34:28.150 --> 00:34:30.730
in the east room
of the White House.

00:34:30.730 --> 00:34:33.730
And here, you see one of the
things he does again and again,

00:34:33.730 --> 00:34:38.409
which hearkens back to, some
ways more or less explicitly,

00:34:38.409 --> 00:34:40.540
a history of abuse.

00:34:40.540 --> 00:34:41.980
That would give
people misgivings

00:34:41.980 --> 00:34:43.989
about precision medicine.

00:34:43.989 --> 00:34:47.350
And tries to encourage people
that they should move forward.

00:34:47.350 --> 00:34:50.080
So he says here at this launch,
"we've got to figure out,

00:34:50.080 --> 00:34:53.050
how do we make sure that if I
donate my data to this big pool

00:34:53.050 --> 00:34:54.850
that it's not going
to be misused?

00:34:54.850 --> 00:34:57.310
That it's not going to be
commercialized in some way

00:34:57.310 --> 00:34:58.450
I don't know about?

00:34:58.450 --> 00:35:03.970
And so we've got to set up
a series of structures."

00:35:03.970 --> 00:35:07.990
So part of the
structures was a series.

00:35:07.990 --> 00:35:12.430
This is a fascinating
document on privacy and trust

00:35:12.430 --> 00:35:14.020
principles.

00:35:14.020 --> 00:35:18.010
At its most radical,
it's asserting a right

00:35:18.010 --> 00:35:20.830
to citizen science, a right
for individual consumers

00:35:20.830 --> 00:35:24.670
to be able to use their
genome, and to have access

00:35:24.670 --> 00:35:27.020
to the information that
their genetic information

00:35:27.020 --> 00:35:29.560
and genetic data might provide.

00:35:29.560 --> 00:35:32.260
It asserts a strong
right to privacy.

00:35:32.260 --> 00:35:35.110
It asserts a 21st
century version

00:35:35.110 --> 00:35:37.900
of a patients' bill of
rights or research subjects'

00:35:37.900 --> 00:35:39.430
bill of rights.

00:35:39.430 --> 00:35:41.710
It's a very
aspirational document.

00:35:41.710 --> 00:35:44.950
And indeed, it's a document
about any legal bearings.

00:35:44.950 --> 00:35:46.720
So it's kind of all aspiration.

00:35:46.720 --> 00:35:50.080
But it's a very interesting
historical document

00:35:50.080 --> 00:35:52.330
that, I think, we'll be
talking about for a long time.

00:35:52.330 --> 00:35:55.510
Because it very much
bears the imprimatur,

00:35:55.510 --> 00:35:58.990
I think, in some ways, of many
of the kind of Silicon Valley

00:35:58.990 --> 00:36:03.310
diaspora that come to work in
the Obama administration, that

00:36:03.310 --> 00:36:06.220
take pay cuts, who very much
believe in the work that's

00:36:06.220 --> 00:36:09.460
being done here to advance
science and technology policy.

00:36:09.460 --> 00:36:13.750
And bring with them a very
kind of romantic idea of what

00:36:13.750 --> 00:36:16.630
science and technology can do.

00:36:16.630 --> 00:36:20.440
Another quote from Obama that
gets him in trouble, "I would

00:36:20.440 --> 00:36:24.190
like to think that if someone
does a test on me or my genes,

00:36:24.190 --> 00:36:26.080
that that's mine.

00:36:26.080 --> 00:36:28.150
But that's not always how
we define these issues.

00:36:28.150 --> 00:36:32.050
So there's some legal
issues involved, as well."

00:36:32.050 --> 00:36:34.330
So within a few hours,
The New York Times

00:36:34.330 --> 00:36:36.070
is talking about how
the president weighs

00:36:36.070 --> 00:36:37.450
in on data from genes.

00:36:37.450 --> 00:36:41.680
Because as many of us
know, your genomic data

00:36:41.680 --> 00:36:42.670
does not belong to you.

00:36:42.670 --> 00:36:45.700
Someone captures
it in a laboratory.

00:36:45.700 --> 00:36:47.710
And indeed, George
Contreras, who's

00:36:47.710 --> 00:36:50.220
a law professor at the
University of Utah,

00:36:50.220 --> 00:36:55.420
who I interviewed recently, who
went to law school with Obama,

00:36:55.420 --> 00:37:02.755
here at HLS, writes this
rejoinder to President Obama.

00:37:02.755 --> 00:37:04.630
That says in part, "US
courts have repeatedly

00:37:04.630 --> 00:37:07.210
denied individual censorship
claims over data derived

00:37:07.210 --> 00:37:08.860
from their cells and tissue.

00:37:08.860 --> 00:37:10.450
Just imagine the
chaos that would

00:37:10.450 --> 00:37:13.210
ensue if each of the million
participants in the Precision

00:37:13.210 --> 00:37:15.370
Medicine Initiative
could claim ownership

00:37:15.370 --> 00:37:19.270
over discoveries that were
made after large pools of DNA

00:37:19.270 --> 00:37:20.150
were analyzed."

00:37:20.150 --> 00:37:22.830
So imagine, indeed.

00:37:22.830 --> 00:37:26.130
So President Obama
and his staff realized

00:37:26.130 --> 00:37:29.070
that they had to, for all
sorts of reasons, sell it.

00:37:29.070 --> 00:37:32.200
So this is, as
far as I can tell,

00:37:32.200 --> 00:37:35.370
the only of their big projects
that had two launches.

00:37:35.370 --> 00:37:37.470
So there's the
January 2015 launch.

00:37:37.470 --> 00:37:41.310
That's a couple of weeks after
the State of the Union address,

00:37:41.310 --> 00:37:43.200
in which Obama launches this.

00:37:43.200 --> 00:37:47.580
Then there's a
summit a year later.

00:37:47.580 --> 00:37:52.380
Which he engages
researchers, the woman here,

00:37:52.380 --> 00:37:56.160
from the Broad Institute,
research scientists

00:37:56.160 --> 00:37:59.400
to talk about, in a public way--

00:37:59.400 --> 00:38:05.820
this was streamed-- what the
Precision Medicine Initiative

00:38:05.820 --> 00:38:07.320
might be able to accomplish.

00:38:07.320 --> 00:38:10.560
But also to give voice
from the perspective

00:38:10.560 --> 00:38:14.580
of patients, consumers,
health care economists--

00:38:14.580 --> 00:38:16.360
what some of the
challenges might be.

00:38:16.360 --> 00:38:20.550
So there's lots of conversation,
most of it initiated

00:38:20.550 --> 00:38:23.340
by him about
privacy fears, about

00:38:23.340 --> 00:38:25.500
fears of genetic
discrimination, about

00:38:25.500 --> 00:38:27.990
the need for new safeguards,
and also the need

00:38:27.990 --> 00:38:30.360
for more nimble
regulation if something

00:38:30.360 --> 00:38:33.915
like precision medicine should
take off in the United States.

00:38:36.542 --> 00:38:38.125
Actually, I think
this is fascinating.

00:38:38.125 --> 00:38:39.210
It's 42 minutes.

00:38:39.210 --> 00:38:42.150
It's really interesting,
because President Obama

00:38:42.150 --> 00:38:44.220
is on the stage with
actual scientists

00:38:44.220 --> 00:38:46.960
and takes it upon himself
to talk about the science.

00:38:46.960 --> 00:38:50.400
So there's also this odd--

00:38:50.400 --> 00:38:54.360
as someone who really admires
expertise, as he does,

00:38:54.360 --> 00:38:57.060
he's also very learned
and very much wanted

00:38:57.060 --> 00:38:59.160
to demonstrate that
he had learned quite

00:38:59.160 --> 00:39:02.100
a lot about genome wide
association studies,

00:39:02.100 --> 00:39:03.610
and the need for
diverse databases,

00:39:03.610 --> 00:39:04.860
and all these sorts of things.

00:39:04.860 --> 00:39:07.770
So it's a fascinating
performance

00:39:07.770 --> 00:39:09.960
of the ethical framing
that I'm talking about.

00:39:09.960 --> 00:39:13.920
And also, it's an interesting
Obama presidency moment.

00:39:13.920 --> 00:39:17.640
So part of what they're talking
about in this conversation

00:39:17.640 --> 00:39:22.020
is anticipation of a facet
of the Precision Medicine

00:39:22.020 --> 00:39:24.810
Initiative called All of
Us, which is an endeavor

00:39:24.810 --> 00:39:29.970
to recruit 1 million volunteers
from around the United States

00:39:29.970 --> 00:39:32.070
to provide genetic data,
biological samples,

00:39:32.070 --> 00:39:33.300
and other health information.

00:39:33.300 --> 00:39:36.090
Because the genetic data is not
useful without the other health

00:39:36.090 --> 00:39:37.230
information.

00:39:37.230 --> 00:39:39.700
And also to encourage
open data sharing.

00:39:39.700 --> 00:39:42.150
So there's this open
science, citizen science

00:39:42.150 --> 00:39:44.190
piece of this that remains.

00:39:44.190 --> 00:39:45.600
Volunteers will
be able to access

00:39:45.600 --> 00:39:47.580
their health information
as well as research

00:39:47.580 --> 00:39:49.620
that uses their data.

00:39:49.620 --> 00:39:52.800
So as President Obama would
suggest in this conversation,

00:39:52.800 --> 00:39:54.390
this summit at
which, again, they're

00:39:54.390 --> 00:39:56.760
really trying to sell people.

00:39:56.760 --> 00:39:59.190
And they're trying to
get people to overcome

00:39:59.190 --> 00:40:01.232
their skepticism,
variously, about why

00:40:01.232 --> 00:40:02.190
this should go forward.

00:40:02.190 --> 00:40:04.620
So they're really selling
it at this second summit.

00:40:04.620 --> 00:40:07.380
It's important that these
be, as he describes,

00:40:07.380 --> 00:40:09.090
diverse databases.

00:40:09.090 --> 00:40:11.370
And so the face
of all of us often

00:40:11.370 --> 00:40:12.660
looks something like this.

00:40:12.660 --> 00:40:17.040
We need a million person
database that, quite frankly,

00:40:17.040 --> 00:40:20.190
is probably over sampled
for people of color,

00:40:20.190 --> 00:40:24.150
if the sort of types of
big data analysis that

00:40:24.150 --> 00:40:27.840
wants to be accomplished
can be accomplished, there.

00:40:27.840 --> 00:40:29.400
And this remains
a central issue.

00:40:29.400 --> 00:40:34.590
This is an article that a
colleague, Maleeha Fullerton,

00:40:34.590 --> 00:40:38.760
published with a
colleague in Nature,

00:40:38.760 --> 00:40:40.680
called Genomics is
Failing on Diversity,

00:40:40.680 --> 00:40:44.010
about the lack of diversity
in genetic databases.

00:40:44.010 --> 00:40:48.990
That really gave a sense
of urgency to the All of Us

00:40:48.990 --> 00:40:51.990
initiative.

00:40:51.990 --> 00:40:54.630
If it's the case that we need
to have more diverse databases,

00:40:54.630 --> 00:40:55.880
how are we going to get there?

00:40:55.880 --> 00:40:58.740
This is data from
the same article

00:40:58.740 --> 00:41:02.520
about the bias, with
regards to genetic samples

00:41:02.520 --> 00:41:06.570
that they're significantly
majority genetic samples

00:41:06.570 --> 00:41:11.520
of European ancestry,
that have, obviously,

00:41:11.520 --> 00:41:15.630
analytic implications for
the import of the work

00:41:15.630 --> 00:41:18.870
if precision medicine works,
and if this Precision Medicine

00:41:18.870 --> 00:41:22.240
Initiative is to go forward.

00:41:22.240 --> 00:41:27.840
So there's a kind
of fever to get

00:41:27.840 --> 00:41:29.250
these more diverse databases.

00:41:29.250 --> 00:41:31.530
It's also part of
the express mission

00:41:31.530 --> 00:41:33.960
of the All of Us Initiative.

00:41:33.960 --> 00:41:36.600
But all of this is
occurring against a backdrop

00:41:36.600 --> 00:41:40.020
in which other things
with data are happening.

00:41:40.020 --> 00:41:43.020
So Nancy Secola, in the
Wall Street Journal,

00:41:43.020 --> 00:41:45.570
in 2013, would name Obama--

00:41:45.570 --> 00:41:47.940
I call him, for this
talk, the ELSI Presidency.

00:41:47.940 --> 00:41:50.730
She calls him the Big
Data Presidency, but not

00:41:50.730 --> 00:41:52.440
because of the PMI.

00:41:52.440 --> 00:41:54.150
She calls him the
Big Data Presidency

00:41:54.150 --> 00:41:57.660
because she's writing
here about the NSA

00:41:57.660 --> 00:41:59.910
and about the surveillance
infrastructure

00:41:59.910 --> 00:42:02.370
that the Obama
administration-- another thing

00:42:02.370 --> 00:42:05.130
distinctive to science and
technology in the Obama

00:42:05.130 --> 00:42:10.560
administration-- expanded more
than any administration prior.

00:42:10.560 --> 00:42:13.710
So all of us in the
Precision Medicine Initiative

00:42:13.710 --> 00:42:15.990
are happening at a
time where we have

00:42:15.990 --> 00:42:17.700
a ratcheting up in
public discourse

00:42:17.700 --> 00:42:21.390
of conversation about big data,
more generally, and concerns

00:42:21.390 --> 00:42:25.340
about surveillance, both on
the part of a cyber security

00:42:25.340 --> 00:42:29.600
infrastructure and on the
part of private companies.

00:42:29.600 --> 00:42:32.540
Such that, this
is from Stat News,

00:42:32.540 --> 00:42:37.670
by 2017, it's the case that
we're being told that in order

00:42:37.670 --> 00:42:41.120
to advance medicine's future--

00:42:41.120 --> 00:42:44.600
and this is an article on
how the NIH is endeavoring

00:42:44.600 --> 00:42:47.720
through all of us to win the
trust of communities who had

00:42:47.720 --> 00:42:49.020
been mistreated in the past--

00:42:52.130 --> 00:42:54.590
as a central challenge to
the work that they're doing.

00:42:57.270 --> 00:43:03.240
So this is from that
2015 announcement

00:43:03.240 --> 00:43:06.090
of the first launch of
the PMI, in the east room

00:43:06.090 --> 00:43:06.908
at the White House.

00:43:06.908 --> 00:43:09.450
President Obama pictured there
with Francis Collins, director

00:43:09.450 --> 00:43:12.390
of the NIH, and Harold
Varmus, who, for a time,

00:43:12.390 --> 00:43:15.300
was co-chair with
John Holdren and Eric

00:43:15.300 --> 00:43:19.110
Lander of the President
Council of Advisors

00:43:19.110 --> 00:43:22.120
on Science and Technology.

00:43:22.120 --> 00:43:25.650
So this is a moment of
possibility and aspiration,

00:43:25.650 --> 00:43:26.970
as I said.

00:43:26.970 --> 00:43:29.340
But it also takes a few years.

00:43:29.340 --> 00:43:30.420
This is 2015.

00:43:30.420 --> 00:43:33.300
It's not really until
late 2017, early 2018,

00:43:33.300 --> 00:43:36.770
that the real enrollment
for all of us begins.

00:43:36.770 --> 00:43:39.113
And I should say that
my university, Columbia,

00:43:39.113 --> 00:43:39.780
working with Mt.

00:43:39.780 --> 00:43:41.910
Sinai and some other
institutions in New York City,

00:43:41.910 --> 00:43:45.180
is one of the enrollment centers
for the Precision Medicine

00:43:45.180 --> 00:43:47.460
Initiative.

00:43:47.460 --> 00:43:49.350
So what's also
happening in big data?

00:43:49.350 --> 00:43:55.830
So this is how Wired chooses
to cover the launch of the NIH

00:43:55.830 --> 00:43:57.870
All of Us enrollment.

00:43:57.870 --> 00:44:01.980
The first line here, from
this piece from May of 2018,

00:44:01.980 --> 00:44:05.340
is about Cambridge Analytica,
and talks about the challenges

00:44:05.340 --> 00:44:08.940
that the NIH and all of us
will face with the Precision

00:44:08.940 --> 00:44:11.520
Medicine Initiative, in which
the public is increasingly

00:44:11.520 --> 00:44:15.170
concerned about data.

00:44:15.170 --> 00:44:17.690
Washington Post, "NIH
seeks health data

00:44:17.690 --> 00:44:19.520
of 1 million people,
with genetic privacy

00:44:19.520 --> 00:44:24.490
suddenly an issue,"
again, from May of 2018.

00:44:24.490 --> 00:44:28.630
So I want to suggest here
that, as I describe in my book

00:44:28.630 --> 00:44:31.990
that Dean Brown-Nagin
so generously described,

00:44:31.990 --> 00:44:37.180
The Social Life of DNA,
part of what is happening

00:44:37.180 --> 00:44:39.670
with regards to the
Precision Medicine Initiative

00:44:39.670 --> 00:44:44.260
is that the ways in which
ideas about data and DNA

00:44:44.260 --> 00:44:46.360
are elaborated in
one social site

00:44:46.360 --> 00:44:49.240
actually affect how people think
about them in other places.

00:44:49.240 --> 00:44:53.800
So it is the case, for example,
that people that I interviewed

00:44:53.800 --> 00:44:58.090
about direct to consumer
ancestry testing

00:44:58.090 --> 00:45:01.000
would often reference things
like the use of genetics

00:45:01.000 --> 00:45:02.320
in the criminal justice system.

00:45:02.320 --> 00:45:05.800
In this case, to exonerate a
man who'd been wrongly in prison

00:45:05.800 --> 00:45:10.660
for 25 years, who was
exonerated through the work

00:45:10.660 --> 00:45:13.990
of the Innocence Project,
which has freed just

00:45:13.990 --> 00:45:17.830
under 300 people over more
than a decade of work.

00:45:21.190 --> 00:45:23.650
Also happening, particularly
in the new presidential

00:45:23.650 --> 00:45:26.830
administration, are debates
about whether DNA testing

00:45:26.830 --> 00:45:30.970
and DNA analysis should be used
to reunite immigrant families

00:45:30.970 --> 00:45:37.540
in a political moment in
which anti-immigrant fears

00:45:37.540 --> 00:45:40.870
and anti-immigrant sentiment
in the United States

00:45:40.870 --> 00:45:43.330
is pronounced.

00:45:43.330 --> 00:45:48.400
As well as the use of databases
by the criminal justice

00:45:48.400 --> 00:46:02.080
system without warrants and
other legal regulations being

00:46:02.080 --> 00:46:03.470
met.

00:46:03.470 --> 00:46:05.080
So part of what
I want to suggest

00:46:05.080 --> 00:46:08.890
is that as we move from Obama,
the ELSI President, the Big

00:46:08.890 --> 00:46:12.790
Data President, and also the
Black President, who I think

00:46:12.790 --> 00:46:15.910
holds a particular place and
can say particular things

00:46:15.910 --> 00:46:18.580
about how genetics
might be misused,

00:46:18.580 --> 00:46:22.270
how data might be misused.

00:46:22.270 --> 00:46:25.900
But also in the way that
was true of his presidency,

00:46:25.900 --> 00:46:32.020
allow people to trust him
as his person and a person.

00:46:32.020 --> 00:46:34.270
Much of this is lost in
the Trump presidency.

00:46:34.270 --> 00:46:39.190
I think that few could imagine
launching a Precision Medicine

00:46:39.190 --> 00:46:43.630
Initiative, I think, in the same
way under a Trump presidency.

00:46:43.630 --> 00:46:47.710
But here we have an initiative
that is moving forward.

00:46:47.710 --> 00:46:51.280
And it's moving forward to
an enrollment stage at a time

00:46:51.280 --> 00:46:56.350
where there are legitimate
concerns about genetics

00:46:56.350 --> 00:46:59.530
and about data, more generally.

00:46:59.530 --> 00:47:01.180
So the ELSI frame--

00:47:01.180 --> 00:47:05.020
that becomes the frame, in part,
for federal science, I argue,

00:47:05.020 --> 00:47:07.780
in the Obama administration--

00:47:07.780 --> 00:47:10.450
has faced lots of criticism.

00:47:10.450 --> 00:47:14.920
As early as 2003, the science
and technology studies scholar,

00:47:14.920 --> 00:47:16.690
Landon Winter,
who was testifying

00:47:16.690 --> 00:47:23.410
at a committee on the
ELSI of nanotechnology,

00:47:23.410 --> 00:47:26.740
would say, "there is a tendency
for those to conduct research

00:47:26.740 --> 00:47:28.930
about the ethical dimensions
of emerging technology

00:47:28.930 --> 00:47:30.970
to gravitate towards
the more comfortable

00:47:30.970 --> 00:47:34.090
even trivial questions involved,
avoiding issues that might

00:47:34.090 --> 00:47:36.040
become a focus of conflict.

00:47:36.040 --> 00:47:40.790
People in bioethics
rarely say no."

00:47:40.790 --> 00:47:43.920
And one might say the same
of the Obama Administration's

00:47:43.920 --> 00:47:46.050
approach to its ethical framing.

00:47:46.050 --> 00:47:49.560
So while it did give voice
to mistreatment of the past,

00:47:49.560 --> 00:47:52.440
it did do a kind
of performance that

00:47:52.440 --> 00:47:54.660
allowed people,
if they wanted to,

00:47:54.660 --> 00:47:58.410
overcome the skepticism
that they had.

00:47:58.410 --> 00:48:02.640
They were never meant to be
engagements, conversations,

00:48:02.640 --> 00:48:04.740
performances, public
events that were

00:48:04.740 --> 00:48:06.720
intended for people to say no.

00:48:06.720 --> 00:48:10.590
It was always the case that
the moonshots would proceed.

00:48:10.590 --> 00:48:13.530
It was always the case
that the moonshots

00:48:13.530 --> 00:48:17.220
would be funded
almost exclusively

00:48:17.220 --> 00:48:19.350
through federal
appropriation, in this case.

00:48:19.350 --> 00:48:23.150
Because Obama's funding
was blocked in other ways.

00:48:23.150 --> 00:48:26.010
But they also
knew, as an entity,

00:48:26.010 --> 00:48:29.140
as an organization, that they
had to have a flight plan.

00:48:29.140 --> 00:48:32.710
That there had to be some public
performance, some public voice

00:48:32.710 --> 00:48:38.020
to ethical guardrails
and concerns.

00:48:38.020 --> 00:48:41.990
We can hope that
as we move forward

00:48:41.990 --> 00:48:45.220
in thinking about the
ethical turn more generally

00:48:45.220 --> 00:48:49.330
in US culture with regards to
data ethics, computer science

00:48:49.330 --> 00:48:51.760
ethics, genetics and
ethics, and the like,

00:48:51.760 --> 00:48:55.270
that we might hark
back to a time in 1990,

00:48:55.270 --> 00:49:00.010
where we imagined that an
ethical orientation to science

00:49:00.010 --> 00:49:03.175
and technology could
be broad and capacious.

00:49:03.175 --> 00:49:06.645
It could include
unprotected data banks.

00:49:06.645 --> 00:49:09.010
It could include a
genetic underclass

00:49:09.010 --> 00:49:14.384
now well in formation, law
enforcement agencies, as well.

00:49:14.384 --> 00:49:15.830
Thank you.

00:49:15.830 --> 00:49:18.722
[APPLAUSE]

00:49:24.988 --> 00:49:29.130
- I'm Nick Patterson I'm a
geneticist and I've worked

00:49:29.130 --> 00:49:33.810
extensively on African-American
medical genetics.

00:49:33.810 --> 00:49:38.670
And I just wanted to tell
you a small incident, which

00:49:38.670 --> 00:49:42.300
I think is revealing about the
difficulties of interacting

00:49:42.300 --> 00:49:45.240
with scientific research
and law enforcement.

00:49:45.240 --> 00:49:48.090
I was involved in a
cardiovascular study

00:49:48.090 --> 00:49:49.650
on African-Americans.

00:49:49.650 --> 00:49:53.460
We were seeking genetic
links to heart disease

00:49:53.460 --> 00:49:55.500
in the African-American
community.

00:49:55.500 --> 00:49:57.990
This is something called
the Jackson Heart Study.

00:49:57.990 --> 00:50:00.780
And it was centered
in Mississippi.

00:50:00.780 --> 00:50:03.390
The response we got from the
African-American community

00:50:03.390 --> 00:50:07.500
down there was much
worse than we thought.

00:50:07.500 --> 00:50:09.750
We got fewer people signed up.

00:50:09.750 --> 00:50:14.070
And the key thing was
that many, many members

00:50:14.070 --> 00:50:16.230
of the African-American
community

00:50:16.230 --> 00:50:18.780
said, if I give
you my DNA, will it

00:50:18.780 --> 00:50:21.610
be available to law enforcement?

00:50:21.610 --> 00:50:25.390
And the answer is, under
subpoena, absolutely, yes.

00:50:25.390 --> 00:50:26.530
Thank you very much.

00:50:26.530 --> 00:50:29.470
We don't want to know anymore.

00:50:29.470 --> 00:50:31.720
So that's a real difficulty.

00:50:31.720 --> 00:50:34.270
You have an ethics community
in the White House.

00:50:34.270 --> 00:50:36.480
You have law enforcement
organizations, sometimes

00:50:36.480 --> 00:50:39.040
at state level, who aren't
the least interested

00:50:39.040 --> 00:50:40.810
in what the White
House is saying.

00:50:40.810 --> 00:50:45.340
And the whole thing interacts
in very complex ways,

00:50:45.340 --> 00:50:47.770
often not very advantageous.

00:50:47.770 --> 00:50:50.560
I don't really
have a model, here.

00:50:50.560 --> 00:50:52.070
But I wonder if you have.

00:50:52.070 --> 00:50:54.580
- Well, I guess one
thing I would say

00:50:54.580 --> 00:50:57.340
is that it needs to be
OK for people to say no.

00:50:57.340 --> 00:51:00.040
So I think that we need to be
able to have a conversation

00:51:00.040 --> 00:51:01.870
in which folks should say no.

00:51:01.870 --> 00:51:08.080
And there's not a sense of
entitlement to people's DNA

00:51:08.080 --> 00:51:10.192
information is one
thing I would offer.

00:51:10.192 --> 00:51:11.650
I thought, actually,
you were going

00:51:11.650 --> 00:51:13.150
to say something
about the Tuskegee

00:51:13.150 --> 00:51:14.380
Experiment or the Holocaust.

00:51:14.380 --> 00:51:15.880
These are the kinds
of, particularly

00:51:15.880 --> 00:51:18.760
in the social science
literature and medicine,

00:51:18.760 --> 00:51:22.060
stories that come up more
often about people's refusal

00:51:22.060 --> 00:51:23.980
or skepticism, about
African-Americans

00:51:23.980 --> 00:51:28.900
in particular, about
participating in such studies.

00:51:28.900 --> 00:51:33.610
But the headlines that
I ended with, certainly,

00:51:33.610 --> 00:51:36.130
when I first started
working with people

00:51:36.130 --> 00:51:39.580
around contemporary genetics
issues, post-human genome

00:51:39.580 --> 00:51:42.280
genetics, conversations I would
have with African-Americans--

00:51:42.280 --> 00:51:46.090
it was certainly the case
that the criminal justice

00:51:46.090 --> 00:51:48.160
system was mentioned.

00:51:48.160 --> 00:51:52.600
But there were all sorts of
other fears that people had,

00:51:52.600 --> 00:51:53.680
as well.

00:51:53.680 --> 00:51:56.200
I think as we continue to
have these high profile

00:51:56.200 --> 00:52:00.490
cases in which not only
are folks exonerated--

00:52:00.490 --> 00:52:03.940
and we should say that something
like the Innocence Project

00:52:03.940 --> 00:52:06.220
only makes sense in a
society in which you

00:52:06.220 --> 00:52:10.630
incarcerate 2.3 million people,
many of them without cause.

00:52:13.540 --> 00:52:19.510
But as these cases come to light
of surreptitious DNA collection

00:52:19.510 --> 00:52:24.190
by criminal justice authorities,
the use of what people thought

00:52:24.190 --> 00:52:27.610
were citizen science databases
that they were participating in

00:52:27.610 --> 00:52:31.210
with other geneticists to learn
more about their families,

00:52:31.210 --> 00:52:34.930
being used, again, without
subpoena, without a warrant

00:52:34.930 --> 00:52:37.990
by the criminal justice
system, that it's only

00:52:37.990 --> 00:52:39.250
going to get more challenging.

00:52:39.250 --> 00:52:41.620
So I would say to
you that if you

00:52:41.620 --> 00:52:43.240
were to go ahead
and do that now,

00:52:43.240 --> 00:52:47.920
in the face of two summers,
now, of these stories about how

00:52:47.920 --> 00:52:51.280
pernicious the criminal
justice authorities have been

00:52:51.280 --> 00:52:54.280
and their use of
these open databases,

00:52:54.280 --> 00:52:57.600
that your yield
would be less, still.

00:52:57.600 --> 00:52:58.600
Thanks for your comment.

00:53:03.520 --> 00:53:05.260
- Doctor Nelson,
that was fantastic.

00:53:05.260 --> 00:53:05.760
Thank you.

00:53:05.760 --> 00:53:06.860
- Thank you.

00:53:06.860 --> 00:53:09.000
- I'm thinking with
my capture hat on.

00:53:09.000 --> 00:53:09.510
- Yes.

00:53:09.510 --> 00:53:12.683
- And I am wondering--

00:53:12.683 --> 00:53:14.850
and I'm just I'm looking
forward to reading the book

00:53:14.850 --> 00:53:16.440
and learning more--

00:53:16.440 --> 00:53:21.090
what was the role of commercial
corporate enterprises

00:53:21.090 --> 00:53:22.530
in this process?

00:53:22.530 --> 00:53:26.670
And once upon a time,
recognizing as I say this--

00:53:26.670 --> 00:53:30.420
and I'll just leave
the answer to you--

00:53:30.420 --> 00:53:33.960
we would have thought, well,
the drug companies or biopharma.

00:53:33.960 --> 00:53:36.180
But in the world that
you're describing,

00:53:36.180 --> 00:53:38.580
as you know undoubtedly
better than I do,

00:53:38.580 --> 00:53:42.840
it's these networks of capital,
and science, and technology.

00:53:42.840 --> 00:53:46.470
Venture capital funds,
hedge funds, Silicon Valley,

00:53:46.470 --> 00:53:49.320
which is the new biggest
player in health care,

00:53:49.320 --> 00:53:51.360
in combination with these.

00:53:51.360 --> 00:53:53.400
And so just an
open ended question

00:53:53.400 --> 00:53:55.000
that I'd just love
to know more about

00:53:55.000 --> 00:53:57.330
is, what were the pressure
points that you've

00:53:57.330 --> 00:53:59.820
seen in the Obama
administration,

00:53:59.820 --> 00:54:01.710
including in some
of these groups,

00:54:01.710 --> 00:54:05.880
Holdren's groups, and
others for what you might

00:54:05.880 --> 00:54:07.380
call industrial interests?

00:54:07.380 --> 00:54:08.870
- Yes.

00:54:08.870 --> 00:54:11.370
You won't be surprised to hear
that the industrial interests

00:54:11.370 --> 00:54:13.530
were significant.

00:54:13.530 --> 00:54:15.960
Yes, right.

00:54:15.960 --> 00:54:18.690
But distinctive in that many of
them were for Silicon Valley.

00:54:18.690 --> 00:54:23.310
So you had, I think, instead
of having the K Street lobby

00:54:23.310 --> 00:54:25.530
situation, you had people who--

00:54:25.530 --> 00:54:27.163
in some cases,
young entrepreneurs

00:54:27.163 --> 00:54:28.830
or VCs from Silicon
Valley-- were really

00:54:28.830 --> 00:54:32.150
engaging with the federal
government for the first time.

00:54:32.150 --> 00:54:34.863
And engagement, as opposed to
we just want to disrupt it.

00:54:34.863 --> 00:54:36.030
It was actually, we will go.

00:54:36.030 --> 00:54:38.520
We will take meetings
and the like.

00:54:38.520 --> 00:54:40.740
So that was
certainly part of it.

00:54:40.740 --> 00:54:43.830
Part of what I've heard a lot in
the conversations with staffers

00:54:43.830 --> 00:54:46.440
is that you'll recall that
the Obama Administration did

00:54:46.440 --> 00:54:47.610
a lot of commitments.

00:54:47.610 --> 00:54:52.763
So My Brother's
Keeper, for example,

00:54:52.763 --> 00:54:54.180
would be one of
these commitments.

00:54:54.180 --> 00:54:57.870
Which partly because the Obama
administration was really

00:54:57.870 --> 00:55:03.120
blocked in getting funding for
things through the legislature,

00:55:03.120 --> 00:55:05.790
they were, I think,
made to do more and be

00:55:05.790 --> 00:55:09.930
more creative in these
commercial partnerships.

00:55:09.930 --> 00:55:12.480
And so they borrowed
this commitment model

00:55:12.480 --> 00:55:13.800
from the Clinton Foundation.

00:55:13.800 --> 00:55:15.420
It's the Clinton
Global Foundation--

00:55:15.420 --> 00:55:19.200
it's the private public
commitments model.

00:55:19.200 --> 00:55:20.850
And do quite a lot of that.

00:55:20.850 --> 00:55:26.100
But it becomes not so
much a free market,

00:55:26.100 --> 00:55:27.360
ideological commitment.

00:55:27.360 --> 00:55:30.990
But I think there's
that, of course.

00:55:30.990 --> 00:55:34.320
But also, I think
this happens a lot.

00:55:34.320 --> 00:55:35.970
The strategy that
they're left with,

00:55:35.970 --> 00:55:40.830
given that they can't get money
out of the legislature, right?

00:55:40.830 --> 00:55:44.790
Given that in the first
few hours after Obama

00:55:44.790 --> 00:55:47.220
is first president, Mitch
McConnell is basically like,

00:55:47.220 --> 00:55:50.740
we will frustrate anything
you try to do, forever.

00:55:50.740 --> 00:55:53.130
And that has implications
for what they're able to do

00:55:53.130 --> 00:55:55.890
and who they must
partner with in the work

00:55:55.890 --> 00:55:57.180
that they do in science.

00:55:57.180 --> 00:56:00.450
Also this is a total nerdy,
Daniel Carpenter thing.

00:56:00.450 --> 00:56:02.850
Given what I've learned
from you about bureaucracy,

00:56:02.850 --> 00:56:05.580
but it also had implications
for how they did their work.

00:56:05.580 --> 00:56:09.158
So they couldn't appoint people.

00:56:09.158 --> 00:56:10.950
Because you couldn't
get any appropriations

00:56:10.950 --> 00:56:11.970
lines to appoint people.

00:56:11.970 --> 00:56:15.330
So the Innovation Fellows,
which I was just like,

00:56:15.330 --> 00:56:16.230
it was so amazing.

00:56:16.230 --> 00:56:18.120
The first interviews I was
doing, I was just like,

00:56:18.120 --> 00:56:19.037
oh, it was so amazing.

00:56:19.037 --> 00:56:20.890
You guys did this
Innovation Fellows.

00:56:20.890 --> 00:56:23.788
And someone sort of
said to me flatly,

00:56:23.788 --> 00:56:25.080
you know why we had to do that?

00:56:25.080 --> 00:56:26.520
It's because we
didn't have any budget

00:56:26.520 --> 00:56:27.812
lines to make any appointments.

00:56:27.812 --> 00:56:30.660
But you can appoint a Fellow.

00:56:30.660 --> 00:56:33.000
The president can
appoint Fellows all day

00:56:33.000 --> 00:56:36.870
and try to figure out how to
get funding to support them.

00:56:36.870 --> 00:56:40.110
So it's partly not a
new story about capture.

00:56:40.110 --> 00:56:43.740
But it's partly
about what happens

00:56:43.740 --> 00:56:49.230
in a presidential administration
with a deeply recalcitrant

00:56:49.230 --> 00:56:54.280
legislative branch, and how
they try to work around that.

00:56:54.280 --> 00:56:56.130
- Hi, thank you for this.

00:56:56.130 --> 00:56:57.900
I wanted to ask you
a little bit more

00:56:57.900 --> 00:57:01.230
about how the current public
conversation around the ethics

00:57:01.230 --> 00:57:05.460
of big data is impacting the
way that this ethical framing is

00:57:05.460 --> 00:57:06.750
taking form.

00:57:06.750 --> 00:57:09.300
Because if I think back to the
early days of the Human Genome

00:57:09.300 --> 00:57:11.550
Project and the emergence
of the ELSI agenda,

00:57:11.550 --> 00:57:14.160
you can see pretty clearly
how it is that the HIV AIDS

00:57:14.160 --> 00:57:17.160
epidemic that was taking place
in that historical moment,

00:57:17.160 --> 00:57:19.830
that impacted what people
were thinking about in terms

00:57:19.830 --> 00:57:21.130
of ethical issues.

00:57:21.130 --> 00:57:23.220
But here, the connection
seems a little bit looser

00:57:23.220 --> 00:57:26.310
to me, in that you have a lot of
public conversation about data

00:57:26.310 --> 00:57:28.620
privacy, and the
right to privacy.

00:57:28.620 --> 00:57:31.380
While at the same time, you
have a very pro information

00:57:31.380 --> 00:57:34.680
bias in what's happening in the
Precision Medicine Initiative.

00:57:34.680 --> 00:57:38.250
That's about access to
research as a good, right?

00:57:38.250 --> 00:57:40.692
So I'm wondering if you
can just draw those links

00:57:40.692 --> 00:57:42.150
a little bit closer
about how it is

00:57:42.150 --> 00:57:44.340
that the important
ethical conversations

00:57:44.340 --> 00:57:47.340
of this historical moment are
shaping what's going on today?

00:57:47.340 --> 00:57:48.698
- Yeah, thank you for that.

00:57:48.698 --> 00:57:49.990
That's a really great question.

00:57:49.990 --> 00:57:53.110
And I'm not sure that I'll
have a totally complete answer,

00:57:53.110 --> 00:57:54.400
but I'll endeavor one.

00:57:54.400 --> 00:57:58.470
So I think we see it a
little bit in the quote

00:57:58.470 --> 00:58:01.830
that I pulled about Obama
saying, if that's my DNA,

00:58:01.830 --> 00:58:03.030
then that's me.

00:58:03.030 --> 00:58:06.780
And you see it as well in that
document of privacy and trust

00:58:06.780 --> 00:58:07.620
principles.

00:58:07.620 --> 00:58:13.260
So it's very much about putting
the individual consumer,

00:58:13.260 --> 00:58:17.790
as data point, data
supplier, in the driver's

00:58:17.790 --> 00:58:20.460
seat of making decisions
about privacy and access

00:58:20.460 --> 00:58:21.780
to their data.

00:58:21.780 --> 00:58:25.590
Even as we know that that's
not the legal standard,

00:58:25.590 --> 00:58:29.100
it very much gives voice
to that as a sort of ethos

00:58:29.100 --> 00:58:30.930
and as an ideal.

00:58:30.930 --> 00:58:39.570
And so the ethical
complication is that the ELSI--

00:58:39.570 --> 00:58:41.880
and the Paul Rabinow
slide that I put up

00:58:41.880 --> 00:58:43.860
suggests this, as well--

00:58:43.860 --> 00:58:46.020
as it's designed, is
really downstream.

00:58:46.020 --> 00:58:47.490
So you build the technology.

00:58:47.490 --> 00:58:50.820
And then you decide or
have some conversation

00:58:50.820 --> 00:58:52.860
about what happens with it.

00:58:52.860 --> 00:58:56.190
As opposed to a
project like PMI,

00:58:56.190 --> 00:59:00.570
which would really require a
more anticipatory, or upstream,

00:59:00.570 --> 00:59:01.525
or midstream approach.

00:59:01.525 --> 00:59:03.150
Something where you're
asking questions

00:59:03.150 --> 00:59:06.812
as it's happening and engaging
individuals in communities with

00:59:06.812 --> 00:59:08.270
regards to how they
think about it.

00:59:08.270 --> 00:59:12.085
So there is a mismatch.

00:59:12.085 --> 00:59:12.960
I think you're right.

00:59:12.960 --> 00:59:14.760
And why the dots
don't connect is

00:59:14.760 --> 00:59:19.020
that I think what we expect
for ethics in this moment

00:59:19.020 --> 00:59:22.500
are different from the formative
ELSI moment, with regards

00:59:22.500 --> 00:59:28.620
to ELSI information, as opposed
to being solely downstream,

00:59:28.620 --> 00:59:32.530
after the project
is all but baked.

00:59:32.530 --> 00:59:35.130
What Rabinow uses as a
distinction that's very useful

00:59:35.130 --> 00:59:39.480
is that he distinguishes--

00:59:39.480 --> 00:59:41.610
I should say
Rabinow and Bennet--

00:59:41.610 --> 00:59:46.560
between what he calls
cooperation and collaboration.

00:59:46.560 --> 00:59:49.560
And so for him,
with the ELSI work,

00:59:49.560 --> 00:59:52.343
cooperation is like
the bioethicists,

00:59:52.343 --> 00:59:53.760
the social scientists
are supposed

00:59:53.760 --> 00:59:56.550
to be here working on
a parallel track that

00:59:56.550 --> 00:59:59.710
does not intersect at all any
of the science or miss any of it

00:59:59.710 --> 01:00:00.210
up.

01:00:00.210 --> 01:00:01.710
It's really like
get out of here.

01:00:01.710 --> 01:00:03.390
And what they were
imagining when

01:00:03.390 --> 01:00:06.120
they got involved in the
Systems Bio ELSI Project

01:00:06.120 --> 01:00:09.600
was collaboration-- that
there would be conversations

01:00:09.600 --> 01:00:10.602
early on.

01:00:10.602 --> 01:00:12.060
What does it mean
that we don't yet

01:00:12.060 --> 01:00:15.958
have laws that allow people to
say that their data is theirs?

01:00:15.958 --> 01:00:17.500
How are we going to
think about that?

01:00:17.500 --> 01:00:18.958
What are we going
to do about that?

01:00:18.958 --> 01:00:21.310
And that was really kind of
forestalled in the project.

01:00:21.310 --> 01:00:24.570
So I think you're right.

01:00:24.570 --> 01:00:30.000
The dots don't connect, because
there's a new, larger ethical

01:00:30.000 --> 01:00:32.590
conversation that is emerging.

01:00:32.590 --> 01:00:34.470
And I was talking
to students today

01:00:34.470 --> 01:00:40.560
in the Radcliffe Student
Program about the ethical turn

01:00:40.560 --> 01:00:42.150
has not only come
to federal science.

01:00:42.150 --> 01:00:45.330
It's come to how we think
about society, more generally.

01:00:45.330 --> 01:00:48.930
We actually think the
ethics of data ethics

01:00:48.930 --> 01:00:51.330
is a kind of panacea
for everything.

01:00:51.330 --> 01:00:53.910
And obviously, that's quite
dangerous and obviously not

01:00:53.910 --> 01:00:54.930
true.

01:00:54.930 --> 01:00:59.280
But it also means that we don't
use words like discrimination,

01:00:59.280 --> 01:01:01.710
justice, injustice.

01:01:01.710 --> 01:01:04.670
Ethics fills that
space, as well.

01:01:04.670 --> 01:01:06.720
So that's another
backdrop that makes,

01:01:06.720 --> 01:01:11.670
I think, the ELSI piece a bit
both inadequate for this moment

01:01:11.670 --> 01:01:13.166
and a little murky.

01:01:13.166 --> 01:01:14.230
- Thank you for that.

01:01:16.930 --> 01:01:17.680
- Hi.

01:01:17.680 --> 01:01:19.160
- Hi.

01:01:19.160 --> 01:01:22.690
- I'm a biologist and chemist
in the chemistry grad program

01:01:22.690 --> 01:01:23.530
at MIT.

01:01:23.530 --> 01:01:26.980
And as biologists, we get data.

01:01:26.980 --> 01:01:31.120
And then it's up to us
to decide what it means.

01:01:31.120 --> 01:01:33.100
And there's a couple
of places where

01:01:33.100 --> 01:01:35.318
I'm a little bit
concerned about that.

01:01:35.318 --> 01:01:37.360
If the milk chugging
challenge is any indication,

01:01:37.360 --> 01:01:40.150
white supremacists will
take meaningless biological

01:01:40.150 --> 01:01:42.760
distinctions and
twist and turn them

01:01:42.760 --> 01:01:45.250
upside down until they say
something that justifies

01:01:45.250 --> 01:01:46.840
their bigoted bullshit.

01:01:46.840 --> 01:01:52.000
And then in a more
subtle distinction,

01:01:52.000 --> 01:01:55.750
biologists tend to take
doctors' word for it

01:01:55.750 --> 01:01:59.350
in terms of what is a
pathology, despite the known

01:01:59.350 --> 01:02:01.120
history, in which
being gay and trans

01:02:01.120 --> 01:02:04.960
used to be listed in
the DM5 as disorders.

01:02:04.960 --> 01:02:07.180
And now, we know how
ridiculous that is.

01:02:07.180 --> 01:02:10.960
And biologists will
continue to do GWA studies,

01:02:10.960 --> 01:02:13.360
trying to figure out which
genes cause the autism

01:02:13.360 --> 01:02:16.870
disease without ever questioning
whether autism is actually

01:02:16.870 --> 01:02:17.430
a disorder.

01:02:17.430 --> 01:02:19.150
And the vast majority
of autistic people

01:02:19.150 --> 01:02:20.245
don't want to be cured.

01:02:20.245 --> 01:02:22.690
They want to be accepted.

01:02:22.690 --> 01:02:23.560
So I'm wondering.

01:02:23.560 --> 01:02:27.730
So let's say that we get
all of these very broad,

01:02:27.730 --> 01:02:29.080
genetic studies to happen.

01:02:29.080 --> 01:02:31.600
People are willing to
give up their data.

01:02:31.600 --> 01:02:34.480
Was their thought in
the Obama administration

01:02:34.480 --> 01:02:37.090
about how to keep that data
from being misinterpreted

01:02:37.090 --> 01:02:38.515
and misused?

01:02:38.515 --> 01:02:39.520
- Not at all.

01:02:44.320 --> 01:02:49.870
Your opening sentence was I'm
a biologist and a chemist.

01:02:49.870 --> 01:02:50.800
And we use this data.

01:02:50.800 --> 01:02:52.180
And we don't say what it means.

01:02:52.180 --> 01:02:54.310
But of course, you
do say what it means.

01:02:54.310 --> 01:02:56.020
- I said it is up
to us to figure out.

01:02:56.020 --> 01:02:56.770
- It is up to you.

01:02:56.770 --> 01:02:59.680
And you are engaged,
particularly if you're

01:02:59.680 --> 01:03:02.950
talking about human genetics,
and about human disease,

01:03:02.950 --> 01:03:06.280
and a practice of creating
classifications and categories

01:03:06.280 --> 01:03:07.600
that are racialized.

01:03:07.600 --> 01:03:11.400
And so then when the white
supremacists take up,

01:03:11.400 --> 01:03:14.920
in another way,
ways that we create

01:03:14.920 --> 01:03:19.470
algorithms and meanings out of
data, we can be mad about it.

01:03:19.470 --> 01:03:20.470
Because it's disgusting.

01:03:20.470 --> 01:03:21.887
But we also can't
be mad about it.

01:03:21.887 --> 01:03:24.310
Because it is another
practice of classification

01:03:24.310 --> 01:03:25.630
and categorization.

01:03:25.630 --> 01:03:29.080
That is, I think, part of
what science does at its best

01:03:29.080 --> 01:03:31.180
and at its worst.

01:03:31.180 --> 01:03:35.290
So there's no surprises there.

01:03:35.290 --> 01:03:39.790
And I think the
cluster of things

01:03:39.790 --> 01:03:42.730
that you raised are about
the issue of the politics

01:03:42.730 --> 01:03:47.290
and power of classification
and how to think about that.

01:03:47.290 --> 01:03:53.230
And I think scientists have
to be upfront about that.

01:03:53.230 --> 01:03:57.280
That's part of what the work
is and that these categories

01:03:57.280 --> 01:03:59.350
travel in the world.

01:03:59.350 --> 01:04:03.670
A lot of my work has
been how lay people

01:04:03.670 --> 01:04:06.460
and sometimes not lay
people really take up

01:04:06.460 --> 01:04:08.440
scientific categories
and use them

01:04:08.440 --> 01:04:10.060
for all sorts of political work.

01:04:10.060 --> 01:04:14.170
And the literature on
not only Amy Harman's

01:04:14.170 --> 01:04:16.730
reporting in The Times, but
the social science literature,

01:04:16.730 --> 01:04:18.970
Aaron Pinovsky and
Joan Donovan's work

01:04:18.970 --> 01:04:23.590
on how white nationalists
interpret genetic ancestry

01:04:23.590 --> 01:04:25.660
testing--

01:04:25.660 --> 01:04:28.450
sorry to say, I guess,
as a social scientist,

01:04:28.450 --> 01:04:31.780
happy to say that the mechanisms
that I describe in my work

01:04:31.780 --> 01:04:34.060
with African-Americans
are the same mechanisms.

01:04:34.060 --> 01:04:36.760
That's the same categories
or those same schema

01:04:36.760 --> 01:04:40.300
in which ways people are
making sense of what it means.

01:04:40.300 --> 01:04:44.860
It's negation, magical
thinking, acceptance, sort

01:04:44.860 --> 01:04:47.080
of drilling down into the data.

01:04:47.080 --> 01:04:50.813
They're the same kind of
gestures, unfortunately.

01:04:55.743 --> 01:04:57.540
- Thank you for
a wonderful talk.

01:04:57.540 --> 01:04:58.340
Janet Rich-Edwards.

01:04:58.340 --> 01:05:00.590
I'm an epidemiologist here,
at Harvard, and this year,

01:05:00.590 --> 01:05:01.460
a Radcliffe Fellow.

01:05:01.460 --> 01:05:02.090
- Great.

01:05:02.090 --> 01:05:07.970
- And my question is about--
this feels very internally

01:05:07.970 --> 01:05:09.940
domestic facing for the US.

01:05:09.940 --> 01:05:10.440
- Sure.

01:05:10.440 --> 01:05:13.880
- And I'm curious about,
during this administration,

01:05:13.880 --> 01:05:19.070
attempts to coordinate, debate,
discuss with other countries.

01:05:19.070 --> 01:05:20.870
And this feels
like it's becoming

01:05:20.870 --> 01:05:23.900
even more relevant, for example,
with the recent gene editing

01:05:23.900 --> 01:05:26.090
of human embryos from China.

01:05:26.090 --> 01:05:28.370
I'm just curious about how
the administration thought

01:05:28.370 --> 01:05:29.310
about that.

01:05:29.310 --> 01:05:31.100
- I don't know.

01:05:31.100 --> 01:05:33.590
I haven't actually
looked into that.

01:05:33.590 --> 01:05:38.810
If there are others who know
more about it, do let me know.

01:05:38.810 --> 01:05:40.280
The thing about
federal science is

01:05:40.280 --> 01:05:43.280
it's so nation state obsessed.

01:05:43.280 --> 01:05:47.750
Even one of the
examples Jennifer--

01:05:47.750 --> 01:05:55.550
of how the Personalized Genomics
Act of 2006 to 2007 sort of

01:05:55.550 --> 01:05:59.540
uses the phrase of
securing genomic medicine

01:05:59.540 --> 01:06:00.860
for all Americans.

01:06:00.860 --> 01:06:04.220
It's very much kind of a
nationalist, sovereign project

01:06:04.220 --> 01:06:08.330
around genetics, even as we
understand these things to sort

01:06:08.330 --> 01:06:12.620
be global and planetary in
their scale and implications.

01:06:12.620 --> 01:06:15.350
I certainly wondered, actually,
what an Obama administration

01:06:15.350 --> 01:06:19.310
would have said about lots
of contemporary controversies

01:06:19.310 --> 01:06:24.320
in science, even around the
issue of Cambridge Analytica,

01:06:24.320 --> 01:06:28.400
things that lack a
regulation around big tech,

01:06:28.400 --> 01:06:32.120
and certainly with
the gene editing.

01:06:32.120 --> 01:06:33.380
It's hard to know.

01:06:33.380 --> 01:06:34.145
I'll say this.

01:06:37.830 --> 01:06:41.450
I was a witness,
or gave testimony,

01:06:41.450 --> 01:06:44.600
or had a conversation with
some colleagues at the National

01:06:44.600 --> 01:06:47.870
Academies who did an NAS
report on gene editing,

01:06:47.870 --> 01:06:51.230
and germline editing, and trying
to distinguish between those

01:06:51.230 --> 01:06:52.730
and what might be done.

01:06:52.730 --> 01:06:56.300
And even people in
that room, who I think

01:06:56.300 --> 01:06:58.130
knew better and think
about these things

01:06:58.130 --> 01:07:03.770
on the global scale, in
structure of the NHS,

01:07:03.770 --> 01:07:06.260
it's a kind of
national conversation.

01:07:06.260 --> 01:07:10.700
So there would be gestures such
as if we changed the germ line,

01:07:10.700 --> 01:07:12.560
we are changing all
of human population.

01:07:12.560 --> 01:07:15.290
But somehow, that then
could be captured back

01:07:15.290 --> 01:07:19.160
into a conversation about
science in the United States.

01:07:19.160 --> 01:07:24.560
So I think in these
kind of federal bodies,

01:07:24.560 --> 01:07:27.830
we do a disservice to
what are planetary issues,

01:07:27.830 --> 01:07:28.918
as you suggest.

01:07:32.201 --> 01:07:36.130
- Thank you so
much for this talk.

01:07:36.130 --> 01:07:38.732
I think I'm very
persuaded by the question

01:07:38.732 --> 01:07:40.440
of ethical framing or
the way that you're

01:07:40.440 --> 01:07:42.480
describing ethical framing.

01:07:42.480 --> 01:07:44.100
I wonder whether
you could juxtapose

01:07:44.100 --> 01:07:46.680
this kind of ethical
framing around medicine,

01:07:46.680 --> 01:07:48.180
and technology, and
the technologies

01:07:48.180 --> 01:07:51.190
related to this
particular program,

01:07:51.190 --> 01:07:55.230
particularly with the Obama
administration's drone program.

01:07:55.230 --> 01:07:58.500
Because in the Obama
administration,

01:07:58.500 --> 01:08:02.838
in 2012, they describe drones
as, specifically, ethical.

01:08:02.838 --> 01:08:04.380
That was the language
that they used.

01:08:04.380 --> 01:08:04.880
- Yeah.

01:08:04.880 --> 01:08:06.630
- And so it seems
to me that there

01:08:06.630 --> 01:08:09.690
is a very interesting
politics around ethics that's

01:08:09.690 --> 01:08:12.840
part of Obama, which I would
love to hear just how you think

01:08:12.840 --> 01:08:14.875
about the specificity,
here, but also

01:08:14.875 --> 01:08:16.750
juxtaposing those
different ethical contexts.

01:08:16.750 --> 01:08:17.340
- Don't leave.

01:08:17.340 --> 01:08:20.640
Because I'd actually like to
have a back and forth one about

01:08:20.640 --> 01:08:22.598
this.

01:08:22.598 --> 01:08:24.390
Something that just
happened around drones,

01:08:24.390 --> 01:08:25.390
I've thought about this.

01:08:25.390 --> 01:08:29.520
And I think when I'm
writing up the AI piece,

01:08:29.520 --> 01:08:30.899
I will write about drones.

01:08:30.899 --> 01:08:33.990
But the news last week is
that the Trump Administration

01:08:33.990 --> 01:08:36.600
is no longer going to
count drone deaths.

01:08:36.600 --> 01:08:38.399
So that was a moment
where I thought,

01:08:38.399 --> 01:08:42.060
was it ethical to
count drone deaths?

01:08:42.060 --> 01:08:46.710
Do we wish that we had an
Obama Administration that

01:08:46.710 --> 01:08:50.742
thought that they were doing
some sort of ethical exercise

01:08:50.742 --> 01:08:52.200
in the fact that
they were offering

01:08:52.200 --> 01:08:53.970
some sort of public
accountability

01:08:53.970 --> 01:08:57.000
to automated death squads?

01:08:57.000 --> 01:09:00.495
And so I don't have, I
think, an easy answer.

01:09:03.149 --> 01:09:03.700
to that.

01:09:03.700 --> 01:09:04.950
Certainly, that's not ethical.

01:09:04.950 --> 01:09:08.080
And I'm not even sure.

01:09:08.080 --> 01:09:09.930
I use framing, and
I use performance,

01:09:09.930 --> 01:09:14.490
because I don't want to
suggest in a normative sense

01:09:14.490 --> 01:09:16.500
that this is ethical.

01:09:16.500 --> 01:09:22.260
But that we have reached
a moment as a society

01:09:22.260 --> 01:09:25.950
that if you want to advance
certain scientific endeavors,

01:09:25.950 --> 01:09:29.700
post Hiroshima, post name your--

01:09:29.700 --> 01:09:34.140
Jacques Ranciere has this
essay on the ethical turn

01:09:34.140 --> 01:09:34.979
in politics.

01:09:34.979 --> 01:09:38.729
And for him, it's a temporality
that's post atrocity.

01:09:38.729 --> 01:09:44.580
It's any post atrocity turn then
becomes the ethical politics.

01:09:44.580 --> 01:09:51.060
So I would want to
forestall the use of ethical

01:09:51.060 --> 01:09:54.180
as a normative claim,
but understand it

01:09:54.180 --> 01:10:00.240
as a necessary narrative
of legitimation

01:10:00.240 --> 01:10:03.330
or a necessary practice
of legitimation.

01:10:03.330 --> 01:10:05.528
- I think it's exactly correct.

01:10:05.528 --> 01:10:07.320
I just think there's
something interesting.

01:10:07.320 --> 01:10:09.420
Because I think he puts
himself very forward

01:10:09.420 --> 01:10:11.580
in this kind of ethical framing.

01:10:11.580 --> 01:10:13.252
You didn't see
Obama that much when

01:10:13.252 --> 01:10:14.460
it came to the drone warfare.

01:10:14.460 --> 01:10:15.085
- That's right.

01:10:15.085 --> 01:10:16.250
No, I think that's-- well--

01:10:16.250 --> 01:10:17.785
- Well--

01:10:17.785 --> 01:10:18.930
- --yes and no.

01:10:18.930 --> 01:10:22.050
He wouldn't be having a
summit on a stage talking

01:10:22.050 --> 01:10:24.180
about the misdeeds of the past.

01:10:24.180 --> 01:10:30.624
But there are some conversations
with him about the drone stuff.

01:10:30.624 --> 01:10:32.352
[MUSIC PLAYING]

01:10:32.352 --> 01:10:34.890
- Join me in thanking
Doctor Nelson

01:10:34.890 --> 01:10:37.320
for that wonderful lecture.

01:10:37.320 --> 01:10:38.820
[APPLAUSE]

01:10:38.820 --> 01:10:41.570
[MUSIC PLAYING]

