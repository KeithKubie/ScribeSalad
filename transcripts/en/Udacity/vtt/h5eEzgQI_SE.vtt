WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:00.920
The particular case,

00:00:00.920 --> 00:00:05.960
I'd like us to talk about in more detail
is linear value function approximation.

00:00:05.960 --> 00:00:11.040
So that is in particular the case
where our Q function is represented

00:00:11.040 --> 00:00:15.950
as a weighted linear combination of
the features that represent the state.

00:00:15.950 --> 00:00:17.240
And maybe the state in action,

00:00:17.240 --> 00:00:19.170
but we're going to keep
the action separate for now.

00:00:19.170 --> 00:00:21.650
&gt;&gt; Okay.
&gt;&gt; So this is how the Q function

00:00:21.650 --> 00:00:24.630
can be represented,
if we're doing things linearly.

00:00:24.630 --> 00:00:28.340
So we have this set of weights, wai.

00:00:28.340 --> 00:00:29.770
And we have a set of features or

00:00:29.770 --> 00:00:33.395
at least this function f that maps
states to particular feature values.

00:00:33.395 --> 00:00:35.230
And let's say we've got
n different features.

00:00:35.230 --> 00:00:37.100
So if we're representing
things linearly,

00:00:37.100 --> 00:00:40.070
what we're doing is we're saying
let's sum over all the features for

00:00:40.070 --> 00:00:44.100
the current state, the value of that
feature times the weight that is being

00:00:44.100 --> 00:00:46.750
used to represent the cube function for
this action.

00:00:46.750 --> 00:00:49.739
And just yes, some of it, essentially
take the dot product between this

00:00:49.739 --> 00:00:51.358
feature vector and the weight vector.

00:00:51.358 --> 00:00:55.807
And it's these parameters, these wa's,
that are actually providing us

00:00:55.807 --> 00:01:00.326
the generalization, the ability to make
a prediction to new states because

00:01:00.326 --> 00:01:04.650
there's parameters that are shared
between all the different states.

00:01:04.650 --> 00:01:06.960
&gt;&gt; Sure, that makes sense.

00:01:06.960 --> 00:01:11.440
So it's like in their own network
with nothing nonlinear going on.

00:01:11.440 --> 00:01:16.635
&gt;&gt; Yeah, in this particular case it
is exactly a [LAUGH] linear function.

00:01:16.635 --> 00:01:19.600
&gt;&gt; [LAUGH]
&gt;&gt; [LAUGH] Which you can think of as

00:01:19.600 --> 00:01:22.220
being under all that without any
nonlinear and with a single layer.

00:01:22.220 --> 00:01:24.040
&gt;&gt; Yeah, and so
in fact you have a whole set of them.

00:01:24.040 --> 00:01:27.600
You have a whole set of neural networks
all kind of happening in parallel.

00:01:27.600 --> 00:01:31.562
I suppose you could claim that
they're one neural network with

00:01:31.562 --> 00:01:34.380
a the non-linearity, which is kind of
some kind of max function or something

00:01:34.380 --> 00:01:38.560
that figures out which action you should
take based upon each of the Q(S,a)'s.

00:01:38.560 --> 00:01:41.280
And so you really are kind of
learning a neural network.

00:01:41.280 --> 00:01:42.700
&gt;&gt; Yeah, I can agree with that.

00:01:42.700 --> 00:01:45.987
I mean, we're going to talk a little bit
more about using more general neural

00:01:45.987 --> 00:01:49.500
network structures in this setting,
instead of just linear weights.

00:01:49.500 --> 00:01:52.050
But the linear weight case is kind
of easier for us to think about.

00:01:52.050 --> 00:01:54.370
And there's actually been a tremendous
amount of research on this particular

00:01:54.370 --> 00:01:56.900
case because the hope has been that

00:01:56.900 --> 00:02:01.030
it's more well-behaved than what we get
with non-linear function approximation.

00:02:01.030 --> 00:02:01.590
&gt;&gt; Usually is.

00:02:01.590 --> 00:02:04.180
&gt;&gt; Let's think a little bit about what
these weights are actually representing.

00:02:04.180 --> 00:02:04.900
&gt;&gt; Okay.

00:02:04.900 --> 00:02:06.170
&gt;&gt; One way you can think
about the weight for

00:02:06.170 --> 00:02:09.050
a feature is that it gives a kind
of sense of importance for

00:02:09.050 --> 00:02:12.570
each of the features in how much they're
contributing to the action's value.

00:02:12.570 --> 00:02:14.285
&gt;&gt; Sure, so, if the weight, ai,

00:02:14.285 --> 00:02:17.100
is 0, then it doesn't
matter what the feature is.

00:02:17.100 --> 00:02:18.220
It doesn't contribute at all.

00:02:18.220 --> 00:02:21.070
&gt;&gt; That's right, and so, then,
it completely ignores the feature for

00:02:21.070 --> 00:02:21.830
that prediction.

00:02:21.830 --> 00:02:26.120
&gt;&gt; And if the weight is a billion,
then it means a lot, probably.

00:02:26.120 --> 00:02:28.440
And if it's negative a billion
it also means a lot,

00:02:28.440 --> 00:02:30.050
just in the different direction.

00:02:30.050 --> 00:02:31.650
&gt;&gt; Right sort of anti-importance.

00:02:31.650 --> 00:02:35.234
&gt;&gt; Well, not necessarily, I mean,
the feature depends upon how you

00:02:35.234 --> 00:02:38.510
want to interpret the xi
produces a negative number.

00:02:38.510 --> 00:02:40.949
And you're actually,
the weight is also negative.

00:02:40.949 --> 00:02:44.270
If you're saying that that
feature is really important and

00:02:44.270 --> 00:02:47.718
the negativeness just it's kind of
a function of the fact that you want you

00:02:47.718 --> 00:02:50.380
want Q values to be higher
if you're going to use them.

00:02:50.380 --> 00:02:52.422
&gt;&gt; Okay, all right, I think that's
a good way to think about it.

00:02:52.422 --> 00:02:54.930
All right, so
this just kind of makes sense or

00:02:54.930 --> 00:02:59.520
you feel like you appreciate the notion
of a linear value function approximator?

00:02:59.520 --> 00:03:01.390
&gt;&gt; Yeah, I think so, that makes sense.

00:03:01.390 --> 00:03:04.060
You just add up all your features and
weight them appropriately.

00:03:04.060 --> 00:03:06.800
&gt;&gt; Cool, all right, so let's kind of
make sure that we understand this.

00:03:06.800 --> 00:03:07.300
&gt;&gt; Okay.

