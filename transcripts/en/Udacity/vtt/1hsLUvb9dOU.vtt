WEBVTT
Kind: captions
Language: en

00:00:00.160 --> 00:00:02.969
LIke you said,
it's sort of an old school way doing it.

00:00:02.969 --> 00:00:06.770
They were the first methods being used
in what's called pattern recognition.

00:00:06.770 --> 00:00:08.670
Pattern recognition's entire field or

00:00:08.670 --> 00:00:11.980
discipline that looked at making
these kinds of decisions.

00:00:11.980 --> 00:00:15.820
And one of the reasons was it was
very easy to model this analytically.

00:00:15.820 --> 00:00:17.950
Because you'd use things like Gaussians,
or whatever.

00:00:17.950 --> 00:00:22.550
Or mixtures of Gaussians, and you could
do this with modest amounts of data

00:00:22.550 --> 00:00:25.960
in a smallish moderate
number of dimensions, and

00:00:25.960 --> 00:00:28.520
because a lot of this was done
before we had serious computers, or

00:00:28.520 --> 00:00:29.870
before we had serious data.

00:00:29.870 --> 00:00:31.320
This was really important.

00:00:31.320 --> 00:00:34.280
But sort of in the modern world, or
not even the modern world anymore, but

00:00:34.280 --> 00:00:37.750
the world 20 years ago, which I like to
think of as being modern, because back

00:00:37.750 --> 00:00:40.730
then I was in my 30s, and I'm hoping
that I'm not like, really that old.

00:00:40.730 --> 00:00:43.010
But now I'm like,
man I'm old, okay fine.

00:00:43.010 --> 00:00:47.210
But in the modern world there are some
liabilities of the generative method.

00:00:47.210 --> 00:00:51.230
First of all, these days, many of our
signals are high-dimensional, right.

00:00:51.230 --> 00:00:54.590
So we get some description of a signal,
whether it's stock market data or

00:00:54.590 --> 00:00:55.660
whatever it is.

00:00:55.660 --> 00:01:00.860
I might have a feature space that's
tens of thousands of dimensions,

00:01:00.860 --> 00:01:02.260
or at least many hundreds of dimensions.

00:01:02.260 --> 00:01:04.150
It's a very high-dimensional vector.

00:01:04.150 --> 00:01:07.690
And if you actually want to represent
the density, in that high-dimensional

00:01:07.690 --> 00:01:11.080
space I, I wrote here that
it's called sort of data hard.

00:01:11.080 --> 00:01:11.920
And what I mean by that is

00:01:11.920 --> 00:01:14.400
the thing becomes exponential in
the number of features that you have.

00:01:14.400 --> 00:01:17.650
So you have to have sort of massive,
massive, massive amounts of data.

00:01:17.650 --> 00:01:19.070
And even more mass, when, you know,

00:01:19.070 --> 00:01:22.840
we tend to think sort of Google
styles data being is massive.

00:01:22.840 --> 00:01:23.530
No.

00:01:23.530 --> 00:01:27.020
You know, when you've got tens of
thousands of dimensions, it, it's,

00:01:27.020 --> 00:01:30.520
the amount of data you need to densely
sample that is, is exponential,

00:01:30.520 --> 00:01:32.030
and we just don't have it.

00:01:32.030 --> 00:01:34.990
But, there's even a bigger liability,
okay?

00:01:34.990 --> 00:01:38.190
The bigger liability is that

00:01:38.190 --> 00:01:43.260
we don't actually care about
modelling the coal class.

00:01:43.260 --> 00:01:45.980
Right?
If I've got sort of skin things and

00:01:45.980 --> 00:01:47.450
not skin things.

00:01:47.450 --> 00:01:51.330
Imagine a whole bunch of colored pixels
that have nothing to do with skin,

00:01:51.330 --> 00:01:54.060
I don't have to model that as not skin.

00:01:54.060 --> 00:01:55.960
We only care about making
the right decisions.

00:01:55.960 --> 00:01:59.930
So we should be modelling
the boundaries, the hard cases.

00:01:59.930 --> 00:02:02.390
The cases where I'm not really sure.

00:02:02.390 --> 00:02:05.400
And when you do a general model
of a category or of a class,

00:02:05.400 --> 00:02:10.139
you're worried about the vast majority
of them, so the skin pixels, not this,

00:02:10.139 --> 00:02:12.740
just this boundary that's
next to the non-skin ones.

00:02:12.740 --> 00:02:16.097
And I'm not even totally sure
what it means to model non-class,

00:02:16.097 --> 00:02:20.510
non-skin pixels, because that's
everything from you know, the pixels on

00:02:20.510 --> 00:02:25.430
colored shirts, to the pixels on grass,
to the pixels on tree bark.

00:02:25.430 --> 00:02:29.150
Yeah, it's kind of a weird, not,
non skin's not really a great class.

00:02:29.150 --> 00:02:33.540
What I care about is, find me the pixels
that may be labeled as skin, or

00:02:33.540 --> 00:02:34.660
maybe not.

00:02:34.660 --> 00:02:37.900
And finally,
I'm going to give you a feature vector,

00:02:37.900 --> 00:02:41.060
a bunch of features that
describe an instance.

00:02:41.060 --> 00:02:43.170
And we might not have any idea,
a priori,

00:02:43.170 --> 00:02:48.650
which features actually are good for
discriminating between the classes.

00:02:48.650 --> 00:02:51.490
So part of our building a classifier

00:02:51.490 --> 00:02:54.300
is essentially doing feature selection,
right?

00:02:54.300 --> 00:02:57.920
We have to figure out what
parts of the features, or

00:02:57.920 --> 00:03:03.090
what parts of the signal,
are the sort of informative ones.

00:03:03.090 --> 00:03:03.780
And, so, for

00:03:03.780 --> 00:03:08.890
training a classifier, our general model
has no way of talking about doing that.

00:03:08.890 --> 00:03:11.440
But the methods we're
about to talk about,

00:03:11.440 --> 00:03:14.310
which are called discriminative methods,
inherently do that.

