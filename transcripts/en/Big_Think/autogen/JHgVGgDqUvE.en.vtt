WEBVTT
Kind: captions
Language: en

00:00:04.470 --> 00:00:08.950
John Stuart Mill was an extraordinary and
influential thinker in the early 19th century

00:00:08.950 --> 00:00:10.500
in England.

00:00:10.500 --> 00:00:18.490
He was something of a radical within his society
at the time and, as a consequence, was very

00:00:18.490 --> 00:00:23.699
interested in the ability to to develop and
communicate radical ideas that were outside

00:00:23.699 --> 00:00:26.970
the mainstream, because he was interested
in a lot of those ideas himself, and he was

00:00:26.970 --> 00:00:31.980
much more interested in how a free society
should operate the ability of people to think

00:00:31.980 --> 00:00:38.930
for themselves in a free society, and sometimes
run against the grain of public opinion and

00:00:38.930 --> 00:00:41.150
mainstream thought in general.

00:00:41.150 --> 00:00:47.120
He offered a variety of arguments about why
it is we ought to value that kind of speech,

00:00:47.120 --> 00:00:51.180
those kinds of spaces, that kind of robust
debate.

00:00:51.180 --> 00:00:56.910
So one of those arguments I characterize as
an argument driven by humility.

00:00:56.910 --> 00:01:03.160
That is, that part of what Mill wanted to
remind us is that we all might be mistaken,

00:01:03.160 --> 00:01:05.329
that our own understanding is limited.

00:01:05.329 --> 00:01:07.700
Our own set of ideas are very limited.

00:01:07.700 --> 00:01:09.170
And that we can learn from each other.

00:01:09.170 --> 00:01:12.890
And we can learn from others who have different
ideas than ourselves.

00:01:12.890 --> 00:01:16.500
But that requires some willingness to accept
the possibility that we, in fact, might be

00:01:16.500 --> 00:01:17.510
mistaken.

00:01:17.510 --> 00:01:22.430
And of course, we walk around most of the
time with the belief that we are upholding

00:01:22.430 --> 00:01:26.040
a set of correct ideas, that we think we know
our own minds.

00:01:26.040 --> 00:01:28.750
We think the ideas we hold are true.

00:01:28.750 --> 00:01:30.550
That's why we hold them in the first place.

00:01:30.550 --> 00:01:35.880
And so it can be challenging to go into a
conversation and go into a discussion, go

00:01:35.880 --> 00:01:41.890
into a public space and accept the possibility
that we might be wrong.

00:01:41.890 --> 00:01:46.120
But Mill wanted to emphasize that it's only
by accepting that possibility that we're wrong

00:01:46.120 --> 00:01:47.930
that we can have the opportunity to learn.

00:01:47.930 --> 00:01:55.270
And it's important for our own sake that we
be able to continue to learn and grow by talking

00:01:55.270 --> 00:02:00.630
to people with different ideas and being genuinely
open to the possibility that they might persuade

00:02:00.630 --> 00:02:01.630
us.

00:02:01.630 --> 00:02:03.210
They might show the flaws in our ideas.

00:02:03.210 --> 00:02:04.479
They might expose our mistakes.

00:02:04.479 --> 00:02:07.869
And as a consequence, they might help us make
progress.

00:02:07.869 --> 00:02:12.470
But he also constructs an argument that's
really grounded instead on a concern with

00:02:12.470 --> 00:02:14.690
arrogance of others.

00:02:14.690 --> 00:02:20.459
Here, the concern is not so much that we be
willing to hear from people that we disagree

00:02:20.459 --> 00:02:23.220
with because we accept the possibility that
we might be wrong.

00:02:23.220 --> 00:02:29.459
But instead, he wants to speak to our instincts
to want to suppress opinions that we find

00:02:29.459 --> 00:02:35.239
disagreeable or dangerous so that no one else
can hear them, instead.

00:02:35.239 --> 00:02:38.800
And this is fundamentally a paternalistic
concern, a concern that we're worried about

00:02:38.800 --> 00:02:42.200
other people, that they might be misled by
bad ideas.

00:02:42.200 --> 00:02:46.780
And so even if we think that we ourselves
are capable of separating good ideas from

00:02:46.780 --> 00:02:51.860
bad ideas, and so as consequence, we should
be able to hear a wide range of views and

00:02:51.860 --> 00:02:57.240
arguments, we might be much less comfortable
that other people can make the same distinctions,

00:02:57.240 --> 00:03:02.590
will come to good decisions, exercise good
judgment when listening to those ideas.

00:03:02.590 --> 00:03:07.000
And so as a consequence, there's a certain
arrogance where we want to impose our own

00:03:07.000 --> 00:03:12.871
beliefs on others and shield them from the
opposition; shield them from listening to

00:03:12.871 --> 00:03:16.930
the critics so that the only voices they hear
are our own.

00:03:16.930 --> 00:03:22.050
And it's difficult to resist that tendency
and that instinct, precisely because when

00:03:22.050 --> 00:03:29.390
we're thinking about what ideas in society
we find as wrongheaded, disturbing, maybe

00:03:29.390 --> 00:03:33.670
dangerous, it becomes all the more tempting
to think, when confronted with that dangerous

00:03:33.670 --> 00:03:37.840
idea, that we shouldn't expose anyone else
to that dangerous idea because they might

00:03:37.840 --> 00:03:39.420
be polluted by it.

00:03:39.420 --> 00:03:40.750
They might believe it.

00:03:40.750 --> 00:03:42.240
And they might even want to act on it.

00:03:42.240 --> 00:03:47.530
And finally, Mill offers an argument that
I characterize as an argument from conviction,

00:03:47.530 --> 00:03:51.790
which is to say that he says, we have a set
of ideas that we walk around with.

00:03:51.790 --> 00:03:53.840
And we think they're probably right.

00:03:53.840 --> 00:03:57.870
We assume oftentimes they're right; we haven't
thought about them very carefully.

00:03:57.870 --> 00:03:59.880
And they may be very deeply held ideas.

00:03:59.880 --> 00:04:03.570
They may be central to our belief system,
our value system.

00:04:03.570 --> 00:04:07.340
More generally, they may be crucial to how
we think about the world and how it operates,

00:04:07.340 --> 00:04:09.280
more generally.

00:04:09.280 --> 00:04:13.560
But oftentimes, we don't have a lot of reason
to think about those ideas very carefully.

00:04:13.560 --> 00:04:16.280
We haven't explored them or thought about
them very carefully ourselves.

00:04:16.280 --> 00:04:17.909
Instead, we've received them from others.

00:04:17.909 --> 00:04:23.310
We've taken it for granted they're probably
true, and we've moved on.

00:04:23.310 --> 00:04:27.240
But he emphasizes that we don't really know
how true those ideas are.

00:04:27.240 --> 00:04:31.729
We don't know how confident we ought to be
about the truth of those ideas until we've

00:04:31.729 --> 00:04:36.680
seen them tested in intellectual battle, and
until we've seen critics go after them with

00:04:36.680 --> 00:04:41.639
hard arguments, with counter evidence, with
objections, and we've seen how well those

00:04:41.639 --> 00:04:44.150
ideas can weather that kind of storm.

00:04:44.150 --> 00:04:48.750
Can our ideas stand up to criticism and skeptical
inquiry?

00:04:48.750 --> 00:04:52.860
And he says we shouldn't be very confident
in ideas that we are not willing to expose

00:04:52.860 --> 00:04:54.940
to those kind of criticisms.

00:04:54.940 --> 00:04:59.660
That it's precisely the ideas that we've seen
weather the criticism that we ought to be

00:04:59.660 --> 00:05:01.290
confident about.

00:05:01.290 --> 00:05:06.430
And so as a consequence he encourages us to
think that if we want to have real confidence

00:05:06.430 --> 00:05:12.150
in our beliefs as individuals, but also as
a society, that we should be particularly

00:05:12.150 --> 00:05:16.750
willing to expose our ideas to the harshest
critics we can find because those critics

00:05:16.750 --> 00:05:21.680
will help us, and they will help us be more
confident in the strength of our own ideas.

00:05:21.680 --> 00:05:25.370
And sometimes they will also show us the weaknesses
of our ideas and force us, then, to think

00:05:25.370 --> 00:05:29.890
more carefully about them and force us to
build better and more robust supports for

00:05:29.890 --> 00:05:30.890
those ideas.

00:05:30.890 --> 00:05:36.720
So we will come away more sophisticated thinkers
with more carefully held and carefully considered

00:05:36.720 --> 00:05:38.430
ideas than we went into those conversations
with.

