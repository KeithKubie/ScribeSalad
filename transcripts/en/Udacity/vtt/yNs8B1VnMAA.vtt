WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.875
The most general kernel launch we can do looks like thi:, square of 3 parameters.

00:00:05.875 --> 00:00:08.347
The first is the dimensionality of the grid of blocks

00:00:08.347 --> 00:00:12.288
that has bx X by X bz blocks.

00:00:12.288 --> 00:00:20.855
Each one of those blocks is specified by this parameter: the block of threads that has tx X ty X tz threads in it,

00:00:20.855 --> 00:00:23.393
and recall that this has a maximum size.

00:00:23.393 --> 00:00:26.846
Finally, there's a third argument that defaults to zero if you don't use it,

00:00:26.846 --> 00:00:29.100
and we're not going to cover it specifically today.

00:00:29.100 --> 00:00:33.487
It's the amount of shared memory in bytes allocated per thread block.

00:00:33.487 --> 00:00:39.167
With this one kernel call, you can launch an enormous number of threads.

00:00:39.167 --> 00:00:44.275
And let's all remember, with great power comes great responsibility, so launch your kernels wisely.

00:00:44.275 --> 00:00:46.342
One more important thing about blocks and threads.

00:00:46.342 --> 00:00:51.220
Recall from our square kernel, that each thread knows its thread ID within a block.

00:00:51.220 --> 00:00:52.845
It actually knows many things.

00:00:52.845 --> 00:00:57.588
First is threaded x, as we've seen, which thread it is within the block.

00:00:57.588 --> 00:00:58.757
Here we have a block.

00:00:58.757 --> 00:01:05.235
Each thread, say this thread here, knows its index in each of the x, y, and z dimensions,

00:01:05.235 --> 00:01:10.940
and we can access those as thread idx.x, thread idx.y, and dot z.

00:01:10.940 --> 00:01:14.801
We also know block Dim, the size of a block.

00:01:14.801 --> 00:01:17.234
How many threads are there in this block

00:01:17.234 --> 00:01:21.080
along the x dimension, the y dimension, and potentially the z dimension?

00:01:21.080 --> 00:01:23.284
So we know those two things for a block.

00:01:23.284 --> 00:01:25.757
We know the analogous things for a grid.

00:01:25.757 --> 00:01:31.899
Block index for instance is which block am I in within the grid. Again dot x, dot y, and dot z.

00:01:31.899 --> 00:01:35.896
And grid Dim will tell us the size of the grid, how many blocks there are

00:01:35.896 --> 00:01:39.131
in the x dimension, the y dimension, and the z dimension.

00:01:39.131 --> 00:01:42.700
What I want you to take home from this little discussion is only the following.

00:01:42.700 --> 00:01:48.199
It's convenient to have multi-dimensional grids and blocks when your problem has multiple dimensions.

00:01:48.199 --> 00:01:50.937
CUDA implements this natively and efficiently.

00:01:50.940 --> 00:01:56.971
When you call thread at idx.x, or block dim.y, that's a very efficient thing within CUDA.

00:01:56.971 --> 00:01:59.375
Since we're doing image processing in this course,

00:01:59.375 --> 00:02:03.513
you should be counting on finding a lot of two dimensional grids and blocks.

00:02:03.513 --> 00:02:05.713
So, let's wrap up with a little quiz.

00:02:05.713 --> 00:02:07.581
Let's say I launch the following kernel.

00:02:07.581 --> 00:02:14.428
Kernel with 2 parameters dim 3 (8, 4, 2, 2) and dim 3 (16, 16).

00:02:14.428 --> 00:02:17.011
How many blocks will this call launch,

00:02:17.011 --> 00:02:20.508
how many threads per block, and how many total threads?

