WEBVTT
Kind: captions
Language: en

00:15:37.270 --> 00:15:40.830
today I here at CMU supported by K&amp;L

00:15:40.830 --> 00:15:40.840
today I here at CMU supported by K&amp;L
 

00:15:40.840 --> 00:15:43.680
today I here at CMU supported by K&amp;L
gates thank you to those of you brave

00:15:43.680 --> 00:15:43.690
gates thank you to those of you brave
 

00:15:43.690 --> 00:15:45.210
gates thank you to those of you brave
enough and intrepid enough to make it

00:15:45.210 --> 00:15:45.220
enough and intrepid enough to make it
 

00:15:45.220 --> 00:15:47.850
enough and intrepid enough to make it
here at the early hour of 9:00 a.m. we

00:15:47.850 --> 00:15:47.860
here at the early hour of 9:00 a.m. we
 

00:15:47.860 --> 00:15:50.190
here at the early hour of 9:00 a.m. we
apologize that we had asked you to get

00:15:50.190 --> 00:15:50.200
apologize that we had asked you to get
 

00:15:50.200 --> 00:15:52.760
apologize that we had asked you to get
here so early but we've got a wonderful

00:15:52.760 --> 00:15:52.770
here so early but we've got a wonderful
 

00:15:52.770 --> 00:15:55.170
here so early but we've got a wonderful
incredibly packed day today that we

00:15:55.170 --> 00:15:55.180
incredibly packed day today that we
 

00:15:55.180 --> 00:15:57.480
incredibly packed day today that we
wanted to be able to just get started

00:15:57.480 --> 00:15:57.490
wanted to be able to just get started
 

00:15:57.490 --> 00:16:00.450
wanted to be able to just get started
with some of our wonderful speakers in

00:16:00.450 --> 00:16:00.460
with some of our wonderful speakers in
 

00:16:00.460 --> 00:16:01.950
with some of our wonderful speakers in
fact we're gonna lead off this morning

00:16:01.950 --> 00:16:01.960
fact we're gonna lead off this morning
 

00:16:01.960 --> 00:16:05.940
fact we're gonna lead off this morning
with the recipient last night of the

00:16:05.940 --> 00:16:05.950
with the recipient last night of the
 

00:16:05.950 --> 00:16:08.300
with the recipient last night of the
inaugural K&amp;L gates professorship of

00:16:08.300 --> 00:16:08.310
inaugural K&amp;L gates professorship of
 

00:16:08.310 --> 00:16:11.040
inaugural K&amp;L gates professorship of
ethics and computational technologies

00:16:11.040 --> 00:16:11.050
ethics and computational technologies
 

00:16:11.050 --> 00:16:14.460
ethics and computational technologies
eleanor Bosch ela is the director of the

00:16:14.460 --> 00:16:14.470
eleanor Bosch ela is the director of the
 

00:16:14.470 --> 00:16:16.620
eleanor Bosch ela is the director of the
community robotics education and

00:16:16.620 --> 00:16:16.630
community robotics education and
 

00:16:16.630 --> 00:16:19.440
community robotics education and
technology empowerment lab for those of

00:16:19.440 --> 00:16:19.450
technology empowerment lab for those of
 

00:16:19.450 --> 00:16:21.270
technology empowerment lab for those of
you who were here last night you heard

00:16:21.270 --> 00:16:21.280
you who were here last night you heard
 

00:16:21.280 --> 00:16:22.890
you who were here last night you heard
him refer to the create lab now you know

00:16:22.890 --> 00:16:22.900
him refer to the create lab now you know
 

00:16:22.900 --> 00:16:25.560
him refer to the create lab now you know
what the acronym stands for which is

00:16:25.560 --> 00:16:25.570
what the acronym stands for which is
 

00:16:25.570 --> 00:16:27.270
what the acronym stands for which is
focused on the development of

00:16:27.270 --> 00:16:27.280
focused on the development of
 

00:16:27.280 --> 00:16:29.190
focused on the development of
community-based social and educational

00:16:29.190 --> 00:16:29.200
community-based social and educational
 

00:16:29.200 --> 00:16:31.950
community-based social and educational
robotics and really transforming

00:16:31.950 --> 00:16:31.960
robotics and really transforming
 

00:16:31.960 --> 00:16:33.330
robotics and really transforming
people's lives through community

00:16:33.330 --> 00:16:33.340
people's lives through community
 

00:16:33.340 --> 00:16:35.910
people's lives through community
engagement to identify the challenges

00:16:35.910 --> 00:16:35.920
engagement to identify the challenges
 

00:16:35.920 --> 00:16:37.740
engagement to identify the challenges
that people face in their lives and the

00:16:37.740 --> 00:16:37.750
that people face in their lives and the
 

00:16:37.750 --> 00:16:39.900
that people face in their lives and the
ways that robotic and AI technologies

00:16:39.900 --> 00:16:39.910
ways that robotic and AI technologies
 

00:16:39.910 --> 00:16:43.860
ways that robotic and AI technologies
can really address respond and spawned

00:16:43.860 --> 00:16:43.870
can really address respond and spawned
 

00:16:43.870 --> 00:16:46.410
can really address respond and spawned
to those challenges and then support

00:16:46.410 --> 00:16:46.420
to those challenges and then support
 

00:16:46.420 --> 00:16:48.180
to those challenges and then support
people's abilities to achieve their

00:16:48.180 --> 00:16:48.190
people's abilities to achieve their
 

00:16:48.190 --> 00:16:48.720
people's abilities to achieve their
goals

00:16:48.720 --> 00:16:48.730
goals
 

00:16:48.730 --> 00:16:50.580
goals
and over the years the create labs

00:16:50.580 --> 00:16:50.590
and over the years the create labs
 

00:16:50.590 --> 00:16:52.800
and over the years the create labs
programs have engaged over 40,000 people

00:16:52.800 --> 00:16:52.810
programs have engaged over 40,000 people
 

00:16:52.810 --> 00:16:55.320
programs have engaged over 40,000 people
globally so the reach is not simply here

00:16:55.320 --> 00:16:55.330
globally so the reach is not simply here
 

00:16:55.330 --> 00:16:57.600
globally so the reach is not simply here
in the community not simply on campus

00:16:57.600 --> 00:16:57.610
in the community not simply on campus
 

00:16:57.610 --> 00:16:59.670
in the community not simply on campus
not even simply in the United States but

00:16:59.670 --> 00:16:59.680
not even simply in the United States but
 

00:16:59.680 --> 00:17:02.640
not even simply in the United States but
reaches around the globe ILA's been a

00:17:02.640 --> 00:17:02.650
reaches around the globe ILA's been a
 

00:17:02.650 --> 00:17:05.130
reaches around the globe ILA's been a
CMU faculty member since 1997 is the

00:17:05.130 --> 00:17:05.140
CMU faculty member since 1997 is the
 

00:17:05.140 --> 00:17:07.050
CMU faculty member since 1997 is the
author of four books dozens of articles

00:17:07.050 --> 00:17:07.060
author of four books dozens of articles
 

00:17:07.060 --> 00:17:09.660
author of four books dozens of articles
and holds 13 patents some of which were

00:17:09.660 --> 00:17:09.670
and holds 13 patents some of which were
 

00:17:09.670 --> 00:17:13.140
and holds 13 patents some of which were
part of what led him to have a brief I

00:17:13.140 --> 00:17:13.150
part of what led him to have a brief I
 

00:17:13.150 --> 00:17:15.390
part of what led him to have a brief I
believe career as a startup entrepreneur

00:17:15.390 --> 00:17:15.400
believe career as a startup entrepreneur
 

00:17:15.400 --> 00:17:17.520
believe career as a startup entrepreneur
he's been named a Kavli fellow by the

00:17:17.520 --> 00:17:17.530
he's been named a Kavli fellow by the
 

00:17:17.530 --> 00:17:19.770
he's been named a Kavli fellow by the
National Academy of Sciences and in fact

00:17:19.770 --> 00:17:19.780
National Academy of Sciences and in fact
 

00:17:19.780 --> 00:17:21.720
National Academy of Sciences and in fact
has been inducted into the I wanna make

00:17:21.720 --> 00:17:21.730
has been inducted into the I wanna make
 

00:17:21.730 --> 00:17:23.220
has been inducted into the I wanna make
sure I get this right the June Harless

00:17:23.220 --> 00:17:23.230
sure I get this right the June Harless
 

00:17:23.230 --> 00:17:26.670
sure I get this right the June Harless
West Virginia Hall of Fame so I think

00:17:26.670 --> 00:17:26.680
West Virginia Hall of Fame so I think
 

00:17:26.680 --> 00:17:28.560
West Virginia Hall of Fame so I think
probably a distinction that is unique in

00:17:28.560 --> 00:17:28.570
probably a distinction that is unique in
 

00:17:28.570 --> 00:17:32.130
probably a distinction that is unique in
this room following ILA's remarks he'll

00:17:32.130 --> 00:17:32.140
this room following ILA's remarks he'll
 

00:17:32.140 --> 00:17:34.110
this room following ILA's remarks he'll
be joined for a brief conversation by

00:17:34.110 --> 00:17:34.120
be joined for a brief conversation by
 

00:17:34.120 --> 00:17:36.240
be joined for a brief conversation by
Tom Simon Knight senior writer for Wired

00:17:36.240 --> 00:17:36.250
Tom Simon Knight senior writer for Wired
 

00:17:36.250 --> 00:17:38.550
Tom Simon Knight senior writer for Wired
who was previously the San Francisco

00:17:38.550 --> 00:17:38.560
who was previously the San Francisco
 

00:17:38.560 --> 00:17:40.410
who was previously the San Francisco
bureau chief at MIT Technology Review

00:17:40.410 --> 00:17:40.420
bureau chief at MIT Technology Review
 

00:17:40.420 --> 00:17:43.050
bureau chief at MIT Technology Review
and has written and edited technology

00:17:43.050 --> 00:17:43.060
and has written and edited technology
 

00:17:43.060 --> 00:17:44.580
and has written and edited technology
coverage at the New Scientist magazine

00:17:44.580 --> 00:17:44.590
coverage at the New Scientist magazine
 

00:17:44.590 --> 00:17:47.040
coverage at the New Scientist magazine
and now in his current position at Wired

00:17:47.040 --> 00:17:47.050
and now in his current position at Wired
 

00:17:47.050 --> 00:17:49.380
and now in his current position at Wired
he covers artificial intelligence and

00:17:49.380 --> 00:17:49.390
he covers artificial intelligence and
 

00:17:49.390 --> 00:17:50.580
he covers artificial intelligence and
its effects on the world

00:17:50.580 --> 00:17:50.590
its effects on the world
 

00:17:50.590 --> 00:17:56.370
its effects on the world
without further ado Elin or Bosch thank

00:17:56.370 --> 00:17:56.380
without further ado Elin or Bosch thank
 

00:17:56.380 --> 00:17:59.700
without further ado Elin or Bosch thank
you well thank you David for the

00:17:59.700 --> 00:17:59.710
you well thank you David for the
 

00:17:59.710 --> 00:18:00.870
you well thank you David for the
wonderful introduction and good morning

00:18:00.870 --> 00:18:00.880
wonderful introduction and good morning
 

00:18:00.880 --> 00:18:06.450
wonderful introduction and good morning
all to loosen my jaw and set the stage

00:18:06.450 --> 00:18:06.460
all to loosen my jaw and set the stage
 

00:18:06.460 --> 00:18:10.020
all to loosen my jaw and set the stage
some true stories first true story I'm

00:18:10.020 --> 00:18:10.030
some true stories first true story I'm
 

00:18:10.030 --> 00:18:12.450
some true stories first true story I'm
sitting in a room there's ministers of

00:18:12.450 --> 00:18:12.460
sitting in a room there's ministers of
 

00:18:12.460 --> 00:18:14.990
sitting in a room there's ministers of
transportation and ministers of Defense

00:18:14.990 --> 00:18:15.000
transportation and ministers of Defense
 

00:18:15.000 --> 00:18:17.430
transportation and ministers of Defense
ministers of sports from various

00:18:17.430 --> 00:18:17.440
ministers of sports from various
 

00:18:17.440 --> 00:18:19.290
ministers of sports from various
countries in the room and the

00:18:19.290 --> 00:18:19.300
countries in the room and the
 

00:18:19.300 --> 00:18:21.200
countries in the room and the
editor-in-chief of one of the biggest

00:18:21.200 --> 00:18:21.210
editor-in-chief of one of the biggest
 

00:18:21.210 --> 00:18:23.820
editor-in-chief of one of the biggest
journalism newspaper companies in the

00:18:23.820 --> 00:18:23.830
journalism newspaper companies in the
 

00:18:23.830 --> 00:18:26.580
journalism newspaper companies in the
world gets up and says we've been had by

00:18:26.580 --> 00:18:26.590
world gets up and says we've been had by
 

00:18:26.590 --> 00:18:28.980
world gets up and says we've been had by
ourselves when we published the first

00:18:28.980 --> 00:18:28.990
ourselves when we published the first
 

00:18:28.990 --> 00:18:32.430
ourselves when we published the first
story outing fake news I went online to

00:18:32.430 --> 00:18:32.440
story outing fake news I went online to
 

00:18:32.440 --> 00:18:34.920
story outing fake news I went online to
see our fake news story and on our

00:18:34.920 --> 00:18:34.930
see our fake news story and on our
 

00:18:34.930 --> 00:18:37.410
see our fake news story and on our
online version of our website there's

00:18:37.410 --> 00:18:37.420
online version of our website there's
 

00:18:37.420 --> 00:18:38.730
online version of our website there's
our fake news story in the middle and

00:18:38.730 --> 00:18:38.740
our fake news story in the middle and
 

00:18:38.740 --> 00:18:41.370
our fake news story in the middle and
above it and below it there was fake

00:18:41.370 --> 00:18:41.380
above it and below it there was fake
 

00:18:41.380 --> 00:18:45.440
above it and below it there was fake
news because we were selling Adwords and

00:18:45.440 --> 00:18:45.450
news because we were selling Adwords and
 

00:18:45.450 --> 00:18:48.120
news because we were selling Adwords and
the people who bought and won the

00:18:48.120 --> 00:18:48.130
the people who bought and won the
 

00:18:48.130 --> 00:18:49.740
the people who bought and won the
auction happened - the fake news

00:18:49.740 --> 00:18:49.750
auction happened - the fake news
 

00:18:49.750 --> 00:18:53.310
auction happened - the fake news
purveyors immediately and and he said

00:18:53.310 --> 00:18:53.320
purveyors immediately and and he said
 

00:18:53.320 --> 00:18:56.640
purveyors immediately and and he said
you know this is our own fault we don't

00:18:56.640 --> 00:18:56.650
you know this is our own fault we don't
 

00:18:56.650 --> 00:18:58.830
you know this is our own fault we don't
even know how to compensate our own

00:18:58.830 --> 00:18:58.840
even know how to compensate our own
 

00:18:58.840 --> 00:19:01.350
even know how to compensate our own
investigative journalism without being

00:19:01.350 --> 00:19:01.360
investigative journalism without being
 

00:19:01.360 --> 00:19:02.880
investigative journalism without being
part of a community that we're trying to

00:19:02.880 --> 00:19:02.890
part of a community that we're trying to
 

00:19:02.890 --> 00:19:06.600
part of a community that we're trying to
say is a disaster immediately gets up

00:19:06.600 --> 00:19:06.610
say is a disaster immediately gets up
 

00:19:06.610 --> 00:19:09.180
say is a disaster immediately gets up
the CEO of the biggest behavioral

00:19:09.180 --> 00:19:09.190
the CEO of the biggest behavioral
 

00:19:09.190 --> 00:19:11.580
the CEO of the biggest behavioral
analyst company in the world and says I

00:19:11.580 --> 00:19:11.590
analyst company in the world and says I
 

00:19:11.590 --> 00:19:12.720
analyst company in the world and says I
completely agree with that he just said

00:19:12.720 --> 00:19:12.730
completely agree with that he just said
 

00:19:12.730 --> 00:19:16.020
completely agree with that he just said
that was me I did the article on top and

00:19:16.020 --> 00:19:16.030
that was me I did the article on top and
 

00:19:16.030 --> 00:19:17.130
that was me I did the article on top and
I did the article on the bottom and

00:19:17.130 --> 00:19:17.140
I did the article on the bottom and
 

00:19:17.140 --> 00:19:20.970
I did the article on the bottom and
guess what I have a team of machine

00:19:20.970 --> 00:19:20.980
guess what I have a team of machine
 

00:19:20.980 --> 00:19:23.460
guess what I have a team of machine
learning people who are amazing at what

00:19:23.460 --> 00:19:23.470
learning people who are amazing at what
 

00:19:23.470 --> 00:19:25.680
learning people who are amazing at what
they do my computer's do hundreds of

00:19:25.680 --> 00:19:25.690
they do my computer's do hundreds of
 

00:19:25.690 --> 00:19:28.800
they do my computer's do hundreds of
millions of a/b comparisons a day and we

00:19:28.800 --> 00:19:28.810
millions of a/b comparisons a day and we
 

00:19:28.810 --> 00:19:30.750
millions of a/b comparisons a day and we
know this is a direct quote how to

00:19:30.750 --> 00:19:30.760
know this is a direct quote how to
 

00:19:30.760 --> 00:19:33.680
know this is a direct quote how to
maximize dopamine response by people and

00:19:33.680 --> 00:19:33.690
maximize dopamine response by people and
 

00:19:33.690 --> 00:19:36.380
maximize dopamine response by people and
we know how to make a system that

00:19:36.380 --> 00:19:36.390
we know how to make a system that
 

00:19:36.390 --> 00:19:39.390
we know how to make a system that
maximizes this and engages you and

00:19:39.390 --> 00:19:39.400
maximizes this and engages you and
 

00:19:39.400 --> 00:19:40.980
maximizes this and engages you and
causes you to click through and it makes

00:19:40.980 --> 00:19:40.990
causes you to click through and it makes
 

00:19:40.990 --> 00:19:44.460
causes you to click through and it makes
me money and I admit that it's not

00:19:44.460 --> 00:19:44.470
me money and I admit that it's not
 

00:19:44.470 --> 00:19:46.650
me money and I admit that it's not
completely ethical but it really works

00:19:46.650 --> 00:19:46.660
completely ethical but it really works
 

00:19:46.660 --> 00:19:48.930
completely ethical but it really works
well and I challenge any of you in this

00:19:48.930 --> 00:19:48.940
well and I challenge any of you in this
 

00:19:48.940 --> 00:19:50.310
well and I challenge any of you in this
room to come up with a better way for me

00:19:50.310 --> 00:19:50.320
room to come up with a better way for me
 

00:19:50.320 --> 00:19:51.420
room to come up with a better way for me
to make as much money and I'll switch

00:19:51.420 --> 00:19:51.430
to make as much money and I'll switch
 

00:19:51.430 --> 00:19:57.080
to make as much money and I'll switch
right away another story a few years ago

00:19:57.080 --> 00:19:57.090
right away another story a few years ago
 

00:19:57.090 --> 00:20:00.900
right away another story a few years ago
gentleman came back from war and started

00:20:00.900 --> 00:20:00.910
gentleman came back from war and started
 

00:20:00.910 --> 00:20:02.100
gentleman came back from war and started
a

00:20:02.100 --> 00:20:02.110
a
 

00:20:02.110 --> 00:20:08.130
a
a bar Irish themed pub in Atlanta and it

00:20:08.130 --> 00:20:08.140
a bar Irish themed pub in Atlanta and it
 

00:20:08.140 --> 00:20:09.330
a bar Irish themed pub in Atlanta and it
was a transitional neighborhood where

00:20:09.330 --> 00:20:09.340
was a transitional neighborhood where
 

00:20:09.340 --> 00:20:12.030
was a transitional neighborhood where
gentrification was happening but there

00:20:12.030 --> 00:20:12.040
gentrification was happening but there
 

00:20:12.040 --> 00:20:13.560
gentrification was happening but there
were people homeless folks on the

00:20:13.560 --> 00:20:13.570
were people homeless folks on the
 

00:20:13.570 --> 00:20:15.600
were people homeless folks on the
sidewalk and he didn't like this

00:20:15.600 --> 00:20:15.610
sidewalk and he didn't like this
 

00:20:15.610 --> 00:20:17.430
sidewalk and he didn't like this
homeless presence on the sidewalk in

00:20:17.430 --> 00:20:17.440
homeless presence on the sidewalk in
 

00:20:17.440 --> 00:20:19.350
homeless presence on the sidewalk in
front of his pub so he built the world's

00:20:19.350 --> 00:20:19.360
front of his pub so he built the world's
 

00:20:19.360 --> 00:20:24.900
front of his pub so he built the world's
first bum bot bu MB ot robot controlled

00:20:24.900 --> 00:20:24.910
first bum bot bu MB ot robot controlled
 

00:20:24.910 --> 00:20:26.610
first bum bot bu MB ot robot controlled
by him that would threaten people on

00:20:26.610 --> 00:20:26.620
by him that would threaten people on
 

00:20:26.620 --> 00:20:28.200
by him that would threaten people on
this on the sidewalk with a high

00:20:28.200 --> 00:20:28.210
this on the sidewalk with a high
 

00:20:28.210 --> 00:20:30.030
this on the sidewalk with a high
pressure water cannon and a spotlight

00:20:30.030 --> 00:20:30.040
pressure water cannon and a spotlight
 

00:20:30.040 --> 00:20:32.430
pressure water cannon and a spotlight
and a speaker and it made the news

00:20:32.430 --> 00:20:32.440
and a speaker and it made the news
 

00:20:32.440 --> 00:20:34.950
and a speaker and it made the news
stories and the stories in the news

00:20:34.950 --> 00:20:34.960
stories and the stories in the news
 

00:20:34.960 --> 00:20:37.159
stories and the stories in the news
which fascinated me were about the

00:20:37.159 --> 00:20:37.169
which fascinated me were about the
 

00:20:37.169 --> 00:20:40.140
which fascinated me were about the
empowerment he had as a maker inventing

00:20:40.140 --> 00:20:40.150
empowerment he had as a maker inventing
 

00:20:40.150 --> 00:20:43.409
empowerment he had as a maker inventing
a whole new innovative product now fast

00:20:43.409 --> 00:20:43.419
a whole new innovative product now fast
 

00:20:43.419 --> 00:20:45.680
a whole new innovative product now fast
forward about seven years last year

00:20:45.680 --> 00:20:45.690
forward about seven years last year
 

00:20:45.690 --> 00:20:48.150
forward about seven years last year
nightscope started having this wonderful

00:20:48.150 --> 00:20:48.160
nightscope started having this wonderful
 

00:20:48.160 --> 00:20:50.430
nightscope started having this wonderful
robot night scope which is a security

00:20:50.430 --> 00:20:50.440
robot night scope which is a security
 

00:20:50.440 --> 00:20:52.890
robot night scope which is a security
guard that you can rent and have roam

00:20:52.890 --> 00:20:52.900
guard that you can rent and have roam
 

00:20:52.900 --> 00:20:55.850
guard that you can rent and have roam
around your establishment night scope

00:20:55.850 --> 00:20:55.860
around your establishment night scope
 

00:20:55.860 --> 00:20:58.650
around your establishment night scope
was purchased by an establishment in San

00:20:58.650 --> 00:20:58.660
was purchased by an establishment in San
 

00:20:58.660 --> 00:21:01.440
was purchased by an establishment in San
Francisco because the sidewalk in front

00:21:01.440 --> 00:21:01.450
Francisco because the sidewalk in front
 

00:21:01.450 --> 00:21:02.700
Francisco because the sidewalk in front
of the establishment has so many

00:21:02.700 --> 00:21:02.710
of the establishment has so many
 

00:21:02.710 --> 00:21:04.830
of the establishment has so many
homeless people on it and so now we have

00:21:04.830 --> 00:21:04.840
homeless people on it and so now we have
 

00:21:04.840 --> 00:21:06.270
homeless people on it and so now we have
a commercial robot used by an

00:21:06.270 --> 00:21:06.280
a commercial robot used by an
 

00:21:06.280 --> 00:21:08.580
a commercial robot used by an
establishment to actually keep people

00:21:08.580 --> 00:21:08.590
establishment to actually keep people
 

00:21:08.590 --> 00:21:11.610
establishment to actually keep people
away from their sidewalk this is where

00:21:11.610 --> 00:21:11.620
away from their sidewalk this is where
 

00:21:11.620 --> 00:21:14.669
away from their sidewalk this is where
the story can't be made up it's too good

00:21:14.669 --> 00:21:14.679
the story can't be made up it's too good
 

00:21:14.679 --> 00:21:15.570
the story can't be made up it's too good
to be fake

00:21:15.570 --> 00:21:15.580
to be fake
 

00:21:15.580 --> 00:21:18.330
to be fake
the establishment that bought nightscope

00:21:18.330 --> 00:21:18.340
the establishment that bought nightscope
 

00:21:18.340 --> 00:21:21.240
the establishment that bought nightscope
and used it to make sure homeless didn't

00:21:21.240 --> 00:21:21.250
and used it to make sure homeless didn't
 

00:21:21.250 --> 00:21:22.590
and used it to make sure homeless didn't
congregate on the sidewalk in front of

00:21:22.590 --> 00:21:22.600
congregate on the sidewalk in front of
 

00:21:22.600 --> 00:21:24.780
congregate on the sidewalk in front of
their establishment was the Society for

00:21:24.780 --> 00:21:24.790
their establishment was the Society for
 

00:21:24.790 --> 00:21:28.409
their establishment was the Society for
the Prevention of Cruelty to Animals no

00:21:28.409 --> 00:21:28.419
the Prevention of Cruelty to Animals no
 

00:21:28.419 --> 00:21:28.890
the Prevention of Cruelty to Animals no
kidding

00:21:28.890 --> 00:21:28.900
kidding
 

00:21:28.900 --> 00:21:32.630
kidding
go look this up so the SPCA used a robot

00:21:32.630 --> 00:21:32.640
go look this up so the SPCA used a robot
 

00:21:32.640 --> 00:21:35.039
go look this up so the SPCA used a robot
to intimidate people on the sidewalk

00:21:35.039 --> 00:21:35.049
to intimidate people on the sidewalk
 

00:21:35.049 --> 00:21:38.640
to intimidate people on the sidewalk
until by the way San Francisco City

00:21:38.640 --> 00:21:38.650
until by the way San Francisco City
 

00:21:38.650 --> 00:21:44.760
until by the way San Francisco City
Council made that illegal another one we

00:21:44.760 --> 00:21:44.770
Council made that illegal another one we
 

00:21:44.770 --> 00:21:46.799
Council made that illegal another one we
talked a great deal about war and robots

00:21:46.799 --> 00:21:46.809
talked a great deal about war and robots
 

00:21:46.809 --> 00:21:49.470
talked a great deal about war and robots
and whether robots should in a situation

00:21:49.470 --> 00:21:49.480
and whether robots should in a situation
 

00:21:49.480 --> 00:21:51.659
and whether robots should in a situation
where there's a war going on make

00:21:51.659 --> 00:21:51.669
where there's a war going on make
 

00:21:51.669 --> 00:21:53.390
where there's a war going on make
decisions about taking human life and

00:21:53.390 --> 00:21:53.400
decisions about taking human life and
 

00:21:53.400 --> 00:21:55.770
decisions about taking human life and
it's an excellent and important argument

00:21:55.770 --> 00:21:55.780
it's an excellent and important argument
 

00:21:55.780 --> 00:21:56.730
it's an excellent and important argument
to have and there's some outstanding

00:21:56.730 --> 00:21:56.740
to have and there's some outstanding
 

00:21:56.740 --> 00:22:00.380
to have and there's some outstanding
books on the subject

00:22:00.380 --> 00:22:00.390
 

00:22:00.390 --> 00:22:03.900
meanwhile in South Korea one of the

00:22:03.900 --> 00:22:03.910
meanwhile in South Korea one of the
 

00:22:03.910 --> 00:22:05.250
meanwhile in South Korea one of the
biggest electronics manufacturers in the

00:22:05.250 --> 00:22:05.260
biggest electronics manufacturers in the
 

00:22:05.260 --> 00:22:07.650
biggest electronics manufacturers in the
world made a machine gun activated

00:22:07.650 --> 00:22:07.660
world made a machine gun activated
 

00:22:07.660 --> 00:22:09.090
world made a machine gun activated
turret that's completely autonomous

00:22:09.090 --> 00:22:09.100
turret that's completely autonomous
 

00:22:09.100 --> 00:22:11.220
turret that's completely autonomous
users near-infrared to actually identify

00:22:11.220 --> 00:22:11.230
users near-infrared to actually identify
 

00:22:11.230 --> 00:22:13.560
users near-infrared to actually identify
people and shoot at them and it's used

00:22:13.560 --> 00:22:13.570
people and shoot at them and it's used
 

00:22:13.570 --> 00:22:15.690
people and shoot at them and it's used
today to guard some actual

00:22:15.690 --> 00:22:15.700
today to guard some actual
 

00:22:15.700 --> 00:22:17.460
today to guard some actual
retail establishments and it's already

00:22:17.460 --> 00:22:17.470
retail establishments and it's already
 

00:22:17.470 --> 00:22:20.580
retail establishments and it's already
installed today on the DMZ and it's not

00:22:20.580 --> 00:22:20.590
installed today on the DMZ and it's not
 

00:22:20.590 --> 00:22:22.019
installed today on the DMZ and it's not
one odd actor there are multiple

00:22:22.019 --> 00:22:22.029
one odd actor there are multiple
 

00:22:22.029 --> 00:22:23.490
one odd actor there are multiple
companies now doing this in South Korea

00:22:23.490 --> 00:22:23.500
companies now doing this in South Korea
 

00:22:23.500 --> 00:22:27.330
companies now doing this in South Korea
as well as in the Middle East now go

00:22:27.330 --> 00:22:27.340
as well as in the Middle East now go
 

00:22:27.340 --> 00:22:28.500
as well as in the Middle East now go
back a few years ago let's talk about

00:22:28.500 --> 00:22:28.510
back a few years ago let's talk about
 

00:22:28.510 --> 00:22:31.980
back a few years ago let's talk about
drones Los Angeles is testing drones for

00:22:31.980 --> 00:22:31.990
drones Los Angeles is testing drones for
 

00:22:31.990 --> 00:22:33.389
drones Los Angeles is testing drones for
one of the first times a few years ago

00:22:33.389 --> 00:22:33.399
one of the first times a few years ago
 

00:22:33.399 --> 00:22:36.360
one of the first times a few years ago
they had to join up in the sky cameras

00:22:36.360 --> 00:22:36.370
they had to join up in the sky cameras
 

00:22:36.370 --> 00:22:37.649
they had to join up in the sky cameras
down and the police were having a blast

00:22:37.649 --> 00:22:37.659
down and the police were having a blast
 

00:22:37.659 --> 00:22:40.440
down and the police were having a blast
flying this thing around just like your

00:22:40.440 --> 00:22:40.450
flying this thing around just like your
 

00:22:40.450 --> 00:22:43.289
flying this thing around just like your
kids except when they're flying this

00:22:43.289 --> 00:22:43.299
kids except when they're flying this
 

00:22:43.299 --> 00:22:44.430
kids except when they're flying this
thing around just playing with it they

00:22:44.430 --> 00:22:44.440
thing around just playing with it they
 

00:22:44.440 --> 00:22:47.039
thing around just playing with it they
noticed pot they notice the whole

00:22:47.039 --> 00:22:47.049
noticed pot they notice the whole
 

00:22:47.049 --> 00:22:48.509
noticed pot they notice the whole
marijuana plantation behind somebody's

00:22:48.509 --> 00:22:48.519
marijuana plantation behind somebody's
 

00:22:48.519 --> 00:22:50.100
marijuana plantation behind somebody's
walls they went oh look at that

00:22:50.100 --> 00:22:50.110
walls they went oh look at that
 

00:22:50.110 --> 00:22:53.850
walls they went oh look at that
what so they go in and make arrests and

00:22:53.850 --> 00:22:53.860
what so they go in and make arrests and
 

00:22:53.860 --> 00:22:55.320
what so they go in and make arrests and
it goes all the way up to the state

00:22:55.320 --> 00:22:55.330
it goes all the way up to the state
 

00:22:55.330 --> 00:22:57.210
it goes all the way up to the state
Supreme Court because the question is

00:22:57.210 --> 00:22:57.220
Supreme Court because the question is
 

00:22:57.220 --> 00:22:59.789
Supreme Court because the question is
they didn't have any right to search

00:22:59.789 --> 00:22:59.799
they didn't have any right to search
 

00:22:59.799 --> 00:23:02.370
they didn't have any right to search
they didn't have a warrant well what the

00:23:02.370 --> 00:23:02.380
they didn't have a warrant well what the
 

00:23:02.380 --> 00:23:04.110
they didn't have a warrant well what the
court said in the end was you know what

00:23:04.110 --> 00:23:04.120
court said in the end was you know what
 

00:23:04.120 --> 00:23:07.200
court said in the end was you know what
now that there are drones our assumption

00:23:07.200 --> 00:23:07.210
now that there are drones our assumption
 

00:23:07.210 --> 00:23:09.000
now that there are drones our assumption
to the right of privacy by having a high

00:23:09.000 --> 00:23:09.010
to the right of privacy by having a high
 

00:23:09.010 --> 00:23:11.370
to the right of privacy by having a high
wall around our house actually no longer

00:23:11.370 --> 00:23:11.380
wall around our house actually no longer
 

00:23:11.380 --> 00:23:13.889
wall around our house actually no longer
applies because drones are commonly

00:23:13.889 --> 00:23:13.899
applies because drones are commonly
 

00:23:13.899 --> 00:23:16.379
applies because drones are commonly
available and they go above things so

00:23:16.379 --> 00:23:16.389
available and they go above things so
 

00:23:16.389 --> 00:23:17.610
available and they go above things so
you don't get your right to privacy

00:23:17.610 --> 00:23:17.620
you don't get your right to privacy
 

00:23:17.620 --> 00:23:19.230
you don't get your right to privacy
assumed unless you happen to have a roof

00:23:19.230 --> 00:23:19.240
assumed unless you happen to have a roof
 

00:23:19.240 --> 00:23:23.549
assumed unless you happen to have a roof
over your marijuana plantation so it's

00:23:23.549 --> 00:23:23.559
over your marijuana plantation so it's
 

00:23:23.559 --> 00:23:25.639
over your marijuana plantation so it's
kind of fascinating that the legal

00:23:25.639 --> 00:23:25.649
kind of fascinating that the legal
 

00:23:25.649 --> 00:23:28.560
kind of fascinating that the legal
ramification was to change the rights we

00:23:28.560 --> 00:23:28.570
ramification was to change the rights we
 

00:23:28.570 --> 00:23:30.870
ramification was to change the rights we
have around privacy because of the piece

00:23:30.870 --> 00:23:30.880
have around privacy because of the piece
 

00:23:30.880 --> 00:23:32.009
have around privacy because of the piece
of technology that was boundary

00:23:32.009 --> 00:23:32.019
of technology that was boundary
 

00:23:32.019 --> 00:23:35.789
of technology that was boundary
technology and fast-forward to a couple

00:23:35.789 --> 00:23:35.799
technology and fast-forward to a couple
 

00:23:35.799 --> 00:23:37.080
technology and fast-forward to a couple
months ago I was in a meeting with the

00:23:37.080 --> 00:23:37.090
months ago I was in a meeting with the
 

00:23:37.090 --> 00:23:38.310
months ago I was in a meeting with the
Minister of Transportation and where the

00:23:38.310 --> 00:23:38.320
Minister of Transportation and where the
 

00:23:38.320 --> 00:23:40.049
Minister of Transportation and where the
biggest countries in the world and we

00:23:40.049 --> 00:23:40.059
biggest countries in the world and we
 

00:23:40.059 --> 00:23:40.980
biggest countries in the world and we
were taking questions from the audience

00:23:40.980 --> 00:23:40.990
were taking questions from the audience
 

00:23:40.990 --> 00:23:42.930
were taking questions from the audience
about drones and people were saying

00:23:42.930 --> 00:23:42.940
about drones and people were saying
 

00:23:42.940 --> 00:23:44.370
about drones and people were saying
questions like well what's the

00:23:44.370 --> 00:23:44.380
questions like well what's the
 

00:23:44.380 --> 00:23:45.450
questions like well what's the
regulatory infrastructure you're gonna

00:23:45.450 --> 00:23:45.460
regulatory infrastructure you're gonna
 

00:23:45.460 --> 00:23:47.460
regulatory infrastructure you're gonna
put in place to allow drones to fly and

00:23:47.460 --> 00:23:47.470
put in place to allow drones to fly and
 

00:23:47.470 --> 00:23:49.889
put in place to allow drones to fly and
the answer from the Minister was we have

00:23:49.889 --> 00:23:49.899
the answer from the Minister was we have
 

00:23:49.899 --> 00:23:52.289
the answer from the Minister was we have
no idea somebody else has what about

00:23:52.289 --> 00:23:52.299
no idea somebody else has what about
 

00:23:52.299 --> 00:23:53.970
no idea somebody else has what about
tort and liability how we're gonna deal

00:23:53.970 --> 00:23:53.980
tort and liability how we're gonna deal
 

00:23:53.980 --> 00:23:57.269
tort and liability how we're gonna deal
with insurance around drones answer we

00:23:57.269 --> 00:23:57.279
with insurance around drones answer we
 

00:23:57.279 --> 00:24:00.180
with insurance around drones answer we
have no clue nearly every question the

00:24:00.180 --> 00:24:00.190
have no clue nearly every question the
 

00:24:00.190 --> 00:24:01.680
have no clue nearly every question the
audience asked the answer that was

00:24:01.680 --> 00:24:01.690
audience asked the answer that was
 

00:24:01.690 --> 00:24:02.909
audience asked the answer that was
received by the audience from the

00:24:02.909 --> 00:24:02.919
received by the audience from the
 

00:24:02.919 --> 00:24:04.200
received by the audience from the
Minister of Transportation for that

00:24:04.200 --> 00:24:04.210
Minister of Transportation for that
 

00:24:04.210 --> 00:24:08.340
Minister of Transportation for that
country was we have no idea okay one

00:24:08.340 --> 00:24:08.350
country was we have no idea okay one
 

00:24:08.350 --> 00:24:10.019
country was we have no idea okay one
final true story for you let's go to

00:24:10.019 --> 00:24:10.029
final true story for you let's go to
 

00:24:10.029 --> 00:24:14.370
final true story for you let's go to
cars remember the cute Google car it had

00:24:14.370 --> 00:24:14.380
cars remember the cute Google car it had
 

00:24:14.380 --> 00:24:15.690
cars remember the cute Google car it had
no steering wheel do you remember that

00:24:15.690 --> 00:24:15.700
no steering wheel do you remember that
 

00:24:15.700 --> 00:24:19.529
no steering wheel do you remember that
it was steering free why I think we need

00:24:19.529 --> 00:24:19.539
it was steering free why I think we need
 

00:24:19.539 --> 00:24:21.539
it was steering free why I think we need
to revisit that question because it is

00:24:21.539 --> 00:24:21.549
to revisit that question because it is
 

00:24:21.549 --> 00:24:22.769
to revisit that question because it is
very relevant to what you've been

00:24:22.769 --> 00:24:22.779
very relevant to what you've been
 

00:24:22.779 --> 00:24:24.360
very relevant to what you've been
hearing about in the news today

00:24:24.360 --> 00:24:24.370
hearing about in the news today
 

00:24:24.370 --> 00:24:26.100
hearing about in the news today
so the reason they had no steering wheel

00:24:26.100 --> 00:24:26.110
so the reason they had no steering wheel
 

00:24:26.110 --> 00:24:28.139
so the reason they had no steering wheel
is kind of interesting they took a bunch

00:24:28.139 --> 00:24:28.149
is kind of interesting they took a bunch
 

00:24:28.149 --> 00:24:29.590
is kind of interesting they took a bunch
of pre I

00:24:29.590 --> 00:24:29.600
of pre I
 

00:24:29.600 --> 00:24:31.620
of pre I
Priuses and put the self-driving

00:24:31.620 --> 00:24:31.630
Priuses and put the self-driving
 

00:24:31.630 --> 00:24:34.660
Priuses and put the self-driving
software in it in early days we have to

00:24:34.660 --> 00:24:34.670
software in it in early days we have to
 

00:24:34.670 --> 00:24:36.040
software in it in early days we have to
give come up with some floral form for

00:24:36.040 --> 00:24:36.050
give come up with some floral form for
 

00:24:36.050 --> 00:24:36.460
give come up with some floral form for
it right

00:24:36.460 --> 00:24:36.470
it right
 

00:24:36.470 --> 00:24:39.760
it right
and then they trained Google employees

00:24:39.760 --> 00:24:39.770
and then they trained Google employees
 

00:24:39.770 --> 00:24:41.650
and then they trained Google employees
to use these cars and they put cameras

00:24:41.650 --> 00:24:41.660
to use these cars and they put cameras
 

00:24:41.660 --> 00:24:42.820
to use these cars and they put cameras
in them to watch the Google employees

00:24:42.820 --> 00:24:42.830
in them to watch the Google employees
 

00:24:42.830 --> 00:24:46.150
in them to watch the Google employees
and see what they do and the engineers

00:24:46.150 --> 00:24:46.160
and see what they do and the engineers
 

00:24:46.160 --> 00:24:48.250
and see what they do and the engineers
then reviewed the video footage of this

00:24:48.250 --> 00:24:48.260
then reviewed the video footage of this
 

00:24:48.260 --> 00:24:50.920
then reviewed the video footage of this
and they were gobsmacked there would be

00:24:50.920 --> 00:24:50.930
and they were gobsmacked there would be
 

00:24:50.930 --> 00:24:52.780
and they were gobsmacked there would be
an engineer who on their first day on

00:24:52.780 --> 00:24:52.790
an engineer who on their first day on
 

00:24:52.790 --> 00:24:54.250
an engineer who on their first day on
the highway from San Francisco down to

00:24:54.250 --> 00:24:54.260
the highway from San Francisco down to
 

00:24:54.260 --> 00:24:56.560
the highway from San Francisco down to
Mountain View or in the Google

00:24:56.560 --> 00:24:56.570
Mountain View or in the Google
 

00:24:56.570 --> 00:24:59.530
Mountain View or in the Google
self-driving car cameras there and their

00:24:59.530 --> 00:24:59.540
self-driving car cameras there and their
 

00:24:59.540 --> 00:25:01.240
self-driving car cameras there and their
babies in the backseat in the in a

00:25:01.240 --> 00:25:01.250
babies in the backseat in the in a
 

00:25:01.250 --> 00:25:02.380
babies in the backseat in the in a
little car seat and you know what

00:25:02.380 --> 00:25:02.390
little car seat and you know what
 

00:25:02.390 --> 00:25:03.490
little car seat and you know what
they're doing they're like this the

00:25:03.490 --> 00:25:03.500
they're doing they're like this the
 

00:25:03.500 --> 00:25:07.150
they're doing they're like this the
entire time you so cute the whole time

00:25:07.150 --> 00:25:07.160
entire time you so cute the whole time
 

00:25:07.160 --> 00:25:09.610
entire time you so cute the whole time
on the highway there was one guy

00:25:09.610 --> 00:25:09.620
on the highway there was one guy
 

00:25:09.620 --> 00:25:13.930
on the highway there was one guy
memorably who spilled his coffee so for

00:25:13.930 --> 00:25:13.940
memorably who spilled his coffee so for
 

00:25:13.940 --> 00:25:17.410
memorably who spilled his coffee so for
10 minutes he was like this on the floor

00:25:17.410 --> 00:25:17.420
10 minutes he was like this on the floor
 

00:25:17.420 --> 00:25:20.020
10 minutes he was like this on the floor
trying to clean the floor while the cars

00:25:20.020 --> 00:25:20.030
trying to clean the floor while the cars
 

00:25:20.030 --> 00:25:21.400
trying to clean the floor while the cars
on the highway barreling down the road

00:25:21.400 --> 00:25:21.410
on the highway barreling down the road
 

00:25:21.410 --> 00:25:23.800
on the highway barreling down the road
so what did Google do they had a meeting

00:25:23.800 --> 00:25:23.810
so what did Google do they had a meeting
 

00:25:23.810 --> 00:25:26.340
so what did Google do they had a meeting
and they panicked they said holy buckets

00:25:26.340 --> 00:25:26.350
and they panicked they said holy buckets
 

00:25:26.350 --> 00:25:28.810
and they panicked they said holy buckets
people who we trained who're Google

00:25:28.810 --> 00:25:28.820
people who we trained who're Google
 

00:25:28.820 --> 00:25:30.850
people who we trained who're Google
engineers carefully selected for their

00:25:30.850 --> 00:25:30.860
engineers carefully selected for their
 

00:25:30.860 --> 00:25:33.580
engineers carefully selected for their
raw intelligence of superiority are

00:25:33.580 --> 00:25:33.590
raw intelligence of superiority are
 

00:25:33.590 --> 00:25:35.830
raw intelligence of superiority are
doing what their completely trusting the

00:25:35.830 --> 00:25:35.840
doing what their completely trusting the
 

00:25:35.840 --> 00:25:38.860
doing what their completely trusting the
car well then the answer is obvious we

00:25:38.860 --> 00:25:38.870
car well then the answer is obvious we
 

00:25:38.870 --> 00:25:40.000
car well then the answer is obvious we
gotta get rid of the steering wheel we

00:25:40.000 --> 00:25:40.010
gotta get rid of the steering wheel we
 

00:25:40.010 --> 00:25:43.210
gotta get rid of the steering wheel we
can't trust people at all that's why

00:25:43.210 --> 00:25:43.220
can't trust people at all that's why
 

00:25:43.220 --> 00:25:44.470
can't trust people at all that's why
there was no steering wheel in the

00:25:44.470 --> 00:25:44.480
there was no steering wheel in the
 

00:25:44.480 --> 00:25:47.830
there was no steering wheel in the
little cute Google car now fast-forward

00:25:47.830 --> 00:25:47.840
little cute Google car now fast-forward
 

00:25:47.840 --> 00:25:48.940
little cute Google car now fast-forward
to the accidents you've heard about it

00:25:48.940 --> 00:25:48.950
to the accidents you've heard about it
 

00:25:48.950 --> 00:25:51.480
to the accidents you've heard about it
over the last few years dude in Tesla

00:25:51.480 --> 00:25:51.490
over the last few years dude in Tesla
 

00:25:51.490 --> 00:25:54.700
over the last few years dude in Tesla
watching Harry Potter am I getting this

00:25:54.700 --> 00:25:54.710
watching Harry Potter am I getting this
 

00:25:54.710 --> 00:25:56.680
watching Harry Potter am I getting this
right watching a Harry Potter movie or

00:25:56.680 --> 00:25:56.690
right watching a Harry Potter movie or
 

00:25:56.690 --> 00:25:58.510
right watching a Harry Potter movie or
listening to a Harry Potter audio drive

00:25:58.510 --> 00:25:58.520
listening to a Harry Potter audio drive
 

00:25:58.520 --> 00:26:00.400
listening to a Harry Potter audio drive
running into this side of a truck that

00:26:00.400 --> 00:26:00.410
running into this side of a truck that
 

00:26:00.410 --> 00:26:02.190
running into this side of a truck that
if he was looking up he would have seen

00:26:02.190 --> 00:26:02.200
if he was looking up he would have seen
 

00:26:02.200 --> 00:26:05.700
if he was looking up he would have seen
person in car running into a bicycle

00:26:05.700 --> 00:26:05.710
person in car running into a bicycle
 

00:26:05.710 --> 00:26:07.960
person in car running into a bicycle
where the safety driver is clearly not

00:26:07.960 --> 00:26:07.970
where the safety driver is clearly not
 

00:26:07.970 --> 00:26:09.130
where the safety driver is clearly not
paying attention for the couple of

00:26:09.130 --> 00:26:09.140
paying attention for the couple of
 

00:26:09.140 --> 00:26:10.680
paying attention for the couple of
seconds before the crash

00:26:10.680 --> 00:26:10.690
seconds before the crash
 

00:26:10.690 --> 00:26:13.840
seconds before the crash
in a funny way Google was right their

00:26:13.840 --> 00:26:13.850
in a funny way Google was right their
 

00:26:13.850 --> 00:26:15.640
in a funny way Google was right their
attempted solution was removing the

00:26:15.640 --> 00:26:15.650
attempted solution was removing the
 

00:26:15.650 --> 00:26:17.710
attempted solution was removing the
steering wheel a very extreme point of

00:26:17.710 --> 00:26:17.720
steering wheel a very extreme point of
 

00:26:17.720 --> 00:26:21.940
steering wheel a very extreme point of
view the back step was let's not bother

00:26:21.940 --> 00:26:21.950
view the back step was let's not bother
 

00:26:21.950 --> 00:26:23.050
view the back step was let's not bother
with that actual let's just leave it

00:26:23.050 --> 00:26:23.060
with that actual let's just leave it
 

00:26:23.060 --> 00:26:25.030
with that actual let's just leave it
there and make sure people know as Eric

00:26:25.030 --> 00:26:25.040
there and make sure people know as Eric
 

00:26:25.040 --> 00:26:26.800
there and make sure people know as Eric
showed in his video when people should

00:26:26.800 --> 00:26:26.810
showed in his video when people should
 

00:26:26.810 --> 00:26:28.810
showed in his video when people should
just take over like that as if people

00:26:28.810 --> 00:26:28.820
just take over like that as if people
 

00:26:28.820 --> 00:26:32.620
just take over like that as if people
have the sudden attention to jump into a

00:26:32.620 --> 00:26:32.630
have the sudden attention to jump into a
 

00:26:32.630 --> 00:26:35.310
have the sudden attention to jump into a
high-stress situation and react quickly

00:26:35.310 --> 00:26:35.320
high-stress situation and react quickly
 

00:26:35.320 --> 00:26:37.570
high-stress situation and react quickly
which by the way is the opposite of how

00:26:37.570 --> 00:26:37.580
which by the way is the opposite of how
 

00:26:37.580 --> 00:26:41.500
which by the way is the opposite of how
pilots work with auto pilots so what

00:26:41.500 --> 00:26:41.510
pilots work with auto pilots so what
 

00:26:41.510 --> 00:26:42.970
pilots work with auto pilots so what
wasn't in the news

00:26:42.970 --> 00:26:42.980
wasn't in the news
 

00:26:42.980 --> 00:26:45.850
wasn't in the news
in that case is how hard it is for all

00:26:45.850 --> 00:26:45.860
in that case is how hard it is for all
 

00:26:45.860 --> 00:26:48.580
in that case is how hard it is for all
of these cars to see bicycles but a

00:26:48.580 --> 00:26:48.590
of these cars to see bicycles but a
 

00:26:48.590 --> 00:26:50.289
of these cars to see bicycles but a
human on a bicycle and our nice thick

00:26:50.289 --> 00:26:50.299
human on a bicycle and our nice thick
 

00:26:50.299 --> 00:26:52.180
human on a bicycle and our nice thick
legs make it obvious that we are there

00:26:52.180 --> 00:26:52.190
legs make it obvious that we are there
 

00:26:52.190 --> 00:26:54.669
legs make it obvious that we are there
but bicycles are a bunch of little thin

00:26:54.669 --> 00:26:54.679
but bicycles are a bunch of little thin
 

00:26:54.679 --> 00:26:56.080
but bicycles are a bunch of little thin
frames and the lighter goes right

00:26:56.080 --> 00:26:56.090
frames and the lighter goes right
 

00:26:56.090 --> 00:26:58.060
frames and the lighter goes right
through them and by the way all those

00:26:58.060 --> 00:26:58.070
through them and by the way all those
 

00:26:58.070 --> 00:27:00.610
through them and by the way all those
sensors the robots have are noisy so

00:27:00.610 --> 00:27:00.620
sensors the robots have are noisy so
 

00:27:00.620 --> 00:27:02.080
sensors the robots have are noisy so
when you have little frames reflecting a

00:27:02.080 --> 00:27:02.090
when you have little frames reflecting a
 

00:27:02.090 --> 00:27:04.750
when you have little frames reflecting a
little bit of light that's noise if we

00:27:04.750 --> 00:27:04.760
little bit of light that's noise if we
 

00:27:04.760 --> 00:27:07.240
little bit of light that's noise if we
were to actually see the bicycles we'd

00:27:07.240 --> 00:27:07.250
were to actually see the bicycles we'd
 

00:27:07.250 --> 00:27:09.009
were to actually see the bicycles we'd
be on a part of the curve that Eric

00:27:09.009 --> 00:27:09.019
be on a part of the curve that Eric
 

00:27:09.019 --> 00:27:10.750
be on a part of the curve that Eric
showed where we'd have a huge number of

00:27:10.750 --> 00:27:10.760
showed where we'd have a huge number of
 

00:27:10.760 --> 00:27:12.820
showed where we'd have a huge number of
false positives so we avoid that by

00:27:12.820 --> 00:27:12.830
false positives so we avoid that by
 

00:27:12.830 --> 00:27:15.070
false positives so we avoid that by
hoping to see their legs but that means

00:27:15.070 --> 00:27:15.080
hoping to see their legs but that means
 

00:27:15.080 --> 00:27:18.159
hoping to see their legs but that means
person walking with a bicycle is walking

00:27:18.159 --> 00:27:18.169
person walking with a bicycle is walking
 

00:27:18.169 --> 00:27:20.110
person walking with a bicycle is walking
with an invisible stick and that's a

00:27:20.110 --> 00:27:20.120
with an invisible stick and that's a
 

00:27:20.120 --> 00:27:23.649
with an invisible stick and that's a
problem so these are all true examples

00:27:23.649 --> 00:27:23.659
problem so these are all true examples
 

00:27:23.659 --> 00:27:26.080
problem so these are all true examples
and I want us to put on our physicians

00:27:26.080 --> 00:27:26.090
and I want us to put on our physicians
 

00:27:26.090 --> 00:27:28.629
and I want us to put on our physicians
hats and be a physician for a second and

00:27:28.629 --> 00:27:28.639
hats and be a physician for a second and
 

00:27:28.639 --> 00:27:30.610
hats and be a physician for a second and
say that these are symptoms and the

00:27:30.610 --> 00:27:30.620
say that these are symptoms and the
 

00:27:30.620 --> 00:27:32.200
say that these are symptoms and the
question I want to ask is what are these

00:27:32.200 --> 00:27:32.210
question I want to ask is what are these
 

00:27:32.210 --> 00:27:34.720
question I want to ask is what are these
the symptoms of and I have a kind of

00:27:34.720 --> 00:27:34.730
the symptoms of and I have a kind of
 

00:27:34.730 --> 00:27:36.580
the symptoms of and I have a kind of
hypothetical proposition for you about

00:27:36.580 --> 00:27:36.590
hypothetical proposition for you about
 

00:27:36.590 --> 00:27:38.919
hypothetical proposition for you about
what these are because I believe these

00:27:38.919 --> 00:27:38.929
what these are because I believe these
 

00:27:38.929 --> 00:27:40.720
what these are because I believe these
are all symptoms of one thing and

00:27:40.720 --> 00:27:40.730
are all symptoms of one thing and
 

00:27:40.730 --> 00:27:42.879
are all symptoms of one thing and
they're one odd thing that I don't think

00:27:42.879 --> 00:27:42.889
they're one odd thing that I don't think
 

00:27:42.889 --> 00:27:44.730
they're one odd thing that I don't think
we've spent enough time talking about I

00:27:44.730 --> 00:27:44.740
we've spent enough time talking about I
 

00:27:44.740 --> 00:27:47.580
we've spent enough time talking about I
believe these are symptoms of alienation

00:27:47.580 --> 00:27:47.590
believe these are symptoms of alienation
 

00:27:47.590 --> 00:27:49.990
believe these are symptoms of alienation
we're creating a world in which we are

00:27:49.990 --> 00:27:50.000
we're creating a world in which we are
 

00:27:50.000 --> 00:27:52.629
we're creating a world in which we are
alienating ourselves from the reality

00:27:52.629 --> 00:27:52.639
alienating ourselves from the reality
 

00:27:52.639 --> 00:27:54.850
alienating ourselves from the reality
we're constructing and there's three

00:27:54.850 --> 00:27:54.860
we're constructing and there's three
 

00:27:54.860 --> 00:27:56.470
we're constructing and there's three
ways in which I believe we're doing this

00:27:56.470 --> 00:27:56.480
ways in which I believe we're doing this
 

00:27:56.480 --> 00:27:58.600
ways in which I believe we're doing this
alienation I want to talk about that now

00:27:58.600 --> 00:27:58.610
alienation I want to talk about that now
 

00:27:58.610 --> 00:28:00.399
alienation I want to talk about that now
the first one relates to robotics itself

00:28:00.399 --> 00:28:00.409
the first one relates to robotics itself
 

00:28:00.409 --> 00:28:03.100
the first one relates to robotics itself
AI and robotics fundamentally was born

00:28:03.100 --> 00:28:03.110
AI and robotics fundamentally was born
 

00:28:03.110 --> 00:28:06.490
AI and robotics fundamentally was born
out of the desire to do mimesis to mimic

00:28:06.490 --> 00:28:06.500
out of the desire to do mimesis to mimic
 

00:28:06.500 --> 00:28:08.409
out of the desire to do mimesis to mimic
humanity it was all about this question

00:28:08.409 --> 00:28:08.419
humanity it was all about this question
 

00:28:08.419 --> 00:28:10.269
humanity it was all about this question
of what makes us tick and how do we

00:28:10.269 --> 00:28:10.279
of what makes us tick and how do we
 

00:28:10.279 --> 00:28:12.669
of what makes us tick and how do we
cognitively create systems that tick the

00:28:12.669 --> 00:28:12.679
cognitively create systems that tick the
 

00:28:12.679 --> 00:28:16.269
cognitively create systems that tick the
way we do how do we replicate the human

00:28:16.269 --> 00:28:16.279
way we do how do we replicate the human
 

00:28:16.279 --> 00:28:19.750
way we do how do we replicate the human
miracle in machine form and that's

00:28:19.750 --> 00:28:19.760
miracle in machine form and that's
 

00:28:19.760 --> 00:28:22.870
miracle in machine form and that's
mimesis it's a one-to-one replacement of

00:28:22.870 --> 00:28:22.880
mimesis it's a one-to-one replacement of
 

00:28:22.880 --> 00:28:24.909
mimesis it's a one-to-one replacement of
the human intelligence with something

00:28:24.909 --> 00:28:24.919
the human intelligence with something
 

00:28:24.919 --> 00:28:26.620
the human intelligence with something
new and maybe that's why they called it

00:28:26.620 --> 00:28:26.630
new and maybe that's why they called it
 

00:28:26.630 --> 00:28:28.810
new and maybe that's why they called it
AI which I agree 100% with Eric is kind

00:28:28.810 --> 00:28:28.820
AI which I agree 100% with Eric is kind
 

00:28:28.820 --> 00:28:30.940
AI which I agree 100% with Eric is kind
of a bad name for it the word artificial

00:28:30.940 --> 00:28:30.950
of a bad name for it the word artificial
 

00:28:30.950 --> 00:28:34.289
of a bad name for it the word artificial
throws us off

00:28:34.289 --> 00:28:34.299
 

00:28:34.299 --> 00:28:36.399
fundamentally the first form of

00:28:36.399 --> 00:28:36.409
fundamentally the first form of
 

00:28:36.409 --> 00:28:37.720
fundamentally the first form of
alienation I'm going to talk about is

00:28:37.720 --> 00:28:37.730
alienation I'm going to talk about is
 

00:28:37.730 --> 00:28:40.450
alienation I'm going to talk about is
the alienation from mimesis itself AI

00:28:40.450 --> 00:28:40.460
the alienation from mimesis itself AI
 

00:28:40.460 --> 00:28:42.549
the alienation from mimesis itself AI
the reality what it is today

00:28:42.549 --> 00:28:42.559
the reality what it is today
 

00:28:42.559 --> 00:28:46.000
the reality what it is today
has alienated us from that very idea of

00:28:46.000 --> 00:28:46.010
has alienated us from that very idea of
 

00:28:46.010 --> 00:28:49.149
has alienated us from that very idea of
a one-to-one relationship or one to one

00:28:49.149 --> 00:28:49.159
a one-to-one relationship or one to one
 

00:28:49.159 --> 00:28:51.730
a one-to-one relationship or one to one
replacement hypothesis from person to

00:28:51.730 --> 00:28:51.740
replacement hypothesis from person to
 

00:28:51.740 --> 00:28:54.159
replacement hypothesis from person to
artificial person we don't aren't making

00:28:54.159 --> 00:28:54.169
artificial person we don't aren't making
 

00:28:54.169 --> 00:28:56.800
artificial person we don't aren't making
artificial people by any stretch

00:28:56.800 --> 00:28:56.810
artificial people by any stretch
 

00:28:56.810 --> 00:28:58.560
artificial people by any stretch
in fact if I look at the most successful

00:28:58.560 --> 00:28:58.570
in fact if I look at the most successful
 

00:28:58.570 --> 00:29:02.140
in fact if I look at the most successful
AI systems today that I boast about and

00:29:02.140 --> 00:29:02.150
AI systems today that I boast about and
 

00:29:02.150 --> 00:29:04.390
AI systems today that I boast about and
I am proud of they have nothing to do

00:29:04.390 --> 00:29:04.400
I am proud of they have nothing to do
 

00:29:04.400 --> 00:29:06.220
I am proud of they have nothing to do
with people they don't work like people

00:29:06.220 --> 00:29:06.230
with people they don't work like people
 

00:29:06.230 --> 00:29:07.930
with people they don't work like people
they don't smell like people they don't

00:29:07.930 --> 00:29:07.940
they don't smell like people they don't
 

00:29:07.940 --> 00:29:09.760
they don't smell like people they don't
behave like people but they solve world

00:29:09.760 --> 00:29:09.770
behave like people but they solve world
 

00:29:09.770 --> 00:29:11.350
behave like people but they solve world
problems I'm gonna give you two quick

00:29:11.350 --> 00:29:11.360
problems I'm gonna give you two quick
 

00:29:11.360 --> 00:29:13.270
problems I'm gonna give you two quick
examples to give you a sense of how

00:29:13.270 --> 00:29:13.280
examples to give you a sense of how
 

00:29:13.280 --> 00:29:14.920
examples to give you a sense of how
different these systems are how

00:29:14.920 --> 00:29:14.930
different these systems are how
 

00:29:14.930 --> 00:29:18.000
different these systems are how
alienated from human mimesis first

00:29:18.000 --> 00:29:18.010
alienated from human mimesis first
 

00:29:18.010 --> 00:29:20.920
alienated from human mimesis first
system I love done by Steve Smith right

00:29:20.920 --> 00:29:20.930
system I love done by Steve Smith right
 

00:29:20.930 --> 00:29:23.590
system I love done by Steve Smith right
here in Carnegie Mellon University East

00:29:23.590 --> 00:29:23.600
here in Carnegie Mellon University East
 

00:29:23.600 --> 00:29:25.960
here in Carnegie Mellon University East
Liberty all the traffic lights in this

00:29:25.960 --> 00:29:25.970
Liberty all the traffic lights in this
 

00:29:25.970 --> 00:29:27.850
Liberty all the traffic lights in this
neighborhood have cameras on them now

00:29:27.850 --> 00:29:27.860
neighborhood have cameras on them now
 

00:29:27.860 --> 00:29:31.060
neighborhood have cameras on them now
and instead of having regular metric

00:29:31.060 --> 00:29:31.070
and instead of having regular metric
 

00:29:31.070 --> 00:29:33.280
and instead of having regular metric
counters that decide how long the green

00:29:33.280 --> 00:29:33.290
counters that decide how long the green
 

00:29:33.290 --> 00:29:35.650
counters that decide how long the green
light red light episodes last these

00:29:35.650 --> 00:29:35.660
light red light episodes last these
 

00:29:35.660 --> 00:29:37.330
light red light episodes last these
cameras look at pedestrians and they

00:29:37.330 --> 00:29:37.340
cameras look at pedestrians and they
 

00:29:37.340 --> 00:29:39.760
cameras look at pedestrians and they
look at cars and they optimize

00:29:39.760 --> 00:29:39.770
look at cars and they optimize
 

00:29:39.770 --> 00:29:41.950
look at cars and they optimize
beautifully across a network of dozens

00:29:41.950 --> 00:29:41.960
beautifully across a network of dozens
 

00:29:41.960 --> 00:29:44.890
beautifully across a network of dozens
of lights the exact pacing of the red

00:29:44.890 --> 00:29:44.900
of lights the exact pacing of the red
 

00:29:44.900 --> 00:29:46.270
of lights the exact pacing of the red
and green lights in such a way as to

00:29:46.270 --> 00:29:46.280
and green lights in such a way as to
 

00:29:46.280 --> 00:29:49.210
and green lights in such a way as to
minimize idle time in cars and maximize

00:29:49.210 --> 00:29:49.220
minimize idle time in cars and maximize
 

00:29:49.220 --> 00:29:51.400
minimize idle time in cars and maximize
pedestrian throughput which you get is

00:29:51.400 --> 00:29:51.410
pedestrian throughput which you get is
 

00:29:51.410 --> 00:29:53.980
pedestrian throughput which you get is
much much faster pedestrian walking and

00:29:53.980 --> 00:29:53.990
much much faster pedestrian walking and
 

00:29:53.990 --> 00:29:56.200
much much faster pedestrian walking and
much much less particulate matter in the

00:29:56.200 --> 00:29:56.210
much much less particulate matter in the
 

00:29:56.210 --> 00:29:58.330
much much less particulate matter in the
air from idling it actually works

00:29:58.330 --> 00:29:58.340
air from idling it actually works
 

00:29:58.340 --> 00:30:00.370
air from idling it actually works
something extraordinary like I think 40

00:30:00.370 --> 00:30:00.380
something extraordinary like I think 40
 

00:30:00.380 --> 00:30:02.280
something extraordinary like I think 40
percent reduction in local pollution

00:30:02.280 --> 00:30:02.290
percent reduction in local pollution
 

00:30:02.290 --> 00:30:04.980
percent reduction in local pollution
just from idling of cars I mean

00:30:04.980 --> 00:30:04.990
just from idling of cars I mean
 

00:30:04.990 --> 00:30:07.780
just from idling of cars I mean
ridiculously cool results but this is an

00:30:07.780 --> 00:30:07.790
ridiculously cool results but this is an
 

00:30:07.790 --> 00:30:09.600
ridiculously cool results but this is an
intelligent network of cameras

00:30:09.600 --> 00:30:09.610
intelligent network of cameras
 

00:30:09.610 --> 00:30:11.980
intelligent network of cameras
responsive to people and pedestrians is

00:30:11.980 --> 00:30:11.990
responsive to people and pedestrians is
 

00:30:11.990 --> 00:30:14.470
responsive to people and pedestrians is
that a human is it replacing a human job

00:30:14.470 --> 00:30:14.480
that a human is it replacing a human job
 

00:30:14.480 --> 00:30:16.570
that a human is it replacing a human job
no it has nothing to do with any task

00:30:16.570 --> 00:30:16.580
no it has nothing to do with any task
 

00:30:16.580 --> 00:30:17.740
no it has nothing to do with any task
that a human had been sitting there

00:30:17.740 --> 00:30:17.750
that a human had been sitting there
 

00:30:17.750 --> 00:30:19.840
that a human had been sitting there
doing there are no no MS sitting there

00:30:19.840 --> 00:30:19.850
doing there are no no MS sitting there
 

00:30:19.850 --> 00:30:21.730
doing there are no no MS sitting there
hitting lights turning lights green and

00:30:21.730 --> 00:30:21.740
hitting lights turning lights green and
 

00:30:21.740 --> 00:30:24.460
hitting lights turning lights green and
red this is a whole new category of

00:30:24.460 --> 00:30:24.470
red this is a whole new category of
 

00:30:24.470 --> 00:30:26.230
red this is a whole new category of
action I'll give you one more example

00:30:26.230 --> 00:30:26.240
action I'll give you one more example
 

00:30:26.240 --> 00:30:28.480
action I'll give you one more example
that comes out of the old lab of Jeff

00:30:28.480 --> 00:30:28.490
that comes out of the old lab of Jeff
 

00:30:28.490 --> 00:30:29.710
that comes out of the old lab of Jeff
Schneider and a number of other people

00:30:29.710 --> 00:30:29.720
Schneider and a number of other people
 

00:30:29.720 --> 00:30:32.230
Schneider and a number of other people
at Carnegie Mellon which is the ability

00:30:32.230 --> 00:30:32.240
at Carnegie Mellon which is the ability
 

00:30:32.240 --> 00:30:34.770
at Carnegie Mellon which is the ability
to do behavioral analytics to discover

00:30:34.770 --> 00:30:34.780
to do behavioral analytics to discover
 

00:30:34.780 --> 00:30:37.300
to do behavioral analytics to discover
dangerous situations they did a very

00:30:37.300 --> 00:30:37.310
dangerous situations they did a very
 

00:30:37.310 --> 00:30:38.920
dangerous situations they did a very
famous piece of work about seven years

00:30:38.920 --> 00:30:38.930
famous piece of work about seven years
 

00:30:38.930 --> 00:30:41.320
famous piece of work about seven years
ago looking at purchasing habits in drug

00:30:41.320 --> 00:30:41.330
ago looking at purchasing habits in drug
 

00:30:41.330 --> 00:30:43.150
ago looking at purchasing habits in drug
stores and they were able to create

00:30:43.150 --> 00:30:43.160
stores and they were able to create
 

00:30:43.160 --> 00:30:46.000
stores and they were able to create
systems that can in advance predict the

00:30:46.000 --> 00:30:46.010
systems that can in advance predict the
 

00:30:46.010 --> 00:30:47.800
systems that can in advance predict the
onset of pandemics in the United States

00:30:47.800 --> 00:30:47.810
onset of pandemics in the United States
 

00:30:47.810 --> 00:30:51.520
onset of pandemics in the United States
like the cold virus by changes in

00:30:51.520 --> 00:30:51.530
like the cold virus by changes in
 

00:30:51.530 --> 00:30:53.050
like the cold virus by changes in
purchasing habits in drug stores

00:30:53.050 --> 00:30:53.060
purchasing habits in drug stores
 

00:30:53.060 --> 00:30:55.960
purchasing habits in drug stores
there was nobody doing that at the CDC

00:30:55.960 --> 00:30:55.970
there was nobody doing that at the CDC
 

00:30:55.970 --> 00:30:56.860
there was nobody doing that at the CDC
like that

00:30:56.860 --> 00:30:56.870
like that
 

00:30:56.870 --> 00:30:58.420
like that
because it couldn't be done it's a big

00:30:58.420 --> 00:30:58.430
because it couldn't be done it's a big
 

00:30:58.430 --> 00:31:00.100
because it couldn't be done it's a big
data analytics problem and they did it

00:31:00.100 --> 00:31:00.110
data analytics problem and they did it
 

00:31:00.110 --> 00:31:02.350
data analytics problem and they did it
and it took the same system and today

00:31:02.350 --> 00:31:02.360
and it took the same system and today
 

00:31:02.360 --> 00:31:04.420
and it took the same system and today
they use it for human sex trafficking so

00:31:04.420 --> 00:31:04.430
they use it for human sex trafficking so
 

00:31:04.430 --> 00:31:06.460
they use it for human sex trafficking so
they're able to actually find elements

00:31:06.460 --> 00:31:06.470
they're able to actually find elements
 

00:31:06.470 --> 00:31:07.630
they're able to actually find elements
of human sex trafficking around the

00:31:07.630 --> 00:31:07.640
of human sex trafficking around the
 

00:31:07.640 --> 00:31:10.240
of human sex trafficking around the
world by simply taking all of the

00:31:10.240 --> 00:31:10.250
world by simply taking all of the
 

00:31:10.250 --> 00:31:10.600
world by simply taking all of the
community

00:31:10.600 --> 00:31:10.610
community
 

00:31:10.610 --> 00:31:12.310
community
Media in the internet and analyzing the

00:31:12.310 --> 00:31:12.320
Media in the internet and analyzing the
 

00:31:12.320 --> 00:31:14.350
Media in the internet and analyzing the
massive speed that does not replace

00:31:14.350 --> 00:31:14.360
massive speed that does not replace
 

00:31:14.360 --> 00:31:16.840
massive speed that does not replace
anybody who's doing that work that way

00:31:16.840 --> 00:31:16.850
anybody who's doing that work that way
 

00:31:16.850 --> 00:31:19.900
anybody who's doing that work that way
instead it's not mimesis but a whole new

00:31:19.900 --> 00:31:19.910
instead it's not mimesis but a whole new
 

00:31:19.910 --> 00:31:21.669
instead it's not mimesis but a whole new
way of thinking about computational

00:31:21.669 --> 00:31:21.679
way of thinking about computational
 

00:31:21.679 --> 00:31:23.490
way of thinking about computational
intelligence applied to a real problem

00:31:23.490 --> 00:31:23.500
intelligence applied to a real problem
 

00:31:23.500 --> 00:31:26.410
intelligence applied to a real problem
now the second problem the second kind

00:31:26.410 --> 00:31:26.420
now the second problem the second kind
 

00:31:26.420 --> 00:31:28.660
now the second problem the second kind
of alienation alienation from failure

00:31:28.660 --> 00:31:28.670
of alienation alienation from failure
 

00:31:28.670 --> 00:31:31.870
of alienation alienation from failure
and this is a really big problem we have

00:31:31.870 --> 00:31:31.880
and this is a really big problem we have
 

00:31:31.880 --> 00:31:33.940
and this is a really big problem we have
an intuition for how humans fail and

00:31:33.940 --> 00:31:33.950
an intuition for how humans fail and
 

00:31:33.950 --> 00:31:35.980
an intuition for how humans fail and
with natural intelligence we understand

00:31:35.980 --> 00:31:35.990
with natural intelligence we understand
 

00:31:35.990 --> 00:31:37.419
with natural intelligence we understand
what failure looks like and what success

00:31:37.419 --> 00:31:37.429
what failure looks like and what success
 

00:31:37.429 --> 00:31:39.340
what failure looks like and what success
looks like and I just explained to you

00:31:39.340 --> 00:31:39.350
looks like and I just explained to you
 

00:31:39.350 --> 00:31:40.750
looks like and I just explained to you
success does not look anything like

00:31:40.750 --> 00:31:40.760
success does not look anything like
 

00:31:40.760 --> 00:31:42.970
success does not look anything like
human success in the regime of robots

00:31:42.970 --> 00:31:42.980
human success in the regime of robots
 

00:31:42.980 --> 00:31:45.520
human success in the regime of robots
and AI but guess what failure looks

00:31:45.520 --> 00:31:45.530
and AI but guess what failure looks
 

00:31:45.530 --> 00:31:47.140
and AI but guess what failure looks
nothing like human failure either and

00:31:47.140 --> 00:31:47.150
nothing like human failure either and
 

00:31:47.150 --> 00:31:49.960
nothing like human failure either and
yet we have biases that make us try and

00:31:49.960 --> 00:31:49.970
yet we have biases that make us try and
 

00:31:49.970 --> 00:31:53.080
yet we have biases that make us try and
suit the the robot failure into the

00:31:53.080 --> 00:31:53.090
suit the the robot failure into the
 

00:31:53.090 --> 00:31:54.909
suit the the robot failure into the
close of human failure I'll give you a

00:31:54.909 --> 00:31:54.919
close of human failure I'll give you a
 

00:31:54.919 --> 00:31:56.230
close of human failure I'll give you a
couple of examples from two friends of

00:31:56.230 --> 00:31:56.240
couple of examples from two friends of
 

00:31:56.240 --> 00:31:58.090
couple of examples from two friends of
mine Sewer Russell has an example he

00:31:58.090 --> 00:31:58.100
mine Sewer Russell has an example he
 

00:31:58.100 --> 00:31:59.710
mine Sewer Russell has an example he
uses he shows a picture and in the

00:31:59.710 --> 00:31:59.720
uses he shows a picture and in the
 

00:31:59.720 --> 00:32:02.590
uses he shows a picture and in the
picture there's some people and there's

00:32:02.590 --> 00:32:02.600
picture there's some people and there's
 

00:32:02.600 --> 00:32:05.919
picture there's some people and there's
a market and he uses one of the online

00:32:05.919 --> 00:32:05.929
a market and he uses one of the online
 

00:32:05.929 --> 00:32:07.900
a market and he uses one of the online
image analysis tools and it spits out a

00:32:07.900 --> 00:32:07.910
image analysis tools and it spits out a
 

00:32:07.910 --> 00:32:09.669
image analysis tools and it spits out a
sentence it says a group of people

00:32:09.669 --> 00:32:09.679
sentence it says a group of people
 

00:32:09.679 --> 00:32:11.230
sentence it says a group of people
buying vegetables at a fruit stand and

00:32:11.230 --> 00:32:11.240
buying vegetables at a fruit stand and
 

00:32:11.240 --> 00:32:13.000
buying vegetables at a fruit stand and
the people in the onions look at this

00:32:13.000 --> 00:32:13.010
the people in the onions look at this
 

00:32:13.010 --> 00:32:15.669
the people in the onions look at this
and go wow that's awesome that AI system

00:32:15.669 --> 00:32:15.679
and go wow that's awesome that AI system
 

00:32:15.679 --> 00:32:16.720
and go wow that's awesome that AI system
really knows what's going on in that

00:32:16.720 --> 00:32:16.730
really knows what's going on in that
 

00:32:16.730 --> 00:32:19.000
really knows what's going on in that
picture then you zoom in on the picture

00:32:19.000 --> 00:32:19.010
picture then you zoom in on the picture
 

00:32:19.010 --> 00:32:20.980
picture then you zoom in on the picture
there's no group of people it's one

00:32:20.980 --> 00:32:20.990
there's no group of people it's one
 

00:32:20.990 --> 00:32:23.530
there's no group of people it's one
person there's no fruit stand it's a

00:32:23.530 --> 00:32:23.540
person there's no fruit stand it's a
 

00:32:23.540 --> 00:32:26.650
person there's no fruit stand it's a
bunch of green leaves and yet to you the

00:32:26.650 --> 00:32:26.660
bunch of green leaves and yet to you the
 

00:32:26.660 --> 00:32:28.000
bunch of green leaves and yet to you the
human observer when you look at that

00:32:28.000 --> 00:32:28.010
human observer when you look at that
 

00:32:28.010 --> 00:32:28.930
human observer when you look at that
picture you love it

00:32:28.930 --> 00:32:28.940
picture you love it
 

00:32:28.940 --> 00:32:31.510
picture you love it
rod Brooks doesn't even better one he

00:32:31.510 --> 00:32:31.520
rod Brooks doesn't even better one he
 

00:32:31.520 --> 00:32:34.870
rod Brooks doesn't even better one he
shows a picture and the computer says a

00:32:34.870 --> 00:32:34.880
shows a picture and the computer says a
 

00:32:34.880 --> 00:32:36.100
shows a picture and the computer says a
group of children playing frisbee on

00:32:36.100 --> 00:32:36.110
group of children playing frisbee on
 

00:32:36.110 --> 00:32:40.350
group of children playing frisbee on
grass and then he asks the same system

00:32:40.350 --> 00:32:40.360
grass and then he asks the same system
 

00:32:40.360 --> 00:32:42.010
grass and then he asks the same system
because it is a group of children

00:32:42.010 --> 00:32:42.020
because it is a group of children
 

00:32:42.020 --> 00:32:43.120
because it is a group of children
playing frisbee on grass that one

00:32:43.120 --> 00:32:43.130
playing frisbee on grass that one
 

00:32:43.130 --> 00:32:45.220
playing frisbee on grass that one
actually gets it right so then he asked

00:32:45.220 --> 00:32:45.230
actually gets it right so then he asked
 

00:32:45.230 --> 00:32:47.440
actually gets it right so then he asked
the system so can six months olds play

00:32:47.440 --> 00:32:47.450
the system so can six months olds play
 

00:32:47.450 --> 00:32:50.110
the system so can six months olds play
frisbee it has no idea do frisbees taste

00:32:50.110 --> 00:32:50.120
frisbee it has no idea do frisbees taste
 

00:32:50.120 --> 00:32:53.380
frisbee it has no idea do frisbees taste
good no clue how far do fizz bees fly no

00:32:53.380 --> 00:32:53.390
good no clue how far do fizz bees fly no
 

00:32:53.390 --> 00:32:57.010
good no clue how far do fizz bees fly no
idea that sentence is there because a

00:32:57.010 --> 00:32:57.020
idea that sentence is there because a
 

00:32:57.020 --> 00:32:59.080
idea that sentence is there because a
statistical analysis that made that

00:32:59.080 --> 00:32:59.090
statistical analysis that made that
 

00:32:59.090 --> 00:33:01.240
statistical analysis that made that
sentence a construct associated with

00:33:01.240 --> 00:33:01.250
sentence a construct associated with
 

00:33:01.250 --> 00:33:03.250
sentence a construct associated with
that picture it doesn't mean that the

00:33:03.250 --> 00:33:03.260
that picture it doesn't mean that the
 

00:33:03.260 --> 00:33:04.600
that picture it doesn't mean that the
computer has any clue what any of the

00:33:04.600 --> 00:33:04.610
computer has any clue what any of the
 

00:33:04.610 --> 00:33:06.400
computer has any clue what any of the
individuated words in the sentence mean

00:33:06.400 --> 00:33:06.410
individuated words in the sentence mean
 

00:33:06.410 --> 00:33:08.560
individuated words in the sentence mean
or what the semantics of that sentence

00:33:08.560 --> 00:33:08.570
or what the semantics of that sentence
 

00:33:08.570 --> 00:33:11.080
or what the semantics of that sentence
are in that particular case and maybe it

00:33:11.080 --> 00:33:11.090
are in that particular case and maybe it
 

00:33:11.090 --> 00:33:13.120
are in that particular case and maybe it
does and maybe it doesn't but we the

00:33:13.120 --> 00:33:13.130
does and maybe it doesn't but we the
 

00:33:13.130 --> 00:33:15.370
does and maybe it doesn't but we the
observers have no idea if it does or it

00:33:15.370 --> 00:33:15.380
observers have no idea if it does or it
 

00:33:15.380 --> 00:33:17.950
observers have no idea if it does or it
doesn't and yet our failing as humans is

00:33:17.950 --> 00:33:17.960
doesn't and yet our failing as humans is
 

00:33:17.960 --> 00:33:20.490
doesn't and yet our failing as humans is
to imbue upon that computer meaning

00:33:20.490 --> 00:33:20.500
to imbue upon that computer meaning
 

00:33:20.500 --> 00:33:22.480
to imbue upon that computer meaning
because it's using human language so

00:33:22.480 --> 00:33:22.490
because it's using human language so
 

00:33:22.490 --> 00:33:24.520
because it's using human language so
certainly it understands same problem I

00:33:24.520 --> 00:33:24.530
certainly it understands same problem I
 

00:33:24.530 --> 00:33:26.140
certainly it understands same problem I
have with my colleagues who put eyes and

00:33:26.140 --> 00:33:26.150
have with my colleagues who put eyes and
 

00:33:26.150 --> 00:33:28.570
have with my colleagues who put eyes and
ears and a smile on their robot and then

00:33:28.570 --> 00:33:28.580
ears and a smile on their robot and then
 

00:33:28.580 --> 00:33:30.610
ears and a smile on their robot and then
when it smiles you in view upon it

00:33:30.610 --> 00:33:30.620
when it smiles you in view upon it
 

00:33:30.620 --> 00:33:33.970
when it smiles you in view upon it
effect when that effect is literally

00:33:33.970 --> 00:33:33.980
effect when that effect is literally
 

00:33:33.980 --> 00:33:36.970
effect when that effect is literally
Hollywood so that's the second kind of

00:33:36.970 --> 00:33:36.980
Hollywood so that's the second kind of
 

00:33:36.980 --> 00:33:39.880
Hollywood so that's the second kind of
failure alienation from failure the last

00:33:39.880 --> 00:33:39.890
failure alienation from failure the last
 

00:33:39.890 --> 00:33:42.780
failure alienation from failure the last
one is actually the worst one in a way

00:33:42.780 --> 00:33:42.790
one is actually the worst one in a way
 

00:33:42.790 --> 00:33:46.419
one is actually the worst one in a way
when I got my PhD we used to deal a lot

00:33:46.419 --> 00:33:46.429
when I got my PhD we used to deal a lot
 

00:33:46.429 --> 00:33:47.650
when I got my PhD we used to deal a lot
with something called non monotonic

00:33:47.650 --> 00:33:47.660
with something called non monotonic
 

00:33:47.660 --> 00:33:49.690
with something called non monotonic
reasoning humans make assumptions to

00:33:49.690 --> 00:33:49.700
reasoning humans make assumptions to
 

00:33:49.700 --> 00:33:51.640
reasoning humans make assumptions to
make the world something we can deal

00:33:51.640 --> 00:33:51.650
make the world something we can deal
 

00:33:51.650 --> 00:33:54.130
make the world something we can deal
with we ignore irrelevant detail and

00:33:54.130 --> 00:33:54.140
with we ignore irrelevant detail and
 

00:33:54.140 --> 00:33:56.020
with we ignore irrelevant detail and
think about relevant detail and then we

00:33:56.020 --> 00:33:56.030
think about relevant detail and then we
 

00:33:56.030 --> 00:33:57.100
think about relevant detail and then we
change our minds if something becomes

00:33:57.100 --> 00:33:57.110
change our minds if something becomes
 

00:33:57.110 --> 00:33:58.330
change our minds if something becomes
relevant that we thought was irrelevant

00:33:58.330 --> 00:33:58.340
relevant that we thought was irrelevant
 

00:33:58.340 --> 00:34:00.460
relevant that we thought was irrelevant
like oh my car's not starting and I'm

00:34:00.460 --> 00:34:00.470
like oh my car's not starting and I'm
 

00:34:00.470 --> 00:34:01.570
like oh my car's not starting and I'm
late for an appointment now I have to

00:34:01.570 --> 00:34:01.580
late for an appointment now I have to
 

00:34:01.580 --> 00:34:02.890
late for an appointment now I have to
start worrying about my car not starting

00:34:02.890 --> 00:34:02.900
start worrying about my car not starting
 

00:34:02.900 --> 00:34:04.780
start worrying about my car not starting
but I don't spend all morning worrying

00:34:04.780 --> 00:34:04.790
but I don't spend all morning worrying
 

00:34:04.790 --> 00:34:06.460
but I don't spend all morning worrying
about that until it becomes a real thing

00:34:06.460 --> 00:34:06.470
about that until it becomes a real thing
 

00:34:06.470 --> 00:34:09.760
about that until it becomes a real thing
so we sometimes call that things like

00:34:09.760 --> 00:34:09.770
so we sometimes call that things like
 

00:34:09.770 --> 00:34:11.139
so we sometimes call that things like
the closed world assumption we make an

00:34:11.139 --> 00:34:11.149
the closed world assumption we make an
 

00:34:11.149 --> 00:34:12.520
the closed world assumption we make an
assumption that the world is what it is

00:34:12.520 --> 00:34:12.530
assumption that the world is what it is
 

00:34:12.530 --> 00:34:14.320
assumption that the world is what it is
and it's kind of static until we have to

00:34:14.320 --> 00:34:14.330
and it's kind of static until we have to
 

00:34:14.330 --> 00:34:16.450
and it's kind of static until we have to
change our mind well the problem is we

00:34:16.450 --> 00:34:16.460
change our mind well the problem is we
 

00:34:16.460 --> 00:34:17.649
change our mind well the problem is we
make that assumption about technology

00:34:17.649 --> 00:34:17.659
make that assumption about technology
 

00:34:17.659 --> 00:34:20.200
make that assumption about technology
when I see the boundaries of efficacy

00:34:20.200 --> 00:34:20.210
when I see the boundaries of efficacy
 

00:34:20.210 --> 00:34:22.359
when I see the boundaries of efficacy
that a computer has I assume that's what

00:34:22.359 --> 00:34:22.369
that a computer has I assume that's what
 

00:34:22.369 --> 00:34:23.710
that a computer has I assume that's what
a computer can do that's what AI is

00:34:23.710 --> 00:34:23.720
a computer can do that's what AI is
 

00:34:23.720 --> 00:34:25.599
a computer can do that's what AI is
capable of and I will always be wrong

00:34:25.599 --> 00:34:25.609
capable of and I will always be wrong
 

00:34:25.609 --> 00:34:28.210
capable of and I will always be wrong
because AI is dynamic it is not static

00:34:28.210 --> 00:34:28.220
because AI is dynamic it is not static
 

00:34:28.220 --> 00:34:30.190
because AI is dynamic it is not static
and what it can do tomorrow is different

00:34:30.190 --> 00:34:30.200
and what it can do tomorrow is different
 

00:34:30.200 --> 00:34:32.290
and what it can do tomorrow is different
from what it can do today and our

00:34:32.290 --> 00:34:32.300
from what it can do today and our
 

00:34:32.300 --> 00:34:36.700
from what it can do today and our
ability as a human populace to make hay

00:34:36.700 --> 00:34:36.710
ability as a human populace to make hay
 

00:34:36.710 --> 00:34:38.500
ability as a human populace to make hay
of that does not exist we don't

00:34:38.500 --> 00:34:38.510
of that does not exist we don't
 

00:34:38.510 --> 00:34:40.419
of that does not exist we don't
understand how to think about a system

00:34:40.419 --> 00:34:40.429
understand how to think about a system
 

00:34:40.429 --> 00:34:41.950
understand how to think about a system
whose capability has changed every day

00:34:41.950 --> 00:34:41.960
whose capability has changed every day
 

00:34:41.960 --> 00:34:44.230
whose capability has changed every day
and that's a fundamental problem is that

00:34:44.230 --> 00:34:44.240
and that's a fundamental problem is that
 

00:34:44.240 --> 00:34:46.149
and that's a fundamental problem is that
we have a static model of a dynamic

00:34:46.149 --> 00:34:46.159
we have a static model of a dynamic
 

00:34:46.159 --> 00:34:50.740
we have a static model of a dynamic
system so diagnosis if we are being

00:34:50.740 --> 00:34:50.750
system so diagnosis if we are being
 

00:34:50.750 --> 00:34:52.840
system so diagnosis if we are being
alienated from this technology in the

00:34:52.840 --> 00:34:52.850
alienated from this technology in the
 

00:34:52.850 --> 00:34:53.500
alienated from this technology in the
case of success

00:34:53.500 --> 00:34:53.510
case of success
 

00:34:53.510 --> 00:34:55.149
case of success
in the case of failure and by our

00:34:55.149 --> 00:34:55.159
in the case of failure and by our
 

00:34:55.159 --> 00:34:57.270
in the case of failure and by our
inability to understand how it's moving

00:34:57.270 --> 00:34:57.280
inability to understand how it's moving
 

00:34:57.280 --> 00:34:59.770
inability to understand how it's moving
what is the diagnosis well the diagnosis

00:34:59.770 --> 00:34:59.780
what is the diagnosis well the diagnosis
 

00:34:59.780 --> 00:35:01.510
what is the diagnosis well the diagnosis
is very simple where AI illiterate and

00:35:01.510 --> 00:35:01.520
is very simple where AI illiterate and
 

00:35:01.520 --> 00:35:03.660
is very simple where AI illiterate and
by we I don't mean the wonderful

00:35:03.660 --> 00:35:03.670
by we I don't mean the wonderful
 

00:35:03.670 --> 00:35:06.940
by we I don't mean the wonderful
lawmakers and colleagues that I have in

00:35:06.940 --> 00:35:06.950
lawmakers and colleagues that I have in
 

00:35:06.950 --> 00:35:08.859
lawmakers and colleagues that I have in
this room I mean the human population I

00:35:08.859 --> 00:35:08.869
this room I mean the human population I
 

00:35:08.869 --> 00:35:10.480
this room I mean the human population I
mean those who have to engage in civic

00:35:10.480 --> 00:35:10.490
mean those who have to engage in civic
 

00:35:10.490 --> 00:35:12.730
mean those who have to engage in civic
discourse nationally internationally so

00:35:12.730 --> 00:35:12.740
discourse nationally internationally so
 

00:35:12.740 --> 00:35:15.640
discourse nationally internationally so
we're a AI literate and it matters now

00:35:15.640 --> 00:35:15.650
we're a AI literate and it matters now
 

00:35:15.650 --> 00:35:17.590
we're a AI literate and it matters now
compared to 20 years ago because AI is

00:35:17.590 --> 00:35:17.600
compared to 20 years ago because AI is
 

00:35:17.600 --> 00:35:19.660
compared to 20 years ago because AI is
actually changing the world to its

00:35:19.660 --> 00:35:19.670
actually changing the world to its
 

00:35:19.670 --> 00:35:22.270
actually changing the world to its
elections to it marketing and all the

00:35:22.270 --> 00:35:22.280
elections to it marketing and all the
 

00:35:22.280 --> 00:35:23.590
elections to it marketing and all the
other ways in which a changes the world

00:35:23.590 --> 00:35:23.600
other ways in which a changes the world
 

00:35:23.600 --> 00:35:25.690
other ways in which a changes the world
and it's funny if you look at you know

00:35:25.690 --> 00:35:25.700
and it's funny if you look at you know
 

00:35:25.700 --> 00:35:28.570
and it's funny if you look at you know
very very fast financial trades they

00:35:28.570 --> 00:35:28.580
very very fast financial trades they
 

00:35:28.580 --> 00:35:29.800
very very fast financial trades they
change the world but at least in a

00:35:29.800 --> 00:35:29.810
change the world but at least in a
 

00:35:29.810 --> 00:35:31.450
change the world but at least in a
little way we were all read about it on

00:35:31.450 --> 00:35:31.460
little way we were all read about it on
 

00:35:31.460 --> 00:35:33.730
little way we were all read about it on
marketplace the difference is these new

00:35:33.730 --> 00:35:33.740
marketplace the difference is these new
 

00:35:33.740 --> 00:35:35.680
marketplace the difference is these new
AI systems they change what humans do on

00:35:35.680 --> 00:35:35.690
AI systems they change what humans do on
 

00:35:35.690 --> 00:35:37.370
AI systems they change what humans do on
mass they change our behavior

00:35:37.370 --> 00:35:37.380
mass they change our behavior
 

00:35:37.380 --> 00:35:39.860
mass they change our behavior
so they're pushing back hard I think the

00:35:39.860 --> 00:35:39.870
so they're pushing back hard I think the
 

00:35:39.870 --> 00:35:42.290
so they're pushing back hard I think the
mistake got made a few years ago when we

00:35:42.290 --> 00:35:42.300
mistake got made a few years ago when we
 

00:35:42.300 --> 00:35:44.360
mistake got made a few years ago when we
invented the phrase stem we really

00:35:44.360 --> 00:35:44.370
invented the phrase stem we really
 

00:35:44.370 --> 00:35:46.340
invented the phrase stem we really
really messed that one up big time we

00:35:46.340 --> 00:35:46.350
really messed that one up big time we
 

00:35:46.350 --> 00:35:48.230
really messed that one up big time we
invented the word stem we said all our

00:35:48.230 --> 00:35:48.240
invented the word stem we said all our
 

00:35:48.240 --> 00:35:50.570
invented the word stem we said all our
kids have to learn stem stem is what

00:35:50.570 --> 00:35:50.580
kids have to learn stem stem is what
 

00:35:50.580 --> 00:35:53.150
kids have to learn stem stem is what
matters and we excluded the humanities

00:35:53.150 --> 00:35:53.160
matters and we excluded the humanities
 

00:35:53.160 --> 00:35:56.330
matters and we excluded the humanities
completely when what ratters is social

00:35:56.330 --> 00:35:56.340
completely when what ratters is social
 

00:35:56.340 --> 00:35:58.970
completely when what ratters is social
science applied to the computer science

00:35:58.970 --> 00:35:58.980
science applied to the computer science
 

00:35:58.980 --> 00:36:00.740
science applied to the computer science
that we do it's the combination of the

00:36:00.740 --> 00:36:00.750
that we do it's the combination of the
 

00:36:00.750 --> 00:36:01.940
that we do it's the combination of the
two that lets us understand the world

00:36:01.940 --> 00:36:01.950
two that lets us understand the world
 

00:36:01.950 --> 00:36:05.000
two that lets us understand the world
and yet stem excluded that divisive lis

00:36:05.000 --> 00:36:05.010
and yet stem excluded that divisive lis
 

00:36:05.010 --> 00:36:07.010
and yet stem excluded that divisive lis
it also took all of these disciplines

00:36:07.010 --> 00:36:07.020
it also took all of these disciplines
 

00:36:07.020 --> 00:36:08.810
it also took all of these disciplines
and created silos for them science

00:36:08.810 --> 00:36:08.820
and created silos for them science
 

00:36:08.820 --> 00:36:10.820
and created silos for them science
technology engineering math as if

00:36:10.820 --> 00:36:10.830
technology engineering math as if
 

00:36:10.830 --> 00:36:12.380
technology engineering math as if
they're individual areas of learning

00:36:12.380 --> 00:36:12.390
they're individual areas of learning
 

00:36:12.390 --> 00:36:14.900
they're individual areas of learning
that we can optimize and then we know

00:36:14.900 --> 00:36:14.910
that we can optimize and then we know
 

00:36:14.910 --> 00:36:17.000
that we can optimize and then we know
what to do and we don't because knowing

00:36:17.000 --> 00:36:17.010
what to do and we don't because knowing
 

00:36:17.010 --> 00:36:19.460
what to do and we don't because knowing
anything about those four alone and not

00:36:19.460 --> 00:36:19.470
anything about those four alone and not
 

00:36:19.470 --> 00:36:21.830
anything about those four alone and not
transdisciplinary doesn't allow us to

00:36:21.830 --> 00:36:21.840
transdisciplinary doesn't allow us to
 

00:36:21.840 --> 00:36:23.990
transdisciplinary doesn't allow us to
understand the changes in robotics so

00:36:23.990 --> 00:36:24.000
understand the changes in robotics so
 

00:36:24.000 --> 00:36:26.690
understand the changes in robotics so
I'm at the final part of my talk I've

00:36:26.690 --> 00:36:26.700
I'm at the final part of my talk I've
 

00:36:26.700 --> 00:36:28.130
I'm at the final part of my talk I've
told you about the problems the

00:36:28.130 --> 00:36:28.140
told you about the problems the
 

00:36:28.140 --> 00:36:30.320
told you about the problems the
questions what's our treatment and I

00:36:30.320 --> 00:36:30.330
questions what's our treatment and I
 

00:36:30.330 --> 00:36:33.080
questions what's our treatment and I
believe our treatment is actually that

00:36:33.080 --> 00:36:33.090
believe our treatment is actually that
 

00:36:33.090 --> 00:36:34.010
believe our treatment is actually that
we have to future-proof

00:36:34.010 --> 00:36:34.020
we have to future-proof
 

00:36:34.020 --> 00:36:36.560
we have to future-proof
ourself to the dynamism of AI itself we

00:36:36.560 --> 00:36:36.570
ourself to the dynamism of AI itself we
 

00:36:36.570 --> 00:36:38.720
ourself to the dynamism of AI itself we
have to future-proof our population to

00:36:38.720 --> 00:36:38.730
have to future-proof our population to
 

00:36:38.730 --> 00:36:40.400
have to future-proof our population to
the idea that artificial intelligence is

00:36:40.400 --> 00:36:40.410
the idea that artificial intelligence is
 

00:36:40.410 --> 00:36:42.530
the idea that artificial intelligence is
a moving entity and that it will change

00:36:42.530 --> 00:36:42.540
a moving entity and that it will change
 

00:36:42.540 --> 00:36:46.790
a moving entity and that it will change
and I'll give you an example Eric talked

00:36:46.790 --> 00:36:46.800
and I'll give you an example Eric talked
 

00:36:46.800 --> 00:36:48.170
and I'll give you an example Eric talked
in his keynote speech yesterday about

00:36:48.170 --> 00:36:48.180
in his keynote speech yesterday about
 

00:36:48.180 --> 00:36:50.270
in his keynote speech yesterday about
not just the fact that these systems

00:36:50.270 --> 00:36:50.280
not just the fact that these systems
 

00:36:50.280 --> 00:36:51.830
not just the fact that these systems
have computational bias but in fact

00:36:51.830 --> 00:36:51.840
have computational bias but in fact
 

00:36:51.840 --> 00:36:54.230
have computational bias but in fact
Microsoft's working on ways to overcome

00:36:54.230 --> 00:36:54.240
Microsoft's working on ways to overcome
 

00:36:54.240 --> 00:36:56.630
Microsoft's working on ways to overcome
that by us that's excellent but I

00:36:56.630 --> 00:36:56.640
that by us that's excellent but I
 

00:36:56.640 --> 00:36:58.940
that by us that's excellent but I
challenge you to show the fluency in the

00:36:58.940 --> 00:36:58.950
challenge you to show the fluency in the
 

00:36:58.950 --> 00:37:00.980
challenge you to show the fluency in the
public to then ask the next question

00:37:00.980 --> 00:37:00.990
public to then ask the next question
 

00:37:00.990 --> 00:37:03.050
public to then ask the next question
which is how will those corrective

00:37:03.050 --> 00:37:03.060
which is how will those corrective
 

00:37:03.060 --> 00:37:05.360
which is how will those corrective
techniques be tested and audited how

00:37:05.360 --> 00:37:05.370
techniques be tested and audited how
 

00:37:05.370 --> 00:37:06.440
techniques be tested and audited how
will we know if they work or not

00:37:06.440 --> 00:37:06.450
will we know if they work or not
 

00:37:06.450 --> 00:37:08.300
will we know if they work or not
how can the public know that they don't

00:37:08.300 --> 00:37:08.310
how can the public know that they don't
 

00:37:08.310 --> 00:37:10.310
how can the public know that they don't
have the literacy the fluency that we

00:37:10.310 --> 00:37:10.320
have the literacy the fluency that we
 

00:37:10.320 --> 00:37:12.320
have the literacy the fluency that we
need for that so fundamentally I think

00:37:12.320 --> 00:37:12.330
need for that so fundamentally I think
 

00:37:12.330 --> 00:37:15.620
need for that so fundamentally I think
we need the same kind of fluency for AI

00:37:15.620 --> 00:37:15.630
we need the same kind of fluency for AI
 

00:37:15.630 --> 00:37:18.260
we need the same kind of fluency for AI
for civic discourse that today we have

00:37:18.260 --> 00:37:18.270
for civic discourse that today we have
 

00:37:18.270 --> 00:37:20.180
for civic discourse that today we have
around say government people know how

00:37:20.180 --> 00:37:20.190
around say government people know how
 

00:37:20.190 --> 00:37:22.820
around say government people know how
the separation of power works in the

00:37:22.820 --> 00:37:22.830
the separation of power works in the
 

00:37:22.830 --> 00:37:24.350
the separation of power works in the
United States they know how elections

00:37:24.350 --> 00:37:24.360
United States they know how elections
 

00:37:24.360 --> 00:37:26.000
United States they know how elections
work they know what the Electoral

00:37:26.000 --> 00:37:26.010
work they know what the Electoral
 

00:37:26.010 --> 00:37:28.330
work they know what the Electoral
College is everybody needs to have that

00:37:28.330 --> 00:37:28.340
College is everybody needs to have that
 

00:37:28.340 --> 00:37:31.070
College is everybody needs to have that
undergirding of knowledge so that we can

00:37:31.070 --> 00:37:31.080
undergirding of knowledge so that we can
 

00:37:31.080 --> 00:37:32.270
undergirding of knowledge so that we can
have civic discourse so we can make

00:37:32.270 --> 00:37:32.280
have civic discourse so we can make
 

00:37:32.280 --> 00:37:34.100
have civic discourse so we can make
decisions as a community we don't have

00:37:34.100 --> 00:37:34.110
decisions as a community we don't have
 

00:37:34.110 --> 00:37:35.960
decisions as a community we don't have
that undergirding of knowledge about AI

00:37:35.960 --> 00:37:35.970
that undergirding of knowledge about AI
 

00:37:35.970 --> 00:37:39.200
that undergirding of knowledge about AI
and that's a fundamental problem so in

00:37:39.200 --> 00:37:39.210
and that's a fundamental problem so in
 

00:37:39.210 --> 00:37:41.180
and that's a fundamental problem so in
conclusion what I'm saying is that we

00:37:41.180 --> 00:37:41.190
conclusion what I'm saying is that we
 

00:37:41.190 --> 00:37:44.480
conclusion what I'm saying is that we
need fluency and what that means is we

00:37:44.480 --> 00:37:44.490
need fluency and what that means is we
 

00:37:44.490 --> 00:37:46.910
need fluency and what that means is we
need to recombine a juxtaposition of AI

00:37:46.910 --> 00:37:46.920
need to recombine a juxtaposition of AI
 

00:37:46.920 --> 00:37:48.740
need to recombine a juxtaposition of AI
and humanity we need people to

00:37:48.740 --> 00:37:48.750
and humanity we need people to
 

00:37:48.750 --> 00:37:51.050
and humanity we need people to
understand what humanity is

00:37:51.050 --> 00:37:51.060
understand what humanity is
 

00:37:51.060 --> 00:37:52.730
understand what humanity is
what are the ways in which AI is

00:37:52.730 --> 00:37:52.740
what are the ways in which AI is
 

00:37:52.740 --> 00:37:54.110
what are the ways in which AI is
actually what I'm gonna call alien

00:37:54.110 --> 00:37:54.120
actually what I'm gonna call alien
 

00:37:54.120 --> 00:37:55.430
actually what I'm gonna call alien
intelligence so I'll give you a new

00:37:55.430 --> 00:37:55.440
intelligence so I'll give you a new
 

00:37:55.440 --> 00:37:57.230
intelligence so I'll give you a new
moniker I'll keep the same acronym to

00:37:57.230 --> 00:37:57.240
moniker I'll keep the same acronym to
 

00:37:57.240 --> 00:37:59.060
moniker I'll keep the same acronym to
make it easy so instead of CI I'm gonna

00:37:59.060 --> 00:37:59.070
make it easy so instead of CI I'm gonna
 

00:37:59.070 --> 00:38:00.590
make it easy so instead of CI I'm gonna
I'm gonna say it's alien intelligence

00:38:00.590 --> 00:38:00.600
I'm gonna say it's alien intelligence
 

00:38:00.600 --> 00:38:02.750
I'm gonna say it's alien intelligence
but I think we need the population to

00:38:02.750 --> 00:38:02.760
but I think we need the population to
 

00:38:02.760 --> 00:38:04.550
but I think we need the population to
understand how alien that intelligence

00:38:04.550 --> 00:38:04.560
understand how alien that intelligence
 

00:38:04.560 --> 00:38:07.430
understand how alien that intelligence
is how unrelated to the human form or

00:38:07.430 --> 00:38:07.440
is how unrelated to the human form or
 

00:38:07.440 --> 00:38:09.830
is how unrelated to the human form or
the human failings and I'm gonna give

00:38:09.830 --> 00:38:09.840
the human failings and I'm gonna give
 

00:38:09.840 --> 00:38:11.510
the human failings and I'm gonna give
you an example and pose you with a final

00:38:11.510 --> 00:38:11.520
you an example and pose you with a final
 

00:38:11.520 --> 00:38:14.420
you an example and pose you with a final
challenge the example I'll give you that

00:38:14.420 --> 00:38:14.430
challenge the example I'll give you that
 

00:38:14.430 --> 00:38:16.610
challenge the example I'll give you that
we've nailed recently is climate change

00:38:16.610 --> 00:38:16.620
we've nailed recently is climate change
 

00:38:16.620 --> 00:38:18.740
we've nailed recently is climate change
climate change is social and it's

00:38:18.740 --> 00:38:18.750
climate change is social and it's
 

00:38:18.750 --> 00:38:21.290
climate change is social and it's
systemic and what the world has managed

00:38:21.290 --> 00:38:21.300
systemic and what the world has managed
 

00:38:21.300 --> 00:38:22.790
systemic and what the world has managed
to do is come up with markers for

00:38:22.790 --> 00:38:22.800
to do is come up with markers for
 

00:38:22.800 --> 00:38:25.430
to do is come up with markers for
changes in climate the world has figured

00:38:25.430 --> 00:38:25.440
changes in climate the world has figured
 

00:38:25.440 --> 00:38:27.230
changes in climate the world has figured
out ways to systematize the

00:38:27.230 --> 00:38:27.240
out ways to systematize the
 

00:38:27.240 --> 00:38:28.910
out ways to systematize the
understanding of how climate change

00:38:28.910 --> 00:38:28.920
understanding of how climate change
 

00:38:28.920 --> 00:38:30.590
understanding of how climate change
affects the world both in terms of

00:38:30.590 --> 00:38:30.600
affects the world both in terms of
 

00:38:30.600 --> 00:38:32.540
affects the world both in terms of
access to clean water access to air

00:38:32.540 --> 00:38:32.550
access to clean water access to air
 

00:38:32.550 --> 00:38:35.390
access to clean water access to air
climate induced refugees political

00:38:35.390 --> 00:38:35.400
climate induced refugees political
 

00:38:35.400 --> 00:38:37.010
climate induced refugees political
changes due to climate and of course

00:38:37.010 --> 00:38:37.020
changes due to climate and of course
 

00:38:37.020 --> 00:38:39.320
changes due to climate and of course
nutritional gaps due to climate we know

00:38:39.320 --> 00:38:39.330
nutritional gaps due to climate we know
 

00:38:39.330 --> 00:38:40.820
nutritional gaps due to climate we know
how to visualize this we know how to

00:38:40.820 --> 00:38:40.830
how to visualize this we know how to
 

00:38:40.830 --> 00:38:43.460
how to visualize this we know how to
quantify this and because we can do all

00:38:43.460 --> 00:38:43.470
quantify this and because we can do all
 

00:38:43.470 --> 00:38:45.710
quantify this and because we can do all
that we can look 40 years hence show you

00:38:45.710 --> 00:38:45.720
that we can look 40 years hence show you
 

00:38:45.720 --> 00:38:47.240
that we can look 40 years hence show you
the ways in which boundaries are being

00:38:47.240 --> 00:38:47.250
the ways in which boundaries are being
 

00:38:47.250 --> 00:38:49.790
the ways in which boundaries are being
pushed in irreversible ways and as a

00:38:49.790 --> 00:38:49.800
pushed in irreversible ways and as a
 

00:38:49.800 --> 00:38:51.440
pushed in irreversible ways and as a
result what do we have we have the SDGs

00:38:51.440 --> 00:38:51.450
result what do we have we have the SDGs
 

00:38:51.450 --> 00:38:53.030
result what do we have we have the SDGs
the strategic development goes from a UN

00:38:53.030 --> 00:38:53.040
the strategic development goes from a UN
 

00:38:53.040 --> 00:38:54.680
the strategic development goes from a UN
we have very explicit and clear

00:38:54.680 --> 00:38:54.690
we have very explicit and clear
 

00:38:54.690 --> 00:38:56.630
we have very explicit and clear
boundaries along which governments can

00:38:56.630 --> 00:38:56.640
boundaries along which governments can
 

00:38:56.640 --> 00:38:58.760
boundaries along which governments can
actually act together because they can

00:38:58.760 --> 00:38:58.770
actually act together because they can
 

00:38:58.770 --> 00:39:01.100
actually act together because they can
see the possible future that's poor if

00:39:01.100 --> 00:39:01.110
see the possible future that's poor if
 

00:39:01.110 --> 00:39:03.470
see the possible future that's poor if
we don't do the right thing so that is

00:39:03.470 --> 00:39:03.480
we don't do the right thing so that is
 

00:39:03.480 --> 00:39:04.760
we don't do the right thing so that is
how we've dealt with climate change

00:39:04.760 --> 00:39:04.770
how we've dealt with climate change
 

00:39:04.770 --> 00:39:06.440
how we've dealt with climate change
there's a systematized approach that has

00:39:06.440 --> 00:39:06.450
there's a systematized approach that has
 

00:39:06.450 --> 00:39:09.080
there's a systematized approach that has
quantified the externalities of how

00:39:09.080 --> 00:39:09.090
quantified the externalities of how
 

00:39:09.090 --> 00:39:12.650
quantified the externalities of how
climate change affects humanity we need

00:39:12.650 --> 00:39:12.660
climate change affects humanity we need
 

00:39:12.660 --> 00:39:15.740
climate change affects humanity we need
this for AI you know if you take other

00:39:15.740 --> 00:39:15.750
this for AI you know if you take other
 

00:39:15.750 --> 00:39:16.970
this for AI you know if you take other
ways in which we've changed human

00:39:16.970 --> 00:39:16.980
ways in which we've changed human
 

00:39:16.980 --> 00:39:18.860
ways in which we've changed human
behavior like the opioid drug epidemic

00:39:18.860 --> 00:39:18.870
behavior like the opioid drug epidemic
 

00:39:18.870 --> 00:39:20.690
behavior like the opioid drug epidemic
we're starting to quantify that because

00:39:20.690 --> 00:39:20.700
we're starting to quantify that because
 

00:39:20.700 --> 00:39:21.950
we're starting to quantify that because
it's having such a massive impact on

00:39:21.950 --> 00:39:21.960
it's having such a massive impact on
 

00:39:21.960 --> 00:39:24.230
it's having such a massive impact on
society like in West Virginia where I do

00:39:24.230 --> 00:39:24.240
society like in West Virginia where I do
 

00:39:24.240 --> 00:39:26.060
society like in West Virginia where I do
a great deal of work but we need

00:39:26.060 --> 00:39:26.070
a great deal of work but we need
 

00:39:26.070 --> 00:39:28.100
a great deal of work but we need
precisely this quantified systematized

00:39:28.100 --> 00:39:28.110
precisely this quantified systematized
 

00:39:28.110 --> 00:39:31.400
precisely this quantified systematized
understanding for the externalities the

00:39:31.400 --> 00:39:31.410
understanding for the externalities the
 

00:39:31.410 --> 00:39:34.250
understanding for the externalities the
ways in which AI changes society so we

00:39:34.250 --> 00:39:34.260
ways in which AI changes society so we
 

00:39:34.260 --> 00:39:36.320
ways in which AI changes society so we
can show the boundary conditions and the

00:39:36.320 --> 00:39:36.330
can show the boundary conditions and the
 

00:39:36.330 --> 00:39:38.120
can show the boundary conditions and the
knees and the curves where we have to

00:39:38.120 --> 00:39:38.130
knees and the curves where we have to
 

00:39:38.130 --> 00:39:43.250
knees and the curves where we have to
act as a unified whole planet to enforce

00:39:43.250 --> 00:39:43.260
act as a unified whole planet to enforce
 

00:39:43.260 --> 00:39:44.960
act as a unified whole planet to enforce
the changes that cause us to stay within

00:39:44.960 --> 00:39:44.970
the changes that cause us to stay within
 

00:39:44.970 --> 00:39:46.400
the changes that cause us to stay within
a regime of controlled is acceptable

00:39:46.400 --> 00:39:46.410
a regime of controlled is acceptable
 

00:39:46.410 --> 00:39:50.270
a regime of controlled is acceptable
that means democracy that means personal

00:39:50.270 --> 00:39:50.280
that means democracy that means personal
 

00:39:50.280 --> 00:39:53.350
that means democracy that means personal
agency that means personal dignity and

00:39:53.350 --> 00:39:53.360
agency that means personal dignity and
 

00:39:53.360 --> 00:39:58.190
agency that means personal dignity and
my final point is mulready said AI is

00:39:58.190 --> 00:39:58.200
my final point is mulready said AI is
 

00:39:58.200 --> 00:40:00.620
my final point is mulready said AI is
dynamic fundamentally this means if we

00:40:00.620 --> 00:40:00.630
dynamic fundamentally this means if we
 

00:40:00.630 --> 00:40:03.200
dynamic fundamentally this means if we
don't do this if we don't create for AI

00:40:03.200 --> 00:40:03.210
don't do this if we don't create for AI
 

00:40:03.210 --> 00:40:04.760
don't do this if we don't create for AI
the same systematize

00:40:04.760 --> 00:40:04.770
the same systematize
 

00:40:04.770 --> 00:40:06.830
the same systematize
approach with essentially strategic

00:40:06.830 --> 00:40:06.840
approach with essentially strategic
 

00:40:06.840 --> 00:40:09.140
approach with essentially strategic
goals as we have for climate change we

00:40:09.140 --> 00:40:09.150
goals as we have for climate change we
 

00:40:09.150 --> 00:40:11.960
goals as we have for climate change we
are otherwise basically lobsters in a

00:40:11.960 --> 00:40:11.970
are otherwise basically lobsters in a
 

00:40:11.970 --> 00:40:14.420
are otherwise basically lobsters in a
pot of warm water and the water will

00:40:14.420 --> 00:40:14.430
pot of warm water and the water will
 

00:40:14.430 --> 00:40:16.670
pot of warm water and the water will
gradually warm and will accommodate to

00:40:16.670 --> 00:40:16.680
gradually warm and will accommodate to
 

00:40:16.680 --> 00:40:18.770
gradually warm and will accommodate to
those changes ever so gradually and we

00:40:18.770 --> 00:40:18.780
those changes ever so gradually and we
 

00:40:18.780 --> 00:40:21.050
those changes ever so gradually and we
will change and by the time the water

00:40:21.050 --> 00:40:21.060
will change and by the time the water
 

00:40:21.060 --> 00:40:22.280
will change and by the time the water
boils we'll have changed quite

00:40:22.280 --> 00:40:22.290
boils we'll have changed quite
 

00:40:22.290 --> 00:40:24.770
boils we'll have changed quite
thoroughly and quite irreversibly thank

00:40:24.770 --> 00:40:24.780
thoroughly and quite irreversibly thank
 

00:40:24.780 --> 00:40:32.150
thoroughly and quite irreversibly thank
you thank you for a great thank you for

00:40:32.150 --> 00:40:32.160
you thank you for a great thank you for
 

00:40:32.160 --> 00:40:34.040
you thank you for a great thank you for
a great tour Gila let's sit down we have

00:40:34.040 --> 00:40:34.050
a great tour Gila let's sit down we have
 

00:40:34.050 --> 00:40:38.780
a great tour Gila let's sit down we have
a few minutes here so your talk reminded

00:40:38.780 --> 00:40:38.790
a few minutes here so your talk reminded
 

00:40:38.790 --> 00:40:39.980
a few minutes here so your talk reminded
me of something you said on stage

00:40:39.980 --> 00:40:39.990
me of something you said on stage
 

00:40:39.990 --> 00:40:42.680
me of something you said on stage
yesterday at one point you said that you

00:40:42.680 --> 00:40:42.690
yesterday at one point you said that you
 

00:40:42.690 --> 00:40:45.740
yesterday at one point you said that you
were convinced that artificial changes

00:40:45.740 --> 00:40:45.750
were convinced that artificial changes
 

00:40:45.750 --> 00:40:48.230
were convinced that artificial changes
would change our conception of humanity

00:40:48.230 --> 00:40:48.240
would change our conception of humanity
 

00:40:48.240 --> 00:40:50.090
would change our conception of humanity
and I wondered if you could expand on

00:40:50.090 --> 00:40:50.100
and I wondered if you could expand on
 

00:40:50.100 --> 00:40:54.710
and I wondered if you could expand on
that yes I think there's two things that

00:40:54.710 --> 00:40:54.720
that yes I think there's two things that
 

00:40:54.720 --> 00:40:56.450
that yes I think there's two things that
artificial intelligence does to us that

00:40:56.450 --> 00:40:56.460
artificial intelligence does to us that
 

00:40:56.460 --> 00:40:58.730
artificial intelligence does to us that
it's dangerous if it's doing it to us

00:40:58.730 --> 00:40:58.740
it's dangerous if it's doing it to us
 

00:40:58.740 --> 00:41:00.830
it's dangerous if it's doing it to us
and we're not recognizing that first of

00:41:00.830 --> 00:41:00.840
and we're not recognizing that first of
 

00:41:00.840 --> 00:41:04.220
and we're not recognizing that first of
all it changes our sense of what humans

00:41:04.220 --> 00:41:04.230
all it changes our sense of what humans
 

00:41:04.230 --> 00:41:07.370
all it changes our sense of what humans
are unique at and what we derive dignity

00:41:07.370 --> 00:41:07.380
are unique at and what we derive dignity
 

00:41:07.380 --> 00:41:09.010
are unique at and what we derive dignity
from the pleasure of dignity from

00:41:09.010 --> 00:41:09.020
from the pleasure of dignity from
 

00:41:09.020 --> 00:41:11.420
from the pleasure of dignity from
secondly artificial intelligence changes

00:41:11.420 --> 00:41:11.430
secondly artificial intelligence changes
 

00:41:11.430 --> 00:41:12.860
secondly artificial intelligence changes
our sense of what's possible

00:41:12.860 --> 00:41:12.870
our sense of what's possible
 

00:41:12.870 --> 00:41:14.930
our sense of what's possible
you know we're distracted so much by

00:41:14.930 --> 00:41:14.940
you know we're distracted so much by
 

00:41:14.940 --> 00:41:16.670
you know we're distracted so much by
stories of things like immortality and

00:41:16.670 --> 00:41:16.680
stories of things like immortality and
 

00:41:16.680 --> 00:41:18.950
stories of things like immortality and
singularity precisely because they

00:41:18.950 --> 00:41:18.960
singularity precisely because they
 

00:41:18.960 --> 00:41:20.930
singularity precisely because they
redefine our sense of who we might be

00:41:20.930 --> 00:41:20.940
redefine our sense of who we might be
 

00:41:20.940 --> 00:41:24.920
redefine our sense of who we might be
one day I have had CEOs visit me here

00:41:24.920 --> 00:41:24.930
one day I have had CEOs visit me here
 

00:41:24.930 --> 00:41:27.200
one day I have had CEOs visit me here
who've popped a handful of pills during

00:41:27.200 --> 00:41:27.210
who've popped a handful of pills during
 

00:41:27.210 --> 00:41:30.260
who've popped a handful of pills during
lunch at Alibaba and I've jokingly asked

00:41:30.260 --> 00:41:30.270
lunch at Alibaba and I've jokingly asked
 

00:41:30.270 --> 00:41:31.790
lunch at Alibaba and I've jokingly asked
this one gentleman what are you doing

00:41:31.790 --> 00:41:31.800
this one gentleman what are you doing
 

00:41:31.800 --> 00:41:32.960
this one gentleman what are you doing
and he said oh I'm part of this life

00:41:32.960 --> 00:41:32.970
and he said oh I'm part of this life
 

00:41:32.970 --> 00:41:35.120
and he said oh I'm part of this life
extension program for immortality and he

00:41:35.120 --> 00:41:35.130
extension program for immortality and he
 

00:41:35.130 --> 00:41:37.430
extension program for immortality and he
was serious and when I jokingly asked

00:41:37.430 --> 00:41:37.440
was serious and when I jokingly asked
 

00:41:37.440 --> 00:41:38.750
was serious and when I jokingly asked
him so how do you do with financial

00:41:38.750 --> 00:41:38.760
him so how do you do with financial
 

00:41:38.760 --> 00:41:41.870
him so how do you do with financial
planning for that hahaha he gave me the

00:41:41.870 --> 00:41:41.880
planning for that hahaha he gave me the
 

00:41:41.880 --> 00:41:43.430
planning for that hahaha he gave me the
card of his financial planner he said oh

00:41:43.430 --> 00:41:43.440
card of his financial planner he said oh
 

00:41:43.440 --> 00:41:45.140
card of his financial planner he said oh
I have a great guy and he does immortal

00:41:45.140 --> 00:41:45.150
I have a great guy and he does immortal
 

00:41:45.150 --> 00:41:50.240
I have a great guy and he does immortal
planning seriously that's the humanity

00:41:50.240 --> 00:41:50.250
planning seriously that's the humanity
 

00:41:50.250 --> 00:41:51.910
planning seriously that's the humanity
concept he has has completely changed

00:41:51.910 --> 00:41:51.920
concept he has has completely changed
 

00:41:51.920 --> 00:41:56.120
concept he has has completely changed
you know that's not a Bill Gates who

00:41:56.120 --> 00:41:56.130
you know that's not a Bill Gates who
 

00:41:56.130 --> 00:41:57.860
you know that's not a Bill Gates who
wants to think about his legacy in terms

00:41:57.860 --> 00:41:57.870
wants to think about his legacy in terms
 

00:41:57.870 --> 00:41:59.720
wants to think about his legacy in terms
of positive impact on the world that's

00:41:59.720 --> 00:41:59.730
of positive impact on the world that's
 

00:41:59.730 --> 00:42:00.950
of positive impact on the world that's
somebody who believes he's gonna live

00:42:00.950 --> 00:42:00.960
somebody who believes he's gonna live
 

00:42:00.960 --> 00:42:03.080
somebody who believes he's gonna live
forever and that's the world we now live

00:42:03.080 --> 00:42:03.090
forever and that's the world we now live
 

00:42:03.090 --> 00:42:05.090
forever and that's the world we now live
in is with people that have that mindset

00:42:05.090 --> 00:42:05.100
in is with people that have that mindset
 

00:42:05.100 --> 00:42:07.670
in is with people that have that mindset
and have levers of power okay and you

00:42:07.670 --> 00:42:07.680
and have levers of power okay and you
 

00:42:07.680 --> 00:42:09.620
and have levers of power okay and you
have worked with AI and robotics for a

00:42:09.620 --> 00:42:09.630
have worked with AI and robotics for a
 

00:42:09.630 --> 00:42:10.910
have worked with AI and robotics for a
long time and thinking about the

00:42:10.910 --> 00:42:10.920
long time and thinking about the
 

00:42:10.920 --> 00:42:12.320
long time and thinking about the
consequences has that changed your

00:42:12.320 --> 00:42:12.330
consequences has that changed your
 

00:42:12.330 --> 00:42:14.320
consequences has that changed your
understanding of humanity or your

00:42:14.320 --> 00:42:14.330
understanding of humanity or your
 

00:42:14.330 --> 00:42:16.450
understanding of humanity or your
the sense of yourself I'm guessing you

00:42:16.450 --> 00:42:16.460
the sense of yourself I'm guessing you
 

00:42:16.460 --> 00:42:19.390
the sense of yourself I'm guessing you
don't take pills to a forever no I don't

00:42:19.390 --> 00:42:19.400
don't take pills to a forever no I don't
 

00:42:19.400 --> 00:42:20.740
don't take pills to a forever no I don't
well I think we need to make room for

00:42:20.740 --> 00:42:20.750
well I think we need to make room for
 

00:42:20.750 --> 00:42:24.280
well I think we need to make room for
the next generation in general yes I

00:42:24.280 --> 00:42:24.290
the next generation in general yes I
 

00:42:24.290 --> 00:42:27.250
the next generation in general yes I
think my own sense of self has changed

00:42:27.250 --> 00:42:27.260
think my own sense of self has changed
 

00:42:27.260 --> 00:42:30.070
think my own sense of self has changed
tremendously I think I recognize that

00:42:30.070 --> 00:42:30.080
tremendously I think I recognize that
 

00:42:30.080 --> 00:42:35.500
tremendously I think I recognize that
that we are less good at understanding

00:42:35.500 --> 00:42:35.510
that we are less good at understanding
 

00:42:35.510 --> 00:42:36.940
that we are less good at understanding
what we should be doing in the world

00:42:36.940 --> 00:42:36.950
what we should be doing in the world
 

00:42:36.950 --> 00:42:39.520
what we should be doing in the world
than we used to then I used to believe I

00:42:39.520 --> 00:42:39.530
than we used to then I used to believe I
 

00:42:39.530 --> 00:42:42.040
than we used to then I used to believe I
used to believe it was very clear how we

00:42:42.040 --> 00:42:42.050
used to believe it was very clear how we
 

00:42:42.050 --> 00:42:43.390
used to believe it was very clear how we
should have a quick career and how we

00:42:43.390 --> 00:42:43.400
should have a quick career and how we
 

00:42:43.400 --> 00:42:44.650
should have a quick career and how we
should kind of Forge your direction and

00:42:44.650 --> 00:42:44.660
should kind of Forge your direction and
 

00:42:44.660 --> 00:42:47.200
should kind of Forge your direction and
have impact now what I see is a world

00:42:47.200 --> 00:42:47.210
have impact now what I see is a world
 

00:42:47.210 --> 00:42:48.760
have impact now what I see is a world
that's changing around us quite rapidly

00:42:48.760 --> 00:42:48.770
that's changing around us quite rapidly
 

00:42:48.770 --> 00:42:51.280
that's changing around us quite rapidly
and dramatically I remember 20 30 years

00:42:51.280 --> 00:42:51.290
and dramatically I remember 20 30 years
 

00:42:51.290 --> 00:42:52.270
and dramatically I remember 20 30 years
ago feeling like the world's getting

00:42:52.270 --> 00:42:52.280
ago feeling like the world's getting
 

00:42:52.280 --> 00:42:54.490
ago feeling like the world's getting
more peaceful polarity O'Leary's Asians

00:42:54.490 --> 00:42:54.500
more peaceful polarity O'Leary's Asians
 

00:42:54.500 --> 00:42:56.080
more peaceful polarity O'Leary's Asians
decreasing things are kind of looking

00:42:56.080 --> 00:42:56.090
decreasing things are kind of looking
 

00:42:56.090 --> 00:42:57.520
decreasing things are kind of looking
good my kids are gonna have a better

00:42:57.520 --> 00:42:57.530
good my kids are gonna have a better
 

00:42:57.530 --> 00:42:59.590
good my kids are gonna have a better
life than me I don't really feel that

00:42:59.590 --> 00:42:59.600
life than me I don't really feel that
 

00:42:59.600 --> 00:43:01.120
life than me I don't really feel that
way anymore I feel like we have a

00:43:01.120 --> 00:43:01.130
way anymore I feel like we have a
 

00:43:01.130 --> 00:43:02.920
way anymore I feel like we have a
pathway that's rocky and we have to do

00:43:02.920 --> 00:43:02.930
pathway that's rocky and we have to do
 

00:43:02.930 --> 00:43:04.270
pathway that's rocky and we have to do
everything we can to keep ourselves from

00:43:04.270 --> 00:43:04.280
everything we can to keep ourselves from
 

00:43:04.280 --> 00:43:06.340
everything we can to keep ourselves from
actually ending up in a worse place than

00:43:06.340 --> 00:43:06.350
actually ending up in a worse place than
 

00:43:06.350 --> 00:43:09.880
actually ending up in a worse place than
we are in today right okay and you spoke

00:43:09.880 --> 00:43:09.890
we are in today right okay and you spoke
 

00:43:09.890 --> 00:43:11.109
we are in today right okay and you spoke
at the in there about trying to look to

00:43:11.109 --> 00:43:11.119
at the in there about trying to look to
 

00:43:11.119 --> 00:43:14.830
at the in there about trying to look to
the future and and think about how am i

00:43:14.830 --> 00:43:14.840
the future and and think about how am i
 

00:43:14.840 --> 00:43:16.359
the future and and think about how am i
changing what is being useful exercise

00:43:16.359 --> 00:43:16.369
changing what is being useful exercise
 

00:43:16.369 --> 00:43:18.670
changing what is being useful exercise
and you indeed wrote a whole book that

00:43:18.670 --> 00:43:18.680
and you indeed wrote a whole book that
 

00:43:18.680 --> 00:43:20.170
and you indeed wrote a whole book that
kind of took that approach wherever

00:43:20.170 --> 00:43:20.180
kind of took that approach wherever
 

00:43:20.180 --> 00:43:22.150
kind of took that approach wherever
futures in the East chapter you you

00:43:22.150 --> 00:43:22.160
futures in the East chapter you you
 

00:43:22.160 --> 00:43:24.940
futures in the East chapter you you
wrote a little fictional skit looking

00:43:24.940 --> 00:43:24.950
wrote a little fictional skit looking
 

00:43:24.950 --> 00:43:27.010
wrote a little fictional skit looking
ahead we were talking about one of those

00:43:27.010 --> 00:43:27.020
ahead we were talking about one of those
 

00:43:27.020 --> 00:43:29.170
ahead we were talking about one of those
earlier which you title it mediocracy

00:43:29.170 --> 00:43:29.180
earlier which you title it mediocracy
 

00:43:29.180 --> 00:43:31.060
earlier which you title it mediocracy
can you just introduce this to that yeah

00:43:31.060 --> 00:43:31.070
can you just introduce this to that yeah
 

00:43:31.070 --> 00:43:32.710
can you just introduce this to that yeah
there's one that I called mediocracy

00:43:32.710 --> 00:43:32.720
there's one that I called mediocracy
 

00:43:32.720 --> 00:43:36.820
there's one that I called mediocracy
the idea behind that title was the story

00:43:36.820 --> 00:43:36.830
the idea behind that title was the story
 

00:43:36.830 --> 00:43:38.320
the idea behind that title was the story
story with this idea that a company has

00:43:38.320 --> 00:43:38.330
story with this idea that a company has
 

00:43:38.330 --> 00:43:41.800
story with this idea that a company has
an inventory excess inventory of 50,000

00:43:41.800 --> 00:43:41.810
an inventory excess inventory of 50,000
 

00:43:41.810 --> 00:43:44.230
an inventory excess inventory of 50,000
green lawn chairs and the way you deal

00:43:44.230 --> 00:43:44.240
green lawn chairs and the way you deal
 

00:43:44.240 --> 00:43:46.180
green lawn chairs and the way you deal
with that in this conceptualized future

00:43:46.180 --> 00:43:46.190
with that in this conceptualized future
 

00:43:46.190 --> 00:43:48.070
with that in this conceptualized future
20 years from now I didn't realize it

00:43:48.070 --> 00:43:48.080
20 years from now I didn't realize it
 

00:43:48.080 --> 00:43:50.920
20 years from now I didn't realize it
was now is you run your behavioral

00:43:50.920 --> 00:43:50.930
was now is you run your behavioral
 

00:43:50.930 --> 00:43:52.480
was now is you run your behavioral
analytics system create bespoke

00:43:52.480 --> 00:43:52.490
analytics system create bespoke
 

00:43:52.490 --> 00:43:54.250
analytics system create bespoke
marketing copy for every individual

00:43:54.250 --> 00:43:54.260
marketing copy for every individual
 

00:43:54.260 --> 00:43:56.230
marketing copy for every individual
human being on earth that maximizes the

00:43:56.230 --> 00:43:56.240
human being on earth that maximizes the
 

00:43:56.240 --> 00:43:57.220
human being on earth that maximizes the
chance that they want to buy a green

00:43:57.220 --> 00:43:57.230
chance that they want to buy a green
 

00:43:57.230 --> 00:44:00.849
chance that they want to buy a green
lawn chair and you overnight sell your

00:44:00.849 --> 00:44:00.859
lawn chair and you overnight sell your
 

00:44:00.859 --> 00:44:02.560
lawn chair and you overnight sell your
inventory and it's interesting because

00:44:02.560 --> 00:44:02.570
inventory and it's interesting because
 

00:44:02.570 --> 00:44:04.210
inventory and it's interesting because
the tails backing you the dog you're no

00:44:04.210 --> 00:44:04.220
the tails backing you the dog you're no
 

00:44:04.220 --> 00:44:07.210
the tails backing you the dog you're no
longer building and selling product that

00:44:07.210 --> 00:44:07.220
longer building and selling product that
 

00:44:07.220 --> 00:44:09.220
longer building and selling product that
people need you're simply controlling

00:44:09.220 --> 00:44:09.230
people need you're simply controlling
 

00:44:09.230 --> 00:44:10.210
people need you're simply controlling
the need of people with a giant

00:44:10.210 --> 00:44:10.220
the need of people with a giant
 

00:44:10.220 --> 00:44:12.640
the need of people with a giant
universal remote to make sure they buy

00:44:12.640 --> 00:44:12.650
universal remote to make sure they buy
 

00:44:12.650 --> 00:44:14.080
universal remote to make sure they buy
whatever you have excess inventory of

00:44:14.080 --> 00:44:14.090
whatever you have excess inventory of
 

00:44:14.090 --> 00:44:17.500
whatever you have excess inventory of
and then the point I made was that if we

00:44:17.500 --> 00:44:17.510
and then the point I made was that if we
 

00:44:17.510 --> 00:44:19.780
and then the point I made was that if we
look not just at consumer choice but

00:44:19.780 --> 00:44:19.790
look not just at consumer choice but
 

00:44:19.790 --> 00:44:21.970
look not just at consumer choice but
voters choice what happens when people

00:44:21.970 --> 00:44:21.980
voters choice what happens when people
 

00:44:21.980 --> 00:44:24.970
voters choice what happens when people
are able to create highly bespoke copy

00:44:24.970 --> 00:44:24.980
are able to create highly bespoke copy
 

00:44:24.980 --> 00:44:27.099
are able to create highly bespoke copy
for each individual person then

00:44:27.099 --> 00:44:27.109
for each individual person then
 

00:44:27.109 --> 00:44:27.880
for each individual person then
maximizes

00:44:27.880 --> 00:44:27.890
maximizes
 

00:44:27.890 --> 00:44:29.109
maximizes
chants they vote for the candidate who

00:44:29.109 --> 00:44:29.119
chants they vote for the candidate who
 

00:44:29.119 --> 00:44:30.519
chants they vote for the candidate who
is paying the most money for that

00:44:30.519 --> 00:44:30.529
is paying the most money for that
 

00:44:30.529 --> 00:44:33.519
is paying the most money for that
marketing well this is now happening I

00:44:33.519 --> 00:44:33.529
marketing well this is now happening I
 

00:44:33.529 --> 00:44:35.799
marketing well this is now happening I
called it mediocracy because at some

00:44:35.799 --> 00:44:35.809
called it mediocracy because at some
 

00:44:35.809 --> 00:44:37.839
called it mediocracy because at some
point personal agency has been reduced

00:44:37.839 --> 00:44:37.849
point personal agency has been reduced
 

00:44:37.849 --> 00:44:39.609
point personal agency has been reduced
to the point where it's hard to any

00:44:39.609 --> 00:44:39.619
to the point where it's hard to any
 

00:44:39.619 --> 00:44:42.039
to the point where it's hard to any
longer call the system democracy it's

00:44:42.039 --> 00:44:42.049
longer call the system democracy it's
 

00:44:42.049 --> 00:44:43.509
longer call the system democracy it's
difficult to use that word with a

00:44:43.509 --> 00:44:43.519
difficult to use that word with a
 

00:44:43.519 --> 00:44:45.430
difficult to use that word with a
straight face when in fact people's

00:44:45.430 --> 00:44:45.440
straight face when in fact people's
 

00:44:45.440 --> 00:44:47.799
straight face when in fact people's
political choices are not really being

00:44:47.799 --> 00:44:47.809
political choices are not really being
 

00:44:47.809 --> 00:44:49.779
political choices are not really being
controlled directly by their brain but

00:44:49.779 --> 00:44:49.789
controlled directly by their brain but
 

00:44:49.789 --> 00:44:52.269
controlled directly by their brain but
bias system that consists of their brain

00:44:52.269 --> 00:44:52.279
bias system that consists of their brain
 

00:44:52.279 --> 00:44:54.400
bias system that consists of their brain
and very carefully customized marketing

00:44:54.400 --> 00:44:54.410
and very carefully customized marketing
 

00:44:54.410 --> 00:44:58.089
and very carefully customized marketing
copy okay so it's kind of it's an

00:44:58.089 --> 00:44:58.099
copy okay so it's kind of it's an
 

00:44:58.099 --> 00:45:00.150
copy okay so it's kind of it's an
unequal fight right you have this big

00:45:00.150 --> 00:45:00.160
unequal fight right you have this big
 

00:45:00.160 --> 00:45:03.160
unequal fight right you have this big
analytic machinery working against your

00:45:03.160 --> 00:45:03.170
analytic machinery working against your
 

00:45:03.170 --> 00:45:05.730
analytic machinery working against your
you know small biological system what

00:45:05.730 --> 00:45:05.740
you know small biological system what
 

00:45:05.740 --> 00:45:08.380
you know small biological system what
what can we do about that have you any

00:45:08.380 --> 00:45:08.390
what can we do about that have you any
 

00:45:08.390 --> 00:45:10.059
what can we do about that have you any
thoughts about how we can level the

00:45:10.059 --> 00:45:10.069
thoughts about how we can level the
 

00:45:10.069 --> 00:45:11.589
thoughts about how we can level the
playing field and allow us to continue

00:45:11.589 --> 00:45:11.599
playing field and allow us to continue
 

00:45:11.599 --> 00:45:15.250
playing field and allow us to continue
to be you know real actors in in reality

00:45:15.250 --> 00:45:15.260
to be you know real actors in in reality
 

00:45:15.260 --> 00:45:17.620
to be you know real actors in in reality
I loved ocean days talks yesterday in

00:45:17.620 --> 00:45:17.630
I loved ocean days talks yesterday in
 

00:45:17.630 --> 00:45:20.680
I loved ocean days talks yesterday in
his spotlight speech I love the idea of

00:45:20.680 --> 00:45:20.690
his spotlight speech I love the idea of
 

00:45:20.690 --> 00:45:22.059
his spotlight speech I love the idea of
redress I think actually that's a really

00:45:22.059 --> 00:45:22.069
redress I think actually that's a really
 

00:45:22.069 --> 00:45:25.150
redress I think actually that's a really
important point I think the general data

00:45:25.150 --> 00:45:25.160
important point I think the general data
 

00:45:25.160 --> 00:45:27.519
important point I think the general data
privacy protection regulations that

00:45:27.519 --> 00:45:27.529
privacy protection regulations that
 

00:45:27.529 --> 00:45:29.410
privacy protection regulations that
Europe is putting in place or something

00:45:29.410 --> 00:45:29.420
Europe is putting in place or something
 

00:45:29.420 --> 00:45:30.849
Europe is putting in place or something
we should be emulating in the US I

00:45:30.849 --> 00:45:30.859
we should be emulating in the US I
 

00:45:30.859 --> 00:45:33.700
we should be emulating in the US I
believe we have to create really deep

00:45:33.700 --> 00:45:33.710
believe we have to create really deep
 

00:45:33.710 --> 00:45:36.430
believe we have to create really deep
understanding of the ethics of AI in

00:45:36.430 --> 00:45:36.440
understanding of the ethics of AI in
 

00:45:36.440 --> 00:45:38.859
understanding of the ethics of AI in
humanity basically from lower school

00:45:38.859 --> 00:45:38.869
humanity basically from lower school
 

00:45:38.869 --> 00:45:39.999
humanity basically from lower school
middle school high school all the way

00:45:39.999 --> 00:45:40.009
middle school high school all the way
 

00:45:40.009 --> 00:45:41.920
middle school high school all the way
through college so that the next

00:45:41.920 --> 00:45:41.930
through college so that the next
 

00:45:41.930 --> 00:45:44.079
through college so that the next
generation of engineers politicians and

00:45:44.079 --> 00:45:44.089
generation of engineers politicians and
 

00:45:44.089 --> 00:45:46.180
generation of engineers politicians and
civic leaders actually understand this

00:45:46.180 --> 00:45:46.190
civic leaders actually understand this
 

00:45:46.190 --> 00:45:49.240
civic leaders actually understand this
boundary technology and I think we need

00:45:49.240 --> 00:45:49.250
boundary technology and I think we need
 

00:45:49.250 --> 00:45:50.920
boundary technology and I think we need
disclosure you know the forms we signed

00:45:50.920 --> 00:45:50.930
disclosure you know the forms we signed
 

00:45:50.930 --> 00:45:53.559
disclosure you know the forms we signed
today the opt-ins are complete joke so I

00:45:53.559 --> 00:45:53.569
today the opt-ins are complete joke so I
 

00:45:53.569 --> 00:45:54.849
today the opt-ins are complete joke so I
think we need fundamentally to rethink

00:45:54.849 --> 00:45:54.859
think we need fundamentally to rethink
 

00:45:54.859 --> 00:45:57.069
think we need fundamentally to rethink
how we disclose the ways in which were

00:45:57.069 --> 00:45:57.079
how we disclose the ways in which were
 

00:45:57.079 --> 00:45:59.259
how we disclose the ways in which were
manipulated online the idea that the

00:45:59.259 --> 00:45:59.269
manipulated online the idea that the
 

00:45:59.269 --> 00:46:00.579
manipulated online the idea that the
biggest marketer can get up and actually

00:46:00.579 --> 00:46:00.589
biggest marketer can get up and actually
 

00:46:00.589 --> 00:46:04.210
biggest marketer can get up and actually
talk about dopamine in the in the view

00:46:04.210 --> 00:46:04.220
talk about dopamine in the in the view
 

00:46:04.220 --> 00:46:06.069
talk about dopamine in the in the view
of the public and not feel embarrassed

00:46:06.069 --> 00:46:06.079
of the public and not feel embarrassed
 

00:46:06.079 --> 00:46:08.170
of the public and not feel embarrassed
about doing that is remarkable that's

00:46:08.170 --> 00:46:08.180
about doing that is remarkable that's
 

00:46:08.180 --> 00:46:11.109
about doing that is remarkable that's
drug design it's exactly the same as

00:46:11.109 --> 00:46:11.119
drug design it's exactly the same as
 

00:46:11.119 --> 00:46:13.390
drug design it's exactly the same as
designing drugs for addiction and it's

00:46:13.390 --> 00:46:13.400
designing drugs for addiction and it's
 

00:46:13.400 --> 00:46:15.849
designing drugs for addiction and it's
become ok to talk about that right ok

00:46:15.849 --> 00:46:15.859
become ok to talk about that right ok
 

00:46:15.859 --> 00:46:17.859
become ok to talk about that right ok
and and you spoke about this this

00:46:17.859 --> 00:46:17.869
and and you spoke about this this
 

00:46:17.869 --> 00:46:20.200
and and you spoke about this this
failure of intuition that people tend to

00:46:20.200 --> 00:46:20.210
failure of intuition that people tend to
 

00:46:20.210 --> 00:46:22.240
failure of intuition that people tend to
have artificial systems you know we have

00:46:22.240 --> 00:46:22.250
have artificial systems you know we have
 

00:46:22.250 --> 00:46:23.710
have artificial systems you know we have
a tendency to anthropomorphize and

00:46:23.710 --> 00:46:23.720
a tendency to anthropomorphize and
 

00:46:23.720 --> 00:46:27.940
a tendency to anthropomorphize and
project a little bit do you have an idea

00:46:27.940 --> 00:46:27.950
project a little bit do you have an idea
 

00:46:27.950 --> 00:46:30.940
project a little bit do you have an idea
of how we can change that Tennessee at a

00:46:30.940 --> 00:46:30.950
of how we can change that Tennessee at a
 

00:46:30.950 --> 00:46:34.150
of how we can change that Tennessee at a
large scale like it can we maybe we just

00:46:34.150 --> 00:46:34.160
large scale like it can we maybe we just
 

00:46:34.160 --> 00:46:35.950
large scale like it can we maybe we just
haven't had enough time to learn an

00:46:35.950 --> 00:46:35.960
haven't had enough time to learn an
 

00:46:35.960 --> 00:46:38.440
haven't had enough time to learn an
intuition for how these machines operate

00:46:38.440 --> 00:46:38.450
intuition for how these machines operate
 

00:46:38.450 --> 00:46:39.670
intuition for how these machines operate
or fail as you

00:46:39.670 --> 00:46:39.680
or fail as you
 

00:46:39.680 --> 00:46:41.500
or fail as you
I actually think that's something that's

00:46:41.500 --> 00:46:41.510
I actually think that's something that's
 

00:46:41.510 --> 00:46:43.960
I actually think that's something that's
on some of you the journalists and I

00:46:43.960 --> 00:46:43.970
on some of you the journalists and I
 

00:46:43.970 --> 00:46:45.160
on some of you the journalists and I
think you can do an outstanding job of

00:46:45.160 --> 00:46:45.170
think you can do an outstanding job of
 

00:46:45.170 --> 00:46:46.930
think you can do an outstanding job of
that I believe you know sometimes I talk

00:46:46.930 --> 00:46:46.940
that I believe you know sometimes I talk
 

00:46:46.940 --> 00:46:48.220
that I believe you know sometimes I talk
and people say well we can't make

00:46:48.220 --> 00:46:48.230
and people say well we can't make
 

00:46:48.230 --> 00:46:50.020
and people say well we can't make
everybody a computer scientist I think

00:46:50.020 --> 00:46:50.030
everybody a computer scientist I think
 

00:46:50.030 --> 00:46:52.569
everybody a computer scientist I think
there's a huge huge area in the middle

00:46:52.569 --> 00:46:52.579
there's a huge huge area in the middle
 

00:46:52.579 --> 00:46:54.309
there's a huge huge area in the middle
between making somebody computer

00:46:54.309 --> 00:46:54.319
between making somebody computer
 

00:46:54.319 --> 00:46:56.079
between making somebody computer
scientists and leaving them illiterate I

00:46:56.079 --> 00:46:56.089
scientists and leaving them illiterate I
 

00:46:56.089 --> 00:46:58.150
scientists and leaving them illiterate I
think there's really outstanding ways in

00:46:58.150 --> 00:46:58.160
think there's really outstanding ways in
 

00:46:58.160 --> 00:46:59.410
think there's really outstanding ways in
which you can teach people the teach

00:46:59.410 --> 00:46:59.420
which you can teach people the teach
 

00:46:59.420 --> 00:47:00.609
which you can teach people the teach
people the failings of these machines

00:47:00.609 --> 00:47:00.619
people the failings of these machines
 

00:47:00.619 --> 00:47:03.730
people the failings of these machines
show them how the computational bias for

00:47:03.730 --> 00:47:03.740
show them how the computational bias for
 

00:47:03.740 --> 00:47:05.500
show them how the computational bias for
instance causes errors in

00:47:05.500 --> 00:47:05.510
instance causes errors in
 

00:47:05.510 --> 00:47:08.109
instance causes errors in
decision-making and we can I think teach

00:47:08.109 --> 00:47:08.119
decision-making and we can I think teach
 

00:47:08.119 --> 00:47:10.990
decision-making and we can I think teach
a lot that stops far short of having to

00:47:10.990 --> 00:47:11.000
a lot that stops far short of having to
 

00:47:11.000 --> 00:47:12.549
a lot that stops far short of having to
force upon them getting a PhD in the

00:47:12.549 --> 00:47:12.559
force upon them getting a PhD in the
 

00:47:12.559 --> 00:47:14.260
force upon them getting a PhD in the
subject right so I think it's education

00:47:14.260 --> 00:47:14.270
subject right so I think it's education
 

00:47:14.270 --> 00:47:16.180
subject right so I think it's education
and I think it's investigative

00:47:16.180 --> 00:47:16.190
and I think it's investigative
 

00:47:16.190 --> 00:47:18.160
and I think it's investigative
journalism that can do that of course

00:47:18.160 --> 00:47:18.170
journalism that can do that of course
 

00:47:18.170 --> 00:47:19.870
journalism that can do that of course
the irony is we have rapidly falling

00:47:19.870 --> 00:47:19.880
the irony is we have rapidly falling
 

00:47:19.880 --> 00:47:21.640
the irony is we have rapidly falling
funding for investigative journalism so

00:47:21.640 --> 00:47:21.650
funding for investigative journalism so
 

00:47:21.650 --> 00:47:24.190
funding for investigative journalism so
instead we have people who don't get

00:47:24.190 --> 00:47:24.200
instead we have people who don't get
 

00:47:24.200 --> 00:47:25.870
instead we have people who don't get
monetized like the old Huffington Post

00:47:25.870 --> 00:47:25.880
monetized like the old Huffington Post
 

00:47:25.880 --> 00:47:30.370
monetized like the old Huffington Post
writers mmm okay and you also talked

00:47:30.370 --> 00:47:30.380
writers mmm okay and you also talked
 

00:47:30.380 --> 00:47:31.510
writers mmm okay and you also talked
about another failure you talked about

00:47:31.510 --> 00:47:31.520
about another failure you talked about
 

00:47:31.520 --> 00:47:34.359
about another failure you talked about
was this this failure from a Mises field

00:47:34.359 --> 00:47:34.369
was this this failure from a Mises field
 

00:47:34.369 --> 00:47:37.000
was this this failure from a Mises field
to started out trying to do that and and

00:47:37.000 --> 00:47:37.010
to started out trying to do that and and
 

00:47:37.010 --> 00:47:38.170
to started out trying to do that and and
hasn't managed it

00:47:38.170 --> 00:47:38.180
hasn't managed it
 

00:47:38.180 --> 00:47:40.630
hasn't managed it
can we get back to it do we want to is

00:47:40.630 --> 00:47:40.640
can we get back to it do we want to is
 

00:47:40.640 --> 00:47:43.809
can we get back to it do we want to is
it something that we should desire it's

00:47:43.809 --> 00:47:43.819
it something that we should desire it's
 

00:47:43.819 --> 00:47:45.549
it something that we should desire it's
an interesting question you know I have

00:47:45.549 --> 00:47:45.559
an interesting question you know I have
 

00:47:45.559 --> 00:47:47.289
an interesting question you know I have
colleagues who are trying to make quite

00:47:47.289 --> 00:47:47.299
colleagues who are trying to make quite
 

00:47:47.299 --> 00:47:49.240
colleagues who are trying to make quite
literally babies the idea is if I make

00:47:49.240 --> 00:47:49.250
literally babies the idea is if I make
 

00:47:49.250 --> 00:47:50.829
literally babies the idea is if I make
an artificial baby then I can raise it

00:47:50.829 --> 00:47:50.839
an artificial baby then I can raise it
 

00:47:50.839 --> 00:47:54.309
an artificial baby then I can raise it
and it'll become human in ethical

00:47:54.309 --> 00:47:54.319
and it'll become human in ethical
 

00:47:54.319 --> 00:47:56.799
and it'll become human in ethical
normative behavior there's a whole hype

00:47:56.799 --> 00:47:56.809
normative behavior there's a whole hype
 

00:47:56.809 --> 00:47:58.960
normative behavior there's a whole hype
of hypothetical there that people hew

00:47:58.960 --> 00:47:58.970
of hypothetical there that people hew
 

00:47:58.970 --> 00:48:02.260
of hypothetical there that people hew
toward I don't know in a value judgment

00:48:02.260 --> 00:48:02.270
toward I don't know in a value judgment
 

00:48:02.270 --> 00:48:04.329
toward I don't know in a value judgment
sense that we need to do mimesis I don't

00:48:04.329 --> 00:48:04.339
sense that we need to do mimesis I don't
 

00:48:04.339 --> 00:48:05.140
sense that we need to do mimesis I don't
know that we need to replace people

00:48:05.140 --> 00:48:05.150
know that we need to replace people
 

00:48:05.150 --> 00:48:07.510
know that we need to replace people
one-to-one the biological desire to

00:48:07.510 --> 00:48:07.520
one-to-one the biological desire to
 

00:48:07.520 --> 00:48:08.589
one-to-one the biological desire to
understand how humans work is is

00:48:08.589 --> 00:48:08.599
understand how humans work is is
 

00:48:08.599 --> 00:48:10.450
understand how humans work is is
absolutely outstandingly important and

00:48:10.450 --> 00:48:10.460
absolutely outstandingly important and
 

00:48:10.460 --> 00:48:12.220
absolutely outstandingly important and
interesting and we should always go

00:48:12.220 --> 00:48:12.230
interesting and we should always go
 

00:48:12.230 --> 00:48:14.020
interesting and we should always go
toward that cognitive orthotics will

00:48:14.020 --> 00:48:14.030
toward that cognitive orthotics will
 

00:48:14.030 --> 00:48:16.089
toward that cognitive orthotics will
benefit from that so our ability to help

00:48:16.089 --> 00:48:16.099
benefit from that so our ability to help
 

00:48:16.099 --> 00:48:18.280
benefit from that so our ability to help
people have quality of life as they grow

00:48:18.280 --> 00:48:18.290
people have quality of life as they grow
 

00:48:18.290 --> 00:48:20.319
people have quality of life as they grow
old is gonna be directly impacted by our

00:48:20.319 --> 00:48:20.329
old is gonna be directly impacted by our
 

00:48:20.329 --> 00:48:22.569
old is gonna be directly impacted by our
ability to do that it's not so much that

00:48:22.569 --> 00:48:22.579
ability to do that it's not so much that
 

00:48:22.579 --> 00:48:24.640
ability to do that it's not so much that
the fact that huge away from a basis is

00:48:24.640 --> 00:48:24.650
the fact that huge away from a basis is
 

00:48:24.650 --> 00:48:28.990
the fact that huge away from a basis is
bad as it is we have a tendency to

00:48:28.990 --> 00:48:29.000
bad as it is we have a tendency to
 

00:48:29.000 --> 00:48:31.120
bad as it is we have a tendency to
assume that that robot replaces a human

00:48:31.120 --> 00:48:31.130
assume that that robot replaces a human
 

00:48:31.130 --> 00:48:33.400
assume that that robot replaces a human
when in fact it's utterly alien to us

00:48:33.400 --> 00:48:33.410
when in fact it's utterly alien to us
 

00:48:33.410 --> 00:48:36.609
when in fact it's utterly alien to us
and unless we train people to understand

00:48:36.609 --> 00:48:36.619
and unless we train people to understand
 

00:48:36.619 --> 00:48:38.770
and unless we train people to understand
that I don't think they'll ever have the

00:48:38.770 --> 00:48:38.780
that I don't think they'll ever have the
 

00:48:38.780 --> 00:48:42.609
that I don't think they'll ever have the
the skin to accept that okay and we have

00:48:42.609 --> 00:48:42.619
the skin to accept that okay and we have
 

00:48:42.619 --> 00:48:44.289
the skin to accept that okay and we have
time for more question I'm gonna borrow

00:48:44.289 --> 00:48:44.299
time for more question I'm gonna borrow
 

00:48:44.299 --> 00:48:45.970
time for more question I'm gonna borrow
one from you yesterday on this stage you

00:48:45.970 --> 00:48:45.980
one from you yesterday on this stage you
 

00:48:45.980 --> 00:48:47.079
one from you yesterday on this stage you
said that everyone had to answer three

00:48:47.079 --> 00:48:47.089
said that everyone had to answer three
 

00:48:47.089 --> 00:48:49.120
said that everyone had to answer three
questions we have time for just one of

00:48:49.120 --> 00:48:49.130
questions we have time for just one of
 

00:48:49.130 --> 00:48:52.090
questions we have time for just one of
them so one of your questions was

00:48:52.090 --> 00:48:52.100
them so one of your questions was
 

00:48:52.100 --> 00:48:54.640
them so one of your questions was
think 10 years into the future what is

00:48:54.640 --> 00:48:54.650
think 10 years into the future what is
 

00:48:54.650 --> 00:48:56.170
think 10 years into the future what is
something that you were very excited

00:48:56.170 --> 00:48:56.180
something that you were very excited
 

00:48:56.180 --> 00:48:58.300
something that you were very excited
about hey I'm making possible that we

00:48:58.300 --> 00:48:58.310
about hey I'm making possible that we
 

00:48:58.310 --> 00:49:00.849
about hey I'm making possible that we
would improve the world in some way you

00:49:00.849 --> 00:49:00.859
would improve the world in some way you
 

00:49:00.859 --> 00:49:02.080
would improve the world in some way you
know maybe you could take us out on a

00:49:02.080 --> 00:49:02.090
know maybe you could take us out on a
 

00:49:02.090 --> 00:49:04.180
know maybe you could take us out on a
high note here that's a great question

00:49:04.180 --> 00:49:04.190
high note here that's a great question
 

00:49:04.190 --> 00:49:10.870
high note here that's a great question
so actually the quality of life of an

00:49:10.870 --> 00:49:10.880
so actually the quality of life of an
 

00:49:10.880 --> 00:49:12.490
so actually the quality of life of an
individual human is probably the thing

00:49:12.490 --> 00:49:12.500
individual human is probably the thing
 

00:49:12.500 --> 00:49:13.930
individual human is probably the thing
that I'm most excited about and so when

00:49:13.930 --> 00:49:13.940
that I'm most excited about and so when
 

00:49:13.940 --> 00:49:15.460
that I'm most excited about and so when
I look at everything from exoskeletal

00:49:15.460 --> 00:49:15.470
I look at everything from exoskeletal
 

00:49:15.470 --> 00:49:17.410
I look at everything from exoskeletal
structures that would allow somebody to

00:49:17.410 --> 00:49:17.420
structures that would allow somebody to
 

00:49:17.420 --> 00:49:21.340
structures that would allow somebody to
walk who were they to fall it would be a

00:49:21.340 --> 00:49:21.350
walk who were they to fall it would be a
 

00:49:21.350 --> 00:49:23.109
walk who were they to fall it would be a
huge change in quality of life but if

00:49:23.109 --> 00:49:23.119
huge change in quality of life but if
 

00:49:23.119 --> 00:49:24.970
huge change in quality of life but if
this system allows them to walk use

00:49:24.970 --> 00:49:24.980
this system allows them to walk use
 

00:49:24.980 --> 00:49:27.250
this system allows them to walk use
their musculature and if they start

00:49:27.250 --> 00:49:27.260
their musculature and if they start
 

00:49:27.260 --> 00:49:29.890
their musculature and if they start
falling it catches them I love that idea

00:49:29.890 --> 00:49:29.900
falling it catches them I love that idea
 

00:49:29.900 --> 00:49:31.599
falling it catches them I love that idea
I love the idea of extending people's

00:49:31.599 --> 00:49:31.609
I love the idea of extending people's
 

00:49:31.609 --> 00:49:33.310
I love the idea of extending people's
personal sense of agency and empowerment

00:49:33.310 --> 00:49:33.320
personal sense of agency and empowerment
 

00:49:33.320 --> 00:49:35.230
personal sense of agency and empowerment
and you can apply that in this

00:49:35.230 --> 00:49:35.240
and you can apply that in this
 

00:49:35.240 --> 00:49:37.320
and you can apply that in this
biological sense of you know muscular

00:49:37.320 --> 00:49:37.330
biological sense of you know muscular
 

00:49:37.330 --> 00:49:39.670
biological sense of you know muscular
exoskeletons and you can apply this in a

00:49:39.670 --> 00:49:39.680
exoskeletons and you can apply this in a
 

00:49:39.680 --> 00:49:43.300
exoskeletons and you can apply this in a
core cognitive orthotic sense the idea

00:49:43.300 --> 00:49:43.310
core cognitive orthotic sense the idea
 

00:49:43.310 --> 00:49:45.880
core cognitive orthotic sense the idea
that you can have cognitive systems that

00:49:45.880 --> 00:49:45.890
that you can have cognitive systems that
 

00:49:45.890 --> 00:49:48.340
that you can have cognitive systems that
work with a human not to replace their

00:49:48.340 --> 00:49:48.350
work with a human not to replace their
 

00:49:48.350 --> 00:49:50.230
work with a human not to replace their
thinking but to help them keep thinking

00:49:50.230 --> 00:49:50.240
thinking but to help them keep thinking
 

00:49:50.240 --> 00:49:52.450
thinking but to help them keep thinking
even as they're thinking degrades I

00:49:52.450 --> 00:49:52.460
even as they're thinking degrades I
 

00:49:52.460 --> 00:49:54.849
even as they're thinking degrades I
think is powerfully important to our own

00:49:54.849 --> 00:49:54.859
think is powerfully important to our own
 

00:49:54.859 --> 00:49:57.580
think is powerfully important to our own
ability to age gracefully and aged well

00:49:57.580 --> 00:49:57.590
ability to age gracefully and aged well
 

00:49:57.590 --> 00:49:59.859
ability to age gracefully and aged well
so to me that's the thing where I

00:49:59.859 --> 00:49:59.869
so to me that's the thing where I
 

00:49:59.869 --> 00:50:02.050
so to me that's the thing where I
believe those technologies based on the

00:50:02.050 --> 00:50:02.060
believe those technologies based on the
 

00:50:02.060 --> 00:50:03.310
believe those technologies based on the
cognitive side and on the muscular

00:50:03.310 --> 00:50:03.320
cognitive side and on the muscular
 

00:50:03.320 --> 00:50:06.160
cognitive side and on the muscular
skeletal side actually will come of age

00:50:06.160 --> 00:50:06.170
skeletal side actually will come of age
 

00:50:06.170 --> 00:50:08.349
skeletal side actually will come of age
in the next 10 to 15 years and it's a

00:50:08.349 --> 00:50:08.359
in the next 10 to 15 years and it's a
 

00:50:08.359 --> 00:50:10.120
in the next 10 to 15 years and it's a
sea change right I could go for a walk

00:50:10.120 --> 00:50:10.130
sea change right I could go for a walk
 

00:50:10.130 --> 00:50:13.510
sea change right I could go for a walk
with my great-grandfather a hike up a

00:50:13.510 --> 00:50:13.520
with my great-grandfather a hike up a
 

00:50:13.520 --> 00:50:15.609
with my great-grandfather a hike up a
trail at Yosemite which would be

00:50:15.609 --> 00:50:15.619
trail at Yosemite which would be
 

00:50:15.619 --> 00:50:18.010
trail at Yosemite which would be
unthinkable today and that I think is

00:50:18.010 --> 00:50:18.020
unthinkable today and that I think is
 

00:50:18.020 --> 00:50:20.440
unthinkable today and that I think is
very inspiring wonderful ok the nice

00:50:20.440 --> 00:50:20.450
very inspiring wonderful ok the nice
 

00:50:20.450 --> 00:50:21.970
very inspiring wonderful ok the nice
thing about the positive ELA thank you

00:50:21.970 --> 00:50:21.980
thing about the positive ELA thank you
 

00:50:21.980 --> 00:50:24.830
thing about the positive ELA thank you
so much

00:50:24.830 --> 00:50:24.840
 

00:50:24.840 --> 00:50:34.030
[Applause]

00:50:34.030 --> 00:50:34.040
 

00:50:34.040 --> 00:50:36.410
people are understanding that robot

00:50:36.410 --> 00:50:36.420
people are understanding that robot
 

00:50:36.420 --> 00:50:38.690
people are understanding that robot
systems don't exist in a vacuum that are

00:50:38.690 --> 00:50:38.700
systems don't exist in a vacuum that are
 

00:50:38.700 --> 00:50:41.030
systems don't exist in a vacuum that are
robots regardless of what they do are

00:50:41.030 --> 00:50:41.040
robots regardless of what they do are
 

00:50:41.040 --> 00:50:43.010
robots regardless of what they do are
going to have to interact with humans at

00:50:43.010 --> 00:50:43.020
going to have to interact with humans at
 

00:50:43.020 --> 00:50:44.540
going to have to interact with humans at
the end of the day these advances that

00:50:44.540 --> 00:50:44.550
the end of the day these advances that
 

00:50:44.550 --> 00:50:46.040
the end of the day these advances that
we're seeing in computer vision where

00:50:46.040 --> 00:50:46.050
we're seeing in computer vision where
 

00:50:46.050 --> 00:50:47.839
we're seeing in computer vision where
we're able to very very rapidly detect

00:50:47.839 --> 00:50:47.849
we're able to very very rapidly detect
 

00:50:47.849 --> 00:50:50.420
we're able to very very rapidly detect
people's facial expressions or people's

00:50:50.420 --> 00:50:50.430
people's facial expressions or people's
 

00:50:50.430 --> 00:50:52.430
people's facial expressions or people's
body posture through things like open

00:50:52.430 --> 00:50:52.440
body posture through things like open
 

00:50:52.440 --> 00:50:55.670
body posture through things like open
pose have enabled our systems to get the

00:50:55.670 --> 00:50:55.680
pose have enabled our systems to get the
 

00:50:55.680 --> 00:50:57.380
pose have enabled our systems to get the
data that they need in order to

00:50:57.380 --> 00:50:57.390
data that they need in order to
 

00:50:57.390 --> 00:51:00.050
data that they need in order to
interpret human social behavior and then

00:51:00.050 --> 00:51:00.060
interpret human social behavior and then
 

00:51:00.060 --> 00:51:02.240
interpret human social behavior and then
on the human robot interaction side all

00:51:02.240 --> 00:51:02.250
on the human robot interaction side all
 

00:51:02.250 --> 00:51:04.040
on the human robot interaction side all
of these you know many studies coming

00:51:04.040 --> 00:51:04.050
of these you know many studies coming
 

00:51:04.050 --> 00:51:05.210
of these you know many studies coming
out that are trying to understand how

00:51:05.210 --> 00:51:05.220
out that are trying to understand how
 

00:51:05.220 --> 00:51:06.859
out that are trying to understand how
people interact with robots in various

00:51:06.859 --> 00:51:06.869
people interact with robots in various
 

00:51:06.869 --> 00:51:09.319
people interact with robots in various
ways and how robots can interpret human

00:51:09.319 --> 00:51:09.329
ways and how robots can interpret human
 

00:51:09.329 --> 00:51:11.270
ways and how robots can interpret human
behavior and use their own social

00:51:11.270 --> 00:51:11.280
behavior and use their own social
 

00:51:11.280 --> 00:51:13.430
behavior and use their own social
behavior to improve the interactions

00:51:13.430 --> 00:51:13.440
behavior to improve the interactions
 

00:51:13.440 --> 00:51:16.430
behavior to improve the interactions
between human and robot and so on the

00:51:16.430 --> 00:51:16.440
between human and robot and so on the
 

00:51:16.440 --> 00:51:18.950
between human and robot and so on the
production and understanding side the

00:51:18.950 --> 00:51:18.960
production and understanding side the
 

00:51:18.960 --> 00:51:20.450
production and understanding side the
human robot interaction research is

00:51:20.450 --> 00:51:20.460
human robot interaction research is
 

00:51:20.460 --> 00:51:21.950
human robot interaction research is
going to play a big part my vision for

00:51:21.950 --> 00:51:21.960
going to play a big part my vision for
 

00:51:21.960 --> 00:51:23.569
going to play a big part my vision for
the future is that technology has a

00:51:23.569 --> 00:51:23.579
the future is that technology has a
 

00:51:23.579 --> 00:51:25.400
the future is that technology has a
positive impact we have to answer

00:51:25.400 --> 00:51:25.410
positive impact we have to answer
 

00:51:25.410 --> 00:51:27.530
positive impact we have to answer
questions about how our technology could

00:51:27.530 --> 00:51:27.540
questions about how our technology could
 

00:51:27.540 --> 00:51:29.240
questions about how our technology could
be used for good and could be used for

00:51:29.240 --> 00:51:29.250
be used for good and could be used for
 

00:51:29.250 --> 00:51:31.760
be used for good and could be used for
bad and how we can aim our technological

00:51:31.760 --> 00:51:31.770
bad and how we can aim our technological
 

00:51:31.770 --> 00:51:34.460
bad and how we can aim our technological
advances toward positive impact in the

00:51:34.460 --> 00:51:34.470
advances toward positive impact in the
 

00:51:34.470 --> 00:51:37.280
advances toward positive impact in the
world I think this really means that we

00:51:37.280 --> 00:51:37.290
world I think this really means that we
 

00:51:37.290 --> 00:51:39.079
world I think this really means that we
need to be multidisciplinary need to

00:51:39.079 --> 00:51:39.089
need to be multidisciplinary need to
 

00:51:39.089 --> 00:51:43.240
need to be multidisciplinary need to
pull in lawyers and policy makers and

00:51:43.240 --> 00:51:43.250
pull in lawyers and policy makers and
 

00:51:43.250 --> 00:51:46.880
pull in lawyers and policy makers and
people from social sciences and we also

00:51:46.880 --> 00:51:46.890
people from social sciences and we also
 

00:51:46.890 --> 00:51:48.770
people from social sciences and we also
need to pull in people from technology

00:51:48.770 --> 00:51:48.780
need to pull in people from technology
 

00:51:48.780 --> 00:51:51.109
need to pull in people from technology
who understand the capabilities of these

00:51:51.109 --> 00:51:51.119
who understand the capabilities of these
 

00:51:51.119 --> 00:51:52.490
who understand the capabilities of these
systems and understand what's even

00:51:52.490 --> 00:51:52.500
systems and understand what's even
 

00:51:52.500 --> 00:51:54.950
systems and understand what's even
possible to talk about in in terms of

00:51:54.950 --> 00:51:54.960
possible to talk about in in terms of
 

00:51:54.960 --> 00:52:02.750
possible to talk about in in terms of
the societal impact

00:52:02.750 --> 00:52:02.760
 

00:52:02.760 --> 00:52:06.140
so thanks to Allah for wonderful talk

00:52:06.140 --> 00:52:06.150
so thanks to Allah for wonderful talk
 

00:52:06.150 --> 00:52:08.540
so thanks to Allah for wonderful talk
and Tom for those great questions to

00:52:08.540 --> 00:52:08.550
and Tom for those great questions to
 

00:52:08.550 --> 00:52:09.770
and Tom for those great questions to
help explore some of these issues in

00:52:09.770 --> 00:52:09.780
help explore some of these issues in
 

00:52:09.780 --> 00:52:11.900
help explore some of these issues in
more detail we're going to shift now

00:52:11.900 --> 00:52:11.910
more detail we're going to shift now
 

00:52:11.910 --> 00:52:14.870
more detail we're going to shift now
into the second session of the

00:52:14.870 --> 00:52:14.880
into the second session of the
 

00:52:14.880 --> 00:52:17.990
into the second session of the
conference focused on trust so I think

00:52:17.990 --> 00:52:18.000
conference focused on trust so I think
 

00:52:18.000 --> 00:52:19.760
conference focused on trust so I think
it's very easy for people to focus on

00:52:19.760 --> 00:52:19.770
it's very easy for people to focus on
 

00:52:19.770 --> 00:52:21.470
it's very easy for people to focus on
the trust that we might or might not

00:52:21.470 --> 00:52:21.480
the trust that we might or might not
 

00:52:21.480 --> 00:52:23.630
the trust that we might or might not
have in the technologies but one of the

00:52:23.630 --> 00:52:23.640
have in the technologies but one of the
 

00:52:23.640 --> 00:52:25.130
have in the technologies but one of the
important questions is to really go

00:52:25.130 --> 00:52:25.140
important questions is to really go
 

00:52:25.140 --> 00:52:27.260
important questions is to really go
beyond that and to think about the trust

00:52:27.260 --> 00:52:27.270
beyond that and to think about the trust
 

00:52:27.270 --> 00:52:28.790
beyond that and to think about the trust
that we might have and those who develop

00:52:28.790 --> 00:52:28.800
that we might have and those who develop
 

00:52:28.800 --> 00:52:30.109
that we might have and those who develop
the technology or those who are

00:52:30.109 --> 00:52:30.119
the technology or those who are
 

00:52:30.119 --> 00:52:32.210
the technology or those who are
deploying and using the technology or

00:52:32.210 --> 00:52:32.220
deploying and using the technology or
 

00:52:32.220 --> 00:52:33.710
deploying and using the technology or
those who regulate and write the laws

00:52:33.710 --> 00:52:33.720
those who regulate and write the laws
 

00:52:33.720 --> 00:52:36.470
those who regulate and write the laws
about the technology or even more how

00:52:36.470 --> 00:52:36.480
about the technology or even more how
 

00:52:36.480 --> 00:52:38.120
about the technology or even more how
technology might change the

00:52:38.120 --> 00:52:38.130
technology might change the
 

00:52:38.130 --> 00:52:40.340
technology might change the
relationships of trust that we have with

00:52:40.340 --> 00:52:40.350
relationships of trust that we have with
 

00:52:40.350 --> 00:52:42.920
relationships of trust that we have with
one another so how can the development

00:52:42.920 --> 00:52:42.930
one another so how can the development
 

00:52:42.930 --> 00:52:45.920
one another so how can the development
of a new technology change our human

00:52:45.920 --> 00:52:45.930
of a new technology change our human
 

00:52:45.930 --> 00:52:47.480
of a new technology change our human
human interactions including those that

00:52:47.480 --> 00:52:47.490
human interactions including those that
 

00:52:47.490 --> 00:52:49.609
human interactions including those that
are grounded in this really fundamental

00:52:49.609 --> 00:52:49.619
are grounded in this really fundamental
 

00:52:49.619 --> 00:52:51.380
are grounded in this really fundamental
notion of trust so I'm going to be

00:52:51.380 --> 00:52:51.390
notion of trust so I'm going to be
 

00:52:51.390 --> 00:52:53.390
notion of trust so I'm going to be
exploring that over the next hour and a

00:52:53.390 --> 00:52:53.400
exploring that over the next hour and a
 

00:52:53.400 --> 00:52:56.260
exploring that over the next hour and a
half and through it through a variety of

00:52:56.260 --> 00:52:56.270
half and through it through a variety of
 

00:52:56.270 --> 00:52:58.970
half and through it through a variety of
formats and we're going to start with a

00:52:58.970 --> 00:52:58.980
formats and we're going to start with a
 

00:52:58.980 --> 00:53:01.310
formats and we're going to start with a
talk by one of our K&amp;L gates

00:53:01.310 --> 00:53:01.320
talk by one of our K&amp;L gates
 

00:53:01.320 --> 00:53:03.230
talk by one of our K&amp;L gates
presidential fellows abigail marsh

00:53:03.230 --> 00:53:03.240
presidential fellows abigail marsh
 

00:53:03.240 --> 00:53:05.780
presidential fellows abigail marsh
abigail was a double major in computer

00:53:05.780 --> 00:53:05.790
abigail was a double major in computer
 

00:53:05.790 --> 00:53:07.670
abigail was a double major in computer
science and mathematics at Oberlin

00:53:07.670 --> 00:53:07.680
science and mathematics at Oberlin
 

00:53:07.680 --> 00:53:10.820
science and mathematics at Oberlin
College in Ohio and is now a PhD student

00:53:10.820 --> 00:53:10.830
College in Ohio and is now a PhD student
 

00:53:10.830 --> 00:53:13.010
College in Ohio and is now a PhD student
in the societal computing program here

00:53:13.010 --> 00:53:13.020
in the societal computing program here
 

00:53:13.020 --> 00:53:15.170
in the societal computing program here
in the computer science department her

00:53:15.170 --> 00:53:15.180
in the computer science department her
 

00:53:15.180 --> 00:53:16.940
in the computer science department her
work really is focused on a notion of

00:53:16.940 --> 00:53:16.950
work really is focused on a notion of
 

00:53:16.950 --> 00:53:19.609
work really is focused on a notion of
usable privacy the idea of how do we

00:53:19.609 --> 00:53:19.619
usable privacy the idea of how do we
 

00:53:19.619 --> 00:53:22.820
usable privacy the idea of how do we
have privacy that is helping us achieve

00:53:22.820 --> 00:53:22.830
have privacy that is helping us achieve
 

00:53:22.830 --> 00:53:25.010
have privacy that is helping us achieve
the ends that we want and in particular

00:53:25.010 --> 00:53:25.020
the ends that we want and in particular
 

00:53:25.020 --> 00:53:27.170
the ends that we want and in particular
how that arises with adolescents and

00:53:27.170 --> 00:53:27.180
how that arises with adolescents and
 

00:53:27.180 --> 00:53:36.770
how that arises with adolescents and
teenagers so without further ado thank

00:53:36.770 --> 00:53:36.780
teenagers so without further ado thank
 

00:53:36.780 --> 00:53:38.750
teenagers so without further ado thank
you so much and thank you David for the

00:53:38.750 --> 00:53:38.760
you so much and thank you David for the
 

00:53:38.760 --> 00:53:40.310
you so much and thank you David for the
welcome that includes my undergraduate

00:53:40.310 --> 00:53:40.320
welcome that includes my undergraduate
 

00:53:40.320 --> 00:53:44.150
welcome that includes my undergraduate
education I really appreciate that um so

00:53:44.150 --> 00:53:44.160
education I really appreciate that um so
 

00:53:44.160 --> 00:53:47.000
education I really appreciate that um so
the funny thing about being a privacy

00:53:47.000 --> 00:53:47.010
the funny thing about being a privacy
 

00:53:47.010 --> 00:53:49.880
the funny thing about being a privacy
researcher is that when you see a news

00:53:49.880 --> 00:53:49.890
researcher is that when you see a news
 

00:53:49.890 --> 00:53:53.300
researcher is that when you see a news
story about some way that technology or

00:53:53.300 --> 00:53:53.310
story about some way that technology or
 

00:53:53.310 --> 00:53:55.940
story about some way that technology or
a tech company has violated trust you

00:53:55.940 --> 00:53:55.950
a tech company has violated trust you
 

00:53:55.950 --> 00:53:58.480
a tech company has violated trust you
actually see through that and you say oh

00:53:58.480 --> 00:53:58.490
actually see through that and you say oh
 

00:53:58.490 --> 00:54:01.310
actually see through that and you say oh
this is a privacy violation that these

00:54:01.310 --> 00:54:01.320
this is a privacy violation that these
 

00:54:01.320 --> 00:54:03.320
this is a privacy violation that these
people are really outraged about yes we

00:54:03.320 --> 00:54:03.330
people are really outraged about yes we
 

00:54:03.330 --> 00:54:06.500
people are really outraged about yes we
frame it in the public is trust but for

00:54:06.500 --> 00:54:06.510
frame it in the public is trust but for
 

00:54:06.510 --> 00:54:08.540
frame it in the public is trust but for
example you look at Cambridge analytic

00:54:08.540 --> 00:54:08.550
example you look at Cambridge analytic
 

00:54:08.550 --> 00:54:11.000
example you look at Cambridge analytic
as scandal recently Facebook has

00:54:11.000 --> 00:54:11.010
as scandal recently Facebook has
 

00:54:11.010 --> 00:54:13.630
as scandal recently Facebook has
multiple so let's focus on Cambridge and

00:54:13.630 --> 00:54:13.640
multiple so let's focus on Cambridge and
 

00:54:13.640 --> 00:54:15.540
multiple so let's focus on Cambridge and
you see that

00:54:15.540 --> 00:54:15.550
you see that
 

00:54:15.550 --> 00:54:19.320
you see that
what's really being talked about here is

00:54:19.320 --> 00:54:19.330
what's really being talked about here is
 

00:54:19.330 --> 00:54:22.200
what's really being talked about here is
the idea that Facebook would allow

00:54:22.200 --> 00:54:22.210
the idea that Facebook would allow
 

00:54:22.210 --> 00:54:24.900
the idea that Facebook would allow
outside parties to collect information

00:54:24.900 --> 00:54:24.910
outside parties to collect information
 

00:54:24.910 --> 00:54:28.140
outside parties to collect information
about people who did not consent to it

00:54:28.140 --> 00:54:28.150
about people who did not consent to it
 

00:54:28.150 --> 00:54:30.330
about people who did not consent to it
so they thought that information was

00:54:30.330 --> 00:54:30.340
so they thought that information was
 

00:54:30.340 --> 00:54:32.010
so they thought that information was
private they thought it was contained

00:54:32.010 --> 00:54:32.020
private they thought it was contained
 

00:54:32.020 --> 00:54:33.570
private they thought it was contained
within their social networks and

00:54:33.570 --> 00:54:33.580
within their social networks and
 

00:54:33.580 --> 00:54:35.600
within their social networks and
Facebook servers and they had no idea

00:54:35.600 --> 00:54:35.610
Facebook servers and they had no idea
 

00:54:35.610 --> 00:54:38.610
Facebook servers and they had no idea
that somebody outside of Facebook could

00:54:38.610 --> 00:54:38.620
that somebody outside of Facebook could
 

00:54:38.620 --> 00:54:41.250
that somebody outside of Facebook could
actually be harvesting it and using it

00:54:41.250 --> 00:54:41.260
actually be harvesting it and using it
 

00:54:41.260 --> 00:54:43.950
actually be harvesting it and using it
for unstated purposes that the user did

00:54:43.950 --> 00:54:43.960
for unstated purposes that the user did
 

00:54:43.960 --> 00:54:46.920
for unstated purposes that the user did
not get to consent to right and you also

00:54:46.920 --> 00:54:46.930
not get to consent to right and you also
 

00:54:46.930 --> 00:54:49.410
not get to consent to right and you also
see other examples of things like this

00:54:49.410 --> 00:54:49.420
see other examples of things like this
 

00:54:49.420 --> 00:54:51.510
see other examples of things like this
we talked a lot about algorithmic bias

00:54:51.510 --> 00:54:51.520
we talked a lot about algorithmic bias
 

00:54:51.520 --> 00:54:54.090
we talked a lot about algorithmic bias
and one way that privacy researchers

00:54:54.090 --> 00:54:54.100
and one way that privacy researchers
 

00:54:54.100 --> 00:54:55.500
and one way that privacy researchers
study algorithmic bias is through

00:54:55.500 --> 00:54:55.510
study algorithmic bias is through
 

00:54:55.510 --> 00:54:57.630
study algorithmic bias is through
behavioral advertising online behavioral

00:54:57.630 --> 00:54:57.640
behavioral advertising online behavioral
 

00:54:57.640 --> 00:54:59.160
behavioral advertising online behavioral
advertising where the fundamental

00:54:59.160 --> 00:54:59.170
advertising where the fundamental
 

00:54:59.170 --> 00:55:02.850
advertising where the fundamental
question is often how did this website

00:55:02.850 --> 00:55:02.860
question is often how did this website
 

00:55:02.860 --> 00:55:04.560
question is often how did this website
this advertising network which I've

00:55:04.560 --> 00:55:04.570
this advertising network which I've
 

00:55:04.570 --> 00:55:06.950
this advertising network which I've
never directly interacted with on my own

00:55:06.950 --> 00:55:06.960
never directly interacted with on my own
 

00:55:06.960 --> 00:55:09.570
never directly interacted with on my own
get this information about me to be able

00:55:09.570 --> 00:55:09.580
get this information about me to be able
 

00:55:09.580 --> 00:55:11.400
get this information about me to be able
to profile me and sell me these ads

00:55:11.400 --> 00:55:11.410
to profile me and sell me these ads
 

00:55:11.410 --> 00:55:14.310
to profile me and sell me these ads
which may be biased in some way as a

00:55:14.310 --> 00:55:14.320
which may be biased in some way as a
 

00:55:14.320 --> 00:55:16.020
which may be biased in some way as a
woman maybe I'm more likely to see

00:55:16.020 --> 00:55:16.030
woman maybe I'm more likely to see
 

00:55:16.030 --> 00:55:18.420
woman maybe I'm more likely to see
pregnancy-related ads or mother related

00:55:18.420 --> 00:55:18.430
pregnancy-related ads or mother related
 

00:55:18.430 --> 00:55:20.790
pregnancy-related ads or mother related
ads and I didn't even know that the

00:55:20.790 --> 00:55:20.800
ads and I didn't even know that the
 

00:55:20.800 --> 00:55:22.620
ads and I didn't even know that the
advertising network knew my gender to

00:55:22.620 --> 00:55:22.630
advertising network knew my gender to
 

00:55:22.630 --> 00:55:24.870
advertising network knew my gender to
begin with right so these trust

00:55:24.870 --> 00:55:24.880
begin with right so these trust
 

00:55:24.880 --> 00:55:26.700
begin with right so these trust
violations are actually privacy

00:55:26.700 --> 00:55:26.710
violations are actually privacy
 

00:55:26.710 --> 00:55:30.240
violations are actually privacy
violations in my own work I decided to

00:55:30.240 --> 00:55:30.250
violations in my own work I decided to
 

00:55:30.250 --> 00:55:34.290
violations in my own work I decided to
say privacy is is a fantastic area of

00:55:34.290 --> 00:55:34.300
say privacy is is a fantastic area of
 

00:55:34.300 --> 00:55:36.720
say privacy is is a fantastic area of
research for technologists but so far

00:55:36.720 --> 00:55:36.730
research for technologists but so far
 

00:55:36.730 --> 00:55:39.660
research for technologists but so far
it's really been focused on self

00:55:39.660 --> 00:55:39.670
it's really been focused on self
 

00:55:39.670 --> 00:55:42.270
it's really been focused on self
sufficient adults people in their 20s or

00:55:42.270 --> 00:55:42.280
sufficient adults people in their 20s or
 

00:55:42.280 --> 00:55:44.820
sufficient adults people in their 20s or
30s or 40s or 50s and I'm sorry for

00:55:44.820 --> 00:55:44.830
30s or 40s or 50s and I'm sorry for
 

00:55:44.830 --> 00:55:45.930
30s or 40s or 50s and I'm sorry for
those of you who've been left out of

00:55:45.930 --> 00:55:45.940
those of you who've been left out of
 

00:55:45.940 --> 00:55:48.180
those of you who've been left out of
that but that is the range that's

00:55:48.180 --> 00:55:48.190
that but that is the range that's
 

00:55:48.190 --> 00:55:50.790
that but that is the range that's
generally considered worth studying in a

00:55:50.790 --> 00:55:50.800
generally considered worth studying in a
 

00:55:50.800 --> 00:55:54.030
generally considered worth studying in a
lot of privacy research and there aren't

00:55:54.030 --> 00:55:54.040
lot of privacy research and there aren't
 

00:55:54.040 --> 00:55:57.510
lot of privacy research and there aren't
a lot of people who have focused on the

00:55:57.510 --> 00:55:57.520
a lot of people who have focused on the
 

00:55:57.520 --> 00:55:59.940
a lot of people who have focused on the
fact that people outside of that

00:55:59.940 --> 00:55:59.950
fact that people outside of that
 

00:55:59.950 --> 00:56:02.040
fact that people outside of that
relatively narrow range of human

00:56:02.040 --> 00:56:02.050
relatively narrow range of human
 

00:56:02.050 --> 00:56:03.840
relatively narrow range of human
experience are interacting with

00:56:03.840 --> 00:56:03.850
experience are interacting with
 

00:56:03.850 --> 00:56:05.360
experience are interacting with
technology sharing their information

00:56:05.360 --> 00:56:05.370
technology sharing their information
 

00:56:05.370 --> 00:56:07.620
technology sharing their information
with these websites and with the

00:56:07.620 --> 00:56:07.630
with these websites and with the
 

00:56:07.630 --> 00:56:10.020
with these websites and with the
software and therefore can experience

00:56:10.020 --> 00:56:10.030
software and therefore can experience
 

00:56:10.030 --> 00:56:13.470
software and therefore can experience
privacy violations as well many of you

00:56:13.470 --> 00:56:13.480
privacy violations as well many of you
 

00:56:13.480 --> 00:56:15.210
privacy violations as well many of you
in this room will have been parents or

00:56:15.210 --> 00:56:15.220
in this room will have been parents or
 

00:56:15.220 --> 00:56:17.460
in this room will have been parents or
if you are parents at the very least you

00:56:17.460 --> 00:56:17.470
if you are parents at the very least you
 

00:56:17.470 --> 00:56:19.680
if you are parents at the very least you
were a child at one point and you

00:56:19.680 --> 00:56:19.690
were a child at one point and you
 

00:56:19.690 --> 00:56:21.810
were a child at one point and you
probably recognize that the teenage

00:56:21.810 --> 00:56:21.820
probably recognize that the teenage
 

00:56:21.820 --> 00:56:23.970
probably recognize that the teenage
years are very difficult years it's hard

00:56:23.970 --> 00:56:23.980
years are very difficult years it's hard
 

00:56:23.980 --> 00:56:25.720
years are very difficult years it's hard
to raise a teenager

00:56:25.720 --> 00:56:25.730
to raise a teenager
 

00:56:25.730 --> 00:56:28.810
to raise a teenager
especially in today's era where teens

00:56:28.810 --> 00:56:28.820
especially in today's era where teens
 

00:56:28.820 --> 00:56:30.490
especially in today's era where teens
are spending a lot of time online or

00:56:30.490 --> 00:56:30.500
are spending a lot of time online or
 

00:56:30.500 --> 00:56:32.230
are spending a lot of time online or
spending time with their devices right

00:56:32.230 --> 00:56:32.240
spending time with their devices right
 

00:56:32.240 --> 00:56:36.010
spending time with their devices right
and so as a parent it's natural to want

00:56:36.010 --> 00:56:36.020
and so as a parent it's natural to want
 

00:56:36.020 --> 00:56:38.500
and so as a parent it's natural to want
some sort of assistance some sort of

00:56:38.500 --> 00:56:38.510
some sort of assistance some sort of
 

00:56:38.510 --> 00:56:40.180
some sort of assistance some sort of
help and there are a lot of software

00:56:40.180 --> 00:56:40.190
help and there are a lot of software
 

00:56:40.190 --> 00:56:42.760
help and there are a lot of software
aids that promise to parents oh we'll

00:56:42.760 --> 00:56:42.770
aids that promise to parents oh we'll
 

00:56:42.770 --> 00:56:44.770
aids that promise to parents oh we'll
take care of making sure that your child

00:56:44.770 --> 00:56:44.780
take care of making sure that your child
 

00:56:44.780 --> 00:56:48.340
take care of making sure that your child
stays out of bad websites or only uses

00:56:48.340 --> 00:56:48.350
stays out of bad websites or only uses
 

00:56:48.350 --> 00:56:49.990
stays out of bad websites or only uses
appropriate language or something like

00:56:49.990 --> 00:56:50.000
appropriate language or something like
 

00:56:50.000 --> 00:56:51.609
appropriate language or something like
that which seems like a miracle fix

00:56:51.609 --> 00:56:51.619
that which seems like a miracle fix
 

00:56:51.619 --> 00:56:54.430
that which seems like a miracle fix
right you can't be watching your child's

00:56:54.430 --> 00:56:54.440
right you can't be watching your child's
 

00:56:54.440 --> 00:56:56.109
right you can't be watching your child's
phone use over their shoulder every

00:56:56.109 --> 00:56:56.119
phone use over their shoulder every
 

00:56:56.119 --> 00:56:58.510
phone use over their shoulder every
second of the day so great install a

00:56:58.510 --> 00:56:58.520
second of the day so great install a
 

00:56:58.520 --> 00:57:00.550
second of the day so great install a
software and do that and these

00:57:00.550 --> 00:57:00.560
software and do that and these
 

00:57:00.560 --> 00:57:02.109
software and do that and these
software's offer a lot of benefits

00:57:02.109 --> 00:57:02.119
software's offer a lot of benefits
 

00:57:02.119 --> 00:57:04.599
software's offer a lot of benefits
especially for younger children maybe we

00:57:04.599 --> 00:57:04.609
especially for younger children maybe we
 

00:57:04.609 --> 00:57:06.730
especially for younger children maybe we
agree that five-year-old shouldn't have

00:57:06.730 --> 00:57:06.740
agree that five-year-old shouldn't have
 

00:57:06.740 --> 00:57:09.700
agree that five-year-old shouldn't have
access to pornography right so it's easy

00:57:09.700 --> 00:57:09.710
access to pornography right so it's easy
 

00:57:09.710 --> 00:57:12.670
access to pornography right so it's easy
to hit just block all porn and your

00:57:12.670 --> 00:57:12.680
to hit just block all porn and your
 

00:57:12.680 --> 00:57:14.710
to hit just block all porn and your
five-year-old can use your iPad without

00:57:14.710 --> 00:57:14.720
five-year-old can use your iPad without
 

00:57:14.720 --> 00:57:17.440
five-year-old can use your iPad without
any danger of a weird Google result sort

00:57:17.440 --> 00:57:17.450
any danger of a weird Google result sort
 

00:57:17.450 --> 00:57:18.940
any danger of a weird Google result sort
of like prompting that

00:57:18.940 --> 00:57:18.950
of like prompting that
 

00:57:18.950 --> 00:57:20.710
of like prompting that
birds-and-the-bees discussion a little

00:57:20.710 --> 00:57:20.720
birds-and-the-bees discussion a little
 

00:57:20.720 --> 00:57:24.130
birds-and-the-bees discussion a little
too early but it runs into a lot of

00:57:24.130 --> 00:57:24.140
too early but it runs into a lot of
 

00:57:24.140 --> 00:57:25.870
too early but it runs into a lot of
issues when we talk about teens and

00:57:25.870 --> 00:57:25.880
issues when we talk about teens and
 

00:57:25.880 --> 00:57:27.820
issues when we talk about teens and
preteens who are doing a lot of their

00:57:27.820 --> 00:57:27.830
preteens who are doing a lot of their
 

00:57:27.830 --> 00:57:29.410
preteens who are doing a lot of their
socialization and identity formation

00:57:29.410 --> 00:57:29.420
socialization and identity formation
 

00:57:29.420 --> 00:57:31.750
socialization and identity formation
online right they're talking to their

00:57:31.750 --> 00:57:31.760
online right they're talking to their
 

00:57:31.760 --> 00:57:33.670
online right they're talking to their
friends they're figuring out who they

00:57:33.670 --> 00:57:33.680
friends they're figuring out who they
 

00:57:33.680 --> 00:57:35.080
friends they're figuring out who they
are and some of that might mean

00:57:35.080 --> 00:57:35.090
are and some of that might mean
 

00:57:35.090 --> 00:57:37.620
are and some of that might mean
exploring concepts and topics that are

00:57:37.620 --> 00:57:37.630
exploring concepts and topics that are
 

00:57:37.630 --> 00:57:39.910
exploring concepts and topics that are
occasionally inappropriate and in

00:57:39.910 --> 00:57:39.920
occasionally inappropriate and in
 

00:57:39.920 --> 00:57:42.010
occasionally inappropriate and in
general might be inappropriate but are

00:57:42.010 --> 00:57:42.020
general might be inappropriate but are
 

00:57:42.020 --> 00:57:44.430
general might be inappropriate but are
necessary and important in certain

00:57:44.430 --> 00:57:44.440
necessary and important in certain
 

00:57:44.440 --> 00:57:47.650
necessary and important in certain
contexts right and there's a lot of

00:57:47.650 --> 00:57:47.660
contexts right and there's a lot of
 

00:57:47.660 --> 00:57:49.870
contexts right and there's a lot of
trust violations that these softwares

00:57:49.870 --> 00:57:49.880
trust violations that these softwares
 

00:57:49.880 --> 00:57:53.290
trust violations that these softwares
can pose as a child why would I want a

00:57:53.290 --> 00:57:53.300
can pose as a child why would I want a
 

00:57:53.300 --> 00:57:55.630
can pose as a child why would I want a
software like this on my phone how do I

00:57:55.630 --> 00:57:55.640
software like this on my phone how do I
 

00:57:55.640 --> 00:57:57.370
software like this on my phone how do I
know it's going to respect my autonomy

00:57:57.370 --> 00:57:57.380
know it's going to respect my autonomy
 

00:57:57.380 --> 00:57:59.950
know it's going to respect my autonomy
it's essentially designed to snitch on

00:57:59.950 --> 00:57:59.960
it's essentially designed to snitch on
 

00:57:59.960 --> 00:58:02.620
it's essentially designed to snitch on
everything I've ever done wrong and send

00:58:02.620 --> 00:58:02.630
everything I've ever done wrong and send
 

00:58:02.630 --> 00:58:04.510
everything I've ever done wrong and send
an alert directly to my parent at the

00:58:04.510 --> 00:58:04.520
an alert directly to my parent at the
 

00:58:04.520 --> 00:58:07.260
an alert directly to my parent at the
moment of violation that like hey

00:58:07.260 --> 00:58:07.270
moment of violation that like hey
 

00:58:07.270 --> 00:58:09.550
moment of violation that like hey
something is going wrong here you should

00:58:09.550 --> 00:58:09.560
something is going wrong here you should
 

00:58:09.560 --> 00:58:13.690
something is going wrong here you should
go punish your child right and even if

00:58:13.690 --> 00:58:13.700
go punish your child right and even if
 

00:58:13.700 --> 00:58:16.000
go punish your child right and even if
we don't consider the child's feelings

00:58:16.000 --> 00:58:16.010
we don't consider the child's feelings
 

00:58:16.010 --> 00:58:18.280
we don't consider the child's feelings
there's still the parents concerns about

00:58:18.280 --> 00:58:18.290
there's still the parents concerns about
 

00:58:18.290 --> 00:58:21.490
there's still the parents concerns about
trust right these software's can collect

00:58:21.490 --> 00:58:21.500
trust right these software's can collect
 

00:58:21.500 --> 00:58:24.730
trust right these software's can collect
a lot of information about what the kid

00:58:24.730 --> 00:58:24.740
a lot of information about what the kid
 

00:58:24.740 --> 00:58:26.349
a lot of information about what the kid
is doing with their phone some of them

00:58:26.349 --> 00:58:26.359
is doing with their phone some of them
 

00:58:26.359 --> 00:58:29.560
is doing with their phone some of them
suggest collecting every text message

00:58:29.560 --> 00:58:29.570
suggest collecting every text message
 

00:58:29.570 --> 00:58:31.300
suggest collecting every text message
the contents of every text message that

00:58:31.300 --> 00:58:31.310
the contents of every text message that
 

00:58:31.310 --> 00:58:33.190
the contents of every text message that
your child sends or every social media

00:58:33.190 --> 00:58:33.200
your child sends or every social media
 

00:58:33.200 --> 00:58:35.200
your child sends or every social media
message right that means

00:58:35.200 --> 00:58:35.210
message right that means
 

00:58:35.210 --> 00:58:39.130
message right that means
and and pictures I don't necessarily

00:58:39.130 --> 00:58:39.140
and and pictures I don't necessarily
 

00:58:39.140 --> 00:58:41.740
and and pictures I don't necessarily
want a company to have that data about

00:58:41.740 --> 00:58:41.750
want a company to have that data about
 

00:58:41.750 --> 00:58:45.480
want a company to have that data about
me or about my child and these are

00:58:45.480 --> 00:58:45.490
me or about my child and these are
 

00:58:45.490 --> 00:58:48.160
me or about my child and these are
concerns that parents have to face when

00:58:48.160 --> 00:58:48.170
concerns that parents have to face when
 

00:58:48.170 --> 00:58:50.799
concerns that parents have to face when
they choose to install a software like

00:58:50.799 --> 00:58:50.809
they choose to install a software like
 

00:58:50.809 --> 00:58:53.079
they choose to install a software like
this on their child's device right we

00:58:53.079 --> 00:58:53.089
this on their child's device right we
 

00:58:53.089 --> 00:58:54.700
this on their child's device right we
don't like when Google or Facebook has

00:58:54.700 --> 00:58:54.710
don't like when Google or Facebook has
 

00:58:54.710 --> 00:58:57.099
don't like when Google or Facebook has
this information but we're supposed to

00:58:57.099 --> 00:58:57.109
this information but we're supposed to
 

00:58:57.109 --> 00:58:59.559
this information but we're supposed to
be okay with it when a much smaller less

00:58:59.559 --> 00:58:59.569
be okay with it when a much smaller less
 

00:58:59.569 --> 00:59:01.990
be okay with it when a much smaller less
accountable company does and finally

00:59:01.990 --> 00:59:02.000
accountable company does and finally
 

00:59:02.000 --> 00:59:03.819
accountable company does and finally
there are questions of algorithmic

00:59:03.819 --> 00:59:03.829
there are questions of algorithmic
 

00:59:03.829 --> 00:59:06.579
there are questions of algorithmic
biases a lot of these softwares use ml

00:59:06.579 --> 00:59:06.589
biases a lot of these softwares use ml
 

00:59:06.589 --> 00:59:09.370
biases a lot of these softwares use ml
to do something like predictive blocking

00:59:09.370 --> 00:59:09.380
to do something like predictive blocking
 

00:59:09.380 --> 00:59:11.530
to do something like predictive blocking
of content within webpages but how do I

00:59:11.530 --> 00:59:11.540
of content within webpages but how do I
 

00:59:11.540 --> 00:59:14.680
of content within webpages but how do I
know as a parent that this opaque

00:59:14.680 --> 00:59:14.690
know as a parent that this opaque
 

00:59:14.690 --> 00:59:17.079
know as a parent that this opaque
algorithm is respecting my parenting

00:59:17.079 --> 00:59:17.089
algorithm is respecting my parenting
 

00:59:17.089 --> 00:59:18.730
algorithm is respecting my parenting
wishes is blocking what it should be and

00:59:18.730 --> 00:59:18.740
wishes is blocking what it should be and
 

00:59:18.740 --> 00:59:20.890
wishes is blocking what it should be and
is not blocking what it shouldn't be so

00:59:20.890 --> 00:59:20.900
is not blocking what it shouldn't be so
 

00:59:20.900 --> 00:59:23.799
is not blocking what it shouldn't be so
there are a lot of trust issues here

00:59:23.799 --> 00:59:23.809
there are a lot of trust issues here
 

00:59:23.809 --> 00:59:27.670
there are a lot of trust issues here
with technology that involve people

00:59:27.670 --> 00:59:27.680
with technology that involve people
 

00:59:27.680 --> 00:59:31.329
with technology that involve people
other than than self sufficient sort of

00:59:31.329 --> 00:59:31.339
other than than self sufficient sort of
 

00:59:31.339 --> 00:59:33.400
other than than self sufficient sort of
middle range adults who are willingly

00:59:33.400 --> 00:59:33.410
middle range adults who are willingly
 

00:59:33.410 --> 00:59:36.430
middle range adults who are willingly
interacting with the the software in

00:59:36.430 --> 00:59:36.440
interacting with the the software in
 

00:59:36.440 --> 00:59:39.220
interacting with the the software in
question and we need to continue to ask

00:59:39.220 --> 00:59:39.230
question and we need to continue to ask
 

00:59:39.230 --> 00:59:41.859
question and we need to continue to ask
questions about who is using this and

00:59:41.859 --> 00:59:41.869
questions about who is using this and
 

00:59:41.869 --> 00:59:43.990
questions about who is using this and
who is being affected so we make sure to

00:59:43.990 --> 00:59:44.000
who is being affected so we make sure to
 

00:59:44.000 --> 00:59:46.089
who is being affected so we make sure to
capture the experiences and the privacy

00:59:46.089 --> 00:59:46.099
capture the experiences and the privacy
 

00:59:46.099 --> 00:59:58.750
capture the experiences and the privacy
needs of everybody in our society thank

00:59:58.750 --> 00:59:58.760
needs of everybody in our society thank
 

00:59:58.760 --> 01:00:00.460
needs of everybody in our society thank
you so much happy really wonderful and

01:00:00.460 --> 01:00:00.470
you so much happy really wonderful and
 

01:00:00.470 --> 01:00:03.220
you so much happy really wonderful and
it's always wonderful to see the amazing

01:00:03.220 --> 01:00:03.230
it's always wonderful to see the amazing
 

01:00:03.230 --> 01:00:04.510
it's always wonderful to see the amazing
research that's being done by the

01:00:04.510 --> 01:00:04.520
research that's being done by the
 

01:00:04.520 --> 01:00:07.680
research that's being done by the
students here that it isn't simply

01:00:07.680 --> 01:00:07.690
students here that it isn't simply
 

01:00:07.690 --> 01:00:10.390
students here that it isn't simply
faculty it's the graduate students it's

01:00:10.390 --> 01:00:10.400
faculty it's the graduate students it's
 

01:00:10.400 --> 01:00:12.250
faculty it's the graduate students it's
the undergraduates it's the many people

01:00:12.250 --> 01:00:12.260
the undergraduates it's the many people
 

01:00:12.260 --> 01:00:14.049
the undergraduates it's the many people
around this community all engaged in

01:00:14.049 --> 01:00:14.059
around this community all engaged in
 

01:00:14.059 --> 01:00:17.799
around this community all engaged in
asking these kinds of questions so for

01:00:17.799 --> 01:00:17.809
asking these kinds of questions so for
 

01:00:17.809 --> 01:00:19.180
asking these kinds of questions so for
then for the next part of the session

01:00:19.180 --> 01:00:19.190
then for the next part of the session
 

01:00:19.190 --> 01:00:20.950
then for the next part of the session
we're gonna try something a little bit

01:00:20.950 --> 01:00:20.960
we're gonna try something a little bit
 

01:00:20.960 --> 01:00:22.960
we're gonna try something a little bit
different and and hopefully it will go

01:00:22.960 --> 01:00:22.970
different and and hopefully it will go
 

01:00:22.970 --> 01:00:26.140
different and and hopefully it will go
smoothly so we're going to ask three of

01:00:26.140 --> 01:00:26.150
smoothly so we're going to ask three of
 

01:00:26.150 --> 01:00:29.140
smoothly so we're going to ask three of
our distinguished guests to join us up

01:00:29.140 --> 01:00:29.150
our distinguished guests to join us up
 

01:00:29.150 --> 01:00:32.230
our distinguished guests to join us up
here and perhaps turn the tables a

01:00:32.230 --> 01:00:32.240
here and perhaps turn the tables a
 

01:00:32.240 --> 01:00:33.819
here and perhaps turn the tables a
little bit have them not simply be

01:00:33.819 --> 01:00:33.829
little bit have them not simply be
 

01:00:33.829 --> 01:00:36.910
little bit have them not simply be
speakers but also be moderators so what

01:00:36.910 --> 01:00:36.920
speakers but also be moderators so what
 

01:00:36.920 --> 01:00:37.990
speakers but also be moderators so what
we're calling I'm calling it a long

01:00:37.990 --> 01:00:38.000
we're calling I'm calling it a long
 

01:00:38.000 --> 01:00:40.299
we're calling I'm calling it a long
conversation and the idea is that we

01:00:40.299 --> 01:00:40.309
conversation and the idea is that we
 

01:00:40.309 --> 01:00:42.220
conversation and the idea is that we
will sequentially interview one another

01:00:42.220 --> 01:00:42.230
will sequentially interview one another
 

01:00:42.230 --> 01:00:43.960
will sequentially interview one another
for a brief period of time about five

01:00:43.960 --> 01:00:43.970
for a brief period of time about five
 

01:00:43.970 --> 01:00:45.730
for a brief period of time about five
minutes at which point there will be a

01:00:45.730 --> 01:00:45.740
minutes at which point there will be a
 

01:00:45.740 --> 01:00:48.160
minutes at which point there will be a
very discreet chime to let everyone know

01:00:48.160 --> 01:00:48.170
very discreet chime to let everyone know
 

01:00:48.170 --> 01:00:48.550
very discreet chime to let everyone know
that

01:00:48.550 --> 01:00:48.560
that
 

01:00:48.560 --> 01:00:50.500
that
going to move on in the next part of the

01:00:50.500 --> 01:00:50.510
going to move on in the next part of the
 

01:00:50.510 --> 01:00:51.640
going to move on in the next part of the
interview will happen and then we'll

01:00:51.640 --> 01:00:51.650
interview will happen and then we'll
 

01:00:51.650 --> 01:00:53.020
interview will happen and then we'll
we'll have a much broader conversation

01:00:53.020 --> 01:00:53.030
we'll have a much broader conversation
 

01:00:53.030 --> 01:00:55.540
we'll have a much broader conversation
among the four of us around issues of

01:00:55.540 --> 01:00:55.550
among the four of us around issues of
 

01:00:55.550 --> 01:00:58.720
among the four of us around issues of
trust so I'm delighted to invite up

01:00:58.720 --> 01:00:58.730
trust so I'm delighted to invite up
 

01:00:58.730 --> 01:01:00.100
trust so I'm delighted to invite up
three people

01:01:00.100 --> 01:01:00.110
three people
 

01:01:00.110 --> 01:01:02.380
three people
Kirsten vineyard is an expert in

01:01:02.380 --> 01:01:02.390
Kirsten vineyard is an expert in
 

01:01:02.390 --> 01:01:04.570
Kirsten vineyard is an expert in
international security policy with over

01:01:04.570 --> 01:01:04.580
international security policy with over
 

01:01:04.580 --> 01:01:06.550
international security policy with over
20 years of experience at the United

01:01:06.550 --> 01:01:06.560
20 years of experience at the United
 

01:01:06.560 --> 01:01:08.230
20 years of experience at the United
Nations she's currently the deputy

01:01:08.230 --> 01:01:08.240
Nations she's currently the deputy
 

01:01:08.240 --> 01:01:10.450
Nations she's currently the deputy
director and chief of operations at the

01:01:10.450 --> 01:01:10.460
director and chief of operations at the
 

01:01:10.460 --> 01:01:12.490
director and chief of operations at the
UN Institute for disarmament research

01:01:12.490 --> 01:01:12.500
UN Institute for disarmament research
 

01:01:12.500 --> 01:01:15.400
UN Institute for disarmament research
unity R and since 2013 she's led you

01:01:15.400 --> 01:01:15.410
unity R and since 2013 she's led you
 

01:01:15.410 --> 01:01:17.200
unity R and since 2013 she's led you
Nadir's work on the weaponization of

01:01:17.200 --> 01:01:17.210
Nadir's work on the weaponization of
 

01:01:17.210 --> 01:01:19.350
Nadir's work on the weaponization of
increasingly autonomous technologies

01:01:19.350 --> 01:01:19.360
increasingly autonomous technologies
 

01:01:19.360 --> 01:01:21.880
increasingly autonomous technologies
that sentence came out wrong she's led

01:01:21.880 --> 01:01:21.890
that sentence came out wrong she's led
 

01:01:21.890 --> 01:01:23.530
that sentence came out wrong she's led
the work on trying to understand the

01:01:23.530 --> 01:01:23.540
the work on trying to understand the
 

01:01:23.540 --> 01:01:25.480
the work on trying to understand the
impacts and how we might address the

01:01:25.480 --> 01:01:25.490
impacts and how we might address the
 

01:01:25.490 --> 01:01:26.920
impacts and how we might address the
weaponization she has not been

01:01:26.920 --> 01:01:26.930
weaponization she has not been
 

01:01:26.930 --> 01:01:30.670
weaponization she has not been
weaponizing technology herself she also

01:01:30.670 --> 01:01:30.680
weaponizing technology herself she also
 

01:01:30.680 --> 01:01:32.470
weaponizing technology herself she also
served as a consultant to four of the

01:01:32.470 --> 01:01:32.480
served as a consultant to four of the
 

01:01:32.480 --> 01:01:34.840
served as a consultant to four of the
five UN groups of governmental experts

01:01:34.840 --> 01:01:34.850
five UN groups of governmental experts
 

01:01:34.850 --> 01:01:38.020
five UN groups of governmental experts
on cyber security Moshe Vardy is the

01:01:38.020 --> 01:01:38.030
on cyber security Moshe Vardy is the
 

01:01:38.030 --> 01:01:39.550
on cyber security Moshe Vardy is the
George Distinguished Service professor

01:01:39.550 --> 01:01:39.560
George Distinguished Service professor
 

01:01:39.560 --> 01:01:41.710
George Distinguished Service professor
in computational engineering and

01:01:41.710 --> 01:01:41.720
in computational engineering and
 

01:01:41.720 --> 01:01:42.970
in computational engineering and
director of the Ken Kennedy Institute

01:01:42.970 --> 01:01:42.980
director of the Ken Kennedy Institute
 

01:01:42.980 --> 01:01:45.190
director of the Ken Kennedy Institute
for information technology at Rice

01:01:45.190 --> 01:01:45.200
for information technology at Rice
 

01:01:45.200 --> 01:01:47.500
for information technology at Rice
University he's a world leader on

01:01:47.500 --> 01:01:47.510
University he's a world leader on
 

01:01:47.510 --> 01:01:49.120
University he's a world leader on
automated reasoning and is the author

01:01:49.120 --> 01:01:49.130
automated reasoning and is the author
 

01:01:49.130 --> 01:01:52.810
automated reasoning and is the author
and co-author of over 500 papers as well

01:01:52.810 --> 01:01:52.820
and co-author of over 500 papers as well
 

01:01:52.820 --> 01:01:54.580
and co-author of over 500 papers as well
as two books he's received numerous

01:01:54.580 --> 01:01:54.590
as two books he's received numerous
 

01:01:54.590 --> 01:01:56.980
as two books he's received numerous
awards and honorary degrees and is a

01:01:56.980 --> 01:01:56.990
awards and honorary degrees and is a
 

01:01:56.990 --> 01:01:58.630
awards and honorary degrees and is a
member of five different national

01:01:58.630 --> 01:01:58.640
member of five different national
 

01:01:58.640 --> 01:02:00.490
member of five different national
academies including the US National

01:02:00.490 --> 01:02:00.500
academies including the US National
 

01:02:00.500 --> 01:02:02.290
academies including the US National
Academy of Engineering and the US

01:02:02.290 --> 01:02:02.300
Academy of Engineering and the US
 

01:02:02.300 --> 01:02:05.020
Academy of Engineering and the US
National Academy of Sciences finally

01:02:05.020 --> 01:02:05.030
National Academy of Sciences finally
 

01:02:05.030 --> 01:02:06.970
National Academy of Sciences finally
Manuela Veloso is the Herbert a Simon

01:02:06.970 --> 01:02:06.980
Manuela Veloso is the Herbert a Simon
 

01:02:06.980 --> 01:02:09.370
Manuela Veloso is the Herbert a Simon
University professor and head of the

01:02:09.370 --> 01:02:09.380
University professor and head of the
 

01:02:09.380 --> 01:02:10.720
University professor and head of the
machine learning department here at

01:02:10.720 --> 01:02:10.730
machine learning department here at
 

01:02:10.730 --> 01:02:12.760
machine learning department here at
Carnegie Mellon University she's

01:02:12.760 --> 01:02:12.770
Carnegie Mellon University she's
 

01:02:12.770 --> 01:02:14.830
Carnegie Mellon University she's
transformed our understanding of social

01:02:14.830 --> 01:02:14.840
transformed our understanding of social
 

01:02:14.840 --> 01:02:17.020
transformed our understanding of social
and collaborative robotics and has also

01:02:17.020 --> 01:02:17.030
and collaborative robotics and has also
 

01:02:17.030 --> 01:02:19.090
and collaborative robotics and has also
authored over 500 papers

01:02:19.090 --> 01:02:19.100
authored over 500 papers
 

01:02:19.100 --> 01:02:20.620
authored over 500 papers
she was named the Einstein chair

01:02:20.620 --> 01:02:20.630
she was named the Einstein chair
 

01:02:20.630 --> 01:02:22.450
she was named the Einstein chair
professor by the Chinese Academy of

01:02:22.450 --> 01:02:22.460
professor by the Chinese Academy of
 

01:02:22.460 --> 01:02:25.390
professor by the Chinese Academy of
Sciences in 2012 is a fellow of the

01:02:25.390 --> 01:02:25.400
Sciences in 2012 is a fellow of the
 

01:02:25.400 --> 01:02:26.770
Sciences in 2012 is a fellow of the
American Association for the Advancement

01:02:26.770 --> 01:02:26.780
American Association for the Advancement
 

01:02:26.780 --> 01:02:29.020
American Association for the Advancement
of science as well as the I Triple E and

01:02:29.020 --> 01:02:29.030
of science as well as the I Triple E and
 

01:02:29.030 --> 01:02:31.630
of science as well as the I Triple E and
triple AI and is a former president of

01:02:31.630 --> 01:02:31.640
triple AI and is a former president of
 

01:02:31.640 --> 01:02:34.720
triple AI and is a former president of
the triple AI so Kirsten Moshe and

01:02:34.720 --> 01:02:34.730
the triple AI so Kirsten Moshe and
 

01:02:34.730 --> 01:02:36.040
the triple AI so Kirsten Moshe and
Manuela if you could join me up here on

01:02:36.040 --> 01:02:36.050
Manuela if you could join me up here on
 

01:02:36.050 --> 01:02:38.210
Manuela if you could join me up here on
stage

01:02:38.210 --> 01:02:38.220
stage
 

01:02:38.220 --> 01:03:00.260
stage
[Applause]

01:03:00.260 --> 01:03:00.270
 

01:03:00.270 --> 01:03:05.069
so start with Kirsten in your view what

01:03:05.069 --> 01:03:05.079
so start with Kirsten in your view what
 

01:03:05.079 --> 01:03:07.109
so start with Kirsten in your view what
is the most important or challenging

01:03:07.109 --> 01:03:07.119
is the most important or challenging
 

01:03:07.119 --> 01:03:09.300
is the most important or challenging
aspect for trust in AI and robotic

01:03:09.300 --> 01:03:09.310
aspect for trust in AI and robotic
 

01:03:09.310 --> 01:03:11.640
aspect for trust in AI and robotic
technologies including their development

01:03:11.640 --> 01:03:11.650
technologies including their development
 

01:03:11.650 --> 01:03:16.170
technologies including their development
and use a nice simple question with only

01:03:16.170 --> 01:03:16.180
and use a nice simple question with only
 

01:03:16.180 --> 01:03:17.790
and use a nice simple question with only
one answer the only one answer will make

01:03:17.790 --> 01:03:17.800
one answer the only one answer will make
 

01:03:17.800 --> 01:03:20.280
one answer the only one answer will make
possible all right well I'm coming to

01:03:20.280 --> 01:03:20.290
possible all right well I'm coming to
 

01:03:20.290 --> 01:03:21.599
possible all right well I'm coming to
this conversation from an international

01:03:21.599 --> 01:03:21.609
this conversation from an international
 

01:03:21.609 --> 01:03:24.000
this conversation from an international
security and arms control perspective so

01:03:24.000 --> 01:03:24.010
security and arms control perspective so
 

01:03:24.010 --> 01:03:25.410
security and arms control perspective so
I guess you won't be surprised when I

01:03:25.410 --> 01:03:25.420
I guess you won't be surprised when I
 

01:03:25.420 --> 01:03:27.240
I guess you won't be surprised when I
say that I find the implications of the

01:03:27.240 --> 01:03:27.250
say that I find the implications of the
 

01:03:27.250 --> 01:03:30.059
say that I find the implications of the
weaponization of these technologies to

01:03:30.059 --> 01:03:30.069
weaponization of these technologies to
 

01:03:30.069 --> 01:03:34.020
weaponization of these technologies to
be a particularly important topic issues

01:03:34.020 --> 01:03:34.030
be a particularly important topic issues
 

01:03:34.030 --> 01:03:36.630
be a particularly important topic issues
surrounding transparency validation and

01:03:36.630 --> 01:03:36.640
surrounding transparency validation and
 

01:03:36.640 --> 01:03:38.790
surrounding transparency validation and
verification of algorithmic systems are

01:03:38.790 --> 01:03:38.800
verification of algorithmic systems are
 

01:03:38.800 --> 01:03:40.650
verification of algorithmic systems are
among the most important open questions

01:03:40.650 --> 01:03:40.660
among the most important open questions
 

01:03:40.660 --> 01:03:42.720
among the most important open questions
in AI today and they are equally

01:03:42.720 --> 01:03:42.730
in AI today and they are equally
 

01:03:42.730 --> 01:03:43.920
in AI today and they are equally
important from an arms control

01:03:43.920 --> 01:03:43.930
important from an arms control
 

01:03:43.930 --> 01:03:47.040
important from an arms control
perspective when we start considering

01:03:47.040 --> 01:03:47.050
perspective when we start considering
 

01:03:47.050 --> 01:03:48.839
perspective when we start considering
the implications of increasing autonomy

01:03:48.839 --> 01:03:48.849
the implications of increasing autonomy
 

01:03:48.849 --> 01:03:50.700
the implications of increasing autonomy
in weapons systems so I'm going to give

01:03:50.700 --> 01:03:50.710
in weapons systems so I'm going to give
 

01:03:50.710 --> 01:03:54.210
in weapons systems so I'm going to give
you three examples of how Trust in these

01:03:54.210 --> 01:03:54.220
you three examples of how Trust in these
 

01:03:54.220 --> 01:03:56.339
you three examples of how Trust in these
systems is challenged by developments in

01:03:56.339 --> 01:03:56.349
systems is challenged by developments in
 

01:03:56.349 --> 01:03:58.890
systems is challenged by developments in
AI so first we have challenges for

01:03:58.890 --> 01:03:58.900
AI so first we have challenges for
 

01:03:58.900 --> 01:04:00.630
AI so first we have challenges for
testing and verification of weapons

01:04:00.630 --> 01:04:00.640
testing and verification of weapons
 

01:04:00.640 --> 01:04:02.960
testing and verification of weapons
systems and it's probably pretty obvious

01:04:02.960 --> 01:04:02.970
systems and it's probably pretty obvious
 

01:04:02.970 --> 01:04:06.359
systems and it's probably pretty obvious
but you really want to trust your weapon

01:04:06.359 --> 01:04:06.369
but you really want to trust your weapon
 

01:04:06.369 --> 01:04:08.849
but you really want to trust your weapon
systems these are technologies that are

01:04:08.849 --> 01:04:08.859
systems these are technologies that are
 

01:04:08.859 --> 01:04:11.700
systems these are technologies that are
intentionally designed to do harm right

01:04:11.700 --> 01:04:11.710
intentionally designed to do harm right
 

01:04:11.710 --> 01:04:13.710
intentionally designed to do harm right
unlike many of the technologies that we

01:04:13.710 --> 01:04:13.720
unlike many of the technologies that we
 

01:04:13.720 --> 01:04:17.550
unlike many of the technologies that we
design and because of that as operators

01:04:17.550 --> 01:04:17.560
design and because of that as operators
 

01:04:17.560 --> 01:04:19.770
design and because of that as operators
of these systems you have a moral and

01:04:19.770 --> 01:04:19.780
of these systems you have a moral and
 

01:04:19.780 --> 01:04:21.359
of these systems you have a moral and
legal responsibilities probably at a

01:04:21.359 --> 01:04:21.369
legal responsibilities probably at a
 

01:04:21.369 --> 01:04:24.660
legal responsibilities probably at a
higher level as then you would have as

01:04:24.660 --> 01:04:24.670
higher level as then you would have as
 

01:04:24.670 --> 01:04:25.920
higher level as then you would have as
an operator of a different type of

01:04:25.920 --> 01:04:25.930
an operator of a different type of
 

01:04:25.930 --> 01:04:28.020
an operator of a different type of
technology that's not designed to cause

01:04:28.020 --> 01:04:28.030
technology that's not designed to cause
 

01:04:28.030 --> 01:04:31.380
technology that's not designed to cause
harm and one of the reasons that we

01:04:31.380 --> 01:04:31.390
harm and one of the reasons that we
 

01:04:31.390 --> 01:04:33.839
harm and one of the reasons that we
trust our weapon systems is because we

01:04:33.839 --> 01:04:33.849
trust our weapon systems is because we
 

01:04:33.849 --> 01:04:36.210
trust our weapon systems is because we
rigorously test them before deployment

01:04:36.210 --> 01:04:36.220
rigorously test them before deployment
 

01:04:36.220 --> 01:04:38.220
rigorously test them before deployment
and this isn't an aspiration it's

01:04:38.220 --> 01:04:38.230
and this isn't an aspiration it's
 

01:04:38.230 --> 01:04:39.660
and this isn't an aspiration it's
actually a legal requirement under

01:04:39.660 --> 01:04:39.670
actually a legal requirement under
 

01:04:39.670 --> 01:04:41.880
actually a legal requirement under
article 36 of the Additional Protocol

01:04:41.880 --> 01:04:41.890
article 36 of the Additional Protocol
 

01:04:41.890 --> 01:04:44.760
article 36 of the Additional Protocol
one to the Geneva Conventions so

01:04:44.760 --> 01:04:44.770
one to the Geneva Conventions so
 

01:04:44.770 --> 01:04:45.900
one to the Geneva Conventions so
increasing autonomy and weapons systems

01:04:45.900 --> 01:04:45.910
increasing autonomy and weapons systems
 

01:04:45.910 --> 01:04:48.599
increasing autonomy and weapons systems
challenges testing I'm due in large part

01:04:48.599 --> 01:04:48.609
challenges testing I'm due in large part
 

01:04:48.609 --> 01:04:50.750
challenges testing I'm due in large part
to issues of predictability

01:04:50.750 --> 01:04:50.760
to issues of predictability
 

01:04:50.760 --> 01:04:53.090
to issues of predictability
and it's further complicated in the case

01:04:53.090 --> 01:04:53.100
and it's further complicated in the case
 

01:04:53.100 --> 01:04:56.270
and it's further complicated in the case
of learning systems where the system

01:04:56.270 --> 01:04:56.280
of learning systems where the system
 

01:04:56.280 --> 01:04:59.560
of learning systems where the system
continues to learn post-deployment

01:04:59.560 --> 01:04:59.570
continues to learn post-deployment
 

01:04:59.570 --> 01:05:02.780
continues to learn post-deployment
and then verification which is a very

01:05:02.780 --> 01:05:02.790
and then verification which is a very
 

01:05:02.790 --> 01:05:05.599
and then verification which is a very
important concept in arms control we use

01:05:05.599 --> 01:05:05.609
important concept in arms control we use
 

01:05:05.609 --> 01:05:07.810
important concept in arms control we use
it as a stability mechanism verification

01:05:07.810 --> 01:05:07.820
it as a stability mechanism verification
 

01:05:07.820 --> 01:05:10.250
it as a stability mechanism verification
so how could international regulation of

01:05:10.250 --> 01:05:10.260
so how could international regulation of
 

01:05:10.260 --> 01:05:12.670
so how could international regulation of
military applications of AI be verified

01:05:12.670 --> 01:05:12.680
military applications of AI be verified
 

01:05:12.680 --> 01:05:16.400
military applications of AI be verified
verification usually involves counting

01:05:16.400 --> 01:05:16.410
verification usually involves counting
 

01:05:16.410 --> 01:05:20.540
verification usually involves counting
physical objects right so intangible

01:05:20.540 --> 01:05:20.550
physical objects right so intangible
 

01:05:20.550 --> 01:05:22.280
physical objects right so intangible
capabilities don't really work that way

01:05:22.280 --> 01:05:22.290
capabilities don't really work that way
 

01:05:22.290 --> 01:05:23.900
capabilities don't really work that way
and it's difficult to imagine that

01:05:23.900 --> 01:05:23.910
and it's difficult to imagine that
 

01:05:23.910 --> 01:05:26.000
and it's difficult to imagine that
states or even corporations would be

01:05:26.000 --> 01:05:26.010
states or even corporations would be
 

01:05:26.010 --> 01:05:28.940
states or even corporations would be
willing to permit inspection of their

01:05:28.940 --> 01:05:28.950
willing to permit inspection of their
 

01:05:28.950 --> 01:05:31.670
willing to permit inspection of their
code or algorithms and it's questionable

01:05:31.670 --> 01:05:31.680
code or algorithms and it's questionable
 

01:05:31.680 --> 01:05:33.050
code or algorithms and it's questionable
that even inspection would even be

01:05:33.050 --> 01:05:33.060
that even inspection would even be
 

01:05:33.060 --> 01:05:37.250
that even inspection would even be
useful at because determining whether or

01:05:37.250 --> 01:05:37.260
useful at because determining whether or
 

01:05:37.260 --> 01:05:38.570
useful at because determining whether or
not an algorithm is quote-unquote

01:05:38.570 --> 01:05:38.580
not an algorithm is quote-unquote
 

01:05:38.580 --> 01:05:41.900
not an algorithm is quote-unquote
militarized is probably near impossible

01:05:41.900 --> 01:05:41.910
militarized is probably near impossible
 

01:05:41.910 --> 01:05:44.870
militarized is probably near impossible
right because it's a dual use sort of

01:05:44.870 --> 01:05:44.880
right because it's a dual use sort of
 

01:05:44.880 --> 01:05:47.359
right because it's a dual use sort of
situation second example would be trust

01:05:47.359 --> 01:05:47.369
situation second example would be trust
 

01:05:47.369 --> 01:05:49.550
situation second example would be trust
by the user so machine learning systems

01:05:49.550 --> 01:05:49.560
by the user so machine learning systems
 

01:05:49.560 --> 01:05:53.150
by the user so machine learning systems
behave sometimes behave unexpectedly or

01:05:53.150 --> 01:05:53.160
behave sometimes behave unexpectedly or
 

01:05:53.160 --> 01:05:55.640
behave sometimes behave unexpectedly or
in unanticipated ways and in many cases

01:05:55.640 --> 01:05:55.650
in unanticipated ways and in many cases
 

01:05:55.650 --> 01:05:58.310
in unanticipated ways and in many cases
having AI helped us solve problems in

01:05:58.310 --> 01:05:58.320
having AI helped us solve problems in
 

01:05:58.320 --> 01:06:06.170
having AI helped us solve problems in
previously unimaginative AI but as we

01:06:06.170 --> 01:06:06.180
previously unimaginative AI but as we
 

01:06:06.180 --> 01:06:08.630
previously unimaginative AI but as we
become accustomed to AI enabled objects

01:06:08.630 --> 01:06:08.640
become accustomed to AI enabled objects
 

01:06:08.640 --> 01:06:11.540
become accustomed to AI enabled objects
behaving in surprising ways we're gonna

01:06:11.540 --> 01:06:11.550
behaving in surprising ways we're gonna
 

01:06:11.550 --> 01:06:14.120
behaving in surprising ways we're gonna
have one less metric to determine

01:06:14.120 --> 01:06:14.130
have one less metric to determine
 

01:06:14.130 --> 01:06:17.750
have one less metric to determine
whether a weapon system is behaving in a

01:06:17.750 --> 01:06:17.760
whether a weapon system is behaving in a
 

01:06:17.760 --> 01:06:20.390
whether a weapon system is behaving in a
way other than the way the operator

01:06:20.390 --> 01:06:20.400
way other than the way the operator
 

01:06:20.400 --> 01:06:23.540
way other than the way the operator
intended so that could be due to

01:06:23.540 --> 01:06:23.550
intended so that could be due to
 

01:06:23.550 --> 01:06:25.430
intended so that could be due to
internal error or it could be due to

01:06:25.430 --> 01:06:25.440
internal error or it could be due to
 

01:06:25.440 --> 01:06:27.380
internal error or it could be due to
malicious intervention within the system

01:06:27.380 --> 01:06:27.390
malicious intervention within the system
 

01:06:27.390 --> 01:06:29.210
malicious intervention within the system
and that's going to diminish the

01:06:29.210 --> 01:06:29.220
and that's going to diminish the
 

01:06:29.220 --> 01:06:30.830
and that's going to diminish the
operators ability to intervene or

01:06:30.830 --> 01:06:30.840
operators ability to intervene or
 

01:06:30.840 --> 01:06:33.980
operators ability to intervene or
exercise control and as military systems

01:06:33.980 --> 01:06:33.990
exercise control and as military systems
 

01:06:33.990 --> 01:06:35.690
exercise control and as military systems
become increasingly autonomous and

01:06:35.690 --> 01:06:35.700
become increasingly autonomous and
 

01:06:35.700 --> 01:06:38.990
become increasingly autonomous and
concurrently humans become decreasingly

01:06:38.990 --> 01:06:39.000
concurrently humans become decreasingly
 

01:06:39.000 --> 01:06:41.030
concurrently humans become decreasingly
present in their operation and oversight

01:06:41.030 --> 01:06:41.040
present in their operation and oversight
 

01:06:41.040 --> 01:06:43.400
present in their operation and oversight
there's a risk that humans no longer

01:06:43.400 --> 01:06:43.410
there's a risk that humans no longer
 

01:06:43.410 --> 01:06:46.190
there's a risk that humans no longer
serve as the redundant safety feature

01:06:46.190 --> 01:06:46.200
serve as the redundant safety feature
 

01:06:46.200 --> 01:06:48.230
serve as the redundant safety feature
which they currently serve in many

01:06:48.230 --> 01:06:48.240
which they currently serve in many
 

01:06:48.240 --> 01:06:50.060
which they currently serve in many
weapons systems I mean I think we're all

01:06:50.060 --> 01:06:50.070
weapons systems I mean I think we're all
 

01:06:50.070 --> 01:06:52.190
weapons systems I mean I think we're all
we've all know about the many nuclear

01:06:52.190 --> 01:06:52.200
we've all know about the many nuclear
 

01:06:52.200 --> 01:06:54.620
we've all know about the many nuclear
near-misses that have been avoided

01:06:54.620 --> 01:06:54.630
near-misses that have been avoided
 

01:06:54.630 --> 01:06:56.330
near-misses that have been avoided
because a human operator followed their

01:06:56.330 --> 01:06:56.340
because a human operator followed their
 

01:06:56.340 --> 01:06:58.370
because a human operator followed their
instincts rather than what the

01:06:58.370 --> 01:06:58.380
instincts rather than what the
 

01:06:58.380 --> 01:06:59.900
instincts rather than what the
technology was telling them what's

01:06:59.900 --> 01:06:59.910
technology was telling them what's
 

01:06:59.910 --> 01:07:01.730
technology was telling them what's
happening so if a humans no longer

01:07:01.730 --> 01:07:01.740
happening so if a humans no longer
 

01:07:01.740 --> 01:07:03.710
happening so if a humans no longer
capable of intervening

01:07:03.710 --> 01:07:03.720
capable of intervening
 

01:07:03.720 --> 01:07:09.020
capable of intervening
and oh my finish up that sentence you've

01:07:09.020 --> 01:07:09.030
and oh my finish up that sentence you've
 

01:07:09.030 --> 01:07:10.190
and oh my finish up that sentence you've
certainly finished the sentence all

01:07:10.190 --> 01:07:10.200
certainly finished the sentence all
 

01:07:10.200 --> 01:07:12.500
certainly finished the sentence all
right if they're no longer capable of

01:07:12.500 --> 01:07:12.510
right if they're no longer capable of
 

01:07:12.510 --> 01:07:16.280
right if they're no longer capable of
intervening due to speed or in your

01:07:16.280 --> 01:07:16.290
intervening due to speed or in your
 

01:07:16.290 --> 01:07:18.110
intervening due to speed or in your
ability to understand the system or

01:07:18.110 --> 01:07:18.120
ability to understand the system or
 

01:07:18.120 --> 01:07:20.980
ability to understand the system or
perhaps even worse we've left the human

01:07:20.980 --> 01:07:20.990
perhaps even worse we've left the human
 

01:07:20.990 --> 01:07:24.470
perhaps even worse we've left the human
on the loop marginally just in order to

01:07:24.470 --> 01:07:24.480
on the loop marginally just in order to
 

01:07:24.480 --> 01:07:27.770
on the loop marginally just in order to
serve as a scapegoat for technologic

01:07:27.770 --> 01:07:27.780
serve as a scapegoat for technologic
 

01:07:27.780 --> 01:07:29.810
serve as a scapegoat for technologic
technologies possible failings or

01:07:29.810 --> 01:07:29.820
technologies possible failings or
 

01:07:29.820 --> 01:07:31.790
technologies possible failings or
shortcomings and that's problematic so

01:07:31.790 --> 01:07:31.800
shortcomings and that's problematic so
 

01:07:31.800 --> 01:07:33.110
shortcomings and that's problematic so
those are two examples and maybe I'll

01:07:33.110 --> 01:07:33.120
those are two examples and maybe I'll
 

01:07:33.120 --> 01:07:34.580
those are two examples and maybe I'll
get a chance to tell your third I'm sure

01:07:34.580 --> 01:07:34.590
get a chance to tell your third I'm sure
 

01:07:34.590 --> 01:07:40.400
get a chance to tell your third I'm sure
there will be opportunities so good to

01:07:40.400 --> 01:07:40.410
there will be opportunities so good to
 

01:07:40.410 --> 01:07:44.150
there will be opportunities so good to
see much in your view what is the most

01:07:44.150 --> 01:07:44.160
see much in your view what is the most
 

01:07:44.160 --> 01:07:46.010
see much in your view what is the most
important or challenging aspect for

01:07:46.010 --> 01:07:46.020
important or challenging aspect for
 

01:07:46.020 --> 01:07:47.840
important or challenging aspect for
trust in AI and robotic technologies

01:07:47.840 --> 01:07:47.850
trust in AI and robotic technologies
 

01:07:47.850 --> 01:07:51.340
trust in AI and robotic technologies
including in their development and use

01:07:51.340 --> 01:07:51.350
including in their development and use
 

01:07:51.350 --> 01:07:54.770
including in their development and use
so I think it's important to recognize

01:07:54.770 --> 01:07:54.780
so I think it's important to recognize
 

01:07:54.780 --> 01:07:56.660
so I think it's important to recognize
that we have any situation right now

01:07:56.660 --> 01:07:56.670
that we have any situation right now
 

01:07:56.670 --> 01:07:59.720
that we have any situation right now
that we have I would say trust crisis

01:07:59.720 --> 01:07:59.730
that we have I would say trust crisis
 

01:07:59.730 --> 01:08:02.870
that we have I would say trust crisis
and and I want to read quotes from two

01:08:02.870 --> 01:08:02.880
and and I want to read quotes from two
 

01:08:02.880 --> 01:08:05.150
and and I want to read quotes from two
recent articles appear in the bossing in

01:08:05.150 --> 01:08:05.160
recent articles appear in the bossing in
 

01:08:05.160 --> 01:08:08.690
recent articles appear in the bossing in
fact in the world journal just peggy

01:08:08.690 --> 01:08:08.700
fact in the world journal just peggy
 

01:08:08.700 --> 01:08:11.600
fact in the world journal just peggy
noonan last october article somehow

01:08:11.600 --> 01:08:11.610
noonan last october article somehow
 

01:08:11.610 --> 01:08:13.370
noonan last october article somehow
talked about the gun issue and she tried

01:08:13.370 --> 01:08:13.380
talked about the gun issue and she tried
 

01:08:13.380 --> 01:08:15.080
talked about the gun issue and she tried
to explain why people buy guns and

01:08:15.080 --> 01:08:15.090
to explain why people buy guns and
 

01:08:15.090 --> 01:08:17.390
to explain why people buy guns and
argument I think is very weak but it

01:08:17.390 --> 01:08:17.400
argument I think is very weak but it
 

01:08:17.400 --> 01:08:19.060
argument I think is very weak but it
doesn't matter for the purpose of this

01:08:19.060 --> 01:08:19.070
doesn't matter for the purpose of this
 

01:08:19.070 --> 01:08:22.550
doesn't matter for the purpose of this
discussion and she writes because all of

01:08:22.550 --> 01:08:22.560
discussion and she writes because all of
 

01:08:22.560 --> 01:08:25.210
discussion and she writes because all of
the personal and financial information

01:08:25.210 --> 01:08:25.220
the personal and financial information
 

01:08:25.220 --> 01:08:29.540
the personal and financial information
got hacked in the latest breach because

01:08:29.540 --> 01:08:29.550
got hacked in the latest breach because
 

01:08:29.550 --> 01:08:32.000
got hacked in the latest breach because
the country because our country's real

01:08:32.000 --> 01:08:32.010
the country because our country's real
 

01:08:32.010 --> 01:08:35.020
the country because our country's real
overloads are in Silicon Valley and

01:08:35.020 --> 01:08:35.030
overloads are in Silicon Valley and
 

01:08:35.030 --> 01:08:39.410
overloads are in Silicon Valley and
appear to be moral Martians who operate

01:08:39.410 --> 01:08:39.420
appear to be moral Martians who operate
 

01:08:39.420 --> 01:08:43.850
appear to be moral Martians who operate
on some will new postmodern ethical

01:08:43.850 --> 01:08:43.860
on some will new postmodern ethical
 

01:08:43.860 --> 01:08:46.250
on some will new postmodern ethical
wavelengths I guess with financial

01:08:46.250 --> 01:08:46.260
wavelengths I guess with financial
 

01:08:46.260 --> 01:08:49.640
wavelengths I guess with financial
planning for immortality and they will

01:08:49.640 --> 01:08:49.650
planning for immortality and they will
 

01:08:49.650 --> 01:08:52.430
planning for immortality and they will
be the ones programming the robots that

01:08:52.430 --> 01:08:52.440
be the ones programming the robots that
 

01:08:52.440 --> 01:08:57.950
be the ones programming the robots that
will soon take all the jobs January of

01:08:57.950 --> 01:08:57.960
will soon take all the jobs January of
 

01:08:57.960 --> 01:09:01.460
will soon take all the jobs January of
this year Niall Ferguson most alarming

01:09:01.460 --> 01:09:01.470
this year Niall Ferguson most alarming
 

01:09:01.470 --> 01:09:04.850
this year Niall Ferguson most alarming
was the morphing of cyberspace into

01:09:04.850 --> 01:09:04.860
was the morphing of cyberspace into
 

01:09:04.860 --> 01:09:07.940
was the morphing of cyberspace into
Siberia not to mention the cyber

01:09:07.940 --> 01:09:07.950
Siberia not to mention the cyber
 

01:09:07.950 --> 01:09:08.900
Siberia not to mention the cyber
caliphates

01:09:08.900 --> 01:09:08.910
caliphates
 

01:09:08.910 --> 01:09:13.130
caliphates
a dark and lawless realm were malevolent

01:09:13.130 --> 01:09:13.140
a dark and lawless realm were malevolent
 

01:09:13.140 --> 01:09:16.959
a dark and lawless realm were malevolent
actors ranging from Russian trolls

01:09:16.959 --> 01:09:16.969
actors ranging from Russian trolls
 

01:09:16.969 --> 01:09:20.260
actors ranging from Russian trolls
- PO isis twitter users could work with

01:09:20.260 --> 01:09:20.270
- PO isis twitter users could work with
 

01:09:20.270 --> 01:09:23.829
- PO isis twitter users could work with
impurity to subvert the institutional

01:09:23.829 --> 01:09:23.839
impurity to subvert the institutional
 

01:09:23.839 --> 01:09:27.280
impurity to subvert the institutional
foundation of democracy if this does not

01:09:27.280 --> 01:09:27.290
foundation of democracy if this does not
 

01:09:27.290 --> 01:09:29.979
foundation of democracy if this does not
reflect a crisis in trust i don't know

01:09:29.979 --> 01:09:29.989
reflect a crisis in trust i don't know
 

01:09:29.989 --> 01:09:33.849
reflect a crisis in trust i don't know
what is so if we won't talk about trust

01:09:33.849 --> 01:09:33.859
what is so if we won't talk about trust
 

01:09:33.859 --> 01:09:36.579
what is so if we won't talk about trust
we have to stop thinking what does trust

01:09:36.579 --> 01:09:36.589
we have to stop thinking what does trust
 

01:09:36.589 --> 01:09:39.430
we have to stop thinking what does trust
mean so I kind of try to reflect a

01:09:39.430 --> 01:09:39.440
mean so I kind of try to reflect a
 

01:09:39.440 --> 01:09:42.660
mean so I kind of try to reflect a
little bit on my own personal experience

01:09:42.660 --> 01:09:42.670
little bit on my own personal experience
 

01:09:42.670 --> 01:09:46.539
little bit on my own personal experience
in in my military service in there in

01:09:46.539 --> 01:09:46.549
in in my military service in there in
 

01:09:46.549 --> 01:09:50.249
in in my military service in there in
the Israeli Defense Forces I went to

01:09:50.249 --> 01:09:50.259
the Israeli Defense Forces I went to
 

01:09:50.259 --> 01:09:54.039
the Israeli Defense Forces I went to
parachuting training and you jump from a

01:09:54.039 --> 01:09:54.049
parachuting training and you jump from a
 

01:09:54.049 --> 01:09:58.570
parachuting training and you jump from a
height of about 1,400 feet which is a

01:09:58.570 --> 01:09:58.580
height of about 1,400 feet which is a
 

01:09:58.580 --> 01:10:01.500
height of about 1,400 feet which is a
rather terrifying experience I mean you

01:10:01.500 --> 01:10:01.510
rather terrifying experience I mean you
 

01:10:01.510 --> 01:10:04.150
rather terrifying experience I mean you
you're back brain tells you you're going

01:10:04.150 --> 01:10:04.160
you're back brain tells you you're going
 

01:10:04.160 --> 01:10:05.800
you're back brain tells you you're going
to die because you're falling off the

01:10:05.800 --> 01:10:05.810
to die because you're falling off the
 

01:10:05.810 --> 01:10:08.500
to die because you're falling off the
cliff and you have to trust the

01:10:08.500 --> 01:10:08.510
cliff and you have to trust the
 

01:10:08.510 --> 01:10:10.959
cliff and you have to trust the
parachute and you have to trust the

01:10:10.959 --> 01:10:10.969
parachute and you have to trust the
 

01:10:10.969 --> 01:10:12.880
parachute and you have to trust the
parachute folder that folder it properly

01:10:12.880 --> 01:10:12.890
parachute folder that folder it properly
 

01:10:12.890 --> 01:10:17.709
parachute folder that folder it properly
so trust means vulnerability you need

01:10:17.709 --> 01:10:17.719
so trust means vulnerability you need
 

01:10:17.719 --> 01:10:19.660
so trust means vulnerability you need
trust when you have a sense of danger

01:10:19.660 --> 01:10:19.670
trust when you have a sense of danger
 

01:10:19.670 --> 01:10:22.450
trust when you have a sense of danger
and you're trusting something or someone

01:10:22.450 --> 01:10:22.460
and you're trusting something or someone
 

01:10:22.460 --> 01:10:26.140
and you're trusting something or someone
to help you face this danger and so

01:10:26.140 --> 01:10:26.150
to help you face this danger and so
 

01:10:26.150 --> 01:10:27.970
to help you face this danger and so
obviously if we're the crisis of trust

01:10:27.970 --> 01:10:27.980
obviously if we're the crisis of trust
 

01:10:27.980 --> 01:10:29.410
obviously if we're the crisis of trust
it means you're all feeling very

01:10:29.410 --> 01:10:29.420
it means you're all feeling very
 

01:10:29.420 --> 01:10:32.890
it means you're all feeling very
vulnerable and do we trust the

01:10:32.890 --> 01:10:32.900
vulnerable and do we trust the
 

01:10:32.900 --> 01:10:35.920
vulnerable and do we trust the
technology that is now providing us so I

01:10:35.920 --> 01:10:35.930
technology that is now providing us so I
 

01:10:35.930 --> 01:10:37.120
technology that is now providing us so I
think when it comes to cybersecurity

01:10:37.120 --> 01:10:37.130
think when it comes to cybersecurity
 

01:10:37.130 --> 01:10:39.340
think when it comes to cybersecurity
there's no cybersecurity there's either

01:10:39.340 --> 01:10:39.350
there's no cybersecurity there's either
 

01:10:39.350 --> 01:10:42.790
there's no cybersecurity there's either
insecurity it's a colossal failure of us

01:10:42.790 --> 01:10:42.800
insecurity it's a colossal failure of us
 

01:10:42.800 --> 01:10:45.520
insecurity it's a colossal failure of us
is a computing discipline as well as

01:10:45.520 --> 01:10:45.530
is a computing discipline as well as
 

01:10:45.530 --> 01:10:47.650
is a computing discipline as well as
they as they I think as a political

01:10:47.650 --> 01:10:47.660
they as they I think as a political
 

01:10:47.660 --> 01:10:49.870
they as they I think as a political
institution around us that we have not

01:10:49.870 --> 01:10:49.880
institution around us that we have not
 

01:10:49.880 --> 01:10:52.479
institution around us that we have not
set up better standard for cybersecurity

01:10:52.479 --> 01:10:52.489
set up better standard for cybersecurity
 

01:10:52.489 --> 01:10:55.660
set up better standard for cybersecurity
and now we are talking about do we trust

01:10:55.660 --> 01:10:55.670
and now we are talking about do we trust
 

01:10:55.670 --> 01:10:58.600
and now we are talking about do we trust
the day the decisions the machine will

01:10:58.600 --> 01:10:58.610
the day the decisions the machine will
 

01:10:58.610 --> 01:11:00.490
the day the decisions the machine will
make and we had a lot about equity and

01:11:00.490 --> 01:11:00.500
make and we had a lot about equity and
 

01:11:00.500 --> 01:11:03.459
make and we had a lot about equity and
biases and transparency and I have had

01:11:03.459 --> 01:11:03.469
biases and transparency and I have had
 

01:11:03.469 --> 01:11:06.100
biases and transparency and I have had
very little discussion should we

01:11:06.100 --> 01:11:06.110
very little discussion should we
 

01:11:06.110 --> 01:11:08.740
very little discussion should we
delegate this decision to machines you

01:11:08.740 --> 01:11:08.750
delegate this decision to machines you
 

01:11:08.750 --> 01:11:10.300
delegate this decision to machines you
know we are somehow as if we are living

01:11:10.300 --> 01:11:10.310
know we are somehow as if we are living
 

01:11:10.310 --> 01:11:12.640
know we are somehow as if we are living
in a deterministic universe in which

01:11:12.640 --> 01:11:12.650
in a deterministic universe in which
 

01:11:12.650 --> 01:11:14.320
in a deterministic universe in which
it's just determined the machines will

01:11:14.320 --> 01:11:14.330
it's just determined the machines will
 

01:11:14.330 --> 01:11:17.320
it's just determined the machines will
make these human decisions you know now

01:11:17.320 --> 01:11:17.330
make these human decisions you know now
 

01:11:17.330 --> 01:11:19.450
make these human decisions you know now
it's just deciding you know whether

01:11:19.450 --> 01:11:19.460
it's just deciding you know whether
 

01:11:19.460 --> 01:11:21.520
it's just deciding you know whether
you'll get power or not whether we'll

01:11:21.520 --> 01:11:21.530
you'll get power or not whether we'll
 

01:11:21.530 --> 01:11:23.290
you'll get power or not whether we'll
separate a child from their from their

01:11:23.290 --> 01:11:23.300
separate a child from their from their
 

01:11:23.300 --> 01:11:25.270
separate a child from their from their
family when is it going to be sighted

01:11:25.270 --> 01:11:25.280
family when is it going to be sighted
 

01:11:25.280 --> 01:11:27.040
family when is it going to be sighted
whom are you going to who's going to be

01:11:27.040 --> 01:11:27.050
whom are you going to who's going to be
 

01:11:27.050 --> 01:11:28.080
whom are you going to who's going to be
your mate you know will

01:11:28.080 --> 01:11:28.090
your mate you know will
 

01:11:28.090 --> 01:11:30.720
your mate you know will
we already heard everything why bother

01:11:30.720 --> 01:11:30.730
we already heard everything why bother
 

01:11:30.730 --> 01:11:32.730
we already heard everything why bother
with tinder you know we'll let the

01:11:32.730 --> 01:11:32.740
with tinder you know we'll let the
 

01:11:32.740 --> 01:11:34.170
with tinder you know we'll let the
Machine decide whom you should you

01:11:34.170 --> 01:11:34.180
Machine decide whom you should you
 

01:11:34.180 --> 01:11:38.250
Machine decide whom you should you
should go out with and so and the

01:11:38.250 --> 01:11:38.260
should go out with and so and the
 

01:11:38.260 --> 01:11:40.140
should go out with and so and the
reality is that people don't like to

01:11:40.140 --> 01:11:40.150
reality is that people don't like to
 

01:11:40.150 --> 01:11:42.510
reality is that people don't like to
talk so much here is that our life are

01:11:42.510 --> 01:11:42.520
talk so much here is that our life are
 

01:11:42.520 --> 01:11:45.620
talk so much here is that our life are
now with technology is be run by

01:11:45.620 --> 01:11:45.630
now with technology is be run by
 

01:11:45.630 --> 01:11:47.420
now with technology is be run by
incredibly large and powerful

01:11:47.420 --> 01:11:47.430
incredibly large and powerful
 

01:11:47.430 --> 01:11:50.540
incredibly large and powerful
corporations total equity of the five

01:11:50.540 --> 01:11:50.550
corporations total equity of the five
 

01:11:50.550 --> 01:11:53.040
corporations total equity of the five
tech companies over three trillion

01:11:53.040 --> 01:11:53.050
tech companies over three trillion
 

01:11:53.050 --> 01:11:55.290
tech companies over three trillion
dollars and one of the things we've

01:11:55.290 --> 01:11:55.300
dollars and one of the things we've
 

01:11:55.300 --> 01:11:57.270
dollars and one of the things we've
helped before there's no ethics when it

01:11:57.270 --> 01:11:57.280
helped before there's no ethics when it
 

01:11:57.280 --> 01:11:59.640
helped before there's no ethics when it
comes to corporations if it's if it's

01:11:59.640 --> 01:11:59.650
comes to corporations if it's if it's
 

01:11:59.650 --> 01:12:02.790
comes to corporations if it's if it's
legal they can do it and it makes money

01:12:02.790 --> 01:12:02.800
legal they can do it and it makes money
 

01:12:02.800 --> 01:12:12.420
legal they can do it and it makes money
they will do it we seem to be on this

01:12:12.420 --> 01:12:12.430
they will do it we seem to be on this
 

01:12:12.430 --> 01:12:16.410
they will do it we seem to be on this
one is quite a lot right new view what

01:12:16.410 --> 01:12:16.420
one is quite a lot right new view what
 

01:12:16.420 --> 01:12:17.580
one is quite a lot right new view what
is the most important or challenging

01:12:17.580 --> 01:12:17.590
is the most important or challenging
 

01:12:17.590 --> 01:12:19.800
is the most important or challenging
aspect for trust in iron robotic

01:12:19.800 --> 01:12:19.810
aspect for trust in iron robotic
 

01:12:19.810 --> 01:12:22.410
aspect for trust in iron robotic
technology including little development

01:12:22.410 --> 01:12:22.420
technology including little development
 

01:12:22.420 --> 01:12:27.870
technology including little development
and news so I have a more engineering

01:12:27.870 --> 01:12:27.880
and news so I have a more engineering
 

01:12:27.880 --> 01:12:32.250
and news so I have a more engineering
view of this trust question and more

01:12:32.250 --> 01:12:32.260
view of this trust question and more
 

01:12:32.260 --> 01:12:36.570
view of this trust question and more
kind of like I've been quite questioning

01:12:36.570 --> 01:12:36.580
kind of like I've been quite questioning
 

01:12:36.580 --> 01:12:40.290
kind of like I've been quite questioning
how can we do it better at really the

01:12:40.290 --> 01:12:40.300
how can we do it better at really the
 

01:12:40.300 --> 01:12:43.770
how can we do it better at really the
development level so we all want to

01:12:43.770 --> 01:12:43.780
development level so we all want to
 

01:12:43.780 --> 01:12:47.910
development level so we all want to
trust these machines but eventually we

01:12:47.910 --> 01:12:47.920
trust these machines but eventually we
 

01:12:47.920 --> 01:12:52.440
trust these machines but eventually we
have to interact with our PhD students

01:12:52.440 --> 01:12:52.450
have to interact with our PhD students
 

01:12:52.450 --> 01:12:54.870
have to interact with our PhD students
with our students to do PhD thesis to

01:12:54.870 --> 01:12:54.880
with our students to do PhD thesis to
 

01:12:54.880 --> 01:12:56.610
with our students to do PhD thesis to
advance the science of artificial

01:12:56.610 --> 01:12:56.620
advance the science of artificial
 

01:12:56.620 --> 01:12:59.310
advance the science of artificial
intelligence and robotics so how is my

01:12:59.310 --> 01:12:59.320
intelligence and robotics so how is my
 

01:12:59.320 --> 01:13:01.620
intelligence and robotics so how is my
dialogue with those students how is my

01:13:01.620 --> 01:13:01.630
dialogue with those students how is my
 

01:13:01.630 --> 01:13:06.210
dialogue with those students how is my
line of research how is like the steps

01:13:06.210 --> 01:13:06.220
line of research how is like the steps
 

01:13:06.220 --> 01:13:09.360
line of research how is like the steps
that we take to advance our science

01:13:09.360 --> 01:13:09.370
that we take to advance our science
 

01:13:09.370 --> 01:13:12.720
that we take to advance our science
going to be different because in fact we

01:13:12.720 --> 01:13:12.730
going to be different because in fact we
 

01:13:12.730 --> 01:13:14.040
going to be different because in fact we
care about trust

01:13:14.040 --> 01:13:14.050
care about trust
 

01:13:14.050 --> 01:13:19.170
care about trust
so my few remarks are really bringing

01:13:19.170 --> 01:13:19.180
so my few remarks are really bringing
 

01:13:19.180 --> 01:13:23.190
so my few remarks are really bringing
you down to not the army not the weapons

01:13:23.190 --> 01:13:23.200
you down to not the army not the weapons
 

01:13:23.200 --> 01:13:25.800
you down to not the army not the weapons
but to the moment in which you face a

01:13:25.800 --> 01:13:25.810
but to the moment in which you face a
 

01:13:25.810 --> 01:13:28.560
but to the moment in which you face a
computer and you have to type if these

01:13:28.560 --> 01:13:28.570
computer and you have to type if these
 

01:13:28.570 --> 01:13:30.570
computer and you have to type if these
than that and you have to program these

01:13:30.570 --> 01:13:30.580
than that and you have to program these
 

01:13:30.580 --> 01:13:33.540
than that and you have to program these
machines and you have to help build

01:13:33.540 --> 01:13:33.550
machines and you have to help build
 

01:13:33.550 --> 01:13:37.260
machines and you have to help build
programs for which eventually there will

01:13:37.260 --> 01:13:37.270
programs for which eventually there will
 

01:13:37.270 --> 01:13:40.300
programs for which eventually there will
be a change in society so

01:13:40.300 --> 01:13:40.310
be a change in society so
 

01:13:40.310 --> 01:13:43.210
be a change in society so
along those lines for me this question

01:13:43.210 --> 01:13:43.220
along those lines for me this question
 

01:13:43.220 --> 01:13:46.570
along those lines for me this question
of trust has to do with the fact that

01:13:46.570 --> 01:13:46.580
of trust has to do with the fact that
 

01:13:46.580 --> 01:13:49.270
of trust has to do with the fact that
our AI machinery our machine learning

01:13:49.270 --> 01:13:49.280
our AI machinery our machine learning
 

01:13:49.280 --> 01:13:52.990
our AI machinery our machine learning
our robotics machinery has been more of

01:13:52.990 --> 01:13:53.000
our robotics machinery has been more of
 

01:13:53.000 --> 01:13:55.420
our robotics machinery has been more of
a problem solver what's the shortest

01:13:55.420 --> 01:13:55.430
a problem solver what's the shortest
 

01:13:55.430 --> 01:13:58.690
a problem solver what's the shortest
path and we generate a solution but the

01:13:58.690 --> 01:13:58.700
path and we generate a solution but the
 

01:13:58.700 --> 01:14:00.820
path and we generate a solution but the
way that we actually function when

01:14:00.820 --> 01:14:00.830
way that we actually function when
 

01:14:00.830 --> 01:14:02.980
way that we actually function when
writing code when writing programs when

01:14:02.980 --> 01:14:02.990
writing code when writing programs when
 

01:14:02.990 --> 01:14:05.110
writing code when writing programs when
writing algorithms is that we don't have

01:14:05.110 --> 01:14:05.120
writing algorithms is that we don't have
 

01:14:05.120 --> 01:14:07.710
writing algorithms is that we don't have
the challenge of justifying or

01:14:07.710 --> 01:14:07.720
the challenge of justifying or
 

01:14:07.720 --> 01:14:11.350
the challenge of justifying or
explaining why did you say this was a

01:14:11.350 --> 01:14:11.360
explaining why did you say this was a
 

01:14:11.360 --> 01:14:13.300
explaining why did you say this was a
bottle why do you classify this as a

01:14:13.300 --> 01:14:13.310
bottle why do you classify this as a
 

01:14:13.310 --> 01:14:16.950
bottle why do you classify this as a
chair so the explanation part has been

01:14:16.950 --> 01:14:16.960
chair so the explanation part has been
 

01:14:16.960 --> 01:14:19.540
chair so the explanation part has been
what's present in the old days I mean

01:14:19.540 --> 01:14:19.550
what's present in the old days I mean
 

01:14:19.550 --> 01:14:21.100
what's present in the old days I mean
and it has been always kind of

01:14:21.100 --> 01:14:21.110
and it has been always kind of
 

01:14:21.110 --> 01:14:22.900
and it has been always kind of
underlying their research we even have

01:14:22.900 --> 01:14:22.910
underlying their research we even have
 

01:14:22.910 --> 01:14:24.970
underlying their research we even have
teasers on explanation based learning

01:14:24.970 --> 01:14:24.980
teasers on explanation based learning
 

01:14:24.980 --> 01:14:28.350
teasers on explanation based learning
when we have theses on all sorts of like

01:14:28.350 --> 01:14:28.360
when we have theses on all sorts of like
 

01:14:28.360 --> 01:14:32.590
when we have theses on all sorts of like
analogy trying to come up with like the

01:14:32.590 --> 01:14:32.600
analogy trying to come up with like the
 

01:14:32.600 --> 01:14:35.680
analogy trying to come up with like the
similarity between two problems and

01:14:35.680 --> 01:14:35.690
similarity between two problems and
 

01:14:35.690 --> 01:14:38.140
similarity between two problems and
justify that resemblance to make

01:14:38.140 --> 01:14:38.150
justify that resemblance to make
 

01:14:38.150 --> 01:14:41.650
justify that resemblance to make
adaptations so but it's not as present

01:14:41.650 --> 01:14:41.660
adaptations so but it's not as present
 

01:14:41.660 --> 01:14:44.710
adaptations so but it's not as present
now in terms of actually solving big

01:14:44.710 --> 01:14:44.720
now in terms of actually solving big
 

01:14:44.720 --> 01:14:47.820
now in terms of actually solving big
problems and still also being able to

01:14:47.820 --> 01:14:47.830
problems and still also being able to
 

01:14:47.830 --> 01:14:50.160
problems and still also being able to
justify if needed

01:14:50.160 --> 01:14:50.170
justify if needed
 

01:14:50.170 --> 01:14:53.140
justify if needed
and have our algorithms generate such

01:14:53.140 --> 01:14:53.150
and have our algorithms generate such
 

01:14:53.150 --> 01:14:55.900
and have our algorithms generate such
justifications so my research and my

01:14:55.900 --> 01:14:55.910
justifications so my research and my
 

01:14:55.910 --> 01:14:58.240
justifications so my research and my
understanding of trust leads me to for

01:14:58.240 --> 01:14:58.250
understanding of trust leads me to for
 

01:14:58.250 --> 01:15:01.150
understanding of trust leads me to for
example have our autonomous robots who

01:15:01.150 --> 01:15:01.160
example have our autonomous robots who
 

01:15:01.160 --> 01:15:03.340
example have our autonomous robots who
actually navigate in our environments

01:15:03.340 --> 01:15:03.350
actually navigate in our environments
 

01:15:03.350 --> 01:15:06.100
actually navigate in our environments
arrive to our office and be able to

01:15:06.100 --> 01:15:06.110
arrive to our office and be able to
 

01:15:06.110 --> 01:15:08.680
arrive to our office and be able to
answer in language and not in whatever

01:15:08.680 --> 01:15:08.690
answer in language and not in whatever
 

01:15:08.690 --> 01:15:11.050
answer in language and not in whatever
language they use internally of numbers

01:15:11.050 --> 01:15:11.060
language they use internally of numbers
 

01:15:11.060 --> 01:15:14.280
language they use internally of numbers
and probability and all sorts of like

01:15:14.280 --> 01:15:14.290
and probability and all sorts of like
 

01:15:14.290 --> 01:15:18.190
and probability and all sorts of like
functions in language why are you late

01:15:18.190 --> 01:15:18.200
functions in language why are you late
 

01:15:18.200 --> 01:15:22.960
functions in language why are you late
and why did you take that route and what

01:15:22.960 --> 01:15:22.970
and why did you take that route and what
 

01:15:22.970 --> 01:15:26.890
and why did you take that route and what
are you going to do next so I believe

01:15:26.890 --> 01:15:26.900
are you going to do next so I believe
 

01:15:26.900 --> 01:15:29.110
are you going to do next so I believe
that trust comes from the interaction

01:15:29.110 --> 01:15:29.120
that trust comes from the interaction
 

01:15:29.120 --> 01:15:32.280
that trust comes from the interaction
with the device with the machine and

01:15:32.280 --> 01:15:32.290
with the device with the machine and
 

01:15:32.290 --> 01:15:35.110
with the device with the machine and
eventually that machine needs to be able

01:15:35.110 --> 01:15:35.120
eventually that machine needs to be able
 

01:15:35.120 --> 01:15:39.640
eventually that machine needs to be able
to be queried needs to be able to be

01:15:39.640 --> 01:15:39.650
to be queried needs to be able to be
 

01:15:39.650 --> 01:15:42.040
to be queried needs to be able to be
questioned about the decisions that

01:15:42.040 --> 01:15:42.050
questioned about the decisions that
 

01:15:42.050 --> 01:15:44.590
questioned about the decisions that
actually they made towards solving

01:15:44.590 --> 01:15:44.600
actually they made towards solving
 

01:15:44.600 --> 01:15:46.570
actually they made towards solving
whatever problem we asked them to solve

01:15:46.570 --> 01:15:46.580
whatever problem we asked them to solve
 

01:15:46.580 --> 01:15:50.110
whatever problem we asked them to solve
so in that sense for me Trust has to do

01:15:50.110 --> 01:15:50.120
so in that sense for me Trust has to do
 

01:15:50.120 --> 01:15:52.750
so in that sense for me Trust has to do
a lot with transparency

01:15:52.750 --> 01:15:52.760
a lot with transparency
 

01:15:52.760 --> 01:15:57.460
a lot with transparency
with explanation with counterfactuals

01:15:57.460 --> 01:15:57.470
with explanation with counterfactuals
 

01:15:57.470 --> 01:16:00.460
with explanation with counterfactuals
can we ask a machine what if you had

01:16:00.460 --> 01:16:00.470
can we ask a machine what if you had
 

01:16:00.470 --> 01:16:02.229
can we ask a machine what if you had
done something different can these

01:16:02.229 --> 01:16:02.239
done something different can these
 

01:16:02.239 --> 01:16:04.090
done something different can these
machine process these type of questions

01:16:04.090 --> 01:16:04.100
machine process these type of questions
 

01:16:04.100 --> 01:16:08.740
machine process these type of questions
and be more explicit about whatever

01:16:08.740 --> 01:16:08.750
and be more explicit about whatever
 

01:16:08.750 --> 01:16:11.800
and be more explicit about whatever
algorithm they are running and what the

01:16:11.800 --> 01:16:11.810
algorithm they are running and what the
 

01:16:11.810 --> 01:16:14.910
algorithm they are running and what the
solution would be all those scenarios so

01:16:14.910 --> 01:16:14.920
solution would be all those scenarios so
 

01:16:14.920 --> 01:16:18.100
solution would be all those scenarios so
transparency and explanation I think are

01:16:18.100 --> 01:16:18.110
transparency and explanation I think are
 

01:16:18.110 --> 01:16:20.140
transparency and explanation I think are
part of the internals of AI machines

01:16:20.140 --> 01:16:20.150
part of the internals of AI machines
 

01:16:20.150 --> 01:16:22.979
part of the internals of AI machines
that may enable us to build more trust

01:16:22.979 --> 01:16:22.989
that may enable us to build more trust
 

01:16:22.989 --> 01:16:27.940
that may enable us to build more trust
in what they do thanks to all three of

01:16:27.940 --> 01:16:27.950
in what they do thanks to all three of
 

01:16:27.950 --> 01:16:29.950
in what they do thanks to all three of
you really got got some wonderful issues

01:16:29.950 --> 01:16:29.960
you really got got some wonderful issues
 

01:16:29.960 --> 01:16:32.440
you really got got some wonderful issues
out on the table and so I actually would

01:16:32.440 --> 01:16:32.450
out on the table and so I actually would
 

01:16:32.450 --> 01:16:34.240
out on the table and so I actually would
like to start Manuela if it's okay with

01:16:34.240 --> 01:16:34.250
like to start Manuela if it's okay with
 

01:16:34.250 --> 01:16:35.500
like to start Manuela if it's okay with
you with what you were just talking

01:16:35.500 --> 01:16:35.510
you with what you were just talking
 

01:16:35.510 --> 01:16:37.479
you with what you were just talking
about in terms of the transparency and

01:16:37.479 --> 01:16:37.489
about in terms of the transparency and
 

01:16:37.489 --> 01:16:39.670
about in terms of the transparency and
explain ability and I think one question

01:16:39.670 --> 01:16:39.680
explain ability and I think one question
 

01:16:39.680 --> 01:16:41.260
explain ability and I think one question
that comes up when we think about the

01:16:41.260 --> 01:16:41.270
that comes up when we think about the
 

01:16:41.270 --> 01:16:43.840
that comes up when we think about the
trust is perhaps transparency for whom

01:16:43.840 --> 01:16:43.850
trust is perhaps transparency for whom
 

01:16:43.850 --> 01:16:45.850
trust is perhaps transparency for whom
or explain ability for whom because of

01:16:45.850 --> 01:16:45.860
or explain ability for whom because of
 

01:16:45.860 --> 01:16:46.840
or explain ability for whom because of
course something that would be

01:16:46.840 --> 01:16:46.850
course something that would be
 

01:16:46.850 --> 01:16:49.900
course something that would be
understandable or explainable to a PhD

01:16:49.900 --> 01:16:49.910
understandable or explainable to a PhD
 

01:16:49.910 --> 01:16:51.280
understandable or explainable to a PhD
graduate student might be very different

01:16:51.280 --> 01:16:51.290
graduate student might be very different
 

01:16:51.290 --> 01:16:54.040
graduate student might be very different
from somebody on the street who doesn't

01:16:54.040 --> 01:16:54.050
from somebody on the street who doesn't
 

01:16:54.050 --> 01:16:55.930
from somebody on the street who doesn't
know as much about the technology so how

01:16:55.930 --> 01:16:55.940
know as much about the technology so how
 

01:16:55.940 --> 01:16:57.010
know as much about the technology so how
do we think about these different

01:16:57.010 --> 01:16:57.020
do we think about these different
 

01:16:57.020 --> 01:17:00.880
do we think about these different
audiences for explain ability it's a

01:17:00.880 --> 01:17:00.890
audiences for explain ability it's a
 

01:17:00.890 --> 01:17:02.580
audiences for explain ability it's a
very good question not only the

01:17:02.580 --> 01:17:02.590
very good question not only the
 

01:17:02.590 --> 01:17:05.410
very good question not only the
different audiences but also different

01:17:05.410 --> 01:17:05.420
different audiences but also different
 

01:17:05.420 --> 01:17:08.250
different audiences but also different
moments in time even for someone that

01:17:08.250 --> 01:17:08.260
moments in time even for someone that
 

01:17:08.260 --> 01:17:11.500
moments in time even for someone that
interacts with the robot or with the

01:17:11.500 --> 01:17:11.510
interacts with the robot or with the
 

01:17:11.510 --> 01:17:13.330
interacts with the robot or with the
agent many times you don't want to

01:17:13.330 --> 01:17:13.340
agent many times you don't want to
 

01:17:13.340 --> 01:17:15.430
agent many times you don't want to
produce the same explanation today that

01:17:15.430 --> 01:17:15.440
produce the same explanation today that
 

01:17:15.440 --> 01:17:17.800
produce the same explanation today that
you produced yesterday or it's otherwise

01:17:17.800 --> 01:17:17.810
you produced yesterday or it's otherwise
 

01:17:17.810 --> 01:17:20.050
you produced yesterday or it's otherwise
it's just you are telling me the same

01:17:20.050 --> 01:17:20.060
it's just you are telling me the same
 

01:17:20.060 --> 01:17:22.720
it's just you are telling me the same
thing and that didn't help me so we

01:17:22.720 --> 01:17:22.730
thing and that didn't help me so we
 

01:17:22.730 --> 01:17:25.600
thing and that didn't help me so we
actually introduced this concept of a

01:17:25.600 --> 01:17:25.610
actually introduced this concept of a
 

01:17:25.610 --> 01:17:28.660
actually introduced this concept of a
space of explanations a space of

01:17:28.660 --> 01:17:28.670
space of explanations a space of
 

01:17:28.670 --> 01:17:31.750
space of explanations a space of
verbalization together with one of my

01:17:31.750 --> 01:17:31.760
verbalization together with one of my
 

01:17:31.760 --> 01:17:34.600
verbalization together with one of my
students eyes of raj and vittorio

01:17:34.600 --> 01:17:34.610
students eyes of raj and vittorio
 

01:17:34.610 --> 01:17:37.210
students eyes of raj and vittorio
pereira and stephanie Rosenthal and we

01:17:37.210 --> 01:17:37.220
pereira and stephanie Rosenthal and we
 

01:17:37.220 --> 01:17:38.770
pereira and stephanie Rosenthal and we
have been working on this issue about

01:17:38.770 --> 01:17:38.780
have been working on this issue about
 

01:17:38.780 --> 01:17:43.000
have been working on this issue about
the the multiple facets of explanations

01:17:43.000 --> 01:17:43.010
the the multiple facets of explanations
 

01:17:43.010 --> 01:17:46.060
the the multiple facets of explanations
and in fact trust these levels of trust

01:17:46.060 --> 01:17:46.070
and in fact trust these levels of trust
 

01:17:46.070 --> 01:17:48.340
and in fact trust these levels of trust
is levels of transparency this level of

01:17:48.340 --> 01:17:48.350
is levels of transparency this level of
 

01:17:48.350 --> 01:17:53.170
is levels of transparency this level of
explanation are not a single entity like

01:17:53.170 --> 01:17:53.180
explanation are not a single entity like
 

01:17:53.180 --> 01:17:55.360
explanation are not a single entity like
you say a single kind of like concept

01:17:55.360 --> 01:17:55.370
you say a single kind of like concept
 

01:17:55.370 --> 01:17:57.490
you say a single kind of like concept
and we have done some machine learning

01:17:57.490 --> 01:17:57.500
and we have done some machine learning
 

01:17:57.500 --> 01:18:00.610
and we have done some machine learning
on crowdsourcing people and trying to

01:18:00.610 --> 01:18:00.620
on crowdsourcing people and trying to
 

01:18:00.620 --> 01:18:03.760
on crowdsourcing people and trying to
understand if someone asks what what

01:18:03.760 --> 01:18:03.770
understand if someone asks what what
 

01:18:03.770 --> 01:18:04.670
understand if someone asks what what
exactly

01:18:04.670 --> 01:18:04.680
exactly
 

01:18:04.680 --> 01:18:07.730
exactly
you happen by the elevator that that

01:18:07.730 --> 01:18:07.740
you happen by the elevator that that
 

01:18:07.740 --> 01:18:10.430
you happen by the elevator that that
exactly by the hell by the elevator

01:18:10.430 --> 01:18:10.440
exactly by the hell by the elevator
 

01:18:10.440 --> 01:18:12.530
exactly by the hell by the elevator
would be something that would require a

01:18:12.530 --> 01:18:12.540
would be something that would require a
 

01:18:12.540 --> 01:18:15.440
would be something that would require a
much more narrow explanation as if

01:18:15.440 --> 01:18:15.450
much more narrow explanation as if
 

01:18:15.450 --> 01:18:17.900
much more narrow explanation as if
someone would ask where you come from

01:18:17.900 --> 01:18:17.910
someone would ask where you come from
 

01:18:17.910 --> 01:18:20.420
someone would ask where you come from
and that's like a language that requires

01:18:20.420 --> 01:18:20.430
and that's like a language that requires
 

01:18:20.430 --> 01:18:23.510
and that's like a language that requires
a different explanation of the mobility

01:18:23.510 --> 01:18:23.520
a different explanation of the mobility
 

01:18:23.520 --> 01:18:26.780
a different explanation of the mobility
of the machine then what happened by the

01:18:26.780 --> 01:18:26.790
of the machine then what happened by the
 

01:18:26.790 --> 01:18:29.360
of the machine then what happened by the
elevator so we did a lot of research and

01:18:29.360 --> 01:18:29.370
elevator so we did a lot of research and
 

01:18:29.370 --> 01:18:31.820
elevator so we did a lot of research and
we do as we speak a lot of research on

01:18:31.820 --> 01:18:31.830
we do as we speak a lot of research on
 

01:18:31.830 --> 01:18:34.280
we do as we speak a lot of research on
trying to understand a question from a

01:18:34.280 --> 01:18:34.290
trying to understand a question from a
 

01:18:34.290 --> 01:18:38.090
trying to understand a question from a
human what exactly a means in terms of

01:18:38.090 --> 01:18:38.100
human what exactly a means in terms of
 

01:18:38.100 --> 01:18:41.140
human what exactly a means in terms of
an explanation required from the machine

01:18:41.140 --> 01:18:41.150
an explanation required from the machine
 

01:18:41.150 --> 01:18:44.480
an explanation required from the machine
so it seems to me that in a lot of cases

01:18:44.480 --> 01:18:44.490
so it seems to me that in a lot of cases
 

01:18:44.490 --> 01:18:46.490
so it seems to me that in a lot of cases
this kind of explained ability if we had

01:18:46.490 --> 01:18:46.500
this kind of explained ability if we had
 

01:18:46.500 --> 01:18:49.520
this kind of explained ability if we had
it would be able to to help some with

01:18:49.520 --> 01:18:49.530
it would be able to to help some with
 

01:18:49.530 --> 01:18:50.690
it would be able to to help some with
one of the issues that you raised

01:18:50.690 --> 01:18:50.700
one of the issues that you raised
 

01:18:50.700 --> 01:18:52.460
one of the issues that you raised
Kirsten which was about the difficulty

01:18:52.460 --> 01:18:52.470
Kirsten which was about the difficulty
 

01:18:52.470 --> 01:18:55.910
Kirsten which was about the difficulty
of verification in rapidly changing

01:18:55.910 --> 01:18:55.920
of verification in rapidly changing
 

01:18:55.920 --> 01:18:57.800
of verification in rapidly changing
environments where the system might be

01:18:57.800 --> 01:18:57.810
environments where the system might be
 

01:18:57.810 --> 01:18:59.930
environments where the system might be
deployed somewhere whether on the

01:18:59.930 --> 01:18:59.940
deployed somewhere whether on the
 

01:18:59.940 --> 01:19:02.630
deployed somewhere whether on the
battlefield or in the international

01:19:02.630 --> 01:19:02.640
battlefield or in the international
 

01:19:02.640 --> 01:19:04.370
battlefield or in the international
context where perhaps it hasn't been

01:19:04.370 --> 01:19:04.380
context where perhaps it hasn't been
 

01:19:04.380 --> 01:19:06.050
context where perhaps it hasn't been
used before so how do we verify that

01:19:06.050 --> 01:19:06.060
used before so how do we verify that
 

01:19:06.060 --> 01:19:07.820
used before so how do we verify that
it's going to work there do you think

01:19:07.820 --> 01:19:07.830
it's going to work there do you think
 

01:19:07.830 --> 01:19:09.080
it's going to work there do you think
that explained ability would be

01:19:09.080 --> 01:19:09.090
that explained ability would be
 

01:19:09.090 --> 01:19:11.450
that explained ability would be
something that could provide a guide as

01:19:11.450 --> 01:19:11.460
something that could provide a guide as
 

01:19:11.460 --> 01:19:15.680
something that could provide a guide as
we think about sort of how to how we can

01:19:15.680 --> 01:19:15.690
we think about sort of how to how we can
 

01:19:15.690 --> 01:19:17.810
we think about sort of how to how we can
build trust in as you said some of these

01:19:17.810 --> 01:19:17.820
build trust in as you said some of these
 

01:19:17.820 --> 01:19:19.460
build trust in as you said some of these
technologies that can can even have

01:19:19.460 --> 01:19:19.470
technologies that can can even have
 

01:19:19.470 --> 01:19:25.790
technologies that can can even have
lethal impacts well used a great word

01:19:25.790 --> 01:19:25.800
lethal impacts well used a great word
 

01:19:25.800 --> 01:19:27.560
lethal impacts well used a great word
transparency and that's something that

01:19:27.560 --> 01:19:27.570
transparency and that's something that
 

01:19:27.570 --> 01:19:29.270
transparency and that's something that
we talk again a lot about in arms

01:19:29.270 --> 01:19:29.280
we talk again a lot about in arms
 

01:19:29.280 --> 01:19:31.760
we talk again a lot about in arms
control as a stabilizing element so yes

01:19:31.760 --> 01:19:31.770
control as a stabilizing element so yes
 

01:19:31.770 --> 01:19:33.080
control as a stabilizing element so yes
I think explain ability is

01:19:33.080 --> 01:19:33.090
I think explain ability is
 

01:19:33.090 --> 01:19:35.510
I think explain ability is
extraordinarily important at the same

01:19:35.510 --> 01:19:35.520
extraordinarily important at the same
 

01:19:35.520 --> 01:19:39.080
extraordinarily important at the same
time it circles back to that question of

01:19:39.080 --> 01:19:39.090
time it circles back to that question of
 

01:19:39.090 --> 01:19:44.000
time it circles back to that question of
for who are we explaining to and and

01:19:44.000 --> 01:19:44.010
for who are we explaining to and and
 

01:19:44.010 --> 01:19:46.400
for who are we explaining to and and
when because when we're talking about

01:19:46.400 --> 01:19:46.410
when because when we're talking about
 

01:19:46.410 --> 01:19:50.930
when because when we're talking about
lethal systems sometimes post facto

01:19:50.930 --> 01:19:50.940
lethal systems sometimes post facto
 

01:19:50.940 --> 01:19:53.030
lethal systems sometimes post facto
explain ability it's good to be able to

01:19:53.030 --> 01:19:53.040
explain ability it's good to be able to
 

01:19:53.040 --> 01:19:55.850
explain ability it's good to be able to
unpack that right afterwards if

01:19:55.850 --> 01:19:55.860
unpack that right afterwards if
 

01:19:55.860 --> 01:19:58.370
unpack that right afterwards if
something went wrong but it's it's a bit

01:19:58.370 --> 01:19:58.380
something went wrong but it's it's a bit
 

01:19:58.380 --> 01:20:01.640
something went wrong but it's it's a bit
late right so explain ability is very

01:20:01.640 --> 01:20:01.650
late right so explain ability is very
 

01:20:01.650 --> 01:20:04.760
late right so explain ability is very
important but I think we should be

01:20:04.760 --> 01:20:04.770
important but I think we should be
 

01:20:04.770 --> 01:20:07.340
important but I think we should be
focusing more on on thinking about how

01:20:07.340 --> 01:20:07.350
focusing more on on thinking about how
 

01:20:07.350 --> 01:20:12.140
focusing more on on thinking about how
do we ensure confidence in the systems

01:20:12.140 --> 01:20:12.150
do we ensure confidence in the systems
 

01:20:12.150 --> 01:20:14.090
do we ensure confidence in the systems
whether they are weapon systems or other

01:20:14.090 --> 01:20:14.100
whether they are weapon systems or other
 

01:20:14.100 --> 01:20:16.540
whether they are weapon systems or other
systems before we deploy them

01:20:16.540 --> 01:20:16.550
systems before we deploy them
 

01:20:16.550 --> 01:20:18.580
systems before we deploy them
and so explained ability I think is a

01:20:18.580 --> 01:20:18.590
and so explained ability I think is a
 

01:20:18.590 --> 01:20:20.500
and so explained ability I think is a
much earlier part of the process then

01:20:20.500 --> 01:20:20.510
much earlier part of the process then
 

01:20:20.510 --> 01:20:22.810
much earlier part of the process then
actually post-deployment I mean it's

01:20:22.810 --> 01:20:22.820
actually post-deployment I mean it's
 

01:20:22.820 --> 01:20:24.129
actually post-deployment I mean it's
still necessary and it's part of that

01:20:24.129 --> 01:20:24.139
still necessary and it's part of that
 

01:20:24.139 --> 01:20:26.140
still necessary and it's part of that
very important human machine interface

01:20:26.140 --> 01:20:26.150
very important human machine interface
 

01:20:26.150 --> 01:20:28.060
very important human machine interface
that's going to be critical in all of

01:20:28.060 --> 01:20:28.070
that's going to be critical in all of
 

01:20:28.070 --> 01:20:31.000
that's going to be critical in all of
our AI embedded systems but explain

01:20:31.000 --> 01:20:31.010
our AI embedded systems but explain
 

01:20:31.010 --> 01:20:32.589
our AI embedded systems but explain
ability with weapon systems because of

01:20:32.589 --> 01:20:32.599
ability with weapon systems because of
 

01:20:32.599 --> 01:20:37.629
ability with weapon systems because of
the risk being so high it's I think it's

01:20:37.629 --> 01:20:37.639
the risk being so high it's I think it's
 

01:20:37.639 --> 01:20:40.209
the risk being so high it's I think it's
a bit of a unicorn we need it we need it

01:20:40.209 --> 01:20:40.219
a bit of a unicorn we need it we need it
 

01:20:40.219 --> 01:20:42.490
a bit of a unicorn we need it we need it
a lot sooner certainly as you said the

01:20:42.490 --> 01:20:42.500
a lot sooner certainly as you said the
 

01:20:42.500 --> 01:20:44.859
a lot sooner certainly as you said the
post factor that that is small comfort

01:20:44.859 --> 01:20:44.869
post factor that that is small comfort
 

01:20:44.869 --> 01:20:47.080
post factor that that is small comfort
if after the fact you know why that

01:20:47.080 --> 01:20:47.090
if after the fact you know why that
 

01:20:47.090 --> 01:20:48.820
if after the fact you know why that
happened it seems that in many ways that

01:20:48.820 --> 01:20:48.830
happened it seems that in many ways that
 

01:20:48.830 --> 01:20:49.839
happened it seems that in many ways that
connects to some of things you were

01:20:49.839 --> 01:20:49.849
connects to some of things you were
 

01:20:49.849 --> 01:20:52.990
connects to some of things you were
raised in Moshe in terms of the need to

01:20:52.990 --> 01:20:53.000
raised in Moshe in terms of the need to
 

01:20:53.000 --> 01:20:54.280
raised in Moshe in terms of the need to
be able to trust the developers

01:20:54.280 --> 01:20:54.290
be able to trust the developers
 

01:20:54.290 --> 01:20:56.530
be able to trust the developers
themselves we can trust men well as

01:20:56.530 --> 01:20:56.540
themselves we can trust men well as
 

01:20:56.540 --> 01:20:58.620
themselves we can trust men well as
graduate students we can trust Manuela

01:20:58.620 --> 01:20:58.630
graduate students we can trust Manuela
 

01:20:58.630 --> 01:21:00.820
graduate students we can trust Manuela
but as we've been hearing about in

01:21:00.820 --> 01:21:00.830
but as we've been hearing about in
 

01:21:00.830 --> 01:21:03.209
but as we've been hearing about in
various times throughout this conference

01:21:03.209 --> 01:21:03.219
various times throughout this conference
 

01:21:03.219 --> 01:21:05.439
various times throughout this conference
there are companies who are doing things

01:21:05.439 --> 01:21:05.449
there are companies who are doing things
 

01:21:05.449 --> 01:21:07.839
there are companies who are doing things
that perhaps are not out of an effort to

01:21:07.839 --> 01:21:07.849
that perhaps are not out of an effort to
 

01:21:07.849 --> 01:21:10.060
that perhaps are not out of an effort to
produce technology that will help people

01:21:10.060 --> 01:21:10.070
produce technology that will help people
 

01:21:10.070 --> 01:21:11.859
produce technology that will help people
as opposed to helping the bottom line so

01:21:11.859 --> 01:21:11.869
as opposed to helping the bottom line so
 

01:21:11.869 --> 01:21:14.470
as opposed to helping the bottom line so
could we extend for example this notion

01:21:14.470 --> 01:21:14.480
could we extend for example this notion
 

01:21:14.480 --> 01:21:16.240
could we extend for example this notion
of explained ability to the developers

01:21:16.240 --> 01:21:16.250
of explained ability to the developers
 

01:21:16.250 --> 01:21:18.010
of explained ability to the developers
they have to explain why they did what

01:21:18.010 --> 01:21:18.020
they have to explain why they did what
 

01:21:18.020 --> 01:21:19.930
they have to explain why they did what
they did or what solutions do you think

01:21:19.930 --> 01:21:19.940
they did or what solutions do you think
 

01:21:19.940 --> 01:21:21.399
they did or what solutions do you think
we might bore paths might we be able to

01:21:21.399 --> 01:21:21.409
we might bore paths might we be able to
 

01:21:21.409 --> 01:21:23.770
we might bore paths might we be able to
go down to improve trust in developers

01:21:23.770 --> 01:21:23.780
go down to improve trust in developers
 

01:21:23.780 --> 01:21:26.680
go down to improve trust in developers
well I think we have to go back to the

01:21:26.680 --> 01:21:26.690
well I think we have to go back to the
 

01:21:26.690 --> 01:21:28.359
well I think we have to go back to the
questions why do we need trust and when

01:21:28.359 --> 01:21:28.369
questions why do we need trust and when
 

01:21:28.369 --> 01:21:30.030
questions why do we need trust and when
it trusts because we feel vulnerable

01:21:30.030 --> 01:21:30.040
it trusts because we feel vulnerable
 

01:21:30.040 --> 01:21:33.010
it trusts because we feel vulnerable
okay and this is true this is basically

01:21:33.010 --> 01:21:33.020
okay and this is true this is basically
 

01:21:33.020 --> 01:21:34.959
okay and this is true this is basically
human fear if you go if you have a child

01:21:34.959 --> 01:21:34.969
human fear if you go if you have a child
 

01:21:34.969 --> 01:21:37.180
human fear if you go if you have a child
I remember being being a child and

01:21:37.180 --> 01:21:37.190
I remember being being a child and
 

01:21:37.190 --> 01:21:40.300
I remember being being a child and
walking in it in darkness why are you

01:21:40.300 --> 01:21:40.310
walking in it in darkness why are you
 

01:21:40.310 --> 01:21:43.300
walking in it in darkness why are you
afraid when it's dark well because you

01:21:43.300 --> 01:21:43.310
afraid when it's dark well because you
 

01:21:43.310 --> 01:21:44.589
afraid when it's dark well because you
don't know what are the threats out

01:21:44.589 --> 01:21:44.599
don't know what are the threats out
 

01:21:44.599 --> 01:21:47.350
don't know what are the threats out
there right I mean so you turn the light

01:21:47.350 --> 01:21:47.360
there right I mean so you turn the light
 

01:21:47.360 --> 01:21:49.600
there right I mean so you turn the light
on and okay there's nothing here to

01:21:49.600 --> 01:21:49.610
on and okay there's nothing here to
 

01:21:49.610 --> 01:21:53.410
on and okay there's nothing here to
worry about and so human beings are very

01:21:53.410 --> 01:21:53.420
worry about and so human beings are very
 

01:21:53.420 --> 01:21:54.070
worry about and so human beings are very
vulnerable

01:21:54.070 --> 01:21:54.080
vulnerable
 

01:21:54.080 --> 01:21:57.760
vulnerable
we're very fragile okay and so all if

01:21:57.760 --> 01:21:57.770
we're very fragile okay and so all if
 

01:21:57.770 --> 01:21:59.589
we're very fragile okay and so all if
you think about all what all these

01:21:59.589 --> 01:21:59.599
you think about all what all these
 

01:21:59.599 --> 01:22:01.350
you think about all what all these
things were talking about transparency

01:22:01.350 --> 01:22:01.360
things were talking about transparency
 

01:22:01.360 --> 01:22:04.149
things were talking about transparency
and explained ability are all

01:22:04.149 --> 01:22:04.159
and explained ability are all
 

01:22:04.159 --> 01:22:06.879
and explained ability are all
essentially a way to assuage us that we

01:22:06.879 --> 01:22:06.889
essentially a way to assuage us that we
 

01:22:06.889 --> 01:22:08.979
essentially a way to assuage us that we
don't need to be afraid so this is

01:22:08.979 --> 01:22:08.989
don't need to be afraid so this is
 

01:22:08.989 --> 01:22:10.660
don't need to be afraid so this is
really we need to go back is the issue

01:22:10.660 --> 01:22:10.670
really we need to go back is the issue
 

01:22:10.670 --> 01:22:11.890
really we need to go back is the issue
in some sense it's not so much about

01:22:11.890 --> 01:22:11.900
in some sense it's not so much about
 

01:22:11.900 --> 01:22:15.040
in some sense it's not so much about
trust the issue is about vulnerability

01:22:15.040 --> 01:22:15.050
trust the issue is about vulnerability
 

01:22:15.050 --> 01:22:16.209
trust the issue is about vulnerability
and fear

01:22:16.209 --> 01:22:16.219
and fear
 

01:22:16.219 --> 01:22:18.700
and fear
and unfortunately what we've been

01:22:18.700 --> 01:22:18.710
and unfortunately what we've been
 

01:22:18.710 --> 01:22:21.040
and unfortunately what we've been
learning in the more you learn that your

01:22:21.040 --> 01:22:21.050
learning in the more you learn that your
 

01:22:21.050 --> 01:22:24.790
learning in the more you learn that your
fields are rational they're really you

01:22:24.790 --> 01:22:24.800
fields are rational they're really you
 

01:22:24.800 --> 01:22:26.560
fields are rational they're really you
know just because you're paranoid it

01:22:26.560 --> 01:22:26.570
know just because you're paranoid it
 

01:22:26.570 --> 01:22:27.850
know just because you're paranoid it
doesn't mean the summer is not trying to

01:22:27.850 --> 01:22:27.860
doesn't mean the summer is not trying to
 

01:22:27.860 --> 01:22:28.410
doesn't mean the summer is not trying to
kill you

01:22:28.410 --> 01:22:28.420
kill you
 

01:22:28.420 --> 01:22:30.120
kill you
and what have been learning recently

01:22:30.120 --> 01:22:30.130
and what have been learning recently
 

01:22:30.130 --> 01:22:31.980
and what have been learning recently
there are people out there for us no

01:22:31.980 --> 01:22:31.990
there are people out there for us no
 

01:22:31.990 --> 01:22:34.530
there are people out there for us no
maybe not to kill us but to manipulate

01:22:34.530 --> 01:22:34.540
maybe not to kill us but to manipulate
 

01:22:34.540 --> 01:22:37.560
maybe not to kill us but to manipulate
us and this if you think about this

01:22:37.560 --> 01:22:37.570
us and this if you think about this
 

01:22:37.570 --> 01:22:40.680
us and this if you think about this
issue being money manipulated it goes

01:22:40.680 --> 01:22:40.690
issue being money manipulated it goes
 

01:22:40.690 --> 01:22:42.270
issue being money manipulated it goes
back to our sense of self and

01:22:42.270 --> 01:22:42.280
back to our sense of self and
 

01:22:42.280 --> 01:22:44.880
back to our sense of self and
vulnerability and we feel violated when

01:22:44.880 --> 01:22:44.890
vulnerability and we feel violated when
 

01:22:44.890 --> 01:22:47.250
vulnerability and we feel violated when
we realize we've been manipulated and so

01:22:47.250 --> 01:22:47.260
we realize we've been manipulated and so
 

01:22:47.260 --> 01:22:48.870
we realize we've been manipulated and so
maybe it's not a threat for life but it

01:22:48.870 --> 01:22:48.880
maybe it's not a threat for life but it
 

01:22:48.880 --> 01:22:50.310
maybe it's not a threat for life but it
is still some kind of a threat to our

01:22:50.310 --> 01:22:50.320
is still some kind of a threat to our
 

01:22:50.320 --> 01:22:53.160
is still some kind of a threat to our
own notion of self and self determinacy

01:22:53.160 --> 01:22:53.170
own notion of self and self determinacy
 

01:22:53.170 --> 01:22:55.530
own notion of self and self determinacy
and so we start have to figure out I

01:22:55.530 --> 01:22:55.540
and so we start have to figure out I
 

01:22:55.540 --> 01:22:57.810
and so we start have to figure out I
mean the issue first of all is not how

01:22:57.810 --> 01:22:57.820
mean the issue first of all is not how
 

01:22:57.820 --> 01:22:59.910
mean the issue first of all is not how
to somehow make us feel safer first of

01:22:59.910 --> 01:22:59.920
to somehow make us feel safer first of
 

01:22:59.920 --> 01:23:02.550
to somehow make us feel safer first of
all they have to be real safety then we

01:23:02.550 --> 01:23:02.560
all they have to be real safety then we
 

01:23:02.560 --> 01:23:04.740
all they have to be real safety then we
deal with the psychological factor okay

01:23:04.740 --> 01:23:04.750
deal with the psychological factor okay
 

01:23:04.750 --> 01:23:06.720
deal with the psychological factor okay
right now and fourthly we are missing

01:23:06.720 --> 01:23:06.730
right now and fourthly we are missing
 

01:23:06.730 --> 01:23:09.390
right now and fourthly we are missing
the regulatory framework that will make

01:23:09.390 --> 01:23:09.400
the regulatory framework that will make
 

01:23:09.400 --> 01:23:11.850
the regulatory framework that will make
this technological world really safe and

01:23:11.850 --> 01:23:11.860
this technological world really safe and
 

01:23:11.860 --> 01:23:14.220
this technological world really safe and
that's why we are fredericks that's why

01:23:14.220 --> 01:23:14.230
that's why we are fredericks that's why
 

01:23:14.230 --> 01:23:16.350
that's why we are fredericks that's why
we have no trust in the system so we

01:23:16.350 --> 01:23:16.360
we have no trust in the system so we
 

01:23:16.360 --> 01:23:18.240
we have no trust in the system so we
have to go beyond just focusing on the

01:23:18.240 --> 01:23:18.250
have to go beyond just focusing on the
 

01:23:18.250 --> 01:23:20.730
have to go beyond just focusing on the
trust assume that it's a it's a safe

01:23:20.730 --> 01:23:20.740
trust assume that it's a it's a safe
 

01:23:20.740 --> 01:23:24.120
trust assume that it's a it's a safe
world and you're feeling of fearfulness

01:23:24.120 --> 01:23:24.130
world and you're feeling of fearfulness
 

01:23:24.130 --> 01:23:27.330
world and you're feeling of fearfulness
are not justified right now I have to

01:23:27.330 --> 01:23:27.340
are not justified right now I have to
 

01:23:27.340 --> 01:23:29.580
are not justified right now I have to
say I think they are justified so we

01:23:29.580 --> 01:23:29.590
say I think they are justified so we
 

01:23:29.590 --> 01:23:31.350
say I think they are justified so we
have to go beyond the trust issue we

01:23:31.350 --> 01:23:31.360
have to go beyond the trust issue we
 

01:23:31.360 --> 01:23:34.140
have to go beyond the trust issue we
have to remove the threat first and then

01:23:34.140 --> 01:23:34.150
have to remove the threat first and then
 

01:23:34.150 --> 01:23:35.430
have to remove the threat first and then
we have to deal how do we make sure that

01:23:35.430 --> 01:23:35.440
we have to deal how do we make sure that
 

01:23:35.440 --> 01:23:37.620
we have to deal how do we make sure that
people really trust that this is a safe

01:23:37.620 --> 01:23:37.630
people really trust that this is a safe
 

01:23:37.630 --> 01:23:41.610
people really trust that this is a safe
environment so Manuela would you you

01:23:41.610 --> 01:23:41.620
environment so Manuela would you you
 

01:23:41.620 --> 01:23:43.020
environment so Manuela would you you
want to switch to becoming a social

01:23:43.020 --> 01:23:43.030
want to switch to becoming a social
 

01:23:43.030 --> 01:23:44.820
want to switch to becoming a social
scientist and policy maker to remove

01:23:44.820 --> 01:23:44.830
scientist and policy maker to remove
 

01:23:44.830 --> 01:23:48.450
scientist and policy maker to remove
some of these threats I'm going to wave

01:23:48.450 --> 01:23:48.460
some of these threats I'm going to wave
 

01:23:48.460 --> 01:23:54.930
some of these threats I'm going to wave
my hands but I actually tend to disagree

01:23:54.930 --> 01:23:54.940
my hands but I actually tend to disagree
 

01:23:54.940 --> 01:24:03.870
my hands but I actually tend to disagree
with this so you know besides the fact

01:24:03.870 --> 01:24:03.880
with this so you know besides the fact
 

01:24:03.880 --> 01:24:06.810
with this so you know besides the fact
of of being safe and afraid you also

01:24:06.810 --> 01:24:06.820
of of being safe and afraid you also
 

01:24:06.820 --> 01:24:09.600
of of being safe and afraid you also
want to trust a machine that if you ask

01:24:09.600 --> 01:24:09.610
want to trust a machine that if you ask
 

01:24:09.610 --> 01:24:11.730
want to trust a machine that if you ask
you know find me a flight to Paris

01:24:11.730 --> 01:24:11.740
you know find me a flight to Paris
 

01:24:11.740 --> 01:24:14.760
you know find me a flight to Paris
tomorrow or get me a good flight to

01:24:14.760 --> 01:24:14.770
tomorrow or get me a good flight to
 

01:24:14.770 --> 01:24:17.940
tomorrow or get me a good flight to
Lisbon that actually it does the job so

01:24:17.940 --> 01:24:17.950
Lisbon that actually it does the job so
 

01:24:17.950 --> 01:24:19.920
Lisbon that actually it does the job so
it's just trusting the fact that the

01:24:19.920 --> 01:24:19.930
it's just trusting the fact that the
 

01:24:19.930 --> 01:24:22.020
it's just trusting the fact that the
thing is going to do what you expected

01:24:22.020 --> 01:24:22.030
thing is going to do what you expected
 

01:24:22.030 --> 01:24:24.420
thing is going to do what you expected
it to do or if you have like a robot

01:24:24.420 --> 01:24:24.430
it to do or if you have like a robot
 

01:24:24.430 --> 01:24:27.210
it to do or if you have like a robot
around here that you'd say you know go

01:24:27.210 --> 01:24:27.220
around here that you'd say you know go
 

01:24:27.220 --> 01:24:29.100
around here that you'd say you know go
to the conference room and guide the

01:24:29.100 --> 01:24:29.110
to the conference room and guide the
 

01:24:29.110 --> 01:24:31.380
to the conference room and guide the
visitor back to my office that that's

01:24:31.380 --> 01:24:31.390
visitor back to my office that that's
 

01:24:31.390 --> 01:24:33.180
visitor back to my office that that's
the case that the robot does not go to

01:24:33.180 --> 01:24:33.190
the case that the robot does not go to
 

01:24:33.190 --> 01:24:35.580
the case that the robot does not go to
the kitchen or does not go anywhere else

01:24:35.580 --> 01:24:35.590
the kitchen or does not go anywhere else
 

01:24:35.590 --> 01:24:38.700
the kitchen or does not go anywhere else
so or my refrigerator if I put something

01:24:38.700 --> 01:24:38.710
so or my refrigerator if I put something
 

01:24:38.710 --> 01:24:41.040
so or my refrigerator if I put something
in the freezer I expect it to

01:24:41.040 --> 01:24:41.050
in the freezer I expect it to
 

01:24:41.050 --> 01:24:43.350
in the freezer I expect it to
actually freeze the food so there is

01:24:43.350 --> 01:24:43.360
actually freeze the food so there is
 

01:24:43.360 --> 01:24:46.440
actually freeze the food so there is
something about technology that I mean

01:24:46.440 --> 01:24:46.450
something about technology that I mean
 

01:24:46.450 --> 01:24:48.060
something about technology that I mean
for me the trust is that in some sense

01:24:48.060 --> 01:24:48.070
for me the trust is that in some sense
 

01:24:48.070 --> 01:24:50.910
for me the trust is that in some sense
also it does what it's expected to do

01:24:50.910 --> 01:24:50.920
also it does what it's expected to do
 

01:24:50.920 --> 01:24:56.030
also it does what it's expected to do
and I think that that before the actual

01:24:56.030 --> 01:24:56.040
and I think that that before the actual
 

01:24:56.040 --> 01:24:59.220
and I think that that before the actual
solving my vulnerability there is also

01:24:59.220 --> 01:24:59.230
solving my vulnerability there is also
 

01:24:59.230 --> 01:25:03.060
solving my vulnerability there is also
this the need to meet the expectation

01:25:03.060 --> 01:25:03.070
this the need to meet the expectation
 

01:25:03.070 --> 01:25:05.940
this the need to meet the expectation
meet the specification and in AI we are

01:25:05.940 --> 01:25:05.950
meet the specification and in AI we are
 

01:25:05.950 --> 01:25:08.520
meet the specification and in AI we are
still not there because we really don't

01:25:08.520 --> 01:25:08.530
still not there because we really don't
 

01:25:08.530 --> 01:25:11.310
still not there because we really don't
have like robust robots that we say go

01:25:11.310 --> 01:25:11.320
have like robust robots that we say go
 

01:25:11.320 --> 01:25:13.980
have like robust robots that we say go
down this road and don't don't go over

01:25:13.980 --> 01:25:13.990
down this road and don't don't go over
 

01:25:13.990 --> 01:25:17.370
down this road and don't don't go over
anyone we are still trying to find the

01:25:17.370 --> 01:25:17.380
anyone we are still trying to find the
 

01:25:17.380 --> 01:25:20.210
anyone we are still trying to find the
the machinery that matches the

01:25:20.210 --> 01:25:20.220
the machinery that matches the
 

01:25:20.220 --> 01:25:22.710
the machinery that matches the
specification and what we would like the

01:25:22.710 --> 01:25:22.720
specification and what we would like the
 

01:25:22.720 --> 01:25:25.170
specification and what we would like the
autonomous agent the autonomous robot

01:25:25.170 --> 01:25:25.180
autonomous agent the autonomous robot
 

01:25:25.180 --> 01:25:27.930
autonomous agent the autonomous robot
the autonomous area assistant to do if I

01:25:27.930 --> 01:25:27.940
the autonomous area assistant to do if I
 

01:25:27.940 --> 01:25:29.850
the autonomous area assistant to do if I
need a man a doctor and I have an AI

01:25:29.850 --> 01:25:29.860
need a man a doctor and I have an AI
 

01:25:29.860 --> 01:25:31.560
need a man a doctor and I have an AI
assistant that I would like to say and

01:25:31.560 --> 01:25:31.570
assistant that I would like to say and
 

01:25:31.570 --> 01:25:34.860
assistant that I would like to say and
say go and see if you find any case

01:25:34.860 --> 01:25:34.870
say go and see if you find any case
 

01:25:34.870 --> 01:25:37.200
say go and see if you find any case
similar to these on all the images you

01:25:37.200 --> 01:25:37.210
similar to these on all the images you
 

01:25:37.210 --> 01:25:39.240
similar to these on all the images you
have collected all these data from all

01:25:39.240 --> 01:25:39.250
have collected all these data from all
 

01:25:39.250 --> 01:25:40.050
have collected all these data from all
over the world

01:25:40.050 --> 01:25:40.060
over the world
 

01:25:40.060 --> 01:25:43.020
over the world
I would like to trust that the thing

01:25:43.020 --> 01:25:43.030
I would like to trust that the thing
 

01:25:43.030 --> 01:25:45.120
I would like to trust that the thing
that I'm talking with is a Isis that

01:25:45.120 --> 01:25:45.130
that I'm talking with is a Isis that
 

01:25:45.130 --> 01:25:48.330
that I'm talking with is a Isis that
does in fact go through all the data in

01:25:48.330 --> 01:25:48.340
does in fact go through all the data in
 

01:25:48.340 --> 01:25:50.640
does in fact go through all the data in
the whole world and not just two parts

01:25:50.640 --> 01:25:50.650
the whole world and not just two parts
 

01:25:50.650 --> 01:25:53.940
the whole world and not just two parts
of it to actually answer my question

01:25:53.940 --> 01:25:53.950
of it to actually answer my question
 

01:25:53.950 --> 01:25:57.030
of it to actually answer my question
so the what I believe it's happening

01:25:57.030 --> 01:25:57.040
so the what I believe it's happening
 

01:25:57.040 --> 01:25:59.550
so the what I believe it's happening
what I believe for me Trust is that the

01:25:59.550 --> 01:25:59.560
what I believe for me Trust is that the
 

01:25:59.560 --> 01:26:04.080
what I believe for me Trust is that the
task that I will interact with is AI

01:26:04.080 --> 01:26:04.090
task that I will interact with is AI
 

01:26:04.090 --> 01:26:06.780
task that I will interact with is AI
agent to be performed is actually done

01:26:06.780 --> 01:26:06.790
agent to be performed is actually done
 

01:26:06.790 --> 01:26:09.690
agent to be performed is actually done
the way I expected it to be done so that

01:26:09.690 --> 01:26:09.700
the way I expected it to be done so that
 

01:26:09.700 --> 01:26:13.770
the way I expected it to be done so that
kind of like matching my expectations

01:26:13.770 --> 01:26:13.780
kind of like matching my expectations
 

01:26:13.780 --> 01:26:16.020
kind of like matching my expectations
when I interact with the AI agent is

01:26:16.020 --> 01:26:16.030
when I interact with the AI agent is
 

01:26:16.030 --> 01:26:19.290
when I interact with the AI agent is
where I believe that I build that trust

01:26:19.290 --> 01:26:19.300
where I believe that I build that trust
 

01:26:19.300 --> 01:26:22.200
where I believe that I build that trust
in the machine I want to add one thing

01:26:22.200 --> 01:26:22.210
in the machine I want to add one thing
 

01:26:22.210 --> 01:26:24.050
in the machine I want to add one thing
though to the point that these

01:26:24.050 --> 01:26:24.060
though to the point that these
 

01:26:24.060 --> 01:26:26.610
though to the point that these
distrusting the developers do not trust

01:26:26.610 --> 01:26:26.620
distrusting the developers do not trust
 

01:26:26.620 --> 01:26:29.070
distrusting the developers do not trust
me do not trust my students and I'll

01:26:29.070 --> 01:26:29.080
me do not trust my students and I'll
 

01:26:29.080 --> 01:26:32.310
me do not trust my students and I'll
explain why it's not not trusting but

01:26:32.310 --> 01:26:32.320
explain why it's not not trusting but
 

01:26:32.320 --> 01:26:35.700
explain why it's not not trusting but
when just one single thing I'm not going

01:26:35.700 --> 01:26:35.710
when just one single thing I'm not going
 

01:26:35.710 --> 01:26:38.580
when just one single thing I'm not going
to put my hands on fire and guarantee

01:26:38.580 --> 01:26:38.590
to put my hands on fire and guarantee
 

01:26:38.590 --> 01:26:40.920
to put my hands on fire and guarantee
that my robot is not going to hit the

01:26:40.920 --> 01:26:40.930
that my robot is not going to hit the
 

01:26:40.930 --> 01:26:45.240
that my robot is not going to hit the
wall or I I just have a hard time

01:26:45.240 --> 01:26:45.250
wall or I I just have a hard time
 

01:26:45.250 --> 01:26:48.600
wall or I I just have a hard time
achieving that level of assurance and

01:26:48.600 --> 01:26:48.610
achieving that level of assurance and
 

01:26:48.610 --> 01:26:53.490
achieving that level of assurance and
and the reason is because the world the

01:26:53.490 --> 01:26:53.500
and the reason is because the world the
 

01:26:53.500 --> 01:26:54.670
and the reason is because the world the
environment

01:26:54.670 --> 01:26:54.680
environment
 

01:26:54.680 --> 01:26:58.960
environment
the people are very complex systems it's

01:26:58.960 --> 01:26:58.970
the people are very complex systems it's
 

01:26:58.970 --> 01:27:02.140
the people are very complex systems it's
extremely complex - from a research

01:27:02.140 --> 01:27:02.150
extremely complex - from a research
 

01:27:02.150 --> 01:27:05.500
extremely complex - from a research
point of view develop a solution that is

01:27:05.500 --> 01:27:05.510
point of view develop a solution that is
 

01:27:05.510 --> 01:27:08.950
point of view develop a solution that is
trustable for the complexity of where we

01:27:08.950 --> 01:27:08.960
trustable for the complexity of where we
 

01:27:08.960 --> 01:27:11.860
trustable for the complexity of where we
want to make our systems autonomous it's

01:27:11.860 --> 01:27:11.870
want to make our systems autonomous it's
 

01:27:11.870 --> 01:27:15.940
want to make our systems autonomous it's
not bad faith it's not like it's not

01:27:15.940 --> 01:27:15.950
not bad faith it's not like it's not
 

01:27:15.950 --> 01:27:18.730
not bad faith it's not like it's not
really intention it's just that it is

01:27:18.730 --> 01:27:18.740
really intention it's just that it is
 

01:27:18.740 --> 01:27:22.660
really intention it's just that it is
too complex it's just too hard and it's

01:27:22.660 --> 01:27:22.670
too complex it's just too hard and it's
 

01:27:22.670 --> 01:27:24.670
too complex it's just too hard and it's
too hard in the sense that there is a

01:27:24.670 --> 01:27:24.680
too hard in the sense that there is a
 

01:27:24.680 --> 01:27:27.700
too hard in the sense that there is a
very uncertain system that you now are

01:27:27.700 --> 01:27:27.710
very uncertain system that you now are
 

01:27:27.710 --> 01:27:30.940
very uncertain system that you now are
supposed to handle with some kind of

01:27:30.940 --> 01:27:30.950
supposed to handle with some kind of
 

01:27:30.950 --> 01:27:34.330
supposed to handle with some kind of
like algorithm so it's like the sandy

01:27:34.330 --> 01:27:34.340
like algorithm so it's like the sandy
 

01:27:34.340 --> 01:27:37.860
like algorithm so it's like the sandy
storm it's like 9/11 it's like all these

01:27:37.860 --> 01:27:37.870
storm it's like 9/11 it's like all these
 

01:27:37.870 --> 01:27:41.800
storm it's like 9/11 it's like all these
complex things that no one was able even

01:27:41.800 --> 01:27:41.810
complex things that no one was able even
 

01:27:41.810 --> 01:27:44.200
complex things that no one was able even
within humans to be able to find a

01:27:44.200 --> 01:27:44.210
within humans to be able to find a
 

01:27:44.210 --> 01:27:48.040
within humans to be able to find a
solution for them they just I mean the

01:27:48.040 --> 01:27:48.050
solution for them they just I mean the
 

01:27:48.050 --> 01:27:51.400
solution for them they just I mean the
world is too difficult it's too hard on

01:27:51.400 --> 01:27:51.410
world is too difficult it's too hard on
 

01:27:51.410 --> 01:27:53.560
world is too difficult it's too hard on
the other hand are we going to give up

01:27:53.560 --> 01:27:53.570
the other hand are we going to give up
 

01:27:53.570 --> 01:27:55.750
the other hand are we going to give up
on automating things just because of the

01:27:55.750 --> 01:27:55.760
on automating things just because of the
 

01:27:55.760 --> 01:27:58.120
on automating things just because of the
complexity and so what I'm trying to

01:27:58.120 --> 01:27:58.130
complexity and so what I'm trying to
 

01:27:58.130 --> 01:28:01.480
complexity and so what I'm trying to
tell you is like this I believe we have

01:28:01.480 --> 01:28:01.490
tell you is like this I believe we have
 

01:28:01.490 --> 01:28:05.950
tell you is like this I believe we have
to accept their AI as humans do will

01:28:05.950 --> 01:28:05.960
to accept their AI as humans do will
 

01:28:05.960 --> 01:28:08.740
to accept their AI as humans do will
eventually make mistakes what we might

01:28:08.740 --> 01:28:08.750
eventually make mistakes what we might
 

01:28:08.750 --> 01:28:11.530
eventually make mistakes what we might
not want to accept is that it doesn't

01:28:11.530 --> 01:28:11.540
not want to accept is that it doesn't
 

01:28:11.540 --> 01:28:14.500
not want to accept is that it doesn't
improve over time we might not want to

01:28:14.500 --> 01:28:14.510
improve over time we might not want to
 

01:28:14.510 --> 01:28:16.990
improve over time we might not want to
himself is the lack of learning what I'm

01:28:16.990 --> 01:28:17.000
himself is the lack of learning what I'm
 

01:28:17.000 --> 01:28:19.390
himself is the lack of learning what I'm
saying is that any kind of instance of

01:28:19.390 --> 01:28:19.400
saying is that any kind of instance of
 

01:28:19.400 --> 01:28:22.600
saying is that any kind of instance of
something that didn't go well needs to

01:28:22.600 --> 01:28:22.610
something that didn't go well needs to
 

01:28:22.610 --> 01:28:25.240
something that didn't go well needs to
be more data and needs to be more input

01:28:25.240 --> 01:28:25.250
be more data and needs to be more input
 

01:28:25.250 --> 01:28:28.300
be more data and needs to be more input
for the eye system in its dynamics like

01:28:28.300 --> 01:28:28.310
for the eye system in its dynamics like
 

01:28:28.310 --> 01:28:31.300
for the eye system in its dynamics like
Allah was saying to become better even

01:28:31.300 --> 01:28:31.310
Allah was saying to become better even
 

01:28:31.310 --> 01:28:34.300
Allah was saying to become better even
whatever a cognitive assistant you do to

01:28:34.300 --> 01:28:34.310
whatever a cognitive assistant you do to
 

01:28:34.310 --> 01:28:38.020
whatever a cognitive assistant you do to
a person if it's not a moving system a

01:28:38.020 --> 01:28:38.030
a person if it's not a moving system a
 

01:28:38.030 --> 01:28:39.880
a person if it's not a moving system a
dynamic system that gets better with

01:28:39.880 --> 01:28:39.890
dynamic system that gets better with
 

01:28:39.890 --> 01:28:42.910
dynamic system that gets better with
experience we are not going to ever be

01:28:42.910 --> 01:28:42.920
experience we are not going to ever be
 

01:28:42.920 --> 01:28:45.850
experience we are not going to ever be
able to I believe generates some kind of

01:28:45.850 --> 01:28:45.860
able to I believe generates some kind of
 

01:28:45.860 --> 01:28:49.240
able to I believe generates some kind of
static system that handles this enormous

01:28:49.240 --> 01:28:49.250
static system that handles this enormous
 

01:28:49.250 --> 01:28:51.430
static system that handles this enormous
complexity and just to finish one

01:28:51.430 --> 01:28:51.440
complexity and just to finish one
 

01:28:51.440 --> 01:28:53.620
complexity and just to finish one
thought I've been doing robot soccer for

01:28:53.620 --> 01:28:53.630
thought I've been doing robot soccer for
 

01:28:53.630 --> 01:28:57.070
thought I've been doing robot soccer for
20 years so little soccer playing robots

01:28:57.070 --> 01:28:57.080
20 years so little soccer playing robots
 

01:28:57.080 --> 01:28:59.860
20 years so little soccer playing robots
that go to these competitions even after

01:28:59.860 --> 01:28:59.870
that go to these competitions even after
 

01:28:59.870 --> 01:29:02.920
that go to these competitions even after
20 years that is always something that

01:29:02.920 --> 01:29:02.930
20 years that is always something that
 

01:29:02.930 --> 01:29:06.970
20 years that is always something that
surprises us in these games with an

01:29:06.970 --> 01:29:06.980
surprises us in these games with an
 

01:29:06.980 --> 01:29:08.689
surprises us in these games with an
opponent robot

01:29:08.689 --> 01:29:08.699
opponent robot
 

01:29:08.699 --> 01:29:11.990
opponent robot
there is a verse sri just shoots and

01:29:11.990 --> 01:29:12.000
there is a verse sri just shoots and
 

01:29:12.000 --> 01:29:13.879
there is a verse sri just shoots and
bounces off one of our robots and we say

01:29:13.879 --> 01:29:13.889
bounces off one of our robots and we say
 

01:29:13.889 --> 01:29:15.770
bounces off one of our robots and we say
how come you are supposed to shoot

01:29:15.770 --> 01:29:15.780
how come you are supposed to shoot
 

01:29:15.780 --> 01:29:17.959
how come you are supposed to shoot
directly to go not use our robots and

01:29:17.959 --> 01:29:17.969
directly to go not use our robots and
 

01:29:17.969 --> 01:29:20.750
directly to go not use our robots and
bouncing halls yeah that's what happened

01:29:20.750 --> 01:29:20.760
bouncing halls yeah that's what happened
 

01:29:20.760 --> 01:29:23.839
bouncing halls yeah that's what happened
two years ago then last year another one

01:29:23.839 --> 01:29:23.849
two years ago then last year another one
 

01:29:23.849 --> 01:29:26.810
two years ago then last year another one
of these surprises inevitably even after

01:29:26.810 --> 01:29:26.820
of these surprises inevitably even after
 

01:29:26.820 --> 01:29:29.030
of these surprises inevitably even after
20 years can you imagine that I go to

01:29:29.030 --> 01:29:29.040
20 years can you imagine that I go to
 

01:29:29.040 --> 01:29:31.250
20 years can you imagine that I go to
these games and I'm still surprised how

01:29:31.250 --> 01:29:31.260
these games and I'm still surprised how
 

01:29:31.260 --> 01:29:33.589
these games and I'm still surprised how
these adversaries figure out something

01:29:33.589 --> 01:29:33.599
these adversaries figure out something
 

01:29:33.599 --> 01:29:38.149
these adversaries figure out something
that I did not talk about so that puts

01:29:38.149 --> 01:29:38.159
that I did not talk about so that puts
 

01:29:38.159 --> 01:29:40.760
that I did not talk about so that puts
you in this kind of learning curve in

01:29:40.760 --> 01:29:40.770
you in this kind of learning curve in
 

01:29:40.770 --> 01:29:43.220
you in this kind of learning curve in
this kind of like trying to minimize the

01:29:43.220 --> 01:29:43.230
this kind of like trying to minimize the
 

01:29:43.230 --> 01:29:46.760
this kind of like trying to minimize the
errors you make and not really assuring

01:29:46.760 --> 01:29:46.770
errors you make and not really assuring
 

01:29:46.770 --> 01:29:47.870
errors you make and not really assuring
that there are no errors

01:29:47.870 --> 01:29:47.880
that there are no errors
 

01:29:47.880 --> 01:29:52.189
that there are no errors
it's just and of course

01:29:52.189 --> 01:29:52.199
it's just and of course
 

01:29:52.199 --> 01:29:54.709
it's just and of course
perfect predictability and Trust you

01:29:54.709 --> 01:29:54.719
perfect predictability and Trust you
 

01:29:54.719 --> 01:29:55.939
perfect predictability and Trust you
know you don't have to have perfect for

01:29:55.939 --> 01:29:55.949
know you don't have to have perfect for
 

01:29:55.949 --> 01:29:57.379
know you don't have to have perfect for
the predictability to have trust we

01:29:57.379 --> 01:29:57.389
the predictability to have trust we
 

01:29:57.389 --> 01:29:59.270
the predictability to have trust we
could have for example many of us have

01:29:59.270 --> 01:29:59.280
could have for example many of us have
 

01:29:59.280 --> 01:30:01.550
could have for example many of us have
trust in other humans even though humans

01:30:01.550 --> 01:30:01.560
trust in other humans even though humans
 

01:30:01.560 --> 01:30:04.010
trust in other humans even though humans
surprising each other all the time it's

01:30:04.010 --> 01:30:04.020
surprising each other all the time it's
 

01:30:04.020 --> 01:30:05.479
surprising each other all the time it's
I think does go to this issue the motion

01:30:05.479 --> 01:30:05.489
I think does go to this issue the motion
 

01:30:05.489 --> 01:30:06.979
I think does go to this issue the motion
is saying if we're making ourselves

01:30:06.979 --> 01:30:06.989
is saying if we're making ourselves
 

01:30:06.989 --> 01:30:09.319
is saying if we're making ourselves
vulnerable in certain ways and Trust is

01:30:09.319 --> 01:30:09.329
vulnerable in certain ways and Trust is
 

01:30:09.329 --> 01:30:11.780
vulnerable in certain ways and Trust is
relying on somebody else when you're in

01:30:11.780 --> 01:30:11.790
relying on somebody else when you're in
 

01:30:11.790 --> 01:30:14.390
relying on somebody else when you're in
that state of vulnerability and I think

01:30:14.390 --> 01:30:14.400
that state of vulnerability and I think
 

01:30:14.400 --> 01:30:15.620
that state of vulnerability and I think
it raises all kinds of interesting

01:30:15.620 --> 01:30:15.630
it raises all kinds of interesting
 

01:30:15.630 --> 01:30:17.359
it raises all kinds of interesting
questions of course about the weapons

01:30:17.359 --> 01:30:17.369
questions of course about the weapons
 

01:30:17.369 --> 01:30:20.959
questions of course about the weapons
space because is it reason you know

01:30:20.959 --> 01:30:20.969
space because is it reason you know
 

01:30:20.969 --> 01:30:22.729
space because is it reason you know
we've got very good reasons to think

01:30:22.729 --> 01:30:22.739
we've got very good reasons to think
 

01:30:22.739 --> 01:30:25.100
we've got very good reasons to think
they won't be perfect they will make

01:30:25.100 --> 01:30:25.110
they won't be perfect they will make
 

01:30:25.110 --> 01:30:26.810
they won't be perfect they will make
mistakes of course human soldiers make

01:30:26.810 --> 01:30:26.820
mistakes of course human soldiers make
 

01:30:26.820 --> 01:30:29.000
mistakes of course human soldiers make
mistakes human policymakers make just

01:30:29.000 --> 01:30:29.010
mistakes human policymakers make just
 

01:30:29.010 --> 01:30:32.300
mistakes human policymakers make just
make mistakes so when we think about

01:30:32.300 --> 01:30:32.310
make mistakes so when we think about
 

01:30:32.310 --> 01:30:35.120
make mistakes so when we think about
verification we think about deliberation

01:30:35.120 --> 01:30:35.130
verification we think about deliberation
 

01:30:35.130 --> 01:30:37.490
verification we think about deliberation
about what we as an international

01:30:37.490 --> 01:30:37.500
about what we as an international
 

01:30:37.500 --> 01:30:40.390
about what we as an international
community or a National Defense

01:30:40.390 --> 01:30:40.400
community or a National Defense
 

01:30:40.400 --> 01:30:43.580
community or a National Defense
organization ought to do how do we think

01:30:43.580 --> 01:30:43.590
organization ought to do how do we think
 

01:30:43.590 --> 01:30:45.770
organization ought to do how do we think
about the necessity of accidents the

01:30:45.770 --> 01:30:45.780
about the necessity of accidents the
 

01:30:45.780 --> 01:30:47.569
about the necessity of accidents the
necessity of surprises they're going to

01:30:47.569 --> 01:30:47.579
necessity of surprises they're going to
 

01:30:47.579 --> 01:30:51.620
necessity of surprises they're going to
happen is it you know do we do we aspire

01:30:51.620 --> 01:30:51.630
happen is it you know do we do we aspire
 

01:30:51.630 --> 01:30:54.530
happen is it you know do we do we aspire
to too much if we aspire to we know we

01:30:54.530 --> 01:30:54.540
to too much if we aspire to we know we
 

01:30:54.540 --> 01:30:55.760
to too much if we aspire to we know we
aspire to too much voice fire to

01:30:55.760 --> 01:30:55.770
aspire to too much voice fire to
 

01:30:55.770 --> 01:30:59.240
aspire to too much voice fire to
perfection give thoughts about the

01:30:59.240 --> 01:30:59.250
perfection give thoughts about the
 

01:30:59.250 --> 01:31:02.479
perfection give thoughts about the
relevance of accidents and surprises in

01:31:02.479 --> 01:31:02.489
relevance of accidents and surprises in
 

01:31:02.489 --> 01:31:04.160
relevance of accidents and surprises in
the context of weapons feel free to say

01:31:04.160 --> 01:31:04.170
the context of weapons feel free to say
 

01:31:04.170 --> 01:31:10.100
the context of weapons feel free to say
you'd like to pass actually I wanted to

01:31:10.100 --> 01:31:10.110
you'd like to pass actually I wanted to
 

01:31:10.110 --> 01:31:11.240
you'd like to pass actually I wanted to
pick up on something my mother was

01:31:11.240 --> 01:31:11.250
pick up on something my mother was
 

01:31:11.250 --> 01:31:13.459
pick up on something my mother was
talking do you mind I'm here talking

01:31:13.459 --> 01:31:13.469
talking do you mind I'm here talking
 

01:31:13.469 --> 01:31:15.439
talking do you mind I'm here talking
about expectations and this is a really

01:31:15.439 --> 01:31:15.449
about expectations and this is a really
 

01:31:15.449 --> 01:31:17.240
about expectations and this is a really
probably quite technologically

01:31:17.240 --> 01:31:17.250
probably quite technologically
 

01:31:17.250 --> 01:31:19.370
probably quite technologically
sophisticated audience I mean

01:31:19.370 --> 01:31:19.380
sophisticated audience I mean
 

01:31:19.380 --> 01:31:20.839
sophisticated audience I mean
technologically illiterate but I deal

01:31:20.839 --> 01:31:20.849
technologically illiterate but I deal
 

01:31:20.849 --> 01:31:21.540
technologically illiterate but I deal
with a lot of people

01:31:21.540 --> 01:31:21.550
with a lot of people
 

01:31:21.550 --> 01:31:22.439
with a lot of people
don't have a lot of technological

01:31:22.439 --> 01:31:22.449
don't have a lot of technological
 

01:31:22.449 --> 01:31:27.330
don't have a lot of technological
literacy and I I think we're at a real

01:31:27.330 --> 01:31:27.340
literacy and I I think we're at a real
 

01:31:27.340 --> 01:31:29.129
literacy and I I think we're at a real
interesting tipping point when it comes

01:31:29.129 --> 01:31:29.139
interesting tipping point when it comes
 

01:31:29.139 --> 01:31:30.959
interesting tipping point when it comes
to this issue of trust and technology

01:31:30.959 --> 01:31:30.969
to this issue of trust and technology
 

01:31:30.969 --> 01:31:35.310
to this issue of trust and technology
right now where a lot of people have

01:31:35.310 --> 01:31:35.320
right now where a lot of people have
 

01:31:35.320 --> 01:31:38.310
right now where a lot of people have
blind trust we have fear but we have

01:31:38.310 --> 01:31:38.320
blind trust we have fear but we have
 

01:31:38.320 --> 01:31:41.160
blind trust we have fear but we have
blind trust in technology and recent

01:31:41.160 --> 01:31:41.170
blind trust in technology and recent
 

01:31:41.170 --> 01:31:43.589
blind trust in technology and recent
events kick 1 because there's many to

01:31:43.589 --> 01:31:43.599
events kick 1 because there's many to
 

01:31:43.599 --> 01:31:47.129
events kick 1 because there's many to
choose from I have I think brought us to

01:31:47.129 --> 01:31:47.139
choose from I have I think brought us to
 

01:31:47.139 --> 01:31:49.319
choose from I have I think brought us to
a societal conversation about wait a

01:31:49.319 --> 01:31:49.329
a societal conversation about wait a
 

01:31:49.329 --> 01:31:51.600
a societal conversation about wait a
minute we need have to go from having

01:31:51.600 --> 01:31:51.610
minute we need have to go from having
 

01:31:51.610 --> 01:31:57.000
minute we need have to go from having
blind trust to having our technologies

01:31:57.000 --> 01:31:57.010
blind trust to having our technologies
 

01:31:57.010 --> 01:31:59.790
blind trust to having our technologies
the developers of those technologies and

01:31:59.790 --> 01:31:59.800
the developers of those technologies and
 

01:31:59.800 --> 01:32:02.069
the developers of those technologies and
the users and the deployers of those

01:32:02.069 --> 01:32:02.079
the users and the deployers of those
 

01:32:02.079 --> 01:32:03.930
the users and the deployers of those
technologies they need to earn my trust

01:32:03.930 --> 01:32:03.940
technologies they need to earn my trust
 

01:32:03.940 --> 01:32:06.270
technologies they need to earn my trust
and we're gonna have to make that

01:32:06.270 --> 01:32:06.280
and we're gonna have to make that
 

01:32:06.280 --> 01:32:08.839
and we're gonna have to make that
tipping point between blind trust and

01:32:08.839 --> 01:32:08.849
tipping point between blind trust and
 

01:32:08.849 --> 01:32:10.919
tipping point between blind trust and
earning trust and what are the

01:32:10.919 --> 01:32:10.929
earning trust and what are the
 

01:32:10.929 --> 01:32:12.780
earning trust and what are the
mechanisms and what are the tools that

01:32:12.780 --> 01:32:12.790
mechanisms and what are the tools that
 

01:32:12.790 --> 01:32:16.890
mechanisms and what are the tools that
we have to earn trust to verify trust to

01:32:16.890 --> 01:32:16.900
we have to earn trust to verify trust to
 

01:32:16.900 --> 01:32:19.109
we have to earn trust to verify trust to
have reliable systems predictable

01:32:19.109 --> 01:32:19.119
have reliable systems predictable
 

01:32:19.119 --> 01:32:21.390
have reliable systems predictable
systems confidence in our systems it's

01:32:21.390 --> 01:32:21.400
systems confidence in our systems it's
 

01:32:21.400 --> 01:32:26.780
systems confidence in our systems it's
not much more interesting than weapons

01:32:26.780 --> 01:32:26.790
 

01:32:26.790 --> 01:32:30.030
earning trust and in fact one of the

01:32:30.030 --> 01:32:30.040
earning trust and in fact one of the
 

01:32:30.040 --> 01:32:31.890
earning trust and in fact one of the
things that we are working on now is

01:32:31.890 --> 01:32:31.900
things that we are working on now is
 

01:32:31.900 --> 01:32:36.899
things that we are working on now is
like to have these robots actually what

01:32:36.899 --> 01:32:36.909
like to have these robots actually what
 

01:32:36.909 --> 01:32:39.839
like to have these robots actually what
we call verifiable answers so if I ask a

01:32:39.839 --> 01:32:39.849
we call verifiable answers so if I ask a
 

01:32:39.849 --> 01:32:41.580
we call verifiable answers so if I ask a
robot how long did it take you to go

01:32:41.580 --> 01:32:41.590
robot how long did it take you to go
 

01:32:41.590 --> 01:32:43.950
robot how long did it take you to go
from the lab to my office and the robot

01:32:43.950 --> 01:32:43.960
from the lab to my office and the robot
 

01:32:43.960 --> 01:32:47.010
from the lab to my office and the robot
says you know two minutes and a half how

01:32:47.010 --> 01:32:47.020
says you know two minutes and a half how
 

01:32:47.020 --> 01:32:49.770
says you know two minutes and a half how
do we know that number is right and so

01:32:49.770 --> 01:32:49.780
do we know that number is right and so
 

01:32:49.780 --> 01:32:51.569
do we know that number is right and so
what we do is that we actually have

01:32:51.569 --> 01:32:51.579
what we do is that we actually have
 

01:32:51.579 --> 01:32:53.910
what we do is that we actually have
techniques to decompose that question

01:32:53.910 --> 01:32:53.920
techniques to decompose that question
 

01:32:53.920 --> 01:32:57.899
techniques to decompose that question
and to say ok how much did he take you

01:32:57.899 --> 01:32:57.909
and to say ok how much did he take you
 

01:32:57.909 --> 01:33:00.060
and to say ok how much did he take you
from going to the lab to the kitchen and

01:33:00.060 --> 01:33:00.070
from going to the lab to the kitchen and
 

01:33:00.070 --> 01:33:03.270
from going to the lab to the kitchen and
the robot would say a minute and 10

01:33:03.270 --> 01:33:03.280
the robot would say a minute and 10
 

01:33:03.280 --> 01:33:05.459
the robot would say a minute and 10
seconds and now we ask from the kitchen

01:33:05.459 --> 01:33:05.469
seconds and now we ask from the kitchen
 

01:33:05.469 --> 01:33:08.970
seconds and now we ask from the kitchen
to my office and if these adapts to 2.5

01:33:08.970 --> 01:33:08.980
to my office and if these adapts to 2.5
 

01:33:08.980 --> 01:33:13.169
to my office and if these adapts to 2.5
30 we took 2 minutes and 30 seconds then

01:33:13.169 --> 01:33:13.179
30 we took 2 minutes and 30 seconds then
 

01:33:13.179 --> 01:33:15.750
30 we took 2 minutes and 30 seconds then
you trust that the answer was good so we

01:33:15.750 --> 01:33:15.760
you trust that the answer was good so we
 

01:33:15.760 --> 01:33:16.919
you trust that the answer was good so we
are doing a lot of research with

01:33:16.919 --> 01:33:16.929
are doing a lot of research with
 

01:33:16.929 --> 01:33:19.319
are doing a lot of research with
vittorio pereira in his PhD thesis on

01:33:19.319 --> 01:33:19.329
vittorio pereira in his PhD thesis on
 

01:33:19.329 --> 01:33:23.910
vittorio pereira in his PhD thesis on
this kind of like earning the trust on

01:33:23.910 --> 01:33:23.920
this kind of like earning the trust on
 

01:33:23.920 --> 01:33:26.640
this kind of like earning the trust on
finding methods to decompose your

01:33:26.640 --> 01:33:26.650
finding methods to decompose your
 

01:33:26.650 --> 01:33:28.680
finding methods to decompose your
questions so that there if there was a

01:33:28.680 --> 01:33:28.690
questions so that there if there was a
 

01:33:28.690 --> 01:33:33.629
questions so that there if there was a
malware or some wrong answer that you

01:33:33.629 --> 01:33:33.639
malware or some wrong answer that you
 

01:33:33.639 --> 01:33:34.930
malware or some wrong answer that you
cannot from a

01:33:34.930 --> 01:33:34.940
cannot from a
 

01:33:34.940 --> 01:33:37.840
cannot from a
theoretical point of view randomly

01:33:37.840 --> 01:33:37.850
theoretical point of view randomly
 

01:33:37.850 --> 01:33:41.650
theoretical point of view randomly
combined so much ever so much malware

01:33:41.650 --> 01:33:41.660
combined so much ever so much malware
 

01:33:41.660 --> 01:33:43.990
combined so much ever so much malware
that eventually things become consistent

01:33:43.990 --> 01:33:44.000
that eventually things become consistent
 

01:33:44.000 --> 01:33:47.680
that eventually things become consistent
so we are trying to earn trust not only

01:33:47.680 --> 01:33:47.690
so we are trying to earn trust not only
 

01:33:47.690 --> 01:33:51.450
so we are trying to earn trust not only
by explain ability but by checking

01:33:51.450 --> 01:33:51.460
by explain ability but by checking
 

01:33:51.460 --> 01:33:54.430
by explain ability but by checking
consistency of the answers such that

01:33:54.430 --> 01:33:54.440
consistency of the answers such that
 

01:33:54.440 --> 01:33:57.220
consistency of the answers such that
they actually add up to something that

01:33:57.220 --> 01:33:57.230
they actually add up to something that
 

01:33:57.230 --> 01:33:59.490
they actually add up to something that
makes sense and after all they are

01:33:59.490 --> 01:33:59.500
makes sense and after all they are
 

01:33:59.500 --> 01:34:01.420
makes sense and after all they are
computing or they are answering

01:34:01.420 --> 01:34:01.430
computing or they are answering
 

01:34:01.430 --> 01:34:04.270
computing or they are answering
something that overall makes sense and

01:34:04.270 --> 01:34:04.280
something that overall makes sense and
 

01:34:04.280 --> 01:34:07.570
something that overall makes sense and
it's proved to be right and so that's

01:34:07.570 --> 01:34:07.580
it's proved to be right and so that's
 

01:34:07.580 --> 01:34:09.280
it's proved to be right and so that's
something that's very new in our

01:34:09.280 --> 01:34:09.290
something that's very new in our
 

01:34:09.290 --> 01:34:12.189
something that's very new in our
research I mean we barely have started

01:34:12.189 --> 01:34:12.199
research I mean we barely have started
 

01:34:12.199 --> 01:34:15.520
research I mean we barely have started
this but again this is the question of

01:34:15.520 --> 01:34:15.530
this but again this is the question of
 

01:34:15.530 --> 01:34:17.260
this but again this is the question of
like when they give you an answer do you

01:34:17.260 --> 01:34:17.270
like when they give you an answer do you
 

01:34:17.270 --> 01:34:19.780
like when they give you an answer do you
trust it or not so you transform that is

01:34:19.780 --> 01:34:19.790
trust it or not so you transform that is
 

01:34:19.790 --> 01:34:21.040
trust it or not so you transform that is
like saying oh if it's giving me this

01:34:21.040 --> 01:34:21.050
like saying oh if it's giving me this
 

01:34:21.050 --> 01:34:23.500
like saying oh if it's giving me this
answer okay then I'm going to trick it

01:34:23.500 --> 01:34:23.510
answer okay then I'm going to trick it
 

01:34:23.510 --> 01:34:25.959
answer okay then I'm going to trick it
and ask them more questions until I'm

01:34:25.959 --> 01:34:25.969
and ask them more questions until I'm
 

01:34:25.969 --> 01:34:29.140
and ask them more questions until I'm
confident that I earned that I mean that

01:34:29.140 --> 01:34:29.150
confident that I earned that I mean that
 

01:34:29.150 --> 01:34:33.550
confident that I earned that I mean that
this thing is trust able I'll just put

01:34:33.550 --> 01:34:33.560
this thing is trust able I'll just put
 

01:34:33.560 --> 01:34:34.840
this thing is trust able I'll just put
in a quick plug I think that this is one

01:34:34.840 --> 01:34:34.850
in a quick plug I think that this is one
 

01:34:34.850 --> 01:34:37.390
in a quick plug I think that this is one
of those places where interdisciplinary

01:34:37.390 --> 01:34:37.400
of those places where interdisciplinary
 

01:34:37.400 --> 01:34:39.040
of those places where interdisciplinary
work multidisciplinary work becomes

01:34:39.040 --> 01:34:39.050
work multidisciplinary work becomes
 

01:34:39.050 --> 01:34:40.630
work multidisciplinary work becomes
really critical because this idea of

01:34:40.630 --> 01:34:40.640
really critical because this idea of
 

01:34:40.640 --> 01:34:42.250
really critical because this idea of
earning trust development of trust

01:34:42.250 --> 01:34:42.260
earning trust development of trust
 

01:34:42.260 --> 01:34:44.229
earning trust development of trust
that's that's an area that social

01:34:44.229 --> 01:34:44.239
that's that's an area that social
 

01:34:44.239 --> 01:34:46.090
that's that's an area that social
psychologists organizational behavior

01:34:46.090 --> 01:34:46.100
psychologists organizational behavior
 

01:34:46.100 --> 01:34:47.860
psychologists organizational behavior
theorists have have studied for a long

01:34:47.860 --> 01:34:47.870
theorists have have studied for a long
 

01:34:47.870 --> 01:34:49.840
theorists have have studied for a long
time so there's a lot of resources that

01:34:49.840 --> 01:34:49.850
time so there's a lot of resources that
 

01:34:49.850 --> 01:34:52.120
time so there's a lot of resources that
that can be sort of bootstrapped to

01:34:52.120 --> 01:34:52.130
that can be sort of bootstrapped to
 

01:34:52.130 --> 01:34:52.780
that can be sort of bootstrapped to
maybe

01:34:52.780 --> 01:34:52.790
maybe
 

01:34:52.790 --> 01:34:54.100
maybe
short-circuit some of these things but

01:34:54.100 --> 01:34:54.110
short-circuit some of these things but
 

01:34:54.110 --> 01:34:57.070
short-circuit some of these things but
mostly I'm sorry you know we talk a lot

01:34:57.070 --> 01:34:57.080
mostly I'm sorry you know we talk a lot
 

01:34:57.080 --> 01:34:58.930
mostly I'm sorry you know we talk a lot
about trusting technology but the

01:34:58.930 --> 01:34:58.940
about trusting technology but the
 

01:34:58.940 --> 01:35:00.700
about trusting technology but the
reality is Trust is mostly human

01:35:00.700 --> 01:35:00.710
reality is Trust is mostly human
 

01:35:00.710 --> 01:35:04.420
reality is Trust is mostly human
relationship so if I'm talking about the

01:35:04.420 --> 01:35:04.430
relationship so if I'm talking about the
 

01:35:04.430 --> 01:35:05.830
relationship so if I'm talking about the
robot it will come out of manual at

01:35:05.830 --> 01:35:05.840
robot it will come out of manual at
 

01:35:05.840 --> 01:35:07.510
robot it will come out of manual at
Manuela's lab and I said trust it all

01:35:07.510 --> 01:35:07.520
Manuela's lab and I said trust it all
 

01:35:07.520 --> 01:35:10.720
Manuela's lab and I said trust it all
but I really trust Manila to make best

01:35:10.720 --> 01:35:10.730
but I really trust Manila to make best
 

01:35:10.730 --> 01:35:12.520
but I really trust Manila to make best
efforts to give me something which is

01:35:12.520 --> 01:35:12.530
efforts to give me something which is
 

01:35:12.530 --> 01:35:16.420
efforts to give me something which is
going to be safe so because I really you

01:35:16.420 --> 01:35:16.430
going to be safe so because I really you
 

01:35:16.430 --> 01:35:18.580
going to be safe so because I really you
know I most of the time for most people

01:35:18.580 --> 01:35:18.590
know I most of the time for most people
 

01:35:18.590 --> 01:35:20.920
know I most of the time for most people
the technology is kind of a black box so

01:35:20.920 --> 01:35:20.930
the technology is kind of a black box so
 

01:35:20.930 --> 01:35:22.570
the technology is kind of a black box so
what does it mean that I trust this

01:35:22.570 --> 01:35:22.580
what does it mean that I trust this
 

01:35:22.580 --> 01:35:24.250
what does it mean that I trust this
program I have to trust the developer of

01:35:24.250 --> 01:35:24.260
program I have to trust the developer of
 

01:35:24.260 --> 01:35:26.080
program I have to trust the developer of
this program so we really need to think

01:35:26.080 --> 01:35:26.090
this program so we really need to think
 

01:35:26.090 --> 01:35:27.670
this program so we really need to think
about the different actors that are

01:35:27.670 --> 01:35:27.680
about the different actors that are
 

01:35:27.680 --> 01:35:30.760
about the different actors that are
involved here and to think of trust as a

01:35:30.760 --> 01:35:30.770
involved here and to think of trust as a
 

01:35:30.770 --> 01:35:32.170
involved here and to think of trust as a
relationship it's a human relationship

01:35:32.170 --> 01:35:32.180
relationship it's a human relationship
 

01:35:32.180 --> 01:35:34.570
relationship it's a human relationship
between different actors to a trust

01:35:34.570 --> 01:35:34.580
between different actors to a trust
 

01:35:34.580 --> 01:35:37.540
between different actors to a trust
Manuela yes do I trust certain

01:35:37.540 --> 01:35:37.550
Manuela yes do I trust certain
 

01:35:37.550 --> 01:35:45.120
Manuela yes do I trust certain
corporations maybe no do I trust a

01:35:45.120 --> 01:35:45.130
corporations maybe no do I trust a
 

01:35:45.130 --> 01:35:48.550
corporations maybe no do I trust a
developer that I know nothing about

01:35:48.550 --> 01:35:48.560
developer that I know nothing about
 

01:35:48.560 --> 01:35:51.160
developer that I know nothing about
you know I mean partly it's the same

01:35:51.160 --> 01:35:51.170
you know I mean partly it's the same
 

01:35:51.170 --> 01:35:55.180
you know I mean partly it's the same
thing you know when when we have a we

01:35:55.180 --> 01:35:55.190
thing you know when when we have a we
 

01:35:55.190 --> 01:35:56.860
thing you know when when we have a we
feel safe with people we know because we

01:35:56.860 --> 01:35:56.870
feel safe with people we know because we
 

01:35:56.870 --> 01:35:59.080
feel safe with people we know because we
have gone to rebuild trust between them

01:35:59.080 --> 01:35:59.090
have gone to rebuild trust between them
 

01:35:59.090 --> 01:36:01.090
have gone to rebuild trust between them
you walk into a place where you don't

01:36:01.090 --> 01:36:01.100
you walk into a place where you don't
 

01:36:01.100 --> 01:36:04.420
you walk into a place where you don't
know anyone and in certain areas of the

01:36:04.420 --> 01:36:04.430
know anyone and in certain areas of the
 

01:36:04.430 --> 01:36:06.880
know anyone and in certain areas of the
world still a stranger every stranger is

01:36:06.880 --> 01:36:06.890
world still a stranger every stranger is
 

01:36:06.890 --> 01:36:10.240
world still a stranger every stranger is
a potential risk and so so we have to

01:36:10.240 --> 01:36:10.250
a potential risk and so so we have to
 

01:36:10.250 --> 01:36:11.860
a potential risk and so so we have to
start thinking less about the technology

01:36:11.860 --> 01:36:11.870
start thinking less about the technology
 

01:36:11.870 --> 01:36:14.650
start thinking less about the technology
and more about who are the sort of of

01:36:14.650 --> 01:36:14.660
and more about who are the sort of of
 

01:36:14.660 --> 01:36:16.780
and more about who are the sort of of
characters in this play and what are the

01:36:16.780 --> 01:36:16.790
characters in this play and what are the
 

01:36:16.790 --> 01:36:18.430
characters in this play and what are the
set of trust we can have between them

01:36:18.430 --> 01:36:18.440
set of trust we can have between them
 

01:36:18.440 --> 01:36:20.260
set of trust we can have between them
and one of the sing of course we know in

01:36:20.260 --> 01:36:20.270
and one of the sing of course we know in
 

01:36:20.270 --> 01:36:22.150
and one of the sing of course we know in
warfare situation it's a different

01:36:22.150 --> 01:36:22.160
warfare situation it's a different
 

01:36:22.160 --> 01:36:24.040
warfare situation it's a different
situation and we have to see very

01:36:24.040 --> 01:36:24.050
situation and we have to see very
 

01:36:24.050 --> 01:36:25.990
situation and we have to see very
differently about trust then we think in

01:36:25.990 --> 01:36:26.000
differently about trust then we think in
 

01:36:26.000 --> 01:36:28.270
differently about trust then we think in
a non-hostile situation but I think the

01:36:28.270 --> 01:36:28.280
a non-hostile situation but I think the
 

01:36:28.280 --> 01:36:29.680
a non-hostile situation but I think the
trust ultimately it's not relation

01:36:29.680 --> 01:36:29.690
trust ultimately it's not relation
 

01:36:29.690 --> 01:36:32.080
trust ultimately it's not relation
between human and machine it's a

01:36:32.080 --> 01:36:32.090
between human and machine it's a
 

01:36:32.090 --> 01:36:36.480
between human and machine it's a
relationship between humans

01:36:36.480 --> 01:36:36.490
 

01:36:36.490 --> 01:36:39.640
well it seems we'll be like humans they

01:36:39.640 --> 01:36:39.650
well it seems we'll be like humans they
 

01:36:39.650 --> 01:36:41.980
well it seems we'll be like humans they
will make decisions they will process

01:36:41.980 --> 01:36:41.990
will make decisions they will process
 

01:36:41.990 --> 01:36:44.470
will make decisions they will process
information they will have tons of data

01:36:44.470 --> 01:36:44.480
information they will have tons of data
 

01:36:44.480 --> 01:36:46.810
information they will have tons of data
and they will be things you interact

01:36:46.810 --> 01:36:46.820
and they will be things you interact
 

01:36:46.820 --> 01:36:49.150
and they will be things you interact
with like you interact with humans so

01:36:49.150 --> 01:36:49.160
with like you interact with humans so
 

01:36:49.160 --> 01:36:51.880
with like you interact with humans so
eventually you may want to also trust

01:36:51.880 --> 01:36:51.890
eventually you may want to also trust
 

01:36:51.890 --> 01:36:55.810
eventually you may want to also trust
the machinery and not just the humans

01:36:55.810 --> 01:36:55.820
the machinery and not just the humans
 

01:36:55.820 --> 01:36:56.860
the machinery and not just the humans
will develop the machine I don't

01:36:56.860 --> 01:36:56.870
will develop the machine I don't
 

01:36:56.870 --> 01:36:58.990
will develop the machine I don't
disagree but if I trust my refrigerator

01:36:58.990 --> 01:36:59.000
disagree but if I trust my refrigerator
 

01:36:59.000 --> 01:37:02.320
disagree but if I trust my refrigerator
is because I really trust ultimately the

01:37:02.320 --> 01:37:02.330
is because I really trust ultimately the
 

01:37:02.330 --> 01:37:04.150
is because I really trust ultimately the
process that led to building this I mean

01:37:04.150 --> 01:37:04.160
process that led to building this I mean
 

01:37:04.160 --> 01:37:06.070
process that led to building this I mean
how does that every filter of mmm I

01:37:06.070 --> 01:37:06.080
how does that every filter of mmm I
 

01:37:06.080 --> 01:37:08.770
how does that every filter of mmm I
trust one because it does what it's

01:37:08.770 --> 01:37:08.780
trust one because it does what it's
 

01:37:08.780 --> 01:37:11.200
trust one because it does what it's
supposed to do but I don't think there's

01:37:11.200 --> 01:37:11.210
supposed to do but I don't think there's
 

01:37:11.210 --> 01:37:13.270
supposed to do but I don't think there's
anything nefarious about it that really

01:37:13.270 --> 01:37:13.280
anything nefarious about it that really
 

01:37:13.280 --> 01:37:14.920
anything nefarious about it that really
the goal is at some point to suddenly

01:37:14.920 --> 01:37:14.930
the goal is at some point to suddenly
 

01:37:14.930 --> 01:37:16.840
the goal is at some point to suddenly
surprise me and give me poison food

01:37:16.840 --> 01:37:16.850
surprise me and give me poison food
 

01:37:16.850 --> 01:37:18.970
surprise me and give me poison food
because you know I've the people who

01:37:18.970 --> 01:37:18.980
because you know I've the people who
 

01:37:18.980 --> 01:37:21.670
because you know I've the people who
built I trust them ultimately so we end

01:37:21.670 --> 01:37:21.680
built I trust them ultimately so we end
 

01:37:21.680 --> 01:37:24.550
built I trust them ultimately so we end
up trusting me trusting machines by by

01:37:24.550 --> 01:37:24.560
up trusting me trusting machines by by
 

01:37:24.560 --> 01:37:26.440
up trusting me trusting machines by by
their predictability if something is

01:37:26.440 --> 01:37:26.450
their predictability if something is
 

01:37:26.450 --> 01:37:28.000
their predictability if something is
predictably having a certain way which

01:37:28.000 --> 01:37:28.010
predictably having a certain way which
 

01:37:28.010 --> 01:37:31.450
predictably having a certain way which
says okay but also we we intuitively

01:37:31.450 --> 01:37:31.460
says okay but also we we intuitively
 

01:37:31.460 --> 01:37:34.060
says okay but also we we intuitively
think about the dose the Actos human

01:37:34.060 --> 01:37:34.070
think about the dose the Actos human
 

01:37:34.070 --> 01:37:36.160
think about the dose the Actos human
actors involved in this which of course

01:37:36.160 --> 01:37:36.170
actors involved in this which of course
 

01:37:36.170 --> 01:37:38.350
actors involved in this which of course
then raises a whole other set of issues

01:37:38.350 --> 01:37:38.360
then raises a whole other set of issues
 

01:37:38.360 --> 01:37:40.660
then raises a whole other set of issues
and complexities around when you have

01:37:40.660 --> 01:37:40.670
and complexities around when you have
 

01:37:40.670 --> 01:37:42.910
and complexities around when you have
companies doing this that for good

01:37:42.910 --> 01:37:42.920
companies doing this that for good
 

01:37:42.920 --> 01:37:44.260
companies doing this that for good
competitive reasons I'm not going to

01:37:44.260 --> 01:37:44.270
competitive reasons I'm not going to
 

01:37:44.270 --> 01:37:46.030
competitive reasons I'm not going to
disclose how they built the technology

01:37:46.030 --> 01:37:46.040
disclose how they built the technology
 

01:37:46.040 --> 01:37:48.370
disclose how they built the technology
are not gonna how do we get transparency

01:37:48.370 --> 01:37:48.380
are not gonna how do we get transparency
 

01:37:48.380 --> 01:37:50.860
are not gonna how do we get transparency
of those of that sort and I think these

01:37:50.860 --> 01:37:50.870
of those of that sort and I think these
 

01:37:50.870 --> 01:37:53.080
of those of that sort and I think these
raise an enormous number of questions

01:37:53.080 --> 01:37:53.090
raise an enormous number of questions
 

01:37:53.090 --> 01:37:54.670
raise an enormous number of questions
and unfortunately I'm getting the red

01:37:54.670 --> 01:37:54.680
and unfortunately I'm getting the red
 

01:37:54.680 --> 01:37:57.390
and unfortunately I'm getting the red
light that tells us that that our

01:37:57.390 --> 01:37:57.400
light that tells us that that our
 

01:37:57.400 --> 01:38:00.010
light that tells us that that our
conversation is coming to a close I

01:38:00.010 --> 01:38:00.020
conversation is coming to a close I
 

01:38:00.020 --> 01:38:02.080
conversation is coming to a close I
wanted to give you each

01:38:02.080 --> 01:38:02.090
wanted to give you each
 

01:38:02.090 --> 01:38:04.600
wanted to give you each
one minute if you want to say something

01:38:04.600 --> 01:38:04.610
one minute if you want to say something
 

01:38:04.610 --> 01:38:06.640
one minute if you want to say something
very quickly sort of in closing I just

01:38:06.640 --> 01:38:06.650
very quickly sort of in closing I just
 

01:38:06.650 --> 01:38:09.250
very quickly sort of in closing I just
want to say one thing I saw recently a

01:38:09.250 --> 01:38:09.260
want to say one thing I saw recently a
 

01:38:09.260 --> 01:38:13.209
want to say one thing I saw recently a
very interesting video in New York then

01:38:13.209 --> 01:38:13.219
very interesting video in New York then
 

01:38:13.219 --> 01:38:15.939
very interesting video in New York then
which people were interviewed on the

01:38:15.939 --> 01:38:15.949
which people were interviewed on the
 

01:38:15.949 --> 01:38:20.379
which people were interviewed on the
streets about these things we kind of

01:38:20.379 --> 01:38:20.389
streets about these things we kind of
 

01:38:20.389 --> 01:38:22.750
streets about these things we kind of
mark I accept all those terms of

01:38:22.750 --> 01:38:22.760
mark I accept all those terms of
 

01:38:22.760 --> 01:38:25.810
mark I accept all those terms of
conditions of iPhones and Facebook's and

01:38:25.810 --> 01:38:25.820
conditions of iPhones and Facebook's and
 

01:38:25.820 --> 01:38:29.709
conditions of iPhones and Facebook's and
all of this and they were horrible the

01:38:29.709 --> 01:38:29.719
all of this and they were horrible the
 

01:38:29.719 --> 01:38:32.739
all of this and they were horrible the
things we accept and I was looking at

01:38:32.739 --> 01:38:32.749
things we accept and I was looking at
 

01:38:32.749 --> 01:38:34.419
things we accept and I was looking at
that I mean I was looking at that and

01:38:34.419 --> 01:38:34.429
that I mean I was looking at that and
 

01:38:34.429 --> 01:38:37.270
that I mean I was looking at that and
say guess what it was a lawyer

01:38:37.270 --> 01:38:37.280
say guess what it was a lawyer
 

01:38:37.280 --> 01:38:39.879
say guess what it was a lawyer
it was a human who generated that thing

01:38:39.879 --> 01:38:39.889
it was a human who generated that thing
 

01:38:39.889 --> 01:38:41.919
it was a human who generated that thing
and not an AI system

01:38:41.919 --> 01:38:41.929
and not an AI system
 

01:38:41.929 --> 01:38:45.009
and not an AI system
imagine if their texts were generated by

01:38:45.009 --> 01:38:45.019
imagine if their texts were generated by
 

01:38:45.019 --> 01:38:47.679
imagine if their texts were generated by
a robot or an AI system which was

01:38:47.679 --> 01:38:47.689
a robot or an AI system which was
 

01:38:47.689 --> 01:38:50.439
a robot or an AI system which was
fooling me into accepting all sorts of

01:38:50.439 --> 01:38:50.449
fooling me into accepting all sorts of
 

01:38:50.449 --> 01:38:52.750
fooling me into accepting all sorts of
like horrible things that we accept we

01:38:52.750 --> 01:38:52.760
like horrible things that we accept we
 

01:38:52.760 --> 01:38:54.790
like horrible things that we accept we
never read that like pages and pages and

01:38:54.790 --> 01:38:54.800
never read that like pages and pages and
 

01:38:54.800 --> 01:38:57.699
never read that like pages and pages and
pages and whoever generated that was not

01:38:57.699 --> 01:38:57.709
pages and whoever generated that was not
 

01:38:57.709 --> 01:39:01.750
pages and whoever generated that was not
an AI system was a human so shame on the

01:39:01.750 --> 01:39:01.760
an AI system was a human so shame on the
 

01:39:01.760 --> 01:39:04.839
an AI system was a human so shame on the
humans in the sense that that's where

01:39:04.839 --> 01:39:04.849
humans in the sense that that's where
 

01:39:04.849 --> 01:39:07.149
humans in the sense that that's where
like I go back now to what Moshe was

01:39:07.149 --> 01:39:07.159
like I go back now to what Moshe was
 

01:39:07.159 --> 01:39:09.790
like I go back now to what Moshe was
saying but let's educate the humans

01:39:09.790 --> 01:39:09.800
saying but let's educate the humans
 

01:39:09.800 --> 01:39:13.779
saying but let's educate the humans
let's eventually have the humans make

01:39:13.779 --> 01:39:13.789
let's eventually have the humans make
 

01:39:13.789 --> 01:39:16.449
let's eventually have the humans make
these things we accept on in terms of

01:39:16.449 --> 01:39:16.459
these things we accept on in terms of
 

01:39:16.459 --> 01:39:18.819
these things we accept on in terms of
like machinery be trusted trusted

01:39:18.819 --> 01:39:18.829
like machinery be trusted trusted
 

01:39:18.829 --> 01:39:22.029
like machinery be trusted trusted
because this Facebook example yes we

01:39:22.029 --> 01:39:22.039
because this Facebook example yes we
 

01:39:22.039 --> 01:39:23.890
because this Facebook example yes we
didn't accept but how did you know that

01:39:23.890 --> 01:39:23.900
didn't accept but how did you know that
 

01:39:23.900 --> 01:39:25.629
didn't accept but how did you know that
in the whole thing that you signed up

01:39:25.629 --> 01:39:25.639
in the whole thing that you signed up
 

01:39:25.639 --> 01:39:27.819
in the whole thing that you signed up
for you were not accepting that these

01:39:27.819 --> 01:39:27.829
for you were not accepting that these
 

01:39:27.829 --> 01:39:29.890
for you were not accepting that these
data would go somewhere else I mean I

01:39:29.890 --> 01:39:29.900
data would go somewhere else I mean I
 

01:39:29.900 --> 01:39:33.009
data would go somewhere else I mean I
have no clue you know we just accept so

01:39:33.009 --> 01:39:33.019
have no clue you know we just accept so
 

01:39:33.019 --> 01:39:36.009
have no clue you know we just accept so
Humanzee the loop of technology need to

01:39:36.009 --> 01:39:36.019
Humanzee the loop of technology need to
 

01:39:36.019 --> 01:39:38.620
Humanzee the loop of technology need to
make sure that things are trustable and

01:39:38.620 --> 01:39:38.630
make sure that things are trustable and
 

01:39:38.630 --> 01:39:41.049
make sure that things are trustable and
humans need to hear make sure that that

01:39:41.049 --> 01:39:41.059
humans need to hear make sure that that
 

01:39:41.059 --> 01:39:47.739
humans need to hear make sure that that
is the case I'm sorry for my case but

01:39:47.739 --> 01:39:47.749
is the case I'm sorry for my case but
 

01:39:47.749 --> 01:39:50.229
is the case I'm sorry for my case but
that's really intimidating the things we

01:39:50.229 --> 01:39:50.239
that's really intimidating the things we
 

01:39:50.239 --> 01:39:52.479
that's really intimidating the things we
accept in these terms and conditions

01:39:52.479 --> 01:39:52.489
accept in these terms and conditions
 

01:39:52.489 --> 01:39:54.399
accept in these terms and conditions
it's like oh my god what am i signing

01:39:54.399 --> 01:39:54.409
it's like oh my god what am i signing
 

01:39:54.409 --> 01:39:58.029
it's like oh my god what am i signing
for and somehow it's still not generated

01:39:58.029 --> 01:39:58.039
for and somehow it's still not generated
 

01:39:58.039 --> 01:40:00.790
for and somehow it's still not generated
by an AI system and I wonder if it were

01:40:00.790 --> 01:40:00.800
by an AI system and I wonder if it were
 

01:40:00.800 --> 01:40:02.709
by an AI system and I wonder if it were
an AI system generating those conditions

01:40:02.709 --> 01:40:02.719
an AI system generating those conditions
 

01:40:02.719 --> 01:40:05.859
an AI system generating those conditions
if people would not be all outraged how

01:40:05.859 --> 01:40:05.869
if people would not be all outraged how
 

01:40:05.869 --> 01:40:09.699
if people would not be all outraged how
common AI system told me to accept all

01:40:09.699 --> 01:40:09.709
common AI system told me to accept all
 

01:40:09.709 --> 01:40:12.459
common AI system told me to accept all
these conditions I'm telling you trust

01:40:12.459 --> 01:40:12.469
these conditions I'm telling you trust
 

01:40:12.469 --> 01:40:14.709
these conditions I'm telling you trust
in technology rather than humans

01:40:14.709 --> 01:40:14.719
in technology rather than humans
 

01:40:14.719 --> 01:40:18.160
in technology rather than humans
mosha any final thought I I think we

01:40:18.160 --> 01:40:18.170
mosha any final thought I I think we
 

01:40:18.170 --> 01:40:20.379
mosha any final thought I I think we
really need to think very hard about

01:40:20.379 --> 01:40:20.389
really need to think very hard about
 

01:40:20.389 --> 01:40:22.760
really need to think very hard about
what makes corporations behave

01:40:22.760 --> 01:40:22.770
what makes corporations behave
 

01:40:22.770 --> 01:40:24.890
what makes corporations behave
unethically and it's not the people in

01:40:24.890 --> 01:40:24.900
unethically and it's not the people in
 

01:40:24.900 --> 01:40:26.839
unethically and it's not the people in
them I mean some of the people here from

01:40:26.839 --> 01:40:26.849
them I mean some of the people here from
 

01:40:26.849 --> 01:40:29.629
them I mean some of the people here from
cooperation as we serve some of I spent

01:40:29.629 --> 01:40:29.639
cooperation as we serve some of I spent
 

01:40:29.639 --> 01:40:31.580
cooperation as we serve some of I spent
a big part of my life in a cooperation

01:40:31.580 --> 01:40:31.590
a big part of my life in a cooperation
 

01:40:31.590 --> 01:40:34.069
a big part of my life in a cooperation
many of conferencing cooperation but

01:40:34.069 --> 01:40:34.079
many of conferencing cooperation but
 

01:40:34.079 --> 01:40:35.390
many of conferencing cooperation but
nevertheless there is something our

01:40:35.390 --> 01:40:35.400
nevertheless there is something our
 

01:40:35.400 --> 01:40:37.569
nevertheless there is something our
current economic system that makes

01:40:37.569 --> 01:40:37.579
current economic system that makes
 

01:40:37.579 --> 01:40:40.100
current economic system that makes
corporations behave legally and

01:40:40.100 --> 01:40:40.110
corporations behave legally and
 

01:40:40.110 --> 01:40:43.160
corporations behave legally and
ethically and that means either we need

01:40:43.160 --> 01:40:43.170
ethically and that means either we need
 

01:40:43.170 --> 01:40:45.530
ethically and that means either we need
to change the laws to make more

01:40:45.530 --> 01:40:45.540
to change the laws to make more
 

01:40:45.540 --> 01:40:47.810
to change the laws to make more
behaviors illegal or we need to rethink

01:40:47.810 --> 01:40:47.820
behaviors illegal or we need to rethink
 

01:40:47.820 --> 01:40:49.399
behaviors illegal or we need to rethink
the incentive system under which they

01:40:49.399 --> 01:40:49.409
the incentive system under which they
 

01:40:49.409 --> 01:40:51.919
the incentive system under which they
operate because they are just right now

01:40:51.919 --> 01:40:51.929
operate because they are just right now
 

01:40:51.929 --> 01:40:54.649
operate because they are just right now
in this part of our history so immensely

01:40:54.649 --> 01:40:54.659
in this part of our history so immensely
 

01:40:54.659 --> 01:40:57.229
in this part of our history so immensely
powerful the day behavior has huge

01:40:57.229 --> 01:40:57.239
powerful the day behavior has huge
 

01:40:57.239 --> 01:41:03.020
powerful the day behavior has huge
impact on our lives sometimes I think we

01:41:03.020 --> 01:41:03.030
impact on our lives sometimes I think we
 

01:41:03.030 --> 01:41:04.700
impact on our lives sometimes I think we
get we get caught up in the bright and

01:41:04.700 --> 01:41:04.710
get we get caught up in the bright and
 

01:41:04.710 --> 01:41:06.709
get we get caught up in the bright and
shiny and the possibilities and the

01:41:06.709 --> 01:41:06.719
shiny and the possibilities and the
 

01:41:06.719 --> 01:41:09.049
shiny and the possibilities and the
potentials of new technologies and we

01:41:09.049 --> 01:41:09.059
potentials of new technologies and we
 

01:41:09.059 --> 01:41:11.830
potentials of new technologies and we
forget that these technologies serve us

01:41:11.830 --> 01:41:11.840
forget that these technologies serve us
 

01:41:11.840 --> 01:41:15.919
forget that these technologies serve us
right and so rather than starting always

01:41:15.919 --> 01:41:15.929
right and so rather than starting always
 

01:41:15.929 --> 01:41:19.250
right and so rather than starting always
as a technology centric conversation

01:41:19.250 --> 01:41:19.260
as a technology centric conversation
 

01:41:19.260 --> 01:41:21.169
as a technology centric conversation
which is not only constantly evolving

01:41:21.169 --> 01:41:21.179
which is not only constantly evolving
 

01:41:21.179 --> 01:41:22.970
which is not only constantly evolving
due to innovation but also quite

01:41:22.970 --> 01:41:22.980
due to innovation but also quite
 

01:41:22.980 --> 01:41:25.100
due to innovation but also quite
alienating for a large part of the the

01:41:25.100 --> 01:41:25.110
alienating for a large part of the the
 

01:41:25.110 --> 01:41:26.450
alienating for a large part of the the
population who doesn't have the

01:41:26.450 --> 01:41:26.460
population who doesn't have the
 

01:41:26.460 --> 01:41:28.010
population who doesn't have the
technological sophistication to

01:41:28.010 --> 01:41:28.020
technological sophistication to
 

01:41:28.020 --> 01:41:30.310
technological sophistication to
participate in some of the more deeper

01:41:30.310 --> 01:41:30.320
participate in some of the more deeper
 

01:41:30.320 --> 01:41:32.750
participate in some of the more deeper
conversations about it we need to be

01:41:32.750 --> 01:41:32.760
conversations about it we need to be
 

01:41:32.760 --> 01:41:35.569
conversations about it we need to be
having more human centric conversations

01:41:35.569 --> 01:41:35.579
having more human centric conversations
 

01:41:35.579 --> 01:41:40.399
having more human centric conversations
about how humans employ technology to to

01:41:40.399 --> 01:41:40.409
about how humans employ technology to to
 

01:41:40.409 --> 01:41:42.350
about how humans employ technology to to
meet human objectives unfortunately in

01:41:42.350 --> 01:41:42.360
meet human objectives unfortunately in
 

01:41:42.360 --> 01:41:44.689
meet human objectives unfortunately in
my in my field that's human objectives

01:41:44.689 --> 01:41:44.699
my in my field that's human objectives
 

01:41:44.699 --> 01:41:46.490
my in my field that's human objectives
of conflict and resolving these are the

01:41:46.490 --> 01:41:46.500
of conflict and resolving these are the
 

01:41:46.500 --> 01:41:48.830
of conflict and resolving these are the
tools of violence that humans decide to

01:41:48.830 --> 01:41:48.840
tools of violence that humans decide to
 

01:41:48.840 --> 01:41:51.740
tools of violence that humans decide to
employ but in other fields whether it's

01:41:51.740 --> 01:41:51.750
employ but in other fields whether it's
 

01:41:51.750 --> 01:41:54.200
employ but in other fields whether it's
healthcare education or criminal justice

01:41:54.200 --> 01:41:54.210
healthcare education or criminal justice
 

01:41:54.210 --> 01:41:56.629
healthcare education or criminal justice
these are tools that work for us and we

01:41:56.629 --> 01:41:56.639
these are tools that work for us and we
 

01:41:56.639 --> 01:42:01.069
these are tools that work for us and we
need to can affirm our human values and

01:42:01.069 --> 01:42:01.079
need to can affirm our human values and
 

01:42:01.079 --> 01:42:03.649
need to can affirm our human values and
our objectives and our desires and what

01:42:03.649 --> 01:42:03.659
our objectives and our desires and what
 

01:42:03.659 --> 01:42:06.379
our objectives and our desires and what
levels of trust we're going to demand or

01:42:06.379 --> 01:42:06.389
levels of trust we're going to demand or
 

01:42:06.389 --> 01:42:10.459
levels of trust we're going to demand or
what what metrics we're going to use and

01:42:10.459 --> 01:42:10.469
what what metrics we're going to use and
 

01:42:10.469 --> 01:42:14.390
what what metrics we're going to use and
then ensure that our deployers and our

01:42:14.390 --> 01:42:14.400
then ensure that our deployers and our
 

01:42:14.400 --> 01:42:17.089
then ensure that our deployers and our
developers of technologies meet those

01:42:17.089 --> 01:42:17.099
developers of technologies meet those
 

01:42:17.099 --> 01:42:21.260
developers of technologies meet those
requirements because we're in charge at

01:42:21.260 --> 01:42:21.270
requirements because we're in charge at
 

01:42:21.270 --> 01:42:21.830
requirements because we're in charge at
least for now

01:42:21.830 --> 01:42:21.840
least for now
 

01:42:21.840 --> 01:42:25.100
least for now
[Laughter]

01:42:25.100 --> 01:42:25.110
[Laughter]
 

01:42:25.110 --> 01:42:27.080
[Laughter]
so with that call to action let's thank

01:42:27.080 --> 01:42:27.090
so with that call to action let's thank
 

01:42:27.090 --> 01:42:27.690
so with that call to action let's thank
our

01:42:27.690 --> 01:42:27.700
our
 

01:42:27.700 --> 01:42:37.440
our
panelists conversations so we're now

01:42:37.440 --> 01:42:37.450
panelists conversations so we're now
 

01:42:37.450 --> 01:42:42.960
panelists conversations so we're now
going to shift to one last part of our

01:42:42.960 --> 01:42:42.970
going to shift to one last part of our
 

01:42:42.970 --> 01:42:45.690
going to shift to one last part of our
session which is please leave the

01:42:45.690 --> 01:42:45.700
session which is please leave the
 

01:42:45.700 --> 01:42:47.130
session which is please leave the
microphone so sorry

01:42:47.130 --> 01:42:47.140
microphone so sorry
 

01:42:47.140 --> 01:42:48.750
microphone so sorry
they'll get back up there eventually

01:42:48.750 --> 01:42:48.760
they'll get back up there eventually
 

01:42:48.760 --> 01:42:52.230
they'll get back up there eventually
which is a final spotlight talk by

01:42:52.230 --> 01:42:52.240
which is a final spotlight talk by
 

01:42:52.240 --> 01:42:54.900
which is a final spotlight talk by
Professor Anka dragon who is an

01:42:54.900 --> 01:42:54.910
Professor Anka dragon who is an
 

01:42:54.910 --> 01:42:56.250
Professor Anka dragon who is an
assistant professor in electrical

01:42:56.250 --> 01:42:56.260
assistant professor in electrical
 

01:42:56.260 --> 01:42:57.960
assistant professor in electrical
engineering and computer science at UC

01:42:57.960 --> 01:42:57.970
engineering and computer science at UC
 

01:42:57.970 --> 01:43:02.130
engineering and computer science at UC
Berkeley and a I believe proud at least

01:43:02.130 --> 01:43:02.140
Berkeley and a I believe proud at least
 

01:43:02.140 --> 01:43:04.920
Berkeley and a I believe proud at least
an alumna got her PhD from here at

01:43:04.920 --> 01:43:04.930
an alumna got her PhD from here at
 

01:43:04.930 --> 01:43:06.270
an alumna got her PhD from here at
Carnegie Mellon and I think is proud of

01:43:06.270 --> 01:43:06.280
Carnegie Mellon and I think is proud of
 

01:43:06.280 --> 01:43:09.750
Carnegie Mellon and I think is proud of
that fact I hope and she at Berkeley

01:43:09.750 --> 01:43:09.760
that fact I hope and she at Berkeley
 

01:43:09.760 --> 01:43:11.790
that fact I hope and she at Berkeley
runs the interactive autonomy and

01:43:11.790 --> 01:43:11.800
runs the interactive autonomy and
 

01:43:11.800 --> 01:43:13.770
runs the interactive autonomy and
collaborative technologies or interact

01:43:13.770 --> 01:43:13.780
collaborative technologies or interact
 

01:43:13.780 --> 01:43:15.870
collaborative technologies or interact
lab which is really focused on a lot of

01:43:15.870 --> 01:43:15.880
lab which is really focused on a lot of
 

01:43:15.880 --> 01:43:17.760
lab which is really focused on a lot of
these questions about human and human

01:43:17.760 --> 01:43:17.770
these questions about human and human
 

01:43:17.770 --> 01:43:21.240
these questions about human and human
robot interaction how do we have robots

01:43:21.240 --> 01:43:21.250
robot interaction how do we have robots
 

01:43:21.250 --> 01:43:23.640
robot interaction how do we have robots
that actually are able to interact with

01:43:23.640 --> 01:43:23.650
that actually are able to interact with
 

01:43:23.650 --> 01:43:25.950
that actually are able to interact with
humans in ways that can support and

01:43:25.950 --> 01:43:25.960
humans in ways that can support and
 

01:43:25.960 --> 01:43:29.130
humans in ways that can support and
empower both sides which requires doing

01:43:29.130 --> 01:43:29.140
empower both sides which requires doing
 

01:43:29.140 --> 01:43:31.020
empower both sides which requires doing
research really at the intersections of

01:43:31.020 --> 01:43:31.030
research really at the intersections of
 

01:43:31.030 --> 01:43:33.240
research really at the intersections of
robotics machine learning and cognitive

01:43:33.240 --> 01:43:33.250
robotics machine learning and cognitive
 

01:43:33.250 --> 01:43:35.460
robotics machine learning and cognitive
science she's also helped to found the

01:43:35.460 --> 01:43:35.470
science she's also helped to found the
 

01:43:35.470 --> 01:43:38.220
science she's also helped to found the
Berkeley AI Research Lab is a COPI I of

01:43:38.220 --> 01:43:38.230
Berkeley AI Research Lab is a COPI I of
 

01:43:38.230 --> 01:43:40.350
Berkeley AI Research Lab is a COPI I of
the Center for human compatible AI and

01:43:40.350 --> 01:43:40.360
the Center for human compatible AI and
 

01:43:40.360 --> 01:43:43.500
the Center for human compatible AI and
has won multiple early career Awards and

01:43:43.500 --> 01:43:43.510
has won multiple early career Awards and
 

01:43:43.510 --> 01:43:44.940
has won multiple early career Awards and
were delighted to welcome her about to

01:43:44.940 --> 01:43:44.950
were delighted to welcome her about to
 

01:43:44.950 --> 01:43:51.069
were delighted to welcome her about to
Pittsburgh on code jargon

01:43:51.069 --> 01:43:51.079
 

01:43:51.079 --> 01:43:53.569
hi everyone pleasure to be here I am

01:43:53.569 --> 01:43:53.579
hi everyone pleasure to be here I am
 

01:43:53.579 --> 01:43:56.629
hi everyone pleasure to be here I am
going to basically agree with everything

01:43:56.629 --> 01:43:56.639
going to basically agree with everything
 

01:43:56.639 --> 01:43:58.459
going to basically agree with everything
that Manuel I said and maybe add one

01:43:58.459 --> 01:43:58.469
that Manuel I said and maybe add one
 

01:43:58.469 --> 01:44:03.109
that Manuel I said and maybe add one
twist so robots take actions that change

01:44:03.109 --> 01:44:03.119
twist so robots take actions that change
 

01:44:03.119 --> 01:44:04.729
twist so robots take actions that change
the state of the world and as we've

01:44:04.729 --> 01:44:04.739
the state of the world and as we've
 

01:44:04.739 --> 01:44:07.459
the state of the world and as we've
heard yesterday what the way they choose

01:44:07.459 --> 01:44:07.469
heard yesterday what the way they choose
 

01:44:07.469 --> 01:44:09.469
heard yesterday what the way they choose
the actions to take is usually via

01:44:09.469 --> 01:44:09.479
the actions to take is usually via
 

01:44:09.479 --> 01:44:11.119
the actions to take is usually via
something called a reward function or

01:44:11.119 --> 01:44:11.129
something called a reward function or
 

01:44:11.129 --> 01:44:12.979
something called a reward function or
objective function so they plan actions

01:44:12.979 --> 01:44:12.989
objective function so they plan actions
 

01:44:12.989 --> 01:44:16.699
objective function so they plan actions
that in expectation maximize cumulative

01:44:16.699 --> 01:44:16.709
that in expectation maximize cumulative
 

01:44:16.709 --> 01:44:20.089
that in expectation maximize cumulative
reward I think when things can go wrong

01:44:20.089 --> 01:44:20.099
reward I think when things can go wrong
 

01:44:20.099 --> 01:44:23.509
reward I think when things can go wrong
is when people have mental models of

01:44:23.509 --> 01:44:23.519
is when people have mental models of
 

01:44:23.519 --> 01:44:25.790
is when people have mental models of
these robots then do not match up with

01:44:25.790 --> 01:44:25.800
these robots then do not match up with
 

01:44:25.800 --> 01:44:29.750
these robots then do not match up with
reality and so I've been so there for

01:44:29.750 --> 01:44:29.760
reality and so I've been so there for
 

01:44:29.760 --> 01:44:32.029
reality and so I've been so there for
instance the robot is much less capable

01:44:32.029 --> 01:44:32.039
instance the robot is much less capable
 

01:44:32.039 --> 01:44:33.619
instance the robot is much less capable
than what the person assumes or it

01:44:33.619 --> 01:44:33.629
than what the person assumes or it
 

01:44:33.629 --> 01:44:35.659
than what the person assumes or it
doesn't take the actions that the person

01:44:35.659 --> 01:44:35.669
doesn't take the actions that the person
 

01:44:35.669 --> 01:44:38.359
doesn't take the actions that the person
thinks that the robot will take and so

01:44:38.359 --> 01:44:38.369
thinks that the robot will take and so
 

01:44:38.369 --> 01:44:40.580
thinks that the robot will take and so
I've been asked to talk about trust but

01:44:40.580 --> 01:44:40.590
I've been asked to talk about trust but
 

01:44:40.590 --> 01:44:42.709
I've been asked to talk about trust but
what I really want to talk about is not

01:44:42.709 --> 01:44:42.719
what I really want to talk about is not
 

01:44:42.719 --> 01:44:44.929
what I really want to talk about is not
so much how do we get people to trust

01:44:44.929 --> 01:44:44.939
so much how do we get people to trust
 

01:44:44.939 --> 01:44:47.929
so much how do we get people to trust
these systems but rather how do we

01:44:47.929 --> 01:44:47.939
these systems but rather how do we
 

01:44:47.939 --> 01:44:50.629
these systems but rather how do we
ensure alignment between the person's

01:44:50.629 --> 01:44:50.639
ensure alignment between the person's
 

01:44:50.639 --> 01:44:53.299
ensure alignment between the person's
mental model and reality and I think

01:44:53.299 --> 01:44:53.309
mental model and reality and I think
 

01:44:53.309 --> 01:44:54.859
mental model and reality and I think
that there's two complimentary ways to

01:44:54.859 --> 01:44:54.869
that there's two complimentary ways to
 

01:44:54.869 --> 01:44:57.319
that there's two complimentary ways to
talk about doing that on the one hand we

01:44:57.319 --> 01:44:57.329
talk about doing that on the one hand we
 

01:44:57.329 --> 01:44:59.899
talk about doing that on the one hand we
can work on the robot side and try to

01:44:59.899 --> 01:44:59.909
can work on the robot side and try to
 

01:44:59.909 --> 01:45:02.629
can work on the robot side and try to
bring the robot up to match to live up

01:45:02.629 --> 01:45:02.639
bring the robot up to match to live up
 

01:45:02.639 --> 01:45:04.580
bring the robot up to match to live up
to our expectations and I would call

01:45:04.580 --> 01:45:04.590
to our expectations and I would call
 

01:45:04.590 --> 01:45:06.409
to our expectations and I would call
that making a trust ball or trustworthy

01:45:06.409 --> 01:45:06.419
that making a trust ball or trustworthy
 

01:45:06.419 --> 01:45:09.709
that making a trust ball or trustworthy
on the other hand we could work on the

01:45:09.709 --> 01:45:09.719
on the other hand we could work on the
 

01:45:09.719 --> 01:45:12.350
on the other hand we could work on the
human side and bring expectations and

01:45:12.350 --> 01:45:12.360
human side and bring expectations and
 

01:45:12.360 --> 01:45:16.219
human side and bring expectations and
calibrate them right to reality my

01:45:16.219 --> 01:45:16.229
calibrate them right to reality my
 

01:45:16.229 --> 01:45:17.750
calibrate them right to reality my
background my personal background is

01:45:17.750 --> 01:45:17.760
background my personal background is
 

01:45:17.760 --> 01:45:22.040
background my personal background is
actually in transparency so I don't want

01:45:22.040 --> 01:45:22.050
actually in transparency so I don't want
 

01:45:22.050 --> 01:45:23.509
actually in transparency so I don't want
to focus so much on transparency today

01:45:23.509 --> 01:45:23.519
to focus so much on transparency today
 

01:45:23.519 --> 01:45:24.679
to focus so much on transparency today
but I do want to talk about it for a

01:45:24.679 --> 01:45:24.689
but I do want to talk about it for a
 

01:45:24.689 --> 01:45:26.029
but I do want to talk about it for a
couple minutes to just share some

01:45:26.029 --> 01:45:26.039
couple minutes to just share some
 

01:45:26.039 --> 01:45:29.119
couple minutes to just share some
highlights so if we talk about robots

01:45:29.119 --> 01:45:29.129
highlights so if we talk about robots
 

01:45:29.129 --> 01:45:31.759
highlights so if we talk about robots
being transparent we have to actually

01:45:31.759 --> 01:45:31.769
being transparent we have to actually
 

01:45:31.769 --> 01:45:35.029
being transparent we have to actually
define what that means and I'm gonna

01:45:35.029 --> 01:45:35.039
define what that means and I'm gonna
 

01:45:35.039 --> 01:45:36.770
define what that means and I'm gonna
propose one definition which is what

01:45:36.770 --> 01:45:36.780
propose one definition which is what
 

01:45:36.780 --> 01:45:38.149
propose one definition which is what
I've been using I don't think it's the

01:45:38.149 --> 01:45:38.159
I've been using I don't think it's the
 

01:45:38.159 --> 01:45:39.409
I've been using I don't think it's the
only definition but the way I've been

01:45:39.409 --> 01:45:39.419
only definition but the way I've been
 

01:45:39.419 --> 01:45:41.239
only definition but the way I've been
thinking about the problem is that

01:45:41.239 --> 01:45:41.249
thinking about the problem is that
 

01:45:41.249 --> 01:45:44.929
thinking about the problem is that
there's some internal state to the robot

01:45:44.929 --> 01:45:44.939
there's some internal state to the robot
 

01:45:44.939 --> 01:45:47.929
there's some internal state to the robot
like its capability its utility its what

01:45:47.929 --> 01:45:47.939
like its capability its utility its what
 

01:45:47.939 --> 01:45:50.299
like its capability its utility its what
it plans on doing and the human doesn't

01:45:50.299 --> 01:45:50.309
it plans on doing and the human doesn't
 

01:45:50.309 --> 01:45:53.239
it plans on doing and the human doesn't
get to know that but what the human can

01:45:53.239 --> 01:45:53.249
get to know that but what the human can
 

01:45:53.249 --> 01:45:55.189
get to know that but what the human can
have is some sort of estimate or belief

01:45:55.189 --> 01:45:55.199
have is some sort of estimate or belief
 

01:45:55.199 --> 01:45:57.469
have is some sort of estimate or belief
in what that is and that's the robot

01:45:57.469 --> 01:45:57.479
in what that is and that's the robot
 

01:45:57.479 --> 01:46:00.739
in what that is and that's the robot
takes actions in the world and these

01:46:00.739 --> 01:46:00.749
takes actions in the world and these
 

01:46:00.749 --> 01:46:02.270
takes actions in the world and these
actions could be physical actions or

01:46:02.270 --> 01:46:02.280
actions could be physical actions or
 

01:46:02.280 --> 01:46:03.150
actions could be physical actions or
explanation

01:46:03.150 --> 01:46:03.160
explanation
 

01:46:03.160 --> 01:46:06.130
explanation
that ends up changing the person's

01:46:06.130 --> 01:46:06.140
that ends up changing the person's
 

01:46:06.140 --> 01:46:07.930
that ends up changing the person's
estimate the person gets to observe that

01:46:07.930 --> 01:46:07.940
estimate the person gets to observe that
 

01:46:07.940 --> 01:46:09.730
estimate the person gets to observe that
and adjust their mental model over time

01:46:09.730 --> 01:46:09.740
and adjust their mental model over time
 

01:46:09.740 --> 01:46:12.250
and adjust their mental model over time
and so I believe that we have an

01:46:12.250 --> 01:46:12.260
and so I believe that we have an
 

01:46:12.260 --> 01:46:14.380
and so I believe that we have an
opportunity here for the robot to not

01:46:14.380 --> 01:46:14.390
opportunity here for the robot to not
 

01:46:14.390 --> 01:46:17.230
opportunity here for the robot to not
just maximize the reward that's been

01:46:17.230 --> 01:46:17.240
just maximize the reward that's been
 

01:46:17.240 --> 01:46:20.140
just maximize the reward that's been
given to achieve the functional task but

01:46:20.140 --> 01:46:20.150
given to achieve the functional task but
 

01:46:20.150 --> 01:46:23.470
given to achieve the functional task but
also reason about how its actions are

01:46:23.470 --> 01:46:23.480
also reason about how its actions are
 

01:46:23.480 --> 01:46:26.110
also reason about how its actions are
affecting the person's belief and try to

01:46:26.110 --> 01:46:26.120
affecting the person's belief and try to
 

01:46:26.120 --> 01:46:28.810
affecting the person's belief and try to
come up with actions that are that

01:46:28.810 --> 01:46:28.820
come up with actions that are that
 

01:46:28.820 --> 01:46:31.150
come up with actions that are that
steered the person's belief towards the

01:46:31.150 --> 01:46:31.160
steered the person's belief towards the
 

01:46:31.160 --> 01:46:33.730
steered the person's belief towards the
correct mental model towards reality and

01:46:33.730 --> 01:46:33.740
correct mental model towards reality and
 

01:46:33.740 --> 01:46:35.830
correct mental model towards reality and
that to me is what transparency means

01:46:35.830 --> 01:46:35.840
that to me is what transparency means
 

01:46:35.840 --> 01:46:38.230
that to me is what transparency means
and before I move on I just want to give

01:46:38.230 --> 01:46:38.240
and before I move on I just want to give
 

01:46:38.240 --> 01:46:40.000
and before I move on I just want to give
you a few examples of what that might

01:46:40.000 --> 01:46:40.010
you a few examples of what that might
 

01:46:40.010 --> 01:46:43.720
you a few examples of what that might
look like so here's a robot that is

01:46:43.720 --> 01:46:43.730
look like so here's a robot that is
 

01:46:43.730 --> 01:46:45.850
look like so here's a robot that is
planning to grab one of these two

01:46:45.850 --> 01:46:45.860
planning to grab one of these two
 

01:46:45.860 --> 01:46:47.230
planning to grab one of these two
bottles the one on the right and it

01:46:47.230 --> 01:46:47.240
bottles the one on the right and it
 

01:46:47.240 --> 01:46:48.940
bottles the one on the right and it
could do it pretty efficiently but then

01:46:48.940 --> 01:46:48.950
could do it pretty efficiently but then
 

01:46:48.950 --> 01:46:50.500
could do it pretty efficiently but then
it'd be kind of confusing to a person

01:46:50.500 --> 01:46:50.510
it'd be kind of confusing to a person
 

01:46:50.510 --> 01:46:52.390
it'd be kind of confusing to a person
observing which bottled the robot is

01:46:52.390 --> 01:46:52.400
observing which bottled the robot is
 

01:46:52.400 --> 01:46:54.040
observing which bottled the robot is
going for so what this robot is figuring

01:46:54.040 --> 01:46:54.050
going for so what this robot is figuring
 

01:46:54.050 --> 01:46:56.920
going for so what this robot is figuring
out is that by exaggerating its motion

01:46:56.920 --> 01:46:56.930
out is that by exaggerating its motion
 

01:46:56.930 --> 01:46:59.530
out is that by exaggerating its motion
to the right it can become more clear to

01:46:59.530 --> 01:46:59.540
to the right it can become more clear to
 

01:46:59.540 --> 01:47:02.440
to the right it can become more clear to
a person observing this motion what it

01:47:02.440 --> 01:47:02.450
a person observing this motion what it
 

01:47:02.450 --> 01:47:04.030
a person observing this motion what it
is that it's about to do it's not the

01:47:04.030 --> 01:47:04.040
is that it's about to do it's not the
 

01:47:04.040 --> 01:47:05.710
is that it's about to do it's not the
most efficient way but it's a way that

01:47:05.710 --> 01:47:05.720
most efficient way but it's a way that
 

01:47:05.720 --> 01:47:07.960
most efficient way but it's a way that
increases transparency by carefully

01:47:07.960 --> 01:47:07.970
increases transparency by carefully
 

01:47:07.970 --> 01:47:09.910
increases transparency by carefully
selecting actions that take the person's

01:47:09.910 --> 01:47:09.920
selecting actions that take the person's
 

01:47:09.920 --> 01:47:12.220
selecting actions that take the person's
belief towards the object on the right

01:47:12.220 --> 01:47:12.230
belief towards the object on the right
 

01:47:12.230 --> 01:47:13.810
belief towards the object on the right
the correct go that was my thesis at

01:47:13.810 --> 01:47:13.820
the correct go that was my thesis at
 

01:47:13.820 --> 01:47:15.760
the correct go that was my thesis at
Carnegie Mellon here we call this

01:47:15.760 --> 01:47:15.770
Carnegie Mellon here we call this
 

01:47:15.770 --> 01:47:17.500
Carnegie Mellon here we call this
legible motion in the meantime we've

01:47:17.500 --> 01:47:17.510
legible motion in the meantime we've
 

01:47:17.510 --> 01:47:20.110
legible motion in the meantime we've
generalized this to a few things so it

01:47:20.110 --> 01:47:20.120
generalized this to a few things so it
 

01:47:20.120 --> 01:47:21.910
generalized this to a few things so it
utilities for instance here's an

01:47:21.910 --> 01:47:21.920
utilities for instance here's an
 

01:47:21.920 --> 01:47:24.490
utilities for instance here's an
autonomous car sort of placing the

01:47:24.490 --> 01:47:24.500
autonomous car sort of placing the
 

01:47:24.500 --> 01:47:26.680
autonomous car sort of placing the
passenger in a situation and showing in

01:47:26.680 --> 01:47:26.690
passenger in a situation and showing in
 

01:47:26.690 --> 01:47:28.480
passenger in a situation and showing in
the situation I would cut this other guy

01:47:28.480 --> 01:47:28.490
the situation I would cut this other guy
 

01:47:28.490 --> 01:47:30.640
the situation I would cut this other guy
off to convey to the passenger that look

01:47:30.640 --> 01:47:30.650
off to convey to the passenger that look
 

01:47:30.650 --> 01:47:31.960
off to convey to the passenger that look
my driving style is a little bit more on

01:47:31.960 --> 01:47:31.970
my driving style is a little bit more on
 

01:47:31.970 --> 01:47:34.450
my driving style is a little bit more on
the aggressive side I do believe we have

01:47:34.450 --> 01:47:34.460
the aggressive side I do believe we have
 

01:47:34.460 --> 01:47:37.030
the aggressive side I do believe we have
to calibrate expectations about

01:47:37.030 --> 01:47:37.040
to calibrate expectations about
 

01:47:37.040 --> 01:47:39.940
to calibrate expectations about
capability a lot and so because people

01:47:39.940 --> 01:47:39.950
capability a lot and so because people
 

01:47:39.950 --> 01:47:42.400
capability a lot and so because people
tend to over assume so what we've been

01:47:42.400 --> 01:47:42.410
tend to over assume so what we've been
 

01:47:42.410 --> 01:47:44.170
tend to over assume so what we've been
working on is also these robots that

01:47:44.170 --> 01:47:44.180
working on is also these robots that
 

01:47:44.180 --> 01:47:48.010
working on is also these robots that
fail and show you the failures and show

01:47:48.010 --> 01:47:48.020
fail and show you the failures and show
 

01:47:48.020 --> 01:47:50.980
fail and show you the failures and show
them expressively so a robot that says

01:47:50.980 --> 01:47:50.990
them expressively so a robot that says
 

01:47:50.990 --> 01:47:52.660
them expressively so a robot that says
here's what I'm trying to do and it's

01:47:52.660 --> 01:47:52.670
here's what I'm trying to do and it's
 

01:47:52.670 --> 01:47:54.700
here's what I'm trying to do and it's
not working and and here's why it's not

01:47:54.700 --> 01:47:54.710
not working and and here's why it's not
 

01:47:54.710 --> 01:47:56.200
not working and and here's why it's not
working I'm trying to pull on this thing

01:47:56.200 --> 01:47:56.210
working I'm trying to pull on this thing
 

01:47:56.210 --> 01:47:57.490
working I'm trying to pull on this thing
but it's locked I'm trying to push this

01:47:57.490 --> 01:47:57.500
but it's locked I'm trying to push this
 

01:47:57.500 --> 01:47:58.810
but it's locked I'm trying to push this
thing but I can't do it I'm trying to

01:47:58.810 --> 01:47:58.820
thing but I can't do it I'm trying to
 

01:47:58.820 --> 01:47:59.950
thing but I can't do it I'm trying to
lift this Cup

01:47:59.950 --> 01:47:59.960
lift this Cup
 

01:47:59.960 --> 01:48:02.710
lift this Cup
but it's too heavy and then the final

01:48:02.710 --> 01:48:02.720
but it's too heavy and then the final
 

01:48:02.720 --> 01:48:07.600
but it's too heavy and then the final
example is one of a agent that plays

01:48:07.600 --> 01:48:07.610
example is one of a agent that plays
 

01:48:07.610 --> 01:48:09.580
example is one of a agent that plays
pong trained by a deep reinforcement

01:48:09.580 --> 01:48:09.590
pong trained by a deep reinforcement
 

01:48:09.590 --> 01:48:10.720
pong trained by a deep reinforcement
learning which is all the rage these

01:48:10.720 --> 01:48:10.730
learning which is all the rage these
 

01:48:10.730 --> 01:48:13.540
learning which is all the rage these
days what the agent is doing here is

01:48:13.540 --> 01:48:13.550
days what the agent is doing here is
 

01:48:13.550 --> 01:48:15.930
days what the agent is doing here is
it's showing us

01:48:15.930 --> 01:48:15.940
it's showing us
 

01:48:15.940 --> 01:48:18.810
it's showing us
how it would act in states that if

01:48:18.810 --> 01:48:18.820
how it would act in states that if
 

01:48:18.820 --> 01:48:21.630
how it would act in states that if
things are critical meaning states where

01:48:21.630 --> 01:48:21.640
things are critical meaning states where
 

01:48:21.640 --> 01:48:23.430
things are critical meaning states where
it thinks it's really important to take

01:48:23.430 --> 01:48:23.440
it thinks it's really important to take
 

01:48:23.440 --> 01:48:26.610
it thinks it's really important to take
the action that it's about to take so 4

01:48:26.610 --> 01:48:26.620
the action that it's about to take so 4
 

01:48:26.620 --> 01:48:28.860
the action that it's about to take so 4
pong this means when the ball is coming

01:48:28.860 --> 01:48:28.870
pong this means when the ball is coming
 

01:48:28.870 --> 01:48:31.620
pong this means when the ball is coming
close to you and it's at a high speed

01:48:31.620 --> 01:48:31.630
close to you and it's at a high speed
 

01:48:31.630 --> 01:48:33.270
close to you and it's at a high speed
then it's really important to move that

01:48:33.270 --> 01:48:33.280
then it's really important to move that
 

01:48:33.280 --> 01:48:35.640
then it's really important to move that
pellet upward down and so the agent is

01:48:35.640 --> 01:48:35.650
pellet upward down and so the agent is
 

01:48:35.650 --> 01:48:38.130
pellet upward down and so the agent is
showing you this so that you can build

01:48:38.130 --> 01:48:38.140
showing you this so that you can build
 

01:48:38.140 --> 01:48:39.990
showing you this so that you can build
this mental model of what it is that it

01:48:39.990 --> 01:48:40.000
this mental model of what it is that it
 

01:48:40.000 --> 01:48:43.650
this mental model of what it is that it
actually has learned so in a nutshell we

01:48:43.650 --> 01:48:43.660
actually has learned so in a nutshell we
 

01:48:43.660 --> 01:48:47.790
actually has learned so in a nutshell we
can enable transparency by being careful

01:48:47.790 --> 01:48:47.800
can enable transparency by being careful
 

01:48:47.800 --> 01:48:51.390
can enable transparency by being careful
about steering the person's belief in

01:48:51.390 --> 01:48:51.400
about steering the person's belief in
 

01:48:51.400 --> 01:48:54.540
about steering the person's belief in
the right direction but after working on

01:48:54.540 --> 01:48:54.550
the right direction but after working on
 

01:48:54.550 --> 01:48:56.280
the right direction but after working on
transparency for a bit I became a little

01:48:56.280 --> 01:48:56.290
transparency for a bit I became a little
 

01:48:56.290 --> 01:48:58.890
transparency for a bit I became a little
bit disappointed with it because what

01:48:58.890 --> 01:48:58.900
bit disappointed with it because what
 

01:48:58.900 --> 01:49:01.200
bit disappointed with it because what
transparency is about is calibrating the

01:49:01.200 --> 01:49:01.210
transparency is about is calibrating the
 

01:49:01.210 --> 01:49:03.030
transparency is about is calibrating the
person's expectation it's not working on

01:49:03.030 --> 01:49:03.040
person's expectation it's not working on
 

01:49:03.040 --> 01:49:05.880
person's expectation it's not working on
the person and wouldn't it be nice if we

01:49:05.880 --> 01:49:05.890
the person and wouldn't it be nice if we
 

01:49:05.890 --> 01:49:08.370
the person and wouldn't it be nice if we
could do some work on the robot side to

01:49:08.370 --> 01:49:08.380
could do some work on the robot side to
 

01:49:08.380 --> 01:49:11.250
could do some work on the robot side to
get the robot to live up to the person's

01:49:11.250 --> 01:49:11.260
get the robot to live up to the person's
 

01:49:11.260 --> 01:49:13.380
get the robot to live up to the person's
expectation as opposed to just bring the

01:49:13.380 --> 01:49:13.390
expectation as opposed to just bring the
 

01:49:13.390 --> 01:49:16.500
expectation as opposed to just bring the
person's expectations down in a lot of

01:49:16.500 --> 01:49:16.510
person's expectations down in a lot of
 

01:49:16.510 --> 01:49:18.540
person's expectations down in a lot of
ways this is what artificial

01:49:18.540 --> 01:49:18.550
ways this is what artificial
 

01:49:18.550 --> 01:49:20.670
ways this is what artificial
intelligence is all about most of the

01:49:20.670 --> 01:49:20.680
intelligence is all about most of the
 

01:49:20.680 --> 01:49:22.800
intelligence is all about most of the
work in AI is about making robots most

01:49:22.800 --> 01:49:22.810
work in AI is about making robots most
 

01:49:22.810 --> 01:49:24.900
work in AI is about making robots most
trustworthy making robots actually more

01:49:24.900 --> 01:49:24.910
trustworthy making robots actually more
 

01:49:24.910 --> 01:49:27.990
trustworthy making robots actually more
capable of doing the thing typically

01:49:27.990 --> 01:49:28.000
capable of doing the thing typically
 

01:49:28.000 --> 01:49:32.220
capable of doing the thing typically
that means getting robots to solve this

01:49:32.220 --> 01:49:32.230
that means getting robots to solve this
 

01:49:32.230 --> 01:49:34.680
that means getting robots to solve this
optimization problem how do you actually

01:49:34.680 --> 01:49:34.690
optimization problem how do you actually
 

01:49:34.690 --> 01:49:36.660
optimization problem how do you actually
optimize the reward that it's been given

01:49:36.660 --> 01:49:36.670
optimize the reward that it's been given
 

01:49:36.670 --> 01:49:39.420
optimize the reward that it's been given
to you but what I've been finding is

01:49:39.420 --> 01:49:39.430
to you but what I've been finding is
 

01:49:39.430 --> 01:49:42.890
to you but what I've been finding is
that even though this is one modality of

01:49:42.890 --> 01:49:42.900
that even though this is one modality of
 

01:49:42.900 --> 01:49:45.120
that even though this is one modality of
increasing capability there's another

01:49:45.120 --> 01:49:45.130
increasing capability there's another
 

01:49:45.130 --> 01:49:47.790
increasing capability there's another
thing that can go wrong which is the

01:49:47.790 --> 01:49:47.800
thing that can go wrong which is the
 

01:49:47.800 --> 01:49:53.670
thing that can go wrong which is the
reward function itself so sometimes the

01:49:53.670 --> 01:49:53.680
reward function itself so sometimes the
 

01:49:53.680 --> 01:49:55.439
reward function itself so sometimes the
reward function does not actually

01:49:55.439 --> 01:49:55.449
reward function does not actually
 

01:49:55.449 --> 01:49:58.830
reward function does not actually
correspond to what we actually want the

01:49:58.830 --> 01:49:58.840
correspond to what we actually want the
 

01:49:58.840 --> 01:50:01.800
correspond to what we actually want the
robot to be optimizing for and it makes

01:50:01.800 --> 01:50:01.810
robot to be optimizing for and it makes
 

01:50:01.810 --> 01:50:03.540
robot to be optimizing for and it makes
sense because the people who are

01:50:03.540 --> 01:50:03.550
sense because the people who are
 

01:50:03.550 --> 01:50:05.280
sense because the people who are
building these robots were human too

01:50:05.280 --> 01:50:05.290
building these robots were human too
 

01:50:05.290 --> 01:50:07.950
building these robots were human too
right and we're fallible and we don't

01:50:07.950 --> 01:50:07.960
right and we're fallible and we don't
 

01:50:07.960 --> 01:50:10.170
right and we're fallible and we don't
always encode the right objectives or

01:50:10.170 --> 01:50:10.180
always encode the right objectives or
 

01:50:10.180 --> 01:50:12.270
always encode the right objectives or
incentives in the robot here's a cute

01:50:12.270 --> 01:50:12.280
incentives in the robot here's a cute
 

01:50:12.280 --> 01:50:14.760
incentives in the robot here's a cute
example of this going wrong this is

01:50:14.760 --> 01:50:14.770
example of this going wrong this is
 

01:50:14.770 --> 01:50:17.520
example of this going wrong this is
video from open AI and this is a boat

01:50:17.520 --> 01:50:17.530
video from open AI and this is a boat
 

01:50:17.530 --> 01:50:20.490
video from open AI and this is a boat
racing agent you can't tell that it's

01:50:20.490 --> 01:50:20.500
racing agent you can't tell that it's
 

01:50:20.500 --> 01:50:22.950
racing agent you can't tell that it's
trying to race by looking at it the

01:50:22.950 --> 01:50:22.960
trying to race by looking at it the
 

01:50:22.960 --> 01:50:25.500
trying to race by looking at it the
reason is that the reward function was

01:50:25.500 --> 01:50:25.510
reason is that the reward function was
 

01:50:25.510 --> 01:50:28.700
reason is that the reward function was
score points in the game and so

01:50:28.700 --> 01:50:28.710
score points in the game and so
 

01:50:28.710 --> 01:50:30.920
score points in the game and so
on the top left there you see all the

01:50:30.920 --> 01:50:30.930
on the top left there you see all the
 

01:50:30.930 --> 01:50:32.600
on the top left there you see all the
other agents actually completing the

01:50:32.600 --> 01:50:32.610
other agents actually completing the
 

01:50:32.610 --> 01:50:35.810
other agents actually completing the
race what our boat does is it figures

01:50:35.810 --> 01:50:35.820
race what our boat does is it figures
 

01:50:35.820 --> 01:50:38.660
race what our boat does is it figures
out this loop that it can do and time it

01:50:38.660 --> 01:50:38.670
out this loop that it can do and time it
 

01:50:38.670 --> 01:50:40.850
out this loop that it can do and time it
just right so that it collects all these

01:50:40.850 --> 01:50:40.860
just right so that it collects all these
 

01:50:40.860 --> 01:50:44.030
just right so that it collects all these
turbo boosters at the right time and get

01:50:44.030 --> 01:50:44.040
turbo boosters at the right time and get
 

01:50:44.040 --> 01:50:46.730
turbo boosters at the right time and get
a gazillion points okay so you look at

01:50:46.730 --> 01:50:46.740
a gazillion points okay so you look at
 

01:50:46.740 --> 01:50:48.920
a gazillion points okay so you look at
this as designer they're like oh my god

01:50:48.920 --> 01:50:48.930
this as designer they're like oh my god
 

01:50:48.930 --> 01:50:50.390
this as designer they're like oh my god
of course this is not what I wanted of

01:50:50.390 --> 01:50:50.400
of course this is not what I wanted of
 

01:50:50.400 --> 01:50:51.530
of course this is not what I wanted of
course I wanted you to actually

01:50:51.530 --> 01:50:51.540
course I wanted you to actually
 

01:50:51.540 --> 01:50:53.240
course I wanted you to actually
participate in the race and try to win

01:50:53.240 --> 01:50:53.250
participate in the race and try to win
 

01:50:53.250 --> 01:50:56.030
participate in the race and try to win
but that's not what was specified this

01:50:56.030 --> 01:50:56.040
but that's not what was specified this
 

01:50:56.040 --> 01:50:58.910
but that's not what was specified this
is not a new problem Steve Russell and

01:50:58.910 --> 01:50:58.920
is not a new problem Steve Russell and
 

01:50:58.920 --> 01:51:00.800
is not a new problem Steve Russell and
Peter Norvig if this example and their

01:51:00.800 --> 01:51:00.810
Peter Norvig if this example and their
 

01:51:00.810 --> 01:51:04.090
Peter Norvig if this example and their
AI book of a vacuum cleaning robot and

01:51:04.090 --> 01:51:04.100
AI book of a vacuum cleaning robot and
 

01:51:04.100 --> 01:51:07.730
AI book of a vacuum cleaning robot and
the reward function could be the amount

01:51:07.730 --> 01:51:07.740
the reward function could be the amount
 

01:51:07.740 --> 01:51:09.950
the reward function could be the amount
of dust you managed to suck in and that

01:51:09.950 --> 01:51:09.960
of dust you managed to suck in and that
 

01:51:09.960 --> 01:51:11.000
of dust you managed to suck in and that
kind of makes sense because the more

01:51:11.000 --> 01:51:11.010
kind of makes sense because the more
 

01:51:11.010 --> 01:51:12.980
kind of makes sense because the more
dust that sucks in the cleaner the floor

01:51:12.980 --> 01:51:12.990
dust that sucks in the cleaner the floor
 

01:51:12.990 --> 01:51:14.900
dust that sucks in the cleaner the floor
is but then depending on the hardware

01:51:14.900 --> 01:51:14.910
is but then depending on the hardware
 

01:51:14.910 --> 01:51:17.810
is but then depending on the hardware
the optimal policy can be suck in a

01:51:17.810 --> 01:51:17.820
the optimal policy can be suck in a
 

01:51:17.820 --> 01:51:19.940
the optimal policy can be suck in a
little bit of dust and then dump it all

01:51:19.940 --> 01:51:19.950
little bit of dust and then dump it all
 

01:51:19.950 --> 01:51:22.340
little bit of dust and then dump it all
out then suck in a little bit more dump

01:51:22.340 --> 01:51:22.350
out then suck in a little bit more dump
 

01:51:22.350 --> 01:51:26.360
out then suck in a little bit more dump
it all back out right and recycle that I

01:51:26.360 --> 01:51:26.370
it all back out right and recycle that I
 

01:51:26.370 --> 01:51:27.830
it all back out right and recycle that I
don't think this is necessarily that

01:51:27.830 --> 01:51:27.840
don't think this is necessarily that
 

01:51:27.840 --> 01:51:29.390
don't think this is necessarily that
specific to AI think this is kind of a

01:51:29.390 --> 01:51:29.400
specific to AI think this is kind of a
 

01:51:29.400 --> 01:51:31.760
specific to AI think this is kind of a
general problem with with technology as

01:51:31.760 --> 01:51:31.770
general problem with with technology as
 

01:51:31.770 --> 01:51:34.520
general problem with with technology as
a whole and I think it comes from some

01:51:34.520 --> 01:51:34.530
a whole and I think it comes from some
 

01:51:34.530 --> 01:51:36.380
a whole and I think it comes from some
of them we all know about which is that

01:51:36.380 --> 01:51:36.390
of them we all know about which is that
 

01:51:36.390 --> 01:51:38.600
of them we all know about which is that
we were not very good at saying what we

01:51:38.600 --> 01:51:38.610
we were not very good at saying what we
 

01:51:38.610 --> 01:51:40.310
we were not very good at saying what we
want right we have all these myths and

01:51:40.310 --> 01:51:40.320
want right we have all these myths and
 

01:51:40.320 --> 01:51:41.930
want right we have all these myths and
legends about be careful what you wish

01:51:41.930 --> 01:51:41.940
legends about be careful what you wish
 

01:51:41.940 --> 01:51:43.880
legends about be careful what you wish
for and the reason it should be careful

01:51:43.880 --> 01:51:43.890
for and the reason it should be careful
 

01:51:43.890 --> 01:51:45.560
for and the reason it should be careful
is because you might just get it and it

01:51:45.560 --> 01:51:45.570
is because you might just get it and it
 

01:51:45.570 --> 01:51:47.870
is because you might just get it and it
might not be happy with the consequences

01:51:47.870 --> 01:51:47.880
might not be happy with the consequences
 

01:51:47.880 --> 01:51:50.060
might not be happy with the consequences
like King Midas wishing that everything

01:51:50.060 --> 01:51:50.070
like King Midas wishing that everything
 

01:51:50.070 --> 01:51:52.820
like King Midas wishing that everything
it touched turned to gold and I do want

01:51:52.820 --> 01:51:52.830
it touched turned to gold and I do want
 

01:51:52.830 --> 01:51:54.500
it touched turned to gold and I do want
to emphasize that this is not a story

01:51:54.500 --> 01:51:54.510
to emphasize that this is not a story
 

01:51:54.510 --> 01:51:57.140
to emphasize that this is not a story
about that is only applicable to Ages

01:51:57.140 --> 01:51:57.150
about that is only applicable to Ages
 

01:51:57.150 --> 01:51:59.270
about that is only applicable to Ages
that actually are capable at optimizing

01:51:59.270 --> 01:51:59.280
that actually are capable at optimizing
 

01:51:59.280 --> 01:52:01.550
that actually are capable at optimizing
their objectives I struggle with this

01:52:01.550 --> 01:52:01.560
their objectives I struggle with this
 

01:52:01.560 --> 01:52:03.290
their objectives I struggle with this
every day I do a lot of motion planning

01:52:03.290 --> 01:52:03.300
every day I do a lot of motion planning
 

01:52:03.300 --> 01:52:05.360
every day I do a lot of motion planning
work and motion planning you have to

01:52:05.360 --> 01:52:05.370
work and motion planning you have to
 

01:52:05.370 --> 01:52:06.950
work and motion planning you have to
write down a cost function that trades

01:52:06.950 --> 01:52:06.960
write down a cost function that trades
 

01:52:06.960 --> 01:52:08.390
write down a cost function that trades
off between different things that are

01:52:08.390 --> 01:52:08.400
off between different things that are
 

01:52:08.400 --> 01:52:10.580
off between different things that are
important to the robot this case

01:52:10.580 --> 01:52:10.590
important to the robot this case
 

01:52:10.590 --> 01:52:12.530
important to the robot this case
distance to the person and distance to

01:52:12.530 --> 01:52:12.540
distance to the person and distance to
 

01:52:12.540 --> 01:52:14.690
distance to the person and distance to
fragile objects and so on what

01:52:14.690 --> 01:52:14.700
fragile objects and so on what
 

01:52:14.700 --> 01:52:17.150
fragile objects and so on what
inevitably happens is you tune the thing

01:52:17.150 --> 01:52:17.160
inevitably happens is you tune the thing
 

01:52:17.160 --> 01:52:20.060
inevitably happens is you tune the thing
it works over 10 20 different problem

01:52:20.060 --> 01:52:20.070
it works over 10 20 different problem
 

01:52:20.070 --> 01:52:22.460
it works over 10 20 different problem
settings different environments and then

01:52:22.460 --> 01:52:22.470
settings different environments and then
 

01:52:22.470 --> 01:52:24.650
settings different environments and then
you encounter a new environment at some

01:52:24.650 --> 01:52:24.660
you encounter a new environment at some
 

01:52:24.660 --> 01:52:26.210
you encounter a new environment at some
point that's different enough and the

01:52:26.210 --> 01:52:26.220
point that's different enough and the
 

01:52:26.220 --> 01:52:28.100
point that's different enough and the
optimal behavior does not actually

01:52:28.100 --> 01:52:28.110
optimal behavior does not actually
 

01:52:28.110 --> 01:52:30.640
optimal behavior does not actually
correspond to what you actually wanted

01:52:30.640 --> 01:52:30.650
correspond to what you actually wanted
 

01:52:30.650 --> 01:52:34.130
correspond to what you actually wanted
so overall we're not great at specifying

01:52:34.130 --> 01:52:34.140
so overall we're not great at specifying
 

01:52:34.140 --> 01:52:36.980
so overall we're not great at specifying
these reward functions and I don't want

01:52:36.980 --> 01:52:36.990
these reward functions and I don't want
 

01:52:36.990 --> 01:52:38.870
these reward functions and I don't want
to make because this is an AI in ethics

01:52:38.870 --> 01:52:38.880
to make because this is an AI in ethics
 

01:52:38.880 --> 01:52:40.130
to make because this is an AI in ethics
conference I do want to make a little

01:52:40.130 --> 01:52:40.140
conference I do want to make a little
 

01:52:40.140 --> 01:52:42.290
conference I do want to make a little
bit of a theoretical point on ethics

01:52:42.290 --> 01:52:42.300
bit of a theoretical point on ethics
 

01:52:42.300 --> 01:52:42.510
bit of a theoretical point on ethics
which

01:52:42.510 --> 01:52:42.520
which
 

01:52:42.520 --> 01:52:44.100
which
is that I think that makes it difficult

01:52:44.100 --> 01:52:44.110
is that I think that makes it difficult
 

01:52:44.110 --> 01:52:47.550
is that I think that makes it difficult
to encode the ethical principles that we

01:52:47.550 --> 01:52:47.560
to encode the ethical principles that we
 

01:52:47.560 --> 01:52:50.360
to encode the ethical principles that we
as humans find so easy and common sense

01:52:50.360 --> 01:52:50.370
as humans find so easy and common sense
 

01:52:50.370 --> 01:52:53.760
as humans find so easy and common sense
into these machines and all us minqi as

01:52:53.760 --> 01:52:53.770
into these machines and all us minqi as
 

01:52:53.770 --> 01:52:56.550
into these machines and all us minqi as
as my helper to make this point so

01:52:56.550 --> 01:52:56.560
as my helper to make this point so
 

01:52:56.560 --> 01:52:58.500
as my helper to make this point so
Mickey Mouse this is a this is from

01:52:58.500 --> 01:52:58.510
Mickey Mouse this is a this is from
 

01:52:58.510 --> 01:53:01.080
Mickey Mouse this is a this is from
Fantasia Mickey Mouse was charged with

01:53:01.080 --> 01:53:01.090
Fantasia Mickey Mouse was charged with
 

01:53:01.090 --> 01:53:03.540
Fantasia Mickey Mouse was charged with
getting water from outside the house

01:53:03.540 --> 01:53:03.550
getting water from outside the house
 

01:53:03.550 --> 01:53:07.440
getting water from outside the house
into the home and Mickey gets tired of

01:53:07.440 --> 01:53:07.450
into the home and Mickey gets tired of
 

01:53:07.450 --> 01:53:11.520
into the home and Mickey gets tired of
this and makes a robot right uses magic

01:53:11.520 --> 01:53:11.530
this and makes a robot right uses magic
 

01:53:11.530 --> 01:53:13.680
this and makes a robot right uses magic
to bring a broom to life and shows it

01:53:13.680 --> 01:53:13.690
to bring a broom to life and shows it
 

01:53:13.690 --> 01:53:15.300
to bring a broom to life and shows it
how to do the test and Mickey goes to

01:53:15.300 --> 01:53:15.310
how to do the test and Mickey goes to
 

01:53:15.310 --> 01:53:18.390
how to do the test and Mickey goes to
bed and then Mickey wakes up and he's in

01:53:18.390 --> 01:53:18.400
bed and then Mickey wakes up and he's in
 

01:53:18.400 --> 01:53:20.690
bed and then Mickey wakes up and he's in
a puddle of water and he realizes that

01:53:20.690 --> 01:53:20.700
a puddle of water and he realizes that
 

01:53:20.700 --> 01:53:22.950
a puddle of water and he realizes that
his robot assistant was a bit

01:53:22.950 --> 01:53:22.960
his robot assistant was a bit
 

01:53:22.960 --> 01:53:25.170
his robot assistant was a bit
overzealous with optimizing the

01:53:25.170 --> 01:53:25.180
overzealous with optimizing the
 

01:53:25.180 --> 01:53:28.070
overzealous with optimizing the
objective function that he specified

01:53:28.070 --> 01:53:28.080
objective function that he specified
 

01:53:28.080 --> 01:53:30.540
objective function that he specified
what's interesting here is that Mickey

01:53:30.540 --> 01:53:30.550
what's interesting here is that Mickey
 

01:53:30.550 --> 01:53:32.730
what's interesting here is that Mickey
then goes and you'll see in a second he

01:53:32.730 --> 01:53:32.740
then goes and you'll see in a second he
 

01:53:32.740 --> 01:53:37.910
then goes and you'll see in a second he
goes and tries to stop the broom but

01:53:37.910 --> 01:53:37.920
goes and tries to stop the broom but
 

01:53:37.920 --> 01:53:41.070
goes and tries to stop the broom but
that doesn't work because the broom was

01:53:41.070 --> 01:53:41.080
that doesn't work because the broom was
 

01:53:41.080 --> 01:53:42.960
that doesn't work because the broom was
given an objective function and sort of

01:53:42.960 --> 01:53:42.970
given an objective function and sort of
 

01:53:42.970 --> 01:53:44.910
given an objective function and sort of
what make you suggesting is not optimal

01:53:44.910 --> 01:53:44.920
what make you suggesting is not optimal
 

01:53:44.920 --> 01:53:48.330
what make you suggesting is not optimal
and so kind of a best be very very basic

01:53:48.330 --> 01:53:48.340
and so kind of a best be very very basic
 

01:53:48.340 --> 01:53:49.920
and so kind of a best be very very basic
I'm not sure I would even call it

01:53:49.920 --> 01:53:49.930
I'm not sure I would even call it
 

01:53:49.930 --> 01:53:52.170
I'm not sure I would even call it
ethical basic principle you might want

01:53:52.170 --> 01:53:52.180
ethical basic principle you might want
 

01:53:52.180 --> 01:53:54.270
ethical basic principle you might want
to encode right in this reward function

01:53:54.270 --> 01:53:54.280
to encode right in this reward function
 

01:53:54.280 --> 01:53:55.650
to encode right in this reward function
is look you should do what people say

01:53:55.650 --> 01:53:55.660
is look you should do what people say
 

01:53:55.660 --> 01:53:59.010
is look you should do what people say
okay so I just want to point out a

01:53:59.010 --> 01:53:59.020
okay so I just want to point out a
 

01:53:59.020 --> 01:54:00.780
okay so I just want to point out a
theoretical level that that's not

01:54:00.780 --> 01:54:00.790
theoretical level that that's not
 

01:54:00.790 --> 01:54:03.000
theoretical level that that's not
actually that trivial so the way you

01:54:03.000 --> 01:54:03.010
actually that trivial so the way you
 

01:54:03.010 --> 01:54:04.080
actually that trivial so the way you
might structure this you might say

01:54:04.080 --> 01:54:04.090
might structure this you might say
 

01:54:04.090 --> 01:54:06.330
might structure this you might say
here's the normal reward function you

01:54:06.330 --> 01:54:06.340
here's the normal reward function you
 

01:54:06.340 --> 01:54:07.980
here's the normal reward function you
should optimize for this except if the

01:54:07.980 --> 01:54:07.990
should optimize for this except if the
 

01:54:07.990 --> 01:54:10.920
should optimize for this except if the
person says do something else right more

01:54:10.920 --> 01:54:10.930
person says do something else right more
 

01:54:10.930 --> 01:54:12.330
person says do something else right more
reward than doing this something else

01:54:12.330 --> 01:54:12.340
reward than doing this something else
 

01:54:12.340 --> 01:54:16.370
reward than doing this something else
but if you set this up to be high enough

01:54:16.370 --> 01:54:16.380
but if you set this up to be high enough
 

01:54:16.380 --> 01:54:18.780
but if you set this up to be high enough
not that I'm worried that robots would

01:54:18.780 --> 01:54:18.790
not that I'm worried that robots would
 

01:54:18.790 --> 01:54:20.460
not that I'm worried that robots would
actually figure out how to do this at

01:54:20.460 --> 01:54:20.470
actually figure out how to do this at
 

01:54:20.470 --> 01:54:22.380
actually figure out how to do this at
all but just theoretically I want to

01:54:22.380 --> 01:54:22.390
all but just theoretically I want to
 

01:54:22.390 --> 01:54:23.880
all but just theoretically I want to
point out that which of what we just did

01:54:23.880 --> 01:54:23.890
point out that which of what we just did
 

01:54:23.890 --> 01:54:26.730
point out that which of what we just did
is we provided an incentive to the robot

01:54:26.730 --> 01:54:26.740
is we provided an incentive to the robot
 

01:54:26.740 --> 01:54:29.700
is we provided an incentive to the robot
to try to get itself in situations where

01:54:29.700 --> 01:54:29.710
to try to get itself in situations where
 

01:54:29.710 --> 01:54:31.530
to try to get itself in situations where
then people would react and give it

01:54:31.530 --> 01:54:31.540
then people would react and give it
 

01:54:31.540 --> 01:54:33.600
then people would react and give it
Corrections so that it can then accept

01:54:33.600 --> 01:54:33.610
Corrections so that it can then accept
 

01:54:33.610 --> 01:54:36.150
Corrections so that it can then accept
them and cash in on all of that reward

01:54:36.150 --> 01:54:36.160
them and cash in on all of that reward
 

01:54:36.160 --> 01:54:39.240
them and cash in on all of that reward
right and similarly if you make it too

01:54:39.240 --> 01:54:39.250
right and similarly if you make it too
 

01:54:39.250 --> 01:54:41.400
right and similarly if you make it too
low other things happen so it's not

01:54:41.400 --> 01:54:41.410
low other things happen so it's not
 

01:54:41.410 --> 01:54:43.200
low other things happen so it's not
trivial to tune these things right even

01:54:43.200 --> 01:54:43.210
trivial to tune these things right even
 

01:54:43.210 --> 01:54:46.740
trivial to tune these things right even
for something as basic as do what people

01:54:46.740 --> 01:54:46.750
for something as basic as do what people
 

01:54:46.750 --> 01:54:49.890
for something as basic as do what people
say now I'm not worried about this would

01:54:49.890 --> 01:54:49.900
say now I'm not worried about this would
 

01:54:49.900 --> 01:54:51.210
say now I'm not worried about this would
robots today you know pass that they

01:54:51.210 --> 01:54:51.220
robots today you know pass that they
 

01:54:51.220 --> 01:54:53.160
robots today you know pass that they
have very narrow action spaces so they

01:54:53.160 --> 01:54:53.170
have very narrow action spaces so they
 

01:54:53.170 --> 01:54:54.660
have very narrow action spaces so they
would never figure out even if that's

01:54:54.660 --> 01:54:54.670
would never figure out even if that's
 

01:54:54.670 --> 01:54:56.260
would never figure out even if that's
the reward function how

01:54:56.260 --> 01:54:56.270
the reward function how
 

01:54:56.270 --> 01:54:58.120
the reward function how
you actually do that here's the robot it

01:54:58.120 --> 01:54:58.130
you actually do that here's the robot it
 

01:54:58.130 --> 01:55:00.250
you actually do that here's the robot it
moves from a start to a goal location

01:55:00.250 --> 01:55:00.260
moves from a start to a goal location
 

01:55:00.260 --> 01:55:02.110
moves from a start to a goal location
it's trying to be efficient it's trying

01:55:02.110 --> 01:55:02.120
it's trying to be efficient it's trying
 

01:55:02.120 --> 01:55:04.600
it's trying to be efficient it's trying
to optimize for staying away from things

01:55:04.600 --> 01:55:04.610
to optimize for staying away from things
 

01:55:04.610 --> 01:55:07.510
to optimize for staying away from things
and I it's very easy to get it to do

01:55:07.510 --> 01:55:07.520
and I it's very easy to get it to do
 

01:55:07.520 --> 01:55:09.910
and I it's very easy to get it to do
what I want so if I'm not happy with how

01:55:09.910 --> 01:55:09.920
what I want so if I'm not happy with how
 

01:55:09.920 --> 01:55:12.130
what I want so if I'm not happy with how
it's doing the task if for instance I

01:55:12.130 --> 01:55:12.140
it's doing the task if for instance I
 

01:55:12.140 --> 01:55:13.810
it's doing the task if for instance I
think that it's keeping the bottle the

01:55:13.810 --> 01:55:13.820
think that it's keeping the bottle the
 

01:55:13.820 --> 01:55:17.380
think that it's keeping the bottle the
the mug too high up what I can do is I

01:55:17.380 --> 01:55:17.390
the mug too high up what I can do is I
 

01:55:17.390 --> 01:55:20.800
the mug too high up what I can do is I
can just go there and push on it and it

01:55:20.800 --> 01:55:20.810
can just go there and push on it and it
 

01:55:20.810 --> 01:55:22.030
can just go there and push on it and it
will do the thing and I can write a

01:55:22.030 --> 01:55:22.040
will do the thing and I can write a
 

01:55:22.040 --> 01:55:23.680
will do the thing and I can write a
controller pretty easily maybe an

01:55:23.680 --> 01:55:23.690
controller pretty easily maybe an
 

01:55:23.690 --> 01:55:25.810
controller pretty easily maybe an
impedance controller that makes the

01:55:25.810 --> 01:55:25.820
impedance controller that makes the
 

01:55:25.820 --> 01:55:27.960
impedance controller that makes the
robot actually compliant to human touch

01:55:27.960 --> 01:55:27.970
robot actually compliant to human touch
 

01:55:27.970 --> 01:55:30.520
robot actually compliant to human touch
the interesting thing for the robot

01:55:30.520 --> 01:55:30.530
the interesting thing for the robot
 

01:55:30.530 --> 01:55:32.050
the interesting thing for the robot
though I know it's hard for a real robot

01:55:32.050 --> 01:55:32.060
though I know it's hard for a real robot
 

01:55:32.060 --> 01:55:34.570
though I know it's hard for a real robot
today is not so much accepting this kind

01:55:34.570 --> 01:55:34.580
today is not so much accepting this kind
 

01:55:34.580 --> 01:55:37.030
today is not so much accepting this kind
of oversight but figuring out what to do

01:55:37.030 --> 01:55:37.040
of oversight but figuring out what to do
 

01:55:37.040 --> 01:55:39.520
of oversight but figuring out what to do
with it afterwards because the moment I

01:55:39.520 --> 01:55:39.530
with it afterwards because the moment I
 

01:55:39.530 --> 01:55:42.340
with it afterwards because the moment I
let go right the robot goes back to

01:55:42.340 --> 01:55:42.350
let go right the robot goes back to
 

01:55:42.350 --> 01:55:45.280
let go right the robot goes back to
optimizing its objective it's its reward

01:55:45.280 --> 01:55:45.290
optimizing its objective it's its reward
 

01:55:45.290 --> 01:55:47.290
optimizing its objective it's its reward
function and so the moment I let go

01:55:47.290 --> 01:55:47.300
function and so the moment I let go
 

01:55:47.300 --> 01:55:49.480
function and so the moment I let go
right the robot goes back to the old way

01:55:49.480 --> 01:55:49.490
right the robot goes back to the old way
 

01:55:49.490 --> 01:55:51.850
right the robot goes back to the old way
of doing the task and I keep pushing on

01:55:51.850 --> 01:55:51.860
of doing the task and I keep pushing on
 

01:55:51.860 --> 01:55:52.150
of doing the task and I keep pushing on
it

01:55:52.150 --> 01:55:52.160
it
 

01:55:52.160 --> 01:55:53.350
it
I think e's going back and I keep

01:55:53.350 --> 01:55:53.360
I think e's going back and I keep
 

01:55:53.360 --> 01:55:54.730
I think e's going back and I keep
pushing at it and if it keeps going back

01:55:54.730 --> 01:55:54.740
pushing at it and if it keeps going back
 

01:55:54.740 --> 01:55:57.070
pushing at it and if it keeps going back
to what it thinks is the optimal way of

01:55:57.070 --> 01:55:57.080
to what it thinks is the optimal way of
 

01:55:57.080 --> 01:55:59.010
to what it thinks is the optimal way of
doing it and can be pretty frustrating

01:55:59.010 --> 01:55:59.020
doing it and can be pretty frustrating
 

01:55:59.020 --> 01:56:01.780
doing it and can be pretty frustrating
so with real robots I think the more

01:56:01.780 --> 01:56:01.790
so with real robots I think the more
 

01:56:01.790 --> 01:56:04.570
so with real robots I think the more
into sort of near-term problem is that

01:56:04.570 --> 01:56:04.580
into sort of near-term problem is that
 

01:56:04.580 --> 01:56:06.460
into sort of near-term problem is that
you shouldn't just be compliant you

01:56:06.460 --> 01:56:06.470
you shouldn't just be compliant you
 

01:56:06.470 --> 01:56:09.640
you shouldn't just be compliant you
should actually try to continually learn

01:56:09.640 --> 01:56:09.650
should actually try to continually learn
 

01:56:09.650 --> 01:56:11.470
should actually try to continually learn
from this oversight that people give you

01:56:11.470 --> 01:56:11.480
from this oversight that people give you
 

01:56:11.480 --> 01:56:13.840
from this oversight that people give you
and try to not make the same mistakes

01:56:13.840 --> 01:56:13.850
and try to not make the same mistakes
 

01:56:13.850 --> 01:56:17.800
and try to not make the same mistakes
again and again and again and so with

01:56:17.800 --> 01:56:17.810
again and again and again and so with
 

01:56:17.810 --> 01:56:19.810
again and again and again and so with
what all these three examples I think

01:56:19.810 --> 01:56:19.820
what all these three examples I think
 

01:56:19.820 --> 01:56:21.700
what all these three examples I think
teach us is that the classical AI

01:56:21.700 --> 01:56:21.710
teach us is that the classical AI
 

01:56:21.710 --> 01:56:23.920
teach us is that the classical AI
picture here is missing something

01:56:23.920 --> 01:56:23.930
picture here is missing something
 

01:56:23.930 --> 01:56:25.900
picture here is missing something
there's no reward function that's

01:56:25.900 --> 01:56:25.910
there's no reward function that's
 

01:56:25.910 --> 01:56:28.060
there's no reward function that's
exogenously specify it doesn't come from

01:56:28.060 --> 01:56:28.070
exogenously specify it doesn't come from
 

01:56:28.070 --> 01:56:30.700
exogenously specify it doesn't come from
the sky and still what we have is we

01:56:30.700 --> 01:56:30.710
the sky and still what we have is we
 

01:56:30.710 --> 01:56:33.190
the sky and still what we have is we
have people that want things internally

01:56:33.190 --> 01:56:33.200
have people that want things internally
 

01:56:33.200 --> 01:56:36.610
have people that want things internally
and that's what the robot should be

01:56:36.610 --> 01:56:36.620
and that's what the robot should be
 

01:56:36.620 --> 01:56:39.670
and that's what the robot should be
trying to optimize for if it's a

01:56:39.670 --> 01:56:39.680
trying to optimize for if it's a
 

01:56:39.680 --> 01:56:43.720
trying to optimize for if it's a
designer right then the designer might

01:56:43.720 --> 01:56:43.730
designer right then the designer might
 

01:56:43.730 --> 01:56:46.750
designer right then the designer might
actually specify a reward function but

01:56:46.750 --> 01:56:46.760
actually specify a reward function but
 

01:56:46.760 --> 01:56:48.430
actually specify a reward function but
chances are because we're human and

01:56:48.430 --> 01:56:48.440
chances are because we're human and
 

01:56:48.440 --> 01:56:50.500
chances are because we're human and
because we're fallible but that's not

01:56:50.500 --> 01:56:50.510
because we're fallible but that's not
 

01:56:50.510 --> 01:56:51.960
because we're fallible but that's not
necessarily going to match up perfectly

01:56:51.960 --> 01:56:51.970
necessarily going to match up perfectly
 

01:56:51.970 --> 01:56:54.070
necessarily going to match up perfectly
it's not gonna be totally drugged but

01:56:54.070 --> 01:56:54.080
it's not gonna be totally drugged but
 

01:56:54.080 --> 01:56:56.050
it's not gonna be totally drugged but
it's not gonna match up perfectly to

01:56:56.050 --> 01:56:56.060
it's not gonna match up perfectly to
 

01:56:56.060 --> 01:56:58.300
it's not gonna match up perfectly to
what people actually what the designer

01:56:58.300 --> 01:56:58.310
what people actually what the designer
 

01:56:58.310 --> 01:57:00.940
what people actually what the designer
actually wants internally and what we do

01:57:00.940 --> 01:57:00.950
actually wants internally and what we do
 

01:57:00.950 --> 01:57:02.920
actually wants internally and what we do
right now is we just take that for

01:57:02.920 --> 01:57:02.930
right now is we just take that for
 

01:57:02.930 --> 01:57:04.690
right now is we just take that for
granted we just plug it in and say this

01:57:04.690 --> 01:57:04.700
granted we just plug it in and say this
 

01:57:04.700 --> 01:57:06.950
granted we just plug it in and say this
is what we're optimizing for as if

01:57:06.950 --> 01:57:06.960
is what we're optimizing for as if
 

01:57:06.960 --> 01:57:08.990
is what we're optimizing for as if
humans are perfect but they're not and I

01:57:08.990 --> 01:57:09.000
humans are perfect but they're not and I
 

01:57:09.000 --> 01:57:10.280
humans are perfect but they're not and I
think the picture that we should really

01:57:10.280 --> 01:57:10.290
think the picture that we should really
 

01:57:10.290 --> 01:57:12.770
think the picture that we should really
be reasoning about is this one where you

01:57:12.770 --> 01:57:12.780
be reasoning about is this one where you
 

01:57:12.780 --> 01:57:14.480
be reasoning about is this one where you
have a robot the trust actually work

01:57:14.480 --> 01:57:14.490
have a robot the trust actually work
 

01:57:14.490 --> 01:57:15.800
have a robot the trust actually work
with the person to figure out what it is

01:57:15.800 --> 01:57:15.810
with the person to figure out what it is
 

01:57:15.810 --> 01:57:18.620
with the person to figure out what it is
that they really want and it's hard

01:57:18.620 --> 01:57:18.630
that they really want and it's hard
 

01:57:18.630 --> 01:57:20.060
that they really want and it's hard
because you know we can't actually

01:57:20.060 --> 01:57:20.070
because you know we can't actually
 

01:57:20.070 --> 01:57:22.550
because you know we can't actually
decode what people think internally it's

01:57:22.550 --> 01:57:22.560
decode what people think internally it's
 

01:57:22.560 --> 01:57:24.800
decode what people think internally it's
a really tough tough thing to do but I

01:57:24.800 --> 01:57:24.810
a really tough tough thing to do but I
 

01:57:24.810 --> 01:57:26.180
a really tough tough thing to do but I
think we can make some progress towards

01:57:26.180 --> 01:57:26.190
think we can make some progress towards
 

01:57:26.190 --> 01:57:28.190
think we can make some progress towards
that so let me give you an example of

01:57:28.190 --> 01:57:28.200
that so let me give you an example of
 

01:57:28.200 --> 01:57:30.610
that so let me give you an example of
one thing that we've been thinking about

01:57:30.610 --> 01:57:30.620
one thing that we've been thinking about
 

01:57:30.620 --> 01:57:33.080
one thing that we've been thinking about
so we're back to the boat racing game do

01:57:33.080 --> 01:57:33.090
so we're back to the boat racing game do
 

01:57:33.090 --> 01:57:34.970
so we're back to the boat racing game do
you remember the game with the with the

01:57:34.970 --> 01:57:34.980
you remember the game with the with the
 

01:57:34.980 --> 01:57:37.670
you remember the game with the with the
boat racing that was doing the loop so

01:57:37.670 --> 01:57:37.680
boat racing that was doing the loop so
 

01:57:37.680 --> 01:57:39.560
boat racing that was doing the loop so
what was happening there was essentially

01:57:39.560 --> 01:57:39.570
what was happening there was essentially
 

01:57:39.570 --> 01:57:42.800
what was happening there was essentially
the boat had the choice between winning

01:57:42.800 --> 01:57:42.810
the boat had the choice between winning
 

01:57:42.810 --> 01:57:46.630
the boat had the choice between winning
and getting a lot of points say 20 or

01:57:46.630 --> 01:57:46.640
and getting a lot of points say 20 or
 

01:57:46.640 --> 01:57:48.710
and getting a lot of points say 20 or
exploiting this kind of loop that it

01:57:48.710 --> 01:57:48.720
exploiting this kind of loop that it
 

01:57:48.720 --> 01:57:51.290
exploiting this kind of loop that it
could do get even more points but not

01:57:51.290 --> 01:57:51.300
could do get even more points but not
 

01:57:51.300 --> 01:57:55.910
could do get even more points but not
win and it shows the second version and

01:57:55.910 --> 01:57:55.920
win and it shows the second version and
 

01:57:55.920 --> 01:57:57.500
win and it shows the second version and
the reason it shows the second version

01:57:57.500 --> 01:57:57.510
the reason it shows the second version
 

01:57:57.510 --> 01:58:00.500
the reason it shows the second version
was because there was a designer who

01:58:00.500 --> 01:58:00.510
was because there was a designer who
 

01:58:00.510 --> 01:58:02.180
was because there was a designer who
said look you should optimize for score

01:58:02.180 --> 01:58:02.190
said look you should optimize for score
 

01:58:02.190 --> 01:58:04.400
said look you should optimize for score
in the game so the interesting question

01:58:04.400 --> 01:58:04.410
in the game so the interesting question
 

01:58:04.410 --> 01:58:06.770
in the game so the interesting question
is why did the designers say that right

01:58:06.770 --> 01:58:06.780
is why did the designers say that right
 

01:58:06.780 --> 01:58:08.960
is why did the designers say that right
we designers are not totally dumb right

01:58:08.960 --> 01:58:08.970
we designers are not totally dumb right
 

01:58:08.970 --> 01:58:10.220
we designers are not totally dumb right
we're not just gonna write down every

01:58:10.220 --> 01:58:10.230
we're not just gonna write down every
 

01:58:10.230 --> 01:58:11.570
we're not just gonna write down every
word function and deployed their sent

01:58:11.570 --> 01:58:11.580
word function and deployed their sent
 

01:58:11.580 --> 01:58:13.250
word function and deployed their sent
the robot off them to the world and hope

01:58:13.250 --> 01:58:13.260
the robot off them to the world and hope
 

01:58:13.260 --> 01:58:16.550
the robot off them to the world and hope
for the best so the reason was that the

01:58:16.550 --> 01:58:16.560
for the best so the reason was that the
 

01:58:16.560 --> 01:58:18.650
for the best so the reason was that the
designer actually tested this robot on

01:58:18.650 --> 01:58:18.660
designer actually tested this robot on
 

01:58:18.660 --> 01:58:21.260
designer actually tested this robot on
some environments and on those

01:58:21.260 --> 01:58:21.270
some environments and on those
 

01:58:21.270 --> 01:58:24.590
some environments and on those
environments optimizing for points got

01:58:24.590 --> 01:58:24.600
environments optimizing for points got
 

01:58:24.600 --> 01:58:26.420
environments optimizing for points got
the boat to actually do the correct

01:58:26.420 --> 01:58:26.430
the boat to actually do the correct
 

01:58:26.430 --> 01:58:27.190
the boat to actually do the correct
thing

01:58:27.190 --> 01:58:27.200
thing
 

01:58:27.200 --> 01:58:30.860
thing
so at training time the the environments

01:58:30.860 --> 01:58:30.870
so at training time the the environments
 

01:58:30.870 --> 01:58:32.900
so at training time the the environments
that the person actually looked at were

01:58:32.900 --> 01:58:32.910
that the person actually looked at were
 

01:58:32.910 --> 01:58:34.850
that the person actually looked at were
pretty different than this one test

01:58:34.850 --> 01:58:34.860
pretty different than this one test
 

01:58:34.860 --> 01:58:36.620
pretty different than this one test
environment the training time you could

01:58:36.620 --> 01:58:36.630
environment the training time you could
 

01:58:36.630 --> 01:58:39.260
environment the training time you could
actually win with a lot of points if you

01:58:39.260 --> 01:58:39.270
actually win with a lot of points if you
 

01:58:39.270 --> 01:58:40.880
actually win with a lot of points if you
had fewer points then you wouldn't win

01:58:40.880 --> 01:58:40.890
had fewer points then you wouldn't win
 

01:58:40.890 --> 01:58:42.560
had fewer points then you wouldn't win
as much or as many times or you would

01:58:42.560 --> 01:58:42.570
as much or as many times or you would
 

01:58:42.570 --> 01:58:46.130
as much or as many times or you would
lose and so score and winning were

01:58:46.130 --> 01:58:46.140
lose and so score and winning were
 

01:58:46.140 --> 01:58:48.350
lose and so score and winning were
correlated at training time but they

01:58:48.350 --> 01:58:48.360
correlated at training time but they
 

01:58:48.360 --> 01:58:50.060
correlated at training time but they
were no longer correlated at test time

01:58:50.060 --> 01:58:50.070
were no longer correlated at test time
 

01:58:50.070 --> 01:58:52.700
were no longer correlated at test time
and that's what broke things so that's

01:58:52.700 --> 01:58:52.710
and that's what broke things so that's
 

01:58:52.710 --> 01:58:54.230
and that's what broke things so that's
one of the things that can go wrong or

01:58:54.230 --> 01:58:54.240
one of the things that can go wrong or
 

01:58:54.240 --> 01:58:55.190
one of the things that can go wrong or
you have features that no longer

01:58:55.190 --> 01:58:55.200
you have features that no longer
 

01:58:55.200 --> 01:58:57.830
you have features that no longer
correlate things can go wrong in many

01:58:57.830 --> 01:58:57.840
correlate things can go wrong in many
 

01:58:57.840 --> 01:58:59.960
correlate things can go wrong in many
other ways here's another example say

01:58:59.960 --> 01:58:59.970
other ways here's another example say
 

01:58:59.970 --> 01:59:02.570
other ways here's another example say
I'm building a robot to drive around the

01:59:02.570 --> 01:59:02.580
I'm building a robot to drive around the
 

01:59:02.580 --> 01:59:05.480
I'm building a robot to drive around the
CMU campus and I know it's gonna have to

01:59:05.480 --> 01:59:05.490
CMU campus and I know it's gonna have to
 

01:59:05.490 --> 01:59:06.890
CMU campus and I know it's gonna have to
deal with terrain and it deals with

01:59:06.890 --> 01:59:06.900
deal with terrain and it deals with
 

01:59:06.900 --> 01:59:09.320
deal with terrain and it deals with
grass and and paved roads and dirt roads

01:59:09.320 --> 01:59:09.330
grass and and paved roads and dirt roads
 

01:59:09.330 --> 01:59:11.530
grass and and paved roads and dirt roads
and so on and maybe I want the robot to

01:59:11.530 --> 01:59:11.540
and so on and maybe I want the robot to
 

01:59:11.540 --> 01:59:14.270
and so on and maybe I want the robot to
stay to avoid the grass and protect it

01:59:14.270 --> 01:59:14.280
stay to avoid the grass and protect it
 

01:59:14.280 --> 01:59:16.310
stay to avoid the grass and protect it
so I have to write down a reward

01:59:16.310 --> 01:59:16.320
so I have to write down a reward
 

01:59:16.320 --> 01:59:18.710
so I have to write down a reward
function for that the robot doesn't

01:59:18.710 --> 01:59:18.720
function for that the robot doesn't
 

01:59:18.720 --> 01:59:20.299
function for that the robot doesn't
actually know what

01:59:20.299 --> 01:59:20.309
actually know what
 

01:59:20.309 --> 01:59:22.879
actually know what
grass and what's dirt and so on and so

01:59:22.879 --> 01:59:22.889
grass and what's dirt and so on and so
 

01:59:22.889 --> 01:59:25.250
grass and what's dirt and so on and so
all it has is some sensor input let's

01:59:25.250 --> 01:59:25.260
all it has is some sensor input let's
 

01:59:25.260 --> 01:59:27.979
all it has is some sensor input let's
say lidar came from camera images and so

01:59:27.979 --> 01:59:27.989
say lidar came from camera images and so
 

01:59:27.989 --> 01:59:29.719
say lidar came from camera images and so
the first thing I'll do is I'll write

01:59:29.719 --> 01:59:29.729
the first thing I'll do is I'll write
 

01:59:29.729 --> 01:59:32.509
the first thing I'll do is I'll write
down some classifiers some detectors for

01:59:32.509 --> 01:59:32.519
down some classifiers some detectors for
 

01:59:32.519 --> 01:59:34.159
down some classifiers some detectors for
this terrain types and then I'll define

01:59:34.159 --> 01:59:34.169
this terrain types and then I'll define
 

01:59:34.169 --> 01:59:35.809
this terrain types and then I'll define
my reward function that says you know

01:59:35.809 --> 01:59:35.819
my reward function that says you know
 

01:59:35.819 --> 01:59:38.270
my reward function that says you know
grass is bad going on dirt or pavement

01:59:38.270 --> 01:59:38.280
grass is bad going on dirt or pavement
 

01:59:38.280 --> 01:59:41.689
grass is bad going on dirt or pavement
is better and so I deployed the robot

01:59:41.689 --> 01:59:41.699
is better and so I deployed the robot
 

01:59:41.699 --> 01:59:45.469
is better and so I deployed the robot
after some testing and it does well in

01:59:45.469 --> 01:59:45.479
after some testing and it does well in
 

01:59:45.479 --> 01:59:48.049
after some testing and it does well in
CMU I send it to Berkeley does well in

01:59:48.049 --> 01:59:48.059
CMU I send it to Berkeley does well in
 

01:59:48.059 --> 01:59:49.489
CMU I send it to Berkeley does well in
Berkeley and then I don't know I send it

01:59:49.489 --> 01:59:49.499
Berkeley and then I don't know I send it
 

01:59:49.499 --> 01:59:52.339
Berkeley and then I don't know I send it
to Hawaii and then Hawaii right there's

01:59:52.339 --> 01:59:52.349
to Hawaii and then Hawaii right there's
 

01:59:52.349 --> 01:59:55.129
to Hawaii and then Hawaii right there's
grass there's dirt but there's maybe

01:59:55.129 --> 01:59:55.139
grass there's dirt but there's maybe
 

01:59:55.139 --> 01:59:57.290
grass there's dirt but there's maybe
some dangerous surfaces as well that I

01:59:57.290 --> 01:59:57.300
some dangerous surfaces as well that I
 

01:59:57.300 --> 01:59:59.509
some dangerous surfaces as well that I
don't want the robot to go over for

01:59:59.509 --> 01:59:59.519
don't want the robot to go over for
 

01:59:59.519 --> 02:00:01.849
don't want the robot to go over for
dramatic effect in this talk will refer

02:00:01.849 --> 02:00:01.859
dramatic effect in this talk will refer
 

02:00:01.859 --> 02:00:04.339
dramatic effect in this talk will refer
to these as lava right there's mountains

02:00:04.339 --> 02:00:04.349
to these as lava right there's mountains
 

02:00:04.349 --> 02:00:06.409
to these as lava right there's mountains
of lava now what the robot will do a

02:00:06.409 --> 02:00:06.419
of lava now what the robot will do a
 

02:00:06.419 --> 02:00:08.119
of lava now what the robot will do a
deployment time is it's gonna use a

02:00:08.119 --> 02:00:08.129
deployment time is it's gonna use a
 

02:00:08.129 --> 02:00:09.979
deployment time is it's gonna use a
three word function that I define to

02:00:09.979 --> 02:00:09.989
three word function that I define to
 

02:00:09.989 --> 02:00:12.619
three word function that I define to
evaluate the different surfaces and who

02:00:12.619 --> 02:00:12.629
evaluate the different surfaces and who
 

02:00:12.629 --> 02:00:14.299
evaluate the different surfaces and who
knows what it's gonna do for lava that

02:00:14.299 --> 02:00:14.309
knows what it's gonna do for lava that
 

02:00:14.309 --> 02:00:15.770
knows what it's gonna do for lava that
wasn't right and we don't have detectors

02:00:15.770 --> 02:00:15.780
wasn't right and we don't have detectors
 

02:00:15.780 --> 02:00:17.869
wasn't right and we don't have detectors
for that we totally forgot about it so

02:00:17.869 --> 02:00:17.879
for that we totally forgot about it so
 

02:00:17.879 --> 02:00:19.520
for that we totally forgot about it so
this is one thing that can another thing

02:00:19.520 --> 02:00:19.530
this is one thing that can another thing
 

02:00:19.530 --> 02:00:20.959
this is one thing that can another thing
that can go wrong which is maybe we

02:00:20.959 --> 02:00:20.969
that can go wrong which is maybe we
 

02:00:20.969 --> 02:00:22.309
that can go wrong which is maybe we
don't actually think of all the edge

02:00:22.309 --> 02:00:22.319
don't actually think of all the edge
 

02:00:22.319 --> 02:00:24.139
don't actually think of all the edge
cases of all the possible things that

02:00:24.139 --> 02:00:24.149
cases of all the possible things that
 

02:00:24.149 --> 02:00:26.689
cases of all the possible things that
our robots might have to face like

02:00:26.689 --> 02:00:26.699
our robots might have to face like
 

02:00:26.699 --> 02:00:28.429
our robots might have to face like
dangerous surfaces that don't appear at

02:00:28.429 --> 02:00:28.439
dangerous surfaces that don't appear at
 

02:00:28.439 --> 02:00:30.699
dangerous surfaces that don't appear at
training time but if you're at test time

02:00:30.699 --> 02:00:30.709
training time but if you're at test time
 

02:00:30.709 --> 02:00:33.619
training time but if you're at test time
so even though with the boat example and

02:00:33.619 --> 02:00:33.629
so even though with the boat example and
 

02:00:33.629 --> 02:00:35.899
so even though with the boat example and
this navigation example there are

02:00:35.899 --> 02:00:35.909
this navigation example there are
 

02:00:35.909 --> 02:00:37.569
this navigation example there are
different things that are going wrong

02:00:37.569 --> 02:00:37.579
different things that are going wrong
 

02:00:37.579 --> 02:00:39.859
different things that are going wrong
they have one important thing in common

02:00:39.859 --> 02:00:39.869
they have one important thing in common
 

02:00:39.869 --> 02:00:42.709
they have one important thing in common
which is what gives me hope and that one

02:00:42.709 --> 02:00:42.719
which is what gives me hope and that one
 

02:00:42.719 --> 02:00:44.359
which is what gives me hope and that one
thing that they have in common is that

02:00:44.359 --> 02:00:44.369
thing that they have in common is that
 

02:00:44.369 --> 02:00:47.270
thing that they have in common is that
the designer actually did a pretty good

02:00:47.270 --> 02:00:47.280
the designer actually did a pretty good
 

02:00:47.280 --> 02:00:51.619
the designer actually did a pretty good
job for the training environments in

02:00:51.619 --> 02:00:51.629
job for the training environments in
 

02:00:51.629 --> 02:00:53.989
job for the training environments in
other words there's not much that we

02:00:53.989 --> 02:00:53.999
other words there's not much that we
 

02:00:53.999 --> 02:00:55.520
other words there's not much that we
know about the true reward what the

02:00:55.520 --> 02:00:55.530
know about the true reward what the
 

02:00:55.530 --> 02:00:57.829
know about the true reward what the
person actually wants but there's one

02:00:57.829 --> 02:00:57.839
person actually wants but there's one
 

02:00:57.839 --> 02:00:59.599
person actually wants but there's one
thing that we know which is that

02:00:59.599 --> 02:00:59.609
thing that we know which is that
 

02:00:59.609 --> 02:01:01.429
thing that we know which is that
whatever reward function the person

02:01:01.429 --> 02:01:01.439
whatever reward function the person
 

02:01:01.439 --> 02:01:03.949
whatever reward function the person
specified it might not work always it

02:01:03.949 --> 02:01:03.959
specified it might not work always it
 

02:01:03.959 --> 02:01:05.270
specified it might not work always it
might not produce the right behavior

02:01:05.270 --> 02:01:05.280
might not produce the right behavior
 

02:01:05.280 --> 02:01:07.879
might not produce the right behavior
always but on the training environments

02:01:07.879 --> 02:01:07.889
always but on the training environments
 

02:01:07.889 --> 02:01:09.829
always but on the training environments
it produces the right behavior and

02:01:09.829 --> 02:01:09.839
it produces the right behavior and
 

02:01:09.839 --> 02:01:11.929
it produces the right behavior and
that's information that we now have

02:01:11.929 --> 02:01:11.939
that's information that we now have
 

02:01:11.939 --> 02:01:14.599
that's information that we now have
about the true reward all right we don't

02:01:14.599 --> 02:01:14.609
about the true reward all right we don't
 

02:01:14.609 --> 02:01:16.129
about the true reward all right we don't
have the true reward but we know this

02:01:16.129 --> 02:01:16.139
have the true reward but we know this
 

02:01:16.139 --> 02:01:17.839
have the true reward but we know this
much and in fact that adequate that's

02:01:17.839 --> 02:01:17.849
much and in fact that adequate that's
 

02:01:17.849 --> 02:01:20.419
much and in fact that adequate that's
all that we should assume if a person

02:01:20.419 --> 02:01:20.429
all that we should assume if a person
 

02:01:20.429 --> 02:01:22.939
all that we should assume if a person
specifies a reward another way of saying

02:01:22.939 --> 02:01:22.949
specifies a reward another way of saying
 

02:01:22.949 --> 02:01:25.099
specifies a reward another way of saying
the same thing is that look what we end

02:01:25.099 --> 02:01:25.109
the same thing is that look what we end
 

02:01:25.109 --> 02:01:28.849
the same thing is that look what we end
up specifying is contextualized in the

02:01:28.849 --> 02:01:28.859
up specifying is contextualized in the
 

02:01:28.859 --> 02:01:31.549
up specifying is contextualized in the
experiences that we have robots are not

02:01:31.549 --> 02:01:31.559
experiences that we have robots are not
 

02:01:31.559 --> 02:01:34.359
experiences that we have robots are not
interpreted literally right should

02:01:34.359 --> 02:01:34.369
interpreted literally right should
 

02:01:34.369 --> 02:01:36.429
interpreted literally right should
interpreted as being contextualized in

02:01:36.429 --> 02:01:36.439
interpreted as being contextualized in
 

02:01:36.439 --> 02:01:40.359
interpreted as being contextualized in
the experiences that we have for robot

02:01:40.359 --> 02:01:40.369
the experiences that we have for robot
 

02:01:40.369 --> 02:01:41.709
the experiences that we have for robot
assistant the artist mathematically the

02:01:41.709 --> 02:01:41.719
assistant the artist mathematically the
 

02:01:41.719 --> 02:01:43.029
assistant the artist mathematically the
way we do this is instead of just

02:01:43.029 --> 02:01:43.039
way we do this is instead of just
 

02:01:43.039 --> 02:01:45.909
way we do this is instead of just
optimizing the reward function we treat

02:01:45.909 --> 02:01:45.919
optimizing the reward function we treat
 

02:01:45.919 --> 02:01:47.469
optimizing the reward function we treat
it as an observation and the Bayesian

02:01:47.469 --> 02:01:47.479
it as an observation and the Bayesian
 

02:01:47.479 --> 02:01:49.000
it as an observation and the Bayesian
sense about the underlying true reward

02:01:49.000 --> 02:01:49.010
sense about the underlying true reward
 

02:01:49.010 --> 02:01:51.100
sense about the underlying true reward
and to do that we have to reason about

02:01:51.100 --> 02:01:51.110
and to do that we have to reason about
 

02:01:51.110 --> 02:01:55.209
and to do that we have to reason about
if theta star is the true reward if the

02:01:55.209 --> 02:01:55.219
if theta star is the true reward if the
 

02:01:55.219 --> 02:01:56.679
if theta star is the true reward if the
trade the person who is looking at the

02:01:56.679 --> 02:01:56.689
trade the person who is looking at the
 

02:01:56.689 --> 02:01:58.299
trade the person who is looking at the
training environment what will they

02:01:58.299 --> 02:01:58.309
training environment what will they
 

02:01:58.309 --> 02:02:00.129
training environment what will they
write down what is likely for them to

02:02:00.129 --> 02:02:00.139
write down what is likely for them to
 

02:02:00.139 --> 02:02:02.080
write down what is likely for them to
specify and that's where we use our

02:02:02.080 --> 02:02:02.090
specify and that's where we use our
 

02:02:02.090 --> 02:02:04.419
specify and that's where we use our
insight what we do is we say well how

02:02:04.419 --> 02:02:04.429
insight what we do is we say well how
 

02:02:04.429 --> 02:02:06.850
insight what we do is we say well how
likely is the beta tilde to be written

02:02:06.850 --> 02:02:06.860
likely is the beta tilde to be written
 

02:02:06.860 --> 02:02:08.739
likely is the beta tilde to be written
down as the specified reward

02:02:08.739 --> 02:02:08.749
down as the specified reward
 

02:02:08.749 --> 02:02:11.199
down as the specified reward
well I have to look at what behavior it

02:02:11.199 --> 02:02:11.209
well I have to look at what behavior it
 

02:02:11.209 --> 02:02:13.239
well I have to look at what behavior it
incentivizes on the training

02:02:13.239 --> 02:02:13.249
incentivizes on the training
 

02:02:13.249 --> 02:02:15.939
incentivizes on the training
environments and if that behavior is

02:02:15.939 --> 02:02:15.949
environments and if that behavior is
 

02:02:15.949 --> 02:02:19.029
environments and if that behavior is
good with respect to theta star then I

02:02:19.029 --> 02:02:19.039
good with respect to theta star then I
 

02:02:19.039 --> 02:02:20.679
good with respect to theta star then I
know that if theta star is the correct

02:02:20.679 --> 02:02:20.689
know that if theta star is the correct
 

02:02:20.689 --> 02:02:22.449
know that if theta star is the correct
reward theta tilde is likely to be

02:02:22.449 --> 02:02:22.459
reward theta tilde is likely to be
 

02:02:22.459 --> 02:02:23.919
reward theta tilde is likely to be
written down more likely to be written

02:02:23.919 --> 02:02:23.929
written down more likely to be written
 

02:02:23.929 --> 02:02:26.229
written down more likely to be written
down by the designer as the specified

02:02:26.229 --> 02:02:26.239
down by the designer as the specified
 

02:02:26.239 --> 02:02:28.179
down by the designer as the specified
reward so that's how we do it

02:02:28.179 --> 02:02:28.189
reward so that's how we do it
 

02:02:28.189 --> 02:02:29.949
reward so that's how we do it
intuitively what this means is as

02:02:29.949 --> 02:02:29.959
intuitively what this means is as
 

02:02:29.959 --> 02:02:32.979
intuitively what this means is as
follows going back to the boat example

02:02:32.979 --> 02:02:32.989
follows going back to the boat example
 

02:02:32.989 --> 02:02:35.080
follows going back to the boat example
imagine that there's a plethora of

02:02:35.080 --> 02:02:35.090
imagine that there's a plethora of
 

02:02:35.090 --> 02:02:37.689
imagine that there's a plethora of
different reward functions that the

02:02:37.689 --> 02:02:37.699
different reward functions that the
 

02:02:37.699 --> 02:02:40.569
different reward functions that the
person that the person might define

02:02:40.569 --> 02:02:40.579
person that the person might define
 

02:02:40.579 --> 02:02:42.639
person that the person might define
right so there's all these different

02:02:42.639 --> 02:02:42.649
right so there's all these different
 

02:02:42.649 --> 02:02:44.739
right so there's all these different
features that might be relevant the

02:02:44.739 --> 02:02:44.749
features that might be relevant the
 

02:02:44.749 --> 02:02:47.199
features that might be relevant the
person specified theta 2 which is

02:02:47.199 --> 02:02:47.209
person specified theta 2 which is
 

02:02:47.209 --> 02:02:48.989
person specified theta 2 which is
maximized score that's what they picked

02:02:48.989 --> 02:02:48.999
maximized score that's what they picked
 

02:02:48.999 --> 02:02:52.270
maximized score that's what they picked
instead of just optimizing for score

02:02:52.270 --> 02:02:52.280
instead of just optimizing for score
 

02:02:52.280 --> 02:02:54.819
instead of just optimizing for score
what our robot is going to do is it's

02:02:54.819 --> 02:02:54.829
what our robot is going to do is it's
 

02:02:54.829 --> 02:02:56.679
what our robot is going to do is it's
going to take a step back and say what's

02:02:56.679 --> 02:02:56.689
going to take a step back and say what's
 

02:02:56.689 --> 02:02:58.330
going to take a step back and say what's
the experience that they had to draw on

02:02:58.330 --> 02:02:58.340
the experience that they had to draw on
 

02:02:58.340 --> 02:03:00.879
the experience that they had to draw on
when they specified theta 2 let's take a

02:03:00.879 --> 02:03:00.889
when they specified theta 2 let's take a
 

02:03:00.889 --> 02:03:02.049
when they specified theta 2 let's take a
look right they looked at these

02:03:02.049 --> 02:03:02.059
look right they looked at these
 

02:03:02.059 --> 02:03:03.669
look right they looked at these
environments where you could either win

02:03:03.669 --> 02:03:03.679
environments where you could either win
 

02:03:03.679 --> 02:03:06.399
environments where you could either win
with a lot of points or lose with fewer

02:03:06.399 --> 02:03:06.409
with a lot of points or lose with fewer
 

02:03:06.409 --> 02:03:09.100
with a lot of points or lose with fewer
points and theta 2 incentivizes the

02:03:09.100 --> 02:03:09.110
points and theta 2 incentivizes the
 

02:03:09.110 --> 02:03:10.750
points and theta 2 incentivizes the
behavior where you get a lot of score

02:03:10.750 --> 02:03:10.760
behavior where you get a lot of score
 

02:03:10.760 --> 02:03:14.080
behavior where you get a lot of score
and you and you also win and so what the

02:03:14.080 --> 02:03:14.090
and you and you also win and so what the
 

02:03:14.090 --> 02:03:16.689
and you and you also win and so what the
robot is wondering now is for which of

02:03:16.689 --> 02:03:16.699
robot is wondering now is for which of
 

02:03:16.699 --> 02:03:21.549
robot is wondering now is for which of
all these possibilities is winning with

02:03:21.549 --> 02:03:21.559
all these possibilities is winning with
 

02:03:21.559 --> 02:03:23.409
all these possibilities is winning with
high score a good idea which of these

02:03:23.409 --> 02:03:23.419
high score a good idea which of these
 

02:03:23.419 --> 02:03:24.939
high score a good idea which of these
reward functions could have been the

02:03:24.939 --> 02:03:24.949
reward functions could have been the
 

02:03:24.949 --> 02:03:26.770
reward functions could have been the
true reward function and what you can

02:03:26.770 --> 02:03:26.780
true reward function and what you can
 

02:03:26.780 --> 02:03:28.350
true reward function and what you can
figure out pretty easily is that

02:03:28.350 --> 02:03:28.360
figure out pretty easily is that
 

02:03:28.360 --> 02:03:31.020
figure out pretty easily is that
maximizing score likes this behavior

02:03:31.020 --> 02:03:31.030
maximizing score likes this behavior
 

02:03:31.030 --> 02:03:34.119
maximizing score likes this behavior
minimizing score or trying to lose if

02:03:34.119 --> 02:03:34.129
minimizing score or trying to lose if
 

02:03:34.129 --> 02:03:36.069
minimizing score or trying to lose if
that were the objective that doesn't

02:03:36.069 --> 02:03:36.079
that were the objective that doesn't
 

02:03:36.079 --> 02:03:37.239
that were the objective that doesn't
like this behavior so you can throw that

02:03:37.239 --> 02:03:37.249
like this behavior so you can throw that
 

02:03:37.249 --> 02:03:39.600
like this behavior so you can throw that
right out but you also understand that

02:03:39.600 --> 02:03:39.610
right out but you also understand that
 

02:03:39.610 --> 02:03:42.699
right out but you also understand that
maximizing winning is something that

02:03:42.699 --> 02:03:42.709
maximizing winning is something that
 

02:03:42.709 --> 02:03:44.379
maximizing winning is something that
likes this behavior so now the robot

02:03:44.379 --> 02:03:44.389
likes this behavior so now the robot
 

02:03:44.389 --> 02:03:46.899
likes this behavior so now the robot
knows ok I was told to optimize for

02:03:46.899 --> 02:03:46.909
knows ok I was told to optimize for
 

02:03:46.909 --> 02:03:47.560
knows ok I was told to optimize for
school

02:03:47.560 --> 02:03:47.570
school
 

02:03:47.570 --> 02:03:49.839
school
I'm pretty sure the person didn't mean

02:03:49.839 --> 02:03:49.849
I'm pretty sure the person didn't mean
 

02:03:49.849 --> 02:03:53.259
I'm pretty sure the person didn't mean
to lose or to minimize score but I don't

02:03:53.259 --> 02:03:53.269
to lose or to minimize score but I don't
 

02:03:53.269 --> 02:03:55.060
to lose or to minimize score but I don't
know if they didn't mean to win because

02:03:55.060 --> 02:03:55.070
know if they didn't mean to win because
 

02:03:55.070 --> 02:03:57.000
know if they didn't mean to win because
based on the information that they had

02:03:57.000 --> 02:03:57.010
based on the information that they had
 

02:03:57.010 --> 02:04:00.129
based on the information that they had
winning also might look like a good

02:04:00.129 --> 02:04:00.139
winning also might look like a good
 

02:04:00.139 --> 02:04:03.759
winning also might look like a good
thing so and they might have not gotten

02:04:03.759 --> 02:04:03.769
thing so and they might have not gotten
 

02:04:03.769 --> 02:04:07.419
thing so and they might have not gotten
that so this is a very simple to example

02:04:07.419 --> 02:04:07.429
that so this is a very simple to example
 

02:04:07.429 --> 02:04:08.830
that so this is a very simple to example
we've been playing with situations that

02:04:08.830 --> 02:04:08.840
we've been playing with situations that
 

02:04:08.840 --> 02:04:10.989
we've been playing with situations that
are actually complicated where the robot

02:04:10.989 --> 02:04:10.999
are actually complicated where the robot
 

02:04:10.999 --> 02:04:12.970
are actually complicated where the robot
doesn't get convenient access to all the

02:04:12.970 --> 02:04:12.980
doesn't get convenient access to all the
 

02:04:12.980 --> 02:04:14.830
doesn't get convenient access to all the
important relevant fixer features like

02:04:14.830 --> 02:04:14.840
important relevant fixer features like
 

02:04:14.840 --> 02:04:16.720
important relevant fixer features like
winning we've been looking at motion

02:04:16.720 --> 02:04:16.730
winning we've been looking at motion
 

02:04:16.730 --> 02:04:19.540
winning we've been looking at motion
planning to where we end up with these

02:04:19.540 --> 02:04:19.550
planning to where we end up with these
 

02:04:19.550 --> 02:04:21.459
planning to where we end up with these
more robust behaviors and these

02:04:21.459 --> 02:04:21.469
more robust behaviors and these
 

02:04:21.469 --> 02:04:23.589
more robust behaviors and these
complicated new environments that the

02:04:23.589 --> 02:04:23.599
complicated new environments that the
 

02:04:23.599 --> 02:04:27.129
complicated new environments that the
robot is choosing and so overall I think

02:04:27.129 --> 02:04:27.139
robot is choosing and so overall I think
 

02:04:27.139 --> 02:04:28.330
robot is choosing and so overall I think
that was just one example of the

02:04:28.330 --> 02:04:28.340
that was just one example of the
 

02:04:28.340 --> 02:04:30.580
that was just one example of the
approaches we can take but overall what

02:04:30.580 --> 02:04:30.590
approaches we can take but overall what
 

02:04:30.590 --> 02:04:32.859
approaches we can take but overall what
I'd say is whether it's a designer

02:04:32.859 --> 02:04:32.869
I'd say is whether it's a designer
 

02:04:32.869 --> 02:04:36.189
I'd say is whether it's a designer
that's writing down a reward function or

02:04:36.189 --> 02:04:36.199
that's writing down a reward function or
 

02:04:36.199 --> 02:04:37.810
that's writing down a reward function or
an end user telling you that you're

02:04:37.810 --> 02:04:37.820
an end user telling you that you're
 

02:04:37.820 --> 02:04:39.910
an end user telling you that you're
doing something wrong or even actually

02:04:39.910 --> 02:04:39.920
doing something wrong or even actually
 

02:04:39.920 --> 02:04:42.640
doing something wrong or even actually
giving you Corrections what the robot

02:04:42.640 --> 02:04:42.650
giving you Corrections what the robot
 

02:04:42.650 --> 02:04:44.950
giving you Corrections what the robot
should be doing is taking goal of this

02:04:44.950 --> 02:04:44.960
should be doing is taking goal of this
 

02:04:44.960 --> 02:04:47.620
should be doing is taking goal of this
in as useful evidence it's useful

02:04:47.620 --> 02:04:47.630
in as useful evidence it's useful
 

02:04:47.630 --> 02:04:49.450
in as useful evidence it's useful
information about what people actually

02:04:49.450 --> 02:04:49.460
information about what people actually
 

02:04:49.460 --> 02:04:51.520
information about what people actually
want and what the robot is actually

02:04:51.520 --> 02:04:51.530
want and what the robot is actually
 

02:04:51.530 --> 02:04:54.669
want and what the robot is actually
supposed to do and improving that over

02:04:54.669 --> 02:04:54.679
supposed to do and improving that over
 

02:04:54.679 --> 02:04:56.859
supposed to do and improving that over
time and getting better and better at

02:04:56.859 --> 02:04:56.869
time and getting better and better at
 

02:04:56.869 --> 02:04:59.410
time and getting better and better at
optimizing not a specified reward but

02:04:59.410 --> 02:04:59.420
optimizing not a specified reward but
 

02:04:59.420 --> 02:05:01.479
optimizing not a specified reward but
what people actually want here's what

02:05:01.479 --> 02:05:01.489
what people actually want here's what
 

02:05:01.489 --> 02:05:03.609
what people actually want here's what
happens with our little example when you

02:05:03.609 --> 02:05:03.619
happens with our little example when you
 

02:05:03.619 --> 02:05:05.200
happens with our little example when you
do this I push on the robot

02:05:05.200 --> 02:05:05.210
do this I push on the robot
 

02:05:05.210 --> 02:05:07.149
do this I push on the robot
and instead of just going back the robot

02:05:07.149 --> 02:05:07.159
and instead of just going back the robot
 

02:05:07.159 --> 02:05:10.029
and instead of just going back the robot
interprets that as evidence about what I

02:05:10.029 --> 02:05:10.039
interprets that as evidence about what I
 

02:05:10.039 --> 02:05:12.640
interprets that as evidence about what I
want and it ends up doing the task very

02:05:12.640 --> 02:05:12.650
want and it ends up doing the task very
 

02:05:12.650 --> 02:05:17.739
want and it ends up doing the task very
differently so to conclude there's this

02:05:17.739 --> 02:05:17.749
differently so to conclude there's this
 

02:05:17.749 --> 02:05:19.750
differently so to conclude there's this
mismatch that we now have and I think

02:05:19.750 --> 02:05:19.760
mismatch that we now have and I think
 

02:05:19.760 --> 02:05:22.479
mismatch that we now have and I think
both making robots more trustworthy and

02:05:22.479 --> 02:05:22.489
both making robots more trustworthy and
 

02:05:22.489 --> 02:05:24.250
both making robots more trustworthy and
the ways that we've talked about as well

02:05:24.250 --> 02:05:24.260
the ways that we've talked about as well
 

02:05:24.260 --> 02:05:26.709
the ways that we've talked about as well
as making robots more transparent it's

02:05:26.709 --> 02:05:26.719
as making robots more transparent it's
 

02:05:26.719 --> 02:05:29.080
as making robots more transparent it's
going to help with not necessarily

02:05:29.080 --> 02:05:29.090
going to help with not necessarily
 

02:05:29.090 --> 02:05:30.970
going to help with not necessarily
resolving one thing or another but

02:05:30.970 --> 02:05:30.980
resolving one thing or another but
 

02:05:30.980 --> 02:05:35.020
resolving one thing or another but
bringing these these two items the real

02:05:35.020 --> 02:05:35.030
bringing these these two items the real
 

02:05:35.030 --> 02:05:37.479
bringing these these two items the real
robot and the mental model closer to

02:05:37.479 --> 02:05:37.489
robot and the mental model closer to
 

02:05:37.489 --> 02:05:39.790
robot and the mental model closer to
each other and have a common middle

02:05:39.790 --> 02:05:39.800
each other and have a common middle
 

02:05:39.800 --> 02:05:42.580
each other and have a common middle
ground that works out well for the human

02:05:42.580 --> 02:05:42.590
ground that works out well for the human
 

02:05:42.590 --> 02:05:44.649
ground that works out well for the human
and the robot with that I'd like to

02:05:44.649 --> 02:05:44.659
and the robot with that I'd like to
 

02:05:44.659 --> 02:05:46.440
and the robot with that I'd like to
thank you very much

02:05:46.440 --> 02:05:46.450
thank you very much
 

02:05:46.450 --> 02:05:53.910
thank you very much
[Applause]

02:05:53.910 --> 02:05:53.920
[Applause]
 

02:05:53.920 --> 02:05:57.600
[Applause]
thank you so much you won't need the mic

02:05:57.600 --> 02:05:57.610
thank you so much you won't need the mic
 

02:05:57.610 --> 02:06:00.850
thank you so much you won't need the mic
so that was really wonderful and I think

02:06:00.850 --> 02:06:00.860
so that was really wonderful and I think
 

02:06:00.860 --> 02:06:02.830
so that was really wonderful and I think
especially the ways in which you focused

02:06:02.830 --> 02:06:02.840
especially the ways in which you focused
 

02:06:02.840 --> 02:06:06.279
especially the ways in which you focused
on reward functions as connected

02:06:06.279 --> 02:06:06.289
on reward functions as connected
 

02:06:06.289 --> 02:06:07.779
on reward functions as connected
directly into the end of the previous

02:06:07.779 --> 02:06:07.789
directly into the end of the previous
 

02:06:07.789 --> 02:06:09.729
directly into the end of the previous
panel this idea that we want the robots

02:06:09.729 --> 02:06:09.739
panel this idea that we want the robots
 

02:06:09.739 --> 02:06:12.310
panel this idea that we want the robots
to to support our goals in our interests

02:06:12.310 --> 02:06:12.320
to to support our goals in our interests
 

02:06:12.320 --> 02:06:13.720
to to support our goals in our interests
well then we have to say what counts is

02:06:13.720 --> 02:06:13.730
well then we have to say what counts is
 

02:06:13.730 --> 02:06:16.750
well then we have to say what counts is
success and how do we do that well that

02:06:16.750 --> 02:06:16.760
success and how do we do that well that
 

02:06:16.760 --> 02:06:18.370
success and how do we do that well that
might be very hard for us humans to do

02:06:18.370 --> 02:06:18.380
might be very hard for us humans to do
 

02:06:18.380 --> 02:06:21.129
might be very hard for us humans to do
and so how can the robot learn what we

02:06:21.129 --> 02:06:21.139
and so how can the robot learn what we
 

02:06:21.139 --> 02:06:24.430
and so how can the robot learn what we
wanted without us even knowing it but

02:06:24.430 --> 02:06:24.440
wanted without us even knowing it but
 

02:06:24.440 --> 02:06:25.959
wanted without us even knowing it but
but of course I have to ask that there's

02:06:25.959 --> 02:06:25.969
but of course I have to ask that there's
 

02:06:25.969 --> 02:06:29.229
but of course I have to ask that there's
a risk I might say and want the robot to

02:06:29.229 --> 02:06:29.239
a risk I might say and want the robot to
 

02:06:29.239 --> 02:06:31.290
a risk I might say and want the robot to
help me not eat lots of chocolate cake

02:06:31.290 --> 02:06:31.300
help me not eat lots of chocolate cake
 

02:06:31.300 --> 02:06:33.549
help me not eat lots of chocolate cake
but then it looks at what I actually do

02:06:33.549 --> 02:06:33.559
but then it looks at what I actually do
 

02:06:33.559 --> 02:06:35.290
but then it looks at what I actually do
and says boy you eat a lot of chocolate

02:06:35.290 --> 02:06:35.300
and says boy you eat a lot of chocolate
 

02:06:35.300 --> 02:06:39.040
and says boy you eat a lot of chocolate
cake so how do we help the you know are

02:06:39.040 --> 02:06:39.050
cake so how do we help the you know are
 

02:06:39.050 --> 02:06:40.569
cake so how do we help the you know are
there ways that the robots might be able

02:06:40.569 --> 02:06:40.579
there ways that the robots might be able
 

02:06:40.579 --> 02:06:43.450
there ways that the robots might be able
to help us overcome our own in abilities

02:06:43.450 --> 02:06:43.460
to help us overcome our own in abilities
 

02:06:43.460 --> 02:06:47.229
to help us overcome our own in abilities
to live by what we want that's a

02:06:47.229 --> 02:06:47.239
to live by what we want that's a
 

02:06:47.239 --> 02:06:50.049
to live by what we want that's a
fantastic question because I think

02:06:50.049 --> 02:06:50.059
fantastic question because I think
 

02:06:50.059 --> 02:06:51.459
fantastic question because I think
you're right that there is there is a

02:06:51.459 --> 02:06:51.469
you're right that there is there is a
 

02:06:51.469 --> 02:06:55.540
you're right that there is there is a
risk that what we end up optimizing for

02:06:55.540 --> 02:06:55.550
risk that what we end up optimizing for
 

02:06:55.550 --> 02:06:58.450
risk that what we end up optimizing for
and what we want the robot to do are

02:06:58.450 --> 02:06:58.460
and what we want the robot to do are
 

02:06:58.460 --> 02:07:00.100
and what we want the robot to do are
very different but maybe one way I'd

02:07:00.100 --> 02:07:00.110
very different but maybe one way I'd
 

02:07:00.110 --> 02:07:04.629
very different but maybe one way I'd
look at this is that our objectives are

02:07:04.629 --> 02:07:04.639
look at this is that our objectives are
 

02:07:04.639 --> 02:07:06.279
look at this is that our objectives are
still there I still want to be a healthy

02:07:06.279 --> 02:07:06.289
still there I still want to be a healthy
 

02:07:06.289 --> 02:07:09.850
still there I still want to be a healthy
person but I'm pretty let's say myopic

02:07:09.850 --> 02:07:09.860
person but I'm pretty let's say myopic
 

02:07:09.860 --> 02:07:13.089
person but I'm pretty let's say myopic
or greedy in my planning horizon right

02:07:13.089 --> 02:07:13.099
or greedy in my planning horizon right
 

02:07:13.099 --> 02:07:16.689
or greedy in my planning horizon right
so I end up being tempted by the

02:07:16.689 --> 02:07:16.699
so I end up being tempted by the
 

02:07:16.699 --> 02:07:18.640
so I end up being tempted by the
chocolate because I don't necessarily

02:07:18.640 --> 02:07:18.650
chocolate because I don't necessarily
 

02:07:18.650 --> 02:07:21.339
chocolate because I don't necessarily
think through in the moment of all the

02:07:21.339 --> 02:07:21.349
think through in the moment of all the
 

02:07:21.349 --> 02:07:23.490
think through in the moment of all the
implications this is gonna have or maybe

02:07:23.490 --> 02:07:23.500
implications this is gonna have or maybe
 

02:07:23.500 --> 02:07:26.049
implications this is gonna have or maybe
I'm just you know there's one there's

02:07:26.049 --> 02:07:26.059
I'm just you know there's one there's
 

02:07:26.059 --> 02:07:27.580
I'm just you know there's one there's
many ways to which I can be suboptimal

02:07:27.580 --> 02:07:27.590
many ways to which I can be suboptimal
 

02:07:27.590 --> 02:07:30.569
many ways to which I can be suboptimal
and what I'm going for and so I think

02:07:30.569 --> 02:07:30.579
and what I'm going for and so I think
 

02:07:30.579 --> 02:07:33.790
and what I'm going for and so I think
one important to the line of work to

02:07:33.790 --> 02:07:33.800
one important to the line of work to
 

02:07:33.800 --> 02:07:36.790
one important to the line of work to
take when trying to look at human

02:07:36.790 --> 02:07:36.800
take when trying to look at human
 

02:07:36.800 --> 02:07:38.680
take when trying to look at human
behavior and sort of back out what our

02:07:38.680 --> 02:07:38.690
behavior and sort of back out what our
 

02:07:38.690 --> 02:07:41.560
behavior and sort of back out what our
incentives are is is to account for the

02:07:41.560 --> 02:07:41.570
incentives are is is to account for the
 

02:07:41.570 --> 02:07:43.359
incentives are is is to account for the
fact that people are not gonna be

02:07:43.359 --> 02:07:43.369
fact that people are not gonna be
 

02:07:43.369 --> 02:07:45.310
fact that people are not gonna be
optimal and serve therefore their

02:07:45.310 --> 02:07:45.320
optimal and serve therefore their
 

02:07:45.320 --> 02:07:47.770
optimal and serve therefore their
Corrections and their actions are not

02:07:47.770 --> 02:07:47.780
Corrections and their actions are not
 

02:07:47.780 --> 02:07:51.069
Corrections and their actions are not
necessarily going to be what they would

02:07:51.069 --> 02:07:51.079
necessarily going to be what they would
 

02:07:51.079 --> 02:07:54.520
necessarily going to be what they would
if the person were actually truly

02:07:54.520 --> 02:07:54.530
if the person were actually truly
 

02:07:54.530 --> 02:07:57.430
if the person were actually truly
optimal perfectly optimal and what we've

02:07:57.430 --> 02:07:57.440
optimal perfectly optimal and what we've
 

02:07:57.440 --> 02:07:59.709
optimal perfectly optimal and what we've
been finding is that for instance if we

02:07:59.709 --> 02:07:59.719
been finding is that for instance if we
 

02:07:59.719 --> 02:08:01.340
been finding is that for instance if we
assume that the person

02:08:01.340 --> 02:08:01.350
assume that the person
 

02:08:01.350 --> 02:08:03.320
assume that the person
myopic right then we can do a much

02:08:03.320 --> 02:08:03.330
myopic right then we can do a much
 

02:08:03.330 --> 02:08:05.210
myopic right then we can do a much
better job recovering their true

02:08:05.210 --> 02:08:05.220
better job recovering their true
 

02:08:05.220 --> 02:08:06.920
better job recovering their true
objective function and sort of kind of

02:08:06.920 --> 02:08:06.930
objective function and sort of kind of
 

02:08:06.930 --> 02:08:08.930
objective function and sort of kind of
controlled experiments then if we assume

02:08:08.930 --> 02:08:08.940
controlled experiments then if we assume
 

02:08:08.940 --> 02:08:11.420
controlled experiments then if we assume
that they weren't right so so I think

02:08:11.420 --> 02:08:11.430
that they weren't right so so I think
 

02:08:11.430 --> 02:08:13.130
that they weren't right so so I think
it's important for robots to actually

02:08:13.130 --> 02:08:13.140
it's important for robots to actually
 

02:08:13.140 --> 02:08:15.320
it's important for robots to actually
take these biases that we might have and

02:08:15.320 --> 02:08:15.330
take these biases that we might have and
 

02:08:15.330 --> 02:08:16.700
take these biases that we might have and
they're different ones they're just

02:08:16.700 --> 02:08:16.710
they're different ones they're just
 

02:08:16.710 --> 02:08:18.230
they're different ones they're just
planning fallacy there's all sorts of

02:08:18.230 --> 02:08:18.240
planning fallacy there's all sorts of
 

02:08:18.240 --> 02:08:20.450
planning fallacy there's all sorts of
different biases that people have but

02:08:20.450 --> 02:08:20.460
different biases that people have but
 

02:08:20.460 --> 02:08:22.190
different biases that people have but
but maybe that's one way to think about

02:08:22.190 --> 02:08:22.200
but maybe that's one way to think about
 

02:08:22.200 --> 02:08:24.170
but maybe that's one way to think about
it and that would enable the robot not

02:08:24.170 --> 02:08:24.180
it and that would enable the robot not
 

02:08:24.180 --> 02:08:26.090
it and that would enable the robot not
necessarily to identify what do we want

02:08:26.090 --> 02:08:26.100
necessarily to identify what do we want
 

02:08:26.100 --> 02:08:28.010
necessarily to identify what do we want
to be healthy or not but I think the key

02:08:28.010 --> 02:08:28.020
to be healthy or not but I think the key
 

02:08:28.020 --> 02:08:30.040
to be healthy or not but I think the key
to what I was talking about is really

02:08:30.040 --> 02:08:30.050
to what I was talking about is really
 

02:08:30.050 --> 02:08:33.620
to what I was talking about is really
get the right uncertainty right it's not

02:08:33.620 --> 02:08:33.630
get the right uncertainty right it's not
 

02:08:33.630 --> 02:08:36.130
get the right uncertainty right it's not
like the robot knows whether winning or

02:08:36.130 --> 02:08:36.140
like the robot knows whether winning or
 

02:08:36.140 --> 02:08:39.320
like the robot knows whether winning or
score is the right one it's not like the

02:08:39.320 --> 02:08:39.330
score is the right one it's not like the
 

02:08:39.330 --> 02:08:41.810
score is the right one it's not like the
robot knows that lavas bad right it just

02:08:41.810 --> 02:08:41.820
robot knows that lavas bad right it just
 

02:08:41.820 --> 02:08:44.540
robot knows that lavas bad right it just
knows that given what you've said

02:08:44.540 --> 02:08:44.550
knows that given what you've said
 

02:08:44.550 --> 02:08:46.820
knows that given what you've said
there's not enough evidence of either

02:08:46.820 --> 02:08:46.830
there's not enough evidence of either
 

02:08:46.830 --> 02:08:48.800
there's not enough evidence of either
way and it has uncertainty about those

02:08:48.800 --> 02:08:48.810
way and it has uncertainty about those
 

02:08:48.810 --> 02:08:49.940
way and it has uncertainty about those
and there's there's things that it

02:08:49.940 --> 02:08:49.950
and there's there's things that it
 

02:08:49.950 --> 02:08:51.380
and there's there's things that it
doesn't have uncertainty about because

02:08:51.380 --> 02:08:51.390
doesn't have uncertainty about because
 

02:08:51.390 --> 02:08:52.970
doesn't have uncertainty about because
they don't match up at all it's not

02:08:52.970 --> 02:08:52.980
they don't match up at all it's not
 

02:08:52.980 --> 02:08:55.190
they don't match up at all it's not
they're not possible hypotheses being

02:08:55.190 --> 02:08:55.200
they're not possible hypotheses being
 

02:08:55.200 --> 02:08:56.630
they're not possible hypotheses being
able to recognize some of those known

02:08:56.630 --> 02:08:56.640
able to recognize some of those known
 

02:08:56.640 --> 02:08:58.790
able to recognize some of those known
unknown having something become a known

02:08:58.790 --> 02:08:58.800
unknown having something become a known
 

02:08:58.800 --> 02:08:59.930
unknown having something become a known
unknown to use the language from

02:08:59.930 --> 02:08:59.940
unknown to use the language from
 

02:08:59.940 --> 02:09:02.480
unknown to use the language from
America's talk that's right so I wonder

02:09:02.480 --> 02:09:02.490
America's talk that's right so I wonder
 

02:09:02.490 --> 02:09:04.690
America's talk that's right so I wonder
could you also use these same sorts of

02:09:04.690 --> 02:09:04.700
could you also use these same sorts of
 

02:09:04.700 --> 02:09:08.270
could you also use these same sorts of
techniques to handle potential

02:09:08.270 --> 02:09:08.280
techniques to handle potential
 

02:09:08.280 --> 02:09:09.740
techniques to handle potential
challenges where the robot has to

02:09:09.740 --> 02:09:09.750
challenges where the robot has to
 

02:09:09.750 --> 02:09:11.660
challenges where the robot has to
interact with multiple people so the

02:09:11.660 --> 02:09:11.670
interact with multiple people so the
 

02:09:11.670 --> 02:09:13.190
interact with multiple people so the
robot has to learn you know interacts

02:09:13.190 --> 02:09:13.200
robot has to learn you know interacts
 

02:09:13.200 --> 02:09:15.260
robot has to learn you know interacts
with you interacts with me and we might

02:09:15.260 --> 02:09:15.270
with you interacts with me and we might
 

02:09:15.270 --> 02:09:17.120
with you interacts with me and we might
have different reward functions where it

02:09:17.120 --> 02:09:17.130
have different reward functions where it
 

02:09:17.130 --> 02:09:19.460
have different reward functions where it
has to learn what's in common what's

02:09:19.460 --> 02:09:19.470
has to learn what's in common what's
 

02:09:19.470 --> 02:09:21.650
has to learn what's in common what's
different between us with the same kind

02:09:21.650 --> 02:09:21.660
different between us with the same kind
 

02:09:21.660 --> 02:09:23.120
different between us with the same kind
of techniques be usable for that

02:09:23.120 --> 02:09:23.130
of techniques be usable for that
 

02:09:23.130 --> 02:09:25.250
of techniques be usable for that
challenge good so one thing that we've

02:09:25.250 --> 02:09:25.260
challenge good so one thing that we've
 

02:09:25.260 --> 02:09:30.040
challenge good so one thing that we've
experimented with is if the robot can

02:09:30.040 --> 02:09:30.050
experimented with is if the robot can
 

02:09:30.050 --> 02:09:33.140
experimented with is if the robot can
learn from many people when it sees a

02:09:33.140 --> 02:09:33.150
learn from many people when it sees a
 

02:09:33.150 --> 02:09:34.490
learn from many people when it sees a
new person it shouldn't start from

02:09:34.490 --> 02:09:34.500
new person it shouldn't start from
 

02:09:34.500 --> 02:09:36.920
new person it shouldn't start from
scratch right so for instance we did

02:09:36.920 --> 02:09:36.930
scratch right so for instance we did
 

02:09:36.930 --> 02:09:38.630
scratch right so for instance we did
this in the context of say driving

02:09:38.630 --> 02:09:38.640
this in the context of say driving
 

02:09:38.640 --> 02:09:40.400
this in the context of say driving
styles right so I want the car to

02:09:40.400 --> 02:09:40.410
styles right so I want the car to
 

02:09:40.410 --> 02:09:42.050
styles right so I want the car to
customize to how you want to drive how

02:09:42.050 --> 02:09:42.060
customize to how you want to drive how
 

02:09:42.060 --> 02:09:43.250
customize to how you want to drive how
they want to drive how they want to

02:09:43.250 --> 02:09:43.260
they want to drive how they want to
 

02:09:43.260 --> 02:09:45.140
they want to drive how they want to
drive and when I see the end person I

02:09:45.140 --> 02:09:45.150
drive and when I see the end person I
 

02:09:45.150 --> 02:09:46.520
drive and when I see the end person I
don't want to start they're sort of

02:09:46.520 --> 02:09:46.530
don't want to start they're sort of
 

02:09:46.530 --> 02:09:47.600
don't want to start they're sort of
learning from scratch because there's

02:09:47.600 --> 02:09:47.610
learning from scratch because there's
 

02:09:47.610 --> 02:09:49.520
learning from scratch because there's
common things that all people share and

02:09:49.520 --> 02:09:49.530
common things that all people share and
 

02:09:49.530 --> 02:09:51.530
common things that all people share and
then there's individual differences and

02:09:51.530 --> 02:09:51.540
then there's individual differences and
 

02:09:51.540 --> 02:09:53.650
then there's individual differences and
so one way I think about this is to

02:09:53.650 --> 02:09:53.660
so one way I think about this is to
 

02:09:53.660 --> 02:09:56.600
so one way I think about this is to
learn from your from all of your

02:09:56.600 --> 02:09:56.610
learn from your from all of your
 

02:09:56.610 --> 02:09:58.850
learn from your from all of your
previous users and build in a sense of

02:09:58.850 --> 02:09:58.860
previous users and build in a sense of
 

02:09:58.860 --> 02:10:01.520
previous users and build in a sense of
prior for for what you should expect

02:10:01.520 --> 02:10:01.530
prior for for what you should expect
 

02:10:01.530 --> 02:10:04.070
prior for for what you should expect
going in and then let that new person's

02:10:04.070 --> 02:10:04.080
going in and then let that new person's
 

02:10:04.080 --> 02:10:06.740
going in and then let that new person's
actions sort of and take those in as

02:10:06.740 --> 02:10:06.750
actions sort of and take those in as
 

02:10:06.750 --> 02:10:08.919
actions sort of and take those in as
evidence and turn that priority

02:10:08.919 --> 02:10:08.929
evidence and turn that priority
 

02:10:08.929 --> 02:10:11.979
evidence and turn that priority
so can thereby sort of find what's

02:10:11.979 --> 02:10:11.989
so can thereby sort of find what's
 

02:10:11.989 --> 02:10:13.689
so can thereby sort of find what's
similar among all of us while still

02:10:13.689 --> 02:10:13.699
similar among all of us while still
 

02:10:13.699 --> 02:10:15.850
similar among all of us while still
allowing for the fact that people do

02:10:15.850 --> 02:10:15.860
allowing for the fact that people do
 

02:10:15.860 --> 02:10:17.620
allowing for the fact that people do
drive differently or want the robot arm

02:10:17.620 --> 02:10:17.630
drive differently or want the robot arm
 

02:10:17.630 --> 02:10:19.419
drive differently or want the robot arm
to move differently the kind of

02:10:19.419 --> 02:10:19.429
to move differently the kind of
 

02:10:19.429 --> 02:10:21.399
to move differently the kind of
individual customization that's right

02:10:21.399 --> 02:10:21.409
individual customization that's right
 

02:10:21.409 --> 02:10:24.090
individual customization that's right
that's right but I do want to bring up a

02:10:24.090 --> 02:10:24.100
that's right but I do want to bring up a
 

02:10:24.100 --> 02:10:27.610
that's right but I do want to bring up a
related point that I struggle with which

02:10:27.610 --> 02:10:27.620
related point that I struggle with which
 

02:10:27.620 --> 02:10:32.770
related point that I struggle with which
is the car has multiple passengers which

02:10:32.770 --> 02:10:32.780
is the car has multiple passengers which
 

02:10:32.780 --> 02:10:35.380
is the car has multiple passengers which
driving style should I choose I put a

02:10:35.380 --> 02:10:35.390
driving style should I choose I put a
 

02:10:35.390 --> 02:10:37.209
driving style should I choose I put a
robot in a home and there's different

02:10:37.209 --> 02:10:37.219
robot in a home and there's different
 

02:10:37.219 --> 02:10:39.130
robot in a home and there's different
people who all have different

02:10:39.130 --> 02:10:39.140
people who all have different
 

02:10:39.140 --> 02:10:41.740
people who all have different
preferences which of them right what

02:10:41.740 --> 02:10:41.750
preferences which of them right what
 

02:10:41.750 --> 02:10:44.649
preferences which of them right what
combination I think all the tools that I

02:10:44.649 --> 02:10:44.659
combination I think all the tools that I
 

02:10:44.659 --> 02:10:46.240
combination I think all the tools that I
was talking about and all everything

02:10:46.240 --> 02:10:46.250
was talking about and all everything
 

02:10:46.250 --> 02:10:49.209
was talking about and all everything
that I've done has been very much along

02:10:49.209 --> 02:10:49.219
that I've done has been very much along
 

02:10:49.219 --> 02:10:53.560
that I've done has been very much along
the line of one one person one robot and

02:10:53.560 --> 02:10:53.570
the line of one one person one robot and
 

02:10:53.570 --> 02:10:55.660
the line of one one person one robot and
the robot is trying to learn these sort

02:10:55.660 --> 02:10:55.670
the robot is trying to learn these sort
 

02:10:55.670 --> 02:10:56.979
the robot is trying to learn these sort
of the internal objective that the

02:10:56.979 --> 02:10:56.989
of the internal objective that the
 

02:10:56.989 --> 02:10:59.020
of the internal objective that the
person wants the robot to be optimizing

02:10:59.020 --> 02:10:59.030
person wants the robot to be optimizing
 

02:10:59.030 --> 02:11:01.660
person wants the robot to be optimizing
and I don't know what to do when there's

02:11:01.660 --> 02:11:01.670
and I don't know what to do when there's
 

02:11:01.670 --> 02:11:03.010
and I don't know what to do when there's
multiple people I mean there's simple

02:11:03.010 --> 02:11:03.020
multiple people I mean there's simple
 

02:11:03.020 --> 02:11:04.270
multiple people I mean there's simple
things you could do like you could take

02:11:04.270 --> 02:11:04.280
things you could do like you could take
 

02:11:04.280 --> 02:11:06.250
things you could do like you could take
averages you could do sort of risk

02:11:06.250 --> 02:11:06.260
averages you could do sort of risk
 

02:11:06.260 --> 02:11:09.040
averages you could do sort of risk
averse you could do min max you could do

02:11:09.040 --> 02:11:09.050
averse you could do min max you could do
 

02:11:09.050 --> 02:11:12.220
averse you could do min max you could do
max min there's things like that but I

02:11:12.220 --> 02:11:12.230
max min there's things like that but I
 

02:11:12.230 --> 02:11:14.020
max min there's things like that but I
don't know what the right answer is well

02:11:14.020 --> 02:11:14.030
don't know what the right answer is well
 

02:11:14.030 --> 02:11:15.760
don't know what the right answer is well
I think in fairness to you

02:11:15.760 --> 02:11:15.770
I think in fairness to you
 

02:11:15.770 --> 02:11:17.500
I think in fairness to you
I don't think social scientists no I

02:11:17.500 --> 02:11:17.510
I don't think social scientists no I
 

02:11:17.510 --> 02:11:19.060
I don't think social scientists no I
don't think political scientists no I

02:11:19.060 --> 02:11:19.070
don't think political scientists no I
 

02:11:19.070 --> 02:11:20.830
don't think political scientists no I
mean this is sort of the ubiquity

02:11:20.830 --> 02:11:20.840
mean this is sort of the ubiquity
 

02:11:20.840 --> 02:11:22.990
mean this is sort of the ubiquity
ubiquitous problem in human experiences

02:11:22.990 --> 02:11:23.000
ubiquitous problem in human experiences
 

02:11:23.000 --> 02:11:24.250
ubiquitous problem in human experiences
what do you have when you're conflicting

02:11:24.250 --> 02:11:24.260
what do you have when you're conflicting
 

02:11:24.260 --> 02:11:26.080
what do you have when you're conflicting
values and conflicting interests I think

02:11:26.080 --> 02:11:26.090
values and conflicting interests I think
 

02:11:26.090 --> 02:11:28.030
values and conflicting interests I think
it's okay if robot assists haven't

02:11:28.030 --> 02:11:28.040
it's okay if robot assists haven't
 

02:11:28.040 --> 02:11:30.550
it's okay if robot assists haven't
solved this problem for us yet but we'll

02:11:30.550 --> 02:11:30.560
solved this problem for us yet but we'll
 

02:11:30.560 --> 02:11:33.250
solved this problem for us yet but we'll
look forward to it in a few years and I

02:11:33.250 --> 02:11:33.260
look forward to it in a few years and I
 

02:11:33.260 --> 02:11:34.419
look forward to it in a few years and I
guess speaking of a few years I'm

02:11:34.419 --> 02:11:34.429
guess speaking of a few years I'm
 

02:11:34.429 --> 02:11:35.830
guess speaking of a few years I'm
curious what do you see is sort of the

02:11:35.830 --> 02:11:35.840
curious what do you see is sort of the
 

02:11:35.840 --> 02:11:38.919
curious what do you see is sort of the
biggest opportunities for trust AI

02:11:38.919 --> 02:11:38.929
biggest opportunities for trust AI
 

02:11:38.929 --> 02:11:41.110
biggest opportunities for trust AI
robotics sort of in this space over the

02:11:41.110 --> 02:11:41.120
robotics sort of in this space over the
 

02:11:41.120 --> 02:11:43.750
robotics sort of in this space over the
next let's say five to ten years I think

02:11:43.750 --> 02:11:43.760
next let's say five to ten years I think
 

02:11:43.760 --> 02:11:46.240
next let's say five to ten years I think
I'm gonna go with basically Eli's answer

02:11:46.240 --> 02:11:46.250
I'm gonna go with basically Eli's answer
 

02:11:46.250 --> 02:11:51.390
I'm gonna go with basically Eli's answer
because I feel like as AI capability

02:11:51.390 --> 02:11:51.400
because I feel like as AI capability
 

02:11:51.400 --> 02:11:53.620
because I feel like as AI capability
advances and I'm much more pessimistic

02:11:53.620 --> 02:11:53.630
advances and I'm much more pessimistic
 

02:11:53.630 --> 02:11:56.229
advances and I'm much more pessimistic
about the degree of that advanced than

02:11:56.229 --> 02:11:56.239
about the degree of that advanced than
 

02:11:56.239 --> 02:11:57.550
about the degree of that advanced than
other people are but I think we are

02:11:57.550 --> 02:11:57.560
other people are but I think we are
 

02:11:57.560 --> 02:12:03.130
other people are but I think we are
making progress I think with that we get

02:12:03.130 --> 02:12:03.140
making progress I think with that we get
 

02:12:03.140 --> 02:12:05.200
making progress I think with that we get
this opportunity to help people be

02:12:05.200 --> 02:12:05.210
this opportunity to help people be
 

02:12:05.210 --> 02:12:07.930
this opportunity to help people be
better at the things that they do so you

02:12:07.930 --> 02:12:07.940
better at the things that they do so you
 

02:12:07.940 --> 02:12:09.850
better at the things that they do so you
know kind of talking about what we were

02:12:09.850 --> 02:12:09.860
know kind of talking about what we were
 

02:12:09.860 --> 02:12:11.229
know kind of talking about what we were
saying earlier where people tend to be

02:12:11.229 --> 02:12:11.239
saying earlier where people tend to be
 

02:12:11.239 --> 02:12:13.479
saying earlier where people tend to be
myopic well one thing that we found is

02:12:13.479 --> 02:12:13.489
myopic well one thing that we found is
 

02:12:13.489 --> 02:12:16.270
myopic well one thing that we found is
that it when the robot is on the same

02:12:16.270 --> 02:12:16.280
that it when the robot is on the same
 

02:12:16.280 --> 02:12:18.580
that it when the robot is on the same
team with you and you're trying to do it

02:12:18.580 --> 02:12:18.590
team with you and you're trying to do it
 

02:12:18.590 --> 02:12:22.240
team with you and you're trying to do it
together if the robot acknowledges that

02:12:22.240 --> 02:12:22.250
together if the robot acknowledges that
 

02:12:22.250 --> 02:12:24.370
together if the robot acknowledges that
you maybe don't tend to think ten steps

02:12:24.370 --> 02:12:24.380
you maybe don't tend to think ten steps
 

02:12:24.380 --> 02:12:27.520
you maybe don't tend to think ten steps
ahead it can sort of organize the world

02:12:27.520 --> 02:12:27.530
ahead it can sort of organize the world
 

02:12:27.530 --> 02:12:29.620
ahead it can sort of organize the world
and take actions in such a way that when

02:12:29.620 --> 02:12:29.630
and take actions in such a way that when
 

02:12:29.630 --> 02:12:32.970
and take actions in such a way that when
you then react to those actions that

02:12:32.970 --> 02:12:32.980
you then react to those actions that
 

02:12:32.980 --> 02:12:37.090
you then react to those actions that
reaction is good globally as well simple

02:12:37.090 --> 02:12:37.100
reaction is good globally as well simple
 

02:12:37.100 --> 02:12:38.020
reaction is good globally as well simple
example because I think what I'm saying

02:12:38.020 --> 02:12:38.030
example because I think what I'm saying
 

02:12:38.030 --> 02:12:40.510
example because I think what I'm saying
is very abstract it can be as simple as

02:12:40.510 --> 02:12:40.520
is very abstract it can be as simple as
 

02:12:40.520 --> 02:12:44.230
is very abstract it can be as simple as
when I give when the robot gives you an

02:12:44.230 --> 02:12:44.240
when I give when the robot gives you an
 

02:12:44.240 --> 02:12:47.500
when I give when the robot gives you an
object okay take it okay you take it in

02:12:47.500 --> 02:12:47.510
object okay take it okay you take it in
 

02:12:47.510 --> 02:12:49.840
object okay take it okay you take it in
the most comfortable way for you now

02:12:49.840 --> 02:12:49.850
the most comfortable way for you now
 

02:12:49.850 --> 02:12:51.730
the most comfortable way for you now
imagine you had an actual goal like you

02:12:51.730 --> 02:12:51.740
imagine you had an actual goal like you
 

02:12:51.740 --> 02:12:53.350
imagine you had an actual goal like you
have to put in a dishwasher or something

02:12:53.350 --> 02:12:53.360
have to put in a dishwasher or something
 

02:12:53.360 --> 02:12:56.410
have to put in a dishwasher or something
right we don't tend to necessarily think

02:12:56.410 --> 02:12:56.420
right we don't tend to necessarily think
 

02:12:56.420 --> 02:12:58.210
right we don't tend to necessarily think
ahead to the goal

02:12:58.210 --> 02:12:58.220
ahead to the goal
 

02:12:58.220 --> 02:13:00.760
ahead to the goal
we just we do the thing right not always

02:13:00.760 --> 02:13:00.770
we just we do the thing right not always
 

02:13:00.770 --> 02:13:02.470
we just we do the thing right not always
and not for everyone but especially if

02:13:02.470 --> 02:13:02.480
and not for everyone but especially if
 

02:13:02.480 --> 02:13:04.270
and not for everyone but especially if
we're wrapped up with other things and

02:13:04.270 --> 02:13:04.280
we're wrapped up with other things and
 

02:13:04.280 --> 02:13:06.370
we're wrapped up with other things and
one thing that the robot could do is can

02:13:06.370 --> 02:13:06.380
one thing that the robot could do is can
 

02:13:06.380 --> 02:13:08.470
one thing that the robot could do is can
be reasoning about that and then he and

02:13:08.470 --> 02:13:08.480
be reasoning about that and then he and
 

02:13:08.480 --> 02:13:11.080
be reasoning about that and then he and
you the thing sort of in a way where it

02:13:11.080 --> 02:13:11.090
you the thing sort of in a way where it
 

02:13:11.090 --> 02:13:14.200
you the thing sort of in a way where it
makes sure that the way you then grab it

02:13:14.200 --> 02:13:14.210
makes sure that the way you then grab it
 

02:13:14.210 --> 02:13:16.390
makes sure that the way you then grab it
is then conducive to your goal so use

02:13:16.390 --> 02:13:16.400
is then conducive to your goal so use
 

02:13:16.400 --> 02:13:18.010
is then conducive to your goal so use
things you still react myopically but

02:13:18.010 --> 02:13:18.020
things you still react myopically but
 

02:13:18.020 --> 02:13:19.510
things you still react myopically but
the robot is setting things up such that

02:13:19.510 --> 02:13:19.520
the robot is setting things up such that
 

02:13:19.520 --> 02:13:21.810
the robot is setting things up such that
you're actually better at the task

02:13:21.810 --> 02:13:21.820
you're actually better at the task
 

02:13:21.820 --> 02:13:24.700
you're actually better at the task
because of its actions or another thing

02:13:24.700 --> 02:13:24.710
because of its actions or another thing
 

02:13:24.710 --> 02:13:28.060
because of its actions or another thing
is going back to explain ability it'd be

02:13:28.060 --> 02:13:28.070
is going back to explain ability it'd be
 

02:13:28.070 --> 02:13:30.510
is going back to explain ability it'd be
nice and I think people are doing that

02:13:30.510 --> 02:13:30.520
nice and I think people are doing that
 

02:13:30.520 --> 02:13:33.280
nice and I think people are doing that
because robots are getting better and

02:13:33.280 --> 02:13:33.290
because robots are getting better and
 

02:13:33.290 --> 02:13:34.870
because robots are getting better and
better things like go and so on and

02:13:34.870 --> 02:13:34.880
better things like go and so on and
 

02:13:34.880 --> 02:13:37.510
better things like go and so on and
whatever other tasks better than human

02:13:37.510 --> 02:13:37.520
whatever other tasks better than human
 

02:13:37.520 --> 02:13:40.390
whatever other tasks better than human
capability it'd be nice if that made us

02:13:40.390 --> 02:13:40.400
capability it'd be nice if that made us
 

02:13:40.400 --> 02:13:42.970
capability it'd be nice if that made us
better as well so robot could kind of

02:13:42.970 --> 02:13:42.980
better as well so robot could kind of
 

02:13:42.980 --> 02:13:45.040
better as well so robot could kind of
help you make these decisions and say if

02:13:45.040 --> 02:13:45.050
help you make these decisions and say if
 

02:13:45.050 --> 02:13:47.230
help you make these decisions and say if
you do this just be careful that you

02:13:47.230 --> 02:13:47.240
you do this just be careful that you
 

02:13:47.240 --> 02:13:49.270
you do this just be careful that you
know 10 moves from now you might end up

02:13:49.270 --> 02:13:49.280
know 10 moves from now you might end up
 

02:13:49.280 --> 02:13:51.370
know 10 moves from now you might end up
here and here's why and then the person

02:13:51.370 --> 02:13:51.380
here and here's why and then the person
 

02:13:51.380 --> 02:13:52.120
here and here's why and then the person
can learn from that

02:13:52.120 --> 02:13:52.130
can learn from that
 

02:13:52.130 --> 02:13:55.390
can learn from that
and get better and so so just to

02:13:55.390 --> 02:13:55.400
and get better and so so just to
 

02:13:55.400 --> 02:13:57.690
and get better and so so just to
conclude the more speculative question

02:13:57.690 --> 02:13:57.700
conclude the more speculative question
 

02:13:57.700 --> 02:14:01.240
conclude the more speculative question
so in say 10 years when we're on I guess

02:14:01.240 --> 02:14:01.250
so in say 10 years when we're on I guess
 

02:14:01.250 --> 02:14:04.330
so in say 10 years when we're on I guess
that would be the sixth CMU K&amp;L gates

02:14:04.330 --> 02:14:04.340
that would be the sixth CMU K&amp;L gates
 

02:14:04.340 --> 02:14:06.970
that would be the sixth CMU K&amp;L gates
conference how is it going to be

02:14:06.970 --> 02:14:06.980
conference how is it going to be
 

02:14:06.980 --> 02:14:08.470
conference how is it going to be
different how do you think things are

02:14:08.470 --> 02:14:08.480
different how do you think things are
 

02:14:08.480 --> 02:14:10.930
different how do you think things are
going to have changed either socially or

02:14:10.930 --> 02:14:10.940
going to have changed either socially or
 

02:14:10.940 --> 02:14:15.150
going to have changed either socially or
in this that we're talking about here I

02:14:15.150 --> 02:14:15.160
in this that we're talking about here I
 

02:14:15.160 --> 02:14:19.510
in this that we're talking about here I
guess my prediction would be that we're

02:14:19.510 --> 02:14:19.520
guess my prediction would be that we're
 

02:14:19.520 --> 02:14:23.410
guess my prediction would be that we're
gonna start talking even more about what

02:14:23.410 --> 02:14:23.420
gonna start talking even more about what
 

02:14:23.420 --> 02:14:25.810
gonna start talking even more about what
I might call model Mis specification so

02:14:25.810 --> 02:14:25.820
I might call model Mis specification so
 

02:14:25.820 --> 02:14:27.550
I might call model Mis specification so
that's one thing that I kind of foresee

02:14:27.550 --> 02:14:27.560
that's one thing that I kind of foresee
 

02:14:27.560 --> 02:14:29.710
that's one thing that I kind of foresee
being very worried about because so what

02:14:29.710 --> 02:14:29.720
being very worried about because so what
 

02:14:29.720 --> 02:14:30.640
being very worried about because so what
do you mean right

02:14:30.640 --> 02:14:30.650
do you mean right
 

02:14:30.650 --> 02:14:34.870
do you mean right
so we talked a lot about trying to

02:14:34.870 --> 02:14:34.880
so we talked a lot about trying to
 

02:14:34.880 --> 02:14:37.150
so we talked a lot about trying to
figure out what people want and I'm

02:14:37.150 --> 02:14:37.160
figure out what people want and I'm
 

02:14:37.160 --> 02:14:39.880
figure out what people want and I'm
worried that oftentimes the space that

02:14:39.880 --> 02:14:39.890
worried that oftentimes the space that
 

02:14:39.890 --> 02:14:41.740
worried that oftentimes the space that
we're we're always looking at a kind of

02:14:41.740 --> 02:14:41.750
we're we're always looking at a kind of
 

02:14:41.750 --> 02:14:43.330
we're we're always looking at a kind of
a closed world assumption here are the

02:14:43.330 --> 02:14:43.340
a closed world assumption here are the
 

02:14:43.340 --> 02:14:45.130
a closed world assumption here are the
possible things even if they're defined

02:14:45.130 --> 02:14:45.140
possible things even if they're defined
 

02:14:45.140 --> 02:14:47.170
possible things even if they're defined
on sort of raw information you're the

02:14:47.170 --> 02:14:47.180
on sort of raw information you're the
 

02:14:47.180 --> 02:14:49.090
on sort of raw information you're the
possible things that a person could want

02:14:49.090 --> 02:14:49.100
possible things that a person could want
 

02:14:49.100 --> 02:14:50.980
possible things that a person could want
and I just worried that we don't have

02:14:50.980 --> 02:14:50.990
and I just worried that we don't have
 

02:14:50.990 --> 02:14:53.560
and I just worried that we don't have
even observations about things that

02:14:53.560 --> 02:14:53.570
even observations about things that
 

02:14:53.570 --> 02:14:55.210
even observations about things that
people care about that influence what

02:14:55.210 --> 02:14:55.220
people care about that influence what
 

02:14:55.220 --> 02:14:58.240
people care about that influence what
they want and so kind of model Mis

02:14:58.240 --> 02:14:58.250
they want and so kind of model Mis
 

02:14:58.250 --> 02:14:59.800
they want and so kind of model Mis
specification drawing these inferences

02:14:59.800 --> 02:14:59.810
specification drawing these inferences
 

02:14:59.810 --> 02:15:02.830
specification drawing these inferences
over a closed world when we just we in

02:15:02.830 --> 02:15:02.840
over a closed world when we just we in
 

02:15:02.840 --> 02:15:05.710
over a closed world when we just we in
fact have no way of knowing basically

02:15:05.710 --> 02:15:05.720
fact have no way of knowing basically
 

02:15:05.720 --> 02:15:08.440
fact have no way of knowing basically
leads to lead can lead to issues another

02:15:08.440 --> 02:15:08.450
leads to lead can lead to issues another
 

02:15:08.450 --> 02:15:09.670
leads to lead can lead to issues another
thing they can lead to issue is just

02:15:09.670 --> 02:15:09.680
thing they can lead to issue is just
 

02:15:09.680 --> 02:15:12.340
thing they can lead to issue is just
inherent ambiguity where I really can't

02:15:12.340 --> 02:15:12.350
inherent ambiguity where I really can't
 

02:15:12.350 --> 02:15:13.960
inherent ambiguity where I really can't
figure out based on what you're doing or

02:15:13.960 --> 02:15:13.970
figure out based on what you're doing or
 

02:15:13.970 --> 02:15:15.970
figure out based on what you're doing or
what you're saying if you want this or

02:15:15.970 --> 02:15:15.980
what you're saying if you want this or
 

02:15:15.980 --> 02:15:18.340
what you're saying if you want this or
better that so then I'm sort of I need

02:15:18.340 --> 02:15:18.350
better that so then I'm sort of I need
 

02:15:18.350 --> 02:15:20.290
better that so then I'm sort of I need
to be risking risk-averse or

02:15:20.290 --> 02:15:20.300
to be risking risk-averse or
 

02:15:20.300 --> 02:15:21.790
to be risking risk-averse or
conservative but that's the best I can

02:15:21.790 --> 02:15:21.800
conservative but that's the best I can
 

02:15:21.800 --> 02:15:23.890
conservative but that's the best I can
do the other thing that I think will

02:15:23.890 --> 02:15:23.900
do the other thing that I think will
 

02:15:23.900 --> 02:15:26.770
do the other thing that I think will
change is is maybe the hype for AI will

02:15:26.770 --> 02:15:26.780
change is is maybe the hype for AI will
 

02:15:26.780 --> 02:15:29.890
change is is maybe the hype for AI will
die down and we'll get welcome to focus

02:15:29.890 --> 02:15:29.900
die down and we'll get welcome to focus
 

02:15:29.900 --> 02:15:33.280
die down and we'll get welcome to focus
much more on these very kind of I don't

02:15:33.280 --> 02:15:33.290
much more on these very kind of I don't
 

02:15:33.290 --> 02:15:36.190
much more on these very kind of I don't
know near-term very practical ethical

02:15:36.190 --> 02:15:36.200
know near-term very practical ethical
 

02:15:36.200 --> 02:15:39.730
know near-term very practical ethical
issues and I think this particular

02:15:39.730 --> 02:15:39.740
issues and I think this particular
 

02:15:39.740 --> 02:15:41.170
issues and I think this particular
conference is a really good job with

02:15:41.170 --> 02:15:41.180
conference is a really good job with
 

02:15:41.180 --> 02:15:43.030
conference is a really good job with
that but I've been at kind of other

02:15:43.030 --> 02:15:43.040
that but I've been at kind of other
 

02:15:43.040 --> 02:15:45.490
that but I've been at kind of other
types of events where it's you know it's

02:15:45.490 --> 02:15:45.500
types of events where it's you know it's
 

02:15:45.500 --> 02:15:47.140
types of events where it's you know it's
sort of very far out that everyone's

02:15:47.140 --> 02:15:47.150
sort of very far out that everyone's
 

02:15:47.150 --> 02:15:49.300
sort of very far out that everyone's
worried that in 10 years artificial

02:15:49.300 --> 02:15:49.310
worried that in 10 years artificial
 

02:15:49.310 --> 02:15:51.220
worried that in 10 years artificial
general intelligence will happen and I

02:15:51.220 --> 02:15:51.230
general intelligence will happen and I
 

02:15:51.230 --> 02:15:54.460
general intelligence will happen and I
think my prediction is that you know it

02:15:54.460 --> 02:15:54.470
think my prediction is that you know it
 

02:15:54.470 --> 02:15:57.610
think my prediction is that you know it
won't and then the hype will be a little

02:15:57.610 --> 02:15:57.620
won't and then the hype will be a little
 

02:15:57.620 --> 02:15:59.230
won't and then the hype will be a little
more reduced then we'll be able to talk

02:15:59.230 --> 02:15:59.240
more reduced then we'll be able to talk
 

02:15:59.240 --> 02:16:01.240
more reduced then we'll be able to talk
about real kind of what yellow is saying

02:16:01.240 --> 02:16:01.250
about real kind of what yellow is saying
 

02:16:01.250 --> 02:16:03.760
about real kind of what yellow is saying
you know real kind of narrow AI that

02:16:03.760 --> 02:16:03.770
you know real kind of narrow AI that
 

02:16:03.770 --> 02:16:06.070
you know real kind of narrow AI that
does something really useful which can

02:16:06.070 --> 02:16:06.080
does something really useful which can
 

02:16:06.080 --> 02:16:08.230
does something really useful which can
both empower and and cause challenges

02:16:08.230 --> 02:16:08.240
both empower and and cause challenges
 

02:16:08.240 --> 02:16:10.060
both empower and and cause challenges
for people that's right well thank you

02:16:10.060 --> 02:16:10.070
for people that's right well thank you
 

02:16:10.070 --> 02:16:13.610
for people that's right well thank you
so much this is really wonderful

02:16:13.610 --> 02:16:13.620
 

02:16:13.620 --> 02:16:17.450
and this this concludes our session on

02:16:17.450 --> 02:16:17.460
and this this concludes our session on
 

02:16:17.460 --> 02:16:20.180
and this this concludes our session on
trust I invite you all to stay and have

02:16:20.180 --> 02:16:20.190
trust I invite you all to stay and have
 

02:16:20.190 --> 02:16:21.890
trust I invite you all to stay and have
lunch in the back room please feel free

02:16:21.890 --> 02:16:21.900
lunch in the back room please feel free
 

02:16:21.900 --> 02:16:23.420
lunch in the back room please feel free
to come back up to these tables is

02:16:23.420 --> 02:16:23.430
to come back up to these tables is
 

02:16:23.430 --> 02:16:25.310
to come back up to these tables is
perfectly fine to have food and beverage

02:16:25.310 --> 02:16:25.320
perfectly fine to have food and beverage
 

02:16:25.320 --> 02:16:27.380
perfectly fine to have food and beverage
here and we will be starting back up at

02:16:27.380 --> 02:16:27.390
here and we will be starting back up at
 

02:16:27.390 --> 02:16:29.630
here and we will be starting back up at
noon with our session on policy and

02:16:29.630 --> 02:16:29.640
noon with our session on policy and
 

02:16:29.640 --> 02:16:32.369
noon with our session on policy and
governance thanks

02:16:32.369 --> 02:16:32.379
governance thanks
 

02:16:32.379 --> 02:17:09.780
governance thanks
[Music]

02:17:09.780 --> 02:17:09.790
 

02:17:09.790 --> 02:17:11.849
you

