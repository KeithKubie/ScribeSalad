WEBVTT
Kind: captions
Language: en

00:00:05.240 --> 00:00:06.990
MAYA BEN ARI: Hello,
everyone, and welcome

00:00:06.990 --> 00:00:11.680
to Behind the Scenes-- What's
New in Android Accessibility.

00:00:11.680 --> 00:00:13.500
My name is Maya Ben Ari.

00:00:13.500 --> 00:00:16.450
I'm a product manager on
Android accessibility.

00:00:16.450 --> 00:00:18.450
And with me today are
a couple of people

00:00:18.450 --> 00:00:20.890
from the accessibility team.

00:00:20.890 --> 00:00:23.380
We're going to show you
a couple of new features,

00:00:23.380 --> 00:00:27.650
a couple of new demos,
and a unique look

00:00:27.650 --> 00:00:29.120
of behind the scene.

00:00:29.120 --> 00:00:31.080
So this is our agenda for today.

00:00:31.080 --> 00:00:34.240
We'll give a brief overview
about accessibility.

00:00:34.240 --> 00:00:39.230
We'll talk about what's new
in accessibility in Android N.

00:00:39.230 --> 00:00:43.120
We'll talk about the
Gesture Dispatch API

00:00:43.120 --> 00:00:46.570
and show a couple
of very cool demos.

00:00:46.570 --> 00:00:52.450
Also, we'll look through Voice
Access, a new accessibility

00:00:52.450 --> 00:00:52.950
service.

00:00:52.950 --> 00:00:57.460
And then we'll give a brief
look at behind the scene

00:00:57.460 --> 00:01:00.730
in UX research.

00:01:00.730 --> 00:01:03.250
So let's start.

00:01:03.250 --> 00:01:05.810
What is accessibility?

00:01:05.810 --> 00:01:09.680
Accessibility is about
creating products

00:01:09.680 --> 00:01:12.980
that are usable by
everyone, including people

00:01:12.980 --> 00:01:16.490
with disabilities, such
as motor impairment

00:01:16.490 --> 00:01:18.280
or visual impairment.

00:01:18.280 --> 00:01:20.020
But I'd like to
rephrase this definition

00:01:20.020 --> 00:01:22.920
as slightly different.

00:01:22.920 --> 00:01:24.800
And I would say
that accessibility

00:01:24.800 --> 00:01:27.540
is about challenging
the assumptions we

00:01:27.540 --> 00:01:30.210
make about our users.

00:01:30.210 --> 00:01:33.380
For example, can the
user see the device

00:01:33.380 --> 00:01:35.920
or distinguish between colors?

00:01:35.920 --> 00:01:39.130
Can he or she touch the
device or hear back the sound

00:01:39.130 --> 00:01:40.680
that the device is producing?

00:01:40.680 --> 00:01:45.010
And can the user speak
back to the device?

00:01:45.010 --> 00:01:47.950
Now, this is not a small number.

00:01:47.950 --> 00:01:52.320
20% of the US population will
have some sort of a disability

00:01:52.320 --> 00:01:56.960
during their lifetime,
according to the US Census.

00:01:56.960 --> 00:01:59.130
But it's not only that.

00:01:59.130 --> 00:02:04.710
Challenging the assumption
can benefit all the users.

00:02:04.710 --> 00:02:05.429
Why?

00:02:05.429 --> 00:02:06.970
Because some of the
technologies that

00:02:06.970 --> 00:02:11.630
were developed in the past, such
as speech recognition or word

00:02:11.630 --> 00:02:14.630
prediction, started as
technologies for users

00:02:14.630 --> 00:02:17.120
with accessibility needs.

00:02:17.120 --> 00:02:19.370
But this is not all.

00:02:19.370 --> 00:02:24.550
We are all the accessibility
users sometime.

00:02:24.550 --> 00:02:27.860
This is called
situational disability.

00:02:27.860 --> 00:02:32.260
When we drive our car, we
cannot look at our phone.

00:02:32.260 --> 00:02:34.460
When we are in a
noisy environment,

00:02:34.460 --> 00:02:36.400
we cannot hear the
sound of the device,

00:02:36.400 --> 00:02:38.790
and we cannot speak
back to the device.

00:02:38.790 --> 00:02:42.180
And when we carry heavy
bags from the supermarket,

00:02:42.180 --> 00:02:44.370
we cannot touch the device.

00:02:44.370 --> 00:02:47.600
So we want to design
an inclusive experience

00:02:47.600 --> 00:02:53.190
for all users, regardless
of what restriction the user

00:02:53.190 --> 00:02:54.495
might have.

00:02:57.030 --> 00:03:00.780
Now, let me briefly mention
some accessibility services

00:03:00.780 --> 00:03:04.630
and features available
on the platform today.

00:03:04.630 --> 00:03:08.610
So first, what is an
accessibility service?

00:03:08.610 --> 00:03:11.760
This is a long-running
privilege service

00:03:11.760 --> 00:03:15.280
that changes the interaction
model with a device in one

00:03:15.280 --> 00:03:17.130
of two ways.

00:03:17.130 --> 00:03:21.610
One, it can change the way the
user interacts with a device,

00:03:21.610 --> 00:03:23.950
or it can change
the way that content

00:03:23.950 --> 00:03:26.910
is presented to the user.

00:03:26.910 --> 00:03:28.720
Now, the first
accessibility service

00:03:28.720 --> 00:03:32.270
we have on the device
today is TalkBack.

00:03:32.270 --> 00:03:36.720
TalkBack is targeted for
people with vision impairment,

00:03:36.720 --> 00:03:37.930
or blind.

00:03:37.930 --> 00:03:40.530
And it's basically
a screen reader.

00:03:40.530 --> 00:03:44.490
Now, the user can interact with
the device using touch gesture,

00:03:44.490 --> 00:03:49.140
and content is presented,
spoken to the user

00:03:49.140 --> 00:03:52.160
through text-to-speech.

00:03:52.160 --> 00:03:55.930
The second accessibility
service is BrailleBack.

00:03:55.930 --> 00:04:00.300
So can we switch to the demo?

00:04:00.300 --> 00:04:03.850
So BrailleBack is similar to
TalkBack, just in this case,

00:04:03.850 --> 00:04:05.950
the user can interrupt
with something

00:04:05.950 --> 00:04:09.080
which is called a
Braille-refreshable display.

00:04:09.080 --> 00:04:13.490
The user can type
through these keys,

00:04:13.490 --> 00:04:16.550
or interrupt with this joystick.

00:04:16.550 --> 00:04:19.200
And then the
content is presented

00:04:19.200 --> 00:04:22.019
using Braille in
those Braille cells,

00:04:22.019 --> 00:04:26.280
with the dots
raising and lowering.

00:04:26.280 --> 00:04:30.140
The next service
is Switch Access.

00:04:30.140 --> 00:04:33.360
Switch Access is targeted
for a motor-impaired user

00:04:33.360 --> 00:04:37.240
who has trouble interacting
with a touch display.

00:04:37.240 --> 00:04:39.530
In this case, we
have something which

00:04:39.530 --> 00:04:41.860
is called adaptive switch.

00:04:41.860 --> 00:04:44.330
This adaptive switch
has two buttons.

00:04:44.330 --> 00:04:48.110
And the user can configure
one button as Next,

00:04:48.110 --> 00:04:50.110
and one button as Select.

00:04:50.110 --> 00:04:52.810
And using only
these two buttons,

00:04:52.810 --> 00:04:54.550
the user can interact
with the device.

00:04:54.550 --> 00:04:59.710
Note that the switch can be
with more or less the buttons.

00:04:59.710 --> 00:05:03.160
Can we switch back
to the slides?

00:05:03.160 --> 00:05:06.485
And the last accessibility
service is Voice Access.

00:05:06.485 --> 00:05:12.160
In Voice Access, the user can
preform low-level interaction

00:05:12.160 --> 00:05:15.680
on the device using
only his voice.

00:05:15.680 --> 00:05:18.590
This is a new service that
we originally launched.

00:05:18.590 --> 00:05:22.650
And Patrick and Scott, from
the accessibility group,

00:05:22.650 --> 00:05:25.640
will soon tell us
more about this one.

00:05:30.930 --> 00:05:34.090
We also have a couple of
accessibility features

00:05:34.090 --> 00:05:36.010
already baked into
the platform--

00:05:36.010 --> 00:05:40.170
for example, large text,
magnification gestures,

00:05:40.170 --> 00:05:43.130
coloring version or color
correction for people

00:05:43.130 --> 00:05:46.600
with light sensitivity
or who are colorblind,

00:05:46.600 --> 00:05:49.106
high-contrast text,
and caption support.

00:05:53.900 --> 00:05:55.880
In the next section,
we're going to dive

00:05:55.880 --> 00:05:58.850
into the latest and
greatest feature

00:05:58.850 --> 00:06:01.080
for accessibility in Android.

00:06:01.080 --> 00:06:04.050
And we have a lot of
very exciting things

00:06:04.050 --> 00:06:04.940
to share with you.

00:06:07.480 --> 00:06:11.950
The first one is vision
setting on the Welcome screen.

00:06:11.950 --> 00:06:14.620
This will enable
visually impaired users

00:06:14.620 --> 00:06:18.670
to independently
set up their device.

00:06:18.670 --> 00:06:23.260
Now can we switch
please to the demo?

00:06:27.790 --> 00:06:29.180
Focus.

00:06:29.180 --> 00:06:29.950
OK.

00:06:29.950 --> 00:06:32.850
So this is the main screen,
the Welcome screen on Android.

00:06:32.850 --> 00:06:35.540
And here at the bottom,
we have vision settings

00:06:35.540 --> 00:06:38.295
that flash every 10 seconds.

00:06:42.530 --> 00:06:44.770
4, 3, here you go.

00:06:44.770 --> 00:06:50.050
So if I tap on that, I am
presented a couple of options.

00:06:50.050 --> 00:06:54.330
I have magnification gesture,
phone size, display size,

00:06:54.330 --> 00:06:55.190
TalkBack.

00:06:55.190 --> 00:06:58.490
So for example, I can select
magnification gestures,

00:06:58.490 --> 00:07:05.290
and then I can triple-tap,
and I can increase the size

00:07:05.290 --> 00:07:07.810
and magnify the UI.

00:07:07.810 --> 00:07:12.060
Now, another option that I want
to highlight is display size.

00:07:12.060 --> 00:07:15.750
This is a new feature
launched in Android N.

00:07:15.750 --> 00:07:18.950
So if this is the
regular screen size,

00:07:18.950 --> 00:07:25.860
I can increase the size of
the overall UI to be bigger.

00:07:25.860 --> 00:07:27.990
Now, the nice thing
about all those settings

00:07:27.990 --> 00:07:30.310
is that whatever
settings I'm selecting,

00:07:30.310 --> 00:07:34.990
it's going to be reflected both
through all the Welcome screen,

00:07:34.990 --> 00:07:38.250
but also as the user setting
throughout the device.

00:07:41.250 --> 00:07:42.120
Back to the slides.

00:07:47.270 --> 00:07:50.090
Another cool feature
is mono audio support.

00:07:50.090 --> 00:07:52.550
This one is intended
for people who

00:07:52.550 --> 00:07:56.170
have hearing loss in one ear.

00:07:56.170 --> 00:08:00.870
And this enables them to
listen to mono audio stream.

00:08:00.870 --> 00:08:04.390
And we do that by combining
the left and right channels

00:08:04.390 --> 00:08:09.120
into a single mono audio stream.

00:08:09.120 --> 00:08:12.080
And we also have a couple
of new features in TalkBack,

00:08:12.080 --> 00:08:16.090
including improved tutorial
clarity, improved gesture

00:08:16.090 --> 00:08:19.710
detection to work better across
different devices and hardware.

00:08:19.710 --> 00:08:23.840
And also, we added a new API
for accessibility service

00:08:23.840 --> 00:08:26.320
to turn themselves off.

00:08:26.320 --> 00:08:30.320
So if the user accidentally
turns on TalkBack

00:08:30.320 --> 00:08:35.990
on the Welcome screen, they
can easily turn it off.

00:08:35.990 --> 00:08:39.419
Now, the next section is about
the gesture dispatch API.

00:08:39.419 --> 00:08:43.480
And this is something that I'm
personally very excited about,

00:08:43.480 --> 00:08:47.900
because now we will allow app
developers to build services

00:08:47.900 --> 00:08:53.450
such as point scanning, face
tracker, and eye tracker.

00:08:53.450 --> 00:08:55.870
So for the next one,
I'd like to invite

00:08:55.870 --> 00:08:58.640
Anna, an engineer on
the accessibility team,

00:08:58.640 --> 00:09:00.435
to demo the APIs.

00:09:03.215 --> 00:09:04.706
[APPLAUSE]

00:09:09.680 --> 00:09:11.250
ANNA GALUSZA: Thanks, Maya.

00:09:11.250 --> 00:09:13.666
I'm Anna, and I'll tell you
about the new gesture dispatch

00:09:13.666 --> 00:09:15.850
API that lets accessibility
services mimic

00:09:15.850 --> 00:09:17.210
touching the screen.

00:09:17.210 --> 00:09:19.150
First of all, what's a touch?

00:09:19.150 --> 00:09:22.970
Well, it has three parts--
placing a finger on the screen,

00:09:22.970 --> 00:09:26.100
drawing a path or gesture,
and lifting the finger.

00:09:26.100 --> 00:09:28.780
The new API lets you,
as the developer,

00:09:28.780 --> 00:09:31.890
specify that middle
portion, the path taken

00:09:31.890 --> 00:09:34.710
by an imaginary
finger or fingers.

00:09:34.710 --> 00:09:37.590
Now, why is this important
for accessibility?

00:09:37.590 --> 00:09:39.550
Let's take a look
at Switch Access,

00:09:39.550 --> 00:09:42.220
an accessibility service
that does not assume

00:09:42.220 --> 00:09:44.130
that you can touch the screen.

00:09:44.130 --> 00:09:47.770
Rather, it lets you use a
switch or a set of switches

00:09:47.770 --> 00:09:50.450
to move-highlight
across actionable views

00:09:50.450 --> 00:09:53.450
and select the currently
highlighted view.

00:09:53.450 --> 00:09:56.120
Now, this leaves off
some functionality

00:09:56.120 --> 00:09:58.800
when you don't want to
interact with the entire view,

00:09:58.800 --> 00:10:01.850
but rather a small part of it.

00:10:01.850 --> 00:10:05.690
The example that I'll be using
is Google Maps, specifically

00:10:05.690 --> 00:10:09.070
the maps area, which
supports complex gestures--

00:10:09.070 --> 00:10:13.180
things like zooming in and out
and padding the visible area.

00:10:13.180 --> 00:10:16.260
So with this new
gesture dispatch API,

00:10:16.260 --> 00:10:18.800
we can add point scanning
to Switch Access,

00:10:18.800 --> 00:10:21.610
and that lets us perform
these complex gestures.

00:10:21.610 --> 00:10:26.720
So let's take a look at how we
can use one switch to operate

00:10:26.720 --> 00:10:27.360
Google Maps.

00:10:38.050 --> 00:10:39.537
We'll start in the Maps app.

00:10:39.537 --> 00:10:41.870
And you'll notice here I have
a switch already connected

00:10:41.870 --> 00:10:43.640
to my device.

00:10:43.640 --> 00:10:45.780
I like to get walking
directions to the three

00:10:45.780 --> 00:10:47.869
buildings just west of here.

00:10:47.869 --> 00:10:49.660
I don't quite remember
what they're called.

00:10:49.660 --> 00:10:52.730
But fortunately, once we
make a selection on the map,

00:10:52.730 --> 00:10:55.440
we can get directions that way.

00:10:55.440 --> 00:10:57.960
So here it seems like
I don't see those three

00:10:57.960 --> 00:11:02.220
buildings on the map, so I'll
have to pan to get to see them.

00:11:02.220 --> 00:11:05.130
I'll start point scanning
by pressing the switch.

00:11:05.130 --> 00:11:07.790
And the first thing
I'll do now is select

00:11:07.790 --> 00:11:10.850
where I want to
perform that gesture.

00:11:10.850 --> 00:11:13.880
First the y-coordinate,
then the x-coordinate.

00:11:13.880 --> 00:11:15.850
And here I'll choose
to swipe right.

00:11:21.650 --> 00:11:24.220
So now at the lower left,
we see the three buildings

00:11:24.220 --> 00:11:25.700
that I'd like to walk to.

00:11:25.700 --> 00:11:28.670
I'm going to place a pin
there by long-pressing.

00:11:28.670 --> 00:11:32.900
So again, I'll start by choosing
the location first, starting

00:11:32.900 --> 00:11:39.660
with the y-coordinate again,
and then the x-coordinate.

00:11:39.660 --> 00:11:42.190
And here I'll choose long-press
from the Actions menu.

00:11:46.950 --> 00:11:48.457
This gives me a
button at the bottom

00:11:48.457 --> 00:11:51.110
of the screen asking whether
I'd like walking directions.

00:11:51.110 --> 00:11:53.480
As that's exactly
what I'll want,

00:11:53.480 --> 00:11:55.560
I'm going to select that button.

00:11:55.560 --> 00:11:57.545
So again, I'll choose
the location first.

00:12:07.359 --> 00:12:08.525
And here I'll choose Select.

00:12:13.050 --> 00:12:15.140
And here we are--
directions to the point

00:12:15.140 --> 00:12:17.325
we just chose from the
map using just one switch.

00:12:17.325 --> 00:12:19.029
I'll hand the mike
back to Maya now,

00:12:19.029 --> 00:12:21.320
who will tell you about
another really cool application

00:12:21.320 --> 00:12:23.020
of the gesture dispatch API.

00:12:23.020 --> 00:12:24.466
[APPLAUSE]

00:12:31.710 --> 00:12:34.090
MAYA BEN ARI: Thank
you, Anna, for the demo.

00:12:34.090 --> 00:12:37.730
And the next demo is an
extremely exciting one

00:12:37.730 --> 00:12:41.570
for a head tracker, using
the dispatch gesture API,

00:12:41.570 --> 00:12:45.160
by a company called
Sesame Enable.

00:12:45.160 --> 00:12:47.490
Sesame Enable is
an Israeli company

00:12:47.490 --> 00:12:49.965
that was co-founded
by two people--

00:12:49.965 --> 00:12:56.100
Oded, who is a
computer vision expert;

00:12:56.100 --> 00:12:59.930
and Giora, who is a
high-current engineer who

00:12:59.930 --> 00:13:05.090
became quadriplegic due
to spinal cord injury.

00:13:05.090 --> 00:13:09.160
Now, Sesame Enable
utilizes the front camera

00:13:09.160 --> 00:13:13.590
of the device to
track head movements

00:13:13.590 --> 00:13:16.110
and move a mouse cursor.

00:13:16.110 --> 00:13:19.950
Now, I'd like to invite
Vladi, the head of development

00:13:19.950 --> 00:13:24.070
from Sesame Enable, onto the
stage to demo the technology.

00:13:24.070 --> 00:13:25.416
[APPLAUSE]

00:13:33.320 --> 00:13:34.010
Hey, Vladi.

00:13:34.010 --> 00:13:34.836
How are you doing?

00:13:34.836 --> 00:13:35.960
VLADI: Great, great, great.

00:13:35.960 --> 00:13:37.168
MAYA BEN ARI: Ready for this?

00:13:40.360 --> 00:13:44.420
So the first thing that Vladi
will do is he will-- can

00:13:44.420 --> 00:13:45.340
we move to the demo?

00:13:48.600 --> 00:13:51.520
The first thing that Vladi
will do is enable the service.

00:13:51.520 --> 00:13:53.400
Now, this can be
done through voice.

00:13:53.400 --> 00:13:55.700
But because of the
acoustics here, Vladi

00:13:55.700 --> 00:14:00.310
will just tap on the
Sesame Enable notification.

00:14:00.310 --> 00:14:02.635
Now, the service will
calibrate Vladi's face.

00:14:06.540 --> 00:14:10.040
After it locks it down, Vladi
can control a mouse cursor

00:14:10.040 --> 00:14:12.520
using only his head.

00:14:12.520 --> 00:14:17.150
Now, if Vladi would like to tap
on something, he just dwells.

00:14:27.540 --> 00:14:30.720
And he can tap.

00:14:30.720 --> 00:14:36.455
Now, once Vladi is into his
email, he can swipe up or down.

00:14:53.700 --> 00:15:08.705
I think we're a little
bit excited. [LAUGHS]

00:15:08.705 --> 00:15:09.246
VLADI: Sorry.

00:15:29.164 --> 00:15:30.080
MAYA BEN ARI: It's OK.

00:15:46.250 --> 00:15:47.113
It's OK.

00:16:00.332 --> 00:16:04.450
Would you like me to help you?

00:16:04.450 --> 00:16:07.110
Do you want me to help you?

00:16:07.110 --> 00:16:08.550
VLADI: You can try it.

00:16:08.550 --> 00:16:11.470
MAYA BEN ARI: Let's try it out.

00:16:11.470 --> 00:16:13.650
So the first thing
that I'm going to do--

00:16:13.650 --> 00:16:19.390
and we didn't reverse it, so I'm
going to try to help here-- I'm

00:16:19.390 --> 00:16:20.800
going to calibrate my face.

00:16:26.280 --> 00:16:26.780
OK.

00:16:26.780 --> 00:16:28.940
Now I can control
the mouse cursor.

00:16:28.940 --> 00:16:33.845
It's a little bit hard here,
because the overall stage

00:16:33.845 --> 00:16:35.900
is shaky.

00:16:35.900 --> 00:16:36.590
It is hard.

00:16:50.394 --> 00:16:52.600
Yeah, it's hard to calibrate.

00:16:52.600 --> 00:16:55.670
The overall stage is
shaky, and it's hard to do.

00:16:55.670 --> 00:16:57.690
But this is what this
demo is all about.

00:16:57.690 --> 00:17:02.540
So in general, after we
move the mouse cursor,

00:17:02.540 --> 00:17:05.640
we can also, like,
lock the sensor.

00:17:05.640 --> 00:17:07.544
This is by looking right.

00:17:20.290 --> 00:17:21.792
Yeah.

00:17:21.792 --> 00:17:23.250
VLADI: Do you want
me to try again?

00:17:23.250 --> 00:17:23.750
MAYA BEN ARI: Yeah, sure.

00:17:23.750 --> 00:17:24.250
Try again.

00:17:27.079 --> 00:17:28.420
Just go to Candy Crush.

00:17:31.121 --> 00:17:31.620
Yeah.

00:17:31.620 --> 00:17:32.540
Sorry.

00:17:32.540 --> 00:17:36.220
So in general, this demo is
about how to control a mouse

00:17:36.220 --> 00:17:38.890
cursor using the device.

00:17:38.890 --> 00:17:40.870
It's a little bit hard
to do it on stage,

00:17:40.870 --> 00:17:45.360
because the [INAUDIBLE]
stage is a little bit shaky.

00:17:45.360 --> 00:17:46.000
That's right.

00:17:59.560 --> 00:18:00.060
And--

00:18:00.060 --> 00:18:03.350
[MUSIC PLAYING]

00:18:06.180 --> 00:18:09.770
So the thing is basically,
you can do everything

00:18:09.770 --> 00:18:11.720
using a head tracker
on the device,

00:18:11.720 --> 00:18:16.390
including tapping and
touching and swiping and also

00:18:16.390 --> 00:18:18.820
downloading any app
from the Play Store

00:18:18.820 --> 00:18:22.870
and basically interacting with
that app only using your face.

00:18:22.870 --> 00:18:24.328
[APPLAUSE]

00:18:27.730 --> 00:18:31.120
So if you want to try it out
in a little bit of a less

00:18:31.120 --> 00:18:34.950
shaky stage, you are more
than welcome to come out

00:18:34.950 --> 00:18:39.290
to Access &amp; Empathy
sandbox to try it out.

00:18:39.290 --> 00:18:44.560
And one last note about this API
is that while this API is very

00:18:44.560 --> 00:18:49.090
powerful, it doesn't diminish
the need for an app developer

00:18:49.090 --> 00:18:53.550
to make their accessible, such
as adding content labelling

00:18:53.550 --> 00:18:55.940
or increasing touch target size.

00:18:55.940 --> 00:18:58.770
Because while the API
allows you to interact

00:18:58.770 --> 00:19:00.930
with different
elements on the screen,

00:19:00.930 --> 00:19:05.380
it doesn't know which
element it interacts with.

00:19:05.380 --> 00:19:12.470
So following every best practice
is still very important.

00:19:12.470 --> 00:19:14.955
So thank you so much,
Vladi, for your help.

00:19:14.955 --> 00:19:16.216
[APPLAUSE]

00:19:21.380 --> 00:19:23.550
And with that, I
would like to hand it

00:19:23.550 --> 00:19:28.964
off to Patrick and Scott
to talk about Voice Access.

00:19:28.964 --> 00:19:30.452
[APPLAUSE]

00:19:48.621 --> 00:19:49.620
PATRICK CLARY: Alrighty.

00:19:49.620 --> 00:19:51.300
Thanks, Maya.

00:19:51.300 --> 00:19:53.040
I'm Patrick Clary,
product manager

00:19:53.040 --> 00:19:54.340
on accessibility at Google.

00:19:54.340 --> 00:19:56.460
And with me is Scott
Newman, software engineer

00:19:56.460 --> 00:19:58.520
on accessibility at Google.

00:19:58.520 --> 00:20:00.640
And we're here, very
excited to talk to you

00:20:00.640 --> 00:20:03.070
about a new accessibility
service for Android

00:20:03.070 --> 00:20:04.910
called Voice Access.

00:20:04.910 --> 00:20:07.220
And this is an
accessibility service

00:20:07.220 --> 00:20:10.979
that is meant for users
with a motor impairment that

00:20:10.979 --> 00:20:13.145
find it hard to use a touch
screen with their hands.

00:20:16.132 --> 00:20:18.590
But before we talk about that,
I want to tell you about one

00:20:18.590 --> 00:20:20.870
of our testers,
whose name is Andy.

00:20:20.870 --> 00:20:25.530
Andy is a 65-year-old male
with essential tremor.

00:20:25.530 --> 00:20:28.010
And for Andy, he
really likes to be

00:20:28.010 --> 00:20:30.330
able to communicate
with friends and family

00:20:30.330 --> 00:20:33.580
and send them pictures through
email and messages and updates.

00:20:33.580 --> 00:20:35.910
And he generally
does this at home

00:20:35.910 --> 00:20:39.080
on his desktop PC
utilizing an app

00:20:39.080 --> 00:20:40.800
like Dragon
NaturallySpeaking, which

00:20:40.800 --> 00:20:44.440
allows him to dictate by voice.

00:20:44.440 --> 00:20:47.650
However, Andy would really like
to be able to do this on the go

00:20:47.650 --> 00:20:49.410
from his mobile device.

00:20:49.410 --> 00:20:52.180
But due to his tremor,
using a touch screen

00:20:52.180 --> 00:20:53.326
is very problematic.

00:20:56.920 --> 00:20:58.570
Now, if we take
a step back here,

00:20:58.570 --> 00:21:02.120
we realize that Andy's
experience is not that unique.

00:21:02.120 --> 00:21:04.300
In fact, there are millions
of people in the US

00:21:04.300 --> 00:21:07.220
alone that have some
form of motor impairment

00:21:07.220 --> 00:21:10.210
that impacts how they
can use a touch screen.

00:21:10.210 --> 00:21:12.940
So this can range from
people with essential tremor,

00:21:12.940 --> 00:21:16.940
like Andy, to people who have
Parkinson's, amputees, people

00:21:16.940 --> 00:21:19.760
with arthritis, even people
with spinal cord injuries,

00:21:19.760 --> 00:21:21.780
just to name a few.

00:21:21.780 --> 00:21:23.190
Now, in addition
to that, there's

00:21:23.190 --> 00:21:24.730
many more people
who have what we

00:21:24.730 --> 00:21:27.860
call a situational disability,
like Maya mentioned before.

00:21:27.860 --> 00:21:29.790
This could be a
temporary impairment

00:21:29.790 --> 00:21:32.180
that affects their use of
a touch screen, something

00:21:32.180 --> 00:21:33.960
like a broken hand or wrist.

00:21:33.960 --> 00:21:36.520
Or maybe their
hands are occupied.

00:21:36.520 --> 00:21:38.260
A common use case
we actually hear

00:21:38.260 --> 00:21:39.680
is that someone
might be cooking,

00:21:39.680 --> 00:21:40.990
and their hands are dirty.

00:21:40.990 --> 00:21:42.381
They don't use their hands.

00:21:42.381 --> 00:21:44.755
And they'd love to be able to
still control their device.

00:21:47.770 --> 00:21:51.050
So this is really the motivation
we have for Voice Access.

00:21:51.050 --> 00:21:53.050
And our goal with
Voice Access is

00:21:53.050 --> 00:21:57.370
to provide someone this
complete control of their device

00:21:57.370 --> 00:21:59.570
through use of
their voice alone.

00:21:59.570 --> 00:22:01.260
In essence, we want
to be able to allow

00:22:01.260 --> 00:22:05.450
users to click by voice.

00:22:05.450 --> 00:22:07.940
Or, to put it in the words
of one of our testers,

00:22:07.940 --> 00:22:13.660
"Use your voice and you're
able to access the world."

00:22:13.660 --> 00:22:17.480
So you might be asking, how
does an accessibility service

00:22:17.480 --> 00:22:20.380
like Voice Access differ
from a voice assistant

00:22:20.380 --> 00:22:24.020
like Google Now or OK Google,
where you can say this hot word

00:22:24.020 --> 00:22:27.620
and then perform a search query,
which is more conversational?

00:22:27.620 --> 00:22:29.730
Or you can perform
a voice action,

00:22:29.730 --> 00:22:33.500
like you can set a reminder,
you can create a calendar event?

00:22:33.500 --> 00:22:35.570
An accessibility
service is different.

00:22:35.570 --> 00:22:37.540
What we're looking for
is to empower people

00:22:37.540 --> 00:22:43.180
to be able to use their device
and have full device control.

00:22:43.180 --> 00:22:46.350
Now the high-level
voice assistant

00:22:46.350 --> 00:22:48.890
is really lacking the
fine-grained commands

00:22:48.890 --> 00:22:49.650
needed to do this.

00:22:49.650 --> 00:22:52.940
So for example, I mentioned
Jeff likes to send messages

00:22:52.940 --> 00:22:54.280
to friends and family.

00:22:54.280 --> 00:22:56.740
So from his mobile device,
if he wanted to do this,

00:22:56.740 --> 00:22:58.720
he might have to
open the camera app,

00:22:58.720 --> 00:23:00.720
take a photo by
pressing a button.

00:23:00.720 --> 00:23:03.860
Then open an app like Hangouts
by clicking on the icon,

00:23:03.860 --> 00:23:06.880
scrolling and swiping to
the contact he wanted,

00:23:06.880 --> 00:23:09.820
clicking on Attach the
Photo, and then tapping

00:23:09.820 --> 00:23:14.140
on the text box, typing in
text, and then clicking Send.

00:23:14.140 --> 00:23:16.270
So with Voice
Access, our goal is

00:23:16.270 --> 00:23:21.870
for each of those touch actions
to enable a corresponding voice

00:23:21.870 --> 00:23:24.570
command that allows
users to chain together

00:23:24.570 --> 00:23:29.240
a series of these commands
to perform a complex task.

00:23:29.240 --> 00:23:32.300
So to see it in real
life, I'll hand it over

00:23:32.300 --> 00:23:34.401
to Scott, who will
give you guys a demo.

00:23:34.401 --> 00:23:35.900
SCOTT NEWMAN: Thanks
a lot, Patrick.

00:23:35.900 --> 00:23:38.250
So my name is Scott Newman.

00:23:38.250 --> 00:23:40.690
I am a software engineer
on the accessibility team.

00:23:40.690 --> 00:23:43.690
And I'm excited to give you
a demo of Voice Access today.

00:23:43.690 --> 00:23:45.490
Before I go ahead
and get started,

00:23:45.490 --> 00:23:48.400
I just wanted to mention that
as some of you may be aware,

00:23:48.400 --> 00:23:50.880
speech recognition
demos can be fickle

00:23:50.880 --> 00:23:52.140
in front of live audiences.

00:23:52.140 --> 00:23:54.820
So if we run into any
issues, just bear with me,

00:23:54.820 --> 00:23:56.280
and we'll get through them.

00:23:56.280 --> 00:23:59.020
So with that, let's go
ahead and get started.

00:23:59.020 --> 00:24:02.200
So I remember that Patrick
sent me a message a little bit

00:24:02.200 --> 00:24:02.840
earlier.

00:24:02.840 --> 00:24:05.220
And I'd like to read it,
but before I actually

00:24:05.220 --> 00:24:08.420
read the message, I'm going to
go into Accessibility settings

00:24:08.420 --> 00:24:10.994
and enable large text
so it's a little easier

00:24:10.994 --> 00:24:12.660
for those people in
the back of the room

00:24:12.660 --> 00:24:15.278
to see what's on the screen.

00:24:15.278 --> 00:24:17.750
[TONE]

00:24:17.750 --> 00:24:19.690
Open Settings.

00:24:19.690 --> 00:24:21.890
[TONE]

00:24:21.890 --> 00:24:24.543
Scroll to the bottom.

00:24:24.543 --> 00:24:25.891
[TONE]

00:24:26.390 --> 00:24:30.320
Tap Accessibility.

00:24:30.320 --> 00:24:32.260
[TONE]

00:24:32.260 --> 00:24:35.532
Tap Large Text.

00:24:35.532 --> 00:24:36.906
[TONE]

00:24:37.830 --> 00:24:40.530
Go Home.

00:24:40.530 --> 00:24:43.360
Go Home.

00:24:43.360 --> 00:24:45.214
Let's try one more time.

00:24:45.214 --> 00:24:46.450
[TONE]

00:24:46.450 --> 00:24:48.110
Go Home.

00:24:48.110 --> 00:24:49.471
[TONE]

00:24:49.890 --> 00:24:50.390
All right.

00:24:50.390 --> 00:24:51.210
There we go.

00:24:51.210 --> 00:24:53.070
So that's Voice
Access an action.

00:24:53.070 --> 00:24:55.220
So what actually
happened right there?

00:24:55.220 --> 00:24:58.470
So you may notice that there's
this persistent blue button

00:24:58.470 --> 00:25:00.730
that appears on the top
right of the screen.

00:25:00.730 --> 00:25:03.010
And so that's at Voice
Access activation button.

00:25:03.010 --> 00:25:05.340
So from any screen, you
just press that button,

00:25:05.340 --> 00:25:07.270
and then Voice Access
starts listening.

00:25:07.270 --> 00:25:10.670
And then from
there, you can issue

00:25:10.670 --> 00:25:12.790
commands to globally
navigate the device,

00:25:12.790 --> 00:25:14.930
interact with individual
elements on the screen,

00:25:14.930 --> 00:25:18.500
and basically control your
device entirely by voice.

00:25:18.500 --> 00:25:22.060
So what I did there was I opened
the Settings app by saying,

00:25:22.060 --> 00:25:23.280
open settings.

00:25:23.280 --> 00:25:27.180
I said, scroll to the bottom to
actually scroll the screen down

00:25:27.180 --> 00:25:30.140
as if I were performing a
traditional tap gesture.

00:25:30.140 --> 00:25:33.730
Then I said, tap Accessibility
to tap the corresponding button

00:25:33.730 --> 00:25:37.130
on the screen that was labeled
with the text accessibility.

00:25:37.130 --> 00:25:38.760
And then I did the
exact same thing

00:25:38.760 --> 00:25:41.700
to press the switch
labeled Large Text.

00:25:41.700 --> 00:25:44.960
So this actually uses the
same accessibility APIs

00:25:44.960 --> 00:25:47.020
that underlie the
other accessibility

00:25:47.020 --> 00:25:50.840
services that we've seen so far,
like TalkBack or Switch Access.

00:25:50.840 --> 00:25:53.950
So as long as you follow
accessibility development best

00:25:53.950 --> 00:25:56.030
practices, your
apps should actually

00:25:56.030 --> 00:25:59.150
work with Voice Access
right out of the box.

00:25:59.150 --> 00:26:01.180
So with that, let's
actually see the message

00:26:01.180 --> 00:26:03.491
that Patrick sent me.

00:26:03.491 --> 00:26:04.892
[TONE]

00:26:04.892 --> 00:26:06.710
Could we go back to cast?

00:26:06.710 --> 00:26:07.820
Thanks.

00:26:07.820 --> 00:26:09.700
[TONE]

00:26:09.700 --> 00:26:11.450
Open Hangouts.

00:26:11.450 --> 00:26:12.950
[TONE]

00:26:14.950 --> 00:26:17.960
Patrick Clary.

00:26:17.960 --> 00:26:18.880
[TONE]

00:26:20.260 --> 00:26:23.100
Stop Voice Access.

00:26:23.100 --> 00:26:23.950
[TONE]

00:26:23.950 --> 00:26:27.720
Again, so I used Voice Access
to open the Hangouts app.

00:26:27.720 --> 00:26:29.780
And then when I said,
Patrick Clary, it actually

00:26:29.780 --> 00:26:32.990
found the clickable button
on the screen with text

00:26:32.990 --> 00:26:35.890
that was labeled Patrick Clary
and then clicked that button

00:26:35.890 --> 00:26:37.410
on my behalf.

00:26:37.410 --> 00:26:39.600
So one other thing that
you may be noticing

00:26:39.600 --> 00:26:41.390
is that there are
these numbers that

00:26:41.390 --> 00:26:43.950
are drawn on the screen whenever
Voice Access is actively

00:26:43.950 --> 00:26:44.680
listening.

00:26:44.680 --> 00:26:47.897
And so what that is is
kind of a safety fallback.

00:26:47.897 --> 00:26:50.480
So if you want to interact with
something on the screen that's

00:26:50.480 --> 00:26:52.410
clickable or
scrollable, and there's

00:26:52.410 --> 00:26:54.585
no text associated
with it-- let's say,

00:26:54.585 --> 00:26:56.880
a clickable image--
then you can default

00:26:56.880 --> 00:26:59.410
to just saying the number,
and it will flick that element

00:26:59.410 --> 00:27:00.750
on your behalf.

00:27:00.750 --> 00:27:04.000
So with that, I'm going to
respond to Patrick's message

00:27:04.000 --> 00:27:05.822
and then send it.

00:27:05.822 --> 00:27:08.280
[TONE]

00:27:08.280 --> 00:27:11.954
Type, the party is at 7:00.

00:27:11.954 --> 00:27:13.906
[TONE]

00:27:13.906 --> 00:27:15.770
I actually notice
that I made a mistake.

00:27:15.770 --> 00:27:18.200
The party is I think at
8:00 instead of 7:00,

00:27:18.200 --> 00:27:20.096
so let me change really quickly.

00:27:20.096 --> 00:27:21.960
[TONE]

00:27:21.960 --> 00:27:23.810
Replace 7:00 with 8:00.

00:27:27.960 --> 00:27:31.430
So in addition to
navigation, interacting

00:27:31.430 --> 00:27:33.530
with individual
elements on the screen,

00:27:33.530 --> 00:27:36.260
we actually offer a full suite
of text-editing commands.

00:27:36.260 --> 00:27:39.161
And so that was just one of very
many that you can use to edit

00:27:39.161 --> 00:27:39.660
text.

00:27:39.660 --> 00:27:43.030
You can replace parts
of text with other text.

00:27:43.030 --> 00:27:44.300
You can copy.

00:27:44.300 --> 00:27:45.650
You can move elements around.

00:27:45.650 --> 00:27:48.330
So it's just a really fast
way to actually interact

00:27:48.330 --> 00:27:51.210
with whatever's on
the current screen.

00:27:51.210 --> 00:27:52.710
And the Hangouts
app actually didn't

00:27:52.710 --> 00:27:55.790
need to do anything special
to work with Voice Access.

00:27:55.790 --> 00:27:57.700
It just works right
out of the box.

00:27:57.700 --> 00:28:00.014
So what I'm going to do
now is send the message.

00:28:00.014 --> 00:28:02.180
You'll notice that at the
bottom right of the screen

00:28:02.180 --> 00:28:03.740
is this green Send button.

00:28:03.740 --> 00:28:06.000
And there's no text
associated with it.

00:28:06.000 --> 00:28:07.880
So in order to
click that button,

00:28:07.880 --> 00:28:09.729
I'm going to reactivate
Voice Access,

00:28:09.729 --> 00:28:11.520
and then I'm going to
say the number that's

00:28:11.520 --> 00:28:14.300
associated with it that appears
right next to the button.

00:28:14.300 --> 00:28:16.800
Then it's going to click that
button and send the message.

00:28:16.800 --> 00:28:18.870
So let's go ahead and do that.

00:28:18.870 --> 00:28:20.860
[TONE]

00:28:20.860 --> 00:28:23.286
Tap 11.

00:28:23.286 --> 00:28:24.250
[TONE]

00:28:25.700 --> 00:28:27.637
Stop Voice Access.

00:28:27.637 --> 00:28:29.038
Nope.

00:28:29.038 --> 00:28:29.972
[TONE]

00:28:31.380 --> 00:28:32.870
Undo.

00:28:32.870 --> 00:28:33.730
[TONE]

00:28:35.020 --> 00:28:37.190
Stop Voice Access.

00:28:37.190 --> 00:28:38.660
[TONE]

00:28:38.660 --> 00:28:40.600
So that's Voice Access for you.

00:28:40.600 --> 00:28:44.110
So notice that you
can start Voice Access

00:28:44.110 --> 00:28:45.600
by pressing this blue button.

00:28:45.600 --> 00:28:48.100
Actually, if you want to do
it completely hands-free,

00:28:48.100 --> 00:28:51.086
if you say the OK
Google command,

00:28:51.086 --> 00:28:53.210
there's actually another
way that you can access it

00:28:53.210 --> 00:28:55.040
completely hands-free by voice.

00:28:55.040 --> 00:28:57.390
We offer a whole host
of activation methods

00:28:57.390 --> 00:28:59.460
so you can choose what's
most efficient for you.

00:28:59.460 --> 00:29:01.310
Similarly, you can
stop Voice Access

00:29:01.310 --> 00:29:03.240
by saying, stop
voice access, or just

00:29:03.240 --> 00:29:06.180
by touching the screen, which
is kind of a fail-safe option

00:29:06.180 --> 00:29:08.640
to leave Voice Access quickly.

00:29:08.640 --> 00:29:10.390
So that's what's Voice
Access in practice.

00:29:10.390 --> 00:29:13.790
Can we go back to
the deck, please?

00:29:13.790 --> 00:29:14.500
Thanks.

00:29:14.500 --> 00:29:17.350
So let's hear from some
actual Voice Access users

00:29:17.350 --> 00:29:20.282
about how it's
impacted their lives.

00:29:20.282 --> 00:29:21.240
Roll the video, please.

00:29:21.240 --> 00:29:24.186
[VIDEO PLAYBACK]

00:29:24.186 --> 00:29:25.360
-Let's go, guys.

00:29:32.050 --> 00:29:34.190
My name's Stephanie,
and I just finished

00:29:34.190 --> 00:29:36.220
my master's in advertising.

00:29:36.220 --> 00:29:39.260
I'm a C4/C5 split-level
quadriplegic.

00:29:39.260 --> 00:29:42.220
I have no feeling
from my collarbone

00:29:42.220 --> 00:29:46.340
down, so it is absolutely vital
that I'm able to use my voice.

00:29:46.340 --> 00:29:47.660
OK, Google.

00:29:47.660 --> 00:29:49.170
Start Voice Access.

00:29:49.170 --> 00:29:53.600
-My name's Jeff, and I have
a neurological condition

00:29:53.600 --> 00:29:55.870
called essential tremor.

00:29:55.870 --> 00:30:00.560
It is incredibly difficult
to use my hands and fingers.

00:30:00.560 --> 00:30:03.920
It is very easy for
me to use my voice.

00:30:03.920 --> 00:30:05.170
OK, Google.

00:30:05.170 --> 00:30:07.880
Start Voice Access.

00:30:07.880 --> 00:30:12.450
-After using this product for
probably about 10 seconds,

00:30:12.450 --> 00:30:14.170
I think I'm falling
in love with it.

00:30:14.170 --> 00:30:16.400
Open camera.

00:30:16.400 --> 00:30:19.730
You use your voice, and you're
able to access the world.

00:30:19.730 --> 00:30:30.120
Shutter, share Hangouts,
Astrid Weber, Send.

00:30:30.120 --> 00:30:34.560
-I cannot tell you how excited
I am about this product.

00:30:34.560 --> 00:30:36.540
Open calendar, new.

00:30:36.540 --> 00:30:40.680
When you don't have the ability
to use your fingers and hands--

00:30:40.680 --> 00:30:45.565
family movie night-- it's
really all about voice.

00:30:51.810 --> 00:30:52.393
[END PLAYBACK]

00:30:52.393 --> 00:30:53.866
[APPLAUSE]

00:31:00.579 --> 00:31:02.120
SCOTT NEWMAN: So
that's Voice Access.

00:31:02.120 --> 00:31:03.911
We're really excited
for you to try it out.

00:31:03.911 --> 00:31:05.230
It's in open beta right now.

00:31:05.230 --> 00:31:08.780
So if you come over to the
Access &amp; Empathy sandbox here,

00:31:08.780 --> 00:31:10.261
you could try it out yourself.

00:31:10.261 --> 00:31:11.760
With that, I'm going
to hand it over

00:31:11.760 --> 00:31:14.343
to Astrid and Jen, who are going
to talk about how you can use

00:31:14.343 --> 00:31:16.640
UX research to improve the
quality of your product,

00:31:16.640 --> 00:31:18.790
with Voice Access
as a case study.

00:31:18.790 --> 00:31:20.855
Thanks a lot.

00:31:20.855 --> 00:31:22.340
[APPLAUSE]

00:31:23.830 --> 00:31:25.290
JEN DEVINS: Thank you, Scott.

00:31:25.290 --> 00:31:27.610
Hi, my name is Jen,
and this is Astrid.

00:31:27.610 --> 00:31:31.370
We are inclusive design
and researchers in Google,

00:31:31.370 --> 00:31:33.280
and we wanted to
share with you today

00:31:33.280 --> 00:31:36.660
a little bit about how UX
research influenced and drove

00:31:36.660 --> 00:31:40.210
the design of Voice Access.

00:31:40.210 --> 00:31:42.770
But first, what is UX research?

00:31:42.770 --> 00:31:44.520
The general
definition is that it

00:31:44.520 --> 00:31:48.850
focuses on understanding user
behaviors, needs, motivations

00:31:48.850 --> 00:31:51.820
through observation
techniques, task analysis,

00:31:51.820 --> 00:31:53.660
and other methodologies.

00:31:53.660 --> 00:31:56.060
The key here is
that while we might

00:31:56.060 --> 00:31:58.400
think we know what users
want, because maybe we

00:31:58.400 --> 00:32:02.480
are users of our own product, or
maybe we are really close to it

00:32:02.480 --> 00:32:05.340
and develop and design it,
it's critical to get out

00:32:05.340 --> 00:32:08.000
there and get feedback
from external users

00:32:08.000 --> 00:32:11.550
and understand their unique
perspectives, insights,

00:32:11.550 --> 00:32:14.140
challenges, and pain points.

00:32:14.140 --> 00:32:16.850
In fact, the products
that we demoed here today

00:32:16.850 --> 00:32:20.600
all underwent many iterations
of design and development,

00:32:20.600 --> 00:32:23.290
and all of which were inspired
and driven by UX research.

00:32:26.320 --> 00:32:29.340
The process itself is
about a five-step process,

00:32:29.340 --> 00:32:33.320
and it can be cyclical if
you want to keep refining.

00:32:33.320 --> 00:32:34.980
The way it was applied
to Voice Access,

00:32:34.980 --> 00:32:38.200
it was first looking at
what are the objectives

00:32:38.200 --> 00:32:40.080
of the product as a whole.

00:32:40.080 --> 00:32:44.220
One key objective
of Voice Access

00:32:44.220 --> 00:32:47.770
was that they wanted to
ensure it was easy to use,

00:32:47.770 --> 00:32:50.350
easy to learn how to
use right out of the box

00:32:50.350 --> 00:32:52.260
in a hands-free manner.

00:32:52.260 --> 00:32:54.630
And so from there, they
developed hypotheses.

00:32:54.630 --> 00:32:55.880
OK.

00:32:55.880 --> 00:33:02.860
So based on that objective, they
thought that contextual help

00:33:02.860 --> 00:33:06.720
was the best way to allow
people to learn how to use

00:33:06.720 --> 00:33:08.840
the product in the moment.

00:33:08.840 --> 00:33:12.270
From there, they defined what
the best methodologies were

00:33:12.270 --> 00:33:16.140
to use, conducted the research,
synthesized those findings,

00:33:16.140 --> 00:33:19.410
and reported those back to the
team, which further iterated

00:33:19.410 --> 00:33:21.294
on the design of the product.

00:33:21.294 --> 00:33:22.710
So now Astrid is
going to take you

00:33:22.710 --> 00:33:26.370
through the specific
methodologies used

00:33:26.370 --> 00:33:28.395
and how those insights
actually impacted

00:33:28.395 --> 00:33:29.520
the design of Voice Access.

00:33:33.382 --> 00:33:34.590
ASTRID WEBER: Thank you, Jen.

00:33:37.460 --> 00:33:38.550
I'm Astrid Weber.

00:33:38.550 --> 00:33:41.030
I'm a UX researcher
working on Voice Access.

00:33:41.030 --> 00:33:45.770
And I'd like to show you how
we accompanied the design

00:33:45.770 --> 00:33:49.640
and development process with
a few research methodologies.

00:33:49.640 --> 00:33:53.350
And I'd like to get started
with formative research.

00:33:53.350 --> 00:33:56.350
Formative research is
if you go into the field

00:33:56.350 --> 00:33:59.192
in order to understand
about your users

00:33:59.192 --> 00:34:00.150
from their daily lives.

00:34:00.150 --> 00:34:02.430
So you go and see
how they work, how

00:34:02.430 --> 00:34:04.070
they lives their lives at home.

00:34:04.070 --> 00:34:06.590
And we did that in particular
with users with severe motor

00:34:06.590 --> 00:34:08.449
impairments, as
you've seen before

00:34:08.449 --> 00:34:10.860
with the user in our video.

00:34:10.860 --> 00:34:13.710
What we learned out there
is that at the moment,

00:34:13.710 --> 00:34:17.239
there is no cohesive strategy
for people who cannot use

00:34:17.239 --> 00:34:21.000
their hands in order to access
their mobile devices completely

00:34:21.000 --> 00:34:22.780
hands-free.

00:34:22.780 --> 00:34:25.780
After we knew that, we
went back and developed

00:34:25.780 --> 00:34:28.940
the first prototype
of Voice Access.

00:34:28.940 --> 00:34:33.989
As soon as we had something
that was testable, we test it.

00:34:33.989 --> 00:34:36.540
And we did so with
internal testing.

00:34:36.540 --> 00:34:39.980
Internal testing is probably
best known to tech companies,

00:34:39.980 --> 00:34:42.179
because all you
need is yourself.

00:34:42.179 --> 00:34:45.060
So all of us within the team
installed the application,

00:34:45.060 --> 00:34:47.010
people outside the
team, and we tried

00:34:47.010 --> 00:34:49.469
to use it in as
many circumstances

00:34:49.469 --> 00:34:51.810
and contexts as possible.

00:34:51.810 --> 00:34:54.260
What we found was a lot of bugs.

00:34:54.260 --> 00:34:58.040
So we addressed those bugs,
we made the product better.

00:34:58.040 --> 00:35:01.030
We iterated it until
we got to the point

00:35:01.030 --> 00:35:03.980
that we felt the product is so
stable now that we can actually

00:35:03.980 --> 00:35:06.510
put it in front of real users.

00:35:06.510 --> 00:35:07.910
And that's what we did.

00:35:07.910 --> 00:35:09.870
We ran usability studies.

00:35:09.870 --> 00:35:14.920
Usability studies are when you
invite people to actually come

00:35:14.920 --> 00:35:16.620
into your lab.

00:35:16.620 --> 00:35:19.180
Those are people from the
core audience, so in our case,

00:35:19.180 --> 00:35:23.300
people with severe motor
impairments, and they test it.

00:35:23.300 --> 00:35:25.170
And you are in front of them.

00:35:25.170 --> 00:35:26.930
You can see exactly
what they're doing.

00:35:26.930 --> 00:35:29.630
And they're running through
a couple of tasks with you,

00:35:29.630 --> 00:35:31.910
and you see the
limitations of the product.

00:35:31.910 --> 00:35:33.290
You see where it's failing.

00:35:33.290 --> 00:35:36.920
But you also see where people
are especially delighted.

00:35:36.920 --> 00:35:40.730
And what you see actually in
the picture is one of our labs.

00:35:40.730 --> 00:35:43.070
It's designed to
be very comfortable

00:35:43.070 --> 00:35:44.810
and welcoming to our users.

00:35:44.810 --> 00:35:47.040
And at the same
time, it has cameras

00:35:47.040 --> 00:35:51.200
to capture audio and video,
so afterwards we can actually

00:35:51.200 --> 00:35:54.670
go back into the data,
analyze, and see exactly how we

00:35:54.670 --> 00:35:57.520
can improve the product.

00:35:57.520 --> 00:36:00.624
Usability studies are great,
but they have their limitations.

00:36:00.624 --> 00:36:02.040
And I think the
biggest limitation

00:36:02.040 --> 00:36:04.480
is that it's a very
short period of time

00:36:04.480 --> 00:36:06.990
that your user is
interacting with the product.

00:36:06.990 --> 00:36:10.600
And it's in a lab environment,
so it's not the real life.

00:36:10.600 --> 00:36:16.050
So we went one step further
and conducted diary studies.

00:36:16.050 --> 00:36:19.030
Diary studies, as the
name already indicates,

00:36:19.030 --> 00:36:22.440
are studies where your
user is going to keep

00:36:22.440 --> 00:36:24.270
a diary about their usage.

00:36:24.270 --> 00:36:26.000
So what did we do?

00:36:26.000 --> 00:36:28.580
We sent Voice Access
home with the users

00:36:28.580 --> 00:36:31.120
on their personal
devices installed,

00:36:31.120 --> 00:36:33.120
and they could use it
in whichever context

00:36:33.120 --> 00:36:34.690
they wanted to.

00:36:34.690 --> 00:36:36.340
The only thing they
had to do-- they

00:36:36.340 --> 00:36:38.840
actually had to promise us--
was that they would report back

00:36:38.840 --> 00:36:39.940
about the experience.

00:36:39.940 --> 00:36:41.620
So you can do that
over the phone,

00:36:41.620 --> 00:36:45.045
you can have them write emails,
or just fill in a quick survey.

00:36:45.045 --> 00:36:46.420
And in the end of
the study, they

00:36:46.420 --> 00:36:48.260
would come back into
the office with us

00:36:48.260 --> 00:36:51.220
and give us a report-- how they
used the product, what they

00:36:51.220 --> 00:36:53.050
liked, what they didn't like.

00:36:53.050 --> 00:36:54.670
What we learned
from that process

00:36:54.670 --> 00:36:58.850
is that for one,
Voice Access really

00:36:58.850 --> 00:37:02.260
needs to be polished and
be visually delightful.

00:37:02.260 --> 00:37:06.160
You've seen in the video the
latest design that we have.

00:37:06.160 --> 00:37:07.480
We didn't start off on that.

00:37:07.480 --> 00:37:10.490
I have a few more examples
on that in a minute from you.

00:37:10.490 --> 00:37:13.370
And the second thing,
if you use it on the go,

00:37:13.370 --> 00:37:17.170
you need a really easy way to
activate and deactivate it.

00:37:17.170 --> 00:37:19.650
Because otherwise, it's too
much hassle for the user

00:37:19.650 --> 00:37:22.600
to actually dive
into the software

00:37:22.600 --> 00:37:25.010
and then again, when you
don't want it to listen,

00:37:25.010 --> 00:37:26.990
deactivate it.

00:37:26.990 --> 00:37:30.690
So let me show you these
examples that I just mentioned.

00:37:30.690 --> 00:37:33.930
The first one that I
would like to talk about

00:37:33.930 --> 00:37:36.510
is how we improve
the contextual help.

00:37:36.510 --> 00:37:38.560
You see on the left-hand
side the before,

00:37:38.560 --> 00:37:40.930
and on the right-hand
side, you see the after.

00:37:40.930 --> 00:37:42.620
So what is that?

00:37:42.620 --> 00:37:45.340
On the left-hand side, we see
a long list of all the voice

00:37:45.340 --> 00:37:47.200
commands that we're offering.

00:37:47.200 --> 00:37:49.830
Everyone who's
using or developing

00:37:49.830 --> 00:37:52.670
on voice-based software knows
that the biggest challenge

00:37:52.670 --> 00:37:56.690
is how can you actually teach
your user what they can say

00:37:56.690 --> 00:37:58.400
and how can they remember that.

00:37:58.400 --> 00:38:01.310
So it is essential that we
are offering a place where

00:38:01.310 --> 00:38:03.820
the user can go
back and check again

00:38:03.820 --> 00:38:07.160
what they can say in order
to get to a specific result.

00:38:07.160 --> 00:38:10.380
We thought, it makes sense
to just offer one long list,

00:38:10.380 --> 00:38:11.770
everything in one place.

00:38:11.770 --> 00:38:13.310
People will find that way.

00:38:13.310 --> 00:38:16.530
When we observed them
in usability studies,

00:38:16.530 --> 00:38:19.400
we found that this is
actually not the case.

00:38:19.400 --> 00:38:21.695
People got lost
along the long list.

00:38:21.695 --> 00:38:23.820
They even forgot what
they were looking for,

00:38:23.820 --> 00:38:25.880
because they were so
overwhelmed by all the stuff

00:38:25.880 --> 00:38:27.440
that we offer in there.

00:38:27.440 --> 00:38:29.940
And also the way we
presented the information,

00:38:29.940 --> 00:38:33.840
without any examples, was
not intuitive to understand

00:38:33.840 --> 00:38:34.930
for them.

00:38:34.930 --> 00:38:36.180
So what did we do?

00:38:36.180 --> 00:38:39.520
We see on the right-hand
side the first screen shot.

00:38:39.520 --> 00:38:40.690
We have categories now.

00:38:40.690 --> 00:38:42.990
So we have Basics and
navigation, Gestures,

00:38:42.990 --> 00:38:44.490
and Text editing.

00:38:44.490 --> 00:38:47.920
And with those, the users
deep-dived into a smaller

00:38:47.920 --> 00:38:49.590
subset of commands.

00:38:49.590 --> 00:38:51.370
What you see then on
the next screenshot,

00:38:51.370 --> 00:38:54.110
within Basics and navigation,
that the user actually

00:38:54.110 --> 00:38:56.630
gets specific examples
of the voice action

00:38:56.630 --> 00:38:57.850
that they can take.

00:38:57.850 --> 00:39:00.930
And by doing so, we actually
had much better results

00:39:00.930 --> 00:39:04.040
that users were able to
find what they were saying

00:39:04.040 --> 00:39:05.970
and also for remembering
later on where

00:39:05.970 --> 00:39:08.520
to find that command again.

00:39:08.520 --> 00:39:12.640
The second example I'd like to
show to you is our tutorial.

00:39:12.640 --> 00:39:14.630
Again, having a
really good tutorial

00:39:14.630 --> 00:39:16.600
is crucial, especially
if people have not

00:39:16.600 --> 00:39:19.050
used voice interactions
before in order

00:39:19.050 --> 00:39:21.280
to navigate the interface.

00:39:21.280 --> 00:39:24.320
We wanted to make it
as real as possible,

00:39:24.320 --> 00:39:26.400
so we took a screenshot
of the interface

00:39:26.400 --> 00:39:28.770
and explained it to the users.

00:39:28.770 --> 00:39:31.620
What we didn't
expect was that users

00:39:31.620 --> 00:39:34.020
would want to interact
with this screenshot,

00:39:34.020 --> 00:39:36.150
and wouldn't distinguish
between a screenshot

00:39:36.150 --> 00:39:38.690
versus the real product.

00:39:38.690 --> 00:39:42.990
So we took the learning back,
and we designed the experience,

00:39:42.990 --> 00:39:45.290
as you see it on
the right-hand side,

00:39:45.290 --> 00:39:48.710
to be text explaining
the functionality.

00:39:48.710 --> 00:39:51.020
So this is how to use
some numbers, what

00:39:51.020 --> 00:39:52.920
Scott had demoed before.

00:39:52.920 --> 00:39:56.280
And we did have numbers
now on the screen,

00:39:56.280 --> 00:39:58.500
but those are real, so you
can interact with them.

00:39:58.500 --> 00:40:00.710
So the user is learning
about it immediately,

00:40:00.710 --> 00:40:03.080
and they can apply the learning.

00:40:03.080 --> 00:40:07.370
And with that, we actually
made really good progress.

00:40:07.370 --> 00:40:10.450
And now Jen is going to
talk about usability testing

00:40:10.450 --> 00:40:14.260
and how you can use it for
your very own application.

00:40:14.260 --> 00:40:15.950
JEN DEVINS: Thanks, Astrid.

00:40:15.950 --> 00:40:18.110
So in the few
minutes remaining, we

00:40:18.110 --> 00:40:20.790
wanted to leave you with a
quick starter guide of how

00:40:20.790 --> 00:40:22.520
to do your own
usability studies,

00:40:22.520 --> 00:40:24.730
because we do find
them very effective.

00:40:24.730 --> 00:40:26.210
And you don't need
anything fancy

00:40:26.210 --> 00:40:28.270
to actually execute these.

00:40:28.270 --> 00:40:30.600
Usability testing
is really useful

00:40:30.600 --> 00:40:33.750
to understand how people
use your product and why.

00:40:33.750 --> 00:40:35.960
And that's the key
point is the why.

00:40:35.960 --> 00:40:38.060
Before you jump and
just bring somebody in

00:40:38.060 --> 00:40:39.790
and have them run
through some tests,

00:40:39.790 --> 00:40:42.110
you want to have a
plan and a strategy,

00:40:42.110 --> 00:40:44.440
first starting with what are
the key questions you want

00:40:44.440 --> 00:40:46.106
to answer with this research.

00:40:46.106 --> 00:40:47.980
Write these down, review
them with your team,

00:40:47.980 --> 00:40:49.885
make sure everyone
is on the same page.

00:40:49.885 --> 00:40:51.670
These are your
research questions.

00:40:51.670 --> 00:40:54.070
And without solid
research questions,

00:40:54.070 --> 00:40:58.054
the end result might not meet
everybody's expectations.

00:40:58.054 --> 00:40:59.720
So based on these
questions, then you'll

00:40:59.720 --> 00:41:03.090
identify tasks that will help
you answer these questions.

00:41:03.090 --> 00:41:06.030
So for example,
if a question was,

00:41:06.030 --> 00:41:09.600
are users able to onboard
without any additional

00:41:09.600 --> 00:41:12.180
assistance, you would
bring in the new user

00:41:12.180 --> 00:41:14.580
and have them start the
app for the first time

00:41:14.580 --> 00:41:17.630
and maybe run through some
of your key fundamental tasks

00:41:17.630 --> 00:41:19.370
and see if they can
do it without asking

00:41:19.370 --> 00:41:22.235
for assistance from you,
looking in the help, or online.

00:41:24.810 --> 00:41:28.540
Once you're happy with your
study and your test questions

00:41:28.540 --> 00:41:30.740
and tasks, you want
to think about who

00:41:30.740 --> 00:41:33.130
to bring in and actually
conduct the study on.

00:41:33.130 --> 00:41:36.510
Now, you can certainly start
with friends and family.

00:41:36.510 --> 00:41:39.040
Ideally, those people will
actually be using your product,

00:41:39.040 --> 00:41:40.270
or do use it.

00:41:40.270 --> 00:41:41.940
And we also highly
recommend having

00:41:41.940 --> 00:41:44.820
a diverse set of participants
as much as possible.

00:41:44.820 --> 00:41:47.810
And you can actually reach
out to various organizations

00:41:47.810 --> 00:41:50.140
that lobby for
accessibility needs,

00:41:50.140 --> 00:41:52.920
and they're more than willing
to accommodate you and get

00:41:52.920 --> 00:41:56.280
some people to help
run the study on.

00:41:56.280 --> 00:41:59.540
Now, when it comes to actually
running it and figuring out

00:41:59.540 --> 00:42:01.630
where to run this, you
don't need a fancy lab

00:42:01.630 --> 00:42:02.710
like we showed.

00:42:02.710 --> 00:42:04.884
You can just find a
quiet, comfortable space.

00:42:04.884 --> 00:42:07.050
And you want to make sure
that there's room in there

00:42:07.050 --> 00:42:11.460
for yourself, the
participant, obviously.

00:42:11.460 --> 00:42:13.850
Ideally, you will have
somebody to help take notes,

00:42:13.850 --> 00:42:16.450
and you'll have some
video recording equipment.

00:42:16.450 --> 00:42:20.640
And also, it's great to have
a developer or a designer,

00:42:20.640 --> 00:42:22.800
somebody that's very
close to the product,

00:42:22.800 --> 00:42:25.200
there to observe as well.

00:42:25.200 --> 00:42:27.200
And there's been
tons of books written

00:42:27.200 --> 00:42:32.240
on how to actually conduct
usability studies effectively.

00:42:32.240 --> 00:42:34.770
They all kind of boil it down
to these four key steps--

00:42:34.770 --> 00:42:37.010
asking the users to
perform the test,

00:42:37.010 --> 00:42:39.410
and then taking a step back
and just observing them,

00:42:39.410 --> 00:42:41.950
seeing what are they
actually doing other

00:42:41.950 --> 00:42:43.360
than completing the task.

00:42:43.360 --> 00:42:45.580
Are they hovering in
interesting spots?

00:42:45.580 --> 00:42:46.680
Are they using a keyboard?

00:42:46.680 --> 00:42:48.450
What keyboard shortcuts
are they using?

00:42:48.450 --> 00:42:50.030
And that leads to
the next point,

00:42:50.030 --> 00:42:51.910
which is digging into why.

00:42:51.910 --> 00:42:53.750
I notice you were
hovering over that button.

00:42:53.750 --> 00:42:54.680
Can you tell me why?

00:42:54.680 --> 00:42:56.260
What did you expect to happen?

00:42:56.260 --> 00:42:58.260
Or after they
complete a task, did

00:42:58.260 --> 00:42:59.850
that meet your expectations?

00:42:59.850 --> 00:43:02.070
And this is the magic of
usability studies-- being

00:43:02.070 --> 00:43:05.480
able to actually understand
the rationale and the meaning

00:43:05.480 --> 00:43:08.120
behind their behaviors.

00:43:08.120 --> 00:43:10.800
And then I think the most
challenging part of this,

00:43:10.800 --> 00:43:12.710
especially if you are
close to the product,

00:43:12.710 --> 00:43:14.100
is remaining neutral.

00:43:14.100 --> 00:43:16.945
You might have the urge to want
to kind of defend or explain,

00:43:16.945 --> 00:43:18.820
well, we tried this,
but we couldn't do this,

00:43:18.820 --> 00:43:19.755
or we tried this.

00:43:19.755 --> 00:43:21.550
This is not the time to do that.

00:43:21.550 --> 00:43:24.320
You're just there to
listen, absorb the feedback,

00:43:24.320 --> 00:43:25.945
and move on.

00:43:25.945 --> 00:43:27.540
Oh, and then practice.

00:43:27.540 --> 00:43:29.300
Definitely practice
at least once

00:43:29.300 --> 00:43:31.660
before bringing in real users.

00:43:31.660 --> 00:43:33.730
During the study,
you want to ensure

00:43:33.730 --> 00:43:36.230
that you write down the most
interesting findings right

00:43:36.230 --> 00:43:37.870
away.

00:43:37.870 --> 00:43:39.750
And then review those
findings with your team

00:43:39.750 --> 00:43:40.780
after each participant.

00:43:40.780 --> 00:43:42.710
This will greatly
help at the end,

00:43:42.710 --> 00:43:45.280
just kind of summarizing
your findings.

00:43:45.280 --> 00:43:47.710
If you have the ability
to actually videotape it,

00:43:47.710 --> 00:43:52.020
cut small video snippets to
help support your findings.

00:43:52.020 --> 00:43:55.260
Again, not everybody will
have been there with you

00:43:55.260 --> 00:43:58.200
during the study, so when
you're presenting your findings,

00:43:58.200 --> 00:44:00.720
you can show, look, this
is how the users actually

00:44:00.720 --> 00:44:02.620
interacted with the app.

00:44:02.620 --> 00:44:04.620
And then one of the
most critical pieces

00:44:04.620 --> 00:44:07.240
is it would be a real shame
to do all of this work

00:44:07.240 --> 00:44:09.990
and have it just sit in
a dock somewhere unused.

00:44:09.990 --> 00:44:12.060
You want to have
somebody in charge,

00:44:12.060 --> 00:44:16.470
ready to drive the process
to address these issues.

00:44:16.470 --> 00:44:18.910
Of course, it doesn't have to
happen right then and there.

00:44:18.910 --> 00:44:21.920
But you want to be sure that
somebody is taking the charge

00:44:21.920 --> 00:44:24.180
to prioritize and
figure out what

00:44:24.180 --> 00:44:26.440
are bugs, what are
feature requests,

00:44:26.440 --> 00:44:29.470
and when they will be addressed.

00:44:29.470 --> 00:44:35.070
So we have on the
I/O app in our Spaces

00:44:35.070 --> 00:44:37.860
a great link to give
you more details

00:44:37.860 --> 00:44:40.737
on how to conduct usability
studies if you're interested.

00:44:40.737 --> 00:44:42.320
And overall, we hope
that you've found

00:44:42.320 --> 00:44:45.880
that this brief overview of
the research methodologies

00:44:45.880 --> 00:44:47.999
used for Voice Access inspiring.

00:44:47.999 --> 00:44:50.040
And hopefully you can
bring it back to your team.

00:44:50.040 --> 00:44:52.702
And now back to Patrick.

00:44:52.702 --> 00:44:54.091
[APPLAUSE]

00:44:56.332 --> 00:44:57.373
PATRICK CLARY: All right.

00:44:57.373 --> 00:44:59.772
Thanks, Jen.

00:44:59.772 --> 00:45:01.230
Thank you, everyone,
for attending.

00:45:01.230 --> 00:45:04.880
So as you can see, it's
very important for us

00:45:04.880 --> 00:45:07.410
to hear from users with
accessibility needs

00:45:07.410 --> 00:45:10.540
so that we can learn how
to improve the platform

00:45:10.540 --> 00:45:13.280
and for all of our developers
to take into account Android

00:45:13.280 --> 00:45:15.140
development best
practices, so we can all

00:45:15.140 --> 00:45:17.450
make apps that are great
for everyone who has

00:45:17.450 --> 00:45:18.980
different accessibility needs.

00:45:18.980 --> 00:45:22.420
So if you'd like to try out
Voice Access, it's in beta now.

00:45:22.420 --> 00:45:26.640
You can sign up for the
beta at g.co/voiceaccess.

00:45:26.640 --> 00:45:28.240
Also listed on the
screen here are

00:45:28.240 --> 00:45:31.190
some other talks we're doing
that are accessibility-related.

00:45:31.190 --> 00:45:32.060
Please attend those.

00:45:32.060 --> 00:45:33.270
They're all great.

00:45:33.270 --> 00:45:34.710
Come visit our sandbox.

00:45:34.710 --> 00:45:36.410
It's Access &amp; Empathy.

00:45:36.410 --> 00:45:38.650
It's actually right
over that way.

00:45:38.650 --> 00:45:42.170
And you can go there to
do a demo of Voice Access.

00:45:42.170 --> 00:45:46.830
You can go see the demo of
the Sesame head tracking,

00:45:46.830 --> 00:45:49.600
learn about many more things,
and also attend our code lab.

00:45:49.600 --> 00:45:50.700
So thank you, everyone.

00:45:50.700 --> 00:45:51.300
Take care.

00:45:51.300 --> 00:45:52.200
[APPLAUSE]

00:45:53.700 --> 00:45:57.050
[MUSIC PLAYING]

