WEBVTT
Kind: captions
Language: en

00:00:01.087 --> 00:00:02.670
FEMALE SPEAKER: My
name is [INAUDIBLE]

00:00:02.670 --> 00:00:04.680
and I work in our
People Operations team.

00:00:04.680 --> 00:00:07.370
And I'm really excited
to introduce Doctor John

00:00:07.370 --> 00:00:08.660
Ioannidis.

00:00:08.660 --> 00:00:12.260
John is a professor of medicine,
health research and policy,

00:00:12.260 --> 00:00:14.090
and statistics at Stanford.

00:00:14.090 --> 00:00:16.070
So not just one,
but all of those.

00:00:16.070 --> 00:00:18.830
He's also the co-director of
the very recently launched

00:00:18.830 --> 00:00:21.420
Meta-Research Innovation
Center at Stanford,

00:00:21.420 --> 00:00:25.140
also known as METRICS, which
is a research-to-action center

00:00:25.140 --> 00:00:27.040
whose purpose is to
advance excellence

00:00:27.040 --> 00:00:29.310
in scientific research.

00:00:29.310 --> 00:00:32.030
Previously, John was chairman
at the Department of Hygiene

00:00:32.030 --> 00:00:34.190
and Epidemiology
at the University

00:00:34.190 --> 00:00:37.130
of Ioannida School of
Medicine in Greece,

00:00:37.130 --> 00:00:39.600
as well as an adjunct
professor at Tufts University

00:00:39.600 --> 00:00:41.310
School of Medicine.

00:00:41.310 --> 00:00:43.850
John is best known for his
research and published papers

00:00:43.850 --> 00:00:47.540
on scientific studies,
particularly the 2005 paper

00:00:47.540 --> 00:00:50.520
"Why Most Published Research
Findings Are False"--

00:00:50.520 --> 00:00:53.270
I can't understand why that
one was controversial--

00:00:53.270 --> 00:00:55.670
which has been the most
downloaded technical paper from

00:00:55.670 --> 00:00:58.380
the leading open access medical
journal "The Public Library

00:00:58.380 --> 00:01:00.010
of Science."

00:01:00.010 --> 00:01:02.820
John's current work is focused
on improving research design

00:01:02.820 --> 00:01:03.410
standards.

00:01:03.410 --> 00:01:06.870
And today's talk is titled
"Reproducible Research-- False

00:01:06.870 --> 00:01:08.100
or True?"

00:01:08.100 --> 00:01:10.120
The talk is being
live-streamed and recorded,

00:01:10.120 --> 00:01:12.144
so we ask that questions
are held until the end

00:01:12.144 --> 00:01:13.560
and that you wait
for a microphone

00:01:13.560 --> 00:01:15.880
so that everyone can
hear your questions.

00:01:15.880 --> 00:01:18.707
Please join me in welcoming
Dr. John Ioannidis.

00:01:18.707 --> 00:01:21.092
[APPLAUSE]

00:01:24.910 --> 00:01:26.835
DR. IOANNIDIS: Thank
you, [INAUDIBLE].

00:01:26.835 --> 00:01:28.710
I would like to share
some thoughts with you,

00:01:28.710 --> 00:01:30.574
and I realize it's
a videotaped talk.

00:01:30.574 --> 00:01:32.740
But this doesn't mean that
you should not interrupt.

00:01:32.740 --> 00:01:34.720
Actually, please do interrupt.

00:01:34.720 --> 00:01:37.050
Because otherwise it's going
to be very boring lecture,

00:01:37.050 --> 00:01:38.612
I presume.

00:01:38.612 --> 00:01:40.320
It's a great pleasure
to be here to share

00:01:40.320 --> 00:01:41.360
these thoughts with you.

00:01:44.340 --> 00:01:47.770
Science is a big enterprise.

00:01:47.770 --> 00:01:50.470
We're talking about
15 million people

00:01:50.470 --> 00:01:53.660
that have published papers
indexed in SCOPE in the last 15

00:01:53.660 --> 00:01:54.560
years.

00:01:54.560 --> 00:01:57.800
And this is about
25 million papers.

00:01:57.800 --> 00:02:00.860
Now I'm sure that Google
Scholar has better coverage,

00:02:00.860 --> 00:02:04.120
but I couldn't find the exact
numbers for that time period.

00:02:04.120 --> 00:02:04.820
Any guess?

00:02:04.820 --> 00:02:06.520
Maybe it's 30 million.

00:02:06.520 --> 00:02:10.139
That have at least one item
listed under Google Scholar.

00:02:10.139 --> 00:02:12.380
So how many
discoveries do we have

00:02:12.380 --> 00:02:14.950
in science in these
last 15 years?

00:02:14.950 --> 00:02:16.480
Major discoveries?

00:02:16.480 --> 00:02:18.950
Maybe a few thousand?

00:02:18.950 --> 00:02:20.420
I see two.

00:02:20.420 --> 00:02:20.930
OK.

00:02:20.930 --> 00:02:21.700
I'm an optimist.

00:02:21.700 --> 00:02:23.850
I think we have several
thousand, but really not

00:02:23.850 --> 00:02:25.760
15 million discoveries.

00:02:25.760 --> 00:02:29.170
So far less than one
per person, on average.

00:02:29.170 --> 00:02:33.064
Probably one in 1,000, or one in
10,000, maybe one in a million,

00:02:33.064 --> 00:02:34.480
depending on how
you look at that.

00:02:37.570 --> 00:02:39.280
Self-correction should work.

00:02:39.280 --> 00:02:42.990
So even though we don't make
big discoveries all the time,

00:02:42.990 --> 00:02:45.990
we find small pieces that
may be correct or wrong.

00:02:45.990 --> 00:02:49.436
And we can correct
them if they're wrong.

00:02:49.436 --> 00:02:50.810
The ability of
self-correction is

00:02:50.810 --> 00:02:52.768
considered one of the
main features of science.

00:02:52.768 --> 00:02:54.930
In a cumulative
meta-analysis framework,

00:02:54.930 --> 00:02:58.150
if sufficient time elapses,
then we will get to the truth.

00:02:58.150 --> 00:02:59.230
Eventually.

00:02:59.230 --> 00:03:01.980
But the question is how
quickly do we get there?

00:03:01.980 --> 00:03:05.219
Of course we corrected
that the Earth is not

00:03:05.219 --> 00:03:07.010
the center of the world,
and the Sun is not

00:03:07.010 --> 00:03:10.420
going around the Earth, but
it took us about 2,000 years

00:03:10.420 --> 00:03:11.490
to do that.

00:03:11.490 --> 00:03:18.150
So an issue of efficiency arises
on how we could do that faster.

00:03:18.150 --> 00:03:21.410
Self-correction is often not
happening promptly enough.

00:03:21.410 --> 00:03:24.110
It may be impeded by
destruction of evidence,

00:03:24.110 --> 00:03:27.025
production of wrong evidence,
or distortion of evidence.

00:03:30.290 --> 00:03:32.350
Here's the possibilities
of what could happen

00:03:32.350 --> 00:03:35.480
when we have a new
discovery being proposed

00:03:35.480 --> 00:03:36.970
and efforts to replicate it.

00:03:36.970 --> 00:03:41.766
We have the optimal path,
which is that the discovery is

00:03:41.766 --> 00:03:43.390
correct and the
replication is correct.

00:03:43.390 --> 00:03:45.670
The self-correcting,
the discovery was wrong,

00:03:45.670 --> 00:03:47.080
but the replication was correct.

00:03:47.080 --> 00:03:49.430
The false nonreplication,
the discovery was correct

00:03:49.430 --> 00:03:51.280
but the replication was wrong.

00:03:51.280 --> 00:03:53.620
The perpetuated fallacy,
discovery was wrong,

00:03:53.620 --> 00:03:56.050
the replication was also wrong.

00:03:56.050 --> 00:03:57.930
And challenge fallacy,
discovery was wrong

00:03:57.930 --> 00:04:00.310
and replication was not
done, because people

00:04:00.310 --> 00:04:01.810
didn't think that
they should do it.

00:04:01.810 --> 00:04:03.900
And unconfirmed genuine
discovery, the discovery

00:04:03.900 --> 00:04:06.910
was correct and the replication,
again, was not done.

00:04:06.910 --> 00:04:09.240
Now different fields
have different profiles

00:04:09.240 --> 00:04:13.770
of these six options in terms of
their frequency and prevalence.

00:04:13.770 --> 00:04:16.130
And I'm going to
show you some data

00:04:16.130 --> 00:04:18.850
from psychological science.

00:04:18.850 --> 00:04:20.339
This includes a
lot of disciplines.

00:04:20.339 --> 00:04:23.190
And it's summing some
empirical studies

00:04:23.190 --> 00:04:24.790
that were published last year.

00:04:24.790 --> 00:04:27.900
Well, late 2012, a
year and a half ago.

00:04:27.900 --> 00:04:30.620
In "Perspectives on
Psychological Science,"

00:04:30.620 --> 00:04:34.230
I was asked to summarize
all these empirical studies

00:04:34.230 --> 00:04:36.450
on one paper in that same issue.

00:04:36.450 --> 00:04:37.830
And here's how it looks like.

00:04:37.830 --> 00:04:43.930
The optimal represents less
than 1% of that literature.

00:04:43.930 --> 00:04:46.860
The self-correcting,
again, less than 1%.

00:04:46.860 --> 00:04:49.270
False nonreplication,
far less than 1%.

00:04:49.270 --> 00:04:51.435
Perpetuated fallacy, 2%.

00:04:51.435 --> 00:04:53.800
Unconfirmed genuine
discovery, 43%.

00:04:53.800 --> 00:04:56.790
And unchallenged fallacy, 53%.

00:04:56.790 --> 00:04:58.890
There's a lot of uncertainty
in these numbers.

00:04:58.890 --> 00:05:02.580
They could be better than that,
they could be worse than that.

00:05:02.580 --> 00:05:03.100
Yes?

00:05:03.100 --> 00:05:04.808
AUDIENCE: How do we
know it was a fallacy

00:05:04.808 --> 00:05:06.110
if it was unchallenged?

00:05:06.110 --> 00:05:07.680
DR. IOANNIDIS: OK.

00:05:07.680 --> 00:05:09.030
Good question.

00:05:09.030 --> 00:05:12.180
Based on what we
see whenever we do

00:05:12.180 --> 00:05:16.270
take an extra step to do that.

00:05:16.270 --> 00:05:20.070
The only way to
discriminate rigorously

00:05:20.070 --> 00:05:21.770
between these
categories is when we

00:05:21.770 --> 00:05:23.940
do have an effort
at replication.

00:05:23.940 --> 00:05:26.600
So psychological
sciences in general

00:05:26.600 --> 00:05:32.600
have a culture that replication
is not really very advantageous

00:05:32.600 --> 00:05:34.910
for the promotion
of someone's career.

00:05:34.910 --> 00:05:36.400
But many of the
scientific fields

00:05:36.400 --> 00:05:38.550
have developed some
replication culture,

00:05:38.550 --> 00:05:42.790
and we have more evidence
on how frequently results

00:05:42.790 --> 00:05:44.210
do get replicated.

00:05:44.210 --> 00:05:48.400
When we have empirical evidence
in fields where replication

00:05:48.400 --> 00:05:51.832
practices are common, then most
the time most of the initially

00:05:51.832 --> 00:05:53.540
claimed statistically
significant effects

00:05:53.540 --> 00:05:56.640
are either false positives
or substantially exaggerated.

00:05:56.640 --> 00:05:59.180
And here's a few examples.

00:05:59.180 --> 00:06:03.790
This is genetic epidemiology,
where for many years

00:06:03.790 --> 00:06:05.520
we were running
tens of thousands

00:06:05.520 --> 00:06:09.360
of studies in the very same way
that we continue to do research

00:06:09.360 --> 00:06:10.510
in most scientific fields.

00:06:10.510 --> 00:06:12.620
We had a hypothesis.

00:06:12.620 --> 00:06:14.535
In that case, we thought
that one gene may

00:06:14.535 --> 00:06:17.940
be related to some disease,
and we were testing for that.

00:06:17.940 --> 00:06:19.810
And we were coming
up with papers.

00:06:19.810 --> 00:06:22.870
I have published lots of such
papers saying that that gene is

00:06:22.870 --> 00:06:27.350
associated with the risk of
major depressive disorder,

00:06:27.350 --> 00:06:29.870
smoking, acute coronary
syndrome, osteoporosis,

00:06:29.870 --> 00:06:31.920
coronary artery
disease, da-da-da-da-da.

00:06:31.920 --> 00:06:34.590
And then we have a revolution.

00:06:34.590 --> 00:06:37.150
People realize that,
well, we're not really

00:06:37.150 --> 00:06:39.040
making much progress.

00:06:39.040 --> 00:06:40.500
How about joining forces?

00:06:40.500 --> 00:06:42.960
Instead of each one of us
publishing a small study,

00:06:42.960 --> 00:06:46.440
we have lots of studies
coalescing into consortia.

00:06:46.440 --> 00:06:49.420
And we can measure the whole
genome instead of one snippet

00:06:49.420 --> 00:06:50.670
at a time.

00:06:50.670 --> 00:06:52.380
By doing that, we
have the ability

00:06:52.380 --> 00:06:55.410
to try to see what happened
to all of that literature

00:06:55.410 --> 00:06:57.980
where we thought that
we had identified

00:06:57.980 --> 00:07:02.130
57 loci for major depression,
359 loci for smoking,

00:07:02.130 --> 00:07:02.950
and so forth.

00:07:02.950 --> 00:07:04.700
And this is the
replicated gene loci

00:07:04.700 --> 00:07:08.340
in that new agnostic
testing arena.

00:07:08.340 --> 00:07:11.010
The replication rate is 1.1%.

00:07:11.010 --> 00:07:15.230
So 98.9% of the
original discoveries

00:07:15.230 --> 00:07:17.180
were not reproduced.

00:07:17.180 --> 00:07:20.200
And this is pretty much the mode
that most scientific fields,

00:07:20.200 --> 00:07:21.940
especially in
biomedicine, at least,

00:07:21.940 --> 00:07:23.960
are still working at one
hypothesis at a time,

00:07:23.960 --> 00:07:26.010
or a few hypotheses at
a time, or publishing

00:07:26.010 --> 00:07:29.440
one or a few
hypotheses at a time.

00:07:29.440 --> 00:07:30.440
This is one other field.

00:07:30.440 --> 00:07:32.850
This is nutritional
epidemiology.

00:07:32.850 --> 00:07:36.900
And this is an apples and
oranges meta-analysis.

00:07:36.900 --> 00:07:39.150
Actually it's not an apples
and oranges meta-analysis.

00:07:39.150 --> 00:07:44.530
It's a wine and tomatoes and tea
and sugar and salt and potato

00:07:44.530 --> 00:07:46.980
and pork and onion and many
other things meta-analysis.

00:07:46.980 --> 00:07:50.450
So what we tried to
do, we took a cookbook,

00:07:50.450 --> 00:07:51.980
literally, "The
Boston Cookbook,"

00:07:51.980 --> 00:07:54.640
and randomly selected
50 ingredients.

00:07:54.640 --> 00:07:57.010
And we asked the
question for how many

00:07:57.010 --> 00:07:59.790
of these 50 ingredients
that you can eat,

00:07:59.790 --> 00:08:01.600
that-- We just had
lunch, for example.

00:08:01.600 --> 00:08:05.329
Several of them were
probably in what I ate.

00:08:05.329 --> 00:08:07.370
How many of them have
scientific studies claiming

00:08:07.370 --> 00:08:10.860
an increased or decreased
risk for cancer?

00:08:10.860 --> 00:08:12.730
What would be your guess?

00:08:12.730 --> 00:08:13.641
AUDIENCE: 48.

00:08:13.641 --> 00:08:14.390
DR. IOANNIDIS: 48.

00:08:14.390 --> 00:08:15.670
OK.

00:08:15.670 --> 00:08:16.730
Very close.

00:08:16.730 --> 00:08:18.300
We found 40.

00:08:18.300 --> 00:08:20.550
Actually, the other
10 do have studies,

00:08:20.550 --> 00:08:23.250
but we just searched
in a way that we

00:08:23.250 --> 00:08:24.760
tried to find the
exact ingredient.

00:08:24.760 --> 00:08:27.420
So for example, vanilla
was not among the 40.

00:08:27.420 --> 00:08:29.640
It was among the 10 that
we didn't find a study.

00:08:29.640 --> 00:08:32.549
But if you search for vanillin,
which is within vanilla,

00:08:32.549 --> 00:08:35.299
you would have found studies
trying to associate vanillin

00:08:35.299 --> 00:08:37.289
with increased or
decreased cancer risk.

00:08:37.289 --> 00:08:38.880
And this is the effect sizes.

00:08:38.880 --> 00:08:41.299
This is the relative
risks for different types

00:08:41.299 --> 00:08:42.570
of food ingredients.

00:08:42.570 --> 00:08:44.890
And this is for different
types of cancer.

00:08:44.890 --> 00:08:49.370
And these are relative risks of
decrease, if it's less than 1,

00:08:49.370 --> 00:08:54.810
or increase per roughly
one serving per day.

00:08:54.810 --> 00:08:58.080
So if you take
literally a 0.5, it

00:08:58.080 --> 00:09:01.780
means that with one
more serving per day,

00:09:01.780 --> 00:09:05.680
you can halve the
burden of cancer.

00:09:05.680 --> 00:09:10.870
One more serving of
tea, for example.

00:09:10.870 --> 00:09:15.050
According to that study,
you cut cancer risk by 60%.

00:09:15.050 --> 00:09:19.490
One more serving per
day here, so potatoes,

00:09:19.490 --> 00:09:23.300
one more serving per day, you
double the risk of cancer.

00:09:23.300 --> 00:09:25.900
Around the world, one more
serving of potatoes per day

00:09:25.900 --> 00:09:28.930
will double the cancer
risk around the world.

00:09:28.930 --> 00:09:34.680
How many of these estimates do
you think are close to reality?

00:09:34.680 --> 00:09:37.185
Let's say reality
plus, minus 5%.

00:09:39.800 --> 00:09:41.120
[LAUGHTER]

00:09:41.120 --> 00:09:42.000
OK.

00:09:42.000 --> 00:09:43.304
So very, very few.

00:09:43.304 --> 00:09:44.720
And most likely
it's the ones that

00:09:44.720 --> 00:09:48.030
are very close to
that line of 1.

00:09:48.030 --> 00:09:52.000
I'm a professor of medicine
and disease prevention,

00:09:52.000 --> 00:09:54.100
so I do believe that
several of these foods

00:09:54.100 --> 00:09:55.921
do affect cancer risk.

00:09:55.921 --> 00:09:57.420
And I think that
it also makes sense

00:09:57.420 --> 00:10:01.290
to try to promote, for
example, fruits and vegetables

00:10:01.290 --> 00:10:03.630
or to decrease, for
example, I think

00:10:03.630 --> 00:10:05.780
pork has mostly
bad studies there.

00:10:05.780 --> 00:10:08.990
And red meat probably has
increased cancer risk.

00:10:08.990 --> 00:10:11.786
But the best studies, the
ones that are least biased,

00:10:11.786 --> 00:10:13.160
for fruit and
vegetables, suggest

00:10:13.160 --> 00:10:15.230
that with one
serving per day, we

00:10:15.230 --> 00:10:19.710
can have a relative
risk of 0.998.

00:10:19.710 --> 00:10:21.800
So it would be almost
indistinguishable

00:10:21.800 --> 00:10:23.380
to that vertical line of 1.

00:10:23.380 --> 00:10:24.682
But it is a benefit.

00:10:24.682 --> 00:10:26.640
And if you translate it
to a global population,

00:10:26.640 --> 00:10:28.850
it would mean tens of
thousands of people

00:10:28.850 --> 00:10:31.820
would be spared from
cancer if we do that.

00:10:31.820 --> 00:10:33.650
But it's not a 0.5.

00:10:33.650 --> 00:10:34.450
It's not a 2.

00:10:34.450 --> 00:10:38.910
It's not 0.7 or a 1.3.

00:10:38.910 --> 00:10:42.080
Here's one other field,
pharmacoepidemiology.

00:10:42.080 --> 00:10:43.870
Here we had the benefit
of having access

00:10:43.870 --> 00:10:48.590
to the data on prescriptions
for many years,

00:10:48.590 --> 00:10:52.330
and on cancers over many
years, of an entire country.

00:10:52.330 --> 00:10:53.130
Sweden.

00:10:53.130 --> 00:10:54.660
Sweden has amazing registries.

00:10:54.660 --> 00:10:57.260
And our colleagues
Kristina and Jan Sundquist

00:10:57.260 --> 00:11:00.740
at the University of Lund do
have access to these databases.

00:11:00.740 --> 00:11:03.760
So what we did here, we
just did an analysis.

00:11:03.760 --> 00:11:10.036
We are trying to associate all
medications against all cancer.

00:11:10.036 --> 00:11:12.160
There's about 2,000 different
types of medications.

00:11:12.160 --> 00:11:16.550
We grouped them into
550-something clusters,

00:11:16.550 --> 00:11:19.220
because there's several
beta-blockers, for example.

00:11:19.220 --> 00:11:23.280
And here are the
results as p values,

00:11:23.280 --> 00:11:27.540
this is minus log 10 p value,
for different categories

00:11:27.540 --> 00:11:28.630
of medication.

00:11:28.630 --> 00:11:30.420
So these are classes.

00:11:30.420 --> 00:11:37.980
And three out of four medication
classes may affect cancer risk.

00:11:37.980 --> 00:11:38.990
I did this analysis.

00:11:38.990 --> 00:11:41.120
I think it's correct.

00:11:41.120 --> 00:11:43.130
Well, who knows.

00:11:43.130 --> 00:11:46.570
But do you believe
that this is sensible?

00:11:46.570 --> 00:11:49.860
That three out of four
medication classes

00:11:49.860 --> 00:11:52.450
would increase or
decrease cancer risk?

00:11:52.450 --> 00:11:55.140
Some of these p
values-- This is 100.

00:11:55.140 --> 00:12:00.200
It means a p value of
10 to the minus 100.

00:12:00.200 --> 00:12:02.700
Zero point da-da-da.

00:12:02.700 --> 00:12:04.580
Yes.

00:12:04.580 --> 00:12:06.046
It's an amazing number.

00:12:06.046 --> 00:12:07.920
I mean, in terms of
statistical significance,

00:12:07.920 --> 00:12:10.770
you cannot get any
better than that.

00:12:10.770 --> 00:12:14.670
But in fact, it's very likely
that very, very few of these

00:12:14.670 --> 00:12:16.610
medications affect cancer risk.

00:12:16.610 --> 00:12:20.000
What is happening here
is we're facing big data

00:12:20.000 --> 00:12:21.730
with lots of confounding.

00:12:21.730 --> 00:12:24.330
Even if you run the
very best analysis,

00:12:24.330 --> 00:12:26.460
you will see lots
of that confounding

00:12:26.460 --> 00:12:30.970
coming to the surface and giving
you signals right and left.

00:12:30.970 --> 00:12:33.793
Each of them could be
a publishable paper.

00:12:33.793 --> 00:12:35.292
I think we can
publish a few hundred

00:12:35.292 --> 00:12:38.490
papers out of that
project alone.

00:12:38.490 --> 00:12:40.710
Or probably none.

00:12:40.710 --> 00:12:42.830
Now more replication.

00:12:42.830 --> 00:12:45.707
I think if we have replication
in an additional data set,

00:12:45.707 --> 00:12:47.290
some of these problems
will disappear.

00:12:47.290 --> 00:12:48.830
You will not see
it again and again

00:12:48.830 --> 00:12:52.472
unless you have the same biases
appearing again and again.

00:12:52.472 --> 00:12:53.430
Who's going to do that?

00:12:53.430 --> 00:12:56.330
Well, the industry,
recently, has

00:12:56.330 --> 00:12:58.700
been challenged asking
for more replication.

00:12:58.700 --> 00:13:01.160
I have been surprised,
because many years ago I

00:13:01.160 --> 00:13:03.970
was struggling to convince
that we need to replicate some

00:13:03.970 --> 00:13:06.890
of the classics of, for
example, drug intervention.

00:13:06.890 --> 00:13:09.150
And the industry was
very defensive on that.

00:13:09.150 --> 00:13:11.640
But now, when it comes
to pre-clinical research,

00:13:11.640 --> 00:13:14.930
colleagues from
several companies

00:13:14.930 --> 00:13:17.870
have tried to reproduce
academic research done

00:13:17.870 --> 00:13:20.660
in the very best centers by
the very best scientists.

00:13:20.660 --> 00:13:23.840
And trying to see, if I have
pre-clinical drug targets that

00:13:23.840 --> 00:13:25.780
have been published
in the top journals,

00:13:25.780 --> 00:13:28.300
can I reproduce these results?

00:13:28.300 --> 00:13:29.890
Because I want to
use these results

00:13:29.890 --> 00:13:32.120
to be able to
develop my new drug

00:13:32.120 --> 00:13:33.990
to become the new blockbuster.

00:13:33.990 --> 00:13:36.370
So this is how it looks like.

00:13:36.370 --> 00:13:39.610
Very, very bad replication
rates by several teams

00:13:39.610 --> 00:13:44.160
at Amway and Bayer
and other companies.

00:13:44.160 --> 00:13:48.260
70 to 89% nonreplication.

00:13:48.260 --> 00:13:51.650
For the Amgen project, only
six of the 53 landmark studies

00:13:51.650 --> 00:13:53.860
could be reproduced.

00:13:53.860 --> 00:13:57.370
And that was even after asking
the original investigators

00:13:57.370 --> 00:13:59.610
to specify exactly
what they were

00:13:59.610 --> 00:14:02.080
doing to get these results.

00:14:02.080 --> 00:14:04.941
So the conclusions in that
paper, for example in "Nature"

00:14:04.941 --> 00:14:06.440
a couple years ago,
that the failure

00:14:06.440 --> 00:14:09.200
to win the war on cancer has
been blamed on many factors,

00:14:09.200 --> 00:14:11.060
but recently a new
culprit has emerged.

00:14:11.060 --> 00:14:13.480
Too many basic scientific
discoveries are just wrong.

00:14:16.060 --> 00:14:18.330
This means that
hedge funds often

00:14:18.330 --> 00:14:20.960
don't trust science nowadays.

00:14:20.960 --> 00:14:23.230
This is a statement
from a journal

00:14:23.230 --> 00:14:25.760
that I don't read routinely.

00:14:25.760 --> 00:14:28.000
It's in the interface
of business and science.

00:14:28.000 --> 00:14:30.170
It says that at least
50% of published studies,

00:14:30.170 --> 00:14:31.929
even those in top-tier
academic journals,

00:14:31.929 --> 00:14:34.470
cannot be repeated with the same
conclusions by an industrial

00:14:34.470 --> 00:14:35.200
lab.

00:14:35.200 --> 00:14:37.880
And the potential for not being
able to reproduce academic data

00:14:37.880 --> 00:14:40.640
is a disincentive to
early-stage investors.

00:14:40.640 --> 00:14:42.800
At least one venture
capital, [INAUDIBLE]

00:14:42.800 --> 00:14:44.510
and now there's
far more than that,

00:14:44.510 --> 00:14:46.960
is hiring contract
research organizations

00:14:46.960 --> 00:14:49.190
to independently validate
academic science prior

00:14:49.190 --> 00:14:50.700
to putting up serious money.

00:14:50.700 --> 00:14:53.990
Which means that this is bad
news for me as a Stanford

00:14:53.990 --> 00:14:54.930
professor.

00:14:54.930 --> 00:14:58.460
It means that my work,
I'm doing that maybe

00:14:58.460 --> 00:15:01.090
for fun, to get promoted,
to get my next grant,

00:15:01.090 --> 00:15:03.420
but if you really
want to trust my work,

00:15:03.420 --> 00:15:05.050
find someone else to repeat it.

00:15:05.050 --> 00:15:07.450
Otherwise you cannot
take it for granted.

00:15:07.450 --> 00:15:09.970
I need to fight back to
regain my reputation.

00:15:09.970 --> 00:15:12.280
I think it's extremely
important that I

00:15:12.280 --> 00:15:15.190
don't leave that perception
to be floating around.

00:15:17.820 --> 00:15:20.270
Some countries are probably
even worse in that regard.

00:15:20.270 --> 00:15:23.880
And this is a piece of work
that I did with Dan Fanelli

00:15:23.880 --> 00:15:27.480
and came out about six
months ago in "PNAS."

00:15:27.480 --> 00:15:29.370
We used data from two extremes.

00:15:29.370 --> 00:15:32.770
One is genomics, where
measurement is very accurate,

00:15:32.770 --> 00:15:35.250
and the other is
psychology and psychiatry

00:15:35.250 --> 00:15:37.250
and behavioral sciences,
where the measurement's

00:15:37.250 --> 00:15:39.100
pretty subjective.

00:15:39.100 --> 00:15:40.630
And we asked the
question is there

00:15:40.630 --> 00:15:43.300
more bias in one field
versus the other?

00:15:43.300 --> 00:15:45.730
And is there more bias
with extreme results

00:15:45.730 --> 00:15:49.880
in studies coming from specific
countries versus others?

00:15:49.880 --> 00:15:52.920
What we found, number
one, there is bias.

00:15:52.920 --> 00:15:53.760
Probably.

00:15:53.760 --> 00:15:56.180
Small studies tend to give
exaggerated results which

00:15:56.180 --> 00:15:58.290
are not seen in larger studies.

00:15:58.290 --> 00:15:59.590
In both fields.

00:15:59.590 --> 00:16:01.890
But when it comes to
subjective outcomes

00:16:01.890 --> 00:16:05.110
like behavioral sciences,
then the US studies

00:16:05.110 --> 00:16:08.600
are far more likely to
find extreme results.

00:16:08.600 --> 00:16:10.080
Why is that?

00:16:10.080 --> 00:16:11.830
One might argue
that maybe there's

00:16:11.830 --> 00:16:13.360
more pressure in the US.

00:16:13.360 --> 00:16:15.760
Or at least this is reflecting
studies done, on average,

00:16:15.760 --> 00:16:18.470
a few years ago to
several years ago.

00:16:18.470 --> 00:16:20.429
Maybe for an academic
investigator,

00:16:20.429 --> 00:16:22.720
there's more pressure to
deliver a significant finding,

00:16:22.720 --> 00:16:24.719
an extreme finding, in
order to get it published

00:16:24.719 --> 00:16:27.160
in a major journal and
continue to get funded.

00:16:27.160 --> 00:16:29.970
I think this has become
probably a global perspective

00:16:29.970 --> 00:16:33.250
at the moment, but maybe
when we analyzed these data,

00:16:33.250 --> 00:16:35.275
it was far more prominent
in the United States.

00:16:37.980 --> 00:16:39.930
Why research findings
may not be credible?

00:16:39.930 --> 00:16:41.760
Is there something
wrong with science?

00:16:41.760 --> 00:16:42.970
There's nothing
wrong with science.

00:16:42.970 --> 00:16:43.390
There's nothing
wrong with science.

00:16:43.390 --> 00:16:46.149
I think science is the best
that we have, as human beings,

00:16:46.149 --> 00:16:48.190
to understand the world,
to understand ourselves,

00:16:48.190 --> 00:16:50.380
to understand what
is happening and what

00:16:50.380 --> 00:16:52.380
might happen in the future.

00:16:52.380 --> 00:16:55.420
But unavoidably, there is bias.

00:16:55.420 --> 00:16:56.990
And also there's random error.

00:16:56.990 --> 00:16:59.250
Which means lots of
comparisons being done.

00:16:59.250 --> 00:17:01.030
And usually there's
plenty of both.

00:17:01.030 --> 00:17:03.990
And the question is can we
dissect these two forces

00:17:03.990 --> 00:17:06.760
and minimize them?

00:17:06.760 --> 00:17:08.839
How many biases are out there?

00:17:08.839 --> 00:17:09.800
I don't know.

00:17:09.800 --> 00:17:13.030
I'm considered to be an expert
on bias, but I had no clue.

00:17:13.030 --> 00:17:16.190
So I was trying to
create a list of bias,

00:17:16.190 --> 00:17:18.550
and when I met [INAUDIBLE]
a number of years ago,

00:17:18.550 --> 00:17:22.319
he said, "Why don't we have the
computer read the entire PubMed

00:17:22.319 --> 00:17:25.369
overnight and tell us how
many biases we can identify."

00:17:25.369 --> 00:17:28.520
So this is a galaxy of biases.

00:17:28.520 --> 00:17:33.360
It's 235 biases mapped across
17 million PubMed papers.

00:17:33.360 --> 00:17:36.090
I have to say I have never
heard about a third of them.

00:17:36.090 --> 00:17:38.440
And I'm considered
to be an expert.

00:17:38.440 --> 00:17:40.570
How many of these biases
do I think ahead of time

00:17:40.570 --> 00:17:42.280
when I design a new study?

00:17:42.280 --> 00:17:43.576
Probably very few.

00:17:43.576 --> 00:17:45.450
But this doesn't mean
that they do not exist.

00:17:45.450 --> 00:17:50.330
So even methodologists
cannot really anticipate all

00:17:50.330 --> 00:17:53.040
the biases that may occur.

00:17:53.040 --> 00:17:55.330
This is a time array
for biases slide.

00:17:55.330 --> 00:17:58.600
It shows how popular they are in
the literature, how many people

00:17:58.600 --> 00:17:59.910
are talking about them.

00:17:59.910 --> 00:18:02.320
So if you see white color,
it means that they are hot.

00:18:02.320 --> 00:18:04.120
People are discussing them.

00:18:04.120 --> 00:18:06.690
Here's an error, 1882.

00:18:06.690 --> 00:18:10.140
One of the many errors,
probably, I have made.

00:18:10.140 --> 00:18:12.776
And if you see black, it means
that no one is interested.

00:18:12.776 --> 00:18:14.400
There's no papers
discussing that bias.

00:18:14.400 --> 00:18:17.450
However, even when people are
discussing about bias-- so

00:18:17.450 --> 00:18:20.220
for example, "confounding"
is the most common bias term

00:18:20.220 --> 00:18:23.170
in the literature, and
since the late 1970s

00:18:23.170 --> 00:18:26.550
it has been discussed by
many, many papers-- what

00:18:26.550 --> 00:18:28.710
do people say about confounding?

00:18:28.710 --> 00:18:30.650
Every epidemiological
paper in the discussion

00:18:30.650 --> 00:18:32.570
will say confounding
is a problem

00:18:32.570 --> 00:18:34.130
with epidemiological studies.

00:18:34.130 --> 00:18:37.650
However, our study does
not have that problem.

00:18:37.650 --> 00:18:40.980
Because we did a very
good job in whatever way.

00:18:40.980 --> 00:18:41.886
Yes?

00:18:41.886 --> 00:18:43.830
AUDIENCE: Could you briefly
explain what confounding means?

00:18:43.830 --> 00:18:45.288
DR. IOANNIDIS: So
confounding means

00:18:45.288 --> 00:18:51.210
that you have some exposure
that is related both to the risk

00:18:51.210 --> 00:18:53.400
factor that you're
interested to study

00:18:53.400 --> 00:18:58.050
and with the outcome that
you're interested to study.

00:18:58.050 --> 00:19:01.292
But the effect does not
go through the risk factor

00:19:01.292 --> 00:19:02.250
that you want to study.

00:19:02.250 --> 00:19:03.850
This is the official definition.

00:19:03.850 --> 00:19:06.820
Practically, it means that
the two groups that you're

00:19:06.820 --> 00:19:09.480
comparing to try to see
if the risk factor has

00:19:09.480 --> 00:19:12.710
an impact on the
outcome are unbalanced

00:19:12.710 --> 00:19:15.910
in an important way in
regard to that confounder.

00:19:15.910 --> 00:19:18.400
The confounder is not the same
in those who have the risk

00:19:18.400 --> 00:19:21.540
factor and those who do
not have the risk factor.

00:19:21.540 --> 00:19:24.894
So it's the main reason
why in the analysis

00:19:24.894 --> 00:19:26.310
of the medications,
for example, I

00:19:26.310 --> 00:19:28.380
see that 3/4 of the
classes of medications

00:19:28.380 --> 00:19:30.730
have an association
with cancer risk.

00:19:30.730 --> 00:19:31.780
It's confounding.

00:19:31.780 --> 00:19:34.650
Confounding by indication,
in that case, most likely.

00:19:34.650 --> 00:19:36.320
And other types of confounding.

00:19:36.320 --> 00:19:38.330
But most of the times
that we discuss bias,

00:19:38.330 --> 00:19:41.810
we do that to try to say
that our study is protected.

00:19:41.810 --> 00:19:43.200
Same thing for publication bias.

00:19:43.200 --> 00:19:45.919
Publication bias is a very
popular term in meta-analysis.

00:19:45.919 --> 00:19:48.210
Almost every meta-analysis,
if you read the discussion,

00:19:48.210 --> 00:19:50.910
it says publication bias
is a threat to analysis,

00:19:50.910 --> 00:19:53.590
however, our meta-analysis
is probably immune to that

00:19:53.590 --> 00:19:56.880
or not affected,
because we did x or y,

00:19:56.880 --> 00:19:59.860
or we think that it's
not a problem here.

00:20:02.750 --> 00:20:05.910
In many cases, when we have
the benefit of multiple studies

00:20:05.910 --> 00:20:07.920
that try to replicate
the original findings,

00:20:07.920 --> 00:20:09.940
we see that correction
of the bias.

00:20:09.940 --> 00:20:11.550
So these are
genetic associations

00:20:11.550 --> 00:20:14.890
that were proposed many years
ago in leading journals.

00:20:14.890 --> 00:20:17.680
And when they were proposed,
they were highly cited papers,

00:20:17.680 --> 00:20:19.850
they were highly statistically
significant results.

00:20:19.850 --> 00:20:23.270
But as we did more studies
on the very same association,

00:20:23.270 --> 00:20:26.450
the cumulative odds ratio
gravitated towards the null.

00:20:26.450 --> 00:20:28.525
And at the end of the
day, at the latest update,

00:20:28.525 --> 00:20:30.900
there was no longer any signal
that it was even nominally

00:20:30.900 --> 00:20:32.430
statistically significant.

00:20:32.430 --> 00:20:34.660
However, to do that, you
need a replication culture.

00:20:34.660 --> 00:20:36.100
You need a situation
where people

00:20:36.100 --> 00:20:38.740
are willing to perform these
additional replications.

00:20:38.740 --> 00:20:41.240
And as I said, this
is not very frequent.

00:20:44.680 --> 00:20:45.410
Question.

00:20:45.410 --> 00:20:46.376
AUDIENCE: The graphic
in the last slide,

00:20:46.376 --> 00:20:48.791
is that possibly explaining
[INAUDIBLE] regression

00:20:48.791 --> 00:20:51.690
to the mean about
that publication bias?

00:20:51.690 --> 00:20:54.300
DR. IOANNIDIS: So the question
is whether this behavior would

00:20:54.300 --> 00:20:57.770
be attributed also to a
regression to the mean.

00:20:57.770 --> 00:20:59.820
It could be, to some extent.

00:20:59.820 --> 00:21:02.830
And some of these
diminishing effects

00:21:02.830 --> 00:21:05.560
could be regression to the
mean for some effects that

00:21:05.560 --> 00:21:09.420
are genuine but inflated
when we first discover them.

00:21:09.420 --> 00:21:11.644
And I think I'll show
some examples about that.

00:21:11.644 --> 00:21:13.310
In most of these cases
that I show here,

00:21:13.310 --> 00:21:17.060
I think the most likely scenario
is that they were just null.

00:21:17.060 --> 00:21:19.920
And were chance findings
that we perform replication,

00:21:19.920 --> 00:21:20.656
they go away.

00:21:20.656 --> 00:21:22.530
But the possibility of
regression to the mean

00:21:22.530 --> 00:21:25.125
is there for other situations.

00:21:25.125 --> 00:21:27.410
AUDIENCE: What's the
difference between those two?

00:21:27.410 --> 00:21:29.369
They seem like kind
of the same things.

00:21:29.369 --> 00:21:30.910
Publish the most
interesting results,

00:21:30.910 --> 00:21:32.076
they'll regress to the mean.

00:21:32.076 --> 00:21:33.300
DR. IOANNIDIS: Yeah.

00:21:33.300 --> 00:21:35.930
What is the difference between
the two is that in one case,

00:21:35.930 --> 00:21:38.370
there's absolutely nothing.

00:21:38.370 --> 00:21:39.960
And we have an
exaggerated result

00:21:39.960 --> 00:21:43.190
that reflects a
completely null truth.

00:21:43.190 --> 00:21:45.100
And the second
possibility is that we

00:21:45.100 --> 00:21:50.020
have an exaggerated result that
reflects some truth, partially.

00:21:50.020 --> 00:21:52.350
There is a signal,
there's a true signal,

00:21:52.350 --> 00:21:54.430
but it's not as big
as we have found.

00:21:54.430 --> 00:21:56.362
So qualitatively,
it is different.

00:21:56.362 --> 00:21:57.570
In one case, there's nothing.

00:21:57.570 --> 00:21:59.300
In the other case,
there is something.

00:21:59.300 --> 00:22:01.232
In terms of the
magnitude of the fact,

00:22:01.232 --> 00:22:02.690
if you look at the
exaggeration, it

00:22:02.690 --> 00:22:07.080
could be equally big
in both circumstances.

00:22:07.080 --> 00:22:09.860
This is another empirical
evaluation looking at the creme

00:22:09.860 --> 00:22:12.190
de la creme of
clinical research.

00:22:12.190 --> 00:22:14.670
What I've looked at
here is the studies

00:22:14.670 --> 00:22:17.930
that were published
in any medical journal

00:22:17.930 --> 00:22:20.790
and have been the most
cited in the literature.

00:22:20.790 --> 00:22:23.430
So those that got more
than 1,000 citations.

00:22:23.430 --> 00:22:26.160
And trying to see whether
additional studies were done

00:22:26.160 --> 00:22:29.390
down the road to see if
they would replicate what

00:22:29.390 --> 00:22:31.390
the original studies
had proposed.

00:22:31.390 --> 00:22:33.790
Five out of six
nonrandomized studies

00:22:33.790 --> 00:22:34.910
could not be replicated.

00:22:34.910 --> 00:22:37.840
They were found to be either
completely wrong or grossly

00:22:37.840 --> 00:22:39.130
exaggerated.

00:22:39.130 --> 00:22:42.390
And about 25% of
randomized trials

00:22:42.390 --> 00:22:45.340
were also found to be either
completely wrong or grossly

00:22:45.340 --> 00:22:45.970
exaggerated.

00:22:45.970 --> 00:22:47.620
And this is the
creme de la creme.

00:22:47.620 --> 00:22:50.010
This is the most influential
clinical research,

00:22:50.010 --> 00:22:53.100
and this is the type
of nonreplication rate

00:22:53.100 --> 00:22:54.380
that we witness.

00:22:54.380 --> 00:22:56.630
AUDIENCE: What does "randomized"
mean in that context?

00:22:56.630 --> 00:22:58.004
DR. IOANNIDIS:
"Randomized" means

00:22:58.004 --> 00:23:00.500
that this is clinical
research, so we

00:23:00.500 --> 00:23:02.940
want to see whether a
drug or a lifestyle change

00:23:02.940 --> 00:23:06.230
or whatever is effective
in reducing mortality

00:23:06.230 --> 00:23:08.650
or cardiovascular deaths
or cancer or whatever.

00:23:08.650 --> 00:23:13.800
So we randomly create
the two populations

00:23:13.800 --> 00:23:16.410
that will get the intervention
or not get the intervention.

00:23:16.410 --> 00:23:19.570
So it's the best way that
we can study interventions,

00:23:19.570 --> 00:23:22.670
because it's as
unbiased as it could be.

00:23:22.670 --> 00:23:25.090
The two groups are
generated by chance,

00:23:25.090 --> 00:23:27.330
and therefore they should
be similar in terms

00:23:27.330 --> 00:23:29.970
of whatever other
characteristics they have.

00:23:29.970 --> 00:23:32.100
If they're not similar,
then we have the potential

00:23:32.100 --> 00:23:34.100
for confounding that we
were mentioning earlier.

00:23:37.140 --> 00:23:40.920
So much of the
time, what we get is

00:23:40.920 --> 00:23:43.600
what I would call excess
significance bias.

00:23:43.600 --> 00:23:45.910
People want to get
significant results.

00:23:45.910 --> 00:23:48.860
And the ways to do
that are manifold.

00:23:48.860 --> 00:23:50.860
But at the end of the
day, they boil down

00:23:50.860 --> 00:23:52.714
to three different mechanisms.

00:23:52.714 --> 00:23:54.630
Results that become
positive while they should

00:23:54.630 --> 00:23:56.910
have been negative.

00:23:56.910 --> 00:23:59.820
Results that are negative
that are being suppressed.

00:23:59.820 --> 00:24:01.534
Never published, not visible.

00:24:01.534 --> 00:24:02.950
And fake positive
results that are

00:24:02.950 --> 00:24:04.939
being created out of vacuum.

00:24:04.939 --> 00:24:06.480
There's no data,
there's no patients,

00:24:06.480 --> 00:24:08.830
there's no information
in reality,

00:24:08.830 --> 00:24:11.080
and someone creates
a fake paper.

00:24:11.080 --> 00:24:13.670
I don't think that the
third mechanism is common.

00:24:13.670 --> 00:24:19.110
Scientists are not saints, but
I think that on average, we're

00:24:19.110 --> 00:24:22.360
a very honest bunch of people.

00:24:22.360 --> 00:24:25.270
You may see cases
of fraud coming

00:24:25.270 --> 00:24:28.140
to the forefront
of the news, but I

00:24:28.140 --> 00:24:30.120
think this is a very
uncommon scenario.

00:24:30.120 --> 00:24:32.580
I don't think that someone
would waste their whole life

00:24:32.580 --> 00:24:37.520
to be trained as a scientist
to be a fraudulent manipulator.

00:24:37.520 --> 00:24:39.810
But results that are
negative that are suppressed

00:24:39.810 --> 00:24:41.080
are probably not uncommon.

00:24:41.080 --> 00:24:43.520
And I think this first
mechanism-- results

00:24:43.520 --> 00:24:47.910
that are really negative when
the original intention, what

00:24:47.910 --> 00:24:51.460
was the original protocol,
the original hypothesis,

00:24:51.460 --> 00:24:53.680
they do become
positive by changing

00:24:53.680 --> 00:24:56.710
that analysis by adding an
extra layer of exploration

00:24:56.710 --> 00:24:59.646
to the data set-- I think
this probably pretty common.

00:24:59.646 --> 00:25:01.520
At the end of the day,
the common consequence

00:25:01.520 --> 00:25:03.155
of all these practices
is an inflation

00:25:03.155 --> 00:25:05.800
in the proportion of
observed positive results.

00:25:05.800 --> 00:25:07.850
And that means
that one would have

00:25:07.850 --> 00:25:09.900
too many studies with
significant results.

00:25:09.900 --> 00:25:12.540
That would mean even
seemingly replicated results

00:25:12.540 --> 00:25:14.670
in the same question.

00:25:14.670 --> 00:25:17.170
Too many significant
results is not necessarily

00:25:17.170 --> 00:25:18.280
a sign of replication.

00:25:18.280 --> 00:25:20.830
It could mean something
is going wrong here.

00:25:20.830 --> 00:25:26.150
And here's one indirect
insight into this.

00:25:26.150 --> 00:25:30.050
This is another paper by
Dan Fanelli where there's

00:25:30.050 --> 00:25:33.240
a sample of papers evaluated
across different scientific

00:25:33.240 --> 00:25:34.290
fields.

00:25:34.290 --> 00:25:36.060
And the conclusion
is that fields

00:25:36.060 --> 00:25:40.250
that have more rigorous
research practices and more

00:25:40.250 --> 00:25:43.750
rigorous criteria for claiming
discoveries, like physics

00:25:43.750 --> 00:25:45.470
and space science,
for example, they

00:25:45.470 --> 00:25:47.780
have the lowest proportion
of statistically significant

00:25:47.780 --> 00:25:49.840
results in their literature.

00:25:49.840 --> 00:25:52.820
Conversely, fields like
psychiatry, psychology,

00:25:52.820 --> 00:25:55.790
clinical medicine, pharmacology,
toxicology, material science,

00:25:55.790 --> 00:25:58.850
they have about 90%,
sometimes more than that.

00:25:58.850 --> 00:26:02.940
There's some journals that only
publish significant papers.

00:26:02.940 --> 00:26:06.140
You take a whole issue and it's
only significant papers there.

00:26:06.140 --> 00:26:09.487
They have a 95% or
more, sometimes,

00:26:09.487 --> 00:26:11.320
significant results
that they get published.

00:26:11.320 --> 00:26:14.890
This is just too
good to be true.

00:26:14.890 --> 00:26:19.070
And the question, then, is
what do we do with that?

00:26:19.070 --> 00:26:21.210
What solutions might we have?

00:26:21.210 --> 00:26:23.850
And I will discuss a few of
these potential solutions

00:26:23.850 --> 00:26:28.730
in the last 10, 15 minutes.

00:26:28.730 --> 00:26:31.640
One is to learn to live
with small and tiny effects.

00:26:31.640 --> 00:26:33.520
I know that maybe
this is not very

00:26:33.520 --> 00:26:36.230
attractive to say in Silicon
Valley, where everybody says

00:26:36.230 --> 00:26:39.130
that we have the new major
discovery of the future,

00:26:39.130 --> 00:26:43.490
of the 21st century, or the
third millennium, or whatever.

00:26:43.490 --> 00:26:46.965
Yes, that would be great, but
most of the genuine effects

00:26:46.965 --> 00:26:50.220
that we are going
to find and document

00:26:50.220 --> 00:26:51.810
are going to be pretty small.

00:26:51.810 --> 00:26:54.890
There's an empirical
evaluation of risk factors

00:26:54.890 --> 00:26:57.190
and interventions
with tiny effects,

00:26:57.190 --> 00:27:00.580
meaning odds ratios
less than 1.05.

00:27:00.580 --> 00:27:02.110
I think many of those are real.

00:27:02.110 --> 00:27:04.700
And actually, in many
sizes, these tiny effects

00:27:04.700 --> 00:27:06.720
are likely to be the
majority of them.

00:27:06.720 --> 00:27:09.470
In biological sciences, I
think, most of the effects

00:27:09.470 --> 00:27:11.940
to be discovered are likely
to be very, very small.

00:27:11.940 --> 00:27:14.286
Maybe even smaller than 1.05.

00:27:14.286 --> 00:27:16.410
One of them alone is not
going to change the world.

00:27:16.410 --> 00:27:18.110
But a thousand of them?

00:27:18.110 --> 00:27:20.810
If we can combine information
from 1,000 tiny effects,

00:27:20.810 --> 00:27:23.050
we would get more than
a major discovery.

00:27:23.050 --> 00:27:26.580
So we may just need to
realign our expectations

00:27:26.580 --> 00:27:28.950
about what we're chasing.

00:27:28.950 --> 00:27:34.280
Second possibility is to
try to rigorously replicate

00:27:34.280 --> 00:27:36.960
whatever large effects we find.

00:27:36.960 --> 00:27:39.170
If you're talking
about single studies,

00:27:39.170 --> 00:27:40.880
large effects are pretty common.

00:27:40.880 --> 00:27:42.410
So this is an
empirical evaluation

00:27:42.410 --> 00:27:46.030
where we looked at half
of the medical literature

00:27:46.030 --> 00:27:47.370
for clinical trials.

00:27:47.370 --> 00:27:51.440
We used data from 220,000
clinical trials' worth of data

00:27:51.440 --> 00:27:54.960
that had been included in 85,000
meta-analyses in the Cochrane

00:27:54.960 --> 00:27:57.690
Collaboration, Cochrane Library.

00:27:57.690 --> 00:28:01.710
And this covers any type
of medical intervention.

00:28:01.710 --> 00:28:06.530
How often do you think, across
this whole medicine evidence,

00:28:06.530 --> 00:28:10.320
do we have interventions that
pertain to mortality risk,

00:28:10.320 --> 00:28:13.500
they reduce mortality
risk by fivefold--

00:28:13.500 --> 00:28:16.110
so if 10 people were to
die only two or fewer

00:28:16.110 --> 00:28:21.660
are going to die-- significant
results at p value of 0.001

00:28:21.660 --> 00:28:26.160
or less, and no clear
evidence for huge bias

00:28:26.160 --> 00:28:27.960
that you can easily discern?

00:28:27.960 --> 00:28:30.760
So this is the entire
medicine, more or less,

00:28:30.760 --> 00:28:32.520
220,000 randomized trials.

00:28:32.520 --> 00:28:35.700
Or, well, to be exact,
about half of it.

00:28:35.700 --> 00:28:38.940
How many medical
interventions can do that?

00:28:38.940 --> 00:28:42.530
Increased mortality fivefold
and have really strong support

00:28:42.530 --> 00:28:43.670
from clinical trials?

00:28:43.670 --> 00:28:44.460
Any guess?

00:28:44.460 --> 00:28:47.300
Out of the 85,000 meta-analyses?

00:28:47.300 --> 00:28:48.370
Close to zero.

00:28:48.370 --> 00:28:50.120
We found one.

00:28:50.120 --> 00:28:51.700
So not zero.

00:28:51.700 --> 00:28:53.320
There is a few more.

00:28:53.320 --> 00:28:55.292
And I said this is not
the entire medicine,

00:28:55.292 --> 00:28:57.250
and there is some
interventions that have never

00:28:57.250 --> 00:28:59.210
been tested in clinical trials.

00:28:59.210 --> 00:29:03.700
So insulin for diabetes
was discovered before even

00:29:03.700 --> 00:29:05.290
randomized trials
were discovered.

00:29:05.290 --> 00:29:07.130
But really there's
very, very few

00:29:07.130 --> 00:29:10.760
that achieve such huge benefits
and are well documented.

00:29:10.760 --> 00:29:14.600
Extracorporeal oxygenation
for premature babies.

00:29:14.600 --> 00:29:17.520
It does have such a huge effect.

00:29:17.520 --> 00:29:20.860
So the question
that one has to ask

00:29:20.860 --> 00:29:26.450
is how much vibration of
effects is there in the results

00:29:26.450 --> 00:29:26.950
that I see?

00:29:26.950 --> 00:29:29.130
By vibration of
effects, I mean how many

00:29:29.130 --> 00:29:33.600
opportunities have there been
in the background of that result

00:29:33.600 --> 00:29:35.432
to be obtained?

00:29:35.432 --> 00:29:37.890
Has there been only one analysis
that would have been done,

00:29:37.890 --> 00:29:40.670
or is it multiple analyses, and
maybe people have cherry-picked

00:29:40.670 --> 00:29:42.420
what analyses they
wanted to present?

00:29:42.420 --> 00:29:44.400
And this is a manifestation
of the vibration

00:29:44.400 --> 00:29:46.550
of effects in grand scale.

00:29:46.550 --> 00:29:49.340
That's a study that I did
with Chirag Patel and Melinda

00:29:49.340 --> 00:29:52.270
Burford where we tried to
evaluate different risk

00:29:52.270 --> 00:29:54.550
factors for mortality
in NHANES, which

00:29:54.550 --> 00:29:59.340
is a large database from a
household survey in the US.

00:29:59.340 --> 00:30:01.990
And we ask the question can
you get different results

00:30:01.990 --> 00:30:05.640
if you analyze the
same data differently?

00:30:05.640 --> 00:30:07.184
And for each one
of these data sets,

00:30:07.184 --> 00:30:09.350
we have analyzed the same
association, the same risk

00:30:09.350 --> 00:30:11.710
factor, in about a
million different ways.

00:30:11.710 --> 00:30:13.750
And this is the
cloud of the results.

00:30:13.750 --> 00:30:16.900
The p value and the hazard
ratio that you get for death.

00:30:16.900 --> 00:30:19.690
There's lots of risk
factors, like vitamin E

00:30:19.690 --> 00:30:23.164
here, alpha-tocopherol,
that you can get this shape,

00:30:23.164 --> 00:30:25.580
which suggests that depending
on how you analyze the data,

00:30:25.580 --> 00:30:28.700
you can get a result to suggest
that alpha-tocopherol increases

00:30:28.700 --> 00:30:30.850
mortality, or you
can get a result that

00:30:30.850 --> 00:30:33.370
shows that alpha-tocopherol
increases mortality.

00:30:33.370 --> 00:30:35.780
So you can get decrease,
increase, no effect,

00:30:35.780 --> 00:30:36.900
whatever you wish.

00:30:36.900 --> 00:30:40.220
If you're a believer that
alpha-tocopherol should do x,

00:30:40.220 --> 00:30:41.360
you can get that x.

00:30:41.360 --> 00:30:43.940
I mean, just play with the data
and you'll get what you want.

00:30:47.490 --> 00:30:49.640
Another possibility
is to promote

00:30:49.640 --> 00:30:50.900
large-scale collaboration.

00:30:50.900 --> 00:30:52.560
So I showed you
the example where

00:30:52.560 --> 00:30:56.560
we thought that we had
found 359 gene loci that

00:30:56.560 --> 00:30:58.750
regulate smoking behavior.

00:30:58.750 --> 00:31:02.460
When we decided to join forces
and perform a very large study,

00:31:02.460 --> 00:31:05.790
a consortium study, with very
rigorous statistical methods

00:31:05.790 --> 00:31:09.600
and look across the whole
genome, we found only four.

00:31:09.600 --> 00:31:13.970
And actually only none of
these four was one of the 359

00:31:13.970 --> 00:31:16.430
that we thought would be there.

00:31:16.430 --> 00:31:19.682
So we killed 359, we found four.

00:31:19.682 --> 00:31:21.390
Since we published
that study, the number

00:31:21.390 --> 00:31:24.340
is up to seven that have
been well documented.

00:31:24.340 --> 00:31:25.110
Is that bad news?

00:31:25.110 --> 00:31:26.360
I would say this is good news.

00:31:26.360 --> 00:31:28.300
We have seven now that
we know are genuine.

00:31:28.300 --> 00:31:30.190
They have very strong
statistical support,

00:31:30.190 --> 00:31:33.270
very rigorous replication
across all these teams

00:31:33.270 --> 00:31:35.640
that have joined forces.

00:31:35.640 --> 00:31:37.850
Reporting of research could
also make a difference.

00:31:37.850 --> 00:31:40.120
Many papers are very
difficult to understand

00:31:40.120 --> 00:31:41.270
what is happening.

00:31:41.270 --> 00:31:43.770
The methods are very
sketchy, the results

00:31:43.770 --> 00:31:47.450
are fragmented, and forget
about the discussion.

00:31:47.450 --> 00:31:49.410
So there's lots of
efforts, and all these

00:31:49.410 --> 00:31:51.850
have been brought under
the umbrella of the EQUATOR

00:31:51.850 --> 00:31:56.360
Network led by Doug Altman at
Oxford, trying to put together

00:31:56.360 --> 00:31:59.377
all these efforts to standardize
reporting of research

00:31:59.377 --> 00:32:00.960
results of different
types of designs.

00:32:03.640 --> 00:32:07.050
Registration, I think, could
also make a difference.

00:32:07.050 --> 00:32:10.960
You can think of studies' being
registered ahead of time rather

00:32:10.960 --> 00:32:13.820
than just wait for studies
to appear out of the blue.

00:32:13.820 --> 00:32:15.790
You know that a
study does exist.

00:32:15.790 --> 00:32:18.580
And I think that
the major problem,

00:32:18.580 --> 00:32:20.510
as I tried to describe
in that paper in "JAMA"

00:32:20.510 --> 00:32:23.560
is not really papers
on studies that exist.

00:32:23.560 --> 00:32:27.330
I worry mostly about
studies that don't exist.

00:32:27.330 --> 00:32:29.320
And you may think
that I'm paranoid.

00:32:29.320 --> 00:32:33.520
But let me try to explain why I
fear studies that don't exist.

00:32:33.520 --> 00:32:35.320
I fear studies that
could potentially

00:32:35.320 --> 00:32:39.180
exist if someone were to spend
the time to create that study.

00:32:39.180 --> 00:32:41.180
So we have a data set.

00:32:41.180 --> 00:32:43.050
There's millions of
studies that could

00:32:43.050 --> 00:32:44.710
be created out of that data set.

00:32:44.710 --> 00:32:47.210
So what I would like
to know is really

00:32:47.210 --> 00:32:49.300
what data sets are
out there and what

00:32:49.300 --> 00:32:50.760
could be done with
these data sets.

00:32:50.760 --> 00:32:51.760
What is the potential?

00:32:51.760 --> 00:32:54.590
It's like mapping
nuclear weapons.

00:32:54.590 --> 00:32:57.320
None of them has have been sent.

00:32:57.320 --> 00:32:59.890
The missiles are not
sent to target yet,

00:32:59.890 --> 00:33:03.130
but it's good to know that
there's 10,000 missiles that

00:33:03.130 --> 00:33:04.480
could be launched at some point.

00:33:07.310 --> 00:33:09.420
And these are the different
levels of registration

00:33:09.420 --> 00:33:12.250
that you can think of
for any scientific study.

00:33:12.250 --> 00:33:14.490
Level zero would
be no registration.

00:33:14.490 --> 00:33:17.960
It means that no
one has registered

00:33:17.960 --> 00:33:20.860
that idea or that product or
that data set or whatever,

00:33:20.860 --> 00:33:21.880
and here it comes.

00:33:21.880 --> 00:33:24.180
I've never heard about
that that it was happening.

00:33:24.180 --> 00:33:25.250
Fine.

00:33:25.250 --> 00:33:26.620
Let's keep it.

00:33:26.620 --> 00:33:28.770
But it means that we
need to replicate it.

00:33:28.770 --> 00:33:32.060
Otherwise it's very, very
unlikely that it would be true.

00:33:32.060 --> 00:33:33.270
Some of them would be true.

00:33:33.270 --> 00:33:36.330
But not very high chance.

00:33:36.330 --> 00:33:38.590
Registration of data
set is what I described.

00:33:38.590 --> 00:33:42.490
We know what data sets
and opportunities exist.

00:33:42.490 --> 00:33:43.570
Registration of protocol.

00:33:43.570 --> 00:33:45.861
It means that we have started
formulating a hypothesis.

00:33:45.861 --> 00:33:47.550
We do have a hypothesis.

00:33:47.550 --> 00:33:49.250
Then people would
know about that.

00:33:49.250 --> 00:33:50.660
Registration of
the analysis plan

00:33:50.660 --> 00:33:52.451
is different than
registration of protocol,

00:33:52.451 --> 00:33:55.570
because analysis plan is
an extra level of detail

00:33:55.570 --> 00:33:57.810
on how exactly the data
are going to be analyzed.

00:33:57.810 --> 00:34:00.300
And even seasoned
analysts acknowledge

00:34:00.300 --> 00:34:03.605
that the analysis plan may
really change down the road.

00:34:03.605 --> 00:34:05.730
Registration of the analysis
plan and the raw data,

00:34:05.730 --> 00:34:07.684
which means that if
people have time to waste,

00:34:07.684 --> 00:34:09.100
they can go back
to their own data

00:34:09.100 --> 00:34:10.724
and try to repeat
that analysis and see

00:34:10.724 --> 00:34:12.270
whether they get
the same results.

00:34:12.270 --> 00:34:14.030
And finally open
live streaming, which

00:34:14.030 --> 00:34:16.780
means that I do my
research, I open my computer

00:34:16.780 --> 00:34:20.600
to public view, and you can
start sending me messages.

00:34:20.600 --> 00:34:23.310
John, don't push that button,
don't run that chi-square test,

00:34:23.310 --> 00:34:26.040
it's the wrong test for these
data set, it's very silly.

00:34:26.040 --> 00:34:28.060
Or your whole product
is wrong, we've

00:34:28.060 --> 00:34:30.030
done that before, you
don't need to repeat it.

00:34:30.030 --> 00:34:31.530
Do it this way.

00:34:31.530 --> 00:34:33.820
Some fields are experimenting
with these options,

00:34:33.820 --> 00:34:36.020
and I'm not saying that
all fields should adopt

00:34:36.020 --> 00:34:39.610
open live streaming, but I think
moving more from level zero

00:34:39.610 --> 00:34:44.744
to level one, two, three,
four, five may be beneficial.

00:34:44.744 --> 00:34:45.244
Yes?

00:34:47.735 --> 00:34:49.360
AUDIENCE: Is the
point of registration,

00:34:49.360 --> 00:34:53.909
then, that you get the criticism
earlier and save people time?

00:34:53.909 --> 00:34:56.429
DR. IOANNIDIS: The question
is whether by registering

00:34:56.429 --> 00:34:58.280
you get the criticism earlier.

00:34:58.280 --> 00:34:59.860
Part of the benefit is that.

00:34:59.860 --> 00:35:03.720
But I think that there's
also more transparency.

00:35:03.720 --> 00:35:06.220
So in a way,
registration would help

00:35:06.220 --> 00:35:08.660
cure some of the
publication bias problem.

00:35:08.660 --> 00:35:10.960
Because people would
know that even though I

00:35:10.960 --> 00:35:13.860
see one study that is published,
there's 30 studies out there.

00:35:13.860 --> 00:35:14.970
Where is the other 29?

00:35:14.970 --> 00:35:16.560
I need to go and
find their results

00:35:16.560 --> 00:35:20.290
before I make some conclusions
and start policy actions based

00:35:20.290 --> 00:35:21.850
on the one that is published.

00:35:21.850 --> 00:35:25.050
So I think that there could be
many benefits at many layers.

00:35:25.050 --> 00:35:26.610
And obviously we
have a good sense

00:35:26.610 --> 00:35:28.590
of what the research
agenda looks like.

00:35:28.590 --> 00:35:30.560
Funders or other
scientists may decide

00:35:30.560 --> 00:35:32.600
that here we have
50 studies already.

00:35:32.600 --> 00:35:34.510
Why do we need yet another one?

00:35:34.510 --> 00:35:38.800
So it could be a multiple
level of benefits.

00:35:38.800 --> 00:35:40.480
This is an empirical
evaluation looking

00:35:40.480 --> 00:35:44.470
at how common data sharing is
in different scientific journals

00:35:44.470 --> 00:35:46.680
in the articles that
they've published.

00:35:46.680 --> 00:35:49.600
We looked at the 50
highest impact factor

00:35:49.600 --> 00:35:52.790
journals across
science, and we tried

00:35:52.790 --> 00:35:54.700
to see if they have
policies in place

00:35:54.700 --> 00:35:58.870
for sharing of materials,
of protocols, of raw data,

00:35:58.870 --> 00:36:03.290
and also whether it may be a
prerequisite for publication.

00:36:03.290 --> 00:36:05.690
And if you see green color,
that's very good news.

00:36:05.690 --> 00:36:08.140
It means that these journals
do have policies in place

00:36:08.140 --> 00:36:10.720
for different aspects
of the sharing process.

00:36:10.720 --> 00:36:12.620
But the last column,
which is very tiny

00:36:12.620 --> 00:36:15.440
font-- You have to trust me,
but there's lots of zeros.

00:36:15.440 --> 00:36:18.470
And these zeroes are the
number of papers out of 10

00:36:18.470 --> 00:36:21.430
that we screened in each one
of these journals that actually

00:36:21.430 --> 00:36:23.580
adhered to these policies.

00:36:23.580 --> 00:36:27.630
So there's lots of sensitization
about these issues,

00:36:27.630 --> 00:36:29.870
but when it comes
to real life, it's

00:36:29.870 --> 00:36:31.580
very difficult to
find the raw data.

00:36:31.580 --> 00:36:33.400
And even if you want
to waste your time

00:36:33.400 --> 00:36:37.450
to repeat the analysis,
it's not really doable.

00:36:37.450 --> 00:36:42.140
So if you want to waste your
time, what would you get?

00:36:42.140 --> 00:36:44.460
A few years ago, I
gathered a number

00:36:44.460 --> 00:36:46.730
of colleagues who were very
interested in microarray

00:36:46.730 --> 00:36:49.110
analysis around the
world, and we got in touch

00:36:49.110 --> 00:36:52.240
with Myles Axton, the
editor of "Nature Genetics."

00:36:52.240 --> 00:36:55.000
And we said, your general
has been visionary.

00:36:55.000 --> 00:36:56.610
This is true.

00:36:56.610 --> 00:36:58.400
You have a policy
in place that data

00:36:58.400 --> 00:37:01.790
should be shared in public as
a prerequisite for publication

00:37:01.790 --> 00:37:03.190
for microarray studies.

00:37:03.190 --> 00:37:06.030
So let's try to see whether
we can repeat the analysis

00:37:06.030 --> 00:37:08.240
and specific tables or
figures from microarray papers

00:37:08.240 --> 00:37:09.560
published in "Nature Genetics."

00:37:09.560 --> 00:37:11.620
Impact factor of 40,
one of the best journals

00:37:11.620 --> 00:37:13.640
across any scientific field.

00:37:13.640 --> 00:37:15.970
And this is what we did.

00:37:15.970 --> 00:37:19.740
Out of 18 papers that we
tried to repeat the analysis,

00:37:19.740 --> 00:37:22.720
we could repeat the
analysis only for two.

00:37:22.720 --> 00:37:24.930
And for the others,
we could reproduce

00:37:24.930 --> 00:37:26.480
with some
discrepancies, we could

00:37:26.480 --> 00:37:29.437
reproduce from process data
with some discrepancies,

00:37:29.437 --> 00:37:31.520
could reproduce partially
with some discrepancies,

00:37:31.520 --> 00:37:33.930
and then the majority we
could not reproduce at all.

00:37:33.930 --> 00:37:35.440
And the reasons for that?

00:37:35.440 --> 00:37:37.640
The data basis were not
available, actually,

00:37:37.640 --> 00:37:39.970
even though they
were supposed to be.

00:37:39.970 --> 00:37:43.030
Software were not
available, were homemade

00:37:43.030 --> 00:37:44.250
and had disappeared.

00:37:44.250 --> 00:37:45.440
The methods were unclear.

00:37:45.440 --> 00:37:46.860
So none of the
experts in the team

00:37:46.860 --> 00:37:48.460
could understand
what was happening.

00:37:48.460 --> 00:37:50.930
Or people could understand
what was happening,

00:37:50.930 --> 00:37:53.200
but we got a very
different result.

00:37:53.200 --> 00:37:56.000
So this is one of the highest
impact factor journals, one

00:37:56.000 --> 00:37:58.560
of the most
transparent journals,

00:37:58.560 --> 00:38:00.190
research by the very best teams.

00:38:00.190 --> 00:38:02.000
And repeatability
is two out of 18.

00:38:02.000 --> 00:38:05.210
A little bit over 10%.

00:38:05.210 --> 00:38:08.530
The other question is who's
going to do the replication?

00:38:08.530 --> 00:38:10.572
Will it be the
same investigators?

00:38:10.572 --> 00:38:12.030
Would it be different
investigators

00:38:12.030 --> 00:38:12.760
of the same school?

00:38:12.760 --> 00:38:14.218
Would it be different
investigators

00:38:14.218 --> 00:38:16.580
of competing theories
or hypotheses?

00:38:16.580 --> 00:38:17.820
Combinations of the above?

00:38:17.820 --> 00:38:19.810
Would it be open
to the wide public?

00:38:19.810 --> 00:38:20.370
Anyone?

00:38:20.370 --> 00:38:21.940
Especially we have
these raw data

00:38:21.940 --> 00:38:23.730
sets available in public view?

00:38:23.730 --> 00:38:26.840
I think the results and
the replication profile

00:38:26.840 --> 00:38:29.790
could be different depending
on who is replicating.

00:38:29.790 --> 00:38:35.930
And all of these ideas are
currently really being debated.

00:38:35.930 --> 00:38:38.940
It's a very hot debate about
what type of reproducibility

00:38:38.940 --> 00:38:39.546
we need.

00:38:39.546 --> 00:38:41.170
And there's lots of
an initiatives that

00:38:41.170 --> 00:38:44.774
are appearing around the
world to try to do that.

00:38:44.774 --> 00:38:46.940
So, for example, Brian Nosek
has launched the Center

00:38:46.940 --> 00:38:49.070
for Open Science,
focusing mostly

00:38:49.070 --> 00:38:50.760
on psychological
and social sciences

00:38:50.760 --> 00:38:52.690
repeatability and
reproducibility.

00:38:52.690 --> 00:38:54.270
The Reproducibility
Initiative has

00:38:54.270 --> 00:38:56.810
started replicating the
most highly cited research

00:38:56.810 --> 00:38:58.160
in cell biology.

00:38:58.160 --> 00:39:00.670
And it has an open initiative
also for other studies

00:39:00.670 --> 00:39:03.860
to be repeated by
independent labs.

00:39:03.860 --> 00:39:05.970
As [INAUDIBLE]
mentioned, we recently

00:39:05.970 --> 00:39:09.680
launched with Steve Goodman
METRICS, the Meta-Research

00:39:09.680 --> 00:39:12.060
Innovation Center
at Stanford, which

00:39:12.060 --> 00:39:14.800
we aim to try to coalesce
all of these efforts

00:39:14.800 --> 00:39:16.710
around the world on
different aspects

00:39:16.710 --> 00:39:19.500
of reproducible research
and research and research.

00:39:19.500 --> 00:39:21.540
So anyone who might
be interested to join

00:39:21.540 --> 00:39:23.260
in that effort, please
send me an email

00:39:23.260 --> 00:39:26.400
or find a way to reach me.

00:39:26.400 --> 00:39:28.710
If I don't respond immediately,
please, I apologize.

00:39:28.710 --> 00:39:31.380
But sometimes I get overwhelmed.

00:39:31.380 --> 00:39:35.020
But we're very excited about
probing different possibilities

00:39:35.020 --> 00:39:38.700
about how to promote
reproducible research.

00:39:38.700 --> 00:39:41.520
To do that, maybe we
need to change the reward

00:39:41.520 --> 00:39:43.730
systems and the
incentive systems.

00:39:43.730 --> 00:39:46.330
If, for example, funding
agencies, all they want

00:39:46.330 --> 00:39:47.862
is significant
results and claims

00:39:47.862 --> 00:39:49.820
for major discoveries,
this what they will get.

00:39:49.820 --> 00:39:52.080
Significant results and
claims for discoveries.

00:39:52.080 --> 00:39:54.980
If we realign the incentives
both for funding agencies

00:39:54.980 --> 00:39:57.395
and for institutions and
for research institutes

00:39:57.395 --> 00:40:00.590
and for companies to get
translatable results, results

00:40:00.590 --> 00:40:03.870
that you can make sense of, that
you can apply, that you can get

00:40:03.870 --> 00:40:08.530
something out for the real
world, reproducible results,

00:40:08.530 --> 00:40:12.590
high-quality results, this
would be a very different story.

00:40:12.590 --> 00:40:16.720
And one note of caveat.

00:40:16.720 --> 00:40:19.340
I don't want us to
reach the other end

00:40:19.340 --> 00:40:21.000
of the spectrum,
the other extreme.

00:40:21.000 --> 00:40:23.580
Just having too much
wasted replication.

00:40:23.580 --> 00:40:25.110
Here's one example.

00:40:25.110 --> 00:40:27.850
This is an interesting topic.

00:40:27.850 --> 00:40:30.720
This is status for prevention
of atrial fibrillation

00:40:30.720 --> 00:40:32.070
after cardiac surgery.

00:40:32.070 --> 00:40:34.410
Should one use statons
in that setting?

00:40:34.410 --> 00:40:35.450
Good question.

00:40:35.450 --> 00:40:36.820
I would like to know the answer.

00:40:36.820 --> 00:40:38.445
There are randomized
trials about that.

00:40:38.445 --> 00:40:40.029
There's also
meta-analyses about that.

00:40:40.029 --> 00:40:41.570
How many meta-analyses
are out there?

00:40:41.570 --> 00:40:43.960
There's 11 meta-analyses
when we published that paper.

00:40:43.960 --> 00:40:46.630
I think there's 14 now.

00:40:46.630 --> 00:40:50.530
Why do we need 14 efforts
to perform meta-analysis

00:40:50.530 --> 00:40:51.500
on these data sets?

00:40:51.500 --> 00:40:52.882
Within three years, practically.

00:40:52.882 --> 00:40:54.090
They all get the same result.

00:40:54.090 --> 00:40:55.740
The first one was inconclusive.

00:40:55.740 --> 00:40:57.920
But after that they all
got the same result.

00:40:57.920 --> 00:41:02.830
So some broader picture of what
is the research agenda looking

00:41:02.830 --> 00:41:05.450
like may be helpful to
avoid wasting resources

00:41:05.450 --> 00:41:08.170
for performing the fifteenth
meta-analysis on the very

00:41:08.170 --> 00:41:12.070
same topic and allocating
resources more wisely.

00:41:12.070 --> 00:41:13.630
And this is another caveat.

00:41:13.630 --> 00:41:16.630
We have to take into
account a changing world.

00:41:16.630 --> 00:41:19.650
This is another field that
we recently looked at.

00:41:19.650 --> 00:41:22.810
This is genetic meta-analysis.

00:41:22.810 --> 00:41:27.760
And the different bars here
represent genetic meta-analyses

00:41:27.760 --> 00:41:29.050
from different countries.

00:41:29.050 --> 00:41:31.210
The blue bar is not the US.

00:41:31.210 --> 00:41:33.060
The blue bar is China.

00:41:33.060 --> 00:41:38.300
So in that field China went
from 1% less than 10 years ago

00:41:38.300 --> 00:41:42.980
to about 60, 70% of the
entire global production

00:41:42.980 --> 00:41:46.590
in English-language, high
impact factor journals.

00:41:46.590 --> 00:41:49.290
Or good impact factor journals.

00:41:49.290 --> 00:41:50.430
That's interesting.

00:41:50.430 --> 00:41:52.240
I do believe that
China is really

00:41:52.240 --> 00:41:54.270
the new giant in
science, and I see

00:41:54.270 --> 00:41:55.560
that in many different fields.

00:41:55.560 --> 00:41:58.320
We took a closer look to
see what's happening here.

00:41:58.320 --> 00:42:00.570
So we looked at these papers.

00:42:00.570 --> 00:42:02.530
In terms of reporting,
they look great.

00:42:02.530 --> 00:42:03.630
They look wonderful.

00:42:03.630 --> 00:42:06.310
The tables are very meticulous,
very well structured.

00:42:06.310 --> 00:42:10.300
The details about the
methods, they're very nice.

00:42:10.300 --> 00:42:11.430
Wonderful.

00:42:11.430 --> 00:42:13.970
But almost all of
them are wrong.

00:42:13.970 --> 00:42:15.090
Why's that?

00:42:15.090 --> 00:42:17.520
Because they depend
on collecting

00:42:17.520 --> 00:42:19.520
fragments of
published information

00:42:19.520 --> 00:42:20.904
on specific genetic
associations.

00:42:20.904 --> 00:42:22.320
So pretty much the
same literature

00:42:22.320 --> 00:42:24.590
that I showed you in one
of the earlier slides?

00:42:24.590 --> 00:42:27.670
These are meta-analyses
compiling the small pieces

00:42:27.670 --> 00:42:29.200
of information
that are published.

00:42:29.200 --> 00:42:32.420
They cannot take into account
the very large initiatives that

00:42:32.420 --> 00:42:35.930
have data sets that are
50 or 100 times larger

00:42:35.930 --> 00:42:38.920
and conclusively fine null
results for these associations.

00:42:38.920 --> 00:42:40.410
Just because they're
not available.

00:42:40.410 --> 00:42:41.450
It's not their fault.

00:42:41.450 --> 00:42:46.440
But they just gather what they
can see under the lamppost.

00:42:46.440 --> 00:42:48.120
And what they can see
under the lamppost

00:42:48.120 --> 00:42:53.170
is very limited, fragmented,
and potentially highly biased.

00:42:53.170 --> 00:42:55.540
So to conclude, I
think that there's

00:42:55.540 --> 00:42:57.790
a very large number of
conscious, unconscious,

00:42:57.790 --> 00:43:00.710
and subconscious biases that
can operate in the research

00:43:00.710 --> 00:43:02.380
process.

00:43:02.380 --> 00:43:04.680
This is likely to be
just human nature,

00:43:04.680 --> 00:43:06.380
and we should take
that for granted.

00:43:06.380 --> 00:43:09.640
We should just try to see
how we can work through that.

00:43:09.640 --> 00:43:11.640
Replication,
reproducibility practices

00:43:11.640 --> 00:43:14.510
vary a lot across
different research fields.

00:43:14.510 --> 00:43:16.510
And I think that the
adoption of these practices

00:43:16.510 --> 00:43:20.390
can be key to the success
rates, efficiency, credibility,

00:43:20.390 --> 00:43:22.700
and legacy of each field.

00:43:22.700 --> 00:43:25.500
Fields that are noncredible
can become highly credible,

00:43:25.500 --> 00:43:27.770
others that are credible
can lose credibility,

00:43:27.770 --> 00:43:29.840
depending on what
practices they adopt.

00:43:29.840 --> 00:43:32.450
And I think that it's
a huge research area

00:43:32.450 --> 00:43:34.570
to understand which are
really the best practices

00:43:34.570 --> 00:43:37.250
to improve our
credibility rates.

00:43:37.250 --> 00:43:39.690
I just want to thank
a few of my colleagues

00:43:39.690 --> 00:43:42.580
that have been involved in
some of the empirical studies

00:43:42.580 --> 00:43:44.255
that I showed you today.

00:43:44.255 --> 00:43:46.880
Since I'm famous because most of
my published research findings

00:43:46.880 --> 00:43:49.830
are wrong, they should
not be blamed for that.

00:43:49.830 --> 00:43:51.580
I think that the
part that was wrong

00:43:51.580 --> 00:43:53.790
is mine, the part that
was correct is theirs.

00:43:53.790 --> 00:43:55.244
Thank you.

00:43:55.244 --> 00:44:01.320
[APPLAUSE]

00:44:01.320 --> 00:44:05.220
AUDIENCE: Back to where you have
all those studies where they

00:44:05.220 --> 00:44:07.250
continue to produce
inconclusive results,

00:44:07.250 --> 00:44:10.600
that would suggest to me
that there's somebody out

00:44:10.600 --> 00:44:12.592
there that wants
to find a result.

00:44:12.592 --> 00:44:14.300
And they keep trying
to find that result.

00:44:14.300 --> 00:44:16.190
Is that how you see it?

00:44:16.190 --> 00:44:17.430
DR. IOANNIDIS: Absolutely.

00:44:17.430 --> 00:44:20.930
I think that there is a
lot of confirmation bias.

00:44:20.930 --> 00:44:22.590
If people have
developed a theory

00:44:22.590 --> 00:44:25.030
or they have a field
that is expecting

00:44:25.030 --> 00:44:28.570
to find some associations or
some effects or some results

00:44:28.570 --> 00:44:30.260
and they don't see
that, they will just

00:44:30.260 --> 00:44:35.310
keep analyzing the data or keep
accruing other research efforts

00:44:35.310 --> 00:44:38.090
until they get that
result that they want.

00:44:38.090 --> 00:44:39.590
I think this is very risky.

00:44:39.590 --> 00:44:43.180
Because it creates bubbles
of scientific disciplines.

00:44:43.180 --> 00:44:45.230
I think that many
scientific disciplines

00:44:45.230 --> 00:44:49.910
are just bubbles like the candid
gene association bubble that

00:44:49.910 --> 00:44:52.190
burst when we had better
studies, larger studies,

00:44:52.190 --> 00:44:54.460
with more careful
characterization of both

00:44:54.460 --> 00:44:57.080
the genome and
better sample sizes.

00:44:57.080 --> 00:44:58.660
How common these bubbles are?

00:44:58.660 --> 00:45:02.180
I think it's open for debate.

00:45:02.180 --> 00:45:03.930
I think most scientists
would be defensive

00:45:03.930 --> 00:45:06.560
that their own field
is not a bubble.

00:45:06.560 --> 00:45:10.070
But I suspect that there's
many bubbles out there.

00:45:10.070 --> 00:45:11.500
AUDIENCE: While
there's certainly

00:45:11.500 --> 00:45:14.160
a bias towards publishing
positive results,

00:45:14.160 --> 00:45:17.770
how can we account for the
fact that there's probably also

00:45:17.770 --> 00:45:21.190
a bias for testing
relationships for which there's

00:45:21.190 --> 00:45:24.160
a plausible mechanism
in the first place?

00:45:24.160 --> 00:45:27.700
So we're not just testing random
predictors on our outcome,

00:45:27.700 --> 00:45:31.100
but rather things that we
could believe plausibly

00:45:31.100 --> 00:45:34.475
or scientifically that would
influence that outcome?

00:45:34.475 --> 00:45:35.850
DR. IOANNIDIS: I
think that there

00:45:35.850 --> 00:45:38.560
is room for incorporating
plausibility,

00:45:38.560 --> 00:45:40.850
biological plausibility,
and other lines of evidence

00:45:40.850 --> 00:45:41.960
in designing studies.

00:45:41.960 --> 00:45:46.060
I'm not saying that
everything should be agnostic.

00:45:46.060 --> 00:45:48.560
And in many cases, we have
tons of previous evidence

00:45:48.560 --> 00:45:50.440
that we need to
take into account.

00:45:50.440 --> 00:45:53.560
So for example, if
I were to design

00:45:53.560 --> 00:45:56.800
a large-scale randomized
trial to test a new treatment,

00:45:56.800 --> 00:45:59.140
probably I will not take
any treatment to be tested.

00:45:59.140 --> 00:46:01.850
I will take one that has gone
through pre-clinical research,

00:46:01.850 --> 00:46:06.040
early clinical research, early
phase studies, phase one, two,

00:46:06.040 --> 00:46:07.820
and it shows promising
results all along.

00:46:07.820 --> 00:46:10.720
So by the time I
get there, I have

00:46:10.720 --> 00:46:13.310
incorporated all that
previous evidence

00:46:13.310 --> 00:46:14.900
and decided that
this is a good study

00:46:14.900 --> 00:46:17.530
to do to have the conclusive
result of whether it

00:46:17.530 --> 00:46:19.270
does really work.

00:46:19.270 --> 00:46:23.250
However, in most circumstances,
in my experience,

00:46:23.250 --> 00:46:26.340
and in a number of empirical
studies that we have done,

00:46:26.340 --> 00:46:29.700
biological plausibility
is inflated.

00:46:29.700 --> 00:46:32.060
It's overinterpreted.

00:46:32.060 --> 00:46:34.290
People used biological
plausibility

00:46:34.290 --> 00:46:37.210
in ways that suit their needs.

00:46:37.210 --> 00:46:39.630
And much of the
time it is post hoc.

00:46:39.630 --> 00:46:41.000
They find the result.

00:46:41.000 --> 00:46:43.560
And then they draw
the circle around it.

00:46:43.560 --> 00:46:45.990
And it's interesting.

00:46:45.990 --> 00:46:50.740
Any result can be explained
away as being plausible.

00:46:50.740 --> 00:46:53.960
I cannot think of any result
that someone could not summon

00:46:53.960 --> 00:46:55.480
biological plausibility.

00:46:55.480 --> 00:46:57.390
So how do you solve that?

00:46:57.390 --> 00:46:58.770
I think you need registration.

00:46:58.770 --> 00:47:01.380
You need to have registration
of a protocol that says,

00:47:01.380 --> 00:47:03.150
specifically, this
is my hypothesis,

00:47:03.150 --> 00:47:04.920
and this is what I base it on.

00:47:04.920 --> 00:47:07.890
This is the plausibility
argument, or arguments,

00:47:07.890 --> 00:47:10.830
that I have, and let's
see what happens.

00:47:10.830 --> 00:47:13.240
And then it's a good choice.

00:47:13.240 --> 00:47:15.580
And if it's a nice
result, that's great.

00:47:15.580 --> 00:47:19.020
Whatever the result
is, then it's valuable.

00:47:19.020 --> 00:47:20.870
AUDIENCE: Professor,
based on your research,

00:47:20.870 --> 00:47:23.610
would you say that
science currently

00:47:23.610 --> 00:47:26.460
is undergoing a crisis episode?

00:47:26.460 --> 00:47:29.800
Given the number of papers
that are simply wrong?

00:47:29.800 --> 00:47:32.170
DR. IOANNIDIS: Is science
undergoing a crisis.

00:47:32.170 --> 00:47:36.740
AUDIENCE: And if so, how urgent
would you say it is to fix it?

00:47:36.740 --> 00:47:41.060
DR. IOANNIDIS: It depends
on how you define crisis.

00:47:41.060 --> 00:47:44.790
If crisis is synonymous with
we have been infiltrated

00:47:44.790 --> 00:47:47.790
by millions of
fraudulent people, no.

00:47:47.790 --> 00:47:54.090
If crisis is that our efficiency
is very low, I would say yes.

00:47:54.090 --> 00:47:59.080
I think that the efficiency of
many practices of conducting

00:47:59.080 --> 00:48:00.470
research currently is very low.

00:48:00.470 --> 00:48:02.060
We have a lot of waste.

00:48:02.060 --> 00:48:04.770
If you see that as a
machine, the machine

00:48:04.770 --> 00:48:07.260
could operate far
more efficiently.

00:48:07.260 --> 00:48:10.220
And the question is what
are the best interventions

00:48:10.220 --> 00:48:11.830
to improve that efficiency?

00:48:11.830 --> 00:48:13.421
In a series of papers
in "The Lancet"

00:48:13.421 --> 00:48:15.420
along with several
colleagues earlier this year,

00:48:15.420 --> 00:48:18.450
we estimated that the waste
in biomedical research

00:48:18.450 --> 00:48:20.580
is about 85%.

00:48:20.580 --> 00:48:22.060
So is that a crisis?

00:48:22.060 --> 00:48:24.500
I would argue it's a
very high percentage.

00:48:24.500 --> 00:48:26.410
Some might argue that,
well, that's not bad,

00:48:26.410 --> 00:48:31.340
15%, I mean, it could be 1%.

00:48:31.340 --> 00:48:32.450
I think I'm an optimist.

00:48:32.450 --> 00:48:36.680
I believe that 15% could
become 40% and or 60%.

00:48:36.680 --> 00:48:39.050
It's unlikely it
will become 100%.

00:48:39.050 --> 00:48:42.470
Science is very difficult,
and even under the very best

00:48:42.470 --> 00:48:44.992
intentions we will
keep making lots

00:48:44.992 --> 00:48:46.700
of errors and lots of
suboptimal choices.

00:48:46.700 --> 00:48:51.769
But I think we can get that
15% to a much higher range.

00:48:51.769 --> 00:48:54.060
And I think that this is true
for many other scientific

00:48:54.060 --> 00:48:55.900
domains even beyond biomedicine.

00:48:58.514 --> 00:49:00.430
AUDIENCE: Have you are
anyone else looked into

00:49:00.430 --> 00:49:03.530
at what point in the research
process results become wrong?

00:49:03.530 --> 00:49:07.142
So do studies typically
have poor designs?

00:49:07.142 --> 00:49:08.725
Or do the samples
get mixed up, or are

00:49:08.725 --> 00:49:10.300
there bugs in the software?

00:49:10.300 --> 00:49:12.510
Or maybe the data's correct
and wrongly interpreted.

00:49:12.510 --> 00:49:14.492
Do you have any sense of that?

00:49:14.492 --> 00:49:15.950
DR. IOANNIDIS: So
what is the stage

00:49:15.950 --> 00:49:18.640
that most studies get it wrong.

00:49:18.640 --> 00:49:20.220
It's a continuum.

00:49:20.220 --> 00:49:22.790
There's multiple
phases, and each phase

00:49:22.790 --> 00:49:24.780
has its waste contribution.

00:49:24.780 --> 00:49:26.510
And there's waste
contribution even

00:49:26.510 --> 00:49:30.310
from selecting the study
to perform or the question.

00:49:30.310 --> 00:49:32.170
There's lots of
studies that just

00:49:32.170 --> 00:49:35.230
have no rationale
that should be done.

00:49:35.230 --> 00:49:38.450
If someone says, I'm going
to do another meta-analysis

00:49:38.450 --> 00:49:40.589
on statons for prevention
of atrial fibrillation,

00:49:40.589 --> 00:49:42.130
I will say, well,
we have 14 already.

00:49:42.130 --> 00:49:44.600
Why do we need a fifteenth?

00:49:44.600 --> 00:49:46.180
But I'm sure that
there will be one.

00:49:46.180 --> 00:49:48.430
Probably in the next few months.

00:49:48.430 --> 00:49:50.327
There's then a lot of
waste in the design.

00:49:50.327 --> 00:49:52.410
There's lots of waste in
the conduct of the study.

00:49:52.410 --> 00:49:54.080
There's lots of waste in
the analysis of the data.

00:49:54.080 --> 00:49:56.204
There's lots of waste in
the reporting of the data.

00:49:56.204 --> 00:49:58.547
There's lots of waste in
the post-publication or

00:49:58.547 --> 00:50:04.370
post-publication interpretation
and use and implementation

00:50:04.370 --> 00:50:06.180
of the database or
whatever they mean.

00:50:06.180 --> 00:50:08.446
It's not just one point.

00:50:08.446 --> 00:50:09.820
AUDIENCE: Has it
been quantified?

00:50:09.820 --> 00:50:11.319
Can you say that a
quarter of papers

00:50:11.319 --> 00:50:13.810
are wrong because
of a software bug?

00:50:13.810 --> 00:50:15.310
DR. IOANNIDIS: It
has been qualified

00:50:15.310 --> 00:50:19.990
for specific subsets
of scientific fields.

00:50:19.990 --> 00:50:24.560
I think it would be misleading
to say that all fields are

00:50:24.560 --> 00:50:28.010
suffering more from one
of these five steps.

00:50:28.010 --> 00:50:30.100
Depending on the field,
you may have more waste

00:50:30.100 --> 00:50:32.070
in an early phase
or a late phase.

00:50:34.850 --> 00:50:36.230
AUDIENCE: What
does this research

00:50:36.230 --> 00:50:39.030
lead you to think about
the role of journals?

00:50:39.030 --> 00:50:41.770
Certainly they've
come under criticism

00:50:41.770 --> 00:50:44.510
for the fees they charge
people to access them

00:50:44.510 --> 00:50:46.720
and things like that.

00:50:46.720 --> 00:50:48.991
Do you see journals as
driving change here,

00:50:48.991 --> 00:50:50.490
or is this something
where there are

00:50:50.490 --> 00:50:52.530
things in addition to
instead of journals

00:50:52.530 --> 00:50:55.590
that are getting the registered
studies or other information

00:50:55.590 --> 00:50:56.819
out there?

00:50:56.819 --> 00:50:59.360
DR. IOANNIDIS: Journals can be
a very influential stakeholder

00:50:59.360 --> 00:51:00.520
in the whole process.

00:51:00.520 --> 00:51:03.210
Because they control much of
their reward and incentive

00:51:03.210 --> 00:51:05.170
system.

00:51:05.170 --> 00:51:08.560
So this means that they
can make thing far worse,

00:51:08.560 --> 00:51:10.310
or they can make
things far better.

00:51:10.310 --> 00:51:12.160
One example where they
make things far worse

00:51:12.160 --> 00:51:13.618
is where you have
generals that are

00:51:13.618 --> 00:51:16.010
willing to accept
practically anything,

00:51:16.010 --> 00:51:17.210
hardly with any peer review.

00:51:17.210 --> 00:51:18.900
There was that hoax
that was published

00:51:18.900 --> 00:51:21.150
in "Science" several months ago.

00:51:21.150 --> 00:51:22.700
300 journals were
sent a paper that

00:51:22.700 --> 00:51:25.500
was a fake paper with all the
errors that you could imagine,

00:51:25.500 --> 00:51:26.880
and half of them accepted it.

00:51:26.880 --> 00:51:32.290
And another 20% were
still considering it.

00:51:32.290 --> 00:51:34.020
They can do things much better.

00:51:34.020 --> 00:51:36.720
So, for example, registration
of clinical trials

00:51:36.720 --> 00:51:39.090
would not have been
successful unless all

00:51:39.090 --> 00:51:42.390
the major clinical journals
had agreed that we're not

00:51:42.390 --> 00:51:45.060
going to publish a clinical
trial unless it is registered.

00:51:45.060 --> 00:51:48.160
People have been talking
about registration for ages.

00:51:48.160 --> 00:51:49.620
I remember the 1990s.

00:51:49.620 --> 00:51:52.900
BMJ had come up with a nice
idea about a trial amnesty,

00:51:52.900 --> 00:51:54.870
saying, if you haven't
published your results,

00:51:54.870 --> 00:51:56.330
we will forgive you.

00:51:56.330 --> 00:51:58.370
Come out and tell
us what you found.

00:51:58.370 --> 00:52:00.860
Nobody came out to
tell what they found.

00:52:00.860 --> 00:52:04.525
But if "BMJ" and "JAMA" and
"Lancet" and "New England

00:52:04.525 --> 00:52:07.150
Journal of Medicine" and all the
major specialty journals said,

00:52:07.150 --> 00:52:09.710
we're not going to publish your
work unless it's registered,

00:52:09.710 --> 00:52:11.310
then it'd happen.

00:52:11.310 --> 00:52:12.700
It creates new challenges.

00:52:12.700 --> 00:52:14.490
Now that we have
registered studies,

00:52:14.490 --> 00:52:17.020
we see that, well,
there's other caveats.

00:52:17.020 --> 00:52:18.520
So you could still
register a study,

00:52:18.520 --> 00:52:21.020
but the protocol may
not be very transparent.

00:52:21.020 --> 00:52:23.640
There's still lots of leeway
for vibration of effects

00:52:23.640 --> 00:52:25.130
and for exploration
of the analysis

00:52:25.130 --> 00:52:26.239
that you want to present.

00:52:26.239 --> 00:52:27.530
So now we need to work on that.

00:52:27.530 --> 00:52:30.240
How do you get
journals to buy in

00:52:30.240 --> 00:52:32.110
that you don't need to
just register a study

00:52:32.110 --> 00:52:34.070
and say, oh, yeah,
I'm doing a study,

00:52:34.070 --> 00:52:36.490
but really be precise
about what is being done

00:52:36.490 --> 00:52:37.890
and how it's going to be done?

00:52:37.890 --> 00:52:40.050
So journals are a
major stakeholder.

00:52:40.050 --> 00:52:44.630
They could really affect
the whole system enormously.

00:52:44.630 --> 00:52:46.980
AUDIENCE: So with
many hypothesis tests

00:52:46.980 --> 00:52:49.940
it's very simple and well
understood how the power and p

00:52:49.940 --> 00:52:52.097
values change as a
function of sample size.

00:52:52.097 --> 00:52:54.180
So I was wondering if there
are any inferences you

00:52:54.180 --> 00:52:57.160
have from distributions of
sample sizes and p values.

00:52:57.160 --> 00:52:58.600
Is there a big
cluster of p values

00:52:58.600 --> 00:53:02.710
just below 0.05 when you
look across these studies,

00:53:02.710 --> 00:53:03.681
for example?

00:53:03.681 --> 00:53:05.930
DR. IOANNIDIS: There are
several studies, empirically,

00:53:05.930 --> 00:53:07.471
that have looked at
different fields.

00:53:07.471 --> 00:53:11.200
And they find that there is a
concentration of p values very

00:53:11.200 --> 00:53:15.630
close to the 0.05 magic number.

00:53:15.630 --> 00:53:18.310
Most of that work has been done
in the psychological sciences,

00:53:18.310 --> 00:53:23.080
and there's a big hump
just next to the 0.05.

00:53:23.080 --> 00:53:26.020
In my experience, when we've
looked at different data sets

00:53:26.020 --> 00:53:31.310
in other fields of epidemiology,
we see a hump next to 0.05.

00:53:31.310 --> 00:53:33.160
Not necessarily less than 0.05.

00:53:33.160 --> 00:53:37.020
It could be less but
also slightly higher.

00:53:37.020 --> 00:53:39.610
And these are papers that
have what we call "spin."

00:53:39.610 --> 00:53:43.340
So people get a p
value of 0.07, but they

00:53:43.340 --> 00:53:46.360
say, oh, we found
an association.

00:53:46.360 --> 00:53:50.330
0.07, it's the same as 0.05.

00:53:50.330 --> 00:53:57.520
But 0.07 could be
0.08, 0.10, 0.12.

00:53:57.520 --> 00:54:00.540
There are attractors in
the p value distribution.

00:54:00.540 --> 00:54:02.970
And this is highly visible,
especially in fields

00:54:02.970 --> 00:54:04.890
that have a very long
tradition of working

00:54:04.890 --> 00:54:09.850
with specific thresholds
that claim who is the winner.

00:54:09.850 --> 00:54:11.970
Even in fields that have
rigorous statistical

00:54:11.970 --> 00:54:12.470
thresholds.

00:54:12.470 --> 00:54:15.820
For example, genome-wide
association studies.

00:54:15.820 --> 00:54:19.770
We have accepted that
instead of a p value of 0.05,

00:54:19.770 --> 00:54:23.350
we need a p value of 5
times 10 to the minus 8.

00:54:23.350 --> 00:54:26.660
You still see a hump very
close to the 5 times 10

00:54:26.660 --> 00:54:29.610
to the minus 8.

00:54:29.610 --> 00:54:33.064
But at least you hope that,
and empirically shows,

00:54:33.064 --> 00:54:34.480
that most of these
values that are

00:54:34.480 --> 00:54:38.110
very close to that
threshold are replicable.

00:54:38.110 --> 00:54:44.109
So in contrast to those that
are just in this 0.05 threshold.

00:54:44.109 --> 00:54:45.650
AUDIENCE: Maybe
following up on that,

00:54:45.650 --> 00:54:47.940
do you think we make
the problem worse

00:54:47.940 --> 00:54:50.190
by focusing on the
wrong statistics?

00:54:50.190 --> 00:54:53.250
Maybe we shouldn't focus
on p values at all,

00:54:53.250 --> 00:54:57.230
but rather have confidence
intervals over effect size.

00:54:57.230 --> 00:54:58.480
DR. IOANNIDIS: Possibly.

00:54:58.480 --> 00:55:00.230
For a long time, I
have argued, of course,

00:55:00.230 --> 00:55:04.250
in favor of effect sizes and
uncertainty surrounding them.

00:55:04.250 --> 00:55:07.230
I have also suggested that
many other colleagues have

00:55:07.230 --> 00:55:08.910
done the same, that
it would be better

00:55:08.910 --> 00:55:11.470
to use Bayesian approaches in
presenting and interpreting

00:55:11.470 --> 00:55:12.520
results.

00:55:12.520 --> 00:55:14.160
However, I want to be honest.

00:55:14.160 --> 00:55:17.040
I don't think that changing
the inferential rules

00:55:17.040 --> 00:55:19.170
from a frequentist
approach, let's say,

00:55:19.170 --> 00:55:23.170
to a fully Bayesian
approach will necessarily

00:55:23.170 --> 00:55:24.340
cure these problems.

00:55:24.340 --> 00:55:27.740
For example, if you
embed into people's minds

00:55:27.740 --> 00:55:30.960
that a base factor of 1,000
is what they should be looking

00:55:30.960 --> 00:55:34.680
for, people will just try to
get a base factor of 1,000.

00:55:34.680 --> 00:55:37.800
They were trying to
get a p value of 0.05,

00:55:37.800 --> 00:55:40.160
now they will try to get
a base factor of 1,000.

00:55:40.160 --> 00:55:43.640
The one difference is
the base factor of 1,000

00:55:43.640 --> 00:55:46.820
would be something that would
be more directly interpretable.

00:55:46.820 --> 00:55:49.840
And it would be
easier to understand

00:55:49.840 --> 00:55:54.700
what it means for
other purposes rather

00:55:54.700 --> 00:55:57.130
than for the bias of
twisting the analysis

00:55:57.130 --> 00:55:59.580
to get a result
passing the threshold.

00:55:59.580 --> 00:56:00.030
FEMALE SPEAKER:
All right, that's

00:56:00.030 --> 00:56:01.330
all the time we
have for questions,

00:56:01.330 --> 00:56:03.680
but I think Dr. Ioannidis will
be around for a little bit

00:56:03.680 --> 00:56:04.410
to answer questions.

00:56:04.410 --> 00:56:06.159
So let's give him a
big round of applause.

00:56:06.159 --> 00:56:06.760
Thank you.

00:56:06.760 --> 00:56:09.810
[APPLAUSE]

