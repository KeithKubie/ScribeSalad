WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.964
[MUSIC PLAYING]

00:00:05.624 --> 00:00:07.040
SPEAKER: In this
video, you'll see

00:00:07.040 --> 00:00:08.630
how you can get
TensorBoard working

00:00:08.630 --> 00:00:11.420
with Keras-based
TensorFlow code.

00:00:11.420 --> 00:00:14.180
In this example, I'm using
the Fashion MNIST dataset

00:00:14.180 --> 00:00:16.309
to do some basic
computer vision, where

00:00:16.309 --> 00:00:19.070
I can train a Keras
neural network to classify

00:00:19.070 --> 00:00:20.270
items of clothing.

00:00:20.270 --> 00:00:22.126
It's set to train
for five epochs,

00:00:22.126 --> 00:00:23.750
and you can see the
progress, including

00:00:23.750 --> 00:00:26.810
the loss and the accuracy,
in the output window.

00:00:26.810 --> 00:00:28.460
We can see that it
finishes training

00:00:28.460 --> 00:00:31.190
with an accuracy of
about 86%, and we

00:00:31.190 --> 00:00:33.560
output some sample predictions.

00:00:33.560 --> 00:00:36.020
But how do we visualize
this with TensorBoard?

00:00:36.020 --> 00:00:38.300
Let's start by importing
the time library

00:00:38.300 --> 00:00:39.920
and TensorBoard itself.

00:00:39.920 --> 00:00:41.652
It can be found in
tensorflow.pytho

00:00:41.652 --> 00:00:43.370
n.kera.callbacks.

00:00:43.370 --> 00:00:45.410
Next, after the
model is defined,

00:00:45.410 --> 00:00:47.660
we want to instantiate
TensorBoard.

00:00:47.660 --> 00:00:49.580
Note that we specify
a log directory

00:00:49.580 --> 00:00:50.990
where stuff will get written.

00:00:50.990 --> 00:00:52.610
Finally, as the
model is training

00:00:52.610 --> 00:00:54.320
in the model.fit
function, we need

00:00:54.320 --> 00:00:57.700
to tell Keras to call
back to TensorBoard.

00:00:57.700 --> 00:01:00.830
We simply do this by specifying
the callback's parameter

00:01:00.830 --> 00:01:03.880
and tell it to use whatever we
call the TensorBoard instance.

00:01:03.880 --> 00:01:06.880
In this case, it's all
lowercase tensorboard.

00:01:06.880 --> 00:01:09.370
Now, in your terminal, you
can execute the TensorBoard

00:01:09.370 --> 00:01:11.380
command, pointing
at the log directory

00:01:11.380 --> 00:01:12.637
that you just specified.

00:01:12.637 --> 00:01:14.470
You'll see that it
executes, and it gives me

00:01:14.470 --> 00:01:19.300
a TensorBoard at HTTP
Machine Name colon 6,006.

00:01:19.300 --> 00:01:22.300
Now, if I retrain
again, when it's done,

00:01:22.300 --> 00:01:24.060
I can take a look
in TensorBoard.

00:01:24.060 --> 00:01:26.740
TensorBoard will launch, and I
can start investigating things

00:01:26.740 --> 00:01:28.985
like the loss and the accuracy.

00:01:28.985 --> 00:01:30.360
I can also look
at the graph that

00:01:30.360 --> 00:01:31.545
was built for the training.

00:01:31.545 --> 00:01:33.420
And that's just how to
get it up and running.

00:01:33.420 --> 00:01:35.550
There's lots of great things
that you can do further with

00:01:35.550 --> 00:01:37.080
TensorBoard, and
you can see them

00:01:37.080 --> 00:01:39.240
at tensorflow.org/tensorboard.

00:01:39.240 --> 00:01:42.100
To learn more about TensorFlow,
visit tensorflow.org.

00:01:42.100 --> 00:01:43.590
For more videos
about TensorFlow,

00:01:43.590 --> 00:01:45.299
click the Subscribe
button, and if you've

00:01:45.299 --> 00:01:47.340
any questions about this
video, please leave them

00:01:47.340 --> 00:01:48.880
in the comments below.

00:01:48.880 --> 00:01:49.620
Thank you.

00:01:49.620 --> 00:01:52.670
[MUSIC PLAYING]

