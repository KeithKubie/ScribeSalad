1
00:00:00,990 --> 00:00:04,710
The Joe Rogan experience far away. Do
you think we are for something like that?

2
00:00:05,070 --> 00:00:09,180
10 years. So in 10 years we're
going to have green people if in,

3
00:00:09,300 --> 00:00:10,230
if someone's so choose,

4
00:00:10,240 --> 00:00:12,840
if someone's who chooses and if it sucks
we'll they'll be able to go back to

5
00:00:12,841 --> 00:00:15,540
normal color. Well if it's,
that's a good question. Um,

6
00:00:15,750 --> 00:00:20,750
if it's with this kind of gene therapy
and it's a small number of genes

7
00:00:20,940 --> 00:00:21,780
probably,

8
00:00:21,781 --> 00:00:25,320
but we are messing with very complex
systems that we don't fully understand it.

9
00:00:25,321 --> 00:00:26,670
So that's why there's a lot of unknowns.

10
00:00:26,671 --> 00:00:29,280
And coming back to your point
on regulation, that's why we,

11
00:00:29,460 --> 00:00:32,190
I don't think we want a total
free for all. If you'll say, hey,

12
00:00:32,191 --> 00:00:37,020
I'm going to edit my own jeans and
you don't want some backyard hustler.

13
00:00:37,140 --> 00:00:40,740
Yeah, it's true. The lab. It's true
cause they were saying about the hulk.

14
00:00:41,070 --> 00:00:43,890
I mean I just think that there are
all kinds of, you know, we're humans,

15
00:00:43,891 --> 00:00:46,020
we're diverse.
Any kind of thing that you can think of.

16
00:00:46,200 --> 00:00:48,090
There is a range and there's,
you know,

17
00:00:48,180 --> 00:00:50,990
crazy on the left and crazy on
the ride and crazy at the top.

18
00:00:51,110 --> 00:00:53,940
So people are going to want to do things.
And the question is,

19
00:00:53,941 --> 00:00:55,290
if with any society,

20
00:00:55,650 --> 00:00:59,040
what do we think is okay and
what do we think is not okay?

21
00:00:59,130 --> 00:01:01,140
And maybe there should be some,

22
00:01:01,200 --> 00:01:06,120
I believe there should be some
limit to how far people can go with

23
00:01:06,150 --> 00:01:09,810
experimenting, certainly,
possibly likely on themselves,

24
00:01:09,880 --> 00:01:13,680
certainly on their future children.
Certainly on the future children. Yeah.

25
00:01:13,710 --> 00:01:16,890
But once you're 18, I think do whatever
the fuck you want. If you realize,

26
00:01:16,950 --> 00:01:19,230
well maybe 25,
25,

27
00:01:19,980 --> 00:01:23,880
we're going to have a lot of 25 girls
with Gills. It's like we probably will.

28
00:01:23,881 --> 00:01:26,970
It's like, it seemed like the tattoo
seemed like a good idea. Yeah.

29
00:01:26,971 --> 00:01:29,420
Well we probably will be.
Um,

30
00:01:29,790 --> 00:01:33,570
so you think we're probably like 50
years away from that being a reality.

31
00:01:33,720 --> 00:01:35,070
So I think that we are,

32
00:01:35,790 --> 00:01:40,350
the genetic revolution has already begun
and it's going to fundamentally change

33
00:01:40,500 --> 00:01:43,800
our lives in, in three big areas.
The first is our healthcare.

34
00:01:43,980 --> 00:01:47,310
So we're moving from a system of
generalized healthcare based on population

35
00:01:47,311 --> 00:01:48,960
averages so that when
you go to your doctor,

36
00:01:48,961 --> 00:01:52,680
you're treated because you're a human
just based on average and we're moving to

37
00:01:52,681 --> 00:01:56,660
a world of personalized medicine and the
foundation of your personalized health

38
00:01:56,661 --> 00:01:59,580
care will be your sequence genome
in your electronic health records.

39
00:01:59,581 --> 00:02:03,870
That's how they know you are you. And
that's how they can say this is a drug,

40
00:02:03,871 --> 00:02:06,630
this is an intervention that will
work for you. When we do that,

41
00:02:06,930 --> 00:02:09,630
then we're going to have
to sequence everybody.

42
00:02:09,631 --> 00:02:12,420
So we're going to have about 2 billion
people have had their whole genome

43
00:02:12,421 --> 00:02:15,510
sequence, uh, within the,
uh, within the da a decade.

44
00:02:15,780 --> 00:02:20,070
And then we're going to be able to compare
what the genes say to how those genes

45
00:02:20,071 --> 00:02:23,160
are expressed.
And then humans become a big dataset.

46
00:02:23,190 --> 00:02:26,760
And that's going to move us from precision
to predictive healthcare where you're

47
00:02:26,761 --> 00:02:29,820
going to be just born and you're going
to have all this information or your

48
00:02:29,821 --> 00:02:32,970
parents love all this stuff about how
certain really important aspects of your

49
00:02:32,971 --> 00:02:36,060
life are going to play on. Some of
that is going to be disease-related,

50
00:02:36,360 --> 00:02:38,070
but some of that's just
going to be life related.

51
00:02:38,071 --> 00:02:41,400
Like you have a better than average
chance of being really great at math or

52
00:02:41,640 --> 00:02:45,480
having a high Iq, low Iq,
or being a great sprinter.

53
00:02:45,481 --> 00:02:48,420
And how do we think about that?
And then again,

54
00:02:48,421 --> 00:02:49,800
a revolution that's already happening.

55
00:02:49,801 --> 00:02:51,810
We're gonna just gonna change
the way we make babies.

56
00:02:51,811 --> 00:02:56,400
We're going to get away from sex as
the primary mechanism for conceiving.

57
00:02:56,400 --> 00:02:59,260
Our kids will still have sex for
all the great reasons. Uh, we do.

58
00:02:59,650 --> 00:03:03,880
And that's going to open up a
whole new world of a gist of how,

59
00:03:03,881 --> 00:03:08,590
of applying science to what it means
to be a human with a lot of new

60
00:03:08,591 --> 00:03:09,310
possibilities.

61
00:03:09,310 --> 00:03:12,700
That's what going to be so freaking when
people stop having sex to make kids and

62
00:03:12,701 --> 00:03:16,150
they make kids in a lab. Every kid's
mean in the lab when not only that,

63
00:03:16,151 --> 00:03:20,140
I think we're going to move to an era,
an era where people who have,

64
00:03:20,200 --> 00:03:25,060
who make babies through sex
will be seen as taking a risk.

65
00:03:25,061 --> 00:03:29,290
Kind of like people who don't vaccinate
their kids where it's natural to not,

66
00:03:29,291 --> 00:03:32,380
it's more natural to not vaccinate your
kids than to do it, but people say,

67
00:03:32,381 --> 00:03:35,890
wait a second, you're taking on
a risk on behalf of your kids.

68
00:03:35,891 --> 00:03:40,600
About 3% of all kids in the world are
born with some kind of harmful genetic

69
00:03:40,601 --> 00:03:44,560
abnormality using in vitro
fertilization and embryo screening.

70
00:03:44,561 --> 00:03:47,530
That 3% can be brought down significantly.

71
00:03:47,531 --> 00:03:51,520
And what happens if you see somebody 20
years from now who has a kid with one of

72
00:03:51,521 --> 00:03:55,650
those preventable diseases? Do you
think that's fate or do you think, well,

73
00:03:55,660 --> 00:03:57,310
wait a second.
Those parents,

74
00:03:57,730 --> 00:04:02,400
they made an ideological decision about
how they want it to conceive their kids.

75
00:04:02,420 --> 00:04:07,270
I think we're moving towards some really
deep and fundamental changes. Sim. Well,

76
00:04:08,020 --> 00:04:12,760
yeah, that's a, that's an interesting
conversation of whether or not

77
00:04:14,220 --> 00:04:18,540
you wonder what if we're ever going to
get to a point where people don't allow

78
00:04:18,541 --> 00:04:22,230
people sort of like, people don't allow
people to not get vaccinated right now.

79
00:04:22,260 --> 00:04:25,110
Like there's a lot of that going on today,
right?

80
00:04:26,500 --> 00:04:28,990
Which is great, right? You don't
want diseases floating around.

81
00:04:29,320 --> 00:04:34,150
But what if that gets to the place
where we do that with people,

82
00:04:34,180 --> 00:04:36,580
with people creating new life
forms? What if you say, hey,

83
00:04:36,940 --> 00:04:40,650
you are being irresponsible. You just
having sex and having a kid. Yeah,

84
00:04:40,750 --> 00:04:44,560
I know that's your grandma did it. We
don't do it that way in 2099. Yeah,

85
00:04:44,980 --> 00:04:48,070
I think it's going to be hard to do that
in a society like the United States,

86
00:04:48,220 --> 00:04:51,820
but in a country like North
Korea, there'll be able to
do that. Or if a country,

87
00:04:51,821 --> 00:04:55,760
if they said, look, um, you can
make babies however you want. Um,

88
00:04:55,870 --> 00:05:00,700
but if you make babies the old fashioned
way and if you have some kind of

89
00:05:00,730 --> 00:05:04,120
genetic, your kid has some kind of
genetic disorder that was preventable.

90
00:05:04,330 --> 00:05:06,850
We're just not going to
cover it with insurance.

91
00:05:06,851 --> 00:05:11,110
So you're going to have a
$10 million lifetime bill,

92
00:05:11,400 --> 00:05:14,050
but you don't need to,
you don't need to require something.

93
00:05:14,051 --> 00:05:17,340
You can create an environment where
people's behaviors will change it.

94
00:05:17,350 --> 00:05:21,070
And then there are, there
will be increasing social
pressures. I mean right now,

95
00:05:21,460 --> 00:05:21,731
you know,

96
00:05:21,731 --> 00:05:24,940
somebody sees some little kid riding
around their bicycle without a helmet.

97
00:05:25,210 --> 00:05:27,370
They're kind of looking at the
parents like, Hey, what are you doing?

98
00:05:27,371 --> 00:05:29,380
How come you're, you're, you
don't have a helmet on your kids.

99
00:05:29,800 --> 00:05:34,060
And I just think that we're moving
toward this kind of societal change where

100
00:05:34,420 --> 00:05:37,520
people will, I believe, see, uh,

101
00:05:37,720 --> 00:05:41,740
conceiving their kids in the lab
as a safer, safer alternative.

102
00:05:41,741 --> 00:05:43,990
And it's not just safety
because once you do that,

103
00:05:44,290 --> 00:05:49,290
then that opens you up to the possibility
of all other kinds of applications of

104
00:05:50,140 --> 00:05:50,711
technology,

105
00:05:50,711 --> 00:05:55,630
not just not just to eliminate
risks or prevent disease,

106
00:05:55,990 --> 00:05:57,860
but you have a lot more information.

107
00:05:57,860 --> 00:06:02,860
So already it's possible to active roughly
rank order 15 pre implanted embryos,

108
00:06:03,531 --> 00:06:08,531
tallest to shortest in a
decade from highest a genetic
component of Iq to lowest

109
00:06:09,021 --> 00:06:12,080
genetic component of is. I mean this
stuff is very real and it's very personal.

110
00:06:12,830 --> 00:06:15,320
What do you think will be the first
thing that people start manipulating?

111
00:06:16,010 --> 00:06:21,010
I think certainly health health is will
be the primary driver because that's

112
00:06:21,530 --> 00:06:23,360
every parents biggest fear and that's,

113
00:06:23,690 --> 00:06:26,510
that is what is going to be
kind of the entry application.

114
00:06:26,511 --> 00:06:31,340
People wanting to make sure that their
kids don't suffer from terrible genetic

115
00:06:31,700 --> 00:06:35,780
diseases. And then I think the
second will probably be longevity.

116
00:06:35,781 --> 00:06:40,310
I mean right now there's a lot of work
going uh, going on sequencing, um,

117
00:06:40,340 --> 00:06:40,791
people,

118
00:06:40,791 --> 00:06:45,020
the super agers people who live to their
late nineties people do a hundred to

119
00:06:45,021 --> 00:06:48,230
identify what are the genetic
patterns that these people have.

120
00:06:48,230 --> 00:06:51,440
So it's like to live to 90, you have
to do all the things that you advocate,

121
00:06:51,441 --> 00:06:52,580
healthy living and whatever.

122
00:06:52,581 --> 00:06:56,060
But to live to into a hundred you really
need the genetics to make that possible.

123
00:06:56,061 --> 00:07:00,050
So we're going to identify what are some
of the genetic patterns that allow you

124
00:07:00,051 --> 00:07:03,440
to live those kinds of, of long
lines. But then after that,

125
00:07:03,890 --> 00:07:08,180
then it's wide open. I mean it's,
it's higher genetic component of Iq,

126
00:07:08,630 --> 00:07:12,350
outgoing personality, faster
sprinter. I mean we are humans,

127
00:07:12,351 --> 00:07:17,351
we are primarily genetic beings and we
are going to be able to look under the

128
00:07:17,571 --> 00:07:22,571
hood of what it means to be human and
we'll have these incredible choices and we

129
00:07:22,611 --> 00:07:24,020
have,
it's a huge responsibility.

130
00:07:24,050 --> 00:07:26,630
How long do you think before
you have a person with forearms?

131
00:07:27,260 --> 00:07:30,890
I think it's going to take a long time.
Couple hundred years. Well, the thing is,

132
00:07:30,930 --> 00:07:35,450
here's how I see it. So the real driver,
there's two, two primary drivers.

133
00:07:35,451 --> 00:07:39,140
One will be embryo
selection. Um, so right now,

134
00:07:39,141 --> 00:07:43,130
average woman going through IVF
has about 15 eggs extracted.

135
00:07:43,640 --> 00:07:46,820
Um, and then in IVF,
in vitro fertilization,

136
00:07:46,880 --> 00:07:51,880
those eggs are fertilized using the male
sperm and an average male ejaculation.

137
00:07:53,270 --> 00:07:56,840
There's about a billion sperm cell.
So managers given it away. Women,

138
00:07:57,290 --> 00:08:00,170
human female mammals are a little
bit or a little bit stingy.

139
00:08:00,590 --> 00:08:04,300
But then the next killer
application is using a process, um,

140
00:08:04,500 --> 00:08:08,750
called induced pluripotent stem cells.
And so Shinya Yamanaka these great,

141
00:08:08,800 --> 00:08:13,250
a Japanese scientist won the 2012 Nobel
prize for developing a way to turn any

142
00:08:13,251 --> 00:08:17,450
adult cell into a stem cell. So a stem
cells, a kind of cell, it can be anything.

143
00:08:17,960 --> 00:08:22,820
Um, and so you take let's say a skin
graft that has millions of cells.

144
00:08:23,210 --> 00:08:27,680
You induce those as those adult
skin cells into stem cells.

145
00:08:27,680 --> 00:08:30,860
So you use these four things called
Yamanaka factors. And so now you have,

146
00:08:31,280 --> 00:08:36,280
let's call it a hundred thousand stem
cells and then you can induce those cells

147
00:08:36,860 --> 00:08:39,860
into egg precursor cells and then eggs.

148
00:08:39,890 --> 00:08:44,270
So all of a sudden humans are creating
eggs like salmon on this huge scale.

149
00:08:44,271 --> 00:08:46,700
So you have 100,000 eggs,

150
00:08:46,970 --> 00:08:51,500
fertilize them with the male sperm
in a machine and automated process.

151
00:08:51,501 --> 00:08:56,501
You grow them for about five days and
then you sequence cells extracted from

152
00:08:56,850 --> 00:08:58,110
each one of those.

153
00:08:58,170 --> 00:09:03,170
And the cost of genome sequencing in
2003 it was $1 billion and now it's $800.

154
00:09:03,751 --> 00:09:08,100
It's going to be next to nothing within
a decade. And then you have real options.

155
00:09:08,101 --> 00:09:08,970
Cause then you get this,

156
00:09:09,010 --> 00:09:12,630
put this whole spreadsheet and algorithm
and then you go to the parents.

157
00:09:12,631 --> 00:09:16,200
They will, what are your priorities? And
maybe they'll say, well I want health,

158
00:09:16,350 --> 00:09:20,700
I want longevity. I want
high Iq when you're choosing
from big numbers like that,

159
00:09:20,701 --> 00:09:23,220
you have some real options.
And then on top of that,

160
00:09:23,221 --> 00:09:27,120
then there is this precision gene
editing the stuff that happened in,

161
00:09:27,121 --> 00:09:29,930
in China last year. And I think it
will, it will be. And the reason,

162
00:09:29,931 --> 00:09:32,970
coming back to your question about
forearms, I think it's going to be varied.

163
00:09:32,971 --> 00:09:36,590
People have this idea that tools
like Chris Berg and abused,

164
00:09:36,600 --> 00:09:40,010
someone's going to sit at a computer and
say like forearms and three heads and,

165
00:09:40,150 --> 00:09:43,590
and wings and, and whatever. But
it's pretty hard because, um,

166
00:09:43,650 --> 00:09:48,210
human biology is incredibly complicated
and we, we, we always know more,

167
00:09:48,570 --> 00:09:52,890
um, the worth the very beginning of
understanding the full complexity of human

168
00:09:52,891 --> 00:09:55,110
biology enough to make
these big kinds of changes.

169
00:09:55,111 --> 00:09:57,930
But if you're choosing from
100,000 fertilized eggs,

170
00:09:57,931 --> 00:10:00,570
those are all your natural kids.
Yeah.

171
00:10:00,690 --> 00:10:04,680
And then you would get the best of
that and then work on those. Exactly.

172
00:10:04,720 --> 00:10:07,560
That's exactly the model. You get
that and then you say, all right,

173
00:10:07,590 --> 00:10:12,590
what if you had like 20 sons that were
awesome and they didn't tell you about 18

174
00:10:12,751 --> 00:10:13,051
of them?

175
00:10:13,051 --> 00:10:18,030
And you kept two of them than 18 of them
shipped off to some military industrial

176
00:10:18,031 --> 00:10:20,340
complex. Yeah. Turn them into assassins.

177
00:10:20,670 --> 00:10:23,790
Any kind of crazy thing you can
think of as the problem, right?

178
00:10:23,820 --> 00:10:26,250
It's all this stuff will be possible.
And so,

179
00:10:26,490 --> 00:10:29,610
and a lot of technologies you can
imagine all kinds of crazy stuff.

180
00:10:29,611 --> 00:10:32,060
And that's coming back to your
earlier point about regulations.

181
00:10:32,070 --> 00:10:34,990
We want to live in
regulated environments mean.

182
00:10:35,060 --> 00:10:36,870
So like now think of the
Internet and you know,

183
00:10:36,871 --> 00:10:38,550
in the beginning days of the
Internet people thought, Oh,

184
00:10:38,551 --> 00:10:42,240
just let the Internet be let you know.
Just let it play out.

185
00:10:42,241 --> 00:10:43,380
It's going to liberate all of us.

186
00:10:43,381 --> 00:10:48,240
And now China's showing how the Internet
can be actually be really actively used

187
00:10:48,241 --> 00:10:49,960
to suppress people.
Facebook is,

188
00:10:49,961 --> 00:10:53,280
is taking people's information and
Google in a way that's frightening.

189
00:10:53,281 --> 00:10:54,450
A lot of people and peers are saying,
hey,

190
00:10:54,810 --> 00:10:57,270
it shouldn't be that these
companies can do whatever they want.

191
00:10:57,271 --> 00:11:01,980
We have to have some way of establishing
limits because not every individual is

192
00:11:01,981 --> 00:11:04,800
able to entirely protect themselves.
They don't have the power,

193
00:11:04,801 --> 00:11:06,090
they don't have all the information.

194
00:11:06,300 --> 00:11:08,600
We need some representatives
helping us with the,

195
00:11:08,760 --> 00:11:11,070
the real concern is the competition,
right?

196
00:11:11,100 --> 00:11:14,700
The real concern is whether or not we
do something with rigging in regards to

197
00:11:14,701 --> 00:11:15,360
regulation.

198
00:11:15,360 --> 00:11:18,870
That's somehow another stifles competition
on our end and doesn't allow us to

199
00:11:18,871 --> 00:11:22,230
compete with Russia and
China, particularly China.
Yeah, that's exactly right.

200
00:11:22,231 --> 00:11:25,680
And so, um, what we need to
do is to find that balance.

201
00:11:25,681 --> 00:11:29,100
And one of the big issues,
uh, for this is privacy.

202
00:11:29,130 --> 00:11:30,540
So if you kind of look around the world,

203
00:11:30,541 --> 00:11:33,960
let's say there's the kind of the big
countries and groupings of countries,

204
00:11:33,961 --> 00:11:36,510
there's three models of privacy.
There's Europe,

205
00:11:36,720 --> 00:11:40,050
which has the strongest privacy
protections for all kinds of data,

206
00:11:40,051 --> 00:11:41,460
including genetic data.

207
00:11:41,970 --> 00:11:46,590
There's China that has the weakest and
there's the United States that has the

208
00:11:46,591 --> 00:11:50,490
middle. And the paradox is
from an individual perspective,

209
00:11:50,550 --> 00:11:52,440
we are all thinking,
well,

210
00:11:52,590 --> 00:11:55,660
we kind want to be like Europe because
I don't want somebody accessing my

211
00:11:55,661 --> 00:11:58,000
personal information,
especially my genetic information.

212
00:11:58,001 --> 00:12:00,250
This is like my most intimate information.

213
00:12:00,700 --> 00:12:05,110
But genetics is the
ultimate big data problem.

214
00:12:05,170 --> 00:12:09,820
And so you need these big data pools
and you'd access to dig these big data

215
00:12:09,821 --> 00:12:13,050
pools in order to unlock
the secrets of genetics.

216
00:12:13,051 --> 00:12:14,620
So these three different groupings,

217
00:12:14,621 --> 00:12:18,430
everyone's making a huge bet on the
future and the way we're going to know who

218
00:12:18,431 --> 00:12:21,490
wins. Like right now in
the, in the it world,

219
00:12:21,491 --> 00:12:25,150
we have Amazon and apple and
Google and those big companies,

220
00:12:25,151 --> 00:12:26,650
but whoever gets this bet,
right?

221
00:12:27,010 --> 00:12:32,010
They will be the ones who will be leading
the way and making a huge amount of of

222
00:12:32,110 --> 00:12:35,770
money on these technologies because
we're talking about is, is it trillion,

223
00:12:35,771 --> 00:12:37,750
multi trillion dollar industry.
Okay.

