WEBVTT
Kind: captions
Language: en

00:00:02.570 --> 00:00:04.820
MALE SPEAKER: I'm pleased
to welcome Matt Richtel back

00:00:04.820 --> 00:00:05.320
to Google.

00:00:05.320 --> 00:00:07.350
I say, welcome
back, since he spoke

00:00:07.350 --> 00:00:10.002
at one of the first authors
at Google events in San

00:00:10.002 --> 00:00:11.710
Francisco about seven
years ago, so we're

00:00:11.710 --> 00:00:13.120
delighted to have him back.

00:00:13.120 --> 00:00:15.530
So Matt, as many of you know,
is investigative journalist

00:00:15.530 --> 00:00:16.890
for the "New York Times."

00:00:16.890 --> 00:00:21.320
He won a Pulitzer Prize in
2010 for his work on the issue

00:00:21.320 --> 00:00:22.820
of distracted driving.

00:00:22.820 --> 00:00:24.920
And today, he's here to
talk about his new book.

00:00:24.920 --> 00:00:27.170
It's actually not that new,
but it's new on paperback,

00:00:27.170 --> 00:00:29.570
I believe-- "A
Deadly Wandering."

00:00:29.570 --> 00:00:32.500
We'll do about 20-ish minutes
of a presentation by Matt.

00:00:32.500 --> 00:00:34.540
We'll do some question
and answer after that.

00:00:34.540 --> 00:00:36.540
And there are books in
the back for those of you

00:00:36.540 --> 00:00:37.736
who are here live.

00:00:37.736 --> 00:00:39.111
Please join me in
welcoming Matt.

00:00:39.111 --> 00:00:42.580
[APPLAUSE]

00:00:42.580 --> 00:00:43.830
MATT RICHTEL: Thank you, Such.

00:00:47.020 --> 00:00:51.590
So, a quick preface-- you
mentioned the first book.

00:00:51.590 --> 00:00:54.910
The first book came out in 2007.

00:00:54.910 --> 00:00:58.340
And just a brief anecdote about
it-- it was called "Hooked."

00:00:58.340 --> 00:01:01.210
And a friend of mine,
actually right around here,

00:01:01.210 --> 00:01:04.519
went to Barnes &amp;
Noble and saw it

00:01:04.519 --> 00:01:08.340
on the front table,
sandwiched between a book

00:01:08.340 --> 00:01:13.350
by Martha Stewart and
a Superman anthology.

00:01:13.350 --> 00:01:16.040
And he was very fired up.

00:01:16.040 --> 00:01:18.050
This here's his buddy
Matt's first book.

00:01:18.050 --> 00:01:22.910
He takes out his camera phone,
goes to take a picture of it.

00:01:22.910 --> 00:01:26.680
And the clerk comes from behind
the desk and says, "Excuse me,

00:01:26.680 --> 00:01:27.180
sir.

00:01:27.180 --> 00:01:28.120
What are you doing?"

00:01:28.120 --> 00:01:30.700
He says, "I'm taking a
picture of my friend's book."

00:01:30.700 --> 00:01:33.640
And the guy goes, "You've
got to be kidding me.

00:01:33.640 --> 00:01:36.770
You're friends with
Martha Stewart?"

00:01:36.770 --> 00:01:39.750
Quick question, for those
of you live-- anybody

00:01:39.750 --> 00:01:44.220
currently in a bad
relationship, or have you

00:01:44.220 --> 00:01:46.550
been in a bad relationship?

00:01:46.550 --> 00:01:49.471
Show of hands-- one, two, three.

00:01:49.471 --> 00:01:51.220
Are you in a bad
relationship with someone

00:01:51.220 --> 00:01:53.630
you're sitting next
to you right now?

00:01:53.630 --> 00:01:54.770
No, OK.

00:01:54.770 --> 00:01:58.380
I am going to propose
today that you

00:01:58.380 --> 00:02:00.980
are in a bad relationship
with your phone.

00:02:03.800 --> 00:02:05.620
It's a lot like
your relationship

00:02:05.620 --> 00:02:08.820
with your high school
sweetheart, where

00:02:08.820 --> 00:02:10.810
it seemed really good.

00:02:10.810 --> 00:02:15.490
But in retrospect, she
or he was a lot more

00:02:15.490 --> 00:02:17.750
demanding than you
realized at the time.

00:02:17.750 --> 00:02:19.570
You didn't quite fit right.

00:02:19.570 --> 00:02:24.500
Maybe you needed some time apart
to get your perspective back.

00:02:24.500 --> 00:02:28.560
This is going to be a little
bit about the question,

00:02:28.560 --> 00:02:29.992
is technology addictive?

00:02:29.992 --> 00:02:31.950
I'm going to get to an
answer to that question.

00:02:31.950 --> 00:02:35.160
It's going to go far
afield of the car, which

00:02:35.160 --> 00:02:38.790
is where my research
started in the series

00:02:38.790 --> 00:02:41.610
that Such alluded
to, "Previously

00:02:41.610 --> 00:02:42.560
Undistracted Driving."

00:02:42.560 --> 00:02:44.851
I'm going to talk about your
relationship to your phone

00:02:44.851 --> 00:02:45.590
broadly.

00:02:45.590 --> 00:02:50.110
There are some really, really
remarkable research right now.

00:02:50.110 --> 00:02:52.370
I think this is a great
audience to be discussing it

00:02:52.370 --> 00:02:52.869
in front of.

00:02:52.869 --> 00:02:54.520
But that said,
I'm going to start

00:02:54.520 --> 00:02:57.950
by just telling you
I about something

00:02:57.950 --> 00:02:59.790
that happened in a car.

00:02:59.790 --> 00:03:02.370
Because it is the narrative
throughline of the book,

00:03:02.370 --> 00:03:04.550
"A Deadly Wandering."

00:03:04.550 --> 00:03:08.647
It happened on the last
day of summer in 2006.

00:03:08.647 --> 00:03:09.980
And I want you to meet this guy.

00:03:09.980 --> 00:03:12.860
His name is Reggie Shaw.

00:03:12.860 --> 00:03:16.880
He looks and is exactly
what you see here.

00:03:16.880 --> 00:03:19.580
He is the veritable
All-American kid.

00:03:19.580 --> 00:03:23.370
And when I say that, he is the
good kind of All-American kid,

00:03:23.370 --> 00:03:24.600
like the nice guy.

00:03:24.600 --> 00:03:28.380
You know, like, A minuses
and B pluses, not A pluses.

00:03:28.380 --> 00:03:30.410
And he played on
the basketball team,

00:03:30.410 --> 00:03:32.210
but was the nice kind of jock.

00:03:32.210 --> 00:03:35.320
And he really just
wanted to fall in love.

00:03:35.320 --> 00:03:40.470
And he really, really wanted
to go on an LDS mission.

00:03:40.470 --> 00:03:43.950
He lived in the
northernmost county of Utah.

00:03:43.950 --> 00:03:48.100
And he was on his mission
in the summer, the beginning

00:03:48.100 --> 00:03:52.780
of the summer of
2006 when he felt

00:03:52.780 --> 00:03:55.800
duty-bound to admit
something to the president

00:03:55.800 --> 00:03:59.230
of the missionary
training center.

00:03:59.230 --> 00:04:02.670
He'd had premarital sex, and
he had not come clean about it

00:04:02.670 --> 00:04:05.510
to his bishop and had not
done the spiritual work.

00:04:05.510 --> 00:04:08.860
And in the LDS
community, that's not OK.

00:04:08.860 --> 00:04:11.140
And he knew that he would
come home humiliated

00:04:11.140 --> 00:04:12.230
in front of his community.

00:04:12.230 --> 00:04:16.610
Why do I tell you this seemingly
startling and even intimate

00:04:16.610 --> 00:04:20.800
detail about this young man who
was 19 years old at the time?

00:04:20.800 --> 00:04:25.610
Because this is a guy
who's a good, good guy.

00:04:25.610 --> 00:04:30.430
He's also a guy who might
not tell the truth if he were

00:04:30.430 --> 00:04:32.810
pressed, like telling
his ward bishop that he

00:04:32.810 --> 00:04:37.040
hadn't had premarital sex when
he had, to go on his mission.

00:04:37.040 --> 00:04:40.790
And on the last day of summer
2006, it was September.

00:04:40.790 --> 00:04:42.640
He was back from
his Mormon mission

00:04:42.640 --> 00:04:45.400
doing the spiritual
work to go back again.

00:04:45.400 --> 00:04:48.050
And he was driving at
6:30 in the morning

00:04:48.050 --> 00:04:51.510
on a mountainous road through
the northernmost county

00:04:51.510 --> 00:04:53.480
of Utah.

00:04:53.480 --> 00:04:55.270
He was going 55 miles an hour.

00:04:55.270 --> 00:04:59.260
Despite the fact that it
was the last day of summer,

00:04:59.260 --> 00:05:02.660
it was starting to
rain freezing rain.

00:05:02.660 --> 00:05:05.970
And there was a car
behind him, a truck

00:05:05.970 --> 00:05:11.560
carrying two tons of horseshoes
and horseshoe-making equipment.

00:05:11.560 --> 00:05:13.970
You guys, this is a
missile at highway speeds.

00:05:13.970 --> 00:05:18.210
And the driver of it is
noticing that Reggie,

00:05:18.210 --> 00:05:22.790
our All-American young man,
is occasionally swerving

00:05:22.790 --> 00:05:25.966
across the yellow divider.

00:05:25.966 --> 00:05:27.590
Coming the other
direction this morning

00:05:27.590 --> 00:05:30.760
are these two guys, Jim
Furfaro and Keith O'Dell.

00:05:30.760 --> 00:05:32.350
Jim has the beard.

00:05:32.350 --> 00:05:34.990
They are-- sincerely,
not cliched--

00:05:34.990 --> 00:05:36.320
they are rocket scientists.

00:05:36.320 --> 00:05:40.790
They are building the booster
for the next space shuttle.

00:05:40.790 --> 00:05:43.740
They're commuting to work.

00:05:43.740 --> 00:05:46.430
The guy without the beard,
Keith, is known as the genius.

00:05:46.430 --> 00:05:48.100
He's won the
highest safety award

00:05:48.100 --> 00:05:51.490
from NASA, the Snoopy award.

00:05:51.490 --> 00:05:54.180
And the next time Reggie
crosses the yellow divider,

00:05:54.180 --> 00:05:56.670
he clips the Saturn
these two guys are in,

00:05:56.670 --> 00:06:03.540
it spins across the road,
it is nailed broadside

00:06:03.540 --> 00:06:05.600
by the guy carrying
two tons of horseshoes

00:06:05.600 --> 00:06:08.510
and horseshoe-making equipment.

00:06:08.510 --> 00:06:10.275
The rocket scientists
are dead on impact.

00:06:15.300 --> 00:06:18.270
I hope you'll pick up the
book, "A Deadly Wandering."

00:06:18.270 --> 00:06:20.070
I don't want to circumvent it.

00:06:20.070 --> 00:06:23.100
I don't want to undermine
the drama of it.

00:06:23.100 --> 00:06:28.600
But what ensues is a
remarkable, seminal mystery,

00:06:28.600 --> 00:06:29.690
an investigation.

00:06:29.690 --> 00:06:33.130
But it is ultimately determined
over Reggie's denials

00:06:33.130 --> 00:06:35.310
that he has texted 11
times in the minutes

00:06:35.310 --> 00:06:37.600
and seconds around the crash.

00:06:37.600 --> 00:06:40.530
And it leads to the
first criminal trial,

00:06:40.530 --> 00:06:42.265
certainly in Utah,
maybe in the US.

00:06:44.840 --> 00:06:47.584
So since that time,
I've told you today

00:06:47.584 --> 00:06:49.500
that we're not going to
be talking exclusively

00:06:49.500 --> 00:06:51.020
about texting and driving.

00:06:51.020 --> 00:06:53.620
But I want to frame
the conversation

00:06:53.620 --> 00:06:57.200
around that for this
very significant reason.

00:06:57.200 --> 00:07:00.100
If we can text and
drive in the car

00:07:00.100 --> 00:07:05.350
when we're moving, when lives
are at stake, when we know it,

00:07:05.350 --> 00:07:08.400
what does it say about our
behavior the rest of the time?

00:07:08.400 --> 00:07:10.750
So I want to tell
you something here.

00:07:10.750 --> 00:07:14.690
I want to tell you about a
remarkable statistical gap.

00:07:14.690 --> 00:07:20.430
Currently, these figures are
from-- forgive me the source.

00:07:20.430 --> 00:07:25.140
It's the AAA Foundation for
Highway Safety, Traffic Safety.

00:07:25.140 --> 00:07:27.860
84.4% of us say
texting and driving

00:07:27.860 --> 00:07:31.410
is completely unacceptable.

00:07:31.410 --> 00:07:36.460
36% say they read or
text while driving.

00:07:36.460 --> 00:07:37.820
27% have sent one.

00:07:37.820 --> 00:07:42.990
That's 2014, not a good gap
between what we say we believe

00:07:42.990 --> 00:07:46.740
and how we behave--
not the startling part.

00:07:46.740 --> 00:07:49.120
Here's the startling part.

00:07:49.120 --> 00:07:52.600
That behavior's up since 2012.

00:07:52.600 --> 00:07:57.870
All the PSAs, the public
service number announcements,

00:07:57.870 --> 00:08:03.200
all the laws passed-- the
gap is widening between what

00:08:03.200 --> 00:08:08.010
we say is wrong and what we do.

00:08:08.010 --> 00:08:10.470
You guys want to hear
the gap that sounds

00:08:10.470 --> 00:08:13.402
most similar to that to me?

00:08:13.402 --> 00:08:14.860
Anybody want to
take a guess that's

00:08:14.860 --> 00:08:19.980
here where there's such a gap
between what we say we believe

00:08:19.980 --> 00:08:20.850
and how we behave?

00:08:24.000 --> 00:08:26.170
Not drinking-- we're
better at that.

00:08:26.170 --> 00:08:28.910
What else?

00:08:28.910 --> 00:08:34.350
Smoking-- every smoker
says, this is not exactly

00:08:34.350 --> 00:08:36.820
a great idea for my health.

00:08:36.820 --> 00:08:37.840
They do it anyway.

00:08:37.840 --> 00:08:39.830
Why do they do it?

00:08:39.830 --> 00:08:40.567
It's addictive.

00:08:40.567 --> 00:08:42.650
We're going to get to the
question of whether it's

00:08:42.650 --> 00:08:43.960
addictive today.

00:08:43.960 --> 00:08:46.770
But to get there, I want
to tell you a little bit

00:08:46.770 --> 00:08:50.270
about your brain on computers,
about your relationship

00:08:50.270 --> 00:08:50.940
with computers.

00:08:50.940 --> 00:08:52.356
And to do so, I'm
going to ask you

00:08:52.356 --> 00:08:54.360
to travel back with me in time.

00:08:54.360 --> 00:08:56.770
We're going to do a
little neuroscience.

00:08:56.770 --> 00:09:01.300
I want you picture
yourself as a cave person.

00:09:01.300 --> 00:09:03.200
So the way to do
this is very simple.

00:09:03.200 --> 00:09:04.750
Picture yourself, but hairier.

00:09:07.990 --> 00:09:08.810
So there you are.

00:09:08.810 --> 00:09:15.420
This is your forbear
tending to a fire, eons ago.

00:09:15.420 --> 00:09:18.270
Lion comes up from
behind, or better yet,

00:09:18.270 --> 00:09:19.750
let's use this example.

00:09:19.750 --> 00:09:21.460
The person tending
to the fire gets

00:09:21.460 --> 00:09:25.350
a tap on his or her
shoulder from behind.

00:09:25.350 --> 00:09:28.210
Can the person ignore
the tap on the shoulder?

00:09:28.210 --> 00:09:28.710
No way.

00:09:28.710 --> 00:09:30.370
I'm getting nodded heads.

00:09:30.370 --> 00:09:31.830
You guys hopefully
live streaming

00:09:31.830 --> 00:09:32.890
are nodding your heads.

00:09:32.890 --> 00:09:34.570
Why can't you ignore the tap?

00:09:37.250 --> 00:09:38.640
Anyone?

00:09:38.640 --> 00:09:41.340
You have no idea if it's
opportunity or threat.

00:09:41.340 --> 00:09:44.040
And maybe the
threat is profound.

00:09:44.040 --> 00:09:45.760
Maybe it's someone with a spear.

00:09:45.760 --> 00:09:47.800
Maybe the opportunity
is a potential mate.

00:09:47.800 --> 00:09:49.270
Maybe it's someone with food.

00:09:49.270 --> 00:09:51.930
Maybe they're
warning of a volcano.

00:09:51.930 --> 00:09:54.940
In the car, here's the analog.

00:09:54.940 --> 00:09:59.840
Driving, phone
rings, proverbial tap

00:09:59.840 --> 00:10:02.640
on the shoulder from anyone,
anywhere in the world.

00:10:02.640 --> 00:10:06.510
Now, I want to tell you what's
happening inside your brain

00:10:06.510 --> 00:10:08.530
at that moment.

00:10:08.530 --> 00:10:13.470
When tending to a
fire, when driving,

00:10:13.470 --> 00:10:18.970
you are using this part
of your brain-- prefrontal

00:10:18.970 --> 00:10:20.947
cortex, frontal lobe.

00:10:20.947 --> 00:10:22.030
I know you guys know this.

00:10:22.030 --> 00:10:23.510
I'll just go over it briefly.

00:10:23.510 --> 00:10:25.460
It is the thing that
makes us the most

00:10:25.460 --> 00:10:27.150
human, the most evolved.

00:10:27.150 --> 00:10:29.720
You can see by comparison
other creatures.

00:10:29.720 --> 00:10:32.300
This is your executive
control center.

00:10:32.300 --> 00:10:35.910
It dictates attention,
focus, decision-making,

00:10:35.910 --> 00:10:37.500
go down the list.

00:10:37.500 --> 00:10:41.320
Art, architecture,
civilization-- all that we are,

00:10:41.320 --> 00:10:45.560
higher levels, is
involved with that.

00:10:45.560 --> 00:10:48.350
And it's involved with
driving-- attending to the road,

00:10:48.350 --> 00:10:51.000
attending to the fire,
like the cave person.

00:10:51.000 --> 00:10:53.360
But when the signal
comes, the tap

00:10:53.360 --> 00:10:58.540
on the shoulder, very roughly,
the signal comes from here.

00:10:58.540 --> 00:11:01.590
This is much more shared
with these other animals.

00:11:01.590 --> 00:11:04.570
The reptilian part of the
brain, ancient, comes up

00:11:04.570 --> 00:11:10.580
and it says, when you have
a roar of the lion-- lion!

00:11:10.580 --> 00:11:12.760
Run or die.

00:11:12.760 --> 00:11:17.020
Someone with a spear--
turn around or die.

00:11:17.020 --> 00:11:19.340
When you're in the car
and the phone rings,

00:11:19.340 --> 00:11:20.730
maybe it's your boss.

00:11:20.730 --> 00:11:22.940
Maybe it's your mate.

00:11:22.940 --> 00:11:26.970
Maybe it's a prince from
Nigeria who needs money.

00:11:26.970 --> 00:11:27.900
You take my point.

00:11:27.900 --> 00:11:30.910
It, in effect, hijacks
that part of your brain.

00:11:30.910 --> 00:11:33.850
It is a basic, primitive thing.

00:11:33.850 --> 00:11:38.300
Put this down in your brains
as point number one, evidence

00:11:38.300 --> 00:11:42.190
point number one, of the ways
in which your phone begins

00:11:42.190 --> 00:11:44.180
to hijack this
part of your brain,

00:11:44.180 --> 00:11:48.907
even against your professed
will or your understanding

00:11:48.907 --> 00:11:49.740
of what's dangerous.

00:11:52.290 --> 00:11:55.070
Just a quick question that
someone will invariably have.

00:11:55.070 --> 00:11:56.980
Such, will you come
up here for a second?

00:12:00.250 --> 00:12:02.410
OK, Such.

00:12:02.410 --> 00:12:04.590
People will ask, why can't
I attend to both things

00:12:04.590 --> 00:12:06.460
at once, two streams
of information?

00:12:06.460 --> 00:12:08.540
Let's just go through
this exercise.

00:12:08.540 --> 00:12:11.740
Recite A to I as
fast as you can.

00:12:11.740 --> 00:12:13.896
MALE SPEAKER: A,B,
C,D, E, F, G, H, I.

00:12:13.896 --> 00:12:16.550
MATT RICHTEL: Well done.

00:12:16.550 --> 00:12:17.930
That is a Googler for you.

00:12:21.290 --> 00:12:21.984
Now, 1 to 9.

00:12:21.984 --> 00:12:23.650
MALE SPEAKER: 1, 2,
3, 4, 5, 6, 7, 8, 9.

00:12:23.650 --> 00:12:24.400
MATT RICHTEL: Wow.

00:12:24.400 --> 00:12:25.400
Now, alternate.

00:12:25.400 --> 00:12:26.330
A, 1, B, 2.

00:12:26.330 --> 00:12:29.476
MALE SPEAKER: A, 1, B,
2, C, 3, D, 4, E, 5.

00:12:29.476 --> 00:12:31.061
MATT RICHTEL: You may sit.

00:12:31.061 --> 00:12:32.310
MALE SPEAKER: Thank you, Matt.

00:12:32.310 --> 00:12:36.330
MATT RICHTEL: So look-- for
those of you keeping score

00:12:36.330 --> 00:12:39.100
at home or at your desks, you
see how much longer it takes.

00:12:39.100 --> 00:12:43.070
That is an act of switching
information streams.

00:12:43.070 --> 00:12:45.990
It's called switching
costs, switching tasks.

00:12:45.990 --> 00:12:47.150
You guys know these terms.

00:12:47.150 --> 00:12:48.822
You've heard of them.

00:12:48.822 --> 00:12:50.530
You're at your desk,
you're in your car--

00:12:50.530 --> 00:12:52.980
to switch among streams
of information takes

00:12:52.980 --> 00:12:58.960
profound, profound
neurological energy,

00:12:58.960 --> 00:13:01.680
even when it's something
as simple as that.

00:13:01.680 --> 00:13:04.227
So now, checklist--
tap on the shoulder,

00:13:04.227 --> 00:13:05.310
you don't know what it is.

00:13:05.310 --> 00:13:07.814
Now I've shown you that you
can't do two things at once.

00:13:07.814 --> 00:13:09.480
We're going to speed
ahead a little bit.

00:13:09.480 --> 00:13:11.260
This is the cost, by
the way, of ignoring

00:13:11.260 --> 00:13:12.520
the tap on the shoulder.

00:13:12.520 --> 00:13:16.160
This is called doing a
PowerPoint when you have

00:13:16.160 --> 00:13:17.600
too much time on your hands.

00:13:17.600 --> 00:13:20.900
You can find anything on
the fancy internet machine.

00:13:20.900 --> 00:13:23.570
OK, look-- it's not just
information that's coming in.

00:13:23.570 --> 00:13:26.460
It's social information.

00:13:26.460 --> 00:13:31.590
Social information also
is critical at an adaptive

00:13:31.590 --> 00:13:34.390
or even primitive DNA level.

00:13:34.390 --> 00:13:36.350
Let me just illustrate
by way of an example.

00:13:36.350 --> 00:13:40.930
Let's go back to our forbear
in front of the fire.

00:13:40.930 --> 00:13:45.280
If my buddy in front of the
fire puts his hand in the fire

00:13:45.280 --> 00:13:48.470
and gets it burned and gets
blisters and gets an infection

00:13:48.470 --> 00:13:53.290
and dies and cannot tell me
that that's what's happened,

00:13:53.290 --> 00:13:56.470
I then have to put my
hand in the fire and I die

00:13:56.470 --> 00:13:58.590
and the species goes with it.

00:13:58.590 --> 00:14:00.900
Social information is critical.

00:14:00.900 --> 00:14:04.010
There's a question as to whether
it's hardwired into our DNA

00:14:04.010 --> 00:14:05.420
or primitively adapted.

00:14:05.420 --> 00:14:08.520
But in any case, we're talking
about the way back machine,

00:14:08.520 --> 00:14:09.310
right?

00:14:09.310 --> 00:14:11.400
So now it's not just
a tap on the shoulder.

00:14:11.400 --> 00:14:12.940
It's social
information that we're

00:14:12.940 --> 00:14:17.422
programmed to respond
to-- one and two-- three.

00:14:17.422 --> 00:14:18.880
One of my favorite
pieces of trivia

00:14:18.880 --> 00:14:23.400
in reading this book--
you would say to yourself,

00:14:23.400 --> 00:14:26.200
if most of the stuff
I get on my phone

00:14:26.200 --> 00:14:28.860
is irrelevant and
even counterproductive

00:14:28.860 --> 00:14:32.210
spam, if you will, wouldn't
that condition me not

00:14:32.210 --> 00:14:34.620
to look at my device?

00:14:34.620 --> 00:14:38.390
Anyone want to take
a stab at this one?

00:14:38.390 --> 00:14:40.910
Not you, because you've read
the book, and can, by the way,

00:14:40.910 --> 00:14:42.420
can vouch for the book.

00:14:42.420 --> 00:14:43.884
MALE SPEAKER: Absolutely.

00:14:43.884 --> 00:14:44.759
Absolutely.

00:14:44.759 --> 00:14:45.550
I'll do that later.

00:14:45.550 --> 00:14:47.080
MATT RICHTEL: An
astounding review.

00:14:50.800 --> 00:14:53.120
Get them while they're hot.

00:14:53.120 --> 00:14:55.090
Here's why.

00:14:55.090 --> 00:14:58.410
When you get irrelevant
information all the time,

00:14:58.410 --> 00:15:00.880
you never know when the
good piece of information

00:15:00.880 --> 00:15:02.340
is going to come.

00:15:02.340 --> 00:15:05.790
This is the same
thing that makes--

00:15:05.790 --> 00:15:07.792
what's the gizmo
where we pull the--

00:15:07.792 --> 00:15:08.750
AUDIENCE: Slot machine.

00:15:08.750 --> 00:15:10.166
MATT RICHTEL: Thank
you very much.

00:15:10.166 --> 00:15:12.440
But I'll make it a
more profound example.

00:15:12.440 --> 00:15:13.940
B.F. Skinner, you
guys have probably

00:15:13.940 --> 00:15:15.580
heard of-- Skinnerian
psychology,

00:15:15.580 --> 00:15:18.370
behavioral psychology.

00:15:18.370 --> 00:15:23.270
Way back when, he
does an experiment.

00:15:23.270 --> 00:15:27.440
Rat in a cage-- there's
that lever in the cage.

00:15:27.440 --> 00:15:31.740
Rat doesn't know which press
of the lever will bring food.

00:15:31.740 --> 00:15:34.896
So the rat hits the
lever all the time.

00:15:34.896 --> 00:15:36.520
It's called intermittent
reinforcement,

00:15:36.520 --> 00:15:39.470
one of the most powerful
lures in psychology,

00:15:39.470 --> 00:15:42.420
if you'll forgive the
comparison of us to rodents.

00:15:42.420 --> 00:15:44.310
You see where I'm
going with this.

00:15:44.310 --> 00:15:47.270
Intermittent reinforcement--
will press the lever for food,

00:15:47.270 --> 00:15:50.230
will hit mouse for food--
mouse, rodent, rat.

00:15:50.230 --> 00:15:52.150
Now I've gone on a
terrible tangent.

00:15:55.120 --> 00:15:56.730
The lure of worthless data.

00:15:56.730 --> 00:16:00.120
So the fact that
it's irrelevant data

00:16:00.120 --> 00:16:03.640
doesn't make this
less appealing.

00:16:03.640 --> 00:16:06.260
It can make it more appealing.

00:16:06.260 --> 00:16:08.610
Tap on the shoulder--
a mechanical activity

00:16:08.610 --> 00:16:09.530
of survival.

00:16:09.530 --> 00:16:12.830
Social information-- the
lure of worthless activity.

00:16:12.830 --> 00:16:16.930
OK, this one's pretty
early in the research.

00:16:16.930 --> 00:16:19.390
But you guys are familiar
with or you've heard

00:16:19.390 --> 00:16:21.240
of the neurochemical dopamine?

00:16:21.240 --> 00:16:25.860
It's the neurochemical involved
in reward structures involved

00:16:25.860 --> 00:16:28.240
in drugs, narcotics.

00:16:28.240 --> 00:16:33.120
There is some early research
that suggests, shows,

00:16:33.120 --> 00:16:34.940
that when you interact
with your device,

00:16:34.940 --> 00:16:39.160
in particular video games, you
get a little burst of dopamine.

00:16:39.160 --> 00:16:40.560
So here's how the
theory goes on.

00:16:40.560 --> 00:16:42.470
And I think we're
still working this out.

00:16:42.470 --> 00:16:44.400
We, I mean, in
society-- I don't want

00:16:44.400 --> 00:16:46.420
to go beyond where
the research is.

00:16:46.420 --> 00:16:50.100
But there's some really
powerful early research

00:16:50.100 --> 00:16:54.310
that essentially says,
leads to a hypothesis,

00:16:54.310 --> 00:16:56.320
that you get a little
burst of dopamine

00:16:56.320 --> 00:16:57.800
when you interact
with your device.

00:16:57.800 --> 00:16:59.050
Do you guys know this feeling?

00:16:59.050 --> 00:17:01.542
A little surge, a
little excitement.

00:17:01.542 --> 00:17:03.000
You get a little
burst of dopamine.

00:17:03.000 --> 00:17:04.458
You get a little
burst of dopamine.

00:17:04.458 --> 00:17:07.420
And then in its
absence, you feel bored.

00:17:07.420 --> 00:17:09.030
So what do you do?

00:17:09.030 --> 00:17:10.619
You seek it out.

00:17:10.619 --> 00:17:13.900
This is a heavy-duty
reinforcement cycle

00:17:13.900 --> 00:17:16.240
at the neurochemical level.

00:17:16.240 --> 00:17:20.099
And this is a quote from the guy
who teaches internet addiction.

00:17:20.099 --> 00:17:22.400
There's actually a class
at a medical school,

00:17:22.400 --> 00:17:23.780
at the University
of Connecticut.

00:17:23.780 --> 00:17:25.849
"You see the computer,
it's one trigger.

00:17:25.849 --> 00:17:27.990
Then you sit at the
keyboard, it's another.

00:17:27.990 --> 00:17:30.150
You push the key,
you get a result.

00:17:30.150 --> 00:17:32.360
There's a cascade of dopamine.

00:17:32.360 --> 00:17:34.190
It's the big kahuna.

00:17:34.190 --> 00:17:38.650
It's in a sense a narcotic."

00:17:38.650 --> 00:17:40.570
And I just want to add
one final thing here

00:17:40.570 --> 00:17:42.470
when we're adding
up these pieces.

00:17:42.470 --> 00:17:46.210
So we've got dopamine,
the tap on the shoulder,

00:17:46.210 --> 00:17:49.910
lure of worthless data,
and the one other.

00:17:49.910 --> 00:17:54.560
And there's one more
here on neurochemicals.

00:17:54.560 --> 00:17:58.990
Harvard researchers have shown
that the sharing of information

00:17:58.990 --> 00:18:02.220
releases dopamine--
of social information.

00:18:02.220 --> 00:18:05.040
Humans so willingly
self-disclose because doing so

00:18:05.040 --> 00:18:07.670
represents an event
with intrinsic value,

00:18:07.670 --> 00:18:12.850
in the same way as with primary
awards such as food and sex.

00:18:12.850 --> 00:18:15.610
So now it's not
just getting stuff.

00:18:15.610 --> 00:18:17.770
It's providing stuff.

00:18:17.770 --> 00:18:20.840
I hope at this point in
the conversation you're

00:18:20.840 --> 00:18:23.440
beginning to view your device
a little differently than you

00:18:23.440 --> 00:18:25.300
may have viewed it previously.

00:18:25.300 --> 00:18:28.340
Yes, it is all
the amazing things

00:18:28.340 --> 00:18:29.840
that we have come to count on.

00:18:29.840 --> 00:18:31.820
It is a communications device.

00:18:31.820 --> 00:18:33.400
It is a navigation device.

00:18:33.400 --> 00:18:35.140
It is an information device.

00:18:35.140 --> 00:18:37.280
This is not a screed
against technology.

00:18:37.280 --> 00:18:39.530
It is also something else.

00:18:39.530 --> 00:18:45.890
It is an act of
neurochemical activity,

00:18:45.890 --> 00:18:47.920
habituation-- maybe
interdependence,

00:18:47.920 --> 00:18:50.320
maybe co-dependence.

00:18:50.320 --> 00:18:52.820
I want to tell you what
all this adds up to.

00:18:52.820 --> 00:18:56.060
I want to give you a theory
that I sort of worked

00:18:56.060 --> 00:19:00.356
with scientists and learned from
scientists and added it all up.

00:19:00.356 --> 00:19:05.190
I want to draw a comparison to
the industrialization of food.

00:19:05.190 --> 00:19:08.800
When food was industrialized,
it was, on the whole,

00:19:08.800 --> 00:19:12.330
a remarkable thing.

00:19:12.330 --> 00:19:13.700
We tilled the fields.

00:19:13.700 --> 00:19:16.460
We got the food where it
needed to go on trucks

00:19:16.460 --> 00:19:24.050
and trains-- more calories to
more people, more survival.

00:19:24.050 --> 00:19:25.740
No way to argue about that.

00:19:25.740 --> 00:19:29.530
But at the same time, as
we industrialized food,

00:19:29.530 --> 00:19:32.350
we came up with
incredible processes

00:19:32.350 --> 00:19:36.100
for creating food
and calories that

00:19:36.100 --> 00:19:38.060
can be so seductive
as to be dangerous.

00:19:38.060 --> 00:19:40.820
And I'm thinking of
the vending machine.

00:19:40.820 --> 00:19:43.100
I'm thinking-- I don't
want to pick on Doritos,

00:19:43.100 --> 00:19:45.600
but that's just the first
thing that comes to mind.

00:19:45.600 --> 00:19:48.240
You know, a Dorito
actually has--

00:19:48.240 --> 00:19:52.090
it's so tasty because it has a
concentration of sugar and fat

00:19:52.090 --> 00:19:54.190
that we crave.

00:19:54.190 --> 00:19:56.240
But the thing is,
in the old days,

00:19:56.240 --> 00:19:59.250
if you got that concentration
of sugar and fat,

00:19:59.250 --> 00:20:02.020
you climbed over a mountain
and went into the cave

00:20:02.020 --> 00:20:04.900
and killed the woolly
mammoth with your bare hands.

00:20:04.900 --> 00:20:07.190
And by the time you ate
that woolly mammoth,

00:20:07.190 --> 00:20:08.800
you sure needed it.

00:20:08.800 --> 00:20:10.430
But now you walk
down the hallway

00:20:10.430 --> 00:20:12.530
and hit a button for a quarter.

00:20:12.530 --> 00:20:13.960
And you've got
sugar and fat that

00:20:13.960 --> 00:20:16.800
leads to-- can lead,
in excessive amounts,

00:20:16.800 --> 00:20:18.470
to diabetes and obesity.

00:20:18.470 --> 00:20:20.740
And we're only
learning now the costs.

00:20:20.740 --> 00:20:22.260
Here's the parallel.

00:20:22.260 --> 00:20:26.150
There is no doubt that this
technology, this communications

00:20:26.150 --> 00:20:29.990
technology, is so
remarkable and amazing

00:20:29.990 --> 00:20:33.380
and leads to efficiencies and
the creation of PowerPoints

00:20:33.380 --> 00:20:40.050
and talking on FaceTime to
grandparents and loved ones.

00:20:40.050 --> 00:20:40.550
Forget it.

00:20:40.550 --> 00:20:43.016
We'll be on the moon soon--
I mean, on Mars soon.

00:20:43.016 --> 00:20:43.890
We'll be on the moon.

00:20:43.890 --> 00:20:46.130
I'm telling you guys.

00:20:46.130 --> 00:20:48.960
America is getting to the moon.

00:20:48.960 --> 00:20:50.010
And that's my next book.

00:20:50.010 --> 00:20:52.040
We will get there.

00:20:52.040 --> 00:20:54.900
Or Mars and beyond--
there's no doubt.

00:20:54.900 --> 00:20:57.429
But I want you to
begin to think about,

00:20:57.429 --> 00:20:59.220
as I have begun to
think about from talking

00:20:59.220 --> 00:21:00.810
to these researchers
and I lay out

00:21:00.810 --> 00:21:04.110
in this context of this
harrowing accident mystery,

00:21:04.110 --> 00:21:06.590
that there is junk
food in our midst.

00:21:06.590 --> 00:21:10.200
And unless we are aware of
the way in which this stuff is

00:21:10.200 --> 00:21:13.380
playing to us, we
may well get whatever

00:21:13.380 --> 00:21:18.510
is the equivalent of obesity and
diabetes, which is distraction.

00:21:18.510 --> 00:21:23.240
So "the cell phone
meets a deep need

00:21:23.240 --> 00:21:25.650
for social connection with
a greater ease and a greater

00:21:25.650 --> 00:21:28.480
potential detriment to
do it in the same way

00:21:28.480 --> 00:21:31.200
that a vending machine
that is right down the hall

00:21:31.200 --> 00:21:32.770
plays to our need for calories."

00:21:32.770 --> 00:21:36.170
This is from a Yale MD and
social media professor.

00:21:36.170 --> 00:21:39.040
Let me just end
with one anecdote.

00:21:39.040 --> 00:21:41.290
I have a son who's
now almost seven,

00:21:41.290 --> 00:21:46.760
but when he was almost two, I
think, or almost three-- this

00:21:46.760 --> 00:21:48.550
is not him.

00:21:48.550 --> 00:21:51.250
He was at his
grandmother's house.

00:21:51.250 --> 00:21:53.240
And I didn't think--
his name's Milo.

00:21:53.240 --> 00:21:56.180
I didn't think he
knew that many words.

00:21:56.180 --> 00:21:59.440
He just kind of would barely
put sentences together.

00:21:59.440 --> 00:22:06.510
And his phone-- I'm starting
the whole presentation over.

00:22:06.510 --> 00:22:10.440
His foot hit one of those little
Fisher-Price mobile phones

00:22:10.440 --> 00:22:12.000
and it rang.

00:22:12.000 --> 00:22:13.510
And he picks it up.

00:22:13.510 --> 00:22:15.430
And I was just so
blown away, because I

00:22:15.430 --> 00:22:18.560
didn't know he knew these words,
certainly not in this order.

00:22:18.560 --> 00:22:20.920
And he picks up the little
phone and he goes, "I'll

00:22:20.920 --> 00:22:23.020
call you from a land line."

00:22:23.020 --> 00:22:27.510
So let this be our
lesson, occasionally

00:22:27.510 --> 00:22:29.360
from the mouth of babes.

00:22:29.360 --> 00:22:31.370
I'll call you from a land line.

00:22:31.370 --> 00:22:33.687
Let's have a chat.

00:22:33.687 --> 00:22:35.520
And incidentally, you
guys, among the things

00:22:35.520 --> 00:22:37.490
we can talk about
are practically,

00:22:37.490 --> 00:22:39.270
what does this mean
in everyday life?

00:22:39.270 --> 00:22:43.060
What are antidotes to it?

00:22:43.060 --> 00:22:44.240
Anyway, lots of things.

00:22:44.240 --> 00:22:44.390
Go.

00:22:44.390 --> 00:22:45.040
MALE SPEAKER: Absolutely.

00:22:45.040 --> 00:22:47.220
So you alluded towards
the end to the angle

00:22:47.220 --> 00:22:48.180
that I'm most
interested in, which

00:22:48.180 --> 00:22:49.270
is the evolutionary angle.

00:22:49.270 --> 00:22:51.120
You mentioned junk food.

00:22:51.120 --> 00:22:53.570
We've got these powerful
evolutionary cues

00:22:53.570 --> 00:22:55.520
for sugars, salts, and fats.

00:22:55.520 --> 00:22:58.700
And processed food
plays right into that.

00:22:58.700 --> 00:23:00.890
So it occurred to me
while you were speaking,

00:23:00.890 --> 00:23:02.980
imagine if people had
jobs where they just

00:23:02.980 --> 00:23:05.117
had to eat Doritos all day.

00:23:05.117 --> 00:23:06.950
I mean, here at Google,
what would they say?

00:23:06.950 --> 00:23:10.950
Stat, we check more email,
like, seven times more email

00:23:10.950 --> 00:23:13.080
than the average,
other tech worker?

00:23:13.080 --> 00:23:15.320
The number is probably
bigger than that.

00:23:15.320 --> 00:23:18.150
It almost feels like we're
paid to eat Doritos all day.

00:23:18.150 --> 00:23:21.125
What's a realistic
solution to you?

00:23:21.125 --> 00:23:24.740
MATT RICHTEL: Well,
that's a great point

00:23:24.740 --> 00:23:25.740
and a great question.

00:23:25.740 --> 00:23:29.150
And let me just
address that briefly

00:23:29.150 --> 00:23:35.130
in the context of distracted
driving, as we blossom out.

00:23:35.130 --> 00:23:38.460
Car issues are not new.

00:23:38.460 --> 00:23:42.350
Drunk driving,
seat belts-- we've

00:23:42.350 --> 00:23:45.810
worked hard as a society to
come to terms with those issues.

00:23:45.810 --> 00:23:48.030
And there are rules
for having them happen.

00:23:48.030 --> 00:23:52.930
But in those instances,
it wasn't the case

00:23:52.930 --> 00:23:58.160
that there was societal pressure
to say, drink and drive.

00:23:58.160 --> 00:24:00.410
And no one ever told
you it was cool not

00:24:00.410 --> 00:24:03.210
to wear your seat belt. Maybe
one buddy joked with you,

00:24:03.210 --> 00:24:04.310
you were wimpy.

00:24:04.310 --> 00:24:06.250
Whatever.

00:24:06.250 --> 00:24:09.150
There is now enormous
societal pressure

00:24:09.150 --> 00:24:10.690
to stay connected all the time.

00:24:10.690 --> 00:24:13.560
And if you start paying
attention to the marketing,

00:24:13.560 --> 00:24:17.130
as I've documented some in
my book, some of the ads

00:24:17.130 --> 00:24:21.160
essentially say, you are uncool
if you don't have a signal,

00:24:21.160 --> 00:24:23.260
even on top of Everest.

00:24:23.260 --> 00:24:25.880
Somehow you are less than
if you're not connected.

00:24:25.880 --> 00:24:31.680
So it goes beyond you're
habituated at your desk.

00:24:31.680 --> 00:24:36.680
You actually are a less than
if you're not connected.

00:24:36.680 --> 00:24:39.910
What's my thought about
ways to address it?

00:24:39.910 --> 00:24:42.670
I actually think some of
the companies in the Valley

00:24:42.670 --> 00:24:46.210
have begun to think about
this, including you guys.

00:24:46.210 --> 00:24:47.730
I did a story a
bit about it where

00:24:47.730 --> 00:24:50.180
you will encourage
people to disconnect

00:24:50.180 --> 00:24:55.040
for the sake of having lucid,
cogent, long-term, creative

00:24:55.040 --> 00:24:56.920
thoughts.

00:24:56.920 --> 00:24:59.230
It's really, really hard to do.

00:24:59.230 --> 00:25:02.020
We were at lunch with a
couple of your colleagues.

00:25:02.020 --> 00:25:05.340
And we were talking
about my writing process.

00:25:05.340 --> 00:25:07.670
And actually, in
retrospect, I said, well,

00:25:07.670 --> 00:25:08.860
I don't do anything special.

00:25:08.860 --> 00:25:10.330
I do one thing special.

00:25:10.330 --> 00:25:12.020
I turn off my phone.

00:25:12.020 --> 00:25:15.792
You cannot get
invested in something.

00:25:15.792 --> 00:25:17.500
You're going to say
you can, and you need

00:25:17.500 --> 00:25:19.200
those streams of information.

00:25:19.200 --> 00:25:22.760
The truth is, what it behaves
as, to a large extent,

00:25:22.760 --> 00:25:25.497
is a procrastination device.

00:25:25.497 --> 00:25:27.080
When you're in the
middle of something

00:25:27.080 --> 00:25:31.229
hard that takes the most
amount of your energy--

00:25:31.229 --> 00:25:32.270
will you testify to this?

00:25:32.270 --> 00:25:32.894
You're nodding.

00:25:32.894 --> 00:25:37.460
You will easily go look at your
phone, because-- so what to do?

00:25:37.460 --> 00:25:39.040
You have a lot of self-control.

00:25:39.040 --> 00:25:41.750
I don't think your boss needs
to hear from you that quickly.

00:25:41.750 --> 00:25:42.280
You tell me.

00:25:42.280 --> 00:25:44.140
I mean, reflect with me.

00:25:44.140 --> 00:25:47.067
What would happen you were 15
minutes late on a response?

00:25:47.067 --> 00:25:48.150
MALE SPEAKER: Interesting.

00:25:48.150 --> 00:25:49.922
We can hash this out
right now, can't we?

00:25:49.922 --> 00:25:51.630
MATT RICHTEL: Oh, yes,
your boss is here.

00:25:51.630 --> 00:25:52.850
MALE SPEAKER: Conveniently.

00:25:52.850 --> 00:25:54.280
It's a good question,
I think, for Googlers.

00:25:54.280 --> 00:25:55.571
I think it varies team to team.

00:25:55.571 --> 00:25:58.360
There are roles where you
are expected to be on call.

00:25:58.360 --> 00:26:01.320
There are some more
forward-thinking folks

00:26:01.320 --> 00:26:03.620
who won't fire you
if that's the case.

00:26:03.620 --> 00:26:04.990
I think it varies.

00:26:04.990 --> 00:26:07.968
Would you guys agree?

00:26:07.968 --> 00:26:08.752
AUDIENCE: Sure.

00:26:08.752 --> 00:26:09.252
It's Google.

00:26:09.252 --> 00:26:09.680
It depends.

00:26:09.680 --> 00:26:10.721
MALE SPEAKER: It depends.

00:26:10.721 --> 00:26:12.680
Dot, dot, dot.

00:26:12.680 --> 00:26:16.650
MATT RICHTEL: So I think
one takeaway for me--

00:26:16.650 --> 00:26:18.590
I'll speak for me--
is understanding

00:26:18.590 --> 00:26:22.400
the habituation that happens
and the feeling of craving that

00:26:22.400 --> 00:26:24.100
begins to develop.

00:26:24.100 --> 00:26:27.940
Once I begin to see that that
is the better part of my desire

00:26:27.940 --> 00:26:32.640
to stay on my device, and
that it's not actually

00:26:32.640 --> 00:26:36.750
this desperate need to
hear the next message that

00:26:36.750 --> 00:26:39.250
will be the difference
between life and death,

00:26:39.250 --> 00:26:41.510
I can draw better lines.

00:26:41.510 --> 00:26:44.579
I mean, it's like the first step
is admitting you have a modem.

00:26:44.579 --> 00:26:46.120
No, that doesn't
really work anymore.

00:26:46.120 --> 00:26:47.200
MALE SPEAKER: So
if I may, I guess

00:26:47.200 --> 00:26:49.690
what you're saying-- we talk
about this as an addiction.

00:26:49.690 --> 00:26:52.256
And so one common behavior
they say or a sign of am I

00:26:52.256 --> 00:26:53.630
an addict or not
is the inability

00:26:53.630 --> 00:26:55.230
to set clear boundaries.

00:26:55.230 --> 00:26:56.110
You set a line.

00:26:56.110 --> 00:26:57.600
You're always crossing it.

00:26:57.600 --> 00:26:59.090
So I guess what
you're saying is,

00:26:59.090 --> 00:27:00.990
the first step is
just being cognizant.

00:27:00.990 --> 00:27:03.890
So if you find yourself
on the top of Everest

00:27:03.890 --> 00:27:05.960
and you need to post
that on Instagram,

00:27:05.960 --> 00:27:09.010
or if the phone dings in
the car and all of a sudden

00:27:09.010 --> 00:27:10.010
the road doesn't matter.

00:27:10.010 --> 00:27:12.960
You have to know
what that ding is,

00:27:12.960 --> 00:27:15.250
you can catch yourself,
and then think,

00:27:15.250 --> 00:27:17.360
do I really want
to be this person?

00:27:17.360 --> 00:27:20.230
MATT RICHTEL: Would it be OK
to throw in a fun study here

00:27:20.230 --> 00:27:21.960
to reinforce the risks?

00:27:21.960 --> 00:27:24.602
Will you guys endure the
chocolate cake study?

00:27:24.602 --> 00:27:25.310
I'll do it quick.

00:27:25.310 --> 00:27:26.890
I'll make it simple.

00:27:26.890 --> 00:27:31.267
Researchers do this study where
they have some people in a room

00:27:31.267 --> 00:27:33.850
and they ask them, do you want
the chocolate cake or the fruit

00:27:33.850 --> 00:27:35.290
cocktail snack?

00:27:35.290 --> 00:27:37.790
But some of the people
going into the experiment,

00:27:37.790 --> 00:27:41.500
into the room, have to
remember a string of numbers.

00:27:41.500 --> 00:27:44.740
To a very statistically
significant degree,

00:27:44.740 --> 00:27:46.940
the people who have to
remember the numbers

00:27:46.940 --> 00:27:48.060
choose the chocolate cake.

00:27:48.060 --> 00:27:50.100
What do the researchers infer?

00:27:50.100 --> 00:27:53.730
They infer that when you're
juggling information,

00:27:53.730 --> 00:27:55.760
you make a very
different decision.

00:27:55.760 --> 00:28:00.180
In fact, you make a, quote,
unquote, "less good" decision.

00:28:00.180 --> 00:28:01.960
So what does this
have to do with what

00:28:01.960 --> 00:28:03.050
we're talking about here?

00:28:03.050 --> 00:28:05.710
There's other research to
back this up, a bunch of it

00:28:05.710 --> 00:28:06.750
in the book.

00:28:06.750 --> 00:28:09.810
But when you are juggling
information on your phone

00:28:09.810 --> 00:28:11.450
or when you're
juggling two streams

00:28:11.450 --> 00:28:13.434
or keeping a lot in
your head, you actually

00:28:13.434 --> 00:28:15.600
can't make a good decision
about whether to even use

00:28:15.600 --> 00:28:16.610
your device.

00:28:16.610 --> 00:28:19.220
It's one of the interesting
things about the car example.

00:28:19.220 --> 00:28:21.877
When you're driving, you're
consuming some of this.

00:28:21.877 --> 00:28:23.460
It makes it hard to
decide, should you

00:28:23.460 --> 00:28:25.042
even answer the phone?

00:28:25.042 --> 00:28:26.500
There's a bunch of
research in here

00:28:26.500 --> 00:28:29.650
that will show you
are more creative,

00:28:29.650 --> 00:28:32.500
you have better memory, you
are better able to learn,

00:28:32.500 --> 00:28:34.380
when you're not
using the device.

00:28:34.380 --> 00:28:36.850
Again, not a screed
against technology,

00:28:36.850 --> 00:28:41.940
but a clarion call,
if you will, to say,

00:28:41.940 --> 00:28:44.580
I can use this to my advantage.

00:28:44.580 --> 00:28:47.000
And I could be
the most powerful.

00:28:47.000 --> 00:28:48.730
It can be a bit of
kryptonite if I don't.

00:28:48.730 --> 00:28:49.730
MALE SPEAKER: Very cool.

00:28:49.730 --> 00:28:52.240
So let's talk back in the
lens of addiction again.

00:28:52.240 --> 00:28:55.820
You also hear that people who
are suffering from an addiction

00:28:55.820 --> 00:28:59.720
find that moment of clarity when
they kind of hit rock bottom.

00:28:59.720 --> 00:29:01.090
And so I know you're a parent.

00:29:01.090 --> 00:29:02.000
There's parents in the audience.

00:29:02.000 --> 00:29:03.666
Imagine if you're
trying to get your kid

00:29:03.666 --> 00:29:06.880
to stop texting and driving or
to put the phone in the trunk

00:29:06.880 --> 00:29:08.120
while they're driving.

00:29:08.120 --> 00:29:11.080
Do you find that folks with
this sort of tech addiction

00:29:11.080 --> 00:29:12.600
need to have that
moment of clarity?

00:29:12.600 --> 00:29:14.500
Do you hear people
talking about,

00:29:14.500 --> 00:29:16.860
I was on the top of Everest
and I needed my phone out.

00:29:16.860 --> 00:29:17.930
That's when I realized
I had a problem.

00:29:17.930 --> 00:29:20.263
Because I don't hear those
stories about tech addiction.

00:29:20.263 --> 00:29:22.682
MATT RICHTEL: Unfortunately,
a lot of those stories--

00:29:22.682 --> 00:29:24.140
and some of them
are in here-- have

00:29:24.140 --> 00:29:26.280
to do about a car incident.

00:29:26.280 --> 00:29:32.630
But you know what's-- I've had
my son or daughter say to me--

00:29:32.630 --> 00:29:35.997
so you guys know this experience
to take it out of the car,

00:29:35.997 --> 00:29:38.580
where someone's trying to talk
to you and you have your device

00:29:38.580 --> 00:29:41.015
and you go, it's just
one thing I have to do.

00:29:41.015 --> 00:29:42.150
You know that, right?

00:29:42.150 --> 00:29:44.500
And you really don't.

00:29:44.500 --> 00:29:47.900
I've had my kids, I think,
more than once say to me--

00:29:47.900 --> 00:29:52.040
I think my son said to me,
"Hey you have kids, you know."

00:29:52.040 --> 00:29:54.660
And I'm aware of this.

00:29:54.660 --> 00:29:58.240
And what happens is when you're
in the moment with that device,

00:29:58.240 --> 00:30:00.740
it is so consuming.

00:30:00.740 --> 00:30:03.930
It's so, so terribly
consuming that you are

00:30:03.930 --> 00:30:06.060
blind to everything around you.

00:30:06.060 --> 00:30:11.340
And you really do feel like you
are essential at that moment.

00:30:11.340 --> 00:30:14.970
Now I would challenge you
guys in a way I perpetually

00:30:14.970 --> 00:30:16.720
challenge myself, always.

00:30:16.720 --> 00:30:18.720
How urgent is that thing?

00:30:18.720 --> 00:30:20.900
How important am I?

00:30:20.900 --> 00:30:23.100
I always am finding
I'm way less important

00:30:23.100 --> 00:30:26.067
than I imagine that I might be.

00:30:26.067 --> 00:30:27.150
MALE SPEAKER: Interesting.

00:30:27.150 --> 00:30:28.290
AUDIENCE: I have a
quick question, just

00:30:28.290 --> 00:30:29.820
following up on the cars, then.

00:30:29.820 --> 00:30:30.990
Because you put your
cell phone away,

00:30:30.990 --> 00:30:32.370
but a lot of the
new-fangled cars

00:30:32.370 --> 00:30:35.920
have a dash which is
effectively a giant cellphone.

00:30:35.920 --> 00:30:38.620
Is that not like taking an
alcoholic, who's driving,

00:30:38.620 --> 00:30:41.140
and installing a
keg and beer tap

00:30:41.140 --> 00:30:42.480
in the front seat of the car?

00:30:42.480 --> 00:30:44.410
MATT RICHTEL: Yeah, I
mean-- what's your name?

00:30:44.410 --> 00:30:45.350
AUDIENCE: Olivier.

00:30:45.350 --> 00:30:49.170
MATT RICHTEL: Olivier, that is
what a lot of the scientists

00:30:49.170 --> 00:30:49.720
say today.

00:30:49.720 --> 00:30:53.880
There is a really vibrant
conversation going on,

00:30:53.880 --> 00:30:56.940
policy conversation
going on, around the car.

00:30:56.940 --> 00:30:59.820
And the conversation
basically goes like this.

00:30:59.820 --> 00:31:03.490
The car makers say, people are
going to do this stuff anyway.

00:31:03.490 --> 00:31:06.450
Let's make it, quote, unquote,
"as safe as possible."

00:31:06.450 --> 00:31:09.410
And the policy folks
and the safety folks

00:31:09.410 --> 00:31:12.180
and the neuroscientists say,
you got to be kidding me.

00:31:12.180 --> 00:31:13.970
There is no safe as possible.

00:31:13.970 --> 00:31:16.190
There's safe and there's unsafe.

00:31:16.190 --> 00:31:19.480
And when you look down and
when you take your eyes

00:31:19.480 --> 00:31:22.950
off the road, even in the
case of some of the new stuff

00:31:22.950 --> 00:31:25.910
where they project, they use
holographic, sophisticated

00:31:25.910 --> 00:31:28.100
optics to project it
through the windshield,

00:31:28.100 --> 00:31:30.670
even when you're looking in
the direction of the road,

00:31:30.670 --> 00:31:34.800
you still have your focus
on, say, a notification

00:31:34.800 --> 00:31:36.390
that says, "incoming text."

00:31:36.390 --> 00:31:38.920
What this fits into is
this larger conversation,

00:31:38.920 --> 00:31:42.530
Olivier, which
basically says, are

00:31:42.530 --> 00:31:47.800
we able to draw a stark line
and modify some of our behavior,

00:31:47.800 --> 00:31:50.890
or we just trying to
find more convenient ways

00:31:50.890 --> 00:31:52.460
to fit it into our lives?

00:31:52.460 --> 00:31:55.980
Right now in that junk
food conversation,

00:31:55.980 --> 00:32:00.830
basically as a society,
we are 16-year-olds

00:32:00.830 --> 00:32:04.290
who just discovered
$5 in our pocket

00:32:04.290 --> 00:32:09.540
and the store on the corner
has a sale on nacho cheese.

00:32:09.540 --> 00:32:11.196
And forget about it.

00:32:11.196 --> 00:32:12.320
MALE SPEAKER: Really quick.

00:32:12.320 --> 00:32:13.243
So the mic isn't
working, so we're just

00:32:13.243 --> 00:32:14.060
going to repeat the question.

00:32:14.060 --> 00:32:15.910
So we're talking
about a text sabbath,

00:32:15.910 --> 00:32:18.452
or taking a sabbath from
technology for a day or more

00:32:18.452 --> 00:32:19.910
and trying to see
there's anecdotes

00:32:19.910 --> 00:32:20.925
of that being effective.

00:32:20.925 --> 00:32:23.330
MATT RICHTEL: Anecdotes and
science-- just a tiny bit

00:32:23.330 --> 00:32:24.230
of science here.

00:32:24.230 --> 00:32:26.670
A woman from this
area at Stanford

00:32:26.670 --> 00:32:30.550
did a terrific
study with veterans

00:32:30.550 --> 00:32:32.410
who were suffering PTSD.

00:32:32.410 --> 00:32:34.020
And I mentioned
this in the book.

00:32:34.020 --> 00:32:36.260
And when they began to
do some meditation, which

00:32:36.260 --> 00:32:41.620
is its own form of sabbath,
they became far less responsive

00:32:41.620 --> 00:32:43.840
to bursts of
external stimulation

00:32:43.840 --> 00:32:46.080
that might otherwise
unnerve them.

00:32:46.080 --> 00:32:47.620
There are a bunch
of other evidence

00:32:47.620 --> 00:32:51.200
that adds up and seems to
suggest those sabbaths do work.

00:32:51.200 --> 00:32:52.930
You slow down your thinking.

00:32:52.930 --> 00:32:54.990
You make a clearer decision.

00:32:54.990 --> 00:32:57.290
You're not burning
your working memory,

00:32:57.290 --> 00:32:58.907
that I was alluding to earlier.

00:32:58.907 --> 00:33:00.740
They really work if you
can stick with them.

00:33:00.740 --> 00:33:04.110
And they need not be-- I mean,
I wonder what you would say.

00:33:04.110 --> 00:33:06.036
You do a lot of backpacking.

00:33:06.036 --> 00:33:07.660
What happens for you
when you get away?

00:33:07.660 --> 00:33:08.352
MALE SPEAKER: It's
interesting, because I

00:33:08.352 --> 00:33:10.600
think towards the end of
the book, the neuroscientist

00:33:10.600 --> 00:33:13.400
that you refer to throughout,
I think one or two of them

00:33:13.400 --> 00:33:15.990
were talking about, they want
to find the science behind why

00:33:15.990 --> 00:33:18.120
stepping out into
nature, the outdoors,

00:33:18.120 --> 00:33:20.790
it actually has a
profound effect on people.

00:33:20.790 --> 00:33:21.330
It's tough.

00:33:21.330 --> 00:33:25.640
I wonder-- it's almost
like a reinforcing,

00:33:25.640 --> 00:33:26.440
I guess, anecdote.

00:33:26.440 --> 00:33:28.530
You hear so many people
talk about the outdoors

00:33:28.530 --> 00:33:30.510
and nature being restorative.

00:33:30.510 --> 00:33:32.687
I almost wonder if we expect
it before we get there.

00:33:32.687 --> 00:33:35.020
You kind of have to let
yourself experience it, I think.

00:33:35.020 --> 00:33:37.420
But I think it is the sabbath.

00:33:37.420 --> 00:33:40.450
I think it probably,
the working memory,

00:33:40.450 --> 00:33:42.390
these things get
to take a break.

00:33:42.390 --> 00:33:45.799
A lot of the systems get to
stop operating at rapid pace.

00:33:45.799 --> 00:33:48.090
MATT RICHTEL: Yeah, I don't
want to overdo the science,

00:33:48.090 --> 00:33:50.660
but there's stuff in
here about research--

00:33:50.660 --> 00:33:52.570
what happens, how you
learn and remember

00:33:52.570 --> 00:33:54.430
better when you let this rest.

00:33:54.430 --> 00:33:57.610
But anecdotally, I
will tell you someone's

00:33:57.610 --> 00:34:00.150
called me with a story that
I'm not prepared to report yet,

00:34:00.150 --> 00:34:01.700
because I need more evidence.

00:34:01.700 --> 00:34:04.690
But, of a man, sleep deprived
from playing video games who

00:34:04.690 --> 00:34:06.030
killed someone on a roadway.

00:34:06.030 --> 00:34:08.820
And it may be a seminal
case, in the spirit of this,

00:34:08.820 --> 00:34:11.350
who was up for 55 hours.

00:34:11.350 --> 00:34:13.199
I'm not totally clear
on the details yet.

00:34:13.199 --> 00:34:18.760
But other folks at Stanford talk
a ton about the costs to sleep.

00:34:18.760 --> 00:34:21.380
And you've been seeing
this blue light stuff.

00:34:21.380 --> 00:34:25.150
Got to say again, not a screed
against technology, just a

00:34:25.150 --> 00:34:27.870
call to let's understand
the power of it.

00:34:27.870 --> 00:34:30.500
Even driving-- and I can't
remember the numbers.

00:34:30.500 --> 00:34:31.449
They're in the book.

00:34:31.449 --> 00:34:33.014
And they might go
up to 12 seconds,

00:34:33.014 --> 00:34:34.305
depending on what you're doing.

00:34:34.305 --> 00:34:38.770
But when you are looking
down-- but even when you're not

00:34:38.770 --> 00:34:43.040
looking down, if you are
focused on something else,

00:34:43.040 --> 00:34:45.020
your brain is elsewhere.

00:34:45.020 --> 00:34:48.195
Most of the time-- let's
take the driving context.

00:34:48.195 --> 00:34:49.820
Let's forget about
the working contest.

00:34:49.820 --> 00:34:52.900
Most of the time,
you get away with it.

00:34:52.900 --> 00:34:55.340
We are actually bad
scientists in our own lives.

00:34:55.340 --> 00:34:57.640
This is a very bad sample size.

00:34:57.640 --> 00:35:00.470
You text and drive, you text
and drive, nothing ever happens.

00:35:00.470 --> 00:35:01.460
You do it 100 times.

00:35:01.460 --> 00:35:05.330
You go, 100% of the time,
nothing bad happened.

00:35:05.330 --> 00:35:09.010
So that means nothing
bad will ever happen.

00:35:09.010 --> 00:35:11.030
The problem is,
in those instances

00:35:11.030 --> 00:35:12.960
where you have to
react like this--

00:35:12.960 --> 00:35:16.330
has anybody here ever been
in a wreck due to whatever?

00:35:16.330 --> 00:35:18.380
So do you remember how
quickly that happens?

00:35:18.380 --> 00:35:20.040
It's almost unbelievable.

00:35:20.040 --> 00:35:21.880
You can't even
remember what happened.

00:35:21.880 --> 00:35:23.370
Someone comes around a corner.

00:35:23.370 --> 00:35:24.800
It's that instant.

00:35:24.800 --> 00:35:26.650
And I've heard some
terrible stories

00:35:26.650 --> 00:35:28.180
in the course of reporting this.

00:35:28.180 --> 00:35:31.800
It's that terrible,
terrible tragic instant,

00:35:31.800 --> 00:35:35.640
when somebody comes across the
road, where someone swerves,

00:35:35.640 --> 00:35:37.030
and you can't react.

00:35:37.030 --> 00:35:40.965
And then those milliseconds,
let alone seconds, matter.

00:35:40.965 --> 00:35:42.090
MALE SPEAKER: Really quick.

00:35:42.090 --> 00:35:42.970
Somehow the mic
isn't picking it up.

00:35:42.970 --> 00:35:45.430
It was a great question
about company culture

00:35:45.430 --> 00:35:50.010
and if other companies have
programs or initiatives

00:35:50.010 --> 00:35:52.540
that they've done to
try to curb this at all.

00:35:52.540 --> 00:35:55.580
MATT RICHTEL: I'm going to
ask our British visitor.

00:35:55.580 --> 00:35:57.630
Was it British Telecom?

00:35:57.630 --> 00:35:59.030
There's a company
in Britain that

00:35:59.030 --> 00:36:03.820
has no emails after 5 o'clock
at night, or maybe it's Germany.

00:36:03.820 --> 00:36:06.170
Oh, it's a car company
in Germany, I think.

00:36:06.170 --> 00:36:08.710
And they will say,
you just can't answer.

00:36:08.710 --> 00:36:10.730
You can somehow be
penalized for it.

00:36:10.730 --> 00:36:15.100
Surely someone who's watching
online will know that.

00:36:15.100 --> 00:36:18.280
Years ago, Intel flirted
with No Email Fridays

00:36:18.280 --> 00:36:19.270
for a group of people.

00:36:19.270 --> 00:36:22.420
You guys have some people doing
some really interesting stuff.

00:36:22.420 --> 00:36:24.290
I've written about
it on our front page.

00:36:24.290 --> 00:36:29.890
Facebook, Twitter had someone
talking about meditation stuff.

00:36:29.890 --> 00:36:32.010
The truth is-- and I'm
in this business too.

00:36:32.010 --> 00:36:33.730
I'm a "New York Times" reporter.

00:36:33.730 --> 00:36:35.850
When they need me, they need me.

00:36:35.850 --> 00:36:38.320
But the reality of it
is-- and you mentioned

00:36:38.320 --> 00:36:39.410
the self-importance piece.

00:36:39.410 --> 00:36:41.180
I really would underscore it.

00:36:41.180 --> 00:36:44.240
As I've reflected
a lot, I think we

00:36:44.240 --> 00:36:51.180
tend to use this stuff much more
for our validation, escaping,

00:36:51.180 --> 00:36:54.260
sense of importance, all
that stuff than our bosses

00:36:54.260 --> 00:36:56.770
really need us.

00:36:56.770 --> 00:37:01.100
So again, I'd urge
you to explore,

00:37:01.100 --> 00:37:04.420
as I am continuing to explore--
I am far from terrific

00:37:04.420 --> 00:37:07.960
at this-- just how
urgent it really is.

00:37:07.960 --> 00:37:11.450
I think it oftentimes can fall
to an individual to control it,

00:37:11.450 --> 00:37:14.355
even as much as we would
blame the external culture.

00:37:14.355 --> 00:37:16.480
MALE SPEAKER: I want to
actually piggyback on that.

00:37:16.480 --> 00:37:19.350
So I was thinking about
the evolutionary need

00:37:19.350 --> 00:37:21.150
for social interaction.

00:37:21.150 --> 00:37:22.300
You get the ping.

00:37:22.300 --> 00:37:23.450
Is it a Facebook comment?

00:37:23.450 --> 00:37:25.840
Is it a Like, Instagram,
Twitter, what is it?

00:37:25.840 --> 00:37:27.360
But I'm also
thinking about FOMO.

00:37:27.360 --> 00:37:29.026
So Fear Of Missing
Out-- a lot of people

00:37:29.026 --> 00:37:30.290
talk about it in the Valley.

00:37:30.290 --> 00:37:32.509
So one thing we hear
about now, as you're

00:37:32.509 --> 00:37:34.800
sitting at the doctor's
office, you're sitting in line.

00:37:34.800 --> 00:37:36.070
You pull out your phone.

00:37:36.070 --> 00:37:39.740
Even if you're not on email,
you're reading new articles.

00:37:39.740 --> 00:37:42.420
There's a certain fear, I
think, for a lot of folks

00:37:42.420 --> 00:37:44.600
that if you're not up to
speed with the times--

00:37:44.600 --> 00:37:47.380
and it's world events,
current events.

00:37:47.380 --> 00:37:48.620
It's politics.

00:37:48.620 --> 00:37:51.850
It can be just media and
fashion, all sorts of stuff,

00:37:51.850 --> 00:37:52.860
sports.

00:37:52.860 --> 00:37:53.960
What about that FOMO?

00:37:53.960 --> 00:37:56.110
What about just fear of
not being in the know?

00:37:56.110 --> 00:37:59.290
Is that an evolutionary
thing as well?

00:37:59.290 --> 00:38:01.290
MATT RICHTEL: The short
answer is, I don't know.

00:38:01.290 --> 00:38:03.176
May I do a longer
answer and get weird?

00:38:03.176 --> 00:38:05.050
MALE SPEAKER: Are we
cool with getting weird?

00:38:05.050 --> 00:38:06.300
MATT RICHTEL: Can I get weird?

00:38:06.300 --> 00:38:07.870
MALE SPEAKER: Do I
need to step away?

00:38:07.870 --> 00:38:09.260
MATT RICHTEL: No, no, no.

00:38:09.260 --> 00:38:11.290
I need you to make
animal noises.

00:38:11.290 --> 00:38:13.210
No, I'm kidding--
not that weird.

00:38:17.070 --> 00:38:20.610
I think FOMO is an
illusion, to a large extent.

00:38:20.610 --> 00:38:23.980
And the weird part
of this is, I'm

00:38:23.980 --> 00:38:26.850
willing to go spiritual and
existential with you, if you

00:38:26.850 --> 00:38:27.350
want.

00:38:27.350 --> 00:38:29.320
And I'll do it by
way of coming back

00:38:29.320 --> 00:38:32.130
to Reggie Shaw, the young
man who got in the accident.

00:38:32.130 --> 00:38:36.400
Remember he had come
back from his mission?

00:38:36.400 --> 00:38:37.680
I know Reggie very well.

00:38:37.680 --> 00:38:39.750
This is a very,
very intimate book

00:38:39.750 --> 00:38:43.660
with deep portrayals of
people and their thoughts--

00:38:43.660 --> 00:38:46.730
his family, the prosecutors,
the victims' advocate,

00:38:46.730 --> 00:38:49.490
and in particular, Reggie.

00:38:49.490 --> 00:38:52.530
The woman that he had coupled
with that got him in trouble

00:38:52.530 --> 00:38:54.620
wound up getting
married to someone else.

00:38:54.620 --> 00:38:56.449
And when he was driving
that morning, even

00:38:56.449 --> 00:38:57.990
at 6:30 in the
morning, he was having

00:38:57.990 --> 00:39:02.380
an essentially
meaningless text exchange

00:39:02.380 --> 00:39:04.840
with another young woman.

00:39:04.840 --> 00:39:06.910
If I had to ask myself,
what was Reggie doing,

00:39:06.910 --> 00:39:09.230
I think Reggie was filling
a hole at that moment.

00:39:09.230 --> 00:39:11.150
He was really struggling.

00:39:11.150 --> 00:39:13.800
And when I think
about FOMO, and I

00:39:13.800 --> 00:39:16.270
think about what draws
us to our devices

00:39:16.270 --> 00:39:19.160
all the time, I think
a lot personally

00:39:19.160 --> 00:39:22.400
about filling moments,
about escaping,

00:39:22.400 --> 00:39:25.140
about finding stimulation.

00:39:25.140 --> 00:39:27.600
I mean, think of
the challenge just

00:39:27.600 --> 00:39:30.900
of sitting in line
at the grocery store,

00:39:30.900 --> 00:39:32.710
and you go to your device.

00:39:32.710 --> 00:39:36.020
Think of the challenge of
sitting with someone in silence

00:39:36.020 --> 00:39:39.520
and waiting for an
interesting conversation,

00:39:39.520 --> 00:39:42.600
or just getting to know
the person in quiet.

00:39:42.600 --> 00:39:46.230
Think of the
discomfort of making

00:39:46.230 --> 00:39:51.360
quiet OK, your own moments OK.

00:39:51.360 --> 00:39:55.980
On the scale of weird and
existential and spiritual,

00:39:55.980 --> 00:39:59.100
I don't think these
were ever easy things.

00:39:59.100 --> 00:40:03.450
I mean, I think that that
is an endless-- not endless,

00:40:03.450 --> 00:40:07.850
but it's an essential part
of the human condition.

00:40:07.850 --> 00:40:09.570
And part of what
we're doing, I think,

00:40:09.570 --> 00:40:13.110
when we put terms on it, like,
I'm afraid of missing out,

00:40:13.110 --> 00:40:16.050
some of that might be true if
it's pertinent to your job.

00:40:16.050 --> 00:40:22.510
Some of it might be rather fear
of being in the moment Fee--

00:40:22.510 --> 00:40:24.700
MALE SPEAKER: We
can trademark it.

00:40:24.700 --> 00:40:26.630
I sense a book about
this coming up.

00:40:26.630 --> 00:40:29.980
I sense a work of
fiction, perhaps.

00:40:29.980 --> 00:40:32.320
Children in the car being
a lot more distracting

00:40:32.320 --> 00:40:34.280
than a text or an email
coming in on the phone.

00:40:34.280 --> 00:40:37.310
MATT RICHTEL: So another-- I
mentioned the spam research,

00:40:37.310 --> 00:40:38.560
which was one of my favorites.

00:40:38.560 --> 00:40:40.768
Another one of my favorites,
when I-- bit of trivia--

00:40:40.768 --> 00:40:42.270
am doing this,
was, what if I have

00:40:42.270 --> 00:40:43.610
someone in the car with me?

00:40:43.610 --> 00:40:45.496
Isn't that also a distraction?

00:40:45.496 --> 00:40:46.662
AUDIENCE: There's the radio.

00:40:46.662 --> 00:40:48.490
All these things
are distracting.

00:40:48.490 --> 00:40:50.073
MATT RICHTEL: So all
these things-- so

00:40:50.073 --> 00:40:51.860
let's start with the passenger.

00:40:51.860 --> 00:40:56.960
Passenger turns out to be
even a safety advantage.

00:40:56.960 --> 00:40:59.254
Not a kid, but a passenger.

00:40:59.254 --> 00:41:00.670
And I'll come to
kids in a second.

00:41:00.670 --> 00:41:05.640
But a passenger says to
you, look out, it's raining.

00:41:05.640 --> 00:41:09.670
Modulates his or her voice with
the conditions on the road,

00:41:09.670 --> 00:41:13.120
actually acts as a proverbial
second set of eyes.

00:41:13.120 --> 00:41:16.390
When there are teens in a
car with a teen driver, that

00:41:16.390 --> 00:41:18.810
is a safety disadvantage,
the research shows.

00:41:18.810 --> 00:41:21.570
I don't know when
it's an adult driver

00:41:21.570 --> 00:41:25.750
with-- were you a teen father?

00:41:25.750 --> 00:41:28.050
I'm just kidding.

00:41:28.050 --> 00:41:30.680
So I don't actually know
about that piece of it.

00:41:30.680 --> 00:41:34.100
But let's go to radio, which is
another really good question.

00:41:34.100 --> 00:41:38.160
It turns out that now, with
being able to map the brain

00:41:38.160 --> 00:41:41.400
and be able to do lots
of cognitive measures,

00:41:41.400 --> 00:41:44.190
we can begin to
see the variability

00:41:44.190 --> 00:41:46.790
of cognitive distraction
from various activities,

00:41:46.790 --> 00:41:50.310
from the most extreme,
which is texting,

00:41:50.310 --> 00:41:52.970
where you're looking down,
you're manually engaged,

00:41:52.970 --> 00:41:56.380
you're cognitively engaged, to
maybe on the other end, which

00:41:56.380 --> 00:41:57.590
is the radio.

00:41:57.590 --> 00:42:01.350
The radio, you are, to an
extent cognitively engaged.

00:42:01.350 --> 00:42:04.940
Less so, though, when talking
to somebody even hands-free,

00:42:04.940 --> 00:42:08.880
because they can see through
mapping the brain how much more

00:42:08.880 --> 00:42:12.610
of the brain gets engaged,
including the visual cortex.

00:42:12.610 --> 00:42:15.624
Because you in your mind's
eye are picturing the person

00:42:15.624 --> 00:42:16.540
you're talking to you.

00:42:16.540 --> 00:42:20.820
And the act of
interacting with somebody

00:42:20.820 --> 00:42:21.970
takes up more of the brain.

00:42:21.970 --> 00:42:26.040
So all of these go to those
milliseconds of switching time.

00:42:26.040 --> 00:42:28.090
Now if you're like me
and you occasionally

00:42:28.090 --> 00:42:32.560
yell at sports talk radio,
I'm not sure where that falls.

00:42:32.560 --> 00:42:38.660
And I should stipulate here
that road distractions have

00:42:38.660 --> 00:42:40.880
been a problem for a long time.

00:42:40.880 --> 00:42:43.400
Fatalities have been in
the tens of thousands

00:42:43.400 --> 00:42:46.460
for many years, owing
to the largest extent,

00:42:46.460 --> 00:42:49.010
from drunk driving, but
to lots of other things.

00:42:49.010 --> 00:42:53.410
The issue here is whether this
thing has become systemic.

00:42:53.410 --> 00:42:55.860
It's not the
occasional look away.

00:42:55.860 --> 00:42:59.380
It's an activity that
30% of people are doing.

00:42:59.380 --> 00:43:01.390
And that's just texting.

00:43:01.390 --> 00:43:05.540
And 90%, 85%, say it's
completely unacceptable.

00:43:05.540 --> 00:43:08.080
So we're talking really
in a systemic level

00:43:08.080 --> 00:43:09.750
about orders of magnitude.

00:43:09.750 --> 00:43:12.014
This is not the occasional
bite of a burger.

00:43:12.014 --> 00:43:14.180
MALE SPEAKER: That's actually
an interesting thought

00:43:14.180 --> 00:43:16.409
about the orders of magnitude.

00:43:16.409 --> 00:43:18.950
I think when-- you mention this
was a landmark case, Reggie's

00:43:18.950 --> 00:43:21.250
case, the first time we
think, definitely in Utah,

00:43:21.250 --> 00:43:24.490
that somebody was on trial
for texting and driving.

00:43:24.490 --> 00:43:25.890
And there was a question.

00:43:25.890 --> 00:43:27.940
The science, the
research says that it

00:43:27.940 --> 00:43:31.540
is orders of magnitude more
dangerous to text and drive.

00:43:31.540 --> 00:43:34.310
But the question was, even
with orders of magnitude,

00:43:34.310 --> 00:43:35.649
is it still that dangerous?

00:43:35.649 --> 00:43:37.440
MATT RICHTEL: Does it
qualify as dangerous?

00:43:37.440 --> 00:43:39.189
MALE SPEAKER: So what's
your take on that?

00:43:39.189 --> 00:43:42.230
MATT RICHTEL: I can only give
you what the measures are.

00:43:42.230 --> 00:43:44.200
The measures, by the
safety advocates--

00:43:44.200 --> 00:43:49.450
and let's say it's texting--
this is Virginia Tech

00:43:49.450 --> 00:43:54.720
Transportation Institute--
23 times risk of crash

00:43:54.720 --> 00:43:56.400
or near crash.

00:43:56.400 --> 00:43:59.350
University of Utah would
put that at six times.

00:43:59.350 --> 00:44:01.110
They would put
talking on hands-free

00:44:01.110 --> 00:44:05.070
at four times greater risk
of crash or near crash.

00:44:05.070 --> 00:44:07.680
Now, you say objectively
is that a risk?

00:44:07.680 --> 00:44:09.970
Here's how I do
the math on this.

00:44:09.970 --> 00:44:18.040
There are in excess of 300,000
serious car crashes a year,

00:44:18.040 --> 00:44:21.030
serious injury car
crashes in the US,

00:44:21.030 --> 00:44:23.510
and 30,000-plus fatalities.

00:44:23.510 --> 00:44:27.010
So you're already talking
about the most dangerous thing

00:44:27.010 --> 00:44:31.350
you will do all day,
period, end of conversation.

00:44:31.350 --> 00:44:33.602
So, yes.

00:44:33.602 --> 00:44:35.810
MALE SPEAKER: I'm going to
take quick step back here.

00:44:35.810 --> 00:44:37.205
I hadn't met you until today.

00:44:37.205 --> 00:44:39.330
And I read this book and
I knew I'd meet you today.

00:44:39.330 --> 00:44:40.800
And I was wondering,
I wonder if he's

00:44:40.800 --> 00:44:43.216
going to be one of these guys
who's just like, if you ever

00:44:43.216 --> 00:44:44.434
text and drive, you're crazy.

00:44:44.434 --> 00:44:45.600
You're going to kill people.

00:44:45.600 --> 00:44:46.700
It's terrible.

00:44:46.700 --> 00:44:49.310
And meeting you, it seems
like you wrote this book less

00:44:49.310 --> 00:44:52.046
to chastise people
for a potentially very

00:44:52.046 --> 00:44:54.420
dangerous behavior and more
to, I guess, raise awareness,

00:44:54.420 --> 00:44:57.800
like think about-- so why
did you take up this topic?

00:44:57.800 --> 00:45:00.110
You've been doing it for awhile.

00:45:00.110 --> 00:45:04.110
MATT RICHTEL: I watched my
behavior outside of the car.

00:45:04.110 --> 00:45:05.920
I mean, you're dead right.

00:45:05.920 --> 00:45:09.930
This is not an effort
to throw stones.

00:45:09.930 --> 00:45:13.190
And it's actually not the way
I like to approach journalism

00:45:13.190 --> 00:45:13.890
in general.

00:45:13.890 --> 00:45:15.600
I think issues are complicated.

00:45:15.600 --> 00:45:17.930
There usually
aren't conspiracies.

00:45:17.930 --> 00:45:21.190
A lot of things grow simply
out of the human condition.

00:45:21.190 --> 00:45:23.770
And so I watch my own
behavior with the phone

00:45:23.770 --> 00:45:28.000
and then I watch my own behavior
in the car with the phone.

00:45:28.000 --> 00:45:32.000
And I said to myself, lots
of things are at play here.

00:45:32.000 --> 00:45:34.254
And what's interesting
to me about the car--

00:45:34.254 --> 00:45:35.670
and I said this
at the beginning--

00:45:35.670 --> 00:45:39.630
is it's the perfect
place to set this story.

00:45:39.630 --> 00:45:42.800
Because if we can do it
under these conditions,

00:45:42.800 --> 00:45:45.530
at 55 miles an hour in the
freezing rain when you're

00:45:45.530 --> 00:45:48.380
a pretty decent guy who would
go to his missionary training

00:45:48.380 --> 00:45:51.830
center president and admit
that he has to go home

00:45:51.830 --> 00:45:54.170
with his tail between his
legs and he's a good guy,

00:45:54.170 --> 00:45:56.190
like many of us are
good people, then

00:45:56.190 --> 00:45:59.050
what does it say about us
under other circumstances?

00:45:59.050 --> 00:46:04.680
So to me, this is an act
for myself, for others,

00:46:04.680 --> 00:46:07.570
to try to understand,
what is this thing?

00:46:07.570 --> 00:46:11.017
I think it's fair to say--
I've heard this said,

00:46:11.017 --> 00:46:13.350
and I don't know that I can
prove it with numbers to you

00:46:13.350 --> 00:46:14.060
today.

00:46:14.060 --> 00:46:18.320
But the phone is the most
quickly adopted technology

00:46:18.320 --> 00:46:22.340
in all of human history, by
far faster than the book.

00:46:22.340 --> 00:46:27.420
When that happens, that's not
because Motorola and Apple

00:46:27.420 --> 00:46:29.530
and Verizon tell you to get it.

00:46:29.530 --> 00:46:32.000
There's no shortage of companies
in this country telling

00:46:32.000 --> 00:46:33.250
you to buy everything.

00:46:33.250 --> 00:46:35.520
And most of us buy none of it.

00:46:35.520 --> 00:46:37.800
But many of us have two phones.

00:46:37.800 --> 00:46:39.980
That is not an accident.

00:46:39.980 --> 00:46:41.220
That's not marketing.

00:46:41.220 --> 00:46:45.840
That goes to utility, power,
and when it's that big, to me

00:46:45.840 --> 00:46:49.690
it goes to the fact that it hits
at social, primitive wiring.

00:46:49.690 --> 00:46:51.510
And that's what I try
to explicate here.

00:46:51.510 --> 00:46:52.510
MALE SPEAKER: Wonderful.

00:46:52.510 --> 00:46:55.160
My last question-- thank you
for that-- last one for me.

00:46:55.160 --> 00:46:57.527
So one thing you do
great in this book,

00:46:57.527 --> 00:46:59.360
among other things, the
data and everything,

00:46:59.360 --> 00:47:01.318
is you really get into
the stories behind a lot

00:47:01.318 --> 00:47:02.940
of the key players in the book.

00:47:02.940 --> 00:47:04.860
And I was really
surprised towards the end.

00:47:04.860 --> 00:47:06.050
I don't want to betray
too much for those

00:47:06.050 --> 00:47:07.300
who are going to read it soon.

00:47:07.300 --> 00:47:09.550
You talk about the importance
of telling the truth.

00:47:09.550 --> 00:47:11.216
And that was a really
powerful, I think,

00:47:11.216 --> 00:47:12.800
one or two chapters for me.

00:47:12.800 --> 00:47:13.700
And I'm curious.

00:47:13.700 --> 00:47:16.670
It almost seemed--
I almost wondered

00:47:16.670 --> 00:47:18.620
why you had those chapters.

00:47:18.620 --> 00:47:21.860
You build it up so well, here's
what the value of the truth is.

00:47:21.860 --> 00:47:23.930
Was it a reminder
that we all need

00:47:23.930 --> 00:47:27.450
to tell the truth to ourselves
about our technology use?

00:47:27.450 --> 00:47:29.340
Why did you talk
about the truth?

00:47:29.340 --> 00:47:31.370
MATT RICHTEL: Yes
is the short answer.

00:47:31.370 --> 00:47:37.410
I mean, at the end of this
book, partly, very nakedly,

00:47:37.410 --> 00:47:40.560
it was the publisher saying,
so what do we do about this?

00:47:40.560 --> 00:47:45.640
And I didn't want to write a
book that was a "how-to" book.

00:47:45.640 --> 00:47:47.860
And they knew that well.

00:47:47.860 --> 00:47:52.470
I believe more than
anything-- sorry.

00:47:52.470 --> 00:47:53.870
Pull back.

00:47:53.870 --> 00:47:56.900
"I believe" is not the
right sentence there.

00:47:56.900 --> 00:47:59.130
I love the tell stories.

00:47:59.130 --> 00:48:02.350
I think it's just
a personal passion.

00:48:02.350 --> 00:48:05.290
And I love to
captivate myself as I'm

00:48:05.290 --> 00:48:07.960
doing the task and the
reader who is listening.

00:48:07.960 --> 00:48:10.370
That is a very connected
experience for me.

00:48:10.370 --> 00:48:14.330
So I didn't want this book to
suddenly go into a manifesto.

00:48:14.330 --> 00:48:15.790
The publisher wanted something.

00:48:15.790 --> 00:48:19.580
And I tried to
find the line where

00:48:19.580 --> 00:48:23.170
I could stay in the
spirit of this book,

00:48:23.170 --> 00:48:27.900
but also explain what happened
here that led to change.

00:48:27.900 --> 00:48:30.270
Because as you'll see
if you read this book,

00:48:30.270 --> 00:48:33.160
that a remarkable thing happened
at the end of this story.

00:48:33.160 --> 00:48:36.160
And I'm not going to give
it away-- a truly remarkable

00:48:36.160 --> 00:48:38.550
transformation happened
with this character,

00:48:38.550 --> 00:48:40.200
like no other I've
ever witnessed

00:48:40.200 --> 00:48:41.940
in fiction or real life.

00:48:41.940 --> 00:48:45.960
And it came from someone
confronting himself.

00:48:45.960 --> 00:48:48.900
And I went and talked to
people about the challenge

00:48:48.900 --> 00:48:51.450
of doing that, because I think
it lies at the heart of this.

00:48:51.450 --> 00:48:54.770
And all the time in my
relationship with my device,

00:48:54.770 --> 00:48:57.330
as I began this thing, talking
about your relationship

00:48:57.330 --> 00:48:59.040
with the device,
I have to confront

00:48:59.040 --> 00:49:02.670
that relationship and all
the things it represents.

00:49:02.670 --> 00:49:06.450
If my wife says, did
you take out the trash,

00:49:06.450 --> 00:49:09.710
and I suddenly find myself
checking the Giants' score

00:49:09.710 --> 00:49:13.660
seconds later, I ask myself,
why did I just go do that?

00:49:13.660 --> 00:49:17.710
And naturally, the answer is,
because the Giants need me.

00:49:17.710 --> 00:49:19.200
It's probably
because I'm escaping

00:49:19.200 --> 00:49:22.980
from a moment of whatever
it is-- irritability,

00:49:22.980 --> 00:49:26.240
didn't she ask me
that-- something human.

00:49:26.240 --> 00:49:30.960
So I'm trying to find the
ways in which my device gets

00:49:30.960 --> 00:49:33.260
in the way of truth.

00:49:33.260 --> 00:49:37.010
And I'm sorry to be so
long-winded from lunch.

00:49:37.010 --> 00:49:38.860
I can't help myself.

00:49:38.860 --> 00:49:41.570
I want to thank you
guys for coming.

00:49:41.570 --> 00:49:43.477
I really, really
genuinely appreciate it.

00:49:43.477 --> 00:49:45.810
MALE SPEAKER: Well, thanks
for being here as well, Matt.

00:49:45.810 --> 00:49:50.660
[APPLAUSE]

