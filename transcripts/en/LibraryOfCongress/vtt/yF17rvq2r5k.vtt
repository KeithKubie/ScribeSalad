WEBVTT
Kind: captions
Language: en

00:00:15.480 --> 00:00:16.780
&gt;&gt; John Haskell:
Welcome everybody.

00:00:16.780 --> 00:00:18.080
Let me have your attention.

00:00:18.080 --> 00:00:19.610
You can keep eating,
drinking, et cetera.

00:00:19.610 --> 00:00:23.170
I'm John Haskell, the
Director of the Kluge Center.

00:00:23.170 --> 00:00:26.870
I see a lot of people that I
recognize from other events

00:00:26.870 --> 00:00:29.830
that we've done or the Library
has done so welcome to you

00:00:29.830 --> 00:00:31.170
and also welcome, of course,

00:00:31.170 --> 00:00:33.780
to folks who have not
done Kluge Center events

00:00:33.780 --> 00:00:37.070
and we'll make sure that you're
inundated with information

00:00:37.070 --> 00:00:38.570
about subsequent events.

00:00:38.570 --> 00:00:41.520
The Dinner and Democracy Series
that a lot of you are familiar

00:00:41.520 --> 00:00:44.550
with well this dinner event is a
little bit different but it fits

00:00:44.550 --> 00:00:47.260
into our mission where, you
know, we mean to be the place

00:00:47.260 --> 00:00:48.890
at the Library where
conversations

00:00:48.890 --> 00:00:52.290
and the challenges
facing democracies happen.

00:00:52.290 --> 00:00:55.340
As you may know, we do
this in different ways.

00:00:55.340 --> 00:00:58.020
We do dinner events
for staff like this,

00:00:58.020 --> 00:01:02.250
we do breakfast off the record
conversations with scholars

00:01:02.250 --> 00:01:06.260
for members and we do
a lot of public events

00:01:06.260 --> 00:01:09.220
that the staff many times
come to featuring a range

00:01:09.220 --> 00:01:10.810
of thought leaders
just in the last year

00:01:10.810 --> 00:01:13.970
so we've had Anne
Applebaum in a conversation

00:01:13.970 --> 00:01:15.270
down in Coolidge Auditorium.

00:01:15.270 --> 00:01:18.910
J.D. Vance, Jonathan
Haidt on Coddling

00:01:18.910 --> 00:01:21.180
of the American Mind,
and many others.

00:01:21.180 --> 00:01:24.700
I hope you'll consider attending
those when you learn about them

00:01:24.700 --> 00:01:26.000
and we're going to
have information

00:01:26.000 --> 00:01:27.690
on the next Dinner
and Democracy Series.

00:01:27.690 --> 00:01:29.900
Those are those geeky seminars
that many of you have gone

00:01:29.900 --> 00:01:33.890
to that that are held over
in the Madison Building.

00:01:33.890 --> 00:01:37.910
We will have a new series of
those coming up next year.

00:01:37.910 --> 00:01:41.090
Just last year the Carnegie
Corporation gave a generous gift

00:01:41.090 --> 00:01:43.360
to the Library of
Congress to support chairs

00:01:43.360 --> 00:01:47.470
at the Kluge Center in US
Russia and US China relations.

00:01:47.470 --> 00:01:50.760
Tonight represents our
kickoff event for the Library

00:01:50.760 --> 00:01:53.010
of Congress chairs and US Russia

00:01:53.010 --> 00:01:55.170
and then also US
China relations.

00:01:55.170 --> 00:01:57.160
Our first scholar,
James Goldgeier,

00:01:57.160 --> 00:01:58.820
who is sitting right
here in front of me,

00:01:58.820 --> 00:02:01.060
just came to the
Center last month.

00:02:01.060 --> 00:02:04.000
He will be here through
May of next year.

00:02:04.000 --> 00:02:06.980
Jim's a Professor of, there's an
extensive bio in your materials,

00:02:06.980 --> 00:02:09.030
Jim is a Professor of
International Relations

00:02:09.030 --> 00:02:12.620
and served as Dean of the
School of International service

00:02:12.620 --> 00:02:16.160
at American University
from 2011 to 2017.

00:02:16.160 --> 00:02:19.470
He is concurrent with this
library appointment a visiting

00:02:19.470 --> 00:02:21.850
Senior Fellow at the
Council on Foreign Relations.

00:02:21.850 --> 00:02:25.080
He has held numerous public
policy appointments including

00:02:25.080 --> 00:02:28.410
Director for Russian,
Ukrainian and Eurasian Affairs

00:02:28.410 --> 00:02:31.030
at the National Security
Council.

00:02:31.030 --> 00:02:32.330
Goldgeier has published,

00:02:32.330 --> 00:02:35.080
is author of 4 books including
America Between the Wars:

00:02:35.080 --> 00:02:39.280
From 11/9 to 9/11, and
Not Whether But When:

00:02:39.280 --> 00:02:41.740
The US Decision to Enlarge NATO.

00:02:41.740 --> 00:02:43.920
Jim will be available to
you in a range of ways

00:02:43.920 --> 00:02:47.860
over the next 8 months on panels
like this as well as informally

00:02:47.860 --> 00:02:50.620
through briefings with
committee staff and others.

00:02:50.620 --> 00:02:53.500
We're planning events to
give Congress more context

00:02:53.500 --> 00:02:55.440
on other forms of
disinformation,

00:02:55.440 --> 00:02:58.480
the effectiveness of sanctions
as a foreign policy tool,

00:02:58.480 --> 00:03:01.320
why what happened in Russia
happened since the fall

00:03:01.320 --> 00:03:03.340
of the Soviet Union
and other topics.

00:03:03.340 --> 00:03:06.880
Let me also bring to your
attention our US China Chair,

00:03:06.880 --> 00:03:09.410
Minxin Pei, from
Claremont McKenna College,

00:03:09.410 --> 00:03:11.550
who will be in residence
beginning

00:03:11.550 --> 00:03:12.990
in January for 8 months.

00:03:12.990 --> 00:03:15.620
He's one of the world's
foremost experts on China.

00:03:15.620 --> 00:03:18.400
He'll be in residence here
for as I said for 8 months.

00:03:18.400 --> 00:03:21.810
He'll be heading panels on
the trade war with China,

00:03:21.810 --> 00:03:24.710
social control in
China, Chinese advances

00:03:24.710 --> 00:03:27.620
in technology and other matters.

00:03:27.620 --> 00:03:30.460
A couple of housekeeping things.

00:03:30.460 --> 00:03:33.170
We are taping this event.

00:03:33.170 --> 00:03:36.000
We may be featuring
it on our website.

00:03:36.000 --> 00:03:39.980
When we moved to Q&amp;A after
about 45 minutes or an hour

00:03:39.980 --> 00:03:42.280
of presentation by
the panel members,

00:03:42.280 --> 00:03:47.000
we will cut off the taping and
so that you guys are not going

00:03:47.000 --> 00:03:51.020
to appear on the Library
website asking a question.

00:03:51.020 --> 00:03:55.270
So don't worry about that, but
anyway carry on and I'm going

00:03:55.270 --> 00:03:57.320
to turn the event
over to Jim Goldgeier.

00:03:57.320 --> 00:03:58.980
Welcome, Jim.

00:03:58.980 --> 00:04:01.330
[ Applause ]

00:04:01.330 --> 00:04:02.630
&gt;&gt; All right.

00:04:02.630 --> 00:04:04.430
Come on up.

00:04:04.430 --> 00:04:19.290
[ Background talking ]

00:04:19.290 --> 00:04:20.590
&gt;&gt; James Goldgeier: Perfect.

00:04:20.590 --> 00:04:21.890
Well, thank you all so much
for coming out tonight.

00:04:21.890 --> 00:04:26.270
It's great to have such
a range of folks here

00:04:26.270 --> 00:04:31.770
from different parts the
congressional staff and it seems

00:04:31.770 --> 00:04:35.920
like this was a good topic
to choose to discuss,

00:04:35.920 --> 00:04:39.430
and we look forward especially
to your questions and ways

00:04:39.430 --> 00:04:40.730
in which we can help you

00:04:40.730 --> 00:04:43.430
with your work is what's
most important to us.

00:04:43.430 --> 00:04:46.570
So thanks to John Haskell
for his directorship

00:04:46.570 --> 00:04:49.970
of the Kluge Center and
thanks to our folks here

00:04:49.970 --> 00:04:51.790
from the Carnegie
Corporation of New York.

00:04:51.790 --> 00:04:55.090
It's great to see them
supporting the Kluge Center

00:04:55.090 --> 00:04:56.390
in this way.

00:04:56.390 --> 00:05:00.000
And we've got 3 amazing experts
here tonight who can talk

00:05:00.000 --> 00:05:03.190
with us about different
aspects of this issue

00:05:03.190 --> 00:05:06.330
of Russian information
manipulation,

00:05:06.330 --> 00:05:11.190
their role in US elections and
we're going to talk a little bit

00:05:11.190 --> 00:05:15.830
about to compare with
what we saw in 2016

00:05:15.830 --> 00:05:20.670
with what we're seeing here
in 2018 and really given that,

00:05:20.670 --> 00:05:25.730
you know, we're only a few
weeks out from this election

00:05:25.730 --> 00:05:28.680
that we really want to make
sure that we're talking sort

00:05:28.680 --> 00:05:33.950
of a the longer-term about the
kinds of things as a country

00:05:33.950 --> 00:05:36.580
that we should, can be
thinking about doing

00:05:36.580 --> 00:05:39.950
in response to these activities.

00:05:39.950 --> 00:05:43.680
So I'm going to open with
some discussions of my own

00:05:43.680 --> 00:05:47.430
for the 3 panelists and then,
you know, we do want to move

00:05:47.430 --> 00:05:51.470
into a Q&amp;A with you all so
that we make sure that we get,

00:05:51.470 --> 00:05:54.630
that we answer the questions
of the people who are going

00:05:54.630 --> 00:05:57.310
to be doing the actual
work here.

00:05:57.310 --> 00:06:00.720
So the bios are in the folder

00:06:00.720 --> 00:06:03.770
but just mentioning
the affiliations.

00:06:03.770 --> 00:06:08.550
Dr. Carla Anne Robbins on the
far end, who is both a professor

00:06:08.550 --> 00:06:10.780
at Baruch College and
head of the Masters

00:06:10.780 --> 00:06:12.920
in International Affairs
Program there as well

00:06:12.920 --> 00:06:14.880
as an Adjunct Senior Fellow

00:06:14.880 --> 00:06:17.390
at the Council on
Foreign Relations.

00:06:17.390 --> 00:06:20.960
Thomas Rid, who is a Professor

00:06:20.960 --> 00:06:22.400
at Johns Hopkins
University School

00:06:22.400 --> 00:06:25.810
of Advanced International
Studies, and is a great addition

00:06:25.810 --> 00:06:28.880
to Washington DC having
come a year ago from the UK.

00:06:28.880 --> 00:06:32.470
It's great to have him part
of a very dynamic program

00:06:32.470 --> 00:06:35.290
at the Kissinger
Institute at Johns Hopkins.

00:06:35.290 --> 00:06:37.940
And Dr. Alina Polyakova,

00:06:37.940 --> 00:06:41.360
who is here from the
Brookings Institution

00:06:41.360 --> 00:06:44.420
where she works not only
on these issues related

00:06:44.420 --> 00:06:47.940
to Russian foreign policy
but also issues related

00:06:47.940 --> 00:06:50.590
to populism throughout
Europe, which is, of course,

00:06:50.590 --> 00:06:53.250
an incredibly important topic.

00:06:53.250 --> 00:06:56.800
So we're going to start
with Carla, who is going

00:06:56.800 --> 00:06:59.790
to show us a little bit

00:06:59.790 --> 00:07:05.240
about what this information
manipulation actually looks like

00:07:05.240 --> 00:07:10.510
and to just give us a sense
of the kinds of things

00:07:10.510 --> 00:07:14.260
that people are seeing
that are being produced

00:07:14.260 --> 00:07:17.130
by whoever she's
going to tell us

00:07:17.130 --> 00:07:18.680
about who's doing
the production.

00:07:18.680 --> 00:07:20.600
So, Carla, let's start with you.

00:07:20.600 --> 00:07:23.210
&gt;&gt; Carla Anne Robbins: Thank you
so much, Jim, and thank you all.

00:07:23.210 --> 00:07:24.510
Great to see you.

00:07:24.510 --> 00:07:29.780
So the Russians push out their,
there's a great echo here,

00:07:29.780 --> 00:07:34.990
their disinformation on a whole
variety of different platforms

00:07:34.990 --> 00:07:39.300
on local language websites as
we know a lot about Facebook

00:07:39.300 --> 00:07:41.840
and Twitter and Instagram.

00:07:41.840 --> 00:07:44.860
They also have their RT
Television Network and website.

00:07:44.860 --> 00:07:46.930
You guys, I don't know
if you spend any time

00:07:46.930 --> 00:07:50.430
on RT it's somewhat mind
numbing, but I would suggest

00:07:50.430 --> 00:07:52.820
that it definitely gives you
an insight into how they think.

00:07:52.820 --> 00:07:59.390
It's Sputnik, they have a, we're
going to look at a few videos

00:07:59.390 --> 00:08:02.450
from something they call In
The Now, which is on YouTube

00:08:02.450 --> 00:08:04.840
and it's now migrated
over to Twitter,

00:08:04.840 --> 00:08:08.520
but these political
technologists tell you,

00:08:08.520 --> 00:08:10.490
there are messages for
different audiences,

00:08:10.490 --> 00:08:12.870
but certain themes are constant.

00:08:12.870 --> 00:08:15.570
Western governments
are weak or unraveling,

00:08:15.570 --> 00:08:19.050
elections are rigged,
God-fearing working people are

00:08:19.050 --> 00:08:21.250
under siege by migrants,
terrorists

00:08:21.250 --> 00:08:23.590
and cosmopolitan interests,

00:08:23.590 --> 00:08:26.630
the news from corrupt corporate
mainstream media can't be

00:08:26.630 --> 00:08:29.600
trusted and truth
is all relative.

00:08:29.600 --> 00:08:33.990
You have your truth, I
have my truth and, yeah,

00:08:33.990 --> 00:08:36.130
maybe there were
protesters meeting in Moscow

00:08:36.130 --> 00:08:38.420
but what about Ferguson?

00:08:38.420 --> 00:08:44.980
They also have this
incredible 21st Century mastery

00:08:44.980 --> 00:08:48.740
of what goes viral and as
I said they tailor this

00:08:48.740 --> 00:08:51.100
for difficult cultures
and countries.

00:08:51.100 --> 00:08:54.970
When I worked at the New York
Times I wish I had understood

00:08:54.970 --> 00:08:58.250
to go viral as well as their
to do it although we did it

00:08:58.250 --> 00:09:01.860
with the truth and maybe things
that aren't true do better

00:09:01.860 --> 00:09:04.140
on viral which is a
very frightening notion

00:09:04.140 --> 00:09:06.220
for someone who is a journalist.

00:09:06.220 --> 00:09:08.250
The last year they
pushed out on websites

00:09:08.250 --> 00:09:11.260
across Central Europe
was story in Polish

00:09:11.260 --> 00:09:14.730
that spreading Muslim [phonetic]
culture had led 150,000 women

00:09:14.730 --> 00:09:18.560
in Sweden to undergo
female genital mutilation.

00:09:18.560 --> 00:09:20.590
Obviously not true.

00:09:20.590 --> 00:09:22.090
A story in Czech claiming

00:09:22.090 --> 00:09:26.030
that US ships were delivering
migrants to Europe and one

00:09:26.030 --> 00:09:28.940
in Russian claiming
Ukraine's health ministry is

00:09:28.940 --> 00:09:30.240
selling organs.

00:09:30.240 --> 00:09:33.810
And I just chose
those from randomly.

00:09:33.810 --> 00:09:37.750
If you want to see what
they're doing every day,

00:09:37.750 --> 00:09:40.580
the EU something, called the
EU Disinformation Review,

00:09:40.580 --> 00:09:42.070
which you can sign up for.

00:09:42.070 --> 00:09:47.500
These things come into my inbox
and you will see just dozens

00:09:47.500 --> 00:09:49.570
of stories like this
all the time coming

00:09:49.570 --> 00:09:52.090
out on different websites
not just inside of Russia

00:09:52.090 --> 00:09:53.800
but across Central
Europe, Eastern Europe

00:09:53.800 --> 00:09:55.900
and Western Europe as well.

00:09:55.900 --> 00:10:00.050
And they are incredibly
viral and quite compelling.

00:10:00.050 --> 00:10:04.830
So what I'm going to show
you here are just 2 videos

00:10:04.830 --> 00:10:06.410
from something called
In The Now,

00:10:06.410 --> 00:10:08.540
which they've developed
for milennials.

00:10:08.540 --> 00:10:11.160
I've chosen them because
they're in English but also

00:10:11.160 --> 00:10:13.250
because they're pretty
compelling,

00:10:13.250 --> 00:10:20.380
and I can't really tell you, you
know, what their influence is.

00:10:20.380 --> 00:10:22.620
Influence is a very
interesting question

00:10:22.620 --> 00:10:25.800
and Thomas can tell us
a lot more about this

00:10:25.800 --> 00:10:28.380
because he's much more an
expert on it than I am,

00:10:28.380 --> 00:10:31.070
but RT which used to
be called Russia Today

00:10:31.070 --> 00:10:34.330
until they cleverly rebranded
themselves claims a reach

00:10:34.330 --> 00:10:36.930
of 700 million viewers
in 100 countries.

00:10:36.930 --> 00:10:38.350
Nielsen does not track them

00:10:38.350 --> 00:10:40.510
so we don't really know
how many people watch them

00:10:40.510 --> 00:10:41.810
or click on their website.

00:10:41.810 --> 00:10:47.850
They have 3.1 million YouTube
subscribers that we know

00:10:47.850 --> 00:10:52.070
versus 4.1 million for CNN so
it's a substantial thing but,

00:10:52.070 --> 00:10:53.740
you know, most of
their clicks if you go

00:10:53.740 --> 00:10:58.700
on their YouTube site are for,
you know, tsunamis in Japan.

00:10:58.700 --> 00:11:00.700
I mean they're click bait.

00:11:00.700 --> 00:11:05.230
On the other hand, a
little bit goes a long way

00:11:05.230 --> 00:11:06.650
when you're talking about viral.

00:11:06.650 --> 00:11:11.100
In the 2016 trolling,
$100,000 in Facebook ads,

00:11:11.100 --> 00:11:13.200
2,700 Facebook accounts,

00:11:13.200 --> 00:11:17.280
80,000 posts reached
126 million Americans.

00:11:17.280 --> 00:11:21.190
Slightly fewer than the
number of people who voted.

00:11:21.190 --> 00:11:25.390
This question of metrics versus
viral I defer to an expert

00:11:25.390 --> 00:11:27.240
like this on this question.

00:11:27.240 --> 00:11:30.990
So when you look at the numbers
on these particular videos,

00:11:30.990 --> 00:11:33.200
they look reasonably small,

00:11:33.200 --> 00:11:34.710
but one of the things
these numbers I'm going

00:11:34.710 --> 00:11:39.920
to show you are the numbers
that are RT In The Now numbers.

00:11:39.920 --> 00:11:42.540
One of the other things that
I've noticed in looking at some

00:11:42.540 --> 00:11:44.890
of these things is they
get picked up not just

00:11:44.890 --> 00:11:47.680
by pro-Russia websites
they also get picked

00:11:47.680 --> 00:11:51.270
up by alt-right websites
and there is a feedback

00:11:51.270 --> 00:11:52.990
that takes place
that's quite interesting

00:11:52.990 --> 00:11:54.290
and you can track some of them

00:11:54.290 --> 00:11:55.590
and there are some
very interesting people

00:11:55.590 --> 00:11:57.960
who are doing very
interesting forensic research

00:11:57.960 --> 00:12:00.110
like at the Atlanta Council
and a variety of other places

00:12:00.110 --> 00:12:02.250
that see the way things
bounce back and forth

00:12:02.250 --> 00:12:05.270
between Russian websites as
well as alt-right websites.

00:12:05.270 --> 00:12:07.460
So there's a lot of very
interesting work being done

00:12:07.460 --> 00:12:08.760
on this.

00:12:08.760 --> 00:12:12.340
So with that I will show
some of our favorites.

00:12:12.340 --> 00:12:15.370
Ah, yes, this is how
they describe themselves,

00:12:15.370 --> 00:12:17.860
news served hot with
a side of smile.

00:12:17.860 --> 00:12:20.160
It sounds so benign.

00:12:24.140 --> 00:12:28.050
&gt;&gt; I didn't care
when you got the DNC.

00:12:28.050 --> 00:12:30.980
I was fine when you
hacked Clinton's emails,

00:12:30.980 --> 00:12:33.790
but this time you've
gone too far, Russia.

00:12:33.790 --> 00:12:36.450
You've touched the
most sacred place,

00:12:36.450 --> 00:12:40.490
the source of all my funny
vids and friend's baby pictures

00:12:40.490 --> 00:12:43.010
and the only reason I
remember my friend's birthday.

00:12:43.010 --> 00:12:45.400
&gt;&gt; Russian interference
in the 2016 election

00:12:45.400 --> 00:12:47.790
and how it ties to Facebook ads.

00:12:47.790 --> 00:12:50.890
&gt;&gt; It sold about $100,000
worth of political ads

00:12:50.890 --> 00:12:53.180
to a so-called Russian
troll farm.

00:12:53.180 --> 00:12:55.360
&gt;&gt; Yes, it was about helping
Trump and hurting Hilary.

00:12:55.360 --> 00:12:58.790
&gt;&gt; Do you want me to
believe that $100,000 worth

00:12:58.790 --> 00:13:02.810
of Facebook ads could swing the
US elections trumping Hilary's

00:13:02.810 --> 00:13:06.570
campaign, which cost
over a billion dollars?

00:13:06.570 --> 00:13:09.010
And then Facebook says 25%

00:13:09.010 --> 00:13:12.500
of those ads weren't
even seen by anybody.

00:13:12.500 --> 00:13:16.120
And then there's Google who
just last month said it found no

00:13:16.120 --> 00:13:17.690
such Russian ads.

00:13:17.690 --> 00:13:21.270
Okay, Google, are you sure
there's no Russian interference

00:13:21.270 --> 00:13:22.570
on your platforms?

00:13:22.570 --> 00:13:25.050
That's better.

00:13:25.050 --> 00:13:27.230
You know if Russia
wants to get better

00:13:27.230 --> 00:13:29.750
at this then they should
learn from the best, America.

00:13:29.750 --> 00:13:35.730
In 1996, Bill Clinton endorsed
a $10 billion loan from the IMF

00:13:35.730 --> 00:13:38.460
to Boris Yeltsin which
helped him win the Kremlin

00:13:38.460 --> 00:13:39.760
and Russian hearts.

00:13:39.760 --> 00:13:42.190
Why? Because he was
completely incompetent

00:13:42.190 --> 00:13:44.100
in letting Russia fall apart,

00:13:44.100 --> 00:13:46.500
which was exactly why he
was the perfect candidate.

00:13:46.500 --> 00:13:49.100
Then Putin came along and
said get the hell out of here,

00:13:49.100 --> 00:13:51.340
America, this is our country
but that's another story.

00:13:51.340 --> 00:13:54.060
If you really want to
sway an election, Russia,

00:13:54.060 --> 00:13:56.500
you've got to do it
the American way.

00:13:56.500 --> 00:14:01.270
Learn from the best and have
the balls to spend billions.

00:14:01.270 --> 00:14:02.570
What do guys think?

00:14:02.570 --> 00:14:05.470
Did these Facebook ads
sway the US elections

00:14:05.470 --> 00:14:06.770
and leave us with Trump?

00:14:06.770 --> 00:14:08.070
Comment below.

00:14:08.070 --> 00:14:10.070
Give me a thumbs
up or thumbs down.

00:14:10.070 --> 00:14:15.230
It's up to you.

00:14:15.230 --> 00:14:16.530
&gt;&gt; Carla Anne Robbins:
That's Anisa,

00:14:16.530 --> 00:14:18.510
the Tokyo Rose of
our generation.

00:14:18.510 --> 00:14:22.080
[ Laughter ]

00:14:22.080 --> 00:14:23.380
And just one more.

00:14:23.380 --> 00:14:25.990
They spent a lot of
time attacking CNN,

00:14:25.990 --> 00:14:27.560
attacking the New York Times

00:14:27.560 --> 00:14:31.000
because you couldn't possibly
trust the mainstream media

00:14:31.000 --> 00:14:33.760
or anything of that sort,
but they also it's not just

00:14:33.760 --> 00:14:36.010
about the United States
and Russian influence

00:14:36.010 --> 00:14:39.190
in the election; they also
spent a lot of time on Syria

00:14:39.190 --> 00:14:40.490
and a variety of other things

00:14:40.490 --> 00:14:44.640
and this one has
to do with Syria.

00:14:44.640 --> 00:14:47.680
&gt;&gt; Final messages are
flying out of Aleppo, Syria.

00:14:47.680 --> 00:14:51.760
They're taking social media
by storm simultaneously.

00:14:51.760 --> 00:14:55.510
It almost looks like a
coordinated PR campaign.

00:14:55.510 --> 00:14:58.220
[ Inaudible ]

00:14:58.220 --> 00:14:59.560
&gt;&gt; This may be my last video.

00:14:59.560 --> 00:15:05.100
&gt;&gt; This might be close to if
not the last communication.

00:15:05.100 --> 00:15:06.830
&gt;&gt; It's the last time
that I talk to you.

00:15:06.830 --> 00:15:11.340
&gt;&gt; It's almost as if they were
hoping these final messages

00:15:11.340 --> 00:15:16.050
would trend and get picked
up by mainstream media.

00:15:16.050 --> 00:15:18.140
&gt;&gt; [Inaudible] people are
running they don't know where,

00:15:18.140 --> 00:15:19.440
just running.

00:15:19.440 --> 00:15:21.570
&gt;&gt; We are here living
a genocide literally.

00:15:21.570 --> 00:15:23.610
&gt;&gt; People are executed
it's as simple as that.

00:15:23.610 --> 00:15:26.770
&gt;&gt; it's almost like these
are just innocent civilians

00:15:26.770 --> 00:15:29.770
with no message, no
strategy, no politics,

00:15:29.770 --> 00:15:33.250
just people simply
fighting for their lives.

00:15:33.250 --> 00:15:35.520
One day saying goodbye
to the world

00:15:35.520 --> 00:15:38.680
on social media the next day
giving interviews to BBC,

00:15:38.680 --> 00:15:41.430
CNN and Al Jazeera
all in primetime.

00:15:41.430 --> 00:15:42.730
Well, they're not.

00:15:42.730 --> 00:15:44.030
These are activists.

00:15:44.030 --> 00:15:46.490
Some of them just
recently joined Twitter

00:15:46.490 --> 00:15:49.490
and clearly support
the revolution.

00:15:49.490 --> 00:15:51.760
They have thousands
of followers.

00:15:51.760 --> 00:15:55.010
Some call themselves journalists
are verified on Facebook

00:15:55.010 --> 00:15:56.500
like Bilal Abdul Kareem,

00:15:56.500 --> 00:16:00.450
an American who has no
problem pushing propaganda,

00:16:00.450 --> 00:16:01.890
you know, the rebels.

00:16:01.890 --> 00:16:05.540
This guy is a member of the
White Helmets who were founded

00:16:05.540 --> 00:16:09.010
by a British ex-military
officer and have been funded

00:16:09.010 --> 00:16:11.210
with millions by the US and UK

00:16:11.210 --> 00:16:14.710
and then there's a
little girl named Bana,

00:16:14.710 --> 00:16:18.510
also joined Twitter not
so long ago in September.

00:16:18.510 --> 00:16:22.060
She's already verified and
has over 200,000 followers.

00:16:22.060 --> 00:16:26.480
Bana is 7 years old and
tweets in perfect English

00:16:26.480 --> 00:16:28.130
from the heart of east Aleppo

00:16:28.130 --> 00:16:30.540
with a little help
from her mommy.

00:16:30.540 --> 00:16:34.500
She, of course, also had a
final message just in time.

00:16:34.500 --> 00:16:36.850
So what do all of these
people have in common?

00:16:36.850 --> 00:16:40.130
They want you to think
there's one side to this story,

00:16:40.130 --> 00:16:43.760
one truth that Oslyn is
randomly going from city to city

00:16:43.760 --> 00:16:47.260
and killing his own people for
some crazy reason with the help

00:16:47.260 --> 00:16:50.250
of Russia even though the whole
world is watching every step.

00:16:50.250 --> 00:16:53.660
They want you to think that
these civilians pouring

00:16:53.660 --> 00:16:56.180
out of Aleppo are running
from genocide committed

00:16:56.180 --> 00:16:58.990
by the Syrian army and
those who celebrate

00:16:58.990 --> 00:17:00.290
on the streets are dancing

00:17:00.290 --> 00:17:03.840
on children's graves while
al-Qaeda infiltrated rebels are

00:17:03.840 --> 00:17:08.310
bravely and heroically defending
civilians in East Aleppo.

00:17:08.310 --> 00:17:11.040
The question is do you buy it?

00:17:11.040 --> 00:17:13.510
Because millions of people do.

00:17:13.510 --> 00:17:19.650
[ Music ]

00:17:19.650 --> 00:17:21.820
&gt;&gt; Carla Anne Robbins:
Do you buy it?

00:17:21.820 --> 00:17:23.120
With that.

00:17:23.120 --> 00:17:24.420
&gt;&gt; James Goldgeier:
Thanks, Carla.

00:17:24.420 --> 00:17:31.940
All right so, Thomas, what do
these things, what do they do

00:17:31.940 --> 00:17:35.970
and when we compare
what was done in 2016

00:17:35.970 --> 00:17:38.840
and what race concerns
about what was done

00:17:38.840 --> 00:17:43.020
in 2016 how does it compare
to what has been done

00:17:43.020 --> 00:17:44.550
in this election cycle?

00:17:44.550 --> 00:17:49.130
Is it similar in terms
of the type of material,

00:17:49.130 --> 00:17:53.090
the scale of it, who
it is targeted to?

00:17:53.090 --> 00:17:56.590
If you could just give us
a sense of the evolution

00:17:56.590 --> 00:17:58.860
of this type of activity
and what it means.

00:17:58.860 --> 00:18:01.140
&gt;&gt; Thomas Rid: Yeah,
I'll be brief.

00:18:01.140 --> 00:18:08.660
So what we find in 2016 is
we saw hacking, you know,

00:18:08.660 --> 00:18:13.440
dial back remember the
14th of June 2016 is

00:18:13.440 --> 00:18:17.010
when this big Washington Post
story broke about the DNC hack,

00:18:17.010 --> 00:18:22.320
that the DNC had been hacked and
then one day later on the 15th

00:18:22.320 --> 00:18:26.300
of June the first leaks
started appearing first

00:18:26.300 --> 00:18:30.150
by this hacker claiming to
be independent [inaudible]

00:18:30.150 --> 00:18:33.160
which later turned out to be
Russian Military Intelligence.

00:18:33.160 --> 00:18:36.970
Now, we had what we saw with
hacking, I think I need to speak

00:18:36.970 --> 00:18:39.960
in this direction here, what
we saw with hacking, sorry,

00:18:39.960 --> 00:18:42.270
guys over there, hacking

00:18:42.270 --> 00:18:51.050
and leaking just very briefly
the evidence that we had in 2016

00:18:51.050 --> 00:18:55.120
that this was going on
was there from day 1.

00:18:55.120 --> 00:19:00.650
I remember I was doing a threat
intelligence class literally

00:19:00.650 --> 00:19:06.920
on the 15th of June in London
and just a few months prior

00:19:06.920 --> 00:19:09.280
to that I was actually at a
Russian security conference

00:19:09.280 --> 00:19:13.450
where we learned some tricks of
the trade of malware analysis.

00:19:13.450 --> 00:19:16.690
So I applied some of that to the
material that became available

00:19:16.690 --> 00:19:20.040
on the 14th of June as did
a lot of people in infosect,

00:19:20.040 --> 00:19:22.820
information security,
cyber security community.

00:19:22.820 --> 00:19:26.800
And there was no doubt that
this was actually a Russian hack

00:19:26.800 --> 00:19:30.440
and when the leak started it
was equally clear to anybody

00:19:30.440 --> 00:19:33.420
in the field that this
is a Russian operation.

00:19:33.420 --> 00:19:38.990
So one of the failures I
think in hindsight failures

00:19:38.990 --> 00:19:41.460
of both the Obama Administration

00:19:41.460 --> 00:19:47.240
but really also the intelligence
community was they reacted

00:19:47.240 --> 00:19:49.730
so slowly to this
leaking operation

00:19:49.730 --> 00:19:53.030
because it was very clear
early on that it was effective,

00:19:53.030 --> 00:19:56.640
that it was picked up by the
press and the press treated it

00:19:56.640 --> 00:19:59.620
as genuine material
although already

00:19:59.620 --> 00:20:03.760
in a very fast leak we
saw traces of messing

00:20:03.760 --> 00:20:08.130
with the content of
modifying content,

00:20:08.130 --> 00:20:09.570
metadata mainly but still.

00:20:09.570 --> 00:20:16.020
Today in 2018 we don't see,
we see a lot of hacking still,

00:20:16.020 --> 00:20:20.440
you know, I'm looking here at
a room of high value targets.

00:20:20.440 --> 00:20:26.220
I'm not joking, but we
don't see any leaks so far.

00:20:26.220 --> 00:20:27.810
So that's a completely
different situation.

00:20:27.810 --> 00:20:29.950
What I would also like to
stress that we are not looking

00:20:29.950 --> 00:20:31.320
at a general election situation.

00:20:31.320 --> 00:20:34.980
It's much harder to interfere
with a mid-term election

00:20:34.980 --> 00:20:37.720
because there's no
presidential election going

00:20:37.720 --> 00:20:40.370
on at the same time
with the same focus.

00:20:40.370 --> 00:20:43.110
So, completely different
ballgame

00:20:43.110 --> 00:20:46.740
and I'm deliberately completely
ignoring the social media aspect

00:20:46.740 --> 00:20:49.750
right now because I think
it's to be really simplistic

00:20:49.750 --> 00:20:52.960
in this room it's blown
out of proportion.

00:20:52.960 --> 00:20:54.260
The most important component

00:20:54.260 --> 00:20:59.070
of 2016 was the leaking not
the social media amplification.

00:20:59.070 --> 00:21:02.470
The operation by the
way was also disjointed.

00:21:02.470 --> 00:21:04.290
The social media
Twitter especially

00:21:04.290 --> 00:21:10.220
and Facebook the disinformation
component was not synced

00:21:10.220 --> 00:21:11.690
up with the leaking.

00:21:11.690 --> 00:21:14.600
But let me make this very
personal for a moment

00:21:14.600 --> 00:21:17.400
for everybody here in the room.

00:21:17.400 --> 00:21:20.440
I'm going to say
something that many

00:21:20.440 --> 00:21:23.120
of you wouldn't admit
freely but I have it

00:21:23.120 --> 00:21:26.060
from trustworthy sources
that literally everybody

00:21:26.060 --> 00:21:27.910
in this room has
a Google account,

00:21:27.910 --> 00:21:30.990
maybe also a Slack account.

00:21:30.990 --> 00:21:33.690
I'm just assuming here that many

00:21:33.690 --> 00:21:37.470
of you use their Google
account sometimes at work.

00:21:37.470 --> 00:21:41.380
Right? So let me
ask you let's ignore

00:21:41.380 --> 00:21:45.340
that fact whether you use it at
work or not and let's just talk

00:21:45.340 --> 00:21:48.550
about your personal Google
account for a moment.

00:21:48.550 --> 00:21:51.170
Who in the this room, and we
know hacking is going on, right?

00:21:51.170 --> 00:21:54.610
You are high value targets, who
in this room if I can ask you

00:21:54.610 --> 00:21:59.820
for a show of hands, who in this
room is using advanced security

00:21:59.820 --> 00:22:03.330
settings, you know, 2-factor
authentication, a password

00:22:03.330 --> 00:22:04.940
and then something else,

00:22:04.940 --> 00:22:09.150
in order to protect a
personal gmail account?

00:22:09.150 --> 00:22:13.650
Who is using advanced
security settings?

00:22:13.650 --> 00:22:17.000
And just to repeat I'm not
asking you whether you use your

00:22:17.000 --> 00:22:18.300
Google at work.

00:22:18.300 --> 00:22:19.670
This is not the question
I'm asking.

00:22:19.670 --> 00:22:23.100
[Laughter] Are you actually
securing your gmail account

00:22:23.100 --> 00:22:24.700
with 2-factor authentication?

00:22:24.700 --> 00:22:30.140
And I'm a little shocked at what
I see here is only 1/3 at best.

00:22:30.140 --> 00:22:32.740
Those of you who haven't raised
their hands you know what to do

00:22:32.740 --> 00:22:35.880
when you get home
and I'm not joking

00:22:35.880 --> 00:22:40.500
because it's relatively easy
to break into an email account

00:22:40.500 --> 00:22:44.310
if you don't secure it with
2-factor authentication.

00:22:44.310 --> 00:22:45.640
And, of course, there
are different ways

00:22:45.640 --> 00:22:46.940
to do that securely.

00:22:46.940 --> 00:22:48.310
Don't use SMS by the way.

00:22:48.310 --> 00:22:49.610
It's not secure.

00:22:49.610 --> 00:22:50.910
So keep it simple.

00:22:50.910 --> 00:22:55.350
Use an app or even better
Yubico key for the second step,

00:22:55.350 --> 00:22:57.790
but really everybody in
this room I just want

00:22:57.790 --> 00:22:59.780
to make this very
applied for a moment

00:22:59.780 --> 00:23:04.810
in mind should use actually
Google advanced protection and,

00:23:04.810 --> 00:23:07.380
you know, we understand
the dynamics here.

00:23:08.510 --> 00:23:10.570
Using a personal account
at work is something

00:23:10.570 --> 00:23:12.420
that happens everywhere,
it happens here,

00:23:12.420 --> 00:23:15.150
it happens in my companies,
I do it too all the time

00:23:15.150 --> 00:23:18.130
because my gmail
account is more secure

00:23:18.130 --> 00:23:19.820
than my university account.

00:23:19.820 --> 00:23:23.600
I'm even using a gmail
account public facing me

00:23:23.600 --> 00:23:26.290
because in my line
of work working

00:23:26.290 --> 00:23:29.300
with a university email account
has such a bad reputation

00:23:29.300 --> 00:23:32.200
because they're so badly
secured that I don't want

00:23:32.200 --> 00:23:33.500
to take the reputational risk

00:23:33.500 --> 00:23:35.440
of actually using my
employer's email account.

00:23:35.440 --> 00:23:39.050
That's how bad the situation is.

00:23:39.050 --> 00:23:41.950
It's not much better here, and
I think this is a huge problem

00:23:41.950 --> 00:23:46.590
that all parliaments,
all elected, you know,

00:23:46.590 --> 00:23:51.120
all democracies are facing
because the security setup,

00:23:51.120 --> 00:23:52.420
you know, basically
we're looking

00:23:52.420 --> 00:23:56.550
at 435 small business
units in the House

00:23:56.550 --> 00:23:59.570
and 100 small business
units slightly larger ones

00:23:59.570 --> 00:24:01.310
in the center.

00:24:01.310 --> 00:24:06.710
So, you know, fixing security
raises difficult organizational

00:24:06.710 --> 00:24:08.460
and ethical issues here.

00:24:08.460 --> 00:24:12.220
Do I have another
minute or you want me to?

00:24:12.220 --> 00:24:13.520
&gt;&gt; James Goldgeier: Yeah, sure.

00:24:13.520 --> 00:24:15.980
One more minute is good.

00:24:15.980 --> 00:24:17.280
&gt;&gt; Thomas Rid: Okay.

00:24:17.280 --> 00:24:19.100
So let me say something
about leaking side of things.

00:24:19.100 --> 00:24:21.540
I spoke about the hacking today.

00:24:21.540 --> 00:24:23.110
How about the disinformation
side?

00:24:23.110 --> 00:24:25.800
I'm currently finishing
up a book on the history

00:24:25.800 --> 00:24:31.750
of disinformation 20th
Century story really,

00:24:31.750 --> 00:24:36.660
and what is the goal of
disinformation operations?

00:24:36.660 --> 00:24:39.210
What is the logic,
logic of disinformation?

00:24:39.210 --> 00:24:42.360
I think it's important to
state that very clearly.

00:24:42.360 --> 00:24:47.210
The logic of disinformation
is to undermine the trust

00:24:47.210 --> 00:24:52.350
that we have in the
institutions that guard facts

00:24:52.350 --> 00:24:54.730
to undermine the trust
in law enforcement

00:24:54.730 --> 00:24:58.090
because they only function
on the basis of fact.

00:24:58.090 --> 00:24:59.390
So undermine the trust

00:24:59.390 --> 00:25:02.270
in the intelligence community
there are also, you know,

00:25:02.270 --> 00:25:06.640
analytically keeping facts,
they're writing factual reports,

00:25:06.640 --> 00:25:10.260
undermine the authority of
investigative journalism

00:25:10.260 --> 00:25:13.470
and really undermine also
the authority of parts

00:25:13.470 --> 00:25:16.990
of the public administration
especially election commissions

00:25:16.990 --> 00:25:20.610
that are in charge of guarding
the fact at this moment

00:25:20.610 --> 00:25:24.640
of grade vulnerability,
that is election night,

00:25:24.640 --> 00:25:27.460
because if you can't trust
the facts on election night,

00:25:27.460 --> 00:25:29.150
what are you doing to do?

00:25:29.150 --> 00:25:31.380
If you can't trust the facts,
you can't trust the press

00:25:31.380 --> 00:25:34.060
when you switch on your TV
or when you go to the website

00:25:34.060 --> 00:25:35.720
of the New York Times
or something,

00:25:35.720 --> 00:25:40.200
if you can't trust the providers
of the facts on election night,

00:25:40.200 --> 00:25:45.380
then you will default
to trusting your tribe.

00:25:45.380 --> 00:25:50.220
So this is a very unpleasant
truth to articulate here,

00:25:50.220 --> 00:25:53.560
but right now the biggest
threat to the integrity

00:25:53.560 --> 00:25:55.890
of the election,
the biggest threat

00:25:55.890 --> 00:25:59.190
on that very fragile moment
that every democracy is facing

00:25:59.190 --> 00:26:03.550
on the evening of election
night, is not Russia.

00:26:03.550 --> 00:26:06.780
The biggest threat is that
powerful people and groups

00:26:06.780 --> 00:26:10.950
in this country will
call the legitimacy

00:26:10.950 --> 00:26:15.090
of the election itself into
question on election night.

00:26:15.090 --> 00:26:19.060
Now, when that happens, we're
facing a very dangerous moment

00:26:19.060 --> 00:26:23.310
because election night is
also a moment where the peace,

00:26:23.310 --> 00:26:26.880
peaceful transition of
power is on the line.

00:26:26.880 --> 00:26:31.640
I think, and I really
apologize for sounding so dire

00:26:31.640 --> 00:26:34.940
and alarmist here, but I
think and I also apologize

00:26:34.940 --> 00:26:37.580
for not looking into
this direction,

00:26:37.580 --> 00:26:42.320
but I think in this building
we should really have,

00:26:42.320 --> 00:26:45.430
you should really have
conversations, you know,

00:26:45.430 --> 00:26:51.120
with your member of Congress
or your senator and nudge them

00:26:51.120 --> 00:26:55.250
to have private conversations
about what to do in the heat

00:26:55.250 --> 00:26:59.590
of the moment on election
night if shit hits the fan

00:26:59.590 --> 00:27:02.190
because it could and if that
happens, then we're looking

00:27:02.190 --> 00:27:05.060
at a very dangerous moment and
we have to be ready to face

00:27:05.060 --> 00:27:09.560
that moment and not improvise
when it comes to that.

00:27:09.560 --> 00:27:13.630
So, because ultimately
the responsibility

00:27:13.630 --> 00:27:16.450
to de-escalate will be here,

00:27:16.450 --> 00:27:18.590
will be in Congress,
nobody else.

00:27:18.590 --> 00:27:20.230
It can't come from
the Executive Branch.

00:27:20.230 --> 00:27:22.780
Nobody else will have the
political clout and power

00:27:22.780 --> 00:27:29.310
in that moment to fan, you
know, to sort of step forward

00:27:29.310 --> 00:27:32.240
and say let's relax
this is what happened,

00:27:32.240 --> 00:27:33.550
this is what we should do.

00:27:33.550 --> 00:27:35.810
So, yeah, I'd like
to close with that.

00:27:35.810 --> 00:27:37.110
&gt;&gt; James Goldgeier: Okay.

00:27:37.110 --> 00:27:38.410
So, thank you.

00:27:38.410 --> 00:27:42.360
So, Alina, you know,
Carla showed the videos

00:27:42.360 --> 00:27:46.090
that are an attempt to sort

00:27:46.090 --> 00:27:49.100
of structure the way people are
thinking about particular issues

00:27:49.100 --> 00:27:53.920
and Thomas just talked about
the different efforts underway

00:27:53.920 --> 00:27:57.830
that can undermine
trust in institutions

00:27:57.830 --> 00:28:00.380
and cast doubt on legitimacy.

00:28:00.380 --> 00:28:04.480
Is this part of some kind

00:28:04.480 --> 00:28:09.960
of coherent Russian strategy
vis-a-vis the United States?

00:28:09.960 --> 00:28:12.540
If so, whose strategy is it?

00:28:12.540 --> 00:28:15.690
And, you know, how should
we be thinking about sort

00:28:15.690 --> 00:28:21.140
of the big picture of what is
going on in the Russian side?

00:28:21.140 --> 00:28:23.640
&gt;&gt; Alina Polyankova: Thank
you, Jim, and I'm very lucky

00:28:23.640 --> 00:28:26.300
to be following these two
presentations because, one,

00:28:26.300 --> 00:28:30.700
I hope I won't be as
dark as Thomas has been

00:28:30.700 --> 00:28:37.070
and hopefully I'll combine some
of what you have shown as well.

00:28:37.070 --> 00:28:40.610
I think it's important to
remember that, you know,

00:28:40.610 --> 00:28:45.830
what Thomas is talking about and
the disinformation activities

00:28:45.830 --> 00:28:48.040
of RT and Facebook and
Twitter, et cetera,

00:28:48.040 --> 00:28:50.790
don't take place in a vacuum.

00:28:50.790 --> 00:28:55.170
There is a much broader
ecosystem here, an ecosystem

00:28:55.170 --> 00:28:56.850
of political warfare,

00:28:56.850 --> 00:29:00.690
which includes disinformation
campaigns to the [inaudible]

00:29:00.690 --> 00:29:04.800
of social media, which includes
cyber attacks and leaks,

00:29:04.800 --> 00:29:07.270
which includes then the
amplification of those leaks

00:29:07.270 --> 00:29:10.390
and true in the US case
these are not coordinated,

00:29:10.390 --> 00:29:11.690
but they do try to
coordinate them

00:29:11.690 --> 00:29:13.710
in the French case during
the [inaudible] election,

00:29:13.710 --> 00:29:15.010
not successfully.

00:29:15.010 --> 00:29:17.010
We can talk a little bit about
why it was not successful,

00:29:17.010 --> 00:29:18.580
but they still maybe
have learned

00:29:18.580 --> 00:29:23.740
or they should have a better
coordination mechanism there.

00:29:23.740 --> 00:29:26.620
And it also includes things
like political influence.

00:29:26.620 --> 00:29:31.360
So co-opting individuals,
political parties,

00:29:31.360 --> 00:29:34.360
or not [inaudible] just
forging strategic alliances,

00:29:34.360 --> 00:29:39.190
for example, with anti-EU,
pro-Russian political parties

00:29:39.190 --> 00:29:42.810
in Europe which the Kremlin
has built out a network

00:29:42.810 --> 00:29:45.900
of relationships with including
formal cooperation agreements

00:29:45.900 --> 00:29:48.280
with at least four of
those political parties.

00:29:48.280 --> 00:29:52.120
And it also includes a
thing more importantly money

00:29:52.120 --> 00:29:54.810
laundering and elicit finance.

00:29:54.810 --> 00:29:58.500
So the buying of influence
in European countries

00:29:58.500 --> 00:30:03.810
in the United States through
the export of cryptocracy.

00:30:03.810 --> 00:30:08.480
To my mind this is the most
difficult issue to explore

00:30:08.480 --> 00:30:09.780
because it's very difficult

00:30:09.780 --> 00:30:11.500
to trace those financial
flows unless you're

00:30:11.500 --> 00:30:14.280
in the intelligence community
but there's also a lot more

00:30:14.280 --> 00:30:17.910
that we can do in the United
States and in Europe to try

00:30:17.910 --> 00:30:21.230
to close off some of
those opportunities.

00:30:21.230 --> 00:30:26.180
So, we have to look at this as a
basket of tools as an ecosystem.

00:30:26.180 --> 00:30:28.100
It's not always so coordinated.

00:30:28.100 --> 00:30:31.850
I agree with you there, Thomas,
but then in the grand scheme

00:30:31.850 --> 00:30:35.610
of things amplifies the
objectives that Russia is trying

00:30:35.610 --> 00:30:39.860
to pursue but it's very obvious
this is not just about Russia.

00:30:39.860 --> 00:30:43.600
I mean Russia has pioneered
some of these tools but now

00:30:43.600 --> 00:30:48.360
that has shown how effective
these low-cost operations can be

00:30:48.360 --> 00:30:50.990
they will clearly and are
clearly already being used

00:30:50.990 --> 00:30:54.790
by other hostile foreign actors.

00:30:54.790 --> 00:30:59.260
And so the way these
things function the,

00:30:59.260 --> 00:31:03.120
so the toolbox I mentioned,
is that they exploit gaps,

00:31:03.120 --> 00:31:05.300
they exploit loop holes
in our legal systems

00:31:05.300 --> 00:31:08.070
like campaign finances,
campaign finance regulations,

00:31:08.070 --> 00:31:11.650
for example, and they exploit
divisions in our society.

00:31:11.650 --> 00:31:13.570
I think all of you are
familiar with how that happens

00:31:13.570 --> 00:31:16.780
on Facebook by support
through Black [inaudible]

00:31:16.780 --> 00:31:19.510
on the one hand and the
white nationalists groups

00:31:19.510 --> 00:31:22.880
on the other hand and trying
to coordinate protest movements

00:31:22.880 --> 00:31:26.190
and things like that
between these various groups.

00:31:26.190 --> 00:31:27.950
I won't go into too
much detail about that,

00:31:27.950 --> 00:31:30.140
but I think the bigger point

00:31:30.140 --> 00:31:33.420
about a strategic intent is
I do think there's some point

00:31:33.420 --> 00:31:36.800
to recognize that what
Russia has done and continues

00:31:36.800 --> 00:31:41.070
to do has not been
innovative or sophisticated

00:31:41.070 --> 00:31:43.100
from a technical perspective.

00:31:43.100 --> 00:31:46.170
They've basically taken the
tools that already existed

00:31:46.170 --> 00:31:50.280
out there that corporations
use, the private sector use.

00:31:50.280 --> 00:31:53.200
So, like Nike, for example,

00:31:53.200 --> 00:31:56.760
would use the same micro
targeting tools on Facebook

00:31:56.760 --> 00:32:00.260
or Twitter and Google to
try to sell sneakers to men

00:32:00.260 --> 00:32:04.430
between the ages 17 to 19 living
in the suburbs of Michigan

00:32:04.430 --> 00:32:07.200
who bought Adidas sneakers
in the last 6 months

00:32:07.200 --> 00:32:10.170
and who may have all of
these other attitudinal

00:32:10.170 --> 00:32:12.070
demographic characteristics.

00:32:12.070 --> 00:32:14.760
These kinds of micro
targeting tools that allow

00:32:14.760 --> 00:32:16.990
for not just precision marketing

00:32:16.990 --> 00:32:19.870
but also precision
propaganda exists

00:32:19.870 --> 00:32:23.150
because there's a
multi-billion dollar industry

00:32:23.150 --> 00:32:26.370
because every piece of
content that we see online.

00:32:26.370 --> 00:32:29.120
So, in your Facebook feed and
your Twitter feed wherever

00:32:29.120 --> 00:32:31.390
and your Google search
what appears first

00:32:31.390 --> 00:32:33.410
that is already a
manipulated environment

00:32:33.410 --> 00:32:36.280
and the environment is
manipulated not so much

00:32:36.280 --> 00:32:39.370
by hostile actors but it's
manipulated by market forces.

00:32:39.370 --> 00:32:44.150
And what Russia did in their
operations is they were able

00:32:44.150 --> 00:32:48.840
to co-op these tools and what
they're able to achieve is

00:32:48.840 --> 00:32:51.600
with very little
money very high impact

00:32:51.600 --> 00:32:53.740
and by impact I don't
mean changing the outcome

00:32:53.740 --> 00:32:55.410
of the election.

00:32:55.410 --> 00:32:58.730
I don't see a lot of evidence
and that's what happened

00:32:58.730 --> 00:33:03.250
in the United States given the
low level of Russian engagement.

00:33:03.250 --> 00:33:07.690
What I do see is that from
the last 2 years our entire

00:33:07.690 --> 00:33:09.400
political system and debate

00:33:09.400 --> 00:33:14.930
in conversation has been
completely overtaken by,

00:33:14.930 --> 00:33:17.870
we're still talking about it
and for the midterms, you know,

00:33:17.870 --> 00:33:21.710
what the Russians did is
Donald Trump, you know,

00:33:21.710 --> 00:33:26.920
[inaudible] candidate was,
did Hilary lose legitimately?

00:33:26.920 --> 00:33:29.110
We're still talking about
these issues for 2 years

00:33:29.110 --> 00:33:32.460
and they're incredibly
divisive to our society.

00:33:32.460 --> 00:33:35.140
And so from that perspective
it's been incredibly successful

00:33:35.140 --> 00:33:38.260
and high impact at
a very low cost.

00:33:38.260 --> 00:33:42.550
So why did the Russians do
this I thing is the question,

00:33:42.550 --> 00:33:46.430
why do they continue to do this?

00:33:46.430 --> 00:33:49.610
Well, I think we have to
understand what the Kremlin does

00:33:49.610 --> 00:33:53.090
from the perspective
of pre-rational actor.

00:33:53.090 --> 00:33:57.380
The Russia today faces
quite a significant number

00:33:57.380 --> 00:34:00.020
of constraints.

00:34:00.020 --> 00:34:02.450
Those constraints being
limited resources.

00:34:02.450 --> 00:34:04.570
The Russian economy
is relatively small

00:34:04.570 --> 00:34:07.600
and will stagnate for
the foreseeable future.

00:34:07.600 --> 00:34:09.250
So it's not China, you know,

00:34:09.250 --> 00:34:12.180
the government can't
just snap its fingers

00:34:12.180 --> 00:34:15.280
and have an AI strategy
that will invest, you know,

00:34:15.280 --> 00:34:17.830
hundreds of billions by 2030.

00:34:17.830 --> 00:34:19.820
They can't do that.

00:34:19.820 --> 00:34:21.850
They don't have the capacity

00:34:21.850 --> 00:34:24.350
for homegrown private
sector innovation.

00:34:24.350 --> 00:34:26.900
So they can't compete
with the United States.

00:34:26.900 --> 00:34:28.200
Russia attempts to set

00:34:28.200 --> 00:34:31.530
up a Silicon Valley have
been pretty much a failure.

00:34:31.530 --> 00:34:34.860
This is the [inaudible] they
tried to setup some years ago

00:34:34.860 --> 00:34:39.340
which hasn't spurred the kind
of innovation that we see coming

00:34:39.340 --> 00:34:43.160
from the United States and
increasingly from China.

00:34:43.160 --> 00:34:46.910
And it has a major
human capital problem.

00:34:46.910 --> 00:34:49.450
Russia is experiencing
a brain drain.

00:34:49.450 --> 00:34:52.160
We don't know a lot
about the details of it

00:34:52.160 --> 00:34:54.900
but certainly anecdotally we
know that a lot of individuals

00:34:54.900 --> 00:34:58.100
who have tech sector
skills that speak English,

00:34:58.100 --> 00:35:00.880
other European languages,
don't have other opportunities

00:35:00.880 --> 00:35:03.820
in Russia because the
economy is broken,

00:35:03.820 --> 00:35:06.670
there's very little
growth projected

00:35:06.670 --> 00:35:08.400
and it's hydrocarbon dependent.

00:35:08.400 --> 00:35:10.540
Must like the Soviet
economy was.

00:35:10.540 --> 00:35:13.910
So it's very difficult for an
educated young person to be able

00:35:13.910 --> 00:35:16.240
to pursue opportunities
there especially they can

00:35:16.240 --> 00:35:18.400
go elsewhere.

00:35:18.400 --> 00:35:24.180
So, in my view if I'm sitting
in the Kremlin and I'm trying

00:35:24.180 --> 00:35:27.400
to think through how to achieve
my broader strategic goal

00:35:27.400 --> 00:35:30.400
which is what Thomas said
to undermine the west,

00:35:30.400 --> 00:35:32.610
to undermine trust in
democratic institutions,

00:35:32.610 --> 00:35:36.290
other institutions underpinning
democracies in the west.

00:35:36.290 --> 00:35:39.330
I see them outflanked
militarily,

00:35:39.330 --> 00:35:41.750
outflanked economically,

00:35:41.750 --> 00:35:46.530
but there are very convenient
targets of opportunity

00:35:46.530 --> 00:35:50.080
if we invest in a
symmetric warfare.

00:35:50.080 --> 00:35:53.090
And, of course, from a Russian
perspective this has been a long

00:35:53.090 --> 00:35:56.380
forming part of Russian military
doctrine warfare isn't just

00:35:56.380 --> 00:35:59.500
about tanks or no tanks.

00:35:59.500 --> 00:36:03.450
It's a spectrum and information
warfare is very much part

00:36:03.450 --> 00:36:05.740
and parcel of that
spectrum and over the course

00:36:05.740 --> 00:36:09.900
of the last let's
say maybe since 2006

00:36:09.900 --> 00:36:11.310
but still has been accelerated

00:36:11.310 --> 00:36:15.700
in 2012 the Russian government
has been investing we don't know

00:36:15.700 --> 00:36:19.100
how much obviously and
developing its tool

00:36:19.100 --> 00:36:22.520
of asymmetric warfare and this,
again, is a rational strategy

00:36:22.520 --> 00:36:25.310
because this is where the
Kremlin can still have

00:36:25.310 --> 00:36:28.840
comparative advantage or it
lacks that comparative advantage

00:36:28.840 --> 00:36:33.490
in other arenas and at the end
of the day it's a zero sum view

00:36:33.490 --> 00:36:37.770
of the world meaning that you
don't have to be a great power,

00:36:37.770 --> 00:36:39.870
which is of course
the aspiration

00:36:39.870 --> 00:36:42.950
that Putin sees himself
reaching,

00:36:42.950 --> 00:36:46.750
the aspiration isn't matched
by reality, but you don't have

00:36:46.750 --> 00:36:48.890
to be a really great power.

00:36:48.890 --> 00:36:51.860
All you have to do is push
everybody else down so

00:36:51.860 --> 00:36:55.400
that your stock rises above
them and that's really the view

00:36:55.400 --> 00:36:58.830
of the world and that's
really how I understand all

00:36:58.830 --> 00:37:02.420
of these influence
operation and where they fit

00:37:02.420 --> 00:37:04.060
in the broader spectrum

00:37:04.060 --> 00:37:07.260
of Russian foreign
policy in general.

00:37:07.260 --> 00:37:09.370
And so because we're
talking to all of you

00:37:09.370 --> 00:37:13.060
who are congressional
staff and you have to think

00:37:13.060 --> 00:37:14.360
about what do we do about all

00:37:14.360 --> 00:37:18.580
of this not just what is it I
do think there's a few things

00:37:18.580 --> 00:37:20.370
that you want to take,
you may want to take

00:37:20.370 --> 00:37:23.220
into consideration probably
after the elections are over,

00:37:23.220 --> 00:37:30.150
you know, down the line
we are still engaged

00:37:30.150 --> 00:37:33.660
in fighting the wars
of yester year.

00:37:33.660 --> 00:37:35.900
We still don't know
what to really do

00:37:35.900 --> 00:37:38.930
about social media manipulation
of this information.

00:37:38.930 --> 00:37:46.050
The US government has not
responded in a coordinated way.

00:37:46.050 --> 00:37:47.870
We also don't have the
institutions we used

00:37:47.870 --> 00:37:50.940
to have in the Cold War.

00:37:50.940 --> 00:37:56.870
So one thing I would say is that
what's coming at us if I'm right

00:37:56.870 --> 00:37:58.950
about Russian strategic
investments

00:37:58.950 --> 00:38:02.500
in the space is much
more sophisticated tools,

00:38:02.500 --> 00:38:05.170
a precision propaganda
disinformation

00:38:05.170 --> 00:38:07.750
that will harness the power
of emerging technologies

00:38:07.750 --> 00:38:11.960
like artificial intelligence
to be much more precise

00:38:11.960 --> 00:38:14.740
and [inaudible] very cheap
[inaudible] these algorithms

00:38:14.740 --> 00:38:16.880
they'll all out there
in Open Source.

00:38:16.880 --> 00:38:19.550
So the amazing part anybody
can make deep [inaudible],

00:38:19.550 --> 00:38:24.630
anybody can manipulate audio,
anybody can manipulate video,

00:38:24.630 --> 00:38:27.410
place people's faces, you
know, about all this, right?

00:38:27.410 --> 00:38:30.100
I don't have to tell you you
all are like young and part

00:38:30.100 --> 00:38:33.410
of the digital revolution
and we're not.

00:38:33.410 --> 00:38:35.110
But there are things
that Congress can do.

00:38:35.110 --> 00:38:38.860
I think one we haven't
had updated AI strategy

00:38:38.860 --> 00:38:42.360
because this is really
the core of the future

00:38:42.360 --> 00:38:44.330
of political warfare in my view.

00:38:44.330 --> 00:38:47.360
Congress should take a much more
active role in crafting what

00:38:47.360 --> 00:38:51.340
that is and potentially seeking
to incorporate more aspects

00:38:51.340 --> 00:38:55.580
of a real AI strategy
into the NDAA.

00:38:55.580 --> 00:38:58.390
I mentioned elicit finance.

00:38:58.390 --> 00:39:03.420
Beneficial ownership legislation
is absolutely key here.

00:39:03.420 --> 00:39:08.090
A registry that I think has
proposed multiple bills now

00:39:08.090 --> 00:39:10.870
which there is a registry
of beneficial ownership,

00:39:10.870 --> 00:39:13.280
find [phonetic] the
ownership that is regulated

00:39:13.280 --> 00:39:15.660
and administered by
Fenced In [phonetic].

00:39:15.660 --> 00:39:18.880
This would not be public,
which is what it is in the UK

00:39:18.880 --> 00:39:22.030
but it would bring up the US
to some level of standards

00:39:22.030 --> 00:39:25.590
like the Cayman Islands
potentially not necessarily

00:39:25.590 --> 00:39:27.860
with our European
friends and allies.

00:39:27.860 --> 00:39:29.200
And this I think
would be an easy fix

00:39:29.200 --> 00:39:32.680
and it would go a very long
way in at least blocking some

00:39:32.680 --> 00:39:35.820
of those initial loop
holes and gaps that we have

00:39:35.820 --> 00:39:37.850
in a regular touring
[phonetic] environment.

00:39:37.850 --> 00:39:39.640
So I'll stop with
those two things.

00:39:39.640 --> 00:39:40.940
&gt;&gt; James Goldgeier: Great.

00:39:40.940 --> 00:39:42.240
Thank you.

00:39:42.240 --> 00:39:45.000
Carla, I wanted to just come
back to what you were showing us

00:39:45.000 --> 00:39:48.670
at the beginning especially
in the context of what Thomas

00:39:48.670 --> 00:39:50.540
and Alina have discussed
with us.

00:39:50.540 --> 00:39:55.930
In terms of addressing this
challenge I mean we don't

00:39:55.930 --> 00:40:02.190
in this country as a matter of
course seek to regulate content.

00:40:02.190 --> 00:40:03.490
And so --

00:40:03.490 --> 00:40:04.790
&gt;&gt; Carla Anne Robbins:
-- thank God.

00:40:04.790 --> 00:40:06.090
&gt;&gt; James Goldgeier: Right,

00:40:06.090 --> 00:40:08.470
so we have a Pulitzer
Prize winning reporter here

00:40:08.470 --> 00:40:12.240
but we don't say that
we're going to, you know,

00:40:12.240 --> 00:40:15.550
not have this other
voice out there just

00:40:15.550 --> 00:40:19.600
because it's spewing
disinformation and isn't

00:40:19.600 --> 00:40:22.410
at the same level as
somebody like you.

00:40:22.410 --> 00:40:26.760
So, how, so both of those
voices are out there

00:40:26.760 --> 00:40:30.070
for the public to choose from.

00:40:30.070 --> 00:40:31.370
&gt;&gt; Carla Anne Robbins:
Are you saying

00:40:31.370 --> 00:40:32.670
that Anisa is more
persuasive than I am?

00:40:32.670 --> 00:40:34.370
&gt;&gt; James Goldgeier: I didn't
say Anisa was more persuasive

00:40:34.370 --> 00:40:38.610
than you are, but what do you
do in that type of a situation?

00:40:38.610 --> 00:40:41.120
&gt;&gt; Carla Anne Robbins: This
is why it's asymmetric warfare

00:40:41.120 --> 00:40:43.250
and that's, you know,
there's no question

00:40:43.250 --> 00:40:48.480
that free societies are
soft targets for and one

00:40:48.480 --> 00:40:51.470
of the things, listen, Putin
has got a lot of problems

00:40:51.470 --> 00:40:55.790
and that's one of the reasons
why he's chosen to do this

00:40:55.790 --> 00:40:58.590
but they got something
that we didn't figure out.

00:40:58.590 --> 00:41:01.810
They saw our vulnerability
and they saw that there are,

00:41:01.810 --> 00:41:03.890
that there's a fundamental
frustration

00:41:03.890 --> 00:41:06.900
in developed societies
that they're tapping into.

00:41:06.900 --> 00:41:10.460
If there were not more basic
political problems going

00:41:10.460 --> 00:41:12.280
on this wouldn't
be so persuasive.

00:41:12.280 --> 00:41:15.330
I mean we have to think
about this in greater terms.

00:41:15.330 --> 00:41:20.640
This isn't just if we shut
this down this would go away.

00:41:20.640 --> 00:41:22.330
There is something
else that we, you know,

00:41:22.330 --> 00:41:28.530
to be slightly more optimistic
here Thomas pointed out that we

00:41:28.530 --> 00:41:33.770
in the press were much like
the 4-year olds play soccer.

00:41:33.770 --> 00:41:37.920
Everybody raced after the
ball during the 2016 election

00:41:37.920 --> 00:41:41.920
and didn't say, gee, hmm,

00:41:41.920 --> 00:41:46.580
the hacking story itself was
far less an interesting story

00:41:46.580 --> 00:41:48.440
than what was in
Hilary's emails.

00:41:48.440 --> 00:41:53.830
It was only later that we
all got a little bit smarter

00:41:53.830 --> 00:41:55.800
about this.

00:41:55.800 --> 00:41:59.510
I believe I think there's
actually quite persuasive proof

00:41:59.510 --> 00:42:02.880
that we are capable of learning.

00:42:02.880 --> 00:42:04.980
The French elections
we talked about this

00:42:04.980 --> 00:42:08.450
in passing the French took a
look at what happened with us

00:42:08.450 --> 00:42:12.350
and when they dumped those
9 gigs of information

00:42:12.350 --> 00:42:16.160
from [inaudible] hacking
now granted they had a black

00:42:16.160 --> 00:42:19.070
out period and we can talk about
there being forensic research

00:42:19.070 --> 00:42:21.520
of a variety of things that went
on there, but there was more

00:42:21.520 --> 00:42:23.130
of an awareness there.

00:42:23.130 --> 00:42:26.290
There's an entire fact-checking
process that's going

00:42:26.290 --> 00:42:29.340
on that went on in the
Brazilian elections,

00:42:29.340 --> 00:42:32.080
a fact-checking process
in finance that goes

00:42:32.080 --> 00:42:34.660
out of the Shorenstein
Center at Harvard.

00:42:34.660 --> 00:42:38.760
There's an attempt here
in the press at least,

00:42:38.760 --> 00:42:42.100
in the American press and
in the press around world,

00:42:42.100 --> 00:42:45.360
to try not to make
that same mistake.

00:42:45.360 --> 00:42:50.940
If Thomas is right that the real
problem in 2016 was not Facebook

00:42:50.940 --> 00:42:53.970
and Twitter and I'm not saying
that he was right or wrong

00:42:53.970 --> 00:42:57.640
on this, the real problem
was that the press all raced

00:42:57.640 --> 00:43:01.600
to that one story itself
I think we're smarter

00:43:01.600 --> 00:43:03.960
and I think we have more
self-awareness on it,

00:43:03.960 --> 00:43:05.390
but I think we have
to be vigilant.

00:43:05.390 --> 00:43:07.950
Editors have to be vigilant,
reports have to be vigilant

00:43:07.950 --> 00:43:11.500
and we have to learn, we have
to be aware of these things.

00:43:11.500 --> 00:43:13.030
I know Thomas is not
going to agree with me.

00:43:13.030 --> 00:43:16.360
He doesn't think we're capable
of learning, but I would argue,

00:43:16.360 --> 00:43:18.610
I would argue that we
are more self-aware

00:43:18.610 --> 00:43:20.480
and there's certainly
a huge effort

00:43:20.480 --> 00:43:23.890
across the journalism community
not just in this country

00:43:23.890 --> 00:43:27.980
by across the world
to use a variety

00:43:27.980 --> 00:43:32.810
of tools including crowd sourced
information to do fact-checking

00:43:32.810 --> 00:43:34.710
and make sure this
stuff doesn't take off.

00:43:34.710 --> 00:43:37.830
Now, does that mean that
people are not going to believe

00:43:37.830 --> 00:43:39.170
in their Facebook feed?

00:43:39.170 --> 00:43:41.660
That the Pope endorsed
Donald Trump?

00:43:41.660 --> 00:43:43.910
There will be people
who believe that,

00:43:43.910 --> 00:43:48.110
but I think that next time
something is hacked we're not

00:43:48.110 --> 00:43:51.690
going to behave like 4 year olds
going after the soccer ball.

00:43:51.690 --> 00:43:53.130
&gt;&gt; Thomas Rid: Can
I respond to this?

00:43:53.130 --> 00:43:54.430
&gt;&gt; Carla Anne Robbins: Sure.

00:43:54.430 --> 00:43:55.730
&gt;&gt; James Goldgeier: Please.

00:43:55.730 --> 00:43:57.670
&gt;&gt; Thomas Rid: I
mean I do believe

00:43:57.670 --> 00:43:59.440
that we are capable of learning.

00:43:59.440 --> 00:44:03.180
After all I'm, my business is
teaching so to a degree I have

00:44:03.180 --> 00:44:05.670
to believe in learning.

00:44:05.670 --> 00:44:07.070
&gt;&gt; Carla Anne Robbins: I
meant we as journalists.

00:44:07.070 --> 00:44:09.990
&gt;&gt; Thomas Rid: Oh, still
I even teach journalists.

00:44:09.990 --> 00:44:13.360
So the, but the problem
is a little more complex

00:44:13.360 --> 00:44:16.420
than that obviously
because have you,

00:44:16.420 --> 00:44:18.080
and this is a genuine question,

00:44:18.080 --> 00:44:22.810
have we see that [inaudible]
moment in American journalism,

00:44:22.810 --> 00:44:25.240
you know, that is
comparable to what happened

00:44:25.240 --> 00:44:27.900
after the Iraq invasion?

00:44:27.900 --> 00:44:30.780
What I see is and saw

00:44:30.780 --> 00:44:35.700
to an extent still see is
a really impressive amount

00:44:35.700 --> 00:44:39.880
of self-righteousness in
covering Facebook and Twitter,

00:44:39.880 --> 00:44:42.730
Facebook more than
Twitter for reasons

00:44:42.730 --> 00:44:44.560
that I really don't understand.

00:44:44.560 --> 00:44:46.850
Pointing the finger at
social media companies

00:44:46.850 --> 00:44:49.230
with a certain feel good
attitude behind the off the

00:44:49.230 --> 00:44:51.910
record phase of the conversation
I feel I can make it a little

00:44:51.910 --> 00:44:53.210
more lively.

00:44:53.210 --> 00:44:54.510
&gt;&gt; Carla Anne Robbins:
We're actually not

00:44:54.510 --> 00:44:55.810
yet in the off the record
phase but please go on.

00:44:55.810 --> 00:44:57.110
[Laughter]

00:44:57.110 --> 00:44:58.410
&gt;&gt; Thomas Rid: Fair enough.

00:44:58.410 --> 00:44:59.710
&gt;&gt; Carla Anne Robbins: As if
anything can be off the record

00:44:59.710 --> 00:45:01.050
with 150 people in the
room, but please do go on.

00:45:01.050 --> 00:45:02.350
&gt;&gt; Thomas Rid: As in not

00:45:02.350 --> 00:45:04.350
on the website later
on, but fair enough.

00:45:04.350 --> 00:45:07.980
So, I mean the point
is that, you know,

00:45:07.980 --> 00:45:14.740
take the Podesta leaks everyday
of October 2016 we had one,

00:45:14.740 --> 00:45:17.320
you know, we had one leak coming
out actually a little more

00:45:17.320 --> 00:45:22.570
than one per day and it was
just exasperating to watch how

00:45:22.570 --> 00:45:27.520
like Pavlov's dogs, you know,
conditioned to follow the stick.

00:45:27.520 --> 00:45:29.480
At that level it was
not a secret anymore

00:45:29.480 --> 00:45:32.390
that influence operation was
underway of major proportions.

00:45:32.390 --> 00:45:34.530
That was really depressing
to watch, but I didn't want

00:45:34.530 --> 00:45:38.140
to relitigate the past.

00:45:38.140 --> 00:45:44.080
&gt;&gt; Carla Anne Robbins: Okay, I
believe and I think if you look

00:45:44.080 --> 00:45:47.530
at the fact-checking exercises
that have been set up,

00:45:47.530 --> 00:45:49.340
which have been done
with consortiums

00:45:49.340 --> 00:45:53.520
of newspapers this is,
I'm not going to comment

00:45:53.520 --> 00:45:55.730
on the self-righteousness
of journalists

00:45:55.730 --> 00:46:00.060
versus the self-righteousness
of academics given the fact

00:46:00.060 --> 00:46:05.810
that I'm both, but certainly
if you look at the effort

00:46:05.810 --> 00:46:08.110
that has been made in
subsequent elections

00:46:08.110 --> 00:46:13.620
to do fact-checking exercises
certainly there is a very strong

00:46:13.620 --> 00:46:16.220
sense of awareness of the
dangers that are out there

00:46:16.220 --> 00:46:17.820
and the desire not to fall

00:46:17.820 --> 00:46:20.900
into a trap whether there has
been a transcendent mea culpa

00:46:20.900 --> 00:46:25.350
moment of the level that you
want the media is not one

00:46:25.350 --> 00:46:26.650
big blob.

00:46:26.650 --> 00:46:28.880
There's many different news
organizations but I would say

00:46:28.880 --> 00:46:31.990
that these fact checking
exercises shows and awareness

00:46:31.990 --> 00:46:34.870
that they, that we don't
want to get fooled again.

00:46:34.870 --> 00:46:37.530
&gt;&gt; Thomas Rid: Agreeing is
boring for the audience.

00:46:37.530 --> 00:46:40.020
&gt;&gt; James Goldgeier: I have one
question for Alina following

00:46:40.020 --> 00:46:43.040
up on her presentation and
then we're going to open it up.

00:46:43.040 --> 00:46:44.710
We're going to turn
off the cameras

00:46:44.710 --> 00:46:46.830
and we'll get your questions.

00:46:46.830 --> 00:46:51.210
So you mentioned the need
to update the AI strategy

00:46:51.210 --> 00:46:57.870
and incorporating that into the
next NDAA and I'm just wondering

00:46:57.870 --> 00:47:00.620
if you could just say a couple
of words about the types

00:47:00.620 --> 00:47:04.000
of things you think need
to be done in that regard?

00:47:04.000 --> 00:47:06.100
&gt;&gt; Alina Polyankova: I did
forget to mention one thing

00:47:06.100 --> 00:47:07.970
that I think is worth
thinking about.

00:47:07.970 --> 00:47:10.680
I mentioned the online
advertising industry

00:47:10.680 --> 00:47:13.360
which is now basically
the wild, wild west.

00:47:13.360 --> 00:47:15.240
It's completely unregulated.

00:47:15.240 --> 00:47:18.120
One reason for that is
because social media

00:47:18.120 --> 00:47:21.030
in the private sector space
has been completely unregulated

00:47:21.030 --> 00:47:25.720
as well reminds me of
the days of tobacco.

00:47:25.720 --> 00:47:28.200
This is going to be a
controversial example comparing

00:47:28.200 --> 00:47:33.270
Facebook, Twitter and Google
to big tobacco in the 1950s,

00:47:33.270 --> 00:47:35.280
but I think what we're
talking about at the end

00:47:35.280 --> 00:47:39.220
of the day is how do you affect
behavioral change among people?

00:47:39.220 --> 00:47:42.110
And it is possible
through a combination

00:47:42.110 --> 00:47:46.760
of regulation civil
society activism,

00:47:46.760 --> 00:47:50.090
new institutions being
built and awareness raising.

00:47:50.090 --> 00:47:52.420
So you know how do
we go from 1950s

00:47:52.420 --> 00:47:55.310
when big tobacco was also
completely unregulated

00:47:55.310 --> 00:47:57.990
completely and, in
fact, you know,

00:47:57.990 --> 00:47:59.870
pregnant women are recommended

00:47:59.870 --> 00:48:04.040
that they should smoke
for smooth delivery.

00:48:04.040 --> 00:48:06.800
So how did we go from that

00:48:06.800 --> 00:48:09.610
to smoking essentially
being outlawed?

00:48:09.610 --> 00:48:11.650
I mean essentially illegal

00:48:11.650 --> 00:48:13.330
in the United States
and most places.

00:48:13.330 --> 00:48:17.070
We took a combination
of Congressional action

00:48:17.070 --> 00:48:21.830
to a combination of messages
coming from trusted sources,

00:48:21.830 --> 00:48:26.890
which is again goes back to
this question of the key crux

00:48:26.890 --> 00:48:29.700
of our democratic
institutions are norms

00:48:29.700 --> 00:48:32.240
and if you don't
have a trusted source

00:48:32.240 --> 00:48:34.100
and the Surgeon General
was a trusted source

00:48:34.100 --> 00:48:38.920
in the tobacco example, how
can you actually get people

00:48:38.920 --> 00:48:40.440
to believe anything?

00:48:40.440 --> 00:48:45.550
And that's why the attacks we've
all been describing have been

00:48:45.550 --> 00:48:47.150
targeting this one
specific area.

00:48:47.150 --> 00:48:48.960
And, of course, it took a lot

00:48:48.960 --> 00:48:51.960
of public awareness
campaigns and lots of money.

00:48:51.960 --> 00:48:53.630
At the end of the day
things like labeling

00:48:53.630 --> 00:48:55.600
on cigarettes also didn't
work just like labeling

00:48:55.600 --> 00:48:59.530
on certain content on
social media doesn't work.

00:48:59.530 --> 00:49:02.910
In fact, Facebook
did a quick beta test

00:49:02.910 --> 00:49:04.390
of labeling disputed content

00:49:04.390 --> 00:49:07.540
and guess what people
clicked on it more.

00:49:07.540 --> 00:49:12.020
Right? Because we human
psychology makes us want to look

00:49:12.020 --> 00:49:17.090
at train wrecks and it makes us
want to look at that, you know,

00:49:17.090 --> 00:49:20.270
hidden, dirty, sexy stuff,
you know, we're not supposed

00:49:20.270 --> 00:49:23.350
to be looking at and some things
[inaudible] bad I don't want

00:49:23.350 --> 00:49:24.650
to look at it.

00:49:24.650 --> 00:49:29.160
So I think the question to
all of us is how do you get,

00:49:29.160 --> 00:49:33.720
how do you think about messaging
some reason reject automatically

00:49:33.720 --> 00:49:35.830
because people don't
respond well.

00:49:35.830 --> 00:49:39.810
They have a strongly held belief
and you present them with facts

00:49:39.810 --> 00:49:44.480
that counter that belief
it doesn't actually matter.

00:49:44.480 --> 00:49:46.810
People actually double down
in their belief, right?

00:49:46.810 --> 00:49:49.100
And there's a lot of
social psychology research

00:49:49.100 --> 00:49:50.400
that shows this.

00:49:50.400 --> 00:49:51.870
I think we're still having
this conversation I'm talking

00:49:51.870 --> 00:49:53.330
about the wars of yester year.

00:49:53.330 --> 00:49:56.110
So the wars of the future which
is what you actually asked me

00:49:56.110 --> 00:49:59.880
about and AI issues,
you know, one,

00:49:59.880 --> 00:50:02.190
a lot of this work is happening
in the classified space

00:50:02.190 --> 00:50:03.490
and we don't know about it.

00:50:03.490 --> 00:50:06.340
At least I don't know
about it, and I accept

00:50:06.340 --> 00:50:08.750
that so there may
be things happening.

00:50:08.750 --> 00:50:11.760
My sense is that most of what's
probably happening has a very

00:50:11.760 --> 00:50:14.820
clear military dimensions
about swarm technology

00:50:14.820 --> 00:50:18.360
and [inaudible] technologies
and things like that.

00:50:18.360 --> 00:50:22.420
We need to understand
what is the range

00:50:22.420 --> 00:50:24.960
of US government
research and development

00:50:24.960 --> 00:50:27.220
and artificial intelligence

00:50:27.220 --> 00:50:29.390
across all the agencies
not just DoD?

00:50:29.390 --> 00:50:32.980
Can we have a classified
assessment of that?

00:50:32.980 --> 00:50:34.590
It has to be classified.

00:50:34.590 --> 00:50:37.200
Where are we investing?

00:50:37.200 --> 00:50:39.810
And if there is an
attack of this nature,

00:50:39.810 --> 00:50:42.000
they utilize these
new technologies

00:50:42.000 --> 00:50:46.080
like [inaudible] generated
out of serial networks,

00:50:46.080 --> 00:50:50.250
which is what produces these
deep [inaudible] how do we set

00:50:50.250 --> 00:50:52.920
up a system of metrics
to respond?

00:50:52.920 --> 00:50:55.050
We don't have processes
or mechanisms,

00:50:55.050 --> 00:50:56.850
there's no inner agency
process that I know

00:50:56.850 --> 00:51:01.140
about that would get the
US government to turn

00:51:01.140 --> 00:51:04.180
on when there's a response
needed or not to respond

00:51:04.180 --> 00:51:06.240
when there's no response
needed, right?

00:51:06.240 --> 00:51:09.030
So we need to be thinking
about resources, about,

00:51:09.030 --> 00:51:11.470
I'm just thinking
implications not

00:51:11.470 --> 00:51:14.670
in just the military space
public diplomacy, for example,

00:51:14.670 --> 00:51:18.410
absolutely critical,
State Department, DHS,

00:51:18.410 --> 00:51:21.660
we have the capacity and the
tools but we're not thinking

00:51:21.660 --> 00:51:25.890
about the next piece and that's
really what I'm talking about.

00:51:25.890 --> 00:51:27.190
I'm talking about
the implications

00:51:27.190 --> 00:51:28.490
of artificial intelligence.

00:51:28.490 --> 00:51:31.130
It's not just about the
shifts in our economy

00:51:31.130 --> 00:51:33.800
and what jobs will be lost
and jobs will be gained,

00:51:33.800 --> 00:51:35.530
these are [inaudible]
technologies at the end

00:51:35.530 --> 00:51:38.510
of the day and they can be
used for good and evil just

00:51:38.510 --> 00:51:40.560
like Facebook or
Twitter as we found out.

00:51:40.560 --> 00:51:41.860
&gt;&gt; James Goldgeier:
Great, thanks.

00:51:41.860 --> 00:51:43.540
Well, I do want to open
it up and so we'll move

00:51:43.540 --> 00:51:47.760
on to the unrecorded
part of this session

00:51:47.760 --> 00:51:49.950
so that you can ask
whatever questions.

