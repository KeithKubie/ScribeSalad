WEBVTT
Kind: captions
Language: en

00:00:00.190 --> 00:00:02.850
In this lesson I've covered distributed shared memory

00:00:02.850 --> 00:00:06.200
and particularly I've given you a specific example

00:00:06.200 --> 00:00:09.640
of a distributed shared memory system called Treadmarks

00:00:09.640 --> 00:00:13.420
that uses lazy release consistency and multiple writer

00:00:13.420 --> 00:00:15.580
coherence. I just want to leave you with

00:00:15.580 --> 00:00:19.550
some thoughts about non-page based DSM systems before

00:00:19.550 --> 00:00:22.742
concluding this lesson. There have been systems that

00:00:22.742 --> 00:00:25.370
have been built that do not use granularity

00:00:25.370 --> 00:00:28.120
of a page for coherence maintenance. I

00:00:28.120 --> 00:00:31.040
mentioned earlier that if you want to maintain

00:00:31.040 --> 00:00:34.920
granularity not at the page level, then you

00:00:34.920 --> 00:00:39.280
have to track individual reads and writes that

00:00:39.280 --> 00:00:43.750
is happening on a thread. So one approach is what is called a library based

00:00:43.750 --> 00:00:46.880
approach. Here the idea is that, the programming

00:00:46.880 --> 00:00:50.400
framework, the programming library, is going to give

00:00:50.400 --> 00:00:54.190
you a way by which you can annotate

00:00:54.190 --> 00:00:56.130
shared variables that you're going to use in your

00:00:56.130 --> 00:01:01.000
program. Whenever you touch a shared variable part of

00:01:01.000 --> 00:01:04.470
creating the executable is to cause a trap at

00:01:04.470 --> 00:01:07.120
the point of access to the shared variable

00:01:07.120 --> 00:01:10.480
so that the DSM software will be contacted, and

00:01:10.480 --> 00:01:13.620
the DSM software can then take the coherence action

00:01:13.620 --> 00:01:16.210
at the point of access to that shared variable.

00:01:16.210 --> 00:01:18.320
So, in this case, there is no operating

00:01:18.320 --> 00:01:22.690
system support needed because in the binary itself

00:01:22.690 --> 00:01:28.760
we are making sure that at the point of access we're going to result in a trap

00:01:28.760 --> 00:01:33.420
that will get us into the trap handler that is part of DSM software so that it

00:01:33.420 --> 00:01:36.510
can take the coherence actions. And examples of

00:01:36.510 --> 00:01:41.320
systems that use this mechanism include Shasta, that was

00:01:41.320 --> 00:01:45.490
done at Digital Equipment Corporation, and Beehive which

00:01:45.490 --> 00:01:48.170
was done at Georgia Tech. And because we

00:01:48.170 --> 00:01:51.300
are doing this sharing at the level of

00:01:51.300 --> 00:01:54.440
variables, you don't have any fault sharing which

00:01:54.440 --> 00:01:57.396
is possible with page based systems and single

00:01:57.396 --> 00:02:00.490
write or cache coherence protocol. So once the

00:02:00.490 --> 00:02:03.190
DSM software takes the coherence action, which might

00:02:03.190 --> 00:02:06.350
include fetching the data that is associated with the

00:02:06.350 --> 00:02:08.610
variable you are trying to access, then the

00:02:08.610 --> 00:02:12.120
DSM software can resume this thread that caused

00:02:12.120 --> 00:02:14.770
this trap in the first place. Another approach

00:02:14.770 --> 00:02:19.820
to providing shared abstractions is not at the level

00:02:19.820 --> 00:02:23.110
of memory locations, but at the level of

00:02:23.110 --> 00:02:26.560
structures that are meaningful for an application. And,

00:02:26.560 --> 00:02:28.750
this is what is called structured DSM. So,

00:02:28.750 --> 00:02:31.910
the idea is that there is a programming library

00:02:31.910 --> 00:02:35.240
which actually provides abstractions that can be

00:02:35.240 --> 00:02:38.200
manipulated in an application program. And the

00:02:38.200 --> 00:02:41.840
abstractions can be manipulated using API calls

00:02:41.840 --> 00:02:44.140
that are part of the language runtime. So

00:02:44.140 --> 00:02:47.960
when the application makes the API call,

00:02:47.960 --> 00:02:51.040
at that point, when an application makes those

00:02:51.040 --> 00:02:53.890
API calls that point, the language runtime

00:02:53.890 --> 00:02:57.120
gets into gear and says what coherence actions

00:02:57.120 --> 00:03:00.540
do I need to make in order to satisfy

00:03:00.540 --> 00:03:04.150
this API call. All of those coherence actions are going

00:03:04.150 --> 00:03:06.450
to be taken at the point of that API

00:03:06.450 --> 00:03:09.530
call, and that might include fetching data from a remote

00:03:09.530 --> 00:03:12.553
node in the cluster. And once the semantics of

00:03:12.553 --> 00:03:16.130
that API call have been executed by the language runtime,

00:03:16.130 --> 00:03:19.050
then it's going to resume this thread that made

00:03:19.050 --> 00:03:22.180
the call in the first place. Again, there is no

00:03:22.180 --> 00:03:28.175
OS support needed for this. And the structured DSM is a very popular approach

00:03:28.175 --> 00:03:33.310
that has been used in systems such as Linda, Orca, and Stampede that was done at

00:03:33.310 --> 00:03:36.410
Georgia Tech, and successors to Stampede called

00:03:36.410 --> 00:03:40.420
Stampede RT and, and PTS. And in this

00:03:40.420 --> 00:03:43.280
course later on, we're going to see PTS

00:03:43.280 --> 00:03:46.120
as an example of a structured DSM system.

