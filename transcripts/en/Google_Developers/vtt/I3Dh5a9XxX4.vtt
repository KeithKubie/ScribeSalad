WEBVTT
Kind: captions
Language: en

00:00:06.010 --> 00:00:08.940
ALON LEVI: Hi, everyone.

00:00:08.940 --> 00:00:10.930
Hello.

00:00:10.930 --> 00:00:12.380
Thanks for coming.

00:00:12.380 --> 00:00:15.280
We're here to talk about
orchestrating Google Compute

00:00:15.280 --> 00:00:17.250
Engine through Google
App Engine.

00:00:17.250 --> 00:00:18.460
My name is Alon Levi.

00:00:18.460 --> 00:00:20.930
I'm a tech lead and manager
for Google App Engine.

00:00:20.930 --> 00:00:23.620
And this is Adam Eijdenberg,
product manager for Google

00:00:23.620 --> 00:00:24.650
Compute Engine.

00:00:24.650 --> 00:00:29.276
And today we're going to talk
about orchestrating Compute

00:00:29.276 --> 00:00:31.450
Engine through App Engine, but
more generally how to use

00:00:31.450 --> 00:00:34.630
Compute Engine and App
Engine together.

00:00:34.630 --> 00:00:37.760
And so let's get started.

00:00:37.760 --> 00:00:40.650
So first off, some of you ask
yourselves, why should I care?

00:00:40.650 --> 00:00:43.860
Why is it useful to use these
two systems together?

00:00:43.860 --> 00:00:46.020
So quick show of hands, how
many of you have used App

00:00:46.020 --> 00:00:47.940
Engine already?

00:00:47.940 --> 00:00:48.400
OK.

00:00:48.400 --> 00:00:49.650
So wow, a lot of people.

00:00:49.650 --> 00:00:50.770
That's awesome.

00:00:50.770 --> 00:00:52.480
So you guys are already aware
App Engine's been

00:00:52.480 --> 00:00:53.990
around for a while.

00:00:53.990 --> 00:00:57.750
It provides a very specialized
optimized container for

00:00:57.750 --> 00:01:01.250
running applications where we
take care of all of the

00:01:01.250 --> 00:01:03.850
details of scaling and managing
your resources, and

00:01:03.850 --> 00:01:06.790
you focus on your application
code.

00:01:06.790 --> 00:01:09.460
But over the past couple of
years, we've talked to a lot

00:01:09.460 --> 00:01:10.080
of our customers.

00:01:10.080 --> 00:01:12.210
And they've told us that
sometimes they run into things

00:01:12.210 --> 00:01:13.760
they just can't do
on App Engine.

00:01:13.760 --> 00:01:15.790
Maybe they want to run a
language that's not supported

00:01:15.790 --> 00:01:18.470
or they want to run a piece of
third party code that they've

00:01:18.470 --> 00:01:21.440
either written or picked
up through open source.

00:01:21.440 --> 00:01:24.640
And there's no way to do that
in App Engine today.

00:01:24.640 --> 00:01:26.070
So that's one reason
why you might

00:01:26.070 --> 00:01:27.730
want to use them together.

00:01:27.730 --> 00:01:30.240
How many of you run an
Infrastructure as a Service

00:01:30.240 --> 00:01:33.760
solution or VM, something
like that?

00:01:33.760 --> 00:01:34.160
All right.

00:01:34.160 --> 00:01:36.660
So less people, but
still a good show.

00:01:36.660 --> 00:01:39.460
So on the other hand, for
those of you who are

00:01:39.460 --> 00:01:43.100
comfortable working with your
own infrastructure solutions,

00:01:43.100 --> 00:01:45.390
there are some things as part
of your infrastructure

00:01:45.390 --> 00:01:48.690
solution you may want to break
out and run in a platform so

00:01:48.690 --> 00:01:50.630
that you don't have to
manage or maintain.

00:01:50.630 --> 00:01:51.880
And so that's another
really good reason.

00:01:51.880 --> 00:01:53.660
And so we're going to try to
touch on those as well as a

00:01:53.660 --> 00:01:55.710
variety of other reasons.

00:01:55.710 --> 00:01:58.150
So App Engine and Compute
Engine, let's talk about what

00:01:58.150 --> 00:02:00.240
they have in common.

00:02:00.240 --> 00:02:05.390
So they're both compute
containers.

00:02:05.390 --> 00:02:07.840
You write your code and you
push them to our product.

00:02:07.840 --> 00:02:11.540
And then we manage
the machines.

00:02:11.540 --> 00:02:13.000
So App Engine is platform.

00:02:13.000 --> 00:02:14.790
Compute Engine is
infrastructure.

00:02:14.790 --> 00:02:17.430
They're sort of two different
level of abstractions that are

00:02:17.430 --> 00:02:19.630
best suited for different
types of tasks.

00:02:19.630 --> 00:02:21.900
App Engine is very specialized,
where Compute

00:02:21.900 --> 00:02:23.790
Engine is very flexible.

00:02:23.790 --> 00:02:25.460
And so to get the most value,
you're going to want to use

00:02:25.460 --> 00:02:27.510
them together.

00:02:27.510 --> 00:02:29.850
We plan to show you when you
might want to use both and

00:02:29.850 --> 00:02:32.150
show you some patterns of how
to wire them together.

00:02:32.150 --> 00:02:34.180
But first, let's talk about
what they have in common.

00:02:34.180 --> 00:02:37.280
So obviously you guys are here
at Google I/O. They're both

00:02:37.280 --> 00:02:40.870
offered by Google in the same
way that you're used to using

00:02:40.870 --> 00:02:44.150
many of Google's
other services.

00:02:44.150 --> 00:02:45.860
They run inside Google's
data centers.

00:02:45.860 --> 00:02:47.820
And they give you the
scalability and power that

00:02:47.820 --> 00:02:48.830
you're used to getting.

00:02:48.830 --> 00:02:49.970
They're offered as a service.

00:02:49.970 --> 00:02:50.890
You go to the website.

00:02:50.890 --> 00:02:51.590
You click a button.

00:02:51.590 --> 00:02:52.960
You've got your resources.

00:02:52.960 --> 00:02:55.570
And you're ready to go.

00:02:55.570 --> 00:02:56.730
Google's data centers.

00:02:56.730 --> 00:02:59.750
Google runs a state of the art,
efficient, secure network

00:02:59.750 --> 00:03:02.650
of data centers that
is awesome.

00:03:02.650 --> 00:03:04.380
By running your apps there, you
can take advantage of what

00:03:04.380 --> 00:03:07.760
we've built and integrated on
for our own purposes and our

00:03:07.760 --> 00:03:11.200
own products, such as Gmail,
Calendar, et cetera.

00:03:11.200 --> 00:03:14.290
But I'm not going to get into
all of the details.

00:03:14.290 --> 00:03:16.930
But if you're interested, you
can check out that link and

00:03:16.930 --> 00:03:19.850
read about them for yourself.

00:03:19.850 --> 00:03:21.070
Google App Engine.

00:03:21.070 --> 00:03:23.350
Platform as a Service.

00:03:23.350 --> 00:03:25.380
Easy to write, simple to
scale, and trivial to

00:03:25.380 --> 00:03:28.440
maintain, App Engine gives you
a specialized optimized

00:03:28.440 --> 00:03:31.140
container for running certain
workloads incredibly well

00:03:31.140 --> 00:03:33.000
where you don't have to worry
about anything except for the

00:03:33.000 --> 00:03:35.590
logic and the system that
you have to build.

00:03:35.590 --> 00:03:36.380
It's fully managed.

00:03:36.380 --> 00:03:37.980
There are no machines
to administer.

00:03:37.980 --> 00:03:40.160
And it's auto-scalable, meaning
it'll turn on more

00:03:40.160 --> 00:03:41.450
resources as you need them.

00:03:41.450 --> 00:03:44.300
And it'll turn them down
when you don't.

00:03:44.300 --> 00:03:45.370
Fully integrated also.

00:03:45.370 --> 00:03:48.230
So it means you've got a variety
of services and tools

00:03:48.230 --> 00:03:50.970
that are available and just
there for you to use.

00:03:50.970 --> 00:03:54.240
You make an API call, you can
access the things like the

00:03:54.240 --> 00:03:57.870
Datastore, Task Queue, Memcache,
search, a variety of

00:03:57.870 --> 00:04:00.100
other things.

00:04:00.100 --> 00:04:01.560
When is App Engine optimal?

00:04:01.560 --> 00:04:04.740
What kind of workloads
is it best for?

00:04:04.740 --> 00:04:06.460
In general, it's when you don't
want to worry about the

00:04:06.460 --> 00:04:11.100
infrastructure, when you just
want to focus on the code.

00:04:11.100 --> 00:04:13.020
Things like web UIs and
API endpoints are

00:04:13.020 --> 00:04:14.310
good examples of this.

00:04:14.310 --> 00:04:16.720
You want to make sure that your
API endpoint or your web

00:04:16.720 --> 00:04:19.980
UI is always up and running,
even if there are issues in

00:04:19.980 --> 00:04:21.850
other parts, even if you're
getting a ton of load.

00:04:21.850 --> 00:04:24.220
Maybe you haven't provisioned
enough resources, you got

00:04:24.220 --> 00:04:26.230
really popular, you want to
present your users with

00:04:26.230 --> 00:04:27.040
something--

00:04:27.040 --> 00:04:29.070
something useful, something
custom, something that you can

00:04:29.070 --> 00:04:30.950
present to them even
if the rest of the

00:04:30.950 --> 00:04:32.860
system is having issues.

00:04:32.860 --> 00:04:33.930
You just don't want to
worry about that.

00:04:33.930 --> 00:04:35.390
You want it to just work.

00:04:35.390 --> 00:04:38.590
Other types of things are
workflows, when it's really

00:04:38.590 --> 00:04:39.520
just about the logic.

00:04:39.520 --> 00:04:41.860
You want to string a bunch
of things together.

00:04:41.860 --> 00:04:43.160
You want to make sure
they work in tandem.

00:04:43.160 --> 00:04:44.720
And you want to make sure that
they get retried and the

00:04:44.720 --> 00:04:45.900
systems are up.

00:04:45.900 --> 00:04:47.970
App Engine's a great
way to do that.

00:04:47.970 --> 00:04:49.290
If you have a managed
back end, you

00:04:49.290 --> 00:04:52.070
want stateful service.

00:04:52.070 --> 00:04:55.970
And you don't need to access the
machine, but you want to

00:04:55.970 --> 00:04:58.960
make sure that it stays up.

00:04:58.960 --> 00:05:01.140
App Engine provides back ends
and you can do that there.

00:05:01.140 --> 00:05:03.750
But as I said before, App
Engine doesn't serve

00:05:03.750 --> 00:05:04.390
everybody's needs.

00:05:04.390 --> 00:05:06.840
So that's why we have
Compute Engine.

00:05:06.840 --> 00:05:08.360
Infrastructure as a Service.

00:05:08.360 --> 00:05:10.800
It's high performance,
easy scalability, and

00:05:10.800 --> 00:05:11.830
it's a great value.

00:05:11.830 --> 00:05:15.420
It gives you the ability to
reach down and actually get to

00:05:15.420 --> 00:05:20.180
the raw part of the VM and
run any code you want.

00:05:20.180 --> 00:05:23.280
So you're able to get the high
performance that you need to

00:05:23.280 --> 00:05:26.940
or run off-the-shelf components,
things like that.

00:05:26.940 --> 00:05:29.370
And so when is it optimal?

00:05:29.370 --> 00:05:31.440
In general, it's when you
need low-level access or

00:05:31.440 --> 00:05:32.670
fine-grained control.

00:05:32.670 --> 00:05:34.940
As you saw in the keynote
yesterday, it's great for

00:05:34.940 --> 00:05:37.650
large batch workloads when you
want to turn up a bunch of

00:05:37.650 --> 00:05:40.910
highly optimized processes to
just churn through a lot of

00:05:40.910 --> 00:05:45.320
work, or when you want to
fine-tune and run native code

00:05:45.320 --> 00:05:46.820
or you want to run languages
that aren't supported

00:05:46.820 --> 00:05:48.940
otherwise on App Engine.

00:05:48.940 --> 00:05:51.380
Also, if you're used to using
your favorite open source

00:05:51.380 --> 00:05:54.340
stack and you just want to do
that, you can do that with

00:05:54.340 --> 00:05:55.610
Compute Engine.

00:05:55.610 --> 00:06:00.210
So when to use them together,
sort of a summary.

00:06:00.210 --> 00:06:03.170
When you want to get unstuck
from platform; to extend the

00:06:03.170 --> 00:06:06.210
power of your App Engine app
with some high performance

00:06:06.210 --> 00:06:09.870
system that you've built, that
you want to run on Linux VMs;

00:06:09.870 --> 00:06:11.860
or to simplify your
Infrastructure as a Service

00:06:11.860 --> 00:06:15.150
systems, to sort of break out
the components that you don't

00:06:15.150 --> 00:06:15.890
want to manage.

00:06:15.890 --> 00:06:17.900
You just want them to run all
the time and then you can

00:06:17.900 --> 00:06:20.890
focus on the logic of that
system and then writing the

00:06:20.890 --> 00:06:22.560
code that goes into your VM.

00:06:22.560 --> 00:06:25.810
And so now I'm going to hand
it over to Adam, to walk

00:06:25.810 --> 00:06:27.710
through the demo that we built
and show you guys how we put

00:06:27.710 --> 00:06:28.960
these two systems together.

00:06:32.710 --> 00:06:35.120
ADAM EIJDENBERG: Thank you,
Alon, for the introduction.

00:06:35.120 --> 00:06:37.026
So yesterday, we were absolutely
thrilled to be able

00:06:37.026 --> 00:06:39.690
to finally announce Compute
Engine to you guys so that you

00:06:39.690 --> 00:06:42.580
can get out there and start
signing up for our limited

00:06:42.580 --> 00:06:46.280
preview program and
start using it.

00:06:46.280 --> 00:06:49.570
Today I'm going to walk through
an example application

00:06:49.570 --> 00:06:52.580
that we're going to build.

00:06:52.580 --> 00:06:54.240
We're going to try to exemplify
the two types of

00:06:54.240 --> 00:06:56.720
workflow that we think makes
complete sense to integrate

00:06:56.720 --> 00:06:59.320
Compute Engine with
App Engine.

00:06:59.320 --> 00:07:03.190
We're going to get unstuck from
Platform as a Service,

00:07:03.190 --> 00:07:05.610
where we need to use a native
process to do some work.

00:07:05.610 --> 00:07:07.880
And we're going to use App
Engine to orchestrate and

00:07:07.880 --> 00:07:11.430
manage the service that we have
running there as well.

00:07:11.430 --> 00:07:13.810
So the premise for the sample
app that we're going to build,

00:07:13.810 --> 00:07:16.750
we're going to build some of the
components that you might

00:07:16.750 --> 00:07:20.120
need for, say, a website that
does video sharing.

00:07:20.120 --> 00:07:24.340
And obviously there are very
many pieces that go into a

00:07:24.340 --> 00:07:26.650
site like that, but the three
pieces we're going to look at

00:07:26.650 --> 00:07:29.880
today are being able to upload
files directly from your

00:07:29.880 --> 00:07:32.320
browser into our Cloud
Storage offering.

00:07:32.320 --> 00:07:34.700
We're going to look at how you
would then process those

00:07:34.700 --> 00:07:38.560
files, maybe transcode them to
another format using a native

00:07:38.560 --> 00:07:41.130
application that we can't
run on App Engine.

00:07:41.130 --> 00:07:43.560
And then we're going to look
at how we can manage the

00:07:43.560 --> 00:07:45.960
virtual machines that are
running and use App Engine to

00:07:45.960 --> 00:07:49.280
monitor those, create new ones
as needed, and remove old ones

00:07:49.280 --> 00:07:50.530
that are no longer necessary.

00:07:53.960 --> 00:07:55.820
The basic architecture for the
application that we're going

00:07:55.820 --> 00:07:57.030
to build is as follows.

00:07:57.030 --> 00:07:58.830
We're going to have App
Engine serve the

00:07:58.830 --> 00:08:00.350
front end to our users.

00:08:00.350 --> 00:08:02.220
And that is going to be the user
interface that they use

00:08:02.220 --> 00:08:05.680
that will automatically scale
to be able to handle all of

00:08:05.680 --> 00:08:08.390
the user-facing traffic.

00:08:08.390 --> 00:08:10.950
When videos are uploaded through
that, we're going to

00:08:10.950 --> 00:08:12.820
create entries in
a task queue.

00:08:12.820 --> 00:08:15.640
And that's a pool task queue
that we can then use for our

00:08:15.640 --> 00:08:18.710
working machines to consume
tasks from that queue and then

00:08:18.710 --> 00:08:20.895
proceed to do the workload
that they need

00:08:20.895 --> 00:08:22.180
to process on there.

00:08:22.180 --> 00:08:24.340
We think one of the key parts
of our initial offering of

00:08:24.340 --> 00:08:27.760
Compute Engine is our workload
processing, to be able to use

00:08:27.760 --> 00:08:31.270
the performance and the scale
that we have there.

00:08:31.270 --> 00:08:33.309
Once we have that data, we're
going to write that back to

00:08:33.309 --> 00:08:37.169
Cloud Storage and use Cloud
Storage, our internet object

00:08:37.169 --> 00:08:41.590
store, to serve that
data back to users.

00:08:41.590 --> 00:08:44.320
So I'll switch to Alon for the
first demo, just to show the

00:08:44.320 --> 00:08:45.980
first part of this
application.

00:08:45.980 --> 00:08:48.720
And then we'll go through and
talk about some of the back

00:08:48.720 --> 00:08:51.910
end, how we set that up.

00:08:51.910 --> 00:08:55.595
So Alon, would you like to maybe
drag and drop a file,

00:08:55.595 --> 00:08:59.377
maybe those two small files,
into our application there?

00:08:59.377 --> 00:09:00.627
ALON LEVI: I'd love to.

00:09:04.850 --> 00:09:05.960
Let's try this again.

00:09:05.960 --> 00:09:08.380
Drag and drop, very difficult.

00:09:08.380 --> 00:09:08.680
ADAM EIJDENBERG: OK.

00:09:08.680 --> 00:09:11.650
While we're waiting for those to
upload, we always have that

00:09:11.650 --> 00:09:13.320
little moment where
we have a gap.

00:09:13.320 --> 00:09:15.710
And one announcement we forgot
yesterday, which was actually

00:09:15.710 --> 00:09:17.050
my mother's birthday.

00:09:17.050 --> 00:09:17.960
And I was a really bad son.

00:09:17.960 --> 00:09:19.800
I'm a long way away and we got
caught up with the Compute

00:09:19.800 --> 00:09:21.970
Engine announcement,
and I forgot that.

00:09:21.970 --> 00:09:23.250
So we've uploaded those files.

00:09:23.250 --> 00:09:26.120
Those have now come up in
the application here.

00:09:26.120 --> 00:09:28.080
The first one has uploaded.

00:09:28.080 --> 00:09:30.490
Not only has it uploaded, we
track the progress of that,

00:09:30.490 --> 00:09:32.360
it's put an entry in
the task queue.

00:09:32.360 --> 00:09:36.420
Compute Engine has processed
that and put it back on there

00:09:36.420 --> 00:09:37.520
and sent that back
to the browser

00:09:37.520 --> 00:09:39.870
through the channel API.

00:09:39.870 --> 00:09:41.570
So let's maybe go through in
a little bit of detail what

00:09:41.570 --> 00:09:42.815
happened on the back end.

00:09:42.815 --> 00:09:44.175
Want to switch back?

00:09:44.175 --> 00:09:45.425
ALON LEVI: Yes.

00:09:48.630 --> 00:09:48.850
ADAM EIJDENBERG: OK.

00:09:48.850 --> 00:09:51.500
So here's the basic workflow
that we've used here.

00:09:51.500 --> 00:09:53.910
We have the browser is the
person on the left.

00:09:53.910 --> 00:09:55.560
And they want to upload
their file.

00:09:55.560 --> 00:09:58.260
In this particular case, we're
not uploading directly into

00:09:58.260 --> 00:09:59.170
App Engine.

00:09:59.170 --> 00:10:02.340
We are doing the post directly
to Cloud Storage.

00:10:02.340 --> 00:10:05.150
So we're bypassing the entire
App Engine framework there.

00:10:05.150 --> 00:10:08.080
What we are using App Engine
for is that we're doing a

00:10:08.080 --> 00:10:11.410
request to App Engine to create
an endpoint where I can

00:10:11.410 --> 00:10:12.830
upload that file to.

00:10:12.830 --> 00:10:15.720
And we're doing that using a
self-signed policy that we'll

00:10:15.720 --> 00:10:17.930
talk about in detail in a
minute, which is a feature of

00:10:17.930 --> 00:10:20.630
Cloud Storage to allow
temporary access to a

00:10:20.630 --> 00:10:22.500
particular location
to upload a file.

00:10:26.120 --> 00:10:28.990
Once we have the endpoint, we
then create a form object.

00:10:28.990 --> 00:10:32.420
We submit to that with the
data that we have.

00:10:32.420 --> 00:10:34.820
And then we can report progress
in the web browser to

00:10:34.820 --> 00:10:37.040
show you what percentage of the
file is uploaded and what

00:10:37.040 --> 00:10:39.460
speed it's being uploaded at.

00:10:39.460 --> 00:10:42.260
And we're using some of the new
HTML5 functionality here,

00:10:42.260 --> 00:10:46.296
such as cross-origin resource
sharing, cores, and some of

00:10:46.296 --> 00:10:49.480
the permissions that are
associated with that.

00:10:49.480 --> 00:10:51.630
So going through that in some
detail, I'm going to show some

00:10:51.630 --> 00:10:52.830
code today.

00:10:52.830 --> 00:10:55.300
What we have here is some of
the JavaScript that we have

00:10:55.300 --> 00:10:56.930
running in the browser.

00:10:56.930 --> 00:10:58.960
So we have a number
of parts here.

00:10:58.960 --> 00:11:01.830
We have this startUpload
command.

00:11:01.830 --> 00:11:04.840
And here we do an Ajax call back
to our App Engine app to

00:11:04.840 --> 00:11:07.200
get this upload endpoint.

00:11:07.200 --> 00:11:10.620
We then create a FormData object
and we take all of the

00:11:10.620 --> 00:11:13.270
parameters that the App Engine
call returned to us and we

00:11:13.270 --> 00:11:15.800
pipe that into our
FormData object.

00:11:15.800 --> 00:11:19.370
We then append the file
to that as well.

00:11:19.370 --> 00:11:23.110
We create the XML HTTP request
to do the upload.

00:11:23.110 --> 00:11:25.690
We add listeners to that to
track the progress and to

00:11:25.690 --> 00:11:27.640
track when it's complete.

00:11:27.640 --> 00:11:30.870
And then we start
sending that.

00:11:30.870 --> 00:11:34.200
We're also using the
dataTransfer object and the

00:11:34.200 --> 00:11:37.570
files on the HTML5 to make that
drag and drop area where

00:11:37.570 --> 00:11:38.820
we can put that file.

00:11:41.930 --> 00:11:44.810
On the back end, I'm showing now
some platform code that is

00:11:44.810 --> 00:11:45.770
on our App Engine app.

00:11:45.770 --> 00:11:48.060
So this is where we are creating
the endpoint for

00:11:48.060 --> 00:11:49.450
uploading the file.

00:11:49.450 --> 00:11:51.690
And this is kind of the first
part before we get into

00:11:51.690 --> 00:11:54.130
Compute Engine, just getting the
files into Cloud Storage,

00:11:54.130 --> 00:11:57.320
which is a good location for
us to process these.

00:11:57.320 --> 00:11:58.880
So here we are creating
a policy.

00:11:58.880 --> 00:12:01.820
We set an expiry date that says
for the next one hour

00:12:01.820 --> 00:12:05.810
period of time, we want to allow
people to upload files

00:12:05.810 --> 00:12:07.860
to this specific URL.

00:12:07.860 --> 00:12:10.670
And this URL contains a
random UUID that we

00:12:10.670 --> 00:12:12.240
generate on the fly.

00:12:12.240 --> 00:12:15.990
That creates a policy document
that we then sign using the

00:12:15.990 --> 00:12:19.490
App Engine App Identity module
that uses the service

00:12:19.490 --> 00:12:20.610
account-- and I'll
talk more about

00:12:20.610 --> 00:12:21.600
service accounts shortly.

00:12:21.600 --> 00:12:24.080
But it uses the service account
associated with the

00:12:24.080 --> 00:12:27.050
App Engine account to sign
this policy so that Cloud

00:12:27.050 --> 00:12:29.650
Storage, which knows that the
service account has permission

00:12:29.650 --> 00:12:32.810
to write to that location, will
allow the post to succeed

00:12:32.810 --> 00:12:35.750
on the next step.

00:12:35.750 --> 00:12:39.870
Then we return that data to the
full endpoint as well as

00:12:39.870 --> 00:12:43.960
the other parameters that we
need for the front end, for

00:12:43.960 --> 00:12:45.230
the JavaScript to submit that.

00:12:48.100 --> 00:12:50.850
So once the file has finished
uploading, we then create a

00:12:50.850 --> 00:12:53.390
task queue entry.

00:12:53.390 --> 00:12:55.930
The browser sends a message back
to the App Engine app to

00:12:55.930 --> 00:12:56.990
say it's complete.

00:12:56.990 --> 00:12:59.210
We then create an entry
in the task queue.

00:13:04.530 --> 00:13:06.330
Just to give an idea of what
kind of things we're putting

00:13:06.330 --> 00:13:08.960
in that task queue, in the task
queue I'm just showing

00:13:08.960 --> 00:13:09.870
the payload data here.

00:13:09.870 --> 00:13:11.690
It's probably very hard
to read at the back.

00:13:11.690 --> 00:13:15.100
But we have a UUID, basically
the path in Cloud Storage

00:13:15.100 --> 00:13:17.050
where the file is located.

00:13:17.050 --> 00:13:20.100
And then some identification
so that when the task is

00:13:20.100 --> 00:13:23.560
complete, the worker will call
back to App Engine to tell it

00:13:23.560 --> 00:13:25.300
that it's done with some payload
there, to let us now

00:13:25.300 --> 00:13:26.740
that it's finished.

00:13:26.740 --> 00:13:31.130
So it's a very small payload.

00:13:31.130 --> 00:13:32.730
This moves to the second part.

00:13:32.730 --> 00:13:35.830
We've uploaded the files
onto our system now.

00:13:35.830 --> 00:13:38.540
And now we're looking at what
can we do once we're on the

00:13:38.540 --> 00:13:39.120
virtual machine.

00:13:39.120 --> 00:13:42.120
Let's set the virtual machines
up to process these files as

00:13:42.120 --> 00:13:45.070
they come through.

00:13:45.070 --> 00:13:49.410
We're using the Task Queue REST
API, which is a way of

00:13:49.410 --> 00:13:51.650
being able to allow an external
application outside

00:13:51.650 --> 00:13:54.630
of App Engine to be able to
access the task queue within

00:13:54.630 --> 00:13:56.020
App Engine.

00:13:56.020 --> 00:13:59.230
We use the service accounts that
are on the Compute Engine

00:13:59.230 --> 00:14:01.660
instances to automatically
authenticate

00:14:01.660 --> 00:14:03.220
back to task queue.

00:14:03.220 --> 00:14:06.830
And then we have a basic loop
that runs in a worker thread

00:14:06.830 --> 00:14:10.200
on each machine that does
one very simple thing.

00:14:10.200 --> 00:14:12.960
It polls the task queue
for new jobs.

00:14:12.960 --> 00:14:16.480
When it finds one, it requests
a lease on that job, which

00:14:16.480 --> 00:14:18.660
means that no one else
will get that job.

00:14:18.660 --> 00:14:20.420
But that lease expires
after a set period of

00:14:20.420 --> 00:14:22.910
time, say 30 seconds.

00:14:22.910 --> 00:14:25.080
It then spins off a thread
to do the actual work to

00:14:25.080 --> 00:14:26.440
process that job.

00:14:26.440 --> 00:14:27.550
And it monitors it.

00:14:27.550 --> 00:14:29.970
And if we get close to 30
seconds but the job's not

00:14:29.970 --> 00:14:32.420
finished, we then
update the task.

00:14:32.420 --> 00:14:36.570
We extend our lease so that it
doesn't expire and that we

00:14:36.570 --> 00:14:38.660
keep that job until
we're finished.

00:14:38.660 --> 00:14:43.530
If we have to terminate our
machine for some reason,

00:14:43.530 --> 00:14:46.490
another machine would
automatically pick up that

00:14:46.490 --> 00:14:49.720
task as soon as it expires.

00:14:49.720 --> 00:14:52.010
When we're complete, we
delete that task.

00:14:52.010 --> 00:14:54.470
And then we do a call back to
our App Engine app to let us

00:14:54.470 --> 00:14:56.700
know that the task
is complete.

00:14:59.750 --> 00:15:01.630
Let's go through some
of the code on that.

00:15:01.630 --> 00:15:03.720
We have a task processing
loop.

00:15:03.720 --> 00:15:05.220
We will make the slides
available afterwards.

00:15:05.220 --> 00:15:06.950
I see a lot of people
taking pictures.

00:15:06.950 --> 00:15:08.200
We will make these available.

00:15:10.730 --> 00:15:12.830
So the first part here,
we have our loop.

00:15:12.830 --> 00:15:17.510
We're requesting a lease on the
objects on the task queue.

00:15:17.510 --> 00:15:20.890
Once we find an object that's
come through, we then decode

00:15:20.890 --> 00:15:22.820
the payload that has
come with that.

00:15:22.820 --> 00:15:27.390
And we spawn a thread to
do the actual workload.

00:15:27.390 --> 00:15:30.245
We then have a loop that
attempts to join that thread

00:15:30.245 --> 00:15:32.700
and times out after a certain
period of time.

00:15:32.700 --> 00:15:36.220
If it times out and the thread
is still alive, we then extend

00:15:36.220 --> 00:15:38.770
our lease on that task queue so
that no one else gets that

00:15:38.770 --> 00:15:41.780
job until we're finished.

00:15:41.780 --> 00:15:46.110
Once we're complete, we delete
the item from the task queue.

00:15:46.110 --> 00:15:47.570
And we're done.

00:15:47.570 --> 00:15:49.750
So that's kind of the main
container thread that I think

00:15:49.750 --> 00:15:52.780
will be quite generic for a
lot of workload processing

00:15:52.780 --> 00:15:55.750
within a virtual machine.

00:15:55.750 --> 00:15:58.390
The actual specifics of what our
particular workload does

00:15:58.390 --> 00:16:02.700
in this case after we spawn that
thread, is we copy the

00:16:02.700 --> 00:16:04.320
source file from
Cloud Storage.

00:16:04.320 --> 00:16:06.410
We copy that locally.

00:16:06.410 --> 00:16:08.660
We then run a video transcoding
library.

00:16:08.660 --> 00:16:12.390
In this case, we're using FFmpeg
to convert that to a

00:16:12.390 --> 00:16:14.570
different format and a
different resolution.

00:16:14.570 --> 00:16:19.810
And then when we're finished, we
copy that file back again.

00:16:19.810 --> 00:16:23.730
So it's really quite a simple
actual workflow processing at

00:16:23.730 --> 00:16:24.980
the end of it.

00:16:26.750 --> 00:16:28.310
We have a little bit
of code here.

00:16:28.310 --> 00:16:30.710
This is probably the least
interesting part of the talk.

00:16:30.710 --> 00:16:33.980
But here is what we're actually
doing on the server

00:16:33.980 --> 00:16:35.410
after we spawn that
thread off.

00:16:35.410 --> 00:16:39.275
We're just doing a very basic
subprocess called gsutil to

00:16:39.275 --> 00:16:40.630
copy the file across.

00:16:40.630 --> 00:16:43.040
We could also do that
programmatically.

00:16:43.040 --> 00:16:45.080
But this is fairly
straightforward.

00:16:45.080 --> 00:16:47.880
We then spin off the FFmpeg
library with a whole slew of

00:16:47.880 --> 00:16:50.180
options to re-encode that.

00:16:50.180 --> 00:16:53.330
We run gsutil to send
it back again.

00:16:53.330 --> 00:16:56.300
And then finally, we change
the access control on that

00:16:56.300 --> 00:16:57.840
file to make it publicly
readable to

00:16:57.840 --> 00:16:59.090
serve through our website.

00:17:01.250 --> 00:17:03.160
And then we do some cleanup
at the end.

00:17:03.160 --> 00:17:05.260
And we do the call back to the
App Engine app just using a

00:17:05.260 --> 00:17:06.905
standard urlopen command.

00:17:09.940 --> 00:17:12.670
So let's talk a little bit about
the virtual machines.

00:17:12.670 --> 00:17:14.140
So we've written
our script now.

00:17:14.140 --> 00:17:16.510
And now we want to get it on a
virtual machine so we can test

00:17:16.510 --> 00:17:19.460
it and start playing with it
and getting it to run.

00:17:19.460 --> 00:17:21.560
So from my workstation,
I can run the

00:17:21.560 --> 00:17:25.310
gcutil addinstance command.

00:17:25.310 --> 00:17:27.530
And this is where I can spin up
a new virtual machine from

00:17:27.530 --> 00:17:29.030
my command line.

00:17:29.030 --> 00:17:31.340
I give it the zone where
I want it to create.

00:17:31.340 --> 00:17:32.550
I give it the machine type.

00:17:32.550 --> 00:17:34.510
In this case, I'm
picking 8 cores.

00:17:34.510 --> 00:17:37.250
And here I'm giving it some
service account scopes.

00:17:37.250 --> 00:17:39.240
And what that means is that
we're automatically going to

00:17:39.240 --> 00:17:42.820
provision a service account on
that machine that will have

00:17:42.820 --> 00:17:46.860
permission to apply tokens to
access task queue information

00:17:46.860 --> 00:17:49.940
and get full control over
my Cloud Storage area.

00:17:52.720 --> 00:17:54.620
After that's created, and it
doesn't take very long to

00:17:54.620 --> 00:17:59.150
create, I'm using gcutil
to SSH to that machine.

00:17:59.150 --> 00:18:01.760
And so gcutil wraps
the SSH command.

00:18:01.760 --> 00:18:05.760
It makes it very, very simple to
secure shell into a machine

00:18:05.760 --> 00:18:08.080
that you have created and not
have to worry about putting

00:18:08.080 --> 00:18:09.340
usernames and passwords in.

00:18:09.340 --> 00:18:13.400
We use a public key
system for that.

00:18:13.400 --> 00:18:15.780
So once we're on that machine,
which here is a standard

00:18:15.780 --> 00:18:20.400
Ubuntu 12 image, we can then
have full root access over

00:18:20.400 --> 00:18:21.350
that machine.

00:18:21.350 --> 00:18:23.690
So I can install any
package I like.

00:18:23.690 --> 00:18:24.640
So I'll just run sudo.

00:18:24.640 --> 00:18:26.030
I'm on the sudo list
automatically.

00:18:26.030 --> 00:18:28.600
I can install anything I like.

00:18:28.600 --> 00:18:31.830
I can then copy information
from my Cloud Storage area

00:18:31.830 --> 00:18:34.540
directly onto the machine
using gsutil.

00:18:34.540 --> 00:18:37.310
And the neat thing about this
is because we created the

00:18:37.310 --> 00:18:40.530
machine with these service
accounts, I don't have to run

00:18:40.530 --> 00:18:43.555
the gsutil configure auth
command and do the oauth dance

00:18:43.555 --> 00:18:45.620
and go to my browser and
paste things in.

00:18:45.620 --> 00:18:47.860
We've already done that
on the back end.

00:18:47.860 --> 00:18:50.750
gsutil is designed to use
that service account.

00:18:50.750 --> 00:18:55.010
So long as the bucket you're
copying from allows permission

00:18:55.010 --> 00:18:57.770
to the service account named
for this project on virtual

00:18:57.770 --> 00:19:00.890
machines, that will run without
any further work on

00:19:00.890 --> 00:19:02.140
your behalf.

00:19:04.600 --> 00:19:08.290
And then I can set the job up,
run it, debug it, and play

00:19:08.290 --> 00:19:09.540
with it as much as I like.

00:19:11.840 --> 00:19:14.305
So I just wanted to just take
a moment out and just talk a

00:19:14.305 --> 00:19:15.790
little bit about authentication
and

00:19:15.790 --> 00:19:17.110
authorization.

00:19:17.110 --> 00:19:19.570
This is something that I found
personally when I was

00:19:19.570 --> 00:19:22.670
integrating three to four of
our different products

00:19:22.670 --> 00:19:25.325
together here a little bit
daunting at first, to figure

00:19:25.325 --> 00:19:28.110
out the difference between
the various types.

00:19:28.110 --> 00:19:31.020
Essentially, we have what we
call a service account, which

00:19:31.020 --> 00:19:35.230
is basically a pretend user that
represents an application

00:19:35.230 --> 00:19:38.710
that you might want to allow to
access other resources from

00:19:38.710 --> 00:19:41.370
another project or access
another application.

00:19:41.370 --> 00:19:43.880
So it doesn't represent the
person using the software.

00:19:43.880 --> 00:19:46.085
It represents, say, I want this
set of virtual machines

00:19:46.085 --> 00:19:48.210
to be able to access
a task queue.

00:19:48.210 --> 00:19:50.670
Or I want this web application
to be able to write files to

00:19:50.670 --> 00:19:52.540
Cloud Storage.

00:19:52.540 --> 00:19:57.360
And we have really two, but it
kind of looks like three

00:19:57.360 --> 00:19:58.920
different types of
service accounts

00:19:58.920 --> 00:20:02.170
within the Google ecosystem.

00:20:02.170 --> 00:20:05.940
We have service accounts that
you can create through the

00:20:05.940 --> 00:20:10.350
developer or the administration
console API,

00:20:10.350 --> 00:20:12.560
which is where you can create
oauth tokens for installed

00:20:12.560 --> 00:20:14.030
applications or web

00:20:14.030 --> 00:20:16.320
applications or service accounts.

00:20:16.320 --> 00:20:19.270
And when you create one here,
we allocate a big long email

00:20:19.270 --> 00:20:21.450
address that's the name of
the service account.

00:20:21.450 --> 00:20:25.910
And then we give you a p12
private key to download.

00:20:25.910 --> 00:20:29.300
You have to download that file
and then you can use that

00:20:29.300 --> 00:20:31.460
anywhere, whether it's within
Google products, whether it's

00:20:31.460 --> 00:20:34.460
on your desktop, whether it's
in a different cloud

00:20:34.460 --> 00:20:35.720
infrastructure.

00:20:35.720 --> 00:20:40.790
You can use that to sign a
request to get an oauth token.

00:20:40.790 --> 00:20:41.800
But you have to manage

00:20:41.800 --> 00:20:43.080
distributing that key yourself.

00:20:43.080 --> 00:20:44.250
You have to make sure
it's secure.

00:20:44.250 --> 00:20:46.430
You have to make sure it doesn't
get lost anywhere.

00:20:46.430 --> 00:20:48.760
And you have to do a lot
of the hard work there.

00:20:48.760 --> 00:20:49.650
But it is portable.

00:20:49.650 --> 00:20:51.472
You can run it anywhere.

00:20:51.472 --> 00:20:54.420
The second types of service
accounts we have are what we

00:20:54.420 --> 00:20:56.910
call provision service accounts,
which is where

00:20:56.910 --> 00:20:59.750
within both of our code
execution units, both App

00:20:59.750 --> 00:21:03.860
Engine and within Compute
Engine, we have the ability to

00:21:03.860 --> 00:21:07.590
take care of creating
automatically a service

00:21:07.590 --> 00:21:08.940
account for you.

00:21:08.940 --> 00:21:12.660
So in App Engine, we have
the App Identity module.

00:21:12.660 --> 00:21:15.270
We have dot get_access_token.

00:21:15.270 --> 00:21:17.530
And in Compute Engine, we have
a metadata server, which I'll

00:21:17.530 --> 00:21:19.350
go through in a little bit
more detail in a minute.

00:21:19.350 --> 00:21:22.300
But these are both ways that we
will automatically create

00:21:22.300 --> 00:21:23.730
access tokens for you.

00:21:23.730 --> 00:21:27.320
We can sign blobs for you, so
that you don't have to worry

00:21:27.320 --> 00:21:29.950
about distributing those
keys yourself.

00:21:29.950 --> 00:21:32.825
The downside is, it will only
work within the container.

00:21:32.825 --> 00:21:38.730
But the positive side is, much
easier to deal with.

00:21:38.730 --> 00:21:40.590
So I just wanted to take that
little note out to talk about

00:21:40.590 --> 00:21:42.910
those two different types.

00:21:42.910 --> 00:21:44.120
They're interchangeable.

00:21:44.120 --> 00:21:46.990
Both of them will give you an
email address that you can

00:21:46.990 --> 00:21:49.280
then add to access
control lists.

00:21:49.280 --> 00:21:52.470
In our example here, we have a
queue dot yaml file, which

00:21:52.470 --> 00:21:54.530
represents the pool queue
where we are putting

00:21:54.530 --> 00:21:55.970
the video jobs into.

00:21:55.970 --> 00:21:59.290
And we had to add permission to
the Compute Engine service

00:21:59.290 --> 00:22:02.090
account to be able to read
from that queue.

00:22:02.090 --> 00:22:05.670
We have an access control list
within Cloud Storage.

00:22:05.670 --> 00:22:09.490
So I gave the App Engine account
permission to upload

00:22:09.490 --> 00:22:10.870
files into Cloud Storage.

00:22:10.870 --> 00:22:14.080
And that's why it was able
to sign that blob for the

00:22:14.080 --> 00:22:16.590
self-signed policy earlier.

00:22:16.590 --> 00:22:19.830
And we also have the ability to
add that within the teams

00:22:19.830 --> 00:22:22.630
page in the administration
console and the development

00:22:22.630 --> 00:22:26.570
console, so that in this case
the App Engine service

00:22:26.570 --> 00:22:29.080
account, I've added that as a
team member to my Compute

00:22:29.080 --> 00:22:30.230
Engine project.

00:22:30.230 --> 00:22:33.350
So the App Engine app is able to
create virtual machines and

00:22:33.350 --> 00:22:38.540
tear them down and take care
of that management for me.

00:22:38.540 --> 00:22:41.400
So I hope that helps give a
little bit of clarity on the

00:22:41.400 --> 00:22:45.790
different types of service
accounts that we have there.

00:22:45.790 --> 00:22:48.470
So let's talk in a little bit
more detail about how we

00:22:48.470 --> 00:22:52.530
authenticate from within a
Compute Engine instance.

00:22:52.530 --> 00:22:55.820
Within App Engine, we have the
get identity get access token

00:22:55.820 --> 00:22:57.220
method that we saw before.

00:22:57.220 --> 00:23:00.570
But within Compute Engine, we
have a metadata server.

00:23:00.570 --> 00:23:03.840
And on this metadata server,
this is a server that is

00:23:03.840 --> 00:23:07.230
available only to your virtual
machine; every virtual machine

00:23:07.230 --> 00:23:08.910
can access a different one.

00:23:08.910 --> 00:23:11.650
And it lets you see various bits
of information about the

00:23:11.650 --> 00:23:13.890
virtual machine that
it's within.

00:23:13.890 --> 00:23:17.200
And one of those has a
particular path you can go to

00:23:17.200 --> 00:23:20.550
that will acquire an access
token for you based on the

00:23:20.550 --> 00:23:22.970
service accounts that were
used when we created that

00:23:22.970 --> 00:23:24.590
virtual machine.

00:23:24.590 --> 00:23:26.800
And you can call that
programmatically from within

00:23:26.800 --> 00:23:28.610
any application on there.

00:23:28.610 --> 00:23:30.740
You can call it with cURL
to test it to make

00:23:30.740 --> 00:23:31.810
sure it comes out.

00:23:31.810 --> 00:23:33.970
It will take care of refreshing
that token for you.

00:23:33.970 --> 00:23:35.720
If you've used service accounts
before, you know that

00:23:35.720 --> 00:23:37.840
they'll time out after a
certain period of time.

00:23:37.840 --> 00:23:39.540
This will take care
of that for you.

00:23:39.540 --> 00:23:41.400
You can call this every
time you need a token.

00:23:41.400 --> 00:23:45.340
Just call it and it will return
a token that will work.

00:23:45.340 --> 00:23:47.000
So in our particular application
here, we're

00:23:47.000 --> 00:23:50.870
calling this from within Python,
within our task queue

00:23:50.870 --> 00:23:52.480
in the Python area.

00:23:52.480 --> 00:23:54.510
And here I'm calling it.

00:23:54.510 --> 00:23:56.890
I'm telling it I need the scope
for the task queue which

00:23:56.890 --> 00:23:58.720
matches up against the
permission I gave the virtual

00:23:58.720 --> 00:24:00.680
machine when I created it.

00:24:00.680 --> 00:24:02.600
And I'm putting that
inside of an access

00:24:02.600 --> 00:24:04.770
token credentials object.

00:24:04.770 --> 00:24:07.880
And the reason I'm doing that
is because every time I'm

00:24:07.880 --> 00:24:12.550
executing a call against that
Task Queue API, using our

00:24:12.550 --> 00:24:17.270
Python API client, I'm passing
an HTTP object based on that

00:24:17.270 --> 00:24:21.830
access credentials
that we returned.

00:24:21.830 --> 00:24:25.600
So this is a gap I omitted from
the previous slide there.

00:24:29.160 --> 00:24:31.300
Let's talk a little bit about
what happens after we've

00:24:31.300 --> 00:24:33.110
finished processing.

00:24:33.110 --> 00:24:34.530
Let's remember where we are.

00:24:34.530 --> 00:24:36.220
We've uploaded files.

00:24:36.220 --> 00:24:39.480
We've had an application run
on a virtual machine, find

00:24:39.480 --> 00:24:42.480
those files, run FFmpeg
over them, copy them

00:24:42.480 --> 00:24:44.090
back to Cloud Storage.

00:24:44.090 --> 00:24:46.990
And now we've called the call
back into the App Engine app,

00:24:46.990 --> 00:24:49.720
which has a payload, which
was passed to us

00:24:49.720 --> 00:24:50.790
as part of a queue.

00:24:50.790 --> 00:24:55.320
And that tells us what data,
what job is now complete.

00:24:55.320 --> 00:24:58.210
And the App Engine app is now
pushing that, via the Channel

00:24:58.210 --> 00:25:00.910
API, directly back to the
browser so it will pop

00:25:00.910 --> 00:25:04.770
straight up in front
of the user there.

00:25:04.770 --> 00:25:07.360
We then serve that video
directly from Cloud Storage.

00:25:07.360 --> 00:25:08.690
So we do the request straight
back to Cloud

00:25:08.690 --> 00:25:12.790
Storage to get that data.

00:25:12.790 --> 00:25:15.450
We've talked about the first
two parts that I wanted to

00:25:15.450 --> 00:25:17.360
talk about, which were
uploading files

00:25:17.360 --> 00:25:18.620
through Cloud Storage.

00:25:18.620 --> 00:25:21.620
We've talked about how to get
unstuck from our Platform as a

00:25:21.620 --> 00:25:23.670
Service if it's running
native code.

00:25:23.670 --> 00:25:25.910
And the third part that I'd like
to talk about now, which

00:25:25.910 --> 00:25:29.410
I think is really interesting,
is how we can use App Engine

00:25:29.410 --> 00:25:31.920
to actually control the virtual
machines that are

00:25:31.920 --> 00:25:34.410
created and automatically scale
and make sure we have

00:25:34.410 --> 00:25:37.720
enough virtual machines to
handle the workload that I'm

00:25:37.720 --> 00:25:38.540
being passed.

00:25:38.540 --> 00:25:40.540
App Engine already does a great
job of this for the

00:25:40.540 --> 00:25:42.850
user-facing requests.

00:25:42.850 --> 00:25:45.340
But we need to do something on
the back end to make sure the

00:25:45.340 --> 00:25:49.090
virtual machines come up
in the same fashion.

00:25:49.090 --> 00:25:50.830
So I'm going to start with
a diagram and then

00:25:50.830 --> 00:25:52.140
we'll jump to a demo.

00:25:52.140 --> 00:25:56.400
We're doing essentially two
things to facilitate this.

00:25:56.400 --> 00:25:58.940
Each virtual machine has a
heartbeat on that that is

00:25:58.940 --> 00:26:01.650
calling back to App Engine
that gives it information

00:26:01.650 --> 00:26:05.630
about the CPU utilization on
that machine, information

00:26:05.630 --> 00:26:07.640
about what throughput it
is achieving when it is

00:26:07.640 --> 00:26:11.820
converting videos, and some
other statistical information.

00:26:11.820 --> 00:26:16.360
Separately, we have a chron job
within our App Engine app

00:26:16.360 --> 00:26:20.280
that periodically calculates how
many virtual machines we

00:26:20.280 --> 00:26:22.670
think we need to process the
amount of work that we

00:26:22.670 --> 00:26:24.770
currently have outstanding.

00:26:24.770 --> 00:26:29.270
We used a very, very simplistic
algorithm for this

00:26:29.270 --> 00:26:30.870
demonstration in a minute.

00:26:30.870 --> 00:26:33.120
When we look at the throughput
that we're achieving, we look

00:26:33.120 --> 00:26:36.660
at the total number of
outstanding work in terms of

00:26:36.660 --> 00:26:39.420
gigabytes or megabytes of video
we have in the queue.

00:26:39.420 --> 00:26:41.880
And then we divide that out to
reach a target of, we want to

00:26:41.880 --> 00:26:44.690
be able to process all of our
videos, if everything was spun

00:26:44.690 --> 00:26:47.200
up, in about 30 seconds.

00:26:47.200 --> 00:26:49.290
I think there's probably far
more sophisticated queue

00:26:49.290 --> 00:26:51.570
control theory lessons we could
go into about different

00:26:51.570 --> 00:26:52.990
ways of doing the scaling.

00:26:52.990 --> 00:26:55.230
This is just a simple example
that we're going to use today.

00:26:58.400 --> 00:27:00.440
So let's switch back to
the demonstration.

00:27:06.160 --> 00:27:09.130
Here we go.

00:27:09.130 --> 00:27:10.640
I want to go the Advanced
Options.

00:27:10.640 --> 00:27:10.930
ALON LEVI: Yes.

00:27:10.930 --> 00:27:12.880
Let's go Advanced.

00:27:12.880 --> 00:27:13.460
ADAM EIJDENBERG: OK.

00:27:13.460 --> 00:27:15.220
And I'll explain what the
graph is in a minute.

00:27:15.220 --> 00:27:18.760
But just let's drag and drop
the-- oh, before you drag and

00:27:18.760 --> 00:27:21.180
drop that, maybe change that
Number of Uploads number to

00:27:21.180 --> 00:27:22.720
maybe 1,000.

00:27:22.720 --> 00:27:23.340
ALON LEVI: 1,000?

00:27:23.340 --> 00:27:23.640
ADAM EIJDENBERG: 1,000.

00:27:23.640 --> 00:27:26.020
ALON LEVI: OK.

00:27:26.020 --> 00:27:26.960
ADAM EIJDENBERG: Now
let's drag and drop

00:27:26.960 --> 00:27:28.470
that demo video there.

00:27:28.470 --> 00:27:30.770
Now the first video we uploaded
was pretty small.

00:27:30.770 --> 00:27:31.930
It was only one megabyte.

00:27:31.930 --> 00:27:32.910
This one's not huge.

00:27:32.910 --> 00:27:34.000
It's nine megabytes.

00:27:34.000 --> 00:27:35.860
And it runs for about
three minutes.

00:27:35.860 --> 00:27:38.440
But I wanted to pick one that
was slightly bigger, but not

00:27:38.440 --> 00:27:40.680
big enough to challenge the
internet connection that we

00:27:40.680 --> 00:27:42.200
might have here.

00:27:42.200 --> 00:27:45.660
And what we have on the graph
here, on the right we have

00:27:45.660 --> 00:27:46.710
three lines.

00:27:46.710 --> 00:27:50.130
The red line that we see
tracking up is the amount in

00:27:50.130 --> 00:27:51.930
gigabytes of outstanding videos

00:27:51.930 --> 00:27:54.110
that we have to process.

00:27:54.110 --> 00:27:57.000
And the axis for that is on
the right of the screen.

00:27:57.000 --> 00:27:58.970
We can see that's about
eight gigabytes

00:27:58.970 --> 00:28:01.190
of video we've uploaded.

00:28:01.190 --> 00:28:02.410
We cheated a little bit.

00:28:02.410 --> 00:28:04.430
We uploaded it once.

00:28:04.430 --> 00:28:07.720
But when I passed that parameter
of 1,000 there on

00:28:07.720 --> 00:28:11.220
the back end, the App Engine
created 1,000 entries in that

00:28:11.220 --> 00:28:15.680
task queue to each re-encode
that same video but it brought

00:28:15.680 --> 00:28:18.890
it back to a different
location every time.

00:28:18.890 --> 00:28:21.240
So the blue line, it's a little
bit difficult to see at

00:28:21.240 --> 00:28:24.390
the bottom there, but the
blue line is showing CPU

00:28:24.390 --> 00:28:29.090
utilization for 100
virtual machines.

00:28:29.090 --> 00:28:30.470
On the left, we can see
how many virtual

00:28:30.470 --> 00:28:32.410
machines we have running.

00:28:32.410 --> 00:28:35.240
The yellow line represents how
many we have running right now

00:28:35.240 --> 00:28:37.090
or have requested to run.

00:28:37.090 --> 00:28:39.130
So when we started this
demonstration, we had exactly

00:28:39.130 --> 00:28:40.960
two virtual machines running.

00:28:40.960 --> 00:28:43.690
And when we created all these
other entries in the task

00:28:43.690 --> 00:28:45.860
queue, we realized we needed a
lot more virtual machines to

00:28:45.860 --> 00:28:49.340
be able to process this data
in a quick fashion.

00:28:49.340 --> 00:28:53.130
So we decided that we needed
100 virtual machines.

00:28:53.130 --> 00:28:55.850
So it means that it quickly
jumped up to 100.

00:28:55.850 --> 00:28:58.580
They haven't started instantly,
but that's

00:28:58.580 --> 00:29:00.750
basically the point in time
where our app has decided that

00:29:00.750 --> 00:29:03.130
it needs those extra
virtual machines.

00:29:03.130 --> 00:29:06.420
So what we can see coming
up now, the blue line.

00:29:06.420 --> 00:29:10.290
The blue line is representing
the cumulative CPU utilization

00:29:10.290 --> 00:29:12.480
across all of those
virtual machines.

00:29:12.480 --> 00:29:14.850
So what that means is that when
that blue line hits the

00:29:14.850 --> 00:29:17.800
yellow line, we are 100%
spun up and we are

00:29:17.800 --> 00:29:23.000
100% processing videos.

00:29:23.000 --> 00:29:24.140
So we're doing pretty well.

00:29:24.140 --> 00:29:24.476
ALON LEVI: Yes.

00:29:24.476 --> 00:29:26.060
They're starting to come in.

00:29:26.060 --> 00:29:26.990
ADAM EIJDENBERG: So what
we'll see here--

00:29:26.990 --> 00:29:28.890
ALON LEVI: The demo
is working.

00:29:28.890 --> 00:29:30.660
ADAM EIJDENBERG: The demo is
working, which is good.

00:29:30.660 --> 00:29:33.160
What we can see on the left here
is we can see the videos

00:29:33.160 --> 00:29:34.410
coming back.

00:29:34.410 --> 00:29:38.100
What we did when we went to the
Advanced mode, we chose

00:29:38.100 --> 00:29:41.120
not to show the videos as they
returned, because then I have

00:29:41.120 --> 00:29:44.830
my web browser trying to
download 1,000 relatively

00:29:44.830 --> 00:29:47.550
sized videos in a short
order block of time.

00:29:47.550 --> 00:29:49.960
But later we can click on one of
those links just to verify

00:29:49.960 --> 00:29:52.410
it's not an elaborate hoax.

00:29:52.410 --> 00:29:53.490
So those are coming back.

00:29:53.490 --> 00:29:55.996
I kind of get excited when I see
that blue line go up and I

00:29:55.996 --> 00:30:01.710
start seeing that red line
absolutely shoot down there.

00:30:01.710 --> 00:30:04.030
So that goes pretty quickly.

00:30:04.030 --> 00:30:05.820
What I think is really
interesting, actually, is the

00:30:05.820 --> 00:30:08.550
consistency we see from
Compute Engine.

00:30:08.550 --> 00:30:11.410
If we get patient and watch
this for a few minutes, we

00:30:11.410 --> 00:30:14.000
typically see it sort of go down
and then it will flatten

00:30:14.000 --> 00:30:15.170
and then go down again.

00:30:15.170 --> 00:30:16.860
All the videos are
the same size.

00:30:16.860 --> 00:30:18.810
They all start processing
at the same time.

00:30:18.810 --> 00:30:21.780
And they all finish pretty
much at the same time.

00:30:21.780 --> 00:30:23.330
We have a little bit
of delay in there.

00:30:28.370 --> 00:30:32.190
We can see the CPU utilization
is not quite 100% anymore.

00:30:32.190 --> 00:30:33.300
That's expected.

00:30:33.300 --> 00:30:36.690
And the reason for that is we
have five threads on each of

00:30:36.690 --> 00:30:39.030
these virtual machines.

00:30:39.030 --> 00:30:40.620
They're all eight
core machines.

00:30:40.620 --> 00:30:43.930
And I've set it to begin five
worker threads on each.

00:30:43.930 --> 00:30:47.970
So 5 times 100 is 500
worker threads.

00:30:47.970 --> 00:30:50.580
And as we sort of run out of
content to process-- we only

00:30:50.580 --> 00:30:52.530
uploaded 1,000 videos.

00:30:52.530 --> 00:30:56.600
We do sort of run out of
jobs pretty quickly.

00:30:56.600 --> 00:30:58.710
And you can see we're finishing
off there quite

00:30:58.710 --> 00:31:00.960
nicely now.

00:31:00.960 --> 00:31:03.110
So Alon, maybe while we're
waiting for that to finish,

00:31:03.110 --> 00:31:05.320
can you switch to the second
tab out there?

00:31:05.320 --> 00:31:08.880
And let's maybe increase the
number of virtual machines

00:31:08.880 --> 00:31:12.130
that we can have process
to, say, 400.

00:31:12.130 --> 00:31:16.630
We'll hit Update and then maybe
go back to that tab.

00:31:16.630 --> 00:31:19.000
See, that's just
about finished.

00:31:19.000 --> 00:31:19.260
OK.

00:31:19.260 --> 00:31:22.000
Go back to the Advanced
options.

00:31:22.000 --> 00:31:24.810
Let's make the Number
of Uploads--

00:31:24.810 --> 00:31:26.930
you can see we've rescaled that
now, so the axis on the

00:31:26.930 --> 00:31:29.910
left is now showing we have the
100 virtual machines on a

00:31:29.910 --> 00:31:31.730
scale up to 400.

00:31:31.730 --> 00:31:37.540
Let's maybe upload 4,000
of those files.

00:31:37.540 --> 00:31:39.200
And that will take a few
minutes to start up.

00:31:39.200 --> 00:31:43.200
So we'll switch back to it
in about five minutes.

00:31:43.200 --> 00:31:44.670
And I'll just talk through a
little bit more of the code.

00:31:44.670 --> 00:31:48.190
Then we'll show you how
that's coming along.

00:31:48.190 --> 00:31:50.720
OK.

00:31:50.720 --> 00:31:52.750
So I'll just go through a little
bit of the detail on

00:31:52.750 --> 00:31:56.150
what's happening on each of
those virtual machines to

00:31:56.150 --> 00:31:57.660
support the scaling
part of that.

00:31:57.660 --> 00:32:01.100
We have a very simple heartbeat
script I have

00:32:01.100 --> 00:32:02.140
running on each box.

00:32:02.140 --> 00:32:04.840
And that box is simply
running mpstat every

00:32:04.840 --> 00:32:06.610
second for one second.

00:32:06.610 --> 00:32:09.490
And it is then reporting that
back to App Engine through a

00:32:09.490 --> 00:32:13.190
call back to an end point that
we pass as a parameter when we

00:32:13.190 --> 00:32:15.460
create the virtual machine.

00:32:15.460 --> 00:32:19.700
That's the call back just
spinning up there.

00:32:19.700 --> 00:32:22.060
And we have our very simplistic
code here for the

00:32:22.060 --> 00:32:24.560
scaling of the virtual
machine.

00:32:24.560 --> 00:32:27.460
In App Engine we have an entity
for each of the VM

00:32:27.460 --> 00:32:29.380
instances that is running.

00:32:29.380 --> 00:32:31.730
We then sum up all the
throughput we're

00:32:31.730 --> 00:32:33.180
seeing for each one.

00:32:33.180 --> 00:32:35.680
We then add up all of the
videos that we have

00:32:35.680 --> 00:32:36.280
outstanding.

00:32:36.280 --> 00:32:37.060
We have a status on that.

00:32:37.060 --> 00:32:40.670
The zero means it hasn't
finished yet.

00:32:40.670 --> 00:32:44.640
We then do some pretty rough
and ready math on that to

00:32:44.640 --> 00:32:47.860
figure out how many virtual
machines we actually need.

00:32:47.860 --> 00:32:52.290
And I had that Settings page
earlier in the App Engine app

00:32:52.290 --> 00:32:54.150
where I could specify
a min and a max

00:32:54.150 --> 00:32:55.400
number of virtual machines.

00:32:55.400 --> 00:32:58.490
That's just a standard App
Engine page I put in there to

00:32:58.490 --> 00:33:00.310
play around with
those settings.

00:33:00.310 --> 00:33:03.880
So we have a floor of the min
and a ceiling of the max.

00:33:03.880 --> 00:33:07.860
I can control how many workers
I want per virtual machine.

00:33:07.860 --> 00:33:10.790
And then we do some pretty
simple math here.

00:33:10.790 --> 00:33:13.870
We say, if I don't have enough
virtual machines, go and

00:33:13.870 --> 00:33:14.680
create some more.

00:33:14.680 --> 00:33:18.960
And if I've got too many,
terminate the old ones.

00:33:18.960 --> 00:33:21.242
And I just thought I'd take you
through just a little bit

00:33:21.242 --> 00:33:23.980
of information about how to
create a virtual machine.

00:33:23.980 --> 00:33:25.980
We did it via the command
line before.

00:33:25.980 --> 00:33:29.150
But I'd like to do it here
through our REST API and show

00:33:29.150 --> 00:33:32.000
some of the fields that
go through there.

00:33:32.000 --> 00:33:34.850
So the first is I'm picking a
fairly unimaginative name for

00:33:34.850 --> 00:33:36.850
each virtual machine,
just based on UUID.

00:33:39.910 --> 00:33:41.820
There's two ways I can start
a virtual machine.

00:33:41.820 --> 00:33:45.810
I can either use a stock
standard image and then run

00:33:45.810 --> 00:33:48.120
apt-get and install all the
packages I need on there.

00:33:48.120 --> 00:33:49.900
And I did that for
a long time.

00:33:49.900 --> 00:33:53.120
And then the other way to do it
is you can do that once and

00:33:53.120 --> 00:33:57.140
then you can create an image,
upload that to Cloud Storage,

00:33:57.140 --> 00:33:59.735
create that within your Compute
Engine project, and

00:33:59.735 --> 00:34:01.120
then refer to the image
when you start

00:34:01.120 --> 00:34:02.590
subsequent virtual machines.

00:34:02.590 --> 00:34:04.610
So that way, I don't have to
reinstall the software and

00:34:04.610 --> 00:34:06.650
pound everyone's mirrors when
I'm trying to pull down all

00:34:06.650 --> 00:34:08.360
those packages every time.

00:34:08.360 --> 00:34:11.230
So here on the right, I'm
pulling up a particular image

00:34:11.230 --> 00:34:13.969
that I created earlier.

00:34:13.969 --> 00:34:16.079
I select the machine type
and the zone where I

00:34:16.079 --> 00:34:16.830
want to put this in.

00:34:16.830 --> 00:34:20.980
I have all these running over,
I think on the East Coast

00:34:20.980 --> 00:34:24.110
today, but on the central zone
when I created this slide.

00:34:24.110 --> 00:34:27.780
I'm picking the eight core
machine type so that I have

00:34:27.780 --> 00:34:30.580
nice beefy virtual machines for
my processing so it runs

00:34:30.580 --> 00:34:33.290
nice and quick for us.

00:34:33.290 --> 00:34:35.719
I specify some information
about the type of network

00:34:35.719 --> 00:34:37.230
interface I want on
that machine.

00:34:37.230 --> 00:34:39.830
And here I just want a really
standard default

00:34:39.830 --> 00:34:40.540
configuration.

00:34:40.540 --> 00:34:44.540
So I'm just using
a basic set up.

00:34:44.540 --> 00:34:47.320
Here is where I create the
service accounts and I tell it

00:34:47.320 --> 00:34:50.880
what service accounts the
metadata server should allow

00:34:50.880 --> 00:34:52.780
me to apply a token for.

00:34:52.780 --> 00:34:56.030
So here, both task queue access
and full control over

00:34:56.030 --> 00:34:57.280
my Cloud Storage.

00:34:59.600 --> 00:35:02.570
And then finally I'm able
to add a start-up

00:35:02.570 --> 00:35:04.010
script to that machine.

00:35:04.010 --> 00:35:06.060
So while I created the image
that has the software

00:35:06.060 --> 00:35:09.450
installed on there, I still left
a simple start-up script

00:35:09.450 --> 00:35:14.150
here so that I can then pass
some information to it as to,

00:35:14.150 --> 00:35:15.120
here's what to do when
you start up.

00:35:15.120 --> 00:35:18.780
I want you to start five task
queue readers and maybe one

00:35:18.780 --> 00:35:23.180
CPU heartbeat monitor that
we had written there.

00:35:23.180 --> 00:35:25.910
And we pass those parameters
to that information such as

00:35:25.910 --> 00:35:27.640
the App Engine app that's
running it, so that we can get

00:35:27.640 --> 00:35:31.230
this call backs through there.

00:35:31.230 --> 00:35:33.290
We're using the standard
Python client API

00:35:33.290 --> 00:35:34.370
library that we have.

00:35:34.370 --> 00:35:36.930
And like literally, that's
all it is to

00:35:36.930 --> 00:35:38.180
creating a virtual machine.

00:35:40.880 --> 00:35:43.050
So how are we going
there, Alon?

00:35:43.050 --> 00:35:43.900
Will we switch back--

00:35:43.900 --> 00:35:44.800
ALON LEVI: We're getting
through, yes.

00:35:44.800 --> 00:35:46.470
We can switch back.

00:35:46.470 --> 00:35:47.870
ADAM EIJDENBERG: Let's switch
back and see how we're going

00:35:47.870 --> 00:35:49.440
with our virtual machines.

00:35:49.440 --> 00:35:51.140
Live demos, always fun.

00:35:51.140 --> 00:35:52.850
ALON LEVI: Coming along.

00:35:52.850 --> 00:35:53.330
ADAM EIJDENBERG: OK.

00:35:53.330 --> 00:35:57.080
So we have actually created 400
virtual machines, which is

00:35:57.080 --> 00:35:58.070
pretty cool.

00:35:58.070 --> 00:36:01.570
What is actually quite
interesting too is we can see

00:36:01.570 --> 00:36:04.080
on the top left there, we can
see that yellow line has

00:36:04.080 --> 00:36:05.200
dipped just a little bit.

00:36:05.200 --> 00:36:08.720
And what that is, is it's
figured out that,

00:36:08.720 --> 00:36:09.430
hey, you know what?

00:36:09.430 --> 00:36:12.180
We've actually got a few too
many virtual machines running.

00:36:12.180 --> 00:36:14.580
We have two that have been
running for a couple of hours

00:36:14.580 --> 00:36:16.520
already, from before
this demonstration.

00:36:16.520 --> 00:36:17.760
They're no longer needed.

00:36:17.760 --> 00:36:19.880
And so I may as well terminate
them now so we don't get

00:36:19.880 --> 00:36:20.910
billed for those.

00:36:20.910 --> 00:36:21.990
I keep the other ones running.

00:36:21.990 --> 00:36:25.170
There's no point terminating
something in less than close

00:36:25.170 --> 00:36:29.970
to one hour, because that's
the most efficient way to

00:36:29.970 --> 00:36:32.670
optimize for your
resource usage.

00:36:32.670 --> 00:36:33.940
So let's finish it off there.

00:36:33.940 --> 00:36:34.305
ALON LEVI: All right.

00:36:34.305 --> 00:36:34.670
We're all done.

00:36:34.670 --> 00:36:37.710
ADAM EIJDENBERG: So maybe,
Alon, maybe let's upload

00:36:37.710 --> 00:36:38.760
10,000 videos.

00:36:38.760 --> 00:36:41.310
Maybe let's show the dash
this time as well.

00:36:41.310 --> 00:36:41.630
ALON LEVI: 10,000.

00:36:41.630 --> 00:36:44.140
And we'll turn on this little
dashboard that shows us the

00:36:44.140 --> 00:36:45.696
throughput we're getting
in-- what is it?

00:36:45.696 --> 00:36:48.010
It's hours of video
per minute?

00:36:48.010 --> 00:36:48.880
ADAM EIJDENBERG: Yes.

00:36:48.880 --> 00:36:50.990
What we're showing down there
is how many hours of video

00:36:50.990 --> 00:36:53.240
we're actually processing per
minute when we upload this.

00:36:53.240 --> 00:36:53.920
Let's drop that on.

00:36:53.920 --> 00:36:55.420
And then it will reset
the counter.

00:36:55.420 --> 00:36:56.590
ALON LEVI: So remember,
these virtual machines

00:36:56.590 --> 00:36:57.710
are all up and ready.

00:36:57.710 --> 00:37:00.300
So there's no initialization
required.

00:37:00.300 --> 00:37:02.020
It's just going to
start processing.

00:37:02.020 --> 00:37:02.220
ADAM EIJDENBERG: OK.

00:37:02.220 --> 00:37:04.950
So the timer reset when that
file was uploaded.

00:37:04.950 --> 00:37:09.047
We now have 10,000 jobs being
created in our task queue on

00:37:09.047 --> 00:37:10.240
that server there.

00:37:10.240 --> 00:37:14.400
We see that red line scale
up to about 80 gigabytes.

00:37:14.400 --> 00:37:17.310
We have about 80 gigabytes
of video being processed.

00:37:17.310 --> 00:37:19.030
We see that that dashboard
will say zero

00:37:19.030 --> 00:37:19.500
for a little while.

00:37:19.500 --> 00:37:21.860
We have to wait for the first
video to finish processing

00:37:21.860 --> 00:37:22.980
before we update
that dashboard.

00:37:22.980 --> 00:37:25.526
It's when we get the signal back
to our application that

00:37:25.526 --> 00:37:28.270
that finishes.

00:37:28.270 --> 00:37:30.850
We can see the CPU utilization,
it's jumped up to

00:37:30.850 --> 00:37:35.000
pretty much 100%,
which is good.

00:37:35.000 --> 00:37:38.270
And we'll see how quickly
those videos process.

00:37:38.270 --> 00:37:41.150
A bit of the dip in the red
graph, I suspect that's a bug

00:37:41.150 --> 00:37:44.160
in the order of how
we're displaying

00:37:44.160 --> 00:37:45.840
those numbers there.

00:37:45.840 --> 00:37:47.160
We'll see those begin
to come in.

00:37:47.160 --> 00:37:49.310
The ones that pick those things
up from the task queue

00:37:49.310 --> 00:37:51.580
first come in pretty quickly.

00:37:51.580 --> 00:37:54.740
The others should start coming
in pretty consistently.

00:37:54.740 --> 00:37:57.850
We're at about the one
minute mark here.

00:37:57.850 --> 00:38:00.285
We have had that line moving
pretty quickly up here.

00:38:03.660 --> 00:38:05.620
We have about 2,000
worker threads.

00:38:05.620 --> 00:38:07.830
We have 5 times 400, 2,000
worker threads here.

00:38:07.830 --> 00:38:09.460
And they're kind of all
finishing at once.

00:38:09.460 --> 00:38:13.800
I think the Channel API is doing
a really good job here.

00:38:13.800 --> 00:38:14.380
So what are we at?

00:38:14.380 --> 00:38:18.770
67, 68.

00:38:18.770 --> 00:38:22.276
And I think we'll probably hit
a steady state at around 70,

00:38:22.276 --> 00:38:27.300
until maybe that second batch of
videos start processing in,

00:38:27.300 --> 00:38:29.585
which I think will probably
trickle in pretty shortly.

00:38:29.585 --> 00:38:31.030
And we see that number's
dipping down.

00:38:31.030 --> 00:38:33.070
That's just because it's an
average from the start to the

00:38:33.070 --> 00:38:34.290
finish there.

00:38:34.290 --> 00:38:36.070
Let's just maybe wait for
that second batch to

00:38:36.070 --> 00:38:37.750
start coming through.

00:38:37.750 --> 00:38:39.320
And then we'll flick onto
the next slide.

00:38:39.320 --> 00:38:40.320
We've probably seen
enough video

00:38:40.320 --> 00:38:41.570
processing at that point.

00:38:45.020 --> 00:38:47.260
Again, we can see that
consistency in the performance

00:38:47.260 --> 00:38:48.200
of Compute Engine there.

00:38:48.200 --> 00:38:50.930
Even though we have 400 virtual
machines here, we can

00:38:50.930 --> 00:38:54.590
see it processing pretty much
at the same rate, mostly a

00:38:54.590 --> 00:38:57.370
step function, as that red line
decreases as we finish

00:38:57.370 --> 00:38:59.200
those jobs there.

00:38:59.200 --> 00:39:01.200
Just a note, on the App Engine
side, I'm using the

00:39:01.200 --> 00:39:03.200
task queue for this.

00:39:03.200 --> 00:39:05.030
Because I was spinning
up a huge--

00:39:05.030 --> 00:39:09.010
a relatively large number of
work is consuming that task

00:39:09.010 --> 00:39:11.740
queue, one of the things I did
there is I shattered that into

00:39:11.740 --> 00:39:13.270
10 separate task queues.

00:39:13.270 --> 00:39:16.160
So every time we're creating a
job to put on the queue, which

00:39:16.160 --> 00:39:18.720
I'm actually creating in batches
of 50, I'm randomly

00:39:18.720 --> 00:39:22.140
picking one of those task queues
to add that 50 jobs to.

00:39:22.140 --> 00:39:25.420
And on the other end on the
virtual machines, each one of

00:39:25.420 --> 00:39:28.310
those when it polls the task
queue for a new job, it

00:39:28.310 --> 00:39:31.260
randomly switches between those
10 task queues that we

00:39:31.260 --> 00:39:34.390
have running there.

00:39:34.390 --> 00:39:37.000
And we can see that that's
running pretty nice and quick.

00:39:37.000 --> 00:39:40.150
And how many-- we've got
192 hours of video.

00:39:40.150 --> 00:39:41.230
That's about a week's worth.

00:39:41.230 --> 00:39:43.950
ALON LEVI: About 73 hours
every minute, yes.

00:39:43.950 --> 00:39:44.560
Pretty good.

00:39:44.560 --> 00:39:46.890
Two minutes.

00:39:46.890 --> 00:39:53.310
ADAM EIJDENBERG: So let's flick
back to the slides.

00:39:53.310 --> 00:39:55.140
We wanted to show you
two things today.

00:39:55.140 --> 00:39:58.140
I think the two really
interesting ways to use

00:39:58.140 --> 00:40:01.880
Compute Engine and App Engine
together are, again--

00:40:01.880 --> 00:40:04.020
within App Engine, you're
building an app, does a great

00:40:04.020 --> 00:40:06.810
job of the front end, does a
great job of a lot of parts,

00:40:06.810 --> 00:40:09.900
but sometimes I just need
to run some native code.

00:40:09.900 --> 00:40:13.560
And I think this is a really
great way of being able to

00:40:13.560 --> 00:40:15.500
interact with Compute Engine
to take care of those large

00:40:15.500 --> 00:40:16.770
workload processing.

00:40:16.770 --> 00:40:19.420
And I think the second part
that's really interesting is,

00:40:19.420 --> 00:40:20.790
let's say I have a large
workload that

00:40:20.790 --> 00:40:22.350
does a lot of work.

00:40:22.350 --> 00:40:23.660
Something needs to
monitor those.

00:40:23.660 --> 00:40:25.020
Something needs to keep
track of those.

00:40:25.020 --> 00:40:28.830
Something needs to curate that
and look after that.

00:40:28.830 --> 00:40:30.660
And I could create more virtual
machines to look after

00:40:30.660 --> 00:40:32.470
my other virtual machines.

00:40:32.470 --> 00:40:33.900
But then someone needs to look
up after those virtual

00:40:33.900 --> 00:40:36.990
machines and maybe get another
one to look after those.

00:40:36.990 --> 00:40:40.320
And it seems to me that App
Engine, we already have a lot

00:40:40.320 --> 00:40:42.770
of people at Google looking
after App Engine, making sure

00:40:42.770 --> 00:40:45.420
that's up and running for you.

00:40:45.420 --> 00:40:48.430
And I think it's a really neat
way of having something that I

00:40:48.430 --> 00:40:51.010
know is always up and running,
something I can rely on to

00:40:51.010 --> 00:40:53.910
manage all of those virtual
machines that I have running

00:40:53.910 --> 00:40:55.910
in my environment.

00:40:55.910 --> 00:40:58.570
So Compute Engine, we are
in limited preview.

00:40:58.570 --> 00:41:02.050
Please, please visit our
website and sign up.

00:41:02.050 --> 00:41:06.250
We're taking requests now
for a period of time.

00:41:06.250 --> 00:41:07.710
I have a bunch of
reference URLs.

00:41:07.710 --> 00:41:09.670
I'm not going to go through them
in detail now, but just

00:41:09.670 --> 00:41:11.875
to show you all of the various
bits of documentation that

00:41:11.875 --> 00:41:14.860
were relevant to the parts of
the demonstration today.

00:41:19.100 --> 00:41:21.160
This will be up on YouTube
within the next couple of

00:41:21.160 --> 00:41:22.210
days, I think.

00:41:22.210 --> 00:41:24.060
ALON LEVI: We'll put the slides
up online so you can

00:41:24.060 --> 00:41:25.750
copy/paste.

00:41:25.750 --> 00:41:26.870
ADAM EIJDENBERG: So
any questions?

00:41:26.870 --> 00:41:28.134
ALON LEVI: Thank
you very much.

00:41:28.134 --> 00:41:31.403
[APPLAUSE]

00:41:31.403 --> 00:41:33.271
ALON LEVI: And one more
thing I should add.

00:41:33.271 --> 00:41:35.200
I don't know how many of you
guys stopped by the Cloud

00:41:35.200 --> 00:41:36.400
Platform sandbox area.

00:41:36.400 --> 00:41:37.680
We had those delicious
chocolates for

00:41:37.680 --> 00:41:38.790
the past two days.

00:41:38.790 --> 00:41:40.670
We've only got a few boxes left,
so we're going to hand

00:41:40.670 --> 00:41:43.000
them out to people who
ask questions.

00:41:43.000 --> 00:41:45.830
So take it away.

00:41:45.830 --> 00:41:50.180
AUDIENCE: You mentioned about
using provisioning APIs to

00:41:50.180 --> 00:41:56.150
access the compute itself
as a resource.

00:41:56.150 --> 00:41:58.920
Obviously it helps a lot
in elastic computing.

00:41:58.920 --> 00:42:02.040
But one of the common use cases
from a functionality

00:42:02.040 --> 00:42:08.180
standpoint is to use the
existing resources, the four

00:42:08.180 --> 00:42:12.960
resources, Memcache, BigTable,
Cloud SQL, and you showed

00:42:12.960 --> 00:42:15.200
already Cloud Storage.

00:42:15.200 --> 00:42:17.760
How do you use that as
a provisioning--

00:42:17.760 --> 00:42:20.500
how do you access those
resources using the

00:42:20.500 --> 00:42:24.570
provisioning API from
Cloud Compute?

00:42:24.570 --> 00:42:26.085
Am I making sense here?

00:42:26.085 --> 00:42:26.450
ALON LEVI: Yes.

00:42:26.450 --> 00:42:26.720
ADAM EIJDENBERG: Yes.

00:42:26.720 --> 00:42:27.050
Absolutely.

00:42:27.050 --> 00:42:28.610
I mean, some of those
we can access today.

00:42:28.610 --> 00:42:30.800
So task queue has an API
that we hit today.

00:42:30.800 --> 00:42:33.060
Cloud storage, of course,
has an API.

00:42:33.060 --> 00:42:35.490
We're looking at ways of making
it even a cleaner

00:42:35.490 --> 00:42:37.880
integration with some of the
other App Engine components

00:42:37.880 --> 00:42:40.300
there that are really, really
valuable to people, exactly

00:42:40.300 --> 00:42:43.210
like you said, like Memcache,
like Datastore.

00:42:43.210 --> 00:42:44.410
ALON LEVI: So it's not
all quite there yet.

00:42:44.410 --> 00:42:45.200
But we're working on it.

00:42:45.200 --> 00:42:47.110
And hopefully we'll have
more to announce soon.

00:42:47.110 --> 00:42:49.380
AUDIENCE: So currently the one
that you're using is going to

00:42:49.380 --> 00:42:52.410
be two separate requests, one
on App Engine and the other

00:42:52.410 --> 00:42:53.790
one on course.

00:42:53.790 --> 00:42:56.890
So it's like JSONP, which makes
a separate, independent

00:42:56.890 --> 00:42:58.640
request to Compute Cloud?

00:42:58.640 --> 00:43:01.880
ALON LEVI: So talking between
App Engine and Compute Cloud,

00:43:01.880 --> 00:43:04.875
we're making HTTP requests
between the two.

00:43:04.875 --> 00:43:06.170
AUDIENCE: Two different
requests.

00:43:06.170 --> 00:43:07.500
ALON LEVI: Well, yes.

00:43:07.500 --> 00:43:09.390
I mean, Compute talks
to App Engine.

00:43:09.390 --> 00:43:10.540
That's a request.

00:43:10.540 --> 00:43:11.730
And then the response.

00:43:11.730 --> 00:43:15.280
And then if you want to talk
to Task Queue or Cloud

00:43:15.280 --> 00:43:17.520
Storage, you can talk directly
to that service.

00:43:17.520 --> 00:43:21.040
But for things like Datastore
and Memcache and the like,

00:43:21.040 --> 00:43:23.626
we're still working on those.

00:43:23.626 --> 00:43:26.766
And you can come up and grab a
chocolate bar, if you want.

00:43:26.766 --> 00:43:29.580
Or you can come by after.

00:43:29.580 --> 00:43:30.620
AUDIENCE: Hello.

00:43:30.620 --> 00:43:33.970
I was wondering if there is a
way to manage the keys we

00:43:33.970 --> 00:43:38.740
create, to set an expiration,
revoke, re-create the keys?

00:43:38.740 --> 00:43:39.850
ALON LEVI: For the
service account?

00:43:39.850 --> 00:43:41.100
ADAM EIJDENBERG: For the
service accounts?

00:43:41.100 --> 00:43:43.580
AUDIENCE: Yes.

00:43:43.580 --> 00:43:45.310
ADAM EIJDENBERG: If you're using
the provisioned service

00:43:45.310 --> 00:43:48.810
accounts, we take care of a
lot of that complexity.

00:43:48.810 --> 00:43:50.680
Are you talking about ones
that you create in the

00:43:50.680 --> 00:43:52.390
administration console
that you download?

00:43:52.390 --> 00:43:53.640
AUDIENCE: Yes.

00:43:55.450 --> 00:43:56.140
ADAM EIJDENBERG: Come and
talk to us later.

00:43:56.140 --> 00:43:57.360
I'll check with the
team on that.

00:43:57.360 --> 00:44:00.030
I think there's a way that you
can revoke those from within

00:44:00.030 --> 00:44:01.450
the administration area.

00:44:01.450 --> 00:44:02.590
I don't know if they
can be set to

00:44:02.590 --> 00:44:04.740
automatically expire or not.

00:44:04.740 --> 00:44:05.800
AUDIENCE: OK.

00:44:05.800 --> 00:44:06.960
One last question.

00:44:06.960 --> 00:44:11.090
Any plans to open source the
sample you showed us?

00:44:11.090 --> 00:44:11.520
ADAM EIJDENBERG: Yes.

00:44:11.520 --> 00:44:12.500
Absolutely.

00:44:12.500 --> 00:44:14.230
We probably need to get back
to the office, let the dust

00:44:14.230 --> 00:44:16.970
settle a bit, and clean some
of the code up for you.

00:44:16.970 --> 00:44:19.950
I tried to put as many of the
crucial parts of the code into

00:44:19.950 --> 00:44:22.250
the presentation that will get
out sooner than probably the

00:44:22.250 --> 00:44:23.220
rest of it.

00:44:23.220 --> 00:44:24.920
AUDIENCE: It should work
the same if I use

00:44:24.920 --> 00:44:26.322
Python or Java, right?

00:44:26.322 --> 00:44:26.690
ALON LEVI: Yes.

00:44:26.690 --> 00:44:28.210
I mean, all those
APIs will work.

00:44:28.210 --> 00:44:28.350
ADAM EIJDENBERG: Absolutely.

00:44:28.350 --> 00:44:31.050
There's no need to use
Python there at all.

00:44:31.050 --> 00:44:31.990
I like it.

00:44:31.990 --> 00:44:33.010
But there's absolutely
no reason that

00:44:33.010 --> 00:44:33.370
you need to use it.

00:44:33.370 --> 00:44:33.810
AUDIENCE: OK.

00:44:33.810 --> 00:44:35.060
Thank you.

00:44:37.420 --> 00:44:40.890
AUDIENCE: How does Compute
Engine differentiate from AWS?

00:44:40.890 --> 00:44:42.110
Is it usability?

00:44:42.110 --> 00:44:44.430
Is it just the brand?

00:44:44.430 --> 00:44:45.590
ADAM EIJDENBERG: Performance.

00:44:45.590 --> 00:44:50.270
We see very strong consistency
of performance.

00:44:50.270 --> 00:44:54.065
We see value in terms of how
much compute you get for your

00:44:54.065 --> 00:44:57.370
dollar, and consistency.

00:44:57.370 --> 00:44:59.490
AUDIENCE: Does that consistency
go down to disk

00:44:59.490 --> 00:45:01.365
level, like storage level?

00:45:04.700 --> 00:45:05.600
ADAM EIJDENBERG: Yes,
essentially.

00:45:05.600 --> 00:45:08.220
So if you have--

00:45:08.220 --> 00:45:09.990
it's probably best
to talk to--

00:45:09.990 --> 00:45:11.780
I mean, we have a number of
our partners and trusted

00:45:11.780 --> 00:45:13.300
testers came up yesterday.

00:45:13.300 --> 00:45:14.720
And you can always
listen to us.

00:45:14.720 --> 00:45:18.060
It's usually good to listen
to the users of it.

00:45:18.060 --> 00:45:20.040
And they had very favorable
thing to say there.

00:45:20.040 --> 00:45:22.920
I think if you have a four core
or an eight core machine,

00:45:22.920 --> 00:45:24.420
then you're guaranteed
to get your own

00:45:24.420 --> 00:45:26.830
spindle, one or two spindles?

00:45:26.830 --> 00:45:28.160
One spindle.

00:45:28.160 --> 00:45:29.500
I have a tech lead in
the front here.

00:45:29.500 --> 00:45:30.860
And he's nodding at me a lot, so
that's always a good sign.

00:45:30.860 --> 00:45:32.660
ALON LEVI: That's a good sign.

00:45:32.660 --> 00:45:33.910
AUDIENCE: [INAUDIBLE]

00:45:41.480 --> 00:45:41.630
ADAM EIJDENBERG: OK.

00:45:41.630 --> 00:45:43.520
I'll just repeat that
from our tech lead.

00:45:43.520 --> 00:45:47.040
Our persistent disk product has
less than 3% variance on

00:45:47.040 --> 00:45:49.920
random four kilobyte
read-writes.

00:45:49.920 --> 00:45:50.820
AUDIENCE: Yes.

00:45:50.820 --> 00:45:52.070
ALON LEVI: Good job.

00:45:53.930 --> 00:45:54.134
AUDIENCE: Hi.

00:45:54.134 --> 00:45:59.280
I was just curious if you have
any idea of how much work

00:45:59.280 --> 00:46:01.830
difference it would be if you
created that whole application

00:46:01.830 --> 00:46:04.120
just in Compute Engine.

00:46:04.120 --> 00:46:07.230
And would you do some kind of
comparison of that, just

00:46:07.230 --> 00:46:08.955
what's the value added
of App Engine?

00:46:11.585 --> 00:46:11.870
ADAM EIJDENBERG: Yes.

00:46:11.870 --> 00:46:13.460
I mean, I think you could
go either way.

00:46:13.460 --> 00:46:14.910
So I guess it depends
what environment

00:46:14.910 --> 00:46:16.040
you're most used to.

00:46:16.040 --> 00:46:19.170
If you like App Engine, if you
want to build it on the

00:46:19.170 --> 00:46:21.180
Platform as a Service, I think
that's a great offering.

00:46:21.180 --> 00:46:24.350
I've found that task queues are
a really natural way to

00:46:24.350 --> 00:46:28.010
access those Compute
Engine resources.

00:46:28.010 --> 00:46:32.280
All those heartbeats reporting
back from 400 VMs very

00:46:32.280 --> 00:46:34.430
quickly, that actually needs
to spin up a number of App

00:46:34.430 --> 00:46:36.550
Engine instances for that, which
kind of surprised me.

00:46:36.550 --> 00:46:38.820
But I was really glad it did
that automatically for me.

00:46:38.820 --> 00:46:40.620
I didn't even have to
worry about that.

00:46:40.620 --> 00:46:43.980
You could build that front end
directly on a LAMP stack if

00:46:43.980 --> 00:46:45.930
you wanted.

00:46:45.930 --> 00:46:46.640
You can go either way.

00:46:46.640 --> 00:46:48.560
ALON LEVI: The other nice thing
is that because we do

00:46:48.560 --> 00:46:50.440
the development through App
Engine and App Engine was sort

00:46:50.440 --> 00:46:53.350
of controlling and provisioning
the VMs, as the

00:46:53.350 --> 00:46:55.090
development was happening, all
we were doing was deploying an

00:46:55.090 --> 00:46:57.680
App Engine app and using the App
Engine tools and sort of

00:46:57.680 --> 00:47:00.750
using all of the monitoring and
logs and things that come

00:47:00.750 --> 00:47:01.650
along with that.

00:47:01.650 --> 00:47:05.570
And so you still get the fast,
iterative cycle that you're

00:47:05.570 --> 00:47:06.860
used to with App Engine.

00:47:06.860 --> 00:47:12.080
And then the management of the
VMs is done from there.

00:47:12.080 --> 00:47:13.880
AUDIENCE: I mean, just any
gauge for how much more

00:47:13.880 --> 00:47:16.690
efficient you were in ginning
up the app because of that?

00:47:16.690 --> 00:47:17.700
ADAM EIJDENBERG: Well, we didn't
try it both ways, so

00:47:17.700 --> 00:47:19.070
it's hard to compare.

00:47:19.070 --> 00:47:22.606
But you're welcome to give
it a try and let us know.

00:47:22.606 --> 00:47:23.856
Thanks.

00:47:25.750 --> 00:47:29.410
AUDIENCE: I was impressed by the
different tiers of storage

00:47:29.410 --> 00:47:31.320
that you put into Compute
Engine, the persistent

00:47:31.320 --> 00:47:33.860
storage, the ephemeral
storage.

00:47:33.860 --> 00:47:37.340
Are there plans to making the
persistent storage mountable

00:47:37.340 --> 00:47:38.590
through App Engine?

00:47:42.060 --> 00:47:44.050
ADAM EIJDENBERG: That's
something we can think about.

00:47:44.050 --> 00:47:46.390
We don't have any concrete
plans right now.

00:47:46.390 --> 00:47:47.640
ALON LEVI: Thanks.

00:47:49.380 --> 00:47:49.900
AUDIENCE: Hi.

00:47:49.900 --> 00:47:54.350
With the Google VMs that you
spin up, is that the standard

00:47:54.350 --> 00:47:55.650
Ubuntu Linux?

00:47:55.650 --> 00:47:57.520
Is there anything special
about it?

00:47:57.520 --> 00:47:59.690
Are there any limitations that
you guys imposed about stuff

00:47:59.690 --> 00:48:03.920
that you can't do as opposed
to the plain version?

00:48:03.920 --> 00:48:04.100
ADAM EIJDENBERG: Yes.

00:48:04.100 --> 00:48:05.130
They're pretty standard.

00:48:05.130 --> 00:48:08.370
We do have our own kernel on
there, that we've hardened and

00:48:08.370 --> 00:48:11.030
optimized for the environment.

00:48:11.030 --> 00:48:12.280
AUDIENCE: Thank you.

00:48:14.510 --> 00:48:16.510
AUDIENCE: So you explained
the use cases of

00:48:16.510 --> 00:48:19.040
App Engine and Compute.

00:48:19.040 --> 00:48:20.725
There is this intermediate
thing which

00:48:20.725 --> 00:48:21.460
is called back end.

00:48:21.460 --> 00:48:23.880
So what is the plan for it?

00:48:23.880 --> 00:48:24.130
ADAM EIJDENBERG: Yes.

00:48:24.130 --> 00:48:28.100
So back ends are our way to
sort of run a stateful

00:48:28.100 --> 00:48:29.480
addressable service
on App Engine.

00:48:29.480 --> 00:48:32.360
You sort of get the advantages
of having App Engine take care

00:48:32.360 --> 00:48:36.100
of it and being able to scale if
you use dynamic back ends.

00:48:36.100 --> 00:48:37.700
But it's sort of different
than Compute.

00:48:37.700 --> 00:48:39.920
You still can't run
native code.

00:48:39.920 --> 00:48:41.720
It's still the App
Engine container.

00:48:41.720 --> 00:48:43.310
But it's sort of halfway
in between.

00:48:43.310 --> 00:48:47.640
So you can use it for things
where you don't really need to

00:48:47.640 --> 00:48:49.670
access the entire machine
but you want some

00:48:49.670 --> 00:48:50.600
bit of stateful services.

00:48:50.600 --> 00:48:55.250
So I think there's a place for
it in between somewhere.

00:48:55.250 --> 00:48:56.500
ALON LEVI: Yes.

00:48:58.200 --> 00:49:02.310
AUDIENCE: I'm curious if your
example you showed us the day,

00:49:02.310 --> 00:49:05.000
the whole transformation storage
and all this, can you

00:49:05.000 --> 00:49:08.700
make a guess if this example
would be a real world

00:49:08.700 --> 00:49:12.215
application how much money
you have burned for this?

00:49:12.215 --> 00:49:13.720
ADAM EIJDENBERG: Yes.

00:49:13.720 --> 00:49:14.420
That's a good question.

00:49:14.420 --> 00:49:17.570
So the App Engine app I have set
up that has billing turned

00:49:17.570 --> 00:49:20.180
on, because I like to be able
to see what happens there.

00:49:20.180 --> 00:49:24.990
The App Engine app was really
very, very low, very low even

00:49:24.990 --> 00:49:26.810
for the bursts I've
putting on there.

00:49:26.810 --> 00:49:29.870
On the Compute Engine side,
the cost of those virtual

00:49:29.870 --> 00:49:33.050
machines that were running,
the 8 core, $1.16 an hour.

00:49:33.050 --> 00:49:36.350
So that times 400 for one
hour of those running.

00:49:39.670 --> 00:49:41.480
AUDIENCE: This is more of
a legal question than a

00:49:41.480 --> 00:49:43.740
technical question.

00:49:43.740 --> 00:49:46.950
Do you know what's the
licensing thing?

00:49:46.950 --> 00:49:49.316
Could would we run licensed
software on these?

00:49:49.316 --> 00:49:49.742
ALON LEVI: Yes.

00:49:49.742 --> 00:49:50.430
I think so.

00:49:50.430 --> 00:49:50.870
I mean, it's--

00:49:50.870 --> 00:49:53.810
AUDIENCE: So if we were to run
VMware or whatever it was that

00:49:53.810 --> 00:49:56.190
required a license, there's
no issues with that?

00:49:59.160 --> 00:50:00.410
AUDIENCE: [INAUDIBLE]

00:50:18.010 --> 00:50:20.080
ADAM EIJDENBERG: I'll just
repeat that answer.

00:50:20.080 --> 00:50:22.260
The answer was that you need to
check with the provider of

00:50:22.260 --> 00:50:22.690
the software.

00:50:22.690 --> 00:50:23.710
It's their license.

00:50:23.710 --> 00:50:26.280
Some providers won't have
restrictions, some will.

00:50:26.280 --> 00:50:28.330
ALON LEVI: From Compute Engine's
perspective, you

00:50:28.330 --> 00:50:28.890
could run it.

00:50:28.890 --> 00:50:32.420
But it's up to you to figure
out if you're allowed to.

00:50:32.420 --> 00:50:36.130
AUDIENCE: Are there any plans to
have specialized CPUs like

00:50:36.130 --> 00:50:43.320
AMD Radeon GPUs available in
a compute kind of format?

00:50:43.320 --> 00:50:43.810
ADAM EIJDENBERG: I'm sorry.

00:50:43.810 --> 00:50:45.040
What type of GPUs?

00:50:45.040 --> 00:50:46.790
AUDIENCE: An AMD Radeon GPU.

00:50:50.500 --> 00:50:52.120
ADAM EIJDENBERG: I think that's
something that we can

00:50:52.120 --> 00:50:52.810
think about.

00:50:52.810 --> 00:50:54.290
But I don't have anything
concrete to

00:50:54.290 --> 00:50:55.540
announce today on that.

00:50:59.070 --> 00:50:59.270
OK.

00:50:59.270 --> 00:50:59.830
Well, thank you.

00:50:59.830 --> 00:51:02.050
Thank you everyone for your
time this morning.

