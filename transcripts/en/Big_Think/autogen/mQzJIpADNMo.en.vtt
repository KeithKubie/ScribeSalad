WEBVTT
Kind: captions
Language: en

00:00:04.440 --> 00:00:15.110
I think we still know so little about what
it means to be human that the confidence with

00:00:15.110 --> 00:00:25.160
which we think we can upload ourselves to
silicon or recreate ourselves with algorithms

00:00:25.160 --> 00:00:27.840
is shocking to me.

00:00:27.840 --> 00:00:35.320
The only ones out there who think they know
what human consciousness is are computer engineers.

00:00:35.320 --> 00:00:43.820
If you talk to actual brain researchers and
neuroscientists, they say, we're nowhere close.

00:00:43.820 --> 00:00:51.120
We don't even know for sure what goes on in
a single square centimeter of soil.

00:00:51.120 --> 00:00:58.479
We're still trying to teach agriculture companies
that the soil is alive, that it's not just

00:00:58.479 --> 00:01:00.569
dirt that you can put chemicals on.

00:01:00.569 --> 00:01:01.639
It's a living matrix.

00:01:01.639 --> 00:01:06.850
If we don't even know what a single centimeter
of soil is, how do we know what the human

00:01:06.850 --> 00:01:07.850
brain is?

00:01:07.850 --> 00:01:08.850
We don't.

00:01:08.850 --> 00:01:10.250
We don't know what the source of consciousness
is.

00:01:10.250 --> 00:01:11.580
We don't know where we come from.

00:01:11.580 --> 00:01:15.530
We don't even know if there's a meaning to
this universe or not.

00:01:15.530 --> 00:01:22.330
Yet, we think that we can make a simulation
that's as valid as this?

00:01:22.330 --> 00:01:25.480
Every simulation we make misses something.

00:01:25.480 --> 00:01:32.850
Think about the difference between being in
a jazz club and listening to a great CD.

00:01:32.850 --> 00:01:34.350
There's a difference, you know.

00:01:34.350 --> 00:01:38.000
And some of those differences, we understand,
and some of them, we don't.

00:01:38.000 --> 00:01:43.460
So when I see people rushing off to upload
consciousness to a chip, it feels more like

00:01:43.460 --> 00:01:48.390
escape from humanity than it is a journey
forward.

00:01:48.390 --> 00:01:49.550
And I get it.

00:01:49.550 --> 00:01:50.750
Life is scary.

00:01:50.750 --> 00:01:54.850
I mean, women, real-life women, are scary.

00:01:54.850 --> 00:01:57.640
You know, the people are scary.

00:01:57.640 --> 00:01:59.680
The moisture is scary.

00:01:59.680 --> 00:02:01.460
Death is scary.

00:02:01.460 --> 00:02:03.600
Babies are scary.

00:02:03.600 --> 00:02:07.700
Other people who don't speak the same language
or have the same customs, they're scary.

00:02:07.700 --> 00:02:09.250
All sorts of stuff is scary.

00:02:09.250 --> 00:02:16.531
And I understand the idea of this kind of
having a Sim City perfected simulation that

00:02:16.531 --> 00:02:20.890
I can go into and not have to worry about
all that stuff I don't know, where everything

00:02:20.890 --> 00:02:25.910
is discrete, everything is a yes/no, this/that,
all the choices have been made.

00:02:25.910 --> 00:02:29.640
There's a certain attractiveness to that,
but that's dead.

00:02:29.640 --> 00:02:30.640
It's not alive.

00:02:30.640 --> 00:02:31.640
There's no wonder.

00:02:31.640 --> 00:02:32.640
There's no awe.

00:02:32.640 --> 00:02:38.370
There's nothing strange and liminal and ambiguous
about it.

00:02:38.370 --> 00:02:43.640
I was on a panel with a famous transhumanist,
and he was arguing that it's time that human

00:02:43.640 --> 00:02:49.860
beings come to accept that we will have to
pass the torch of evolution to our digital

00:02:49.860 --> 00:02:51.650
successors.

00:02:51.650 --> 00:02:56.870
And that once computers have the singularity
and they're really thinking and better than

00:02:56.870 --> 00:03:01.160
us, then we should really only stick around
as long as the computers need us, you know,

00:03:01.160 --> 00:03:05.170
to keep the lights on and oil their little
circuits or whatever we have to do.

00:03:05.170 --> 00:03:08.840
And then, after that, fade into oblivion.

00:03:08.840 --> 00:03:10.791
And I said, hey, no, wait a minute.

00:03:10.791 --> 00:03:11.950
Human beings are still special.

00:03:11.950 --> 00:03:12.950
We're weird.

00:03:12.950 --> 00:03:13.950
We're quirky.

00:03:13.950 --> 00:03:19.450
We've got David Lynch movies and weird yoga
positions and stuff we don't understand, and

00:03:19.450 --> 00:03:22.750
we're ambiguous and weird and quirky.

00:03:22.750 --> 00:03:26.070
You know, we deserve a place in the digital
future.

00:03:26.070 --> 00:03:31.069
And he said, oh, Rushkoff, you're just saying
that because you're human.

00:03:31.069 --> 00:03:32.310
As if it's hubris, right?

00:03:32.310 --> 00:03:35.069
Oh, I'm just defending my little team.

00:03:35.069 --> 00:03:37.410
And that's where I got the idea, all right,
fine, I'm a human.

00:03:37.410 --> 00:03:39.400
I'm on Team Human.

00:03:39.400 --> 00:03:44.510
And it's not Team Human against the algorithms
or against anything other than those who want

00:03:44.510 --> 00:03:45.930
to get rid of the humans.

00:03:45.930 --> 00:03:49.319
I think humans deserve a place.

00:03:49.319 --> 00:03:54.160
Certainly, until we understand what it is
we are, we shouldn't get rid of us.

00:03:54.160 --> 00:03:57.010
And as far as I'm concerned, we're cool.

00:03:57.010 --> 00:03:59.140
We're still weird and funny and wonderful.

00:03:59.140 --> 00:04:00.940
And yeah, we destroyed the environment.

00:04:00.940 --> 00:04:02.440
We did really nasty things.

00:04:02.440 --> 00:04:06.599
But I would argue we do those things when
we're less than human.

00:04:06.599 --> 00:04:09.700
We do those things when we can dehumanize
others.

00:04:09.700 --> 00:04:12.670
You can't have slaves if you're thinking of
those as people.

00:04:12.670 --> 00:04:17.200
You can only have slaves if you're thinking
of them as something other than people.

00:04:17.200 --> 00:04:26.700
And this desire to transcend the human, I
feel like it's excusing a whole lot of behaviors.

00:04:26.700 --> 00:04:29.669
It's excusing a whole lot of dehumanization.

00:04:29.669 --> 00:04:34.699
It makes it easier to send kids into caves
to get rare earth metals for your phone.

00:04:34.699 --> 00:04:37.960
It makes it easier to create toxic waste everywhere.

00:04:37.960 --> 00:04:44.680
It makes it easier for you to think of the
human timeline as having a beginning, middle,

00:04:44.680 --> 00:04:47.040
and an end, because we're going to transcend
it.

00:04:47.040 --> 00:04:59.600
And that's a sick Western, neoliberal, growth-based,
apocalyptic myth that could very well end

00:04:59.600 --> 00:05:02.660
our species.

00:05:02.660 --> 00:05:06.409
But really, I would say to the detriment of
our little universe.

