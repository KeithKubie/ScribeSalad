WEBVTT
Kind: captions
Language: en

00:00:00.149 --> 00:00:02.000 align:start position:0%
 
when<00:00:00.539><c> training</c><00:00:00.900><c> a</c><00:00:00.930><c> neural</c><00:00:01.110><c> network</c><00:00:01.380><c> one</c><00:00:01.860><c> of</c>

00:00:02.000 --> 00:00:02.010 align:start position:0%
when training a neural network one of
 

00:00:02.010 --> 00:00:03.560 align:start position:0%
when training a neural network one of
the<00:00:02.129><c> techniques</c><00:00:02.550><c> to</c><00:00:02.669><c> speed</c><00:00:03.030><c> up</c><00:00:03.179><c> your</c><00:00:03.210><c> training</c>

00:00:03.560 --> 00:00:03.570 align:start position:0%
the techniques to speed up your training
 

00:00:03.570 --> 00:00:06.110 align:start position:0%
the techniques to speed up your training
is<00:00:03.870><c> if</c><00:00:03.990><c> you</c><00:00:04.080><c> normalize</c><00:00:04.620><c> your</c><00:00:05.040><c> inputs</c><00:00:05.520><c> let's</c>

00:00:06.110 --> 00:00:06.120 align:start position:0%
is if you normalize your inputs let's
 

00:00:06.120 --> 00:00:08.089 align:start position:0%
is if you normalize your inputs let's
see<00:00:06.270><c> what</c><00:00:06.390><c> that</c><00:00:06.569><c> means</c><00:00:06.830><c> let's</c><00:00:07.830><c> see</c><00:00:07.950><c> the</c>

00:00:08.089 --> 00:00:08.099 align:start position:0%
see what that means let's see the
 

00:00:08.099 --> 00:00:10.459 align:start position:0%
see what that means let's see the
training<00:00:08.370><c> sets</c><00:00:08.700><c> with</c><00:00:08.940><c> two</c><00:00:09.240><c> input</c><00:00:09.719><c> features</c><00:00:10.139><c> so</c>

00:00:10.459 --> 00:00:10.469 align:start position:0%
training sets with two input features so
 

00:00:10.469 --> 00:00:12.799 align:start position:0%
training sets with two input features so
the<00:00:10.679><c> input</c><00:00:11.070><c> features</c><00:00:11.400><c> X</c><00:00:11.670><c> are</c><00:00:12.150><c> two-dimensional</c>

00:00:12.799 --> 00:00:12.809 align:start position:0%
the input features X are two-dimensional
 

00:00:12.809 --> 00:00:14.870 align:start position:0%
the input features X are two-dimensional
and<00:00:13.440><c> here's</c><00:00:13.650><c> a</c><00:00:13.710><c> scatterplot</c><00:00:14.190><c> of</c><00:00:14.639><c> your</c>

00:00:14.870 --> 00:00:14.880 align:start position:0%
and here's a scatterplot of your
 

00:00:14.880 --> 00:00:18.040 align:start position:0%
and here's a scatterplot of your
training<00:00:15.630><c> set</c><00:00:16.130><c> normalizing</c><00:00:17.130><c> your</c><00:00:17.160><c> inputs</c>

00:00:18.040 --> 00:00:18.050 align:start position:0%
training set normalizing your inputs
 

00:00:18.050 --> 00:00:22.300 align:start position:0%
training set normalizing your inputs
corresponds<00:00:19.050><c> to</c><00:00:19.230><c> two</c><00:00:19.740><c> steps</c><00:00:19.980><c> the</c><00:00:20.189><c> first</c><00:00:20.820><c> is</c><00:00:21.390><c> to</c>

00:00:22.300 --> 00:00:22.310 align:start position:0%
corresponds to two steps the first is to
 

00:00:22.310 --> 00:00:26.359 align:start position:0%
corresponds to two steps the first is to
subtract<00:00:23.310><c> out</c><00:00:23.580><c> or</c><00:00:23.850><c> to</c><00:00:24.359><c> zero</c><00:00:24.720><c> out</c><00:00:24.750><c> the</c><00:00:24.980><c> mean</c><00:00:25.980><c> so</c>

00:00:26.359 --> 00:00:26.369 align:start position:0%
subtract out or to zero out the mean so
 

00:00:26.369 --> 00:00:32.350 align:start position:0%
subtract out or to zero out the mean so
you<00:00:26.430><c> set</c><00:00:26.789><c> mu</c><00:00:27.180><c> equals</c><00:00:28.080><c> 1</c><00:00:28.410><c> over</c><00:00:28.680><c> m</c><00:00:28.970><c> sum</c><00:00:29.970><c> over</c><00:00:30.330><c> I</c><00:00:30.539><c> of</c>

00:00:32.350 --> 00:00:32.360 align:start position:0%
you set mu equals 1 over m sum over I of
 

00:00:32.360 --> 00:00:36.560 align:start position:0%
you set mu equals 1 over m sum over I of
X<00:00:33.360><c> I</c><00:00:33.750><c> so</c><00:00:34.230><c> this</c><00:00:34.380><c> is</c><00:00:34.440><c> a</c><00:00:34.559><c> vector</c><00:00:34.980><c> and</c><00:00:35.160><c> then</c><00:00:35.460><c> X</c><00:00:35.730><c> gets</c>

00:00:36.560 --> 00:00:36.570 align:start position:0%
X I so this is a vector and then X gets
 

00:00:36.570 --> 00:00:38.569 align:start position:0%
X I so this is a vector and then X gets
set<00:00:36.809><c> as</c><00:00:36.989><c> X</c><00:00:37.260><c> minus</c><00:00:37.680><c> mu</c><00:00:37.890><c> for</c><00:00:38.160><c> every</c><00:00:38.370><c> training</c>

00:00:38.569 --> 00:00:38.579 align:start position:0%
set as X minus mu for every training
 

00:00:38.579 --> 00:00:41.299 align:start position:0%
set as X minus mu for every training
example<00:00:39.030><c> so</c><00:00:39.329><c> this</c><00:00:39.480><c> means</c><00:00:39.719><c> you</c><00:00:40.620><c> just</c><00:00:40.980><c> move</c><00:00:41.129><c> the</c>

00:00:41.299 --> 00:00:41.309 align:start position:0%
example so this means you just move the
 

00:00:41.309 --> 00:00:43.970 align:start position:0%
example so this means you just move the
training<00:00:41.610><c> set</c><00:00:41.790><c> until</c><00:00:42.210><c> it</c><00:00:42.329><c> has</c><00:00:42.510><c> zero</c><00:00:43.469><c> mean</c><00:00:43.739><c> and</c>

00:00:43.970 --> 00:00:43.980 align:start position:0%
training set until it has zero mean and
 

00:00:43.980 --> 00:00:48.709 align:start position:0%
training set until it has zero mean and
then<00:00:44.910><c> the</c><00:00:45.000><c> second</c><00:00:45.360><c> step</c><00:00:45.510><c> is</c><00:00:45.840><c> to</c><00:00:46.399><c> normalize</c><00:00:47.719><c> the</c>

00:00:48.709 --> 00:00:48.719 align:start position:0%
then the second step is to normalize the
 

00:00:48.719 --> 00:00:50.600 align:start position:0%
then the second step is to normalize the
variances<00:00:49.410><c> so</c><00:00:49.680><c> notice</c><00:00:50.070><c> here</c><00:00:50.250><c> that</c><00:00:50.309><c> the</c>

00:00:50.600 --> 00:00:50.610 align:start position:0%
variances so notice here that the
 

00:00:50.610 --> 00:00:53.270 align:start position:0%
variances so notice here that the
feature<00:00:50.820><c> x1</c><00:00:51.300><c> has</c><00:00:52.020><c> a</c><00:00:52.050><c> much</c><00:00:52.350><c> larger</c><00:00:52.590><c> variance</c>

00:00:53.270 --> 00:00:53.280 align:start position:0%
feature x1 has a much larger variance
 

00:00:53.280 --> 00:00:55.970 align:start position:0%
feature x1 has a much larger variance
than<00:00:53.550><c> the</c><00:00:53.640><c> feature</c><00:00:53.820><c> x2</c><00:00:54.750><c> here</c><00:00:55.199><c> so</c><00:00:55.500><c> what</c><00:00:55.680><c> we</c><00:00:55.800><c> do</c>

00:00:55.970 --> 00:00:55.980 align:start position:0%
than the feature x2 here so what we do
 

00:00:55.980 --> 00:01:01.939 align:start position:0%
than the feature x2 here so what we do
is<00:00:56.160><c> set</c><00:00:56.690><c> Sigma</c><00:00:57.690><c> equals</c><00:00:58.320><c> 1</c><00:00:59.070><c> over</c><00:00:59.100><c> m</c><00:00:59.489><c> sum</c><00:01:00.300><c> of</c><00:01:00.539><c> X</c><00:01:01.410><c> I</c>

00:01:01.939 --> 00:01:01.949 align:start position:0%
is set Sigma equals 1 over m sum of X I
 

00:01:01.949 --> 00:01:05.630 align:start position:0%
is set Sigma equals 1 over m sum of X I
star<00:01:02.910><c> saw</c><00:01:03.210><c> two</c><00:01:03.510><c> I</c><00:01:03.809><c> guess</c><00:01:04.710><c> this</c><00:01:04.890><c> is</c><00:01:05.070><c> element</c>

00:01:05.630 --> 00:01:05.640 align:start position:0%
star saw two I guess this is element
 

00:01:05.640 --> 00:01:08.420 align:start position:0%
star saw two I guess this is element
wise<00:01:05.880><c> squaring</c><00:01:05.909><c> and</c><00:01:06.750><c> so</c><00:01:07.409><c> now</c><00:01:07.590><c> Sigma</c><00:01:08.070><c> squared</c>

00:01:08.420 --> 00:01:08.430 align:start position:0%
wise squaring and so now Sigma squared
 

00:01:08.430 --> 00:01:11.660 align:start position:0%
wise squaring and so now Sigma squared
is<00:01:08.580><c> a</c><00:01:08.909><c> vector</c><00:01:09.360><c> with</c><00:01:10.080><c> the</c><00:01:10.290><c> variances</c><00:01:11.040><c> of</c><00:01:11.070><c> each</c>

00:01:11.660 --> 00:01:11.670 align:start position:0%
is a vector with the variances of each
 

00:01:11.670 --> 00:01:13.789 align:start position:0%
is a vector with the variances of each
of<00:01:11.850><c> the</c><00:01:11.939><c> features</c><00:01:12.330><c> and</c><00:01:13.049><c> notice</c><00:01:13.500><c> we've</c><00:01:13.680><c> already</c>

00:01:13.789 --> 00:01:13.799 align:start position:0%
of the features and notice we've already
 

00:01:13.799 --> 00:01:16.789 align:start position:0%
of the features and notice we've already
subtracted<00:01:14.159><c> out</c><00:01:14.549><c> the</c><00:01:14.700><c> means</c><00:01:14.909><c> so</c><00:01:15.119><c> X</c><00:01:15.420><c> I</c><00:01:15.710><c> squared</c>

00:01:16.789 --> 00:01:16.799 align:start position:0%
subtracted out the means so X I squared
 

00:01:16.799 --> 00:01:18.920 align:start position:0%
subtracted out the means so X I squared
element<00:01:17.220><c> Y</c><00:01:17.340><c> squared</c><00:01:17.850><c> is</c><00:01:18.000><c> just</c><00:01:18.299><c> the</c><00:01:18.420><c> variances</c>

00:01:18.920 --> 00:01:18.930 align:start position:0%
element Y squared is just the variances
 

00:01:18.930 --> 00:01:21.499 align:start position:0%
element Y squared is just the variances
and<00:01:19.200><c> you</c><00:01:19.710><c> take</c><00:01:19.920><c> you</c><00:01:20.040><c> an</c><00:01:20.189><c> example</c><00:01:20.460><c> and</c><00:01:20.850><c> divide</c>

00:01:21.499 --> 00:01:21.509 align:start position:0%
and you take you an example and divide
 

00:01:21.509 --> 00:01:24.080 align:start position:0%
and you take you an example and divide
it<00:01:21.689><c> by</c><00:01:21.720><c> you</c><00:01:22.530><c> know</c><00:01:22.590><c> this</c><00:01:22.799><c> vector</c><00:01:23.250><c> Sigma</c><00:01:23.759><c> squared</c>

00:01:24.080 --> 00:01:24.090 align:start position:0%
it by you know this vector Sigma squared
 

00:01:24.090 --> 00:01:27.580 align:start position:0%
it by you know this vector Sigma squared
and<00:01:24.360><c> so</c><00:01:24.750><c> in</c><00:01:24.869><c> pictures</c><00:01:25.280><c> you</c><00:01:26.280><c> end</c><00:01:26.460><c> up</c><00:01:26.640><c> with</c><00:01:27.060><c> this</c>

00:01:27.580 --> 00:01:27.590 align:start position:0%
and so in pictures you end up with this
 

00:01:27.590 --> 00:01:31.640 align:start position:0%
and so in pictures you end up with this
where<00:01:28.590><c> now</c><00:01:28.799><c> the</c><00:01:29.220><c> variance</c><00:01:29.670><c> of</c><00:01:29.939><c> x1</c><00:01:30.659><c> and</c><00:01:30.960><c> x2</c><00:01:31.200><c> are</c>

00:01:31.640 --> 00:01:31.650 align:start position:0%
where now the variance of x1 and x2 are
 

00:01:31.650 --> 00:01:37.010 align:start position:0%
where now the variance of x1 and x2 are
both<00:01:33.380><c> equal</c><00:01:34.380><c> to</c><00:01:34.409><c> 1</c><00:01:34.740><c> oh</c><00:01:35.180><c> into</c><00:01:36.180><c> one</c><00:01:36.450><c> tip</c><00:01:36.750><c> if</c><00:01:36.930><c> you</c>

00:01:37.010 --> 00:01:37.020 align:start position:0%
both equal to 1 oh into one tip if you
 

00:01:37.020 --> 00:01:39.859 align:start position:0%
both equal to 1 oh into one tip if you
use<00:01:37.200><c> this</c><00:01:37.470><c> to</c><00:01:37.860><c> scale</c><00:01:38.729><c> your</c><00:01:39.000><c> training</c><00:01:39.659><c> data</c>

00:01:39.859 --> 00:01:39.869 align:start position:0%
use this to scale your training data
 

00:01:39.869 --> 00:01:43.940 align:start position:0%
use this to scale your training data
then<00:01:40.650><c> use</c><00:01:40.920><c> the</c><00:01:41.100><c> same</c><00:01:41.840><c> mu</c><00:01:42.840><c> and</c><00:01:43.140><c> Sigma</c><00:01:43.590><c> squared</c>

00:01:43.940 --> 00:01:43.950 align:start position:0%
then use the same mu and Sigma squared
 

00:01:43.950 --> 00:01:47.840 align:start position:0%
then use the same mu and Sigma squared
to<00:01:44.820><c> normalize</c><00:01:45.390><c> your</c><00:01:46.350><c> test</c><00:01:46.680><c> set</c><00:01:46.860><c> right</c><00:01:47.700><c> in</c>

00:01:47.840 --> 00:01:47.850 align:start position:0%
to normalize your test set right in
 

00:01:47.850 --> 00:01:50.300 align:start position:0%
to normalize your test set right in
particular<00:01:48.170><c> you</c><00:01:49.170><c> don't</c><00:01:49.380><c> want</c><00:01:49.590><c> to</c><00:01:49.710><c> normalize</c>

00:01:50.300 --> 00:01:50.310 align:start position:0%
particular you don't want to normalize
 

00:01:50.310 --> 00:01:51.590 align:start position:0%
particular you don't want to normalize
the<00:01:50.520><c> training</c><00:01:50.850><c> set</c><00:01:51.060><c> and</c><00:01:51.090><c> the</c><00:01:51.270><c> test</c><00:01:51.479><c> set</c>

00:01:51.590 --> 00:01:51.600 align:start position:0%
the training set and the test set
 

00:01:51.600 --> 00:01:54.050 align:start position:0%
the training set and the test set
differently<00:01:52.200><c> whatever</c><00:01:53.130><c> this</c><00:01:53.310><c> value</c><00:01:53.369><c> is</c><00:01:53.880><c> and</c>

00:01:54.050 --> 00:01:54.060 align:start position:0%
differently whatever this value is and
 

00:01:54.060 --> 00:01:56.690 align:start position:0%
differently whatever this value is and
whatever<00:01:54.329><c> this</c><00:01:54.540><c> value</c><00:01:54.930><c> is</c><00:01:55.140><c> use</c><00:01:55.740><c> them</c><00:01:56.009><c> in</c><00:01:56.219><c> you</c>

00:01:56.690 --> 00:01:56.700 align:start position:0%
whatever this value is use them in you
 

00:01:56.700 --> 00:01:59.330 align:start position:0%
whatever this value is use them in you
know<00:01:56.820><c> these</c><00:01:57.180><c> two</c><00:01:57.450><c> formulas</c><00:01:58.049><c> so</c><00:01:58.950><c> that</c><00:01:59.130><c> you</c>

00:01:59.330 --> 00:01:59.340 align:start position:0%
know these two formulas so that you
 

00:01:59.340 --> 00:02:01.310 align:start position:0%
know these two formulas so that you
scare<00:01:59.670><c> your</c><00:01:59.820><c> test</c><00:02:00.119><c> set</c><00:02:00.329><c> in</c><00:02:00.479><c> exactly</c><00:02:01.020><c> the</c><00:02:01.140><c> same</c>

00:02:01.310 --> 00:02:01.320 align:start position:0%
scare your test set in exactly the same
 

00:02:01.320 --> 00:02:03.230 align:start position:0%
scare your test set in exactly the same
way<00:02:01.530><c> rather</c><00:02:01.829><c> than</c><00:02:02.100><c> estimating</c><00:02:02.250><c> mu</c><00:02:02.820><c> and</c><00:02:02.969><c> Sigma</c>

00:02:03.230 --> 00:02:03.240 align:start position:0%
way rather than estimating mu and Sigma
 

00:02:03.240 --> 00:02:05.060 align:start position:0%
way rather than estimating mu and Sigma
squared<00:02:03.479><c> separately</c><00:02:03.960><c> on</c><00:02:04.380><c> your</c><00:02:04.560><c> training</c><00:02:04.799><c> set</c>

00:02:05.060 --> 00:02:05.070 align:start position:0%
squared separately on your training set
 

00:02:05.070 --> 00:02:05.730 align:start position:0%
squared separately on your training set
and<00:02:05.100><c> test</c>

00:02:05.730 --> 00:02:05.740 align:start position:0%
and test
 

00:02:05.740 --> 00:02:08.340 align:start position:0%
and test
because<00:02:06.670><c> you</c><00:02:06.790><c> want</c><00:02:07.030><c> your</c><00:02:07.180><c> data</c><00:02:07.450><c> both</c><00:02:07.990><c> training</c>

00:02:08.340 --> 00:02:08.350 align:start position:0%
because you want your data both training
 

00:02:08.350 --> 00:02:10.770 align:start position:0%
because you want your data both training
and<00:02:08.619><c> test</c><00:02:08.890><c> examples</c><00:02:09.399><c> to</c><00:02:09.580><c> go</c><00:02:09.729><c> through</c><00:02:09.970><c> the</c><00:02:10.479><c> same</c>

00:02:10.770 --> 00:02:10.780 align:start position:0%
and test examples to go through the same
 

00:02:10.780 --> 00:02:13.380 align:start position:0%
and test examples to go through the same
transformation<00:02:11.650><c> defined</c><00:02:12.610><c> by</c><00:02:12.819><c> the</c><00:02:12.880><c> same</c><00:02:13.180><c> Mew</c>

00:02:13.380 --> 00:02:13.390 align:start position:0%
transformation defined by the same Mew
 

00:02:13.390 --> 00:02:15.720 align:start position:0%
transformation defined by the same Mew
and<00:02:13.630><c> Sigma</c><00:02:13.930><c> squared</c><00:02:14.280><c> calculated</c><00:02:15.280><c> on</c><00:02:15.490><c> your</c>

00:02:15.720 --> 00:02:15.730 align:start position:0%
and Sigma squared calculated on your
 

00:02:15.730 --> 00:02:18.270 align:start position:0%
and Sigma squared calculated on your
training<00:02:16.180><c> data</c><00:02:16.360><c> so</c><00:02:16.900><c> why</c><00:02:17.170><c> do</c><00:02:17.230><c> we</c><00:02:17.470><c> do</c><00:02:17.740><c> this</c><00:02:17.950><c> why</c>

00:02:18.270 --> 00:02:18.280 align:start position:0%
training data so why do we do this why
 

00:02:18.280 --> 00:02:20.160 align:start position:0%
training data so why do we do this why
do<00:02:18.340><c> we</c><00:02:18.550><c> want</c><00:02:18.790><c> to</c><00:02:18.910><c> normalize</c><00:02:19.090><c> the</c><00:02:19.750><c> input</c>

00:02:20.160 --> 00:02:20.170 align:start position:0%
do we want to normalize the input
 

00:02:20.170 --> 00:02:22.260 align:start position:0%
do we want to normalize the input
features<00:02:20.620><c> recall</c><00:02:21.550><c> that</c><00:02:21.760><c> the</c><00:02:21.850><c> cost</c><00:02:22.060><c> function</c>

00:02:22.260 --> 00:02:22.270 align:start position:0%
features recall that the cost function
 

00:02:22.270 --> 00:02:25.830 align:start position:0%
features recall that the cost function
is<00:02:22.690><c> defined</c><00:02:23.110><c> as</c><00:02:23.739><c> written</c><00:02:24.190><c> on</c><00:02:24.430><c> top</c><00:02:24.940><c> right</c><00:02:25.180><c> it</c>

00:02:25.830 --> 00:02:25.840 align:start position:0%
is defined as written on top right it
 

00:02:25.840 --> 00:02:28.650 align:start position:0%
is defined as written on top right it
turns<00:02:26.110><c> out</c><00:02:26.350><c> that</c><00:02:26.680><c> if</c><00:02:26.980><c> you</c><00:02:27.310><c> use</c><00:02:27.660><c> unnormalized</c>

00:02:28.650 --> 00:02:28.660 align:start position:0%
turns out that if you use unnormalized
 

00:02:28.660 --> 00:02:31.199 align:start position:0%
turns out that if you use unnormalized
input<00:02:29.350><c> features</c><00:02:29.709><c> is</c><00:02:30.010><c> more</c><00:02:30.580><c> likely</c><00:02:30.910><c> that</c><00:02:31.090><c> your</c>

00:02:31.199 --> 00:02:31.209 align:start position:0%
input features is more likely that your
 

00:02:31.209 --> 00:02:33.000 align:start position:0%
input features is more likely that your
cost<00:02:31.450><c> function</c><00:02:31.630><c> will</c><00:02:32.140><c> look</c><00:02:32.350><c> like</c><00:02:32.500><c> this</c><00:02:32.739><c> at</c><00:02:32.980><c> a</c>

00:02:33.000 --> 00:02:33.010 align:start position:0%
cost function will look like this at a
 

00:02:33.010 --> 00:02:36.479 align:start position:0%
cost function will look like this at a
very<00:02:33.510><c> squished</c><00:02:34.510><c> out</c><00:02:34.720><c> bow</c><00:02:35.230><c> very</c><00:02:35.590><c> elongated</c>

00:02:36.479 --> 00:02:36.489 align:start position:0%
very squished out bow very elongated
 

00:02:36.489 --> 00:02:39.060 align:start position:0%
very squished out bow very elongated
cost<00:02:36.790><c> function</c><00:02:37.239><c> where</c><00:02:38.140><c> you</c><00:02:38.500><c> know</c><00:02:38.620><c> the</c><00:02:38.830><c> minimum</c>

00:02:39.060 --> 00:02:39.070 align:start position:0%
cost function where you know the minimum
 

00:02:39.070 --> 00:02:40.740 align:start position:0%
cost function where you know the minimum
you're<00:02:39.370><c> trying</c><00:02:39.610><c> to</c><00:02:39.700><c> find</c><00:02:39.940><c> this</c><00:02:40.150><c> maybe</c><00:02:40.450><c> over</c>

00:02:40.740 --> 00:02:40.750 align:start position:0%
you're trying to find this maybe over
 

00:02:40.750 --> 00:02:43.259 align:start position:0%
you're trying to find this maybe over
there<00:02:40.989><c> but</c><00:02:41.590><c> if</c><00:02:41.800><c> you're</c><00:02:41.920><c> beakers</c><00:02:42.670><c> are</c><00:02:42.910><c> on</c><00:02:43.030><c> very</c>

00:02:43.259 --> 00:02:43.269 align:start position:0%
there but if you're beakers are on very
 

00:02:43.269 --> 00:02:45.740 align:start position:0%
there but if you're beakers are on very
different<00:02:43.720><c> scales</c><00:02:44.080><c> say</c><00:02:44.920><c> the</c><00:02:45.070><c> feature</c><00:02:45.280><c> x1</c>

00:02:45.740 --> 00:02:45.750 align:start position:0%
different scales say the feature x1
 

00:02:45.750 --> 00:02:49.370 align:start position:0%
different scales say the feature x1
ranges<00:02:46.750><c> from</c><00:02:46.930><c> 1</c><00:02:47.200><c> to</c><00:02:47.440><c> 1000</c><00:02:48.250><c> and</c><00:02:48.489><c> the</c><00:02:48.640><c> feature</c><00:02:48.850><c> x2</c>

00:02:49.370 --> 00:02:49.380 align:start position:0%
ranges from 1 to 1000 and the feature x2
 

00:02:49.380 --> 00:02:53.759 align:start position:0%
ranges from 1 to 1000 and the feature x2
ranges<00:02:50.380><c> from</c><00:02:50.590><c> 0</c><00:02:51.310><c> to</c><00:02:51.550><c> 1</c><00:02:51.820><c> then</c><00:02:52.660><c> it</c><00:02:53.019><c> turns</c><00:02:53.530><c> out</c>

00:02:53.759 --> 00:02:53.769 align:start position:0%
ranges from 0 to 1 then it turns out
 

00:02:53.769 --> 00:02:56.460 align:start position:0%
ranges from 0 to 1 then it turns out
that<00:02:54.130><c> ratio</c><00:02:54.850><c> or</c><00:02:55.390><c> the</c><00:02:55.450><c> range</c><00:02:55.870><c> of</c><00:02:56.019><c> values</c><00:02:56.170><c> for</c>

00:02:56.460 --> 00:02:56.470 align:start position:0%
that ratio or the range of values for
 

00:02:56.470 --> 00:03:00.150 align:start position:0%
that ratio or the range of values for
the<00:02:56.800><c> parameters</c><00:02:57.510><c> w1</c><00:02:58.510><c> and</c><00:02:58.750><c> w2</c><00:02:59.260><c> will</c><00:02:59.860><c> end</c><00:03:00.010><c> up</c>

00:03:00.150 --> 00:03:00.160 align:start position:0%
the parameters w1 and w2 will end up
 

00:03:00.160 --> 00:03:02.340 align:start position:0%
the parameters w1 and w2 will end up
taking<00:03:00.370><c> on</c><00:03:00.610><c> very</c><00:03:00.910><c> different</c><00:03:01.300><c> values</c><00:03:01.690><c> and</c><00:03:01.989><c> so</c>

00:03:02.340 --> 00:03:02.350 align:start position:0%
taking on very different values and so
 

00:03:02.350 --> 00:03:05.370 align:start position:0%
taking on very different values and so
maybe<00:03:03.190><c> these</c><00:03:03.519><c> axes</c><00:03:04.150><c> should</c><00:03:04.300><c> be</c><00:03:04.390><c> w1</c><00:03:04.810><c> and</c><00:03:04.989><c> w2</c>

00:03:05.370 --> 00:03:05.380 align:start position:0%
maybe these axes should be w1 and w2
 

00:03:05.380 --> 00:03:07.710 align:start position:0%
maybe these axes should be w1 and w2
probe<00:03:05.560><c> intuition</c><00:03:06.130><c> I'll</c><00:03:06.250><c> plot</c><00:03:06.459><c> W</c><00:03:06.880><c> and</c><00:03:06.970><c> B</c><00:03:07.120><c> be</c><00:03:07.660><c> a</c>

00:03:07.710 --> 00:03:07.720 align:start position:0%
probe intuition I'll plot W and B be a
 

00:03:07.720 --> 00:03:09.180 align:start position:0%
probe intuition I'll plot W and B be a
cost<00:03:07.989><c> function</c><00:03:08.140><c> can</c><00:03:08.560><c> be</c><00:03:08.590><c> a</c><00:03:08.709><c> very</c><00:03:08.980><c> elongated</c>

00:03:09.180 --> 00:03:09.190 align:start position:0%
cost function can be a very elongated
 

00:03:09.190 --> 00:03:11.850 align:start position:0%
cost function can be a very elongated
bow<00:03:10.060><c> like</c><00:03:10.360><c> that</c><00:03:10.600><c> so</c><00:03:11.320><c> if</c><00:03:11.380><c> you</c><00:03:11.470><c> plot</c><00:03:11.650><c> the</c>

00:03:11.850 --> 00:03:11.860 align:start position:0%
bow like that so if you plot the
 

00:03:11.860 --> 00:03:14.940 align:start position:0%
bow like that so if you plot the
contours<00:03:12.190><c> of</c><00:03:12.610><c> this</c><00:03:12.850><c> function</c><00:03:13.680><c> you</c><00:03:14.680><c> can</c><00:03:14.799><c> have</c><00:03:14.920><c> a</c>

00:03:14.940 --> 00:03:14.950 align:start position:0%
contours of this function you can have a
 

00:03:14.950 --> 00:03:16.850 align:start position:0%
contours of this function you can have a
very<00:03:15.160><c> elongated</c><00:03:16.030><c> function</c><00:03:16.420><c> like</c><00:03:16.600><c> that</c>

00:03:16.850 --> 00:03:16.860 align:start position:0%
very elongated function like that
 

00:03:16.860 --> 00:03:19.259 align:start position:0%
very elongated function like that
whereas<00:03:17.860><c> if</c><00:03:18.130><c> you</c><00:03:18.250><c> normalize</c><00:03:18.730><c> the</c><00:03:18.910><c> features</c>

00:03:19.259 --> 00:03:19.269 align:start position:0%
whereas if you normalize the features
 

00:03:19.269 --> 00:03:22.410 align:start position:0%
whereas if you normalize the features
then<00:03:19.630><c> your</c><00:03:19.989><c> cost</c><00:03:20.530><c> function</c><00:03:21.090><c> well</c><00:03:22.090><c> on</c><00:03:22.239><c> average</c>

00:03:22.410 --> 00:03:22.420 align:start position:0%
then your cost function well on average
 

00:03:22.420 --> 00:03:25.199 align:start position:0%
then your cost function well on average
look<00:03:23.079><c> more</c><00:03:23.440><c> symmetric</c><00:03:24.370><c> and</c><00:03:24.549><c> if</c><00:03:24.910><c> you</c><00:03:25.090><c> are</c>

00:03:25.199 --> 00:03:25.209 align:start position:0%
look more symmetric and if you are
 

00:03:25.209 --> 00:03:26.880 align:start position:0%
look more symmetric and if you are
running<00:03:25.690><c> bathe</c><00:03:26.019><c> in</c><00:03:26.140><c> the</c><00:03:26.260><c> scent</c><00:03:26.410><c> on</c><00:03:26.620><c> the</c><00:03:26.680><c> cost</c>

00:03:26.880 --> 00:03:26.890 align:start position:0%
running bathe in the scent on the cost
 

00:03:26.890 --> 00:03:28.860 align:start position:0%
running bathe in the scent on the cost
function<00:03:27.070><c> like</c><00:03:27.400><c> the</c><00:03:27.519><c> one</c><00:03:27.670><c> on</c><00:03:27.820><c> the</c><00:03:27.940><c> left</c><00:03:28.180><c> then</c>

00:03:28.860 --> 00:03:28.870 align:start position:0%
function like the one on the left then
 

00:03:28.870 --> 00:03:29.970 align:start position:0%
function like the one on the left then
you<00:03:29.079><c> might</c><00:03:29.230><c> have</c><00:03:29.350><c> to</c><00:03:29.470><c> use</c><00:03:29.590><c> a</c><00:03:29.620><c> very</c><00:03:29.890><c> small</c>

00:03:29.970 --> 00:03:29.980 align:start position:0%
you might have to use a very small
 

00:03:29.980 --> 00:03:31.770 align:start position:0%
you might have to use a very small
learning<00:03:30.370><c> rate</c><00:03:30.760><c> because</c><00:03:31.060><c> over</c><00:03:31.269><c> here</c>

00:03:31.770 --> 00:03:31.780 align:start position:0%
learning rate because over here
 

00:03:31.780 --> 00:03:33.960 align:start position:0%
learning rate because over here
you<00:03:32.170><c> know</c><00:03:32.290><c> the</c><00:03:32.440><c> grading</c><00:03:32.769><c> descent</c><00:03:33.220><c> might</c><00:03:33.400><c> need</c>

00:03:33.960 --> 00:03:33.970 align:start position:0%
you know the grading descent might need
 

00:03:33.970 --> 00:03:35.970 align:start position:0%
you know the grading descent might need
a<00:03:34.030><c> lot</c><00:03:34.299><c> of</c><00:03:34.510><c> steps</c><00:03:34.840><c> to</c><00:03:35.230><c> oscillate</c><00:03:35.739><c> back</c><00:03:35.920><c> and</c>

00:03:35.970 --> 00:03:35.980 align:start position:0%
a lot of steps to oscillate back and
 

00:03:35.980 --> 00:03:39.390 align:start position:0%
a lot of steps to oscillate back and
forth<00:03:36.360><c> right</c><00:03:37.360><c> before</c><00:03:37.930><c> it</c><00:03:38.019><c> finally</c><00:03:38.290><c> finds</c><00:03:39.280><c> its</c>

00:03:39.390 --> 00:03:39.400 align:start position:0%
forth right before it finally finds its
 

00:03:39.400 --> 00:03:41.970 align:start position:0%
forth right before it finally finds its
way<00:03:39.430><c> to</c><00:03:39.549><c> the</c><00:03:39.730><c> minimum</c><00:03:40.150><c> whereas</c><00:03:41.049><c> if</c><00:03:41.620><c> you</c><00:03:41.829><c> have</c><00:03:41.950><c> a</c>

00:03:41.970 --> 00:03:41.980 align:start position:0%
way to the minimum whereas if you have a
 

00:03:41.980 --> 00:03:44.880 align:start position:0%
way to the minimum whereas if you have a
more<00:03:42.549><c> spherical</c><00:03:43.450><c> contours</c><00:03:44.320><c> than</c><00:03:44.560><c> wherever</c>

00:03:44.880 --> 00:03:44.890 align:start position:0%
more spherical contours than wherever
 

00:03:44.890 --> 00:03:47.520 align:start position:0%
more spherical contours than wherever
you<00:03:45.070><c> start</c><00:03:45.370><c> breathing</c><00:03:46.030><c> descents</c><00:03:46.690><c> can</c><00:03:46.930><c> pretty</c>

00:03:47.520 --> 00:03:47.530 align:start position:0%
you start breathing descents can pretty
 

00:03:47.530 --> 00:03:49.199 align:start position:0%
you start breathing descents can pretty
much<00:03:47.650><c> go</c><00:03:48.010><c> straight</c><00:03:48.340><c> to</c><00:03:48.519><c> the</c><00:03:48.640><c> minimum</c><00:03:49.000><c> you</c><00:03:49.150><c> can</c>

00:03:49.199 --> 00:03:49.209 align:start position:0%
much go straight to the minimum you can
 

00:03:49.209 --> 00:03:51.270 align:start position:0%
much go straight to the minimum you can
take<00:03:49.480><c> much</c><00:03:49.720><c> larger</c><00:03:50.140><c> steps</c><00:03:50.410><c> but</c><00:03:50.890><c> gradient</c>

00:03:51.270 --> 00:03:51.280 align:start position:0%
take much larger steps but gradient
 

00:03:51.280 --> 00:03:53.099 align:start position:0%
take much larger steps but gradient
descent<00:03:51.609><c> need</c><00:03:51.970><c> rather</c><00:03:52.299><c> than</c><00:03:52.570><c> needing</c><00:03:52.720><c> to</c>

00:03:53.099 --> 00:03:53.109 align:start position:0%
descent need rather than needing to
 

00:03:53.109 --> 00:03:55.500 align:start position:0%
descent need rather than needing to
oscillate<00:03:54.070><c> around</c><00:03:54.430><c> like</c><00:03:54.700><c> the</c><00:03:54.940><c> picture</c><00:03:55.239><c> on</c><00:03:55.390><c> the</c>

00:03:55.500 --> 00:03:55.510 align:start position:0%
oscillate around like the picture on the
 

00:03:55.510 --> 00:03:57.960 align:start position:0%
oscillate around like the picture on the
left<00:03:55.540><c> of</c><00:03:56.410><c> course</c><00:03:56.440><c> in</c><00:03:56.769><c> practice</c><00:03:56.920><c> W</c><00:03:57.640><c> is</c><00:03:57.730><c> a</c><00:03:57.790><c> high</c>

00:03:57.960 --> 00:03:57.970 align:start position:0%
left of course in practice W is a high
 

00:03:57.970 --> 00:04:00.780 align:start position:0%
left of course in practice W is a high
dimensional<00:03:58.480><c> vector</c><00:03:58.900><c> and</c><00:03:59.620><c> so</c><00:04:00.100><c> trying</c><00:04:00.459><c> to</c><00:04:00.519><c> plot</c>

00:04:00.780 --> 00:04:00.790 align:start position:0%
dimensional vector and so trying to plot
 

00:04:00.790 --> 00:04:02.910 align:start position:0%
dimensional vector and so trying to plot
this<00:04:01.000><c> in</c><00:04:01.209><c> 2d</c><00:04:01.630><c> doesn't</c><00:04:02.140><c> convey</c><00:04:02.470><c> all</c><00:04:02.709><c> the</c>

00:04:02.910 --> 00:04:02.920 align:start position:0%
this in 2d doesn't convey all the
 

00:04:02.920 --> 00:04:04.920 align:start position:0%
this in 2d doesn't convey all the
intuitions<00:04:03.519><c> correctly</c><00:04:04.150><c> but</c><00:04:04.600><c> the</c><00:04:04.720><c> rough</c>

00:04:04.920 --> 00:04:04.930 align:start position:0%
intuitions correctly but the rough
 

00:04:04.930 --> 00:04:06.720 align:start position:0%
intuitions correctly but the rough
intuition<00:04:05.530><c> that</c><00:04:05.769><c> your</c><00:04:05.920><c> cost</c><00:04:06.130><c> function</c><00:04:06.280><c> will</c>

00:04:06.720 --> 00:04:06.730 align:start position:0%
intuition that your cost function will
 

00:04:06.730 --> 00:04:08.490 align:start position:0%
intuition that your cost function will
be<00:04:06.850><c> you</c><00:04:07.090><c> know</c><00:04:07.120><c> more</c><00:04:07.420><c> round</c><00:04:07.690><c> and</c><00:04:08.049><c> easier</c><00:04:08.470><c> to</c>

00:04:08.490 --> 00:04:08.500 align:start position:0%
be you know more round and easier to
 

00:04:08.500 --> 00:04:09.620 align:start position:0%
be you know more round and easier to
optimize

00:04:09.620 --> 00:04:09.630 align:start position:0%
optimize
 

00:04:09.630 --> 00:04:11.810 align:start position:0%
optimize
your<00:04:09.840><c> features</c><00:04:10.260><c> are</c><00:04:10.470><c> all</c><00:04:10.650><c> on</c><00:04:10.830><c> similar</c><00:04:11.430><c> skills</c>

00:04:11.810 --> 00:04:11.820 align:start position:0%
your features are all on similar skills
 

00:04:11.820 --> 00:04:15.290 align:start position:0%
your features are all on similar skills
not<00:04:12.570><c> all</c><00:04:12.810><c> not</c><00:04:13.170><c> from</c><00:04:13.440><c> 1</c><00:04:14.040><c> to</c><00:04:14.160><c> 1000</c><00:04:14.760><c> 0</c><00:04:14.880><c> to</c><00:04:15.090><c> 1</c><00:04:15.270><c> but</c>

00:04:15.290 --> 00:04:15.300 align:start position:0%
not all not from 1 to 1000 0 to 1 but
 

00:04:15.300 --> 00:04:18.440 align:start position:0%
not all not from 1 to 1000 0 to 1 but
mostly<00:04:15.840><c> from</c><00:04:16.170><c> your</c><00:04:16.320><c> minus</c><00:04:16.800><c> 1</c><00:04:17.010><c> to</c><00:04:17.220><c> 1</c><00:04:17.250><c> or</c><00:04:17.790><c> with</c>

00:04:18.440 --> 00:04:18.450 align:start position:0%
mostly from your minus 1 to 1 or with
 

00:04:18.450 --> 00:04:20.390 align:start position:0%
mostly from your minus 1 to 1 or with
about<00:04:18.989><c> similar</c><00:04:19.440><c> variants</c><00:04:19.830><c> as</c><00:04:19.980><c> each</c><00:04:20.160><c> other</c>

00:04:20.390 --> 00:04:20.400 align:start position:0%
about similar variants as each other
 

00:04:20.400 --> 00:04:22.850 align:start position:0%
about similar variants as each other
that<00:04:20.940><c> just</c><00:04:21.180><c> makes</c><00:04:21.390><c> your</c><00:04:21.600><c> cost</c><00:04:22.200><c> function</c><00:04:22.620><c> J</c>

00:04:22.850 --> 00:04:22.860 align:start position:0%
that just makes your cost function J
 

00:04:22.860 --> 00:04:25.550 align:start position:0%
that just makes your cost function J
easier<00:04:23.160><c> and</c><00:04:23.700><c> faster</c><00:04:23.910><c> to</c><00:04:24.240><c> optimize</c><00:04:24.900><c> in</c>

00:04:25.550 --> 00:04:25.560 align:start position:0%
easier and faster to optimize in
 

00:04:25.560 --> 00:04:29.030 align:start position:0%
easier and faster to optimize in
practice<00:04:26.070><c> if</c><00:04:26.370><c> one</c><00:04:26.640><c> feature</c><00:04:26.910><c> say</c><00:04:27.690><c> x1</c><00:04:28.040><c> ranges</c>

00:04:29.030 --> 00:04:29.040 align:start position:0%
practice if one feature say x1 ranges
 

00:04:29.040 --> 00:04:32.000 align:start position:0%
practice if one feature say x1 ranges
from<00:04:29.190><c> 0</c><00:04:29.490><c> to</c><00:04:29.670><c> 1</c><00:04:29.910><c> and</c><00:04:29.940><c> x2</c><00:04:30.540><c> ranges</c><00:04:31.230><c> from</c><00:04:31.350><c> minus</c><00:04:31.800><c> 1</c>

00:04:32.000 --> 00:04:32.010 align:start position:0%
from 0 to 1 and x2 ranges from minus 1
 

00:04:32.010 --> 00:04:35.480 align:start position:0%
from 0 to 1 and x2 ranges from minus 1
to<00:04:32.040><c> 1</c><00:04:32.250><c> and</c><00:04:32.640><c> x3</c><00:04:33.390><c> ranges</c><00:04:34.020><c> from</c><00:04:34.110><c> 1</c><00:04:34.350><c> to</c><00:04:34.530><c> 2</c><00:04:34.710><c> you</c><00:04:35.370><c> know</c>

00:04:35.480 --> 00:04:35.490 align:start position:0%
to 1 and x3 ranges from 1 to 2 you know
 

00:04:35.490 --> 00:04:37.700 align:start position:0%
to 1 and x3 ranges from 1 to 2 you know
these<00:04:35.730><c> are</c><00:04:35.940><c> fairly</c><00:04:36.210><c> similar</c><00:04:36.630><c> ranges</c><00:04:37.230><c> so</c><00:04:37.500><c> this</c>

00:04:37.700 --> 00:04:37.710 align:start position:0%
these are fairly similar ranges so this
 

00:04:37.710 --> 00:04:39.650 align:start position:0%
these are fairly similar ranges so this
will<00:04:37.860><c> work</c><00:04:37.980><c> just</c><00:04:38.250><c> fine</c><00:04:38.490><c> is</c><00:04:38.790><c> when</c><00:04:39.390><c> there</c><00:04:39.630><c> are</c>

00:04:39.650 --> 00:04:39.660 align:start position:0%
will work just fine is when there are
 

00:04:39.660 --> 00:04:41.510 align:start position:0%
will work just fine is when there are
dramatically<00:04:40.320><c> different</c><00:04:40.440><c> ranges</c><00:04:41.130><c> like</c><00:04:41.280><c> ones</c>

00:04:41.510 --> 00:04:41.520 align:start position:0%
dramatically different ranges like ones
 

00:04:41.520 --> 00:04:43.100 align:start position:0%
dramatically different ranges like ones
from<00:04:41.700><c> one</c><00:04:41.880><c> to</c><00:04:42.030><c> a</c><00:04:42.060><c> thousand</c><00:04:42.630><c> and</c><00:04:42.750><c> another</c><00:04:42.960><c> from</c>

00:04:43.100 --> 00:04:43.110 align:start position:0%
from one to a thousand and another from
 

00:04:43.110 --> 00:04:44.960 align:start position:0%
from one to a thousand and another from
zero<00:04:43.350><c> to</c><00:04:43.500><c> one</c><00:04:43.710><c> that</c><00:04:44.280><c> that</c><00:04:44.430><c> really</c><00:04:44.610><c> hurts</c><00:04:44.910><c> the</c>

00:04:44.960 --> 00:04:44.970 align:start position:0%
zero to one that that really hurts the
 

00:04:44.970 --> 00:04:47.180 align:start position:0%
zero to one that that really hurts the
optimization<00:04:45.630><c> algorithm</c><00:04:45.900><c> but</c><00:04:46.770><c> by</c><00:04:46.920><c> just</c>

00:04:47.180 --> 00:04:47.190 align:start position:0%
optimization algorithm but by just
 

00:04:47.190 --> 00:04:49.460 align:start position:0%
optimization algorithm but by just
setting<00:04:47.340><c> all</c><00:04:47.700><c> of</c><00:04:47.850><c> them</c><00:04:47.970><c> to</c><00:04:48.150><c> zero</c><00:04:48.510><c> mean</c><00:04:48.810><c> and</c><00:04:49.110><c> say</c>

00:04:49.460 --> 00:04:49.470 align:start position:0%
setting all of them to zero mean and say
 

00:04:49.470 --> 00:04:51.740 align:start position:0%
setting all of them to zero mean and say
variance<00:04:50.280><c> 1</c><00:04:50.520><c> like</c><00:04:50.790><c> we</c><00:04:50.940><c> did</c><00:04:51.090><c> in</c><00:04:51.210><c> the</c><00:04:51.300><c> last</c><00:04:51.480><c> slide</c>

00:04:51.740 --> 00:04:51.750 align:start position:0%
variance 1 like we did in the last slide
 

00:04:51.750 --> 00:04:53.240 align:start position:0%
variance 1 like we did in the last slide
that<00:04:51.780><c> just</c><00:04:52.050><c> guarantees</c><00:04:52.740><c> that</c><00:04:52.770><c> all</c><00:04:53.100><c> your</c>

00:04:53.240 --> 00:04:53.250 align:start position:0%
that just guarantees that all your
 

00:04:53.250 --> 00:04:55.430 align:start position:0%
that just guarantees that all your
features<00:04:53.640><c> are</c><00:04:53.730><c> similar</c><00:04:54.030><c> scale</c><00:04:54.510><c> and</c><00:04:54.780><c> will</c>

00:04:55.430 --> 00:04:55.440 align:start position:0%
features are similar scale and will
 

00:04:55.440 --> 00:04:57.230 align:start position:0%
features are similar scale and will
usually<00:04:55.680><c> help</c><00:04:56.130><c> your</c><00:04:56.370><c> learning</c><00:04:56.700><c> Avrum</c><00:04:57.000><c> run</c>

00:04:57.230 --> 00:04:57.240 align:start position:0%
usually help your learning Avrum run
 

00:04:57.240 --> 00:05:00.020 align:start position:0%
usually help your learning Avrum run
faster<00:04:57.750><c> so</c><00:04:58.350><c> if</c><00:04:58.650><c> your</c><00:04:58.830><c> input</c><00:04:59.070><c> features</c><00:04:59.610><c> came</c>

00:05:00.020 --> 00:05:00.030 align:start position:0%
faster so if your input features came
 

00:05:00.030 --> 00:05:01.940 align:start position:0%
faster so if your input features came
from<00:05:00.330><c> very</c><00:05:00.660><c> different</c><00:05:01.050><c> scales</c><00:05:01.350><c> maybe</c><00:05:01.710><c> some</c>

00:05:01.940 --> 00:05:01.950 align:start position:0%
from very different scales maybe some
 

00:05:01.950 --> 00:05:03.830 align:start position:0%
from very different scales maybe some
features<00:05:02.310><c> are</c><00:05:02.520><c> from</c><00:05:02.640><c> 0</c><00:05:02.790><c> to</c><00:05:02.940><c> 1</c><00:05:03.120><c> some</c><00:05:03.420><c> from</c><00:05:03.570><c> 1</c><00:05:03.720><c> to</c>

00:05:03.830 --> 00:05:03.840 align:start position:0%
features are from 0 to 1 some from 1 to
 

00:05:03.840 --> 00:05:06.470 align:start position:0%
features are from 0 to 1 some from 1 to
1000<00:05:04.410><c> then</c><00:05:04.920><c> it's</c><00:05:05.070><c> important</c><00:05:05.550><c> to</c><00:05:05.580><c> normalize</c>

00:05:06.470 --> 00:05:06.480 align:start position:0%
1000 then it's important to normalize
 

00:05:06.480 --> 00:05:08.990 align:start position:0%
1000 then it's important to normalize
your<00:05:06.750><c> features</c><00:05:07.200><c> if</c><00:05:08.160><c> your</c><00:05:08.310><c> features</c><00:05:08.490><c> came</c><00:05:08.850><c> in</c>

00:05:08.990 --> 00:05:09.000 align:start position:0%
your features if your features came in
 

00:05:09.000 --> 00:05:10.610 align:start position:0%
your features if your features came in
on<00:05:09.150><c> similar</c><00:05:09.480><c> skills</c><00:05:09.750><c> in</c><00:05:09.960><c> this</c><00:05:10.080><c> step</c><00:05:10.290><c> is</c><00:05:10.440><c> less</c>

00:05:10.610 --> 00:05:10.620 align:start position:0%
on similar skills in this step is less
 

00:05:10.620 --> 00:05:12.800 align:start position:0%
on similar skills in this step is less
important<00:05:11.250><c> although</c><00:05:11.850><c> performing</c><00:05:12.540><c> this</c><00:05:12.630><c> type</c>

00:05:12.800 --> 00:05:12.810 align:start position:0%
important although performing this type
 

00:05:12.810 --> 00:05:14.960 align:start position:0%
important although performing this type
of<00:05:12.870><c> normalization</c><00:05:13.260><c> pretty</c><00:05:14.160><c> much</c><00:05:14.370><c> never</c><00:05:14.610><c> does</c>

00:05:14.960 --> 00:05:14.970 align:start position:0%
of normalization pretty much never does
 

00:05:14.970 --> 00:05:17.420 align:start position:0%
of normalization pretty much never does
any<00:05:15.150><c> harm</c><00:05:15.450><c> so</c><00:05:15.720><c> often</c><00:05:16.200><c> you</c><00:05:16.680><c> know</c><00:05:16.740><c> do</c><00:05:16.950><c> it</c><00:05:16.980><c> anyway</c>

00:05:17.420 --> 00:05:17.430 align:start position:0%
any harm so often you know do it anyway
 

00:05:17.430 --> 00:05:19.490 align:start position:0%
any harm so often you know do it anyway
if<00:05:17.610><c> I'm</c><00:05:17.760><c> not</c><00:05:18.030><c> sure</c><00:05:18.330><c> whether</c><00:05:18.870><c> or</c><00:05:18.990><c> not</c><00:05:19.230><c> they</c><00:05:19.410><c> were</c>

00:05:19.490 --> 00:05:19.500 align:start position:0%
if I'm not sure whether or not they were
 

00:05:19.500 --> 00:05:21.650 align:start position:0%
if I'm not sure whether or not they were
help<00:05:19.710><c> with</c><00:05:19.980><c> speeding</c><00:05:20.820><c> up</c><00:05:21.030><c> training</c><00:05:21.390><c> for</c><00:05:21.600><c> your</c>

00:05:21.650 --> 00:05:21.660 align:start position:0%
help with speeding up training for your
 

00:05:21.660 --> 00:05:24.560 align:start position:0%
help with speeding up training for your
algorithm<00:05:22.170><c> so</c><00:05:23.040><c> that's</c><00:05:23.310><c> it</c><00:05:23.520><c> for</c><00:05:23.760><c> normalizing</c>

00:05:24.560 --> 00:05:24.570 align:start position:0%
algorithm so that's it for normalizing
 

00:05:24.570 --> 00:05:26.720 align:start position:0%
algorithm so that's it for normalizing
your<00:05:24.600><c> input</c><00:05:25.080><c> features</c><00:05:25.470><c> next</c><00:05:26.190><c> let's</c><00:05:26.550><c> keep</c>

00:05:26.720 --> 00:05:26.730 align:start position:0%
your input features next let's keep
 

00:05:26.730 --> 00:05:28.430 align:start position:0%
your input features next let's keep
talking<00:05:26.940><c> about</c><00:05:27.240><c> ways</c><00:05:27.540><c> to</c><00:05:27.900><c> speed</c><00:05:28.170><c> up</c><00:05:28.200><c> the</c>

00:05:28.430 --> 00:05:28.440 align:start position:0%
talking about ways to speed up the
 

00:05:28.440 --> 00:05:31.580 align:start position:0%
talking about ways to speed up the
training<00:05:28.710><c> of</c><00:05:28.980><c> your</c><00:05:29.160><c> new</c><00:05:29.310><c> network</c>

