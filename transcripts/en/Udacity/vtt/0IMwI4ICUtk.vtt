WEBVTT
Kind: captions
Language: en

00:00:00.470 --> 00:00:02.780
So, how ideal is an ideal cache?

00:00:02.780 --> 00:00:04.765
Does ideal compare to real?

00:00:04.765 --> 00:00:09.210
I want to go over some facts that
help justify the ideal cache model.

00:00:09.210 --> 00:00:12.820
Remember that the ideal cache model
seems to have some super powers.

00:00:12.820 --> 00:00:14.440
So a technical question is,

00:00:14.440 --> 00:00:17.650
are the assumptions of the ideal
cache model too strong?

00:00:17.650 --> 00:00:21.069
What I want to do now is go over
the justification from the original

00:00:21.069 --> 00:00:23.602
cacheable VS model paper,
which was by Frigo,

00:00:23.602 --> 00:00:28.187
et al, and appeared in the Foundations
of Computer Science, or FOCS, in 1999.

00:00:28.187 --> 00:00:31.650
The first fact is about
the assumption of optimal replacement.

00:00:31.650 --> 00:00:33.730
It's a lemma, and here's what it says.

00:00:33.730 --> 00:00:36.860
Suppose you take your algorithm and
you count the number of cache misses it

00:00:36.860 --> 00:00:40.730
incurs on a machine with
an LRU replacement policy.

00:00:40.730 --> 00:00:43.560
Now suppose you're given
a different machine.

00:00:43.560 --> 00:00:47.800
This machine has the same line size,
but it only has half the cache.

00:00:47.800 --> 00:00:50.490
It also implements an optimal
replacement policy,

00:00:50.490 --> 00:00:52.640
rather than an LRU policy.

00:00:52.640 --> 00:00:55.290
In other words,
it has a better replacement policy, but

00:00:55.290 --> 00:00:57.120
it has less space.

00:00:57.120 --> 00:01:00.140
It's both slightly better,
being optimal, but also slightly worse,

00:01:00.140 --> 00:01:01.480
having less space.

00:01:01.480 --> 00:01:05.180
The lemma says that the number of
transfer on the LRU machine will be

00:01:05.180 --> 00:01:09.010
within a factor of 2 of the number of
transfers on this slightly better or

00:01:09.010 --> 00:01:11.490
slightly worse optimal machine.

00:01:11.490 --> 00:01:13.250
Now, I know what you might be thinking.

00:01:13.250 --> 00:01:14.200
Huh?

00:01:14.200 --> 00:01:15.338
What the?

00:01:15.338 --> 00:01:19.254
[SOUND] At first glance,
this lemma may seem a bit odd, but

00:01:19.254 --> 00:01:22.119
here's a very natural interpretation.

00:01:22.119 --> 00:01:24.989
Suppose you design an algorithm
assuming optimal replacement,

00:01:24.989 --> 00:01:27.340
which is what we're going to be doing.

00:01:27.340 --> 00:01:32.080
Then the performance of that algorithm
on a more realistic LRU machine will be

00:01:32.080 --> 00:01:34.170
asymptotically close.

00:01:34.170 --> 00:01:35.100
In other words,

00:01:35.100 --> 00:01:39.158
optimal replacement isn't as strong
an assumption as you might think.

00:01:39.158 --> 00:01:43.360
Now, there's a more specific, technical
requirement which is one of regularity.

00:01:43.360 --> 00:01:49.330
We say QOPT is regular if it's big
O of QOPT with twice the cache.

00:01:49.330 --> 00:01:51.310
In other words,
let's say you design an algorithm and

00:01:51.310 --> 00:01:57.160
you find out what QOPT is on a machine
with an optimal replacement policy.

00:01:57.160 --> 00:01:58.200
What you calculate for

00:01:58.200 --> 00:02:03.470
QOPT is regular if QOPT is big
O of QOPT with twice the cache.

00:02:03.470 --> 00:02:07.070
So, if you can show that QOPT
is regular in this sense,

00:02:07.070 --> 00:02:10.780
then QLRU will be proportional to QOPT.

