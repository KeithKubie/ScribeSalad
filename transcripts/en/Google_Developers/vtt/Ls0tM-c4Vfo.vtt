WEBVTT
Kind: captions
Language: en

00:00:07.370 --> 00:00:14.190
&gt;&gt;Bill Buzbee: Welcome. My name is Bill Buzbee,
and I am here with Ben Cheng. We are with

00:00:14.190 --> 00:00:18.110
Google's Android team and are going to talk
to you today about the new JIT compiler that

00:00:18.110 --> 00:00:25.110
was announced this morning.
Now -- Oops. Wrong direction here.

00:00:25.890 --> 00:00:31.210
So we've got a live Google Wave going on in
this session, so if you have a browser handy,

00:00:31.210 --> 00:00:38.210
hop on over to bit.ly/blzjnf.
&gt;&gt;&gt; (Off mic)

00:00:46.129 --> 00:00:53.129
&gt;&gt;Bill Buzbee: Okay. So the way this is going
to work today, we are going to break this

00:00:59.030 --> 00:01:04.010
talk into two parts. In the beginning, I am
going to talk a bit about JIT compilers in

00:01:04.010 --> 00:01:09.640
general. Why, in particular, we chose this
style of JIT compiler for portable Android

00:01:09.640 --> 00:01:14.250
devices, what kind of performance you can
expect to see out of the JIT, and then where

00:01:14.250 --> 00:01:18.830
we expect to take this JIT in the future.
Then we're going to shift gears a little bit,

00:01:18.830 --> 00:01:23.750
and as you know, this is an open source project,
so all the source code for the JIT is going

00:01:23.750 --> 00:01:28.440
to be part of the Android open source release.
And with that source code you will be able

00:01:28.440 --> 00:01:34.500
to build some specially instrumented and profiling
versions of the JIT to enable to you do some

00:01:34.500 --> 00:01:38.710
more interesting things about seeing how the
JIT interacts with your application. And Ben

00:01:38.710 --> 00:01:43.520
is going to talk more about that. He will
dig into performance case studies, show you

00:01:43.520 --> 00:01:47.750
how to profile with the JIT, and then talk
to you about one of the features that I think

00:01:47.750 --> 00:01:52.230
is particularly cool with the JIT, something
a normal user wouldn't use but as developers

00:01:52.230 --> 00:01:58.300
you might be interested in, and that's the
self-verification mode that the JIT has itself.

00:01:58.300 --> 00:02:02.600
Now, if you are going to write a program for
Android, you are most likely going to write

00:02:02.600 --> 00:02:07.380
it in the Java programming language and then
push the source code through the SDK. And

00:02:07.380 --> 00:02:12.310
what pops out at the end is an executable
targeted to the Dalvik virtual machine.

00:02:12.310 --> 00:02:18.640
Now, as they mentioned this morning in the
keynote, one of the great things about targeting

00:02:18.640 --> 00:02:23.249
a virtual machine is that you can just simply
move an implementation of that virtual machine

00:02:23.249 --> 00:02:27.420
to different physical devices with different
underlying processors, different hardware

00:02:27.420 --> 00:02:30.319
capabilities, but the application should still
run.

00:02:30.319 --> 00:02:35.689
I am not going to go into a lot of detail
about what Dalvik is, our particular virtual

00:02:35.689 --> 00:02:41.209
machine, but I will point you to a talk that
was done in Google I/O two years ago. Follow

00:02:41.209 --> 00:02:46.430
this link, and Dan Bornstein gave a great
talk about Dalvik, why we chose it and what

00:02:46.430 --> 00:02:49.459
are the features.
But I do want to bring out a couple of key

00:02:49.459 --> 00:02:53.090
features of Dalvik that are important in this
context.

00:02:53.090 --> 00:02:59.299
Number one, Dalvik is an extremely compact
representation for an executable. And that

00:02:59.299 --> 00:03:04.950
was so important for us with a mobile device
with limited resources.

00:03:04.950 --> 00:03:10.609
Second, it accomplished that largely through
an emphasis on sharing code and data.

00:03:10.609 --> 00:03:17.609
And then finally, the Dalvik environment has
a security sandbox system where we process

00:03:18.629 --> 00:03:25.290
sandbox security system that enables you to
make sure that information doesn't bleed from

00:03:25.290 --> 00:03:28.760
one process to another when you don't want
it to. And that becomes important when we

00:03:28.760 --> 00:03:34.329
are thinking about JITs.
Now, at the center of every Dalvik virtual

00:03:34.329 --> 00:03:39.129
machine implementation is an instruction-at-a-time
interpreter.

00:03:39.129 --> 00:03:44.370
Interpreters, the way they work, they will
go out and fetch one Dalvik instruction at

00:03:44.370 --> 00:03:48.829
a time. We call them Dalvik byte codes, pull
the instruction apart, see what it is, that's

00:03:48.829 --> 00:03:53.919
called the decode phase, and then go ahead
and interpret it or execute it.

00:03:53.919 --> 00:03:58.669
And that execution is done by using actually
the host instructions on the host processor.

00:03:58.669 --> 00:04:04.389
But what you have in effect there with interpretation
is an extra stage of execution. So you have

00:04:04.389 --> 00:04:08.650
to pull up the byte code, figure out what
it is, then use host instructions to carry

00:04:08.650 --> 00:04:13.790
it out, and the CPU will pick up the host
instructions and execute them.

00:04:13.790 --> 00:04:19.620
And that extra level of evaluation is what
gives interpreters a bit of a bad name for

00:04:19.620 --> 00:04:24.080
being slow. I mean, there's some great reasons
why you would want to use an interpreter,

00:04:24.080 --> 00:04:31.080
but the down side is that they are often a
bit slower than natively compiled code.

00:04:31.479 --> 00:04:37.780
Now, we didn't that I that -- We think that
sometimes this interpretation gets more of

00:04:37.780 --> 00:04:41.810
a bad rap than it really should in an Android
system, and there are several reasons for

00:04:41.810 --> 00:04:44.530
that.
First of all, our interpreter is really, really

00:04:44.530 --> 00:04:50.810
fast. It's a very well done interpreter.
We had one of our partners benchmark our Dalvik

00:04:50.810 --> 00:04:56.300
interpreter against a traditional Java interpreter,
and they told us that the Dalvik interpreter

00:04:56.300 --> 00:05:00.180
was roughly twice as fast, which we were happy
to hear.

00:05:00.180 --> 00:05:05.360
But the other and perhaps more important reason
is that not everything -- when your application

00:05:05.360 --> 00:05:10.990
is running on an Android system, it's not
really in interpretation the whole time. The

00:05:10.990 --> 00:05:16.370
system itself has already been natively compiled
and optimized. A lot of the libraries, the

00:05:16.370 --> 00:05:21.680
really key libraries, graphics and other things
that you need to run fast, are done in native

00:05:21.680 --> 00:05:26.919
code already, so it's really just sometimes
a smallish amount of code that's actually

00:05:26.919 --> 00:05:32.270
being interpreted when your program runs.
Ben recently did a little bit of a study with

00:05:32.270 --> 00:05:37.280
his phone running over the weekend and found
in typical use, less than a third of the total

00:05:37.280 --> 00:05:41.770
execution time was actually spent interpreted.
Most of the time was spent running code that

00:05:41.770 --> 00:05:47.840
was already natively compiled and optimized.
And the upshot of that is for most applications,

00:05:47.840 --> 00:05:52.069
the interpreter performance is just fine.
And in fact, it's really a benefit there,

00:05:52.069 --> 00:05:58.110
because an interpreted environment typically
requires less memory -- a smaller memory footprint

00:05:58.110 --> 00:06:02.379
than a natively compiled one. And we will
talk a little bit more about that in general,

00:06:02.379 --> 00:06:08.780
but just the high-order bit here is that the
Dalvik byte codes are very expressive for

00:06:08.780 --> 00:06:13.090
their size. So if you translate a Dalvik byte
code into say underlying ARM instructions,

00:06:13.090 --> 00:06:18.659
you get a significant code expansion.
So keeping it Dalvik is actually a good idea.

00:06:18.659 --> 00:06:25.409
But this good enough for most applications
doesn't mean it's perfect. For some applications,

00:06:25.409 --> 00:06:30.830
you really, really do feel the pain of interpretation.
Applications in which you do a lot of computation.

00:06:30.830 --> 00:06:36.870
And that gets painful, because you experience
the slowdown of the interpreter, which is

00:06:36.870 --> 00:06:41.939
often on the order of five to ten times.
Now, we have had two strategies in play --

00:06:41.939 --> 00:06:46.819
 or two strategies planned to deal with this
slowdown that computation intensive programs

00:06:46.819 --> 00:06:51.610
would face. The first of those, the result
we came out last year with the release of

00:06:51.610 --> 00:06:57.250
the Android NDK or native development kit.
This was a software development kit that makes

00:06:57.250 --> 00:07:04.139
it easier to isolate the compute intensive
portions of your program, rewrite those in

00:07:04.139 --> 00:07:09.469
a natively compiled language and then call
them from your Android application.

00:07:09.469 --> 00:07:14.530
The other part of the solution is what we
have announced today, and that's the just-in-time

00:07:14.530 --> 00:07:18.669
compiler.
A just-in-time compiler still has an interpreter

00:07:18.669 --> 00:07:24.240
involved. The interpreter will interpret your
program until it identifies what's the most

00:07:24.240 --> 00:07:28.689
compute intensive part of it. What's the really
hot chunks of your program. And then it will

00:07:28.689 --> 00:07:34.189
pull those out, compile them and optimize
them into native code so the next time you

00:07:34.189 --> 00:07:37.810
invoke that section of code, you are not doing
interpretation anymore, you are just doing

00:07:37.810 --> 00:07:43.919
direct execution of the native code.
Now, putting a JIT on Android has been something

00:07:43.919 --> 00:07:50.360
we have talked about for a long time internally,
but the big question was what kind of a JIT

00:07:50.360 --> 00:07:55.860
can we fit into an Android system?
As it turns out, the JIT design space is pretty

00:07:55.860 --> 00:08:02.110
large. I mean, with the popularity of Java,
most people now are familiar with JITs. And

00:08:02.110 --> 00:08:06.979
generally, a particular style of JIT, but
actually, there's quite a broad design field.

00:08:06.979 --> 00:08:12.319
The way we like to think of it is you can
break it down into -- break the JIT design

00:08:12.319 --> 00:08:18.499
down into two axes. Along one axis would be
what does it mean for just-in-time. When do

00:08:18.499 --> 00:08:23.689
you do the compilation? You could do it when
you first install the application or maybe

00:08:23.689 --> 00:08:29.590
you do it the first time a method is called
or when you page in some code off of disk.

00:08:29.590 --> 00:08:35.800
The other axes is what is the unit of compilation?
Do you compile the whole program, a whole

00:08:35.800 --> 00:08:42.490
shared library, just a physical page of code?
Or maybe you do a method or a string of instructions

00:08:42.490 --> 00:08:46.670
or even a single instruction worth of code
at once.

00:08:46.670 --> 00:08:52.260
Looking back over the last 20 years or so
with just-in-time compilers and dynamic translation

00:08:52.260 --> 00:08:58.500
systems, you could actually pretty much fill
in every square of that matrix about the chunk

00:08:58.500 --> 00:09:03.040
of thing were you compiling and when it was
you were doing the compilation.

00:09:03.040 --> 00:09:08.019
And it's not really the case that any one
combination is best. Each combination had

00:09:08.019 --> 00:09:12.959
a set of characteristics that were good in
some situations, and bad in another. And what

00:09:12.959 --> 00:09:17.180
our trick -- the trick for because to find
the combination that worked really well in

00:09:17.180 --> 00:09:23.170
a portable memory constrained device.
So our key requirements going into this process,

00:09:23.170 --> 00:09:29.450
we needed to find a JIT system that could
deliver performance using a very small amount

00:09:29.450 --> 00:09:32.260
of memory.
From all the talks today you will hear about

00:09:32.260 --> 00:09:36.380
how important memory is on these small devices,
and I think you know this. So we couldn't

00:09:36.380 --> 00:09:40.510
have a JIT that wasted a lot of memory or
took too much.

00:09:40.510 --> 00:09:46.920
The next, it had to co-exist with this processor
container security model. And this -- I won't

00:09:46.920 --> 00:09:51.790
get into this too much, but a lot of JIT styles
would have information being bled between

00:09:51.790 --> 00:09:57.230
processes, and we needed to avoid that.
And finally, the last two ones are something

00:09:57.230 --> 00:10:02.540
that we considered really important for this
type of device. We wanted the performance

00:10:02.540 --> 00:10:08.240
that were going to be delivered by the just-in-time
compilation to come to the user quickly. We

00:10:08.240 --> 00:10:12.740
didn't want somebody to have an application
that they had to run to warm it up for, you

00:10:12.740 --> 00:10:17.550
know, a minute, an hour, a day. We wanted
them to get the boost from compilation as

00:10:17.550 --> 00:10:22.240
soon as possible.
And finally, we're kind of sensitive about

00:10:22.240 --> 00:10:26.990
this is an interactive device, so we are sensitive
to jerky execution and pausing. We wanted

00:10:26.990 --> 00:10:33.990
the transition between interpretation and
compiled code to be really smooth.

00:10:34.000 --> 00:10:40.980
So I won't go through the whole matrix. But
the question really came down to two general

00:10:40.980 --> 00:10:47.180
classes of JIT styles.
The first one, method-based JIT is what you

00:10:47.180 --> 00:10:52.139
are most familiar with in the Java world.
This is what you would see on a server style

00:10:52.139 --> 00:10:55.810
JIT.
It starts off with interpreting your program

00:10:55.810 --> 00:11:01.529
until it finds the methods that are most frequently
executed, the hot methods. Then it pull out

00:11:01.529 --> 00:11:06.720
the code a method at a time, in method size
chunked, do the compilation, and then create

00:11:06.720 --> 00:11:13.720
a native version of that method in optimized
host code. There are some great strengths

00:11:14.459 --> 00:11:19.500
to this model and that's one of the reasons
it's very popular today, but the biggest one

00:11:19.500 --> 00:11:24.019
is you have a really nice optimization window.
If you are doing optimizations, you have to

00:11:24.019 --> 00:11:27.850
know what's happening in the code you are
optimizing, but as important, or even more

00:11:27.850 --> 00:11:32.740
important, you need to know what's not going
to happen, what can't happen so you can make

00:11:32.740 --> 00:11:36.959
the best assumptions You need that these pointers
are not going to alias. You need to know that

00:11:36.959 --> 00:11:40.949
this subexpression is never going to be used
again so I can drop it.

00:11:40.949 --> 00:11:47.430
And doing compilation in method sized chunks
has that advantage.

00:11:47.430 --> 00:11:51.500
Secondly, in this kind of environment where
you are interpreting some of the time and

00:11:51.500 --> 00:11:55.829
you are running compiled code other times,
you are going to have to transition between

00:11:55.829 --> 00:12:01.269
those two domains. And transitioning at method
boundaries is a nice clean place to do it

00:12:01.269 --> 00:12:05.949
because the interpreter and the compiled code
need to know where everything lives in order

00:12:05.949 --> 00:12:11.699
to make this whole thing work together.
But weaknesses. It definitely has some. And

00:12:11.699 --> 00:12:16.570
the primary weakness is that even though you
have identified what the hot methods are,

00:12:16.570 --> 00:12:21.160
all these hot methods are most likely going
to contain some cold code, some code that

00:12:21.160 --> 00:12:24.990
isn't going to be executed handling the exceptional
cases, the odd cases.

00:12:24.990 --> 00:12:29.290
And with method-at-a-time compilation, you
are going to be spending resources, time and

00:12:29.290 --> 00:12:35.209
space, to compile an optimized code that's
never really going to be run.

00:12:35.209 --> 00:12:40.149
The other down side to a method-based compilation
system is that it takes a lot more memory

00:12:40.149 --> 00:12:45.730
to do the compile. And that's, in part, because
you are compiling more instructions at once,

00:12:45.730 --> 00:12:51.699
and also the optimizations you would do, the
kind of flow analysis over the whole method

00:12:51.699 --> 00:12:55.949
is pretty expensive in terms of the resources
you need to do the compilation.

00:12:55.949 --> 00:13:01.079
And finally, doing all this extra work means
it's going to be longer before the benefit

00:13:01.079 --> 00:13:07.110
of that compilation comes to you.
So the other style, the trace-based JIT, this

00:13:07.110 --> 00:13:11.910
is a style a lot of people hadn't heard much
about, but it actually is really popular.

00:13:11.910 --> 00:13:17.720
It is the style of JIT that is typically used
when you are doing code migrations or virtualizations

00:13:17.720 --> 00:13:23.990
of one architecture on another. This was very
popular back in the '90s especially.

00:13:23.990 --> 00:13:28.959
What it does is very similar to the method-based
JIT, is you start off interpreting, but you

00:13:28.959 --> 00:13:32.699
interpret until you find out what the hot
chunks of code are. But in this case, the

00:13:32.699 --> 00:13:38.410
chunks are not contained methods. They are
actually just a run of instructions that will

00:13:38.410 --> 00:13:42.699
start someplace, you will execute for a while,
maybe you will follow a branch or two, perhaps

00:13:42.699 --> 00:13:47.250
you will identify a loop, and it will pull
out just those instructions, straighten them

00:13:47.250 --> 00:13:51.959
out into a straight line trace of code, and
then optimize that straight line trace of

00:13:51.959 --> 00:13:56.029
code.
It will take these translated chunks and store

00:13:56.029 --> 00:14:00.800
them in a translation cache, and chain them
all together so execution will kind of bounce

00:14:00.800 --> 00:14:07.480
from one trace to another.
And this type of trace formation, you don't

00:14:07.480 --> 00:14:12.190
actually even need to respect method call
boundaries. You can even have a trace that

00:14:12.190 --> 00:14:16.300
goes through a method call.
The great strength of this one is that you

00:14:16.300 --> 00:14:20.959
are only optimizing the hottest of the hot
code. It really has to be the code that's

00:14:20.959 --> 00:14:26.990
running before you bother to put the resources
in to compiling it.

00:14:26.990 --> 00:14:33.470
Another benefit that's a little bit more subtle,
but quite useful, is that this type of JIT

00:14:33.470 --> 00:14:38.079
system is typically more tightly integrated
with the interpreter. So you are bouncing

00:14:38.079 --> 00:14:42.860
between the interpreter and the translated
code a little bit more frequently, but what

00:14:42.860 --> 00:14:46.459
it also means is that you are never very far
away from the interpreter.

00:14:46.459 --> 00:14:53.459
So in the translated code, you can arrange
it, if you choose, to have it that the translated

00:14:53.500 --> 00:14:56.160
code doesn't have to deal with any exceptional
cases.

00:14:56.160 --> 00:15:01.319
If it detects that some assumption that's
made has gone wrong or it sees there's a null

00:15:01.319 --> 00:15:04.980
pointer here I have to deal with, it doesn't
actually have to deal with it. It can just

00:15:04.980 --> 00:15:10.819
roll back the state, return to the interpreter
and let the interpreter handle all the messy

00:15:10.819 --> 00:15:16.470
nastiness associated with handling these unusual
cases. And this actually turns out to be pretty

00:15:16.470 --> 00:15:23.470
powerful in allowing a trace compiler to be
simpler and focus really on what's going to

00:15:23.639 --> 00:15:27.810
return the performance rather than all the
details about handling every possible corner

00:15:27.810 --> 00:15:34.810
case. But, of course, still being correct.
Finally, you get a really rapid return on

00:15:34.880 --> 00:15:38.759
investment. The performance comes back quickly.
You are compiling small chunks. You don't

00:15:38.759 --> 00:15:43.420
have to wait very long before you decide some
chunk is hot and you can stitch it write into

00:15:43.420 --> 00:15:47.709
an application and get the boost from that
compilation right away.

00:15:47.709 --> 00:15:52.990
Now, as with everything, there are down sides.
The primary down side in a trace-based system

00:15:52.990 --> 00:15:59.029
is it relates to that window of optimization.
You don't really have a good view of the world

00:15:59.029 --> 00:16:03.230
outside of the trace when you are optimizing
that trace. You can only optimize within it.

00:16:03.230 --> 00:16:07.670
You don't really know what's happening once
you leave the trace, so you have to make kind

00:16:07.670 --> 00:16:13.389
of worst-case assumptions with optimizations,
and that limits you somewhat.

00:16:13.389 --> 00:16:17.990
Also, if there is -- as I mentioned you are
popping back and forth more frequently with

00:16:17.990 --> 00:16:23.269
the interpreted mode versus translated so
if there is an extra cost associated with

00:16:23.269 --> 00:16:26.470
making that transition, you are going to pay
it more frequently.

00:16:26.470 --> 00:16:33.009
And then finally, these fragments of code
pretty much are always continuously changing

00:16:33.009 --> 00:16:38.629
and it becomes very difficult to share changing
fragments of code across processes.

00:16:38.629 --> 00:16:42.430
It's actually kind of difficult to share them
even within a process among threads, but we

00:16:42.430 --> 00:16:46.800
can do that.
But across processes would be tough.

00:16:46.800 --> 00:16:48.949
Okay.
So lots of words.

00:16:48.949 --> 00:16:53.529
So let me throw a picture up here and get
back to this notion of what is hot.

00:16:53.529 --> 00:16:59.339
Now, Ben took a look at one of the key --
 the key processes on a running Android system.

00:16:59.339 --> 00:17:04.290
And that's the system server process.
It's a process that provides services to running

00:17:04.290 --> 00:17:07.500
applications.
And the bytecode involved in that was about

00:17:07.500 --> 00:17:12.750
four and a half megabytes.
Now, profiling this over 25 minutes as if

00:17:12.750 --> 00:17:19.380
we were a method at a time JIT, found that
roughly 8% of that four and a half megabytes

00:17:19.380 --> 00:17:24.339
of code was actually worth compiling.
The rest of it either wasn't executed or wasn't

00:17:24.339 --> 00:17:28.189
executed enough to bother to try to speed
it up.

00:17:28.189 --> 00:17:34.299
But then looking at it just in terms of hot
traces, it goes all the way down to 2%, so

00:17:34.299 --> 00:17:41.299
2% for us of that large process mattered enough
that it needed to be optimized.

00:17:42.090 --> 00:17:46.190
And this is kind of the benefit of a trace
compiler.

00:17:46.190 --> 00:17:50.830
If we look at just the high-order bit of the
decision point, it was that the method JIT

00:17:50.830 --> 00:17:55.830
could provide the best optimization possibilities,
but the trace JIT really does provide the

00:17:55.830 --> 00:18:01.400
best return on investment, the best return
for the memory and processor spent in order

00:18:01.400 --> 00:18:06.230
to do the translation.
So that's what we decided to go with.

00:18:06.230 --> 00:18:13.230
The Dalvik JIT in Froyo is a trace-based JIT.
And, again, the key factors for us making

00:18:14.100 --> 00:18:20.460
this decision was to minimize the memory use
and then also to get that performance coming

00:18:20.460 --> 00:18:25.299
back to the user as quickly as possible.
One thing we worried about is, if we had gone

00:18:25.299 --> 00:18:32.179
with another model, is the usage case of a
user downloading an application from the market

00:18:32.179 --> 00:18:37.450
and then discarding it before it had been
running long enough to trigger the hot code

00:18:37.450 --> 00:18:41.380
detection and the recompilation to give you
the performance that you needed.

00:18:41.380 --> 00:18:46.320
With a trace JIT, the performance comes to
you just almost immediately.

00:18:46.320 --> 00:18:53.320
Now, we also realized, too, that although
we kind of obsess over battery-powered Android

00:18:53.690 --> 00:18:57.799
devices, a lot of times they're not really
battery powered and they don't really need

00:18:57.799 --> 00:19:01.360
to be that responsive.
And that's when they're plugged in and charging.

00:19:01.360 --> 00:19:07.510
When one of these phones is charging, it actually
looks a lot like a server, an environment

00:19:07.510 --> 00:19:13.960
in which a method-based JIT is most appropriate.
While we're not doing it now, we're leaving

00:19:13.960 --> 00:19:18.700
the path open that in the future, we could
perhaps bring in the best of both worlds,

00:19:18.700 --> 00:19:24.390
have the trace JIT available to give the immediate
speed boost for a running application when

00:19:24.390 --> 00:19:27.440
you're running battery powered.
And then when you're charging, when the phone

00:19:27.440 --> 00:19:33.370
is not being used, perhaps a more advanced
method-based JIT could come along and do some

00:19:33.370 --> 00:19:37.789
extra optimization.
But that's just a possible path forward.

00:19:37.789 --> 00:19:43.299
Okay, so time for a flowchart.
Let's just walk through very quickly kind

00:19:43.299 --> 00:19:47.690
of a simplified version of how the trace JIT
works.

00:19:47.690 --> 00:19:51.990
So when I mentioned a trace is a string of
instructions, kind of a straight-line string

00:19:51.990 --> 00:19:54.350
of instructions.
And that has to have a start.

00:19:54.350 --> 00:19:58.150
We call the potential start of any trace to
be the trace head.

00:19:58.150 --> 00:20:01.490
That's, you know, the point in the code that
the trace can begin from.

00:20:01.490 --> 00:20:07.370
Let's say we're in the interpreter and let's
say we're at one of these trace head points.

00:20:07.370 --> 00:20:13.190
Now, that's generally the target of a backward
branch, the entry point to a method, the target

00:20:13.190 --> 00:20:16.630
of an indirect branch.
There are several possibilities.

00:20:16.630 --> 00:20:22.529
The interpreter will say, hey, I'm at a potential
trace head, and so it will increment a profile

00:20:22.529 --> 00:20:28.480
counter associated with that potential head.
Then it will ask itself, have I been here

00:20:28.480 --> 00:20:32.630
enough that this thing matters?
In the beginning, the answer will be no.

00:20:32.630 --> 00:20:37.720
So the interpreter will go back to interpreting
as fast as it can, until it comes to the next

00:20:37.720 --> 00:20:41.830
potential trace head.
It will update its profile counter, ask the

00:20:41.830 --> 00:20:45.100
question again, have I reached my threshold?
Is this something that's interesting?

00:20:45.100 --> 00:20:48.850
And eventually, the answer will come back,
yes, this is interesting.

00:20:48.850 --> 00:20:52.850
I've been here enough.
This is something I want to take a look at.

00:20:52.850 --> 00:20:57.600
The next question is asked, do I already have
a translation for this address?

00:20:57.600 --> 00:21:02.960
And if I do, then will this send execution
directly to that translation so it can start

00:21:02.960 --> 00:21:05.940
translating natively?
But, again, let's say we're in the beginning

00:21:05.940 --> 00:21:08.440
of the world.
The answer would be no.

00:21:08.440 --> 00:21:11.760
So we don't have a translation for that address.
So we want to build one.

00:21:11.760 --> 00:21:16.460
So we go into -- we go back to the interpreter.
So we're going to continue interpreting, but

00:21:16.460 --> 00:21:18.850
we're going to continue interpreting in a
special mode.

00:21:18.850 --> 00:21:23.080
We call this trace-building mode.
We essentially single-step the interpreter,

00:21:23.080 --> 00:21:28.470
and every time we successfully interpret an
instruction, we'll add that instruction to

00:21:28.470 --> 00:21:32.890
the list of instructions for that trace that
we want to have translated.

00:21:32.890 --> 00:21:38.210
Now, how long we keep doing that and when
we stop, that's one of the tuning parameters

00:21:38.210 --> 00:21:41.470
we have in the JIT.
Basically, you know, how many branches do

00:21:41.470 --> 00:21:45.240
you follow before your trace is terminated?
At some point, we'll decide, okay, this is

00:21:45.240 --> 00:21:47.830
long enough.
We want to terminate this trace.

00:21:47.830 --> 00:21:50.760
And then we'll send the request off to the
compiler thread.

00:21:50.760 --> 00:21:56.620
Meanwhile, the interpreter goes back to interpreting
so you can continue making forward progress.

00:21:56.620 --> 00:22:01.080
Now, at some point, the compiler thread will
get around to compiling that trace into a

00:22:01.080 --> 00:22:06.980
sequence of native instructions, and it will
install it into the translation cache.

00:22:06.980 --> 00:22:12.520
Now, one of the -- something to keep in mind,
when we first put a translation in the translation

00:22:12.520 --> 00:22:16.830
cache, it's going to have some -- all traces
are going to have branches that exit the trace.

00:22:16.830 --> 00:22:22.520
When we first put it in the translation cache,
those branches that exit the trace are going

00:22:22.520 --> 00:22:28.120
to be hard-wired to send us back to the interpreter.
So if the very first time we jump in, we do

00:22:28.120 --> 00:22:33.760
the translation, then we get back to the interpreter
and go look for new hot traces to compile.

00:22:33.760 --> 00:22:39.179
But on the way out, once we have completed
that trace and we're going back to the interpreter,

00:22:39.179 --> 00:22:43.029
the question will be asked, is there a translation
for where I'm going?

00:22:43.029 --> 00:22:48.380
And if the answer is yes, then we'll replace
that exit branch with a direct trace-to-trace

00:22:48.380 --> 00:22:53.260
branch.
The upshot of this is that, in practice, very

00:22:53.260 --> 00:22:56.909
quickly, we spend very little time in the
interpreter.

00:22:56.909 --> 00:23:01.110
We'll collect all of our hot traces, chain
them all together, and so we're really just

00:23:01.110 --> 00:23:05.640
bouncing from trace to trace to trace to trace
in the translation cache, with an occasional

00:23:05.640 --> 00:23:10.360
bounce out to the interpreter to find some
other hot trace before we come back in to

00:23:10.360 --> 00:23:15.210
the translation cache.
It works remarkably well.

00:23:15.210 --> 00:23:18.049
Okay.
So that's kind of what I've already said.

00:23:18.049 --> 00:23:24.120
Now, what I described was really the flow
for almost any trace-based JIT.

00:23:24.120 --> 00:23:28.720
It's the basic flow model.
Some specifics about the Dalvik JIT.

00:23:28.720 --> 00:23:34.380
We have a per -- a translation cache per process.
So every Dalvik process is going to have its

00:23:34.380 --> 00:23:38.279
own private translation cache.
But all the threads within that process will

00:23:38.279 --> 00:23:45.179
share that cache.
We have some simple traces right now.

00:23:45.179 --> 00:23:49.070
This is kind of release 1.0.
So we're being conservative.

00:23:49.070 --> 00:23:52.690
Our traces are not very long.
They'll generally be just one or two basic

00:23:52.690 --> 00:23:56.010
blocks.
And a basic block in compiler terms is a string

00:23:56.010 --> 00:24:00.830
of instructions followed by a branch out.
Our optimizations are pretty straightforward.

00:24:00.830 --> 00:24:06.549
For local optimizations, we do register promotion,
load store elimination, if we can eliminate

00:24:06.549 --> 00:24:11.110
null checks, we do so, and then we do some
instruction scheduling just on -- based on

00:24:11.110 --> 00:24:15.230
some heuristics.
We've also got some nice loop detection code

00:24:15.230 --> 00:24:17.720
in there.
So if we can detect a loop, we can do some

00:24:17.720 --> 00:24:23.820
more -- more -- some of the simple loop optimizations
in variant code motion, and play around a

00:24:23.820 --> 00:24:27.059
bit with the induction variables.
Okay.

00:24:27.059 --> 00:24:29.960
So now this is really the slide that everybody
cares about.

00:24:29.960 --> 00:24:33.399
How well did it work?
It worked out really pretty well.

00:24:33.399 --> 00:24:39.480
This top chart here, it's -- the scale on
the left shows you how many times faster the

00:24:39.480 --> 00:24:45.309
JIT'd code is than the interpreted code, the
JIT'd code in Froyo is than the interpreted

00:24:45.309 --> 00:24:49.470
code that you would see in the Eclair release.
And we're seeing anywhere from two to five

00:24:49.470 --> 00:24:56.470
times performance boost -- excuse me -- on
these kind of applications.

00:24:57.419 --> 00:25:02.460
Now, again, this is -- just want to be clear
 -- this is a performance boost of the interpreted

00:25:02.460 --> 00:25:04.520
code.
So if you have an application that's already

00:25:04.520 --> 00:25:09.190
spending most of its time in a native code
library, the JIT is not going to do much for

00:25:09.190 --> 00:25:12.159
you because you're not really doing any interpretation
to start with.

00:25:12.159 --> 00:25:18.330
This is an improvement relative to the amount
of interpretation that happens in the program.

00:25:18.330 --> 00:25:23.399
But we're still pretty happy with it.
Now, the bottom chart, though, I'll have to

00:25:23.399 --> 00:25:26.299
say, is actually the one that I'm personally
happiest with.

00:25:26.299 --> 00:25:31.200
And this is an indication of how much memory
we consume in order to get this performance

00:25:31.200 --> 00:25:36.909
boost.
If you look at that first one, LINpack, that

00:25:36.909 --> 00:25:42.880
scale on the left is actually in kilobytes.
So we're not measuring memory usage in megabytes

00:25:42.880 --> 00:25:48.659
or gigabytes, but actually, we're only consuming
100 or so kilobytes of total heap.

00:25:48.659 --> 00:25:54.820
And this is heap for the profiling system,
for the JIT compiler itself, and the memory

00:25:54.820 --> 00:25:58.240
used by the translations that are produced
by it.

00:25:58.240 --> 00:26:03.799
And this is really a very, very small number
relative to traditional JITs.

00:26:03.799 --> 00:26:08.630
So we're extremely happy about, again, the
return on investment, the performance we've

00:26:08.630 --> 00:26:14.070
been able to achieve with the very small amount
of memory that we're using.

00:26:14.070 --> 00:26:17.130
So what's next?
This is our first release.

00:26:17.130 --> 00:26:22.039
We've got some nice plans going forward.
The two key optimizations that we didn't include

00:26:22.039 --> 00:26:27.230
in Froyo that we're working on currently are
method in-lining and trace extension.

00:26:27.230 --> 00:26:31.210
And by trace extension, I mean we're going
to have those traces run more than a couple

00:26:31.210 --> 00:26:34.620
basic blocks, mostly so that we can identify
loops.

00:26:34.620 --> 00:26:40.919
It's important to identify loops in the hot
traces so that you can perform the loop optimizations.

00:26:40.919 --> 00:26:46.820
Other things we're looking at is persistent
profile information, off-line trace coalescing.

00:26:46.820 --> 00:26:52.909
These are really things that address that
case in which we want to do something when

00:26:52.909 --> 00:26:57.669
your phone is charging, when you're not actively
using it, to make things go faster.

00:26:57.669 --> 00:27:04.620
And then, finally, tuning, tuning, and more
tuning will continue to make this thing better.

00:27:04.620 --> 00:27:06.830
Okay.
So now I'm going to turn it over to Ben.

00:27:06.830 --> 00:27:10.809
And he's going to tell you a little bit more
about the things you can do if you go out

00:27:10.809 --> 00:27:15.330
and get the sources of the JIT and build some
of these special profile versions.

00:27:15.330 --> 00:27:18.820
&gt;&gt;Ben Cheng: Okay.
Thank you, Bill.

00:27:18.820 --> 00:27:21.429
Hi, everyone.
My name is Ben Cheng.

00:27:21.429 --> 00:27:24.250
I'm also a software engineer in the Dalvik
team.

00:27:24.250 --> 00:27:28.429
Now that you know the overall structure and
the performance figures in the version 1.0

00:27:28.429 --> 00:27:33.700
and the Dalvik JIT implementation, in the
second half of the talk, I'm going to go over

00:27:33.700 --> 00:27:38.840
the key techniques we used to address the
performance and the correctness issues we

00:27:38.840 --> 00:27:43.840
encountered during the course of development.
If you're also a compiler hacker and plan

00:27:43.840 --> 00:27:48.830
to make contributions to the Dalvik JIT project
in the future or even plan to port a JIT to

00:27:48.830 --> 00:27:53.640
a brand-new platform, I'm sure you'll find
the following information very useful.

00:27:53.640 --> 00:27:58.110
If you are an app developer, please try to
stay awake for the next five slides.

00:27:58.110 --> 00:28:00.580
[ Laughter ]
&gt;&gt;Ben Cheng: And after those, you can just

00:28:00.580 --> 00:28:04.679
sit back, relax, and enjoy the speedup from
the JIT.

00:28:04.679 --> 00:28:10.029
So after the JIT infrastructure is in place,
the typical tuning, tuning, and more tuning

00:28:10.029 --> 00:28:15.820
cycle starts with workload analysis.
Because if the majority of cycles are spent

00:28:15.820 --> 00:28:21.260
in a VM interpreter, then that's a good benchmark
for additional JIT tuning, because the maximum

00:28:21.260 --> 00:28:26.460
cycles that can be shaved by the JIT will
only be a fraction of those originally spent

00:28:26.460 --> 00:28:31.850
in a VM interpreter.
So the tool we can use is called the OProfile.

00:28:31.850 --> 00:28:38.850
And with the profiling information, you get
the rough idea on whether to expect a 5X or

00:28:38.919 --> 00:28:45.919
.5% speedup from the JIT.
Once the workload is in -- the suitable workload

00:28:49.370 --> 00:28:54.870
is identified, the next task is to verify
whether the JIT is able to migrate all the

00:28:54.870 --> 00:28:59.159
cycles from the VM interpreter to the JIT'd
code cache.

00:28:59.159 --> 00:29:04.140
Again, the profiler will be able to provide
you some insight to validate if that's the

00:29:04.140 --> 00:29:09.990
case or not. What OProfile cannot provide,
at least for now, on Android platform, is

00:29:09.990 --> 00:29:14.960
the capability to distinguish individual translation
boundaries in a code cache.

00:29:14.960 --> 00:29:21.360
Therefore, it also lacks the capability to
map a translation to a Java source level.

00:29:21.360 --> 00:29:27.120
So we wrote our own ad hoc profiler which
will instrument every translation with count

00:29:27.120 --> 00:29:31.390
increment instructions.
And from the profile counts, you can find

00:29:31.390 --> 00:29:36.220
out the hottest translations very easily.
And those are good starting points to find

00:29:36.220 --> 00:29:43.140
out additional performance tuning opportunities.
In the third part of my talk, I'm going to

00:29:43.140 --> 00:29:49.000
share with you some practical ways to debug
the JIT, like all our compiler projects, if

00:29:49.000 --> 00:29:55.409
the compiler is crashing, a conventional way
to triage that is to selectively disable more

00:29:55.409 --> 00:30:00.299
and more operations in the compiler until
the smoking gun is found.

00:30:00.299 --> 00:30:05.750
Not only is that a tedious and a lengthy process
to begin with, the dynamic nature of the JIT

00:30:05.750 --> 00:30:10.549
adds additional challenge to the triage process,
because the batch translation you are trying

00:30:10.549 --> 00:30:17.549
to identify may not be compiled every time.
So we take a step further by converting the

00:30:18.059 --> 00:30:23.409
frequent synchronization with the interpreter
to our advantage by designing a verification

00:30:23.409 --> 00:30:29.179
framework that actively validates every single
line of JIT'd code against an interpreter,

00:30:29.179 --> 00:30:33.450
which is considered the golden reference of
the VM implementation.

00:30:33.450 --> 00:30:39.299
If there is any divergence detected there,
we will report that in a log and that will

00:30:39.299 --> 00:30:46.299
greatly shorten the triage process.
Now let's move on to local analysis and benchmarking.

00:30:47.190 --> 00:30:51.669
I remember in my school days, benchmarking
for a compiler is really boring.

00:30:51.669 --> 00:30:58.519
I would run a single command to start a test
harness for spec 95 or 2000, and a few hours

00:30:58.519 --> 00:31:04.090
later, I got a bunch of numbers come back.
If I'm using a simulator, I actually can plan

00:31:04.090 --> 00:31:09.860
a day trip between two benchmarking runs.
In our Android device, since the most likely

00:31:09.860 --> 00:31:14.710
CPU-intensive workload are games, I definitely
won't mind spending an extended period of

00:31:14.710 --> 00:31:21.710
time playing one of my favorite games, RoboDefense
to measure its performance.

00:31:21.919 --> 00:31:28.919
Well, it turns out that the CPU cycles spent
on the VM is really, really light in these

00:31:29.090 --> 00:31:33.269
workloads.
So here is the OProfile result taken from

00:31:33.269 --> 00:31:40.269
playing a game from level 00 to 080.
You can see that 74% of the CPU cycles are

00:31:41.070 --> 00:31:46.429
spent in the skia library, busy drawing the
robots on the screen.

00:31:46.429 --> 00:31:53.429
The time spent in the VM is actually only
4.34%, including the GC time.

00:31:54.139 --> 00:32:00.210
So it turns out that this is a perfect benchmark
for skia tuning or even GCC tuning, because

00:32:00.210 --> 00:32:04.539
skia is native code.
But the maximum performance gain you can get

00:32:04.539 --> 00:32:11.539
from optimizing a VM is capped at 4.34%.
Now let's look at a different game, called

00:32:12.809 --> 00:32:17.330
Checkers, from the Brain and Puzzle section
on the Android Market.

00:32:17.330 --> 00:32:20.850
And this is actually written by a fellow Googler,
Aart Bik.

00:32:20.850 --> 00:32:26.360
Now, regardless of the JIT, this is a perfect
benchmark, because that will clearly print

00:32:26.360 --> 00:32:31.830
the number of nodes traversed in a fixed amount
of time on the bottom right screen.

00:32:31.830 --> 00:32:37.049
And I may zoom in there.
So in the two screen shots here, the left-hand

00:32:37.049 --> 00:32:40.669
one is the Eclair version or the interpreter-only
version.

00:32:40.669 --> 00:32:44.639
The right-hand one is the JIT version, or
Froyo version.

00:32:44.639 --> 00:32:51.639
And the play time is set to ten seconds.
As Bill mentioned earlier, we measured a 5.4X

00:32:52.539 --> 00:32:59.539
speedup on Nexus One.
Because the score jumped for 965K to 5.2 million.

00:32:59.710 --> 00:33:03.840
One fun fact about the game is that if you
look at the feedback on the Android Market,

00:33:03.840 --> 00:33:09.269
you will find a few one- or two-star ratings,
because people think this game is too difficult

00:33:09.269 --> 00:33:13.460
for users to beat.
So I'm pretty sure that the checkers players

00:33:13.460 --> 00:33:19.070
will be among the first wave of Froyo users
to notice additional performance difference,

00:33:19.070 --> 00:33:20.840
probably through frustration.
[ Laughter ]

00:33:20.840 --> 00:33:27.840
&gt;&gt;Ben Cheng: And in case you were wondering
why it shows a remote cousin of the 099 go

00:33:28.360 --> 00:33:35.139
benchmark from spec 95 to showcase the JIT
running on the 2010 Android device, well,

00:33:35.139 --> 00:33:40.159
there are two primary reasons.
The first one is, the checkers is an easy,

00:33:40.159 --> 00:33:45.289
accessible application on the Android Market.
And that can be used to measure the VM baseline

00:33:45.289 --> 00:33:48.630
performance across different platforms very
easily.

00:33:48.630 --> 00:33:53.350
The second reason is, tuning a JIT is like
tuning a muscle car, where you want all the

00:33:53.350 --> 00:34:00.139
horsepower to stay in the power train instead
of being wasted by air conditioner or stereo.

00:34:00.139 --> 00:34:06.529
So here is the ten-second profile result taken
from the JIT version, where the Dalvik JIT

00:34:06.529 --> 00:34:11.090
code cache line accounts for all the cycles
spent in the code cache.

00:34:11.090 --> 00:34:17.410
And libdvm.so accounts for all the cycles
spent in the statically compiled code.

00:34:17.410 --> 00:34:22.860
The combined sum here accounts for 96.45%
of the overall CPU time.

00:34:22.860 --> 00:34:27.670
And that's why optimizing the VM will provide
you the biggest bang for the buck for this

00:34:27.670 --> 00:34:32.260
kind of workload.
On the other hand, if the game is modified

00:34:32.260 --> 00:34:37.870
in the future to perform a fixed amount of
workload in the shortest amount of time, then

00:34:37.870 --> 00:34:44.870
you can spend 80% of the CPU cycles doing
something else or simply sleep.

00:34:45.230 --> 00:34:49.370
Now let's take a look at the breakdown between
the dynamic and the static cycles.

00:34:49.370 --> 00:34:55.700
As shown here, the ratio is 97 to 3.
It means that the trace-based JIT did an excellent

00:34:55.700 --> 00:35:02.040
job identifying all the hot traces in the
workload and migrated cycles from the VM interpreter

00:35:02.040 --> 00:35:07.280
to the JIT code cache line.
Now let's move on to a second topic, which

00:35:07.280 --> 00:35:13.020
is how to measure the effectiveness of the
JIT itself.

00:35:13.020 --> 00:35:18.310
So in addition to the top-line performance
numbers, the amount of resource consumed by

00:35:18.310 --> 00:35:22.480
the JIT is another important area we want
to monitor.

00:35:22.480 --> 00:35:28.130
So if you load -- for example, if you want
to know the code bloat ratio from Dalvik bytecode

00:35:28.130 --> 00:35:33.300
to the generated native code, because the
code cache is a fixed-size memory buffer,

00:35:33.300 --> 00:35:40.200
and the lower the code bloat ratio is, the
more translations can be placed in there.

00:35:40.200 --> 00:35:44.380
Right now, we don't have garbage collection
on the code cache, so whenever that gets full,

00:35:44.380 --> 00:35:49.460
we just nuke it and restart from scratch.
And that's why we also want to know how fast

00:35:49.460 --> 00:35:55.100
the JIT compiler can crank out translations.
So if you load the profiling version of the

00:35:55.100 --> 00:36:01.350
VM onto the phone, at any time, you can just
send a user two signal or 12 to the pid of

00:36:01.350 --> 00:36:07.380
the selected process, and a bunch of useful
statistics will be printed in a log.

00:36:07.380 --> 00:36:12.620
For example, the numbers here are taken from
the system server process after using a phone

00:36:12.620 --> 00:36:18.240
for 20 minutes, including checking e-mails,
browsing the Web, and making phone calls.

00:36:18.240 --> 00:36:24.690
In this particular snapshot here, there are
9898 or close to 10,000 compilations made

00:36:24.690 --> 00:36:29.830
during this 20-minute span, and they occupy
796 kilobytes in the code cache.

00:36:29.830 --> 00:36:34.180
So, on average, each compilation takes about
80 bytes.

00:36:34.180 --> 00:36:40.010
And although we are not doing method-based
compilation, we still try to keep track of

00:36:40.010 --> 00:36:45.560
the total size of hot methods.
The way we do that is, whenever a trace is

00:36:45.560 --> 00:36:50.290
picked up by the compiler thread, we also
identify the containing method and tag the

00:36:50.290 --> 00:36:53.810
method as hot.
In this way, we can get a total size of the

00:36:53.810 --> 00:36:58.830
hot choices and hot methods in the Dalvik
bytecode level.

00:36:58.830 --> 00:37:05.830
So in this example here, the red number 104K
accounts for the total size of at least 10,000

00:37:06.520 --> 00:37:12.000
hot traces.
And the green number, 396K, is the total size

00:37:12.000 --> 00:37:16.750
of the hot method.
And as Bill mentioned earlier, the trace-based

00:37:16.750 --> 00:37:23.250
JIT effectively only touched 26% of the Dalvik
bytecode in hot method.

00:37:23.250 --> 00:37:28.620
Now that we know the total size of generated
code and original Dalvik bytecode size in

00:37:28.620 --> 00:37:33.500
the traces, we can calculate the code bloat
ration, which is 7.7 in this case.

00:37:33.500 --> 00:37:39.290
It is actually not as high as that appears
to be, because Dalvik bytecode is known for

00:37:39.290 --> 00:37:44.710
its compact representation, and all the new
and arranged checks that couldn't be optimized

00:37:44.710 --> 00:37:49.670
away are generated in-line by the compiler.
But there is always room for improvement,

00:37:49.670 --> 00:37:51.640
and we'll definitely look into that.
And all the new and arranged checks that couldn't

00:37:51.640 --> 00:37:52.630
be optimized away are generated in-line by
the compiler. But there is always room for

00:37:52.630 --> 00:37:53.150
improvement, and we will definitely look into
that.

00:37:53.150 --> 00:37:57.720
Now let's take a look at how fast the JIT
compiler can produce compilations.

00:37:57.720 --> 00:38:03.090
The way we measure that is whenever a work
order is consumed by the compiler thread,

00:38:03.090 --> 00:38:08.130
we take a time stamp. Then when a generated
code is installed in the code cache, we take

00:38:08.130 --> 00:38:13.570
another time stamp. Then a delta here is the
work clock turnaround time per compilation

00:38:13.570 --> 00:38:18.800
unit.
So an example here, to generate this 10,000

00:38:18.800 --> 00:38:24.240
compilations takes slightly over six seconds
out of the 20-minute span. And on average,

00:38:24.240 --> 00:38:30.340
each compilation takes about 609 microseconds.
Also note that the time measure here involves

00:38:30.340 --> 00:38:35.650
the boot process which is very busy because
there are many, many threads containing for

00:38:35.650 --> 00:38:39.840
the single CPU unit system.
So the JIT latency here can be considered

00:38:39.840 --> 00:38:44.670
as the upper bound.
When a system is in a stable state, the JIT

00:38:44.670 --> 00:38:51.490
latency we measured is typically in the 100
to 150 second micro second range.

00:38:51.490 --> 00:38:56.500
Now, let's talk about the last performance
tuning in the talk, which is how to use the

00:38:56.500 --> 00:39:02.450
JIT profiler to inspect the quality of generated
code.

00:39:02.450 --> 00:39:06.780
Again, if you load the profiling version of
the VM onto the phone and enable a special

00:39:06.780 --> 00:39:12.760
property, like that specified in the title,
you have effectively enabled the JIT profiler.

00:39:12.760 --> 00:39:18.180
And at any time if you send a user two signal
to the PID of a selected process, all the

00:39:18.180 --> 00:39:23.690
sorted profile counts will be printed in a
log. And the numbers here are also taken from

00:39:23.690 --> 00:39:28.720
the system server process. I am going to use
the top row to go over the meaning of individual

00:39:28.720 --> 00:39:32.930
cells.
The first number of 15368 is the total number

00:39:32.930 --> 00:39:39.930
of times that hot translation is dispatched
and that accounts for 1.15% of the total dispatches.

00:39:41.030 --> 00:39:48.030
The zero plus-2 283 top (inaudible) means
the beginning of the translation is also at

00:39:48.770 --> 00:39:53.460
the beginning of the containing method. And
there are two Dalvik instructions, including

00:39:53.460 --> 00:40:00.460
the trace. And it comes from line number 283
in hashmap.Java.

00:40:00.520 --> 00:40:05.630
The verbose output of the top ten translations
including the Dalvik bytecode and the generated

00:40:05.630 --> 00:40:12.100
thumb or thumb 2 instructions are also printed
in a log, and that will facilitate in-depth

00:40:12.100 --> 00:40:18.790
code quality analysis. And I am going to show
you a verbose output momentarily.

00:40:18.790 --> 00:40:25.790
Now let's move on to the third topic, which
is about the debugging and verification tools

00:40:26.150 --> 00:40:33.150
we developed and how we strive to ensure the
highest level of stability of the JIT.

00:40:34.700 --> 00:40:41.400
So right now let me turn on the phone. This
one.

00:40:41.400 --> 00:40:48.400
And I will put that aside first.
So if the VM is brought on by a JIT bug, usually

00:40:51.310 --> 00:40:56.650
it manifests itself either as native crash
in the code cache or on code exceptions in

00:40:56.650 --> 00:41:01.160
the Java source level.
So the phone here I just turned on actually

00:41:01.160 --> 00:41:06.100
contains an injected bug in one of the codegen
routines, and you will never make it to the

00:41:06.100 --> 00:41:12.500
home screen. But if you look at the bug reports
in the log, you will see a variety of reasons

00:41:12.500 --> 00:41:18.060
reported. Photograph for example, you will
see a run-time exception thrown in a system

00:41:18.060 --> 00:41:25.060
server thread. And another symptom due to
the same injected bug is array index out of

00:41:25.780 --> 00:41:32.130
bounds exception in the windows manager threat.
And yet another symptom due to the same big

00:41:32.130 --> 00:41:34.690
is a stack overflow error in the system server
thread.

00:41:34.690 --> 00:41:40.700
In case you are wondering what the injected
bug was, I basically made a one-line change

00:41:40.700 --> 00:41:47.040
in the load constant routine so that all the
16-bit sine extended constant loaded by the

00:41:47.040 --> 00:41:52.850
JIT will be one greater than the original
value specified in the byte code.

00:41:52.850 --> 00:41:57.370
And this phone will be stuck in the miserable
state forever.

00:41:57.370 --> 00:42:02.250
If you look at the crash reports, it is not
clear whether the injected bug -- whether

00:42:02.250 --> 00:42:07.890
the bug is in the application itself or the
JIT compiler. And uncertainty like that will

00:42:07.890 --> 00:42:14.890
definitely hinder the triage process.
So in real life, when we get an incoming bug

00:42:15.030 --> 00:42:20.610
report concerning the JIT, the first thing
we do is to disable the JIT and try to reproduce

00:42:20.610 --> 00:42:25.660
the problem in an interpreter-only mode. If
the problem just goes away, then we know,

00:42:25.660 --> 00:42:30.970
okay, must be our fault.
And roughly speaking, the top two sources

00:42:30.970 --> 00:42:36.340
for issues in the JIT come from code generation
routines and optimization routines.

00:42:36.340 --> 00:42:41.030
In the early days, when a JIT does only type
of oh-zero type of code generation, since

00:42:41.030 --> 00:42:46.620
there are 256 byte code in the system, there
are only 256 potential places for a bug to

00:42:46.620 --> 00:42:53.500
hide. So the first debugging support we implemented
is to selectively disable an arbitrary set

00:42:53.500 --> 00:42:58.880
of op codes for the JIT, and we used the interpreter
to execute those.

00:42:58.880 --> 00:43:03.670
So as long as we can find a reliable way to
reproduce the crash, it's only a matter of

00:43:03.670 --> 00:43:09.170
several rungs of binary search to root cause
the problem. And clearly, the injected codegen

00:43:09.170 --> 00:43:14.050
bug can be found that way.
But as the compiler becomes more ask more

00:43:14.050 --> 00:43:18.840
sophisticated and additional optimizations
like registry allocation or scheduling are

00:43:18.840 --> 00:43:25.370
in place, the binary search mechanism becomes
less reliable because disabling certain op

00:43:25.370 --> 00:43:29.830
codes might get rid of instruction mix that
triggers the problem.

00:43:29.830 --> 00:43:35.030
So we also implemented a method based filtering
mechanism where as long as you can narrow

00:43:35.030 --> 00:43:40.640
down the bug to a small set of methods, you
can enable or disable the JIT only for traces

00:43:40.640 --> 00:43:45.580
coming from those methods to see if that makes
any difference.

00:43:45.580 --> 00:43:51.270
As you may already have noticed here, the
triaging techniques we used here involves

00:43:51.270 --> 00:43:56.610
constant toggling between the JIT and an interpreter.
And we are very motivated not to do that by

00:43:56.610 --> 00:44:01.270
ourselves manually.
So the ingenious idea we came up was to hire

00:44:01.270 --> 00:44:03.250
a summer intern last year.
[ Laughter ]

00:44:03.250 --> 00:44:06.490
&gt;&gt;Ben Cheng: And the name of the project is
self-verification.

00:44:06.490 --> 00:44:12.630
Instead of locking the intern in his office
doing verification all by himself, we actually

00:44:12.630 --> 00:44:18.850
worked together by designing a brand-new verification
framework based on tricks to roll back and

00:44:18.850 --> 00:44:24.000
commit the memory states.
So basically, the VM is able to execute the

00:44:24.000 --> 00:44:28.940
same instruction sequence twice by two different
execution engines in an interleaved way.

00:44:28.940 --> 00:44:35.940
At the end of both rounds we do a state comparison
and report the divergence detected there.

00:44:39.200 --> 00:44:44.300
So we call that self-verification.
And because the execution and the verification

00:44:44.300 --> 00:44:50.090
all happen on the same physical device, without
user intervention, and it is capable of detecting

00:44:50.090 --> 00:44:57.010
both code generation and optimization bugs.
So now let me turn on the second phone here

00:44:57.010 --> 00:45:02.690
which is loaded with the same code generation
bug, but with self-verification enabled. My

00:45:02.690 --> 00:45:08.490
prediction is it will be able to tell you
exactly where the injected bug is, and fixing

00:45:08.490 --> 00:45:13.370
that will take less than three minutes. But
before that happens, let me quickly go over

00:45:13.370 --> 00:45:20.370
the work flow of self-verification.
So if you take a snapshot of the VM state,

00:45:20.800 --> 00:45:26.010
there are three categories of information
that matter. The content on the stack, the

00:45:26.010 --> 00:45:31.880
content on the heap, and the Dalvik PC. So
the verification cycle starts by creating

00:45:31.880 --> 00:45:38.880
a shadow copy of the top frame on the stack.
And we only need to care about the top frame

00:45:38.900 --> 00:45:44.540
because currently, the trace is confined in
a single method boundary.

00:45:44.540 --> 00:45:51.050
All the heap accesses in the trace are intercepted
and emulated at run time. So all the store

00:45:51.050 --> 00:45:57.830
to the heap will be stored in the simple table
data structure by the address and data pair.

00:45:57.830 --> 00:46:03.650
And all the loads from the heap will be routed
to the table first to see if there's any recent

00:46:03.650 --> 00:46:10.110
update from the same trace. If not, the content
will be served by the real heap.

00:46:10.110 --> 00:46:14.720
Then we dispatched a JIT'd code, and that
it execute to the end. Then we will remember

00:46:14.720 --> 00:46:20.040
the end PC.
Then we restore the PC to the beginning value

00:46:20.040 --> 00:46:23.170
and it re-executes the same instruction sequence
using the interpreter.

00:46:23.170 --> 00:46:29.920
We will know exactly when to do state comparison,
because right now there is a maximum number

00:46:29.920 --> 00:46:35.720
of instructions that can be including a trace.
So if we hit the limit before seeing the end

00:46:35.720 --> 00:46:40.700
PC, we know we have a control flow divergence
and we will just report that.

00:46:40.700 --> 00:46:46.170
Otherwise, when the end PC is met, we just
initiate a state comparison and report any

00:46:46.170 --> 00:46:52.510
divergence detected there.
So, in fact, we can configure the self-verification

00:46:52.510 --> 00:46:59.180
in one of two modes. Blocking versus nonblocking.
If we just implement a brand-new optimization,

00:46:59.180 --> 00:47:05.210
we want to run that in the blocking mode because
the VM will just freeze the application if

00:47:05.210 --> 00:47:09.070
there is a divergence detected, and that will
get our immediate attention.

00:47:09.070 --> 00:47:15.370
But if the goal is to find corner case
bugs which may take longer to surface, we want

00:47:15.370 --> 00:47:20.350
to run that in the nonblocking mode where
the VM will allow the application to continue

00:47:20.350 --> 00:47:24.440
as long as the debug information is recorded
in the log.

00:47:24.440 --> 00:47:30.310
In this way, you can do stress testing on
your primary phone, 24 by 7, without the worry

00:47:30.310 --> 00:47:37.310
that the phone is not functional when you
need to use that.

00:47:37.690 --> 00:47:44.690
And so the phone here, the second phone here
is actually running a self-verification in

00:47:45.040 --> 00:47:47.720
a nonblocking mode. And that's why the phone
is still usable.

00:47:47.720 --> 00:47:52.670
And I am going to use the extracted example
here to go through the meaning of the debug

00:47:52.670 --> 00:47:57.350
information, and I am going to show you the
life log after that.

00:47:57.350 --> 00:48:02.910
So first you will see a clear message telling
you that some kind of divergence are detected

00:48:02.910 --> 00:48:07.390
in the registers.
It will also tell you the class name, method

00:48:07.390 --> 00:48:14.390
name and the Dalvik PC of the offending translation.
Then it will tell you the instruction sequence

00:48:14.590 --> 00:48:21.550
executed by the interpreter before the divergence
is detected. In this case here, the interpreter

00:48:21.550 --> 00:48:27.360
executes a constant 16 instruction followed
by if greater equal instruction.

00:48:27.360 --> 00:48:32.220
It will also tell you where the divergence
comes from. In this case here, it's in the

00:48:32.220 --> 00:48:38.360
v0 register in the Dalvik stack frame. In
the interpreter versions it's B5. In the JIT'd

00:48:38.360 --> 00:48:44.350
code it's v6. And remember the injected bug
is count 16 where the JIT'd value is one greater

00:48:44.350 --> 00:48:50.010
than the interpreter value.
Since we manage the code cache by not only

00:48:50.010 --> 00:48:55.800
storing the generated code but also the original
trace information, we can easily replay the

00:48:55.800 --> 00:49:01.420
compilation request with verbose mode turned
on so that you can see the Dalvik code and

00:49:01.420 --> 00:49:05.430
the corresponding native code.
And that's exactly the same mechanism used

00:49:05.430 --> 00:49:09.720
by the profiler to report the content of the
hot translations.

00:49:09.720 --> 00:49:16.620
So in this particular example here, um see
that the constant 16 is trying to load value

00:49:16.620 --> 00:49:23.620
181 into V zero and since we know the divergence
is in V zero we just follow the native code

00:49:23.760 --> 00:49:30.440
that touches the same location on the stack.
Right now the registry allocator will reserve

00:49:30.440 --> 00:49:36.810
R5 as the frame-based pointer. And since V0
is the first slot on the stack, so we know

00:49:36.810 --> 00:49:43.810
it must the store R0 R5 plus zero that deposits
the bad value onto the stack.

00:49:43.910 --> 00:49:49.140
Then we follow the used stack chain on R0.
Then we see, oh, this move here is trying

00:49:49.140 --> 00:49:55.690
to load 182 to R0, but the original byte code
is trying to load 181, and bingo, we have

00:49:55.690 --> 00:50:00.780
found the bug.
Now let me show you the life log spewed on

00:50:00.780 --> 00:50:07.780
the phone here.
I just type AVB log Cad. You can see a lot

00:50:20.070 --> 00:50:27.070
of live debugging information is spewed on
the phone as we are using that.

00:50:27.430 --> 00:50:33.290
And hopefully through the example here, you
see there's trends of self-verification, because

00:50:33.290 --> 00:50:39.280
that's easy to use. It provides really good
test coverage, and you will isolate and report

00:50:39.280 --> 00:50:43.710
any problem found.
And that's why we get to spend more time writing

00:50:43.710 --> 00:50:50.710
useful optimization code than debugging.
Okay. So to wrap up today's talk, over the

00:50:54.630 --> 00:51:00.180
past year, our team has delivered a resource
friendly JIT for the Dalvik version machine

00:51:00.180 --> 00:51:05.790
from ground up. We pay special attention to
the memory overhead, so that it can fit the

00:51:05.790 --> 00:51:11.600
budget on embedded systems. And through a
set of CPU intensive workloads, we demonstrated

00:51:11.600 --> 00:51:18.600
that it can provide 2 to 5x speedup over the
Eclair release. And we already have new optimizations

00:51:19.880 --> 00:51:26.220
waiting in the pipeline, and we believe JIT
will enable a new class of applications for

00:51:26.220 --> 00:51:32.390
the Android platform. So in your new application,
if you can provide an easy way to find out

00:51:32.390 --> 00:51:36.900
the performance numbers, like the checkers
game, we'll be more than happy to use your

00:51:36.900 --> 00:51:42.000
application as a real world benchmark to explore
new optimization opportunities in the JIT.

00:51:42.000 --> 00:51:48.200
And last but not least, we have the hard working
verification robot in the Dalvik land, so

00:51:48.200 --> 00:51:52.410
that's why we encourage people to just sit
back, relax enjoy the speedup from the JIT.

00:51:52.410 --> 00:51:59.410
Thank you. That's all we have.
[ Applause ]

00:52:01.510 --> 00:52:08.510
&gt;&gt;Bill Buzbee: Now we have some time to take
a few questions.

00:52:10.450 --> 00:52:13.870
And probably best to go to the microphone
so that people can hear.

00:52:13.870 --> 00:52:20.830
&gt;&gt;Ben Cheng: There's one.
&gt;&gt;Bill Buzbee: Yes.

00:52:20.830 --> 00:52:27.200
&gt;&gt;&gt; Okay. I'm just curious, before you --
 since you are verifying the JIT against your

00:52:27.200 --> 00:52:30.430
interpreter, are you 100% sure you don't have
bugs in the interpreter?

00:52:30.430 --> 00:52:35.320
&gt;&gt;Bill Buzbee: Yeah, the -- we're -- the interpreter
has been pounded on quite well.

00:52:35.320 --> 00:52:40.020
In fact, one of the reasons why the interpreter
is such a nice thing to compare against is

00:52:40.020 --> 00:52:45.390
that it's really -- you can think of it is
that there's only 230 or so Dalvik bytecodes.

00:52:45.390 --> 00:52:50.240
And the interpreter deals with them individually.
So you can individually validate each of those

00:52:50.240 --> 00:52:54.370
230.
What makes the JIT more difficult to validate

00:52:54.370 --> 00:52:59.310
is that when we optimize, we're interleaving
instructions, we're rearranging things, and

00:52:59.310 --> 00:53:03.580
so the combination effects makes it much tougher
to validate.

00:53:03.580 --> 00:53:08.240
The interpreter is relatively simple to make
sure that's correct.

00:53:08.240 --> 00:53:09.890
And our interpreter's been solid for quite
a while.

00:53:09.890 --> 00:53:11.550
&gt;&gt;&gt; Okay.
Second quick question.

00:53:11.550 --> 00:53:16.460
When you have a trace that contains a branch
instruction, or when you start -- you mentioned

00:53:16.460 --> 00:53:23.460
stitching traces together, how do you know
that the state of all the variables, the stack,

00:53:24.130 --> 00:53:28.220
the heap, anything that trace can refer to,
is consistent between multiple runs of that

00:53:28.220 --> 00:53:30.700
trace?
In other words, how do you know the trace

00:53:30.700 --> 00:53:34.060
 -- the trace is actually valid if it includes
a branch instruction when you start running

00:53:34.060 --> 00:53:38.310
it, how do you know you're actually going
to start following the branch when you run

00:53:38.310 --> 00:53:45.310
the trace ahead of the branch instruction?
&gt;&gt;Bill Buzbee: So the trace will kind of re-evaluate

00:53:47.370 --> 00:53:52.359
all of its variables as it's running.
The one -- what you may be getting at is 

00:53:52.359 --> 00:53:56.180
-- Ben, do you want to talk a little bit about
the predicted invokes?

00:53:56.180 --> 00:54:01.170
&gt;&gt;Ben Cheng: Yes.
So for Java virtual calls, we try to chain

00:54:01.170 --> 00:54:08.170
the call side to the most likely callee.
But we do keep a live profiling count as the

00:54:08.660 --> 00:54:13.800
invocation is dispatched.
If we find that we mispredict too often, we

00:54:13.800 --> 00:54:17.240
will try to rechain that to the currently
most likely callee.

00:54:17.240 --> 00:54:20.520
So we do have some dynamic learning system
in the JIT'd code.

00:54:20.520 --> 00:54:25.830
&gt;&gt;&gt; 

00:54:25.830 --> 00:54:32.450
So if I understood correctly, for each process,
you compile; right? So it's separate.

00:54:32.450 --> 00:54:38.990
So how about system libraries?
Do they also compile each time in each process?

00:54:38.990 --> 00:54:43.820
&gt;&gt;Bill Buzbee: Yes.
So in this release, the answer is yes.

00:54:43.820 --> 00:54:47.240
We don't pay attention to where the execution
comes from.

00:54:47.240 --> 00:54:53.530
And so if multiple processes are using the
same system code, each will have its private

00:54:53.530 --> 00:54:56.350
hot traces.
And those traces may be different from process

00:54:56.350 --> 00:55:00.870
to process.
We have explored some future possibilities

00:55:00.870 --> 00:55:07.870
of having some kind of canned, precompiled,
preoptimized traces for common system stuff.

00:55:08.310 --> 00:55:13.680
But we don't have that in first release.
&gt;&gt;&gt; And I have a question, it's not directly

00:55:13.680 --> 00:55:18.290
related to JIT, but how about garbage collection,
can you say anything?

00:55:18.290 --> 00:55:23.180
Did it get faster on Froyo?
&gt;&gt;Ben Cheng: All we can say is we have colleagues

00:55:23.180 --> 00:55:25.200
currently working on that.
&gt;&gt;&gt; Okay.

00:55:25.200 --> 00:55:27.560
&gt;&gt;Ben Cheng: But maybe that will be the next
milestone release.

00:55:27.560 --> 00:55:30.319
&gt;&gt;&gt; Okay.
Thanks.

00:55:30.319 --> 00:55:33.300
&gt;&gt;&gt; Hi.
I had two questions.

00:55:33.300 --> 00:55:38.820
The first one was, does it work on X86?
And the seconds was, are you generating Thumb

00:55:38.820 --> 00:55:42.790
instructions and ARM instructions or just
Thumb or what's going on?

00:55:42.790 --> 00:55:46.980
&gt;&gt;Bill Buzbee: Okay.
So this release -- this release of the JIT

00:55:46.980 --> 00:55:52.180
is for ARM processors.
And we will generate -- in general, we try

00:55:52.180 --> 00:55:57.870
to generate Thumb instructions for the traces,
but we'll occasionally branch out to common

00:55:57.870 --> 00:56:02.700
routines that are done in ARM.
And we'll either generate Thumb or Thumb-2,

00:56:02.700 --> 00:56:06.400
depending on the -- what's supported by the
underlying processor.

00:56:06.400 --> 00:56:11.900
We also will understand whether the underlying
processor has VFP floating point, and we'll

00:56:11.900 --> 00:56:16.500
either use those instructions or generate
calls out to run-time support routines to

00:56:16.500 --> 00:56:20.070
handle floating point.
It's configurable when you build the JIT.

00:56:20.070 --> 00:56:24.610
&gt;&gt;&gt; And so only -- only ARM right now?
Is that what you meant?

00:56:24.610 --> 00:56:26.730
&gt;&gt;Bill Buzbee: That's correct.
Only ARM processors today.

00:56:26.730 --> 00:56:33.280
&gt;&gt;&gt; Okay.
&gt;&gt;Ben Cheng: do you want to ask a question

00:56:33.280 --> 00:56:37.350
from the moderator?
&gt;&gt;Bill Buzbee: Oh, moderator questions.

00:56:37.350 --> 00:56:40.440
Power savings.
So the power savings question is much like

00:56:40.440 --> 00:56:47.440
the general performance.
We -- a little bit like that.

00:56:48.160 --> 00:56:52.690
When we're doing less -- you know, taking
less CPU cycles to do the same amount of work,

00:56:52.690 --> 00:56:55.980
we'll be saving the power that would have
been consumed by those CPU cycles.

00:56:55.980 --> 00:57:02.980
I wouldn't expect you to notice a big power
difference in normal usage, because the primary

00:57:03.010 --> 00:57:07.360
consumer of power on the devices is generally
going to be the display and the radios.

00:57:07.360 --> 00:57:12.120
And then what's left over is the CPU and memory.
And we'll compress the CPU cycles somewhat.

00:57:12.120 --> 00:57:17.730
So we expect that to be positive, but it was
not the primary motivation for doing the JIT.

00:57:17.730 --> 00:57:24.730
Performance was the primary motivation.
&gt;&gt;Ben Cheng: So the next one is how well does

00:57:25.170 --> 00:57:30.430
the JIT compiler use the native processor?
Does it produce generic ARMv 5 code or is

00:57:30.430 --> 00:57:34.040
it smart enough to optimize on ARMv 9 with
neon extensions.

00:57:34.040 --> 00:57:36.840
&gt;&gt;Bill Buzbee: I think we answered that one.
It's configurable.

00:57:36.840 --> 00:57:43.840
&gt;&gt;Ben Cheng: The next is, what kind of memory
footprint is the JIT compiler aiming for and

00:57:46.480 --> 00:57:52.720
how much will be left for the application
after enabling JIT compilation?

00:57:52.720 --> 00:57:59.340
So we aimed for 100K.
&gt;&gt;Bill Buzbee: Our target was about 100K.

00:57:59.340 --> 00:58:05.340
The Nexus One has more memory, so we kind
of relaxed the constraints for that.

00:58:05.340 --> 00:58:10.150
But it's also a configurable thing, too.
We can kind of cap the max usage of memory.

00:58:10.150 --> 00:58:13.300
But, in general, we were shooting for about
100K bytes per process.

00:58:13.300 --> 00:58:17.130
&gt;&gt;Ben Cheng: Yeah, so I think we'll answer
the last question here.

00:58:17.130 --> 00:58:23.760
So people's tests indicate it will be up to
450% faster, but how noticeable is the change

00:58:23.760 --> 00:58:28.500
to the end user?
So the answer is, your mileage may vary.

00:58:28.500 --> 00:58:34.540
So suppose you have a workload where 50% of
the cycles are in the graphics and 50% in

00:58:34.540 --> 00:58:38.270
the VM.
Even though we provide 5X speedup on the VM

00:58:38.270 --> 00:58:43.620
part, you're only going to notice 40% gain.
So it really depends on the distribution of

00:58:43.620 --> 00:58:48.840
the work cycles to begin with.
And I think we have run out of time.

00:58:48.840 --> 00:58:50.600
&gt;&gt;Bill Buzbee: Oh, yes.
&gt;&gt;&gt; One more.

00:58:50.600 --> 00:58:54.450
&gt;&gt;&gt; (inaudible) has had Gazelle instruction
set for quite some time, and Android for now

00:58:54.450 --> 00:59:01.450
is primarily targeted for ARM, you know, hardware.
Do you -- can you elaborate on Dalvik's use

00:59:04.140 --> 00:59:09.210
of Gazelle instruction set?
And if not, is Google working with ARM for

00:59:09.210 --> 00:59:13.920
future optimizations on the chipset itself?
&gt;&gt;Bill Buzbee: Well, let me just make that

00:59:13.920 --> 00:59:17.420
really brief.
The -- we're not using the -- actually, I

00:59:17.420 --> 00:59:23.590
think what you're shooting for is the Thumb-2e
extensions that kind of are in ARM processors

00:59:23.590 --> 00:59:28.330
to support JIT compilation.
Those are good things, but if you look at

00:59:28.330 --> 00:59:33.490
them more carefully, what they really do is,
they will boost an interpreter's speed when

00:59:33.490 --> 00:59:36.170
it's handling bytecodes one at a time.
Okay?

00:59:36.170 --> 00:59:39.820
They make things go faster if you don't try
to intermix instructions.

00:59:39.820 --> 00:59:44.770
The gain from the JIT happens because we're
able to take a collection of instructions

00:59:44.770 --> 00:59:51.770
and interleave them with scheduling and optimization.
And in that environment, the kind of hardware

00:59:51.770 --> 00:59:56.020
execution of bytecode model actually holds
you back a little bit.

00:59:56.020 --> 01:00:00.390
So we believe we're faster with this model
than we would have been if we had actually

01:00:00.390 --> 01:00:06.830
used hardware acceleration of individual bytecode
execution.

01:00:06.830 --> 01:00:08.350
And I think we are -- we are really out of
time.

01:00:08.350 --> 01:00:09.440
&gt;&gt;Ben Cheng: Okay.
Thank you.

