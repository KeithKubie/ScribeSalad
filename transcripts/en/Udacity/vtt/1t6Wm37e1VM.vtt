WEBVTT
Kind: captions
Language: en

00:00:00.340 --> 00:00:01.340
Okay Michael, are you ready?

00:00:01.340 --> 00:00:03.310
&gt;&gt; I am afraid so.

00:00:03.310 --> 00:00:06.710
&gt;&gt; All right, which one do you want to fill out first?

00:00:06.710 --> 00:00:10.600
&gt;&gt; Let's just do them in order, so ,one nearest neighbor. You, you explained,

00:00:10.600 --> 00:00:13.490
how the training works. We just take the assorted list, and leave it there.

00:00:13.490 --> 00:00:14.310
&gt;&gt; Mm-hm.

00:00:14.310 --> 00:00:19.440
&gt;&gt; And we have the classifier, or the aggressor itself ,has linear space,

00:00:19.440 --> 00:00:23.900
and now at query time, we need to find the nearest neighbor, Um-huh.

00:00:23.900 --> 00:00:25.600
&gt;&gt; Which we could do by taking the query

00:00:25.600 --> 00:00:29.560
point, and running through the whole list ,and seeing which

00:00:29.560 --> 00:00:33.140
one it's closest to, but, because, it's sorted I think

00:00:33.140 --> 00:00:35.740
we, we outta be able to use binary search and,

00:00:35.740 --> 00:00:41.690
and in log time, find the closest, point to the query.

00:00:41.690 --> 00:00:43.350
&gt;&gt; That's exactly right, you should be able to do

00:00:43.350 --> 00:00:47.000
that in log base, two time. What if it weren't sorted?

00:00:47.000 --> 00:00:50.630
&gt;&gt; Yeah then, like I said, I think you could just scan through the whole

00:00:50.630 --> 00:00:53.290
list and that would be linear time and that's not a big deal.

00:00:53.290 --> 00:00:55.820
&gt;&gt; Right, yeah, we could do linear time, but, because I gave you a

00:00:55.820 --> 00:00:58.210
sorted list, because, I'm so helpful, you

00:00:58.210 --> 00:00:59.690
can do it in [INAUDIBLE] time, okay, but.

00:00:59.690 --> 00:01:01.860
&gt;&gt; That was, that was very, very thoughtful of you.

00:01:01.860 --> 00:01:04.500
&gt;&gt; It was I thought, I thought of her, so what about on the, space side?

00:01:04.500 --> 00:01:09.960
&gt;&gt; Alright, so the amount of space that you need to process its query is

00:01:09.960 --> 00:01:12.430
linear. We don't need to take any special,

00:01:12.430 --> 00:01:16.230
set aside, space beyond, a couple simple variables.

00:01:16.230 --> 00:01:19.150
And the data that we're given, which we've already accounted for.

00:01:19.150 --> 00:01:21.750
&gt;&gt; Right, so then why would it be linear, if we accounted for it?

00:01:21.750 --> 00:01:23.530
&gt;&gt; Did I say linear? I meant constant.

00:01:23.530 --> 00:01:24.600
&gt;&gt; Yes, yes, that's right,

00:01:26.890 --> 00:01:29.240
constant. That's what you meant. That's what you said. That's what happened.

00:01:29.240 --> 00:01:30.948
&gt;&gt; [LAUGH]

00:01:30.948 --> 00:01:31.220
&gt;&gt; Okay.

00:01:31.220 --> 00:01:33.210
&gt;&gt; It's a good thing, this wasn't being recorded,

00:01:33.210 --> 00:01:34.695
so we could verify one way or the other.

00:01:34.695 --> 00:01:35.800
&gt;&gt; [LAUGH] It is a good thing, maybe we'll

00:01:35.800 --> 00:01:38.391
look it up on Wikipedia, and it'll say confusingly [LAUGH]

00:01:38.391 --> 00:01:40.400
&gt;&gt; Linear sometimes use to mean constant.

00:01:40.400 --> 00:01:44.030
&gt;&gt; Constant. [LAUGH]. Yeah, that is pretty confusing.

00:01:44.030 --> 00:01:45.510
&gt;&gt; Okay, what about k and n?

00:01:45.510 --> 00:01:48.930
&gt;&gt; Alright, K and n. So k and n, so the training process,

00:01:48.930 --> 00:01:52.080
the learning process, is exactly the same, as it is for one year stamper,

00:01:52.080 --> 00:01:54.810
which is to say you do nothing and you pass all the data

00:01:54.810 --> 00:01:58.890
forward, to the, The query processor. So it's going to be 1 n.

00:01:58.890 --> 00:02:00.980
&gt;&gt; That is correct, nice.

00:02:00.980 --> 00:02:05.000
&gt;&gt; Now querying, seems like its a little more subtle. So

00:02:05.000 --> 00:02:07.640
we can find the single nearest neighbor in log and time.

00:02:07.640 --> 00:02:08.241
&gt;&gt; Mm-mm.

00:02:08.241 --> 00:02:12.950
&gt;&gt; Where we going to get the other K minus one? So, I'm pretty sure,

00:02:12.950 --> 00:02:17.500
that ,once we find the nearest neighbor we can kind of start doing a little,

00:02:17.500 --> 00:02:20.700
Spread out search, from there, until we found the k nearest neighbors.

00:02:20.700 --> 00:02:22.940
&gt;&gt; Sure. So, you're saying, you know,

00:02:22.940 --> 00:02:24.380
you've got these points. They're already in a

00:02:24.380 --> 00:02:27.653
line, you find the nearest neighbor. You

00:02:27.653 --> 00:02:29.530
know ,the, the next nearest neighbors have to

00:02:29.530 --> 00:02:35.360
be within k of the points surrounding it, and so you can just move in

00:02:35.360 --> 00:02:39.370
kind of, either direction and pick them up as you go. Yeah, something like that.

00:02:39.370 --> 00:02:39.920
&gt;&gt; Okay.

00:02:39.920 --> 00:02:40.950
&gt;&gt; I mean the way that, the way that I

00:02:40.950 --> 00:02:42.540
was thinking about it is that, I, I think you

00:02:42.540 --> 00:02:46.440
can use the same algorithm that you used for merging lists, in merge sort,

00:02:46.440 --> 00:02:50.420
but here the lists actually corresponds, to being, to the left of the query

00:02:50.420 --> 00:02:53.340
point, and being to the right of the query point and they are both

00:02:53.340 --> 00:02:57.920
sorted ,in terms of their distance from the query point. Sure, yeah, I buy that.

00:02:57.920 --> 00:03:01.690
&gt;&gt; So, so that ought to give us log n, plus k.

00:03:01.690 --> 00:03:04.220
&gt;&gt; Okay, so, do we need to write the k?

00:03:04.220 --> 00:03:07.600
&gt;&gt; I'm going to say yes, because, if k is

00:03:07.600 --> 00:03:11.530
on the order of like, n over 2, then it's going to dominate. If k is on

00:03:11.530 --> 00:03:13.090
the order of log n, then it's not

00:03:13.090 --> 00:03:15.180
going to dominate. Mm, that's a good point. So,

00:03:15.180 --> 00:03:17.760
yeah, we'll do k. I will point out that if k is on the order of

00:03:17.760 --> 00:03:20.960
n over 2, you're right, it will dominate, and then really this is big o of n.

00:03:20.960 --> 00:03:21.830
&gt;&gt; That's right.

00:03:21.830 --> 00:03:24.240
&gt;&gt; But if it's on the order of log n, then it's

00:03:24.240 --> 00:03:26.440
just log n plus n, and so it's a big old long

00:03:26.440 --> 00:03:28.660
n, log n. But ,you're right, so we should probably keep the

00:03:28.660 --> 00:03:32.740
k around because, we don't know its relationship to n. Okay, fair enough.

00:03:32.740 --> 00:03:34.600
Okay, what about the space requirements?

00:03:34.600 --> 00:03:37.230
&gt;&gt; We know one bit of relationship, it's smaller than or equal to n.

00:03:37.230 --> 00:03:38.350
&gt;&gt; That's true.

00:03:38.350 --> 00:03:39.580
&gt;&gt; Because that would be really weird, if I gave you

00:03:39.580 --> 00:03:41.510
ten data points and asked you for the 20 nearest neighbors.

00:03:41.510 --> 00:03:43.640
&gt;&gt; That's the sort of thing you would do.

00:03:43.640 --> 00:03:44.480
&gt;&gt; It's the sort of thing you would

00:03:44.480 --> 00:03:46.530
do, but then ,it would be really confusing.

00:03:46.530 --> 00:03:47.110
&gt;&gt; No, no, no, it's the sort of

00:03:47.110 --> 00:03:48.940
thing YOU would do, again, let's go to Wikipedia.

00:03:48.940 --> 00:03:52.136
&gt;&gt; Confusingly, twenty sometimes means ten. [LAUGH]

00:03:52.136 --> 00:03:53.970
&gt;&gt; Okay. So what about space?

00:03:53.970 --> 00:03:56.630
&gt;&gt; Space, so, I don't understand why,

00:03:56.630 --> 00:03:58.170
it would ever need more than constant space.

00:03:58.170 --> 00:04:01.680
So, so we're going to, zip around in that. I mean, I guess, if

00:04:01.680 --> 00:04:05.550
do it really badly ,we can use K space. To kind of copy over

00:04:05.550 --> 00:04:09.178
what those, possible nearest neighbors are. But ,we don't need to keep track

00:04:09.178 --> 00:04:12.530
of them. We can just point to them in place, so it's constant.

00:04:12.530 --> 00:04:13.030
&gt;&gt; Okay,

00:04:15.180 --> 00:04:17.649
yea that's true in fact, because, it's sorted all you really need

00:04:17.649 --> 00:04:21.110
to know is the beginning and the ending. So, that's two things

00:04:21.110 --> 00:04:23.900
that's constant. Okay, cool, alright, good,

00:04:23.900 --> 00:04:25.380
so what about linear regression? Your

00:04:25.380 --> 00:04:29.470
favorite little algorithm thing that you did? When we talked about this before.

00:04:29.470 --> 00:04:32.030
&gt;&gt; I do like, linear regression. The learning in

00:04:32.030 --> 00:04:35.070
this case, is what we are mapping, real number

00:04:35.070 --> 00:04:37.730
input to a real number output. The way we

00:04:37.730 --> 00:04:41.020
are doing that is we are taking, its probably

00:04:41.020 --> 00:04:44.310
M X plus B sort of form [CROSSTALK]. We

00:04:44.310 --> 00:04:48.020
need to find, the multiplier and the additive constant. which,

00:04:48.020 --> 00:04:52.450
It seems, like, in general doing a regression involves,

00:04:52.450 --> 00:04:54.920
inverting a matrix. But, in this case,I think the matrix

00:04:54.920 --> 00:04:57.190
that we're talking about is of constant size. So

00:04:57.190 --> 00:05:00.152
inverting, is, constant time. I think, it's as easy ,as

00:05:00.152 --> 00:05:03.014
basically just scanning through the list ,to populate that,

00:05:03.014 --> 00:05:06.030
that ,constant size matrix. So, I'm going to say order n.

00:05:06.030 --> 00:05:06.650
&gt;&gt; Yep.

00:05:06.650 --> 00:05:08.060
&gt;&gt; To process the data.

00:05:08.060 --> 00:05:09.110
&gt;&gt; That is correct.

00:05:09.110 --> 00:05:12.190
&gt;&gt; There's probably a really nice algorithm for that.

00:05:12.190 --> 00:05:13.940
&gt;&gt; Yeah, probably some kind of linear regression algorithm.

00:05:13.940 --> 00:05:16.620
&gt;&gt; Yeah. [LAUGH] No, I mean like the general

00:05:16.620 --> 00:05:20.130
linear regression algorithm is, is involves inverting a matrix.

00:05:20.130 --> 00:05:20.550
&gt;&gt; Right.

00:05:20.550 --> 00:05:24.060
&gt;&gt; Or something like it, something equivalent to it. But here

00:05:24.060 --> 00:05:27.730
because, we're, it's all in scaler land, I think it's simpler.

00:05:27.730 --> 00:05:30.060
&gt;&gt; Yeah, I think that's right. Okay ,so what about space?

00:05:30.060 --> 00:05:31.270
&gt;&gt; All right, so space interpreted

00:05:31.270 --> 00:05:32.960
the data that you passed forward from

00:05:32.960 --> 00:05:37.960
the learning algorithm, to the regressor, is just,

00:05:37.960 --> 00:05:41.960
well MX plus B. It's just M and B, which is constant. There's the two numbers.

00:05:41.960 --> 00:05:43.936
&gt;&gt; Right, that's 2, 2 is like 1,

00:05:43.936 --> 00:05:46.740
[UNKNOWN] large values [LAUGH] of 1, so it's constant.

00:05:46.740 --> 00:05:51.530
&gt;&gt; Yeah, All right, now at query time, you give me an X.

00:05:51.530 --> 00:05:56.070
I multiply, it by M and add B, so that's constant time [CROSSTALK]. So,

00:05:56.070 --> 00:05:59.080
before the query, cost was expensive and the learning

00:05:59.080 --> 00:06:01.310
cost was cheap. And now we've kind of swapped that around.

00:06:02.490 --> 00:06:05.470
&gt;&gt; Yeah, we have, so space would be.

00:06:05.470 --> 00:06:07.060
&gt;&gt; Space, oh, that you're asking me?

00:06:07.060 --> 00:06:07.390
&gt;&gt; Yeah.

00:06:07.390 --> 00:06:10.130
&gt;&gt; Space for the query would be constant as well.

00:06:10.130 --> 00:06:11.860
&gt;&gt; Right, exactly, so yeah, so you made

00:06:11.860 --> 00:06:13.830
a good point here. So earlier on, we had

00:06:13.830 --> 00:06:17.360
the situation where learning was fast, was constant, and

00:06:17.360 --> 00:06:21.070
querying was, you know, not as fast. It was,

00:06:21.070 --> 00:06:24.480
you know, probably logarithmic. But, in the regression case,

00:06:24.480 --> 00:06:29.290
learning was expensive and the querying was easy, so

00:06:29.290 --> 00:06:31.580
we swapped around, that's exactly right. So, why would

00:06:31.580 --> 00:06:34.650
you care about that, well, let's see, I'll point

00:06:34.650 --> 00:06:36.510
out something, which is though, even though we swapped

00:06:36.510 --> 00:06:38.370
out what was expensive in terms of time and

00:06:38.370 --> 00:06:42.910
what wasn't, you'll notice that. It's only logarithmic at

00:06:42.910 --> 00:06:47.120
query time for these first two but it's linear for

00:06:47.120 --> 00:06:49.240
the learning time, in, linear regression, so doesn't that

00:06:49.240 --> 00:06:52.110
mean that linear regression is always slower and worse?

00:06:52.110 --> 00:06:55.940
&gt;&gt; No really, because we only have to

00:06:55.940 --> 00:06:58.430
learn once, but we can query many, many times.

00:06:58.430 --> 00:07:03.210
&gt;&gt; Right, right. So I guess if we query more than, you know,

00:07:03.210 --> 00:07:05.520
n times for example ,it'll certainly be,

00:07:05.520 --> 00:07:08.040
worse overall. In terms of running time.

00:07:08.040 --> 00:07:08.990
&gt;&gt; That's right.

00:07:08.990 --> 00:07:09.440
&gt;&gt; Okay.

00:07:09.440 --> 00:07:12.190
&gt;&gt; Though, it's, though it's interesting, because like when I see numbers

00:07:12.190 --> 00:07:15.470
like this, my, my algorithm, hat tells me that

00:07:15.470 --> 00:07:17.520
I should try to balance them a little bit more.

00:07:17.520 --> 00:07:20.140
Like, here it's, it's you can make, learning ,essentially

00:07:20.140 --> 00:07:22.280
free and the other one you can make querying essentially

00:07:22.280 --> 00:07:26.180
free. Really you want to split those, somewhat evenly. Though

00:07:26.180 --> 00:07:27.720
it's, not obvious to me how you would do that.

00:07:27.720 --> 00:07:30.700
Like, square root of n, learning time and then

00:07:30.700 --> 00:07:32.470
square root of n query time or something like that.

00:07:32.470 --> 00:07:33.910
&gt;&gt; Yeah, but you did say something else that was

00:07:33.910 --> 00:07:35.779
important right? Which is that you only have to learn once.

00:07:37.210 --> 00:07:38.420
&gt;&gt; Yeah, It's true.

00:07:38.420 --> 00:07:40.880
&gt;&gt; So, the balance you know, really depends

00:07:40.880 --> 00:07:42.070
on how often you're going to do querying and

00:07:42.070 --> 00:07:43.640
exactly, what power it gives you. I mean,

00:07:43.640 --> 00:07:45.190
the trade off is really there. Don't you think?

00:07:45.190 --> 00:07:47.660
&gt;&gt; Yeah, I guess so. I mean so, so specifically,

00:07:47.660 --> 00:07:50.200
in the, in the version where you just query ones.

00:07:50.200 --> 00:07:50.820
&gt;&gt; Right.

00:07:50.820 --> 00:07:53.240
&gt;&gt; Then the balance thing could be more interesting.

00:07:53.240 --> 00:07:54.940
&gt;&gt; Sure, okay, cool. All right anything else

00:07:54.940 --> 00:07:57.230
you want to observe about this. Let's see,

00:07:57.230 --> 00:07:59.060
we got the trade off between learning versus

00:07:59.060 --> 00:08:00.990
querying. So, either you do all your work upfront,

00:08:02.030 --> 00:08:07.380
or, you put it ,off ,and do your work only, when you're forced to at query time.

00:08:07.380 --> 00:08:10.330
&gt;&gt; Yeah, I guess, well one thing, is, I want to point out that there's

00:08:10.330 --> 00:08:13.320
a nice Mr. Rodgers, reference in the title. That was, that was very cool.

00:08:13.320 --> 00:08:16.110
&gt;&gt; Thank you very much. And the second thing, is

00:08:16.110 --> 00:08:19.390
that it does strike me, in a sense, that what's going

00:08:19.390 --> 00:08:21.700
on here for the nearest neighbor algorithms, is that you

00:08:21.700 --> 00:08:24.440
just put off ,doing any work until you absolutely have to.

00:08:24.440 --> 00:08:25.641
&gt;&gt; Mm-hm.

00:08:25.641 --> 00:08:29.450
&gt;&gt; Which strikes me as kind of a procrastinatory approach.

00:08:29.450 --> 00:08:32.919
&gt;&gt; So that's a good word, that you used there, procrastinate.

00:08:32.919 --> 00:08:35.539
The words that people use, in the literature, are ,uh, lazy.

00:08:35.539 --> 00:08:37.669
&gt;&gt; Mm.

00:08:37.669 --> 00:08:40.169
&gt;&gt; They say that these are lazy learners, versus

00:08:40.169 --> 00:08:42.900
something like linear regression, which is an eager learner.

00:08:42.900 --> 00:08:44.290
&gt;&gt; Eager.

00:08:44.290 --> 00:08:47.870
&gt;&gt; Yes. So, linear regression, is eager, it wants to learn right away, and it

00:08:47.870 --> 00:08:50.510
does, but nearest neighbor algorithms are lazy. They

00:08:50.510 --> 00:08:54.566
want to put off, learning until they absolutely ,have

00:08:54.566 --> 00:08:58.029
to, and so we refer to this class ,as lazy and this class as eager.

00:08:58.029 --> 00:09:00.950
&gt;&gt; I See, so I guess its the case, that, if

00:09:00.950 --> 00:09:04.340
we never query it, then the lazy learner definitely comes out ahead.

00:09:04.340 --> 00:09:05.690
&gt;&gt; Right, that makes sense.

00:09:05.690 --> 00:09:06.600
&gt;&gt; Yeah.

00:09:06.600 --> 00:09:10.800
&gt;&gt; It's just in time learning, or JIL. [LAUGH]

00:09:10.800 --> 00:09:12.750
Or JITL, I guess, which doesn't roll off the tongue

00:09:12.750 --> 00:09:15.050
anywhere near as well. Okay, cool. So we've gotten

00:09:15.050 --> 00:09:16.790
through this quiz. Would you like to do another one?

00:09:16.790 --> 00:09:18.860
&gt;&gt; Yeah, I just have to get this JITL off my tongue.

00:09:18.860 --> 00:09:21.090
&gt;&gt; [LAUGH]

