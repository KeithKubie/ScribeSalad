WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.393
[MUSIC PLAYING]

00:00:04.393 --> 00:00:06.060
SANDEEP GUPTA: My
name is Sandeep Gupta.

00:00:06.060 --> 00:00:07.850
I'm a product manager in Google.

00:00:07.850 --> 00:00:09.558
YANNICK ASSOGBA: And
I'm Yannick Assogba,

00:00:09.558 --> 00:00:11.808
and I'm a software engineer
on the TensorFlow.js team.

00:00:11.808 --> 00:00:13.933
SANDEEP GUPTA: And we are
here to talk to you today

00:00:13.933 --> 00:00:15.740
about machine learning
and JavaScript.

00:00:15.740 --> 00:00:17.660
So the video that
you just saw, this

00:00:17.660 --> 00:00:20.870
was our very first
AI-inspired Google Doodle.

00:00:20.870 --> 00:00:22.670
And it was able to
bring machine learning

00:00:22.670 --> 00:00:24.860
to life in a very
fun and creative way

00:00:24.860 --> 00:00:26.570
to millions of users.

00:00:26.570 --> 00:00:28.670
And what users were
able to do with this

00:00:28.670 --> 00:00:31.480
is that you're able to use a
machine learning model directly

00:00:31.480 --> 00:00:34.070
running in the browser
that was able to synthesize

00:00:34.070 --> 00:00:35.810
a box-style harmony.

00:00:35.810 --> 00:00:39.080
And what made this possible
was this library called

00:00:39.080 --> 00:00:41.000
TensorFlow.js.

00:00:41.000 --> 00:00:44.300
So TensorFlow.js is an
open-source library for machine

00:00:44.300 --> 00:00:46.010
learning in JavaScript.

00:00:46.010 --> 00:00:49.070
It's part of the TensorFlow
family of products,

00:00:49.070 --> 00:00:52.670
and it's built specifically to
make it easier for JavaScript

00:00:52.670 --> 00:00:54.890
developers to build
and use machine

00:00:54.890 --> 00:00:59.260
learning models within their
JavaScript applications.

00:00:59.260 --> 00:01:03.500
You use this library
in one of three ways.

00:01:03.500 --> 00:01:07.030
You can use one of the
pre-existing pre-trained models

00:01:07.030 --> 00:01:10.510
that we provide, and directly
run them within your JavaScript

00:01:10.510 --> 00:01:11.770
applications.

00:01:11.770 --> 00:01:14.600
You can use one of the models
that we have packaged for you,

00:01:14.600 --> 00:01:17.740
or you can take pretty much any
TensorFlow model that you have

00:01:17.740 --> 00:01:22.590
and use a converter and run
it with TensorFlow JavaScript.

00:01:22.590 --> 00:01:24.540
You can use a
previously-trained model,

00:01:24.540 --> 00:01:27.960
and then retrain it with your
own data to customize it,

00:01:27.960 --> 00:01:30.270
and this is often useful
to solve the problem that's

00:01:30.270 --> 00:01:31.710
of interest to you.

00:01:31.710 --> 00:01:34.900
This is done using a technique
called transfer learning.

00:01:34.900 --> 00:01:37.540
And then lastly, it's a
full-feature JavaScript library

00:01:37.540 --> 00:01:39.850
that lets you write
and alter models

00:01:39.850 --> 00:01:41.680
directly with JavaScript.

00:01:41.680 --> 00:01:43.690
And so you can create
a completely new model

00:01:43.690 --> 00:01:45.740
from scratch.

00:01:45.740 --> 00:01:48.500
Today in this talk, we will
talk a lot about the first

00:01:48.500 --> 00:01:49.790
and the third one of these.

00:01:49.790 --> 00:01:51.380
For the re-training
examples, there

00:01:51.380 --> 00:01:53.870
are a bunch of these on our
website and in the codelabs,

00:01:53.870 --> 00:01:58.510
and we encourage you to sort
of take a look after the talk.

00:01:58.510 --> 00:02:00.160
The other part is
that JavaScript

00:02:00.160 --> 00:02:02.200
is a very versatile
language, and it works

00:02:02.200 --> 00:02:04.210
on a variety of platforms.

00:02:04.210 --> 00:02:08.259
So you can use TensorFlow.js
on all of these platforms.

00:02:08.259 --> 00:02:10.118
We see a ton of use
cases in the browser,

00:02:10.118 --> 00:02:12.160
and it has a lot of
advantages because, you know,

00:02:12.160 --> 00:02:14.470
browser is super interactive.

00:02:14.470 --> 00:02:18.130
You have easy access to sensors,
such as webcam and microphone,

00:02:18.130 --> 00:02:21.700
which you can then bring into
your machine learning models.

00:02:21.700 --> 00:02:24.070
And also we use
WebGL-based acceleration.

00:02:24.070 --> 00:02:25.690
So if you have a
GPU in your system,

00:02:25.690 --> 00:02:27.430
you can take advantage
of that and get

00:02:27.430 --> 00:02:29.830
really good performance.

00:02:29.830 --> 00:02:34.300
TensorFlow.js will also run
server-side using Node.js.

00:02:34.300 --> 00:02:38.470
It runs on a variety of mobile
platforms in iOS and Android

00:02:38.470 --> 00:02:41.620
using mobile web
platforms, and also it

00:02:41.620 --> 00:02:45.060
can run in desktop
applications using Electron.

00:02:45.060 --> 00:02:49.920
And we'll see, later in the
talk, more examples of this.

00:02:49.920 --> 00:02:53.210
So we launched TensorFlow.js
one year back last March,

00:02:53.210 --> 00:02:55.910
and then earlier this year
at our developer summit

00:02:55.910 --> 00:02:58.040
we released version 1.0.

00:02:58.040 --> 00:03:01.550
And we have been amazed to see
really good adoption and usage

00:03:01.550 --> 00:03:04.130
by the community, and some
really good sort of popularity

00:03:04.130 --> 00:03:05.300
numbers.

00:03:05.300 --> 00:03:06.980
We are really,
really excited to see

00:03:06.980 --> 00:03:09.710
more than 100 external
contributors who

00:03:09.710 --> 00:03:12.553
are contributing to and
making the library better.

00:03:12.553 --> 00:03:14.720
So for those of you who are
in the audience or those

00:03:14.720 --> 00:03:17.060
of you listening, thank
you very much from all

00:03:17.060 --> 00:03:20.347
of the TensorFlow.js team.

00:03:20.347 --> 00:03:22.430
So let's dive a little bit
deeper into the library

00:03:22.430 --> 00:03:24.210
and see how it is used.

00:03:24.210 --> 00:03:25.730
OK, I'm going to
start with looking

00:03:25.730 --> 00:03:27.785
at some pre-trained
models first.

00:03:27.785 --> 00:03:31.760
So I want to show you
a few of these today.

00:03:31.760 --> 00:03:34.850
So we have packaged a
variety or a collection

00:03:34.850 --> 00:03:37.910
of pre-trained models
for use out of the box

00:03:37.910 --> 00:03:40.580
to solve some of the most
common types of ML problems

00:03:40.580 --> 00:03:43.340
that you might encounter.

00:03:43.340 --> 00:03:45.150
These work with images.

00:03:45.150 --> 00:03:47.780
So we-- for tasks such
as image classification,

00:03:47.780 --> 00:03:50.750
detecting objects, segmenting
objects, and finding boundaries

00:03:50.750 --> 00:03:53.630
of objects, recognizing
human gesture and human

00:03:53.630 --> 00:03:56.360
pose from image or video data.

00:03:56.360 --> 00:03:58.830
We have a few
speech audio models,

00:03:58.830 --> 00:04:02.660
which work with speech commands
to recognize spoken words.

00:04:02.660 --> 00:04:06.020
We have a couple of text models
for analyzing, understanding,

00:04:06.020 --> 00:04:08.060
and classifying text.

00:04:08.060 --> 00:04:12.110
All of these models are packaged
with very easy-to-use wrapped

00:04:12.110 --> 00:04:15.770
APIs for easy consumption
in JavaScript applications.

00:04:15.770 --> 00:04:18.860
You can either NPM install
them, or you can directly

00:04:18.860 --> 00:04:22.530
use them from our hosted
scripts with nothing to install.

00:04:22.530 --> 00:04:25.742
So let's take a look
at two examples.

00:04:25.742 --> 00:04:28.200
The first model I want to show
you is an image-based model.

00:04:28.200 --> 00:04:29.730
It's called BodyPix.

00:04:29.730 --> 00:04:32.610
So this is the model that
lets you take image data,

00:04:32.610 --> 00:04:35.355
and it finds whether there is
a person in that image or not.

00:04:35.355 --> 00:04:37.230
And if there is a person,
it will segment out

00:04:37.230 --> 00:04:38.397
the boundary of that person.

00:04:38.397 --> 00:04:40.470
So it will label each
pixel as whether it

00:04:40.470 --> 00:04:42.460
belongs to the person or not.

00:04:42.460 --> 00:04:44.610
And you can also do
body part segmentation.

00:04:44.610 --> 00:04:48.660
So it can further divide up the
pixels that belong to a person

00:04:48.660 --> 00:04:51.820
into one of 24 body parts.

00:04:51.820 --> 00:04:53.820
So let's take a look at
what the code looks like

00:04:53.820 --> 00:04:57.390
and how you would use
a model like this.

00:04:57.390 --> 00:04:59.690
So you start by
loading the library

00:04:59.690 --> 00:05:02.360
and by loading the
model using the script

00:05:02.360 --> 00:05:06.330
tag from our hosted scripts.

00:05:06.330 --> 00:05:07.530
You choose an image file.

00:05:07.530 --> 00:05:10.830
You can load it from disk or you
could point to a webcam element

00:05:10.830 --> 00:05:13.330
to load it from the webcam.

00:05:13.330 --> 00:05:15.190
And once you have
an image, then you

00:05:15.190 --> 00:05:18.520
create an instance
of the BodyPix model,

00:05:18.520 --> 00:05:21.610
and you call its person
segmentation method

00:05:21.610 --> 00:05:23.980
on the image that
you have chosen.

00:05:23.980 --> 00:05:25.960
Because this runs
asynchronously,

00:05:25.960 --> 00:05:27.610
you wait for the
result and we do that

00:05:27.610 --> 00:05:28.930
by using the wait keyword.

00:05:31.720 --> 00:05:34.480
So once you get back
the segmentation result,

00:05:34.480 --> 00:05:36.940
it returns an object,
and this object

00:05:36.940 --> 00:05:39.130
has the width and the
height of the image,

00:05:39.130 --> 00:05:43.060
and also a binary array of zeros
and ones, with the pixels where

00:05:43.060 --> 00:05:45.580
the person is found are
labeled, and you see that

00:05:45.580 --> 00:05:49.710
in that image on the right.

00:05:49.710 --> 00:05:52.200
You could also use the body
parts segmentation method

00:05:52.200 --> 00:05:53.640
instead of the
person segmentation

00:05:53.640 --> 00:05:56.730
method, in which case you
would get the sub-body part

00:05:56.730 --> 00:05:59.460
classification.

00:05:59.460 --> 00:06:02.990
The model is packaged with
a set of utility functions

00:06:02.990 --> 00:06:05.150
for rendering, and here
you see the example

00:06:05.150 --> 00:06:07.260
of the drawPixelatedMask()
function,

00:06:07.260 --> 00:06:09.830
which produces this
image on the right.

00:06:09.830 --> 00:06:13.100
OK, so this is how you would use
one of these image-based models

00:06:13.100 --> 00:06:17.310
directly in your
web application.

00:06:17.310 --> 00:06:20.780
The second model I want to show
you is a speech commands model.

00:06:20.780 --> 00:06:22.880
So this is an audio
model that will look for,

00:06:22.880 --> 00:06:25.040
that will listen
to microphone data,

00:06:25.040 --> 00:06:27.530
and try to recognize
some spoken words.

00:06:27.530 --> 00:06:30.700
So you can use this to build
voice controls and interfaces

00:06:30.700 --> 00:06:33.140
or to recognize
words for translation

00:06:33.140 --> 00:06:35.040
and other types of applications.

00:06:35.040 --> 00:06:37.415
So let me quickly switch
to the demo laptop.

00:06:41.520 --> 00:06:44.900
So we have a small glitch
application written,

00:06:44.900 --> 00:06:47.030
which uses the speech
commands model,

00:06:47.030 --> 00:06:49.850
and we are using a version
of a pre-trained model, which

00:06:49.850 --> 00:06:52.680
is trained on a vocabulary of
just four simple words-- up,

00:06:52.680 --> 00:06:54.050
down, left and right.

00:06:54.050 --> 00:06:57.110
So when I click start and
I can speak these words,

00:06:57.110 --> 00:06:59.550
this application will
display a matching emoji.

00:06:59.550 --> 00:07:02.775
So let's try it out.

00:07:02.775 --> 00:07:03.769
Left.

00:07:03.769 --> 00:07:05.760
Up.

00:07:05.760 --> 00:07:07.020
Left.

00:07:07.020 --> 00:07:07.860
Down.

00:07:07.860 --> 00:07:10.090
Down.

00:07:10.090 --> 00:07:10.590
OK.

00:07:10.590 --> 00:07:12.305
Right.

00:07:12.305 --> 00:07:14.130
Left.

00:07:14.130 --> 00:07:15.250
Up.

00:07:15.250 --> 00:07:15.750
There we go.

00:07:19.320 --> 00:07:21.902
We can go back to the screen.

00:07:21.902 --> 00:07:24.360
This actually points to what
you would frequently encounter

00:07:24.360 --> 00:07:25.640
with machine learning models.

00:07:25.640 --> 00:07:28.560
There are a lot of other factors
that you have to account for--

00:07:28.560 --> 00:07:31.440
things like background
noise, and just training data

00:07:31.440 --> 00:07:34.700
representing adequately
the type of data that it

00:07:34.700 --> 00:07:37.950
will encounter in real life.

00:07:37.950 --> 00:07:41.460
So let's again take a look at
what the code would look like.

00:07:41.460 --> 00:07:43.490
Again, you use the script
tag similar to before

00:07:43.490 --> 00:07:46.370
to load the model and
to load our library.

00:07:46.370 --> 00:07:49.970
And now, we create an instance
of the speech commands model

00:07:49.970 --> 00:07:52.970
and we initialize it or we use
a version of the speech commands

00:07:52.970 --> 00:07:55.790
model that's trained for
the specific vocabulary

00:07:55.790 --> 00:07:56.340
of interest.

00:07:56.340 --> 00:07:58.340
So in this case, it's
this directional four-word

00:07:58.340 --> 00:07:59.315
vocabulary.

00:07:59.315 --> 00:08:01.940
We have packaged this model with
a couple of other vocabularies

00:08:01.940 --> 00:08:04.730
that you can use, and also
you can extend this model

00:08:04.730 --> 00:08:07.320
to your own vocabulary
using transfer learning.

00:08:07.320 --> 00:08:10.140
And we have a codelab
which shows how to do that.

00:08:10.140 --> 00:08:12.650
So once you have
initiated the model,

00:08:12.650 --> 00:08:14.840
then we call its
listen method, which

00:08:14.840 --> 00:08:17.150
starts listening to
the microphone data.

00:08:17.150 --> 00:08:19.400
And then once it
recognizes these words,

00:08:19.400 --> 00:08:22.340
then it returns a set of
probabilities for the matching

00:08:22.340 --> 00:08:24.110
score for each of
the spoken words

00:08:24.110 --> 00:08:27.080
in its set of labeled classes.

00:08:27.080 --> 00:08:29.900
And then once you've figured
out what the spoken word is,

00:08:29.900 --> 00:08:33.650
then you can use that to
display emojis, for example,

00:08:33.650 --> 00:08:35.590
in that particular example.

00:08:35.590 --> 00:08:38.270
OK, so I'm going to
turn it over to Yannick,

00:08:38.270 --> 00:08:41.510
who will show you how to do
training using this library.

00:08:41.510 --> 00:08:43.190
YANNICK ASSOGBA: Thanks Sandeep.

00:08:43.190 --> 00:08:44.150
Hello.

00:08:44.150 --> 00:08:46.610
So, Sandeep showed you
one of the simplest ways

00:08:46.610 --> 00:08:49.218
to get started with machine
learning with TensorFlow.js,

00:08:49.218 --> 00:08:51.260
and that's to take one of
our pre-trained models,

00:08:51.260 --> 00:08:52.772
incorporate it into your app.

00:08:52.772 --> 00:08:54.230
And, if you noticed,
you won't even

00:08:54.230 --> 00:08:56.810
have to think about
tensors, but there

00:08:56.810 --> 00:08:59.510
are situations where there
won't be a model that works out

00:08:59.510 --> 00:09:01.430
of the box for your
use case, and that's

00:09:01.430 --> 00:09:03.110
where training comes in.

00:09:03.110 --> 00:09:06.620
So TensorFlow.js has a full
API to support training custom

00:09:06.620 --> 00:09:09.410
models right in JavaScript.

00:09:09.410 --> 00:09:11.330
So last year here
at I/O, we showed

00:09:11.330 --> 00:09:14.930
a demo of training a game
controller using webcam input--

00:09:14.930 --> 00:09:17.180
in this example, your face--

00:09:17.180 --> 00:09:18.812
to control this Pac-Man game.

00:09:18.812 --> 00:09:21.020
And this year, we're going
to look a bit more closely

00:09:21.020 --> 00:09:22.970
at the training
process, focusing

00:09:22.970 --> 00:09:25.580
on training in Node.js,
and what it looks

00:09:25.580 --> 00:09:27.590
like to bring your own data.

00:09:27.590 --> 00:09:31.100
Now some of the advantages
of training in Node.js

00:09:31.100 --> 00:09:36.050
include generally increased
access to memory and storage,

00:09:36.050 --> 00:09:39.448
increased performance in certain
situations, and importantly,

00:09:39.448 --> 00:09:41.240
being able to browse
the internet while you

00:09:41.240 --> 00:09:43.815
wait for your model to train.

00:09:43.815 --> 00:09:45.690
In the browser, when
you're training a model,

00:09:45.690 --> 00:09:48.200
you have to keep
the tab focused.

00:09:48.200 --> 00:09:51.380
Else, many browsers will
throttle performance

00:09:51.380 --> 00:09:52.040
on that tab.

00:09:52.040 --> 00:09:55.940
So it's quite handy that you're
able to do something else.

00:09:55.940 --> 00:10:00.200
All right, so let's train
a custom text classifier,

00:10:00.200 --> 00:10:01.640
and there's really
two main things

00:10:01.640 --> 00:10:04.020
I'd like you to take
away from this exercise.

00:10:04.020 --> 00:10:05.510
The first is
generally how to work

00:10:05.510 --> 00:10:08.480
with text in TensorFlow.js,
and the other

00:10:08.480 --> 00:10:11.990
is a general principle of using
an existing building block

00:10:11.990 --> 00:10:14.600
to bootstrap your
machine learning project.

00:10:14.600 --> 00:10:16.460
This is referred to
as transfer learning,

00:10:16.460 --> 00:10:18.252
and it's really helpful
when you're getting

00:10:18.252 --> 00:10:19.640
started with machine learning.

00:10:19.640 --> 00:10:23.560
And we'll see more about that
in the example, but to step back

00:10:23.560 --> 00:10:26.000
a bit, what can you do
with a text classifier?

00:10:26.000 --> 00:10:29.380
So there are classical examples,
such as sentiment analysis,

00:10:29.380 --> 00:10:31.402
or spam detection,
but you can also

00:10:31.402 --> 00:10:32.860
do things like log
scrubbing, where

00:10:32.860 --> 00:10:34.540
you may look through
your logs for maybe

00:10:34.540 --> 00:10:37.540
personal or private information
that you don't want to keep,

00:10:37.540 --> 00:10:41.188
and obfuscate it or remove
it before you store it.

00:10:41.188 --> 00:10:43.480
But you can also do things
like analyze product reviews

00:10:43.480 --> 00:10:46.270
or do document clustering.

00:10:46.270 --> 00:10:51.227
But today, we're going to build
a component for a chatbot,

00:10:51.227 --> 00:10:52.810
and in particular,
we're going to look

00:10:52.810 --> 00:10:55.150
at classifying user intents.

00:10:55.150 --> 00:10:57.580
So, for example,
given the sentence,

00:10:57.580 --> 00:10:59.300
"Will it rain in the
next 30 minutes?"

00:10:59.300 --> 00:11:02.530
we want the model to detect
that that's a GetWeather

00:11:02.530 --> 00:11:06.160
intent, or something like
"Play the latest Bach album,"

00:11:06.160 --> 00:11:09.220
should be a PlayMusic intent.

00:11:09.220 --> 00:11:12.820
So any machine learning project
needs data to learn from,

00:11:12.820 --> 00:11:15.130
and today the data we're
going to use come from

00:11:15.130 --> 00:11:17.890
comes from the Snips
AI NLU benchmark,

00:11:17.890 --> 00:11:21.460
and it's an open-source dataset
that's available on GitHub.

00:11:21.460 --> 00:11:23.590
And for our first
task, we're basically

00:11:23.590 --> 00:11:25.420
going to start
with a spreadsheet.

00:11:25.420 --> 00:11:28.720
As you can see, it has the
query sentences on one side,

00:11:28.720 --> 00:11:32.590
and the intents on the other.

00:11:32.590 --> 00:11:35.410
However, one thing we need
to do is convert this text

00:11:35.410 --> 00:11:38.980
into numbers so that we can
feed it into our neural network

00:11:38.980 --> 00:11:43.390
because neural networks
don't really understand text

00:11:43.390 --> 00:11:47.230
natively, and that is where
the Universal Sentence

00:11:47.230 --> 00:11:48.670
Encoder comes in.

00:11:48.670 --> 00:11:51.250
It's a deep neural
network created by Google

00:11:51.250 --> 00:11:54.640
that I like to think
of as NLP in a box.

00:11:54.640 --> 00:11:57.160
It takes sentences
and turns them

00:11:57.160 --> 00:12:00.370
into lists of numbers
that encode the meaning

00:12:00.370 --> 00:12:02.770
and syntax of those
sentences, and we'll

00:12:02.770 --> 00:12:04.790
take a look at an example.

00:12:04.790 --> 00:12:06.490
So let's think of
this example, "What

00:12:06.490 --> 00:12:09.460
is the weather in
Cambridge, Massachusetts?"

00:12:09.460 --> 00:12:12.100
The Universal Sentence Encoder
will take that sentence

00:12:12.100 --> 00:12:15.760
and turn it into an
array of 512 numbers,

00:12:15.760 --> 00:12:18.550
and it will always be
512 numbers regardless

00:12:18.550 --> 00:12:20.800
of the length of the
sentence, which is actually

00:12:20.800 --> 00:12:23.620
quite nice because it gives
us a regular sort of structure

00:12:23.620 --> 00:12:26.460
to work with.

00:12:26.460 --> 00:12:30.050
And this is what the code looks
like to create those numbers.

00:12:30.050 --> 00:12:31.955
So, similar to what
Sandeep showed earlier,

00:12:31.955 --> 00:12:36.050
we load our pre-trained model,
the Universal Sentence Encoder.

00:12:36.050 --> 00:12:39.240
We wait for its waits
to finish loading,

00:12:39.240 --> 00:12:41.990
and then we call this
model.embed() with

00:12:41.990 --> 00:12:43.970
the sentences that
we want to pass in.

00:12:43.970 --> 00:12:47.870
And this process of turning
these sentences into numbers

00:12:47.870 --> 00:12:49.495
is often referred
to as embedding

00:12:49.495 --> 00:12:51.620
in machine learning
terminology, and you'll kind of

00:12:51.620 --> 00:12:52.880
hear that term a bit.

00:12:52.880 --> 00:12:55.170
So just a bit of
what that looks like.

00:12:55.170 --> 00:13:00.700
Wait for the result, and
that's our set of 512 numbers.

00:13:00.700 --> 00:13:01.990
OK.

00:13:01.990 --> 00:13:03.050
Next is the intent.

00:13:03.050 --> 00:13:05.480
So we also have to convert
these into numbers.

00:13:05.480 --> 00:13:07.210
So since these are
categories and we

00:13:07.210 --> 00:13:09.280
have a small number
of them, we can

00:13:09.280 --> 00:13:12.040
use a scheme called
oneHot encoding

00:13:12.040 --> 00:13:15.580
to turn the label into a
small array that has a 1

00:13:15.580 --> 00:13:18.560
in the position
corresponding to that label.

00:13:18.560 --> 00:13:22.090
So in this example, we
have our GetWeather intent,

00:13:22.090 --> 00:13:24.460
and notice the first
element of the array is a 1

00:13:24.460 --> 00:13:26.260
and the rest are zeros.

00:13:26.260 --> 00:13:27.970
In the corner, you
will see the other two

00:13:27.970 --> 00:13:30.160
intents we're using in
this demo, the Play Music

00:13:30.160 --> 00:13:32.440
one and the AddToPlayList,
and there's always

00:13:32.440 --> 00:13:35.170
just a single one in
the array representing

00:13:35.170 --> 00:13:39.270
which category this represents.

00:13:39.270 --> 00:13:42.330
And here is the code to do
that, and it is basically

00:13:42.330 --> 00:13:44.910
an index look-up into a list.

00:13:44.910 --> 00:13:48.630
So we call the method
tf.oneHot, given

00:13:48.630 --> 00:13:51.960
the index of the label
we want to encode

00:13:51.960 --> 00:13:54.160
as well as the total number
of categories we have.

00:13:54.160 --> 00:13:57.090
So here, GetWeather and
three, and then it's

00:13:57.090 --> 00:13:59.220
going to return that
compact array that

00:13:59.220 --> 00:14:02.880
is our numerical
representation of the label.

00:14:02.880 --> 00:14:04.210
All right.

00:14:04.210 --> 00:14:08.350
So now we have our inputs,
or often as referred to

00:14:08.350 --> 00:14:12.280
in machine learning, our xs,
and our targets, which are also

00:14:12.280 --> 00:14:15.010
referred to as ys often.

00:14:15.010 --> 00:14:19.060
And now our goal is to take
the 512 numbers representing

00:14:19.060 --> 00:14:22.720
the input and predict
that smaller array that's

00:14:22.720 --> 00:14:25.840
1, 0, 0 that represents
that particular intent,

00:14:25.840 --> 00:14:28.360
and we're going to train
a model to do that.

00:14:31.970 --> 00:14:35.610
So let's code up a model.

00:14:35.610 --> 00:14:40.430
So this is the entire
code for the model.

00:14:40.430 --> 00:14:43.720
It's not too much code,
but it does a lot of work,

00:14:43.720 --> 00:14:45.700
and as you spend
time with this, it

00:14:45.700 --> 00:14:47.920
becomes more and more familiar.

00:14:47.920 --> 00:14:51.190
At the top, we see our
EMBEDDING_DIMS, 512,

00:14:51.190 --> 00:14:54.010
and NUM_CLASSES that represent
the size of the input

00:14:54.010 --> 00:14:56.270
and the output of the
model, respectively.

00:14:56.270 --> 00:15:00.490
So 512 numbers coming in,
three numbers going out.

00:15:00.490 --> 00:15:04.690
The part that's highlighted is
the entire model definition,

00:15:04.690 --> 00:15:06.170
and I won't dwell
on this too long,

00:15:06.170 --> 00:15:07.805
but this is a common
building block

00:15:07.805 --> 00:15:09.430
you'll see in neural
networks, and it's

00:15:09.430 --> 00:15:11.300
known as a dense network.

00:15:11.300 --> 00:15:13.390
So we start with a
sequential model,

00:15:13.390 --> 00:15:16.390
and this network
just has one layer,

00:15:16.390 --> 00:15:18.280
and it's the one dense
layer, and its job

00:15:18.280 --> 00:15:21.400
is to convert 512
numbers to three numbers.

00:15:21.400 --> 00:15:23.680
That's its entire job.

00:15:23.680 --> 00:15:26.080
The deep learning
part will have been

00:15:26.080 --> 00:15:29.960
take care of by the
Universal Sentence Encoder.

00:15:29.960 --> 00:15:33.110
Finally, we compile the model
to get it ready for training,

00:15:33.110 --> 00:15:35.120
and here we pick
an optimizer, which

00:15:35.120 --> 00:15:37.100
is an algorithm that's
going to drive the wait

00:15:37.100 --> 00:15:39.200
updates during the
training process,

00:15:39.200 --> 00:15:41.848
as well as a loss function to
tell us how well we're doing.

00:15:41.848 --> 00:15:43.640
And here, we're picking
one that's commonly

00:15:43.640 --> 00:15:46.530
used for classification tasks.

00:15:46.530 --> 00:15:48.870
So onto the training loop.

00:15:48.870 --> 00:15:52.830
So model.fit() is the function
that actually runs the whole

00:15:52.830 --> 00:15:55.320
training process, and here
we're calling it with a few

00:15:55.320 --> 00:15:58.440
parameters. xs are
our input sentences.

00:15:58.440 --> 00:16:02.400
ys are those targets
from our training set,

00:16:02.400 --> 00:16:05.910
and then two extra parameters.
epochs is a fancy word that

00:16:05.910 --> 00:16:07.740
refers to the
number of times you

00:16:07.740 --> 00:16:10.650
go through the data set
before you're done training,

00:16:10.650 --> 00:16:13.710
and you can set that kind
of to whatever you want.

00:16:13.710 --> 00:16:17.350
validationSplit is a
fraction between 0 and 1,

00:16:17.350 --> 00:16:19.590
and it indicates a
portion of the data

00:16:19.590 --> 00:16:22.740
that we're going to set
aside and not train with,

00:16:22.740 --> 00:16:24.720
but we can use it to
see how well we're

00:16:24.720 --> 00:16:26.340
doing at making predictions.

00:16:29.250 --> 00:16:30.890
So before we look
at the demo itself,

00:16:30.890 --> 00:16:34.010
let's take a quick look
at what the code to deploy

00:16:34.010 --> 00:16:36.210
that trained model would
look like in the browser,

00:16:36.210 --> 00:16:38.810
and let's just take
a quick sample.

00:16:38.810 --> 00:16:42.510
So we'd first load the models
in the metadata, but for now

00:16:42.510 --> 00:16:46.020
I just want you to focus on
the three lines in the middle.

00:16:46.020 --> 00:16:48.560
So the basic process is
that we take the input query

00:16:48.560 --> 00:16:50.160
from the user.

00:16:50.160 --> 00:16:53.840
We're going to use the Universal
Sentence Encoder to embed it

00:16:53.840 --> 00:16:56.540
into that numerical
representation.

00:16:56.540 --> 00:16:59.870
Then we're going to call our
model, with model.predict(),

00:16:59.870 --> 00:17:01.460
to get our final prediction.

00:17:01.460 --> 00:17:04.339
We're going to call the
.array() to get the values out,

00:17:04.339 --> 00:17:07.675
and we're going to use
that to drive our UI.

00:17:07.675 --> 00:17:09.800
And in this case, our UI
is going to look something

00:17:09.800 --> 00:17:13.040
like this, and it's about
150 lines of JavaScript,

00:17:13.040 --> 00:17:14.420
and about 100 lines of CSS.

00:17:14.420 --> 00:17:19.109
So it's not terribly large.

00:17:19.109 --> 00:17:22.380
So let's get our hands into it.

00:17:22.380 --> 00:17:26.630
So if you just switch to
the demo laptop, please.

00:17:31.100 --> 00:17:32.470
All right.

00:17:32.470 --> 00:17:35.792
So we're just going to sort of
take a quick tour of the code.

00:17:35.792 --> 00:17:37.000
It's all available on GitHub.

00:17:37.000 --> 00:17:39.400
So here is that spreadsheet
that we started with--

00:17:39.400 --> 00:17:40.930
our queries and our intents.

00:17:40.930 --> 00:17:44.170
And I've done a bunch of the
pre-processing beforehand,

00:17:44.170 --> 00:17:46.670
so that we don't have to wait
for that [INAUDIBLE] complete.

00:17:46.670 --> 00:17:48.880
So the first step was
converting it to tensors,

00:17:48.880 --> 00:17:52.180
and it's just those long
lists of 512 numbers.

00:17:52.180 --> 00:17:54.370
JSON isn't the most efficient
format to store this,

00:17:54.370 --> 00:17:55.370
but it's quite readable.

00:17:55.370 --> 00:17:57.820
So you can actually just
look at what a tensor is.

00:17:57.820 --> 00:18:00.620
It's just a long
list of numbers.

00:18:00.620 --> 00:18:03.050
We also have some
metadata for our model.

00:18:03.050 --> 00:18:07.000
So these are the three classes
that we're going to train,

00:18:07.000 --> 00:18:09.368
and we have about
6,000 sentences

00:18:09.368 --> 00:18:10.660
that we're going to learn from.

00:18:13.190 --> 00:18:17.475
Our model itself looks
pretty much like what

00:18:17.475 --> 00:18:18.350
we saw in the slides.

00:18:18.350 --> 00:18:20.940
There's no surprises there.

00:18:20.940 --> 00:18:23.960
And finally, our script that's
going to run the training.

00:18:23.960 --> 00:18:25.890
Its main job-- it takes
a bunch of options,

00:18:25.890 --> 00:18:29.040
but its main job is to load
the data and train the model.

00:18:29.040 --> 00:18:32.480
So it's going to do that with
model.fit() as we saw earlier.

00:18:32.480 --> 00:18:35.000
We're going to wait for
that to be complete,

00:18:35.000 --> 00:18:38.340
and then we're going to
save that model to disk.

00:18:38.340 --> 00:18:41.130
So that's going to save a
JSON file and a binary file.

00:18:41.130 --> 00:18:43.910
The JSON file contains the sort
of structure of the network.

00:18:43.910 --> 00:18:47.360
The binary file contains the
weights in an efficient format.

00:18:47.360 --> 00:18:51.300
Both of those are
loadable in the browser,

00:18:51.300 --> 00:18:52.710
and that's our basic process.

00:18:52.710 --> 00:18:54.740
So let's see what that
kind of looks like.

00:18:57.270 --> 00:19:02.000
So here I'm going to run
the training script for this

00:19:02.000 --> 00:19:06.240
while I'll say
yarn train-intent.

00:19:06.240 --> 00:19:08.230
It's going to load
up, load our script,

00:19:08.230 --> 00:19:12.260
and use TensorFlow on the CPU
and we're off to the races.

00:19:12.260 --> 00:19:15.850
So each one of these lines
that it prints is an epoch,

00:19:15.850 --> 00:19:18.530
and that's a trip
through the entire data

00:19:18.530 --> 00:19:21.070
set of about 6,000
sentences, and you

00:19:21.070 --> 00:19:22.840
notice it goes pretty quickly.

00:19:22.840 --> 00:19:27.250
It typically finishes in
about 20 seconds, and boom--

00:19:27.250 --> 00:19:29.827
19.90 today.

00:19:29.827 --> 00:19:30.910
And we've trained a model.

00:19:30.910 --> 00:19:31.750
It's done.

00:19:31.750 --> 00:19:34.000
We can now load that in
the browser and use that

00:19:34.000 --> 00:19:36.010
to make predictions.

00:19:36.010 --> 00:19:37.960
You can look at the
file that's produced.

00:19:37.960 --> 00:19:39.890
It's a really small model file.

00:19:39.890 --> 00:19:44.080
So I'm going to start this demo
app, which is here in our app

00:19:44.080 --> 00:19:46.703
folder, and it's just like a
client-side JavaScript app,

00:19:46.703 --> 00:19:49.120
and this is really where all
the machine learning happens,

00:19:49.120 --> 00:19:50.808
where we make our predictions.

00:19:54.720 --> 00:19:58.160
So this is going to copy the
model that we just trained over

00:19:58.160 --> 00:20:00.290
into the folder for
the client-side app

00:20:00.290 --> 00:20:02.600
and launch it in dev mode.

00:20:02.600 --> 00:20:05.060
I'm actually going to
lift this a bit higher,

00:20:05.060 --> 00:20:06.810
and now we can try
and make predictions.

00:20:06.810 --> 00:20:14.430
So we can ask it like, what
is the weather in Cambridge?

00:20:14.430 --> 00:20:17.140
Sweet, and it responds with
a nice cloud for like it

00:20:17.140 --> 00:20:20.590
has detected a weather query.

00:20:20.590 --> 00:20:23.309
Or we can say, play
the latest Bach album.

00:20:29.800 --> 00:20:32.860
And it's correctly classified
that as a PlayMusic one.

00:20:32.860 --> 00:20:40.720
Or even things like but those
sick beats on my running list--

00:20:40.720 --> 00:20:43.330
not that I run
terribly often, but we

00:20:43.330 --> 00:20:46.750
get the right response
back of AddToPlaylist,

00:20:46.750 --> 00:20:49.300
but what happens when you
give it something surprising?

00:20:49.300 --> 00:20:53.970
Like, get me a pizza.

00:20:53.970 --> 00:20:56.650
Well, it's just going to
throw its hands up and shrug,

00:20:56.650 --> 00:20:58.110
and that's actually
quite useful.

00:20:58.110 --> 00:20:59.790
You generally don't
want your model

00:20:59.790 --> 00:21:02.910
to do things when it's not
the right thing that it's

00:21:02.910 --> 00:21:04.530
been trained to do.

00:21:04.530 --> 00:21:07.200
And how we've set this up
is that we set a threshold

00:21:07.200 --> 00:21:08.640
for confidence in
classification,

00:21:08.640 --> 00:21:10.470
and so it should be
pretty confident in one

00:21:10.470 --> 00:21:13.030
of these classes before
it takes that action,

00:21:13.030 --> 00:21:16.500
and that's very useful to
think of when you're building

00:21:16.500 --> 00:21:18.610
a machine-learning-driven app.

00:21:18.610 --> 00:21:23.550
It's sometimes good to say, I
don't know or not [INAUDIBLE]..

00:21:23.550 --> 00:21:24.330
So, sweet.

00:21:24.330 --> 00:21:26.130
That's our classifier.

00:21:26.130 --> 00:21:28.380
Let's head back to
the slides for a bit.

00:21:32.510 --> 00:21:33.080
All right.

00:21:33.080 --> 00:21:34.640
So we built our
custom classifier.

00:21:34.640 --> 00:21:36.450
Yay.

00:21:36.450 --> 00:21:39.940
And in many instances, that
might be all that you need.

00:21:39.940 --> 00:21:42.600
It may be the final
step of your pipeline,

00:21:42.600 --> 00:21:45.060
or once you have
the specific intent,

00:21:45.060 --> 00:21:47.070
you can apply some
handwritten rules

00:21:47.070 --> 00:21:50.500
to extract information and do
the rest of your processing.

00:21:50.500 --> 00:21:53.480
However, we can train
models to do more than just

00:21:53.480 --> 00:21:55.980
whole sentence classification.

00:21:55.980 --> 00:21:58.500
So, given our
original query, "What

00:21:58.500 --> 00:22:00.370
is the weather in
Cambridge, Massachusetts?"

00:22:00.370 --> 00:22:03.540
we may want to know, what's
the location-related aspect

00:22:03.540 --> 00:22:05.500
of this sentence,
and that's what

00:22:05.500 --> 00:22:07.650
we're going to look at next.

00:22:07.650 --> 00:22:10.880
So we can reformulate our
problem a bit to this.

00:22:10.880 --> 00:22:14.720
So, given a sentence,
we want to tag each word

00:22:14.720 --> 00:22:17.150
in the sentence with a tag.

00:22:17.150 --> 00:22:22.800
Like TOK for generic
token or LOC for location.

00:22:22.800 --> 00:22:24.800
We could have other tag
types, but for now we're

00:22:24.800 --> 00:22:27.440
just going to focus on these
two and the weather queries.

00:22:31.050 --> 00:22:34.993
Like before, we need to
convert our text into numbers,

00:22:34.993 --> 00:22:37.410
and like before, we're going
to use the Universal Sentence

00:22:37.410 --> 00:22:38.642
Encoder to do that.

00:22:38.642 --> 00:22:40.600
We're just going to give
it one word at a time.

00:22:40.600 --> 00:22:45.000
So now each word becomes
an array of 512 numbers,

00:22:45.000 --> 00:22:48.240
and in addition we're going
to add these special tokens

00:22:48.240 --> 00:22:50.080
at the end of our sentences.

00:22:50.080 --> 00:22:53.400
And that's the __PAD tokens.

00:22:53.400 --> 00:22:54.630
These will have two purposes.

00:22:54.630 --> 00:22:56.713
They'll let us know when
the end of a sentence is,

00:22:56.713 --> 00:22:59.880
but more importantly, we're
going to add enough of them

00:22:59.880 --> 00:23:03.930
so that all of our sentences
are effectively the same length.

00:23:03.930 --> 00:23:06.840
And this will be useful
for us because it gives us

00:23:06.840 --> 00:23:10.620
a nice rectangular matrix that
we can use during training,

00:23:10.620 --> 00:23:14.130
and that's just way
more efficient to train.

00:23:14.130 --> 00:23:16.920
So this is roughly what
our input will look like.

00:23:16.920 --> 00:23:20.190
They'll be sort of enough
pad tokens to make everything

00:23:20.190 --> 00:23:22.230
a given length.

00:23:22.230 --> 00:23:25.620
What about our targets?

00:23:25.620 --> 00:23:28.290
So now we want to predict
something for each word,

00:23:28.290 --> 00:23:31.140
and we're going to use
oneHot encoding again.

00:23:31.140 --> 00:23:33.930
Conveniently, we have three
categories like before.

00:23:33.930 --> 00:23:37.950
So we have our TOK category,
our LOC for location,

00:23:37.950 --> 00:23:40.230
and the special
pad category that

00:23:40.230 --> 00:23:42.930
will tell us when we've reached
the end of the sentence.

00:23:42.930 --> 00:23:46.260
And we see the oneHot encoding
scheme just like before.

00:23:49.720 --> 00:23:52.470
So once you've done that for
our inputs and our outputs,

00:23:52.470 --> 00:23:54.900
we now have them
represented as sequences.

00:23:54.900 --> 00:23:57.870
So now each sentence
is a sequence

00:23:57.870 --> 00:24:02.070
of those arrays of numbers, and
we need an appropriate model

00:24:02.070 --> 00:24:03.850
to handle them.

00:24:03.850 --> 00:24:06.000
So you can use a dense
network like before,

00:24:06.000 --> 00:24:09.010
though I'd advise maybe
adding some capacity to that,

00:24:09.010 --> 00:24:11.550
but today we're going to look
at a special kind of network,

00:24:11.550 --> 00:24:13.500
known as a recurrent
neural network,

00:24:13.500 --> 00:24:15.690
and in particular a
special kind of layer

00:24:15.690 --> 00:24:21.250
known as an LSTM that is geared
towards handling sequences.

00:24:21.250 --> 00:24:24.540
So let's take a look at that.

00:24:24.540 --> 00:24:28.160
So here is our new
model function.

00:24:28.160 --> 00:24:30.860
First, I want you to notice
that the start and end of it

00:24:30.860 --> 00:24:33.860
is pretty similar to
what we saw before.

00:24:33.860 --> 00:24:37.820
EMBEDDING_DIMS is still 512,
and the number of classes

00:24:37.820 --> 00:24:39.650
is still three.

00:24:39.650 --> 00:24:42.770
We still start with a sequential
model, and the end of it

00:24:42.770 --> 00:24:43.620
is pretty similar.

00:24:43.620 --> 00:24:46.340
We're going to compile it
with the same optimizer

00:24:46.340 --> 00:24:48.050
and the same loss function.

00:24:50.840 --> 00:24:53.330
So really, the meat of
it is in the middle.

00:24:53.330 --> 00:24:56.710
So instead of starting
with a dense layer,

00:24:56.710 --> 00:24:58.540
we're going to
use an LSTM layer,

00:24:58.540 --> 00:25:00.940
and this is a special
kind of layer that--

00:25:00.940 --> 00:25:03.460
it's designed to learn
across sequences.

00:25:03.460 --> 00:25:06.320
And here, think of each
sentence as a sequence.

00:25:06.320 --> 00:25:09.940
So we're going to configure it,
set a maximum sequence length,

00:25:09.940 --> 00:25:12.790
and then after that we're going
to do one more special thing.

00:25:12.790 --> 00:25:14.890
We're going to
take the LSTM layer

00:25:14.890 --> 00:25:17.410
and wrap it in a
bi-directional layer

00:25:17.410 --> 00:25:21.073
to give us a
bi-directional LSTM.

00:25:21.073 --> 00:25:22.990
And this is useful because
it allows the model

00:25:22.990 --> 00:25:25.280
to learn context
in both directions.

00:25:25.280 --> 00:25:27.730
So you can think of it as
reading the sentence left

00:25:27.730 --> 00:25:31.750
to right and then right to left,
and trying to learn from that.

00:25:31.750 --> 00:25:34.630
Finally, we end
with a dense layer,

00:25:34.630 --> 00:25:36.970
and this is very common
in classification problems

00:25:36.970 --> 00:25:39.040
to end with a dense
layer that has

00:25:39.040 --> 00:25:42.250
your number of output
classes, the NUM_CLASSES

00:25:42.250 --> 00:25:44.980
that you see in the slide.

00:25:44.980 --> 00:25:47.690
But because of the LSTM
stuff we did previously,

00:25:47.690 --> 00:25:50.810
we do have to wrap it in this
time-distributed layer that's

00:25:50.810 --> 00:25:52.900
going to unroll some
of the sequence stuff

00:25:52.900 --> 00:25:54.580
that happened earlier.

00:25:54.580 --> 00:25:58.910
So that's our entire
model definition again.

00:25:58.910 --> 00:26:01.220
Let's get our hands
into it again.

00:26:01.220 --> 00:26:02.960
Let's see what that looks like.

00:26:02.960 --> 00:26:09.430
So I'm going to go back
to the demo machine suite.

00:26:09.430 --> 00:26:12.910
Let me close that
and head to the code.

00:26:12.910 --> 00:26:15.172
Again, I've
pre-prepared the data.

00:26:15.172 --> 00:26:16.630
So we can see what
that looks like.

00:26:19.150 --> 00:26:23.260
Here's our input data, and it's
just the sentences broken up

00:26:23.260 --> 00:26:26.770
into words with a tag for each
word, and somewhere in there

00:26:26.770 --> 00:26:28.460
there's some LOC ones.

00:26:28.460 --> 00:26:29.680
So that's our input.

00:26:29.680 --> 00:26:33.970
Another thing I've done is I've
pre-embedded all of the words,

00:26:33.970 --> 00:26:36.590
and just written them to a file.

00:26:36.590 --> 00:26:39.220
So we can just look that up
instead of calling Universal

00:26:39.220 --> 00:26:41.360
Sentence Encoder each time.

00:26:41.360 --> 00:26:43.030
So with that
pre-processing done,

00:26:43.030 --> 00:26:47.110
we can look at our
model definition,

00:26:47.110 --> 00:26:50.630
and-- sorry this is
the tagger model--

00:26:50.630 --> 00:26:52.060
and if you look
at this on GitHub,

00:26:52.060 --> 00:26:54.395
you'll see that it's a little
more involved than what's

00:26:54.395 --> 00:26:56.770
in the slide, and that's
because the example we've put up

00:26:56.770 --> 00:27:00.200
allows you to train three
different kinds of models.

00:27:00.200 --> 00:27:04.120
You can train a one-directional
LSTM, the bi-directional LSTM

00:27:04.120 --> 00:27:06.790
we were talking about
today, or a dense network.

00:27:06.790 --> 00:27:08.680
And that's just to let
you compare and see

00:27:08.680 --> 00:27:10.970
how they behave,
but other than that,

00:27:10.970 --> 00:27:13.740
it's pretty much the same.

00:27:13.740 --> 00:27:16.230
Our training script
is very similar.

00:27:16.230 --> 00:27:17.410
The data is a bit bigger.

00:27:17.410 --> 00:27:19.920
So there's a little bit
more data management.

00:27:19.920 --> 00:27:22.710
So we call
fitDataset() this time,

00:27:22.710 --> 00:27:26.350
and then we save that to
disk just like before.

00:27:26.350 --> 00:27:33.330
So that's the outline of our
process, and we can run that.

00:27:33.330 --> 00:27:36.800
So I'm just going to
yarn train-tagger,

00:27:36.800 --> 00:27:38.857
and we'll see what
that looks like.

00:27:38.857 --> 00:27:41.190
So we'll start it, and all
of this training, by the way,

00:27:41.190 --> 00:27:42.230
is just using CPU.

00:27:42.230 --> 00:27:44.630
So you don't necessarily need
a GPU to do any training,

00:27:44.630 --> 00:27:46.665
but it does speed things up.

00:27:46.665 --> 00:27:48.290
So we've started
training, and probably

00:27:48.290 --> 00:27:50.150
the first thing you've
noticed is that it's

00:27:50.150 --> 00:27:52.250
a lot slower than before.

00:27:52.250 --> 00:27:53.870
The data is much
bigger this time.

00:27:53.870 --> 00:27:58.410
Each word is 512 numbers, and
the model is more complex.

00:27:58.410 --> 00:27:59.872
So it will take
more time to train,

00:27:59.872 --> 00:28:01.580
and I'd say on average
it takes somewhere

00:28:01.580 --> 00:28:03.770
between 10 and 20
minutes depending

00:28:03.770 --> 00:28:05.700
on what options you pick.

00:28:05.700 --> 00:28:08.030
So we're not going to
wait for the whole thing.

00:28:08.030 --> 00:28:11.600
To speed up the presentation,
I did train a model last night.

00:28:11.600 --> 00:28:14.450
So we're just going
to use that, and look

00:28:14.450 --> 00:28:18.830
at a demo app that's designed
to sort of show you the process.

00:28:18.830 --> 00:28:21.147
So I'm just going to start
that, yarn tagger-app.

00:28:24.130 --> 00:28:28.000
So we copy our model over it
just like before and start up

00:28:28.000 --> 00:28:30.940
our front-end
application, and this

00:28:30.940 --> 00:28:33.070
is a demo app just
designed to give you

00:28:33.070 --> 00:28:36.980
a sense of what is the pipeline
that inputs are going through.

00:28:36.980 --> 00:28:39.670
So we can now enter
a query like "What is

00:28:39.670 --> 00:28:42.460
the weather in Cambridge, MA?"

00:28:45.400 --> 00:28:50.170
So the first line is our input
sentence that's been tokenized.

00:28:50.170 --> 00:28:52.450
The sort of grid thing
is a representation

00:28:52.450 --> 00:28:55.840
of those 512 numbers from the
Universal Sentence Encoder,

00:28:55.840 --> 00:28:59.200
and then below that is our
top category that comes out.

00:28:59.200 --> 00:29:01.950
And you can see that Cambridge,
Massachusetts is nicely

00:29:01.950 --> 00:29:05.163
classified as being
location-related.

00:29:05.163 --> 00:29:07.080
One nice thing about
these models, you can try

00:29:07.080 --> 00:29:09.850
is somewhat more
complex ones like "What

00:29:09.850 --> 00:29:17.150
is the weather in white
river junction Vermont?"

00:29:17.150 --> 00:29:20.170
and that's a place I
have actually been to,

00:29:20.170 --> 00:29:21.970
and it does get it correct.

00:29:21.970 --> 00:29:24.430
We have this longer
location-related sequence,

00:29:24.430 --> 00:29:27.970
and it's correctly tagged the
tokens as belonging to that.

00:29:27.970 --> 00:29:32.050
You'll notice the confidence
on the VT is a little lower.

00:29:32.050 --> 00:29:35.060
If we use the more
traditional capitalization--

00:29:35.060 --> 00:29:43.670
so, "What is the weather in
white river junction VT?"

00:29:43.670 --> 00:29:46.850
you'll notice that the
classification score for VT,

00:29:46.850 --> 00:29:49.730
the abbreviation for
Vermont, goes way up,

00:29:49.730 --> 00:29:52.220
but because we've used
a bi-directional LSTM,

00:29:52.220 --> 00:29:54.470
you'll also notice that
the words before that,

00:29:54.470 --> 00:29:57.260
their confidence scores
go up because its reading

00:29:57.260 --> 00:29:59.090
the context in both directions.

00:29:59.090 --> 00:30:01.220
So that can be super handy.

00:30:01.220 --> 00:30:03.260
Another thing that's
important to realize

00:30:03.260 --> 00:30:06.480
is that it's not just
memorizing place names.

00:30:06.480 --> 00:30:10.880
So if you try just typing
in "white river junction,"

00:30:10.880 --> 00:30:14.486
it's not going to detect that as
location, or even "white river

00:30:14.486 --> 00:30:21.380
junction vt," and
that's because it's

00:30:21.380 --> 00:30:23.420
learned to find
these in the context

00:30:23.420 --> 00:30:24.810
of these
weather-related queries.

00:30:24.810 --> 00:30:25.800
That's the training data.

00:30:25.800 --> 00:30:27.258
So it's not just
gone and memorized

00:30:27.258 --> 00:30:29.803
a bunch of location
names, for example.

00:30:29.803 --> 00:30:31.220
So it's important
to keep in mind.

00:30:31.220 --> 00:30:35.190
Like, it's really based on
what you gave it to train.

00:30:35.190 --> 00:30:40.370
All right, and we can
switch back to these slides.

00:30:40.370 --> 00:30:42.930
Sweet, that worked.

00:30:42.930 --> 00:30:43.430
So, yay.

00:30:43.430 --> 00:30:46.390
We trained an intent
classifier and a model

00:30:46.390 --> 00:30:51.180
that can extract information
from that identified intent.

00:30:51.180 --> 00:30:52.650
Sweet.

00:30:52.650 --> 00:30:55.410
So is it time to ship
this into production?

00:30:55.410 --> 00:30:57.120
I would caution against this.

00:30:57.120 --> 00:30:59.820
So you really should
take care to first test

00:30:59.820 --> 00:31:03.210
that your model is robust
to different situations,

00:31:03.210 --> 00:31:05.580
and that it will match
your user's expectations.

00:31:05.580 --> 00:31:07.410
Machine learning models
are probabilistic

00:31:07.410 --> 00:31:11.040
and behave differently based
on often subtle differences

00:31:11.040 --> 00:31:12.810
in the training data used.

00:31:12.810 --> 00:31:15.990
So it's super important to
have a good test set, including

00:31:15.990 --> 00:31:18.215
some tricky cases,
and just validate

00:31:18.215 --> 00:31:19.590
that with your
users to make sure

00:31:19.590 --> 00:31:22.090
it matches those expectations.

00:31:22.090 --> 00:31:25.410
And Google has a number of great
resources online on this topic,

00:31:25.410 --> 00:31:27.030
and I also recommend
checking out

00:31:27.030 --> 00:31:29.440
the designing
human-centered AI products

00:31:29.440 --> 00:31:32.670
talk by some of our
colleagues in Google Pair

00:31:32.670 --> 00:31:36.410
later this afternoon at I/O.

00:31:36.410 --> 00:31:39.200
So now you've seen a bit
of what the workflow looks

00:31:39.200 --> 00:31:41.210
like to train a model.

00:31:41.210 --> 00:31:43.340
You can check out the
full code on GitHub.

00:31:43.340 --> 00:31:45.650
I've included a short
link to it here,

00:31:45.650 --> 00:31:49.022
and it's part of our larger
repository of examples.

00:31:49.022 --> 00:31:50.480
And next, I'm going
to hand it back

00:31:50.480 --> 00:31:52.130
to Sandeep to talk
about different ways

00:31:52.130 --> 00:31:53.720
that TensorFlow.js
has been used.

00:31:53.720 --> 00:31:54.800
Thanks.

00:31:54.800 --> 00:31:56.804
SANDEEP GUPTA:
Thank you, Yannick.

00:31:56.804 --> 00:32:02.290
[APPLAUSE]

00:32:02.290 --> 00:32:05.810
So we saw how the library can
be used for using and training

00:32:05.810 --> 00:32:06.980
machine learning models.

00:32:06.980 --> 00:32:08.355
I want to just
take a few minutes

00:32:08.355 --> 00:32:11.060
and quickly show you a variety
of applications of what people

00:32:11.060 --> 00:32:13.010
are doing with TensorFlow.js.

00:32:13.010 --> 00:32:16.230
We saw earlier that it runs on
a bunch of different platforms.

00:32:16.230 --> 00:32:20.510
So these examples will
sort of span many of these.

00:32:20.510 --> 00:32:22.400
Creatability, this
is a project that's

00:32:22.400 --> 00:32:24.920
being developed by the
Creative Labs team in Google,

00:32:24.920 --> 00:32:27.590
and this consists of
a set of experiments

00:32:27.590 --> 00:32:29.210
where they're
exploring how to use

00:32:29.210 --> 00:32:33.560
AI and ML to make these
creative tools more accessible.

00:32:33.560 --> 00:32:35.792
These run machine learning
models in the browser,

00:32:35.792 --> 00:32:37.250
and in this particular
case you see

00:32:37.250 --> 00:32:40.970
a person controlling a keyboard
with head gestures and head

00:32:40.970 --> 00:32:41.900
motion.

00:32:41.900 --> 00:32:43.550
They have some
really cool examples,

00:32:43.550 --> 00:32:46.290
and I encourage you to check out
the experiment sandbox, which

00:32:46.290 --> 00:32:48.890
is showing many of these
all on the website.

00:32:51.440 --> 00:32:54.590
Uber uses machine learning
in a very significant way

00:32:54.590 --> 00:32:58.730
for a wide variety of problems
at a very large scale,

00:32:58.730 --> 00:33:01.700
and Manifold is a
browser-based application

00:33:01.700 --> 00:33:05.330
that Uber uses to visualize and
debug their machine learning

00:33:05.330 --> 00:33:07.830
models and data pipelines.

00:33:07.830 --> 00:33:09.630
So this application
runs in the browser,

00:33:09.630 --> 00:33:11.900
and they're using
TensorFlow.js for a lot

00:33:11.900 --> 00:33:15.570
of numerical computations
that they want to use here.

00:33:15.570 --> 00:33:19.620
So, for example, distance
calculations and visualization,

00:33:19.620 --> 00:33:22.008
as well as clustering
of data, et cetera.

00:33:22.008 --> 00:33:24.050
They were able to find
that, because of the WebGL

00:33:24.050 --> 00:33:26.390
acceleration, they
could accelerate

00:33:26.390 --> 00:33:28.430
these computations
more than 100x

00:33:28.430 --> 00:33:33.090
compared to just natively
using JavaScript.

00:33:33.090 --> 00:33:34.560
AirBnB has an
interesting use case

00:33:34.560 --> 00:33:37.890
where their Trust team,
when a user is trying

00:33:37.890 --> 00:33:42.570
to upload a profile picture to
the AirBnB website, sometimes

00:33:42.570 --> 00:33:44.730
people accidentally
use a driver's license

00:33:44.730 --> 00:33:46.620
picture or a passport
picture, which

00:33:46.620 --> 00:33:50.095
may end up containing personal,
sensitive information.

00:33:50.095 --> 00:33:51.720
So AirBnB runs a
machine learning model

00:33:51.720 --> 00:33:55.275
directly on your client-side
in the browser or on device

00:33:55.275 --> 00:33:57.150
so that if you were to
choose a picture which

00:33:57.150 --> 00:33:59.370
may have some
sensitive information,

00:33:59.370 --> 00:34:02.250
it will alert you before
you upload that picture

00:34:02.250 --> 00:34:05.520
and prevent you from doing that.

00:34:05.520 --> 00:34:09.540
On the server-side, Clinic.js
is a really nice example

00:34:09.540 --> 00:34:12.360
of an application that
NearForm has built.

00:34:12.360 --> 00:34:14.830
This is a Node.js-based
application,

00:34:14.830 --> 00:34:20.280
which is used for profiling
node jobs or node processes.

00:34:20.280 --> 00:34:24.719
And they're using TensorFlow.js
to look for anomalies or spikes

00:34:24.719 --> 00:34:27.699
in CPU usage or
memory consumption

00:34:27.699 --> 00:34:29.969
of these node applications.

00:34:29.969 --> 00:34:32.699
So it's a really nice example
of server-side application

00:34:32.699 --> 00:34:35.880
of TensorFlow.js.

00:34:35.880 --> 00:34:38.969
In the desktop, TensorFlow.js
can be used with Electron,

00:34:38.969 --> 00:34:41.969
and Magenta Studio
is a set of plugins

00:34:41.969 --> 00:34:44.489
that has packaged a collection
of machine learning models

00:34:44.489 --> 00:34:48.420
for music generation
that used TensorFlow.js

00:34:48.420 --> 00:34:52.050
for some very fun and
creative music applications.

00:34:52.050 --> 00:34:54.870
I think Magenta has a talk
later today that you might

00:34:54.870 --> 00:34:58.140
want to check out, And they also
have some demos in the sandbox.

00:34:58.140 --> 00:35:01.140
We have the Ableton Live
plug-in for this in our sandbox

00:35:01.140 --> 00:35:04.810
that you can see.

00:35:04.810 --> 00:35:09.280
TensorFlow.js also runs on
mobile platforms on mobile web

00:35:09.280 --> 00:35:12.220
both on iOS and
Android, and recently we

00:35:12.220 --> 00:35:13.840
have been working
on adding support

00:35:13.840 --> 00:35:15.580
for the WeChat application.

00:35:15.580 --> 00:35:19.165
So WeChat is a very popular
social media platform

00:35:19.165 --> 00:35:22.120
and messaging application,
and it has a mini program

00:35:22.120 --> 00:35:24.430
environment, which
lets developers

00:35:24.430 --> 00:35:26.650
build these small JavaScript
applications called

00:35:26.650 --> 00:35:30.110
mini programs and easily
deploy and share them.

00:35:30.110 --> 00:35:32.200
So let's take a quick
look at a prototype

00:35:32.200 --> 00:35:34.490
of what this could look like.

00:35:34.490 --> 00:35:36.340
So in this video,
what you will see

00:35:36.340 --> 00:35:42.310
is a Pac-Man game that's
shared as a WeChat mini-app,

00:35:42.310 --> 00:35:47.020
and it will let the user control
this game using head motion

00:35:47.020 --> 00:35:49.180
from the phone's camera.

00:35:49.180 --> 00:35:50.770
So you see the
WeChat application

00:35:50.770 --> 00:35:53.680
being launched here, and
then one of my friends

00:35:53.680 --> 00:35:57.640
has shared this mini
program via a link.

00:35:57.640 --> 00:36:00.730
And I just click on it
and I launch this game,

00:36:00.730 --> 00:36:02.410
and now this game is
a little JavaScript

00:36:02.410 --> 00:36:05.530
program that's running within
the WeChat environment.

00:36:05.530 --> 00:36:07.840
After I do a very
quick calibration step

00:36:07.840 --> 00:36:10.270
by looking straight
up at the phone,

00:36:10.270 --> 00:36:12.110
I'm ready to play this game.

00:36:12.110 --> 00:36:13.660
And so this Pac-Man
game is loaded,

00:36:13.660 --> 00:36:16.180
and you will see in a
moment, my head motion

00:36:16.180 --> 00:36:19.340
is driving that little
Pac-Man character.

00:36:19.340 --> 00:36:20.920
So a really fun
way of interacting

00:36:20.920 --> 00:36:22.690
with device, and
the nice thing is

00:36:22.690 --> 00:36:26.620
that you can do a variety of
things using webcams, using

00:36:26.620 --> 00:36:30.340
text, using speech, and have a
very convenient way of sharing

00:36:30.340 --> 00:36:34.380
these applications without
having to install anything.

00:36:34.380 --> 00:36:36.670
So we saw a bunch of examples.

00:36:36.670 --> 00:36:39.330
I just want to quickly show
you that the community has

00:36:39.330 --> 00:36:41.790
been building some really
interesting applications

00:36:41.790 --> 00:36:43.530
and use cases beyond
all the examples

00:36:43.530 --> 00:36:44.910
that I've shown you so far.

00:36:44.910 --> 00:36:46.410
And for those of
you in the audience

00:36:46.410 --> 00:36:49.440
who have been using
TensorFlow.js, a big thank you.

00:36:49.440 --> 00:36:51.258
We have a collection
of these examples

00:36:51.258 --> 00:36:53.300
that you can check out on
our gallery page, which

00:36:53.300 --> 00:36:55.740
are extending
TensorFlow.js and using it

00:36:55.740 --> 00:36:57.690
for things like
reinforcement learning

00:36:57.690 --> 00:37:00.660
for that self-driving car
example or generative models

00:37:00.660 --> 00:37:04.100
and a variety of other
interesting applications.

00:37:04.100 --> 00:37:05.890
We also have a
bunch of developers

00:37:05.890 --> 00:37:08.740
who are building add-on
libraries as extensions

00:37:08.740 --> 00:37:11.080
on top of
TensorFlow.js, and these

00:37:11.080 --> 00:37:14.020
are extending TensorFlow.js
in very useful ways

00:37:14.020 --> 00:37:16.570
for libraries that
let you track hand

00:37:16.570 --> 00:37:20.870
gestures or facial movement
and facial gestures

00:37:20.870 --> 00:37:23.200
or also do more things
like hyperparameter

00:37:23.200 --> 00:37:26.320
tuning of machine learning
models, et cetera.

00:37:26.320 --> 00:37:28.570
So there are a bunch of these
resources also available

00:37:28.570 --> 00:37:30.370
on our website.

00:37:30.370 --> 00:37:33.190
So in closing, I want to just
point out a couple of resources

00:37:33.190 --> 00:37:35.710
to help you get started.

00:37:35.710 --> 00:37:37.740
There is this new textbook
that is coming out.

00:37:37.740 --> 00:37:39.490
It's called Deep
Learning With JavaScript,

00:37:39.490 --> 00:37:40.907
and it's written
by our colleagues

00:37:40.907 --> 00:37:42.970
on the TensorFlow.js team.

00:37:42.970 --> 00:37:45.430
It's an excellent resource for
learning about deep learning

00:37:45.430 --> 00:37:47.590
and machine learning,
and all examples

00:37:47.590 --> 00:37:51.130
are written in JavaScript
using TensorFlow.js.

00:37:51.130 --> 00:37:53.020
For our audience here
and people listening ,

00:37:53.020 --> 00:37:55.700
we have a really nice sort of
an offer of a discount code.

00:37:55.700 --> 00:37:58.300
So that might find that useful.

00:37:58.300 --> 00:38:02.380
TensorFlow recently also
launched a new Coursera course

00:38:02.380 --> 00:38:05.710
for deep-learning AI
to introduce TensorFlow

00:38:05.710 --> 00:38:06.742
and machine learning.

00:38:06.742 --> 00:38:08.200
And as part of this
course, we will

00:38:08.200 --> 00:38:10.150
have a module on
TensorFlow.js, which we'll be

00:38:10.150 --> 00:38:12.625
launching in a couple of weeks.

00:38:12.625 --> 00:38:15.310
I just want to point out
a few more useful links

00:38:15.310 --> 00:38:19.010
on our website for our
models repo, for our gallery.

00:38:19.010 --> 00:38:21.760
And then also we have an
office hours session right here

00:38:21.760 --> 00:38:23.710
in Google I I/O tomorrow.

00:38:23.710 --> 00:38:25.570
You can come by and
ask your questions

00:38:25.570 --> 00:38:27.550
and meet the TensorFlow.js team.

00:38:27.550 --> 00:38:29.320
You can check out
many more demos

00:38:29.320 --> 00:38:32.650
at our demonstration
in the AI/ML sandbox,

00:38:32.650 --> 00:38:34.930
and also there are a
few hands-on codelabs

00:38:34.930 --> 00:38:38.030
that you can try interactively
in the codelabs area.

00:38:38.030 --> 00:38:40.030
So thank you so much for
coming out here today,

00:38:40.030 --> 00:38:42.940
and have a great
rest of the I/O.

