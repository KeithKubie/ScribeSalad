WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.465
[MUSIC PLAYING]

00:00:05.920 --> 00:00:08.230
CHRIS RAMSDALE: Hello, and
welcome to Google I/O 2017.

00:00:08.230 --> 00:00:09.950
I hope everybody had
a great first day

00:00:09.950 --> 00:00:12.490
and got to check out some of
the sessions, the sandboxes

00:00:12.490 --> 00:00:13.900
and the codelabs.

00:00:13.900 --> 00:00:15.790
I'm Chris Ramsdale, the
lead product manager

00:00:15.790 --> 00:00:17.361
for the Google Assistant SDK.

00:00:17.361 --> 00:00:19.360
GLEN SHIRES: And I'm Glen
Shires, technical lead

00:00:19.360 --> 00:00:20.777
for the Google Assistant SDK.

00:00:20.777 --> 00:00:22.360
CHRIS RAMSDALE:
Today, we want to talk

00:00:22.360 --> 00:00:25.330
to you about one ubiquitous
Google Assistant experience

00:00:25.330 --> 00:00:29.899
that utilizes many of the
devices in your everyday life.

00:00:29.899 --> 00:00:31.690
Back at I/O last year,
the Google Assistant

00:00:31.690 --> 00:00:36.160
made its debut in the form
of integration with Allo.

00:00:36.160 --> 00:00:38.770
And while much of the technology
that makes up the Assistant

00:00:38.770 --> 00:00:40.570
had been in the
works for years--

00:00:40.570 --> 00:00:44.020
things like voice search,
automated speech recognition,

00:00:44.020 --> 00:00:46.122
natural language understanding--

00:00:46.122 --> 00:00:47.830
while they'd been in
the works for years,

00:00:47.830 --> 00:00:50.230
it was the first time that
they'd made their public debut

00:00:50.230 --> 00:00:52.700
in the form of the Assistant.

00:00:52.700 --> 00:00:55.180
Now, since then, the teams
have been hard at work

00:00:55.180 --> 00:00:58.750
to flesh out the story
that Google wants to tell,

00:00:58.750 --> 00:01:01.570
in terms of launching new
devices like the Google

00:01:01.570 --> 00:01:06.784
Home, the Pixel, and
other Android platforms.

00:01:06.784 --> 00:01:09.190
And we've also brought
third-party services

00:01:09.190 --> 00:01:11.830
into the fold, via
Actions on Google,

00:01:11.830 --> 00:01:14.620
as well as home automation
devices and services

00:01:14.620 --> 00:01:17.590
in terms of technologies like
the Home Graph and Smarthome

00:01:17.590 --> 00:01:20.475
agents which I'll
talk about in a bit.

00:01:20.475 --> 00:01:22.600
And while this was great,
when we took a step back,

00:01:22.600 --> 00:01:24.870
we realized something
was missing.

00:01:24.870 --> 00:01:27.160
See at Google, especially
within the Assistant team,

00:01:27.160 --> 00:01:29.020
one of our missions
is to help you

00:01:29.020 --> 00:01:33.160
with whatever you want, wherever
you want, wherever you are.

00:01:33.160 --> 00:01:35.980
We managed to bring some of the
fundamental services to you,

00:01:35.980 --> 00:01:40.070
be it news, podcasts,
home automation, weather,

00:01:40.070 --> 00:01:42.220
but they were only
available from devices

00:01:42.220 --> 00:01:43.720
that Google provided.

00:01:43.720 --> 00:01:44.770
Now, let's be honest.

00:01:44.770 --> 00:01:46.270
We don't expect you
to have a Google

00:01:46.270 --> 00:01:47.794
Home in every corner
of your house,

00:01:47.794 --> 00:01:49.210
nor do we expect
Google to provide

00:01:49.210 --> 00:01:51.520
every appliance in your house.

00:01:51.520 --> 00:01:53.830
In order to meet you
whenever you needed it,

00:01:53.830 --> 00:01:57.340
wherever you need it, we needed
to empower a diverse ecosystem

00:01:57.340 --> 00:01:59.320
of third-party
device manufacturers

00:01:59.320 --> 00:02:01.840
that were able to embed the
Google Assistant in the devices

00:02:01.840 --> 00:02:03.290
they were building.

00:02:03.290 --> 00:02:06.010
Just as Actions
on Google enables

00:02:06.010 --> 00:02:10.030
you to extend the Assistant to
include third-party services,

00:02:10.030 --> 00:02:12.746
we needed an analogous
offering on the device side.

00:02:12.746 --> 00:02:14.620
We needed a way to allow
device manufacturers

00:02:14.620 --> 00:02:16.570
to embed the Assistant
and to extend

00:02:16.570 --> 00:02:19.660
it to control the devices.

00:02:19.660 --> 00:02:21.340
Enter the Google
Assistant SDK, which

00:02:21.340 --> 00:02:22.780
we launched three weeks ago.

00:02:22.780 --> 00:02:23.530
It does just that.

00:02:23.530 --> 00:02:26.260
It's a software development kit
that allows third party device

00:02:26.260 --> 00:02:28.705
manufacturers to embed the
Assistant in their device.

00:02:31.210 --> 00:02:33.760
At its core is a
gRPC API that allows

00:02:33.760 --> 00:02:37.570
you to access the Assistant
from any platform.

00:02:37.570 --> 00:02:40.870
Along with that comes
documentation, samples,

00:02:40.870 --> 00:02:44.050
and tools to get
started quickly.

00:02:44.050 --> 00:02:47.260
The API itself is an
audio in, audio out API.

00:02:47.260 --> 00:02:49.180
It allows you to
build hardware where

00:02:49.180 --> 00:02:52.165
users can interact with the
Assistant in a general form--

00:02:52.165 --> 00:02:53.290
hey, Google, how big is Mt.

00:02:53.290 --> 00:02:55.540
Everest?-- to a personal form--

00:02:55.540 --> 00:02:57.644
hey, Google, what's
on my calendar today--

00:02:57.644 --> 00:02:59.560
to working with any other
third-party services

00:02:59.560 --> 00:03:02.794
that have extended the
assistant via Actions on Google.

00:03:02.794 --> 00:03:04.210
And given the fact
that the API is

00:03:04.210 --> 00:03:06.160
built on the gRPC
protocol, which

00:03:06.160 --> 00:03:08.500
is optimized for
bidirectional streaming,

00:03:08.500 --> 00:03:11.200
you can be sure that your
audio flows smoothly and is

00:03:11.200 --> 00:03:13.890
processed quickly.

00:03:13.890 --> 00:03:15.890
And while it was only
announced three weeks ago,

00:03:15.890 --> 00:03:18.150
we've already seen a lot of
cool innovation happening

00:03:18.150 --> 00:03:19.890
within the communities.

00:03:19.890 --> 00:03:22.200
For starters, we have
a Mocktails Mixer

00:03:22.200 --> 00:03:24.150
out on Main Street
that I encourage you

00:03:24.150 --> 00:03:26.000
to come out to see a demo of.

00:03:26.000 --> 00:03:29.330
It's a collaboration between
the Google Assistant SDK team

00:03:29.330 --> 00:03:31.940
and a creative agency
called Deeplocal.

00:03:31.940 --> 00:03:34.350
And it's a mixer that has
the Google Assistant built in

00:03:34.350 --> 00:03:38.520
and will bring you any
drink of your choice.

00:03:38.520 --> 00:03:41.520
We're also seeing other ideas
within the startup communities,

00:03:41.520 --> 00:03:44.204
everything from
the AutoPi.io folks

00:03:44.204 --> 00:03:45.870
which have instructions
for how to embed

00:03:45.870 --> 00:03:48.420
the assistant on
like a prototype car,

00:03:48.420 --> 00:03:51.065
to what appears to be a
Wi-Fi enabled smart rabbit.

00:03:51.065 --> 00:03:52.440
For those of you
who would rather

00:03:52.440 --> 00:03:54.648
have a smart rabbit in your
house than a Google Home,

00:03:54.648 --> 00:03:55.789
you now have options.

00:03:55.789 --> 00:03:57.330
But seriously, beyond
that we're also

00:03:57.330 --> 00:03:59.430
working with commercial
OEMs to embed

00:03:59.430 --> 00:04:02.130
the Assistant in their devices.

00:04:02.130 --> 00:04:03.660
And over the coming
months, we'll

00:04:03.660 --> 00:04:06.630
have commercial terms, things
like device certification

00:04:06.630 --> 00:04:12.380
programs, branding
guidelines and UX guidelines.

00:04:12.380 --> 00:04:14.480
Speaking of spurring
innovation, another program

00:04:14.480 --> 00:04:16.779
that we launched was
called AIY, similar

00:04:16.779 --> 00:04:19.570
to the do-it-yourself
communities which is DIY.

00:04:19.570 --> 00:04:22.019
AIY aims to bring artificial
intelligence to the Maker

00:04:22.019 --> 00:04:25.190
Toolkit, allowing them to build
devices that help both them

00:04:25.190 --> 00:04:27.110
and their communities.

00:04:27.110 --> 00:04:29.900
At the core of the program is a
set of kits that you can build.

00:04:29.900 --> 00:04:31.640
The first kit that
we rolled out was

00:04:31.640 --> 00:04:34.970
a voice kit that comes with
the Google Assistant SDK,

00:04:34.970 --> 00:04:38.540
as well as a button, a
speaker, a cardboard box,

00:04:38.540 --> 00:04:41.180
and instructions for making
your own makeshift Google Home

00:04:41.180 --> 00:04:44.510
that we hope you extend in
ways that we never dreamed of.

00:04:44.510 --> 00:04:45.980
You may notice one up here.

00:04:45.980 --> 00:04:46.700
Right up here.

00:04:46.700 --> 00:04:48.533
Glen will be doing demos
on it very shortly.

00:04:52.140 --> 00:04:54.272
So that's what we've
launched, and I

00:04:54.272 --> 00:04:55.980
want to talk a little
bit more about what

00:04:55.980 --> 00:04:57.210
we're launching today.

00:04:57.210 --> 00:05:00.210
So as of yesterday, we've
added a thick client library

00:05:00.210 --> 00:05:03.810
to the SDK that does things
like automate a lot of the lower

00:05:03.810 --> 00:05:05.550
level plumbing, as
well as give you

00:05:05.550 --> 00:05:08.310
client-side functionality
in terms of Hotword support

00:05:08.310 --> 00:05:09.894
and timers and alarms.

00:05:09.894 --> 00:05:11.310
With the addition
of this library,

00:05:11.310 --> 00:05:13.159
developers now have options.

00:05:13.159 --> 00:05:14.700
If you want more
automation or if you

00:05:14.700 --> 00:05:16.717
need Hotword support
or timers and alarms,

00:05:16.717 --> 00:05:19.050
we think the Google Assistant
library, that thick client

00:05:19.050 --> 00:05:20.735
library, is a good fit.

00:05:20.735 --> 00:05:22.860
You just need to be
comfortable with embedded Linux

00:05:22.860 --> 00:05:25.320
and an [? RMD-7 ?] chipset,
because the client side code is

00:05:25.320 --> 00:05:28.380
tied to that particular
platform and that hardware.

00:05:28.380 --> 00:05:32.760
On the other hand, if you favor
or need platform independence,

00:05:32.760 --> 00:05:34.830
we think the gRPC
API is a great route.

00:05:34.830 --> 00:05:37.620
As I had mentioned, it's
accessible from any platform,

00:05:37.620 --> 00:05:40.440
any hardware, any
language, with the caveat

00:05:40.440 --> 00:05:42.060
that it doesn't
have the client side

00:05:42.060 --> 00:05:45.230
support of Hotwords, timers and
alarms, but that's just now.

00:05:50.810 --> 00:05:53.210
And I want to take a
moment to actually preview

00:05:53.210 --> 00:05:55.840
some of the tools that
we're building to make voice

00:05:55.840 --> 00:05:57.956
control of devices much easier.

00:05:57.956 --> 00:05:59.330
Now, Glen's going
to have a demo,

00:05:59.330 --> 00:06:01.696
and we also have demos
over in Sandbox B of this,

00:06:01.696 --> 00:06:04.070
but I thought I'd take a moment
to provide a higher level

00:06:04.070 --> 00:06:06.950
view so you can
understand broadly

00:06:06.950 --> 00:06:09.800
what we're trying to achieve
here with more devices

00:06:09.800 --> 00:06:12.830
being in your life having
the assistant on them.

00:06:12.830 --> 00:06:14.990
See, first it's important
to know what devices you

00:06:14.990 --> 00:06:17.450
have access to in your house--

00:06:17.450 --> 00:06:20.900
be it the TV, or a
speaker, an oven,

00:06:20.900 --> 00:06:22.880
or that Wi-Fi smart
enabled rabbit

00:06:22.880 --> 00:06:24.770
that we just talked about.

00:06:24.770 --> 00:06:26.570
By knowing what devices
we have access to,

00:06:26.570 --> 00:06:28.700
or what you have access
to in your house,

00:06:28.700 --> 00:06:30.440
we can actually
enable and create

00:06:30.440 --> 00:06:33.369
more natural conversations
with those devices.

00:06:33.369 --> 00:06:35.660
And we think that's very
important, because if we don't

00:06:35.660 --> 00:06:38.210
get this right, this
whole voice enabled thing

00:06:38.210 --> 00:06:41.690
that we're trying to
all do and make happen,

00:06:41.690 --> 00:06:44.260
it's going to be very hard
for the masses to adopt it.

00:06:44.260 --> 00:06:45.890
You want to have
normal conversations

00:06:45.890 --> 00:06:47.265
with the things
in your life just

00:06:47.265 --> 00:06:48.800
like the people in your life.

00:06:48.800 --> 00:06:51.200
So by knowing what devices
you have access to,

00:06:51.200 --> 00:06:53.690
we can make the
conversation more natural.

00:06:53.690 --> 00:06:55.440
So instead of
saying, for example,

00:06:55.440 --> 00:06:57.860
if you had a smart enabled
oven, and you're in your living

00:06:57.860 --> 00:07:00.440
room talking to your Google
Home, instead of saying,

00:07:00.440 --> 00:07:03.090
hey, Google, let me
talk to my company,

00:07:03.090 --> 00:07:05.270
my company, set
the oven to bake,

00:07:05.270 --> 00:07:09.170
set the oven to 425, what
you can do is say OK Google,

00:07:09.170 --> 00:07:11.450
set the oven to bake at 425.

00:07:11.450 --> 00:07:13.430
Just as you would
if you are talking

00:07:13.430 --> 00:07:15.722
to your child or
your wife or somebody

00:07:15.722 --> 00:07:17.430
else that happened to
be in your kitchen.

00:07:17.430 --> 00:07:19.820
It's more natural.

00:07:19.820 --> 00:07:22.975
Second of all, when I move from
being in my living room talking

00:07:22.975 --> 00:07:25.100
to my Google Home and now
I've moved to my kitchen,

00:07:25.100 --> 00:07:27.650
say I'm preparing
dinner, I'm actually

00:07:27.650 --> 00:07:30.050
talking to the
device itself, which

00:07:30.050 --> 00:07:32.580
if you had to talk to the
device itself and say,

00:07:32.580 --> 00:07:36.406
hey, Google, let me talk to my
company, set the oven to bake,

00:07:36.406 --> 00:07:38.780
set the temperature to 425,
that's really odd when you're

00:07:38.780 --> 00:07:39.440
talking to the device.

00:07:39.440 --> 00:07:41.606
What you want to be able
to do while you're chopping

00:07:41.606 --> 00:07:44.630
the carrots and potatoes
is simply say, OK Google,

00:07:44.630 --> 00:07:46.072
set to bake at 425.

00:07:46.072 --> 00:07:48.530
You end up having more natural
conversations whether you're

00:07:48.530 --> 00:07:50.840
talking to the Google Home
to work with the device,

00:07:50.840 --> 00:07:53.610
you're talking to
the device itself.

00:07:53.610 --> 00:07:55.340
So that's the end
user experience--

00:07:55.340 --> 00:07:56.780
that's the beginning of
the end user experience

00:07:56.780 --> 00:07:57.860
that we're trying to achieve.

00:07:57.860 --> 00:07:59.901
But let's take a second
to go a little bit deeper

00:07:59.901 --> 00:08:03.380
and talk about how that
actually would work.

00:08:03.380 --> 00:08:06.590
So take the case
where you're actually

00:08:06.590 --> 00:08:08.090
doing remote invocation.

00:08:08.090 --> 00:08:09.470
You're talking to
the Google Home

00:08:09.470 --> 00:08:11.540
which is setting up the oven.

00:08:11.540 --> 00:08:13.790
In that case you say,
OK Google, set the oven

00:08:13.790 --> 00:08:16.820
to bake at 425 degrees.

00:08:16.820 --> 00:08:19.700
So that query goes from
me to my Google Home

00:08:19.700 --> 00:08:21.590
then to the Assistant
Service running.

00:08:21.590 --> 00:08:23.360
That Assistant
Service is made up

00:08:23.360 --> 00:08:26.640
of speech recognition, natural
language understanding,

00:08:26.640 --> 00:08:29.600
the Smarthome, and a technology
we call the Home Graph.

00:08:29.600 --> 00:08:33.530
So what it can do is it can
take that query, what I said,

00:08:33.530 --> 00:08:34.730
and start to parse it apart.

00:08:34.730 --> 00:08:37.490
And when it parses it apart,
the speech recognition

00:08:37.490 --> 00:08:39.450
actually talks to the
Home Graph and says,

00:08:39.450 --> 00:08:42.919
hey, do you recognize any of
these pieces in this phrase?

00:08:42.919 --> 00:08:44.710
And the Home Graphs
says, I actually do.

00:08:44.710 --> 00:08:48.050
I recognize the oven as being
a device that's been registered

00:08:48.050 --> 00:08:49.429
with the Home Graph.

00:08:49.429 --> 00:08:51.470
The way it gets registered
is when you'd actually

00:08:51.470 --> 00:08:53.660
go to your home device
and on the Assistant app

00:08:53.660 --> 00:08:54.770
on your phone you
could say, I want

00:08:54.770 --> 00:08:56.894
to add that to my Home
Graph, and it would walk you

00:08:56.894 --> 00:08:57.952
through that flow.

00:08:57.952 --> 00:08:59.660
So now, the Home Graph
says, I understand

00:08:59.660 --> 00:09:00.620
that that's the oven.

00:09:00.620 --> 00:09:02.494
So the speech recognition
says, that's great.

00:09:02.494 --> 00:09:05.150
So I've got the oven,
which is the noun,

00:09:05.150 --> 00:09:06.680
the thing I'm trying
to operate on,

00:09:06.680 --> 00:09:08.596
and then I've got these
other things that look

00:09:08.596 --> 00:09:09.860
like verbs and nouns as well.

00:09:09.860 --> 00:09:13.250
And it passes that over to the
natural language understanding,

00:09:13.250 --> 00:09:14.360
that service.

00:09:14.360 --> 00:09:16.190
It takes that and says
to the Home Graph,

00:09:16.190 --> 00:09:19.820
do you understand what it means
to set this program, which is

00:09:19.820 --> 00:09:21.870
bake, and set this temperature?

00:09:21.870 --> 00:09:23.510
And the Home Graph says yes.

00:09:23.510 --> 00:09:26.510
The oven is capable of these
certain traits, programs

00:09:26.510 --> 00:09:30.640
that are like bake and warm and
broil, and then temperatures,

00:09:30.640 --> 00:09:31.970
and that's a number.

00:09:31.970 --> 00:09:34.470
So at that point in time, the
natural language understanding

00:09:34.470 --> 00:09:36.650
can say cool, I understand
not only what they said,

00:09:36.650 --> 00:09:38.600
but what they intended.

00:09:38.600 --> 00:09:41.077
But it says, I have no
idea what to do with this.

00:09:41.077 --> 00:09:43.410
I've got an intent, but I
don't know what to do with it.

00:09:43.410 --> 00:09:45.034
So it sends that over
to the Smarthome,

00:09:45.034 --> 00:09:46.970
and the Smarthome
says, cool, I got this.

00:09:46.970 --> 00:09:49.160
I actually know what
to do with this intent.

00:09:49.160 --> 00:09:50.990
I know that the
oven is of this type

00:09:50.990 --> 00:09:53.120
and tied to this manufacturer.

00:09:53.120 --> 00:09:55.780
And this manufacturer actually
has a third-party cloud

00:09:55.780 --> 00:10:00.681
and knows how to actually get
the intent down to the device.

00:10:00.681 --> 00:10:02.930
To give you a concrete
example, this is very analogous

00:10:02.930 --> 00:10:06.740
if you have say a Nest
thermostat in your home.

00:10:06.740 --> 00:10:08.200
You're talking to
the Google Home,

00:10:08.200 --> 00:10:09.908
the Google Home does
all this processing,

00:10:09.908 --> 00:10:12.200
and at the end of it,
the Smarthome component

00:10:12.200 --> 00:10:15.090
hands it off to the Nest
cloud, and the Nest cloud says,

00:10:15.090 --> 00:10:18.350
I know how to actually query the
device for what temperature it

00:10:18.350 --> 00:10:21.776
is, or to set the
temperature on the device.

00:10:21.776 --> 00:10:22.400
So I apologize.

00:10:22.400 --> 00:10:23.970
This actually says
local execution path.

00:10:23.970 --> 00:10:25.400
This is the remote
invocation path

00:10:25.400 --> 00:10:27.316
where I'm actually
controlling the device when

00:10:27.316 --> 00:10:28.960
I'm not talking to the device.

00:10:28.960 --> 00:10:30.710
So let's talk about
how you actually would

00:10:30.710 --> 00:10:33.240
do the local invocation path.

00:10:33.240 --> 00:10:36.970
So again, this is when I'm in
the kitchen talking to my oven.

00:10:36.970 --> 00:10:40.860
I say, OK Google, set
to bake at 425 degrees.

00:10:40.860 --> 00:10:43.190
Now that query comes
back in the same path,

00:10:43.190 --> 00:10:45.260
but notice I didn't
say the oven.

00:10:45.260 --> 00:10:48.071
So the speech recognition,
it gets the query.

00:10:48.071 --> 00:10:50.320
It's missing the oven piece,
but what it actually gets

00:10:50.320 --> 00:10:53.630
is some bit of metadata,
which is the device ID.

00:10:53.630 --> 00:10:56.330
That comes from the Assistant
being embedded on the oven,

00:10:56.330 --> 00:10:58.160
picking up the
query, figuring out

00:10:58.160 --> 00:11:01.220
what device it's coming from
and passing it up to our cloud.

00:11:01.220 --> 00:11:03.080
So the speech
recognition says, look,

00:11:03.080 --> 00:11:08.000
I got this set to
bake at 425 degrees,

00:11:08.000 --> 00:11:09.410
but I also got this device ID.

00:11:09.410 --> 00:11:11.320
Home Graph, do you know
what to do with this?

00:11:11.320 --> 00:11:13.195
And in a very similar
fashion, the Home Graph

00:11:13.195 --> 00:11:15.890
says, oh yes, I
recognize that device ID.

00:11:15.890 --> 00:11:18.380
It's tied to this manufacturer,
and it's this thing.

00:11:18.380 --> 00:11:19.244
It's an oven.

00:11:19.244 --> 00:11:20.660
So now, the speech
recognition has

00:11:20.660 --> 00:11:22.765
the same fundamental
building blocks,

00:11:22.765 --> 00:11:24.140
through local
invocation, that it

00:11:24.140 --> 00:11:26.180
did through remote invocation.

00:11:26.180 --> 00:11:30.260
So it can pass it on to the
NLU the Natural Language

00:11:30.260 --> 00:11:32.150
Understanding,
and the NLU can do

00:11:32.150 --> 00:11:34.640
the same thing it did before,
and then it passes it over

00:11:34.640 --> 00:11:35.510
to the Smarthome.

00:11:35.510 --> 00:11:38.250
Now, at this point in time,
things twist a little bit.

00:11:38.250 --> 00:11:40.610
The Smarthome says,
OK, I understand

00:11:40.610 --> 00:11:43.010
what the user-- the intent
of the user, but that intent

00:11:43.010 --> 00:11:45.020
came from an interaction
with a device,

00:11:45.020 --> 00:11:47.981
because the Smarthome gets
the device ID as well.

00:11:47.981 --> 00:11:50.480
And so when it talks to the
Home Graph, the Home Graph goes,

00:11:50.480 --> 00:11:53.060
you can send that back
down to the device.

00:11:53.060 --> 00:11:55.220
You don't have to go
through a third-party cloud.

00:11:55.220 --> 00:11:57.220
So what the Smarthome
does is it sends back down

00:11:57.220 --> 00:12:01.880
to the device the audio, so
setting oven to 425 degrees,

00:12:01.880 --> 00:12:04.100
as well as the structured
response in terms

00:12:04.100 --> 00:12:06.510
of a JSON payload back
down to the device.

00:12:06.510 --> 00:12:07.792
The device can say, cool.

00:12:07.792 --> 00:12:09.500
Actually, when it
sends it to the device,

00:12:09.500 --> 00:12:12.680
it's sending to the Assistant
that's embedded on the device.

00:12:12.680 --> 00:12:14.474
And the Assistant
picks it up it says,

00:12:14.474 --> 00:12:15.890
I don't know what
to do with this,

00:12:15.890 --> 00:12:17.556
but let me see if I
have a module that's

00:12:17.556 --> 00:12:19.430
actually registered to
handle this response.

00:12:19.430 --> 00:12:20.221
Do, do, do, do, do.

00:12:20.221 --> 00:12:21.410
I do.

00:12:21.410 --> 00:12:24.770
Calls that on the device,
and that code actually

00:12:24.770 --> 00:12:28.950
sets the oven to
bake at 425 degrees.

00:12:28.950 --> 00:12:31.580
Now, to the end user this
is great, because again,

00:12:31.580 --> 00:12:33.470
it creates a natural
conversation no matter

00:12:33.470 --> 00:12:35.330
where you are in your home.

00:12:35.330 --> 00:12:38.120
And while I gave an
example of just one device,

00:12:38.120 --> 00:12:39.474
fast forward two to five years.

00:12:39.474 --> 00:12:42.140
Imagine a whole bunch of devices
in your home that are listening

00:12:42.140 --> 00:12:43.610
and you're
interacting with them.

00:12:43.610 --> 00:12:45.712
If you have odd
conversations, that's

00:12:45.712 --> 00:12:47.420
just not going to work
out in your favor.

00:12:47.420 --> 00:12:49.987
So that's what's good from the
user experience perspective.

00:12:49.987 --> 00:12:52.070
From the developer perspective
and from the device

00:12:52.070 --> 00:12:54.980
manufacturer's perspective,
you get code reuse.

00:12:54.980 --> 00:12:57.230
The same code that's
being executed

00:12:57.230 --> 00:13:00.090
when I'm talking to my home
device back down to the oven

00:13:00.090 --> 00:13:02.465
is the same code that's running
when I'm talking directly

00:13:02.465 --> 00:13:03.180
to my device.

00:13:03.180 --> 00:13:05.060
So if it's a developer
you get code reuse.

00:13:05.060 --> 00:13:06.550
That's good.

00:13:06.550 --> 00:13:08.120
As a device
manufacturer, the benefit

00:13:08.120 --> 00:13:11.150
is that it's a shorter
path to getting to market,

00:13:11.150 --> 00:13:12.770
because you don't
have to have a cloud

00:13:12.770 --> 00:13:15.487
presence to have the
Assistant running on a device.

00:13:15.487 --> 00:13:17.570
So if your goal is to make
the devices that you're

00:13:17.570 --> 00:13:21.230
building smarter by embedding
the Assistant on them,

00:13:21.230 --> 00:13:23.090
you can go to local
invocation route

00:13:23.090 --> 00:13:25.070
and simply put
code on the device

00:13:25.070 --> 00:13:28.430
and let the Assistant, our
speech recognition, NLU,

00:13:28.430 --> 00:13:31.370
Smarthome, and Home Graph handle
all this stuff in the cloud,

00:13:31.370 --> 00:13:33.020
because as you notice
on this screen,

00:13:33.020 --> 00:13:34.869
there is no cloud presence.

00:13:34.869 --> 00:13:36.410
We've dropped the
yellow bit that was

00:13:36.410 --> 00:13:37.704
on the remote invocation path.

00:13:37.704 --> 00:13:40.370
So we think that's great that as
a developer you get code reuse,

00:13:40.370 --> 00:13:43.130
and as a device manufacturer
that you get a shorter time

00:13:43.130 --> 00:13:44.550
to market.

00:13:44.550 --> 00:13:46.267
So OK, enough with
the high level stuff.

00:13:46.267 --> 00:13:48.350
I'm going to turn it over
to Glen to do some demos

00:13:48.350 --> 00:13:49.610
and talk about some code.

00:13:49.610 --> 00:13:51.693
GLEN SHIRES: All right,
thank you very much Chris.

00:13:51.693 --> 00:13:53.444
I appreciate that.

00:13:53.444 --> 00:13:56.432
[APPLAUSE]

00:14:04.570 --> 00:14:07.510
So as Chris mentioned,
yesterday, we

00:14:07.510 --> 00:14:12.617
announced the Hotword Library
that is available for download.

00:14:12.617 --> 00:14:14.200
So you can start
experimenting with it

00:14:14.200 --> 00:14:18.340
and start building it into
your project and products.

00:14:18.340 --> 00:14:22.140
What I'd like to do
is demonstrate that,

00:14:22.140 --> 00:14:23.560
jump right into a demo.

00:14:29.110 --> 00:14:33.450
OK Google, what sound
does a whale make?

00:14:33.450 --> 00:14:35.111
GOOGLE: Here's a whale sound.

00:14:35.111 --> 00:14:39.440
[WHALE SOUND]

00:14:39.440 --> 00:14:42.580
GLEN SHIRES: OK Google,
what's 18% of $57?

00:14:45.470 --> 00:14:50.080
GOOGLE: The answer is $10.26.

00:14:50.080 --> 00:14:52.300
GLEN SHIRES: OK Google,
add peanut butter

00:14:52.300 --> 00:14:54.850
to my shopping list.

00:14:54.850 --> 00:14:58.690
GOOGLE: OK, I've added peanut
butter to your shopping list.

00:14:58.690 --> 00:15:00.820
GLEN SHIRES: So there you go.

00:15:00.820 --> 00:15:04.780
So what we've done is we have
created a library that you

00:15:04.780 --> 00:15:10.840
can download and make it
really easy to incorporate OK

00:15:10.840 --> 00:15:16.780
Google into your projects,
as well as including

00:15:16.780 --> 00:15:19.437
the timers, alarms,
and other things.

00:15:19.437 --> 00:15:20.770
I'm sorry, it should have been--

00:15:23.546 --> 00:15:24.920
could we show this
one more time?

00:15:24.920 --> 00:15:26.294
I'm sorry, let's
go back to that.

00:15:29.020 --> 00:15:31.490
What I wanted to do is show
you exactly what I had here.

00:15:31.490 --> 00:15:34.550
This is a Raspberry
Pi, and I simply

00:15:34.550 --> 00:15:37.100
have a microphone, a single
microphone, and a speaker,

00:15:37.100 --> 00:15:40.430
plugged into a Raspberry
Pi, a power supply,

00:15:40.430 --> 00:15:43.670
and ethernet because Wi-Fi in
here is a little bit tricky.

00:15:43.670 --> 00:15:46.200
But that would work
on Wi-Fi as well.

00:15:46.200 --> 00:15:49.400
So basically, we just simply
have a speaker, a microphone,

00:15:49.400 --> 00:15:51.080
and an internet
connection, and that's

00:15:51.080 --> 00:15:56.720
all we need to implement
the capability of farfield,

00:15:56.720 --> 00:16:03.130
activation of the Hotword,
and to implement basic Google

00:16:03.130 --> 00:16:04.067
Assistant.

00:16:10.280 --> 00:16:12.770
So let me show you exactly
what is in the library.

00:16:12.770 --> 00:16:16.040
What's really cool is it's
extremely simple to use.

00:16:16.040 --> 00:16:20.060
This client library, you only
need to call a few method

00:16:20.060 --> 00:16:22.860
calls to make it work.

00:16:22.860 --> 00:16:24.800
Actually, you can
only call one method

00:16:24.800 --> 00:16:27.770
if you want to, just call
start, and it will just

00:16:27.770 --> 00:16:30.620
run autonomously,
waiting locally

00:16:30.620 --> 00:16:33.440
to listen for the Hotword,
OK Google, and then when

00:16:33.440 --> 00:16:35.780
it hears that, it
will take the audio,

00:16:35.780 --> 00:16:38.640
send it up to the Google
servers for processing.

00:16:38.640 --> 00:16:40.890
And when the audio comes
back, it will play that.

00:16:40.890 --> 00:16:42.890
So if that's all you want
to do, just call start

00:16:42.890 --> 00:16:44.487
and you're done, literally.

00:16:44.487 --> 00:16:46.070
There's a few other
things you can do.

00:16:46.070 --> 00:16:48.800
For example, you might want to
have a button on your device

00:16:48.800 --> 00:16:50.030
that mutes the microphone.

00:16:50.030 --> 00:16:52.370
So you can call that
mute the microphone.

00:16:52.370 --> 00:16:53.510
Turn that on and off.

00:16:53.510 --> 00:16:56.120
Or also, you may want to have
a button or a remote control

00:16:56.120 --> 00:16:58.440
where you activate it by
pushing rather than saying,

00:16:58.440 --> 00:17:00.990
OK Google, or Hey
Google as the Hotword.

00:17:00.990 --> 00:17:04.819
And so you can call
start interaction.

00:17:04.819 --> 00:17:07.700
We also have a number
of events that come out

00:17:07.700 --> 00:17:10.730
as it's processing so that
you can watch the status

00:17:10.730 --> 00:17:14.390
and perhaps have lights that
indicate the current status.

00:17:14.390 --> 00:17:17.180
For example,
conversation turn started

00:17:17.180 --> 00:17:20.060
means somebody said,
OK Google, and you've

00:17:20.060 --> 00:17:22.790
begun that conversation.

00:17:22.790 --> 00:17:25.160
End of utterance means
the person has finished

00:17:25.160 --> 00:17:29.570
talking, and recognizing speech
finished means the server has

00:17:29.570 --> 00:17:33.005
finished recognizing the speech,
and then responding started

00:17:33.005 --> 00:17:36.020
is actually talking back to
you, responding finished.

00:17:36.020 --> 00:17:39.290
So you can set up light bulbs
or whatever that indicate

00:17:39.290 --> 00:17:40.820
the status as it's going along.

00:17:40.820 --> 00:17:42.680
There's also alert
started, finish,

00:17:42.680 --> 00:17:45.462
so for timers and alarms.

00:17:45.462 --> 00:17:47.420
So number of events that
you can handle or not,

00:17:47.420 --> 00:17:49.920
depending on what exactly you'd
like to do with your device.

00:17:53.190 --> 00:17:55.470
So let me show you
another option,

00:17:55.470 --> 00:17:57.690
and this is basically
an option that if you

00:17:57.690 --> 00:17:59.520
want to do something
that's very minimal,

00:17:59.520 --> 00:18:04.680
or if you want more flexibility
and you don't need a Hotword,

00:18:04.680 --> 00:18:12.960
we have other options as well,
which is in this case, a way

00:18:12.960 --> 00:18:15.150
that you can make remote
procedure calls directly

00:18:15.150 --> 00:18:16.620
against the server.

00:18:16.620 --> 00:18:18.840
So it's minimal
processing on the board.

00:18:18.840 --> 00:18:22.230
In this case, I actually
have a Raspberry Pi Zero,

00:18:22.230 --> 00:18:26.340
which is a $5 or $10 retail
product, which is really

00:18:26.340 --> 00:18:28.500
all you need to do this,
because all it's doing

00:18:28.500 --> 00:18:30.930
is sending audio to the
cloud and getting audio back.

00:18:30.930 --> 00:18:33.990
It's not doing any
processing here.

00:18:33.990 --> 00:18:37.500
And this is also very portable
to most platforms, most

00:18:37.500 --> 00:18:40.500
operating systems, and
most programming languages,

00:18:40.500 --> 00:18:41.730
and completely open source.

00:18:47.160 --> 00:18:49.670
So what we have
with this is a way

00:18:49.670 --> 00:18:51.680
to talk to the cloud,
the Google cloud,

00:18:51.680 --> 00:18:54.560
called gRPC or Remote
Procedure Calls,

00:18:54.560 --> 00:18:58.210
and these remote procedure calls
run on nearly any platform.

00:18:58.210 --> 00:18:59.820
So you could easily port these--

00:18:59.820 --> 00:19:04.303
well, they're already on Linux,
Mac, Windows, Android, iPhone,

00:19:04.303 --> 00:19:08.690
already supporting languages
of C, Go, Python, Node.js, PHP,

00:19:08.690 --> 00:19:11.870
Ruby, and there's
an open tool chain

00:19:11.870 --> 00:19:16.160
that you can easily port
these to any other platform.

00:19:16.160 --> 00:19:19.450
The thing about it is, it's a
nice, robust protocol, error

00:19:19.450 --> 00:19:23.060
handling protocol, that also
allows bidirectional streaming.

00:19:23.060 --> 00:19:26.060
So what that means is, you could
be sending audio to the server

00:19:26.060 --> 00:19:28.250
while the server is
sending information back.

00:19:28.250 --> 00:19:29.976
And when the server
is responding,

00:19:29.976 --> 00:19:31.850
obviously you can continue
to send things up.

00:19:31.850 --> 00:19:35.360
So it's a
bidirectional protocol,

00:19:35.360 --> 00:19:37.160
and it's available
for any platform.

00:19:40.460 --> 00:19:42.500
So what I'd like to do
is demonstrate this.

00:19:48.890 --> 00:19:57.470
And in this case, I
actually have the voice kit

00:19:57.470 --> 00:20:02.450
that Chris was
talking about, which

00:20:02.450 --> 00:20:05.852
is all the pieces you
need to build this.

00:20:05.852 --> 00:20:07.310
Of course, if you
want to just have

00:20:07.310 --> 00:20:09.662
a speaker and a microphone,
you can do it that way.

00:20:09.662 --> 00:20:11.120
But let me show
you how this works.

00:20:11.120 --> 00:20:13.490
In this case, I'm using the
push to talk, as I said,

00:20:13.490 --> 00:20:17.570
because it's a simpler protocol
without the Hotword Library.

00:20:17.570 --> 00:20:20.150
And could we get
this on the screen?

00:20:25.270 --> 00:20:26.760
Can we get the device--

00:20:26.760 --> 00:20:28.060
there, thank you very much.

00:20:28.060 --> 00:20:28.560
OK.

00:20:33.570 --> 00:20:35.945
How do you say, "nice
to meet you," in Korean?

00:20:38.530 --> 00:20:39.731
GOOGLE: [SPEAKING KOREAN]

00:20:44.810 --> 00:20:48.518
GLEN SHIRES: What
time is it in Berlin?

00:20:48.518 --> 00:20:51.500
GOOGLE: The time in
Berlin, Germany is 6:50 PM.

00:20:57.020 --> 00:21:00.340
GLEN SHIRES: Set
the light to green.

00:21:00.340 --> 00:21:01.349
GOOGLE: OK.

00:21:01.349 --> 00:21:03.140
GLEN SHIRES: Doesn't
show up as well there.

00:21:03.140 --> 00:21:05.900
But maybe you can see here live
that the light turned green.

00:21:08.520 --> 00:21:09.730
Make it red.

00:21:09.730 --> 00:21:13.680
Oops, got to press the button.

00:21:13.680 --> 00:21:14.430
Make it red.

00:21:18.209 --> 00:21:19.500
GOOGLE: It's not raining there.

00:21:19.500 --> 00:21:20.906
It's mostly sunny.

00:21:20.906 --> 00:21:24.240
[LAUGHTER]

00:21:24.240 --> 00:21:26.970
GLEN SHIRES: Make it yellow.

00:21:26.970 --> 00:21:27.690
GOOGLE: OK.

00:21:27.690 --> 00:21:29.370
GLEN SHIRES: There we go.

00:21:29.370 --> 00:21:32.040
So this is demonstrating
the device actions,

00:21:32.040 --> 00:21:33.630
which we're
previewing right now,

00:21:33.630 --> 00:21:38.110
which allows you to
directly talk to the device.

00:21:38.110 --> 00:21:41.670
So rather than, let's say if
I'm using my Google Assistant

00:21:41.670 --> 00:21:43.200
on my phone, I
might have to say,

00:21:43.200 --> 00:21:47.422
tell my oven to set
the temperature to 425.

00:21:47.422 --> 00:21:49.380
If I actually go over to
my oven and then press

00:21:49.380 --> 00:21:51.760
the button on it, I don't
want to say, tell my oven.

00:21:51.760 --> 00:21:55.320
I just want to say, set
the temperature to 425.

00:21:55.320 --> 00:21:59.370
And so what we've done is when
the device with the microphone

00:21:59.370 --> 00:22:01.890
is listening, it
basically takes precedence

00:22:01.890 --> 00:22:03.720
over all other actions.

00:22:03.720 --> 00:22:05.700
So you can program
actions on Google

00:22:05.700 --> 00:22:08.130
to do your own custom
actions, and then

00:22:08.130 --> 00:22:11.490
when they're on your device,
you'd actually take precedence.

00:22:11.490 --> 00:22:15.360
So you don't have to preference
it with, tell my oven to,

00:22:15.360 --> 00:22:16.290
set the temperature.

00:22:16.290 --> 00:22:21.004
Just say, set the
temperature to 425.

00:22:21.004 --> 00:22:22.670
Let me show one more
that's kind of fun.

00:22:26.450 --> 00:22:27.260
Play trivia game.

00:22:30.190 --> 00:22:31.930
GOOGLE: You said
the magic words.

00:22:31.930 --> 00:22:33.970
Welcome to game show
mode, my friend.

00:22:33.970 --> 00:22:38.919
[MUSIC PLAYING]

00:22:38.919 --> 00:22:41.210
GLEN SHIRES: So you can see,
we play all sorts of audio

00:22:41.210 --> 00:22:41.709
through it.

00:22:41.709 --> 00:22:44.870
It's not just our favorite
lady, but it's not just

00:22:44.870 --> 00:22:47.810
the Assistant, but
it's whatever you

00:22:47.810 --> 00:22:49.842
want to do when you're
making your own actions.

00:22:49.842 --> 00:22:52.300
You can create actions that
have all sorts of sound effects

00:22:52.300 --> 00:22:53.734
and mix and match those.

00:22:53.734 --> 00:22:55.400
GOOGLE: I'm the host
of this silly show.

00:22:55.400 --> 00:22:56.270
How many contestants do we have?

00:22:56.270 --> 00:22:57.561
GLEN SHIRES: So I'll stop that.

00:23:04.600 --> 00:23:05.600
Actually, you know what?

00:23:05.600 --> 00:23:07.690
I keep going back and
forth and I apologize.

00:23:07.690 --> 00:23:10.130
There was one more thing I
wanted to point out on this.

00:23:10.130 --> 00:23:11.120
GOOGLE: Sounds great.

00:23:11.120 --> 00:23:12.620
Let's play five rounds.

00:23:12.620 --> 00:23:14.030
Let's hear from you now.

00:23:14.030 --> 00:23:15.950
I have some important
questions to ask.

00:23:15.950 --> 00:23:19.580
Contestant one, can
you say, smarty pants?

00:23:19.580 --> 00:23:21.730
GLEN SHIRES: So what
I wanted to point out

00:23:21.730 --> 00:23:23.570
is there's two microphones
here, and I'm not

00:23:23.570 --> 00:23:24.890
going to play the trivia game.

00:23:24.890 --> 00:23:26.990
But I wanted to
point out the fact

00:23:26.990 --> 00:23:31.190
that we work very well with
one or two microphones.

00:23:31.190 --> 00:23:37.290
And I'll get to
that in a moment.

00:23:37.290 --> 00:23:42.200
So the gRPC API is
a very flexible API

00:23:42.200 --> 00:23:45.440
that lets you have
a lot more control,

00:23:45.440 --> 00:23:48.350
and I wanted to run
through how the API worked.

00:23:48.350 --> 00:23:52.970
First of all, if you want
to connect to the API,

00:23:52.970 --> 00:23:56.660
you just create a connection
with a couple simple commands,

00:23:56.660 --> 00:23:58.850
make a channel, gives
you a stub and then

00:23:58.850 --> 00:24:00.080
you can call a service.

00:24:00.080 --> 00:24:01.777
We have a service
we call Converse,

00:24:01.777 --> 00:24:03.860
so we can converse back
and forth with the server.

00:24:08.330 --> 00:24:11.030
Once you've set up a
connection to the server, what

00:24:11.030 --> 00:24:13.580
you want to do is
configure exactly how

00:24:13.580 --> 00:24:15.080
you want to send
audio to the server

00:24:15.080 --> 00:24:16.610
and how you want to receive it.

00:24:16.610 --> 00:24:19.290
In this case, we're
sending audio as linear 16,

00:24:19.290 --> 00:24:21.520
which is plain old PCM.

00:24:21.520 --> 00:24:23.660
Doesn't have to be compressed.

00:24:23.660 --> 00:24:26.210
We do allow FLAC
compression, which

00:24:26.210 --> 00:24:28.330
is a lossless compression,
which cuts down

00:24:28.330 --> 00:24:29.960
the bandwidth by about half.

00:24:29.960 --> 00:24:35.570
We're going to send it with a
sample rate of 16,000 Hertz,

00:24:35.570 --> 00:24:38.450
and then we're going to tell
the server what we want back.

00:24:38.450 --> 00:24:41.510
And in this case, we're going
to get OPUS_IN_OGG, which

00:24:41.510 --> 00:24:45.050
is a nice, tight
compression engine,

00:24:45.050 --> 00:24:48.530
and we'll say I have
a sample rate of 22k.

00:24:48.530 --> 00:24:51.650
So that gives us some
better quality audio.

00:24:51.650 --> 00:24:54.680
So we basically set
up a configuration,

00:24:54.680 --> 00:24:57.320
and then we start sending
things to the server.

00:24:57.320 --> 00:24:59.660
The first thing we send
is that configuration,

00:24:59.660 --> 00:25:00.950
followed by audio.

00:25:00.950 --> 00:25:02.840
So we're sending
audio in chunks.

00:25:02.840 --> 00:25:06.040
Were streaming
audio to the server.

00:25:06.040 --> 00:25:08.540
And then the server will tell
us when it's got enough audio.

00:25:08.540 --> 00:25:11.510
When it has heard
the end of the query.

00:25:14.400 --> 00:25:18.271
And then we can be receiving
the audio and process.

00:25:18.271 --> 00:25:19.770
So when we receive
end of utterance,

00:25:19.770 --> 00:25:22.974
we're actually going
to stop sending audio.

00:25:22.974 --> 00:25:25.140
And then we're going to
gather the audio coming back

00:25:25.140 --> 00:25:27.960
from the server
and play that back.

00:25:27.960 --> 00:25:31.590
It also has a
microphone mode that

00:25:31.590 --> 00:25:34.830
allows us to continue to talk.

00:25:34.830 --> 00:25:38.970
So in other words, as you're
having something like a trivia

00:25:38.970 --> 00:25:40.899
game, as you're
playing, you don't

00:25:40.899 --> 00:25:42.690
have to keep pressing
the button each time.

00:25:42.690 --> 00:25:45.622
When it asks you a question,
it keeps the microphone open

00:25:45.622 --> 00:25:46.455
so you can continue.

00:25:52.410 --> 00:25:55.800
Finally, I wanted to talk
about the two microphones

00:25:55.800 --> 00:25:58.740
and the neural beamforming.

00:25:58.740 --> 00:26:01.590
One thing that we do to keep
costs down in the client

00:26:01.590 --> 00:26:04.820
is make it work very well with
either one or two microphones.

00:26:04.820 --> 00:26:06.930
And with two
microphones, we do what

00:26:06.930 --> 00:26:09.570
we call neural
beamforming in the cloud.

00:26:09.570 --> 00:26:12.750
So that the cloud's optimized
for farfield recognition,

00:26:12.750 --> 00:26:15.930
in other words, you can
be several feet away.

00:26:15.930 --> 00:26:17.790
And it's very noise robust.

00:26:17.790 --> 00:26:20.860
And we use machine
learning to process that.

00:26:20.860 --> 00:26:22.920
So in other words, very
common in a household,

00:26:22.920 --> 00:26:24.680
for example, that
you may be speaking,

00:26:24.680 --> 00:26:27.710
there's a television, a
radio, other kids, dogs,

00:26:27.710 --> 00:26:29.740
dishwashers all running
at the same time.

00:26:29.740 --> 00:26:32.410
So there's a lot of noise.

00:26:32.410 --> 00:26:35.149
But what we do is, on the
server we do all the processing

00:26:35.149 --> 00:26:35.940
to filter that out.

00:26:35.940 --> 00:26:39.240
So you don't need to have any
additional client processing.

00:26:39.240 --> 00:26:40.830
Just send the two
channels directly up

00:26:40.830 --> 00:26:45.067
to the server and we do the
neural beamforming for you.

00:26:45.067 --> 00:26:46.650
So what this does
is it keeps the cost

00:26:46.650 --> 00:26:47.774
to the client to a minimum.

00:26:54.400 --> 00:26:58.900
So one thing I like about this
voice kit, and just the fact

00:26:58.900 --> 00:27:01.630
that we have the SDK and
made it so available,

00:27:01.630 --> 00:27:03.130
is that a lot of
people have started

00:27:03.130 --> 00:27:07.000
using it in just the three
weeks that it's been available.

00:27:07.000 --> 00:27:08.890
A friend of mine
actually told me

00:27:08.890 --> 00:27:11.175
that his daughter
came to him and said

00:27:11.175 --> 00:27:13.300
she wanted to be an engineer
and she wanted to make

00:27:13.300 --> 00:27:16.210
a kitty that she can talk to.

00:27:16.210 --> 00:27:20.740
And the amazing thing is,
she was able to do that.

00:27:20.740 --> 00:27:23.260
They actually got together one
evening and built a voice kit

00:27:23.260 --> 00:27:27.010
together, put together
the Google Assistant,

00:27:27.010 --> 00:27:31.430
and now she's actually got a
kitty that she can talk to.

00:27:31.430 --> 00:27:32.830
Which, when I sit
back and think,

00:27:32.830 --> 00:27:35.320
when I was a kid
there was no way,

00:27:35.320 --> 00:27:38.710
it was just a dream that I could
build a robot I could talk to

00:27:38.710 --> 00:27:40.960
and it would actually
understand what I'm saying

00:27:40.960 --> 00:27:43.570
and actually talk back,
it'd be intelligent.

00:27:43.570 --> 00:27:46.510
Let alone the fact that I could
ask it virtually any question

00:27:46.510 --> 00:27:49.990
in the world and actually
get a response, because it

00:27:49.990 --> 00:27:51.820
would know the answers.

00:27:51.820 --> 00:27:54.700
So it's really
inspiring to me that we

00:27:54.700 --> 00:27:57.520
can inspire young
engineers, and I

00:27:57.520 --> 00:27:59.860
hope that we're also
inspiring you to create

00:27:59.860 --> 00:28:02.030
wonderful new devices.

00:28:02.030 --> 00:28:03.750
Let me turn it
back over to Chris.

00:28:03.750 --> 00:28:04.818
Thanks.

00:28:04.818 --> 00:28:07.722
[APPLAUSE]

00:28:10.162 --> 00:28:11.370
CHRIS RAMSDALE: Thanks, Glen.

00:28:11.370 --> 00:28:13.207
Those were some
awesome demos and words

00:28:13.207 --> 00:28:14.290
of inspiration at the end.

00:28:14.290 --> 00:28:15.210
I like that.

00:28:15.210 --> 00:28:17.670
So to wrap up here, when
we set out on this talk,

00:28:17.670 --> 00:28:20.040
we wanted to create one
ubiquitous Google Assistant

00:28:20.040 --> 00:28:22.020
experience that helped
you with whatever

00:28:22.020 --> 00:28:25.080
you needed, wherever you need
it, whenever you needed it.

00:28:25.080 --> 00:28:28.140
We've got Actions on Google to
handle the whatever, as well

00:28:28.140 --> 00:28:30.690
as the Google Assistant,
but the Actions on Google

00:28:30.690 --> 00:28:33.240
extend that Assistant
into other services

00:28:33.240 --> 00:28:34.570
that you utilize in your life.

00:28:34.570 --> 00:28:36.000
So we've got that
whatever cover.

00:28:36.000 --> 00:28:38.350
With the addition of
the Assistant SDK,

00:28:38.350 --> 00:28:39.952
we can handle the
whenever, wherever,

00:28:39.952 --> 00:28:41.910
because we extend out
from just the Google Home

00:28:41.910 --> 00:28:46.080
device or your Pixel or your
Android phone, to other devices

00:28:46.080 --> 00:28:48.750
that you will have in your life.

00:28:48.750 --> 00:28:51.692
And technologies like the Home
Graph and Smarthome agents

00:28:51.692 --> 00:28:53.150
tie it all together
so you can have

00:28:53.150 --> 00:28:55.650
a natural conversation with
those devices in your life

00:28:55.650 --> 00:28:57.520
and feel very comfortable.

00:28:57.520 --> 00:28:59.580
So I wanted to say thanks
for taking your time

00:28:59.580 --> 00:29:01.660
to come out and talk with us.

00:29:01.660 --> 00:29:04.889
We've got a couple next
steps if you're interested.

00:29:04.889 --> 00:29:06.430
So first of all, I
want to reiterate,

00:29:06.430 --> 00:29:08.790
we've got an Actions on
Google Developer Challenge.

00:29:08.790 --> 00:29:13.350
If you sign up at
g.co/actionschallenge you can

00:29:13.350 --> 00:29:15.810
register to win a ticket
to next year's I/O,

00:29:15.810 --> 00:29:19.090
as well as over 20
more other items.

00:29:19.090 --> 00:29:22.650
And beyond that, we've
got demos going on

00:29:22.650 --> 00:29:24.739
and Sandbox B. I'll be there.

00:29:24.739 --> 00:29:25.530
Glen will be there.

00:29:25.530 --> 00:29:27.821
There's other engineers,
product managers and developer

00:29:27.821 --> 00:29:28.740
[INAUDIBLE] folks.

00:29:28.740 --> 00:29:30.060
So come check it out.

00:29:30.060 --> 00:29:32.582
We've got a codelab for
some hands-on hacking.

00:29:32.582 --> 00:29:34.290
We've got the
Assistant-enabled Mocktails

00:29:34.290 --> 00:29:36.622
Mixer which I'll be demoing
throughout the afternoon.

00:29:36.622 --> 00:29:38.580
And then we've got the
home automation session,

00:29:38.580 --> 00:29:41.310
which goes deeper into that
Home Graph and Smarthome

00:29:41.310 --> 00:29:45.060
agents at 4:30 with our
colleagues Mark and David.

00:29:45.060 --> 00:29:47.517
And then obviously,
we have documentation,

00:29:47.517 --> 00:29:49.600
Getting Started guides,
and technology to download

00:29:49.600 --> 00:29:53.280
at developers.googl
e.com/assistant/sdk.

00:29:53.280 --> 00:29:53.850
So cool.

00:29:53.850 --> 00:29:54.790
Thank you so much.

00:29:54.790 --> 00:29:55.650
And we'll take some
questions because I

00:29:55.650 --> 00:29:57.191
think we've got
about 10 minutes left

00:29:57.191 --> 00:29:58.980
if you want to come up and ask.

00:29:58.980 --> 00:29:59.840
Thanks again.

00:29:59.840 --> 00:30:01.720
[APPLAUSE]

00:30:01.720 --> 00:30:06.390
[MUSIC PLAYING]

