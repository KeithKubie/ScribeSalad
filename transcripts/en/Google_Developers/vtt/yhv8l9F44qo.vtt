WEBVTT
Kind: captions
Language: en

00:00:08.260 --> 00:00:09.260
&gt;&gt;Ficus Kirkpatrick: Hi.

00:00:09.260 --> 00:00:10.350
I'm Ficus Kirkpatrick.

00:00:10.350 --> 00:00:12.270
I'm an engineer on the Android team.

00:00:12.270 --> 00:00:13.910
I work on the Play Store.

00:00:13.910 --> 00:00:17.890
And I'm here to talk to you today about something
we made that makes it really easy to develop

00:00:17.890 --> 00:00:21.099
super fast networked applications for Android.

00:00:21.099 --> 00:00:25.900
[ Applause ]
&gt;&gt;Ficus Kirkpatrick: All right.

00:00:25.900 --> 00:00:27.830
Very good!

00:00:27.830 --> 00:00:31.120
It's called Volley.

00:00:31.120 --> 00:00:32.940
So what is Volley?

00:00:32.940 --> 00:00:35.250
Well, it's a networking library.

00:00:35.250 --> 00:00:41.580
So when I say "Volley," you might be thinking
of something like this, you know, a client

00:00:41.580 --> 00:00:44.330
sends a request to a server over the net.

00:00:44.330 --> 00:00:45.989
It comes back.

00:00:45.989 --> 00:00:47.879
Metaphor complete.

00:00:47.879 --> 00:00:50.150
Message received.

00:00:50.150 --> 00:00:55.120
But when I named it, I was really thinking
of something more like this.

00:00:55.120 --> 00:00:58.280
Mobile app design is getting better and better.

00:00:58.280 --> 00:01:01.780
But also more and more demanding for engineers.

00:01:01.780 --> 00:01:07.930
A lot of current designs are really beautiful,
with a lot of rich metadata and tons of images.

00:01:07.930 --> 00:01:14.180
But these things requires tons of network
requests to get all that data and images.

00:01:14.180 --> 00:01:19.060
And there's a tremendous opportunity to make
our apps faster by running those requests

00:01:19.060 --> 00:01:21.030
in parallel.

00:01:21.030 --> 00:01:26.220
So you probably don't want to do quite as
many requests in parallel as shown up here.

00:01:26.220 --> 00:01:29.830
I think if we stick to the metaphor, that
looks kind of like a denial of service attack.

00:01:29.830 --> 00:01:32.180
[ Laughter ]
&gt;&gt;Ficus Kirkpatrick: But a volley does make

00:01:32.180 --> 00:01:37.420
it very easy for you to run your request concurrently
without really having to think about threading

00:01:37.420 --> 00:01:39.240
or networking yourself.

00:01:39.240 --> 00:01:44.320
Sorry, threading or synchronization yourself.

00:01:44.320 --> 00:01:49.100
The library comes with most things you need
right out of the box, things like accessing

00:01:49.100 --> 00:01:54.030
JSON APIs or loading images are trivial to
do with Volley.

00:01:54.030 --> 00:01:57.990
But it's easy to grow with your needs as well.

00:01:57.990 --> 00:01:59.630
There's a lot of customization options.

00:01:59.630 --> 00:02:04.310
You can do your own custom retry and backoff
algorithms.

00:02:04.310 --> 00:02:09.310
You can customize request priority and ordering,
and a lot more.

00:02:09.310 --> 00:02:15.870
It also includes a very powerful request tracing
system that we've found invaluable in debugging

00:02:15.870 --> 00:02:20.549
and profiling our network activity on the
Play Store.

00:02:20.549 --> 00:02:23.120
Okay.

00:02:23.120 --> 00:02:26.719
So why do we even need a networking library
at all?

00:02:26.719 --> 00:02:30.120
Android already has Apache HTTP client.

00:02:30.120 --> 00:02:32.109
It already has HTTP URL connection.

00:02:32.109 --> 00:02:33.989
True, it sure does.

00:02:33.989 --> 00:02:39.060
People have made tons of great apps with them.

00:02:39.060 --> 00:02:44.939
So here are four apps that I use all the time
on my phone, Foursquare, Twitter, YouTube,

00:02:44.939 --> 00:02:45.939
and News and Weather.

00:02:45.939 --> 00:02:47.359
These apps are great.

00:02:47.359 --> 00:02:48.549
I love them.

00:02:48.549 --> 00:02:51.549
And they have a lot of things in common.

00:02:51.549 --> 00:02:57.629
They display paginated lists of items, typically
with a thumbnail for each item.

00:02:57.629 --> 00:03:02.239
You can click on something and view an item
with more metadata or more images.

00:03:02.239 --> 00:03:07.260
And there's typically some kind of write operation
or post request type thing, like posting a

00:03:07.260 --> 00:03:10.969
tweet or writing a restaurant review or something
like that.

00:03:10.969 --> 00:03:16.611
And all of these apps had to reinvent several
wheels to do what are, at heart, basically

00:03:16.611 --> 00:03:19.379
the same tasks.

00:03:19.379 --> 00:03:24.209
Doing response caching or things are fast,
getting retry right, executing requests in

00:03:24.209 --> 00:03:25.239
parallel.

00:03:25.239 --> 00:03:28.120
Everybody pretty much rolls their own.

00:03:28.120 --> 00:03:32.790
So what we wanted to do with Volley was both
provide an interface where you can step up

00:03:32.790 --> 00:03:38.260
a little bit and think a little less about
wire protocols and network transports and

00:03:38.260 --> 00:03:44.189
more about logical operations as well as just
wrap up a lot of the things that we've learned

00:03:44.189 --> 00:03:50.999
in developing production-quality apps at Google
over the last few years.

00:03:50.999 --> 00:03:56.969
So Volley was designed for exactly the kinds
of needs that those applications have.

00:03:56.969 --> 00:04:04.220
Relatively small, RPC-like operations, fetching
some metadata or getting a profile picture,

00:04:04.220 --> 00:04:07.260
and put them in the view hierarchy.

00:04:07.260 --> 00:04:12.540
It's also perfectly fine for doing those same
kinds of operations in the background.

00:04:12.540 --> 00:04:18.750
But it really excels at the intersection of
UI and network.

00:04:18.750 --> 00:04:21.109
It's not for everything, though.

00:04:21.109 --> 00:04:23.480
Responses are delivered whole in memory.

00:04:23.480 --> 00:04:29.540
So that makes for an API that's really easy
to use but not a good one for streaming operations

00:04:29.540 --> 00:04:31.960
like downloading a video or an MP3.

00:04:31.960 --> 00:04:34.450
But that's okay.

00:04:34.450 --> 00:04:36.350
You don't have to use it for everything.

00:04:36.350 --> 00:04:41.010
There are several apps at Google that use
Volley for their RPCs and use another system,

00:04:41.010 --> 00:04:49.840
like Download Manager or whatever, for long-lived,
large file download operations.

00:04:49.840 --> 00:04:53.190
Okay.

00:04:53.190 --> 00:04:57.810
So let's take a simplified example of that
kind of common pattern that I talked about.

00:04:57.810 --> 00:05:06.190
I built a sample app that shows a title and
a description loaded page by page from a server,

00:05:06.190 --> 00:05:11.820
with a nice-looking thumbnail image for each
item.

00:05:11.820 --> 00:05:14.040
Okay.

00:05:14.040 --> 00:05:19.630
So we have a server that speaks a relatively
simple JSON protocol.

00:05:19.630 --> 00:05:23.250
This is, by the way, going to be the basis
of my microblogging startup.

00:05:23.250 --> 00:05:26.740
So if any of you are angel investors, please
come see me afterward.

00:05:26.740 --> 00:05:29.780
[ Laughter ]
&gt;&gt;Ficus Kirkpatrick: The protocol is really

00:05:29.780 --> 00:05:30.780
simple.

00:05:30.780 --> 00:05:36.670
We've got -- the outer response is just a
list of item JSON objects with an optional

00:05:36.670 --> 00:05:40.390
token to retrieve the next page.

00:05:40.390 --> 00:05:46.740
And each item is simply a title, a description,
and an image URL all as strings.

00:05:46.740 --> 00:05:50.930
Pretty straightforward.

00:05:50.930 --> 00:05:54.510
On the client side, again, we have a pretty
typical application architecture.

00:05:54.510 --> 00:05:55.520
We've got an activity.

00:05:55.520 --> 00:05:57.820
It holds an adapter and a ListView.

00:05:57.820 --> 00:06:03.370
The adapter loads data from the network from
the API server and manufactures views for

00:06:03.370 --> 00:06:07.030
the ListView upon request.

00:06:07.030 --> 00:06:09.430
Okay.

00:06:09.430 --> 00:06:13.650
So here we are in get view in our adapter
in a typical implementation.

00:06:13.650 --> 00:06:18.670
The standard trick here is to use the position
passed in to GetView as a hit for when you

00:06:18.670 --> 00:06:21.570
should download the next page.

00:06:21.570 --> 00:06:26.810
For example, if you have ten items in your
page, when the ListView asks you for the eighth

00:06:26.810 --> 00:06:33.120
thing, you go ahead and call load more data
to fetch the next page of data.

00:06:33.120 --> 00:06:35.680
Okay.

00:06:35.680 --> 00:06:40.850
Now, how is load more data actually implemented?

00:06:40.850 --> 00:06:46.900
The usual approach is to use an async task
or something like that.

00:06:46.900 --> 00:06:52.400
So here in do in background, we open an HTTP
URL connection.

00:06:52.400 --> 00:06:55.050
We get the input stream for the response data.

00:06:55.050 --> 00:06:57.870
We make a byte array output stream to copy
it into.

00:06:57.870 --> 00:07:02.210
We use this magical function that I've written
100 times in my life to copy it from the input

00:07:02.210 --> 00:07:03.920
stream to the output stream.

00:07:03.920 --> 00:07:08.830
And then we pass it to the JSON object constructor
for parsing and return it back.

00:07:08.830 --> 00:07:11.620
So pretty straightforward conceptually.

00:07:11.620 --> 00:07:15.770
One thing to note here is that there's actually
a ton of boilerplate crap I had to cut out

00:07:15.770 --> 00:07:17.900
in order to make this fit on one slide.

00:07:17.900 --> 00:07:20.430
So you don't see all the extra async task
stuff.

00:07:20.430 --> 00:07:25.250
And I think more annoyingly, you don't see
all of the try-catch blocks here.

00:07:25.250 --> 00:07:29.870
You have to try-catch for I/O exception if
there's a network problem or JSON exception,

00:07:29.870 --> 00:07:32.680
if there's a parsing error.

00:07:32.680 --> 00:07:34.740
And then you have to close your input stream.

00:07:34.740 --> 00:07:37.500
And then closing your input stream can throw
two.

00:07:37.500 --> 00:07:40.490
So you need to try-catch there and have a
finally block.

00:07:40.490 --> 00:07:44.520
And this whole thing is probably twice the
size or more if you were to see it in something

00:07:44.520 --> 00:07:47.530
that would compile.

00:07:47.530 --> 00:07:54.770
Finally, we land back in onPostExecute on
the main thread with our parse JSON object.

00:07:54.770 --> 00:08:00.560
We pluck out the individual items from that
root JSON object, append them to the list

00:08:00.560 --> 00:08:05.990
that backs our adapter, call notify data set
changed, and then let the ListView call us

00:08:05.990 --> 00:08:09.600
back to actually make the views.

00:08:09.600 --> 00:08:12.080
Okay.

00:08:12.080 --> 00:08:16.370
Now we're back in GetView with some data.

00:08:16.370 --> 00:08:21.370
So now we can populate our two text views
with the title and description strings.

00:08:21.370 --> 00:08:24.610
And we now have the image URL, so we can kick
that off for loading.

00:08:24.610 --> 00:08:33.729
Again, if you're familiar with, this you typically
use an async task or something like that.

00:08:33.729 --> 00:08:39.370
So let's look at a naive implementation of
an image-loading async task.

00:08:39.370 --> 00:08:44.870
Here in the constructor, we squirrel away
the image view that we want to populate from

00:08:44.870 --> 00:08:47.570
the image at the given URL.

00:08:47.570 --> 00:08:50.710
And then in background, it's pretty straightforward
from there.

00:08:50.710 --> 00:08:55.260
You open the HTTP URL connection, you get
the response stream and pass it off bit map

00:08:55.260 --> 00:08:56.830
factory for image decoding.

00:08:56.830 --> 00:09:02.570
Again, I had to cut out all of the try-catch,
you know, muckety-muck boilerplate stuff.

00:09:02.570 --> 00:09:05.550
It's all pretty straightforward so far.

00:09:05.550 --> 00:09:07.380
But tedious.

00:09:07.380 --> 00:09:13.570
Finally, again, we get back onto the main
thread in onPostExecute.

00:09:13.570 --> 00:09:19.840
And we just simply set image bit map on our
image view that we saved in the constructor.

00:09:19.840 --> 00:09:22.710
Okay.

00:09:22.710 --> 00:09:26.800
So there are actually a whole bunch of problems
with the code I just showed you.

00:09:26.800 --> 00:09:31.710
Things ranging from outright bugs to things
that are just way too inefficient to ship.

00:09:31.710 --> 00:09:37.180
So I want to talk about some of the higher-level
issues and problems and then discuss Volley's

00:09:37.180 --> 00:09:39.730
approach to solving them.

00:09:39.730 --> 00:09:41.400
Okay.

00:09:41.400 --> 00:09:48.230
First, the code as written, all network requests
execute in serial, so one after the other.

00:09:48.230 --> 00:09:52.110
And this is because you called asynctask.execute,
and I'm blaming you for calling it even though

00:09:52.110 --> 00:09:53.490
I wrote the code.

00:09:53.490 --> 00:09:58.010
And you didn't call async task on execute
or executer.

00:09:58.010 --> 00:10:01.650
Or you didn't pass a thread sync executer
to async task.

00:10:01.650 --> 00:10:05.550
Or maybe you didn't even know you had to do
that.

00:10:05.550 --> 00:10:11.620
It also means that in order to fetch the next
page of data, if the user is scrolling down,

00:10:11.620 --> 00:10:14.510
you have to wait for all the image requests
to complete, because things are scheduled

00:10:14.510 --> 00:10:18.040
strictly first in, first out.

00:10:18.040 --> 00:10:21.880
Volley automatically schedules your network
requests across a thread pool.

00:10:21.880 --> 00:10:25.210
You can choose the size of the pool or just
use the default.

00:10:25.210 --> 00:10:28.670
We had the best results with four threads
in our testing in the Play Store.

00:10:28.670 --> 00:10:31.550
So that's the default we chose.

00:10:31.550 --> 00:10:34.180
Volley also supports request prioritization.

00:10:34.180 --> 00:10:40.270
So you can set your main metadata at high
or medium priority, set your images to low,

00:10:40.270 --> 00:10:44.200
and then if you even -- if you have even a
single thread, you never have to wait for

00:10:44.200 --> 00:10:48.550
more than one image request to complete before
you can fetch that next page of data and let

00:10:48.550 --> 00:10:54.450
the user continue scrolling down.

00:10:54.450 --> 00:10:58.570
If you rotate the screen, your activity gets
destroyed, of course.

00:10:58.570 --> 00:11:01.550
It gets recreated, and you start over from
scratch.

00:11:01.550 --> 00:11:06.140
So that -- in this case, that means reloading
absolutely everything from the network.

00:11:06.140 --> 00:11:07.640
So this isn't a big deal; right?

00:11:07.640 --> 00:11:09.130
You write your own cache.

00:11:09.130 --> 00:11:13.230
You -- maybe you put your images in a hash
map or an LRU cache.

00:11:13.230 --> 00:11:17.330
And, of course, you still have to do that,
which is tedious.

00:11:17.330 --> 00:11:21.970
And it also doesn't help you for the next
time the user launches your app and you need

00:11:21.970 --> 00:11:25.550
to reload everything again because those caches
are only going to live for the lifetime of

00:11:25.550 --> 00:11:28.250
your process.

00:11:28.250 --> 00:11:33.050
Volley provides transparent disk and memory
caching of responses out of the box.

00:11:33.050 --> 00:11:36.050
So what does transparent caching mean?

00:11:36.050 --> 00:11:40.020
It just means the caller doesn't have to know
about the existence of the cache.

00:11:40.020 --> 00:11:47.730
When there's a cache hit, it simply behaves
like a super fast network response.

00:11:47.730 --> 00:11:52.030
You can provide your own cache implementation,
or we have one that you can use in the toolbox

00:11:52.030 --> 00:11:53.440
right out of the box.

00:11:53.440 --> 00:11:54.440
And it's very fast.

00:11:54.440 --> 00:12:01.430
We typically see response times of a few milliseconds
for a typically, you know, 10 to 50K advertised

00:12:01.430 --> 00:12:04.290
JPEG image.

00:12:04.290 --> 00:12:08.240
Volley also provides some advanced tools particular
to image loading.

00:12:08.240 --> 00:12:13.130
I'll talk about that in a minute.

00:12:13.130 --> 00:12:17.190
Those of you who have written an app like
this probably saw the bug in my load image

00:12:17.190 --> 00:12:21.390
async task right off the bat.

00:12:21.390 --> 00:12:25.990
We've got a bunch of async tasks in flight
and they're all loading the images.

00:12:25.990 --> 00:12:29.690
And maybe the user is scrolling around like
crazy and the views are getting recycled in

00:12:29.690 --> 00:12:30.690
the ListView.

00:12:30.690 --> 00:12:37.029
So by the time the async task actually completes,
on post execute runs and we set the bit map

00:12:37.029 --> 00:12:40.320
in an image view that doesn't really belong
to the async task anymore.

00:12:40.320 --> 00:12:41.320
Okay.

00:12:41.320 --> 00:12:42.320
So what do you do here?

00:12:42.320 --> 00:12:47.020
You have a view holder, and you maybe keep
the URL in it and make sure that it matches.

00:12:47.020 --> 00:12:51.390
But then you're letting a request complete
which it doesn't matter anymore.

00:12:51.390 --> 00:12:55.080
You're just going to throw the results away,
which makes things slow and it's wasteful.

00:12:55.080 --> 00:12:59.760
So then maybe you keep track of your async
tasks and cancel them when you get recycled.

00:12:59.760 --> 00:13:02.630
Again, more work.

00:13:02.630 --> 00:13:06.940
Volley provides a really powerful request
cancellation API where you can easily cancel

00:13:06.940 --> 00:13:12.320
a single request or you can set blocks or
scopes of requests to cancel.

00:13:12.320 --> 00:13:15.730
Or you can just use the network image view
that I'm going to talk about in a second from

00:13:15.730 --> 00:13:20.020
the toolbox, which does everything for you.

00:13:20.020 --> 00:13:22.550
Okay.

00:13:22.550 --> 00:13:24.610
One last problem.

00:13:24.610 --> 00:13:28.920
Until Gingerbread, HTTP URL connection was
buggy and flaky.

00:13:28.920 --> 00:13:34.030
So for those of you who would try to run this
simple code on Froyo or before, you might

00:13:34.030 --> 00:13:36.170
run into some problems here.

00:13:36.170 --> 00:13:42.920
So you could use Apache HTTP client, but that's
also buggy and no longer supported.

00:13:42.920 --> 00:13:45.250
So that's okay.

00:13:45.250 --> 00:13:48.640
Volley abstracts away the underlying network
transport.

00:13:48.640 --> 00:13:55.430
So, in fact, if you use our standard setup
helper methods, on Froyo, you'll automatically

00:13:55.430 --> 00:13:59.480
get an Apache stack, which works best there,
and on Gingerbread and above, you automatically

00:13:59.480 --> 00:14:03.300
get an HTTP connection stack.

00:14:03.300 --> 00:14:07.990
One really nice thing about this approach
is that it doesn't just solve the problem

00:14:07.990 --> 00:14:15.330
of this kind of varying behavior of these
HTTP stacks, but it also creates an opportunity.

00:14:15.330 --> 00:14:19.160
So say you want to port to Square's new OkHttp
library.

00:14:19.160 --> 00:14:20.160
&gt;&gt;&gt; Whoo!

00:14:20.160 --> 00:14:24.250
&gt;&gt;Ficus Kirkpatrick: Yeah, I'm a fan.

00:14:24.250 --> 00:14:27.880
You can just replace that in one place in
your app without having to go do a complete

00:14:27.880 --> 00:14:28.880
refactor of your code.

00:14:28.880 --> 00:14:32.170
It's, like, a much more targeted place.

00:14:32.170 --> 00:14:34.020
Okay.

00:14:34.020 --> 00:14:37.680
So let's look at how we'd implement this map
uses Volley.

00:14:37.680 --> 00:14:41.900
There are two main things you interact with
in Volley, two main classes: Request queue

00:14:41.900 --> 00:14:43.470
and request.

00:14:43.470 --> 00:14:48.440
Request queue is the interface you use for
dispatching requests to the network.

00:14:48.440 --> 00:14:53.530
You can make a request queue on demand if
you want, but typically, you'll instead create

00:14:53.530 --> 00:14:58.020
it early on, at startup time, and keep it
around and use it as a Singleton.

00:14:58.020 --> 00:14:59.690
Here we also make an image loader.

00:14:59.690 --> 00:15:02.410
And I'll talk about that in a little bit.

00:15:02.410 --> 00:15:04.029
Okay.

00:15:04.029 --> 00:15:07.240
Here's something dense.

00:15:07.240 --> 00:15:11.770
Here in the Volley version of load more data,
we make a JSON object request, which is one

00:15:11.770 --> 00:15:16.110
of the standard requests that comes stock
in the Volley toolbox.

00:15:16.110 --> 00:15:18.290
And we add it to the queue.

00:15:18.290 --> 00:15:19.620
We provide it with a listener.

00:15:19.620 --> 00:15:25.050
And a listener is the standard callback interface
you use for receiving your responses.

00:15:25.050 --> 00:15:33.660
And the response listener here looks a whole
lot like the async task version in onPostExecute.

00:15:33.660 --> 00:15:38.700
We just parse out the JSON, append the items
to our backing list, and call notify data

00:15:38.700 --> 00:15:40.529
set changed.

00:15:40.529 --> 00:15:43.779
So there are two bigger things I want to point
out here.

00:15:43.779 --> 00:15:44.779
One is, this is it.

00:15:44.779 --> 00:15:45.779
This is the whole thing.

00:15:45.779 --> 00:15:48.019
I went on and on about the boilerplate before.

00:15:48.019 --> 00:15:49.690
The boilerplate is gone.

00:15:49.690 --> 00:15:54.070
This is the whole thing, end to end.

00:15:54.070 --> 00:15:59.060
Second, the fact that this response listener
looks a lot like onpostexecute in the async

00:15:59.060 --> 00:16:01.860
task version means it's easy to port your
app to Volley.

00:16:01.860 --> 00:16:05.610
So you don't have to boil the ocean and rewrite
your app if you want to start taking advantage

00:16:05.610 --> 00:16:08.990
of this.

00:16:08.990 --> 00:16:12.209
Okay.

00:16:12.209 --> 00:16:14.000
Getting the image is even easier.

00:16:14.000 --> 00:16:18.399
We just stowaway the image request in our
view holder and cancel it when we're getting

00:16:18.399 --> 00:16:19.399
recycled.

00:16:19.399 --> 00:16:24.020
And image loader, again from the Volley toolbox,
handles the rest.

00:16:24.020 --> 00:16:26.769
It provides the memory caching for you.

00:16:26.769 --> 00:16:32.050
It -- you can even pass in drawables for loading
or error states.

00:16:32.050 --> 00:16:40.160
And image loader will take it away from there
for you.

00:16:40.160 --> 00:16:45.340
But maybe you're a programmer after my own
heart, which is to say, super lazy.

00:16:45.340 --> 00:16:49.080
You can just use network image view in the
Volley toolbox.

00:16:49.080 --> 00:16:50.360
It's a subclass of image view.

00:16:50.360 --> 00:16:54.899
You can simply replace your usages of image
view in your layouts with this.

00:16:54.899 --> 00:16:57.700
You call set image URL, and you're done.

00:16:57.700 --> 00:17:01.090
When it gets detached from the view hierarchy,
the request is automatically cancelled if

00:17:01.090 --> 00:17:03.040
it's still in flight.

00:17:03.040 --> 00:17:06.250
That's it.

00:17:06.250 --> 00:17:11.370
One -- one subtle but I think pretty awesome
thing about Volley's image loading code is

00:17:11.370 --> 00:17:13.240
response batching.

00:17:13.240 --> 00:17:18.540
So if you use image loader or network image
view, the library holds your image responses

00:17:18.540 --> 00:17:24.040
for a short period of time after -- after
one comes and attempts to batch them together

00:17:24.040 --> 00:17:26.450
in a single path to the main thread.

00:17:26.450 --> 00:17:31.370
What this means in practice is that batches
and images load in the UI simultaneously.

00:17:31.370 --> 00:17:35.600
Or, for instance, say you're running an animation
when you load an image, like, you fade it

00:17:35.600 --> 00:17:36.600
in.

00:17:36.600 --> 00:17:38.679
All those things fade in together in sync.

00:17:38.679 --> 00:17:43.790
And just a little secret sauce on it.

00:17:43.790 --> 00:17:46.650
Okay.

00:17:46.650 --> 00:17:52.040
So the image stuff, I think, shows that Volley
handles the basics out of the box pretty -- pretty

00:17:52.040 --> 00:17:53.340
strongly.

00:17:53.340 --> 00:17:57.180
But I also want to show what happens when
you run out of the toolbox and you need to

00:17:57.180 --> 00:17:59.110
roll your own.

00:17:59.110 --> 00:18:01.500
We have a toolbox, but it doesn't include
everything.

00:18:01.500 --> 00:18:03.120
But it's really easy to extend.

00:18:03.120 --> 00:18:08.240
So let's take a look at making a new type
of request.

00:18:08.240 --> 00:18:14.590
If you haven't heard of the GSON library,
it's a JSON serialization and deserialization

00:18:14.590 --> 00:18:20.460
library that uses reflection to populate your
Java model objects from JSON objects.

00:18:20.460 --> 00:18:25.030
You just make Java classes that look like
your JSON schema, pass it all to GSON, and

00:18:25.030 --> 00:18:26.750
it figures it out for you.

00:18:26.750 --> 00:18:33.520
So here's the relevant snippet for a GSON
adapter for Volley.

00:18:33.520 --> 00:18:36.510
This whole thing is about 60 lines of code.

00:18:36.510 --> 00:18:38.320
This is kind of the meat of it.

00:18:38.320 --> 00:18:40.340
You can see there's a gist URL on screen.

00:18:40.340 --> 00:18:45.000
You can look at the whole thing to drop into
your app if you want.

00:18:45.000 --> 00:18:50.150
But it's -- you know, it amounts to, you know,
a few lines of code.

00:18:50.150 --> 00:18:55.470
So we make a string out of the data that comes
back from the server.

00:18:55.470 --> 00:19:00.480
We pass that to GSONs from JSON method along
with the class object of our root response

00:19:00.480 --> 00:19:02.350
that helps with reflection.

00:19:02.350 --> 00:19:07.160
We use Volley's HTTP header parser helpers
from the toolbox.

00:19:07.160 --> 00:19:08.970
And that's it.

00:19:08.970 --> 00:19:11.480
You can even see we handle those parse errors.

00:19:11.480 --> 00:19:16.080
And that happens at the response time, not
necessarily in your application code where

00:19:16.080 --> 00:19:21.080
you're thinking more about errors and less
about every different type of them that could

00:19:21.080 --> 00:19:23.730
happen.

00:19:23.730 --> 00:19:26.380
Okay.

00:19:26.380 --> 00:19:31.420
Let's take another look at load more data
with that new cool request we just made.

00:19:31.420 --> 00:19:36.460
So instead of using JSON object request, we
make a new GSON request and pass in the class

00:19:36.460 --> 00:19:39.380
object of our list response.

00:19:39.380 --> 00:19:40.380
And then that's it.

00:19:40.380 --> 00:19:41.510
It's even smaller.

00:19:41.510 --> 00:19:45.720
We append the items to our backing store and
then call notify data set changed.

00:19:45.720 --> 00:19:49.650
One cool little thing about this is that it
means that the parsing actually happens on

00:19:49.650 --> 00:19:54.620
the background worker thread instead of in
the main thread, like when we do it on onPostExecute,

00:19:54.620 --> 00:19:58.929
so you get a little bit more parallelism there
for free.

00:19:58.929 --> 00:20:01.040
Okay.

00:20:01.040 --> 00:20:05.770
I want to change gears a little bit and talk
about the underlying implementation of Volley,

00:20:05.770 --> 00:20:11.630
kind of how it works, some of the semantics
it defines, and give a little look under the

00:20:11.630 --> 00:20:18.110
hood as the implementer, not necessarily as
the user.

00:20:18.110 --> 00:20:23.360
So Volley, like I mentioned before, handles
operating a thread pool for you.

00:20:23.360 --> 00:20:28.250
There's one cache dispatcher thread, there's
one or more network dispatcher threads.

00:20:28.250 --> 00:20:34.950
This diagram shows the flow of a request through
the dispatch pipeline.

00:20:34.950 --> 00:20:37.230
The blue boxes are the main thread.

00:20:37.230 --> 00:20:40.920
That's typically going to be your calling
code and the response handler.

00:20:40.920 --> 00:20:43.900
The green boxes are the cache dispatcher thread.

00:20:43.900 --> 00:20:48.820
And the orange boxes are the network dispatcher
threads.

00:20:48.820 --> 00:20:52.900
The cache dispatcher's job is essentially
triage.

00:20:52.900 --> 00:20:58.120
It figures out whether we can re- -- service
a request entirely from cache or whether we

00:20:58.120 --> 00:21:02.470
have to go to the network to get it, such
as in the case of a cache miss or perhaps

00:21:02.470 --> 00:21:07.280
a cache hit, but that's expired.

00:21:07.280 --> 00:21:11.500
In the case of an expired cache hit, it's
also responsible for forwarding the cache

00:21:11.500 --> 00:21:16.540
response to the network dispatchers so that
they can be reused in the event of an ETag

00:21:16.540 --> 00:21:21.500
match and the server has an opportunity to
give you a 304.

00:21:21.500 --> 00:21:26.910
When we do end up needing to go to the network,
like in the case of -- like in the cases I

00:21:26.910 --> 00:21:31.900
mentioned, the network dispatcher services
the requests over HTTP, handles parsing the

00:21:31.900 --> 00:21:37.540
responses using that parsing code I just showed,
and then posts the response back to the main

00:21:37.540 --> 00:21:41.169
thread as a whole parsed object.

00:21:41.169 --> 00:21:45.020
As a user of the library, you typically don't
have to think about any of this stuff.

00:21:45.020 --> 00:21:49.049
You enqueue your request from the main thread,
you get your responses on the main thread,

00:21:49.049 --> 00:21:51.470
and that's it.

00:21:51.470 --> 00:21:58.980
But if you really want to dig in and learn
more about the request pipeline, Volley has

00:21:58.980 --> 00:22:05.340
a fire hose of debugging information that's
available for you if you want it.

00:22:05.340 --> 00:22:10.960
You can just set a system property, and you
get verbose output of the complete lifetime

00:22:10.960 --> 00:22:14.370
of all stages of the request dispatch pipeline.

00:22:14.370 --> 00:22:20.120
Here's one random chunk of log I took from
my sample app when it was in the middle of

00:22:20.120 --> 00:22:24.440
loading a bunch of images.

00:22:24.440 --> 00:22:28.610
At the top, you can see that this request
took 443 milliseconds.

00:22:28.610 --> 00:22:30.590
It was low priority, because it's an image.

00:22:30.590 --> 00:22:34.790
And it was the 11th request processed by this
dispatcher.

00:22:34.790 --> 00:22:42.120
Each subsequent line below that describes
another step through the dispatch pipeline.

00:22:42.120 --> 00:22:48.250
You can see on thread one, that's the main
thread, at -- oh, and, by the way, each line

00:22:48.250 --> 00:22:52.059
shows the incremental time that that step
took.

00:22:52.059 --> 00:22:54.549
On the main thread, the request is added to
the queue.

00:22:54.549 --> 00:22:59.780
68 milliseconds later, it arrives at the cache
dispatcher, which means there was a little

00:22:59.780 --> 00:23:04.270
bit of contention for the cache -- the cache
triage thread there.

00:23:04.270 --> 00:23:09.470
The cache dispatcher figures out right away
that it's a hit but it's expired, and it forwards

00:23:09.470 --> 00:23:15.419
it along to the network dispatcher pool.

00:23:15.419 --> 00:23:27.790
Now, it takes 136 milliseconds to begin processing
by the network dispatcher, which is even longer,

00:23:27.790 --> 00:23:32.500
so there's actually even a bit more contention
for the network dispatchers than for the cache

00:23:32.500 --> 00:23:34.410
dispatcher, you can see.

00:23:34.410 --> 00:23:38.480
It takes -- the HTTP request takes 127 milliseconds.

00:23:38.480 --> 00:23:43.250
Now, this is an expired cache hit for an image,
so one thing to note is that this would typically

00:23:43.250 --> 00:23:46.580
be much faster and you'd get that 304.

00:23:46.580 --> 00:23:49.830
But this is a homemade Web server I made,
and it's crappy and doesn't have any features.

00:23:49.830 --> 00:23:52.580
So don't do that.

00:23:52.580 --> 00:23:57.970
And finally, parsing the request takes about
100 milliseconds.

00:23:57.970 --> 00:24:02.789
In this case, it's an image request, so parsing
means image decoding.

00:24:02.789 --> 00:24:03.789
One side note.

00:24:03.789 --> 00:24:08.179
100 milliseconds is actually a pretty long
time to decode an image.

00:24:08.179 --> 00:24:11.610
What's actually going on here is there's a
whole flurry of requests going on and our

00:24:11.610 --> 00:24:17.570
image decoder doesn't allow more concurrent
image decodes than there are CPU cores, which

00:24:17.570 --> 00:24:24.950
is one more thing we found to be optimal in
our testing and development on the Play Store.

00:24:24.950 --> 00:24:33.380
Lastly, we write the response bytes to the
cache from the network dispatcher.

00:24:33.380 --> 00:24:37.850
And we post the parsed object back to the
main thread, and we're done.

00:24:37.850 --> 00:24:42.200
So this is a pretty advanced feature, and
I don't think most people will use it.

00:24:42.200 --> 00:24:47.360
But we have really found it invaluable in
digging in and profiling our use in the Play

00:24:47.360 --> 00:24:48.980
Store.

00:24:48.980 --> 00:24:52.170
Here's one common thing that you can find
using this log.

00:24:52.170 --> 00:24:57.840
So if you're seeing a large amount of time
between post response and done, what that

00:24:57.840 --> 00:25:01.039
means is that there's a lot of contention
for the main thread.

00:25:01.039 --> 00:25:04.190
If there's a lot of contention for the main
thread, you're doing too much on the main

00:25:04.190 --> 00:25:05.190
thread.

00:25:05.190 --> 00:25:08.510
You can dig in from there.

00:25:08.510 --> 00:25:11.290
Okay.

00:25:11.290 --> 00:25:13.179
So why do I keep going on about the main thread?

00:25:13.179 --> 00:25:18.090
Obviously, you can't touch the UI from a background
thread, so you'd have to post back there anyway.

00:25:18.090 --> 00:25:21.840
But my obsession with the main thread -- and
ask anyone who works with me, it is an obsession

00:25:21.840 --> 00:25:28.400
-- is about more than just the inconvenience
of having to post a rentable back.

00:25:28.400 --> 00:25:33.090
When you do everything on one thread and don't
share any state with your workers, synchronization

00:25:33.090 --> 00:25:34.260
is implicit.

00:25:34.260 --> 00:25:36.160
You don't have to think about locking.

00:25:36.160 --> 00:25:38.940
You don't want to think about locking, because
locking is hard.

00:25:38.940 --> 00:25:42.960
And I'll give you an example.

00:25:42.960 --> 00:25:46.710
How many people have ever written a block
of code that looks like this?

00:25:46.710 --> 00:25:48.690
A few?

00:25:48.690 --> 00:25:49.690
Okay.

00:25:49.690 --> 00:25:51.660
Me, too.

00:25:51.660 --> 00:25:52.660
So here's what happens.

00:25:52.660 --> 00:25:54.640
Here we are, our async task is completed.

00:25:54.640 --> 00:25:57.169
We're in onPostExecute, and something has
crashed.

00:25:57.169 --> 00:25:58.169
We're touching the UI.

00:25:58.169 --> 00:26:00.060
The UI is dead.

00:26:00.060 --> 00:26:04.160
But it's way too late in the schedule to figure
out why this is happening, so we cram a little

00:26:04.160 --> 00:26:07.070
null pointer check in our code.

00:26:07.070 --> 00:26:09.900
It doesn't crash anymore, and we head off
to the launch party.

00:26:09.900 --> 00:26:14.289
[ Laughter ]
&gt;&gt;Ficus Kirkpatrick: But it's a waste of effort,

00:26:14.289 --> 00:26:18.980
it's a waste of CPU cycles, it's a waste of
network bandwidth, and it's a waste of battery

00:26:18.980 --> 00:26:25.010
to allow a request to finish that you're just
going to ignore the result of.

00:26:25.010 --> 00:26:31.419
So it also leaves these warts of, like, if
null checks at the top of all your methods

00:26:31.419 --> 00:26:33.510
all over your code.

00:26:33.510 --> 00:26:38.360
I mentioned Volley has a powerful cancellation
API.

00:26:38.360 --> 00:26:42.810
And the main thread interfaces with it like
this: Volley always delivers responses on

00:26:42.810 --> 00:26:43.920
the main thread.

00:26:43.920 --> 00:26:48.400
What that means is that once cancel returns,
you can be guaranteed that your response will

00:26:48.400 --> 00:26:49.930
not be delivered.

00:26:49.930 --> 00:26:53.510
So here you can just keep track of all the
requests you have in flight and then cancel

00:26:53.510 --> 00:26:54.750
them in onStop.

00:26:54.750 --> 00:26:59.001
You know that when onStop returns and you're
no longer allowed to touch the UI, the request

00:26:59.001 --> 00:27:03.990
won't be delivered, so you don't have to check
for null at the top of all of your listeners.

00:27:03.990 --> 00:27:06.600
But you can actually do this with async task,
too.

00:27:06.600 --> 00:27:09.870
So how about this?

00:27:09.870 --> 00:27:16.640
I mentioned Volley lets you set up blocks
or scopes of requests.

00:27:16.640 --> 00:27:23.990
It lets you tag any request with an arbitrary
object that you can use to set up a bulk cancellation

00:27:23.990 --> 00:27:24.990
scope.

00:27:24.990 --> 00:27:29.780
So in this example, you tag all the requests
with the activity they belong to, and then

00:27:29.780 --> 00:27:34.880
you simply pass those to cancel all in onStop,
and you can be guaranteed that you're not

00:27:34.880 --> 00:27:38.500
going to get any more responses.

00:27:38.500 --> 00:27:39.870
You don't have to use the activity.

00:27:39.870 --> 00:27:44.429
You could define a smaller scope, like, say
you want to group all thumbnail requests from

00:27:44.429 --> 00:27:47.580
one view pager tab and cancel them when you
swipe away.

00:27:47.580 --> 00:27:53.970
You can do that, too.

00:27:53.970 --> 00:27:58.270
If you really want to go nuts, you can actually
specify a custom filter deciding which requests

00:27:58.270 --> 00:28:01.090
to keep and which requests to cancel.

00:28:01.090 --> 00:28:04.590
Say, for example, you've got a post request
in the background and you want to let that

00:28:04.590 --> 00:28:07.100
go, but you want to cancel all your thumbnails.

00:28:07.100 --> 00:28:13.000
You can do that, too.

00:28:13.000 --> 00:28:15.760
Okay.

00:28:15.760 --> 00:28:21.610
So we've covered how easy it is to build an
app with Volley, or even port your app to

00:28:21.610 --> 00:28:25.419
Volley, and how to grow up from there.

00:28:25.419 --> 00:28:28.970
Just on the porting topic, I want to mention,
those of you who have the Google I/O 2013

00:28:28.970 --> 00:28:33.020
app, that was ported to Volley about a month
ago, and the whole thing took about half a

00:28:33.020 --> 00:28:34.020
day.

00:28:34.020 --> 00:28:35.669
And it wasn't me who did it, by the way.

00:28:35.669 --> 00:28:38.919
So you don't have to be an expert.

00:28:38.919 --> 00:28:44.929
We've again seen those complicated cases defining
custom requests, doing, you know, more advanced

00:28:44.929 --> 00:28:47.440
cancellation operations.

00:28:47.440 --> 00:28:51.620
And you can do it with a lot less code and
a lot more functionality than you could in

00:28:51.620 --> 00:28:53.289
rolling your own.

00:28:53.289 --> 00:28:58.049
It's easier than doing it yourself, and you
get the benefit of all of those -- all those

00:28:58.049 --> 00:29:01.980
lessons we've learned the hard way in developing
our apps at Google.

00:29:01.980 --> 00:29:03.500
But it's also faster than doing it yourself.

00:29:03.500 --> 00:29:04.560
It's also faster than doing it yourself.

00:29:04.560 --> 00:29:09.440
The Google+ team did a benchmark last year
after bunch of different networking libraries

00:29:09.440 --> 00:29:12.780
and Volleyed every single one.

00:29:12.780 --> 00:29:18.780
They ran on FroYo, through Ice Cream Sandwich
and Jellybean, on different types of hardware.

00:29:18.780 --> 00:29:22.559
They ran on EDGE, 3G, 4G, wi-fi.

00:29:22.559 --> 00:29:29.409
Volley was faster every single time, in some
cases by a factor of 10.

00:29:29.409 --> 00:29:32.230
Okay.

00:29:32.230 --> 00:29:33.230
So you're sold.

00:29:33.230 --> 00:29:35.340
How do you get started?

00:29:35.340 --> 00:29:36.340
It's pretty easy.

00:29:36.340 --> 00:29:37.340
Just clone the project.

00:29:37.340 --> 00:29:41.020
We have the repository URL up on the screen.

00:29:41.020 --> 00:29:43.160
From there it's pretty simple.

00:29:43.160 --> 00:29:48.360
There's an Eclipse project -- I guess we will
need to add an Android Studio one -- right

00:29:48.360 --> 00:29:50.309
there in the repository.

00:29:50.309 --> 00:29:55.600
There's also a build.xml file so you can use
add to build yourself a jar or you can just

00:29:55.600 --> 00:29:57.830
drop your code into your app, any of those
things.

00:29:57.830 --> 00:30:04.520
You call volley.newrequestqueue, start adding
requests to the queue and you're off and running.

00:30:04.520 --> 00:30:06.650
That's pretty much it.

00:30:06.650 --> 00:30:09.890
Anything else?

00:30:09.890 --> 00:30:10.890
That's all I have.

00:30:10.890 --> 00:30:13.979
Thank you very much for coming.

00:30:13.979 --> 00:30:24.410
[ Applause ]
&gt;&gt;Ficus Kirkpatrick: I did want to leave time

00:30:24.410 --> 00:30:30.059
for Q and A, and I will also be at office
hours after this or you can hit me up on G+

00:30:30.059 --> 00:30:31.460
or Twitter.

00:30:31.460 --> 00:30:33.850
So we can take some questions.

00:30:33.850 --> 00:30:36.310
&gt;&gt;&gt; Hi, my name is Alexi with (Indiscernible).

00:30:36.310 --> 00:30:46.200
Can you talk about size of the in-memory cache
for bitmaps, disk size of the cache for bitmaps?

00:30:46.200 --> 00:30:50.520
And if you hit the disk cache, on which does
the bitmap decoding happens?

00:30:50.520 --> 00:30:53.880
&gt;&gt;Ficus Kirkpatrick: That's a great question.

00:30:53.880 --> 00:30:59.230
So the sizes of the caches are completely
configurable by you.

00:30:59.230 --> 00:31:05.040
You can choose the in-memory cache size and
the disk cache size separately.

00:31:05.040 --> 00:31:07.370
All blocking IO is done on background threads.

00:31:07.370 --> 00:31:10.030
We never do blocking IO on the main thread.

00:31:10.030 --> 00:31:15.140
But it's actually important to do the in-memory
cache stuff on the main thread before you

00:31:15.140 --> 00:31:17.720
ever even get to the HTTP stack.

00:31:17.720 --> 00:31:23.010
The reason for that being that you don't want
to leave back into the main looper again.

00:31:23.010 --> 00:31:27.600
You want to know immediately that you have
your bitmap so that you don't defer, let a

00:31:27.600 --> 00:31:31.460
layout pass happen and then set your image
bitmap and you get a little flicker.

00:31:31.460 --> 00:31:34.040
Does that answer your question?

00:31:34.040 --> 00:31:39.830
&gt;&gt;&gt; [ Inaudible ].
&gt;&gt;Ficus Kirkpatrick: He asked about disk thread

00:31:39.830 --> 00:31:43.340
versus networking thread.

00:31:43.340 --> 00:31:47.710
Caching -- caching from the disk is all read
on the cache thread.

00:31:47.710 --> 00:31:50.540
So there's serialization at the cache thread.

00:31:50.540 --> 00:31:54.030
Basically things can tend for the cache thread
and get stuck if one thing is reading from

00:31:54.030 --> 00:31:55.610
the cache.

00:31:55.610 --> 00:32:01.000
We have a design for how to split up cache
workers or defer the work somewhere else.

00:32:01.000 --> 00:32:02.370
We just haven't needed it.

00:32:02.370 --> 00:32:05.220
It's been fast enough.

00:32:05.220 --> 00:32:07.470
&gt;&gt;&gt; So my name is Mike from Abex Systems.

00:32:07.470 --> 00:32:10.830
I'm really happy that you guys were able to
encapsulate the caching logic.

00:32:10.830 --> 00:32:13.000
We had troubles trying to do that ourselves.

00:32:13.000 --> 00:32:18.120
My question is one thing that we need to do
is establish different links for cached objects.

00:32:18.120 --> 00:32:23.270
So for a certain object we determine -- we
deem it as static versus dynamic and we cache

00:32:23.270 --> 00:32:24.640
it for different lengths of time.

00:32:24.640 --> 00:32:27.740
Is that something that will be supported by
this Volley structure?

00:32:27.740 --> 00:32:29.220
&gt;&gt;Ficus Kirkpatrick: Yeah.

00:32:29.220 --> 00:32:33.419
So he's asking about cache TTL basically.

00:32:33.419 --> 00:32:39.890
So Volley's cache implementation on disk respects
all the standard HTTP cache shutters.

00:32:39.890 --> 00:32:45.279
So if your server sets this thing expires
immediately, it respects that.

00:32:45.279 --> 00:32:47.409
It doesn't even get written to cache.

00:32:47.409 --> 00:32:51.539
If you say this thing lasts for a day, this
thing lasts for a year, again, the expiration

00:32:51.539 --> 00:32:52.539
is respected.

00:32:52.539 --> 00:32:56.820
We don't have -- there's no TTL in memory
cache.

00:32:56.820 --> 00:33:01.260
In our experience things just thrash through
way too fast, but again you can pass in your

00:33:01.260 --> 00:33:03.220
own implementation if you need to.

00:33:03.220 --> 00:33:05.040
&gt;&gt;&gt; Hi, Ficus.

00:33:05.040 --> 00:33:09.190
I'm Chuck from AWeber Communications.

00:33:09.190 --> 00:33:10.980
Thank you for this.

00:33:10.980 --> 00:33:14.940
I've seen a lot of different approaches to
solving this problem and written a few myself,

00:33:14.940 --> 00:33:20.320
and one common thing that seems to occur a
lot is the dreaded out of memory exceptions,

00:33:20.320 --> 00:33:25.390
and particularly when you're dealing with
larger images and lower end devices.

00:33:25.390 --> 00:33:30.400
So I'm wondering if you saw how Volley compared
to other solutions and the number of occurrences

00:33:30.400 --> 00:33:34.990
of this and some tips for dealing with that
scenario.

00:33:34.990 --> 00:33:40.070
&gt;&gt;Ficus Kirkpatrick: Yeah, we definitely struggled
with out of memory errors a lot.

00:33:40.070 --> 00:33:45.710
It's a tough problem because if you have a
lot of memory to use you can make things fast.

00:33:45.710 --> 00:33:50.370
The solution that we ended up on that worked
really well for us was a couple of things.

00:33:50.370 --> 00:33:55.610
One, I mentioned that we don't decode more
things concurrently than there are CPU cores.

00:33:55.610 --> 00:34:02.250
That actually ends up having a pretty positive
effect on your kind of instantly measured

00:34:02.250 --> 00:34:05.110
heap pressure.

00:34:05.110 --> 00:34:09.829
And the other thing that we do is that we
actually in the Play Store we specify the

00:34:09.829 --> 00:34:14.569
size of the in-memory cache as a function
of the screen size, which kind of makes sense,

00:34:14.569 --> 00:34:18.599
right, because you typically want to have
as much in cache to fill three screens' worth

00:34:18.599 --> 00:34:20.710
of data.

00:34:20.710 --> 00:34:26.700
As it turns out, devices are typically built
with the memory to support the screen that

00:34:26.700 --> 00:34:30.750
they need to fill, so it tends to work out
somewhat coincidentally.

00:34:30.750 --> 00:34:33.720
I would say this isn't really a Volley thing.

00:34:33.720 --> 00:34:37.179
I think it's a "how to choose your cache size"
thing.

00:34:37.179 --> 00:34:40.190
And so we don't use soft references or weak
references.

00:34:40.190 --> 00:34:41.409
They don't work well.

00:34:41.409 --> 00:34:45.790
We use hard references and set a strong budget.

00:34:45.790 --> 00:34:51.359
And we are conservative in setting that budget
by scaling down with the screen and really

00:34:51.359 --> 00:34:52.880
with the number of pixels.

00:34:52.880 --> 00:34:53.880
&gt;&gt;&gt; Thanks.

00:34:53.880 --> 00:34:56.280
&gt;&gt;&gt; Hi, my name is Mark.

00:34:56.280 --> 00:35:00.700
I would like to know when is this going to
make it into the SDK manager?

00:35:00.700 --> 00:35:07.430
And the second part of the question is lots
of images, small size, this sounds a lot like

00:35:07.430 --> 00:35:09.550
the network protocol SPDY.

00:35:09.550 --> 00:35:13.220
Are you planning on integrating SPDY into
Volley?

00:35:13.220 --> 00:35:18.400
&gt;&gt;Ficus Kirkpatrick: This is easy to answer.

00:35:18.400 --> 00:35:20.260
I don't know.

00:35:20.260 --> 00:35:22.410
It's easy enough to get cloned.

00:35:22.410 --> 00:35:28.850
I don't think we have a great answer for that,
so I will duck that and answer your question

00:35:28.850 --> 00:35:29.850
about SPDY.

00:35:29.850 --> 00:35:32.140
I'm really excited about SPDY.

00:35:32.140 --> 00:35:36.430
Volley was -- it was on my mind when we were
designing it.

00:35:36.430 --> 00:35:41.980
Somebody right now is working on putting the
OkHttp library that Square just released -- you

00:35:41.980 --> 00:35:47.740
may have seen it -- as an underlying transport
stack for Volley.

00:35:47.740 --> 00:35:54.440
I haven't tried Ok with SPDY yet, but according
to Jesse, the author, you can plug SPDY into

00:35:54.440 --> 00:35:59.359
the back of OkHttp, which would pretty much
give you SPDY in Volley.

00:35:59.359 --> 00:36:00.460
So yes, you can do it.

00:36:00.460 --> 00:36:03.770
It doesn't work yet, but we intend for it
to work really soon.

00:36:03.770 --> 00:36:05.440
&gt;&gt;&gt; That's great.

00:36:05.440 --> 00:36:06.440
&gt;&gt;&gt; Hey.

00:36:06.440 --> 00:36:11.119
One of the things that we have found is that
a lot of our activities tend to have a mapping

00:36:11.119 --> 00:36:13.550
to like an API call.

00:36:13.550 --> 00:36:16.930
And what we would like to do is basically
make the API call before we do the transition

00:36:16.930 --> 00:36:18.470
to the activity.

00:36:18.470 --> 00:36:21.690
A lot of these requests can't actually be
cached or shouldn't be cached.

00:36:21.690 --> 00:36:26.349
Is there any way to serialize your request
objects?

00:36:26.349 --> 00:36:30.539
&gt;&gt;Ficus Kirkpatrick: Yes.

00:36:30.539 --> 00:36:33.940
You can kind of roll your own or the really
dirty thing that we have done before is you

00:36:33.940 --> 00:36:39.580
make a separate request queue with one worker
thread and then things are first in, first

00:36:39.580 --> 00:36:41.820
out if they're the same priority.

00:36:41.820 --> 00:36:43.250
So you can do it.

00:36:43.250 --> 00:36:45.519
It's -- the API is not optimized for it.

00:36:45.519 --> 00:36:46.519
&gt;&gt;&gt; Okay.

00:36:46.519 --> 00:36:50.870
Any plans to optimize the API for it or add
it as a feature?

00:36:50.870 --> 00:36:51.980
&gt;&gt;Ficus Kirkpatrick: No.

00:36:51.980 --> 00:36:55.099
Traditionally what we do in the case where
we have API calls that need to be made in

00:36:55.099 --> 00:37:00.410
the serial is we initiate the second one from
the response handler of the first one.

00:37:00.410 --> 00:37:01.720
&gt;&gt;&gt; Oh, sorry.

00:37:01.720 --> 00:37:07.050
By serialize the API call to action, I mean
like parse it so that you can pass it across

00:37:07.050 --> 00:37:08.180
the activity boundary.

00:37:08.180 --> 00:37:11.000
&gt;&gt;Ficus Kirkpatrick: I see.

00:37:11.000 --> 00:37:15.300
So what I would do in that case, I think,
is just pass the URL of your request or the

00:37:15.300 --> 00:37:17.319
metadata in a parsable or something, right?

00:37:17.319 --> 00:37:21.070
&gt;&gt;&gt; Right, but then the request isn't going
to start until after you make the transition

00:37:21.070 --> 00:37:22.070
across activities.

00:37:22.070 --> 00:37:24.380
&gt;&gt;Ficus Kirkpatrick: Ah, I see.

00:37:24.380 --> 00:37:27.580
So I think your option there is going to be
to kind of shove it into static somewhere.

00:37:27.580 --> 00:37:32.000
I don't think there's a great answer to your
question.

00:37:32.000 --> 00:37:33.480
&gt;&gt;&gt; Okay.

00:37:33.480 --> 00:37:34.960
Thanks.

00:37:34.960 --> 00:37:37.310
&gt;&gt;&gt; Hi, my name is Jonathan.

00:37:37.310 --> 00:37:38.960
I just have a quick question.

00:37:38.960 --> 00:37:42.220
In all your examples you were using JSON request
and responses.

00:37:42.220 --> 00:37:50.820
I was wondering if there was any way to use
different types of protocol like XML, for

00:37:50.820 --> 00:37:51.820
example?

00:37:51.820 --> 00:37:52.820
&gt;&gt;Ficus Kirkpatrick: Sure.

00:37:52.820 --> 00:37:55.710
Yeah, I think I just forgot to mention this.

00:37:55.710 --> 00:38:00.520
We use protocol buffers pervasively in the
Play Store, and the Play Store runs on Volley.

00:38:00.520 --> 00:38:05.750
Yeah, you can use XML, you can -- I used JSON
because it's easier to read on the slides,

00:38:05.750 --> 00:38:09.730
but yeah, we use protobuf, you can use XML.

00:38:09.730 --> 00:38:11.599
We have some things that are done as raw strings.

00:38:11.599 --> 00:38:15.020
Obviously images are all just formats of requests.

00:38:15.020 --> 00:38:16.020
&gt;&gt;&gt; Okay.

00:38:16.020 --> 00:38:18.840
So it should be pretty easy to plug in whatever
we want to use?

00:38:18.840 --> 00:38:20.200
&gt;&gt;Ficus Kirkpatrick: Very much.

00:38:20.200 --> 00:38:23.600
And if you look at the gist I showed in the
presentation to give you a starting point

00:38:23.600 --> 00:38:26.340
of writing like your own XML particular request.

00:38:26.340 --> 00:38:27.340
&gt;&gt;&gt; Okay.

00:38:27.340 --> 00:38:28.340
Sounds good.

00:38:28.340 --> 00:38:33.980
And last question: Is there anything built
into end all with three tries in case of request

00:38:33.980 --> 00:38:35.100
barriers and stuff?

00:38:35.100 --> 00:38:37.480
&gt;&gt;Ficus Kirkpatrick: Yes, it does have a retry
for you.

00:38:37.480 --> 00:38:42.380
I didn't have time to cover it right now,
but can you set a custom retry policy, you

00:38:42.380 --> 00:38:44.920
can set back off algorithm, all that stuff.

00:38:44.920 --> 00:38:45.920
&gt;&gt;&gt; All right.

00:38:45.920 --> 00:38:46.920
Sounds great.

00:38:46.920 --> 00:38:47.920
Thanks a lot.

00:38:47.920 --> 00:38:48.920
&gt;&gt;Ficus Kirkpatrick: So I'm going to hold
questions for now.

00:38:48.920 --> 00:38:52.990
I'll be at office hours if you guys want to
talk to me in person.

00:38:52.990 --> 00:38:54.470
Thanks again for coming.

00:38:54.470 --> 00:38:58.250
Please scan the QR code to rate this session
unless you didn't like it.

00:38:58.250 --> 00:39:00.380
And thanks very much.

00:39:00.380 --> 00:39:01.079
[ Applause ]

