WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:03.410
IAN LEWIS: So this is the
"Making Sense with IoT--"

00:00:03.410 --> 00:00:07.700
"Making Sense of IoT
Data with the Cloud."

00:00:07.700 --> 00:00:12.130
So if you're wrong room, then
you can kind of check out now.

00:00:12.130 --> 00:00:13.390
So my name's Ian Lewis.

00:00:13.390 --> 00:00:16.670
I'm a developer advocate on
the Google Cloud Platform team.

00:00:16.670 --> 00:00:18.030
I'm based in Tokyo, Japan.

00:00:18.030 --> 00:00:22.920
So if you're ever out there, you
can kind of give me a holler.

00:00:22.920 --> 00:00:25.999
I'm kind of into Python
and Go and IoT and cloud

00:00:25.999 --> 00:00:27.040
and those type of things.

00:00:27.040 --> 00:00:28.870
So if you're ever
interested, you

00:00:28.870 --> 00:00:33.440
can kind of hit me up
on Twitter @IanMLewis.

00:00:33.440 --> 00:00:36.550
I'm always on there and I'm
really willing to talk to you.

00:00:36.550 --> 00:00:38.430
And I'd love to hear
from you about questions

00:00:38.430 --> 00:00:44.810
or things like that if you think
of them later after the talk.

00:00:44.810 --> 00:00:47.570
So today we're going to
be talking about IoT.

00:00:47.570 --> 00:00:51.780
And so IoT is the Internet
of Things, obviously.

00:00:51.780 --> 00:00:55.570
And that enables you to get a
lot more data about the world

00:00:55.570 --> 00:01:00.220
around you and to be able to
use that data to make better

00:01:00.220 --> 00:01:04.190
decisions about how to
do things, improve things

00:01:04.190 --> 00:01:06.760
in your life, be more
efficient, et cetera.

00:01:06.760 --> 00:01:11.890
So anything from
smartphones to dishwashers

00:01:11.890 --> 00:01:16.960
to just connected devices
that can measure sensor data

00:01:16.960 --> 00:01:21.490
like temperature or humidity
or those type of things.

00:01:21.490 --> 00:01:24.510
And all of those are kind of
creating all of this data.

00:01:24.510 --> 00:01:28.390
But dealing with that data
can actually pretty hard.

00:01:28.390 --> 00:01:32.600
You want to actually be
able to use that data later.

00:01:32.600 --> 00:01:37.660
So let's say that you
have a great idea for kind

00:01:37.660 --> 00:01:39.030
of a connected device.

00:01:39.030 --> 00:01:40.910
Maybe it's a robot arm.

00:01:40.910 --> 00:01:42.700
Maybe it's a sensor.

00:01:42.700 --> 00:01:44.600
Maybe it's a dishwasher.

00:01:48.100 --> 00:01:51.290
So once you have this
data or this new idea

00:01:51.290 --> 00:01:53.794
and it's collecting all this
data, there's a lot of things

00:01:53.794 --> 00:01:55.335
that you have to
kind of think about.

00:01:55.335 --> 00:01:57.210
You have to think about
being able to connect

00:01:57.210 --> 00:02:01.000
the device to the network
to be able to send the data.

00:02:01.000 --> 00:02:03.620
So establishing the
connections, being

00:02:03.620 --> 00:02:07.630
able to do authentication, being
able to manage that connection

00:02:07.630 --> 00:02:12.702
so that it stays live so
you can actually send data.

00:02:12.702 --> 00:02:14.410
Then you have to be
able to actually read

00:02:14.410 --> 00:02:15.390
the data from the sensors.

00:02:15.390 --> 00:02:17.140
You have to know enough
about the hardware

00:02:17.140 --> 00:02:19.860
to be able to read the
data from the sensor,

00:02:19.860 --> 00:02:22.090
to be able to then
take it in your program

00:02:22.090 --> 00:02:24.920
and actually be able to send it.

00:02:24.920 --> 00:02:27.860
Then you have to actually send
the data over the network.

00:02:27.860 --> 00:02:29.830
And this can be done
in a number of ways.

00:02:29.830 --> 00:02:33.730
But what if your connection
is over a wireless connection?

00:02:33.730 --> 00:02:36.200
Maybe it kind of
goes in and out.

00:02:36.200 --> 00:02:40.930
You have to be able to deal with
those type of connection issues

00:02:40.930 --> 00:02:41.930
that they might arise.

00:02:41.930 --> 00:02:45.030
A lot of IoT related
devices are on SIM networks

00:02:45.030 --> 00:02:47.180
or on 3G or that type of thing.

00:02:49.701 --> 00:02:51.450
You have to then be
able to take that data

00:02:51.450 --> 00:02:53.210
and process it on the server.

00:02:53.210 --> 00:02:56.400
So you have to be able to figure
out how to take that data,

00:02:56.400 --> 00:03:00.010
do some processing with it,
and then actually store it.

00:03:00.010 --> 00:03:01.800
But you can imagine
that if there's

00:03:01.800 --> 00:03:05.070
lots and lots of devices
and lots of data coming in,

00:03:05.070 --> 00:03:10.357
you have to be able to handle
all of that data coming in.

00:03:10.357 --> 00:03:12.690
And then you have to be able
to actually store the data.

00:03:12.690 --> 00:03:15.540
So perhaps you
have a large number

00:03:15.540 --> 00:03:17.460
of devices that are
all generating data.

00:03:17.460 --> 00:03:19.585
You have to be able to
store a large amount of data

00:03:19.585 --> 00:03:22.917
and be able to handle
that type of throughput.

00:03:22.917 --> 00:03:24.500
And then there's one
last thing that I

00:03:24.500 --> 00:03:28.710
think is like a fairly--
that people kind of overlook.

00:03:28.710 --> 00:03:30.770
Like you can actually get
the data and store it,

00:03:30.770 --> 00:03:32.769
but then you have to be
able to get the data out

00:03:32.769 --> 00:03:38.160
easily and analyze
it and figure out

00:03:38.160 --> 00:03:42.890
how to make the decisions
smarter and be more efficient.

00:03:42.890 --> 00:03:45.370
So this analysis part is
actually also really, really

00:03:45.370 --> 00:03:47.530
important, being able to
get the data out actually

00:03:47.530 --> 00:03:51.390
once you've stored it.

00:03:51.390 --> 00:03:53.070
So in this talk, I
kind of want to go

00:03:53.070 --> 00:03:57.200
through how you would actually
build an IoT application that

00:03:57.200 --> 00:04:01.750
is creating a lot of data and
needs to process that data

00:04:01.750 --> 00:04:04.450
and store that
data in the cloud.

00:04:04.450 --> 00:04:06.250
And so I'm going to
kind of go through kind

00:04:06.250 --> 00:04:10.312
of a high level, what this type
of project would look like,

00:04:10.312 --> 00:04:11.770
what are the typical
type of things

00:04:11.770 --> 00:04:15.030
you would see in
an IoT application.

00:04:15.030 --> 00:04:18.010
And then eventually we'll
kind of get down and actually

00:04:18.010 --> 00:04:22.270
start with a particular
use case or a case study

00:04:22.270 --> 00:04:25.470
about how to actually
architect an application.

00:04:25.470 --> 00:04:27.280
So some of the
typical components

00:04:27.280 --> 00:04:30.490
in an IoT
application-- so here's

00:04:30.490 --> 00:04:33.100
an eye level architecture.

00:04:33.100 --> 00:04:35.750
You might have a
bunch of devices.

00:04:35.750 --> 00:04:37.782
Say this is like an
industrial application.

00:04:37.782 --> 00:04:39.865
I'm thinking mostly about
industrial applications.

00:04:39.865 --> 00:04:41.670
A lot of people
kind of think of IoT

00:04:41.670 --> 00:04:44.600
as kind of this connected
home type of thing.

00:04:44.600 --> 00:04:46.800
And that's also relevant.

00:04:46.800 --> 00:04:48.890
But I kind of think
of connected home

00:04:48.890 --> 00:04:52.450
as a special type of
industrial use cases.

00:04:52.450 --> 00:04:54.750
So I'm going to speak in a
very generic way about how

00:04:54.750 --> 00:04:56.780
to do IoT applications.

00:04:56.780 --> 00:04:59.530
But here's kind of a
typical architecture.

00:04:59.530 --> 00:05:01.700
You might have a bunch of
devices like in your home

00:05:01.700 --> 00:05:09.390
or in a factory or at a power
generation plant or whatever.

00:05:09.390 --> 00:05:11.890
And they're all
collecting data and then

00:05:11.890 --> 00:05:14.650
sending that data to a cloud
service that can actually then

00:05:14.650 --> 00:05:17.420
process and store that data.

00:05:17.420 --> 00:05:19.740
And you might have the
devices actually connected

00:05:19.740 --> 00:05:23.870
via just a cable to something
like a gateway server that

00:05:23.870 --> 00:05:27.510
will actually send the data
over the network, or maybe

00:05:27.510 --> 00:05:34.850
over a short wave
wireless so that it

00:05:34.850 --> 00:05:36.570
works on a short distance.

00:05:36.570 --> 00:05:38.490
But then from the
gateway you can actually

00:05:38.490 --> 00:05:40.200
send to the internet.

00:05:40.200 --> 00:05:42.750
So you may have a number of
different types of setups.

00:05:42.750 --> 00:05:45.134
Or the device itself could
be connected directly

00:05:45.134 --> 00:05:45.800
to the internet.

00:05:45.800 --> 00:05:48.810
In that sense, it would kind
of serve as its own gateway.

00:05:48.810 --> 00:05:51.410
So you can have a number
of different scenarios.

00:05:51.410 --> 00:05:54.630
But as a general
rule, you just kind of

00:05:54.630 --> 00:06:02.450
have this gateway type of
thing in your architecture

00:06:02.450 --> 00:06:04.499
quite often.

00:06:04.499 --> 00:06:06.790
And then when you kind of
zoom in under the cloud side,

00:06:06.790 --> 00:06:09.081
you might actually have a
number of moving parts there.

00:06:09.081 --> 00:06:12.390
So you might have a front end
that actually takes in the data

00:06:12.390 --> 00:06:14.935
from your device,
and then some back

00:06:14.935 --> 00:06:17.590
ends that actually process
and store the data.

00:06:17.590 --> 00:06:22.530
So there might be
any number of type

00:06:22.530 --> 00:06:26.530
of permutations of this type of
background-- or this back end.

00:06:26.530 --> 00:06:30.370
But you might see these type
of-- but all architectures will

00:06:30.370 --> 00:06:36.470
tend to fall in this
type of diagram.

00:06:36.470 --> 00:06:39.190
So now that I've
looked at that, I'll

00:06:39.190 --> 00:06:44.520
try to go in and fill the blanks
about what you might actually

00:06:44.520 --> 00:06:47.590
use for the front and the
back end for your application

00:06:47.590 --> 00:06:49.250
in a kind of a case study later.

00:06:49.250 --> 00:06:51.940
But next I want to talk about
the actual types of data

00:06:51.940 --> 00:06:54.717
that you would have to
send between devices

00:06:54.717 --> 00:06:55.425
and your service.

00:06:58.104 --> 00:06:59.520
So we've thought
a lot about this,

00:06:59.520 --> 00:07:04.950
and one of the types of
data that you would send

00:07:04.950 --> 00:07:06.740
or that you would
have is metadata.

00:07:06.740 --> 00:07:10.600
So these are device
IDs or classes

00:07:10.600 --> 00:07:13.450
or models or revisions,
those type of things,

00:07:13.450 --> 00:07:15.090
about your device.

00:07:15.090 --> 00:07:17.170
And so this would
be basically data

00:07:17.170 --> 00:07:20.840
that exists but doesn't
really change very much.

00:07:20.840 --> 00:07:25.210
This is something that's very
static for a particular device.

00:07:25.210 --> 00:07:27.980
And so it might
give you information

00:07:27.980 --> 00:07:30.440
about the capabilities
of the device.

00:07:30.440 --> 00:07:32.290
But it doesn't really change.

00:07:32.290 --> 00:07:34.040
And it could be kind
of freeform data.

00:07:34.040 --> 00:07:36.300
You don't really
necessarily know

00:07:36.300 --> 00:07:37.820
exactly what might be in here.

00:07:37.820 --> 00:07:41.350
Depending on the type of
device, it might be different.

00:07:41.350 --> 00:07:42.210
Also state data.

00:07:42.210 --> 00:07:45.160
State data is very
similar to metadata

00:07:45.160 --> 00:07:48.550
except that this will kind
of change fairly often,

00:07:48.550 --> 00:07:53.830
because the device itself might
change state or change location

00:07:53.830 --> 00:07:55.030
or whatever.

00:07:55.030 --> 00:07:57.780
So here we might have
the status of the device,

00:07:57.780 --> 00:08:01.580
whether it's ready or its in
an error state or it's failing.

00:08:01.580 --> 00:08:02.980
You might have
the status of each

00:08:02.980 --> 00:08:06.824
and every one of the
devices or the sensors.

00:08:06.824 --> 00:08:08.240
So in this case
we have one that's

00:08:08.240 --> 00:08:12.490
like a temperature sensor that
shows the current temperature

00:08:12.490 --> 00:08:13.950
and says that it's reading.

00:08:13.950 --> 00:08:16.820
And we might also have location,
if, say, your device has

00:08:16.820 --> 00:08:19.160
a GPS or something like that.

00:08:19.160 --> 00:08:21.110
So this might be
updated every minute

00:08:21.110 --> 00:08:23.650
or every hour or whatever.

00:08:23.650 --> 00:08:28.980
But it's kind of continually
updated as the state

00:08:28.980 --> 00:08:30.660
changes for your device.

00:08:30.660 --> 00:08:32.220
Next is telemetry data.

00:08:32.220 --> 00:08:35.100
So telemetry is not really
a commonly used word,

00:08:35.100 --> 00:08:37.490
but it's generally
time series data.

00:08:37.490 --> 00:08:41.190
So this is the data that
the kind of meat and bones--

00:08:41.190 --> 00:08:44.100
or meat and potatoes
type of application data

00:08:44.100 --> 00:08:46.650
that your sensors
are generating.

00:08:46.650 --> 00:08:51.270
So basically over time, it'll
generate read only data that

00:08:51.270 --> 00:08:53.410
can be viewed as a time series.

00:08:53.410 --> 00:08:59.620
So maybe the humidity in the
room or the amount of water

00:08:59.620 --> 00:09:02.910
flowing through a pipe
or something like that.

00:09:02.910 --> 00:09:04.990
And then it's
basically read only.

00:09:04.990 --> 00:09:07.400
So it doesn't update.

00:09:07.400 --> 00:09:10.880
But depending on the number
of devices that you have,

00:09:10.880 --> 00:09:14.870
you could very quickly get
into very large amounts of data

00:09:14.870 --> 00:09:16.520
and a very high throughput.

00:09:16.520 --> 00:09:19.160
So you need to be
able to handle that.

00:09:19.160 --> 00:09:22.090
And generally you
quickly have to apply

00:09:22.090 --> 00:09:24.310
big data type of strategies.

00:09:24.310 --> 00:09:26.950
The fourth type of data
that I wanted to talk about

00:09:26.950 --> 00:09:28.360
was commands.

00:09:28.360 --> 00:09:30.190
So commands are things
that would actually

00:09:30.190 --> 00:09:34.950
be sent to the device, so
telling a specific device

00:09:34.950 --> 00:09:39.420
to spin 360 degrees or spin
90 degrees, or something

00:09:39.420 --> 00:09:43.750
like that, or run a self
cleaning cycle or do something.

00:09:43.750 --> 00:09:47.510
And these are
generally not really--

00:09:47.510 --> 00:09:50.090
they have a specific
type of properties

00:09:50.090 --> 00:09:53.370
in that they are not really
represented in state data

00:09:53.370 --> 00:09:54.700
very easily.

00:09:54.700 --> 00:09:56.850
So when you send a
command to a device,

00:09:56.850 --> 00:09:59.520
you want to actually have
that command execute one time,

00:09:59.520 --> 00:10:02.660
and you want to be able to
know if the device actually

00:10:02.660 --> 00:10:04.910
succeeded in running
the command or not.

00:10:04.910 --> 00:10:10.080
So things like
sending the command

00:10:10.080 --> 00:10:14.210
and having it actually run twice
because of intermittent type

00:10:14.210 --> 00:10:18.400
of communication
problems or things

00:10:18.400 --> 00:10:21.600
like that, like if you
told it to turn 90 degrees,

00:10:21.600 --> 00:10:24.250
if it actually ran it twice,
it would turn 180 degrees.

00:10:24.250 --> 00:10:25.916
And you don't really
want it to do that.

00:10:25.916 --> 00:10:27.840
So you want these
kind of like run

00:10:27.840 --> 00:10:31.014
only once type of semantics.

00:10:31.014 --> 00:10:32.430
It's also kind of
temporal, so you

00:10:32.430 --> 00:10:34.850
want to have some sort
of TTL or something

00:10:34.850 --> 00:10:37.250
in order to be able to time
out these type of commands.

00:10:40.540 --> 00:10:46.230
So that's some of
the types of data

00:10:46.230 --> 00:10:52.460
and general view of architecture
for a [? NC ?] application.

00:10:52.460 --> 00:10:56.010
So next I want to talk about
actually applying those ideas

00:10:56.010 --> 00:11:03.449
or applying the cloud to
solve some of those problems.

00:11:03.449 --> 00:11:05.240
And so I'm going to do
kind of a case study

00:11:05.240 --> 00:11:08.590
and take those set
of requirements,

00:11:08.590 --> 00:11:11.920
and then actually try to create
an architecture that will

00:11:11.920 --> 00:11:13.710
satisfy those requirements.

00:11:13.710 --> 00:11:17.800
So the requirements for this
particular application that I'm

00:11:17.800 --> 00:11:19.834
going to do are pretty simple.

00:11:19.834 --> 00:11:21.750
It's just basically read
some temperature data

00:11:21.750 --> 00:11:25.916
from a large number of
devices for analysis later.

00:11:25.916 --> 00:11:27.540
And then we're going
to manage the info

00:11:27.540 --> 00:11:30.086
and status of each device.

00:11:30.086 --> 00:11:31.460
So if we read
these requirements,

00:11:31.460 --> 00:11:36.030
we can kind of see that the
types of data that I was

00:11:36.030 --> 00:11:37.330
talking about kind of pop out.

00:11:37.330 --> 00:11:39.300
So here we have the
temperature data

00:11:39.300 --> 00:11:40.540
would be our telemetry data.

00:11:40.540 --> 00:11:44.420
This is the data that
runs as a time series.

00:11:44.420 --> 00:11:46.494
And then info about
each device is metadata.

00:11:46.494 --> 00:11:47.910
And then the status
of each device

00:11:47.910 --> 00:11:49.980
could be seen as state, right?

00:11:49.980 --> 00:11:53.740
So let's go and actually
start trying to architect

00:11:53.740 --> 00:11:57.130
an application like this.

00:11:57.130 --> 00:12:01.350
So our architecture is
going to be pretty simple.

00:12:01.350 --> 00:12:02.780
I'm not going to use a gateway.

00:12:02.780 --> 00:12:07.330
Our device will actually connect
directly to the internet.

00:12:07.330 --> 00:12:09.615
So in that sense, it's
acting as its own gateway.

00:12:12.240 --> 00:12:14.446
And so when you look at
the overall architecture,

00:12:14.446 --> 00:12:15.320
it looks very simple.

00:12:15.320 --> 00:12:19.590
But if you actually drill in,
it can be a little bit more

00:12:19.590 --> 00:12:21.204
complicated.

00:12:21.204 --> 00:12:23.120
So there's a number of
things that you kind of

00:12:23.120 --> 00:12:24.310
have to think about.

00:12:24.310 --> 00:12:26.202
So on the device
side, you actually

00:12:26.202 --> 00:12:28.410
have to think about which
device you're going to use,

00:12:28.410 --> 00:12:29.910
like how you're going to
actually build the device,

00:12:29.910 --> 00:12:31.285
what sort of
sensors you're going

00:12:31.285 --> 00:12:34.375
to have on the device, as
well as the software that's

00:12:34.375 --> 00:12:35.500
going to run on the device.

00:12:35.500 --> 00:12:37.625
So you have to be able to
actually run the software

00:12:37.625 --> 00:12:40.050
or create the software that's
going to run on the device.

00:12:40.050 --> 00:12:43.490
What kind of software
is that going to be?

00:12:43.490 --> 00:12:45.910
Then you also on
the cloud side need

00:12:45.910 --> 00:12:48.170
to be able to
handle things like,

00:12:48.170 --> 00:12:50.670
say you're pretty telemetry
data and you're continuously

00:12:50.670 --> 00:12:52.330
sending that to the cloud.

00:12:52.330 --> 00:12:57.540
What if the wireless
is kind of flaky?

00:12:57.540 --> 00:13:01.180
How do you handle
that sort of thing?

00:13:01.180 --> 00:13:03.140
Also, how do you handle
the stream processing?

00:13:03.140 --> 00:13:05.499
Like if the device
sends data to the cloud

00:13:05.499 --> 00:13:07.540
and the cloud's not ready
to actually process it,

00:13:07.540 --> 00:13:09.682
how do you deal with that?

00:13:09.682 --> 00:13:11.390
So we're going to
actually deal with that

00:13:11.390 --> 00:13:13.110
by using a message queue.

00:13:13.110 --> 00:13:15.967
So a message queue is going to
take a message from our device.

00:13:15.967 --> 00:13:18.300
In this case it's going to
be telling us the temperature

00:13:18.300 --> 00:13:19.159
data in a message.

00:13:19.159 --> 00:13:20.950
And that's going to
get stored in the queue

00:13:20.950 --> 00:13:23.510
until the stream
processing system is ready.

00:13:23.510 --> 00:13:25.160
And then the string
processing system

00:13:25.160 --> 00:13:27.430
is going to take that data
from the message queue,

00:13:27.430 --> 00:13:29.430
and then write that to
our time series database.

00:13:31.670 --> 00:13:34.560
And then we're going to store
our state data and metadata

00:13:34.560 --> 00:13:37.705
in a state database.

00:13:37.705 --> 00:13:40.080
So I'm going to go through
all of these and actually kind

00:13:40.080 --> 00:13:44.415
of fill in what each one of
these are as we go along here.

00:13:44.415 --> 00:13:46.040
So the first thing
I want to talk about

00:13:46.040 --> 00:13:47.590
is the actual device.

00:13:47.590 --> 00:13:51.320
So for my little
application, I'm

00:13:51.320 --> 00:13:55.000
going to be using a BeagleBone.

00:13:55.000 --> 00:14:00.380
And so that's this device over
here, if I can switch over.

00:14:00.380 --> 00:14:01.910
So I have a little
device over here.

00:14:01.910 --> 00:14:05.367
This is a BeagleBone with some
temperature sensors on it.

00:14:05.367 --> 00:14:06.950
I'll show you that
a little bit later.

00:14:10.340 --> 00:14:16.260
So going back, the BeagleBone
is an open source mini computer

00:14:16.260 --> 00:14:17.130
that runs Linux.

00:14:17.130 --> 00:14:19.010
It's very similar to
kind of a Raspberry Pi

00:14:19.010 --> 00:14:20.920
if you're familiar with that.

00:14:20.920 --> 00:14:23.970
It's developed by Seed Studio.

00:14:23.970 --> 00:14:26.636
Or this particular one is
developed by Seed Studio.

00:14:26.636 --> 00:14:28.510
It's an open source one,
so if you wanted to,

00:14:28.510 --> 00:14:32.140
you could print these circuits
out yourself if you wanted to.

00:14:32.140 --> 00:14:35.010
But it comes with these really
cool connectors, these I2C

00:14:35.010 --> 00:14:38.990
and RS-232 connectors, which
make it easy to kind of plug

00:14:38.990 --> 00:14:44.040
into devices without actually
having to solder them.

00:14:44.040 --> 00:14:49.440
And Seed Studio also makes
some cool Grove sensors,

00:14:49.440 --> 00:14:52.550
which you can actually
plug into the BeagleBone.

00:14:52.550 --> 00:14:55.559
and then actually get
it to connect and work

00:14:55.559 --> 00:14:57.100
without actually
having to solder it,

00:14:57.100 --> 00:15:01.220
which is pretty cool for
doing some prototyping.

00:15:01.220 --> 00:15:07.390
So here I'm going to use this
analog to digital converter

00:15:07.390 --> 00:15:09.250
and a temperature sensor.

00:15:09.250 --> 00:15:11.560
So the temperature sensor
creates some analog data,

00:15:11.560 --> 00:15:13.143
and then that's going
to get converted

00:15:13.143 --> 00:15:18.430
to digital to actually go to the
Grove-- or to the BeagleBone,

00:15:18.430 --> 00:15:20.530
sorry.

00:15:20.530 --> 00:15:23.170
The next thing I want to
talk about is the software.

00:15:23.170 --> 00:15:27.084
So on the BeagleBone,
it runs Linux.

00:15:27.084 --> 00:15:28.500
And so what I'm
going to do is I'm

00:15:28.500 --> 00:15:32.510
going to create an
application on Node.js.

00:15:32.510 --> 00:15:34.010
And there's this
really cool library

00:15:34.010 --> 00:15:38.830
called the Johnny Five, which
is a JavaScript robotics and IoT

00:15:38.830 --> 00:15:40.230
platform.

00:15:40.230 --> 00:15:42.060
And it's got a really cool logo.

00:15:42.060 --> 00:15:45.620
And yeah, I picked
it for the logo.

00:15:45.620 --> 00:15:48.429
But it's got a really
cool interface.

00:15:48.429 --> 00:15:49.720
And it's written in JavaScript.

00:15:49.720 --> 00:15:52.530
And most people kind
of know JavaScript.

00:15:52.530 --> 00:15:55.640
And JavaScript is a heck of a
lot better than writing C++.

00:15:55.640 --> 00:15:59.240
So that's what I chose.

00:15:59.240 --> 00:16:02.940
So Johnny Five, like if you
actually write an application,

00:16:02.940 --> 00:16:04.140
it kind of looks like this.

00:16:04.140 --> 00:16:06.430
It's just regular JavaScript.

00:16:06.430 --> 00:16:10.940
So you can just require
the Johnny Five module.

00:16:10.940 --> 00:16:14.010
And then I'm also using
the BeagleBone I/O module,

00:16:14.010 --> 00:16:20.720
which is used to connect to the
interfaces on the BeagleBone.

00:16:20.720 --> 00:16:23.510
And then you can kind of
pass the BeagleBone objects

00:16:23.510 --> 00:16:27.680
to Johnny Five to
create a board object.

00:16:27.680 --> 00:16:35.070
And then you can set an on
ready signal or a function

00:16:35.070 --> 00:16:39.240
so that when the board is ready
you can actually run some code.

00:16:39.240 --> 00:16:40.770
So you'll set up the board.

00:16:40.770 --> 00:16:45.470
And then it will set up all
of the connectors and things

00:16:45.470 --> 00:16:46.936
like that on the board.

00:16:46.936 --> 00:16:49.560
And so when it's ready, then you
can actually run the function.

00:16:49.560 --> 00:16:50.934
So that's really
good so that you

00:16:50.934 --> 00:16:52.930
don't have to deal
with timing and things

00:16:52.930 --> 00:16:56.910
like that for when
you're actually

00:16:56.910 --> 00:16:58.017
running your application.

00:16:58.017 --> 00:16:59.600
So the next thing
that I'm going to do

00:16:59.600 --> 00:17:02.270
is I'm going to store
the state database state

00:17:02.270 --> 00:17:03.790
data in Firebase.

00:17:03.790 --> 00:17:07.369
So you might have heard about
Firebase from the keynote.

00:17:07.369 --> 00:17:10.130
Firebase is a
platform for creating

00:17:10.130 --> 00:17:13.050
mobile applications or
real time applications,

00:17:13.050 --> 00:17:14.359
especially mobile.

00:17:14.359 --> 00:17:15.900
But what's really
cool about it is it

00:17:15.900 --> 00:17:20.099
includes this NoSQL back end,
which is kind of JSON based.

00:17:20.099 --> 00:17:23.900
So it looks really a
lot like a JSON object

00:17:23.900 --> 00:17:26.460
and works like a JSON object.

00:17:26.460 --> 00:17:30.710
So it has kind of a tree
structure inside of it.

00:17:30.710 --> 00:17:34.330
And so I'm going to be
using this to actually store

00:17:34.330 --> 00:17:36.610
the state database
or state data.

00:17:36.610 --> 00:17:38.510
So as the application
is running,

00:17:38.510 --> 00:17:40.480
it will update the state data.

00:17:40.480 --> 00:17:43.410
So Firebase, you can kind
of connect to it like this.

00:17:43.410 --> 00:17:45.970
You require the Firebase module.

00:17:45.970 --> 00:17:48.160
And then you can
authenticate to it using

00:17:48.160 --> 00:17:50.550
the Firebase token generator.

00:17:50.550 --> 00:17:53.030
And then once you've
authenticated,

00:17:53.030 --> 00:17:55.850
you'll have a reference
to the database.

00:17:55.850 --> 00:18:00.990
And then you can use that to
set objects to the database.

00:18:00.990 --> 00:18:04.230
And right now I'm just
setting a whole JSON object

00:18:04.230 --> 00:18:06.850
to a particular key
in the database.

00:18:06.850 --> 00:18:09.220
And this is just going to
contain all of my sensor

00:18:09.220 --> 00:18:12.090
or my state data for the device.

00:18:12.090 --> 00:18:14.510
And so as I'm kind of looping
through the application,

00:18:14.510 --> 00:18:17.660
as it's reading data
from the device,

00:18:17.660 --> 00:18:20.420
it'll actually update
the state as well.

00:18:20.420 --> 00:18:22.820
So for the back end part,
for the telemetry data,

00:18:22.820 --> 00:18:25.772
I'm going to be
using Cloud Pub/Sub.

00:18:25.772 --> 00:18:27.480
So this is our messaging
queue that we're

00:18:27.480 --> 00:18:30.780
going to use to take
the telemetry data.

00:18:30.780 --> 00:18:34.296
We're then going to process
that data using Dataflow.

00:18:34.296 --> 00:18:36.170
And then we're going to
store the time series

00:18:36.170 --> 00:18:39.080
data in Cloud Bigtable.

00:18:39.080 --> 00:18:41.660
So I'll talk about each
one of these in turn.

00:18:41.660 --> 00:18:43.730
But what's really great
is that each one of these

00:18:43.730 --> 00:18:47.970
will scale to handle
a large amount of data

00:18:47.970 --> 00:18:49.080
coming into them.

00:18:49.080 --> 00:18:50.800
So each of these
independently scale,

00:18:50.800 --> 00:18:53.950
which will allow me to
handle many, many devices

00:18:53.950 --> 00:18:54.960
in the future.

00:18:54.960 --> 00:18:58.770
So Cloud Pub/Sub is just our
managed fully time messaging

00:18:58.770 --> 00:18:59.720
service.

00:18:59.720 --> 00:19:02.160
So it basically just acts
as a messaging queue.

00:19:02.160 --> 00:19:05.860
So you can put data
into the queue.

00:19:05.860 --> 00:19:11.300
And then on the outside
of it, the Dataflow

00:19:11.300 --> 00:19:13.100
will actually take
messages from the queue

00:19:13.100 --> 00:19:16.160
and then process
them as it's ready.

00:19:16.160 --> 00:19:19.980
So this will do a
lot to help kind

00:19:19.980 --> 00:19:26.830
of smooth out sending data from
the device to the processing

00:19:26.830 --> 00:19:28.850
system back end.

00:19:28.850 --> 00:19:34.740
And Dataflow is kind of a
unified programming model

00:19:34.740 --> 00:19:37.200
and managed service for
doing streaming data.

00:19:37.200 --> 00:19:41.990
So this is very similar to
something like Spark or Hadoop.

00:19:41.990 --> 00:19:44.090
Or it's kind of like an
in-between between them.

00:19:44.090 --> 00:19:47.400
But it's unified so that it
works with streaming or batch

00:19:47.400 --> 00:19:49.060
models.

00:19:49.060 --> 00:19:51.600
So in this case we're going
to use it for streaming,

00:19:51.600 --> 00:19:53.152
but you can also
use it for batch.

00:19:53.152 --> 00:19:54.610
Basically what you
do is you create

00:19:54.610 --> 00:19:59.240
kind of a pipeline with a
bunch of different steps.

00:19:59.240 --> 00:20:02.330
And each one of those
steps you define how

00:20:02.330 --> 00:20:04.230
to handle one piece of data.

00:20:04.230 --> 00:20:07.140
And then it kind of handles
how to scale that up

00:20:07.140 --> 00:20:09.530
and parallelize that for you.

00:20:09.530 --> 00:20:12.970
So we'll look at that
a little bit later.

00:20:12.970 --> 00:20:16.490
And then lastly Cloud
Bigtable is a NoSQL database

00:20:16.490 --> 00:20:20.760
that Google uses
internally for a lot

00:20:20.760 --> 00:20:23.570
of our core services
like Search and Analytics

00:20:23.570 --> 00:20:25.000
and Maps and Gmail.

00:20:25.000 --> 00:20:28.540
Essentially what it is a
key-value type of database,

00:20:28.540 --> 00:20:33.590
but the keys are kind of sorted
kind of lexicographically.

00:20:33.590 --> 00:20:37.390
So that's great for things
like time series data.

00:20:37.390 --> 00:20:42.010
It also maps from one
key to a row of data.

00:20:42.010 --> 00:20:44.160
So you can have multiple values.

00:20:44.160 --> 00:20:46.670
So each of those
are in a column.

00:20:46.670 --> 00:20:48.850
So what we can do is
you'll have a key,

00:20:48.850 --> 00:20:51.500
and then you could
map to any number

00:20:51.500 --> 00:20:55.392
of pieces of sensor data.

00:20:55.392 --> 00:20:57.600
In our case, we're just
going using temperature data.

00:20:57.600 --> 00:21:00.460
But you could imagine that you
could have many different types

00:21:00.460 --> 00:21:01.360
of sensor data.

00:21:04.080 --> 00:21:07.030
So on the application side,
in order to send to Pub/Sub,

00:21:07.030 --> 00:21:10.000
we're going to create
our thermometer object.

00:21:10.000 --> 00:21:12.160
This is a Johnny
Five object which

00:21:12.160 --> 00:21:20.270
will read data from the Grove
sensor every five seconds.

00:21:23.230 --> 00:21:27.120
And then basically we'll set a
callback on this thermometer.

00:21:27.120 --> 00:21:30.890
So when there's data available,
it'll run this function.

00:21:30.890 --> 00:21:35.470
And we'll just publish
that data to Cloud Pub/Sub.

00:21:35.470 --> 00:21:40.370
So here I'm sending the
data with our device

00:21:40.370 --> 00:21:45.210
ID and a channel and a timestamp
and the actual temperature

00:21:45.210 --> 00:21:47.830
data.

00:21:47.830 --> 00:21:52.320
So this just goes into Cloud
Pub/Sub as a JSON data.

00:21:52.320 --> 00:21:55.140
And then on the
Dataflow side, here we

00:21:55.140 --> 00:22:00.820
have a couple of things
to just set up Dataflow

00:22:00.820 --> 00:22:05.067
be able to read from Pub/Sub
and write to Cloud Bigtable.

00:22:05.067 --> 00:22:06.900
So these are just
basically objects that I'm

00:22:06.900 --> 00:22:09.730
going to create from
some command line

00:22:09.730 --> 00:22:15.000
arguments to tell Dataflow what
Pub/Sub topic I should use,

00:22:15.000 --> 00:22:16.460
what Bigtable
table I should use,

00:22:16.460 --> 00:22:18.950
and what Bigtable
cluster I should use.

00:22:18.950 --> 00:22:22.860
And then we'll actually
create a Dataflow pipeline.

00:22:22.860 --> 00:22:25.240
So this pipeline is just,
you create an object.

00:22:25.240 --> 00:22:26.390
This is Java code.

00:22:26.390 --> 00:22:29.510
So we just create a
pipeline from our objects

00:22:29.510 --> 00:22:31.220
or from our options.

00:22:31.220 --> 00:22:33.680
And then we're going to
create a three part pipeline.

00:22:33.680 --> 00:22:39.270
One is just a built in step
that we can use for Dataflow.

00:22:39.270 --> 00:22:43.652
This is Pub/Sub, or
to read from Pub/Sub.

00:22:43.652 --> 00:22:46.110
And then we're going to read
that using a JSON coder, which

00:22:46.110 --> 00:22:50.230
is allows us to reach JSON data.

00:22:50.230 --> 00:22:52.590
And then we're going to apply
this mutation transform,

00:22:52.590 --> 00:22:56.350
which is a transform that
I wrote in Java code.

00:22:56.350 --> 00:22:58.220
And then at the end
we're going to write

00:22:58.220 --> 00:23:01.360
to a particular table in
Bigtable based on the options

00:23:01.360 --> 00:23:01.860
that we had.

00:23:04.950 --> 00:23:08.020
So here's how I'm going to write
my actual mutation transform.

00:23:08.020 --> 00:23:12.570
So I can write code
for Cloud Dataflow that

00:23:12.570 --> 00:23:15.830
will define how to
process each record that

00:23:15.830 --> 00:23:18.430
comes in to Dataflow.

00:23:18.430 --> 00:23:20.900
So we're going to be
reading from Pub/Sub.

00:23:20.900 --> 00:23:23.370
So each message that
comes into Pub/Sub

00:23:23.370 --> 00:23:26.490
is going to be passed
to my transform.

00:23:26.490 --> 00:23:28.400
And then this process
element is going

00:23:28.400 --> 00:23:33.750
to be called in order to
actually process that.

00:23:33.750 --> 00:23:37.800
So going through that,
we're reading from the JSON

00:23:37.800 --> 00:23:41.230
object that was passed in.

00:23:41.230 --> 00:23:43.620
So we're reading a
single JSON object

00:23:43.620 --> 00:23:46.060
and all of the fields--
device ID, channel, timestamp,

00:23:46.060 --> 00:23:49.040
and data.

00:23:49.040 --> 00:23:50.840
And then we're going
to create a rowKey

00:23:50.840 --> 00:23:57.560
for Cloud Bigtable using our
device ID and the timestamp.

00:23:57.560 --> 00:24:00.750
And then we're going to create a
PUT request for Cloud Bigtable.

00:24:03.256 --> 00:24:04.630
And so now I'm
just going to loop

00:24:04.630 --> 00:24:08.150
through the keys that
were sent in the data.

00:24:08.150 --> 00:24:10.620
And in this case, it's
just the temperature data.

00:24:10.620 --> 00:24:13.750
But we're going to just
add that column to our row,

00:24:13.750 --> 00:24:16.870
and then finally
send the PUT request

00:24:16.870 --> 00:24:20.050
as output for our transform.

00:24:20.050 --> 00:24:24.070
So that's going to basically
just change our JSON object

00:24:24.070 --> 00:24:27.265
into a PUT request
for Cloud Bigtable.

00:24:31.280 --> 00:24:34.550
So now that I talked a
little bit about that,

00:24:34.550 --> 00:24:37.250
I'm going to jump over
to actually show you

00:24:37.250 --> 00:24:41.070
a working example of that.

00:24:41.070 --> 00:24:41.850
Let's see.

00:24:50.580 --> 00:24:55.720
So first, I want to
start my application.

00:24:55.720 --> 00:24:59.240
So here, I'm on my BeagleBone.

00:24:59.240 --> 00:25:01.500
And I'm going to
start my Node.js app.

00:25:01.500 --> 00:25:04.414
This takes a second to start up.

00:25:04.414 --> 00:25:05.830
But once that
starts up, we should

00:25:05.830 --> 00:25:08.410
be able to go into Firebase.

00:25:08.410 --> 00:25:15.222
I have my Firebase-- this is
actually the old console here.

00:25:15.222 --> 00:25:16.680
So once that actually
starts up, we

00:25:16.680 --> 00:25:19.930
should be able to see
that the state data starts

00:25:19.930 --> 00:25:22.330
getting updated into Firebase.

00:25:22.330 --> 00:25:25.060
And you can kind of see from the
management console in Firebase

00:25:25.060 --> 00:25:26.810
which fields are
actually getting updated.

00:25:26.810 --> 00:25:28.851
So here we can see that
the status of this sensor

00:25:28.851 --> 00:25:30.310
is pending.

00:25:30.310 --> 00:25:33.620
So once that gets starting, we
can see that it's now reading.

00:25:33.620 --> 00:25:38.760
And the temperature currently
is a nice 20 degrees Celsius.

00:25:38.760 --> 00:25:41.866
And I have this set up to
read every five seconds.

00:25:41.866 --> 00:25:43.740
So this timestamp will
get updated as well as

00:25:43.740 --> 00:25:44.406
the temperature.

00:25:48.660 --> 00:25:51.200
So now that I've got that,
I'm going to go ahead--

00:25:51.200 --> 00:25:53.650
this is actually reading data
and sending it to Pub/Sub.

00:25:53.650 --> 00:25:57.520
So Pub/Sub is kind of
queuing up that data.

00:25:57.520 --> 00:26:00.010
And then I can actually
start my Dataflow pipeline.

00:26:00.010 --> 00:26:03.080
So Dataflow, basically
in order to start it,

00:26:03.080 --> 00:26:05.080
you just write it like
a regular Java program.

00:26:05.080 --> 00:26:08.260
So here I'm just going to
use Maven to start it up.

00:26:08.260 --> 00:26:12.960
But there's also
an Eclipse plug-in

00:26:12.960 --> 00:26:16.730
that you can use to run Dataflow
jobs directly from Eclipse.

00:26:16.730 --> 00:26:20.110
So if you're an Eclipse
person, then that's

00:26:20.110 --> 00:26:21.860
definitely something
you should look into.

00:26:21.860 --> 00:26:23.443
But I'm kind of a
command line junkie,

00:26:23.443 --> 00:26:26.865
so I like to use
the command line.

00:26:26.865 --> 00:26:29.240
So if you run this, this will
actually start up Dataflow,

00:26:29.240 --> 00:26:32.800
and Dataflow will
actually start up some VMs

00:26:32.800 --> 00:26:36.510
on GCE, or on Compute Engine,
in order to actually run

00:26:36.510 --> 00:26:38.160
your processing.

00:26:38.160 --> 00:26:40.860
And that will kind
of scale up and down

00:26:40.860 --> 00:26:45.440
based on the number of
messages coming into Pub/Sub.

00:26:45.440 --> 00:26:47.740
But it takes a few minutes
to actually start those VMs.

00:26:47.740 --> 00:26:49.530
So I actually have
one running here.

00:26:49.530 --> 00:26:54.999
That's the cooking show
way of doing things.

00:26:54.999 --> 00:26:56.540
So I've got one
already running here.

00:27:02.990 --> 00:27:05.000
Let's go and look at Dataflow.

00:27:05.000 --> 00:27:10.260
So if you go into the cloud
console and you go to big data

00:27:10.260 --> 00:27:13.000
in to Dataflow, once
you've created a job,

00:27:13.000 --> 00:27:17.510
you can see it in the
list of jobs in Dataflow.

00:27:17.510 --> 00:27:19.100
And then if you
click on that job,

00:27:19.100 --> 00:27:22.600
you can actually see a
visualization of the steps

00:27:22.600 --> 00:27:23.820
within that job.

00:27:23.820 --> 00:27:25.370
So here, these are
the three steps

00:27:25.370 --> 00:27:29.100
that I created in
my Java program.

00:27:29.100 --> 00:27:31.440
So here it shows
the Pub/Sub read.

00:27:31.440 --> 00:27:37.320
This is the Java
transform that I wrote.

00:27:37.320 --> 00:27:41.100
And then this is the part to
actually write to Bigtable.

00:27:41.100 --> 00:27:43.430
So you could have any
number of permutations

00:27:43.430 --> 00:27:46.390
of how you actually create
a Dataflow pipeline.

00:27:46.390 --> 00:27:48.459
But I just kind of
created a simple one here.

00:27:48.459 --> 00:27:50.250
And it doesn't have to
be linear like this.

00:27:50.250 --> 00:27:53.180
You can actually have,
from my transform,

00:27:53.180 --> 00:27:57.210
I could actually have a step two
after it to write to Bigtable,

00:27:57.210 --> 00:27:59.630
but also write
to, say, BigQuery.

00:27:59.630 --> 00:28:02.881
So BigQuery is another
kind of analytical database

00:28:02.881 --> 00:28:04.630
that you could use to
store data, and then

00:28:04.630 --> 00:28:07.370
run SQL queries over it.

00:28:07.370 --> 00:28:09.340
So you could definitely
do things like that.

00:28:09.340 --> 00:28:12.576
That's kind of one of the
really great and flexible things

00:28:12.576 --> 00:28:13.200
about Dataflow.

00:28:19.380 --> 00:28:23.505
So just going back, and
then I have a little sort

00:28:23.505 --> 00:28:27.030
of visualization of the data.

00:28:30.070 --> 00:28:40.930
So if I go over here--
so this is a little app

00:28:40.930 --> 00:28:45.020
that kind of will query
Bigtable in real time

00:28:45.020 --> 00:28:50.079
to actually check to see
the temperature currently.

00:28:50.079 --> 00:28:51.120
So this is pretty boring.

00:28:51.120 --> 00:28:55.740
It's just basically
saying the same.

00:28:55.740 --> 00:28:59.570
But if we go over
here and we kind of

00:28:59.570 --> 00:29:01.350
squeeze this with my
finger, hopefully it

00:29:01.350 --> 00:29:08.150
should actually make the
temperature increase here.

00:29:08.150 --> 00:29:13.110
So I'm pretty hot today
I guess, 25 degrees.

00:29:16.916 --> 00:29:20.610
So you can kind of do these
sort of real time applications

00:29:20.610 --> 00:29:21.110
as well.

00:29:21.110 --> 00:29:24.080
So this is actually--
we'll show you

00:29:24.080 --> 00:29:25.700
kind of that the
data is actually

00:29:25.700 --> 00:29:29.050
going all the way through
the whole pipeline

00:29:29.050 --> 00:29:31.580
and actually ending up in
Bigtable, because we're

00:29:31.580 --> 00:29:34.780
actually doing a Bigtable
scan here to get the data.

00:29:41.840 --> 00:29:44.055
So I'm going to jump
back to the slides.

00:29:48.850 --> 00:29:52.530
So kind of just to
wrap up, I wanted

00:29:52.530 --> 00:29:54.240
to go through and
make sure that we

00:29:54.240 --> 00:29:56.060
checked all the boxes
for our requirements

00:29:56.060 --> 00:29:58.200
for our application.

00:29:58.200 --> 00:29:59.986
So we were able to
read the temperature

00:29:59.986 --> 00:30:00.860
data from the device.

00:30:04.509 --> 00:30:06.550
We were able to handle a
large number of devices,

00:30:06.550 --> 00:30:11.520
because each of the back end
pieces-- Pub/Sub, Dataflow,

00:30:11.520 --> 00:30:14.830
and Bigtable-- are only
able to scale and handle

00:30:14.830 --> 00:30:16.620
large number of devices.

00:30:16.620 --> 00:30:18.640
We're also able to
pull out and analyze

00:30:18.640 --> 00:30:21.940
that data using Bigtable.

00:30:21.940 --> 00:30:24.830
We can do that either
by scanning Bigtable,

00:30:24.830 --> 00:30:28.070
or we can develop, like
I said, other methods

00:30:28.070 --> 00:30:31.600
like writing
directly to BigQuery

00:30:31.600 --> 00:30:36.440
and then doing SQL queries on
it and doing analysis that way.

00:30:36.440 --> 00:30:39.220
And then we were also able
to manage the info and status

00:30:39.220 --> 00:30:42.280
of each device using Firebase.

00:30:42.280 --> 00:30:45.042
So these are a number of how
you could kind of put together

00:30:45.042 --> 00:30:47.000
different parts of the
cloud to actually create

00:30:47.000 --> 00:30:51.760
a full solution for managing
IoT devices or managing data.

00:30:51.760 --> 00:30:55.746
[MUSIC PLAYING]

