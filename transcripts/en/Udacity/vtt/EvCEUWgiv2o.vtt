WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:02.920
So now let's talk about the virtues of this

00:00:02.920 --> 00:00:06.110
link list based queuing lock. Some of virtues are

00:00:06.110 --> 00:00:09.040
exactly similar to the Anderson's queuing lock, and that

00:00:09.040 --> 00:00:11.780
is it is fair. And so Anderson's lock was also

00:00:11.780 --> 00:00:14.300
fair, ticket lock was also fair. The linked list

00:00:14.300 --> 00:00:18.190
queuing lock is also fair. And again, the spin location

00:00:18.190 --> 00:00:22.360
is unique for every spinner, right? Every spinner has

00:00:22.360 --> 00:00:25.370
a unique spin location to wait on and so that

00:00:25.370 --> 00:00:27.150
is similar to the Anderson's queue lock as

00:00:27.150 --> 00:00:30.650
well. And that's good because you're not causing contention

00:00:30.650 --> 00:00:33.430
on the network when the lock is released. When

00:00:33.430 --> 00:00:36.490
one guy releases the lock, others if they're waiting,

00:00:36.490 --> 00:00:39.180
they don't, they don't get bothered by by the,

00:00:39.180 --> 00:00:43.140
by the signal. And exactly one processor gets signaled

00:00:43.140 --> 00:00:46.160
when the lock is released. That's also good. And

00:00:46.160 --> 00:00:50.610
usually, there's only one atomic operation per critical section.

00:00:50.610 --> 00:00:52.970
And the only thing that happens is this corner case.

00:00:52.970 --> 00:00:55.870
In order to implement this corner case, you have to

00:00:55.870 --> 00:00:59.350
use a second atomic operation. But if the link list

00:00:59.350 --> 00:01:02.420
has several members in this, in these examples. I'm just

00:01:02.420 --> 00:01:05.550
showing only two requesters at a time. But if the

00:01:05.550 --> 00:01:08.940
link list has a number of requesters, then if I

00:01:08.940 --> 00:01:12.470
am middle of the gang, have, using the lock, I

00:01:12.470 --> 00:01:15.960
simply signal the successor. I don't have to do anything fancy

00:01:15.960 --> 00:01:19.110
in terms of compare and swap. So this is something

00:01:19.110 --> 00:01:22.090
that needs to be done only for the corner case, not

00:01:22.090 --> 00:01:25.520
as a, a routine for doing the unlock operation. And

00:01:25.520 --> 00:01:27.740
the other good thing that we already mentioned is that the

00:01:27.740 --> 00:01:31.280
space complexity of this data structure is proportional to the

00:01:31.280 --> 00:01:34.450
number of requesters to the lock at any point of time.

00:01:34.450 --> 00:01:37.193
So it is dynamic. It's not statically defined as in

00:01:37.193 --> 00:01:41.040
the array-based queueing lock. And so that's one of the biggest

00:01:41.040 --> 00:01:45.110
virtues of this particular algorithm that the space

00:01:45.110 --> 00:01:47.940
complexity is bound by the number of dynamic

00:01:47.940 --> 00:01:50.370
requests to a particular lock, and not the

00:01:50.370 --> 00:01:53.950
size of the multi-processor itself. Now the downside

00:01:53.950 --> 00:01:58.430
to this link list based queuing lock of course is the fact that there is link

00:01:58.430 --> 00:02:01.660
list maintenance overhead that is associated with making

00:02:01.660 --> 00:02:06.350
a lock request or unlock request. And Anderson's [INAUDIBLE]

00:02:06.350 --> 00:02:08.800
queue lock because it is in a irregular structure

00:02:08.800 --> 00:02:13.240
can be slightly faster than this, link list based algorithm.

00:02:13.240 --> 00:02:14.950
And one of the things that I should mention

00:02:14.950 --> 00:02:18.270
to that is that both Anderson's [UNKNOWN] queue lock as

00:02:18.270 --> 00:02:23.300
well as the NCS link list based, queue lock.

00:02:23.300 --> 00:02:26.230
May result in poorer performance if the architecture does not

00:02:26.230 --> 00:02:28.940
support fancy instructions like this, because they have to

00:02:28.940 --> 00:02:32.140
be simulated using test and set, so that can be

00:02:32.140 --> 00:02:34.810
a little detriment to to this particular

00:02:34.810 --> 00:02:37.400
algorithm as well. We have discussed different

00:02:37.400 --> 00:02:39.545
algorithms for implementing locks in a shared

00:02:39.545 --> 00:02:43.790
memory multi processor. If the processor has some

00:02:43.790 --> 00:02:46.430
form of affection free operation, then the

00:02:46.430 --> 00:02:49.570
two flavors of queue based locks, both due

00:02:49.570 --> 00:02:57.170
to Anderson and MCS, they are good bet for scalability. If on the other hand,

00:02:57.170 --> 00:02:59.920
the processor only has test and set, then an

00:02:59.920 --> 00:03:03.400
exponential backoff algorithm would be a good bet for scalability.

