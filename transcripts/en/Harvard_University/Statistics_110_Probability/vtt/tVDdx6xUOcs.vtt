WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:02.010
Well let's get started.

00:00:02.010 --> 00:00:06.870
Thanks for coming despite the rain, but at

00:00:06.870 --> 00:00:12.020
least we can feel lucky that the sun rose
today cuz we have a lot more to do and

00:00:12.020 --> 00:00:14.870
it would be hard to do if
the sun stopped rising.

00:00:14.870 --> 00:00:18.530
So, okay, so
we were talking about MGFs last time.

00:00:18.530 --> 00:00:22.650
We've done all the theory that we need for
MGFs but I'm not sure

00:00:22.650 --> 00:00:26.800
that the intuition is clear enough yet
and there are some important examples.

00:00:26.800 --> 00:00:29.580
So I just want to start with
a few examples of MGFs.

00:00:29.580 --> 00:00:31.860
We already have all the theorems.

00:00:31.860 --> 00:00:36.550
Okay, especially,
how do we work with MGFs for

00:00:36.550 --> 00:00:41.920
some of the most important distributions
such as exponential, normal, and Poisson?

00:00:41.920 --> 00:00:45.030
Just to show you how
the MGFs are useful for

00:00:45.030 --> 00:00:47.910
some of those famous distributions, okay.

00:00:47.910 --> 00:00:49.170
So let's start with the exponential.

00:00:50.660 --> 00:00:59.203
And [COUGH] we talked before about,
So this is the Expo MGF.

00:00:59.203 --> 00:01:03.457
We talked before about the fact that if we
have exponential lambda we can always find

00:01:03.457 --> 00:01:06.240
a constant to multiply by
to make it exponential one.

00:01:06.240 --> 00:01:09.749
So let's just start with the exponential
one case cuz that's simpler,

00:01:09.749 --> 00:01:11.024
hat is lambda equals one.

00:01:12.270 --> 00:01:14.737
Let x be exponential one, and

00:01:14.737 --> 00:01:20.080
suppose that we wanna find find MGF and
find the moments, okay.

00:01:21.930 --> 00:01:23.247
Find moments.

00:01:25.843 --> 00:01:30.430
And this will really show you why it's
called the moment generating function.

00:01:30.430 --> 00:01:31.510
That doesn't actually,

00:01:31.510 --> 00:01:34.730
I didn't actually talk about where
did the word moment come from?

00:01:34.730 --> 00:01:36.240
It comes from physics.

00:01:36.240 --> 00:01:38.740
Those of you who've done
moment of inertia and stuff,

00:01:38.740 --> 00:01:43.710
there's actually a pretty strong analogy
between variance and moment of inertia.

00:01:43.710 --> 00:01:47.340
That doesn't answer the question for where
did the word moment come from in physics,

00:01:47.340 --> 00:01:49.150
but you can ask the physicist that.

00:01:49.150 --> 00:01:52.870
But it came into statistics via physics
because of this analogy with moment

00:01:52.870 --> 00:01:54.250
of inertia.

00:01:54.250 --> 00:01:59.769
Anyway, so we have an exponential,
okay, and so let's find the MGF.

00:01:59.769 --> 00:02:05.270
Well by lotus that's
a pretty easy calculation.

00:02:05.270 --> 00:02:11.822
M(t), remember just by definition it's
just the expected value of (e to the tx).

00:02:11.822 --> 00:02:15.990
And this is a perfectly
valid thing to write down.

00:02:15.990 --> 00:02:19.360
This (e tx), that's just some random,
we're taking it's expectation,

00:02:19.360 --> 00:02:22.100
and then we're viewing
this as a function of t.

00:02:22.100 --> 00:02:27.460
And I pointed out last time, t is a dummy
variable, so I could of just as well said

00:02:27.460 --> 00:02:33.316
M(s) = expected (e to the sx), or whatever
you wanna call it that doesn't clash.

00:02:33.316 --> 00:02:36.263
[COUGH] The interpretation
is just that this is a very,

00:02:36.263 --> 00:02:39.931
very useful bookkeeping device for
keeping track of moments, and

00:02:39.931 --> 00:02:43.942
it's another way to describe distribution,
rather than a CDF or a PDF.

00:02:43.942 --> 00:02:45.800
Okay, so let's just compute this thing.

00:02:45.800 --> 00:02:51.744
Well this is an easy lotus problem
cuz by lotus we can just immediately

00:02:51.744 --> 00:02:57.596
say this is the integral 0 to infinity,
e to the tx, e to the -x dx.

00:02:59.921 --> 00:03:04.894
All right,
that's just immediate from lotus,

00:03:04.894 --> 00:03:11.941
combine the two exponentials,
so that's e to the -x(1-t) dx.

00:03:11.941 --> 00:03:14.530
So that's just an easy integral, right.

00:03:16.240 --> 00:03:21.079
So that integral, well actually one way
to do it is just to do the integral.

00:03:21.079 --> 00:03:25.065
Another way to do this integral is to
recognize this as another exponential

00:03:25.065 --> 00:03:29.340
PDF with a different parameter and
put it in the normalizing constant.

00:03:29.340 --> 00:03:36.241
And you'll get 1 over 1- t,
and this is for t less than 1.

00:03:36.241 --> 00:03:39.240
If t is bigger than 1,
we have some problems here.

00:03:39.240 --> 00:03:44.145
Cuz if you let t be 2 for example,
then that would 1- 2 is -1.

00:03:44.145 --> 00:03:47.350
You'd get e to the +x,
which would blow up.

00:03:47.350 --> 00:03:50.380
But as long as t is less than 1,
this will be okay.

00:03:50.380 --> 00:03:52.490
Exponential decay, not exponential growth.

00:03:53.570 --> 00:03:56.120
So we have to assume t is less than 1.

00:03:56.120 --> 00:04:00.540
But that's okay, cuz we talked last time
about the fact that we wanted to have some

00:04:00.540 --> 00:04:05.220
interval, I called it -a to
a on which this is finite.

00:04:05.220 --> 00:04:09.375
So in this this case it's finite
everywhere to the left of 1, right.

00:04:09.375 --> 00:04:12.685
So in particular it could take
some interval like say -1

00:04:12.685 --> 00:04:16.135
to 1 open interval on which it's finite.

00:04:16.135 --> 00:04:18.988
So this is a perfectly valid MGF.

00:04:18.988 --> 00:04:25.035
Okay, so
now we wanna get the moments, right.

00:04:25.035 --> 00:04:32.090
So from what I said last time,
we could take this thing 1 over 1-t and

00:04:32.090 --> 00:04:36.150
start taking derivatives,
so, and plug in 0.

00:04:36.150 --> 00:04:40.542
So would be true that M'(0)
would be the mean and

00:04:40.542 --> 00:04:45.100
M''(0) would be the second moment.

00:04:46.360 --> 00:04:50.190
And once we have this and
this we could easily get the variance.

00:04:50.190 --> 00:04:54.490
We already talked about the mean and the
variance of the exponentials, so you could

00:04:54.490 --> 00:04:59.520
do this and check that it agrees with
what we did earlier through lotus, okay.

00:04:59.520 --> 00:05:03.348
And then third moment would be the third

00:05:03.348 --> 00:05:08.870
derivative evaluated at 0,
and so on, right.

00:05:08.870 --> 00:05:10.600
So we could do that, but

00:05:10.600 --> 00:05:14.550
that's kind of annoying in the sense that
you have to keep taking derivatives.

00:05:14.550 --> 00:05:18.800
Now for this function, taking a bunch
of derivatives is not too bad, okay.

00:05:18.800 --> 00:05:24.930
But it's still a much better way to do
this, Is to recognize the pattern, right.

00:05:24.930 --> 00:05:27.990
A lot of this is about
pattern recognition, okay.

00:05:29.400 --> 00:05:31.992
Where have we seen 1 over 1-t before?

00:05:34.350 --> 00:05:36.650
Geometric series, right.

00:05:36.650 --> 00:05:39.660
We keep using the Taylor series for
e to the x and geometric series over and

00:05:39.660 --> 00:05:40.310
over again.

00:05:40.310 --> 00:05:42.250
It can go in both directions, right.

00:05:42.250 --> 00:05:47.270
You can have the geometric series result
and write it as a geometric series or

00:05:47.270 --> 00:05:49.269
you can have a geometric series and
simplify it to this.

00:05:50.420 --> 00:05:52.520
Anytime you see one over
one minus something,

00:05:52.520 --> 00:05:56.666
you should be thinking that may have
something to do with the geometric series.

00:05:56.666 --> 00:05:59.217
That may be a useful interpretation,
it may not, but

00:05:59.217 --> 00:06:03.033
at least the idea should pop into your
mind just cuz you see this pattern, okay.

00:06:03.033 --> 00:06:11.045
So if we do that we get 1 over 1-t
equals just a geometric series,

00:06:11.045 --> 00:06:15.350
a sum t to the n, n=0 to infinity.

00:06:16.430 --> 00:06:21.668
And this is valid for t greater than,
for absolute value of t less than 1.

00:06:23.097 --> 00:06:25.080
That's when this converges.

00:06:25.080 --> 00:06:28.580
By writing it this way,
we don't actually have to do derivatives.

00:06:28.580 --> 00:06:32.960
We're just looking at this series,
okay, and

00:06:32.960 --> 00:06:37.131
then we're just gonna
read off the moments.

00:06:37.131 --> 00:06:39.770
So the only thing we have to be
careful about is the n factorial.

00:06:39.770 --> 00:06:44.713
Because I said with the MGF,
you take the Taylor expansion and

00:06:44.713 --> 00:06:49.765
the moment is whatever is in front
of t to the n over n factorial.

00:06:49.765 --> 00:06:53.150
I don't see an n factorial here,
but that's no problem, right.

00:06:53.150 --> 00:06:53.910
We just multiply and

00:06:53.910 --> 00:06:56.830
divide by n factorial,
cuz we need the n factorial there.

00:06:58.660 --> 00:07:04.390
So I'll multiply by n factorial
t to the n over n factorial.

00:07:04.390 --> 00:07:07.810
Now this matches exactly the pattern
that we talked about last time,

00:07:07.810 --> 00:07:13.030
about what ever's in front of the t to the
n over n factorial, that's the nth moment.

00:07:13.030 --> 00:07:14.370
So that's the nth moment.

00:07:15.720 --> 00:07:21.530
So we immediately know now that E(x
to the n)=n factorial for all n.

00:07:21.530 --> 00:07:23.260
So instead of taking derivatives over and

00:07:23.260 --> 00:07:29.240
over again, we simultaneously
get all the moments of x, okay.

00:07:29.240 --> 00:07:31.580
So that's nice, right.

00:07:31.580 --> 00:07:33.503
Didn't need to take any derivatives.

00:07:38.015 --> 00:07:42.718
So, by the way, that's kind of like
the coolest thing about MGFs is

00:07:42.718 --> 00:07:48.570
the fact that if you, just in general,
not necessarily for this example.

00:07:48.570 --> 00:07:53.800
If you wanna find the moments
of some distribution by lotus,

00:07:53.800 --> 00:07:55.640
you would think you have to integrate,
right.

00:07:55.640 --> 00:07:59.610
You want e of x to the n so you're going
to integrate x to the n times the PDF.

00:07:59.610 --> 00:08:02.348
That may be an incredibly
difficult integral.

00:08:02.348 --> 00:08:06.700
But the MGFs, once you have the MGF,
we're taking derivatives not integrals.

00:08:06.700 --> 00:08:09.270
So it's pretty surprising
to me at least that you can

00:08:09.270 --> 00:08:13.780
do derivatives of the MGF rather
than the integrals of powers of X.

00:08:13.780 --> 00:08:18.307
Derivatives are much easier usually than
integrals, so that can save a lot of work.

00:08:19.727 --> 00:08:24.329
So let's just quickly see what
happens if it's exponential lambda,

00:08:24.329 --> 00:08:26.750
where lambda is not necessarily 1.

00:08:26.750 --> 00:08:30.969
So now let's let Y be exponential lambda.

00:08:32.958 --> 00:08:36.888
And then, let's just convert it,
just to see how to apply this.

00:08:39.371 --> 00:08:41.313
Convert it, well, exponential, so

00:08:41.313 --> 00:08:45.014
we talked before about the fact that
if you multiply or divide by lambda,

00:08:45.014 --> 00:08:48.980
it may be hard to remember, should you
multiply by lambda or divide lambda?

00:08:48.980 --> 00:08:50.860
But there's an easy way to see that.

00:08:50.860 --> 00:08:55.442
Let's just let X =, Lambda Y.

00:08:58.909 --> 00:09:02.409
So I need to multiply by lambda
rather than dividing because we know

00:09:02.409 --> 00:09:05.340
the exponential lambda
has mean 1 over lambda.

00:09:05.340 --> 00:09:07.820
So if we multiply by lambda
now this has a mean 1.

00:09:07.820 --> 00:09:11.542
And we show that this is,
in fact, exponential of 1.

00:09:11.542 --> 00:09:13.180
So we've converted it to this case.

00:09:14.500 --> 00:09:19.793
In other words, Y = X over lambda,
and we can take nth powers.

00:09:21.665 --> 00:09:25.890
So now we immediately have to
moment of the nth moment of Y.

00:09:25.890 --> 00:09:30.902
Expected value Y to be n = expected
value of X to the n which is n!,

00:09:30.902 --> 00:09:33.013
divided by lambda to the n.

00:09:34.958 --> 00:09:39.900
Okay, so I didn't do any calculus here.

00:09:39.900 --> 00:09:41.858
I only used the geometric series.

00:09:43.868 --> 00:09:48.522
We could have directly done something
similar to this for Y, but I think

00:09:48.522 --> 00:09:54.040
it's easier working with the exponential
one and then converting it back.

00:09:54.040 --> 00:09:56.170
Similarly, at the end of last time,

00:09:56.170 --> 00:09:59.720
we derived the MGF of the standard normal,
okay?

00:09:59.720 --> 00:10:02.690
Now if you want any
normal mu sigma squared,

00:10:02.690 --> 00:10:05.380
then you just write a mu plus sigma z,
right?

00:10:05.380 --> 00:10:08.630
Then you can get its MGF very easily.

00:10:08.630 --> 00:10:10.724
So a lot of times it's easier to
work with the standard normal.

00:10:12.248 --> 00:10:17.151
Okay, so speaking of standard normal,
let's actually get the normal moments now.

00:10:19.567 --> 00:10:21.021
We already know the odd moments.

00:10:22.391 --> 00:10:30.778
So the problem is let Z be standard
normal, And find all its moments.

00:10:35.605 --> 00:10:36.385
Okay?

00:10:39.617 --> 00:10:41.973
We already know that
the first moment is 0 and

00:10:41.973 --> 00:10:45.540
the second moment is 1 cuz
it's mean 0 variance 1.

00:10:45.540 --> 00:10:47.962
We already know that
the odd moments are all 0.

00:10:52.624 --> 00:10:58.268
That's just by symmetry, we mentioned
that fact before but you should check for

00:10:58.268 --> 00:11:02.846
yourself that that makes sense,
that to practice the symmetry.

00:11:05.002 --> 00:11:07.613
Because if you write down
the integral using LOTUS,

00:11:07.613 --> 00:11:10.937
you would be integrating an odd
function symmetrically about 0 so

00:11:10.937 --> 00:11:13.590
the negative area cancels
the positive area.

00:11:13.590 --> 00:11:16.830
So don't need to do any work to get this,
just use symmetry.

00:11:16.830 --> 00:11:19.930
Even moments, though,
that seems pretty hard.

00:11:19.930 --> 00:11:25.962
And we already know E of Z squared, and
we did that by doing some integrations.

00:11:25.962 --> 00:11:29.160
Now if we want E of Z to the forth,
if we use LOTUS,

00:11:29.160 --> 00:11:33.693
you're gonna have to integrate Z to
the fourth times the normal PDF.

00:11:33.693 --> 00:11:36.080
How do you do that integral?

00:11:36.080 --> 00:11:40.168
I don't know, I mean, you can try doing
some substitutions, you can try doing

00:11:40.168 --> 00:11:44.391
integration by parts and you can easily
spend a couple hours doing that integral.

00:11:44.391 --> 00:11:47.843
And it's possible to do it, but
it's not easy, it'll be a lot of work.

00:11:47.843 --> 00:11:50.197
And that would just be the fourth moment,
and then you'll say well,

00:11:50.197 --> 00:11:51.220
what about the sixth moment?

00:11:51.220 --> 00:11:53.010
What about the eighth moment, right?

00:11:53.010 --> 00:11:56.070
So that's not a very
efficient way to do things,

00:11:56.070 --> 00:11:58.319
it's doing a lot of
nasty looking integrals.

00:11:59.470 --> 00:12:02.660
Okay, so let's use the MGF instead.

00:12:02.660 --> 00:12:06.566
The MGF that we derived last time is

00:12:06.566 --> 00:12:11.824
the function M of t = e
to the t squared over 2.

00:12:14.686 --> 00:12:19.154
So that at least gives us an approach to
getting the moments that doesn't involve

00:12:19.154 --> 00:12:22.188
having to figure out how to
do these integrals, okay?

00:12:22.188 --> 00:12:24.407
It's something more straightforward.

00:12:24.407 --> 00:12:28.684
Like for derivatives, we have the chain
rule, the product rule and so on.

00:12:28.684 --> 00:12:33.094
There's no chance that you can't do this
derivative if you know your chain rule and

00:12:33.094 --> 00:12:35.310
product rule, and stuff like that.

00:12:35.310 --> 00:12:39.895
Whereas for integration, you may just
not know how to do the integral, okay?

00:12:39.895 --> 00:12:42.999
So we could take the derivative of this,
use the chain rule.

00:12:42.999 --> 00:12:48.732
And we're gonna get a t that comes out
in front because of the chain rule.

00:12:48.732 --> 00:12:50.525
And then we take the second derivative,

00:12:50.525 --> 00:12:53.753
because then there's gonna be a t out
there after the first derivative.

00:12:53.753 --> 00:12:56.528
Then we will have to use the product rule,
okay.

00:12:56.528 --> 00:13:00.296
And then we take another derivative,
then we have 2 terms and

00:13:00.296 --> 00:13:04.580
then terms start multiplying and
get more and more terms to deal with.

00:13:04.580 --> 00:13:08.580
And it'll get more and more tedious and
ugly, the more derivatives we took.

00:13:08.580 --> 00:13:10.696
It's still something that you can do.

00:13:10.696 --> 00:13:16.050
It's pretty mechanical, but it's tedious,
and we wanna avoid tedious stuff, okay.

00:13:16.050 --> 00:13:17.838
So here's a much better
way to think about it.

00:13:20.298 --> 00:13:22.134
Over there with the exponential,

00:13:22.134 --> 00:13:25.500
I emphasized just the pattern
recognition geometric series.

00:13:26.851 --> 00:13:29.890
Let's apply the same thinking again.

00:13:29.890 --> 00:13:34.440
Pattern recognition,
this is e to a power, okay?

00:13:34.440 --> 00:13:36.660
Unlike the geometric series,
the Taylor series for

00:13:36.660 --> 00:13:38.670
e to the x converges everywhere.

00:13:39.820 --> 00:13:42.530
So I can immediately just write
down the Taylor series for this,

00:13:42.530 --> 00:13:44.550
without taking any derivatives.

00:13:44.550 --> 00:13:52.710
This is just the sum of t squared
over 2 to the n over n!, right.

00:13:52.710 --> 00:13:56.627
Because the Taylor series for e to the x
is valid everywhere, so in particular,

00:13:56.627 --> 00:13:58.510
I can plug in t squared over 2, okay?

00:13:58.510 --> 00:14:00.867
So this is a much,
much better way to do it,

00:14:00.867 --> 00:14:03.228
than to start taking derivatives of this.

00:14:03.228 --> 00:14:08.839
So let's simplify this, this is the sum,
notice that we're only gonna get

00:14:08.839 --> 00:14:14.022
even powers of t, which makes sense
because this is an even function.

00:14:16.115 --> 00:14:21.747
So it's gonna be t to the 2n, And,

00:14:21.747 --> 00:14:27.848
there's a 1 over 2 to the n in
the denominator and there's an n!.

00:14:31.215 --> 00:14:33.510
Okay, so that's what it is.

00:14:33.510 --> 00:14:37.490
Now, same as over there,
we just have to read off the moments.

00:14:37.490 --> 00:14:40.120
The only thing you have to be careful
about is the fact that there's a 2n here

00:14:40.120 --> 00:14:43.940
in the exponent, and there's an n!, there.

00:14:45.000 --> 00:14:48.008
So there's kind of a mismatch right now,
okay?

00:14:48.008 --> 00:14:55.594
We want the 2n moment because 2n
is just an arbitrary even number.

00:14:55.594 --> 00:14:59.006
Okay, we want the 2n moment,
so the 2n moment,

00:14:59.006 --> 00:15:02.680
we want the coefficient
t to the 2n over 2n!.

00:15:02.680 --> 00:15:03.560
We don't have a 2n!.

00:15:04.690 --> 00:15:06.920
Well that's okay, just put in 2n!.

00:15:08.980 --> 00:15:10.948
As long as we multiply by that, it's okay.

00:15:10.948 --> 00:15:16.215
So I just multiplied and divided by 2n!,
that immediately tells use the answer.

00:15:17.922 --> 00:15:22.321
The expected value of Z to the 2n, so
that's just an arbitrary even moment,

00:15:22.321 --> 00:15:28.760
we already have the odd moments, Is just
the coefficient of t to the 2n over 2n!.

00:15:28.760 --> 00:15:29.680
That's everything that's left.

00:15:29.680 --> 00:15:34.805
That's 2n!, over 2 to the n n!.

00:15:39.896 --> 00:15:45.631
And let's just check whether this
makes sense in the cases we know.

00:15:45.631 --> 00:15:51.381
If n = 1, N = 1,

00:15:51.381 --> 00:15:55.471
this is 2!, over 2 times 2,

00:15:55.471 --> 00:15:59.110
when n = 1, so 2 times 1.

00:15:59.110 --> 00:16:04.350
Okay, so So
that's 2 divided by 2 times 1 is 1.

00:16:04.350 --> 00:16:08.235
So E(Z-squared) = 1, and that's what
we expected because the variance is 1.

00:16:08.235 --> 00:16:12.656
And let's just do a couple more, n = 2, so

00:16:12.656 --> 00:16:16.970
then get the fourth moment,
z to the fourth.

00:16:16.970 --> 00:16:21.113
n = 2, four factorial is 24 divided by 8,

00:16:21.113 --> 00:16:25.489
24 divide by 8 is 3,
so the 4th moment is 3.

00:16:27.865 --> 00:16:33.513
And the next one E(Z to the 6th)

00:16:33.513 --> 00:16:38.164
is gonna be 3.5 = 15.

00:16:38.164 --> 00:16:41.100
And you'll see,
alright as 1 times 3 times 5.

00:16:41.100 --> 00:16:45.866
You'll see the pattern as, if it's 1,
1 times 3, 1 times 3 times 5,

00:16:45.866 --> 00:16:48.570
1 times 3 times 5 times 7 and so on.

00:16:48.570 --> 00:16:52.228
And this is not the first time
that we've seen these numbers, or

00:16:52.228 --> 00:16:56.447
at least if you've done the strategic
practice problems going way back.

00:16:56.447 --> 00:17:00.671
That was the number of ways to break two
n people into end to end partnerships and

00:17:00.671 --> 00:17:02.670
there's a story problem there.

00:17:02.670 --> 00:17:06.736
We could either write it this way,
or as a product of odd numbers.

00:17:06.736 --> 00:17:11.635
So kind of a surprising fact,
or at least I found it really

00:17:11.635 --> 00:17:16.265
surprising that the same expression
comes up for even moments of the normal.

00:17:16.265 --> 00:17:21.125
As it's the same number as breaking
up people into partnerships and

00:17:21.125 --> 00:17:23.080
counting number of ways to do that.

00:17:23.080 --> 00:17:27.220
And I thought that was kind of mysterious,
it turns out that it's not a coincidence.

00:17:27.220 --> 00:17:30.460
But there's this kind of a very
deep combinatorial explanation for

00:17:30.460 --> 00:17:34.460
that which I can't get into but
there is a reason for that.

00:17:34.460 --> 00:17:38.940
Anyway, that gives us all the moments
of the normal distribution now

00:17:38.940 --> 00:17:42.140
without doing any calculus.

00:17:42.140 --> 00:17:45.430
So that's nice, okay?

00:17:45.430 --> 00:17:49.810
So one more MGF problem,
we haven't talked it yet in class,

00:17:49.810 --> 00:17:53.730
the MGF of the Poisson distribution,
so let's do that.

00:18:01.610 --> 00:18:07.010
So you know Poisson, we know that
the mean is, the Poisson lambda, we know

00:18:07.010 --> 00:18:11.100
it has mean lambda and variance lambda,
but we haven't computed any other moments.

00:18:12.210 --> 00:18:14.691
But mainly for the Poisson,
I wanted to show you the other,

00:18:14.691 --> 00:18:18.180
like I said last time that there are three
reasons why the MGF is important.

00:18:18.180 --> 00:18:22.340
And those examples to illustrate
the fact why it's a moment generating,

00:18:22.340 --> 00:18:25.450
cuz we generated all the moments.

00:18:25.450 --> 00:18:29.620
But for the Poisson I wanna show
you the other important reasons.

00:18:29.620 --> 00:18:34.910
So let's let x be Poisson lambda and
find its MGF again.

00:18:36.900 --> 00:18:40.890
Well, let's just use LOTUS,
the expected value

00:18:40.890 --> 00:18:45.890
of E(e to tx) = the sum, so

00:18:45.890 --> 00:18:51.350
Poisson takes non-negative integer values
so I'll just say k equals 0 infinity.

00:18:52.760 --> 00:18:58.724
e to the tk, all right it's just LOTUS,
e to the mn times the Poisson pmf,

00:18:58.724 --> 00:19:03.266
e to the minus lambda,
lambda to the k over k factorial.

00:19:04.595 --> 00:19:08.420
Okay, looks like a kind of ugly sum.

00:19:08.420 --> 00:19:14.105
But actually you'll find that this sum is
an example on the math review handout,

00:19:14.105 --> 00:19:17.035
so I was planning for in advance.

00:19:17.035 --> 00:19:20.145
But you don't have to memorize that or
anything,

00:19:20.145 --> 00:19:24.605
this is just another example of pattern
recognition dealing with a series.

00:19:24.605 --> 00:19:26.850
It looks a little ugly
when you first see it but

00:19:26.850 --> 00:19:30.411
this is actually easy once you're
familiar with the pattern, right?

00:19:30.411 --> 00:19:34.693
So either the minus lambda comes
out cause that's just a constant,

00:19:34.693 --> 00:19:36.580
look at what's left inside.

00:19:37.630 --> 00:19:41.880
We have, this is either the t to the k and
this is lambda to the k, so

00:19:41.880 --> 00:19:46.370
together that's lambda e
to the t to the k, right?

00:19:46.370 --> 00:19:51.390
So all that's left is the sum of
something to the k over k factorial.

00:19:51.390 --> 00:19:53.920
That's just the the Taylor series for
e to the x again.

00:19:53.920 --> 00:19:57.960
So this is very easy once you've mastered
the Taylor series for e to the x.

00:19:57.960 --> 00:20:03.935
So and just immediately write that down,
that is the Taylor Series for

00:20:03.935 --> 00:20:08.200
e to the x evaluated at x
= lambda e to the t, okay?

00:20:09.350 --> 00:20:13.460
So we can simplify that a little bit,
it's e to the lambda e to the t- 1.

00:20:13.460 --> 00:20:17.570
So that's the Poisson MGF

00:20:21.030 --> 00:20:26.355
and it's valid for all values of t
because the series converges for all t.

00:20:26.355 --> 00:20:29.800
Okay, so that's the Poisson MGF.

00:20:29.800 --> 00:20:34.280
So one thing we could do with it
is to start taking derivatives or

00:20:35.380 --> 00:20:39.025
trying to expand it or
whatever to get the moments.

00:20:39.025 --> 00:20:42.390
But I'm not doing this example
because I want do moments,

00:20:42.390 --> 00:20:45.470
I want to show you the other
applications of MGF.

00:20:45.470 --> 00:20:50.770
So now let's let Y be the Poisson of mu.

00:20:50.770 --> 00:20:53.840
So we have two Poisson's now,
not one Poisson.

00:20:53.840 --> 00:20:57.206
And suppose that X and Y are independent.

00:21:00.471 --> 00:21:04.550
And the problem is find
the distribution of X + Y.

00:21:04.550 --> 00:21:08.486
So we wanna study the sum of
two independent Poissons.

00:21:10.937 --> 00:21:15.728
Okay, so that's called a convolution, and
we'll come back to convolutions later

00:21:15.728 --> 00:21:19.390
on in the semester, but
you know in general it can be nasty.

00:21:19.390 --> 00:21:21.540
But I pointed out last time that for

00:21:21.540 --> 00:21:25.820
MGFs you can just multiply the MGFs,
that's easy.

00:21:25.820 --> 00:21:31.430
Whereas, doing a sum or
an integral could be pretty nasty, okay?

00:21:31.430 --> 00:21:33.899
So all we have to do is multiply the MGFs.

00:21:36.470 --> 00:21:41.270
That is I'm just going to take
the MGF of X times the MGF of Y.

00:21:42.860 --> 00:21:48.900
So here's the MGF of X,
e to the lambda, e to the t minus 1.

00:21:48.900 --> 00:21:51.008
MGF of Y is going to be the same thing,

00:21:51.008 --> 00:21:55.010
except that the parameter is now
called mu instead of lambda.

00:21:55.010 --> 00:22:01.350
So that's gonna be e to the mu, e to
the t- 1 =, and let's just simplify it.

00:22:01.350 --> 00:22:05.700
That's e to the lambda + mu,
factor that out, e to the t- 1.

00:22:05.700 --> 00:22:11.423
That immediately tells us that
X + Y is Poisson lambda + mu.

00:22:15.798 --> 00:22:18.183
Because of the fact,
we didn't prove this theorem,

00:22:18.183 --> 00:22:20.250
as I said that's a really
difficult theorem.

00:22:20.250 --> 00:22:27.740
But that is a theorem that this is
the Poisson lambda plus mu MGF.

00:22:27.740 --> 00:22:30.220
There's no other distribution
that has the same MGF.

00:22:30.220 --> 00:22:32.360
So this is, therefore,
the only possibility.

00:22:33.740 --> 00:22:37.850
By the way, it was obvious that the mean
had to be lambda + mu, by linearity.

00:22:37.850 --> 00:22:39.810
So this, we already knew.

00:22:39.810 --> 00:22:41.760
The interesting part is that it's Poisson,

00:22:41.760 --> 00:22:43.918
the sum of independent
Poissons is still Poisson.

00:22:43.918 --> 00:22:48.412
Most distributions don't
have such a nice property.

00:22:48.412 --> 00:22:52.200
Like you'll add independent
versions of them,

00:22:52.200 --> 00:22:54.650
and usually you get some other family.

00:22:54.650 --> 00:22:58.030
Here it's still within the Poisson
family of distributions, okay?

00:22:58.030 --> 00:23:00.370
So that's a very,
very nice property of the Poisson.

00:23:01.840 --> 00:23:04.818
And a common mistake with this,

00:23:04.818 --> 00:23:10.127
is to ignore the assumption that X and
Y are independent.

00:23:10.127 --> 00:23:14.615
So to justify being able to be just
multiply the MGFs we need X and

00:23:14.615 --> 00:23:17.020
Y to be independent.

00:23:17.020 --> 00:23:24.020
So just to see a quick counter example,
if they're not independent.

00:23:27.130 --> 00:23:31.900
If X and Y are dependent,
well the most extreme case

00:23:31.900 --> 00:23:36.290
of dependence that I can
think of is when X = Y.

00:23:36.290 --> 00:23:42.317
Okay, so let's just see why
this doesn't work when X = Y.

00:23:42.317 --> 00:23:46.440
Well obviously if X = Y, then X + Y is 2X.

00:23:48.570 --> 00:23:49.954
And that's not Poisson.

00:23:52.765 --> 00:23:53.960
Why is that not Poisson?

00:24:01.346 --> 00:24:07.654
Yeah,
&gt;&gt; [INAUDIBLE].

00:24:07.654 --> 00:24:12.076
&gt;&gt; Okay, so that's a good way
to think of it with the MGF,

00:24:12.076 --> 00:24:16.998
if we take the MGF of this thing
you're gonna get 2 in there.

00:24:16.998 --> 00:24:19.420
And what you actually gonna have,

00:24:19.420 --> 00:24:25.279
you are gonna take the selected value of
e to the 2tx, so you've replaced t by 2t.

00:24:25.279 --> 00:24:29.821
So you'd get 2t up there and
that doesn't look like a Poisson, now so

00:24:29.821 --> 00:24:35.222
that's close to a proof but it's a little
more complicated than I was thinking of.

00:24:35.222 --> 00:24:39.523
And you would still deed to say like could
there be some miracle of algebra that

00:24:39.523 --> 00:24:41.191
would reduce that back down.

00:24:41.191 --> 00:24:42.361
It's not true right?

00:24:42.361 --> 00:24:44.151
If you put a 2 there
it's not of this form.

00:24:44.151 --> 00:24:47.810
But still, what if you just didn't
think of the brilliant algebraic way to

00:24:47.810 --> 00:24:49.010
simplify it down.

00:24:49.010 --> 00:24:53.110
Yeah.
&gt;&gt; [INAUDIBLE]

00:24:53.110 --> 00:24:55.080
&gt;&gt; Yeah that's the simplest way to see it.

00:24:55.080 --> 00:24:58.545
What she just said was
that this thing is even.

00:25:01.163 --> 00:25:03.900
So that's one good way to see it.

00:25:03.900 --> 00:25:08.310
A Poisson has to take on any
possibles non-negative integer value.

00:25:08.310 --> 00:25:12.208
This thing is always an even number,
so it couldn't possibly be a Poisson.

00:25:12.208 --> 00:25:13.910
That's the simplest way to think about it,

00:25:13.910 --> 00:25:15.708
is just looking at one
of the possible values.

00:25:15.708 --> 00:25:20.865
Another way to see it, would be to compute
the variance, the mean and variance.

00:25:20.865 --> 00:25:26.260
So the expected value of x plus y,
which is 2x, would be 2 lambda.

00:25:28.300 --> 00:25:32.080
So if it were Poisson, it would have to
be Poisson 2 lambda cuz that's the mean.

00:25:32.080 --> 00:25:38.960
But the variance of 2x is 4 lambda
cuz the 2 comes out squared.

00:25:38.960 --> 00:25:41.400
For a Poisson the mean
always equals the variance.

00:25:41.400 --> 00:25:43.588
For this thing the variance is double.

00:25:43.588 --> 00:25:49.050
Intuitively that should make sense because
you're adding the same thing to itself.

00:25:49.050 --> 00:25:52.978
That increases the variance compared
to if you added independent things,

00:25:52.978 --> 00:25:56.093
then you might expect if one
thing happens to be very large,

00:25:56.093 --> 00:25:58.544
then the other thing might offset it,
right?

00:25:58.544 --> 00:26:02.023
But if you're adding the same thing
to itself and it happens to be large,

00:26:02.023 --> 00:26:04.717
then you're adding the same
large thing twice, okay?

00:26:04.717 --> 00:26:08.177
I've seen similar mistakes, cause
this is like an easy counter example.

00:26:08.177 --> 00:26:12.515
I've seen some more mistakes since
that one time, many many times

00:26:12.515 --> 00:26:16.709
where maybe we have something
like a sum of x1 plus x2 plus x3.

00:26:16.709 --> 00:26:20.310
And a student just then
replaces them all in their iid,

00:26:20.310 --> 00:26:24.707
and a student replaces them all by
x plus x plus x, and then get 3x.

00:26:24.707 --> 00:26:27.074
But X is not independent of itself, and

00:26:27.074 --> 00:26:29.816
you'll end up with
the same mistake as this.

00:26:29.816 --> 00:26:33.120
So I wanna mention that counterexample,
okay?

00:26:33.120 --> 00:26:37.610
So and there's other ways to see it,
too, but

00:26:37.610 --> 00:26:41.220
we just talked about three reasons why
this was not Poisson when using the MGF,

00:26:41.220 --> 00:26:44.260
one by looking at the possible values,
one by looking at the mean and variance.

00:26:44.260 --> 00:26:47.424
So hopefully you're convinced
now that that's not Poisson.

00:26:47.424 --> 00:26:54.895
Okay, so next major topic in this
course is joint distributions.

00:26:54.895 --> 00:26:59.595
That is, something we dealt
with a little bit before but

00:26:59.595 --> 00:27:04.397
just like bringing it in as its
own topic in its own right.

00:27:04.397 --> 00:27:07.094
So joint distributions just means,

00:27:07.094 --> 00:27:12.753
how do we work with the distribution
of more than one random variable, okay?

00:27:12.753 --> 00:27:16.155
So that's why everything in this
course is cumulative, right?

00:27:16.155 --> 00:27:19.630
Because if you don't fully
understand the CDF of one random

00:27:19.630 --> 00:27:24.149
variable then it's going to be really
hard to understand the joint CDF of more

00:27:24.149 --> 00:27:26.179
than one random variable, okay?

00:27:26.179 --> 00:27:27.855
So joint distributions,

00:27:27.855 --> 00:27:31.900
we already talk about independence
versus dependence right?

00:27:31.900 --> 00:27:36.648
If you have independent random variables
joint distribution just means multiply

00:27:36.648 --> 00:27:41.338
the individual CDFs of the individuals
PDFs and it's pretty straightforward.

00:27:41.338 --> 00:27:44.627
Remember the slogan independent
means multiple, okay?

00:27:44.627 --> 00:27:49.037
But in general we need to have
some tools and notation and so

00:27:49.037 --> 00:27:52.823
on for
dealing with dependent random variables.

00:27:52.823 --> 00:27:58.094
Maybe just two of them or
maybe a million of them, okay?

00:27:58.094 --> 00:28:02.362
So we're gonna talk about
joint distributions.

00:28:02.362 --> 00:28:06.155
And I think the best way to
start is in the simplest case,

00:28:06.155 --> 00:28:08.676
where we have two random variables.

00:28:08.676 --> 00:28:12.361
And let's even say there are two
binary random variables.

00:28:12.361 --> 00:28:16.202
So we can think of this in
terms of two by two tables.

00:28:16.202 --> 00:28:18.410
And this may seem really, really simple.

00:28:18.410 --> 00:28:22.510
I hope it seems pretty simple, cuz then if
you understand this simple case really,

00:28:22.510 --> 00:28:27.300
really well, it'll give you a lot of
intuition for the more complicated case.

00:28:27.300 --> 00:28:32.207
Okay, so I'll start with a simple

00:28:32.207 --> 00:28:36.952
one where x and y are Bernoullis.

00:28:36.952 --> 00:28:41.637
Possibly dependent, possibly independent,
and possibly the same p,

00:28:41.637 --> 00:28:43.440
possibly different p's.

00:28:43.440 --> 00:28:46.254
I'm not saying they're both
Bernoulli-p with the same p.

00:28:46.254 --> 00:28:52.778
Okay, then we can think of this
in terms of two by two tables.

00:28:52.778 --> 00:28:59.354
So we could draw an example
light like this with a table and

00:28:59.354 --> 00:29:05.245
we could just tabulate
values where here is x = 0,

00:29:05.245 --> 00:29:09.363
x = 1, and y = 0, y = 1, okay?

00:29:09.363 --> 00:29:14.567
Okay and then to specify the joint
distribution all we have to

00:29:14.567 --> 00:29:21.213
do is put in four numbers here that
are non-negative and add up to 1, right?

00:29:21.213 --> 00:29:24.714
Any four numbers you want as long
as they are non-negative and

00:29:24.714 --> 00:29:27.691
add up to 1 that will be
a valid joint distribution.

00:29:27.691 --> 00:29:34.729
So remember for your know PMFs to be valid
a PMF just non-negative adds up to 1?

00:29:34.729 --> 00:29:39.194
Completely analogous it's just now in two
dimensions instead of one dimension okay?

00:29:39.194 --> 00:29:42.001
So we can just make up four
numbers that add up to one.

00:29:42.001 --> 00:29:45.800
I guess we can talk about some
of the general definitions here.

00:29:45.800 --> 00:29:47.918
So this is for this specific case.

00:29:47.918 --> 00:29:50.775
But let's also talk
about the general case.

00:29:50.775 --> 00:29:57.041
So if we have x and y, first of all,

00:29:57.041 --> 00:30:00.940
they're joint CDF.

00:30:00.940 --> 00:30:04.460
It's completely analogous
to the individual CDF.

00:30:04.460 --> 00:30:08.280
So the joint CDF is the function
of two variables now.

00:30:08.280 --> 00:30:15.720
F(x,y) = the probability X less than or
equal to x, Y less than or equal to Y.

00:30:19.616 --> 00:30:26.127
Similarly we have a joint
PMF in the discrete case.

00:30:31.291 --> 00:30:36.216
Which would just be the probability that
X equals little x, Y equals little y,

00:30:36.216 --> 00:30:36.973
all right.

00:30:36.973 --> 00:30:37.845
So we just add this part.

00:30:37.845 --> 00:30:38.821
That's the PMF.

00:30:38.821 --> 00:30:43.368
The joint PMF means we're considering
both of them together, okay?

00:30:43.368 --> 00:30:47.659
Now, in the case where they're
independent if x and y are independent.

00:30:47.659 --> 00:30:55.075
That means that this joint PMF is the
product, P of X = x times P of Y equals y.

00:30:55.075 --> 00:30:57.936
So we need, so
that's called the joint CDF.

00:30:57.936 --> 00:30:59.008
Joint PMF.

00:31:01.416 --> 00:31:04.480
And now, so this is when we're
considering them together, right?

00:31:04.480 --> 00:31:06.839
Because it's comma within the same P.

00:31:06.839 --> 00:31:09.572
Right, it's considering them jointly.

00:31:09.572 --> 00:31:11.721
Okay if they're independent,

00:31:11.721 --> 00:31:15.868
that's equivalent to independence
is you can split this up.

00:31:15.868 --> 00:31:19.299
Okay, so now there's another concept
that we need called marginal

00:31:23.571 --> 00:31:27.730
The marginal distribution,
marginal just means take them separately.

00:31:27.730 --> 00:31:33.907
So the marginal distribution for
x would be a probably x less than or

00:31:33.907 --> 00:31:38.551
equal x is called the marginal
distribution of x.

00:31:41.507 --> 00:31:47.110
Similarly marginal PMF would
just be just this part, okay?

00:31:47.110 --> 00:31:50.110
So therefore in words,
we could say that marginal

00:31:52.250 --> 00:31:56.163
Independence means that
the joint distribution,

00:31:56.163 --> 00:31:59.987
the joint CDF is the product
of the marginal CDFs.

00:31:59.987 --> 00:32:02.796
Okay, and similarly we have,

00:32:02.796 --> 00:32:08.196
we can continue this over here,
we have the notion of a joint

00:32:08.196 --> 00:32:16.252
PDF I'm doing kind of discrete and

00:32:16.252 --> 00:32:19.653
continuous together, because
they're analogous to each other and

00:32:19.653 --> 00:32:22.127
they're analogous to
the one dimensional case.

00:32:22.127 --> 00:32:28.189
So a join PDF, which we might
write as little f(x, y) such that,

00:32:28.189 --> 00:32:34.170
so this would be the continuous
case in two dimensions.

00:32:34.170 --> 00:32:38.560
What does it mean to be a joint PDF?

00:32:38.560 --> 00:32:41.250
Just as like in the one dimensional case,

00:32:41.250 --> 00:32:45.530
the PDF is what you integrate
to get a probability.

00:32:45.530 --> 00:32:48.270
Two dimensional case, same thing.

00:32:48.270 --> 00:32:53.562
If we wanna know what's
the probability that x and

00:32:53.562 --> 00:32:58.854
y are in some set,
let's say x,y is in some set B,

00:32:58.854 --> 00:33:02.636
where B is some region in the plane.

00:33:02.636 --> 00:33:06.650
Maybe it's a rectangle,
maybe it's a circle or something.

00:33:06.650 --> 00:33:09.860
Just imagine some area in the plane.

00:33:09.860 --> 00:33:16.391
Then what we do is integrate
over that region f of x, ydxdy.

00:33:19.475 --> 00:33:23.639
So that's the first time that we've
written down a double integral here, but

00:33:23.639 --> 00:33:27.486
as far as what we're concerned, for
the most part, double integrals,

00:33:27.486 --> 00:33:31.864
for this course, the double integrals,
we're not gonna need to do a lot of them.

00:33:31.864 --> 00:33:35.616
And when we do normally we can just
think of it as one single integral and

00:33:35.616 --> 00:33:38.362
another single integral so
just do two integrals.

00:33:40.921 --> 00:33:44.318
But the intuition should be clear, right?

00:33:44.318 --> 00:33:47.085
The PDF is what you integrate
to get a probability.

00:33:47.085 --> 00:33:50.765
So it's completely analogous.

00:33:50.765 --> 00:33:53.560
And so independence means that

00:33:56.746 --> 00:34:01.300
We've already talked about this before,
I'm just using new terminology for it.

00:34:01.300 --> 00:34:05.051
Independence means that the joint x and
y are independent.

00:34:07.219 --> 00:34:13.011
If and only if, The joint

00:34:13.011 --> 00:34:18.716
CDF is the product of the marginal CDFs.

00:34:18.716 --> 00:34:21.433
So, I'll call that, just for emphasis,

00:34:21.433 --> 00:34:26.419
it would be confusing to use the same
letter F here without any clarification.

00:34:26.419 --> 00:34:29.146
This is the marginal CDF of x.

00:34:29.146 --> 00:34:32.296
This is the marginal cd F of x,
this is the marginal cd F of y,

00:34:32.296 --> 00:34:33.871
this is the joint cd F, okay?

00:34:33.871 --> 00:34:37.299
So it says that instead of having to do
some kind of complicated joint thing,

00:34:37.299 --> 00:34:41.010
I can just find the probability of this
event times the probability of this event.

00:34:41.010 --> 00:34:42.781
So that's the definition of independence.

00:34:42.781 --> 00:34:47.938
But we've seen over and over again that
usually it's easier to use PDFs or PMFs.

00:34:47.938 --> 00:34:52.111
So it's equivalent,
it's not too difficult.

00:34:52.111 --> 00:34:57.693
It's a little bit tedious but
with some algebra, we can show that

00:34:57.693 --> 00:35:04.508
it's the same thing as saying the joint
pmf is the product of the marginal pmfs.

00:35:07.458 --> 00:35:09.086
That's in the discrete case.

00:35:11.490 --> 00:35:16.949
And in the continuous case,
that the joint PDF,

00:35:16.949 --> 00:35:21.088
is the product of the marginal PDFs.

00:35:25.422 --> 00:35:31.109
And I wanna emphasize that this
has to be for all x and y.

00:35:31.109 --> 00:35:34.891
Not just for x and
y that make this thing positive.

00:35:34.891 --> 00:35:37.713
You have to pay attention
to the zeros also.

00:35:37.713 --> 00:35:41.173
We'll see an example like that later.

00:35:41.173 --> 00:35:46.678
So for all real x and y,
we can't restrict it.

00:35:46.678 --> 00:35:50.992
All right, so coming back to this
little example, we can make up any four

00:35:50.992 --> 00:35:55.048
numbers we want as long as they're
non-negative and add up to one.

00:35:55.048 --> 00:35:59.078
So I made up 4 numbers,
just for the sake of example.

00:35:59.078 --> 00:36:04.096
Two-sixth, one-sixth,two-sixth, one-sixth.

00:36:04.096 --> 00:36:08.563
So I made up a simple little example here,
and

00:36:08.563 --> 00:36:13.629
I could ask the question,
are x and y independent?

00:36:13.629 --> 00:36:18.923
And to answer that we need to say well

00:36:18.923 --> 00:36:23.520
two ways we can think about it.

00:36:23.520 --> 00:36:29.448
One would be so I so I wrote this in terms
of, you know, joint CDFs, joint PMF.

00:36:29.448 --> 00:36:32.550
We could also write
something like conditional.

00:36:32.550 --> 00:36:37.381
That is independence means you
don't have the distribution of y

00:36:37.381 --> 00:36:39.805
given that x equals something.

00:36:39.805 --> 00:36:42.351
It doesn't actually depend on that x part.

00:36:42.351 --> 00:36:45.547
So it's the same as
the unconditional distribution.

00:36:45.547 --> 00:36:47.156
Okay, so, well anyway, so

00:36:47.156 --> 00:36:51.060
each number in this table is one
of the joint probabilities, right?

00:36:51.060 --> 00:36:53.995
So two-sixth is the probability that x and
y are both zero,

00:36:53.995 --> 00:36:58.080
one-sixth is the probability that
they're both one, and so on, okay?

00:36:58.080 --> 00:37:01.880
So to check that they're independent
from the definition, well,

00:37:01.880 --> 00:37:06.700
what that means is we first need to
find the marginal distributions and

00:37:06.700 --> 00:37:09.400
then check that this is true.

00:37:10.420 --> 00:37:16.869
Okay, now to get from
the marginal to the joint.

00:37:16.869 --> 00:37:21.320
Here's just quickly how do we
get marginal distributions?

00:37:21.320 --> 00:37:29.220
Getting marginals is actually pretty
easy from the joint distribution.

00:37:29.220 --> 00:37:33.258
Because Let's just do
the discrete case first.

00:37:33.258 --> 00:37:37.857
If we wanna know the marginal
distribution of x as the marginal PMF,

00:37:37.857 --> 00:37:40.600
then just by the action of probability,

00:37:40.600 --> 00:37:44.734
all we have to do is add up
the different possibilities for y.

00:37:44.734 --> 00:37:52.348
So that the sum of all y P of X = x,
Y = y, okay?

00:37:52.348 --> 00:37:55.041
Because just the axiom
of probability right?

00:37:55.041 --> 00:37:58.234
That we're adding up just
joint cases the union is this.

00:37:58.234 --> 00:37:59.630
You can also write it as a conditional.

00:37:59.630 --> 00:38:04.067
You can also think of this as the law of
probability, and write given Y equals y,

00:38:04.067 --> 00:38:06.795
times P of Y equals y,
it would be the same thing.

00:38:06.795 --> 00:38:12.000
Okay, that just says add up, X = x, but
Y could be anything so we sum over Y.

00:38:12.000 --> 00:38:15.437
That's called marginalizing over Y,
that we're just summing up.

00:38:15.437 --> 00:38:19.015
We start with this thing that's
a function of x and y, sum over all y,

00:38:19.015 --> 00:38:21.680
then we just get a function of x.

00:38:21.680 --> 00:38:28.912
And in the continuous case, let's get
the marginal so that's the discrete case.

00:38:28.912 --> 00:38:33.759
And the continuous case, let's say we want
the marginal distribution of y, similarly,

00:38:33.759 --> 00:38:36.118
you can get the marginal
distribution of y,

00:38:36.118 --> 00:38:38.438
I'm not gonna write the same thing again.

00:38:38.438 --> 00:38:40.888
If you want the marginal PDF?

00:38:40.888 --> 00:38:43.069
So this is the marginal PDF of y.

00:38:43.069 --> 00:38:45.004
Marginal, this means viewing it.

00:38:45.004 --> 00:38:47.810
On its own, as its own thing, right?

00:38:49.080 --> 00:38:51.943
Then all we have to do is integrate
completely analogous to this.

00:38:51.943 --> 00:38:56.608
Integrate the joint density, f of x,y,

00:38:56.608 --> 00:39:00.483
(x, y), integrate over all x.

00:39:00.483 --> 00:39:03.007
That's just the continuous analog of that.

00:39:03.007 --> 00:39:05.389
Here we're summing over all values.

00:39:05.389 --> 00:39:07.812
I swapped the x and
y here just for variety,

00:39:07.812 --> 00:39:10.112
here we are summing overall values of y.

00:39:10.112 --> 00:39:17.188
Here we're integrating overall values
of x, the joint density, okay?

00:39:17.188 --> 00:39:19.161
So, you can go in that direction,

00:39:19.161 --> 00:39:23.450
this is getting marginal distributions
from joint distributions.

00:39:23.450 --> 00:39:25.216
You can't go in the other direction.

00:39:25.216 --> 00:39:30.115
If we only know the marginal distributions
that doesn't tell us anything about how x

00:39:30.115 --> 00:39:32.467
and y are related to each other, right?

00:39:32.467 --> 00:39:34.064
So you can't go any other way.

00:39:34.064 --> 00:39:37.186
But you can go from the joint
distributions to the marginal

00:39:37.186 --> 00:39:38.085
distribution.

00:39:38.085 --> 00:39:42.030
So for this example,
let's get the marginal distributions.

00:39:43.100 --> 00:39:44.843
So what's the probability that y equals 0?

00:39:44.843 --> 00:39:47.610
Well, obviously, we're just adding
this case plus this case, right?

00:39:47.610 --> 00:39:49.740
Cuz those are the two
cases where y equals 0.

00:39:49.740 --> 00:39:52.185
So we add those two cases,
we get four-sixths.

00:39:53.820 --> 00:39:56.040
Add these two cases, we get two six's.

00:39:56.040 --> 00:39:59.950
And for the other way around if we
want the X = 0, just add this case and

00:39:59.950 --> 00:40:02.570
this case and
you get three six's or one half.

00:40:02.570 --> 00:40:04.970
This one plus this one, 3 / 6.

00:40:07.090 --> 00:40:09.450
And by the way,
one thing you have to be careful about,

00:40:09.450 --> 00:40:13.940
is the terminology in economics and
statistics is very different.

00:40:13.940 --> 00:40:17.560
And when you take an econ class you
always hear about marginal revenue and

00:40:17.560 --> 00:40:20.450
marginal cost and things like that.

00:40:20.450 --> 00:40:25.360
And usually in like, AP Econ,
then they don't want to use calculus, and

00:40:25.360 --> 00:40:29.220
so they explain everything is incremental,
if you do one more unit of something,

00:40:29.220 --> 00:40:30.620
then what happens?

00:40:30.620 --> 00:40:34.180
And then later when you actually
see what's going on with calculus,

00:40:34.180 --> 00:40:39.120
you realize that in Econ,
marginal means derivative and

00:40:39.120 --> 00:40:43.600
in statistics, marginal means integrate,
so it's completely

00:40:43.600 --> 00:40:48.260
opposite meaning and I don't know
where the Econ term came from but

00:40:48.260 --> 00:40:51.310
you can see here where
the statistics term came from.

00:40:51.310 --> 00:40:54.050
Cuz it's called marginal cuz we
write these numbers in the margins.

00:40:54.050 --> 00:40:56.150
So that's a marginal distribution.

00:40:58.300 --> 00:41:00.650
So, once you understand
this two by two table,

00:41:00.650 --> 00:41:04.570
you basically have the key
intuition into joint distributions.

00:41:06.300 --> 00:41:12.640
In this case,
here they are independent in this example.

00:41:14.360 --> 00:41:19.801
To check that they're independent
There are other ways to do it,

00:41:19.801 --> 00:41:22.102
but just to check it by the definition,

00:41:22.102 --> 00:41:26.070
what independence means is that
to compute any of these entries.

00:41:26.070 --> 00:41:30.622
Let's say 2/6ths Asl I need to do
is find the probability that X = 0

00:41:30.622 --> 00:41:35.513
x the probability that y = 0 so
I'd multiple 3/6ths times 4/6ths.

00:41:35.513 --> 00:41:39.851
Which is 1/2 times 2/3 is 1/3 which
is this, so if you get this number I

00:41:39.851 --> 00:41:44.030
can multiply this times this and so
on so you check this four numbers.

00:41:44.030 --> 00:41:48.080
So each of these joint probabilities
is obtained by just multiplying

00:41:48.080 --> 00:41:49.610
two marginal probabilities.

00:41:49.610 --> 00:41:51.990
So that means they are independent.

00:41:51.990 --> 00:41:55.160
Or as you can make up your own examples,
if you just

00:41:55.160 --> 00:41:58.800
here is kind of an extreme example
it doesn't have to be this extreme.

00:41:58.800 --> 00:42:03.070
But I can pick whatever numbers I want
as long as they're nonnegative and

00:42:03.070 --> 00:42:05.360
add up to 1.

00:42:05.360 --> 00:42:13.190
For example, I just made one up here
where these nonnegative add up to 1.

00:42:13.190 --> 00:42:16.300
So this is a perfectly
valid joint distribution.

00:42:16.300 --> 00:42:22.740
But you can see right away that this
0 means that it's not gonna be true,

00:42:22.740 --> 00:42:28.120
that if you multiply,
you can't obtain it that way cuz if you

00:42:28.120 --> 00:42:32.451
do the marginal thing again,
1/2, 1/2, and this is 1/4,

00:42:32.451 --> 00:42:36.890
3/4, and you multiply 1/4 x 1/2,
you don't get 0.

00:42:36.890 --> 00:42:39.440
So this one would be dependent.

00:42:39.440 --> 00:42:42.320
This one is dependent,
you can make up your own examples.

00:42:42.320 --> 00:42:44.440
It doesn't have to have a 0
in it to make it dependent,

00:42:44.440 --> 00:42:47.770
that was just an easy,
extreme case to see what's going on.

00:42:49.170 --> 00:42:56.800
Okay, so this is a simple two dimensional
discrete example to think about.

00:42:56.800 --> 00:43:01.750
Let's also do one simple
continuous example just to

00:43:01.750 --> 00:43:06.180
have some intuition on
what this all means.

00:43:06.180 --> 00:43:10.660
So the simplest way to start is I
think at the uniform distribution.

00:43:10.660 --> 00:43:12.850
What is uniform in two dimensions mean?

00:43:15.828 --> 00:43:21.147
So let's consider as an example

00:43:21.147 --> 00:43:27.057
what if we have uniform on the square

00:43:27.057 --> 00:43:31.785
that's all x y such that x and

00:43:31.785 --> 00:43:36.519
y are both between 0 and 1.

00:43:43.110 --> 00:43:45.080
So we just have this square here.

00:43:45.080 --> 00:43:50.010
We can draw our coordinates, and
have a square here where this is 1 and

00:43:50.010 --> 00:43:50.880
this is 1, okay?

00:43:50.880 --> 00:43:52.280
So we have this square, and

00:43:52.280 --> 00:43:56.630
we want a distribution that's
uniform over this square, so.

00:43:56.630 --> 00:43:59.910
Remember, in the one-dimensional case,

00:43:59.910 --> 00:44:04.268
uniform meant that the PDF was
constant on some interval, okay?

00:44:04.268 --> 00:44:09.680
So the analogous concept would be, we want
a PDF, which is gonna be a joint PDF,

00:44:09.680 --> 00:44:15.380
and we want it to be
constant on that square.

00:44:17.510 --> 00:44:20.200
And 0 outside the square, right?

00:44:21.790 --> 00:44:26.240
So, that just captures the notion
of being a completely random point.

00:44:26.240 --> 00:44:31.490
As we're picking a random point, x comma
y, we want a completely random point

00:44:31.490 --> 00:44:36.430
in the square, so we want the density
to be constant all over that square.

00:44:36.430 --> 00:44:39.600
So 0 outside, let's find the joint PDF.

00:44:39.600 --> 00:44:47.508
Well, the joint PDF, therefore from
what I just said is some constant c,

00:44:47.508 --> 00:44:53.395
if x and y are both between 0 and
1, and 0 otherwise.

00:44:58.031 --> 00:45:04.096
Now in one dimension, if you integrate
the number of one over some interval,

00:45:04.096 --> 00:45:06.910
you get the length of the interval.

00:45:08.170 --> 00:45:12.700
In two dimensions if you
integrate the constant one

00:45:12.700 --> 00:45:16.911
over some region you get
the area of the region so

00:45:16.911 --> 00:45:22.939
if we integrate this thing we get
the area, so the integral is area,

00:45:28.808 --> 00:45:32.652
So C = 1/area would normalize it,

00:45:32.652 --> 00:45:37.740
which = 1 because the area
of that square is 1.

00:45:37.740 --> 00:45:42.775
So the joint PDF would just be 1
inside here and 0 outside, and

00:45:42.775 --> 00:45:48.475
if you want the marginal distributions,
then just integrate out the,

00:45:48.475 --> 00:45:54.186
integrate this Dx or integrate this Dy,
you'll get 1 so marginally,

00:45:58.195 --> 00:46:03.370
X and y are independent uniform,
which is pretty intuitive uniform 01.

00:46:03.370 --> 00:46:08.100
Which is kind of intuitive right because
it just says if you pick a random

00:46:08.100 --> 00:46:13.230
point in the square in the x coordinates
uniform, the y coordinate is uniform.

00:46:13.230 --> 00:46:16.280
So that's pretty straightforward,
that's an example of independence.

00:46:16.280 --> 00:46:21.420
But I want to contrast that
with an example of dependence,

00:46:21.420 --> 00:46:23.760
where instead of a square,
let's use a circle.

00:46:27.000 --> 00:46:34.260
So, suppose we want uniform in
the circle I'll say disc for clarity.

00:46:35.290 --> 00:46:38.260
A circle might just mean a circle
we want everything inside.

00:46:38.260 --> 00:46:43.330
So on the disc, x squared plus y
squared less than or equal to 1.

00:46:43.330 --> 00:46:49.910
Okay, so let's see what that looks like so
we just draw a circle.

00:46:49.910 --> 00:46:52.340
Sorry, it doesn't look like
a very good circle, but

00:46:52.340 --> 00:46:56.840
pretend that that's a perfect
circle centered at 0 of radius 1.

00:46:56.840 --> 00:47:00.220
And we wanna be uniform in here, okay?

00:47:00.220 --> 00:47:05.700
We wanna write down what the joint PDF,
what are the marginal PDF's, okay?

00:47:05.700 --> 00:47:09.647
So first of all for
the Joint PDF by the same kinda reasoning.

00:47:15.100 --> 00:47:20.740
It's just because its uniform that that
means another way to say uniform is that

00:47:20.740 --> 00:47:25.350
the probability of some region must
be proportional to its area, right.

00:47:25.350 --> 00:47:28.850
So now in one dimension I said
probability is proportional to length for

00:47:28.850 --> 00:47:30.190
uniform distribution.

00:47:30.190 --> 00:47:34.020
Here probability is proportional to area,
so because of that the normalizing

00:47:34.020 --> 00:47:39.190
constant has to be 1 over the area of
the circle, Pi r squared, so that's Pi.

00:47:39.190 --> 00:47:45.930
So a joint PDF is 1 over pi
inside the circle and 0 outside.

00:47:49.797 --> 00:47:54.927
And a common mistake with this kind
of thing is to then think that that

00:47:54.927 --> 00:47:59.970
says that they're independent
because that's just a constant so

00:47:59.970 --> 00:48:05.840
it doesn't It looks like I can factor 1
over pi as constant times a constant.

00:48:05.840 --> 00:48:11.163
It's just a constant but they're not
independent because of this constraint.

00:48:14.362 --> 00:48:19.041
They're actually very dependent
because for example, if x is 0,

00:48:19.041 --> 00:48:22.570
then y could be anywhere from -1 to 1.

00:48:22.570 --> 00:48:27.910
But if x is close to one, then y has to
be in some tiny little interval, right?

00:48:27.910 --> 00:48:35.270
So, if we fix x to be here, then y
could be between here and here, right?

00:48:35.270 --> 00:48:41.630
So the values depend on where,

00:48:41.630 --> 00:48:45.080
that is knowing x constrains
the possible values of y.

00:48:45.080 --> 00:48:47.200
That says that they're not independent.

00:48:47.200 --> 00:48:49.600
So here x and y are dependent.

00:48:50.720 --> 00:48:56.339
And in fact,
we can show that given that x equals x

00:48:58.250 --> 00:49:02.060
Then, we can actually say, what can y be?

00:49:02.060 --> 00:49:08.760
Y has to be between square root of
1 minus x squared and minus that.

00:49:11.830 --> 00:49:13.920
Because x squared plus y squared
are less than or equal to 1.

00:49:13.920 --> 00:49:16.260
So this depends on x,
this is the constraint.

00:49:17.360 --> 00:49:21.660
So we might guess that Y is
uniform between here and here.

00:49:21.660 --> 00:49:26.290
That is if X is here,
then we know it's between here and here,

00:49:26.290 --> 00:49:28.920
but could be anywhere, right?

00:49:28.920 --> 00:49:30.540
So a good guess would be uniform,

00:49:30.540 --> 00:49:34.090
but next time we'll do an integral
to show that for practice.

00:49:34.090 --> 00:49:36.680
But you can see right
now they're dependent.

00:49:36.680 --> 00:49:39.220
Okay, so see you on Friday.

