WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.415
[MUSIC PLAYING]

00:00:08.710 --> 00:00:10.960
WEI LIN: I'm a senior
director of PAI,

00:00:10.960 --> 00:00:13.930
the platform of artificial
intelligence in Alibaba.

00:00:13.930 --> 00:00:18.440
Today I will give you a brief
introduction about our work.

00:00:18.440 --> 00:00:21.130
This is an overview of
our computation platform.

00:00:21.130 --> 00:00:23.690
We have a global
storage system with

00:00:23.690 --> 00:00:25.300
the heterogeneous resource.

00:00:25.300 --> 00:00:28.210
On top that we have
uniform resource management

00:00:28.210 --> 00:00:31.330
to support all different types
of computation framework,

00:00:31.330 --> 00:00:33.215
including PAI.

00:00:33.215 --> 00:00:36.740
Here's a snapshot of
the PAI user interface.

00:00:36.740 --> 00:00:40.630
People can pull and try
components, and build

00:00:40.630 --> 00:00:42.320
a workflow very easily.

00:00:42.320 --> 00:00:45.080
The system runs on top
of millions of CPU cores,

00:00:45.080 --> 00:00:46.880
and thousands of GPU cores.

00:00:46.880 --> 00:00:50.370
Our single training job can
scale up to a thousand workers,

00:00:50.370 --> 00:00:53.150
with billions of
features and parameters.

00:00:53.150 --> 00:00:55.730
And we also have a public
server in our cloud

00:00:55.730 --> 00:00:58.920
for the external user as well.

00:00:58.920 --> 00:01:02.010
Here is our key in
our system design.

00:01:02.010 --> 00:01:05.160
We want to have some
easy-going building blocks

00:01:05.160 --> 00:01:08.830
for AI application creators.

00:01:08.830 --> 00:01:15.360
We also provide-- cover the full
web cycle for those developers,

00:01:15.360 --> 00:01:19.200
to give them a one-stop
programming experience.

00:01:19.200 --> 00:01:21.660
Our core is our engine
which can provide

00:01:21.660 --> 00:01:27.390
high performance, low cost, good
flexibility, and extensibility.

00:01:27.390 --> 00:01:30.390
Since this is a
TensorFlow dev summit,

00:01:30.390 --> 00:01:33.480
I will talk more about our work
in the deep learning engine.

00:01:33.480 --> 00:01:37.280
Our ultimate goal is to let the
developer focus on modelling

00:01:37.280 --> 00:01:38.700
their neural network.

00:01:38.700 --> 00:01:43.450
Net assistant, PAI, helps
them run their model easily,

00:01:43.450 --> 00:01:45.720
efficiently, and to scale.

00:01:45.720 --> 00:01:47.470
How do we achieve that?

00:01:47.470 --> 00:01:50.640
We deeply leverage
TensorFlow, because TensorFlow

00:01:50.640 --> 00:01:54.300
has a very good flexible and
extensible system design.

00:01:54.300 --> 00:01:57.550
And we did a lot of
in-depth optimization,

00:01:57.550 --> 00:01:59.070
which is listed on the right.

00:02:02.250 --> 00:02:05.160
Inside Alibaba, the
recommendation system

00:02:05.160 --> 00:02:07.350
has billions of
features that requires

00:02:07.350 --> 00:02:09.780
a thousand workers in training.

00:02:09.780 --> 00:02:13.390
We have to enhance TensorFlow,
especially on the runtime

00:02:13.390 --> 00:02:16.380
and distributed
training mechanism,

00:02:16.380 --> 00:02:21.880
to leverage the sparsity
of the data better.

00:02:21.880 --> 00:02:25.050
We also improved the
communication protocol

00:02:25.050 --> 00:02:30.330
to introduce this
multi-layer, or reduced ring,

00:02:30.330 --> 00:02:35.250
to build on top of the
network hierarchy topology.

00:02:35.250 --> 00:02:38.600
We also support different
communication protocols,

00:02:38.600 --> 00:02:42.790
like RDMA and NCCL.

00:02:42.790 --> 00:02:46.670
In order to fully utilize
new GPU architecture

00:02:46.670 --> 00:02:48.230
like [INAUDIBLE].

00:02:48.230 --> 00:02:52.070
We enhanced a TensorFlow
that can automatically run

00:02:52.070 --> 00:02:54.550
the model with mixed precision.

00:02:54.550 --> 00:02:56.830
From the initial
results, we actually

00:02:56.830 --> 00:03:01.770
improved this three times
in our real scenarios.

00:03:01.770 --> 00:03:04.440
We asked for easy programming.

00:03:04.440 --> 00:03:06.120
We worked with the
community together,

00:03:06.120 --> 00:03:10.590
to improve the auto-parallelism.

00:03:10.590 --> 00:03:15.495
We introduced TAO, which is
based on the XLA framework,

00:03:15.495 --> 00:03:18.300
and that did a lot
of the optimization.

00:03:18.300 --> 00:03:24.450
Including the cost-based graph
split, graph optimization,

00:03:24.450 --> 00:03:28.570
kernel fusion, and
full-stage code-gen.

00:03:28.570 --> 00:03:34.330
On the inference side, we
introduced the PAI-Blade tools,

00:03:34.330 --> 00:03:39.070
which has three levels
of optimization.

00:03:39.070 --> 00:03:40.730
Here are some results.

00:03:40.730 --> 00:03:43.270
We can see that on
those public models,

00:03:43.270 --> 00:03:46.040
we are on par with TensorRT.

00:03:46.040 --> 00:03:47.050
Slightly better.

00:03:49.590 --> 00:03:53.700
Recently, graph neural networks
gained a lot of attention

00:03:53.700 --> 00:03:55.520
inside Alibaba.

00:03:55.520 --> 00:04:01.110
In our real scenario, we faced
a more challenging [INAUDIBLE] ,

00:04:01.110 --> 00:04:03.180
group, having four properties.

00:04:03.180 --> 00:04:06.170
They are large-scale
heterogeneous, attributed,

00:04:06.170 --> 00:04:07.160
and dynamic.

00:04:07.160 --> 00:04:11.480
We had to enhance TensorFlow
to solve those challenges.

00:04:11.480 --> 00:04:18.470
We also developed a general
CN inference engine,

00:04:18.470 --> 00:04:22.970
with-- on FPGA, and integrated
this engine with TensorFlow.

00:04:22.970 --> 00:04:26.820
We have deployed this solution
to our CityBrain project

00:04:26.820 --> 00:04:27.320
in China.

00:04:30.200 --> 00:04:32.720
PAI also provide
a lot of the SDK

00:04:32.720 --> 00:04:36.770
for the developer to
accelerate their research,

00:04:36.770 --> 00:04:39.890
including Reinforcement
Learning, Transfer Learning

00:04:39.890 --> 00:04:43.790
package, and the Computation
Vision natural language

00:04:43.790 --> 00:04:45.350
processing.

00:04:45.350 --> 00:04:50.400
They are all built up
on top of TensorFlow.

00:04:50.400 --> 00:04:53.200
Currently we already
contributed a lot--

00:04:53.200 --> 00:04:56.830
50-- probably more
than 50 PRs back.

00:04:56.830 --> 00:04:59.250
I came here to want to
have more connection,

00:04:59.250 --> 00:05:03.030
and to try to share more of
our work with the community.

00:05:03.030 --> 00:05:04.470
Thank you.

00:05:04.470 --> 00:05:08.120
[MUSIC PLAYING]

