WEBVTT
Kind: captions
Language: en

00:00:05.940 --> 00:00:09.540
In the face of immortality, morality is going
to radically change, right.

00:00:09.540 --> 00:00:11.290
We’ve evolved to die.

00:00:11.290 --> 00:00:16.090
Like for the entire history of life on this
planet life has come to an end.

00:00:16.090 --> 00:00:20.930
There is nothing, you know, consciously there’s
nothing period out there that says this is

00:00:20.930 --> 00:00:22.420
how you behave if you live forever.

00:00:22.420 --> 00:00:29.070
This is how you start to structure a society
if I can store my personality on a computer.

00:00:29.070 --> 00:00:30.070
This is what I do.

00:00:30.070 --> 00:00:32.689
I can store that personality onto a computer
and download it into another body.

00:00:32.689 --> 00:00:36.579
These are huge, far flung really strange questions,
right.

00:00:36.579 --> 00:00:41.989
And they seem totally science fiction at this
point but everything we’ve seen over the

00:00:41.989 --> 00:00:46.789
past 25 years, right, is most of the science
fiction cannon from the twentith century has

00:00:46.789 --> 00:00:50.260
turned into science fact in the twenty-first
century already.

00:00:50.260 --> 00:00:55.620
So this twenty-first century sci-fi idea of
mind uploading is probably going to be here

00:00:55.620 --> 00:00:56.870
by the twenty-second century.

00:00:56.870 --> 00:01:01.780
So we’ve got 50 years, 70 years to start
figuring out these really complicated hard

00:01:01.780 --> 00:01:03.199
questions.

00:01:03.199 --> 00:01:06.390
The idea in mind uploading is that we can
store ourselves on silicon.

00:01:06.390 --> 00:01:11.720
We can upload our personalities, our brains,
some part of our consciousness onto computers

00:01:11.720 --> 00:01:12.970
and they can stay around forever.

00:01:12.970 --> 00:01:17.660
It is a far out there technology for sure
even though British Telecom is working on

00:01:17.660 --> 00:01:19.000
it, even though people are working on it.

00:01:19.000 --> 00:01:20.420
It’s very early days.

00:01:20.420 --> 00:01:23.670
Ray Kurzweil has famously kind of pegged the
date when we’re going to have to deal with

00:01:23.670 --> 00:01:25.780
this problem as 2045.

00:01:25.780 --> 00:01:28.600
That may be really, really enthusiastic.

00:01:28.600 --> 00:01:30.710
I think it’s a conservative prediction.

00:01:30.710 --> 00:01:35.880
But the point is that at some point in the
century this is probably going to get real.

00:01:35.880 --> 00:01:39.390
And you’ve got to stop and you’ve got
to go for all five of the world’s major

00:01:39.390 --> 00:01:41.780
religions just to start there.

00:01:41.780 --> 00:01:43.260
Use the threat of the hereafter, right.

00:01:43.260 --> 00:01:48.020
What’s going to happen after this life to
steer morality and shape behavior.

00:01:48.020 --> 00:01:53.310
So what happens to theological morality in
the face of technological immortality is the

00:01:53.310 --> 00:01:54.950
big kind of metaphysical question.

00:01:54.950 --> 00:01:59.460
If you look at the science fiction work of
Richard K. Morgan whose fantastic, he talks

00:01:59.460 --> 00:02:03.680
about what happens when consciousness becomes
downloadable and bodies become expendable

00:02:03.680 --> 00:02:07.840
and what that means for soldiers and armies
and mercenaries and things along those lines.

00:02:07.840 --> 00:02:13.110
So there’s a really like a gritty cyberpunk
underbelly in the mind uploading technology

00:02:13.110 --> 00:02:16.970
even though it’s being developed for educational
purposes so we can preserve the brains of

00:02:16.970 --> 00:02:20.500
the Einstein’s and the Beethoven’s and
the Richard Feynman’s of the world and really

00:02:20.500 --> 00:02:21.600
kind of get inside them.

00:02:21.600 --> 00:02:23.890
But it’s sort of like I think of it like
television, right.

00:02:23.890 --> 00:02:26.920
When they created television they thought
it was going to be used for educational purposes

00:02:26.920 --> 00:02:29.890
and that was the only – ask the creator
of TV what do you think this would be good

00:02:29.890 --> 00:02:30.890
for.

00:02:30.890 --> 00:02:33.170
Well education of course.

00:02:33.170 --> 00:02:35.410
Fifty years later there’s not much education.

00:02:35.410 --> 00:02:40.730
There’s a whole lot of crap and I think
we can see the same thing with mind uploading.

00:02:40.730 --> 00:02:46.500
But the difference of course is that mind
uploading, storing selves on silicon, even

00:02:46.500 --> 00:02:51.320
teetering on the edge of so-called immortality
changes everything about what it means to

00:02:51.320 --> 00:02:54.380
be human at a really fundamental deep level.

00:02:54.380 --> 00:02:58.340
And when I say fundamental deep level I mean
we’re starting to muck around and mess around

00:02:58.340 --> 00:03:00.950
with evolutionary processes.

00:03:00.950 --> 00:03:04.780
Processes we have no idea what happens if
you interrupt them because we’ve never done

00:03:04.780 --> 00:03:06.330
it before.

