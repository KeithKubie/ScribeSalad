WEBVTT
Kind: captions
Language: en

00:00:00.570 --> 00:00:03.620
Here is a simulation created
by Khan Academy user Justin

00:00:03.620 --> 00:00:07.150
Helps that once again tries to
give us an understanding of why

00:00:07.150 --> 00:00:11.710
we divide by n minus 1 to get an
unbiased estimate of population

00:00:11.710 --> 00:00:14.450
variance when we're trying to
calculate the sample variance.

00:00:14.450 --> 00:00:16.280
So what he does
here, the simulation,

00:00:16.280 --> 00:00:19.430
it has a population that
has a uniform distribution.

00:00:19.430 --> 00:00:21.690
So he says, I used a flat
probabilistic distribution

00:00:21.690 --> 00:00:24.870
from 0 to 100 for my population.

00:00:24.870 --> 00:00:26.900
Then we start sampling
from that population.

00:00:26.900 --> 00:00:29.510
We're going to use
samples of size 50.

00:00:29.510 --> 00:00:31.720
And what we do is for
each of those samples,

00:00:31.720 --> 00:00:37.330
we calculate the sample
variance based on dividing by n,

00:00:37.330 --> 00:00:40.440
by dividing by n
minus 1 and n minus 2.

00:00:40.440 --> 00:00:43.210
And as we keep having more
and more and more samples,

00:00:43.210 --> 00:00:45.950
we take the mean of the
variances calculated

00:00:45.950 --> 00:00:46.701
in different ways.

00:00:46.701 --> 00:00:48.658
And we figure out what
those means converge to.

00:00:48.658 --> 00:00:49.460
So that's a sample.

00:00:49.460 --> 00:00:50.376
Here's another sample.

00:00:50.376 --> 00:00:51.380
Here's another sample.

00:00:51.380 --> 00:00:53.910
If I sample here then
I'm now adding a bunch

00:00:53.910 --> 00:00:56.030
and I'm sampling continuously.

00:00:56.030 --> 00:00:59.210
And he saw something
very interesting happen.

00:00:59.210 --> 00:01:06.020
When I divide by n, I get
my sample variance is still,

00:01:06.020 --> 00:01:08.650
even when I'm taking the mean
of many, many, many, many sample

00:01:08.650 --> 00:01:10.066
variances that
I've already taken,

00:01:10.066 --> 00:01:12.570
I'm still underestimating
the true variance.

00:01:12.570 --> 00:01:14.200
When I divide by n
minus 1, it looks

00:01:14.200 --> 00:01:15.920
like I'm getting a
pretty good estimate,

00:01:15.920 --> 00:01:17.830
the mean of all of
my sample variances

00:01:17.830 --> 00:01:20.160
is really converged
to the true variance.

00:01:20.160 --> 00:01:22.720
When I divided by n
minus 2 just for kicks,

00:01:22.720 --> 00:01:27.510
it's pretty clear
that I overestimated

00:01:27.510 --> 00:01:30.780
with my mean of my
sample variances,

00:01:30.780 --> 00:01:32.729
I overestimated
the true variance.

00:01:32.729 --> 00:01:34.770
So this gives us a pretty
good sense of n minus 1

00:01:34.770 --> 00:01:36.310
is the right thing to do.

00:01:36.310 --> 00:01:40.140
Now this is another interesting
way of visualizing it.

00:01:40.140 --> 00:01:42.370
In the horizontal
axis right over here,

00:01:42.370 --> 00:01:45.900
we're comparing each plot
is one of our samples,

00:01:45.900 --> 00:01:48.100
and how far to the right
is how much more is

00:01:48.100 --> 00:01:50.294
that sample mean
than the true mean?

00:01:50.294 --> 00:01:52.210
And when we go to the
left, it's how much less

00:01:52.210 --> 00:01:54.230
is a sample mean
than the true mean?

00:01:54.230 --> 00:01:56.120
So for example, this
sample right over here,

00:01:56.120 --> 00:01:57.870
it's all the way
over to the right.

00:01:57.870 --> 00:02:00.720
It's the sample mean there was
a lot more than the true mean.

00:02:00.720 --> 00:02:03.160
Sample mean here was a lot
less than the true mean.

00:02:03.160 --> 00:02:06.210
Sample mean here only a little
bit more than the true mean.

00:02:06.210 --> 00:02:10.979
In the vertical axis, using
this denominator, dividing by n,

00:02:10.979 --> 00:02:13.570
we calculate two
different variances.

00:02:13.570 --> 00:02:16.170
One variance, we
use the sample mean.

00:02:16.170 --> 00:02:19.430
The other variance, we
use the population mean.

00:02:19.430 --> 00:02:21.510
And this, in the
vertical axis, we

00:02:21.510 --> 00:02:24.610
compare the difference
between the mean calculated

00:02:24.610 --> 00:02:26.850
with the sample mean
versus the mean calculated

00:02:26.850 --> 00:02:28.490
with the population mean.

00:02:28.490 --> 00:02:30.600
So for example, this
point right over here,

00:02:30.600 --> 00:02:33.690
when we calculate our mean
with our sample mean, which

00:02:33.690 --> 00:02:36.224
is the normal way we
do it, it significantly

00:02:36.224 --> 00:02:37.640
underestimates
what the mean would

00:02:37.640 --> 00:02:40.470
have been if somehow we knew
what the population mean was

00:02:40.470 --> 00:02:42.670
and we could
calculate it that way.

00:02:42.670 --> 00:02:44.480
And you get this really
interesting shape.

00:02:44.480 --> 00:02:45.896
And it's something
to think about.

00:02:45.896 --> 00:02:48.870
And he recommends some
thinking about why or what kind

00:02:48.870 --> 00:02:51.350
of a shape this actually is.

00:02:51.350 --> 00:02:54.250
The other interesting thing is
when you look at it this way,

00:02:54.250 --> 00:02:55.770
it's pretty clear
this entire graph

00:02:55.770 --> 00:02:58.850
is sitting below
the horizontal axis.

00:02:58.850 --> 00:03:01.810
So we're always, when we
calculate our sample variance

00:03:01.810 --> 00:03:06.380
using this formula, when we use
of the sample mean to do it,

00:03:06.380 --> 00:03:10.670
which we typically do, we're
always getting a lower variance

00:03:10.670 --> 00:03:14.980
than when we use
the population mean.

00:03:14.980 --> 00:03:18.120
Now this over here, when
we divide by n minus 1,

00:03:18.120 --> 00:03:19.970
we're not always
underestimating.

00:03:19.970 --> 00:03:21.840
Sometimes we are
overestimating it.

00:03:21.840 --> 00:03:24.089
And when you take the mean
of all of these variances,

00:03:24.089 --> 00:03:24.630
you converge.

00:03:24.630 --> 00:03:27.670
And here we're overestimating
it a little bit more.

00:03:27.670 --> 00:03:30.170
And just to be clear what we're
talking about in these three

00:03:30.170 --> 00:03:31.940
graphs, let me take
a screen shot of it

00:03:31.940 --> 00:03:34.610
and explain it in a
little bit more depth.

00:03:34.610 --> 00:03:39.240
So just to be clear, in this
red graph right over here,

00:03:39.240 --> 00:03:40.270
let me do this.

00:03:40.270 --> 00:03:42.160
A color close to at least.

00:03:42.160 --> 00:03:44.290
So this orange,
what this distance

00:03:44.290 --> 00:03:46.820
is for each of
these samples, we're

00:03:46.820 --> 00:03:54.260
calculating the sample
variance using, so let me,

00:03:54.260 --> 00:03:56.160
using the sample mean.

00:03:56.160 --> 00:03:59.830
And in this case, we are
using n as our denominator.

00:03:59.830 --> 00:04:01.470
In this case right over here.

00:04:01.470 --> 00:04:04.595
And from that we're subtracting
the sample variance,

00:04:04.595 --> 00:04:06.970
or I guess you could call this
some kind of pseudo sample

00:04:06.970 --> 00:04:11.130
variance, if we somehow
knew the population mean.

00:04:11.130 --> 00:04:13.520
This isn't something that
you see a lot in statistics.

00:04:13.520 --> 00:04:19.540
But it's a gauge of how much we
are underestimating our sample

00:04:19.540 --> 00:04:22.960
variance given that we don't
have the true population mean

00:04:22.960 --> 00:04:24.660
at our disposal.

00:04:24.660 --> 00:04:26.165
And so this is the distance.

00:04:26.165 --> 00:04:27.790
This is the distance
we're calculating.

00:04:27.790 --> 00:04:31.860
And you see we're
always underestimating.

00:04:31.860 --> 00:04:33.830
Here we overestimate
a little bit.

00:04:33.830 --> 00:04:35.460
And we also underestimate.

00:04:35.460 --> 00:04:38.130
But when you take the mean,
when you average them all out,

00:04:38.130 --> 00:04:39.920
it converges to
the actual value.

00:04:39.920 --> 00:04:41.770
So here we're
dividing by n minus 1,

00:04:41.770 --> 00:04:44.802
here we're dividing
by n minus 2.

