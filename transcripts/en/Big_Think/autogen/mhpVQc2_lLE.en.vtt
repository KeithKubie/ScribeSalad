WEBVTT
Kind: captions
Language: en

00:00:02.530 --> 00:00:05.650
 
if you think much about physics and

00:00:05.650 --> 00:00:05.660
if you think much about physics and
 

00:00:05.660 --> 00:00:08.530
if you think much about physics and
cognition and intelligence it's pretty

00:00:08.530 --> 00:00:08.540
cognition and intelligence it's pretty
 

00:00:08.540 --> 00:00:11.409
cognition and intelligence it's pretty
obvious the human mind is not the

00:00:11.409 --> 00:00:11.419
obvious the human mind is not the
 

00:00:11.419 --> 00:00:13.539
obvious the human mind is not the
smartest possible general intelligence

00:00:13.539 --> 00:00:13.549
smartest possible general intelligence
 

00:00:13.549 --> 00:00:15.640
smartest possible general intelligence
any more than humans are the highest

00:00:15.640 --> 00:00:15.650
any more than humans are the highest
 

00:00:15.650 --> 00:00:17.560
any more than humans are the highest
jumpers are the fastest runners we're

00:00:17.560 --> 00:00:17.570
jumpers are the fastest runners we're
 

00:00:17.570 --> 00:00:21.009
jumpers are the fastest runners we're
not going to be the smartest thinkers if

00:00:21.009 --> 00:00:21.019
not going to be the smartest thinkers if
 

00:00:21.019 --> 00:00:25.179
not going to be the smartest thinkers if
you are going to work toward AGI rather

00:00:25.179 --> 00:00:25.189
you are going to work toward AGI rather
 

00:00:25.189 --> 00:00:27.329
you are going to work toward AGI rather
than focusing on some narrow application

00:00:27.329 --> 00:00:27.339
than focusing on some narrow application
 

00:00:27.339 --> 00:00:30.790
than focusing on some narrow application
there's a number of different approaches

00:00:30.790 --> 00:00:30.800
there's a number of different approaches
 

00:00:30.800 --> 00:00:34.210
there's a number of different approaches
that you might take and I've spent some

00:00:34.210 --> 00:00:34.220
that you might take and I've spent some
 

00:00:34.220 --> 00:00:37.240
that you might take and I've spent some
time just surveying the AGI field as a

00:00:37.240 --> 00:00:37.250
time just surveying the AGI field as a
 

00:00:37.250 --> 00:00:38.980
time just surveying the AGI field as a
whole and organizing an annual

00:00:38.980 --> 00:00:38.990
whole and organizing an annual
 

00:00:38.990 --> 00:00:41.080
whole and organizing an annual
conference on the AGI and then I've

00:00:41.080 --> 00:00:41.090
conference on the AGI and then I've
 

00:00:41.090 --> 00:00:44.010
conference on the AGI and then I've
spent a bunch more time on a specific

00:00:44.010 --> 00:00:44.020
spent a bunch more time on a specific
 

00:00:44.020 --> 00:00:47.680
spent a bunch more time on a specific
AGI approach which is based on the open

00:00:47.680 --> 00:00:47.690
AGI approach which is based on the open
 

00:00:47.690 --> 00:00:51.910
AGI approach which is based on the open
cog open source software platform in the

00:00:51.910 --> 00:00:51.920
cog open source software platform in the
 

00:00:51.920 --> 00:00:54.640
cog open source software platform in the
big picture one way to approach AGI is

00:00:54.640 --> 00:00:54.650
big picture one way to approach AGI is
 

00:00:54.650 --> 00:00:57.070
big picture one way to approach AGI is
to try to emulate the human brain at

00:00:57.070 --> 00:00:57.080
to try to emulate the human brain at
 

00:00:57.080 --> 00:01:00.340
to try to emulate the human brain at
some level of precision and this is the

00:01:00.340 --> 00:01:00.350
some level of precision and this is the
 

00:01:00.350 --> 00:01:02.290
some level of precision and this is the
approach I see for example google

00:01:02.290 --> 00:01:02.300
approach I see for example google
 

00:01:02.300 --> 00:01:04.899
approach I see for example google
deepmind's taking they've taken deep

00:01:04.899 --> 00:01:04.909
deepmind's taking they've taken deep
 

00:01:04.909 --> 00:01:06.880
deepmind's taking they've taken deep
neural networks which in their common

00:01:06.880 --> 00:01:06.890
neural networks which in their common
 

00:01:06.890 --> 00:01:10.270
neural networks which in their common
form are mostly a model of visual and

00:01:10.270 --> 00:01:10.280
form are mostly a model of visual and
 

00:01:10.280 --> 00:01:13.090
form are mostly a model of visual and
auditory processing in the human brain

00:01:13.090 --> 00:01:13.100
auditory processing in the human brain
 

00:01:13.100 --> 00:01:16.200
auditory processing in the human brain
and now in their recent work such as the

00:01:16.200 --> 00:01:16.210
and now in their recent work such as the
 

00:01:16.210 --> 00:01:19.450
and now in their recent work such as the
DNC differential neural computer they're

00:01:19.450 --> 00:01:19.460
DNC differential neural computer they're
 

00:01:19.460 --> 00:01:21.969
DNC differential neural computer they're
taking these deep networks that model

00:01:21.969 --> 00:01:21.979
taking these deep networks that model
 

00:01:21.979 --> 00:01:24.249
taking these deep networks that model
visual or auditory processing and

00:01:24.249 --> 00:01:24.259
visual or auditory processing and
 

00:01:24.259 --> 00:01:25.989
visual or auditory processing and
they're coupling that with a memory

00:01:25.989 --> 00:01:25.999
they're coupling that with a memory
 

00:01:25.999 --> 00:01:28.120
they're coupling that with a memory
matrix which models some aspect of what

00:01:28.120 --> 00:01:28.130
matrix which models some aspect of what
 

00:01:28.130 --> 00:01:30.639
matrix which models some aspect of what
the hippocampus does which is the part

00:01:30.639 --> 00:01:30.649
the hippocampus does which is the part
 

00:01:30.649 --> 00:01:32.770
the hippocampus does which is the part
of the brain that deals with working

00:01:32.770 --> 00:01:32.780
of the brain that deals with working
 

00:01:32.780 --> 00:01:34.569
of the brain that deals with working
memory short-term memory among other

00:01:34.569 --> 00:01:34.579
memory short-term memory among other
 

00:01:34.579 --> 00:01:37.480
memory short-term memory among other
things so this illustrates an approach

00:01:37.480 --> 00:01:37.490
things so this illustrates an approach
 

00:01:37.490 --> 00:01:40.359
things so this illustrates an approach
where you take neural networks emulating

00:01:40.359 --> 00:01:40.369
where you take neural networks emulating
 

00:01:40.369 --> 00:01:42.370
where you take neural networks emulating
different parts of the brain and maybe

00:01:42.370 --> 00:01:42.380
different parts of the brain and maybe
 

00:01:42.380 --> 00:01:43.840
different parts of the brain and maybe
you take more and more in the neural

00:01:43.840 --> 00:01:43.850
you take more and more in the neural
 

00:01:43.850 --> 00:01:45.459
you take more and more in the neural
networks emulating different parts of

00:01:45.459 --> 00:01:45.469
networks emulating different parts of
 

00:01:45.469 --> 00:01:47.739
networks emulating different parts of
the human brain you try to get them to

00:01:47.739 --> 00:01:47.749
the human brain you try to get them to
 

00:01:47.749 --> 00:01:50.590
the human brain you try to get them to
all work together not necessarily doing

00:01:50.590 --> 00:01:50.600
all work together not necessarily doing
 

00:01:50.600 --> 00:01:53.679
all work together not necessarily doing
computational neuroscience but trying to

00:01:53.679 --> 00:01:53.689
computational neuroscience but trying to
 

00:01:53.689 --> 00:01:56.020
computational neuroscience but trying to
emulate the way different parts of the

00:01:56.020 --> 00:01:56.030
emulate the way different parts of the
 

00:01:56.030 --> 00:01:57.760
emulate the way different parts of the
brain are doing processing in the way

00:01:57.760 --> 00:01:57.770
brain are doing processing in the way
 

00:01:57.770 --> 00:02:00.190
brain are doing processing in the way
they're talking to each other a totally

00:02:00.190 --> 00:02:00.200
they're talking to each other a totally
 

00:02:00.200 --> 00:02:02.440
they're talking to each other a totally
different approach is being taken by a

00:02:02.440 --> 00:02:02.450
different approach is being taken by a
 

00:02:02.450 --> 00:02:05.620
different approach is being taken by a
guy named Marcus hooter in Australian

00:02:05.620 --> 00:02:05.630
guy named Marcus hooter in Australian
 

00:02:05.630 --> 00:02:07.929
guy named Marcus hooter in Australian
National University he wrote a beautiful

00:02:07.929 --> 00:02:07.939
National University he wrote a beautiful
 

00:02:07.939 --> 00:02:11.290
National University he wrote a beautiful
book on universal AI in which he showed

00:02:11.290 --> 00:02:11.300
book on universal AI in which he showed
 

00:02:11.300 --> 00:02:14.050
book on universal AI in which he showed
how to write a superhuman infinitely

00:02:14.050 --> 00:02:14.060
how to write a superhuman infinitely
 

00:02:14.060 --> 00:02:15.020
how to write a superhuman infinitely
intelligence think

00:02:15.020 --> 00:02:15.030
intelligence think
 

00:02:15.030 --> 00:02:18.050
intelligence think
machine and like 50 lines of code the

00:02:18.050 --> 00:02:18.060
machine and like 50 lines of code the
 

00:02:18.060 --> 00:02:21.440
machine and like 50 lines of code the
problem is it would take more computing

00:02:21.440 --> 00:02:21.450
problem is it would take more computing
 

00:02:21.450 --> 00:02:23.000
problem is it would take more computing
power than there is in the entire

00:02:23.000 --> 00:02:23.010
power than there is in the entire
 

00:02:23.010 --> 00:02:25.120
power than there is in the entire
universe to run so it's so it's not

00:02:25.120 --> 00:02:25.130
universe to run so it's so it's not
 

00:02:25.130 --> 00:02:27.410
universe to run so it's so it's not
practically useful but they're done

00:02:27.410 --> 00:02:27.420
practically useful but they're done
 

00:02:27.420 --> 00:02:29.059
practically useful but they're done
trying to scale down from this

00:02:29.059 --> 00:02:29.069
trying to scale down from this
 

00:02:29.069 --> 00:02:32.300
trying to scale down from this
theoretical AGI to find something that

00:02:32.300 --> 00:02:32.310
theoretical AGI to find something that
 

00:02:32.310 --> 00:02:35.449
theoretical AGI to find something that
that will really work now the approach

00:02:35.449 --> 00:02:35.459
that will really work now the approach
 

00:02:35.459 --> 00:02:38.960
that will really work now the approach
we're taking in the OpenCog project is

00:02:38.960 --> 00:02:38.970
we're taking in the OpenCog project is
 

00:02:38.970 --> 00:02:42.199
we're taking in the OpenCog project is
different than either of those we're

00:02:42.199 --> 00:02:42.209
different than either of those we're
 

00:02:42.209 --> 00:02:44.330
different than either of those we're
attempting to emulate at a very high

00:02:44.330 --> 00:02:44.340
attempting to emulate at a very high
 

00:02:44.340 --> 00:02:47.449
attempting to emulate at a very high
level the way the human mind seems to

00:02:47.449 --> 00:02:47.459
level the way the human mind seems to
 

00:02:47.459 --> 00:02:50.960
level the way the human mind seems to
work as an embodied social generally

00:02:50.960 --> 00:02:50.970
work as an embodied social generally
 

00:02:50.970 --> 00:02:53.479
work as an embodied social generally
intelligent agent which is coming to

00:02:53.479 --> 00:02:53.489
intelligent agent which is coming to
 

00:02:53.489 --> 00:02:56.840
intelligent agent which is coming to
grips with hard problems in the context

00:02:56.840 --> 00:02:56.850
grips with hard problems in the context
 

00:02:56.850 --> 00:02:58.759
grips with hard problems in the context
of coming to grips with itself and it's

00:02:58.759 --> 00:02:58.769
of coming to grips with itself and it's
 

00:02:58.769 --> 00:03:01.490
of coming to grips with itself and it's
an its life in the world we're not

00:03:01.490 --> 00:03:01.500
an its life in the world we're not
 

00:03:01.500 --> 00:03:03.949
an its life in the world we're not
trying to model the way the brain works

00:03:03.949 --> 00:03:03.959
trying to model the way the brain works
 

00:03:03.959 --> 00:03:05.990
trying to model the way the brain works
at the level of neurons or neural

00:03:05.990 --> 00:03:06.000
at the level of neurons or neural
 

00:03:06.000 --> 00:03:08.440
at the level of neurons or neural
networks we're looking at the human mind

00:03:08.440 --> 00:03:08.450
networks we're looking at the human mind
 

00:03:08.450 --> 00:03:11.120
networks we're looking at the human mind
more from a high-level cognitive point

00:03:11.120 --> 00:03:11.130
more from a high-level cognitive point
 

00:03:11.130 --> 00:03:13.280
more from a high-level cognitive point
of view what kinds of memory are there

00:03:13.280 --> 00:03:13.290
of view what kinds of memory are there
 

00:03:13.290 --> 00:03:16.040
of view what kinds of memory are there
well there's semantic memory about

00:03:16.040 --> 00:03:16.050
well there's semantic memory about
 

00:03:16.050 --> 00:03:18.650
well there's semantic memory about
abstract knowledge or concrete facts

00:03:18.650 --> 00:03:18.660
abstract knowledge or concrete facts
 

00:03:18.660 --> 00:03:20.860
abstract knowledge or concrete facts
there's episodic memory of our

00:03:20.860 --> 00:03:20.870
there's episodic memory of our
 

00:03:20.870 --> 00:03:23.750
there's episodic memory of our
autobiographical history they're sensory

00:03:23.750 --> 00:03:23.760
autobiographical history they're sensory
 

00:03:23.760 --> 00:03:24.920
autobiographical history they're sensory
motor memory

00:03:24.920 --> 00:03:24.930
motor memory
 

00:03:24.930 --> 00:03:27.289
motor memory
there's associative memory of things

00:03:27.289 --> 00:03:27.299
there's associative memory of things
 

00:03:27.299 --> 00:03:29.150
there's associative memory of things
that have been related to us in our

00:03:29.150 --> 00:03:29.160
that have been related to us in our
 

00:03:29.160 --> 00:03:29.780
that have been related to us in our
lives

00:03:29.780 --> 00:03:29.790
lives
 

00:03:29.790 --> 00:03:32.060
lives
there's procedural memory of how to do

00:03:32.060 --> 00:03:32.070
there's procedural memory of how to do
 

00:03:32.070 --> 00:03:34.370
there's procedural memory of how to do
things and we then look at the different

00:03:34.370 --> 00:03:34.380
things and we then look at the different
 

00:03:34.380 --> 00:03:37.310
things and we then look at the different
kinds of learning and reasoning the

00:03:37.310 --> 00:03:37.320
kinds of learning and reasoning the
 

00:03:37.320 --> 00:03:40.729
kinds of learning and reasoning the
human mind can do we can do logical

00:03:40.729 --> 00:03:40.739
human mind can do we can do logical
 

00:03:40.739 --> 00:03:42.800
human mind can do we can do logical
deduction sometimes we're not always

00:03:42.800 --> 00:03:42.810
deduction sometimes we're not always
 

00:03:42.810 --> 00:03:45.050
deduction sometimes we're not always
good at it we we make emotional

00:03:45.050 --> 00:03:45.060
good at it we we make emotional
 

00:03:45.060 --> 00:03:48.110
good at it we we make emotional
intuitive leaps and strange creative

00:03:48.110 --> 00:03:48.120
intuitive leaps and strange creative
 

00:03:48.120 --> 00:03:51.080
intuitive leaps and strange creative
combinations of things we learn by trial

00:03:51.080 --> 00:03:51.090
combinations of things we learn by trial
 

00:03:51.090 --> 00:03:53.900
combinations of things we learn by trial
and error and habit we learn socially by

00:03:53.900 --> 00:03:53.910
and error and habit we learn socially by
 

00:03:53.910 --> 00:03:56.360
and error and habit we learn socially by
imitating mirroring emulating or

00:03:56.360 --> 00:03:56.370
imitating mirroring emulating or
 

00:03:56.370 --> 00:03:59.630
imitating mirroring emulating or
opposing others these different kinds of

00:03:59.630 --> 00:03:59.640
opposing others these different kinds of
 

00:03:59.640 --> 00:04:02.000
opposing others these different kinds of
memory and learning that the human mind

00:04:02.000 --> 00:04:02.010
memory and learning that the human mind
 

00:04:02.010 --> 00:04:05.090
memory and learning that the human mind
has one can attempt to achieve each of

00:04:05.090 --> 00:04:05.100
has one can attempt to achieve each of
 

00:04:05.100 --> 00:04:07.640
has one can attempt to achieve each of
those with a cutting-edge computer

00:04:07.640 --> 00:04:07.650
those with a cutting-edge computer
 

00:04:07.650 --> 00:04:10.550
those with a cutting-edge computer
science algorithm rather than trying to

00:04:10.550 --> 00:04:10.560
science algorithm rather than trying to
 

00:04:10.560 --> 00:04:13.340
science algorithm rather than trying to
achieve each of those functions and

00:04:13.340 --> 00:04:13.350
achieve each of those functions and
 

00:04:13.350 --> 00:04:16.430
achieve each of those functions and
structures in the way the brain does so

00:04:16.430 --> 00:04:16.440
structures in the way the brain does so
 

00:04:16.440 --> 00:04:19.210
structures in the way the brain does so
what we have in OpenCog we have a

00:04:19.210 --> 00:04:19.220
what we have in OpenCog we have a
 

00:04:19.220 --> 00:04:23.240
what we have in OpenCog we have a
central knowledge repository which is

00:04:23.240 --> 00:04:23.250
central knowledge repository which is
 

00:04:23.250 --> 00:04:25.670
central knowledge repository which is
very dynamic and lives in RAM on a large

00:04:25.670 --> 00:04:25.680
very dynamic and lives in RAM on a large
 

00:04:25.680 --> 00:04:27.920
very dynamic and lives in RAM on a large
network of computers which we call the

00:04:27.920 --> 00:04:27.930
network of computers which we call the
 

00:04:27.930 --> 00:04:28.730
network of computers which we call the
atoms

00:04:28.730 --> 00:04:28.740
atoms
 

00:04:28.740 --> 00:04:32.629
atoms
and for for the mathematicians or

00:04:32.629 --> 00:04:32.639
and for for the mathematicians or
 

00:04:32.639 --> 00:04:35.480
and for for the mathematicians or
computer science in the audience the the

00:04:35.480 --> 00:04:35.490
computer science in the audience the the
 

00:04:35.490 --> 00:04:37.610
computer science in the audience the the
item space is what you'd call a a

00:04:37.610 --> 00:04:37.620
item space is what you'd call a a
 

00:04:37.620 --> 00:04:40.520
item space is what you'd call a a
weighted labeled hypergraph so it has

00:04:40.520 --> 00:04:40.530
weighted labeled hypergraph so it has
 

00:04:40.530 --> 00:04:43.969
weighted labeled hypergraph so it has
nodes it has links a link can go between

00:04:43.969 --> 00:04:43.979
nodes it has links a link can go between
 

00:04:43.979 --> 00:04:46.370
nodes it has links a link can go between
two nodes or a link you go between three

00:04:46.370 --> 00:04:46.380
two nodes or a link you go between three
 

00:04:46.380 --> 00:04:49.790
two nodes or a link you go between three
four five or fifty nodes different nodes

00:04:49.790 --> 00:04:49.800
four five or fifty nodes different nodes
 

00:04:49.800 --> 00:04:52.520
four five or fifty nodes different nodes
and links have different types and the

00:04:52.520 --> 00:04:52.530
and links have different types and the
 

00:04:52.530 --> 00:04:54.529
and links have different types and the
nodes and links can have numbers

00:04:54.529 --> 00:04:54.539
nodes and links can have numbers
 

00:04:54.539 --> 00:04:56.570
nodes and links can have numbers
attached to them another link could have

00:04:56.570 --> 00:04:56.580
attached to them another link could have
 

00:04:56.580 --> 00:04:58.610
attached to them another link could have
a weight indicating a probability or a

00:04:58.610 --> 00:04:58.620
a weight indicating a probability or a
 

00:04:58.620 --> 00:05:00.710
a weight indicating a probability or a
confidence it could have a weight

00:05:00.710 --> 00:05:00.720
confidence it could have a weight
 

00:05:00.720 --> 00:05:02.450
confidence it could have a weight
indicating how important it is to the

00:05:02.450 --> 00:05:02.460
indicating how important it is to the
 

00:05:02.460 --> 00:05:04.790
indicating how important it is to the
system right now or how important it is

00:05:04.790 --> 00:05:04.800
system right now or how important it is
 

00:05:04.800 --> 00:05:07.219
system right now or how important it is
in the long term so it should be kept

00:05:07.219 --> 00:05:07.229
in the long term so it should be kept
 

00:05:07.229 --> 00:05:10.250
in the long term so it should be kept
around in the system's memory on this

00:05:10.250 --> 00:05:10.260
around in the system's memory on this
 

00:05:10.260 --> 00:05:14.420
around in the system's memory on this
atom space this weighted labeled hyper

00:05:14.420 --> 00:05:14.430
atom space this weighted labeled hyper
 

00:05:14.430 --> 00:05:17.680
atom space this weighted labeled hyper
graph we can have a lot of different AI

00:05:17.680 --> 00:05:17.690
graph we can have a lot of different AI
 

00:05:17.690 --> 00:05:20.779
graph we can have a lot of different AI
processes working together cooperatively

00:05:20.779 --> 00:05:20.789
processes working together cooperatively
 

00:05:20.789 --> 00:05:24.980
processes working together cooperatively
so the the atom space the memory store

00:05:24.980 --> 00:05:24.990
so the the atom space the memory store
 

00:05:24.990 --> 00:05:27.740
so the the atom space the memory store
is what we would call neural symbolic

00:05:27.740 --> 00:05:27.750
is what we would call neural symbolic
 

00:05:27.750 --> 00:05:31.310
is what we would call neural symbolic
that means we can represent nodes and

00:05:31.310 --> 00:05:31.320
that means we can represent nodes and
 

00:05:31.320 --> 00:05:33.620
that means we can represent nodes and
links that are like neurons in the brain

00:05:33.620 --> 00:05:33.630
links that are like neurons in the brain
 

00:05:33.630 --> 00:05:36.409
links that are like neurons in the brain
which is fairly low-level but we can

00:05:36.409 --> 00:05:36.419
which is fairly low-level but we can
 

00:05:36.419 --> 00:05:38.950
which is fairly low-level but we can
also represent nodes and links that are

00:05:38.950 --> 00:05:38.960
also represent nodes and links that are
 

00:05:38.960 --> 00:05:40.189
also represent nodes and links that are
higher-level

00:05:40.189 --> 00:05:40.199
higher-level
 

00:05:40.199 --> 00:05:42.920
higher-level
representing pieces of symbolic logic

00:05:42.920 --> 00:05:42.930
representing pieces of symbolic logic
 

00:05:42.930 --> 00:05:45.649
representing pieces of symbolic logic
expressions so we can do explicit

00:05:45.649 --> 00:05:45.659
expressions so we can do explicit
 

00:05:45.659 --> 00:05:47.570
expressions so we can do explicit
logical reasoning which is pretty

00:05:47.570 --> 00:05:47.580
logical reasoning which is pretty
 

00:05:47.580 --> 00:05:50.540
logical reasoning which is pretty
abstract and low-level neural net stuff

00:05:50.540 --> 00:05:50.550
abstract and low-level neural net stuff
 

00:05:50.550 --> 00:05:54.140
abstract and low-level neural net stuff
in the same hyper graph the same atom

00:05:54.140 --> 00:05:54.150
in the same hyper graph the same atom
 

00:05:54.150 --> 00:05:57.290
in the same hyper graph the same atom
space acting on this atom space we have

00:05:57.290 --> 00:05:57.300
space acting on this atom space we have
 

00:05:57.300 --> 00:06:00.320
space acting on this atom space we have
deep neural networks for visual and

00:06:00.320 --> 00:06:00.330
deep neural networks for visual and
 

00:06:00.330 --> 00:06:02.750
deep neural networks for visual and
auditory perception we have a

00:06:02.750 --> 00:06:02.760
auditory perception we have a
 

00:06:02.760 --> 00:06:05.420
auditory perception we have a
probabilistic logic engine which does

00:06:05.420 --> 00:06:05.430
probabilistic logic engine which does
 

00:06:05.430 --> 00:06:07.850
probabilistic logic engine which does
abstract reasoning we have an

00:06:07.850 --> 00:06:07.860
abstract reasoning we have an
 

00:06:07.860 --> 00:06:09.649
abstract reasoning we have an
evolutionary learning algorithm that

00:06:09.649 --> 00:06:09.659
evolutionary learning algorithm that
 

00:06:09.659 --> 00:06:12.379
evolutionary learning algorithm that
uses genetic algorithm type methods to

00:06:12.379 --> 00:06:12.389
uses genetic algorithm type methods to
 

00:06:12.389 --> 00:06:15.920
uses genetic algorithm type methods to
try to evolve radical new ideas and

00:06:15.920 --> 00:06:15.930
try to evolve radical new ideas and
 

00:06:15.930 --> 00:06:18.409
try to evolve radical new ideas and
concepts and look for data patterns and

00:06:18.409 --> 00:06:18.419
concepts and look for data patterns and
 

00:06:18.419 --> 00:06:20.839
concepts and look for data patterns and
we have a neural net type dynamic that

00:06:20.839 --> 00:06:20.849
we have a neural net type dynamic that
 

00:06:20.849 --> 00:06:23.839
we have a neural net type dynamic that
spreads activity and importance

00:06:23.839 --> 00:06:23.849
spreads activity and importance
 

00:06:23.849 --> 00:06:26.390
spreads activity and importance
throughout the network a few other

00:06:26.390 --> 00:06:26.400
throughout the network a few other
 

00:06:26.400 --> 00:06:28.670
throughout the network a few other
algorithms a pattern mining algorithm

00:06:28.670 --> 00:06:28.680
algorithms a pattern mining algorithm
 

00:06:28.680 --> 00:06:30.920
algorithms a pattern mining algorithm
that just scans through the whole atom

00:06:30.920 --> 00:06:30.930
that just scans through the whole atom
 

00:06:30.930 --> 00:06:33.219
that just scans through the whole atom
space looking for surprising stuff and

00:06:33.219 --> 00:06:33.229
space looking for surprising stuff and
 

00:06:33.229 --> 00:06:36.200
space looking for surprising stuff and
the trick is all these different

00:06:36.200 --> 00:06:36.210
the trick is all these different
 

00:06:36.210 --> 00:06:39.320
the trick is all these different
cognitive algorithms have to work

00:06:39.320 --> 00:06:39.330
cognitive algorithms have to work
 

00:06:39.330 --> 00:06:41.970
cognitive algorithms have to work
together cooperatively

00:06:41.970 --> 00:06:41.980
together cooperatively
 

00:06:41.980 --> 00:06:43.920
together cooperatively
to help each other rather than hurt each

00:06:43.920 --> 00:06:43.930
to help each other rather than hurt each
 

00:06:43.930 --> 00:06:46.770
to help each other rather than hurt each
other see the bottleneck in essentially

00:06:46.770 --> 00:06:46.780
other see the bottleneck in essentially
 

00:06:46.780 --> 00:06:50.220
other see the bottleneck in essentially
every AI approach ever taken be it a

00:06:50.220 --> 00:06:50.230
every AI approach ever taken be it a
 

00:06:50.230 --> 00:06:52.620
every AI approach ever taken be it a
neural net a logic engine the genetic

00:06:52.620 --> 00:06:52.630
neural net a logic engine the genetic
 

00:06:52.630 --> 00:06:55.200
neural net a logic engine the genetic
algorithm whatever the bottleneck in

00:06:55.200 --> 00:06:55.210
algorithm whatever the bottleneck in
 

00:06:55.210 --> 00:06:57.810
algorithm whatever the bottleneck in
every AI approach ever taken has been

00:06:57.810 --> 00:06:57.820
every AI approach ever taken has been
 

00:06:57.820 --> 00:07:00.480
every AI approach ever taken has been
what we call combinatorial explosion and

00:07:00.480 --> 00:07:00.490
what we call combinatorial explosion and
 

00:07:00.490 --> 00:07:03.090
what we call combinatorial explosion and
what that means is you have a lot of

00:07:03.090 --> 00:07:03.100
what that means is you have a lot of
 

00:07:03.100 --> 00:07:04.920
what that means is you have a lot of
data items your a lot of perceptions

00:07:04.920 --> 00:07:04.930
data items your a lot of perceptions
 

00:07:04.930 --> 00:07:07.320
data items your a lot of perceptions
coming into your eye or you have a lot

00:07:07.320 --> 00:07:07.330
coming into your eye or you have a lot
 

00:07:07.330 --> 00:07:09.810
coming into your eye or you have a lot
of possible moves on the chessboard or a

00:07:09.810 --> 00:07:09.820
of possible moves on the chessboard or a
 

00:07:09.820 --> 00:07:11.850
of possible moves on the chessboard or a
lot of possible ways to move the wheel

00:07:11.850 --> 00:07:11.860
lot of possible ways to move the wheel
 

00:07:11.860 --> 00:07:15.120
lot of possible ways to move the wheel
of the car and there's so many

00:07:15.120 --> 00:07:15.130
of the car and there's so many
 

00:07:15.130 --> 00:07:17.730
of the car and there's so many
combinations of possible data items and

00:07:17.730 --> 00:07:17.740
combinations of possible data items and
 

00:07:17.740 --> 00:07:20.100
combinations of possible data items and
possible things you could do sifting

00:07:20.100 --> 00:07:20.110
possible things you could do sifting
 

00:07:20.110 --> 00:07:22.950
possible things you could do sifting
through all those combinations becomes

00:07:22.950 --> 00:07:22.960
through all those combinations becomes
 

00:07:22.960 --> 00:07:25.890
through all those combinations becomes
an exponential problem I mean if you

00:07:25.890 --> 00:07:25.900
an exponential problem I mean if you
 

00:07:25.900 --> 00:07:28.290
an exponential problem I mean if you
have a thousand things there's two to

00:07:28.290 --> 00:07:28.300
have a thousand things there's two to
 

00:07:28.300 --> 00:07:30.030
have a thousand things there's two to
the one thousandth will hit combine them

00:07:30.030 --> 00:07:30.040
the one thousandth will hit combine them
 

00:07:30.040 --> 00:07:32.610
the one thousandth will hit combine them
and that and that's way too many so how

00:07:32.610 --> 00:07:32.620
and that and that's way too many so how
 

00:07:32.620 --> 00:07:34.800
and that and that's way too many so how
to sift through combinatorial explosions

00:07:34.800 --> 00:07:34.810
to sift through combinatorial explosions
 

00:07:34.810 --> 00:07:37.890
to sift through combinatorial explosions
is the core problem everyone has to deal

00:07:37.890 --> 00:07:37.900
is the core problem everyone has to deal
 

00:07:37.900 --> 00:07:40.400
is the core problem everyone has to deal
with in a deep neural network as

00:07:40.400 --> 00:07:40.410
with in a deep neural network as
 

00:07:40.410 --> 00:07:43.800
with in a deep neural network as
currently pursued it's solved by making

00:07:43.800 --> 00:07:43.810
currently pursued it's solved by making
 

00:07:43.810 --> 00:07:46.280
currently pursued it's solved by making
the network have a very specific

00:07:46.280 --> 00:07:46.290
the network have a very specific
 

00:07:46.290 --> 00:07:48.660
the network have a very specific
structure which reflects the structure

00:07:48.660 --> 00:07:48.670
structure which reflects the structure
 

00:07:48.670 --> 00:07:52.530
structure which reflects the structure
of visual and auditory streams and in a

00:07:52.530 --> 00:07:52.540
of visual and auditory streams and in a
 

00:07:52.540 --> 00:07:54.900
of visual and auditory streams and in a
logic engine you don't have that sort of

00:07:54.900 --> 00:07:54.910
logic engine you don't have that sort of
 

00:07:54.910 --> 00:07:56.730
logic engine you don't have that sort of
luxury because the logic engine has to

00:07:56.730 --> 00:07:56.740
luxury because the logic engine has to
 

00:07:56.740 --> 00:07:58.890
luxury because the logic engine has to
deal with anything not not just sensory

00:07:58.890 --> 00:07:58.900
deal with anything not not just sensory
 

00:07:58.900 --> 00:08:02.910
deal with anything not not just sensory
data but what we do in OpenCog is we've

00:08:02.910 --> 00:08:02.920
data but what we do in OpenCog is we've
 

00:08:02.920 --> 00:08:05.940
data but what we do in OpenCog is we've
worked out a system where each of the

00:08:05.940 --> 00:08:05.950
worked out a system where each of the
 

00:08:05.950 --> 00:08:08.340
worked out a system where each of the
cognitive processes can help the other

00:08:08.340 --> 00:08:08.350
cognitive processes can help the other
 

00:08:08.350 --> 00:08:11.010
cognitive processes can help the other
one out when they when it gets stuck in

00:08:11.010 --> 00:08:11.020
one out when they when it gets stuck in
 

00:08:11.020 --> 00:08:13.260
one out when they when it gets stuck in
some combinatorial explosion problems so

00:08:13.260 --> 00:08:13.270
some combinatorial explosion problems so
 

00:08:13.270 --> 00:08:15.600
some combinatorial explosion problems so
if a deep neural network trying to

00:08:15.600 --> 00:08:15.610
if a deep neural network trying to
 

00:08:15.610 --> 00:08:17.520
if a deep neural network trying to
perceive things gets confused because

00:08:17.520 --> 00:08:17.530
perceive things gets confused because
 

00:08:17.530 --> 00:08:18.990
perceive things gets confused because
it's dark or it's looking at something

00:08:18.990 --> 00:08:19.000
it's dark or it's looking at something
 

00:08:19.000 --> 00:08:21.330
it's dark or it's looking at something
it never saw before well maybe the

00:08:21.330 --> 00:08:21.340
it never saw before well maybe the
 

00:08:21.340 --> 00:08:23.580
it never saw before well maybe the
reasoning engine can come in and do some

00:08:23.580 --> 00:08:23.590
reasoning engine can come in and do some
 

00:08:23.590 --> 00:08:25.290
reasoning engine can come in and do some
inference to cut through that confusion

00:08:25.290 --> 00:08:25.300
inference to cut through that confusion
 

00:08:25.300 --> 00:08:28.290
inference to cut through that confusion
if najuk already is getting confused and

00:08:28.290 --> 00:08:28.300
if najuk already is getting confused and
 

00:08:28.300 --> 00:08:30.540
if najuk already is getting confused and
doesn't know what step to take next

00:08:30.540 --> 00:08:30.550
doesn't know what step to take next
 

00:08:30.550 --> 00:08:31.620
doesn't know what step to take next
because there's just so many

00:08:31.620 --> 00:08:31.630
because there's just so many
 

00:08:31.630 --> 00:08:33.960
because there's just so many
possibilities out there and not much

00:08:33.960 --> 00:08:33.970
possibilities out there and not much
 

00:08:33.970 --> 00:08:36.570
possibilities out there and not much
information about them well maybe you

00:08:36.570 --> 00:08:36.580
information about them well maybe you
 

00:08:36.580 --> 00:08:38.790
information about them well maybe you
fish into your sensory motor memory and

00:08:38.790 --> 00:08:38.800
fish into your sensory motor memory and
 

00:08:38.800 --> 00:08:41.010
fish into your sensory motor memory and
you use deep learning to visualize

00:08:41.010 --> 00:08:41.020
you use deep learning to visualize
 

00:08:41.020 --> 00:08:43.230
you use deep learning to visualize
something you saw before and that gives

00:08:43.230 --> 00:08:43.240
something you saw before and that gives
 

00:08:43.240 --> 00:08:45.600
something you saw before and that gives
you a clue of how to pair through the

00:08:45.600 --> 00:08:45.610
you a clue of how to pair through the
 

00:08:45.610 --> 00:08:48.120
you a clue of how to pair through the
many possibilities that the logic engine

00:08:48.120 --> 00:08:48.130
many possibilities that the logic engine
 

00:08:48.130 --> 00:08:51.000
many possibilities that the logic engine
is seeing now you you can model this

00:08:51.000 --> 00:08:51.010
is seeing now you you can model this
 

00:08:51.010 --> 00:08:54.699
is seeing now you you can model this
kind of cognitive synergy

00:08:54.699 --> 00:08:54.709
kind of cognitive synergy
 

00:08:54.709 --> 00:08:56.749
kind of cognitive synergy
mathematically using a branch of

00:08:56.749 --> 00:08:56.759
mathematically using a branch of
 

00:08:56.759 --> 00:08:59.360
mathematically using a branch of
mathematics called category theory which

00:08:59.360 --> 00:08:59.370
mathematics called category theory which
 

00:08:59.370 --> 00:09:01.389
mathematics called category theory which
is something I've been working on lately

00:09:01.389 --> 00:09:01.399
is something I've been working on lately
 

00:09:01.399 --> 00:09:05.509
is something I've been working on lately
but what's really interesting more so is

00:09:05.509 --> 00:09:05.519
but what's really interesting more so is
 

00:09:05.519 --> 00:09:08.329
but what's really interesting more so is
to build a system that manifests this

00:09:08.329 --> 00:09:08.339
to build a system that manifests this
 

00:09:08.339 --> 00:09:11.869
to build a system that manifests this
and achieves general intelligence as a

00:09:11.869 --> 00:09:11.879
and achieves general intelligence as a
 

00:09:11.879 --> 00:09:13.519
and achieves general intelligence as a
result and that's what we're doing in

00:09:13.519 --> 00:09:13.529
result and that's what we're doing in
 

00:09:13.529 --> 00:09:15.740
result and that's what we're doing in
the OpenCog project we're not there yet

00:09:15.740 --> 00:09:15.750
the OpenCog project we're not there yet
 

00:09:15.750 --> 00:09:18.949
the OpenCog project we're not there yet
to general intelligence but we're

00:09:18.949 --> 00:09:18.959
to general intelligence but we're
 

00:09:18.959 --> 00:09:20.929
to general intelligence but we're
getting there step by step we're using

00:09:20.929 --> 00:09:20.939
getting there step by step we're using
 

00:09:20.939 --> 00:09:24.139
getting there step by step we're using
our open source open cog platform to

00:09:24.139 --> 00:09:24.149
our open source open cog platform to
 

00:09:24.149 --> 00:09:27.249
our open source open cog platform to
control david Henson's beautiful

00:09:27.249 --> 00:09:27.259
control david Henson's beautiful
 

00:09:27.259 --> 00:09:29.929
control david Henson's beautiful
incredibly realistic humanoid robots

00:09:29.929 --> 00:09:29.939
incredibly realistic humanoid robots
 

00:09:29.939 --> 00:09:32.240
incredibly realistic humanoid robots
like this Sofia robot which has gotten a

00:09:32.240 --> 00:09:32.250
like this Sofia robot which has gotten a
 

00:09:32.250 --> 00:09:34.999
like this Sofia robot which has gotten a
lot of media attention in the last year

00:09:34.999 --> 00:09:35.009
lot of media attention in the last year
 

00:09:35.009 --> 00:09:37.840
lot of media attention in the last year
we're using OpenCog to analyze

00:09:37.840 --> 00:09:37.850
we're using OpenCog to analyze
 

00:09:37.850 --> 00:09:40.579
we're using OpenCog to analyze
biological data related to the genetics

00:09:40.579 --> 00:09:40.589
biological data related to the genetics
 

00:09:40.589 --> 00:09:43.790
biological data related to the genetics
of longevity and we're doing a host of

00:09:43.790 --> 00:09:43.800
of longevity and we're doing a host of
 

00:09:43.800 --> 00:09:46.850
of longevity and we're doing a host of
other consulting projects using this so

00:09:46.850 --> 00:09:46.860
other consulting projects using this so
 

00:09:46.860 --> 00:09:49.429
other consulting projects using this so
we're we're proceeding on an R&amp;D track

00:09:49.429 --> 00:09:49.439
we're we're proceeding on an R&amp;D track
 

00:09:49.439 --> 00:09:51.559
we're we're proceeding on an R&amp;D track
and an application track at the same

00:09:51.559 --> 00:09:51.569
and an application track at the same
 

00:09:51.569 --> 00:09:55.309
and an application track at the same
time but our end goal with the system is

00:09:55.309 --> 00:09:55.319
time but our end goal with the system is
 

00:09:55.319 --> 00:09:59.300
time but our end goal with the system is
to use cognitive synergy on our neural

00:09:59.300 --> 00:09:59.310
to use cognitive synergy on our neural
 

00:09:59.310 --> 00:10:02.019
to use cognitive synergy on our neural
symbolic knowledge store to achieve

00:10:02.019 --> 00:10:02.029
symbolic knowledge store to achieve
 

00:10:02.029 --> 00:10:05.090
symbolic knowledge store to achieve
initially human level III but that's

00:10:05.090 --> 00:10:05.100
initially human level III but that's
 

00:10:05.100 --> 00:10:08.540
initially human level III but that's
just an early stage goal and then AI at

00:10:08.540 --> 00:10:08.550
just an early stage goal and then AI at
 

00:10:08.550 --> 00:10:11.420
just an early stage goal and then AI at
much beyond the human level and that is

00:10:11.420 --> 00:10:11.430
much beyond the human level and that is
 

00:10:11.430 --> 00:10:13.999
much beyond the human level and that is
another advantage of taking an approach

00:10:13.999 --> 00:10:14.009
another advantage of taking an approach
 

00:10:14.009 --> 00:10:17.120
another advantage of taking an approach
that doesn't adhere slavishly to the

00:10:17.120 --> 00:10:17.130
that doesn't adhere slavishly to the
 

00:10:17.130 --> 00:10:19.309
that doesn't adhere slavishly to the
human brain the brain is pretty good at

00:10:19.309 --> 00:10:19.319
human brain the brain is pretty good at
 

00:10:19.319 --> 00:10:22.100
human brain the brain is pretty good at
recognizing faces because millions of

00:10:22.100 --> 00:10:22.110
recognizing faces because millions of
 

00:10:22.110 --> 00:10:24.439
recognizing faces because millions of
years of evolution went into that part

00:10:24.439 --> 00:10:24.449
years of evolution went into that part
 

00:10:24.449 --> 00:10:26.809
years of evolution went into that part
of the brain but for doing science or

00:10:26.809 --> 00:10:26.819
of the brain but for doing science or
 

00:10:26.819 --> 00:10:28.970
of the brain but for doing science or
math or logical reasoning or strategic

00:10:28.970 --> 00:10:28.980
math or logical reasoning or strategic
 

00:10:28.980 --> 00:10:31.850
math or logical reasoning or strategic
planning we're pretty bad and and these

00:10:31.850 --> 00:10:31.860
planning we're pretty bad and and these
 

00:10:31.860 --> 00:10:34.189
planning we're pretty bad and and these
are things that we've started doing only

00:10:34.189 --> 00:10:34.199
are things that we've started doing only
 

00:10:34.199 --> 00:10:36.769
are things that we've started doing only
recently in evolutionary time as a

00:10:36.769 --> 00:10:36.779
recently in evolutionary time as a
 

00:10:36.779 --> 00:10:40.040
recently in evolutionary time as a
result of modern culture so I think

00:10:40.040 --> 00:10:40.050
result of modern culture so I think
 

00:10:40.050 --> 00:10:43.370
result of modern culture so I think
actually OpenCog and other AI systems

00:10:43.370 --> 00:10:43.380
actually OpenCog and other AI systems
 

00:10:43.380 --> 00:10:46.329
actually OpenCog and other AI systems
have potential to be far better than

00:10:46.329 --> 00:10:46.339
have potential to be far better than
 

00:10:46.339 --> 00:10:49.249
have potential to be far better than
human beings that the sort of logical

00:10:49.249 --> 00:10:49.259
human beings that the sort of logical
 

00:10:49.259 --> 00:10:52.400
human beings that the sort of logical
and strategic side of things and I think

00:10:52.400 --> 00:10:52.410
and strategic side of things and I think
 

00:10:52.410 --> 00:10:54.199
and strategic side of things and I think
that's quite important because if you

00:10:54.199 --> 00:10:54.209
that's quite important because if you
 

00:10:54.209 --> 00:10:56.990
that's quite important because if you
take a human being and upgrade them to

00:10:56.990 --> 00:10:57.000
take a human being and upgrade them to
 

00:10:57.000 --> 00:11:02.119
take a human being and upgrade them to
like 10,000 IQ the the outcomes might

00:11:02.119 --> 00:11:02.129
like 10,000 IQ the the outcomes might
 

00:11:02.129 --> 00:11:04.280
like 10,000 IQ the the outcomes might
not be what you want because you you've

00:11:04.280 --> 00:11:04.290
not be what you want because you you've
 

00:11:04.290 --> 00:11:06.110
not be what you want because you you've
got a motivational system and an

00:11:06.110 --> 00:11:06.120
got a motivational system and an
 

00:11:06.120 --> 00:11:07.970
got a motivational system and an
emotional system that

00:11:07.970 --> 00:11:07.980
emotional system that
 

00:11:07.980 --> 00:11:11.180
emotional system that
basically evolved in pre-human animals

00:11:11.180 --> 00:11:11.190
basically evolved in pre-human animals
 

00:11:11.190 --> 00:11:15.070
basically evolved in pre-human animals
whereas if you architect a system where

00:11:15.070 --> 00:11:15.080
whereas if you architect a system where
 

00:11:15.080 --> 00:11:17.900
whereas if you architect a system where
rationality and empathy play a deeper

00:11:17.900 --> 00:11:17.910
rationality and empathy play a deeper
 

00:11:17.910 --> 00:11:20.390
rationality and empathy play a deeper
role in the architecture then as its

00:11:20.390 --> 00:11:20.400
role in the architecture then as its
 

00:11:20.400 --> 00:11:23.540
role in the architecture then as its
intelligence routes way up we may find a

00:11:23.540 --> 00:11:23.550
intelligence routes way up we may find a
 

00:11:23.550 --> 00:11:27.250
intelligence routes way up we may find a
more beneficial outcome

00:11:27.250 --> 00:11:27.260
 
 

00:11:27.260 --> 00:11:30.490
 
[Music]

