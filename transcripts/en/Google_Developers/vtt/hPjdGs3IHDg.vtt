WEBVTT
Kind: captions
Language: en

00:00:00.295 --> 00:00:01.290
SETH LADD: Welcome, everyone.

00:00:01.290 --> 00:00:03.620
This is Dartisans, Episode 5.

00:00:03.620 --> 00:00:04.580
Today's topic--

00:00:04.580 --> 00:00:08.500
the Dart Virtual Machine, with
special guests from the Dart

00:00:08.500 --> 00:00:08.975
Virtual Machine.

00:00:08.975 --> 00:00:12.300
We have engineers who work on
the project with us today to

00:00:12.300 --> 00:00:15.060
talk about the project, answer
your questions, and give us an

00:00:15.060 --> 00:00:18.140
idea of what's been going on
with the VM, what they're

00:00:18.140 --> 00:00:21.150
working on now, and perhaps even
what they see coming down

00:00:21.150 --> 00:00:22.740
the pipe for the VM.

00:00:22.740 --> 00:00:25.730
This is the Dart Hangout, and
we encourage everyone to

00:00:25.730 --> 00:00:26.820
participate.

00:00:26.820 --> 00:00:32.509
You can join us at
html5rocks.com/live to watch

00:00:32.509 --> 00:00:33.440
this live feed.

00:00:33.440 --> 00:00:35.990
Also, there's a chat
embedded there.

00:00:35.990 --> 00:00:37.830
Also, links to the Moderator.

00:00:37.830 --> 00:00:41.230
We will be taking your
questions later on.

00:00:41.230 --> 00:00:44.780
So please do vote up and down
the questions there and submit

00:00:44.780 --> 00:00:45.730
your own, of course.

00:00:45.730 --> 00:00:47.640
And hopefully, you
can join us.

00:00:47.640 --> 00:00:49.280
So add a comment
to the original

00:00:49.280 --> 00:00:51.360
post for this broadcast.

00:00:51.360 --> 00:00:54.700
And we'll try to add you to our
circles and invite you to

00:00:54.700 --> 00:00:55.080
the Hangout.

00:00:55.080 --> 00:00:57.150
This is for everyone
to participate.

00:00:57.150 --> 00:00:59.340
So we hope you do provide
your questions and

00:00:59.340 --> 00:01:02.130
jump in and join us.

00:01:02.130 --> 00:01:05.530
Before we introduce the Dart VM
team here, who's joined us,

00:01:05.530 --> 00:01:08.950
just a couple news in the Dart
community that I found pretty

00:01:08.950 --> 00:01:10.990
interesting and cool over the
past couple of weeks I thought

00:01:10.990 --> 00:01:12.870
I'd share with everyone.

00:01:12.870 --> 00:01:15.430
This is a real big thanks
to Dartwatch.

00:01:15.430 --> 00:01:17.090
They're on Google+.

00:01:17.090 --> 00:01:19.310
And Chris Buckett, who runs that
page, has been doing a

00:01:19.310 --> 00:01:21.810
great job collecting
all of the news.

00:01:21.810 --> 00:01:23.350
So let me just run through some
of the cool things that

00:01:23.350 --> 00:01:23.970
have been going on.

00:01:23.970 --> 00:01:27.160
A couple weekends ago, there
were five different Dart

00:01:27.160 --> 00:01:29.310
Hackathons across the globe.

00:01:29.310 --> 00:01:33.310
London, Indonesia, Tokyo,
Kiev, and [INAUDIBLE]

00:01:33.310 --> 00:01:37.860
Ukraine and saw some really cool
demos, feedback, projects

00:01:37.860 --> 00:01:40.030
come out of these Hackathons.

00:01:40.030 --> 00:01:42.880
We'll be posting a summary of
what everyone's been working

00:01:42.880 --> 00:01:46.070
on and pointing out some of
the winning teams soon on

00:01:46.070 --> 00:01:47.790
news.dartlang.org.

00:01:47.790 --> 00:01:49.100
So do follow along there.

00:01:51.630 --> 00:01:55.770
May 24th is an Introduction to
Dart in Munich, Germany.

00:01:55.770 --> 00:01:58.940
I think that's a collaboration
with a couple different GTUGs

00:01:58.940 --> 00:02:02.090
and JUGs and different user
groups and meet-ups there.

00:02:02.090 --> 00:02:04.160
Some Dart engineers
will be on hand.

00:02:04.160 --> 00:02:06.500
So that's May 24th in Munich.

00:02:06.500 --> 00:02:08.560
Please do join them.

00:02:08.560 --> 00:02:12.890
Alexander Orlov is organizing
a Dart Hackathon in Munich,

00:02:12.890 --> 00:02:15.700
much in the style of the global
Hackathons that have

00:02:15.700 --> 00:02:16.480
been happening all over.

00:02:16.480 --> 00:02:20.650
Alexander's an early adopter in
the Dart project, and he's

00:02:20.650 --> 00:02:21.850
looking for people to come by.

00:02:21.850 --> 00:02:24.860
So we'll post all of these links
in the show notes, but

00:02:24.860 --> 00:02:27.800
hopefully, you can join him in
Munich for the Hackathon.

00:02:27.800 --> 00:02:29.840
Some cool projects that
I found recently.

00:02:29.840 --> 00:02:33.120
John Evans, another one of our
early adopters in the Dart

00:02:33.120 --> 00:02:36.770
community, wrote a great blog
post about how he contributed

00:02:36.770 --> 00:02:38.090
to the Dart project.

00:02:38.090 --> 00:02:39.560
Dart is open source.

00:02:39.560 --> 00:02:43.470
You can find it at
dart.googlecode.com.

00:02:43.470 --> 00:02:45.630
And he actually got his patch
in and worked with the

00:02:45.630 --> 00:02:47.530
engineers to get it all
reviewed, and then talked

00:02:47.530 --> 00:02:48.870
about his experience.

00:02:48.870 --> 00:02:51.700
And so if you're interested
about how he did that and how

00:02:51.700 --> 00:02:53.940
you might be able to contribute,
go ahead

00:02:53.940 --> 00:02:55.400
and read his post.

00:02:55.400 --> 00:02:57.160
John also works on Dart code.

00:02:57.160 --> 00:03:00.700
And he ported a Z-Machine to
Dart, and you can find that on

00:03:00.700 --> 00:03:02.980
GitHub, which is very,
very cool.

00:03:02.980 --> 00:03:04.730
A couple other cool projects.

00:03:04.730 --> 00:03:06.640
The GitHub user, Mythz--

00:03:06.640 --> 00:03:08.700
M-Y-T-H-Z--

00:03:08.700 --> 00:03:09.940
wrote a Redis driver.

00:03:09.940 --> 00:03:14.660
Redis is a NoSQL key-value
store database that he's

00:03:14.660 --> 00:03:18.260
written the Dart drivers for, so
that he can plug Redis into

00:03:18.260 --> 00:03:22.190
his Dart applications via the
Dart Virtual Machine.

00:03:22.190 --> 00:03:25.850
And the Google I/O sessions
were announced.

00:03:25.850 --> 00:03:27.640
Most of them are now live.

00:03:27.640 --> 00:03:31.010
And we have three sessions this
year at Google I/O, two

00:03:31.010 --> 00:03:36.350
sessions in the main tracks, one
behind Dart with Lars Bak

00:03:36.350 --> 00:03:37.510
and Kasper Lund.

00:03:37.510 --> 00:03:41.440
And we also have, "Putting the
App Back into Web Apps," which

00:03:41.440 --> 00:03:46.290
is talking about how Dart and
web programming intersect.

00:03:46.290 --> 00:03:49.810
There's also a hands-on code
lab for Dart as well, where

00:03:49.810 --> 00:03:53.770
you can get dirty with Dart
code, and you'll learn how to

00:03:53.770 --> 00:03:56.890
write a client and server
app in Dart.

00:03:56.890 --> 00:03:59.750
And so hope to see you at Google
I/O. And if you can't

00:03:59.750 --> 00:04:00.720
be there, that's OK.

00:04:00.720 --> 00:04:03.210
Everything is being recorded,
and a lot of stuff's being

00:04:03.210 --> 00:04:07.390
live-streamed, so there's lots
of cool ways to participate.

00:04:07.390 --> 00:04:09.970
And again, we'll post all of
these links in the show notes

00:04:09.970 --> 00:04:13.870
as well later after
the broadcast.

00:04:13.870 --> 00:04:17.570
So with that, we're going to
welcome our special guests,

00:04:17.570 --> 00:04:20.000
some of our Dart Virtual
Machine engineers.

00:04:20.000 --> 00:04:22.340
And we'll talk all about what's
going on in VM land.

00:04:22.340 --> 00:04:23.160
So welcome, guys.

00:04:23.160 --> 00:04:24.510
Thanks for coming
onto the show.

00:04:24.510 --> 00:04:25.470
[INTERPOSING VOICES]

00:04:25.470 --> 00:04:28.185
SETH LADD: So let's go around
the room really quickly, so

00:04:28.185 --> 00:04:29.700
everyone gets an idea of--

00:04:29.700 --> 00:04:32.660
I'm really interested in who
you are, but also what have

00:04:32.660 --> 00:04:34.460
you worked on previously?

00:04:34.460 --> 00:04:37.540
How did you become part
of this VM team?

00:04:37.540 --> 00:04:38.875
And we'll start here
with Todd.

00:04:38.875 --> 00:04:41.760
TODD TURNIDGE: I'm Todd
Turnidge, and I've

00:04:41.760 --> 00:04:42.770
been on the team for--

00:04:42.770 --> 00:04:43.480
I don't know.

00:04:43.480 --> 00:04:44.390
Is it a year now?

00:04:44.390 --> 00:04:44.800
Something?

00:04:44.800 --> 00:04:46.780
IVAN POSVA: Somewhere like
nine months, or so.

00:04:46.780 --> 00:04:48.440
TODD TURNIDGE: I used to do
virtual machines back in the

00:04:48.440 --> 00:04:50.370
distant past, and I took a
break from it for awhile.

00:04:50.370 --> 00:04:52.880
But it's nice to be back,
working again with some people

00:04:52.880 --> 00:04:54.130
I've worked with before.

00:04:56.950 --> 00:04:57.212
SIVA ANNAMALAI: Hi.

00:04:57.212 --> 00:04:58.733
Yeah, my name is
Siva Annamalai.

00:04:58.733 --> 00:05:01.230
I've been here for close to--

00:05:01.230 --> 00:05:03.430
ever since the project started,
so it's been close to

00:05:03.430 --> 00:05:04.590
two years now, I think.

00:05:04.590 --> 00:05:08.730
And prior to this, I was also
working on virtual machines

00:05:08.730 --> 00:05:12.890
with different languages and
different companies also.

00:05:12.890 --> 00:05:14.850
And that's how I
got into this.

00:05:14.850 --> 00:05:15.842
IVAN POSVA: Yeah.

00:05:15.842 --> 00:05:16.680
I'm Ivan Posva.

00:05:16.680 --> 00:05:19.070
Again, as Siva, I was
here from the

00:05:19.070 --> 00:05:20.770
start of the Dart project.

00:05:20.770 --> 00:05:24.750
Before that, I worked on V8, and
then at other companies.

00:05:24.750 --> 00:05:27.420
I think I've worked with
everybody here in the room

00:05:27.420 --> 00:05:29.220
outside of Google already.

00:05:29.220 --> 00:05:31.740
So, yeah,
[SPEAKING FOREIGN LANGUAGE].

00:05:31.740 --> 00:05:33.720
MALE SPEAKER 1: My name is
[? Surgeon Mentrovich. ?]

00:05:33.720 --> 00:05:35.580
I've worked with Ivan
here already

00:05:35.580 --> 00:05:37.040
before in other companies.

00:05:37.040 --> 00:05:40.570
And we worked a little bit on
V8, a little bit matter taken

00:05:40.570 --> 00:05:41.210
through Google.

00:05:41.210 --> 00:05:45.570
And I have joined that project
from the beginning.

00:05:45.570 --> 00:05:46.880
I'm having a lot of fun.

00:05:46.880 --> 00:05:47.720
SETH LADD: Awesome.

00:05:47.720 --> 00:05:48.890
Thanks, guys.

00:05:48.890 --> 00:05:51.930
So building a virtual machine
seems like black magic.

00:05:51.930 --> 00:05:54.570
This is always something that's
below the covers, under

00:05:54.570 --> 00:05:55.830
the hood, if you will.

00:05:55.830 --> 00:05:58.530
So for everyone watching, can
you help us just understand

00:05:58.530 --> 00:06:00.230
what a virtual machine is?

00:06:00.230 --> 00:06:02.200
Most people are familiar
with compilers.

00:06:02.200 --> 00:06:04.270
They generate machine code, and
then you run that program.

00:06:04.270 --> 00:06:06.370
But what's different in a
virtual machine world?

00:06:06.370 --> 00:06:09.530
IVAN POSVA: So, I would say,
first of all, we want to keep

00:06:09.530 --> 00:06:11.225
it black magic, so we won't
answer the question.

00:06:11.225 --> 00:06:12.125
SETH LADD: OK.

00:06:12.125 --> 00:06:12.830
IVAN POSVA: No.

00:06:12.830 --> 00:06:16.700
OK, so how did we start?

00:06:16.700 --> 00:06:20.332
Well, we have kind of an idea of
what the Dart language was

00:06:20.332 --> 00:06:21.440
supposed to do.

00:06:21.440 --> 00:06:25.630
So, Siva and I started in one
area where we just said, OK,

00:06:25.630 --> 00:06:27.810
these aren't the VM objects
that we need.

00:06:27.810 --> 00:06:28.990
This is the object hierarchy.

00:06:28.990 --> 00:06:33.425
The VM's internal data
structures are also basically

00:06:33.425 --> 00:06:34.740
in the VM heap.

00:06:34.740 --> 00:06:37.590
They're garbage-collected, so
even though they're used from

00:06:37.590 --> 00:06:39.660
C++, we keep them there.

00:06:39.660 --> 00:06:41.970
And Siva started then
with handles and--

00:06:41.970 --> 00:06:42.540
SIVA ANNAMALAI: Right.

00:06:42.540 --> 00:06:46.060
So essentially, we had the
representation of all these

00:06:46.060 --> 00:06:47.290
Dart objects in the VM.

00:06:47.290 --> 00:06:50.500
But then we have to be careful
on how we access them, be

00:06:50.500 --> 00:06:53.980
garbage collection aware, and
also we used this notion of

00:06:53.980 --> 00:06:57.150
handles so that the code in the
VM itself is safe as far

00:06:57.150 --> 00:07:01.370
as people writing it and
other aspects of it.

00:07:01.370 --> 00:07:04.050
So that's a pretty big aspect
of the VM, is infrastructure

00:07:04.050 --> 00:07:06.250
support for the garbage
collector.

00:07:06.250 --> 00:07:08.720
And then, of course, there's
the open compilation, which

00:07:08.720 --> 00:07:10.160
[? Surgeon ?] can talk about.

00:07:10.160 --> 00:07:14.330
MALE SPEAKER 1: Yeah, the key
that appears as black magic is

00:07:14.330 --> 00:07:17.780
we need a lot of discipline
when we design the system,

00:07:17.780 --> 00:07:21.450
because the ability and
simplicity is of the utmost

00:07:21.450 --> 00:07:22.700
importance.

00:07:22.700 --> 00:07:25.250
And the same is of the compiler
part, which I was

00:07:25.250 --> 00:07:30.290
working on, is to get the system
with gradually improved

00:07:30.290 --> 00:07:35.410
performance, which we are now
on our way to do, but still

00:07:35.410 --> 00:07:39.940
contain the ultimate
reliability, so that we cannot

00:07:39.940 --> 00:07:41.435
allow the users to have crashes

00:07:41.435 --> 00:07:43.660
when running our system.

00:07:43.660 --> 00:07:46.740
So we have to be disciplined
and hard-working.

00:07:46.740 --> 00:07:50.790
And I think, then, that black
magic-- it's not black magic,

00:07:50.790 --> 00:07:51.596
white magic.

00:07:51.596 --> 00:07:52.000
SETH LADD: Good.

00:07:52.000 --> 00:07:53.460
Yeah, magic for good.

00:07:53.460 --> 00:07:57.420
But I hear the terms "engine"
and "interpreter" and

00:07:57.420 --> 00:07:59.720
"compiler" and "virtual
machine" So

00:07:59.720 --> 00:08:01.380
I'm familiar with--

00:08:01.380 --> 00:08:03.440
for instance, Ruby's an
implementation that really is

00:08:03.440 --> 00:08:05.830
more of an interpreter, if
I understand correctly.

00:08:05.830 --> 00:08:07.790
What's the difference between
that and a virtual machine?

00:08:11.984 --> 00:08:13.320
IVAN POSVA: I wouldn't
say there's a

00:08:13.320 --> 00:08:14.670
big difference, right?

00:08:14.670 --> 00:08:20.090
So all of these language
virtual machines, they

00:08:20.090 --> 00:08:21.990
implement one particular
language.

00:08:21.990 --> 00:08:24.820
They either use an interpreter,
or in our case,

00:08:24.820 --> 00:08:28.200
we skip the interpreter
step and go straight

00:08:28.200 --> 00:08:29.700
to generated code.

00:08:29.700 --> 00:08:32.260
SETH LADD: OK.

00:08:32.260 --> 00:08:34.700
IVAN POSVA: Yeah, I think,
coming back to the black

00:08:34.700 --> 00:08:38.840
magic, both Siva and
[? Surgeon ?] touched on it.

00:08:38.840 --> 00:08:42.660
It's really, as I'm trying to
keep the overview of the whole

00:08:42.660 --> 00:08:47.070
VM, trying to keep simple APIs,
keeping the VM hackable,

00:08:47.070 --> 00:08:52.270
so that as you see changes need
to be made, the APIs,

00:08:52.270 --> 00:08:56.050
between the different subsystems
are kept simple.

00:08:56.050 --> 00:08:59.120
And that way, you can still--

00:08:59.120 --> 00:09:01.240
nothing is set in stone,
essentially.

00:09:01.240 --> 00:09:03.300
SETH LADD: Yeah, especially
this early in the project,

00:09:03.300 --> 00:09:04.670
it's still a technology
preview.

00:09:04.670 --> 00:09:06.550
We're learning a lot of good
lessons that we implement,

00:09:06.550 --> 00:09:07.280
other people implement.

00:09:07.280 --> 00:09:08.160
So that's good.

00:09:08.160 --> 00:09:09.110
We have to have our meet
in the middle.

00:09:09.110 --> 00:09:10.420
IVAN POSVA: And that
basically--

00:09:10.420 --> 00:09:15.510
a lot of talk to change big
areas of the isolate

00:09:15.510 --> 00:09:16.380
dispatching and so on.

00:09:16.380 --> 00:09:16.980
SETH LADD: Yeah.

00:09:16.980 --> 00:09:19.390
And we'll definitely come
back to isolates.

00:09:19.390 --> 00:09:21.680
What about the life cycle
of Dart code then?

00:09:21.680 --> 00:09:24.140
So you mentioned that we skip
the interpreter part, we go

00:09:24.140 --> 00:09:25.100
straight to machine code.

00:09:25.100 --> 00:09:27.470
At a high level, can you
just walk me through--

00:09:27.470 --> 00:09:28.680
there's a compiler there.

00:09:28.680 --> 00:09:31.210
What happens when we
take the Dart code?

00:09:31.210 --> 00:09:34.120
SIVA ANNAMALAI: So essentially,
on the command

00:09:34.120 --> 00:09:37.815
line, you specify a script that
is the Dart code that you

00:09:37.815 --> 00:09:38.550
want to run.

00:09:38.550 --> 00:09:42.715
So essentially, the VM, when it
starts up, it already does

00:09:42.715 --> 00:09:45.150
a boot kind of thing where
it loads in all the code

00:09:45.150 --> 00:09:47.940
libraries, which are
out there, actually

00:09:47.940 --> 00:09:49.080
built into the VM.

00:09:49.080 --> 00:09:51.105
Then we load the script.

00:09:51.105 --> 00:09:54.670
We pass the script, tokenize
it, everything.

00:09:54.670 --> 00:09:56.330
But we don't yet start
compiling the

00:09:56.330 --> 00:09:57.380
methods at this point.

00:09:57.380 --> 00:09:59.390
We just tokenize the screen.

00:09:59.390 --> 00:10:02.020
And then there is the main
method that we invoke.

00:10:02.020 --> 00:10:03.460
And that's when the
first compilation

00:10:03.460 --> 00:10:05.590
happens of that method.

00:10:05.590 --> 00:10:08.250
In the process, we are, of
course, creating objects in

00:10:08.250 --> 00:10:09.890
the heap as we go along
with the script

00:10:09.890 --> 00:10:12.180
object and other things.

00:10:12.180 --> 00:10:14.530
And then, once the main
is compiled, we

00:10:14.530 --> 00:10:16.260
start executing that--

00:10:16.260 --> 00:10:18.110
machine code, that is--
which is compiled.

00:10:18.110 --> 00:10:21.050
And that, in turn, we call other
methods, which trigger a

00:10:21.050 --> 00:10:23.770
compilation of these other
methods and creation of each.

00:10:23.770 --> 00:10:25.350
IVAN POSVA: So it's like
pulling on a string.

00:10:28.360 --> 00:10:31.140
Once we tokenize the whole
thing, we have all the VM

00:10:31.140 --> 00:10:34.070
internal data structures that
describe all the classes that

00:10:34.070 --> 00:10:37.510
are part of this Dart program.

00:10:37.510 --> 00:10:40.570
All of the methods, we sort of
know where the methods start.

00:10:40.570 --> 00:10:44.940
So when main calls some other
method, we can pull on that.

00:10:44.940 --> 00:10:51.270
We have the pre-chewed,
tokenized content of the

00:10:51.270 --> 00:10:53.940
script for that part
of the method.

00:10:53.940 --> 00:10:57.170
So we can basically,
lazily, as you go,

00:10:57.170 --> 00:10:59.430
compile the little pieces.

00:10:59.430 --> 00:11:02.640
And that works, actually,
pretty well.

00:11:02.640 --> 00:11:03.155
TODD TURNIDGE: Yeah.

00:11:03.155 --> 00:11:06.460
The optimizing compiler
kicks in later.

00:11:06.460 --> 00:11:07.880
MALE SPEAKER 1: So essentially,

00:11:07.880 --> 00:11:08.890
we have that code.

00:11:08.890 --> 00:11:11.640
It's tokenized, and can use
it with the presentation.

00:11:11.640 --> 00:11:15.775
And it has a two-stage
compilation system, which

00:11:15.775 --> 00:11:18.350
first one collects all the
necessary information about

00:11:18.350 --> 00:11:20.030
rampant behavior of
the language--

00:11:20.030 --> 00:11:21.490
of the program.

00:11:21.490 --> 00:11:24.680
And then from that one, we
decide to optimize and to use

00:11:24.680 --> 00:11:28.840
all the latest and known and
still unknown optimization

00:11:28.840 --> 00:11:32.575
technologies to get the best
performance out of the Dart.

00:11:32.575 --> 00:11:33.700
TODD TURNIDGE: Currently,
we optimize

00:11:33.700 --> 00:11:36.550
based on just a counter.

00:11:36.550 --> 00:11:37.910
But it might change
in the future.

00:11:37.910 --> 00:11:40.130
MALE SPEAKER 1: But this
is a flexible thing.

00:11:40.130 --> 00:11:43.692
Right now we do simple so we can
develop the prototype as

00:11:43.692 --> 00:11:44.830
soon as possible.

00:11:44.830 --> 00:11:47.960
IVAN POSVA: And then the
optimization steps currently

00:11:47.960 --> 00:11:52.120
are relatively simplistic, but
they allow again, as we try to

00:11:52.120 --> 00:11:54.040
grow and so on.

00:11:54.040 --> 00:11:57.140
So we get the type of feedback
from the running program.

00:11:57.140 --> 00:11:58.990
We know, OK, generally--

00:11:58.990 --> 00:12:03.120
or we've only see you called
this dynamic method here.

00:12:03.120 --> 00:12:05.260
It always resolves to
that other class.

00:12:05.260 --> 00:12:06.813
So we use that.

00:12:06.813 --> 00:12:08.020
We use that knowledge.

00:12:08.020 --> 00:12:09.720
SETH LADD: Now, you mentioned
performance.

00:12:09.720 --> 00:12:12.320
And I believe some of the people
working on the Dart VM

00:12:12.320 --> 00:12:13.400
used to work on V8.

00:12:13.400 --> 00:12:14.092
Is that--

00:12:14.092 --> 00:12:15.070
IVAN POSVA: That's correct.

00:12:15.070 --> 00:12:15.820
SETH LADD: OK.

00:12:15.820 --> 00:12:18.550
So what are some of the things
we learned as we built V8 that

00:12:18.550 --> 00:12:21.410
prepped us for this next
generation virtual machine?

00:12:21.410 --> 00:12:22.700
Maybe in terms of performance?

00:12:22.700 --> 00:12:27.271
I know there's some things
that we now know to do.

00:12:27.271 --> 00:12:29.990
MALE SPEAKER 1: I don't
think we have any--

00:12:29.990 --> 00:12:35.140
we need just time to implement
all the features that we need.

00:12:35.140 --> 00:12:38.090
There is sometimes a
new program from

00:12:38.090 --> 00:12:39.460
JavaScript to Dart.

00:12:39.460 --> 00:12:43.420
And you don't think of that as
a different language that may

00:12:43.420 --> 00:12:45.790
pre-empt you if your program
acts in a way like it does

00:12:45.790 --> 00:12:46.540
JavaScript.

00:12:46.540 --> 00:12:50.015
But if our program does like
it's intended to be, you are

00:12:50.015 --> 00:12:53.480
going to see performance
that Dart--

00:12:53.480 --> 00:12:57.610
that is much better than a
JavaScript system can provide.

00:12:57.610 --> 00:13:04.600
IVAN POSVA: So the lessons we
took from V8 was Crankshaft,

00:13:04.600 --> 00:13:08.350
for example, showed that
having a really basic,

00:13:08.350 --> 00:13:11.970
two-stage compiler, that the
second stage really kicked in

00:13:11.970 --> 00:13:15.740
and used all the type feedback,
and started doing

00:13:15.740 --> 00:13:20.290
advanced compiler optimizations
really pays off.

00:13:20.290 --> 00:13:22.940
So that is what [? Surgeon's ?]

00:13:22.940 --> 00:13:25.345
doing, applying some
of those lessons.

00:13:28.300 --> 00:13:29.430
Other than-- yeah, go ahead.

00:13:29.430 --> 00:13:33.580
SIVA ANNAMALAI: The thing that
Todd talked about of counting

00:13:33.580 --> 00:13:36.550
and this thing, it was proven
that that works very well in

00:13:36.550 --> 00:13:39.640
the Crankshaft scenario, too,
as opposed to seeing some

00:13:39.640 --> 00:13:42.660
crazy, you know, taking
profiles, discounting scheme.

00:13:42.660 --> 00:13:46.292
They've adopted it too,
now, I guess.

00:13:46.292 --> 00:13:48.770
IVAN POSVA: Initially, they
used time-based profiling.

00:13:48.770 --> 00:13:51.600
And they switched to
counters as well.

00:13:51.600 --> 00:13:55.450
TODD TURNIDGE: And they talked
about object layout, some

00:13:55.450 --> 00:13:56.750
things like that.

00:13:56.750 --> 00:13:58.320
Is that a performance
lesson from V8?

00:13:58.320 --> 00:14:00.280
IVAN POSVA: That is a
performance lesson from V8.

00:14:00.280 --> 00:14:03.320
For example, what we
did in V8 was--

00:14:03.320 --> 00:14:06.470
initially, we had just basically
the object with the

00:14:06.470 --> 00:14:09.480
property values hanging
off to the side.

00:14:09.480 --> 00:14:14.490
At some point, we had-- the
object had some room for

00:14:14.490 --> 00:14:18.760
properties in the object itself,
so that it didn't have

00:14:18.760 --> 00:14:20.410
to go through a double
D reference

00:14:20.410 --> 00:14:21.950
to get at the object.

00:14:21.950 --> 00:14:26.830
That was something that really
helped V8's performance.

00:14:26.830 --> 00:14:32.100
And we said, V8, we have all
these heuristics to figure out

00:14:32.100 --> 00:14:34.190
how big this area is.

00:14:34.190 --> 00:14:37.900
Dart, as a language, is much
cleaner and safer that way.

00:14:37.900 --> 00:14:39.115
You can't add new properties.

00:14:39.115 --> 00:14:41.332
So you know exactly how much
you need to allocate.

00:14:41.332 --> 00:14:43.950
SETH LADD: This is a really
interesting point that I

00:14:43.950 --> 00:14:48.050
always find fascinating to watch
the team's work with, is

00:14:48.050 --> 00:14:51.260
the intersection between
language design impacting VM

00:14:51.260 --> 00:14:53.860
design and VM design impacting
language design.

00:14:53.860 --> 00:14:57.420
It sounds like this is one of
those areas where we knew from

00:14:57.420 --> 00:15:00.030
our prior experience that if you
have a language where you

00:15:00.030 --> 00:15:02.690
can just add properties and
methods at run time, then you

00:15:02.690 --> 00:15:04.760
can't necessarily take advantage
of some of the

00:15:04.760 --> 00:15:08.270
deeper optimizations that we
then in the Dart language,

00:15:08.270 --> 00:15:10.380
say, OK, well, if you can't
add a property, then that

00:15:10.380 --> 00:15:12.800
means, well, we can be a little
bit more smarter in our

00:15:12.800 --> 00:15:14.402
virtual machine.

00:15:14.402 --> 00:15:17.410
IVAN POSVA: Or less smart.

00:15:17.410 --> 00:15:18.210
Keep it more-- keep
it simpler.

00:15:18.210 --> 00:15:18.590
[INTERPOSING VOICES]

00:15:18.590 --> 00:15:19.190
SETH LADD: Keep it
simpler, yeah.

00:15:19.190 --> 00:15:21.376
TODD TURNIDGE: Keep
it simpler.

00:15:21.376 --> 00:15:24.640
Having fewer checks to
execute at run time.

00:15:24.640 --> 00:15:27.410
SETH LADD: Can you talk more
about the dynamic between the

00:15:27.410 --> 00:15:28.860
language design and
the VM design?

00:15:28.860 --> 00:15:31.390
Do you work closely with the
guys building language?

00:15:31.390 --> 00:15:33.410
Do you think it's really
just one big team?

00:15:33.410 --> 00:15:34.260
How does that work?

00:15:34.260 --> 00:15:37.120
IVAN POSVA: Todd, how loud do
you have to shout until you

00:15:37.120 --> 00:15:38.422
reach loud?

00:15:38.422 --> 00:15:41.890
TODD TURNIDGE: The language
specification fellow actually

00:15:41.890 --> 00:15:45.275
sits at the desk beside mine,
so we have pretty much a

00:15:45.275 --> 00:15:46.095
direct channel to him.

00:15:46.095 --> 00:15:46.370
SETH LADD: That's awesome.

00:15:46.370 --> 00:15:48.510
TODD TURNIDGE: And he works a
lot with the fellows over in

00:15:48.510 --> 00:15:50.880
our groups who have primary
responsibility for language.

00:15:50.880 --> 00:15:54.770
But most of those people, in
previous lives, were virtual

00:15:54.770 --> 00:15:55.860
machine engineers.

00:15:55.860 --> 00:15:59.430
So there's not really a wall in
terms of the knowledge of

00:15:59.430 --> 00:16:01.130
virtual machine design.

00:16:01.130 --> 00:16:04.320
Generally, they try not to give
us things that are too

00:16:04.320 --> 00:16:06.215
hard to implement or that we
can't implement efficiently.

00:16:06.215 --> 00:16:08.850
IVAN POSVA: Well, I don't think
they even thought about

00:16:08.850 --> 00:16:10.885
doing stuff at Dart
to implement.

00:16:10.885 --> 00:16:11.740
TODD TURNIDGE: Right.

00:16:11.740 --> 00:16:13.240
It just wouldn't have--

00:16:13.240 --> 00:16:15.656
They know Occult.

00:16:15.656 --> 00:16:17.885
MALE SPEAKER 1: Even if we are
in different time zones, I

00:16:17.885 --> 00:16:20.220
think, the communication between
[INAUDIBLE] and us

00:16:20.220 --> 00:16:21.740
work pretty well.

00:16:21.740 --> 00:16:25.010
And we give them feedback when
we find something that doesn't

00:16:25.010 --> 00:16:28.420
seem to be working well from the
implementation standpoint.

00:16:28.420 --> 00:16:31.650
Because in a design, having
thought of something, you

00:16:31.650 --> 00:16:34.070
don't really know how well it
works until you have put it

00:16:34.070 --> 00:16:36.320
down in the bits and bytes.

00:16:36.320 --> 00:16:37.480
And that works well.

00:16:37.480 --> 00:16:41.870
IVAN POSVA: I think it helps
that Kasper is also basically

00:16:41.870 --> 00:16:43.460
working on dart2js.

00:16:43.460 --> 00:16:47.955
So they feel some of
that same pain.

00:16:47.955 --> 00:16:50.660
SETH LADD: So this always comes
up, especially when we

00:16:50.660 --> 00:16:53.830
initially launched Dart, was,
oh, that's great, you have a

00:16:53.830 --> 00:16:54.070
new language.

00:16:54.070 --> 00:16:56.980
But why not work on a bytecode
VM and then let people kind of

00:16:56.980 --> 00:16:59.120
tack on top of that?

00:16:59.120 --> 00:17:01.730
Do you have any perspective on
the design of Dart as it is

00:17:01.730 --> 00:17:03.970
today, where you have Dart code
that runs just pretty

00:17:03.970 --> 00:17:06.099
much straight into the
virtual machine?

00:17:06.099 --> 00:17:08.319
And what were some of the
design decisions there?

00:17:08.319 --> 00:17:11.440
Why not a bytecode VM?

00:17:11.440 --> 00:17:12.630
IVAN POSVA: Should I?

00:17:12.630 --> 00:17:13.569
SIVA ANNAMALAI: Yeah,
go ahead.

00:17:13.569 --> 00:17:13.829
No, go ahead.

00:17:13.829 --> 00:17:16.540
IVAN POSVA: Well, to me,
I look at it this way.

00:17:16.540 --> 00:17:21.069
When you have a bytecode
VM for Dart similar to

00:17:21.069 --> 00:17:23.069
JavaScript, we always
want it to be

00:17:23.069 --> 00:17:25.890
distributed as source code.

00:17:25.890 --> 00:17:29.040
No precompilation steps
necessary for the developers.

00:17:29.040 --> 00:17:32.180
So you really want to be able
to hit just reload.

00:17:32.180 --> 00:17:34.430
You change your script,
reload, run.

00:17:34.430 --> 00:17:38.750
No compilation script to
bytecode is necessary.

00:17:38.750 --> 00:17:41.490
The option we could have had
was that the VM itself that

00:17:41.490 --> 00:17:45.000
compiles bytecodes executes
those bytecodes in an

00:17:45.000 --> 00:17:47.950
interpreter, and then basically
does the optimizing

00:17:47.950 --> 00:17:49.200
compiler based on that.

00:17:53.230 --> 00:17:57.750
We've opted skipping that step
instead of having a relatively

00:17:57.750 --> 00:18:01.420
simple, fast compiler
to machine code.

00:18:01.420 --> 00:18:05.530
And I sort of look at the CPU
as a really fast interpreter

00:18:05.530 --> 00:18:12.655
of these x86 bytecodes.

00:18:12.655 --> 00:18:15.930
MALE SPEAKER 1: I
don't see any--

00:18:15.930 --> 00:18:18.600
I used to go to bytecodes, and I
don't see the clear benefits

00:18:18.600 --> 00:18:19.990
for us using bytecodes.

00:18:19.990 --> 00:18:23.690
It's an additional definition
that we need to maintain.

00:18:23.690 --> 00:18:27.310
And the main reason I--

00:18:27.310 --> 00:18:30.340
main argument for bytecodes, I
heard it from other people who

00:18:30.340 --> 00:18:33.840
like to work with other
languages to run on our VM.

00:18:33.840 --> 00:18:37.110
And for that, I think that that
is not a bad idea to use

00:18:37.110 --> 00:18:40.010
as intermediate languages
by itself.

00:18:40.010 --> 00:18:42.920
So if you have a language, you
can translate it to Dart and

00:18:42.920 --> 00:18:44.411
run it from that point.

00:18:44.411 --> 00:18:45.320
TODD TURNIDGE: Right.

00:18:45.320 --> 00:18:46.800
And that can amplify--

00:18:46.800 --> 00:18:49.070
every additional layer you
introduce is one more chance

00:18:49.070 --> 00:18:51.950
for your definitions to have
a slight mismatch.

00:18:51.950 --> 00:18:53.800
And so you have--

00:18:53.800 --> 00:18:55.750
a method call is supposed to
behave this way at the

00:18:55.750 --> 00:18:56.350
language level.

00:18:56.350 --> 00:18:58.370
But at the virtual machine
level, maybe it acts slightly

00:18:58.370 --> 00:18:59.720
differently.

00:18:59.720 --> 00:19:02.910
It's more areas where you can
forget what's going on.

00:19:02.910 --> 00:19:06.900
And if we always know this is
what the user typed in, then

00:19:06.900 --> 00:19:09.690
we can do what the user said to
do at every point in time.

00:19:09.690 --> 00:19:11.052
There's no middleman.

00:19:11.052 --> 00:19:12.190
MALE SPEAKER 1: It clears
complexity.

00:19:12.190 --> 00:19:17.540
And clear complexity means both
slower and less reliable.

00:19:17.540 --> 00:19:18.980
SIVA ANNAMALAI: Yeah.

00:19:18.980 --> 00:19:22.080
Actually, the bytecodes don't
actually skip the whole

00:19:22.080 --> 00:19:23.880
passing phase, because we
still have to do the

00:19:23.880 --> 00:19:26.150
verification of the bytecode
that comes in.

00:19:26.150 --> 00:19:27.900
And so it's not like you're
saving on the

00:19:27.900 --> 00:19:29.315
whole parsing thing.

00:19:29.315 --> 00:19:31.760
So you still have
to do it anyway.

00:19:31.760 --> 00:19:34.390
And having it in source form
doesn't make it any worse.

00:19:34.390 --> 00:19:37.160
And like [? Surgeon ?] said,
interoperability is achieved

00:19:37.160 --> 00:19:39.730
easily, because we already have
so many translators to

00:19:39.730 --> 00:19:40.246
Dart language.

00:19:40.246 --> 00:19:43.340
And you can just run it straight
as though it is an

00:19:43.340 --> 00:19:45.160
intermediate representation.

00:19:45.160 --> 00:19:46.040
SETH LADD: Good point.

00:19:46.040 --> 00:19:47.850
It's very web-friendly
this way.

00:19:47.850 --> 00:19:50.165
You hit it best where you--
reload is the new compile.

00:19:50.165 --> 00:19:50.880
SIVA ANNAMALAI: Exactly.

00:19:50.880 --> 00:19:51.470
SETH LADD: So you
need something

00:19:51.470 --> 00:19:52.905
that works like that.

00:19:52.905 --> 00:19:53.590
Yeah, great.

00:19:53.590 --> 00:19:54.760
Thanks.

00:19:54.760 --> 00:19:57.780
Switching gears a little bit, to
me, one of the great novel

00:19:57.780 --> 00:20:01.290
features of the Dart virtual
machine is isolates.

00:20:01.290 --> 00:20:04.920
Now, you've been working a
lot on isolates, Todd.

00:20:04.920 --> 00:20:06.720
Can you explain, what
is an isolate?

00:20:06.720 --> 00:20:07.370
Is it a thread?

00:20:07.370 --> 00:20:08.640
Is it a process?

00:20:08.640 --> 00:20:09.990
What does it do?

00:20:09.990 --> 00:20:11.600
TODD TURNIDGE: Well, an isolate
is a lot like a

00:20:11.600 --> 00:20:14.530
thread, but nobody else shares
any of its state.

00:20:14.530 --> 00:20:18.310
So when you're writing an
isolate, you know that there's

00:20:18.310 --> 00:20:21.270
no way that you have to have
locking or race conditions or

00:20:21.270 --> 00:20:22.070
anything like that.

00:20:22.070 --> 00:20:23.970
There's just perfect safety.

00:20:23.970 --> 00:20:26.070
And all of your communication
with other isolates is done

00:20:26.070 --> 00:20:28.050
with a message system.

00:20:28.050 --> 00:20:33.060
And so it's a nice abstraction
for having parallel work but

00:20:33.060 --> 00:20:37.430
without having a lot of the
things that really require a

00:20:37.430 --> 00:20:39.920
lot of heavy thinking that you
have in other languages.

00:20:39.920 --> 00:20:42.630
Here you have your isolate,
and there's a very strong

00:20:42.630 --> 00:20:43.810
invariant about its
protection.

00:20:43.810 --> 00:20:46.100
It's a lot more like a
process or something.

00:20:48.850 --> 00:20:50.910
SETH LADD: I've heard parallels
drawn between our

00:20:50.910 --> 00:20:54.280
isolate system and Erlang
actors, for instance.

00:20:54.280 --> 00:20:55.802
Do you think that's
a fair analogy?

00:20:55.802 --> 00:20:58.520
IVAN POSVA: That was definitely
part of it.

00:20:58.520 --> 00:20:59.440
SIVA ANNAMALAI: That definitely
was part of the

00:20:59.440 --> 00:21:00.490
inspiration, yeah.

00:21:00.490 --> 00:21:03.705
The big thing being that, as
Todd mentioned, the heaps are

00:21:03.705 --> 00:21:06.480
isolated, and there is
no sharing going on.

00:21:06.480 --> 00:21:08.070
So it makes it--

00:21:08.070 --> 00:21:11.250
as though you are just writing
a single-threaded program.

00:21:11.250 --> 00:21:14.982
There's none of this whole
synchronization complexities

00:21:14.982 --> 00:21:16.770
that people need to deal with.

00:21:16.770 --> 00:21:19.110
And then when you interact with
other isolates, you just

00:21:19.110 --> 00:21:20.525
message them.

00:21:20.525 --> 00:21:23.090
TODD TURNIDGE: It even applies
in some of the internal VM

00:21:23.090 --> 00:21:27.710
implementation, the fact that
we know that this isolate's

00:21:27.710 --> 00:21:29.635
code can't really interact with
this other one's code.

00:21:29.635 --> 00:21:30.890
And it means that we
could generate

00:21:30.890 --> 00:21:31.710
simpler code for them.

00:21:31.710 --> 00:21:34.800
We don't need to have a lot of
locking that goes on there.

00:21:34.800 --> 00:21:38.000
I mean, we have a few data
structures in the VM that have

00:21:38.000 --> 00:21:40.160
to do with how messages are
passed back and forth, or

00:21:40.160 --> 00:21:42.640
about how threads are pulled
from a thread pool, the need

00:21:42.640 --> 00:21:44.790
to be synchronization aware.

00:21:44.790 --> 00:21:46.710
But most of the VM actually
gets to be

00:21:46.710 --> 00:21:47.940
blissfully free of that.

00:21:47.940 --> 00:21:50.810
IVAN POSVA: Essentially, only
the isolate implementation

00:21:50.810 --> 00:21:54.430
ridge locks, and everything
else is, you know

00:21:54.430 --> 00:21:56.281
you're the only guy.

00:21:56.281 --> 00:21:58.140
SETH LADD: So it's pleasing.

00:21:58.140 --> 00:22:00.290
And I think part of the isolate
is done to get the

00:22:00.290 --> 00:22:02.880
census because Dart code has
to compile the JavaScript.

00:22:02.880 --> 00:22:05.800
And JavaScript is itself
single-threaded, and so I can

00:22:05.800 --> 00:22:07.850
see this interplay
of requirements.

00:22:07.850 --> 00:22:10.700
But again, I think we end up
with a really nice system.

00:22:10.700 --> 00:22:12.650
How are isolates implemented
today?

00:22:12.650 --> 00:22:15.930
Is there a thread pool of one
process per isolate in the VM?

00:22:15.930 --> 00:22:16.550
TODD TURNIDGE: Yeah.

00:22:16.550 --> 00:22:18.730
About a month or so ago,
we switched from--

00:22:18.730 --> 00:22:20.990
we used to be a thread per
isolate, which obviously

00:22:20.990 --> 00:22:22.550
doesn't scale well.

00:22:22.550 --> 00:22:24.890
When you're building a virtual
machine, often you'll say, I

00:22:24.890 --> 00:22:26.860
want to get something
working now.

00:22:26.860 --> 00:22:28.200
And then I'm going to make
it better and better.

00:22:28.200 --> 00:22:31.180
And so we have this sort of
iterative, incremental

00:22:31.180 --> 00:22:31.720
improvement.

00:22:31.720 --> 00:22:34.040
And one of the things we
improved recently was we added

00:22:34.040 --> 00:22:34.920
a thread pool.

00:22:34.920 --> 00:22:38.070
So if a certain isolate is gone
to sleep, it's waiting

00:22:38.070 --> 00:22:41.000
for message, and it'll be woken
up when it gets the

00:22:41.000 --> 00:22:42.050
message sent to it.

00:22:42.050 --> 00:22:43.440
Its thread goes into the pool.

00:22:43.440 --> 00:22:45.800
And then the next isolate comes
along, and if it needs

00:22:45.800 --> 00:22:46.690
to run, it can share it.

00:22:46.690 --> 00:22:49.400
So it allows us to scale
more isolates

00:22:49.400 --> 00:22:51.320
on top of your threads.

00:22:51.320 --> 00:22:53.040
IVAN POSVA: There's still
more to be done.

00:22:53.040 --> 00:22:54.890
TODD TURNIDGE: Yeah,
absolutely.

00:22:54.890 --> 00:22:57.205
It's an area that we've just
scratched the surface on.

00:22:57.205 --> 00:23:01.300
IVAN POSVA: So for example,
currently, we have the initial

00:23:01.300 --> 00:23:05.320
heaps for per isolate are much
bigger than we would want to.

00:23:05.320 --> 00:23:10.050
So we want to basically
grow them as needed.

00:23:10.050 --> 00:23:14.550
We have still a lot of the core
library that is loaded.

00:23:14.550 --> 00:23:16.650
Is it per isolate?

00:23:16.650 --> 00:23:18.280
It's currently loaded
per isolate.

00:23:18.280 --> 00:23:19.212
SETH LADD: Wow.

00:23:19.212 --> 00:23:21.960
SIVA ANNAMALAI: There's a lot
of recent data on that that

00:23:21.960 --> 00:23:24.895
comes in as part of the boot
process that is not modified

00:23:24.895 --> 00:23:27.010
and can be shared
across isolates.

00:23:27.010 --> 00:23:28.780
But that's something we
are looking at to

00:23:28.780 --> 00:23:30.530
see how much of it--

00:23:30.530 --> 00:23:32.910
again, this goes to Todd's
question of reducing the

00:23:32.910 --> 00:23:36.127
footprint of an isolate, like
how the thread pool did it.

00:23:36.127 --> 00:23:39.840
IVAN POSVA: And just basically
starting to squeeze on it.

00:23:39.840 --> 00:23:42.790
SETH LADD: And so do you think
that when further iterations

00:23:42.790 --> 00:23:46.860
of the isolate subsystem appear,
is the expectation

00:23:46.860 --> 00:23:49.160
that developers can
start up a large

00:23:49.160 --> 00:23:49.930
amount of these isolates?

00:23:49.930 --> 00:23:51.240
Are they intended to
be lightweight--

00:23:51.240 --> 00:23:51.700
[INTERPOSING VOICES]

00:23:51.700 --> 00:23:53.350
SETH LADD: --constructs?

00:23:53.350 --> 00:23:53.640
Great.

00:23:53.640 --> 00:23:54.420
For sure.

00:23:54.420 --> 00:23:58.100
IVAN POSVA: And again, as Todd
said, currently an isolate

00:23:58.100 --> 00:24:01.436
becomes runnable, it
gets a thread.

00:24:01.436 --> 00:24:03.760
And we might basically want
to limit how many

00:24:03.760 --> 00:24:05.370
threads we want to create.

00:24:05.370 --> 00:24:06.640
Currently we just create--

00:24:06.640 --> 00:24:12.660
if you have 100 isolates that
want to run all in parallel,

00:24:12.660 --> 00:24:14.610
currently we create
100 threads.

00:24:14.610 --> 00:24:19.090
Maybe we'll try to limit that
at some point, so that they

00:24:19.090 --> 00:24:20.760
start sharing threads
and so on.

00:24:20.760 --> 00:24:23.130
But currently, this is not a
complexity that we are trying

00:24:23.130 --> 00:24:26.320
to address, because there
are bigger fish to fry.

00:24:26.320 --> 00:24:27.130
SETH LADD: Sure.

00:24:27.130 --> 00:24:29.040
TODD TURNIDGE: We do reclaim
idle threads right now.

00:24:29.040 --> 00:24:31.430
So if you reach some peak and
you go down, we'll reclaim

00:24:31.430 --> 00:24:35.431
them if they're fallow
for awhile.

00:24:35.431 --> 00:24:37.220
SETH LADD: Well, this is
probably an area that we'd

00:24:37.220 --> 00:24:39.190
love feedback from our
external users.

00:24:39.190 --> 00:24:40.450
How are they using isolates?

00:24:40.450 --> 00:24:42.760
What kind of systems
are they building?

00:24:42.760 --> 00:24:44.620
What kind of limits
do they run into?

00:24:44.620 --> 00:24:47.590
And what are the use cases that
prompts these limits?

00:24:47.590 --> 00:24:50.460
So I guess this is a question,
really, for everyone watching.

00:24:50.460 --> 00:24:53.270
Do try out the isolates on
the virtual machine.

00:24:53.270 --> 00:24:55.660
Try it with your systems,
your libraries.

00:24:55.660 --> 00:24:59.070
Let us know how it works for
you, what kind of additional

00:24:59.070 --> 00:25:00.480
control you might need.

00:25:00.480 --> 00:25:03.460
And I'll take this opportunity
to remind everyone, this is

00:25:03.460 --> 00:25:07.170
Dartisans Episode 5, where we're
meeting with the Dart VM

00:25:07.170 --> 00:25:08.070
team today.

00:25:08.070 --> 00:25:11.900
And you can follow along
at html5rocks.com/live.

00:25:11.900 --> 00:25:14.910
And we have a Moderator
and a chat there.

00:25:14.910 --> 00:25:17.220
So you can participate
there as well.

00:25:17.220 --> 00:25:18.500
So I have a couple more
questions, and then I think

00:25:18.500 --> 00:25:21.610
we'll dive into the Moderator
questions.

00:25:21.610 --> 00:25:23.280
So what are the plans
for debugging?

00:25:23.280 --> 00:25:26.750
I saw some debugging already
from the editor that goes into

00:25:26.750 --> 00:25:28.190
Dartium, the web browser.

00:25:28.190 --> 00:25:29.490
What's the team working
on right

00:25:29.490 --> 00:25:30.555
now in terms of debugging?

00:25:30.555 --> 00:25:33.120
IVAN POSVA: So in terms
of debugging--

00:25:33.120 --> 00:25:36.955
Matthias isn't here, so I'll
try to answer for him.

00:25:36.955 --> 00:25:40.330
In terms of debugging, the first
effort was to be able to

00:25:40.330 --> 00:25:41.590
debug Dartium.

00:25:41.590 --> 00:25:46.860
So you have an app in your web
browser, hook it up to the

00:25:46.860 --> 00:25:50.990
Chrome Developer Console, set
break points, inspect the

00:25:50.990 --> 00:25:53.950
stack, variables of the
stack, and so on.

00:25:53.950 --> 00:25:56.170
That is mostly working.

00:25:56.170 --> 00:26:00.300
I'm sure there are still some
grey areas in that stuff that

00:26:00.300 --> 00:26:02.240
is not implemented properly.

00:26:02.240 --> 00:26:05.160
But the feedback I
got from some of

00:26:05.160 --> 00:26:07.615
developers was very positive.

00:26:11.420 --> 00:26:14.680
And then, we switched
gears a bit.

00:26:14.680 --> 00:26:18.430
Now it's being able to debug
standalone programs, be it

00:26:18.430 --> 00:26:21.750
scripts, be it server
programs.

00:26:21.750 --> 00:26:23.870
Generally, we talk about
Dartium and how

00:26:23.870 --> 00:26:27.460
Dart is inside Chrome.

00:26:27.460 --> 00:26:30.200
With Dart IO, you can build
pretty beefy servers.

00:26:30.200 --> 00:26:33.720
We use some of it for our
internal Dart infrastructure

00:26:33.720 --> 00:26:35.140
for testing and so on.

00:26:37.650 --> 00:26:40.100
So you can build pretty
beefy programs.

00:26:40.100 --> 00:26:44.610
So far Mads and his team have
been doing print, println,

00:26:44.610 --> 00:26:46.480
print debugging.

00:26:46.480 --> 00:26:51.070
So they want to have something
that is more like a real

00:26:51.070 --> 00:26:54.420
developer experience
for those programs.

00:26:54.420 --> 00:26:55.600
So that's what we've
been doing.

00:26:55.600 --> 00:26:59.290
And there is a wide protocol
being defined.

00:26:59.290 --> 00:27:03.650
It's JSON to some debugger
process.

00:27:03.650 --> 00:27:04.270
You have the debugee.

00:27:04.270 --> 00:27:08.660
And I know Matthias has been
working on it a basically

00:27:08.660 --> 00:27:13.220
small Dart program that can
basically be used as a

00:27:13.220 --> 00:27:16.170
debugger itself, like a
command line debugger.

00:27:16.170 --> 00:27:18.430
Or you hook it up
with the other.

00:27:18.430 --> 00:27:19.900
SIVA ANNAMALAI: Yeah.

00:27:19.900 --> 00:27:23.234
That is kind of a test program
for testing the wide protocol.

00:27:23.234 --> 00:27:27.510
IVAN POSVA: And I think if it
becomes useful, that test

00:27:27.510 --> 00:27:30.690
program can actually mature into
something that you can

00:27:30.690 --> 00:27:33.336
use like GDB, let's say.

00:27:33.336 --> 00:27:34.170
[INTERPOSING VOICES]

00:27:34.170 --> 00:27:35.010
IVAN POSVA: command line.

00:27:35.010 --> 00:27:35.208
SETH LADD: Right.

00:27:35.208 --> 00:27:35.340
Debugger, yeah.

00:27:35.340 --> 00:27:36.651
IVAN POSVA:

00:27:36.651 --> 00:27:38.980
SETH LADD: But I think this is
a great clarification for

00:27:38.980 --> 00:27:41.860
everyone watching, is that Dart
is-- the virtual machine

00:27:41.860 --> 00:27:44.015
is not just targeted
to web browsers.

00:27:44.015 --> 00:27:47.220
And as you were mentioning, we
have a suite of I/O libraries,

00:27:47.220 --> 00:27:51.030
like files and directories, raw
sockets, web servers, that

00:27:51.030 --> 00:27:54.320
all run from the command line,
essentially, as a server.

00:27:54.320 --> 00:27:57.750
And our Hackathon attendees, for
instance, everyone was--

00:27:57.750 --> 00:27:58.370
not everyone.

00:27:58.370 --> 00:28:01.840
Many people were doing client-
and server-based apps.

00:28:01.840 --> 00:28:04.110
And many people were asking
about the debugging.

00:28:04.110 --> 00:28:06.570
And so it's cool to see that
that's on their radar.

00:28:06.570 --> 00:28:07.880
But I love that about Dart.

00:28:07.880 --> 00:28:10.500
You can have the same code on
the client and the server

00:28:10.500 --> 00:28:13.540
running and some nice
code sharing.

00:28:13.540 --> 00:28:14.630
And it's cool.

00:28:14.630 --> 00:28:17.980
Same constructs in
both places.

00:28:17.980 --> 00:28:20.310
Another big feature that
always comes up in

00:28:20.310 --> 00:28:23.410
conversation that I get and
questions is reflection.

00:28:23.410 --> 00:28:25.420
How will reflection
work in Dart?

00:28:25.420 --> 00:28:30.340
And we hear rumblings of this
system called Mirrors.

00:28:30.340 --> 00:28:32.930
And I think, Todd, are
you working on yours?

00:28:32.930 --> 00:28:34.050
Can you talk a little
bit about--

00:28:34.050 --> 00:28:35.020
TODD TURNIDGE: We get to
do a lot of fun work.

00:28:35.020 --> 00:28:36.940
[INTERPOSING VOICES]

00:28:36.940 --> 00:28:39.000
SETH LADD: So what
are mirrors?

00:28:39.000 --> 00:28:40.922
Where is just simple
reflection?

00:28:40.922 --> 00:28:42.850
TODD TURNIDGE: Well, one
of the people in

00:28:42.850 --> 00:28:44.360
our team, Gilad Bracha--

00:28:44.360 --> 00:28:47.910
he wrote an interesting
paper about mirrors.

00:28:47.910 --> 00:28:50.490
It's just an approach to
reflection that tries to avoid

00:28:50.490 --> 00:28:53.010
certain downfalls in
other systems.

00:28:53.010 --> 00:28:56.010
Each object has an associated
object called a mirror.

00:28:56.010 --> 00:28:57.360
And the mirror could
refer to a local

00:28:57.360 --> 00:29:00.030
object or a remote object.

00:29:00.030 --> 00:29:01.940
You don't have to have this
mirror to have it do all of

00:29:01.940 --> 00:29:04.880
the reflective operations.

00:29:04.880 --> 00:29:08.590
And he argues a lot for it in
the paper, in terms of he

00:29:08.590 --> 00:29:11.300
stratifies which things you can
do at which level, and it

00:29:11.300 --> 00:29:13.420
tends to make a cleaner
conceptual

00:29:13.420 --> 00:29:14.360
break in the system.

00:29:14.360 --> 00:29:16.870
And it also tends to be more
of the thing you could take

00:29:16.870 --> 00:29:19.360
one mirror implementation and
substitute in a different one.

00:29:19.360 --> 00:29:21.035
So this one might be
your local mirrors.

00:29:21.035 --> 00:29:22.550
This one might be your
remote mirrors.

00:29:22.550 --> 00:29:24.310
This one might be a different
kind of mirrors.

00:29:24.310 --> 00:29:25.825
Instead of going on the
live program, it

00:29:25.825 --> 00:29:27.775
reflects on a language--

00:29:27.775 --> 00:29:28.660
IVAN POSVA: A core dump.

00:29:28.660 --> 00:29:30.390
TODD TURNIDGE: Or a core dump
or something like that.

00:29:30.390 --> 00:29:32.685
And so it's a lot like
dependency injection.

00:29:32.685 --> 00:29:35.800
If you design it right, you
can inject a new library

00:29:35.800 --> 00:29:36.740
implementation.

00:29:36.740 --> 00:29:38.890
So in terms of implementation,
it's still

00:29:38.890 --> 00:29:40.860
early days for that.

00:29:40.860 --> 00:29:43.902
We're just beginning to
implement his proposal and

00:29:43.902 --> 00:29:47.658
flush out the details of that.

00:29:47.658 --> 00:29:48.770
IVAN POSVA: Yeah.

00:29:48.770 --> 00:29:52.240
Also, some of the ideas he has
is that that you can have that

00:29:52.240 --> 00:29:53.720
mirrors can have certain
capabilities.

00:29:53.720 --> 00:29:56.120
Maybe you can only inspect,
not change a program, and

00:29:56.120 --> 00:29:58.540
stuff like that.

00:29:58.540 --> 00:30:01.170
He wants to be able to use
mirrors to build out

00:30:01.170 --> 00:30:02.560
completely new isolates.

00:30:02.560 --> 00:30:06.930
So you basically say, OK, give
me a new isolate mirror.

00:30:06.930 --> 00:30:09.345
I want to load this library into
it, this library into it,

00:30:09.345 --> 00:30:11.610
and this other library
into it.

00:30:11.610 --> 00:30:15.300
And then I add this code.

00:30:15.300 --> 00:30:18.280
And then it loads
another method.

00:30:18.280 --> 00:30:21.370
Or maybe even pre-populate
it with some state.

00:30:21.370 --> 00:30:23.120
And then call this
method on it.

00:30:23.120 --> 00:30:24.870
So it's really like--

00:30:24.870 --> 00:30:27.060
TODD TURNIDGE: It's like
a dynamic code

00:30:27.060 --> 00:30:27.800
loading kind of thing.

00:30:27.800 --> 00:30:30.390
IVAN POSVA: Legos for your
program, and then you say, OK,

00:30:30.390 --> 00:30:31.470
now it's done--

00:30:31.470 --> 00:30:32.640
run.

00:30:32.640 --> 00:30:39.560
And mirrors are then strong
enough to kind of do the

00:30:39.560 --> 00:30:42.210
reflection yourself, or
basically do more than just

00:30:42.210 --> 00:30:45.050
reflection yourself.

00:30:45.050 --> 00:30:47.856
Build up new objects
and so on.

00:30:47.856 --> 00:30:49.775
SETH LADD: Are you aware of
any other systems that use

00:30:49.775 --> 00:30:50.470
this concept of mirrors?

00:30:50.470 --> 00:30:54.590
Or is Dart going to be one of
the first or the first that is

00:30:54.590 --> 00:30:56.930
implementing this for real world
kind of applications?

00:30:56.930 --> 00:30:59.426
IVAN POSVA: You worked on
[? Strunk, ?] right?

00:30:59.426 --> 00:31:00.920
MALE SPEAKER 1: Yeah, I
worked a little bit.

00:31:00.920 --> 00:31:03.520
I was mostly working on
some other parts.

00:31:03.520 --> 00:31:05.335
TODD TURNIDGE: Did he do it
with this other language?

00:31:05.335 --> 00:31:07.600
IVAN POSVA: Yes, I think.

00:31:07.600 --> 00:31:08.510
Newspeak has it.

00:31:08.510 --> 00:31:12.010
So it's been around
for a while.

00:31:12.010 --> 00:31:13.470
These ideas.

00:31:13.470 --> 00:31:17.580
They've not been
used too much.

00:31:17.580 --> 00:31:19.830
But on the other hand, for
example, if you used V8, and

00:31:19.830 --> 00:31:24.130
you used the debugging V8, all
of the debugging API behind

00:31:24.130 --> 00:31:25.805
the scenes is implemented
with these mirrors.

00:31:28.540 --> 00:31:34.010
So you can't really tell,
but that's what it uses

00:31:34.010 --> 00:31:35.030
underneath.

00:31:35.030 --> 00:31:37.260
SETH LADD: This is a hot
feature request.

00:31:37.260 --> 00:31:39.610
So it's cool to hear that we
have a really solid plan.

00:31:39.610 --> 00:31:42.170
We've seen this implemented in
other languages, and it's

00:31:42.170 --> 00:31:42.835
coming for Dart.

00:31:42.835 --> 00:31:46.170
And I think it will enable a
lot of great lower-level

00:31:46.170 --> 00:31:48.330
libraries that people will
build on top of.

00:31:48.330 --> 00:31:52.130
Things like JSON parsing could
really love the mirrors as you

00:31:52.130 --> 00:31:54.590
reconstruct an object based
on some text streams.

00:31:54.590 --> 00:31:58.360
So yeah, that's great.

00:31:58.360 --> 00:32:01.570
Before we dive into questions,
I have another question on

00:32:01.570 --> 00:32:03.710
language design impacting
VM design.

00:32:03.710 --> 00:32:06.840
One of the more novel features
of Dart is its optional

00:32:06.840 --> 00:32:08.290
static-type annotations.

00:32:08.290 --> 00:32:11.670
Now, I'm just curious how that
might have impacted, at all,

00:32:11.670 --> 00:32:14.775
if at all, the VM design.

00:32:14.775 --> 00:32:18.350
Did you have to go to a new
place in VM design because of

00:32:18.350 --> 00:32:19.340
these optional static types?

00:32:19.340 --> 00:32:21.940
Or is the way they designed them
for them to be decoupled

00:32:21.940 --> 00:32:23.250
and it really didn't impact?

00:32:23.250 --> 00:32:25.692
What was the intersection
there?

00:32:25.692 --> 00:32:27.830
MALE SPEAKER 1: So optional
typing is known from

00:32:27.830 --> 00:32:30.360
JavaScript and from
[INAUDIBLE].

00:32:30.360 --> 00:32:34.900
Now, in addition to that, we
need to do this optional

00:32:34.900 --> 00:32:37.530
static run-time checking.

00:32:37.530 --> 00:32:40.260
So those checks need to be
eliminated, need to be

00:32:40.260 --> 00:32:42.020
efficient, and so on, so on.

00:32:42.020 --> 00:32:45.640
We have a lot of novel ideas how
to do this correctly and

00:32:45.640 --> 00:32:46.310
efficiently.

00:32:46.310 --> 00:32:49.600
We are not yet there, so the
run-time checks, they're a

00:32:49.600 --> 00:32:51.670
little bit too slow
for our taste.

00:32:51.670 --> 00:32:55.460
We are working on making the
check mode as fast as we can

00:32:55.460 --> 00:32:57.520
and putting optimization
to get it done.

00:32:57.520 --> 00:33:02.300
So making these optional
run-time checks very quick is

00:33:02.300 --> 00:33:03.600
a challenge.

00:33:03.600 --> 00:33:06.690
We have found that a lot of--
that the idea of optional

00:33:06.690 --> 00:33:10.220
typing and these--

00:33:10.220 --> 00:33:13.240
it's kind of novel to
many people who are

00:33:13.240 --> 00:33:13.970
accustomed to it.

00:33:13.970 --> 00:33:16.640
If you started typing, and I
think there's a lot of people

00:33:16.640 --> 00:33:18.730
who have to get used to that.

00:33:18.730 --> 00:33:21.910
How they can use that
efficiently in their systems

00:33:21.910 --> 00:33:24.755
is a challenge, but I
think it's worth it.

00:33:24.755 --> 00:33:28.500
IVAN POSVA: I think really you
can tell some of the team

00:33:28.500 --> 00:33:33.090
members skip the V8 step.

00:33:33.090 --> 00:33:35.290
In JavaScript, you have no
types, you have no static

00:33:35.290 --> 00:33:38.120
types, and you always have to
figure it out at run-time.

00:33:38.120 --> 00:33:43.310
For some, that came from
statically typed languages.

00:33:43.310 --> 00:33:46.570
It was hard to let go of,
but it's right here.

00:33:46.570 --> 00:33:47.990
It has this type.

00:33:47.990 --> 00:33:50.240
While this is only--

00:33:50.240 --> 00:33:52.570
it is not guaranteed
to be correct.

00:33:52.570 --> 00:33:55.870
So it is otherwise-- so unless
they're in check mode, you

00:33:55.870 --> 00:33:59.610
can't rely on that.

00:33:59.610 --> 00:34:01.840
From the VM's perspective,
even though a type was

00:34:01.840 --> 00:34:04.630
specified, we read
it as a bar.

00:34:04.630 --> 00:34:07.180
We don't know anything about
it until we get the type

00:34:07.180 --> 00:34:07.946
feedback on it.

00:34:07.946 --> 00:34:08.639
SETH LADD: Right.

00:34:08.639 --> 00:34:10.630
And that's where that check
mode, as you were talking

00:34:10.630 --> 00:34:12.179
about, comes into play.

00:34:12.179 --> 00:34:15.159
For those who don't know, Dart
can run in really two

00:34:15.159 --> 00:34:15.730
different modes.

00:34:15.730 --> 00:34:19.030
One mode we call production mode
where all these optional

00:34:19.030 --> 00:34:20.920
static type annotations
are effectively--

00:34:20.920 --> 00:34:23.960
or where you were saying,
you just see a bar.

00:34:23.960 --> 00:34:28.230
But then you flip a flag and you
get check mode where the

00:34:28.230 --> 00:34:31.449
VM and the other run times
begin to respect these

00:34:31.449 --> 00:34:34.110
optional static type annotations
can do some

00:34:34.110 --> 00:34:35.075
dynamic type assertions.

00:34:35.075 --> 00:34:36.350
IVAN POSVA: Yeah.

00:34:36.350 --> 00:34:38.760
It's developer mode,
more like it.

00:34:38.760 --> 00:34:41.194
So you really-- you're
expecting this

00:34:41.194 --> 00:34:43.460
type T here, right?

00:34:43.460 --> 00:34:46.386
And you make sure that the
variable being assigned has

00:34:46.386 --> 00:34:49.120
that or the value being assigned
to this variable has

00:34:49.120 --> 00:34:50.730
the appropriate time.

00:34:50.730 --> 00:34:53.804
MALE SPEAKER 1: It's important
to know also that when you add

00:34:53.804 --> 00:34:57.970
types to Dart, it doesn't
improve your performance.

00:34:57.970 --> 00:35:00.360
So you're not using the
type information to

00:35:00.360 --> 00:35:01.720
generate better code.

00:35:01.720 --> 00:35:04.230
And we feel we don't need it.

00:35:04.230 --> 00:35:07.330
We think with all the obstacles
to the technology

00:35:07.330 --> 00:35:12.760
that we have to this position,
we don't need that to generate

00:35:12.760 --> 00:35:15.165
code of high performance.

00:35:15.165 --> 00:35:16.365
SETH LADD: Great.

00:35:16.365 --> 00:35:19.320
SIVA ANNAMALAI: It's more for
employing program productivity

00:35:19.320 --> 00:35:23.460
in terms of making the code more
legible and how we are

00:35:23.460 --> 00:35:25.380
structuring it and
things like that.

00:35:25.380 --> 00:35:28.290
Everybody knows JavaScript is
probably hard to read and

00:35:28.290 --> 00:35:29.228
understand.

00:35:29.228 --> 00:35:31.020
But we're trying.

00:35:31.020 --> 00:35:33.445
That's one of the prime
goals, was that.

00:35:33.445 --> 00:35:35.570
IVAN POSVA: And then you can add
the static type warnings

00:35:35.570 --> 00:35:39.030
on top of it during
the run time.

00:35:39.030 --> 00:35:42.790
We don't look at it, but ahead
of time, you already got

00:35:42.790 --> 00:35:45.070
static type warnings
from the editor.

00:35:45.070 --> 00:35:47.770
You're assigning something
that doesn't match here.

00:35:47.770 --> 00:35:49.040
Is this really all you want?

00:35:49.040 --> 00:35:52.874
Occasionally, you know better.

00:35:52.874 --> 00:35:55.570
SETH LADD: And for those that do
use the editor, you get the

00:35:55.570 --> 00:35:56.680
static type warnings.

00:35:56.680 --> 00:35:58.510
And if you don't use the editor,
there's a standalone

00:35:58.510 --> 00:36:02.060
program that we're continuing
to improve which can run

00:36:02.060 --> 00:36:03.930
through your code and give you
these static warnings so you

00:36:03.930 --> 00:36:05.950
can integrate into your tool
chain as you see fit.

00:36:05.950 --> 00:36:08.100
So it's really, really nice.

00:36:08.100 --> 00:36:09.750
One other feature I remembered
of the Dart

00:36:09.750 --> 00:36:11.990
virtual machine is snapshots.

00:36:11.990 --> 00:36:14.260
Has anyone been working
on snapshots lately?

00:36:14.260 --> 00:36:15.630
SIVA ANNAMALAI: Yeah.

00:36:15.630 --> 00:36:20.040
We did an initial round of
snapshotting the whole code

00:36:20.040 --> 00:36:23.260
libraries and in the case of
Dartium, the whole DOM and

00:36:23.260 --> 00:36:25.530
[INAUDIBLE] libraries,
which are kind of now

00:36:25.530 --> 00:36:27.350
in-built into the VM.

00:36:27.350 --> 00:36:31.180
So any time an isolate is
started, it doesn't re-read

00:36:31.180 --> 00:36:32.440
all these code libraries.

00:36:32.440 --> 00:36:35.320
It just starts off from
the snapshot.

00:36:35.320 --> 00:36:38.620
So what the advantage of that is
you don't have to tokenize

00:36:38.620 --> 00:36:40.180
the whole thing again.

00:36:40.180 --> 00:36:43.340
So you get that all in priority,
and it kind of

00:36:43.340 --> 00:36:46.490
speeds up the starting
process.

00:36:46.490 --> 00:36:49.390
Apart from that, we also have
something called application

00:36:49.390 --> 00:36:54.300
snapshots, which Dartium has
been using it, in that when

00:36:54.300 --> 00:36:57.890
you first load an application,
it creates a snapshot of that

00:36:57.890 --> 00:37:00.350
application, stores it off
in the builder cache.

00:37:00.350 --> 00:37:03.790
And then subsequent reload of
the page full start from the

00:37:03.790 --> 00:37:07.940
builder cache and runs it, which
again, the advantage is

00:37:07.940 --> 00:37:11.100
it skips over all the tokenizing
and the whole

00:37:11.100 --> 00:37:13.260
parsing concept.

00:37:13.260 --> 00:37:15.330
SETH LADD: Does the snapshot
system-- this is might be a

00:37:15.330 --> 00:37:17.780
Dartium question, but
how does it know

00:37:17.780 --> 00:37:19.050
to expire that snapshot?

00:37:19.050 --> 00:37:20.600
Does it look at some of the
headers coming in from the

00:37:20.600 --> 00:37:21.330
source file?

00:37:21.330 --> 00:37:21.660
SIVA ANNAMALAI: Yeah.

00:37:21.660 --> 00:37:23.040
It's the same standard
[INAUDIBLE]

00:37:23.040 --> 00:37:26.290
cache expiry policy that they
have in the regular browser.

00:37:26.290 --> 00:37:29.235
It's the same thing you apply
to this, too, if it expires.

00:37:29.235 --> 00:37:30.620
IVAN POSVA: They just
stick the binary

00:37:30.620 --> 00:37:32.270
blob into the cache.

00:37:32.270 --> 00:37:36.250
Instead of the resource,
they load it.

00:37:36.250 --> 00:37:40.390
Or next to the resource,
they load it.

00:37:40.390 --> 00:37:43.070
Maybe we need to take
a step back.

00:37:43.070 --> 00:37:44.320
What is inside a snapshot?

00:37:47.020 --> 00:37:51.690
So as we said, on your
earlier question, how

00:37:51.690 --> 00:37:52.690
does it even get going?

00:37:52.690 --> 00:37:57.495
What do we need to do
to start up a VM?

00:37:57.495 --> 00:38:00.100
Well, we parse the program.

00:38:00.100 --> 00:38:03.750
We build up its internal data
structures so that we don't

00:38:03.750 --> 00:38:06.880
have to re-parse the individual
characters.

00:38:06.880 --> 00:38:11.240
We have this, what we
call a token stream.

00:38:11.240 --> 00:38:15.720
So all of that structure
lives in the snapshot.

00:38:15.720 --> 00:38:18.120
So when you reload the snapshot,
basically, the whole

00:38:18.120 --> 00:38:19.300
structure of the--

00:38:19.300 --> 00:38:21.420
these classes are
this library.

00:38:24.030 --> 00:38:28.150
These methods and fields are
associated with these classes.

00:38:28.150 --> 00:38:32.930
All of that is basically
read in from a

00:38:32.930 --> 00:38:35.610
serialized object stream.

00:38:35.610 --> 00:38:41.265
These objects are recreated
again immediately without any

00:38:41.265 --> 00:38:42.600
real parsing going on.

00:38:42.600 --> 00:38:45.680
So that's basically where
the snapshot starts.

00:38:45.680 --> 00:38:48.510
That's why Siva can say, well,
you have a snapshot.

00:38:48.510 --> 00:38:50.090
You just reload it.

00:38:50.090 --> 00:38:52.210
Boom, here's your VM.

00:38:52.210 --> 00:38:54.680
SIVA ANNAMALAI: So the way to
look at it is to say it's a

00:38:54.680 --> 00:38:58.920
snapshot of the image of the
heap that was there after we

00:38:58.920 --> 00:39:02.180
did the initial parsing and
built up all the initial data

00:39:02.180 --> 00:39:03.190
structures and so on.

00:39:03.190 --> 00:39:06.990
So that heap has been dumped
into this, again, serialized

00:39:06.990 --> 00:39:09.070
into this buffer.

00:39:09.070 --> 00:39:12.210
And then we deserialize it the
next time we load it so that

00:39:12.210 --> 00:39:15.910
the heap just comes out without
having done any of the

00:39:15.910 --> 00:39:17.546
initial parsing and all that.

00:39:17.546 --> 00:39:18.340
IVAN POSVA: I don't know.

00:39:18.340 --> 00:39:21.150
Some of the viewers
might have seen--

00:39:21.150 --> 00:39:24.830
when they looked in the V8
implementation details, there

00:39:24.830 --> 00:39:29.960
is a snapshot there as well,
because V8 has--

00:39:29.960 --> 00:39:33.980
some areas of the JavaScript
libraries are written in

00:39:33.980 --> 00:39:35.810
JavaScript itself for V8.

00:39:35.810 --> 00:39:40.350
So what V8 does, basically it
snapshots that part of the

00:39:40.350 --> 00:39:43.050
core libraries.

00:39:43.050 --> 00:39:46.820
The problem for JavaScript
versus Dart is that you build

00:39:46.820 --> 00:39:49.820
up your program structure beyond
what is really known to

00:39:49.820 --> 00:39:52.840
the VM itself.

00:39:52.840 --> 00:39:54.730
It needs to execute code.

00:39:54.730 --> 00:39:58.370
And to properly be able to
snapshot things, it's really

00:39:58.370 --> 00:40:03.425
hard to figure out once you
start executing code.

00:40:03.425 --> 00:40:05.940
With the Dart language, you have
this structure is in the

00:40:05.940 --> 00:40:08.890
class, not as executing
programs.

00:40:08.890 --> 00:40:10.230
It's in the source code.

00:40:10.230 --> 00:40:13.110
So that's why we can snapshot
bigger things, even

00:40:13.110 --> 00:40:15.015
applications.

00:40:15.015 --> 00:40:17.780
SETH LADD: I think some of the
initial research the Seattle

00:40:17.780 --> 00:40:21.220
team did was 10 times
better start-up

00:40:21.220 --> 00:40:23.610
performance due to snapshots.

00:40:23.610 --> 00:40:26.210
And so I'm really looking
forward to that.

00:40:26.210 --> 00:40:28.110
So let's go ahead and take some
of our viewer questions

00:40:28.110 --> 00:40:28.540
from the Moderator.

00:40:28.540 --> 00:40:33.030
If you're just joining us,
html5rocks.com/live has a link

00:40:33.030 --> 00:40:33.820
to this Moderator.

00:40:33.820 --> 00:40:36.520
You can vote up and down
questions or ask your own.

00:40:36.520 --> 00:40:38.170
We'll start right at the top.

00:40:38.170 --> 00:40:42.270
Our buddy Ladislav, who is
prolific on the general

00:40:42.270 --> 00:40:43.710
discussion mailing list.

00:40:43.710 --> 00:40:45.280
So thanks for all
your help there.

00:40:45.280 --> 00:40:46.750
TODD TURNIDGE: We should
say hi Ladislav.

00:40:46.750 --> 00:40:48.280
I see a lot of his emails.

00:40:48.280 --> 00:40:50.966
IVAN POSVA: same with us.

00:40:50.966 --> 00:40:53.450
SETH LADD: He asks, "If I
understand correctly, isolates

00:40:53.450 --> 00:40:55.240
are meant to be very lightweight
in Dart.

00:40:55.240 --> 00:40:59.136
Yet the VM trashes my OS badly
if I create like 100 of them."

00:40:59.136 --> 00:41:01.080
TODD TURNIDGE: Yeah, he has a
bug open for this, I think.

00:41:01.080 --> 00:41:03.120
SETH LADD: OK. "What are the
intricacies in this, and how

00:41:03.120 --> 00:41:05.190
do you plan to tackle them?" So
I know we talked about it a

00:41:05.190 --> 00:41:08.060
little bit, but if there's a
bug, have we thought about

00:41:08.060 --> 00:41:09.160
anything more?

00:41:09.160 --> 00:41:11.770
TODD TURNIDGE: Well, I need to
re-review the bug now that we

00:41:11.770 --> 00:41:12.355
have the thread pools.

00:41:12.355 --> 00:41:14.780
I think the bug was
file before that.

00:41:14.780 --> 00:41:15.990
And then there's just--

00:41:15.990 --> 00:41:18.860
we consume a certain amount
of resources per isolate.

00:41:18.860 --> 00:41:21.560
And we need to just start
turning the screws on that.

00:41:21.560 --> 00:41:24.510
And then there's even some
objects that we could share

00:41:24.510 --> 00:41:26.050
across all isolates.

00:41:26.050 --> 00:41:29.090
Ivan did some work recently with
something called class

00:41:29.090 --> 00:41:32.990
indexes that are where an object
doesn't need to refer

00:41:32.990 --> 00:41:34.150
to its class for its own heap.

00:41:34.150 --> 00:41:36.110
It can refer to just the general
notion of I am a

00:41:36.110 --> 00:41:38.830
string and what a string
is in isolate.

00:41:38.830 --> 00:41:40.540
One might be a little different
than this one, but

00:41:40.540 --> 00:41:42.280
we can actually share
the data.

00:41:42.280 --> 00:41:46.680
And so we could start to
actually share a lot more

00:41:46.680 --> 00:41:47.650
between isolates.

00:41:47.650 --> 00:41:49.140
I don't know if that'll
help with-- it

00:41:49.140 --> 00:41:49.970
will help with scaling.

00:41:49.970 --> 00:41:52.020
IVAN POSVA: Oh, it will
help definitely on

00:41:52.020 --> 00:41:53.265
a per isolate overhead.

00:41:53.265 --> 00:41:55.735
TODD TURNIDGE: Per isolate
overhead is sort of what's

00:41:55.735 --> 00:41:57.770
trashing your OS problem
over there.

00:41:57.770 --> 00:42:00.070
IVAN POSVA: And if it's not the
threads anymore, then it's

00:42:00.070 --> 00:42:02.340
the per-isolate overhead
is much higher

00:42:02.340 --> 00:42:03.820
than we want it to.

00:42:03.820 --> 00:42:06.100
We have a grand plan
to get there.

00:42:06.100 --> 00:42:10.620
And it's essentially the three
of us that need to get some of

00:42:10.620 --> 00:42:15.967
these ideas that we hashed
out, implemented.

00:42:15.967 --> 00:42:19.070
SIVA ANNAMALAI: And also, our
heap policy right now is not

00:42:19.070 --> 00:42:22.300
that great, so we tend to just
keep growing the heap.

00:42:22.300 --> 00:42:25.130
And so the isolate
takes more--

00:42:25.130 --> 00:42:27.000
the fill time starts
to increase.

00:42:27.000 --> 00:42:30.350
And I think Ivan has a plan
on trying to do a more

00:42:30.350 --> 00:42:33.580
progressive growth of the heap,
so it should reduce that

00:42:33.580 --> 00:42:35.280
footprint also.

00:42:35.280 --> 00:42:36.080
SETH LADD: Cool.

00:42:36.080 --> 00:42:39.400
Well, it's great to hear so much
interest and attention

00:42:39.400 --> 00:42:41.430
from the outside world
and then from the VM

00:42:41.430 --> 00:42:44.020
engineers as well.

00:42:44.020 --> 00:42:47.630
So Adam, who is another one of
our early adopters up in San

00:42:47.630 --> 00:42:49.746
Francisco actually asks--

00:42:49.746 --> 00:42:51.090
oop, I just lost it.

00:42:51.090 --> 00:42:54.050
"Can you explain what object
tagging means in the VM

00:42:54.050 --> 00:42:56.520
world?" Looks like he's someone
who likes to dive into

00:42:56.520 --> 00:42:57.790
the source code a little bit.

00:43:00.660 --> 00:43:02.620
Is there a way to--

00:43:02.620 --> 00:43:06.050
IVAN POSVA: It's unclear what
the-- well, I think I know

00:43:06.050 --> 00:43:06.750
what he asks.

00:43:06.750 --> 00:43:09.210
TODD TURNIDGE: Is he asking
about small integers?

00:43:09.210 --> 00:43:10.770
IVAN POSVA: think that's
what it is.

00:43:10.770 --> 00:43:13.961
SIVA ANNAMALAI: Actually, can
we-- if he is live, can he ask

00:43:13.961 --> 00:43:17.202
us what exactly he meant
by object tagging?

00:43:17.202 --> 00:43:19.800
I'm a little confused on what
he meant by object tagging.

00:43:19.800 --> 00:43:20.940
SETH LADD: We'll follow up.

00:43:20.940 --> 00:43:22.210
I know he's on another
event today.

00:43:22.210 --> 00:43:23.750
So Adam, we'll follow
up with you offline.

00:43:23.750 --> 00:43:25.070
Ask again on the mailing list.

00:43:25.070 --> 00:43:27.165
[INTERPOSING VOICES]

00:43:27.165 --> 00:43:28.510
IVAN POSVA: OK.

00:43:28.510 --> 00:43:32.360
If I heard this question
without any--

00:43:32.360 --> 00:43:35.630
I thought maybe we can get a
little bit more info of what

00:43:35.630 --> 00:43:38.700
he wanted to know.

00:43:38.700 --> 00:43:39.940
In the VM, we--

00:43:39.940 --> 00:43:44.420
like a lot of the language
virtual machines that don't

00:43:44.420 --> 00:43:49.390
have static types for integers
and other basic types,

00:43:49.390 --> 00:43:54.080
integers are really, really
frequently used.

00:43:54.080 --> 00:44:01.070
So what we do is we have
pointers that we just add a

00:44:01.070 --> 00:44:04.240
little bit as one.

00:44:04.240 --> 00:44:06.020
That means those are tagged.

00:44:06.020 --> 00:44:08.190
These are real pointers.

00:44:08.190 --> 00:44:11.075
And then integers themselves,
all integers

00:44:11.075 --> 00:44:12.370
have the low-bit zero.

00:44:12.370 --> 00:44:16.860
They're basically shifted by,
excuse me, by one bit to the

00:44:16.860 --> 00:44:18.140
left so we have--

00:44:18.140 --> 00:44:20.850
instead of 32-bit integers on
the 32-bit machine, we have

00:44:20.850 --> 00:44:25.910
31-bit integers that we
can very efficiently

00:44:25.910 --> 00:44:28.250
represent in the VM.

00:44:28.250 --> 00:44:33.740
And so the low bit really tells
us, when we look at what

00:44:33.740 --> 00:44:39.260
is an object reference, the low
bit tells us, OK, this is

00:44:39.260 --> 00:44:44.030
what we call a small integer,
a 31-bit integer on a x86 or

00:44:44.030 --> 00:44:49.460
an ARM versus a real object
pointer that we have to--

00:44:49.460 --> 00:44:51.490
where we can get at
its class and its

00:44:51.490 --> 00:44:53.440
fields a different way.

00:44:53.440 --> 00:44:56.460
If you tried to call integer
methods on that, on one of

00:44:56.460 --> 00:45:01.850
these smize or small integers,
we can't load the class out of

00:45:01.850 --> 00:45:04.690
the object because
it's not there.

00:45:04.690 --> 00:45:07.090
We have to find the class
somewhere else.

00:45:07.090 --> 00:45:09.531
That's where the class index
and so on helps us swap

00:45:09.531 --> 00:45:10.710
because we can then
just load it.

00:45:10.710 --> 00:45:13.100
TODD TURNIDGE: And it means
that we can compile pretty

00:45:13.100 --> 00:45:14.090
efficient code for integers.

00:45:14.090 --> 00:45:16.950
MALE SPEAKER 1: And it's also
true, for example, sometimes

00:45:16.950 --> 00:45:19.170
you have two operations between
those, but it won't be

00:45:19.170 --> 00:45:21.550
the integer that's-- it'll just
be an integer which is

00:45:21.550 --> 00:45:22.520
larger than 31-bit.

00:45:22.520 --> 00:45:24.180
It creates an object.

00:45:24.180 --> 00:45:26.592
It gets stacked, and then
present that new integer and

00:45:26.592 --> 00:45:27.330
get [INAUDIBLE] to it.

00:45:27.330 --> 00:45:29.920
IVAN POSVA: Yeah.

00:45:29.920 --> 00:45:32.420
To the user, it's completely
transparent.

00:45:32.420 --> 00:45:36.870
MALE SPEAKER 1: For us,
it makes it easy to--

00:45:36.870 --> 00:45:41.980
especially for the optimizing
compiler, you just basically--

00:45:41.980 --> 00:45:44.520
for a lot of operations, you
can just-- during normal

00:45:44.520 --> 00:45:46.740
integer operations, you
check whether the low

00:45:46.740 --> 00:45:48.440
bits have been set.

00:45:48.440 --> 00:45:51.240
And then you're back
off to the races.

00:45:51.240 --> 00:45:52.890
MALE SPEAKER 1: Your performance
provides and

00:45:52.890 --> 00:45:56.470
incredible help and is very
simple to implement.

00:45:56.470 --> 00:45:59.210
The next step for doubles,
you cannot do that.

00:45:59.210 --> 00:46:03.200
And all the double operations
need to go via objects in the

00:46:03.200 --> 00:46:03.685
un-optimization.

00:46:03.685 --> 00:46:08.620
We're working very hard on
making doubles, real doubles,

00:46:08.620 --> 00:46:11.020
machine double, and to bring
the performance up.

00:46:11.020 --> 00:46:12.730
IVAN POSVA: Yeah.

00:46:12.730 --> 00:46:15.870
And then on a 64-bit VM, a lot
of people, I think, are

00:46:15.870 --> 00:46:18.150
starting to use that as well.

00:46:18.150 --> 00:46:22.400
On a 64-bit VM, while it's 63
bit of small integers, I think

00:46:22.400 --> 00:46:22.590
that is a--

00:46:22.590 --> 00:46:23.665
TODD TURNIDGE: Which is
a lot of small int.

00:46:23.665 --> 00:46:25.340
IVAN POSVA: Yeah, that
is a pretty large

00:46:25.340 --> 00:46:29.110
value for a small integer.

00:46:29.110 --> 00:46:32.000
And then, yeah, we have a couple
behind the scenes.

00:46:32.000 --> 00:46:33.850
We have this whole integer
hierarchy.

00:46:33.850 --> 00:46:38.350
From a small integer, you flow
over to a medium integer,

00:46:38.350 --> 00:46:40.710
which is really a
64-bit value.

00:46:40.710 --> 00:46:45.060
It's heap-allocated, but then
we just use the regular

00:46:45.060 --> 00:46:47.150
machine instructions
to operate on that.

00:46:47.150 --> 00:46:49.160
Then, you flow over to
the big end, which

00:46:49.160 --> 00:46:51.100
is arbitrarily sized.

00:46:51.100 --> 00:46:52.560
SETH LADD: And we should
probably talk about the

00:46:52.560 --> 00:46:55.055
language semantics are that
integers are arbitrarily--

00:46:55.055 --> 00:46:55.970
IVAN POSVA: Sized.

00:46:55.970 --> 00:46:56.830
SETH LADD: --sized or--

00:46:56.830 --> 00:46:58.440
yeah.

00:46:58.440 --> 00:46:59.540
Great.

00:46:59.540 --> 00:47:02.910
Well, OK, we've got about
10 minutes left.

00:47:02.910 --> 00:47:07.650
Songhun Kim, who leads the
Korea Darlang User Group,

00:47:07.650 --> 00:47:11.985
asks, "Are we sharing any
benchmarks between the Dart VM

00:47:11.985 --> 00:47:16.180
and V8?" And what I think he's
really asking is how are we

00:47:16.180 --> 00:47:18.986
kind of measuring ourselves?

00:47:18.986 --> 00:47:21.340
MALE SPEAKER 1: We have
benchmarks written in

00:47:21.340 --> 00:47:24.610
JavaScript and in Dart,
and none of them--

00:47:24.610 --> 00:47:28.260
the JavaScript benchmarks we
run on the best JavaScript

00:47:28.260 --> 00:47:32.700
engine available now, which is
V8 and compare it to dart2dart

00:47:32.700 --> 00:47:34.850
and track this on
a daily basis.

00:47:34.850 --> 00:47:37.670
And we are seeing improvement.

00:47:37.670 --> 00:47:41.430
And we will see more and more
improvement until we can

00:47:41.430 --> 00:47:43.270
develop faster than V8.

00:47:43.270 --> 00:47:45.430
IVAN POSVA: Currently, I don't
think we're there yet.

00:47:45.430 --> 00:47:47.930
SETH LADD: Still very early,
but it's great to hear that

00:47:47.930 --> 00:47:49.340
we're tracking this stuff.

00:47:49.340 --> 00:47:50.350
MALE SPEAKER 1: Absolutely.

00:47:50.350 --> 00:47:52.560
SETH LADD: Another question I
believe probably came in from

00:47:52.560 --> 00:47:56.480
the comments or the chat stream
was, "What types of

00:47:56.480 --> 00:47:59.710
things are being put into the
Dart VM to allow developers to

00:47:59.710 --> 00:48:02.840
control/be notified
about GC events?

00:48:02.840 --> 00:48:04.990
This is a large problem at
high-performance JavaScript

00:48:04.990 --> 00:48:07.960
applications where apps can't
control when a GC flush

00:48:07.960 --> 00:48:10.320
occurs." Any thoughts about--

00:48:10.320 --> 00:48:11.730
I think this is really asking
about two things.

00:48:11.730 --> 00:48:16.240
One, he's asking, can I be
notified when GC occurs?

00:48:16.240 --> 00:48:20.140
And two, can I control when
a GC might occur?

00:48:20.140 --> 00:48:24.330
As VM engineers, I'm sure you've
seen systems built one

00:48:24.330 --> 00:48:24.840
way or the other.

00:48:24.840 --> 00:48:28.150
What are your thoughts there?

00:48:28.150 --> 00:48:33.410
SIVA ANNAMALAI: In terms of
notification, the Dart API, if

00:48:33.410 --> 00:48:36.950
I remember right, the Dartium
did request it, and delivered

00:48:36.950 --> 00:48:40.520
a notification that we call
back from the Dart API, I

00:48:40.520 --> 00:48:41.200
think, is--

00:48:41.200 --> 00:48:42.444
TODD TURNIDGE: Yeah, at the
embedder level, you can

00:48:42.444 --> 00:48:42.876
certainly--

00:48:42.876 --> 00:48:43.310
[INTERPOSING VOICES]

00:48:43.310 --> 00:48:44.920
SIVA ANNAMALAI: As an embedder,
you can actually

00:48:44.920 --> 00:48:46.546
register yourself.

00:48:46.546 --> 00:48:48.380
TODD TURNIDGE: You can control
all call-backs, upload

00:48:48.380 --> 00:48:51.262
call-backs and weak reference
sets and the whole thing.

00:48:51.262 --> 00:48:54.140
SIVA ANNAMALAI: But in terms of
controlling it, I have some

00:48:54.140 --> 00:48:55.170
strong views on that.

00:48:55.170 --> 00:48:58.730
Maybe others don't share it, but
I've generally felt that

00:48:58.730 --> 00:49:02.430
trying to control when a GC
happens is not quite a good

00:49:02.430 --> 00:49:05.085
approach, because the garbage
collector does have heuristics

00:49:05.085 --> 00:49:07.830
built into it to control
these things.

00:49:07.830 --> 00:49:11.120
And you know that it has been--
at least my experience

00:49:11.120 --> 00:49:14.110
with these things have been that
the nicely implemented

00:49:14.110 --> 00:49:17.267
garbage collector in the VM
does a pretty good job of

00:49:17.267 --> 00:49:19.880
knowing when garbage
collection should

00:49:19.880 --> 00:49:22.060
happen and does it.

00:49:22.060 --> 00:49:26.200
IVAN POSVA: So when you look
at the other languages that

00:49:26.200 --> 00:49:34.820
allow exposure of the GC event
and trigger GC here, good VM's

00:49:34.820 --> 00:49:40.720
implementing these languages
generally ignore these calls,

00:49:40.720 --> 00:49:45.540
because it's been-- often in
our experience, it's been

00:49:45.540 --> 00:49:46.905
often at the wrong time.

00:49:46.905 --> 00:49:49.440
TODD TURNIDGE: And also, we've
got a different environment,

00:49:49.440 --> 00:49:51.200
because we have per-isolate
heaps.

00:49:51.200 --> 00:49:51.920
IVAN POSVA:

00:49:51.920 --> 00:49:54.840
TODD TURNIDGE: So in other
systems, you might have a

00:49:54.840 --> 00:49:58.580
stop-the-world GC, where it
actually affects all threads.

00:49:58.580 --> 00:50:00.980
Here, there's no need for any
other isolate to stop just

00:50:00.980 --> 00:50:02.990
because one isolate
needs the GC.

00:50:02.990 --> 00:50:05.480
Also, you should also expect
that that heap will be sort of

00:50:05.480 --> 00:50:09.710
proportional to the size of
work that isolate's doing.

00:50:09.710 --> 00:50:12.080
That isolate's heap might be a
lot easier to collect than the

00:50:12.080 --> 00:50:13.020
whole thing.

00:50:13.020 --> 00:50:16.300
So in terms of global hiccups,
you should expect fewer and

00:50:16.300 --> 00:50:17.555
where we hope they'd
be smaller.

00:50:17.555 --> 00:50:19.580
But I'm not a GC guy.

00:50:19.580 --> 00:50:25.170
IVAN POSVA: Currently, there's
a lot of work that I and Carl

00:50:25.170 --> 00:50:27.360
implemented.

00:50:27.360 --> 00:50:29.670
Maybe with help from [INAUDIBLE]
or somebody else.

00:50:29.670 --> 00:50:33.130
And in the GC, as Siva mentioned
already, that growth

00:50:33.130 --> 00:50:36.890
policy is completely
not implemented.

00:50:36.890 --> 00:50:40.360
So we just keep growing old
space until you reach its max.

00:50:40.360 --> 00:50:43.740
And then even though we know
that maybe there's not enough

00:50:43.740 --> 00:50:51.560
live to warrant the growth of
that into the next size, that

00:50:51.560 --> 00:50:55.865
will be more efficient to
collect now, stuff like that.

00:50:55.865 --> 00:50:58.630
SETH LADD: Well, I'm wondering
also if the tooling systems

00:50:58.630 --> 00:51:02.600
can also help developers with
large memory, high-performance

00:51:02.600 --> 00:51:03.540
applications as well?

00:51:03.540 --> 00:51:05.970
I know that developer tools
in Chrome give you some

00:51:05.970 --> 00:51:07.230
visibility into what's
going on.

00:51:07.230 --> 00:51:11.540
So the feeling here is not being
able to manually trigger

00:51:11.540 --> 00:51:12.650
is probably the right thing.

00:51:12.650 --> 00:51:15.272
But I think we could do things
at the tooling level to help

00:51:15.272 --> 00:51:16.096
people get visibility.

00:51:16.096 --> 00:51:20.340
IVAN POSVA: I think Carl has a
prototype where he kind of

00:51:20.340 --> 00:51:22.240
gives you a heap dump.

00:51:22.240 --> 00:51:23.360
What is live now?

00:51:23.360 --> 00:51:25.880
And where is it being
held from?

00:51:25.880 --> 00:51:28.535
And you should be able to
graphically inspect that here

00:51:28.535 --> 00:51:29.210
is this object.

00:51:29.210 --> 00:51:29.960
Why does it live?

00:51:29.960 --> 00:51:31.220
Who points to it?

00:51:31.220 --> 00:51:33.960
And so on.

00:51:33.960 --> 00:51:37.906
How far he is along with
that, I don't know.

00:51:37.906 --> 00:51:39.800
SETH LADD: Well, I've got
a couple more questions.

00:51:39.800 --> 00:51:42.990
Ladislav asks, again, "As far as
I know, the coming debugger

00:51:42.990 --> 00:51:45.860
communicates with the VM via
adjacent-based protocol,"

00:51:45.860 --> 00:51:47.380
which I think we covered
earlier.

00:51:47.380 --> 00:51:50.720
"My wild guess is that this must
bring some overhead, and

00:51:50.720 --> 00:51:53.190
that some binary format
like Protobufs

00:51:53.190 --> 00:51:54.900
might be more efficient.

00:51:54.900 --> 00:51:57.996
Is that the case or am I wrong?"
is what he asks.

00:51:57.996 --> 00:52:02.480
IVAN POSVA: It's probably JSON
or Protobufs or some binary

00:52:02.480 --> 00:52:05.420
format would be more compact.

00:52:05.420 --> 00:52:08.590
It might be easier to parse
on the other end.

00:52:12.160 --> 00:52:14.610
I don't think it's huge.

00:52:14.610 --> 00:52:16.980
And it's-- you're dealing
with a human.

00:52:16.980 --> 00:52:19.090
So the latency--

00:52:19.090 --> 00:52:20.320
TODD TURNIDGE: We don't
generally have debugger

00:52:20.320 --> 00:52:22.320
benchmarks that we
pay attention to.

00:52:22.320 --> 00:52:23.940
I guess probably people
who do GDB do.

00:52:23.940 --> 00:52:27.480
But generally, if you hit Next
and then, in a reasonable

00:52:27.480 --> 00:52:30.075
amount of time, you see the
Next statement come up.

00:52:30.075 --> 00:52:32.290
SIVA ANNAMALAI: But usually
it's not the wide protocol

00:52:32.290 --> 00:52:33.760
that dominates a Next.

00:52:33.760 --> 00:52:36.360
And there's a lot more things
going on behind the scenes for

00:52:36.360 --> 00:52:38.700
a implementation of Next.

00:52:38.700 --> 00:52:42.630
And the tradeoff here, that,
of course, JSON is a pretty

00:52:42.630 --> 00:52:45.520
popular format that a lot of
other tools might already be

00:52:45.520 --> 00:52:46.950
aware of using it.

00:52:46.950 --> 00:52:50.660
So the tradeoff is it's pretty
good in that aspect.

00:52:50.660 --> 00:52:54.020
So we get a protocol that a
lot of other people might

00:52:54.020 --> 00:52:56.840
already understand
as opposed to a

00:52:56.840 --> 00:52:58.073
proprietary binary format.

00:52:58.073 --> 00:53:01.640
IVAN POSVA: The human-readable
is always nice for debugging

00:53:01.640 --> 00:53:02.810
in these areas.

00:53:02.810 --> 00:53:03.902
SETH LADD: I think I agree.

00:53:03.902 --> 00:53:08.020
IVAN POSVA: I mean, debugging
the debugger protocol itself.

00:53:08.020 --> 00:53:12.230
That gets us probably there more
quickly than if we had to

00:53:12.230 --> 00:53:16.350
count bits on the wire when
we're figuring out, why

00:53:16.350 --> 00:53:17.410
doesn't this work?

00:53:17.410 --> 00:53:19.360
SETH LADD: And just like most
things that we're working on

00:53:19.360 --> 00:53:20.610
now, this is all early days.

00:53:20.610 --> 00:53:22.110
And so who knows what the
future will bring.

00:53:22.110 --> 00:53:23.240
But I agree.

00:53:23.240 --> 00:53:26.930
Less moving parts, less unique
capabilities, more

00:53:26.930 --> 00:53:30.600
human-readable at this stage,
probably better.

00:53:30.600 --> 00:53:30.830
OK.

00:53:30.830 --> 00:53:31.070
Great.

00:53:31.070 --> 00:53:32.020
Well, last question.

00:53:32.020 --> 00:53:34.430
Something a little
bit different.

00:53:34.430 --> 00:53:36.840
"What types of things would
game developers need to be

00:53:36.840 --> 00:53:39.515
aware of at the VM level to
write high-performance code?"

00:53:39.515 --> 00:53:42.790
And to elaborate more, we have
the question asker here on the

00:53:42.790 --> 00:53:45.710
other side of the camera,
Colt, who is a very

00:53:45.710 --> 00:53:46.900
experienced game developer.

00:53:46.900 --> 00:53:49.460
And I know he's been working a
lot building web-based games.

00:53:49.460 --> 00:53:51.970
So is there something that
you are particularly--

00:53:51.970 --> 00:53:53.660
like a angle on that question?

00:53:53.660 --> 00:53:55.570
COLT MCANLIS: Just the
larger deep-dive.

00:53:55.570 --> 00:53:58.670
When game developers are writing
HTML5 code, they have

00:53:58.670 --> 00:54:01.480
to have the mental model of how
JavaScript is working and

00:54:01.480 --> 00:54:03.900
then the secondary model of what
that actually turns into

00:54:03.900 --> 00:54:05.050
when you have sat
on the fence.

00:54:05.050 --> 00:54:07.230
And I didn't know if there was
anything you guys have done

00:54:07.230 --> 00:54:10.790
already with performance or
profiling that you may want to

00:54:10.790 --> 00:54:12.977
think about, or be aware of,
or at least notify the

00:54:12.977 --> 00:54:15.200
community of that are things
that they should start

00:54:15.200 --> 00:54:18.310
thinking about when trying to
write games that run at 60

00:54:18.310 --> 00:54:21.285
Hertz with full graphics, and
sound running, and networking,

00:54:21.285 --> 00:54:21.620
and everything.

00:54:21.620 --> 00:54:22.530
IVAN POSVA: OK.

00:54:22.530 --> 00:54:25.860
So I think I would start
off with, don't

00:54:25.860 --> 00:54:27.110
mix ints and doubles.

00:54:29.650 --> 00:54:30.250
Excuse me.

00:54:30.250 --> 00:54:32.590
In JavaScript, you don't
necessarily have that problem,

00:54:32.590 --> 00:54:35.485
because it's just kind
of a big mishmash

00:54:35.485 --> 00:54:36.735
in the number hierarchy.

00:54:40.070 --> 00:54:44.990
For us, it's really helpful if
you say, I'm going to use this

00:54:44.990 --> 00:54:46.910
as a double.

00:54:46.910 --> 00:54:50.345
Define your constants as 1.0
instead of 1, stuff like that.

00:54:50.345 --> 00:54:52.260
That helps dramatically.

00:54:52.260 --> 00:54:56.200
Some of the type feedback I
think will make this easier to

00:54:56.200 --> 00:55:00.685
deal with in the optimizing
compiler.

00:55:00.685 --> 00:55:02.990
SETH LADD: What about games
with a lot of matrix math?

00:55:02.990 --> 00:55:03.926
COLT MCANLIS: Yeah.

00:55:03.926 --> 00:55:05.798
Lots of linear optimization
and range reversal.

00:55:05.798 --> 00:55:09.430
MALE SPEAKER 1: I think it's
important not to deduct

00:55:09.430 --> 00:55:11.580
certain performance
characteristics from where we

00:55:11.580 --> 00:55:13.370
are now, because where
we are going is

00:55:13.370 --> 00:55:14.300
going to be quite different.

00:55:14.300 --> 00:55:17.158
If you figure out, oh, this,
if I do it that way, it's

00:55:17.158 --> 00:55:18.560
going to be much faster
than the other way.

00:55:18.560 --> 00:55:20.860
It doesn't mean it's going
to stay that way.

00:55:20.860 --> 00:55:22.760
So we are trying to improve.

00:55:22.760 --> 00:55:29.300
We are focused on improving the
normal code, which means,

00:55:29.300 --> 00:55:32.035
bright clean code,
simple code.

00:55:32.035 --> 00:55:34.660
Don't go, oh, I have to code
this and this and that.

00:55:34.660 --> 00:55:36.457
And then I'm going to
get faster because I

00:55:36.457 --> 00:55:37.260
made it right now.

00:55:37.260 --> 00:55:39.650
That's even not going
to be the future.

00:55:39.650 --> 00:55:42.580
Simple code, clean code
should work very good.

00:55:42.580 --> 00:55:43.030
IVAN POSVA: Yeah.

00:55:43.030 --> 00:55:46.320
And if it doesn't, file a bug.

00:55:46.320 --> 00:55:50.530
The other thing is, we already
have the whole native arrays

00:55:50.530 --> 00:55:53.180
for floats, and then
they're typed.

00:55:53.180 --> 00:55:56.570
So you can really say,
I want the float

00:55:56.570 --> 00:56:00.380
32 or float 64 arrays.

00:56:00.380 --> 00:56:03.100
You can have them external if
you want to, so that they're

00:56:03.100 --> 00:56:07.320
shared with a graphics card
and so on from a web

00:56:07.320 --> 00:56:09.040
developer's perspective.

00:56:09.040 --> 00:56:12.210
Unfortunately, I think they're
not exactly hooked into

00:56:12.210 --> 00:56:14.660
Dartium yet.

00:56:14.660 --> 00:56:17.736
So I think that is
the next step.

00:56:17.736 --> 00:56:20.450
So in the VM, they're
supported.

00:56:20.450 --> 00:56:25.225
But if you ask for a type array
from Dartium, you get a

00:56:25.225 --> 00:56:26.490
different copy.

00:56:26.490 --> 00:56:28.100
MALE SPEAKER 1: And I hope in
the future, you'll be able

00:56:28.100 --> 00:56:32.630
soon to get a bit more precise
set of documentation for the

00:56:32.630 --> 00:56:36.040
performance, but now it's
way too early for that.

00:56:36.040 --> 00:56:38.710
SETH LADD: I think we have Box2D
wired into some of our

00:56:38.710 --> 00:56:39.530
performance metrics.

00:56:39.530 --> 00:56:41.750
So that's something used by a
lot of web developers, and

00:56:41.750 --> 00:56:42.220
that's good.

00:56:42.220 --> 00:56:46.150
I think it's-- as long as it's
on that radar, that's great.

00:56:46.150 --> 00:56:47.780
Well, I think that's all
the time we have today.

00:56:47.780 --> 00:56:50.075
So I want to thank everyone for
watching and certainly all

00:56:50.075 --> 00:56:50.770
your questions.

00:56:50.770 --> 00:56:53.300
And then, of course, our
engineers from the Dart VM

00:56:53.300 --> 00:56:54.810
team, thank you very much
for spending your

00:56:54.810 --> 00:56:56.300
time with us today.

00:56:56.300 --> 00:56:59.135
This is all going to be recorded
and posted to our

00:56:59.135 --> 00:57:01.150
YouTube channel, so you
can catch up there.

00:57:01.150 --> 00:57:05.000
And please do follow Google
Chrome Developers and

00:57:05.000 --> 00:57:08.210
Dart-structured web apps in
Google+ for more Hangouts like

00:57:08.210 --> 00:57:11.530
this, and where we post news
and announcements, and

00:57:11.530 --> 00:57:13.940
interact with the community
every day.

00:57:13.940 --> 00:57:16.110
So thanks everyone for their
time, and we'll see you next

00:57:16.110 --> 00:57:17.360
time on Dartisans.

