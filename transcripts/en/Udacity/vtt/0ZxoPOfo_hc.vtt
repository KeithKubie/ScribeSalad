WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.339
Okay, so the second half of this unit concentrates on sort.

00:00:03.339 --> 00:00:08.077
Sorting is a fundamental operation, and understanding how we might approach this problem in

00:00:08.077 --> 00:00:13.618
the parallel world gives a lot of insight as to what works well and what doesn't work well on GPUs.

00:00:13.618 --> 00:00:15.817
There's a lot of neat algorithms in sorting,

00:00:15.817 --> 00:00:18.321
and I hope the rest of the unit gives you some new ideas about

00:00:18.321 --> 00:00:22.133
how to approach the design of efficient parallel algorithms.

00:00:22.133 --> 00:00:26.596
Now, sort is a challenging problem on GPUs for several reasons.

00:00:26.596 --> 00:00:32.843
The first is that most sort algorithms are serial algorithms, or at least, usually expressed in a serial fashion,

00:00:32.843 --> 00:00:35.473
particularly those you might have learned in an algorithms class.

00:00:35.473 --> 00:00:39.976
So all those nice algorithms that you learned in school are not necessarily applicable here,

00:00:39.976 --> 00:00:42.876
and we'll see this in a bit. The second is that for performance reasons,

00:00:42.876 --> 00:00:47.651
we prefer to look at algorithms, parallel algorithms that coalesce memory axises and have little

00:00:47.651 --> 00:00:51.350
branch divergents among threads, and particularly that are able to keep the

00:00:51.350 --> 00:00:54.899
hardware busy by keeping lots of threads busy at the same time.

00:00:54.899 --> 00:00:59.329
So the sort of algorithms that you might have learned in an algorithm course tend to be moving

00:00:59.329 --> 00:01:02.838
around little bits of memory at a time and they have very branchy code,

00:01:02.838 --> 00:01:07.636
and they're not often very parallel, so we'd like to take a look at algorithms that

00:01:07.636 --> 00:01:12.075
have the other characteristics, that can keep the hardware busy, that do limit branch divergence,

00:01:12.075 --> 00:01:14.508
that do prefer coalesced memory accesses.

00:01:14.508 --> 00:01:18.949
What we're going to do is look at some classic sorting algorithms and discuss how they

00:01:18.949 --> 00:01:21.381
might map onto a parallel world.

00:01:21.381 --> 00:01:26.384
We'll start with one of the simplest algorithms and one that maps nicely to a parallel implementation.

00:01:26.384 --> 00:01:31.858
Odd-even sort, also known as brick sort. If you're familiar with the serial algorithm called bubble sort,

00:01:31.858 --> 00:01:34.361
this is the parallel version of bubble sort.

00:01:34.361 --> 00:01:38.164
So, we're going to start by putting all of our elements to sort in a row,

00:01:38.164 --> 00:01:43.303
And then we're going to mark all the even elements as black and all the odd elements as red.

00:01:43.303 --> 00:01:48.476
In an odd-even sort, in the first phase, each red element looks down the line to the left

00:01:48.476 --> 00:01:53.139
toward the left end and pairs up with the black elements it's facing.

00:01:53.139 --> 00:01:56.947
Now if that pair is out of order, they swap places and colors as well.

00:01:56.947 --> 00:02:01.939
Otherwise, they stay in the same places. Now, every red element turns around, faces to its right,

00:02:01.939 --> 00:02:06.824
and pairs up with the black element in the other direction. Again, they swap if they're out of order.

00:02:06.824 --> 00:02:10.526
So we continue until the sequence is sorted. So let's try an example.

00:02:10.526 --> 00:02:14.829
So just to show this with some real numbers, we'll try a sample with these five numbers.

00:02:14.829 --> 00:02:17.068
We start by pairing them up, starting at the left,

00:02:17.068 --> 00:02:19.916
and we swap each pair if they're out of order.

00:02:19.916 --> 00:02:23.376
Then we pair them with the opposite polarity and continue the process.

00:02:23.376 --> 00:02:25.914
We return to pairing them the way we did in the first step

00:02:25.914 --> 00:02:29.918
and continue to pair them one way then the other way, then one way then the other way,

00:02:29.918 --> 00:02:32.552
until we finally conclude with a sorted sequence.

00:02:32.552 --> 00:02:35.253
So it's very important that we understand how to measure

00:02:35.253 --> 00:02:40.056
the step and work complexity of these algorithms, because that's often the dominant factor in their run time.

00:02:40.056 --> 00:02:44.227
So, for this algorithm, what is the step complexity of this algorithm?

00:02:44.227 --> 00:02:48.999
Order of 1, log n, n, n log n, or n squared, the number of steps.

00:02:48.999 --> 00:02:52.839
And what is the total amount of work that we need to do with the same choices?

00:02:52.839 --> 00:02:54.000
Please check your choice.

