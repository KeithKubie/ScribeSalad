WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.722
It's also worth noting that different math instructions take different amounts of time.

00:00:03.722 --> 00:00:06.985
And this topic gets maybe half a ninja.

00:00:06.985 --> 00:00:12.348
You can go really deep understanding the latencies involved in different math optimizations,

00:00:12.348 --> 00:00:15.628
but there's a few general principles that probably everybody should keep in mind.

00:00:15.628 --> 00:00:19.954
So the first to keep in mind is use double precision only when you really mean it.

00:00:19.954 --> 00:00:23.100
64-bit math is slower than 32-bit math,

00:00:23.100 --> 00:00:28.809
but it's easy to forget that floating point literals like 2.5 here are interpreted as fp64

00:00:28.809 --> 00:00:30.999
unless you add the f suffix.

00:00:30.999 --> 00:00:35.407
Therefore, this statement on the left will take longer to execute than this one on the right.

00:00:35.407 --> 00:00:38.615
It's a subtle distinction, and clearly sometimes you need to use double precision,

00:00:38.615 --> 00:00:40.550
but if you're concerned about performance

00:00:40.550 --> 00:00:43.148
and you're trying to squeeze the last few percent out of your kernels,

00:00:43.148 --> 00:00:46.329
only use it when you're absolutely intending to use it.

00:00:46.329 --> 00:00:51.394
A second math-oriented optimization is to use intrinsics whenever possible for common operations.

00:00:51.394 --> 00:00:54.813
CUDA supports special versions of many common math operations,

00:00:54.813 --> 00:00:59.685
like sine and cosine and exponent, that are called intrinsics.

00:00:59.685 --> 00:01:04.811
These built-in functions achieve 2 to 3 bits less precision than their counterparts in math.h,

00:01:04.811 --> 00:01:06.936
but they are much faster.

00:01:06.936 --> 00:01:12.009
There are also compiler flags for fast square root, fast division, 0D norms and so forth.

00:01:12.009 --> 00:01:14.338
And you can see the programming guide for more detail.

