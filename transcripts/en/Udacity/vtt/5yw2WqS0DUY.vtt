WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.264
So we have this chicken and the egg
problem and those of you, I'm assuming,

00:00:03.264 --> 00:00:04.386
most of you are familiar,

00:00:04.386 --> 00:00:06.732
this is actually referred
to as k-means clustering.

00:00:06.732 --> 00:00:10.010
It solves the chicken and the egg
problem by smashing them together,

00:00:10.010 --> 00:00:12.781
which could be a pretty nasty picture,
but essentially,

00:00:12.781 --> 00:00:14.950
it's just an iterative algorithm.

00:00:14.950 --> 00:00:16.129
What you do is, just as it is says here.

00:00:16.129 --> 00:00:20.969
And we'll take an illustration in a
minute, you randomly, yes just randomly,

00:00:20.969 --> 00:00:22.689
pick some cluster centers.

00:00:22.689 --> 00:00:25.510
You might try to be a little smart
about how you do that or, or not.

00:00:25.510 --> 00:00:27.403
I find it easier to be not smart.

00:00:27.403 --> 00:00:29.360
And then, once you have the centers,

00:00:29.360 --> 00:00:32.429
we know which points should be
assigned to those clusters.

00:00:32.429 --> 00:00:35.493
Once we've assigned to the clusters,
that's step two,

00:00:35.493 --> 00:00:39.619
given the points in clusters, step
three, we can re-assign the center, and

00:00:39.619 --> 00:00:42.900
you set that, you set the new
cluster center to be that.

00:00:42.900 --> 00:00:45.980
And step four is, well if any
of the cluster centers move, and

00:00:45.980 --> 00:00:49.655
the only reason they would have moved
is because you changed the assignments,

00:00:49.655 --> 00:00:50.856
you go back to step two.

00:00:50.856 --> 00:00:54.880
And this is classical k-means and
I assume most of you have seen that.

00:00:54.880 --> 00:00:56.993
But, just showing a few
in the contest of,

00:00:56.993 --> 00:01:00.931
context of segmentation here's a nice
little example from Andrew Moore,

00:01:00.931 --> 00:01:03.980
recently appointed the Dean
at Carnegie Melon.

00:01:03.980 --> 00:01:05.180
Congratulations Andrew.

00:01:05.180 --> 00:01:07.212
So here we have k-means, right?

00:01:07.212 --> 00:01:09.720
So we've got a bunch of points.

00:01:09.720 --> 00:01:12.770
Now we know where we think
the cluster should be, but

00:01:12.770 --> 00:01:13.790
that's because we're smart.

00:01:13.790 --> 00:01:15.360
A computer's not so smart.

00:01:15.360 --> 00:01:16.890
We picked some random centers,
so there they are.

00:01:16.890 --> 00:01:21.000
Not a particularly good
choice of initial collection.

00:01:21.000 --> 00:01:24.090
We then partitioned the space up, right?

00:01:24.090 --> 00:01:27.383
So those of you from computer
science recognize this diagram.

00:01:27.383 --> 00:01:32.469
This is the, the fracturing of the,
of the space such that this line says

00:01:32.469 --> 00:01:38.220
that everything here is closest to
that point, more than any other point.

00:01:38.220 --> 00:01:41.820
And so once we have those assignments,
what we can do is,

00:01:41.820 --> 00:01:45.220
we move the centers to be at the center

00:01:45.220 --> 00:01:47.870
of the points that were assigned to
that cluster, and then we iterate.

00:01:47.870 --> 00:01:49.425
All right?

00:01:49.425 --> 00:01:51.780
And we repeat that until it terminates.

