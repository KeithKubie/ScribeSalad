WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.912
[MUSIC PLAYING]

00:00:05.537 --> 00:00:07.620
EITAN MARDER-EPPSTEIN:
How's everyone doing today?

00:00:07.620 --> 00:00:08.350
Yeah?

00:00:08.350 --> 00:00:09.430
Good.

00:00:09.430 --> 00:00:10.690
All right.

00:00:10.690 --> 00:00:15.010
Well, welcome to Google I/O. My
name is Eitan Marder-Eppstein.

00:00:15.010 --> 00:00:18.530
And I am an engineering
manager here at Google.

00:00:18.530 --> 00:00:20.620
And I work on augmented reality.

00:00:20.620 --> 00:00:24.161
And I'm going to take a few
polls throughout this talk.

00:00:24.161 --> 00:00:25.660
And the first one
is how many of you

00:00:25.660 --> 00:00:29.300
are familiar with augmented
reality in general?

00:00:29.300 --> 00:00:30.300
OK.

00:00:30.300 --> 00:00:33.690
Every time I give a talk
like this, more hands go up,

00:00:33.690 --> 00:00:35.770
which is a really,
really great thing.

00:00:35.770 --> 00:00:37.200
And today, what
I'm going to do is

00:00:37.200 --> 00:00:40.410
give a quick refresher about
augmented reality for those

00:00:40.410 --> 00:00:43.110
of you who maybe aren't
quite as familiar with it,

00:00:43.110 --> 00:00:46.120
and especially how augmented
reality relates to smartphones,

00:00:46.120 --> 00:00:47.953
which is something that
we're really, really

00:00:47.953 --> 00:00:49.170
excited about here at Google.

00:00:49.170 --> 00:00:51.295
And then I'm going to talk
about some of the things

00:00:51.295 --> 00:00:53.550
that we're doing at
Google to improve

00:00:53.550 --> 00:00:57.450
our platform for augmented
reality and the capabilities

00:00:57.450 --> 00:00:59.890
that we give to some
of these devices.

00:00:59.890 --> 00:01:00.390
All right.

00:01:00.390 --> 00:01:01.737
So I need my clicker.

00:01:01.737 --> 00:01:03.570
So I'm actually going
to go over here to get

00:01:03.570 --> 00:01:05.370
the presentation started.

00:01:05.370 --> 00:01:07.180
But off we go.

00:01:07.180 --> 00:01:10.440
So smartphone AR stems
from this observation

00:01:10.440 --> 00:01:12.960
that over the last
decade, our phones

00:01:12.960 --> 00:01:15.310
have gotten immensely
more powerful,

00:01:15.310 --> 00:01:18.330
CPUs and GPUs have
improved a lot.

00:01:18.330 --> 00:01:21.270
But the ability of phones
to see and understand

00:01:21.270 --> 00:01:23.820
their environments, and
really make sense of the world

00:01:23.820 --> 00:01:26.760
around them, until
very recently was

00:01:26.760 --> 00:01:29.050
largely unchanged and limited.

00:01:29.050 --> 00:01:31.720
So if you pointed your
phone at this table,

00:01:31.720 --> 00:01:33.900
it would allow you to take
a picture of the table

00:01:33.900 --> 00:01:36.900
or even a video of your friend
climbing over the table.

00:01:36.900 --> 00:01:39.480
But your phone wouldn't
really have an understanding

00:01:39.480 --> 00:01:42.360
of the geometry of the
table, of its position

00:01:42.360 --> 00:01:45.210
relative to the table as
it moves through space.

00:01:45.210 --> 00:01:49.890
And so what augmented reality
seeks to do on smartphones

00:01:49.890 --> 00:01:55.170
is to take all of this amazing
advancement in computing power

00:01:55.170 --> 00:01:58.410
and leverage it to bring new
capabilities to your phone,

00:01:58.410 --> 00:02:01.170
and to take your phone from
beyond just the screen,

00:02:01.170 --> 00:02:04.710
beyond its own little box,
to expand it to understanding

00:02:04.710 --> 00:02:05.850
the world around it.

00:02:05.850 --> 00:02:08.320
So now, when my phone
looks at this table,

00:02:08.320 --> 00:02:10.410
it can see that there's
a surface there,

00:02:10.410 --> 00:02:12.060
that there are
chairs next to it.

00:02:12.060 --> 00:02:13.650
And as I move through
the environment,

00:02:13.650 --> 00:02:16.860
my phone can actually track
its position as it moves.

00:02:16.860 --> 00:02:19.200
And we think at Google
that augmented reality

00:02:19.200 --> 00:02:20.452
is really exciting.

00:02:20.452 --> 00:02:22.410
And we've been excited
to see some of the stuff

00:02:22.410 --> 00:02:25.050
that you've built. And
we've categorized it

00:02:25.050 --> 00:02:28.050
into two main buckets
where we think

00:02:28.050 --> 00:02:31.120
augmented reality can be really,
really great for applications.

00:02:31.120 --> 00:02:35.040
So the first bucket is we think
that augmented reality can

00:02:35.040 --> 00:02:36.930
be useful on smartphones.

00:02:36.930 --> 00:02:39.452
So recently, I was
remodeling my kitchen.

00:02:39.452 --> 00:02:41.160
All right, another
poll-- how many of you

00:02:41.160 --> 00:02:43.770
have remodeled
anything in a house?

00:02:43.770 --> 00:02:44.520
All right.

00:02:44.520 --> 00:02:48.660
So if you've done that,
you know that measurements

00:02:48.660 --> 00:02:50.100
is a real pain.

00:02:50.100 --> 00:02:52.510
And what I needed to do was
measure for a backsplash.

00:02:52.510 --> 00:02:55.320
We were buying some subway
tile for our kitchen.

00:02:55.320 --> 00:02:58.230
And I, instead of taking
a tape measure out,

00:02:58.230 --> 00:03:01.590
actually pulled out my
phone, went to my counter,

00:03:01.590 --> 00:03:05.400
and measured from point A to
B to C. And I did all of that

00:03:05.400 --> 00:03:07.290
without moving any
of my appliances

00:03:07.290 --> 00:03:09.540
where I would have normally
had to move in order

00:03:09.540 --> 00:03:11.940
to get an accurate measurement
with my tape measure.

00:03:11.940 --> 00:03:14.040
So AR can be useful
in that way, just

00:03:14.040 --> 00:03:16.560
from providing a better
geometric understanding

00:03:16.560 --> 00:03:17.810
about your environment.

00:03:17.810 --> 00:03:21.000
AR can also be useful for
shopping applications.

00:03:21.000 --> 00:03:25.637
So recently, we had some
very old chairs at my house.

00:03:25.637 --> 00:03:27.720
And my partner and I were
looking to replace them,

00:03:27.720 --> 00:03:29.670
kind of like these chairs here.

00:03:29.670 --> 00:03:32.010
And we were getting
into a debate over which

00:03:32.010 --> 00:03:33.750
chairs we liked more.

00:03:33.750 --> 00:03:35.340
And so with
augmented reality, we

00:03:35.340 --> 00:03:37.680
were able to take a
3D model of a chair,

00:03:37.680 --> 00:03:40.590
place it in the environment,
see the exact size and scale

00:03:40.590 --> 00:03:41.520
and color.

00:03:41.520 --> 00:03:43.590
And we could have our
arguments about inevitably

00:03:43.590 --> 00:03:45.720
what kind of chair
we would have at home

00:03:45.720 --> 00:03:48.270
rather than exposing
everyone to it at the store,

00:03:48.270 --> 00:03:50.850
and be more targeted about
how we made our purchase

00:03:50.850 --> 00:03:54.030
and even buy this furniture
online and feel much more

00:03:54.030 --> 00:03:55.540
comfortable with it.

00:03:55.540 --> 00:03:57.750
So that's how AR can
just provide more utility

00:03:57.750 --> 00:03:59.140
in your daily life.

00:03:59.140 --> 00:04:01.770
But AR can also be fun.

00:04:01.770 --> 00:04:05.130
So imagine a character
running across the floor,

00:04:05.130 --> 00:04:08.280
jumping onto this chair,
and jumping onto this table,

00:04:08.280 --> 00:04:10.410
or me sitting in
one of these chairs

00:04:10.410 --> 00:04:12.810
and having the floor
drop out from under me

00:04:12.810 --> 00:04:15.330
to create an ice fishing game.

00:04:15.330 --> 00:04:17.079
Ice fishing sounds
a little bit boring,

00:04:17.079 --> 00:04:18.779
but I can tell you
that in this game,

00:04:18.779 --> 00:04:20.690
it's actually a lot of fun.

00:04:20.690 --> 00:04:24.030
And AR can also be used
for creative expression.

00:04:24.030 --> 00:04:29.480
So here, now in your pocket,
you have a lot of ability

00:04:29.480 --> 00:04:31.700
to go out and create
new things that

00:04:31.700 --> 00:04:36.510
were previously only capable
to be created by professionals.

00:04:36.510 --> 00:04:38.960
So you can generate
computer-generated content

00:04:38.960 --> 00:04:40.490
on the go, on the fly.

00:04:40.490 --> 00:04:42.440
You can take your
favorite character

00:04:42.440 --> 00:04:44.180
and put them into
your scene, and have

00:04:44.180 --> 00:04:45.920
your friend pose next to them.

00:04:45.920 --> 00:04:49.220
Or you can take pizza or hot
dogs or your favorite food

00:04:49.220 --> 00:04:51.290
items, as we showed
here, and put them

00:04:51.290 --> 00:04:52.760
on the table in front of you.

00:04:52.760 --> 00:04:56.690
But now, you have this amazing
video editing capability

00:04:56.690 --> 00:04:57.770
in your pocket.

00:04:57.770 --> 00:05:00.290
And for those of you who
have seen our AR Stickers

00:05:00.290 --> 00:05:02.047
application on the
Google Pixel phone,

00:05:02.047 --> 00:05:03.380
you know what I'm talking about.

00:05:03.380 --> 00:05:05.338
And for those who haven't,
please check it out.

00:05:05.338 --> 00:05:07.460
It's really, really cool
to have this creation

00:05:07.460 --> 00:05:09.681
power in your pocket.

00:05:09.681 --> 00:05:10.180
All right.

00:05:10.180 --> 00:05:11.950
So that's great.

00:05:11.950 --> 00:05:13.210
AR can be useful.

00:05:13.210 --> 00:05:14.410
AR can be fun.

00:05:14.410 --> 00:05:17.530
But how do you actually
build applications for AR?

00:05:17.530 --> 00:05:19.360
How do you get
involved as developers?

00:05:19.360 --> 00:05:21.430
This is a developer conference.

00:05:21.430 --> 00:05:25.555
So how many of you are familiar
with ARCore, when I say ARCore?

00:05:25.555 --> 00:05:27.550
All right, about half of you.

00:05:27.550 --> 00:05:30.670
So ARCore is Google's
development platform

00:05:30.670 --> 00:05:32.260
for augmented reality.

00:05:32.260 --> 00:05:35.890
We want to make it easy for
you to build applications that

00:05:35.890 --> 00:05:38.470
take advantage of
these new capabilities

00:05:38.470 --> 00:05:41.020
that phones provide, of
the ability of phones

00:05:41.020 --> 00:05:43.060
to see and understand
their environments,

00:05:43.060 --> 00:05:44.890
and to build applications
that actually

00:05:44.890 --> 00:05:47.350
react to this understanding.

00:05:47.350 --> 00:05:49.870
And ARCore was launched
a few months ago.

00:05:49.870 --> 00:05:52.450
And it provides three
main capabilities

00:05:52.450 --> 00:05:54.230
to allow you to do this.

00:05:54.230 --> 00:05:57.460
The first is something
we call motion tracking.

00:05:57.460 --> 00:06:00.730
So here, consider the example
of taking the Scarecrow

00:06:00.730 --> 00:06:02.530
from "The Wizard
of Oz" and wanting

00:06:02.530 --> 00:06:04.900
to place the Scarecrow
at a taco stand

00:06:04.900 --> 00:06:07.120
and make it seem like he's
waiting in line for tacos

00:06:07.120 --> 00:06:09.620
because everyone loves tacos.

00:06:09.620 --> 00:06:14.080
So here, if I look at the
Scarecrow with my phone,

00:06:14.080 --> 00:06:16.860
ARCore actually
understands its position

00:06:16.860 --> 00:06:20.010
relative to a virtual object
that I've placed in space.

00:06:20.010 --> 00:06:22.560
So as I move a meter
forward, the phone

00:06:22.560 --> 00:06:25.480
knows that I've moved a
meter in this direction.

00:06:25.480 --> 00:06:27.750
And as I turn left, the
phone also knows that.

00:06:27.750 --> 00:06:31.350
It's able to track its motion
as I move through space.

00:06:31.350 --> 00:06:33.540
And now, if I combine
that with my desire

00:06:33.540 --> 00:06:36.450
to place the Scarecrow
a meter in front of me,

00:06:36.450 --> 00:06:38.730
I can put the
Scarecrow right here.

00:06:38.730 --> 00:06:41.130
And as I move my
phone around, I can

00:06:41.130 --> 00:06:45.870
change where I'm rendering the
Scarecrow in the virtual scene

00:06:45.870 --> 00:06:48.510
to match my physical
environment.

00:06:48.510 --> 00:06:52.980
So that allows you to
register virtual objects

00:06:52.980 --> 00:06:56.700
to your physical scene in a
very natural and intuitive way.

00:06:56.700 --> 00:06:59.070
The second capability
that ARCore provides

00:06:59.070 --> 00:07:01.150
is something called
lighting estimation.

00:07:01.150 --> 00:07:03.270
So here, continuing our
"Wizard of Oz" theme,

00:07:03.270 --> 00:07:05.040
we've got the Cowardly Lion.

00:07:05.040 --> 00:07:06.720
And when you turn
off the lights,

00:07:06.720 --> 00:07:10.110
say we want to make the lion
afraid because it's cowardly.

00:07:10.110 --> 00:07:13.020
So here, ARCore is
looking at the camera feed

00:07:13.020 --> 00:07:15.420
and it is estimating
the real world

00:07:15.420 --> 00:07:17.700
lighting of your environment.

00:07:17.700 --> 00:07:21.030
And with that estimate,
ARCore can now

00:07:21.030 --> 00:07:23.700
light characters in
a realistic fashion,

00:07:23.700 --> 00:07:25.980
helping you to build a more
immersive experience that

00:07:25.980 --> 00:07:28.410
looks natural because the
virtual objects that you're

00:07:28.410 --> 00:07:30.400
putting in your
scene look correct.

00:07:30.400 --> 00:07:33.120
So you can see the
tone on the lion change

00:07:33.120 --> 00:07:34.860
when it goes from light to dark.

00:07:34.860 --> 00:07:36.900
And you can even
script interactions

00:07:36.900 --> 00:07:38.100
for your characters.

00:07:38.100 --> 00:07:42.330
In this case, making the lion
afraid when the lights go off.

00:07:42.330 --> 00:07:45.060
And the third capability
that ARCore provides

00:07:45.060 --> 00:07:47.080
is environment understanding.

00:07:47.080 --> 00:07:49.920
So here, as ARCore is
moving around the world

00:07:49.920 --> 00:07:52.380
and it's tracking its
motion and it's also

00:07:52.380 --> 00:07:54.390
estimating the lighting
of the environment,

00:07:54.390 --> 00:07:57.240
ARCore is also trying
to recognize surfaces.

00:07:57.240 --> 00:07:59.580
So ARCore might
recognize this plane

00:07:59.580 --> 00:08:03.000
below me which is the
ground, or this surface here

00:08:03.000 --> 00:08:05.160
which is the table,
or even maybe

00:08:05.160 --> 00:08:07.320
this vertical surface behind me.

00:08:07.320 --> 00:08:09.210
And it allows you
to place objects

00:08:09.210 --> 00:08:11.140
that are grounded to reality.

00:08:11.140 --> 00:08:13.020
So if we want to place
the Android character

00:08:13.020 --> 00:08:16.110
on this table, I can
detect the surface

00:08:16.110 --> 00:08:19.290
and actually place my virtual
character on a physical object

00:08:19.290 --> 00:08:20.350
in the world.

00:08:20.350 --> 00:08:23.280
So those are three
capabilities-- motion tracking,

00:08:23.280 --> 00:08:26.310
lighting estimation, and
environment understanding.

00:08:26.310 --> 00:08:28.170
And when you combine
them together,

00:08:28.170 --> 00:08:30.090
it allows you to build
these experiences that

00:08:30.090 --> 00:08:32.640
were previously
impossible, that bring

00:08:32.640 --> 00:08:35.669
the virtual and
physical worlds together

00:08:35.669 --> 00:08:38.280
and meld them into
a new reality that

00:08:38.280 --> 00:08:41.370
enables people to see and
experience your application

00:08:41.370 --> 00:08:43.260
in a new and different light.

00:08:43.260 --> 00:08:46.530
And we're really excited
about this and the opportunity

00:08:46.530 --> 00:08:50.310
to bring apps to our
ecosystem for it.

00:08:50.310 --> 00:08:53.250
And so we have
worked really, really

00:08:53.250 --> 00:08:57.240
hard to expose
support for ARCare

00:08:57.240 --> 00:08:59.590
on as many devices as possible.

00:08:59.590 --> 00:09:03.870
And with help from our partners
in our Android OEM ecosystem,

00:09:03.870 --> 00:09:08.190
today ARCore is supported
on over 100 million devices.

00:09:08.190 --> 00:09:12.060
And we're working to increase
that number every single day.

00:09:12.060 --> 00:09:14.790
We believe that
augmented reality

00:09:14.790 --> 00:09:19.200
is a next shift in computing,
and that soon everyone

00:09:19.200 --> 00:09:23.440
will take for granted that
this power is in their devices.

00:09:23.440 --> 00:09:25.000
So that's our scale.

00:09:25.000 --> 00:09:27.090
But we're also
interested in scaling

00:09:27.090 --> 00:09:29.280
the capabilities of ARCore.

00:09:29.280 --> 00:09:32.640
We want to teach ARCore to do
new and interesting things.

00:09:32.640 --> 00:09:35.890
And that's what the rest of
the talk is going to be about.

00:09:35.890 --> 00:09:38.850
So today, we're announcing
some new things in ARCore.

00:09:38.850 --> 00:09:41.440
And they fall broadly
into two categories.

00:09:41.440 --> 00:09:44.040
The first is we're announcing
some new capabilities

00:09:44.040 --> 00:09:46.950
for ARCore, improving
what these devices can do.

00:09:46.950 --> 00:09:49.800
And those are Augmented
Images and Cloud Anchors.

00:09:49.800 --> 00:09:52.570
And we'll talk about
them in the talk today.

00:09:52.570 --> 00:09:56.550
And then we're also announcing
some new tools for ARCore.

00:09:56.550 --> 00:09:59.280
One new tool is how you
can use augmented reality

00:09:59.280 --> 00:10:01.800
on the web, which we
think is really exciting.

00:10:01.800 --> 00:10:05.790
And you can check a talk to
that later today at 12:30 PM.

00:10:05.790 --> 00:10:08.640
And another is how
you can more easily

00:10:08.640 --> 00:10:13.410
write 3D applications for
Android and AR specifically.

00:10:13.410 --> 00:10:15.420
We've introduced our
scene form library,

00:10:15.420 --> 00:10:18.540
which is a helper library
for 3D rendering on Android.

00:10:18.540 --> 00:10:22.350
And we encourage you to check
out that talk at 5:30 today.

00:10:22.350 --> 00:10:24.861
So enough about the preamble.

00:10:24.861 --> 00:10:26.610
We're now going to get
into the meat of it

00:10:26.610 --> 00:10:28.950
and talk about
what's new in ARCore.

00:10:28.950 --> 00:10:31.520
And I'm going to kick it off
with our first feature, which

00:10:31.520 --> 00:10:33.420
are augmented images.

00:10:33.420 --> 00:10:36.180
So augmented images
stem from your feedback.

00:10:36.180 --> 00:10:40.890
We've heard you as you develop
augmented reality applications,

00:10:40.890 --> 00:10:43.800
ask us, hey, AR is great.

00:10:43.800 --> 00:10:46.140
Wouldn't it be better
if we could also

00:10:46.140 --> 00:10:49.110
trigger augmented
reality experiences off

00:10:49.110 --> 00:10:52.260
of 2D images in our
environment, like movie posters

00:10:52.260 --> 00:10:53.490
or textbooks?

00:10:53.490 --> 00:10:57.890
And so augmented images
seek to do just that.

00:10:57.890 --> 00:11:00.260
Augmented images
provide a mechanism

00:11:00.260 --> 00:11:02.990
to take a 2D
texture in the world

00:11:02.990 --> 00:11:06.170
and make it more
engaging by expanding it

00:11:06.170 --> 00:11:10.160
to a 3D interactive object.

00:11:10.160 --> 00:11:12.390
And to show a concrete
example of this,

00:11:12.390 --> 00:11:15.740
consider the case where we
have a new children's toy.

00:11:15.740 --> 00:11:18.530
It's called Castle Toy, I think.

00:11:18.530 --> 00:11:22.280
And we have told
ARCore, hey, we want

00:11:22.280 --> 00:11:25.370
you to recognize the surface
of this Castle Toy box.

00:11:25.370 --> 00:11:27.560
So now, as part of
the product, you

00:11:27.560 --> 00:11:30.380
can hold up your phone to
it and you can actually

00:11:30.380 --> 00:11:33.080
have an immersive
experience come out

00:11:33.080 --> 00:11:37.080
of that box, a more engaging
experience for your product.

00:11:37.080 --> 00:11:40.680
So augmented images allow you to
detect these kinds of textures.

00:11:40.680 --> 00:11:44.720
And then script behaviors,
and take this 2D flat surface

00:11:44.720 --> 00:11:47.970
and turn it into 3D, which
we think is really exciting.

00:11:47.970 --> 00:11:49.430
And it's based on your feedback.

00:11:49.430 --> 00:11:52.700
You told us that you wanted
this feature and now we have it.

00:11:52.700 --> 00:11:54.590
So that's the future
in a nutshell.

00:11:54.590 --> 00:11:56.480
But I want to tell
you about how it works

00:11:56.480 --> 00:12:00.170
and also how you can use
it in your applications.

00:12:00.170 --> 00:12:02.240
So augmented images
fundamentally

00:12:02.240 --> 00:12:05.460
work in three major steps.

00:12:05.460 --> 00:12:09.260
The first step is you
need to tell ARCore what

00:12:09.260 --> 00:12:11.180
images you're interested in.

00:12:11.180 --> 00:12:13.680
And there are two ways
that you can do this.

00:12:13.680 --> 00:12:16.760
The first way to do
this is to tell ARCore

00:12:16.760 --> 00:12:20.450
that you want to detect certain
kinds of images in real time.

00:12:20.450 --> 00:12:22.730
So you could download
an image from a server.

00:12:22.730 --> 00:12:25.180
You could have it bundled
in your application.

00:12:25.180 --> 00:12:28.730
And you tell ARCore
at runtime that,

00:12:28.730 --> 00:12:31.070
hey, please load
this image, learn

00:12:31.070 --> 00:12:33.800
how to detect it in the scene,
and tell me when you do.

00:12:33.800 --> 00:12:37.490
The second option is to
tell ARCore in advance.

00:12:37.490 --> 00:12:40.610
So we've provided tools where
you, on your desktop computer,

00:12:40.610 --> 00:12:44.750
can take up to 1,000 images
and train ARCore on them

00:12:44.750 --> 00:12:47.120
in an offline fashion,
saying, I would

00:12:47.120 --> 00:12:50.960
like you to be able to recognize
any of these 1,000 images

00:12:50.960 --> 00:12:53.090
when I run my
application on device.

00:12:53.090 --> 00:12:53.960
All right.

00:12:53.960 --> 00:12:56.090
So the next step
is now that we've

00:12:56.090 --> 00:12:58.630
trained ARCore to
recognize these images,

00:12:58.630 --> 00:13:00.380
we actually want to
detect them on device.

00:13:00.380 --> 00:13:03.500
We want to show ARCore a
scene and have it detect

00:13:03.500 --> 00:13:05.060
the images that we've trained.

00:13:05.060 --> 00:13:07.730
So now, when ARCore moves
around the environment

00:13:07.730 --> 00:13:10.850
with your phone,
ARCore will also

00:13:10.850 --> 00:13:12.440
look for textures
in the environment

00:13:12.440 --> 00:13:15.440
and try to match those to the
textures that you trained on.

00:13:15.440 --> 00:13:17.810
And when it finds
a match, ARCore

00:13:17.810 --> 00:13:19.910
provides you information
on that match

00:13:19.910 --> 00:13:24.840
with the third step, which is
it gives you a tracked object.

00:13:24.840 --> 00:13:27.500
So for those of you who
are familiar with ARCore,

00:13:27.500 --> 00:13:31.100
tracked objects are a notion
for the physical objects

00:13:31.100 --> 00:13:33.050
in space that
ARCore knows about.

00:13:33.050 --> 00:13:34.610
To this point,
that's been planes

00:13:34.610 --> 00:13:38.090
like these surfaces, both
horizontal and now vertical.

00:13:38.090 --> 00:13:41.720
But it also can give you points
in the environment of interest

00:13:41.720 --> 00:13:43.070
that you can attach to.

00:13:43.070 --> 00:13:46.160
And now, an augmented image is
just another tracked object.

00:13:46.160 --> 00:13:47.570
So you use it just
like you would

00:13:47.570 --> 00:13:50.180
use any plane or any point.

00:13:50.180 --> 00:13:53.390
And you can attach
your virtual content

00:13:53.390 --> 00:13:56.900
to the detection of the
physical object in the world.

00:13:56.900 --> 00:13:57.560
So that's it.

00:13:57.560 --> 00:13:59.310
Really simple,
three simple steps--

00:13:59.310 --> 00:14:02.570
number one, tell ARCore
what you're looking for.

00:14:02.570 --> 00:14:06.230
Number two, have ARCore
detect objects in the scene.

00:14:06.230 --> 00:14:08.690
And number three, attach
your virtual content

00:14:08.690 --> 00:14:10.970
to these physical objects.

00:14:10.970 --> 00:14:13.590
And because this is a
developer conference,

00:14:13.590 --> 00:14:15.800
I want to show you those
same steps in code.

00:14:15.800 --> 00:14:18.690
We're going to go through
them in Java really quick.

00:14:18.690 --> 00:14:20.930
But this is also the same
for Unity and Unreal.

00:14:20.930 --> 00:14:23.870
The concepts apply across all
of our development environments.

00:14:23.870 --> 00:14:26.900
So we'll go through the
same exact steps again.

00:14:26.900 --> 00:14:32.120
Step number one is you need to
add images to ARCore's memory.

00:14:32.120 --> 00:14:35.120
You need to tell it what
images it's interested in.

00:14:35.120 --> 00:14:39.020
And so here, we're creating this
new augmented images database

00:14:39.020 --> 00:14:40.610
and just adding an image to it.

00:14:40.610 --> 00:14:43.220
And we're doing this in
real time on the phone.

00:14:43.220 --> 00:14:44.870
Now, this is a
little bit expensive.

00:14:44.870 --> 00:14:46.850
You have to pay a
cost, computationally,

00:14:46.850 --> 00:14:48.260
for each image you add.

00:14:48.260 --> 00:14:51.020
So a little bit later,
I'll also show you

00:14:51.020 --> 00:14:53.570
how to create it with the
alternate flow on the computer.

00:14:53.570 --> 00:14:57.530
But once ARCore has a database
of images that it can detect,

00:14:57.530 --> 00:14:59.220
we go to the second step.

00:14:59.220 --> 00:15:01.670
So the second step is
ARCore is always looking

00:15:01.670 --> 00:15:03.290
for those images for you.

00:15:03.290 --> 00:15:06.140
And you can get it from the
AR frame, each and every frame

00:15:06.140 --> 00:15:09.300
that AR sees or that
ARCore sees in the world.

00:15:09.300 --> 00:15:11.750
So now, you've got a list
of all the augmented images

00:15:11.750 --> 00:15:12.920
in the scene.

00:15:12.920 --> 00:15:16.010
And you want to attach
virtual content to it.

00:15:16.010 --> 00:15:19.430
So that brings me
to the third step.

00:15:19.430 --> 00:15:21.790
So for step number
three, you just

00:15:21.790 --> 00:15:25.480
take the augmented images, the
augmented image that you want.

00:15:25.480 --> 00:15:27.550
And you create an
anchor off of it.

00:15:27.550 --> 00:15:30.730
And then you can attach
virtual content to that anchor.

00:15:30.730 --> 00:15:34.450
And it's the same as you would
for any kind of plane detection

00:15:34.450 --> 00:15:37.820
or point detection that you've
been used to in the past.

00:15:37.820 --> 00:15:39.550
So that's it,
three simple steps.

00:15:39.550 --> 00:15:43.030
And if you want to do
the pre-computation

00:15:43.030 --> 00:15:45.310
on the computer,
this is what you run.

00:15:45.310 --> 00:15:47.590
So there's a command
called build-db.

00:15:47.590 --> 00:15:50.210
And you can pass up to 1,000
images into this command.

00:15:50.210 --> 00:15:52.870
And it'll build an image
database in advance

00:15:52.870 --> 00:15:57.280
that you can then load in
ARCore using this code.

00:15:57.280 --> 00:16:01.210
So this loads the database
from file, pulls it in.

00:16:01.210 --> 00:16:04.210
It's computationally efficient
because ARCore has already

00:16:04.210 --> 00:16:06.790
done the work that it needs
to to be able to recognize

00:16:06.790 --> 00:16:08.230
these images later.

00:16:08.230 --> 00:16:11.230
And now, you can go off and
running with the same other two

00:16:11.230 --> 00:16:13.750
steps that we showed before,
which is detecting the image

00:16:13.750 --> 00:16:16.160
and then placing
content relative to it.

00:16:16.160 --> 00:16:16.700
All right.

00:16:16.700 --> 00:16:17.620
Pretty simple.

00:16:17.620 --> 00:16:21.260
Now, I want to show you
a demo of this in action.

00:16:21.260 --> 00:16:25.940
So we're going to switch
to the Pixel phone here.

00:16:25.940 --> 00:16:31.620
And we're going to run
this augmented images demo.

00:16:31.620 --> 00:16:36.740
So here, we've actually trained
ARCore to recognize this poster

00:16:36.740 --> 00:16:37.800
on the wall.

00:16:37.800 --> 00:16:39.740
And so when I look
at the poster,

00:16:39.740 --> 00:16:43.790
you can see that it fades out
and it goes from 2D into 3D.

00:16:43.790 --> 00:16:49.870
And now as I move, the
perspective that I see changes.

00:16:49.870 --> 00:16:53.267
So I've got a 3D object
coming out of this 2D texture.

00:16:53.267 --> 00:16:54.850
Nothing's really
changed in the world.

00:16:54.850 --> 00:16:57.611
But I can make it more
engaging and immersive.

00:16:57.611 --> 00:16:58.110
All right.

00:16:58.110 --> 00:17:03.280
So that's the demo of augmented
images, pretty simple.

00:17:03.280 --> 00:17:07.140
And now, I want to talk a
little bit about some use cases.

00:17:07.140 --> 00:17:09.210
Posters are great
for demos, but we

00:17:09.210 --> 00:17:12.880
think augmented images have
a lot more potential as well.

00:17:12.880 --> 00:17:15.780
So the first use case that we're
excited about is education.

00:17:15.780 --> 00:17:18.359
Imagine a textbook coming
to life in front of you,

00:17:18.359 --> 00:17:21.630
or going into a museum tour
where artwork on the wall

00:17:21.630 --> 00:17:23.940
jumps out at you and
gives you more information

00:17:23.940 --> 00:17:26.670
about the artists or maybe
their progression as they

00:17:26.670 --> 00:17:28.410
were sketching a painting.

00:17:28.410 --> 00:17:30.990
We think augmented images
are useful for advertising.

00:17:30.990 --> 00:17:33.169
Advertising is all
about engagement.

00:17:33.169 --> 00:17:35.460
Imagine being at a movie
theater and holding your phone

00:17:35.460 --> 00:17:38.400
up to a movie poster and
having content come out

00:17:38.400 --> 00:17:40.140
or telling you showtimes.

00:17:40.140 --> 00:17:43.200
Or imagine being at a bus
stop with a little bit of time

00:17:43.200 --> 00:17:45.150
to kill and engaging
with the ad that you

00:17:45.150 --> 00:17:49.010
have on the side of
the bus stop station.

00:17:49.010 --> 00:17:52.530
We think augmented images can
also be useful for the products

00:17:52.530 --> 00:17:53.850
that you're advertising.

00:17:53.850 --> 00:17:56.190
So here, you can
build products that

00:17:56.190 --> 00:17:58.500
meld the physical and
digital worlds, that

00:17:58.500 --> 00:18:00.000
bring both together.

00:18:00.000 --> 00:18:02.940
It could be Castle Toy, where
you have an experience that

00:18:02.940 --> 00:18:05.610
comes out of the
box itself, or it

00:18:05.610 --> 00:18:08.760
could be a how-to guide
for your coffee machine

00:18:08.760 --> 00:18:11.220
as you try to make
coffee for the first time

00:18:11.220 --> 00:18:12.870
with your expensive
espresso machine

00:18:12.870 --> 00:18:14.640
and you have no idea what to do.

00:18:14.640 --> 00:18:17.220
So we think augmented
images expand

00:18:17.220 --> 00:18:20.066
the capabilities and
usefulness of AR in general.

00:18:20.066 --> 00:18:21.690
And we're really,
really excited to see

00:18:21.690 --> 00:18:23.220
what you build with them.

00:18:23.220 --> 00:18:25.330
And we also are not done yet.

00:18:25.330 --> 00:18:27.372
We're going to talk about
one more feature today.

00:18:27.372 --> 00:18:28.871
And for that, I'm
going to bring out

00:18:28.871 --> 00:18:31.320
James Birney, who's a product
manager who works with me.

00:18:31.320 --> 00:18:33.759
And he's going to talk to
you about Cloud Anchors.

00:18:33.759 --> 00:18:35.050
I think you'll really enjoy it.

00:18:35.050 --> 00:18:35.758
Thanks very much.

00:18:35.758 --> 00:18:36.606
Come on up, James.

00:18:36.606 --> 00:18:38.478
[APPLAUSE]

00:18:40.330 --> 00:18:42.080
JAMES BIRNEY: So real
quick, before we get

00:18:42.080 --> 00:18:44.160
started-- you guys have
been sitting for awhile.

00:18:44.160 --> 00:18:45.770
And I really like doing this
at the beginning of our things.

00:18:45.770 --> 00:18:48.570
We're going to do the wave real
quick going across the room.

00:18:48.570 --> 00:18:49.165
All right?

00:18:49.165 --> 00:18:49.790
You guys ready?

00:18:49.790 --> 00:18:51.290
Laptops ready?

00:18:51.290 --> 00:18:55.200
All right, three, two, one--
up, up, up, up, up, up, up.

00:18:55.200 --> 00:18:56.400
Yay, ARCore.

00:18:56.400 --> 00:18:56.900
Woo-hoo!

00:19:00.050 --> 00:19:00.800
It worked.

00:19:00.800 --> 00:19:02.780
[LAUGHS]

00:19:03.280 --> 00:19:05.020
All right.

00:19:05.020 --> 00:19:07.510
Thank you, guys.

00:19:07.510 --> 00:19:08.110
All right.

00:19:08.110 --> 00:19:11.920
So like Eitan mentioned,
my name's James Birney.

00:19:11.920 --> 00:19:14.050
I'm a product manager on
ARCore, and specifically

00:19:14.050 --> 00:19:14.825
on Cloud Anchors.

00:19:14.825 --> 00:19:17.200
Raise your hand if you saw
the Cloud Anchors announcement

00:19:17.200 --> 00:19:18.514
yesterday.

00:19:18.514 --> 00:19:19.180
All right, good.

00:19:19.180 --> 00:19:21.304
That's slightly more
than half, awesome.

00:19:21.304 --> 00:19:23.470
So that's what we're going
to cover in this section.

00:19:23.470 --> 00:19:24.340
Hopefully you guys
are going to be

00:19:24.340 --> 00:19:26.839
really excited by the time we
get through talking with Cloud

00:19:26.839 --> 00:19:30.900
Anchors and you're going to want
to immediately start building.

00:19:30.900 --> 00:19:33.170
So before we hop
into Cloud Anchors,

00:19:33.170 --> 00:19:37.340
it's really important to
start with where AR is today.

00:19:37.340 --> 00:19:42.740
So could I get a quick hand if
you've built an AR app before?

00:19:42.740 --> 00:19:45.210
All right, so that's
roughly about half of you.

00:19:45.210 --> 00:19:48.460
So for the other half,
what happens when--

00:19:48.460 --> 00:19:49.954
let's say that
together we're going

00:19:49.954 --> 00:19:52.370
to build an app where we're
going to place some dinosaurs.

00:19:52.370 --> 00:19:55.120
And so we're going to
have a T-Rex over here

00:19:55.120 --> 00:19:56.810
and maybe a
Triceratops over here.

00:19:56.810 --> 00:19:58.160
And they're going to interact.

00:19:58.160 --> 00:20:00.920
The way that we would do
that in the AR app today

00:20:00.920 --> 00:20:02.870
is we would plant an anchor.

00:20:02.870 --> 00:20:05.900
And then the T-Rex
and the Triceratops

00:20:05.900 --> 00:20:10.060
would be placed as relative
offsets from those anchors.

00:20:10.060 --> 00:20:13.790
And that becomes your
reference frame in your AR app.

00:20:13.790 --> 00:20:16.322
Now, let's say that Eitan
were to come back up on stage.

00:20:16.322 --> 00:20:18.530
He's not going to come up
because that's a long walk.

00:20:18.530 --> 00:20:24.260
But Eitan goes ahead and creates
a separate dinosaur app over

00:20:24.260 --> 00:20:25.040
here.

00:20:25.040 --> 00:20:27.710
And he places, say, a
bunch of pterodactyls.

00:20:27.710 --> 00:20:29.990
And again, he plants an anchor.

00:20:29.990 --> 00:20:33.050
And his pterodactyls are all
placed relative to that anchor.

00:20:33.050 --> 00:20:37.820
Now, what's missing
is Eitan's app

00:20:37.820 --> 00:20:39.635
is running in a
different reality,

00:20:39.635 --> 00:20:41.930
a different augmented
reality than the app

00:20:41.930 --> 00:20:43.650
that we have over here.

00:20:43.650 --> 00:20:46.070
And the reason why
is those two anchors

00:20:46.070 --> 00:20:47.840
can't talk to each other.

00:20:47.840 --> 00:20:51.020
So this is what
Cloud Anchors solves,

00:20:51.020 --> 00:20:53.630
is we give you the ability
to create a shared reference

00:20:53.630 --> 00:20:54.420
frame.

00:20:54.420 --> 00:20:56.419
So that reference frame
I was mentioning before,

00:20:56.419 --> 00:20:58.640
where you have the anchor
and you have the offsets

00:20:58.640 --> 00:21:01.790
to our T-Rex and
to our pterodactyl,

00:21:01.790 --> 00:21:06.620
that now, we can have a
common anchor in the middle

00:21:06.620 --> 00:21:08.510
and all the AR content.

00:21:08.510 --> 00:21:12.410
So everything from
pterodactyls to T-Rexes

00:21:12.410 --> 00:21:14.254
are able to then
interact and play.

00:21:14.254 --> 00:21:16.670
And then you can create these
really fun experiences where

00:21:16.670 --> 00:21:18.086
not only is my
content interacting

00:21:18.086 --> 00:21:21.110
with Eitan's content, but I
can control Eitan's content.

00:21:21.110 --> 00:21:22.760
He can control mine.

00:21:22.760 --> 00:21:24.530
That's pretty cool.

00:21:24.530 --> 00:21:28.040
So that's kind of an abstract
thing where I'm literally

00:21:28.040 --> 00:21:30.050
moving my hands around onstage.

00:21:30.050 --> 00:21:34.580
A more concrete example
would be our Just a Line app,

00:21:34.580 --> 00:21:36.440
which if you haven't
seen it before

00:21:36.440 --> 00:21:39.080
is an experimental app
that we as Google built.

00:21:39.080 --> 00:21:41.750
It literally draws a
single line in space.

00:21:41.750 --> 00:21:44.270
And what we added
to it is the ability

00:21:44.270 --> 00:21:48.050
to do not just one artist,
but multiple artists drawing

00:21:48.050 --> 00:21:49.330
in the same space.

00:21:49.330 --> 00:21:51.590
So I'm going to show
you an extended version

00:21:51.590 --> 00:21:55.340
of the video they showed you
really quickly yesterday,

00:21:55.340 --> 00:21:59.520
where you can see multiple
artists drawing together.

00:21:59.520 --> 00:22:01.400
And hopefully you
see from this video

00:22:01.400 --> 00:22:03.066
the powerful experience
that you get out

00:22:03.066 --> 00:22:08.360
of this, where now, you're able
to interact with your friends

00:22:08.360 --> 00:22:09.500
and draw together.

00:22:09.500 --> 00:22:11.002
And when one person
draws a line,

00:22:11.002 --> 00:22:12.210
you can build on top of that.

00:22:17.630 --> 00:22:19.850
So I'll give it a second
here for the video to finish

00:22:19.850 --> 00:22:21.600
and for you guys to
absorb what's going on

00:22:21.600 --> 00:22:22.950
because that's a new concept.

00:22:26.420 --> 00:22:28.320
OK, so let's talk a
little bit about how

00:22:28.320 --> 00:22:30.930
we create these cloud anchors.

00:22:30.930 --> 00:22:33.330
We've done an awful lot of
work to make it very simple.

00:22:33.330 --> 00:22:34.990
So it's only a few steps.

00:22:34.990 --> 00:22:36.970
Let me walk you through them.

00:22:36.970 --> 00:22:39.510
So step one is--

00:22:39.510 --> 00:22:42.010
let's say in this example,
we make our stick woman.

00:22:42.010 --> 00:22:43.950
Her name is going to be Alice.

00:22:43.950 --> 00:22:46.980
And Alice is going to
place a cloud anchor.

00:22:46.980 --> 00:22:49.430
Now, the verb that we use
to create a cloud anchor

00:22:49.430 --> 00:22:51.030
is called hosting.

00:22:51.030 --> 00:22:54.120
The reason why is we're going
to host that native anchor up

00:22:54.120 --> 00:22:55.530
to the cloud.

00:22:55.530 --> 00:22:57.930
So when we host
that cloud anchor,

00:22:57.930 --> 00:22:59.760
the features which
are the visual

00:22:59.760 --> 00:23:01.300
features in the environment.

00:23:01.300 --> 00:23:04.050
So let's say that
Alice is standing here.

00:23:04.050 --> 00:23:08.250
And as Alice is
looking at the table,

00:23:08.250 --> 00:23:10.200
she places a cloud
anchor or the app

00:23:10.200 --> 00:23:13.159
will place a cloud anchor
for her on the stage, right

00:23:13.159 --> 00:23:14.700
here next to our
beautiful succulent.

00:23:14.700 --> 00:23:16.550
Do you guys like our succulent?

00:23:16.550 --> 00:23:17.200
OK.

00:23:17.200 --> 00:23:19.200
[LAUGHS] Thank you.

00:23:19.200 --> 00:23:21.490
I appreciate the one person.

00:23:21.490 --> 00:23:22.110
OK.

00:23:22.110 --> 00:23:26.640
So what the phone is going to
extract from the environment

00:23:26.640 --> 00:23:29.490
is all the points
where these leaves come

00:23:29.490 --> 00:23:32.340
to what the phone will see
as contrast points, where

00:23:32.340 --> 00:23:34.530
the colors change, where
the lighting changes.

00:23:34.530 --> 00:23:36.510
So the edge of this
table, the edge

00:23:36.510 --> 00:23:38.400
of this tablecloth,
every point where

00:23:38.400 --> 00:23:41.430
the leaves kind of change, those
are the visual features that

00:23:41.430 --> 00:23:44.880
get abstracted and then
get uploaded to the cloud.

00:23:44.880 --> 00:23:47.880
That then gets
saved and processed.

00:23:47.880 --> 00:23:49.590
And what Alice gets
back in a couple

00:23:49.590 --> 00:23:52.440
seconds is that cloud anchor.

00:23:52.440 --> 00:23:57.180
Now, in that cloud anchor is
a really important attribute.

00:23:57.180 --> 00:23:59.910
That attribute is
the Cloud Anchor ID.

00:23:59.910 --> 00:24:05.160
So you can think about
the Cloud Anchor ID as--

00:24:05.160 --> 00:24:06.840
you can think
about Cloud Anchors

00:24:06.840 --> 00:24:08.370
the same way you
think about a file.

00:24:08.370 --> 00:24:11.310
So say you're going to save
a file to Google Drive.

00:24:11.310 --> 00:24:14.239
And when you save it, you need
to create a file name, right?

00:24:14.239 --> 00:24:15.780
Well, with Cloud
Anchors, we're going

00:24:15.780 --> 00:24:19.824
to create essentially that
file name or that ID for you.

00:24:19.824 --> 00:24:21.240
And that ID is the
way that you're

00:24:21.240 --> 00:24:22.200
going to reference it later.

00:24:22.200 --> 00:24:24.180
Would be really hard to find the
file without knowing the name,

00:24:24.180 --> 00:24:25.070
right?

00:24:25.070 --> 00:24:29.260
So the Cloud Anchor ID
is the same concept.

00:24:29.260 --> 00:24:31.560
So how this comes
into play is all

00:24:31.560 --> 00:24:35.730
Alice needs to do to get Bob,
our stick man over there,

00:24:35.730 --> 00:24:39.960
to connect to Alice's
cloud anchor is to--

00:24:39.960 --> 00:24:43.980
excuse me-- is to send over
that Cloud Anchor ID to Bob.

00:24:43.980 --> 00:24:47.430
And that's all she needs
to send over to Bob.

00:24:47.430 --> 00:24:49.170
Once Bob has the
Cloud Anchor ID,

00:24:49.170 --> 00:24:52.080
he then uses the
Cloud Anchor ID to--

00:24:52.080 --> 00:24:54.330
and our verb here is resolve.

00:24:54.330 --> 00:24:56.790
In resolving, we'll
add the Cloud Anchor ID

00:24:56.790 --> 00:24:59.260
to Bob's reference frame.

00:24:59.260 --> 00:25:01.530
So let's say that Bob is
standing right here as well.

00:25:01.530 --> 00:25:03.090
He looks at the same area.

00:25:03.090 --> 00:25:05.520
The visual features that will
get uploaded to the cloud,

00:25:05.520 --> 00:25:07.800
in the cloud will match
those visual features

00:25:07.800 --> 00:25:11.580
against the visual features that
Alice had previously uploaded.

00:25:11.580 --> 00:25:15.360
And we will give Bob
back a cloud anchor

00:25:15.360 --> 00:25:17.400
that will be relative
to where his device is.

00:25:17.400 --> 00:25:20.000
So even though both devices
are in different locations,

00:25:20.000 --> 00:25:24.390
we'll create the cloud anchor in
a consistent physical location.

00:25:24.390 --> 00:25:25.760
And that's the magic.

00:25:25.760 --> 00:25:27.900
Because they're in a
consistent physical location,

00:25:27.900 --> 00:25:30.090
you then have a shared
reference frame.

00:25:30.090 --> 00:25:32.547
And then at that
point, we can place--

00:25:32.547 --> 00:25:34.380
again, let's use dinosaurs
because everybody

00:25:34.380 --> 00:25:35.867
loves dinosaurs, right--

00:25:35.867 --> 00:25:38.200
we can place our dinosaurs
relative to that cloud anchor

00:25:38.200 --> 00:25:41.700
and we can start our
shared AR experience.

00:25:41.700 --> 00:25:43.770
Hopefully that makes sense.

00:25:43.770 --> 00:25:45.442
Oh, cloud anchor comes back.

00:25:45.442 --> 00:25:47.400
And then I'm going to
tie it all together here.

00:25:47.400 --> 00:25:49.320
We created a very
fancy visualization.

00:25:49.320 --> 00:25:51.420
The orange dots
that come up, those

00:25:51.420 --> 00:25:54.060
are the visual features
we were talking about.

00:25:54.060 --> 00:25:55.110
They go up to the cloud.

00:25:55.110 --> 00:25:57.940
Bob uploads his visual
features up to the cloud.

00:25:57.940 --> 00:25:58.740
They get matched.

00:25:58.740 --> 00:26:01.114
And then the two of them create
the same shared reference

00:26:01.114 --> 00:26:01.680
frame.

00:26:01.680 --> 00:26:04.740
And then once that shared
reference frame is created--

00:26:04.740 --> 00:26:06.600
wait a second for the
GIF to loop around--

00:26:06.600 --> 00:26:08.819
you'll see that
spaceship show up.

00:26:08.819 --> 00:26:10.860
And then the two of them
can follow the spaceship

00:26:10.860 --> 00:26:12.002
around the room.

00:26:12.002 --> 00:26:13.710
And once they're
paired, then the devices

00:26:13.710 --> 00:26:14.964
can go anywhere in the room.

00:26:14.964 --> 00:26:16.630
And they're in the
same reference frame.

00:26:16.630 --> 00:26:17.921
And they can interact together.

00:26:21.610 --> 00:26:22.110
All right.

00:26:22.110 --> 00:26:26.160
So let's keep on going one
level deeper, like "Inception,"

00:26:26.160 --> 00:26:27.930
with some sample code.

00:26:27.930 --> 00:26:31.290
OK, so same format as
before, but before we

00:26:31.290 --> 00:26:33.990
get to those two methods
of hosting and resolving,

00:26:33.990 --> 00:26:37.060
it's really important that
we enable the feature.

00:26:37.060 --> 00:26:39.330
So when you're
working with ARCore,

00:26:39.330 --> 00:26:43.650
interact with the session.config
and turn on our feature.

00:26:43.650 --> 00:26:45.900
You need to do this
on all devices.

00:26:45.900 --> 00:26:48.250
But hopefully this is
pretty straightforward.

00:26:48.250 --> 00:26:50.900
Then on the first device--

00:26:50.900 --> 00:26:52.540
so this is Alice's
device, the one

00:26:52.540 --> 00:26:54.760
that creates the Cloud Anchor.

00:26:54.760 --> 00:26:58.360
The main method we need to
call here is HostCloudAnchor.

00:26:58.360 --> 00:27:00.640
On HostCloud-- and then with--

00:27:00.640 --> 00:27:01.450
excuse me.

00:27:01.450 --> 00:27:03.280
With HostCloudAnchor,
you can feed

00:27:03.280 --> 00:27:06.850
in any preexisting
native anchor.

00:27:06.850 --> 00:27:09.640
So as Eitan was
mentioning before,

00:27:09.640 --> 00:27:12.040
normally this is created from
a horizontal plane or now

00:27:12.040 --> 00:27:13.570
from a vertical plane.

00:27:13.570 --> 00:27:16.810
And you can pass in that
anchor into HostCloudAnchor.

00:27:16.810 --> 00:27:18.820
Asynchronously that
call will complete

00:27:18.820 --> 00:27:20.060
in a couple of seconds.

00:27:20.060 --> 00:27:21.817
And what comes back
is your cloud anchor.

00:27:21.817 --> 00:27:24.400
Now, what did we talk about is
the really important thing that

00:27:24.400 --> 00:27:26.965
comes from the cloud anchor?

00:27:26.965 --> 00:27:28.090
All right, Cloud Anchor ID.

00:27:28.090 --> 00:27:28.589
Thank you.

00:27:28.589 --> 00:27:32.680
[LAUGHS] So then,
it is completely up

00:27:32.680 --> 00:27:35.470
to you what means of
device-to-device communication

00:27:35.470 --> 00:27:36.469
you want to use.

00:27:36.469 --> 00:27:38.510
The demo that we're going
to show you in a second

00:27:38.510 --> 00:27:39.790
uses Firebase.

00:27:39.790 --> 00:27:41.769
There's also two other
demos in the Sandboxes

00:27:41.769 --> 00:27:43.060
I'd encourage you to check out.

00:27:43.060 --> 00:27:44.420
Those also use Firebase as well.

00:27:44.420 --> 00:27:46.360
It's a great means to
communicate between.

00:27:46.360 --> 00:27:50.670
But you can use
any means you want.

00:27:50.670 --> 00:27:54.180
So then on Bob's device--

00:27:54.180 --> 00:27:55.920
and it's a really
important point here.

00:27:55.920 --> 00:27:57.420
This is not limited to just Bob.

00:27:57.420 --> 00:28:02.840
We could also have Bob,
Jerry, Johnny, Eitan.

00:28:02.840 --> 00:28:05.280
And it can be as many
users as we want.

00:28:05.280 --> 00:28:10.350
That all they need to do to
join that cloud anchor is

00:28:10.350 --> 00:28:12.210
receive the Cloud Anchor ID.

00:28:12.210 --> 00:28:15.120
That's the one that
Alice just sent over.

00:28:15.120 --> 00:28:17.280
And then we need to
resolve that cloud anchor.

00:28:17.280 --> 00:28:20.560
In order to resolve the cloud
anchor, it's dead simple.

00:28:20.560 --> 00:28:23.460
All you need to do is pass
in the Cloud Anchor ID.

00:28:23.460 --> 00:28:25.230
In the background,
under the hood,

00:28:25.230 --> 00:28:27.030
we will take those
visual features

00:28:27.030 --> 00:28:29.090
from what the user is
currently looking at.

00:28:29.090 --> 00:28:31.590
So it's important that the user
is, again, currently looking

00:28:31.590 --> 00:28:34.289
where Alice was.

00:28:34.289 --> 00:28:36.330
And we'll upload those
features and then give you

00:28:36.330 --> 00:28:37.501
that cloud anchor back.

00:28:37.501 --> 00:28:39.250
And then at that point,
you're good to go.

00:28:39.250 --> 00:28:42.247
You can start placing assets
relative to that cloud anchor.

00:28:44.870 --> 00:28:46.800
So quick question,
what operating system

00:28:46.800 --> 00:28:51.320
were those devices in that
code example running on?

00:28:51.320 --> 00:28:51.860
Anyone?

00:28:51.860 --> 00:28:52.970
All right.

00:28:52.970 --> 00:28:55.670
So the really
important point here

00:28:55.670 --> 00:28:59.210
is Cloud Anchors work
on both Android--

00:28:59.210 --> 00:29:02.300
which means any ARCore-enabled
Android device--

00:29:02.300 --> 00:29:09.140
and any iOS ARKit-enabled
device, which for today

00:29:09.140 --> 00:29:11.890
is going to be iPhones.

00:29:11.890 --> 00:29:16.150
And we believe this is
incredibly important to making

00:29:16.150 --> 00:29:18.850
shared AR a reality.

00:29:18.850 --> 00:29:21.427
There's no reason that
we should discriminate

00:29:21.427 --> 00:29:23.260
which of our friends
can play a game with us

00:29:23.260 --> 00:29:25.725
based on which operating
system they run on their phone.

00:29:25.725 --> 00:29:27.600
That's not really
important to whether or not

00:29:27.600 --> 00:29:28.606
Eitan and I are friends.

00:29:28.606 --> 00:29:29.980
If he has an
iPhone, he should be

00:29:29.980 --> 00:29:33.280
able to play shared
AR with me, right?

00:29:33.280 --> 00:29:40.270
So now, I'm going to invite
Eitan on up on stage.

00:29:40.270 --> 00:29:42.250
And we're going to give
you guys a live demo.

00:29:42.250 --> 00:29:47.347
Because it's one thing
to say that everything

00:29:47.347 --> 00:29:49.180
works cross-platform,
but it's another thing

00:29:49.180 --> 00:29:51.000
to show you guys
with a live demo.

00:29:51.000 --> 00:29:52.375
EITAN MARDER-EPPSTEIN:
All right.

00:29:52.375 --> 00:29:55.210
So maybe one last poll
just to get started.

00:29:55.210 --> 00:29:57.280
Who thinks I'm going
to win this game?

00:29:57.280 --> 00:29:58.292
Raise your hand.

00:29:58.292 --> 00:30:00.180
Oh.

00:30:00.180 --> 00:30:00.940
Oh, it's tough.

00:30:00.940 --> 00:30:02.480
All right, who thinks
James is going to win?

00:30:02.480 --> 00:30:03.815
That's the rest of you, right?

00:30:03.815 --> 00:30:04.695
[LAUGHS]

00:30:04.695 --> 00:30:06.820
JAMES BIRNEY: So you guys
are getting to know Eitan

00:30:06.820 --> 00:30:07.870
better every minute.

00:30:07.870 --> 00:30:11.767
And it's really important to
know Eitan sandbags a lot.

00:30:11.767 --> 00:30:12.850
EITAN MARDER-EPPSTEIN: OK.

00:30:12.850 --> 00:30:14.420
I just got to join this room.

00:30:17.110 --> 00:30:18.090
OK.

00:30:18.090 --> 00:30:20.310
So now, I'm going
to set up my board.

00:30:20.310 --> 00:30:21.550
And James, you set up yours.

00:30:21.550 --> 00:30:22.110
JAMES BIRNEY: Yeah.

00:30:22.110 --> 00:30:23.590
EITAN MARDER-EPPSTEIN: And you
want to get close to me, right?

00:30:23.590 --> 00:30:24.506
JAMES BIRNEY: [LAUGHS]

00:30:24.506 --> 00:30:26.400
EITAN MARDER-EPPSTEIN:
You need that help.

00:30:26.400 --> 00:30:27.880
JAMES BIRNEY: I'm also
showing off a little bit here.

00:30:27.880 --> 00:30:29.379
You can see as
mine's moving around,

00:30:29.379 --> 00:30:31.180
the same state is
being reflected in both

00:30:31.180 --> 00:30:32.720
at the same physical location.

00:30:32.720 --> 00:30:34.690
So I'm going to press that.

00:30:34.690 --> 00:30:36.895
Here's our futuristic-looking
light boards.

00:30:36.895 --> 00:30:39.299
EITAN MARDER-EPPSTEIN:
All right, here we go.

00:30:39.299 --> 00:30:41.340
JAMES BIRNEY: And we have
people in the back that

00:30:41.340 --> 00:30:43.307
are organizing bets,
in case anybody wants

00:30:43.307 --> 00:30:44.390
to make money off of this.

00:30:44.390 --> 00:30:45.556
EITAN MARDER-EPPSTEIN: Yeah.

00:30:45.556 --> 00:30:48.690
So the goal here is to turn
the other person's board

00:30:48.690 --> 00:30:49.380
your color.

00:30:49.380 --> 00:30:52.920
And I feel like James
has been sandbagging me

00:30:52.920 --> 00:30:55.410
in all of our practice sessions
because he's doing much

00:30:55.410 --> 00:30:59.070
better than he has in the past.

00:30:59.070 --> 00:30:59.626
Let's see.

00:30:59.626 --> 00:31:00.500
JAMES BIRNEY: Oh, no.

00:31:00.500 --> 00:31:03.090
That was [INAUDIBLE].

00:31:03.090 --> 00:31:04.770
EITAN MARDER-EPPSTEIN:
Oh, so close.

00:31:04.770 --> 00:31:07.550
Hold on.

00:31:07.550 --> 00:31:08.240
All right.

00:31:08.240 --> 00:31:10.259
Just one more shot,
one more shot.

00:31:10.259 --> 00:31:12.550
JAMES BIRNEY: You'll notice
that Eitan and I both can't

00:31:12.550 --> 00:31:12.646
multitask--

00:31:12.646 --> 00:31:13.896
EITAN MARDER-EPPSTEIN: Oh, no.

00:31:13.896 --> 00:31:15.330
JAMES BIRNEY: --very well.

00:31:15.330 --> 00:31:16.871
EITAN MARDER-EPPSTEIN:
Did I get him?

00:31:16.871 --> 00:31:17.830
JAMES BIRNEY: Oh.

00:31:17.830 --> 00:31:18.860
All right.

00:31:18.860 --> 00:31:20.080
Thank you.

00:31:20.080 --> 00:31:20.730
Hey, it worked.

00:31:20.730 --> 00:31:22.466
[APPLAUSE]

00:31:23.770 --> 00:31:24.530
All right.

00:31:24.530 --> 00:31:26.650
And just to reiterate,
so that was an iPhone

00:31:26.650 --> 00:31:27.610
that Eitan was using.

00:31:27.610 --> 00:31:28.990
This is a Pixel 2.

00:31:28.990 --> 00:31:32.170
But this very well could
have been any Android

00:31:32.170 --> 00:31:34.270
ARCore-enabled device.

00:31:34.270 --> 00:31:36.290
That could have been any
ARKit-enabled device.

00:31:40.640 --> 00:31:44.000
And there's my clicker.

00:31:44.000 --> 00:31:46.940
OK, so let's talk
about use cases.

00:31:46.940 --> 00:31:47.760
That was gaming.

00:31:47.760 --> 00:31:50.100
That was an example of
gaming working really well.

00:31:50.100 --> 00:31:52.861
But shared AR does not
need to stop at gaming.

00:31:52.861 --> 00:31:54.860
We think there's a whole
lot of other categories

00:31:54.860 --> 00:31:58.340
where shared AR can make a
big difference in the world.

00:31:58.340 --> 00:31:59.300
Oops.

00:31:59.300 --> 00:32:00.217
Lance, help me.

00:32:00.217 --> 00:32:01.550
Can you go back a slide, please?

00:32:04.280 --> 00:32:07.070
Pretty please?

00:32:07.070 --> 00:32:08.470
Thank you.

00:32:08.470 --> 00:32:12.710
OK, so four categories that
briefly let's talk about.

00:32:12.710 --> 00:32:15.510
So one is in the
education space.

00:32:15.510 --> 00:32:17.600
This is an example of--

00:32:17.600 --> 00:32:21.530
let me phrase this as
a question instead.

00:32:21.530 --> 00:32:23.680
Raise your hand after
I say two options.

00:32:23.680 --> 00:32:25.640
Option A, you can
learn about what

00:32:25.640 --> 00:32:28.040
it's like to explore on
Mars and the Mars missions

00:32:28.040 --> 00:32:30.860
from a textbook,
option A. Option B,

00:32:30.860 --> 00:32:32.660
you can learn from
an interactive 3D

00:32:32.660 --> 00:32:36.290
model of the Rover that you can
play with with your friends.

00:32:36.290 --> 00:32:38.160
All for option A?

00:32:38.160 --> 00:32:38.660
OK.

00:32:38.660 --> 00:32:40.100
Option B?

00:32:40.100 --> 00:32:41.540
All right.

00:32:41.540 --> 00:32:45.452
See, we're making improvements
in how people learn.

00:32:45.452 --> 00:32:47.160
And the demo that
we're showing you here,

00:32:47.160 --> 00:32:51.110
this is an example
that NASA built for us.

00:32:51.110 --> 00:32:53.120
This doesn't need to stop
at space exploration,

00:32:53.120 --> 00:32:55.670
although that's a pretty
big area to explore.

00:32:55.670 --> 00:32:57.410
You could do this
as well in any sort

00:32:57.410 --> 00:32:59.599
of visual area such as biology.

00:32:59.599 --> 00:33:01.640
There's a couple cool
demos where you can explore

00:33:01.640 --> 00:33:03.617
the human body together.

00:33:03.617 --> 00:33:04.700
And I'll leave it at that.

00:33:08.690 --> 00:33:10.530
Let's hop on down to
creative expression.

00:33:10.530 --> 00:33:12.190
So you saw our Just
a Line example,

00:33:12.190 --> 00:33:14.380
which is where we draw
the white line in space.

00:33:14.380 --> 00:33:16.090
But we can go beyond that.

00:33:16.090 --> 00:33:17.650
Take for example
this block building

00:33:17.650 --> 00:33:20.410
app that was built
by [INAUDIBLE],, where

00:33:20.410 --> 00:33:23.450
you can build a full
block building thing

00:33:23.450 --> 00:33:26.770
and then 3D print it later.

00:33:26.770 --> 00:33:28.930
It's very, very cool.

00:33:28.930 --> 00:33:31.090
And you can imagine what
this would look like

00:33:31.090 --> 00:33:32.920
as well with the AR Stickers.

00:33:32.920 --> 00:33:36.460
Raise your hand if you
played with AR Stickers.

00:33:36.460 --> 00:33:39.310
So you can imagine what
this would look like if now

00:33:39.310 --> 00:33:42.820
as you're placing
Stormtroopers or--

00:33:42.820 --> 00:33:45.160
help me, the Demogorgon--

00:33:45.160 --> 00:33:47.530
as you're placing Demogorgon,
someone else can place El

00:33:47.530 --> 00:33:50.070
and have the fight be between
your different phones.

00:33:50.070 --> 00:33:53.390
That would be a
very fun experience.

00:33:53.390 --> 00:33:57.560
Gaming-- so now, you can do
ice fishing with your friends.

00:33:57.560 --> 00:33:59.372
Haven't you guys always
wanted to do that?

00:33:59.372 --> 00:34:02.775
[LAUGHING] Believe
me, it actually

00:34:02.775 --> 00:34:05.150
is an awful lot more fun than
it sounds when you just say

00:34:05.150 --> 00:34:07.190
ice fishing with your friends.

00:34:07.190 --> 00:34:09.830
It's particularly fun on
a hot day in San Francisco

00:34:09.830 --> 00:34:12.800
to be able to look
down at the sidewalk

00:34:12.800 --> 00:34:16.880
and turn the sidewalk
into a ice fishing pool.

00:34:16.880 --> 00:34:20.630
Beyond ice fishing, you can
imagine playing laser tag

00:34:20.630 --> 00:34:21.440
with your friends.

00:34:21.440 --> 00:34:22.820
Can now be just
with your phones.

00:34:22.820 --> 00:34:25.130
You don't need to
buy special gear.

00:34:25.130 --> 00:34:28.190
You can just-- two
people, quickly pair,

00:34:28.190 --> 00:34:30.013
do host and resolve.

00:34:30.013 --> 00:34:32.179
And then you're off and
going, and playing laser tag

00:34:32.179 --> 00:34:33.889
with as many of your
friends as possible

00:34:33.889 --> 00:34:36.305
because Cloud Anchors are not
limited just to two devices.

00:34:36.305 --> 00:34:40.070
You can use n number of devices.

00:34:40.070 --> 00:34:42.739
And then shopping--
so how many of you

00:34:42.739 --> 00:34:46.010
guys have bought something and
then had your partner, when

00:34:46.010 --> 00:34:48.230
it actually showed up, veto it?

00:34:48.230 --> 00:34:49.880
Then you had to return it.

00:34:49.880 --> 00:34:51.199
Show of hands.

00:34:51.199 --> 00:34:52.850
Yeah, that's a big pain, right?

00:34:52.850 --> 00:34:55.880
Then you have to go through find
the UPS store, the FedEx store,

00:34:55.880 --> 00:34:56.840
mail it back.

00:34:56.840 --> 00:34:59.650
That's not a good experience.

00:34:59.650 --> 00:35:04.380
It's a lot better if you can
preview it with your partners.

00:35:04.380 --> 00:35:08.730
So now, with Cloud Anchors, if
I'm placing a speaker system

00:35:08.730 --> 00:35:13.290
here, I can have my wife also
look at that speaker system

00:35:13.290 --> 00:35:14.340
from her phone.

00:35:14.340 --> 00:35:18.060
And there's a feeling of
consistency and a feeling

00:35:18.060 --> 00:35:20.570
of trust that you built
if you're the advertiser

00:35:20.570 --> 00:35:22.110
or the e-commerce site--

00:35:22.110 --> 00:35:24.360
that if you have two
users looking at it

00:35:24.360 --> 00:35:26.940
and it shows up consistently
for both of them,

00:35:26.940 --> 00:35:30.210
you build this trust that
the product I'm buying,

00:35:30.210 --> 00:35:32.520
when I'm previewing
it, is actually

00:35:32.520 --> 00:35:34.200
going to look that
way when it shows up.

00:35:34.200 --> 00:35:36.033
Because it's showing
up on multiple devices.

00:35:38.840 --> 00:35:39.340
All right.

00:35:39.340 --> 00:35:41.347
So that's everything
for Cloud Anchors.

00:35:41.347 --> 00:35:42.930
Now, let's talk about
getting started.

00:35:46.600 --> 00:35:51.030
So ARCore, no surprise, already
supports Unity and Unreal,

00:35:51.030 --> 00:35:52.750
your standard game engines.

00:35:52.750 --> 00:35:54.790
And then obviously we
support Android Studio

00:35:54.790 --> 00:35:57.640
for Android Native Development.

00:35:57.640 --> 00:36:02.100
As well, since Cloud
Anchors are cross-platform,

00:36:02.100 --> 00:36:05.130
we provide a SDK so that
you can do your development

00:36:05.130 --> 00:36:07.180
Xcode as well.

00:36:07.180 --> 00:36:10.240
All four of these environments
are live as of yesterday

00:36:10.240 --> 00:36:12.466
at 1:00 PM.

00:36:12.466 --> 00:36:14.354
[APPLAUSE]

00:36:17.660 --> 00:36:19.100
Thank you.

00:36:19.100 --> 00:36:21.830
So for the folks
here at I/O, you guys

00:36:21.830 --> 00:36:24.410
have a bunch of
resources-- or you folks

00:36:24.410 --> 00:36:27.320
have a bunch of resources that
you have at your disposal.

00:36:27.320 --> 00:36:28.970
Please take advantage of them.

00:36:28.970 --> 00:36:31.550
There are three awesome
demos in the Sandbox.

00:36:31.550 --> 00:36:33.560
If you guys liked
playing Light Board,

00:36:33.560 --> 00:36:36.830
and especially if you want
to play Eitan in Light Board,

00:36:36.830 --> 00:36:40.100
our Sandbox is right over
there in the AR Sandbox.

00:36:40.100 --> 00:36:42.380
Eitan will be there up
until somebody beats him.

00:36:42.380 --> 00:36:43.960
Right, Eitan?

00:36:43.960 --> 00:36:44.810
Yeah, thank you.

00:36:47.610 --> 00:36:50.490
We also have the Just a Line
demo over in the Experiments

00:36:50.490 --> 00:36:50.990
Sandbox.

00:36:50.990 --> 00:36:52.290
Please check that out.

00:36:52.290 --> 00:36:55.520
And then the demo that Eitan
showed with this picture

00:36:55.520 --> 00:37:00.140
frame as well as two others are
available in the AR Sandbox.

00:37:00.140 --> 00:37:01.730
It's a really,
really fun exhibit.

00:37:01.730 --> 00:37:03.410
Please go ahead and
play around with it.

00:37:03.410 --> 00:37:06.620
I suspect it'll give you a bunch
of very cool ideas for what

00:37:06.620 --> 00:37:09.200
you can build.

00:37:09.200 --> 00:37:12.590
For Codelabs, we have over
80 workstations set up.

00:37:12.590 --> 00:37:14.060
Please play around with them.

00:37:14.060 --> 00:37:17.524
Every workstation is also
paired with an Android device.

00:37:17.524 --> 00:37:19.190
So not only can you
go through the code,

00:37:19.190 --> 00:37:21.510
but you can actually
compile it onto the phone.

00:37:21.510 --> 00:37:25.760
And then you can see what the
code you just built actually

00:37:25.760 --> 00:37:27.632
works like on a phone.

00:37:27.632 --> 00:37:29.090
And then we also
have office hours.

00:37:29.090 --> 00:37:30.340
Please take advantage of that.

00:37:30.340 --> 00:37:32.810
We have some incredibly
intelligent guru staff

00:37:32.810 --> 00:37:35.390
to answer any
questions you have.

00:37:35.390 --> 00:37:37.380
And then a quick shameless plug.

00:37:37.380 --> 00:37:39.710
Our team, the ARCore
team is incredibly busy

00:37:39.710 --> 00:37:41.660
giving talks this week.

00:37:41.660 --> 00:37:42.979
Please take advantage of those.

00:37:42.979 --> 00:37:45.020
Done an awful lot of work
putting those in to you

00:37:45.020 --> 00:37:47.660
to give you a very
concise explanation.

00:37:47.660 --> 00:37:51.870
There's two more today
and two more tomorrow.

00:37:51.870 --> 00:37:59.220
And then after I/O or
for the folks online,

00:37:59.220 --> 00:38:03.940
developers.google.com/ar
has all the extra resources,

00:38:03.940 --> 00:38:06.700
plus all the Codelabs are
also available on there.

00:38:06.700 --> 00:38:12.940
And again, all four of our SDKs
are available as of yesterday.

00:38:12.940 --> 00:38:14.430
So thank you very much.

00:38:14.430 --> 00:38:16.168
Appreciate your time.

00:38:16.168 --> 00:38:19.334
[MUSIC PLAYING]

