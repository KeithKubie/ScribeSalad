WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.360
 
so what a deep learning have to do the

00:00:02.360 --> 00:00:02.370
so what a deep learning have to do the
 

00:00:02.370 --> 00:00:04.370
so what a deep learning have to do the
brain at the risk of giving away the

00:00:04.370 --> 00:00:04.380
brain at the risk of giving away the
 

00:00:04.380 --> 00:00:06.470
brain at the risk of giving away the
punchline I would say not a whole lot

00:00:06.470 --> 00:00:06.480
punchline I would say not a whole lot
 

00:00:06.480 --> 00:00:08.660
punchline I would say not a whole lot
but let's take a quick look at why

00:00:08.660 --> 00:00:08.670
but let's take a quick look at why
 

00:00:08.670 --> 00:00:10.459
but let's take a quick look at why
people keep making the analogy between

00:00:10.459 --> 00:00:10.469
people keep making the analogy between
 

00:00:10.469 --> 00:00:13.490
people keep making the analogy between
deep learning and the human brain when

00:00:13.490 --> 00:00:13.500
deep learning and the human brain when
 

00:00:13.500 --> 00:00:15.440
deep learning and the human brain when
you implement a neural network this is

00:00:15.440 --> 00:00:15.450
you implement a neural network this is
 

00:00:15.450 --> 00:00:18.590
you implement a neural network this is
what you do for prop and back prop and I

00:00:18.590 --> 00:00:18.600
what you do for prop and back prop and I
 

00:00:18.600 --> 00:00:20.269
what you do for prop and back prop and I
think because it's been difficult to

00:00:20.269 --> 00:00:20.279
think because it's been difficult to
 

00:00:20.279 --> 00:00:22.700
think because it's been difficult to
convey intuitions about what these

00:00:22.700 --> 00:00:22.710
convey intuitions about what these
 

00:00:22.710 --> 00:00:24.560
convey intuitions about what these
equations are doing really great and

00:00:24.560 --> 00:00:24.570
equations are doing really great and
 

00:00:24.570 --> 00:00:27.140
equations are doing really great and
descends on a very complex function the

00:00:27.140 --> 00:00:27.150
descends on a very complex function the
 

00:00:27.150 --> 00:00:29.720
descends on a very complex function the
analogy that is like the brain has

00:00:29.720 --> 00:00:29.730
analogy that is like the brain has
 

00:00:29.730 --> 00:00:32.389
analogy that is like the brain has
become really an oversimplified

00:00:32.389 --> 00:00:32.399
become really an oversimplified
 

00:00:32.399 --> 00:00:34.430
become really an oversimplified
explanation for what this is doing but

00:00:34.430 --> 00:00:34.440
explanation for what this is doing but
 

00:00:34.440 --> 00:00:36.650
explanation for what this is doing but
the simplicity of this makes it you know

00:00:36.650 --> 00:00:36.660
the simplicity of this makes it you know
 

00:00:36.660 --> 00:00:39.139
the simplicity of this makes it you know
kind of seductive for people to just say

00:00:39.139 --> 00:00:39.149
kind of seductive for people to just say
 

00:00:39.149 --> 00:00:41.389
kind of seductive for people to just say
it publicly as well as the media to

00:00:41.389 --> 00:00:41.399
it publicly as well as the media to
 

00:00:41.399 --> 00:00:43.280
it publicly as well as the media to
report it and certainly called the

00:00:43.280 --> 00:00:43.290
report it and certainly called the
 

00:00:43.290 --> 00:00:45.889
report it and certainly called the
popular imagination and there is a very

00:00:45.889 --> 00:00:45.899
popular imagination and there is a very
 

00:00:45.899 --> 00:00:48.459
popular imagination and there is a very
loose analogy between let's say a

00:00:48.459 --> 00:00:48.469
loose analogy between let's say a
 

00:00:48.469 --> 00:00:51.770
loose analogy between let's say a
logistic regression unit with a sigmoid

00:00:51.770 --> 00:00:51.780
logistic regression unit with a sigmoid
 

00:00:51.780 --> 00:00:55.939
logistic regression unit with a sigmoid
activation function and here's a cartoon

00:00:55.939 --> 00:00:55.949
activation function and here's a cartoon
 

00:00:55.949 --> 00:00:58.580
activation function and here's a cartoon
of a single neuron in the brain in this

00:00:58.580 --> 00:00:58.590
of a single neuron in the brain in this
 

00:00:58.590 --> 00:01:01.880
of a single neuron in the brain in this
picture of a biological neuron on this

00:01:01.880 --> 00:01:01.890
picture of a biological neuron on this
 

00:01:01.890 --> 00:01:03.590
picture of a biological neuron on this
neuron which is a cell in your brain

00:01:03.590 --> 00:01:03.600
neuron which is a cell in your brain
 

00:01:03.600 --> 00:01:06.320
neuron which is a cell in your brain
receives electric signals from you know

00:01:06.320 --> 00:01:06.330
receives electric signals from you know
 

00:01:06.330 --> 00:01:09.410
receives electric signals from you know
other neurons mu X 1 X 2 X 3 or maybe

00:01:09.410 --> 00:01:09.420
other neurons mu X 1 X 2 X 3 or maybe
 

00:01:09.420 --> 00:01:12.289
other neurons mu X 1 X 2 X 3 or maybe
from other neurons a 1 a 2 a 3 there's a

00:01:12.289 --> 00:01:12.299
from other neurons a 1 a 2 a 3 there's a
 

00:01:12.299 --> 00:01:15.109
from other neurons a 1 a 2 a 3 there's a
simple thresholded computation and then

00:01:15.109 --> 00:01:15.119
simple thresholded computation and then
 

00:01:15.119 --> 00:01:17.840
simple thresholded computation and then
if this neuron fires it sends a pulse of

00:01:17.840 --> 00:01:17.850
if this neuron fires it sends a pulse of
 

00:01:17.850 --> 00:01:20.690
if this neuron fires it sends a pulse of
electricity down the axon down this long

00:01:20.690 --> 00:01:20.700
electricity down the axon down this long
 

00:01:20.700 --> 00:01:23.630
electricity down the axon down this long
wire I have two other neurons so there

00:01:23.630 --> 00:01:23.640
wire I have two other neurons so there
 

00:01:23.640 --> 00:01:27.469
wire I have two other neurons so there
is a very simplistic analogy between a

00:01:27.469 --> 00:01:27.479
is a very simplistic analogy between a
 

00:01:27.479 --> 00:01:29.569
is a very simplistic analogy between a
single logistic unit between a single

00:01:29.569 --> 00:01:29.579
single logistic unit between a single
 

00:01:29.579 --> 00:01:32.179
single logistic unit between a single
neuron and your network and a biological

00:01:32.179 --> 00:01:32.189
neuron and your network and a biological
 

00:01:32.189 --> 00:01:35.090
neuron and your network and a biological
neuron like that shown on a right but I

00:01:35.090 --> 00:01:35.100
neuron like that shown on a right but I
 

00:01:35.100 --> 00:01:37.490
neuron like that shown on a right but I
think that today even neuroscientists

00:01:37.490 --> 00:01:37.500
think that today even neuroscientists
 

00:01:37.500 --> 00:01:40.160
think that today even neuroscientists
have almost no idea what even a single

00:01:40.160 --> 00:01:40.170
have almost no idea what even a single
 

00:01:40.170 --> 00:01:42.710
have almost no idea what even a single
neuron is doing a single neuron appears

00:01:42.710 --> 00:01:42.720
neuron is doing a single neuron appears
 

00:01:42.720 --> 00:01:44.690
neuron is doing a single neuron appears
to be much more complex than we are able

00:01:44.690 --> 00:01:44.700
to be much more complex than we are able
 

00:01:44.700 --> 00:01:48.080
to be much more complex than we are able
to characterize with neuroscience and

00:01:48.080 --> 00:01:48.090
to characterize with neuroscience and
 

00:01:48.090 --> 00:01:50.690
to characterize with neuroscience and
while some of what is doing is a little

00:01:50.690 --> 00:01:50.700
while some of what is doing is a little
 

00:01:50.700 --> 00:01:53.210
while some of what is doing is a little
bit like logistic regression there's

00:01:53.210 --> 00:01:53.220
bit like logistic regression there's
 

00:01:53.220 --> 00:01:55.069
bit like logistic regression there's
still a lot about what even a single

00:01:55.069 --> 00:01:55.079
still a lot about what even a single
 

00:01:55.079 --> 00:01:57.380
still a lot about what even a single
neuron does that no one then no human

00:01:57.380 --> 00:01:57.390
neuron does that no one then no human
 

00:01:57.390 --> 00:02:00.260
neuron does that no one then no human
today understands for example exactly

00:02:00.260 --> 00:02:00.270
today understands for example exactly
 

00:02:00.270 --> 00:02:01.969
today understands for example exactly
how neurons in the human brain learn

00:02:01.969 --> 00:02:01.979
how neurons in the human brain learn
 

00:02:01.979 --> 00:02:04.890
how neurons in the human brain learn
this is still a very mysterious process

00:02:04.890 --> 00:02:04.900
this is still a very mysterious process
 

00:02:04.900 --> 00:02:07.170
this is still a very mysterious process
and it's completely unclear today

00:02:07.170 --> 00:02:07.180
and it's completely unclear today
 

00:02:07.180 --> 00:02:08.969
and it's completely unclear today
whether the human brain uses an

00:02:08.969 --> 00:02:08.979
whether the human brain uses an
 

00:02:08.979 --> 00:02:10.410
whether the human brain uses an
algorithm does anything like back

00:02:10.410 --> 00:02:10.420
algorithm does anything like back
 

00:02:10.420 --> 00:02:12.300
algorithm does anything like back
propagation or gradient descent or if

00:02:12.300 --> 00:02:12.310
propagation or gradient descent or if
 

00:02:12.310 --> 00:02:14.220
propagation or gradient descent or if
there's some fundamentally different

00:02:14.220 --> 00:02:14.230
there's some fundamentally different
 

00:02:14.230 --> 00:02:16.620
there's some fundamentally different
learning principle that the human brain

00:02:16.620 --> 00:02:16.630
learning principle that the human brain
 

00:02:16.630 --> 00:02:20.610
learning principle that the human brain
uses so when I think of deep learning I

00:02:20.610 --> 00:02:20.620
uses so when I think of deep learning I
 

00:02:20.620 --> 00:02:22.980
uses so when I think of deep learning I
think of it as being very good and

00:02:22.980 --> 00:02:22.990
think of it as being very good and
 

00:02:22.990 --> 00:02:25.260
think of it as being very good and
learning very sectional functions very

00:02:25.260 --> 00:02:25.270
learning very sectional functions very
 

00:02:25.270 --> 00:02:28.410
learning very sectional functions very
complex functions to learn X to Y

00:02:28.410 --> 00:02:28.420
complex functions to learn X to Y
 

00:02:28.420 --> 00:02:30.450
complex functions to learn X to Y
mappings to learn input-output mappings

00:02:30.450 --> 00:02:30.460
mappings to learn input-output mappings
 

00:02:30.460 --> 00:02:33.630
mappings to learn input-output mappings
in supervised learning and whereas D is

00:02:33.630 --> 00:02:33.640
in supervised learning and whereas D is
 

00:02:33.640 --> 00:02:35.790
in supervised learning and whereas D is
like the brain analogy maybe that was

00:02:35.790 --> 00:02:35.800
like the brain analogy maybe that was
 

00:02:35.800 --> 00:02:38.610
like the brain analogy maybe that was
useful once I think the field has moved

00:02:38.610 --> 00:02:38.620
useful once I think the field has moved
 

00:02:38.620 --> 00:02:40.800
useful once I think the field has moved
to the point where that analogy is

00:02:40.800 --> 00:02:40.810
to the point where that analogy is
 

00:02:40.810 --> 00:02:43.140
to the point where that analogy is
breaking down and I tend not to use that

00:02:43.140 --> 00:02:43.150
breaking down and I tend not to use that
 

00:02:43.150 --> 00:02:46.500
breaking down and I tend not to use that
analogy much anymore so that's it for

00:02:46.500 --> 00:02:46.510
analogy much anymore so that's it for
 

00:02:46.510 --> 00:02:49.050
analogy much anymore so that's it for
neural networks and the brain um I do

00:02:49.050 --> 00:02:49.060
neural networks and the brain um I do
 

00:02:49.060 --> 00:02:50.700
neural networks and the brain um I do
think that the good field of computer

00:02:50.700 --> 00:02:50.710
think that the good field of computer
 

00:02:50.710 --> 00:02:53.250
think that the good field of computer
vision has taken a bit more inspiration

00:02:53.250 --> 00:02:53.260
vision has taken a bit more inspiration
 

00:02:53.260 --> 00:02:55.500
vision has taken a bit more inspiration
from human brains and other disciplines

00:02:55.500 --> 00:02:55.510
from human brains and other disciplines
 

00:02:55.510 --> 00:02:57.900
from human brains and other disciplines
that also apply deep learning but I

00:02:57.900 --> 00:02:57.910
that also apply deep learning but I
 

00:02:57.910 --> 00:03:00.270
that also apply deep learning but I
personally use the analogy you know to

00:03:00.270 --> 00:03:00.280
personally use the analogy you know to
 

00:03:00.280 --> 00:03:02.060
personally use the analogy you know to
the human brain less than I used to

00:03:02.060 --> 00:03:02.070
the human brain less than I used to
 

00:03:02.070 --> 00:03:05.730
the human brain less than I used to
so that's it for this video you now know

00:03:05.730 --> 00:03:05.740
so that's it for this video you now know
 

00:03:05.740 --> 00:03:07.830
so that's it for this video you now know
how to implement for prop and back prop

00:03:07.830 --> 00:03:07.840
how to implement for prop and back prop
 

00:03:07.840 --> 00:03:09.870
how to implement for prop and back prop
in gradient descent even for deep neural

00:03:09.870 --> 00:03:09.880
in gradient descent even for deep neural
 

00:03:09.880 --> 00:03:12.060
in gradient descent even for deep neural
networks best of luck with the pro

00:03:12.060 --> 00:03:12.070
networks best of luck with the pro
 

00:03:12.070 --> 00:03:14.070
networks best of luck with the pro
exercise and I look forward to sharing

00:03:14.070 --> 00:03:14.080
exercise and I look forward to sharing
 

00:03:14.080 --> 00:03:16.320
exercise and I look forward to sharing
more of these ideas of you in the second

00:03:16.320 --> 00:03:16.330
more of these ideas of you in the second
 

00:03:16.330 --> 00:03:18.510
more of these ideas of you in the second
course

