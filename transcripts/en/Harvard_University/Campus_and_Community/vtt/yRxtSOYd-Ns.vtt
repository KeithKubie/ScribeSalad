WEBVTT
Kind: captions
Language: en

00:00:10.880 --> 00:00:12.644
Good morning everybody.

00:00:12.644 --> 00:00:13.310
I'm Judy Singer.

00:00:13.310 --> 00:00:15.160
I'm the senior vice provost
for faculty development

00:00:15.160 --> 00:00:15.780
and diversity.

00:00:15.780 --> 00:00:18.870
And I want to thank you all
for coming to this event

00:00:18.870 --> 00:00:21.950
to talk about the
faculty search process

00:00:21.950 --> 00:00:26.285
and how research in decision
making and in social psychology

00:00:26.285 --> 00:00:30.290
and in economics can help
us understand better how

00:00:30.290 --> 00:00:34.332
we choose, why we choose, and
how we think and sometimes

00:00:34.332 --> 00:00:36.790
unconsciously don't think about
what we're doing when we're

00:00:36.790 --> 00:00:39.180
doing a faculty search.

00:00:39.180 --> 00:00:41.390
First I want to start out
by thanking everybody here

00:00:41.390 --> 00:00:43.310
who's serving on a
faculty search committee

00:00:43.310 --> 00:00:45.580
or is otherwise involved
in faculty searches, which

00:00:45.580 --> 00:00:47.560
is everyone in the room.

00:00:47.560 --> 00:00:50.030
I would say that the
identification of the Harvard

00:00:50.030 --> 00:00:53.780
faculty of the future is one the
most important things that we

00:00:53.780 --> 00:00:54.560
do.

00:00:54.560 --> 00:00:57.830
And it gives us the opportunity
to reshape the Harvard faculty,

00:00:57.830 --> 00:01:00.400
to think about what kinds
of exciting new directions

00:01:00.400 --> 00:01:02.930
we want to strike out in and
what kinds of bench strength

00:01:02.930 --> 00:01:05.220
do we want to reinforce.

00:01:05.220 --> 00:01:07.510
The reality is that
faculty searches

00:01:07.510 --> 00:01:10.100
are incredibly time consuming.

00:01:10.100 --> 00:01:11.590
I think that anybody
who's chaired

00:01:11.590 --> 00:01:13.117
a search, at the
end of the process,

00:01:13.117 --> 00:01:15.450
would probably say it's about
the equivalent of teaching

00:01:15.450 --> 00:01:16.510
a course.

00:01:16.510 --> 00:01:18.930
It requires an enormous
amount of effort.

00:01:18.930 --> 00:01:21.750
And we thank you for
your commitment to that.

00:01:21.750 --> 00:01:23.960
And it's also why
generations of Harvard

00:01:23.960 --> 00:01:27.480
faculty before you sat on
searches that lead to you.

00:01:27.480 --> 00:01:29.630
So you can think that
you're basically paying it

00:01:29.630 --> 00:01:32.750
backwards or forwards for
people who did for you what

00:01:32.750 --> 00:01:33.975
you're doing for the future.

00:01:33.975 --> 00:01:36.600
And it's also why the president
and provost review every tenure

00:01:36.600 --> 00:01:37.770
appointment at the University.

00:01:37.770 --> 00:01:39.478
They have a lot of
things on their plate.

00:01:39.478 --> 00:01:41.550
And the fact that they
take the time to do that

00:01:41.550 --> 00:01:44.420
speaks to the importance
of faculty searches.

00:01:44.420 --> 00:01:45.920
I want to say a
word about diversity

00:01:45.920 --> 00:01:47.570
and how we think about it.

00:01:47.570 --> 00:01:50.040
I think it's fair to say
that a diverse faculty is

00:01:50.040 --> 00:01:51.680
a strong faculty.

00:01:51.680 --> 00:01:55.100
And it emerges from the broadest
consideration of talent.

00:01:55.100 --> 00:01:58.000
If you think about the
students that you're teaching,

00:01:58.000 --> 00:01:59.490
you will always
note that they are

00:01:59.490 --> 00:02:01.500
more diverse than your
faculty colleagues

00:02:01.500 --> 00:02:03.270
in a faculty meeting.

00:02:03.270 --> 00:02:06.300
The broader the pool that
you work from, the better

00:02:06.300 --> 00:02:08.440
chance you're going to
have to find the faculty

00:02:08.440 --> 00:02:11.950
members of the future that
you're really looking for.

00:02:11.950 --> 00:02:14.960
A lot of people think diversity
is a sort of newfangled topic

00:02:14.960 --> 00:02:18.640
that we're just talking
about in the last few years.

00:02:18.640 --> 00:02:22.480
But in fact diversity has been a
topic about the Harvard faculty

00:02:22.480 --> 00:02:23.990
for quite some time.

00:02:23.990 --> 00:02:25.730
This quote, which
I will read, comes

00:02:25.730 --> 00:02:30.230
from a report was issued in 1938
called the Committee of Eight.

00:02:30.230 --> 00:02:32.760
And if anybody
wonders what gave rise

00:02:32.760 --> 00:02:34.670
to the ad hoc tenure
review process,

00:02:34.670 --> 00:02:36.190
it's not from time in memoriam.

00:02:36.190 --> 00:02:38.440
It was a recommendation
of this Committee of Eight

00:02:38.440 --> 00:02:41.000
that reported to
President Conant

00:02:41.000 --> 00:02:43.490
that we needed new
procedures for identifying

00:02:43.490 --> 00:02:46.340
the faculty of the future.

00:02:46.340 --> 00:02:48.300
The entire report talks
about faculty search

00:02:48.300 --> 00:02:50.860
processes in the early
part of the century.

00:02:50.860 --> 00:02:53.870
The appendix, there's
a section on diversity.

00:02:53.870 --> 00:02:56.440
It's not about the diversity
that we're used to reading.

00:02:56.440 --> 00:02:59.000
And I'll read this to you.

00:02:59.000 --> 00:03:01.800
"It is a common opinion
that Jews, regardless

00:03:01.800 --> 00:03:03.280
of their qualifications,
have found

00:03:03.280 --> 00:03:04.960
it increasingly
difficult to obtain

00:03:04.960 --> 00:03:07.320
academic posts in America.

00:03:07.320 --> 00:03:09.810
At Harvard, some of the
most distinguished members

00:03:09.810 --> 00:03:13.570
of its faculty, past and
present, have been Jews.

00:03:13.570 --> 00:03:15.257
The extent to which
antisemitic bias

00:03:15.257 --> 00:03:17.590
has come to operate in the
making of junior appointments

00:03:17.590 --> 00:03:19.780
is difficult to assess.

00:03:19.780 --> 00:03:22.340
Those who raise the issue
seemed in agreement,

00:03:22.340 --> 00:03:25.470
to use the words of one of
them, 'that racial prejudice is

00:03:25.470 --> 00:03:28.850
so thoroughly ingrained and
taken for granted that no one

00:03:28.850 --> 00:03:31.620
takes much notice of it except
in particularly flagrant

00:03:31.620 --> 00:03:34.480
cases.' The committee is
informed that certain members

00:03:34.480 --> 00:03:36.860
of the faculty object to
the appointment of Jews

00:03:36.860 --> 00:03:39.400
to the tutorial staff in
the belief that they are

00:03:39.400 --> 00:03:41.740
unacceptable to undergraduates."

00:03:41.740 --> 00:03:44.080
And the report goes on and
basically makes a statement

00:03:44.080 --> 00:03:46.810
about the value of
diversity and says,

00:03:46.810 --> 00:03:49.490
"conscious or
unconscious antisemitism

00:03:49.490 --> 00:03:52.350
would be a betrayal to the best
traditions of the university."

00:03:52.350 --> 00:03:54.330
It's rather remarkable
in 1938 they were

00:03:54.330 --> 00:03:56.460
talking about unconscious bias.

00:03:56.460 --> 00:03:58.910
That was an interesting
way of framing it.

00:03:58.910 --> 00:04:01.600
I wish this problem went away.

00:04:01.600 --> 00:04:06.390
But this is from a search
committee report last year.

00:04:06.390 --> 00:04:08.211
This is a direct
quote from the report.

00:04:08.211 --> 00:04:09.710
And there are quotes
embedded in it.

00:04:09.710 --> 00:04:12.990
So this is a quote from
somebody in the report.

00:04:12.990 --> 00:04:15.240
"The following anecdote
makes me a bit unsure

00:04:15.240 --> 00:04:17.430
about my and our judgment.

00:04:17.430 --> 00:04:19.160
The last African
American candidate

00:04:19.160 --> 00:04:22.110
we had was Y. The
consensus was that she

00:04:22.110 --> 00:04:24.390
did a very poor job
of fielding questions,

00:04:24.390 --> 00:04:27.540
and we wondered about
her quality of mind.

00:04:27.540 --> 00:04:29.250
Her paper has now
been published in--"

00:04:29.250 --> 00:04:30.749
I'm not naming the
journal, but it's

00:04:30.749 --> 00:04:32.430
a top journal in the field.

00:04:32.430 --> 00:04:34.940
"Clearly she's been a very
successful academic since"

00:04:34.940 --> 00:04:36.360
she went to Yale.

00:04:36.360 --> 00:04:39.130
"And with hindsight, I wish
we'd made her an offer.

00:04:39.130 --> 00:04:42.570
I wonder whether we're in a
similar situation with X,"

00:04:42.570 --> 00:04:44.294
the candidate they're
considering now.

00:04:44.294 --> 00:04:46.835
"The committee sought to remove
the weighting of presentation

00:04:46.835 --> 00:04:49.157
in its deliberations,
but still felt

00:04:49.157 --> 00:04:50.740
that there was
significant uncertainty

00:04:50.740 --> 00:04:52.930
about X's future trajectory.

00:04:52.930 --> 00:04:55.880
We therefore do not
recommend proceeding with X,

00:04:55.880 --> 00:04:57.730
but we would strongly
urge the school

00:04:57.730 --> 00:05:01.360
to go back and reconsider Y,"
who oh by the way we rejected

00:05:01.360 --> 00:05:02.390
two years ago.

00:05:02.390 --> 00:05:05.260
And X is at the University of
Chicago and doing quite well.

00:05:08.217 --> 00:05:10.300
This is a conversation I
had with an academic dean

00:05:10.300 --> 00:05:11.469
last week.

00:05:11.469 --> 00:05:13.510
"I met with--" this is
the academic dean's voice.

00:05:13.510 --> 00:05:15.843
"I met with the department
to discuss the two finalists,

00:05:15.843 --> 00:05:18.496
X and Y. A distinguished
member of the department not

00:05:18.496 --> 00:05:20.120
on the search committee
raised his hand

00:05:20.120 --> 00:05:22.310
and said, 'I have
serious concerns

00:05:22.310 --> 00:05:24.470
about the process
in this search.

00:05:24.470 --> 00:05:26.540
This short list makes
it clear that the search

00:05:26.540 --> 00:05:28.510
was referring to start.

00:05:28.510 --> 00:05:34.230
How else could the two finalists
be female?'" That's last week.

00:05:34.230 --> 00:05:37.540
So clearly there
are issues about how

00:05:37.540 --> 00:05:40.910
we search for faculty, how we
think about what we're doing,

00:05:40.910 --> 00:05:43.540
and how we can do better
what we're trying to do,

00:05:43.540 --> 00:05:45.970
which is build an
outstanding faculty.

00:05:45.970 --> 00:05:48.750
The genesis for today's
event came from a topic

00:05:48.750 --> 00:05:50.880
that Sheena Iyengar,
one of our panelists,

00:05:50.880 --> 00:05:53.610
gave last year at the
Kennedy School on her book

00:05:53.610 --> 00:05:54.542
The Art of Choosing.

00:05:54.542 --> 00:05:57.000
And in fact she is giving a
public lecture at the Radcliffe

00:05:57.000 --> 00:05:59.530
Institute later today if you're
interested in learning more

00:05:59.530 --> 00:06:01.270
about it.

00:06:01.270 --> 00:06:02.330
The talk was wonderful.

00:06:02.330 --> 00:06:04.060
I encourage you
to go to her talk.

00:06:04.060 --> 00:06:08.590
And at dinner, with a whole
bunch of decision scientists,

00:06:08.590 --> 00:06:11.320
I throw out the question, "How
does your work on decision

00:06:11.320 --> 00:06:14.586
science have a role in how we
think about faculty searches?"

00:06:14.586 --> 00:06:16.460
And it was an incredibly
lively conversation.

00:06:16.460 --> 00:06:18.760
It's what led to
the event today.

00:06:18.760 --> 00:06:20.420
Decisions about
faculty recruitment

00:06:20.420 --> 00:06:23.560
are fundamentally multivariate--
there are lots of dimensions--

00:06:23.560 --> 00:06:25.130
and continuous.

00:06:25.130 --> 00:06:26.720
It's not a black
and white situation.

00:06:26.720 --> 00:06:29.530
But in the end, we have to
make a yes or no decision

00:06:29.530 --> 00:06:30.930
about a particular candidate.

00:06:30.930 --> 00:06:34.226
And so it's a very
difficult problem space.

00:06:34.226 --> 00:06:35.600
So the kinds of
things that we've

00:06:35.600 --> 00:06:37.290
asked our panelists
to talk about today

00:06:37.290 --> 00:06:40.350
are what makes for the most
effective search committee.

00:06:40.350 --> 00:06:43.534
Should search committees develop
selection criteria in advance,

00:06:43.534 --> 00:06:45.950
because after all, don't faculty
members know good faculty

00:06:45.950 --> 00:06:46.820
when they see them?

00:06:46.820 --> 00:06:49.580
There is this sense that you
already know how to do this.

00:06:49.580 --> 00:06:51.470
Do cultural factors
really play a role?

00:06:51.470 --> 00:06:54.810
Aren't smart people able to
guard against unconscious bias?

00:06:54.810 --> 00:06:56.880
And how do we deal with
search committee dynamics

00:06:56.880 --> 00:06:59.840
and the conflicts
that inevitably rise?

00:06:59.840 --> 00:07:03.820
And how do we reach consensus
on a decision making process?

00:07:03.820 --> 00:07:09.970
I'm going to introduce the
three panelists on your right--

00:07:09.970 --> 00:07:12.320
OK, my right there.

00:07:12.320 --> 00:07:15.150
Sheena Iyengar, who is the
ST Lee Professor of Business

00:07:15.150 --> 00:07:16.350
at Columbia Business School.

00:07:16.350 --> 00:07:20.120
She has a 1997 PhD in social
psychology from Stanford.

00:07:20.120 --> 00:07:22.220
And as I mentioned
her recent book,

00:07:22.220 --> 00:07:24.440
bestselling book,
The Art of Choosing,

00:07:24.440 --> 00:07:26.580
examines a whole set of
questions about choice--

00:07:26.580 --> 00:07:29.370
how we make choices, the
relationship between how

00:07:29.370 --> 00:07:33.010
we choose and who we are,
how we are influences that,

00:07:33.010 --> 00:07:36.700
why we're often so
disappointed in our choices,

00:07:36.700 --> 00:07:40.090
and how much control do
we really have over them.

00:07:40.090 --> 00:07:42.000
In the middle is
Iris Bohnet, who

00:07:42.000 --> 00:07:44.369
is a Professor of Public
Policy at Harvard and Director

00:07:44.369 --> 00:07:46.660
of the Harvard Kennedy School's
Women and Public Policy

00:07:46.660 --> 00:07:47.460
Program.

00:07:47.460 --> 00:07:51.390
A 1997 PhD in economics from
the University of Zurich.

00:07:51.390 --> 00:07:53.930
Iris's research
combines insights

00:07:53.930 --> 00:07:56.810
from economics and psychology.

00:07:56.810 --> 00:08:00.160
Historically her work is focused
on trust and its determinants,

00:08:00.160 --> 00:08:02.280
and its relevance for
negotiation and decision

00:08:02.280 --> 00:08:03.070
making.

00:08:03.070 --> 00:08:05.153
More recently-- and she's
going to talk about some

00:08:05.153 --> 00:08:08.430
of more recent work-- she
has been focusing on choice

00:08:08.430 --> 00:08:12.600
architecture and
knowledge, how outcomes

00:08:12.600 --> 00:08:16.830
can be influenced by little
small things in processes.

00:08:16.830 --> 00:08:19.770
And finally on the far
right, Mahzarin Banaji,

00:08:19.770 --> 00:08:23.480
Richard Clarke Professor of
Social Ethics in our Psychology

00:08:23.480 --> 00:08:26.710
Department, and
also Senior Advisor

00:08:26.710 --> 00:08:29.640
to the FAS dean on
faculty development.

00:08:29.640 --> 00:08:33.480
Mahzarin has a 1986 PhD from
Ohio State in psychology.

00:08:33.480 --> 00:08:35.070
And she studies
the mental systems

00:08:35.070 --> 00:08:37.980
that operate in implicit
or unconscious mode.

00:08:37.980 --> 00:08:40.390
In particular, she's interested
in the unconscious nature

00:08:40.390 --> 00:08:42.849
of assessments in self
and other humans that

00:08:42.849 --> 00:08:45.140
reflect feelings and knowledge
about their social group

00:08:45.140 --> 00:08:46.470
membership.

00:08:46.470 --> 00:08:49.202
In her new role, Mahzarin
is working very closely

00:08:49.202 --> 00:08:51.660
with the dean of faculty of
Arts and Sciences, very closely

00:08:51.660 --> 00:08:55.450
with me and my office, on
trying to identify and challenge

00:08:55.450 --> 00:08:58.100
any barriers that stand
in the way of achieving

00:08:58.100 --> 00:09:01.360
our goal of having the
most outstanding faculty.

00:09:01.360 --> 00:09:04.030
The game plan is that Sheena
and Iris will each speak

00:09:04.030 --> 00:09:05.440
for about 20 minutes.

00:09:05.440 --> 00:09:07.740
And Mahzarin will make
some concluding remarks

00:09:07.740 --> 00:09:09.430
and will moderate
the discussion.

00:09:09.430 --> 00:09:13.670
So with that, let me turn
it over to Sheena Iyengar.

00:09:13.670 --> 00:09:16.640
[APPLAUSE]

00:09:19.610 --> 00:09:22.085
Hello everyone.

00:09:22.085 --> 00:09:27.250
So when I got this
email from Judy saying,

00:09:27.250 --> 00:09:29.930
will you come and speak
to the various search

00:09:29.930 --> 00:09:35.110
committees at Harvard about how
to improve the academic hiring

00:09:35.110 --> 00:09:39.530
decision making process--
I'm looking at this email

00:09:39.530 --> 00:09:42.840
and extremely intimidated
by this email.

00:09:42.840 --> 00:09:45.830
Do I really know enough
to make suggestions

00:09:45.830 --> 00:09:48.930
about how to improve academic
hiring decision making

00:09:48.930 --> 00:09:50.570
processes?

00:09:50.570 --> 00:09:53.720
At the same time, I was
a bit intrigued by this,

00:09:53.720 --> 00:09:55.760
by the daunting exercise.

00:09:55.760 --> 00:09:59.260
Because as a member of the
decision making research

00:09:59.260 --> 00:10:02.855
community, certainly I'm
aware of the various biases

00:10:02.855 --> 00:10:05.990
and things that affect our
decisions, whether we're hiring

00:10:05.990 --> 00:10:07.760
or whatever decision
we're making.

00:10:07.760 --> 00:10:10.650
And we're not always proud
when we see the kinds of things

00:10:10.650 --> 00:10:13.140
that bear out in the results.

00:10:13.140 --> 00:10:15.543
And then at the
same time, I've sat

00:10:15.543 --> 00:10:17.570
on a number of different
search committees,

00:10:17.570 --> 00:10:19.920
and now sit on the
P and T and keep

00:10:19.920 --> 00:10:22.040
wondering to myself,
how do we improve this?

00:10:22.040 --> 00:10:24.880
I mean, how do we debias
everybody so that we actually

00:10:24.880 --> 00:10:27.900
make the best choices?

00:10:27.900 --> 00:10:33.400
If you look at the research,
I couldn't find a single study

00:10:33.400 --> 00:10:38.260
that actually looked at academic
hiring decision processes that

00:10:38.260 --> 00:10:42.784
documented the various things
that we do during that process,

00:10:42.784 --> 00:10:44.450
although there is a
lot of research that

00:10:44.450 --> 00:10:48.860
looks at hiring decision
making processes in general.

00:10:48.860 --> 00:10:53.560
And as a quick sort of
thumbnail summary of that,

00:10:53.560 --> 00:10:56.560
we see that we make mistakes
every step of the way

00:10:56.560 --> 00:10:58.790
in terms of how we go about it.

00:10:58.790 --> 00:11:01.990
When we look at resumes
and collect resumes,

00:11:01.990 --> 00:11:06.070
white people are 50% more
likely to get an interview

00:11:06.070 --> 00:11:07.890
than African Americans.

00:11:07.890 --> 00:11:10.760
Men are more likely to get
hired for certain positions

00:11:10.760 --> 00:11:13.780
or considered for certain
positions than our women.

00:11:13.780 --> 00:11:17.752
Turns out that the actual
sound of your name and letters

00:11:17.752 --> 00:11:19.210
that make up your
name can actually

00:11:19.210 --> 00:11:21.043
make a difference in
terms of whether you're

00:11:21.043 --> 00:11:25.060
likely to be hired or not or
at least interviewed or not.

00:11:25.060 --> 00:11:27.390
Then when you look at the
actual interview process,

00:11:27.390 --> 00:11:29.720
there's all kinds of
studies that show us things

00:11:29.720 --> 00:11:33.310
that we're not quite happy when
we read about that might affect

00:11:33.310 --> 00:11:36.140
this like the strength
of someone's handshake

00:11:36.140 --> 00:11:37.570
could make a difference.

00:11:37.570 --> 00:11:40.370
The first impression you make
in the first minute, perhaps

00:11:40.370 --> 00:11:43.880
plus or minus 30 seconds, the
overall 30 minute interview

00:11:43.880 --> 00:11:46.670
or, you can imagine,
job talk can actually

00:11:46.670 --> 00:11:49.110
affect what you
think of this person.

00:11:49.110 --> 00:11:52.200
And studies have shown, at
least in private industry,

00:11:52.200 --> 00:11:54.770
that in fact we tend to
overweight those interviews

00:11:54.770 --> 00:11:56.850
and think that they're
much more diagnostic

00:11:56.850 --> 00:12:00.980
of our performance in the
long run than they really are.

00:12:00.980 --> 00:12:03.330
And that in general when it
comes down to interviews,

00:12:03.330 --> 00:12:06.250
we tend to like and hire
those people that remind us

00:12:06.250 --> 00:12:08.390
of ourselves, have
similar attitudes,

00:12:08.390 --> 00:12:10.450
are demographically
more similar to us,

00:12:10.450 --> 00:12:14.480
maybe have similar
personalities to us.

00:12:14.480 --> 00:12:18.910
Now I look at all this
research and realize oh my god,

00:12:18.910 --> 00:12:21.230
there's all these mistakes
that we might be making.

00:12:21.230 --> 00:12:23.320
And then I try to debias myself.

00:12:23.320 --> 00:12:26.590
And that becomes a rather
daunting, intimidating task,

00:12:26.590 --> 00:12:28.990
particularly given that
so many of these biases

00:12:28.990 --> 00:12:31.800
happen to us at a rather
subconscious level.

00:12:31.800 --> 00:12:34.020
Can I really debias
myself and make

00:12:34.020 --> 00:12:36.660
sure that I'm not
going to be affected

00:12:36.660 --> 00:12:39.350
by, say, the compliment
that this person gave me

00:12:39.350 --> 00:12:40.540
that sounded so genuine?

00:12:40.540 --> 00:12:44.170
I mean, aren't I
human in the end?

00:12:44.170 --> 00:12:47.030
A few years ago when my
colleagues and I-- and many

00:12:47.030 --> 00:12:49.180
of my colleagues were
social psychologists--

00:12:49.180 --> 00:12:53.760
and I got together, and
we're trying to put together

00:12:53.760 --> 00:12:57.310
the decision making module
for our core course in the MBA

00:12:57.310 --> 00:13:00.490
program in
organizational behavior,

00:13:00.490 --> 00:13:02.320
we thought about
how were we going

00:13:02.320 --> 00:13:05.890
to teach our students about
decision making policies

00:13:05.890 --> 00:13:07.330
and how to counteract act.

00:13:07.330 --> 00:13:11.220
And we showed them all
different exercises

00:13:11.220 --> 00:13:13.785
in which we make them
aware of the various biases

00:13:13.785 --> 00:13:15.320
that they engage in.

00:13:15.320 --> 00:13:17.930
But then we wanted to
give them an exercise that

00:13:17.930 --> 00:13:20.950
felt more real, that was the
kind of exercise they would

00:13:20.950 --> 00:13:23.450
be doing in their
real jobs, and also

00:13:23.450 --> 00:13:26.590
be able to give them some sort
of heuristics or guidelines

00:13:26.590 --> 00:13:30.700
on how they could
improve upon that.

00:13:30.700 --> 00:13:32.900
In a nutshell, what
I'm going to show

00:13:32.900 --> 00:13:36.600
you is an exercise
which we designed.

00:13:36.600 --> 00:13:40.560
And in the designing of that
exercise, what we sort of took

00:13:40.560 --> 00:13:42.690
a position as
being is we decided

00:13:42.690 --> 00:13:46.380
that it was unrealistic to
take the stand that we're

00:13:46.380 --> 00:13:50.280
going to make every single
individual debiased.

00:13:50.280 --> 00:13:52.820
We assume that
they'll all be biased.

00:13:52.820 --> 00:13:56.930
But that what we could do
was create a decision making

00:13:56.930 --> 00:14:01.850
process for the group
in which we could create

00:14:01.850 --> 00:14:04.710
an environment and
a set of processes

00:14:04.710 --> 00:14:07.530
that people could
employ as a group which

00:14:07.530 --> 00:14:10.760
would create an environment
which would result in more

00:14:10.760 --> 00:14:12.730
informed decision making.

00:14:12.730 --> 00:14:14.630
That was really the
goal that we set out.

00:14:14.630 --> 00:14:17.930
So we weren't trying to make
any particular individual less

00:14:17.930 --> 00:14:18.430
biased.

00:14:18.430 --> 00:14:20.550
If that happens, great.

00:14:20.550 --> 00:14:22.660
But what we're
really trying to do

00:14:22.660 --> 00:14:25.450
is create a simple set of
decision making processes

00:14:25.450 --> 00:14:28.560
at the group level
which will improve

00:14:28.560 --> 00:14:33.850
upon the decisions that might
happen at the individual level.

00:14:33.850 --> 00:14:36.640
So let me describe
to you this exercise.

00:14:36.640 --> 00:14:39.780
And this exercise, while
we adapted it at Columbia,

00:14:39.780 --> 00:14:42.140
it's actually not
our possession.

00:14:42.140 --> 00:14:44.460
It's adapted from an
exercise that was originally

00:14:44.460 --> 00:14:50.155
created actually at Kellogg
and was originally from there.

00:14:50.155 --> 00:14:52.530
But the idea of a professor
who is actually at the London

00:14:52.530 --> 00:14:54.610
Business School,
an experience he

00:14:54.610 --> 00:14:57.170
had in his own personal
life, and that then

00:14:57.170 --> 00:14:59.420
turned into an exercise
which has been running around

00:14:59.420 --> 00:15:02.810
in different forms
in various schools.

00:15:02.810 --> 00:15:06.700
So in this exercise, we
take the MBA students

00:15:06.700 --> 00:15:12.080
and we divide them
up into two groups.

00:15:12.080 --> 00:15:14.860
And these two sets-- two
different groups types

00:15:14.860 --> 00:15:17.480
in fact-- these
groups have to make

00:15:17.480 --> 00:15:19.620
a decision about whom to hire.

00:15:19.620 --> 00:15:21.470
And they have to
figure out whom to hire

00:15:21.470 --> 00:15:24.570
for a senior vice president
position in information

00:15:24.570 --> 00:15:27.020
technology.

00:15:27.020 --> 00:15:31.410
And these groups are made
up of five individuals.

00:15:31.410 --> 00:15:34.090
These five individuals
represent different positions

00:15:34.090 --> 00:15:40.210
in an organization--
CFO, head of marketing,

00:15:40.210 --> 00:15:42.744
different positions-- head of
sales-- different positions

00:15:42.744 --> 00:15:44.660
that you would imagine
at the top of the ranks

00:15:44.660 --> 00:15:46.095
in an organization.

00:15:46.095 --> 00:15:48.050
And they now have to
decide whom they're

00:15:48.050 --> 00:15:52.960
going to hire that's going to be
head of information technology.

00:15:52.960 --> 00:15:56.320
Just as you would have in a
normal hiring decision making

00:15:56.320 --> 00:16:00.990
situation, all of
these five individuals

00:16:00.990 --> 00:16:05.340
have some pieces of
information that's the same.

00:16:05.340 --> 00:16:09.950
So they have three candidates,
Sarah, Catherine, and Janet.

00:16:09.950 --> 00:16:12.910
So they all have information
that's the same for all three

00:16:12.910 --> 00:16:14.560
of these candidates.

00:16:14.560 --> 00:16:19.040
But as a function of
their particular positions

00:16:19.040 --> 00:16:20.730
and the kind of
information that gets

00:16:20.730 --> 00:16:24.430
relayed to them as a
function of their position,

00:16:24.430 --> 00:16:27.790
they also have some information
about the various candidates

00:16:27.790 --> 00:16:31.330
that's not shared.

00:16:31.330 --> 00:16:35.860
So one set of groups engage in
a decision making process that's

00:16:35.860 --> 00:16:39.210
like this where they have
five individuals, information

00:16:39.210 --> 00:16:41.040
about those three candidates.

00:16:41.040 --> 00:16:42.960
Some of that
information is shared.

00:16:42.960 --> 00:16:46.610
Some of that information
is not shared.

00:16:46.610 --> 00:16:50.130
Another set of groups
have five individuals,

00:16:50.130 --> 00:16:52.030
but those five
individuals are given

00:16:52.030 --> 00:16:55.460
all of the information
about all three candidates

00:16:55.460 --> 00:17:00.570
that is available at
that moment of decision.

00:17:00.570 --> 00:17:02.850
So what happens?

00:17:02.850 --> 00:17:05.930
Well, what happens-- and we've
been running this exercise now

00:17:05.930 --> 00:17:07.119
for a number of years.

00:17:07.119 --> 00:17:08.990
And actually what
we find is very

00:17:08.990 --> 00:17:10.770
consistent with
the prior research

00:17:10.770 --> 00:17:13.530
on this, the research
on hidden profiles

00:17:13.530 --> 00:17:15.682
by Stasser and colleagues.

00:17:15.682 --> 00:17:18.220
And what we find is
that the groups that

00:17:18.220 --> 00:17:22.349
make the decision when they have
some information that's shared,

00:17:22.349 --> 00:17:25.470
some information
that's not shared,

00:17:25.470 --> 00:17:28.600
you find that 75%
of these groups

00:17:28.600 --> 00:17:33.310
hire a woman by the
name of Catherine.

00:17:33.310 --> 00:17:35.630
When you have the
groups that had

00:17:35.630 --> 00:17:38.590
all the information
at their disposal,

00:17:38.590 --> 00:17:43.980
now you find 85% of
them choose Janet.

00:17:43.980 --> 00:17:48.606
Now in truth, all three of
these candidates are qualified.

00:17:48.606 --> 00:17:51.380
Now let's just look back
at the general information

00:17:51.380 --> 00:17:52.910
about these three candidates.

00:17:52.910 --> 00:17:56.370
They're all very qualified
candidates, much like sort

00:17:56.370 --> 00:17:58.600
of academic possibilities
that we might hire,

00:17:58.600 --> 00:18:01.150
academics we might
consider hiring.

00:18:01.150 --> 00:18:03.020
So you have three individuals.

00:18:03.020 --> 00:18:06.110
They're all perfectly suited
for a senior vice president

00:18:06.110 --> 00:18:07.990
of information technology.

00:18:07.990 --> 00:18:09.750
One of them is an
external candidate.

00:18:09.750 --> 00:18:12.990
Two of them are
internal candidates.

00:18:12.990 --> 00:18:17.380
But why is it that when the
information is not shared,

00:18:17.380 --> 00:18:20.310
when it's distributed
across individuals,

00:18:20.310 --> 00:18:22.780
you see one candidate
chosen, and when

00:18:22.780 --> 00:18:25.250
everybody has all
the information,

00:18:25.250 --> 00:18:28.290
you see another
candidate chosen?

00:18:28.290 --> 00:18:30.560
When you look at the
way the information

00:18:30.560 --> 00:18:36.630
is distributed, what you
see is that Catherine

00:18:36.630 --> 00:18:40.150
has more positive information
that happens to be shared

00:18:40.150 --> 00:18:43.230
across all five group members.

00:18:43.230 --> 00:18:46.860
When you look at
Janet, she has a piece

00:18:46.860 --> 00:18:50.450
of negative information--
does not recognize

00:18:50.450 --> 00:18:53.370
the contributions of others.

00:18:53.370 --> 00:18:55.510
That piece of
negative information

00:18:55.510 --> 00:18:59.700
is shared across all the groups.

00:18:59.700 --> 00:19:03.680
In truth, if all the information
about every candidate

00:19:03.680 --> 00:19:08.100
were to have been surfaced,
it looks like Janet probably

00:19:08.100 --> 00:19:09.600
has a little bit of an edge.

00:19:09.600 --> 00:19:13.560
She has a bit more positive
information associated with her

00:19:13.560 --> 00:19:16.550
than, say, Catherine or Sarah,
although you could make a case

00:19:16.550 --> 00:19:17.410
for any one of them.

00:19:20.190 --> 00:19:24.150
Now in the classroom when
the students come back

00:19:24.150 --> 00:19:29.800
and we debrief this exercise,
we find out what they did.

00:19:29.800 --> 00:19:32.450
We find out what happened in
those groups that were trying

00:19:32.450 --> 00:19:35.020
to figure out whom to hire.

00:19:35.020 --> 00:19:38.350
And what we find is in groups
where the information is

00:19:38.350 --> 00:19:40.470
distributed, much
like it would be

00:19:40.470 --> 00:19:45.020
in a real hiring decision making
process, what did they do?

00:19:45.020 --> 00:19:48.370
Well, everybody has
the basic information

00:19:48.370 --> 00:19:50.175
about those three candidates.

00:19:50.175 --> 00:19:51.760
They start their meeting.

00:19:51.760 --> 00:19:54.950
The moderator wants
to be efficient.

00:19:54.950 --> 00:19:57.246
And so the moderator
takes a poll.

00:19:57.246 --> 00:19:59.630
A reasonable thing
to do, take a poll.

00:19:59.630 --> 00:20:02.560
Let's just find out,
where's the consensus?

00:20:02.560 --> 00:20:04.220
They take a poll
and they find out,

00:20:04.220 --> 00:20:09.250
well you know, people seem to
be generally split on Catherine.

00:20:09.250 --> 00:20:11.450
More people usually
want Catherine.

00:20:11.450 --> 00:20:13.390
Some people want Sarah.

00:20:13.390 --> 00:20:15.740
Maybe one person
on occasion thinks

00:20:15.740 --> 00:20:18.020
Janet might look
good, depending on how

00:20:18.020 --> 00:20:20.050
much positive
information about Janet

00:20:20.050 --> 00:20:23.690
has been shared with
that one individual.

00:20:23.690 --> 00:20:25.530
Well now they've made a vote.

00:20:25.530 --> 00:20:28.140
Now the moderator says, well,
let's talk about these three

00:20:28.140 --> 00:20:29.000
candidates.

00:20:29.000 --> 00:20:31.625
Let's figure out what
are their pros and cons.

00:20:31.625 --> 00:20:34.400
So they jot down all the
pros and cons associated

00:20:34.400 --> 00:20:37.620
with these three candidates.

00:20:37.620 --> 00:20:39.880
Well, they jot down
all the pros and cons,

00:20:39.880 --> 00:20:41.440
and it becomes
very clear to them

00:20:41.440 --> 00:20:45.010
that Catherine is the
dominating alternative.

00:20:45.010 --> 00:20:47.570
Sometimes they pick
Sarah, mainly because they

00:20:47.570 --> 00:20:51.190
have a little bit of a bias
in favor of an internal person

00:20:51.190 --> 00:20:53.745
rather an external person.

00:20:53.745 --> 00:20:57.440
But when they come
back to that classroom,

00:20:57.440 --> 00:21:02.930
and now I put up all the
information, and I say to them,

00:21:02.930 --> 00:21:08.090
did you know
everything about Janet?

00:21:08.090 --> 00:21:11.720
And my question isn't, did
you pick the right one.

00:21:11.720 --> 00:21:13.950
Are you confident that
you picked the best one?

00:21:13.950 --> 00:21:17.280
Because any of them
could be the best one.

00:21:17.280 --> 00:21:19.640
My question is
simply, did you have

00:21:19.640 --> 00:21:24.560
all the information about Janet
that was available to you?

00:21:24.560 --> 00:21:28.890
And second, if you had had
some of this information which

00:21:28.890 --> 00:21:31.960
was not available to you
at the time of decision,

00:21:31.960 --> 00:21:34.360
do you think it would have
mattered to you while you

00:21:34.360 --> 00:21:37.340
were making that decision?

00:21:37.340 --> 00:21:41.130
And if the answer to
both of these questions

00:21:41.130 --> 00:21:44.490
is no, I didn't have
all the information,

00:21:44.490 --> 00:21:47.540
yes it would have mattered,
well then my question

00:21:47.540 --> 00:21:50.870
is, did you give
Janet a fair hearing.

00:21:53.500 --> 00:21:55.080
And as I said
before, when people

00:21:55.080 --> 00:21:57.270
have all the
information, they tend

00:21:57.270 --> 00:22:01.230
to be more likely
to choose Janet.

00:22:01.230 --> 00:22:04.710
Now we then go on to
do other exercises

00:22:04.710 --> 00:22:08.640
and teach them a decision
making process that we think

00:22:08.640 --> 00:22:12.180
makes that process
more fair, or at least

00:22:12.180 --> 00:22:15.750
gives all of the candidates
more of a fair hearing.

00:22:15.750 --> 00:22:17.730
If you remember,
my goal here is not

00:22:17.730 --> 00:22:20.740
to debias all the
individuals of the group.

00:22:20.740 --> 00:22:24.770
I'm assuming all the
individuals are biased.

00:22:24.770 --> 00:22:28.030
My goal is simply to make
sure that every candidate

00:22:28.030 --> 00:22:31.090
has a fair hearing.

00:22:31.090 --> 00:22:33.650
Why did they not
have a fair hearing

00:22:33.650 --> 00:22:35.770
in the traditional model
that they were using?

00:22:35.770 --> 00:22:38.470
They didn't go out to be biased.

00:22:38.470 --> 00:22:39.790
But what happens?

00:22:39.790 --> 00:22:42.020
When you actually
look at the process

00:22:42.020 --> 00:22:45.420
that these groups describe
that they used, well,

00:22:45.420 --> 00:22:49.830
once you have that vote
out-- I like Catherine.

00:22:49.830 --> 00:22:54.340
I like Sarah-- when I'm
surfacing the pros and cons,

00:22:54.340 --> 00:22:57.210
I'm more likely to surface
the things that support

00:22:57.210 --> 00:22:59.490
what I think to be true.

00:22:59.490 --> 00:23:01.420
I'm more likely
to forget whatever

00:23:01.420 --> 00:23:04.145
little positive things I know
about Janet, particularly when

00:23:04.145 --> 00:23:06.020
a whole bunch of other
people said, you know,

00:23:06.020 --> 00:23:07.645
she doesn't recognize
the contributions

00:23:07.645 --> 00:23:09.790
of her fellow colleagues.

00:23:09.790 --> 00:23:11.660
Yeah, I know, isn't
that really bad?

00:23:11.660 --> 00:23:17.320
And then you start having the
Janet sucks song going on.

00:23:17.320 --> 00:23:20.190
So that one piece of
negative shared information

00:23:20.190 --> 00:23:24.940
ends up becoming more available,
and also gains in weight.

00:23:28.310 --> 00:23:31.540
The people that ended
up voting initially

00:23:31.540 --> 00:23:32.800
stick to their opinion.

00:23:32.800 --> 00:23:36.120
Sort of a commitment and
consistency effect goes on.

00:23:36.120 --> 00:23:38.030
They also start
finding information

00:23:38.030 --> 00:23:40.790
that's more likely to
support their opinion, known

00:23:40.790 --> 00:23:42.680
as confirmation bias.

00:23:42.680 --> 00:23:45.800
And also in the end you
try to get some consensus.

00:23:45.800 --> 00:23:48.140
There's a sort of Janet
sucks thing going on.

00:23:48.140 --> 00:23:53.060
And that ends up looking
like a group think process.

00:23:53.060 --> 00:23:56.470
So are there things we can
do with the group level

00:23:56.470 --> 00:23:58.420
decision making
processes that we

00:23:58.420 --> 00:24:02.930
can put in place that would give
people more of a fair hearing?

00:24:02.930 --> 00:24:04.610
So what I'm going to
describe to you now

00:24:04.610 --> 00:24:07.830
is a decision making
process that I've

00:24:07.830 --> 00:24:11.080
adapted for academic
hiring that's based on what

00:24:11.080 --> 00:24:13.566
we use with the MBA students.

00:24:13.566 --> 00:24:15.690
By the way, it's also
something that we're actually

00:24:15.690 --> 00:24:18.270
employing right now at the
Columbia Business School

00:24:18.270 --> 00:24:23.450
as we search for the
candidate for our new decision

00:24:23.450 --> 00:24:25.350
making academic hire.

00:24:25.350 --> 00:24:30.670
So ask me in a few months
if we were successful.

00:24:30.670 --> 00:24:34.180
And what I'd like to emphasize
here is what I'm putting out

00:24:34.180 --> 00:24:35.370
here is a proposal.

00:24:35.370 --> 00:24:39.330
So you can feel free to--
I'm expecting you to throw

00:24:39.330 --> 00:24:43.070
some gentle darts at me.

00:24:43.070 --> 00:24:44.090
Feel free to disagree.

00:24:44.090 --> 00:24:47.790
It's really I'm trying to
give you food for thought.

00:24:47.790 --> 00:24:51.280
So here's my proposal.

00:24:51.280 --> 00:24:55.990
Stage one of an academic
hiring process--

00:24:55.990 --> 00:24:59.695
you come up with a criteria,
some general criteria.

00:24:59.695 --> 00:25:02.270
And at this stage, I
would make that criteria

00:25:02.270 --> 00:25:04.590
fairly vague and general.

00:25:04.590 --> 00:25:07.550
I'm looking for-- the
best person right now

00:25:07.550 --> 00:25:12.020
is the leading scholar in
decision making, negotiations,

00:25:12.020 --> 00:25:14.810
broadly defined.

00:25:14.810 --> 00:25:19.270
That now gives you the
ability to search widely.

00:25:19.270 --> 00:25:23.650
Gather up resumes from as
far and wide as you'd like.

00:25:23.650 --> 00:25:27.880
And sometimes people find
it helpful to designate

00:25:27.880 --> 00:25:32.170
some members of the committee
to specifically search

00:25:32.170 --> 00:25:33.710
for diversity candidate.

00:25:33.710 --> 00:25:37.120
And I'd like to emphasize here
that diversity doesn't just

00:25:37.120 --> 00:25:41.020
apply to ethnic and
gender distribution.

00:25:41.020 --> 00:25:44.540
That's certainly an important
diversity component.

00:25:44.540 --> 00:25:47.190
But it also applies
to diversity in terms

00:25:47.190 --> 00:25:48.930
of intellectual contribution.

00:25:48.930 --> 00:25:53.620
So for example in our current
decision making hiring process,

00:25:53.620 --> 00:25:58.090
we've got an
anthropologist on the list,

00:25:58.090 --> 00:26:00.790
and we're considering hiring an
anthropologist at the Columbia

00:26:00.790 --> 00:26:05.780
Business School that
studies primates and does

00:26:05.780 --> 00:26:08.720
brain research and also
does research in economics,

00:26:08.720 --> 00:26:10.130
having to do with trust.

00:26:10.130 --> 00:26:16.586
So it can be quite diverse
even in terms of intellect.

00:26:16.586 --> 00:26:20.480
So now you've got
all these resumes.

00:26:20.480 --> 00:26:24.190
And you might actually
have quite a few resumes.

00:26:24.190 --> 00:26:26.140
Now if you had a
lot of resumes, we

00:26:26.140 --> 00:26:28.630
know from research that
been conducted by me

00:26:28.630 --> 00:26:30.540
and a number of other
people, it can kind of

00:26:30.540 --> 00:26:32.410
overwhelming if
you suddenly have

00:26:32.410 --> 00:26:36.580
to look at, say, a hundred
or even 50 odd applications

00:26:36.580 --> 00:26:39.290
and make some real
decisions about who's going

00:26:39.290 --> 00:26:41.890
to make it into the short list.

00:26:41.890 --> 00:26:44.965
So to avoid a sort of
information overload

00:26:44.965 --> 00:26:51.400
or a too much choice overload
effect, what I propose doing

00:26:51.400 --> 00:26:56.340
is that we take those
sets of resumes of vitaes,

00:26:56.340 --> 00:27:00.010
divide them up across
the committee members

00:27:00.010 --> 00:27:03.720
so that no one committee member,
say, has more than 10 or 15,

00:27:03.720 --> 00:27:08.170
make it a manageable
set of vitaes.

00:27:08.170 --> 00:27:11.440
Each candidate gets seen
by two committee members

00:27:11.440 --> 00:27:15.940
so that you don't have any
particular individual that's

00:27:15.940 --> 00:27:17.780
going to get killed
as a function of one

00:27:17.780 --> 00:27:20.760
particular individual's
preferences in one

00:27:20.760 --> 00:27:23.040
or the other direction.

00:27:23.040 --> 00:27:25.420
And the committee members
are now given the task

00:27:25.420 --> 00:27:28.530
not of saying yes or no, do we
want to interview that person.

00:27:28.530 --> 00:27:31.610
That's a little
complicated at this stage.

00:27:31.610 --> 00:27:34.940
Instead they're given
the task of simply rating

00:27:34.940 --> 00:27:38.580
them high, medium, low-- good
candidate for an interview,

00:27:38.580 --> 00:27:41.940
medium, low.

00:27:41.940 --> 00:27:46.030
Now you generate these ratings
of high, medium, and low.

00:27:46.030 --> 00:27:48.240
You bring them
together in a meeting.

00:27:48.240 --> 00:27:50.930
You collate the results.

00:27:50.930 --> 00:27:53.230
And now you have a list.

00:27:53.230 --> 00:27:55.890
How many made it such that
they were all in the high?

00:27:55.890 --> 00:28:00.030
How many were kind of a mix
of highs and mediums, mediums

00:28:00.030 --> 00:28:00.960
and lows?

00:28:00.960 --> 00:28:03.570
And now you can make
a criteria by which

00:28:03.570 --> 00:28:06.080
you're going to cut
out the applicants

00:28:06.080 --> 00:28:07.455
that you don't
want to interview.

00:28:07.455 --> 00:28:10.660
So again, the task here is
not picking out, initially,

00:28:10.660 --> 00:28:12.940
who you are going
to interview, whom

00:28:12.940 --> 00:28:14.350
you're not going to interview.

00:28:14.350 --> 00:28:16.570
Because that's ultimately
a little bit of an easier

00:28:16.570 --> 00:28:19.050
decision to make.

00:28:19.050 --> 00:28:21.150
Once you've come up with
a rule by which you're

00:28:21.150 --> 00:28:24.090
going to throw out the
candidates that you don't want

00:28:24.090 --> 00:28:27.440
to interview, now you've
got a list of candidates

00:28:27.440 --> 00:28:31.480
that you think might be
feasible to interview.

00:28:31.480 --> 00:28:34.810
At this point, you can
start having the discussion

00:28:34.810 --> 00:28:39.450
about what your more
specific criteria is

00:28:39.450 --> 00:28:43.410
and use that for
narrowing down that list

00:28:43.410 --> 00:28:45.800
of potential
interview candidates

00:28:45.800 --> 00:28:48.690
to a more manageable set.

00:28:48.690 --> 00:28:51.730
And that committee can decide
what that manageable set is.

00:28:51.730 --> 00:28:52.710
Is it going to be five?

00:28:52.710 --> 00:28:54.000
Is it going to be seven?

00:28:54.000 --> 00:28:57.120
I usually don't
recommend going past 10

00:28:57.120 --> 00:29:00.530
because you're just not going to
remember all their interviews.

00:29:00.530 --> 00:29:02.370
Your fellow colleagues
aren't going

00:29:02.370 --> 00:29:04.590
to remember all
their interviews.

00:29:04.590 --> 00:29:08.970
It leaves you open
more to being more

00:29:08.970 --> 00:29:11.710
likely to vote in favor of those
candidates that are somehow

00:29:11.710 --> 00:29:14.860
more memorable in some way such
that would open yourself up

00:29:14.860 --> 00:29:15.910
to a little more bias.

00:29:15.910 --> 00:29:19.860
You want to really try to
make the evaluation process as

00:29:19.860 --> 00:29:21.180
manageable as possible.

00:29:23.950 --> 00:29:28.170
So now let's say you've
decided on your candidates.

00:29:28.170 --> 00:29:30.940
You've brought them in for
their various job talks.

00:29:30.940 --> 00:29:33.840
They've met with your
fellow colleagues.

00:29:33.840 --> 00:29:36.620
You ask your fellow colleagues
to give their opinion

00:29:36.620 --> 00:29:38.670
high, medium, low.

00:29:38.670 --> 00:29:44.410
Never ask them yea or
nay-- high, medium, low.

00:29:44.410 --> 00:29:47.120
Now you come to stage two.

00:29:47.120 --> 00:29:51.720
How are you going to decide
whom to get that offer to?

00:29:51.720 --> 00:29:54.860
How you going to run that
really critical meetings, or set

00:29:54.860 --> 00:29:57.140
of meetings in which
you're going to decide

00:29:57.140 --> 00:30:00.420
who to give that offer to?

00:30:00.420 --> 00:30:05.694
So when you have that first
meeting, what's your goal?

00:30:05.694 --> 00:30:08.680
You goal is not to pick
the best candidate.

00:30:08.680 --> 00:30:13.440
Your goal is to give each
person a fair hearing.

00:30:13.440 --> 00:30:16.460
So how are you going to do that?

00:30:16.460 --> 00:30:23.810
First, you have a specific
discussion about the criteria.

00:30:23.810 --> 00:30:26.180
Put that criteria on the board.

00:30:26.180 --> 00:30:28.440
And naturally, as
fellow academics,

00:30:28.440 --> 00:30:30.730
we're all going to have
strong opinions about what

00:30:30.730 --> 00:30:32.860
our criteria should
and should not be.

00:30:32.860 --> 00:30:35.520
Some people will weigh
more heavily the importance

00:30:35.520 --> 00:30:36.940
of having an internal person.

00:30:36.940 --> 00:30:39.200
Some people will weigh
more heavily the importance

00:30:39.200 --> 00:30:40.970
of an external person.

00:30:40.970 --> 00:30:43.460
Some people will
weigh more heavily

00:30:43.460 --> 00:30:46.510
adding strength to an
already existing strength.

00:30:46.510 --> 00:30:48.970
Some people will
feel that it's more

00:30:48.970 --> 00:30:51.340
important to weigh diversity.

00:30:51.340 --> 00:30:53.650
And these are a legitimate
things to value.

00:30:53.650 --> 00:30:57.750
The important thing is to get
the criteria out there and get

00:30:57.750 --> 00:31:01.750
out there what the trade-offs
are in terms of which things

00:31:01.750 --> 00:31:03.930
we value more, which
things we value less.

00:31:03.930 --> 00:31:08.130
And it's OK to have some
disagreements up there.

00:31:08.130 --> 00:31:11.080
Next thing we put
up-- so at this point

00:31:11.080 --> 00:31:12.980
we haven't yet
asked anybody what

00:31:12.980 --> 00:31:16.330
they think of the candidates.

00:31:16.330 --> 00:31:19.560
Now what we put up
is we ask each person

00:31:19.560 --> 00:31:22.870
to surface all the
information that they have

00:31:22.870 --> 00:31:25.257
about each of the candidates.

00:31:25.257 --> 00:31:27.090
We're not asking them
to give their opinion.

00:31:27.090 --> 00:31:30.190
We want to stop them from
giving their opinions.

00:31:30.190 --> 00:31:32.590
Just, let's get out
all the information

00:31:32.590 --> 00:31:36.960
about all the candidates
under consideration.

00:31:36.960 --> 00:31:39.375
After you've surfaced
all the information

00:31:39.375 --> 00:31:44.190
that you have possibly available
to you at this moment in time,

00:31:44.190 --> 00:31:47.510
about the candidates,
now you're in a position

00:31:47.510 --> 00:31:50.450
to start putting evaluations.

00:31:50.450 --> 00:31:53.130
And the way we run
the evaluations is we

00:31:53.130 --> 00:31:55.710
ask each of the
committee members

00:31:55.710 --> 00:31:59.710
to, semiprivately-- meaning on
a private sheet of paper-- rate

00:31:59.710 --> 00:32:02.100
the candidates
high, medium, low.

00:32:02.100 --> 00:32:03.650
Don't put your name on it.

00:32:03.650 --> 00:32:08.270
And hand that to the moderator,
head of the search committee.

00:32:08.270 --> 00:32:10.690
That moderator now
collates the results

00:32:10.690 --> 00:32:12.990
and puts them up on the board.

00:32:12.990 --> 00:32:16.550
The reason why I say it's
semiprivate, because obviously

00:32:16.550 --> 00:32:18.350
can I really figure
out who might

00:32:18.350 --> 00:32:21.530
have given a little more
preference to one candidate

00:32:21.530 --> 00:32:23.630
to another after awhile
of knowing our colleagues?

00:32:23.630 --> 00:32:26.730
Of course we all
know, to some extent,

00:32:26.730 --> 00:32:28.990
where our colleagues'
preferences lie.

00:32:28.990 --> 00:32:32.860
But it's still important to
not have a name attached to it,

00:32:32.860 --> 00:32:35.710
put it up on the board,
and have a sense of where

00:32:35.710 --> 00:32:39.070
does the group stand.

00:32:39.070 --> 00:32:42.440
Around which candidates do
we have more of a consensus?

00:32:42.440 --> 00:32:45.630
Around which candidates do
we have less of a consensus,

00:32:45.630 --> 00:32:50.040
much more of a sort of
minority support around?

00:32:50.040 --> 00:32:52.010
Once you have those
numbers up on the board--

00:32:52.010 --> 00:32:54.259
and again, they're all rated
in terms of high, medium,

00:32:54.259 --> 00:32:59.016
and low-- we now first
address the minority opinion.

00:32:59.016 --> 00:33:02.310
What does those people that are
supporting the candidates that

00:33:02.310 --> 00:33:06.130
are less preferred, what
are their arguments,

00:33:06.130 --> 00:33:08.790
so that those arguments
are heard in case

00:33:08.790 --> 00:33:11.340
other people still
feel like they

00:33:11.340 --> 00:33:13.060
want to change their minds.

00:33:13.060 --> 00:33:16.330
That's another reason why you
don't put the name associated

00:33:16.330 --> 00:33:21.320
with the opinions or the votes
up there, because it gives

00:33:21.320 --> 00:33:24.180
people a chance to possibly
revise their opinion

00:33:24.180 --> 00:33:26.930
without loss of face.

00:33:26.930 --> 00:33:29.980
So now you have the minority
opinion that's surfaced.

00:33:29.980 --> 00:33:32.530
People can think about it.

00:33:32.530 --> 00:33:35.820
At that point, we start
discussing the majority

00:33:35.820 --> 00:33:37.370
opinion.

00:33:37.370 --> 00:33:40.980
And in the process of
discussing the majority opinion,

00:33:40.980 --> 00:33:43.361
we also think it's
helpful to do--

00:33:43.361 --> 00:33:45.860
what we've been trying to do
anyway at the Columbia Business

00:33:45.860 --> 00:33:49.400
School is also surface the
discussion around, well,

00:33:49.400 --> 00:33:51.910
say we hire this person.

00:33:51.910 --> 00:33:56.090
What do we expect them to
do once they come here?

00:33:56.090 --> 00:33:58.950
Are they going to be a good fit?

00:33:58.950 --> 00:34:01.870
Is it possible that the research
that they've done that's

00:34:01.870 --> 00:34:04.280
been so fascinating
up until this point,

00:34:04.280 --> 00:34:06.110
would it continue here?

00:34:06.110 --> 00:34:09.460
Would it necessarily have
to change if they came here?

00:34:09.460 --> 00:34:11.679
We're being sensitive
to the recent research

00:34:11.679 --> 00:34:13.389
on star analysts
that was done here

00:34:13.389 --> 00:34:18.385
at Harvard which shows that
when star analysts move

00:34:18.385 --> 00:34:20.510
to another organization,
their performance actually

00:34:20.510 --> 00:34:23.060
can drop by 20%.

00:34:23.060 --> 00:34:26.090
Now can we say anything
meaningful about what

00:34:26.090 --> 00:34:28.469
someone's future
trajectory is going to be?

00:34:28.469 --> 00:34:31.989
No, we don't really know
for sure what will happen.

00:34:31.989 --> 00:34:34.159
But we think it's
useful to at least have

00:34:34.159 --> 00:34:37.840
that discussion, to
at least think about,

00:34:37.840 --> 00:34:41.370
what are our expectations of
this person once they arrive.

00:34:41.370 --> 00:34:44.510
And perhaps that
discussion might bring out

00:34:44.510 --> 00:34:46.550
other things we
hadn't thought about,

00:34:46.550 --> 00:34:51.414
and might also influence our
preferences towards the end.

00:34:51.414 --> 00:34:57.520
In the final stage,
we make a decision.

00:34:57.520 --> 00:34:58.845
We try to gauge consensus.

00:34:58.845 --> 00:35:03.090
We try to gauge everybody's
voice, everybody's input.

00:35:03.090 --> 00:35:05.580
Because in the end
of the day, how well

00:35:05.580 --> 00:35:08.210
that candidate will
do at your institution

00:35:08.210 --> 00:35:11.710
will depend on
everybody's buy-in.

00:35:11.710 --> 00:35:15.170
Only if you cannot get
absolute buy-in do you go with

00:35:15.170 --> 00:35:17.000
the majority vote.

00:35:17.000 --> 00:35:19.660
We try to reserve that
only for the final moments

00:35:19.660 --> 00:35:23.790
if you really can't
get consensus.

00:35:23.790 --> 00:35:26.320
Now one of the
things that I think

00:35:26.320 --> 00:35:31.430
is really important for us
to do that we don't do and is

00:35:31.430 --> 00:35:34.545
probably really scary to
even contemplate doing,

00:35:34.545 --> 00:35:38.540
but if we really want to be able
to improve our decision making

00:35:38.540 --> 00:35:41.160
process over the
long run, we need

00:35:41.160 --> 00:35:44.180
to have a procedure
in place for auditing.

00:35:44.180 --> 00:35:48.870
We need to be able to look
back, have a system in place

00:35:48.870 --> 00:35:51.690
where we look back, have
the information that we

00:35:51.690 --> 00:35:55.080
had at that moment when
we made that decision,

00:35:55.080 --> 00:35:56.700
and be able to
audit our decisions.

00:35:56.700 --> 00:35:58.750
How did we do that time?

00:35:58.750 --> 00:36:01.810
Did we reject somebody
that maybe in retrospect we

00:36:01.810 --> 00:36:04.578
should not have rejected?

00:36:04.578 --> 00:36:06.800
And to have that
ability, even if you

00:36:06.800 --> 00:36:11.530
can't undo that decision, it's
important to be able to audit.

00:36:11.530 --> 00:36:14.890
Because when you audit, you
now have more information

00:36:14.890 --> 00:36:19.212
about what things you can
avoid doing going forward.

00:36:19.212 --> 00:36:21.340
And I'm not saying
that auditing has

00:36:21.340 --> 00:36:25.070
to be this formal thing that's
taken over by the provost's

00:36:25.070 --> 00:36:26.980
office or by the dean's office.

00:36:26.980 --> 00:36:30.880
Do it internally, informally,
within your own departments

00:36:30.880 --> 00:36:33.920
just as an internal
check for yourself.

00:36:33.920 --> 00:36:36.270
Because ultimately
we all have the goal

00:36:36.270 --> 00:36:39.470
of making sure we hire
the very best people that

00:36:39.470 --> 00:36:41.470
will contribute the
most to our institution.

00:36:44.580 --> 00:36:48.720
So with that, I'm going to
leave it open for discussion.

00:36:48.720 --> 00:36:49.884
Thank you very much.

00:36:49.884 --> 00:36:53.342
[APPLAUSE]

00:37:17.060 --> 00:37:18.380
Good morning everyone.

00:37:18.380 --> 00:37:21.450
It's a great pleasure to
contribute to the discussion

00:37:21.450 --> 00:37:24.700
as well and follow
Sheena, who I think

00:37:24.700 --> 00:37:28.480
has done such a wonderful job in
helping us think about a better

00:37:28.480 --> 00:37:30.290
design for the process.

00:37:30.290 --> 00:37:33.750
What I plan to do this morning
is give you some input.

00:37:33.750 --> 00:37:36.700
So less of a structure
at how to do this,

00:37:36.700 --> 00:37:41.850
but some ideas that just came
out of research in recent years

00:37:41.850 --> 00:37:46.370
of what to think about in
terms of improving the process.

00:37:46.370 --> 00:37:48.630
In particular I want to
talk about gender equality

00:37:48.630 --> 00:37:52.570
nudges and a bit about
why diversity matters

00:37:52.570 --> 00:37:55.750
and how we could even
think about the benefits

00:37:55.750 --> 00:37:58.200
or the diversity premium.

00:37:58.200 --> 00:38:00.110
So "Nudge," I think
most of you are

00:38:00.110 --> 00:38:03.750
familiar with Cass Sunstein
and Richard Thaler's book that

00:38:03.750 --> 00:38:05.200
has recently come out.

00:38:05.200 --> 00:38:09.640
A nudge is a gentle
persuader that

00:38:09.640 --> 00:38:13.640
builds on our insides
of how our minds work.

00:38:13.640 --> 00:38:18.720
And it's quite different from an
incentive or regulation or even

00:38:18.720 --> 00:38:21.520
information, so other
types of interventions

00:38:21.520 --> 00:38:23.150
that you could think about it.

00:38:23.150 --> 00:38:25.750
In fact better than even trying
to describe what a nudge is,

00:38:25.750 --> 00:38:29.050
I want to show
you a short video,

00:38:29.050 --> 00:38:32.925
which is a nice illustration
of a little nudge.

00:38:38.532 --> 00:38:39.198
[VIDEO PLAYBACK]

00:38:39.198 --> 00:38:42.691
[MUSIC PLAYING]

00:40:21.992 --> 00:40:23.670
[END PLAYBACK]

00:40:23.670 --> 00:40:27.680
OK, so this was a video
about the people's choices

00:40:27.680 --> 00:40:30.460
between stairs and escalator.

00:40:30.460 --> 00:40:34.570
And what the video did
is transform the stairs

00:40:34.570 --> 00:40:35.290
into a piano.

00:40:35.290 --> 00:40:37.280
So that's what made
it more fun for people

00:40:37.280 --> 00:40:40.222
to walk up the stairs.

00:40:40.222 --> 00:40:42.180
So that kind of gives
you an idea of the nudge.

00:40:42.180 --> 00:40:44.100
We're neither paying
people to do something

00:40:44.100 --> 00:40:48.520
nor we're regulating certain
behavior nor are we putting up

00:40:48.520 --> 00:40:51.780
a sign there, it's good for
your health to use the stairs.

00:40:51.780 --> 00:40:54.940
But we're changing the
environment ever so slightly

00:40:54.940 --> 00:40:56.510
to affect people's choices.

00:40:56.510 --> 00:41:01.570
And that's the idea behind
gender equality nudges

00:41:01.570 --> 00:41:03.180
that we now want to build on.

00:41:03.180 --> 00:41:10.370
And so as Sheena-- what we're
arguing is that very rarely

00:41:10.370 --> 00:41:15.300
do wrong decisions come about
because people intentionally

00:41:15.300 --> 00:41:18.860
try to rig the system or try
to choose the candidate that

00:41:18.860 --> 00:41:21.276
was close to their own
interests or any of that sort.

00:41:21.276 --> 00:41:22.650
But it really has
much more to do

00:41:22.650 --> 00:41:25.900
with how our minds work with
bounds and rationality, will

00:41:25.900 --> 00:41:28.810
power, and bounded awareness.

00:41:28.810 --> 00:41:32.470
So I have a little illustration
here of that for you

00:41:32.470 --> 00:41:34.100
so you can all see it.

00:41:34.100 --> 00:41:34.870
Often we do this.

00:41:34.870 --> 00:41:36.160
And I though with
the faculty, I'm

00:41:36.160 --> 00:41:37.326
not going to do it this way.

00:41:37.326 --> 00:41:39.065
But we often do it as
a little experiment

00:41:39.065 --> 00:41:41.410
where we ask half the
people to close their eyes

00:41:41.410 --> 00:41:43.460
and look at this and
see what they see.

00:41:43.460 --> 00:41:45.560
And so what you see, ABC.

00:41:45.560 --> 00:41:47.550
And then I would ask the
other half of the room

00:41:47.550 --> 00:41:48.980
to close their
eyes and would show

00:41:48.980 --> 00:41:52.805
the first half, this number
sequence here, 12, 13, 14.

00:41:52.805 --> 00:41:57.470
And of course the middle
number here, the B,

00:41:57.470 --> 00:42:02.030
is identical to the
B that you saw here.

00:42:02.030 --> 00:42:03.960
So that's just an
illustration of what

00:42:03.960 --> 00:42:10.330
you see depends on the context
in which you see something.

00:42:10.330 --> 00:42:12.280
Let me give you one
more illustration.

00:42:12.280 --> 00:42:16.870
And that is you're comparing
squares A and squares B.

00:42:16.870 --> 00:42:20.280
And the question is, what
is the color of square B?

00:42:20.280 --> 00:42:25.030
And I would assume most of
you see B as lighter than A

00:42:25.030 --> 00:42:28.080
because your minds want to
make sense of the pattern

00:42:28.080 --> 00:42:29.670
that you see here.

00:42:29.670 --> 00:42:31.950
In addition, being
super smart, you also

00:42:31.950 --> 00:42:35.680
want to take into account that
there's a little shadow here,

00:42:35.680 --> 00:42:37.280
which might make B darker.

00:42:37.280 --> 00:42:43.480
Turns out that when we cover
the surroundings of A and B,

00:42:43.480 --> 00:42:46.400
the colors are,
in fact identical.

00:42:46.400 --> 00:42:50.200
So again, it really matters
how we look at things

00:42:50.200 --> 00:42:51.630
and what you see.

00:42:51.630 --> 00:42:54.140
And so, of course in
a picture like this

00:42:54.140 --> 00:42:57.390
what you see, who
you see as a leader,

00:42:57.390 --> 00:43:00.070
who you see as a follower,
who see as senior, junior,

00:43:00.070 --> 00:43:03.900
as attractive, not attractive,
black, white, female,

00:43:03.900 --> 00:43:07.290
et cetera depends on
how you look at this.

00:43:07.290 --> 00:43:09.110
So that's really
where I want to start.

00:43:09.110 --> 00:43:11.470
And I want to talk
about three studies.

00:43:11.470 --> 00:43:13.560
And the first one in fact
is the least developed,

00:43:13.560 --> 00:43:15.190
but I want to give you the idea.

00:43:15.190 --> 00:43:17.960
Because I think particular
for faculty hiring,

00:43:17.960 --> 00:43:19.865
this one is actually
an important one,

00:43:19.865 --> 00:43:21.240
but I don't have
any results yet.

00:43:21.240 --> 00:43:23.720
But here's the idea.

00:43:23.720 --> 00:43:30.440
It builds on research in
psychology on variety seeking.

00:43:30.440 --> 00:43:34.800
And here's how one of
the early studies worked:

00:43:34.800 --> 00:43:39.650
students were given choices
of candies or snacks.

00:43:39.650 --> 00:43:43.710
And in one condition, people
had to make a choice for,

00:43:43.710 --> 00:43:46.245
let's assume, every
snack for a whole month.

00:43:46.245 --> 00:43:48.804
So at the beginning of the
month, I'm given 10 choices.

00:43:48.804 --> 00:43:49.470
Here's an apple.

00:43:49.470 --> 00:43:50.261
Here's a candy bar.

00:43:50.261 --> 00:43:51.640
Here's this or that.

00:43:51.640 --> 00:43:54.450
Choose a snack for
every day of the month.

00:43:54.450 --> 00:43:58.070
And then in another condition,
a different group of students

00:43:58.070 --> 00:44:00.340
was asked every
morning of the month

00:44:00.340 --> 00:44:03.890
to choose what snack
to have that day.

00:44:03.890 --> 00:44:06.410
And as you might imagine,
in the heat of the moment

00:44:06.410 --> 00:44:09.870
that morning, people would
go for their favorite snack

00:44:09.870 --> 00:44:11.970
like the Mars bar.

00:44:11.970 --> 00:44:14.630
But if you choose at the
beginning of the month

00:44:14.630 --> 00:44:17.140
and make 30 choices
at the same time,

00:44:17.140 --> 00:44:18.680
people would go for variety.

00:44:18.680 --> 00:44:22.706
You can't choose the
same old snack 30 times.

00:44:22.706 --> 00:44:24.080
But every morning,
you're kind of

00:44:24.080 --> 00:44:25.413
going to go with the same snack.

00:44:25.413 --> 00:44:26.600
And you've all been there.

00:44:26.600 --> 00:44:28.683
Going back to your favorite
restaurant, every time

00:44:28.683 --> 00:44:30.031
you're like, not today.

00:44:30.031 --> 00:44:32.530
I'm not going to take the same
thing that I have every time.

00:44:32.530 --> 00:44:36.520
But of course that's
what you like best maybe.

00:44:36.520 --> 00:44:39.230
So that's known as
variety seeking.

00:44:39.230 --> 00:44:42.099
And we want to apply
this to hiring decisions.

00:44:42.099 --> 00:44:44.140
And I think the intuition
is very straightforward

00:44:44.140 --> 00:44:47.390
that if you hire five
people at the same time,

00:44:47.390 --> 00:44:52.580
if you hire in clusters, what's
often known as cluster hiring,

00:44:52.580 --> 00:44:56.780
diversity will emerge in a
very different way than when

00:44:56.780 --> 00:44:59.460
you hire one person at a time.

00:44:59.460 --> 00:45:01.790
So our hypothesis is that
when you hire sequentially,

00:45:01.790 --> 00:45:04.360
one person at a time,
we will be much more

00:45:04.360 --> 00:45:07.890
likely to go with
our favorite snack,

00:45:07.890 --> 00:45:10.560
with our favorite candidate, the
candidate that we're familiar

00:45:10.560 --> 00:45:14.340
with, the type of attributes
that we've always hired,

00:45:14.340 --> 00:45:18.260
and are possibly
also the least risky.

00:45:18.260 --> 00:45:19.640
So that's the
first idea, that we

00:45:19.640 --> 00:45:22.600
have to think about how we
hire in terms of do we hire one

00:45:22.600 --> 00:45:25.170
at a time or sequentially.

00:45:25.170 --> 00:45:28.320
Now a related study,
but in fact building

00:45:28.320 --> 00:45:34.007
on a different psychological
mechanism, is our evaluations.

00:45:34.007 --> 00:45:35.840
And that's joint work
of Max Bazerman, who's

00:45:35.840 --> 00:45:38.680
sitting right there, and
Alexander [INAUDIBLE],

00:45:38.680 --> 00:45:41.420
who is a doctoral student
at the Kennedy School.

00:45:41.420 --> 00:45:43.280
And here's what we want to do.

00:45:43.280 --> 00:45:46.340
We want to look at how we
evaluate the candidates.

00:45:46.340 --> 00:45:51.050
And that is now more
about what criteria

00:45:51.050 --> 00:45:54.740
do we take into account as
we're evaluating candidates,

00:45:54.740 --> 00:45:57.105
and how many candidates do
we look at the same time.

00:45:57.105 --> 00:46:00.970
In fact I think I'm going to go
fast forward here and show you

00:46:00.970 --> 00:46:04.190
the design so you get a
sense of what we're doing.

00:46:04.190 --> 00:46:06.810
So this is a study that we
conducted in the Harvard

00:46:06.810 --> 00:46:09.030
Decision Science Laboratory.

00:46:09.030 --> 00:46:14.660
And it has the
following scenario.

00:46:14.660 --> 00:46:17.050
We first had a group
of people come in.

00:46:17.050 --> 00:46:18.870
And they perform a task.

00:46:18.870 --> 00:46:22.150
They perform either a math
task or a verbal task.

00:46:22.150 --> 00:46:23.841
And these are our agents.

00:46:23.841 --> 00:46:25.590
We're actually not
particularly interested

00:46:25.590 --> 00:46:27.381
about their behavior,
but we need your data

00:46:27.381 --> 00:46:30.680
to know how they
performed in these tasks.

00:46:30.680 --> 00:46:32.470
And then you come in.

00:46:32.470 --> 00:46:35.580
You come in as the principal
or the hiring agent,

00:46:35.580 --> 00:46:39.270
HR officer, or a person who
is responsible for promotion

00:46:39.270 --> 00:46:40.990
decision.

00:46:40.990 --> 00:46:43.230
And we give you information
of the performance

00:46:43.230 --> 00:46:46.420
of these candidates
in this experiment.

00:46:46.420 --> 00:46:49.940
And then we're telling
you can now choose one,

00:46:49.940 --> 00:46:52.830
and you will be paid based
on that person's performance

00:46:52.830 --> 00:46:54.212
in a future round.

00:46:54.212 --> 00:46:56.420
So we're not telling you
that the person participated

00:46:56.420 --> 00:46:57.836
in this experiment
several rounds.

00:46:57.836 --> 00:46:59.870
We're telling you about
their past performance,

00:46:59.870 --> 00:47:02.590
but they've also participated
in one more around.

00:47:02.590 --> 00:47:05.060
You can choose someone
for this future round,

00:47:05.060 --> 00:47:08.781
and you will be paid based
on how well that person did.

00:47:08.781 --> 00:47:10.280
And what we're
interested in is what

00:47:10.280 --> 00:47:11.470
you based your decision on.

00:47:11.470 --> 00:47:15.750
Do you base your decision
on past performance, which

00:47:15.750 --> 00:47:17.630
is the right thing
to do, statistically

00:47:17.630 --> 00:47:19.471
speaking-- very highly,
highly correlated

00:47:19.471 --> 00:47:20.470
with future performance.

00:47:20.470 --> 00:47:22.595
So how well you solved the
math problem in the past

00:47:22.595 --> 00:47:24.080
is very predictive
of how well you

00:47:24.080 --> 00:47:25.360
do that in the future round.

00:47:25.360 --> 00:47:32.150
Or do you take other criteria
about that person into account?

00:47:32.150 --> 00:47:35.270
And we give you a host of
demographic information

00:47:35.270 --> 00:47:39.780
on these people, which
however is identical for all

00:47:39.780 --> 00:47:42.210
our candidates but for gender.

00:47:42.210 --> 00:47:43.960
So you learn that the
person is a student.

00:47:43.960 --> 00:47:47.400
You learn the person's
between 18 and 22 years,

00:47:47.400 --> 00:47:49.790
is from the Boston
area, et cetera,

00:47:49.790 --> 00:47:51.850
in our case was Caucasian.

00:47:51.850 --> 00:47:54.470
Everything's identical
but for the gender.

00:47:54.470 --> 00:47:59.210
So we're wondering, do
gender stereotypical beliefs

00:47:59.210 --> 00:48:04.120
about performance affect your
likelihood of hiring a person.

00:48:04.120 --> 00:48:08.410
So are you more likely to choose
the woman for the verbal task

00:48:08.410 --> 00:48:13.410
and the man for the math
task, possibly independent

00:48:13.410 --> 00:48:17.790
or disregarding information
of their past performance?

00:48:17.790 --> 00:48:19.540
OK, so that's what we do.

00:48:19.540 --> 00:48:21.270
And we have a two by
two by two design.

00:48:21.270 --> 00:48:25.000
So we have both, as I said,
male and female candidates.

00:48:25.000 --> 00:48:28.660
And we have the
following two conditions

00:48:28.660 --> 00:48:30.570
where the performance
of the person

00:48:30.570 --> 00:48:32.872
was either high, was
a good performance.

00:48:32.872 --> 00:48:34.330
And you got
information about that.

00:48:34.330 --> 00:48:36.370
So you knew how that
person performed compared

00:48:36.370 --> 00:48:38.425
to the mean of the group.

00:48:38.425 --> 00:48:39.800
So either it was
a high performer

00:48:39.800 --> 00:48:41.720
or it was a low performer.

00:48:41.720 --> 00:48:44.390
So you know the person
did worse than the mean.

00:48:44.390 --> 00:48:47.130
And your alternative, if
you do not hire the person

00:48:47.130 --> 00:48:49.730
is, you go back to the
pool and we pick someone

00:48:49.730 --> 00:48:50.959
at random for you.

00:48:50.959 --> 00:48:52.750
So you know the expected
value of the pool.

00:48:52.750 --> 00:48:54.790
You know an average in the pool.

00:48:54.790 --> 00:48:56.950
People for example
found 10 math problems.

00:48:56.950 --> 00:48:58.300
This is a personal who found 12.

00:48:58.300 --> 00:49:00.872
This is a person who found 8.

00:49:00.872 --> 00:49:04.000
And so this is now the
important condition here.

00:49:04.000 --> 00:49:06.200
And that is, we're
looking at what

00:49:06.200 --> 00:49:09.910
happens when you evaluate
one candidate at a time.

00:49:09.910 --> 00:49:11.970
So what if you get
performance information

00:49:11.970 --> 00:49:14.400
on the male candidate here,
and you know he's male.

00:49:14.400 --> 00:49:17.080
You know he's male, yep.

00:49:17.080 --> 00:49:17.920
You know he's male.

00:49:17.920 --> 00:49:18.920
That was a deep insight.

00:49:22.450 --> 00:49:25.700
And you know how he
performed in the past.

00:49:25.700 --> 00:49:28.340
As compared to,
you get information

00:49:28.340 --> 00:49:29.715
on two candidates, at least.

00:49:29.715 --> 00:49:32.960
Could be more, but at
least two where you can

00:49:32.960 --> 00:49:34.480
make comparison information.

00:49:34.480 --> 00:49:37.322
So they give you information
on a man and a woman

00:49:37.322 --> 00:49:38.780
and how they
performed in the past.

00:49:38.780 --> 00:49:42.070
And we're arguing that
comparison information

00:49:42.070 --> 00:49:48.910
is going to make your judgments,
loosely speak, more rational.

00:49:48.910 --> 00:49:50.780
And what I mean
with that is, you

00:49:50.780 --> 00:49:53.680
will be focusing more on
the objective criteria which

00:49:53.680 --> 00:49:57.220
in fact are predictive
of future behavior.

00:49:57.220 --> 00:49:59.090
OK, so here's what we find.

00:49:59.090 --> 00:50:02.880
I'm going to first show
you the separate condition.

00:50:02.880 --> 00:50:06.870
Now note, these are equally
qualified candidates.

00:50:06.870 --> 00:50:10.280
So you know how well they
performed in the past.

00:50:10.280 --> 00:50:11.670
They performed at
the same level.

00:50:16.650 --> 00:50:19.360
The likelihood of
choosing a man is 66%,

00:50:19.360 --> 00:50:22.270
and the likelihood of
choosing a female is 44%.

00:50:22.270 --> 00:50:26.480
Everything absolutely identical.

00:50:26.480 --> 00:50:28.930
You get a similar, not
quite as extreme, pattern

00:50:28.930 --> 00:50:30.042
for the low performance.

00:50:30.042 --> 00:50:31.750
You also note the
performance didn't seem

00:50:31.750 --> 00:50:33.820
to matter quite as much here.

00:50:33.820 --> 00:50:36.570
But it really was driven
by the gender stereotype.

00:50:36.570 --> 00:50:38.920
Now let's compare that
with the joint evaluation

00:50:38.920 --> 00:50:41.920
where you compare
two candidates.

00:50:41.920 --> 00:50:45.780
The gender bias
completely disappears.

00:50:45.780 --> 00:50:49.230
You also know that certainly
as a low performing candidate,

00:50:49.230 --> 00:50:51.750
you do not want to
be evaluated jointly.

00:50:51.750 --> 00:50:53.800
Because that now
becomes very salient.

00:50:53.800 --> 00:50:56.240
Your performance
becomes very salient.

00:50:56.240 --> 00:50:59.656
And people do not hire the
low performing candidates.

00:50:59.656 --> 00:51:02.880
And this is now putting
it all together.

00:51:02.880 --> 00:51:04.860
Now just quickly so
you get the sense,

00:51:04.860 --> 00:51:05.965
this is not just for math.

00:51:05.965 --> 00:51:07.590
We actually get the
reverse for verbal.

00:51:07.590 --> 00:51:10.190
This was the verbal task.

00:51:10.190 --> 00:51:12.430
It was a word find task,
different types of tasks.

00:51:12.430 --> 00:51:14.650
Here you have to find nations.

00:51:14.650 --> 00:51:17.860
And for example you have
Singapore down here.

00:51:17.860 --> 00:51:20.570
And you have to mark the
words that you could find.

00:51:20.570 --> 00:51:23.440
So we find reversal
in the gender bias.

00:51:23.440 --> 00:51:28.120
Now for verbal tasks, people
prefer the woman to the man

00:51:28.120 --> 00:51:31.250
when they evaluate the
person one at a time.

00:51:31.250 --> 00:51:35.550
As soon as we evaluate
jointly, the gender bias

00:51:35.550 --> 00:51:37.580
goes away again.

00:51:37.580 --> 00:51:41.330
So of course that has
implications for hiring

00:51:41.330 --> 00:51:43.402
and promotion decisions.

00:51:43.402 --> 00:51:44.860
So one question
you may want to ask

00:51:44.860 --> 00:51:48.830
yourself is, the
positions you hire for,

00:51:48.830 --> 00:51:53.060
are their gender
stereotypically male or female?

00:51:53.060 --> 00:51:58.690
Do they fall into the math or do
they fall into the verbal camp?

00:51:58.690 --> 00:52:03.630
So for many organizations,
leadership positions

00:52:03.630 --> 00:52:08.500
are typically associated with
being in the male domain.

00:52:08.500 --> 00:52:12.110
So generally you would
worry based on these results

00:52:12.110 --> 00:52:14.110
that promotions to
leadership positions

00:52:14.110 --> 00:52:15.520
fall into the math camp.

00:52:15.520 --> 00:52:19.200
And so we see those kind of
gender stereotypes emerge.

00:52:19.200 --> 00:52:21.630
And of course then
as an organization,

00:52:21.630 --> 00:52:23.637
you want to maximize
performance.

00:52:23.637 --> 00:52:25.595
You would probably prefer
this joint evaluation

00:52:25.595 --> 00:52:28.310
to a separate evaluation,
although there

00:52:28.310 --> 00:52:30.930
are many, many reasons here--
and I put them down-- many,

00:52:30.930 --> 00:52:32.550
many interest groups
would actually

00:52:32.550 --> 00:52:34.520
prefer the separate
evaluation because it

00:52:34.520 --> 00:52:37.635
serves them better, in
particular the low performers.

00:52:37.635 --> 00:52:40.620
The less qualified people,
for them, it really

00:52:40.620 --> 00:52:44.180
hurts to be compared
with the high performer.

00:52:44.180 --> 00:52:47.090
OK, so this is an example
of a gender nudge.

00:52:47.090 --> 00:52:49.910
You can slightly
change the process

00:52:49.910 --> 00:52:52.080
by which you
evaluate candidates,

00:52:52.080 --> 00:52:54.990
and we would argue therefore
affect the likelihood

00:52:54.990 --> 00:52:59.220
that you base your
decision on stereotypes

00:52:59.220 --> 00:53:04.830
or on past performance or
more objective criteria.

00:53:04.830 --> 00:53:08.210
I want to end with one
more study here, which

00:53:08.210 --> 00:53:12.470
looks a bit more about
effects of diversity

00:53:12.470 --> 00:53:15.120
or the balance in a team.

00:53:15.120 --> 00:53:18.254
And just a side
comment, if you're

00:53:18.254 --> 00:53:19.920
interested in the
benefits of diversity,

00:53:19.920 --> 00:53:24.850
a really nice paper is coming
out this month in Science

00:53:24.850 --> 00:53:27.500
on the benefits of
diversity in teams, which

00:53:27.500 --> 00:53:30.180
I think does one of the best
jobs so far looking across 10

00:53:30.180 --> 00:53:33.190
different tasks, in all
kinds of diversity dimensions

00:53:33.190 --> 00:53:36.850
kind of looking at what are
the effects of diversity.

00:53:36.850 --> 00:53:40.500
And generally there is
the diversity premium.

00:53:40.500 --> 00:53:43.310
But diversity, as you
all know, is hard work.

00:53:43.310 --> 00:53:48.250
So the question is, is it
more of a public goods problem

00:53:48.250 --> 00:53:51.620
where individually we don't want
to actually labor that hard?

00:53:51.620 --> 00:53:52.880
Because diversity is hard.

00:53:52.880 --> 00:53:54.910
It's hard to work
across boundaries.

00:53:54.910 --> 00:53:56.880
But organizationally,
it would actually

00:53:56.880 --> 00:53:59.760
be a good thing if we did.

00:53:59.760 --> 00:54:02.090
So we want to look at
why does that matter.

00:54:02.090 --> 00:54:06.040
And what I'm proposing, in
fact a very, very simple model.

00:54:06.040 --> 00:54:09.860
It's a theoretical model
based in information theory

00:54:09.860 --> 00:54:12.910
in economics, but we also
test in the laboratory.

00:54:12.910 --> 00:54:16.110
And here's just the idea
of what we want to look at.

00:54:16.110 --> 00:54:19.040
We're saying that in
many, many situations,

00:54:19.040 --> 00:54:22.070
including in academia,
we are in an environment

00:54:22.070 --> 00:54:24.860
that you might want to call up
or out, where it's a tournament

00:54:24.860 --> 00:54:27.210
style environment
where either you

00:54:27.210 --> 00:54:28.980
get the big price,
which is tenure,

00:54:28.980 --> 00:54:31.770
or you go someplace else.

00:54:31.770 --> 00:54:33.469
You make get tenure there.

00:54:33.469 --> 00:54:34.260
But it's up or out.

00:54:34.260 --> 00:54:36.980
So that's the kind of
environment we want to study.

00:54:36.980 --> 00:54:39.580
And in this environment,
a very simple way

00:54:39.580 --> 00:54:42.480
to look at the environment
is that the likelihood

00:54:42.480 --> 00:54:44.070
of getting tenure,
the output has

00:54:44.070 --> 00:54:46.560
something to do with the
effort that we put in.

00:54:46.560 --> 00:54:48.010
But there's this
random component

00:54:48.010 --> 00:54:50.171
that we're not
particularly interested in.

00:54:50.171 --> 00:54:52.670
And hopefully a big fraction
of the output is due to effort,

00:54:52.670 --> 00:54:56.730
but there's also some randomness
involved in the process.

00:54:56.730 --> 00:54:58.970
And the main argument
that we're making

00:54:58.970 --> 00:55:02.810
is that information
that you have

00:55:02.810 --> 00:55:07.540
about this random component has
something to do with how many

00:55:07.540 --> 00:55:11.950
like you are around.

00:55:11.950 --> 00:55:14.180
So think of the
following situation.

00:55:14.180 --> 00:55:16.670
You're trying to get information
on the tenure process.

00:55:16.670 --> 00:55:19.110
You're a junior faculty member.

00:55:19.110 --> 00:55:21.610
And as it just happened to
me recently, as Judy knows,

00:55:21.610 --> 00:55:22.510
you get an email.

00:55:22.510 --> 00:55:24.930
I'm chairing a
committee right now.

00:55:24.930 --> 00:55:27.300
You get an email
from the candidate.

00:55:27.300 --> 00:55:28.950
What information is available?

00:55:28.950 --> 00:55:34.060
Could we get access
to other statements

00:55:34.060 --> 00:55:36.070
from the past, research
statements, et cetera,

00:55:36.070 --> 00:55:37.250
et cetera.

00:55:37.250 --> 00:55:39.675
Now it turns out
that that information

00:55:39.675 --> 00:55:43.860
is kind of implicitly available,
but you have to ask for it.

00:55:43.860 --> 00:55:49.280
Now often the asking
happens along gender lines

00:55:49.280 --> 00:55:52.790
or racial lines, or
even nationality lines,

00:55:52.790 --> 00:55:54.380
also disciplinary lines.

00:55:54.380 --> 00:55:57.500
And the person more
naturally to ask for help

00:55:57.500 --> 00:56:00.170
often is someone who is like me.

00:56:00.170 --> 00:56:03.060
And there's a lot of research
on networks and mentoring,

00:56:03.060 --> 00:56:05.370
et cetera, which suggests
that that's true.

00:56:05.370 --> 00:56:08.340
But also in this case
it in fact was true.

00:56:08.340 --> 00:56:10.130
And then there's another
piece of evidence

00:56:10.130 --> 00:56:12.845
that is based on the Hannah
Riley Bowles' research, who

00:56:12.845 --> 00:56:14.560
is at the Kennedy School.

00:56:14.560 --> 00:56:16.687
It's harder for women to ask.

00:56:16.687 --> 00:56:18.520
You may also know the
book by Linda Babcock,

00:56:18.520 --> 00:56:21.880
Women Don't Ask, because
there's social consequences

00:56:21.880 --> 00:56:23.110
if you do ask.

00:56:23.110 --> 00:56:25.680
So I think this is a
bit of a side comment.

00:56:25.680 --> 00:56:30.290
But as I'm thinking about our
hiring and promotion procedures

00:56:30.290 --> 00:56:32.340
and tenure evaluations,
that is something

00:56:32.340 --> 00:56:35.650
that I urge us to
think hard about.

00:56:35.650 --> 00:56:38.020
What information is
explicitly available,

00:56:38.020 --> 00:56:39.690
and what is
implicitly available?

00:56:39.690 --> 00:56:42.120
What do people have to ask for?

00:56:42.120 --> 00:56:45.930
And what if there are
differences in your ability

00:56:45.930 --> 00:56:51.080
to ask because of who you are or
because of the network that you

00:56:51.080 --> 00:56:54.232
are in because there are
fewer people like you around?

00:56:54.232 --> 00:56:56.190
And Judy, in fact she
had an interesting story,

00:56:56.190 --> 00:56:58.930
if I may share that,
gave a presentation

00:56:58.930 --> 00:57:01.230
with a male faculty member.

00:57:01.230 --> 00:57:03.370
And they totally shared
the presentation.

00:57:03.370 --> 00:57:05.039
She said, and then
interestingly enough,

00:57:05.039 --> 00:57:06.580
afterwards there
was a line of people

00:57:06.580 --> 00:57:09.470
who wanted to talk to
the authors of the study,

00:57:09.470 --> 00:57:11.300
and totally gender segregated.

00:57:11.300 --> 00:57:12.980
The women would talk
to Judy and the men

00:57:12.980 --> 00:57:14.757
would talk to him,
although the study had

00:57:14.757 --> 00:57:15.840
nothing to do with gender.

00:57:18.350 --> 00:57:21.160
So I think I wanted to trigger
your thinking a little bit

00:57:21.160 --> 00:57:25.160
of, so how does it matter who
else is in the room or who else

00:57:25.160 --> 00:57:26.180
in the team?

00:57:26.180 --> 00:57:28.285
So for us in our model,
we're arguing this

00:57:28.285 --> 00:57:29.692
is an informational argument.

00:57:29.692 --> 00:57:31.150
I'm sure there's
many others-- just

00:57:31.150 --> 00:57:32.275
an informational arguments.

00:57:32.275 --> 00:57:35.080
So I'm better informed
about this random component

00:57:35.080 --> 00:57:37.490
here, the things
that are maybe not

00:57:37.490 --> 00:57:39.840
quite as transparent,
the more people like

00:57:39.840 --> 00:57:42.420
me are around because I
can ask them for advice.

00:57:42.420 --> 00:57:45.280
I can get information
on what to do,

00:57:45.280 --> 00:57:47.120
what is available
and not available.

00:57:47.120 --> 00:57:50.590
And I don't want to walk you
through the whole study here.

00:57:50.590 --> 00:57:52.160
But that's exactly what we find.

00:57:52.160 --> 00:57:55.100
So we create groups,
majority groups

00:57:55.100 --> 00:57:57.710
which are better informed
on that luck component,

00:57:57.710 --> 00:57:59.170
that random component.

00:57:59.170 --> 00:58:01.180
And we create groups
which are worse informed

00:58:01.180 --> 00:58:02.780
on that random component.

00:58:02.780 --> 00:58:04.780
And we find that this
affects their performance.

00:58:04.780 --> 00:58:08.760
In fact I'm going to go
fast forward here if I can

00:58:08.760 --> 00:58:11.270
and just show you the
final results here.

00:58:11.270 --> 00:58:13.194
So what you have here
is the large group,

00:58:13.194 --> 00:58:14.610
the majority group
which is better

00:58:14.610 --> 00:58:18.200
informed, and this is an
indicator of their performance.

00:58:18.200 --> 00:58:21.400
Turns out that we
always find this gap,

00:58:21.400 --> 00:58:23.050
this informational
gap is just due

00:58:23.050 --> 00:58:27.570
to informational differences
about this more random

00:58:27.570 --> 00:58:31.680
component in this process.

00:58:31.680 --> 00:58:34.030
So with that, let me conclude.

00:58:34.030 --> 00:58:38.320
Gentle changes in
procedures can really

00:58:38.320 --> 00:58:42.690
have quite dramatic impact
we would submit to you.

00:58:42.690 --> 00:58:44.460
So we know the choice
of comparison sets

00:58:44.460 --> 00:58:47.510
affect the likelihood
of being hired.

00:58:47.510 --> 00:58:50.519
So just to think about how
you look at candidates.

00:58:50.519 --> 00:58:51.810
You look at them one at a time.

00:58:51.810 --> 00:58:53.145
Do you compare them?

00:58:53.145 --> 00:58:54.980
Do we have comparison
information

00:58:54.980 --> 00:58:56.189
as part of our process?

00:58:56.189 --> 00:58:57.230
What does that look like?

00:58:57.230 --> 00:58:59.579
Do we leave it up to
the letter writers

00:58:59.579 --> 00:59:01.120
to choose their own
comparison group,

00:59:01.120 --> 00:59:04.060
or do we give the
comparison group?

00:59:04.060 --> 00:59:06.570
Really think hard
about comparisons

00:59:06.570 --> 00:59:07.950
and how you're using them.

00:59:07.950 --> 00:59:09.750
And then secondly
just an illustration

00:59:09.750 --> 00:59:13.920
of how the gender balance,
or diversity more generally

00:59:13.920 --> 00:59:16.315
in teams, might affect
people's performance

00:59:16.315 --> 00:59:20.210
due to these informational
differences between the two

00:59:20.210 --> 00:59:20.820
groups.

00:59:20.820 --> 00:59:21.618
Thank you.

00:59:21.618 --> 00:59:25.602
[APPLAUSE]

00:59:43.720 --> 00:59:45.670
My mother taught
me to speak loudly,

00:59:45.670 --> 00:59:51.140
so I don't need a microphone.

00:59:51.140 --> 00:59:54.170
Let me just begin by
saying that we really

00:59:54.170 --> 00:59:57.715
have to recognize that we are
in a very, very different place

00:59:57.715 --> 01:00:01.683
now than groups of people who
sat in this very room 10 and 20

01:00:01.683 --> 01:00:04.884
and 30 years ago
might have been.

01:00:04.884 --> 01:00:07.617
And we have to begin
with that difference

01:00:07.617 --> 01:00:10.848
because without that kind
of optimism, that we're

01:00:10.848 --> 01:00:13.166
different from them,
it will be hard to make

01:00:13.166 --> 01:00:16.315
the kind of progress that I
believe that we need to make.

01:00:16.315 --> 01:00:18.800
We're different from
them in two ways.

01:00:18.800 --> 01:00:21.285
We're different because
our conscious minds

01:00:21.285 --> 01:00:23.273
have changed dramatically.

01:00:23.273 --> 01:00:27.249
If I showed a list of what
people like ourselves believed

01:00:27.249 --> 01:00:30.728
in the 1950s about groups of
people, you would be shocked.

01:00:30.728 --> 01:00:33.213
In fact, I'm glad
Judy started this

01:00:33.213 --> 01:00:35.698
by pointing out what
antisemitism in places

01:00:35.698 --> 01:00:39.390
like Yale and Harvard was like.

01:00:39.390 --> 01:00:42.790
I'll point out a
book by Dan Oren,

01:00:42.790 --> 01:00:48.430
written many years ago now
called Joining the Club-- A

01:00:48.430 --> 01:00:49.980
History of Jews at Yale.

01:00:49.980 --> 01:00:53.230
And as I read it, I just
especially remember this one

01:00:53.230 --> 01:00:55.570
page where he
literally just xeroxed

01:00:55.570 --> 01:01:02.220
a copy of an application form
and the reason for rejection

01:01:02.220 --> 01:01:03.280
in it.

01:01:03.280 --> 01:01:06.800
And some professor
at Yale had scrawled

01:01:06.800 --> 01:01:09.580
in the box that said
reason for rejection,

01:01:09.580 --> 01:01:12.970
has a Mediterranean nose.

01:01:12.970 --> 01:01:16.340
That was, at Yale-- and I'm
going to argue, I think,

01:01:16.340 --> 01:01:21.160
here too-- a sufficient basis
for rejecting a candidate.

01:01:21.160 --> 01:01:22.750
We are not those people.

01:01:22.750 --> 01:01:25.620
We no longer not only
say things like that,

01:01:25.620 --> 01:01:27.140
we don't believe them.

01:01:27.140 --> 01:01:29.910
We would frown upon people
who say things like that.

01:01:29.910 --> 01:01:34.440
But I'm going to argue that
even antisemitism hasn't gotten.

01:01:34.440 --> 01:01:38.210
All you had to do is listen
carefully to liberal NPR

01:01:38.210 --> 01:01:41.480
during the Bernie Madoff weeks.

01:01:41.480 --> 01:01:44.380
And here it's surfacing
again to the top

01:01:44.380 --> 01:01:45.820
as if it had not gone away.

01:01:45.820 --> 01:01:49.210
So I'm here to say these
things, that our minds have

01:01:49.210 --> 01:01:52.420
two very different modes
in which they function.

01:01:52.420 --> 01:01:53.930
There is a conscious mode.

01:01:53.930 --> 01:01:56.830
Think about Abraham
Lincoln, the emancipator,

01:01:56.830 --> 01:02:00.520
and know that we have the
emancipator in each of us.

01:02:00.520 --> 01:02:02.960
But we also have in
each of our minds

01:02:02.960 --> 01:02:05.850
Abraham Lincoln who believed
that black and white could

01:02:05.850 --> 01:02:08.750
never be equal, that one
was superior to the other,

01:02:08.750 --> 01:02:12.430
that they could never work
together, let alone ever marry.

01:02:12.430 --> 01:02:14.520
We carry that in
each of our minds,

01:02:14.520 --> 01:02:15.910
and we had better know that.

01:02:15.910 --> 01:02:17.690
And this is one of
the ways in which we

01:02:17.690 --> 01:02:20.320
are different from
our predecessors,

01:02:20.320 --> 01:02:22.610
that we're not going
to be happy just saying

01:02:22.610 --> 01:02:24.910
that because I don't
say Mediterranean nose,

01:02:24.910 --> 01:02:27.000
I no longer have these biases.

01:02:27.000 --> 01:02:27.700
We do.

01:02:27.700 --> 01:02:28.790
We have tons of them.

01:02:28.790 --> 01:02:28.900
What's

01:02:28.900 --> 01:02:30.860
So what's second way in
which we're different?

01:02:30.860 --> 01:02:33.550
We're different because
even 10 years ago,

01:02:33.550 --> 01:02:35.980
there was not a
science of this stuff.

01:02:35.980 --> 01:02:39.070
What Sheena and what Iris
and what others have now

01:02:39.070 --> 01:02:42.770
demonstrated for us
is that just as we

01:02:42.770 --> 01:02:46.110
can be great physicists and
great people who understand

01:02:46.110 --> 01:02:49.360
strategy and finance and
medicine, because we are

01:02:49.360 --> 01:02:52.320
schooled in those
methods, that likewise

01:02:52.320 --> 01:02:55.820
we have to be schooled, every
one of us to some extent,

01:02:55.820 --> 01:02:57.780
in the processes
of decision making.

01:02:57.780 --> 01:02:59.100
Because there is a science.

01:02:59.100 --> 01:03:01.110
It can tell us about
the right and wrong ways

01:03:01.110 --> 01:03:02.470
to make decisions.

01:03:02.470 --> 01:03:04.850
And we have to hold ourselves
to a higher standard

01:03:04.850 --> 01:03:08.210
because this knowledge
was simply not available

01:03:08.210 --> 01:03:11.220
even a few years ago, let
alone a few decades ago.

01:03:11.220 --> 01:03:13.560
So our responsibility
is greater.

01:03:13.560 --> 01:03:15.910
If I had to leave you
with like a few ideas

01:03:15.910 --> 01:03:17.715
that we might use to
have a discussion--

01:03:17.715 --> 01:03:19.730
and my job really
is to just help

01:03:19.730 --> 01:03:22.250
moderate a discussion
between our two

01:03:22.250 --> 01:03:25.110
amazing speakers
and you as you begin

01:03:25.110 --> 01:03:27.220
to think about
searches-- could I just

01:03:27.220 --> 01:03:29.320
say that I think the first
thing to keep in mind

01:03:29.320 --> 01:03:31.840
is that you as
chairs of departments

01:03:31.840 --> 01:03:34.140
and as members of
search committees

01:03:34.140 --> 01:03:36.200
automatically
become conservative

01:03:36.200 --> 01:03:37.990
when you're put in that role.

01:03:37.990 --> 01:03:40.850
Social psychology will tell
you over and over again

01:03:40.850 --> 01:03:45.060
that we believe that the font
or the source of behavior

01:03:45.060 --> 01:03:49.160
information or action
lies in individual people,

01:03:49.160 --> 01:03:50.940
but we don't
recognize the extent

01:03:50.940 --> 01:03:54.720
to which power and
source of influence

01:03:54.720 --> 01:03:56.760
lies in the situation.

01:03:56.760 --> 01:03:59.210
By putting you on a
bicycle and having you

01:03:59.210 --> 01:04:04.180
race around Cambridge, we can
make you hate car drivers.

01:04:04.180 --> 01:04:06.200
As soon as we put
you in a car, we

01:04:06.200 --> 01:04:08.760
can make you hate people like
me who race around crazily

01:04:08.760 --> 01:04:10.100
on a bicycle.

01:04:10.100 --> 01:04:12.020
I mean, these are
simple roles that we

01:04:12.020 --> 01:04:15.530
play that have very powerful
effects on what we like,

01:04:15.530 --> 01:04:16.890
who we think is good, and so on.

01:04:16.890 --> 01:04:18.670
And one of the things
I'm very concerned

01:04:18.670 --> 01:04:21.950
about-- because I have seen
it happen to me-- that I

01:04:21.950 --> 01:04:25.460
am unwilling to even
use the word risk

01:04:25.460 --> 01:04:27.256
or risky when I'm on
a search committee.

01:04:27.256 --> 01:04:28.880
But being outside
the search committee,

01:04:28.880 --> 01:04:31.790
I'm perfectly happy to say,
let's try this new thing.

01:04:31.790 --> 01:04:36.060
So I just want you to be aware
that when you are in that role,

01:04:36.060 --> 01:04:37.980
you will never want
to make a false alarm.

01:04:37.980 --> 01:04:40.510
You'd rather have a miss
because letting somebody good

01:04:40.510 --> 01:04:43.470
go away to Stanford you
will say is not as big

01:04:43.470 --> 01:04:45.780
a problem as having
some dud here stuck

01:04:45.780 --> 01:04:47.850
with us for the next 50 years.

01:04:47.850 --> 01:04:50.930
And so you will-- you
will be pushing very hard.

01:04:50.930 --> 01:04:54.510
And I'm just going to ask
that you consult very broadly

01:04:54.510 --> 01:04:56.530
to know that while you
should be carefuf--

01:04:56.530 --> 01:05:00.220
and I do believe with you that
for us, the criterion should

01:05:00.220 --> 01:05:02.640
be one where a miss is
better than a false alarm.

01:05:02.640 --> 01:05:04.670
So I'm not asking
us to change that.

01:05:04.670 --> 01:05:06.680
But how we think
something is a false alarm

01:05:06.680 --> 01:05:08.900
or when we think
something's a false alarm is

01:05:08.900 --> 01:05:11.402
really dependent on the type
of person we're looking for.

01:05:11.402 --> 01:05:13.360
And that's something
we're going to have to do.

01:05:13.360 --> 01:05:16.080
So believe in this, the
power of situations,

01:05:16.080 --> 01:05:17.750
and analyze the
situation for what

01:05:17.750 --> 01:05:20.570
it's doing to you as you
make these decisions.

01:05:20.570 --> 01:05:22.270
The second point
that I want to make

01:05:22.270 --> 01:05:26.790
is that we all carry a
model of what success means.

01:05:26.790 --> 01:05:29.750
And that model is hugely
powerful in guiding

01:05:29.750 --> 01:05:33.520
all sorts of search processes.

01:05:33.520 --> 01:05:35.860
You know, I was at
Vanderbilt University

01:05:35.860 --> 01:05:38.640
speaking to their
medical school last week.

01:05:38.640 --> 01:05:41.310
And I remember thinking as
I was being asked questions

01:05:41.310 --> 01:05:44.570
in deeply Southern accents,
I thought to myself,

01:05:44.570 --> 01:05:48.320
maybe at Harvard we've gotten
over a lot of different kinds

01:05:48.320 --> 01:05:49.790
of biases.

01:05:49.790 --> 01:05:51.925
But I bet that this
person asking me

01:05:51.925 --> 01:05:55.390
a perfectly good question could
never get a job here because

01:05:55.390 --> 01:05:59.500
to us, a Southern
accent is correlated

01:05:59.500 --> 01:06:01.590
with many other
things that we truly

01:06:01.590 --> 01:06:05.501
believe is not smart, has
different values, and so on.

01:06:05.501 --> 01:06:07.250
And so I'm just bringing
this up because I

01:06:07.250 --> 01:06:10.920
want you to think about
diversity in a much broader way

01:06:10.920 --> 01:06:12.070
then we have.

01:06:12.070 --> 01:06:15.890
I have a colleague who looks
to you very mainstream--

01:06:15.890 --> 01:06:23.190
white, male, Protestant,
six feet, six inches tall.

01:06:23.190 --> 01:06:26.690
And yet he walks around Harvard
feeling like he doesn't belong.

01:06:26.690 --> 01:06:30.980
And he feels that because
he's a farm boy from Illinois,

01:06:30.980 --> 01:06:32.430
and he grew up on a small farm.

01:06:32.430 --> 01:06:34.014
And he says, you
know, I never fit in.

01:06:34.014 --> 01:06:36.263
In rooms like this, I feel
I'm going to drop something

01:06:36.263 --> 01:06:37.760
or I'm going to
say something that

01:06:37.760 --> 01:06:40.650
isn't like how people--
he's been here for 20 years

01:06:40.650 --> 01:06:42.740
and for the previous 20 at Yale.

01:06:42.740 --> 01:06:45.680
But he still believes that he's
this bumbling farm boy who is

01:06:45.680 --> 01:06:47.147
going to say something stupid.

01:06:47.147 --> 01:06:48.980
What I want to take
away is that this person

01:06:48.980 --> 01:06:51.050
is very valuable
to the university

01:06:51.050 --> 01:06:54.010
because one of things
he does is he never

01:06:54.010 --> 01:06:55.780
toes the line in any way.

01:06:55.780 --> 01:06:58.660
He's the first one to
say to us, you guys

01:06:58.660 --> 01:07:01.007
just don't think this way,
because he carries around

01:07:01.007 --> 01:07:03.590
in his mind this view that he's
different from the rest of us.

01:07:03.590 --> 01:07:06.970
And so he's very valuable
to us because he will not

01:07:06.970 --> 01:07:09.490
take any decision at
face value and will

01:07:09.490 --> 01:07:10.490
probe a little bit more.

01:07:10.490 --> 01:07:12.980
And I'm going to ask us
that we-- diversity needs

01:07:12.980 --> 01:07:16.090
to be thought about in
a whole variety of ways.

01:07:16.090 --> 01:07:19.000
And finally I want to say,
don't trust people like me.

01:07:19.000 --> 01:07:22.600
Don't trust people who look like
they're women, people of color,

01:07:22.600 --> 01:07:24.910
and that we will do what's
right for our groups.

01:07:24.910 --> 01:07:25.620
We won't.

01:07:25.620 --> 01:07:30.050
We too have in our minds
embodied the very same things

01:07:30.050 --> 01:07:31.860
that you regard to be important.

01:07:31.860 --> 01:07:34.050
And we will make the
same mistakes with you

01:07:34.050 --> 01:07:37.750
unless we are all being
educated to be different.

01:07:37.750 --> 01:07:40.440
So I have developed
a set of tests

01:07:40.440 --> 01:07:43.680
that will teach us something
about what's in our minds.

01:07:43.680 --> 01:07:45.360
I encourage you to
take those tests,

01:07:45.360 --> 01:07:47.570
because you may discover
that as somebody white,

01:07:47.570 --> 01:07:49.840
you actually don't
have a pro-white bias.

01:07:49.840 --> 01:07:53.190
As somebody black, you may
actually have a pro-white bias.

01:07:53.190 --> 01:07:55.670
And you need to know what's
in your individual minds

01:07:55.670 --> 01:07:58.890
as you go forward in
making these decisions.

01:07:58.890 --> 01:08:02.150
So with that, let me just say
that keeping in mind that there

01:08:02.150 --> 01:08:06.640
are situational influences
that we embody in us models

01:08:06.640 --> 01:08:09.270
of things that are
good that are actually

01:08:09.270 --> 01:08:11.070
very much the
standard is something

01:08:11.070 --> 01:08:12.236
that we have to worry about.

01:08:12.236 --> 01:08:14.770
And finally I will
say that familiarity

01:08:14.770 --> 01:08:18.330
is a hugely powerful
motivator of behavior.

01:08:18.330 --> 01:08:20.050
There's a lovely
New Yorker cartoon

01:08:20.050 --> 01:08:23.229
that has two snails
talking to each other,

01:08:23.229 --> 01:08:26.340
looking at a large
tape dispenser.

01:08:26.340 --> 01:08:29.710
And one snail says
to the other snail,

01:08:29.710 --> 01:08:31.939
"I don't care that
she's a tape dispenser.

01:08:31.939 --> 01:08:34.300
I just love her."

01:08:34.300 --> 01:08:36.460
And I think that this
is what happens to us.

01:08:36.460 --> 01:08:39.510
When we see tape dispensers
that look like ourselves,

01:08:39.510 --> 01:08:41.670
our heart just
rushes out to them.

01:08:41.670 --> 01:08:44.600
It could be anything that
makes the familiarity.

01:08:44.600 --> 01:08:48.490
Their eyes could be the same
color as our mother's eyes.

01:08:48.490 --> 01:08:50.810
Their father may have
gone to the same school

01:08:50.810 --> 01:08:53.170
that you went to.

01:08:53.170 --> 01:08:55.770
You may both love
classical music.

01:08:55.770 --> 01:09:00.520
These are the kinds of things
that make interviews be deadly.

01:09:00.520 --> 01:09:03.260
And we base so much
on the interview.

01:09:03.260 --> 01:09:05.930
And there are good data to
suggest that unless each of us

01:09:05.930 --> 01:09:10.160
is schooled in performing
structured interviews,

01:09:10.160 --> 01:09:14.130
that the interview plus
resume leads to worse

01:09:14.130 --> 01:09:17.340
decisions than resume alone.

01:09:17.340 --> 01:09:20.620
And we'd better know that
before we spend the kind of time

01:09:20.620 --> 01:09:23.470
that we do on talks
focusing on things

01:09:23.470 --> 01:09:26.819
like physical form, accent,
where somebody's come from,

01:09:26.819 --> 01:09:27.319
and so on.

01:09:27.319 --> 01:09:29.149
So I'm just putting
these out for you

01:09:29.149 --> 01:09:30.890
because the job
we're now telling

01:09:30.890 --> 01:09:33.653
you have is far
bigger and far harder

01:09:33.653 --> 01:09:34.819
than you might have thought.

01:09:34.819 --> 01:09:36.380
You can ask yourself,
what am I supposed to do,

01:09:36.380 --> 01:09:38.200
like think about every
one of these things?

01:09:38.200 --> 01:09:39.825
How am I ever going
to make a decision?

01:09:39.825 --> 01:09:42.540
Well, we'll do it, and we'll do
it better than people before us

01:09:42.540 --> 01:09:45.330
did because we have
knowledge that they didn't.

01:09:45.330 --> 01:09:46.989
So with that, I'm going to stop.

01:09:46.989 --> 01:09:49.760
And I'll tell you that
we'll open this up

01:09:49.760 --> 01:09:54.120
for at least a few minutes of
questions to our two panelists.

01:09:54.120 --> 01:09:55.350
And I will help moderate.

01:09:55.350 --> 01:09:56.630
So just raise your hand.

01:09:56.630 --> 01:09:58.310
And also ask
questions of the kinds

01:09:58.310 --> 01:10:00.780
of things you would want
the administration to do.

01:10:00.780 --> 01:10:03.660
Today you heard about things
like multiple searches

01:10:03.660 --> 01:10:06.480
at one time may be better
than one after the other.

01:10:06.480 --> 01:10:08.840
Well maybe our deans
need to know this.

01:10:08.840 --> 01:10:11.000
And maybe they need to
figure out ways with us,

01:10:11.000 --> 01:10:13.869
but how to construct
searches so we can maximize

01:10:13.869 --> 01:10:14.910
the possibility of these.

01:10:14.910 --> 01:10:17.650
So feel free to raise anything
you want, and I'm sure Sheena

01:10:17.650 --> 01:10:20.290
and Iris will answer them all.

01:10:20.290 --> 01:10:22.020
Yes.

01:10:22.020 --> 01:10:24.520
Just stand up and ask question
so we know who you are.

01:10:24.520 --> 01:10:28.860
A few times the phrase
objective criteria came up.

01:10:28.860 --> 01:10:34.165
And I was wondering if you could
say a bit more about what that

01:10:34.165 --> 01:10:36.170
means in the context
faculty searches,

01:10:36.170 --> 01:10:41.720
both in the initial stage one
of filtering out applications,

01:10:41.720 --> 01:10:44.650
and also later
when one is trying

01:10:44.650 --> 01:10:51.450
to draw the line between
perhaps legitimate questions

01:10:51.450 --> 01:10:53.194
of collegiality
and whether someone

01:10:53.194 --> 01:10:54.860
will be a good citizen
in the department

01:10:54.860 --> 01:10:58.820
and interact with others
and inappropriate criteria

01:10:58.820 --> 01:11:02.145
that we don't want to be using
that becomes very close when

01:11:02.145 --> 01:11:04.620
you start thinking about fit.

01:11:04.620 --> 01:11:07.750
Let me try and take
a first try at this.

01:11:07.750 --> 01:11:09.580
So certainly in our
experiments that

01:11:09.580 --> 01:11:11.410
was very easy to delineate.

01:11:11.410 --> 01:11:14.750
I completely here
you that in search

01:11:14.750 --> 01:11:17.700
processes, in
evaluation procedures,

01:11:17.700 --> 01:11:20.160
that's much harder to do.

01:11:20.160 --> 01:11:26.500
So I think the first step
might be along Sheena's lines,

01:11:26.500 --> 01:11:31.330
really to think about what
are the criteria that we want

01:11:31.330 --> 01:11:35.930
our decisions to based on,
to think hard about what

01:11:35.930 --> 01:11:37.020
are those criteria.

01:11:37.020 --> 01:11:39.650
And I think we all can have
some sense of publications,

01:11:39.650 --> 01:11:41.539
et cetera, citations
and other things

01:11:41.539 --> 01:11:42.580
that we might care about.

01:11:42.580 --> 01:11:48.115
And to have the discussion of
what are we worrying about,

01:11:48.115 --> 01:11:49.740
and then get a sense
of how much weight

01:11:49.740 --> 01:11:51.650
should be put in all of these.

01:11:51.650 --> 01:11:54.860
Just one additional
comment, I think

01:11:54.860 --> 01:11:56.706
there are situations
where it's very obvious

01:11:56.706 --> 01:11:58.330
and then there's
others where it's not.

01:11:58.330 --> 01:12:01.390
But I'm thinking of
Claudia Goldin's work

01:12:01.390 --> 01:12:04.360
on blind auditions
of orchestras where

01:12:04.360 --> 01:12:06.450
it was pretty clear that
the decision should not

01:12:06.450 --> 01:12:10.000
be based on the gender of
the race or anything else

01:12:10.000 --> 01:12:12.600
but how good a violinist
that person is.

01:12:12.600 --> 01:12:14.611
And of course the
blindness-- if anything

01:12:14.611 --> 01:12:16.360
we haven't mentioned
that because it's not

01:12:16.360 --> 01:12:20.340
very practical-- but
that blindness is really

01:12:20.340 --> 01:12:23.290
the only way that I
believe, at this point,

01:12:23.290 --> 01:12:25.540
we could really
overcome our biases.

01:12:25.540 --> 01:12:28.530
I mean, everything
else we're proposing

01:12:28.530 --> 01:12:30.080
I think are improvements.

01:12:30.080 --> 01:12:33.110
But at the end of the day,
we're all part of this society,

01:12:33.110 --> 01:12:38.140
and therefore we'll
fall into these trap.

01:12:38.140 --> 01:12:42.460
So my view on this is that
the point at which you

01:12:42.460 --> 01:12:46.930
can be, quote, unquote,
objective-- and objective is

01:12:46.930 --> 01:12:52.460
also sort of a subjective term--
is in that process where you're

01:12:52.460 --> 01:12:54.890
looking at those initial
vitaes and you're

01:12:54.890 --> 01:12:57.840
evaluating who's going to
make it into the short list

01:12:57.840 --> 01:13:01.090
to interview, I think
at that point for that,

01:13:01.090 --> 01:13:05.680
you can come up with
more measurable criteria.

01:13:05.680 --> 01:13:09.170
You can create quantitative
measures of, say, publication

01:13:09.170 --> 01:13:11.390
record, impact on the field.

01:13:11.390 --> 01:13:13.210
Whether you believe
in citation hits,

01:13:13.210 --> 01:13:16.880
I mean that's obviously always
been a controversy depending

01:13:16.880 --> 01:13:17.500
on field.

01:13:17.500 --> 01:13:21.220
Like always the operations
people are anti-citation hits

01:13:21.220 --> 01:13:23.132
and the psychologists
are pro-citation hits.

01:13:23.132 --> 01:13:24.632
And so then you
never quite know how

01:13:24.632 --> 01:13:26.570
to get your head
around that one.

01:13:26.570 --> 01:13:29.860
But to the extent that
the particular group has

01:13:29.860 --> 01:13:32.230
a set of measurable
criteria that you

01:13:32.230 --> 01:13:36.430
can use to do that high,
medium, low on the vitaes,

01:13:36.430 --> 01:13:38.900
I think at that
stage it's helpful.

01:13:38.900 --> 01:13:41.460
I think once you get to
that short list of people

01:13:41.460 --> 01:13:44.130
that you're into
reviewing, it's probably

01:13:44.130 --> 01:13:46.640
fair to say that you're
interviewing people

01:13:46.640 --> 01:13:49.920
that are probably all great.

01:13:49.920 --> 01:13:52.160
I presume you won't
be interviewing them

01:13:52.160 --> 01:13:55.380
if they haven't met the bar.

01:13:55.380 --> 01:13:58.950
And at that point what
is, quote, objective,

01:13:58.950 --> 01:14:01.730
which is even more
subjective, is

01:14:01.730 --> 01:14:04.510
what I was talking about
before in stage two,

01:14:04.510 --> 01:14:06.430
is coming up with
as much as possible

01:14:06.430 --> 01:14:08.630
your specific
criteria as to what

01:14:08.630 --> 01:14:10.830
you're looking
for, acknowledging

01:14:10.830 --> 01:14:12.230
the disagreements.

01:14:12.230 --> 01:14:15.190
But at least once you have
that specific criteria,

01:14:15.190 --> 01:14:17.630
you're now focusing
everybody's attention

01:14:17.630 --> 01:14:20.220
towards those criteria.

01:14:20.220 --> 01:14:24.000
And now while surfacing
the information related

01:14:24.000 --> 01:14:26.430
to the different
candidates, you're

01:14:26.430 --> 01:14:29.590
forcing the people
doing the evaluating

01:14:29.590 --> 01:14:33.540
to think about those candidates
in terms of that criteria

01:14:33.540 --> 01:14:35.060
that they just talked about.

01:14:35.060 --> 01:14:38.220
So that's why I said first
board have the criteria,

01:14:38.220 --> 01:14:40.480
second board have
the information

01:14:40.480 --> 01:14:43.300
about the various
candidates surfacing,

01:14:43.300 --> 01:14:45.520
and then do the
semiprivate vote.

01:14:45.520 --> 01:14:49.080
I mean, that's
about as objective

01:14:49.080 --> 01:14:54.460
I can make a subjective
evaluation process to be.

01:14:54.460 --> 01:14:56.720
Yeah, and next you.

01:14:59.540 --> 01:15:02.460
The question I have is
recommendation letters

01:15:02.460 --> 01:15:04.683
play a huge role
in a lot of this,

01:15:04.683 --> 01:15:06.000
reference letters from faculty.

01:15:06.000 --> 01:15:09.430
And I'm worried a lot
about bias in that process.

01:15:09.430 --> 01:15:11.540
So partly we know
certain faculty.

01:15:11.540 --> 01:15:12.440
We trust them.

01:15:12.440 --> 01:15:13.975
And sure, there
are biases in how

01:15:13.975 --> 01:15:15.141
we form those relationships.

01:15:15.141 --> 01:15:17.525
But also, the letters
must inherently

01:15:17.525 --> 01:15:19.750
reflect biases of
the letter writers.

01:15:19.750 --> 01:15:23.078
So I'm wondering whether
learning about this stuff,

01:15:23.078 --> 01:15:25.230
we should be downgrading
those letters

01:15:25.230 --> 01:15:28.090
relative to their current role,
which is really quite dominant,

01:15:28.090 --> 01:15:30.580
at least in economics for sure.

01:15:34.070 --> 01:15:36.220
Yeah, go ahead Sheena.

01:15:36.220 --> 01:15:37.810
This is always very hard.

01:15:37.810 --> 01:15:39.650
And that's why I
had said earlier

01:15:39.650 --> 01:15:42.385
that I gave up on this goal
of trying to completely

01:15:42.385 --> 01:15:47.310
debias individuals or even
debias the individuals making

01:15:47.310 --> 01:15:48.290
up the group.

01:15:48.290 --> 01:15:51.730
So I would say in
your process, you're

01:15:51.730 --> 01:15:54.340
gathering up different
bits of information.

01:15:54.340 --> 01:15:56.350
You're gathering up
those reference letters.

01:15:56.350 --> 01:15:59.110
I wouldn't remove them, because
that's still information.

01:15:59.110 --> 01:16:03.100
I mean you really don't
want to have somebody that's

01:16:03.100 --> 01:16:06.350
thought of as not capable of
doing research on their own

01:16:06.350 --> 01:16:08.380
or producing a
paper on their own.

01:16:08.380 --> 01:16:10.380
So that's still
valuable information,

01:16:10.380 --> 01:16:14.500
but that shouldn't be the only
information that you're using.

01:16:14.500 --> 01:16:16.440
So you're gathering
up the various bits

01:16:16.440 --> 01:16:20.810
of information, and when
you set up your criteria

01:16:20.810 --> 01:16:23.360
as to what you're looking
for, at that stage you

01:16:23.360 --> 01:16:27.340
can specify which
bits of information

01:16:27.340 --> 01:16:31.360
are more or less important, and
then surface the information

01:16:31.360 --> 01:16:32.460
related to each candidate.

01:16:32.460 --> 01:16:35.190
So at least whatever
information you do have there,

01:16:35.190 --> 01:16:39.260
it's all getting
considered in that process.

01:16:39.260 --> 01:16:43.670
But I agree with you that the
letter writer will be biased.

01:16:43.670 --> 01:16:45.700
Each individual on
the committee will

01:16:45.700 --> 01:16:50.690
be biased towards their
favorite letter writers.

01:16:50.690 --> 01:16:52.400
And I think that's just a given.

01:16:52.400 --> 01:16:55.520
And what you hope is that by
creating the decision making

01:16:55.520 --> 01:16:59.250
process which is including
everybody's opinion-- which

01:16:59.250 --> 01:17:01.390
is all the committee
members-- as well

01:17:01.390 --> 01:17:05.540
as all the bits of information
about each candidate,

01:17:05.540 --> 01:17:08.100
that that combination
will enable

01:17:08.100 --> 01:17:12.330
you to make a more informed
decision that gives

01:17:12.330 --> 01:17:13.800
each candidate a fair hearing.

01:17:16.320 --> 01:17:19.140
Mahzarin, could I just add
one more thing to that.

01:17:19.140 --> 01:17:21.630
And I don't also have
a silver bullet at all.

01:17:21.630 --> 01:17:25.330
And I think a lot
of biases there.

01:17:25.330 --> 01:17:27.311
I don't think you want
to give up on them,

01:17:27.311 --> 01:17:29.060
because the other bias
we're worried about

01:17:29.060 --> 01:17:31.530
is of course in group bias.

01:17:31.530 --> 01:17:33.450
So you need to have
some outsiders who

01:17:33.450 --> 01:17:36.250
are not part of the institution
to give you some feedback.

01:17:36.250 --> 01:17:41.590
And I also think one way
to at least them hopefully

01:17:41.590 --> 01:17:43.600
improve the quality
of the letters

01:17:43.600 --> 01:17:47.100
that you get a little bit is
diversity on the evaluation

01:17:47.100 --> 01:17:50.960
committee where we
know, as I said,

01:17:50.960 --> 01:17:53.790
we tend to know people
from our own genders,

01:17:53.790 --> 01:17:56.490
from our own disciplines, maybe
even more importantly, but also

01:17:56.490 --> 01:18:01.530
from our own nationalities
and educational backgrounds.

01:18:01.530 --> 01:18:05.660
So therefore I think the
broader you can reach out

01:18:05.660 --> 01:18:08.100
to different sets of
evaluators, the more likely

01:18:08.100 --> 01:18:11.270
you'll get a good outcome.

01:18:11.270 --> 01:18:14.470
Let me just add something
to what you just said.

01:18:14.470 --> 01:18:16.420
And I don't have any
research to back this up.

01:18:16.420 --> 01:18:18.760
I'm just going to tell
you about our experience.

01:18:18.760 --> 01:18:22.910
One experiment we are trying
at the Columbia Business School

01:18:22.910 --> 01:18:26.320
is we do have a very,
very diverse committee.

01:18:26.320 --> 01:18:28.430
So we're hiring this
decision making person.

01:18:28.430 --> 01:18:31.700
We have one finance
person, one economist,

01:18:31.700 --> 01:18:35.100
one operations researcher,
one marketing person.

01:18:35.100 --> 01:18:37.640
And then we have management
and faculty on this.

01:18:37.640 --> 01:18:40.920
So it's a really intellectually
diverse group of people.

01:18:40.920 --> 01:18:42.560
And so of course
every committee member

01:18:42.560 --> 01:18:44.130
has their own
favorite candidate.

01:18:44.130 --> 01:18:45.180
That's a given.

01:18:45.180 --> 01:18:47.170
And of course every
single committee member

01:18:47.170 --> 01:18:51.180
has their own biases
about how they

01:18:51.180 --> 01:18:56.170
want to interpret good and bad
quality research, et cetera.

01:18:56.170 --> 01:18:59.640
And I would say that
diversity has been good

01:18:59.640 --> 01:19:02.650
so far in that
it's been surfacing

01:19:02.650 --> 01:19:05.830
a lot of interesting candidates
that we previously might not

01:19:05.830 --> 01:19:06.850
have thought about.

01:19:06.850 --> 01:19:09.920
But I think in order
for it to work,

01:19:09.920 --> 01:19:15.790
you have to have a moderator
that makes it a point

01:19:15.790 --> 01:19:19.665
to not being in favor of
any particular candidate

01:19:19.665 --> 01:19:22.360
and who sticks to process.

01:19:22.360 --> 01:19:24.670
Because if at any
point the moderator

01:19:24.670 --> 01:19:26.920
loses control of
that process, I do

01:19:26.920 --> 01:19:29.280
think that having
a diverse group

01:19:29.280 --> 01:19:33.580
is a great recipe
for greater conflict.

01:19:33.580 --> 01:19:38.760
And can I add to that by saying
that these biases that we

01:19:38.760 --> 01:19:40.350
have exist for a reason.

01:19:40.350 --> 01:19:41.860
They're not absolutely nutty.

01:19:41.860 --> 01:19:45.537
They're there because in some
old world, they helped us.

01:19:45.537 --> 01:19:47.370
They helped us pay
attention to those people

01:19:47.370 --> 01:19:48.600
will looked like
us who were going

01:19:48.600 --> 01:19:49.960
to be less likely to kill us.

01:19:49.960 --> 01:19:52.600
It's just that now we
don't live in the world

01:19:52.600 --> 01:19:54.480
where people who
look just like us

01:19:54.480 --> 01:19:58.480
are any less likely
to kill us than--

01:19:58.480 --> 01:20:00.850
And so I'm going to argue
that these things that

01:20:00.850 --> 01:20:04.050
used to really pay
off no longer do

01:20:04.050 --> 01:20:06.360
because we have to look
at somebody very different

01:20:06.360 --> 01:20:06.930
from us.

01:20:06.930 --> 01:20:09.700
And a business person has to
say, can I outsource to them

01:20:09.700 --> 01:20:11.310
and make a lot of
money off of them.

01:20:11.310 --> 01:20:14.220
You have to make decisions
that are of that kind.

01:20:14.220 --> 01:20:17.490
And that is why we're
saying, let's examine them.

01:20:17.490 --> 01:20:19.750
So one way around
this problem is

01:20:19.750 --> 01:20:22.470
that we will not be able to get
rid of these sorts of biases.

01:20:22.470 --> 01:20:24.180
We can do the most blatant ones.

01:20:24.180 --> 01:20:26.950
But another way around
it, if we're smart,

01:20:26.950 --> 01:20:30.180
is to multiply biases, that
is to say multiply them

01:20:30.180 --> 01:20:33.870
across people so that different
biases are present in the room,

01:20:33.870 --> 01:20:36.370
so that I will say this
is the best person for us

01:20:36.370 --> 01:20:38.590
and somebody else will
say absolutely not,

01:20:38.590 --> 01:20:41.200
there's somebody else
who's even better.

01:20:41.200 --> 01:20:42.564
Yeah, one, and then you.

01:20:42.564 --> 01:20:43.552
Peter Manuelian.

01:20:43.552 --> 01:20:45.528
I think you said
a general reaction

01:20:45.528 --> 01:20:48.492
in situations where a search
committee tends to find

01:20:48.492 --> 01:20:49.974
[INAUDIBLE].

01:20:49.974 --> 01:20:51.950
And I've heard
arguments on both sides.

01:20:51.950 --> 01:20:53.432
One may say, well
this looks real

01:20:53.432 --> 01:20:54.694
bad on the search committee.

01:20:54.694 --> 01:20:55.902
They're punting the decision.

01:20:55.902 --> 01:20:57.384
They're punting upstairs.

01:20:57.384 --> 01:20:58.866
[INAUDIBLE]

01:20:58.866 --> 01:21:01.830
Or I've heard the opposite that
this is really a good thing

01:21:01.830 --> 01:21:03.806
to do and at least we'll
guarantee ourselves

01:21:03.806 --> 01:21:06.752
a finalist and a choice
rather than the second,

01:21:06.752 --> 01:21:08.252
have one person who
runs [INAUDIBLE]

01:21:08.252 --> 01:21:09.728
that person be rejected.

01:21:09.728 --> 01:21:10.228
[INAUDIBLE]

01:21:14.710 --> 01:21:16.790
I actually like the
idea a great deal.

01:21:16.790 --> 01:21:18.100
I like the idea.

01:21:18.100 --> 01:21:20.100
And I go back to
what Sheena said.

01:21:20.100 --> 01:21:22.700
By the time we're
bringing people out,

01:21:22.700 --> 01:21:24.490
they're all very, very good.

01:21:24.490 --> 01:21:26.090
They're very strong on paper.

01:21:26.090 --> 01:21:27.650
We know the work.

01:21:27.650 --> 01:21:30.800
But, this is where the
conservatism of being

01:21:30.800 --> 01:21:32.240
on a committee kicks in.

01:21:32.240 --> 01:21:34.160
One of them does become favored.

01:21:34.160 --> 01:21:37.400
And the difference between them
gets magnified in our minds

01:21:37.400 --> 01:21:39.770
in ways that are
absolutely irrational.

01:21:39.770 --> 01:21:42.610
And this is where I do
believe that forcing

01:21:42.610 --> 01:21:44.690
a committee, by
forcing at as much

01:21:44.690 --> 01:21:47.910
as you can force a herd of
squirrels, which is what

01:21:47.910 --> 01:21:51.940
faculty are, you can
sort of say look,

01:21:51.940 --> 01:21:53.280
this is to your advantage.

01:21:53.280 --> 01:21:56.120
You want to educate the
president and the dean

01:21:56.120 --> 01:21:57.430
about a whole field.

01:21:57.430 --> 01:22:00.090
It's really important
for you to give them

01:22:00.090 --> 01:22:02.370
multiple candidates
because who knows,

01:22:02.370 --> 01:22:04.594
you may actually be able
to hire more than one,

01:22:04.594 --> 01:22:06.510
or if not this year in
the future or whatever.

01:22:06.510 --> 01:22:09.230
And I do believe that
keeping that open

01:22:09.230 --> 01:22:12.320
and not basically locking
into a single person

01:22:12.320 --> 01:22:15.560
is going to pay off for
us in many, many ways.

01:22:15.560 --> 01:22:17.710
And I'm watching our
administration do this.

01:22:17.710 --> 01:22:19.530
When they look at a
short list and when

01:22:19.530 --> 01:22:21.321
they look at the letters
that have come in,

01:22:21.321 --> 01:22:22.950
even if there's a
favored candidate,

01:22:22.950 --> 01:22:25.710
I hear the dean asking,
but what about this person

01:22:25.710 --> 01:22:27.050
who's not number one.

01:22:27.050 --> 01:22:27.970
Why?

01:22:27.970 --> 01:22:31.670
What makes this person, he
or she, be number three?

01:22:31.670 --> 01:22:33.360
And is it really
number three, or is it

01:22:33.360 --> 01:22:36.340
only number three with the
frame you're currently using

01:22:36.340 --> 01:22:38.720
and with a slightly different
frame, that person may

01:22:38.720 --> 01:22:40.084
get bumped up to number one.

01:22:40.084 --> 01:22:41.500
And what are we're
going to do now

01:22:41.500 --> 01:22:44.040
that we've heard, after
the letters were written,

01:22:44.040 --> 01:22:46.940
that she won a MacArthur
Award or something like that.

01:22:46.940 --> 01:22:49.080
All of those sorts
of things I think

01:22:49.080 --> 01:22:50.960
administrators can help us do.

01:22:50.960 --> 01:22:52.760
So yes, you had a question.

01:22:52.760 --> 01:22:55.664
I had a question,
two part question.

01:22:55.664 --> 01:22:58.568
I've been asked to
chair the [INAUDIBLE]

01:22:58.568 --> 01:23:00.020
for all ranks [INAUDIBLE].

01:23:00.020 --> 01:23:06.230
So we, in principle, could
hire a professor [INAUDIBLE]

01:23:06.230 --> 01:23:07.120
for tenure.

01:23:07.120 --> 01:23:09.550
We could also hire a PhD.

01:23:09.550 --> 01:23:13.022
And could that then
add one more complexity

01:23:13.022 --> 01:23:14.510
in comparing candidates?

01:23:14.510 --> 01:23:18.090
I wonder if you had
any advice on that.

01:23:18.090 --> 01:23:23.137
And the second is, we have
a student advisory committee

01:23:23.137 --> 01:23:24.051
[INAUDIBLE].

01:23:24.051 --> 01:23:30.330
And if you had any advice on how
we could construct it to have

01:23:30.330 --> 01:23:32.630
them contribute to the process.

01:23:32.630 --> 01:23:34.950
So actually we did
recently struggle

01:23:34.950 --> 01:23:36.885
with the first of
your two questions.

01:23:39.440 --> 01:23:43.370
There were a few candiates--
back to this decision making,

01:23:43.370 --> 01:23:45.890
hiring decision making process.

01:23:45.890 --> 01:23:47.580
We had a bunch of candidates.

01:23:47.580 --> 01:23:48.670
They were all great.

01:23:48.670 --> 01:23:52.420
And they ranged anywhere
from just out of PhD

01:23:52.420 --> 01:23:56.480
to maybe might be
ready for early tenure

01:23:56.480 --> 01:23:59.660
to very, very, very senior.

01:23:59.660 --> 01:24:03.550
And in everybody, it looked
like it would come down

01:24:03.550 --> 01:24:06.610
to people having different
sort of preferences, et cetera.

01:24:06.610 --> 01:24:08.160
And it looked like
it was probably

01:24:08.160 --> 01:24:11.270
going to become a very
contentious discussion.

01:24:11.270 --> 01:24:15.060
And what I-- and again, I don't
have any research to back this

01:24:15.060 --> 01:24:18.200
up-- what I proposed,
and which ended up

01:24:18.200 --> 01:24:21.350
happening to simplify the
decision-- because I feel when

01:24:21.350 --> 01:24:25.120
possible, try to come
up with decision rules

01:24:25.120 --> 01:24:29.660
because people are more likely
to agree on decision rules.

01:24:29.660 --> 01:24:32.650
And so the decision
rule I proposed

01:24:32.650 --> 01:24:36.280
was that we not lump people
of all different ranks,

01:24:36.280 --> 01:24:40.040
that it would just make the
discussion too unwieldy.

01:24:40.040 --> 01:24:42.620
Let's just start with
the senior people.

01:24:42.620 --> 01:24:44.100
They're more comparable.

01:24:44.100 --> 01:24:48.350
You have an easier
evaluation process.

01:24:48.350 --> 01:24:51.190
If we don't succeed
on the senior level,

01:24:51.190 --> 01:24:52.960
then we'll go to the next level.

01:24:52.960 --> 01:24:56.510
So at least in my sort
of biased opinion,

01:24:56.510 --> 01:24:58.737
I wouldn't try to
compare all three sets.

01:24:58.737 --> 01:24:59.820
It's just too complicated.

01:25:03.060 --> 01:25:06.360
I wanted to add something in
particular, and responding also

01:25:06.360 --> 01:25:10.440
to the previous question
about the two candidates.

01:25:10.440 --> 01:25:13.390
So part of our research suggests
that comparison information

01:25:13.390 --> 01:25:14.420
is a good thing.

01:25:14.420 --> 01:25:17.100
And I think generally that's
what the research suggests.

01:25:17.100 --> 01:25:20.530
However, of course,
you can craft

01:25:20.530 --> 01:25:22.790
comparison sets strategically.

01:25:22.790 --> 01:25:24.880
So I just wanted us
to be aware of that,

01:25:24.880 --> 01:25:27.990
that you can also make
your preferred candidate

01:25:27.990 --> 01:25:30.760
shine more if you choose
the appropriate comparison

01:25:30.760 --> 01:25:31.730
strategically.

01:25:31.730 --> 01:25:34.170
So comparisons are
not just always good.

01:25:34.170 --> 01:25:37.290
But if you'd be very honest
about the comparison set,

01:25:37.290 --> 01:25:39.430
the research suggests
that it will actually

01:25:39.430 --> 01:25:40.675
improve the outcome.

01:25:40.675 --> 01:25:44.120
Can we take one more
question, and then Judy

01:25:44.120 --> 01:25:46.200
will say few words in closing.

01:25:46.200 --> 01:25:48.997
Yes, why don't you come up
here and ask your question

01:25:48.997 --> 01:25:51.850
and close.

01:25:51.850 --> 01:25:55.250
Picking up on what Iris said
about access to information,

01:25:55.250 --> 01:25:57.380
one question that
comes to mind is,

01:25:57.380 --> 01:25:59.960
should we share with
potential candidates--

01:25:59.960 --> 01:26:02.630
especially in junior searches--
what the criteria are?

01:26:02.630 --> 01:26:06.230
In other words, should we try
to make it more standardized,

01:26:06.230 --> 01:26:08.440
the experience that
people have coming here,

01:26:08.440 --> 01:26:11.180
or are we better off
withholding that because that's

01:26:11.180 --> 01:26:16.969
an internal discussion about
what's going on in the school?

01:26:16.969 --> 01:26:19.010
When you say criteria, do
you mean criteria for--

01:26:19.010 --> 01:26:20.110
[INTERPOSING VOICES]

01:26:20.110 --> 01:26:20.610
--tenure?

01:26:20.610 --> 01:26:21.440
The criteria.

01:26:21.440 --> 01:26:22.310
The tenure criteria?

01:26:22.310 --> 01:26:24.270
Not the tenure criteria,
the objective criteria

01:26:24.270 --> 01:26:27.281
that you're developing
in your search.

01:26:27.281 --> 01:26:28.340
Ah, I see.

01:26:28.340 --> 01:26:30.570
I do have something to say.

01:26:30.570 --> 01:26:33.230
Can I do that?

01:26:33.230 --> 01:26:36.400
I think that the nature of our
work is such that we cannot

01:26:36.400 --> 01:26:39.990
have a clear set of criteria
that we can lay out there.

01:26:39.990 --> 01:26:41.810
There is a bit
there that is fuzzy.

01:26:41.810 --> 01:26:44.920
And that's both
good intellectually,

01:26:44.920 --> 01:26:47.540
but it is what's going
to make us be more biased

01:26:47.540 --> 01:26:48.300
in certain ways.

01:26:48.300 --> 01:26:50.090
So I have a lovely
study for you that

01:26:50.090 --> 01:26:51.760
was done at Yale University.

01:26:51.760 --> 01:26:55.910
It was done by Geoff Cohen and
Eric Uhlmann in which they took

01:26:55.910 --> 01:26:58.810
a very masculine profession
like police work,

01:26:58.810 --> 01:27:00.990
and they gave people
two candidates.

01:27:00.990 --> 01:27:03.520
And one was male,
one was female.

01:27:03.520 --> 01:27:06.140
And in some cases, the
male was book smart

01:27:06.140 --> 01:27:08.060
and the female was street smart.

01:27:08.060 --> 01:27:10.600
And in the other case,
it was the reverse.

01:27:10.600 --> 01:27:14.010
And what they discovered
that was just really striking

01:27:14.010 --> 01:27:16.650
is that if the male
was book smart,

01:27:16.650 --> 01:27:19.660
people said this job
needs a book smart person.

01:27:19.660 --> 01:27:21.840
If the male was
street smart, people

01:27:21.840 --> 01:27:24.480
said this job needs a
street smart person.

01:27:24.480 --> 01:27:27.050
And what they argued is that
what we're doing in our minds,

01:27:27.050 --> 01:27:29.570
because we're so smart
about turning things around

01:27:29.570 --> 01:27:32.010
to get the outcome that
we think is the right one,

01:27:32.010 --> 01:27:36.400
that we're literally fitting the
criterion to the person and not

01:27:36.400 --> 01:27:38.010
the person to the criterion.

01:27:38.010 --> 01:27:40.560
And I'm going to argue that
this is something where

01:27:40.560 --> 01:27:43.000
we will be helped, at least
by putting-- so they actually

01:27:43.000 --> 01:27:45.290
showed a lovely reversal.

01:27:45.290 --> 01:27:47.320
You lose the bias if
you make people say up

01:27:47.320 --> 01:27:49.830
front, what are you
most important criteria.

01:27:49.830 --> 01:27:51.830
Then the candidates
are presented,

01:27:51.830 --> 01:27:53.300
and then you make a decision.

01:27:53.300 --> 01:27:54.780
And so I kind of
take this point,

01:27:54.780 --> 01:27:56.460
even though I think
that for us it's

01:27:56.460 --> 01:27:59.320
going to be awfully hard to lay
out what those criteria are.

01:27:59.320 --> 01:28:01.320
But at least to
ourselves, it might

01:28:01.320 --> 01:28:04.140
be useful to know that
we said A is important.

01:28:04.140 --> 01:28:05.850
And now we're
actually preferring B

01:28:05.850 --> 01:28:07.780
because it might be
the candidate that's

01:28:07.780 --> 01:28:09.182
making us go in that direction.

01:28:14.490 --> 01:28:19.650
I guess I would add to what
Mahzarin just said and also

01:28:19.650 --> 01:28:23.940
say that I would not give the
criteria to the candidates

01:28:23.940 --> 01:28:28.600
because once you've stated
the criteria up front,

01:28:28.600 --> 01:28:33.510
you're giving less
wiggle room later on.

01:28:33.510 --> 01:28:36.880
I would have that discussion
internally about your criteria

01:28:36.880 --> 01:28:39.190
so that you all
know, but I don't

01:28:39.190 --> 01:28:42.910
think I would reveal
that to the candidates.

01:28:42.910 --> 01:28:44.650
Well, I see we've
run out of time.

01:28:44.650 --> 01:28:46.020
I want to keep this on schedule.

01:28:46.020 --> 01:28:48.040
So I want to thank
everyone for coming,

01:28:48.040 --> 01:28:49.790
everyone who's chairing
a search committee

01:28:49.790 --> 01:28:51.320
or is working on
a search process,

01:28:51.320 --> 01:28:54.520
and especially our panelists,
who I think have given us

01:28:54.520 --> 01:28:55.915
wonderful food for thought.

01:28:55.915 --> 01:28:58.040
We're going to be putting
this video up on the web.

01:28:58.040 --> 01:29:01.440
I encourage you to get your
colleagues to watch this.

01:29:01.440 --> 01:29:04.740
We'll also be making available
the slides and other resource

01:29:04.740 --> 01:29:08.260
material that really talk
about how research can

01:29:08.260 --> 01:29:09.784
inform how we do our processes.

01:29:09.784 --> 01:29:12.200
So I want to thank everybody,
and especially our panelists

01:29:12.200 --> 01:29:12.800
for coming.

01:29:12.800 --> 01:29:16.150
[APPLAUSE]

