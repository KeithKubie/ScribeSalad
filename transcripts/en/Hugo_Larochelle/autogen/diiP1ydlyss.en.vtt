WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.689
 in this capsule we will see the concept 

00:00:02.280 --> 00:00:05.689
 loss minimization 

00:00:05.720 --> 00:00:12.059
 So we do not see the cure of the tax collector 

00:00:08.160 --> 00:00:13.410
 and we saw a rule to change the 

00:00:12.059 --> 00:00:14.759
 parameters so that the tax collector 

00:00:13.410 --> 00:00:17.039
 learn to do less and less 

00:00:14.759 --> 00:00:19.830
 errors but in what we will see my 

00:00:17.039 --> 00:00:21.930
 son is that one can derive the jaws 

00:00:19.830 --> 00:00:24.210
 collectors have with a principle a 

00:00:21.930 --> 00:00:26.160
 little more general to derive 

00:00:24.210 --> 00:00:28.230
 algae learning and one 

00:00:26.160 --> 00:00:29.609
 advantages of this principle there is that we 

00:00:28.230 --> 00:00:31.199
 did we will not be able to develop 

00:00:29.609 --> 00:00:32.640
 several other types behind 

00:00:31.199 --> 00:00:35.130
 learning from the same 

00:00:32.640 --> 00:00:38.010
 principle we hurry higher that 

00:00:35.130 --> 00:00:42.030
 is called the principle of 

00:00:38.010 --> 00:00:43.559
 minimization of losses and the idea is 

00:00:42.030 --> 00:00:45.809
 to see the problem of taking wise 

00:00:43.559 --> 00:00:48.980
 as an optimization problem we 

00:00:45.809 --> 00:00:52.410
 tries to optimize a medium loss on 

00:00:48.980 --> 00:00:54.690
 our prediction for each of 

00:00:52.410 --> 00:00:56.399
 learning examples actually this 

00:00:54.690 --> 00:00:58.590
 what we will do is for each example 

00:00:56.399 --> 00:01:01.710
 drive we will try to 

00:00:58.590 --> 00:01:03.480
 to minimize a distance that we will call 

00:01:01.710 --> 00:01:05.850
 loss did with a loss function 

00:01:03.480 --> 00:01:09.780
 that we call suck sic we note the 

00:01:05.850 --> 00:01:11.369
 6th 'who compares the target yt which is 

00:01:09.780 --> 00:01:13.860
 expected for the example tm 

00:01:11.369 --> 00:01:16.890
 drive with our prediction 

00:01:13.860 --> 00:01:17.400
 made by our model for example our 

00:01:16.890 --> 00:01:21.479
 perception 

00:01:17.400 --> 00:01:24.270
 so we note h2 existed where we put w a 

00:01:21.479 --> 00:01:25.680
 index to indicate the parameters so 

00:01:24.270 --> 00:01:28.829
 the degrees of freedom that allows 

00:01:25.680 --> 00:01:30.720
 to adjust ours our model so w 

00:01:28.829 --> 00:01:32.369
 for one perceive it would be the vector 

00:01:30.720 --> 00:01:34.170
 of weight then it could count too 

00:01:32.369 --> 00:01:36.900
 the beautiful 

00:01:34.170 --> 00:01:39.180
 associated with a prediction so this 

00:01:36.900 --> 00:01:42.360
 function that a distance that checks to 

00:01:39.180 --> 00:01:43.470
 how much our prediction h and close 

00:01:42.360 --> 00:01:47.130
 of the target 

00:01:43.470 --> 00:01:49.590
 yt we will call that a function of 

00:01:47.130 --> 00:01:50.970
 losses under the collector have 

00:01:49.590 --> 00:01:55.110
 the loss function we are going to use 

00:01:50.970 --> 00:01:56.149
 it's the function here it's going to be less 1 

00:01:55.110 --> 00:02:03.479
 time 

00:01:56.149 --> 00:02:06.270
 yt - h2x t times the product that was going 

00:02:03.479 --> 00:02:08.340
 go back w is excited when I remember 

00:02:06.270 --> 00:02:15.299
 that the product because here is the sum 

00:02:08.340 --> 00:02:19.590
 on all elements and wy be xti 

00:02:15.299 --> 00:02:21.690
 so the iem elements of the vector xt 

00:02:19.590 --> 00:02:24.870
 so if we look in detail at this 

00:02:21.690 --> 00:02:27.120
 loss function if the prediction is 

00:02:24.870 --> 00:02:30.840
 good ie if they were there 

00:02:27.120 --> 00:02:33.299
 corresponds to the prediction h2x holds the 

00:02:30.840 --> 00:02:35.819
 blow and 06 actually what if he 

00:02:33.299 --> 00:02:38.190
 rectifies feast h to excite so this term 

00:02:35.819 --> 00:02:39.299
 Syria here is zero 

00:02:38.190 --> 00:02:44.609
 we can import the value of these terms 

00:02:39.299 --> 00:02:46.350
 and if the prediction the loss makes 2 0 

00:02:44.609 --> 00:02:49.739
 on the other hand if the prediction is bad 

00:02:46.350 --> 00:02:53.670
 ie if yt and not equal to buy 

00:02:49.739 --> 00:02:56.690
 xt the loss your correspondents made to the 

00:02:53.670 --> 00:03:00.540
 distance between where the difference actually 

00:02:56.690 --> 00:03:04.500
 this is absolute between what goes into 

00:03:00.540 --> 00:03:08.370
 the function of those and the tax collector 

00:03:04.500 --> 00:03:10.350
 mean w times excited and the threshold to 

00:03:08.370 --> 00:03:11.280
 to cross for the prediction to be 

00:03:10.350 --> 00:03:14.400
 good 

00:03:11.280 --> 00:03:19.160
 so for example if we had that yt is 

00:03:14.400 --> 00:03:22.340
 equal to 1 but that two excited 

00:03:19.160 --> 00:03:27.660
 w in index is equal to zero 

00:03:22.340 --> 00:03:31.889
 so that here it implies that wx 

00:03:27.660 --> 00:03:33.900
 the producer in w is excited must be 

00:03:31.889 --> 00:03:36.180
 smaller than 0 so we remember that 

00:03:33.900 --> 00:03:38.340
 the father be wrong calculation be here and then 

00:03:36.180 --> 00:03:40.319
 next of that he compares this with zero 

00:03:38.340 --> 00:03:43.769
 like that here it's smaller 0 it's going 

00:03:40.319 --> 00:03:45.840
 predict zero otherwise he predicts one so 

00:03:43.769 --> 00:03:47.170
 in this case also actually the problem 

00:03:45.840 --> 00:03:50.800
 we would like 

00:03:47.170 --> 00:03:52.989
 wx exist be greater than 0 then 

00:03:50.800 --> 00:03:58.989
 what we will pay as the loss 

00:03:52.989 --> 00:04:01.989
 associated it's going to be actually wxx the 

00:03:58.989 --> 00:04:05.190
 distance between what I predicted and 0 

00:04:01.989 --> 00:04:07.120
 so in that if that term there would be 

00:04:05.190 --> 00:04:10.239
 negative but we are interested in 

00:04:07.120 --> 00:04:13.870
 distance between that and 0 so we would like 

00:04:10.239 --> 00:04:16.900
 in fact the loss is 2 - w times 

00:04:13.870 --> 00:04:17.380
 excited so in the case where the prediction 

00:04:16.900 --> 00:04:19.660
 in t1 

00:04:17.380 --> 00:04:22.240
 we got 0 the distance between 

00:04:19.660 --> 00:04:24.100
 what I put in drive function 

00:04:22.240 --> 00:04:28.979
 thresholds and the threshold I would have wanted 

00:04:24.100 --> 00:04:31.900
 to exceed it is less times w times excited 

00:04:28.979 --> 00:04:34.690
 and the least we actually have it here 

00:04:31.900 --> 00:04:37.810
 actually if there is and is equal to 1 

00:04:34.690 --> 00:04:38.620
 and that's equal to zero to see 1 - 0 which 

00:04:37.810 --> 00:04:41.290
 is a 

00:04:38.620 --> 00:04:43.050
 but have the least here so have 

00:04:41.290 --> 00:04:47.400
 actually that the loss is going to be less 

00:04:43.050 --> 00:04:49.780
 w9 x external that is going to be a term can 

00:04:47.400 --> 00:04:52.030
 have a loss that will be positive and 

00:04:49.780 --> 00:04:54.760
 who's going to be the distance between what 

00:04:52.030 --> 00:04:56.289
 I gave at the entrance of my function of 

00:04:54.760 --> 00:04:59.590
 thresholds and the threshold I would have wanted 

00:04:56.289 --> 00:05:01.990
 cross to have a prediction that 

00:04:59.590 --> 00:05:03.640
 is vain ok so if that's the function of 

00:05:01.990 --> 00:05:05.440
 losses for the tax collector one is rather 

00:05:03.640 --> 00:05:07.720
 we will see that if we use this 

00:05:05.440 --> 00:05:08.979
 loss function there the principle 

00:05:07.720 --> 00:05:10.300
 hominizing a loss we 

00:05:08.979 --> 00:05:12.220
 allow you to dream of the gatehouse 

00:05:10.300 --> 00:05:14.440
 collector and then we'll see in others 

00:05:12.220 --> 00:05:16.510
 capsules that for other definitions 

00:05:14.440 --> 00:05:18.310
 of losses we will derive from others 

00:05:16.510 --> 00:05:21.990
 elsewhere learning power of 

00:05:18.310 --> 00:05:21.990
 properties sometimes more interesting 

00:05:22.530 --> 00:05:28.000
 so the idea behind the paradigm of the 

00:05:26.830 --> 00:05:30.220
 mine of the loss is that 

00:05:28.000 --> 00:05:32.620
 doing learning is 

00:05:30.220 --> 00:05:35.919
 minimize the average loss between 

00:05:32.620 --> 00:05:37.630
 each of each of the exact targets and 

00:05:35.919 --> 00:05:41.229
 and my prediction that I'm doing for 

00:05:37.630 --> 00:05:43.240
 the excited input to saulcy so we're going 

00:05:41.229 --> 00:05:44.830
 formulate problem understand from 

00:05:43.240 --> 00:05:46.479
 minimization I want to minimize the 

00:05:44.830 --> 00:05:49.180
 average of the loss on my set 

00:05:46.479 --> 00:05:50.830
 drive and for that but degree of 

00:05:49.180 --> 00:05:52.750
 freedom what I can adjust for 

00:05:50.830 --> 00:05:55.030
 minimize the loss it's the parameters 

00:05:52.750 --> 00:05:56.800
 of my model is to improve the 

00:05:55.030 --> 00:05:59.650
 behavior of my model by modifying 

00:05:56.800 --> 00:06:00.270
 its parameters to get the loss on 

00:05:59.650 --> 00:06:02.150
 my whole 

00:06:00.270 --> 00:06:05.130
 German which is the smallest possible 

00:06:02.150 --> 00:06:07.170
 so we could start with a 

00:06:05.130 --> 00:06:08.340
 value of w given that we use 

00:06:07.170 --> 00:06:09.960
 maybe randomly 

00:06:08.340 --> 00:06:12.150
 so we have an example playing here on the 11th 

00:06:09.960 --> 00:06:14.220
 may youth have camped w it's a single 

00:06:12.150 --> 00:06:16.470
 setting then a galley fire that 

00:06:14.220 --> 00:06:18.690
 can load then that's sure access 

00:06:16.470 --> 00:06:21.450
 ziks over the accused y here that would be 

00:06:18.690 --> 00:06:23.640
 the value of the average of the loss of the 

00:06:21.450 --> 00:06:24.960
 go up the training room and when 

00:06:23.640 --> 00:06:26.610
 I would like to do is from 

00:06:24.960 --> 00:06:29.070
 this initial value here I would like 

00:06:26.610 --> 00:06:32.340
 make w adjustments to get a 

00:06:29.070 --> 00:06:33.570
 better value of peace is so what 

00:06:32.340 --> 00:06:35.640
 that I might want to do here 

00:06:33.570 --> 00:06:37.740
 it was at this point this is what I 

00:06:35.640 --> 00:06:40.800
 should move my value from w plus to 

00:06:37.740 --> 00:06:42.540
 left or right to decrease my 

00:06:40.800 --> 00:06:45.030
 average loss on my whole 

00:06:42.540 --> 00:06:46.200
 drive and so if we can 

00:06:45.030 --> 00:06:48.270
 formulate it's like a problem of 

00:06:46.200 --> 00:06:51.660
 local search this is a problem of 

00:06:48.270 --> 00:06:54.560
 research that actually is special in 

00:06:51.660 --> 00:06:56.520
 the sense where here w takes values 

00:06:54.560 --> 00:06:58.050
 continue so it's a bit difficult 

00:06:56.520 --> 00:07:01.530
 to do as with cities like 

00:06:58.050 --> 00:07:04.530
 bing for example to define to define 

00:07:01.530 --> 00:07:06.840
 a neighborhood in this case this is at 

00:07:04.530 --> 00:07:10.560
 clear what is the neighbor of 1.6 la 

00:07:06.840 --> 00:07:14.370
 value wt 1.101 what is his neighbor this 

00:07:10.560 --> 00:07:17.940
 that it's a point 011 or a corner 1 0 

00:07:14.370 --> 00:07:20.670
 1 0 1 1 if you are so we will use 

00:07:17.940 --> 00:07:23.430
 magritte a little bit a little different 

00:07:20.670 --> 00:07:25.350
 adapted for parameters so of 

00:07:23.430 --> 00:07:27.780
 w values ​​that can take 

00:07:25.350 --> 00:07:29.520
 real values ​​to try to optimize 

00:07:27.780 --> 00:07:30.690
 that but it's going to be similar and the 

00:07:29.520 --> 00:07:32.910
 local search ie we will 

00:07:30.690 --> 00:07:36.330
 take w we'll do little 

00:07:32.910 --> 00:07:37.800
 jumps to try to improve our 

00:07:36.330 --> 00:07:44.840
 average loss are as much it has me 

00:07:37.800 --> 00:07:47.160
 really so here is the description more 

00:07:44.840 --> 00:07:48.330
 highest level more intuitive of 

00:07:47.160 --> 00:07:49.950
 comment what we will solve this 

00:07:48.330 --> 00:07:51.180
 problem 

00:07:49.950 --> 00:07:53.730
 so what we prefer not to advance 

00:07:51.180 --> 00:07:56.640
 start by initializing the value of w 

00:07:53.730 --> 00:07:58.530
 a certain point in his vote is associated 

00:07:56.640 --> 00:08:02.250
 a value of the average loss that is 

00:07:58.530 --> 00:08:04.140
 of 6 and 6 throws that my average loss 

00:08:02.250 --> 00:08:06.360
 it's a function that goes on and on 

00:08:04.140 --> 00:08:08.910
 for which I can calculate 

00:08:06.360 --> 00:08:10.920
 drifts and so gradients not what 

00:08:08.910 --> 00:08:12.740
 I could do if look at this 

00:08:10.920 --> 00:08:15.199
 point as well as she is the keeper 

00:08:12.740 --> 00:08:18.380
 so among others from yoda this 

00:08:15.199 --> 00:08:20.419
 game to have the information of 11.6 if 

00:08:18.380 --> 00:08:23.090
 I'm increasing w is what my loss is going 

00:08:20.419 --> 00:08:25.490
 increase or not in this case we have that 

00:08:23.090 --> 00:08:27.800
 so the gradient this point would tell me 

00:08:25.490 --> 00:08:30.410
 that you describe it partially in fact 

00:08:27.800 --> 00:08:32.390
 since we have just one element we have 

00:08:30.410 --> 00:08:34.219
 as well as to their friends just and so 

00:08:32.390 --> 00:08:37.250
 the partial derivatives of the average cost per 

00:08:34.219 --> 00:08:39.080
 report to all surveys would be positive 

00:08:37.250 --> 00:08:42.649
 because if I miss w we see that 

00:08:39.080 --> 00:08:44.930
 actually the function the loss 

00:08:42.649 --> 00:08:47.089
 average increases so what I prefer 

00:08:44.930 --> 00:08:50.990
 it's going in the opposite direction where 

00:08:47.089 --> 00:08:52.940
 she drifted partial to try 

00:08:50.990 --> 00:08:55.730
 since the opposite direction tell me 

00:08:52.940 --> 00:08:57.020
 finally that if I go in the 

00:08:55.730 --> 00:08:58.399
 opposite direction of the guardian I 

00:08:57.020 --> 00:09:02.180
 expect the loss function 

00:08:58.399 --> 00:09:05.029
 average decreases so that would tell me 

00:09:02.180 --> 00:09:06.170
 because the pip function increases in 

00:09:05.029 --> 00:09:08.390
 this election if I should go 

00:09:06.170 --> 00:09:10.580
 in the reverse direction ie to 

00:09:08.390 --> 00:09:14.330
 left and there I could take a step 

00:09:10.580 --> 00:09:16.850
 in that direction to get a 

00:09:14.330 --> 00:09:18.410
 new point to 1 go point I will do 

00:09:16.850 --> 00:09:19.370
 again the assessment of the loss 

00:09:18.410 --> 00:09:22.399
 average on mount the training room 

00:09:19.370 --> 00:09:25.670
 and I will look at what is the divine 

00:09:22.399 --> 00:09:28.190
 partial poses this value of w there again 

00:09:25.670 --> 00:09:29.270
 once we see that if I increase w the 

00:09:28.190 --> 00:09:30.950
 loss function means to increase 

00:09:29.270 --> 00:09:33.279
 so I'll go in the opposite direction 

00:09:30.950 --> 00:09:39.350
 you're not going in that direction 

00:09:33.279 --> 00:09:40.820
 week at this point if I had read value 

00:09:39.350 --> 00:09:42.399
 average simulation debt 

00:09:40.820 --> 00:09:46.790
 drive and the dense that if I 

00:09:42.399 --> 00:09:48.410
 notice if I increase the value of w in 

00:09:46.790 --> 00:09:50.270
 does the loss will diminish so that wants 

00:09:48.410 --> 00:09:53.510
 say that drift and partial she 

00:09:50.270 --> 00:09:55.160
 would have a negative sign so would tell me 

00:09:53.510 --> 00:09:55.550
 that if I'm going to increase the loss 

00:09:55.160 --> 00:09:57.020
 average 

00:09:55.550 --> 00:09:58.399
 it is in this direction that I am 

00:09:57.020 --> 00:10:01.060
 I'm going to have the opposite I want 

00:09:58.399 --> 00:10:04.040
 decrease the average loss should go 

00:10:01.060 --> 00:10:06.860
 right then I could take a step 

00:10:04.040 --> 00:10:09.220
 in that direction if and continue 

00:10:06.860 --> 00:10:13.430
 like that until I get to a 

00:10:09.220 --> 00:10:14.810
 optimum a minimum actually in this case 

00:10:13.430 --> 00:10:15.770
 if this procedure the beard and a 

00:10:14.810 --> 00:10:18.100
 local minimum 

00:10:15.770 --> 00:10:21.829
 we observe that they would have a better 

00:10:18.100 --> 00:10:24.079
 minimum here if we had initialize here 

00:10:21.829 --> 00:10:26.100
 we would eventually arrive at this 

00:10:24.079 --> 00:10:28.649
 point so so something 

00:10:26.100 --> 00:10:31.199
 link langkow has seen this earlier 

00:10:28.649 --> 00:10:32.759
 procedure there called downhill 

00:10:31.199 --> 00:10:36.149
 of gradient because every time we 

00:10:32.759 --> 00:10:38.339
 calculate the gradient so with only one 

00:10:36.149 --> 00:10:41.339
 with a scalar it's the equivalent of 

00:10:38.339 --> 00:10:44.880
 the partial derivatives drift and so 

00:10:41.339 --> 00:10:48.180
 we will go down in the direction 

00:10:44.880 --> 00:10:50.130
 opposite of the gradient to make the for 

00:10:48.180 --> 00:10:51.930
 change the value of our lady for 

00:10:50.130 --> 00:10:54.600
 one hundred because of that we call it the 

00:10:51.930 --> 00:10:57.120
 descent of gaza and like white rice 

00:10:54.600 --> 00:10:58.889
 bing the guardian descent 

00:10:57.120 --> 00:11:05.870
 we can only guarantee to arrive 

00:10:58.889 --> 00:11:05.870
 to a point that is going to be a local minimum 

00:11:07.519 --> 00:11:12.569
 so we did an example in one 

00:11:10.470 --> 00:11:14.100
 dimension where we had a single parameter 

00:11:12.569 --> 00:11:17.880
 adjusted but as long as it happens 

00:11:14.100 --> 00:11:19.949
 if we have two parameters added adjust 

00:11:17.880 --> 00:11:21.480
 so my young people we have a function that 

00:11:19.949 --> 00:11:24.420
 the average loss then that depends on 

00:11:21.480 --> 00:11:27.839
 two possible values ​​that I was only xy 

00:11:24.420 --> 00:11:31.019
 we could have noted them w1 then w2 if 

00:11:27.839 --> 00:11:32.610
 I wanted to refer to the 

00:11:31.019 --> 00:11:34.610
 parameters of a tax collector have by 

00:11:32.610 --> 00:11:37.649
 example the two takers will perceive 

00:11:34.610 --> 00:11:40.019
 so in this case it's actually the gradian 

00:11:37.649 --> 00:11:41.939
 rather than the derivatives will match 

00:11:40.019 --> 00:11:44.100
 to the vectors that point in the 

00:11:41.939 --> 00:11:46.709
 direction where the growth rate of 

00:11:44.100 --> 00:11:48.810
 the higher works ok so if I 

00:11:46.709 --> 00:11:51.410
 was starting my optimization here at 7 in 

00:11:48.810 --> 00:11:54.329
 their six of my xy parameters 

00:11:51.410 --> 00:11:57.360
 but in that if the gradian tip 

00:11:54.329 --> 00:12:00.949
 reid in the direction that increases the 

00:11:57.360 --> 00:12:04.110
 function as much as possible and in the case 

00:12:00.949 --> 00:12:05.550
 of optimizing the average loss 

00:12:04.110 --> 00:12:07.740
 on the training set that's me 

00:12:05.550 --> 00:12:10.769
 would give the direction that 

00:12:07.740 --> 00:12:13.589
 would correspond to changes in my 

00:12:10.769 --> 00:12:15.410
 parameters that would increase the most my 

00:12:13.589 --> 00:12:18.449
 average loss on my former coach 

00:12:15.410 --> 00:12:20.399
 and so for the case at several 

00:12:18.449 --> 00:12:22.800
 dimensions it's going to be the same idea I 

00:12:20.399 --> 00:12:25.439
 will go in the opposite direction to 

00:12:22.800 --> 00:12:27.660
 gradient and I'm going to step into 

00:12:25.439 --> 00:12:30.720
 this direction is there so I'm going 

00:12:27.660 --> 00:12:32.850
 take my point here and then I'm going to 

00:12:30.720 --> 00:12:34.320
 move in the opposite direction of 

00:12:32.850 --> 00:12:36.570
 guardian 

00:12:34.320 --> 00:12:38.520
 according to a certain distance with a 

00:12:36.570 --> 00:12:40.860
 not sure it gave me my new 

00:12:38.520 --> 00:12:42.450
 value to my new value I'm going to 

00:12:40.860 --> 00:12:45.030
 settings i'm going to evaluate the canadian 

00:12:42.450 --> 00:12:47.610
 who's going pretty busy who commits 

00:12:45.030 --> 00:12:49.980
 another direction and institude like 

00:12:47.610 --> 00:12:52.320
 that until forgiveness until 

00:12:49.980 --> 00:12:53.970
 that we arrive at possibly a 

00:12:52.320 --> 00:12:55.140
 optimal to frames so in this case 

00:12:53.970 --> 00:12:59.580
 we could have arrived there 

00:12:55.140 --> 00:13:01.680
 at this point so in this example ci 

00:12:59.580 --> 00:13:06.630
 leaves in two dimensions we can see the 

00:13:01.680 --> 00:13:08.880
 gradian as if imagine that in fact the 

00:13:06.630 --> 00:13:12.090
 function corresponds a species of valier 

00:13:08.880 --> 00:13:14.760
 with valleys hills like 

00:13:12.090 --> 00:13:16.800
 those where hills and the caretaker does 

00:13:14.760 --> 00:13:19.530
 will tell me if I was standing 

00:13:16.800 --> 00:13:21.450
 dance on this ground there in which 

00:13:19.530 --> 00:13:24.870
 direction to that if I take a step I 

00:13:21.450 --> 00:13:26.700
 will increase my altitude the most 

00:13:24.870 --> 00:13:29.430
 quickly possible as much as possible 

00:13:26.700 --> 00:13:32.640
 with a single step and mathematically 

00:13:29.430 --> 00:13:33.990
 done on an infinitely small package but 

00:13:32.640 --> 00:13:36.360
 so the idea of ​​the gradient descent 

00:13:33.990 --> 00:13:37.710
 it's basically to take this 

00:13:36.360 --> 00:13:38.670
 direction there belgians were going in the 

00:13:37.710 --> 00:13:40.110
 opposite 

00:13:38.670 --> 00:13:43.560
 then that's how I go 

00:13:40.110 --> 00:13:45.420
 get as low as possible from in 

00:13:43.560 --> 00:13:48.680
 the land where I find myself for 

00:13:45.420 --> 00:13:48.680
 eventually arrive in a 

00:13:51.740 --> 00:13:57.900
 ok so with this December technique 

00:13:56.190 --> 00:14:02.160
 two guardians I would like to optimize the 

00:13:57.900 --> 00:14:06.960
 average loss so I want to optimize the 

00:14:02.160 --> 00:14:08.880
 loss for all the pairs y txt then 

00:14:06.960 --> 00:14:09.530
 if I want to calculate the gradient of the 

00:14:08.880 --> 00:14:12.000
 average loss 

00:14:09.530 --> 00:14:14.810
 it's going to be the vector of all 

00:14:12.000 --> 00:14:18.000
 drifts and partial of this average 

00:14:14.810 --> 00:14:20.100
 since the drift and so if I did 

00:14:18.000 --> 00:14:22.980
 the partial theory here versus a 

00:14:20.100 --> 00:14:24.690
 wii2 parameter partial view of a 

00:14:22.980 --> 00:14:27.810
 constant times a function that's the 

00:14:24.690 --> 00:14:30.450
 constant times the drift and partial of 

00:14:27.810 --> 00:14:31.710
 the function so I can inserted there 

00:14:30.450 --> 00:14:32.910
 hervé by this one 

00:14:31.710 --> 00:14:34.140
 there again the partial tort 

00:14:32.910 --> 00:14:34.650
 a sum is the sum of the ten 

00:14:34.140 --> 00:14:36.300
 patients 

00:14:34.650 --> 00:14:38.820
 so I can introduce the drift by 

00:14:36.300 --> 00:14:40.920
 the one here so judged that the derivatives 

00:14:38.820 --> 00:14:42.450
 partial of all this expression here 

00:14:40.920 --> 00:14:44.880
 that the average losses 

00:14:42.450 --> 00:14:46.920
 it's actually the average of the derivatives 

00:14:44.880 --> 00:14:47.790
 partial for each of my examples 

00:14:46.920 --> 00:14:50.610
 yt 

00:14:47.790 --> 00:14:52.050
 xt so if I wanted to do the descent 

00:14:50.610 --> 00:14:54.600
 guards as I describe them 

00:14:52.050 --> 00:14:57.120
 previously I will have to calculate the 

00:14:54.600 --> 00:14:58.830
 average derivatives but for all 

00:14:57.120 --> 00:15:00.750
 examples as a whole 

00:14:58.830 --> 00:15:02.310
 drive before you can do 

00:15:00.750 --> 00:15:05.070
 an update from my parents told me 

00:15:02.310 --> 00:15:07.320
 to go in the opposite direction of 

00:15:05.070 --> 00:15:08.570
 gradient hockey and that if I have a big 

00:15:07.320 --> 00:15:11.460
 example a group together 

00:15:08.570 --> 00:15:14.220
 workout it's going to require a lot 

00:15:11.460 --> 00:15:19.620
 calculations before I can adapt my 

00:15:14.220 --> 00:15:22.440
 parameters and have for that we will use 

00:15:19.620 --> 00:15:24.530
 a variant the descent of guards who 

00:15:22.440 --> 00:15:26.280
 the descent of the stochastic guards 

00:15:24.530 --> 00:15:28.050
 the idea of ​​the descent of gaza 

00:15:26.280 --> 00:15:30.750
 stochastic is to update the 

00:15:28.050 --> 00:15:33.120
 parameters from the gradient but 

00:15:30.750 --> 00:15:35.430
 for a single example chosen for you 

00:15:33.120 --> 00:15:37.620
 randomly among our center 

00:15:35.430 --> 00:15:39.690
 drive so what we want to do 

00:15:37.620 --> 00:15:40.770
 we're going to initialize meinau 

00:15:39.690 --> 00:15:41.850
 paramat randomly 

00:15:40.770 --> 00:15:44.580
 then for a number of ideas 

00:15:41.850 --> 00:15:47.700
 ration or until they reach 

00:15:44.580 --> 00:15:49.850
 some downtime we're going to shoot a 

00:15:47.700 --> 00:15:53.600
 example of scoring training 

00:15:49.850 --> 00:15:56.550
 drive a single example excited yt 

00:15:53.600 --> 00:15:58.980
 and we will calculate what is the derivative 

00:15:56.550 --> 00:16:00.210
 partial for each of the parameters of 

00:15:58.980 --> 00:16:01.740
 the loss function 

00:16:00.210 --> 00:16:05.190
 so we will finally calculate the 

00:16:01.740 --> 00:16:11.040
 Canadian versus w and we'll put 

00:16:05.190 --> 00:16:13.080
 up to date each one obama win7 scratching a ride 

00:16:11.040 --> 00:16:16.290
 alpha learning that is going to be the 

00:16:13.080 --> 00:16:18.570
 pot size i'm going to do times the 

00:16:16.290 --> 00:16:20.340
 drift and partial loss by 

00:16:18.570 --> 00:16:23.010
 report to a parameter that I put to 

00:16:20.340 --> 00:16:25.800
 day so if what has changed is that 

00:16:23.010 --> 00:16:30.440
 to update my wai I will not 

00:16:25.800 --> 00:16:32.360
 calculate the average losses so the 

00:16:30.440 --> 00:16:33.740
 the average partial theories of 

00:16:32.360 --> 00:16:36.880
 losses so I'm not going to calculate the of 

00:16:33.740 --> 00:16:38.480
 benchmarks there partial reviews of the 

00:16:36.880 --> 00:16:41.570
 average loss 

00:16:38.480 --> 00:16:43.730
 I'm actually drawing a single example 

00:16:41.570 --> 00:16:46.100
 and then just from this example I 

00:16:43.730 --> 00:16:47.090
 go a calculation and its derivatives 

00:16:46.100 --> 00:16:48.440
 partial to all 

00:16:47.090 --> 00:16:49.780
 settings and updates them 

00:16:48.440 --> 00:16:51.860
 at once 

00:16:49.780 --> 00:16:54.110
 so that's a close to a procedure 

00:16:51.860 --> 00:16:55.580
 which is much more effective when we 

00:16:54.110 --> 00:17:00.740
 has a training set that is 

00:16:55.580 --> 00:17:04.900
 big actually if I have cardinali t2 

00:17:00.740 --> 00:17:07.310
 number of training examples 

00:17:04.900 --> 00:17:09.319
 whose test shot no it's my agent 

00:17:07.310 --> 00:17:12.740
 which contains all my excited parts yt 

00:17:09.319 --> 00:17:14.180
 well I'll do as many updates 

00:17:12.740 --> 00:17:16.670
 parameters as examples 

00:17:14.180 --> 00:17:18.890
 drive after going through everything 

00:17:16.670 --> 00:17:20.420
 the whole training world while 

00:17:18.890 --> 00:17:22.459
 with the procedure of getting off 

00:17:20.420 --> 00:17:24.680
 normal gradient I will make a single bet 

00:17:22.459 --> 00:17:27.560
 up to date after going through all the 

00:17:24.680 --> 00:17:29.600
 training examples and so I say 

00:17:27.560 --> 00:17:31.610
 here that normally with shots one would have 

00:17:29.600 --> 00:17:34.250
 randomly drawn our examples 

00:17:31.610 --> 00:17:36.050
 training that we choose to do 

00:17:34.250 --> 00:17:38.810
 our updates every update 

00:17:36.050 --> 00:17:41.030
 but in fact often what we do 

00:17:38.810 --> 00:17:44.210
 is that we start with the first 

00:17:41.030 --> 00:17:45.920
 example x1 y 1 did an update 

00:17:44.210 --> 00:17:47.840
 then from his takes the second example 

00:17:45.920 --> 00:17:49.310
 exit hours y two made a bet 

00:17:47.840 --> 00:17:52.280
 day is so often in fact 

00:17:49.310 --> 00:17:54.260
 practice we will stick in order to 

00:17:52.280 --> 00:17:55.250
 through our training examples and 

00:17:54.260 --> 00:17:58.420
 that's how we're going to bring forth 

00:17:55.250 --> 00:17:58.420
 stochastic gaza ash 

00:17:59.350 --> 00:18:05.330
 we will go back to the tax collector so 

00:18:02.630 --> 00:18:11.060
 for the tax collector we have the loss we have 

00:18:05.330 --> 00:18:12.560
 defined its - times yt - hd xt times the 

00:18:11.060 --> 00:18:16.490
 product that was going to fit my vector of 

00:18:12.560 --> 00:18:20.120
 allow w and xt and here too I'm doing 

00:18:16.490 --> 00:18:22.520
 partial derivatives by a permit w12 

00:18:20.120 --> 00:18:24.200
 but weight demand because it will be so 

00:18:22.520 --> 00:18:26.570
 if I calculate it here in relation to my 

00:18:24.200 --> 00:18:29.060
 loss for my dad it's round I'm getting 

00:18:26.570 --> 00:18:30.650
 so here we will treat this as a 

00:18:29.060 --> 00:18:33.110
 constant so we do there hervé 

00:18:30.650 --> 00:18:35.840
 partial to products 

00:18:33.110 --> 00:18:43.910
 wx school exist the product that at 

00:18:35.840 --> 00:18:45.830
 the wfe xtc the sum on i of wy sees xt 

00:18:43.910 --> 00:18:48.050
 it so if I do there derivatives 

00:18:45.830 --> 00:18:50.260
 partial of belvis compared to in 

00:18:48.050 --> 00:18:56.390
 do I should use another clue 

00:18:50.260 --> 00:18:57.680
 so we are aroused from wgi excited here and there 

00:18:56.390 --> 00:18:59.870
 also I'm doing partial hervé of 

00:18:57.680 --> 00:19:02.810
 this sum there compared to 1 wy 

00:18:59.870 --> 00:19:06.800
 accurate for example the 1st may 

00:19:02.810 --> 00:19:10.250
 all other terms wgi once existed j 

00:19:06.800 --> 00:19:13.930
 that do not depend on the first of the first 

00:19:10.250 --> 00:19:17.600
 of wxy and also of the first 

00:19:13.930 --> 00:19:19.970
 allow w1 in my sector w all 

00:19:17.600 --> 00:19:21.680
 these other terms are constant by 

00:19:19.970 --> 00:19:23.570
 report to my father 

00:19:21.680 --> 00:19:27.470
 ok so in fact I'm only interested 

00:19:23.570 --> 00:19:30.310
 themes or gitega life and drift 

00:19:27.470 --> 00:19:32.750
 and partial with respect to that term 

00:19:30.310 --> 00:19:36.950
 so we have the parameter once a 

00:19:32.750 --> 00:19:39.620
 constant that excites and I see drift 

00:19:36.950 --> 00:19:41.390
 and that's just excited and if 

00:19:39.620 --> 00:19:44.930
 I do there streets compared to a 

00:19:41.390 --> 00:19:47.690
 element to give it's going to be the der 

00:19:44.930 --> 00:19:49.730
 to spend it going to be excited precisely 

00:19:47.690 --> 00:19:51.440
 times that term there that I treated as 

00:19:49.730 --> 00:19:53.720
 a constant the reason why 

00:19:51.440 --> 00:19:54.980
 I have an approximation here that is 

00:19:53.720 --> 00:19:57.050
 normally I should do 

00:19:54.980 --> 00:19:58.730
 derive also by this term 

00:19:57.050 --> 00:20:00.710
 there here that depends on 2 w 

00:19:58.730 --> 00:20:03.800
 but if I make an approximation that I 

00:20:00.710 --> 00:20:05.300
 suppose and that's actually constant and 

00:20:03.800 --> 00:20:06.400
 I will speak a little more under in 

00:20:05.300 --> 00:20:09.140
 moments 

00:20:06.400 --> 00:20:12.740
 but so we see that the sight of 

00:20:09.140 --> 00:20:15.170
 partial compared to allow wy that 

00:20:12.740 --> 00:20:18.020
 corresponds to that term here for my 

00:20:15.170 --> 00:20:19.670
 loss of the collector and want to heal 

00:20:18.020 --> 00:20:22.520
 to go down stochastic gaza tells me 

00:20:19.670 --> 00:20:22.850
 to take the wy and then put them to 

00:20:22.520 --> 00:20:25.070
 day 

00:20:22.850 --> 00:20:27.560
 subtracting a learning rate 

00:20:25.070 --> 00:20:30.470
 or a step of two gradient centers 

00:20:27.560 --> 00:20:33.350
 alpha times the drift and partial by 

00:20:30.470 --> 00:20:38.350
 relation to my parameters we see that 

00:20:33.350 --> 00:20:42.590
 partial mammary is either here - yt - h 

00:20:38.350 --> 00:20:45.500
 h2x t times excited there is so I have a 

00:20:42.590 --> 00:20:49.670
 less here who will console themselves with those - 

00:20:45.500 --> 00:20:53.740
 there here so I have more alpha xy witnesses 

00:20:49.670 --> 00:20:56.230
 hdx tréfois xti and if you 

00:20:53.740 --> 00:20:59.530
 proud that's exactly the rule of 

00:20:56.230 --> 00:21:00.490
 day where the shore learning for the 

00:20:59.530 --> 00:21:02.530
 collector's gallery 

00:21:00.490 --> 00:21:04.720
 ok so we did find the 

00:21:02.530 --> 00:21:06.760
 learning procedure for the 

00:21:04.720 --> 00:21:14.970
 tax collector by treating as a problem 

00:21:06.760 --> 00:21:17.920
 of minimization to do you so 

00:21:14.970 --> 00:21:19.390
 the advantage here is that if I take 

00:21:17.920 --> 00:21:21.460
 any model and that I am 

00:21:19.390 --> 00:21:23.920
 able to formulate it in the form 

00:21:21.460 --> 00:21:25.929
 of an immunization of a loss of which I 

00:21:23.920 --> 00:21:26.800
 defined a function there it is a 

00:21:25.929 --> 00:21:30.250
 loss function 

00:21:26.800 --> 00:21:33.880
 I define a value of a form 

00:21:30.250 --> 00:21:36.130
 parametric for my prediction hw ii x 

00:21:33.880 --> 00:21:38.500
 but I'm able to train this 

00:21:36.130 --> 00:21:39.760
 model there to treat it as a take 

00:21:38.500 --> 00:21:41.100
 optimization of hominization 

00:21:39.760 --> 00:21:44.950
 losses 

00:21:41.100 --> 00:21:46.210
 it's true if I can calculate prices 

00:21:44.950 --> 00:21:47.260
 facial I can calculate the gradients 

00:21:46.210 --> 00:21:48.790
 so that there could be some 

00:21:47.260 --> 00:21:51.610
 loss functions for which we can not 

00:21:48.790 --> 00:21:52.900
 calculate gradients and in this case 

00:21:51.610 --> 00:21:54.940
 as good we can always do 

00:21:52.900 --> 00:21:57.010
 some approximations and again the 

00:21:54.940 --> 00:21:58.410
 parsley dish this trunk if what we did 

00:21:57.010 --> 00:22:00.640
 we do a little cheat 

00:21:58.410 --> 00:22:01.650
 so I said that derivatives by 

00:22:00.640 --> 00:22:04.990
 report to h 

00:22:01.650 --> 00:22:08.620
 w of x actually she is not defined 

00:22:04.990 --> 00:22:09.330
 when wx and the product 40 wx is 

00:22:08.620 --> 00:22:12.460
 equal to zero 

00:22:09.330 --> 00:22:15.040
 so I have the function cei which is 

00:22:12.460 --> 00:22:16.690
 used in my calculation of my prediction 

00:22:15.040 --> 00:22:20.440
 actually to zero I have a 

00:22:16.690 --> 00:22:23.440
 discontinuity where it changes drastically 

00:22:20.440 --> 00:22:26.090
 from zero to so at this point if in 

00:22:23.440 --> 00:22:29.620
 there is no 

00:22:26.090 --> 00:22:32.000
 we have no derivatives that is defined 

00:22:29.620 --> 00:22:33.590
 so we made any summons when 

00:22:32.000 --> 00:22:35.960
 suppose it's hervé here and 

00:22:33.590 --> 00:22:38.900
 to 0 that heroes also elsewhere 

00:22:35.960 --> 00:22:40.340
 hero here then the heroes here there hervé 

00:22:38.900 --> 00:22:43.580
 so effectively and no variation 

00:22:40.340 --> 00:22:44.740
 so we had to do some 

00:22:43.580 --> 00:22:48.020
 approximation 

00:22:44.740 --> 00:22:49.400
 but we will see other algorithms 

00:22:48.020 --> 00:22:52.159
 next videos where we will not have 

00:22:49.400 --> 00:22:54.080
 easy approximations there and we will 

00:22:52.159 --> 00:22:59.120
 will be able to apply the December war 

00:22:54.080 --> 00:23:01.039
 two guards in a normal way so a 

00:22:59.120 --> 00:23:03.620
 disadvantages actually of precisely 

00:23:01.039 --> 00:23:05.029
 this very hot white faction that we have 

00:23:03.620 --> 00:23:07.520
 in the group of people lawsuits we 

00:23:05.029 --> 00:23:09.380
 make this approximation there and that that 

00:23:07.520 --> 00:23:11.480
 implies among other things that when we go 

00:23:09.380 --> 00:23:14.270
 train a tax collector we will see that 

00:23:11.480 --> 00:23:16.299
 the training curve so the curve 

00:23:14.270 --> 00:23:20.539
 who will show that she is the loss 

00:23:16.299 --> 00:23:21.529
 average or what error or another 

00:23:20.539 --> 00:23:23.029
 what we can look at is the error 

00:23:21.529 --> 00:23:25.820
 classification on our week times 

00:23:23.029 --> 00:23:28.309
 drive is actually also so 

00:23:25.820 --> 00:23:30.590
 a little unstable so we'll see that his 

00:23:28.309 --> 00:23:32.120
 look at the mistake one makes one does not 

00:23:30.590 --> 00:23:33.260
 was watching a class 

00:23:32.120 --> 00:23:35.510
 learning that is rather than a 

00:23:33.260 --> 00:23:37.460
 kept the mistake keep the success rate 

00:23:35.510 --> 00:23:40.850
 the round of carboys classification 

00:23:37.460 --> 00:23:42.830
 often saw that the court was doing that 

00:23:40.850 --> 00:23:43.370
 like that and vary quite a bit 

00:23:42.830 --> 00:23:46.210
 unstable 

00:23:43.370 --> 00:23:47.779
 is that it can be a little annoying for 

00:23:46.210 --> 00:23:49.970
 determine when should we 

00:23:47.779 --> 00:23:51.200
 stop learning in the 

00:23:49.970 --> 00:23:53.990
 next capitulum what are we going to see 

00:23:51.200 --> 00:23:59.090
 how can we define 

00:23:53.990 --> 00:24:01.730
 another value of the loss function 

00:23:59.090 --> 00:24:03.320
 another learning pace via the 

00:24:01.730 --> 00:24:05.240
 Parisian of the loss loss for 

00:24:03.320 --> 00:24:06.830
 fix this problem there may have a 

00:24:05.240 --> 00:24:10.090
 algorithm we learn it training 

00:24:06.830 --> 00:24:10.090
 will be more stable 

