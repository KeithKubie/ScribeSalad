WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:02.580
Okay Michael, so here's our second ,quiz, is

00:00:02.580 --> 00:00:05.689
a row. In the last quiz, we talked about

00:00:05.689 --> 00:00:07.850
running time and space time, but now we're going to

00:00:07.850 --> 00:00:13.690
talk about ,how the k-nn algorithm, actually works. And

00:00:13.690 --> 00:00:17.990
in particular how different choices, between distance metrics, values

00:00:17.990 --> 00:00:21.470
of k, and how you're going to put them together,

00:00:21.470 --> 00:00:23.270
can give you different answers, okay? So, what I

00:00:23.270 --> 00:00:25.600
have over here on the left is training data.

00:00:25.600 --> 00:00:27.720
This is a regression problem and you're training

00:00:27.720 --> 00:00:29.970
data is made up of xy pairs. X is

00:00:29.970 --> 00:00:33.040
two dimensional. Okay? So this is a function

00:00:33.040 --> 00:00:38.810
from R squared to some value in R1. Okay?

00:00:38.810 --> 00:00:40.610
&gt;&gt; Mm-hm.

00:00:40.610 --> 00:00:43.550
&gt;&gt; So, the first dimension represents, something

00:00:43.550 --> 00:00:46.370
and the second dimension, represents something. And then

00:00:46.370 --> 00:00:50.740
there's some particular, output over here. And what I want you to do, is given a

00:00:50.740 --> 00:00:56.460
query point, 4, 2 produce what the proper y or output

00:00:56.460 --> 00:00:59.580
ought to be, given all of this training did. You're with me?

00:00:59.580 --> 00:01:00.680
&gt;&gt; Yeah.

00:01:00.680 --> 00:01:03.610
&gt;&gt; Okay, so I want you to do it in four different cases, I

00:01:03.610 --> 00:01:09.150
want you to do it in the case where, your distance matrix is euclidean, Okay.

00:01:09.150 --> 00:01:13.091
&gt;&gt; The distance metric, in R2?

00:01:13.091 --> 00:01:14.250
&gt;&gt; Yes.

00:01:14.250 --> 00:01:15.900
&gt;&gt; Oh I see because, we're going to measure the distance

00:01:15.900 --> 00:01:17.650
between the query and the different data points.

00:01:17.650 --> 00:01:17.860
&gt;&gt; Right.

00:01:17.860 --> 00:01:18.613
&gt;&gt; Yeah. Okay. Uh-huh.

00:01:18.613 --> 00:01:21.100
&gt;&gt; Mm-hm. So it's euclidean, for a case of one

00:01:21.100 --> 00:01:24.990
nearest neighbor and three nearest neighbor and I want you

00:01:24.990 --> 00:01:27.530
to take, for example, in the three nearest neighbor case.

00:01:27.530 --> 00:01:30.100
I want you take their output and average them. Okay?

00:01:30.100 --> 00:01:30.800
&gt;&gt; Okay.

00:01:30.800 --> 00:01:35.590
&gt;&gt; Now, in the I also want you to do the same thing. But in the case

00:01:35.590 --> 00:01:38.450
where instead of using Euclidean distance, we use Manhattan

00:01:38.450 --> 00:01:41.140
distance. But again, for both 1 nearest neighbor and

00:01:41.140 --> 00:01:43.080
3 nearest neighbor And in any case where

00:01:43.080 --> 00:01:44.850
we have ties, like in three nearest neighbor where

00:01:44.850 --> 00:01:46.060
we absolutely have to have at least three of

00:01:46.060 --> 00:01:48.810
these things show up, just let 'em average. Okay?

00:01:48.810 --> 00:01:49.030
&gt;&gt; Got you.

00:01:49.030 --> 00:01:50.480
&gt;&gt; Now we're doing averaging instead of

00:01:50.480 --> 00:01:53.130
straight voting, because, this is a regression problem.

00:01:53.130 --> 00:01:53.920
&gt;&gt; Got it.

00:01:53.920 --> 00:01:55.400
&gt;&gt; Okay. Any questions?

00:01:55.400 --> 00:02:01.230
&gt;&gt; Maybe. Let's see. Three nearest neighbor. And so if there's ties, we, we

00:02:01.230 --> 00:02:04.030
use the college ranking trick of including

00:02:04.030 --> 00:02:06.550
everybody who's at least as good as the

00:02:06.550 --> 00:02:08.860
k, largest or k closest.

00:02:08.860 --> 00:02:10.729
&gt;&gt; Yes, exactly.

00:02:10.729 --> 00:02:13.650
&gt;&gt; Okay, yeah, no I think, I think I can take a stab at this.

00:02:13.650 --> 00:02:15.090
&gt;&gt; Okay, cool then go.

