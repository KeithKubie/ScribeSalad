WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.423
[MUSIC PLAYING]

00:00:07.830 --> 00:00:10.080
CHET HASSE: We're going
to talk about trash.

00:00:10.080 --> 00:00:12.972
So why are we going
to talk about trash?

00:00:12.972 --> 00:00:14.180
Why don't we-- yeah, let me--

00:00:14.180 --> 00:00:15.013
[INTERPOSING VOICES]

00:00:15.013 --> 00:00:17.700
CHET HASSE: All right, so there
is a common phrase in software,

00:00:17.700 --> 00:00:21.734
"garbage in, garbage out,"
but nobody ever says how fast.

00:00:21.734 --> 00:00:23.400
So we're going to
talk about that today.

00:00:23.400 --> 00:00:23.910
And why?

00:00:23.910 --> 00:00:27.204
Because back at I/O, we
had this talk that we gave,

00:00:27.204 --> 00:00:28.620
called Modern
Android Development.

00:00:28.620 --> 00:00:30.360
I have to apologize
for the sunglasses.

00:00:30.360 --> 00:00:32.090
The sun was right there--

00:00:32.090 --> 00:00:34.650
right there, really annoying,
couldn't see a thing.

00:00:34.650 --> 00:00:36.180
Sunglasses didn't actually help.

00:00:36.180 --> 00:00:39.720
Nor did they make
us look any better.

00:00:39.720 --> 00:00:41.520
So we talked about many things.

00:00:41.520 --> 00:00:44.460
You know, Android had
certain development practices

00:00:44.460 --> 00:00:45.300
way back then.

00:00:45.300 --> 00:00:48.000
And Android has changed,
and devices have changed,

00:00:48.000 --> 00:00:49.210
and ecosystems have changed.

00:00:49.210 --> 00:00:51.255
And now we are recommending
different practices.

00:00:51.255 --> 00:00:53.880
All the stuff that you may have
known about Android development

00:00:53.880 --> 00:00:55.734
may not necessarily
be true today.

00:00:55.734 --> 00:00:57.900
One of the things that we
talked about in particular

00:00:57.900 --> 00:01:01.070
was a lot about memory
and garbage collection.

00:01:01.070 --> 00:01:03.600
We had certain
recommendations there.

00:01:03.600 --> 00:01:06.450
So for example, we said,
back in the Dalvik days,

00:01:06.450 --> 00:01:08.760
Dalvik was optimized for size.

00:01:08.760 --> 00:01:10.710
It was meant to fit
in a very small area.

00:01:10.710 --> 00:01:13.112
It didn't have a lot of
area to do things like AOT.

00:01:13.112 --> 00:01:14.820
It didn't have a place
to stash the code.

00:01:14.820 --> 00:01:16.403
You really needed
to constrain memory.

00:01:16.403 --> 00:01:18.150
The optimizations
were not optimal.

00:01:18.150 --> 00:01:20.700
Allocations/collections--
unbelievably expensive.

00:01:20.700 --> 00:01:22.680
You get GC for
alloc all the time,

00:01:22.680 --> 00:01:24.360
causing jank all over the place.

00:01:24.360 --> 00:01:25.970
Heap fragmentation
was a problem.

00:01:25.970 --> 00:01:29.580
So really the recommendation was
to not really allocate anything

00:01:29.580 --> 00:01:31.950
ever if you could
possibly help it.

00:01:31.950 --> 00:01:34.029
And use primitive
types everywhere,

00:01:34.029 --> 00:01:36.570
because objects are expensive
because you're allocating them.

00:01:36.570 --> 00:01:38.062
Avoid autoboxing,
all this stuff.

00:01:38.062 --> 00:01:40.270
ROMAIN GUY: Yes, so I need
to correct you once again.

00:01:40.270 --> 00:01:42.270
You said, avoid the
locations whenever possible.

00:01:42.270 --> 00:01:43.450
Enums, they don't allocate.

00:01:43.450 --> 00:01:43.880
CHET HASSE: Yeah.

00:01:43.880 --> 00:01:44.418
OK, well--

00:01:44.418 --> 00:01:45.876
ROMAIN GUY: That's
the whole point.

00:01:45.876 --> 00:01:49.950
CHET HASSE: But but but but
but they take up space, right?

00:01:49.950 --> 00:01:51.705
So that's what, 1
to 2K compared to--

00:01:51.705 --> 00:01:52.830
ROMAIN GUY: You can't say--

00:01:52.830 --> 00:01:53.663
[INTERPOSING VOICES]

00:01:53.663 --> 00:01:54.960
CHET HASSE: All right, anyway.

00:01:54.960 --> 00:01:58.020
It's memory-related.

00:01:58.020 --> 00:02:01.590
So the recommendation instead
was, pay attention to ART,

00:02:01.590 --> 00:02:03.891
because it turns out ART is
optimized for performance,

00:02:03.891 --> 00:02:05.640
actually getting faster
with every release

00:02:05.640 --> 00:02:07.500
because the whole
platform was built

00:02:07.500 --> 00:02:10.979
to be able to optimize more and
more the more the team works

00:02:10.979 --> 00:02:11.830
on it.

00:02:11.830 --> 00:02:13.780
We're doing JT as well as AOT.

00:02:13.780 --> 00:02:15.210
So we compile this code.

00:02:15.210 --> 00:02:16.710
We find out where
the hotspots are,

00:02:16.710 --> 00:02:18.780
and we stash this
code somewhere so we

00:02:18.780 --> 00:02:21.470
can run that faster next time
you go through that loop.

00:02:21.470 --> 00:02:23.730
Allocations and collections
are much, much faster.

00:02:23.730 --> 00:02:25.860
We'll go into
details about this.

00:02:25.860 --> 00:02:28.590
We had the ability to defragment
the heap and actually compact

00:02:28.590 --> 00:02:29.407
as we go now.

00:02:29.407 --> 00:02:30.990
And there's a large
object heap, which

00:02:30.990 --> 00:02:34.296
makes some of the allocations
amazingly faster and simpler

00:02:34.296 --> 00:02:35.170
than they used to be.

00:02:35.170 --> 00:02:38.460
So the new recommendations
are, go ahead and allocate.

00:02:38.460 --> 00:02:40.740
It's really not that
big a deal anymore.

00:02:40.740 --> 00:02:43.350
Still be concerned for
inner loop situations,

00:02:43.350 --> 00:02:45.510
and be aware that
you are actually

00:02:45.510 --> 00:02:47.190
causing the device to do stuff.

00:02:47.190 --> 00:02:49.980
You are causing
battery and CPU usage.

00:02:49.980 --> 00:02:52.339
So you still want to be
aware of these things,

00:02:52.339 --> 00:02:53.880
but maybe they're
not such a big deal

00:02:53.880 --> 00:02:56.190
that they should affect your
APIs and your development

00:02:56.190 --> 00:02:57.523
patterns the way that they used.

00:02:57.523 --> 00:03:01.800
However, that was a lot of
really terse information

00:03:01.800 --> 00:03:03.610
stuffed into a very
short amount of time.

00:03:03.610 --> 00:03:06.193
So we thought maybe we should
do this talk to actually explain

00:03:06.193 --> 00:03:07.740
ourselves a little
more completely,

00:03:07.740 --> 00:03:10.320
and say, why is this the case.

00:03:10.320 --> 00:03:13.440
Maybe talk about what ART
has done to make life better.

00:03:13.440 --> 00:03:15.666
The original idea for
the talk was actually,

00:03:15.666 --> 00:03:17.040
OK, well, we said
all this stuff,

00:03:17.040 --> 00:03:18.120
but wouldn't it be
nice if we could just

00:03:18.120 --> 00:03:20.160
write a bunch of
demo applications,

00:03:20.160 --> 00:03:22.650
and show benchmarks,
and say, this is why,

00:03:22.650 --> 00:03:26.430
and these are the canonical
results that prove our premise.

00:03:26.430 --> 00:03:29.100
And it turns out
that is really hard.

00:03:29.100 --> 00:03:32.700
Because garbage collection, by
its nature, especially in ART,

00:03:32.700 --> 00:03:33.529
is concurrent.

00:03:33.529 --> 00:03:35.820
There's stuff happening in
the background all the time.

00:03:35.820 --> 00:03:38.130
And if you want to trigger
that thing right now,

00:03:38.130 --> 00:03:40.050
you will not be able to.

00:03:40.050 --> 00:03:42.607
So we made an attempt to
write some demo applications.

00:03:42.607 --> 00:03:44.190
You will see some
of the results here.

00:03:44.190 --> 00:03:47.370
But we realized we don't
really have enough canonical

00:03:47.370 --> 00:03:48.894
deterministic data to show you.

00:03:48.894 --> 00:03:50.310
So instead we're
going to tell you

00:03:50.310 --> 00:03:52.531
the background of why
it's difficult to write

00:03:52.531 --> 00:03:54.780
these things because everything
is happening magically

00:03:54.780 --> 00:03:56.500
for you in the background.

00:03:56.500 --> 00:03:58.860
So first of all, let's
talk about memory.

00:03:58.860 --> 00:04:00.850
We see a couple of simple
lines of code here.

00:04:00.850 --> 00:04:02.230
We have a primitive type.

00:04:02.230 --> 00:04:02.730
Here's foo.

00:04:02.730 --> 00:04:04.080
We're going to
set it equal to 5,

00:04:04.080 --> 00:04:05.910
and then we're going to
allocate an object here.

00:04:05.910 --> 00:04:08.243
Well, there are different
kinds of memory in the system,

00:04:08.243 --> 00:04:09.369
and different implications.

00:04:09.369 --> 00:04:11.160
So if we're going to
have a primitive type,

00:04:11.160 --> 00:04:14.910
that may show up in the stack,
or it may show up in registers.

00:04:14.910 --> 00:04:18.700
Dalvik was a register-based
allocation system.

00:04:18.700 --> 00:04:20.472
So it would actually
pop it in over there.

00:04:20.472 --> 00:04:22.680
But whether it shows up in
the stack or the register,

00:04:22.680 --> 00:04:24.346
you can think of it
as essentially free.

00:04:24.346 --> 00:04:26.627
It's kind of allocated
at compiler time.

00:04:26.627 --> 00:04:28.210
It says, when I run
this line of code,

00:04:28.210 --> 00:04:29.820
here's where I'm going
to stick this thing.

00:04:29.820 --> 00:04:31.694
It didn't need to find
space for it anywhere.

00:04:31.694 --> 00:04:33.799
It knows that it has
space on the stack.

00:04:33.799 --> 00:04:35.340
Sort of you can
think of that as kind

00:04:35.340 --> 00:04:40.110
of limitless storage space--
as well as the registers.

00:04:40.110 --> 00:04:42.840
It will basically find a
cubbyhole to stash that thing.

00:04:42.840 --> 00:04:43.500
It's free.

00:04:43.500 --> 00:04:46.560
However, when you allocate
any other sort of thing--

00:04:46.560 --> 00:04:49.800
when you say, new object, then
it needs to find space for it

00:04:49.800 --> 00:04:52.740
in the heap, which means it
needs to figure out where it's

00:04:52.740 --> 00:04:55.830
going to fit among the other
things that already occupy

00:04:55.830 --> 00:04:56.420
the heap.

00:04:56.420 --> 00:04:57.836
And it will find
space down there.

00:04:57.836 --> 00:04:59.880
So that's the
basic memory system

00:04:59.880 --> 00:05:03.290
of the runtime and
the computer overall.

00:05:03.290 --> 00:05:06.255
So the idea of
garbage collection--

00:05:06.255 --> 00:05:08.130
we've all been doing
garbage collection, even

00:05:08.130 --> 00:05:11.250
before higher level languages
like Java and Kotlin.

00:05:11.250 --> 00:05:15.060
If you're writing C++ code, then
you can do an allocation like

00:05:15.060 --> 00:05:18.420
this, and then you can write
the code that actually uses that

00:05:18.420 --> 00:05:20.160
object that you've allocated.

00:05:20.160 --> 00:05:22.252
And then if you don't
do anything else,

00:05:22.252 --> 00:05:23.460
you've just linked an object.

00:05:23.460 --> 00:05:26.250
You're taking up space
in memory somewhere

00:05:26.250 --> 00:05:29.280
that eventually is going to
cause you to run out of memory.

00:05:29.280 --> 00:05:31.470
So what you need to do is
actually free the object.

00:05:31.470 --> 00:05:33.870
So you delete the thing,
you reclaim that memory.

00:05:33.870 --> 00:05:36.600
So you're basically doing
manual garbage collection here.

00:05:36.600 --> 00:05:39.464
But sometimes you forget that
you've freed that over there.

00:05:39.464 --> 00:05:41.130
And then in this other
place over there,

00:05:41.130 --> 00:05:43.080
you continue using that object.

00:05:43.080 --> 00:05:44.680
And then you crash--

00:05:44.680 --> 00:05:46.200
maybe.

00:05:46.200 --> 00:05:48.240
So very
non-deterministic system.

00:05:48.240 --> 00:05:51.120
You are responsible for
managing your own garbage,

00:05:51.120 --> 00:05:53.010
your own allocations
and collections.

00:05:53.010 --> 00:05:54.240
It tends to be tedious.

00:05:54.240 --> 00:05:56.526
It tends to be very error-prone.

00:05:56.526 --> 00:05:58.740
And so higher level
languages came along.

00:05:58.740 --> 00:06:02.100
So we have language like Java,
where you allocate an object,

00:06:02.100 --> 00:06:04.710
and then you write the code
that actually uses that thing,

00:06:04.710 --> 00:06:06.540
and then eventually it is freed.

00:06:06.540 --> 00:06:09.067
And if you continue
using it, then you still

00:06:09.067 --> 00:06:10.650
have a reference to
this object, which

00:06:10.650 --> 00:06:13.890
means it's going to eventually
be freed without freeing it

00:06:13.890 --> 00:06:14.910
too soon.

00:06:14.910 --> 00:06:16.380
The system knows
what's going on.

00:06:16.380 --> 00:06:17.880
You don't have to
manage this thing.

00:06:17.880 --> 00:06:19.180
It does it for you.

00:06:19.180 --> 00:06:23.150
However, if it's doing it for
you, several questions occur.

00:06:23.150 --> 00:06:24.310
And there is no crash.

00:06:24.310 --> 00:06:27.150
Yay-- well, ideally.

00:06:27.150 --> 00:06:30.080
So there are some things
that naturally occur to you,

00:06:30.080 --> 00:06:31.769
such as OK, well,
how long does it

00:06:31.769 --> 00:06:33.060
take for the system to do this?

00:06:33.060 --> 00:06:35.970
I know how long my malloc
statement was going to take

00:06:35.970 --> 00:06:37.050
in C++.

00:06:37.050 --> 00:06:39.090
But how long is it going
to take for this system

00:06:39.090 --> 00:06:41.335
to automatically find
space in the heap for me?

00:06:41.335 --> 00:06:42.960
How long does it take
to walk the heap,

00:06:42.960 --> 00:06:45.150
find the appropriate
spot, to put this thing,

00:06:45.150 --> 00:06:46.517
and then allocate that space?

00:06:46.517 --> 00:06:48.850
How long does it take to
actually collect these objects?

00:06:48.850 --> 00:06:51.480
When a reference goes away,
when will it be collected,

00:06:51.480 --> 00:06:54.500
and how long does it take to
actually collect these things?

00:06:54.500 --> 00:06:57.670
And what impact is
there system-wide?

00:06:57.670 --> 00:07:00.000
So if we're running this
sort of garbage collector

00:07:00.000 --> 00:07:03.000
thread, this heavyweight
thing in the background, then

00:07:03.000 --> 00:07:06.030
what impact does that have
on jank on the UI thread

00:07:06.030 --> 00:07:07.190
or whatever?

00:07:07.190 --> 00:07:09.780
And when do these
things actually happen?

00:07:09.780 --> 00:07:12.300
And also, how efficient
is that heap usage?

00:07:12.300 --> 00:07:14.844
It's not just going to malloc
these little tiny chunks

00:07:14.844 --> 00:07:15.510
for your things.

00:07:15.510 --> 00:07:17.820
It's probably allocating
a large amount of space,

00:07:17.820 --> 00:07:20.310
and then putting things in
there, and sorting them around.

00:07:20.310 --> 00:07:22.080
And certainly on
Dalvik, as we'll see,

00:07:22.080 --> 00:07:23.795
it's fragmenting
the heap over time,

00:07:23.795 --> 00:07:25.920
which means you may have
a lot of memory available,

00:07:25.920 --> 00:07:28.687
but you can't necessarily
even access it anymore.

00:07:28.687 --> 00:07:30.270
So how efficient is
that, and how much

00:07:30.270 --> 00:07:33.152
memory are you taking up in the
system to do all this stuff?

00:07:33.152 --> 00:07:35.610
ROMAIN GUY: So we're going to
start by taking a look at how

00:07:35.610 --> 00:07:37.900
Dalvik collects garbage.

00:07:37.900 --> 00:07:41.040
Dalvik was the runtime we were
using until Android KitKat.

00:07:41.040 --> 00:07:43.560
It was replacing
Lollipop with ART.

00:07:43.560 --> 00:07:45.034
So this is a
picture of the heap.

00:07:45.034 --> 00:07:46.950
Everything that's in
white has been allocated.

00:07:46.950 --> 00:07:48.050
And we have a few holes.

00:07:48.050 --> 00:07:49.992
And we're trying to
allocate this blue object.

00:07:49.992 --> 00:07:51.450
So what Dalvik is
going to do, it's

00:07:51.450 --> 00:07:52.890
just going to walk
through the heap

00:07:52.890 --> 00:07:54.600
and find this spot
where the object fits.

00:07:54.600 --> 00:07:58.320
When it finds one, pretty
easy, just slot it there.

00:07:58.320 --> 00:08:00.870
Things become a lot
more complicated

00:08:00.870 --> 00:08:03.990
when it comes time
to collect objects.

00:08:03.990 --> 00:08:05.230
So there's four phases.

00:08:05.230 --> 00:08:07.320
The first one,
Dalvik has to pause

00:08:07.320 --> 00:08:09.090
all the threads in
your application

00:08:09.090 --> 00:08:10.470
to find a route set.

00:08:10.470 --> 00:08:13.710
So route sets are
typically local variables--

00:08:13.710 --> 00:08:16.240
threads, studied variables.

00:08:16.240 --> 00:08:18.480
They're just the routes
of all the locations

00:08:18.480 --> 00:08:20.160
that can be reached
in your application.

00:08:20.160 --> 00:08:21.360
So that takes a bit of time.

00:08:21.360 --> 00:08:24.400
And during that time, your
application cannot do anything.

00:08:24.400 --> 00:08:26.100
The second phase is concurrent.

00:08:26.100 --> 00:08:27.690
Your app is running again.

00:08:27.690 --> 00:08:29.610
So from this route,
Dalvik we'll find

00:08:29.610 --> 00:08:33.350
all the objects that can be
reached and mark them as such.

00:08:33.350 --> 00:08:37.550
Unfortunately, since that
second phase is concurrent,

00:08:37.550 --> 00:08:39.789
allocations could be
triggered during that time.

00:08:39.789 --> 00:08:41.580
So you see here, like
for instance, we just

00:08:41.580 --> 00:08:45.280
allocating another object.

00:08:45.280 --> 00:08:48.020
So we need to pause the
application again and find

00:08:48.020 --> 00:08:49.680
the reachable objects again.

00:08:49.680 --> 00:08:51.900
And all your threads are
paused, so your application

00:08:51.900 --> 00:08:53.500
stutters a little bit again.

00:08:53.500 --> 00:08:56.320
And finally, we can mark all the
objects that are not reachable.

00:08:56.320 --> 00:08:58.870
And there are candidates
for garbage collection.

00:08:58.870 --> 00:09:00.360
So the collection
itself just gets

00:09:00.360 --> 00:09:02.740
rid of the objects in the heap.

00:09:02.740 --> 00:09:05.640
So now, if we want to allocate
something in the heap,

00:09:05.640 --> 00:09:07.290
and the heap is
pretty much full,

00:09:07.290 --> 00:09:10.445
and we have objects that have
been marked for allocation,

00:09:10.445 --> 00:09:12.670
Dalvik will go through
the heap, realize

00:09:12.670 --> 00:09:14.580
that there is no
memory available,

00:09:14.580 --> 00:09:16.770
and then it will trigger
a garbage collection

00:09:16.770 --> 00:09:18.750
for the specific use
case of an allocation.

00:09:18.750 --> 00:09:20.070
That's the GC_FOR_ALLOC.

00:09:20.070 --> 00:09:22.320
And every time this
happens, you see a log.

00:09:22.320 --> 00:09:24.360
On KitKat, doing
an adb logcat, you

00:09:24.360 --> 00:09:26.940
can see those
GC_FOR_ALLOC messages.

00:09:26.940 --> 00:09:30.240
So it will run the collection,
get rid of this memory,

00:09:30.240 --> 00:09:35.550
then we can run through the
typical allocation mechanism.

00:09:35.550 --> 00:09:37.645
However, sometimes
your heap is full.

00:09:37.645 --> 00:09:39.660
There are no objects
that can be collected.

00:09:39.660 --> 00:09:41.140
Every object is reachable.

00:09:41.140 --> 00:09:45.070
So Dalvik will run through the
heap-- can't find anything.

00:09:45.070 --> 00:09:46.950
And only two things can happen.

00:09:46.950 --> 00:09:50.760
Either the heap will grow or
your application will crash.

00:09:50.760 --> 00:09:54.380
And it's the Out of Memory error
that you've seen, I'm sure,

00:09:54.380 --> 00:09:58.230
in a lot of visual applications,
especially on older devices.

00:09:58.230 --> 00:10:00.920
This typically happens when you
are allocating large objects.

00:10:00.920 --> 00:10:04.630
I remember a lot of developers
in the early days of Android

00:10:04.630 --> 00:10:06.840
filed bugs against
Bitmap Factory

00:10:06.840 --> 00:10:09.870
because Out of Memory
error tended to happen

00:10:09.870 --> 00:10:12.450
during the decoding of bitmaps.

00:10:12.450 --> 00:10:15.120
And they thought there was a
memory leak in Bitmap Factory.

00:10:15.120 --> 00:10:17.970
The main reason was
bitmap objects are big,

00:10:17.970 --> 00:10:20.460
and it was hard to
find space for them.

00:10:20.460 --> 00:10:24.100
There was no leak in
Bitmap factory whatsoever.

00:10:24.100 --> 00:10:27.640
CHET HASSE: So we wrote
a simple demo application

00:10:27.640 --> 00:10:30.580
to show off how some of the
stuff with heap fragmentation

00:10:30.580 --> 00:10:31.310
works.

00:10:31.310 --> 00:10:34.870
So in the demo, we
allocate chunks of memory

00:10:34.870 --> 00:10:36.380
all the way up to max heap.

00:10:36.380 --> 00:10:37.930
So your heap starts
out very small.

00:10:37.930 --> 00:10:39.670
And then if you can't
allocate an object,

00:10:39.670 --> 00:10:42.250
it's going to grow that over
and over and over until it

00:10:42.250 --> 00:10:43.570
reaches the max possible.

00:10:43.570 --> 00:10:45.909
So for this demo, we
allocate these 1 meg chunks.

00:10:45.909 --> 00:10:48.200
You press this button that
says, there's 400 megs free.

00:10:48.200 --> 00:10:50.260
You press the button, it's going
to allocate all these 1 meg

00:10:50.260 --> 00:10:53.050
chunks, all the way until it
grows the heap until it cannot

00:10:53.050 --> 00:10:53.800
anymore.

00:10:53.800 --> 00:10:54.590
You get an error.

00:10:54.590 --> 00:10:56.620
We catch the error, and now
we know the heap is full.

00:10:56.620 --> 00:10:57.010
There's no space anywhere.

00:10:57.010 --> 00:10:57.790
ROMAIN GUY: And
this is pretty much

00:10:57.790 --> 00:10:59.873
the only situation where
you should do a try-catch

00:10:59.873 --> 00:11:00.970
on an out of memory error.

00:11:00.970 --> 00:11:02.572
Don't do that in
your application.

00:11:02.572 --> 00:11:03.958
[CHET CHUCKLING]

00:11:04.882 --> 00:11:07.869
CHET HASSE: And then we say, OK,
well there's only one meg free.

00:11:07.869 --> 00:11:09.910
So we're going to go ahead
and fragment the heap,

00:11:09.910 --> 00:11:11.919
and we're going to
free a bunch of chunks.

00:11:11.919 --> 00:11:13.960
So we're basically going
to go through everything

00:11:13.960 --> 00:11:16.180
we've allocated, and
free every other one

00:11:16.180 --> 00:11:17.290
through the entire heap.

00:11:17.290 --> 00:11:19.498
ROMAIN GUY: So just go
through every other reference,

00:11:19.498 --> 00:11:21.010
set it to null,
then force the GC

00:11:21.010 --> 00:11:23.365
a couple times to make sure
that that memory goes away.

00:11:23.365 --> 00:11:24.990
CHET HASSE: And then
we get this result

00:11:24.990 --> 00:11:28.450
that says, OK, the fragmented
heap size is now 200 megs.

00:11:28.450 --> 00:11:29.890
So we should have
plenty of space

00:11:29.890 --> 00:11:32.730
to go ahead and allocate
a two megabyte object.

00:11:32.730 --> 00:11:34.870
So that blue object
there, it's only 2 megs.

00:11:34.870 --> 00:11:37.690
We've got 200 megs free.

00:11:37.690 --> 00:11:40.160
So what can be the problem?

00:11:40.160 --> 00:11:42.460
So we press the button,
and it says, nope, we

00:11:42.460 --> 00:11:43.722
can't fit that in there.

00:11:43.722 --> 00:11:46.180
And if you look at the log,
you get these depressing things

00:11:46.180 --> 00:11:46.975
here, where it says--

00:11:46.975 --> 00:11:48.970
ROMAIN GUY: It's the
best error message in all

00:11:48.970 --> 00:11:50.080
of computer science, I think.

00:11:50.080 --> 00:11:51.100
CHET HASSE: Yes, right here.

00:11:51.100 --> 00:11:51.850
This is beautiful.

00:11:51.850 --> 00:11:56.620
It says, OK, you have
200 megs free out of 400.

00:11:56.620 --> 00:11:59.410
And we're forcing a collection
so that we can make room

00:11:59.410 --> 00:12:00.790
for a 2 meg chunk.

00:12:00.790 --> 00:12:03.280
And we're trying
really hard to do that,

00:12:03.280 --> 00:12:04.580
and we ran out of memory.

00:12:04.580 --> 00:12:07.540
So we cannot find space
for 2 megs out of 200.

00:12:07.540 --> 00:12:10.057
Because apparently Dalvik
was really bad at math.

00:12:10.057 --> 00:12:11.890
The problem was, of
course, that we couldn't

00:12:11.890 --> 00:12:14.560
find 2 megs contiguous,
and Dalvik did not

00:12:14.560 --> 00:12:16.570
have the ability to
compact the heap.

00:12:16.570 --> 00:12:17.530
You get what you get.

00:12:17.530 --> 00:12:19.942
Once we put the thing there,
it was not going to move.

00:12:19.942 --> 00:12:21.400
So we couldn't
actually shove stuff

00:12:21.400 --> 00:12:26.070
to the side to make room
for a larger object.

00:12:26.070 --> 00:12:28.790
So ART came along in Lollipop.

00:12:28.790 --> 00:12:31.277
As I said, it's a platform
for optimizations.

00:12:31.277 --> 00:12:33.610
It no longer had the memory
constraints that Dalvik did,

00:12:33.610 --> 00:12:35.943
so they could sort of build
in a lot of the fundamentals

00:12:35.943 --> 00:12:37.550
that they'd been
improving over time.

00:12:37.550 --> 00:12:40.900
But out of the box, it came with
much faster allocation times,

00:12:40.900 --> 00:12:44.620
much faster collections, as
well as a faster runtime,

00:12:44.620 --> 00:12:47.470
the ability to do
ahead-of-time compilations,

00:12:47.470 --> 00:12:50.170
so we're actually running
binary code all the time.

00:12:50.170 --> 00:12:51.900
We're not constantly
jitting things

00:12:51.900 --> 00:12:53.490
to find how we can
speed things up.

00:12:53.490 --> 00:12:54.550
We're making everything faster.

00:12:54.550 --> 00:12:55.780
ROMAIN GUY: One thing
we need to make clear

00:12:55.780 --> 00:12:58.420
is when we talk about
allocation and faster allocation

00:12:58.420 --> 00:13:01.390
in this talk, we mean just the
time it takes for the runtime

00:13:01.390 --> 00:13:02.410
to reserve the memory.

00:13:02.410 --> 00:13:03.460
We are not talking
about the time it

00:13:03.460 --> 00:13:04.780
takes to run the constructors.

00:13:04.780 --> 00:13:06.280
It has nothing to
do with your code.

00:13:06.280 --> 00:13:09.695
It's only in the runtime itself.

00:13:09.695 --> 00:13:12.280
CHET HASSE: All right, so
how did ART allocation work?

00:13:12.280 --> 00:13:14.446
ROMAIN GUY: So in ART, we
introduced a new allocator

00:13:14.446 --> 00:13:15.310
called a RosAlloc.

00:13:15.310 --> 00:13:17.350
And I don't know what
it stands for, actually.

00:13:17.350 --> 00:13:19.750
But it replaces something
called dlmalloc.

00:13:19.750 --> 00:13:23.500
So DL stands for Doug Lea, who
is also the person who wrote,

00:13:23.500 --> 00:13:25.277
I believe, java.util.concurrent.

00:13:25.277 --> 00:13:26.860
CHET HASSE: That's
what happens if you

00:13:26.860 --> 00:13:28.510
write a really nice algorithm.

00:13:28.510 --> 00:13:30.320
Then people name the
algorithm after you.

00:13:30.320 --> 00:13:32.028
ROMAIN GUY: Yeah, he's
the kind of person

00:13:32.028 --> 00:13:35.300
that makes me feel very
inadequate as an engineer--

00:13:35.300 --> 00:13:36.680
really smart.

00:13:36.680 --> 00:13:39.370
Anyway, dlmalloc is
basically the algorithm

00:13:39.370 --> 00:13:42.326
behind the malloc function
call in native code.

00:13:42.326 --> 00:13:44.200
So this is what you use
when you call malloc,

00:13:44.200 --> 00:13:46.030
or we call new in C or C++.

00:13:46.030 --> 00:13:47.590
This is the algorithm
we're using.

00:13:47.590 --> 00:13:49.570
So Dalvik was relying on that.

00:13:49.570 --> 00:13:51.990
ART replaced it with
its own, calls Ros.

00:13:51.990 --> 00:13:55.369
So the main benefit of RosAlloc
is that it's thread-aware.

00:13:55.369 --> 00:13:57.910
So it's able to do allocations
that are specific to a thread.

00:13:57.910 --> 00:14:00.760
And we're going to
look at this in detail.

00:14:00.760 --> 00:14:03.467
And you'll understand why
it brings a lot of benefits.

00:14:03.467 --> 00:14:05.800
There's also a lot of little
tweaks that have been done.

00:14:05.800 --> 00:14:07.660
So small allocations
are grouped together

00:14:07.660 --> 00:14:09.310
to reduce fragmentation.

00:14:09.310 --> 00:14:11.970
We align larger
locations on pages--

00:14:11.970 --> 00:14:15.310
typically 4 kilobytes on
modern OSes, and gives you

00:14:15.310 --> 00:14:16.739
better performance.

00:14:16.739 --> 00:14:19.030
Also, finer-grained lock,
because the garbage collector

00:14:19.030 --> 00:14:22.770
has to acquire locks because we
have a lot of threads running.

00:14:22.770 --> 00:14:25.730
It used to protect
a lot more code.

00:14:25.730 --> 00:14:28.080
So now it protects takes less
code, and it runs faster.

00:14:28.080 --> 00:14:31.720
And overall, allocations with
RosAlloc are four to five times

00:14:31.720 --> 00:14:33.550
faster than they
were with Dalvik.

00:14:33.550 --> 00:14:36.510
Again, this is just about the
act of allocating the memory.

00:14:36.510 --> 00:14:38.110
It has nothing to
do with your code.

00:14:38.110 --> 00:14:39.830
You could do something
really, really,

00:14:39.830 --> 00:14:41.680
really expensive in
your constructor,

00:14:41.680 --> 00:14:45.134
and we would not be five
times faster than Dalvik.

00:14:45.134 --> 00:14:46.050
CHET HASSE: All right.

00:14:46.050 --> 00:14:48.020
So let's take a look
at how allocations work

00:14:48.020 --> 00:14:50.460
on ART, in this new system.

00:14:50.460 --> 00:14:51.560
Oh, sorry.

00:14:51.560 --> 00:14:53.660
The other very, very
important thing with ART

00:14:53.660 --> 00:14:55.640
was the ability to
deal with large objects

00:14:55.640 --> 00:14:56.970
in a much better way.

00:14:56.970 --> 00:14:59.180
So you've got this
normal-sized object.

00:14:59.180 --> 00:15:01.850
It's going to find a space
for it in the heap over here.

00:15:01.850 --> 00:15:04.760
And what happens if you
have this large item?

00:15:04.760 --> 00:15:09.480
By a large object, we mean an
array of primitives or string.

00:15:09.480 --> 00:15:12.350
And these are the types chosen,
because we can guarantee

00:15:12.350 --> 00:15:15.020
that these objects will not have
a reference to something else.

00:15:15.020 --> 00:15:16.070
They can live
completely on their own.

00:15:16.070 --> 00:15:17.930
ROMAIN GUY: And it's an array
of at least 12 kilobytes.

00:15:17.930 --> 00:15:18.750
CHET HASSE: Yes.

00:15:18.750 --> 00:15:20.434
And that is the
heuristic for now.

00:15:20.434 --> 00:15:21.600
That could change over time.

00:15:21.600 --> 00:15:24.409
But right now, it's 12K,
primitive types or string.

00:15:24.409 --> 00:15:25.700
So you've got this huge object.

00:15:25.700 --> 00:15:26.908
Where are we going to put it?

00:15:26.908 --> 00:15:30.062
Well, in Dalvik, we would
put it where, exactly?

00:15:30.062 --> 00:15:31.520
You can see in this
fragmented heap

00:15:31.520 --> 00:15:33.300
that there may not
be space for it.

00:15:33.300 --> 00:15:35.370
In ART, it's a
little bit simpler.

00:15:35.370 --> 00:15:37.980
The complicated mechanism
looks like this.

00:15:37.980 --> 00:15:39.350
We just put it somewhere.

00:15:39.350 --> 00:15:41.860
We just malloc a space for
it, and shove it in there.

00:15:41.860 --> 00:15:45.020
It's not even in a object
bucket that holds all of them.

00:15:45.020 --> 00:15:47.526
We just allocate a space
for it somewhere in there.

00:15:47.526 --> 00:15:49.400
And we say, OK, you are
now part of the heap.

00:15:49.400 --> 00:15:51.983
But really it's just living on
it's own somewhere-- very fast,

00:15:51.983 --> 00:15:53.980
very easy.

00:15:53.980 --> 00:15:55.860
It's also a moving collector.

00:15:55.860 --> 00:15:58.140
So we can actually
compact things.

00:15:58.140 --> 00:16:00.870
So we no longer have the
fragmentation problem.

00:16:00.870 --> 00:16:04.980
However, it does this
in the background.

00:16:04.980 --> 00:16:08.710
So actually it's a
little more complicated.

00:16:08.710 --> 00:16:11.370
My understanding
originally was, well,

00:16:11.370 --> 00:16:14.280
if your application goes
into the background,

00:16:14.280 --> 00:16:16.440
then eventually this very
expensive operation--

00:16:16.440 --> 00:16:18.302
it could take up to
100 milliseconds--

00:16:18.302 --> 00:16:20.010
may run that's going
to compact the heap.

00:16:20.010 --> 00:16:22.080
Obviously, we don't want to
run that in the foreground,

00:16:22.080 --> 00:16:23.980
because we're going to jank
your app all over the place.

00:16:23.980 --> 00:16:25.440
So we're going to wait
till it's sitting there

00:16:25.440 --> 00:16:27.450
in the background, user
is doing something else,

00:16:27.450 --> 00:16:28.658
they're not paying attention.

00:16:28.658 --> 00:16:30.390
So we're compacting
the heap for you.

00:16:30.390 --> 00:16:31.050
That's awesome.

00:16:31.050 --> 00:16:33.466
So I said, OK, well I'm going
to demonstrate this and show

00:16:33.466 --> 00:16:37.780
that same defragmentation crash
error that we saw earlier.

00:16:37.780 --> 00:16:41.430
I'm going to show how it
crashes on KitKat, using Dalvik,

00:16:41.430 --> 00:16:43.676
and it will also crash
in all of the releases

00:16:43.676 --> 00:16:46.300
until we're able to do it in the
foreground on a later release,

00:16:46.300 --> 00:16:49.230
in O. And this will
be a cool demo.

00:16:49.230 --> 00:16:52.470
And then I ran and on
L, and it didn't crash.

00:16:52.470 --> 00:16:55.650
And the thing is, yes, it will
defragment in the background,

00:16:55.650 --> 00:16:57.450
but it will also do
it in the foreground

00:16:57.450 --> 00:16:59.970
if it has to, which is
really what you want.

00:16:59.970 --> 00:17:02.634
So if you actually
need that memory now,

00:17:02.634 --> 00:17:04.300
wouldn't it be nice
if you didn't crash?

00:17:04.300 --> 00:17:04.869
So that's what we--

00:17:04.869 --> 00:17:06.994
ROMAIN GUY: That compaction
is almost a replacement

00:17:06.994 --> 00:17:09.540
for the GC_FOR_ALLOC
from before.

00:17:09.540 --> 00:17:11.819
CHET HASSE: So now it
basically takes everything,

00:17:11.819 --> 00:17:14.490
it says, well, you need space
for this really large object.

00:17:14.490 --> 00:17:17.609
We're going to go ahead and
compact things, and then

00:17:17.609 --> 00:17:18.869
put it where we need to.

00:17:18.869 --> 00:17:23.130
So on L and above, we run
the same fragmentation demo

00:17:23.130 --> 00:17:24.300
that we saw before.

00:17:24.300 --> 00:17:27.869
We go ahead and alloc up
to the maximum heap size.

00:17:27.869 --> 00:17:30.330
It says, yep, you've only
got about 1 meg free.

00:17:30.330 --> 00:17:32.310
And we go ahead and
free every other meg,

00:17:32.310 --> 00:17:34.170
null out those
references, and then we

00:17:34.170 --> 00:17:36.300
try to find space
for this 2 meg block.

00:17:36.300 --> 00:17:38.760
It compacts the heap,
and puts it in--

00:17:38.760 --> 00:17:40.614
very simple.

00:17:40.614 --> 00:17:42.280
ROMAIN GUY: So, another
improvement-- so

00:17:42.280 --> 00:17:43.980
remember with the
Dalvik GC, we had

00:17:43.980 --> 00:17:47.790
those four phases, including
two pauses for your application.

00:17:47.790 --> 00:17:50.650
So the pauses were bad because
your application was not doing

00:17:50.650 --> 00:17:51.980
anything during that time.

00:17:51.980 --> 00:17:54.310
But what was even worse
was that those pauses

00:17:54.310 --> 00:17:55.930
could be pretty expensive.

00:17:55.930 --> 00:17:58.330
So on average, the sum
of those two pauses

00:17:58.330 --> 00:17:59.910
was about 10 milliseconds.

00:17:59.910 --> 00:18:01.660
But even when it was
only 10 milliseconds,

00:18:01.660 --> 00:18:03.200
that was actually pretty good.

00:18:03.200 --> 00:18:05.140
I mean, we've done a
lot of performance work

00:18:05.140 --> 00:18:07.780
over the years, and I've seen
these kind of pauses last

00:18:07.780 --> 00:18:10.700
for 100, 200 milliseconds
in some applications.

00:18:10.700 --> 00:18:12.830
And during that time,
nothing happens,

00:18:12.830 --> 00:18:15.550
which means no matter how
good your UI is, it will jank.

00:18:15.550 --> 00:18:17.410
Like if the user is
trying to scroll,

00:18:17.410 --> 00:18:19.240
it's not going to work well.

00:18:19.240 --> 00:18:22.660
One of the things
that ART does is

00:18:22.660 --> 00:18:24.190
it removes one of the pauses.

00:18:24.190 --> 00:18:26.717
So now the first
step, the marking

00:18:26.717 --> 00:18:29.050
the route set, finding the
routes of all the allocations

00:18:29.050 --> 00:18:31.662
that are reachable in your
heap, is now a concurrent phase.

00:18:31.662 --> 00:18:33.370
It doesn't pause the
application anymore.

00:18:33.370 --> 00:18:36.550
And on top of that,
the second one--

00:18:36.550 --> 00:18:39.410
the only pause that we still
have left is also a lot faster.

00:18:39.410 --> 00:18:41.409
So instead of spending
10 milliseconds in there,

00:18:41.409 --> 00:18:43.080
we only spend about
3 milliseconds now.

00:18:43.080 --> 00:18:44.830
So at most, your
application will probably

00:18:44.830 --> 00:18:45.910
pause for 3 milliseconds.

00:18:45.910 --> 00:18:48.560
So if your application
is well-optimized,

00:18:48.560 --> 00:18:51.090
the GC happens during an
admission or scrolling.

00:18:51.090 --> 00:18:55.656
You should be able to look
reach 60 fps without any jank.

00:18:55.656 --> 00:18:58.270
Another thing that
was introduced in ART

00:18:58.270 --> 00:19:00.490
was the concept of the
minor garbage collection.

00:19:00.490 --> 00:19:04.960
So the idea here is to keep
track of all the objects

00:19:04.960 --> 00:19:07.780
that have been allocated
since the last major garbage

00:19:07.780 --> 00:19:09.020
collection.

00:19:09.020 --> 00:19:10.810
Those are typically
temporary objects,

00:19:10.810 --> 00:19:12.180
and we're going to
look at them first.

00:19:12.180 --> 00:19:14.596
So if we can reclaim enough
memory by looking at a subject

00:19:14.596 --> 00:19:16.090
first, because
they're short-lived,

00:19:16.090 --> 00:19:18.510
we won't have to go
through the entire heap.

00:19:18.510 --> 00:19:20.260
CHET HASSE: This is
one of the things that

00:19:20.260 --> 00:19:22.930
has an important consequence
for Android development,

00:19:22.930 --> 00:19:24.970
where we used to tell
you, never allocate even

00:19:24.970 --> 00:19:26.500
temporary objects,
because they tend

00:19:26.500 --> 00:19:28.660
to be expensive, because they're
going to fragment the heap.

00:19:28.660 --> 00:19:29.810
We have to do the allocation.

00:19:29.810 --> 00:19:31.018
We have to do the collection.

00:19:31.018 --> 00:19:33.490
All of a sudden, we made
temporary object allocation

00:19:33.490 --> 00:19:35.207
and collection much
faster and easier.

00:19:35.207 --> 00:19:36.290
ROMAIN GUY: It's not free.

00:19:36.290 --> 00:19:37.780
It's just less expensive.

00:19:37.780 --> 00:19:38.890
CHET HASSE: Yes.

00:19:38.890 --> 00:19:40.510
ROMAIN GUY: We also introduced
the larger malloc heap

00:19:40.510 --> 00:19:41.230
that we talked about.

00:19:41.230 --> 00:19:42.480
So we have less fragmentation.

00:19:42.480 --> 00:19:44.260
But one of the huge
benefits of that

00:19:44.260 --> 00:19:47.080
is, because we don't
fragment the heap as much,

00:19:47.080 --> 00:19:50.150
we don't have to grow the heap
as much in all the processes.

00:19:50.150 --> 00:19:53.209
And of course, we don't
have to GC_FOR_ALLOC.

00:19:53.209 --> 00:19:54.250
I mean, they still exist.

00:19:54.250 --> 00:19:56.708
We just don't see them as much
because they were very, very

00:19:56.708 --> 00:19:58.070
common in the Dalvik days.

00:19:58.070 --> 00:20:00.190
And also there's
a faster runtime.

00:20:00.190 --> 00:20:01.930
That's the ahead-of-time
compilation.

00:20:01.930 --> 00:20:03.220
And we introduced the G tag.

00:20:03.220 --> 00:20:06.230
But this has nothing to do
with the garbage collector.

00:20:06.230 --> 00:20:09.880
Marshmallow-- I was
joking with Chet yesterday

00:20:09.880 --> 00:20:11.650
that it's kind of
a boring release,

00:20:11.650 --> 00:20:14.620
because I can never remember
what was in Marshmallow.

00:20:14.620 --> 00:20:15.970
So here it is--

00:20:15.970 --> 00:20:17.571
optimizations in ART.

00:20:17.571 --> 00:20:18.820
CHET HASSE: Things got faster.

00:20:18.820 --> 00:20:20.890
Fine-grained details,
things got faster.

00:20:23.740 --> 00:20:26.150
And again, things got faster.

00:20:26.150 --> 00:20:27.310
Isn't that nice?

00:20:27.310 --> 00:20:29.330
Allocation in particular.

00:20:29.330 --> 00:20:32.790
They rewrote everything, all
the core stuff in assembly.

00:20:32.790 --> 00:20:34.760
And that turns out to
still help in software.

00:20:34.760 --> 00:20:35.600
Who knew?

00:20:35.600 --> 00:20:37.160
And now we're up
to about 10 times

00:20:37.160 --> 00:20:41.396
faster for allocation costs
when you compare it to Dalvik.

00:20:41.396 --> 00:20:44.990
And now we're in Oreo,
where basically they

00:20:44.990 --> 00:20:46.020
rewrote the whole thing.

00:20:46.020 --> 00:20:48.380
So we introduce an
entirely new collector,

00:20:48.380 --> 00:20:51.230
called the Concurrent
Heap Compaction Collector.

00:20:51.230 --> 00:20:53.120
And this means that
now we can actually

00:20:53.120 --> 00:20:54.860
compact in the
foreground, not just

00:20:54.860 --> 00:20:57.510
when we need to do that
GC_FOR_ALLOC compact to find

00:20:57.510 --> 00:20:58.010
a space.

00:20:58.010 --> 00:20:59.870
But it is actually
running all the time,

00:20:59.870 --> 00:21:01.940
moving stuff around,
and optimizing

00:21:01.940 --> 00:21:04.370
what the heap looks like
so that allocations are

00:21:04.370 --> 00:21:07.010
much faster and easier overall.

00:21:07.010 --> 00:21:09.390
So defragmentation
in the foreground,

00:21:09.390 --> 00:21:11.240
you're not resizing
the heap is often

00:21:11.240 --> 00:21:12.865
because the heap is
always optimized,

00:21:12.865 --> 00:21:14.990
because we're always sort
of culling the things out

00:21:14.990 --> 00:21:16.500
of it as necessary.

00:21:16.500 --> 00:21:18.500
There's far fewer
GC_FOR_ALLOCs because we just

00:21:18.500 --> 00:21:20.510
don't get into that
situation anymore.

00:21:20.510 --> 00:21:23.005
Huge savings for
the entire device.

00:21:23.005 --> 00:21:23.630
Think about it.

00:21:23.630 --> 00:21:26.784
If you can only defragment the
heap when an application is

00:21:26.784 --> 00:21:28.700
in the background, what
about the applications

00:21:28.700 --> 00:21:31.158
and services that are constantly
in the foreground-- system

00:21:31.158 --> 00:21:34.910
service, play
services, system UI.

00:21:34.910 --> 00:21:37.040
Well, we couldn't
necessarily defragment those

00:21:37.040 --> 00:21:38.859
until it got into a
really bad situation.

00:21:38.859 --> 00:21:41.150
Wouldn't it be nice if we
could do it in the foreground

00:21:41.150 --> 00:21:42.550
so that those things
were optimized?

00:21:42.550 --> 00:21:44.120
Well, if we can do
it for them, that

00:21:44.120 --> 00:21:47.420
means we're getting system-wide
savings on the pure heap size

00:21:47.420 --> 00:21:50.110
of all of those applications.

00:21:50.110 --> 00:21:52.640
So smaller heaps for
all means less memory

00:21:52.640 --> 00:21:53.870
in the entire system.

00:21:53.870 --> 00:21:56.060
And what we found
was the entire device

00:21:56.060 --> 00:22:00.840
had about a 30% savings on
overall memory requirements.

00:22:00.840 --> 00:22:03.710
So we can take a look at how
compaction works in general.

00:22:03.710 --> 00:22:07.710
We have these 256K buckets
that are assigned per thread.

00:22:07.710 --> 00:22:10.250
Which means, again,
huge savings in not

00:22:10.250 --> 00:22:12.740
having to lock down all the
threads to do these allocations

00:22:12.740 --> 00:22:13.730
and collections.

00:22:13.730 --> 00:22:15.840
Instead, a thread,
if it needs memory,

00:22:15.840 --> 00:22:17.870
it's just responsible
for itself.

00:22:17.870 --> 00:22:19.855
So a thread says, OK,
I need some memory.

00:22:19.855 --> 00:22:21.230
It's handed one
of these buckets.

00:22:21.230 --> 00:22:22.890
It allocates in there.

00:22:22.890 --> 00:22:25.480
And then over time that
thing may get defragmented.

00:22:25.480 --> 00:22:27.770
There's a heuristic
that they have about

00:22:27.770 --> 00:22:31.250
if there's less than 70%
or 75% utilization in one

00:22:31.250 --> 00:22:34.250
of these things, then they'll go
ahead and collect it, and empty

00:22:34.250 --> 00:22:35.340
the thing out entirely.

00:22:35.340 --> 00:22:38.299
So we see the T1,
2, 3 regions here

00:22:38.299 --> 00:22:39.590
don't have much going on there.

00:22:39.590 --> 00:22:41.399
So we're going to take
the memory in there,

00:22:41.399 --> 00:22:43.690
all of those allocations,
and shove them somewhere else

00:22:43.690 --> 00:22:47.120
in the heap, completely empty
out those buckets, which

00:22:47.120 --> 00:22:49.340
allows something
that's super-efficient,

00:22:49.340 --> 00:22:51.500
called thread-local
bump allocator.

00:22:51.500 --> 00:22:52.970
This means that
all we have to do

00:22:52.970 --> 00:22:54.350
is actually just move a pointer.

00:22:54.350 --> 00:22:56.150
We don't need to
walk the heap to find

00:22:56.150 --> 00:22:57.680
where the free space is.

00:22:57.680 --> 00:23:00.685
We just put the next object
in the next available space.

00:23:00.685 --> 00:23:02.810
And we know where that is
according to the pointer.

00:23:02.810 --> 00:23:04.760
It turns out, all
of this stuff put

00:23:04.760 --> 00:23:07.880
together, we're now 18
times faster than Dalvik

00:23:07.880 --> 00:23:09.390
for these allocations.

00:23:09.390 --> 00:23:12.275
So we can see how these
allocations work in practice.

00:23:12.275 --> 00:23:14.150
You can see all these
little colored objects.

00:23:14.150 --> 00:23:16.010
We're making space for the
in the different threads that

00:23:16.010 --> 00:23:17.420
need those allocations.

00:23:17.420 --> 00:23:20.370
If we take a close look at T1,
you've got the free pointer.

00:23:20.370 --> 00:23:21.627
We've emptied it out.

00:23:21.627 --> 00:23:22.460
We've zeroed it out.

00:23:22.460 --> 00:23:24.117
We're at the beginning
of that bucket.

00:23:24.117 --> 00:23:25.700
And now we need to
allocate an object.

00:23:25.700 --> 00:23:28.520
Well, we know where to put it
because the pointer tells us.

00:23:28.520 --> 00:23:30.310
And now all we do is
advance the pointer.

00:23:30.310 --> 00:23:32.768
The pointer tells us where to
put the next one, and the one

00:23:32.768 --> 00:23:34.020
after that, and so on.

00:23:34.020 --> 00:23:37.080
So very fast and easy compared
to what we were doing before.

00:23:37.080 --> 00:23:38.870
We can see on the
graph the comparison

00:23:38.870 --> 00:23:41.660
of where we were out with
Dalvik allocation costs

00:23:41.660 --> 00:23:46.130
compared to where we're at
now in O, with bump pointer

00:23:46.130 --> 00:23:50.755
and assembly
allocations instead.

00:23:50.755 --> 00:23:52.850
All right, so where
are we going now?

00:23:52.850 --> 00:23:56.000
It is important to note
that the young generation

00:23:56.000 --> 00:23:58.310
stuff that we talked
about as being so awesome

00:23:58.310 --> 00:23:59.570
is currently gone.

00:23:59.570 --> 00:24:01.863
ROMAIN GUY: But
it's back in AOSP.

00:24:01.863 --> 00:24:04.184
And so it will probably
be in the future release.

00:24:04.184 --> 00:24:04.850
CHET HASSE: Yep.

00:24:04.850 --> 00:24:06.850
So it's important to note.

00:24:06.850 --> 00:24:08.360
There are trade-offs here.

00:24:08.360 --> 00:24:09.834
We believe it's better overall.

00:24:09.834 --> 00:24:12.500
All of the benefits that you get
from the garbage collector in O

00:24:12.500 --> 00:24:15.470
should compensate for the
young generation collections

00:24:15.470 --> 00:24:16.530
not being there anymore.

00:24:16.530 --> 00:24:18.610
However, they're still
a nice thing to have.

00:24:18.610 --> 00:24:20.060
So they're back in AOSP.

00:24:20.060 --> 00:24:23.060
So look for those to show
up in a future release.

00:24:23.060 --> 00:24:24.650
ROMAIN GUY: So
object pools-- this

00:24:24.650 --> 00:24:27.650
is a technique that we've
recommended using in the past.

00:24:27.650 --> 00:24:30.820
We use it ourselves extensively
inside the platform.

00:24:30.820 --> 00:24:33.290
And the conventional wisdom
is that reusing object

00:24:33.290 --> 00:24:36.080
has to be faster than allocating
them and collecting them

00:24:36.080 --> 00:24:36.742
all the time.

00:24:36.742 --> 00:24:38.450
And you can see here
we have a preference

00:24:38.450 --> 00:24:41.840
graph so the x-axis is
the size of the object

00:24:41.840 --> 00:24:44.033
that you're creating or reusing.

00:24:44.033 --> 00:24:47.026
In red, it's the time it
takes to handle those objects

00:24:47.026 --> 00:24:48.650
with a pool, and in
blue, it's the time

00:24:48.650 --> 00:24:50.850
it takes to just allocate
and collect those objects.

00:24:50.850 --> 00:24:54.830
And until N, using the
pool was basically always

00:24:54.830 --> 00:24:57.440
a win compared to the
garbage collector.

00:24:57.440 --> 00:25:00.340
But with O, with all the
improvements we've done,

00:25:00.340 --> 00:25:03.500
and this new thread-bump
local allocator,

00:25:03.500 --> 00:25:06.590
synchronized pools of
objects are generally slower.

00:25:06.590 --> 00:25:09.730
And I want to emphasize the
synchronized part of the pool.

00:25:09.730 --> 00:25:12.500
If you have a pool of objects
that's used only on one thread,

00:25:12.500 --> 00:25:14.510
and that thread only,
you're effectively

00:25:14.510 --> 00:25:18.320
doing the kind of optimization
that ART does for you now in O.

00:25:18.320 --> 00:25:20.390
So you might not see those
same kind of savings.

00:25:20.390 --> 00:25:22.670
But in general, on O, if
you have a synchronized pool

00:25:22.670 --> 00:25:26.150
of objects, you'd be probably
better off without that pool.

00:25:26.150 --> 00:25:28.070
Again, make sure you
profile your application

00:25:28.070 --> 00:25:29.250
before you take it out.

00:25:29.250 --> 00:25:30.916
CHET HASSE: And there's
a certain memory

00:25:30.916 --> 00:25:34.070
size-- a certain size of object
where these graphs cross.

00:25:34.070 --> 00:25:35.870
But this was in a
benchmark application

00:25:35.870 --> 00:25:39.150
that was really hammering it
and maximizing the bandwidth.

00:25:39.150 --> 00:25:41.330
So the general
advice is, you really

00:25:41.330 --> 00:25:44.600
shouldn't use that, especially
the synchronized pool approach.

00:25:44.600 --> 00:25:48.230
Because A, it's error-prone
and tedious to manage, and B,

00:25:48.230 --> 00:25:51.950
it is slower in general because
that synchronization access

00:25:51.950 --> 00:25:55.490
tends to be slower than
what we can do now with--

00:25:55.490 --> 00:25:56.510
[INTERPOSING VOICES]

00:25:56.510 --> 00:25:57.968
ROMAIN GUY: The
whole point of O is

00:25:57.968 --> 00:26:02.468
that we don't have a lock
anymore for the allocations.

00:26:02.468 --> 00:26:06.140
CHET HASSE: So what are
the recommendations now?

00:26:06.140 --> 00:26:08.570
Creating garbage is OK.

00:26:08.570 --> 00:26:10.850
I wouldn't go out of your
way to create garbage.

00:26:10.850 --> 00:26:12.500
It is still taking time.

00:26:12.500 --> 00:26:14.780
You are requiring
us to take time

00:26:14.780 --> 00:26:17.920
to allocate objects, as
well as later collect them.

00:26:17.920 --> 00:26:20.540
And you're taking up battery
and CPU, and you're causing--

00:26:20.540 --> 00:26:21.220
ROMAIN GUY: But
don't do like Chet.

00:26:21.220 --> 00:26:22.640
Pick up after yourself.

00:26:22.640 --> 00:26:23.722
You should see his desk.

00:26:23.722 --> 00:26:24.680
It's pretty disgusting.

00:26:24.680 --> 00:26:25.760
[CHUCKLING]

00:26:25.760 --> 00:26:28.574
CHET HASSE: I like to
be a counterexample.

00:26:28.574 --> 00:26:32.090
So in general, creating
the stuff, if you need it,

00:26:32.090 --> 00:26:34.037
is OK, and so is collecting it.

00:26:34.037 --> 00:26:35.870
Use the types and the
objects that you need.

00:26:35.870 --> 00:26:37.970
If they make sense
for the architecture,

00:26:37.970 --> 00:26:40.220
for the APIs that you're
building, for the libraries,

00:26:40.220 --> 00:26:42.510
for your code, go
ahead and use those.

00:26:42.510 --> 00:26:45.860
We are now pushing everybody to
use int and bitflags everywhere

00:26:45.860 --> 00:26:50.200
to optimize every little CPU
cycle and memory allocation.

00:26:50.200 --> 00:26:52.080
Instead, go ahead
and allocate when

00:26:52.080 --> 00:26:53.330
you need to for your use case.

00:26:53.330 --> 00:26:55.022
However, GC is still overhead.

00:26:55.022 --> 00:26:56.480
ROMAIN GUY: And
we're going to look

00:26:56.480 --> 00:26:58.290
at a demo that showcases that.

00:26:58.290 --> 00:26:59.232
CHET HASSE: Yep.

00:26:59.232 --> 00:27:01.400
And make the right
choices for you.

00:27:01.400 --> 00:27:03.980
And in general, the
framework programmers,

00:27:03.980 --> 00:27:05.880
we still are your inner loop.

00:27:05.880 --> 00:27:07.520
So we still take
the old practices.

00:27:07.520 --> 00:27:09.530
Because why would
we allocate if we

00:27:09.530 --> 00:27:12.440
didn't need to, if we can
make your inner loop faster?

00:27:12.440 --> 00:27:14.300
So be aware of the
inner loop situations.

00:27:14.300 --> 00:27:16.624
Otherwise, do the right
thing for your code.

00:27:16.624 --> 00:27:20.450
All right, so I wrote
a simple application

00:27:20.450 --> 00:27:23.300
to sort of showcase
some of the jank stuff

00:27:23.300 --> 00:27:25.840
that you can see because of
allocations and collections.

00:27:25.840 --> 00:27:28.790
And this-- during the
onDraw, I would call out

00:27:28.790 --> 00:27:31.650
to a method to run some stuff.

00:27:31.650 --> 00:27:34.160
And in this case, we're
going to test autoboxing.

00:27:34.160 --> 00:27:37.040
So we have an array of
100,000 Float objects--

00:27:37.040 --> 00:27:38.659
capital F Float objects.

00:27:38.659 --> 00:27:40.200
So it's not just
the primitive float.

00:27:40.200 --> 00:27:41.741
Instead, it's the
capital F. So we're

00:27:41.741 --> 00:27:43.790
going to be allocating
these objects on the fly.

00:27:43.790 --> 00:27:45.820
Here's what the method
looks like that's going

00:27:45.820 --> 00:27:47.197
to run on every single frame.

00:27:47.197 --> 00:27:49.280
It's going to walk the
entire length of the array,

00:27:49.280 --> 00:27:51.380
and take a primitive
float, and stuff it

00:27:51.380 --> 00:27:53.530
into the array, which is
going to cause an autobox.

00:27:53.530 --> 00:27:55.580
So these little
tiny allocations are

00:27:55.580 --> 00:27:57.380
going to go into this array.

00:27:57.380 --> 00:27:59.420
A lot of them,
over time, because

00:27:59.420 --> 00:28:00.942
of the autoboxing
thing, it's going

00:28:00.942 --> 00:28:02.900
to cause a bunch of
allocations, and then we're

00:28:02.900 --> 00:28:05.100
going to need to collect
them over time as well.

00:28:05.100 --> 00:28:07.970
So if we take a
look at the demo.

00:28:07.970 --> 00:28:09.080
Let me pop out.

00:28:09.080 --> 00:28:13.160
All right, so we're
running on K here.

00:28:13.160 --> 00:28:14.940
We run this animation.

00:28:14.940 --> 00:28:19.274
We should take a
look at the log here.

00:28:19.274 --> 00:28:21.576
And we run the
autobox, and now we're

00:28:21.576 --> 00:28:22.700
calling out to that method.

00:28:22.700 --> 00:28:25.175
And the important thing here,
if you look at the log--

00:28:28.887 --> 00:28:33.450
so we're taking allocation
times of 28, 24,

00:28:33.450 --> 00:28:35.760
in general high-20s
milliseconds.

00:28:35.760 --> 00:28:37.710
And we're causing a
lot of GC_FOR_ALLOCs,

00:28:37.710 --> 00:28:40.950
because that is what happens
when you do this thing.

00:28:40.950 --> 00:28:42.342
So we can pause this one.

00:28:42.342 --> 00:28:44.550
We can pop over and see what
this looks like on O. We

00:28:44.550 --> 00:28:46.140
can run the animation here.

00:28:46.140 --> 00:28:52.335
We enable the log for O.
We'll do the autoboxing.

00:28:52.335 --> 00:28:53.960
And now we can zoom
in on this, and you

00:28:53.960 --> 00:28:55.251
will notice a couple of things.

00:28:55.251 --> 00:28:57.440
One is that the
allocation times obviously

00:28:57.440 --> 00:29:00.090
are much less than
they were before.

00:29:00.090 --> 00:29:02.840
And also, more importantly,
there are no GC_FOR_ALLOCs.

00:29:02.840 --> 00:29:04.580
We allocate, we
collect, but we're never

00:29:04.580 --> 00:29:06.440
triggering that
that jank-inducing

00:29:06.440 --> 00:29:07.790
GC_FOR_ALLOC in this case.

00:29:10.540 --> 00:29:14.810
There is a similar test
that I wrote for bitmaps.

00:29:14.810 --> 00:29:16.340
So we're running along--

00:29:16.340 --> 00:29:20.800
let's take a look
at the KitKat log.

00:29:20.800 --> 00:29:24.230
So in this one, you're
allocating bitmaps.

00:29:24.230 --> 00:29:26.480
And again, we're getting
a lot of jank there.

00:29:26.480 --> 00:29:28.340
If we zoom in on the
log, you're seeing

00:29:28.340 --> 00:29:31.040
the allocations for these
large objects at the 1,000

00:29:31.040 --> 00:29:32.180
by 1,000 bitmap.

00:29:32.180 --> 00:29:34.880
If you're taking 12, 13
milliseconds each time,

00:29:34.880 --> 00:29:37.340
and you're constantly
triggering these GC_FOR_ALLOCs,

00:29:37.340 --> 00:29:39.770
because you need to collect
the old memory to make room

00:29:39.770 --> 00:29:41.716
for the new one.

00:29:41.716 --> 00:29:48.430
So if you pop over to the O
log, stop this one over here,

00:29:48.430 --> 00:29:51.310
run the animation,
do the bitmap test,

00:29:51.310 --> 00:29:55.320
and now we've got
allocation times of 0, 1.

00:29:55.320 --> 00:29:57.070
Because again, all
it's doing is a malloc.

00:29:57.070 --> 00:29:59.230
It's just shoving it into
the large object heap.

00:29:59.230 --> 00:30:03.822
Very easy to allocate, very easy
to collect when it needs it.

00:30:03.822 --> 00:30:04.778
Stop that.

00:30:08.130 --> 00:30:10.120
All right.

00:30:10.120 --> 00:30:12.470
That just duplicates
what I just said.

00:30:12.470 --> 00:30:13.620
Here's the bitmap test.

00:30:13.620 --> 00:30:14.270
Very simple.

00:30:14.270 --> 00:30:16.730
It's just walking
through every frame.

00:30:16.730 --> 00:30:19.400
It's allocating 1,000
by 1,000 bitmap.

00:30:19.400 --> 00:30:22.205
And then you see the
results that we did.

00:30:22.205 --> 00:30:23.150
ROMAIN GUY: All right.

00:30:23.150 --> 00:30:26.247
So this is a demo
to basically stress

00:30:26.247 --> 00:30:28.580
test the garbage collector
and see what kind of overhead

00:30:28.580 --> 00:30:29.079
we get.

00:30:29.079 --> 00:30:31.430
So this is a kind of
a ray tracer using

00:30:31.430 --> 00:30:33.972
fancy physically-based rendering
that I wrote for my desktop.

00:30:33.972 --> 00:30:36.304
CHET HASSE: You can tell it's
a ray tracer, because it's

00:30:36.304 --> 00:30:37.790
a checkerboard with spheres.

00:30:37.790 --> 00:30:39.710
ROMAIN GUY: That's right.

00:30:39.710 --> 00:30:42.250
And I ported it to Android.

00:30:42.250 --> 00:30:44.180
And I want to run
you through the code

00:30:44.180 --> 00:30:46.110
because there's hundreds
of lines of code.

00:30:46.110 --> 00:30:47.120
So this is Kotlin.

00:30:47.120 --> 00:30:49.886
But the trick here is that
this does a lot of allocation.

00:30:49.886 --> 00:30:51.260
So I have a data
class, a float3.

00:30:51.260 --> 00:30:53.720
It just contains three
floats, x, y, and z.

00:30:53.720 --> 00:30:54.780
And those are primitives.

00:30:54.780 --> 00:30:58.139
They're not the capital F
objects that you get in Java.

00:30:58.139 --> 00:31:00.680
And here I have a function, just
an excerpt of those hundreds

00:31:00.680 --> 00:31:01.534
of lines of code.

00:31:01.534 --> 00:31:03.700
And you can see it's just
doing math on the objects.

00:31:03.700 --> 00:31:06.310
So I'm using operator
overloading in Kotlin.

00:31:06.310 --> 00:31:10.070
We are multiplying float3 called
x by a bunch of constants.

00:31:10.070 --> 00:31:11.570
We're do divisions, additions.

00:31:11.570 --> 00:31:14.070
But the important thing here
is that the way those functions

00:31:14.070 --> 00:31:17.110
are implemented, my
float3 is immutable.

00:31:17.110 --> 00:31:18.920
So every time I add
or multiply, I'm

00:31:18.920 --> 00:31:20.390
creating a new float3 object.

00:31:20.390 --> 00:31:22.160
So those are fairly
small objects.

00:31:22.160 --> 00:31:24.546
But for every pixel that we'll
want to render in that ray

00:31:24.546 --> 00:31:26.420
tracer, we're going to
be allocating hundreds

00:31:26.420 --> 00:31:28.790
of thousands or millions
of these float3's.

00:31:28.790 --> 00:31:30.920
So we're going to
really exercise the GC.

00:31:30.920 --> 00:31:35.420
So then I created two system
images, one on KitKat,

00:31:35.420 --> 00:31:37.790
one on O, both running
on the emulator.

00:31:37.790 --> 00:31:39.320
We're emulating
the same hardware.

00:31:39.320 --> 00:31:40.615
It's a Nexus 5x.

00:31:40.615 --> 00:31:41.990
We have the same
number of cores.

00:31:41.990 --> 00:31:43.800
They're running on
the same host machine.

00:31:43.800 --> 00:31:46.740
So the only difference really
is the garbage collector.

00:31:46.740 --> 00:31:50.147
What I'm going to
press Next, both demos

00:31:50.147 --> 00:31:51.230
will run at the same time.

00:31:51.230 --> 00:31:53.010
We're going to start rendering
an animation with that ray

00:31:53.010 --> 00:31:53.510
tracer.

00:31:53.510 --> 00:31:56.650
And at the top you have O, and
at the bottom you have KitKat.

00:31:56.650 --> 00:31:59.021
See if you can spot the
difference in performance.

00:32:11.787 --> 00:32:13.200
So we'll save us some time.

00:32:13.200 --> 00:32:16.894
It takes 47 seconds for KitKat
to render the first tile.

00:32:16.894 --> 00:32:18.810
CHET HASSE: Yeah, but
it's a really good tile.

00:32:18.810 --> 00:32:20.310
ROMAIN GUY: It's a
really good tile.

00:32:20.310 --> 00:32:22.974
And again, we're running
the exact same application.

00:32:22.974 --> 00:32:24.390
The only difference
is effectively

00:32:24.390 --> 00:32:27.202
the garbage collector.

00:32:27.202 --> 00:32:29.670
So on O, rendering
one tile takes

00:32:29.670 --> 00:32:33.240
about 100 to 500
milliseconds, and on K, it

00:32:33.240 --> 00:32:34.990
takes 40 to 50 seconds.

00:32:34.990 --> 00:32:37.200
So two orders of
magnitude slower.

00:32:37.200 --> 00:32:40.470
And if you look at the logs on
KitKat, this is what we see.

00:32:40.470 --> 00:32:42.420
We see a bunch of GC file logs.

00:32:42.420 --> 00:32:45.000
And I just grabbed logs
for about 10 seconds

00:32:45.000 --> 00:32:46.620
worth of computations.

00:32:46.620 --> 00:32:49.980
And you can see we're constantly
stopping all the threads.

00:32:49.980 --> 00:32:53.070
We're blocking the
applications all the time.

00:32:53.070 --> 00:32:55.170
Nothing is getting done.

00:32:55.170 --> 00:32:57.450
That's a lot of GCs.

00:32:57.450 --> 00:33:01.766
And you can see, every time the
GC takes 3 to 5 milliseconds.

00:33:01.766 --> 00:33:05.370
So if we look at
systrace on O, we

00:33:05.370 --> 00:33:08.140
can see that even though
things are better,

00:33:08.140 --> 00:33:10.650
they are not quite perfect.

00:33:10.650 --> 00:33:13.890
So this is systrace here.

00:33:13.890 --> 00:33:15.442
You can see what
the CPUs are doing.

00:33:15.442 --> 00:33:17.400
And from afar, it looks
like they are very busy

00:33:17.400 --> 00:33:19.290
because of three
worker threads that

00:33:19.290 --> 00:33:21.885
are computing this 3D scene.

00:33:21.885 --> 00:33:25.004
But you can see there's a lot
of cases where the CPUs are

00:33:25.004 --> 00:33:26.170
actually not doing anything.

00:33:26.170 --> 00:33:28.210
There's holes in our pipe.

00:33:28.210 --> 00:33:30.440
So if you look at
the app itself,

00:33:30.440 --> 00:33:31.729
we see two interesting things.

00:33:31.729 --> 00:33:33.270
First of all, I have
my three threads

00:33:33.270 --> 00:33:36.030
that are computing--
that are doing the work.

00:33:36.030 --> 00:33:37.380
They're busy chugging along.

00:33:37.380 --> 00:33:40.710
But from time to time, here for
instance, the pause, and you

00:33:40.710 --> 00:33:43.374
probably can't read this, but
it says "full suspend check."

00:33:43.374 --> 00:33:44.790
And then we're not
doing anything.

00:33:44.790 --> 00:33:46.410
We're not doing any computation.

00:33:46.410 --> 00:33:49.760
And the reason is we have this
thread called the heap test

00:33:49.760 --> 00:33:50.430
daemon.

00:33:50.430 --> 00:33:52.605
It's basically the
concurrent garbage collector.

00:33:52.605 --> 00:33:54.980
So even though we're doing
concurrent garbage collection,

00:33:54.980 --> 00:33:57.010
and then locating
so many objects,

00:33:57.010 --> 00:34:00.540
it takes so much time for the
concurrent garbage collection

00:34:00.540 --> 00:34:01.240
to do its job.

00:34:01.240 --> 00:34:03.470
So here it's taking
about 200 milliseconds

00:34:03.470 --> 00:34:05.880
in load time that our threads--

00:34:05.880 --> 00:34:06.840
from time to time--

00:34:06.840 --> 00:34:08.082
have to block anyway.

00:34:08.082 --> 00:34:09.540
It's not that we
want to pause them

00:34:09.540 --> 00:34:11.144
because we have to pause them.

00:34:11.144 --> 00:34:13.560
It's not for the algorithms,
because the garbage collector

00:34:13.560 --> 00:34:15.110
is still busy.

00:34:15.110 --> 00:34:17.489
And originally, I was
planning more threads.

00:34:17.489 --> 00:34:19.949
And I was running
into weird situations

00:34:19.949 --> 00:34:22.290
where I had so many threads
doing computation that I

00:34:22.290 --> 00:34:24.210
was starting the GC thread.

00:34:24.210 --> 00:34:25.860
And it could not
run fast enough,

00:34:25.860 --> 00:34:27.889
so my threads were
pausing even more,

00:34:27.889 --> 00:34:31.710
and as a result, were getting
only about 30% to 40% CPU

00:34:31.710 --> 00:34:32.954
utilization.

00:34:32.954 --> 00:34:34.620
So we're not using
all the compute power

00:34:34.620 --> 00:34:36.389
that we have available
on the device.

00:34:36.389 --> 00:34:38.400
So the demo you saw
running on O could actually

00:34:38.400 --> 00:34:41.280
be something like three
times faster than that

00:34:41.280 --> 00:34:44.042
if I was not allocating as much.

00:34:44.042 --> 00:34:45.625
Another thing I
wanted to talk about--

00:34:45.625 --> 00:34:47.489
we only have four minutes left,
so we'll go through this fairly

00:34:47.489 --> 00:34:48.199
quickly--

00:34:48.199 --> 00:34:51.600
is that you have to be careful
when you create benchmarks,

00:34:51.600 --> 00:34:54.330
because the garbage
collector can greatly affect

00:34:54.330 --> 00:34:56.790
the results of your benchmark--

00:34:56.790 --> 00:34:58.920
not really the benchmark
itself, but the algorithm

00:34:58.920 --> 00:35:01.253
you are benchmarking, once
it's inside your application,

00:35:01.253 --> 00:35:02.660
it might behave
very differently.

00:35:02.660 --> 00:35:04.402
So I'm going to
skip some of this.

00:35:04.402 --> 00:35:06.360
Basically a quick recap--
when you have a CPU--

00:35:06.360 --> 00:35:09.132
this is the Pixel 3
CPU, the gold cores.

00:35:09.132 --> 00:35:10.590
We have big cores
and little cores.

00:35:10.590 --> 00:35:12.000
I'm looking at the big cores.

00:35:12.000 --> 00:35:13.740
Every core has an L1 cache.

00:35:13.740 --> 00:35:15.410
That's about 64 kilobytes.

00:35:15.410 --> 00:35:17.760
Every core has an L2 cache.

00:35:17.760 --> 00:35:20.580
That's a 256 kilobyte cache.

00:35:20.580 --> 00:35:23.760
And then there's an L3 cache
that's shared by all the cores.

00:35:23.760 --> 00:35:24.809
And this is important.

00:35:24.809 --> 00:35:26.350
Because when you
want to access data.

00:35:26.350 --> 00:35:27.750
So here, we have a
float array, and I just

00:35:27.750 --> 00:35:29.490
want to read one
float from that array.

00:35:29.490 --> 00:35:31.110
The first time we
access that float,

00:35:31.110 --> 00:35:34.500
the CPU is going to look in the
L1 cache, see if it's there.

00:35:34.500 --> 00:35:36.491
If it's not, it has to
go fetch it from the L2.

00:35:36.491 --> 00:35:38.240
If it's not there, it
has to go to the L3,

00:35:38.240 --> 00:35:39.720
and then finally to the RAM.

00:35:39.720 --> 00:35:43.560
And every time we have to fall
back to a higher level cache,

00:35:43.560 --> 00:35:45.210
we have to do an
expensive memory

00:35:45.210 --> 00:35:46.950
access that gets more
and more expensive

00:35:46.950 --> 00:35:48.210
as you go up the chain.

00:35:48.210 --> 00:35:51.040
So accessing the L1 takes
only a few nanoseconds.

00:35:51.040 --> 00:35:53.680
Accessing the L2 is going to
take 4 or 5 times that amount.

00:35:53.680 --> 00:35:55.346
Accessing the L3 is
going to be probably

00:35:55.346 --> 00:35:57.980
10 times slower, and so on.

00:35:57.980 --> 00:36:04.320
So I wrote a demo that allocates
a list of arrays of floats.

00:36:04.320 --> 00:36:08.490
Each array of floats is 4
floats, so it's 16 bytes.

00:36:08.490 --> 00:36:10.760
They're represented
by the red lines here.

00:36:10.760 --> 00:36:13.405
And I built a benchmark
basically using that.

00:36:13.405 --> 00:36:15.030
I'm just going to
run some computations

00:36:15.030 --> 00:36:17.120
over those arrays of floats.

00:36:17.120 --> 00:36:19.890
So if I look at all those arrays
of floats, one after the other,

00:36:19.890 --> 00:36:22.350
in the loop, this is what it's
going to look like in RAM.

00:36:22.350 --> 00:36:25.140
All the arrays are
neatly stacked together

00:36:25.140 --> 00:36:27.070
next to one another in RAM.

00:36:27.070 --> 00:36:29.730
And I'm using a
width of 64 bytes

00:36:29.730 --> 00:36:32.840
here for a reason that we're
going to see in a minute.

00:36:32.840 --> 00:36:34.926
Then I wrote a very
simple algorithm.

00:36:34.926 --> 00:36:36.050
So I go through the arrays.

00:36:36.050 --> 00:36:37.110
That takes four of them.

00:36:37.110 --> 00:36:37.860
I run some computations.

00:36:37.860 --> 00:36:40.240
It doesn't really matter what
computations I'm running.

00:36:40.240 --> 00:36:41.950
And let's see what
happens from memory.

00:36:41.950 --> 00:36:45.360
So when we access the first
float array in our list,

00:36:45.360 --> 00:36:47.670
it's not anywhere in our caches.

00:36:47.670 --> 00:36:51.510
It's in the RAM, but it's not
in the L1 or the L2 or the L3.

00:36:51.510 --> 00:36:54.360
So we're going to go fetch
it and put it in the L1.

00:36:54.360 --> 00:36:56.070
But one optimization
that CPUs have

00:36:56.070 --> 00:36:57.780
is that when you need
1 byte of memory,

00:36:57.780 --> 00:36:59.405
they're not going to
fetch only 1 byte.

00:36:59.405 --> 00:37:01.260
They're going to fetch
64 bytes at a time.

00:37:01.260 --> 00:37:03.390
So by finishing the
first array, we actually

00:37:03.390 --> 00:37:05.890
fetch the next three
arrays at the same time.

00:37:05.890 --> 00:37:08.520
So then when I want
to read those arrays,

00:37:08.520 --> 00:37:12.225
nothing happens because they're
already in the L1 cache.

00:37:12.225 --> 00:37:13.530
So this is pretty efficient.

00:37:13.530 --> 00:37:15.060
Then we run our computation.

00:37:15.060 --> 00:37:18.540
Now in my test app, I've
modified the initialization

00:37:18.540 --> 00:37:22.500
of the arrays so that I allocate
other stuff between each array.

00:37:22.500 --> 00:37:24.300
And I'm doing this to
basically replicate

00:37:24.300 --> 00:37:27.169
what happens when your garbage
collector moves things around,

00:37:27.169 --> 00:37:28.710
or you have
fragmentation in the app,

00:37:28.710 --> 00:37:30.543
if you do your allocations
over the lifetime

00:37:30.543 --> 00:37:31.530
of the application.

00:37:31.530 --> 00:37:33.660
For any number of reasons
that we've seen before,

00:37:33.660 --> 00:37:36.690
your locations won't be neatly
next to one another in RAM.

00:37:36.690 --> 00:37:40.410
So here I'm representing this
with a bunch of gray lines.

00:37:40.410 --> 00:37:41.970
So if you run the
algorithm again,

00:37:41.970 --> 00:37:43.980
we go fetch our first array.

00:37:43.980 --> 00:37:46.230
But instead of
fetching the other data

00:37:46.230 --> 00:37:47.856
that we want, we
fetch that great data,

00:37:47.856 --> 00:37:49.563
stuff that we don't
even know what it is,

00:37:49.563 --> 00:37:51.070
but it's going to
be put in the L1.

00:37:51.070 --> 00:37:53.610
So then when we want the next
array, it's not in the L1,

00:37:53.610 --> 00:37:55.680
and we have to go back
to memory and get it,

00:37:55.680 --> 00:37:57.460
and so on, and so on.

00:37:57.460 --> 00:37:59.340
But again, we're running
the same algorithm.

00:37:59.340 --> 00:38:00.756
It's just now we
have to do more--

00:38:00.756 --> 00:38:02.490
the CPU has to do more work.

00:38:02.490 --> 00:38:07.210
And we can recreate the same
thing by spacing out our arrays

00:38:07.210 --> 00:38:10.900
even more so that we won't find
the arrays in the L2 or the L3,

00:38:10.900 --> 00:38:13.740
and we can force the CPU to
do even more and more work.

00:38:13.740 --> 00:38:17.080
So if we run those different
variants of the algorithm--

00:38:17.080 --> 00:38:18.961
where again all we
did was change the way

00:38:18.961 --> 00:38:19.960
we allocate the objects.

00:38:19.960 --> 00:38:21.760
We're running the exact
same computations.

00:38:21.760 --> 00:38:26.530
When everything is neatly
store stored together in RAM,

00:38:26.530 --> 00:38:29.530
the algorithm takes about,
I think, 150 milliseconds

00:38:29.530 --> 00:38:30.940
on the Pixel 3.

00:38:30.940 --> 00:38:32.720
So that's the no thrash.

00:38:32.720 --> 00:38:35.330
And when I space out the
allocation so that we confine

00:38:35.330 --> 00:38:37.330
the data we want in
the L1, certainly we're

00:38:37.330 --> 00:38:38.560
almost twice as slow.

00:38:38.560 --> 00:38:40.580
We're running the same
exact computations.

00:38:40.580 --> 00:38:44.560
But the CPU is just busy
going to fetch data in RAM.

00:38:44.560 --> 00:38:46.270
And if I space out
the locations even

00:38:46.270 --> 00:38:48.820
more so that we confine
the data in the L2,

00:38:48.820 --> 00:38:50.800
now we are over
five times slower.

00:38:50.800 --> 00:38:53.060
Again, same exact algorithm.

00:38:53.060 --> 00:38:55.570
So if you write benchmarks--
and that's very good,

00:38:55.570 --> 00:38:57.220
you should probably do that--

00:38:57.220 --> 00:38:59.020
be very careful.

00:38:59.020 --> 00:39:01.054
Be aware of the fact
that the numbers you're

00:39:01.054 --> 00:39:02.470
going to get in
your benchmark may

00:39:02.470 --> 00:39:04.270
be very different than
the numbers you're

00:39:04.270 --> 00:39:10.370
going to get in the actual app
running on your users' devices.

00:39:10.370 --> 00:39:14.527
Yeah, you are truly benchmarking
the super access patterns.

00:39:14.527 --> 00:39:15.610
And with that, we're done.

00:39:15.610 --> 00:39:16.804
We have six seconds left.

00:39:16.804 --> 00:39:18.220
CHET HASSE: Very
important thing--

00:39:18.220 --> 00:39:20.410
if you are interested in
what we talked about today,

00:39:20.410 --> 00:39:21.580
there is a deeper
version of this

00:39:21.580 --> 00:39:23.740
as well as a lot of the
runtime improvements in ART

00:39:23.740 --> 00:39:26.539
over time by liaison
engineers on the ART team.

00:39:26.539 --> 00:39:27.580
So please check that out.

00:39:27.580 --> 00:39:29.621
It's at the same time as
the fireside chat, which

00:39:29.621 --> 00:39:31.120
I think is at 11:10.

00:39:31.120 --> 00:39:33.490
So please go see
that talk as well.

00:39:33.490 --> 00:39:34.674
And that's it.

00:39:34.674 --> 00:39:35.590
ROMAIN GUY: Thank you.

00:39:35.590 --> 00:39:36.790
[APPLAUSE]

00:39:36.790 --> 00:39:40.740
[MUSIC PLAYING]

