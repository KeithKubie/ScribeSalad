WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.250
&gt;&gt; SCHWARZ: All right. Well, let's get started.
Hi everyone I'm Don Schwarz. This is Toby

00:00:07.250 --> 00:00:13.690
Reyelts. And we're here today to talk to you
about Java support for App Engine. So, the

00:00:13.690 --> 00:00:16.440
goal here is really to bring you up to speed
for all of the new features and improvements

00:00:16.440 --> 00:00:20.259
that we've made over the--little over a year
since we launched Java support. Before we

00:00:20.259 --> 00:00:24.600
get started, I just want to remind everyone
that you can go to this URL and view live

00:00:24.600 --> 00:00:28.649
session notes and you can ask and vote on
questions on Google Wave. All right, so here's

00:00:28.649 --> 00:00:33.160
what you can expect from our talk today. We're
going to start with just some quick statistics,

00:00:33.160 --> 00:00:40.190
a quick over view of how we've grown over
the course of the year. And then we're going

00:00:40.190 --> 00:00:44.050
to spend most of the time doing a demo and
introducing a demo and doing a deep dive into

00:00:44.050 --> 00:00:48.149
the code after you guys see it. And then we'll
talk about some additional improvements we

00:00:48.149 --> 00:00:56.399
made including some behind the scenes up--improvements
to performance and compatibility. So we now

00:00:56.399 --> 00:01:02.780
host over 100,000 Java applications on App
Engine. So this is primarily web apps but

00:01:02.780 --> 00:01:08.900
we also have backends for Android and iPhone
apps. We have OpenSocial apps, Facebook apps,

00:01:08.900 --> 00:01:13.560
Wave Robots, Chat Bots, et cetera. And that's
approximately one third of all App Engine

00:01:13.560 --> 00:01:17.090
apps. So, you know, I think that's pretty
good evidence that when you consider that

00:01:17.090 --> 00:01:21.100
Python had--about a year had start on us,
both languages are very important to us and

00:01:21.100 --> 00:01:30.200
grow it at a pretty steady rate. We serve
thousands of hits per second in a pretty much

00:01:30.200 --> 00:01:33.200
steady state. But we also have a number of
applications with very spiky traffic patterns.

00:01:33.200 --> 00:01:36.880
So, the example you see here is something
called Gigya Socialize which is something

00:01:36.880 --> 00:01:41.829
we've highlighted on our blog in the past
and they do basically a chat service that

00:01:41.829 --> 00:01:47.590
is often advertised in television advertisements.
So, they have very spiky traffic. I mean,

00:01:47.590 --> 00:01:51.320
what you see here is actually a graph taken
from their admin console that shows them ramping

00:01:51.320 --> 00:01:55.350
from basically no traffic up to about 1,600
hits per second over the course in just an

00:01:55.350 --> 00:01:59.539
hour or two. So, you know, I think that's
really good evidence that we can absorb large

00:01:59.539 --> 00:02:03.320
traffic spikes on your behalf which is one
of the big benefits of App Engine.

00:02:03.320 --> 00:02:13.930
&gt;&gt; REYELTS: So, Don and I spent--is this thing
on? There we go. So, Don and I spend a lot

00:02:13.930 --> 00:02:19.300
time trying to figure out, what was the best
way to introduce all of these new features

00:02:19.300 --> 00:02:25.690
that have kind of accumulated in App Engine
over the last year. And one thing we learn

00:02:25.690 --> 00:02:31.100
from our session--our I/O session last year
was that people really enjoy, you know, good

00:02:31.100 --> 00:02:38.720
fun demos and getting deep into the code of
those demos. So, we decided, you know, why

00:02:38.720 --> 00:02:44.290
mess with success? So, we're going to do the
same thing this year. We've got a game that

00:02:44.290 --> 00:02:49.810
we're going to have you all hopefully participate
in if the Wi-Fi cooperates. And we're going

00:02:49.810 --> 00:03:04.800
to take a deep dive into that code. So, let's
pull that up. We have Wave questions already.

00:03:04.800 --> 00:03:17.310
So this is a game we like to call Dance Dance
Robot. And kind of the way this game works

00:03:17.310 --> 00:03:24.320
is that, you have this Simon robot. It's kind
of a mix between Simon says and between memory.

00:03:24.320 --> 00:03:29.800
And this robot, right over here, he makes
dance steps. He moves his limbs and your goal

00:03:29.800 --> 00:03:35.930
as a player is to do--is to repeat the same
dance steps in the same order. As you can

00:03:35.930 --> 00:03:45.040
see the URL--the URL here is "dance-dance-robot.appspot.com".
So, if I come in here, I'll just enter my

00:03:45.040 --> 00:03:51.160
name and then join the game. So, when I do
that, it goes and it looks for a game. Looks

00:03:51.160 --> 00:03:57.220
like a bunch of people have already joined
in with me. So, you can see that it dynamically

00:03:57.220 --> 00:04:02.510
picks up other players. There are a max of
like eight players in the game. And so here,

00:04:02.510 --> 00:04:10.820
the robot is doing its dance. So, I'll do
the dance too. And then if you do it right,

00:04:10.820 --> 00:04:15.680
you get a happy robot and you get some points.
If you do it wrong, well we can kind--we can

00:04:15.680 --> 00:04:20.680
kind of see Don up there. His robot's really
sad. Don didn't get the dance right. So, we'll

00:04:20.680 --> 00:04:32.240
do a few more
of these rounds. One really cool thing about

00:04:32.240 --> 00:04:37.879
this is, this is real-time push, what you're
seeing, right. As everybody else in the audience

00:04:37.879 --> 00:04:43.710
and Don here and everybody is making their
moves, those moves are being broadcast to

00:04:43.710 --> 00:04:47.379
everybody in the game. And some of you may
actually be playing the game and you're in

00:04:47.379 --> 00:04:56.490
a different game, right, you'll see other
participants in the audience playing with

00:04:56.490 --> 00:04:59.320
you. Oops. I wasn't paying attention. I just
missed that one too. As the rounds go on,

00:04:59.320 --> 00:05:10.710
the game gets harder, we add more dance steps
and things like that go on. I'm really bad

00:05:10.710 --> 00:05:15.050
at this. I cant--I can't play and talk at
the same time. I don't think I'm going to

00:05:15.050 --> 00:05:22.539
win this. Looks like--looks like maybe Brandy
is going to beat us all. We actually tried

00:05:22.539 --> 00:05:27.330
to set this up for the demos that only took
five rounds but I guess we didn't quiet get

00:05:27.330 --> 00:05:28.780
that right either.
&gt;&gt; Anyone else can just to do it.

00:05:28.780 --> 00:05:43.050
&gt;&gt; REYELTS: Yeah. Somebody else beat us to
it and started the 10-round game. So, you

00:05:43.050 --> 00:05:48.030
just have to suffer through it. Sorry. I could
talk a little bit more about this actually.

00:05:48.030 --> 00:05:56.349
So, Dance Dance Robot is actually GWT app,
a Google Web Toolkit app. And of course, the

00:05:56.349 --> 00:06:04.449
back end is App Engine. And part of the push
API, I was talking about earlier, is a new

00:06:04.449 --> 00:06:11.400
API that we've actually just released. In
fact, we just got it out to production servers

00:06:11.400 --> 00:06:16.770
very, very recently. So, we were up to the
last minute making sure--making sure this

00:06:16.770 --> 00:06:21.129
all would actually go for I/O. So I'm very
happy to see like alarms and bells and whistles

00:06:21.129 --> 00:06:54.979
aren't going off here. We're almost done,
two more rounds. So, Don told me while I was--while

00:06:54.979 --> 00:07:06.999
I was working on some of the icons, some of
that he had first come with, I drew the sad

00:07:06.999 --> 00:07:10.249
robot, the sad android and he told me, man
that sad android doesn't look as it is sad,

00:07:10.249 --> 00:07:24.100
it looks creepy. But we didn't have a lot
of time to change that unfortunately. We also

00:07:24.100 --> 00:07:27.920
had a big--we had a big tiff with the android
guys, they were like, "Man, we love that.

00:07:27.920 --> 00:07:31.389
You're using our android logo and that's really
awesome." But you cant call the game Dance

00:07:31.389 --> 00:07:39.189
Dance droid because Lucas will get really
upset and you cant call a Dance Dance Android

00:07:39.189 --> 00:07:47.111
because then our partners will get really
upset too. So, we lost two of our favorite

00:07:47.111 --> 00:07:50.599
game names. All right, so, the 10 rounds are
over and you can see what happens at the end

00:07:50.599 --> 00:07:55.029
of the these 10 rounds like the scores have
been calculating and everything like that.

00:07:55.029 --> 00:08:01.029
And what's happening on the server is, we're
generating the award and so I got fifth place

00:08:01.029 --> 00:08:06.249
which is not so great. You guys in the audience,
so, who--I think Britney was first place or

00:08:06.249 --> 00:08:16.719
something like that. There we go, that was
our demo. And now, we'll actually jump into

00:08:16.719 --> 00:08:21.319
the code for this. I'll take applause if anybody
wants to applause. Thank you very much. So,

00:08:21.319 --> 00:08:27.189
like I was saying, this is a--this is a Google
Web Toolkit application. Actually, I take

00:08:27.189 --> 00:08:30.279
it back. I'm going to jump in to slides first
and talk about the channel service. How about

00:08:30.279 --> 00:08:33.220
that? And I'll give you guys just a little
bit more background. We'll talk about the

00:08:33.220 --> 00:08:38.520
design and things like that first, that'll
be a better order, I think. So, here's the

00:08:38.520 --> 00:08:43.040
game design. As I was saying, it's Google
Web Toolkit app. We actually use two transports

00:08:43.040 --> 00:08:50.270
to talk--to talk to App Engine. The first
is, typical GWT RPC. And GWT RPC is just XML

00:08:50.270 --> 00:08:55.980
HTTP request to the server. We make all our
outgoing request to the server via that transport.

00:08:55.980 --> 00:09:00.690
The second transport is a channel service
and that's a new service I was talking about

00:09:00.690 --> 00:09:06.840
that is a push-based service, so all of the
messages from App Engine that we want to push

00:09:06.840 --> 00:09:12.880
to all of the different players during the
game that goes across the channel service.

00:09:12.880 --> 00:09:16.690
Oops, wrong direction. So, on the back end
we make heavy use of the task queue service.

00:09:16.690 --> 00:09:22.660
And the task queue service is--it's been around
for like six months or so new since last year

00:09:22.660 --> 00:09:27.140
and basically what that lets us do is that--it
lets us run a lot of background game logic

00:09:27.140 --> 00:09:32.330
asynchronously. So anytime in our code like
on the server where you would write code and

00:09:32.330 --> 00:09:37.970
you would want to block for a response or
just wait. Instead we, you know, fire off

00:09:37.970 --> 00:09:44.640
a task right, and do that in the background.
And then we make use of three different storage

00:09:44.640 --> 00:09:51.490
services on the back end. So, there's a Datastore
and Memcache and Blobstore. And Datastore

00:09:51.490 --> 00:09:54.910
and Memcache, we use the skies and tandem
which is typical, we store our games state

00:09:54.910 --> 00:10:00.530
in their and then we cache it additionally
in memcache. We talked to the Datastore via

00:10:00.530 --> 00:10:05.820
JDO. There are a lot of ways you can talk
to it, you know, JDO, JPA. There are like

00:10:05.820 --> 00:10:11.570
three different third party libraries out
there that are pretty prominent like objectify

00:10:11.570 --> 00:10:18.670
and simple DS and twig. We use HTTP sessions
and those--those are transparently backed

00:10:18.670 --> 00:10:23.491
by both of those guys. And then--and then
there's Blobstore and the way we use that

00:10:23.491 --> 00:10:28.060
is that, is that award certificate you saw
in the end was dynamically generated. So that's

00:10:28.060 --> 00:10:33.370
kind of like a large image or a, you know,
a couple large images that we store and that

00:10:33.370 --> 00:10:39.440
we store in Blobstore and then we dynamically
scale it to the size of your screen and render

00:10:39.440 --> 00:10:47.020
the place and the player text over that in
Blobstores. So, in general, the point of Blobstores

00:10:47.020 --> 00:10:54.070
that you can store, really large objects and,
you know, I receive them and serve them out.

00:10:54.070 --> 00:10:58.560
So let me talk more about the channel service
since that's really like--a really new feature.

00:10:58.560 --> 00:11:05.400
So its push messaging and it's over HTTP but
it's actually bidirectional. So, if you've

00:11:05.400 --> 00:11:13.830
ever heard of like hanging gets or like a
comet or even like WebSockets is coming along,

00:11:13.830 --> 00:11:19.050
right. You're pretty familiar with this style
of communication. In fact I think we have

00:11:19.050 --> 00:11:25.430
plans to actually make the channel service
interrupt with WebSockets later. The way this

00:11:25.430 --> 00:11:31.370
works on the server is we have a channel service
API and that allows you to send messages and

00:11:31.370 --> 00:11:36.370
then you receive messages from clients in
a web hook. So, the same way that you would

00:11:36.370 --> 00:11:42.930
get like email messages or that you'd receive
XMPP messages. You get those on the web hook

00:11:42.930 --> 00:11:48.490
with the channel service too. On the client
side what we have is a JavaScript library.

00:11:48.490 --> 00:11:54.180
And so, it's a web app, you take this JavaScript
library in your web app and has an API that

00:11:54.180 --> 00:11:59.450
use. And it looks--it looks pretty similar
to the server API but instead of having a

00:11:59.450 --> 00:12:03.751
web hook which doesn't make any sense in the
client, you have JavaScript call backs to

00:12:03.751 --> 00:12:10.550
receive messages from the server. And finally,
the channel service is built on a Gmail chat

00:12:10.550 --> 00:12:15.751
client which, you know, which runs Google--which
runs on Google talk and the benefit of that

00:12:15.751 --> 00:12:22.010
is that you know, it's already scalable, it's
already well tested and so you're building,

00:12:22.010 --> 00:12:29.580
you know, your code on services that have
been around for a while. So, here's the server

00:12:29.580 --> 00:12:35.280
API with a funky identity comment. This is
what you had programmed to on the server side.

00:12:35.280 --> 00:12:40.790
There are three basic functions here. The
first thing you would do to communicate with

00:12:40.790 --> 00:12:46.300
clients is to create a channel. And you do
that by specifying a unique application key.

00:12:46.300 --> 00:12:51.440
And that application key just--is just an
identifier, you come with that, identifies

00:12:51.440 --> 00:12:56.080
that channel. Once you--once you passed that
in and you get a response, the service has

00:12:56.080 --> 00:13:03.090
created a channel for you and it returns an
ID that is a client side channel ID. So that

00:13:03.090 --> 00:13:11.570
ID is what you will pass to the client to
your JavaScript app, right. To have it connect

00:13:11.570 --> 00:13:17.070
to the channel. After you've created the channel,
then you can send messages on the channel.

00:13:17.070 --> 00:13:22.070
You pass the channel message object and the
constituent parts of this are the application

00:13:22.070 --> 00:13:26.280
key that you specified to create the channel
in the first place. And then, and then the

00:13:26.280 --> 00:13:31.450
actual message contents that you want to push
to the client. Now, the channel service only

00:13:31.450 --> 00:13:39.330
let's you send strings directly, like UTF-8
encoded strings. So you can't by defaults

00:13:39.330 --> 00:13:46.570
and vary--like send objects over the channel
service instead of string data. And finally,

00:13:46.570 --> 00:13:51.820
you receive messages, like I said on a WebHook
in the channels server--for the channel service.

00:13:51.820 --> 00:13:56.230
And what you have to do is you have to like
parse the data out of the HttpServletRequest.

00:13:56.230 --> 00:14:01.470
Similar--again, similar to the way you would
do that for email or whatever, so that's what

00:14:01.470 --> 00:14:06.980
the parse message function is for. Now, let's
talk something about the Client API. Like

00:14:06.980 --> 00:14:11.870
I said before, it's an implemented in JavaScript,
but we also plan on providing Java wrapper

00:14:11.870 --> 00:14:18.811
around that for Google Web Toolkit applications.
And here is some sample code of what--of what

00:14:18.811 --> 00:14:23.950
the API looks like. First, you create a channel,
and you specify that channel ID that I talked

00:14:23.950 --> 00:14:28.230
about that was return to you on the server.
So, you get a channel object back and then

00:14:28.230 --> 00:14:33.840
you open that channel object, you get a socket.
And that socket is how you communicate on

00:14:33.840 --> 00:14:41.220
that channel. There's an on Open-Callback,
that callback is called once the channel has

00:14:41.220 --> 00:14:44.910
fully been established, once your communication
has been established there. So you can act

00:14:44.910 --> 00:14:49.110
on it at that point. And then there's the
on message callback and that's called every

00:14:49.110 --> 00:14:56.350
single time the server pushes, you know, pushes
a message to your client and the "event.data"

00:14:56.350 --> 00:15:01.610
there is the string data for that message.
And then finally, sending a message is really

00:15:01.610 --> 00:15:06.840
simple you just push a string in there and
then boom it goes to the server. I guess I

00:15:06.840 --> 00:15:14.300
could have highlighted those since I was talking
about them. So the Task Queue Service, this

00:15:14.300 --> 00:15:17.160
is kind of new. Like I said, it's about six
months old but we'll go quickly over some

00:15:17.160 --> 00:15:24.320
of the features. It allows you to do work
in the background asynchronously and dynamically,

00:15:24.320 --> 00:15:30.590
so instead of like--you can create like task
queues on the fly and tasks on the fly in

00:15:30.590 --> 00:15:37.330
response to whatever. You can have up to 50
requests per second on tasks and--my direction

00:15:37.330 --> 00:15:44.390
was wrong in that slide. This works on the
DevAppServer. This is fairly new. What you

00:15:44.390 --> 00:15:49.720
are able to, is you're able to take--you're
able to schedule tasks like you would in a

00:15:49.720 --> 00:15:54.630
real server, and it'll automatically execute
which is pretty nice. So you get the same

00:15:54.630 --> 00:16:00.790
behavior as you would in prod. You are also
able to see the tasks and execute them manually,

00:16:00.790 --> 00:16:08.560
and that will also help you out in your testing.
Something else that's also fairly new is that

00:16:08.560 --> 00:16:13.220
tasks can participate in data storage transactions.
And so what this means is that when you go

00:16:13.220 --> 00:16:19.070
to add a task in a queue, if you have it participating
in the transaction, then that task won't get

00:16:19.070 --> 00:16:26.160
executed, for example, if the transaction
gets rolled back. Okay, so before we go and

00:16:26.160 --> 00:16:35.790
talk about the Blobstore Service, let's dive
in to the code of the application that actually

00:16:35.790 --> 00:16:43.540
makes use of the channel service. So, I talked
about being a GWT application. And we have

00:16:43.540 --> 00:16:48.060
our RPC, our GWT RPC service right here, and
it's called the Game Service. And the Game

00:16:48.060 --> 00:16:53.550
Service has a few methods. There was the original
login screen we saw, and then we have something

00:16:53.550 --> 00:16:59.851
that's a confirm login. So after we've established
communication on our channel, then the client

00:16:59.851 --> 00:17:04.680
confirms that they're ready to receive messages.
And then every time you take a step the client

00:17:04.680 --> 00:17:09.529
makes a call to the server to let you know
that steps has been taken. So, let's dive

00:17:09.529 --> 00:17:15.179
in to the implementation of login here. So,
you can see that we go in, reserve a game,

00:17:15.179 --> 00:17:16.839
and then we're doing some work here with the
HTTP session and so on. And we're starting

00:17:16.839 --> 00:17:26.629
a transaction and then adding you as a player
to the game. And let's get a little bit further

00:17:26.629 --> 00:17:31.399
down here, so we can talk about the channel
service. So right here, we have a--just a

00:17:31.399 --> 00:17:37.669
small little abstraction. We call the push
server. And if we follow into the create channel

00:17:37.669 --> 00:17:42.090
call--and we pass a player in here. You can
see that we're just--we're just using the

00:17:42.090 --> 00:17:48.830
same channel service API that went into the
slide just a moment ago, and calling that

00:17:48.830 --> 00:17:53.210
create channel function. And we're just passing
in a key, that's the player key. So basically

00:17:53.210 --> 00:17:59.429
each player gets their own channel, right.
So, that's all really pretty simple. And then

00:17:59.429 --> 00:18:03.470
the channel ID that comes back from there
is returned from this function. And so if

00:18:03.470 --> 00:18:10.600
we come back up, there it is again. And then
in our login results, what we do is we return

00:18:10.600 --> 00:18:15.840
that channel ID. So these login results go
back to the client and the client has that

00:18:15.840 --> 00:18:21.929
channel ID that it can establish communication
on. So if we--let's follow into the client

00:18:21.929 --> 00:18:33.529
code and see its side of that. So this is
like the main classes. This is kind of--it's

00:18:33.529 --> 00:18:37.190
the entry point for the GWT application. And
there is actually a fine game--a fine game

00:18:37.190 --> 00:18:43.690
panel. And this is the login screen basically.
So, after login successfully happens, it calls

00:18:43.690 --> 00:18:49.350
back into the main panel, and it calls this
login complete function. And we see the--basically,

00:18:49.350 --> 00:18:54.429
about the first thing we do here is we create
a client side channel, right? And it's using

00:18:54.429 --> 00:19:00.983
that channel ID that came from the login results
that was return from the server. So, this

00:19:00.983 --> 00:19:05.730
API looks a little bit different from--we
saw that was a JavaScript API before, but

00:19:05.730 --> 00:19:12.639
this is Java code. Well, let's dive into the
guts of this create channel call. So what's

00:19:12.639 --> 00:19:18.470
going here is this is taking advantage of
GWT's JavaScript Native Interface functionality.

00:19:18.470 --> 00:19:25.450
So this is a JavaScript right here, which
looks like the code we saw. It's just creating

00:19:25.450 --> 00:19:31.270
a new channel and just passing in the ID.
And so, it's really just a thin wrapper. And

00:19:31.270 --> 00:19:38.950
if we looked at the other classes related
to this like--let's see, like the socket listener,

00:19:38.950 --> 00:19:44.049
and things like that. Well, socket listener
doesn't have any code. That's not useful.

00:19:44.049 --> 00:19:49.070
But in general, all of these are just a really
thin wrapper around the JavaScript API, so

00:19:49.070 --> 00:19:51.350
just straightforward. So, what we do here
on a "channel.open" is we're establishing

00:19:51.350 --> 00:19:58.880
a communication. We're establishing communication
a socket when we pass in the socket listener.

00:19:58.880 --> 00:20:04.970
And there are two callbacks on the socket
listener. The first is on open, here. And

00:20:04.970 --> 00:20:10.781
the second is on message. And like we said
on open was a callback that occurred when

00:20:10.781 --> 00:20:19.779
the channel communication was established.
So when we know that the channel is established,

00:20:19.779 --> 00:20:24.200
we call an RPC to the server. This is the
confirm login, so we're making a callback

00:20:24.200 --> 00:20:28.710
to the server letting it know, hey, the channel's
up. We're ready to receive messages from the

00:20:28.710 --> 00:20:34.929
server, right. And then the server response,
and sends a--and sends us a bunch of messages

00:20:34.929 --> 00:20:40.559
that tells us who's--which players are already
in the game. So that's what's going on right

00:20:40.559 --> 00:20:45.820
there. And then on message, this is the other
callback that's called every single time the

00:20:45.820 --> 00:20:51.119
server pushes a message to us, right? And
I talked about this--just being a string.

00:20:51.119 --> 00:20:55.600
And we can see that that's what I'm receiving
here is a string. But we're doing something

00:20:55.600 --> 00:21:01.110
pretty tricky and neat here, which is that
we're taking advantage of GWT serialization

00:21:01.110 --> 00:21:08.779
to encode objects into strings. So, this is
a little bit of magic, a serialization stream

00:21:08.779 --> 00:21:14.740
reader. There's a corresponding serialization
stream writer on the server side. And that

00:21:14.740 --> 00:21:17.680
encodes the object into a string and then
we push that string on the channel API, and

00:21:17.680 --> 00:21:25.249
then we decode it here. And so you can see
what we get beck is this message object. And

00:21:25.249 --> 00:21:31.720
if we follow into the message objects, you
can see it has a--let me turn-on something

00:21:31.720 --> 00:21:40.779
here, so you can see on the left-hand side;
auto-scroll--to source and from source. There

00:21:40.779 --> 00:22:00.019
we go. So, you can see that there are actually
several different kinds of messages here and

00:22:00.019 --> 00:22:02.659
these are all subtypes. And we get the correct,
you know, subtype that was serialized across

00:22:02.659 --> 00:22:06.899
the channel. Somebody is trying to call us.
So, that's basically it for the channel service.

00:22:06.899 --> 00:22:12.840
Let me go back to the slides here. I talked
about the Task Queue Service. So, I think

00:22:12.840 --> 00:22:16.159
we're ready to talk about Blobstore.
&gt;&gt; [INDISTINCT]

00:22:16.159 --> 00:22:20.820
&gt;&gt; REYELTS: Yes, let me do that. That's a
great idea. Before we go on to Blobstore,

00:22:20.820 --> 00:22:25.129
let me go back into the IDE here and talk
a little bit about the code around the Task

00:22:25.129 --> 00:22:29.900
Queue Service. So let's go back into the login,
the implementation of that login method. So

00:22:29.900 --> 00:22:36.059
we saw here that we're creating a channel
and things like that. Well, here's--what Don

00:22:36.059 --> 00:22:42.419
was saying is that deferred third party library,
called the deferred API. And this is the library

00:22:42.419 --> 00:22:49.980
that's written by Vince Bonfanti, I hope I'm
not mangling his name, which simplifies a

00:22:49.980 --> 00:22:54.110
lot of the Task Queue APIs. So if you're doing
some simple stuff with Task Queues, it's a

00:22:54.110 --> 00:22:59.120
great API. We're actually considering it for
inclusion in the SDK. We'll have to do some

00:22:59.120 --> 00:23:05.080
code review and some tweaks. And we found
some bugs along the way but we hope that it

00:23:05.080 --> 00:23:10.529
will make it. So, if we follow through to
this API. We can see--we can see that's its

00:23:10.529 --> 00:23:17.549
pretty simple here. There's a defer method
and you pass a task and some options. Well,

00:23:17.549 --> 00:23:23.279
let's ignore the options for now. Those aren't
really important, but the way this works is

00:23:23.279 --> 00:23:29.320
that deferrable is an interface which is the
single callback, do task. So, this is where

00:23:29.320 --> 00:23:34.980
you would do work in your task, right. You
just implement this interface and you do your

00:23:34.980 --> 00:23:41.919
work. And I can actually show you that. So
we have send new player as an example of a

00:23:41.919 --> 00:23:48.840
deferrable. So, when we defer in the instance
of the send new player objects, Vince's library,

00:23:48.840 --> 00:23:53.549
the deferred library does all the work of
actually creating a new task and adding it

00:23:53.549 --> 00:23:57.889
on to the task queue and it actually like
ends up serializing these objects. Like it

00:23:57.889 --> 00:24:03.940
ends up serializing the send new player object
in Memcache or even in the Datastore if necessary,

00:24:03.940 --> 00:24:10.539
and then and then when the task executes on
the task queue, he calls back through to our

00:24:10.539 --> 00:24:14.289
object and calls the do--in the do task method.
And so in here, you can see we're just getting

00:24:14.289 --> 00:24:19.720
a list of all the players in the game and
then--and then just sending them--sending

00:24:19.720 --> 00:24:26.499
a message out with those players. And then,
you know, we have a few more examples of those

00:24:26.499 --> 00:24:31.299
tasks here. Like dance begin where we do significant
amount of work, and then and then the start

00:24:31.299 --> 00:24:36.059
game task. I think that's a pretty good coverage
there. Oops.

00:24:36.059 --> 00:24:43.139
&gt;&gt; SCHWARZ: I'll set you up the bomb. There
we go. Okay, so now let's talk a little bit

00:24:43.139 --> 00:24:47.750
about the Blobstore Service. So Toby mentioned
earlier that the certificate image thing you

00:24:47.750 --> 00:24:53.190
saw at the end was powered by Blobstore in
the image API. So, let's talk a little bit

00:24:53.190 --> 00:24:58.730
more about what Blobstore is. I know a lot
of you are probably familiar with that. I

00:24:58.730 --> 00:25:00.639
think we launched it back in December. But
it basically allows you to upload and stream

00:25:00.639 --> 00:25:07.840
large files. So, in App Engine, we tend to
pass request and responses around as atomic

00:25:07.840 --> 00:25:11.049
units, and that's one of the reasons that
those are limited to ten megabytes right now,

00:25:11.049 --> 00:25:15.769
but we know that's on and off. We know occasionally
you need to be able to have your users upload

00:25:15.769 --> 00:25:20.450
large files and to stream them back to users.
So we basically implemented a separate infrastructure

00:25:20.450 --> 00:25:25.279
that handles streaming uploads and downloads
specifically tuned for large files. So the

00:25:25.279 --> 00:25:31.399
way this works is that you get a one time
use URL for uploading and you just submit

00:25:31.399 --> 00:25:35.840
an HTML form with file elements attached to
it, and we handle all of the upload and persistence

00:25:35.840 --> 00:25:39.160
of that blob and tracking blobs over time.
And we give you a callback whenever a blob

00:25:39.160 --> 00:25:44.530
is at and that contains a reference to that
blob. So once you have a reference, you can

00:25:44.530 --> 00:25:51.720
either serve it back to users in a streaming
fashion or you can retrieve chunks of it a

00:25:51.720 --> 00:25:55.010
time and process it within your application
code. And finally, the image of API has been

00:25:55.010 --> 00:25:59.799
modified to take blobs as input data, so this
is very useful. For example, if you want users

00:25:59.799 --> 00:26:01.789
to upload profile pictures, you know, they
may have just taken it off the digital camera

00:26:01.789 --> 00:26:05.799
and not really of the sense for the fact that
it's a five megabyte image, this allows them

00:26:05.799 --> 00:26:11.619
to upload it Blobstore and then you can still
thumbnail it down to a reasonable size for

00:26:11.619 --> 00:26:14.900
storage in your application. So let's take
a quick look at the application code that

00:26:14.900 --> 00:26:23.580
actually implements this. If we pull up--so,
before we actually started this demo, I uploaded

00:26:23.580 --> 00:26:29.049
that initial template for the award certificate
at the end. That wasn't the one I was planning

00:26:29.049 --> 00:26:34.869
to use to be honest, but it works. And so,
I upload it through this admin only JSP. You

00:26:34.869 --> 00:26:39.120
can see here which is just really trivial.
All of this has an HTML form with the file

00:26:39.120 --> 00:26:42.559
element, the one App Engine. A specific point
here is that we're making this create upload

00:26:42.559 --> 00:26:47.679
URL API call to get the URL for it. And this
string we're passing here is the URL where

00:26:47.679 --> 00:26:54.989
we want to receive our callback. So if we
take a look at the server that actually implements

00:26:54.989 --> 00:27:00.370
that URL, you can see here that it's basically
just making another API call to get the uploaded

00:27:00.370 --> 00:27:04.440
blobs, this is getting the reference to the
blobs from the callback. There was just one

00:27:04.440 --> 00:27:08.389
of them attached to this name, and then we
basically have some boilerplate JDO code here

00:27:08.389 --> 00:27:14.340
which attaches it to a JDO entity and persist
it to a Datastore. And then finally at the

00:27:14.340 --> 00:27:19.100
end, it redirects you, you also have to redirect
at the end of the Blobstore callback. So,

00:27:19.100 --> 00:27:22.140
in this case we redirect to the server that
actually provides that back to the users for

00:27:22.140 --> 00:27:26.679
distinct purposes. But this is the same server
that's used to serve that in image up at the

00:27:26.679 --> 00:27:34.230
very end of the game. So if we take a look
at that, sort of lift--it's basically very

00:27:34.230 --> 00:27:39.159
simple, it's just querying that word object
back form JDO, it takes the blob reference

00:27:39.159 --> 00:27:43.740
out of it, here, and makes it into something
the image servers knows about, and then it

00:27:43.740 --> 00:27:48.659
makes a set of image API calls here. As we
can see that we're resizing the image to a

00:27:48.659 --> 00:27:52.389
reasonable size, and then were compositing
some other images on top of it. And what those

00:27:52.389 --> 00:27:57.399
other images actually are is the dynamic text
of your name and the place that you received.

00:27:57.399 --> 00:28:01.940
Now, the image API doesn't support rendering
of text at least right now. So what we did

00:28:01.940 --> 00:28:07.009
is we actually found an open source library
called light text, which is on Google code

00:28:07.009 --> 00:28:10.190
hosting, that was actually--I don't know if
it was specifically written with App Engine

00:28:10.190 --> 00:28:15.239
in mind but it's promoting that it's supported
on App Engine Java, and it emits a bitmap

00:28:15.239 --> 00:28:19.989
images for the text which is something that
the image API supports as its input source.

00:28:19.989 --> 00:28:25.470
So we were able to very simply render the
text into a bitmap and then composite that

00:28:25.470 --> 00:28:30.159
directly on top of our word template. And
then at the very end we just stream the data

00:28:30.159 --> 00:28:38.120
out to the user. It was just that simple to
build everything on the server side. Great.

00:28:38.120 --> 00:28:41.860
Oh, and actually I can show you--I can just
show you what that looks like here. So this

00:28:41.860 --> 00:28:48.600
was the server directly emitting an image
back to the browser, and it's pretty quick.

00:28:48.600 --> 00:28:55.490
Okay, so, let's go back to the slides here.
So we also made a--rolled out a diagnostic

00:28:55.490 --> 00:29:01.220
tool this year called App Stats, which makes
it very easy for you to profile API calls

00:29:01.220 --> 00:29:05.730
that are used in your application. So later
in the talk we're going to talk a little bit

00:29:05.730 --> 00:29:09.859
about loading requests and the work that we've
done to try to speed up loading requests.

00:29:09.859 --> 00:29:11.340
But putting loading request aside, the majority
of your time, unless you're a very CPU intensive

00:29:11.340 --> 00:29:16.570
application, is going to be spent in API calls,
so it's very important that you have transparency

00:29:16.570 --> 00:29:26.809
into what API calls you're making and you
can make tweaks to them. In last year's talk,

00:29:26.809 --> 00:29:30.779
I talk through the API calls that were involved--the
layers that were involved in an API call and

00:29:30.779 --> 00:29:34.100
pointed out kind of the one central piece
that all API calls flow through is a class

00:29:34.100 --> 00:29:39.769
called the API proxy. It will actually showed
you some sample code that installed in API

00:29:39.769 --> 00:29:46.120
proxy delegate that gets a call back whenever
an API call occurs and can make--can basically

00:29:46.120 --> 00:29:51.070
log data about it. Apps that's basically takes
this to a whole new level. We have a servlet

00:29:51.070 --> 00:29:55.769
filter that's very easy to install which manages
an API proxy delegate for you. It does all

00:29:55.769 --> 00:30:00.529
the hard work and it stores all the data to
memcache. And then we also provide a servlet

00:30:00.529 --> 00:30:06.249
that takes that data out of memcache and renders
it in a nice graphical way. So, we actually

00:30:06.249 --> 00:30:12.480
have apps that's installed on this game and
was running the whole time you guys were playing

00:30:12.480 --> 00:30:15.600
it, maybe some of you are still playing it,
I'm not sure. But if we bring up the servlet

00:30:15.600 --> 00:30:19.600
here for apps stats, we should be able to
go into one of these arbitrary requests and

00:30:19.600 --> 00:30:23.450
see what it's doing. That one's not terribly
interesting. It's just to make query, but

00:30:23.450 --> 00:30:28.369
most of this should be making several API
calls [INDISTINCT]. Yeah, okay, so there's

00:30:28.369 --> 00:30:36.080
where you can see where we made two channel
API calls and then a task queue call at the

00:30:36.080 --> 00:30:40.321
end. So you can see that in this case we spent
234 milliseconds out of 238 milliseconds in

00:30:40.321 --> 00:30:45.990
API calls that's sort of improves the point
I was making. We also track the request and

00:30:45.990 --> 00:30:50.950
response data and the call stack for each
of these API calls so you can get a little--dig

00:30:50.950 --> 00:30:59.580
a little deeper and find out what's really
going on. Okay, so, that's it for the demo,

00:30:59.580 --> 00:31:01.720
let's talk about some additional functionality
that we've had it over the course of the year.

00:31:01.720 --> 00:31:07.940
We made a number of Datastore improvements
that--probably one of the biggest ones is

00:31:07.940 --> 00:31:15.899
support for cursors which allow you to pick
up a query where you left off in the previous

00:31:15.899 --> 00:31:17.550
request, so that makes it very easy to page
through large data sets across requests. As

00:31:17.550 --> 00:31:22.130
part of this, we've dropped the thousand query
limit, so you can now--the only limit to how

00:31:22.130 --> 00:31:26.860
much data you can query is your overall request
deadline. We had a bulk ID allocation which

00:31:26.860 --> 00:31:31.320
makes it feasible to upload large interdependent
sets of data; our bulk imports will still

00:31:31.320 --> 00:31:35.850
take advantage of that. We also allow you
to choose eventual consistency over strong

00:31:35.850 --> 00:31:40.809
consistency for your queries. So if you can
tolerate still data, this allows you to have

00:31:40.809 --> 00:31:47.369
faster and more reliable queries. We track
and store statistics about you're Datastores,

00:31:47.369 --> 00:31:51.559
you're Datastore data. Primarily this is so
that we can give you more transparency in

00:31:51.559 --> 00:31:54.759
your admin console and to where your storage
code is going. But you can also query these

00:31:54.759 --> 00:32:00.360
things programmatically, so it's possible
to find out estimates of the total number

00:32:00.360 --> 00:32:06.519
of entities in your data store in constant
time. And a huge number of JDO and JPA improvements.

00:32:06.519 --> 00:32:09.539
If you tried it last year, and you ran into
this trouble, definitely try again it now,

00:32:09.539 --> 00:32:16.279
it's come a long way. We've made a number
of improvements to the URLFetch API, deadlines

00:32:16.279 --> 00:32:20.669
are now configurable. So, in addition to the
standard five second default deadline, you

00:32:20.669 --> 00:32:24.929
can now increase it up to ten seconds and,
you know, in the future we hope to increase

00:32:24.929 --> 00:32:32.590
that as well. And we added support for asynchronous
URLFetch API calls, so you can fetch up the

00:32:32.590 --> 00:32:33.590
ten URLs in parallel. We don't give you callbacks
when they finish, what we do is we have this

00:32:33.590 --> 00:32:40.570
future-based API that wraps around the eventual
result and you can either block or pull on

00:32:40.570 --> 00:32:45.190
it. And the infrastructure for this is just
general infrastructure that works for all

00:32:45.190 --> 00:32:49.169
APIs, but the URLFetch is the first API. We're
actually exposing this directly to user code,

00:32:49.169 --> 00:32:55.669
but we expect to do that more in the future.
Last year, we talked about how App Engine

00:32:55.669 --> 00:33:00.179
was especially well-suited for web applications,
but that we were going to add more support

00:33:00.179 --> 00:33:04.629
for WebHooks to make it more powerful in the
future and we definitely kept that promise.

00:33:04.629 --> 00:33:09.140
In addition to task queues, which we talked
about, we also have support for an XMPP APIs

00:33:09.140 --> 00:33:14.570
so you can send and receive messages, you
can receive incoming email. And we're very

00:33:14.570 --> 00:33:19.429
happy that the wave team provided a new API
which allows both active and passive wave

00:33:19.429 --> 00:33:24.269
robots. And what that means for you is that
you can receive notification that that a wave

00:33:24.269 --> 00:33:29.169
changed as a WebHook persist some data to
task queue to do a complex calculation offline

00:33:29.169 --> 00:33:35.820
and then come back and update the original
wave once your calculation is complete. We

00:33:35.820 --> 00:33:41.380
also added support for kind of first class
support for unit testing. So, we now have

00:33:41.380 --> 00:33:45.440
an App Engine testing JAR that contains subset
of the DevAppServer basically just enough

00:33:45.440 --> 00:33:51.799
functionality to discover API implementations
on the class path and route API calls through

00:33:51.799 --> 00:33:57.460
to it. But it also contains a set of task
config classes that lets you configure each

00:33:57.460 --> 00:34:02.409
API. So for example, we will disable disk
usage of the Datastore by default because,

00:34:02.409 --> 00:34:06.830
you know, you don't generally want that in
a unit disk. If you want to know more about

00:34:06.830 --> 00:34:11.950
this, Max Ross is doing a talk, I think, in
this room later today that's going to talk

00:34:11.950 --> 00:34:17.569
about this thing in more detail, I believe.
Okay, so, now let's talk about some behind

00:34:17.569 --> 00:34:23.849
the scenes performance optimizations we've
made. We know that loading requests are very

00:34:23.849 --> 00:34:28.849
important. They're probably much more important
on App Engine than they would be in another

00:34:28.849 --> 00:34:33.319
Java hosting environment where you're not
necessarily dynamically rebalancing and reloading

00:34:33.319 --> 00:34:38.179
applications across many JBMs. And for that
reason, a lot of Java applications or Java

00:34:38.179 --> 00:34:44.159
libraries aren't really optimized for load
startup time. But despite that we think we've

00:34:44.159 --> 00:34:48.929
made a number of things that help apps across
the board and have really improve loading

00:34:48.929 --> 00:34:55.349
request latency, and we have a lot additional
ideas for big improvements as well. So one

00:34:55.349 --> 00:34:59.569
of the big things we rolled out this year
was precompilation, and we don't--we haven't

00:34:59.569 --> 00:35:04.039
really talked about this much in the past,
but when you deploy bytecode on App Engine,

00:35:04.039 --> 00:35:09.060
we need to process it; we need to be able
to look at that bite code and see what you're

00:35:09.060 --> 00:35:12.940
doing. And we do this for a number of reasons,
but the biggest reason is to enable applications

00:35:12.940 --> 00:35:17.369
or libraries that would otherwise not run
in our secured environment to run on App Engine.

00:35:17.369 --> 00:35:21.660
And we need to maintain compatibility and
this is one of the ways that we do it. So

00:35:21.660 --> 00:35:25.480
we used to do this dynamically when we would
load a class, we would immediately process

00:35:25.480 --> 00:35:29.160
the bytecode; that contribute to some slowness
during loading requests. So since a couple

00:35:29.160 --> 00:35:34.119
of SDK releases ago when we turn down precompilation
by default, what we basically do now is to

00:35:34.119 --> 00:35:35.540
process all of that bytecode at deployment
time. So, this not only saves us time during

00:35:35.540 --> 00:35:43.610
loading requests because if it's not work,
we do not have to then and don't have to do

00:35:43.610 --> 00:35:49.950
redundantly. But it also gives us the opportunity
for more expensive optimizations. So, we're

00:35:49.950 --> 00:35:53.190
experimenting with things like building stack
maps if your bytecode doesn't already have

00:35:53.190 --> 00:35:59.460
it or building JAR indexes that map out how
your code is laid out across multiple files,

00:35:59.460 --> 00:36:03.010
or even something as frivolous, changing the
compilation or--sorry, the compression level

00:36:03.010 --> 00:36:06.849
of a JAR can have a big impact. So these are
things that we can--we now have an opportunity

00:36:06.849 --> 00:36:13.450
to do behind the scenes as you deploy your
code. So how does this work? Well, the SDK

00:36:13.450 --> 00:36:17.079
is already responsible for uploading a set
of application files and they're check sums

00:36:17.079 --> 00:36:21.400
to the server, because the server needs to
know which files hasn't seen before and request

00:36:21.400 --> 00:36:26.270
the actual contents from SDK. As part of this,
we also identify which files are likely to

00:36:26.270 --> 00:36:32.079
contain bytecode, and we've break those into
chunks of roughly equal work and send those

00:36:32.079 --> 00:36:36.069
chunks back to the SDK, then the SDK just
iterates through them sequentially compiling

00:36:36.069 --> 00:36:40.539
them one at a time. So there's lots of opportunity
for more parallelization and improvements

00:36:40.539 --> 00:36:46.340
here but, we just did something as simple
as possible. But one really interesting requirement

00:36:46.340 --> 00:36:50.010
of precompilation is that we occasionally
need to reprocess the bytecode for all applications.

00:36:50.010 --> 00:36:55.829
You know, for example, if there's some new
method that we need to be aware of or some

00:36:55.829 --> 00:36:59.240
new optimization we want to roll out, we need
to process code for all 100,000 Java apps.

00:36:59.240 --> 00:37:04.089
So you might think that that will be really
slow and a lot of work and slow down our release

00:37:04.089 --> 00:37:08.089
cycle, but it turns out that we only need
to process each unique file once across all

00:37:08.089 --> 00:37:13.210
apps, and luckily most--you know, many Java
apps shared most of the same java libraries,

00:37:13.210 --> 00:37:15.950
so it's really not that much work. The last
time we had to do this, the total amount of

00:37:15.950 --> 00:37:20.690
bytecode we processed was only about 35 Gigabytes,
which, you know, when you consider reusing

00:37:20.690 --> 00:37:22.380
standard Google tools like MapReduce and stuff
is really not even enough data to register.

00:37:22.380 --> 00:37:32.589
So here are some of the results of the precompilation.
What you see here is the loading or request

00:37:32.589 --> 00:37:37.910
latency before and after we rolled out precompilation,
split up into a few different categories.

00:37:37.910 --> 00:37:42.890
There's the time spent in application code,
there's the time spent in API calls, garbage

00:37:42.890 --> 00:37:46.859
collection, hotspot compilation, and then
finally the red line of the end is bytecode

00:37:46.859 --> 00:37:50.339
processing, which is what we are really targeting
here. And you can see that from most steps

00:37:50.339 --> 00:37:55.369
and including a sample of [INDISTINCT] map
and a couple of real world apps that I grabbed

00:37:55.369 --> 00:38:00.350
here. We completely eliminated bytecode processing,
which was about 30 % to 40 % of the overall

00:38:00.350 --> 00:38:07.640
request time. For other apps like JRuby and
Rhino and similar dynamic languages, we didn't

00:38:07.640 --> 00:38:11.450
eliminate it, we only reduced the bytecode
processing time. And the reason for that is

00:38:11.450 --> 00:38:16.980
that these libraries like many Java libraries
now generate bytecode on the fly or instrument

00:38:16.980 --> 00:38:22.980
bytecode. So we still need to be able to--to
do this processing of the bytecodes on the

00:38:22.980 --> 00:38:28.740
fly. We can't predict every class that they're
going to try to load at deployment time. And

00:38:28.740 --> 00:38:32.890
that's why you see there's still some red
at the end, after precompilation is enabled.

00:38:32.890 --> 00:38:35.760
But at the very least we've eliminated all
the bytecode processing for the language run-time

00:38:35.760 --> 00:38:42.851
itself and in a dependent libraries like as
[INDISTINCT], those sorts of libraries. So

00:38:42.851 --> 00:38:45.099
it was still a big win all around.
&gt;&gt; REYELTS: So, hello. There we go. That's

00:38:45.099 --> 00:38:58.801
not bad. So I'm going to talk about some of
the Reflection Optimizations that we--that

00:38:58.801 --> 00:39:04.720
we made specifically. So we had a set of big
improvements that basically fell into two

00:39:04.720 --> 00:39:10.250
categories. The first one is a caching access
checks and the second had to do with failures.

00:39:10.250 --> 00:39:16.369
And so the deal with caching access checks
is that they--they turned out to be really

00:39:16.369 --> 00:39:21.790
expensive. And the example I want to talk
about specifically is the sample grails app.

00:39:21.790 --> 00:39:29.580
So what happened is a--is Graeme Rocher who
is like a Grails lead handed us the sample

00:39:29.580 --> 00:39:34.299
grails app and he said, "You know, what can
I do to speed this up? Or what can you do

00:39:34.299 --> 00:39:39.829
to speed this up?" And so we started doing
profiling on this app. And one of the things

00:39:39.829 --> 00:39:45.390
we learned is that in the loading request
it was making 11,000 reflective calls. And

00:39:45.390 --> 00:39:50.539
if you know anything about Java then you know
reflection is like pretty slow compared to

00:39:50.539 --> 00:39:56.789
like normal method calls to begin with. And
as we look closer at that data, what we saw

00:39:56.789 --> 00:40:03.200
was that 50% of those reflective calls were
actually only being made against three different

00:40:03.200 --> 00:40:07.200
methods. And so the good thing about that
is--that means that we could put together

00:40:07.200 --> 00:40:13.200
a cache that would cache the checks against
those methods. And it would be extremely effective

00:40:13.200 --> 00:40:19.450
and it--it was and it turned out to be great.
In the second case, what we learn about failures

00:40:19.450 --> 00:40:22.660
is that some--some reflective invocations
I just--they fail very slowly. They have to

00:40:22.660 --> 00:40:29.829
go through a bunch of checks and as they go
down each check and you--and you do all this

00:40:29.829 --> 00:40:35.559
passing, you can end up just doing a lot of
work, when it comes to failure. And an example

00:40:35.559 --> 00:40:40.051
here is a--is a JRuby runtime. We've been
working a lot like Charles Nodder who is like

00:40:40.051 --> 00:40:47.109
a JRuby lead. And help trying to help speed
up Ruby loading requests and what we found,

00:40:47.109 --> 00:40:51.960
for example, is that there were cases where
it was making reflective calls like "set accessible"

00:40:51.960 --> 00:40:58.109
against "object.finalize". And if you know--if
you remember "object.finalize", it's a protected

00:40:58.109 --> 00:41:03.740
method on objects. So we don't let applications
grab that method and do stuff with that. But

00:41:03.740 --> 00:41:08.760
the problem was--was that JRuby was doing
that hundreds and hundreds of times on startup.

00:41:08.760 --> 00:41:14.910
It just would repeatedly fail over and over
again and not realize that it was doing that.

00:41:14.910 --> 00:41:20.109
So there are few things that we could do on
our end to help tweak that. But working together

00:41:20.109 --> 00:41:25.810
with--with Charles, we were actually able
to improve the JRuby runtime itself, so that

00:41:25.810 --> 00:41:34.990
it doesn't do those failures both on--or off
App Engine. So, in general, with this performance

00:41:34.990 --> 00:41:40.079
improvements we made, we were able to speed
up startup for 10--for--to make it about 10%

00:41:40.079 --> 00:41:44.359
faster for most dynamic language runtimes.
So there's Groovy and JRuby. But there is

00:41:44.359 --> 00:41:51.720
also Rhino and--and other runtimes like that.
Here's a graph of some of the performance

00:41:51.720 --> 00:41:56.900
improvements we specifically made. You can
see that in some cases and some of the improvements

00:41:56.900 --> 00:42:02.540
were modest, but in other cases like "callingstring.index"
reflectively, it was like an order of magnitude

00:42:02.540 --> 00:42:07.559
improvement. And the--and yeah, so the gray
bar here--the gray bars are the old times

00:42:07.559 --> 00:42:14.240
and the blue bars are the new times and these
times are actually microseconds. So, we're

00:42:14.240 --> 00:42:21.550
optimizing on the microsecond level here,
to bring you faster startup times on App Engine.

00:42:21.550 --> 00:42:27.510
And, yeah, you can see "set accessible", where
JRuby was doing a lot of calls faster. Here's

00:42:27.510 --> 00:42:34.079
the second graph with some more times here,
and what I'd point out is--is one of these--we

00:42:34.079 --> 00:42:38.750
couldn't like make the graph very well. We
could go like exponential or whatever, but

00:42:38.750 --> 00:42:44.589
then things wouldn't look like right. Anyway,
we optimize something that was at--that took

00:42:44.589 --> 00:42:51.500
20,000 microseconds all the way down to about
200. So that was a--that was two orders of

00:42:51.500 --> 00:42:54.829
magnitude improvement, which is--which is
pretty--we're pretty happy about and it shows

00:42:54.829 --> 00:43:01.079
up in the end. So let me talk more about future
performance improvements to App Engine that

00:43:01.079 --> 00:43:06.450
we're working on right now. The first set
of improvements have to do with reducing I/O

00:43:06.450 --> 00:43:14.680
latency. And--and which also translates to
API call latency too. So if you have like

00:43:14.680 --> 00:43:22.900
really short fast API calls right now, there's--there's
almost like a constant overhead to those API

00:43:22.900 --> 00:43:29.540
calls, in general. And so a memcache call
for example, might be a fast call. But due

00:43:29.540 --> 00:43:34.640
to this I/O latency constant overhead it has
a pretty significant impact. So when we roll

00:43:34.640 --> 00:43:40.230
out this change, you'll see for example memcache
calls improved in performance by a pretty

00:43:40.230 --> 00:43:45.640
hefty percentage. And in general, any I/O
you're doing, will have less like latency

00:43:45.640 --> 00:43:52.700
to it. Another thing we did is that we're
reducing the time spend in JIT and garbage

00:43:52.700 --> 00:43:58.089
collection overall. And when I say reducing
it, what I really mean is that we're--we're

00:43:58.089 --> 00:44:05.180
improving the parallelization of--were--of
that works such that it all happens concurrently

00:44:05.180 --> 00:44:10.260
and therefore you spend less time blocking
in it. So the same amount of CPU time will

00:44:10.260 --> 00:44:14.520
take place but it will be happening on more
processors and so therefore your app will

00:44:14.520 --> 00:44:21.160
be loading and running faster for all intensive
purposes. The last improvement I'd like to

00:44:21.160 --> 00:44:28.990
talk about are reserved instances. And like
Don mentioned before, we know that a lot--a

00:44:28.990 --> 00:44:33.970
lot of people been having a pain with this
and the pain is typically for people who aren't

00:44:33.970 --> 00:44:38.359
getting, you know, who are getting a lot of
traffic. But--but we know that there are a

00:44:38.359 --> 00:44:43.120
lot people using App Engine that--that don't
get a lot of traffic and it's important to

00:44:43.120 --> 00:44:48.839
help our customers out. And so we've been--we've
been working very hard and we have a plan.

00:44:48.839 --> 00:44:52.440
Unfortunately, we can't quite give you all
the details about it, since we're still working

00:44:52.440 --> 00:44:56.960
on it. But let me give you some of the highlights.
The first is that, yes, you will actually

00:44:56.960 --> 00:45:03.579
be able to dedicate JVMs and yes that will
reduce your loading requests. The second thing

00:45:03.579 --> 00:45:08.410
is--is that because you're dedicating a JVM
that means that JVM is going to be in memory

00:45:08.410 --> 00:45:13.420
like all the time, right? And that--and that's
actually a cost to us. In general, we've tried

00:45:13.420 --> 00:45:20.170
to make App Engine, fit the philosophy that
you only use--you only pay for what you use,

00:45:20.170 --> 00:45:25.010
right? Well, in this case, you're using more
memory. So unfortunately, you'll have to pay

00:45:25.010 --> 00:45:32.559
a little bit with that. But we are doing everything
to make those costs very reasonable and so

00:45:32.559 --> 00:45:37.299
we hope to give you good details on that soon.
And then the third thing is that as we give

00:45:37.299 --> 00:45:42.530
you the capability to dedicate, to reserve
this JVMs, what we're also going to do is

00:45:42.530 --> 00:45:48.130
to improve the App Eng console to give you
greater visibility and to how App Engine is

00:45:48.130 --> 00:45:54.660
actually spinning up and creating JVMs and
things like that for you. So you'll be able

00:45:54.660 --> 00:46:04.460
to make good decision making around all of
this. So now we're done talking about performance

00:46:04.460 --> 00:46:09.550
and I would like to talk some about compatibility
and how we've been improving that. If you've

00:46:09.550 --> 00:46:13.920
been watching and been using App Engine, you'd
noticed that our top issue is over the last

00:46:13.920 --> 00:46:18.880
year in terms of compatibility, in terms of
Jerry compatibility has been around XML. Everybody

00:46:18.880 --> 00:46:25.000
uses lot of X ML on app engine apparently.
So we work very hard to--to bring those libraries,

00:46:25.000 --> 00:46:29.800
and the good thing is that not only can you
now use all these built in XML libraries in

00:46:29.800 --> 00:46:34.490
App Engine, you can actually even bring your
own. So, for example, if there's a newer version

00:46:34.490 --> 00:46:41.039
of one of these third party libraries, then
typically those will work out of the box for

00:46:41.039 --> 00:46:45.289
you. We also white-listed a few additional
classes that were causing problems with third

00:46:45.289 --> 00:46:50.500
party libraries and then we white-listed a
lot of classes that were causing problems

00:46:50.500 --> 00:46:57.480
in terms of serialization, which also improved
compatibility. Here's a slide that just list

00:46:57.480 --> 00:47:02.930
all of these libraries and as far as we know
did not work a year ago and do now, and this

00:47:02.930 --> 00:47:07.750
is far from exhaustive. We just wanted to
give some good examples of a lot of libraries

00:47:07.750 --> 00:47:12.980
that are now compatible with App Engine and
how we're working hard to continue to improve

00:47:12.980 --> 00:47:17.740
compatibility. And we'd like to take all the
credit for--for this, but the truth is--is

00:47:17.740 --> 00:47:22.310
that in general, I would--I would imagine
that there are probably people on the audience

00:47:22.310 --> 00:47:28.390
here who have done a lot of work, issuing
bug reports and talking to the people who

00:47:28.390 --> 00:47:33.440
work on this libraries and maybe even submitting
patches. So what we'd really like to do is

00:47:33.440 --> 00:47:39.410
give thanks to the open source community for
working very hard with us to make libraries

00:47:39.410 --> 00:47:47.530
compatible with App Engine. Finally, I'd like
to talk about DevAppServer sandbox emulation

00:47:47.530 --> 00:47:53.880
and it seems like a little odd slide to put
in with compatibility. But what this--what's

00:47:53.880 --> 00:47:58.020
important about this is that as we improve
the emulation on the DevAppServer, and it

00:47:58.020 --> 00:48:01.619
helps you feel confident. You don't have to
go up to the production server all the time

00:48:01.619 --> 00:48:07.319
to make sure that your library is or are compatible
and whatnot. So we thought we'd talk a little

00:48:07.319 --> 00:48:11.380
bit about that too. One new feature is that
we're doing very good at enforcing the whitelist

00:48:11.380 --> 00:48:16.240
now. If you've been using app engine since
it started, there were--there are a lot of

00:48:16.240 --> 00:48:19.779
classes that you could use in the DevAppServer
and there were--and you really had to take

00:48:19.779 --> 00:48:26.069
your app into production to--to have any confidence
at all that you weren't using something that

00:48:26.069 --> 00:48:33.200
you weren't supposed to, but--but that works
well no. We also in addition do better enforcement

00:48:33.200 --> 00:48:38.319
around reflections. So some of the--so a lot
of the things that you can't get away with

00:48:38.319 --> 00:48:43.769
on the app engine production environment,
you now can't get away with it on the DevAppServer.

00:48:43.769 --> 00:48:48.730
And, in fact, we generally improved the stuff
so well that there are now very few complains

00:48:48.730 --> 00:48:54.140
at all about any security differences between
the local and the production environments.

00:48:54.140 --> 00:48:58.900
So let me talk a little bit about how we do
this. What we do, again, if you've been paying

00:48:58.900 --> 00:49:04.269
very close attention, there's a little Java
agent flag that you now--that now get specified

00:49:04.269 --> 00:49:10.309
with the DevAppServer. And what that is doing
is that is--that causes a JVM agent to be

00:49:10.309 --> 00:49:15.230
loaded up with the DevAppServer and that JVM
agent then instruments all the bytecode coming

00:49:15.230 --> 00:49:21.230
out--coming out of your web app. Similar to
how Don was talking about precompilation for

00:49:21.230 --> 00:49:27.240
production. So you can kind of think of it
as like many precompilation for your DevAppServer

00:49:27.240 --> 00:49:32.920
and it goes in and it injects little bytecode
hooks that, like, modify, like, effectively

00:49:32.920 --> 00:49:40.220
the runtime and makes the app conform--conform
to this text. So that does mean the DevAppServer

00:49:40.220 --> 00:49:45.670
is a perfect emulation? Unfortunately not,
there are--the Google production environment

00:49:45.670 --> 00:49:53.369
is so different than the code that runs on
your local machine that we probably will never

00:49:53.369 --> 00:49:57.690
have everything perfect. That means that,
you know, it's still a good idea to every

00:49:57.690 --> 00:50:03.470
once in a while upload your, you know, your
app during development up to production and

00:50:03.470 --> 00:50:10.529
see that things are behaving as you expect.
Then I guess that brings us to the end of

00:50:10.529 --> 00:50:15.690
our talk. So here's a little resource slide
we want to point out that you can hit the

00:50:15.690 --> 00:50:21.240
Dance Dance Robot demo and try it out for
yourself. If you didn't--if the Wi-Fi prevented

00:50:21.240 --> 00:50:27.539
you from doing that today, the source code
is on code.google.com. We do want to let you

00:50:27.539 --> 00:50:33.930
know that since features that you're using
are so new to App Engine they may be disabled

00:50:33.930 --> 00:50:39.220
after the demo for a small period of time
which will bring down the App maybe for a

00:50:39.220 --> 00:50:44.869
day or something like that. And I guess we're
ready to take questions.

00:50:44.869 --> 00:50:47.240
&gt;&gt; Sir, yes. Can we start with--since there
was no one lined up, I'm going to start with

00:50:47.240 --> 00:50:48.240
the moderator.
&gt;&gt; REYELTS: Sure.

00:50:48.240 --> 00:50:49.240
&gt;&gt; And then we can...
&gt;&gt; Switch back and forth.

00:50:49.240 --> 00:51:08.000
&gt;&gt; SCHWARZ: All right. So what's the new COMET
support in App Engine going to be like? How

00:51:08.000 --> 00:51:13.410
do you build efficient applications with always
open COMET connections? I think we've answered

00:51:13.410 --> 00:51:14.940
that throughout our talk. Do we want to say
anything else about it?

00:51:14.940 --> 00:51:21.640
&gt;&gt; REYELTS: You can talk a little bit about
the efficiency but basically the idea is that

00:51:21.640 --> 00:51:27.440
we already have infrastructure to do this.
So when you use Gmail and Google Talk or whatnot,

00:51:27.440 --> 00:51:32.410
we've had to build a bunch of scalable, efficient
infrastructure. So you're piggybacking on

00:51:32.410 --> 00:51:43.430
that with App Engine.
&gt;&gt; SCHWARZ: We should plug as much talk about

00:51:43.430 --> 00:51:58.220
that.
So, there's a talk some time today, I think

00:51:58.220 --> 00:52:07.730
it's immediately after this actually, that's
going to go on a lot more detail about this.

00:52:07.730 --> 00:52:20.339
I don't know where it is or what about I think
it's immediately after this session. Sir?

00:52:20.339 --> 00:52:29.749
&gt;&gt; Hi. So one of those guys who has a Grails
running on App Engine.

00:52:29.749 --> 00:52:35.900
&gt;&gt; REYELTS: Yes. I'm sorry did you say Grails
App? Did I hear you correctly?

00:52:35.900 --> 00:52:38.059
&gt;&gt; Yes.
&gt;&gt; REYELTS: Okay.

00:52:38.059 --> 00:52:56.060
&gt;&gt; And initialization is basically killing
us it doesn't run as a result. So I wanted

00:52:56.060 --> 00:53:06.680
to know what are the plans to optimize it
more and also that would be very, very helpful,

00:53:06.680 --> 00:53:17.309
I guess, that, you know, what you can share
and to make it actually work on App Engine

00:53:17.309 --> 00:53:22.690
and anything else that you can share with
us now, please.

00:53:22.690 --> 00:54:00.240
&gt;&gt; SCHWARZ: Okay. Well, so first of all you
want to make sure that that you're using precompilation,

00:54:00.240 --> 00:54:10.470
so that's on by default. We're still constantly
making changes in the background and it is--this

00:54:10.470 --> 00:54:27.950
is considered kind of best effort thing. So
occasionally precompilation wont' always take

00:54:27.950 --> 00:54:55.869
effect. But you want to make sure--if you
can get in touch with us if you want us to

00:54:55.869 --> 00:55:07.170
give you more information about your application
like the breakdown you saw on that graph earlier

00:55:07.170 --> 00:55:15.650
of GC versus hotspot versus whatever. We can
share some information about that. We've also

00:55:15.650 --> 00:55:23.890
talk about some additional things beyond precompilation
that we were planning to do. Like increasing

00:55:23.890 --> 00:55:33.900
the parallelization of garbage collection
and hotspot compilation, we think that will

00:55:33.900 --> 00:55:42.549
be a pretty dramatic speed up maybe on par
with precompilation and the I/O changes--depending

00:55:42.549 --> 00:55:46.660
on how much weight code you have, that maybe
very significant as well. So, like I said,

00:55:46.660 --> 00:55:49.730
we definitely have some things queued up and
we--those are the short term things. We have

00:55:49.730 --> 00:55:53.350
some very long term things queued up too that
we're not quite ready to talk about yet. So

00:55:53.350 --> 00:56:01.950
it will keep improving that sort of one branch.
And then parallel to that we are introducing

00:56:01.950 --> 00:56:07.440
improved--reserved instances as kind of a
hatch, right? If, you know, if its performance

00:56:07.440 --> 00:56:13.650
still isn't where you want it to be, then
our reserved instances let you pay for the

00:56:13.650 --> 00:56:17.569
privileged of not having to pay that cost,
obviously.

00:56:17.569 --> 00:56:22.079
&gt;&gt; REYELTS: Go ahead.
&gt;&gt; So it's just--you were talking about the

00:56:22.079 --> 00:56:28.410
things you can do on the DevApp server to
try to create a similar environment to production

00:56:28.410 --> 00:56:34.039
changes to the bicode. Is that for only Java
class files that are sitting or could that

00:56:34.039 --> 00:56:37.420
also affect the co-generation that happens?
&gt;&gt; REYELTS: That should work for anything.

00:56:37.420 --> 00:56:43.350
So if you're running a Rhino or Ruby or whatever
they all end up as bicode in the VM. So we

00:56:43.350 --> 00:56:54.349
all--that's the awesome thing about the JVM,
right? You have all these different languages

00:56:54.349 --> 00:56:57.560
and if you--if you operate at bicode level
then things pretty much are great.

00:56:57.560 --> 00:56:58.670
&gt;&gt; Okay. And it seems--one another question,
I was curious--were talking about precompilation

00:56:58.670 --> 00:57:07.329
is going to work for these classes that you
said, you have a JAR file that does a bunch

00:57:07.329 --> 00:57:11.299
of work [INDISTINCT] could help of that if
you're using Rhino or JRuby or some of the

00:57:11.299 --> 00:57:13.930
language that has a big [INDISTINCT] during
generation, that's not going to take advantage

00:57:13.930 --> 00:57:14.930
of that. Are some of this other languages
looking at ways to do ahead of time compiling

00:57:14.930 --> 00:57:16.480
or is that always kind of a challenge with
different frameworks? In this case, generally,

00:57:16.480 --> 00:57:17.480
how that works for...?
&gt;&gt; REYELTS: Yes. We can talk about that a

00:57:17.480 --> 00:57:18.750
bit more but it depends a lot like you put
it out on the language runtime itself. Like,

00:57:18.750 --> 00:57:22.000
for example, there Rhino has like both an
interpreted and JIT mode, right? And the JIT

00:57:22.000 --> 00:57:24.460
mode is faster and helps us, like, produce
more bicodes and stuff like that. Actually,

00:57:24.460 --> 00:57:26.320
Charles Nutter has been working very hard
to like produce--to provide AOT compiling,

00:57:26.320 --> 00:57:27.850
ahead of time compiling for JRuby, that's
much more amendable to App Engine. Like right

00:57:27.850 --> 00:57:31.880
now AOT compiling for JRuby just isn't great
it produces way, way, way more bicodes than

00:57:31.880 --> 00:57:38.339
it ought to and things like that and the--so
I'm really excited to see how the progress

00:57:38.339 --> 00:57:41.789
on that will come along for us.
&gt;&gt; SCHWARZ: Let's take a moderator question

00:57:41.789 --> 00:57:46.849
and I'll get back to you. Official Scala support,
so we don't--we--I don't really know how to

00:57:46.849 --> 00:57:51.670
answer that question. We do have Scala support;
I assumed what this is referring to is things

00:57:51.670 --> 00:57:54.619
like Scala, Scala workers, and different aspects
of Scala.

00:57:54.619 --> 00:58:03.430
&gt;&gt; REYELTS: Yes. I'm not sure. What we do,
what we do and what we have been talking about

00:58:03.430 --> 00:58:15.690
are making other language runtimes that are
JBM languages more supported. So John has

00:58:15.690 --> 00:58:29.950
actually been working on that, actually, several
people have been working on that. So we might

00:58:29.950 --> 00:58:44.119
see, for example, maybe a Ruby runtime that
is actually a JVM runtime. We might see a

00:58:44.119 --> 00:58:54.720
JavaScript runtime at some point. And so maybe
we'd do something with Scala with that too

00:58:54.720 --> 00:58:56.231
and typically this runtimes don't vary a lot,
right, because they're all using the same

00:58:56.231 --> 00:58:57.231
JVM backend. But there's like Polish and Finnish
that you can provide around that in terms

00:58:57.231 --> 00:59:01.320
of like config files like Ruby prefers more
yUML like files or something like that. As

00:59:01.320 --> 00:59:09.269
opposed to like, you know, "web.xml" and App
Engine "web.xml" files. So we don't have any

00:59:09.269 --> 00:59:14.630
thing in the works planned right now for Scala
but really it has such great interop with

00:59:14.630 --> 00:59:15.630
Java. I'm not sure what we would do to improve
it.

00:59:15.630 --> 00:59:16.630
&gt;&gt; SCHWARZ: Yeah. All right.
&gt;&gt; I'd like a full fledge to the API like

00:59:16.630 --> 00:59:17.630
Java 2D. What's the plan for that in the future?
&gt;&gt; SCHWARZ: We've given it a lot of thought.

00:59:17.630 --> 00:59:18.630
I don't think that we've invested a ton of
effort into it currently. But it's definitely

00:59:18.630 --> 00:59:19.630
something that we've thought very hard about.
&gt;&gt; REYELTS: Right. We wanted to, we want a

00:59:19.630 --> 00:59:20.630
full fledge 2D API for App Engine and the--and
again like the problem with that there's just

00:59:20.630 --> 00:59:21.630
tons of native code that is kind of that does
like a lot of things like it use, for example,

00:59:21.630 --> 00:59:22.630
graphic strivers and things like that. And
so we have to be very careful to weave through

00:59:22.630 --> 00:59:23.630
that to make sure that we're going to provide
something that's safe, right? Like for everyone

00:59:23.630 --> 00:59:24.630
to use on App Engine and so--it's definitely
on our plate and we have taken--we've taken

00:59:24.630 --> 00:59:25.630
like initial steps and prototypes towards
it and it definitely looks like there is a

00:59:25.630 --> 00:59:26.630
lot of code that we can use that doesn't depend
upon native code. But it's just--it's a pretty

00:59:26.630 --> 00:59:27.630
big effort. So the time--anytime for that
we don't want promise anything right now.

00:59:27.630 --> 00:59:28.630
&gt;&gt; Hi. So, yesterday according to the announcement
about compatibility with VMware guys and with

00:59:28.630 --> 00:59:29.630
Google Application Engine for business [INDISTINCT],
does it mean that you're going to create a

00:59:29.630 --> 00:59:30.630
separate infrastructure because probably the
Spring guys and then the VMware guys are providing

00:59:30.630 --> 00:59:31.630
support for [INDISTINCT] for example or for
hibernate sample or things like this which

00:59:31.630 --> 00:59:32.630
are more complete Java runtime environment.
&gt;&gt; SCHWARZ: Yes. I don't really know how to

00:59:32.630 --> 00:59:33.630
answer that question. So let me try and repeat
the question. The question was, with the partnerships

00:59:33.630 --> 00:59:34.630
that we announced yesterday with the VMware
and Spring does that mean we will be supporting

00:59:34.630 --> 00:59:35.630
things like hibernate? Is that basically your
question?

00:59:35.630 --> 00:59:36.630
&gt;&gt; So the question is it going to be compatible,
really compatible between Google Application

00:59:36.630 --> 00:59:37.630
Engine and so, for example, VM code?
&gt;&gt; SCHWARZ: Right. Okay. I don't actually;

00:59:37.630 --> 00:59:38.630
I don't actually know how to answer that question
to be perfectly honest. I know that the Google

00:59:38.630 --> 00:59:39.630
App for business sort of product is definitely
something that's going to be kind of compose

00:59:39.630 --> 00:59:40.630
of features that will be added to App Engine
over time and it's just kind of way to tie

00:59:40.630 --> 00:59:41.630
them all together and provide a single price
for them. But I don't know how that fits in

00:59:41.630 --> 00:59:42.630
with the--there are all sort of stuffs talked
about yesterday with interoperability across

00:59:42.630 --> 00:59:43.630
Clouds, to be honest I don't know the answer
to that.

00:59:43.630 --> 00:59:44.630
&gt;&gt; REYELTS: Okay. Do you want to go ahead?
&gt;&gt; Yes. I'm actually looking at the managed

00:59:44.630 --> 00:59:45.630
stock files form the App dashboard question
because I have the same question.

00:59:45.630 --> 00:59:46.630
&gt;&gt; REYELTS: Is that--that's your question?
&gt;&gt; Yes. And basically, you know, when we first

00:59:46.630 --> 00:59:47.630
did our requirements we did--and chose App
Engine we were just going to deploy the application

00:59:47.630 --> 00:59:59.070
part of our company's material on there and
it's a premium model. So, a lot of marketing

00:59:59.070 --> 01:00:02.240
material ended up in there too which they
want to change all the time and, you know,

01:00:02.240 --> 01:00:03.240
I'm head of engineering, so we go through
smoke on staging, we go through smoke on debts,

01:00:03.240 --> 01:00:04.240
and the marketing guys are like, "I just want
to change one file."

01:00:04.240 --> 01:00:06.109
&gt;&gt; REYELTS: I guess the good news is that
right now that if you do change one file and

01:00:06.109 --> 01:00:11.050
you redeploy your app that really only re-uploads
that one file; it won't reload all of the

01:00:11.050 --> 01:00:17.269
files on your application. Like they--the
underlying way that works is we have a whole

01:00:17.269 --> 01:00:24.010
bunch of secure hashing schemes we use, right?
And so we checked with the server, does this

01:00:24.010 --> 01:00:27.640
file exist blah, blah, blah, blah, blah. So
it's not like--it's not really perfect, but

01:00:27.640 --> 01:00:33.270
you should get fast deploys anyway, right?
You're really only uploading the content that

01:00:33.270 --> 01:00:35.269
changed.
&gt;&gt; SCHWARZ: If you really do want a dynamically

01:00:35.269 --> 01:00:39.599
like on the fly change this content, then--and
then you can think about making it part of

01:00:39.599 --> 01:00:43.000
your application instead of a static resource,
right? You can upload it to Blobstore for

01:00:43.000 --> 01:00:47.009
example or just if it's small enough upload
it to the Datastore and serve it dynamically.

01:00:47.009 --> 01:00:49.000
&gt;&gt; REYELTS: Right. That's a really good point.
Like you actually have like CMS functionality,

01:00:49.000 --> 01:00:58.220
right? It's different than just kind of that.
&gt;&gt; Yes. Absolutely. And this is kind of a

01:00:58.220 --> 01:01:00.780
half way there kind of thing.
&gt;&gt; REYELTS: Okay.

01:01:00.780 --> 01:01:04.839
&gt;&gt; Thanks.
&gt;&gt; SCHWARZ: Okay. So what in JEE6 is supported

01:01:04.839 --> 01:01:12.500
currently or in the near future on App Engine?
So I--I'm definitely not an expert in EE 6.

01:01:12.500 --> 01:01:19.180
I know some of the things that includes like
servlet 3.0 and I know it includes new versions

01:01:19.180 --> 01:01:24.490
like JAX-WS and JAXP and all that stuff. I
don't know if any of those versions that are

01:01:24.490 --> 01:01:28.069
new lined up with the versions we currently
support, I don't know that of the top of my

01:01:28.069 --> 01:01:33.140
head. But I will say with respect to servlet
3.0 specifically, we have a guy who works

01:01:33.140 --> 01:01:39.869
20% time on our project sometime and then
was actually on the servelet 3.0 spec committee.

01:01:39.869 --> 01:01:43.559
So it's definitely something we're aware of
and we've talking to him occasionally about

01:01:43.559 --> 01:01:49.940
what it's going to require on our part, and
it's something that we haven't begun on yet

01:01:49.940 --> 01:01:55.180
but it's on the roadmap. It's definitely something
we're thinking about. Okay.

01:01:55.180 --> 01:01:59.789
&gt;&gt; REYELTS: All right, I think we run out
of time here. Are we done?

01:01:59.789 --> 01:02:02.249
&gt;&gt; SCHWARZ: Yeah. We're done.
&gt;&gt; REYELTS: Yeah. They're cutting us off.

01:02:02.249 --> 01:02:07.420
So thank you everyone for coming to the presentation.
Hope you enjoyed it.

