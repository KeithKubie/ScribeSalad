WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:03.510
Let's imagine, for example, that there
is truly only one optimal action.

00:00:03.510 --> 00:00:07.900
Then, as we spend an infinite amount of
time running around in the world, our

00:00:07.900 --> 00:00:11.160
notion of which action is optimal over
here, if we can convert them into actual

00:00:11.160 --> 00:00:15.770
probabilities, will drive whatever
the optimal action is towards one.

00:00:15.770 --> 00:00:17.900
And that just comes from all the stuff
we've been talking about with

00:00:17.900 --> 00:00:20.680
reinforcement learning for
all the time in this class.

00:00:20.680 --> 00:00:24.630
If we can get to an optimal policy by
just experiencing things in the world,

00:00:24.630 --> 00:00:26.610
then eventually,
these numbers will reflect that.

00:00:26.610 --> 00:00:28.900
And it doesn't matter
what the human thinks,

00:00:28.900 --> 00:00:31.850
the real world will drive
the correct answer towards one.

00:00:31.850 --> 00:00:35.210
&gt;&gt; So, you're saying that c
doesn't change over time?

00:00:35.210 --> 00:00:37.900
&gt;&gt; c could change over time, but
let's just imagine it doesn't.

00:00:37.900 --> 00:00:41.950
Let's just say, we pick a value for
c and it comes out this way.

00:00:41.950 --> 00:00:44.690
If you want to say that c changes
over time that's okay, but

00:00:44.690 --> 00:00:49.820
then we're going to deal with that
question by having these numbers here

00:00:49.820 --> 00:00:53.090
reflect whatever we
think c happens to be.

00:00:53.090 --> 00:00:55.941
Remember, we can keep track of all
the labels that we've seen and for any

00:00:55.941 --> 00:00:59.092
given value of c that we have, we can
just change these numbers appropriately.

00:00:59.092 --> 00:00:59.625
&gt;&gt; Okay.

00:00:59.625 --> 00:01:00.980
&gt;&gt; So, it sort of doesn't matter.

00:01:00.980 --> 00:01:02.560
At the time we ask this question,

00:01:02.560 --> 00:01:05.010
I've got a distribution of
reactions according to the human.

00:01:05.010 --> 00:01:08.838
I've got a distribution of actions
according to my experience in the world.

00:01:08.838 --> 00:01:11.528
It no longer matters what I think
about the human because that is

00:01:11.528 --> 00:01:13.300
captured by this distribution.

00:01:13.300 --> 00:01:15.660
So I can just ask the question,
what should I do?

00:01:15.660 --> 00:01:17.251
And here you think the answer is x.

00:01:17.251 --> 00:01:17.878
&gt;&gt; Yeah.

00:01:17.878 --> 00:01:20.510
&gt;&gt; Now,
what if I had different numbers here?

00:01:20.510 --> 00:01:21.563
&gt;&gt; Then I still think it's x.

00:01:21.563 --> 00:01:22.320
&gt;&gt; Yeah.
[LAUGH]

00:01:22.320 --> 00:01:24.050
&gt;&gt; What if it is this?

00:01:24.050 --> 00:01:26.090
Well now I could certainly justify why.

00:01:26.090 --> 00:01:26.845
&gt;&gt; Why.
&gt;&gt; Yeah.

00:01:26.845 --> 00:01:29.052
&gt;&gt; [LAUGH] Tell me why you think y.

00:01:29.052 --> 00:01:32.640
&gt;&gt; So okay, so are we supposed
to imagine that the pi sub A is,

00:01:32.640 --> 00:01:34.415
can the algorithm be wrong?

00:01:34.415 --> 00:01:36.240
&gt;&gt; The algorithm could be wrong.

00:01:36.240 --> 00:01:39.650
But in the same way that we
don't have to worry about

00:01:39.650 --> 00:01:43.640
what's wrong with the human because
the distribution captures it,

00:01:43.640 --> 00:01:45.008
let's make the same assumption here.

00:01:45.008 --> 00:01:48.100
The agent, well this distribution
is going to capture all of

00:01:48.100 --> 00:01:50.520
the uncertainty about
the agent's beliefs.

00:01:50.520 --> 00:01:53.704
So maybe we'll never actually see 0, 1,
0, but we'll see numbers that are close

00:01:53.704 --> 00:01:55.930
enough that I'm just
going to write out 0, 1, 0.

00:01:55.930 --> 00:01:59.390
&gt;&gt; Boy, there's a lot of ways to
combine these numbers together

00:01:59.390 --> 00:02:00.990
in which y ends up being the winner.

00:02:02.940 --> 00:02:05.160
But it strikes me that in particular,

00:02:05.160 --> 00:02:09.509
if we believe pi sub A, then pi sub
A is absolutely certain that it's y.

00:02:09.509 --> 00:02:12.520
So it almost doesn't matter at
this point what pi sub H thinks,

00:02:12.520 --> 00:02:14.235
what the human thinks.

00:02:14.235 --> 00:02:18.010
&gt;&gt; Mm-hm, and by the way, with the same
argument, if it's the case that c

00:02:18.010 --> 00:02:22.220
is equal to 1 for the human, that the
human is infallible, then it really is

00:02:22.220 --> 00:02:24.600
not going to matter what the agent
thinks, because the human's infallible.

00:02:24.600 --> 00:02:26.540
&gt;&gt; Well, unless they,
[LAUGH] unless they disagree.

00:02:26.540 --> 00:02:29.218
But then we have to really believe
that probability is correct.

00:02:29.218 --> 00:02:29.820
&gt;&gt; Right.

00:02:29.820 --> 00:02:31.530
Either the probability is correct or
it's incorrect.

00:02:31.530 --> 00:02:33.820
And for
the purposes of answering this question,

00:02:33.820 --> 00:02:35.490
let's just say
the probabilities are correct.

00:02:35.490 --> 00:02:37.810
In so far they are not it will be
reflected by these distributions.

00:02:37.810 --> 00:02:40.901
&gt;&gt; So we can never have 1, 0,
0 on the top row and then 0, 1,

00:02:40.901 --> 00:02:44.178
0 on the bottom row, because that
just violates the laws of reality.

00:02:44.178 --> 00:02:44.759
&gt;&gt; Right.

00:02:44.759 --> 00:02:45.977
&gt;&gt; So, you would argue for y?

00:02:45.977 --> 00:02:46.662
&gt;&gt; I would.

00:02:46.662 --> 00:02:49.696
&gt;&gt; I think that you've been using
intuition so far and I want you to do

00:02:49.696 --> 00:02:53.300
a little bit more than intuition, so I'm
going to do that by writing out a quiz.

