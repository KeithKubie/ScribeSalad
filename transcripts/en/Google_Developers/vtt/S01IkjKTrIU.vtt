WEBVTT
Kind: captions
Language: en

00:00:04.190 --> 00:00:07.320
We're going to touch on another
one of my passions here,

00:00:07.320 --> 00:00:08.920
and it's a growing passion.

00:00:08.920 --> 00:00:10.810
I still consider myself
a bit of a beginner

00:00:10.810 --> 00:00:11.976
when it comes to containers.

00:00:13.270 --> 00:00:16.135
We're going to talk about
Kubernetes and Docker.

00:00:18.840 --> 00:00:21.280
I want to check what's going on.

00:00:21.280 --> 00:00:24.710
Who here has worked
with containers before?

00:00:26.760 --> 00:00:29.810
That's actually
about as expected.

00:00:29.810 --> 00:00:32.820
Don't worry, we're going
to do some overview,

00:00:32.820 --> 00:00:35.984
so if you don't know the
intricacies of containers

00:00:35.984 --> 00:00:37.525
you'll get a good
summary, hopefully.

00:00:39.800 --> 00:00:43.780
So what are containers
and how can they

00:00:43.780 --> 00:00:46.555
help us be better developers?

00:00:49.250 --> 00:00:51.170
I'm going to start
with the summary

00:00:51.170 --> 00:00:54.010
because that's the most
important part, obviously.

00:00:54.010 --> 00:00:59.470
A container raises
the abstraction level

00:00:59.470 --> 00:01:00.755
for how you develop.

00:01:03.350 --> 00:01:07.090
When you're developing on
traditional virtual machines,

00:01:07.090 --> 00:01:12.330
you are actually interacting
with idealized hardware.

00:01:12.330 --> 00:01:13.300
Right?

00:01:13.300 --> 00:01:16.260
You're interacting with the
operating system, the network,

00:01:16.260 --> 00:01:17.860
the disk, what have you.

00:01:17.860 --> 00:01:21.100
It's fairly well tied
into the environment

00:01:21.100 --> 00:01:22.110
on which you're running.

00:01:23.230 --> 00:01:24.690
You have to know
the ins and outs,

00:01:24.690 --> 00:01:27.060
whether there are any
gotchas, et cetera.

00:01:27.060 --> 00:01:31.680
And what happens is
this becomes kind

00:01:31.680 --> 00:01:35.040
of like an octopus intertwined
with the environment.

00:01:36.190 --> 00:01:38.470
That's not really ideal.

00:01:38.470 --> 00:01:43.670
So containers separate out your
application from where it runs.

00:01:45.600 --> 00:01:49.100
That's like the
most powerful thing

00:01:49.100 --> 00:01:50.635
that I can say about containers.

00:01:52.950 --> 00:02:01.280
So instead of developing on
top of the idealized hardware,

00:02:01.280 --> 00:02:05.530
you're developing against an
idealized operating system,

00:02:05.530 --> 00:02:08.659
a static Linux
environment when you're

00:02:08.659 --> 00:02:09.784
developing with containers.

00:02:12.980 --> 00:02:17.590
It allows you to really
develop in a more generic way

00:02:17.590 --> 00:02:19.320
that can run more places.

00:02:19.320 --> 00:02:21.240
You wind up with this
kind of hermetically

00:02:21.240 --> 00:02:23.060
sealed-- which I think
is an awesome phrase

00:02:23.060 --> 00:02:26.120
to describe containers--
a hermetically sealed

00:02:26.120 --> 00:02:26.620
application.

00:02:28.080 --> 00:02:30.140
This allows you to
really dive into what's

00:02:30.140 --> 00:02:32.600
going on in your
application because it's

00:02:32.600 --> 00:02:34.700
lifted up outside
of the environment.

00:02:35.754 --> 00:02:37.420
We'll get into a
little bit more detail.

00:02:40.760 --> 00:02:42.000
So why do we care?

00:02:43.200 --> 00:02:45.295
Why do developers
care about containers?

00:02:47.680 --> 00:02:50.255
The first reason is stress.

00:02:50.255 --> 00:02:51.130
Who here is stressed?

00:02:53.468 --> 00:02:57.320
I am so stressed I
can't even tell you.

00:02:57.320 --> 00:03:02.610
We deal with stress on a day
to day basis, and often times

00:03:02.610 --> 00:03:04.720
it comes from our deployments.

00:03:06.360 --> 00:03:07.440
Right?

00:03:07.440 --> 00:03:12.100
I remember I once had a bug
in my production system.

00:03:12.100 --> 00:03:13.710
This is before I joined Google.

00:03:15.040 --> 00:03:17.050
I once had a bug in
my production system

00:03:17.050 --> 00:03:19.370
that only existed there.

00:03:21.630 --> 00:03:24.000
It didn't occur in my
development environment.

00:03:24.000 --> 00:03:25.980
It didn't occur in
staging or test.

00:03:27.060 --> 00:03:27.910
Only in production.

00:03:29.010 --> 00:03:32.596
That strikes fear into
the heart of a developer.

00:03:32.596 --> 00:03:34.095
Like ice running
through your veins.

00:03:35.410 --> 00:03:37.690
Because it's so hard to debug.

00:03:37.690 --> 00:03:39.810
It's an environment issue.

00:03:41.002 --> 00:03:42.710
I was combing through
code and I actually

00:03:42.710 --> 00:03:47.090
didn't find anything because
the bug was not in the code.

00:03:47.090 --> 00:03:52.500
It was in the build scripts,
which you can argue is code.

00:03:52.500 --> 00:03:53.970
I'll grant you that.

00:03:53.970 --> 00:03:57.830
So these reliable
deployments, when

00:03:57.830 --> 00:03:59.660
you're operating
with containers,

00:03:59.660 --> 00:04:03.140
it means that your
development environment is

00:04:03.140 --> 00:04:05.800
the same as your staging
or test environment,

00:04:05.800 --> 00:04:07.720
is the same as your
production environment.

00:04:07.720 --> 00:04:12.390
Because you're developing
against that idealized static

00:04:12.390 --> 00:04:13.230
Linux environment.

00:04:14.520 --> 00:04:17.350
The surface area for
bugs, while you can still

00:04:17.350 --> 00:04:20.370
obviously introduce them
into your applications,

00:04:20.370 --> 00:04:22.240
it's dramatically reduced.

00:04:23.680 --> 00:04:27.560
That just makes people
happy and lifts stress.

00:04:27.560 --> 00:04:29.285
So containers, less stress.

00:04:32.000 --> 00:04:34.410
The other reason is
that it is portable.

00:04:36.920 --> 00:04:41.020
You can take a container with
your deployable application

00:04:41.020 --> 00:04:44.300
and move it from one
environment to another.

00:04:45.950 --> 00:04:52.715
So you may decide to run
Compute Engine or another cloud

00:04:52.715 --> 00:04:53.215
provider.

00:04:54.750 --> 00:04:56.370
But with containers
you can easily

00:04:56.370 --> 00:05:00.327
move between different
environments,

00:05:00.327 --> 00:05:01.160
different providers.

00:05:02.270 --> 00:05:03.200
This is awesome.

00:05:03.200 --> 00:05:04.040
This is great.

00:05:04.040 --> 00:05:07.820
What it means is you can
pursue a multi-cloud approach,

00:05:07.820 --> 00:05:08.375
if you want.

00:05:09.740 --> 00:05:14.110
Oftentimes that may, indeed,
be the path you take.

00:05:15.380 --> 00:05:20.320
You can decide to do a hybrid
cloud, a private cloud,

00:05:20.320 --> 00:05:23.100
and then switch from one to
the other when the case may be.

00:05:25.697 --> 00:05:27.530
We've done a lot of
work with Compute Engine

00:05:27.530 --> 00:05:30.220
to make sure it's
awesome and that it's

00:05:30.220 --> 00:05:32.970
a great place for
you to develop,

00:05:32.970 --> 00:05:37.420
but we want you to be there
because you want to be there,

00:05:37.420 --> 00:05:38.670
not because it's hard to move.

00:05:39.830 --> 00:05:43.260
So you get to pick your
cloud, where you run,

00:05:43.260 --> 00:05:44.515
based on its merits.

00:05:45.840 --> 00:05:48.720
That puts the power
back into your hands.

00:05:50.310 --> 00:05:51.560
And that's fantastic.

00:05:51.560 --> 00:05:53.060
That's the way it should be.

00:05:55.420 --> 00:05:59.765
The last reason is
because micro services.

00:06:03.060 --> 00:06:05.670
Containers make it easier
for you to separate out

00:06:05.670 --> 00:06:09.960
your application into
smaller components that

00:06:09.960 --> 00:06:14.880
are far more like Lego
than monolithic structures.

00:06:17.340 --> 00:06:19.910
This means you can
manage them much easier.

00:06:19.910 --> 00:06:23.180
You can debug a micro
service far more easily

00:06:23.180 --> 00:06:25.450
than you can debug a
monolithic application.

00:06:26.900 --> 00:06:28.900
It makes it easier to upgrade.

00:06:28.900 --> 00:06:32.810
You can slowly,
incrementally improve

00:06:32.810 --> 00:06:34.480
what you're offering
to your users.

00:06:36.020 --> 00:06:41.100
And make sure and know that your
surface area for regressions

00:06:41.100 --> 00:06:41.690
is low.

00:06:43.010 --> 00:06:45.810
Then of course you can
mix in other services

00:06:45.810 --> 00:06:47.130
easily and safely.

00:06:50.410 --> 00:06:53.950
However, if you do encounter a
regression based on an upgrade,

00:06:53.950 --> 00:06:56.390
containers also make it
really easy to roll back.

00:06:59.380 --> 00:07:02.610
This is a slide that you
did see in the keynote,

00:07:02.610 --> 00:07:05.470
but everything at Google
runs in a container.

00:07:07.475 --> 00:07:07.975
Everything.

00:07:09.460 --> 00:07:13.900
We've been long-term
fans of containers.

00:07:13.900 --> 00:07:15.440
And why is that?

00:07:15.440 --> 00:07:19.490
What do containers give us
that we love so very much?

00:07:20.510 --> 00:07:23.620
We've been doing this kind
of hyper scale deployments,

00:07:23.620 --> 00:07:25.060
these hyper scale services.

00:07:27.110 --> 00:07:30.830
To be most efficient
we need to make

00:07:30.830 --> 00:07:33.495
as much use of our
resources as possible.

00:07:34.970 --> 00:07:36.790
So the machines
that we run, we want

00:07:36.790 --> 00:07:40.470
them to be as close to
100% capacity as possible.

00:07:41.840 --> 00:07:43.640
Containers let us do that.

00:07:43.640 --> 00:07:45.460
If we have a really
high priority

00:07:45.460 --> 00:07:50.310
job that we want to run, we can
put that on the same machine

00:07:50.310 --> 00:07:55.000
as a low priority job, but
in their own containers.

00:07:55.000 --> 00:07:58.510
That means that the
low priority job

00:07:58.510 --> 00:08:02.097
won't consume the resources
of the high priority one.

00:08:02.097 --> 00:08:03.930
And the resource isolation
means they're not

00:08:03.930 --> 00:08:07.560
going to run up into each
other on another level.

00:08:09.220 --> 00:08:11.900
It also means that we
get a lot of insight

00:08:11.900 --> 00:08:15.190
into how our
applications are running.

00:08:15.190 --> 00:08:19.445
Is one application eating
up a lot of disk space?

00:08:21.080 --> 00:08:21.910
It could be.

00:08:21.910 --> 00:08:24.910
And because it's running in
its own container we can drill

00:08:24.910 --> 00:08:27.190
down, find out which
application that is

00:08:27.190 --> 00:08:28.830
and why it's doing that.

00:08:29.952 --> 00:08:31.285
It gives us resource accounting.

00:08:33.815 --> 00:08:35.690
Then we can, of course,
talk to our engineers

00:08:35.690 --> 00:08:37.570
and create that
nice feedback loop

00:08:37.570 --> 00:08:41.485
between how an application
runs and how it's developed.

00:08:48.420 --> 00:08:50.980
Like I said, we're big
fans of containers.

00:08:50.980 --> 00:08:54.870
We run over 2 billion per week.

00:08:54.870 --> 00:09:01.110
Things like Gmail, Search,
Drive all run in containers.

00:09:01.110 --> 00:09:05.530
In fact, our Compute
Engine, Virtual Machines,

00:09:05.530 --> 00:09:06.950
run in containers as well.

00:09:09.450 --> 00:09:10.350
That's something.

00:09:10.350 --> 00:09:14.160
We're saying, we're throwing
our experience, our weight

00:09:14.160 --> 00:09:18.150
behind this technology and
telling you we're big fans.

00:09:18.150 --> 00:09:21.740
So let's talk a little bit
about the stack at Google.

00:09:25.430 --> 00:09:27.910
The Google cluster
management stack

00:09:27.910 --> 00:09:33.300
is comprised of two sections,
the section in blue,

00:09:33.300 --> 00:09:36.773
and the section in what
I'm going to call marigold.

00:09:39.600 --> 00:09:41.100
That seems like that color.

00:09:42.110 --> 00:09:45.290
So at the base you've
got the managed base

00:09:45.290 --> 00:09:48.300
OS and the node
container manager.

00:09:48.300 --> 00:09:51.130
So these two things
are what are deployed

00:09:51.130 --> 00:09:55.020
on every single machine
in our data centers.

00:09:56.860 --> 00:09:57.620
Every single one.

00:10:00.090 --> 00:10:04.360
The schedules
containers is everything

00:10:04.360 --> 00:10:06.940
that we want to run
on our machines.

00:10:06.940 --> 00:10:09.620
And the cluster
scheduler figures out

00:10:09.620 --> 00:10:11.360
where and when that happens.

00:10:13.042 --> 00:10:14.500
So let's talk out
the blue section.

00:10:16.730 --> 00:10:19.740
This is essentially what
we've released in May

00:10:19.740 --> 00:10:23.952
as our Container Optimized
Virtual Machine Image,

00:10:23.952 --> 00:10:24.910
and that is a mouthful.

00:10:26.450 --> 00:10:32.170
So this means that you can go
from an imperative approach

00:10:32.170 --> 00:10:33.756
to a declarative one.

00:10:33.756 --> 00:10:34.755
And what does that mean?

00:10:37.720 --> 00:10:42.450
We might be at the point
where I say-- sorry,

00:10:42.450 --> 00:10:46.590
I apparently will say sorry--
where I say to a machine,

00:10:46.590 --> 00:10:53.130
I want you to run this software,
do these tasks and shut down.

00:10:55.050 --> 00:10:59.530
If I want to move that into a
declarative approach you say,

00:10:59.530 --> 00:11:06.170
I expect this machine to be
running, doing these tasks

00:11:06.170 --> 00:11:08.790
and shutting down
once that happens.

00:11:08.790 --> 00:11:11.200
It's a really subtle
change, isn't it?

00:11:11.200 --> 00:11:12.660
It's hard to parse.

00:11:12.660 --> 00:11:15.270
It's almost more of
a psychological shift

00:11:15.270 --> 00:11:16.640
than a technological one.

00:11:18.230 --> 00:11:21.950
It means you can go to expecting
what your machine should

00:11:21.950 --> 00:11:23.920
be doing instead
of feeling like you

00:11:23.920 --> 00:11:25.470
have to tell them every time.

00:11:28.630 --> 00:11:30.850
So what does that
actually look like?

00:11:30.850 --> 00:11:33.590
Let's go through a
command line example.

00:11:33.590 --> 00:11:35.630
Who here uses Apache web server?

00:11:37.601 --> 00:11:38.100
Nginx?

00:11:39.980 --> 00:11:44.350
So Nginx is a really
lightweight web server.

00:11:44.350 --> 00:11:46.840
It's easy to install,
easy to spin up,

00:11:46.840 --> 00:11:50.510
and we've been using it for
some of our examples lately.

00:11:50.510 --> 00:11:56.070
We're going to call in
to the cloud sdk gcloud.

00:11:56.070 --> 00:11:59.710
We're going to create a Compute
Engine instance, a Compute

00:11:59.710 --> 00:12:00.690
Engine Virtual Machine.

00:12:00.690 --> 00:12:03.125
We're going to call
it My Nginx Container.

00:12:04.960 --> 00:12:07.680
And we're going to take some
configuration information

00:12:07.680 --> 00:12:11.010
from this containers.yaml file.

00:12:11.010 --> 00:12:12.630
We'll locate it in a zone.

00:12:12.630 --> 00:12:14.130
We're going to use
a small instance.

00:12:14.130 --> 00:12:16.150
It's a lightweight web server.

00:12:16.150 --> 00:12:17.490
We don't need a big one.

00:12:17.490 --> 00:12:21.430
Best practices say, always use
the right tool for the job.

00:12:21.430 --> 00:12:24.010
And then we're going to use
our container optimized VM,

00:12:24.010 --> 00:12:26.406
and that's what that
dash, dash, image,

00:12:26.406 --> 00:12:28.530
really long string that I
don't really want to say.

00:12:29.925 --> 00:12:31.300
And we're going
to contain create

00:12:31.300 --> 00:12:33.280
a container running Ngninx.

00:12:35.440 --> 00:12:36.340
Pretty simple.

00:12:36.340 --> 00:12:39.180
But what is in this
container's .yaml file?

00:12:40.780 --> 00:12:41.280
That's it.

00:12:42.790 --> 00:12:45.940
We've got a nice,
structured specification

00:12:45.940 --> 00:12:50.150
of what we want to happen
inside of the container.

00:12:50.150 --> 00:12:53.530
We want to use the Nginx image.

00:12:53.530 --> 00:12:55.500
We're going to call it www.

00:12:55.500 --> 00:12:58.280
And we're going to
open up a standard port

00:12:58.280 --> 00:13:00.210
to serve traffic over.

00:13:00.210 --> 00:13:01.902
We're mapping 80 to 80/80.

00:13:03.050 --> 00:13:07.079
And that will let us go ahead
and stand up a nice web server

00:13:07.079 --> 00:13:07.995
inside of a container.

00:13:08.845 --> 00:13:11.220
But let's make it a little
bit more complicated, not very

00:13:11.220 --> 00:13:12.570
much.

00:13:12.570 --> 00:13:16.590
Let's say, OK but let's go
back to the best practices.

00:13:16.590 --> 00:13:19.270
We should also open up https.

00:13:21.920 --> 00:13:26.930
We can do that simply by adding
another section under the ports

00:13:26.930 --> 00:13:29.880
and open up port 443.

00:13:29.880 --> 00:13:32.570
So now we have a nice
web server serving

00:13:32.570 --> 00:13:34.990
traffic over http or https.

00:13:36.860 --> 00:13:38.835
Let's get a little
bit more complicated.

00:13:41.950 --> 00:13:44.700
Now this is great
for a web server,

00:13:44.700 --> 00:13:49.460
but what if you've got two
functions maybe sharing

00:13:49.460 --> 00:13:53.850
some data, but they comprise
one overall application.

00:13:55.040 --> 00:13:57.530
So that's what we call a pod.

00:13:59.020 --> 00:14:01.596
We've got the web
server, the www,

00:14:01.596 --> 00:14:06.340
and we've got a data loader
that takes in, say, new things

00:14:06.340 --> 00:14:07.400
that you want to serve.

00:14:09.000 --> 00:14:11.380
So it's going to write
that to the data shard.

00:14:12.460 --> 00:14:16.290
They work nicely together
and they can actually

00:14:16.290 --> 00:14:20.750
function as a unit with this
thing we're calling a pod.

00:14:20.750 --> 00:14:24.010
So as you can see,
the web server, www,

00:14:24.010 --> 00:14:27.340
mounts up our data shard, but
it doesn't need to write to it.

00:14:27.340 --> 00:14:29.300
It's just going to be read only.

00:14:29.300 --> 00:14:32.770
Whereas, the data loader
does need to write,

00:14:32.770 --> 00:14:34.850
so obviously we
don't have that line.

00:14:36.690 --> 00:14:39.390
That's the conceptual
unit a pod.

00:14:41.870 --> 00:14:43.130
What does this look like?

00:14:45.530 --> 00:14:50.890
On the virtual machine itself
we've got a couple of sections.

00:14:50.890 --> 00:14:53.960
We've got what Google provides
and we've got what you provide.

00:14:55.730 --> 00:14:58.080
On the left is all
Google provided.

00:14:58.080 --> 00:15:00.080
You can see it's
kind of haphazard.

00:15:00.080 --> 00:15:01.870
We've got the managed base OS.

00:15:01.870 --> 00:15:04.490
We've got the monitoring
agent, the logging agent.

00:15:04.490 --> 00:15:06.620
But we've also got
Docker running.

00:15:06.620 --> 00:15:10.760
It's already running on
our container optimized

00:15:10.760 --> 00:15:12.600
virtual machine images.

00:15:12.600 --> 00:15:14.500
It's also got a couple
of processes running,

00:15:14.500 --> 00:15:16.430
likes sshd and init.

00:15:17.760 --> 00:15:20.890
On the right hand side is
the container environment

00:15:20.890 --> 00:15:25.950
that we talked about right
on top of that base OS,

00:15:25.950 --> 00:15:28.320
and we've got the user
app, what you create.

00:15:31.870 --> 00:15:35.855
So let's step out
back into scheduling.

00:15:40.970 --> 00:15:44.680
The job of the
cluster scheduler is

00:15:44.680 --> 00:15:50.840
to figure out what resources
are available to it

00:15:50.840 --> 00:15:53.840
and figure out where
the best place is

00:15:53.840 --> 00:15:55.870
for you to run your job.

00:15:55.870 --> 00:16:06.590
So you can say to it,
I need x cores, y ram

00:16:06.590 --> 00:16:09.570
and, let's say, z
amount of disk that I

00:16:09.570 --> 00:16:12.170
want associated
with this container.

00:16:12.170 --> 00:16:13.870
It'll say, OK cool.

00:16:13.870 --> 00:16:14.744
That's awesome.

00:16:14.744 --> 00:16:16.660
I think I can do that,
let me go find a place.

00:16:17.690 --> 00:16:19.700
And it'll find a place
where it can run happily.

00:16:26.660 --> 00:16:28.140
This is where
Kubernetes comes in.

00:16:29.460 --> 00:16:31.760
So Kubernetes is an
open source project.

00:16:31.760 --> 00:16:33.940
It's developed out
in the open on GitHub

00:16:33.940 --> 00:16:37.670
You can go, clone
it, fork it today.

00:16:37.670 --> 00:16:39.919
And we'll give you a link
to that at the very end,

00:16:39.919 --> 00:16:41.210
so don't worry about searching.

00:16:42.300 --> 00:16:47.700
It's actually ancient Greek--
an etymological sidetrack--

00:16:47.700 --> 00:16:49.250
for "pilot" or "helmsman".

00:16:50.890 --> 00:16:52.559
We're a little bit
of nerds at Google,

00:16:52.559 --> 00:16:53.850
I don't know if you could tell.

00:16:56.560 --> 00:16:59.635
What it does is it's
a Cluster Manager.

00:17:00.970 --> 00:17:03.960
It's what we were talking
about in the marigold.

00:17:05.361 --> 00:17:06.819
Do we have any
gophers in the room?

00:17:08.640 --> 00:17:09.140
All right.

00:17:09.140 --> 00:17:11.223
How many of you are confused
by the term "gopher"?

00:17:12.420 --> 00:17:13.180
OK.

00:17:13.180 --> 00:17:14.750
So gopher is what
we generally called

00:17:14.750 --> 00:17:16.740
people who develop and go.

00:17:19.040 --> 00:17:21.440
You'll be happy to know
that Kubernetes is actually

00:17:21.440 --> 00:17:23.819
implemented in the go
programming language.

00:17:23.819 --> 00:17:27.240
It allows you to manage
applications and not machines.

00:17:34.400 --> 00:17:37.490
We developed it out in the
open for a couple of reasons.

00:17:38.540 --> 00:17:40.420
We don't think we
can go it alone.

00:17:40.420 --> 00:17:42.930
We want to make
sure that we gather

00:17:42.930 --> 00:17:46.210
the expertise necessary to make
this an awesome open source

00:17:46.210 --> 00:17:48.490
project for everyone.

00:17:48.490 --> 00:17:50.850
That means being able
to run it wherever

00:17:50.850 --> 00:17:54.010
you want, whether you
want to run it locally,

00:17:54.010 --> 00:17:56.990
on your own cloud, on Google's
cloud-- obviously we've

00:17:56.990 --> 00:17:59.820
done a lot of work to
make it run great there--

00:17:59.820 --> 00:18:01.400
or on a different provider.

00:18:03.980 --> 00:18:07.110
Like Tom just mentioned,
we've gotten a lot of interest

00:18:07.110 --> 00:18:10.080
from other companies who are
becoming active committers

00:18:10.080 --> 00:18:12.400
on the project, and
that's so awesome to see.

00:18:12.400 --> 00:18:16.510
Microsoft, IBM, Red Hat, Docker,
Mesosphere, SaltStack , CoreOS,

00:18:16.510 --> 00:18:18.870
and I've run out of breath
so we're going to stop there.

00:18:20.100 --> 00:18:23.230
And you, too, can submit
pull requests as well.

00:18:23.230 --> 00:18:25.722
You can become a
contributor for Kubernetes.

00:18:25.722 --> 00:18:27.180
So I encourage you
to check it out.

00:18:28.500 --> 00:18:30.190
So what does it
actually look like?

00:18:32.320 --> 00:18:35.910
With Kubernetes it
provides a scheduler layer.

00:18:37.730 --> 00:18:39.700
It lets you schedule
work in the way

00:18:39.700 --> 00:18:43.200
that we were talking about
in a declarative manner,

00:18:43.200 --> 00:18:46.100
but you don't need to know
what machine you're running on.

00:18:46.100 --> 00:18:48.200
That's almost irrelevant, right?

00:18:50.520 --> 00:18:54.947
So you interact with the
Kubernetes Master/Scheduler

00:18:54.947 --> 00:18:56.530
whenever you want
to interact with it.

00:18:57.600 --> 00:19:01.340
So you tell it what
pod you want to run.

00:19:01.340 --> 00:19:04.450
In this case we've got a
Web Server and a Log Roller,

00:19:04.450 --> 00:19:07.205
and it'll schedule the
work out to machines.

00:19:09.010 --> 00:19:11.400
And if all you need is
a few of these pods,

00:19:11.400 --> 00:19:14.770
maybe you're developing a small
application, that's great.

00:19:14.770 --> 00:19:16.530
That's probably
all you need to do.

00:19:17.950 --> 00:19:22.010
But if you've got a
more complex application

00:19:22.010 --> 00:19:25.805
that's going to be too much to
handle, at least rationally.

00:19:27.800 --> 00:19:30.080
So right here we've
got a bunch of pods.

00:19:30.080 --> 00:19:32.680
We've got some front ends, we've
got some back ends, hopefully

00:19:32.680 --> 00:19:34.180
all working in some
sort of harmony.

00:19:35.350 --> 00:19:37.680
But we want to make it easier.

00:19:37.680 --> 00:19:40.650
That's where labels and
selectors come into play.

00:19:41.837 --> 00:19:43.045
It's a really simple concept.

00:19:44.740 --> 00:19:46.495
We assign labels to pods.

00:19:47.830 --> 00:19:50.240
In this case we've got
two types of labels.

00:19:50.240 --> 00:19:52.750
We've got front
end and back end.

00:19:52.750 --> 00:19:56.360
And here we're going to
select all of the front ends

00:19:56.360 --> 00:20:00.510
that we've got running in
our Kubernetes cluster.

00:20:00.510 --> 00:20:04.600
So you can see all of the
front ends are lit up and green

00:20:04.600 --> 00:20:06.225
and the back ends
have been deselected.

00:20:09.580 --> 00:20:10.960
But wait, there's more.

00:20:12.880 --> 00:20:15.930
You can do a more complex query.

00:20:17.320 --> 00:20:21.910
And you only want to select
the production front ends.

00:20:23.380 --> 00:20:27.820
So you can select on both
labels, the stage and the role

00:20:27.820 --> 00:20:28.800
label.

00:20:28.800 --> 00:20:32.110
And again, three front
ends have dropped away

00:20:32.110 --> 00:20:35.070
and we're left with all of
the production front ends.

00:20:37.830 --> 00:20:38.700
OK.

00:20:38.700 --> 00:20:40.345
So now you have a set of pods.

00:20:41.750 --> 00:20:46.040
You can interact with a set of
pods in your Kubernetes cluster

00:20:46.040 --> 00:20:47.550
and you want to
do something cool.

00:20:48.610 --> 00:20:50.465
You can do that with
the replica controller.

00:20:52.870 --> 00:20:57.840
This takes a template, this kind
of pre-defined cookie cutter

00:20:57.840 --> 00:21:03.269
type thing, and a label
selector, and a set of pods

00:21:03.269 --> 00:21:04.310
and a number of replicas.

00:21:06.830 --> 00:21:10.930
What it does is it
keeps maintaining

00:21:10.930 --> 00:21:15.070
the containers, the pods, to
comply with that cookie cutter.

00:21:16.110 --> 00:21:19.520
So right here you can see
we've got four replicas,

00:21:19.520 --> 00:21:23.850
and, lo and behold, we have
four production front ends.

00:21:23.850 --> 00:21:24.821
OK.

00:21:24.821 --> 00:21:25.570
But you know what?

00:21:25.570 --> 00:21:26.870
I decided that's way too many.

00:21:26.870 --> 00:21:28.100
It's a small application.

00:21:28.100 --> 00:21:29.370
I don't need four front ends.

00:21:29.370 --> 00:21:30.620
I want to drop it down to one.

00:21:31.630 --> 00:21:33.860
So the replica
controller is constantly

00:21:33.860 --> 00:21:38.500
monitoring and saying,
hey is my expected state

00:21:38.500 --> 00:21:40.570
the same as my actual state?

00:21:41.590 --> 00:21:45.050
And in this case, I want
to change it to one.

00:21:45.050 --> 00:21:49.410
So I update and the replica
controller will say, oh wait.

00:21:49.410 --> 00:21:50.890
I've got four.

00:21:50.890 --> 00:21:51.640
I only need one.

00:21:51.640 --> 00:21:52.630
That's far too many.

00:21:52.630 --> 00:21:55.200
Let me kill three, and
we're left with one.

00:21:57.980 --> 00:22:01.155
I've clearly made
a drastic error.

00:22:01.155 --> 00:22:03.570
It was not a good idea
to drop it down to one

00:22:03.570 --> 00:22:04.860
so I'll increase it to three.

00:22:04.860 --> 00:22:07.130
Again, our expected
state is different

00:22:07.130 --> 00:22:08.480
than our actual state.

00:22:08.480 --> 00:22:09.980
Let's up it.

00:22:09.980 --> 00:22:15.160
Let's create a couple more
containers until our state is

00:22:15.160 --> 00:22:15.810
the right one.

00:22:18.510 --> 00:22:20.900
Right now we've only been
talking about the front ends,

00:22:20.900 --> 00:22:22.580
the production front
ends, and obviously

00:22:22.580 --> 00:22:25.470
there were back ends
in our cluster as well.

00:22:25.470 --> 00:22:31.280
So we need a way to access
both in an abstracted manner.

00:22:31.280 --> 00:22:33.550
We need a way to access
our production front ends

00:22:33.550 --> 00:22:36.737
and our production back
ends in an abstract way.

00:22:36.737 --> 00:22:38.070
That's what we do with services.

00:22:41.410 --> 00:22:47.120
A service is basically a way for
you to access your set of pods.

00:22:48.730 --> 00:22:50.480
You access them
through an endpoint.

00:22:50.480 --> 00:22:55.660
In this case, for the back ends,
we access them on port 9,000.

00:22:55.660 --> 00:22:59.660
The front ends can
talk to that endpoint.

00:22:59.660 --> 00:23:02.000
It doesn't matter how
many pods there are there.

00:23:03.100 --> 00:23:05.330
It's going to load
balance anything that

00:23:05.330 --> 00:23:09.020
comes in over that port
across the ones that exist.

00:23:10.480 --> 00:23:11.650
So it's a nice easy way.

00:23:11.650 --> 00:23:15.830
Again, you don't need to
care how many containers

00:23:15.830 --> 00:23:18.010
are running, you just
need a way to interact

00:23:18.010 --> 00:23:19.050
with the ones that are.

00:23:22.440 --> 00:23:23.550
So who wants to do a demo?

00:23:25.800 --> 00:23:26.671
OK.

00:23:26.671 --> 00:23:27.170
Awesome.

00:23:28.530 --> 00:23:32.900
So no demo in tech is
complete without cats.

00:23:34.015 --> 00:23:34.515
Right?

00:23:35.670 --> 00:23:37.630
Yeah, I didn't think so.

00:23:37.630 --> 00:23:41.370
Can we switch to
the demo, please?

00:23:41.370 --> 00:23:45.800
Let me unlock my machine
and we will get there.

00:23:48.280 --> 00:23:49.700
Awesome.

00:23:49.700 --> 00:23:50.760
So these are our cats.

00:23:53.020 --> 00:23:58.370
We've got a Kubernetes cluster
running, a simple web server.

00:23:58.370 --> 00:24:01.545
And these are actually
running on Compute Engine.

00:24:03.870 --> 00:24:08.900
This is basically showing
off what the pods are doing.

00:24:08.900 --> 00:24:11.579
Not necessarily
your end goal here,

00:24:11.579 --> 00:24:12.870
but it's good for this purpose.

00:24:14.700 --> 00:24:17.000
I do have a confession to make.

00:24:17.000 --> 00:24:18.805
I'm not a cat person.

00:24:18.805 --> 00:24:19.305
I'm sorry.

00:24:20.990 --> 00:24:23.210
I'm not a cat person,
so what I want to do

00:24:23.210 --> 00:24:28.950
is replace all of these cats
with pictures of a nautilus

00:24:28.950 --> 00:24:30.290
instead.

00:24:30.290 --> 00:24:32.415
That's so much cooler
than cats, I'm sorry.

00:24:33.460 --> 00:24:37.530
So what I'm going to do is pull.

00:24:37.530 --> 00:24:39.530
We've got a data
file that's telling

00:24:39.530 --> 00:24:41.250
us which picture to use.

00:24:42.270 --> 00:24:43.550
I'm going to modify it.

00:24:46.300 --> 00:24:51.070
And you can see here currently
it's pulling kitten.jpg

00:24:51.070 --> 00:24:55.370
and we're going to
make it nautilus.

00:24:55.370 --> 00:24:57.097
Let's see if I
spelled that right.

00:24:57.097 --> 00:24:58.430
Somebody want to spell check me?

00:25:00.860 --> 00:25:02.720
Now what we're going
to do is actually

00:25:02.720 --> 00:25:04.760
go ahead and build
the Docker image.

00:25:06.420 --> 00:25:10.015
So I'm going to build
it, build the container.

00:25:11.720 --> 00:25:13.730
It's going to finish
really rapidly,

00:25:13.730 --> 00:25:15.470
so I'm going to go
ahead and push it.

00:25:18.290 --> 00:25:20.090
It's going to go
ahead and do this,

00:25:20.090 --> 00:25:22.510
but you'll notice that
we still have our cats.

00:25:24.304 --> 00:25:26.470
It's not actually changing
anything with Kubernetes.

00:25:28.010 --> 00:25:29.260
I could refresh the page.

00:25:29.260 --> 00:25:30.720
It's not going to
matter because we

00:25:30.720 --> 00:25:32.240
haven't told it to do anything.

00:25:32.240 --> 00:25:33.970
We haven't told it to update.

00:25:33.970 --> 00:25:35.400
So while that's
actually pushing,

00:25:35.400 --> 00:25:37.200
because it takes a
little bit of time,

00:25:37.200 --> 00:25:40.300
I'm just going to show
you that indeed we

00:25:40.300 --> 00:25:42.190
are still serving up kitten.jpg.

00:25:44.320 --> 00:25:46.470
In fact, if we
take this away you

00:25:46.470 --> 00:25:50.360
can see that we're running
Nginx inside our container.

00:25:52.230 --> 00:25:52.940
So let's see.

00:25:52.940 --> 00:25:55.760
We're on most in
there, anticipating

00:25:55.760 --> 00:25:56.790
just a couple minutes.

00:25:57.950 --> 00:25:59.940
Not a minute, like
a couple seconds.

00:25:59.940 --> 00:26:01.340
That would be insane.

00:26:01.340 --> 00:26:03.190
And we've finished.

00:26:03.190 --> 00:26:06.760
Now we can go ahead and interact
with Kubernetes to update.

00:26:08.870 --> 00:26:13.590
So I've created a link to my
command line to this utility

00:26:13.590 --> 00:26:15.500
and I'm going to do
a rolling update.

00:26:15.500 --> 00:26:17.462
As anybody who's done
production updates,

00:26:17.462 --> 00:26:18.920
you don't want to
do it all at once

00:26:18.920 --> 00:26:20.253
because everything will go down.

00:26:21.270 --> 00:26:23.750
It's generally regarded
as a bad thing.

00:26:23.750 --> 00:26:24.894
Generally.

00:26:24.894 --> 00:26:27.060
So we're going to interact
with the data controller,

00:26:27.060 --> 00:26:30.450
and we're going to do an
update interval of 10 seconds.

00:26:30.450 --> 00:26:32.940
It is also way too
fast for production.

00:26:32.940 --> 00:26:34.960
Everything will go
down if you do this.

00:26:34.960 --> 00:26:37.460
However, since I've got less
than five minutes to go,

00:26:37.460 --> 00:26:39.970
I'm going to go ahead and
live life on the edge.

00:26:41.880 --> 00:26:44.340
It's going to interact
with the Kubernetes API.

00:26:44.340 --> 00:26:47.720
We're going to go back here
and you can see already

00:26:47.720 --> 00:26:50.620
that we have containers
dropping off.

00:26:53.080 --> 00:26:56.180
As they come back
up, hopefully will

00:26:56.180 --> 00:27:00.810
be serving an image that
will contribute to my plan

00:27:00.810 --> 00:27:03.880
to replace all pictures
of cats on the internet

00:27:03.880 --> 00:27:05.195
with pictures of a nautilus.

00:27:06.912 --> 00:27:07.620
Sorry cat people.

00:27:09.630 --> 00:27:10.690
I apologize.

00:27:10.690 --> 00:27:15.740
So you see again, because our
update interval is so short,

00:27:15.740 --> 00:27:18.870
we do not have all of
our containers running

00:27:18.870 --> 00:27:20.687
at once, all of our
pods running at once.

00:27:20.687 --> 00:27:22.770
Clearly you want to do
something a little bit more

00:27:22.770 --> 00:27:24.600
sane as your update interval.

00:27:25.950 --> 00:27:28.995
Once it comes back up it
will pull down the image.

00:27:30.660 --> 00:27:32.060
We've got the pods running.

00:27:32.060 --> 00:27:34.560
It hasn't yet started serving.

00:27:34.560 --> 00:27:37.115
That will come back
as things progress.

00:27:40.340 --> 00:27:41.910
That will happen
in the background.

00:27:41.910 --> 00:27:44.110
I do just want to show you
that we can, actually--

00:27:44.110 --> 00:27:46.690
because these are just Compute
Engine virtual machines--

00:27:46.690 --> 00:27:48.830
we can ssh into the vm's.

00:27:48.830 --> 00:27:50.080
So let's go ahead and do that.

00:27:51.120 --> 00:27:57.110
Let's ssh into Kubernetes
minion-- ha ha ha,

00:27:57.110 --> 00:27:59.570
the thread is complete-- one.

00:27:59.570 --> 00:28:01.130
I've always wanted a minion.

00:28:01.130 --> 00:28:02.630
This is why I went
to grad school.

00:28:02.630 --> 00:28:03.338
I wanted minions.

00:28:05.480 --> 00:28:08.110
We're now inside of
a Kubernetes minion.

00:28:08.110 --> 00:28:10.650
As you can see, my command
prompt completely changed

00:28:10.650 --> 00:28:12.233
because I'm running
a different shell.

00:28:13.280 --> 00:28:15.440
We can take a look
at what's going on.

00:28:16.520 --> 00:28:18.970
Let's do sudo docker ps.

00:28:18.970 --> 00:28:24.250
And you can see, oh, because
it's such big font here,

00:28:24.250 --> 00:28:26.700
but this is our Nginx server.

00:28:26.700 --> 00:28:27.800
You can see.

00:28:27.800 --> 00:28:28.680
We've got that.

00:28:30.410 --> 00:28:33.400
Now remember that
that started with bd8.

00:28:33.400 --> 00:28:33.900
OK?

00:28:34.691 --> 00:28:35.690
So I'm going to kill it.

00:28:40.360 --> 00:28:43.080
That's pretty much all you get
when you kill a Docker process.

00:28:43.080 --> 00:28:45.605
So let's go back and do a ps.

00:28:47.550 --> 00:28:50.920
Now you can see the
Nginx is not there.

00:28:50.920 --> 00:28:55.590
But hey, didn't we say we wanted
four running at any given time?

00:28:55.590 --> 00:28:57.030
So shouldn't it come back up?

00:28:58.630 --> 00:29:00.180
And, in fact, it did.

00:29:00.180 --> 00:29:01.500
And now it starts with ea9.

00:29:03.470 --> 00:29:07.190
We have satisfied the replica
controller's requirements.

00:29:07.190 --> 00:29:10.210
It monitored, it fixed,
and we're good to go.

00:29:11.310 --> 00:29:13.910
So if we could switch back
to the slides, please?

00:29:16.280 --> 00:29:18.380
So that's kind of the
magic that is Kubernetes.

00:29:19.400 --> 00:29:20.960
It's a great open
source project.

00:29:20.960 --> 00:29:23.700
We're excited to see
where it goes next.

00:29:23.700 --> 00:29:29.669
So in summary, we've had a lot
of experiences over the last 10

00:29:29.669 --> 00:29:30.585
years with containers.

00:29:32.130 --> 00:29:36.550
Kubernetes is really our effort
to bring those experiences out

00:29:36.550 --> 00:29:38.570
into the open source
community, as well

00:29:38.570 --> 00:29:41.790
as get other experiences
and other use cases.

00:29:41.790 --> 00:29:44.120
So tell us what you
want to see out of it.

00:29:44.120 --> 00:29:48.380
File bugs, file issues,
and send us pull requests.

00:29:49.640 --> 00:29:50.640
We're happy to see them.

00:29:51.680 --> 00:29:53.710
Here are just some resources.

00:29:53.710 --> 00:29:55.640
This is our
Kubernetes repository,

00:29:55.640 --> 00:29:57.970
our container optimized
virtual machine images.

00:29:59.890 --> 00:30:00.699
We're on Free Node.

00:30:00.699 --> 00:30:02.990
So if you want to chat with
us, it's Google-containers.

00:30:04.730 --> 00:30:06.510
Thanks everyone.

