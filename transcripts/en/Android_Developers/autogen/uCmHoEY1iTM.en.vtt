WEBVTT
Kind: captions
Language: en

00:00:01.550 --> 00:00:03.649 align:start position:0%
 
let's<00:00:02.550><c> be</c><00:00:02.730><c> honest</c><00:00:03.120><c> you're</c><00:00:03.389><c> an</c><00:00:03.480><c> awesome</c>

00:00:03.649 --> 00:00:03.659 align:start position:0%
let's be honest you're an awesome
 

00:00:03.659 --> 00:00:05.809 align:start position:0%
let's be honest you're an awesome
engineer<00:00:04.259><c> with</c><00:00:04.440><c> an</c><00:00:04.560><c> awesome</c><00:00:04.950><c> app</c><00:00:05.130><c> and</c><00:00:05.400><c> you</c><00:00:05.640><c> are</c>

00:00:05.809 --> 00:00:05.819 align:start position:0%
engineer with an awesome app and you are
 

00:00:05.819 --> 00:00:07.909 align:start position:0%
engineer with an awesome app and you are
using<00:00:06.060><c> threading</c><00:00:06.569><c> to</c><00:00:06.690><c> the</c><00:00:06.779><c> max</c><00:00:07.020><c> sadly</c><00:00:07.770><c> though</c>

00:00:07.909 --> 00:00:07.919 align:start position:0%
using threading to the max sadly though
 

00:00:07.919 --> 00:00:09.620 align:start position:0%
using threading to the max sadly though
managing<00:00:08.519><c> all</c><00:00:08.610><c> those</c><00:00:08.760><c> individual</c><00:00:09.330><c> threads</c>

00:00:09.620 --> 00:00:09.630 align:start position:0%
managing all those individual threads
 

00:00:09.630 --> 00:00:10.970 align:start position:0%
managing all those individual threads
and<00:00:09.780><c> assigning</c><00:00:10.080><c> work</c><00:00:10.380><c> between</c><00:00:10.620><c> them</c><00:00:10.830><c> is</c>

00:00:10.970 --> 00:00:10.980 align:start position:0%
and assigning work between them is
 

00:00:10.980 --> 00:00:13.100 align:start position:0%
and assigning work between them is
causing<00:00:11.370><c> you</c><00:00:11.460><c> to</c><00:00:11.580><c> lose</c><00:00:11.730><c> your</c><00:00:11.969><c> hair</c><00:00:12.269><c> my</c><00:00:12.809><c> name</c><00:00:12.960><c> is</c>

00:00:13.100 --> 00:00:13.110 align:start position:0%
causing you to lose your hair my name is
 

00:00:13.110 --> 00:00:15.289 align:start position:0%
causing you to lose your hair my name is
Colt<00:00:13.290><c> McAnlis</c><00:00:13.349><c> and</c><00:00:13.830><c> please</c><00:00:14.099><c> don't</c><00:00:14.910><c> join</c><00:00:15.150><c> the</c>

00:00:15.289 --> 00:00:15.299 align:start position:0%
Colt McAnlis and please don't join the
 

00:00:15.299 --> 00:00:17.480 align:start position:0%
Colt McAnlis and please don't join the
bald<00:00:15.540><c> Club</c><00:00:15.839><c> instead</c><00:00:16.049><c> use</c><00:00:16.770><c> the</c><00:00:16.800><c> thread</c><00:00:17.220><c> pools</c>

00:00:17.480 --> 00:00:17.490 align:start position:0%
bald Club instead use the thread pools
 

00:00:17.490 --> 00:00:19.099 align:start position:0%
bald Club instead use the thread pools
class<00:00:17.789><c> which</c><00:00:18.000><c> is</c><00:00:18.119><c> an</c><00:00:18.210><c> ideal</c><00:00:18.510><c> primitive</c><00:00:18.990><c> for</c>

00:00:19.099 --> 00:00:19.109 align:start position:0%
class which is an ideal primitive for
 

00:00:19.109 --> 00:00:20.990 align:start position:0%
class which is an ideal primitive for
breaking<00:00:19.350><c> up</c><00:00:19.470><c> lots</c><00:00:19.710><c> of</c><00:00:19.859><c> work</c><00:00:20.039><c> into</c><00:00:20.310><c> little</c>

00:00:20.990 --> 00:00:21.000 align:start position:0%
breaking up lots of work into little
 

00:00:21.000 --> 00:00:22.790 align:start position:0%
breaking up lots of work into little
buckets<00:00:21.539><c> see</c><00:00:22.020><c> historically</c><00:00:22.529><c> it</c><00:00:22.740><c> was</c>

00:00:22.790 --> 00:00:22.800 align:start position:0%
buckets see historically it was
 

00:00:22.800 --> 00:00:24.290 align:start position:0%
buckets see historically it was
commonplace<00:00:23.340><c> that</c><00:00:23.490><c> applications</c><00:00:24.000><c> would</c><00:00:24.180><c> use</c>

00:00:24.290 --> 00:00:24.300 align:start position:0%
commonplace that applications would use
 

00:00:24.300 --> 00:00:27.349 align:start position:0%
commonplace that applications would use
a<00:00:24.330><c> dedicated</c><00:00:24.960><c> thread</c><00:00:25.890><c> model</c><00:00:26.400><c> that</c><00:00:26.760><c> is</c><00:00:26.880><c> one</c>

00:00:27.349 --> 00:00:27.359 align:start position:0%
a dedicated thread model that is one
 

00:00:27.359 --> 00:00:28.700 align:start position:0%
a dedicated thread model that is one
thread<00:00:27.660><c> that</c><00:00:27.779><c> only</c><00:00:27.930><c> deals</c><00:00:28.170><c> with</c><00:00:28.289><c> database</c>

00:00:28.700 --> 00:00:28.710 align:start position:0%
thread that only deals with database
 

00:00:28.710 --> 00:00:30.050 align:start position:0%
thread that only deals with database
rights<00:00:28.980><c> while</c><00:00:29.220><c> a</c><00:00:29.250><c> separate</c><00:00:29.609><c> thread</c><00:00:29.789><c> only</c>

00:00:30.050 --> 00:00:30.060 align:start position:0%
rights while a separate thread only
 

00:00:30.060 --> 00:00:31.429 align:start position:0%
rights while a separate thread only
handles<00:00:30.359><c> streaming</c><00:00:30.660><c> of</c><00:00:30.750><c> music</c><00:00:31.050><c> and</c><00:00:31.170><c> a</c><00:00:31.230><c> third</c>

00:00:31.429 --> 00:00:31.439 align:start position:0%
handles streaming of music and a third
 

00:00:31.439 --> 00:00:33.950 align:start position:0%
handles streaming of music and a third
one<00:00:31.619><c> only</c><00:00:31.859><c> handles</c><00:00:32.730><c> networking</c><00:00:33.300><c> these</c><00:00:33.630><c> setups</c>

00:00:33.950 --> 00:00:33.960 align:start position:0%
one only handles networking these setups
 

00:00:33.960 --> 00:00:36.020 align:start position:0%
one only handles networking these setups
are<00:00:34.079><c> okay</c><00:00:34.530><c> because</c><00:00:35.070><c> the</c><00:00:35.309><c> amount</c><00:00:35.489><c> of</c><00:00:35.550><c> work</c><00:00:35.760><c> per</c>

00:00:36.020 --> 00:00:36.030 align:start position:0%
are okay because the amount of work per
 

00:00:36.030 --> 00:00:38.030 align:start position:0%
are okay because the amount of work per
thread<00:00:36.300><c> isn't</c><00:00:36.540><c> that</c><00:00:36.750><c> large</c><00:00:36.989><c> and</c><00:00:37.350><c> it's</c><00:00:37.590><c> okay</c><00:00:37.980><c> to</c>

00:00:38.030 --> 00:00:38.040 align:start position:0%
thread isn't that large and it's okay to
 

00:00:38.040 --> 00:00:40.250 align:start position:0%
thread isn't that large and it's okay to
handle<00:00:38.430><c> this</c><00:00:38.550><c> work</c><00:00:38.760><c> in</c><00:00:38.969><c> sequential</c><00:00:39.450><c> order</c><00:00:39.750><c> but</c>

00:00:40.250 --> 00:00:40.260 align:start position:0%
handle this work in sequential order but
 

00:00:40.260 --> 00:00:42.200 align:start position:0%
handle this work in sequential order but
there<00:00:40.649><c> reaches</c><00:00:41.040><c> a</c><00:00:41.070><c> point</c><00:00:41.460><c> where</c><00:00:41.910><c> this</c><00:00:42.030><c> model</c>

00:00:42.200 --> 00:00:42.210 align:start position:0%
there reaches a point where this model
 

00:00:42.210 --> 00:00:43.700 align:start position:0%
there reaches a point where this model
starts<00:00:42.600><c> to</c><00:00:42.719><c> fall</c><00:00:42.870><c> over</c><00:00:43.170><c> say</c><00:00:43.469><c> for</c><00:00:43.680><c> example</c>

00:00:43.700 --> 00:00:43.710 align:start position:0%
starts to fall over say for example
 

00:00:43.710 --> 00:00:46.310 align:start position:0%
starts to fall over say for example
you've<00:00:44.250><c> got</c><00:00:44.280><c> 40</c><00:00:45.059><c> bitmaps</c><00:00:45.480><c> to</c><00:00:45.570><c> decode</c><00:00:45.989><c> and</c><00:00:46.170><c> each</c>

00:00:46.310 --> 00:00:46.320 align:start position:0%
you've got 40 bitmaps to decode and each
 

00:00:46.320 --> 00:00:48.799 align:start position:0%
you've got 40 bitmaps to decode and each
decode<00:00:46.800><c> takes</c><00:00:47.100><c> like</c><00:00:47.340><c> four</c><00:00:47.850><c> milliseconds</c><00:00:48.690><c> or</c>

00:00:48.799 --> 00:00:48.809 align:start position:0%
decode takes like four milliseconds or
 

00:00:48.809 --> 00:00:50.330 align:start position:0%
decode takes like four milliseconds or
something<00:00:49.110><c> and</c><00:00:49.289><c> putting</c><00:00:49.590><c> all</c><00:00:49.770><c> of</c><00:00:49.800><c> this</c><00:00:50.010><c> work</c>

00:00:50.330 --> 00:00:50.340 align:start position:0%
something and putting all of this work
 

00:00:50.340 --> 00:00:52.700 align:start position:0%
something and putting all of this work
on<00:00:50.460><c> a</c><00:00:50.579><c> single</c><00:00:51.300><c> dedicated</c><00:00:51.629><c> thread</c><00:00:52.230><c> is</c><00:00:52.410><c> a</c><00:00:52.440><c> bad</c>

00:00:52.700 --> 00:00:52.710 align:start position:0%
on a single dedicated thread is a bad
 

00:00:52.710 --> 00:00:54.920 align:start position:0%
on a single dedicated thread is a bad
idea<00:00:52.739><c> since</c><00:00:53.579><c> it'll</c><00:00:53.850><c> take</c><00:00:54.030><c> 80</c><00:00:54.300><c> milliseconds</c>

00:00:54.920 --> 00:00:54.930 align:start position:0%
idea since it'll take 80 milliseconds
 

00:00:54.930 --> 00:00:56.479 align:start position:0%
idea since it'll take 80 milliseconds
total<00:00:55.199><c> to</c><00:00:55.289><c> get</c><00:00:55.410><c> all</c><00:00:55.500><c> that</c><00:00:55.620><c> work</c><00:00:55.829><c> done</c><00:00:55.860><c> in</c><00:00:56.340><c> a</c>

00:00:56.479 --> 00:00:56.489 align:start position:0%
total to get all that work done in a
 

00:00:56.489 --> 00:00:58.670 align:start position:0%
total to get all that work done in a
sequential<00:00:56.969><c> fashion</c><00:00:57.149><c> on</c><00:00:57.660><c> the</c><00:00:57.719><c> other</c><00:00:58.230><c> hand</c><00:00:58.530><c> if</c>

00:00:58.670 --> 00:00:58.680 align:start position:0%
sequential fashion on the other hand if
 

00:00:58.680 --> 00:01:00.470 align:start position:0%
sequential fashion on the other hand if
you<00:00:58.770><c> created</c><00:00:59.129><c> 10</c><00:00:59.370><c> threads</c><00:00:59.699><c> and</c><00:00:59.940><c> let</c><00:01:00.300><c> each</c><00:01:00.449><c> one</c>

00:01:00.470 --> 00:01:00.480 align:start position:0%
you created 10 threads and let each one
 

00:01:00.480 --> 00:01:02.420 align:start position:0%
you created 10 threads and let each one
decode<00:01:01.079><c> four</c><00:01:01.350><c> bitmaps</c><00:01:01.739><c> then</c><00:01:02.070><c> you'd</c><00:01:02.190><c> end</c><00:01:02.370><c> up</c>

00:01:02.420 --> 00:01:02.430 align:start position:0%
decode four bitmaps then you'd end up
 

00:01:02.430 --> 00:01:04.969 align:start position:0%
decode four bitmaps then you'd end up
only<00:01:02.730><c> taking</c><00:01:03.030><c> 16</c><00:01:03.539><c> milliseconds</c><00:01:04.320><c> total</c><00:01:04.589><c> but</c>

00:01:04.969 --> 00:01:04.979 align:start position:0%
only taking 16 milliseconds total but
 

00:01:04.979 --> 00:01:06.140 align:start position:0%
only taking 16 milliseconds total but
then<00:01:05.159><c> of</c><00:01:05.309><c> course</c><00:01:05.339><c> you</c><00:01:05.549><c> run</c><00:01:05.760><c> into</c><00:01:05.970><c> the</c><00:01:06.060><c> problem</c>

00:01:06.140 --> 00:01:06.150 align:start position:0%
then of course you run into the problem
 

00:01:06.150 --> 00:01:08.240 align:start position:0%
then of course you run into the problem
of<00:01:06.420><c> how</c><00:01:06.510><c> to</c><00:01:06.540><c> properly</c><00:01:06.750><c> pass</c><00:01:07.500><c> the</c><00:01:07.740><c> workaround</c>

00:01:08.240 --> 00:01:08.250 align:start position:0%
of how to properly pass the workaround
 

00:01:08.250 --> 00:01:09.890 align:start position:0%
of how to properly pass the workaround
between<00:01:08.610><c> those</c><00:01:08.760><c> threads</c><00:01:09.000><c> schedule</c><00:01:09.510><c> that</c><00:01:09.659><c> work</c>

00:01:09.890 --> 00:01:09.900 align:start position:0%
between those threads schedule that work
 

00:01:09.900 --> 00:01:11.469 align:start position:0%
between those threads schedule that work
and<00:01:10.080><c> then</c><00:01:10.200><c> managing</c><00:01:10.619><c> of</c><00:01:10.740><c> those</c><00:01:10.860><c> threads</c><00:01:11.130><c> and</c>

00:01:11.469 --> 00:01:11.479 align:start position:0%
and then managing of those threads and
 

00:01:11.479 --> 00:01:13.460 align:start position:0%
and then managing of those threads and
before<00:01:12.479><c> you</c><00:01:12.659><c> start</c><00:01:12.720><c> stressing</c><00:01:13.170><c> out</c><00:01:13.439><c> about</c>

00:01:13.460 --> 00:01:13.470 align:start position:0%
before you start stressing out about
 

00:01:13.470 --> 00:01:15.830 align:start position:0%
before you start stressing out about
writing<00:01:13.950><c> all</c><00:01:14.070><c> that</c><00:01:14.220><c> code</c><00:01:14.460><c> don't</c><00:01:14.880><c> worry</c><00:01:15.390><c> this</c>

00:01:15.830 --> 00:01:15.840 align:start position:0%
writing all that code don't worry this
 

00:01:15.840 --> 00:01:18.590 align:start position:0%
writing all that code don't worry this
is<00:01:16.080><c> exactly</c><00:01:16.680><c> what</c><00:01:16.979><c> thread</c><00:01:17.460><c> pool</c><00:01:17.880><c> executors</c>

00:01:18.590 --> 00:01:18.600 align:start position:0%
is exactly what thread pool executors
 

00:01:18.600 --> 00:01:20.899 align:start position:0%
is exactly what thread pool executors
primitive<00:01:19.020><c> is</c><00:01:19.170><c> for</c><00:01:19.560><c> basically</c><00:01:20.159><c> this</c><00:01:20.640><c> class</c>

00:01:20.899 --> 00:01:20.909 align:start position:0%
primitive is for basically this class
 

00:01:20.909 --> 00:01:22.399 align:start position:0%
primitive is for basically this class
will<00:01:21.210><c> just</c><00:01:21.450><c> let</c><00:01:21.570><c> you</c><00:01:21.659><c> spin</c><00:01:21.869><c> up</c><00:01:21.990><c> a</c><00:01:22.080><c> number</c><00:01:22.259><c> of</c>

00:01:22.399 --> 00:01:22.409 align:start position:0%
will just let you spin up a number of
 

00:01:22.409 --> 00:01:24.469 align:start position:0%
will just let you spin up a number of
threads<00:01:22.650><c> and</c><00:01:22.860><c> toss</c><00:01:23.310><c> blocks</c><00:01:23.850><c> of</c><00:01:24.060><c> work</c><00:01:24.299><c> to</c>

00:01:24.469 --> 00:01:24.479 align:start position:0%
threads and toss blocks of work to
 

00:01:24.479 --> 00:01:26.539 align:start position:0%
threads and toss blocks of work to
execute<00:01:24.960><c> on</c><00:01:25.080><c> it</c><00:01:25.110><c> thread</c><00:01:25.770><c> pool</c><00:01:26.009><c> executor</c>

00:01:26.539 --> 00:01:26.549 align:start position:0%
execute on it thread pool executor
 

00:01:26.549 --> 00:01:28.070 align:start position:0%
execute on it thread pool executor
handles<00:01:26.880><c> all</c><00:01:27.060><c> of</c><00:01:27.210><c> the</c><00:01:27.299><c> heavy</c><00:01:27.540><c> lifting</c><00:01:27.990><c> of</c>

00:01:28.070 --> 00:01:28.080 align:start position:0%
handles all of the heavy lifting of
 

00:01:28.080 --> 00:01:30.200 align:start position:0%
handles all of the heavy lifting of
spinning<00:01:28.530><c> up</c><00:01:28.619><c> the</c><00:01:28.770><c> threads</c><00:01:29.040><c> load</c><00:01:29.610><c> balancing</c>

00:01:30.200 --> 00:01:30.210 align:start position:0%
spinning up the threads load balancing
 

00:01:30.210 --> 00:01:31.789 align:start position:0%
spinning up the threads load balancing
work<00:01:30.479><c> across</c><00:01:30.840><c> those</c><00:01:31.200><c> threads</c><00:01:31.439><c> and</c><00:01:31.560><c> even</c>

00:01:31.789 --> 00:01:31.799 align:start position:0%
work across those threads and even
 

00:01:31.799 --> 00:01:33.469 align:start position:0%
work across those threads and even
killing<00:01:32.130><c> those</c><00:01:32.369><c> threads</c><00:01:32.670><c> when</c><00:01:33.119><c> they</c><00:01:33.299><c> have</c>

00:01:33.469 --> 00:01:33.479 align:start position:0%
killing those threads when they have
 

00:01:33.479 --> 00:01:35.480 align:start position:0%
killing those threads when they have
been<00:01:33.630><c> idle</c><00:01:33.990><c> for</c><00:01:34.020><c> a</c><00:01:34.229><c> while</c><00:01:34.470><c> basically</c><00:01:34.950><c> it</c>

00:01:35.480 --> 00:01:35.490 align:start position:0%
been idle for a while basically it
 

00:01:35.490 --> 00:01:37.039 align:start position:0%
been idle for a while basically it
handles<00:01:35.850><c> all</c><00:01:36.000><c> the</c><00:01:36.030><c> heavy</c><00:01:36.270><c> lifting</c><00:01:36.659><c> of</c><00:01:36.720><c> super</c>

00:01:37.039 --> 00:01:37.049 align:start position:0%
handles all the heavy lifting of super
 

00:01:37.049 --> 00:01:39.020 align:start position:0%
handles all the heavy lifting of super
parallel<00:01:37.439><c> processing</c><00:01:37.920><c> on</c><00:01:38.040><c> your</c><00:01:38.280><c> behalf</c><00:01:38.640><c> all</c>

00:01:39.020 --> 00:01:39.030 align:start position:0%
parallel processing on your behalf all
 

00:01:39.030 --> 00:01:40.850 align:start position:0%
parallel processing on your behalf all
you<00:01:39.299><c> have</c><00:01:39.390><c> to</c><00:01:39.509><c> do</c><00:01:39.630><c> is</c><00:01:39.750><c> split</c><00:01:39.960><c> up</c><00:01:40.020><c> the</c><00:01:40.200><c> work</c><00:01:40.350><c> but</c>

00:01:40.850 --> 00:01:40.860 align:start position:0%
you have to do is split up the work but
 

00:01:40.860 --> 00:01:43.190 align:start position:0%
you have to do is split up the work but
there's<00:01:41.189><c> a</c><00:01:41.310><c> small</c><00:01:41.700><c> caveat</c><00:01:42.090><c> here</c><00:01:42.420><c> how</c><00:01:43.020><c> many</c>

00:01:43.190 --> 00:01:43.200 align:start position:0%
there's a small caveat here how many
 

00:01:43.200 --> 00:01:45.440 align:start position:0%
there's a small caveat here how many
threads<00:01:43.530><c> should</c><00:01:44.070><c> your</c><00:01:44.399><c> thread</c><00:01:44.729><c> pool</c><00:01:45.000><c> have</c><00:01:45.299><c> I</c>

00:01:45.440 --> 00:01:45.450 align:start position:0%
threads should your thread pool have I
 

00:01:45.450 --> 00:01:47.149 align:start position:0%
threads should your thread pool have I
mean<00:01:45.570><c> technically</c><00:01:46.200><c> speaking</c><00:01:46.590><c> you</c><00:01:46.920><c> have</c><00:01:47.070><c> the</c>

00:01:47.149 --> 00:01:47.159 align:start position:0%
mean technically speaking you have the
 

00:01:47.159 --> 00:01:48.469 align:start position:0%
mean technically speaking you have the
ability<00:01:47.460><c> to</c><00:01:47.490><c> create</c><00:01:47.759><c> as</c><00:01:47.820><c> many</c><00:01:47.909><c> threads</c><00:01:48.270><c> as</c><00:01:48.390><c> you</c>

00:01:48.469 --> 00:01:48.479 align:start position:0%
ability to create as many threads as you
 

00:01:48.479 --> 00:01:51.889 align:start position:0%
ability to create as many threads as you
want<00:01:48.720><c> but</c><00:01:48.960><c> that's</c><00:01:49.500><c> not</c><00:01:49.979><c> ideal</c><00:01:50.430><c> see</c><00:01:51.000><c> CPUs</c><00:01:51.689><c> can</c>

00:01:51.889 --> 00:01:51.899 align:start position:0%
want but that's not ideal see CPUs can
 

00:01:51.899 --> 00:01:53.630 align:start position:0%
want but that's not ideal see CPUs can
only<00:01:52.049><c> execute</c><00:01:52.380><c> a</c><00:01:52.619><c> certain</c><00:01:53.040><c> number</c><00:01:53.159><c> of</c><00:01:53.310><c> threads</c>

00:01:53.630 --> 00:01:53.640 align:start position:0%
only execute a certain number of threads
 

00:01:53.640 --> 00:01:55.789 align:start position:0%
only execute a certain number of threads
in<00:01:53.820><c> parallel</c><00:01:53.899><c> once</c><00:01:54.899><c> you</c><00:01:54.990><c> get</c><00:01:55.110><c> above</c><00:01:55.439><c> that</c>

00:01:55.789 --> 00:01:55.799 align:start position:0%
in parallel once you get above that
 

00:01:55.799 --> 00:01:57.560 align:start position:0%
in parallel once you get above that
number<00:01:56.070><c> then</c><00:01:56.520><c> the</c><00:01:56.640><c> CPU</c><00:01:57.060><c> has</c><00:01:57.270><c> to</c><00:01:57.360><c> start</c>

00:01:57.560 --> 00:01:57.570 align:start position:0%
number then the CPU has to start
 

00:01:57.570 --> 00:01:59.420 align:start position:0%
number then the CPU has to start
deciding<00:01:57.930><c> which</c><00:01:58.140><c> threads</c><00:01:58.500><c> get</c><00:01:58.710><c> the</c><00:01:58.860><c> next</c><00:01:59.189><c> free</c>

00:01:59.420 --> 00:01:59.430 align:start position:0%
deciding which threads get the next free
 

00:01:59.430 --> 00:02:01.580 align:start position:0%
deciding which threads get the next free
block<00:01:59.700><c> of</c><00:01:59.880><c> processor</c><00:02:00.360><c> time</c><00:02:00.540><c> based</c><00:02:01.200><c> on</c><00:02:01.409><c> how</c>

00:02:01.580 --> 00:02:01.590 align:start position:0%
block of processor time based on how
 

00:02:01.590 --> 00:02:03.920 align:start position:0%
block of processor time based on how
important<00:02:02.130><c> they</c><00:02:02.280><c> are</c><00:02:02.310><c> which</c><00:02:03.090><c> means</c><00:02:03.540><c> that</c><00:02:03.840><c> if</c>

00:02:03.920 --> 00:02:03.930 align:start position:0%
important they are which means that if
 

00:02:03.930 --> 00:02:05.899 align:start position:0%
important they are which means that if
you<00:02:03.960><c> keep</c><00:02:04.200><c> eventually</c><00:02:05.130><c> adding</c><00:02:05.549><c> threads</c>

00:02:05.899 --> 00:02:05.909 align:start position:0%
you keep eventually adding threads
 

00:02:05.909 --> 00:02:08.389 align:start position:0%
you keep eventually adding threads
you'll<00:02:06.390><c> hit</c><00:02:06.630><c> a</c><00:02:06.689><c> break-even</c><00:02:07.290><c> point</c><00:02:07.829><c> where</c><00:02:08.280><c> your</c>

00:02:08.389 --> 00:02:08.399 align:start position:0%
you'll hit a break-even point where your
 

00:02:08.399 --> 00:02:10.160 align:start position:0%
you'll hit a break-even point where your
computation<00:02:09.060><c> isn't</c><00:02:09.390><c> getting</c><00:02:09.569><c> any</c><00:02:09.690><c> faster</c>

00:02:10.160 --> 00:02:10.170 align:start position:0%
computation isn't getting any faster
 

00:02:10.170 --> 00:02:11.990 align:start position:0%
computation isn't getting any faster
even<00:02:10.410><c> though</c><00:02:10.770><c> the</c><00:02:10.979><c> number</c><00:02:11.280><c> of</c><00:02:11.310><c> threads</c><00:02:11.730><c> that</c>

00:02:11.990 --> 00:02:12.000 align:start position:0%
even though the number of threads that
 

00:02:12.000 --> 00:02:12.730 align:start position:0%
even though the number of threads that
you<00:02:12.150><c> have</c>

00:02:12.730 --> 00:02:12.740 align:start position:0%
you have
 

00:02:12.740 --> 00:02:14.890 align:start position:0%
you have
has<00:02:12.890><c> increased</c><00:02:13.550><c> significantly</c><00:02:14.120><c> and</c><00:02:14.390><c> it's</c>

00:02:14.890 --> 00:02:14.900 align:start position:0%
has increased significantly and it's
 

00:02:14.900 --> 00:02:16.090 align:start position:0%
has increased significantly and it's
also<00:02:15.050><c> important</c><00:02:15.500><c> to</c><00:02:15.590><c> note</c><00:02:15.740><c> that</c><00:02:15.770><c> each</c><00:02:16.070><c> of</c>

00:02:16.090 --> 00:02:16.100 align:start position:0%
also important to note that each of
 

00:02:16.100 --> 00:02:19.000 align:start position:0%
also important to note that each of
these<00:02:16.370><c> threads</c><00:02:16.820><c> aren't</c><00:02:17.540><c> free</c><00:02:18.050><c> each</c><00:02:18.680><c> thread</c>

00:02:19.000 --> 00:02:19.010 align:start position:0%
these threads aren't free each thread
 

00:02:19.010 --> 00:02:21.190 align:start position:0%
these threads aren't free each thread
cost<00:02:19.250><c> you</c><00:02:19.310><c> about</c><00:02:19.400><c> 64k</c><00:02:20.120><c> of</c><00:02:20.240><c> memory</c><00:02:20.570><c> and</c><00:02:20.750><c> minimum</c>

00:02:21.190 --> 00:02:21.200 align:start position:0%
cost you about 64k of memory and minimum
 

00:02:21.200 --> 00:02:23.050 align:start position:0%
cost you about 64k of memory and minimum
and<00:02:21.290><c> that</c><00:02:21.380><c> adds</c><00:02:21.920><c> up</c><00:02:22.190><c> quickly</c><00:02:22.460><c> especially</c><00:02:22.760><c> in</c>

00:02:23.050 --> 00:02:23.060 align:start position:0%
and that adds up quickly especially in
 

00:02:23.060 --> 00:02:24.760 align:start position:0%
and that adds up quickly especially in
situations<00:02:23.570><c> where</c><00:02:23.720><c> the</c><00:02:23.810><c> call</c><00:02:24.050><c> stacks</c><00:02:24.380><c> can</c>

00:02:24.760 --> 00:02:24.770 align:start position:0%
situations where the call stacks can
 

00:02:24.770 --> 00:02:27.370 align:start position:0%
situations where the call stacks can
start<00:02:25.010><c> growing</c><00:02:25.460><c> pretty</c><00:02:25.820><c> large</c><00:02:26.210><c> as</c><00:02:26.510><c> such</c><00:02:27.050><c> your</c>

00:02:27.370 --> 00:02:27.380 align:start position:0%
start growing pretty large as such your
 

00:02:27.380 --> 00:02:28.810 align:start position:0%
start growing pretty large as such your
app<00:02:27.530><c> needs</c><00:02:27.830><c> to</c><00:02:27.920><c> find</c><00:02:28.160><c> a</c><00:02:28.220><c> sweet</c><00:02:28.400><c> spot</c><00:02:28.640><c> between</c>

00:02:28.810 --> 00:02:28.820 align:start position:0%
app needs to find a sweet spot between
 

00:02:28.820 --> 00:02:30.580 align:start position:0%
app needs to find a sweet spot between
the<00:02:29.090><c> number</c><00:02:29.330><c> of</c><00:02:29.420><c> cores</c><00:02:29.690><c> and</c><00:02:29.930><c> the</c><00:02:30.260><c> point</c><00:02:30.500><c> of</c>

00:02:30.580 --> 00:02:30.590 align:start position:0%
the number of cores and the point of
 

00:02:30.590 --> 00:02:32.560 align:start position:0%
the number of cores and the point of
diminishing<00:02:30.980><c> return</c><00:02:31.310><c> with</c><00:02:31.820><c> the</c><00:02:32.060><c> number</c><00:02:32.360><c> of</c>

00:02:32.560 --> 00:02:32.570 align:start position:0%
diminishing return with the number of
 

00:02:32.570 --> 00:02:34.870 align:start position:0%
diminishing return with the number of
threads<00:02:32.960><c> thankfully</c><00:02:33.800><c> once</c><00:02:34.100><c> again</c><00:02:34.430><c> the</c><00:02:34.640><c> thread</c>

00:02:34.870 --> 00:02:34.880 align:start position:0%
threads thankfully once again the thread
 

00:02:34.880 --> 00:02:37.120 align:start position:0%
threads thankfully once again the thread
pool<00:02:35.060><c> executors</c><00:02:35.690><c> class</c><00:02:35.900><c> has</c><00:02:36.230><c> got</c><00:02:36.260><c> you</c><00:02:36.770><c> covered</c>

00:02:37.120 --> 00:02:37.130 align:start position:0%
pool executors class has got you covered
 

00:02:37.130 --> 00:02:39.190 align:start position:0%
pool executors class has got you covered
when<00:02:37.700><c> creating</c><00:02:37.970><c> your</c><00:02:38.210><c> thread</c><00:02:38.630><c> pool</c><00:02:38.870><c> you</c><00:02:39.050><c> can</c>

00:02:39.190 --> 00:02:39.200 align:start position:0%
when creating your thread pool you can
 

00:02:39.200 --> 00:02:41.080 align:start position:0%
when creating your thread pool you can
specify<00:02:39.410><c> the</c><00:02:39.680><c> number</c><00:02:40.040><c> of</c><00:02:40.220><c> initial</c><00:02:40.820><c> threads</c>

00:02:41.080 --> 00:02:41.090 align:start position:0%
specify the number of initial threads
 

00:02:41.090 --> 00:02:43.660 align:start position:0%
specify the number of initial threads
and<00:02:41.240><c> the</c><00:02:41.570><c> number</c><00:02:41.840><c> of</c><00:02:41.990><c> maximum</c><00:02:42.710><c> threads</c><00:02:43.040><c> as</c><00:02:43.190><c> the</c>

00:02:43.660 --> 00:02:43.670 align:start position:0%
and the number of maximum threads as the
 

00:02:43.670 --> 00:02:45.220 align:start position:0%
and the number of maximum threads as the
workload<00:02:43.940><c> in</c><00:02:44.240><c> the</c><00:02:44.330><c> thread</c><00:02:44.540><c> pool</c><00:02:44.690><c> changes</c>

00:02:45.220 --> 00:02:45.230 align:start position:0%
workload in the thread pool changes
 

00:02:45.230 --> 00:02:47.080 align:start position:0%
workload in the thread pool changes
it'll<00:02:45.440><c> scale</c><00:02:45.890><c> the</c><00:02:46.100><c> number</c><00:02:46.130><c> of</c><00:02:46.340><c> alive</c><00:02:46.700><c> threads</c>

00:02:47.080 --> 00:02:47.090 align:start position:0%
it'll scale the number of alive threads
 

00:02:47.090 --> 00:02:49.750 align:start position:0%
it'll scale the number of alive threads
to<00:02:47.510><c> match</c><00:02:47.690><c> oh</c><00:02:47.930><c> and</c><00:02:48.230><c> a</c><00:02:48.350><c> quick</c><00:02:48.770><c> note</c><00:02:48.800><c> the</c><00:02:49.340><c> value</c>

00:02:49.750 --> 00:02:49.760 align:start position:0%
to match oh and a quick note the value
 

00:02:49.760 --> 00:02:51.790 align:start position:0%
to match oh and a quick note the value
returned<00:02:50.270><c> from</c><00:02:50.540><c> get</c><00:02:50.780><c> available</c><00:02:51.290><c> processors</c>

00:02:51.790 --> 00:02:51.800 align:start position:0%
returned from get available processors
 

00:02:51.800 --> 00:02:53.770 align:start position:0%
returned from get available processors
may<00:02:52.220><c> not</c><00:02:52.430><c> reflect</c><00:02:52.700><c> the</c><00:02:52.910><c> number</c><00:02:53.270><c> of</c><00:02:53.420><c> physical</c>

00:02:53.770 --> 00:02:53.780 align:start position:0%
may not reflect the number of physical
 

00:02:53.780 --> 00:02:56.050 align:start position:0%
may not reflect the number of physical
cores<00:02:54.140><c> in</c><00:02:54.440><c> the</c><00:02:54.470><c> device</c><00:02:54.830><c> see</c><00:02:55.460><c> some</c><00:02:55.730><c> devices</c>

00:02:56.050 --> 00:02:56.060 align:start position:0%
cores in the device see some devices
 

00:02:56.060 --> 00:02:58.270 align:start position:0%
cores in the device see some devices
have<00:02:56.270><c> CPUs</c><00:02:56.840><c> that</c><00:02:56.870><c> will</c><00:02:57.170><c> deactivate</c><00:02:57.890><c> one</c><00:02:57.920><c> or</c>

00:02:58.270 --> 00:02:58.280 align:start position:0%
have CPUs that will deactivate one or
 

00:02:58.280 --> 00:03:00.340 align:start position:0%
have CPUs that will deactivate one or
more<00:02:58.430><c> cores</c><00:02:58.760><c> depending</c><00:02:59.600><c> on</c><00:02:59.720><c> the</c><00:02:59.810><c> system</c><00:03:00.170><c> load</c>

00:03:00.340 --> 00:03:00.350 align:start position:0%
more cores depending on the system load
 

00:03:00.350 --> 00:03:01.990 align:start position:0%
more cores depending on the system load
to<00:03:00.530><c> save</c><00:03:00.710><c> battery</c><00:03:00.920><c> so</c><00:03:01.490><c> if</c><00:03:01.610><c> your</c><00:03:01.730><c> device</c><00:03:01.970><c> has</c>

00:03:01.990 --> 00:03:02.000 align:start position:0%
to save battery so if your device has
 

00:03:02.000 --> 00:03:04.480 align:start position:0%
to save battery so if your device has
two<00:03:02.480><c> CPUs</c><00:03:02.720><c> but</c><00:03:03.290><c> one</c><00:03:03.440><c> of</c><00:03:03.470><c> them</c><00:03:03.620><c> is</c><00:03:03.710><c> asleep</c><00:03:04.040><c> this</c>

00:03:04.480 --> 00:03:04.490 align:start position:0%
two CPUs but one of them is asleep this
 

00:03:04.490 --> 00:03:06.760 align:start position:0%
two CPUs but one of them is asleep this
value<00:03:04.790><c> could</c><00:03:04.910><c> return</c><00:03:05.240><c> one</c><00:03:05.810><c> and</c><00:03:06.080><c> of</c><00:03:06.560><c> course</c>

00:03:06.760 --> 00:03:06.770 align:start position:0%
value could return one and of course
 

00:03:06.770 --> 00:03:08.470 align:start position:0%
value could return one and of course
thread<00:03:07.040><c> pools</c><00:03:07.250><c> won't</c><00:03:07.520><c> solve</c><00:03:07.700><c> all</c><00:03:08.090><c> of</c><00:03:08.390><c> your</c>

00:03:08.470 --> 00:03:08.480 align:start position:0%
thread pools won't solve all of your
 

00:03:08.480 --> 00:03:10.330 align:start position:0%
thread pools won't solve all of your
threading<00:03:09.050><c> problems</c><00:03:09.500><c> as</c><00:03:09.710><c> mentioned</c><00:03:10.250><c> earlier</c>

00:03:10.330 --> 00:03:10.340 align:start position:0%
threading problems as mentioned earlier
 

00:03:10.340 --> 00:03:12.010 align:start position:0%
threading problems as mentioned earlier
unless<00:03:10.760><c> you're</c><00:03:11.090><c> dealing</c><00:03:11.330><c> with</c><00:03:11.450><c> lots</c><00:03:11.660><c> and</c><00:03:11.810><c> lots</c>

00:03:12.010 --> 00:03:12.020 align:start position:0%
unless you're dealing with lots and lots
 

00:03:12.020 --> 00:03:13.750 align:start position:0%
unless you're dealing with lots and lots
of<00:03:12.140><c> work</c><00:03:12.350><c> packets</c><00:03:12.800><c> all</c><00:03:12.950><c> the</c><00:03:13.070><c> time</c><00:03:13.250><c> this</c>

00:03:13.750 --> 00:03:13.760 align:start position:0%
of work packets all the time this
 

00:03:13.760 --> 00:03:16.090 align:start position:0%
of work packets all the time this
thing's<00:03:14.210><c> kind</c><00:03:14.540><c> of</c><00:03:14.630><c> overkill</c><00:03:15.230><c> it's</c><00:03:15.620><c> best</c><00:03:15.890><c> use</c>

00:03:16.090 --> 00:03:16.100 align:start position:0%
thing's kind of overkill it's best use
 

00:03:16.100 --> 00:03:17.830 align:start position:0%
thing's kind of overkill it's best use
things<00:03:16.340><c> like</c><00:03:16.430><c> handler</c><00:03:16.970><c> threads</c><00:03:17.270><c> or</c><00:03:17.450><c> async</c>

00:03:17.830 --> 00:03:17.840 align:start position:0%
things like handler threads or async
 

00:03:17.840 --> 00:03:20.200 align:start position:0%
things like handler threads or async
task<00:03:18.110><c> loader</c><00:03:18.290><c> for</c><00:03:18.920><c> specific</c><00:03:19.460><c> types</c><00:03:19.910><c> of</c><00:03:20.150><c> work</c>

00:03:20.200 --> 00:03:20.210 align:start position:0%
task loader for specific types of work
 

00:03:20.210 --> 00:03:22.300 align:start position:0%
task loader for specific types of work
blocks<00:03:20.840><c> and</c><00:03:21.050><c> only</c><00:03:21.470><c> throw</c><00:03:21.650><c> the</c><00:03:21.770><c> massive</c>

00:03:22.300 --> 00:03:22.310 align:start position:0%
blocks and only throw the massive
 

00:03:22.310 --> 00:03:24.220 align:start position:0%
blocks and only throw the massive
computing<00:03:22.760><c> problems</c><00:03:23.120><c> at</c><00:03:23.270><c> the</c><00:03:23.690><c> thread</c><00:03:23.960><c> pool</c>

00:03:24.220 --> 00:03:24.230 align:start position:0%
computing problems at the thread pool
 

00:03:24.230 --> 00:03:26.560 align:start position:0%
computing problems at the thread pool
and<00:03:24.590><c> for</c><00:03:25.190><c> you</c><00:03:25.370><c> power</c><00:03:25.700><c> users</c><00:03:26.210><c> out</c><00:03:26.360><c> there</c>

00:03:26.560 --> 00:03:26.570 align:start position:0%
and for you power users out there
 

00:03:26.570 --> 00:03:28.930 align:start position:0%
and for you power users out there
remember<00:03:27.140><c> that</c><00:03:27.260><c> renderscript</c><00:03:28.370><c> might</c><00:03:28.730><c> be</c><00:03:28.910><c> a</c>

00:03:28.930 --> 00:03:28.940 align:start position:0%
remember that renderscript might be a
 

00:03:28.940 --> 00:03:30.310 align:start position:0%
remember that renderscript might be a
better<00:03:29.150><c> alternative</c><00:03:29.210><c> to</c><00:03:29.780><c> large-scale</c>

00:03:30.310 --> 00:03:30.320 align:start position:0%
better alternative to large-scale
 

00:03:30.320 --> 00:03:32.230 align:start position:0%
better alternative to large-scale
parallel<00:03:30.740><c> work</c><00:03:31.160><c> on</c><00:03:31.310><c> android</c><00:03:31.700><c> devices</c><00:03:31.970><c> but</c>

00:03:32.230 --> 00:03:32.240 align:start position:0%
parallel work on android devices but
 

00:03:32.240 --> 00:03:35.050 align:start position:0%
parallel work on android devices but
that's<00:03:32.810><c> a</c><00:03:33.020><c> whole</c><00:03:33.530><c> separate</c><00:03:34.310><c> set</c><00:03:34.700><c> of</c><00:03:34.730><c> videos</c>

00:03:35.050 --> 00:03:35.060 align:start position:0%
that's a whole separate set of videos
 

00:03:35.060 --> 00:03:36.880 align:start position:0%
that's a whole separate set of videos
that<00:03:35.090><c> we</c><00:03:35.660><c> haven't</c><00:03:35.870><c> gotten</c><00:03:36.170><c> into</c><00:03:36.350><c> yet</c><00:03:36.590><c> and</c>

00:03:36.880 --> 00:03:36.890 align:start position:0%
that we haven't gotten into yet and
 

00:03:36.890 --> 00:03:38.620 align:start position:0%
that we haven't gotten into yet and
don't<00:03:37.280><c> forget</c><00:03:37.520><c> that</c><00:03:37.640><c> systrace</c><00:03:38.270><c> is</c><00:03:38.510><c> an</c>

00:03:38.620 --> 00:03:38.630 align:start position:0%
don't forget that systrace is an
 

00:03:38.630 --> 00:03:40.480 align:start position:0%
don't forget that systrace is an
amazingly<00:03:39.140><c> powerful</c><00:03:39.410><c> tool</c><00:03:39.860><c> that</c><00:03:40.070><c> lets</c><00:03:40.430><c> you</c>

00:03:40.480 --> 00:03:40.490 align:start position:0%
amazingly powerful tool that lets you
 

00:03:40.490 --> 00:03:42.250 align:start position:0%
amazingly powerful tool that lets you
visualize<00:03:40.670><c> how</c><00:03:41.210><c> work</c><00:03:41.480><c> is</c><00:03:41.600><c> flowing</c><00:03:42.110><c> through</c>

00:03:42.250 --> 00:03:42.260 align:start position:0%
visualize how work is flowing through
 

00:03:42.260 --> 00:03:44.050 align:start position:0%
visualize how work is flowing through
the<00:03:42.410><c> threads</c><00:03:42.710><c> in</c><00:03:42.920><c> your</c><00:03:42.950><c> application</c><00:03:43.760><c> it's</c><00:03:43.940><c> a</c>

00:03:44.050 --> 00:03:44.060 align:start position:0%
the threads in your application it's a
 

00:03:44.060 --> 00:03:45.970 align:start position:0%
the threads in your application it's a
great<00:03:44.630><c> way</c><00:03:44.870><c> to</c><00:03:44.900><c> validate</c><00:03:45.440><c> that</c><00:03:45.500><c> things</c><00:03:45.830><c> are</c>

00:03:45.970 --> 00:03:45.980 align:start position:0%
great way to validate that things are
 

00:03:45.980 --> 00:03:48.400 align:start position:0%
great way to validate that things are
working<00:03:46.310><c> as</c><00:03:46.430><c> intended</c><00:03:46.850><c> and</c><00:03:47.120><c> also</c><00:03:47.660><c> see</c><00:03:48.140><c> all</c><00:03:48.260><c> the</c>

00:03:48.400 --> 00:03:48.410 align:start position:0%
working as intended and also see all the
 

00:03:48.410 --> 00:03:50.020 align:start position:0%
working as intended and also see all the
other<00:03:48.530><c> crazy</c><00:03:49.130><c> threads</c><00:03:49.640><c> that</c><00:03:49.790><c> are</c><00:03:49.850><c> being</c>

00:03:50.020 --> 00:03:50.030 align:start position:0%
other crazy threads that are being
 

00:03:50.030 --> 00:03:52.720 align:start position:0%
other crazy threads that are being
worked<00:03:50.090><c> on</c><00:03:50.450><c> by</c><00:03:50.660><c> other</c><00:03:50.870><c> parts</c><00:03:51.260><c> of</c><00:03:51.350><c> your</c><00:03:51.830><c> app</c><00:03:52.070><c> and</c>

00:03:52.720 --> 00:03:52.730 align:start position:0%
worked on by other parts of your app and
 

00:03:52.730 --> 00:03:54.280 align:start position:0%
worked on by other parts of your app and
that's<00:03:52.970><c> the</c><00:03:53.300><c> trick</c><00:03:53.510><c> with</c><00:03:53.690><c> performance</c><00:03:54.170><c> isn't</c>

00:03:54.280 --> 00:03:54.290 align:start position:0%
that's the trick with performance isn't
 

00:03:54.290 --> 00:03:56.140 align:start position:0%
that's the trick with performance isn't
it<00:03:54.470><c> I</c><00:03:54.530><c> mean</c><00:03:54.650><c> you</c><00:03:54.980><c> can</c><00:03:55.010><c> make</c><00:03:55.250><c> assumptions</c><00:03:55.910><c> but</c>

00:03:56.140 --> 00:03:56.150 align:start position:0%
it I mean you can make assumptions but
 

00:03:56.150 --> 00:03:57.520 align:start position:0%
it I mean you can make assumptions but
things<00:03:56.360><c> don't</c><00:03:56.630><c> always</c><00:03:56.750><c> work</c><00:03:57.170><c> the</c><00:03:57.230><c> way</c><00:03:57.380><c> you</c>

00:03:57.520 --> 00:03:57.530 align:start position:0%
things don't always work the way you
 

00:03:57.530 --> 00:03:59.380 align:start position:0%
things don't always work the way you
think<00:03:57.920><c> which</c><00:03:58.400><c> is</c><00:03:58.430><c> why</c><00:03:58.730><c> you</c><00:03:58.790><c> need</c><00:03:59.030><c> to</c><00:03:59.090><c> check</c><00:03:59.240><c> out</c>

00:03:59.380 --> 00:03:59.390 align:start position:0%
think which is why you need to check out
 

00:03:59.390 --> 00:04:00.340 align:start position:0%
think which is why you need to check out
the<00:03:59.480><c> rest</c><00:03:59.630><c> of</c><00:03:59.720><c> the</c><00:03:59.810><c> Android</c><00:04:00.200><c> performance</c>

00:04:00.340 --> 00:04:00.350 align:start position:0%
the rest of the Android performance
 

00:04:00.350 --> 00:04:02.140 align:start position:0%
the rest of the Android performance
patterns<00:04:00.740><c> videos</c><00:04:01.040><c> and</c><00:04:01.430><c> don't</c><00:04:01.580><c> forget</c><00:04:01.700><c> to</c><00:04:01.970><c> join</c>

00:04:02.140 --> 00:04:02.150 align:start position:0%
patterns videos and don't forget to join
 

00:04:02.150 --> 00:04:04.540 align:start position:0%
patterns videos and don't forget to join
our<00:04:02.360><c> Google+</c><00:04:02.930><c> community</c><00:04:03.050><c> to</c><00:04:03.740><c> ask</c><00:04:03.890><c> a</c><00:04:04.100><c> lot</c><00:04:04.400><c> of</c>

00:04:04.540 --> 00:04:04.550 align:start position:0%
our Google+ community to ask a lot of
 

00:04:04.550 --> 00:04:07.300 align:start position:0%
our Google+ community to ask a lot of
hard<00:04:04.910><c> threading</c><00:04:05.390><c> questions</c><00:04:05.810><c> as</c><00:04:06.020><c> well</c><00:04:06.200><c> so</c><00:04:06.440><c> keep</c>

00:04:07.300 --> 00:04:07.310 align:start position:0%
hard threading questions as well so keep
 

00:04:07.310 --> 00:04:09.160 align:start position:0%
hard threading questions as well so keep
calm<00:04:07.610><c> profile</c><00:04:08.330><c> your</c><00:04:08.360><c> code</c><00:04:08.540><c> and</c><00:04:08.780><c> always</c>

00:04:09.160 --> 00:04:09.170 align:start position:0%
calm profile your code and always
 

00:04:09.170 --> 00:04:12.400 align:start position:0%
calm profile your code and always
remember<00:04:09.380><c> perf</c><00:04:09.740><c> matters</c>

