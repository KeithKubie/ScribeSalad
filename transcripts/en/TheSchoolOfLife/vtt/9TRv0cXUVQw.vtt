WEBVTT
Kind: captions
Language: en

00:00:00.100 --> 00:00:05.960
The prospect of artificial intelligence excites and repulsive people in equal measure:

00:00:05.960 --> 00:00:09.740
will it bring us a kind of paradise or a techno hell?

00:00:09.740 --> 00:00:15.700
To get a clearer handle of what might happen and when, it's best to divide A.I. into three categories.

00:00:15.700 --> 00:00:21.740
The first of these is "artificial narrow intelligence" or what people call "weak A.I.";

00:00:21.740 --> 00:00:24.100
this kind of A.I. is already in place;

00:00:24.100 --> 00:00:31.060
it's the kind of A.I. that uses big data and complex algorithms to arrange your Facebook timeline or beat you at chess;

00:00:31.060 --> 00:00:38.140
narrow A.I. has an intelligence that's limited to one very specific arena; it may not be able to pass the Turing test,

00:00:38.140 --> 00:00:43.480
but our lives, infrastructure, and financial markets are already very dependent on it.

00:00:43.480 --> 00:00:50.040
The next step up the AI ladder is artificial general intelligence or strong AI;

00:00:50.040 --> 00:00:58.320
this is an intelligence that can, at last, think as well as we can; we're probably about 30 years away from this.

00:00:58.320 --> 00:01:06.540
The hurdles to creating strong AI are all about building machines that are going to be good at doing things which come very easily to humans,

00:01:06.540 --> 00:01:10.000
but which machines have, traditionally, really stumbled with.

00:01:10.000 --> 00:01:14.480
Oddly, it's so much easier to build a machine that can do advanced calculus

00:01:14.480 --> 00:01:19.980
than it is to build one that can get milk from the fridge, recognized granny, or walk up the stairs.

00:01:19.980 --> 00:01:25.340
Our brains are brilliant at so-called "everyday tasks" like decoding 3D images,

00:01:25.340 --> 00:01:32.040
working out people's motivations, and spotting casual sarcasm. We're very far ahead of machines here.

00:01:32.040 --> 00:01:35.240
Some scientists doubt we'll ever see strong AI,

00:01:35.240 --> 00:01:41.480
but the majority of AI experts alive today seem to think that we'll be there in the coming decades;

00:01:41.480 --> 00:01:48.900
if you're under 35 the great probability is that you will be there to enter the strong AI age.

00:01:48.900 --> 00:01:55.700
So, what will happen to the world once we've succeeded in creating an intelligence to rival or equal our own?

00:01:55.700 --> 00:01:59.660
Well, the rivalry will be extremely short lived for one thing

00:01:59.660 --> 00:02:08.220
because the key point about strong AI is that it will be able to learn and upgrade itself on its own without instructions.

00:02:08.220 --> 00:02:13.460
This is what makes it so revolutionary and so different to almost any machine we've ever built;

00:02:13.460 --> 00:02:19.580
the maker won't be in charge of mapping out all the possibilities of the thing he or she has made.

00:02:19.580 --> 00:02:25.620
The machine will be given a baseline capacity, but it can then build on this as it develops.

00:02:25.620 --> 00:02:31.520
It will be a trial and error learner with an infinite capacity to acquire skills;

00:02:31.520 --> 00:02:36.420
it'll have what AI professionals call "recursive self improvement".

00:02:36.420 --> 00:02:42.480
This is crucial because it means there'll be no reason for AI to stall once it reaches the human level.

00:02:42.480 --> 00:02:48.700
The more intelligent system becomes, the better it becomes at improving itself, so the more it will learn and do.

00:02:48.700 --> 00:02:55.040
This virtuous cycle equates to an exponential growth in intelligence that would leave humanity amazed,

00:02:55.040 --> 00:02:58.620
but also baffled, dwarfed, and perhaps very scared.

00:02:58.620 --> 00:03:05.240
It might not take very long at all, only months perhaps, before the machine is cleverer than its creator.

00:03:05.240 --> 00:03:07.400
This is the moment that gets very exciting.

00:03:07.400 --> 00:03:10.620
Itâ€™s a moment often referred to as "The Singularity",

00:03:10.620 --> 00:03:16.340
which is where we encounter the third sort of AI, "artificial superintelligence".

00:03:16.340 --> 00:03:21.580
Technically, this is any AI that exceeds human levels of intelligence even slightly,

00:03:21.580 --> 00:03:27.320
but any self improving superintelligence is going to be sure to improve a lot very fast indeed.

00:03:27.320 --> 00:03:30.420
AI that reach this level would soon be leagues ahead of us,

00:03:30.420 --> 00:03:33.120
and statements such as, "well, let's just switch it off"

00:03:33.120 --> 00:03:37.040
might be like trying to take down the internet with a slingshot.

00:03:37.040 --> 00:03:41.480
The prospect of such super intelligence appalls and excites people in equal measure.

00:03:41.480 --> 00:03:43.780
We're approaching two alternative futures

00:03:43.780 --> 00:03:49.280
with the speed and uncertainty of a skydiver who can't quite remember if he's wearing a parachute or a rucksack.

00:03:49.280 --> 00:03:53.240
Some including: Bill Gates, Stephen Hawking, and Elon Musk are so scared

00:03:53.240 --> 00:03:58.800
they believe that we're unlikely ever to be able to effectively control any super intelligence we create.

00:03:58.800 --> 00:04:06.120
Artificial minds will just single-mindedly pursue their aims and these aims may not necessarily coincide with ours.

00:04:06.120 --> 00:04:08.700
A machine wouldn't specifically want to kill us,

00:04:08.700 --> 00:04:13.660
but it's amorality would mean that it would be willing to cause our extinction if necessary.

00:04:13.660 --> 00:04:17.420
These critics point out that intelligence is not value loaded.

00:04:17.420 --> 00:04:22.440
It's tempting to assume that anything intelligent will just naturally develop vaguely human values,

00:04:22.440 --> 00:04:24.440
like, empathy and respect for life,

00:04:24.440 --> 00:04:29.480
but this can't be guaranteed because ethical values are based on purely human axioms,

00:04:29.480 --> 00:04:33.540
and given that we find it impossible to agree among ourselves what's right and wrong

00:04:33.540 --> 00:04:36.380
in areas like euthanasia or abortion, say,

00:04:36.380 --> 00:04:42.460
how could we possibly program a computer with a knowledge that could soundly and reliably be deemed moral?

00:04:42.460 --> 00:04:46.460
Now that's the pessimistic angle, but there is a more cheerful angle, of course.

00:04:46.460 --> 00:04:50.040
According to the optimists, in a world of artificial super intelligence,

00:04:50.040 --> 00:04:55.900
machines will still be our servants, we'll give them some basic rules of never killing or doing us any harm,

00:04:55.900 --> 00:04:59.760
and then they'll set about solving all the things that have long bedeviled us.

00:04:59.760 --> 00:05:04.340
The immediate priority of super intelligence would be to help us to create free energy,

00:05:04.340 --> 00:05:07.900
in turn, dramatically reducing the prices for almost everything.

00:05:07.900 --> 00:05:14.000
We would soon be in the era that Google's chief futurologists Ray Kurzweil describes as 'abundance':

00:05:14.000 --> 00:05:19.020
everything currently costing would drop to almost $0, the way that data costs now.

00:05:19.020 --> 00:05:22.280
Work for money would, essentially, come to an end.

00:05:22.280 --> 00:05:25.460
The real challenge would be not getting miserable with all this abundance,

00:05:25.460 --> 00:05:32.000
after all, Palm Springs and Monte Carlo already now point to some of the dangers of wealthy people with nothing much to do.

00:05:32.000 --> 00:05:40.680
The solution here is to develop a side of A.I., that's been intriguingly dubbed A.E.I., or, Artificial Emotional Intelligence.

00:05:40.680 --> 00:05:47.360
This A.E.I. would help us with all the tricky tasks at the emotional, psychological, and philosophical end of things.

00:05:47.360 --> 00:05:53.020
We'd be helped with: understanding our psyches, mastering our emotions, drawing out out true talents-

00:05:53.020 --> 00:05:55.560
we'd hit what we were best suited to do with our lives-,

00:05:55.560 --> 00:06:00.340
and guiding us to the people with whom you might form good and satisfying relationships.

00:06:00.340 --> 00:06:05.080
Most of the many psychological mistakes which allow us to waste our lives could be averted;

00:06:05.080 --> 00:06:09.020
instead of fumbling through a mental fog of insecurities and inconsistencies,

00:06:09.020 --> 00:06:13.260
we'd be guided to a more compassionate, happier, and wiser future.

00:06:13.260 --> 00:06:16.500
Science fiction is sometimes dismissed in elite circles,

00:06:16.500 --> 00:06:23.820
but we can see now that: thinking twenty to fifty years ahead, and imagining how life will be is a central task for all of us;

00:06:23.820 --> 00:06:27.560
we should all be science-fiction writers, of a kind, in our minds.

00:06:27.560 --> 00:06:30.920
We are poised just before a tipping point in human history.

00:06:30.920 --> 00:06:34.740
We need to build up the wisdom to control which way we will tip,

00:06:34.740 --> 00:06:40.820
and part of that means thinking very realistically about things that, today, still seem rather phantasmagorical.

00:06:40.820 --> 00:06:43.440
Humans are toolmaking animals;

00:06:43.440 --> 00:06:46.480
we're on the brink of creating tools like no others,

00:06:46.480 --> 00:06:52.120
so the trick is going to be to stay close to the underlying ancient purpose of every tool,

00:06:52.120 --> 00:06:57.560
which is to help us to do something we actually want to do more effectively.

00:06:57.560 --> 00:07:03.340
If we keep our wits about us, there's no real reason our computers should, necessarily, run away from us;

00:07:03.340 --> 00:07:10.560
they should just be much much better versions of our earliest flint axes.

