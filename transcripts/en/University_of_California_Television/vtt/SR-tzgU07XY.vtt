WEBVTT
Kind: captions
Language: en

00:00:00.980 --> 00:00:02.320
- [Presenter] This program is presented

00:00:02.320 --> 00:00:04.740
by University of California Television.

00:00:04.740 --> 00:00:05.900
Like what you learn?

00:00:05.900 --> 00:00:08.610
Visit our website or follow us on Facebook

00:00:08.610 --> 00:00:12.020
and Twitter to keep up with
the latest UCTV programs.

00:00:12.020 --> 00:00:14.490
Also make sure to check out and subscribe

00:00:14.490 --> 00:00:17.900
to our YouTube original
channel UCTV Prime,

00:00:17.900 --> 00:00:19.693
available only on YouTube.

00:00:25.493 --> 00:00:27.910
(soft music)

00:00:56.940 --> 00:01:01.730
- Thank you all of you for
turning out and I noticed

00:01:01.730 --> 00:01:04.620
the little breath of relief

00:01:04.620 --> 00:01:06.890
when you realize you were
not going to get a lecture

00:01:06.890 --> 00:01:08.790
on the immortality of the soul,

00:01:08.790 --> 00:01:10.020
(audience laughing)

00:01:10.020 --> 00:01:12.380
which I would not be
well equipped to give,

00:01:12.380 --> 00:01:14.130
but I suppose one could
say there's this connection

00:01:14.130 --> 00:01:15.530
between what I will talk about,

00:01:15.530 --> 00:01:17.900
if indeed the soul were immortal,

00:01:17.900 --> 00:01:21.810
and if, at least some souls
went, as some people believe,

00:01:21.810 --> 00:01:25.890
to paradise or heaven, then
presumably they would be happy.

00:01:25.890 --> 00:01:28.530
But then we have to ask,
what does that mean?

00:01:28.530 --> 00:01:30.300
What is the good that would be achieved,

00:01:30.300 --> 00:01:33.190
were they to be happy
and that does take us

00:01:33.190 --> 00:01:34.650
pretty close to my topic.

00:01:34.650 --> 00:01:37.100
So I prepare that justification

00:01:37.100 --> 00:01:39.480
in case anyone should
challenge the propriety

00:01:39.480 --> 00:01:41.963
of this talk on that lecture.

00:01:43.410 --> 00:01:45.180
What I'm really going to do is talk

00:01:45.180 --> 00:01:47.830
about what underpins the views

00:01:47.830 --> 00:01:49.360
that I've held on many issues,

00:01:49.360 --> 00:01:51.260
as was mentioned in the introduction,

00:01:51.260 --> 00:01:54.450
about the treatment of
animals, about global poverty,

00:01:54.450 --> 00:01:56.190
about life or death questions.

00:01:56.190 --> 00:01:59.610
So I'm not actually going to be addressing

00:01:59.610 --> 00:02:01.530
the specifics of those questions

00:02:01.530 --> 00:02:05.023
but rather, the value underneath it.

00:02:06.080 --> 00:02:09.610
For essentially my whole
philosophical life,

00:02:09.610 --> 00:02:12.590
certainly since I wrote Practical Ethics

00:02:12.590 --> 00:02:14.490
more than 30 years ago,

00:02:14.490 --> 00:02:17.300
I've held that the right thing to do

00:02:17.300 --> 00:02:20.380
is what does most to
satisfy the preferences

00:02:20.380 --> 00:02:23.870
of all those affected by one's action,

00:02:23.870 --> 00:02:27.030
whether human or non-human.

00:02:27.030 --> 00:02:29.310
That's a view that's generally known

00:02:29.310 --> 00:02:33.150
as preference utilitarianism
and I held it,

00:02:33.150 --> 00:02:35.150
I suppose, to some extent
under the influence

00:02:35.150 --> 00:02:39.540
of one of my Oxford teachers, R. M. Hare,

00:02:39.540 --> 00:02:42.610
whose view was based on what he called

00:02:42.610 --> 00:02:46.690
universal prescriptivism,
that is a view of ethics

00:02:46.690 --> 00:02:49.560
which says that moral
judgments are prescriptions,

00:02:49.560 --> 00:02:51.640
they're not statements, they can't be true

00:02:51.640 --> 00:02:53.790
or false in an ordinary sense.

00:02:53.790 --> 00:02:56.340
Although we can reason about them

00:02:56.340 --> 00:02:59.490
because they have to be universalized

00:02:59.490 --> 00:03:02.223
in a special sense of that term.

00:03:03.720 --> 00:03:08.230
I'd been uneasy about that
meta ethic for quite some time

00:03:08.230 --> 00:03:10.560
but it took two factors or perhaps

00:03:10.560 --> 00:03:13.220
it would be better to
say to great philosophers

00:03:13.220 --> 00:03:18.220
to persuade me to seriously
consider a shift away from it.

00:03:18.470 --> 00:03:21.310
One of them was, as Professor Bann

00:03:21.310 --> 00:03:23.290
mentioned in the introduction,

00:03:23.290 --> 00:03:27.060
Henry Sidgwick, who I'm
currently working on

00:03:27.060 --> 00:03:30.960
and let me say, I'm not just
writing this book by myself,

00:03:30.960 --> 00:03:33.810
I have a co-author, a Polish colleague,

00:03:33.810 --> 00:03:36.340
Dr. Catarina de Lazzari Radek

00:03:36.340 --> 00:03:38.150
and I want to acknowledge that the work

00:03:38.150 --> 00:03:41.450
that I'm presenting is
to some extent drawn

00:03:41.450 --> 00:03:43.170
from work that we have jointly prepared

00:03:43.170 --> 00:03:45.683
as part of the draft of this book.

00:03:46.930 --> 00:03:50.580
The second, and Sidgwick was
an objectivist in ethics,

00:03:50.580 --> 00:03:53.910
so it's some extent working out

00:03:53.910 --> 00:03:56.930
his views on on the nature of ethics.

00:03:56.930 --> 00:04:00.370
The second great philosopher
who has influenced me

00:04:00.370 --> 00:04:05.080
is a contemporary, the Oxford
philosopher Derek Parfit,

00:04:05.080 --> 00:04:09.520
whose major recent work, On What Matters,

00:04:09.520 --> 00:04:13.070
is at least in part an extended defense

00:04:13.070 --> 00:04:16.113
of objectivism in ethics.

00:04:17.510 --> 00:04:20.410
Now, one could accept objectivism

00:04:20.410 --> 00:04:22.970
as a meta-ethical position and still

00:04:22.970 --> 00:04:27.210
be a preference utilitarian
in terms of normative ethics.

00:04:27.210 --> 00:04:29.720
That is, in terms of the the content

00:04:29.720 --> 00:04:31.933
of what you think one ought to do.

00:04:33.170 --> 00:04:36.560
Objectivism doesn't preclude the idea

00:04:36.560 --> 00:04:39.440
that we ought to satisfy
desires or preferences

00:04:39.440 --> 00:04:43.260
as a normative view but it
does, for various reasons,

00:04:43.260 --> 00:04:47.473
increase the appeal of
some alternatives to it.

00:04:48.390 --> 00:04:51.130
And prominent among these is the idea

00:04:51.130 --> 00:04:54.110
that happiness is the ultimate good.

00:04:54.110 --> 00:04:56.180
So what I'm going to talk about today

00:04:56.180 --> 00:04:59.490
is to explore that idea.

00:04:59.490 --> 00:05:00.540
The idea, in other words,

00:05:00.540 --> 00:05:03.360
that instead of being
preference utilitarians,

00:05:03.360 --> 00:05:08.360
we should be closer to
the classical utilitarians

00:05:08.460 --> 00:05:10.560
who were concerned about happiness

00:05:10.560 --> 00:05:13.350
or as it's sometimes put,

00:05:13.350 --> 00:05:16.410
we're hedonistic utilitarians.

00:05:16.410 --> 00:05:18.510
Hedonism from the Greek word for pleasure.

00:05:20.570 --> 00:05:23.853
So section two, what do
we mean by happiness?

00:05:25.090 --> 00:05:28.110
The trinity of 19th century utilitarians,

00:05:28.110 --> 00:05:31.720
that's Jeremy Bentham, John
Stuart Mill, and Henry Sidgwick,

00:05:31.720 --> 00:05:34.680
were all ethical hedonists.

00:05:34.680 --> 00:05:36.740
When they discuss happiness,

00:05:36.740 --> 00:05:40.330
they often use happiness or pleasure

00:05:40.330 --> 00:05:43.270
because for them,
happiness means a surplus

00:05:43.270 --> 00:05:44.853
of pleasure over pain.

00:05:45.870 --> 00:05:46.860
This view has been subject

00:05:46.860 --> 00:05:49.330
to considerable criticism over the years.

00:05:49.330 --> 00:05:52.300
And I'm certainly, was
not been the only one

00:05:52.300 --> 00:05:55.040
who's thought that it was not defensible,

00:05:55.040 --> 00:05:57.833
that preference view was better.

00:05:58.840 --> 00:06:00.440
And there've been quite a few recent works

00:06:00.440 --> 00:06:02.940
examining, in particular,
the concept of happiness

00:06:04.900 --> 00:06:07.770
and what we mean by that.

00:06:07.770 --> 00:06:10.230
One of them is by Fred Feldman.

00:06:10.230 --> 00:06:13.230
It's a book called What Is
This Thing Called Happiness?

00:06:13.230 --> 00:06:16.143
And Feldman is quite critical
of the classical view.

00:06:17.340 --> 00:06:19.960
He attributes to Bentham,
Mill, and Sedgwick,

00:06:19.960 --> 00:06:22.483
what he calls sensory hedonism,

00:06:23.500 --> 00:06:26.850
which essentially means, I guess,

00:06:26.850 --> 00:06:30.570
that you're happy at a time,
if and only if you feel

00:06:30.570 --> 00:06:34.420
more sensory pleasure
than pain at that time,

00:06:34.420 --> 00:06:37.460
and unhappy if and only if
you feel more sensory pain

00:06:37.460 --> 00:06:39.173
than pleasure at that time.

00:06:40.220 --> 00:06:42.010
What does he mean by sensory pleasure?

00:06:42.010 --> 00:06:44.260
Well, I take it that the
dictionary definition

00:06:44.260 --> 00:06:47.620
says relating to sensation
or the physical senses,

00:06:47.620 --> 00:06:50.400
transmitted or perceived by the senses.

00:06:50.400 --> 00:06:53.370
So Feldman seems to
mean something like that

00:06:53.370 --> 00:06:56.360
and he does say that sensory pleasure

00:06:56.360 --> 00:06:59.220
always has some phenomenally

00:06:59.220 --> 00:07:03.070
given sensory intensity which
is a measure of how strong

00:07:03.070 --> 00:07:05.470
or vivid or brilliant the pleasure is.

00:07:05.470 --> 00:07:07.060
So it seems that he's really thinking

00:07:07.060 --> 00:07:10.010
about something at
which the paradigm cases

00:07:10.010 --> 00:07:12.790
would be the physical pleasures,

00:07:12.790 --> 00:07:14.320
whether they're pleasures of sex

00:07:14.320 --> 00:07:16.810
or of eating or of the warmth of the sun

00:07:16.810 --> 00:07:19.283
on your back or something of that sort.

00:07:20.730 --> 00:07:24.060
And indeed, in arguing
against sensory hedonism,

00:07:24.060 --> 00:07:27.910
Feldman uses an example
from sexual pleasure.

00:07:27.910 --> 00:07:30.940
He asked us to imagine
an unfortunate character

00:07:30.940 --> 00:07:33.310
named Wendell, who's seen advertised

00:07:33.310 --> 00:07:36.530
for an orgasm enhancer, that it's claimed

00:07:36.530 --> 00:07:40.205
will give him an amazing 400 hedon orgasm.

00:07:40.205 --> 00:07:41.480
(audience laughing)

00:07:41.480 --> 00:07:43.310
You have to imagine that we can measure

00:07:43.310 --> 00:07:45.563
pleasure in units that are called hedons.

00:07:47.110 --> 00:07:48.960
Although he's been warned by his friends

00:07:48.960 --> 00:07:51.830
that the advertisements
are probably a scam,

00:07:51.830 --> 00:07:54.530
he buys the device and tries it out

00:07:54.530 --> 00:07:56.090
but when the orgasm comes,

00:07:56.090 --> 00:07:58.990
instead of the monster
orgasm he's expecting,

00:07:58.990 --> 00:08:02.210
he gets a pathetic little 12 hedon orgasm.

00:08:02.210 --> 00:08:03.360
(audience laughing)

00:08:03.360 --> 00:08:05.223
Experiencing it, he's unhappy.

00:08:07.000 --> 00:08:08.058
But why?

00:08:08.058 --> 00:08:10.950
(audience laughing)

00:08:10.950 --> 00:08:13.070
After all, Feldman argues, 12 hedons

00:08:13.070 --> 00:08:16.410
is better than no hedons or -12 hedons.

00:08:16.410 --> 00:08:18.600
So surely, Wendell is experiencing

00:08:18.600 --> 00:08:20.200
pleasure rather than pain.

00:08:20.200 --> 00:08:22.410
If happiness is just
having a positive balance

00:08:22.410 --> 00:08:24.650
of pleasure over pain,
we would have to agree

00:08:24.650 --> 00:08:26.830
that at the moment of orgasm, he's happy,

00:08:26.830 --> 00:08:29.110
but anyone observing him
can see that he has a pained

00:08:29.110 --> 00:08:31.783
look on his face and
seems generally unhappy.

00:08:33.730 --> 00:08:37.480
Feldman also has another
case, perhaps more realistic

00:08:37.480 --> 00:08:39.400
and in some respects, the reverse of this.

00:08:39.400 --> 00:08:41.950
He asked us to imagine
a woman in the throes

00:08:41.950 --> 00:08:45.200
of giving birth without drugs
because she wants to be able

00:08:45.200 --> 00:08:47.920
to fully experience the birth process,

00:08:47.920 --> 00:08:50.420
so she's in considerable pain.

00:08:50.420 --> 00:08:53.260
But with one last push,
the baby comes out.

00:08:53.260 --> 00:08:56.280
Later, she says that that was,

00:08:56.280 --> 00:08:58.100
so later, she says that the pain

00:08:58.100 --> 00:08:59.973
was the worst that she's ever felt,

00:09:00.840 --> 00:09:04.060
much greater than she'd
expected but at the same time,

00:09:04.060 --> 00:09:06.883
the birth was the happiest
moment of her life.

00:09:08.160 --> 00:09:10.330
Both these cases, Feldman argues,

00:09:10.330 --> 00:09:12.860
suggest that the hedonism of the Bentham,

00:09:12.860 --> 00:09:15.633
Mill, Sidgwick variety is false.

00:09:17.375 --> 00:09:19.680
Well, I think that this
is really a travesty

00:09:19.680 --> 00:09:22.410
of certainly what Sidgwick was arguing.

00:09:22.410 --> 00:09:24.373
I won't answer for Bentham or Mill,

00:09:25.660 --> 00:09:28.010
because he has a much
broader notion of pleasure.

00:09:28.010 --> 00:09:29.817
For example, among the
pleasures he talks about

00:09:29.817 --> 00:09:32.960
are the pleasures of
intellectual exercise,

00:09:32.960 --> 00:09:37.440
of aesthetic reception, of grasping

00:09:37.440 --> 00:09:39.750
some scientific discovery.

00:09:39.750 --> 00:09:42.300
And he talks about the pleasure of labor,

00:09:42.300 --> 00:09:45.760
meaning, I take it, work
rather than giving birth.

00:09:45.760 --> 00:09:47.360
But still.

00:09:47.360 --> 00:09:49.290
He also notes that there are states

00:09:49.290 --> 00:09:50.630
in which a certain amount of pain

00:09:50.630 --> 00:09:53.280
or discomfort is mixed with pleasure.

00:09:53.280 --> 00:09:55.840
And among such states, he
mentions the triumphant

00:09:55.840 --> 00:09:58.720
conquest of painful obstacles,

00:09:58.720 --> 00:10:01.720
which could well describe
the birth process.

00:10:01.720 --> 00:10:03.280
And he might even be referring to someone

00:10:03.280 --> 00:10:07.490
like Wendell when he writes
of the disappointment

00:10:07.490 --> 00:10:10.560
of the hedonist who fails
to find self satisfaction

00:10:10.560 --> 00:10:11.950
where he seeks for it.

00:10:11.950 --> 00:10:13.720
Adding that this disappointment

00:10:13.720 --> 00:10:16.663
is attended with pain or loss of pleasure.

00:10:18.260 --> 00:10:21.560
Now, admittedly, I'm not
trying to suggest it,

00:10:21.560 --> 00:10:23.760
but when Sidgwick uses the
term self-satisfaction,

00:10:23.760 --> 00:10:25.653
he had masturbation in mind,

00:10:26.680 --> 00:10:28.420
but what the passage does show

00:10:28.420 --> 00:10:31.580
is that he counts disappointment as a pain

00:10:31.580 --> 00:10:33.710
and on that basis could plausibly reject

00:10:33.710 --> 00:10:35.710
Feldman's claim that Wendell,

00:10:35.710 --> 00:10:39.150
at the moment of his
pathetic 12 hedon orgasm,

00:10:39.150 --> 00:10:41.560
which of course is also the
moment at which he realizes

00:10:41.560 --> 00:10:46.230
he's been the victim of
a scam, is experiencing,

00:10:46.230 --> 00:10:48.200
could reject the claim
that that he's experiencing

00:10:48.200 --> 00:10:51.293
a positive balance of pleasure over pain.

00:10:53.290 --> 00:10:56.130
Another hedonist Feldman criticizes

00:10:56.130 --> 00:10:58.290
is my Princeton colleague

00:10:58.290 --> 00:11:00.683
and Nobel laureate, Daniel Kahneman.

00:11:02.460 --> 00:11:05.780
According to Kahneman,
it makes sense to say,

00:11:05.780 --> 00:11:08.060
Helen was happy in the month of March,

00:11:08.060 --> 00:11:10.610
if, and I quote, she
spent most of her time

00:11:10.610 --> 00:11:14.770
engaged in activities she would
rather continue than stop,

00:11:14.770 --> 00:11:17.980
little time in situations
she wished to escape,

00:11:17.980 --> 00:11:20.530
and very important, because life is short,

00:11:20.530 --> 00:11:23.140
not too much time in a neutral state,

00:11:23.140 --> 00:11:25.473
in which she would not care either way.

00:11:27.360 --> 00:11:29.980
In that passage, Kahneman
does use the word activities

00:11:29.980 --> 00:11:32.850
rather than mental states or experiences

00:11:32.850 --> 00:11:36.700
but he also talks
elsewhere about experience

00:11:36.700 --> 00:11:39.660
and experience utility
and the experiencing self

00:11:39.660 --> 00:11:40.670
and I think it's clear

00:11:40.670 --> 00:11:45.053
that he is actually talking
about mental states here.

00:11:46.750 --> 00:11:49.170
He talks for example
about instant utility,

00:11:49.170 --> 00:11:51.850
adding that instant
utility is best understood

00:11:51.850 --> 00:11:54.200
as the strength of the
disposition to continue

00:11:54.200 --> 00:11:57.283
or to interrupt the current experience.

00:11:58.740 --> 00:12:01.440
So his view is a mental state view

00:12:01.440 --> 00:12:03.210
and one that distinguishes
the mental states

00:12:03.210 --> 00:12:05.680
that contribute to happiness
from those that do not,

00:12:05.680 --> 00:12:07.580
by saying just as Sedgwick does,

00:12:07.580 --> 00:12:11.010
that the former are ones
we desire to continue.

00:12:11.010 --> 00:12:13.060
In other words, pleasure or the positive

00:12:13.060 --> 00:12:16.010
mental states utility is not just one

00:12:16.010 --> 00:12:18.140
particular type of sensation.

00:12:18.140 --> 00:12:22.180
It's not to be distinguished
by a certain kind of feeling,

00:12:22.180 --> 00:12:24.090
in the way that we might distinguish

00:12:24.090 --> 00:12:27.910
some particular sensations
as having a certain type

00:12:27.910 --> 00:12:31.780
and then they're just
differing along that continuum.

00:12:31.780 --> 00:12:34.730
But I think pleasure for
Sidgwick and for Kahneman,

00:12:34.730 --> 00:12:39.510
is much more widely
varied and what determines

00:12:39.510 --> 00:12:42.690
that it's pleasure is that
it's a state of consciousness

00:12:42.690 --> 00:12:45.270
that, considered intrinsically,

00:12:45.270 --> 00:12:47.540
just as a state of consciousness,

00:12:47.540 --> 00:12:50.720
you would wish to continue,
you would wish to have more of,

00:12:50.720 --> 00:12:53.100
and conversely, pain is
a state of consciousness

00:12:53.100 --> 00:12:54.960
that considered intrinsically,

00:12:54.960 --> 00:12:57.980
you would wish to have less of.

00:12:57.980 --> 00:13:00.820
And I'm going to come
back to Kahneman's view

00:13:00.820 --> 00:13:03.113
at the end of, towards
the end of the talk.

00:13:05.500 --> 00:13:07.440
What does Feldman put up as an alternative

00:13:07.440 --> 00:13:08.870
to sensory hedonism?

00:13:08.870 --> 00:13:11.730
He talks about attitudinal hedonism,

00:13:11.730 --> 00:13:15.170
which he says is to
have a positive balance

00:13:15.170 --> 00:13:19.770
of intrinsic or current
attitudinal pleasure.

00:13:19.770 --> 00:13:21.870
That's probably not a
very transparent phrase.

00:13:21.870 --> 00:13:23.460
What does it mean?

00:13:23.460 --> 00:13:24.920
Well, for example, he says,

00:13:24.920 --> 00:13:27.620
I might be pleased to learn,
by reading a newspaper,

00:13:27.620 --> 00:13:29.830
that the distribution of bed nets

00:13:29.830 --> 00:13:32.190
by aid agencies has reduced the number

00:13:32.190 --> 00:13:34.970
of children dying from malaria.

00:13:34.970 --> 00:13:36.360
To say that I'm pleased to read

00:13:36.360 --> 00:13:38.543
that doesn't mean, Feldman says,

00:13:38.543 --> 00:13:42.020
that I have a kind of
cheery feeling as I read it

00:13:42.020 --> 00:13:46.130
or that I have a warm
inner glow as I read it.

00:13:46.130 --> 00:13:50.930
It just means that I have this
positive attitude towards it

00:13:51.960 --> 00:13:54.810
and that's how Feldman would replace

00:13:54.810 --> 00:13:57.633
or the classical utilitarian
view as he sees it.

00:13:59.010 --> 00:14:01.530
But as Daniel Hebron points out in another

00:14:01.530 --> 00:14:05.380
recent work on happiness called
the Pursuit of Unhappiness,

00:14:05.380 --> 00:14:08.260
that view takes the fun out of pleasure.

00:14:08.260 --> 00:14:10.370
If the knowledge that fewer children died

00:14:10.370 --> 00:14:13.680
does not involve any positive
emotions or feelings,

00:14:13.680 --> 00:14:17.513
does it really contribute to my happiness?

00:14:18.360 --> 00:14:19.440
I agree with Hebron.

00:14:19.440 --> 00:14:21.010
I don't think it does.

00:14:21.010 --> 00:14:24.280
So I reject Feldman's alternative

00:14:24.280 --> 00:14:26.160
to the traditional view

00:14:26.160 --> 00:14:28.733
as well as his critique of that view.

00:14:31.350 --> 00:14:33.280
Hebron, however, puts his own case

00:14:33.280 --> 00:14:36.963
against a hedonistic view of happiness.

00:14:37.880 --> 00:14:40.070
And I think it's more
difficult to counter.

00:14:40.070 --> 00:14:42.610
His argument is that some pleasures,

00:14:42.610 --> 00:14:45.310
like the enjoyment of eating crackers

00:14:45.310 --> 00:14:47.970
and he also mentions orgasms,

00:14:47.970 --> 00:14:51.193
I guess they just come into
this discussion naturally.

00:14:52.430 --> 00:14:54.750
He thinks that some of
these pleasures, at least,

00:14:54.750 --> 00:14:59.650
may be too superficial to have
any impact on our happiness.

00:14:59.650 --> 00:15:02.903
As he puts it, these pleasures
just don't get to us.

00:15:03.810 --> 00:15:06.780
They flip through consciousness
and that's the end of it.

00:15:06.780 --> 00:15:09.313
They leave our happiness level untouched.

00:15:11.240 --> 00:15:14.350
So Hebron thinks that to feel pleasure

00:15:14.350 --> 00:15:15.960
is just to have an experience

00:15:15.960 --> 00:15:18.730
or may not get to us, whereas to describe

00:15:18.730 --> 00:15:22.280
someone as happy is to say
something that goes deeper,

00:15:22.280 --> 00:15:26.980
to say something about their
emotional state and their mood.

00:15:26.980 --> 00:15:30.490
Emotional states and moods
and not just feelings,

00:15:30.490 --> 00:15:33.710
they're dispositions to feel something.

00:15:33.710 --> 00:15:35.630
To say that I'm irritable, for example,

00:15:35.630 --> 00:15:39.200
is not to say that I'm
feeling irritated right now,

00:15:39.200 --> 00:15:42.600
but rather to say that I'm
liable to become irritated,

00:15:42.600 --> 00:15:44.200
perhaps about trivial things

00:15:44.200 --> 00:15:46.210
that would not bother someone else

00:15:46.210 --> 00:15:49.343
who was in a more
expansive mood than I am.

00:15:51.750 --> 00:15:53.810
Hebron grants that a
person with a generally

00:15:53.810 --> 00:15:56.450
do-er personality might,
because of good fortune,

00:15:56.450 --> 00:15:59.240
be in high spirits for a time
and we could then consider

00:15:59.240 --> 00:16:02.020
her happy, but he says,
this would be a fragile

00:16:02.020 --> 00:16:04.850
sort of happiness, unlike
the robust happiness

00:16:04.850 --> 00:16:07.060
of a person who has a propensity

00:16:07.060 --> 00:16:10.313
to have those positive
moods and emotional states.

00:16:12.610 --> 00:16:16.510
Now, taking that as an
account of common usage

00:16:16.510 --> 00:16:18.830
of how we ordinarily
use the term happiness,

00:16:18.830 --> 00:16:21.330
which of course is a term in common use,

00:16:21.330 --> 00:16:23.103
not a philosophical term of art.

00:16:24.010 --> 00:16:26.070
Quite possibly, Hebron is right,

00:16:26.070 --> 00:16:29.610
that is the sense in which
we most commonly use the term

00:16:29.610 --> 00:16:31.720
and we could then accept his view

00:16:31.720 --> 00:16:34.580
that happiness refers not to the surplus

00:16:34.580 --> 00:16:36.710
of pleasure over pain that the classical

00:16:36.710 --> 00:16:38.793
utilitarians used it to refer to,

00:16:40.730 --> 00:16:43.023
but to having a certain emotional state.

00:16:44.280 --> 00:16:46.400
The question is, does this mean

00:16:46.400 --> 00:16:49.643
that the classical
utilitarians were mistaken?

00:16:56.220 --> 00:16:59.693
Okay, section three, happiness,
utilitarianism, and value.

00:17:01.930 --> 00:17:04.560
If we agree that Hebron's
kind of happiness

00:17:04.560 --> 00:17:07.463
gets the ordinary concept
right, what follows?

00:17:08.690 --> 00:17:13.690
He himself is clear that to
give an account of happiness

00:17:13.830 --> 00:17:18.120
has no implications for a
theory of value, as such.

00:17:18.120 --> 00:17:20.870
So you could reject the hedonistic account

00:17:20.870 --> 00:17:25.580
of happiness without rejecting
the hedonistic kind of value.

00:17:25.580 --> 00:17:28.100
All utilitarians need to do, he says,

00:17:28.100 --> 00:17:29.490
is grant that their theories

00:17:29.490 --> 00:17:32.293
are about pleasure and
not about happiness.

00:17:34.070 --> 00:17:35.810
And given Hebron's account of happiness,

00:17:35.810 --> 00:17:37.890
I think that's a plausible view.

00:17:37.890 --> 00:17:40.280
If happiness is, at least in part,

00:17:40.280 --> 00:17:42.630
a disposition to have certain feelings,

00:17:42.630 --> 00:17:47.630
under certain conditions, how
could that be good in itself?

00:17:47.910 --> 00:17:49.600
What would have to be good, surely,

00:17:49.600 --> 00:17:53.720
is the feelings that it's
a disposition to have,

00:17:53.720 --> 00:17:57.123
not having the disposition as such.

00:17:58.810 --> 00:18:00.670
So utilitarian, then, would have to change

00:18:00.670 --> 00:18:02.480
their vocabulary and speak

00:18:02.480 --> 00:18:05.560
of pleasure rather than unhappiness.

00:18:05.560 --> 00:18:06.520
But they wouldn't have to change

00:18:06.520 --> 00:18:09.883
the utilitarian conclusions
about what we ought to do.

00:18:12.440 --> 00:18:15.330
Still, you might you might
feel the utilitarianism

00:18:15.330 --> 00:18:17.270
would be less persuasive
if they had to talk

00:18:17.270 --> 00:18:19.780
about maximizing the greatest pleasure

00:18:19.780 --> 00:18:22.190
for the greatest number
rather than the greatest

00:18:22.190 --> 00:18:24.233
happiness for the greatest number.

00:18:25.690 --> 00:18:28.550
At least utilitarians need to explain

00:18:28.550 --> 00:18:31.210
why, on their view, happiness is important

00:18:32.860 --> 00:18:34.550
but I think Hebron's own account

00:18:34.550 --> 00:18:37.470
provides such an explanation.

00:18:37.470 --> 00:18:39.710
To be happy, on his view,
is to be in a certain

00:18:39.710 --> 00:18:42.780
emotional state which makes it likely

00:18:42.780 --> 00:18:44.950
that you'll experience pleasure.

00:18:44.950 --> 00:18:48.110
He says, I quote, one of these states,

00:18:48.110 --> 00:18:50.900
it's the single most
important determinant,

00:18:50.900 --> 00:18:53.440
happiness, of our hedonic states.

00:18:53.440 --> 00:18:56.600
So if we combine the
classical utilitarian view

00:18:56.600 --> 00:18:59.140
that the only thing of
intrinsic value is pleasure,

00:18:59.140 --> 00:19:00.910
with Hebron's view that happiness

00:19:00.910 --> 00:19:03.230
consists of a set of emotional states,

00:19:03.230 --> 00:19:05.440
we reach the conclusion that happiness

00:19:05.440 --> 00:19:09.693
is instrumentally good,
not intrinsically good.

00:19:10.760 --> 00:19:14.050
Pleasure, in the sense of being
in a positive hedonic state,

00:19:14.050 --> 00:19:16.710
is intrinsically good and happy people

00:19:16.710 --> 00:19:19.650
are more likely to experience
this positive hedonic state,

00:19:19.650 --> 00:19:23.363
so happiness is an
important instrumental good.

00:19:25.170 --> 00:19:28.730
And I think we can also use this account

00:19:28.730 --> 00:19:30.870
to explain why happiness is important

00:19:30.870 --> 00:19:33.520
in practical deliberation.

00:19:33.520 --> 00:19:38.520
As Hebron himself argues,
it's often easier to work out,

00:19:38.520 --> 00:19:40.670
when making an important choice,

00:19:40.670 --> 00:19:42.770
whether it will lead to you being happy

00:19:42.770 --> 00:19:45.390
or unhappy or other people
being happy or unhappy

00:19:45.390 --> 00:19:48.820
then whether it'll
maximize hedonic states.

00:19:48.820 --> 00:19:52.350
Think, for example, of
making a career choice.

00:19:52.350 --> 00:19:55.920
You might think of a choice
between two different careers

00:19:55.920 --> 00:19:59.510
that one of them will
lead you to be stressed

00:19:59.510 --> 00:20:01.890
and anxious, whereas the other

00:20:01.890 --> 00:20:04.610
will give you more peace of mind.

00:20:04.610 --> 00:20:07.380
So those are not intrinsically
good things themselves

00:20:07.380 --> 00:20:10.800
but they're likely to
contribute to your happiness

00:20:10.800 --> 00:20:13.130
or your unhappiness of course, in a state,

00:20:13.130 --> 00:20:15.600
the career that leads you to
be more stressed and anxious

00:20:15.600 --> 00:20:19.160
and therefore, to mean that you

00:20:19.160 --> 00:20:23.090
less frequently have
positive hedonic states.

00:20:23.090 --> 00:20:27.300
So I think we can explain why,
in terms of making choices,

00:20:27.300 --> 00:20:30.180
happiness might come
to our mind more easily

00:20:30.180 --> 00:20:33.310
than pleasure because it
just may be more easily

00:20:33.310 --> 00:20:36.010
to work out what impact the choices

00:20:36.010 --> 00:20:38.860
will have on this very basic and important

00:20:39.730 --> 00:20:42.730
instrumental good that is likely to lead

00:20:42.730 --> 00:20:45.723
to the actual intrinsic good.

00:20:48.820 --> 00:20:53.070
Section four, arguing for the value

00:20:53.070 --> 00:20:56.063
of mental states, conscious states.

00:20:57.950 --> 00:21:00.060
What I've argued so far

00:21:00.060 --> 00:21:04.330
is that criticisms of hedonism
as an account of happiness

00:21:04.330 --> 00:21:06.340
don't exclude the
possibility that pleasure

00:21:06.340 --> 00:21:08.190
is the only thing of intrinsic value.

00:21:09.140 --> 00:21:10.890
But I haven't yet argued that pleasure

00:21:10.890 --> 00:21:15.760
is of ultimate value or indeed,
of intrinsic value at all,

00:21:15.760 --> 00:21:18.150
let alone the only thing
of intrinsic value.

00:21:18.150 --> 00:21:20.283
Why might we think that it is?

00:21:22.470 --> 00:21:24.280
Well, let's look at how Sidgwick

00:21:24.280 --> 00:21:26.773
argues for pleasure as the ultimate value.

00:21:28.040 --> 00:21:30.560
He begins with a claim that when we think

00:21:30.560 --> 00:21:33.160
about what we judge to be good,

00:21:33.160 --> 00:21:34.900
everything that can survive the scrutiny

00:21:34.900 --> 00:21:37.470
of careful reflection has some connection

00:21:37.470 --> 00:21:39.820
to human existence or at least

00:21:39.820 --> 00:21:42.163
to some consciousness or feeling.

00:21:43.640 --> 00:21:46.110
And in other parts of
the Methods of Ethics,

00:21:46.110 --> 00:21:49.430
he explicitly includes
animal consciousness

00:21:49.430 --> 00:21:53.320
as part of the good so what
we're talking about here

00:21:53.320 --> 00:21:57.170
is the states of, he's
saying that anything

00:21:57.170 --> 00:21:59.570
that can survive the scrutiny
of careful reflection,

00:21:59.570 --> 00:22:01.390
in terms of being judged to be good,

00:22:01.390 --> 00:22:03.290
has to be a conscious state

00:22:03.290 --> 00:22:06.593
of some sentient being, human or animal.

00:22:08.090 --> 00:22:10.690
He considers possible counter
examples to the claim.

00:22:11.650 --> 00:22:14.600
He notes, for example,
that we commonly judge

00:22:14.600 --> 00:22:17.330
inanimate objects or scenes to be good

00:22:17.330 --> 00:22:20.760
because they're beautiful
or bad because they're ugly.

00:22:20.760 --> 00:22:24.280
But, he goes on to say, no
one would consider it rational

00:22:24.280 --> 00:22:25.900
to aim at the production of beauty

00:22:25.900 --> 00:22:29.330
in external nature,
apart from any possible

00:22:29.330 --> 00:22:32.073
contemplation of it by human beings.

00:22:33.450 --> 00:22:37.400
Famously, shortly after
that in Principia Ethica,

00:22:37.400 --> 00:22:40.630
G. E. Moore did challenge that claim

00:22:40.630 --> 00:22:44.400
and asked the reader to
imagine two possible worlds,

00:22:44.400 --> 00:22:47.540
one as beautiful as you
can possibly make it,

00:22:47.540 --> 00:22:50.210
the other as ugly as you
can possibly make it,

00:22:50.210 --> 00:22:55.210
simply one heap of
filth, in Moore's phrase,

00:22:55.240 --> 00:22:57.370
with no redeeming feature and grant

00:22:57.370 --> 00:23:00.200
that no human being or no sentient being

00:23:00.200 --> 00:23:03.280
will ever see either world.

00:23:03.280 --> 00:23:06.200
Nevertheless, Moore, in Principia Ethica,

00:23:06.200 --> 00:23:09.750
said it's rational to prefer
that the beautiful world

00:23:09.750 --> 00:23:12.550
should exist rather than the ugly world.

00:23:12.550 --> 00:23:16.530
Well, you can consult your
own intuitions on this.

00:23:16.530 --> 00:23:18.900
I think if we can really imagine

00:23:18.900 --> 00:23:22.500
that world with no being appreciating it,

00:23:22.500 --> 00:23:25.040
then it really doesn't
make any difference.

00:23:25.040 --> 00:23:27.480
Of course, for us, since
we're imagining it,

00:23:27.480 --> 00:23:30.230
we may like to imagine
the beautiful world,

00:23:30.230 --> 00:23:32.040
that's a more pleasant experience for us,

00:23:32.040 --> 00:23:34.380
but we have to somehow subtract that

00:23:34.380 --> 00:23:36.900
from the process of doing
this thought experiment

00:23:36.900 --> 00:23:39.760
and then I don't think
it makes a difference.

00:23:39.760 --> 00:23:42.500
And incidentally, Moore himself,

00:23:42.500 --> 00:23:45.180
later on in his little book Ethics,

00:23:45.180 --> 00:23:47.410
abandoned that view

00:23:47.410 --> 00:23:49.460
about the worlds without consciousness

00:23:49.460 --> 00:23:51.250
and agreed with Sidgwick that nothing

00:23:51.250 --> 00:23:52.800
is intrinsically good unless

00:23:52.800 --> 00:23:55.233
it has some relation to consciousness.

00:23:57.090 --> 00:24:01.137
But even if we agree that
such things as beauty

00:24:01.137 --> 00:24:03.670
and knowledge are only
good in some relationship

00:24:03.670 --> 00:24:06.510
to human beings or to minds of some kind,

00:24:06.510 --> 00:24:10.240
somebody might say that
it would be reasonable

00:24:10.240 --> 00:24:12.770
to be concerned with producing
them for their own sake

00:24:12.770 --> 00:24:14.480
and take them as ultimate ends,

00:24:14.480 --> 00:24:16.730
irrespective of who may come

00:24:16.730 --> 00:24:20.203
to appreciate the beauty
or gain in knowledge.

00:24:21.390 --> 00:24:23.440
But Sedgewick's argument
is that they can only

00:24:23.440 --> 00:24:26.910
be ultimately good if they
lead either to happiness

00:24:26.910 --> 00:24:30.570
or to the perfection of
excellence of human existence.

00:24:30.570 --> 00:24:32.530
In other words, he's saying,

00:24:32.530 --> 00:24:34.150
these goods have to be connected

00:24:34.150 --> 00:24:36.640
with human existence in some way.

00:24:36.640 --> 00:24:38.240
And he's now considering, yes,

00:24:38.240 --> 00:24:39.780
but maybe they don't have to be connected

00:24:39.780 --> 00:24:41.740
with human existence
in terms of happiness,

00:24:41.740 --> 00:24:45.120
maybe they are connected
with human existence

00:24:45.120 --> 00:24:50.120
in terms of achieving certain
perfections or excellences

00:24:50.430 --> 00:24:54.363
which are intrinsically
good in themselves.

00:24:56.150 --> 00:24:59.070
That idea, of what is intrinsically good

00:24:59.070 --> 00:25:01.340
is perfection or excellence,

00:25:01.340 --> 00:25:05.300
probably sounds a little
odd to modern ears,

00:25:05.300 --> 00:25:08.390
in a more egalitarian kind of era

00:25:08.390 --> 00:25:10.070
but it certainly is an ancient tradition

00:25:10.070 --> 00:25:14.030
which can be traced back,
at least to Ancient Greece

00:25:14.030 --> 00:25:18.120
and to Aristotle and came
into Western thought,

00:25:18.120 --> 00:25:19.930
or Aristotle's version of this idea

00:25:19.930 --> 00:25:22.390
came to Western thinking through Aquinas

00:25:22.390 --> 00:25:24.710
and you can find it today
in contemporary writers

00:25:24.710 --> 00:25:27.560
like John Finnis who are in that,

00:25:27.560 --> 00:25:30.390
loosely in that Thomistic tradition

00:25:30.390 --> 00:25:32.080
but I think the Aristotelian version

00:25:32.080 --> 00:25:34.560
of excellences makes sense

00:25:34.560 --> 00:25:38.150
only within a pre-Darwinian
view of the world.

00:25:38.150 --> 00:25:40.310
That is, a view that that the world exists

00:25:40.310 --> 00:25:43.290
for some purpose and the purpose

00:25:43.290 --> 00:25:46.500
is for us to achieve these highest goods,

00:25:46.500 --> 00:25:50.740
in particular, for Aristotle,
to perfect our rationality

00:25:50.740 --> 00:25:52.260
which is the highest good.

00:25:52.260 --> 00:25:55.480
If we abandon the idea that
the world exists for a purpose,

00:25:55.480 --> 00:25:59.160
then at least, that
Aristotelian way of arguing

00:25:59.160 --> 00:26:02.820
for excellences as intrinsic good,

00:26:02.820 --> 00:26:04.813
I think doesn't really work.

00:26:06.410 --> 00:26:09.850
Because human nature is not
then going to necessarily

00:26:09.850 --> 00:26:10.900
be intrinsically good.

00:26:10.900 --> 00:26:12.650
There may be aspects of our nature

00:26:12.650 --> 00:26:14.840
that we don't want to perfect,

00:26:14.840 --> 00:26:16.470
like aggression, for example,

00:26:16.470 --> 00:26:18.820
which seems on a Darwinian view

00:26:18.820 --> 00:26:21.893
to be one aspect of our human nature.

00:26:24.000 --> 00:26:26.350
There are other forms
of perfectionism too.

00:26:26.350 --> 00:26:30.090
One is related to the
idea of living virtuously.

00:26:30.090 --> 00:26:31.780
And virtue ethics has had something

00:26:31.780 --> 00:26:34.580
of a revival in recent years.

00:26:34.580 --> 00:26:37.300
But I think Sidgwick's
criticism of virtue ethics

00:26:37.300 --> 00:26:41.760
is something that applies
still to modern virtue ethics,

00:26:41.760 --> 00:26:44.740
at least if the virtue ethicist

00:26:44.740 --> 00:26:49.313
is trying to offer a comprehensive
normative ethical theory.

00:26:50.770 --> 00:26:53.730
What Sidgwick says is that to know

00:26:53.730 --> 00:26:55.470
what qualities are virtues,

00:26:55.470 --> 00:26:58.350
we need to know what we ought to do.

00:26:58.350 --> 00:27:00.020
You can't just have the ideas of virtues

00:27:00.020 --> 00:27:03.560
independently of some idea
of what we ought to do.

00:27:03.560 --> 00:27:05.280
And to know what we ought to do,

00:27:05.280 --> 00:27:08.180
we have to define what the good is.

00:27:08.180 --> 00:27:11.250
Therefore to define the
ultimate good as virtue,

00:27:11.250 --> 00:27:13.973
is just to go round in a circle.

00:27:15.170 --> 00:27:16.610
And maybe that can be made clearer

00:27:16.610 --> 00:27:19.060
if we look at some specific virtues.

00:27:19.060 --> 00:27:23.020
Sidgwick, for instance, gives
the example of frugality,

00:27:23.020 --> 00:27:24.700
which was a virtue in Sidgwick's day.

00:27:24.700 --> 00:27:27.550
I guess, people didn't get regular mail

00:27:27.550 --> 00:27:29.919
asking them to take out more credit cards

00:27:29.919 --> 00:27:32.580
when Sidgwick was around.

00:27:32.580 --> 00:27:35.330
So when does frugality pass over

00:27:35.330 --> 00:27:38.690
into the vice of meanness, Sidgwick asks.

00:27:38.690 --> 00:27:42.810
Or when does courage become foolhardiness?

00:27:42.810 --> 00:27:46.883
When do candor or generosity
or humility become excessive?

00:27:47.980 --> 00:27:50.850
Sidgwick argues, you can
only answer those questions

00:27:50.850 --> 00:27:53.960
by having a notion of what is good

00:27:53.960 --> 00:27:55.640
and without such a notion,

00:27:55.640 --> 00:27:58.803
virtue theory would be
seriously incomplete.

00:28:01.470 --> 00:28:04.750
Finally, just one third
form of perfectionism.

00:28:04.750 --> 00:28:07.320
John Rawls, in A Theory of Justice,

00:28:07.320 --> 00:28:09.190
talked about perfectionism as simply

00:28:09.190 --> 00:28:11.140
the idea that achieving excellence,

00:28:11.140 --> 00:28:14.240
whether in art or science or culture,

00:28:14.240 --> 00:28:16.610
trumps all other values.

00:28:16.610 --> 00:28:18.700
So for a perfectionist,
if the achievements

00:28:18.700 --> 00:28:22.700
of Ancient Greece could only be realized

00:28:22.700 --> 00:28:27.670
because they had slaves,
then slavery was justified.

00:28:27.670 --> 00:28:29.883
That, of course, is not Rawls' view.

00:28:31.800 --> 00:28:36.450
But Sedgwick does discuss such a view too

00:28:36.450 --> 00:28:39.220
and he argues that however immediately

00:28:39.220 --> 00:28:41.430
the excellent quality of such gifts

00:28:41.430 --> 00:28:44.340
and skills may be recognized and admired,

00:28:44.340 --> 00:28:46.410
reflection shows that
they're only valuable

00:28:46.410 --> 00:28:49.610
on account of the good or
desirable conscious life

00:28:49.610 --> 00:28:52.130
in which they are or will be actualized

00:28:52.130 --> 00:28:55.590
or which we somehow
promoted by their exercise.

00:28:55.590 --> 00:28:58.700
In other words, he's sticking
to a mental state view

00:28:58.700 --> 00:29:01.580
and saying that art,
science, and philosophy

00:29:01.580 --> 00:29:04.140
are good only insofar as they promote

00:29:04.140 --> 00:29:08.593
or are part of a desirable conscious life.

00:29:09.960 --> 00:29:11.850
And again, you have to ask yourself,

00:29:11.850 --> 00:29:14.170
does reflection show that?

00:29:14.170 --> 00:29:18.040
Sedgwick is appealing to
your considered judgment.

00:29:18.040 --> 00:29:21.340
And again, I would say,
at least that mine does.

00:29:21.340 --> 00:29:22.660
It may not be true of all of you,

00:29:22.660 --> 00:29:25.640
but I think if art,
science, and philosophy

00:29:25.640 --> 00:29:28.930
had no positive effect
on the conscious lives

00:29:28.930 --> 00:29:33.363
of sentient beings at all,
it would not be valuable.

00:29:35.540 --> 00:29:36.660
So Sedgwick, at this stage,

00:29:36.660 --> 00:29:39.050
is taking his argument to
show that ultimate goodness

00:29:39.050 --> 00:29:43.313
is good or desirable
consciousness or sentient life.

00:29:46.090 --> 00:29:47.630
There's a well-known
objection to this view,

00:29:47.630 --> 00:29:49.930
a modern objection that
Sidgwick didn't, of course,

00:29:49.930 --> 00:29:52.240
explicitly consider, although he does say

00:29:52.240 --> 00:29:53.613
some things relevant to it.

00:29:54.540 --> 00:29:56.980
It was put forward by Robert Nozick

00:29:56.980 --> 00:30:00.133
and I'll read you a couple
of relevant passages.

00:30:01.640 --> 00:30:04.740
Suppose there were an experience machine

00:30:04.740 --> 00:30:07.333
that could give you any
experience you desired.

00:30:08.260 --> 00:30:11.600
Superduper neuropsychologists
could stimulate your brain

00:30:11.600 --> 00:30:12.800
so that you would think and feel

00:30:12.800 --> 00:30:14.650
that you were writing a great novel

00:30:14.650 --> 00:30:18.200
or making a friend or
reading an interesting book.

00:30:18.200 --> 00:30:20.170
All the time, you would
be floating in a tank

00:30:20.170 --> 00:30:22.980
with electrodes attached to your brain.

00:30:22.980 --> 00:30:25.470
Should you plug into
this machine for life,

00:30:25.470 --> 00:30:28.503
programming, pre-programming
your life's desires.

00:30:29.420 --> 00:30:30.810
Of course, while in the tank,

00:30:30.810 --> 00:30:32.560
you won't know that you're there.

00:30:32.560 --> 00:30:35.160
You'll think it's all actually happening.

00:30:35.160 --> 00:30:38.480
Others can also plug in, to
have the experiences they want,

00:30:38.480 --> 00:30:42.500
so there's no need to stay
unplugged to serve them

00:30:42.500 --> 00:30:44.330
and Nozick says we should ignore problems

00:30:44.330 --> 00:30:47.060
such as who's going to
service the machines

00:30:47.060 --> 00:30:48.383
if everyone plugs in.

00:30:50.280 --> 00:30:52.360
The question is, would you plug in?

00:30:52.360 --> 00:30:54.250
And the point of the example of course is

00:30:54.250 --> 00:30:56.300
that Nozick expects us to say, no,

00:30:56.300 --> 00:30:59.160
I would not plug in to
the experience machine

00:30:59.160 --> 00:31:01.950
and if you do say no, that surely implies

00:31:01.950 --> 00:31:04.200
that something matters to you other

00:31:04.200 --> 00:31:07.360
than conscious experiences,
other than how your life

00:31:07.360 --> 00:31:10.660
feels from the inside
because if you do plug in,

00:31:10.660 --> 00:31:14.640
you can have the best
possible conscious experiences

00:31:14.640 --> 00:31:17.830
you can imagine of the
whole range of pleasures.

00:31:17.830 --> 00:31:19.420
This is not like Feldman's criticism

00:31:19.420 --> 00:31:20.980
of just sensory pleasures

00:31:20.980 --> 00:31:23.540
because if you want the
pleasure of making a friend

00:31:23.540 --> 00:31:25.930
or reading a good book or
climbing Mount Everest,

00:31:25.930 --> 00:31:28.593
we can program the
machine to give it to you.

00:31:29.670 --> 00:31:32.520
But Nozick says, we don't want that.

00:31:32.520 --> 00:31:34.610
We want to be a certain kind of person,

00:31:34.610 --> 00:31:37.160
loving, brave, intelligent, and so on,

00:31:37.160 --> 00:31:39.650
not just a body floating in a tank.

00:31:39.650 --> 00:31:42.273
We want to live in contact with reality.

00:31:43.950 --> 00:31:45.740
The experience machine is a powerful

00:31:45.740 --> 00:31:47.853
reason for rejecting ethical hedonism.

00:31:49.450 --> 00:31:53.790
But does the conclusion

00:31:53.790 --> 00:31:56.333
really follow from this example?

00:31:59.130 --> 00:32:00.620
It's true that we can have desires

00:32:00.620 --> 00:32:02.340
for things that are not mental states,

00:32:02.340 --> 00:32:04.480
that we do have such desires.

00:32:04.480 --> 00:32:08.130
For example, I might
desire that the people

00:32:08.130 --> 00:32:11.163
I consider to be my friends
like and respect me.

00:32:12.500 --> 00:32:14.820
Suppose also, in fact,
none of these people

00:32:14.820 --> 00:32:18.033
like or respect me, they think
that I'm a conceited fool.

00:32:19.470 --> 00:32:21.770
But they are very well-intentioned people

00:32:21.770 --> 00:32:24.330
and they know about my desire

00:32:24.330 --> 00:32:26.100
and they don't wish to cause me distress

00:32:26.100 --> 00:32:28.270
so they all pretend to
like and respect me.

00:32:28.270 --> 00:32:29.510
(audience laughing)

00:32:29.510 --> 00:32:33.013
And they do this so well that
I never know the difference.

00:32:34.830 --> 00:32:36.550
I live to a ripe old age.

00:32:36.550 --> 00:32:38.790
I died without ever
knowing that I was mistaken

00:32:38.790 --> 00:32:41.640
about the opinions of the
people I took to be my friends.

00:32:42.785 --> 00:32:44.870
Although I believed that my desire

00:32:44.870 --> 00:32:47.280
to be liked and respected was satisfied,

00:32:47.280 --> 00:32:49.930
there's clearly a sense
in which it was not

00:32:49.930 --> 00:32:52.953
and the desire theory, that's
the theory that as I said,

00:32:54.650 --> 00:32:57.550
I certainly used to hold
and for a long time,

00:32:57.550 --> 00:32:59.370
the desire theory does not locate

00:32:59.370 --> 00:33:01.520
ultimate value in mental states alone.

00:33:01.520 --> 00:33:03.440
And so it gives you an easy response

00:33:03.440 --> 00:33:05.913
to the experience machine
thought experiment.

00:33:08.471 --> 00:33:11.100
If we don't want those illusions

00:33:11.100 --> 00:33:15.270
then the desire theory or
the preference utilitarian

00:33:15.270 --> 00:33:18.280
does not have to say
that we should plug in.

00:33:18.280 --> 00:33:20.750
If our desire is to live
in contact with reality,

00:33:20.750 --> 00:33:23.650
it follows from, for the
preference utilitarian,

00:33:23.650 --> 00:33:26.623
that this is what we should indeed do.

00:33:27.550 --> 00:33:29.140
So as I say, that was an example,

00:33:29.140 --> 00:33:31.330
it was one of the
factors, not the only one,

00:33:31.330 --> 00:33:34.310
but one of the factors that led me

00:33:34.310 --> 00:33:35.970
to think that a preference based view

00:33:35.970 --> 00:33:37.683
is better than a hedonistic view.

00:33:38.820 --> 00:33:41.160
But I'm no longer convinced
that the experience machine

00:33:41.160 --> 00:33:43.200
is a sufficient reason for abandoning

00:33:43.200 --> 00:33:46.773
hedonism in favor of
desire-based theory of value.

00:33:48.900 --> 00:33:50.770
I recognize the strengths
of the intuitions

00:33:50.770 --> 00:33:53.900
we have against plugging into the machine.

00:33:53.900 --> 00:33:55.420
There, in part, I believe

00:33:55.420 --> 00:33:58.309
the result of our nature
as purposive beings.

00:33:58.309 --> 00:34:00.880
For thousands of generations,

00:34:00.880 --> 00:34:04.490
in the world in which our
ancestors were surviving,

00:34:04.490 --> 00:34:07.230
both competing and cooperating

00:34:07.230 --> 00:34:09.230
with other intelligent beings,

00:34:09.230 --> 00:34:11.500
to improve their chances of survival

00:34:11.500 --> 00:34:14.780
and the survival of their offspring,

00:34:14.780 --> 00:34:16.770
they had to act purposively.

00:34:16.770 --> 00:34:20.870
They couldn't just act for
the pleasures of the moment.

00:34:20.870 --> 00:34:24.720
So we've evolved a need to act purposively

00:34:24.720 --> 00:34:26.770
and a strong tendency to override

00:34:26.770 --> 00:34:28.970
our immediate pleasures and pains

00:34:28.970 --> 00:34:30.973
for the sake of larger purposes.

00:34:32.200 --> 00:34:33.440
That leads to what's sometimes called

00:34:33.440 --> 00:34:35.510
the paradox of hedonism,

00:34:35.510 --> 00:34:37.980
the idea that we're most
likely to find pleasure

00:34:37.980 --> 00:34:41.770
by setting ourselves
certain purposes and goals

00:34:41.770 --> 00:34:44.300
that stand apart from our
own desire for pleasure.

00:34:44.300 --> 00:34:46.990
If you directly say I'm going to do

00:34:46.990 --> 00:34:49.183
what will give me most pleasure now,

00:34:50.100 --> 00:34:51.890
the paradox of hedonism suggests

00:34:51.890 --> 00:34:53.793
you're not going to find it.

00:34:55.580 --> 00:34:57.420
But the experience machine objection

00:34:57.420 --> 00:35:00.800
asks us to imagine a world
in which everyone's needs

00:35:00.800 --> 00:35:04.673
can be taken care of completely, forever.

00:35:05.590 --> 00:35:07.040
And that includes not only their needs

00:35:07.040 --> 00:35:09.140
for food and shelter but for the avoidance

00:35:09.140 --> 00:35:12.100
of whatever experiences
they wish to avoid.

00:35:12.100 --> 00:35:14.223
In such a radically different world,

00:35:15.080 --> 00:35:18.023
all of our usual purposes become otiose.

00:35:19.070 --> 00:35:21.870
There's no need for us
to save for old-age,

00:35:21.870 --> 00:35:23.470
ensure that our children and grandchildren

00:35:23.470 --> 00:35:26.120
get a good education, or even to seek

00:35:26.120 --> 00:35:29.203
to end world poverty or
protect human rights.

00:35:30.790 --> 00:35:32.180
To make the example complete,

00:35:32.180 --> 00:35:33.770
I guess we have to say there's no need

00:35:33.770 --> 00:35:37.560
for us to work to protect the
welfare of animals either.

00:35:37.560 --> 00:35:39.380
I suppose that might mean

00:35:39.380 --> 00:35:41.130
that they get their own
experience machines.

00:35:41.130 --> 00:35:43.963
I'm not quite sure what
Nozick had in mind there.

00:35:45.290 --> 00:35:49.680
But if we still have this need

00:35:49.680 --> 00:35:51.920
to live to some purpose,
then it's no wonder

00:35:51.920 --> 00:35:54.470
that we think that
there is something wrong

00:35:54.470 --> 00:35:56.883
with plugging into the experience machine.

00:35:59.070 --> 00:36:02.730
The situation resembles
that of asking somebody

00:36:02.730 --> 00:36:05.040
to drink a glass of apple juice in which,

00:36:05.040 --> 00:36:06.510
just in front of their eyes,

00:36:06.510 --> 00:36:10.400
you have taken a roach
carefully sterilized

00:36:10.400 --> 00:36:13.730
in a medical sterilizing
cabinet and then dipped

00:36:13.730 --> 00:36:16.560
it into the apple juice and withdrawn it.

00:36:16.560 --> 00:36:18.320
This is an experiment that has been done

00:36:18.320 --> 00:36:20.930
by Jonathan Hite, among others,

00:36:20.930 --> 00:36:22.990
and we know that many people are reluctant

00:36:22.990 --> 00:36:24.950
to drink the apple juice,
even though previously,

00:36:24.950 --> 00:36:27.560
they have expressed a desire
to drink some apple juice.

00:36:27.560 --> 00:36:28.870
(audience laughing)

00:36:28.870 --> 00:36:31.080
So intellectually, we can grasp

00:36:31.080 --> 00:36:32.610
that there's nothing
wrong with the apple juice

00:36:32.610 --> 00:36:35.700
that had the roach, sterilized
roach dipped into it

00:36:35.700 --> 00:36:38.283
but we can't quite get
rid of that intuition.

00:36:39.170 --> 00:36:41.630
So I'm suggesting that
maybe something similar

00:36:41.630 --> 00:36:43.710
is going on here with our intuition

00:36:43.710 --> 00:36:46.440
that even in the circumstances described,

00:36:46.440 --> 00:36:48.240
very imaginary circumstances,

00:36:48.240 --> 00:36:52.510
quite beyond reality, that we would not

00:36:54.130 --> 00:36:56.183
want to plug into the experience machine.

00:36:57.870 --> 00:36:59.460
There are other reasons too, of course.

00:36:59.460 --> 00:37:01.960
One might be that we just don't believe

00:37:01.960 --> 00:37:03.770
that the technology is foolproof.

00:37:03.770 --> 00:37:08.003
This problem of accepting
the hypothesis and so on.

00:37:09.070 --> 00:37:11.290
Of course, since Nozick put this example,

00:37:11.290 --> 00:37:13.180
we've become familiar with the idea

00:37:13.180 --> 00:37:15.155
from films like The Matrix

00:37:15.155 --> 00:37:17.790
but we don't like that idea either

00:37:17.790 --> 00:37:21.140
because we were being exploited
by intelligent machines

00:37:21.140 --> 00:37:23.460
who needed our body heat to provide energy

00:37:23.460 --> 00:37:25.290
or some further bizarre reason

00:37:25.290 --> 00:37:27.070
that's difficult to understand.

00:37:27.070 --> 00:37:28.640
(audience laughing)

00:37:28.640 --> 00:37:32.220
But you have to imagine
that in Nozick's machines,

00:37:32.220 --> 00:37:33.990
you know that none of
this is going to happen.

00:37:33.990 --> 00:37:36.223
No one is going to suffer or will be.

00:37:37.820 --> 00:37:39.060
Still, the suspicion that something

00:37:39.060 --> 00:37:40.633
will go wrong is hard to avoid.

00:37:41.880 --> 00:37:44.200
There's another possible
factor going on here

00:37:44.200 --> 00:37:46.050
that's been exposed by some empirical

00:37:46.050 --> 00:37:48.743
research by Felipe De Brigard.

00:37:50.530 --> 00:37:53.110
He asked people to imagine,

00:37:53.110 --> 00:37:55.700
he was interested in finding why

00:37:55.700 --> 00:37:57.980
people are reluctant to
enter the experience machine

00:37:57.980 --> 00:37:59.420
or if indeed they are.

00:37:59.420 --> 00:38:01.230
So he asked people to imagine

00:38:01.230 --> 00:38:04.580
that they're already connected
to an experience machine

00:38:04.580 --> 00:38:07.800
and now face the choice of
either remaining connected

00:38:07.800 --> 00:38:09.683
or going back to live in reality.

00:38:10.820 --> 00:38:13.970
And he randomly offered
them one of three vignettes.

00:38:13.970 --> 00:38:15.840
In what he called the neutral vignette,

00:38:15.840 --> 00:38:18.400
you're simply told that
you can go back to reality

00:38:18.400 --> 00:38:20.760
if you like but not given any information

00:38:20.760 --> 00:38:23.063
about what reality will be like for you.

00:38:23.940 --> 00:38:26.530
In the negative vignette,
you're told that in reality,

00:38:26.530 --> 00:38:28.900
you're a prisoner in a
maximum-security prison

00:38:30.290 --> 00:38:32.710
and in the positive vignette,
you're told that in reality,

00:38:32.710 --> 00:38:35.714
you are a multi-millionaire
artist living in Monaco.

00:38:35.714 --> 00:38:37.310
(audience laughing)

00:38:37.310 --> 00:38:40.970
Now, of those participants
given the neutral vignette,

00:38:40.970 --> 00:38:42.880
46% said they would prefer

00:38:42.880 --> 00:38:45.093
to stay plugged into
the experience machine.

00:38:46.750 --> 00:38:49.600
Among those given the negative vignette,

00:38:49.600 --> 00:38:52.360
that figure rose to 87%.

00:38:52.360 --> 00:38:54.150
That's not so surprising,
for the alternative

00:38:54.150 --> 00:38:57.000
for them was life in a
maximum-security prison.

00:38:57.000 --> 00:38:58.440
But most surprisingly of all,

00:38:58.440 --> 00:39:00.740
of those given the positive vignette,

00:39:00.740 --> 00:39:02.970
exactly half preferred to say connected

00:39:02.970 --> 00:39:05.380
to the machine rather
than return to reality

00:39:05.380 --> 00:39:08.290
as a multi-millionaire
artist living in Monaco.

00:39:08.290 --> 00:39:09.950
Monaco has to do a bit better

00:39:09.950 --> 00:39:11.830
in its public relations, obviously.

00:39:11.830 --> 00:39:15.040
(audience laughing)

00:39:15.040 --> 00:39:18.230
So these results don't support Nozick's

00:39:18.230 --> 00:39:20.210
confident judgment that we prefer to live

00:39:20.210 --> 00:39:22.820
in reality rather than
plugged into a machine.

00:39:22.820 --> 00:39:24.330
They also though, admittedly,

00:39:24.330 --> 00:39:25.197
don't support the hedonistic view

00:39:25.197 --> 00:39:27.060
that what people are choosing to do

00:39:27.060 --> 00:39:28.560
is to maximize their pleasure.

00:39:29.870 --> 00:39:32.359
But what is interesting
and the reason why Brigard

00:39:32.359 --> 00:39:35.610
asked the question the way he did,

00:39:35.610 --> 00:39:39.610
is that the status quo bias
is playing a role here.

00:39:39.610 --> 00:39:41.670
So the status quo bias, for
those who are not familiar,

00:39:41.670 --> 00:39:43.700
is a well-known psychological phenomenon.

00:39:43.700 --> 00:39:45.930
It's been studied in various ways,

00:39:45.930 --> 00:39:48.340
that suggests that people are reluctant

00:39:48.340 --> 00:39:51.600
to depart from the status quo.

00:39:51.600 --> 00:39:53.930
So if you give them $2, and for example,

00:39:53.930 --> 00:39:56.163
and say for $2, you can buy this cup.

00:39:57.530 --> 00:40:01.250
Then let's say, relatively,
many people would think,

00:40:01.250 --> 00:40:02.083
oh, that's a nice cup.

00:40:02.083 --> 00:40:04.230
Sure, here's $2, I'll buy it.

00:40:04.230 --> 00:40:07.170
But if you give them the
cup and say here's your cup

00:40:07.170 --> 00:40:09.910
and somebody offers them $2 for it.

00:40:09.910 --> 00:40:11.670
I think I've got this
slightly wrong, sorry,

00:40:11.670 --> 00:40:14.650
but the idea is whatever you give them

00:40:14.650 --> 00:40:16.080
is something, their endowment,

00:40:16.080 --> 00:40:18.590
and they're reluctant to depart from it.

00:40:18.590 --> 00:40:23.120
So the same kind of thing
seems to be going on here,

00:40:23.120 --> 00:40:25.890
that one of the reasons
why we may be reluctant

00:40:25.890 --> 00:40:27.310
to enter into the experience machine

00:40:27.310 --> 00:40:30.210
is we're reasonably
content with the status quo

00:40:30.210 --> 00:40:33.810
and so we don't want to give
it up for something unknown

00:40:33.810 --> 00:40:35.710
but if you ask people to imagine,

00:40:35.710 --> 00:40:39.010
even just imagine that they
are plugged into the machine

00:40:39.010 --> 00:40:41.660
and then that they move
from that to reality,

00:40:41.660 --> 00:40:45.100
then they are also more reluctant

00:40:45.100 --> 00:40:48.160
to abandon the status quo.

00:40:48.160 --> 00:40:49.470
And one way of confirming that,

00:40:49.470 --> 00:40:51.730
once De Brigard had his results,

00:40:51.730 --> 00:40:55.080
he then put a fourth vignette to people,

00:40:55.080 --> 00:40:56.470
identical to the neutral one,

00:40:56.470 --> 00:40:58.440
except that the participants were told

00:40:58.440 --> 00:41:00.550
that life outside the machine is not

00:41:00.550 --> 00:41:04.280
at all like the life
you experienced so far.

00:41:04.280 --> 00:41:06.580
That information dropped
the number of people

00:41:06.580 --> 00:41:11.160
who were prepared to
disconnect from 50% to 41%.

00:41:11.160 --> 00:41:14.203
Not a huge difference but it
did appear to have an effect.

00:41:15.550 --> 00:41:18.690
So that also suggests that
the experience machine

00:41:18.690 --> 00:41:21.193
is not a decisive objection to the view

00:41:21.193 --> 00:41:24.613
that what is ultimately good
is a state of consciousness.

00:41:26.940 --> 00:41:29.520
Section seven, the experiencing self

00:41:29.520 --> 00:41:31.563
and the remembering self.

00:41:37.330 --> 00:41:39.890
Many attempts to survey happiness

00:41:39.890 --> 00:41:42.823
ask people how satisfied
they are with their life.

00:41:43.890 --> 00:41:45.740
For example, there's something called

00:41:45.740 --> 00:41:49.390
the Gallup World Poll,
which has many questions.

00:41:49.390 --> 00:41:52.890
One section is on well-being
and under well-being,

00:41:52.890 --> 00:41:55.320
the Gallup World Poll asked people

00:41:55.320 --> 00:41:57.810
to give a number between 1 and 10,

00:41:57.810 --> 00:41:59.870
indicating their answer to the question,

00:41:59.870 --> 00:42:02.150
all things considered, how satisfied

00:42:02.150 --> 00:42:04.913
are you with your life
as a whole these days?

00:42:06.900 --> 00:42:08.460
Hebron and Feldman have pointed out

00:42:08.460 --> 00:42:12.480
that for various reasons,
this asks a different question

00:42:12.480 --> 00:42:15.620
from how happy are you now?

00:42:15.620 --> 00:42:17.970
You might be satisfied
but you might be satisfied

00:42:17.970 --> 00:42:20.473
because you have low expectations.

00:42:21.420 --> 00:42:22.720
Some people might think, for example,

00:42:22.720 --> 00:42:26.193
well, how happy can a
sinner like me expect to be?

00:42:27.270 --> 00:42:30.520
Or someone who has internalized

00:42:30.520 --> 00:42:33.640
the repressive attitudes of
her society towards women

00:42:33.640 --> 00:42:36.890
might also be fairly, be
not very happy at all,

00:42:36.890 --> 00:42:38.970
but still satisfied with her life.

00:42:38.970 --> 00:42:40.680
The same might be true if you're a member

00:42:40.680 --> 00:42:42.963
of a low caste or an ethnic minority.

00:42:44.930 --> 00:42:46.850
Daniel Kahneman, who I mentioned earlier,

00:42:46.850 --> 00:42:49.540
together with Angus Deaton,

00:42:49.540 --> 00:42:51.240
has shown another interesting distinction

00:42:51.240 --> 00:42:53.220
between the answers that
Americans, at least,

00:42:53.220 --> 00:42:56.240
give to Gallup's life
satisfaction question

00:42:56.240 --> 00:42:57.630
and the answers they give to questions

00:42:57.630 --> 00:42:59.940
about their emotional well-being.

00:42:59.940 --> 00:43:01.900
So on the one hand, an
answer to the question

00:43:01.900 --> 00:43:04.980
that I just gave you,
how satisfied are you,

00:43:04.980 --> 00:43:07.630
all things considered with
your life, these days?

00:43:07.630 --> 00:43:11.680
With questions that indicate the emotional

00:43:11.680 --> 00:43:15.130
quality of an individual's
everyday experiences,

00:43:15.130 --> 00:43:17.740
the frequency and intensity
of experiences of joy,

00:43:17.740 --> 00:43:20.600
stress, sadness, anger, and affection,

00:43:20.600 --> 00:43:22.800
that make one's life
pleasant or unpleasant.

00:43:24.600 --> 00:43:27.130
According to Kahneman and Deaton,

00:43:27.130 --> 00:43:29.070
whereas the higher your income,

00:43:29.070 --> 00:43:32.463
the higher life satisfaction
you are likely to report,

00:43:34.050 --> 00:43:37.860
your emotional well-being
shows no further increases

00:43:37.860 --> 00:43:42.520
once your income reaches
$75,000 per annum.

00:43:42.520 --> 00:43:43.990
As I say, for Americans.

00:43:43.990 --> 00:43:45.500
And this is an interesting answer,

00:43:45.500 --> 00:43:47.530
that there's been a lot of discussion

00:43:47.530 --> 00:43:52.530
about whether, indeed, happiness
does increase with income.

00:43:53.220 --> 00:43:55.590
For many years it was
believed that it did not,

00:43:55.590 --> 00:43:59.240
that it increased only
up to a certain plateau

00:43:59.240 --> 00:44:01.670
and then that it just plateaued.

00:44:01.670 --> 00:44:03.890
Then Kahneman and Deaton argued

00:44:03.890 --> 00:44:05.660
that that was wrong.

00:44:05.660 --> 00:44:06.599
Deaton in particular, initially,

00:44:06.599 --> 00:44:08.670
and a couple of other people argued

00:44:08.670 --> 00:44:11.240
that in fact it does go up indefinitely,

00:44:11.240 --> 00:44:14.380
although admittedly it
goes up much more slowly,

00:44:14.380 --> 00:44:18.030
only after that plateau but
they claimed it did increase.

00:44:18.030 --> 00:44:19.760
Now it seems that the answer is it depends

00:44:19.760 --> 00:44:21.760
exactly on what you're measuring,

00:44:21.760 --> 00:44:23.810
whether you're measuring how people answer

00:44:23.810 --> 00:44:25.640
the life satisfaction question.

00:44:25.640 --> 00:44:27.940
In which case, yes, it
does continue to go up,

00:44:27.940 --> 00:44:31.560
even after the plateau,
although more slowly than before

00:44:31.560 --> 00:44:34.990
or whether it's emotional well-being

00:44:34.990 --> 00:44:37.770
that is the frequency
of these experiences,

00:44:37.770 --> 00:44:40.330
which obviously is closer to
what I've been talking about,

00:44:40.330 --> 00:44:43.300
the hedonistic view of pleasure and pain.

00:44:43.300 --> 00:44:45.880
And there, it does seem that it plateaus

00:44:45.880 --> 00:44:49.730
after this reasonably comfortable level

00:44:49.730 --> 00:44:52.053
of 75000 per annum.

00:44:53.550 --> 00:44:57.163
And as part of this
discussion and other writings,

00:44:59.090 --> 00:45:02.300
Kahneman has, good thing
that I got a laptop here,

00:45:02.300 --> 00:45:04.100
rather than paper I guess, isn't it?

00:45:05.380 --> 00:45:06.820
Kahneman has developed the distinction

00:45:06.820 --> 00:45:11.510
between the experiencing self
and the remembering self.

00:45:11.510 --> 00:45:14.830
And here's one way of
illustrating that distinction.

00:45:14.830 --> 00:45:16.930
Patients undergoing a colonoscopy.

00:45:16.930 --> 00:45:19.340
Thank you, patients
undergoing a colonoscopy

00:45:19.340 --> 00:45:20.880
were asked to report, in intervals,

00:45:20.880 --> 00:45:22.980
the level of pain or
discomfort they were feeling.

00:45:22.980 --> 00:45:23.990
It's pretty amazing than people

00:45:23.990 --> 00:45:25.609
consent to this research, I think.

00:45:25.609 --> 00:45:26.442
(audience laughing)

00:45:26.442 --> 00:45:28.210
Just what you need, you're
undergoing a colonoscopy

00:45:28.210 --> 00:45:30.020
and there's some guy asking
you, how does it feel now?

00:45:30.020 --> 00:45:31.200
How bad is it now?

00:45:31.200 --> 00:45:33.440
Give me a number, 1 out
of 10, what it's like now.

00:45:33.440 --> 00:45:34.440
(audience laughing)

00:45:34.440 --> 00:45:35.940
It seems like people did this.

00:45:37.800 --> 00:45:39.840
Then after the procedure was over,

00:45:39.840 --> 00:45:41.910
they were asked to assess how bad it was

00:45:41.910 --> 00:45:43.410
and to make a hypothetical choice

00:45:43.410 --> 00:45:46.690
between having it repeated
or having a barium enema,

00:45:46.690 --> 00:45:48.690
also I'm not a very pleasant experience.

00:45:49.905 --> 00:45:51.505
And the results were surprising.

00:45:52.420 --> 00:45:55.610
So I'll take just two
sample patients here.

00:45:55.610 --> 00:45:58.960
Patients A and B might
have identically painful

00:45:58.960 --> 00:46:03.340
experiences for the first 10
minutes of the colonoscopy.

00:46:03.340 --> 00:46:05.300
Suppose that patient A's experience

00:46:05.300 --> 00:46:07.960
ends at that point, after 10 minutes,

00:46:07.960 --> 00:46:09.900
then the colonoscopy is over.

00:46:09.900 --> 00:46:12.040
He feels no more pain.

00:46:12.040 --> 00:46:14.420
Whereas patient B's experience,

00:46:14.420 --> 00:46:17.560
having the identical first
10 minutes as patient A,

00:46:17.560 --> 00:46:19.720
continues for another five minutes

00:46:19.720 --> 00:46:22.070
at a level that he still finds painful

00:46:22.070 --> 00:46:25.563
but not as severely painful
as the first 10 minutes.

00:46:27.760 --> 00:46:28.840
Okay, so first question.

00:46:28.840 --> 00:46:30.433
Who suffered the most pain?

00:46:31.370 --> 00:46:32.310
Let me ask you, actually.

00:46:32.310 --> 00:46:33.143
A show of hands,

00:46:33.143 --> 00:46:35.733
how many of you think A
suffered the most pain?

00:46:37.320 --> 00:46:39.553
How many of you think B
suffered the most pain?

00:46:40.450 --> 00:46:42.410
Well, of those who have
dared to show your hands,

00:46:42.410 --> 00:46:44.810
the great majority is for B.

00:46:44.810 --> 00:46:46.270
I think that's right.

00:46:46.270 --> 00:46:47.180
Clearly B did.

00:46:47.180 --> 00:46:49.970
For the first 10 minutes, he
had just as much pain as A

00:46:49.970 --> 00:46:51.880
and then he had an additional five minutes

00:46:51.880 --> 00:46:55.790
of some pain while A was
feeling no pain at all.

00:46:55.790 --> 00:46:57.640
Yet when we ask the patients,

00:46:57.640 --> 00:47:00.870
after the experience is all
over, to rate the experience,

00:47:00.870 --> 00:47:04.140
typically, A rated worse than B

00:47:04.140 --> 00:47:06.393
and is less willing to
repeat the procedure.

00:47:07.280 --> 00:47:09.320
And this is not just in colonoscopies.

00:47:09.320 --> 00:47:12.720
Kahneman has repeated
this by getting people

00:47:12.720 --> 00:47:16.320
to put their arm into extremely cold water

00:47:16.320 --> 00:47:19.930
for two minutes and then
for one further minute

00:47:19.930 --> 00:47:22.130
into water that is still painfully cold

00:47:22.130 --> 00:47:24.960
but not as cold as it was
for the first two minutes.

00:47:24.960 --> 00:47:26.440
And you get the same result.

00:47:26.440 --> 00:47:29.650
The people who put their
arm in the extremely

00:47:29.650 --> 00:47:32.370
cold water for two minutes and
then take it out altogether,

00:47:32.370 --> 00:47:35.150
describe it afterwards
as a worse experience

00:47:35.150 --> 00:47:36.870
than the people who had
the one extra minute

00:47:36.870 --> 00:47:39.523
of still uncomfortably cold water.

00:47:41.090 --> 00:47:44.670
Kahneman calls this
phenomenon duration neglect

00:47:44.670 --> 00:47:47.670
and he considers it a focusing illusion.

00:47:47.670 --> 00:47:50.500
We focus on the last
moments of the experience

00:47:50.500 --> 00:47:53.300
rather than the entire experience.

00:47:53.300 --> 00:47:55.670
And he goes so far as to
say that we have two selves,

00:47:55.670 --> 00:47:58.750
the experiencing self
and the remembering self.

00:47:58.750 --> 00:48:01.160
When we ask questions
about life satisfaction,

00:48:01.160 --> 00:48:03.900
we are necessarily addressing ourselves

00:48:03.900 --> 00:48:05.490
to the remembering self.

00:48:05.490 --> 00:48:06.650
We're asking itself to remember

00:48:06.650 --> 00:48:09.203
what these last few days have been like.

00:48:10.210 --> 00:48:12.510
We can only access the experiencing self

00:48:12.510 --> 00:48:14.490
if we interrupt it at frequent intervals

00:48:14.490 --> 00:48:17.780
to ask, as I said, what is it like now?

00:48:17.780 --> 00:48:18.980
And Kahneman has done this,

00:48:18.980 --> 00:48:21.420
not just for the patients
in colonoscopies,

00:48:21.420 --> 00:48:22.950
but for a larger number of subjects

00:48:22.950 --> 00:48:24.930
going about their daily lives.

00:48:24.930 --> 00:48:28.080
And it's interesting how
technology makes this easier to do.

00:48:28.080 --> 00:48:30.310
He programs their mobile phones

00:48:30.310 --> 00:48:33.170
to interrupt them at very random intervals

00:48:33.170 --> 00:48:36.470
throughout their lives and then
they have to put in a number

00:48:36.470 --> 00:48:40.490
between 0 and 10 to indicate

00:48:40.490 --> 00:48:44.170
the quality of their experience
at that particular moment

00:48:44.170 --> 00:48:46.510
and then he can get all of these results

00:48:46.510 --> 00:48:49.020
and tabulate them, associate them

00:48:49.020 --> 00:48:51.763
with what they were doing at
particular times and so on.

00:48:53.280 --> 00:48:55.140
But given this distinction,

00:48:55.140 --> 00:48:57.600
we then face a value question.

00:48:57.600 --> 00:48:59.370
What is of ultimate value?

00:48:59.370 --> 00:49:02.280
Is it the quality of life
of the experiencing self

00:49:02.280 --> 00:49:03.753
or of the remembering self?

00:49:05.970 --> 00:49:09.300
Kahneman seems to lean
towards the experiencing self,

00:49:09.300 --> 00:49:13.090
saying the logic of duration
waiting is compelling.

00:49:13.090 --> 00:49:14.180
Duration waiting, of course,

00:49:14.180 --> 00:49:16.130
being the idea that we should take account

00:49:16.130 --> 00:49:18.033
of how long an experience lasts.

00:49:19.120 --> 00:49:20.980
And he's also written
that the total utility

00:49:20.980 --> 00:49:24.230
of an episode is a product
of average instant utility,

00:49:24.230 --> 00:49:26.723
the average level, and the duration.

00:49:28.530 --> 00:49:30.340
And that retrospective evaluation

00:49:30.340 --> 00:49:32.580
leads to erroneous estimates of the true

00:49:32.580 --> 00:49:35.310
total utility of past experiences.

00:49:35.310 --> 00:49:37.050
But he also says that duration waiting

00:49:37.050 --> 00:49:39.420
can't be considered a
complete theory of well-being

00:49:39.420 --> 00:49:43.230
because individuals identify
with their remembering self

00:49:43.230 --> 00:49:44.913
and care about their story.

00:49:45.760 --> 00:49:47.400
Quote, a theory of well-being

00:49:47.400 --> 00:49:51.420
that ignores what people
want cannot be sustained.

00:49:51.420 --> 00:49:53.520
So his conclusion is
that the remembering self

00:49:53.520 --> 00:49:56.560
and the experiencing self
must both be considered.

00:49:56.560 --> 00:49:57.930
Their interests don't coincide

00:49:57.930 --> 00:50:00.200
but they both need to
be taken into account.

00:50:00.200 --> 00:50:04.460
That's from his most recent
book, Thinking Fast and Slow.

00:50:04.460 --> 00:50:06.700
And then he adds,
philosophers could struggle

00:50:06.700 --> 00:50:08.823
with these questions for a long time.

00:50:10.260 --> 00:50:12.950
No doubt they could and perhaps they will.

00:50:12.950 --> 00:50:15.660
But Sidgwick did actually
think about these questions

00:50:15.660 --> 00:50:19.150
and without, of course, knowing
exactly this distinction

00:50:19.150 --> 00:50:21.830
that Kahneman is drawing
but he did conclude

00:50:21.830 --> 00:50:24.350
that we should have impartial concern

00:50:24.350 --> 00:50:27.130
for all parts of our conscious life.

00:50:27.130 --> 00:50:28.830
That's a quote and it is of course,

00:50:28.830 --> 00:50:31.970
Kahneman's principle of duration waiting.

00:50:31.970 --> 00:50:32.803
I agree.

00:50:34.060 --> 00:50:35.710
It's true that individuals identify

00:50:35.710 --> 00:50:38.600
with their remembering self
and care about their story

00:50:38.600 --> 00:50:41.210
but presumably, this
actually has some impact

00:50:41.210 --> 00:50:42.660
on their experiences.

00:50:42.660 --> 00:50:45.100
When they're thinking about their story,

00:50:45.100 --> 00:50:48.150
remembering their past
or recent experiences

00:50:48.150 --> 00:50:49.960
and feeling positively about this,

00:50:49.960 --> 00:50:51.670
this is a positive experience

00:50:51.670 --> 00:50:54.210
that improves their current experience.

00:50:54.210 --> 00:50:56.140
And to the extent that their caring

00:50:56.140 --> 00:50:58.910
about the story affects the
quality of their experience,

00:50:58.910 --> 00:51:01.330
of course it does matter on the hedonistic

00:51:01.330 --> 00:51:03.700
view of ultimate value, to the extent

00:51:03.700 --> 00:51:07.320
that it doesn't affect the
quality of their experiences,

00:51:07.320 --> 00:51:09.003
it doesn't matter on that theory.

00:51:10.410 --> 00:51:15.290
So I'm supporting the experiencing

00:51:15.290 --> 00:51:18.223
self over the remembering
self in this choice.

00:51:19.170 --> 00:51:20.560
Is it true, as Kahneman says,

00:51:20.560 --> 00:51:22.320
that a theory of well-being that ignores

00:51:22.320 --> 00:51:25.040
what people want cannot be sustained?

00:51:25.040 --> 00:51:27.390
I certainly would have
thought that in the past

00:51:28.240 --> 00:51:30.010
but now I think that perhaps the only way

00:51:30.010 --> 00:51:32.300
in which that's true is that politically,

00:51:32.300 --> 00:51:34.280
it can't be sustained.

00:51:34.280 --> 00:51:36.240
If government set out to measure happiness

00:51:36.240 --> 00:51:38.270
and to promote it, they'd
better come up with an idea

00:51:38.270 --> 00:51:41.483
of happiness that people want
and are prepared to support.

00:51:42.530 --> 00:51:44.810
It's the remembering self that votes,

00:51:44.810 --> 00:51:48.010
after all, not the experiencing self.

00:51:48.010 --> 00:51:49.810
But that's a problem for democratic theory

00:51:49.810 --> 00:51:52.330
and political philosophy
rather than for the area

00:51:52.330 --> 00:51:54.530
of ethics that inquires
into ultimate value.

00:51:55.960 --> 00:51:57.263
Okay, brief conclusion.

00:51:58.920 --> 00:52:00.670
The 21st century is on track

00:52:00.670 --> 00:52:03.140
to become the happiness century, at least,

00:52:03.140 --> 00:52:06.263
if we can judge by its
first dozen or so years.

00:52:07.200 --> 00:52:09.410
The small Himalayan kingdom of Bhutan

00:52:09.410 --> 00:52:12.730
has long had a policy of
promoting gross national happiness

00:52:12.730 --> 00:52:15.410
rather than gross national product.

00:52:15.410 --> 00:52:17.430
And work in this area has accelerated

00:52:17.430 --> 00:52:20.957
since Bhutan became a
constitutional monarchy

00:52:20.957 --> 00:52:24.333
and a democratic monarchy in 2008.

00:52:25.600 --> 00:52:28.350
That was also the year in
which the french president,

00:52:28.350 --> 00:52:30.270
Nicolas Sarkozy, set up a commission

00:52:30.270 --> 00:52:32.810
chaired by the economist Joseph Stiglitz

00:52:32.810 --> 00:52:35.743
and including also Amartya
Sen and Jean-Paul Fitoussi,

00:52:36.670 --> 00:52:39.470
to recommend ways of
measuring social progress

00:52:39.470 --> 00:52:41.943
as well as economic performance.

00:52:43.370 --> 00:52:45.820
Last year, Bhutan achieved
a diplomatic success

00:52:45.820 --> 00:52:48.520
by persuading the United
Nations General Assembly

00:52:48.520 --> 00:52:50.640
to support a non-binding resolution,

00:52:50.640 --> 00:52:53.540
encouraging member
states to undertake steps

00:52:53.540 --> 00:52:55.280
that give more importance to happiness

00:52:55.280 --> 00:52:58.500
and well-being, in
determining how to achieve

00:52:58.500 --> 00:53:01.363
and measure social and
economic development.

00:53:03.170 --> 00:53:05.870
And earlier this month,

00:53:05.870 --> 00:53:08.870
there was a United Nations
meeting in New York

00:53:08.870 --> 00:53:11.750
to discuss that issue further.

00:53:11.750 --> 00:53:13.700
This year, we've also
seen the United Kingdom

00:53:13.700 --> 00:53:15.520
begin surveying the public with a view

00:53:15.520 --> 00:53:18.210
to establishing a measure
of societal well-being

00:53:18.210 --> 00:53:20.070
and the United States Department

00:53:20.070 --> 00:53:22.650
of Health and Human Services has set up

00:53:22.650 --> 00:53:26.260
a panel of experts in
psychology and economics,

00:53:26.260 --> 00:53:29.200
including Daniel
Kahneman, to try to define

00:53:29.200 --> 00:53:32.163
reliable measures of
subjective well-being.

00:53:33.090 --> 00:53:34.750
If the panel is successful,

00:53:34.750 --> 00:53:38.373
these measures could become
official government statistics.

00:53:40.020 --> 00:53:41.930
Some Americans, responding to the recent

00:53:41.930 --> 00:53:43.140
announcement of this panel,

00:53:43.140 --> 00:53:44.830
have voiced fears that it could herald

00:53:44.830 --> 00:53:47.333
more government interference in our lives.

00:53:49.000 --> 00:53:50.590
In my view, though, Americans have long

00:53:50.590 --> 00:53:53.320
had an exaggerated
suspicion of the dangers

00:53:53.320 --> 00:53:56.040
of government interference
and it's already cost

00:53:56.040 --> 00:53:58.880
them the kind of universal
health care system

00:53:58.880 --> 00:54:02.700
that, in other countries and
other developed countries,

00:54:02.700 --> 00:54:06.290
there's a political consensus
about the desirability of,

00:54:06.290 --> 00:54:09.820
that crosses the liberal,
conservative divide.

00:54:09.820 --> 00:54:11.780
Just as governments see
it as their function

00:54:11.780 --> 00:54:14.200
to promote opportunities
for business development

00:54:14.200 --> 00:54:15.980
that lead to economic growth,

00:54:15.980 --> 00:54:18.840
so I don't see why they should
not see it as their function

00:54:18.840 --> 00:54:21.330
to promote individual choices that lead

00:54:21.330 --> 00:54:24.280
to greater personal happiness or indeed,

00:54:24.280 --> 00:54:28.910
to a maximization of pleasure over pain.

00:54:28.910 --> 00:54:32.900
After all, economic growth
is only a means to an end.

00:54:32.900 --> 00:54:37.320
I have argued that happiness
is also means to an end

00:54:37.320 --> 00:54:39.710
but I think happiness comes closer

00:54:39.710 --> 00:54:43.750
to the ultimate end that I've defended,

00:54:43.750 --> 00:54:45.730
at least, partially defended,

00:54:45.730 --> 00:54:50.510
of intrinsic value of a maximization

00:54:50.510 --> 00:54:53.730
of desirable consciousness, as
Sidgwick would have called it

00:54:53.730 --> 00:54:56.683
or pleasant experiences over painful ones.

00:54:57.700 --> 00:54:59.570
And that seems to me, therefore,

00:54:59.570 --> 00:55:02.223
to be a desirable thing
for governments to do.

00:55:03.250 --> 00:55:05.790
Thank you for your attention.

00:55:05.790 --> 00:55:08.230
I hope that you've found the lecture

00:55:08.230 --> 00:55:10.097
not only a pleasurable experience

00:55:10.097 --> 00:55:11.943
but that I've ended on a high note.

00:55:13.330 --> 00:55:15.490
And I look forward to your questions.

00:55:15.490 --> 00:55:18.657
(audience applauding)

00:55:21.060 --> 00:55:22.910
- [Man] Besides the idea of happiness,

00:55:22.910 --> 00:55:24.850
which in my opinion is what happens to us,

00:55:24.850 --> 00:55:28.560
being instrumental, what about inner joy,

00:55:28.560 --> 00:55:29.960
which is what I really want?

00:55:31.740 --> 00:55:34.760
- So if we're talking about joy,

00:55:34.760 --> 00:55:37.590
I think we are talking about experiences.

00:55:37.590 --> 00:55:42.570
We are talking about a
conscious mental state,

00:55:42.570 --> 00:55:44.290
not a disposition.

00:55:44.290 --> 00:55:47.460
So insofar as you're
actually experiencing joy,

00:55:47.460 --> 00:55:50.900
certainly that would count as a pleasure

00:55:50.900 --> 00:55:53.040
in the term that I'm
using it and therefore,

00:55:53.040 --> 00:55:55.730
as being as something of ultimate value.

00:55:55.730 --> 00:55:57.650
- Okay, thank you.
- Thank you.

00:55:59.320 --> 00:56:00.770
- Little hypothetical thing.

00:56:00.770 --> 00:56:03.610
This is a question for you
and a question for myself.

00:56:03.610 --> 00:56:05.640
If you could clone yourself

00:56:05.640 --> 00:56:09.600
into 1000 experience machines,

00:56:09.600 --> 00:56:12.970
in perpetuity, would you do it?

00:56:12.970 --> 00:56:14.070
(audience laughing)

00:56:14.070 --> 00:56:15.920
Good experience machines.
- Sure.

00:56:15.920 --> 00:56:17.220
Okay, so in a way,

00:56:17.220 --> 00:56:18.190
you're asking a somewhat
different question

00:56:18.190 --> 00:56:19.610
from the one I've addressed

00:56:19.610 --> 00:56:22.340
because you're asking
if this intrinsic value

00:56:22.340 --> 00:56:23.810
that I've talked about is such

00:56:23.810 --> 00:56:25.900
that the more of it, they're better,

00:56:25.900 --> 00:56:29.320
even if that means bringing
new beings into existence,

00:56:29.320 --> 00:56:32.430
rather than raising the intrinsic value

00:56:32.430 --> 00:56:34.243
of the lives of existing beings.

00:56:35.190 --> 00:56:36.630
My answer to that is yes.

00:56:36.630 --> 00:56:39.300
I would think, I do think it
would be a good thing to do.

00:56:39.300 --> 00:56:42.400
Of course, unfortunately in the
planet that we're living on,

00:56:42.400 --> 00:56:43.690
we have limited resources

00:56:43.690 --> 00:56:46.270
and there would be a
negative aspects of it there.

00:56:46.270 --> 00:56:48.430
But if we can imagine
these experience machines,

00:56:48.430 --> 00:56:50.700
we can surely also imagine a planet

00:56:50.700 --> 00:56:52.490
with limitless resources or the ability

00:56:52.490 --> 00:56:53.870
to colonize other planets.

00:56:53.870 --> 00:56:56.733
So then, yes, I do think that
would be a good thing to do.

00:57:00.050 --> 00:57:02.420
- [Audience Member] Hello,
I'm currently studying

00:57:02.420 --> 00:57:04.530
one of your books in one
of my philosophy classes,

00:57:04.530 --> 00:57:08.400
The Life You Can Save,
and I was wondering,

00:57:08.400 --> 00:57:09.950
when you think about happiness,

00:57:09.950 --> 00:57:12.610
do you think we have an
obligation as individuals

00:57:12.610 --> 00:57:17.520
to sacrifice our own
happiness, if it would increase

00:57:17.520 --> 00:57:19.490
more than that much happiness in others?

00:57:19.490 --> 00:57:21.140
If we could somehow measure that.

00:57:23.020 --> 00:57:28.020
- Okay, so my answer that is also yes,

00:57:28.230 --> 00:57:31.540
that is an obligation in the sense

00:57:31.540 --> 00:57:33.869
that it is the thing to do.

00:57:33.869 --> 00:57:36.990
Utilitarians typically don't draw

00:57:36.990 --> 00:57:39.010
much of a distinction
between what we ought to do,

00:57:39.010 --> 00:57:40.160
what's the right thing to do,

00:57:40.160 --> 00:57:42.750
what we have an obligation
to do, and some other ethics.

00:57:42.750 --> 00:57:45.253
These are different categories.

00:57:46.410 --> 00:57:50.050
And in The Life You Can
Save, as you might know,

00:57:50.050 --> 00:57:55.010
I do talk about how demanding
an ethic can reasonably be,

00:57:55.010 --> 00:57:58.850
and I consider essentially,
the question that you're asking

00:57:58.850 --> 00:58:01.890
about relieving suffering,
relieving extreme poverty,

00:58:01.890 --> 00:58:03.340
more than about promoting happiness

00:58:03.340 --> 00:58:06.190
but these are two sides of the same coin

00:58:06.190 --> 00:58:07.880
and very often, relieving suffering

00:58:07.880 --> 00:58:10.910
is the most effective way
we can promote happiness.

00:58:10.910 --> 00:58:12.840
And what I say there, just briefly,

00:58:12.840 --> 00:58:13.850
for those not familiar with it,

00:58:13.850 --> 00:58:17.990
is that at a theoretical level,

00:58:17.990 --> 00:58:20.060
the ethic that I'm
proposing is very demanding

00:58:20.060 --> 00:58:22.150
and has exactly the
implications that you'd make,

00:58:22.150 --> 00:58:25.040
that if we could reduce suffering

00:58:26.690 --> 00:58:29.010
by more than it would cost us,

00:58:29.010 --> 00:58:31.070
in terms of increasing our own suffering,

00:58:31.070 --> 00:58:32.800
we ought to do that.

00:58:32.800 --> 00:58:35.590
But I also think that in terms of an ethic

00:58:35.590 --> 00:58:38.550
that can be effective
in getting people to act

00:58:38.550 --> 00:58:41.050
and in encouraging people to act.

00:58:41.050 --> 00:58:43.500
In other words, an ethic
that we ought to advocate,

00:58:43.500 --> 00:58:46.440
not just as philosophers
but as campaigners

00:58:46.440 --> 00:58:50.310
for social change, that is too demanding.

00:58:50.310 --> 00:58:51.960
And it can be off-putting to people,

00:58:51.960 --> 00:58:53.800
to think that ethics is so demanding.

00:58:53.800 --> 00:58:55.950
So at the end of The Life You Can Save

00:58:55.950 --> 00:58:58.500
and also, for those who
don't want to buy the book,

00:58:59.470 --> 00:59:02.329
there's a website that
I've put up the same name,

00:59:02.329 --> 00:59:04.990
thelifeyoucansave.com,
where I've put this up.

00:59:04.990 --> 00:59:07.410
I've suggested a kind of graduated table

00:59:07.410 --> 00:59:09.950
of what people might consider giving,

00:59:09.950 --> 00:59:12.430
in proportion to their
income and suggested

00:59:12.430 --> 00:59:14.863
that if you do, if you meet that level,

00:59:15.930 --> 00:59:18.020
even though you could still give more

00:59:18.020 --> 00:59:21.050
and not be making a sacrifice as great

00:59:21.050 --> 00:59:24.230
as the gain that you would be achieving,

00:59:24.230 --> 00:59:26.500
you might still feel
that you've done enough

00:59:26.500 --> 00:59:29.633
to satisfy a kind of
decent ethical minimum.

00:59:30.470 --> 00:59:32.490
- [Audience Member] But is it
still doing something wrong

00:59:32.490 --> 00:59:35.783
if we continue to be happy
while others are suffering?

00:59:37.010 --> 00:59:40.630
- As I say, yes, I mean, if you ask me,

00:59:40.630 --> 00:59:43.270
que-philosopher, is that
still doing something wrong,

00:59:43.270 --> 00:59:44.750
I would have to say yes.

00:59:44.750 --> 00:59:46.410
If you ask me as campaigner,

00:59:46.410 --> 00:59:49.710
am I gonna go and tell
people who are a meeting

00:59:49.710 --> 00:59:52.160
or even exceeding the
standard that I put forward

00:59:53.130 --> 00:59:54.110
that they're doing something wrong

00:59:54.110 --> 00:59:55.930
because they could give still more?

00:59:55.930 --> 00:59:58.300
I'm not going to because that would not

00:59:58.300 --> 01:00:00.420
have the best consequences
and as a utilitarian,

01:00:00.420 --> 01:00:02.025
I'm concerned about having
the best consequences.

01:00:02.025 --> 01:00:06.819
(audience laughing)
- Thank you.

01:00:06.819 --> 01:00:08.300
- [Man] Hey, thanks for
coming out, Professor Singer,

01:00:08.300 --> 01:00:09.133
I really appreciate it.
- Thank you.

01:00:09.133 --> 01:00:11.480
- [Man] You know, you
spoke about the government

01:00:11.480 --> 01:00:15.930
promoting personal choices
to derive pleasure over pain.

01:00:15.930 --> 01:00:18.020
I guess my question was, what about,

01:00:18.020 --> 01:00:20.970
or what would you say
to somebody who implies

01:00:20.970 --> 01:00:23.960
that people derive a bit of pleasure

01:00:23.960 --> 01:00:26.730
or direct pleasure from
inflicting pain on others?

01:00:26.730 --> 01:00:29.109
Yeah, I'm not talking
about extreme psychosis,

01:00:29.109 --> 01:00:32.150
but I think to a certain extent,

01:00:32.150 --> 01:00:35.270
it seems like we do
derive a bit of pleasure

01:00:35.270 --> 01:00:36.579
from inflicting pain on others.

01:00:36.579 --> 01:00:38.870
- Are we talking about
consenting others, here?

01:00:38.870 --> 01:00:41.260
I mean, are we talking
about sexual relationships

01:00:41.260 --> 01:00:42.940
that are a little like this

01:00:42.940 --> 01:00:45.720
or are we just talking
about Schottenfreude

01:00:45.720 --> 01:00:47.660
or something like this?
- Sure, well, for instance,

01:00:47.660 --> 01:00:50.063
you know, economic exploitation, you know?

01:00:51.200 --> 01:00:53.280
- I don't see, you see, I don't see.

01:00:53.280 --> 01:00:56.130
I mean, it depends what
you mean by derive pleasure

01:00:56.130 --> 01:00:57.880
from inflicting pain on others.

01:00:57.880 --> 01:01:00.820
I mean, you can think
of the most rapacious,

01:01:00.820 --> 01:01:04.130
exploitative capitalist you like,

01:01:04.130 --> 01:01:06.750
but typically, I think that
what they're trying to do

01:01:06.750 --> 01:01:09.130
is to accumulate as much wealth

01:01:09.130 --> 01:01:11.870
or resources for themselves
and they just don't care

01:01:11.870 --> 01:01:13.850
about the impact that it has on others

01:01:13.850 --> 01:01:16.180
and I think if you said to them, look,

01:01:16.180 --> 01:01:17.160
by snapping your fingers,

01:01:17.160 --> 01:01:19.670
you could make your workers happier,

01:01:19.670 --> 01:01:22.943
it would not cost you anything at all,

01:01:23.830 --> 01:01:25.810
I think most of them would say
fine, I'll snap my fingers.

01:01:25.810 --> 01:01:28.530
You know, it's not that they're sadists.

01:01:28.530 --> 01:01:30.180
It's not that they enjoy the fact

01:01:30.180 --> 01:01:31.580
that they're screwing the workers.

01:01:31.580 --> 01:01:33.800
It's just that they, without
screwing the workers,

01:01:33.800 --> 01:01:35.620
in the real world, they wouldn't get quite

01:01:35.620 --> 01:01:37.610
as much for themselves, we assume.

01:01:37.610 --> 01:01:40.010
I mean, this may or may
not be good economics

01:01:40.010 --> 01:01:42.830
but I assume or they assume.

01:01:42.830 --> 01:01:46.260
So, in that sense,

01:01:46.260 --> 01:01:50.704
I think that then, the suffering of others

01:01:50.704 --> 01:01:53.450
is a byproduct, it's not something

01:01:53.450 --> 01:01:54.660
that they're really aiming at.

01:01:54.660 --> 01:01:57.590
If they were aiming at it, then again,

01:01:57.590 --> 01:01:59.420
sort of following up
from the last question,

01:01:59.420 --> 01:02:01.300
if they're inflicting
more suffering on others

01:02:01.300 --> 01:02:02.280
than they're getting out of it,

01:02:02.280 --> 01:02:05.210
clearly that's gonna be
wrong by any standards.

01:02:05.210 --> 01:02:06.773
- Thank you.
- Thank you.

01:02:08.540 --> 01:02:11.690
- [Man] Hi, given that people watch movies

01:02:11.690 --> 01:02:14.430
and listen to recorded music,

01:02:14.430 --> 01:02:17.450
why is it that only 50% of the people

01:02:17.450 --> 01:02:18.810
would plug into, know this,

01:02:18.810 --> 01:02:20.610
much more exciting pleasure machine?

01:02:22.250 --> 01:02:25.720
- Well, they don't watch movies

01:02:25.720 --> 01:02:29.390
or listen to music, I guess, all the time.

01:02:29.390 --> 01:02:31.040
Certainly they don't, the movie

01:02:31.040 --> 01:02:33.390
is the more total immersion
sort of experience.

01:02:35.230 --> 01:02:37.930
Most people only go to one movie

01:02:37.930 --> 01:02:39.490
or maybe two movies at the most,

01:02:39.490 --> 01:02:41.870
then they get out in the real world.

01:02:41.870 --> 01:02:44.120
So I suppose that's
part of the difference.

01:02:44.120 --> 01:02:47.900
Also though, they know
when they're in the movie,

01:02:47.900 --> 01:02:49.370
that this is an illusion

01:02:50.950 --> 01:02:53.840
and that they can leave it at any time.

01:02:53.840 --> 01:02:57.440
So perhaps that's one
difference between the choices.

01:02:57.440 --> 01:02:58.530
- Thanks.
- Thanks.

01:03:02.060 --> 01:03:03.490
- [Man] Oh, hi, Mr. Singer.

01:03:03.490 --> 01:03:05.510
Currently in my philosophy class,

01:03:05.510 --> 01:03:07.310
we were going over bestiality,

01:03:07.310 --> 01:03:09.220
whether it was morally acceptable or not.

01:03:09.220 --> 01:03:11.690
I was just wondering, yeah,
what were your views on that?

01:03:11.690 --> 01:03:12.760
I know it's a little different

01:03:12.760 --> 01:03:13.994
from everybody else's question.

01:03:13.994 --> 01:03:15.000
(audience laughing)

01:03:15.000 --> 01:03:17.194
- Right, this topic keeps coming up.

01:03:17.194 --> 01:03:18.930
(audience laughing)

01:03:18.930 --> 01:03:21.510
I guess I can't deny that it is relevant

01:03:21.510 --> 01:03:23.653
to discussions of pleasure and pain.

01:03:24.790 --> 01:03:26.020
All I ever wrote on this one,

01:03:26.020 --> 01:03:27.880
I once reviewed a book about bestiality

01:03:27.880 --> 01:03:30.290
but it does keep coming back.

01:03:30.290 --> 01:03:33.120
So I'll give you my view, anyway.

01:03:33.120 --> 01:03:34.883
I'm not troubled by it.

01:03:35.860 --> 01:03:38.940
I think in general,

01:03:38.940 --> 01:03:41.090
humans having sex with animals is wrong

01:03:41.090 --> 01:03:43.790
because in general, it inflicts pain

01:03:43.790 --> 01:03:45.813
and distress on the animals.

01:03:47.480 --> 01:03:50.060
And so it should be prosecuted
under under cruelty laws,

01:03:50.060 --> 01:03:51.830
which obviously, I strongly support

01:03:51.830 --> 01:03:54.230
and in fact, I think
should be made more severe.

01:03:55.440 --> 01:03:59.100
But there are cases of people
having sex with animals

01:03:59.100 --> 01:04:02.640
which do not involve
suffering by the animals.

01:04:02.640 --> 01:04:05.960
There are some cases in
which you could even say

01:04:05.960 --> 01:04:08.900
the animal may consent to the act,

01:04:08.900 --> 01:04:11.350
the animal has every
opportunity to walk away

01:04:11.350 --> 01:04:15.290
or not be the human who's
engaging in this practice

01:04:15.290 --> 01:04:17.893
but does not do so.

01:04:18.960 --> 01:04:22.830
So interesting question is
why do we still have a taboo

01:04:22.830 --> 01:04:25.930
about those sexual relations,

01:04:25.930 --> 01:04:28.610
which sometimes occur
from people who actually

01:04:28.610 --> 01:04:31.840
have very strong positive
attitudes towards animals?

01:04:31.840 --> 01:04:34.060
In fact, I know one of
them who said to me,

01:04:34.060 --> 01:04:36.880
how is it that people think
it's okay to eat animals

01:04:36.880 --> 01:04:39.030
but don't think it's okay
to have sex with them,

01:04:39.030 --> 01:04:43.040
even when they're able to stop

01:04:43.040 --> 01:04:45.020
having the sex if they want to?

01:04:45.020 --> 01:04:46.680
So there is that kind of attitude

01:04:48.010 --> 01:04:50.470
and it is interesting that we've had lots

01:04:50.470 --> 01:04:54.410
of taboos against basically
non-reproductive sex, right?

01:04:54.410 --> 01:04:56.640
We've had taboos, most obviously

01:04:56.640 --> 01:04:58.430
against homosexual relations,

01:04:58.430 --> 01:05:02.450
which fortunately have now broken down.

01:05:02.450 --> 01:05:04.480
We've had taboos against oral sex,

01:05:04.480 --> 01:05:07.200
which have also now broken down.

01:05:07.200 --> 01:05:11.830
But the taboo against sex with animals,

01:05:11.830 --> 01:05:15.403
even in the circumstances
that I described, has not.

01:05:16.250 --> 01:05:17.690
So I'm not saying that in any way,

01:05:17.690 --> 01:05:21.120
it's normal or natural or I'm not saying

01:05:21.120 --> 01:05:26.090
that I, in that sense, am
positively approving this

01:05:26.090 --> 01:05:27.520
or as some people have suggested

01:05:27.520 --> 01:05:29.400
in things they've written about my views.

01:05:29.400 --> 01:05:31.920
But I honestly don't see why

01:05:31.920 --> 01:05:34.760
there should be criminal sanctions

01:05:34.760 --> 01:05:38.910
against it in the specific
group of cases that I mentioned.

01:05:38.910 --> 01:05:39.810
- [Man] Thank you.

01:05:44.090 --> 01:05:46.140
- [Woman] So, some people have mentioned

01:05:46.140 --> 01:05:48.480
an objection to the,
well, not an objection,

01:05:48.480 --> 01:05:50.890
a modification to the experience machine

01:05:50.890 --> 01:05:53.260
where we experience a little bit of pain

01:05:53.260 --> 01:05:55.310
to make the experience more realistic.

01:05:55.310 --> 01:05:57.460
Do you think it's intrinsic in humans

01:05:57.460 --> 01:06:00.243
to want to desire some level of pain?

01:06:02.350 --> 01:06:04.050
- No, I don't think
it's intrinsic in humans

01:06:04.050 --> 01:06:06.750
to want to desire some level of pain

01:06:06.750 --> 01:06:09.300
but it may be that some pleasures

01:06:09.300 --> 01:06:12.410
can only be achieved
with some level of pain.

01:06:12.410 --> 01:06:14.280
That if, for example,

01:06:14.280 --> 01:06:17.130
the pleasures of overcoming a challenge.

01:06:17.130 --> 01:06:19.400
As I said, Sedgwick already mentions

01:06:19.400 --> 01:06:21.310
that triumphant overcoming of obstacles

01:06:21.310 --> 01:06:22.830
in a way that involves pain.

01:06:22.830 --> 01:06:25.100
So that could be the
climbing Everest case.

01:06:25.100 --> 01:06:29.030
So it could be the running
a marathon sort of case.

01:06:29.030 --> 01:06:31.500
And some people, I think, do feel

01:06:31.500 --> 01:06:34.470
that these pleasures are somehow worth it

01:06:34.470 --> 01:06:39.470
and better pleasures
than the other pleasures

01:06:39.500 --> 01:06:41.100
that you get not in that way.

01:06:41.100 --> 01:06:43.020
So I think that's why

01:06:43.020 --> 01:06:45.560
there was this suggested
modification, as you say,

01:06:45.560 --> 01:06:48.660
that it introduces this element

01:06:48.660 --> 01:06:52.080
that other people think
that you need the contrast,

01:06:52.080 --> 01:06:54.150
that without some elements of pain,

01:06:54.150 --> 01:06:57.300
you wouldn't have the
ability to experience

01:06:57.300 --> 01:06:59.320
and really appreciate the pleasures.

01:06:59.320 --> 01:07:01.400
- Thank you.
- Thank you.

01:07:03.150 --> 01:07:05.460
- [Man] Yeah, I guess
one of the consequences

01:07:05.460 --> 01:07:08.200
of your work in animal rights,

01:07:08.200 --> 01:07:09.290
in addition to vegetarianism

01:07:09.290 --> 01:07:11.290
has been sort of this ethical meat

01:07:11.290 --> 01:07:15.360
and more humanely produced
animals that stop the killing.

01:07:15.360 --> 01:07:16.193
And so I guess I'm wondering,

01:07:16.193 --> 01:07:19.150
assuming that that can be assumed

01:07:19.150 --> 01:07:22.960
to be accurate description
of how the animal's treated

01:07:22.960 --> 01:07:26.250
during its life and the
suffering is not there.

01:07:26.250 --> 01:07:28.780
I'm wondering, the actual act of killing,

01:07:28.780 --> 01:07:32.170
can you justify or
justify opposition to it

01:07:32.170 --> 01:07:34.170
from a preference utilitarian standpoint?

01:07:34.170 --> 01:07:37.470
Or do you not or you know,
in the philosopher's hat,

01:07:37.470 --> 01:07:38.340
what would you say and I guess,

01:07:38.340 --> 01:07:41.300
maybe a campaigners, I guess, hat as well,

01:07:41.300 --> 01:07:43.290
as sort of how you would treat the actual,

01:07:43.290 --> 01:07:45.500
the act of the killing, setting aside

01:07:45.500 --> 01:07:47.280
the treatment and the suffering

01:07:47.280 --> 01:07:48.693
of animal during its life?

01:07:50.160 --> 01:07:51.595
- Yeah, well this is
another interesting question

01:07:51.595 --> 01:07:54.110
that does raise some of the differences

01:07:54.110 --> 01:07:57.873
between the preference view
and the hedonistic view.

01:07:58.830 --> 01:08:02.980
So what I've argued in practical ethics

01:08:02.980 --> 01:08:04.850
and and other works written

01:08:04.850 --> 01:08:07.550
from a preference utilitarian standpoint,

01:08:07.550 --> 01:08:11.040
is that the extent to
which killing is wrong

01:08:11.040 --> 01:08:14.290
depends at least partly on the capacity

01:08:14.290 --> 01:08:17.300
of the being killed to have
desires about the future.

01:08:17.300 --> 01:08:21.050
So I've argued that beings

01:08:21.050 --> 01:08:22.800
that are self-aware,

01:08:22.800 --> 01:08:25.323
that see themselves as existing over time,

01:08:27.160 --> 01:08:28.830
can have desires for the future,

01:08:28.830 --> 01:08:31.400
can want to go on living in the future

01:08:31.400 --> 01:08:34.150
and that that makes killing
them more seriously wrong

01:08:34.150 --> 01:08:36.600
than it makes killing beings that lack

01:08:36.600 --> 01:08:39.320
that kind of capacity desires.

01:08:39.320 --> 01:08:42.750
So on this view, killing
some species of animals

01:08:42.750 --> 01:08:44.170
might be more serious than others.

01:08:44.170 --> 01:08:47.250
Chimpanzees, for example,
it seems do have some sense

01:08:47.250 --> 01:08:49.590
of self that enables them to project

01:08:49.590 --> 01:08:51.590
themselves into the future in some ways.

01:08:52.430 --> 01:08:55.229
But perhaps fish don't.

01:08:55.229 --> 01:08:58.540
It's hard to know exactly
where you would draw that line.

01:08:58.540 --> 01:09:01.410
And of course, the line
also applies with humans.

01:09:01.410 --> 01:09:04.210
Both in terms of comparing newborn infants

01:09:04.210 --> 01:09:08.120
with older children and comparing humans

01:09:08.120 --> 01:09:10.700
with some profound
intellectual disabilities

01:09:10.700 --> 01:09:14.350
with others without such profound
intellectual disabilities.

01:09:14.350 --> 01:09:17.930
So, that's led me to views

01:09:17.930 --> 01:09:20.960
about killing both for
animals and for humans

01:09:20.960 --> 01:09:23.173
that have also been controversial.

01:09:24.429 --> 01:09:26.190
And I suppose my answer to your question

01:09:26.190 --> 01:09:28.140
on the preference utilitarian view,

01:09:28.140 --> 01:09:32.160
would be if the animal does
not have self-awareness,

01:09:32.160 --> 01:09:36.653
then the killing in itself
is not intrinsically wrong.

01:09:38.500 --> 01:09:41.490
Although there is a lot more to be said,

01:09:41.490 --> 01:09:43.310
including from a practical point of view,

01:09:43.310 --> 01:09:47.280
about what raising of
animals commercially,

01:09:47.280 --> 01:09:50.900
even with reasonably good
animal welfare standards,

01:09:50.900 --> 01:09:52.900
does to our attitudes to animals

01:09:52.900 --> 01:09:55.770
and to the likelihood that
they will be well looked after.

01:09:55.770 --> 01:09:57.020
One of the interesting differences

01:09:57.020 --> 01:09:59.730
with moving towards the
kind of hedonistic view

01:09:59.730 --> 01:10:03.400
that I'm exploring in
this talk and in this work

01:10:04.570 --> 01:10:07.620
is that it actually gives you only

01:10:07.620 --> 01:10:10.220
an indirect justification for drawing

01:10:10.220 --> 01:10:13.240
this distinction between
beings that are more self-aware

01:10:13.240 --> 01:10:14.880
and those that are not self-aware

01:10:14.880 --> 01:10:17.270
because it doesn't make any difference

01:10:17.270 --> 01:10:19.110
if the animal is killed instantly

01:10:19.110 --> 01:10:21.690
to the actual amount of pleasure or pain

01:10:21.690 --> 01:10:23.140
that it experiences.

01:10:23.140 --> 01:10:24.310
The only difference that it makes

01:10:24.310 --> 01:10:26.410
is that you could say and in fact,

01:10:26.410 --> 01:10:27.823
Bentham says this somewhere,

01:10:28.670 --> 01:10:32.550
that when you have beings

01:10:32.550 --> 01:10:36.400
with the ability to understand
that they have a future

01:10:36.400 --> 01:10:38.640
and to know things
about their environment,

01:10:38.640 --> 01:10:41.850
killing one of them is
likely to cause fear

01:10:41.850 --> 01:10:44.810
and apprehension in others who know

01:10:44.810 --> 01:10:47.270
that therefore, they
could be being killed,

01:10:47.270 --> 01:10:49.130
that that killing is
something that happens

01:10:49.130 --> 01:10:51.840
and therefore, in fear of
being killed themselves.

01:10:51.840 --> 01:10:53.850
Whereas again, if you talk about beings

01:10:53.850 --> 01:10:58.090
with no self-awareness, they
can't have that apprehension

01:10:58.090 --> 01:11:01.070
and so that draws a somewhat similar line

01:11:01.070 --> 01:11:02.660
but for different reasons.

01:11:02.660 --> 01:11:05.180
Again, between different
categories of human beings

01:11:05.180 --> 01:11:07.973
and between humans and at
least some non-human animals.

01:11:11.180 --> 01:11:12.990
- [Man] First of all, I wanted
to thank you for coming out.

01:11:12.990 --> 01:11:14.250
You've actually inspired a paper

01:11:14.250 --> 01:11:16.300
than I'm writing this semester.

01:11:16.300 --> 01:11:17.650
- Thank you.
- My question is,

01:11:17.650 --> 01:11:19.850
if you could reach worldwide fairness,

01:11:19.850 --> 01:11:22.700
your subjective view of it,
for all sentient beings,

01:11:22.700 --> 01:11:24.680
but that would be
contingent on the ceasing

01:11:24.680 --> 01:11:27.150
of your existence, would you take that

01:11:27.150 --> 01:11:30.410
and moreover, is that because reaching

01:11:30.410 --> 01:11:33.010
fairness makes you happy or is happiness

01:11:33.010 --> 01:11:34.660
and fairness completely independent?

01:11:34.660 --> 01:11:37.350
And lastly, what is the limit on the size

01:11:37.350 --> 01:11:40.860
of a system's population of fairness

01:11:40.860 --> 01:11:42.823
where you would no longer consent?

01:11:44.170 --> 01:11:45.520
- So if I understand your question,

01:11:45.520 --> 01:11:46.770
it's a kind of a bit like the one

01:11:46.770 --> 01:11:50.300
that Dostoyevsky asks in
The Brothers Karamazov,

01:11:50.300 --> 01:11:52.200
except that instead of sacrificing

01:11:52.200 --> 01:11:56.730
the little child in order
to produce heaven on earth

01:11:56.730 --> 01:12:00.640
or utopia for forever after,
you have to sacrifice yourself.

01:12:00.640 --> 01:12:01.750
Is that roughly right?

01:12:01.750 --> 01:12:02.660
- Yeah.
- Yeah.

01:12:02.660 --> 01:12:05.640
Okay, so my answer that is yes,

01:12:05.640 --> 01:12:09.870
I definitely ought to sacrifice
myself for that purpose.

01:12:09.870 --> 01:12:12.340
That's not a prediction as to
whether I would or would not.

01:12:12.340 --> 01:12:14.500
I guess I hoped that I would do so.

01:12:14.500 --> 01:12:16.830
It would certainly not
be for my own happiness,

01:12:16.830 --> 01:12:18.350
because after I sacrificed myself,

01:12:18.350 --> 01:12:20.179
I have no further happiness

01:12:20.179 --> 01:12:24.383
and presumably, my
happiness would be brief.

01:12:25.620 --> 01:12:26.950
Now, you could perhaps say, well,

01:12:26.950 --> 01:12:28.800
but if you didn't do
it you would be unhappy

01:12:28.800 --> 01:12:29.633
for the rest of your life

01:12:29.633 --> 01:12:31.450
because you would have
this on your conscience,

01:12:31.450 --> 01:12:33.120
that there was all this suffering going on

01:12:33.120 --> 01:12:36.020
and you could have
stopped it but you didn't.

01:12:36.020 --> 01:12:37.470
So I guess you could argue that.

01:12:37.470 --> 01:12:40.140
But for me, really, the relevant thing

01:12:40.140 --> 01:12:42.010
is that it's clearly what you ought to do.

01:12:42.010 --> 01:12:45.320
If you don't do it then
you're being extremely selfish

01:12:46.270 --> 01:12:48.380
but I certainly don't claim to be a saint

01:12:48.380 --> 01:12:50.070
and that's why I'm not
making any prediction.

01:12:50.070 --> 01:12:53.120
I hope that I would be able to do it.

01:12:53.120 --> 01:12:55.070
Now, your question there, had
a little sting in your tail,

01:12:55.070 --> 01:12:57.750
which I think was how large
does the population have to be?

01:12:57.750 --> 01:12:58.583
So, at the moment,

01:12:58.583 --> 01:12:59.416
is that right?
- There was a intermediate

01:12:59.416 --> 01:13:01.790
part of does that mean that fairness

01:13:01.790 --> 01:13:03.140
and happiness are independent

01:13:03.140 --> 01:13:05.900
or is your fairness
dependent on happiness?

01:13:05.900 --> 01:13:07.660
You kind of touched on it but--

01:13:07.660 --> 01:13:08.493
- Yeah.
- Might be

01:13:08.493 --> 01:13:09.326
completely different.

01:13:09.326 --> 01:13:10.520
- I was taking, well, yeah okay.

01:13:10.520 --> 01:13:11.800
So again, for me,

01:13:11.800 --> 01:13:13.890
fairness is not really
an independent value.

01:13:13.890 --> 01:13:18.260
So I was taking it as the
best possible distribution

01:13:18.260 --> 01:13:20.823
of happiness throughout the population.

01:13:22.900 --> 01:13:26.480
Treating fair as as meaning
the one that maximizes

01:13:26.480 --> 01:13:28.900
the distribution of happiness
throughout the population,

01:13:28.900 --> 01:13:30.850
which is certainly not what everybody

01:13:30.850 --> 01:13:32.273
means by fair, I must admit.

01:13:36.099 --> 01:13:37.340
So now, I guess you have the idea,

01:13:37.340 --> 01:13:39.829
okay, so you're prepared
to do it for seven billion.

01:13:39.829 --> 01:13:42.240
Are you prepared to do
it for seven million?

01:13:42.240 --> 01:13:44.650
Are you prepared to do it for 7000?

01:13:44.650 --> 01:13:46.410
Are you prepared to do it for seven?

01:13:46.410 --> 01:13:49.450
And I suppose, and you know, now,

01:13:49.450 --> 01:13:51.869
I will still give the same answer, right?

01:13:51.869 --> 01:13:55.583
I would think I ought to do
it, even if it's only for two.

01:13:56.890 --> 01:14:01.220
But the likelihood that I will do it

01:14:01.220 --> 01:14:02.840
probably does diminish, you know?

01:14:02.840 --> 01:14:05.540
Because I would think it would be so awful

01:14:05.540 --> 01:14:07.417
not to do it for seven billion,

01:14:07.417 --> 01:14:09.830
for the amount of suffering
that goes on in the world.

01:14:09.830 --> 01:14:11.410
Whereas if it's only two, well,

01:14:11.410 --> 01:14:13.450
their suffering maybe is, you know,

01:14:13.450 --> 01:14:15.670
I could enjoy my life and
that wouldn't be as great

01:14:15.670 --> 01:14:18.290
as how they could enjoy it if I did this

01:14:18.290 --> 01:14:20.990
but the discrepancy is no longer so great,

01:14:20.990 --> 01:14:23.790
so I wouldn't have to
be as horribly selfish

01:14:23.790 --> 01:14:25.750
to decline to do it for two others

01:14:25.750 --> 01:14:28.370
as I would to decline to do
it for seven billion others.

01:14:28.370 --> 01:14:30.120
- Alright, thank you.
- Thank you.

01:14:33.120 --> 01:14:35.650
- [Man] Yes, Professor Singer,

01:14:35.650 --> 01:14:38.833
when you were mentioning
the paradox of hedonism,

01:14:39.800 --> 01:14:43.620
it came to my mind about Dr. Viktor Frankl

01:14:43.620 --> 01:14:47.400
who suggests that by searching

01:14:47.400 --> 01:14:52.400
for consciousness or experience,

01:14:52.460 --> 01:14:56.210
meaning, by going toward meaning,

01:14:56.210 --> 01:14:59.160
that happiness could come as a side-effect

01:14:59.160 --> 01:15:01.520
but to go for happiness as a goal,

01:15:01.520 --> 01:15:04.610
it is likely that you might not reach it.

01:15:04.610 --> 01:15:09.405
So how would you relate
this to this premise?

01:15:09.405 --> 01:15:10.640
It's like consciousness,

01:15:10.640 --> 01:15:11.473
I assume--
- Yes.

01:15:11.473 --> 01:15:14.120
- like meaning is, in consciousness,
is similar in this way.

01:15:14.120 --> 01:15:17.000
- Yes, I think you're right.

01:15:17.000 --> 01:15:20.640
I think that Viktor Frankl's

01:15:20.640 --> 01:15:23.510
psychology or view of life

01:15:23.510 --> 01:15:27.220
is in accordance with
the paradox of hedonism.

01:15:27.220 --> 01:15:29.610
I have a book I wrote a few years ago

01:15:29.610 --> 01:15:30.960
called How Are We To Live?

01:15:30.960 --> 01:15:33.700
Which discusses questions about meaning

01:15:33.700 --> 01:15:37.330
and how they relate to personal happiness

01:15:37.330 --> 01:15:39.530
and therefore to reasons
for acting ethically

01:15:39.530 --> 01:15:44.110
and I refer to Frankl briefly in that.

01:15:44.110 --> 01:15:46.840
So I do think that very often,

01:15:46.840 --> 01:15:51.110
we find happiness and
certainly satisfaction

01:15:51.110 --> 01:15:53.420
but also somebody right at the beginning

01:15:53.420 --> 01:15:56.710
talked about inner joy, also
those kinds of experiences,

01:15:56.710 --> 01:15:59.650
from doing things that we find meaningful.

01:15:59.650 --> 01:16:02.210
That may be, as I say,
related to the kind of beings

01:16:02.210 --> 01:16:04.340
that we are but that
is part of our nature.

01:16:04.340 --> 01:16:05.640
- Like a little more depth,

01:16:05.640 --> 01:16:08.580
rather than just being a
superficial gratification.

01:16:08.580 --> 01:16:09.790
- Yes, rather than just lying on the beach

01:16:09.790 --> 01:16:11.530
and enjoying the sun on
your back, that's right,

01:16:11.530 --> 01:16:13.580
which pulls after a while, I think.

01:16:13.580 --> 01:16:14.413
- [Man] Thank you.

01:16:14.413 --> 01:16:15.246
- Okay.

01:16:18.930 --> 01:16:19.946
- [Audience Member] Hello, how you doing?

01:16:19.946 --> 01:16:20.779
- Good.

01:16:20.779 --> 01:16:22.573
- [Audience Member] Thank
you for coming here today.

01:16:24.120 --> 01:16:25.820
Yeah, I just want, my question is,

01:16:26.940 --> 01:16:28.040
what if we can make the argument

01:16:28.040 --> 01:16:30.110
that certain attitudes or
states of consciousness

01:16:30.110 --> 01:16:33.100
or lenses consistently create

01:16:33.100 --> 01:16:34.990
or petuate or expand happiness.

01:16:34.990 --> 01:16:37.053
For example, love or compassion.

01:16:38.140 --> 01:16:40.080
So shouldn't our focus,
if you are ultimately

01:16:40.080 --> 01:16:42.230
trying to create happiness beyond creating

01:16:42.230 --> 01:16:43.489
those things that create happiness,

01:16:43.489 --> 01:16:46.140
love and compassion and
I find it interesting

01:16:46.140 --> 01:16:48.340
that love hasn't really
been mentioned much,

01:16:49.459 --> 01:16:52.170
in terms of happiness, so what
are your thoughts on that?

01:16:52.170 --> 01:16:54.030
- Sure, because I haven't been trying

01:16:54.030 --> 01:16:57.040
to give an account of what
things lead to happiness.

01:16:57.040 --> 01:17:01.580
I'm not doing what's nowadays
called positive psychology

01:17:02.520 --> 01:17:04.690
of trying to chart out the things

01:17:04.690 --> 01:17:06.797
that, you know, yes, you too can be happy

01:17:06.797 --> 01:17:08.210
and here are the seven steps

01:17:08.210 --> 01:17:10.000
that will lead you to a happy life.

01:17:10.000 --> 01:17:12.240
I'm not saying that isn't
a valuable thing to do,

01:17:12.240 --> 01:17:14.950
insofar as the psychologists are right

01:17:14.950 --> 01:17:17.500
about the seven steps that
will lead you to a happy life.

01:17:17.500 --> 01:17:19.360
I think it's good that people

01:17:19.360 --> 01:17:21.280
are doing that and studying that.

01:17:21.280 --> 01:17:24.400
And I'm quite sure that love is one

01:17:24.400 --> 01:17:28.770
of those important parts
of it, finding love,

01:17:28.770 --> 01:17:31.370
finding close personal relationships,

01:17:31.370 --> 01:17:32.380
anyway, put it that way.

01:17:32.380 --> 01:17:34.030
Not everybody can be fortunate

01:17:34.030 --> 01:17:37.030
enough to find love,
perhaps, for long periods.

01:17:37.030 --> 01:17:38.930
But I do think that
that's a very important

01:17:38.930 --> 01:17:41.120
part of human happiness

01:17:41.120 --> 01:17:44.480
and you also mentioned compassion.

01:17:44.480 --> 01:17:46.330
Compassion, I think is somewhat more mixed

01:17:46.330 --> 01:17:50.220
because while I think
compassion does lead us

01:17:50.220 --> 01:17:53.440
to relate to others, it can also lead us

01:17:53.440 --> 01:17:56.450
to feel more pain when
others are suffering.

01:17:56.450 --> 01:17:59.550
So I think compassion is very important

01:17:59.550 --> 01:18:01.920
in reducing the amount
of suffering in the world

01:18:01.920 --> 01:18:06.760
and therefore is a good
in terms of maximizing

01:18:06.760 --> 01:18:09.480
happiness or pleasure generally,

01:18:09.480 --> 01:18:13.670
but it's not necessarily
for your personal happiness,

01:18:13.670 --> 01:18:16.200
in the same way as I think being able

01:18:16.200 --> 01:18:18.820
to love others and being loved by others

01:18:18.820 --> 01:18:22.493
is very important for
people's personal happiness.

01:18:23.978 --> 01:18:26.783
- Thank you.
- Thank you.

01:18:26.783 --> 01:18:29.040
- [Man] Thank you,
Professor, for being here.

01:18:29.040 --> 01:18:32.990
I have a question about the
ethics of assisted suicide,

01:18:32.990 --> 01:18:35.870
like is there an ethical
framework for assisted suicide

01:18:35.870 --> 01:18:39.860
or to really, like, if
consent is involved,

01:18:39.860 --> 01:18:44.500
can like suicide shops open
up all over the country,

01:18:44.500 --> 01:18:46.590
if there's, like, what's
the ethical framework

01:18:46.590 --> 01:18:48.030
of assisted suicide or?

01:18:48.030 --> 01:18:49.930
- Right, okay, well that, yeah, certainly.

01:18:49.930 --> 01:18:52.020
I mean, that's a relevant issue

01:18:52.020 --> 01:18:54.390
in terms of how to minimize suffering

01:18:54.390 --> 01:18:57.310
because the suffering
that people experience

01:18:57.310 --> 01:19:00.850
in the last months of
their lives is certainly,

01:19:00.850 --> 01:19:04.047
I think, something that is a very

01:19:04.047 --> 01:19:07.143
negative aspect of strong dis-value.

01:19:08.340 --> 01:19:09.470
But you're asking the question

01:19:09.470 --> 01:19:12.020
as if we don't have already
have experience of this.

01:19:12.020 --> 01:19:14.090
But of course, we do.

01:19:14.090 --> 01:19:16.810
Physician assisted suicide
or physician assisted dying,

01:19:16.810 --> 01:19:19.420
if you prefer that
term, has been legalized

01:19:19.420 --> 01:19:23.410
by voter initiatives in
Oregon and Washington,

01:19:23.410 --> 01:19:26.730
has been legalized by a
court decision in Montana

01:19:26.730 --> 01:19:29.980
and along with voluntary euthanasia,

01:19:29.980 --> 01:19:31.700
that is where the doctor
actually administers

01:19:31.700 --> 01:19:33.790
the lethal injection, has been legal

01:19:33.790 --> 01:19:35.630
for many years in the Netherlands

01:19:35.630 --> 01:19:39.210
and more recently in
Belgium and Luxembourg.

01:19:39.210 --> 01:19:41.200
So we know how this works.

01:19:41.200 --> 01:19:43.100
Basically, it works well.

01:19:43.100 --> 01:19:45.520
None of these countries
have wanted to rescind

01:19:45.520 --> 01:19:47.620
their legislation and none of these states

01:19:48.580 --> 01:19:53.480
in the United States,
despite changes of government

01:19:53.480 --> 01:19:58.143
in, for example, in the
Netherlands and in Belgium.

01:19:59.780 --> 01:20:02.770
And it doesn't mean that
there are suicide shops.

01:20:02.770 --> 01:20:06.430
It means that there are
doctors who you can consult

01:20:06.430 --> 01:20:08.993
and request assistance in dying.

01:20:11.215 --> 01:20:14.170
And there's various different
kinds of legislation

01:20:14.170 --> 01:20:17.850
which have periods that the request

01:20:17.850 --> 01:20:20.010
has to lie on the table, in a sense,

01:20:20.010 --> 01:20:22.630
that you you can't say,
I want your assistance

01:20:22.630 --> 01:20:25.260
in dying right now for the first time.

01:20:25.260 --> 01:20:28.240
Perhaps the second opinion
has to be called on.

01:20:28.240 --> 01:20:31.463
But generally, this seems to work well.

01:20:33.034 --> 01:20:35.700
There have been allegations
that it's been abused

01:20:35.700 --> 01:20:37.240
in the Netherlands but those allegations

01:20:37.240 --> 01:20:39.170
don't actually stand up when you look

01:20:39.170 --> 01:20:41.500
at the comparative figures
with other countries

01:20:41.500 --> 01:20:45.460
that have not legalized
voluntary euthanasia.

01:20:45.460 --> 01:20:47.760
And I do think it's a very simple reform

01:20:47.760 --> 01:20:51.120
that reduces unnecessary suffering

01:20:51.120 --> 01:20:53.300
and also gives people what they want.

01:20:53.300 --> 01:20:55.470
So whether you take a desire-based theory,

01:20:55.470 --> 01:20:58.350
a preference-theory or
a hedonistic theory,

01:20:58.350 --> 01:20:59.760
I think both of them point towards

01:20:59.760 --> 01:21:03.070
the legalization of voluntary euthanasia

01:21:03.070 --> 01:21:04.439
and physician assisted suicide.

01:21:04.439 --> 01:21:05.753
- Thank you.
- Thank you.

01:21:07.900 --> 01:21:08.733
- [Man] Hi, Professor Singer.

01:21:08.733 --> 01:21:09.820
I wanted to thank you for being here

01:21:09.820 --> 01:21:11.140
and for much of your work.

01:21:11.140 --> 01:21:13.040
I actually went from a
vegetarian to a vegan

01:21:13.040 --> 01:21:15.760
18 years ago after
reading Animal Liberation.

01:21:15.760 --> 01:21:18.560
And in that book, you
made what's been called

01:21:18.560 --> 01:21:20.270
the argument from marginal cases.

01:21:20.270 --> 01:21:23.300
And I wanted to back up and look at one

01:21:23.300 --> 01:21:25.100
of your answers regarding the wrongness

01:21:25.100 --> 01:21:26.930
of, for instance, killing a cow,

01:21:26.930 --> 01:21:30.083
being in frustrating future preferences.

01:21:31.140 --> 01:21:32.980
On that reasoning, that
would be the wrongness

01:21:32.980 --> 01:21:36.890
of killing a perfectly
healthy infant as well.

01:21:36.890 --> 01:21:39.660
My perspective would be that
whether the infant knows it

01:21:39.660 --> 01:21:41.750
or the cow knows it or
not, they are conscious,

01:21:41.750 --> 01:21:44.370
that consciousness belongs to them

01:21:44.370 --> 01:21:46.390
and you're taking away their future

01:21:46.390 --> 01:21:49.160
stream of consciousness
when you kill them.

01:21:49.160 --> 01:21:51.330
But my understanding is
that that isn't your view,

01:21:51.330 --> 01:21:53.610
that isn't other utilitarians' view,

01:21:53.610 --> 01:21:55.449
like Lori Gruen, at least in the past,

01:21:55.449 --> 01:21:57.030
she's been a utilitarian.

01:21:57.030 --> 01:21:59.329
So I believe you said, maybe,

01:21:59.329 --> 01:22:02.010
that it wasn't inherently
wrong to painlessly

01:22:02.010 --> 01:22:04.260
kill a cow or what's your position there?

01:22:04.260 --> 01:22:06.060
And wouldn't that position also apply

01:22:06.060 --> 01:22:09.783
to healthy, non-self-aware human infants?

01:22:10.970 --> 01:22:12.180
- Okay, so firstly, I didn't say

01:22:12.180 --> 01:22:14.340
anything specifically about cows today.

01:22:14.340 --> 01:22:17.750
I indicated a wide range
between chimpanzees and fish,

01:22:17.750 --> 01:22:18.989
where there might be this spectrum

01:22:18.989 --> 01:22:21.760
and I didn't say where cows fall on it

01:22:21.760 --> 01:22:26.180
and I'm not sure that cows do fall

01:22:26.180 --> 01:22:30.470
on the fishy side, if
you like, of that divide.

01:22:30.470 --> 01:22:31.670
And I'm not even saying, I mean,

01:22:31.670 --> 01:22:33.100
you know, when we talk about fish

01:22:33.100 --> 01:22:35.080
but there's a huge range
of species of course

01:22:35.080 --> 01:22:36.700
and I'm not even really saying

01:22:36.700 --> 01:22:38.560
that there are no fish
that are self-aware.

01:22:38.560 --> 01:22:40.020
I just don't know.

01:22:40.020 --> 01:22:41.380
But there are lots of stories that show

01:22:41.380 --> 01:22:42.840
that cows have long memories.

01:22:42.840 --> 01:22:44.040
- Yeah.
- Particularly,

01:22:45.130 --> 01:22:46.050
a lot of people don't know,

01:22:46.050 --> 01:22:49.660
but the dairy industry
requires newborn calves

01:22:49.660 --> 01:22:51.160
to be taken from their mothers

01:22:52.000 --> 01:22:55.090
and lots of dairy farmers will tell you,

01:22:55.090 --> 01:22:57.390
if they're honest, that the cows

01:22:57.390 --> 01:22:59.070
miss their calves for quite a long time.

01:22:59.070 --> 01:23:00.800
Temple Grandin has a story

01:23:00.800 --> 01:23:03.950
in one of her books about a cow

01:23:03.950 --> 01:23:06.130
that was separated from her calf

01:23:06.130 --> 01:23:09.360
at a particular place
and she used to walk past

01:23:09.360 --> 01:23:11.280
that place coming in from the pastures.

01:23:11.280 --> 01:23:13.750
This was one of the
relatively better dairy farms,

01:23:13.750 --> 01:23:15.750
where cows actually get to be on pasture

01:23:16.750 --> 01:23:19.500
and she used to stop and call and bellow

01:23:19.500 --> 01:23:21.650
for the calf, four months
after the separation.

01:23:21.650 --> 01:23:24.060
So they clearly have long
memories about the past.

01:23:24.060 --> 01:23:24.893
It's not clear to me

01:23:24.893 --> 01:23:27.040
that they don't have
anticipation of the future.

01:23:27.040 --> 01:23:29.420
But if we're talking about beings

01:23:29.420 --> 01:23:31.030
with no anticipation in the future,

01:23:31.030 --> 01:23:33.280
then yes, whether they're human infants

01:23:33.280 --> 01:23:35.253
or whether they're non-human animals,

01:23:36.260 --> 01:23:38.840
killing of them is intrinsically

01:23:38.840 --> 01:23:41.400
or inherently on the same footing.

01:23:41.400 --> 01:23:44.730
There may be different other factors,

01:23:44.730 --> 01:23:46.800
extrinsic factors such as obviously,

01:23:46.800 --> 01:23:48.900
the wishes of the parents are
going to be highly relevant

01:23:48.900 --> 01:23:50.920
to the case of the killing of an infant

01:23:51.950 --> 01:23:53.480
and that may or may not be relevant

01:23:53.480 --> 01:23:55.180
in the case of other animals.

01:23:55.180 --> 01:23:59.053
So that's the view that I've held.

01:24:01.030 --> 01:24:02.590
There are certainly other
people you mentioned,

01:24:02.590 --> 01:24:04.510
Lori Gruen, there are a number of others

01:24:04.510 --> 01:24:06.350
who I've had discussions and debates with,

01:24:06.350 --> 01:24:08.460
and I'm sure I'll continue to do so.

01:24:08.460 --> 01:24:11.140
In fact, there's a conference
called Mining Animals

01:24:11.140 --> 01:24:14.300
in Utrecht, being held in late June.

01:24:14.300 --> 01:24:16.500
And I'm gonna be discussing that issue

01:24:16.500 --> 01:24:17.930
with some other people there.

01:24:17.930 --> 01:24:19.810
So it's still an ongoing question.

01:24:19.810 --> 01:24:24.469
But that is the way that I'm
judging it at the moment.

01:24:24.469 --> 01:24:25.302
Thank you.

01:24:26.310 --> 01:24:28.920
- [Presenter] Let me congratulate
all of the questioners.

01:24:28.920 --> 01:24:31.160
I thought they were exemplary

01:24:31.160 --> 01:24:35.228
and also congratulate Professor Singer.

01:24:35.228 --> 01:24:36.626
(audience applauding)
- Thank you.

01:24:36.626 --> 01:24:37.459
Thank you very much.

01:24:37.459 --> 01:24:39.876
(soft music)

