WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:04.050
FELIPE HOFFA: What can you
do with the election data?

00:00:04.050 --> 00:00:07.370
There is a very big
process going on.

00:00:07.370 --> 00:00:10.757
And I'm really passionate
about sharing this.

00:00:10.757 --> 00:00:12.590
I'm also super happy
to be here with Jordan.

00:00:12.590 --> 00:00:15.901
Jordan is one of the BigQuery
team founder members.

00:00:18.254 --> 00:00:19.670
JORDAN TIGANI: No,
I just, I think

00:00:19.670 --> 00:00:22.330
that it's really
important to understand

00:00:22.330 --> 00:00:25.520
what's going on in government,
and with elections.

00:00:25.520 --> 00:00:27.430
And I'm really
excited that we're

00:00:27.430 --> 00:00:29.940
able to use technology
that I work on

00:00:29.940 --> 00:00:33.000
in order to enable people to
do these important things.

00:00:33.000 --> 00:00:35.775
So I'm not just excited that
people are using my technology.

00:00:35.775 --> 00:00:37.150
I'm excited that
people are going

00:00:37.150 --> 00:00:40.280
to be able to use
it to do things

00:00:40.280 --> 00:00:42.282
that will change the world.

00:00:42.282 --> 00:00:43.990
FELIPE HOFFA: So please
take these tools.

00:00:43.990 --> 00:00:45.370
Bring them to your companies.

00:00:45.370 --> 00:00:49.325
Bring them to whatever
are your challenges.

00:00:49.325 --> 00:00:50.590
And also use them for good.

00:00:50.590 --> 00:00:52.870
Use them for civic purposes.

00:00:52.870 --> 00:00:58.870
So let's briefly review
technology in the US elections.

00:00:58.870 --> 00:01:00.310
JORDAN TIGANI: Thanks, Felipe.

00:01:00.310 --> 00:01:05.590
So in 2004, this was really the
first US presidential election,

00:01:05.590 --> 00:01:10.680
in which technology played
a played a big impact.

00:01:10.680 --> 00:01:13.410
And I don't know if you
remember Howard Dean.

00:01:13.410 --> 00:01:18.150
Howard Dean was a
governor of a small state,

00:01:18.150 --> 00:01:19.140
not very well known.

00:01:19.140 --> 00:01:20.950
But he was getting
massive amounts

00:01:20.950 --> 00:01:22.945
of small online donations.

00:01:22.945 --> 00:01:24.820
And this really kind of
caused people to wake

00:01:24.820 --> 00:01:29.760
up to the idea of using
the internet for elections.

00:01:29.760 --> 00:01:31.930
Now I have Howard Dean
versus Howard Dean

00:01:31.930 --> 00:01:33.880
because Howard Dean
also sort of died

00:01:33.880 --> 00:01:37.230
by technology in the election.

00:01:37.230 --> 00:01:43.290
On January 19, he
was giving a speech

00:01:43.290 --> 00:01:44.670
after one of the primaries.

00:01:44.670 --> 00:01:47.720
And he emitted this sort
of high pitched squeal.

00:01:47.720 --> 00:01:50.560
And these two seconds
of squeal then

00:01:50.560 --> 00:01:56.130
became a viral video that was
replayed over and over again

00:01:56.130 --> 00:01:58.300
across the networks
and on YouTube.

00:01:58.300 --> 00:02:00.424
And this really kind
of made him-- there's

00:02:00.424 --> 00:02:02.090
nothing worse for a
candidate than being

00:02:02.090 --> 00:02:03.050
made to look foolish.

00:02:03.050 --> 00:02:05.390
And this sort of
torpedoed his campaign.

00:02:05.390 --> 00:02:10.030
So we see also the positive
sides and the negative sides

00:02:10.030 --> 00:02:12.720
of technology in elections.

00:02:12.720 --> 00:02:17.920
Now if you fast
forward to 2012, you

00:02:17.920 --> 00:02:21.400
could argue that it was
Obama versus Romney.

00:02:21.400 --> 00:02:24.390
And you could argue
that Obama won.

00:02:24.390 --> 00:02:29.480
But is really the big
data nerd election.

00:02:29.480 --> 00:02:36.740
Each candidate's campaign team
had big data analysis systems

00:02:36.740 --> 00:02:38.550
that were named after whales.

00:02:38.550 --> 00:02:47.980
And it turned out that the Obama
team's whales crushed Romney's.

00:02:47.980 --> 00:02:53.750
They had software that allowed
them to do things like figure

00:02:53.750 --> 00:02:56.340
out how to get
people to the polls,

00:02:56.340 --> 00:03:03.620
how to buy media and spend
less, sort of all these areas.

00:03:03.620 --> 00:03:07.000
Where on the Romney side,
basically, on election day,

00:03:07.000 --> 00:03:09.330
it sort of fizzled.

00:03:09.330 --> 00:03:13.064
So it was really kind
of a resounding victory,

00:03:13.064 --> 00:03:14.730
regardless of which
candidate you liked,

00:03:14.730 --> 00:03:20.475
it was a resounding victory
for the nerd teams that won.

00:03:20.475 --> 00:03:21.850
FELIPE HOFFA: So
what we're going

00:03:21.850 --> 00:03:24.420
to do today matters a lot.

00:03:24.420 --> 00:03:28.150
You can go back to when
the other Clinton was

00:03:28.150 --> 00:03:29.210
elected to be president.

00:03:29.210 --> 00:03:30.770
There was no internet.

00:03:30.770 --> 00:03:34.810
Then, for Bush we saw
ads on the internet.

00:03:34.810 --> 00:03:37.312
Then Obama started doing
the first A/B testings

00:03:37.312 --> 00:03:39.610
on a political campaign.

00:03:39.610 --> 00:03:43.340
And now, four years ago,
we had the whales battling

00:03:43.340 --> 00:03:45.799
And today I have some
challenges for Jordan.

00:03:45.799 --> 00:03:48.090
And we're going to use some
pretty interesting big data

00:03:48.090 --> 00:03:49.040
sets.

00:03:49.040 --> 00:03:52.990
If you know Twitter, they
allowed us to use their data.

00:03:52.990 --> 00:03:55.130
We are ingesting
this in real time.

00:03:59.110 --> 00:04:01.710
JORDAN TIGANI: We also have
the federal election campaign

00:04:01.710 --> 00:04:02.930
data set.

00:04:02.930 --> 00:04:09.070
The US government has a website
of every campaign donation

00:04:09.070 --> 00:04:11.290
given to the candidates
and also what they're

00:04:11.290 --> 00:04:13.110
spending their money on.

00:04:13.110 --> 00:04:16.560
FELIPE HOFFA: What
can we learn from it?

00:04:16.560 --> 00:04:21.089
Next, this data set,
it's a little raw.

00:04:21.089 --> 00:04:23.240
So we have our
friends at OpenSecret

00:04:23.240 --> 00:04:25.760
that have taken this data,
they have cleaned it up,

00:04:25.760 --> 00:04:29.320
and they've made it available
under an open data license.

00:04:29.320 --> 00:04:32.930
So we're going to
be using that, too.

00:04:32.930 --> 00:04:34.930
JORDAN TIGANI: We also
have every Reddit comment

00:04:34.930 --> 00:04:39.780
since 2007, just to give
sort of a less official,

00:04:39.780 --> 00:04:43.115
but perhaps just as
enlightening vision of what's

00:04:43.115 --> 00:04:44.365
happening with the candidates.

00:04:44.365 --> 00:04:46.780
FELIPE HOFFA: Yes, I have to
thank Jason Baumgardner that

00:04:46.780 --> 00:04:49.890
has been collecting and making
these comments available.

00:04:49.890 --> 00:04:52.620
And we're going
to have fun there.

00:04:52.620 --> 00:04:55.950
Wikipedia, that's a
lot of page views.

00:04:55.950 --> 00:04:59.350
Around the 50 billion
page views a month.

00:04:59.350 --> 00:05:01.310
What can we see there?

00:05:01.310 --> 00:05:03.072
That's part of the
challenge today.

00:05:03.072 --> 00:05:04.780
JORDAN TIGANI: And
this is just one table

00:05:04.780 --> 00:05:06.010
that's half a terabyte.

00:05:06.010 --> 00:05:08.730
We have basically-- this
is just one month's worth.

00:05:08.730 --> 00:05:13.170
And we're going to be analyzing
considerably more than that.

00:05:13.170 --> 00:05:16.210
FELIPE HOFFA: GDELT, all of the
news in the world, everything

00:05:16.210 --> 00:05:19.820
that is happening, collected
by Kalev Leetaru starting

00:05:19.820 --> 00:05:23.010
30 years ago until
15 minutes ago,

00:05:23.010 --> 00:05:25.277
more than 300 million events.

00:05:25.277 --> 00:05:26.360
That's also in our tables.

00:05:29.710 --> 00:05:35.290
JORDAN TIGANI: All right,
I guess, before we start,

00:05:35.290 --> 00:05:38.197
I want to just provide
a little editorial note.

00:05:38.197 --> 00:05:40.030
We're going to show a
lot of visualizations.

00:05:40.030 --> 00:05:42.330
We're going to
show a lot of data.

00:05:42.330 --> 00:05:44.660
We, Felipe and I,
may be partisan.

00:05:44.660 --> 00:05:47.460
But we're not trying to
show anything partisan here.

00:05:47.460 --> 00:05:49.940
We're just trying
to show the data.

00:05:49.940 --> 00:05:54.715
But you guys certainly
have ideas, and things

00:05:54.715 --> 00:05:55.930
that you'd like to show.

00:05:55.930 --> 00:05:59.080
We're trying to kind of inspire.

00:05:59.080 --> 00:06:01.450
You guys can take the types
of things that we're doing,

00:06:01.450 --> 00:06:04.710
and then go off, and make
a persuasive argument.

00:06:04.710 --> 00:06:07.210
But we're going to try to just
let the data speak for itself

00:06:07.210 --> 00:06:07.690
today.

00:06:07.690 --> 00:06:08.440
FELIPE HOFFA: Yes.

00:06:08.440 --> 00:06:10.890
Someone told me not to
speak about politics.

00:06:10.890 --> 00:06:14.130
I think we will
data-speak about politics.

00:06:14.130 --> 00:06:14.850
Let's start.

00:06:14.850 --> 00:06:15.905
Let's start with money.

00:06:15.905 --> 00:06:17.030
JORDAN TIGANI: Sounds good.

00:06:17.030 --> 00:06:19.880
FELIPE HOFFA: What tool
are we going to use today?

00:06:19.880 --> 00:06:21.834
JORDAN TIGANI: So I
work on Google BigQuery.

00:06:21.834 --> 00:06:23.000
I know BigQuery really well.

00:06:23.000 --> 00:06:26.010
And I think BigQuery is great
for analyzing election data.

00:06:26.010 --> 00:06:28.010
But if you're not familiar
with Google BigQuery,

00:06:28.010 --> 00:06:33.450
it's a big data SQL query
engine that you don't

00:06:33.450 --> 00:06:34.970
have to spin up any instances.

00:06:34.970 --> 00:06:36.447
It's just all the data is there.

00:06:36.447 --> 00:06:38.780
And one of the things that's
under appreciated about it,

00:06:38.780 --> 00:06:40.030
and we're going
to leverage today,

00:06:40.030 --> 00:06:41.570
is that it's one
global namespace.

00:06:41.570 --> 00:06:45.435
So you can join any two tables
against any other table.

00:06:45.435 --> 00:06:47.310
FELIPE HOFFA: And it's
a really, really fast.

00:06:47.310 --> 00:06:48.980
And it connects with
different tools.

00:06:48.980 --> 00:06:51.550
We're going to start
with Re:dash to run some

00:06:51.550 --> 00:06:52.590
visualizations.

00:06:52.590 --> 00:06:54.460
So my first challenge
for you, Jordan,

00:06:54.460 --> 00:06:57.180
is, can you show
me how much money

00:06:57.180 --> 00:06:59.460
are the candidates
getting this year?

00:06:59.460 --> 00:07:02.620
JORDAN TIGANI: All right, well,
so the first visualization I

00:07:02.620 --> 00:07:05.660
have, and I'm going to
use Re:dash for this.

00:07:05.660 --> 00:07:11.000
And I'm going to go over the
OpenSecrets individual campaign

00:07:11.000 --> 00:07:13.550
donations dataset here.

00:07:13.550 --> 00:07:17.290
And we're joining it
with the candidates.

00:07:17.290 --> 00:07:20.760
We're filtering by codes
that we don't care about.

00:07:20.760 --> 00:07:25.310
And since there are so many
candidates this time around,

00:07:25.310 --> 00:07:27.610
we want to filter out
by only candidates that

00:07:27.610 --> 00:07:35.420
got at least 8,000 donations
and at least 5,000 donations

00:07:35.420 --> 00:07:38.320
in a month.

00:07:38.320 --> 00:07:43.730
So then I just ran that query.

00:07:43.730 --> 00:07:44.782
It took eight seconds.

00:07:44.782 --> 00:07:45.740
And here's the results.

00:07:45.740 --> 00:07:49.340
But we want to make
a nice visualization.

00:07:49.340 --> 00:07:53.610
So I'm opening up the
Re:dash visualization editor.

00:07:53.610 --> 00:07:57.470
We can use a bar chart
with the x column month.

00:07:57.470 --> 00:08:00.222
And the y column we
want just amount.

00:08:00.222 --> 00:08:01.638
And then we group
it by recipient.

00:08:04.220 --> 00:08:05.600
And here we are.

00:08:05.600 --> 00:08:10.570
So we can see that, at
the beginning of 2015,

00:08:10.570 --> 00:08:14.270
it was Hillary Clinton was
getting by far the most

00:08:14.270 --> 00:08:15.970
donations.

00:08:15.970 --> 00:08:19.510
And then fast
forward out to March,

00:08:19.510 --> 00:08:24.230
Bernie Sanders actually
eclipsed Hillary

00:08:24.230 --> 00:08:28.750
in the dollar
amount of donations.

00:08:28.750 --> 00:08:35.011
And we see that Ted
Cruz was increasing.

00:08:35.011 --> 00:08:37.010
And one interesting thing
you might want to note

00:08:37.010 --> 00:08:41.470
is Donald Trump is this
little tiny line here.

00:08:41.470 --> 00:08:44.620
Donald Trump was essentially
self-financing his election.

00:08:44.620 --> 00:08:47.960
So he's not really taking in
much in the way of donations.

00:08:47.960 --> 00:08:49.181
FELIPE HOFFA: Until now.

00:08:49.181 --> 00:08:50.222
JORDAN TIGANI: Until now.

00:08:50.222 --> 00:08:52.555
FELIPE HOFFA: But now, if we
wanted to jump to the past,

00:08:52.555 --> 00:08:54.190
if we wanted to
see what happened

00:08:54.190 --> 00:08:58.390
to Howard Dean, the story you
were mentioning earlier today,

00:08:58.390 --> 00:08:59.510
how do you load this data?

00:08:59.510 --> 00:09:01.120
How do you bring
it into BigQuery?

00:09:01.120 --> 00:09:03.350
JORDAN TIGANI: Sure,
so the OpenSecrets data

00:09:03.350 --> 00:09:06.350
that we have that we were able
to make public, was just 2016.

00:09:06.350 --> 00:09:08.354
So if we want to look
at historical elections,

00:09:08.354 --> 00:09:09.770
we have to use the
data that we've

00:09:09.770 --> 00:09:12.510
downloaded from the Federal
Election Commission.

00:09:12.510 --> 00:09:15.570
And this is what their
download page looks like.

00:09:15.570 --> 00:09:16.980
And I've downloaded that data.

00:09:16.980 --> 00:09:18.920
And I've uploaded it to
Google Cloud Storage.

00:09:18.920 --> 00:09:21.090
And I'm using a
feature on BigQuery

00:09:21.090 --> 00:09:24.617
called federated tables, which
means that the table doesn't

00:09:24.617 --> 00:09:25.325
live in BigQuery.

00:09:25.325 --> 00:09:27.110
It lives in some
external data source.

00:09:27.110 --> 00:09:29.390
In this case, it's
Cloud Storage.

00:09:29.390 --> 00:09:36.050
So it's going to go over all
of the individual donations.

00:09:36.050 --> 00:09:37.570
It's going to read them as CSV.

00:09:37.570 --> 00:09:40.170
And it's a slightly
weird format.

00:09:40.170 --> 00:09:43.170
And because it's a
slightly weird format,

00:09:43.170 --> 00:09:47.250
the donations don't tell
you who you're donating to.

00:09:47.250 --> 00:09:49.090
It just tells you the
code of the committee

00:09:49.090 --> 00:09:49.750
you're donating to.

00:09:49.750 --> 00:09:50.930
So you have to join
against the committee.

00:09:50.930 --> 00:09:52.555
And then you have to
join the committee

00:09:52.555 --> 00:09:54.930
against the candidate.

00:09:54.930 --> 00:09:57.440
So I've just done a
bunch of that work

00:09:57.440 --> 00:10:00.120
and written that
to a summary table.

00:10:00.120 --> 00:10:01.770
And this is the
summary table that

00:10:01.770 --> 00:10:05.440
shows the candidate,
who gave the money,

00:10:05.440 --> 00:10:07.835
and how much they gave.

00:10:07.835 --> 00:10:11.900
And that table is 2
and 1/2 gigabytes.

00:10:11.900 --> 00:10:16.340
And that's everything
from 1980 until the most

00:10:16.340 --> 00:10:19.140
recent elections.

00:10:19.140 --> 00:10:22.690
Now let's look at the
Howard Dean moment.

00:10:22.690 --> 00:10:25.700
So I'm going to run
over that summary table

00:10:25.700 --> 00:10:32.050
that I built. And we're going
to look for candidate Howard

00:10:32.050 --> 00:10:33.750
Dean and John
Kerry, because those

00:10:33.750 --> 00:10:37.984
were the two Democratic
frontrunners at the time.

00:10:37.984 --> 00:10:39.525
And the time range
we're going to use

00:10:39.525 --> 00:10:45.050
is between the end of 2003
to the beginning of 2004.

00:10:45.050 --> 00:10:48.100
And I'm not going to show you
building this visualization

00:10:48.100 --> 00:10:49.630
because it was
just, essentially,

00:10:49.630 --> 00:10:52.040
the same as the
last one except we

00:10:52.040 --> 00:10:57.850
select line chart
instead of bar chart.

00:10:57.850 --> 00:11:02.110
And so you can see, this is the
numbers of donations per week.

00:11:02.110 --> 00:11:07.344
And Howard Dean is
really just crushing it.

00:11:07.344 --> 00:11:09.240
You see, like
December 31, I guess

00:11:09.240 --> 00:11:11.520
everybody gets
their donation in,

00:11:11.520 --> 00:11:14.000
so they can give more next year.

00:11:14.000 --> 00:11:16.472
But January 19 here, the
date of the Dean scream,

00:11:16.472 --> 00:11:17.180
it's interesting.

00:11:17.180 --> 00:11:19.960
His supporters were
still supporting him.

00:11:19.960 --> 00:11:22.050
He was still getting
donations after that.

00:11:22.050 --> 00:11:24.730
But this really
gave his opponent

00:11:24.730 --> 00:11:27.620
a lot more ammunition, realized
that he was vulnerable.

00:11:27.620 --> 00:11:29.350
And people realize,
hey, I'm going

00:11:29.350 --> 00:11:32.290
to give to this other guy.

00:11:32.290 --> 00:11:33.510
FELIPE HOFFA: Wow.

00:11:33.510 --> 00:11:38.590
That's how you can jump to
the past, go to any moment.

00:11:38.590 --> 00:11:40.180
There's a lot of SQL here.

00:11:40.180 --> 00:11:42.530
I don't know who knows SQL here?

00:11:42.530 --> 00:11:43.030
SQL?

00:11:43.030 --> 00:11:44.470
Yes, my kind of people.

00:11:44.470 --> 00:11:45.870
But not everyone.

00:11:45.870 --> 00:11:48.110
So what kind of
tools would you use

00:11:48.110 --> 00:11:51.860
to use this same data to
explore it other ways,

00:11:51.860 --> 00:11:54.069
without a line of SQL?

00:11:54.069 --> 00:11:55.110
JORDAN TIGANI: Let's see.

00:12:02.190 --> 00:12:03.850
So this is Tableau.

00:12:03.850 --> 00:12:07.000
Tableau is a business
intelligence visualization

00:12:07.000 --> 00:12:08.550
tool.

00:12:08.550 --> 00:12:12.630
And Tableau has built-in
support for BigQuery.

00:12:12.630 --> 00:12:18.660
So I'm going to connect
to BigQuery from Tableau.

00:12:18.660 --> 00:12:24.260
And I'm going to connect to
the-- so I look at my project,

00:12:24.260 --> 00:12:27.580
fill out my campaign
funding data set.

00:12:27.580 --> 00:12:30.780
And I'm going to use
this summary table,

00:12:30.780 --> 00:12:31.555
drag it over here.

00:12:31.555 --> 00:12:38.930
Tableau goes and looks up
the schema, cardinality,

00:12:38.930 --> 00:12:41.030
which types of fields they are.

00:12:41.030 --> 00:12:45.420
And then I can build a new
visualization with this.

00:12:45.420 --> 00:12:48.470
And so all I have to do is just
start dragging and dropping.

00:12:48.470 --> 00:12:50.500
So I'm going to
drop amount to rows

00:12:50.500 --> 00:12:52.150
because we're looking at rows.

00:12:52.150 --> 00:12:56.059
And then, of course,
that's not very interesting

00:12:56.059 --> 00:12:57.600
because it just sums
up all the rows.

00:12:57.600 --> 00:13:00.340
But let's then use columns
as candidate affiliations.

00:13:00.340 --> 00:13:02.230
So we can see how much
money has been given

00:13:02.230 --> 00:13:04.190
to various political parties.

00:13:04.190 --> 00:13:06.670
And of course, there's
lots of political parties.

00:13:06.670 --> 00:13:10.050
But in the US, the Democratic
Party and the Republican Party

00:13:10.050 --> 00:13:12.830
get all of the donations.

00:13:12.830 --> 00:13:18.260
And this is really disturbing
because this-- oh, here we go.

00:13:18.260 --> 00:13:19.466
That looks better.

00:13:19.466 --> 00:13:20.590
So this is a visualization.

00:13:20.590 --> 00:13:23.641
I basically just
took the same table

00:13:23.641 --> 00:13:25.640
and just did a little
more dragging and dropping

00:13:25.640 --> 00:13:27.910
that I won't do up here.

00:13:27.910 --> 00:13:30.800
But this is showing
the amount of money

00:13:30.800 --> 00:13:34.120
that is donated by
state, whether they

00:13:34.120 --> 00:13:36.680
give more to Republicans
or more to Democrats.

00:13:36.680 --> 00:13:39.600
And we can actually, we
can go year by year here.

00:13:39.600 --> 00:13:43.780
So let's look at 2008.

00:13:43.780 --> 00:13:46.220
Come on.

00:13:46.220 --> 00:13:52.850
2008, there we go, the year
of Obama's first candidacy.

00:13:52.850 --> 00:13:57.660
You can see that
coasts are very blue.

00:13:57.660 --> 00:13:59.352
The center of the
country is red.

00:13:59.352 --> 00:14:00.810
They're giving more
to Republicans.

00:14:00.810 --> 00:14:05.650
But there's a smattering of
blue throughout the country.

00:14:05.650 --> 00:14:09.350
Then, if you look
at the re-election,

00:14:09.350 --> 00:14:12.100
the things had
solidified, really,

00:14:12.100 --> 00:14:13.520
in the center of the country.

00:14:13.520 --> 00:14:18.320
And basically, they're
giving very heavily

00:14:18.320 --> 00:14:21.560
to the Republican side.

00:14:21.560 --> 00:14:22.690
FELIPE HOFFA: Interesting.

00:14:22.690 --> 00:14:28.540
Back to 2016, how are our
candidates doing so far?

00:14:28.540 --> 00:14:30.240
Primaries.

00:14:30.240 --> 00:14:34.170
JORDAN TIGANI: OK, well,
I don't know if people

00:14:34.170 --> 00:14:36.060
are following the primaries.

00:14:36.060 --> 00:14:39.342
But they're changing a lot.

00:14:39.342 --> 00:14:40.800
There's a bunch of
these primaries.

00:14:40.800 --> 00:14:42.980
So we have a Google
spreadsheet that

00:14:42.980 --> 00:14:47.320
has the winners of each
primary, and the amount of votes

00:14:47.320 --> 00:14:52.100
and delegates for each primary.

00:14:52.100 --> 00:14:55.520
And so when you use a
feature of BigQuery--

00:14:55.520 --> 00:15:01.980
this is also federated
tables-- but we

00:15:01.980 --> 00:15:06.519
have a table here that's backed
by this Google spreadsheet.

00:15:06.519 --> 00:15:08.310
So you can see the
format is Google Sheets.

00:15:08.310 --> 00:15:15.120
And so I can run a query
to see who is winning.

00:15:15.120 --> 00:15:20.440
And Hillary Clinton has the most
total votes, followed not too

00:15:20.440 --> 00:15:22.369
far behind by Donald Trump.

00:15:22.369 --> 00:15:23.910
But one of the cool
things about this

00:15:23.910 --> 00:15:27.670
is you can modify
it in real time.

00:15:27.670 --> 00:15:30.160
So let's stuff the
ballot box for Felipe.

00:15:34.820 --> 00:15:35.820
FELIPE HOFFA: Thank you.

00:15:35.820 --> 00:15:36.558
Thank you all.

00:15:36.558 --> 00:15:37.058
[LAUGHTER]

00:15:40.460 --> 00:15:42.220
JORDAN TIGANI: And
then rerun this query.

00:15:42.220 --> 00:15:44.136
Now sometimes these
queries take a few seconds

00:15:44.136 --> 00:15:46.420
because it's not really
optimized for fast access.

00:15:46.420 --> 00:15:47.182
But hey!

00:15:47.182 --> 00:15:47.682
[APPLAUSE]

00:15:47.682 --> 00:15:49.802
FELIPE HOFFA: Yes.

00:15:49.802 --> 00:15:51.760
People that use BigQuery
know how cool this is.

00:15:55.890 --> 00:15:58.480
Yes, so that's
awesome new feature.

00:15:58.480 --> 00:16:01.220
Please enjoy it.

00:16:01.220 --> 00:16:03.650
Now let's start
connecting the dots.

00:16:03.650 --> 00:16:06.050
These candidates are
collecting a lot of money.

00:16:06.050 --> 00:16:07.450
They are spending money.

00:16:07.450 --> 00:16:09.480
They are getting
votes, delegates.

00:16:09.480 --> 00:16:12.067
Who's the most
efficient of these?

00:16:12.067 --> 00:16:13.900
JORDAN TIGANI: Sorry,
I'm trying to remember

00:16:13.900 --> 00:16:15.140
if we have a query for this.

00:16:15.140 --> 00:16:16.639
Oh yes, we do have
a query for this.

00:16:20.560 --> 00:16:27.300
So this query is going to
operate over the OpenSecrets

00:16:27.300 --> 00:16:28.460
data set again.

00:16:28.460 --> 00:16:37.200
And we are just going to sum
up the amount of donations.

00:16:37.200 --> 00:16:40.940
But then we're going to join
it against the-- there we

00:16:40.940 --> 00:16:43.110
go-- the primary results table.

00:16:43.110 --> 00:16:48.140
So we can see how much money
these people are spending--

00:16:48.140 --> 00:16:51.060
so this is actually the spending
side of things-- per vote

00:16:51.060 --> 00:16:52.900
that they get.

00:16:52.900 --> 00:16:56.720
And so we see that Ben Carson
was spending the most when

00:16:56.720 --> 00:16:58.240
he was in the election.

00:16:58.240 --> 00:17:01.560
He was spending the
most amount per vote,

00:17:01.560 --> 00:17:03.380
followed by Hillary Clinton.

00:17:03.380 --> 00:17:06.200
And of the remaining
major candidates,

00:17:06.200 --> 00:17:08.415
Bernie Sanders has been
the most efficient.

00:17:08.415 --> 00:17:10.790
I take Donald Trump out of
that just because Donald Trump

00:17:10.790 --> 00:17:14.000
is not actually really
running his campaign

00:17:14.000 --> 00:17:16.232
based on donations.

00:17:16.232 --> 00:17:18.190
FELIPE HOFFA: And what's
super interesting here

00:17:18.190 --> 00:17:21.390
is when we start looking
at these efficiencies,

00:17:21.390 --> 00:17:23.869
is that we start wondering why?

00:17:23.869 --> 00:17:27.380
How can one candidate be more
efficient than the other?

00:17:27.380 --> 00:17:30.360
What's driving the results?

00:17:30.360 --> 00:17:33.390
At least in the old
times, we could say TV.

00:17:33.390 --> 00:17:35.640
This is the number of
mentions each candidate is

00:17:35.640 --> 00:17:38.790
getting on TV so far,
measured by GDELT

00:17:38.790 --> 00:17:40.717
using the internet archive.

00:17:40.717 --> 00:17:42.550
And you can see that
Donald Trump is getting

00:17:42.550 --> 00:17:44.010
way more mentions from TV.

00:17:44.010 --> 00:17:46.890
That's a pretty nice
way to get votes

00:17:46.890 --> 00:17:48.710
without spending a lot of money.

00:17:48.710 --> 00:17:50.856
Followed by Clinton,
followed by Sanders,

00:17:50.856 --> 00:17:53.760
and then everyone else.

00:17:53.760 --> 00:17:56.290
And what's interesting
here is that, OK,

00:17:56.290 --> 00:18:00.110
TV is working for
Trump very well.

00:18:00.110 --> 00:18:03.470
But Sanders is getting pretty
efficient without getting

00:18:03.470 --> 00:18:05.300
many TV mentions.

00:18:05.300 --> 00:18:06.970
And we may wonder why.

00:18:06.970 --> 00:18:09.870
And that's where our
next challenges go.

00:18:09.870 --> 00:18:14.200
Let's go to old media
versus the new media.

00:18:14.200 --> 00:18:17.175
We're going to incorporate
new tools, like Dataflow.

00:18:17.175 --> 00:18:18.800
JORDAN TIGANI: So
Google Cloud Dataflow

00:18:18.800 --> 00:18:23.430
is a batch and streaming
data processing

00:18:23.430 --> 00:18:27.590
system, sort of like MapReduce,
but lets you operate it

00:18:27.590 --> 00:18:31.350
at a much higher level.

00:18:31.350 --> 00:18:34.686
And we're using Dataflow
to take Twitter data.

00:18:34.686 --> 00:18:35.560
We're bringing it in.

00:18:35.560 --> 00:18:36.850
We're transforming the data.

00:18:36.850 --> 00:18:44.860
And we're writing it to pub/sub
and to a BigQuery table.

00:18:44.860 --> 00:18:45.750
FELIPE HOFFA: Yes.

00:18:45.750 --> 00:18:48.640
JORDAN TIGANI: And then we're
also going to pull in the data

00:18:48.640 --> 00:18:52.880
from pub/sub and put
it into Firebase.

00:18:52.880 --> 00:18:56.100
And you guys have probably
heard a lot about Firebase

00:18:56.100 --> 00:19:00.400
this week, so I don't have
to go into too much detail.

00:19:00.400 --> 00:19:03.150
FELIPE HOFFA: So, OK,
let's start with old media.

00:19:03.150 --> 00:19:06.030
Let's look at GDELT, all
the news in the world.

00:19:06.030 --> 00:19:11.107
How old is the
worldwide media talking

00:19:11.107 --> 00:19:12.919
about the US candidates?

00:19:12.919 --> 00:19:13.960
JORDAN TIGANI: All right.

00:19:13.960 --> 00:19:17.870
So we're going to use--
so the last visualization

00:19:17.870 --> 00:19:22.020
Felipe showed of the
television efficiency, that

00:19:22.020 --> 00:19:23.990
used the GDELT data set.

00:19:23.990 --> 00:19:26.850
So we have the GDELT
data set in BigQuery.

00:19:26.850 --> 00:19:30.300
But the GDELT data
set has a lot of data.

00:19:30.300 --> 00:19:36.840
It has the emotional content
of every media article.

00:19:36.840 --> 00:19:39.330
It has all of the
people who are mentioned

00:19:39.330 --> 00:19:41.540
in it and the positions
within the article

00:19:41.540 --> 00:19:42.610
that they mentioned.

00:19:42.610 --> 00:19:45.600
But it can be a little bit
hard to query that using SQL.

00:19:45.600 --> 00:19:47.770
So I'm using another
BigQuery feature here

00:19:47.770 --> 00:19:49.600
called user defined functions.

00:19:49.600 --> 00:19:52.750
And user defined functions allow
you to write JavaScript code

00:19:52.750 --> 00:19:55.220
and have those run
inside your query.

00:19:55.220 --> 00:19:57.910
So what I'm doing is, so, for
example, I'm trying to figure,

00:19:57.910 --> 00:20:02.380
for articles that mention
political candidates, which

00:20:02.380 --> 00:20:05.020
one are they really which one
are they really talking about.

00:20:05.020 --> 00:20:08.860
Because a lot of articles about
Clinton also talk about Bernie.

00:20:08.860 --> 00:20:11.000
But the article
is about Clinton.

00:20:11.000 --> 00:20:14.310
So we have a code that
splits out some of these.

00:20:14.310 --> 00:20:16.800
It's about 200 lines
of JavaScript code.

00:20:16.800 --> 00:20:19.840
And then we can run this
directly in BigQuery.

00:20:19.840 --> 00:20:23.360
So I've created a
view that uses this.

00:20:23.360 --> 00:20:27.300
And sorry.

00:20:39.640 --> 00:20:41.056
Sorry.

00:20:41.056 --> 00:20:42.630
Ah, details, there we go.

00:20:42.630 --> 00:20:46.640
And the query basically
just feeds the source data.

00:20:46.640 --> 00:20:50.440
This is the raw GDELT table.

00:20:50.440 --> 00:20:54.610
And then I can switch
back to Re:dash.

00:20:54.610 --> 00:20:57.340
And we can run this query.

00:20:57.340 --> 00:21:00.930
And this query usually
takes about a minute.

00:21:00.930 --> 00:21:03.900
I'm going to hope
that it's fast today.

00:21:03.900 --> 00:21:07.175
And, uh oh.

00:21:07.175 --> 00:21:10.130
FELIPE HOFFA: Ooh.

00:21:10.130 --> 00:21:13.459
We can come back here if it--
oh, we have a [INAUDIBLE] one.

00:21:13.459 --> 00:21:14.500
JORDAN TIGANI: All right.

00:21:14.500 --> 00:21:18.320
I'm going to skip to the
final visualization there.

00:21:18.320 --> 00:21:23.050
But I'll show what, I think I
must have just typed something

00:21:23.050 --> 00:21:25.860
into the box and
it screwed it up.

00:21:25.860 --> 00:21:28.730
But so we're going to
show the emotional content

00:21:28.730 --> 00:21:32.080
of these articles.

00:21:32.080 --> 00:21:34.870
And so this can be either
positive or negative.

00:21:34.870 --> 00:21:38.860
And for the major political
candidates-- or, sorry,

00:21:38.860 --> 00:21:40.840
for just Hillary Clinton
and Donald Trump.

00:21:40.840 --> 00:21:43.900
And we're going to split
those out by country.

00:21:43.900 --> 00:21:48.740
And so we do a
join based on where

00:21:48.740 --> 00:21:50.860
the media source comes from.

00:21:50.860 --> 00:21:54.780
And then we are going to
map that to the article.

00:21:54.780 --> 00:21:59.090
So what we can see-- and
so here's the result.

00:21:59.090 --> 00:22:03.200
Of countries that
are writing articles

00:22:03.200 --> 00:22:07.460
that mention US candidates,
this is with a positive

00:22:07.460 --> 00:22:08.740
versus negative tone.

00:22:08.740 --> 00:22:10.790
And one thing we
should note is, we

00:22:10.790 --> 00:22:13.320
moved the average a
little bit to basically

00:22:13.320 --> 00:22:18.580
be the overall average because,
overall, they were pretty

00:22:18.580 --> 00:22:20.070
negative about both candidates.

00:22:20.070 --> 00:22:25.380
So we're sort of
resetting the zero.

00:22:25.380 --> 00:22:29.165
But so the highest
positive is Turkey.

00:22:29.165 --> 00:22:33.140
I guess Turkey really
likes Hillary Clinton.

00:22:33.140 --> 00:22:35.450
The highest negative
is Switzerland.

00:22:35.450 --> 00:22:39.760
The Swiss are not big
Donald Trump fans.

00:22:39.760 --> 00:22:42.288
Maybe he doesn't
use their banks.

00:22:42.288 --> 00:22:48.100
[LAUGHTER]

00:22:48.100 --> 00:22:50.220
JORDAN TIGANI: And so
you might ask, well,

00:22:50.220 --> 00:22:52.270
can you guys plot this on a map?

00:22:52.270 --> 00:22:54.616
Maybe Felipe was
about to ask me that.

00:22:54.616 --> 00:22:55.490
But we don't have to.

00:22:55.490 --> 00:22:56.600
Somebody already did.

00:22:56.600 --> 00:22:59.020
So [INAUDIBLE], someone
who's done a lot of BigQuery

00:22:59.020 --> 00:23:01.190
queries, and that we've
worked with in the past,

00:23:01.190 --> 00:23:03.690
he plotted these in CartoDB.

00:23:03.690 --> 00:23:05.540
And so this is sort
of the map version

00:23:05.540 --> 00:23:08.690
of which countries are
positive and negative

00:23:08.690 --> 00:23:10.100
about Hillary Clinton.

00:23:10.100 --> 00:23:13.380
And here's the same
for Donald Trump.

00:23:13.380 --> 00:23:15.380
FELIPE HOFFA: Russia
really has a positive tone,

00:23:15.380 --> 00:23:17.090
those articles.

00:23:17.090 --> 00:23:18.459
JORDAN TIGANI: As does Ukraine.

00:23:18.459 --> 00:23:19.250
FELIPE HOFFA: Yeah.

00:23:19.250 --> 00:23:22.320
So it's really cool to be able
to look up the worldwide media,

00:23:22.320 --> 00:23:27.480
join it with where the
source of that media comes,

00:23:27.480 --> 00:23:34.130
join it, look at tone, and start
analyzing what happened there.

00:23:34.130 --> 00:23:36.290
Let's go back to Bernie.

00:23:36.290 --> 00:23:39.110
Where was the first place
you heard about Bernie?

00:23:39.110 --> 00:23:39.830
Was it TV?

00:23:39.830 --> 00:23:40.690
Was it the media?

00:23:40.690 --> 00:23:41.425
Was it Reddit?

00:23:43.419 --> 00:23:45.460
JORDAN TIGANI: I feel like
social media picked up

00:23:45.460 --> 00:23:49.820
on Bernie Sanders before
the mainstream media.

00:23:49.820 --> 00:23:51.949
FELIPE HOFFA: How can you
show me that with data?

00:23:51.949 --> 00:23:52.990
JORDAN TIGANI: All right.

00:23:52.990 --> 00:23:54.114
Well, let's check this out.

00:23:54.114 --> 00:24:01.330
So this is a query that is
going to combine multiple data

00:24:01.330 --> 00:24:02.220
sources together.

00:24:02.220 --> 00:24:13.750
So this is going to
combine the GDELT data set.

00:24:13.750 --> 00:24:17.060
This was the view that
I created earlier.

00:24:17.060 --> 00:24:19.400
We're also going to look
at all Reddit comments.

00:24:19.400 --> 00:24:24.450
So we're going to also look at
candidate popularity in Reddit

00:24:24.450 --> 00:24:25.160
comments.

00:24:25.160 --> 00:24:28.140
Then we're going to look
at Wikipedia page views.

00:24:28.140 --> 00:24:34.480
So maybe people were looking at
the candidate's web page a lot

00:24:34.480 --> 00:24:37.020
and see when see
when those picked up.

00:24:37.020 --> 00:24:39.710
And then we're computing
a trailing average

00:24:39.710 --> 00:24:46.950
so that the numbers don't
bounce up and down too much.

00:24:46.950 --> 00:24:49.870
Beautiful.

00:24:49.870 --> 00:24:53.360
Maybe I can reload this page.

00:24:53.360 --> 00:24:56.490
Just to give an idea of
how big this query is?

00:24:56.490 --> 00:25:03.096
This query is a 5.24 terabytes.

00:25:03.096 --> 00:25:04.790
FELIPE HOFFA: So that's of data.

00:25:04.790 --> 00:25:06.415
JORDAN TIGANI: So
that's a lot of data.

00:25:06.415 --> 00:25:08.240
It takes about a minute.

00:25:08.240 --> 00:25:09.796
And you know, there's
a lot of stuff

00:25:09.796 --> 00:25:11.920
that has to-- we're running
a user defined function

00:25:11.920 --> 00:25:16.550
over billions of
entries in GDELT. We're

00:25:16.550 --> 00:25:20.110
taking these multiple data
sources from different places.

00:25:20.110 --> 00:25:23.900
And so here's what the
visualization looks like.

00:25:23.900 --> 00:25:28.640
So we can see that, really,
the mainstream media and Reddit

00:25:28.640 --> 00:25:31.610
and Wikipedia all really
picked up on the Bernie story

00:25:31.610 --> 00:25:34.160
at about the same time.

00:25:34.160 --> 00:25:37.440
So GDELT is a proxy for
the mainstream media.

00:25:37.440 --> 00:25:39.880
Perhaps these peaks
were a bit higher

00:25:39.880 --> 00:25:43.840
for Reddit and Wikipedia.

00:25:43.840 --> 00:25:51.030
So maybe this is showing
that social media was

00:25:51.030 --> 00:25:53.670
more devoted to Bernie Sanders.

00:25:53.670 --> 00:25:56.590
And then certainly,
this Reddit line

00:25:56.590 --> 00:26:01.920
has stayed higher for most of
the timeframe that we have.

00:26:01.920 --> 00:26:02.670
FELIPE HOFFA: Yes.

00:26:02.670 --> 00:26:06.430
It seems that people really
enjoy when we mentioned Reddit.

00:26:06.430 --> 00:26:07.670
Yes?

00:26:07.670 --> 00:26:11.310
Let's look at what people
are talking in Reddit about.

00:26:11.310 --> 00:26:13.689
Are they talking about
Clinton, Sanders, Trump?

00:26:13.689 --> 00:26:14.730
JORDAN TIGANI: All right.

00:26:14.730 --> 00:26:19.570
So we'll basically look
over all comments in Reddit

00:26:19.570 --> 00:26:28.650
and run a query that figures out
how many authors are commenting

00:26:28.650 --> 00:26:31.510
about these candidates.

00:26:31.510 --> 00:26:33.750
And the query is not
all that interesting.

00:26:33.750 --> 00:26:35.790
Let me just see if--
yeah, we're just

00:26:35.790 --> 00:26:39.290
filtering by the phrases Donald
Trump, Hillary Clinton, Bernie

00:26:39.290 --> 00:26:41.400
Sanders.

00:26:41.400 --> 00:26:46.540
And then we can see what
the timeline looks like.

00:26:46.540 --> 00:26:48.410
FELIPE HOFFA: So we
can see that there

00:26:48.410 --> 00:26:52.460
are more authors talking about
Bernie Sanders than Trump,

00:26:52.460 --> 00:26:54.137
than Clinton.

00:26:54.137 --> 00:26:55.470
And that's just how Reddit goes.

00:26:59.300 --> 00:27:03.070
JORDAN TIGANI: So not everybody
uses the full name Bernie

00:27:03.070 --> 00:27:04.369
Sanders.

00:27:04.369 --> 00:27:05.910
FELIPE HOFFA: That's
a good question.

00:27:05.910 --> 00:27:08.730
JORDAN TIGANI: So they could
just say Bernie, or Hillary,

00:27:08.730 --> 00:27:13.610
or-- I think just Trump.

00:27:13.610 --> 00:27:17.350
Even though the subreddit
for Donald Trump

00:27:17.350 --> 00:27:19.820
is called The Donald,
so maybe in that he gets

00:27:19.820 --> 00:27:21.420
called just Donald more often.

00:27:21.420 --> 00:27:24.560
But one of the nice things
about this in BigQuery

00:27:24.560 --> 00:27:28.080
is it's easy to
change your mind.

00:27:28.080 --> 00:27:31.670
It's easy to just run
a different query.

00:27:31.670 --> 00:27:34.224
And hopefully this
will be fast today.

00:27:34.224 --> 00:27:36.140
FELIPE HOFFA: How long
does it take to analyze

00:27:36.140 --> 00:27:37.854
all of Reddit comments?

00:27:37.854 --> 00:27:40.020
JORDAN TIGANI: So it should
take only a few seconds.

00:27:40.020 --> 00:27:40.520
But--

00:27:40.520 --> 00:27:43.160
FELIPE HOFFA: How
fast is our network?

00:27:43.160 --> 00:27:46.000
JORDAN TIGANI: I'm not going
blame it on the network today.

00:27:46.000 --> 00:27:49.110
I will own this.

00:27:49.110 --> 00:27:51.550
I'll switch back if it doesn't
finish in the next five

00:27:51.550 --> 00:27:52.980
seconds.

00:27:52.980 --> 00:27:55.230
Two-- all right.

00:27:55.230 --> 00:27:57.510
We can jump to something else.

00:27:57.510 --> 00:27:58.960
Here we go!

00:27:58.960 --> 00:27:59.700
Five seconds.

00:27:59.700 --> 00:28:00.950
It knew.

00:28:00.950 --> 00:28:03.720
So it looks about
the same, actually.

00:28:03.720 --> 00:28:07.400
But I think the numbers
are much higher.

00:28:07.400 --> 00:28:11.160
FELIPE HOFFA: 56,000
authors talking about Trump?

00:28:11.160 --> 00:28:12.540
That's a lot of Redditors.

00:28:12.540 --> 00:28:15.980
But then it's hard to know if
they are talking positively

00:28:15.980 --> 00:28:17.890
about Trump, negatively.

00:28:17.890 --> 00:28:19.422
But there are some
subreddits that

00:28:19.422 --> 00:28:20.797
are dedicated to
each candidate--

00:28:20.797 --> 00:28:24.620
Sanders for President, The
Donald, Hillary Clinton.

00:28:24.620 --> 00:28:27.540
Each has their own
group of subredditors

00:28:27.540 --> 00:28:32.137
that have different
behaviors, different likes.

00:28:32.137 --> 00:28:33.970
And a very interesting
question I have there

00:28:33.970 --> 00:28:38.790
is, where were the
supporters four years ago

00:28:38.790 --> 00:28:40.200
for the previous election?

00:28:40.200 --> 00:28:42.283
JORDAN TIGANI: So what we
can do is, for this one,

00:28:42.283 --> 00:28:44.200
we're going to look
at the subreddits that

00:28:44.200 --> 00:28:47.810
are devoted, the Reddit
spaces that are devoted

00:28:47.810 --> 00:28:49.960
to particular candidates.

00:28:49.960 --> 00:28:54.150
In this case, it's Sanders
for President, The Donald,

00:28:54.150 --> 00:28:56.450
and Hillary Clinton.

00:28:56.450 --> 00:29:00.680
And then we're going to
join it against history.

00:29:00.680 --> 00:29:03.430
So we're pulling out authors.

00:29:03.430 --> 00:29:05.365
And they we're joining
against history

00:29:05.365 --> 00:29:07.240
to figure out, what are
these authors posting

00:29:07.240 --> 00:29:09.660
in four years ago, in 2012?

00:29:09.660 --> 00:29:13.560
What were they up to before they
started talking about politics?

00:29:13.560 --> 00:29:14.673
FELIPE HOFFA: Any guess?

00:29:14.673 --> 00:29:15.548
AUDIENCE: [INAUDIBLE]

00:29:20.734 --> 00:29:22.400
JORDAN TIGANI: So the
Sanders supporters

00:29:22.400 --> 00:29:25.490
were talking about space
and Occupy Wall Street.

00:29:25.490 --> 00:29:28.390
Occupy Wall Street
kind of makes sense.

00:29:28.390 --> 00:29:32.685
Trump supporters were talking
about guns and Ron Paul.

00:29:32.685 --> 00:29:34.989
[LAUGHTER]

00:29:34.989 --> 00:29:36.780
And I think there's
one that's interesting,

00:29:36.780 --> 00:29:39.520
is then the Hillary supporters
are basically Enough Ron Paul.

00:29:39.520 --> 00:29:41.200
They had it with Ron Paul.

00:29:41.200 --> 00:29:46.830
So I think it was already
setting up the Hillary versus

00:29:46.830 --> 00:29:49.182
Donald for the [INAUDIBLE].

00:29:49.182 --> 00:29:51.390
FELIPE HOFFA: I love being
able to find these things.

00:29:51.390 --> 00:29:53.270
[CHEERS AND APPLAUSE]

00:29:55.620 --> 00:29:57.670
Thank you.

00:29:57.670 --> 00:29:59.060
Back to real time.

00:29:59.060 --> 00:30:01.030
Back to what's
happening right now.

00:30:01.030 --> 00:30:02.810
Last 60 seconds.

00:30:02.810 --> 00:30:04.660
What are people
talking about now?

00:30:04.660 --> 00:30:06.020
JORDAN TIGANI: All right.

00:30:06.020 --> 00:30:08.060
So actually in
the last campaign,

00:30:08.060 --> 00:30:11.540
one of the things that the
candidates really started doing

00:30:11.540 --> 00:30:13.840
is they started monitoring
Twitter in real time.

00:30:13.840 --> 00:30:18.782
So they would notice, hey, the
candidate made a statement.

00:30:18.782 --> 00:30:19.990
What did Twitter think of it?

00:30:19.990 --> 00:30:22.599
And they could use that
to shape their message

00:30:22.599 --> 00:30:24.140
and how their message
was getting out

00:30:24.140 --> 00:30:25.300
to their supporters.

00:30:25.300 --> 00:30:28.670
So we have a Twitter feed
that is running a Google Cloud

00:30:28.670 --> 00:30:29.770
Dataflow.

00:30:29.770 --> 00:30:33.240
And we're pulling out anything
that mentions the candidates.

00:30:33.240 --> 00:30:35.380
And we're writing
it to two places.

00:30:35.380 --> 00:30:37.359
One is we're streaming
into a BigQuery table.

00:30:37.359 --> 00:30:38.900
And the other one
is we're writing it

00:30:38.900 --> 00:30:41.840
to the Cloud pub/sub.

00:30:41.840 --> 00:30:46.960
And I'm going to jump to-- we
have a really simple server

00:30:46.960 --> 00:30:50.640
that is in JavaScript--
only 100 lines of code--

00:30:50.640 --> 00:31:01.660
that's going to
read from pub/sub.

00:31:01.660 --> 00:31:04.000
And it's going to
write it to Firebase.

00:31:04.000 --> 00:31:07.400
And this is just sort of
the logging of the IDs

00:31:07.400 --> 00:31:10.180
of these Tweets, but so
really, really simple.

00:31:10.180 --> 00:31:15.860
We also have a
very small website

00:31:15.860 --> 00:31:18.860
that's going to create
a dashboard for us.

00:31:24.720 --> 00:31:26.830
And we'll allow that.

00:31:26.830 --> 00:31:29.970
So let me jump back to--

00:31:29.970 --> 00:31:32.520
So here's the
Firebase output here.

00:31:32.520 --> 00:31:37.750
We can see that
we're writing tweets.

00:31:37.750 --> 00:31:39.130
And then here's our dashboard.

00:31:39.130 --> 00:31:42.040
So the dashboard is basically
just pulling up the latest

00:31:42.040 --> 00:31:44.830
tweet and displaying it here.

00:31:44.830 --> 00:31:50.250
And we can also see the
hashtags that show up

00:31:50.250 --> 00:31:52.130
most often with the candidates.

00:31:52.130 --> 00:31:52.880
FELIPE HOFFA: Yes.

00:31:52.880 --> 00:31:55.980
We have no idea what tweets
are being shown in real time.

00:31:55.980 --> 00:31:57.215
So fingers crossed.

00:31:57.215 --> 00:31:58.840
JORDAN TIGANI: So
it's always dangerous

00:31:58.840 --> 00:32:02.152
when you try to show social
media in real time in a talk

00:32:02.152 --> 00:32:02.790
because--

00:32:02.790 --> 00:32:05.475
[LAUGHTER]

00:32:05.475 --> 00:32:07.660
I won't even fill in the
rest of that statement.

00:32:07.660 --> 00:32:09.290
FELIPE HOFFA: And what
kind of interesting things

00:32:09.290 --> 00:32:10.456
can we do with these tweets?

00:32:13.950 --> 00:32:16.000
JORDAN TIGANI: I mentioned
that the candidates

00:32:16.000 --> 00:32:17.650
were using this in real time.

00:32:20.191 --> 00:32:22.690
And so let's just look at the
things that have been tweeted,

00:32:22.690 --> 00:32:25.320
the tweets that have been
done since this talk started.

00:32:25.320 --> 00:32:29.980
So it's been about 30 minutes
since we have been here.

00:32:29.980 --> 00:32:35.210
And so we can see that
there's been 31,000 tweets.

00:32:35.210 --> 00:32:38.530
But that's not really
that impressive.

00:32:38.530 --> 00:32:40.670
30 minutes is a long time.

00:32:40.670 --> 00:32:43.840
So let's look at seconds.

00:32:43.840 --> 00:32:44.930
FELIPE HOFFA: Second.

00:32:44.930 --> 00:32:47.112
JORDAN TIGANI: Ah, thank you.

00:32:47.112 --> 00:32:48.070
I'm an over-pluralizer.

00:32:50.740 --> 00:32:52.500
What about the last 10 seconds?

00:32:52.500 --> 00:32:55.600
How many tweets were
in the last 10 seconds?

00:32:55.600 --> 00:32:58.352
Boom, so we have 45 tweets
in the last 10 seconds

00:32:58.352 --> 00:32:59.560
that are already in BigQuery.

00:32:59.560 --> 00:33:02.260
So this is from the time
when somebody posted this,

00:33:02.260 --> 00:33:03.990
they hit Send on Twitter.

00:33:03.990 --> 00:33:05.700
It's gone through
the Twitter API.

00:33:05.700 --> 00:33:07.370
It's gone to pub/sub.

00:33:07.370 --> 00:33:11.032
And then it's gone
through Dataflow.

00:33:11.032 --> 00:33:12.240
And it's going into BigQuery.

00:33:12.240 --> 00:33:14.236
And it's immediately query-able.

00:33:14.236 --> 00:33:15.352
FELIPE HOFFA: Wow.

00:33:15.352 --> 00:33:16.810
JORDAN TIGANI: So
let's try to look

00:33:16.810 --> 00:33:20.040
at something like what the
candidates would want to do.

00:33:20.040 --> 00:33:24.955
So I'm going to jump
back to Re:dash.

00:33:24.955 --> 00:33:30.870
And so we're going to look at
the hashtags of things that

00:33:30.870 --> 00:33:32.759
have been happening in
the last hour, things

00:33:32.759 --> 00:33:34.300
that people have
been tweeting about,

00:33:34.300 --> 00:33:36.360
that are in tweets
about the candidates.

00:33:36.360 --> 00:33:40.280
And we're going to look and see
how that compares to yesterday.

00:33:40.280 --> 00:33:45.810
So this will hopefully
show us what's

00:33:45.810 --> 00:33:50.150
new, what things are trending
that weren't here yesterday.

00:33:50.150 --> 00:33:52.960
So here is what we have.

00:33:52.960 --> 00:33:59.880
We have people tweeting about
Trump and the second amendment,

00:33:59.880 --> 00:34:00.715
but also Bernie.

00:34:00.715 --> 00:34:01.840
That's sort of interesting.

00:34:01.840 --> 00:34:04.261
I wonder if there was
some news about that.

00:34:04.261 --> 00:34:06.470
FELIPE HOFFA: That's Clinton.

00:34:06.470 --> 00:34:09.060
JORDAN TIGANI: What
interesting Clinton things?

00:34:09.060 --> 00:34:13.450
Probably can't say
some of them on--

00:34:13.450 --> 00:34:14.949
FELIPE HOFFA: Real
time data, sorry.

00:34:14.949 --> 00:34:19.469
JORDAN TIGANI: Adopt-a-palooza,
that's-- anyway.

00:34:19.469 --> 00:34:23.754
So yeah, real time.

00:34:23.754 --> 00:34:25.170
FELIPE HOFFA: Yes,
real time data.

00:34:25.170 --> 00:34:28.820
JORDAN TIGANI: Social media
is always, always interesting.

00:34:28.820 --> 00:34:31.292
FELIPE HOFFA: So we have
about nine minutes left.

00:34:31.292 --> 00:34:32.310
Are we going to do this?

00:34:38.159 --> 00:34:38.945
Are we?

00:34:38.945 --> 00:34:44.820
JORDAN TIGANI:
Unfortunately-- we could,

00:34:44.820 --> 00:34:48.698
but we are not going to
predict the next president.

00:34:48.698 --> 00:34:50.239
But we didn't want
to get out of here

00:34:50.239 --> 00:34:52.560
without showing some prediction.

00:34:52.560 --> 00:34:56.639
After all, we did a reasonably
good job of that last time.

00:34:56.639 --> 00:34:59.345
And Google has
these amazing tools

00:34:59.345 --> 00:35:00.720
that you've probably
been hearing

00:35:00.720 --> 00:35:05.614
about the last few days,
TensorFlow and Cloud Datalab.

00:35:05.614 --> 00:35:07.030
FELIPE HOFFA: Those
are our tools.

00:35:07.030 --> 00:35:10.750
TensorFlow, an open source
tool to run machine learning

00:35:10.750 --> 00:35:11.470
algorithms.

00:35:11.470 --> 00:35:15.700
Datalab, a pretty nice open
source notebook environment

00:35:15.700 --> 00:35:18.860
to mix all of our
elements together.

00:35:18.860 --> 00:35:23.190
So we're going to try to
predict who said what?

00:35:23.190 --> 00:35:26.465
JORDAN TIGANI: That seems
like the safer thing to do.

00:35:26.465 --> 00:35:28.520
FELIPE HOFFA: "Safer."

00:35:28.520 --> 00:35:33.600
JORDAN TIGANI: So I'm going to
look at the data that we have.

00:35:33.600 --> 00:35:38.850
And so we've gathered
some statements

00:35:38.850 --> 00:35:41.100
from various candidates.

00:35:45.840 --> 00:35:47.970
It's not a whole lot of data.

00:35:47.970 --> 00:35:50.820
So we're going to build
a machine-learning model

00:35:50.820 --> 00:35:56.180
with only 200K of data.

00:35:56.180 --> 00:35:58.090
And I'll show you
what these look like.

00:35:58.090 --> 00:36:00.360
These are just statements
that various candidates

00:36:00.360 --> 00:36:02.900
have said that we've
collected from the media.

00:36:05.900 --> 00:36:07.200
And we're going to use this.

00:36:07.200 --> 00:36:14.260
And we're going to feed it
into a machine-learning model.

00:36:14.260 --> 00:36:17.270
I'm going to build the
model while I'm talking.

00:36:17.270 --> 00:36:22.430
So let me just run to this cell.

00:36:25.590 --> 00:36:28.160
So this is Google Cloud Datalab.

00:36:28.160 --> 00:36:32.880
This is the the iPython
or Jupiter notebook

00:36:32.880 --> 00:36:35.440
for doing scientific computing.

00:36:35.440 --> 00:36:37.829
And it has nice integration
with TensorFlow.

00:36:37.829 --> 00:36:40.120
So this seems like a lot of
code, but most of this code

00:36:40.120 --> 00:36:44.830
actually is just
manipulating the text.

00:36:44.830 --> 00:36:50.590
So we're pulling this data
out of Google Cloud Storage.

00:36:50.590 --> 00:36:53.872
And then we're
reading the data files

00:36:53.872 --> 00:36:55.080
and splitting the data files.

00:36:55.080 --> 00:36:57.560
That's actually
most of the code.

00:36:57.560 --> 00:36:59.500
So this is really all
the TensorFlow code

00:36:59.500 --> 00:37:01.620
that we need to do this.

00:37:01.620 --> 00:37:05.560
Most of it is just
setting up outputs,

00:37:05.560 --> 00:37:09.020
setting up what it
means to be right,

00:37:09.020 --> 00:37:12.140
or we're trying to minimize
or maximize-- in this case,

00:37:12.140 --> 00:37:13.610
it's the cross entropy.

00:37:13.610 --> 00:37:17.740
And we're going to use an Ftrl
optimizer, which doesn't really

00:37:17.740 --> 00:37:19.040
matter what that means.

00:37:19.040 --> 00:37:23.610
It's an algorithm that's
used in Google for ads.

00:37:23.610 --> 00:37:27.200
And it also has-- I
mean, you can essentially

00:37:27.200 --> 00:37:29.260
use a lot of different
optimizers here.

00:37:29.260 --> 00:37:31.480
But this one this one
works out pretty well.

00:37:31.480 --> 00:37:33.563
And then we're going to
minimize the cross entropy

00:37:33.563 --> 00:37:35.850
if we want to get,
basically, as close as

00:37:35.850 --> 00:37:38.350
possible to the correct results.

00:37:38.350 --> 00:37:42.240
And then this loop here
just runs the training.

00:37:42.240 --> 00:37:48.860
So we can see the output of the
accuracy of this is about 72%.

00:37:48.860 --> 00:37:50.810
So that may not
seem all that high.

00:37:50.810 --> 00:37:54.610
But if you consider that
we had a human actually

00:37:54.610 --> 00:37:58.390
try to figure out how well they
could do at categorizing these.

00:37:58.390 --> 00:38:00.520
And the human only
got about 60%.

00:38:00.520 --> 00:38:02.970
So we built a model
that can do better

00:38:02.970 --> 00:38:08.501
than a human at identifying
these statements.

00:38:08.501 --> 00:38:09.000
All right.

00:38:09.000 --> 00:38:12.840
So now I have some quotes
from the various candidates.

00:38:12.840 --> 00:38:15.160
And we can run
this model and see

00:38:15.160 --> 00:38:18.170
if we can predict what
they're actually saying.

00:38:18.170 --> 00:38:22.502
And these quotes were not
part of the training set.

00:38:22.502 --> 00:38:23.960
And so these are
things, basically,

00:38:23.960 --> 00:38:24.960
just from their website.

00:38:24.960 --> 00:38:28.040
So let's see-- lovely.

00:38:28.040 --> 00:38:28.540
There we go.

00:38:32.260 --> 00:38:37.531
So predicted Clinton,
actually Clinton.

00:38:37.531 --> 00:38:40.030
FELIPE HOFFA: We will totally
dismantle Iran's global terror

00:38:40.030 --> 00:38:40.530
network.

00:38:42.732 --> 00:38:43.690
TensorFlow [INAUDIBLE].

00:38:46.384 --> 00:38:48.550
What my campaign is about
is a political revolution.

00:38:48.550 --> 00:38:50.190
Millions of people are
standing up and saying,

00:38:50.190 --> 00:38:50.830
enough is enough.

00:38:50.830 --> 00:38:52.288
Our government
belongs to all of us

00:38:52.288 --> 00:38:54.310
and not just a handful
of billionaires.

00:38:54.310 --> 00:38:55.560
Who said that?

00:38:55.560 --> 00:38:56.810
JORDAN TIGANI: Bernie Sanders.

00:38:56.810 --> 00:38:59.110
FELIPE HOFFA: It knows.

00:38:59.110 --> 00:39:01.050
You can read the Cruz one.

00:39:01.050 --> 00:39:02.841
JORDAN TIGANI: We need
a commander-in-chief

00:39:02.841 --> 00:39:05.380
who will prioritize US
national security interests.

00:39:05.380 --> 00:39:08.430
And that one was Ted Cruz.

00:39:08.430 --> 00:39:10.100
FELIPE HOFFA: And
that's pretty good.

00:39:10.100 --> 00:39:11.200
JORDAN TIGANI: So
here's something

00:39:11.200 --> 00:39:13.033
that I don't think any
candidates have said.

00:39:15.844 --> 00:39:19.810
FELIPE HOFFA: Trying something
that they never said.

00:39:19.810 --> 00:39:25.570
JORDAN TIGANI: But does
anybody have a suggestion

00:39:25.570 --> 00:39:28.910
of a statement they want us to
try to guess which candidate

00:39:28.910 --> 00:39:30.675
would be more likely to say it?

00:39:30.675 --> 00:39:32.300
FELIPE HOFFA: Any
random statement?

00:39:32.300 --> 00:39:33.220
Just to try it out?

00:39:33.220 --> 00:39:34.137
JORDAN TIGANI: Anyone?

00:39:34.137 --> 00:39:35.386
AUDIENCE: TensorFlow is great.

00:39:35.386 --> 00:39:36.200
We love TensorFlow.

00:39:36.200 --> 00:39:37.664
JORDAN TIGANI: OK.

00:39:37.664 --> 00:39:51.155
[LAUGHTER]

00:39:51.155 --> 00:39:52.530
FELIPE HOFFA: We
love TensorFlow.

00:39:56.980 --> 00:39:59.070
OK, we're running
out of time now.

00:39:59.070 --> 00:40:01.480
JORDAN TIGANI: Yes.

00:40:01.480 --> 00:40:03.320
FELIPE HOFFA: Time
to close this talk.

00:40:03.320 --> 00:40:05.930
I hope you were entertained.

00:40:05.930 --> 00:40:08.300
But this is not only
about data, not only

00:40:08.300 --> 00:40:11.630
about how we analyze
and entertain ourselves,

00:40:11.630 --> 00:40:13.770
is how we use the
different Google Cloud

00:40:13.770 --> 00:40:18.240
tools-- TensorFlow, Datalab,
BigQuery, of course--

00:40:18.240 --> 00:40:20.150
and how we connect
different data sets,

00:40:20.150 --> 00:40:23.530
how we draw lines
between these points.

00:40:23.530 --> 00:40:27.360
Take these tools and bring
them to our world, how

00:40:27.360 --> 00:40:31.800
we can change where we live?

00:40:31.800 --> 00:40:33.660
We can vote, to start with.

00:40:33.660 --> 00:40:34.870
Well, not everyone can vote.

00:40:34.870 --> 00:40:40.521
But we still can be
part of the process.

00:40:40.521 --> 00:40:43.020
JORDAN TIGANI: And, you know,
these elections are important.

00:40:43.020 --> 00:40:45.300
And we hope that these
tools that we built

00:40:45.300 --> 00:40:47.450
will inspire you to
say, hey, I can do that.

00:40:47.450 --> 00:40:49.090
That's easy.

00:40:49.090 --> 00:40:52.150
Inspire you to actually
go out, and try them,

00:40:52.150 --> 00:40:53.980
and change the world.

00:40:53.980 --> 00:40:55.310
FELIPE HOFFA: Yes.

00:40:55.310 --> 00:40:58.180
And thank you to everyone
that helped us run

00:40:58.180 --> 00:41:01.360
these demos, Reddit, Twitter.

00:41:01.360 --> 00:41:03.690
JORDAN TIGANI: We had
from the Dataflow team,

00:41:03.690 --> 00:41:07.120
Sam [? McVeedy ?], [? Sarah ?]
Robinson helped with

00:41:07.120 --> 00:41:07.990
the Firebase.

00:41:07.990 --> 00:41:10.292
[INAUDIBLE] team helped
with the TensorFlow.

00:41:10.292 --> 00:41:12.000
Lots of people we're
probably forgetting.

00:41:12.000 --> 00:41:12.760
FELIPE HOFFA: Yes,
Re:dash, also, yes.

00:41:12.760 --> 00:41:14.426
JORDAN TIGANI: Re:dash, yes.

00:41:14.426 --> 00:41:15.175
FELIPE HOFFA: Yes.

00:41:15.175 --> 00:41:17.380
A big thanks to
developer advocates,

00:41:17.380 --> 00:41:19.150
everyone that makes I/O happen.

00:41:19.150 --> 00:41:21.900
And if nothing else
works, there are so

00:41:21.900 --> 00:41:23.140
many other things we can do.

00:41:23.140 --> 00:41:27.110
We can be back in two years to
talk about the World Cup again.

00:41:27.110 --> 00:41:28.400
Thank you very much.

00:41:28.400 --> 00:41:29.441
JORDAN TIGANI: Thank you.

00:41:29.441 --> 00:41:31.150
[APPLAUSE]

