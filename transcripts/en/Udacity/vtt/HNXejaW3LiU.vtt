WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:02.969
Here's what I like to do. You pointed out some issues that you

00:00:02.969 --> 00:00:05.790
were concerned about and I thought that maybe you could go and look into

00:00:05.790 --> 00:00:08.430
it a bit more and you did. And so why don't I turn

00:00:08.430 --> 00:00:10.940
things over to you so that you can tell us what you've found out.

00:00:10.940 --> 00:00:13.300
&gt;&gt; Okay, well thank you Michael. Hi again.

00:00:13.300 --> 00:00:13.940
&gt;&gt; Hi.

00:00:13.940 --> 00:00:18.050
&gt;&gt; Thank you Michael. So I did go and I started

00:00:18.050 --> 00:00:20.214
trying to deal with these issues. So just to recap a

00:00:20.214 --> 00:00:22.720
little bit, there were two problems that I had, more or

00:00:22.720 --> 00:00:26.020
less. And they were, that we had all these cool little randomized

00:00:26.020 --> 00:00:29.300
optimization algorithms. And, most of them seemed to share this property

00:00:29.300 --> 00:00:32.820
that the only thing that really happened over time, is you started

00:00:32.820 --> 00:00:34.960
out with some point and you ended up with some point,

00:00:34.960 --> 00:00:37.830
which was supposed to be, you know, the optimal point. And the

00:00:37.830 --> 00:00:41.520
only difference between the first point, and the last point that

00:00:41.520 --> 00:00:43.870
you did or, the one millionth point or however how many you

00:00:43.870 --> 00:00:46.670
iterations you had, is that, that point might have been closer

00:00:46.670 --> 00:00:51.210
to the optimum by some measure. And very little structure was actually

00:00:51.210 --> 00:00:53.870
being kept around or communicated. Only the point was being

00:00:53.870 --> 00:00:56.280
communicated. Now you could argue that that isn't quite true with

00:00:56.280 --> 00:00:59.000
genetic algorithms, but really you move from a single point

00:00:59.000 --> 00:01:02.310
to just a few points. The other problem that I had

00:01:02.310 --> 00:01:05.040
is that we had all of this sort of probability

00:01:05.040 --> 00:01:08.530
theory that was underneath what we were doing, all this randomization.

00:01:08.530 --> 00:01:10.770
But somehow it wasn't at all clear in most of

00:01:10.770 --> 00:01:16.320
the cases, exactly what probability distribution we were dealing with. Now,

00:01:16.320 --> 00:01:18.194
one thing I really liked about some [UNKNOWN]

00:01:18.194 --> 00:01:19.630
is that you were very clear about what

00:01:19.630 --> 00:01:23.140
the probability distribution was. So what I decided to do is to go out there in

00:01:23.140 --> 00:01:27.910
the world and see if I could find maybe a class of algorithms that took care

00:01:27.910 --> 00:01:30.420
of these two points for us. And I

00:01:30.420 --> 00:01:33.820
found something, you'll be very happy hear, Michael.

00:01:33.820 --> 00:01:35.590
&gt;&gt; Yeah, I would love to, to find out what it is.

00:01:35.590 --> 00:01:39.310
&gt;&gt; It turns out that I wrote a paper about this, almost 20 years ago.

00:01:39.310 --> 00:01:40.740
&gt;&gt; [LAUGH] How did you find that?

00:01:40.740 --> 00:01:41.480
&gt;&gt; I just

00:01:41.480 --> 00:01:43.350
said, well if I wanted to start looking someplace,

00:01:43.350 --> 00:01:45.476
I should look at home first. And I stumbled across

00:01:45.476 --> 00:01:45.556
&gt;&gt; Oh.

00:01:45.556 --> 00:01:46.280
&gt;&gt; this paper that I wrote.

00:01:46.280 --> 00:01:49.500
&gt;&gt; I see, I see. So learning about machine learning, really begins at home.

00:01:49.500 --> 00:01:51.550
&gt;&gt; That's exactly right. So, I had to

00:01:51.550 --> 00:01:53.454
re-read the paper because, you know, it is

00:01:53.454 --> 00:01:57.510
a coupl of decades old. And I will point that a lot of other work has been

00:01:57.510 --> 00:02:00.170
done since this that refines on these ideas.

00:02:00.170 --> 00:02:01.800
But, this is fairly straightforward and simple, so,

00:02:01.800 --> 00:02:03.380
I think I am just going to stick with

00:02:03.380 --> 00:02:06.790
this work. And the paper's available for everyone listening

00:02:06.790 --> 00:02:10.130
this to right now or watching this right now. So you can read it and

00:02:10.130 --> 00:02:13.130
all of it's gory details. But I just want to go over the, the high level bit

00:02:13.130 --> 00:02:14.900
here because I, I, I really think it

00:02:14.900 --> 00:02:18.010
kind of gets at this idea. So, in particular,

00:02:18.010 --> 00:02:19.970
the paper that I'm talking about introduced an

00:02:19.970 --> 00:02:22.740
algorithm called Mimic, which actually stands for something,

00:02:24.980 --> 00:02:28.820
though I forget what. And it really had a very simple structure

00:02:28.820 --> 00:02:34.370
to it. The basic idea was to directly model a probability distribution.

00:02:34.370 --> 00:02:35.600
&gt;&gt; Probability distribution of what?

00:02:35.600 --> 00:02:38.530
&gt;&gt; Well, I'll tell you. And, you know, like I said,

00:02:38.530 --> 00:02:42.430
Michael, I will, define exactly what this, probability distribution is for you

00:02:42.430 --> 00:02:45.280
for a second and, and hopefully you'll, you'll buy that it seems

00:02:45.280 --> 00:02:50.400
like a reasonable distribution to model. And given that you have this,

00:02:50.400 --> 00:02:53.380
probability distribution that you're directly modeling, the, the goal

00:02:53.380 --> 00:02:55.220
is to do this sort of search through space, just

00:02:55.220 --> 00:02:56.350
like we did with all the rest of these

00:02:56.350 --> 00:03:01.000
algorithms. And to successfully refine the estimate of that distribution.

00:03:01.000 --> 00:03:02.575
&gt;&gt; Hm.

00:03:02.575 --> 00:03:04.960
&gt;&gt; And the idea is that if you can directly model this

00:03:04.960 --> 00:03:09.710
distribution and refine it over time that, that will in fact convey structure.

00:03:09.710 --> 00:03:12.245
&gt;&gt; Structure in particular of what were learning

00:03:12.245 --> 00:03:15.510
about the search space while we're doing the search.

00:03:15.510 --> 00:03:17.900
&gt;&gt; Exactly, and not just simply the structure of the

00:03:17.900 --> 00:03:20.100
search space, but the structure of the parts of the

00:03:20.100 --> 00:03:22.900
space that represent good points or points that are more

00:03:22.900 --> 00:03:26.400
optimal than others. Yeah, that seems like a really useful thing.

00:03:26.400 --> 00:03:29.700
&gt;&gt; So I'm just going to give you, again, this, this simple mimic algorithm

00:03:29.700 --> 00:03:31.240
that, that sort of captures these basic

00:03:31.240 --> 00:03:32.930
ideas, because I think it's fairly simple

00:03:32.930 --> 00:03:34.860
and easy to understand, while still getting

00:03:34.860 --> 00:03:36.630
some of the underlying issues. But do

00:03:36.630 --> 00:03:38.220
keep in mind that there's been literally

00:03:38.220 --> 00:03:41.440
decades of work since then, and optimization

00:03:41.440 --> 00:03:44.240
space where people have really taken these kinds of ideas and

00:03:44.240 --> 00:03:47.810
refined them to be sort of much more mathematically precise. But this,

00:03:47.810 --> 00:03:49.920
I think, does get the idea across, and I happen to

00:03:49.920 --> 00:03:51.630
understand it, so I thought that I would share it with you.

00:03:51.630 --> 00:03:51.920
&gt;&gt; Hm.

00:03:51.920 --> 00:03:52.290
&gt;&gt; Seem fair?

00:03:52.290 --> 00:03:53.550
&gt;&gt; Yeah, that sounds really exciting.

00:03:53.550 --> 00:03:54.390
&gt;&gt; Excellent.

