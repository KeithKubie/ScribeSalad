WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.000
I want to talk for a moment about how to scale databases.

00:00:03.000 --> 00:00:07.000
Now, like databases themselves, this is a very broad topic,

00:00:07.000 --> 00:00:09.000
but there's a couple concepts I'd like to introduce

00:00:09.000 --> 00:00:11.000
because they're going to affect us in this class.

00:00:11.000 --> 00:00:13.000
There's two reasons you might need to scale a database.

00:00:13.000 --> 00:00:16.000
One is too much load,

00:00:16.000 --> 00:00:19.000
as in a database that's just doing too much work.

00:00:19.000 --> 00:00:22.000
You've got some website that is getting

00:00:22.000 --> 00:00:25.000
millions of requests a day--thousands of requests a second--

00:00:25.000 --> 00:00:28.000
and you've got this one machine that's got your data on it

00:00:28.000 --> 00:00:30.000
and it just can't keep up with all the work.

00:00:30.000 --> 00:00:33.000
So what you might do in this case is take your database--

00:00:33.000 --> 00:00:36.000
which are often represented as little cynlinders--

00:00:36.000 --> 00:00:39.000
and replicate it to other databases.

00:00:39.000 --> 00:00:44.000
So every time we insert a piece of data to this database,

00:00:44.000 --> 00:00:47.000
we send it over to the other guys.

00:00:47.000 --> 00:00:50.000
So all of our database writes go into this one master database.

00:00:50.000 --> 00:00:55.000
In turn, all of that data gets replicated to these slave databases.

00:00:55.000 --> 00:00:58.000
So now we have 3 databases with all of our data on it,

00:00:58.000 --> 00:01:03.000
and so if you've got a site like Reddit that's getting thousands and thousands of requests a second,

00:01:03.000 --> 00:01:06.000
instead of sending all of the database reads--

00:01:06.000 --> 00:01:09.000
all the lookups--to this database,

00:01:09.000 --> 00:01:12.000
we can send it to these databases.

00:01:12.000 --> 00:01:15.000
And that alleviates a lot of this load off of this master database.

00:01:15.000 --> 00:01:18.000
Now, there are much more complicated schemes

00:01:18.000 --> 00:01:21.000
where you might have a multi-master system

00:01:21.000 --> 00:01:26.000
or a bunch of databases that are all working together,

00:01:26.000 --> 00:01:29.000
but this is a fairly common setup

00:01:29.000 --> 00:01:32.000
and a fairly common approach to spreading around the read.

00:01:32.000 --> 00:01:35.000
Because generally in most systems you have a lot more reads

00:01:35.000 --> 00:01:37.000
than you do writes.

00:01:37.000 --> 00:01:39.000
So if your master can keep up with all of the writes,

00:01:39.000 --> 00:01:41.000
your slaves can handle all of the reads.

00:01:41.000 --> 00:01:43.000
There are some downsides to this.

00:01:43.000 --> 00:01:46.000
One is that it doesn't increase the speed of writes.

00:01:46.000 --> 00:01:49.000
We're still bottlenecked by this master receiving all this data,

00:01:49.000 --> 00:01:52.000
who in turn has to send it to all these slaves.

00:01:52.000 --> 00:01:55.000
So if we can still fit all our writes on this one machine, we're in good shape

00:01:55.000 --> 00:01:58.000
and we can spread the reads over as many machines as we need.

00:01:58.000 --> 00:02:01.000
Some of these slaves can even replicate the other machines.

00:02:01.000 --> 00:02:05.000
Another downside is this notion of replication lag.

00:02:05.000 --> 00:02:09.000
And this occurs when you write a piece of data to the master

00:02:09.000 --> 00:02:13.000
but the read hits one of these slaves before the data has propagated,

00:02:13.000 --> 00:02:15.000
and that's called replication lag.

00:02:15.000 --> 00:02:17.000
You can sometimes get some funny behavior.

00:02:17.000 --> 00:02:20.000
And the reason I bring it up now is because in the database we'll be using in this class,

00:02:20.000 --> 00:02:24.000
you can occasionally see symptoms of this type of behavior.

00:02:24.000 --> 00:02:27.000
It's not necessarily owing to a master/slave setup,

00:02:27.000 --> 00:02:32.000
but this is the general concept.

00:02:32.000 --> 00:02:37.000
What happens if you have too much data for one machine?

00:02:37.000 --> 00:02:40.000
The replication handles the case

00:02:40.000 --> 00:02:42.000
where you have too much load.

00:02:42.000 --> 00:02:46.000
Basically, you've got to do too many reads, so you can replicate your database--scale this up.

00:02:46.000 --> 00:02:48.000
What if you just have too much data,

00:02:48.000 --> 00:02:51.000
your master database--or any one of these databases--can't even hold of your data,

00:02:51.000 --> 00:02:54.000
it doesn't fit in memory or even in disk,

00:02:54.000 --> 00:02:56.000
there's just too much?

00:02:56.000 --> 00:02:58.000
One of the things you can do is you can shard the database.

00:02:58.000 --> 00:03:01.000
This is a fairly simple approach, where instead of having one master

00:03:01.000 --> 00:03:04.000
you might have a couple that are all the same size, despite my drawing.

00:03:04.000 --> 00:03:06.000
So let's say we're storing our links database.

00:03:06.000 --> 00:03:10.000
One approach to shardding might be to store links 1-100 here--

00:03:10.000 --> 00:03:12.000
actually, more like 1-a billion here--

00:03:12.000 --> 00:03:15.000
and 101-200 here

00:03:15.000 --> 00:03:18.000
and 201-300 here,

00:03:18.000 --> 00:03:21.000
and basically you store some of your links here and some of your links here

00:03:21.000 --> 00:03:23.000
and some of your links here in this database.

00:03:23.000 --> 00:03:26.000
Obviously, 1-100 probably isn't the correct approach.

00:03:26.000 --> 00:03:29.000
You could probably use a hashing approach as if we had a hashtable

00:03:29.000 --> 00:03:32.000
and these were all cells in our hashtable

00:03:32.000 --> 00:03:34.000
and you hash on some particular key.

00:03:34.000 --> 00:03:39.000
In this case, I'm referring to link ids--the id of whatever you're storing--

00:03:39.000 --> 00:03:42.000
to figure out which database you want to store it in.

00:03:42.000 --> 00:03:45.000
This is cool because now

00:03:45.000 --> 00:03:48.000
if we triple our write load from this scenario over here,

00:03:48.000 --> 00:03:51.000
we have 3 database machines to handle it.

00:03:51.000 --> 00:03:54.000
Likewise, we already have 3 machines to handle the read load.

00:03:54.000 --> 00:03:57.000
And of course you can replicate these machines as well.

00:03:57.000 --> 00:04:00.000
A lot of systems both shard and replicate your machines

00:04:00.000 --> 00:04:03.000
if you really want to get fancy.

00:04:03.000 --> 00:04:06.000
But there are some downsides to shardding as well.

00:04:06.000 --> 00:04:09.000
One of the downsides is the queries get much more complex.

00:04:09.000 --> 00:04:12.000
What if I said that this helps the case

00:04:12.000 --> 00:04:15.000
of find me the link whose id is 150?

00:04:15.000 --> 00:04:18.000
We just say, okay, which does 150 go to?

00:04:18.000 --> 00:04:20.000
You know what hash is to this machine,

00:04:20.000 --> 00:04:22.000
and we do our read and that's that.

00:04:22.000 --> 00:04:26.000
What if I said get me all the links sorted by hotness, for example.

00:04:26.000 --> 00:04:29.000
Well, we don't know where that link may reside,

00:04:29.000 --> 00:04:31.000
especially if we're using a hashing algorithm

00:04:31.000 --> 00:04:34.000
that's more sophisticated than 1-100.

00:04:34.000 --> 00:04:36.000
That's called a range query,

00:04:36.000 --> 00:04:39.000
and a range query might have to hit all of your machines.

00:04:39.000 --> 00:04:44.000
Then we've lost one of our advantages to using this.

00:04:44.000 --> 00:04:47.000
Now, you could replicate these to spread that around,

00:04:47.000 --> 00:04:50.000
but you have to hit all these machines and then merge the results probably

00:04:50.000 --> 00:04:53.000
and do the sort again and memory.

00:04:53.000 --> 00:04:56.000
Some queries become very, very complex.

00:04:56.000 --> 00:05:00.000
Another downside is that joins become difficult or impossible.

00:05:00.000 --> 00:05:02.000
That makes sense.

00:05:02.000 --> 00:05:05.000
If we have this massive database that has multiple tables on it, we can do joints.

00:05:05.000 --> 00:05:08.000
But if we start shardding our database up--

00:05:08.000 --> 00:05:11.000
we have one database that doesn't even fit on one machine.

00:05:11.000 --> 00:05:13.000
So if we can't fit one database on our machine,

00:05:13.000 --> 00:05:15.000
how are we going to fit multiple databases?

00:05:15.000 --> 00:05:18.000
This notion that you have all of your tables in the same place to do a join--

00:05:18.000 --> 00:05:20.000
to do those fancy join SQL queries--

00:05:20.000 --> 00:05:22.000
becomes a lot more difficult.

00:05:22.000 --> 00:05:25.000
Now, there's a lot of research going on

00:05:25.000 --> 00:05:29.000
of building systems that can overcome these downsides,

00:05:29.000 --> 00:05:31.000
but if you take the naive approach to replicating and charting,

00:05:31.000 --> 00:05:34.000
these are some of the things you'll have to deal with.

00:05:34.000 --> 00:05:37.000
Generally the benefits outweigh the downsides,

00:05:37.000 --> 00:05:40.000
because if you design your data in such a way that you don't need to do joins

00:05:40.000 --> 00:05:43.000
or you don't need to do complex queries,

00:05:43.000 --> 00:05:46.000
you're in very good shape with both of these.

00:05:46.000 --> 00:05:49.000
Or maybe you have multiple setups--

00:05:49.000 --> 00:05:53.000
one setup for handling your general load and another setup for handling your complex queries.

00:05:53.000 --> 00:05:56.000
That's okay, and that's actually very common.

00:05:56.000 --> 00:05:58.000
Now, I wanted to introduce these concepts

00:05:58.000 --> 00:06:01.000
because the database we'll be using in this class--

00:06:01.000 --> 00:06:03.000
Google the App Engine Datastore--

00:06:03.000 --> 00:06:07.000
actually has some of these limitations.

00:06:07.000 --> 00:06:11.000
There are no joins allowed, even though it does provide a SQL interface.

00:06:11.000 --> 00:06:15.000
And a lot of more complex queries that you could do in a general SQL database,

00:06:15.000 --> 00:06:19.000
you can't do in Google Datastore, but that's okay.

00:06:19.000 --> 00:06:21.000
You get this really nice benefit of having a database

00:06:21.000 --> 00:06:26.000
that is shardded and replicated to wazoo and back.

00:06:26.000 --> 00:06:29.000
It's actually very fast and reliable.

00:06:29.000 --> 00:06:31.000
You're probably not going to have to worry about systems crashing.

00:06:31.000 --> 00:06:34.000
It's something that replicating a database can help with

00:06:34.000 --> 00:06:36.000
and shardding a database can help with.

00:06:36.000 --> 00:06:39.000
Okay, so I just wanted to introduce those concepts.

00:06:39.000 --> 00:06:42.000
Let's have a quick quiz on it before we move along.

00:06:42.000 --> 00:06:45.000
Which is an appropriate technique for increasing the read speed from a database?

00:06:45.000 --> 00:06:48.000
Get a faster machine. Replicate the database.

00:06:48.000 --> 00:06:52.000
Store less data. Or press the turbo button.

