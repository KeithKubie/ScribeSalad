WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:01.860
MALE SPEAKER: Hi, folks.

00:00:01.860 --> 00:00:03.400
Welcome to our
panel, "Breakthroughs

00:00:03.400 --> 00:00:06.230
in Machine Learning."
we've been talking a lot

00:00:06.230 --> 00:00:09.476
about Google's
long-term vision for AI

00:00:09.476 --> 00:00:10.850
and all the work
we've been doing

00:00:10.850 --> 00:00:15.520
for the past decade and a
half on machine learning.

00:00:15.520 --> 00:00:19.250
And this is important because
our users and your users

00:00:19.250 --> 00:00:20.770
expect the impossible.

00:00:20.770 --> 00:00:22.270
They want technology
that they can

00:00:22.270 --> 00:00:25.180
talk to naturally just the way
you would talk to a person.

00:00:25.180 --> 00:00:27.920
Obviously, not possible
today, but we're

00:00:27.920 --> 00:00:30.410
moving in that direction.

00:00:30.410 --> 00:00:32.490
And I think a point
that often gets missed

00:00:32.490 --> 00:00:34.190
is that Google
isn't just working

00:00:34.190 --> 00:00:37.650
on incremental improvements
to products using known

00:00:37.650 --> 00:00:39.250
machine learning techniques.

00:00:39.250 --> 00:00:42.680
We actually have teams
doing fundamental work

00:00:42.680 --> 00:00:45.272
on improving the state of
the art in machine learning.

00:00:45.272 --> 00:00:47.230
And they're working right
here in Mountain View

00:00:47.230 --> 00:00:50.239
and in our locations
around the world.

00:00:50.239 --> 00:00:52.280
So you're going to hear
from some of these folks.

00:00:52.280 --> 00:00:57.090
I think if you're also getting
your hands into the deep thick

00:00:57.090 --> 00:00:59.430
of things, and you're
working with TensorFlow,

00:00:59.430 --> 00:01:01.400
you're working on
machine learning models,

00:01:01.400 --> 00:01:03.560
you can maybe learn
something from the war

00:01:03.560 --> 00:01:07.000
stories, the challenges that
you hear they've gone through.

00:01:07.000 --> 00:01:08.750
If you're a developer
who just wants

00:01:08.750 --> 00:01:13.630
to use what they've packaged up
in the cloud machine learning

00:01:13.630 --> 00:01:17.180
APIs that we offer, you
can get a good sense

00:01:17.180 --> 00:01:19.920
of which things are working
well and how you might

00:01:19.920 --> 00:01:21.400
use these in your products.

00:01:21.400 --> 00:01:22.390
So I hope you enjoy it.

00:01:22.390 --> 00:01:24.075
We're going to start
with Francoise.

00:01:26.920 --> 00:01:28.880
[APPLAUSE]

00:01:32.512 --> 00:01:33.470
FRANCOISE BEAUFAYS: Hi.

00:01:33.470 --> 00:01:34.580
So my name is Francoise.

00:01:34.580 --> 00:01:36.680
I work on speech recognition.

00:01:36.680 --> 00:01:39.770
And I joined Google
about 10 years ago.

00:01:39.770 --> 00:01:43.310
And it may be hard to remember,
but 10 years ago, there

00:01:43.310 --> 00:01:44.210
was no iPhone.

00:01:44.210 --> 00:01:45.970
There was no Android.

00:01:45.970 --> 00:01:50.980
So speech recognition was
used mostly in call centers.

00:01:50.980 --> 00:01:53.930
And it was this annoying thing.

00:01:53.930 --> 00:01:55.730
It wasn't a lot of fun.

00:01:55.730 --> 00:01:58.130
So I came to Google
with two goals in mind.

00:01:58.130 --> 00:02:01.280
The first one was to make speech
recognition fun and useful.

00:02:01.280 --> 00:02:03.610
And the second one was to
make it work really well

00:02:03.610 --> 00:02:05.270
for everybody on the Earth.

00:02:05.270 --> 00:02:11.510
So with that, we're now 10
years later and about 20%,

00:02:11.510 --> 00:02:15.360
almost 20%, of the queries
that come into Android phones

00:02:15.360 --> 00:02:16.760
are made by voice.

00:02:16.760 --> 00:02:19.720
So we take that
as a real success.

00:02:19.720 --> 00:02:22.520
And, of course, we just
released the Cloud Speech API

00:02:22.520 --> 00:02:25.470
that allows all of you to
develop more fun products

00:02:25.470 --> 00:02:28.030
with speech recognition.

00:02:28.030 --> 00:02:31.070
We currently cover
about 80 languages

00:02:31.070 --> 00:02:35.570
and locales which could reach
to about 4 billion people.

00:02:35.570 --> 00:02:40.880
And you could ask me, why did
it take 10 years to get there?

00:02:40.880 --> 00:02:43.500
After all, speech recognition
should be very easy.

00:02:43.500 --> 00:02:45.910
One-year-olds can do
speech recognition,

00:02:45.910 --> 00:02:49.560
and a few years later, they will
be able to transcribe it, too.

00:02:49.560 --> 00:02:54.670
But if you look at
the different users

00:02:54.670 --> 00:02:59.110
and the different scenarios,
they have different needs.

00:02:59.110 --> 00:03:00.900
And they speak differently.

00:03:00.900 --> 00:03:06.580
So I was hoping to
play a few sound bites.

00:03:06.580 --> 00:03:09.034
Can someone there
click on the video?

00:03:09.034 --> 00:03:09.700
[VIDEO PLAYBACK]

00:03:09.700 --> 00:03:13.750
-When is stinger season
in the Great Barrier Reef?

00:03:13.750 --> 00:03:14.730
-[SPEAKING HUNGARIAN]

00:03:16.590 --> 00:03:19.836
FRANCOISE BEAUFAYS: So this
person is speaking Hungarian.

00:03:19.836 --> 00:03:23.922
-What noise does
an elephant make?

00:03:23.922 --> 00:03:24.830
[END PLAYBACK]

00:03:24.830 --> 00:03:28.040
FRANCOISE BEAUFAYS: So,
I mean, seriously, this

00:03:28.040 --> 00:03:30.660
is the type of data
that we should expect.

00:03:30.660 --> 00:03:35.020
And we want to serve these
users no matter who they are.

00:03:35.020 --> 00:03:37.990
So we do the best we can,
but sometimes, obviously, we

00:03:37.990 --> 00:03:39.206
get it wrong.

00:03:39.206 --> 00:03:43.490
And this is a case that was
recently reported to us.

00:03:43.490 --> 00:03:46.924
A user speaking Spanish
said "llama a Juan."

00:03:46.924 --> 00:03:48.340
They wanted to
call their friends.

00:03:48.340 --> 00:03:51.570
But were recognized "Yamaha
Juan" as if this person wanted

00:03:51.570 --> 00:03:54.530
to buy a piano or something.

00:03:54.530 --> 00:03:57.150
The next one is an example--
you might have guessed by now,

00:03:57.150 --> 00:03:58.340
I'm a French speaker.

00:03:58.340 --> 00:04:00.740
So I try my products in French.

00:04:00.740 --> 00:04:02.460
And a couple of
years ago when I said

00:04:02.460 --> 00:04:07.190
to the Recognizer, [FRENCH],
I would get this result.

00:04:07.190 --> 00:04:09.470
It sounds the same,
but the spelling

00:04:09.470 --> 00:04:11.430
is completely butchered.

00:04:11.430 --> 00:04:14.690
And then I came across
this example in Korean.

00:04:14.690 --> 00:04:16.740
If you look at
the strings, we're

00:04:16.740 --> 00:04:20.290
actually getting every single
Hangul, every single character

00:04:20.290 --> 00:04:23.380
right, but the white spaces
are not at the right space.

00:04:23.380 --> 00:04:25.240
And that means something
very different,

00:04:25.240 --> 00:04:27.800
as you can see from
the translation.

00:04:27.800 --> 00:04:30.220
So we make mistakes.

00:04:30.220 --> 00:04:31.630
But this is speech recognition.

00:04:31.630 --> 00:04:33.520
Speech recognition
is machine learning.

00:04:33.520 --> 00:04:35.580
Machine learning
can fix everything.

00:04:35.580 --> 00:04:38.370
So we can get it right.

00:04:38.370 --> 00:04:41.620
But before we go more
into how we get it right,

00:04:41.620 --> 00:04:45.000
I want to give you just a
very high level look at how

00:04:45.000 --> 00:04:46.790
speech recognition works.

00:04:46.790 --> 00:04:50.140
So you have a speech waveform
that comes into the system.

00:04:50.140 --> 00:04:52.300
And you're trying to get
a sentence out of it.

00:04:52.300 --> 00:04:54.900
So in the system,
there are three models.

00:04:54.900 --> 00:04:57.000
There's an acoustic
model that takes snippets

00:04:57.000 --> 00:04:59.870
of that soundtrack and
tries to find distribution

00:04:59.870 --> 00:05:02.430
of probability over phonemes,
the individual sounds

00:05:02.430 --> 00:05:03.700
of a language.

00:05:03.700 --> 00:05:05.370
Then there's a
pronunciation model

00:05:05.370 --> 00:05:08.970
that takes those phonemes
and makes words out of them.

00:05:08.970 --> 00:05:11.470
And then there's a language
model that strings words

00:05:11.470 --> 00:05:14.020
together with probabilities.

00:05:14.020 --> 00:05:16.220
If you want to see
this is an equation,

00:05:16.220 --> 00:05:17.710
it's essentially
saying that we're

00:05:17.710 --> 00:05:20.570
trying to find the
word sequence that

00:05:20.570 --> 00:05:24.044
has the highest probability
given the acoustic observation.

00:05:24.044 --> 00:05:25.460
And with a little
bit of math, you

00:05:25.460 --> 00:05:27.920
can decompose that into
three probabilities,

00:05:27.920 --> 00:05:31.270
a product of those
three, which correspond

00:05:31.270 --> 00:05:33.190
to the different models.

00:05:33.190 --> 00:05:36.526
So all this to say, this
is a statistical model.

00:05:36.526 --> 00:05:37.900
There are three
different models.

00:05:37.900 --> 00:05:39.590
Everything in there
is statistical

00:05:39.590 --> 00:05:42.360
and can be learned from data.

00:05:42.360 --> 00:05:44.550
And the first one,
the acoustic model,

00:05:44.550 --> 00:05:47.690
is something I want to talk a
little bit more about because

00:05:47.690 --> 00:05:49.830
for a long time, for
many decades, actually,

00:05:49.830 --> 00:05:53.710
we were using a technology
called Gaussian Mixture Models,

00:05:53.710 --> 00:05:56.020
which served the community
of speech recognition

00:05:56.020 --> 00:05:57.750
very well for a long time.

00:05:57.750 --> 00:06:03.990
But in 2012, we changed
that to neural networks.

00:06:03.990 --> 00:06:05.480
And it took us a
while to get there

00:06:05.480 --> 00:06:08.580
because those neural
networks take time to train.

00:06:08.580 --> 00:06:10.530
They're big.

00:06:10.530 --> 00:06:13.230
If you want to get the right
latency characteristics out

00:06:13.230 --> 00:06:15.270
of the system, you
have to optimize a lot.

00:06:15.270 --> 00:06:16.770
But eventually we got there.

00:06:16.770 --> 00:06:18.870
And we get huge
accuracy improvements

00:06:18.870 --> 00:06:20.960
out of switching
to neural networks.

00:06:20.960 --> 00:06:23.370
But in addition to that,
the thing that's interesting

00:06:23.370 --> 00:06:26.760
is that it restarted a
revolution in the field.

00:06:26.760 --> 00:06:29.170
By having that
infrastructure in place,

00:06:29.170 --> 00:06:31.880
we started innovating
the type of architectures

00:06:31.880 --> 00:06:35.220
of the actual structure of the
neural networks and the way

00:06:35.220 --> 00:06:36.470
we're using them.

00:06:36.470 --> 00:06:39.080
And year after year, and I
would say month after month,

00:06:39.080 --> 00:06:41.240
we came out with
new structures that

00:06:41.240 --> 00:06:45.060
were always more powerful
than the previous generation.

00:06:45.060 --> 00:06:47.420
So we went from
deep neural networks

00:06:47.420 --> 00:06:51.420
to recurrent neural
networks with LSTM.

00:06:51.420 --> 00:06:54.028
From there, we added
convolutional layers

00:06:54.028 --> 00:06:57.280
that allow us to better deal
with noise and reverberences

00:06:57.280 --> 00:06:59.270
in this room.

00:06:59.270 --> 00:07:01.810
And from there to a
connectionist temporal

00:07:01.810 --> 00:07:04.670
classification,
CTC, which I will

00:07:04.670 --> 00:07:06.260
show a little bit more about.

00:07:09.010 --> 00:07:14.520
These types of improvement
in the structures

00:07:14.520 --> 00:07:16.380
result in improvements
in quality.

00:07:16.380 --> 00:07:20.590
So over 2015, over all
the different groups

00:07:20.590 --> 00:07:22.290
of languages that
we cover, we've

00:07:22.290 --> 00:07:23.870
had accuracy improvements.

00:07:23.870 --> 00:07:28.990
And going back to
CTC, like I said,

00:07:28.990 --> 00:07:31.810
the CTC has allowed
us to decrease

00:07:31.810 --> 00:07:35.580
the latency of our speech
Recognizer quite a bit.

00:07:35.580 --> 00:07:38.470
And that means that when you're
speaking to your Recognizer,

00:07:38.470 --> 00:07:40.170
you get your
response much faster

00:07:40.170 --> 00:07:44.910
and gives you that snappiness
that feels comfortable.

00:07:44.910 --> 00:07:49.150
Now, of course, sometimes
things are complicated.

00:07:49.150 --> 00:07:51.890
And we went through
several lessons in our life

00:07:51.890 --> 00:07:55.820
as a group doing speech
recognition at Google.

00:07:55.820 --> 00:07:58.214
But for you to really
appreciate those lessons,

00:07:58.214 --> 00:07:59.630
I want to give you
just a tiny bit

00:07:59.630 --> 00:08:02.120
more about how the
speech Recognizer works.

00:08:02.120 --> 00:08:05.010
We're using, like I said, a lot
of data to train our models.

00:08:05.010 --> 00:08:06.510
And there are
different sources that

00:08:06.510 --> 00:08:08.360
go into training those models.

00:08:08.360 --> 00:08:10.960
The models go into
the Recognizer.

00:08:10.960 --> 00:08:15.280
And we're using the data that
comes out of the Recognizer

00:08:15.280 --> 00:08:17.560
to feed back into the
models because that's

00:08:17.560 --> 00:08:20.800
data that's very well matched
to what we're trying to do.

00:08:20.800 --> 00:08:23.000
The problem is that
that data occasionally

00:08:23.000 --> 00:08:26.003
has typos, various problems.

00:08:26.003 --> 00:08:28.710
Data is never clean.

00:08:28.710 --> 00:08:32.970
And that caused the
issues that we've seen.

00:08:32.970 --> 00:08:38.950
So one day in Korean, we
started seeing this word, keu-a,

00:08:38.950 --> 00:08:42.360
appearing all over the place
in our Recognizer outputs.

00:08:42.360 --> 00:08:43.870
And we didn't quite
understand why.

00:08:43.870 --> 00:08:45.610
So we started analyzing.

00:08:45.610 --> 00:08:49.750
And we realized that it was
the voices of little kids.

00:08:49.750 --> 00:08:52.070
It's people making
voice queries,

00:08:52.070 --> 00:08:53.862
but there are kids
in the background.

00:08:53.862 --> 00:08:55.320
And those little
voices-- you know,

00:08:55.320 --> 00:08:57.510
high-pitched words--
the Recognizer didn't

00:08:57.510 --> 00:08:58.790
know what to do with it.

00:08:58.790 --> 00:09:02.250
So it found a word
that was vowel-heavy,

00:09:02.250 --> 00:09:05.530
like [INAUDIBLE] and it
tried to pick that word.

00:09:05.530 --> 00:09:08.000
And it started recognizing
it all over the place.

00:09:08.000 --> 00:09:10.140
And because of the feedback
loop I was showing you,

00:09:10.140 --> 00:09:13.410
it just fed back into the
system and grew and grew.

00:09:13.410 --> 00:09:15.620
But before we could fix
it in British English,

00:09:15.620 --> 00:09:18.330
we started seeing
this word, kdkdkd.

00:09:18.330 --> 00:09:21.910
Now can one of you guess
where that one is coming from?

00:09:24.420 --> 00:09:26.850
Someone said it.

00:09:26.850 --> 00:09:28.390
The train.

00:09:28.390 --> 00:09:29.140
Subway.

00:09:29.140 --> 00:09:32.070
So it's people using their phone
on the train on the subway.

00:09:32.070 --> 00:09:35.050
[SUBWAY SOUND]
And the Recognizer

00:09:35.050 --> 00:09:37.990
didn't know what to do,
and output something.

00:09:37.990 --> 00:09:41.600
And then the last one, it's
maybe a little embarrassing,

00:09:41.600 --> 00:09:47.290
but it was this word. [LAUGHTER]
And when we looked more

00:09:47.290 --> 00:09:50.300
into it, what was happening
is people taking their phone

00:09:50.300 --> 00:09:51.620
and they're [DEEP BREATH].

00:09:51.620 --> 00:09:52.610
And then they talk.

00:09:52.610 --> 00:09:53.950
Take a deep breath.

00:09:53.950 --> 00:09:55.947
So you have that blow of air.

00:09:55.947 --> 00:09:58.113
And then it goes quickly
on the vowel and the click,

00:09:58.113 --> 00:10:01.090
and that's what the
Recognizer found.

00:10:01.090 --> 00:10:05.320
So as soon as I became
aware of that one,

00:10:05.320 --> 00:10:08.580
I knew that we had to
do something about it.

00:10:08.580 --> 00:10:10.510
And we fix these
type of problems

00:10:10.510 --> 00:10:14.470
by actually putting more human
knowledge into our systems.

00:10:14.470 --> 00:10:19.350
We started using more linguists,
using more human resources

00:10:19.350 --> 00:10:24.250
to try to format the data
well and to transcribe

00:10:24.250 --> 00:10:25.670
the data correctly.

00:10:25.670 --> 00:10:29.800
And we built very sophisticated
guidelines to get our data

00:10:29.800 --> 00:10:32.130
transcribed correctly
so that we could

00:10:32.130 --> 00:10:34.260
leverage that human knowledge.

00:10:34.260 --> 00:10:37.030
With just 3 million
annotated waveforms,

00:10:37.030 --> 00:10:39.080
we can train our
acoustic models,

00:10:39.080 --> 00:10:42.250
learn new pronunciations
from the data,

00:10:42.250 --> 00:10:45.380
augment the size of our
language modeling training set.

00:10:45.380 --> 00:10:48.000
And all that gives
you improvements.

00:10:48.000 --> 00:10:49.680
But now, with 3
million waveforms,

00:10:49.680 --> 00:10:51.560
we said, well, we can
do a lot of things.

00:10:51.560 --> 00:10:52.940
How about 30 million?

00:10:52.940 --> 00:10:54.720
So we just embarked
into an effort

00:10:54.720 --> 00:10:58.630
to transcribe 33,000
hours of human speech.

00:10:58.630 --> 00:11:02.420
It takes 600 people to do that
in a reasonable time frame.

00:11:02.420 --> 00:11:04.710
But with this data,
we're dreaming

00:11:04.710 --> 00:11:08.160
about new architectures,
more complicated, more tight

00:11:08.160 --> 00:11:09.140
that we can use.

00:11:09.140 --> 00:11:10.660
And we think that
with that maybe

00:11:10.660 --> 00:11:14.040
we can solve the big dream
of speech recognition,

00:11:14.040 --> 00:11:16.740
of really making it work
for every person on Earth.

00:11:16.740 --> 00:11:17.400
Thank you.

00:11:17.400 --> 00:11:18.768
[APPLAUSE]

00:11:18.768 --> 00:11:23.144
I pass it to Andrew, who will
talk about graphs and pumpkins.

00:11:23.144 --> 00:11:24.560
ANDREW TOMKINS:
Thanks, Francoise.

00:11:24.560 --> 00:11:25.320
Hi, everyone.

00:11:25.320 --> 00:11:27.900
I'm Andrew.

00:11:27.900 --> 00:11:33.000
So this is the usual picture
you have of machine learning.

00:11:33.000 --> 00:11:34.620
We have some reds.

00:11:34.620 --> 00:11:35.450
We have some blues.

00:11:35.450 --> 00:11:37.761
We'd like to try to learn
a model that will separate

00:11:37.761 --> 00:11:38.760
the reds from the blues.

00:11:38.760 --> 00:11:41.800
And then when new input comes
along, we'll apply our model.

00:11:41.800 --> 00:11:43.820
And we'll guess whether
it's a red or a blue.

00:11:43.820 --> 00:11:45.727
So that is not the
framework that we're

00:11:45.727 --> 00:11:46.810
going to talk about today.

00:11:46.810 --> 00:11:47.830
Today, we're going to
talk about something

00:11:47.830 --> 00:11:50.070
a little bit different
for the next 10 minutes.

00:11:50.070 --> 00:11:52.910
So here, here's me.

00:11:52.910 --> 00:11:55.010
I'm there alone solo.

00:11:55.010 --> 00:11:59.220
And you have to guess what
it is that I like to do.

00:11:59.220 --> 00:12:01.320
So from the data, it's
very hard to guess.

00:12:01.320 --> 00:12:03.205
Maybe hats are my thing.

00:12:03.205 --> 00:12:04.920
There's not much
more that you can

00:12:04.920 --> 00:12:06.230
get from the representation.

00:12:06.230 --> 00:12:07.930
Maybe you'd gather
some features,

00:12:07.930 --> 00:12:10.362
and maybe generate a training
set, learn some models,

00:12:10.362 --> 00:12:12.570
and then try to predict what
it is that I like to do.

00:12:12.570 --> 00:12:14.600
But we're going to talk
about another approach.

00:12:14.600 --> 00:12:16.183
We're going to talk
about what could I

00:12:16.183 --> 00:12:20.620
do if I understood not just
this data object alone,

00:12:20.620 --> 00:12:22.950
but if I could put it into
context of its neighborhood

00:12:22.950 --> 00:12:24.210
within my data set.

00:12:24.210 --> 00:12:28.820
And so we'll add relationships
to other pieces of data.

00:12:28.820 --> 00:12:30.480
In this case, it's my kids.

00:12:30.480 --> 00:12:33.117
And now it's possible
to draw some inferences,

00:12:33.117 --> 00:12:34.950
like, maybe what I like
to do is to go trick

00:12:34.950 --> 00:12:36.590
or treating with my kids.

00:12:36.590 --> 00:12:40.410
And so with that intuition,
that rather than operating

00:12:40.410 --> 00:12:43.390
in isolation to classify
each data object,

00:12:43.390 --> 00:12:45.640
we should actually make
use of the relationships

00:12:45.640 --> 00:12:47.750
between different
data points, even data

00:12:47.750 --> 00:12:50.150
points that we don't
completely understand.

00:12:50.150 --> 00:12:54.697
We would like to see how far
we can go with that idea.

00:12:54.697 --> 00:12:56.780
And so we have a piece of
infrastructure at Google

00:12:56.780 --> 00:12:59.970
called Expander, which is
designed to do exactly this.

00:12:59.970 --> 00:13:03.050
So this is a
large-scale platform

00:13:03.050 --> 00:13:05.120
which is intended to
make use of connections

00:13:05.120 --> 00:13:08.990
that we have between
data objects.

00:13:08.990 --> 00:13:10.384
So let me give you an example.

00:13:10.384 --> 00:13:12.050
Clearly, I like to
go trick or treating.

00:13:12.050 --> 00:13:15.440
So it would be very helpful
if I could recognize pumpkins.

00:13:15.440 --> 00:13:18.880
So we actually have this great
image understanding system

00:13:18.880 --> 00:13:19.679
at Google.

00:13:19.679 --> 00:13:20.720
And this is how it works.

00:13:20.720 --> 00:13:22.310
It's given a bunch of images.

00:13:22.310 --> 00:13:24.850
And they have training
labels on them.

00:13:24.850 --> 00:13:27.040
And then it learns,
deep network,

00:13:27.040 --> 00:13:29.470
which will be able to
recognize new images

00:13:29.470 --> 00:13:31.990
and recognize objects
and images in the future.

00:13:31.990 --> 00:13:36.010
And so now we hand it the
rest of the corpus, which

00:13:36.010 --> 00:13:36.660
has no labels.

00:13:36.660 --> 00:13:37.743
And we apply these models.

00:13:37.743 --> 00:13:39.864
And we get our labels.

00:13:39.864 --> 00:13:41.280
So looking at this
data, you could

00:13:41.280 --> 00:13:43.240
ask, just how good
are the labels

00:13:43.240 --> 00:13:44.330
that we're starting with?

00:13:44.330 --> 00:13:46.540
And they're pretty good,
but they're not great.

00:13:46.540 --> 00:13:49.100
So one of those is a
pumpkin, the one on the left.

00:13:49.100 --> 00:13:51.880
The one on the right
is pumpkin soup.

00:13:51.880 --> 00:13:54.480
And, as you can imagine, if you
were a neural network, which

00:13:54.480 --> 00:13:57.800
you are, it would be pretty
hard to be fed that and told

00:13:57.800 --> 00:13:59.850
to learn a representation
of pumpkins,

00:13:59.850 --> 00:14:01.550
and be given these
confusing inputs.

00:14:01.550 --> 00:14:03.400
So what I'm going to
tell you about first

00:14:03.400 --> 00:14:06.140
is a hybrid system that
uses graph-based learning

00:14:06.140 --> 00:14:09.310
and connections in order to
figure out the right training

00:14:09.310 --> 00:14:12.740
data, and then on top of that,
apply its deep network learning

00:14:12.740 --> 00:14:15.070
to figure out the right model.

00:14:15.070 --> 00:14:16.070
So how would we do that?

00:14:16.070 --> 00:14:19.330
Well, we actually do have
connections between these data

00:14:19.330 --> 00:14:20.010
objects.

00:14:20.010 --> 00:14:22.500
So between each of
these pixel arrays,

00:14:22.500 --> 00:14:24.140
we've been able to
learn embeddings,

00:14:24.140 --> 00:14:27.360
which capture the semantic
similarity of two images.

00:14:27.360 --> 00:14:29.210
What is the likelihood
that these two images

00:14:29.210 --> 00:14:30.760
have the same object in them?

00:14:30.760 --> 00:14:32.440
So we can use those edges.

00:14:32.440 --> 00:14:35.470
You can see on the left, we
could propagate the information

00:14:35.470 --> 00:14:36.960
at the top of the
graph that says

00:14:36.960 --> 00:14:40.180
we have things we know to be
pumpkins, through those edges,

00:14:40.180 --> 00:14:42.410
and confirm our
initial intuition

00:14:42.410 --> 00:14:44.202
that the thing in the
bottom was a pumpkin.

00:14:44.202 --> 00:14:46.410
But when we look at the
right-hand side of the graph,

00:14:46.410 --> 00:14:47.570
we can do the same thing.

00:14:47.570 --> 00:14:51.290
We can propagate a couple of
instances of known not pumpkins

00:14:51.290 --> 00:14:53.210
through the graph
to help us conclude

00:14:53.210 --> 00:14:56.240
that our label on the
pumpkin soup is questionable.

00:14:56.240 --> 00:14:57.820
Maybe we ought to rethink it.

00:14:57.820 --> 00:15:01.830
So we can use this approach
to remove about 40%

00:15:01.830 --> 00:15:04.150
of the training data that
initially we were using

00:15:04.150 --> 00:15:05.790
to learn image classifiers.

00:15:05.790 --> 00:15:07.450
And by removing that
data, we actually

00:15:07.450 --> 00:15:10.590
got a 9% lift in our metrics
on image classification,

00:15:10.590 --> 00:15:13.110
which improves what we can do
for Google Photos and Google

00:15:13.110 --> 00:15:14.920
Search.

00:15:14.920 --> 00:15:18.430
So from there, let's take
a look at how this works.

00:15:18.430 --> 00:15:23.580
So this is the one equation
form of graph propagation.

00:15:23.580 --> 00:15:25.500
What we're trying
to do is write down

00:15:25.500 --> 00:15:27.720
a penalty function that
tells us how well we're

00:15:27.720 --> 00:15:30.720
doing with respect to
the neighborhoods that

00:15:30.720 --> 00:15:32.180
are in my data.

00:15:32.180 --> 00:15:35.840
And so you can see, there's
a term-- lu minus lv--

00:15:35.840 --> 00:15:39.350
which says how far apart
are the labels of nodes u

00:15:39.350 --> 00:15:40.670
and v in the data.

00:15:40.670 --> 00:15:43.370
And I will weight that by the
strength of the connection

00:15:43.370 --> 00:15:45.110
between them, wuv.

00:15:45.110 --> 00:15:47.220
And I'll add it up
over my entire dataset.

00:15:47.220 --> 00:15:50.730
That's the penalty that says
how far away I am from properly

00:15:50.730 --> 00:15:53.880
respecting the semantics
of the edges that I have,

00:15:53.880 --> 00:15:55.362
the similarity information.

00:15:55.362 --> 00:15:56.820
And then I'll try
to minimize that.

00:15:56.820 --> 00:15:59.400
It's actually quite
easy to minimize that.

00:15:59.400 --> 00:16:01.560
The equation at the bottom
shows that if what I do

00:16:01.560 --> 00:16:03.960
is, for each of my
data objects, I take

00:16:03.960 --> 00:16:05.510
a look at its neighborhood.

00:16:05.510 --> 00:16:08.000
I use the labels that I have
for the neighbors in order

00:16:08.000 --> 00:16:09.480
to update my label.

00:16:09.480 --> 00:16:11.120
I do that for
everything in the graph.

00:16:11.120 --> 00:16:13.150
And then I do it
again and again.

00:16:13.150 --> 00:16:15.400
Information walks
through the graph.

00:16:15.400 --> 00:16:18.870
And it converges provably
to the optimal assignment

00:16:18.870 --> 00:16:20.430
for that cost function.

00:16:20.430 --> 00:16:22.200
And so from that
starting point, you

00:16:22.200 --> 00:16:24.280
can now layer in a
lot of complexity

00:16:24.280 --> 00:16:27.010
and additional features
into the system.

00:16:27.010 --> 00:16:28.760
So that's the algorithmic side.

00:16:28.760 --> 00:16:31.640
But there's also a system
side here because what

00:16:31.640 --> 00:16:35.260
we would like to do in order to
build these systems is operate

00:16:35.260 --> 00:16:37.440
at the scale of billions
of different data objects

00:16:37.440 --> 00:16:38.620
simultaneously.

00:16:38.620 --> 00:16:41.030
And the label spaces
that we might apply

00:16:41.030 --> 00:16:44.010
could actually have billions
of distinct labels as well.

00:16:44.010 --> 00:16:46.130
And we'd like to
do this on graphs

00:16:46.130 --> 00:16:47.890
so the penalties
that we're measuring

00:16:47.890 --> 00:16:51.350
are measured over trillions of
edges, trillions of connections

00:16:51.350 --> 00:16:52.710
between the objects.

00:16:52.710 --> 00:16:55.660
So that's what we've
built in order to make

00:16:55.660 --> 00:16:57.052
use of these techniques.

00:16:57.052 --> 00:16:58.260
Now that we have these tools.

00:16:58.260 --> 00:17:01.070
Let me give you a couple
of other examples.

00:17:01.070 --> 00:17:04.656
So you heard in the
keynote about SmartReply

00:17:04.656 --> 00:17:06.030
in the context of
messaging apps.

00:17:06.030 --> 00:17:07.571
And I hope people
have had the chance

00:17:07.571 --> 00:17:11.990
to try it out in the
context of Inbox right now.

00:17:11.990 --> 00:17:16.530
Here, the vertices of this
graph are possible responses

00:17:16.530 --> 00:17:18.490
that you might be able to send.

00:17:18.490 --> 00:17:20.410
And the edges
represent similarity.

00:17:20.410 --> 00:17:23.930
So it could come from maybe
a distributional similarity

00:17:23.930 --> 00:17:26.470
to say these responses are
used in the same context.

00:17:26.470 --> 00:17:28.599
Or it could come from
lexical similarity, say,

00:17:28.599 --> 00:17:29.640
they have the same words.

00:17:29.640 --> 00:17:32.430
Or similarity based
on word embeddings.

00:17:32.430 --> 00:17:34.850
When I've got the graph, I
can now run Expander in order

00:17:34.850 --> 00:17:36.220
to generate clusters.

00:17:36.220 --> 00:17:39.360
And that will tell me
about similar phrases

00:17:39.360 --> 00:17:41.120
that have the same meaning.

00:17:41.120 --> 00:17:43.050
The personalization
features that

00:17:43.050 --> 00:17:44.720
were alluded to in
the keynote can then

00:17:44.720 --> 00:17:46.540
choose an appropriate
choice here

00:17:46.540 --> 00:17:48.840
for the particular
user in their context.

00:17:48.840 --> 00:17:50.910
And the understanding of
those different clusters

00:17:50.910 --> 00:17:54.365
can be used to make sure that
we offer diverse choices so

00:17:54.365 --> 00:17:55.740
that we're not
just picking three

00:17:55.740 --> 00:17:58.080
ways of saying the same thing.

00:17:58.080 --> 00:17:59.510
So that's great for English.

00:17:59.510 --> 00:18:01.940
We can do the same thing
in other languages as well.

00:18:01.940 --> 00:18:04.640
So this is an example of just
specifically for responses

00:18:04.640 --> 00:18:05.830
that are greetings.

00:18:05.830 --> 00:18:08.130
So in English, maybe I can
say "Hi!" "How's things?"

00:18:08.130 --> 00:18:08.745
"What's up?"

00:18:08.745 --> 00:18:10.870
And we have connections
between those like the ones

00:18:10.870 --> 00:18:12.640
that we talked about
on the last slide.

00:18:12.640 --> 00:18:15.580
But in French, I
might say [FRENCH].

00:18:15.580 --> 00:18:18.620
And I can start to
build connections

00:18:18.620 --> 00:18:21.430
from the French variant to
the English variant using

00:18:21.430 --> 00:18:24.440
the models that power
Google Translation.

00:18:24.440 --> 00:18:27.770
Maybe "How's things?" and
[NON-ENGLISH] can be connected

00:18:27.770 --> 00:18:29.470
together based on
translate edges.

00:18:29.470 --> 00:18:31.480
And now I can start to
flow semantic meaning

00:18:31.480 --> 00:18:33.012
across a multilingual graph.

00:18:33.012 --> 00:18:35.220
And that would allow us to
build data structures that

00:18:35.220 --> 00:18:39.590
could then power features like
SmartReply in other languages

00:18:39.590 --> 00:18:44.690
like Portuguese, Indonesian,
Spanish, even English.

00:18:44.690 --> 00:18:46.270
Let's do one more,
one more example,

00:18:46.270 --> 00:18:48.090
now in the space
of search queries.

00:18:48.090 --> 00:18:51.860
So of course, I'm interested
in trick or treating.

00:18:51.860 --> 00:18:57.320
I'd like to tell my kids
some stories about Halloween.

00:18:57.320 --> 00:18:59.470
So I'll go to Google
and ask some questions.

00:18:59.470 --> 00:19:01.430
My hope is that Google
will be able to give me

00:19:01.430 --> 00:19:02.940
this featured snippet
back that will

00:19:02.940 --> 00:19:05.730
answer my question directly.

00:19:05.730 --> 00:19:07.900
So we have that capability.

00:19:07.900 --> 00:19:10.530
We would love to be able
to expand the coverage

00:19:10.530 --> 00:19:12.880
and respond to more
questions in that way.

00:19:12.880 --> 00:19:15.360
So this is a graph whose
vertices are queries.

00:19:15.360 --> 00:19:17.790
And the edges represent
the likelihood

00:19:17.790 --> 00:19:20.680
that two queries
would be answered

00:19:20.680 --> 00:19:22.880
by the same
information response.

00:19:22.880 --> 00:19:25.420
And I can now flow
information through that graph

00:19:25.420 --> 00:19:27.080
in order to improve
the coverage.

00:19:27.080 --> 00:19:29.790
You can see that the stronger
edges, the ones that are solid,

00:19:29.790 --> 00:19:32.230
are places where I'm more
confident about the meeting.

00:19:32.230 --> 00:19:33.990
The dotted edges
might represent things

00:19:33.990 --> 00:19:35.240
that have some drift to them.

00:19:35.240 --> 00:19:37.410
So I have to be very
careful about exactly how I

00:19:37.410 --> 00:19:38.690
do the propagation.

00:19:38.690 --> 00:19:41.970
But having done that, we're
able to automatically discover

00:19:41.970 --> 00:19:43.990
semantically equivalent
questions for more

00:19:43.990 --> 00:19:47.110
than a billion
queries in Search.

00:19:47.110 --> 00:19:49.140
So let me wrap up
now just by saying

00:19:49.140 --> 00:19:51.230
that we've been using
machine learning

00:19:51.230 --> 00:19:53.300
on graphs to understand
natural language,

00:19:53.300 --> 00:19:54.830
to understand
queries, to understand

00:19:54.830 --> 00:19:56.890
images and other media objects.

00:19:56.890 --> 00:20:01.390
And we also-- you probably heard
in the keynote about PhotoReply

00:20:01.390 --> 00:20:05.740
where we can actually recommend
responses to images just built

00:20:05.740 --> 00:20:07.350
on the same technology.

00:20:07.350 --> 00:20:09.310
And we can use the
same techniques

00:20:09.310 --> 00:20:12.130
in order to generate concise
models that can actually

00:20:12.130 --> 00:20:14.580
be applied in Android
Wear on a device

00:20:14.580 --> 00:20:16.330
in order to do things
like recommending

00:20:16.330 --> 00:20:20.430
an appropriate response
as we saw in the keynote

00:20:20.430 --> 00:20:21.310
on Wednesday.

00:20:21.310 --> 00:20:25.140
So with that, we found
a lot of great impact

00:20:25.140 --> 00:20:27.970
from graph-based learning,
especially in scenarios

00:20:27.970 --> 00:20:30.460
where you have a lot of data.

00:20:30.460 --> 00:20:32.710
Labels are expensive, but
you understand something

00:20:32.710 --> 00:20:35.210
about the connections
between your data objects.

00:20:35.210 --> 00:20:38.687
So with that, let me pass to
Maya to talk about Glassbox.

00:20:38.687 --> 00:20:40.635
[APPLAUSE]

00:20:43.160 --> 00:20:43.910
MAYA GUPTA: Great.

00:20:43.910 --> 00:20:46.077
So Andy was just talking
about questions and answers

00:20:46.077 --> 00:20:47.284
and doing that automatically.

00:20:47.284 --> 00:20:49.560
We're going to do that
non-automatically for you right

00:20:49.560 --> 00:20:51.074
here in about 10, 15 minutes.

00:20:51.074 --> 00:20:52.990
So if you guys have some
questions that you're

00:20:52.990 --> 00:20:54.490
thinking of, we'll
have you come up

00:20:54.490 --> 00:20:56.484
to the mics in about 10 minutes.

00:20:56.484 --> 00:20:58.650
But first I'm going to talk
about Glassbox learning.

00:20:58.650 --> 00:21:00.860
Sometimes people complain
that machine learning

00:21:00.860 --> 00:21:02.470
fills a little black box.

00:21:02.470 --> 00:21:04.972
And so our team is sort
of dedicated to making

00:21:04.972 --> 00:21:06.180
it a little more transparent.

00:21:06.180 --> 00:21:08.372
And as Francoise
said earlier, it's

00:21:08.372 --> 00:21:10.580
important to get the human
knowledge into the machine

00:21:10.580 --> 00:21:11.070
learning.

00:21:11.070 --> 00:21:13.028
We don't just want to
pour a lot of examples in

00:21:13.028 --> 00:21:14.500
and see what happens.

00:21:14.500 --> 00:21:16.030
Sometimes we know
a little better.

00:21:16.030 --> 00:21:17.760
So let me start with a story.

00:21:17.760 --> 00:21:19.490
About two years
ago, we were working

00:21:19.490 --> 00:21:22.344
on a video recommendation
system using machine learning.

00:21:22.344 --> 00:21:23.510
And we were about to launch.

00:21:23.510 --> 00:21:24.692
The tests looked good.

00:21:24.692 --> 00:21:25.900
Live experiments looked good.

00:21:25.900 --> 00:21:26.734
Everything was fine.

00:21:26.734 --> 00:21:28.816
And then the manager noticed
that if they searched

00:21:28.816 --> 00:21:31.450
for Gangnam Style, and they
watched "Gangnam Style," which

00:21:31.450 --> 00:21:32.850
is this Korean
hip-hop video that

00:21:32.850 --> 00:21:35.900
was very popular at the time,
a suggestion in the top 10

00:21:35.900 --> 00:21:38.230
would come up called
"Il Pulcino Pio," which

00:21:38.230 --> 00:21:40.170
was this little Italian
musical video where

00:21:40.170 --> 00:21:41.840
they make animal sounds.

00:21:41.840 --> 00:21:43.430
And they were very concerned.

00:21:43.430 --> 00:21:45.380
So the manager was
like, whoa, wait, stop.

00:21:45.380 --> 00:21:46.270
What's going on here?

00:21:46.270 --> 00:21:47.870
What is your machine
learning doing?

00:21:47.870 --> 00:21:50.040
I don't know if we can trust it.

00:21:50.040 --> 00:21:51.880
So what happened?

00:21:51.880 --> 00:21:53.060
Well, we'll go back to that.

00:21:53.060 --> 00:21:54.560
But let it motivate
the breakthrough

00:21:54.560 --> 00:21:56.640
that I'm going to talk about
for the next few minutes.

00:21:56.640 --> 00:21:58.140
And to talk about
that breakthrough,

00:21:58.140 --> 00:22:00.950
let's ask another question,
which is, how far will you

00:22:00.950 --> 00:22:03.785
go for hot coffee?

00:22:03.785 --> 00:22:06.160
So you can see here, we're at
the Shoreline Amphitheater.

00:22:06.160 --> 00:22:08.320
And how many results
should we show you

00:22:08.320 --> 00:22:09.580
if you're looking for coffee?

00:22:09.580 --> 00:22:11.080
How far would you
really want to go?

00:22:11.080 --> 00:22:13.440
So let's take this example
and just build ourselves

00:22:13.440 --> 00:22:16.019
a little machine learning
system real-time here.

00:22:16.019 --> 00:22:17.560
And we're just going
to mock this up.

00:22:17.560 --> 00:22:20.020
So since we're doing machine
learning, we need examples.

00:22:20.020 --> 00:22:21.728
And we're just going
to do a 1D case here

00:22:21.728 --> 00:22:23.559
because I draw best
in one dimension.

00:22:23.559 --> 00:22:25.850
So let's say I show you some
coffee one kilometer away.

00:22:25.850 --> 00:22:27.550
And you're like, yeah,
that looks great.

00:22:27.550 --> 00:22:29.091
We show coffee a
little further away.

00:22:29.091 --> 00:22:31.530
You're like, no, I'm not
going to go that far.

00:22:31.530 --> 00:22:33.210
And we get a few
different examples.

00:22:33.210 --> 00:22:35.560
And then, like our
forefathers before us,

00:22:35.560 --> 00:22:37.480
we fit a linear line.

00:22:37.480 --> 00:22:40.800
And we're like, great, now we
kind of know what's going on.

00:22:40.800 --> 00:22:42.220
Except we're Google.

00:22:42.220 --> 00:22:43.052
We have Big Data.

00:22:43.052 --> 00:22:44.010
So we have a lot today.

00:22:44.010 --> 00:22:45.510
We think we can do
something better.

00:22:45.510 --> 00:22:48.470
So we fit a more
flexible model, maybe

00:22:48.470 --> 00:22:50.320
with an SVM or a neural net.

00:22:50.320 --> 00:22:53.350
And wow, that doesn't
look good at all, does it?

00:22:53.350 --> 00:22:54.860
So what's gone wrong here?

00:22:54.860 --> 00:22:58.120
Well, big data is
also noisy data.

00:22:58.120 --> 00:23:02.490
So we have to watch out that
we don't be too flexible.

00:23:02.490 --> 00:23:04.880
Probably the right
answer s to regularize.

00:23:04.880 --> 00:23:06.060
So you regularize.

00:23:06.060 --> 00:23:08.140
This still looks a
little funny, though.

00:23:08.140 --> 00:23:10.190
Do people believe this
is really the true curve

00:23:10.190 --> 00:23:12.380
of how far people are
willing to go for coffee?

00:23:12.380 --> 00:23:14.410
Doesn't seem quite right to me.

00:23:14.410 --> 00:23:16.170
So we could try to
regularize harder,

00:23:16.170 --> 00:23:19.180
but we're going to get
back to linear pretty fast.

00:23:19.180 --> 00:23:20.180
Let's do something else.

00:23:20.180 --> 00:23:22.800
Let's just do a decision tree.

00:23:22.800 --> 00:23:26.200
Still looking a
little problematic.

00:23:26.200 --> 00:23:27.720
So again, the right
answer, well, we

00:23:27.720 --> 00:23:28.950
fit a whole bunch
of decision trees.

00:23:28.950 --> 00:23:30.199
We'll call it a random forest.

00:23:30.199 --> 00:23:31.160
This will be great.

00:23:31.160 --> 00:23:33.680
And this is trying to fit
things a little better,

00:23:33.680 --> 00:23:36.770
but it seems a little weird
because I know something

00:23:36.770 --> 00:23:38.620
as a human, which
is that I don't want

00:23:38.620 --> 00:23:40.032
to walk farther for coffee.

00:23:40.032 --> 00:23:41.990
And the machine learning
isn't picking that up.

00:23:41.990 --> 00:23:43.560
It's like, oh, this is equal.

00:23:43.560 --> 00:23:44.162
This is equal.

00:23:44.162 --> 00:23:45.120
This is a little worse.

00:23:45.120 --> 00:23:47.860
This is-- it's basically
over-fitting a little.

00:23:47.860 --> 00:23:51.570
So what I'd really like to
see is a curve like this.

00:23:51.570 --> 00:23:52.580
It should be smooth.

00:23:52.580 --> 00:23:54.600
It should be
monotonically decreasing.

00:23:54.600 --> 00:23:56.550
Should fit the data
as well as it can.

00:23:56.550 --> 00:23:58.790
This is what we expect our
machine learning to do.

00:23:58.790 --> 00:24:00.790
But this isn't necessarily
what machine learning

00:24:00.790 --> 00:24:01.980
is going to do for you.

00:24:01.980 --> 00:24:03.330
And this is just one dimension.

00:24:03.330 --> 00:24:05.120
Imagine if we're in
100-dimensional space

00:24:05.120 --> 00:24:07.590
or 1,000-dimensional space,
we have noisy examples,

00:24:07.590 --> 00:24:10.610
we just can't trust that it's
going to do the right thing

00:24:10.610 --> 00:24:13.080
just because we throw a
lot of noisy samples at it.

00:24:13.080 --> 00:24:14.360
So what can we do?

00:24:14.360 --> 00:24:17.310
Well, we can try to learn
monotonic functions.

00:24:17.310 --> 00:24:19.360
It turns out that
this is hard and slow.

00:24:19.360 --> 00:24:21.710
One of the oldest techniques,
isotonic regression,

00:24:21.710 --> 00:24:23.730
is o of n to the
fourth complexity.

00:24:23.730 --> 00:24:26.610
Anyone ever run an o to
the n four algorithm?

00:24:26.610 --> 00:24:28.900
Probably not.

00:24:28.900 --> 00:24:30.489
And it dates back a while.

00:24:30.489 --> 00:24:31.780
This is some related work here.

00:24:31.780 --> 00:24:33.617
The top line there
is a 1993 paper,

00:24:33.617 --> 00:24:35.200
one of the first
papers trying to make

00:24:35.200 --> 00:24:37.460
a neural net be monotonic.

00:24:37.460 --> 00:24:39.960
And all these papers here
use very tiny data sets

00:24:39.960 --> 00:24:41.980
and very few number
features because it's really

00:24:41.980 --> 00:24:43.510
computationally challenging.

00:24:43.510 --> 00:24:46.010
So at Google, we've developed
some new techniques for this.

00:24:46.010 --> 00:24:49.640
And our new solution is
actually a very old solution.

00:24:49.640 --> 00:24:51.390
And you guys might
remember these

00:24:51.390 --> 00:24:53.520
from math class trigonometry.

00:24:53.520 --> 00:24:55.260
You go the back
of your textbook.

00:24:55.260 --> 00:24:57.170
And there's a table back there.

00:24:57.170 --> 00:24:58.250
And it's a look up table.

00:24:58.250 --> 00:25:00.140
And you're like, sine of 0.3.

00:25:00.140 --> 00:25:01.390
And you find the closest ones.

00:25:01.390 --> 00:25:03.110
And you interpolate.

00:25:03.110 --> 00:25:04.770
This is from 1619 textbook.

00:25:04.770 --> 00:25:06.710
So this is a very old idea.

00:25:06.710 --> 00:25:07.980
So we're going to do that.

00:25:07.980 --> 00:25:12.280
We're just going to do it
in much higher dimensions.

00:25:12.280 --> 00:25:14.200
So here's an example
just in two dimensions.

00:25:14.200 --> 00:25:15.780
This is a two-by-two
look-up table.

00:25:15.780 --> 00:25:17.560
It only has four parameters.

00:25:17.560 --> 00:25:19.900
And I'm looking at
how far I have to go

00:25:19.900 --> 00:25:21.470
and how good the coffee is.

00:25:21.470 --> 00:25:23.700
And I've got parameter
0, 0, 0.4, and 1.

00:25:23.700 --> 00:25:25.360
Of course, I want
close good coffee.

00:25:25.360 --> 00:25:27.610
And I don't want to go far
even if the coffee is good.

00:25:30.501 --> 00:25:32.750
What's great about this
structure is that because it's

00:25:32.750 --> 00:25:34.116
so structured, it's fast.

00:25:34.116 --> 00:25:35.490
And because it's
so structured, I

00:25:35.490 --> 00:25:37.290
can make it monotonic
pretty easily.

00:25:37.290 --> 00:25:39.660
All I need to do is make
sure that my look-up table

00:25:39.660 --> 00:25:40.840
parameters are increasing.

00:25:40.840 --> 00:25:43.130
Then everything in between
them will also increase.

00:25:43.130 --> 00:25:48.340
So this is easy to check and
relatively easy to constrain.

00:25:48.340 --> 00:25:50.370
And how do we actually
learn those values?

00:25:50.370 --> 00:25:52.437
Well, this isn't trig
class, so we're not just

00:25:52.437 --> 00:25:53.770
going to learn sine and cosines.

00:25:53.770 --> 00:25:55.005
We're going to learn from
examples because this

00:25:55.005 --> 00:25:55.900
is machine learning.

00:25:55.900 --> 00:25:58.010
So we're going to go out and get
some examples of happy people

00:25:58.010 --> 00:25:58.720
with coffee.

00:25:58.720 --> 00:26:01.095
And then we're going to say,
how do we fit this function,

00:26:01.095 --> 00:26:03.700
fit these values so the look-up
table matches your examples?

00:26:03.700 --> 00:26:07.149
And this is just like any
other function learning.

00:26:07.149 --> 00:26:09.190
In fact, we solve it with
another structural risk

00:26:09.190 --> 00:26:12.110
minimization just like you would
lots of other machine learning

00:26:12.110 --> 00:26:12.950
systems.

00:26:12.950 --> 00:26:14.370
You're going to iterate
through all your examples,

00:26:14.370 --> 00:26:15.590
try to get the loss right.

00:26:15.590 --> 00:26:16.634
There's some regularizer.

00:26:16.634 --> 00:26:19.050
And what's new here is that
we have a bunch of constraints

00:26:19.050 --> 00:26:21.507
to enforce that
monotonicity for features

00:26:21.507 --> 00:26:23.090
that humans think
should be monotonic.

00:26:23.090 --> 00:26:24.370
You don't have to do
it for everything,

00:26:24.370 --> 00:26:26.260
but you're like, hey,
distance, you guys make

00:26:26.260 --> 00:26:27.660
sure it's monotonic.

00:26:27.660 --> 00:26:32.970
And those linear inequalities,
they don't look bad up there.

00:26:32.970 --> 00:26:35.870
But in practice, it turns out to
be around 100,000 or maybe even

00:26:35.870 --> 00:26:37.453
1 million of those
linear inequalities

00:26:37.453 --> 00:26:39.470
that we need to enforce
in order to learn

00:26:39.470 --> 00:26:41.100
really big complicated models.

00:26:41.100 --> 00:26:45.170
So you can read more about
the details in a GMR paper

00:26:45.170 --> 00:26:47.329
that's upcoming and in a
[INAUDIBLE] paper that's

00:26:47.329 --> 00:26:49.870
upcoming that focuses on how we
handle all those constraints.

00:26:49.870 --> 00:26:53.880
And you can get those papers
on Archive if you'd like.

00:26:53.880 --> 00:26:55.074
So we can get fancier.

00:26:55.074 --> 00:26:56.740
I showed you a
two-by-two look-up table.

00:26:56.740 --> 00:26:59.090
We can have a much more
flexible model if we just

00:26:59.090 --> 00:27:01.030
have a bigger look-up table.

00:27:01.030 --> 00:27:02.420
We can grow this in dimensions.

00:27:02.420 --> 00:27:04.086
Here's a three-dimensional
look-up table

00:27:04.086 --> 00:27:08.150
on three features, one of which
is categorical in this case.

00:27:08.150 --> 00:27:10.650
This look-up table structure
is going to go as two to the D.

00:27:10.650 --> 00:27:12.690
So at some point we're going
to have some scaling problem.

00:27:12.690 --> 00:27:14.300
But then we just start
to make ensembles.

00:27:14.300 --> 00:27:15.780
Just like you do ensembles
of decision trees,

00:27:15.780 --> 00:27:17.730
we can make ensembles
of look-up tables.

00:27:17.730 --> 00:27:19.990
And we can make cascade
architectures as well.

00:27:19.990 --> 00:27:23.140
So we can now learn incredibly
complicated, but flexible

00:27:23.140 --> 00:27:26.026
monotonic functions if
we want, and very fast

00:27:26.026 --> 00:27:26.942
due to that structure.

00:27:30.410 --> 00:27:32.456
So to get back to
our story, about

00:27:32.456 --> 00:27:34.080
to launch this machine
learning system.

00:27:34.080 --> 00:27:36.294
And someone says,
wait, what's going on?

00:27:36.294 --> 00:27:37.710
How do I know the
machine learning

00:27:37.710 --> 00:27:38.982
is doing the right thing?

00:27:38.982 --> 00:27:41.440
And the wonderful thing is we
knew the machine learning was

00:27:41.440 --> 00:27:43.898
doing the right thing because
we forced it to be monotonic.

00:27:43.898 --> 00:27:45.470
We're like, yeah, don't worry.

00:27:45.470 --> 00:27:48.567
And we took a look at
the data, the features.

00:27:48.567 --> 00:27:49.900
And the features were good, too.

00:27:49.900 --> 00:27:51.483
It really did seem
like there was just

00:27:51.483 --> 00:27:53.310
some set of people
that really wanted

00:27:53.310 --> 00:27:57.805
to watch Korean hip-hop
and Italian animal sounds.

00:27:57.805 --> 00:28:00.180
And as you may have guessed,
the answer is two-year-olds.

00:28:00.180 --> 00:28:02.830
It turned out that these were
popular toilet-training videos

00:28:02.830 --> 00:28:03.840
at the time.

00:28:03.840 --> 00:28:06.880
And that this was a real issue.

00:28:06.880 --> 00:28:08.140
OK, great.

00:28:08.140 --> 00:28:11.250
So that's been our session
on our breakthroughs

00:28:11.250 --> 00:28:12.220
in machine learning.

00:28:12.220 --> 00:28:20.970
[MUSIC PLAYING]

