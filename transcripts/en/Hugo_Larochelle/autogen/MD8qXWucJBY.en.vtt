WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.960 align:start position:0%
 
in<00:00:00.149><c> this</c><00:00:01.050><c> video</c><00:00:01.290><c> we'll</c><00:00:01.530><c> see</c><00:00:01.860><c> an</c><00:00:02.190><c> efficient</c>

00:00:02.960 --> 00:00:02.970 align:start position:0%
in this video we'll see an efficient
 

00:00:02.970 --> 00:00:04.519 align:start position:0%
in this video we'll see an efficient
algorithm<00:00:03.210><c> for</c><00:00:03.570><c> training</c><00:00:03.629><c> a</c><00:00:04.049><c> restricted</c>

00:00:04.519 --> 00:00:04.529 align:start position:0%
algorithm for training a restricted
 

00:00:04.529 --> 00:00:06.470 align:start position:0%
algorithm for training a restricted
Boltzmann<00:00:04.650><c> machine</c><00:00:05.130><c> known</c><00:00:05.549><c> as</c><00:00:05.580><c> contrastive</c>

00:00:06.470 --> 00:00:06.480 align:start position:0%
Boltzmann machine known as contrastive
 

00:00:06.480 --> 00:00:11.270 align:start position:0%
Boltzmann machine known as contrastive
divergence<00:00:08.570><c> so</c><00:00:09.570><c> we've</c><00:00:09.780><c> seen</c><00:00:10.139><c> there's</c><00:00:11.010><c> the</c>

00:00:11.270 --> 00:00:11.280 align:start position:0%
divergence so we've seen there's the
 

00:00:11.280 --> 00:00:13.009 align:start position:0%
divergence so we've seen there's the
post<00:00:11.730><c> machine</c><00:00:12.150><c> how</c><00:00:12.300><c> it</c><00:00:12.420><c> defines</c><00:00:12.570><c> the</c>

00:00:13.009 --> 00:00:13.019 align:start position:0%
post machine how it defines the
 

00:00:13.019 --> 00:00:15.140 align:start position:0%
post machine how it defines the
distribution<00:00:13.679><c> over</c><00:00:13.830><c> X</c><00:00:14.280><c> and</c><00:00:14.639><c> it's</c><00:00:14.940><c> hidden</c>

00:00:15.140 --> 00:00:15.150 align:start position:0%
distribution over X and it's hidden
 

00:00:15.150 --> 00:00:18.470 align:start position:0%
distribution over X and it's hidden
layer<00:00:15.420><c> H</c><00:00:15.750><c> we've</c><00:00:16.590><c> seen</c><00:00:16.859><c> that</c><00:00:17.190><c> we</c><00:00:18.150><c> could</c><00:00:18.330><c> also</c>

00:00:18.470 --> 00:00:18.480 align:start position:0%
layer H we've seen that we could also
 

00:00:18.480 --> 00:00:22.340 align:start position:0%
layer H we've seen that we could also
write<00:00:18.660><c> down</c><00:00:18.900><c> P</c><00:00:19.529><c> of</c><00:00:19.740><c> X</c><00:00:20.660><c> using</c><00:00:21.660><c> the</c><00:00:21.869><c> free</c>

00:00:22.340 --> 00:00:22.350 align:start position:0%
write down P of X using the free
 

00:00:22.350 --> 00:00:25.790 align:start position:0%
write down P of X using the free
energies<00:00:22.740><c> and</c><00:00:23.070><c> we've</c><00:00:23.369><c> looked</c><00:00:23.820><c> at</c><00:00:24.029><c> how</c><00:00:25.019><c> exactly</c>

00:00:25.790 --> 00:00:25.800 align:start position:0%
energies and we've looked at how exactly
 

00:00:25.800 --> 00:00:27.410 align:start position:0%
energies and we've looked at how exactly
it<00:00:26.070><c> tries</c><00:00:26.310><c> to</c><00:00:26.340><c> model</c><00:00:26.939><c> and</c><00:00:27.119><c> increase</c>

00:00:27.410 --> 00:00:27.420 align:start position:0%
it tries to model and increase
 

00:00:27.420 --> 00:00:29.599 align:start position:0%
it tries to model and increase
probability<00:00:28.109><c> for</c><00:00:28.289><c> certain</c><00:00:28.560><c> values</c><00:00:28.710><c> of</c><00:00:28.980><c> the</c>

00:00:29.599 --> 00:00:29.609 align:start position:0%
probability for certain values of the
 

00:00:29.609 --> 00:00:32.810 align:start position:0%
probability for certain values of the
input<00:00:29.880><c> vector</c><00:00:30.060><c> let's</c><00:00:30.990><c> actually</c><00:00:31.170><c> see</c><00:00:31.619><c> how</c><00:00:31.859><c> we</c>

00:00:32.810 --> 00:00:32.820 align:start position:0%
input vector let's actually see how we
 

00:00:32.820 --> 00:00:34.430 align:start position:0%
input vector let's actually see how we
can<00:00:33.059><c> actually</c><00:00:33.239><c> train</c><00:00:33.780><c> the</c><00:00:34.050><c> restricted</c>

00:00:34.430 --> 00:00:34.440 align:start position:0%
can actually train the restricted
 

00:00:34.440 --> 00:00:36.190 align:start position:0%
can actually train the restricted
Boltzmann<00:00:34.770><c> machine</c><00:00:35.010><c> on</c><00:00:35.219><c> some</c><00:00:35.670><c> training</c><00:00:36.000><c> data</c>

00:00:36.190 --> 00:00:36.200 align:start position:0%
Boltzmann machine on some training data
 

00:00:36.200 --> 00:00:38.540 align:start position:0%
Boltzmann machine on some training data
in<00:00:37.200><c> order</c><00:00:37.380><c> to</c><00:00:37.530><c> obtain</c><00:00:37.739><c> a</c><00:00:37.980><c> restricted</c>

00:00:38.540 --> 00:00:38.550 align:start position:0%
in order to obtain a restricted
 

00:00:38.550 --> 00:00:40.069 align:start position:0%
in order to obtain a restricted
Boltzmann<00:00:38.820><c> machine</c><00:00:39.030><c> that</c><00:00:39.180><c> models</c><00:00:39.600><c> well</c><00:00:39.809><c> that</c>

00:00:40.069 --> 00:00:40.079 align:start position:0%
Boltzmann machine that models well that
 

00:00:40.079 --> 00:00:44.410 align:start position:0%
Boltzmann machine that models well that
data<00:00:40.410><c> and</c><00:00:40.739><c> assigns</c><00:00:41.340><c> high</c><00:00:41.520><c> probability</c><00:00:42.210><c> to</c><00:00:42.390><c> it</c>

00:00:44.410 --> 00:00:44.420 align:start position:0%
data and assigns high probability to it
 

00:00:44.420 --> 00:00:48.020 align:start position:0%
data and assigns high probability to it
so<00:00:45.420><c> like</c><00:00:45.989><c> we've</c><00:00:46.170><c> seen</c><00:00:46.379><c> before</c><00:00:46.980><c> we'll</c><00:00:47.579><c> treat</c>

00:00:48.020 --> 00:00:48.030 align:start position:0%
so like we've seen before we'll treat
 

00:00:48.030 --> 00:00:50.389 align:start position:0%
so like we've seen before we'll treat
this<00:00:48.239><c> problem</c><00:00:48.510><c> of</c><00:00:48.840><c> training</c><00:00:49.320><c> as</c><00:00:49.530><c> an</c><00:00:50.039><c> empirical</c>

00:00:50.389 --> 00:00:50.399 align:start position:0%
this problem of training as an empirical
 

00:00:50.399 --> 00:00:53.930 align:start position:0%
this problem of training as an empirical
Muniz<00:00:51.000><c> asian</c><00:00:51.270><c> problem</c><00:00:51.890><c> we'll</c><00:00:52.890><c> do</c><00:00:53.460><c> without</c><00:00:53.640><c> the</c>

00:00:53.930 --> 00:00:53.940 align:start position:0%
Muniz asian problem we'll do without the
 

00:00:53.940 --> 00:00:56.270 align:start position:0%
Muniz asian problem we'll do without the
regularization<00:00:54.329><c> here</c><00:00:54.960><c> and</c><00:00:55.110><c> just</c><00:00:55.320><c> try</c><00:00:56.250><c> to</c>

00:00:56.270 --> 00:00:56.280 align:start position:0%
regularization here and just try to
 

00:00:56.280 --> 00:00:59.779 align:start position:0%
regularization here and just try to
minimize<00:00:56.879><c> the</c><00:00:57.739><c> average</c><00:00:58.739><c> loss</c><00:00:59.129><c> where</c><00:00:59.430><c> the</c><00:00:59.579><c> loss</c>

00:00:59.779 --> 00:00:59.789 align:start position:0%
minimize the average loss where the loss
 

00:00:59.789 --> 00:01:01.849 align:start position:0%
minimize the average loss where the loss
is<00:01:00.120><c> going</c><00:01:00.329><c> to</c><00:01:00.449><c> be</c><00:01:00.690><c> the</c><00:01:01.020><c> most</c><00:01:01.230><c> natural</c><00:01:01.649><c> thing</c>

00:01:01.849 --> 00:01:01.859 align:start position:0%
is going to be the most natural thing
 

00:01:01.859 --> 00:01:04.789 align:start position:0%
is going to be the most natural thing
here<00:01:02.190><c> to</c><00:01:02.370><c> do</c><00:01:02.640><c> which</c><00:01:03.510><c> is</c><00:01:03.629><c> to</c><00:01:03.750><c> use</c><00:01:03.930><c> the</c><00:01:04.199><c> negative</c>

00:01:04.789 --> 00:01:04.799 align:start position:0%
here to do which is to use the negative
 

00:01:04.799 --> 00:01:07.969 align:start position:0%
here to do which is to use the negative
log<00:01:05.299><c> probability</c><00:01:06.299><c> as</c><00:01:06.510><c> our</c><00:01:07.229><c> loss</c><00:01:07.560><c> for</c><00:01:07.830><c> this</c>

00:01:07.969 --> 00:01:07.979 align:start position:0%
log probability as our loss for this
 

00:01:07.979 --> 00:01:10.670 align:start position:0%
log probability as our loss for this
model<00:01:08.479><c> and</c><00:01:09.479><c> so</c><00:01:09.630><c> what</c><00:01:09.810><c> we'd</c><00:01:09.960><c> like</c><00:01:10.170><c> to</c><00:01:10.229><c> do</c><00:01:10.470><c> is</c>

00:01:10.670 --> 00:01:10.680 align:start position:0%
model and so what we'd like to do is
 

00:01:10.680 --> 00:01:13.940 align:start position:0%
model and so what we'd like to do is
optimize<00:01:11.580><c> this</c><00:01:11.939><c> average</c><00:01:12.740><c> negative</c><00:01:13.740><c> log</c>

00:01:13.940 --> 00:01:13.950 align:start position:0%
optimize this average negative log
 

00:01:13.950 --> 00:01:16.820 align:start position:0%
optimize this average negative log
probability<00:01:14.670><c> of</c><00:01:14.970><c> the</c><00:01:15.150><c> training</c><00:01:15.479><c> data</c><00:01:15.830><c> using</c>

00:01:16.820 --> 00:01:16.830 align:start position:0%
probability of the training data using
 

00:01:16.830 --> 00:01:18.830 align:start position:0%
probability of the training data using
an<00:01:16.920><c> optimization</c><00:01:17.490><c> procedure</c><00:01:17.670><c> in</c><00:01:18.240><c> particular</c>

00:01:18.830 --> 00:01:18.840 align:start position:0%
an optimization procedure in particular
 

00:01:18.840 --> 00:01:20.120 align:start position:0%
an optimization procedure in particular
we'd<00:01:18.960><c> like</c><00:01:19.110><c> to</c><00:01:19.229><c> use</c><00:01:19.350><c> to</c><00:01:19.500><c> cast</c><00:01:19.650><c> a</c><00:01:19.799><c> gradient</c>

00:01:20.120 --> 00:01:20.130 align:start position:0%
we'd like to use to cast a gradient
 

00:01:20.130 --> 00:01:22.249 align:start position:0%
we'd like to use to cast a gradient
descent<00:01:20.490><c> because</c><00:01:20.700><c> works</c><00:01:21.390><c> well</c><00:01:21.659><c> and</c><00:01:21.930><c> scales</c>

00:01:22.249 --> 00:01:22.259 align:start position:0%
descent because works well and scales
 

00:01:22.259 --> 00:01:24.890 align:start position:0%
descent because works well and scales
well<00:01:22.500><c> to</c><00:01:22.680><c> large</c><00:01:22.799><c> data</c><00:01:23.070><c> sets</c><00:01:23.460><c> and</c><00:01:23.700><c> so</c><00:01:24.210><c> it</c><00:01:24.570><c> means</c>

00:01:24.890 --> 00:01:24.900 align:start position:0%
well to large data sets and so it means
 

00:01:24.900 --> 00:01:27.710 align:start position:0%
well to large data sets and so it means
that<00:01:25.080><c> to</c><00:01:25.799><c> achieve</c><00:01:26.040><c> this</c><00:01:26.220><c> I</c><00:01:26.400><c> need</c><00:01:26.610><c> the</c><00:01:27.119><c> partial</c>

00:01:27.710 --> 00:01:27.720 align:start position:0%
that to achieve this I need the partial
 

00:01:27.720 --> 00:01:30.350 align:start position:0%
that to achieve this I need the partial
derivative<00:01:28.080><c> of</c><00:01:28.200><c> any</c><00:01:28.470><c> parameter</c><00:01:29.040><c> theta</c><00:01:29.310><c> of</c><00:01:29.670><c> my</c>

00:01:30.350 --> 00:01:30.360 align:start position:0%
derivative of any parameter theta of my
 

00:01:30.360 --> 00:01:33.350 align:start position:0%
derivative of any parameter theta of my
loss<00:01:30.630><c> now</c><00:01:31.619><c> if</c><00:01:31.740><c> I</c><00:01:31.860><c> make</c><00:01:32.100><c> the</c><00:01:32.520><c> derivation</c><00:01:33.090><c> and</c>

00:01:33.350 --> 00:01:33.360 align:start position:0%
loss now if I make the derivation and
 

00:01:33.360 --> 00:01:35.690 align:start position:0%
loss now if I make the derivation and
write<00:01:33.509><c> down</c><00:01:33.659><c> the</c><00:01:33.810><c> expression</c><00:01:34.290><c> for</c><00:01:34.320><c> it</c><00:01:34.700><c> it</c>

00:01:35.690 --> 00:01:35.700 align:start position:0%
write down the expression for it it
 

00:01:35.700 --> 00:01:38.330 align:start position:0%
write down the expression for it it
actually<00:01:35.850><c> has</c><00:01:36.180><c> a</c><00:01:36.450><c> an</c><00:01:37.170><c> expression</c><00:01:37.380><c> which</c><00:01:37.799><c> looks</c>

00:01:38.330 --> 00:01:38.340 align:start position:0%
actually has a an expression which looks
 

00:01:38.340 --> 00:01:40.190 align:start position:0%
actually has a an expression which looks
kind<00:01:38.670><c> of</c><00:01:38.729><c> similar</c><00:01:39.119><c> to</c><00:01:39.150><c> other</c><00:01:39.659><c> things</c><00:01:40.020><c> we've</c>

00:01:40.190 --> 00:01:40.200 align:start position:0%
kind of similar to other things we've
 

00:01:40.200 --> 00:01:41.929 align:start position:0%
kind of similar to other things we've
seen<00:01:40.439><c> before</c><00:01:40.650><c> in</c><00:01:41.159><c> terms</c><00:01:41.280><c> of</c><00:01:41.520><c> partial</c>

00:01:41.929 --> 00:01:41.939 align:start position:0%
seen before in terms of partial
 

00:01:41.939 --> 00:01:43.789 align:start position:0%
seen before in terms of partial
derivatives<00:01:42.030><c> of</c><00:01:42.509><c> parameters</c><00:01:43.049><c> for</c><00:01:43.290><c> neural</c>

00:01:43.789 --> 00:01:43.799 align:start position:0%
derivatives of parameters for neural
 

00:01:43.799 --> 00:01:46.219 align:start position:0%
derivatives of parameters for neural
networks<00:01:43.860><c> we</c><00:01:44.790><c> have</c><00:01:44.909><c> again</c><00:01:45.180><c> a</c><00:01:45.360><c> difference</c><00:01:46.020><c> of</c>

00:01:46.219 --> 00:01:46.229 align:start position:0%
networks we have again a difference of
 

00:01:46.229 --> 00:01:48.889 align:start position:0%
networks we have again a difference of
two<00:01:47.189><c> terms</c><00:01:47.220><c> one</c><00:01:47.820><c> which</c><00:01:48.090><c> depends</c><00:01:48.750><c> on</c><00:01:48.840><c> the</c>

00:01:48.889 --> 00:01:48.899 align:start position:0%
two terms one which depends on the
 

00:01:48.899 --> 00:01:50.690 align:start position:0%
two terms one which depends on the
observation<00:01:49.619><c> and</c><00:01:49.799><c> another</c><00:01:50.189><c> one</c><00:01:50.430><c> which</c>

00:01:50.690 --> 00:01:50.700 align:start position:0%
observation and another one which
 

00:01:50.700 --> 00:01:53.480 align:start position:0%
observation and another one which
depends<00:01:51.299><c> on</c><00:01:51.360><c> more</c><00:01:52.079><c> explicitly</c><00:01:52.590><c> only</c><00:01:53.220><c> on</c><00:01:53.369><c> the</c>

00:01:53.480 --> 00:01:53.490 align:start position:0%
depends on more explicitly only on the
 

00:01:53.490 --> 00:01:56.450 align:start position:0%
depends on more explicitly only on the
model<00:01:53.850><c> and</c><00:01:54.320><c> so</c><00:01:55.320><c> this</c><00:01:55.590><c> partial</c><00:01:56.009><c> derivative</c><00:01:56.070><c> is</c>

00:01:56.450 --> 00:01:56.460 align:start position:0%
model and so this partial derivative is
 

00:01:56.460 --> 00:02:00.490 align:start position:0%
model and so this partial derivative is
going<00:01:56.610><c> to</c><00:01:56.729><c> be</c><00:01:56.820><c> the</c><00:01:57.920><c> expec</c><00:01:58.920><c> expectation</c><00:01:59.790><c> over</c>

00:02:00.490 --> 00:02:00.500 align:start position:0%
going to be the expec expectation over
 

00:02:00.500 --> 00:02:03.560 align:start position:0%
going to be the expec expectation over
what<00:02:01.500><c> we</c><00:02:01.860><c> never</c><00:02:02.219><c> see</c><00:02:02.520><c> which</c><00:02:02.670><c> is</c><00:02:02.880><c> the</c><00:02:03.149><c> hidden</c>

00:02:03.560 --> 00:02:03.570 align:start position:0%
what we never see which is the hidden
 

00:02:03.570 --> 00:02:06.950 align:start position:0%
what we never see which is the hidden
layer<00:02:03.750><c> value</c><00:02:04.200><c> of</c><00:02:04.460><c> the</c><00:02:05.460><c> partial</c><00:02:06.060><c> derivative</c><00:02:06.810><c> of</c>

00:02:06.950 --> 00:02:06.960 align:start position:0%
layer value of the partial derivative of
 

00:02:06.960 --> 00:02:08.889 align:start position:0%
layer value of the partial derivative of
the<00:02:07.200><c> energy</c><00:02:07.320><c> with</c><00:02:07.560><c> respect</c><00:02:07.710><c> to</c><00:02:08.099><c> my</c><00:02:08.220><c> parameter</c>

00:02:08.889 --> 00:02:08.899 align:start position:0%
the energy with respect to my parameter
 

00:02:08.899 --> 00:02:13.610 align:start position:0%
the energy with respect to my parameter
given<00:02:09.899><c> my</c><00:02:10.470><c> observation</c><00:02:11.220><c> so</c><00:02:11.640><c> and</c><00:02:11.940><c> expect</c>

00:02:13.610 --> 00:02:13.620 align:start position:0%
given my observation so and expect
 

00:02:13.620 --> 00:02:15.770 align:start position:0%
given my observation so and expect
partial<00:02:14.220><c> derivative</c><00:02:14.640><c> we</c><00:02:15.420><c> have</c><00:02:15.450><c> to</c><00:02:15.630><c> need</c><00:02:15.720><c> an</c>

00:02:15.770 --> 00:02:15.780 align:start position:0%
partial derivative we have to need an
 

00:02:15.780 --> 00:02:17.780 align:start position:0%
partial derivative we have to need an
expectation<00:02:16.050><c> because</c><00:02:16.620><c> H</c><00:02:16.890><c> we</c><00:02:16.920><c> never</c><00:02:17.400><c> know</c><00:02:17.580><c> what</c>

00:02:17.780 --> 00:02:17.790 align:start position:0%
expectation because H we never know what
 

00:02:17.790 --> 00:02:18.800 align:start position:0%
expectation because H we never know what
its<00:02:17.940><c> value</c><00:02:18.120><c> is</c>

00:02:18.800 --> 00:02:18.810 align:start position:0%
its value is
 

00:02:18.810 --> 00:02:22.310 align:start position:0%
its value is
and<00:02:19.280><c> so</c><00:02:20.280><c> it's</c><00:02:20.430><c> the</c><00:02:20.900><c> expectation</c><00:02:21.900><c> of</c><00:02:22.140><c> this</c>

00:02:22.310 --> 00:02:22.320 align:start position:0%
and so it's the expectation of this
 

00:02:22.320 --> 00:02:23.990 align:start position:0%
and so it's the expectation of this
partial<00:02:22.680><c> derivative</c><00:02:22.770><c> condition</c><00:02:23.760><c> on</c><00:02:23.880><c> the</c>

00:02:23.990 --> 00:02:24.000 align:start position:0%
partial derivative condition on the
 

00:02:24.000 --> 00:02:26.960 align:start position:0%
partial derivative condition on the
observation<00:02:24.630><c> and</c><00:02:24.950><c> then</c><00:02:25.950><c> we</c><00:02:26.100><c> subtract</c><00:02:26.640><c> that</c>

00:02:26.960 --> 00:02:26.970 align:start position:0%
observation and then we subtract that
 

00:02:26.970 --> 00:02:30.530 align:start position:0%
observation and then we subtract that
the<00:02:27.810><c> expectation</c><00:02:28.620><c> over</c><00:02:29.190><c> H</c><00:02:29.400><c> and</c><00:02:29.670><c> I</c><00:02:29.940><c> and</c><00:02:30.360><c> now</c>

00:02:30.530 --> 00:02:30.540 align:start position:0%
the expectation over H and I and now
 

00:02:30.540 --> 00:02:35.090 align:start position:0%
the expectation over H and I and now
also<00:02:30.990><c> X</c><00:02:31.460><c> of</c><00:02:32.460><c> the</c><00:02:32.940><c> again</c><00:02:33.650><c> the</c><00:02:34.650><c> partial</c>

00:02:35.090 --> 00:02:35.100 align:start position:0%
also X of the again the partial
 

00:02:35.100 --> 00:02:36.770 align:start position:0%
also X of the again the partial
derivitive<00:02:35.370><c> the</c><00:02:35.580><c> energy</c><00:02:36.180><c> function</c><00:02:36.600><c> with</c>

00:02:36.770 --> 00:02:36.780 align:start position:0%
derivitive the energy function with
 

00:02:36.780 --> 00:02:38.630 align:start position:0%
derivitive the energy function with
respect<00:02:37.140><c> to</c><00:02:37.230><c> our</c><00:02:37.320><c> parameter</c><00:02:37.890><c> but</c><00:02:38.310><c> notice</c><00:02:38.610><c> now</c>

00:02:38.630 --> 00:02:38.640 align:start position:0%
respect to our parameter but notice now
 

00:02:38.640 --> 00:02:40.910 align:start position:0%
respect to our parameter but notice now
we<00:02:38.850><c> do</c><00:02:39.060><c> an</c><00:02:39.180><c> expectation</c><00:02:39.450><c> over</c><00:02:39.810><c> X</c><00:02:40.200><c> as</c><00:02:40.380><c> well</c><00:02:40.560><c> and</c>

00:02:40.910 --> 00:02:40.920 align:start position:0%
we do an expectation over X as well and
 

00:02:40.920 --> 00:02:44.150 align:start position:0%
we do an expectation over X as well and
this<00:02:41.910><c> is</c><00:02:42.060><c> an</c><00:02:42.180><c> expectation</c><00:02:42.890><c> according</c><00:02:43.890><c> to</c><00:02:44.130><c> our</c>

00:02:44.150 --> 00:02:44.160 align:start position:0%
this is an expectation according to our
 

00:02:44.160 --> 00:02:48.070 align:start position:0%
this is an expectation according to our
model<00:02:44.460><c> so</c><00:02:44.820><c> under</c><00:02:45.150><c> our</c><00:02:45.180><c> models</c><00:02:46.100><c> distribution</c>

00:02:48.070 --> 00:02:48.080 align:start position:0%
model so under our models distribution
 

00:02:48.080 --> 00:02:50.990 align:start position:0%
model so under our models distribution
so<00:02:49.080><c> we</c><00:02:49.110><c> often</c><00:02:49.380><c> refer</c><00:02:49.650><c> to</c><00:02:49.950><c> that</c><00:02:50.100><c> part</c><00:02:50.460><c> computing</c>

00:02:50.990 --> 00:02:51.000 align:start position:0%
so we often refer to that part computing
 

00:02:51.000 --> 00:02:53.540 align:start position:0%
so we often refer to that part computing
this<00:02:51.150><c> part</c><00:02:51.420><c> of</c><00:02:51.510><c> the</c><00:02:51.950><c> gradient</c><00:02:52.950><c> as</c><00:02:53.130><c> the</c>

00:02:53.540 --> 00:02:53.550 align:start position:0%
this part of the gradient as the
 

00:02:53.550 --> 00:02:55.760 align:start position:0%
this part of the gradient as the
positive<00:02:54.060><c> phase</c><00:02:54.240><c> and</c><00:02:54.540><c> this</c><00:02:54.840><c> the</c><00:02:55.380><c> negative</c>

00:02:55.760 --> 00:02:55.770 align:start position:0%
positive phase and this the negative
 

00:02:55.770 --> 00:02:59.510 align:start position:0%
positive phase and this the negative
phase<00:02:55.980><c> for</c><00:02:56.310><c> obvious</c><00:02:56.820><c> reasons</c><00:02:57.210><c> and</c><00:02:58.430><c> but</c><00:02:59.430><c> now</c>

00:02:59.510 --> 00:02:59.520 align:start position:0%
phase for obvious reasons and but now
 

00:02:59.520 --> 00:03:02.750 align:start position:0%
phase for obvious reasons and but now
the<00:02:59.580><c> problem</c><00:02:59.910><c> is</c><00:03:00.240><c> that</c><00:03:00.830><c> this</c><00:03:01.830><c> part</c><00:03:02.340><c> here</c><00:03:02.430><c> is</c>

00:03:02.750 --> 00:03:02.760 align:start position:0%
the problem is that this part here is
 

00:03:02.760 --> 00:03:04.940 align:start position:0%
the problem is that this part here is
actually<00:03:03.360><c> hard</c><00:03:03.690><c> to</c><00:03:03.780><c> compute</c><00:03:04.170><c> it's</c><00:03:04.380><c> generally</c>

00:03:04.940 --> 00:03:04.950 align:start position:0%
actually hard to compute it's generally
 

00:03:04.950 --> 00:03:08.090 align:start position:0%
actually hard to compute it's generally
intractable<00:03:05.340><c> and</c><00:03:06.150><c> the</c><00:03:06.570><c> reason</c><00:03:06.930><c> is</c><00:03:07.140><c> that</c><00:03:07.170><c> we</c>

00:03:08.090 --> 00:03:08.100 align:start position:0%
intractable and the reason is that we
 

00:03:08.100 --> 00:03:10.130 align:start position:0%
intractable and the reason is that we
have<00:03:08.220><c> to</c><00:03:08.400><c> make</c><00:03:08.730><c> an</c><00:03:08.970><c> exponential</c><00:03:09.600><c> sum</c><00:03:09.870><c> over</c>

00:03:10.130 --> 00:03:10.140 align:start position:0%
have to make an exponential sum over
 

00:03:10.140 --> 00:03:14.960 align:start position:0%
have to make an exponential sum over
both<00:03:10.380><c> H</c><00:03:10.680><c> and</c><00:03:11.130><c> X</c><00:03:11.400><c> and</c><00:03:11.670><c> so</c><00:03:12.890><c> perhaps</c><00:03:13.890><c> you'll</c><00:03:14.370><c> be</c>

00:03:14.960 --> 00:03:14.970 align:start position:0%
both H and X and so perhaps you'll be
 

00:03:14.970 --> 00:03:17.210 align:start position:0%
both H and X and so perhaps you'll be
convinced<00:03:15.510><c> that</c><00:03:15.570><c> if</c><00:03:15.900><c> I</c><00:03:16.230><c> give</c><00:03:16.440><c> you</c><00:03:16.590><c> a</c><00:03:16.620><c> value</c><00:03:16.770><c> of</c>

00:03:17.210 --> 00:03:17.220 align:start position:0%
convinced that if I give you a value of
 

00:03:17.220 --> 00:03:19.010 align:start position:0%
convinced that if I give you a value of
the<00:03:17.370><c> visible</c><00:03:17.730><c> layer</c><00:03:17.940><c> so</c><00:03:18.390><c> if</c><00:03:18.480><c> I</c><00:03:18.570><c> give</c><00:03:18.810><c> you</c><00:03:18.930><c> an</c>

00:03:19.010 --> 00:03:19.020 align:start position:0%
the visible layer so if I give you an
 

00:03:19.020 --> 00:03:22.040 align:start position:0%
the visible layer so if I give you an
observation<00:03:19.560><c> X</c><00:03:19.770><c> then</c><00:03:20.430><c> summing</c><00:03:21.330><c> over</c><00:03:21.420><c> H</c><00:03:21.780><c> is</c>

00:03:22.040 --> 00:03:22.050 align:start position:0%
observation X then summing over H is
 

00:03:22.050 --> 00:03:24.320 align:start position:0%
observation X then summing over H is
actually<00:03:22.530><c> something</c><00:03:23.280><c> that's</c><00:03:23.460><c> tractable</c><00:03:23.910><c> to</c>

00:03:24.320 --> 00:03:24.330 align:start position:0%
actually something that's tractable to
 

00:03:24.330 --> 00:03:27.110 align:start position:0%
actually something that's tractable to
do<00:03:24.560><c> for</c><00:03:25.560><c> this</c><00:03:26.130><c> partial</c><00:03:26.550><c> derivative</c><00:03:26.610><c> in</c>

00:03:27.110 --> 00:03:27.120 align:start position:0%
do for this partial derivative in
 

00:03:27.120 --> 00:03:29.690 align:start position:0%
do for this partial derivative in
particular<00:03:27.450><c> for</c><00:03:27.690><c> the</c><00:03:27.840><c> RB</c><00:03:28.110><c> m</c><00:03:28.280><c> and</c><00:03:29.280><c> E</c><00:03:29.370><c> we</c><00:03:29.550><c> can</c>

00:03:29.690 --> 00:03:29.700 align:start position:0%
particular for the RB m and E we can
 

00:03:29.700 --> 00:03:31.610 align:start position:0%
particular for the RB m and E we can
again<00:03:29.940><c> leverage</c><00:03:30.330><c> the</c><00:03:30.480><c> fact</c><00:03:30.750><c> that</c><00:03:30.870><c> we</c><00:03:31.380><c> get</c><00:03:31.500><c> an</c>

00:03:31.610 --> 00:03:31.620 align:start position:0%
again leverage the fact that we get an
 

00:03:31.620 --> 00:03:36.980 align:start position:0%
again leverage the fact that we get an
expression<00:03:31.830><c> of</c><00:03:32.930><c> nested</c><00:03:33.930><c> ik</c><00:03:34.250><c> nested</c><00:03:35.250><c> sums</c><00:03:35.990><c> over</c>

00:03:36.980 --> 00:03:36.990 align:start position:0%
expression of nested ik nested sums over
 

00:03:36.990 --> 00:03:38.840 align:start position:0%
expression of nested ik nested sums over
something<00:03:37.440><c> that</c><00:03:37.470><c> factorizes</c><00:03:38.250><c> with</c><00:03:38.520><c> respect</c>

00:03:38.840 --> 00:03:38.850 align:start position:0%
something that factorizes with respect
 

00:03:38.850 --> 00:03:40.790 align:start position:0%
something that factorizes with respect
to<00:03:38.910><c> each</c><00:03:39.030><c> hidden</c><00:03:39.240><c> unit</c><00:03:39.420><c> and</c><00:03:39.780><c> then</c><00:03:39.930><c> we</c><00:03:40.620><c> can</c>

00:03:40.790 --> 00:03:40.800 align:start position:0%
to each hidden unit and then we can
 

00:03:40.800 --> 00:03:42.530 align:start position:0%
to each hidden unit and then we can
actually<00:03:41.130><c> write</c><00:03:41.400><c> this</c><00:03:41.580><c> down</c><00:03:41.850><c> into</c><00:03:42.390><c> an</c>

00:03:42.530 --> 00:03:42.540 align:start position:0%
actually write this down into an
 

00:03:42.540 --> 00:03:43.640 align:start position:0%
actually write this down into an
expression<00:03:42.930><c> that's</c><00:03:43.020><c> linear</c><00:03:43.320><c> in</c><00:03:43.530><c> the</c><00:03:43.620><c> number</c>

00:03:43.640 --> 00:03:43.650 align:start position:0%
expression that's linear in the number
 

00:03:43.650 --> 00:03:46.070 align:start position:0%
expression that's linear in the number
of<00:03:44.010><c> hidden</c><00:03:44.160><c> units</c><00:03:44.280><c> so</c><00:03:44.670><c> we'll</c><00:03:44.820><c> see</c><00:03:45.000><c> that</c><00:03:45.150><c> more</c>

00:03:46.070 --> 00:03:46.080 align:start position:0%
of hidden units so we'll see that more
 

00:03:46.080 --> 00:03:50.210 align:start position:0%
of hidden units so we'll see that more
and<00:03:47.010><c> more</c><00:03:47.070><c> details</c><00:03:47.580><c> later</c><00:03:47.940><c> in</c><00:03:48.090><c> this</c><00:03:48.270><c> video</c><00:03:49.220><c> but</c>

00:03:50.210 --> 00:03:50.220 align:start position:0%
and more details later in this video but
 

00:03:50.220 --> 00:03:52.310 align:start position:0%
and more details later in this video but
now<00:03:50.370><c> if</c><00:03:50.490><c> you</c><00:03:50.550><c> have</c><00:03:50.610><c> to</c><00:03:50.880><c> do</c><00:03:51.210><c> is</c><00:03:51.330><c> sum</c><00:03:51.540><c> over</c><00:03:51.570><c> both</c><00:03:51.990><c> X</c>

00:03:52.310 --> 00:03:52.320 align:start position:0%
now if you have to do is sum over both X
 

00:03:52.320 --> 00:03:55.280 align:start position:0%
now if you have to do is sum over both X
and<00:03:52.770><c> H</c><00:03:53.040><c> now</c><00:03:53.640><c> this</c><00:03:53.850><c> becomes</c><00:03:54.210><c> intractable</c><00:03:54.780><c> and</c>

00:03:55.280 --> 00:03:55.290 align:start position:0%
and H now this becomes intractable and
 

00:03:55.290 --> 00:03:57.380 align:start position:0%
and H now this becomes intractable and
so<00:03:55.800><c> we'll</c><00:03:55.950><c> have</c><00:03:55.980><c> to</c><00:03:56.280><c> approximate</c><00:03:56.550><c> that</c><00:03:57.090><c> term</c>

00:03:57.380 --> 00:03:57.390 align:start position:0%
so we'll have to approximate that term
 

00:03:57.390 --> 00:04:01.820 align:start position:0%
so we'll have to approximate that term
somehow<00:03:58.100><c> in</c><00:03:59.100><c> order</c><00:03:59.280><c> to</c><00:03:59.520><c> perform</c><00:04:00.830><c> stochastic</c>

00:04:01.820 --> 00:04:01.830 align:start position:0%
somehow in order to perform stochastic
 

00:04:01.830 --> 00:04:07.130 align:start position:0%
somehow in order to perform stochastic
gradient<00:04:01.920><c> descent</c><00:04:02.190><c> efficiently</c><00:04:05.330><c> so</c><00:04:06.330><c> to</c>

00:04:07.130 --> 00:04:07.140 align:start position:0%
gradient descent efficiently so to
 

00:04:07.140 --> 00:04:08.030 align:start position:0%
gradient descent efficiently so to
address<00:04:07.410><c> this</c><00:04:07.530><c> problem</c>

00:04:08.030 --> 00:04:08.040 align:start position:0%
address this problem
 

00:04:08.040 --> 00:04:10.460 align:start position:0%
address this problem
Jeff<00:04:08.430><c> fintan</c><00:04:08.790><c> in</c><00:04:09.030><c> 2002</c><00:04:09.690><c> proposed</c><00:04:10.200><c> the</c>

00:04:10.460 --> 00:04:10.470 align:start position:0%
Jeff fintan in 2002 proposed the
 

00:04:10.470 --> 00:04:13.100 align:start position:0%
Jeff fintan in 2002 proposed the
contrastive<00:04:11.430><c> divergence</c><00:04:12.110><c> learning</c>

00:04:13.100 --> 00:04:13.110 align:start position:0%
contrastive divergence learning
 

00:04:13.110 --> 00:04:15.530 align:start position:0%
contrastive divergence learning
algorithm<00:04:13.550><c> so</c><00:04:14.550><c> there's</c><00:04:14.730><c> some</c><00:04:14.910><c> theory</c><00:04:15.270><c> for</c>

00:04:15.530 --> 00:04:15.540 align:start position:0%
algorithm so there's some theory for
 

00:04:15.540 --> 00:04:18.349 align:start position:0%
algorithm so there's some theory for
what<00:04:16.200><c> this</c><00:04:16.350><c> is</c><00:04:16.410><c> actually</c><00:04:16.650><c> doing</c><00:04:17.150><c> I'm</c><00:04:18.150><c> not</c>

00:04:18.349 --> 00:04:18.359 align:start position:0%
what this is actually doing I'm not
 

00:04:18.359 --> 00:04:20.330 align:start position:0%
what this is actually doing I'm not
going<00:04:18.570><c> to</c><00:04:18.630><c> go</c><00:04:18.810><c> over</c><00:04:19.020><c> that</c><00:04:19.350><c> I'm</c><00:04:19.560><c> just</c><00:04:19.799><c> going</c><00:04:20.190><c> to</c>

00:04:20.330 --> 00:04:20.340 align:start position:0%
going to go over that I'm just going to
 

00:04:20.340 --> 00:04:22.640 align:start position:0%
going to go over that I'm just going to
describe<00:04:20.760><c> what</c><00:04:21.210><c> the</c><00:04:21.330><c> algorithm</c><00:04:21.720><c> is</c><00:04:21.870><c> and</c><00:04:22.169><c> the</c>

00:04:22.640 --> 00:04:22.650 align:start position:0%
describe what the algorithm is and the
 

00:04:22.650 --> 00:04:24.860 align:start position:0%
describe what the algorithm is and the
more<00:04:22.830><c> intuitive</c><00:04:23.310><c> terms</c><00:04:23.669><c> and</c>

00:04:24.860 --> 00:04:24.870 align:start position:0%
more intuitive terms and
 

00:04:24.870 --> 00:04:28.040 align:start position:0%
more intuitive terms and
try<00:04:25.260><c> to</c><00:04:25.320><c> give</c><00:04:25.590><c> more</c><00:04:26.340><c> intuition</c><00:04:26.850><c> for</c><00:04:27.180><c> why</c><00:04:27.990><c> it</c>

00:04:28.040 --> 00:04:28.050 align:start position:0%
try to give more intuition for why it
 

00:04:28.050 --> 00:04:30.710 align:start position:0%
try to give more intuition for why it
should<00:04:28.290><c> actually</c><00:04:28.440><c> work</c><00:04:29.270><c> so</c><00:04:30.270><c> really</c><00:04:30.450><c> the</c><00:04:30.690><c> idea</c>

00:04:30.710 --> 00:04:30.720 align:start position:0%
should actually work so really the idea
 

00:04:30.720 --> 00:04:33.680 align:start position:0%
should actually work so really the idea
is<00:04:31.230><c> to</c><00:04:31.380><c> try</c><00:04:31.560><c> to</c><00:04:31.670><c> do</c><00:04:32.670><c> without</c><00:04:32.820><c> this</c><00:04:33.210><c> double</c>

00:04:33.680 --> 00:04:33.690 align:start position:0%
is to try to do without this double
 

00:04:33.690 --> 00:04:36.950 align:start position:0%
is to try to do without this double
expectation<00:04:34.350><c> and</c><00:04:34.880><c> instead</c><00:04:35.880><c> estimated</c><00:04:36.480><c> so</c>

00:04:36.950 --> 00:04:36.960 align:start position:0%
expectation and instead estimated so
 

00:04:36.960 --> 00:04:38.330 align:start position:0%
expectation and instead estimated so
there<00:04:37.200><c> are</c><00:04:37.260><c> really</c><00:04:37.350><c> three</c><00:04:37.800><c> main</c><00:04:38.100><c> components</c>

00:04:38.330 --> 00:04:38.340 align:start position:0%
there are really three main components
 

00:04:38.340 --> 00:04:41.960 align:start position:0%
there are really three main components
to<00:04:39.170><c> contrastive</c><00:04:40.170><c> divergence</c><00:04:40.200><c> the</c><00:04:40.860><c> first</c><00:04:41.580><c> idea</c>

00:04:41.960 --> 00:04:41.970 align:start position:0%
to contrastive divergence the first idea
 

00:04:41.970 --> 00:04:44.750 align:start position:0%
to contrastive divergence the first idea
is<00:04:42.060><c> that</c><00:04:42.330><c> the</c><00:04:42.810><c> expectation</c><00:04:43.410><c> over</c><00:04:43.800><c> X</c><00:04:44.130><c> and</c><00:04:44.370><c> H</c><00:04:44.490><c> in</c>

00:04:44.750 --> 00:04:44.760 align:start position:0%
is that the expectation over X and H in
 

00:04:44.760 --> 00:04:47.270 align:start position:0%
is that the expectation over X and H in
the<00:04:45.030><c> negative</c><00:04:45.540><c> phase</c><00:04:45.750><c> will</c><00:04:46.560><c> actually</c><00:04:47.010><c> replace</c>

00:04:47.270 --> 00:04:47.280 align:start position:0%
the negative phase will actually replace
 

00:04:47.280 --> 00:04:50.630 align:start position:0%
the negative phase will actually replace
it<00:04:47.640><c> by</c><00:04:47.880><c> a</c><00:04:48.180><c> point</c><00:04:48.570><c> estimate</c><00:04:48.720><c> at</c><00:04:49.320><c> a</c><00:04:49.980><c> single</c>

00:04:50.630 --> 00:04:50.640 align:start position:0%
it by a point estimate at a single
 

00:04:50.640 --> 00:04:53.210 align:start position:0%
it by a point estimate at a single
observation<00:04:50.820><c> X</c><00:04:51.540><c> still</c><00:04:51.870><c> so</c><00:04:52.500><c> the</c><00:04:52.680><c> expectation</c>

00:04:53.210 --> 00:04:53.220 align:start position:0%
observation X still so the expectation
 

00:04:53.220 --> 00:04:56.630 align:start position:0%
observation X still so the expectation
over<00:04:53.280><c> X</c><00:04:53.610><c> we'll</c><00:04:53.940><c> replace</c><00:04:54.210><c> it</c><00:04:54.330><c> by</c><00:04:54.720><c> a</c><00:04:55.640><c> point</c>

00:04:56.630 --> 00:04:56.640 align:start position:0%
over X we'll replace it by a point
 

00:04:56.640 --> 00:04:59.150 align:start position:0%
over X we'll replace it by a point
estimate<00:04:56.790><c> at</c><00:04:57.300><c> X</c><00:04:57.720><c> still</c><00:04:57.990><c> because</c><00:04:58.410><c> if</c><00:04:58.920><c> you</c><00:04:59.040><c> have</c>

00:04:59.150 --> 00:04:59.160 align:start position:0%
estimate at X still because if you have
 

00:04:59.160 --> 00:05:00.530 align:start position:0%
estimate at X still because if you have
that<00:04:59.280><c> point</c><00:04:59.580><c> estimate</c><00:04:59.940><c> if</c><00:05:00.060><c> we</c><00:05:00.180><c> give</c><00:05:00.360><c> me</c><00:05:00.510><c> a</c>

00:05:00.530 --> 00:05:00.540 align:start position:0%
that point estimate if we give me a
 

00:05:00.540 --> 00:05:02.150 align:start position:0%
that point estimate if we give me a
value<00:05:00.780><c> of</c><00:05:00.870><c> the</c><00:05:00.930><c> visible</c><00:05:01.260><c> layer</c><00:05:01.440><c> then</c><00:05:01.710><c> I</c><00:05:01.740><c> can</c><00:05:02.010><c> do</c>

00:05:02.150 --> 00:05:02.160 align:start position:0%
value of the visible layer then I can do
 

00:05:02.160 --> 00:05:05.660 align:start position:0%
value of the visible layer then I can do
the<00:05:02.370><c> expectation</c><00:05:03.030><c> over</c><00:05:03.750><c> H</c><00:05:04.380><c> and</c><00:05:04.650><c> then</c><00:05:05.310><c> get</c><00:05:05.550><c> an</c>

00:05:05.660 --> 00:05:05.670 align:start position:0%
the expectation over H and then get an
 

00:05:05.670 --> 00:05:10.910 align:start position:0%
the expectation over H and then get an
estimate<00:05:06.060><c> of</c><00:05:06.210><c> the</c><00:05:06.860><c> double</c><00:05:07.860><c> expectation</c><00:05:09.920><c> so</c>

00:05:10.910 --> 00:05:10.920 align:start position:0%
estimate of the double expectation so
 

00:05:10.920 --> 00:05:12.680 align:start position:0%
estimate of the double expectation so
that's<00:05:11.100><c> just</c><00:05:11.340><c> really</c><00:05:11.520><c> saying</c><00:05:12.090><c> we'll</c><00:05:12.570><c> do</c>

00:05:12.680 --> 00:05:12.690 align:start position:0%
that's just really saying we'll do
 

00:05:12.690 --> 00:05:14.690 align:start position:0%
that's just really saying we'll do
multicolor<00:05:13.170><c> estimate</c><00:05:13.620><c> of</c><00:05:13.860><c> the</c><00:05:14.130><c> expectation</c>

00:05:14.690 --> 00:05:14.700 align:start position:0%
multicolor estimate of the expectation
 

00:05:14.700 --> 00:05:18.620 align:start position:0%
multicolor estimate of the expectation
with<00:05:14.880><c> a</c><00:05:14.910><c> single</c><00:05:15.330><c> data</c><00:05:15.510><c> point</c><00:05:15.920><c> then</c><00:05:16.920><c> we'll</c><00:05:17.880><c> we</c>

00:05:18.620 --> 00:05:18.630 align:start position:0%
with a single data point then we'll we
 

00:05:18.630 --> 00:05:21.740 align:start position:0%
with a single data point then we'll we
need<00:05:18.780><c> to</c><00:05:18.870><c> obtain</c><00:05:19.020><c> that</c><00:05:19.230><c> X</c><00:05:19.740><c> tilt</c><00:05:20.100><c> somehow</c><00:05:20.760><c> and</c>

00:05:21.740 --> 00:05:21.750 align:start position:0%
need to obtain that X tilt somehow and
 

00:05:21.750 --> 00:05:24.200 align:start position:0%
need to obtain that X tilt somehow and
ideally<00:05:22.230><c> we</c><00:05:22.410><c> like</c><00:05:22.440><c> to</c><00:05:22.710><c> sample</c><00:05:23.550><c> from</c><00:05:23.850><c> the</c><00:05:24.000><c> true</c>

00:05:24.200 --> 00:05:24.210 align:start position:0%
ideally we like to sample from the true
 

00:05:24.210 --> 00:05:25.700 align:start position:0%
ideally we like to sample from the true
distribution<00:05:24.540><c> not</c><00:05:25.170><c> the</c><00:05:25.290><c> true</c><00:05:25.440><c> distribution</c>

00:05:25.700 --> 00:05:25.710 align:start position:0%
distribution not the true distribution
 

00:05:25.710 --> 00:05:27.620 align:start position:0%
distribution not the true distribution
but<00:05:26.100><c> our</c><00:05:26.220><c> model</c><00:05:26.490><c> distribution</c><00:05:26.760><c> and</c><00:05:27.420><c> then</c>

00:05:27.620 --> 00:05:27.630 align:start position:0%
but our model distribution and then
 

00:05:27.630 --> 00:05:28.400 align:start position:0%
but our model distribution and then
we'll<00:05:27.780><c> do</c><00:05:27.930><c> this</c><00:05:28.080><c> by</c>

00:05:28.400 --> 00:05:28.410 align:start position:0%
we'll do this by
 

00:05:28.410 --> 00:05:31.790 align:start position:0%
we'll do this by
Gibbs<00:05:28.800><c> sampling</c><00:05:29.720><c> so</c><00:05:30.720><c> remember</c><00:05:31.440><c> that</c><00:05:31.470><c> Gibbs</c>

00:05:31.790 --> 00:05:31.800 align:start position:0%
Gibbs sampling so remember that Gibbs
 

00:05:31.800 --> 00:05:35.260 align:start position:0%
Gibbs sampling so remember that Gibbs
sampling<00:05:32.160><c> corresponds</c><00:05:32.670><c> to</c><00:05:33.590><c> sampling</c><00:05:34.590><c> each</c>

00:05:35.260 --> 00:05:35.270 align:start position:0%
sampling corresponds to sampling each
 

00:05:35.270 --> 00:05:39.410 align:start position:0%
sampling corresponds to sampling each
variable<00:05:36.270><c> in</c><00:05:37.070><c> my</c><00:05:38.070><c> model</c><00:05:38.550><c> given</c><00:05:39.030><c> the</c><00:05:39.180><c> others</c>

00:05:39.410 --> 00:05:39.420 align:start position:0%
variable in my model given the others
 

00:05:39.420 --> 00:05:41.810 align:start position:0%
variable in my model given the others
and<00:05:40.160><c> specifically</c><00:05:41.160><c> for</c><00:05:41.340><c> a</c><00:05:41.370><c> restricted</c>

00:05:41.810 --> 00:05:41.820 align:start position:0%
and specifically for a restricted
 

00:05:41.820 --> 00:05:43.220 align:start position:0%
and specifically for a restricted
Boltzmann<00:05:42.090><c> machine</c><00:05:42.390><c> performing</c><00:05:43.110><c> that</c>

00:05:43.220 --> 00:05:43.230 align:start position:0%
Boltzmann machine performing that
 

00:05:43.230 --> 00:05:44.930 align:start position:0%
Boltzmann machine performing that
sampling<00:05:43.590><c> is</c><00:05:43.710><c> actually</c><00:05:43.980><c> quite</c><00:05:44.190><c> as</c><00:05:44.340><c> efficient</c>

00:05:44.930 --> 00:05:44.940 align:start position:0%
sampling is actually quite as efficient
 

00:05:44.940 --> 00:05:47.150 align:start position:0%
sampling is actually quite as efficient
because<00:05:45.230><c> conditioned</c><00:05:46.230><c> on</c><00:05:46.380><c> one</c><00:05:46.560><c> layer</c><00:05:46.740><c> all</c><00:05:47.100><c> the</c>

00:05:47.150 --> 00:05:47.160 align:start position:0%
because conditioned on one layer all the
 

00:05:47.160 --> 00:05:49.460 align:start position:0%
because conditioned on one layer all the
other<00:05:47.520><c> elements</c><00:05:48.000><c> in</c><00:05:48.090><c> the</c><00:05:48.120><c> other</c><00:05:48.300><c> layer</c><00:05:48.540><c> are</c>

00:05:49.460 --> 00:05:49.470 align:start position:0%
other elements in the other layer are
 

00:05:49.470 --> 00:05:52.700 align:start position:0%
other elements in the other layer are
independent<00:05:50.070><c> then</c><00:05:50.550><c> I</c><00:05:50.700><c> can</c><00:05:51.000><c> sample</c><00:05:51.900><c> all</c><00:05:52.230><c> the</c>

00:05:52.700 --> 00:05:52.710 align:start position:0%
independent then I can sample all the
 

00:05:52.710 --> 00:05:55.100 align:start position:0%
independent then I can sample all the
values<00:05:53.310><c> in</c><00:05:53.520><c> one</c><00:05:53.760><c> layer</c><00:05:53.940><c> in</c><00:05:54.180><c> parallel</c><00:05:54.600><c> given</c>

00:05:55.100 --> 00:05:55.110 align:start position:0%
values in one layer in parallel given
 

00:05:55.110 --> 00:05:58.160 align:start position:0%
values in one layer in parallel given
the<00:05:55.350><c> value</c><00:05:55.740><c> of</c><00:05:56.030><c> the</c><00:05:57.030><c> opposite</c><00:05:57.630><c> layer</c><00:05:57.810><c> and</c><00:05:58.050><c> then</c>

00:05:58.160 --> 00:05:58.170 align:start position:0%
the value of the opposite layer and then
 

00:05:58.170 --> 00:06:01.130 align:start position:0%
the value of the opposite layer and then
alternate<00:05:58.740><c> between</c><00:05:59.330><c> each</c><00:06:00.330><c> layer</c><00:06:00.660><c> like</c><00:06:00.960><c> this</c>

00:06:01.130 --> 00:06:01.140 align:start position:0%
alternate between each layer like this
 

00:06:01.140 --> 00:06:03.500 align:start position:0%
alternate between each layer like this
and<00:06:01.440><c> so</c><00:06:02.280><c> this</c><00:06:02.430><c> is</c><00:06:02.640><c> actually</c><00:06:02.760><c> very</c><00:06:03.120><c> efficient</c>

00:06:03.500 --> 00:06:03.510 align:start position:0%
and so this is actually very efficient
 

00:06:03.510 --> 00:06:06.590 align:start position:0%
and so this is actually very efficient
to<00:06:03.600><c> do</c><00:06:03.750><c> in</c><00:06:03.900><c> practice</c><00:06:04.110><c> and</c><00:06:05.270><c> then</c><00:06:06.270><c> the</c><00:06:06.390><c> third</c>

00:06:06.590 --> 00:06:06.600 align:start position:0%
to do in practice and then the third
 

00:06:06.600 --> 00:06:08.900 align:start position:0%
to do in practice and then the third
idea<00:06:06.780><c> which</c><00:06:07.140><c> is</c><00:06:07.290><c> perhaps</c><00:06:07.470><c> the</c><00:06:07.800><c> most</c><00:06:08.040><c> important</c>

00:06:08.900 --> 00:06:08.910 align:start position:0%
idea which is perhaps the most important
 

00:06:08.910 --> 00:06:10.220 align:start position:0%
idea which is perhaps the most important
contribution<00:06:09.480><c> behind</c><00:06:09.750><c> contrasted</c>

00:06:10.220 --> 00:06:10.230 align:start position:0%
contribution behind contrasted
 

00:06:10.230 --> 00:06:14.120 align:start position:0%
contribution behind contrasted
divergence<00:06:10.260><c> is</c><00:06:11.240><c> to</c><00:06:12.500><c> perform</c><00:06:13.500><c> Gibbs</c><00:06:13.770><c> sampling</c>

00:06:14.120 --> 00:06:14.130 align:start position:0%
divergence is to perform Gibbs sampling
 

00:06:14.130 --> 00:06:19.190 align:start position:0%
divergence is to perform Gibbs sampling
but<00:06:14.280><c> by</c><00:06:14.460><c> starting</c><00:06:15.180><c> our</c><00:06:15.750><c> sampling</c><00:06:16.650><c> at</c><00:06:17.120><c> a</c><00:06:18.200><c> state</c>

00:06:19.190 --> 00:06:19.200 align:start position:0%
but by starting our sampling at a state
 

00:06:19.200 --> 00:06:22.730 align:start position:0%
but by starting our sampling at a state
where<00:06:19.230><c> the</c><00:06:19.650><c> visible</c><00:06:20.130><c> layer</c><00:06:20.810><c> is</c><00:06:21.810><c> set</c><00:06:22.260><c> to</c><00:06:22.590><c> the</c>

00:06:22.730 --> 00:06:22.740 align:start position:0%
where the visible layer is set to the
 

00:06:22.740 --> 00:06:25.040 align:start position:0%
where the visible layer is set to the
training<00:06:23.190><c> example</c><00:06:23.730><c> for</c><00:06:23.940><c> which</c><00:06:24.090><c> I'm</c><00:06:24.270><c> trying</c><00:06:24.840><c> to</c>

00:06:25.040 --> 00:06:25.050 align:start position:0%
training example for which I'm trying to
 

00:06:25.050 --> 00:06:27.320 align:start position:0%
training example for which I'm trying to
compute<00:06:25.410><c> the</c><00:06:25.650><c> gradient</c><00:06:26.610><c> and</c><00:06:26.760><c> do</c><00:06:26.850><c> an</c><00:06:26.970><c> update</c>

00:06:27.320 --> 00:06:27.330 align:start position:0%
compute the gradient and do an update
 

00:06:27.330 --> 00:06:29.420 align:start position:0%
compute the gradient and do an update
and<00:06:27.570><c> so</c><00:06:28.140><c> instead</c><00:06:28.470><c> of</c><00:06:28.590><c> starting</c><00:06:28.980><c> like</c><00:06:29.310><c> we</c>

00:06:29.420 --> 00:06:29.430 align:start position:0%
and so instead of starting like we
 

00:06:29.430 --> 00:06:31.520 align:start position:0%
and so instead of starting like we
usually<00:06:29.700><c> do</c><00:06:29.820><c> in</c><00:06:29.940><c> Gibbs</c><00:06:30.090><c> sampling</c><00:06:30.480><c> at</c><00:06:30.810><c> the</c>

00:06:31.520 --> 00:06:31.530 align:start position:0%
usually do in Gibbs sampling at the
 

00:06:31.530 --> 00:06:34.940 align:start position:0%
usually do in Gibbs sampling at the
configuration<00:06:32.070><c> of</c><00:06:32.580><c> my</c><00:06:33.110><c> my</c><00:06:34.110><c> layers</c><00:06:34.410><c> my</c><00:06:34.710><c> random</c>

00:06:34.940 --> 00:06:34.950 align:start position:0%
configuration of my my layers my random
 

00:06:34.950 --> 00:06:37.820 align:start position:0%
configuration of my my layers my random
variables<00:06:35.520><c> that</c><00:06:35.880><c> is</c><00:06:36.090><c> sample</c>

00:06:37.820 --> 00:06:37.830 align:start position:0%
variables that is sample
 

00:06:37.830 --> 00:06:39.700 align:start position:0%
variables that is sample
perhaps<00:06:38.100><c> uniformly</c><00:06:38.640><c> and</c><00:06:38.880><c> just</c><00:06:39.090><c> randomly</c>

00:06:39.700 --> 00:06:39.710 align:start position:0%
perhaps uniformly and just randomly
 

00:06:39.710 --> 00:06:42.680 align:start position:0%
perhaps uniformly and just randomly
according<00:06:40.710><c> to</c><00:06:40.920><c> some</c><00:06:41.270><c> initial</c><00:06:42.270><c> distribution</c>

00:06:42.680 --> 00:06:42.690 align:start position:0%
according to some initial distribution
 

00:06:42.690 --> 00:06:45.590 align:start position:0%
according to some initial distribution
I'll<00:06:43.500><c> actually</c><00:06:43.800><c> use</c><00:06:44.100><c> the</c><00:06:44.640><c> value</c><00:06:45.150><c> of</c><00:06:45.390><c> the</c>

00:06:45.590 --> 00:06:45.600 align:start position:0%
I'll actually use the value of the
 

00:06:45.600 --> 00:06:47.990 align:start position:0%
I'll actually use the value of the
training<00:06:45.990><c> observation</c><00:06:46.710><c> for</c><00:06:47.340><c> the</c><00:06:47.550><c> value</c><00:06:47.970><c> of</c>

00:06:47.990 --> 00:06:48.000 align:start position:0%
training observation for the value of
 

00:06:48.000 --> 00:06:50.600 align:start position:0%
training observation for the value of
the<00:06:48.330><c> visible</c><00:06:48.720><c> layer</c><00:06:48.930><c> when</c><00:06:49.290><c> I'm</c><00:06:49.610><c> performing</c>

00:06:50.600 --> 00:06:50.610 align:start position:0%
the visible layer when I'm performing
 

00:06:50.610 --> 00:06:53.210 align:start position:0%
the visible layer when I'm performing
Gibbs<00:06:51.180><c> sampling</c><00:06:51.540><c> and</c><00:06:51.900><c> the</c><00:06:52.650><c> other</c><00:06:52.770><c> thing</c><00:06:53.040><c> is</c>

00:06:53.210 --> 00:06:53.220 align:start position:0%
Gibbs sampling and the other thing is
 

00:06:53.220 --> 00:06:55.190 align:start position:0%
Gibbs sampling and the other thing is
that<00:06:53.250><c> I'm</c><00:06:53.610><c> not</c><00:06:54.060><c> actually</c><00:06:54.240><c> going</c><00:06:54.690><c> to</c><00:06:54.870><c> do</c><00:06:54.990><c> Gibbs</c>

00:06:55.190 --> 00:06:55.200 align:start position:0%
that I'm not actually going to do Gibbs
 

00:06:55.200 --> 00:06:56.810 align:start position:0%
that I'm not actually going to do Gibbs
sampling<00:06:55.560><c> for</c><00:06:55.770><c> long</c><00:06:56.010><c> I'm</c><00:06:56.220><c> actually</c><00:06:56.400><c> going</c><00:06:56.700><c> to</c>

00:06:56.810 --> 00:06:56.820 align:start position:0%
sampling for long I'm actually going to
 

00:06:56.820 --> 00:06:59.960 align:start position:0%
sampling for long I'm actually going to
do<00:06:57.060><c> it</c><00:06:57.210><c> for</c><00:06:58.140><c> one</c><00:06:58.440><c> two</c><00:06:58.800><c> or</c><00:06:59.250><c> just</c><00:06:59.670><c> a</c><00:06:59.760><c> few</c>

00:06:59.960 --> 00:06:59.970 align:start position:0%
do it for one two or just a few
 

00:06:59.970 --> 00:07:02.990 align:start position:0%
do it for one two or just a few
iterations<00:07:00.090><c> and</c><00:07:01.310><c> as</c><00:07:02.310><c> we'll</c><00:07:02.580><c> see</c><00:07:02.820><c> this</c>

00:07:02.990 --> 00:07:03.000 align:start position:0%
iterations and as we'll see this
 

00:07:03.000 --> 00:07:05.240 align:start position:0%
iterations and as we'll see this
actually<00:07:03.300><c> works</c><00:07:03.510><c> well</c><00:07:03.780><c> in</c><00:07:03.900><c> practice</c><00:07:04.190><c> so</c><00:07:05.190><c> to</c>

00:07:05.240 --> 00:07:05.250 align:start position:0%
actually works well in practice so to
 

00:07:05.250 --> 00:07:08.120 align:start position:0%
actually works well in practice so to
illustrate<00:07:05.610><c> this</c><00:07:06.090><c> process</c><00:07:06.420><c> more</c><00:07:06.960><c> visually</c><00:07:07.470><c> so</c>

00:07:08.120 --> 00:07:08.130 align:start position:0%
illustrate this process more visually so
 

00:07:08.130 --> 00:07:11.150 align:start position:0%
illustrate this process more visually so
there's<00:07:08.660><c> air</c><00:07:09.660><c> in</c><00:07:09.930><c> my</c><00:07:10.110><c> figure</c><00:07:10.560><c> there's</c><00:07:10.770><c> below</c>

00:07:11.150 --> 00:07:11.160 align:start position:0%
there's air in my figure there's below
 

00:07:11.160 --> 00:07:13.910 align:start position:0%
there's air in my figure there's below
the<00:07:11.610><c> same</c><00:07:11.820><c> circle</c><00:07:12.270><c> here</c><00:07:12.480><c> so</c><00:07:13.380><c> what</c><00:07:13.530><c> we'll</c><00:07:13.740><c> do</c><00:07:13.890><c> is</c>

00:07:13.910 --> 00:07:13.920 align:start position:0%
the same circle here so what we'll do is
 

00:07:13.920 --> 00:07:16.220 align:start position:0%
the same circle here so what we'll do is
that<00:07:14.250><c> at</c><00:07:15.120><c> training</c><00:07:15.480><c> time</c><00:07:15.720><c> for</c><00:07:15.990><c> a</c><00:07:16.020><c> given</c>

00:07:16.220 --> 00:07:16.230 align:start position:0%
that at training time for a given
 

00:07:16.230 --> 00:07:18.970 align:start position:0%
that at training time for a given
training<00:07:16.500><c> example</c><00:07:17.040><c> I'll</c><00:07:17.220><c> take</c><00:07:17.610><c> the</c><00:07:18.060><c> value</c><00:07:18.600><c> of</c>

00:07:18.970 --> 00:07:18.980 align:start position:0%
training example I'll take the value of
 

00:07:18.980 --> 00:07:22.640 align:start position:0%
training example I'll take the value of
the<00:07:19.980><c> input</c><00:07:20.790><c> vector</c><00:07:20.970><c> X</c><00:07:21.360><c> and</c><00:07:21.690><c> I'll</c><00:07:21.930><c> set</c><00:07:22.200><c> it</c><00:07:22.230><c> as</c><00:07:22.470><c> my</c>

00:07:22.640 --> 00:07:22.650 align:start position:0%
the input vector X and I'll set it as my
 

00:07:22.650 --> 00:07:25.370 align:start position:0%
the input vector X and I'll set it as my
value<00:07:23.040><c> for</c><00:07:23.190><c> my</c><00:07:23.310><c> visible</c><00:07:23.730><c> layer</c><00:07:24.080><c> then</c><00:07:25.080><c> I'll</c>

00:07:25.370 --> 00:07:25.380 align:start position:0%
value for my visible layer then I'll
 

00:07:25.380 --> 00:07:28.730 align:start position:0%
value for my visible layer then I'll
sample<00:07:25.770><c> all</c><00:07:26.490><c> the</c><00:07:27.120><c> hidden</c><00:07:27.330><c> units</c><00:07:27.740><c> conditioned</c>

00:07:28.730 --> 00:07:28.740 align:start position:0%
sample all the hidden units conditioned
 

00:07:28.740 --> 00:07:31.790 align:start position:0%
sample all the hidden units conditioned
on<00:07:28.920><c> observing</c><00:07:29.670><c> this</c><00:07:30.180><c> particular</c><00:07:30.600><c> value</c><00:07:31.590><c> of</c>

00:07:31.790 --> 00:07:31.800 align:start position:0%
on observing this particular value of
 

00:07:31.800 --> 00:07:33.500 align:start position:0%
on observing this particular value of
the<00:07:31.920><c> visible</c><00:07:32.280><c> layer</c><00:07:32.490><c> this</c><00:07:32.850><c> training</c><00:07:33.330><c> example</c>

00:07:33.500 --> 00:07:33.510 align:start position:0%
the visible layer this training example
 

00:07:33.510 --> 00:07:37.820 align:start position:0%
the visible layer this training example
so<00:07:34.500><c> out</c><00:07:34.590><c> sampled</c><00:07:35.190><c> from</c><00:07:35.460><c> P</c><00:07:35.790><c> of</c><00:07:36.000><c> H</c><00:07:36.450><c> given</c><00:07:36.530><c> that</c><00:07:37.530><c> X</c>

00:07:37.820 --> 00:07:37.830 align:start position:0%
so out sampled from P of H given that X
 

00:07:37.830 --> 00:07:43.130 align:start position:0%
so out sampled from P of H given that X
is<00:07:38.280><c> equal</c><00:07:38.880><c> to</c><00:07:39.330><c> X</c><00:07:39.600><c> T</c><00:07:40.560><c> in</c><00:07:40.830><c> this</c><00:07:41.130><c> case</c><00:07:41.190><c> here</c><00:07:42.050><c> just</c><00:07:43.050><c> a</c>

00:07:43.130 --> 00:07:43.140 align:start position:0%
is equal to X T in this case here just a
 

00:07:43.140 --> 00:07:46.160 align:start position:0%
is equal to X T in this case here just a
note<00:07:43.350><c> on</c><00:07:43.380><c> performing</c><00:07:44.220><c> that</c><00:07:44.370><c> sampling</c><00:07:44.790><c> so</c><00:07:45.170><c> each</c>

00:07:46.160 --> 00:07:46.170 align:start position:0%
note on performing that sampling so each
 

00:07:46.170 --> 00:07:47.930 align:start position:0%
note on performing that sampling so each
neuron<00:07:46.440><c> condition</c><00:07:47.100><c> independent</c><00:07:47.700><c> so</c><00:07:47.820><c> they</c>

00:07:47.930 --> 00:07:47.940 align:start position:0%
neuron condition independent so they
 

00:07:47.940 --> 00:07:50.360 align:start position:0%
neuron condition independent so they
each<00:07:48.180><c> a</c><00:07:48.360><c> Bernoulli</c><00:07:48.900><c> for</c><00:07:49.500><c> which</c><00:07:49.650><c> I</c><00:07:49.740><c> can</c><00:07:49.800><c> compute</c>

00:07:50.360 --> 00:07:50.370 align:start position:0%
each a Bernoulli for which I can compute
 

00:07:50.370 --> 00:07:53.410 align:start position:0%
each a Bernoulli for which I can compute
what's<00:07:51.150><c> the</c><00:07:51.390><c> probability</c><00:07:51.960><c> for</c><00:07:52.650><c> that</c>

00:07:53.410 --> 00:07:53.420 align:start position:0%
what's the probability for that
 

00:07:53.420 --> 00:07:55.640 align:start position:0%
what's the probability for that
Bernoulli<00:07:54.420><c> random</c><00:07:54.450><c> variable</c><00:07:55.170><c> that</c><00:07:55.200><c> hidden</c>

00:07:55.640 --> 00:07:55.650 align:start position:0%
Bernoulli random variable that hidden
 

00:07:55.650 --> 00:07:58.670 align:start position:0%
Bernoulli random variable that hidden
unit<00:07:55.920><c> being</c><00:07:56.130><c> called</c><00:07:56.400><c> to</c><00:07:56.490><c> 1</c><00:07:56.700><c> given</c><00:07:57.060><c> X</c><00:07:57.620><c> now</c><00:07:58.620><c> to</c>

00:07:58.670 --> 00:07:58.680 align:start position:0%
unit being called to 1 given X now to
 

00:07:58.680 --> 00:08:01.010 align:start position:0%
unit being called to 1 given X now to
obtain<00:07:58.980><c> a</c><00:07:59.130><c> sample</c><00:07:59.400><c> from</c><00:07:59.910><c> a</c><00:08:00.030><c> Bernoulli</c><00:08:00.510><c> with</c>

00:08:01.010 --> 00:08:01.020 align:start position:0%
obtain a sample from a Bernoulli with
 

00:08:01.020 --> 00:08:02.660 align:start position:0%
obtain a sample from a Bernoulli with
that<00:08:01.200><c> probability</c><00:08:01.860><c> of</c><00:08:01.950><c> being</c><00:08:02.100><c> equal</c><00:08:02.370><c> to</c><00:08:02.490><c> 1</c>

00:08:02.660 --> 00:08:02.670 align:start position:0%
that probability of being equal to 1
 

00:08:02.670 --> 00:08:05.090 align:start position:0%
that probability of being equal to 1
what<00:08:03.240><c> I</c><00:08:03.270><c> can</c><00:08:03.480><c> do</c><00:08:03.630><c> is</c><00:08:03.750><c> just</c><00:08:03.780><c> sample</c><00:08:04.260><c> from</c><00:08:04.830><c> a</c>

00:08:05.090 --> 00:08:05.100 align:start position:0%
what I can do is just sample from a
 

00:08:05.100 --> 00:08:09.550 align:start position:0%
what I can do is just sample from a
uniform<00:08:06.030><c> distribution</c><00:08:06.720><c> between</c><00:08:07.400><c> 0</c><00:08:08.400><c> and</c><00:08:08.670><c> 1</c><00:08:08.970><c> and</c>

00:08:09.550 --> 00:08:09.560 align:start position:0%
uniform distribution between 0 and 1 and
 

00:08:09.560 --> 00:08:13.460 align:start position:0%
uniform distribution between 0 and 1 and
then<00:08:10.560><c> if</c><00:08:10.890><c> that</c><00:08:11.550><c> value</c><00:08:11.940><c> that</c><00:08:12.600><c> uniform</c><00:08:13.350><c> value</c>

00:08:13.460 --> 00:08:13.470 align:start position:0%
then if that value that uniform value
 

00:08:13.470 --> 00:08:18.230 align:start position:0%
then if that value that uniform value
that<00:08:13.680><c> I</c><00:08:13.800><c> sample</c><00:08:14.340><c> is</c><00:08:14.840><c> actually</c><00:08:17.090><c> sorry</c><00:08:18.090><c> it</c>

00:08:18.230 --> 00:08:18.240 align:start position:0%
that I sample is actually sorry it
 

00:08:18.240 --> 00:08:20.540 align:start position:0%
that I sample is actually sorry it
should<00:08:18.390><c> be</c><00:08:18.510><c> the</c><00:08:18.720><c> other</c><00:08:19.260><c> way</c><00:08:19.800><c> around</c><00:08:19.920><c> so</c><00:08:20.220><c> if</c>

00:08:20.540 --> 00:08:20.550 align:start position:0%
should be the other way around so if
 

00:08:20.550 --> 00:08:26.570 align:start position:0%
should be the other way around so if
this<00:08:21.360><c> value</c><00:08:21.810><c> is</c><00:08:22.700><c> greater</c><00:08:23.700><c> than</c><00:08:25.250><c> so</c><00:08:26.250><c> greater</c>

00:08:26.570 --> 00:08:26.580 align:start position:0%
this value is greater than so greater
 

00:08:26.580 --> 00:08:30.200 align:start position:0%
this value is greater than so greater
than<00:08:28.310><c> the</c><00:08:29.310><c> value</c><00:08:29.460><c> the</c><00:08:29.700><c> probability</c><00:08:29.910><c> is</c>

00:08:30.200 --> 00:08:30.210 align:start position:0%
than the value the probability is
 

00:08:30.210 --> 00:08:32.180 align:start position:0%
than the value the probability is
greater<00:08:30.390><c> than</c><00:08:30.750><c> the</c><00:08:31.050><c> value</c><00:08:31.080><c> of</c><00:08:31.440><c> sample</c><00:08:31.830><c> from</c><00:08:32.010><c> my</c>

00:08:32.180 --> 00:08:32.190 align:start position:0%
greater than the value of sample from my
 

00:08:32.190 --> 00:08:36.860 align:start position:0%
greater than the value of sample from my
uniform<00:08:32.729><c> then</c><00:08:33.450><c> I'm</c><00:08:33.780><c> gonna</c><00:08:34.140><c> set</c><00:08:34.530><c> the</c><00:08:35.750><c> that</c><00:08:36.750><c> I'm</c>

00:08:36.860 --> 00:08:36.870 align:start position:0%
uniform then I'm gonna set the that I'm
 

00:08:36.870 --> 00:08:39.410 align:start position:0%
uniform then I'm gonna set the that I'm
going<00:08:37.080><c> to</c><00:08:37.229><c> set</c><00:08:37.500><c> the</c><00:08:38.010><c> hidden</c><00:08:38.370><c> layer</c><00:08:38.580><c> layer</c><00:08:38.970><c> unit</c>

00:08:39.410 --> 00:08:39.420 align:start position:0%
going to set the hidden layer layer unit
 

00:08:39.420 --> 00:08:42.650 align:start position:0%
going to set the hidden layer layer unit
DG<00:08:40.320><c> hidden</c><00:08:40.800><c> layer</c><00:08:40.979><c> the</c><00:08:41.220><c> unit</c><00:08:41.550><c> to</c><00:08:41.880><c> 1</c><00:08:42.420><c> and</c>

00:08:42.650 --> 00:08:42.660 align:start position:0%
DG hidden layer the unit to 1 and
 

00:08:42.660 --> 00:08:44.570 align:start position:0%
DG hidden layer the unit to 1 and
otherwise<00:08:42.990><c> I'm</c><00:08:43.170><c> gonna</c><00:08:43.290><c> set</c><00:08:43.560><c> it</c><00:08:43.680><c> to</c><00:08:43.710><c> 0</c><00:08:44.190><c> so</c><00:08:44.490><c> in</c>

00:08:44.570 --> 00:08:44.580 align:start position:0%
otherwise I'm gonna set it to 0 so in
 

00:08:44.580 --> 00:08:46.700 align:start position:0%
otherwise I'm gonna set it to 0 so in
other<00:08:44.700><c> words</c><00:08:44.940><c> the</c><00:08:45.570><c> value</c><00:08:45.990><c> of</c><00:08:46.200><c> the</c><00:08:46.290><c> hidden</c><00:08:46.530><c> unit</c>

00:08:46.700 --> 00:08:46.710 align:start position:0%
other words the value of the hidden unit
 

00:08:46.710 --> 00:08:48.650 align:start position:0%
other words the value of the hidden unit
is<00:08:46.830><c> going</c><00:08:46.980><c> to</c><00:08:47.040><c> be</c><00:08:47.130><c> the</c><00:08:47.340><c> identity</c><00:08:47.910><c> function</c><00:08:48.210><c> of</c>

00:08:48.650 --> 00:08:48.660 align:start position:0%
is going to be the identity function of
 

00:08:48.660 --> 00:08:50.960 align:start position:0%
is going to be the identity function of
whether<00:08:49.350><c> the</c><00:08:49.950><c> probability</c>

00:08:50.960 --> 00:08:50.970 align:start position:0%
whether the probability
 

00:08:50.970 --> 00:08:54.020 align:start position:0%
whether the probability
the<00:08:51.060><c> hidden</c><00:08:51.330><c> unit</c><00:08:51.570><c> is</c><00:08:51.720><c> greater</c><00:08:52.200><c> than</c><00:08:52.530><c> a</c><00:08:53.030><c> random</c>

00:08:54.020 --> 00:08:54.030 align:start position:0%
the hidden unit is greater than a random
 

00:08:54.030 --> 00:08:56.680 align:start position:0%
the hidden unit is greater than a random
sample<00:08:54.450><c> from</c><00:08:54.480><c> a</c><00:08:54.750><c> uniform</c><00:08:55.020><c> between</c><00:08:55.410><c> 0</c><00:08:55.650><c> &amp;</c><00:08:56.100><c> 1</c><00:08:56.160><c> so</c>

00:08:56.680 --> 00:08:56.690 align:start position:0%
sample from a uniform between 0 &amp; 1 so
 

00:08:56.690 --> 00:09:00.980 align:start position:0%
sample from a uniform between 0 &amp; 1 so
we<00:08:57.690><c> can</c><00:08:57.720><c> see</c><00:08:57.990><c> that</c><00:08:58.140><c> this</c><00:08:58.400><c> will</c><00:08:59.400><c> be</c><00:08:59.700><c> equal</c><00:09:00.450><c> to</c><00:09:00.690><c> 1</c>

00:09:00.980 --> 00:09:00.990 align:start position:0%
we can see that this will be equal to 1
 

00:09:00.990 --> 00:09:05.720 align:start position:0%
we can see that this will be equal to 1
with<00:09:01.260><c> a</c><00:09:01.290><c> probability</c><00:09:01.830><c> of</c><00:09:02.480><c> this</c><00:09:03.530><c> value</c><00:09:04.730><c> because</c>

00:09:05.720 --> 00:09:05.730 align:start position:0%
with a probability of this value because
 

00:09:05.730 --> 00:09:08.720 align:start position:0%
with a probability of this value because
the<00:09:06.060><c> mass</c><00:09:06.480><c> of</c><00:09:06.900><c> a</c><00:09:07.650><c> uniformly</c><00:09:08.610><c> distributed</c>

00:09:08.720 --> 00:09:08.730 align:start position:0%
the mass of a uniformly distributed
 

00:09:08.730 --> 00:09:12.070 align:start position:0%
the mass of a uniformly distributed
random<00:09:09.180><c> variable</c><00:09:09.900><c> between</c><00:09:10.110><c> 0</c><00:09:10.680><c> and</c><00:09:11.010><c> this</c><00:09:11.670><c> value</c>

00:09:12.070 --> 00:09:12.080 align:start position:0%
random variable between 0 and this value
 

00:09:12.080 --> 00:09:15.110 align:start position:0%
random variable between 0 and this value
is<00:09:13.080><c> going</c><00:09:13.380><c> to</c><00:09:13.500><c> be</c><00:09:13.730><c> exactly</c><00:09:14.730><c> because</c><00:09:14.880><c> it's</c>

00:09:15.110 --> 00:09:15.120 align:start position:0%
is going to be exactly because it's
 

00:09:15.120 --> 00:09:18.440 align:start position:0%
is going to be exactly because it's
uniform<00:09:15.690><c> it's</c><00:09:16.230><c> going</c><00:09:16.620><c> to</c><00:09:16.740><c> be</c><00:09:16.890><c> P</c><00:09:17.370><c> of</c><00:09:17.400><c> H</c><00:09:18.000><c> equal</c><00:09:18.420><c> to</c>

00:09:18.440 --> 00:09:18.450 align:start position:0%
uniform it's going to be P of H equal to
 

00:09:18.450 --> 00:09:22.820 align:start position:0%
uniform it's going to be P of H equal to
1<00:09:19.050><c> given</c><00:09:19.590><c> X</c><00:09:19.770><c> so</c><00:09:20.400><c> so</c><00:09:21.030><c> indeed</c><00:09:21.330><c> the</c><00:09:22.080><c> property</c><00:09:22.710><c> that</c>

00:09:22.820 --> 00:09:22.830 align:start position:0%
1 given X so so indeed the property that
 

00:09:22.830 --> 00:09:26.390 align:start position:0%
1 given X so so indeed the property that
this<00:09:23.010><c> is</c><00:09:23.220><c> 1</c><00:09:23.520><c> is</c><00:09:23.820><c> going</c><00:09:24.480><c> to</c><00:09:24.600><c> be</c><00:09:24.720><c> P</c><00:09:24.930><c> of</c><00:09:25.140><c> HD</c><00:09:25.560><c> equal</c><00:09:26.070><c> 1</c>

00:09:26.390 --> 00:09:26.400 align:start position:0%
this is 1 is going to be P of HD equal 1
 

00:09:26.400 --> 00:09:31.220 align:start position:0%
this is 1 is going to be P of HD equal 1
given<00:09:26.970><c> X</c><00:09:28.940><c> okay</c><00:09:29.940><c> so</c><00:09:30.270><c> now</c><00:09:30.570><c> I've</c><00:09:30.840><c> taken</c><00:09:31.050><c> my</c>

00:09:31.220 --> 00:09:31.230 align:start position:0%
given X okay so now I've taken my
 

00:09:31.230 --> 00:09:33.350 align:start position:0%
given X okay so now I've taken my
training<00:09:31.620><c> sample</c><00:09:32.010><c> I've</c><00:09:32.190><c> sampled</c><00:09:32.520><c> each</c><00:09:32.880><c> of</c><00:09:33.240><c> the</c>

00:09:33.350 --> 00:09:33.360 align:start position:0%
training sample I've sampled each of the
 

00:09:33.360 --> 00:09:37.910 align:start position:0%
training sample I've sampled each of the
hidden<00:09:33.960><c> units</c><00:09:35.150><c> conditionally</c><00:09:36.920><c> conditioned</c>

00:09:37.910 --> 00:09:37.920 align:start position:0%
hidden units conditionally conditioned
 

00:09:37.920 --> 00:09:40.130 align:start position:0%
hidden units conditionally conditioned
on<00:09:38.040><c> the</c><00:09:38.280><c> visible</c><00:09:38.970><c> layer</c><00:09:39.150><c> taking</c><00:09:39.570><c> that</c><00:09:39.720><c> value</c>

00:09:40.130 --> 00:09:40.140 align:start position:0%
on the visible layer taking that value
 

00:09:40.140 --> 00:09:44.140 align:start position:0%
on the visible layer taking that value
and<00:09:40.440><c> then</c><00:09:40.980><c> I'm</c><00:09:41.130><c> going</c><00:09:41.400><c> to</c><00:09:42.080><c> reconstruct</c><00:09:43.080><c> a</c>

00:09:44.140 --> 00:09:44.150 align:start position:0%
and then I'm going to reconstruct a
 

00:09:44.150 --> 00:09:48.140 align:start position:0%
and then I'm going to reconstruct a
visible<00:09:45.150><c> layer</c><00:09:45.300><c> by</c><00:09:45.570><c> sampling</c><00:09:46.200><c> from</c><00:09:46.640><c> P</c><00:09:47.640><c> of</c><00:09:47.850><c> X</c>

00:09:48.140 --> 00:09:48.150 align:start position:0%
visible layer by sampling from P of X
 

00:09:48.150 --> 00:09:50.720 align:start position:0%
visible layer by sampling from P of X
given<00:09:48.690><c> the</c><00:09:49.260><c> current</c><00:09:49.650><c> value</c><00:09:50.130><c> of</c><00:09:50.310><c> my</c><00:09:50.490><c> hidden</c>

00:09:50.720 --> 00:09:50.730 align:start position:0%
given the current value of my hidden
 

00:09:50.730 --> 00:09:56.240 align:start position:0%
given the current value of my hidden
layer<00:09:51.050><c> so</c><00:09:52.050><c> I</c><00:09:52.080><c> could</c><00:09:52.260><c> call</c><00:09:52.470><c> this</c><00:09:52.680><c> a</c><00:09:53.030><c> x1</c><00:09:54.030><c> and</c><00:09:55.250><c> then</c>

00:09:56.240 --> 00:09:56.250 align:start position:0%
layer so I could call this a x1 and then
 

00:09:56.250 --> 00:09:58.670 align:start position:0%
layer so I could call this a x1 and then
I'm<00:09:56.370><c> going</c><00:09:56.580><c> to</c><00:09:56.640><c> do</c><00:09:56.850><c> that</c><00:09:57.060><c> for</c><00:09:57.390><c> K</c><00:09:57.750><c> step</c><00:09:58.380><c> so</c><00:09:58.590><c> I'm</c>

00:09:58.670 --> 00:09:58.680 align:start position:0%
I'm going to do that for K step so I'm
 

00:09:58.680 --> 00:10:00.620 align:start position:0%
I'm going to do that for K step so I'm
going<00:09:58.950><c> to</c><00:09:59.100><c> take</c><00:09:59.280><c> X</c><00:09:59.490><c> 1</c><00:09:59.730><c> and</c><00:09:59.940><c> then</c><00:10:00.030><c> sample</c><00:10:00.360><c> a</c><00:10:00.450><c> new</c>

00:10:00.620 --> 00:10:00.630 align:start position:0%
going to take X 1 and then sample a new
 

00:10:00.630 --> 00:10:02.540 align:start position:0%
going to take X 1 and then sample a new
value<00:10:00.840><c> of</c><00:10:00.960><c> the</c><00:10:01.080><c> hidden</c><00:10:01.320><c> there</c><00:10:01.500><c> given</c><00:10:02.040><c> my</c>

00:10:02.540 --> 00:10:02.550 align:start position:0%
value of the hidden there given my
 

00:10:02.550 --> 00:10:04.610 align:start position:0%
value of the hidden there given my
previously<00:10:03.390><c> sample</c><00:10:03.780><c> value</c><00:10:04.080><c> of</c><00:10:04.140><c> the</c><00:10:04.230><c> visible</c>

00:10:04.610 --> 00:10:04.620 align:start position:0%
previously sample value of the visible
 

00:10:04.620 --> 00:10:06.260 align:start position:0%
previously sample value of the visible
layer<00:10:04.800><c> I'm</c><00:10:05.010><c> going</c><00:10:05.070><c> to</c><00:10:05.400><c> alternate</c><00:10:05.850><c> like</c><00:10:06.060><c> this</c>

00:10:06.260 --> 00:10:06.270 align:start position:0%
layer I'm going to alternate like this
 

00:10:06.270 --> 00:10:08.690 align:start position:0%
layer I'm going to alternate like this
performing<00:10:06.810><c> Gibbs</c><00:10:06.990><c> sampling</c><00:10:07.350><c> for</c><00:10:08.010><c> K</c><00:10:08.370><c> steps</c>

00:10:08.690 --> 00:10:08.700 align:start position:0%
performing Gibbs sampling for K steps
 

00:10:08.700 --> 00:10:12.320 align:start position:0%
performing Gibbs sampling for K steps
and<00:10:09.030><c> now</c><00:10:09.960><c> this</c><00:10:10.410><c> last</c><00:10:11.310><c> value</c><00:10:11.670><c> after</c><00:10:12.090><c> I've</c><00:10:12.210><c> done</c>

00:10:12.320 --> 00:10:12.330 align:start position:0%
and now this last value after I've done
 

00:10:12.330 --> 00:10:17.300 align:start position:0%
and now this last value after I've done
my<00:10:12.390><c> K</c><00:10:12.540><c> steps</c><00:10:12.960><c> is</c><00:10:13.230><c> going</c><00:10:14.040><c> to</c><00:10:14.340><c> be</c><00:10:14.580><c> the</c><00:10:16.310><c> negative</c>

00:10:17.300 --> 00:10:17.310 align:start position:0%
my K steps is going to be the negative
 

00:10:17.310 --> 00:10:20.330 align:start position:0%
my K steps is going to be the negative
sample<00:10:18.090><c> X</c><00:10:18.480><c> tilde</c><00:10:19.260><c> X</c><00:10:19.440><c> still</c><00:10:19.620><c> we</c><00:10:19.770><c> often</c><00:10:20.070><c> refer</c><00:10:20.310><c> to</c>

00:10:20.330 --> 00:10:20.340 align:start position:0%
sample X tilde X still we often refer to
 

00:10:20.340 --> 00:10:22.100 align:start position:0%
sample X tilde X still we often refer to
it<00:10:20.460><c> as</c><00:10:20.640><c> a</c><00:10:20.670><c> negative</c><00:10:20.880><c> sample</c><00:10:21.450><c> which</c><00:10:21.660><c> is</c><00:10:21.780><c> used</c><00:10:21.990><c> to</c>

00:10:22.100 --> 00:10:22.110 align:start position:0%
it as a negative sample which is used to
 

00:10:22.110 --> 00:10:25.040 align:start position:0%
it as a negative sample which is used to
estimate<00:10:22.350><c> the</c><00:10:22.790><c> negative</c><00:10:23.790><c> phase</c><00:10:24.270><c> part</c><00:10:24.810><c> of</c><00:10:24.930><c> the</c>

00:10:25.040 --> 00:10:25.050 align:start position:0%
estimate the negative phase part of the
 

00:10:25.050 --> 00:10:27.710 align:start position:0%
estimate the negative phase part of the
gradient<00:10:25.440><c> and</c><00:10:25.590><c> so</c><00:10:26.490><c> I'm</c><00:10:26.550><c> going</c><00:10:26.730><c> to</c><00:10:26.970><c> use</c><00:10:27.180><c> that</c><00:10:27.450><c> as</c>

00:10:27.710 --> 00:10:27.720 align:start position:0%
gradient and so I'm going to use that as
 

00:10:27.720 --> 00:10:29.870 align:start position:0%
gradient and so I'm going to use that as
my<00:10:27.780><c> negative</c><00:10:28.380><c> sample</c><00:10:28.770><c> to</c><00:10:28.920><c> perform</c><00:10:29.370><c> my</c><00:10:29.520><c> point</c>

00:10:29.870 --> 00:10:29.880 align:start position:0%
my negative sample to perform my point
 

00:10:29.880 --> 00:10:36.860 align:start position:0%
my negative sample to perform my point
estimates<00:10:30.720><c> of</c><00:10:30.930><c> the</c><00:10:31.320><c> expectation</c><00:10:32.150><c> over</c><00:10:33.150><c> X</c><00:10:35.870><c> okay</c>

00:10:36.860 --> 00:10:36.870 align:start position:0%
estimates of the expectation over X okay
 

00:10:36.870 --> 00:10:39.260 align:start position:0%
estimates of the expectation over X okay
so<00:10:36.900><c> visually</c><00:10:37.410><c> what</c><00:10:37.560><c> does</c><00:10:37.710><c> this</c><00:10:37.860><c> look</c><00:10:38.100><c> like</c><00:10:38.310><c> so</c>

00:10:39.260 --> 00:10:39.270 align:start position:0%
so visually what does this look like so
 

00:10:39.270 --> 00:10:43.040 align:start position:0%
so visually what does this look like so
I<00:10:39.300><c> get</c><00:10:39.600><c> a</c><00:10:39.630><c> training</c><00:10:39.990><c> example</c><00:10:40.530><c> and</c><00:10:41.780><c> in</c><00:10:42.780><c> the</c>

00:10:43.040 --> 00:10:43.050 align:start position:0%
I get a training example and in the
 

00:10:43.050 --> 00:10:44.750 align:start position:0%
I get a training example and in the
positive<00:10:43.500><c> phase</c><00:10:43.650><c> I</c><00:10:43.830><c> had</c><00:10:44.010><c> to</c><00:10:44.160><c> estimate</c><00:10:44.640><c> this</c>

00:10:44.750 --> 00:10:44.760 align:start position:0%
positive phase I had to estimate this
 

00:10:44.760 --> 00:10:47.060 align:start position:0%
positive phase I had to estimate this
conditional<00:10:45.420><c> expectation</c><00:10:46.230><c> to</c><00:10:46.650><c> sample</c><00:10:46.920><c> if</c><00:10:47.010><c> I</c>

00:10:47.060 --> 00:10:47.070 align:start position:0%
conditional expectation to sample if I
 

00:10:47.070 --> 00:10:48.680 align:start position:0%
conditional expectation to sample if I
imagine<00:10:47.460><c> I</c><00:10:47.550><c> actually</c><00:10:47.730><c> don't</c><00:10:48.210><c> perform</c><00:10:48.450><c> that</c>

00:10:48.680 --> 00:10:48.690 align:start position:0%
imagine I actually don't perform that
 

00:10:48.690 --> 00:10:52.520 align:start position:0%
imagine I actually don't perform that
expectation<00:10:49.320><c> I</c><00:10:49.440><c> just</c><00:10:50.010><c> sample</c><00:10:50.430><c> and</c><00:10:50.870><c> H</c><00:10:51.870><c> given</c>

00:10:52.520 --> 00:10:52.530 align:start position:0%
expectation I just sample and H given
 

00:10:52.530 --> 00:10:57.010 align:start position:0%
expectation I just sample and H given
this<00:10:53.310><c> XT</c><00:10:53.850><c> and</c><00:10:54.180><c> I'll</c><00:10:54.270><c> call</c><00:10:54.570><c> that</c><00:10:54.600><c> H</c><00:10:55.200><c> till</c><00:10:55.980><c> T</c><00:10:56.280><c> and</c>

00:10:57.010 --> 00:10:57.020 align:start position:0%
this XT and I'll call that H till T and
 

00:10:57.020 --> 00:10:59.630 align:start position:0%
this XT and I'll call that H till T and
I've<00:10:58.020><c> also</c><00:10:58.260><c> performed</c><00:10:58.860><c> K</c><00:10:59.010><c> steps</c><00:10:59.190><c> of</c><00:10:59.430><c> Gibbs</c>

00:10:59.630 --> 00:10:59.640 align:start position:0%
I've also performed K steps of Gibbs
 

00:10:59.640 --> 00:11:01.130 align:start position:0%
I've also performed K steps of Gibbs
sampling<00:11:00.030><c> to</c><00:11:00.210><c> have</c><00:11:00.330><c> an</c><00:11:00.480><c> X</c><00:11:00.630><c> tilde</c><00:11:01.080><c> and</c>

00:11:01.130 --> 00:11:01.140 align:start position:0%
sampling to have an X tilde and
 

00:11:01.140 --> 00:11:04.490 align:start position:0%
sampling to have an X tilde and
similarly<00:11:01.890><c> to</c><00:11:02.310><c> perform</c><00:11:03.210><c> that</c><00:11:03.420><c> expect</c>

00:11:04.490 --> 00:11:04.500 align:start position:0%
similarly to perform that expect
 

00:11:04.500 --> 00:11:08.730 align:start position:0%
similarly to perform that expect
estimated<00:11:05.500><c> at</c><00:11:05.620><c> X</c><00:11:06.070><c> still</c><00:11:06.399><c> and</c><00:11:06.670><c> H</c><00:11:07.060><c> still</c><00:11:07.360><c> where</c><00:11:07.740><c> H</c>

00:11:08.730 --> 00:11:08.740 align:start position:0%
estimated at X still and H still where H
 

00:11:08.740 --> 00:11:12.269 align:start position:0%
estimated at X still and H still where H
tilled<00:11:09.160><c> would</c><00:11:09.820><c> be</c><00:11:09.970><c> sample</c><00:11:10.470><c> based</c><00:11:11.470><c> on</c><00:11:11.770><c> the</c>

00:11:12.269 --> 00:11:12.279 align:start position:0%
tilled would be sample based on the
 

00:11:12.279 --> 00:11:13.769 align:start position:0%
tilled would be sample based on the
conditional<00:11:12.790><c> distribution</c><00:11:12.970><c> of</c><00:11:13.360><c> the</c><00:11:13.510><c> hidden</c>

00:11:13.769 --> 00:11:13.779 align:start position:0%
conditional distribution of the hidden
 

00:11:13.779 --> 00:11:18.829 align:start position:0%
conditional distribution of the hidden
layer<00:11:13.960><c> given</c><00:11:14.860><c> that</c><00:11:15.160><c> X</c><00:11:15.520><c> is</c><00:11:16.000><c> equal</c><00:11:16.360><c> to</c><00:11:16.630><c> X</c><00:11:16.839><c> still</c>

00:11:18.829 --> 00:11:18.839 align:start position:0%
layer given that X is equal to X still
 

00:11:18.839 --> 00:11:22.320 align:start position:0%
layer given that X is equal to X still
so<00:11:19.839><c> that</c><00:11:19.990><c> I</c><00:11:20.020><c> get</c><00:11:20.290><c> these</c><00:11:20.470><c> two</c><00:11:20.709><c> pairs</c><00:11:21.010><c> and</c><00:11:21.339><c> if</c><00:11:22.120><c> I</c>

00:11:22.320 --> 00:11:22.330 align:start position:0%
so that I get these two pairs and if I
 

00:11:22.330 --> 00:11:24.000 align:start position:0%
so that I get these two pairs and if I
look<00:11:22.570><c> at</c><00:11:22.750><c> the</c><00:11:22.839><c> gradient</c><00:11:23.080><c> descent</c><00:11:23.290><c> procedure</c>

00:11:24.000 --> 00:11:24.010 align:start position:0%
look at the gradient descent procedure
 

00:11:24.010 --> 00:11:26.389 align:start position:0%
look at the gradient descent procedure
what<00:11:24.310><c> it's</c><00:11:24.459><c> telling</c><00:11:24.670><c> me</c><00:11:24.880><c> is</c><00:11:25.060><c> that</c><00:11:25.450><c> I</c><00:11:25.750><c> should</c>

00:11:26.389 --> 00:11:26.399 align:start position:0%
what it's telling me is that I should
 

00:11:26.399 --> 00:11:29.579 align:start position:0%
what it's telling me is that I should
decrease<00:11:27.399><c> the</c><00:11:27.700><c> energy</c><00:11:28.270><c> at</c><00:11:28.779><c> the</c><00:11:29.140><c> up</c><00:11:29.320><c> training</c>

00:11:29.579 --> 00:11:29.589 align:start position:0%
decrease the energy at the up training
 

00:11:29.589 --> 00:11:32.250 align:start position:0%
decrease the energy at the up training
observation<00:11:30.279><c> and</c><00:11:30.459><c> I</c><00:11:31.029><c> should</c><00:11:31.240><c> increase</c><00:11:31.720><c> it</c><00:11:32.020><c> at</c>

00:11:32.250 --> 00:11:32.260 align:start position:0%
observation and I should increase it at
 

00:11:32.260 --> 00:11:35.610 align:start position:0%
observation and I should increase it at
the<00:11:33.450><c> sample</c><00:11:34.450><c> value</c><00:11:34.810><c> X</c><00:11:35.080><c> still</c><00:11:35.290><c> and</c><00:11:35.470><c> its</c>

00:11:35.610 --> 00:11:35.620 align:start position:0%
the sample value X still and its
 

00:11:35.620 --> 00:11:39.690 align:start position:0%
the sample value X still and its
associated<00:11:36.130><c> hidden</c><00:11:36.550><c> layer</c><00:11:37.680><c> because</c><00:11:38.700><c> low</c>

00:11:39.690 --> 00:11:39.700 align:start position:0%
associated hidden layer because low
 

00:11:39.700 --> 00:11:44.070 align:start position:0%
associated hidden layer because low
energy<00:11:40.089><c> means</c><00:11:40.600><c> high</c><00:11:41.080><c> probability</c><00:11:42.300><c> then</c><00:11:43.300><c> this</c>

00:11:44.070 --> 00:11:44.080 align:start position:0%
energy means high probability then this
 

00:11:44.080 --> 00:11:46.800 align:start position:0%
energy means high probability then this
means<00:11:44.380><c> that</c><00:11:44.680><c> I'm</c><00:11:45.070><c> going</c><00:11:45.610><c> to</c><00:11:45.760><c> increase</c><00:11:46.240><c> really</c>

00:11:46.800 --> 00:11:46.810 align:start position:0%
means that I'm going to increase really
 

00:11:46.810 --> 00:11:50.760 align:start position:0%
means that I'm going to increase really
the<00:11:47.940><c> probability</c><00:11:48.940><c> of</c><00:11:48.970><c> observing</c><00:11:49.380><c> XT</c><00:11:50.380><c> when</c>

00:11:50.760 --> 00:11:50.770 align:start position:0%
the probability of observing XT when
 

00:11:50.770 --> 00:11:52.800 align:start position:0%
the probability of observing XT when
it's<00:11:50.920><c> in</c><00:11:51.100><c> a</c><00:11:51.130><c> layer</c><00:11:51.399><c> and</c><00:11:51.640><c> I'm</c><00:11:52.209><c> going</c><00:11:52.390><c> to</c>

00:11:52.800 --> 00:11:52.810 align:start position:0%
it's in a layer and I'm going to
 

00:11:52.810 --> 00:11:54.660 align:start position:0%
it's in a layer and I'm going to
decrease<00:11:53.140><c> at</c><00:11:53.649><c> the</c><00:11:53.920><c> same</c><00:11:54.160><c> time</c><00:11:54.399><c> the</c>

00:11:54.660 --> 00:11:54.670 align:start position:0%
decrease at the same time the
 

00:11:54.670 --> 00:11:57.329 align:start position:0%
decrease at the same time the
probability<00:11:54.880><c> that</c><00:11:55.660><c> X</c><00:11:56.170><c> still</c><00:11:56.589><c> is</c><00:11:56.740><c> going</c><00:11:56.920><c> to</c><00:11:57.160><c> be</c>

00:11:57.329 --> 00:11:57.339 align:start position:0%
probability that X still is going to be
 

00:11:57.339 --> 00:11:59.880 align:start position:0%
probability that X still is going to be
observed<00:11:57.850><c> under</c><00:11:58.300><c> my</c><00:11:58.839><c> models</c><00:11:59.230><c> distribution</c>

00:11:59.880 --> 00:11:59.890 align:start position:0%
observed under my models distribution
 

00:11:59.890 --> 00:12:02.880 align:start position:0%
observed under my models distribution
and<00:12:00.420><c> so</c><00:12:01.420><c> if</c><00:12:01.720><c> my</c><00:12:02.080><c> training</c><00:12:02.410><c> example</c>

00:12:02.880 --> 00:12:02.890 align:start position:0%
and so if my training example
 

00:12:02.890 --> 00:12:05.850 align:start position:0%
and so if my training example
correspondent<00:12:03.820><c> two</c><00:12:03.910><c> images</c><00:12:04.390><c> of</c><00:12:04.630><c> digits</c><00:12:05.110><c> then</c>

00:12:05.850 --> 00:12:05.860 align:start position:0%
correspondent two images of digits then
 

00:12:05.860 --> 00:12:07.590 align:start position:0%
correspondent two images of digits then
I'd<00:12:06.040><c> be</c><00:12:06.190><c> increasing</c><00:12:06.790><c> the</c><00:12:06.880><c> probability</c><00:12:07.089><c> of</c>

00:12:07.590 --> 00:12:07.600 align:start position:0%
I'd be increasing the probability of
 

00:12:07.600 --> 00:12:09.780 align:start position:0%
I'd be increasing the probability of
observing<00:12:08.020><c> this</c><00:12:08.589><c> particular</c><00:12:08.920><c> digit</c><00:12:09.430><c> here</c>

00:12:09.780 --> 00:12:09.790 align:start position:0%
observing this particular digit here
 

00:12:09.790 --> 00:12:13.590 align:start position:0%
observing this particular digit here
under<00:12:10.209><c> my</c><00:12:10.360><c> model</c><00:12:10.750><c> and</c><00:12:11.430><c> then</c><00:12:12.430><c> say</c><00:12:12.760><c> initially</c><00:12:13.330><c> my</c>

00:12:13.590 --> 00:12:13.600 align:start position:0%
under my model and then say initially my
 

00:12:13.600 --> 00:12:15.750 align:start position:0%
under my model and then say initially my
restricted<00:12:14.560><c> Boltzmann</c><00:12:14.830><c> machine</c><00:12:15.100><c> is</c><00:12:15.279><c> randomly</c>

00:12:15.750 --> 00:12:15.760 align:start position:0%
restricted Boltzmann machine is randomly
 

00:12:15.760 --> 00:12:17.220 align:start position:0%
restricted Boltzmann machine is randomly
initialized<00:12:16.390><c> so</c><00:12:16.660><c> it</c><00:12:16.750><c> essentially</c>

00:12:17.220 --> 00:12:17.230 align:start position:0%
initialized so it essentially
 

00:12:17.230 --> 00:12:18.510 align:start position:0%
initialized so it essentially
corresponds<00:12:17.740><c> to</c><00:12:17.830><c> a</c><00:12:17.920><c> uniform</c><00:12:18.400><c> distribution</c>

00:12:18.510 --> 00:12:18.520 align:start position:0%
corresponds to a uniform distribution
 

00:12:18.520 --> 00:12:22.800 align:start position:0%
corresponds to a uniform distribution
over<00:12:19.650><c> binary</c><00:12:20.650><c> vectors</c><00:12:21.070><c> then</c><00:12:21.790><c> initially</c><00:12:22.660><c> one</c>

00:12:22.800 --> 00:12:22.810 align:start position:0%
over binary vectors then initially one
 

00:12:22.810 --> 00:12:24.090 align:start position:0%
over binary vectors then initially one
I'm<00:12:22.900><c> going</c><00:12:23.020><c> to</c><00:12:23.200><c> sample</c><00:12:23.410><c> is</c><00:12:23.650><c> really</c><00:12:23.890><c> going</c><00:12:24.040><c> to</c>

00:12:24.090 --> 00:12:24.100 align:start position:0%
I'm going to sample is really going to
 

00:12:24.100 --> 00:12:25.860 align:start position:0%
I'm going to sample is really going to
look<00:12:24.370><c> like</c><00:12:24.640><c> noise</c><00:12:25.000><c> essentially</c><00:12:25.570><c> it's</c><00:12:25.720><c> going</c>

00:12:25.860 --> 00:12:25.870 align:start position:0%
look like noise essentially it's going
 

00:12:25.870 --> 00:12:27.990 align:start position:0%
look like noise essentially it's going
to<00:12:25.930><c> look</c><00:12:26.050><c> like</c><00:12:26.110><c> something</c><00:12:26.830><c> like</c><00:12:26.860><c> this</c><00:12:27.010><c> and</c><00:12:27.459><c> so</c>

00:12:27.990 --> 00:12:28.000 align:start position:0%
to look like something like this and so
 

00:12:28.000 --> 00:12:29.790 align:start position:0%
to look like something like this and so
what<00:12:28.209><c> I'll</c><00:12:28.300><c> be</c><00:12:28.330><c> doing</c><00:12:28.600><c> is</c><00:12:28.870><c> then</c><00:12:29.110><c> making</c><00:12:29.529><c> the</c>

00:12:29.790 --> 00:12:29.800 align:start position:0%
what I'll be doing is then making the
 

00:12:29.800 --> 00:12:31.560 align:start position:0%
what I'll be doing is then making the
probability<00:12:30.520><c> of</c><00:12:30.550><c> sampling</c><00:12:31.000><c> something</c><00:12:31.420><c> like</c>

00:12:31.560 --> 00:12:31.570 align:start position:0%
probability of sampling something like
 

00:12:31.570 --> 00:12:34.710 align:start position:0%
probability of sampling something like
this<00:12:31.779><c> from</c><00:12:32.050><c> my</c><00:12:32.230><c> model</c><00:12:32.589><c> much</c><00:12:32.860><c> smaller</c><00:12:33.490><c> and</c><00:12:33.850><c> then</c>

00:12:34.710 --> 00:12:34.720 align:start position:0%
this from my model much smaller and then
 

00:12:34.720 --> 00:12:36.690 align:start position:0%
this from my model much smaller and then
I'll<00:12:34.839><c> continue</c><00:12:35.170><c> iterating</c><00:12:35.500><c> like</c><00:12:35.890><c> this</c><00:12:36.100><c> so</c>

00:12:36.690 --> 00:12:36.700 align:start position:0%
I'll continue iterating like this so
 

00:12:36.700 --> 00:12:38.519 align:start position:0%
I'll continue iterating like this so
next<00:12:36.880><c> time</c><00:12:37.060><c> around</c><00:12:37.209><c> it'll</c><00:12:37.750><c> be</c><00:12:37.839><c> less</c><00:12:38.080><c> likely</c>

00:12:38.519 --> 00:12:38.529 align:start position:0%
next time around it'll be less likely
 

00:12:38.529 --> 00:12:40.380 align:start position:0%
next time around it'll be less likely
that<00:12:38.560><c> X</c><00:12:39.010><c> still</c><00:12:39.250><c> would</c><00:12:39.430><c> look</c><00:12:39.610><c> like</c><00:12:40.120><c> a</c><00:12:40.150><c> random</c>

00:12:40.380 --> 00:12:40.390 align:start position:0%
that X still would look like a random
 

00:12:40.390 --> 00:12:43.230 align:start position:0%
that X still would look like a random
image<00:12:40.660><c> and</c><00:12:41.050><c> the</c><00:12:41.500><c> sample</c><00:12:42.339><c> value</c><00:12:42.700><c> for</c><00:12:42.910><c> X</c><00:12:43.060><c> still</c>

00:12:43.230 --> 00:12:43.240 align:start position:0%
image and the sample value for X still
 

00:12:43.240 --> 00:12:45.210 align:start position:0%
image and the sample value for X still
are<00:12:43.360><c> gonna</c><00:12:43.510><c> be</c><00:12:43.720><c> looking</c><00:12:44.470><c> more</c><00:12:44.650><c> and</c><00:12:44.770><c> more</c><00:12:44.890><c> like</c>

00:12:45.210 --> 00:12:45.220 align:start position:0%
are gonna be looking more and more like
 

00:12:45.220 --> 00:12:47.579 align:start position:0%
are gonna be looking more and more like
actual<00:12:46.089><c> training</c><00:12:46.360><c> examples</c><00:12:46.959><c> because</c><00:12:47.140><c> I</c><00:12:47.290><c> keep</c>

00:12:47.579 --> 00:12:47.589 align:start position:0%
actual training examples because I keep
 

00:12:47.589 --> 00:12:49.920 align:start position:0%
actual training examples because I keep
pushing<00:12:47.860><c> down</c><00:12:48.220><c> the</c><00:12:48.430><c> probability</c><00:12:48.640><c> of</c><00:12:49.300><c> anything</c>

00:12:49.920 --> 00:12:49.930 align:start position:0%
pushing down the probability of anything
 

00:12:49.930 --> 00:12:52.590 align:start position:0%
pushing down the probability of anything
that<00:12:49.959><c> doesn't</c><00:12:50.110><c> look</c><00:12:50.560><c> like</c><00:12:50.800><c> a</c><00:12:51.040><c> digit</c><00:12:51.520><c> and</c><00:12:51.640><c> so</c><00:12:52.450><c> we</c>

00:12:52.590 --> 00:12:52.600 align:start position:0%
that doesn't look like a digit and so we
 

00:12:52.600 --> 00:12:54.420 align:start position:0%
that doesn't look like a digit and so we
can<00:12:52.720><c> see</c><00:12:52.930><c> that</c><00:12:53.110><c> as</c><00:12:53.320><c> we</c><00:12:53.650><c> keep</c><00:12:53.800><c> sampling</c><00:12:54.250><c> like</c>

00:12:54.420 --> 00:12:54.430 align:start position:0%
can see that as we keep sampling like
 

00:12:54.430 --> 00:12:56.400 align:start position:0%
can see that as we keep sampling like
this<00:12:54.670><c> then</c><00:12:55.209><c> eventually</c><00:12:55.480><c> the</c><00:12:55.870><c> gradient</c><00:12:56.350><c> should</c>

00:12:56.400 --> 00:12:56.410 align:start position:0%
this then eventually the gradient should
 

00:12:56.410 --> 00:12:59.760 align:start position:0%
this then eventually the gradient should
become<00:12:56.800><c> smaller</c><00:12:57.130><c> because</c><00:12:57.430><c> the</c><00:12:58.390><c> value</c><00:12:59.290><c> of</c><00:12:59.380><c> XT</c>

00:12:59.760 --> 00:12:59.770 align:start position:0%
become smaller because the value of XT
 

00:12:59.770 --> 00:13:02.699 align:start position:0%
become smaller because the value of XT
is<00:13:00.010><c> gonna</c><00:13:00.250><c> be</c><00:13:00.760><c> more</c><00:13:01.329><c> more</c><00:13:01.600><c> similar</c><00:13:02.050><c> to</c><00:13:02.079><c> the</c>

00:13:02.699 --> 00:13:02.709 align:start position:0%
is gonna be more more similar to the
 

00:13:02.709 --> 00:13:05.670 align:start position:0%
is gonna be more more similar to the
sample<00:13:03.100><c> value</c><00:13:03.399><c> of</c><00:13:03.490><c> X</c><00:13:03.670><c> still</c><00:13:04.050><c> and</c><00:13:05.050><c> so</c><00:13:05.260><c> intuitive</c>

00:13:05.670 --> 00:13:05.680 align:start position:0%
sample value of X still and so intuitive
 

00:13:05.680 --> 00:13:07.319 align:start position:0%
sample value of X still and so intuitive
ly<00:13:06.010><c> this</c><00:13:06.220><c> algorithm</c><00:13:06.579><c> what</c><00:13:06.700><c> it's</c><00:13:06.850><c> doing</c><00:13:07.180><c> is</c>

00:13:07.319 --> 00:13:07.329 align:start position:0%
ly this algorithm what it's doing is
 

00:13:07.329 --> 00:13:10.710 align:start position:0%
ly this algorithm what it's doing is
that<00:13:07.450><c> it's</c><00:13:07.660><c> increasing</c><00:13:08.079><c> the</c><00:13:09.120><c> energy</c><00:13:10.149><c> sorry</c>

00:13:10.710 --> 00:13:10.720 align:start position:0%
that it's increasing the energy sorry
 

00:13:10.720 --> 00:13:12.870 align:start position:0%
that it's increasing the energy sorry
decreasing<00:13:11.200><c> the</c><00:13:11.290><c> energy</c><00:13:11.320><c> of</c><00:13:11.740><c> things</c><00:13:12.670><c> that</c>

00:13:12.870 --> 00:13:12.880 align:start position:0%
decreasing the energy of things that
 

00:13:12.880 --> 00:13:14.250 align:start position:0%
decreasing the energy of things that
look<00:13:13.029><c> like</c><00:13:13.089><c> what's</c><00:13:13.540><c> in</c><00:13:13.660><c> the</c><00:13:13.750><c> training</c><00:13:14.050><c> set</c>

00:13:14.250 --> 00:13:14.260 align:start position:0%
look like what's in the training set
 

00:13:14.260 --> 00:13:16.199 align:start position:0%
look like what's in the training set
while<00:13:14.560><c> increasing</c><00:13:15.040><c> the</c><00:13:15.339><c> energy</c><00:13:15.459><c> of</c><00:13:15.970><c> things</c>

00:13:16.199 --> 00:13:16.209 align:start position:0%
while increasing the energy of things
 

00:13:16.209 --> 00:13:18.000 align:start position:0%
while increasing the energy of things
that<00:13:16.450><c> are</c><00:13:17.410><c> as</c>

00:13:18.000 --> 00:13:18.010 align:start position:0%
that are as
 

00:13:18.010 --> 00:13:20.520 align:start position:0%
that are as
loosen<00:13:18.310><c> a</c><00:13:18.400><c> door</c><00:13:18.760><c> sample</c><00:13:19.180><c> by</c><00:13:19.330><c> the</c><00:13:19.390><c> model</c><00:13:19.840><c> and</c><00:13:20.020><c> we</c>

00:13:20.520 --> 00:13:20.530 align:start position:0%
loosen a door sample by the model and we
 

00:13:20.530 --> 00:13:22.470 align:start position:0%
loosen a door sample by the model and we
keep<00:13:20.710><c> doing</c><00:13:20.860><c> this</c><00:13:21.100><c> until</c><00:13:21.310><c> the</c><00:13:21.610><c> model</c><00:13:21.790><c> fits</c><00:13:22.240><c> out</c>

00:13:22.470 --> 00:13:22.480 align:start position:0%
keep doing this until the model fits out
 

00:13:22.480 --> 00:13:25.830 align:start position:0%
keep doing this until the model fits out
or<00:13:22.810><c> generates</c><00:13:24.150><c> observations</c><00:13:25.150><c> that</c><00:13:25.300><c> are</c><00:13:25.360><c> very</c>

00:13:25.830 --> 00:13:25.840 align:start position:0%
or generates observations that are very
 

00:13:25.840 --> 00:13:27.900 align:start position:0%
or generates observations that are very
similar<00:13:26.110><c> to</c><00:13:26.470><c> what's</c><00:13:26.680><c> in</c><00:13:26.830><c> the</c><00:13:27.040><c> model</c><00:13:27.520><c> in</c><00:13:27.700><c> other</c>

00:13:27.900 --> 00:13:27.910 align:start position:0%
similar to what's in the model in other
 

00:13:27.910 --> 00:13:31.440 align:start position:0%
similar to what's in the model in other
words<00:13:28.150><c> it's</c><00:13:28.360><c> become</c><00:13:28.630><c> a</c><00:13:28.660><c> good</c><00:13:28.960><c> model</c><00:13:29.260><c> of</c><00:13:30.450><c> our</c>

00:13:31.440 --> 00:13:31.450 align:start position:0%
words it's become a good model of our
 

00:13:31.450 --> 00:13:34.080 align:start position:0%
words it's become a good model of our
dataset

