Speaker 1:          00:00          The Joe Rogan experience. We're also, there's a concern about those systems being vulnerable to third party

Speaker 2:          00:07          attacks. Yeah. So hacking. Yeah, that's a, that's a fascinating question. I think there is a whole discipline called adversarial machine learning in AI, which basically any kind of system you can think of how we can feed it. Examples, how we can add a little bit of noise to the system to fool it completely. So there's been demonstrations on Alexa for example, where you can take a, you can take a, you can feed noise into the system that's imperceptible to us humans and make it believe you said anything. So fool the system into thinking, ordering extra toilet paper. I Dunno. Uh, in the same for cars, you can feed noise into the cameras to make us believe that there is, or there isn't a pedestrian,

Speaker 1:          00:59          there is or there isn't lane markings. So someone could do this in theory, at least

Speaker 2:          01:04          in a, in theory that's the big difference is in theory is doable. You can do demonstrations in practices actually really difficult to do in the real world. So in the lab you can do it, you can construct a situation where a pedestrian can wear certain types of clothing or put up a certain kind of sign where they disappear from the system.

Speaker 1:          01:22          I have to ask you this because now I just remembered this. You'd be the perfect person to talk about this. I'm not sure if you remember this case, but there was a guy named Michael Hastings, Michael Hastings with a journalist. And, uh, he was, I believe in Iraq or Afghanistan. He was somewhere overseas and he was stuck there because of this volcano that erupted and I believe Iceland. And he was over there for the Rolling Stone magazine, uh, and doing, doing an article about a general, well, he stayed there for a long time because they were stranded because of the volcano and they got real comfortable around him. And, uh, he reported a lot of the stuff that they said and did that maybe they thought that he probably wouldn't have reported on, including them saying disparaging things about President Obama at the time. Anyway, comes back, the general was forced to resign.

Speaker 1:          02:15          Um, he was a beloved general and, uh, Michael Hastings was in fearing for his life because he thought that they were going to come and get him because these people were very, very angry at him. He wound up driving his car into a tree going like 120 miles an hour and the car exploded and the engine went flying. And people that were the conspiracy theorists were saying they believe that that car had been rigged to work autonomously or that someone for some third party bad person decided to, or good person, depending on your perspective, decided to drive that guy's car into a fucking tree at 120 miles an hour. Do you think that that and is

Speaker 2:          03:00          2011, Michael Hastings def 12, maybe 2012 I think that sounds great. Let's see what it says. 2013, 2013. June, 2013. Do you think that in 2013 that would have been possible?

Speaker 3:          03:21          Okay.

Speaker 2:          03:24          It's entirely possible. No, I just wanted to say that. [inaudible] shout out to the Joe Rogan sub reddit. Okay. Uh, check that one off the list. Jamie. Pull that up, chat off. Um,

Speaker 3:          03:46          Aye.

Speaker 2:          03:47          Whether it's possible is an interesting question, whether it's likely is another question. I, I think it's very unlikely and the other most important questions, that's something we should worry at scale, but our future is cars being used to assassinate essentially people. I'm Russian, so I've, I've heard of those things being done by our friend Putin of it. Um, I think, I think it's very unlikely that this kind of thing would happen at scale, that people would use this. I think there'll be more effective ways to achieve this kind of end for sure. And I, I just think it's a very difficult technical challenge that uh, uh, if hacking happens, it would be at a different level than hacking the AI systems. It'll be just hacking software, right? And hacking software is the kind of the, the kind of thing that can happen with anything. An elevator saw, elevate a software or, uh, any kind of software that operates, any aspect of our lives could be hacked. And that same kind of way. Right. My, my question though was in 2013, was that technology available where they could take over someone's car?

Speaker 2:          05:02          Do you know what car it was? Mercedes, I think it was an s class, C C C C class as is. Yes, yes, yes. But I, I don't think, oh boy, this is like a no, it's, listen, this has been widely speculated. I know, I'm just asking you because you're actually an expert. I mean, it's very rare that you get an expert in autonomous vehicles and you get to run a conspiracy theory behind them to see if they can just put a stamp on it being possible or not. Let me just say that Alex Jones is a fishing, not allowed to say MIT scientists says she's exactly what he's going to try to do. Uh, no, I, um, first of all, let me back off and say I am not a security expert, which is a very important difference. That is important. So then a autonomous vehicle, I'd build a autonomous vehicle systems. I don't know how to make them extremely robust. The security to hacking attacks, right. And have a lot of really good friends, which are some of the coolest people. Uh, I know who are basically hackers converted to security experts. I would say though, loosely speaking, I think the technology was there yes. For with physical access to the car to be able to control it. But I don't, I think it's extremely unlikely. That's what happened.

Speaker 1:          06:16          I agree. I see where you're coming from. I'm not asking you whether or not it's likely that it happened and I'm, I'm sure you don't even have much information on the case cause I had to explain it to you. Right. That's right. I'm the guy also had, uh, some serious amphetamines in the system. Um, they compared it to crystal Meth, but the reality is he was a journalist and most journalists, I don't want to say most all lot are on Adderall and Adderall is essentially amphetamines. I mean, that's what it is. It's real. It's like, it's like next door neighbors to crystal meth really is. Um,

Speaker 2:          06:54          he is it, well you said it's possible they could actually get it to turn the wheel. Yes. I have to look at the exact system. Like I said, drive by wire thing that I mentioned. Some systems are not, uh, it's not so easy to turn. The wheel actually could

Speaker 1:          07:11          get them to just accelerate out of control. He's going like 120 something miles now and just slammed into a tree

Speaker 2:          07:17          entirely possible. Ah, you can't do it twice. The, um, the systems back then though, we're far more primitive. Correct? Yeah. Uh, yeah, but it's, it's really, again, the, the attack vectors here. The, so the way you hack these systems, I have more to do with the software Lola of software that can be primitive than the high level AI stuff. Right. But my issue with was there's no cameras on the outside of the vehicle, like there is on Tesla today, which has autonomous driving as an option as a, so, okay. I see your point now. So he wouldn't be hacking the system that perceives the world and act in the world. It would literally be malfunction that forces it to not be able to brake, accelerate uncontrollably, which is, uh, you know, it's a more basic kind of attack and then control then making the car steer auto lane.

Speaker 2:          08:07          Yes, yes. That's a different, that's what people worry about with autonomous vehicles. Once more and more, you're talking about potentially 10, 20 million lines of source code. So there's all this code and so obviously becomes, uh, amenable, susceptible to bugs that can be exploited to hack the code. And so people are worried, uh, legitimately so that these security attacks would, uh, would lead to these kind of, um, well at the worst case assassinations, but really sort of just basic, uh, basic attacks, basic a hacking attacks. And I think it's, I think that's something that people in the automotive industry and certainly Tesla's really working hard on and making sure that the ad that everything is secure, there's going to be, of course vulnerabilities always. But, uh, I think they're really serious about preventing them. But in the demonstration space, you'd be able to demonstrate some interesting ways to trick the system in terms of computer vision. This all boils down to that these systems are actually, that are ones that are camera based, are not as robust as our human eyes are to the world. So like I said, if you add a little bit of noise, you can convince it to see anything to us humans that look like the same road, like the same three pedestrians, costumes, trawler a little person on the camera lens,

Speaker 1:          09:34          the little cameras, right. You could get down there with a sharpie. That's, that's, that's the one attack vector. That's a as draw stuff. But you jokingly say that, but that's I believe is possible. The Sun plays tricks on Cadillac, Super Cruise, next generation system. We'll address camera problem. Oh well as long as the next generation addresses that you fucking assholes. The Sun plays tricks on it. So next gen system is something you're going to have to bring that Cadillac into the dealership and they're going to have to update the software, update it yet. Whereas Tessa would just handle that shit over the area. Yeah, I got an update the other day. I was like, all right, all right. Question.

Speaker 2:          10:10          Same as, so that, that's an exciting, powerful capability. But then the Boeing, the flip side is, you know, uh, it can significantly change the behavior of the system. And there, there could be a glitch that could be a glitch that could be a bug that the Boeing one's terrifying, especially with a lot of, I mean, that number, whatever it is, it's like 300 combined, 300 plus people dead, maybe even 400. I mean, it's, I don't even know how to think. Think about that number. Yeah. All from a software glitch, the guy who created it or the girl who quoted it must feel fucking terrible. Yeah. And you kind of, you, you walk, man. It's, it's, uh, it's a lot of burden and it's one of the reasons it's one of the most exciting things to work on actually, is the code we write has the capability to save human life. But the terrifying thing is also has the capability to take human life. And that's a, that's a weird place to be as an engineer or directly, a little piece of code. You know, I'll write thousands of them a day. You know, basically notes you're taking could eventually lead to a, somebody dying

Speaker 4:          11:29          [inaudible].