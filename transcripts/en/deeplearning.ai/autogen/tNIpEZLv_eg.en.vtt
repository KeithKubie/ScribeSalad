WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.060 align:start position:0%
 
in<00:00:00.269><c> the</c><00:00:00.420><c> rise</c><00:00:00.599><c> of</c><00:00:00.780><c> deep</c><00:00:00.960><c> learning</c><00:00:01.170><c> one</c><00:00:01.890><c> of</c><00:00:02.010><c> the</c>

00:00:02.060 --> 00:00:02.070 align:start position:0%
in the rise of deep learning one of the
 

00:00:02.070 --> 00:00:04.010 align:start position:0%
in the rise of deep learning one of the
most<00:00:02.250><c> important</c><00:00:02.760><c> ideas</c><00:00:02.909><c> has</c><00:00:03.600><c> been</c><00:00:03.840><c> an</c>

00:00:04.010 --> 00:00:04.020 align:start position:0%
most important ideas has been an
 

00:00:04.020 --> 00:00:05.869 align:start position:0%
most important ideas has been an
algorithm<00:00:04.500><c> called</c><00:00:04.770><c> batch</c><00:00:05.009><c> normalization</c>

00:00:05.869 --> 00:00:05.879 align:start position:0%
algorithm called batch normalization
 

00:00:05.879 --> 00:00:08.810 align:start position:0%
algorithm called batch normalization
created<00:00:06.750><c> by</c><00:00:06.870><c> two</c><00:00:06.930><c> researchers</c><00:00:07.290><c> Sergey</c><00:00:08.280><c> iov</c>

00:00:08.810 --> 00:00:08.820 align:start position:0%
created by two researchers Sergey iov
 

00:00:08.820 --> 00:00:10.910 align:start position:0%
created by two researchers Sergey iov
and<00:00:09.090><c> Christians</c><00:00:09.750><c> a</c><00:00:09.960><c> greedy</c><00:00:10.200><c> batch</c>

00:00:10.910 --> 00:00:10.920 align:start position:0%
and Christians a greedy batch
 

00:00:10.920 --> 00:00:12.620 align:start position:0%
and Christians a greedy batch
normalization<00:00:11.759><c> it</c><00:00:11.969><c> makes</c><00:00:12.179><c> your</c><00:00:12.360><c> hyper</c>

00:00:12.620 --> 00:00:12.630 align:start position:0%
normalization it makes your hyper
 

00:00:12.630 --> 00:00:14.270 align:start position:0%
normalization it makes your hyper
parameter<00:00:13.049><c> search</c><00:00:13.230><c> probably</c><00:00:13.500><c> much</c><00:00:13.740><c> easier</c><00:00:14.130><c> it</c>

00:00:14.270 --> 00:00:14.280 align:start position:0%
parameter search probably much easier it
 

00:00:14.280 --> 00:00:15.740 align:start position:0%
parameter search probably much easier it
makes<00:00:14.340><c> your</c><00:00:14.580><c> neural</c><00:00:14.790><c> network</c><00:00:15.089><c> much</c><00:00:15.540><c> more</c>

00:00:15.740 --> 00:00:15.750 align:start position:0%
makes your neural network much more
 

00:00:15.750 --> 00:00:17.510 align:start position:0%
makes your neural network much more
robust<00:00:16.230><c> to</c><00:00:16.410><c> the</c><00:00:16.500><c> choice</c><00:00:16.680><c> of</c><00:00:16.859><c> hyper</c><00:00:17.039><c> parameters</c>

00:00:17.510 --> 00:00:17.520 align:start position:0%
robust to the choice of hyper parameters
 

00:00:17.520 --> 00:00:19.730 align:start position:0%
robust to the choice of hyper parameters
is<00:00:17.730><c> much</c><00:00:17.940><c> bigger</c><00:00:18.180><c> range</c><00:00:18.510><c> of</c><00:00:18.779><c> hyper</c><00:00:19.320><c> parameters</c>

00:00:19.730 --> 00:00:19.740 align:start position:0%
is much bigger range of hyper parameters
 

00:00:19.740 --> 00:00:21.769 align:start position:0%
is much bigger range of hyper parameters
that<00:00:19.890><c> work</c><00:00:20.070><c> well</c><00:00:20.310><c> and</c><00:00:20.520><c> they'll</c><00:00:21.000><c> also</c><00:00:21.180><c> enable</c>

00:00:21.769 --> 00:00:21.779 align:start position:0%
that work well and they'll also enable
 

00:00:21.779 --> 00:00:23.900 align:start position:0%
that work well and they'll also enable
you<00:00:21.930><c> to</c><00:00:21.960><c> much</c><00:00:22.289><c> more</c><00:00:22.439><c> easily</c><00:00:22.650><c> train</c><00:00:23.310><c> even</c><00:00:23.699><c> very</c>

00:00:23.900 --> 00:00:23.910 align:start position:0%
you to much more easily train even very
 

00:00:23.910 --> 00:00:26.120 align:start position:0%
you to much more easily train even very
deep<00:00:24.150><c> networks</c><00:00:24.660><c> let's</c><00:00:25.590><c> see</c><00:00:25.740><c> how</c><00:00:25.890><c> batch</c>

00:00:26.120 --> 00:00:26.130 align:start position:0%
deep networks let's see how batch
 

00:00:26.130 --> 00:00:28.519 align:start position:0%
deep networks let's see how batch
normalization<00:00:26.910><c> works</c><00:00:27.090><c> when</c><00:00:27.930><c> training</c><00:00:28.320><c> a</c>

00:00:28.519 --> 00:00:28.529 align:start position:0%
normalization works when training a
 

00:00:28.529 --> 00:00:31.009 align:start position:0%
normalization works when training a
model<00:00:28.920><c> such</c><00:00:29.279><c> as</c><00:00:29.310><c> logistic</c><00:00:29.939><c> regression</c><00:00:30.420><c> you</c>

00:00:31.009 --> 00:00:31.019 align:start position:0%
model such as logistic regression you
 

00:00:31.019 --> 00:00:34.069 align:start position:0%
model such as logistic regression you
might<00:00:31.260><c> remember</c><00:00:31.439><c> that</c><00:00:32.570><c> normalizing</c><00:00:33.570><c> the</c>

00:00:34.069 --> 00:00:34.079 align:start position:0%
might remember that normalizing the
 

00:00:34.079 --> 00:00:36.470 align:start position:0%
might remember that normalizing the
input<00:00:34.620><c> features</c><00:00:34.800><c> can</c><00:00:35.340><c> speed</c><00:00:35.610><c> up</c><00:00:35.790><c> learning</c><00:00:36.000><c> in</c>

00:00:36.470 --> 00:00:36.480 align:start position:0%
input features can speed up learning in
 

00:00:36.480 --> 00:00:39.319 align:start position:0%
input features can speed up learning in
computer<00:00:36.930><c> means</c><00:00:37.399><c> subtract</c><00:00:38.399><c> off</c><00:00:38.670><c> the</c><00:00:38.700><c> means</c><00:00:39.090><c> of</c>

00:00:39.319 --> 00:00:39.329 align:start position:0%
computer means subtract off the means of
 

00:00:39.329 --> 00:00:43.420 align:start position:0%
computer means subtract off the means of
your<00:00:39.450><c> training</c><00:00:39.660><c> set</c><00:00:40.070><c> computer</c><00:00:41.070><c> variances</c>

00:00:43.420 --> 00:00:43.430 align:start position:0%
your training set computer variances
 

00:00:43.430 --> 00:00:46.340 align:start position:0%
your training set computer variances
this<00:00:44.430><c> sum</c><00:00:45.000><c> of</c><00:00:45.030><c> X</c><00:00:45.390><c> I</c><00:00:45.539><c> squared</c><00:00:45.960><c> this</c><00:00:46.140><c> is</c><00:00:46.200><c> a</c>

00:00:46.340 --> 00:00:46.350 align:start position:0%
this sum of X I squared this is a
 

00:00:46.350 --> 00:00:50.750 align:start position:0%
this sum of X I squared this is a
element<00:00:47.219><c> wise</c><00:00:47.430><c> squaring</c><00:00:48.829><c> and</c><00:00:49.829><c> then</c><00:00:50.190><c> normalize</c>

00:00:50.750 --> 00:00:50.760 align:start position:0%
element wise squaring and then normalize
 

00:00:50.760 --> 00:00:53.299 align:start position:0%
element wise squaring and then normalize
your<00:00:50.820><c> data</c><00:00:51.030><c> set</c><00:00:51.449><c> according</c><00:00:51.960><c> to</c><00:00:51.989><c> the</c><00:00:52.309><c> variances</c>

00:00:53.299 --> 00:00:53.309 align:start position:0%
your data set according to the variances
 

00:00:53.309 --> 00:00:55.610 align:start position:0%
your data set according to the variances
and<00:00:53.670><c> we</c><00:00:54.059><c> form</c><00:00:54.329><c> an</c><00:00:54.480><c> earlier</c><00:00:54.780><c> video</c><00:00:54.899><c> how</c><00:00:55.379><c> this</c>

00:00:55.610 --> 00:00:55.620 align:start position:0%
and we form an earlier video how this
 

00:00:55.620 --> 00:00:57.950 align:start position:0%
and we form an earlier video how this
can<00:00:55.890><c> turn</c><00:00:56.550><c> the</c><00:00:56.730><c> contours</c><00:00:57.329><c> of</c><00:00:57.510><c> the</c><00:00:57.570><c> learning</c>

00:00:57.950 --> 00:00:57.960 align:start position:0%
can turn the contours of the learning
 

00:00:57.960 --> 00:00:59.270 align:start position:0%
can turn the contours of the learning
problem<00:00:58.170><c> from</c><00:00:58.530><c> something</c><00:00:58.890><c> that</c><00:00:59.010><c> might</c><00:00:59.160><c> be</c>

00:00:59.270 --> 00:00:59.280 align:start position:0%
problem from something that might be
 

00:00:59.280 --> 00:01:01.790 align:start position:0%
problem from something that might be
very<00:00:59.399><c> elongated</c><00:01:00.109><c> you</c><00:01:01.109><c> know</c><00:01:01.170><c> something</c><00:01:01.559><c> that</c>

00:01:01.790 --> 00:01:01.800 align:start position:0%
very elongated you know something that
 

00:01:01.800 --> 00:01:04.399 align:start position:0%
very elongated you know something that
is<00:01:02.010><c> more</c><00:01:02.550><c> round</c><00:01:02.789><c> and</c><00:01:03.120><c> easier</c><00:01:03.629><c> for</c><00:01:04.350><c> an</c>

00:01:04.399 --> 00:01:04.409 align:start position:0%
is more round and easier for an
 

00:01:04.409 --> 00:01:06.050 align:start position:0%
is more round and easier for an
algorithm<00:01:05.100><c> like</c><00:01:05.129><c> gradient</c><00:01:05.309><c> descent</c><00:01:05.700><c> to</c>

00:01:06.050 --> 00:01:06.060 align:start position:0%
algorithm like gradient descent to
 

00:01:06.060 --> 00:01:09.410 align:start position:0%
algorithm like gradient descent to
optimize<00:01:06.540><c> so</c><00:01:07.320><c> this</c><00:01:07.619><c> works</c><00:01:07.890><c> in</c><00:01:08.820><c> terms</c><00:01:09.180><c> of</c>

00:01:09.410 --> 00:01:09.420 align:start position:0%
optimize so this works in terms of
 

00:01:09.420 --> 00:01:12.260 align:start position:0%
optimize so this works in terms of
normalizing<00:01:09.990><c> the</c><00:01:10.380><c> input</c><00:01:10.920><c> feature</c><00:01:11.189><c> values</c><00:01:11.490><c> to</c>

00:01:12.260 --> 00:01:12.270 align:start position:0%
normalizing the input feature values to
 

00:01:12.270 --> 00:01:15.050 align:start position:0%
normalizing the input feature values to
a<00:01:12.510><c> new</c><00:01:13.320><c> network</c><00:01:13.590><c> or</c><00:01:13.950><c> to</c><00:01:14.189><c> logistic</c><00:01:14.610><c> regression</c>

00:01:15.050 --> 00:01:15.060 align:start position:0%
a new network or to logistic regression
 

00:01:15.060 --> 00:01:18.050 align:start position:0%
a new network or to logistic regression
now<00:01:15.540><c> how</c><00:01:16.020><c> about</c><00:01:16.200><c> a</c><00:01:16.500><c> deeper</c><00:01:16.950><c> model</c><00:01:17.430><c> you</c><00:01:17.850><c> have</c>

00:01:18.050 --> 00:01:18.060 align:start position:0%
now how about a deeper model you have
 

00:01:18.060 --> 00:01:20.240 align:start position:0%
now how about a deeper model you have
not<00:01:18.299><c> just</c><00:01:18.570><c> input</c><00:01:19.049><c> features</c><00:01:19.409><c> X</c><00:01:19.650><c> but</c><00:01:19.979><c> in</c><00:01:20.100><c> this</c>

00:01:20.240 --> 00:01:20.250 align:start position:0%
not just input features X but in this
 

00:01:20.250 --> 00:01:23.630 align:start position:0%
not just input features X but in this
layer<00:01:20.549><c> you</c><00:01:20.909><c> have</c><00:01:21.049><c> activations</c><00:01:22.049><c> a</c><00:01:22.320><c> one</c><00:01:23.159><c> in</c><00:01:23.460><c> this</c>

00:01:23.630 --> 00:01:23.640 align:start position:0%
layer you have activations a one in this
 

00:01:23.640 --> 00:01:26.270 align:start position:0%
layer you have activations a one in this
layer<00:01:23.909><c> you</c><00:01:23.939><c> have</c><00:01:24.119><c> activations</c><00:01:24.810><c> a</c><00:01:25.049><c> two</c><00:01:25.110><c> and</c><00:01:25.560><c> so</c>

00:01:26.270 --> 00:01:26.280 align:start position:0%
layer you have activations a two and so
 

00:01:26.280 --> 00:01:28.850 align:start position:0%
layer you have activations a two and so
on<00:01:26.360><c> so</c><00:01:27.360><c> if</c><00:01:27.750><c> you</c><00:01:27.960><c> want</c><00:01:28.170><c> to</c><00:01:28.259><c> train</c><00:01:28.650><c> the</c>

00:01:28.850 --> 00:01:28.860 align:start position:0%
on so if you want to train the
 

00:01:28.860 --> 00:01:34.789 align:start position:0%
on so if you want to train the
parameters<00:01:29.570><c> say</c><00:01:30.570><c> W</c><00:01:31.110><c> 3</c><00:01:31.640><c> B</c><00:01:32.640><c> 3</c><00:01:33.229><c> then</c><00:01:34.229><c> one</c><00:01:34.560><c> would</c><00:01:34.680><c> be</c>

00:01:34.789 --> 00:01:34.799 align:start position:0%
parameters say W 3 B 3 then one would be
 

00:01:34.799 --> 00:01:36.800 align:start position:0%
parameters say W 3 B 3 then one would be
nice<00:01:34.979><c> if</c><00:01:35.250><c> you</c><00:01:35.340><c> can</c><00:01:35.520><c> normalize</c><00:01:36.060><c> the</c><00:01:36.450><c> mean</c><00:01:36.630><c> and</c>

00:01:36.800 --> 00:01:36.810 align:start position:0%
nice if you can normalize the mean and
 

00:01:36.810 --> 00:01:39.740 align:start position:0%
nice if you can normalize the mean and
variance<00:01:36.840><c> of</c><00:01:37.380><c> a</c><00:01:37.560><c> two</c><00:01:37.759><c> to</c><00:01:38.759><c> make</c><00:01:38.939><c> the</c><00:01:39.240><c> training</c>

00:01:39.740 --> 00:01:39.750 align:start position:0%
variance of a two to make the training
 

00:01:39.750 --> 00:01:43.700 align:start position:0%
variance of a two to make the training
of<00:01:39.960><c> W</c><00:01:40.439><c> 3</c><00:01:40.740><c> B</c><00:01:41.009><c> 3</c><00:01:41.060><c> more</c><00:01:42.060><c> efficient</c><00:01:42.540><c> in</c><00:01:42.780><c> the</c><00:01:43.320><c> case</c><00:01:43.530><c> of</c>

00:01:43.700 --> 00:01:43.710 align:start position:0%
of W 3 B 3 more efficient in the case of
 

00:01:43.710 --> 00:01:45.760 align:start position:0%
of W 3 B 3 more efficient in the case of
logistic<00:01:44.130><c> regression</c><00:01:44.640><c> we</c><00:01:44.939><c> saw</c><00:01:45.180><c> how</c>

00:01:45.760 --> 00:01:45.770 align:start position:0%
logistic regression we saw how
 

00:01:45.770 --> 00:01:48.679 align:start position:0%
logistic regression we saw how
normalizing<00:01:46.770><c> x1</c><00:01:47.189><c> x2</c><00:01:47.399><c> x3</c><00:01:47.700><c> maybe</c><00:01:48.180><c> helps</c><00:01:48.540><c> you</c>

00:01:48.679 --> 00:01:48.689 align:start position:0%
normalizing x1 x2 x3 maybe helps you
 

00:01:48.689 --> 00:01:51.980 align:start position:0%
normalizing x1 x2 x3 maybe helps you
train<00:01:48.899><c> W</c><00:01:49.320><c> and</c><00:01:49.500><c> B</c><00:01:49.710><c> more</c><00:01:50.130><c> efficiently</c><00:01:50.610><c> so</c><00:01:51.600><c> here</c>

00:01:51.980 --> 00:01:51.990 align:start position:0%
train W and B more efficiently so here
 

00:01:51.990 --> 00:01:54.889 align:start position:0%
train W and B more efficiently so here
the<00:01:52.259><c> question</c><00:01:52.409><c> is</c><00:01:52.799><c> for</c><00:01:53.159><c> any</c><00:01:53.340><c> hidden</c><00:01:53.729><c> layer</c><00:01:53.909><c> can</c>

00:01:54.889 --> 00:01:54.899 align:start position:0%
the question is for any hidden layer can
 

00:01:54.899 --> 00:02:00.709 align:start position:0%
the question is for any hidden layer can
we<00:01:55.110><c> normalize</c><00:01:57.500><c> the</c><00:01:58.500><c> values</c><00:01:58.979><c> of</c><00:01:59.280><c> a</c><00:01:59.540><c> let's</c><00:02:00.540><c> say</c><00:02:00.689><c> a</c>

00:02:00.709 --> 00:02:00.719 align:start position:0%
we normalize the values of a let's say a
 

00:02:00.719 --> 00:02:02.929 align:start position:0%
we normalize the values of a let's say a
2<00:02:00.930><c> in</c><00:02:01.439><c> this</c><00:02:01.560><c> example</c><00:02:01.950><c> but</c><00:02:02.280><c> really</c><00:02:02.549><c> anything</c>

00:02:02.929 --> 00:02:02.939 align:start position:0%
2 in this example but really anything
 

00:02:02.939 --> 00:02:08.690 align:start position:0%
2 in this example but really anything
later<00:02:03.799><c> so</c><00:02:04.799><c> as</c><00:02:05.009><c> to</c><00:02:05.280><c> train</c><00:02:07.280><c> W</c>

00:02:08.690 --> 00:02:08.700 align:start position:0%
later so as to train W
 

00:02:08.700 --> 00:02:14.009 align:start position:0%
later so as to train W
bb3<00:02:10.409><c> faster</c><00:02:11.459><c> right</c><00:02:12.459><c> since</c><00:02:12.730><c> a2</c><00:02:13.000><c> is</c><00:02:13.420><c> the</c><00:02:13.569><c> input</c>

00:02:14.009 --> 00:02:14.019 align:start position:0%
bb3 faster right since a2 is the input
 

00:02:14.019 --> 00:02:17.190 align:start position:0%
bb3 faster right since a2 is the input
to<00:02:14.920><c> the</c><00:02:15.040><c> next</c><00:02:15.220><c> layer</c><00:02:15.340><c> that</c><00:02:15.849><c> therefore</c><00:02:16.720><c> affects</c>

00:02:17.190 --> 00:02:17.200 align:start position:0%
to the next layer that therefore affects
 

00:02:17.200 --> 00:02:20.880 align:start position:0%
to the next layer that therefore affects
the<00:02:17.319><c> training</c><00:02:17.739><c> of</c><00:02:17.830><c> w3</c><00:02:18.489><c> and</c><00:02:18.700><c> b3</c><00:02:19.470><c> so</c><00:02:20.470><c> this</c><00:02:20.739><c> is</c>

00:02:20.880 --> 00:02:20.890 align:start position:0%
the training of w3 and b3 so this is
 

00:02:20.890 --> 00:02:23.640 align:start position:0%
the training of w3 and b3 so this is
what<00:02:21.150><c> passional</c><00:02:22.150><c> does</c><00:02:22.510><c> batch</c><00:02:22.870><c> normalization</c>

00:02:23.640 --> 00:02:23.650 align:start position:0%
what passional does batch normalization
 

00:02:23.650 --> 00:02:25.830 align:start position:0%
what passional does batch normalization
or<00:02:23.799><c> national</c><00:02:24.310><c> for</c><00:02:24.549><c> short</c><00:02:24.760><c> does</c><00:02:25.090><c> although</c>

00:02:25.830 --> 00:02:25.840 align:start position:0%
or national for short does although
 

00:02:25.840 --> 00:02:28.710 align:start position:0%
or national for short does although
technically<00:02:26.319><c> will</c><00:02:26.680><c> actually</c><00:02:27.099><c> normalize</c><00:02:27.720><c> the</c>

00:02:28.710 --> 00:02:28.720 align:start position:0%
technically will actually normalize the
 

00:02:28.720 --> 00:02:32.910 align:start position:0%
technically will actually normalize the
values<00:02:29.200><c> of</c><00:02:29.530><c> not</c><00:02:30.190><c> a</c><00:02:30.459><c> two</c><00:02:30.519><c> but</c><00:02:31.510><c> z</c><00:02:31.810><c> 2</c><00:02:32.049><c> there</c><00:02:32.799><c> is</c>

00:02:32.910 --> 00:02:32.920 align:start position:0%
values of not a two but z 2 there is
 

00:02:32.920 --> 00:02:34.500 align:start position:0%
values of not a two but z 2 there is
some<00:02:33.129><c> debate</c><00:02:33.430><c> in</c><00:02:33.700><c> the</c><00:02:34.060><c> deep</c><00:02:34.299><c> learning</c>

00:02:34.500 --> 00:02:34.510 align:start position:0%
some debate in the deep learning
 

00:02:34.510 --> 00:02:35.960 align:start position:0%
some debate in the deep learning
literature<00:02:35.260><c> about</c><00:02:35.470><c> whether</c><00:02:35.829><c> you</c><00:02:35.890><c> should</c>

00:02:35.960 --> 00:02:35.970 align:start position:0%
literature about whether you should
 

00:02:35.970 --> 00:02:38.009 align:start position:0%
literature about whether you should
normalize<00:02:36.970><c> the</c><00:02:37.239><c> value</c><00:02:37.569><c> before</c><00:02:37.780><c> the</c>

00:02:38.009 --> 00:02:38.019 align:start position:0%
normalize the value before the
 

00:02:38.019 --> 00:02:40.710 align:start position:0%
normalize the value before the
activation<00:02:38.680><c> functions</c><00:02:39.099><c> on</c><00:02:39.430><c> v2</c><00:02:39.849><c> or</c><00:02:40.360><c> whether</c>

00:02:40.710 --> 00:02:40.720 align:start position:0%
activation functions on v2 or whether
 

00:02:40.720 --> 00:02:42.089 align:start position:0%
activation functions on v2 or whether
they<00:02:40.810><c> should</c><00:02:40.870><c> normalize</c><00:02:41.319><c> the</c><00:02:41.530><c> value</c><00:02:41.890><c> after</c>

00:02:42.089 --> 00:02:42.099 align:start position:0%
they should normalize the value after
 

00:02:42.099 --> 00:02:44.910 align:start position:0%
they should normalize the value after
applying<00:02:42.940><c> the</c><00:02:43.090><c> activation</c><00:02:43.540><c> function</c><00:02:43.569><c> a</c><00:02:44.109><c> to</c><00:02:44.440><c> in</c>

00:02:44.910 --> 00:02:44.920 align:start position:0%
applying the activation function a to in
 

00:02:44.920 --> 00:02:48.030 align:start position:0%
applying the activation function a to in
practice<00:02:45.280><c> normalizing</c><00:02:46.269><c> z2</c><00:02:46.750><c> is</c><00:02:46.799><c> done</c><00:02:47.799><c> much</c>

00:02:48.030 --> 00:02:48.040 align:start position:0%
practice normalizing z2 is done much
 

00:02:48.040 --> 00:02:50.940 align:start position:0%
practice normalizing z2 is done much
more<00:02:48.280><c> often</c><00:02:48.489><c> so</c><00:02:49.120><c> that's</c><00:02:49.959><c> the</c><00:02:50.290><c> version</c><00:02:50.620><c> I</c>

00:02:50.940 --> 00:02:50.950 align:start position:0%
more often so that's the version I
 

00:02:50.950 --> 00:02:52.710 align:start position:0%
more often so that's the version I
present<00:02:51.370><c> and</c><00:02:51.579><c> what</c><00:02:51.730><c> I</c><00:02:51.760><c> would</c><00:02:52.030><c> recommend</c><00:02:52.180><c> you</c>

00:02:52.710 --> 00:02:52.720 align:start position:0%
present and what I would recommend you
 

00:02:52.720 --> 00:02:56.160 align:start position:0%
present and what I would recommend you
use<00:02:53.319><c> as</c><00:02:53.530><c> a</c><00:02:53.560><c> default</c><00:02:54.069><c> choice</c><00:02:54.370><c> so</c><00:02:55.180><c> here</c><00:02:55.629><c> is</c><00:02:55.840><c> how</c>

00:02:56.160 --> 00:02:56.170 align:start position:0%
use as a default choice so here is how
 

00:02:56.170 --> 00:02:58.860 align:start position:0%
use as a default choice so here is how
you<00:02:56.230><c> would</c><00:02:56.530><c> implement</c><00:02:56.739><c> batch</c><00:02:57.579><c> norm</c><00:02:58.060><c> given</c>

00:02:58.860 --> 00:02:58.870 align:start position:0%
you would implement batch norm given
 

00:02:58.870 --> 00:03:05.640 align:start position:0%
you would implement batch norm given
some<00:02:59.319><c> intermediate</c><00:03:00.010><c> values</c><00:03:04.109><c> in</c><00:03:05.109><c> your</c><00:03:05.409><c> neural</c>

00:03:05.640 --> 00:03:05.650 align:start position:0%
some intermediate values in your neural
 

00:03:05.650 --> 00:03:12.539 align:start position:0%
some intermediate values in your neural
net<00:03:09.060><c> let's</c><00:03:10.060><c> say</c><00:03:10.269><c> that</c><00:03:10.480><c> you</c><00:03:10.780><c> have</c><00:03:11.340><c> some</c><00:03:12.340><c> hidden</c>

00:03:12.539 --> 00:03:12.549 align:start position:0%
net let's say that you have some hidden
 

00:03:12.549 --> 00:03:19.289 align:start position:0%
net let's say that you have some hidden
unit<00:03:13.889><c> values</c><00:03:14.889><c> z</c><00:03:15.310><c> 1</c><00:03:15.579><c> up</c><00:03:16.450><c> to</c><00:03:17.010><c> ZM</c><00:03:18.010><c> and</c><00:03:18.340><c> this</c><00:03:19.180><c> is</c>

00:03:19.289 --> 00:03:19.299 align:start position:0%
unit values z 1 up to ZM and this is
 

00:03:19.299 --> 00:03:22.770 align:start position:0%
unit values z 1 up to ZM and this is
really<00:03:19.630><c> from</c><00:03:20.200><c> some</c><00:03:20.500><c> hidden</c><00:03:20.919><c> layer</c><00:03:21.220><c> so</c><00:03:21.669><c> it</c><00:03:22.540><c> be</c>

00:03:22.770 --> 00:03:22.780 align:start position:0%
really from some hidden layer so it be
 

00:03:22.780 --> 00:03:25.409 align:start position:0%
really from some hidden layer so it be
more<00:03:23.019><c> accurate</c><00:03:23.489><c> dividers</c><00:03:24.489><c> as</c><00:03:24.669><c> if</c><00:03:24.940><c> the</c><00:03:25.180><c> some</c>

00:03:25.409 --> 00:03:25.419 align:start position:0%
more accurate dividers as if the some
 

00:03:25.419 --> 00:03:28.080 align:start position:0%
more accurate dividers as if the some
hidden<00:03:25.629><c> layer</c><00:03:25.900><c> I</c><00:03:26.230><c> for</c><00:03:27.069><c> I</c><00:03:27.190><c> equals</c><00:03:27.519><c> 1</c><00:03:27.700><c> through</c><00:03:27.790><c> m</c>

00:03:28.080 --> 00:03:28.090 align:start position:0%
hidden layer I for I equals 1 through m
 

00:03:28.090 --> 00:03:30.629 align:start position:0%
hidden layer I for I equals 1 through m
but<00:03:28.810><c> to</c><00:03:28.959><c> videos</c><00:03:29.260><c> writing</c><00:03:29.560><c> I'm</c><00:03:29.919><c> going</c><00:03:30.190><c> to</c><00:03:30.280><c> omit</c>

00:03:30.629 --> 00:03:30.639 align:start position:0%
but to videos writing I'm going to omit
 

00:03:30.639 --> 00:03:33.659 align:start position:0%
but to videos writing I'm going to omit
this<00:03:31.000><c> square</c><00:03:31.780><c> bracket</c><00:03:31.930><c> L</c><00:03:32.590><c> just</c><00:03:33.220><c> to</c><00:03:33.340><c> simplify</c>

00:03:33.659 --> 00:03:33.669 align:start position:0%
this square bracket L just to simplify
 

00:03:33.669 --> 00:03:35.879 align:start position:0%
this square bracket L just to simplify
the<00:03:33.849><c> notation</c><00:03:34.090><c> on</c><00:03:34.569><c> this</c><00:03:34.720><c> line</c><00:03:34.930><c> so</c><00:03:35.470><c> giving</c>

00:03:35.879 --> 00:03:35.889 align:start position:0%
the notation on this line so giving
 

00:03:35.889 --> 00:03:37.740 align:start position:0%
the notation on this line so giving
these<00:03:36.069><c> values</c><00:03:36.519><c> what</c><00:03:36.819><c> you</c><00:03:36.849><c> do</c><00:03:37.120><c> is</c><00:03:37.299><c> compute</c><00:03:37.629><c> the</c>

00:03:37.740 --> 00:03:37.750 align:start position:0%
these values what you do is compute the
 

00:03:37.750 --> 00:03:42.150 align:start position:0%
these values what you do is compute the
mean<00:03:38.019><c> as</c><00:03:39.209><c> follows</c><00:03:40.530><c> again</c><00:03:41.530><c> all</c><00:03:41.799><c> this</c><00:03:41.980><c> is</c>

00:03:42.150 --> 00:03:42.160 align:start position:0%
mean as follows again all this is
 

00:03:42.160 --> 00:03:44.280 align:start position:0%
mean as follows again all this is
specific<00:03:42.669><c> to</c><00:03:42.699><c> some</c><00:03:43.000><c> layer</c><00:03:43.180><c> l</c><00:03:43.449><c> but</c><00:03:43.780><c> I'm</c><00:03:43.870><c> waiting</c>

00:03:44.280 --> 00:03:44.290 align:start position:0%
specific to some layer l but I'm waiting
 

00:03:44.290 --> 00:03:47.009 align:start position:0%
specific to some layer l but I'm waiting
the<00:03:44.680><c> square</c><00:03:45.340><c> bracket</c><00:03:45.669><c> L</c><00:03:45.849><c> m</c><00:03:46.060><c> and</c><00:03:46.810><c> then</c><00:03:46.959><c> you</c>

00:03:47.009 --> 00:03:47.019 align:start position:0%
the square bracket L m and then you
 

00:03:47.019 --> 00:03:50.490 align:start position:0%
the square bracket L m and then you
compute<00:03:47.410><c> the</c><00:03:47.530><c> variance</c><00:03:47.919><c> using</c><00:03:48.879><c> the</c><00:03:49.500><c> pretty</c>

00:03:50.490 --> 00:03:50.500 align:start position:0%
compute the variance using the pretty
 

00:03:50.500 --> 00:03:52.199 align:start position:0%
compute the variance using the pretty
much<00:03:50.680><c> the</c><00:03:50.709><c> formula</c><00:03:51.250><c> you</c><00:03:51.430><c> would</c><00:03:51.489><c> expect</c><00:03:51.940><c> and</c>

00:03:52.199 --> 00:03:52.209 align:start position:0%
much the formula you would expect and
 

00:03:52.209 --> 00:03:54.000 align:start position:0%
much the formula you would expect and
then<00:03:52.629><c> you</c><00:03:52.810><c> will</c><00:03:52.930><c> take</c><00:03:53.139><c> each</c><00:03:53.379><c> of</c><00:03:53.530><c> the</c><00:03:53.799><c> i's</c><00:03:53.980><c> and</c>

00:03:54.000 --> 00:03:54.010 align:start position:0%
then you will take each of the i's and
 

00:03:54.010 --> 00:03:58.550 align:start position:0%
then you will take each of the i's and
normalize<00:03:54.819><c> it</c><00:03:55.060><c> to</c><00:03:55.599><c> get</c><00:03:55.810><c> zi</c><00:03:56.049><c> normalized</c><00:03:56.889><c> by</c>

00:03:58.550 --> 00:03:58.560 align:start position:0%
normalize it to get zi normalized by
 

00:03:58.560 --> 00:04:01.229 align:start position:0%
normalize it to get zi normalized by
subtracting<00:03:59.560><c> off</c><00:03:59.799><c> the</c><00:03:59.949><c> mean</c><00:04:00.129><c> and</c><00:04:00.400><c> dividing</c><00:04:00.819><c> by</c>

00:04:01.229 --> 00:04:01.239 align:start position:0%
subtracting off the mean and dividing by
 

00:04:01.239 --> 00:04:06.089 align:start position:0%
subtracting off the mean and dividing by
the<00:04:01.980><c> standard</c><00:04:02.980><c> deviation</c><00:04:03.310><c> um</c><00:04:04.650><c> for</c><00:04:05.650><c> numerical</c>

00:04:06.089 --> 00:04:06.099 align:start position:0%
the standard deviation um for numerical
 

00:04:06.099 --> 00:04:08.939 align:start position:0%
the standard deviation um for numerical
stability<00:04:06.340><c> we</c><00:04:07.329><c> usually</c><00:04:07.629><c> add</c><00:04:07.900><c> epsilon</c><00:04:08.769><c> to</c>

00:04:08.939 --> 00:04:08.949 align:start position:0%
stability we usually add epsilon to
 

00:04:08.949 --> 00:04:11.369 align:start position:0%
stability we usually add epsilon to
denominator<00:04:09.579><c> like</c><00:04:09.790><c> that</c><00:04:10.000><c> just</c><00:04:10.419><c> in</c><00:04:10.540><c> case</c><00:04:10.569><c> Sigma</c>

00:04:11.369 --> 00:04:11.379 align:start position:0%
denominator like that just in case Sigma
 

00:04:11.379 --> 00:04:13.289 align:start position:0%
denominator like that just in case Sigma
squared<00:04:11.889><c> turns</c><00:04:12.099><c> out</c><00:04:12.280><c> to</c><00:04:12.430><c> be</c><00:04:12.459><c> 0</c><00:04:12.910><c> and</c><00:04:13.150><c> some</c>

00:04:13.289 --> 00:04:13.299 align:start position:0%
squared turns out to be 0 and some
 

00:04:13.299 --> 00:04:13.880 align:start position:0%
squared turns out to be 0 and some
estimate

00:04:13.880 --> 00:04:13.890 align:start position:0%
estimate
 

00:04:13.890 --> 00:04:17.180 align:start position:0%
estimate
and<00:04:14.190><c> so</c><00:04:14.670><c> now</c><00:04:14.850><c> we're</c><00:04:15.120><c> taking</c><00:04:15.540><c> these</c><00:04:15.950><c> values</c><00:04:16.950><c> E</c>

00:04:17.180 --> 00:04:17.190 align:start position:0%
and so now we're taking these values E
 

00:04:17.190 --> 00:04:20.449 align:start position:0%
and so now we're taking these values E
and<00:04:17.459><c> normalize</c><00:04:17.940><c> them</c><00:04:18.209><c> to</c><00:04:18.510><c> have</c><00:04:18.769><c> mean</c><00:04:19.769><c> 0</c><00:04:19.799><c> and</c>

00:04:20.449 --> 00:04:20.459 align:start position:0%
and normalize them to have mean 0 and
 

00:04:20.459 --> 00:04:23.360 align:start position:0%
and normalize them to have mean 0 and
standard<00:04:21.230><c> unit</c><00:04:22.230><c> variance</c><00:04:22.680><c> so</c><00:04:23.100><c> every</c>

00:04:23.360 --> 00:04:23.370 align:start position:0%
standard unit variance so every
 

00:04:23.370 --> 00:04:26.180 align:start position:0%
standard unit variance so every
component<00:04:23.760><c> of</c><00:04:24.120><c> Z</c><00:04:24.390><c> has</c><00:04:24.840><c> mean</c><00:04:25.200><c> 0</c><00:04:25.230><c> and</c><00:04:25.620><c> variance</c><00:04:25.800><c> 1</c>

00:04:26.180 --> 00:04:26.190 align:start position:0%
component of Z has mean 0 and variance 1
 

00:04:26.190 --> 00:04:28.520 align:start position:0%
component of Z has mean 0 and variance 1
but<00:04:26.760><c> we</c><00:04:26.910><c> don't</c><00:04:27.090><c> want</c><00:04:27.270><c> the</c><00:04:27.390><c> hidden</c><00:04:27.750><c> units</c><00:04:28.140><c> to</c>

00:04:28.520 --> 00:04:28.530 align:start position:0%
but we don't want the hidden units to
 

00:04:28.530 --> 00:04:31.610 align:start position:0%
but we don't want the hidden units to
always<00:04:29.310><c> have</c><00:04:29.700><c> mean</c><00:04:30.060><c> 0</c><00:04:30.090><c> and</c><00:04:30.510><c> variance</c><00:04:30.630><c> 1</c><00:04:31.050><c> maybe</c>

00:04:31.610 --> 00:04:31.620 align:start position:0%
always have mean 0 and variance 1 maybe
 

00:04:31.620 --> 00:04:33.770 align:start position:0%
always have mean 0 and variance 1 maybe
it<00:04:31.770><c> make</c><00:04:31.920><c> sense</c><00:04:32.130><c> but</c><00:04:32.310><c> hidden</c><00:04:32.490><c> units</c><00:04:32.940><c> to</c><00:04:33.630><c> have</c><00:04:33.750><c> a</c>

00:04:33.770 --> 00:04:33.780 align:start position:0%
it make sense but hidden units to have a
 

00:04:33.780 --> 00:04:35.720 align:start position:0%
it make sense but hidden units to have a
different<00:04:34.230><c> distribution</c><00:04:34.380><c> so</c><00:04:35.220><c> what</c><00:04:35.400><c> we'll</c><00:04:35.550><c> do</c>

00:04:35.720 --> 00:04:35.730 align:start position:0%
different distribution so what we'll do
 

00:04:35.730 --> 00:04:39.520 align:start position:0%
different distribution so what we'll do
instead<00:04:35.880><c> is</c><00:04:36.500><c> compute</c><00:04:37.500><c> the</c><00:04:37.980><c> call</c><00:04:38.190><c> to</c><00:04:38.310><c> Z</c><00:04:38.520><c> tilde</c>

00:04:39.520 --> 00:04:39.530 align:start position:0%
instead is compute the call to Z tilde
 

00:04:39.530 --> 00:04:48.830 align:start position:0%
instead is compute the call to Z tilde
equals<00:04:41.000><c> gamma</c><00:04:43.760><c> Z</c><00:04:44.760><c> I</c><00:04:45.350><c> known</c><00:04:47.090><c> plus</c><00:04:48.090><c> beta</c><00:04:48.419><c> and</c>

00:04:48.830 --> 00:04:48.840 align:start position:0%
equals gamma Z I known plus beta and
 

00:04:48.840 --> 00:04:53.780 align:start position:0%
equals gamma Z I known plus beta and
here<00:04:50.150><c> gamma</c><00:04:51.150><c> and</c><00:04:51.540><c> beta</c><00:04:51.600><c> are</c><00:04:52.460><c> learn</c><00:04:53.460><c> about</c>

00:04:53.780 --> 00:04:53.790 align:start position:0%
here gamma and beta are learn about
 

00:04:53.790 --> 00:04:59.570 align:start position:0%
here gamma and beta are learn about
parameters<00:04:54.450><c> of</c><00:04:54.600><c> your</c><00:04:54.630><c> model</c><00:04:58.310><c> so</c><00:04:59.310><c> they're</c>

00:04:59.570 --> 00:04:59.580 align:start position:0%
parameters of your model so they're
 

00:04:59.580 --> 00:05:01.610 align:start position:0%
parameters of your model so they're
using<00:04:59.790><c> gradient</c><00:05:00.270><c> descents</c><00:05:00.690><c> or</c><00:05:01.260><c> some</c><00:05:01.470><c> other</c>

00:05:01.610 --> 00:05:01.620 align:start position:0%
using gradient descents or some other
 

00:05:01.620 --> 00:05:03.409 align:start position:0%
using gradient descents or some other
algorithm<00:05:02.160><c> like</c><00:05:02.370><c> the</c><00:05:02.700><c> gradient</c><00:05:03.090><c> descent</c><00:05:03.330><c> with</c>

00:05:03.409 --> 00:05:03.419 align:start position:0%
algorithm like the gradient descent with
 

00:05:03.419 --> 00:05:06.140 align:start position:0%
algorithm like the gradient descent with
momentum<00:05:03.930><c> RMS</c><00:05:04.440><c> proper</c><00:05:04.800><c> atom</c><00:05:05.190><c> you</c><00:05:05.910><c> would</c>

00:05:06.140 --> 00:05:06.150 align:start position:0%
momentum RMS proper atom you would
 

00:05:06.150 --> 00:05:08.210 align:start position:0%
momentum RMS proper atom you would
update<00:05:06.480><c> the</c><00:05:07.080><c> parameters</c><00:05:07.260><c> gamma</c><00:05:07.860><c> and</c><00:05:08.160><c> beta</c>

00:05:08.210 --> 00:05:08.220 align:start position:0%
update the parameters gamma and beta
 

00:05:08.220 --> 00:05:10.580 align:start position:0%
update the parameters gamma and beta
just<00:05:08.880><c> as</c><00:05:09.090><c> you</c><00:05:09.240><c> would</c><00:05:09.360><c> update</c><00:05:09.570><c> the</c><00:05:10.110><c> weights</c><00:05:10.380><c> of</c>

00:05:10.580 --> 00:05:10.590 align:start position:0%
just as you would update the weights of
 

00:05:10.590 --> 00:05:13.850 align:start position:0%
just as you would update the weights of
the<00:05:10.710><c> neural</c><00:05:10.860><c> network</c><00:05:10.980><c> now</c><00:05:11.970><c> notice</c><00:05:12.720><c> that</c><00:05:13.050><c> the</c>

00:05:13.850 --> 00:05:13.860 align:start position:0%
the neural network now notice that the
 

00:05:13.860 --> 00:05:16.940 align:start position:0%
the neural network now notice that the
effect<00:05:14.190><c> of</c><00:05:14.370><c> gamma</c><00:05:14.610><c> and</c><00:05:14.880><c> beta</c><00:05:14.990><c> is</c><00:05:15.990><c> that</c><00:05:16.800><c> it</c>

00:05:16.940 --> 00:05:16.950 align:start position:0%
effect of gamma and beta is that it
 

00:05:16.950 --> 00:05:20.300 align:start position:0%
effect of gamma and beta is that it
allows<00:05:17.220><c> you</c><00:05:17.550><c> to</c><00:05:17.580><c> set</c><00:05:18.270><c> the</c><00:05:18.600><c> mean</c><00:05:18.870><c> of</c><00:05:19.169><c> V</c><00:05:19.500><c> total</c><00:05:19.830><c> to</c>

00:05:20.300 --> 00:05:20.310 align:start position:0%
allows you to set the mean of V total to
 

00:05:20.310 --> 00:05:21.740 align:start position:0%
allows you to set the mean of V total to
be<00:05:20.430><c> whatever</c><00:05:20.669><c> you</c><00:05:20.880><c> want</c><00:05:21.090><c> it</c><00:05:21.240><c> to</c><00:05:21.300><c> be</c>

00:05:21.740 --> 00:05:21.750 align:start position:0%
be whatever you want it to be
 

00:05:21.750 --> 00:05:26.630 align:start position:0%
be whatever you want it to be
in<00:05:21.990><c> fact</c><00:05:22.410><c> if</c><00:05:22.710><c> gamma</c><00:05:23.010><c> equals</c><00:05:25.610><c> square</c><00:05:26.610><c> root</c>

00:05:26.630 --> 00:05:26.640 align:start position:0%
in fact if gamma equals square root
 

00:05:26.640 --> 00:05:29.659 align:start position:0%
in fact if gamma equals square root
Sigma<00:05:27.120><c> squared</c><00:05:27.950><c> plus</c><00:05:28.950><c> Epsilon</c>

00:05:29.659 --> 00:05:29.669 align:start position:0%
Sigma squared plus Epsilon
 

00:05:29.669 --> 00:05:32.120 align:start position:0%
Sigma squared plus Epsilon
so<00:05:30.090><c> if</c><00:05:30.150><c> camera</c><00:05:30.690><c> were</c><00:05:31.410><c> equal</c><00:05:31.830><c> to</c><00:05:32.010><c> this</c>

00:05:32.120 --> 00:05:32.130 align:start position:0%
so if camera were equal to this
 

00:05:32.130 --> 00:05:35.719 align:start position:0%
so if camera were equal to this
denominator<00:05:32.820><c> term</c><00:05:33.150><c> and</c><00:05:33.390><c> if</c><00:05:33.780><c> beta</c><00:05:34.440><c> were</c><00:05:35.250><c> equal</c>

00:05:35.719 --> 00:05:35.729 align:start position:0%
denominator term and if beta were equal
 

00:05:35.729 --> 00:05:42.950 align:start position:0%
denominator term and if beta were equal
to<00:05:35.970><c> MU</c><00:05:36.950><c> so</c><00:05:37.950><c> this</c><00:05:38.280><c> value</c><00:05:38.669><c> up</c><00:05:38.790><c> here</c><00:05:41.780><c> then</c><00:05:42.780><c> the</c>

00:05:42.950 --> 00:05:42.960 align:start position:0%
to MU so this value up here then the
 

00:05:42.960 --> 00:05:46.219 align:start position:0%
to MU so this value up here then the
effect<00:05:43.320><c> of</c><00:05:43.560><c> gamma</c><00:05:44.310><c> xenon</c><00:05:44.910><c> plus</c><00:05:45.090><c> beta</c><00:05:45.450><c> is</c><00:05:45.900><c> that</c>

00:05:46.219 --> 00:05:46.229 align:start position:0%
effect of gamma xenon plus beta is that
 

00:05:46.229 --> 00:05:49.610 align:start position:0%
effect of gamma xenon plus beta is that
it<00:05:46.470><c> would</c><00:05:46.620><c> exactly</c><00:05:47.100><c> invert</c><00:05:47.729><c> this</c><00:05:48.450><c> equation</c><00:05:49.020><c> so</c>

00:05:49.610 --> 00:05:49.620 align:start position:0%
it would exactly invert this equation so
 

00:05:49.620 --> 00:05:54.320 align:start position:0%
it would exactly invert this equation so
if<00:05:50.330><c> this</c><00:05:51.330><c> is</c><00:05:51.510><c> true</c><00:05:51.830><c> then</c><00:05:52.830><c> actually</c><00:05:53.520><c> these</c>

00:05:54.320 --> 00:05:54.330 align:start position:0%
if this is true then actually these
 

00:05:54.330 --> 00:05:58.880 align:start position:0%
if this is true then actually these
older<00:05:54.900><c> I</c><00:05:55.169><c> is</c><00:05:55.770><c> equal</c><00:05:56.580><c> to</c><00:05:56.850><c> VI</c><00:05:57.660><c> and</c><00:05:58.050><c> so</c><00:05:58.530><c> by</c><00:05:58.740><c> an</c>

00:05:58.880 --> 00:05:58.890 align:start position:0%
older I is equal to VI and so by an
 

00:05:58.890 --> 00:06:00.080 align:start position:0%
older I is equal to VI and so by an
appropriate<00:05:59.400><c> setting</c><00:05:59.580><c> of</c><00:05:59.850><c> the</c><00:05:59.940><c> parameters</c>

00:06:00.080 --> 00:06:00.090 align:start position:0%
appropriate setting of the parameters
 

00:06:00.090 --> 00:06:04.159 align:start position:0%
appropriate setting of the parameters
gamma<00:06:00.780><c> and</c><00:06:01.050><c> beta</c><00:06:01.310><c> this</c><00:06:02.690><c> normalization</c><00:06:03.690><c> step</c>

00:06:04.159 --> 00:06:04.169 align:start position:0%
gamma and beta this normalization step
 

00:06:04.169 --> 00:06:08.420 align:start position:0%
gamma and beta this normalization step
that<00:06:04.770><c> is</c><00:06:04.950><c> these</c><00:06:05.870><c> four</c><00:06:06.870><c> equations</c><00:06:07.440><c> is</c><00:06:07.650><c> just</c>

00:06:08.420 --> 00:06:08.430 align:start position:0%
that is these four equations is just
 

00:06:08.430 --> 00:06:10.490 align:start position:0%
that is these four equations is just
computing<00:06:09.270><c> essentially</c><00:06:09.780><c> the</c><00:06:09.900><c> identity</c>

00:06:10.490 --> 00:06:10.500 align:start position:0%
computing essentially the identity
 

00:06:10.500 --> 00:06:12.380 align:start position:0%
computing essentially the identity
function<00:06:10.710><c> but</c><00:06:11.220><c> by</c><00:06:11.340><c> choosing</c><00:06:11.580><c> other</c><00:06:11.880><c> values</c><00:06:12.360><c> of</c>

00:06:12.380 --> 00:06:12.390 align:start position:0%
function but by choosing other values of
 

00:06:12.390 --> 00:06:16.130 align:start position:0%
function but by choosing other values of
gamma<00:06:12.780><c> and</c><00:06:12.960><c> beta</c><00:06:13.050><c> this</c><00:06:14.040><c> allows</c><00:06:14.340><c> you</c><00:06:14.640><c> to</c><00:06:15.140><c> make</c>

00:06:16.130 --> 00:06:16.140 align:start position:0%
gamma and beta this allows you to make
 

00:06:16.140 --> 00:06:18.200 align:start position:0%
gamma and beta this allows you to make
the<00:06:16.290><c> hidden</c><00:06:16.650><c> unit</c><00:06:16.950><c> values</c><00:06:17.370><c> of</c><00:06:17.610><c> other</c><00:06:17.820><c> means</c>

00:06:18.200 --> 00:06:18.210 align:start position:0%
the hidden unit values of other means
 

00:06:18.210 --> 00:06:18.650 align:start position:0%
the hidden unit values of other means
and<00:06:18.450><c> be</c>

00:06:18.650 --> 00:06:18.660 align:start position:0%
and be
 

00:06:18.660 --> 00:06:20.960 align:start position:0%
and be
winces<00:06:18.960><c> as</c><00:06:19.110><c> well</c><00:06:19.350><c> and</c><00:06:19.590><c> so</c><00:06:20.160><c> the</c><00:06:20.460><c> way</c><00:06:20.610><c> you</c><00:06:20.670><c> fit</c>

00:06:20.960 --> 00:06:20.970 align:start position:0%
winces as well and so the way you fit
 

00:06:20.970 --> 00:06:23.210 align:start position:0%
winces as well and so the way you fit
this<00:06:21.120><c> into</c><00:06:21.330><c> your</c><00:06:21.450><c> neural</c><00:06:21.750><c> network</c><00:06:22.140><c> is</c><00:06:22.320><c> whereas</c>

00:06:23.210 --> 00:06:23.220 align:start position:0%
this into your neural network is whereas
 

00:06:23.220 --> 00:06:25.490 align:start position:0%
this into your neural network is whereas
previously<00:06:23.760><c> you</c><00:06:24.060><c> are</c><00:06:24.210><c> using</c><00:06:24.420><c> these</c><00:06:24.720><c> values</c><00:06:24.960><c> V</c>

00:06:25.490 --> 00:06:25.500 align:start position:0%
previously you are using these values V
 

00:06:25.500 --> 00:06:30.920 align:start position:0%
previously you are using these values V
1<00:06:25.680><c> Z</c><00:06:25.920><c> 2</c><00:06:25.950><c> and</c><00:06:26.430><c> so</c><00:06:26.880><c> on</c><00:06:26.910><c> you</c><00:06:27.780><c> will</c><00:06:27.900><c> now</c><00:06:28.130><c> use</c><00:06:29.510><c> Z</c><00:06:30.510><c> 2</c>

00:06:30.920 --> 00:06:30.930 align:start position:0%
1 Z 2 and so on you will now use Z 2
 

00:06:30.930 --> 00:06:37.880 align:start position:0%
1 Z 2 and so on you will now use Z 2
there<00:06:31.140><c> I</c><00:06:33.770><c> instead</c><00:06:34.770><c> of</c><00:06:35.330><c> Z</c><00:06:36.330><c> I</c><00:06:36.590><c> for</c><00:06:37.590><c> the</c><00:06:37.680><c> later</c>

00:06:37.880 --> 00:06:37.890 align:start position:0%
there I instead of Z I for the later
 

00:06:37.890 --> 00:06:40.220 align:start position:0%
there I instead of Z I for the later
computations<00:06:38.730><c> on</c><00:06:39.000><c> your</c><00:06:39.180><c> network</c><00:06:39.630><c> and</c><00:06:39.750><c> we</c><00:06:40.080><c> want</c>

00:06:40.220 --> 00:06:40.230 align:start position:0%
computations on your network and we want
 

00:06:40.230 --> 00:06:42.710 align:start position:0%
computations on your network and we want
to<00:06:40.320><c> put</c><00:06:40.470><c> back</c><00:06:40.620><c> in</c><00:06:40.890><c> this</c><00:06:41.130><c> sum</c><00:06:41.430><c> square</c><00:06:42.180><c> bracket</c><00:06:42.540><c> L</c>

00:06:42.710 --> 00:06:42.720 align:start position:0%
to put back in this sum square bracket L
 

00:06:42.720 --> 00:06:44.660 align:start position:0%
to put back in this sum square bracket L
you<00:06:43.200><c> know</c><00:06:43.290><c> to</c><00:06:43.500><c> explicitly</c><00:06:44.040><c> to</c><00:06:44.220><c> know</c><00:06:44.400><c> which</c>

00:06:44.660 --> 00:06:44.670 align:start position:0%
you know to explicitly to know which
 

00:06:44.670 --> 00:06:46.820 align:start position:0%
you know to explicitly to know which
layer<00:06:44.940><c> it</c><00:06:45.090><c> is</c><00:06:45.240><c> in</c><00:06:45.420><c> you</c><00:06:45.960><c> can</c><00:06:46.140><c> put</c><00:06:46.320><c> it</c><00:06:46.410><c> back</c><00:06:46.560><c> there</c>

00:06:46.820 --> 00:06:46.830 align:start position:0%
layer it is in you can put it back there
 

00:06:46.830 --> 00:06:48.980 align:start position:0%
layer it is in you can put it back there
so<00:06:47.490><c> the</c><00:06:47.730><c> intuition</c><00:06:47.970><c> I</c><00:06:48.270><c> hope</c><00:06:48.450><c> you</c><00:06:48.600><c> take</c><00:06:48.810><c> away</c>

00:06:48.980 --> 00:06:48.990 align:start position:0%
so the intuition I hope you take away
 

00:06:48.990 --> 00:06:52.370 align:start position:0%
so the intuition I hope you take away
from<00:06:49.080><c> this</c><00:06:49.320><c> is</c><00:06:49.740><c> that</c><00:06:49.850><c> we</c><00:06:50.850><c> saw</c><00:06:51.120><c> how</c><00:06:51.390><c> normalizing</c>

00:06:52.370 --> 00:06:52.380 align:start position:0%
from this is that we saw how normalizing
 

00:06:52.380 --> 00:06:55.250 align:start position:0%
from this is that we saw how normalizing
the<00:06:53.040><c> input</c><00:06:53.430><c> features</c><00:06:53.850><c> X</c><00:06:54.120><c> can</c><00:06:54.600><c> help</c><00:06:54.900><c> learning</c>

00:06:55.250 --> 00:06:55.260 align:start position:0%
the input features X can help learning
 

00:06:55.260 --> 00:06:57.380 align:start position:0%
the input features X can help learning
in<00:06:55.350><c> a</c><00:06:55.440><c> neural</c><00:06:55.620><c> network</c><00:06:55.860><c> and</c><00:06:56.370><c> what</c><00:06:56.880><c> -</c><00:06:57.060><c> alone</c>

00:06:57.380 --> 00:06:57.390 align:start position:0%
in a neural network and what - alone
 

00:06:57.390 --> 00:06:59.450 align:start position:0%
in a neural network and what - alone
does<00:06:57.600><c> is</c><00:06:57.900><c> apply</c><00:06:58.080><c> that</c><00:06:58.590><c> normalization</c><00:06:59.130><c> process</c>

00:06:59.450 --> 00:06:59.460 align:start position:0%
does is apply that normalization process
 

00:06:59.460 --> 00:07:01.880 align:start position:0%
does is apply that normalization process
not<00:06:59.970><c> just</c><00:07:00.210><c> to</c><00:07:00.300><c> the</c><00:07:00.390><c> input</c><00:07:00.720><c> layer</c><00:07:00.870><c> but</c><00:07:01.650><c> to</c><00:07:01.770><c> the</c>

00:07:01.880 --> 00:07:01.890 align:start position:0%
not just to the input layer but to the
 

00:07:01.890 --> 00:07:04.040 align:start position:0%
not just to the input layer but to the
values<00:07:02.310><c> even</c><00:07:02.760><c> deep</c><00:07:03.000><c> in</c><00:07:03.210><c> some</c><00:07:03.450><c> hidden</c><00:07:03.690><c> there</c><00:07:03.960><c> in</c>

00:07:04.040 --> 00:07:04.050 align:start position:0%
values even deep in some hidden there in
 

00:07:04.050 --> 00:07:05.540 align:start position:0%
values even deep in some hidden there in
the<00:07:04.140><c> neural</c><00:07:04.380><c> networks</c><00:07:04.770><c> we</c><00:07:04.890><c> apply</c><00:07:05.160><c> this</c><00:07:05.220><c> type</c>

00:07:05.540 --> 00:07:05.550 align:start position:0%
the neural networks we apply this type
 

00:07:05.550 --> 00:07:07.910 align:start position:0%
the neural networks we apply this type
of<00:07:05.610><c> normalization</c><00:07:06.030><c> to</c><00:07:06.930><c> normalize</c><00:07:07.440><c> the</c><00:07:07.710><c> mean</c>

00:07:07.910 --> 00:07:07.920 align:start position:0%
of normalization to normalize the mean
 

00:07:07.920 --> 00:07:10.970 align:start position:0%
of normalization to normalize the mean
and<00:07:08.130><c> variance</c><00:07:08.190><c> of</c><00:07:08.850><c> some</c><00:07:09.660><c> of</c><00:07:10.080><c> your</c><00:07:10.350><c> hidden</c><00:07:10.560><c> unit</c>

00:07:10.970 --> 00:07:10.980 align:start position:0%
and variance of some of your hidden unit
 

00:07:10.980 --> 00:07:13.940 align:start position:0%
and variance of some of your hidden unit
values<00:07:11.490><c> V</c><00:07:12.210><c> but</c><00:07:12.930><c> one</c><00:07:13.140><c> difference</c><00:07:13.320><c> between</c><00:07:13.620><c> the</c>

00:07:13.940 --> 00:07:13.950 align:start position:0%
values V but one difference between the
 

00:07:13.950 --> 00:07:15.890 align:start position:0%
values V but one difference between the
trading<00:07:14.280><c> inputs</c><00:07:14.730><c> and</c><00:07:14.970><c> these</c><00:07:15.270><c> hidden</c><00:07:15.540><c> unit</c>

00:07:15.890 --> 00:07:15.900 align:start position:0%
trading inputs and these hidden unit
 

00:07:15.900 --> 00:07:18.170 align:start position:0%
trading inputs and these hidden unit
values<00:07:16.320><c> is</c><00:07:16.590><c> you</c><00:07:17.130><c> might</c><00:07:17.340><c> not</c><00:07:17.550><c> want</c><00:07:17.880><c> your</c><00:07:17.970><c> hidden</c>

00:07:18.170 --> 00:07:18.180 align:start position:0%
values is you might not want your hidden
 

00:07:18.180 --> 00:07:20.570 align:start position:0%
values is you might not want your hidden
unit<00:07:18.600><c> values</c><00:07:18.960><c> to</c><00:07:19.110><c> be</c><00:07:19.200><c> forced</c><00:07:19.680><c> to</c><00:07:19.710><c> mean</c><00:07:20.070><c> 0</c><00:07:20.520><c> and</c>

00:07:20.570 --> 00:07:20.580 align:start position:0%
unit values to be forced to mean 0 and
 

00:07:20.580 --> 00:07:23.210 align:start position:0%
unit values to be forced to mean 0 and
variance<00:07:20.790><c> 1</c><00:07:21.240><c> for</c><00:07:22.140><c> example</c><00:07:22.590><c> if</c><00:07:22.830><c> you</c><00:07:22.980><c> have</c><00:07:23.190><c> a</c>

00:07:23.210 --> 00:07:23.220 align:start position:0%
variance 1 for example if you have a
 

00:07:23.220 --> 00:07:25.250 align:start position:0%
variance 1 for example if you have a
sigmoid<00:07:23.850><c> activation</c><00:07:23.970><c> function</c><00:07:24.450><c> you</c><00:07:25.050><c> don't</c>

00:07:25.250 --> 00:07:25.260 align:start position:0%
sigmoid activation function you don't
 

00:07:25.260 --> 00:07:27.350 align:start position:0%
sigmoid activation function you don't
want<00:07:25.470><c> your</c><00:07:25.560><c> values</c><00:07:26.010><c> to</c><00:07:26.280><c> always</c><00:07:26.940><c> be</c><00:07:27.090><c> clustered</c>

00:07:27.350 --> 00:07:27.360 align:start position:0%
want your values to always be clustered
 

00:07:27.360 --> 00:07:29.600 align:start position:0%
want your values to always be clustered
here<00:07:27.750><c> you</c><00:07:27.900><c> might</c><00:07:28.080><c> want</c><00:07:28.290><c> them</c><00:07:28.470><c> to</c><00:07:29.040><c> the</c><00:07:29.220><c> larger</c>

00:07:29.600 --> 00:07:29.610 align:start position:0%
here you might want them to the larger
 

00:07:29.610 --> 00:07:32.240 align:start position:0%
here you might want them to the larger
variance<00:07:30.060><c> or</c><00:07:30.440><c> have</c><00:07:31.440><c> a</c><00:07:31.470><c> mean</c><00:07:31.740><c> that's</c><00:07:31.980><c> different</c>

00:07:32.240 --> 00:07:32.250 align:start position:0%
variance or have a mean that's different
 

00:07:32.250 --> 00:07:33.950 align:start position:0%
variance or have a mean that's different
than<00:07:32.490><c> 0</c><00:07:32.820><c> in</c><00:07:33.030><c> order</c><00:07:33.180><c> to</c><00:07:33.390><c> better</c><00:07:33.600><c> take</c><00:07:33.840><c> advantage</c>

00:07:33.950 --> 00:07:33.960 align:start position:0%
than 0 in order to better take advantage
 

00:07:33.960 --> 00:07:36.260 align:start position:0%
than 0 in order to better take advantage
of<00:07:34.530><c> the</c><00:07:34.680><c> non-linearity</c><00:07:35.190><c> of</c><00:07:35.550><c> the</c><00:07:35.760><c> sigmoid</c>

00:07:36.260 --> 00:07:36.270 align:start position:0%
of the non-linearity of the sigmoid
 

00:07:36.270 --> 00:07:38.000 align:start position:0%
of the non-linearity of the sigmoid
function<00:07:36.660><c> rather</c><00:07:36.930><c> than</c><00:07:37.200><c> have</c><00:07:37.680><c> all</c><00:07:37.890><c> your</c>

00:07:38.000 --> 00:07:38.010 align:start position:0%
function rather than have all your
 

00:07:38.010 --> 00:07:40.040 align:start position:0%
function rather than have all your
values<00:07:38.430><c> being</c><00:07:38.760><c> just</c><00:07:39.120><c> listed</c><00:07:39.690><c> within</c><00:07:39.930><c> your</c>

00:07:40.040 --> 00:07:40.050 align:start position:0%
values being just listed within your
 

00:07:40.050 --> 00:07:42.800 align:start position:0%
values being just listed within your
vision<00:07:40.380><c> so</c><00:07:41.100><c> that's</c><00:07:41.340><c> why</c><00:07:41.610><c> with</c><00:07:42.210><c> the</c><00:07:42.330><c> parameters</c>

00:07:42.800 --> 00:07:42.810 align:start position:0%
vision so that's why with the parameters
 

00:07:42.810 --> 00:07:46.370 align:start position:0%
vision so that's why with the parameters
gamma<00:07:43.470><c> and</c><00:07:43.770><c> beta</c><00:07:44.120><c> you</c><00:07:45.120><c> can</c><00:07:45.300><c> now</c><00:07:45.510><c> make</c><00:07:46.320><c> sure</c>

00:07:46.370 --> 00:07:46.380 align:start position:0%
gamma and beta you can now make sure
 

00:07:46.380 --> 00:07:49.700 align:start position:0%
gamma and beta you can now make sure
that<00:07:46.620><c> your</c><00:07:47.190><c> VI</c><00:07:47.520><c> values</c><00:07:48.180><c> have</c><00:07:48.660><c> the</c><00:07:48.870><c> range</c><00:07:49.500><c> of</c>

00:07:49.700 --> 00:07:49.710 align:start position:0%
that your VI values have the range of
 

00:07:49.710 --> 00:07:52.220 align:start position:0%
that your VI values have the range of
values<00:07:49.890><c> that</c><00:07:50.340><c> you</c><00:07:50.520><c> want</c><00:07:50.750><c> but</c><00:07:51.750><c> what</c><00:07:51.930><c> it</c><00:07:52.050><c> does</c>

00:07:52.220 --> 00:07:52.230 align:start position:0%
values that you want but what it does
 

00:07:52.230 --> 00:07:55.220 align:start position:0%
values that you want but what it does
really<00:07:52.470><c> it</c><00:07:52.710><c> ensures</c><00:07:53.220><c> that</c><00:07:53.450><c> your</c><00:07:54.450><c> hidden</c><00:07:54.660><c> units</c>

00:07:55.220 --> 00:07:55.230 align:start position:0%
really it ensures that your hidden units
 

00:07:55.230 --> 00:07:57.890 align:start position:0%
really it ensures that your hidden units
have<00:07:55.970><c> standardized</c><00:07:56.970><c> mean</c><00:07:57.300><c> and</c><00:07:57.510><c> variance</c>

00:07:57.890 --> 00:07:57.900 align:start position:0%
have standardized mean and variance
 

00:07:57.900 --> 00:07:59.750 align:start position:0%
have standardized mean and variance
where<00:07:58.620><c> the</c><00:07:58.740><c> mean</c><00:07:58.919><c> and</c><00:07:59.100><c> variance</c><00:07:59.130><c> are</c>

00:07:59.750 --> 00:07:59.760 align:start position:0%
where the mean and variance are
 

00:07:59.760 --> 00:08:03.020 align:start position:0%
where the mean and variance are
controlled<00:08:00.450><c> by</c><00:08:00.810><c> two</c><00:08:01.710><c> explicit</c><00:08:02.400><c> parameters</c>

00:08:03.020 --> 00:08:03.030 align:start position:0%
controlled by two explicit parameters
 

00:08:03.030 --> 00:08:05.120 align:start position:0%
controlled by two explicit parameters
gamma<00:08:03.660><c> and</c><00:08:03.930><c> beta</c><00:08:04.020><c> which</c><00:08:04.680><c> the</c><00:08:04.800><c> learning</c>

00:08:05.120 --> 00:08:05.130 align:start position:0%
gamma and beta which the learning
 

00:08:05.130 --> 00:08:08.540 align:start position:0%
gamma and beta which the learning
algorithm<00:08:05.490><c> concentr</c><00:08:06.030><c> whatever</c><00:08:06.720><c> one</c><00:08:07.070><c> so</c><00:08:08.070><c> what</c>

00:08:08.540 --> 00:08:08.550 align:start position:0%
algorithm concentr whatever one so what
 

00:08:08.550 --> 00:08:10.490 align:start position:0%
algorithm concentr whatever one so what
it<00:08:08.640><c> really</c><00:08:08.790><c> does</c><00:08:09.060><c> is</c><00:08:09.330><c> it</c><00:08:09.360><c> normalizes</c><00:08:09.900><c> in</c><00:08:10.320><c> mean</c>

00:08:10.490 --> 00:08:10.500 align:start position:0%
it really does is it normalizes in mean
 

00:08:10.500 --> 00:08:13.280 align:start position:0%
it really does is it normalizes in mean
and<00:08:10.530><c> variance</c><00:08:11.130><c> of</c><00:08:11.460><c> these</c><00:08:12.090><c> hidden</c><00:08:12.390><c> unit</c><00:08:12.840><c> values</c>

00:08:13.280 --> 00:08:13.290 align:start position:0%
and variance of these hidden unit values
 

00:08:13.290 --> 00:08:16.460 align:start position:0%
and variance of these hidden unit values
really<00:08:13.560><c> the</c><00:08:13.770><c> VI</c><00:08:14.030><c> to</c><00:08:15.030><c> have</c><00:08:15.240><c> some</c><00:08:15.600><c> fixed</c>

00:08:16.460 --> 00:08:16.470 align:start position:0%
really the VI to have some fixed
 

00:08:16.470 --> 00:08:19.220 align:start position:0%
really the VI to have some fixed
mean<00:08:16.770><c> and</c><00:08:17.040><c> variance</c><00:08:17.460><c> and</c><00:08:17.820><c> that</c><00:08:18.080><c> mean</c><00:08:19.080><c> and</c>

00:08:19.220 --> 00:08:19.230 align:start position:0%
mean and variance and that mean and
 

00:08:19.230 --> 00:08:21.470 align:start position:0%
mean and variance and that mean and
variance<00:08:19.500><c> could</c><00:08:19.800><c> be</c><00:08:19.919><c> 0</c><00:08:20.280><c> and</c><00:08:20.430><c> 1</c><00:08:20.580><c> or</c><00:08:20.820><c> it</c><00:08:21.240><c> could</c><00:08:21.390><c> be</c>

00:08:21.470 --> 00:08:21.480 align:start position:0%
variance could be 0 and 1 or it could be
 

00:08:21.480 --> 00:08:23.900 align:start position:0%
variance could be 0 and 1 or it could be
some<00:08:21.690><c> other</c><00:08:21.900><c> value</c><00:08:22.380><c> and</c><00:08:23.250><c> is</c><00:08:23.370><c> controlled</c><00:08:23.850><c> by</c>

00:08:23.900 --> 00:08:23.910 align:start position:0%
some other value and is controlled by
 

00:08:23.910 --> 00:08:26.750 align:start position:0%
some other value and is controlled by
these<00:08:24.030><c> parameters</c><00:08:24.780><c> gamma</c><00:08:25.440><c> and</c><00:08:25.710><c> beta</c><00:08:25.770><c> so</c><00:08:26.729><c> I</c>

00:08:26.750 --> 00:08:26.760 align:start position:0%
these parameters gamma and beta so I
 

00:08:26.760 --> 00:08:28.070 align:start position:0%
these parameters gamma and beta so I
hope<00:08:27.000><c> that</c><00:08:27.060><c> gives</c><00:08:27.210><c> you</c><00:08:27.539><c> a</c><00:08:27.570><c> sense</c><00:08:27.810><c> of</c><00:08:27.990><c> the</c>

00:08:28.070 --> 00:08:28.080 align:start position:0%
hope that gives you a sense of the
 

00:08:28.080 --> 00:08:30.350 align:start position:0%
hope that gives you a sense of the
mechanics<00:08:28.770><c> of</c><00:08:28.950><c> how</c><00:08:29.010><c> to</c><00:08:29.190><c> implement</c><00:08:29.700><c> a</c><00:08:30.000><c> tional</c>

00:08:30.350 --> 00:08:30.360 align:start position:0%
mechanics of how to implement a tional
 

00:08:30.360 --> 00:08:32.640 align:start position:0%
mechanics of how to implement a tional
at<00:08:30.930><c> least</c><00:08:31.140><c> for</c><00:08:31.289><c> a</c><00:08:31.320><c> single</c><00:08:31.710><c> layer</c><00:08:31.919><c> in</c><00:08:31.950><c> the</c><00:08:32.219><c> net</c>

00:08:32.640 --> 00:08:32.650 align:start position:0%
at least for a single layer in the net
 

00:08:32.650 --> 00:08:34.890 align:start position:0%
at least for a single layer in the net
in<00:08:33.279><c> the</c><00:08:33.580><c> next</c><00:08:33.849><c> video</c><00:08:34.150><c> I</c><00:08:34.180><c> want</c><00:08:34.300><c> to</c><00:08:34.390><c> show</c><00:08:34.539><c> you</c><00:08:34.599><c> how</c>

00:08:34.890 --> 00:08:34.900 align:start position:0%
in the next video I want to show you how
 

00:08:34.900 --> 00:08:36.779 align:start position:0%
in the next video I want to show you how
to<00:08:34.930><c> fit</c><00:08:35.289><c> bash</c><00:08:35.529><c> them</c><00:08:35.800><c> into</c><00:08:36.099><c> the</c><00:08:36.159><c> neural</c><00:08:36.460><c> network</c>

00:08:36.779 --> 00:08:36.789 align:start position:0%
to fit bash them into the neural network
 

00:08:36.789 --> 00:08:38.850 align:start position:0%
to fit bash them into the neural network
you<00:08:37.029><c> can</c><00:08:37.120><c> deepen</c><00:08:37.930><c> into</c><00:08:38.110><c> network</c><00:08:38.529><c> and</c><00:08:38.710><c> how</c><00:08:38.800><c> to</c>

00:08:38.850 --> 00:08:38.860 align:start position:0%
you can deepen into network and how to
 

00:08:38.860 --> 00:08:40.230 align:start position:0%
you can deepen into network and how to
make<00:08:39.070><c> it</c><00:08:39.219><c> work</c><00:08:39.400><c> for</c><00:08:39.430><c> the</c><00:08:39.700><c> many</c><00:08:39.880><c> different</c>

00:08:40.230 --> 00:08:40.240 align:start position:0%
make it work for the many different
 

00:08:40.240 --> 00:08:41.310 align:start position:0%
make it work for the many different
layers<00:08:40.330><c> on</c><00:08:40.539><c> your</c><00:08:40.750><c> network</c>

00:08:41.310 --> 00:08:41.320 align:start position:0%
layers on your network
 

00:08:41.320 --> 00:08:43.110 align:start position:0%
layers on your network
and<00:08:41.409><c> after</c><00:08:42.130><c> that</c><00:08:42.279><c> will</c><00:08:42.580><c> give</c><00:08:42.789><c> some</c><00:08:43.089><c> more</c>

00:08:43.110 --> 00:08:43.120 align:start position:0%
and after that will give some more
 

00:08:43.120 --> 00:08:45.360 align:start position:0%
and after that will give some more
intuition<00:08:43.690><c> about</c><00:08:44.020><c> why</c><00:08:44.350><c> bash</c><00:08:44.890><c> storm</c><00:08:45.220><c> could</c>

00:08:45.360 --> 00:08:45.370 align:start position:0%
intuition about why bash storm could
 

00:08:45.370 --> 00:08:47.519 align:start position:0%
intuition about why bash storm could
help<00:08:45.580><c> you</c><00:08:45.670><c> train</c><00:08:45.910><c> your</c><00:08:46.210><c> network</c><00:08:46.660><c> so</c><00:08:47.230><c> in</c><00:08:47.350><c> case</c>

00:08:47.519 --> 00:08:47.529 align:start position:0%
help you train your network so in case
 

00:08:47.529 --> 00:08:49.550 align:start position:0%
help you train your network so in case
why<00:08:47.950><c> were</c><00:08:48.220><c> filthy</c><00:08:48.670><c> a</c><00:08:48.850><c> little</c><00:08:49.120><c> bit</c><00:08:49.240><c> mysterious</c>

00:08:49.550 --> 00:08:49.560 align:start position:0%
why were filthy a little bit mysterious
 

00:08:49.560 --> 00:08:52.170 align:start position:0%
why were filthy a little bit mysterious
stay<00:08:50.560><c> with</c><00:08:50.740><c> me</c><00:08:50.860><c> and</c><00:08:51.070><c> I</c><00:08:51.310><c> think</c><00:08:51.520><c> in</c><00:08:51.640><c> the</c><00:08:51.730><c> two</c>

00:08:52.170 --> 00:08:52.180 align:start position:0%
stay with me and I think in the two
 

00:08:52.180 --> 00:08:53.880 align:start position:0%
stay with me and I think in the two
videos<00:08:52.390><c> from</c><00:08:52.720><c> now</c><00:08:52.930><c> we'll</c><00:08:53.320><c> really</c><00:08:53.529><c> make</c><00:08:53.740><c> that</c>

00:08:53.880 --> 00:08:53.890 align:start position:0%
videos from now we'll really make that
 

00:08:53.890 --> 00:08:56.220 align:start position:0%
videos from now we'll really make that
clearer

