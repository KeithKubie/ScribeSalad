WEBVTT
Kind: captions
Language: en

00:00:02.940 --> 00:00:06.400
Hi, I’m Adriene Hill, and Welcome back to
Crash Course, Statistics.

00:00:06.410 --> 00:00:09.040
We all have ideas about how the world works.

00:00:09.040 --> 00:00:13.680
And even if we haven’t ever used numbers
to describe them, we see different beliefs

00:00:13.680 --> 00:00:15.299
everywhere we go.

00:00:15.299 --> 00:00:20.070
From whether it’s healthier to be a vegetarian... to whether school uniforms are a good idea;

00:00:20.070 --> 00:00:23.320
we all have slightly different “models”
of how the world works.

00:00:23.320 --> 00:00:25.010
And yet we all agree on a lot.

00:00:25.010 --> 00:00:28.230
For example, we all believe the sun will come up tomorrow morning--or at least that it’ll

00:00:28.230 --> 00:00:30.270
come up eventually if you live at the poles.

00:00:30.270 --> 00:00:33.570
And we all believe that the Oxygen atoms in
the room won’t all suddenly move to one

00:00:33.570 --> 00:00:36.160
corner of the room, leaving us to suffocate.

00:00:36.160 --> 00:00:39.010
And almost all our beliefs change based on
our experience.

00:00:39.010 --> 00:00:42.320
That’s why your friend with a snake that
he cuddles with all the time isn’t as afraid

00:00:42.320 --> 00:00:46.870
of snakes as you are...since your only exposure to snakes is that one time when you were hiking

00:00:46.870 --> 00:00:49.040
and a rattlesnake almost bit your dog.

00:00:49.040 --> 00:00:52.860
Our beliefs are numerous, sometimes complex, and consistently changing.

00:00:52.860 --> 00:00:56.500
So it can be useful to have a way of doing
statistical inference that reflects that.

00:00:56.500 --> 00:01:05.760
INTRO

00:01:05.760 --> 00:01:10.480
Bayes’ Theorem--or Bayes Rule--tells us
the that probability of A given B, is the

00:01:10.499 --> 00:01:15.759
probability of B given A times the probability of A, all divided by the probability of B.

00:01:15.760 --> 00:01:21.560
And remember that the numerator in this equation is just another--way of writing the probability of A and B.

00:01:21.640 --> 00:01:25.280
For example, When you’re out to lunch, your sister mentions that she have a friend who

00:01:25.280 --> 00:01:28.140
has breast cancer, but doesn’t say much
else.

00:01:28.140 --> 00:01:31.439
You recently saw a documentary about males with breast cancer.

00:01:31.440 --> 00:01:35.409
Because it’s so fresh in your mind, you wonder if your sister’s friend is a male.

00:01:35.409 --> 00:01:39.560
Your gut feeling is that it’s not that likely they’re male... but let’s quantify that.

00:01:39.569 --> 00:01:43.130
You want to know the probability that your
sister’s friend is male, given that you

00:01:43.130 --> 00:01:45.310
know that friend has breast cancer.

00:01:45.310 --> 00:01:48.600
Using Bayes’ theorem, we can calculate this probability.

00:01:48.600 --> 00:01:52.880
The probability of being male, given that you
have breast cancer is equal to the probability

00:01:52.890 --> 00:01:57.880
of having breast cancer given that you are
male times the probability of being male,

00:01:57.880 --> 00:02:00.840
divided by the probability of having breast
cancer.

00:02:00.840 --> 00:02:04.030
Thanks to government health agencies, we know many of these statistics.

00:02:04.030 --> 00:02:08.929
The probability of getting breast cancer given that you’re male is 0.001, and we will assume

00:02:08.929 --> 00:02:12.030
the probability of being male is 0.5.

00:02:12.030 --> 00:02:16.340
The overall probability of getting breast
cancer is 0.063.

00:02:16.340 --> 00:02:20.260
Armed with your facts you calculate that the probability that your sister’s

00:02:20.270 --> 00:02:26.120
friend is male is only about 0.79%...so...not
very likely.

00:02:26.130 --> 00:02:28.380
But maybe more likely than you would have
anticipated.

00:02:28.380 --> 00:02:32.710
If we rearrange Bayes’ Theorem slightly
you can see that it allows you to update your

00:02:32.710 --> 00:02:34.530
beliefs based on new information:

00:02:34.530 --> 00:02:38.360
When we used Bayes’ Theorem what we were really doing was updating our belief that

00:02:38.360 --> 00:02:43.480
a person was male (probably about 50/50 odds if you know nothing else about them) with

00:02:43.480 --> 00:02:46.230
the new information that they had breast cancer.

00:02:46.230 --> 00:02:51.670
This new information changed our belief; we went from a 50 percent chance to about a 0.79%

00:02:51.670 --> 00:02:54.850
chance just by taking into account this new
information.

00:02:54.850 --> 00:03:00.520
This idea about updating beliefs is core to
Bayesian statistics and can be used to test hypotheses.

00:03:00.520 --> 00:03:03.980
We start with some idea or belief about how something works.

00:03:03.980 --> 00:03:06.650
For example, you set your friend Maria up
on a blind date.

00:03:06.650 --> 00:03:10.290
Maria’s excited, but nervous, and on her
way to the coffee shop to meet her blind date

00:03:10.290 --> 00:03:14.600
Jordan, she wonders whether he shares her love of Star Wars.

00:03:14.600 --> 00:03:17.800
From her experience meeting people in the
city, she believes that in general, there

00:03:17.800 --> 00:03:21.190
are slightly more Star Wars fans than non
fans.

00:03:21.190 --> 00:03:26.000
She guesses there’s a 60% chance that a
given person is a Star Wars fan, and a 40%

00:03:26.000 --> 00:03:31.280
chance they are not, which means that she
thinks it’s 1.5 times more likely that someone is a fan.

00:03:31.280 --> 00:03:35.740
When Maria arrives at the coffee shop she
and Jordan do the normal first date small talk.

00:03:35.740 --> 00:03:39.340
He asks her what she did this last weekend,
and she told him that she saw the new Star

00:03:39.340 --> 00:03:39.980
Wars movie.

00:03:40.020 --> 00:03:41.440
Jordan says he did too!

00:03:41.450 --> 00:03:45.500
After hearing this, Maria feels like it’s
more likely that she might have met her Porg

00:03:45.500 --> 00:03:46.820
loving soulmate.

00:03:46.820 --> 00:03:50.920
She knows that not everyone who’s seen Star Wars is a fan, but she can use the fact that

00:03:50.920 --> 00:03:56.819
Jordan has seen it to update her belief about whether or not he is one… or she could ask!

00:03:56.819 --> 00:04:00.560
Maria knows that the probability of having
seen the last Star Wars movie given that you’re

00:04:00.560 --> 00:04:04.819
a fan is 0.99, since pretty much all the fans
rushed to see the movie.

00:04:04.819 --> 00:04:07.630
But not everyone who went to see the movie were fans.

00:04:07.630 --> 00:04:10.930
Some were just curious, and others were dragged by family or friends to see it.

00:04:10.930 --> 00:04:15.319
She thinks that the approximate probability
of having seen the movie given that you’re

00:04:15.319 --> 00:04:20.500
not a fan is 0.5, since some but not all non-fans went to see it.

00:04:20.500 --> 00:04:30.330
Maria can use the ratio of these two probabilities: To see which hypothesis is more probable given

00:04:30.330 --> 00:04:32.000
that we know Jordan saw the movie.

00:04:32.000 --> 00:04:35.990
Based on Maria’s quick calculations, this
new information means that it’s now 1.98

00:04:35.990 --> 00:04:39.400
times more likely that Jordan is a Star Wars fan than not.

00:04:39.400 --> 00:04:42.760
Her heart starts beating a little faster!

00:04:42.760 --> 00:04:47.920
This ratio of the probability of our information under one hypothesis--that he’s a fan--compared

00:04:47.930 --> 00:04:51.550
to another--that he’s not a fan--is called
a Bayes’ Factor.

00:04:51.550 --> 00:04:55.580
It represents the amount of information that we’ve learned about our hypotheses from the data.

00:04:55.580 --> 00:05:01.440
Maria can use it to update her previous belief--or
prior odds--that it’s 1.5x more likely that

00:05:01.449 --> 00:05:03.520
Jordan is a fellow Star Wars fan.

00:05:03.529 --> 00:05:08.759
All she has to do is multiply her prior beliefs--the one’s she held before she had any new information--by

00:05:08.760 --> 00:05:13.800
the Bayes Factor which tells her how much to change her belief, now that she has gotten some evidence.

00:05:13.800 --> 00:05:19.000
The resulting belief is called her posterior
belief in this case 2.97.

00:05:19.000 --> 00:05:21.840
And she can continue to incorporate new information.

00:05:21.849 --> 00:05:26.300
When Jordan says that his dog is named Anakin, she can again update her beliefs.

00:05:26.300 --> 00:05:28.000
Or just ask!

00:05:28.000 --> 00:05:30.830
Mathematically, we took Maria’s prior belief:

00:05:30.830 --> 00:05:35.409
And updated it with our Bayes Factor, which told us how much our data--Jordan seeing the

00:05:35.409 --> 00:05:38.830
new Star Wars movie--should change her beliefs about his fanhood.

00:05:38.830 --> 00:05:43.319
This is a very simple example of how we can use Bayesian Hypothesis Testing to compare

00:05:43.319 --> 00:05:47.539
the probabilities of different hypotheses
based on data that we observe.

00:05:47.539 --> 00:05:51.129
But this doesn’t look exactly like the Bayes’
Theorem that we saw at the beginning...

00:05:51.129 --> 00:05:56.020
That's because instead of looking at the probability of one hypothesis given the data, we’re

00:05:56.020 --> 00:05:58.440
looking at the ratio of two hypotheses.

00:05:58.440 --> 00:06:02.260
Instead of just calculating the probability
that Jordan was a Star wars fan, given that

00:06:02.260 --> 00:06:06.590
he’d seen the latest film, we compared the
probabilities of the two hypotheses, given

00:06:06.590 --> 00:06:07.779
that he’d seen the movie.

00:06:07.779 --> 00:06:11.729
So we’re really looking at the ratio of
two calculations of Bayes’ Theorem because

00:06:11.729 --> 00:06:14.520
we’re comparing two posterior probabilities.

00:06:14.520 --> 00:06:18.539
Luckily, the probability of having seen the
latest Star Wars movie is the same in both

00:06:18.539 --> 00:06:21.740
equations, so it cancels out and we end up
with this:

00:06:21.740 --> 00:06:23.909
In Bayesian Statistics, these things are called:

00:06:23.909 --> 00:06:28.099
the Prior--what you believed before you saw any evidence

00:06:28.099 --> 00:06:32.659
the likelihood--a measure of how much your evidence should change your prior beliefs

00:06:32.659 --> 00:06:36.210
And the Posterior--what you believe after
you’ve seen the evidence

00:06:36.210 --> 00:06:40.720
In a more general form we can say that after we see the data, how likely one hypothesis

00:06:40.720 --> 00:06:45.949
is compared to the other is equal to the ratio of how likely we thought these hypotheses

00:06:45.949 --> 00:06:51.420
were before we got any evidence, adjusted
by the evidence with which the data provided us.

00:06:51.420 --> 00:06:57.740
This reflects the core idea of Bayesian Hypothesis testing: Updating what you currently believe,

00:06:57.740 --> 00:06:58.800
with new information.

00:06:58.800 --> 00:07:01.550
But notice that I said that you update your
belief.

00:07:01.550 --> 00:07:03.220
Inherently, what we believe is subjective.

00:07:03.220 --> 00:07:06.150
It depends on who we are, and what we’ve
experienced.

00:07:06.150 --> 00:07:10.629
While Maria initially believed that a star
wars fan is 1.5 times more likely than an

00:07:10.629 --> 00:07:12.689
non fan, you may believe something else.

00:07:12.689 --> 00:07:15.719
Like that it’s just as likely that someone
is a fan and not a fan.

00:07:15.719 --> 00:07:20.139
And since this is just a personal belief,
it’s okay that you and Maria believe something

00:07:20.139 --> 00:07:21.560
different to begin with.

00:07:21.560 --> 00:07:25.949
But we used Maria’s prior beliefs in our
calculations, if you were to do the same calculations,

00:07:25.949 --> 00:07:27.659
you’d come up with a different number.

00:07:27.659 --> 00:07:30.680
And this is one criticism that Bayesian statistical inference faces.

00:07:30.680 --> 00:07:35.789
One of the main uses of statistics is science which is supposed to be relatively “objective”

00:07:35.789 --> 00:07:41.849
and not influenced by opinion, and yet, here’s a method that includes beliefs in its calculation.

00:07:41.849 --> 00:07:47.039
For example, say a scientist bases her conclusion that Extra Sensory Perception (ESP) exists

00:07:47.039 --> 00:07:50.469
on the posterior odds of her Bayesian calculation.

00:07:50.469 --> 00:07:56.160
She concludes from her study that it is 5
times more likely that ESP exists than doesn’t exist.

00:07:56.160 --> 00:08:00.800
But upon reading her paper, you find that
her prior beliefs about the probability of

00:08:00.800 --> 00:08:03.999
ESP were way higher were way higher than yours.

00:08:03.999 --> 00:08:09.809
She assumed that it was just as likely that
ESP exists as it is that ESP doesn’t exist.

00:08:09.809 --> 00:08:11.879
And that just doesn’t seem right to you.

00:08:11.879 --> 00:08:17.050
You could find another scientist who has about the same prior beliefs about ESP as you do...

00:08:17.050 --> 00:08:19.479
but that seems difficult and a bit inefficient…

00:08:19.479 --> 00:08:20.629
There is a better solution.

00:08:20.629 --> 00:08:25.740
Often studies that use Bayesian calculations will not just report their posterior odds,

00:08:25.740 --> 00:08:28.479
but also the Bayes Factor that they calculated.

00:08:28.479 --> 00:08:33.070
If you disagreed with a researcher’s prior
odds, you could use the reported Bayes Factor

00:08:33.070 --> 00:08:37.890
to adjust your own, different beliefs about
these two specific hypotheses.

00:08:37.890 --> 00:08:43.289
For example, if you believed that it was 1,000 times more likely that ESP doesn’t exist,

00:08:43.289 --> 00:08:48.360
you could use the researcher’s reported
Bayes Factor, 5, and adjust your own beliefs:

00:08:48.360 --> 00:08:52.900
Even though the evidence in the study makes you believe that ESP is more likely than before,

00:08:52.900 --> 00:08:56.550
you still think it’s relatively unlikely
that ESP exists.

00:08:56.550 --> 00:09:01.630
Even though Bayesian Hypothesis Testing includes subjective beliefs, the Bayes factor allows

00:09:01.630 --> 00:09:06.840
you, and anyone else, to use the evidence
from a study or analysis to update whatever

00:09:06.840 --> 00:09:11.680
your prior beliefs about the two specified
hypotheses!

00:09:11.680 --> 00:09:16.320
Just like you and the ESP favoring researcher, sometimes evidence can lead two people to

00:09:16.320 --> 00:09:18.220
very different conclusions.

00:09:18.220 --> 00:09:23.490
But often, unless someone has already decided something has a 0% probability, when there’s

00:09:23.490 --> 00:09:28.470
sufficient evidence, two people with different prior odds will come to the same conclusion.

00:09:28.470 --> 00:09:32.590
For example, you initially believe that sushi
is pretty dangerous and has a high risk of

00:09:32.590 --> 00:09:37.450
infecting you with parasites, and your co-worker thinks that the risk is low to moderate.

00:09:37.450 --> 00:09:41.740
If you both see your boss and entire team
go out to sushi every week for 2 years and

00:09:41.740 --> 00:09:47.190
not have any issues with parasites, both of
you, despite your initial differences, would

00:09:47.190 --> 00:09:51.400
probably have updated your beliefs with this new information and concluded that sushi is

00:09:51.400 --> 00:09:52.850
pretty safe after all.

00:09:52.850 --> 00:09:57.500
If you had only seen your boss go out to sushi 4 times without getting a parasite, you may

00:09:57.500 --> 00:10:01.460
have each come to different conclusions since that’s not as much evidence.

00:10:01.460 --> 00:10:05.130
You may still think sushi is pretty risky,
but that may have been enough evidence to

00:10:05.130 --> 00:10:07.200
convince your co-worker it’s safe.

00:10:07.200 --> 00:10:10.970
Your current beliefs would rely more on your prior beliefs than the new evidence.

00:10:10.970 --> 00:10:15.480
But the huge amount of evidence provided by a group of healthy co-workers over 2 years

00:10:15.480 --> 00:10:19.620
was enough to overwhelm your and your coworker’s
prior beliefs.

00:10:19.620 --> 00:10:24.760
So your new, posterior beliefs are more affected by the evidence than your prior beliefs.

00:10:24.760 --> 00:10:29.680
Bayesian hypothesis testing provides a structured way to quantify a logical process that we

00:10:29.680 --> 00:10:34.080
do every day, incorporating new events into
the way that we see the world.

00:10:34.090 --> 00:10:39.350
It provides an explanation...or at least a
hypothesis--about why two people can see the

00:10:39.350 --> 00:10:41.720
same evidence and reach different conclusions.

00:10:41.720 --> 00:10:46.650
In some situations, the logic of Bayesian
methods similar to how we think naturally.

00:10:46.650 --> 00:10:51.280
Like a doctor who uses patient symptoms like fever and fatigue to update the prior odds

00:10:51.280 --> 00:10:55.940
that a patient has the flu compared to a cold so that they can prescribe the correct treatment.

00:10:55.940 --> 00:11:00.100
Or the way that you updated your belief that
your best friend is a kind, caring person

00:11:00.100 --> 00:11:04.290
by continuously incorporating evidence of
their kindness--like covering the cost of

00:11:04.290 --> 00:11:07.070
your Starbucks when you lost your wallet,
or helping you move.

00:11:07.070 --> 00:11:10.800
In real life you don’t ignore all previous
pieces of evidence you saw as soon as you

00:11:10.800 --> 00:11:15.700
get a new one, and Bayesian Inference allows for you to take your new updated beliefs and

00:11:15.700 --> 00:11:17.360
update them again.

00:11:17.360 --> 00:11:22.630
As some Bayesians say, “yesterday’s posterior (your updated belief), is today’s prior

00:11:22.630 --> 00:11:24.540
(the beliefs to be updated)”

00:11:24.560 --> 00:11:26.720
Thanks for Watching, I’ll see you next time.

