WEBVTT
Kind: captions
Language: en

00:00:05.280 --> 00:00:06.590
SPEAKER 1: OK, everybody.

00:00:06.590 --> 00:00:09.727
So our next session
is security identity.

00:00:09.727 --> 00:00:11.685
To moderate this session
we have Michael Coates

00:00:11.685 --> 00:00:13.744
from Shape Security.

00:00:13.744 --> 00:00:15.910
MICHAEL COATES: Well, I'm
really excited to be here.

00:00:15.910 --> 00:00:17.780
We've got a great
panel lined up.

00:00:17.780 --> 00:00:20.690
I think we're going to have some
very interesting conversations.

00:00:20.690 --> 00:00:24.190
As everyone probably knows,
security is not easy.

00:00:24.190 --> 00:00:27.160
Not that anything else we
talked about today was easy,

00:00:27.160 --> 00:00:29.110
but there are certainly
some loaded topics.

00:00:29.110 --> 00:00:32.180
And I'm really excited for
some good feedback and comments

00:00:32.180 --> 00:00:33.510
from the audience.

00:00:33.510 --> 00:00:35.610
As a reminder, so
we can highlight you

00:00:35.610 --> 00:00:39.320
on the Livestream, do stand
up when you ask a question

00:00:39.320 --> 00:00:41.680
so we'll get all of you in that.

00:00:41.680 --> 00:00:45.060
Briefly introducing everyone
starting over here to my right,

00:00:45.060 --> 00:00:47.720
we've got Mark
Nottingham at Akamai.

00:00:47.720 --> 00:00:50.070
He comes to us from Australia.

00:00:50.070 --> 00:00:55.640
WG chair for HTTP/2, tons of
work on protocols and formats,

00:00:55.640 --> 00:00:58.080
some stuff on RSS,
atom, web services,

00:00:58.080 --> 00:00:59.080
all sorts of good stuff.

00:00:59.080 --> 00:01:00.015
No?

00:01:00.015 --> 00:01:00.430
MARK NOTTINGHAM:
No web services.

00:01:00.430 --> 00:01:00.860
MICHAEL COATES:
Not web services.

00:01:00.860 --> 00:01:02.100
MARK NOTTINGHAM: I
never did web services.

00:01:02.100 --> 00:01:03.516
MICHAEL COATES:
Nothing there, OK.

00:01:03.516 --> 00:01:13.620
K [INAUDIBLE] encryption.

00:01:13.620 --> 00:01:16.780
[INAUDIBLE], and also working
on a HTTPS [INAUDIBLE]

00:01:16.780 --> 00:01:20.470
and SecureDrop,
among other things.

00:01:20.470 --> 00:01:26.810
Chris [INAUDIBLE] Cisco.

00:01:26.810 --> 00:01:30.284
[INAUDIBLE] Foundation,
worked with identity

00:01:30.284 --> 00:01:31.075
in the [INAUDIBLE].

00:01:40.100 --> 00:01:43.760
In Tokyo, co-chair of the web
and mobile interest group,

00:01:43.760 --> 00:01:47.450
and lots of information
on the mobile front.

00:01:47.450 --> 00:01:50.270
And Mike coming from
Google based in Munich.

00:01:50.270 --> 00:01:54.060
Lots of work with the
Chrome privacy team.

00:01:54.060 --> 00:01:56.470
Items like HSTS, mixed content.

00:01:56.470 --> 00:01:58.230
Maybe not HSTS, but
we'll talk about that.

00:01:58.230 --> 00:01:59.470
It's on my agenda, certainly.

00:01:59.470 --> 00:02:01.930
Mixed content and
content security policy.

00:02:01.930 --> 00:02:05.774
So we'll kick things off with
a brief presentation from Yan.

00:02:05.774 --> 00:02:07.940
YAN ZHU: OK, so I think my
name's pronounced "yawn",

00:02:07.940 --> 00:02:10.630
but it's OK if you
guys mess it up.

00:02:10.630 --> 00:02:14.090
So welcome to the security
and identity session.

00:02:14.090 --> 00:02:16.600
Yeah, identities are fluid.

00:02:16.600 --> 00:02:20.270
So I hope to convince
you that this

00:02:20.270 --> 00:02:22.840
is one of the more
interesting sessions,

00:02:22.840 --> 00:02:25.290
but my perspective is
honestly very biased

00:02:25.290 --> 00:02:26.930
because security is so broad.

00:02:26.930 --> 00:02:30.160
So I will definitely not
cover the whole scope

00:02:30.160 --> 00:02:33.050
of what you can ask
during this session.

00:02:33.050 --> 00:02:35.800
So how many of you have
ever felt insecure,

00:02:35.800 --> 00:02:39.390
because you're insecure
about your job, or your love

00:02:39.390 --> 00:02:41.842
life, or finances?

00:02:41.842 --> 00:02:43.800
So some of us haven't
felt any of those things,

00:02:43.800 --> 00:02:45.400
but we still use Quora.

00:02:45.400 --> 00:02:47.080
And when you use
a site like Quora

00:02:47.080 --> 00:02:51.410
that has 10 million-ish
monthly active users,

00:02:51.410 --> 00:02:55.060
you are sending your password
and username over plain HTTP.

00:02:55.060 --> 00:02:57.430
And I checked this
like a month ago.

00:02:57.430 --> 00:03:00.250
Not just serving the
login form over HTTP,

00:03:00.250 --> 00:03:03.470
they're actually sending a
post request over plain HTTP.

00:03:03.470 --> 00:03:08.720
And this is 2014, and
why are we not angry?

00:03:08.720 --> 00:03:12.720
Well, SSL is hard, but
let's try to make it easier.

00:03:12.720 --> 00:03:14.960
And that's one of the
themes we'll talk about.

00:03:14.960 --> 00:03:17.890
So how many people
recognize this slide?

00:03:17.890 --> 00:03:20.900
How many people have
heard of Edward Snowden?

00:03:20.900 --> 00:03:24.720
So Edward Snowden
sort of put HTTP--

00:03:24.720 --> 00:03:27.870
made HTTP look much
worse than it did before,

00:03:27.870 --> 00:03:31.390
because we saw NSA slides
that say, why are we

00:03:31.390 --> 00:03:33.230
interested in HTTP?

00:03:33.230 --> 00:03:38.399
Because HTTP allows the NSA
to do mass surveillance,

00:03:38.399 --> 00:03:39.440
according to these sides.

00:03:42.070 --> 00:03:46.890
And so what previously we
would say, if you use HTTP,

00:03:46.890 --> 00:03:50.000
someone at your coffee shop
can sniff your traffic,

00:03:50.000 --> 00:03:52.330
and read your passwords,
and that's bad.

00:03:52.330 --> 00:03:54.610
But now we can
say, oh now the NSA

00:03:54.610 --> 00:03:57.460
can collect all your
traffic and index it

00:03:57.460 --> 00:04:03.210
into a very ugly GUI
like this that you see.

00:04:03.210 --> 00:04:07.360
So what are people
doing about this?

00:04:07.360 --> 00:04:09.880
Sorry this is a little
bit small to see.

00:04:09.880 --> 00:04:14.530
But I used to work at the EFF,
Electronic Frontier Foundation.

00:04:14.530 --> 00:04:17.380
And about a year
ago we asked people,

00:04:17.380 --> 00:04:21.130
we asked major service
websites which of these things

00:04:21.130 --> 00:04:22.250
do you support?

00:04:22.250 --> 00:04:25.490
So the categories are,
encrypt data center links,

00:04:25.490 --> 00:04:30.100
support HTTPS on your website,
support HTTP Strict Transport

00:04:30.100 --> 00:04:33.450
Security, support [INAUDIBLE]
with forward secrecy,

00:04:33.450 --> 00:04:37.800
and support STARTTLS, which is
transit encryption for mail.

00:04:37.800 --> 00:04:40.020
And when we started,
there was a lot more red.

00:04:40.020 --> 00:04:42.520
And I don't have a
before slide, but you

00:04:42.520 --> 00:04:44.250
can see we have
a lot more green.

00:04:44.250 --> 00:04:46.410
And we have a lot more
companies that say,

00:04:46.410 --> 00:04:47.790
we're working on this.

00:04:47.790 --> 00:04:52.960
Plan quarter two 2014,
this is in progress.

00:04:52.960 --> 00:04:55.830
And people don't
often talk about email

00:04:55.830 --> 00:04:59.740
when they talk about HTTPS,
but it's also really important.

00:04:59.740 --> 00:05:03.320
So we've also seen that
since December 2013,

00:05:03.320 --> 00:05:06.040
email encryption has
risen about 33% to 58%.

00:05:10.080 --> 00:05:13.870
And now people are saying,
oh web traffic encryption

00:05:13.870 --> 00:05:21.190
has more than doubled after
some of the NSA revelations.

00:05:21.190 --> 00:05:25.400
So more exciting things
are happening this year.

00:05:25.400 --> 00:05:29.770
So WordPress is moving
to support SSL fully,

00:05:29.770 --> 00:05:33.800
and that's a huge percentage
of traffic as well.

00:05:33.800 --> 00:05:37.490
But what else is going on
other than HTTPS support

00:05:37.490 --> 00:05:40.140
becoming much more
popular these days?

00:05:40.140 --> 00:05:43.300
So Chromium and
Firefox, the browsers

00:05:43.300 --> 00:05:45.620
are implementing WebCrypto.

00:05:45.620 --> 00:05:50.140
In fact, I think Chrome
37 is out already, right?

00:05:50.140 --> 00:05:53.040
So this has already passed.

00:05:53.040 --> 00:05:56.100
So this will allow
people to more easily do

00:05:56.100 --> 00:05:57.950
Crypto in a browser,
which we see

00:05:57.950 --> 00:06:00.020
more and more of these days.

00:06:00.020 --> 00:06:02.690
So a more interesting--
sorry, not more interesting,

00:06:02.690 --> 00:06:04.640
but another thing
that's happening

00:06:04.640 --> 00:06:08.000
is up HTTP public key pinning.

00:06:08.000 --> 00:06:11.540
So websites will be able to
say, these are the certificate

00:06:11.540 --> 00:06:14.420
authorities we
expect you to see,

00:06:14.420 --> 00:06:18.990
or these are the certificates
that we expect you to see.

00:06:18.990 --> 00:06:22.960
And so Firefox 32
now supports that.

00:06:25.740 --> 00:06:29.110
Another cool initiative is
certificate transparency.

00:06:29.110 --> 00:06:32.800
So how many people here
are familiar with that?

00:06:32.800 --> 00:06:34.360
Very few.

00:06:34.360 --> 00:06:37.160
So essentially,
certificate transparency

00:06:37.160 --> 00:06:40.840
guarantees that if you see
a certificate from a CA

00:06:40.840 --> 00:06:42.410
it is publicly logged.

00:06:42.410 --> 00:06:44.960
And people can go back,
and check those logs,

00:06:44.960 --> 00:06:47.000
and detect attacks.

00:06:47.000 --> 00:06:49.460
And this helps
mitigate the problem

00:06:49.460 --> 00:06:54.870
that any CA can issue a bad
certificate for you currently.

00:06:58.020 --> 00:07:01.500
And Chris Palmer and other
people at Google security

00:07:01.500 --> 00:07:06.330
are saying, let's create
greater incentives for people

00:07:06.330 --> 00:07:09.800
to support HTTPS and
prefer secure origins

00:07:09.800 --> 00:07:11.600
for powerful new web features.

00:07:11.600 --> 00:07:15.790
And so secure as HTTPS,
secure web sockets,

00:07:15.790 --> 00:07:19.440
and local protocols as well.

00:07:19.440 --> 00:07:23.210
So local IPs, rather.

00:07:23.210 --> 00:07:26.050
And I'm sure Mark will
say a lot more about this,

00:07:26.050 --> 00:07:27.750
but HTTP/2 is out.

00:07:27.750 --> 00:07:30.230
And one of the big questions
is, should encryption

00:07:30.230 --> 00:07:31.200
be the default?

00:07:31.200 --> 00:07:33.320
Should we still have to
think about setting up

00:07:33.320 --> 00:07:34.450
SSL certificates?

00:07:34.450 --> 00:07:36.300
Or should it just
be automatically

00:07:36.300 --> 00:07:39.720
part of the protocol and
something that is inherent

00:07:39.720 --> 00:07:42.235
that you have to use if
you're going to use HTTP/2?

00:07:45.230 --> 00:07:46.830
But not everything's great.

00:07:46.830 --> 00:07:49.770
So we saw with Heartbleed
earlier this year

00:07:49.770 --> 00:07:53.910
that certificate revocation
is still very hard to do.

00:07:53.910 --> 00:07:55.880
And this is a very
funny diagram that

00:07:55.880 --> 00:08:01.960
shows-- so the number of sites
that reissued certificates

00:08:01.960 --> 00:08:10.260
after Heartbleed is 43%, but
only 20% revoked certificates.

00:08:10.260 --> 00:08:15.300
And of those, 7% issued
the same private key

00:08:15.300 --> 00:08:17.850
that was compromised, by
Heartbleed presumably,

00:08:17.850 --> 00:08:19.660
was reissued in the certificate.

00:08:19.660 --> 00:08:22.180
So the point of this
is that SSL management

00:08:22.180 --> 00:08:24.090
is very hard for people, right?

00:08:24.090 --> 00:08:28.250
Even with Heartbleed, which
everyone said was a disaster,

00:08:28.250 --> 00:08:30.410
we didn't react as
well as we could,

00:08:30.410 --> 00:08:35.480
as people who maintain
servers and so forth.

00:08:35.480 --> 00:08:38.860
So another thing that keeps
happening is password breaches.

00:08:38.860 --> 00:08:41.559
And we'll talk about why
passwords are so difficult.

00:08:41.559 --> 00:08:43.600
But I think for
most of us, we don't

00:08:43.600 --> 00:08:47.050
realize how hard passwords
are for the average person

00:08:47.050 --> 00:08:49.990
until we see these leaked
password breach data.

00:08:49.990 --> 00:08:52.370
So this is from the Adobe
one earlier this year.

00:08:52.370 --> 00:08:53.410
Oh, we're at Adobe.

00:08:53.410 --> 00:08:56.327
I didn't even think about that.

00:08:56.327 --> 00:08:56.826
Oops.

00:09:00.040 --> 00:09:03.800
So Adobe was
encrypting passwords

00:09:03.800 --> 00:09:05.460
instead of salting
and hashing them.

00:09:05.460 --> 00:09:09.600
So it was fairly easy to
do statistical analysis

00:09:09.600 --> 00:09:12.900
and get the plain
text passwords back.

00:09:12.900 --> 00:09:15.705
And so what people
don't realize was

00:09:15.705 --> 00:09:18.360
what might not have been obvious
is that people's password

00:09:18.360 --> 00:09:20.460
hints, which may not be
stored encrypted at all,

00:09:20.460 --> 00:09:22.790
are often just their password.

00:09:22.790 --> 00:09:25.350
So even if you're doing
salting and hashing,

00:09:25.350 --> 00:09:28.306
peoples' password
hints say 1-2-3-4-5-6,

00:09:28.306 --> 00:09:30.880
and that's their password
a lot of the time.

00:09:30.880 --> 00:09:36.140
Or rhymes with 'assword' is
probably password, right?

00:09:36.140 --> 00:09:37.750
So what's our user model here?

00:09:37.750 --> 00:09:40.816
We have to think about people
who are not good at passwords.

00:09:40.816 --> 00:09:42.940
And what are some ways we
can either make passwords

00:09:42.940 --> 00:09:46.460
better or replace them?

00:09:46.460 --> 00:09:48.380
And I don't know if
we'll talk about this,

00:09:48.380 --> 00:09:51.710
but something that has
been in the news a lot

00:09:51.710 --> 00:09:54.910
lately is third party
tracking in browsers.

00:09:54.910 --> 00:09:58.890
So this is from a while
ago, but a question

00:09:58.890 --> 00:10:03.810
is what browsers implement
third party cookie blocking?

00:10:03.810 --> 00:10:05.860
Even if there's
so much incentive

00:10:05.860 --> 00:10:10.520
for advertisers to use
this sort of tracking?

00:10:10.520 --> 00:10:11.610
So what can browsers do?

00:10:14.190 --> 00:10:16.220
So that's a comic.

00:10:16.220 --> 00:10:19.645
And none of this
was about identity,

00:10:19.645 --> 00:10:21.920
but you can still
ask about identity

00:10:21.920 --> 00:10:23.790
because that's in the
title of the session.

00:10:23.790 --> 00:10:25.260
Yeah, sorry Chris.

00:10:25.260 --> 00:10:29.600
Cool, that's it.

00:10:29.600 --> 00:10:34.600
[APPLAUSE]

00:10:37.262 --> 00:10:39.720
MICHAEL COATES: Great, well
why don't we just dive in here?

00:10:39.720 --> 00:10:41.845
I mean, a lot of the topics
that you mentioned down

00:10:41.845 --> 00:10:44.810
in current events talk
about SSL encryption.

00:10:44.810 --> 00:10:45.970
It seems like a no brainer.

00:10:45.970 --> 00:10:47.800
We don't want our data to
be exposed in the clear.

00:10:47.800 --> 00:10:49.800
We don't want governments
to monitor what we do.

00:10:49.800 --> 00:10:51.550
We don't want our
passwords-- regardless

00:10:51.550 --> 00:10:53.966
of how they're stored, which
is a whole other issue-- just

00:10:53.966 --> 00:10:57.390
to be handed out to everyone
next to us at a coffeehouse.

00:10:57.390 --> 00:11:02.110
So our first question along this
topic comes from Andrew Betts

00:11:02.110 --> 00:11:05.320
and is, setting up
SSL is too hard today.

00:11:05.320 --> 00:11:07.740
What is the single
biggest cause of this?

00:11:07.740 --> 00:11:11.100
And what can we do to make
it much easier and faster?

00:11:11.100 --> 00:11:13.710
And to continue
along with this, Yan,

00:11:13.710 --> 00:11:15.780
why don't you give us
some of your thoughts?

00:11:15.780 --> 00:11:16.363
YAN ZHU: Sure.

00:11:16.363 --> 00:11:19.390
So I think setting
up SSL varies--

00:11:19.390 --> 00:11:22.010
the complexity of the process
varies a lot depending

00:11:22.010 --> 00:11:24.880
on whether you're just someone
with a one page website

00:11:24.880 --> 00:11:28.380
or if you're a company
like Yahoo or Twitter.

00:11:28.380 --> 00:11:30.770
But let's say with the simpler
case, where you're just

00:11:30.770 --> 00:11:32.520
someone with a website
who wants to set up

00:11:32.520 --> 00:11:34.800
SSL, still a large
number of steps.

00:11:34.800 --> 00:11:36.410
So you have to go
to a website, you

00:11:36.410 --> 00:11:38.350
have to pick a
certificate authority,

00:11:38.350 --> 00:11:41.240
buy it, make sure you put
it in the right folder,

00:11:41.240 --> 00:11:43.090
restart your server,
and all that.

00:11:43.090 --> 00:11:45.830
And so I think something
that's really great

00:11:45.830 --> 00:11:49.070
is that CDNs like
CloudFlare-- I don't

00:11:49.070 --> 00:11:51.190
know if I should call them
a CDN in this context--

00:11:51.190 --> 00:11:53.770
but they're thinking about
providing free SSL to all

00:11:53.770 --> 00:11:57.532
their customers and making
that setup process automatic.

00:11:57.532 --> 00:11:59.240
And there are several
other organizations

00:11:59.240 --> 00:12:02.040
are-- like for
instance, if you're

00:12:02.040 --> 00:12:03.880
a payment site like
Stripe you might say,

00:12:03.880 --> 00:12:06.420
we want all of our
customers to use SSL.

00:12:06.420 --> 00:12:09.510
So why don't we make
it as easy as possible

00:12:09.510 --> 00:12:10.980
and make it a one-click process?

00:12:10.980 --> 00:12:13.105
So that's something people
have been thinking about

00:12:13.105 --> 00:12:16.857
is one-click SSL setup
for the very simple case.

00:12:16.857 --> 00:12:18.440
MICHAEL COATES: And
Mark, do you think

00:12:18.440 --> 00:12:20.800
we should have to go through
any of this effort at all?

00:12:20.800 --> 00:12:23.384
Should it just be the de
facto of how we do things?

00:12:23.384 --> 00:12:25.550
MARK NOTTINGHAM: Well, we've
talked about that a lot

00:12:25.550 --> 00:12:27.883
in the ITF in terms of making
it the default for HTTP/2.

00:12:30.730 --> 00:12:33.990
There's the administrative load
of getting the cert configured,

00:12:33.990 --> 00:12:37.470
there's the load of modifying
your content-- which

00:12:37.470 --> 00:12:39.550
for a lot of people is
where most of the work is.

00:12:39.550 --> 00:12:41.750
If you have a lot of
content, it changes the way

00:12:41.750 --> 00:12:44.020
the web security model works.

00:12:44.020 --> 00:12:47.250
Once you get past those-- that's
a transition phase you need

00:12:47.250 --> 00:12:49.099
to go through-- it
becomes a lot easier.

00:12:49.099 --> 00:12:50.890
And I know there are
some efforts out there

00:12:50.890 --> 00:12:52.320
to make all of this easier.

00:12:52.320 --> 00:12:54.040
There's bettercrypto.org,
which is,

00:12:54.040 --> 00:12:56.137
how do you set up good crypto?

00:12:56.137 --> 00:12:57.720
People are working
on making it easier

00:12:57.720 --> 00:13:00.460
to install the cert on the
server with NPM libraries,

00:13:00.460 --> 00:13:02.242
or whatever.

00:13:02.242 --> 00:13:03.450
Sorry, what was the question?

00:13:05.544 --> 00:13:06.960
MICHAEL COATES:
Should individuals

00:13:06.960 --> 00:13:08.110
have to be doing this?

00:13:08.110 --> 00:13:09.049
If it's hard?

00:13:09.049 --> 00:13:11.590
MARK NOTTINGHAM: Are you asking
about opportunistic security?

00:13:11.590 --> 00:13:13.510
Are we going there already?

00:13:13.510 --> 00:13:16.360
So one of the
proposals out there

00:13:16.360 --> 00:13:18.840
is to use what we call
opportunistic security,

00:13:18.840 --> 00:13:22.640
to use TLS under the covers
but not change the URL,

00:13:22.640 --> 00:13:24.230
keep it HTTP.

00:13:24.230 --> 00:13:27.270
Not change the security
context and [? Olock ?] icon.

00:13:27.270 --> 00:13:29.334
It's just protecting
against passive attacks.

00:13:29.334 --> 00:13:31.000
MIKE WEST: To me
that's a terrible idea.

00:13:31.000 --> 00:13:32.410
MARK NOTTINGHAM: Well, this
has been very controversial,

00:13:32.410 --> 00:13:33.210
I was about to say.

00:13:33.210 --> 00:13:33.940
MIKE WEST: To me,
it doesn't actually

00:13:33.940 --> 00:13:36.784
remove any of the burden of
setting up anything, right?

00:13:36.784 --> 00:13:38.200
You still have to
generate a cert,

00:13:38.200 --> 00:13:39.380
you still have to install
it on your server.

00:13:39.380 --> 00:13:40.980
MARK NOTTINGHAM: But you can
do all of that automatically.

00:13:40.980 --> 00:13:42.870
A good service
with implementation

00:13:42.870 --> 00:13:44.870
can do that without any
intervention whatsoever.

00:13:44.870 --> 00:13:46.497
MIKE WEST: If you
look at sslmate.com,

00:13:46.497 --> 00:13:48.580
they actually have an API
to generate normal certs

00:13:48.580 --> 00:13:49.830
that you can also automate.

00:13:49.830 --> 00:13:51.260
So it's not the case that only--

00:13:51.260 --> 00:13:52.470
MARK NOTTINGHAM: But you still
have you install the cert.

00:13:52.470 --> 00:13:53.595
MIKE WEST: Yeah, of course.

00:13:55.175 --> 00:13:56.800
MARK NOTTINGHAM: And
so I'm not arguing

00:13:56.800 --> 00:13:57.925
for opportunistic security.

00:13:57.925 --> 00:13:59.030
I think it's interesting.

00:13:59.030 --> 00:14:01.070
The Mozilla guys
are playing with it.

00:14:01.070 --> 00:14:03.220
I'd say it's experimental
from their standpoint.

00:14:03.220 --> 00:14:06.552
I know the Chrome security
guys are raining down hellfire,

00:14:06.552 --> 00:14:08.010
I would say is
probably a good way.

00:14:08.010 --> 00:14:09.490
They really don't like it.

00:14:09.490 --> 00:14:12.520
And I can understand
that, because it

00:14:12.520 --> 00:14:14.430
reduces the deployment of TLS.

00:14:14.430 --> 00:14:16.580
And I think we have broad
agreement of most people

00:14:16.580 --> 00:14:20.470
on the panel that more
deployment of HTTPS and TLS

00:14:20.470 --> 00:14:22.170
is a very good thing.

00:14:22.170 --> 00:14:23.870
The places where it
gets a lot harder

00:14:23.870 --> 00:14:27.160
are things like internet
of things, or your printer,

00:14:27.160 --> 00:14:28.940
or something on
your local network.

00:14:28.940 --> 00:14:29.770
That's really hard.

00:14:29.770 --> 00:14:31.353
And I think that
part of the community

00:14:31.353 --> 00:14:32.739
needs a lot more love.

00:14:32.739 --> 00:14:35.280
It's easy to say, oh yes, we're
going to get to that one day,

00:14:35.280 --> 00:14:38.050
but I don't see the
browsers focusing on it yet.

00:14:38.050 --> 00:14:41.074
NATASHA ROONEY: So if
content providers still

00:14:41.074 --> 00:14:42.740
need to go in and
install a certificate,

00:14:42.740 --> 00:14:45.590
the how does it ease
the situation for them?

00:14:45.590 --> 00:14:48.420
What is easier for them?

00:14:48.420 --> 00:14:50.907
MARK NOTTINGHAM: Because they
don't have to get it signed.

00:14:50.907 --> 00:14:53.240
It doesn't have to be signed
by a certificate authority.

00:14:53.240 --> 00:14:54.870
So it can be
generated by code, it

00:14:54.870 --> 00:14:56.891
can be installed and
configured by code.

00:14:56.891 --> 00:14:59.140
The idea is that from an
administrator's circumstance,

00:14:59.140 --> 00:15:00.160
you don't do anything.

00:15:00.160 --> 00:15:02.100
It just happens.

00:15:02.100 --> 00:15:04.860
And so that is easier, because
the administrative load is not

00:15:04.860 --> 00:15:06.037
nothing yet.

00:15:06.037 --> 00:15:08.120
MIKE WEST: You don't do
anything except setting up

00:15:08.120 --> 00:15:09.740
all the machinery
such that it works.

00:15:09.740 --> 00:15:11.614
I can't get away from
the idea that you still

00:15:11.614 --> 00:15:14.567
have to do the work to generate
certificates and install them.

00:15:14.567 --> 00:15:15.400
MARK NOTTINGHAM: No.

00:15:15.400 --> 00:15:17.190
MIKE WEST: You have to
set up the scripts, right?

00:15:17.190 --> 00:15:17.730
MARK NOTTINGHAM: No

00:15:17.730 --> 00:15:18.420
MIKE WEST: Yes.

00:15:18.420 --> 00:15:19.880
MARK NOTTINGHAM: A good
implementation-- and again,

00:15:19.880 --> 00:15:21.546
this implementation
does not yet exist--

00:15:21.546 --> 00:15:23.680
MIKE WEST: OK, so.

00:15:23.680 --> 00:15:25.430
MARK NOTTINGHAM: Well
because I don't even

00:15:25.430 --> 00:15:27.100
know if it's in
Firefox Nightly yet.

00:15:27.100 --> 00:15:28.690
I have to ask Patrick.

00:15:28.690 --> 00:15:31.030
But the idea would be
that the server side would

00:15:31.030 --> 00:15:34.030
generate the cert on its own
and configure it on its own.

00:15:34.030 --> 00:15:36.210
Right now, the problem is
the out-of-the-box Apache

00:15:36.210 --> 00:15:38.980
or [? iOS ?] or whatever
configuration is not the best

00:15:38.980 --> 00:15:39.770
configuration.

00:15:39.770 --> 00:15:41.120
It's the default.

00:15:41.120 --> 00:15:43.205
It would be a huge
win for us all

00:15:43.205 --> 00:15:44.859
if the defaults were
better, but this

00:15:44.859 --> 00:15:46.900
is a fight that has happened
in those communities

00:15:46.900 --> 00:15:47.864
for a long time.

00:15:47.864 --> 00:15:49.030
They're not quite there yet.

00:15:49.030 --> 00:15:51.529
MIKE WEST: So what is the value
of opportunistic encryption,

00:15:51.529 --> 00:15:53.410
given that it can be
completely removed

00:15:53.410 --> 00:15:55.142
by dropping a
single HTTP header?

00:15:55.142 --> 00:15:56.100
MARK NOTTINGHAM: Right.

00:15:56.100 --> 00:16:00.350
You have a downgrade attack, you
have men in the middle attacks,

00:16:00.350 --> 00:16:02.500
any active attack can take over.

00:16:02.500 --> 00:16:05.682
And the question is,
what are the consequences

00:16:05.682 --> 00:16:06.890
of the attacker going active?

00:16:06.890 --> 00:16:10.420
And how willing are they going
to be to go attack active?

00:16:10.420 --> 00:16:14.510
So most of the attacks we've
seen exposed by [? Sedona ?]

00:16:14.510 --> 00:16:15.810
have been passive.

00:16:15.810 --> 00:16:17.900
Jacob Applebaum
argues very strongly

00:16:17.900 --> 00:16:22.330
that having protection against
those passive attacks is a win.

00:16:22.330 --> 00:16:24.140
But yes, we know that
some state actors

00:16:24.140 --> 00:16:25.960
are very willing to go active.

00:16:25.960 --> 00:16:26.870
MIKE WEST: I wouldn't
even say state actors.

00:16:26.870 --> 00:16:29.411
You have ISPs that are injecting
JavaScript and reconfiguring

00:16:29.411 --> 00:16:31.690
your everythings,
which is not awesome.

00:16:31.690 --> 00:16:33.690
MARK NOTTINGHAM: And the
interesting thing to me

00:16:33.690 --> 00:16:35.490
is that leaves evidence.

00:16:35.490 --> 00:16:38.060
When they go active, you can
tell they've gone active.

00:16:38.060 --> 00:16:39.640
And what's really
interesting is,

00:16:39.640 --> 00:16:41.350
you were referring to
the Comcast ad injection.

00:16:41.350 --> 00:16:43.891
And there's been a reaction to
that, but as far as I'm aware,

00:16:43.891 --> 00:16:44.970
they're still doing it.

00:16:44.970 --> 00:16:46.870
It's not like they've been
stopped by people going,

00:16:46.870 --> 00:16:48.170
oh no, they're
putting ads in there.

00:16:48.170 --> 00:16:48.400
But they're still doing it

00:16:48.400 --> 00:16:49.360
MIKE WEST: That's
kind of my point,

00:16:49.360 --> 00:16:51.000
is that it's not
just state actors

00:16:51.000 --> 00:16:51.720
that we need to worry about.

00:16:51.720 --> 00:16:53.580
It's really anyone
between you and the server

00:16:53.580 --> 00:16:54.100
that you want to [INAUDIBLE].

00:16:54.100 --> 00:16:55.140
MARK NOTTINGHAM: And that's
what I worry about in all

00:16:55.140 --> 00:16:57.050
of this in both
directions is acclimation.

00:16:57.050 --> 00:16:59.720
When users get used to their
security being degraded,

00:16:59.720 --> 00:17:02.220
or they just come to expect
well that's just how things work

00:17:02.220 --> 00:17:04.080
on the internet, we're
all in a worse place.

00:17:04.080 --> 00:17:05.331
MIKE WEST: I completely agree.

00:17:05.331 --> 00:17:07.663
MICHAEL COATES: So I'd love
to get some people queued up

00:17:07.663 --> 00:17:09.599
in the audience with
some thoughts on SSL.

00:17:09.599 --> 00:17:13.790
So ring in and we'll get
some microphones your way.

00:17:13.790 --> 00:17:17.609
Let's go ahead and get to a
couple of those out there.

00:17:17.609 --> 00:17:21.230
In the meantime,
before this exists,

00:17:21.230 --> 00:17:23.399
anything we can do to
make it easier today?

00:17:26.300 --> 00:17:28.370
MIKE WEST: So like I
said, I think sslmate.com

00:17:28.370 --> 00:17:30.370
is a website that I think
is really interesting,

00:17:30.370 --> 00:17:34.500
because they're starting to put
an API in front of certificate

00:17:34.500 --> 00:17:35.060
generation.

00:17:35.060 --> 00:17:36.480
So you have a script
on your server,

00:17:36.480 --> 00:17:38.354
you say please generate
me a new certificate,

00:17:38.354 --> 00:17:41.380
and it does the work of using
the key or generating a key,

00:17:41.380 --> 00:17:44.780
and then going out, generating
the CSR, grabbing a cert,

00:17:44.780 --> 00:17:46.560
and doing all the
work for you, which

00:17:46.560 --> 00:17:48.460
I think is a really
interesting model.

00:17:48.460 --> 00:17:49.710
I'd like to see more of that.

00:17:49.710 --> 00:17:52.730
What I'd really
like to see is work

00:17:52.730 --> 00:17:56.430
being done by the providers.

00:17:56.430 --> 00:17:58.350
So it's not something
that I think

00:17:58.350 --> 00:18:00.610
browser vendors are really
well placed to solve.

00:18:00.610 --> 00:18:01.985
It's something
that I think needs

00:18:01.985 --> 00:18:06.110
to be done at a server level
and at a provider level.

00:18:06.110 --> 00:18:10.680
So when someone like Wordpress,
or something like CloudFlare

00:18:10.680 --> 00:18:13.280
does work and submits patches
back to the open source

00:18:13.280 --> 00:18:15.570
systems, I think that's a
really healthy relationship.

00:18:15.570 --> 00:18:16.940
And I'd like to see
more of that happening.

00:18:16.940 --> 00:18:19.148
MARK NOTTINGHAM: I'd like
to see the Apache plug-ins,

00:18:19.148 --> 00:18:21.273
and just to make those
really easy to use together.

00:18:21.273 --> 00:18:23.273
CHRIS MESSINA: Actually,
one more thing on that.

00:18:23.273 --> 00:18:24.840
So my friend
[INAUDIBLE] last night

00:18:24.840 --> 00:18:26.880
pointed out that in the
Indyweb organization

00:18:26.880 --> 00:18:28.530
and community have
worked on this.

00:18:28.530 --> 00:18:30.321
And they've got a bunch
of documentation up

00:18:30.321 --> 00:18:33.550
at indyweb.org/https if you want
to put it on your own servers.

00:18:33.550 --> 00:18:35.980
So there's some efforts
in that sense as well.

00:18:35.980 --> 00:18:36.580
MARK NOTTINGHAM: It's kind
of like better crypto.

00:18:36.580 --> 00:18:36.850
CHRIS MESSINA: Yeah.

00:18:36.850 --> 00:18:37.766
The same sort of idea.

00:18:39.790 --> 00:18:42.890
MICHAEL COATES: Out to the
audience, we've got Guy.

00:18:42.890 --> 00:18:43.510
There we are.

00:18:43.510 --> 00:18:45.010
AUDIENCE: I just
wanted to point out

00:18:45.010 --> 00:18:47.167
that there's the technical
aspect of installing it,

00:18:47.167 --> 00:18:49.000
but there's also the
certificate validation,

00:18:49.000 --> 00:18:50.333
which is part of the pain point.

00:18:50.333 --> 00:18:52.707
And I think there the
challenges are very different.

00:18:52.707 --> 00:18:54.165
I mean, if you do
domain validation

00:18:54.165 --> 00:18:56.240
you can see automation
and making that very easy.

00:18:56.240 --> 00:18:58.573
But when you're talking about
organizational validation,

00:18:58.573 --> 00:19:01.046
or extended
validation, those are

00:19:01.046 --> 00:19:03.420
processes that at least today
are part of the trust model

00:19:03.420 --> 00:19:05.794
we're educating our users
about with all sorts of signals

00:19:05.794 --> 00:19:06.824
on the browser.

00:19:06.824 --> 00:19:08.490
And as long as we're
there, then there's

00:19:08.490 --> 00:19:11.760
somebody that needs to call
up or look up another person.

00:19:11.760 --> 00:19:13.820
At least in the Akamai
experience, a lot of times

00:19:13.820 --> 00:19:15.903
those are the bottlenecks
versus the technologies.

00:19:15.903 --> 00:19:18.960
CHRIS MESSINA: And I guess I'd
claim that those have no value.

00:19:18.960 --> 00:19:20.600
That friction is
actually part of the--

00:19:20.600 --> 00:19:21.975
AUDIENCE: They
may have no value,

00:19:21.975 --> 00:19:23.760
but if that is the
claim, then they

00:19:23.760 --> 00:19:26.700
need to provide an
alternative or claim what

00:19:26.700 --> 00:19:27.980
it is that you are giving up.

00:19:27.980 --> 00:19:32.360
MIKE WEST: Yeah, I think from
my perspective domain validation

00:19:32.360 --> 00:19:33.460
is enough.

00:19:33.460 --> 00:19:35.020
Like if I prove that
I own the domain

00:19:35.020 --> 00:19:38.490
and in pin the
cert to my domain,

00:19:38.490 --> 00:19:41.890
proving that I totally
own it, then that's fine.

00:19:41.890 --> 00:19:43.939
I don't need EV, I
don't need a green bar.

00:19:43.939 --> 00:19:45.730
There's really no value
to that whatsoever.

00:19:45.730 --> 00:19:47.313
MARK NOTTINGHAM: You
mean PIN or HSTS?

00:19:47.313 --> 00:19:48.480
MIKE WEST: Both.

00:19:48.480 --> 00:19:50.790
MARK NOTTINGHAM: So I
pin my cert to my domain.

00:19:50.790 --> 00:19:55.290
Is your browser
acknowledging that pin?

00:19:55.290 --> 00:19:57.565
MIKE WEST: I don't know
if public key pins has

00:19:57.565 --> 00:19:58.800
shipped as a header.

00:19:58.800 --> 00:20:00.940
I know that we support
public key pins

00:20:00.940 --> 00:20:05.250
in the pre-load list in
both Chrome and Firefox now.

00:20:05.250 --> 00:20:08.080
I would have to ask folks
whether we support it

00:20:08.080 --> 00:20:08.930
on the open web.

00:20:08.930 --> 00:20:09.670
MARK NOTTINGHAM: I think
it's not yet supported.

00:20:09.670 --> 00:20:12.045
YAN ZHU: I think Chrome has
basic support for the header,

00:20:12.045 --> 00:20:13.162
but Firefox has not.

00:20:13.162 --> 00:20:13.870
MIKE WEST: Right.

00:20:13.870 --> 00:20:16.637
But regardless, that's going
to happen at some point.

00:20:16.637 --> 00:20:19.220
MARK NOTTINGHAM: But you can get
yourself in trouble with that

00:20:19.220 --> 00:20:19.350
too.

00:20:19.350 --> 00:20:20.700
You can put yourself
in a place where

00:20:20.700 --> 00:20:23.325
you've locked all of your users
out of your [INAUDIBLE] server.

00:20:23.325 --> 00:20:24.932
MIKE WEST: And
that's kind of bad.

00:20:24.932 --> 00:20:26.390
MARK NOTTINGHAM:
And I feel like we

00:20:26.390 --> 00:20:28.710
need even more best
practices around all this,

00:20:28.710 --> 00:20:31.087
because the process of getting
a cert and configuring it,

00:20:31.087 --> 00:20:33.670
and all these different little
tiny holes you can get yourself

00:20:33.670 --> 00:20:38.350
in is still very confusing, even
to someone who does this a lot.

00:20:38.350 --> 00:20:40.864
We can do a lot better.

00:20:40.864 --> 00:20:41.780
MICHAEL COATES: Great.

00:20:41.780 --> 00:20:44.880
Let's see here,
we've got to Alex.

00:20:44.880 --> 00:20:47.820
AUDIENCE: So Mark,
to your point I'm

00:20:47.820 --> 00:20:50.229
very curious to know
what folks on the stage

00:20:50.229 --> 00:20:51.770
or the organizations
you work for are

00:20:51.770 --> 00:20:55.670
doing to make it much easier to
get a system image-- like a dmg

00:20:55.670 --> 00:20:58.260
or something-- for a
VM and just get it up

00:20:58.260 --> 00:20:59.900
and running with good security.

00:20:59.900 --> 00:21:02.480
Because today my experience
is that if you take an Ubuntu

00:21:02.480 --> 00:21:04.520
image and you set it up.

00:21:04.520 --> 00:21:06.310
And you set up Apache
and you attempt

00:21:06.310 --> 00:21:07.764
to get your site
encrypted, you're

00:21:07.764 --> 00:21:09.680
going to end up with a
very bad configuration.

00:21:09.680 --> 00:21:12.090
You're going to have the
wrong order for cipher suites.

00:21:12.090 --> 00:21:13.917
You're going to have no HSTS.

00:21:13.917 --> 00:21:16.250
You're just going to be pretty
much boned out of the box

00:21:16.250 --> 00:21:18.520
until you figure out all of
these little fiddly bits.

00:21:18.520 --> 00:21:20.920
What can we do to make it so
that the distro vendors have

00:21:20.920 --> 00:21:22.380
some skin in the game here?

00:21:22.380 --> 00:21:24.990
MARK NOTTINGHAM: So
that's a good question.

00:21:24.990 --> 00:21:28.870
So when I switched my site to
HTTPS, I followed better crypto

00:21:28.870 --> 00:21:31.090
and deviated slightly from it.

00:21:31.090 --> 00:21:32.900
But we have guards
like better crypto,

00:21:32.900 --> 00:21:34.870
we have the SSL
labs tester which

00:21:34.870 --> 00:21:37.310
is a great resource-- I wish
that it was a little easier

00:21:37.310 --> 00:21:40.320
for people to find.

00:21:40.320 --> 00:21:42.390
But actually
convincing the distros,

00:21:42.390 --> 00:21:44.202
my experience is you
go to the distros

00:21:44.202 --> 00:21:46.410
and you make these arguments--
or you going to Apache

00:21:46.410 --> 00:21:48.450
and you make these arguments
about the defaults.

00:21:48.450 --> 00:21:51.364
And there tends to be-- I don't
want to pick on any one party

00:21:51.364 --> 00:21:53.280
here, but there tends
to be a lot of pushback.

00:21:53.280 --> 00:21:54.650
That, oh well we
have legacy reasons,

00:21:54.650 --> 00:21:56.170
we have compatibility
reasons, we

00:21:56.170 --> 00:21:58.336
have these huge groups of
users we need to consider.

00:21:58.336 --> 00:22:00.960
And it's like, well
that's not good enough.

00:22:00.960 --> 00:22:03.572
This is 2014, Edward
Snowden happened,

00:22:03.572 --> 00:22:05.030
and you're still
shipping something

00:22:05.030 --> 00:22:09.080
that's insecure by default
because you want 0.2% better

00:22:09.080 --> 00:22:12.950
interoperability with
IE5, or whatever it is.

00:22:12.950 --> 00:22:14.930
I really think we can
do better than that.

00:22:14.930 --> 00:22:17.200
But I think that takes a
coordinated effort by the web

00:22:17.200 --> 00:22:19.700
community to go
to those operating

00:22:19.700 --> 00:22:22.690
systems and another
communities and say, no this

00:22:22.690 --> 00:22:23.705
isn't good enough.

00:22:23.705 --> 00:22:25.424
And we haven't
quite seen that yet.

00:22:25.424 --> 00:22:27.840
MICHAEL COATES: Well, we'll
go ahead and wrap this one up.

00:22:27.840 --> 00:22:29.950
I heard a few good
ideas to take home.

00:22:29.950 --> 00:22:32.650
The future of
opportunistic encryption,

00:22:32.650 --> 00:22:35.200
that will be good
when we get there.

00:22:35.200 --> 00:22:36.700
There will be some challenges.

00:22:36.700 --> 00:22:39.160
I heard SSL Mate, SSL
Labs, and Indyweb.

00:22:39.160 --> 00:22:42.260
So some interesting items
to take home on that.

00:22:42.260 --> 00:22:44.430
So jumping right along,
no shortage of security

00:22:44.430 --> 00:22:47.230
challenges in the
world or internet.

00:22:47.230 --> 00:22:50.290
This next question paraphrased
from-- I'll try my best--

00:22:50.290 --> 00:22:52.100
Uav Weiss.

00:22:52.100 --> 00:22:55.310
Passwords are increasingly
seen as an anti-pattern.

00:22:55.310 --> 00:22:58.100
What are ideal alternatives?

00:22:58.100 --> 00:23:02.010
And Chris, you spend a
lot of time with identity.

00:23:02.010 --> 00:23:05.739
What has your experience
brought you to on this area?

00:23:05.739 --> 00:23:07.280
CHRIS MESSINA: It
is sad that we keep

00:23:07.280 --> 00:23:09.321
talking about being in 2014.

00:23:09.321 --> 00:23:11.570
And I feel like the last
time I worked on this problem

00:23:11.570 --> 00:23:12.830
was seven years ago.

00:23:12.830 --> 00:23:15.850
And there was a person
seven years before me

00:23:15.850 --> 00:23:17.980
that worked on it, and
back to the stone age.

00:23:17.980 --> 00:23:21.840
So it just doesn't seem
to be a problem that

00:23:21.840 --> 00:23:24.412
is going to solve
itself, certainly.

00:23:24.412 --> 00:23:26.870
And I think the similar to the
problem that you're pointing

00:23:26.870 --> 00:23:30.630
out, and that Alex is
pointing out with the distros,

00:23:30.630 --> 00:23:33.920
it comes down to economics,
behavioral economics as well as

00:23:33.920 --> 00:23:35.630
business model economics.

00:23:35.630 --> 00:23:37.220
The password
anti-pattern is something

00:23:37.220 --> 00:23:41.230
that we identified
when APIs were first

00:23:41.230 --> 00:23:43.185
starting to be
released in the 2005

00:23:43.185 --> 00:23:46.920
to 2007 era of the
golden web, back when

00:23:46.920 --> 00:23:49.105
they drove big cars
with whaleskin hubcaps.

00:23:51.147 --> 00:23:52.730
Sorry if you don't
get that reference,

00:23:52.730 --> 00:23:54.200
it's even longer than that.

00:23:54.200 --> 00:23:58.000
Anyway, the problem of course,
is it's really easy for users

00:23:58.000 --> 00:24:00.140
to remember one little string.

00:24:00.140 --> 00:24:02.820
Of course, if they put it in the
password recovery field anyway,

00:24:02.820 --> 00:24:06.810
then it's-- that's an
amazing slide, by the way.

00:24:06.810 --> 00:24:09.591
Anyway, back when
APIs were getting out,

00:24:09.591 --> 00:24:11.590
Basic was the only way
to do this authentication

00:24:11.590 --> 00:24:13.460
against these different
service providers.

00:24:13.460 --> 00:24:15.370
And the problem was that users
would reuse the same password

00:24:15.370 --> 00:24:15.880
everywhere.

00:24:15.880 --> 00:24:17.671
And so this became a
password anti-pattern,

00:24:17.671 --> 00:24:19.590
because if any one of
those chains was broken,

00:24:19.590 --> 00:24:22.450
effectively all of your
security was then screwed.

00:24:22.450 --> 00:24:25.602
And so we started a campaign
in conjunction with OpenID

00:24:25.602 --> 00:24:27.060
to try to get people
to switch over

00:24:27.060 --> 00:24:29.030
to something that was more of
a centralized authentication

00:24:29.030 --> 00:24:29.530
model.

00:24:29.530 --> 00:24:32.455
And so your OpenID provider--
your identity provider--

00:24:32.455 --> 00:24:34.580
essentially could be as
secure as you want it to be

00:24:34.580 --> 00:24:36.700
or as insecure as you
chose to allow it to be.

00:24:36.700 --> 00:24:39.661
So if you chose not to have a
password on your OpenID server,

00:24:39.661 --> 00:24:40.410
you could do that.

00:24:40.410 --> 00:24:41.910
It would just be
an open redirector,

00:24:41.910 --> 00:24:44.860
and people did that the
prove that OpenID was broken,

00:24:44.860 --> 00:24:45.762
or whatever.

00:24:45.762 --> 00:24:47.470
The problem though is
that getting people

00:24:47.470 --> 00:24:50.200
to change their behavior or
to understand the risks that

00:24:50.200 --> 00:24:51.290
are actually out
there in the world,

00:24:51.290 --> 00:24:52.740
or to make them even
stop for a moment

00:24:52.740 --> 00:24:54.490
to think that if they
pick up their device

00:24:54.490 --> 00:24:57.020
they're opening themselves up
to all sorts of vulnerabilities

00:24:57.020 --> 00:24:59.150
is something that actually
just crushes the entire world

00:24:59.150 --> 00:24:59.691
and universe.

00:24:59.691 --> 00:25:01.290
And their mind sort of melts.

00:25:01.290 --> 00:25:03.980
And as a UX designer,
it's really difficult

00:25:03.980 --> 00:25:06.820
to try to address that problem
through user education,

00:25:06.820 --> 00:25:07.510
for example.

00:25:07.510 --> 00:25:10.360
By telling them that
this is a terrible thing.

00:25:10.360 --> 00:25:13.380
So the ways in which you
may-- I'll give you some

00:25:13.380 --> 00:25:15.190
answers-- the ways in
which you may address

00:25:15.190 --> 00:25:18.890
this would be through
two-factor authentication,

00:25:18.890 --> 00:25:21.550
through behavioral tracking--
so understanding the user's

00:25:21.550 --> 00:25:25.400
behavior-- through
third party validation,

00:25:25.400 --> 00:25:26.900
or-- I had another
one but I forget.

00:25:26.900 --> 00:25:28.177
So there you go.

00:25:28.177 --> 00:25:30.010
MICHAEL COATES: There's
a lot going on here.

00:25:30.010 --> 00:25:30.300
CHRIS MESSINA: There's a lot.

00:25:30.300 --> 00:25:32.000
MICHAEL COATES:
We'll pause on that.

00:25:32.000 --> 00:25:34.701
Natasha, can mobile help?

00:25:34.701 --> 00:25:36.200
We've got this
device in our pocket.

00:25:36.200 --> 00:25:38.030
Does it help us at all here?

00:25:38.030 --> 00:25:39.497
NATASHA ROONEY: Yeah.

00:25:39.497 --> 00:25:41.830
There's a few things that are
happening within this area

00:25:41.830 --> 00:25:42.329
right now.

00:25:42.329 --> 00:25:45.030
And initially I was a little
bit skeptical about this,

00:25:45.030 --> 00:25:48.920
about moving something
from being in the cloud

00:25:48.920 --> 00:25:51.930
and being able to log
into various services

00:25:51.930 --> 00:25:54.990
wherever you are, to going
to being reliant on perhaps

00:25:54.990 --> 00:25:59.220
some hardware token or
some piece of hardware.

00:25:59.220 --> 00:26:02.419
But you're right, it's true
that many of us, or most of us,

00:26:02.419 --> 00:26:03.960
are carrying a mobile
around with us.

00:26:03.960 --> 00:26:06.720
Some people now have
watches that they

00:26:06.720 --> 00:26:09.800
are using as well
in a similar way.

00:26:09.800 --> 00:26:12.890
So there is some argument
to say that why don't we

00:26:12.890 --> 00:26:14.940
utilize those
things that allow us

00:26:14.940 --> 00:26:17.380
to log into various services?

00:26:17.380 --> 00:26:19.130
And on top of the stuff
that was happening

00:26:19.130 --> 00:26:23.370
at OpenID Connect and
the Oauth stuff in ITF,

00:26:23.370 --> 00:26:27.180
there's a lot of work going
on with another organization

00:26:27.180 --> 00:26:33.930
called the FIDO Alliance which
is using a PKI to actually do

00:26:33.930 --> 00:26:36.520
the authentication to
allow you to log in.

00:26:36.520 --> 00:26:41.510
But when you log in, you
do something on the device.

00:26:41.510 --> 00:26:43.730
So it sends a challenge
to the device.

00:26:43.730 --> 00:26:47.622
And then the device can ask
you to identify yourself

00:26:47.622 --> 00:26:48.580
through that challenge.

00:26:48.580 --> 00:26:49.690
But it could be anything.

00:26:49.690 --> 00:26:51.890
It could be a fingerprint scan.

00:26:51.890 --> 00:26:53.520
It could be a password.

00:26:53.520 --> 00:26:57.100
It could be an interpretive
dance, it doesn't matter.

00:26:57.100 --> 00:26:58.880
It could be anything.

00:26:58.880 --> 00:27:01.110
It's what that
device chooses to be

00:27:01.110 --> 00:27:02.946
and what you decide to then use.

00:27:02.946 --> 00:27:04.570
And then the PKR
would then go through,

00:27:04.570 --> 00:27:07.550
and then you're able to
log in to view the site.

00:27:07.550 --> 00:27:09.890
But Chris is right,
getting users

00:27:09.890 --> 00:27:11.610
to accept this is
very difficult.

00:27:11.610 --> 00:27:14.790
I know Mozilla had a
really great system

00:27:14.790 --> 00:27:16.130
with their Persona.

00:27:16.130 --> 00:27:19.670
And what happened to that
was really quite unfortunate.

00:27:19.670 --> 00:27:21.440
The technology was
really fantastic,

00:27:21.440 --> 00:27:23.510
but users just didn't get it.

00:27:23.510 --> 00:27:25.550
He's right, they didn't get it.

00:27:25.550 --> 00:27:28.449
And that sort of died
out because of that,

00:27:28.449 --> 00:27:29.240
and it was a shame.

00:27:29.240 --> 00:27:32.344
So maybe that's where we need
to focus our methods on is that.

00:27:32.344 --> 00:27:33.760
MIKE WEST: Do you
think thats-- do

00:27:33.760 --> 00:27:36.810
you think that's a technology
problem or a UI problem?

00:27:36.810 --> 00:27:40.550
NATASHA ROONEY: See, I think
it probably is the UI problem.

00:27:40.550 --> 00:27:42.535
But I'm not too sure
if I'd described it

00:27:42.535 --> 00:27:45.010
as UI or educational.

00:27:45.010 --> 00:27:48.180
OK, well maybe by the look on
your face it's the same thing.

00:27:48.180 --> 00:27:51.530
So it was getting
them to understand

00:27:51.530 --> 00:27:52.720
that this was still safe.

00:27:52.720 --> 00:27:55.610
I think many, many standard
users will go ahead and think,

00:27:55.610 --> 00:27:58.710
I should put in a username and
I should put in a password.

00:27:58.710 --> 00:27:59.800
That is secure.

00:27:59.800 --> 00:28:02.370
If I'm clicking something
and it's allowing me in,

00:28:02.370 --> 00:28:05.080
that's not something
I want to use.

00:28:05.080 --> 00:28:05.890
That's insecure.

00:28:05.890 --> 00:28:08.210
And then going back
to the HTTP argument,

00:28:08.210 --> 00:28:11.520
I think that most users
would ignore the bar

00:28:11.520 --> 00:28:13.744
and would ignore HTTP.

00:28:13.744 --> 00:28:15.410
And they want to see
a username and they

00:28:15.410 --> 00:28:16.370
want to see a password.

00:28:16.370 --> 00:28:18.230
And that to them
triggers secure.

00:28:18.230 --> 00:28:20.320
And they'll think that
is more secure than HTTPS

00:28:20.320 --> 00:28:23.390
in a big green bar and a
button to say just log in.

00:28:23.390 --> 00:28:25.750
That just, it just doesn't work.

00:28:25.750 --> 00:28:27.620
MIKE WEST: So would we
solve these problems

00:28:27.620 --> 00:28:31.230
if we have a magical system
that generates strong passwords

00:28:31.230 --> 00:28:33.177
for users and saves
them in some way?

00:28:33.177 --> 00:28:35.510
Like the password managers
that are built into browsers?

00:28:35.510 --> 00:28:36.180
NATASHA ROONEY: I don't know.

00:28:36.180 --> 00:28:38.540
I like password managers,
but I like password managers

00:28:38.540 --> 00:28:39.160
right now.

00:28:39.160 --> 00:28:41.650
I think it's a good
stopgap to move forward,

00:28:41.650 --> 00:28:43.160
and I think more
of the future stuff

00:28:43.160 --> 00:28:46.449
is more of this OpenID Connect,
FIDO Alliance, more PKI, more

00:28:46.449 --> 00:28:48.240
of the stuff that
Mozilla was trying to do.

00:28:48.240 --> 00:28:51.490
But that almost just came
a little bit too early.

00:28:51.490 --> 00:28:53.240
So I think we should
still push for that.

00:28:53.240 --> 00:28:55.380
But OK, so going back
to your original point,

00:28:55.380 --> 00:28:56.690
yes it's a UI thing.

00:28:56.690 --> 00:28:59.100
Maybe we just need to
make it a little bit more

00:28:59.100 --> 00:29:01.184
obvious and a little bit
more easy for those users

00:29:01.184 --> 00:29:01.766
to understand.

00:29:01.766 --> 00:29:03.990
CHRIS MESSINA: It's also a
timing and context thing.

00:29:03.990 --> 00:29:07.649
Again, the API interoperability
and integration

00:29:07.649 --> 00:29:09.440
between lots of different
apps and services

00:29:09.440 --> 00:29:12.630
was a big driver and pusher
for a lot, for example.

00:29:12.630 --> 00:29:15.880
And that previous pattern
had to be defeated.

00:29:15.880 --> 00:29:18.520
The things that are happening
now with mobile, and touch ID,

00:29:18.520 --> 00:29:20.061
and stuff like that
I think are going

00:29:20.061 --> 00:29:24.090
to train a generation of users
to not only hate passwords,

00:29:24.090 --> 00:29:26.437
but to not want to
type ever, ever again.

00:29:26.437 --> 00:29:28.020
And they'll only
talk to their device,

00:29:28.020 --> 00:29:29.940
like in "Star
Trek" or something.

00:29:29.940 --> 00:29:32.430
And if you're speaking your
plain text password, which

00:29:32.430 --> 00:29:34.499
is no more plain
text as plain speech,

00:29:34.499 --> 00:29:35.790
that doesn't make sense either.

00:29:35.790 --> 00:29:37.840
So we have to migrate to
where users are going.

00:29:37.840 --> 00:29:41.330
We've in some ways lived in
the future about our security

00:29:41.330 --> 00:29:45.590
awareness for a long time,
using stone age tools

00:29:45.590 --> 00:29:47.004
to authenticate ourselves.

00:29:47.004 --> 00:29:48.420
But I think as
devices get better,

00:29:48.420 --> 00:29:50.770
and they become more ubiquitous,
and users' expectations

00:29:50.770 --> 00:29:53.130
change on how they actually
interact with the devices, that

00:29:53.130 --> 00:29:55.546
creates this opportunity to
actually implement things that

00:29:55.546 --> 00:29:58.060
were relevant 10 years ago now.

00:29:58.060 --> 00:30:00.047
It's just that it
hasn't lined up yet.

00:30:00.047 --> 00:30:02.630
MICHAEL COATES: If you look at
the adoption of the fingerprint

00:30:02.630 --> 00:30:05.245
scanners on iPhones, is
that the direction forward?

00:30:05.245 --> 00:30:07.120
The user doesn't have
to think about anything

00:30:07.120 --> 00:30:08.130
but just touch this.

00:30:08.130 --> 00:30:10.970
And perhaps that's tied
into a password manager.

00:30:10.970 --> 00:30:12.387
Is this the direction
we're going?

00:30:12.387 --> 00:30:14.261
MARK NOTTINGHAM: Well
that's tied into Apple.

00:30:14.261 --> 00:30:16.120
I mean, you're owned
by Apple there.

00:30:16.120 --> 00:30:18.120
CHRIS MESSINA: Will just
evaluate the UX though.

00:30:18.120 --> 00:30:19.390
MARK NOTTINGHAM: Sure.

00:30:19.390 --> 00:30:21.730
But I think becoming
successful because it's Apple.

00:30:21.730 --> 00:30:23.688
CHRIS MESSINA: What's
also interesting about it

00:30:23.688 --> 00:30:26.264
though is that it creates a
type of-- it's interesting.

00:30:26.264 --> 00:30:27.680
There's a behavioral
element to it

00:30:27.680 --> 00:30:29.410
where you can actually have
multiple fingerprints that

00:30:29.410 --> 00:30:30.750
are authenticated to a device.

00:30:30.750 --> 00:30:33.419
So for example, if I have
kids, or if I have a spouse,

00:30:33.419 --> 00:30:35.710
or whatever, and I want them
to be able to authenticate

00:30:35.710 --> 00:30:37.634
purchases, I don't have
to share a password.

00:30:37.634 --> 00:30:39.550
MARK NOTTINGHAM: Wait,
is that with the iOS 8?

00:30:39.550 --> 00:30:40.690
CHRIS MESSINA: Well, so
there's family sharing, which

00:30:40.690 --> 00:30:42.050
is actually addressing the--

00:30:42.050 --> 00:30:42.770
YAN ZHU: MARK NOTTINGHAM:
Because you just

00:30:42.770 --> 00:30:44.390
sold me a new iPhone
if that's the case.

00:30:44.390 --> 00:30:44.640
CHRIS MESSINA: Yeah.

00:30:44.640 --> 00:30:46.140
So the family
sharing thing will be

00:30:46.140 --> 00:30:47.931
interesting to see how
that actually works,

00:30:47.931 --> 00:30:49.360
in terms of shared
authentication.

00:30:49.360 --> 00:30:52.010
But you could actually
add multiple fingers,

00:30:52.010 --> 00:30:53.640
which you didn't have to own.

00:30:53.640 --> 00:30:56.580
So I could have had your
finger and my finger.

00:30:56.580 --> 00:30:58.160
I'm just saying,
all of a sudden we

00:30:58.160 --> 00:30:59.701
have a very interesting
touch device.

00:30:59.701 --> 00:31:02.490
But the point is, it allows
for a different way of managing

00:31:02.490 --> 00:31:04.780
passwords which people do.

00:31:04.780 --> 00:31:06.490
People share their
Amazon passwords.

00:31:06.490 --> 00:31:09.214
One of the biggest things that
I've noticed about-- oh, I

00:31:09.214 --> 00:31:11.130
saw this in the reviews
for "Find My Friends."

00:31:11.130 --> 00:31:12.910
If you guys go to the
app store, check it out.

00:31:12.910 --> 00:31:14.326
There's a lot of
one star reviews,

00:31:14.326 --> 00:31:16.970
because people would say that
actually I allowed my spouse

00:31:16.970 --> 00:31:19.710
to log in under my account
using the same password,

00:31:19.710 --> 00:31:21.210
and you've removed that feature.

00:31:21.210 --> 00:31:23.920
So the sharing of a password
is removing a feature.

00:31:23.920 --> 00:31:26.460
And so if you have to do
two-factor authentication,

00:31:26.460 --> 00:31:28.043
you've actually
disabled functionality

00:31:28.043 --> 00:31:28.970
that people rely on.

00:31:28.970 --> 00:31:30.630
There's a greater context
here that I think needs.

00:31:30.630 --> 00:31:33.046
MICHAEL COATES: Let's get an
audience member lined up too.

00:31:34.751 --> 00:31:36.250
NATASHA ROONEY:
That spans the point

00:31:36.250 --> 00:31:40.720
about having multiple
assurance levels, almost.

00:31:40.720 --> 00:31:44.460
So you say, logging
into my phone

00:31:44.460 --> 00:31:47.040
might be-- I have
password protected

00:31:47.040 --> 00:31:51.060
a lot of the more insecure
applications on my phone.

00:31:51.060 --> 00:31:52.519
So I just want to
log into my phone

00:31:52.519 --> 00:31:53.935
really quickly
because I just want

00:31:53.935 --> 00:31:55.540
to tell when I need
to turn left next,

00:31:55.540 --> 00:31:58.651
or turn right, or check a
text message, or whatever.

00:31:58.651 --> 00:32:01.150
But there's going to be other
things like looking at my bank

00:32:01.150 --> 00:32:03.230
account which I want to
be very, very secure.

00:32:03.230 --> 00:32:05.720
And in which case, then those
different assurance levels

00:32:05.720 --> 00:32:06.621
need to come in.

00:32:06.621 --> 00:32:07.870
And there needs to be methods.

00:32:07.870 --> 00:32:10.944
And people are looking at
methods there to focus on that.

00:32:10.944 --> 00:32:13.110
And it's not just about
multiple different passwords

00:32:13.110 --> 00:32:15.756
or copying out the number
on the front of your card,

00:32:15.756 --> 00:32:17.130
but having those
different levels

00:32:17.130 --> 00:32:19.630
and different types with
different resources.

00:32:19.630 --> 00:32:20.540
MICHAEL COATES: Ada?

00:32:20.540 --> 00:32:23.310
Perfect, what have
you got for us?

00:32:23.310 --> 00:32:25.490
AUDIENCE: You can assume
that your password is

00:32:25.490 --> 00:32:31.050
available from a database you
can purchase online matched

00:32:31.050 --> 00:32:34.480
to your favorite
usernames and emails.

00:32:34.480 --> 00:32:37.500
So is it even useful
to use a password

00:32:37.500 --> 00:32:40.810
in a world in which you can
use two-factor authentication?

00:32:44.769 --> 00:32:45.560
CHRIS MESSINA: Yes.

00:32:45.560 --> 00:32:47.849
I mean, part of it
again is cost, right?

00:32:47.849 --> 00:32:49.390
So if you're building
an application,

00:32:49.390 --> 00:32:51.120
or if you're building
a stupid-- I'm not

00:32:51.120 --> 00:32:54.470
going to name any names--
iOS app, for example,

00:32:54.470 --> 00:32:56.470
and you just want to get
something out the door.

00:32:56.470 --> 00:32:57.940
Security is not a big deal.

00:32:57.940 --> 00:33:00.290
You basically want
to avoid someone else

00:33:00.290 --> 00:33:02.457
taking a selfie on
your behalf, right?

00:33:02.457 --> 00:33:03.915
You don't necessarily
need to throw

00:33:03.915 --> 00:33:06.456
in two-factor authentication
and put that huge speed bump in.

00:33:06.456 --> 00:33:10.711
You're going to have such
a grade of loss of signups.

00:33:10.711 --> 00:33:12.460
Even where it's like,
connect with Twitter

00:33:12.460 --> 00:33:15.230
to log in or whatever, that
extra speed bump actually

00:33:15.230 --> 00:33:16.520
inhibits adoption a lot.

00:33:16.520 --> 00:33:18.688
So again from a cost
benefit analysis,

00:33:18.688 --> 00:33:20.896
I think you have to look at
it from that perspective.

00:33:20.896 --> 00:33:21.800
MICHAEL COATES: We've
got a lot interest.

00:33:21.800 --> 00:33:24.890
I'm going to take on another
topic here before we move on.

00:33:24.890 --> 00:33:25.611
Guy, over there.

00:33:25.611 --> 00:33:27.360
AUDIENCE: I just want
to talk a little bit

00:33:27.360 --> 00:33:28.720
about continuous authentication.

00:33:28.720 --> 00:33:31.119
So we've named a lot of
things, and all the wearables,

00:33:31.119 --> 00:33:33.410
and those components, still
everything you talked about

00:33:33.410 --> 00:33:35.170
was around prompted
authentication

00:33:35.170 --> 00:33:37.080
where somebody logs in.

00:33:37.080 --> 00:33:40.240
Granted, it's easier to put
your finger to something

00:33:40.240 --> 00:33:41.780
than type in a
password or voice it.

00:33:41.780 --> 00:33:45.390
But still, do we need something
that constantly tracks us--

00:33:45.390 --> 00:33:48.710
not in the privacy sense of
the word, but rather locally

00:33:48.710 --> 00:33:49.474
and authenticates.

00:33:49.474 --> 00:33:50.890
CHRIS MESSINA: I
mean, absolutely.

00:33:50.890 --> 00:33:53.466
And the difference is,
who is doing the tracking?

00:33:53.466 --> 00:33:55.590
AUDIENCE: This is not
necessarily communicated out.

00:33:55.590 --> 00:33:57.230
I mean, this is
just something local

00:33:57.230 --> 00:34:00.930
that takes a biometric
indicator or some other form.

00:34:00.930 --> 00:34:03.600
Maybe it's the presence of
a device or whatever it is.

00:34:03.600 --> 00:34:05.350
But it's a little
bit more continuous.

00:34:05.350 --> 00:34:08.480
So as I take the right turn,
I don't need to be stopped.

00:34:08.480 --> 00:34:11.587
I think eventually the user's
goal is not to be secure.

00:34:11.587 --> 00:34:14.170
It's to complete whatever it is
the action that they're doing.

00:34:14.170 --> 00:34:16.211
So we need security to be
as seamless as possible

00:34:16.211 --> 00:34:17.715
as a part of that.

00:34:17.715 --> 00:34:19.090
And that may imply
something that

00:34:19.090 --> 00:34:20.519
doesn't require prompting them.

00:34:20.519 --> 00:34:22.260
MARK NOTTINGHAM: The credit
card companies already do this.

00:34:22.260 --> 00:34:24.389
They track where you
are to figure out

00:34:24.389 --> 00:34:26.560
what credit card
purchases make sense.

00:34:26.560 --> 00:34:30.970
I was in Istanbul two weeks
ago, and somebody's credit card

00:34:30.970 --> 00:34:31.639
didn't work.

00:34:31.639 --> 00:34:33.180
And so they went
and called the bank,

00:34:33.180 --> 00:34:35.560
and the bank said, oh yeah,
we can see you're in Istanbul

00:34:35.560 --> 00:34:37.479
and you're leaving on
such and such date.

00:34:37.479 --> 00:34:39.270
And the thing is, they
hadn't told the bank

00:34:39.270 --> 00:34:41.340
that they were going
to make that trip.

00:34:41.340 --> 00:34:44.170
The airline company shared
the ticket data with the bank

00:34:44.170 --> 00:34:45.370
automatically.

00:34:45.370 --> 00:34:46.830
And it wasn't opt in.

00:34:46.830 --> 00:34:48.110
And so that's like--

00:34:48.110 --> 00:34:48.650
CHRIS MESSINA: Oh I'm
sure there was an opt in.

00:34:48.650 --> 00:34:49.590
You just check the box.

00:34:49.590 --> 00:34:51.250
MARK NOTTINGHAM: Oh yeah,
there's a box way down deep

00:34:51.250 --> 00:34:52.194
or there's an opt out.

00:34:52.194 --> 00:34:53.610
But they didn't
remember doing it.

00:34:53.610 --> 00:34:54.320
CHRIS MESSINA: The
terms were in there.

00:34:54.320 --> 00:34:57.334
MARK NOTTINGHAM: Right, in
that 14,000 pages of text.

00:34:57.334 --> 00:34:59.000
And so that's a really
interesting world

00:34:59.000 --> 00:35:01.670
to live in, because the
European people I was with

00:35:01.670 --> 00:35:02.420
were freaking out.

00:35:02.420 --> 00:35:04.010
They were like, that's illegal.

00:35:04.010 --> 00:35:04.830
I was freaking out.

00:35:04.830 --> 00:35:06.590
I live in Australia,
that's illegal.

00:35:06.590 --> 00:35:09.270
But in the US, hey
that's convenient.

00:35:09.270 --> 00:35:09.860
That's OK.

00:35:13.480 --> 00:35:15.480
MICHAEL COATES: Well,
we've got a lot of topics,

00:35:15.480 --> 00:35:17.000
a lot of interest on
this one but we're

00:35:17.000 --> 00:35:18.350
going to keep charging forward.

00:35:18.350 --> 00:35:20.620
I'm not surprised
that there's plenty

00:35:20.620 --> 00:35:22.132
of opinions on passwords.

00:35:22.132 --> 00:35:24.340
And some of the things I've
heard so far though is we

00:35:24.340 --> 00:35:26.200
really have to work
on usability and make

00:35:26.200 --> 00:35:28.640
it seamless and appropriate.

00:35:28.640 --> 00:35:30.830
Easy when it needs
to be and even more

00:35:30.830 --> 00:35:32.940
robust when it needs to be.

00:35:32.940 --> 00:35:37.260
Moving on, our third question
comes from Ben Vinegar.

00:35:37.260 --> 00:35:40.800
Google Now uses HTTPS
as a ranking signal

00:35:40.800 --> 00:35:43.720
and Server Worker is HTTPS only.

00:35:43.720 --> 00:35:46.670
Both are likely to
increase HTTPS adoption.

00:35:46.670 --> 00:35:48.750
Are there other
security-minded features

00:35:48.750 --> 00:35:50.954
that should incentivized
in this manner?

00:35:50.954 --> 00:35:52.870
And so it feels like as
we take this question,

00:35:52.870 --> 00:35:56.400
we're shifting slightly
away from the security

00:35:56.400 --> 00:35:59.140
that only users face,
like passwords, but more

00:35:59.140 --> 00:36:01.080
to what should our
applications and websites

00:36:01.080 --> 00:36:03.390
be doing automatically?

00:36:03.390 --> 00:36:05.210
Because the sad
reality is, they're

00:36:05.210 --> 00:36:07.947
doing just as much as they need
to, and maybe not even that.

00:36:07.947 --> 00:36:09.530
But this seems like
an incentive model

00:36:09.530 --> 00:36:12.080
that may make them want
to do more for security.

00:36:15.174 --> 00:36:15.840
MIKE WEST: Sure.

00:36:15.840 --> 00:36:19.960
I think it's a really
interesting idea by the search

00:36:19.960 --> 00:36:23.330
team to start promoting
in a small way HTTPS.

00:36:23.330 --> 00:36:26.170
I think that there are search
related reasons that they

00:36:26.170 --> 00:36:29.150
do this, because you need to
ensure that the content you're

00:36:29.150 --> 00:36:32.120
delivering to the user is
actually the content that you

00:36:32.120 --> 00:36:33.920
expect to be
delivered to the user.

00:36:33.920 --> 00:36:37.210
So it HTTPS gives you
some sort of verification

00:36:37.210 --> 00:36:39.610
that you are in fact
talking to cnn.com

00:36:39.610 --> 00:36:43.080
and you're not talking to the
NSA who's injecting stories

00:36:43.080 --> 00:36:45.752
about how awesome the NSA is
onto the front page of cnn.com.

00:36:45.752 --> 00:36:47.210
CHRIS MESSINA: To
make you happier.

00:36:47.210 --> 00:36:48.876
MIKE WEST: To make
you happier, exactly.

00:36:48.876 --> 00:36:52.640
So I think that there are
search quality related reasons

00:36:52.640 --> 00:36:55.220
to do this particular action.

00:36:55.220 --> 00:36:57.560
I don't think it's only
about promoting HTTPS.

00:36:57.560 --> 00:36:59.240
I think that there
are other reasons.

00:36:59.240 --> 00:37:01.480
So I think that for search
engines in particular,

00:37:01.480 --> 00:37:04.470
you would have to find other
quality related reasons

00:37:04.470 --> 00:37:06.114
that you would promote.

00:37:06.114 --> 00:37:07.780
And one of those might
be mixed content.

00:37:07.780 --> 00:37:09.620
So if you have mixed
content on the page,

00:37:09.620 --> 00:37:14.112
then you are in fact degrading
the quality of the HTTPS

00:37:14.112 --> 00:37:16.320
encryption, because you're
loading insecure resources

00:37:16.320 --> 00:37:17.236
into a secure context.

00:37:17.236 --> 00:37:20.080
So perhaps we could
start looking at that.

00:37:20.080 --> 00:37:21.210
HSTS would be nice.

00:37:21.210 --> 00:37:23.730
Because then you can ensure
that there's-- Strict Transport

00:37:23.730 --> 00:37:26.550
Security means that you can't
execute a downgrade attack.

00:37:26.550 --> 00:37:30.360
You can't force someone onto
HTTP from an HTTPS website.

00:37:30.360 --> 00:37:33.030
You say, this website
should always be HTTPS.

00:37:33.030 --> 00:37:34.880
That gives a pretty
solid guarantee

00:37:34.880 --> 00:37:36.815
that you are in fact
talking to the server

00:37:36.815 --> 00:37:38.190
that you expect
to be talking to.

00:37:38.190 --> 00:37:39.648
So these sorts of
things are things

00:37:39.648 --> 00:37:42.290
that would be nice to
promote in some way.

00:37:42.290 --> 00:37:44.170
MARK NOTTINGHAM: And
on the standard side,

00:37:44.170 --> 00:37:46.320
there's more and
more capabilities

00:37:46.320 --> 00:37:49.120
that people are talking about
making HTTPS only or preferring

00:37:49.120 --> 00:37:50.260
HTTPS.

00:37:50.260 --> 00:37:53.256
And I think a lot of
that's because Google

00:37:53.256 --> 00:37:55.670
or the Chrome team recently
brought up that policy which

00:37:55.670 --> 00:37:57.590
was proposing amongst
other browsers

00:37:57.590 --> 00:38:01.750
that powerful new facilities
are by default secure or only

00:38:01.750 --> 00:38:03.070
secure.

00:38:03.070 --> 00:38:05.270
And I think that's
because there's

00:38:05.270 --> 00:38:07.880
a lot of subtlety to security,
where people say oh, I

00:38:07.880 --> 00:38:10.415
don't need HTTPS for that
because I'm doing this, and not

00:38:10.415 --> 00:38:12.790
realizing that there are lots
of other very subtle attack

00:38:12.790 --> 00:38:13.510
vectors.

00:38:13.510 --> 00:38:15.140
Or it might be the
user themselves

00:38:15.140 --> 00:38:17.020
that wants the security
rather than the site

00:38:17.020 --> 00:38:19.519
and its content
wanting the security.

00:38:19.519 --> 00:38:21.560
The use case that comes
up in the ITF-- and there

00:38:21.560 --> 00:38:23.580
was actually a draft
about this as well--

00:38:23.580 --> 00:38:24.730
imagine the search engine.

00:38:24.730 --> 00:38:27.520
And that's public data
that you're getting.

00:38:27.520 --> 00:38:30.220
So it doesn't have
the inherent issues

00:38:30.220 --> 00:38:31.730
around the data you're getting.

00:38:31.730 --> 00:38:34.560
But if you're a gay
teenager in Nigeria,

00:38:34.560 --> 00:38:38.460
and you're searching about being
gay, and or AIDS or whatever,

00:38:38.460 --> 00:38:39.810
that can get you killed.

00:38:39.810 --> 00:38:42.590
And so security really does
matter there for reasons

00:38:42.590 --> 00:38:45.490
that the service provider
might not anticipate.

00:38:45.490 --> 00:38:47.740
MICHAEL COATES: Why don't
we jump out to the audience?

00:38:47.740 --> 00:38:50.750
We have Mark?

00:38:50.750 --> 00:38:54.080
AUDIENCE: I was wondering,
is the obsession with web

00:38:54.080 --> 00:38:57.190
performance setting
back security practices?

00:38:57.190 --> 00:39:01.150
And are there rampant
misconceptions about the trade

00:39:01.150 --> 00:39:02.650
off between security
and performance

00:39:02.650 --> 00:39:05.905
that you feel need
to be corrected?

00:39:05.905 --> 00:39:08.155
MIKE WEST: So Illy [? is ?]
in the audience somewhere.

00:39:08.155 --> 00:39:09.060
MARK NOTTINGHAM: Yeah,
if [? Illy ?] is here,

00:39:09.060 --> 00:39:09.990
just give him the mic.

00:39:12.857 --> 00:39:14.690
MIKE WEST: So anyway,
he has a great website

00:39:14.690 --> 00:39:16.030
called istlsfast.com?

00:39:16.030 --> 00:39:17.830
AUDIENCE: [INAUDIBLE].

00:39:17.830 --> 00:39:19.300
MIKE WEST: Is TLS fast yet.

00:39:19.300 --> 00:39:21.150
I'm sorry, istlsfastyet.com.

00:39:21.150 --> 00:39:24.520
And that answers
some of the questions

00:39:24.520 --> 00:39:28.386
around the speed impact of TLS.

00:39:28.386 --> 00:39:30.760
And I think that [? Illy's ?]
got a really great resource

00:39:30.760 --> 00:39:32.940
there, so I would highly
recommend that you read it.

00:39:32.940 --> 00:39:33.920
MARK NOTTINGHAM: It answers
all the questions, pretty much.

00:39:33.920 --> 00:39:35.260
NATASHA ROONEY: There's some
work going on in this area

00:39:35.260 --> 00:39:35.780
though.

00:39:35.780 --> 00:39:37.380
MARK NOTTINGHAM:
There's TLS 1.3,

00:39:37.380 --> 00:39:39.230
and that's trying to get down
to zero round trip or one round

00:39:39.230 --> 00:39:40.030
trip.

00:39:40.030 --> 00:39:41.238
NATASHA ROONEY: And FastOpen.

00:39:41.238 --> 00:39:43.252
MARK NOTTINGHAM:
Well that's TLS 1.3.

00:39:43.252 --> 00:39:45.460
MIKE WEST: And there's
experimentation with protocols

00:39:45.460 --> 00:39:45.720
as well.

00:39:45.720 --> 00:39:47.261
So if you look at
Quick, they're also

00:39:47.261 --> 00:39:49.159
trying to do zero round trip.

00:39:49.159 --> 00:39:50.700
And that's based on
a different thing

00:39:50.700 --> 00:39:52.980
that I don't remember that was
also doing something similar.

00:39:52.980 --> 00:39:53.490
MARK NOTTINGHAM:
There's a lot of talk

00:39:53.490 --> 00:39:55.240
about UDP based HTTP in general.

00:39:55.240 --> 00:39:58.440
And that's again about
performance while

00:39:58.440 --> 00:39:59.655
not trading off security.

00:39:59.655 --> 00:40:02.071
NATASHA ROONEY: There were
some use cases though mentioned

00:40:02.071 --> 00:40:06.990
in HTTP [INAUDIBLE] about
there being some slow-- well,

00:40:06.990 --> 00:40:09.194
for people that
perhaps use satellite

00:40:09.194 --> 00:40:10.110
connections and stuff.

00:40:10.110 --> 00:40:13.351
And that causes a massive issue,
the current situation with TLS.

00:40:13.351 --> 00:40:14.850
MARK NOTTINGHAM:
There are certainly

00:40:14.850 --> 00:40:18.100
some unusual
deployment scenarios.

00:40:18.100 --> 00:40:20.680
That's more about
those people wanting

00:40:20.680 --> 00:40:22.990
to get inside and do
optimizations on the data

00:40:22.990 --> 00:40:24.430
and not being able
to do that when

00:40:24.430 --> 00:40:25.700
there's encryption present.

00:40:25.700 --> 00:40:29.177
And that opens a whole other
can of worms about security

00:40:29.177 --> 00:40:30.760
and the relationships
happening there.

00:40:30.760 --> 00:40:33.009
MICHAEL COATES: It's certainly
an interesting question

00:40:33.009 --> 00:40:35.990
is that tying it back to
the incentivizing HTTPS.

00:40:35.990 --> 00:40:38.330
If we incentivize
security, we have

00:40:38.330 --> 00:40:40.529
to overcome the perceptions
of those challenges.

00:40:40.529 --> 00:40:42.320
CHRIS MESSINA: And
realities in some cases.

00:40:42.320 --> 00:40:43.945
MICHAEL COATES: And
realities, exactly.

00:40:43.945 --> 00:40:46.580
MARK NOTTINGHAM: And I
think we're working on it.

00:40:46.580 --> 00:40:47.496
MICHAEL COATES: Jonas.

00:40:49.817 --> 00:40:50.650
There comes the mic.

00:40:53.670 --> 00:40:57.530
AUDIENCE: HTML also has some
weird, old anti-features,

00:40:57.530 --> 00:41:02.720
where back in the day HTTPS was
considered the bank websites

00:41:02.720 --> 00:41:03.370
technology.

00:41:03.370 --> 00:41:07.120
And so it turns off
things like referrers

00:41:07.120 --> 00:41:10.520
and does various
other things that I

00:41:10.520 --> 00:41:12.930
don't know off the
top of my head.

00:41:12.930 --> 00:41:15.290
There is work to fix
some of these things.

00:41:15.290 --> 00:41:17.390
So there's a
meta-referrer spec now

00:41:17.390 --> 00:41:19.900
where you say that
even though I'm HTTPS,

00:41:19.900 --> 00:41:21.550
I'm actually just
a normal website.

00:41:21.550 --> 00:41:24.470
Please send referral links.

00:41:24.470 --> 00:41:27.300
But I suspect there's
more work like that

00:41:27.300 --> 00:41:29.290
that needs to be done as well.

00:41:29.290 --> 00:41:30.790
MARK NOTTINGHAM:
Yeah, there's a lot

00:41:30.790 --> 00:41:32.623
of different parts of
the web security model

00:41:32.623 --> 00:41:35.522
that hang off of that decision
to have that little S there.

00:41:35.522 --> 00:41:37.730
And yeah, I agree it would
be nice to pick that apart

00:41:37.730 --> 00:41:40.501
a little bit where
it's appropriate.

00:41:40.501 --> 00:41:43.000
MICHAEL COATES: Let's see, we
have one more person up there.

00:41:43.000 --> 00:41:46.831
Patrick, there we are,
up here in the front.

00:41:46.831 --> 00:41:48.292
There we go.

00:41:52.176 --> 00:41:53.800
AUDIENCE: Natasha
mentioned earlier one

00:41:53.800 --> 00:41:56.290
of the issues with
Persona failing

00:41:56.290 --> 00:42:00.104
was users inherently not
thinking it was secure

00:42:00.104 --> 00:42:01.770
because you weren't
entering a password.

00:42:01.770 --> 00:42:04.760
So I was wondering, how much
does security theater come

00:42:04.760 --> 00:42:07.980
into play when designing secure
interfaces and making things

00:42:07.980 --> 00:42:12.110
think they're secure as
opposed to being secure.

00:42:12.110 --> 00:42:14.360
SPEAKER 1: UX as security
theater, I guess?

00:42:14.360 --> 00:42:15.660
MALE SPEAKER 2: Yeah.

00:42:15.660 --> 00:42:20.040
We do our best to, in
browsers, promote the things

00:42:20.040 --> 00:42:24.290
that we know to be secure,
and promote the things that

00:42:24.290 --> 00:42:25.900
help us make things more secure.

00:42:25.900 --> 00:42:28.850
So there is absolutely security
theater in the browser,

00:42:28.850 --> 00:42:31.100
like the EB certificates
that we talked about earlier.

00:42:31.100 --> 00:42:32.680
They are completely
the same encryption

00:42:32.680 --> 00:42:34.429
as normal certificates,
but they're green.

00:42:34.429 --> 00:42:36.310
So they must be better, right?

00:42:36.310 --> 00:42:38.110
That sort of thing
is good because it

00:42:38.110 --> 00:42:39.620
helps us do things like CT.

00:42:39.620 --> 00:42:42.980
It helps us work better with
certificate authorities.

00:42:42.980 --> 00:42:46.830
So doing those sorts of things
as kind of harmless security

00:42:46.830 --> 00:42:48.810
theater is kind of OK.

00:42:48.810 --> 00:42:51.330
But generally speaking, we
want to build interfaces

00:42:51.330 --> 00:42:53.370
that promote the things
that are actually secure

00:42:53.370 --> 00:42:56.010
and make the guarantees that
we know we can actually make.

00:42:56.010 --> 00:42:58.620
So I hope that we
don't do things

00:42:58.620 --> 00:43:00.560
that are strictly
security theater.

00:43:00.560 --> 00:43:04.470
But I definitely think that we
need to think about the ways

00:43:04.470 --> 00:43:06.140
that users interact
with web pages

00:43:06.140 --> 00:43:08.570
and interact with the
user agent in order

00:43:08.570 --> 00:43:11.760
to ensure that the
behaviors that we promote

00:43:11.760 --> 00:43:14.217
are in fact the ones we
want to promotes, and not

00:43:14.217 --> 00:43:15.470
the alternative.

00:43:15.470 --> 00:43:16.890
SPEAKER 3: Part
of the problem is

00:43:16.890 --> 00:43:19.600
there's a huge generation
of people that have grown up

00:43:19.600 --> 00:43:22.376
expecting username and password,
password being concealed,

00:43:22.376 --> 00:43:24.750
as being the way to understand
that something is actually

00:43:24.750 --> 00:43:25.440
safe.

00:43:25.440 --> 00:43:28.140
So for example, one of
experiments that we did back

00:43:28.140 --> 00:43:29.820
in the OpenID
days-- because you'd

00:43:29.820 --> 00:43:32.810
just type in the URL and that
[INAUDIBLE] authenticate.

00:43:32.810 --> 00:43:34.530
But you could type
in an email address,

00:43:34.530 --> 00:43:36.334
and there'd be a
password box beneath it.

00:43:36.334 --> 00:43:38.250
And of course, we would
drop off the username.

00:43:38.250 --> 00:43:39.730
And we'd drop off the
password, and we'd just sort of

00:43:39.730 --> 00:43:41.700
ignore those things and
drop them on the floor,

00:43:41.700 --> 00:43:44.250
and send you over to
the URL that you'd

00:43:44.250 --> 00:43:45.580
typed in as your email address.

00:43:45.580 --> 00:43:47.038
It was somewhat
confusing to users,

00:43:47.038 --> 00:43:50.020
but that meant that
those services that

00:43:50.020 --> 00:43:51.840
were willing to
participate in that

00:43:51.840 --> 00:43:54.340
were actually preserving
a little more of the user

00:43:54.340 --> 00:43:56.780
security by not creating
another surface area for them

00:43:56.780 --> 00:43:59.400
to be exposed in entering
the same password again.

00:43:59.400 --> 00:44:01.950
So it's not perfect,
but in some ways,

00:44:01.950 --> 00:44:04.410
tricking people into
being more secure,

00:44:04.410 --> 00:44:06.774
if it actually converts better,
is a better thing to do.

00:44:06.774 --> 00:44:09.440
MALE SPEAKER 4: Well, I'll pause
on that, because we're actually

00:44:09.440 --> 00:44:12.142
going to get into it even more
in this very next question.

00:44:12.142 --> 00:44:12.850
SPEAKER 3: Great.

00:44:12.850 --> 00:44:15.016
MALE SPEAKER 4: But it
sounds like there's consensus

00:44:15.016 --> 00:44:17.440
that incentivizing security
is really pretty good.

00:44:17.440 --> 00:44:19.040
I didn't hear any
objections at all.

00:44:19.040 --> 00:44:21.470
SPEAKER 1: I think it's
really hard on mobile,

00:44:21.470 --> 00:44:24.807
like UX on mobile
is not there yet.

00:44:24.807 --> 00:44:26.390
SPEAKER 3: Efficiency
is so important.

00:44:26.390 --> 00:44:27.056
SPEAKER 1: Yeah.

00:44:27.056 --> 00:44:28.510
MALE SPEAKER 4: OK.

00:44:28.510 --> 00:44:30.990
Good, so in terms of
the original question,

00:44:30.990 --> 00:44:32.830
other features, it
sounds like mixed content

00:44:32.830 --> 00:44:34.890
might be a next one to
start charging down.

00:44:34.890 --> 00:44:36.900
If we're going to incentivize
SSL, let's take it

00:44:36.900 --> 00:44:39.400
to the next degree and make
sure it's a good SSL connection.

00:44:39.400 --> 00:44:41.960
MALE SPEAKER 2: Yeah, note that
I an not on the search team,

00:44:41.960 --> 00:44:42.744
for clarity.

00:44:42.744 --> 00:44:43.660
MALE SPEAKER 4: Great.

00:44:43.660 --> 00:44:46.370
So I'm going to move onto
our next question brought

00:44:46.370 --> 00:44:47.710
to us by Matt Andrews.

00:44:47.710 --> 00:44:50.400
"What signals should
the browser communicate

00:44:50.400 --> 00:44:52.030
to users regarding
their security,"

00:44:52.030 --> 00:44:55.920
so no doubt diving into UX
security theater or not.

00:44:55.920 --> 00:44:57.860
"For example,
should we warn users

00:44:57.860 --> 00:45:01.060
about personal
information submissions?

00:45:01.060 --> 00:45:03.240
Should imperfect HTTPS
be flagged differently

00:45:03.240 --> 00:45:05.650
than plain HTTP?

00:45:05.650 --> 00:45:08.930
What would a non-techie
user respond to?"

00:45:08.930 --> 00:45:11.989
And Yan, I think with your
work on HTTPS Everywhere

00:45:11.989 --> 00:45:14.530
and some of those items, this
might be very relevant for you.

00:45:14.530 --> 00:45:16.696
YAN: Yeah, well, I think
the answer to this question

00:45:16.696 --> 00:45:19.680
is hugely different, depending
on whether the user is

00:45:19.680 --> 00:45:23.630
someone technical who knows what
mixed content is versus someone

00:45:23.630 --> 00:45:26.770
who barely knows what the
Lock icon means, right?

00:45:26.770 --> 00:45:30.370
There's only so many
icons you can put there

00:45:30.370 --> 00:45:32.350
before people just
say like, I don't

00:45:32.350 --> 00:45:34.350
understand what this icon means.

00:45:34.350 --> 00:45:36.670
I'm going to ignore
the square entirely.

00:45:36.670 --> 00:45:39.430
So my theory is we've already
saturated at that point,

00:45:39.430 --> 00:45:41.450
and we can't really
add any more icons.

00:45:41.450 --> 00:45:42.575
SPEAKER 3: Peak disclosure.

00:45:42.575 --> 00:45:45.510
YAN: Yeah, I don't
know what else.

00:45:45.510 --> 00:45:49.640
So one thing I did work on at
EFF that's tangentially related

00:45:49.640 --> 00:45:52.780
is displaying to people
when third parties

00:45:52.780 --> 00:45:54.010
are tracking them.

00:45:54.010 --> 00:45:56.660
So yeah, this is also
a security feature,

00:45:56.660 --> 00:45:58.140
not in the same way as HTTPS.

00:45:58.140 --> 00:45:59.640
But if you think
about how much data

00:45:59.640 --> 00:46:02.540
you're leaking to third
parties, in often cases,

00:46:02.540 --> 00:46:05.140
that's a security risk.

00:46:05.140 --> 00:46:07.330
And it turns out
people do really

00:46:07.330 --> 00:46:10.550
like seeing what third
parties are tracking them.

00:46:10.550 --> 00:46:14.340
And I think Mozilla has done
some work with a project called

00:46:14.340 --> 00:46:17.750
Lightbeam to help people
see what the connections are

00:46:17.750 --> 00:46:20.000
between the various first
party sites they're visiting

00:46:20.000 --> 00:46:22.132
and the third party sites.

00:46:22.132 --> 00:46:23.813
So that's a cool
space to move in.

00:46:23.813 --> 00:46:25.271
FEMALE SPEAKER:
Yeah, that can also

00:46:25.271 --> 00:46:28.631
be tackled regulatory-- I know
this is a technical conference.

00:46:28.631 --> 00:46:30.630
So I'll just spend a
little bit of time on that.

00:46:30.630 --> 00:46:33.520
At least in Japan,
it's a guideline.

00:46:33.520 --> 00:46:35.490
It's not actually law,
but there's a guideline

00:46:35.490 --> 00:46:38.850
to say that any application
that takes any personal data

00:46:38.850 --> 00:46:40.680
or basically uses
any permissions

00:46:40.680 --> 00:46:45.740
needs to state to the user,
before they download it,

00:46:45.740 --> 00:46:48.270
what permission is being
taken, what data's being taken,

00:46:48.270 --> 00:46:50.990
who that data then gets
sent to, and roughly

00:46:50.990 --> 00:46:52.980
what that data is
going to be used for.

00:46:52.980 --> 00:46:55.249
So there is some regulation
going on in that area.

00:46:55.249 --> 00:46:57.290
It would be better if it
was tackled technically.

00:46:57.290 --> 00:47:00.180
But that's an interesting
case from a different country.

00:47:00.180 --> 00:47:02.710
SPEAKER 3: I mean, that's
sort of the tension

00:47:02.710 --> 00:47:06.375
between the economics
of the problems that

00:47:06.375 --> 00:47:11.330
can result from security
violations or the breakdowns

00:47:11.330 --> 00:47:15.860
of things compared with
the overall UX experience,

00:47:15.860 --> 00:47:17.700
creating a wonderful
experience-- I think

00:47:17.700 --> 00:47:19.061
is this huge enormous tension.

00:47:19.061 --> 00:47:20.560
And whether it's
through regulations

00:47:20.560 --> 00:47:23.510
or through laws or things like
that that require or demand

00:47:23.510 --> 00:47:25.660
certain disclosures to
be made, ultimately,

00:47:25.660 --> 00:47:27.010
you're going to be affecting
people's businesses

00:47:27.010 --> 00:47:28.551
and business models
and their ability

00:47:28.551 --> 00:47:30.730
to actually offer the
services that they're doing.

00:47:30.730 --> 00:47:32.600
I don't know where this
actually comes down,

00:47:32.600 --> 00:47:36.100
but most users--
and I am somewhat

00:47:36.100 --> 00:47:39.240
OCD about looking at
authorization screens.

00:47:39.240 --> 00:47:42.001
If you go to my Flickr account,
which is under factoryjoe,

00:47:42.001 --> 00:47:43.750
search for "Facebook
authorization." and I

00:47:43.750 --> 00:47:46.130
have like all over the
generations of the Facebook

00:47:46.130 --> 00:47:48.870
Connect dialogues.

00:47:48.870 --> 00:47:51.930
In the beginning, there was lots
of words and lots of disclosure

00:47:51.930 --> 00:47:53.612
and tons of information.

00:47:53.612 --> 00:47:55.320
And now, of course,
you get to this place

00:47:55.320 --> 00:47:57.600
where it's like your face
and your information's

00:47:57.600 --> 00:47:58.766
going to be sent over there.

00:47:58.766 --> 00:47:59.630
That cool?

00:47:59.630 --> 00:48:00.570
They added this
button where it's

00:48:00.570 --> 00:48:01.800
like, edit your information.

00:48:01.800 --> 00:48:02.920
Most people don't care.

00:48:02.920 --> 00:48:06.010
I worked on the Google
authorization dialogues.

00:48:06.010 --> 00:48:08.580
It's extremely difficult to
communicate this information

00:48:08.580 --> 00:48:12.320
in an efficient, effective
way to get people to care

00:48:12.320 --> 00:48:16.270
and to actually be part of
the dialogue and conversation

00:48:16.270 --> 00:48:18.440
with-- to understand the
relationship that they're

00:48:18.440 --> 00:48:20.023
having with these
different providers.

00:48:20.023 --> 00:48:21.620
It becomes just so
over their heads.

00:48:21.620 --> 00:48:24.125
And it provides so
little value to what

00:48:24.125 --> 00:48:26.500
they're trying to do that
providing this in a [INAUDIBLE]

00:48:26.500 --> 00:48:27.130
is difficult.

00:48:27.130 --> 00:48:31.210
So that said, there are reactive
ways of dealing with this,

00:48:31.210 --> 00:48:34.126
as Google does, where they
send out-- what is it?

00:48:34.126 --> 00:48:35.750
Your statement, or
whatever-- your data

00:48:35.750 --> 00:48:36.999
access statement or something.

00:48:36.999 --> 00:48:39.746
So maybe from an
auditing perspective,

00:48:39.746 --> 00:48:42.120
if you have a centralized
identity provider, whether it's

00:48:42.120 --> 00:48:43.967
Facebook, Google,
Twitter or whatever, here

00:48:43.967 --> 00:48:46.050
are the apps that are
asking for your information.

00:48:46.050 --> 00:48:47.980
Here is what we think
they've done with it.

00:48:47.980 --> 00:48:49.100
Here are the number
of your friends

00:48:49.100 --> 00:48:51.566
who have actually uninstalled
or stopped using these apps.

00:48:51.566 --> 00:48:52.940
And here's what
Consumer Reports,

00:48:52.940 --> 00:48:55.090
if they were doing
their job in this space,

00:48:55.090 --> 00:48:57.669
could tell you about
what's happened to people

00:48:57.669 --> 00:48:59.710
who have given their
information to these places.

00:48:59.710 --> 00:49:01.470
So there's just not
a lot of other ways

00:49:01.470 --> 00:49:03.090
in which we're looking at giving
this information to people

00:49:03.090 --> 00:49:04.600
that might be more effective.

00:49:04.600 --> 00:49:06.930
MALE SPEAKER 2: And getting
back to the idea of what

00:49:06.930 --> 00:49:08.620
we can do in the browser,
I think both of you

00:49:08.620 --> 00:49:09.680
were mentioning
that we've already

00:49:09.680 --> 00:49:10.740
put too much on the browser.

00:49:10.740 --> 00:49:12.698
And I think we should
start taking things away.

00:49:12.698 --> 00:49:15.330
For instance, why do we
flag HTTPS as being good?

00:49:15.330 --> 00:49:17.030
Why don't we flag
HTTP as being bad?

00:49:17.030 --> 00:49:20.250
I think that we can start
making it more clear

00:49:20.250 --> 00:49:23.370
that certain
behaviors are good--

00:49:23.370 --> 00:49:25.300
or not good, but default.

00:49:25.300 --> 00:49:27.160
They should be expected.

00:49:27.160 --> 00:49:32.890
And I think both Mozilla and
Google are looking at that bar

00:49:32.890 --> 00:49:34.890
and trying to figure out
what we can do in order

00:49:34.890 --> 00:49:37.306
to encourage the behaviors
that we think are really secure

00:49:37.306 --> 00:49:39.840
and discourage the behaviors
that aren't secure.

00:49:39.840 --> 00:49:40.430
Yeah.

00:49:40.430 --> 00:49:43.100
SPEAKER 1: Like Yan did the
HTTPS Everywhere-- plugging you

00:49:43.100 --> 00:49:46.160
up on that-- but you also get
the HTTP Nowhere extension,

00:49:46.160 --> 00:49:48.120
which I love, which
is your browser

00:49:48.120 --> 00:49:50.720
will refuse to
navigate to HTTP sites.

00:49:50.720 --> 00:49:53.070
And I want to live in a
world where that's normal,

00:49:53.070 --> 00:49:55.660
where I don't have to
explain to my wife and kids

00:49:55.660 --> 00:49:57.800
that yes, you have to
look for the Lock icon.

00:49:57.800 --> 00:49:58.990
And maybe I won't
live in that world.

00:49:58.990 --> 00:50:00.365
But maybe my kids
will, you know,

00:50:00.365 --> 00:50:02.190
where the web is just
encrypted by default.

00:50:02.190 --> 00:50:03.940
And it doesn't work
if it's not encrypted.

00:50:03.940 --> 00:50:04.719
It just breaks.

00:50:04.719 --> 00:50:07.260
MALE SPEAKER 4: And it really
gets to an interesting question

00:50:07.260 --> 00:50:08.750
about this, about what
we should communicate.

00:50:08.750 --> 00:50:10.690
Should we ever put
users in a situation

00:50:10.690 --> 00:50:12.640
where they're making
security decisions?

00:50:12.640 --> 00:50:12.900
SPEAKER 1: Right.

00:50:12.900 --> 00:50:14.566
MALE SPEAKER 4: Aren't
they always going

00:50:14.566 --> 00:50:16.052
to want the secure path?

00:50:16.052 --> 00:50:16.760
SPEAKER 1: Right.

00:50:16.760 --> 00:50:19.260
MALE SPEAKER 4: Is there any
reason we should ever ask them?

00:50:19.260 --> 00:50:19.970
SPEAKER 1: Well--

00:50:19.970 --> 00:50:22.011
MALE SPEAKER 2: Yeah, I
mean, web sites screw up.

00:50:22.011 --> 00:50:24.400
And it's certainly
possible for you

00:50:24.400 --> 00:50:27.790
to need to get to a
website, and-- like

00:50:27.790 --> 00:50:29.010
for example, Onslyde.

00:50:29.010 --> 00:50:30.350
I went to Onslyde this morning.

00:50:30.350 --> 00:50:33.350
And Onslyde, the link
was to onslyde.com.

00:50:33.350 --> 00:50:35.390
But if you look at
the cert details,

00:50:35.390 --> 00:50:36.860
it was for www.onslyde.com.

00:50:36.860 --> 00:50:39.580
And I can make that distinction,
and say, well, they're

00:50:39.580 --> 00:50:41.422
actually the same thing
and click through.

00:50:41.422 --> 00:50:43.130
Chrome is making it
more difficult for me

00:50:43.130 --> 00:50:43.838
to click through.

00:50:43.838 --> 00:50:46.390
I now have to click on Advanced
and then read some text,

00:50:46.390 --> 00:50:49.370
and then down in light gray
text at the bottom of the page,

00:50:49.370 --> 00:50:50.730
there's the Continue button.

00:50:50.730 --> 00:50:53.220
So we're discouraging that
activity to whatever extent

00:50:53.220 --> 00:50:53.960
possible.

00:50:53.960 --> 00:50:56.100
And we allow the
server to tell us

00:50:56.100 --> 00:50:58.580
that we should
completely disable it.

00:50:58.580 --> 00:51:01.200
So if we set up HSTS,
then we won't give you

00:51:01.200 --> 00:51:02.200
that option to continue.

00:51:02.200 --> 00:51:03.991
Because they had asked
for strict security,

00:51:03.991 --> 00:51:05.900
so we're going to give
them strict security.

00:51:05.900 --> 00:51:09.150
But for normal web
pages, it's really tough

00:51:09.150 --> 00:51:11.390
to make a complete
blocking action,

00:51:11.390 --> 00:51:14.856
because the web is a difficult
place and things break.

00:51:14.856 --> 00:51:17.480
FEMALE SPEAKER: Yeah, it sounds
difficult to say that, well, we

00:51:17.480 --> 00:51:19.769
will then go ahead and
stop blocking sites.

00:51:19.769 --> 00:51:21.185
And the web is
such an open place,

00:51:21.185 --> 00:51:23.690
and accessing information
and sharing information

00:51:23.690 --> 00:51:24.825
is the idea of the web.

00:51:24.825 --> 00:51:26.200
And now we're
saying, oh, no, no,

00:51:26.200 --> 00:51:27.700
but we're going to
block these ones.

00:51:27.700 --> 00:51:29.690
And the intentions are great.

00:51:29.690 --> 00:51:31.192
Don't get me wrong.

00:51:31.192 --> 00:51:33.110
It's very hard to
make that decision

00:51:33.110 --> 00:51:36.940
to go and say-- so the things
that the Chrome search team are

00:51:36.940 --> 00:51:39.510
doing at Google about saying,
OK, well, we'll reorder stuff.

00:51:39.510 --> 00:51:41.900
You say, cool, we know
that this is a CNN link.

00:51:41.900 --> 00:51:43.290
Great, that's fantastic.

00:51:43.290 --> 00:51:46.350
But that's a very
common use case.

00:51:46.350 --> 00:51:49.940
But there is a small
percentage chance

00:51:49.940 --> 00:51:56.420
that more unreliable data will
reach to the top over the data

00:51:56.420 --> 00:51:58.650
that you actually want to find.

00:51:58.650 --> 00:52:02.150
So it's a little bit difficult.

00:52:02.150 --> 00:52:04.260
We need to think about
it, how it works out.

00:52:04.260 --> 00:52:05.510
SPEAKER 3: I would
support that point

00:52:05.510 --> 00:52:06.968
from a different
perspective, which

00:52:06.968 --> 00:52:10.280
is to say that the web is a
tinkerer's paradise in a sense.

00:52:10.280 --> 00:52:12.830
And we're asking people
to take a greater

00:52:12.830 --> 00:52:15.229
degree of responsibility for
understanding and knowing

00:52:15.229 --> 00:52:17.020
all the different ways
in which it can fail

00:52:17.020 --> 00:52:18.520
rather than the ways in which
you can get something out

00:52:18.520 --> 00:52:19.200
to the world.

00:52:19.200 --> 00:52:21.764
And so I think if you build
a tax on all of the stuff

00:52:21.764 --> 00:52:23.930
that we're talking about
to make it safer and better

00:52:23.930 --> 00:52:26.520
for everyone, but you increase
the cost of the ability

00:52:26.520 --> 00:52:28.150
to publish to it,
then you will have

00:52:28.150 --> 00:52:29.710
more people building
native apps.

00:52:29.710 --> 00:52:33.190
Because it's cheaper, easier,
and it feels better to do that.

00:52:33.190 --> 00:52:34.254
SPEAKER 1: Right.

00:52:34.254 --> 00:52:35.920
What we're looking
at is we're embarking

00:52:35.920 --> 00:52:39.050
on a very long-term
effort to encourage better

00:52:39.050 --> 00:52:42.860
behaviors by default,
to have best practices,

00:52:42.860 --> 00:52:44.440
little pushes here and there.

00:52:44.440 --> 00:52:46.898
It's not something that's going
to happen overnight or even

00:52:46.898 --> 00:52:49.160
in three or four years,
or even five or 10 years.

00:52:49.160 --> 00:52:50.496
But it has to happen.

00:52:50.496 --> 00:52:51.200
MALE SPEAKER 4: Go
out to audience here.

00:52:51.200 --> 00:52:51.699
Dominic?

00:52:51.699 --> 00:52:55.525
AUDIENCE: Yeah, so it's
great that the web is open.

00:52:55.525 --> 00:52:57.150
It's great that the
web is open, and we

00:52:57.150 --> 00:52:58.920
can use all these
obsolete technologies.

00:52:58.920 --> 00:53:01.920
But we can't use
HTTP 0.9 anymore.

00:53:01.920 --> 00:53:03.930
We can't use Gopher anymore.

00:53:03.930 --> 00:53:05.570
One of these days,
we shouldn't be

00:53:05.570 --> 00:53:07.897
able to use unencrypted
HTTP anymore.

00:53:07.897 --> 00:53:09.230
And I think that's totally fine.

00:53:09.230 --> 00:53:11.271
And as Mark says, it may
be a longer term effort.

00:53:11.271 --> 00:53:12.630
But it doesn't worry me.

00:53:12.630 --> 00:53:14.270
It doesn't seem like
an openness issue

00:53:14.270 --> 00:53:17.630
if you can't use these
legacy technologies, at least

00:53:17.630 --> 00:53:18.330
on that level.

00:53:18.330 --> 00:53:19.996
I mean, yeah, we're
still trying to kill

00:53:19.996 --> 00:53:21.700
showModalDialogue, but whatever.

00:53:21.700 --> 00:53:23.325
SPEAKER 3: I mean,
that's a fair point.

00:53:23.325 --> 00:53:25.317
Does open mean we
have to leave behind--

00:53:25.317 --> 00:53:27.650
we have to keep using all
these things that are horribly

00:53:27.650 --> 00:53:29.290
insecure and aren't
helping us at all?

00:53:29.290 --> 00:53:30.717
Or can we make progress forward?

00:53:30.717 --> 00:53:33.050
FEMALE SPEAKER: Well, I think
you just need think about,

00:53:33.050 --> 00:53:35.008
well, are you going to
use a carrot of a stick?

00:53:35.008 --> 00:53:38.620
Like that's the thing, is
that shutting HTTP data off

00:53:38.620 --> 00:53:40.870
sounds like a bit of
stick method to me.

00:53:40.870 --> 00:53:42.755
I think we need a
few more carrots.

00:53:42.755 --> 00:53:44.380
MALE SPEAKER 2: Well,
I guess, my claim

00:53:44.380 --> 00:53:46.300
would be that if you
want to use Gopher,

00:53:46.300 --> 00:53:47.680
go download a Gopher program.

00:53:47.680 --> 00:53:49.520
And you can still
access all the Gopher

00:53:49.520 --> 00:53:51.500
servers they're
probably still up.

00:53:51.500 --> 00:53:54.216
And you will be taking
that risk, and that's fine.

00:53:54.216 --> 00:53:55.290
SPEAKER 1: And again,
it's an incremental thing.

00:53:55.290 --> 00:53:56.000
I mean, one of the
things that I've

00:53:56.000 --> 00:53:58.800
been talking to people a little
bit about is privacy mode.

00:53:58.800 --> 00:54:02.970
If I'm in privacy mode and I go
see an HTTP site-- or some sort

00:54:02.970 --> 00:54:05.450
of security-centric mode,
I've given the browser

00:54:05.450 --> 00:54:07.420
a signal that hey,
I'm really concerned

00:54:07.420 --> 00:54:09.790
about my personal
privacy and security.

00:54:09.790 --> 00:54:12.760
Maybe the browser should
not let me use an HTTP site.

00:54:12.760 --> 00:54:14.510
So it's kind of an opt-in thing.

00:54:14.510 --> 00:54:16.129
It's an incremental
way to get there,

00:54:16.129 --> 00:54:17.920
rather than just shutting
it off one night.

00:54:17.920 --> 00:54:21.090
FEMALE SPEAKER: Yeah, so if
I'm-- because one of the things

00:54:21.090 --> 00:54:24.720
I was going to say earlier
about I think sometimes,

00:54:24.720 --> 00:54:27.100
one of the biggest issues
is users being in a hurry,

00:54:27.100 --> 00:54:30.200
like they click through because
I need something right now.

00:54:30.200 --> 00:54:31.600
I need to download
Uber right now

00:54:31.600 --> 00:54:33.120
because I need a taxi right now.

00:54:33.120 --> 00:54:34.610
I don't care.

00:54:34.610 --> 00:54:36.930
It doesn't matter what
I'm clicking through.

00:54:36.930 --> 00:54:38.480
I need to get someone now.

00:54:38.480 --> 00:54:41.129
And that's, I think--
they don't read.

00:54:41.129 --> 00:54:41.920
They click through.

00:54:41.920 --> 00:54:43.060
And that's a big issue.

00:54:43.060 --> 00:54:45.760
SPEAKER 1: And it's
interesting you bring that up.

00:54:45.760 --> 00:54:48.630
Yeah, that's true
for a lot of users.

00:54:48.630 --> 00:54:50.530
And security people
I talk to sometimes

00:54:50.530 --> 00:54:53.570
get into this little bit
of a mindset of absolutism,

00:54:53.570 --> 00:54:56.190
where everything has to
be secure all the time.

00:54:56.190 --> 00:54:58.400
Whereas for a large number
of users on the planet,

00:54:58.400 --> 00:54:59.610
they're willing to
make trade-offs.

00:54:59.610 --> 00:55:01.235
And the problem is
they're not educated

00:55:01.235 --> 00:55:02.224
about those trade-offs.

00:55:02.224 --> 00:55:04.140
There's a smaller
population on the planet who

00:55:04.140 --> 00:55:06.790
are very concerned about
security and privacy.

00:55:06.790 --> 00:55:09.260
And they have good reason
to be, for various reasons.

00:55:09.260 --> 00:55:11.340
And we need to give
them good tools too.

00:55:11.340 --> 00:55:14.532
MALE SPEAKER 4: So we'll move
into our next question here.

00:55:14.532 --> 00:55:16.740
This next question actually
is going to pull together

00:55:16.740 --> 00:55:19.380
a few different ideas we've
talked about about user

00:55:19.380 --> 00:55:24.670
experience, SLL, and
the mobile experience--

00:55:24.670 --> 00:55:27.460
or at least moving around
where you connect to the net.

00:55:27.460 --> 00:55:32.050
So brought to us from Cornell
Lysinski, "What should we

00:55:32.050 --> 00:55:34.900
allow intermediaries such
as mobile operator proxies,

00:55:34.900 --> 00:55:37.430
Wi-fi hotspots,
corporate gateways,

00:55:37.430 --> 00:55:41.285
et cetera, to see and
do to user traffic?"

00:55:41.285 --> 00:55:42.910
MALE SPEAKER 2: I
would suggest that we

00:55:42.910 --> 00:55:45.820
let them do whatever the
user enables them to do,

00:55:45.820 --> 00:55:47.710
or whatever the
administrator who

00:55:47.710 --> 00:55:51.950
exerts executive control
over the machine allows,

00:55:51.950 --> 00:55:54.690
which basically means
that if it's over HTTPS,

00:55:54.690 --> 00:55:56.680
they shouldn't be able
to do anything to it

00:55:56.680 --> 00:55:59.510
unless a cert has been
installed in the root

00:55:59.510 --> 00:56:00.930
store of the machine.

00:56:00.930 --> 00:56:04.240
Because that means that someone
exerted administrative control

00:56:04.240 --> 00:56:06.657
over the machine and said,
this is the right thing for you

00:56:06.657 --> 00:56:07.156
to do.

00:56:07.156 --> 00:56:08.440
Go through this mobile proxy.

00:56:08.440 --> 00:56:10.290
That's going to
change everything.

00:56:10.290 --> 00:56:14.066
MALE SPEAKER 4: So you're saying
a coffee shop wireless should

00:56:14.066 --> 00:56:16.190
not be able to intercept,
do a "man in the middle,"

00:56:16.190 --> 00:56:18.440
throw all the warnings, train
people to click through?

00:56:18.440 --> 00:56:19.810
MALE SPEAKER 2: Never, ever.

00:56:19.810 --> 00:56:21.130
SPEAKER 1: And we've
talked about this a lot

00:56:21.130 --> 00:56:22.520
in the HTTP working group.

00:56:22.520 --> 00:56:25.160
And that's the model
we've kind of resolved on,

00:56:25.160 --> 00:56:28.504
is that HTTPS is explicitly
end-to-end secure.

00:56:28.504 --> 00:56:30.920
It's not end-to-end and maybe
this guy comes to the middle

00:56:30.920 --> 00:56:32.820
and has a chat.

00:56:32.820 --> 00:56:36.340
And so the trust
store in the browser

00:56:36.340 --> 00:56:38.710
is a really
fundamental mechanism.

00:56:38.710 --> 00:56:40.640
Now, as we were talking
about last night,

00:56:40.640 --> 00:56:42.720
we can improve the
trust store a lot.

00:56:42.720 --> 00:56:45.210
The user experience around
that is pretty bad right now.

00:56:45.210 --> 00:56:47.334
But that's kind of the
model we're working towards.

00:56:50.610 --> 00:56:52.130
SPEAKER 3: It occurs
to me again-- I

00:56:52.130 --> 00:56:53.120
tend to think about
a lot of things

00:56:53.120 --> 00:56:54.328
from an economic perspective.

00:56:54.328 --> 00:56:56.330
And there is an economic
benefit or reason

00:56:56.330 --> 00:56:58.680
why the coffee shop
would sort of intersperse

00:56:58.680 --> 00:57:00.170
their thing with
ads or whatever.

00:57:00.170 --> 00:57:03.440
People are unwilling to pay for
Wi-Fi or something like that.

00:57:03.440 --> 00:57:05.814
Or if they have
to pay for Wi-Fi,

00:57:05.814 --> 00:57:07.480
to be able to get a
line, because people

00:57:07.480 --> 00:57:09.240
aren't buying enough coffee.

00:57:09.240 --> 00:57:12.421
So I think that the
challenge-- back

00:57:12.421 --> 00:57:14.670
to your point about whether
it's a carrot or a stick--

00:57:14.670 --> 00:57:16.130
is unclear whether
or not it should

00:57:16.130 --> 00:57:20.247
be illegal to break the stuff
and have these captive portals,

00:57:20.247 --> 00:57:22.580
in which case, it's a very
different type of enforcement

00:57:22.580 --> 00:57:23.060
model.

00:57:23.060 --> 00:57:24.560
Or if it's a carrot
thing where it's

00:57:24.560 --> 00:57:26.565
like users have a
different attitude

00:57:26.565 --> 00:57:29.190
and they just shut down if they
don't want be vulnerable to it.

00:57:29.190 --> 00:57:30.815
SPEAKER 1: Personally,
I'm not terribly

00:57:30.815 --> 00:57:32.540
interested in the
legal or legislative.

00:57:32.540 --> 00:57:33.160
SPEAKER 3: Sure, nor
am I suggesting that.

00:57:33.160 --> 00:57:34.360
SPEAKER 1: I'm looking
at technical solutions

00:57:34.360 --> 00:57:36.595
where it's not possible
to get in the middle.

00:57:36.595 --> 00:57:38.220
MALE SPEAKER 4: How
does this play out?

00:57:38.220 --> 00:57:39.980
I mean the coffee
house is one example,

00:57:39.980 --> 00:57:42.744
but the corporate environment
where the company wants

00:57:42.744 --> 00:57:45.160
to step in and say, I'm going
to intercept this connection

00:57:45.160 --> 00:57:46.800
to this unrelated site.

00:57:46.800 --> 00:57:48.210
And otherwise, we have HSTS.

00:57:48.210 --> 00:57:49.440
We never want this to happen.

00:57:49.440 --> 00:57:53.262
SPEAKER 1: But as Mike said, if
the company owns the machine,

00:57:53.262 --> 00:57:54.970
they insert something
in the trust store,

00:57:54.970 --> 00:57:57.210
you sign the contract that
says I'm your employee.

00:57:57.210 --> 00:57:58.930
I know you're going
to sniff my stuff.

00:57:58.930 --> 00:58:00.305
And if you're
smart, you don't go

00:58:00.305 --> 00:58:03.020
to your bank over
your company computer.

00:58:03.020 --> 00:58:06.350
Or if you're in a prison
or if you're in a school--

00:58:06.350 --> 00:58:09.410
they're often the
same sort of thing.

00:58:09.410 --> 00:58:10.980
You have that relationship.

00:58:10.980 --> 00:58:13.563
MALE SPEAKER 4: So we're really
going to the extreme of what's

00:58:13.563 --> 00:58:15.410
allowed may not match
user expectations.

00:58:15.410 --> 00:58:18.210
And I think users perhaps
are not expecting that, even

00:58:18.210 --> 00:58:19.970
in enterprise, whether
or not they should.

00:58:19.970 --> 00:58:21.720
SPEAKER 3: Let's get
back to the check box

00:58:21.720 --> 00:58:24.900
though, for the airfare
thing or whatever where

00:58:24.900 --> 00:58:26.250
you checked a box at some point.

00:58:26.250 --> 00:58:28.333
And the problem is that
we have very little agency

00:58:28.333 --> 00:58:30.890
to actually fight back on
that, where my lawyer talks

00:58:30.890 --> 00:58:33.460
to the app's lawyer
and says, actually,

00:58:33.460 --> 00:58:35.100
these terms I disagree with.

00:58:35.100 --> 00:58:36.660
I don't want you
to sniff my stuff,

00:58:36.660 --> 00:58:37.785
even though I work for you.

00:58:37.785 --> 00:58:38.459
SPEAKER 1: Yeah.

00:58:38.459 --> 00:58:40.750
MALE SPEAKER 4: All right,
we're running short on time.

00:58:40.750 --> 00:58:42.458
But let's get a few
audience participants

00:58:42.458 --> 00:58:45.345
on this most likely
last question.

00:58:45.345 --> 00:58:46.150
There we go.

00:58:46.150 --> 00:58:51.820
AUDIENCE: Hi, just
regarding Wi-Fi hotspots,

00:58:51.820 --> 00:58:55.040
the captive portal situation--
even if they're not

00:58:55.040 --> 00:58:57.770
trying to intercept
the traffic itself,

00:58:57.770 --> 00:59:01.070
they are trying to
intercept the first session.

00:59:01.070 --> 00:59:04.240
And currently, when
I'm on the road trying

00:59:04.240 --> 00:59:08.560
to log onto a random
WiFi, I go to websites

00:59:08.560 --> 00:59:11.240
that I know they are HTTP.

00:59:11.240 --> 00:59:13.870
Otherwise, it just blocks.

00:59:13.870 --> 00:59:17.680
So are there any plans
to standardize on that

00:59:17.680 --> 00:59:19.350
and make that work?

00:59:19.350 --> 00:59:22.300
SPEAKER 1: Yeah, we've had
some background discussions

00:59:22.300 --> 00:59:25.090
about this amongst a couple
different vendors to try

00:59:25.090 --> 00:59:25.670
and improve.

00:59:25.670 --> 00:59:29.100
Everyone's very keenly aware
of that, that that's a problem.

00:59:29.100 --> 00:59:30.875
Getting the right
people in the room,

00:59:30.875 --> 00:59:33.000
and especially because you
need the Wi-Fi networks,

00:59:33.000 --> 00:59:35.610
you need the vendors creating
those captive portals,

00:59:35.610 --> 00:59:37.120
you need the operating
system folks,

00:59:37.120 --> 00:59:38.900
and sometimes,
the browser folks,

00:59:38.900 --> 00:59:40.970
it's really hard to get
everybody in one place.

00:59:40.970 --> 00:59:43.150
But we're working towards that.

00:59:43.150 --> 00:59:45.820
It's not going to be any
time soon, unfortunately.

00:59:45.820 --> 00:59:48.270
But yeah, it's a problem.

00:59:48.270 --> 00:59:49.650
AUDIENCE: OK, so-- OK.

00:59:49.650 --> 00:59:50.647
SPEAKER 1: Sorry.

00:59:50.647 --> 00:59:51.730
MALE SPEAKER 4: Let's see.

00:59:51.730 --> 00:59:54.495
And we had another
comment from the audience.

00:59:57.610 --> 00:59:59.060
There we are.

00:59:59.060 --> 01:00:00.560
AUDIENCE: I'm
wondering, what can we

01:00:00.560 --> 01:00:05.170
do to give better visibility
into what intermediaries

01:00:05.170 --> 01:00:05.790
are installed?

01:00:05.790 --> 01:00:07.810
So even if somebody has
exerted administrative control

01:00:07.810 --> 01:00:09.351
over a device, it
doesn't mean that I

01:00:09.351 --> 01:00:10.850
am necessarily aware of it.

01:00:10.850 --> 01:00:14.630
I've heard rumors of
carriers installing things,

01:00:14.630 --> 01:00:17.000
even my-- like, I may
not be aware that when

01:00:17.000 --> 01:00:20.109
I pick up a device and I
install my corporate thing

01:00:20.109 --> 01:00:22.400
that all my traffic is going
through a corporate proxy.

01:00:22.400 --> 01:00:24.720
And I may be doing very
private things that I-- like,

01:00:24.720 --> 01:00:26.400
maybe I want to opt out, right?

01:00:26.400 --> 01:00:27.980
Maybe I want a different route.

01:00:27.980 --> 01:00:29.867
How do we make that better?

01:00:29.867 --> 01:00:31.950
SPEAKER 1: So there are
two parts to this I think.

01:00:31.950 --> 01:00:33.560
One is, like we
were talking about,

01:00:33.560 --> 01:00:35.850
improving the user experience
around the trust store.

01:00:35.850 --> 01:00:39.470
So I can say, well, this CA,
trust it for these sites,

01:00:39.470 --> 01:00:42.830
but not for arbitrary
other sites, for example.

01:00:42.830 --> 01:00:45.060
And then there's been
some background chatter

01:00:45.060 --> 01:00:47.630
for a long time now
about doing things

01:00:47.630 --> 01:00:50.080
like end-to-end
signatures in HTTP

01:00:50.080 --> 01:00:52.417
where you can sign
content for integrity

01:00:52.417 --> 01:00:54.750
or have multiple layers of
encryption, things like that.

01:00:54.750 --> 01:00:57.239
And there are a lot of people
really interested in that.

01:00:57.239 --> 01:00:59.030
Getting the browser
guys interested in that

01:00:59.030 --> 01:01:00.410
is a little harder so far.

01:01:00.410 --> 01:01:02.780
But there's a lot
of interest there.

01:01:02.780 --> 01:01:05.580
AUDIENCE: Yeah, so I think part
of my question is maybe it's

01:01:05.580 --> 01:01:07.870
more to the vendors,
to the browsers.

01:01:07.870 --> 01:01:10.417
Because it seems like
sometimes-- and granted,

01:01:10.417 --> 01:01:12.000
this is probably an
advanced use case.

01:01:12.000 --> 01:01:13.374
But there are
cases where I would

01:01:13.374 --> 01:01:14.837
like to opt out sometimes.

01:01:14.837 --> 01:01:16.670
And this is not a
question about end-to-end,

01:01:16.670 --> 01:01:19.200
has somebody
manipulated the content.

01:01:19.200 --> 01:01:22.130
It's the fact that it was
seen by somebody else, right,

01:01:22.130 --> 01:01:23.980
so you went through a proxy.

01:01:23.980 --> 01:01:26.370
I want to opt out
sometimes, like maybe I

01:01:26.370 --> 01:01:28.030
don't want specific
type of traffic

01:01:28.030 --> 01:01:30.529
to be seen by my
corporate proxy.

01:01:30.529 --> 01:01:32.070
MALE SPEAKER 2:
Yeah, so with Chrome,

01:01:32.070 --> 01:01:34.440
we don't have any
UI for proxies.

01:01:34.440 --> 01:01:36.170
But I know that on
Android, if there

01:01:36.170 --> 01:01:38.880
is a cert installed in
the trust store that

01:01:38.880 --> 01:01:40.780
isn't one of the
pre-installed certs,

01:01:40.780 --> 01:01:42.720
then there's a
persistent notification

01:01:42.720 --> 01:01:45.630
up in the top bar that shows
you that your device is owned

01:01:45.630 --> 01:01:47.740
by someone else, and
that it's completely

01:01:47.740 --> 01:01:51.240
possible for your traffic
to be routed through someone

01:01:51.240 --> 01:01:52.430
who can read it.

01:01:52.430 --> 01:01:55.360
We don't have that on
Chrome OS, I believe.

01:01:55.360 --> 01:01:56.990
And I don't think we
have it on desktop

01:01:56.990 --> 01:01:59.896
either, because that's
really an OS level thing.

01:01:59.896 --> 01:02:01.770
And it's something that
I think the operating

01:02:01.770 --> 01:02:02.954
system needs to deal with.

01:02:02.954 --> 01:02:04.120
But you're entirely correct.

01:02:04.120 --> 01:02:08.140
The browsers can
and probably should

01:02:08.140 --> 01:02:10.390
figure out ways of
making it clear to users

01:02:10.390 --> 01:02:12.130
that their traffic
is not secure.

01:02:12.130 --> 01:02:14.850
And maybe that's something
we do in the address bar.

01:02:14.850 --> 01:02:16.560
Maybe we don't make
any sites green

01:02:16.560 --> 01:02:18.260
if there's a cert installed.

01:02:18.260 --> 01:02:18.820
I don't know.

01:02:18.820 --> 01:02:19.624
I think there are--

01:02:19.624 --> 01:02:21.665
SPEAKER 1: There are open
bugs for this in Chrome

01:02:21.665 --> 01:02:22.530
and in Firefox.

01:02:22.530 --> 01:02:24.580
And it's been quite
contentious from what I saw.

01:02:24.580 --> 01:02:26.520
I mean-- and there
are two sides to it.

01:02:26.520 --> 01:02:28.300
I don't really
understand the negatives

01:02:28.300 --> 01:02:29.790
as well as I understand
the positives of doing

01:02:29.790 --> 01:02:30.600
what you want to do there.

01:02:30.600 --> 01:02:30.870
But, you know.

01:02:30.870 --> 01:02:33.250
MALE SPEAKER 4: Well, I
think an interesting point

01:02:33.250 --> 01:02:37.270
to wrap things up, a [? night ?]
in the security of usability,

01:02:37.270 --> 01:02:39.970
some contention on
different sides.

01:02:39.970 --> 01:02:42.470
Hopefully, we had some
good discussion here.

01:02:42.470 --> 01:02:44.770
I think there's a lot
of good ideas around how

01:02:44.770 --> 01:02:47.590
do we incentivize security so
people want to do it; how do we

01:02:47.590 --> 01:02:50.390
balance the user experience
so they know what's happening;

01:02:50.390 --> 01:02:52.900
how do we operate in a model
so what happens to users,

01:02:52.900 --> 01:02:55.980
they're aware of and they think
that's correct or aware if it's

01:02:55.980 --> 01:02:56.730
not.

01:02:56.730 --> 01:02:57.940
But I really wanted
to thank everyone

01:02:57.940 --> 01:03:00.273
on the panel, everyone in the
audience for good comments

01:03:00.273 --> 01:03:01.036
and questions.

01:03:01.036 --> 01:03:02.660
I think we'll leave
it there for today.

01:03:02.660 --> 01:03:03.260
Thank you.

01:03:03.260 --> 01:03:06.860
[APPLAUSE]

01:03:06.860 --> 01:03:08.410
SPEAKER 1: [INAUDIBLE].

