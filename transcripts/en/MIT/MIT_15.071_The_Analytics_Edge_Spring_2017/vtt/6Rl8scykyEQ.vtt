WEBVTT
Kind: captions
Language: en

00:00:04.500 --> 00:00:08.490
So why is the game of
Jeopardy hard for a computer?

00:00:08.490 --> 00:00:13.090
We said earlier that Watson had
3,000 processors and a database

00:00:13.090 --> 00:00:16.700
of 200 million pages
of information.

00:00:16.700 --> 00:00:20.620
So shouldn't it be easy for
Watson to play Jeopardy?

00:00:20.620 --> 00:00:23.440
Unfortunately, Jeopardy
has a wide variety

00:00:23.440 --> 00:00:27.100
of categories which are
purposely made cryptic.

00:00:27.100 --> 00:00:30.960
While computers can easily
answer precise questions,

00:00:30.960 --> 00:00:34.290
like computing the square
root of a complicated number,

00:00:34.290 --> 00:00:38.470
understanding natural language
is hard for computers.

00:00:38.470 --> 00:00:42.570
As an example, suppose we ask
Watson to answer the question:

00:00:42.570 --> 00:00:45.620
Where was Albert Einstein born?

00:00:45.620 --> 00:00:47.770
Stored in its
database, Watson might

00:00:47.770 --> 00:00:51.610
have the following information:
"One day, from his city

00:00:51.610 --> 00:00:54.420
views of Ulm, Otto
chose a watercolor

00:00:54.420 --> 00:00:59.140
to send to Albert Einstein as a
remembrance of his birthplace."

00:00:59.140 --> 00:01:01.460
As a human, we can
probably figure out

00:01:01.460 --> 00:01:04.530
that the name of
the city is Ulm,

00:01:04.530 --> 00:01:07.360
but this is a hard
sentence to parse.

00:01:07.360 --> 00:01:10.030
How would you tell a computer
that Albert Einstein was

00:01:10.030 --> 00:01:12.200
born in Ulm using
just this sentence?

00:01:14.820 --> 00:01:15.320
OK.

00:01:15.320 --> 00:01:17.490
So how about if we
just store answers

00:01:17.490 --> 00:01:21.330
to all possible questions that
could be asked on Jeopardy?

00:01:21.330 --> 00:01:24.140
Unfortunately, this
would be impossible.

00:01:24.140 --> 00:01:28.600
An analysis of 200,000
previous Jeopardy questions

00:01:28.600 --> 00:01:32.070
yielded over 2,500
different categories,

00:01:32.070 --> 00:01:36.270
and new questions are created
on Jeopardy all the time.

00:01:36.270 --> 00:01:38.570
Well, OK, then let's
just search Google

00:01:38.570 --> 00:01:40.890
for the answer to the question.

00:01:40.890 --> 00:01:43.800
Unfortunately, no links
to the outside world

00:01:43.800 --> 00:01:46.240
are permitted on
Jeopardy, and this rule

00:01:46.240 --> 00:01:48.610
applied to Watson as well.

00:01:48.610 --> 00:01:51.700
And even if Watson could search
the internet for the answer

00:01:51.700 --> 00:01:54.940
to a question, it can
take considerable skill

00:01:54.940 --> 00:01:58.950
to find the right web page
with the right information.

00:01:58.950 --> 00:02:01.380
So instead, Watson
used analytics

00:02:01.380 --> 00:02:03.780
to answer the
Jeopardy questions.

00:02:03.780 --> 00:02:07.180
Watson received each
question in text form.

00:02:07.180 --> 00:02:10.250
Normally, the players see
and hear the questions,

00:02:10.250 --> 00:02:11.860
but Watson couldn't
hear anything,

00:02:11.860 --> 00:02:16.260
so they decided to feed him
the questions in text instead.

00:02:16.260 --> 00:02:18.990
With the question
in text form, IBM

00:02:18.990 --> 00:02:22.660
was able to use text analytics
and other analytical methods

00:02:22.660 --> 00:02:25.600
to make Watson a
competitive player.

00:02:25.600 --> 00:02:28.200
Overall, they used 100
different techniques

00:02:28.200 --> 00:02:31.760
for analyzing natural
language, finding hypotheses

00:02:31.760 --> 00:02:34.860
for the questions, and
ranking these hypotheses

00:02:34.860 --> 00:02:37.829
to pick an answer.

00:02:37.829 --> 00:02:41.910
Watson had a huge database of
sources and several basic tools

00:02:41.910 --> 00:02:44.310
to help understand language.

00:02:44.310 --> 00:02:48.270
The database consisted of a
massive number of data sources,

00:02:48.270 --> 00:02:52.970
like encyclopedias,
texts, manuals, magazines,

00:02:52.970 --> 00:02:56.700
and downloaded
pages of Wikipedia.

00:02:56.700 --> 00:03:00.220
One of the tools Watson
had was a lexicon,

00:03:00.220 --> 00:03:03.880
which describes the relationship
between different words.

00:03:03.880 --> 00:03:07.250
For example, the lexicon
could tell Watson

00:03:07.250 --> 00:03:10.560
that water is a clear liquid,
but not all clear liquids

00:03:10.560 --> 00:03:12.220
are water.

00:03:12.220 --> 00:03:14.500
Another tool Watson
had was a part

00:03:14.500 --> 00:03:17.490
of speech tagger and parser.

00:03:17.490 --> 00:03:21.400
This would identify
functions of words in text.

00:03:21.400 --> 00:03:24.190
For example, it would
know that the word "race"

00:03:24.190 --> 00:03:27.329
can be used as a verb or a noun.

00:03:27.329 --> 00:03:30.030
"The students had to
race to catch the bus"

00:03:30.030 --> 00:03:34.210
uses race as a verb, while
"Please indicate your race"

00:03:34.210 --> 00:03:37.400
uses race as a noun.

00:03:37.400 --> 00:03:40.400
Then, using these data
sources and tools,

00:03:40.400 --> 00:03:42.400
Watson would answer
a question by going

00:03:42.400 --> 00:03:44.930
through four major steps.

00:03:44.930 --> 00:03:47.730
The first step is
question analysis,

00:03:47.730 --> 00:03:49.640
where Watson tries
to figure out what

00:03:49.640 --> 00:03:51.990
the question is looking for.

00:03:51.990 --> 00:03:55.350
The second step is
hypothesis generation,

00:03:55.350 --> 00:03:57.380
where Watson searches
the information

00:03:57.380 --> 00:04:00.410
sources for possible answers.

00:04:00.410 --> 00:04:02.740
After this, Watson
moves on to step

00:04:02.740 --> 00:04:06.330
three, when the different
hypotheses are scored.

00:04:06.330 --> 00:04:08.100
This means that a
confidence level

00:04:08.100 --> 00:04:11.570
has to be computed
for each answer.

00:04:11.570 --> 00:04:14.490
The final step is
ranking the hypotheses

00:04:14.490 --> 00:04:17.890
to look for a
highly-supported answer.

00:04:17.890 --> 00:04:21.320
In the next two videos, we'll go
through how each of these steps

00:04:21.320 --> 00:04:22.870
work.

