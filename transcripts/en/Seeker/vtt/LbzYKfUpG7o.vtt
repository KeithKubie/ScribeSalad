WEBVTT
Kind: captions
Language: en

00:00:00.199 --> 00:00:07.220
96% of people like cheesy opening jokes according
to a survey of DNews writers.

00:00:07.220 --> 00:00:12.919
Hello voters, Trace here for DNews.

00:00:12.919 --> 00:00:17.450
In this election year with so much stock being
put into what the polls say, it’s important

00:00:17.450 --> 00:00:18.820
they’re as accurate as possible.

00:00:18.820 --> 00:00:22.970
But depending on the poll the results could
be a reflection of how the nation feels as

00:00:22.970 --> 00:00:26.900
a whole, or a bunch of fringe supporters skewing
the outcomes.

00:00:26.900 --> 00:00:31.340
What’s the science behind designing a poll
that will accurately predict how the country

00:00:31.340 --> 00:00:32.340
will vote?

00:00:32.340 --> 00:00:36.160
Obviously, no poll can get ahold of everyone
in the country, otherwise our phones would

00:00:36.160 --> 00:00:37.660
be ringing constantly.

00:00:37.660 --> 00:00:42.140
Instead pollsters have to interview a relatively
small number of people and extrapolate their

00:00:42.140 --> 00:00:47.230
data from there -- they call this a sample,
or N. Scientific polling organizations will

00:00:47.230 --> 00:00:50.570
aim to survey 1,000 to 1,500 people.

00:00:50.570 --> 00:00:56.079
Statistically, the result will almost always
have a 3% margin of sampling error then meaning

00:00:56.079 --> 00:01:00.760
that these people should be representative
of the population’s attitudes give or take

00:01:00.760 --> 00:01:01.760
3%.

00:01:01.760 --> 00:01:05.470
They could survey more people, but after 1,000
people the margin of error doesn’t decrease

00:01:05.470 --> 00:01:06.470
much.

00:01:06.470 --> 00:01:11.429
To get the margin of error down to 1%, pollsters
would have to survey 10,000 people.

00:01:11.429 --> 00:01:15.330
At that point it’s not really worth the
time or effort, not to mention money.

00:01:15.330 --> 00:01:19.549
There are other kinds of errors that go unaccounted
for, like errors in analysis -- where certain

00:01:19.549 --> 00:01:23.899
assumptions the researchers make about how
to handle their data turn out to be wrong

00:01:23.899 --> 00:01:28.399
-- and the nonresponse error -- where people
who support a candidate who’s behind are

00:01:28.399 --> 00:01:32.380
less likely to respond, further skewing results.4,

00:01:32.380 --> 00:01:35.969
Polling organizations like the Pew Research
Center for example will find participants

00:01:35.969 --> 00:01:41.509
by calling them, selecting the geographical
area by area code and the next 5 digits of

00:01:41.509 --> 00:01:42.590
a phone number.

00:01:42.590 --> 00:01:45.340
Then they will randomly dialing the last two.

00:01:45.340 --> 00:01:49.880
The phone numbers randomly selected from one
area are supposed to be proportional to that

00:01:49.880 --> 00:01:52.649
area’s share of phone numbers in the country.

00:01:52.649 --> 00:01:56.810
The idea is to get totally random representatives
from across the nation on the phone, though

00:01:56.810 --> 00:02:02.069
with more people switching to cell phones
it’s gotten a bit harder to pin down.

00:02:02.069 --> 00:02:05.819
Getting them on the phone is the first step,
but the researchers know they don’t have

00:02:05.819 --> 00:02:07.939
an accurate sample just yet.

00:02:07.939 --> 00:02:12.481
Older people are more likely to answer a landline,
so the Pew Research center will ask for the

00:02:12.481 --> 00:02:17.209
youngest male in the house half the time and
the youngest female the other half.

00:02:17.209 --> 00:02:20.890
If it’s a cell phone, yes, pollsters can
(and do) call cell phones, they’ll just

00:02:20.890 --> 00:02:22.530
make sure the person is over 18.

00:02:22.530 --> 00:02:26.689
When it comes to election polling, they’ll
also ask if the person they’re surveying

00:02:26.689 --> 00:02:30.620
plans to vote; if you don’t plan to vote,
your opinion doesn’t really matter -- at

00:02:30.620 --> 00:02:32.900
least at least to the outcome of the election.

00:02:32.900 --> 00:02:34.920
Then they’ll ask who they plan to vote for.

00:02:34.920 --> 00:02:39.150
It’s important this question comes first,
and that the order the candidates are listed

00:02:39.150 --> 00:02:40.629
in is switched up.

00:02:40.629 --> 00:02:44.610
Asking about policy questions first can make
a participant realize they don’t actually

00:02:44.610 --> 00:02:46.129
agree with a candidate.

00:02:46.129 --> 00:02:51.299
Constantly listing one candidate first can
also impact the survey, especially in primaries

00:02:51.299 --> 00:02:54.550
where there can be several candidates and
it’s hard to keep track of them over the

00:02:54.550 --> 00:02:55.550
phone.

00:02:55.550 --> 00:02:59.069
All these precautions are things online polls
don’t do.

00:02:59.069 --> 00:03:03.760
Their samples consist of just the website’s
readership, which could skew to one area,

00:03:03.760 --> 00:03:07.439
one age group, one political bias, or people
who won’t even vote.

00:03:07.439 --> 00:03:11.030
News organizations love to say, "our online
poll shows ____."

00:03:11.030 --> 00:03:16.000
But, their online poll isn't a representative
sample, and doesn't actually, "show" anything,

00:03:16.000 --> 00:03:18.950
except what the people who come to their website
might think.

00:03:18.950 --> 00:03:23.209
Sometimes political ads even masquerade as
polls, asking questions about a candidate

00:03:23.209 --> 00:03:25.470
in a negative way to sway opinion.

00:03:25.470 --> 00:03:29.859
Because scientific polls strive to eliminate
as many of these confounding factors as possible

00:03:29.859 --> 00:03:33.040
they are much more reliable than online public
surveys.

00:03:33.040 --> 00:03:37.840
If you want to check out how well they perform,
the National Council on Public Polls keeps

00:03:37.840 --> 00:03:42.049
track of how accurate each poll was after
every election.

00:03:42.049 --> 00:03:44.150
You can check out their link in the description
below.

00:03:44.150 --> 00:03:48.489
In 2012 Pew predicted Obama would win 50%
to 47%.

00:03:48.489 --> 00:03:50.170
The final tally?

00:03:50.170 --> 00:03:51.640
51 to 47.

00:03:51.640 --> 00:03:55.989
We think we’re pretty special with our precious
Democracy but it isn’t uniquely human.

00:03:55.989 --> 00:04:13.930
Julian and I explore other species that vote
here.

00:04:13.930 --> 00:04:19.850
So even though open online polls are essentially
meaningless, they promote audience engagement.

00:04:19.850 --> 00:04:23.950
Do you think a poll is the best way to do
that or is there a smarter way to get people

00:04:23.950 --> 00:04:30.290
involved?

