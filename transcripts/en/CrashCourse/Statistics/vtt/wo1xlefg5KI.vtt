WEBVTT
Kind: captions
Language: en

00:00:02.960 --> 00:00:06.680
Hi, I’m Adriene Hill, and welcome back to
Crash Course Statistics.

00:00:06.680 --> 00:00:10.720
When comparing groups, there isn’t always
one single box that we can put someone into.

00:00:10.720 --> 00:00:14.240
You might be someone’s child, but also a
parent, and a partner.

00:00:14.240 --> 00:00:18.530
You have an ethnicity or maybe a job title,
and maybe you’re a competitive dog groomer

00:00:18.530 --> 00:00:22.160
And it’s not just people that belong in
multiple groups.

00:00:22.160 --> 00:00:26.779
Your watch might be a smart watch, but also
an Apple product, and something that’s rose

00:00:26.779 --> 00:00:27.779
gold.

00:00:27.779 --> 00:00:29.720
Things and people belong to multiple groups.

00:00:29.720 --> 00:00:32.230
And those groups can overlap or interact.

00:00:32.230 --> 00:00:37.220
So today, we’re going to take a look at
ANOVAs that include more than one grouping variable.

00:00:37.220 --> 00:00:46.480
INTRO

00:00:46.489 --> 00:00:50.500
We want to look at sedan prices to figure
out how they’re affected by manufacturer

00:00:50.500 --> 00:00:51.580
and color.

00:00:51.580 --> 00:00:56.420
For now, we’ll assume that those two factors are independent of each other -- they don’t interact.

00:00:56.480 --> 00:01:01.880
And for this, we use a Factorial ANOVA, which
can have just two grouping variables--like

00:01:01.900 --> 00:01:06.720
car manufacturer and car color--up to hundreds
of grouping variables.

00:01:06.720 --> 00:01:10.600
In this case we're going to look at Toyotas, Hondas, Chevrolets, and Lamborghinis.

00:01:10.600 --> 00:01:13.920
And include the colors blue, red, silver, and white.

00:01:13.920 --> 00:01:19.819
A Factorial ANOVA does almost exactly what
a regular ANOVA does: it takes the overall

00:01:19.819 --> 00:01:24.070
variation--or Sums of Squares--and portions
it out into different categories.

00:01:24.070 --> 00:01:30.350
If we’re interested in how car manufacturer
and color affect price, we first calculate

00:01:30.350 --> 00:01:34.389
the overall variation in the dataset called
the Sums of Squares Total.

00:01:34.389 --> 00:01:40.170
We do this by summing up all the squared distances
between each car price and the mean overall

00:01:40.170 --> 00:01:41.179
car price.

00:01:41.179 --> 00:01:45.659
Then once we know the total variation in the
data set, we set out to use manufacturer and

00:01:45.659 --> 00:01:49.669
color to explain why these sedans have different
prices.

00:01:49.669 --> 00:01:53.600
Our proposed model looks something like this:
Which tells us that we think the price of

00:01:53.600 --> 00:01:59.749
a car is some baseline cost plus an adjustment
for who made the car and what color it is.

00:01:59.749 --> 00:02:04.130
And like before, we know that we won’t always
be exactly spot on.

00:02:04.130 --> 00:02:09.580
So to complete the General Linear Model form
we add an error term which represents how

00:02:09.580 --> 00:02:12.909
“off” our guess was from the actual price
of each car.

00:02:12.909 --> 00:02:18.540
We’re going to use our model and the error
to create F statistics for each part of our

00:02:18.540 --> 00:02:20.739
model, as well as the model as a whole.

00:02:20.739 --> 00:02:25.219
The F-statistic is a ratio between the scaled
Sums of Squares for a variable and the scaled

00:02:25.219 --> 00:02:27.349
Sums of Squares for the Error.

00:02:27.349 --> 00:02:31.790
We call these scaled versions of the Sums
of Squares, Mean Squares.

00:02:31.790 --> 00:02:36.680
When we create these models using statistical
software like R, or Python, or even Excel,

00:02:36.680 --> 00:02:40.040
we’ll usually get what we call an ANOVA
table as an output.

00:02:40.040 --> 00:02:44.099
And the table will give us all the information
we need to answer our questions.

00:02:44.099 --> 00:02:49.920
We can see in this table that the p-value
for color is way bigger than our alpha cutoff

00:02:49.920 --> 00:02:50.920
of 0.05.

00:02:50.920 --> 00:02:55.950
So we did not find evidence that color has
a significant effect on car price.

00:02:55.950 --> 00:03:01.200
On the other hand, we did find evidence that manufacturer has a significant effect on car price.

00:03:01.200 --> 00:03:02.600
And I guess we knew that.

00:03:02.600 --> 00:03:07.060
But just like with our t-tests, we know that
a significant F-test only means this result

00:03:07.060 --> 00:03:08.849
is statistically significant.

00:03:08.849 --> 00:03:13.890
It doesn’t always mean it’s practically
significant to you.

00:03:13.890 --> 00:03:19.010
If there’s a statistically significant effect
of manufacturer on car price but it turns

00:03:19.010 --> 00:03:24.439
out it’s only about a $20 difference well
that might not have a huge impact on whether

00:03:24.439 --> 00:03:26.999
or not you decide to buy a particular car.

00:03:26.999 --> 00:03:29.120
So we need another measure of effect size.

00:03:29.120 --> 00:03:34.349
Something that helps us understand how big
the effect really is in more practical terms.

00:03:34.349 --> 00:03:38.030
There are many different measurements of effect
size for ANOVAs, but they all share similar

00:03:38.030 --> 00:03:40.880
ideas, so we’ll show you just one: eta squared.

00:03:40.880 --> 00:03:46.700
Effect sizes try to tell us how large an effect is compared to how much variation we generally expect.

00:03:46.700 --> 00:03:51.580
In a t-test, we recognize that a new negotiating
technique that only increases salaries by

00:03:51.580 --> 00:03:56.900
about $2 a year is not that exciting because
people’s salaries generally vary way more

00:03:56.900 --> 00:03:58.609
than $2 a year.

00:03:58.609 --> 00:04:00.519
Eta squared does the same thing for us.

00:04:00.519 --> 00:04:04.810
To calculate eta squared, you take the Sums
of Squares for your particular effect--in

00:04:04.810 --> 00:04:10.360
this case, car manufacturer--and divide it
by the Total Sums of Squares for your entire

00:04:10.360 --> 00:04:11.360
data set.

00:04:11.360 --> 00:04:13.090
Eta squared is always between 0 and 1.

00:04:13.090 --> 00:04:16.230
And its interpretation is like the interpretation
of R-squared.

00:04:16.230 --> 00:04:23.020
Eta squared tells you the proportion of total
Variation that’s accounted for by your specific variable.

00:04:23.020 --> 00:04:28.200
So here, in our made up data, we see that
46% of the variation in car price is accounted

00:04:28.210 --> 00:04:29.200
for by manufacturer.

00:04:29.210 --> 00:04:31.030
Sounds like a lot.

00:04:31.030 --> 00:04:35.150
But effect size is something that the person
analyzing the data will have to interpret

00:04:35.150 --> 00:04:36.150
for themselves.

00:04:36.150 --> 00:04:37.590
It can be pretty subjective.

00:04:37.590 --> 00:04:43.340
We might also be interested in how well our
entire model--with both manufacturer AND color--can

00:04:43.340 --> 00:04:45.260
predict sedan prices.

00:04:45.260 --> 00:04:49.530
Say we were designing this model for a car
selling website so that they can tell customers

00:04:49.530 --> 00:04:52.560
what they should expect to pay for their dream
car.

00:04:52.560 --> 00:04:59.560
They might ask us to calculate eta squared--which is here equivalent to R-squared--for our entire model.

00:04:59.560 --> 00:05:02.160
And we can do that the formula is exactly
the same.

00:05:02.169 --> 00:05:07.560
So, now we know that our entire model with
both factors accounts for about 48% of the

00:05:07.560 --> 00:05:09.060
variation in the data.

00:05:09.060 --> 00:05:13.770
If we could explain 100% variation, we could
perfectly predict car price.

00:05:13.770 --> 00:05:18.800
So 48% means we can predict about half the
variation while the rest is explained by other

00:05:18.800 --> 00:05:24.389
factors we did not include in our model, like
size of car and style of car, as well as error.

00:05:24.389 --> 00:05:28.710
We predicted car price using manufacturer
and color with a model assuming that these

00:05:28.710 --> 00:05:31.229
two factors are independent.

00:05:31.229 --> 00:05:35.750
But maybe color has very little effect on
the price of cars from less expensive brands

00:05:35.750 --> 00:05:40.949
like Toyota, Honda, or Chevrolet, whereas
if you’re getting a fancy Lamborghini, color

00:05:40.949 --> 00:05:41.979
may have an effect.

00:05:41.979 --> 00:05:45.069
A lot of people want that bright orange lambo.

00:05:45.069 --> 00:05:48.699
If this were the case, then these two factors
are not independent.

00:05:48.699 --> 00:05:51.770
The effect of color depends on which manufacturer
made the car.

00:05:51.770 --> 00:05:56.139
That’s called an interaction because the
two factors interact with each other.

00:05:56.139 --> 00:05:58.379
And these interactions can be really important.

00:05:58.379 --> 00:06:03.580
Let’s move on from cars and look at how
professional and novice olive oil tasters

00:06:03.580 --> 00:06:04.580
rate olive oil.

00:06:04.580 --> 00:06:06.169
You’re opening an olive oil shop.

00:06:06.169 --> 00:06:09.509
You’ve already traveled the world in search
of the best olives, you’ve learned how to

00:06:09.509 --> 00:06:11.759
extract and process the best oil.

00:06:11.759 --> 00:06:16.020
But as you’re putting the finishing touches
on your storefront and marketing plan, you

00:06:16.020 --> 00:06:17.199
run into an issue.

00:06:17.199 --> 00:06:20.300
You’re not sure how to bottle your oils.

00:06:20.300 --> 00:06:25.950
You could shell out a lot of money for very
Instagrammable fancy bottles or save some

00:06:25.950 --> 00:06:30.229
money and go with a simpler bottle (letting
your oil speak for itself).

00:06:30.229 --> 00:06:33.790
Since you’ve been watching Crash Course
Statistics, you decide to run a small experiment.

00:06:33.790 --> 00:06:39.139
First, you gather two groups of people: olive
oil experts and olive oil novices since those

00:06:39.139 --> 00:06:41.010
are your two main customer groups.

00:06:41.010 --> 00:06:45.629
Then, you give them your delicious olive oil
from both a fancy and a plain bottle, and

00:06:45.629 --> 00:06:48.450
ask them to rate their overall impressions.

00:06:48.450 --> 00:06:52.729
Once you collect your data, you conduct a
TWO-WAY ANOVA, just like the one we did earlier.

00:06:52.729 --> 00:06:56.199
This time, our TWO factors are expertise and
bottle style.

00:06:56.199 --> 00:06:58.370
Two, hence two-way ANOVA.

00:06:58.370 --> 00:07:02.389
But you’re curious to see whether expertise
and bottle style interact.

00:07:02.389 --> 00:07:05.520
So you add one more thing to your model, the
interaction Term.

00:07:05.520 --> 00:07:10.500
We won’t dwell on the math here, but this
new interaction term is calculated similarly

00:07:10.500 --> 00:07:11.990
to all our other terms.

00:07:11.990 --> 00:07:16.240
Since there are 4 different combinations of
our two factors--expert with fancy bottle,

00:07:16.240 --> 00:07:20.919
expert with plain bottle, novice with fancy
bottle, novice with plain bottle-- we calculate

00:07:20.919 --> 00:07:25.409
the sum of the squared distance between the
mean of each of these 4 groups, and the overall

00:07:25.409 --> 00:07:27.090
mean for each point.

00:07:27.090 --> 00:07:30.189
This is sometimes called the Sums of Squares
Between Groups.

00:07:30.189 --> 00:07:33.470
Also, SSB - Sums of Squares Between Groups.

00:07:33.470 --> 00:07:38.360
Then from the Sums of Squares Between Groups,
we subtract the sums of squares for each factor

00:07:38.360 --> 00:07:41.110
in the interaction: expertise and bottle.

00:07:41.110 --> 00:07:46.409
Sums of Squares Between Groups tell us how
much variation is explained by coming from

00:07:46.409 --> 00:07:51.360
one of the four possible combinations of olive
oil expertise and bottle type.

00:07:51.360 --> 00:07:55.820
When we subtracted the main effects of Expertise
and Bottle Type, we were left with the amount

00:07:55.820 --> 00:08:00.580
of variation explained by how these two factors
influence each other.

00:08:00.580 --> 00:08:04.330
Here we can seen the means of all four combinations
of Expertise and Bottle Type.

00:08:04.330 --> 00:08:09.960
This type of plot is called an interaction
plot, because it shows how these two factors interact.

00:08:09.960 --> 00:08:13.740
The blue line represents Experts, and the
red line, Novices.

00:08:13.760 --> 00:08:18.310
You can see that experts rated both bottles
of olive oil similarly, they weren’t swayed

00:08:18.310 --> 00:08:19.680
by the fancy bottle.

00:08:19.680 --> 00:08:25.520
But novices rated olive oil in the fancier
bottles higher than olive oil in the simple ones.

00:08:25.520 --> 00:08:30.780
It seems like the effect of bottle style on
olive oil ratings is different depending on

00:08:30.780 --> 00:08:33.080
whether you’re an expert or a novice.

00:08:33.080 --> 00:08:36.540
This indicates that there’s an interaction
between these two factors.

00:08:36.540 --> 00:08:41.310
If there were NO interaction between Expertise
and Bottle Type, we’d expect the red and

00:08:41.310 --> 00:08:44.210
the blue line to be approximately parallel.

00:08:44.210 --> 00:08:48.500
This would tell us that regardless of expertise,
bottle type has a similar effect.

00:08:48.500 --> 00:08:50.680
(In this case, both prefer the fancy bottle.)

00:08:50.680 --> 00:08:52.970
But, we’ve only looked at graphs so far.

00:08:52.970 --> 00:08:55.630
Let’s pull up the ANOVA table for this model.

00:08:55.630 --> 00:08:59.960
Based on our table, we can see that neither
Expertise alone, nor Bottle Type alone are

00:08:59.960 --> 00:09:03.930
significant but their interaction is.

00:09:03.930 --> 00:09:08.840
When we look at how Experts rate both bottle
types, and Novices rate both bottle types,

00:09:08.850 --> 00:09:13.520
we can see a clear difference, represented
by the different slopes of our red and blue lines.

00:09:13.520 --> 00:09:18.520
And just like before, we can take our significant
effects and calculate an effect size for them,

00:09:18.530 --> 00:09:22.160
so that we can see how practically significant
it is.

00:09:22.160 --> 00:09:27.190
In this case, the amount of variation in our
data due to the interaction between expertise

00:09:27.190 --> 00:09:28.190
and bottle type.

00:09:28.190 --> 00:09:31.320
To get effect size, we just divide by the
total variation.

00:09:31.320 --> 00:09:36.111
In our last example, we talked about eta squared,
which is one way to calculate effect sizes

00:09:36.111 --> 00:09:41.230
for ANOVAs, and is analogous to the R^2 formula
we talked about for regression.

00:09:41.230 --> 00:09:45.280
To calculate eta squared, you just take the
Sums of Squares for your desired effect, and

00:09:45.280 --> 00:09:47.870
divide by the total sums of squares.

00:09:47.870 --> 00:09:52.800
In this case, the interaction effect of bottle
type and expertise accounts for about 9.14%

00:09:52.800 --> 00:09:55.570
of the total variation in the data.

00:09:55.570 --> 00:10:00.190
Effect sizes tell you something about the
magnitude of an effect, but it’s up to you--or

00:10:00.190 --> 00:10:05.230
whoever is analyzing the data--to decide whether
an effect of that size is useful.

00:10:05.230 --> 00:10:09.110
In our model, we only had one significant
effect: the interaction.

00:10:09.110 --> 00:10:12.280
But occasionally we’ll see other significant
effects.

00:10:12.280 --> 00:10:16.420
Single variables, like Bottle Type and Expertise,
are called main effects.

00:10:16.420 --> 00:10:20.800
Statistically significant main effects are
important, but when you interpret them, you

00:10:20.810 --> 00:10:22.400
need to do so with caution.

00:10:22.410 --> 00:10:27.250
For example, if we looked at a study of an
allergy medication, we might observe a significant

00:10:27.250 --> 00:10:31.170
main effect of medication on allergy symptoms.

00:10:31.170 --> 00:10:36.140
Which means that on average, people who took
the medication had less severe symptoms than

00:10:36.140 --> 00:10:37.380
those who didn’t take it.

00:10:37.380 --> 00:10:42.880
But, we also recorded whether or not the subjects
had a certain allergy related gene, gene Y.

00:10:42.880 --> 00:10:47.230
It turns out that there’s a significant
interaction between allergy medication and

00:10:47.230 --> 00:10:49.600
whether or not you have gene Y.

00:10:49.600 --> 00:10:53.770
If you DO have gene Y, the medication doesn’t
work that well.

00:10:53.770 --> 00:10:56.010
In fact, you’ll feel about the same.

00:10:56.010 --> 00:11:00.920
But if you DON’T have gene Y, it works incredibly
well all of a sudden your sneezes are gone!

00:11:00.920 --> 00:11:05.380
If you told everyone that this allergy medication worked….it wouldn’t quite be the whole truth.

00:11:05.380 --> 00:11:11.260
That significant interaction told us that
while on average people displayed fewer symptoms

00:11:11.260 --> 00:11:16.920
on the medication, that allergy relief is
different depending on whether you have gene Y.

00:11:16.920 --> 00:11:21.560
The different slopes for each of our lines
in this interaction plot demonstrate how the

00:11:21.570 --> 00:11:23.760
two groups respond differently.

00:11:23.760 --> 00:11:25.210
Back to your olive oil shop.

00:11:25.210 --> 00:11:28.660
Looking at the data you have--seems like you
should go with the fancy bottles.

00:11:28.660 --> 00:11:33.870
The experts won’t be swayed but the rest
of your customers will like all the embellishment.

00:11:33.870 --> 00:11:37.080
And there’s only a couple olive oil professionals
in your town.

00:11:37.080 --> 00:11:41.530
People, cells, animals, and pretty much anything
we might be interested in measuring, are parts

00:11:41.530 --> 00:11:42.850
of multiple groups.

00:11:42.850 --> 00:11:48.600
So it’s important to have the tools to consider multiple groups together with a statistical model.

00:11:48.600 --> 00:11:52.600
They allow us to have a richer understanding
of how certain things might interact.

00:11:52.600 --> 00:11:56.740
Like your gender and your ethnicity and your
pay.

00:11:56.740 --> 00:12:00.800
Or your age and generation and favorite slurpee
flavor.

00:12:00.800 --> 00:12:03.320
Thanks for watching, I’ll see you next time.

