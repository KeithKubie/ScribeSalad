WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
So now we've learned all about Linear GraphSLAM,

00:00:02.000 --> 00:00:04.000
and that's quite a bit--and it's really simple.

00:00:04.000 --> 00:00:06.000
Every time there's a constraint--

00:00:06.000 --> 00:00:09.000
Initial Position, Motion or Measurement--

00:00:09.000 --> 00:00:14.000
we take this constraint and add something to Omega, Xi.

00:00:14.000 --> 00:00:17.000
And what we add is the constraint itself,

00:00:17.000 --> 00:00:20.000
but it's up multiplied by a strength factor.

00:00:20.000 --> 00:00:22.000
There's nothing else but 1 over sigma--

00:00:22.000 --> 00:00:25.000
the uncertainty in Motion or in Measurements.

00:00:25.000 --> 00:00:27.000
And then when we're done with this adding--

00:00:27.000 --> 00:00:29.000
we simply calculate this guy

00:00:29.000 --> 00:00:31.000
and out comes our best possible PATH--

00:00:31.000 --> 00:00:35.000
and along with the MAP of all the landmarks.

00:00:35.000 --> 00:00:38.000
Isn't that something? Isn't that really cool?

00:00:38.000 --> 00:00:44.000
So let's dive in and have you program your own real robot example.

00:00:44.000 --> 00:00:48.000
This is a fairly complicated generalization of what we just saw.

00:00:48.000 --> 00:00:50.000
I'm giving you an environment where you can specify

00:00:50.000 --> 00:00:52.000
the number of landmarks that exist,

00:00:52.000 --> 00:00:55.000
the number of time steps you want the robot to run,

00:00:55.000 --> 00:00:58.000
the world_size, the measurement_range--that is

00:00:58.000 --> 00:01:01.000
the range at which a robot might be able to see a landmark--

00:01:01.000 --> 00:01:03.000
if it's further away than this--it just won't see it;

00:01:03.000 --> 00:01:06.000
a motion_noise, a measurement_noise,

00:01:06.000 --> 00:01:08.000
and a distance parameter.

00:01:08.000 --> 00:01:11.000
The distance specifies how fast a robot moves in each step.

00:01:11.000 --> 00:01:14.000
And then I'm giving you a routine which makes the data.

00:01:14.000 --> 00:01:19.000
It takes all these parameters and it outputs a data field

00:01:19.000 --> 00:01:24.000
that contains a sequence of motions and a sequence of measurements.

00:01:24.000 --> 00:01:28.000
The code comments on the exact format of what data looks like.

00:01:28.000 --> 00:01:30.000
Now I want you to program the function, SLAM,

00:01:30.000 --> 00:01:33.000
that inputs the data and various important parameters

00:01:33.000 --> 00:01:39.000
and it outputs my result--a sequence of estimated poses,

00:01:39.000 --> 00:01:43.000
the robot PATH, and estimated landmark positions.

00:01:43.000 --> 00:01:45.000
This is really challenging to program.

00:01:45.000 --> 00:01:47.000
It's based on the math I just gave you.

00:01:47.000 --> 00:01:50.000
The robot coordinates are now x and y coordinates.

00:01:50.000 --> 00:01:53.000
The measurements are differences in x and y--

00:01:53.000 --> 00:01:57.000
so you have to duplicate things for x and things for y.

00:01:57.000 --> 00:01:59.000
I, myself, put them all into one big matrix,

00:01:59.000 --> 00:02:02.000
but you could have them in 2 separate matrices, if you so wish.

00:02:02.000 --> 00:02:05.000
You have to apply everything we learned so far,

00:02:05.000 --> 00:02:07.000
including the weights of one with our measurerment_noise

00:02:07.000 --> 00:02:09.000
and one with our motion_noise.

00:02:09.000 --> 00:02:12.000
These happen to be equivalent, in this case--but they might be different.

00:02:12.000 --> 00:02:15.000
And then you have to run SLAM

00:02:15.000 --> 00:02:18.000
and return back to me a result data structure.

00:02:18.000 --> 00:02:21.000
I'm also supplying you with the print_result routine

00:02:21.000 --> 00:02:24.000
so you can go in and see how the result has to look like.

00:02:24.000 --> 00:02:27.000
There's an example routine--that doesn't work--

00:02:27.000 --> 00:02:29.000
that outputs all the correct formats,

00:02:29.000 --> 00:02:33.000
but it tries not to implement the estimate that I want you to estimate.

00:02:33.000 --> 00:02:35.000
You have to bring this to life

00:02:35.000 --> 00:02:38.000
and turn this into an amazing SLAM routine

00:02:38.000 --> 00:02:41.000
so that when you run it, you get the same results that I do

00:02:41.000 --> 00:02:43.000
for the examples here,

00:02:43.000 --> 00:02:45.000
where there's an estimated PATH

00:02:45.000 --> 00:02:47.000
and estimated landmark positions.

00:02:47.000 --> 00:02:49.000
There's one last thing I wanted to know--

00:02:49.000 --> 00:02:52.000
is I assume the initial robot position

00:02:52.000 --> 00:02:54.000
is going to be in the center of the world.

00:02:54.000 --> 00:02:57.000
So it's the real-world set of 100

00:02:57.000 --> 00:03:00.000
and it's going to be 50/50--or here it's printed as 49.999,

00:03:00.000 --> 00:03:02.000
but this is the same as 50.

00:03:02.000 --> 00:03:04.000
So you have to put in a constraint

00:03:04.000 --> 00:03:06.000
that sets the initial robot pose

00:03:06.000 --> 09:59:59.000
to the center of the world.

