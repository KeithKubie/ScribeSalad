WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.149 align:start position:0%
 
in<00:00:00.840><c> this</c><00:00:01.170><c> video</c><00:00:01.439><c> we'll</c><00:00:01.620><c> mention</c><00:00:02.040><c> an</c>

00:00:02.149 --> 00:00:02.159 align:start position:0%
in this video we'll mention an
 

00:00:02.159 --> 00:00:03.830 align:start position:0%
in this video we'll mention an
alternative<00:00:02.790><c> to</c><00:00:03.000><c> maximum</c><00:00:03.510><c> likelihood</c>

00:00:03.830 --> 00:00:03.840 align:start position:0%
alternative to maximum likelihood
 

00:00:03.840 --> 00:00:05.900 align:start position:0%
alternative to maximum likelihood
training<00:00:04.290><c> of</c><00:00:04.560><c> conditional</c><00:00:05.130><c> random</c><00:00:05.339><c> fields</c>

00:00:05.900 --> 00:00:05.910 align:start position:0%
training of conditional random fields
 

00:00:05.910 --> 00:00:10.580 align:start position:0%
training of conditional random fields
known<00:00:06.240><c> as</c><00:00:06.629><c> sort</c><00:00:07.350><c> of</c><00:00:07.379><c> likelihood</c><00:00:09.410><c> so</c><00:00:10.410><c> we've</c>

00:00:10.580 --> 00:00:10.590 align:start position:0%
known as sort of likelihood so we've
 

00:00:10.590 --> 00:00:13.339 align:start position:0%
known as sort of likelihood so we've
seen<00:00:10.950><c> in</c><00:00:11.219><c> the</c><00:00:11.309><c> previous</c><00:00:11.519><c> video</c><00:00:11.759><c> that</c><00:00:12.170><c> we</c><00:00:13.170><c> could</c>

00:00:13.339 --> 00:00:13.349 align:start position:0%
seen in the previous video that we could
 

00:00:13.349 --> 00:00:17.210 align:start position:0%
seen in the previous video that we could
get<00:00:13.469><c> an</c><00:00:13.620><c> expression</c><00:00:13.920><c> for</c><00:00:14.400><c> the</c><00:00:16.100><c> negative</c><00:00:17.100><c> log</c>

00:00:17.210 --> 00:00:17.220 align:start position:0%
get an expression for the negative log
 

00:00:17.220 --> 00:00:20.599 align:start position:0%
get an expression for the negative log
likelihood<00:00:17.699><c> gradients</c><00:00:18.859><c> with</c><00:00:19.859><c> respect</c><00:00:20.250><c> to</c><00:00:20.430><c> the</c>

00:00:20.599 --> 00:00:20.609 align:start position:0%
likelihood gradients with respect to the
 

00:00:20.609 --> 00:00:23.269 align:start position:0%
likelihood gradients with respect to the
parameters<00:00:21.090><c> which</c><00:00:21.300><c> allows</c><00:00:21.600><c> us</c><00:00:21.869><c> to</c><00:00:22.170><c> then</c><00:00:22.949><c> you</c>

00:00:23.269 --> 00:00:23.279 align:start position:0%
parameters which allows us to then you
 

00:00:23.279 --> 00:00:25.370 align:start position:0%
parameters which allows us to then you
know<00:00:23.400><c> get</c><00:00:23.640><c> away</c><00:00:24.060><c> an</c><00:00:24.600><c> expression</c><00:00:25.080><c> to</c><00:00:25.230><c> compute</c>

00:00:25.370 --> 00:00:25.380 align:start position:0%
know get away an expression to compute
 

00:00:25.380 --> 00:00:27.439 align:start position:0%
know get away an expression to compute
for<00:00:26.099><c> performing</c><00:00:26.519><c> gradient</c><00:00:26.910><c> descent</c><00:00:27.269><c> and</c>

00:00:27.439 --> 00:00:27.449 align:start position:0%
for performing gradient descent and
 

00:00:27.449 --> 00:00:29.210 align:start position:0%
for performing gradient descent and
perform<00:00:27.840><c> minimize</c><00:00:28.650><c> the</c><00:00:28.769><c> negative</c><00:00:28.859><c> log</c>

00:00:29.210 --> 00:00:29.220 align:start position:0%
perform minimize the negative log
 

00:00:29.220 --> 00:00:30.980 align:start position:0%
perform minimize the negative log
likelihood<00:00:29.670><c> so</c><00:00:29.820><c> perform</c><00:00:30.179><c> maximum</c><00:00:30.599><c> likelihood</c>

00:00:30.980 --> 00:00:30.990 align:start position:0%
likelihood so perform maximum likelihood
 

00:00:30.990 --> 00:00:32.900 align:start position:0%
likelihood so perform maximum likelihood
training<00:00:31.529><c> of</c><00:00:31.710><c> our</c><00:00:31.890><c> conditional</c><00:00:32.399><c> random</c><00:00:32.520><c> field</c>

00:00:32.900 --> 00:00:32.910 align:start position:0%
training of our conditional random field
 

00:00:32.910 --> 00:00:35.209 align:start position:0%
training of our conditional random field
however<00:00:33.660><c> it</c><00:00:33.930><c> did</c><00:00:34.140><c> involve</c><00:00:34.620><c> an</c><00:00:34.920><c> expectation</c>

00:00:35.209 --> 00:00:35.219 align:start position:0%
however it did involve an expectation
 

00:00:35.219 --> 00:00:41.000 align:start position:0%
however it did involve an expectation
over<00:00:36.260><c> the</c><00:00:37.260><c> label</c><00:00:38.780><c> or</c><00:00:39.780><c> the</c><00:00:39.930><c> target</c><00:00:40.410><c> vector</c><00:00:40.770><c> Y</c>

00:00:41.000 --> 00:00:41.010 align:start position:0%
over the label or the target vector Y
 

00:00:41.010 --> 00:00:44.209 align:start position:0%
over the label or the target vector Y
and<00:00:41.600><c> while</c><00:00:42.600><c> it</c><00:00:42.750><c> might</c><00:00:42.899><c> only</c><00:00:43.110><c> involve</c><00:00:43.680><c> a</c><00:00:44.010><c> few</c>

00:00:44.209 --> 00:00:44.219 align:start position:0%
and while it might only involve a few
 

00:00:44.219 --> 00:00:46.340 align:start position:0%
and while it might only involve a few
variables<00:00:44.520><c> it</c><00:00:44.969><c> still</c><00:00:45.270><c> requires</c><00:00:45.629><c> performing</c>

00:00:46.340 --> 00:00:46.350 align:start position:0%
variables it still requires performing
 

00:00:46.350 --> 00:00:48.020 align:start position:0%
variables it still requires performing
an<00:00:46.530><c> inference</c><00:00:47.070><c> of</c><00:00:47.280><c> what</c><00:00:47.430><c> the</c><00:00:47.579><c> marginal</c>

00:00:48.020 --> 00:00:48.030 align:start position:0%
an inference of what the marginal
 

00:00:48.030 --> 00:00:50.900 align:start position:0%
an inference of what the marginal
distribution<00:00:48.600><c> over</c><00:00:48.750><c> the</c><00:00:49.340><c> subset</c><00:00:50.340><c> of</c><00:00:50.370><c> labels</c>

00:00:50.900 --> 00:00:50.910 align:start position:0%
distribution over the subset of labels
 

00:00:50.910 --> 00:00:53.930 align:start position:0%
distribution over the subset of labels
that<00:00:51.120><c> are</c><00:00:51.180><c> involved</c><00:00:51.629><c> in</c><00:00:51.719><c> the</c><00:00:51.840><c> gradient</c><00:00:52.940><c> might</c>

00:00:53.930 --> 00:00:53.940 align:start position:0%
that are involved in the gradient might
 

00:00:53.940 --> 00:00:55.939 align:start position:0%
that are involved in the gradient might
be<00:00:54.149><c> so</c><00:00:54.360><c> we</c><00:00:54.510><c> have</c><00:00:54.899><c> to</c><00:00:55.050><c> perform</c><00:00:55.469><c> that</c><00:00:55.590><c> inference</c>

00:00:55.939 --> 00:00:55.949 align:start position:0%
be so we have to perform that inference
 

00:00:55.949 --> 00:01:01.180 align:start position:0%
be so we have to perform that inference
and<00:00:56.280><c> unless</c><00:00:57.120><c> we</c><00:00:57.360><c> have</c><00:00:57.539><c> a</c><00:00:59.420><c> graph</c><00:01:00.420><c> which</c><00:01:00.899><c> is</c>

00:01:01.180 --> 00:01:01.190 align:start position:0%
and unless we have a graph which is
 

00:01:01.190 --> 00:01:05.600 align:start position:0%
and unless we have a graph which is
linear<00:01:02.190><c> chain</c><00:01:02.489><c> or</c><00:01:02.850><c> a</c><00:01:02.910><c> tree</c><00:01:03.589><c> this</c><00:01:04.610><c> this</c>

00:01:05.600 --> 00:01:05.610 align:start position:0%
linear chain or a tree this this
 

00:01:05.610 --> 00:01:09.560 align:start position:0%
linear chain or a tree this this
approximate<00:01:06.299><c> inference</c><00:01:07.159><c> so</c><00:01:08.390><c> estimating</c><00:01:09.390><c> this</c>

00:01:09.560 --> 00:01:09.570 align:start position:0%
approximate inference so estimating this
 

00:01:09.570 --> 00:01:12.370 align:start position:0%
approximate inference so estimating this
marginal<00:01:10.080><c> Diskin</c><00:01:10.950><c> ditional</c><00:01:11.220><c> distribution</c>

00:01:12.370 --> 00:01:12.380 align:start position:0%
marginal Diskin ditional distribution
 

00:01:12.380 --> 00:01:14.600 align:start position:0%
marginal Diskin ditional distribution
it's<00:01:13.380><c> just</c><00:01:13.590><c> an</c><00:01:13.710><c> approximation</c><00:01:14.220><c> it</c><00:01:14.460><c> might</c>

00:01:14.600 --> 00:01:14.610 align:start position:0%
it's just an approximation it might
 

00:01:14.610 --> 00:01:17.120 align:start position:0%
it's just an approximation it might
actually<00:01:14.790><c> be</c><00:01:15.150><c> very</c><00:01:15.479><c> bad</c><00:01:15.689><c> in</c><00:01:15.869><c> practice</c><00:01:16.320><c> so</c><00:01:16.950><c> some</c>

00:01:17.120 --> 00:01:17.130 align:start position:0%
actually be very bad in practice so some
 

00:01:17.130 --> 00:01:19.670 align:start position:0%
actually be very bad in practice so some
people<00:01:17.220><c> have</c><00:01:17.400><c> explored</c><00:01:17.939><c> instead</c><00:01:18.680><c> an</c>

00:01:19.670 --> 00:01:19.680 align:start position:0%
people have explored instead an
 

00:01:19.680 --> 00:01:21.789 align:start position:0%
people have explored instead an
alternative<00:01:20.310><c> which</c><00:01:20.700><c> is</c><00:01:20.850><c> to</c><00:01:21.030><c> just</c><00:01:21.210><c> do</c><00:01:21.479><c> without</c>

00:01:21.789 --> 00:01:21.799 align:start position:0%
alternative which is to just do without
 

00:01:21.799 --> 00:01:23.600 align:start position:0%
alternative which is to just do without
maximum<00:01:22.799><c> likelihood</c><00:01:23.040><c> training</c><00:01:23.400><c> and</c><00:01:23.549><c> just</c>

00:01:23.600 --> 00:01:23.610 align:start position:0%
maximum likelihood training and just
 

00:01:23.610 --> 00:01:25.940 align:start position:0%
maximum likelihood training and just
change<00:01:23.939><c> the</c><00:01:24.000><c> last</c><00:01:24.299><c> function</c><00:01:24.509><c> to</c><00:01:25.259><c> be</c><00:01:25.409><c> used</c><00:01:25.650><c> for</c>

00:01:25.940 --> 00:01:25.950 align:start position:0%
change the last function to be used for
 

00:01:25.950 --> 00:01:29.230 align:start position:0%
change the last function to be used for
training<00:01:26.490><c> the</c><00:01:26.700><c> conditional</c><00:01:27.270><c> random</c><00:01:27.390><c> field</c><00:01:27.780><c> I</c>

00:01:29.230 --> 00:01:29.240 align:start position:0%
training the conditional random field I
 

00:01:29.240 --> 00:01:31.550 align:start position:0%
training the conditional random field I
just<00:01:30.240><c> want</c><00:01:30.390><c> to</c><00:01:30.450><c> mention</c><00:01:30.570><c> one</c><00:01:31.049><c> such</c><00:01:31.380><c> approach</c>

00:01:31.550 --> 00:01:31.560 align:start position:0%
just want to mention one such approach
 

00:01:31.560 --> 00:01:35.090 align:start position:0%
just want to mention one such approach
which<00:01:32.189><c> is</c><00:01:32.369><c> known</c><00:01:32.549><c> as</c><00:01:32.729><c> pseudo</c><00:01:33.360><c> likelihood</c><00:01:34.100><c> so</c>

00:01:35.090 --> 00:01:35.100 align:start position:0%
which is known as pseudo likelihood so
 

00:01:35.100 --> 00:01:38.060 align:start position:0%
which is known as pseudo likelihood so
the<00:01:35.670><c> idea</c><00:01:36.210><c> is</c><00:01:36.420><c> that</c><00:01:36.450><c> instead</c><00:01:37.020><c> of</c><00:01:37.259><c> trying</c><00:01:37.950><c> to</c>

00:01:38.060 --> 00:01:38.070 align:start position:0%
the idea is that instead of trying to
 

00:01:38.070 --> 00:01:40.429 align:start position:0%
the idea is that instead of trying to
maximize<00:01:38.340><c> the</c><00:01:38.939><c> probability</c><00:01:39.150><c> of</c><00:01:39.659><c> the</c><00:01:39.930><c> whole</c><00:01:40.170><c> Y</c>

00:01:40.429 --> 00:01:40.439 align:start position:0%
maximize the probability of the whole Y
 

00:01:40.439 --> 00:01:43.870 align:start position:0%
maximize the probability of the whole Y
vector<00:01:40.710><c> given</c><00:01:41.250><c> the</c><00:01:41.909><c> input</c><00:01:42.299><c> we</c><00:01:43.290><c> might</c><00:01:43.439><c> want</c><00:01:43.649><c> to</c>

00:01:43.870 --> 00:01:43.880 align:start position:0%
vector given the input we might want to
 

00:01:43.880 --> 00:01:48.020 align:start position:0%
vector given the input we might want to
maximize<00:01:44.880><c> instead</c><00:01:45.420><c> each</c><00:01:46.290><c> of</c><00:01:46.740><c> the</c><00:01:47.040><c> conditional</c>

00:01:48.020 --> 00:01:48.030 align:start position:0%
maximize instead each of the conditional
 

00:01:48.030 --> 00:01:52.069 align:start position:0%
maximize instead each of the conditional
of<00:01:48.299><c> each</c><00:01:49.290><c> YK</c><00:01:49.770><c> given</c><00:01:50.640><c> everything</c><00:01:51.329><c> else</c><00:01:51.540><c> so</c><00:01:51.869><c> all</c>

00:01:52.069 --> 00:01:52.079 align:start position:0%
of each YK given everything else so all
 

00:01:52.079 --> 00:01:54.289 align:start position:0%
of each YK given everything else so all
otherwise<00:01:52.380><c> and</c><00:01:53.009><c> the</c><00:01:53.340><c> input</c><00:01:53.700><c> so</c><00:01:54.180><c> one</c>

00:01:54.289 --> 00:01:54.299 align:start position:0%
otherwise and the input so one
 

00:01:54.299 --> 00:01:57.560 align:start position:0%
otherwise and the input so one
specifically<00:01:54.780><c> will</c><00:01:55.549><c> minimize</c><00:01:56.549><c> the</c><00:01:56.850><c> negative</c>

00:01:57.560 --> 00:01:57.570 align:start position:0%
specifically will minimize the negative
 

00:01:57.570 --> 00:02:01.819 align:start position:0%
specifically will minimize the negative
sum<00:01:58.409><c> of</c><00:01:58.680><c> the</c><00:01:59.399><c> log</c><00:01:59.670><c> of</c><00:02:00.030><c> the</c><00:02:00.329><c> probability</c><00:02:00.540><c> of</c><00:02:01.350><c> the</c>

00:02:01.819 --> 00:02:01.829 align:start position:0%
sum of the log of the probability of the
 

00:02:01.829 --> 00:02:05.209 align:start position:0%
sum of the log of the probability of the
true<00:02:02.219><c> label</c><00:02:02.759><c> at</c><00:02:03.060><c> position</c><00:02:03.600><c> K</c><00:02:03.630><c> given</c><00:02:04.590><c> all</c><00:02:04.770><c> other</c>

00:02:05.209 --> 00:02:05.219 align:start position:0%
true label at position K given all other
 

00:02:05.219 --> 00:02:07.550 align:start position:0%
true label at position K given all other
labels<00:02:05.670><c> at</c><00:02:05.820><c> position</c><00:02:06.240><c> 1</c><00:02:06.479><c> up</c><00:02:06.750><c> to</c><00:02:06.899><c> K</c><00:02:07.049><c> minus</c><00:02:07.350><c> 1</c>

00:02:07.550 --> 00:02:07.560 align:start position:0%
labels at position 1 up to K minus 1
 

00:02:07.560 --> 00:02:12.290 align:start position:0%
labels at position 1 up to K minus 1
then<00:02:07.920><c> k</c><00:02:08.129><c> plus</c><00:02:08.369><c> 1</c><00:02:08.610><c> up</c><00:02:08.789><c> to</c><00:02:09.119><c> capital</c><00:02:09.959><c> K</c><00:02:10.910><c> so</c><00:02:11.910><c> you</c><00:02:11.970><c> can</c>

00:02:12.290 --> 00:02:12.300 align:start position:0%
then k plus 1 up to capital K so you can
 

00:02:12.300 --> 00:02:13.809 align:start position:0%
then k plus 1 up to capital K so you can
think<00:02:12.420><c> of</c><00:02:12.569><c> it</c><00:02:12.690><c> as</c><00:02:12.810><c> try</c><00:02:13.290><c> to</c>

00:02:13.809 --> 00:02:13.819 align:start position:0%
think of it as try to
 

00:02:13.819 --> 00:02:17.930 align:start position:0%
think of it as try to
in<00:02:14.819><c> turn</c><00:02:15.150><c> each</c><00:02:15.420><c> YK</c><00:02:15.840><c> not</c><00:02:16.800><c> just</c><00:02:17.010><c> from</c><00:02:17.130><c> X</c><00:02:17.400><c> but</c><00:02:17.700><c> from</c>

00:02:17.930 --> 00:02:17.940 align:start position:0%
in turn each YK not just from X but from
 

00:02:17.940 --> 00:02:20.800 align:start position:0%
in turn each YK not just from X but from
all<00:02:18.150><c> other</c><00:02:18.420><c> elements</c><00:02:18.810><c> in</c><00:02:19.110><c> the</c><00:02:19.410><c> vector</c><00:02:19.560><c> Y</c>

00:02:20.800 --> 00:02:20.810 align:start position:0%
all other elements in the vector Y
 

00:02:20.810 --> 00:02:24.530 align:start position:0%
all other elements in the vector Y
what's<00:02:21.810><c> nice</c><00:02:22.050><c> is</c><00:02:22.350><c> that</c><00:02:22.910><c> for</c><00:02:23.910><c> this</c><00:02:24.060><c> expression</c>

00:02:24.530 --> 00:02:24.540 align:start position:0%
what's nice is that for this expression
 

00:02:24.540 --> 00:02:27.199 align:start position:0%
what's nice is that for this expression
we<00:02:24.690><c> can</c><00:02:24.720><c> usually</c><00:02:25.050><c> tractive</c><00:02:25.860><c> lis</c><00:02:26.040><c> compute</c><00:02:26.940><c> the</c>

00:02:27.199 --> 00:02:27.209 align:start position:0%
we can usually tractive lis compute the
 

00:02:27.209 --> 00:02:29.030 align:start position:0%
we can usually tractive lis compute the
exact<00:02:27.690><c> gradients</c><00:02:28.140><c> for</c><00:02:28.260><c> optimizing</c><00:02:28.709><c> that</c>

00:02:29.030 --> 00:02:29.040 align:start position:0%
exact gradients for optimizing that
 

00:02:29.040 --> 00:02:32.300 align:start position:0%
exact gradients for optimizing that
objective<00:02:30.140><c> so</c><00:02:31.140><c> and</c><00:02:31.470><c> that's</c><00:02:31.680><c> because</c><00:02:32.010><c> each</c><00:02:32.280><c> of</c>

00:02:32.300 --> 00:02:32.310 align:start position:0%
objective so and that's because each of
 

00:02:32.310 --> 00:02:34.100 align:start position:0%
objective so and that's because each of
these<00:02:32.580><c> conditionals</c><00:02:33.330><c> essentially</c><00:02:33.930><c> just</c>

00:02:34.100 --> 00:02:34.110 align:start position:0%
these conditionals essentially just
 

00:02:34.110 --> 00:02:36.559 align:start position:0%
these conditionals essentially just
require<00:02:34.590><c> that</c><00:02:35.010><c> we</c><00:02:35.190><c> normalize</c><00:02:35.700><c> over</c><00:02:36.420><c> all</c>

00:02:36.559 --> 00:02:36.569 align:start position:0%
require that we normalize over all
 

00:02:36.569 --> 00:02:40.280 align:start position:0%
require that we normalize over all
values<00:02:36.989><c> of</c><00:02:37.020><c> Y</c><00:02:37.350><c> k</c><00:02:37.800><c> and</c><00:02:38.330><c> usually</c><00:02:39.330><c> y</c><00:02:39.810><c> ki</c><00:02:39.870><c> will</c><00:02:40.080><c> take</c>

00:02:40.280 --> 00:02:40.290 align:start position:0%
values of Y k and usually y ki will take
 

00:02:40.290 --> 00:02:42.979 align:start position:0%
values of Y k and usually y ki will take
a<00:02:40.470><c> fairly</c><00:02:41.040><c> small</c><00:02:41.250><c> number</c><00:02:41.310><c> of</c><00:02:41.880><c> values</c><00:02:42.390><c> so</c><00:02:42.840><c> it's</c>

00:02:42.979 --> 00:02:42.989 align:start position:0%
a fairly small number of values so it's
 

00:02:42.989 --> 00:02:44.600 align:start position:0%
a fairly small number of values so it's
going<00:02:43.110><c> to</c><00:02:43.200><c> be</c><00:02:43.319><c> similar</c><00:02:43.830><c> to</c><00:02:43.860><c> performing</c><00:02:44.550><c> a</c>

00:02:44.600 --> 00:02:44.610 align:start position:0%
going to be similar to performing a
 

00:02:44.610 --> 00:02:46.820 align:start position:0%
going to be similar to performing a
regular<00:02:44.780><c> softmax</c><00:02:45.780><c> computation</c><00:02:46.530><c> and</c><00:02:46.709><c> a</c>

00:02:46.820 --> 00:02:46.830 align:start position:0%
regular softmax computation and a
 

00:02:46.830 --> 00:02:49.220 align:start position:0%
regular softmax computation and a
regular<00:02:47.459><c> neural</c><00:02:47.730><c> network</c><00:02:48.090><c> though</c><00:02:48.330><c> now</c><00:02:48.840><c> this</c>

00:02:49.220 --> 00:02:49.230 align:start position:0%
regular neural network though now this
 

00:02:49.230 --> 00:02:51.110 align:start position:0%
regular neural network though now this
probability<00:02:49.739><c> will</c><00:02:50.130><c> be</c><00:02:50.160><c> influenced</c><00:02:50.700><c> not</c><00:02:50.880><c> just</c>

00:02:51.110 --> 00:02:51.120 align:start position:0%
probability will be influenced not just
 

00:02:51.120 --> 00:02:53.150 align:start position:0%
probability will be influenced not just
by<00:02:51.239><c> the</c><00:02:51.300><c> input</c><00:02:51.690><c> but</c><00:02:51.840><c> also</c><00:02:51.989><c> by</c><00:02:52.290><c> other</c><00:02:52.590><c> label</c>

00:02:53.150 --> 00:02:53.160 align:start position:0%
by the input but also by other label
 

00:02:53.160 --> 00:02:55.820 align:start position:0%
by the input but also by other label
values<00:02:53.519><c> and</c><00:02:54.390><c> the</c><00:02:54.510><c> other</c><00:02:54.630><c> label</c><00:02:55.019><c> values</c><00:02:55.410><c> are</c>

00:02:55.820 --> 00:02:55.830 align:start position:0%
values and the other label values are
 

00:02:55.830 --> 00:02:58.100 align:start position:0%
values and the other label values are
actually<00:02:56.340><c> going</c><00:02:56.489><c> to</c><00:02:56.580><c> be</c><00:02:56.700><c> the</c><00:02:56.940><c> true</c><00:02:57.330><c> label</c>

00:02:58.100 --> 00:02:58.110 align:start position:0%
actually going to be the true label
 

00:02:58.110 --> 00:03:04.400 align:start position:0%
actually going to be the true label
values<00:02:58.530><c> in</c><00:02:59.370><c> the</c><00:02:59.730><c> target</c><00:03:00.650><c> vector</c><00:03:01.650><c> and</c><00:03:03.410><c> another</c>

00:03:04.400 --> 00:03:04.410 align:start position:0%
values in the target vector and another
 

00:03:04.410 --> 00:03:06.140 align:start position:0%
values in the target vector and another
thing<00:03:04.590><c> that's</c><00:03:04.769><c> nice</c><00:03:04.950><c> is</c><00:03:05.010><c> that</c><00:03:05.250><c> each</c><00:03:05.819><c> of</c><00:03:05.880><c> these</c>

00:03:06.140 --> 00:03:06.150 align:start position:0%
thing that's nice is that each of these
 

00:03:06.150 --> 00:03:08.720 align:start position:0%
thing that's nice is that each of these
conditionals<00:03:06.870><c> for</c><00:03:07.290><c> the</c><00:03:08.130><c> conditional</c><00:03:08.610><c> random</c>

00:03:08.720 --> 00:03:08.730 align:start position:0%
conditionals for the conditional random
 

00:03:08.730 --> 00:03:10.940 align:start position:0%
conditionals for the conditional random
field<00:03:09.120><c> is</c><00:03:09.480><c> typically</c><00:03:10.110><c> only</c><00:03:10.290><c> really</c><00:03:10.800><c> gonna</c>

00:03:10.940 --> 00:03:10.950 align:start position:0%
field is typically only really gonna
 

00:03:10.950 --> 00:03:13.490 align:start position:0%
field is typically only really gonna
depend<00:03:11.370><c> on</c><00:03:11.640><c> a</c><00:03:11.700><c> few</c><00:03:12.239><c> of</c><00:03:12.480><c> the</c><00:03:12.660><c> other</c><00:03:12.840><c> target</c>

00:03:13.490 --> 00:03:13.500 align:start position:0%
depend on a few of the other target
 

00:03:13.500 --> 00:03:15.350 align:start position:0%
depend on a few of the other target
variables<00:03:14.010><c> and</c><00:03:14.280><c> that's</c><00:03:14.850><c> because</c><00:03:15.120><c> of</c><00:03:15.269><c> the</c>

00:03:15.350 --> 00:03:15.360 align:start position:0%
variables and that's because of the
 

00:03:15.360 --> 00:03:17.509 align:start position:0%
variables and that's because of the
local<00:03:15.569><c> markov</c><00:03:16.050><c> property</c><00:03:16.319><c> of</c><00:03:16.860><c> a</c><00:03:17.040><c> conditional</c>

00:03:17.509 --> 00:03:17.519 align:start position:0%
local markov property of a conditional
 

00:03:17.519 --> 00:03:19.100 align:start position:0%
local markov property of a conditional
random<00:03:17.640><c> field</c><00:03:18.030><c> if</c><00:03:18.150><c> we</c><00:03:18.239><c> look</c><00:03:18.390><c> at</c><00:03:18.540><c> its</c><00:03:18.720><c> markup</c>

00:03:19.100 --> 00:03:19.110 align:start position:0%
random field if we look at its markup
 

00:03:19.110 --> 00:03:23.210 align:start position:0%
random field if we look at its markup
network<00:03:19.560><c> then</c><00:03:20.010><c> we</c><00:03:20.250><c> know</c><00:03:20.459><c> that</c><00:03:21.079><c> the</c><00:03:22.220><c> property</c>

00:03:23.210 --> 00:03:23.220 align:start position:0%
network then we know that the property
 

00:03:23.220 --> 00:03:25.729 align:start position:0%
network then we know that the property
of<00:03:23.370><c> YK</c><00:03:23.579><c> given</c><00:03:24.150><c> everything</c><00:03:24.390><c> else</c><00:03:24.720><c> reduces</c><00:03:25.500><c> to</c>

00:03:25.729 --> 00:03:25.739 align:start position:0%
of YK given everything else reduces to
 

00:03:25.739 --> 00:03:28.100 align:start position:0%
of YK given everything else reduces to
the<00:03:25.860><c> property</c><00:03:26.280><c> of</c><00:03:26.400><c> YK</c><00:03:26.610><c> given</c><00:03:27.450><c> only</c><00:03:27.660><c> its</c>

00:03:28.100 --> 00:03:28.110 align:start position:0%
the property of YK given only its
 

00:03:28.110 --> 00:03:30.080 align:start position:0%
the property of YK given only its
neighbors<00:03:28.620><c> so</c><00:03:28.799><c> it's</c><00:03:28.980><c> actually</c><00:03:29.340><c> going</c><00:03:29.489><c> to</c><00:03:29.700><c> be</c><00:03:29.850><c> a</c>

00:03:30.080 --> 00:03:30.090 align:start position:0%
neighbors so it's actually going to be a
 

00:03:30.090 --> 00:03:31.970 align:start position:0%
neighbors so it's actually going to be a
much<00:03:30.390><c> simpler</c><00:03:30.810><c> expression</c><00:03:31.350><c> than</c><00:03:31.530><c> just</c><00:03:31.799><c> this</c>

00:03:31.970 --> 00:03:31.980 align:start position:0%
much simpler expression than just this
 

00:03:31.980 --> 00:03:34.520 align:start position:0%
much simpler expression than just this
depending<00:03:32.850><c> on</c><00:03:32.970><c> the</c><00:03:33.090><c> graph</c><00:03:33.329><c> structure</c><00:03:34.260><c> on</c><00:03:34.410><c> the</c>

00:03:34.520 --> 00:03:34.530 align:start position:0%
depending on the graph structure on the
 

00:03:34.530 --> 00:03:39.199 align:start position:0%
depending on the graph structure on the
mark<00:03:34.739><c> of</c><00:03:34.890><c> network</c><00:03:36.380><c> so</c><00:03:37.380><c> that</c><00:03:38.100><c> being</c><00:03:38.790><c> said</c><00:03:38.880><c> with</c>

00:03:39.199 --> 00:03:39.209 align:start position:0%
mark of network so that being said with
 

00:03:39.209 --> 00:03:41.330 align:start position:0%
mark of network so that being said with
still<00:03:39.570><c> to</c><00:03:39.930><c> make</c><00:03:40.079><c> prediction</c><00:03:40.560><c> we</c><00:03:40.739><c> would</c><00:03:40.980><c> still</c>

00:03:41.330 --> 00:03:41.340 align:start position:0%
still to make prediction we would still
 

00:03:41.340 --> 00:03:43.699 align:start position:0%
still to make prediction we would still
normally<00:03:41.730><c> need</c><00:03:42.480><c> to</c><00:03:42.660><c> compute</c><00:03:43.140><c> the</c><00:03:43.290><c> marginal</c>

00:03:43.699 --> 00:03:43.709 align:start position:0%
normally need to compute the marginal
 

00:03:43.709 --> 00:03:45.650 align:start position:0%
normally need to compute the marginal
distribution<00:03:43.920><c> which</c><00:03:44.850><c> might</c><00:03:45.060><c> still</c><00:03:45.420><c> be</c>

00:03:45.650 --> 00:03:45.660 align:start position:0%
distribution which might still be
 

00:03:45.660 --> 00:03:47.870 align:start position:0%
distribution which might still be
intractable<00:03:46.440><c> so</c><00:03:46.890><c> it</c><00:03:46.980><c> makes</c><00:03:47.190><c> training</c><00:03:47.670><c> more</c>

00:03:47.870 --> 00:03:47.880 align:start position:0%
intractable so it makes training more
 

00:03:47.880 --> 00:03:49.940 align:start position:0%
intractable so it makes training more
tractable<00:03:48.359><c> but</c><00:03:48.660><c> at</c><00:03:48.900><c> test</c><00:03:49.350><c> time</c><00:03:49.530><c> we'll</c><00:03:49.739><c> make</c><00:03:49.890><c> a</c>

00:03:49.940 --> 00:03:49.950 align:start position:0%
tractable but at test time we'll make a
 

00:03:49.950 --> 00:03:52.250 align:start position:0%
tractable but at test time we'll make a
prediction<00:03:50.340><c> if</c><00:03:50.730><c> you</c><00:03:50.970><c> wanna</c><00:03:51.090><c> use</c><00:03:51.329><c> prediction</c>

00:03:52.250 --> 00:03:52.260 align:start position:0%
prediction if you wanna use prediction
 

00:03:52.260 --> 00:03:54.140 align:start position:0%
prediction if you wanna use prediction
based<00:03:52.410><c> on</c><00:03:52.560><c> the</c><00:03:52.680><c> marginals</c><00:03:53.190><c> we</c><00:03:53.549><c> still</c><00:03:53.880><c> have</c><00:03:54.030><c> to</c>

00:03:54.140 --> 00:03:54.150 align:start position:0%
based on the marginals we still have to
 

00:03:54.150 --> 00:03:56.319 align:start position:0%
based on the marginals we still have to
do<00:03:54.329><c> some</c><00:03:54.359><c> approximate</c><00:03:55.140><c> inference</c><00:03:55.350><c> so</c><00:03:56.070><c> that</c>

00:03:56.319 --> 00:03:56.329 align:start position:0%
do some approximate inference so that
 

00:03:56.329 --> 00:04:00.440 align:start position:0%
do some approximate inference so that
doesn't<00:03:57.329><c> entirely</c><00:03:57.630><c> solve</c><00:03:58.079><c> our</c><00:03:58.440><c> problem</c><00:03:59.450><c> so</c>

00:04:00.440 --> 00:04:00.450 align:start position:0%
doesn't entirely solve our problem so
 

00:04:00.450 --> 00:04:01.940 align:start position:0%
doesn't entirely solve our problem so
notice<00:04:00.780><c> that</c><00:04:00.810><c> the</c><00:04:01.290><c> reason</c><00:04:01.530><c> we</c><00:04:01.590><c> have</c><00:04:01.709><c> to</c><00:04:01.829><c> do</c>

00:04:01.940 --> 00:04:01.950 align:start position:0%
notice that the reason we have to do
 

00:04:01.950 --> 00:04:04.220 align:start position:0%
notice that the reason we have to do
this<00:04:02.160><c> and</c><00:04:02.430><c> that</c><00:04:02.940><c> this</c><00:04:03.150><c> isn't</c><00:04:03.450><c> a</c><00:04:03.510><c> problem</c><00:04:03.720><c> here</c>

00:04:04.220 --> 00:04:04.230 align:start position:0%
this and that this isn't a problem here
 

00:04:04.230 --> 00:04:06.500 align:start position:0%
this and that this isn't a problem here
is<00:04:04.410><c> that</c><00:04:04.440><c> here</c><00:04:05.370><c> we</c><00:04:05.519><c> are</c><00:04:05.640><c> conditioning</c><00:04:06.239><c> on</c><00:04:06.390><c> the</c>

00:04:06.500 --> 00:04:06.510 align:start position:0%
is that here we are conditioning on the
 

00:04:06.510 --> 00:04:09.170 align:start position:0%
is that here we are conditioning on the
true<00:04:06.780><c> labels</c><00:04:07.290><c> so</c><00:04:07.560><c> we</c><00:04:07.590><c> don't</c><00:04:07.799><c> have</c><00:04:07.980><c> to</c><00:04:08.180><c> infer</c>

00:04:09.170 --> 00:04:09.180 align:start position:0%
true labels so we don't have to infer
 

00:04:09.180 --> 00:04:11.330 align:start position:0%
true labels so we don't have to infer
what<00:04:09.630><c> the</c><00:04:09.989><c> other</c><00:04:10.170><c> labels</c><00:04:10.440><c> might</c><00:04:10.890><c> be</c><00:04:11.100><c> we</c>

00:04:11.330 --> 00:04:11.340 align:start position:0%
what the other labels might be we
 

00:04:11.340 --> 00:04:12.949 align:start position:0%
what the other labels might be we
actually<00:04:11.400><c> know</c><00:04:11.820><c> them</c><00:04:12.030><c> at</c><00:04:12.150><c> training</c><00:04:12.540><c> time</c><00:04:12.750><c> so</c>

00:04:12.949 --> 00:04:12.959 align:start position:0%
actually know them at training time so
 

00:04:12.959 --> 00:04:14.539 align:start position:0%
actually know them at training time so
we<00:04:13.079><c> exploiting</c><00:04:13.590><c> that</c><00:04:13.739><c> at</c><00:04:13.890><c> training</c><00:04:14.190><c> time</c><00:04:14.370><c> but</c>

00:04:14.539 --> 00:04:14.549 align:start position:0%
we exploiting that at training time but
 

00:04:14.549 --> 00:04:17.090 align:start position:0%
we exploiting that at training time but
at<00:04:14.640><c> test</c><00:04:14.880><c> time</c><00:04:14.940><c> we</c><00:04:15.209><c> can't</c><00:04:15.450><c> and</c><00:04:15.720><c> I</c><00:04:16.650><c> should</c><00:04:16.919><c> say</c>

00:04:17.090 --> 00:04:17.100 align:start position:0%
at test time we can't and I should say
 

00:04:17.100 --> 00:04:18.770 align:start position:0%
at test time we can't and I should say
that<00:04:17.130><c> in</c><00:04:17.489><c> practice</c><00:04:18.000><c> we</c><00:04:18.150><c> often</c><00:04:18.419><c> find</c><00:04:18.630><c> that</c>

00:04:18.770 --> 00:04:18.780 align:start position:0%
that in practice we often find that
 

00:04:18.780 --> 00:04:19.849 align:start position:0%
that in practice we often find that
pseudo<00:04:19.109><c> likelihood</c>

00:04:19.849 --> 00:04:19.859 align:start position:0%
pseudo likelihood
 

00:04:19.859 --> 00:04:22.790 align:start position:0%
pseudo likelihood
works<00:04:20.250><c> less</c><00:04:20.609><c> well</c><00:04:20.850><c> so</c><00:04:21.030><c> it</c><00:04:21.120><c> gives</c><00:04:21.650><c> models</c><00:04:22.650><c> are</c>

00:04:22.790 --> 00:04:22.800 align:start position:0%
works less well so it gives models are
 

00:04:22.800 --> 00:04:24.770 align:start position:0%
works less well so it gives models are
not<00:04:23.250><c> as</c><00:04:23.400><c> good</c><00:04:23.610><c> as</c><00:04:23.760><c> models</c><00:04:24.270><c> that</c><00:04:24.390><c> are</c><00:04:24.479><c> trained</c>

00:04:24.770 --> 00:04:24.780 align:start position:0%
not as good as models that are trained
 

00:04:24.780 --> 00:04:26.620 align:start position:0%
not as good as models that are trained
by<00:04:25.380><c> maximum</c><00:04:25.890><c> likelihood</c>

00:04:26.620 --> 00:04:26.630 align:start position:0%
by maximum likelihood
 

00:04:26.630 --> 00:04:30.280 align:start position:0%
by maximum likelihood
and<00:04:26.720><c> there's</c><00:04:27.140><c> some</c><00:04:27.560><c> theory</c><00:04:28.040><c> for</c><00:04:29.110><c> backing</c><00:04:30.110><c> up</c>

00:04:30.280 --> 00:04:30.290 align:start position:0%
and there's some theory for backing up
 

00:04:30.290 --> 00:04:33.160 align:start position:0%
and there's some theory for backing up
why<00:04:30.560><c> we</c><00:04:31.070><c> should</c><00:04:31.490><c> observe</c><00:04:32.090><c> this</c><00:04:32.390><c> so</c><00:04:32.930><c> we're</c><00:04:33.080><c> not</c>

00:04:33.160 --> 00:04:33.170 align:start position:0%
why we should observe this so we're not
 

00:04:33.170 --> 00:04:36.430 align:start position:0%
why we should observe this so we're not
necessarily<00:04:34.000><c> suggests</c><00:04:35.000><c> someone</c><00:04:35.360><c> uses</c><00:04:35.870><c> sort</c>

00:04:36.430 --> 00:04:36.440 align:start position:0%
necessarily suggests someone uses sort
 

00:04:36.440 --> 00:04:38.620 align:start position:0%
necessarily suggests someone uses sort
of<00:04:36.560><c> likelihood</c><00:04:36.890><c> except</c><00:04:37.700><c> perhaps</c><00:04:37.910><c> on</c><00:04:38.240><c> a</c><00:04:38.270><c> very</c>

00:04:38.620 --> 00:04:38.630 align:start position:0%
of likelihood except perhaps on a very
 

00:04:38.630 --> 00:04:41.260 align:start position:0%
of likelihood except perhaps on a very
very<00:04:38.720><c> complicated</c><00:04:39.410><c> model</c><00:04:39.890><c> but</c><00:04:40.880><c> it's</c><00:04:41.000><c> good</c><00:04:41.240><c> to</c>

00:04:41.260 --> 00:04:41.270 align:start position:0%
very complicated model but it's good to
 

00:04:41.270 --> 00:04:42.970 align:start position:0%
very complicated model but it's good to
know<00:04:41.390><c> that</c><00:04:41.510><c> there</c><00:04:42.170><c> are</c><00:04:42.260><c> alternatives</c><00:04:42.830><c> to</c>

00:04:42.970 --> 00:04:42.980 align:start position:0%
know that there are alternatives to
 

00:04:42.980 --> 00:04:46.060 align:start position:0%
know that there are alternatives to
conditional<00:04:43.580><c> random</c><00:04:44.000><c> fields</c><00:04:44.600><c> then</c><00:04:45.110><c> training</c>

00:04:46.060 --> 00:04:46.070 align:start position:0%
conditional random fields then training
 

00:04:46.070 --> 00:04:49.240 align:start position:0%
conditional random fields then training
them<00:04:46.220><c> by</c><00:04:46.370><c> maximum</c><00:04:46.820><c> likelihood</c><00:04:47.150><c> and</c><00:04:48.250><c> certain</c>

00:04:49.240 --> 00:04:49.250 align:start position:0%
them by maximum likelihood and certain
 

00:04:49.250 --> 00:04:51.640 align:start position:0%
them by maximum likelihood and certain
alternatives<00:04:49.760><c> will</c><00:04:49.970><c> be</c><00:04:50.210><c> sort</c><00:04:50.720><c> of</c><00:04:50.810><c> nicer</c><00:04:51.530><c> in</c>

00:04:51.640 --> 00:04:51.650 align:start position:0%
alternatives will be sort of nicer in
 

00:04:51.650 --> 00:04:53.830 align:start position:0%
alternatives will be sort of nicer in
terms<00:04:51.890><c> of</c><00:04:52.160><c> the</c><00:04:52.880><c> computations</c><00:04:53.660><c> that</c><00:04:53.720><c> are</c>

00:04:53.830 --> 00:04:53.840 align:start position:0%
terms of the computations that are
 

00:04:53.840 --> 00:04:56.040 align:start position:0%
terms of the computations that are
required<00:04:54.260><c> for</c><00:04:54.500><c> for</c><00:04:54.830><c> training</c><00:04:55.220><c> them</c><00:04:55.400><c> and</c>

00:04:56.040 --> 00:04:56.050 align:start position:0%
required for for training them and
 

00:04:56.050 --> 00:04:58.330 align:start position:0%
required for for training them and
training<00:04:57.050><c> conditional</c><00:04:57.560><c> random</c><00:04:57.680><c> fields</c><00:04:58.220><c> in</c>

00:04:58.330 --> 00:04:58.340 align:start position:0%
training conditional random fields in
 

00:04:58.340 --> 00:05:00.010 align:start position:0%
training conditional random fields in
general<00:04:58.850><c> is</c><00:04:59.090><c> a</c><00:04:59.120><c> very</c><00:04:59.270><c> active</c><00:04:59.690><c> field</c><00:04:59.840><c> of</c>

00:05:00.010 --> 00:05:00.020 align:start position:0%
general is a very active field of
 

00:05:00.020 --> 00:05:02.980 align:start position:0%
general is a very active field of
research<00:05:00.370><c> but</c><00:05:01.370><c> with</c><00:05:01.610><c> all</c><00:05:01.910><c> we've</c><00:05:02.300><c> seen</c><00:05:02.540><c> and</c><00:05:02.810><c> the</c>

00:05:02.980 --> 00:05:02.990 align:start position:0%
research but with all we've seen and the
 

00:05:02.990 --> 00:05:05.200 align:start position:0%
research but with all we've seen and the
this<00:05:03.680><c> video</c><00:05:03.920><c> and</c><00:05:04.070><c> the</c><00:05:04.130><c> previous</c><00:05:04.280><c> ones</c><00:05:04.730><c> that</c>

00:05:05.200 --> 00:05:05.210 align:start position:0%
this video and the previous ones that
 

00:05:05.210 --> 00:05:08.110 align:start position:0%
this video and the previous ones that
should<00:05:05.360><c> give</c><00:05:05.600><c> you</c><00:05:05.750><c> a</c><00:05:06.500><c> head</c><00:05:07.100><c> start</c><00:05:07.130><c> for</c><00:05:07.670><c> looking</c>

00:05:08.110 --> 00:05:08.120 align:start position:0%
should give you a head start for looking
 

00:05:08.120 --> 00:05:11.050 align:start position:0%
should give you a head start for looking
at<00:05:08.240><c> that</c><00:05:08.390><c> literature</c><00:05:08.750><c> more</c>

