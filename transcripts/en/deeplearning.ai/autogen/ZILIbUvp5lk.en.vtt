WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:01.969 align:start position:0%
 
very<00:00:00.450><c> very</c><00:00:00.659><c> deep</c><00:00:00.989><c> neural</c><00:00:01.290><c> networks</c><00:00:01.560><c> are</c>

00:00:01.969 --> 00:00:01.979 align:start position:0%
very very deep neural networks are
 

00:00:01.979 --> 00:00:04.430 align:start position:0%
very very deep neural networks are
difficult<00:00:02.490><c> to</c><00:00:02.580><c> train</c><00:00:02.850><c> because</c><00:00:03.030><c> of</c><00:00:03.440><c> vanishing</c>

00:00:04.430 --> 00:00:04.440 align:start position:0%
difficult to train because of vanishing
 

00:00:04.440 --> 00:00:06.320 align:start position:0%
difficult to train because of vanishing
and<00:00:04.680><c> exploding</c><00:00:05.250><c> gradients</c><00:00:05.879><c> types</c><00:00:06.180><c> of</c>

00:00:06.320 --> 00:00:06.330 align:start position:0%
and exploding gradients types of
 

00:00:06.330 --> 00:00:08.690 align:start position:0%
and exploding gradients types of
problems<00:00:06.750><c> in</c><00:00:07.350><c> this</c><00:00:07.710><c> video</c><00:00:08.040><c> you</c><00:00:08.130><c> learn</c><00:00:08.460><c> about</c>

00:00:08.690 --> 00:00:08.700 align:start position:0%
problems in this video you learn about
 

00:00:08.700 --> 00:00:10.430 align:start position:0%
problems in this video you learn about
skip<00:00:09.120><c> connections</c><00:00:09.660><c> which</c><00:00:09.929><c> allows</c><00:00:10.200><c> you</c><00:00:10.410><c> to</c>

00:00:10.430 --> 00:00:10.440 align:start position:0%
skip connections which allows you to
 

00:00:10.440 --> 00:00:12.860 align:start position:0%
skip connections which allows you to
take<00:00:10.800><c> the</c><00:00:10.920><c> activation</c><00:00:11.580><c> from</c><00:00:12.120><c> one</c><00:00:12.360><c> layer</c><00:00:12.570><c> and</c>

00:00:12.860 --> 00:00:12.870 align:start position:0%
take the activation from one layer and
 

00:00:12.870 --> 00:00:15.560 align:start position:0%
take the activation from one layer and
suddenly<00:00:13.650><c> feed</c><00:00:13.980><c> it</c><00:00:14.160><c> to</c><00:00:14.370><c> another</c><00:00:14.670><c> layer</c><00:00:14.910><c> even</c>

00:00:15.560 --> 00:00:15.570 align:start position:0%
suddenly feed it to another layer even
 

00:00:15.570 --> 00:00:17.269 align:start position:0%
suddenly feed it to another layer even
much<00:00:15.719><c> deeper</c><00:00:16.230><c> in</c><00:00:16.440><c> the</c><00:00:16.529><c> neural</c><00:00:16.800><c> network</c><00:00:17.100><c> and</c>

00:00:17.269 --> 00:00:17.279 align:start position:0%
much deeper in the neural network and
 

00:00:17.279 --> 00:00:19.460 align:start position:0%
much deeper in the neural network and
using<00:00:17.970><c> that</c><00:00:18.090><c> you</c><00:00:18.359><c> really</c><00:00:18.570><c> build</c><00:00:18.750><c> business</c>

00:00:19.460 --> 00:00:19.470 align:start position:0%
using that you really build business
 

00:00:19.470 --> 00:00:21.710 align:start position:0%
using that you really build business
which<00:00:19.710><c> enables</c><00:00:20.160><c> you</c><00:00:20.340><c> to</c><00:00:20.369><c> Train</c><00:00:20.880><c> very</c><00:00:21.119><c> very</c>

00:00:21.710 --> 00:00:21.720 align:start position:0%
which enables you to Train very very
 

00:00:21.720 --> 00:00:23.810 align:start position:0%
which enables you to Train very very
deep<00:00:21.990><c> in</c><00:00:22.230><c> that</c><00:00:22.350><c> service</c><00:00:22.650><c> sometimes</c><00:00:22.949><c> even</c><00:00:23.430><c> net</c>

00:00:23.810 --> 00:00:23.820 align:start position:0%
deep in that service sometimes even net
 

00:00:23.820 --> 00:00:25.880 align:start position:0%
deep in that service sometimes even net
worth<00:00:24.029><c> of</c><00:00:24.180><c> over</c><00:00:24.390><c> a</c><00:00:24.630><c> hundred</c><00:00:24.689><c> layers</c><00:00:25.350><c> let's</c>

00:00:25.880 --> 00:00:25.890 align:start position:0%
worth of over a hundred layers let's
 

00:00:25.890 --> 00:00:26.570 align:start position:0%
worth of over a hundred layers let's
take<00:00:26.039><c> a</c><00:00:26.070><c> look</c>

00:00:26.570 --> 00:00:26.580 align:start position:0%
take a look
 

00:00:26.580 --> 00:00:28.730 align:start position:0%
take a look
rest<00:00:27.119><c> nets</c><00:00:27.390><c> are</c><00:00:27.599><c> built</c><00:00:27.840><c> out</c><00:00:28.080><c> of</c><00:00:28.410><c> something</c>

00:00:28.730 --> 00:00:28.740 align:start position:0%
rest nets are built out of something
 

00:00:28.740 --> 00:00:31.009 align:start position:0%
rest nets are built out of something
called<00:00:29.130><c> a</c><00:00:29.310><c> residual</c><00:00:29.820><c> block</c><00:00:30.119><c> let's</c><00:00:30.779><c> first</c>

00:00:31.009 --> 00:00:31.019 align:start position:0%
called a residual block let's first
 

00:00:31.019 --> 00:00:33.680 align:start position:0%
called a residual block let's first
describe<00:00:31.439><c> what</c><00:00:31.769><c> that</c><00:00:31.800><c> is</c><00:00:32.360><c> here</c><00:00:33.360><c> are</c><00:00:33.480><c> two</c>

00:00:33.680 --> 00:00:33.690 align:start position:0%
describe what that is here are two
 

00:00:33.690 --> 00:00:35.360 align:start position:0%
describe what that is here are two
layers<00:00:33.960><c> of</c><00:00:34.110><c> a</c><00:00:34.380><c> neural</c><00:00:34.649><c> network</c><00:00:34.800><c> where</c><00:00:35.250><c> you</c>

00:00:35.360 --> 00:00:35.370 align:start position:0%
layers of a neural network where you
 

00:00:35.370 --> 00:00:37.430 align:start position:0%
layers of a neural network where you
start<00:00:35.670><c> off</c><00:00:35.850><c> with</c><00:00:36.090><c> some</c><00:00:36.390><c> activation</c><00:00:36.899><c> and</c><00:00:37.290><c> there</c>

00:00:37.430 --> 00:00:37.440 align:start position:0%
start off with some activation and there
 

00:00:37.440 --> 00:00:40.160 align:start position:0%
start off with some activation and there
L<00:00:37.710><c> then</c><00:00:38.160><c> you</c><00:00:38.190><c> go</c><00:00:38.399><c> to</c><00:00:38.460><c> a</c><00:00:38.610><c> L</c><00:00:38.969><c> plus</c><00:00:39.210><c> 1</c><00:00:39.450><c> and</c><00:00:39.719><c> then</c><00:00:39.960><c> the</c>

00:00:40.160 --> 00:00:40.170 align:start position:0%
L then you go to a L plus 1 and then the
 

00:00:40.170 --> 00:00:43.280 align:start position:0%
L then you go to a L plus 1 and then the
activation<00:00:40.739><c> two</c><00:00:41.340><c> layers</c><00:00:41.610><c> later</c><00:00:41.879><c> is</c><00:00:42.300><c> a</c><00:00:42.600><c> L</c><00:00:42.870><c> plus</c>

00:00:43.280 --> 00:00:43.290 align:start position:0%
activation two layers later is a L plus
 

00:00:43.290 --> 00:00:45.860 align:start position:0%
activation two layers later is a L plus
two<00:00:43.590><c> so</c><00:00:44.160><c> to</c><00:00:44.219><c> go</c><00:00:44.430><c> through</c><00:00:44.700><c> the</c><00:00:45.030><c> steps</c><00:00:45.480><c> in</c><00:00:45.690><c> this</c>

00:00:45.860 --> 00:00:45.870 align:start position:0%
two so to go through the steps in this
 

00:00:45.870 --> 00:00:49.760 align:start position:0%
two so to go through the steps in this
computation<00:00:46.620><c> you</c><00:00:46.829><c> have</c><00:00:47.039><c> a</c><00:00:47.280><c> L</c><00:00:47.969><c> and</c><00:00:48.590><c> then</c><00:00:49.590><c> the</c>

00:00:49.760 --> 00:00:49.770 align:start position:0%
computation you have a L and then the
 

00:00:49.770 --> 00:00:51.939 align:start position:0%
computation you have a L and then the
first<00:00:50.010><c> thing</c><00:00:50.129><c> you</c><00:00:50.250><c> do</c><00:00:50.460><c> is</c><00:00:50.700><c> you</c><00:00:50.850><c> apply</c><00:00:51.149><c> this</c>

00:00:51.939 --> 00:00:51.949 align:start position:0%
first thing you do is you apply this
 

00:00:51.949 --> 00:00:55.819 align:start position:0%
first thing you do is you apply this
linear<00:00:52.949><c> operator</c><00:00:53.430><c> to</c><00:00:53.730><c> it</c><00:00:54.289><c> which</c><00:00:55.289><c> is</c><00:00:55.469><c> governed</c>

00:00:55.819 --> 00:00:55.829 align:start position:0%
linear operator to it which is governed
 

00:00:55.829 --> 00:00:57.260 align:start position:0%
linear operator to it which is governed
by<00:00:55.949><c> this</c><00:00:56.520><c> equation</c>

00:00:57.260 --> 00:00:57.270 align:start position:0%
by this equation
 

00:00:57.270 --> 00:01:02.260 align:start position:0%
by this equation
to<00:00:57.870><c> go</c><00:00:58.050><c> from</c><00:00:58.260><c> a</c><00:00:58.559><c> L</c><00:00:59.460><c> to</c><00:01:00.149><c> compute</c><00:01:00.750><c> Z</c><00:01:01.230><c> L</c><00:01:01.469><c> plus</c><00:01:01.920><c> one</c>

00:01:02.260 --> 00:01:02.270 align:start position:0%
to go from a L to compute Z L plus one
 

00:01:02.270 --> 00:01:04.880 align:start position:0%
to go from a L to compute Z L plus one
by<00:01:03.270><c> multiplying</c><00:01:03.480><c> by</c><00:01:03.960><c> the</c><00:01:04.019><c> weight</c><00:01:04.229><c> matrix</c><00:01:04.650><c> and</c>

00:01:04.880 --> 00:01:04.890 align:start position:0%
by multiplying by the weight matrix and
 

00:01:04.890 --> 00:01:09.380 align:start position:0%
by multiplying by the weight matrix and
adding<00:01:05.250><c> that</c><00:01:05.760><c> bias</c><00:01:06.240><c> vector</c><00:01:07.280><c> after</c><00:01:08.280><c> that</c><00:01:08.490><c> you</c>

00:01:09.380 --> 00:01:09.390 align:start position:0%
adding that bias vector after that you
 

00:01:09.390 --> 00:01:16.359 align:start position:0%
adding that bias vector after that you
apply<00:01:09.720><c> the</c><00:01:10.400><c> relu</c><00:01:11.400><c> the</c><00:01:12.150><c> linearity</c><00:01:12.479><c> to</c><00:01:13.439><c> get</c><00:01:13.680><c> a</c><00:01:14.540><c> o</c>

00:01:16.359 --> 00:01:16.369 align:start position:0%
apply the relu the linearity to get a o
 

00:01:16.369 --> 00:01:19.789 align:start position:0%
apply the relu the linearity to get a o
plus<00:01:17.369><c> one</c><00:01:17.610><c> and</c><00:01:18.030><c> that's</c><00:01:18.360><c> governed</c><00:01:18.780><c> by</c><00:01:18.960><c> this</c>

00:01:19.789 --> 00:01:19.799 align:start position:0%
plus one and that's governed by this
 

00:01:19.799 --> 00:01:23.390 align:start position:0%
plus one and that's governed by this
equation<00:01:20.070><c> where</c><00:01:20.729><c> a</c><00:01:21.000><c> L</c><00:01:21.390><c> plus</c><00:01:21.600><c> one</c><00:01:21.810><c> is</c><00:01:22.049><c> G</c><00:01:22.380><c> of</c><00:01:22.560><c> ZL</c>

00:01:23.390 --> 00:01:23.400 align:start position:0%
equation where a L plus one is G of ZL
 

00:01:23.400 --> 00:01:26.929 align:start position:0%
equation where a L plus one is G of ZL
plus<00:01:23.790><c> 1</c><00:01:24.030><c> then</c><00:01:25.020><c> in</c><00:01:25.200><c> the</c><00:01:25.290><c> next</c><00:01:25.560><c> layer</c><00:01:25.740><c> you</c><00:01:26.130><c> apply</c>

00:01:26.929 --> 00:01:26.939 align:start position:0%
plus 1 then in the next layer you apply
 

00:01:26.939 --> 00:01:31.910 align:start position:0%
plus 1 then in the next layer you apply
this<00:01:27.650><c> linear</c><00:01:28.939><c> step</c><00:01:29.939><c> again</c><00:01:30.270><c> so</c><00:01:30.840><c> it's</c><00:01:31.079><c> governed</c>

00:01:31.910 --> 00:01:31.920 align:start position:0%
this linear step again so it's governed
 

00:01:31.920 --> 00:01:34.190 align:start position:0%
this linear step again so it's governed
by<00:01:32.070><c> that</c><00:01:32.310><c> equation</c><00:01:32.610><c> right</c><00:01:33.119><c> so</c><00:01:33.630><c> this</c><00:01:33.840><c> is</c><00:01:34.020><c> quite</c>

00:01:34.190 --> 00:01:34.200 align:start position:0%
by that equation right so this is quite
 

00:01:34.200 --> 00:01:35.960 align:start position:0%
by that equation right so this is quite
similar<00:01:34.650><c> to</c><00:01:34.710><c> this</c><00:01:34.979><c> equation</c><00:01:35.220><c> we</c><00:01:35.610><c> saw</c><00:01:35.790><c> on</c><00:01:35.850><c> the</c>

00:01:35.960 --> 00:01:35.970 align:start position:0%
similar to this equation we saw on the
 

00:01:35.970 --> 00:01:40.840 align:start position:0%
similar to this equation we saw on the
left<00:01:36.210><c> and</c><00:01:37.280><c> then</c><00:01:38.280><c> finally</c><00:01:38.960><c> you</c><00:01:39.960><c> apply</c><00:01:40.229><c> another</c>

00:01:40.840 --> 00:01:40.850 align:start position:0%
left and then finally you apply another
 

00:01:40.850 --> 00:01:45.190 align:start position:0%
left and then finally you apply another
relu<00:01:41.850><c> operation</c><00:01:42.680><c> which</c><00:01:43.680><c> is</c><00:01:43.860><c> now</c><00:01:44.090><c> governed</c><00:01:45.090><c> by</c>

00:01:45.190 --> 00:01:45.200 align:start position:0%
relu operation which is now governed by
 

00:01:45.200 --> 00:01:48.649 align:start position:0%
relu operation which is now governed by
that<00:01:46.200><c> equation</c><00:01:46.770><c> where</c><00:01:47.280><c> g</c><00:01:47.759><c> here</c><00:01:48.030><c> would</c><00:01:48.240><c> be</c><00:01:48.390><c> the</c>

00:01:48.649 --> 00:01:48.659 align:start position:0%
that equation where g here would be the
 

00:01:48.659 --> 00:01:53.300 align:start position:0%
that equation where g here would be the
relu<00:01:49.500><c> non-linearity</c><00:01:51.500><c> and</c><00:01:52.500><c> this</c><00:01:52.770><c> gives</c><00:01:53.040><c> you</c>

00:01:53.300 --> 00:01:53.310 align:start position:0%
relu non-linearity and this gives you
 

00:01:53.310 --> 00:01:57.770 align:start position:0%
relu non-linearity and this gives you
you<00:01:54.060><c> know</c><00:01:54.090><c> a</c><00:01:54.390><c> L</c><00:01:54.979><c> plus</c><00:01:55.979><c> 2</c><00:01:56.159><c> so</c><00:01:57.090><c> in</c><00:01:57.390><c> other</c><00:01:57.540><c> words</c>

00:01:57.770 --> 00:01:57.780 align:start position:0%
you know a L plus 2 so in other words
 

00:01:57.780 --> 00:02:03.080 align:start position:0%
you know a L plus 2 so in other words
for<00:01:57.990><c> information</c><00:01:58.680><c> from</c><00:01:59.040><c> al</c><00:01:59.909><c> to</c><00:02:00.719><c> flow</c><00:02:01.640><c> to</c><00:02:02.640><c> al</c>

00:02:03.080 --> 00:02:03.090 align:start position:0%
for information from al to flow to al
 

00:02:03.090 --> 00:02:05.569 align:start position:0%
for information from al to flow to al
plus<00:02:03.390><c> 2</c><00:02:03.719><c> it</c><00:02:04.560><c> needs</c><00:02:04.799><c> to</c><00:02:04.920><c> go</c><00:02:05.070><c> through</c><00:02:05.310><c> all</c><00:02:05.549><c> of</c>

00:02:05.569 --> 00:02:05.579 align:start position:0%
plus 2 it needs to go through all of
 

00:02:05.579 --> 00:02:08.350 align:start position:0%
plus 2 it needs to go through all of
these<00:02:05.909><c> steps</c><00:02:06.210><c> which</c><00:02:06.600><c> I'm</c><00:02:06.840><c> going</c><00:02:07.020><c> to</c><00:02:07.110><c> call</c><00:02:07.320><c> the</c>

00:02:08.350 --> 00:02:08.360 align:start position:0%
these steps which I'm going to call the
 

00:02:08.360 --> 00:02:09.680 align:start position:0%
these steps which I'm going to call the
main

00:02:09.680 --> 00:02:09.690 align:start position:0%
main
 

00:02:09.690 --> 00:02:14.270 align:start position:0%
main
of<00:02:10.050><c> this</c><00:02:11.240><c> set</c><00:02:12.240><c> of</c><00:02:12.360><c> layers</c><00:02:12.540><c> in</c><00:02:13.380><c> a</c><00:02:13.740><c> position</c><00:02:14.100><c> that</c>

00:02:14.270 --> 00:02:14.280 align:start position:0%
of this set of layers in a position that
 

00:02:14.280 --> 00:02:16.700 align:start position:0%
of this set of layers in a position that
we're<00:02:14.700><c> going</c><00:02:14.880><c> to</c><00:02:14.970><c> make</c><00:02:15.810><c> a</c><00:02:15.840><c> change</c><00:02:16.290><c> to</c><00:02:16.560><c> this</c>

00:02:16.700 --> 00:02:16.710 align:start position:0%
we're going to make a change to this
 

00:02:16.710 --> 00:02:20.330 align:start position:0%
we're going to make a change to this
we're<00:02:16.980><c> gonna</c><00:02:17.100><c> take</c><00:02:17.400><c> Al</c><00:02:17.880><c> and</c><00:02:18.260><c> just</c><00:02:19.340><c> fast</c>

00:02:20.330 --> 00:02:20.340 align:start position:0%
we're gonna take Al and just fast
 

00:02:20.340 --> 00:02:24.560 align:start position:0%
we're gonna take Al and just fast
forward<00:02:20.790><c> it</c><00:02:20.910><c> copy</c><00:02:21.480><c> it</c><00:02:22.760><c> much</c><00:02:23.760><c> further</c><00:02:24.030><c> into</c><00:02:24.360><c> the</c>

00:02:24.560 --> 00:02:24.570 align:start position:0%
forward it copy it much further into the
 

00:02:24.570 --> 00:02:29.950 align:start position:0%
forward it copy it much further into the
neural<00:02:24.810><c> network</c><00:02:25.140><c> to</c><00:02:25.530><c> here</c><00:02:25.890><c> and</c><00:02:26.070><c> just</c><00:02:27.170><c> add</c><00:02:28.700><c> al</c>

00:02:29.950 --> 00:02:29.960 align:start position:0%
neural network to here and just add al
 

00:02:29.960 --> 00:02:32.660 align:start position:0%
neural network to here and just add al
before<00:02:30.960><c> applying</c><00:02:31.260><c> the</c><00:02:31.470><c> non-linearity</c><00:02:31.920><c> they</c>

00:02:32.660 --> 00:02:32.670 align:start position:0%
before applying the non-linearity they
 

00:02:32.670 --> 00:02:35.270 align:start position:0%
before applying the non-linearity they
really<00:02:32.970><c> non-linearity</c><00:02:33.780><c> and</c><00:02:34.020><c> I'm</c><00:02:34.860><c> gonna</c><00:02:35.010><c> call</c>

00:02:35.270 --> 00:02:35.280 align:start position:0%
really non-linearity and I'm gonna call
 

00:02:35.280 --> 00:02:38.750 align:start position:0%
really non-linearity and I'm gonna call
this<00:02:35.490><c> the</c><00:02:36.020><c> shortcut</c><00:02:37.020><c> so</c><00:02:37.920><c> rather</c><00:02:38.160><c> than</c><00:02:38.430><c> needing</c>

00:02:38.750 --> 00:02:38.760 align:start position:0%
this the shortcut so rather than needing
 

00:02:38.760 --> 00:02:41.810 align:start position:0%
this the shortcut so rather than needing
to<00:02:38.790><c> follow</c><00:02:39.180><c> the</c><00:02:39.420><c> main</c><00:02:39.690><c> path</c><00:02:40.250><c> the</c><00:02:41.250><c> information</c>

00:02:41.810 --> 00:02:41.820 align:start position:0%
to follow the main path the information
 

00:02:41.820 --> 00:02:44.780 align:start position:0%
to follow the main path the information
from<00:02:42.030><c> Al</c><00:02:42.480><c> can</c><00:02:42.780><c> now</c><00:02:42.900><c> follow</c><00:02:43.200><c> a</c><00:02:43.320><c> shortcut</c><00:02:44.010><c> to</c><00:02:44.640><c> go</c>

00:02:44.780 --> 00:02:44.790 align:start position:0%
from Al can now follow a shortcut to go
 

00:02:44.790 --> 00:02:46.670 align:start position:0%
from Al can now follow a shortcut to go
much<00:02:45.030><c> deeper</c><00:02:45.060><c> into</c><00:02:45.720><c> the</c><00:02:45.840><c> neural</c><00:02:46.080><c> network</c><00:02:46.440><c> and</c>

00:02:46.670 --> 00:02:46.680 align:start position:0%
much deeper into the neural network and
 

00:02:46.680 --> 00:02:48.830 align:start position:0%
much deeper into the neural network and
what<00:02:47.370><c> that</c><00:02:47.520><c> means</c><00:02:47.730><c> is</c><00:02:48.000><c> that</c><00:02:48.030><c> this</c><00:02:48.540><c> last</c>

00:02:48.830 --> 00:02:48.840 align:start position:0%
what that means is that this last
 

00:02:48.840 --> 00:02:51.590 align:start position:0%
what that means is that this last
equation<00:02:49.140><c> goes</c><00:02:49.920><c> away</c><00:02:50.190><c> and</c><00:02:50.670><c> we</c><00:02:50.910><c> instead</c><00:02:51.240><c> have</c>

00:02:51.590 --> 00:02:51.600 align:start position:0%
equation goes away and we instead have
 

00:02:51.600 --> 00:02:55.510 align:start position:0%
equation goes away and we instead have
that<00:02:51.900><c> the</c><00:02:52.080><c> output</c><00:02:52.560><c> al</c><00:02:53.280><c> plus</c><00:02:53.550><c> 2</c><00:02:53.850><c> is</c><00:02:54.150><c> the</c><00:02:54.990><c> rather</c>

00:02:55.510 --> 00:02:55.520 align:start position:0%
that the output al plus 2 is the rather
 

00:02:55.520 --> 00:03:00.110 align:start position:0%
that the output al plus 2 is the rather
non-linearity<00:02:56.520><c> G</c><00:02:57.030><c> applied</c><00:02:58.020><c> to</c><00:02:58.340><c> ZL</c><00:02:59.340><c> plus</c><00:02:59.610><c> 2</c><00:02:59.880><c> as</c>

00:03:00.110 --> 00:03:00.120 align:start position:0%
non-linearity G applied to ZL plus 2 as
 

00:03:00.120 --> 00:03:03.590 align:start position:0%
non-linearity G applied to ZL plus 2 as
before<00:03:00.630><c> but</c><00:03:01.200><c> now</c><00:03:01.260><c> plus</c><00:03:01.860><c> al</c><00:03:02.640><c> so</c><00:03:03.060><c> the</c><00:03:03.180><c> addition</c>

00:03:03.590 --> 00:03:03.600 align:start position:0%
before but now plus al so the addition
 

00:03:03.600 --> 00:03:07.310 align:start position:0%
before but now plus al so the addition
of<00:03:03.630><c> this</c><00:03:04.170><c> al</c><00:03:04.950><c> here</c><00:03:05.250><c> it</c><00:03:05.850><c> makes</c><00:03:06.300><c> this</c><00:03:06.510><c> a</c><00:03:06.750><c> residual</c>

00:03:07.310 --> 00:03:07.320 align:start position:0%
of this al here it makes this a residual
 

00:03:07.320 --> 00:03:09.710 align:start position:0%
of this al here it makes this a residual
block<00:03:07.620><c> and</c><00:03:08.250><c> in</c><00:03:08.700><c> pictures</c><00:03:09.150><c> you</c><00:03:09.390><c> can</c><00:03:09.540><c> also</c>

00:03:09.710 --> 00:03:09.720 align:start position:0%
block and in pictures you can also
 

00:03:09.720 --> 00:03:12.350 align:start position:0%
block and in pictures you can also
modify<00:03:10.260><c> this</c><00:03:10.440><c> picture</c><00:03:10.920><c> on</c><00:03:11.010><c> top</c><00:03:11.310><c> by</c><00:03:12.000><c> drawing</c>

00:03:12.350 --> 00:03:12.360 align:start position:0%
modify this picture on top by drawing
 

00:03:12.360 --> 00:03:16.010 align:start position:0%
modify this picture on top by drawing
this<00:03:12.720><c> if</c><00:03:13.350><c> your</c><00:03:13.709><c> shortcut</c><00:03:14.490><c> to</c><00:03:15.000><c> go</c><00:03:15.209><c> here</c><00:03:15.690><c> I'm</c>

00:03:16.010 --> 00:03:16.020 align:start position:0%
this if your shortcut to go here I'm
 

00:03:16.020 --> 00:03:19.100 align:start position:0%
this if your shortcut to go here I'm
going<00:03:16.350><c> to</c><00:03:16.410><c> draw</c><00:03:16.590><c> it</c><00:03:16.650><c> as</c><00:03:17.060><c> going</c><00:03:18.060><c> into</c><00:03:18.330><c> this</c>

00:03:19.100 --> 00:03:19.110 align:start position:0%
going to draw it as going into this
 

00:03:19.110 --> 00:03:22.520 align:start position:0%
going to draw it as going into this
second<00:03:19.860><c> layer</c><00:03:20.010><c> here</c><00:03:20.459><c> because</c><00:03:21.330><c> the</c><00:03:21.990><c> shortcut</c>

00:03:22.520 --> 00:03:22.530 align:start position:0%
second layer here because the shortcut
 

00:03:22.530 --> 00:03:25.070 align:start position:0%
second layer here because the shortcut
is<00:03:22.800><c> actually</c><00:03:23.220><c> added</c><00:03:23.940><c> before</c><00:03:24.270><c> the</c><00:03:24.720><c> relative</c>

00:03:25.070 --> 00:03:25.080 align:start position:0%
is actually added before the relative
 

00:03:25.080 --> 00:03:26.960 align:start position:0%
is actually added before the relative
non-linearity<00:03:25.860><c> so</c><00:03:26.190><c> each</c><00:03:26.370><c> of</c><00:03:26.400><c> these</c><00:03:26.640><c> nodes</c>

00:03:26.960 --> 00:03:26.970 align:start position:0%
non-linearity so each of these nodes
 

00:03:26.970 --> 00:03:28.699 align:start position:0%
non-linearity so each of these nodes
here<00:03:27.330><c> where</c><00:03:27.750><c> that</c><00:03:27.930><c> applies</c><00:03:28.200><c> a</c><00:03:28.230><c> linear</c>

00:03:28.699 --> 00:03:28.709 align:start position:0%
here where that applies a linear
 

00:03:28.709 --> 00:03:31.580 align:start position:0%
here where that applies a linear
function<00:03:29.160><c> and</c><00:03:29.400><c> a</c><00:03:29.850><c> value</c><00:03:30.240><c> so</c><00:03:30.750><c> al</c><00:03:31.200><c> was</c><00:03:31.380><c> being</c>

00:03:31.580 --> 00:03:31.590 align:start position:0%
function and a value so al was being
 

00:03:31.590 --> 00:03:32.330 align:start position:0%
function and a value so al was being
injected

00:03:32.330 --> 00:03:32.340 align:start position:0%
injected
 

00:03:32.340 --> 00:03:34.280 align:start position:0%
injected
after<00:03:32.760><c> the</c><00:03:32.910><c> linear</c><00:03:33.209><c> part</c><00:03:33.420><c> but</c><00:03:33.780><c> before</c><00:03:34.140><c> the</c>

00:03:34.280 --> 00:03:34.290 align:start position:0%
after the linear part but before the
 

00:03:34.290 --> 00:03:36.560 align:start position:0%
after the linear part but before the
rather<00:03:34.470><c> part</c><00:03:34.860><c> and</c><00:03:35.520><c> sometimes</c><00:03:36.000><c> instead</c><00:03:36.360><c> of</c><00:03:36.420><c> the</c>

00:03:36.560 --> 00:03:36.570 align:start position:0%
rather part and sometimes instead of the
 

00:03:36.570 --> 00:03:38.810 align:start position:0%
rather part and sometimes instead of the
terms<00:03:36.810><c> shortcut</c><00:03:37.470><c> you</c><00:03:38.100><c> also</c><00:03:38.250><c> hear</c><00:03:38.640><c> the</c><00:03:38.790><c> term</c>

00:03:38.810 --> 00:03:38.820 align:start position:0%
terms shortcut you also hear the term
 

00:03:38.820 --> 00:03:41.690 align:start position:0%
terms shortcut you also hear the term
skip<00:03:39.510><c> connection</c><00:03:40.290><c> and</c><00:03:40.680><c> that</c><00:03:40.709><c> refers</c><00:03:41.220><c> to</c><00:03:41.250><c> Al</c>

00:03:41.690 --> 00:03:41.700 align:start position:0%
skip connection and that refers to Al
 

00:03:41.700 --> 00:03:43.970 align:start position:0%
skip connection and that refers to Al
just<00:03:41.970><c> skipping</c><00:03:42.480><c> over</c><00:03:42.660><c> a</c><00:03:42.840><c> layer</c><00:03:43.110><c> or</c><00:03:43.530><c> kind</c><00:03:43.890><c> of</c>

00:03:43.970 --> 00:03:43.980 align:start position:0%
just skipping over a layer or kind of
 

00:03:43.980 --> 00:03:46.520 align:start position:0%
just skipping over a layer or kind of
skipping<00:03:44.370><c> over</c><00:03:44.489><c> almost</c><00:03:45.000><c> two</c><00:03:45.570><c> layers</c><00:03:45.840><c> in</c><00:03:46.290><c> order</c>

00:03:46.520 --> 00:03:46.530 align:start position:0%
skipping over almost two layers in order
 

00:03:46.530 --> 00:03:49.670 align:start position:0%
skipping over almost two layers in order
to<00:03:46.980><c> pass</c><00:03:47.370><c> this</c><00:03:47.550><c> information</c><00:03:48.050><c> deeper</c><00:03:49.050><c> into</c><00:03:49.560><c> the</c>

00:03:49.670 --> 00:03:49.680 align:start position:0%
to pass this information deeper into the
 

00:03:49.680 --> 00:03:53.030 align:start position:0%
to pass this information deeper into the
neural<00:03:49.920><c> network</c><00:03:50.280><c> so</c><00:03:51.120><c> what</c><00:03:51.720><c> the</c><00:03:52.290><c> inventors</c><00:03:53.010><c> of</c>

00:03:53.030 --> 00:03:53.040 align:start position:0%
neural network so what the inventors of
 

00:03:53.040 --> 00:03:55.400 align:start position:0%
neural network so what the inventors of
ResNet<00:03:53.850><c> so</c><00:03:54.270><c> that</c><00:03:54.510><c> would</c><00:03:54.600><c> be</c><00:03:54.690><c> climbing</c><00:03:55.110><c> her</c>

00:03:55.400 --> 00:03:55.410 align:start position:0%
ResNet so that would be climbing her
 

00:03:55.410 --> 00:03:59.180 align:start position:0%
ResNet so that would be climbing her
Sally<00:03:56.070><c> Jiang</c><00:03:56.340><c> shouting</c><00:03:57.060><c> Ren</c><00:03:57.270><c> and</c><00:03:57.540><c> Jenson</c><00:03:58.260><c> what</c>

00:03:59.180 --> 00:03:59.190 align:start position:0%
Sally Jiang shouting Ren and Jenson what
 

00:03:59.190 --> 00:04:01.520 align:start position:0%
Sally Jiang shouting Ren and Jenson what
they<00:03:59.280><c> found</c><00:03:59.459><c> was</c><00:03:59.820><c> that</c><00:04:00.050><c> using</c><00:04:01.050><c> residual</c>

00:04:01.520 --> 00:04:01.530 align:start position:0%
they found was that using residual
 

00:04:01.530 --> 00:04:01.970 align:start position:0%
they found was that using residual
blocks

00:04:01.970 --> 00:04:01.980 align:start position:0%
blocks
 

00:04:01.980 --> 00:04:04.760 align:start position:0%
blocks
allows<00:04:02.370><c> you</c><00:04:02.640><c> to</c><00:04:02.940><c> train</c><00:04:03.300><c> much</c><00:04:03.870><c> deeper</c><00:04:04.350><c> neural</c>

00:04:04.760 --> 00:04:04.770 align:start position:0%
allows you to train much deeper neural
 

00:04:04.770 --> 00:04:07.220 align:start position:0%
allows you to train much deeper neural
networks<00:04:05.160><c> and</c><00:04:05.580><c> the</c><00:04:06.270><c> way</c><00:04:06.420><c> you</c><00:04:06.480><c> build</c><00:04:07.020><c> a</c>

00:04:07.220 --> 00:04:07.230 align:start position:0%
networks and the way you build a
 

00:04:07.230 --> 00:04:09.260 align:start position:0%
networks and the way you build a
resident<00:04:07.800><c> is</c><00:04:07.980><c> by</c><00:04:08.160><c> taking</c><00:04:08.400><c> many</c><00:04:08.880><c> of</c><00:04:09.090><c> these</c>

00:04:09.260 --> 00:04:09.270 align:start position:0%
resident is by taking many of these
 

00:04:09.270 --> 00:04:11.930 align:start position:0%
resident is by taking many of these
residual<00:04:10.140><c> blocks</c><00:04:10.440><c> blocks</c><00:04:11.130><c> like</c><00:04:11.340><c> these</c><00:04:11.520><c> and</c>

00:04:11.930 --> 00:04:11.940 align:start position:0%
residual blocks blocks like these and
 

00:04:11.940 --> 00:04:14.479 align:start position:0%
residual blocks blocks like these and
stacking<00:04:12.840><c> them</c><00:04:13.230><c> together</c><00:04:13.410><c> to</c><00:04:13.860><c> form</c><00:04:14.040><c> a</c><00:04:14.250><c> deep</c>

00:04:14.479 --> 00:04:14.489 align:start position:0%
stacking them together to form a deep
 

00:04:14.489 --> 00:04:17.870 align:start position:0%
stacking them together to form a deep
network<00:04:15.180><c> so</c><00:04:16.190><c> let's</c><00:04:17.190><c> look</c><00:04:17.340><c> at</c><00:04:17.489><c> this</c><00:04:17.640><c> network</c>

00:04:17.870 --> 00:04:17.880 align:start position:0%
network so let's look at this network
 

00:04:17.880 --> 00:04:20.659 align:start position:0%
network so let's look at this network
this<00:04:18.270><c> is</c><00:04:18.419><c> not</c><00:04:18.630><c> a</c><00:04:18.660><c> residual</c><00:04:19.140><c> network</c><00:04:19.560><c> um</c><00:04:19.890><c> this</c>

00:04:20.659 --> 00:04:20.669 align:start position:0%
this is not a residual network um this
 

00:04:20.669 --> 00:04:21.770 align:start position:0%
this is not a residual network um this
is<00:04:20.760><c> called</c><00:04:20.910><c> as</c><00:04:21.120><c> a</c>

00:04:21.770 --> 00:04:21.780 align:start position:0%
is called as a
 

00:04:21.780 --> 00:04:23.450 align:start position:0%
is called as a
playing<00:04:21.989><c> that's</c><00:04:22.200><c> work</c><00:04:22.500><c> this</c><00:04:23.280><c> is</c><00:04:23.400><c> a</c>

00:04:23.450 --> 00:04:23.460 align:start position:0%
playing that's work this is a
 

00:04:23.460 --> 00:04:27.260 align:start position:0%
playing that's work this is a
terminology<00:04:23.910><c> of</c><00:04:24.389><c> the</c><00:04:24.900><c> resonant</c><00:04:25.530><c> paper</c><00:04:26.270><c> to</c>

00:04:27.260 --> 00:04:27.270 align:start position:0%
terminology of the resonant paper to
 

00:04:27.270 --> 00:04:29.510 align:start position:0%
terminology of the resonant paper to
turn<00:04:27.540><c> this</c><00:04:27.690><c> into</c><00:04:27.930><c> residence</c><00:04:28.560><c> what</c><00:04:28.830><c> you</c><00:04:28.980><c> do</c><00:04:29.190><c> is</c>

00:04:29.510 --> 00:04:29.520 align:start position:0%
turn this into residence what you do is
 

00:04:29.520 --> 00:04:32.300 align:start position:0%
turn this into residence what you do is
you<00:04:29.760><c> add</c><00:04:30.090><c> all</c><00:04:30.450><c> those</c><00:04:30.810><c> skip</c><00:04:31.740><c> connections</c>

00:04:32.300 --> 00:04:32.310 align:start position:0%
you add all those skip connections
 

00:04:32.310 --> 00:04:34.390 align:start position:0%
you add all those skip connections
although<00:04:32.639><c> those</c><00:04:32.910><c> short</c><00:04:33.240><c> circuit</c><00:04:33.570><c> connections</c>

00:04:34.390 --> 00:04:34.400 align:start position:0%
although those short circuit connections
 

00:04:34.400 --> 00:04:39.610 align:start position:0%
although those short circuit connections
like<00:04:35.400><c> so</c><00:04:35.960><c> so</c><00:04:36.960><c> every</c><00:04:37.230><c> two</c><00:04:37.440><c> layers</c><00:04:37.820><c> ends</c><00:04:38.820><c> up</c><00:04:38.940><c> with</c>

00:04:39.610 --> 00:04:39.620 align:start position:0%
like so so every two layers ends up with
 

00:04:39.620 --> 00:04:44.210 align:start position:0%
like so so every two layers ends up with
that<00:04:41.840><c> additional</c><00:04:42.840><c> change</c><00:04:43.320><c> that</c><00:04:43.560><c> we</c><00:04:43.650><c> saw</c><00:04:43.889><c> on</c>

00:04:44.210 --> 00:04:44.220 align:start position:0%
that additional change that we saw on
 

00:04:44.220 --> 00:04:46.670 align:start position:0%
that additional change that we saw on
their<00:04:44.850><c> previous</c><00:04:45.300><c> slide</c><00:04:45.600><c> to</c><00:04:45.870><c> turn</c><00:04:46.290><c> each</c><00:04:46.650><c> of</c>

00:04:46.670 --> 00:04:46.680 align:start position:0%
their previous slide to turn each of
 

00:04:46.680 --> 00:04:50.060 align:start position:0%
their previous slide to turn each of
these<00:04:47.010><c> into</c><00:04:47.970><c> a</c><00:04:48.000><c> residual</c><00:04:48.600><c> block</c><00:04:48.870><c> so</c><00:04:49.800><c> this</c>

00:04:50.060 --> 00:04:50.070 align:start position:0%
these into a residual block so this
 

00:04:50.070 --> 00:04:52.879 align:start position:0%
these into a residual block so this
picture<00:04:50.340><c> shows</c><00:04:50.760><c> five</c><00:04:51.180><c> residual</c><00:04:51.840><c> blocks</c><00:04:52.139><c> stack</c>

00:04:52.879 --> 00:04:52.889 align:start position:0%
picture shows five residual blocks stack
 

00:04:52.889 --> 00:04:56.150 align:start position:0%
picture shows five residual blocks stack
together<00:04:53.100><c> and</c><00:04:53.580><c> this</c><00:04:54.210><c> is</c><00:04:54.450><c> a</c><00:04:54.810><c> residual</c><00:04:55.500><c> Network</c>

00:04:56.150 --> 00:04:56.160 align:start position:0%
together and this is a residual Network
 

00:04:56.160 --> 00:04:59.840 align:start position:0%
together and this is a residual Network
and<00:04:56.730><c> it</c><00:04:56.880><c> turns</c><00:04:57.060><c> out</c><00:04:57.270><c> that</c><00:04:57.570><c> if</c><00:04:58.470><c> you</c><00:04:58.830><c> use</c><00:04:59.160><c> you</c>

00:04:59.840 --> 00:04:59.850 align:start position:0%
and it turns out that if you use you
 

00:04:59.850 --> 00:05:01.760 align:start position:0%
and it turns out that if you use you
know<00:04:59.940><c> a</c><00:04:59.970><c> standard</c><00:05:00.419><c> optimization</c><00:05:00.960><c> algorithm</c>

00:05:01.760 --> 00:05:01.770 align:start position:0%
know a standard optimization algorithm
 

00:05:01.770 --> 00:05:04.250 align:start position:0%
know a standard optimization algorithm
such<00:05:02.490><c> as</c><00:05:02.520><c> gradient</c><00:05:03.000><c> descents</c><00:05:03.450><c> or</c><00:05:03.630><c> one</c><00:05:03.960><c> of</c><00:05:04.110><c> the</c>

00:05:04.250 --> 00:05:04.260 align:start position:0%
such as gradient descents or one of the
 

00:05:04.260 --> 00:05:06.350 align:start position:0%
such as gradient descents or one of the
fancier<00:05:04.830><c> optimization</c><00:05:05.400><c> algorithms</c><00:05:05.850><c> to</c><00:05:06.120><c> train</c>

00:05:06.350 --> 00:05:06.360 align:start position:0%
fancier optimization algorithms to train
 

00:05:06.360 --> 00:05:08.950 align:start position:0%
fancier optimization algorithms to train
a<00:05:06.390><c> plane</c><00:05:06.630><c> network</c><00:05:07.230><c> so</c><00:05:07.530><c> without</c><00:05:07.890><c> all</c><00:05:08.190><c> the</c><00:05:08.400><c> extra</c>

00:05:08.950 --> 00:05:08.960 align:start position:0%
a plane network so without all the extra
 

00:05:08.960 --> 00:05:12.440 align:start position:0%
a plane network so without all the extra
residual<00:05:09.960><c> without</c><00:05:10.710><c> all</c><00:05:10.950><c> the</c><00:05:11.130><c> extra</c><00:05:11.450><c> shortcuts</c>

00:05:12.440 --> 00:05:12.450 align:start position:0%
residual without all the extra shortcuts
 

00:05:12.450 --> 00:05:13.940 align:start position:0%
residual without all the extra shortcuts
or<00:05:12.660><c> skipped</c><00:05:12.900><c> connections</c><00:05:13.350><c> I</c><00:05:13.440><c> just</c><00:05:13.650><c> drew</c><00:05:13.800><c> in</c>

00:05:13.940 --> 00:05:13.950 align:start position:0%
or skipped connections I just drew in
 

00:05:13.950 --> 00:05:17.330 align:start position:0%
or skipped connections I just drew in
and<00:05:14.310><c> perkily</c><00:05:15.270><c> you</c><00:05:15.450><c> find</c><00:05:15.780><c> that</c><00:05:15.990><c> as</c><00:05:16.590><c> you</c>

00:05:17.330 --> 00:05:17.340 align:start position:0%
and perkily you find that as you
 

00:05:17.340 --> 00:05:19.100 align:start position:0%
and perkily you find that as you
increase<00:05:17.550><c> the</c><00:05:17.910><c> number</c><00:05:17.940><c> of</c><00:05:18.270><c> layers</c><00:05:18.510><c> the</c>

00:05:19.100 --> 00:05:19.110 align:start position:0%
increase the number of layers the
 

00:05:19.110 --> 00:05:20.600 align:start position:0%
increase the number of layers the
training<00:05:19.560><c> error</c><00:05:19.740><c> will</c><00:05:19.830><c> tend</c><00:05:19.950><c> to</c><00:05:20.250><c> decrease</c>

00:05:20.600 --> 00:05:20.610 align:start position:0%
training error will tend to decrease
 

00:05:20.610 --> 00:05:22.670 align:start position:0%
training error will tend to decrease
after<00:05:20.910><c> a</c><00:05:21.120><c> while</c><00:05:21.330><c> but</c><00:05:22.139><c> then</c><00:05:22.260><c> they'll</c><00:05:22.380><c> tend</c><00:05:22.560><c> to</c>

00:05:22.670 --> 00:05:22.680 align:start position:0%
after a while but then they'll tend to
 

00:05:22.680 --> 00:05:27.140 align:start position:0%
after a while but then they'll tend to
go<00:05:22.830><c> back</c><00:05:23.010><c> up</c><00:05:23.300><c> and</c><00:05:24.650><c> in</c><00:05:25.650><c> theory</c><00:05:26.370><c> as</c><00:05:26.640><c> you</c><00:05:26.700><c> make</c><00:05:27.120><c> a</c>

00:05:27.140 --> 00:05:27.150 align:start position:0%
go back up and in theory as you make a
 

00:05:27.150 --> 00:05:29.870 align:start position:0%
go back up and in theory as you make a
new<00:05:27.390><c> network</c><00:05:27.800><c> deeper</c><00:05:28.800><c> you</c><00:05:29.370><c> know</c><00:05:29.490><c> it</c><00:05:29.700><c> should</c>

00:05:29.870 --> 00:05:29.880 align:start position:0%
new network deeper you know it should
 

00:05:29.880 --> 00:05:32.000 align:start position:0%
new network deeper you know it should
only<00:05:30.000><c> do</c><00:05:30.720><c> better</c><00:05:31.080><c> and</c><00:05:31.320><c> better</c><00:05:31.470><c> on</c><00:05:31.890><c> the</c>

00:05:32.000 --> 00:05:32.010 align:start position:0%
only do better and better on the
 

00:05:32.010 --> 00:05:34.430 align:start position:0%
only do better and better on the
training<00:05:32.280><c> set</c><00:05:32.580><c> right</c><00:05:33.120><c> so</c><00:05:33.390><c> the</c><00:05:33.690><c> theory</c><00:05:34.140><c> in</c>

00:05:34.430 --> 00:05:34.440 align:start position:0%
training set right so the theory in
 

00:05:34.440 --> 00:05:36.710 align:start position:0%
training set right so the theory in
theory<00:05:34.830><c> having</c><00:05:35.520><c> a</c><00:05:35.610><c> deeper</c><00:05:35.940><c> network</c><00:05:36.330><c> should</c>

00:05:36.710 --> 00:05:36.720 align:start position:0%
theory having a deeper network should
 

00:05:36.720 --> 00:05:37.640 align:start position:0%
theory having a deeper network should
only<00:05:36.990><c> hope</c>

00:05:37.640 --> 00:05:37.650 align:start position:0%
only hope
 

00:05:37.650 --> 00:05:41.240 align:start position:0%
only hope
but<00:05:38.220><c> in</c><00:05:38.520><c> practice</c><00:05:39.120><c> on</c><00:05:39.360><c> reality</c><00:05:39.840><c> having</c><00:05:40.830><c> a</c><00:05:40.979><c> play</c>

00:05:41.240 --> 00:05:41.250 align:start position:0%
but in practice on reality having a play
 

00:05:41.250 --> 00:05:43.250 align:start position:0%
but in practice on reality having a play
network<00:05:41.760><c> so</c><00:05:42.240><c> now</c><00:05:42.419><c> the</c><00:05:42.479><c> ResNet</c><00:05:42.930><c> but</c><00:05:43.050><c> having</c>

00:05:43.250 --> 00:05:43.260 align:start position:0%
network so now the ResNet but having
 

00:05:43.260 --> 00:05:45.820 align:start position:0%
network so now the ResNet but having
play<00:05:43.470><c> network</c><00:05:43.860><c> this</c><00:05:44.070><c> very</c><00:05:44.280><c> deep</c><00:05:44.550><c> means</c><00:05:45.419><c> that</c>

00:05:45.820 --> 00:05:45.830 align:start position:0%
play network this very deep means that
 

00:05:45.830 --> 00:05:48.560 align:start position:0%
play network this very deep means that
your<00:05:46.830><c> optimization</c><00:05:47.400><c> algorithm</c><00:05:47.910><c> just</c><00:05:48.090><c> as</c><00:05:48.270><c> much</c>

00:05:48.560 --> 00:05:48.570 align:start position:0%
your optimization algorithm just as much
 

00:05:48.570 --> 00:05:50.719 align:start position:0%
your optimization algorithm just as much
harder<00:05:48.960><c> time</c><00:05:49.169><c> in</c><00:05:49.530><c> training</c><00:05:50.039><c> and</c><00:05:50.310><c> so</c><00:05:50.550><c> in</c>

00:05:50.719 --> 00:05:50.729 align:start position:0%
harder time in training and so in
 

00:05:50.729 --> 00:05:53.270 align:start position:0%
harder time in training and so in
reality<00:05:50.930><c> your</c><00:05:51.930><c> training</c><00:05:52.380><c> error</c><00:05:52.560><c> gets</c><00:05:52.919><c> worse</c>

00:05:53.270 --> 00:05:53.280 align:start position:0%
reality your training error gets worse
 

00:05:53.280 --> 00:05:55.460 align:start position:0%
reality your training error gets worse
if<00:05:53.640><c> you</c><00:05:53.820><c> pick</c><00:05:54.030><c> a</c><00:05:54.060><c> network</c><00:05:54.539><c> that's</c><00:05:54.900><c> too</c><00:05:55.260><c> deep</c>

00:05:55.460 --> 00:05:55.470 align:start position:0%
if you pick a network that's too deep
 

00:05:55.470 --> 00:05:58.490 align:start position:0%
if you pick a network that's too deep
but<00:05:56.039><c> what</c><00:05:56.190><c> happens</c><00:05:56.610><c> with</c><00:05:56.850><c> res</c><00:05:57.180><c> Nets</c><00:05:57.479><c> is</c><00:05:57.840><c> that</c>

00:05:58.490 --> 00:05:58.500 align:start position:0%
but what happens with res Nets is that
 

00:05:58.500 --> 00:06:00.860 align:start position:0%
but what happens with res Nets is that
even<00:05:59.190><c> as</c><00:05:59.340><c> a</c><00:05:59.370><c> number</c><00:05:59.729><c> of</c><00:05:59.789><c> layers</c><00:06:00.090><c> gets</c><00:06:00.360><c> deeper</c>

00:06:00.860 --> 00:06:00.870 align:start position:0%
even as a number of layers gets deeper
 

00:06:00.870 --> 00:06:03.200 align:start position:0%
even as a number of layers gets deeper
you<00:06:01.800><c> can</c><00:06:01.830><c> have</c><00:06:02.190><c> the</c><00:06:02.310><c> performance</c><00:06:02.880><c> of</c><00:06:03.120><c> the</c>

00:06:03.200 --> 00:06:03.210 align:start position:0%
you can have the performance of the
 

00:06:03.210 --> 00:06:06.469 align:start position:0%
you can have the performance of the
trading<00:06:03.450><c> ever</c><00:06:03.720><c> to</c><00:06:04.380><c> keep</c><00:06:04.710><c> on</c><00:06:04.890><c> going</c><00:06:05.340><c> down</c><00:06:05.550><c> you</c>

00:06:06.469 --> 00:06:06.479 align:start position:0%
trading ever to keep on going down you
 

00:06:06.479 --> 00:06:08.450 align:start position:0%
trading ever to keep on going down you
know<00:06:06.570><c> even</c><00:06:06.930><c> retrain</c><00:06:07.320><c> a</c><00:06:07.350><c> network</c><00:06:07.860><c> with</c><00:06:08.100><c> over</c><00:06:08.280><c> a</c>

00:06:08.450 --> 00:06:08.460 align:start position:0%
know even retrain a network with over a
 

00:06:08.460 --> 00:06:10.990 align:start position:0%
know even retrain a network with over a
hundred<00:06:08.669><c> layers</c><00:06:09.169><c> and</c><00:06:10.169><c> then</c><00:06:10.320><c> now</c><00:06:10.470><c> some</c><00:06:10.710><c> people</c>

00:06:10.990 --> 00:06:11.000 align:start position:0%
hundred layers and then now some people
 

00:06:11.000 --> 00:06:12.830 align:start position:0%
hundred layers and then now some people
experimenting<00:06:12.000><c> with</c><00:06:12.150><c> networks</c><00:06:12.600><c> there</c><00:06:12.780><c> are</c>

00:06:12.830 --> 00:06:12.840 align:start position:0%
experimenting with networks there are
 

00:06:12.840 --> 00:06:14.390 align:start position:0%
experimenting with networks there are
over<00:06:13.050><c> a</c><00:06:13.080><c> thousand</c><00:06:13.680><c> layers</c>

00:06:14.390 --> 00:06:14.400 align:start position:0%
over a thousand layers
 

00:06:14.400 --> 00:06:16.550 align:start position:0%
over a thousand layers
although<00:06:15.150><c> I</c><00:06:15.180><c> don't</c><00:06:15.300><c> see</c><00:06:15.600><c> that</c><00:06:15.870><c> use</c><00:06:16.139><c> much</c><00:06:16.410><c> in</c>

00:06:16.550 --> 00:06:16.560 align:start position:0%
although I don't see that use much in
 

00:06:16.560 --> 00:06:19.010 align:start position:0%
although I don't see that use much in
practice<00:06:17.009><c> yet</c><00:06:17.400><c> but</c><00:06:18.300><c> by</c><00:06:18.479><c> taking</c><00:06:18.900><c> these</c>

00:06:19.010 --> 00:06:19.020 align:start position:0%
practice yet but by taking these
 

00:06:19.020 --> 00:06:21.290 align:start position:0%
practice yet but by taking these
activations<00:06:19.800><c> being</c><00:06:20.160><c> XOR</c><00:06:20.759><c> these</c><00:06:20.940><c> intermediate</c>

00:06:21.290 --> 00:06:21.300 align:start position:0%
activations being XOR these intermediate
 

00:06:21.300 --> 00:06:24.290 align:start position:0%
activations being XOR these intermediate
activations<00:06:22.199><c> and</c><00:06:22.470><c> allowing</c><00:06:23.460><c> it</c><00:06:23.580><c> to</c><00:06:23.639><c> go</c><00:06:24.030><c> much</c>

00:06:24.290 --> 00:06:24.300 align:start position:0%
activations and allowing it to go much
 

00:06:24.300 --> 00:06:26.480 align:start position:0%
activations and allowing it to go much
deeper<00:06:24.330><c> than</c><00:06:24.900><c> your</c><00:06:25.080><c> network</c><00:06:25.500><c> this</c><00:06:25.919><c> really</c>

00:06:26.480 --> 00:06:26.490 align:start position:0%
deeper than your network this really
 

00:06:26.490 --> 00:06:29.150 align:start position:0%
deeper than your network this really
hosts<00:06:26.820><c> with</c><00:06:27.150><c> the</c><00:06:27.470><c> vanishing</c><00:06:28.470><c> and</c><00:06:28.680><c> exploding</c>

00:06:29.150 --> 00:06:29.160 align:start position:0%
hosts with the vanishing and exploding
 

00:06:29.160 --> 00:06:31.430 align:start position:0%
hosts with the vanishing and exploding
gradient<00:06:29.550><c> problems</c><00:06:30.000><c> and</c><00:06:30.660><c> allows</c><00:06:30.960><c> you</c><00:06:31.199><c> to</c>

00:06:31.430 --> 00:06:31.440 align:start position:0%
gradient problems and allows you to
 

00:06:31.440 --> 00:06:33.290 align:start position:0%
gradient problems and allows you to
Train<00:06:31.770><c> much</c><00:06:32.160><c> deeper</c><00:06:32.580><c> neural</c><00:06:32.850><c> networks</c>

00:06:33.290 --> 00:06:33.300 align:start position:0%
Train much deeper neural networks
 

00:06:33.300 --> 00:06:35.600 align:start position:0%
Train much deeper neural networks
without<00:06:33.810><c> really</c><00:06:34.530><c> appreciable</c><00:06:35.039><c> loss</c><00:06:35.220><c> in</c>

00:06:35.600 --> 00:06:35.610 align:start position:0%
without really appreciable loss in
 

00:06:35.610 --> 00:06:37.700 align:start position:0%
without really appreciable loss in
performance<00:06:35.729><c> and</c><00:06:36.330><c> maybe</c><00:06:36.509><c> at</c><00:06:36.660><c> some</c><00:06:36.810><c> point</c><00:06:36.870><c> this</c>

00:06:37.700 --> 00:06:37.710 align:start position:0%
performance and maybe at some point this
 

00:06:37.710 --> 00:06:39.590 align:start position:0%
performance and maybe at some point this
will<00:06:37.860><c> Plateau</c><00:06:38.190><c> this</c><00:06:38.639><c> will</c><00:06:38.789><c> flatten</c><00:06:39.060><c> out</c><00:06:39.389><c> and</c>

00:06:39.590 --> 00:06:39.600 align:start position:0%
will Plateau this will flatten out and
 

00:06:39.600 --> 00:06:41.840 align:start position:0%
will Plateau this will flatten out and
doesn't<00:06:39.990><c> help</c><00:06:40.139><c> that</c><00:06:40.530><c> much</c><00:06:41.190><c> the</c><00:06:41.430><c> deeper</c><00:06:41.759><c> and</c>

00:06:41.840 --> 00:06:41.850 align:start position:0%
doesn't help that much the deeper and
 

00:06:41.850 --> 00:06:44.749 align:start position:0%
doesn't help that much the deeper and
deeper<00:06:42.120><c> networks</c><00:06:42.539><c> but</c><00:06:43.340><c> residents</c><00:06:44.340><c> are</c><00:06:44.580><c> so</c>

00:06:44.749 --> 00:06:44.759 align:start position:0%
deeper networks but residents are so
 

00:06:44.759 --> 00:06:47.779 align:start position:0%
deeper networks but residents are so
even<00:06:45.380><c> effective</c><00:06:46.380><c> that</c><00:06:46.650><c> helping</c><00:06:47.100><c> train</c><00:06:47.460><c> very</c>

00:06:47.779 --> 00:06:47.789 align:start position:0%
even effective that helping train very
 

00:06:47.789 --> 00:06:50.570 align:start position:0%
even effective that helping train very
deep<00:06:48.060><c> networks</c><00:06:48.539><c> so</c><00:06:49.440><c> you've</c><00:06:49.710><c> now</c><00:06:49.889><c> gotten</c><00:06:50.250><c> an</c>

00:06:50.570 --> 00:06:50.580 align:start position:0%
deep networks so you've now gotten an
 

00:06:50.580 --> 00:06:52.969 align:start position:0%
deep networks so you've now gotten an
overview<00:06:51.060><c> of</c><00:06:51.300><c> how</c><00:06:51.510><c> resonance</c><00:06:52.110><c> work</c><00:06:52.410><c> and</c><00:06:52.770><c> in</c>

00:06:52.969 --> 00:06:52.979 align:start position:0%
overview of how resonance work and in
 

00:06:52.979 --> 00:06:55.730 align:start position:0%
overview of how resonance work and in
fact<00:06:53.160><c> in</c><00:06:53.460><c> this</c><00:06:53.760><c> week's</c><00:06:54.000><c> program</c><00:06:54.780><c> exercise</c><00:06:55.050><c> you</c>

00:06:55.730 --> 00:06:55.740 align:start position:0%
fact in this week's program exercise you
 

00:06:55.740 --> 00:06:57.920 align:start position:0%
fact in this week's program exercise you
get<00:06:55.949><c> to</c><00:06:56.070><c> implement</c><00:06:56.550><c> these</c><00:06:56.669><c> ideas</c><00:06:56.729><c> and</c><00:06:57.389><c> see</c><00:06:57.810><c> it</c>

00:06:57.920 --> 00:06:57.930 align:start position:0%
get to implement these ideas and see it
 

00:06:57.930 --> 00:06:58.879 align:start position:0%
get to implement these ideas and see it
work<00:06:58.080><c> for</c><00:06:58.380><c> yourself</c>

00:06:58.879 --> 00:06:58.889 align:start position:0%
work for yourself
 

00:06:58.889 --> 00:07:01.310 align:start position:0%
work for yourself
but<00:06:59.460><c> next</c><00:06:59.820><c> I</c><00:07:00.030><c> want</c><00:07:00.240><c> to</c><00:07:00.330><c> share</c><00:07:00.510><c> of</c><00:07:00.660><c> you</c><00:07:00.840><c> better</c>

00:07:01.310 --> 00:07:01.320 align:start position:0%
but next I want to share of you better
 

00:07:01.320 --> 00:07:03.680 align:start position:0%
but next I want to share of you better
intuition<00:07:01.620><c> or</c><00:07:02.370><c> even</c><00:07:02.639><c> more</c><00:07:02.820><c> intuition</c><00:07:03.479><c> about</c>

00:07:03.680 --> 00:07:03.690 align:start position:0%
intuition or even more intuition about
 

00:07:03.690 --> 00:07:06.770 align:start position:0%
intuition or even more intuition about
why<00:07:04.110><c> resinous</c><00:07:04.979><c> work</c><00:07:05.310><c> so</c><00:07:05.610><c> well</c><00:07:05.820><c> let's</c><00:07:06.479><c> go</c><00:07:06.660><c> onto</c>

00:07:06.770 --> 00:07:06.780 align:start position:0%
why resinous work so well let's go onto
 

00:07:06.780 --> 00:07:09.530 align:start position:0%
why resinous work so well let's go onto
the<00:07:06.990><c> next</c><00:07:07.020><c> video</c>

