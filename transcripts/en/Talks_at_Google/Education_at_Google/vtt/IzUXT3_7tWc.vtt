WEBVTT
Kind: captions
Language: en

00:00:01.422 --> 00:00:02.880
MAGGIE JOHNSON:
The way that Google

00:00:02.880 --> 00:00:06.670
started was an academic venture.

00:00:06.670 --> 00:00:08.810
JEFF DEAN: How do you
find interesting problems

00:00:08.810 --> 00:00:09.540
in the world?

00:00:09.540 --> 00:00:11.730
ALFRED SPECTOR: Google
depends on academia.

00:00:11.730 --> 00:00:14.090
So many of the good ideas
that we've brought forward

00:00:14.090 --> 00:00:16.010
to the world come from academia.

00:00:16.010 --> 00:00:18.900
JEFF DEAN: One of the real
reasons to engage with academia

00:00:18.900 --> 00:00:20.561
is to get a really
fresh perspective.

00:00:20.561 --> 00:00:22.060
MAGGIE JOHNSON: We
empower academics

00:00:22.060 --> 00:00:23.280
to work on real problems.

00:00:23.280 --> 00:00:25.690
And in the other
direction, academics

00:00:25.690 --> 00:00:28.300
bring ideas and
new approaches that

00:00:28.300 --> 00:00:31.380
are put into practice
much more quickly

00:00:31.380 --> 00:00:32.857
than in an academic environment.

00:00:32.857 --> 00:00:34.690
JEFF DEAN: You know,
oh, that's interesting,

00:00:34.690 --> 00:00:36.534
that's interesting,
that's interesting.

00:00:36.534 --> 00:00:38.200
All of a sudden,
you've knitted together

00:00:38.200 --> 00:00:40.545
something that is really,
really, tremendously powerful.

00:00:40.545 --> 00:00:42.920
MAGGIE JOHNSON: We need their
help because of the problem

00:00:42.920 --> 00:00:44.474
we're trying to
solve internally.

00:00:44.474 --> 00:00:46.890
ALFRED SPECTOR: Academia can
look far out into the future,

00:00:46.890 --> 00:00:50.260
it can take greater risks, and
look for really interesting

00:00:50.260 --> 00:00:51.990
solutions that industry
sometimes cannot.

00:01:05.519 --> 00:01:07.060
KEN GOLDBERG: My
name's Ken Goldberg.

00:01:07.060 --> 00:01:10.180
I'm a professor at UC Berkeley
in the College of Engineering

00:01:10.180 --> 00:01:11.580
and School of Information.

00:01:11.580 --> 00:01:14.330
And I run a robotics lab
there where we do research

00:01:14.330 --> 00:01:15.985
in areas like surgical robotics.

00:01:15.985 --> 00:01:17.610
And what I'm really
excited about right

00:01:17.610 --> 00:01:19.820
now is cloud robotics.

00:01:19.820 --> 00:01:21.570
MATEI CIOCARLIE: And
I am Matei Ciocarlie.

00:01:21.570 --> 00:01:23.650
I'm a research scientist
here at Google.

00:01:23.650 --> 00:01:25.950
I am part of the
robotics effort hoping

00:01:25.950 --> 00:01:28.750
to advance the state of
robotic mobile manipulation

00:01:28.750 --> 00:01:31.200
and allow robots to do
things that they're not

00:01:31.200 --> 00:01:33.010
able to do today.

00:01:33.010 --> 00:01:35.260
KEN GOLDBERG: Well, I've
been interested in this field

00:01:35.260 --> 00:01:38.430
for a long time,
since I was a kid.

00:01:38.430 --> 00:01:41.070
I think every kid gets
interested in robots.

00:01:41.070 --> 00:01:44.230
We sometimes talk about
them as the gateway drug

00:01:44.230 --> 00:01:47.950
for STEM- science, technology,
engineering and math.

00:01:47.950 --> 00:01:49.820
And it's because
that are robots are

00:01:49.820 --> 00:01:51.150
very compelling at all levels.

00:01:51.150 --> 00:01:54.500
I think kids are
captivated by them.

00:01:54.500 --> 00:01:59.020
But really, adults and anyone
is interested in the idea

00:01:59.020 --> 00:02:02.510
of making something
that can become alive.

00:02:02.510 --> 00:02:04.600
Cloud robotics has
a long history.

00:02:04.600 --> 00:02:08.009
The way I think about it is
it goes back to early work

00:02:08.009 --> 00:02:12.580
when the internet emerged
in the early '90s,

00:02:12.580 --> 00:02:16.010
and a number of groups started
putting together robots

00:02:16.010 --> 00:02:17.090
with the internet.

00:02:17.090 --> 00:02:21.720
And the idea was that we could
use the resource of the world

00:02:21.720 --> 00:02:25.830
wide web as a standard to allow
people to come in from anywhere

00:02:25.830 --> 00:02:28.540
in the world and operate
industrial robots.

00:02:28.540 --> 00:02:31.190
MATEI CIOCARLIE: It truly is a
symbiotic relationship, right?

00:02:31.190 --> 00:02:33.800
At Google, one of the
things we deeply care about

00:02:33.800 --> 00:02:35.677
is understanding the world.

00:02:35.677 --> 00:02:37.052
KEN GOLDBERG:
Well, the one thing

00:02:37.052 --> 00:02:40.510
that's really emerged in
the last couple of years

00:02:40.510 --> 00:02:45.140
is a way of thinking about the
cloud as an active resource.

00:02:45.140 --> 00:02:48.270
When the building
that my office is in

00:02:48.270 --> 00:02:50.390
was constructed
only 10 years ago,

00:02:50.390 --> 00:02:52.660
there's an enormous
basement that

00:02:52.660 --> 00:02:55.670
was dedicated for
computing facilities.

00:02:55.670 --> 00:02:58.400
It's empty now, because
we don't do that.

00:02:58.400 --> 00:03:03.050
We don't actually have
computing in the building.

00:03:03.050 --> 00:03:05.060
Everything is done on the cloud.

00:03:05.060 --> 00:03:06.510
We need vast computation.

00:03:06.510 --> 00:03:10.950
We use cloud clusters on demand.

00:03:10.950 --> 00:03:12.340
And that makes a lot more sense.

00:03:12.340 --> 00:03:14.340
Because it can be
centralized, it can be shared,

00:03:14.340 --> 00:03:15.680
they could be upgraded
and maintained.

00:03:15.680 --> 00:03:17.910
MATEI CIOCARLIE: Sharing is a
really important part of it,

00:03:17.910 --> 00:03:18.430
right?

00:03:18.430 --> 00:03:22.350
Imagine if we had
to advance science

00:03:22.350 --> 00:03:23.950
but we couldn't
leverage anything

00:03:23.950 --> 00:03:26.230
that any other person
has done in the past.

00:03:26.230 --> 00:03:27.800
We couldn't teach
each other verbally

00:03:27.800 --> 00:03:29.180
or through the written text.

00:03:29.180 --> 00:03:31.500
And in a sense, that's what
robots are without sharing.

00:03:31.500 --> 00:03:35.250
And the cloud can enable
robots to share knowledge,

00:03:35.250 --> 00:03:38.565
to share things that they've
understood about the world.

00:03:38.565 --> 00:03:40.690
KEN GOLDBERG: We were saying
about it's interesting

00:03:40.690 --> 00:03:46.490
that sharing has become this
very whole new-- it reaches

00:03:46.490 --> 00:03:49.110
new levels where people share
every detail of their life.

00:03:49.110 --> 00:03:51.840
What they had for
breakfast, where they were.

00:03:51.840 --> 00:03:55.700
And in a sense though,
there is this idea

00:03:55.700 --> 00:03:58.096
that robots can start
doing something similar.

00:03:58.096 --> 00:03:59.470
They can say, hey,
I just learned

00:03:59.470 --> 00:04:03.170
how to pick up this pair
of eyeglasses in a new way,

00:04:03.170 --> 00:04:05.720
and instantly share that
with every other robot.

00:04:05.720 --> 00:04:08.350
So if another robot comes and
sees that pair of eyeglasses,

00:04:08.350 --> 00:04:09.910
they know exactly what to do.

00:04:09.910 --> 00:04:16.074
And I think that idea of
accumulating information

00:04:16.074 --> 00:04:18.490
is really what's been happening
with the web at one level,

00:04:18.490 --> 00:04:21.230
but can now enter an
entirely new level.

00:04:21.230 --> 00:04:24.460
Working closely with
James and his colleagues,

00:04:24.460 --> 00:04:28.460
we were able to actually get
access to the computing engine

00:04:28.460 --> 00:04:32.700
and we were able to take
images and do experiments

00:04:32.700 --> 00:04:35.800
that we reported in a
conference paper last year.

00:04:35.800 --> 00:04:38.740
And we're very excited now about
taking this to the next level.

00:04:38.740 --> 00:04:40.620
We have a number
of ideas about how

00:04:40.620 --> 00:04:44.800
image libraries-- or actually
libraries of 3D objects,

00:04:44.800 --> 00:04:47.330
of solids and mechanics,
could actually

00:04:47.330 --> 00:04:50.210
be used to enhance
grasping using ideas

00:04:50.210 --> 00:04:53.120
that Matei has
pioneered where we

00:04:53.120 --> 00:04:58.690
can do, for example,
very complex computation

00:04:58.690 --> 00:05:00.200
about grasp strategies.

00:05:00.200 --> 00:05:01.950
But these can be pre
computed in the cloud

00:05:01.950 --> 00:05:05.190
and then stored so that
they can be indexed online

00:05:05.190 --> 00:05:07.370
very rapidly when a new
object is encountered.

00:05:07.370 --> 00:05:10.040
The field has really
changed dramatically

00:05:10.040 --> 00:05:12.510
in the last couple of years,
and particularly last year

00:05:12.510 --> 00:05:14.830
with the announcement
by Google that it

00:05:14.830 --> 00:05:18.010
was getting into this
field in a big way

00:05:18.010 --> 00:05:21.530
and acquiring a number
of major companies.

00:05:21.530 --> 00:05:24.760
This has been a big
boost for researchers.

00:05:24.760 --> 00:05:28.720
I think bringing a critical mass
of people like Matei, James,

00:05:28.720 --> 00:05:32.420
and many of my former
students together here

00:05:32.420 --> 00:05:37.330
is really creating
this critical mass

00:05:37.330 --> 00:05:40.590
where lots of interesting
things are happening.

00:05:40.590 --> 00:05:46.820
Getting this agenda together
where they are bringing skills

00:05:46.820 --> 00:05:52.330
from many different areas to
focus on problems of robotics

00:05:52.330 --> 00:05:53.630
is very exciting.

00:05:53.630 --> 00:05:56.210
I think that also
because Google is really

00:05:56.210 --> 00:05:59.780
at the forefront
of the cloud, you

00:05:59.780 --> 00:06:03.130
have all the skills in
robotics, traditional robotics

00:06:03.130 --> 00:06:04.970
or advanced robotics
I should say,

00:06:04.970 --> 00:06:06.460
and then you're combining
them with all the skills

00:06:06.460 --> 00:06:07.001
of the cloud.

00:06:07.001 --> 00:06:08.880
And the potential
here is enormous.

00:06:08.880 --> 00:06:10.980
One of [? the good ?]
questions is

00:06:10.980 --> 00:06:13.000
what are these robots
going to look like.

00:06:13.000 --> 00:06:16.220
And my own feeling,
because I work also

00:06:16.220 --> 00:06:18.600
in factories and
factory robots, I'm

00:06:18.600 --> 00:06:21.314
not convinced that
robots are necessarily

00:06:21.314 --> 00:06:22.230
going to be humanoids.

00:06:22.230 --> 00:06:22.810
MATEI CIOCARLIE: Exactly.

00:06:22.810 --> 00:06:24.400
KEN GOLDBERG: I think
that they're not

00:06:24.400 --> 00:06:30.250
going to look-- this comes back
to Sigmund Freud, actually, who

00:06:30.250 --> 00:06:31.750
wrote about the uncanny.

00:06:31.750 --> 00:06:35.170
And the ideas about
the uncanny valley

00:06:35.170 --> 00:06:38.020
indicate that if a robot
looks too much like a human,

00:06:38.020 --> 00:06:41.552
it actually leads to a sense
of discomfort for many people.

00:06:41.552 --> 00:06:42.510
MATEI CIOCARLIE: Right.

00:06:42.510 --> 00:06:43.660
KEN GOLDBERG: And
so I don't think

00:06:43.660 --> 00:06:44.993
we necessarily need to go there.

00:06:44.993 --> 00:06:48.200
I think we want a robot
to look like a machine.

00:06:48.200 --> 00:06:51.150
It'll do something that will go
around and clean up our house,

00:06:51.150 --> 00:06:51.690
for example.

00:06:51.690 --> 00:06:56.132
Keep our floors clean, or
maybe someday keep us company.

00:06:56.132 --> 00:06:58.590
But I don't think it needs to
look like a human to do that.

00:06:58.590 --> 00:07:01.173
MATEI CIOCARLIE: To me, trying
to copy the human [? for the ?]

00:07:01.173 --> 00:07:03.380
robot, you get what you
had hundreds of years ago

00:07:03.380 --> 00:07:05.990
when people were trying to
build flying machines by copying

00:07:05.990 --> 00:07:06.760
the birds.

00:07:06.760 --> 00:07:09.810
And you had devices that
flapped wings and look

00:07:09.810 --> 00:07:13.600
more or less biological
and fell off cliffs.

00:07:13.600 --> 00:07:14.330
Right?

00:07:14.330 --> 00:07:15.760
Whereas when we
finally understood

00:07:15.760 --> 00:07:19.910
the principle of lift,
that's when flight took off.

00:07:19.910 --> 00:07:20.650
Right?

00:07:20.650 --> 00:07:23.290
So a robot doesn't necessarily
have to copy the human.

00:07:23.290 --> 00:07:26.550
If you try to copy the human,
we'll copy the wrong things.

00:07:26.550 --> 00:07:30.650
A robot needs to have a function
and get a job done for us.

00:07:30.650 --> 00:07:33.317
And if it doesn't look human
when doing that, that's fine.

00:07:33.317 --> 00:07:34.150
KEN GOLDBERG: Right.

00:07:34.150 --> 00:07:35.900
So we might not even
recognize-- right now

00:07:35.900 --> 00:07:40.907
when we look-- what robots
may evolve to are things

00:07:40.907 --> 00:07:42.990
that we may not even be
able to imagine right now.

00:07:42.990 --> 00:07:44.448
I mean, they may
not look like what

00:07:44.448 --> 00:07:46.202
we think they're
going to look like.

00:07:46.202 --> 00:07:48.660
So it's a pleasure to come down
to Google where all this is

00:07:48.660 --> 00:07:51.150
happening, really at the
center of all the action.

00:07:51.150 --> 00:07:53.530
And for a lot more details
on all these topics

00:07:53.530 --> 00:07:56.181
we talked about, see my Talk.

