WEBVTT
Kind: captions
Language: en

00:00:09.499 --> 00:00:11.790
ELIZABETH HARTNETT: All right,
good afternoon everyone.

00:00:11.790 --> 00:00:13.340
Welcome to YouTube Space LA.

00:00:13.340 --> 00:00:16.660
My name is Liz Hartnett, and
I oversee global programs

00:00:16.660 --> 00:00:19.400
and education here at the space.

00:00:19.400 --> 00:00:21.740
So at all of our YouTube
spaces, our mission

00:00:21.740 --> 00:00:25.210
is to bring together the most
creative people in the world.

00:00:25.210 --> 00:00:26.720
And with that in
mind, we couldn't

00:00:26.720 --> 00:00:28.670
be more excited to have
this particular Google

00:00:28.670 --> 00:00:30.240
Talk happening here today.

00:00:30.240 --> 00:00:32.720
So a little bit
about why we're here.

00:00:32.720 --> 00:00:36.280
Academics at Google is a
series that we run here.

00:00:36.280 --> 00:00:39.190
And it's about highlighting
creative and innovative

00:00:39.190 --> 00:00:42.000
research projects
that are developed

00:00:42.000 --> 00:00:44.450
by leading academic
institutions.

00:00:44.450 --> 00:00:47.430
So today, we're super
excited to have Jeff Burke.

00:00:47.430 --> 00:00:50.640
He is the Associate Dean for
Technology and Innovation

00:00:50.640 --> 00:00:54.380
at UCLA's Film, TV and
Theater department.

00:00:54.380 --> 00:00:58.150
And he'll be sharing some
really exciting projects

00:00:58.150 --> 00:01:01.210
that he oversaw with
a team of students,

00:01:01.210 --> 00:01:04.050
where they were exploring
of various applications

00:01:04.050 --> 00:01:07.090
for Google Glass, that are
a little bit out of the box.

00:01:07.090 --> 00:01:09.030
So with that, let's give
Jeff a warm welcome.

00:01:12.690 --> 00:01:13.860
JEFF BURKE: Hi, everybody.

00:01:13.860 --> 00:01:15.050
Thanks for having me here.

00:01:15.050 --> 00:01:18.270
I think the last tech talk
that I did a long time ago,

00:01:18.270 --> 00:01:20.570
was in a small conference
room in Mountain View.

00:01:20.570 --> 00:01:23.120
So this is totally different.

00:01:23.120 --> 00:01:27.599
I'm going to talk for about a
half hour about this class--

00:01:27.599 --> 00:01:30.140
the Glass class at the School
of Theater, Film and Television

00:01:30.140 --> 00:01:32.870
at UCLA, that we ran last year.

00:01:32.870 --> 00:01:35.870
And the process of
the class, a couple

00:01:35.870 --> 00:01:38.920
of projects that were produced
as part of that class,

00:01:38.920 --> 00:01:40.850
and some of the technology
that was involved.

00:01:40.850 --> 00:01:42.990
And in particular,
the collaboration

00:01:42.990 --> 00:01:45.320
that happened here
at YouTube Space La

00:01:45.320 --> 00:01:48.070
and with the glass team
about one of those projects.

00:01:48.070 --> 00:01:51.030
And then we'll have about
a half hour for questions.

00:01:51.030 --> 00:01:57.370
So there is always something
that happens in a demo.

00:01:57.370 --> 00:02:01.580
So I'm going to go restart the
slides, if there's a problem.

00:02:08.380 --> 00:02:10.270
OK.

00:02:10.270 --> 00:02:14.040
So the fundamental
question of the class was,

00:02:14.040 --> 00:02:18.250
what are the stories that we
can tell uniquely on Glass?

00:02:18.250 --> 00:02:20.290
And the research
project that went along

00:02:20.290 --> 00:02:22.360
with it was a little bit
different, which was,

00:02:22.360 --> 00:02:24.860
what are the types of stories
that we can tell uniquely?

00:02:24.860 --> 00:02:27.470
How do we think about
the new capabilities

00:02:27.470 --> 00:02:31.720
of wearable computing, of Glass
in particular, of internet

00:02:31.720 --> 00:02:33.800
enabled technologies in general.

00:02:33.800 --> 00:02:36.450
And how do we explore
this in a hands--on way?

00:02:36.450 --> 00:02:41.070
So this class had about 11
undergraduate and graduate

00:02:41.070 --> 00:02:44.560
students from our department
of Film, Television and Digital

00:02:44.560 --> 00:02:46.330
Media and our
department of Theatre,

00:02:46.330 --> 00:02:48.960
as well as some Ph.D.
Computer Science students.

00:02:48.960 --> 00:02:53.380
And then a host of support
from our Remap Lab,

00:02:53.380 --> 00:02:56.130
from other faculty that
became involved in the class,

00:02:56.130 --> 00:02:57.880
and YouTube Space
LA, as they were

00:02:57.880 --> 00:02:59.580
helping us to
produce the project.

00:02:59.580 --> 00:03:01.330
The, kind of,
brief for the class

00:03:01.330 --> 00:03:04.160
was to think about
location based and audience

00:03:04.160 --> 00:03:05.410
aware storytelling.

00:03:05.410 --> 00:03:08.380
How do you tell stories that
are dependent on the context

00:03:08.380 --> 00:03:09.820
of where they're experienced?

00:03:09.820 --> 00:03:12.800
Which is exactly what we saw
as being a unique capability

00:03:12.800 --> 00:03:15.000
of wearable
computing like Glass.

00:03:15.000 --> 00:03:17.070
And this was supported
by Google, by the Glass

00:03:17.070 --> 00:03:19.150
creative collective,
and like I said,

00:03:19.150 --> 00:03:20.910
was really the sort
of intersection

00:03:20.910 --> 00:03:23.410
of research and practice.

00:03:23.410 --> 00:03:25.590
And the explicit
goal of the class

00:03:25.590 --> 00:03:29.680
was to do exploration;
do hands-on exploration

00:03:29.680 --> 00:03:33.170
in storytelling and technology
and then kind of switch modes

00:03:33.170 --> 00:03:35.490
and produce two
projects for the public.

00:03:35.490 --> 00:03:38.101
And when we sort of pitched
this and invited the students,

00:03:38.101 --> 00:03:39.850
we didn't really know
what that would mean

00:03:39.850 --> 00:03:42.450
or that we would end up here.

00:03:42.450 --> 00:03:45.970
And we did do a fair
amount of experimentation

00:03:45.970 --> 00:03:49.440
with Glass as a
point of view camera,

00:03:49.440 --> 00:03:52.520
or as a documentary tool,
or sort of a unique way

00:03:52.520 --> 00:03:54.770
to do filmmaking.

00:03:54.770 --> 00:03:57.730
And that was something that was
very informative for the class

00:03:57.730 --> 00:04:00.010
and the process that
we went through.

00:04:00.010 --> 00:04:02.880
But really the evolution
that we wanted to make

00:04:02.880 --> 00:04:05.270
and the experimentation with
the students were doing,

00:04:05.270 --> 00:04:08.560
was moving from the
idea of a single story,

00:04:08.560 --> 00:04:10.560
to the construction
of a system--

00:04:10.560 --> 00:04:12.060
a system the generates stories.

00:04:12.060 --> 00:04:15.620
And you could think of a game
as exactly that kind of idea,

00:04:15.620 --> 00:04:16.149
right?

00:04:16.149 --> 00:04:19.029
A storytelling system
that people experience.

00:04:19.029 --> 00:04:21.230
And we wanted to do the
same thing in the class.

00:04:21.230 --> 00:04:24.190
In a different talk, that we
don't have time for today,

00:04:24.190 --> 00:04:26.580
I would like to talk
about the relationship

00:04:26.580 --> 00:04:29.650
between the architecture
that supports

00:04:29.650 --> 00:04:31.690
those systems, and
then the stories

00:04:31.690 --> 00:04:34.691
that are built on those systems,
and as this kind of completes

00:04:34.691 --> 00:04:35.190
the picture.

00:04:35.190 --> 00:04:37.500
But we're going to focus on
the first two things today.

00:04:37.500 --> 00:04:40.630
And so stories tend
to have scripts

00:04:40.630 --> 00:04:42.880
and those scripts are enacted.

00:04:42.880 --> 00:04:46.232
And systems have code and
that code is executed.

00:04:46.232 --> 00:04:48.690
And architectures, which we're
going to defer a little bit,

00:04:48.690 --> 00:04:51.200
are specified, and
those specifications

00:04:51.200 --> 00:04:52.462
are embodied in a real thing.

00:04:52.462 --> 00:04:54.170
There is an architecture
for the internet

00:04:54.170 --> 00:04:56.250
and it is embodied
in a real thing.

00:04:56.250 --> 00:04:59.250
All of these have in common
the notion of interpretation.

00:04:59.250 --> 00:05:02.820
Sort of starting with a concept
and then allowing other people

00:05:02.820 --> 00:05:05.760
to interpret it and bring it
to life in a particular way.

00:05:05.760 --> 00:05:08.920
And the influences that
we had in this class,

00:05:08.920 --> 00:05:13.170
we're certainly feature film
and television production.

00:05:13.170 --> 00:05:15.890
In Hollywood, they were
mainstream theater and art.

00:05:15.890 --> 00:05:18.920
But they were also the sort
of avant garde tradition

00:05:18.920 --> 00:05:22.180
in both theater and film,
that led us to sort of think

00:05:22.180 --> 00:05:25.160
about the relationship
between stories and systems.

00:05:25.160 --> 00:05:28.306
This is a scene from a
Beckett play called "Quad,"

00:05:28.306 --> 00:05:29.680
that was produced
for television.

00:05:29.680 --> 00:05:32.330
And if you read the script,
it's really an algorithm--

00:05:32.330 --> 00:05:35.800
a system for movement that
actually generates the end

00:05:35.800 --> 00:05:36.619
experience.

00:05:36.619 --> 00:05:38.910
If you're familiar with the
performance artist Stelarc,

00:05:38.910 --> 00:05:42.020
he actually connected his body
to the internet, long ago,

00:05:42.020 --> 00:05:47.260
and drove the motion of his body
directly from the connection--

00:05:47.260 --> 00:05:50.180
from sort of, the traffic
patterns of the internet,

00:05:50.180 --> 00:05:51.060
live onstage.

00:05:51.060 --> 00:05:53.490
And so on one hand, we have
narrative storytelling,

00:05:53.490 --> 00:05:56.730
and on the other hand, we have
this exploration of new forms,

00:05:56.730 --> 00:05:58.510
and new medias, and
new technologies.

00:05:58.510 --> 00:06:00.760
So the first thing that the
students did in the class,

00:06:00.760 --> 00:06:02.890
was to have an
adaptation project.

00:06:02.890 --> 00:06:05.450
And there are four, sort
of quick images pulled

00:06:05.450 --> 00:06:07.230
from those projects
in the class.

00:06:07.230 --> 00:06:11.690
And they ranged from games, to a
sort of roll playing experience

00:06:11.690 --> 00:06:14.330
based on Dungeons and
Dragons, to original stories

00:06:14.330 --> 00:06:15.600
and performances.

00:06:15.600 --> 00:06:18.390
And those were
experimented with in sort

00:06:18.390 --> 00:06:22.040
of, real time, simple,
live experiments.

00:06:22.040 --> 00:06:23.880
And we built little
pieces of technology

00:06:23.880 --> 00:06:27.080
where we saw things
missing, that

00:06:27.080 --> 00:06:28.840
were crucial to
those experiments.

00:06:28.840 --> 00:06:32.440
So on the left hand
side of the screen,

00:06:32.440 --> 00:06:35.600
is a very simple web interface
that we built for one classroom

00:06:35.600 --> 00:06:39.300
exercise that we couldn't
find an equivalent on Glass.

00:06:39.300 --> 00:06:43.420
And that allowed us to push,
in real time, text or images

00:06:43.420 --> 00:06:46.790
or generally sort of any
HTML five page to Glass,

00:06:46.790 --> 00:06:48.150
with very low delay.

00:06:48.150 --> 00:06:51.120
And get right from somebody
sitting at their desk

00:06:51.120 --> 00:06:54.170
or on a phone, to a
person wearing Glass.

00:06:54.170 --> 00:06:56.030
And these became
a rehearsal tool

00:06:56.030 --> 00:06:59.054
for performers who were
informed by people offstage.

00:06:59.054 --> 00:07:00.470
And so this was
something that was

00:07:00.470 --> 00:07:02.660
built for an experiment,
that came out

00:07:02.660 --> 00:07:05.220
of one of these mid-term,
adaptation projects.

00:07:05.220 --> 00:07:07.670
And that experiment
then, influenced

00:07:07.670 --> 00:07:10.310
all of the sort of
production that we

00:07:10.310 --> 00:07:11.820
put around two concepts, later.

00:07:11.820 --> 00:07:14.170
So we built little bits
of simple technology

00:07:14.170 --> 00:07:15.990
that filled gaps
in what we couldn't

00:07:15.990 --> 00:07:18.150
find in existing Glassware.

00:07:18.150 --> 00:07:21.250
And then by about one quarter
in-- so we have 10 week

00:07:21.250 --> 00:07:23.950
quarters-- by about
10 weeks in, we

00:07:23.950 --> 00:07:26.470
pivoted to really talk
about the movement

00:07:26.470 --> 00:07:30.590
from, what a piece could-- be or
what an artistic concept could

00:07:30.590 --> 00:07:32.180
be-- to actually
what we could make.

00:07:32.180 --> 00:07:34.860
And so what I'll talk about
for the rest of this talk,

00:07:34.860 --> 00:07:38.920
is two projects that were
produced as experiments, based

00:07:38.920 --> 00:07:40.130
on these kind of ideas.

00:07:40.130 --> 00:07:44.100
Either adapting previous works,
for creating original work that

00:07:44.100 --> 00:07:47.690
was inspired by the capabilities
that were available to us.

00:07:47.690 --> 00:07:50.550
And one of the other prompts,
because we're university

00:07:50.550 --> 00:07:52.550
and because this was an
experiment and research,

00:07:52.550 --> 00:07:55.590
was to take some
aspects of those pieces

00:07:55.590 --> 00:07:57.760
to their logical
extreme, and try

00:07:57.760 --> 00:08:00.820
to understand the
relationship between our goal

00:08:00.820 --> 00:08:04.350
as storytellers, the
capability of the technologies,

00:08:04.350 --> 00:08:07.577
and really what would happen
if we went pretty far.

00:08:07.577 --> 00:08:09.660
And so the first example
that I want to talk about

00:08:09.660 --> 00:08:12.030
was an original
story, which will

00:08:12.030 --> 00:08:16.024
screen a piece of now
and later tonight.

00:08:16.024 --> 00:08:17.940
And it was called "Bodies
for a Global Brain."

00:08:17.940 --> 00:08:20.840
And this was by one of our
writer/director MFA students,

00:08:20.840 --> 00:08:23.770
and put together
by the whole class.

00:08:23.770 --> 00:08:27.020
And this was a love story
between a programmer,

00:08:27.020 --> 00:08:31.060
Ada, and an actor, Steve, who
encountered, essentially what

00:08:31.060 --> 00:08:34.704
they felt like was an emerging,
collective consciousness

00:08:34.704 --> 00:08:35.370
on the internet.

00:08:35.370 --> 00:08:37.929
Remember, this is
fiction-- at least so far.

00:08:37.929 --> 00:08:41.630
And they wanted, in the story,
to embody that consciousness

00:08:41.630 --> 00:08:43.250
and go through the
series of steps

00:08:43.250 --> 00:08:46.950
to make it real in the
world and give it eyes.

00:08:46.950 --> 00:08:50.910
And that idea of giving eyes
to some other consciousness,

00:08:50.910 --> 00:08:53.370
came from one of the
mid-term projects.

00:08:53.370 --> 00:08:56.600
This idea of, sort
of, how you could

00:08:56.600 --> 00:08:59.420
drive interaction the real
world, came from another one.

00:08:59.420 --> 00:09:02.660
And so based on that, we built,
with some of the computer

00:09:02.660 --> 00:09:06.010
science students, a concept
for how that piece would work--

00:09:06.010 --> 00:09:09.400
which was actually to mine
the internet for data.

00:09:09.400 --> 00:09:12.010
So we took Twitter as
a kind of easy example,

00:09:12.010 --> 00:09:15.060
pull down Twitter data, and
run it through something--

00:09:15.060 --> 00:09:16.820
and we didn't know
what when we started--

00:09:16.820 --> 00:09:20.740
that would select text
based on the director's

00:09:20.740 --> 00:09:25.590
intent for a scene, and
drive that text to actors out

00:09:25.590 --> 00:09:29.350
in the real world, through
Glass, and have them act out

00:09:29.350 --> 00:09:30.200
a scene.

00:09:30.200 --> 00:09:34.610
And so this sort of idea
took the fictional idea

00:09:34.610 --> 00:09:38.150
and merged it with a
concept for a system that

00:09:38.150 --> 00:09:40.450
was helping to tell
a particular story.

00:09:40.450 --> 00:09:42.600
And so Ada and Steve,
they did have--

00:09:42.600 --> 00:09:45.330
the actors-- they
did have a script.

00:09:45.330 --> 00:09:49.020
That script gave them
an arc per scene.

00:09:49.020 --> 00:09:52.200
And then, somewhere else,
we were mining Twitter

00:09:52.200 --> 00:09:55.170
for-- we ended up taking
about a million tweets--

00:09:55.170 --> 00:09:57.490
and training those
tweets according

00:09:57.490 --> 00:09:59.240
to directorial intention.

00:09:59.240 --> 00:10:01.310
So literally, the
class went through

00:10:01.310 --> 00:10:04.370
and had a page of
15 intentions like,

00:10:04.370 --> 00:10:07.810
to persuade, or to
confront, or to calm.

00:10:07.810 --> 00:10:11.340
And we classified
each of those tweets

00:10:11.340 --> 00:10:14.180
and used that as a training
set for a machine learning

00:10:14.180 --> 00:10:17.210
algorithm that selected
tweets in real time

00:10:17.210 --> 00:10:18.530
and send it to the actors.

00:10:18.530 --> 00:10:20.837
I'm not going to sort of,
unpack that, if you're not

00:10:20.837 --> 00:10:22.420
familiar with the
terminology, but I'm

00:10:22.420 --> 00:10:25.510
happy to do it in the-- either
after or in the question

00:10:25.510 --> 00:10:26.490
and answer.

00:10:26.490 --> 00:10:30.730
And then we took that original,
small, technical experiment

00:10:30.730 --> 00:10:34.440
and connected the system
to that chat application

00:10:34.440 --> 00:10:36.990
the drove real time
information to the actors.

00:10:36.990 --> 00:10:39.230
And then we sent them
out into the world

00:10:39.230 --> 00:10:41.670
to enact these scenes.

00:10:41.670 --> 00:10:44.700
And this was with
somebody off camera,

00:10:44.700 --> 00:10:48.930
selecting a directorial intent
for the scene in real time,

00:10:48.930 --> 00:10:51.950
and having that directorial
intent, in turn,

00:10:51.950 --> 00:10:53.992
select a tweet that
went to the actors.

00:10:53.992 --> 00:10:55.450
And the challenge
for them was, how

00:10:55.450 --> 00:10:56.900
do they embody their characters?

00:10:56.900 --> 00:10:59.392
How did they maintain the
structure of the scene

00:10:59.392 --> 00:11:01.100
that they had laid
out with the director,

00:11:01.100 --> 00:11:03.830
and have this very
unusual, dialogue

00:11:03.830 --> 00:11:06.350
come to them in the
moment, to deliver?

00:11:06.350 --> 00:11:08.390
And so this is an example
of a research project

00:11:08.390 --> 00:11:11.850
that relates to avant
garde practice in the arts

00:11:11.850 --> 00:11:15.630
from many years before us.

00:11:15.630 --> 00:11:18.200
And so I'm going to
run the description

00:11:18.200 --> 00:11:21.025
of this piece along with
a little snippet of one

00:11:21.025 --> 00:11:22.150
of the particular episodes.

00:11:29.890 --> 00:11:32.866
[VIDEO PLAYBACK]

00:11:52.110 --> 00:11:56.620
-I want to talk today about
the extraordinary convergence

00:11:56.620 --> 00:11:59.670
of computing and
human potential.

00:11:59.670 --> 00:12:02.280
-And as the richness
of connections grew,

00:12:02.280 --> 00:12:04.440
then we could
reach a stage where

00:12:04.440 --> 00:12:06.500
we had something on
a planetary level.

00:12:06.500 --> 00:12:10.010
-We are going to use it to
extend and expand who we are.

00:12:10.010 --> 00:12:12.050
We are going to merge
with this technology.

00:12:12.050 --> 00:12:15.062
-Real ethics
produced-- generated

00:12:15.062 --> 00:12:18.170
by something which does
not yet fully exist.

00:12:55.362 --> 00:12:57.320
[END VIDEO PLAYBACK]

00:12:57.320 --> 00:12:59.740
JEFF BURKE: So I'll let a
little bit of this episode run.

00:12:59.740 --> 00:13:01.490
And we're going to
screen this tonight.

00:13:01.490 --> 00:13:03.980
And the writer/director
of the piece and some

00:13:03.980 --> 00:13:06.390
of the rest of the
team will be there.

00:13:06.390 --> 00:13:09.570
But this is a fictional
scene in that story

00:13:09.570 --> 00:13:12.420
that you just heard about,
about the first encounter

00:13:12.420 --> 00:13:14.720
in the real world between
these two characters, who

00:13:14.720 --> 00:13:20.550
have elected to embody a very
new, very sort of early life

00:13:20.550 --> 00:13:21.270
form.

00:13:21.270 --> 00:13:23.860
And literally, what
you're seeing in the text,

00:13:23.860 --> 00:13:26.620
is actually the
Twitter-- the tweets

00:13:26.620 --> 00:13:29.390
that are being pushed to
them based on this off camera

00:13:29.390 --> 00:13:29.960
selection.

00:13:29.960 --> 00:13:32.440
And their challenge
is to make this work

00:13:32.440 --> 00:13:35.610
in terms of the scene, in
addition to just making

00:13:35.610 --> 00:13:37.110
the scene work
either systematically

00:13:37.110 --> 00:13:39.080
or because--
technically, in terms

00:13:39.080 --> 00:13:41.040
of working with the
different technologies that

00:13:41.040 --> 00:13:42.150
are involved in the shoot.

00:13:42.150 --> 00:13:45.000
And so the directors
sort of imagined a arc

00:13:45.000 --> 00:13:49.230
of eight episodes that follow
the changing relationship

00:13:49.230 --> 00:13:51.930
of these two characters
as they go in and out

00:13:51.930 --> 00:13:52.770
of this experiment.

00:13:52.770 --> 00:13:54.430
But what was
interesting for us, was

00:13:54.430 --> 00:13:56.580
to build a system that,
in the real world,

00:13:56.580 --> 00:13:58.580
embodied a little bit of this.

00:13:58.580 --> 00:14:01.640
All right, so we can
return to the slides.

00:14:01.640 --> 00:14:03.780
This is a quick picture--
none of these things

00:14:03.780 --> 00:14:06.232
are highly designed
behind the scenes in terms

00:14:06.232 --> 00:14:07.190
of what they look like.

00:14:07.190 --> 00:14:10.230
But this was the control
page that was used off camera

00:14:10.230 --> 00:14:13.170
to select which of
the sentiments--

00:14:13.170 --> 00:14:16.790
the directorial intents-- were
used to select a tweet that

00:14:16.790 --> 00:14:17.870
was driven to the actors.

00:14:17.870 --> 00:14:20.960
And this was really about
a loop between some body

00:14:20.960 --> 00:14:24.060
of information collected
from the internet, the actors

00:14:24.060 --> 00:14:26.740
in the real world, and
the directors and writers,

00:14:26.740 --> 00:14:28.610
making decisions in real time.

00:14:28.610 --> 00:14:31.540
And they have some ideas for
how to actually integrate

00:14:31.540 --> 00:14:34.470
audience interaction, and
this is a really interesting

00:14:34.470 --> 00:14:35.447
project.

00:14:35.447 --> 00:14:37.030
So the second one I
want to talk about

00:14:37.030 --> 00:14:38.850
is a little bit of
a different vein.

00:14:38.850 --> 00:14:42.050
It's closer to what might
be in a kind of mainstream,

00:14:42.050 --> 00:14:43.080
entertainment context.

00:14:43.080 --> 00:14:46.540
And one of the things that
we noticed about several

00:14:46.540 --> 00:14:48.840
of the mid-term projects
that they did in this class--

00:14:48.840 --> 00:14:50.610
that the students did
in this class-- was they

00:14:50.610 --> 00:14:51.818
had a role playing component.

00:14:51.818 --> 00:14:54.070
We were very interested
in the notion

00:14:54.070 --> 00:14:56.680
that Glass could be
used to pull people out

00:14:56.680 --> 00:14:59.730
of their everyday life and have
them participate in a fiction.

00:14:59.730 --> 00:15:01.690
And role playing
was one, sort of,

00:15:01.690 --> 00:15:05.340
easy way to put that-- give
that a name and kind of create

00:15:05.340 --> 00:15:07.140
an experience around it.

00:15:07.140 --> 00:15:10.440
And so over the course
of the second portion

00:15:10.440 --> 00:15:14.430
of the class, and actually
until quite recently, in April,

00:15:14.430 --> 00:15:16.900
we prepared this project
called Grace Plains, which

00:15:16.900 --> 00:15:19.550
is a live role playing
experience on Google Glass.

00:15:19.550 --> 00:15:21.980
We're going to run
that teaser for that,

00:15:21.980 --> 00:15:24.730
that describes what we
did here YouTube Space

00:15:24.730 --> 00:15:28.260
La, with about-- Over a
course of about three days,

00:15:28.260 --> 00:15:32.660
we ran several iterations of
this with the public and folks

00:15:32.660 --> 00:15:34.749
from UCLA.

00:15:34.749 --> 00:15:37.040
And this was the this was
the experience they came out.

00:15:37.040 --> 00:15:40.280
This is, again, that sort of
teaser presentation of what

00:15:40.280 --> 00:15:40.880
was done here.

00:15:43.776 --> 00:15:48.213
[VIDEO PLAYBACK]

00:15:48.213 --> 00:15:49.692
-Hello.

00:15:49.692 --> 00:15:55.115
I am Dr. Kirshner's creation
and you are all my friends.

00:16:01.031 --> 00:16:03.850
-In Grace Plains, you
are thrown head first

00:16:03.850 --> 00:16:05.820
into a science
fiction thriller where

00:16:05.820 --> 00:16:09.650
you must confront the emergence
of an artificial consciousness.

00:16:09.650 --> 00:16:11.650
After discovering the
death of its creator

00:16:11.650 --> 00:16:13.540
and engaging with
this being, you

00:16:13.540 --> 00:16:15.510
must make a critical
decision about the future

00:16:15.510 --> 00:16:17.270
of this new life.

00:16:17.270 --> 00:16:21.070
-Grace Plains is an interactive,
immersive theater experience.

00:16:21.070 --> 00:16:24.280
When you walk into YouTube
Space La, at which point

00:16:24.280 --> 00:16:26.070
got you equip with
Google Glass, we

00:16:26.070 --> 00:16:28.130
would push you your
biography, at which you

00:16:28.130 --> 00:16:30.320
would basic information
about yourself.

00:16:30.320 --> 00:16:32.230
-I'm Viola Stringer,
computer engineer.

00:16:32.230 --> 00:16:34.760
-Miles Smythe,
scientific engineering.

00:16:34.760 --> 00:16:35.865
-Glenn Frederiksson.

00:16:35.865 --> 00:16:37.360
-Isabelle Bell Moser.

00:16:37.360 --> 00:16:38.540
-Documentary filmmaker.

00:16:38.540 --> 00:16:39.810
-Anjelic Sauvage.

00:16:43.450 --> 00:16:46.730
-Google Glasses worn by
the actors and players

00:16:46.730 --> 00:16:48.060
as they move through the story.

00:16:48.060 --> 00:16:49.910
We can see here everything
that's happening.

00:16:49.910 --> 00:16:53.612
We get all of that on a series
of monitors in another room.

00:16:53.612 --> 00:16:56.070
The first actor is introduced
to you, a character, Siobhan,

00:16:56.070 --> 00:16:58.970
and she starts speaking
to you in character

00:16:58.970 --> 00:17:00.620
and asking you
questions that force

00:17:00.620 --> 00:17:02.160
you to flesh out your identity.

00:17:02.160 --> 00:17:04.340
-Have you all met?

00:17:04.340 --> 00:17:07.820
-If we are successful in
helping you become one

00:17:07.820 --> 00:17:09.819
with the experience and
one with your character,

00:17:09.819 --> 00:17:12.349
you won't react
as Joe Smith, who

00:17:12.349 --> 00:17:14.170
came in and is still
playing Joe Smith.

00:17:14.170 --> 00:17:17.230
Ultimately, the idea is, you
don't want to put yourself

00:17:17.230 --> 00:17:20.609
in someone else's shoes, you
want the shoes to be yours.

00:17:20.609 --> 00:17:22.690
There is a narrative
and there's a story

00:17:22.690 --> 00:17:24.480
and there's this
framework, but you're

00:17:24.480 --> 00:17:26.589
allowed to change the story.

00:17:31.450 --> 00:17:33.881
You are allowed to
do whatever you want.

00:17:33.881 --> 00:17:35.130
-Frederiksson, get your phone!

00:17:35.130 --> 00:17:36.760
-What happened?

00:17:36.760 --> 00:17:38.560
-Hello, my friends.

00:17:38.560 --> 00:17:40.850
Welcome to my home.

00:17:40.850 --> 00:17:43.885
-If you want to use it as a
weapon, this is an amazing--

00:17:43.885 --> 00:17:46.220
-Sometimes, people would
walk in and be like,

00:17:46.220 --> 00:17:48.040
I'm not trusting the thing.

00:17:48.040 --> 00:17:50.666
We need to give it
to the military.

00:17:50.666 --> 00:17:53.660
-The bar is here in
order to welcome you.

00:17:53.660 --> 00:17:55.810
Please, have a drink with me.

00:17:55.810 --> 00:17:58.130
-Sometimes people
would be like, OK, we

00:17:58.130 --> 00:17:59.690
can't give it to
the military, but I

00:17:59.690 --> 00:18:01.530
don't know what to
do with this thing.

00:18:01.530 --> 00:18:04.030
We'd have whole teams and
if somebody said something

00:18:04.030 --> 00:18:05.377
they shut him down.

00:18:05.377 --> 00:18:06.960
People would really
be engaged with it

00:18:06.960 --> 00:18:08.606
and run off into the
other room and somebody

00:18:08.606 --> 00:18:11.264
would chase them down and throw
them away from the keyboard.

00:18:11.264 --> 00:18:11.793
-What's going on?

00:18:11.793 --> 00:18:12.584
What are you doing?

00:18:12.584 --> 00:18:14.300
-Glass offers lot
of possibilities.

00:18:14.300 --> 00:18:17.270
Glass isn't just capture.

00:18:17.270 --> 00:18:18.130
Its delivery.

00:18:18.130 --> 00:18:22.190
We have streams of Glass
being cut to YouTube live.

00:18:22.190 --> 00:18:24.100
That's incredible.

00:18:24.100 --> 00:18:27.240
While it was still
informing the participants

00:18:27.240 --> 00:18:30.840
of their characters and their
objectives and what they feel.

00:18:30.840 --> 00:18:34.120
I mean, that type of
two-way communication

00:18:34.120 --> 00:18:36.646
really opens the door for
all sorts of storytelling.

00:18:36.646 --> 00:18:39.145
-I would just love to see in
the future and be able to like,

00:18:39.145 --> 00:18:41.103
take this sort of format,
being able to install

00:18:41.103 --> 00:18:42.930
this in a longer running story.

00:18:42.930 --> 00:18:44.000
The more participants
who come through,

00:18:44.000 --> 00:18:45.375
the more the
environment changes,

00:18:45.375 --> 00:18:47.140
and the overall world changes.

00:18:47.140 --> 00:18:48.598
-There are so many
different things

00:18:48.598 --> 00:18:50.760
you could do
utilizing this form.

00:18:50.760 --> 00:18:53.960
So it's pretty exciting to me,
to see where it'll go next.

00:19:06.110 --> 00:19:09.026
[END VIDEO PLAYBACK]

00:19:09.026 --> 00:19:11.630
JEFF BURKE: OK, so I'm going to
unpack a little bit about what

00:19:11.630 --> 00:19:14.530
we did and what we learned
in terms of both storytelling

00:19:14.530 --> 00:19:15.640
and technology.

00:19:15.640 --> 00:19:17.820
And so just to
recap a little bit,

00:19:17.820 --> 00:19:21.530
the concept was to start
in this environment.

00:19:21.530 --> 00:19:24.710
The students came and looked
at the space and figured out

00:19:24.710 --> 00:19:26.260
what rooms they
could dress and how

00:19:26.260 --> 00:19:29.490
they could use the
progression of the visitors

00:19:29.490 --> 00:19:31.400
through the space
to kind of reinforce

00:19:31.400 --> 00:19:34.120
this notion of
encountering a laboratory;

00:19:34.120 --> 00:19:37.610
encountering an
artificial consciousness.

00:19:37.610 --> 00:19:40.200
You'll notice a theme
with the other piece,

00:19:40.200 --> 00:19:42.550
a sort of common
idea that showed up

00:19:42.550 --> 00:19:45.080
in both of these
pieces about something

00:19:45.080 --> 00:19:48.360
emerging through our new
technical capabilities.

00:19:48.360 --> 00:19:51.400
But this was something-- a
case where this experience

00:19:51.400 --> 00:19:55.670
was really driven by writers
or writer/directors who

00:19:55.670 --> 00:20:00.410
were back in another room here
YouTube Space La, watching

00:20:00.410 --> 00:20:03.080
the POV camera for each
of the participants,

00:20:03.080 --> 00:20:07.030
and driving both pre-scripted
and improvised dialogue,

00:20:07.030 --> 00:20:08.410
individually to each of them.

00:20:08.410 --> 00:20:10.980
Or actions or
information that was

00:20:10.980 --> 00:20:13.100
related to the progression
of the experience.

00:20:13.100 --> 00:20:15.730
And so we weren't trying
to automate this the way

00:20:15.730 --> 00:20:17.340
the first project did.

00:20:17.340 --> 00:20:19.720
This was really putting kind
of, the writer, in a way,

00:20:19.720 --> 00:20:22.750
in the hot seat, of trying
to answer questions--

00:20:22.750 --> 00:20:24.630
similar to the way
somebody running

00:20:24.630 --> 00:20:26.890
a role playing game might do.

00:20:26.890 --> 00:20:29.240
And there were two
actors that were out

00:20:29.240 --> 00:20:32.170
in the physical space,
that were the proxies

00:20:32.170 --> 00:20:34.380
to drive the story
forward physically,

00:20:34.380 --> 00:20:36.150
if we needed to do that.

00:20:36.150 --> 00:20:39.090
The artificial
consciousness was not a bot.

00:20:39.090 --> 00:20:42.800
It was a guy in the room-- in
the back-- one of the authors.

00:20:42.800 --> 00:20:44.600
And a lot of the
moments that were

00:20:44.600 --> 00:20:47.190
sort of exciting, and
human, and interesting,

00:20:47.190 --> 00:20:50.280
came through the interaction
with this artificial

00:20:50.280 --> 00:20:53.930
consciousness, informed by
the particular perspectives

00:20:53.930 --> 00:20:57.430
that each player
or character had

00:20:57.430 --> 00:20:58.620
coming into them from Glass.

00:20:58.620 --> 00:21:00.410
So there was really
a nice bridge

00:21:00.410 --> 00:21:03.280
between human improvisation
and the technology

00:21:03.280 --> 00:21:06.390
that was bringing story
details to each of the players.

00:21:06.390 --> 00:21:09.730
And over the course of the
sort of 45 minute experience,

00:21:09.730 --> 00:21:11.552
they had a chance
to make a choice

00:21:11.552 --> 00:21:13.510
about the fate of this
artificial consciousness

00:21:13.510 --> 00:21:17.060
and debate it and act on it
in different spaces here.

00:21:17.060 --> 00:21:21.217
And this whole process was
managed in two different ways.

00:21:21.217 --> 00:21:22.800
One, in terms of the
writing in story.

00:21:22.800 --> 00:21:24.660
So the image that
you're seeing here

00:21:24.660 --> 00:21:27.210
is one of the control
rooms that was configured

00:21:27.210 --> 00:21:32.470
to show what text was being sent
to each player and each actor,

00:21:32.470 --> 00:21:35.730
what they were seeing, and then
a set of other cameras that

00:21:35.730 --> 00:21:38.750
were available to provide
alternate perspectives

00:21:38.750 --> 00:21:42.520
on the experience, when we were
streaming out live to YouTube.

00:21:42.520 --> 00:21:46.070
And the script was
actually a bank

00:21:46.070 --> 00:21:48.010
of lines in a
Google spreadsheet,

00:21:48.010 --> 00:21:51.180
that was authored
by the students.

00:21:51.180 --> 00:21:53.720
And this was pulled
into a web interface

00:21:53.720 --> 00:21:55.520
where they would
select dynamically--

00:21:55.520 --> 00:21:57.450
they being the writers
or administrators

00:21:57.450 --> 00:22:00.230
of the experience--
would select dynamically,

00:22:00.230 --> 00:22:02.440
what they wanted to push
out to each character.

00:22:02.440 --> 00:22:05.660
So there were three people
managing the eight participants

00:22:05.660 --> 00:22:07.380
and actors that were there.

00:22:07.380 --> 00:22:09.730
And this was a really
interesting time for us

00:22:09.730 --> 00:22:12.410
to think about the relationship
between the structure

00:22:12.410 --> 00:22:14.840
of the story that
we wanted to have;

00:22:14.840 --> 00:22:17.290
what some of the
pre-existing elements were;

00:22:17.290 --> 00:22:19.850
what could be improvised
and what couldn't be;

00:22:19.850 --> 00:22:23.390
and then where was their agency
in the people experiencing

00:22:23.390 --> 00:22:24.440
the story.

00:22:24.440 --> 00:22:26.570
So this mixture of
sort of back and forth

00:22:26.570 --> 00:22:29.200
between agency and
story structure

00:22:29.200 --> 00:22:32.860
was-- we were able to explore
it in a really unique way

00:22:32.860 --> 00:22:36.190
because of how we could reach
out to each individual--

00:22:36.190 --> 00:22:39.450
each person that was wearing
a device that-- through which

00:22:39.450 --> 00:22:41.260
we could communicate
with them and we

00:22:41.260 --> 00:22:42.700
could see what they were seeing.

00:22:42.700 --> 00:22:46.000
And at the same time, in
another one of the control rooms

00:22:46.000 --> 00:22:49.910
here, we were configured to
pull each of those POV video

00:22:49.910 --> 00:22:54.390
streams and live cut
them out to YouTube.

00:22:54.390 --> 00:22:57.140
And so that was done
by a team of students

00:22:57.140 --> 00:23:00.060
who are cutting the experience
based on infrastructure that

00:23:00.060 --> 00:23:03.110
was put together here by the
engineering team of the space.

00:23:03.110 --> 00:23:07.670
And so they helped us to
get both of the POV footage

00:23:07.670 --> 00:23:10.410
back into the control
room and the text that

00:23:10.410 --> 00:23:12.090
was being sent out, available.

00:23:12.090 --> 00:23:15.090
Because these folks had to
essentially improvise too,

00:23:15.090 --> 00:23:17.240
as they were live-cutting
the experience.

00:23:17.240 --> 00:23:19.830
And so some of the other
people that you see in the room

00:23:19.830 --> 00:23:22.550
are wrangling the technology
behind the scenes,

00:23:22.550 --> 00:23:26.680
in terms of which Glass device
is used for which character;

00:23:26.680 --> 00:23:28.390
and keeping track
of the progression

00:23:28.390 --> 00:23:30.920
of the story from
this perspective.

00:23:30.920 --> 00:23:33.290
And the way that-- the
particular software

00:23:33.290 --> 00:23:38.680
that was used was a sort custom
Glassware app that used webRTC.

00:23:38.680 --> 00:23:42.490
So this is one of the underlying
technologies for Hangouts.

00:23:42.490 --> 00:23:45.240
This is the video and audio
conferencing technology

00:23:45.240 --> 00:23:47.400
that underlies that and
a few other conferencing

00:23:47.400 --> 00:23:48.350
technologies.

00:23:48.350 --> 00:23:52.470
And so we took some of
those open source tools,

00:23:52.470 --> 00:23:55.590
ported them over to
Glass, optimized them

00:23:55.590 --> 00:23:57.940
for this experience,
and then uses that

00:23:57.940 --> 00:24:00.230
as the basis of
the POV streaming.

00:24:00.230 --> 00:24:02.390
So the Glass connected
to the network,

00:24:02.390 --> 00:24:07.730
streamed the POV back live, and
then we had that application--

00:24:07.730 --> 00:24:10.250
that chat application I'd
introduced earlier-- a version

00:24:10.250 --> 00:24:15.790
of that, being used to push text
and the occasional image out

00:24:15.790 --> 00:24:16.660
to the participants.

00:24:16.660 --> 00:24:18.770
And so this they were
running this custom app

00:24:18.770 --> 00:24:21.230
over the course of the
45 minute experience.

00:24:21.230 --> 00:24:24.370
And for us, this was a chance--
all the pictures you're

00:24:24.370 --> 00:24:28.244
seeing here are public that came
in and experienced the piece.

00:24:28.244 --> 00:24:29.910
And part of what was
interesting for us,

00:24:29.910 --> 00:24:31.820
was to actually debrief
with them at the end

00:24:31.820 --> 00:24:34.260
and talk to them about
the type of experience

00:24:34.260 --> 00:24:36.730
they had-- where they felt
empowered, where they felt

00:24:36.730 --> 00:24:40.330
steered, what they enjoyed,
where things lagged.

00:24:40.330 --> 00:24:42.550
And a lot of the sort of
learning about the structure

00:24:42.550 --> 00:24:45.430
and content came through
those conversations

00:24:45.430 --> 00:24:47.990
that happened at the
end in the bar that's

00:24:47.990 --> 00:24:51.060
a set over here at
YouTube Space LA.

00:24:51.060 --> 00:24:54.906
And then we did a few
sort of, additional things

00:24:54.906 --> 00:24:56.530
to try to draw the
experience together.

00:24:56.530 --> 00:24:58.363
We took advantage of
the large displays that

00:24:58.363 --> 00:25:03.270
are here at YouTube and pushed
the content out to YouTube

00:25:03.270 --> 00:25:05.250
and made it available
to folks to look at.

00:25:05.250 --> 00:25:07.120
And I would say that
the thing that we

00:25:07.120 --> 00:25:09.950
would try to do in another
iteration of this project,

00:25:09.950 --> 00:25:12.480
is to confront the
difficulty in making

00:25:12.480 --> 00:25:15.460
a live, compelling,
point of view experience,

00:25:15.460 --> 00:25:18.620
and this live experience
that's pushed out to YouTube.

00:25:18.620 --> 00:25:21.600
And so it's not unlike
the challenge of reality

00:25:21.600 --> 00:25:25.310
television, but this is really
a different format and sort

00:25:25.310 --> 00:25:27.870
of a different way of
bridging what people

00:25:27.870 --> 00:25:29.870
do in the real
world, out to what

00:25:29.870 --> 00:25:31.290
people are watching online.

00:25:31.290 --> 00:25:35.160
And so just a kind of a couple
of quick bits on the technology

00:25:35.160 --> 00:25:37.160
and then I'll switch
over and open it up

00:25:37.160 --> 00:25:39.470
to questions on both projects.

00:25:39.470 --> 00:25:42.750
I'm not sure the you'll be able
to follow the lines and text

00:25:42.750 --> 00:25:44.890
here, but I wanted
to just point out

00:25:44.890 --> 00:25:47.990
three different pieces--
or three different systems

00:25:47.990 --> 00:25:51.480
of technology they were
engineered in collaboration

00:25:51.480 --> 00:25:53.900
with folks in the
YouTube and Glass team.

00:25:53.900 --> 00:25:57.220
So the first was actually,
where did all that video go?

00:25:57.220 --> 00:25:59.230
Right, so we had POV video.

00:25:59.230 --> 00:26:03.000
We were capturing what was being
sent out-- the text prompts

00:26:03.000 --> 00:26:04.790
that were being sent
out to everybody.

00:26:04.790 --> 00:26:07.050
How did it get to all
the different rooms?

00:26:07.050 --> 00:26:10.320
That was essentially what
the engineering team did here

00:26:10.320 --> 00:26:11.410
for us.

00:26:11.410 --> 00:26:16.040
We generated the software that
grabbed the POV video that

00:26:16.040 --> 00:26:19.040
handled the text, we created
the administrative interface,

00:26:19.040 --> 00:26:21.940
and then they integrated it
with the broadcast production

00:26:21.940 --> 00:26:25.770
facilities here at YouTube--
which involved lots of things

00:26:25.770 --> 00:26:28.420
that we can talk about in
the Q and A if you'd like.

00:26:28.420 --> 00:26:30.100
And then, on each of
the Glass devices,

00:26:30.100 --> 00:26:32.620
we ran that Glassware
that I mentioned earlier.

00:26:32.620 --> 00:26:34.984
And it's a little
simpler just to talk

00:26:34.984 --> 00:26:36.650
about them look at
the picture, but this

00:26:36.650 --> 00:26:39.710
is essentially to bridge
an administrator, who

00:26:39.710 --> 00:26:43.190
sat in that room, who
had a script with Glass.

00:26:43.190 --> 00:26:45.920
And so we were using a
combination of web services

00:26:45.920 --> 00:26:48.420
that are pre-existing
for glass and some things

00:26:48.420 --> 00:26:54.511
that we built, to essentially
just push HTML out in real time

00:26:54.511 --> 00:26:55.010
to Glass.

00:26:55.010 --> 00:26:56.180
Pretty simple, right?

00:26:56.180 --> 00:26:59.070
Grab some text from the
script, hit a button,

00:26:59.070 --> 00:27:02.210
render it in HTML, push it
out to a machine in YouTube,

00:27:02.210 --> 00:27:05.390
have that machine display
it on the monitors here.

00:27:05.390 --> 00:27:08.670
And at the same time, have
an application on Glass

00:27:08.670 --> 00:27:10.390
that was listening
for those pushes,

00:27:10.390 --> 00:27:13.670
or listening to receive
that little chunk of HTML,

00:27:13.670 --> 00:27:14.640
and then render it.

00:27:14.640 --> 00:27:16.015
And then in the
background, there

00:27:16.015 --> 00:27:19.330
was the web RTC video streaming
that I mentioned earlier.

00:27:19.330 --> 00:27:22.110
And so then the rest
of the interface

00:27:22.110 --> 00:27:25.980
for the administrators pulled
those individual pieces of text

00:27:25.980 --> 00:27:29.160
from that Google spreadsheet
that I mentioned earlier, which

00:27:29.160 --> 00:27:32.210
was a way for us to
have, especially,

00:27:32.210 --> 00:27:34.600
pre-written dialogue
for each character,

00:27:34.600 --> 00:27:36.670
for a number of different
scenes and situations

00:27:36.670 --> 00:27:38.380
that were very easy to select.

00:27:38.380 --> 00:27:40.980
And so the authoring process
and the experimentation

00:27:40.980 --> 00:27:43.850
and rehearsal process
really involved three parts.

00:27:43.850 --> 00:27:46.100
It was about, what do we write?

00:27:46.100 --> 00:27:48.880
What do we put into this
bank of story material

00:27:48.880 --> 00:27:49.740
that we want to use?

00:27:49.740 --> 00:27:52.100
How do we organize it in
a way that the writers

00:27:52.100 --> 00:27:56.030
and the administrators could
pull it quickly and use it?

00:27:56.030 --> 00:28:00.850
How do we then, create
a sort of structure

00:28:00.850 --> 00:28:03.280
to understand when to use it?

00:28:03.280 --> 00:28:04.864
And that was purely
conceptual, right?

00:28:04.864 --> 00:28:06.946
So that was an agreement
among the administrators.

00:28:06.946 --> 00:28:08.030
When do we use this text?

00:28:08.030 --> 00:28:09.000
When do we do that?

00:28:09.000 --> 00:28:10.420
Where is today's piece going?

00:28:10.420 --> 00:28:13.000
And so that's the conversation
that was happening in the room

00:28:13.000 --> 00:28:13.500
here.

00:28:13.500 --> 00:28:15.500
And then finally, the
sort of third component,

00:28:15.500 --> 00:28:17.979
was the live cut of
the video streams that

00:28:17.979 --> 00:28:19.520
are coming from all
the places, which

00:28:19.520 --> 00:28:23.590
was another creative decision
made by a separate team.

00:28:23.590 --> 00:28:26.850
So this involved collaboration
across Glass and YouTube Space

00:28:26.850 --> 00:28:31.440
La, support from a number
of different units at UCLA

00:28:31.440 --> 00:28:33.850
and here and we really
appreciate the chance

00:28:33.850 --> 00:28:37.940
to try to do an experimental
project of that scale.

00:28:37.940 --> 00:28:41.300
So I want to wrap up with
just a little bit of what

00:28:41.300 --> 00:28:43.950
we could think about
together, in terms

00:28:43.950 --> 00:28:46.450
of the intersection of
storytelling in technology.

00:28:46.450 --> 00:28:48.470
And so one of the
common questions--

00:28:48.470 --> 00:28:51.370
been working-- trained as
an engineer, work with lots

00:28:51.370 --> 00:28:53.110
of computer science
faculty and students,

00:28:53.110 --> 00:28:55.220
and engineering
faculty and students

00:28:55.220 --> 00:28:56.930
and one of the
questions that we get

00:28:56.930 --> 00:28:59.110
a lot is, what's your problem?

00:28:59.110 --> 00:29:00.440
What do you want us to solve?

00:29:00.440 --> 00:29:01.860
What can we do better?

00:29:01.860 --> 00:29:04.655
And in storytelling,
as many of you know,

00:29:04.655 --> 00:29:06.530
it's not really about
what you can do better.

00:29:06.530 --> 00:29:09.340
There are plenty of things
that we can optimize;

00:29:09.340 --> 00:29:11.950
we can share differently;
we can certainly

00:29:11.950 --> 00:29:14.920
go down that road of
what technology can do.

00:29:14.920 --> 00:29:16.650
But the whole goal
of storytelling

00:29:16.650 --> 00:29:19.190
is sort of to pose and
resolve these challenges

00:29:19.190 --> 00:29:20.930
within a different
context, right?

00:29:20.930 --> 00:29:23.650
To ask questions at the
beginning of the story,

00:29:23.650 --> 00:29:26.110
and if it's a narrative
story, to resolve them

00:29:26.110 --> 00:29:28.140
in a certain way over
the course of the story.

00:29:28.140 --> 00:29:29.780
And so our objective
is not really

00:29:29.780 --> 00:29:31.840
to make better stories,
but different ones.

00:29:31.840 --> 00:29:34.660
And ones that resonate
with us today.

00:29:34.660 --> 00:29:36.810
And so what was interesting
about this opportunity

00:29:36.810 --> 00:29:40.310
with Glass was to think about
the themes that resonate

00:29:40.310 --> 00:29:42.060
with us today,
with the students,

00:29:42.060 --> 00:29:44.300
and how some of those
things can be realized

00:29:44.300 --> 00:29:46.960
in unique stories for
particular a platform.

00:29:46.960 --> 00:29:48.960
And so this notion of,
what are the stories

00:29:48.960 --> 00:29:51.370
that we can uniquely
tell with this thing?

00:29:51.370 --> 00:29:54.282
Has been really,
really important to us

00:29:54.282 --> 00:29:55.490
over the course of the class.

00:29:55.490 --> 00:29:58.720
But there's another one, which
is this research question of,

00:29:58.720 --> 00:30:01.570
what are the types of
stories or story systems?

00:30:01.570 --> 00:30:03.750
What are the new
systems that involve

00:30:03.750 --> 00:30:09.440
not only a sort of pre-written,
pre-existing text or images,

00:30:09.440 --> 00:30:12.300
but also a system that embodies
something about the story.

00:30:12.300 --> 00:30:14.500
So in the Global
Brain project we

00:30:14.500 --> 00:30:17.360
tried to embody a concept
that the students wrote--

00:30:17.360 --> 00:30:20.060
a fictional concept--
in a real system.

00:30:20.060 --> 00:30:22.739
And in Grace Plains, they tried
to do the same thing, right?

00:30:22.739 --> 00:30:24.280
There was an artificial
consciousness

00:30:24.280 --> 00:30:25.730
that they tried to embody.

00:30:25.730 --> 00:30:27.600
There was a particular
way of steering

00:30:27.600 --> 00:30:30.430
the actions of the
participants that they achieved

00:30:30.430 --> 00:30:32.130
through human
interaction, in that case.

00:30:32.130 --> 00:30:36.250
But it was a system rather
than one specific story.

00:30:36.250 --> 00:30:38.200
And so this question
is, I think,

00:30:38.200 --> 00:30:40.830
a really intriguing and
fruitful area for us,

00:30:40.830 --> 00:30:43.840
especially when we consider
the nature of technology

00:30:43.840 --> 00:30:45.070
that we encounter today.

00:30:45.070 --> 00:30:49.200
So three sort of quick
thoughts on fanatically,

00:30:49.200 --> 00:30:51.660
where we might go next,
and some of the sort of,

00:30:51.660 --> 00:30:52.770
questions that come up.

00:30:52.770 --> 00:30:56.290
So first, what's intriguing for
us in this and other projects

00:30:56.290 --> 00:31:00.030
are the scale and
connectivity and consequence

00:31:00.030 --> 00:31:01.700
of working with network media.

00:31:01.700 --> 00:31:05.590
And most of you know a lot
about the scale and connectivity

00:31:05.590 --> 00:31:08.290
and consequences and
connectivity into the world.

00:31:08.290 --> 00:31:10.140
So I'm not going to
do more than just

00:31:10.140 --> 00:31:12.900
suggest this theme is
someplace where we might look.

00:31:12.900 --> 00:31:15.740
Another is the evolving
notion of memory.

00:31:15.740 --> 00:31:20.170
And in the Grace Plains
example, a really specific thing

00:31:20.170 --> 00:31:23.710
that comes up is, Grace
Plains was a different story

00:31:23.710 --> 00:31:26.610
each time, but it
didn't remember

00:31:26.610 --> 00:31:28.800
the run of the story
that had come before.

00:31:28.800 --> 00:31:32.860
And so in talking with
another director who's

00:31:32.860 --> 00:31:35.449
interested in sort of a evolving
a new version of that piece,

00:31:35.449 --> 00:31:37.740
one of the things that's
interesting is, for that piece

00:31:37.740 --> 00:31:38.740
to remember.

00:31:38.740 --> 00:31:40.750
And that piece to take
into account things

00:31:40.750 --> 00:31:42.380
have happened
before in the story.

00:31:42.380 --> 00:31:44.600
And this is really
sort of parallel some

00:31:44.600 --> 00:31:46.260
of the technological
capabilities

00:31:46.260 --> 00:31:48.780
that we find ourselves
in possession of,

00:31:48.780 --> 00:31:51.150
through the tools that
are available today.

00:31:51.150 --> 00:31:54.820
And then finally for us, this
intersection of ancient forms

00:31:54.820 --> 00:31:57.100
joked about puppetry but
it's not really joke, right?

00:31:57.100 --> 00:31:59.200
The sort of aesthetic
freedom, in this case,

00:31:59.200 --> 00:32:01.460
that comes with
puppetry and the scale.

00:32:01.460 --> 00:32:05.190
And the very, very modern
tools that are available to us.

00:32:05.190 --> 00:32:07.430
And so these are
three themes that I

00:32:07.430 --> 00:32:10.620
think we could all sort
of explore together

00:32:10.620 --> 00:32:14.310
in the context of these
storytelling and technology

00:32:14.310 --> 00:32:15.364
explorations.

00:32:15.364 --> 00:32:16.780
And ask the question
of what do we

00:32:16.780 --> 00:32:19.740
do if we're technologists in
particular, about building

00:32:19.740 --> 00:32:22.760
architectures that enable
people to tell stories

00:32:22.760 --> 00:32:25.430
but also to make these
sort of story systems

00:32:25.430 --> 00:32:28.670
that embody relationships
in a different way.

00:32:28.670 --> 00:32:31.340
And so with that, I
wanted to turn it over

00:32:31.340 --> 00:32:33.750
to questions on any
of the sort of aspects

00:32:33.750 --> 00:32:36.330
of this from the technology,
to the particular projects,

00:32:36.330 --> 00:32:38.740
to the process.

00:32:38.740 --> 00:32:40.974
And thank you very much.

00:32:40.974 --> 00:32:45.402
[APPLAUSE]

00:32:45.402 --> 00:32:46.860
ELIZABETH HARTNETT: Thanks Jeff.

00:32:46.860 --> 00:32:48.780
Any questions from
the live audience,

00:32:48.780 --> 00:32:51.130
feel free to come up here.

00:32:51.130 --> 00:32:54.560
I do have some questions from
the Dory that were submitted.

00:32:54.560 --> 00:32:56.360
So there's a nice
little meaty one.

00:32:56.360 --> 00:33:01.170
Let's see, do you think engaged,
augmented, reality storytelling

00:33:01.170 --> 00:33:03.420
like this, will replace
traditional entertainment

00:33:03.420 --> 00:33:05.300
consumption in the future?

00:33:05.300 --> 00:33:08.000
Will we lose these sit-back,
theatrical experience

00:33:08.000 --> 00:33:10.435
to point of view?

00:33:10.435 --> 00:33:12.170
JEFF BURKE: This
question I think

00:33:12.170 --> 00:33:15.980
is a common one that
we've talked about

00:33:15.980 --> 00:33:18.580
at the School of Theater,
Film, and TV quite a bit,

00:33:18.580 --> 00:33:20.450
in class and in
different contexts.

00:33:20.450 --> 00:33:22.000
And it seems like not.

00:33:22.000 --> 00:33:22.500
Right?

00:33:22.500 --> 00:33:25.660
The enjoyment of being
a spectator-- which

00:33:25.660 --> 00:33:30.370
isn't necessarily removed
from the work, right?

00:33:30.370 --> 00:33:31.850
It's just a different
relationship.

00:33:31.850 --> 00:33:33.680
Everybody's a
spectator at one point

00:33:33.680 --> 00:33:35.904
and a storyteller
at another point.

00:33:35.904 --> 00:33:37.570
And there's a certain
enjoyment in being

00:33:37.570 --> 00:33:40.200
able to let something
unfold in front of you.

00:33:40.200 --> 00:33:42.110
So no, I don't think
traditional storytelling

00:33:42.110 --> 00:33:46.462
is going to go away in that
sense of the audience story

00:33:46.462 --> 00:33:47.920
or audience performer
relationship.

00:33:47.920 --> 00:33:52.190
I do think that we're going
to see more and more options

00:33:52.190 --> 00:33:56.170
for stories that are not
all the way, sort of,

00:33:56.170 --> 00:33:59.200
engaged, in the way that
say, Grace Plains was,

00:33:59.200 --> 00:34:02.210
and not all the way this sort
of active, augmented reality.

00:34:02.210 --> 00:34:07.000
But have bits of tuning of
the story, or connection

00:34:07.000 --> 00:34:09.440
of people's everyday
experience into the stories

00:34:09.440 --> 00:34:11.830
that they're encountering,
and that we'll see.

00:34:11.830 --> 00:34:13.080
It's not really either or.

00:34:13.080 --> 00:34:15.790
It's sort of the continuum
between the thing that's

00:34:15.790 --> 00:34:17.570
completely separate
from your life,

00:34:17.570 --> 00:34:18.820
and the thing that
you're in the middle of.

00:34:18.820 --> 00:34:20.736
And there's all these
different possibilities.

00:34:20.736 --> 00:34:25.165
But no, I don't think either one
is going to replace the other.

00:34:25.165 --> 00:34:28.060
ELIZABETH HARTNETT: And if you
have any questions, come on up.

00:34:28.060 --> 00:34:29.670
But there's-- I have a question
from the Dory that's kind

00:34:29.670 --> 00:34:30.770
of related to that.

00:34:30.770 --> 00:34:34.860
And so what are some potential
real world applications

00:34:34.860 --> 00:34:36.760
for using Glass in storytelling?

00:34:36.760 --> 00:34:39.530
This person mentioned
theme parks, for instance.

00:34:39.530 --> 00:34:41.084
How do you see it
being used there?

00:34:41.084 --> 00:34:41.875
JEFF BURKE: Really?

00:34:41.875 --> 00:34:43.719
This wasn't real world?

00:34:43.719 --> 00:34:46.620
So, I think the
theme parks are one.

00:34:46.620 --> 00:34:52.070
I think then the notion of
overlaying a fictional world

00:34:52.070 --> 00:34:55.589
on top of physical-- sort
of existing physical space

00:34:55.589 --> 00:34:56.880
is actually really interesting.

00:34:56.880 --> 00:34:59.620
So if you imagine
the home encounter

00:34:59.620 --> 00:35:01.444
with a game environment,
the way that we

00:35:01.444 --> 00:35:04.110
think about gaming right now is,
I sit down in front of a screen

00:35:04.110 --> 00:35:06.550
or I have a screen
with me and the game

00:35:06.550 --> 00:35:08.440
as all the way in there.

00:35:08.440 --> 00:35:11.700
We're seeing technologies
emerge that allow mobile devices

00:35:11.700 --> 00:35:14.694
and console games and
computers to understand the 3D

00:35:14.694 --> 00:35:16.860
environment that they're
in-- the physical structure

00:35:16.860 --> 00:35:17.640
of the room.

00:35:17.640 --> 00:35:19.510
And at some point,
we're going to be

00:35:19.510 --> 00:35:22.980
able to control the surfaces
and images that are in that room

00:35:22.980 --> 00:35:26.770
and start to see fictional
elements from that story

00:35:26.770 --> 00:35:28.770
emerge out into the home.

00:35:28.770 --> 00:35:29.270
Right?

00:35:29.270 --> 00:35:32.540
Into a sort of consumer
experience of entertainment.

00:35:32.540 --> 00:35:36.500
That takes 3D understanding
of the physical environment

00:35:36.500 --> 00:35:40.310
in the home, it takes some way
to adapt the design of the game

00:35:40.310 --> 00:35:43.400
environment and the
story to particular

00:35:43.400 --> 00:35:45.000
a particular real
world environment.

00:35:45.000 --> 00:35:48.916
And it takes some motivation
to do that in the story.

00:35:48.916 --> 00:35:50.540
But I think there's
this sort of bridge

00:35:50.540 --> 00:35:52.680
between the physical--
sorry, the fictional

00:35:52.680 --> 00:35:55.820
and the real world, that
has a lot of richness

00:35:55.820 --> 00:36:01.160
in the home, in the car,
in collective encounters,

00:36:01.160 --> 00:36:03.450
that traditionally we had
been doing only screen based

00:36:03.450 --> 00:36:04.250
experiences in.

00:36:04.250 --> 00:36:06.860
So I do think there
are architectural scale

00:36:06.860 --> 00:36:09.010
possibilities in theme
parks and new buildings

00:36:09.010 --> 00:36:12.400
and certainly
enhancements to theaters

00:36:12.400 --> 00:36:14.240
and other traditional
ways of encountering

00:36:14.240 --> 00:36:16.290
both film and live performance.

00:36:16.290 --> 00:36:20.220
But this sort of, bridge between
fictional and real world,

00:36:20.220 --> 00:36:22.690
in the context of just
the home or the backyard

00:36:22.690 --> 00:36:24.280
or the car-- those
are things where

00:36:24.280 --> 00:36:26.780
I think we're going to start
to see the technologies that we

00:36:26.780 --> 00:36:28.820
need to experiment
with that come out.

00:36:28.820 --> 00:36:33.230
And then that opens up a whole
host of the realistic, consumer

00:36:33.230 --> 00:36:37.080
entertainment and art
experiences that, sort of,

00:36:37.080 --> 00:36:39.760
maybe start in the
screen and fill out

00:36:39.760 --> 00:36:41.350
into the room in
really simple ways--

00:36:41.350 --> 00:36:46.900
through color, image, or
sound, or whatever it might be.

00:36:46.900 --> 00:36:49.400
AUDIENCE: The mic stand's
a little high for me.

00:36:49.400 --> 00:36:53.480
I'm curious about the history
of the design of the system

00:36:53.480 --> 00:36:55.520
that you guys did
with the experience

00:36:55.520 --> 00:36:57.550
here at YouTube Space La.

00:36:57.550 --> 00:37:00.240
How long did it take you guys
and what kind of expertise

00:37:00.240 --> 00:37:03.820
did you guys pull on board to
design such a complex system?

00:37:03.820 --> 00:37:05.050
JEFF BURKE: Good question.

00:37:05.050 --> 00:37:11.660
So we started working
with Glass in the summer--

00:37:11.660 --> 00:37:16.150
so around July-- and then
did the production in April.

00:37:16.150 --> 00:37:17.730
So our understanding
of Glass kind of

00:37:17.730 --> 00:37:19.020
evolved over that time period.

00:37:22.080 --> 00:37:24.417
The specific system
drew from pieces

00:37:24.417 --> 00:37:26.500
that we had built already
and each of those pieces

00:37:26.500 --> 00:37:27.600
was relatively simple.

00:37:27.600 --> 00:37:30.454
So you have an
idea, make something

00:37:30.454 --> 00:37:32.620
over the course of a few
weeks, and then try it out.

00:37:32.620 --> 00:37:34.890
We were trying to
do complex systems.

00:37:34.890 --> 00:37:37.250
So what we did
leverage was, many,

00:37:37.250 --> 00:37:41.030
many years of sort of doing
production level work that

00:37:41.030 --> 00:37:43.940
incorporates new
technology-- which isn't-- So

00:37:43.940 --> 00:37:47.690
that's experience that has
come over a decade of work

00:37:47.690 --> 00:37:49.760
at our lab and at our school.

00:37:49.760 --> 00:37:53.460
We took advantage of the YouTube
sort of engineering experience

00:37:53.460 --> 00:37:55.390
here for the broadcast system.

00:37:55.390 --> 00:37:58.160
So we put this together over
the course of a couple weeks

00:37:58.160 --> 00:38:00.230
with them, in terms
of the systems here.

00:38:00.230 --> 00:38:01.760
And the reason that
could happen is

00:38:01.760 --> 00:38:04.430
because they know
things well here.

00:38:04.430 --> 00:38:06.620
And then in the case
of the Glassware,

00:38:06.620 --> 00:38:08.240
for this specific
thing, we had sort

00:38:08.240 --> 00:38:10.840
of a minor crisis where
we had to implement

00:38:10.840 --> 00:38:12.590
the video streaming
part very quickly.

00:38:12.590 --> 00:38:14.620
And so we grab somebody
that had been working

00:38:14.620 --> 00:38:18.860
on Web RTC-- working on
video streaming for a year

00:38:18.860 --> 00:38:19.654
leading up to it.

00:38:19.654 --> 00:38:21.820
And he could kind of leap
in and do it very quickly.

00:38:21.820 --> 00:38:25.340
So it really was drawing on
a lot of technical expertise

00:38:25.340 --> 00:38:27.250
and experience in
these kind of projects,

00:38:27.250 --> 00:38:28.499
to be able to put it together.

00:38:28.499 --> 00:38:31.900
So I would say the
specific system here,

00:38:31.900 --> 00:38:35.360
we were trying to make
relatively straightforward

00:38:35.360 --> 00:38:36.600
in terms of the technology.

00:38:36.600 --> 00:38:38.955
But to be able to
actually execute

00:38:38.955 --> 00:38:41.330
was built on a lot of experience
both from the folks here

00:38:41.330 --> 00:38:44.566
and from the team that was
supporting the students.

00:38:44.566 --> 00:38:45.710
AUDIENCE: Thank you.

00:38:45.710 --> 00:38:46.834
JEFF BURKE: Sure.

00:38:46.834 --> 00:38:49.250
ELIZABETH HARTNETT: Any other
questions from the audience,

00:38:49.250 --> 00:38:51.050
feel free to come up.

00:38:51.050 --> 00:38:52.930
I have another Dory question.

00:38:52.930 --> 00:38:55.550
So-- some really
good ones on here.

00:38:55.550 --> 00:38:57.900
How has the role of
screenwriter and director

00:38:57.900 --> 00:38:59.599
changed in this new world?

00:38:59.599 --> 00:39:01.140
As you were designing
it, how did you

00:39:01.140 --> 00:39:02.980
determine what the
balance of agency

00:39:02.980 --> 00:39:06.855
would be between the multiple
writers, directors, and actors?

00:39:06.855 --> 00:39:11.710
JEFF BURKE: OK, so the--
those are two separate,

00:39:11.710 --> 00:39:13.210
and kind of
interesting questions.

00:39:13.210 --> 00:39:17.060
So the roles evolve
organically that- in a way,

00:39:17.060 --> 00:39:18.620
they were particular
to the piece.

00:39:18.620 --> 00:39:20.910
Like we didn't say, this
person is the writer

00:39:20.910 --> 00:39:23.210
and this person is the director.

00:39:23.210 --> 00:39:26.910
What happened is
that, we started

00:39:26.910 --> 00:39:29.150
to identify where the
roles where that we needed.

00:39:29.150 --> 00:39:31.380
So we needed somebody
to direct the actors.

00:39:31.380 --> 00:39:34.256
We needed somebody
to create a structure

00:39:34.256 --> 00:39:36.130
for the story that was
coherent-- essentially

00:39:36.130 --> 00:39:37.640
that was the writer.

00:39:37.640 --> 00:39:39.440
But at the same time,
then we needed people

00:39:39.440 --> 00:39:43.240
to drive that text
in a way that was

00:39:43.240 --> 00:39:44.740
sort of improvised in real time.

00:39:44.740 --> 00:39:47.360
And those were actually people
with writing and directing

00:39:47.360 --> 00:39:52.080
experiences, but in this kind
of improvisational writing role.

00:39:52.080 --> 00:39:55.140
And so a lot of the decisions
came about in a really,

00:39:55.140 --> 00:39:57.620
sort of ad hoc
way, as we saw what

00:39:57.620 --> 00:39:59.200
the needs were of the piece.

00:39:59.200 --> 00:40:01.310
And sometimes it worked
and sometimes it didn't.

00:40:01.310 --> 00:40:04.670
And the roles were negotiated,
I would say, very fluidly.

00:40:04.670 --> 00:40:07.670
There was a guy who was
interested in cutting the video

00:40:07.670 --> 00:40:11.034
and so he cut the video and
directed the live stream.

00:40:11.034 --> 00:40:12.950
And then other people
had different interests.

00:40:12.950 --> 00:40:15.350
And so that was the advantage
of a class structure--

00:40:15.350 --> 00:40:17.760
was to experiment with
what those positions were.

00:40:17.760 --> 00:40:22.440
The other question about agency,
was really an ongoing dialogue

00:40:22.440 --> 00:40:25.420
between the different writers
and the writer/directors

00:40:25.420 --> 00:40:27.600
that were involved--
the students.

00:40:27.600 --> 00:40:29.410
In terms of what
we could just let

00:40:29.410 --> 00:40:31.800
happen based on
what was exciting

00:40:31.800 --> 00:40:33.550
and what was happening
at the moment, what

00:40:33.550 --> 00:40:38.946
had to be prescripted and what
was the overall frame that

00:40:38.946 --> 00:40:40.570
wasn't necessarily
the script, but sort

00:40:40.570 --> 00:40:42.480
of the progression of events.

00:40:42.480 --> 00:40:45.770
And I think what we found
is that the students who

00:40:45.770 --> 00:40:48.330
were doing this were really
interested in allowing people

00:40:48.330 --> 00:40:49.340
to have agency.

00:40:49.340 --> 00:40:51.550
Because typically they
were writing pieces

00:40:51.550 --> 00:40:55.180
where the actors or others
don't have agency, right?

00:40:55.180 --> 00:40:58.850
Where they are in a more
controlled film or television

00:40:58.850 --> 00:41:00.584
or online video experience.

00:41:00.584 --> 00:41:02.125
And so they were
excited about agency

00:41:02.125 --> 00:41:07.090
and interested in a
game like experiment.

00:41:07.090 --> 00:41:09.830
What we found though is that
the balance of these things

00:41:09.830 --> 00:41:13.040
meant that the live
streaming that came out of it

00:41:13.040 --> 00:41:15.810
was not in and of itself an
experience that maybe you

00:41:15.810 --> 00:41:19.480
would sit down and watch--
although some people did.

00:41:19.480 --> 00:41:24.270
And so I would say we hit-- we
skewed the agency goal here,

00:41:24.270 --> 00:41:26.340
to focus on the live experience.

00:41:26.340 --> 00:41:28.670
And sort of the
next iteration is

00:41:28.670 --> 00:41:33.840
to really try to balance the--
balance those things in terms

00:41:33.840 --> 00:41:36.790
of agency and then what's
enjoyable for an audience

00:41:36.790 --> 00:41:37.290
online.

00:41:37.290 --> 00:41:39.164
So I don't know if that
answers the question.

00:41:39.164 --> 00:41:42.046
But that's how we
thought about it.

00:41:42.046 --> 00:41:44.020
AUDIENCE: I got a
couple quick questions.

00:41:44.020 --> 00:41:46.060
Are the programs
an apps that you

00:41:46.060 --> 00:41:48.685
created available to the public?

00:41:48.685 --> 00:41:51.590
JEFF BURKE: They could be.

00:41:51.590 --> 00:41:55.162
I mean I think-- I mean
pretty-- So we don't really

00:41:55.162 --> 00:41:56.620
have any objection
to sharing them.

00:41:56.620 --> 00:41:58.540
And so within the sort
of terms of service

00:41:58.540 --> 00:42:04.000
that exist for the Glassware
and access to the APIs,

00:42:04.000 --> 00:42:05.600
we'd be happy to share them.

00:42:05.600 --> 00:42:07.070
I'd be much happier
to share them

00:42:07.070 --> 00:42:09.960
with people that are going to
do similar experimental work.

00:42:09.960 --> 00:42:12.360
And so like if you have
a specific interest,

00:42:12.360 --> 00:42:14.390
we should sit down and
try to provide access.

00:42:14.390 --> 00:42:16.181
There's not really an
intent than any thing

00:42:16.181 --> 00:42:17.270
would be proprietary here.

00:42:17.270 --> 00:42:19.100
AUDIENCE: The other
question was, as far

00:42:19.100 --> 00:42:23.060
as the live streaming and
what appeared on big screen--

00:42:23.060 --> 00:42:25.630
because I was actually
here for Grace Plains.

00:42:25.630 --> 00:42:29.440
And I got to see it for a
tenth of a second on that side.

00:42:29.440 --> 00:42:31.490
Was it-- what were
the limitations

00:42:31.490 --> 00:42:32.860
of what appeared there?

00:42:32.860 --> 00:42:35.440
Because from what
I saw a little--

00:42:35.440 --> 00:42:38.460
where the technology
is right now,

00:42:38.460 --> 00:42:41.450
suffered a little frame rate
loss and a little resolution

00:42:41.450 --> 00:42:42.270
loss.

00:42:42.270 --> 00:42:46.530
JEFF BURKE: So we had optimized
the streaming on Glass

00:42:46.530 --> 00:42:50.860
for all kinds of things, from
the connectivity that we had,

00:42:50.860 --> 00:42:53.557
to battery life, to
real time streaming

00:42:53.557 --> 00:42:54.640
performance and bandwidth.

00:42:54.640 --> 00:43:01.110
And it was optimized for
bandwidth and live performance,

00:43:01.110 --> 00:43:02.020
locally.

00:43:02.020 --> 00:43:04.974
And I would say that-- so
some of the limitations online

00:43:04.974 --> 00:43:06.390
are the ones you
mentioned, right?

00:43:06.390 --> 00:43:08.680
Resolution-- it wasn't
a limitations of device,

00:43:08.680 --> 00:43:11.660
it was a limitation the way that
we configured the streaming.

00:43:11.660 --> 00:43:12.930
Frame rate-- same thing.

00:43:12.930 --> 00:43:15.650
And so in Bodies
for a Global Brain,

00:43:15.650 --> 00:43:19.667
we actually shot, I
don't know, 720p video,

00:43:19.667 --> 00:43:20.500
and it looked great.

00:43:20.500 --> 00:43:21.850
And we were really
happy with it.

00:43:21.850 --> 00:43:23.475
And this just had a
different emphasis.

00:43:23.475 --> 00:43:26.210
So we had tuned it-- I would say
that's-- it has more to do with

00:43:26.210 --> 00:43:29.690
the reality of making real time
streaming across many mobile

00:43:29.690 --> 00:43:33.710
devices work, than being
in a Glass specific thing.

00:43:33.710 --> 00:43:37.570
And so-- I mean, I find
the creative challenges

00:43:37.570 --> 00:43:40.980
were probably more relevant,
since those kinds of things

00:43:40.980 --> 00:43:42.480
are probably going
to get resolved--

00:43:42.480 --> 00:43:44.063
or they can be
resolved with bandwidth

00:43:44.063 --> 00:43:47.590
and time and engineering effort.

00:43:47.590 --> 00:43:49.620
The bigger challenge
with what was out here,

00:43:49.620 --> 00:43:51.245
what we streamed to
YouTube, was really

00:43:51.245 --> 00:43:53.100
how do you structure a
compelling experience

00:43:53.100 --> 00:43:56.470
in a live cut, when you have
eight POV camera's moving

00:43:56.470 --> 00:43:58.670
around and a story that's
evolving as it goes.

00:43:58.670 --> 00:44:01.630
And these are the
things that people--

00:44:01.630 --> 00:44:03.760
I hate to use reality
television is an example--

00:44:03.760 --> 00:44:06.620
but they sit with for--
and look at and then

00:44:06.620 --> 00:44:09.970
edit, to make a
compelling experience.

00:44:09.970 --> 00:44:11.950
And you're trying to
do that on the fly.

00:44:11.950 --> 00:44:14.325
And I think that's some place
where we have a lot of work

00:44:14.325 --> 00:44:14.930
to do.

00:44:14.930 --> 00:44:16.638
Not really a technical
limitation, but it

00:44:16.638 --> 00:44:18.420
was one of the really--
one of the things

00:44:18.420 --> 00:44:22.080
I'd really like to play with,
for example, is using story

00:44:22.080 --> 00:44:26.000
information to help hint
cuts in the live experience,

00:44:26.000 --> 00:44:28.650
and then using sensors
or other information

00:44:28.650 --> 00:44:31.494
about where is a given
person's attention.

00:44:31.494 --> 00:44:32.910
Are two people
looking each other?

00:44:32.910 --> 00:44:34.285
Or were they
looking in the room?

00:44:34.285 --> 00:44:36.430
To hint that live
cutting process.

00:44:36.430 --> 00:44:38.460
But that's a whole
level of automation

00:44:38.460 --> 00:44:42.397
that we weren't getting to here.

00:44:42.397 --> 00:44:43.980
ELIZABETH HARTNETT:
Any last questions

00:44:43.980 --> 00:44:46.230
from the live audience?

00:44:46.230 --> 00:44:46.730
Cool.

00:44:46.730 --> 00:44:50.200
I have a good question
to end on from the Dory.

00:44:50.200 --> 00:44:52.180
Will augmented,
reality storytelling

00:44:52.180 --> 00:44:53.940
be the next democratic
breakthrough

00:44:53.940 --> 00:44:57.310
for storytellers in the way
YouTube was in this decade?

00:44:57.310 --> 00:45:02.542
And do you think that it will
ever become truly accessible?

00:45:02.542 --> 00:45:05.610
JEFF BURKE: Yeah, I
mean I think-- Yes.

00:45:05.610 --> 00:45:07.450
Will it become truly accessible?

00:45:07.450 --> 00:45:12.580
If other technology trends are
any indication, it will be.

00:45:12.580 --> 00:45:14.780
And a lot of-- again--
a lot of the challenges

00:45:14.780 --> 00:45:17.480
that we faced here we're not
really engineering challenges,

00:45:17.480 --> 00:45:19.480
although there
were a lot of them.

00:45:19.480 --> 00:45:21.510
But they were more
about the storytelling.

00:45:21.510 --> 00:45:24.330
And so I think the idea that
these tools exist and people

00:45:24.330 --> 00:45:27.930
make their own stories
and their own experiences,

00:45:27.930 --> 00:45:30.850
is something that's
really easy to imagine.

00:45:30.850 --> 00:45:32.770
And it's easy to imagine
with technologies

00:45:32.770 --> 00:45:35.570
that are out there in
the consumer market,

00:45:35.570 --> 00:45:37.320
or will be soon enough.

00:45:37.320 --> 00:45:41.370
And maybe the missing piece
is, where there are places

00:45:41.370 --> 00:45:43.810
where we can build
authoring tools?

00:45:43.810 --> 00:45:45.991
Where are there
architectures to aid people

00:45:45.991 --> 00:45:47.740
in constructing these
stories so that they

00:45:47.740 --> 00:45:49.750
could have a sophisticated idea?

00:45:49.750 --> 00:45:52.890
Like I really want
to cut to this person

00:45:52.890 --> 00:45:55.100
whenever they're looking
at this other character.

00:45:55.100 --> 00:45:55.600
Right?

00:45:55.600 --> 00:45:58.010
And those are things that
are creatively interesting.

00:45:58.010 --> 00:46:00.300
They're hard to
implement technically.

00:46:00.300 --> 00:46:02.420
They would democratize,
not just the idea

00:46:02.420 --> 00:46:04.110
that such an experience
could be made,

00:46:04.110 --> 00:46:06.100
but that it could be
made at a high level

00:46:06.100 --> 00:46:07.870
of artistic sophistication.

00:46:07.870 --> 00:46:11.520
And maybe those
types of examples

00:46:11.520 --> 00:46:14.774
are the equivalent of why
people really like high quality,

00:46:14.774 --> 00:46:16.690
high performance cameras
in their cellphones--

00:46:16.690 --> 00:46:18.170
for the videos if
they're making.

00:46:18.170 --> 00:46:20.030
And that, maybe the
equivalent of that

00:46:20.030 --> 00:46:23.145
will be coming, in terms of
authoring software and machine

00:46:23.145 --> 00:46:24.520
learning support,
and things that

00:46:24.520 --> 00:46:26.644
are happening in other
products and another product

00:46:26.644 --> 00:46:30.220
domains-- whether it's
Google or other companies

00:46:30.220 --> 00:46:31.600
and other research.

00:46:31.600 --> 00:46:34.730
And so I-- Yes, I
think it will open up.

00:46:34.730 --> 00:46:37.560
I think people will start
to tell stories in a way

00:46:37.560 --> 00:46:40.510
where the fictional and
real world's bridge.

00:46:40.510 --> 00:46:42.330
And where there's all
these possibilities

00:46:42.330 --> 00:46:44.690
for documentary and
historical storytelling

00:46:44.690 --> 00:46:45.950
as well as fiction.

00:46:45.950 --> 00:46:47.980
But where of those
worlds bridge,

00:46:47.980 --> 00:46:50.560
if we can provide some
authoring support in addition

00:46:50.560 --> 00:46:52.535
to just the kind of
core technologies.

00:46:52.535 --> 00:46:54.360
ELIZABETH HARTNETT: Great.

00:46:54.360 --> 00:46:56.930
And with that, we
will wrap it up.

00:46:56.930 --> 00:46:59.170
Thank you so much Jeff,
for coming and speaking

00:46:59.170 --> 00:47:00.320
to our audience.

00:47:00.320 --> 00:47:02.581
[APPLAUSE]

