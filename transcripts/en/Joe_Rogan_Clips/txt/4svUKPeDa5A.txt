Speaker 1:          00:00          How much time have you put into artificial intelligence? And we do a lot of work in my lab on Ai. What about sex robots? Like what rules should they give for sex robots and how much could that damage interpersonal relationships? That's a great question. That's exactly the right question in my view. So our concern with sex robots from a liberty point of view should not in the slightest. B, whether you enjoy a sex robot, it's your business, right? You'd buy or Bot do what you want. I really don't. I see. I find it would be hard pressed to, to object. The problem is with said, well, let's back up from the less provocative. Let's come back to sex. But I looked like a simpler example. First let's talk. Let's talk about your children talking to Alexa. Okay, so the person who designs Alexa wants to make your child's experience easy and pleasant, and as part of the programming of Alexa, because they want to make Alexa the obedient servant of your child, it doesn't require a child to say, please, Alexa, would you play the music for me?

Speaker 1:          00:57          Your child can be as rude as she wants to. Alexa and Alexa will do what she wants. What you should be concerned about, however, is not your child's interaction with Alexa would you should be concerned about is what your child is learning from interacting with Alexa. That then she takes to the playground. So now she's rude to other children. So Alexa is corroding our social fabric. Alexa, in this example is making children rude to each other. So our concern is not so much do we make and do we make, you know, like Asimov's laws of robotics? Do we we, it's not that we want to program the robots so that their don't harm you. We we, it's true. The first law, we don't want the robot to through an act of commission or omission harmer allow human to come to be harmed. It's that we're concerned about how the robot and interacting with you might cause you to harm others.

Speaker 1:          01:45          The robot, the robotic intelligence creates these externalities, these cascade effects. So in the Alexa example, we might want to regulate the programming of devices that speak to children. Not because we want to deprive your daughter, have the right to speak how she wants, but because we recognize that that robot is going to cause your daughter to be rude to other people. Is it really? Do you really think? Yes, the Alexa, what's the weather that that would make your slowly but surely? I think it will contribute. So that's a, it's an example. It's not like, I'm not arguing that Alexa should become ornately think it's so novel to kids that they know it's not a person. I don't think it really all right, but we're using these examples to build a thing. So let's talk about the sex robots. So some people believe that actually the, the emergence of sex robots, which will surely appear in the next 10 or 20 years, um, will, um, will be a fantastic boon.

Speaker 1:          02:42          They think that, um, you'll people be able to experiment. Uh, you'll be able to experiment with same sex relationships. For example, a group sex. Uh, you might learn to be a better lover. So he could practice with the robots and therefore you'd be more experienced when you having sex with a real human. So they said you can't get venereal diseases from a sex robots. You can't hurt their feelings. Uh, so people think that, uh, the argument based on ethical grounds is that this would be terrific, uh, that this will be a benefit. Other people have the opposite opinion. Other people think that actually having sex with a robots first of all is symbolically and, and, um, conceptually vile. They think that, you know, it, it, it did take sex and converts it into a kind of a, a machine, literally a machine like a, you know, function.

Speaker 1:          03:30          Uh, and they furthermore think that it would result in you in one having a kind of anonymous or impersonal interactions with human subsequently that you'll be in trained, you know, to let's say want an obedient, uh, you know, partner, uh, for example, I don't have a stand on this. Like I don't know which way it's going out. And in a way I don't have to get, make a stand on it. Because what I'm interested in recognizing is that when we talk about having, allowing people to have sex with sex, robots not allowing there, it's going to happen. The focus of our concern should be not what is your experience in your bedroom when you have sex with a sex robot? Our concern is a state like my interest. I have no stake or control over what you're doing over there, but my interest is in, in once you have had that experience, how does that change how you interact with other people? Right? And there I think just like anything else, like you can, you can make all the garbage you want in your house, but if you start polluting the environment, you're harming me. So now I have a reason for intervening in your activities on your land. You can't pollute your own land if that pollution runs off onto my land. And so the similar argument can be made or look at autonomous vehicles. Here's an example.

Speaker 1:          04:40          Right now we have all roads. Almost all roads have just human drivers and in 20 or 30 years, almost all roads will probably have only nonhuman drivers. Machines will drive and those autonomous vehicles probably can be yoked together. They can communicate with each other so that you'll have like, like trains of cars moving in synchrony. Like each of them will be communicating with the other nearby cars and you'll have laminar flow where all these vehicles are smoothly moving and joining the highway and leaving the highway and communicating on a citywide scale, slowing traffic down miles away because they anticipate with AI that there'll be a jam here if they don't do that. And, and I think that'll be actually great. I'm actually looking forward to autonomous. I mean, I still like to take my car to a speedway, but you know, drive itself with stick, which I like, but you know, but in between we're going to have a world of what I call hybrid systems of human driven cars and autonomous vehicles coexisting in an on a plane, on an even plane.

Speaker 1:          05:40          And we need to be worried about that because these autonomous vehicles, when we interact with them are going to change how we interact with each other. For example, do we program the autonomous vehicle to drive at a constant steady speed? If you're the designer of the car, you might say, Gee, I don't want this car to crash a, I want the car to drive in a very predictable fashion. And that's what's best for the occupants of the car. That's what's gonna allow me to sell more vehicles. But it may be the case that actually when people are in contact with such a vehicle, they get lulled into a false sense of security. Oh, I'd vehicle never does anything new. I don't need to pay so much attention to the car in front of me. I just miss drive, you know, at a steady clip. And then they veer off and they go to a part of the highway where they're just human drivers.

Speaker 1:          06:27          And now having been lulled into a false sense of security, they cause more collisions is not paying attention. So that autonomous vehicle has changed how I drive in a way that harms other people. So maybe the programming of the vehicle should be to occasionally do erratic things too. Like suddenly slow down or speed up a little bit, obliging me to stay vigilant and pay attention as I'm interacting with that car. So that then when I go to another part of the highway, when I interact with just humans, I have retained that vigilance. Once again, the lesson here is that it's not just about the one on one interaction between the robotic artificial intelligence and the human being. It's about how the robot's affect us. And in my lab, we do many experiments in social systems where we take a group of people and we drop online, we drop a Bot or in the laboratory we have a physical robot and we watch how the presence of the robot doesn't just modify how the human interacts with a robot, but how the humans interact with each other.

Speaker 1:          07:25          So if we put a robot right, they're looking at us with its third, I would, we, uh, you know, would it change how you and I talked to each other, make us different. That's the experiments we're doing. Well, clearly in the sex robot realm, that's going to be a problem. I mean we, we see the difference between humans that, uh, have porn addictions. Yeah, that's a good example. Yeah. Porn addictions. When people do, they developed this very impersonal way of communicating with people and they, they think about sex and the objectification of the opposite sex in a very different reason, a very different way. And it flavors the way you add flavors, your expectations. Yes. Yes. And it makes it difficult. It can make it difficult for you to have normal sexual relationships if you come to see if your expectations are, are, uh, guided by a porn and that is going to be radically magnified by some sort of artificial life form that you created that's indistinguishable.

Speaker 1:          08:25          Yes. Have, you can have an indistinguishable sex partner that is, you know, some incredibly beautiful woman that is a robot and then you or man, let's go, man, women should be quite happy to change their spouses for robots. I wonder if women are going to be as into it as men because I think women divine desire, more emotional intimacy and I think, I mean, uh, on a, on a scale than men do. I, I think, um, I think the jury is out on know what, what the relative balance between men and women, we might be surprised that, uh, that will be replanted males, especially given x societal expectations and women can to those. And, and given how your pain in the ass a lot of men can be. Sure. So it could go both ways. I don't, I'm not prepared to make a prediction who's going to be better off in the gender debate with the emergence of sex robots.

Speaker 1:          09:18          And they'll maybe you way you suggest, I don't know. Well, we're also in this weird position genetically where they're doing genetic ex, ah, experiments on humans. And with the advent of CRISPR emerging technologies, I talked about that in the book too. Entirely possible that there's not gonna be any frumpy bodies anymore. That that's hundreds of years away. But is it? Yes, I think so. I wonder, I mean, I don't know if it is, I think if they start cracking them out in China and they start giving birth to eight foot tall superman, yes. 12 inch Dicks, yes. We're going to have a real issue. Yes. Uh, so we will, uh, yes, that's the least of it, like God, but I mean it's really entirely possible in the future. They're going to have that and then we're going to likely cumins yes. I think that is likely the debate is how far in the future.

Speaker 1:          10:04          So I don't think we're going to start by using these technologies to cure a monogenic diseases. So, you know, like thalassemia for example, so a diseases or certain immune deficiencies, a disease where single gene is defective and uh, and those will be the initial targets. But once we start with that, eventually I think there will be people who will want to genetically engineer other people, uh, their offspring for example, and a modified them in the ways that you suggest, maybe not 12 inch Dick's, but maybe, you know, ability to run fast or something else. Far Smarter. I mean, yes. Isn't that one of these side effects that they showed with the, um, genetic manipulation of these Chinese babies to, uh, eliminate HIV there, that they made them smarter? No, I don't know if they made them smarter there. What's clear from the most recent findings? I've seen from that case is that a unsurprisingly is anyone could predict the technology is not good enough to restrict the mutations to one particular region of the genome.

Speaker 1:          11:00          So there were other changes in the genome in these children that occurred elsewhere rather than the targeted region, which was to increase their immunity to HIV. And we don't know what those are, but those could kill those kids quickly. We could make them better in some ways. We have no way of knowing yet. But I think their conclusion was that it increased their intelligence. I don't, I think it's, I have not seen those results and I think it would be premature. I find that it would because they're very mature to come to their babies does. Yeah. The problem is also sensationalist clickbait, which is that's what you want to click, you know, not just that they did the HIV and they made them smarter is going to get like 40% more clicks. Yes. Ooh. Versus, yeah. Woo. 40%. Yeah. That, I mean, that's, that's just the nature of humans, right?

Speaker 1:          11:42          Yes. Um, just to be clear, I talk about the CRISPR example in, in uh, in blueprint. I actually talk about these, how these technologies, again, my lens on it is how these technologies are going to change how we interact with each other. And it goes back to the example we were talking about at the beginning when we invented cities. That was a technology that changes how we interacted with each other. So human beings for a very long time had been inventing when we invented weapons. That was a technology that changed how we interact with each other. So we have previously done this kind of thing. We've invented a technology that changes how we interact with each other and I'm very interested in, in the and discuss some of those implications. Yeah. I'm, I'm incredibly interested in this because I love to study history and I love to study how crazy the world was four thousand five thousand years ago, a thousand years ago, what it's going to be like in the future.

Speaker 1:          12:33          I just think our understanding of the consequences of our actions are so different than anybody has ever had before. We have just such a broader, first of all, we have examples from all over the world now that we can study very closely, which I don't think really was available to that many people up until fairly recently. You mean? I'm sorry. You're saying the examples are more numerous or capacity to discern them is higher. Our capacity to discern them and just our in depth understanding of these various cultures all over the world. Like what do you've been telling you today about these, the divers and others? We just have so much more data and so much more of an understanding than ever before. Yes, I love the idea that we are, I mean I believe that this is probably the best time ever to be alive and I think that it's probably, I think that's true.

Speaker 1:          13:22          I think there's certainly a lot of terrible things that are wrong in the world today also true. But I think that there's less of that and more good. Exactly that too before. No, I think that's right. And, but one of the arguments that I make is this is a kind of Steven pinker argument that you're outlining, which is, you know, with the emergence of, I mean, people are living longer than they ever have on the whole planet. Fewer people in starvation. We have less violence. I mean, every indicator of human wellbeing is up. Uh, and it's partly due, are largely due in the recent last thousand years to the, uh, to the emergence of the enlightenment and the Phyllis, the philosophy and the science that was guided that emerged about 300 years ago and 200 and some odd years ago. And, and culminating in the present and continuing. So I think, I think this is not just the kind of so-called weekish view of history.

Speaker 1:          14:13          It's not just a progressive sort of fantasy. I think it's the case that these philosophical and scientific moves that our species made in the last few hundred years has improved our wellbeing. However, as we've been discussing today, it's not just historical forces that are tending towards making us better off a deeper and more ancient and more powerful forces also at work, which is natural selection. It's evolutionary and not just historical forces that are relevant to our wellbeing. And we don't just need to look to philosophers to find the path to a good life. Natural selection has equipped us with these capacities for love and friendship and cooperation and teaching and all these good things we've been discussing that also tend to a good life. So, so yes, I totally agree with you. We're better off today than we've ever been on average across the world. However, it's not just that that's contributing to our wellbeing.

Speaker 1:          15:05          This natural selection is literally why we are in this state now and why we were hoping this trend will continue. Yes, we will be in this better place 50 years from now, 100 years from now. Well, natural selection doesn't work over those time scales. So those are historical forces. But the point is we are set up for success. Yes. Um, you know, we are equipped with these, uh, you know, you're given five fingers which make it pos and an opposable thumb, which allows you to manipulate tools. So natural selection has given you an opposable thumb. Culture lets you use a computer. Do you worry about the circumventing of this natural process by artificial intelligence that artificial intelligence is going to introduce some new, incredibly powerful factor into this whole chain of events that by having sex robots and sex or, or, or, or um, robot workers, yes.

Speaker 1:          15:58          Things becoming automated. Yes. This I'm, I'm concerned. I mean, this is, I think I'm very concerned about how technology is going to affect our economy. These, again, these concerns were not the first generation to face these concerns. There were similar concerns with the industrial revolution that workers were being put out of work when machines were invented. Nevertheless, work persisted. People still had jobs to do. Um, there was a disruption. There's no doubt about it. I think Google and the information revolution and these types of robotic automation are disruptive. They're going to affect how we allocate labor and capital and data in our society. There's no doubt about all of that. I thought you were alluding to just to check if you were to the debate, which I don't know the answer to on whether AI will, you know, are we gonna face like a terminator type existence where you know, the machine's rise up and kill us all or not, and you know, very smart people on both sides of that debate.

Speaker 1:          16:52          And I read them all and like I would like, he's right. And then they read the guy that has the opposite of me. I'm like, no, no, he's right. And then it goes back and forth. I don't know who's right. That goes back to nuance, right? Yes. It is nuanced, but it's hard to know whether, again, we're not talking over our lifetimes, right. Over hundreds of years, you know? Is there a time a thousand years from now when the human beings will say, what the hell were our ancestors doing inventing artificial intelligence? They're wiping us out. I don't know the answer to that question. I think there's an issue also with the, the concept of artificial, like artificial life, artificial intelligence. It's, I think it's going to be, life is just going to be a life that we've created. And I don't think it's artificial. I just think it's a different kind of life.

Speaker 1:          17:35          I think that we're thinking of biologically based life of sex. Yes. You know, well, some people should reproduction in terms of the way we've always known it as being the only way that life exists. But if we can create something and that something decides to do things, it's sound create, live on its own. Yeah. It's silicone based life form. Like why not? Why? Why does life have to be something that only exists through the, you know, multiplication of cells. Yes. That's very charitable of you. And uh, it's, people make that claim. Uh, some people think that, you know, those machines in the distant future, we'll look back at us as like one stage of evolution that culminated in them that we're, I've always said that we are some sort of an electronic, uh, Caterpillar that doesn't know that it's going to give birth to a butterfly.

Speaker 1:          18:25          We're making your cocoon. We don't even know what you're doing. That's a great metaphor. I have a hard time accepting that because you're a person. Yes, it's against my interests were, we're so flawed. All these things that we've outlined lollypops those would go away with artificial intelligence. It's a deep philosophical question, Joe. I don't think it's inevitable and I think if the single celled organisms are sitting around wondering what the future would going to be like, where are we going to be replaced? Will they make antibiotics and kill us? Yes. Yes. They are going to kill us. I mean this is, I mean we are so flawed. We do the parade, the ocean. We do pull the fish out of it. If you fuck up the air, do commit genocide. There's all these things that are real, but the artificial life won't have those problems because it won't be emotionally based, won't be biologically based.

Speaker 1:          19:07          It'll just exist. That's a really good story. We're so flawed. Why not? Not so much better. Oh, we're very flawed. We are flawed, but like I said, I'm not going to, we're very flat though. We are fly. I think it's beautiful. Beautiful too. But I think vultures probably think they're beautiful too. That's why they breed with each other. Well, they are beautiful, but, but the point is I think we have a flop beauty. I like, I'm going to stick to my principles that we are, despite our flaws worth it. There's something wonderful about us. And I think that that wonderful creative quality is the reason why we created artificial life in the first place. It's like this, this creation. We've had that impetus. You know, if you look at a lot of the, um, the art, whether it's the Egyptian, you know, the, the, the, the pyramids or other kinds of, um, artistic expression, we seem to have had a desire to transcend death, you know, to make things that sure that looked like us but weren't alive forever actually.

Speaker 1:          20:06          So, I mean, I think in that regard, I think you're quite right that, um, it's not gonna stop that Tennessee is not gonna stop now. You're, you're very, as I said, charitable positive take on the claim and your analogy to a single celled organisms, which are just, you know, but a fleeting, not a fleeting, they're still there, but a phase in our evolution, you know, is something I'm going to have to be thinking about because it's disturbing, honestly. Well it's an objective perspective. If I took myself out of the human race, which I really can't, but if I tried to fake it, I would say, oh I see what's going on here. Yeah. These gummies is, yes, these dummies are buying iPhones and new Mac books because they know that this is what's going to help the of newer, more superior technologies. The more we consume.

Speaker 1:          20:51          It's also based, I think in a lot of ways our insane desire for materialism is fueling this and it could be an inherent property of the human species that it is designed to create this artificial life and that literally is what it's here for. And much like an ant is creating an ant hill and doesn't exactly have some sort of a future plan for its kids and its four o one k plan that what we're doing is like this inherent property of being a human being, our curiosity, our wanderlust, our design, our these things. Yeah. All these things are built in because if you follow them far enough down the line a hundred years, 200 years, it inevitably leads to artificial life. Yes. I think, uh, I think that's possible. Um, and of course we're not going to be alive to see, to test that idea. There's Sun will maybe with CRISPR and all this crazy shit that's coming down.

Speaker 1:          21:46          Oh come on. I know there's nothing's gonna happen in the pace of innovation. People always had been said. If you go back every decade, people say just around the corner, just around the corner, these things that are take forever. They're very hard. Biological systems are very hard to engineer. Um, I don't, and you know, of course the people who do that kind of work will often, I think a lot of them engage in snake oil. You know, they'd want a fund. There was. Sure, but I think it's entirely possible that there's a 20 year old listening to this podcast will be 150 yes. That's possible. Maybe a lot more than that.