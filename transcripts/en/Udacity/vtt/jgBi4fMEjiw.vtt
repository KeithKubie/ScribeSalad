WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:04.500
So DEC-POMDP, I've written out
the expansion of what it stands for.

00:00:04.500 --> 00:00:07.170
Decentralized partially
observable Markov decision, and

00:00:07.170 --> 00:00:08.380
then I kind of ran out of space.

00:00:08.380 --> 00:00:09.340
&gt;&gt; Nah, the P doesn't matter.

00:00:09.340 --> 00:00:12.350
&gt;&gt; But you know that it's a POMDP,
decentralized POMDP, and so

00:00:12.350 --> 00:00:16.850
the quantities that define the DEC-POMDP
are very similar to the quantities that

00:00:16.850 --> 00:00:21.300
define a POMDP,
we've got a set of states, transitions,

00:00:21.300 --> 00:00:24.670
rewards, observations,
observation function.

00:00:24.670 --> 00:00:28.210
The major difference is that
actions are actually taken

00:00:28.210 --> 00:00:31.320
simultaneously by
a finite set of agents.

00:00:31.320 --> 00:00:34.890
There isn't just one driver
there is actually a whole,

00:00:34.890 --> 00:00:38.690
you know, too many emcees,
really, not enough mics.

00:00:38.690 --> 00:00:40.170
&gt;&gt; Well done.
&gt;&gt; There's a set of agents who

00:00:40.170 --> 00:00:43.500
actually get to have some say
over how the transitions works.

00:00:43.500 --> 00:00:46.300
So we're going to say capital I
is that finite set of agents,

00:00:46.300 --> 00:00:51.250
actions available to an agent
is A sub little i for agent I.

00:00:51.250 --> 00:00:54.740
And the transition
function is a function of

00:00:54.740 --> 00:00:58.200
the joint actions taken by all
the agents simultaneously.

00:00:58.200 --> 00:01:03.380
So instead of just going from state
to a next state through an action,

00:01:03.380 --> 00:01:08.940
this is actually, you could think of
it as a vector with one action for

00:01:08.940 --> 00:01:10.170
each of the agents in our set.

00:01:10.170 --> 00:01:10.770
&gt;&gt; All right.

00:01:10.770 --> 00:01:11.400
That makes sense.

00:01:11.400 --> 00:01:14.520
&gt;&gt; So that really is very
similar kind of quantity but

00:01:14.520 --> 00:01:16.550
we break up where
the actions are happening.

00:01:16.550 --> 00:01:18.520
They have to happen jointly.

00:01:18.520 --> 00:01:22.420
And the agents themselves, their
observations about the environment,

00:01:22.420 --> 00:01:25.370
are also distributed, in a sense.

00:01:25.370 --> 00:01:30.460
Agent i gets to gets to see something
that's a function of the agent and

00:01:30.460 --> 00:01:31.470
the state of the world.

00:01:31.470 --> 00:01:35.030
All right, so, this is a model.

00:01:35.030 --> 00:01:37.470
In this model,
all the agents are acting cooperatively,

00:01:37.470 --> 00:01:40.300
because there's one shared reward
function that everybody gets.

00:01:40.300 --> 00:01:42.900
If we actually split the reward
function so there's a different one for

00:01:42.900 --> 00:01:44.310
each of the agents, we get yet

00:01:44.310 --> 00:01:47.040
another model they're not
going to talk about caught up.

00:01:47.040 --> 00:01:50.150
Partially observable stochastic game or
POSG.

00:01:51.570 --> 00:01:52.420
&gt;&gt; POSG.

00:01:52.420 --> 00:01:53.120
&gt;&gt; POSG.

00:01:53.120 --> 00:01:54.500
&gt;&gt; I'm positive that
would be interesting.

00:01:54.500 --> 00:01:57.400
&gt;&gt; Yeah, yeah so we could POSG
this discussion at this point and

00:01:57.400 --> 00:01:58.305
have a side discussion.

00:01:58.305 --> 00:02:01.200
&gt;&gt; [LAUGH] More puns.

00:02:01.200 --> 00:02:03.585
The P stands for puns.

00:02:03.585 --> 00:02:05.500
&gt;&gt; [LAUGH]
&gt;&gt; So, this makes sense and

00:02:05.500 --> 00:02:09.759
sounds great as a formalism goes,
but I'm kind of struck.

00:02:09.759 --> 00:02:13.080
When you brought up the stochastic games
thing, I was thinking the whole time,

00:02:13.080 --> 00:02:15.720
this sounds like game theory stuff.

00:02:15.720 --> 00:02:16.450
&gt;&gt; Yeah, yeah.

00:02:16.450 --> 00:02:19.160
Right, it's sort of clearly game theory
when we have separate reward functions,

00:02:19.160 --> 00:02:22.970
because every agent has its
own personal interests.

00:02:22.970 --> 00:02:27.670
Right, so, the DEC-POMDP setup is
a kind of common interest game,

00:02:27.670 --> 00:02:32.010
might be a word for it, the notion that
there's agents acting independently, but

00:02:32.010 --> 00:02:34.480
they're all acting for the same reward.

00:02:34.480 --> 00:02:36.030
&gt;&gt; So,
we could model this as game theory, or

00:02:36.030 --> 00:02:37.740
is this some different
way of thinking about it?

00:02:37.740 --> 00:02:41.190
&gt;&gt; It's part way between game theory and
POMDPs, yeah.

00:02:41.190 --> 00:02:43.890
It has elements of both, and
in fact, I guess it subsumes both.

00:02:43.890 --> 00:02:47.780
So, you can represent any POMDP as
a DEC-POMDP with just one agent.

00:02:47.780 --> 00:02:52.500
And you can represent any common
interest game as a DEC-POMDP with

00:02:52.500 --> 00:02:56.120
complete observability, or
maybe no states, that sort of thing.

