Speaker 1:          00:00          In this video, we'll describe a very important problem in natural language processing. The problem of language model.

Speaker 1:          00:09          So a language model is a probabilistic model that is signs, probabilities to any sequence of words. So it's a distribution essentially on a sequences of words, on sentences and documents. And so the problem of language modeling or the task of language modeling is to actually learn such a model that will assign high probabilities to a well formed sentences. So sentences that are likely to be written in some document or heard or and so on. Um, this is a problem or task that is very important. Natural language processing. A lot of systems actually incorporate in language modeling component such as speech recognition systems and machine translation systems. So find stance, uh, if we add a sentence wanted to translate in Beth [inaudible] and uh, we had assistant that's pretty good at just translating each individual words. So in would be the Sim would know that you would translate it to uh, which is here also.

Speaker 1:          01:15          And Besson would be translated by person. And then I tell you, Shannon would be considered by smart. Um, but imagine our system is also not so good at determining the order of these words, then, uh, in, in the setting, uh, language model would be very useful in distinguishes funds funds since whether we should prefer a person smart or a smart person as a good translation of in fascinated Asia and particular if you have a good language model than it would recognize that this has a higher probability of being a written by a person in English, then a person smart. So in this case it would have been able to reorder Besson and put it after antigen out in, in the actual translation in English. So, um, there are many other types of usage of uh, language modeling, uh, and language problems, uh, sorry, language models. Uh, and so they are really, really important in natural language processing.

Speaker 2:          02:21          Okay.

Speaker 1:          02:21          And the assumption that one often makes when, uh, someone designs a language model is to make the nef order Markov assumption. What this assumption, uh, says is that if we have a distribution of probability distribution over a sequence, then, uh, the, uh, uh, then we're assuming that we can write it as the product of the probability of each element of the sequence given only the n minus one previous elements in that sequence. Or in our case we're modeling words. So we're assuming that the word at position t is only dependent on the n minus one previous words and does not depend on the other words, uh, before that in the sequence of words in this sentence or in the document. Um, so this is, uh, restrictive, uh, assumption. Uh, it essentially never, he holds it really holds I, except for perhaps very, very large and values. And, um, and whenever I'm going to talk about context, I'm going to talk about these n minus one people's words. They're the words on which were conditioning the probability of observing the next word.

Speaker 1:          03:39          So, uh, the, a model which or type of model that is very frequently used in natural language processing is known as the engram model. So first, let's describe what we mean by Anne Graham and then drive is just a sequence of and words that, uh, usually we extract from some training data from some, uh, uh, corpus of words. So for instance, it would just take that sentence here as our corpus, our, our training data. Uh, then, uh, the unigrams that are contained is what there is, is, which is right here. There's a, there's a sequence and all of the other individual words in that, uh, in that sentence, uh, examples of backgrounds taken from that sentence would be as, uh, because we have is followed by, uh, here, uh, also a sequence because we have, uh, followed by sequence here and so on. And then try grounds, which corresponds to an equals three.

Speaker 1:          04:39          And then Graham for any equals three, uh, when an example is, is a sequence because we have is a sequence here, uh, as sequence of, because we have a sequence of here and so on. So that's what an then Graham is really just a sequence of and words that is usually extract them from some, from Beta, remove some ink. And so, um, and then Graham model is going to estimate the conditional probability that we need in our mark of model for assigning the probability of a whole document or sentence a is going to estimate that conditional probability based on counts of and grams that counts that are extracted from some training corpus of training data. Uh, so specifically if we had a set of words, the m minus one people's words or the context and we're monitoring what's the probability of some given word that is observed next.

Speaker 1:          05:36          But what we do is that we would count. So imagine we have dysfunction count that just contains the number of times that the context, so the word from position t minus one t minus and minus one up to t a w WT minus one. So the number of times we've observed this context followed this word wt. The probability conditional probably as a modeled by, uh, estimated by this model is going to be proportional to that count. And then we're going to normalize that by the number of times we've seen this context followed by any word. So by dividing this way, then we're guaranteed that this estimate of the probability is about it. Probability it's going to sum to one.

Speaker 2:          06:25          Yeah.

Speaker 1:          06:27          No [inaudible] models have one particular problem or challenge that I have to face. Uh, and it's a problem data sparsity so if you want a good model that's accurate, that that is close to reality, a really what we want is, and to be as large as possible. Otherwise, once it's for any equals one, then we actually assuming that all the words are independent because then the n minus one previous words, that's one minus one. That's the zero previous words. So we conditioning on no words before, uh, any word for, uh, when we're modeling the probability of each word in the sentence. So effectively we're considering that all the words are independent, the seeds sequence, which is of course a very crude, uh, assumption to make a, if that any calls to them, we're just assuming that if we know one word, then the distribution of the next word is, uh, uh, not influenced by the third word before or fourth word before then.

Speaker 1:          07:28          So on. Uh, uh, so, uh, so that again is a very crude approximation. So really we want, and to be as large as possible to get a realistic model, Howard for large values of n, then it means that when we're estimating these probabilities in this end grand model, uh, it's going to be much more likely that for some new data and some, uh, testing corporate for which we are evaluating the probability of sentences, it's going to be much more likely that we will have never seen the exact context for which we have to condition for evaluating our conditional probabilities in the uh, and grand model. And so, uh, there are ways of alleviating this problem. Uh, essentially they're all variants of this idea of smoothing the accounts that is, uh, when we're, for instance, estimating the probability of some word given the three previous words.

Speaker 1:          08:23          So we have, uh, uh, for gram here model. And then instead of just making that proportional to the number of times we've seen w one followed by w two w two and NW for a, and then normalizing, we actually have this probability be proportional to a combination of the counts of seeing w one up next to w two w three and four. And then combined with the number of times we've seen just w two followed by w three w four. And then combine that also with w three and four. And then the number of times we've seen w four. And so there's a whole literature on ways of combining these different counts to get a, a model that doesn't ever fit as much in generalizes better. Uh, but, uh, actually as we'll see, uh, uh, this only partly solves the problem in the sense that there's something better we can do a, and specifically we'll see a neural network language model that they cannot perform this approach.