WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:02.430
&gt;&gt; Alright, so let's say something that we actually know about

00:00:02.430 --> 00:00:06.450
this approach to action selection which is called Epsilon Greedy Exploration.

00:00:06.450 --> 00:00:10.100
And what we know is that if the action selection if

00:00:10.100 --> 00:00:14.410
GLIE, which means Greedy in the limit with infinite exploration, and

00:00:14.410 --> 00:00:16.810
that basically means that we are decaying our epsilon for epsilon

00:00:16.810 --> 00:00:19.440
Greedy. That we start off more random and over time we

00:00:19.440 --> 00:00:22.630
get less and less random and more and more Greedy. Then

00:00:22.630 --> 00:00:25.370
we have two things that are true. One is that Q hat

00:00:25.370 --> 00:00:27.490
goes to Q, which is, which comes from kind of a

00:00:27.490 --> 00:00:32.479
standard Q learning convergence result. But, we also have something cooler in

00:00:32.479 --> 00:00:35.920
this case which is that the policy that we're following, pi

00:00:35.920 --> 00:00:39.150
hat, is getting more and more like the optimal policy over time.

00:00:39.150 --> 00:00:39.480
&gt;&gt; Hm.

00:00:39.480 --> 00:00:43.950
&gt;&gt; So, not only do we learn stuff, but we use it, too. And this

00:00:43.950 --> 00:00:46.820
is an example of the exploration exploitation

00:00:46.820 --> 00:00:50.160
dilemma. And exploration exploitation is really, really important,

00:00:50.160 --> 00:00:54.050
not just because they're two words that surprisingly start with

00:00:54.050 --> 00:00:58.090
the same five letters, like unlikely letters. But also, that

00:00:58.090 --> 00:01:00.530
it is strike, it is talking specifically about this issue.

00:01:00.530 --> 00:01:04.650
Exploitation is about using what you know. And exploration is

00:01:04.650 --> 00:01:06.520
about getting the data that you need so that you

00:01:06.520 --> 00:01:09.750
can learn. And this is one particular way of doing,

00:01:09.750 --> 00:01:12.210
it turns out there's lots of other ways of making

00:01:12.210 --> 00:01:15.270
this trade-off and the reason it's a trade-off is because

00:01:15.270 --> 00:01:20.740
there's only one of you. There's only one agent acting in the world and

00:01:20.740 --> 00:01:23.230
it has these two actually somewhat conflicting

00:01:23.230 --> 00:01:25.510
objectives. One is to take actions that it

00:01:25.510 --> 00:01:27.930
doesn't know so much about, so it can learn about them and the other one

00:01:27.930 --> 00:01:31.370
take, takes actions that it knows are good. So that it can get high reward.

00:01:31.370 --> 00:01:33.480
&gt;&gt; Hm, that makes sense. You know, I didn't, I

00:01:33.480 --> 00:01:37.820
never realized that exploration and exploitation share the first five letters.

00:01:37.820 --> 00:01:38.420
&gt;&gt; Hm.

00:01:38.420 --> 00:01:40.380
&gt;&gt; I always knew that they shared the last

00:01:40.380 --> 00:01:41.000
five letters.

00:01:41.000 --> 00:01:43.040
&gt;&gt; Oh, that's interesting too.

00:01:43.040 --> 00:01:46.960
&gt;&gt; Huh. So if you take an r and turn it into an

00:01:46.960 --> 00:01:51.870
it, you might move from exploration to exploitation. I feel like an entire

00:01:51.870 --> 00:01:56.110
political movement could be founded on that. [LAUGH]. But I'm not sure exactly

00:01:56.110 --> 00:01:59.180
what it would be yet. Maybe I'll work on that, before our next lesson.

00:01:59.180 --> 00:02:02.050
&gt;&gt; So I have an algorithm. There, there's a standard, lemma.

00:02:02.050 --> 00:02:02.650
&gt;&gt; Mm hm.

00:02:02.650 --> 00:02:05.770
&gt;&gt; In reinforcement learning theory called the exploration

00:02:05.770 --> 00:02:08.870
exploitation dilemma. Sorry, [LAUGH], no, lemma. The other kind

00:02:08.870 --> 00:02:12.090
of lemma. The exploration exploitation lemma, which has to

00:02:12.090 --> 00:02:14.720
do with taking actions that are either exploring or

00:02:14.720 --> 00:02:18.080
exploiting. But I have one where you actually do teaching.

00:02:18.080 --> 00:02:18.411
&gt;&gt; Mm-hm.

00:02:18.411 --> 00:02:19.740
&gt;&gt; You can actually, each time you take

00:02:19.740 --> 00:02:21.330
an action it's either going to teach the

00:02:21.330 --> 00:02:23.540
agent something, it's going to explore or exploit. So

00:02:23.540 --> 00:02:27.510
I call that exploration exploitation, or explore, exploit, explain.

00:02:27.510 --> 00:02:31.270
&gt;&gt; Oh, nice. But you could have called it the exploration exploitation

00:02:31.270 --> 00:02:33.930
dilemma because you used dilemma. And di means

00:02:33.930 --> 00:02:37.220
two sometimes. And you do the two things.

00:02:37.220 --> 00:02:38.660
&gt;&gt; Well, in fact, dilemma does literally

00:02:38.660 --> 00:02:40.560
mean two. Its a choice between two things.

00:02:40.560 --> 00:02:42.120
&gt;&gt; Right, so its a dilemma.

00:02:42.120 --> 00:02:43.490
&gt;&gt; Nice

00:02:43.490 --> 00:02:44.480
&gt;&gt; Its a lemma about two things.

00:02:44.480 --> 00:02:46.832
&gt;&gt; Alright, so there is, it turns out there's a lot

00:02:46.832 --> 00:02:50.690
of other approaches to exploration and exploitation. And some of them in

00:02:50.690 --> 00:02:53.180
the, in the model based setting. You can do a lot

00:02:53.180 --> 00:02:56.310
more with it, a lot more powerful things with it because you

00:02:56.310 --> 00:02:59.650
actually can keep track of what you've learned effectively in

00:02:59.650 --> 00:03:01.810
the environment and what you haven't, so the algorithm can

00:03:01.810 --> 00:03:06.280
actually know what it knows and can use that information

00:03:06.280 --> 00:03:09.470
to explore things that it doesn't know and exploit things

00:03:09.470 --> 00:03:11.820
that it does know. Q learning doesn't really have that

00:03:11.820 --> 00:03:14.510
distinction. It's a much harder thing to do. So, so

00:03:14.510 --> 00:03:16.770
that's what I wanted to tell you in terms of,

00:03:16.770 --> 00:03:19.300
you know, thinking about exploration-exploitation, does that make sense to you?

00:03:19.300 --> 00:03:22.430
&gt;&gt; It does make sense to me. I think what,

00:03:22.430 --> 00:03:24.310
the main point I got out of this, or a main

00:03:24.310 --> 00:03:27.090
point I got out of this, other than our incredible ability

00:03:27.090 --> 00:03:30.680
to get caught up in letters and coincidences of spelling, is

00:03:30.680 --> 00:03:33.410
that the exploration-exploitation dilemma really is

00:03:33.410 --> 00:03:34.860
a dilemma. It's like the fundamental

00:03:34.860 --> 00:03:38.510
tradeoff in reinforcement learning. You have to exploit because you have

00:03:38.510 --> 00:03:41.230
to use what you've got, but you have to learn or

00:03:41.230 --> 00:03:44.800
otherwise you might not be able to exploit profitably. So you

00:03:44.800 --> 00:03:47.760
have to always trade off between these things, and if you don't,

00:03:47.760 --> 00:03:52.095
you're bound to either learn nothing or to get caught in local minima.

00:03:52.095 --> 00:03:55.140
&gt;&gt; I couldn't agree with you more. In some sense, if you

00:03:55.140 --> 00:03:56.750
think of reinforcement learning as being

00:03:56.750 --> 00:03:59.810
the question of model learning plus planning.

00:03:59.810 --> 00:04:03.480
There's nothing new here because model learning is well studied in the machine

00:04:03.480 --> 00:04:05.520
learning community and planning is well

00:04:05.520 --> 00:04:08.600
studied in the planning and scheduling community.

00:04:08.600 --> 00:04:09.100
&gt;&gt; Planning.

00:04:09.100 --> 00:04:10.890
&gt;&gt; And so, like, what are we adding

00:04:10.890 --> 00:04:12.930
to this? And what we're adding is the fact

00:04:12.930 --> 00:04:15.890
that these two processes interact with each other and depend

00:04:15.890 --> 00:04:19.454
on each other and that's exactly the exploration, exploitation dilemma

00:04:19.454 --> 00:04:22.330
and that's information has to go back and forth between

00:04:22.330 --> 00:04:25.380
these two processes that other people understand and we're the glue.

00:04:26.380 --> 00:04:26.850
&gt;&gt; Or the glee.

00:04:26.850 --> 00:04:30.274
&gt;&gt; [LAUGH] The glee glue.

00:04:30.274 --> 00:04:31.120
&gt;&gt; I like it. That's beautiful.

