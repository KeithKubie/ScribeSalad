WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:03.480
FABIAN HERRMANN: A few
weeks ago, we met Ahmadi.

00:00:03.480 --> 00:00:09.660
He's 11, and a soft-spoken kid
who loves video games, YouTube,

00:00:09.660 --> 00:00:10.660
and basketball.

00:00:10.660 --> 00:00:13.530
And we met Ahmadi while
doing some research

00:00:13.530 --> 00:00:15.670
on emerging technologies.

00:00:15.670 --> 00:00:18.720
So we sat down with Ahmadi
and a couple of his friends

00:00:18.720 --> 00:00:20.370
in Ahmadi's dining room.

00:00:20.370 --> 00:00:23.130
And I basically just asked
him about the future--

00:00:23.130 --> 00:00:26.550
where he'd like to go
and what he'd like to do.

00:00:26.550 --> 00:00:28.860
Here's what he said.

00:00:28.860 --> 00:00:32.549
AHMADI: I will go to Mars on
a flying gold Lamborghini.

00:00:32.549 --> 00:00:34.610
And if I had magic
glasses, I would

00:00:34.610 --> 00:00:39.944
wish for them to bring me my dog
and teleport an ice cream shop.

00:00:43.820 --> 00:00:45.660
FRANZ BLACH: We've
all been there.

00:00:45.660 --> 00:00:48.560
We've all dreamt
about the future.

00:00:48.560 --> 00:00:50.960
I certainly remember
being Ahmadi's age

00:00:50.960 --> 00:00:54.500
and dreaming about flying
cars and robots that

00:00:54.500 --> 00:00:57.440
catered to my every
need, dreaming

00:00:57.440 --> 00:01:02.430
about where new technology would
go and where it would take me.

00:01:02.430 --> 00:01:06.650
And when you dream of the
future, what do you see?

00:01:06.650 --> 00:01:10.820
Do you dream about concurrent
odometry and horizontal plane

00:01:10.820 --> 00:01:12.660
detection?

00:01:12.660 --> 00:01:15.870
Do you fantasize about hot
words and utterance capture?

00:01:18.640 --> 00:01:21.130
Maybe in this group
here today at Playtime,

00:01:21.130 --> 00:01:26.490
perhaps, but at the world
at large, probably not.

00:01:26.490 --> 00:01:32.850
More likely, we dream
about the places we can go,

00:01:32.850 --> 00:01:38.240
the things we can do,
and the people we can be.

00:01:38.240 --> 00:01:39.420
I'm Franz.

00:01:39.420 --> 00:01:41.640
This is Fabian, and
we are from IDEO.

00:01:41.640 --> 00:01:44.640
FABIAN HERRMANN: IDEO is a
global design and innovation

00:01:44.640 --> 00:01:45.870
firm.

00:01:45.870 --> 00:01:47.970
And IDEO pioneered
human-centered design,

00:01:47.970 --> 00:01:51.780
which is a philosophy and
approach towards design which

00:01:51.780 --> 00:01:55.480
always starts with
people's desires.

00:01:55.480 --> 00:01:58.060
And it's really
the only way for us

00:01:58.060 --> 00:02:02.660
how we get inspired about
future products and services.

00:02:02.660 --> 00:02:06.430
And we're here today to talk
about how, in our experience,

00:02:06.430 --> 00:02:10.419
technology is always the
most valuable when it helps

00:02:10.419 --> 00:02:14.140
us actually realize our dreams.

00:02:14.140 --> 00:02:16.360
And we really want
to shift the thinking

00:02:16.360 --> 00:02:19.360
from what technology is
capable of to what it

00:02:19.360 --> 00:02:23.500
enables us, as humans, to do.

00:02:23.500 --> 00:02:26.050
And these four
emerging technologies

00:02:26.050 --> 00:02:28.560
are on everybody's lips today.

00:02:28.560 --> 00:02:35.370
It's like VR, AR,
digital assistants,

00:02:35.370 --> 00:02:37.156
and of course, as well, apps.

00:02:37.156 --> 00:02:39.780
And if we talk about apps, we're
talking about that kind of app

00:02:39.780 --> 00:02:42.740
that you don't have to
download and install.

00:02:42.740 --> 00:02:46.080
We will call them
ephemeral apps.

00:02:46.080 --> 00:02:47.580
FRANZ BLACH: Now,
these technologies

00:02:47.580 --> 00:02:51.520
are becoming increasingly
important computing platforms.

00:02:51.520 --> 00:02:55.350
And none of us want to miss
out on the opportunities

00:02:55.350 --> 00:02:57.690
they represent.

00:02:57.690 --> 00:02:59.700
And some of you may
already be working

00:02:59.700 --> 00:03:01.680
with these technologies,
and some of you

00:03:01.680 --> 00:03:04.540
may be considering
working with them.

00:03:04.540 --> 00:03:07.650
And you may be
thinking to yourself,

00:03:07.650 --> 00:03:12.375
I'd like to get involved,
but I don't know how.

00:03:12.375 --> 00:03:17.230
And if I jump in and get
involved, what should I build?

00:03:17.230 --> 00:03:20.820
What should I make with
these technologies?

00:03:20.820 --> 00:03:24.340
And I'm sure you're
all asking yourself,

00:03:24.340 --> 00:03:27.270
how does any of this
fit into my business

00:03:27.270 --> 00:03:30.600
and how am I going
to make money?

00:03:30.600 --> 00:03:32.580
FABIAN HERRMANN: So today
here at Playtime, we

00:03:32.580 --> 00:03:34.560
heard a lot about
the capabilities

00:03:34.560 --> 00:03:37.077
of those technologies,
about the features,

00:03:37.077 --> 00:03:38.160
and how to implement them.

00:03:38.160 --> 00:03:41.410
So we are not going to
talk about any of that.

00:03:41.410 --> 00:03:44.640
What we are going to
talk about is actually

00:03:44.640 --> 00:03:48.490
what are these technologies good
for from a human perspective,

00:03:48.490 --> 00:03:52.170
how do they fit
into your business,

00:03:52.170 --> 00:03:55.690
and how you can get started,
and of course, most importantly,

00:03:55.690 --> 00:03:58.410
how can we all learn
something from Ahmadi

00:03:58.410 --> 00:04:01.320
and his golden
flying Lamborghini?

00:04:01.320 --> 00:04:03.840
FRANZ BLACH: Now, earlier
this year, Google Play

00:04:03.840 --> 00:04:07.500
approached us, and they posed
a pretty great question.

00:04:07.500 --> 00:04:12.450
They asked us, what are these
technologies really good for?

00:04:12.450 --> 00:04:15.430
Now, we're really
excited by them,

00:04:15.430 --> 00:04:17.470
and we know they have
a ton of potential.

00:04:17.470 --> 00:04:20.320
But what do people actually
want to do with them,

00:04:20.320 --> 00:04:22.820
and how can we help our
developer partners--

00:04:22.820 --> 00:04:24.740
and that's all of
you here today--

00:04:24.740 --> 00:04:28.405
how can we help them make the
most of these technologies?

00:04:28.405 --> 00:04:30.280
FABIAN HERRMANN: And to
answer that question,

00:04:30.280 --> 00:04:31.450
we did what we always do.

00:04:31.450 --> 00:04:33.872
We went out and
talked to people.

00:04:33.872 --> 00:04:35.830
First, we talked to the
people on the forefront

00:04:35.830 --> 00:04:39.017
of those technologies--
researchers, developers,

00:04:39.017 --> 00:04:40.600
some of you guys
here in the audience.

00:04:40.600 --> 00:04:43.000
Because we really wanted
to understand what

00:04:43.000 --> 00:04:44.890
the people that are
developing and creating

00:04:44.890 --> 00:04:47.241
with those technologies
have been actually thinking

00:04:47.241 --> 00:04:47.740
about them.

00:04:50.526 --> 00:04:52.150
FRANZ BLACH: And then
we went and spoke

00:04:52.150 --> 00:04:56.110
to both users and non-users
of these technologies,

00:04:56.110 --> 00:04:59.320
because we wanted to learn
how people imagine these four

00:04:59.320 --> 00:05:02.110
things fitting into their
everyday lives, what

00:05:02.110 --> 00:05:05.890
their hopes and dreams are when
it comes to these technologies.

00:05:05.890 --> 00:05:08.170
And to do this,
we hosted a number

00:05:08.170 --> 00:05:12.954
of group research sessions at
our offices in San Francisco.

00:05:12.954 --> 00:05:14.620
The same themes kept
coming up, so we're

00:05:14.620 --> 00:05:18.310
going to give you a peek
into one of these sessions.

00:05:18.310 --> 00:05:20.410
FABIAN HERRMANN: And for
this particular session,

00:05:20.410 --> 00:05:21.880
we invited five people--

00:05:21.880 --> 00:05:25.600
among them a self-identified
early adopter, a gamer,

00:05:25.600 --> 00:05:27.445
and even a complete techophobe.

00:05:27.445 --> 00:05:30.280
So just to let you know, if
we do these kind of sessions,

00:05:30.280 --> 00:05:33.020
we like to recruit for
the extreme of behaviors

00:05:33.020 --> 00:05:36.220
so that we really span the
full spectrum of experiences

00:05:36.220 --> 00:05:38.950
with any given subject.

00:05:38.950 --> 00:05:41.560
And it's really
important for us that we

00:05:41.560 --> 00:05:44.200
have strong, inspiring
opinions and perspectives

00:05:44.200 --> 00:05:45.730
to push our thinking.

00:05:45.730 --> 00:05:49.300
And as you can see, it's a very
casual, in-person conversation

00:05:49.300 --> 00:05:53.350
over beer, so no one-way mirrors
or fancy tracking technology.

00:05:53.350 --> 00:05:56.920
Because again, the intention was
not to be comprehensive here.

00:05:56.920 --> 00:05:59.080
The intention was
to really understand

00:05:59.080 --> 00:06:03.360
what people are feeling and
what they want, what they do,

00:06:03.360 --> 00:06:04.517
and why.

00:06:04.517 --> 00:06:06.100
FRANZ BLACH: And we
didn't want to get

00:06:06.100 --> 00:06:10.180
distracted by some of the
existing platforms or brands

00:06:10.180 --> 00:06:10.940
or products.

00:06:10.940 --> 00:06:13.960
And so in order to do
that, we created a number

00:06:13.960 --> 00:06:17.890
of design exercises that
abstracted each technology

00:06:17.890 --> 00:06:23.770
into something that people could
hold, draw on, and use to start

00:06:23.770 --> 00:06:25.990
imagining the potential.

00:06:25.990 --> 00:06:28.180
Because we found that
if you give something

00:06:28.180 --> 00:06:32.530
to people that's too polished,
they'll look for the flaws.

00:06:32.530 --> 00:06:35.260
But if you give them
something that's pretty rough,

00:06:35.260 --> 00:06:38.470
they can begin to
see the potential.

00:06:41.050 --> 00:06:43.620
So let's take a look
at what we did for VR,

00:06:43.620 --> 00:06:45.720
the exercise we did for VR.

00:06:45.720 --> 00:06:48.750
So to dig into
people's dreams for VR,

00:06:48.750 --> 00:06:52.620
we handed out different scenes
that ranged from the mundane,

00:06:52.620 --> 00:06:55.770
like commuting on the subway,
to the more fantastical,

00:06:55.770 --> 00:06:59.640
like visiting Mars or
flying over a city.

00:06:59.640 --> 00:07:01.470
And we told people
to imagine that they

00:07:01.470 --> 00:07:03.510
were transported to this place.

00:07:03.510 --> 00:07:06.840
And then we asked them, how
do you think you got there?

00:07:06.840 --> 00:07:08.250
What would you do there?

00:07:08.250 --> 00:07:10.530
Who or what would you
want to bring along?

00:07:10.530 --> 00:07:13.965
Who would you want
to communicate with?

00:07:13.965 --> 00:07:16.090
FABIAN HERRMANN: And we
also chatted with our group

00:07:16.090 --> 00:07:17.350
about AR.

00:07:17.350 --> 00:07:21.010
And to access their hopes
for the future of AR,

00:07:21.010 --> 00:07:22.450
we did another simple exercise.

00:07:22.450 --> 00:07:24.580
We just handed out
this piece of acrylic

00:07:24.580 --> 00:07:26.050
to lay over their
scenes and asked

00:07:26.050 --> 00:07:28.570
them to draw what
they imagined seeing

00:07:28.570 --> 00:07:30.280
through those magic glasses.

00:07:30.280 --> 00:07:32.541
That's how we called them.

00:07:32.541 --> 00:07:33.790
Here's what they came up with.

00:07:33.790 --> 00:07:37.120
And when we play this
video about AR and VR,

00:07:37.120 --> 00:07:40.530
please pay close attention
to what are their wishes.

00:07:40.530 --> 00:07:43.720
Listen to what they're saying,
but also what are their desires

00:07:43.720 --> 00:07:46.704
and wishes implicit
in their words.

00:07:46.704 --> 00:07:47.370
[VIDEO PLAYBACK]

00:07:47.370 --> 00:07:49.590
- I'm underwater scuba diving.

00:07:49.590 --> 00:07:51.390
- I am in downtown Tokyo.

00:07:51.390 --> 00:07:53.280
- I am on the New York subway.

00:07:53.280 --> 00:07:56.430
- I'm currently skydiving
over San Francisco.

00:07:56.430 --> 00:07:59.100
- I was in a meeting,
and I was really bored,

00:07:59.100 --> 00:08:00.420
so I decided to come to Mars.

00:08:00.420 --> 00:08:04.230
- I'm probably with
my seven-year-old.

00:08:04.230 --> 00:08:06.930
- This guy looks like he
could be a famous rock star,

00:08:06.930 --> 00:08:10.440
and it would be really cool if
I could validate that somehow.

00:08:10.440 --> 00:08:13.650
- My magic glasses allow
me to share this experience

00:08:13.650 --> 00:08:15.510
with my followers in real time.

00:08:15.510 --> 00:08:17.160
Over here, we have
the donations that

00:08:17.160 --> 00:08:19.890
are coming in live as my
viewers like what I'm doing.

00:08:19.890 --> 00:08:21.840
- So here you see
a notification.

00:08:21.840 --> 00:08:24.240
Lena wants to join
me on my quest

00:08:24.240 --> 00:08:25.740
to find the Mars treasure.

00:08:25.740 --> 00:08:27.790
- My magic glasses
have two modes.

00:08:27.790 --> 00:08:31.830
One is all about me, and
one is all about them.

00:08:31.830 --> 00:08:33.960
As for the me mode,
it would show me

00:08:33.960 --> 00:08:36.030
recommendations and news feed.

00:08:36.030 --> 00:08:39.330
And then for them, I would
be able to understand

00:08:39.330 --> 00:08:42.502
how my fellow commuters are
doing, what they're thinking,

00:08:42.502 --> 00:08:44.460
what they're feeling,
and what they might need.

00:08:44.460 --> 00:08:46.890
- Here in the
corner, you can see

00:08:46.890 --> 00:08:51.060
that I have a countdown
to when my pizza arrives

00:08:51.060 --> 00:08:52.260
in the real world.

00:08:52.260 --> 00:08:54.690
- And in fact, I
would want the ability

00:08:54.690 --> 00:08:59.010
to almost dismiss all of
it and like better immerse

00:08:59.010 --> 00:09:00.720
myself in the environment.

00:09:00.720 --> 00:09:02.980
[END PLAYBACK]

00:09:02.980 --> 00:09:05.920
FRANZ BLACH: So Nicky wanted to
bring her kids along with her

00:09:05.920 --> 00:09:08.980
to Tokyo, and Angela
wanted to find out

00:09:08.980 --> 00:09:13.120
about that potential
rock star in the subway.

00:09:13.120 --> 00:09:16.630
And when we hear
Susanna say that she

00:09:16.630 --> 00:09:19.030
was in a boring
meeting and escaped

00:09:19.030 --> 00:09:22.720
to Mars to find hidden
treasure with her friend Lena,

00:09:22.720 --> 00:09:23.950
we listen to that story.

00:09:23.950 --> 00:09:28.120
We don't tend to fixate on
whether her VR headset is going

00:09:28.120 --> 00:09:30.040
to make her nauseous
or how she's

00:09:30.040 --> 00:09:33.370
going to be able to pick up
Martian rocks using motion

00:09:33.370 --> 00:09:34.420
controllers.

00:09:34.420 --> 00:09:35.350
FABIAN HERRMANN: And
don't get us wrong.

00:09:35.350 --> 00:09:37.450
Sure, we know that all
those technical constraints

00:09:37.450 --> 00:09:38.033
are important.

00:09:38.033 --> 00:09:39.920
But what people
are actually saying

00:09:39.920 --> 00:09:42.940
is that they want to escape
to an exciting place,

00:09:42.940 --> 00:09:45.640
they want to explore this
place on their own terms,

00:09:45.640 --> 00:09:48.910
and they want to share their
experiences with friends.

00:09:48.910 --> 00:09:52.330
So at its core, for
us, the promise of VR

00:09:52.330 --> 00:09:57.340
is the ability to take
us to amazing new places

00:09:57.340 --> 00:10:01.674
with new abilities that are
only limited by our imagination.

00:10:01.674 --> 00:10:03.590
FRANZ BLACH: Now, we
heard from another person

00:10:03.590 --> 00:10:07.220
that they were playing "Pokemon
Go" during their commute.

00:10:07.220 --> 00:10:09.920
And in doing so,
they began to notice

00:10:09.920 --> 00:10:12.050
all these wonderful
architectural details

00:10:12.050 --> 00:10:15.510
in the New York subway
that they'd missed before.

00:10:15.510 --> 00:10:18.830
If you think about that
story in the context of AR,

00:10:18.830 --> 00:10:21.710
and if you go beyond the
surface, what people want

00:10:21.710 --> 00:10:26.780
from AR is to learn about their
surroundings and the people

00:10:26.780 --> 00:10:28.080
within them.

00:10:28.080 --> 00:10:32.360
So in other words, the
overarching promise of AR

00:10:32.360 --> 00:10:36.050
is that it gives us the
ability to reveal and interact

00:10:36.050 --> 00:10:39.020
with hidden layers
of information right

00:10:39.020 --> 00:10:41.127
within our physical
surroundings.

00:10:41.127 --> 00:10:41.960
FABIAN HERRMANN: OK.

00:10:41.960 --> 00:10:44.510
Now let's look at
digital assistants.

00:10:44.510 --> 00:10:47.910
And to uncover thoughts
on digital assistants,

00:10:47.910 --> 00:10:49.520
we did another very
simple exercise.

00:10:49.520 --> 00:10:53.930
We just asked the group
to basically write

00:10:53.930 --> 00:10:56.480
a job description for
a real life assistant.

00:10:56.480 --> 00:10:59.520
And we asked them, if you
would have this assistant, what

00:10:59.520 --> 00:11:01.070
would you ask them to do?

00:11:01.070 --> 00:11:03.140
Which kind of skills
do they need to have?

00:11:03.140 --> 00:11:05.890
I think most importantly,
which kind of relationship

00:11:05.890 --> 00:11:07.850
do you want to have
with this assistant?

00:11:07.850 --> 00:11:08.874
Here's what they said.

00:11:08.874 --> 00:11:09.540
[VIDEO PLAYBACK]

00:11:09.540 --> 00:11:12.560
- I'm looking for somebody who's
very organized, a self-starter,

00:11:12.560 --> 00:11:14.580
able to predict my needs.

00:11:14.580 --> 00:11:17.420
- Be able to keep
my kids entertained

00:11:17.420 --> 00:11:18.980
without screen time.

00:11:18.980 --> 00:11:23.130
- I would say think Tony
Stark and Pepper and Iron Man.

00:11:23.130 --> 00:11:25.160
She knows what he needs
before he needs it.

00:11:25.160 --> 00:11:27.170
- And I would definitely
look for a willingness

00:11:27.170 --> 00:11:32.610
to challenge my ideas and
propose new or novel solutions.

00:11:32.610 --> 00:11:35.180
- Keep me on track
and honest with a lot

00:11:35.180 --> 00:11:36.830
of my personal goals.

00:11:36.830 --> 00:11:39.950
- If they could show me a
funny animal video every day,

00:11:39.950 --> 00:11:41.090
I would be very happy.

00:11:41.090 --> 00:11:44.525
- The unusual trait is that
this person never, ever sleeps.

00:11:47.100 --> 00:11:48.859
[END PLAYBACK]

00:11:48.859 --> 00:11:50.650
FRANZ BLACH: So people
wanted the assistant

00:11:50.650 --> 00:11:55.240
to go far beyond just simple
task automation or delegation.

00:11:55.240 --> 00:11:58.780
They wanted their assistant to
inspire them, to motivate them,

00:11:58.780 --> 00:12:02.680
to keep them honest,
and to make them laugh.

00:12:02.680 --> 00:12:05.830
In other words, what they
wanted their assistant to be

00:12:05.830 --> 00:12:08.050
is to be very personable.

00:12:08.050 --> 00:12:12.340
And they wanted to interact
with them in very human terms

00:12:12.340 --> 00:12:14.585
through natural conversation.

00:12:14.585 --> 00:12:16.960
FABIAN HERRMANN: So if we
think about digital assistants,

00:12:16.960 --> 00:12:19.510
we really need to think
about their potential, which

00:12:19.510 --> 00:12:24.850
is that they can support us
in very empathic and very

00:12:24.850 --> 00:12:26.290
intuitive ways.

00:12:26.290 --> 00:12:30.970
So they can respond to
our mood, to our context,

00:12:30.970 --> 00:12:33.530
and sometimes even
challenge and surprise us.

00:12:33.530 --> 00:12:35.560
So the promise of
digital assistants

00:12:35.560 --> 00:12:39.250
is to be able to control
information in a very intuitive

00:12:39.250 --> 00:12:41.145
way through conversations.

00:12:41.145 --> 00:12:42.520
And we're very
excited about what

00:12:42.520 --> 00:12:44.620
that could mean for
conversational interfaces,

00:12:44.620 --> 00:12:47.640
and especially for the
expression of personality

00:12:47.640 --> 00:12:49.960
for this technology.

00:12:49.960 --> 00:12:52.660
FRANZ BLACH: Now, finally,
we're going to talk about apps,

00:12:52.660 --> 00:12:56.410
a subject you're all
very familiar with.

00:12:56.410 --> 00:12:58.630
Now, the introduction
of ephemeral apps

00:12:58.630 --> 00:13:02.380
prompted us to revisit
how people approach

00:13:02.380 --> 00:13:06.160
apps in the context of
what they want to do,

00:13:06.160 --> 00:13:08.140
not just how they want to do it.

00:13:10.900 --> 00:13:14.520
FABIAN HERRMANN: So we
basically presented people

00:13:14.520 --> 00:13:15.790
with two scenarios.

00:13:15.790 --> 00:13:19.990
One was a new cafe opened
near your workplace,

00:13:19.990 --> 00:13:21.670
and you want to order
something there.

00:13:21.670 --> 00:13:24.330
And the second one is you
have to park a car in a city

00:13:24.330 --> 00:13:26.010
that you haven't visited before.

00:13:26.010 --> 00:13:27.620
And again, we just
asked them how

00:13:27.620 --> 00:13:29.370
they would do this in
an ideal world, what

00:13:29.370 --> 00:13:32.161
are the challenges coming up,
and how they would go about it.

00:13:32.161 --> 00:13:33.660
Let's take a look
at what they said.

00:13:33.660 --> 00:13:34.326
[VIDEO PLAYBACK]

00:13:34.326 --> 00:13:36.960
- I would like to pull up
some sort of interface that

00:13:36.960 --> 00:13:41.660
will just magically show up and
have a level of social proof

00:13:41.660 --> 00:13:44.580
or validation that this
cafe is actually good.

00:13:44.580 --> 00:13:48.180
- If I had a coffee around
a specific time of day,

00:13:48.180 --> 00:13:51.150
it should just ask me, do you
want me to order your coffee?

00:13:51.150 --> 00:13:55.620
- I would like to at least do it
with minimal human interaction

00:13:55.620 --> 00:13:58.110
and with as few
steps as possible,

00:13:58.110 --> 00:14:00.861
so things like payment
information is already saved.

00:14:00.861 --> 00:14:02.610
- What would be nice
is some sort of alert

00:14:02.610 --> 00:14:04.192
or my assistant
telling me, hey, you

00:14:04.192 --> 00:14:06.150
know what, it's 10 minutes
past the time you're

00:14:06.150 --> 00:14:07.290
allowed to park here.

00:14:07.290 --> 00:14:08.360
Don't park here.

00:14:08.360 --> 00:14:10.500
There's another spot
10 minutes away.

00:14:10.500 --> 00:14:14.100
- It will just automatically
detect when my car has parked

00:14:14.100 --> 00:14:15.510
and then when I've
actually left.

00:14:15.510 --> 00:14:17.190
- I think what I
would want to do

00:14:17.190 --> 00:14:21.210
is I want to pull up and
have my car let me out,

00:14:21.210 --> 00:14:24.134
and then it would drive off.

00:14:24.134 --> 00:14:25.610
[END PLAYBACK]

00:14:25.610 --> 00:14:27.472
FRANZ BLACH: Don't make me park.

00:14:27.472 --> 00:14:31.730
And behind the future that he
imagines, really, is a request.

00:14:31.730 --> 00:14:34.100
And the request
is that he doesn't

00:14:34.100 --> 00:14:36.770
want to deal with the
task of parking his car.

00:14:36.770 --> 00:14:39.500
He just wants to
get on with his day.

00:14:39.500 --> 00:14:44.030
And you heard another person
say that he wanted to order food

00:14:44.030 --> 00:14:48.350
from the new cafe with
minimal human interaction

00:14:48.350 --> 00:14:51.470
and with as few
steps as possible.

00:14:51.470 --> 00:14:57.170
What he's really saying is just
make it easy and simple for me.

00:14:57.170 --> 00:15:00.050
FABIAN HERRMANN: So if we talk
about ephemeral apps, or about

00:15:00.050 --> 00:15:02.360
all apps, for that
matter, people

00:15:02.360 --> 00:15:05.870
aren't really that interested
in which platform or service

00:15:05.870 --> 00:15:07.310
they're interacting with.

00:15:07.310 --> 00:15:11.930
They just want to do what
they do when they need to.

00:15:11.930 --> 00:15:14.780
And it should be as
simple, delightful,

00:15:14.780 --> 00:15:16.670
and intuitive as possible.

00:15:16.670 --> 00:15:21.970
And to be fair, that has been
the promise of apps all along.

00:15:21.970 --> 00:15:24.580
FRANZ BLACH: Now, we had
one more group session.

00:15:24.580 --> 00:15:25.840
This one was with kids.

00:15:25.840 --> 00:15:28.300
You heard from Ahmadi
and his Lamborghini right

00:15:28.300 --> 00:15:30.940
in the beginning.

00:15:30.940 --> 00:15:35.410
We held a session with a
group of kids aged 10 and 11.

00:15:35.410 --> 00:15:39.170
And we spoke to them about
the four same technologies

00:15:39.170 --> 00:15:40.689
and their dreams
for the future when

00:15:40.689 --> 00:15:41.980
it comes to these technologies.

00:15:41.980 --> 00:15:46.270
We did the same for design
research exercises with them

00:15:46.270 --> 00:15:47.680
with one exception.

00:15:47.680 --> 00:15:51.040
Instead of a human assistant,
a personal assistant,

00:15:51.040 --> 00:15:54.370
we asked them to design their
very own personal robot.

00:15:54.370 --> 00:15:57.110
Because, well, hey, why not?

00:15:57.110 --> 00:15:58.660
FABIAN HERRMANN:
And again, we didn't

00:15:58.660 --> 00:16:01.010
look for inspiration
from kids because they're

00:16:01.010 --> 00:16:04.090
going to be the core demographic
of what we're doing here.

00:16:04.090 --> 00:16:06.580
But we asked kids because
they have the ability

00:16:06.580 --> 00:16:10.120
to imagine and dream
unhindered of any constraints

00:16:10.120 --> 00:16:12.850
of technological or
historical baggage.

00:16:12.850 --> 00:16:13.710
And they really did.

00:16:13.710 --> 00:16:15.850
So let's see what they imagined.

00:16:15.850 --> 00:16:16.670
[VIDEO PLAYBACK]

00:16:16.670 --> 00:16:18.200
- This is a [INAUDIBLE].

00:16:18.200 --> 00:16:21.310
It has stretchmarks
on its legs because it

00:16:21.310 --> 00:16:26.270
can be as small as fitting your
pocket and as big as a human.

00:16:26.270 --> 00:16:29.200
It makes gummies for
me in its stomach.

00:16:29.200 --> 00:16:32.950
It rests underneath my
bed, and it's my alarm.

00:16:32.950 --> 00:16:36.940
- I was transported
to Tokyo, Japan.

00:16:36.940 --> 00:16:40.540
And I got here by
taking my private jet.

00:16:40.540 --> 00:16:47.650
I'd like to bring my robot, my
friends, my family, and tons

00:16:47.650 --> 00:16:53.000
of other things, including
a device that I imagined

00:16:53.000 --> 00:16:55.660
that would be a translator
that I would put in my ear,

00:16:55.660 --> 00:16:58.675
and it would translate Japanese.

00:16:58.675 --> 00:17:01.337
[END PLAYBACK]

00:17:01.337 --> 00:17:03.420
FRANZ BLACH: So what does
all of this really mean?

00:17:03.420 --> 00:17:04.650
I know cute kids and all.

00:17:04.650 --> 00:17:10.079
But what did we learn at a
high level from our research?

00:17:10.079 --> 00:17:14.369
Well, if you take a step
back, fundamentally,

00:17:14.369 --> 00:17:17.670
the promise of
all new technology

00:17:17.670 --> 00:17:23.540
has always been to expand
our abilities as humans,

00:17:23.540 --> 00:17:27.510
to enable us to do things that
we weren't able to do before.

00:17:27.510 --> 00:17:31.100
So it's never just been
about what the technology is

00:17:31.100 --> 00:17:33.890
capable of, but more
importantly, it's

00:17:33.890 --> 00:17:36.600
been about what it enables
us to do as people.

00:17:36.600 --> 00:17:40.140
And that's a very
important distinction.

00:17:40.140 --> 00:17:42.620
And these four technologies
we've been speaking about

00:17:42.620 --> 00:17:44.860
give us fantastic new abilities.

00:17:44.860 --> 00:17:48.020
And I think that's why we're
all so excited by them.

00:17:48.020 --> 00:17:51.560
But sometimes when we're
exploring the features

00:17:51.560 --> 00:17:54.470
and specs and capabilities
of these technologies,

00:17:54.470 --> 00:17:57.920
we can lose track of what they
actually, fundamentally mean

00:17:57.920 --> 00:17:58.510
for people.

00:17:58.510 --> 00:18:01.850
And we can get frustrated
by the shortcomings

00:18:01.850 --> 00:18:06.140
of the current incarnation of
these technologies, especially

00:18:06.140 --> 00:18:08.240
when the frameworks
are still new

00:18:08.240 --> 00:18:11.921
and we're all trying to
figure things out together.

00:18:11.921 --> 00:18:13.420
FABIAN HERRMANN:
So here's a summary

00:18:13.420 --> 00:18:16.900
of the four technologies, and
what they enable us to do,

00:18:16.900 --> 00:18:18.770
and what people are
expecting from them.

00:18:18.770 --> 00:18:22.060
So VR should transport
us to different places

00:18:22.060 --> 00:18:23.530
with new abilities.

00:18:23.530 --> 00:18:25.570
Augmented reality
allows us to interact

00:18:25.570 --> 00:18:27.150
with hidden layers
of information

00:18:27.150 --> 00:18:30.010
in our physical surrounding,
while digital assistants let

00:18:30.010 --> 00:18:32.320
us access and control
information and services

00:18:32.320 --> 00:18:34.570
through conversation,
and ephemeral apps

00:18:34.570 --> 00:18:38.560
make it easy for us to do
what we want when we want.

00:18:38.560 --> 00:18:41.350
And again, it's really
important that when

00:18:41.350 --> 00:18:43.600
we develop those
technologies that we

00:18:43.600 --> 00:18:46.300
keep the human story in mind.

00:18:46.300 --> 00:18:50.650
We really need to ask
ourselves if what we are doing

00:18:50.650 --> 00:18:54.190
is in service of the desires
and dreams of the people

00:18:54.190 --> 00:18:56.140
that we're designing for.

00:18:56.140 --> 00:18:59.110
Because if you start
with what people want

00:18:59.110 --> 00:19:01.480
and not what's
technically possible,

00:19:01.480 --> 00:19:03.190
I think you have
an approach that

00:19:03.190 --> 00:19:05.260
increases the likelihood
of really creating

00:19:05.260 --> 00:19:10.860
something meaningful,
desirable, and of lasting value.

00:19:10.860 --> 00:19:15.510
FRANZ BLACH: So right about
now, you may be thinking,

00:19:15.510 --> 00:19:16.061
interesting.

00:19:16.061 --> 00:19:16.560
Cool.

00:19:16.560 --> 00:19:17.320
That's great.

00:19:17.320 --> 00:19:19.690
But how do I apply
this to my business?

00:19:19.690 --> 00:19:23.010
How do I apply this
to my particular case

00:19:23.010 --> 00:19:25.170
and my customer?

00:19:25.170 --> 00:19:28.410
Well, we've got
something for you.

00:19:28.410 --> 00:19:31.170
If you reach
underneath your seats,

00:19:31.170 --> 00:19:33.000
you'll find a deck
of cards glued

00:19:33.000 --> 00:19:34.950
to the bottom of your chairs.

00:19:34.950 --> 00:19:38.450
For the people on
the wooden chairs,

00:19:38.450 --> 00:19:39.540
they're glued to the legs.

00:19:43.397 --> 00:19:43.980
Pop, pop, pop.

00:19:43.980 --> 00:19:44.910
It's like popcorn.

00:19:48.686 --> 00:19:50.540
All right.

00:19:50.540 --> 00:19:55.640
Open the deck of cards up, and
we'll go through them together,

00:19:55.640 --> 00:19:57.890
and we'll explain them to you.

00:19:57.890 --> 00:20:01.520
So we've called
this deck of cards

00:20:01.520 --> 00:20:05.360
human-centered design prompts
for emerging technologies.

00:20:05.360 --> 00:20:09.920
And the deck contains 20 prompts
spanning the four technologies

00:20:09.920 --> 00:20:11.780
we've been talking about.

00:20:11.780 --> 00:20:13.490
And they're there
to help you think

00:20:13.490 --> 00:20:16.520
of potential products
in the context

00:20:16.520 --> 00:20:19.650
of your own particular
customers' needs.

00:20:19.650 --> 00:20:24.080
They're based on our research,
on what we heard people want.

00:20:24.080 --> 00:20:28.460
And they're intended to provide
guidance at that early ideation

00:20:28.460 --> 00:20:31.370
stage when you're trying to
figure out what to build,

00:20:31.370 --> 00:20:33.480
as Ross talked about earlier.

00:20:33.480 --> 00:20:35.570
FABIAN HERRMANN: So here's
how these cards work.

00:20:35.570 --> 00:20:37.310
You remember
Garrett, who earlier

00:20:37.310 --> 00:20:40.250
talked about his magic glasses?

00:20:40.250 --> 00:20:42.470
What he really
wanted is the ability

00:20:42.470 --> 00:20:46.040
to dismiss everything
and immerse himself

00:20:46.040 --> 00:20:47.360
in the environment.

00:20:47.360 --> 00:20:50.450
So he's basically
asking for a Mute button

00:20:50.450 --> 00:20:53.810
to avoid any distraction.

00:20:53.810 --> 00:20:57.890
And that made us think
AR might have the ability

00:20:57.890 --> 00:20:59.166
to help people focus.

00:20:59.166 --> 00:21:01.040
And that's not typically
what we think about.

00:21:01.040 --> 00:21:02.498
When we think about
AR, it's always

00:21:02.498 --> 00:21:05.300
about adding stuff,
about augmenting reality.

00:21:05.300 --> 00:21:08.920
But what if we use it to remove
things and to enhance focus?

00:21:08.920 --> 00:21:13.190
So is there an opportunity to
help prioritize information

00:21:13.190 --> 00:21:16.720
in our environment through AR?

00:21:16.720 --> 00:21:18.810
FRANZ BLACH: So say you
picked up this card,

00:21:18.810 --> 00:21:22.250
and it says, think of a
moment in your user's day

00:21:22.250 --> 00:21:25.620
when they're overwhelmed
or distracted.

00:21:25.620 --> 00:21:29.714
Now consider your particular
user, their day-to-day life.

00:21:29.714 --> 00:21:31.380
And could that be a
certain time of day?

00:21:31.380 --> 00:21:34.386
Or maybe it's a certain type
of situation they're in.

00:21:34.386 --> 00:21:36.010
You picture that
scenario in your mind,

00:21:36.010 --> 00:21:39.060
and then you flip the
card over to the design

00:21:39.060 --> 00:21:41.250
prompt, which
reads, how might we

00:21:41.250 --> 00:21:44.790
use AR to remove distractions?

00:21:44.790 --> 00:21:48.040
So we'll give you an example
so you know how this works.

00:21:48.040 --> 00:21:51.540
So say you're a
physical retailer,

00:21:51.540 --> 00:21:54.420
and when a customer
walks into your store,

00:21:54.420 --> 00:21:57.450
they're faced with hundreds,
possibly even thousands

00:21:57.450 --> 00:21:58.860
of different products.

00:21:58.860 --> 00:22:01.470
And at times, your
user may be browsing,

00:22:01.470 --> 00:22:03.750
and they may just be
roaming the store.

00:22:03.750 --> 00:22:05.610
But at other times,
they may actually

00:22:05.610 --> 00:22:07.410
know exactly what they want.

00:22:07.410 --> 00:22:10.380
And in those cases,
entering a store

00:22:10.380 --> 00:22:15.010
may be a very overwhelming
and distracting experience.

00:22:15.010 --> 00:22:19.890
So you could consider creating
AN ar application that helps

00:22:19.890 --> 00:22:25.320
your customer find exactly what
they want by simply removing

00:22:25.320 --> 00:22:27.090
what they don't.

00:22:27.090 --> 00:22:28.710
Now, that's just an example.

00:22:28.710 --> 00:22:30.900
There's a clear product
opportunity there.

00:22:30.900 --> 00:22:34.370
But you can see how there's
a very human desire--

00:22:34.370 --> 00:22:36.690
in this case, the
need to focus--

00:22:36.690 --> 00:22:40.019
that can be met using AR.

00:22:40.019 --> 00:22:41.810
FABIAN HERRMANN: And
what we are doing here

00:22:41.810 --> 00:22:45.200
is, basically, we're finding
a design opportunity which

00:22:45.200 --> 00:22:49.730
leads with a human scenario
and a need and desire.

00:22:49.730 --> 00:22:52.580
So we didn't choose
the technology first.

00:22:52.580 --> 00:22:55.970
We didn't say which kind of
AR application can we build?

00:22:55.970 --> 00:23:00.350
We basically asked, how
can we help people focus?

00:23:00.350 --> 00:23:03.950
And AR might be one
technology that does that.

00:23:03.950 --> 00:23:06.630
FRANZ BLACH: And in doing this
exercise, in using these cards,

00:23:06.630 --> 00:23:10.040
you may also find
that, actually, some

00:23:10.040 --> 00:23:12.470
of these technologies
don't lend themselves

00:23:12.470 --> 00:23:14.600
to your business
and your customer,

00:23:14.600 --> 00:23:16.400
and that maybe they're
not worth pursuing.

00:23:16.400 --> 00:23:18.080
And that's fine, too.

00:23:18.080 --> 00:23:20.780
At least by doing
it this way, you

00:23:20.780 --> 00:23:23.000
didn't commit months
of resources to it

00:23:23.000 --> 00:23:25.030
before finding out the hard--

00:23:25.030 --> 00:23:26.577
and, well, frankly
expensive-- way.

00:23:26.577 --> 00:23:27.410
FABIAN HERRMANN: OK.

00:23:27.410 --> 00:23:29.810
Let's look at another one--

00:23:29.810 --> 00:23:32.840
something Susan said about
her personal assistant.

00:23:32.840 --> 00:23:36.340
She said she wants
it to make her laugh

00:23:36.340 --> 00:23:37.910
and make sarcastic remarks.

00:23:37.910 --> 00:23:39.770
So that made us think.

00:23:39.770 --> 00:23:41.540
If those digital
assistants should

00:23:41.540 --> 00:23:44.900
have really human,
meaningful conversations,

00:23:44.900 --> 00:23:48.800
they really need to understand
the mood of the person they're

00:23:48.800 --> 00:23:50.650
talking to.

00:23:50.650 --> 00:23:53.530
FRANZ BLACH: Or
as Rupert put it,

00:23:53.530 --> 00:23:56.650
sometimes I want to have
a discussion with it.

00:23:56.650 --> 00:23:59.470
Sometimes I want it to
give me some attitude.

00:23:59.470 --> 00:24:04.210
And sometimes, I just want it
to turn off the damn lights.

00:24:04.210 --> 00:24:07.630
So here's the
corresponding card.

00:24:07.630 --> 00:24:10.000
Think of a moment
in your user's day

00:24:10.000 --> 00:24:11.955
when their mood might change.

00:24:11.955 --> 00:24:12.580
So consider it.

00:24:12.580 --> 00:24:15.520
Is it when they're transitioning
between different behaviors?

00:24:15.520 --> 00:24:18.640
Or perhaps they're moving
between different places,

00:24:18.640 --> 00:24:20.740
or it's dependent
on who they're with.

00:24:20.740 --> 00:24:22.090
You picture the scenario.

00:24:22.090 --> 00:24:25.540
You flip the card over
to the design prompt.

00:24:25.540 --> 00:24:30.160
How might we adapt the digital
assistant's tone and behavior

00:24:30.160 --> 00:24:31.870
to the user's mood?

00:24:31.870 --> 00:24:33.130
FABIAN HERRMANN: So let's see.

00:24:33.130 --> 00:24:36.460
You're a company that
basically delivers personalized

00:24:36.460 --> 00:24:37.840
news via the assistant.

00:24:37.840 --> 00:24:40.360
So you can imagine
that somebody getting

00:24:40.360 --> 00:24:42.960
ready for work in the
morning during a weekday

00:24:42.960 --> 00:24:45.466
wants very different
information and has it

00:24:45.466 --> 00:24:46.840
delivered in a
very different way

00:24:46.840 --> 00:24:49.390
than, let's say, on
a Sunday afternoon.

00:24:49.390 --> 00:24:52.480
And I think it might
be that they want

00:24:52.480 --> 00:24:54.160
more inspirational stories.

00:24:54.160 --> 00:24:55.840
They want to have
more of a conversation

00:24:55.840 --> 00:24:57.270
with their assistant.

00:24:57.270 --> 00:25:00.490
And then the question is, how
does the assistant actually

00:25:00.490 --> 00:25:01.960
participate in
this conversation?

00:25:01.960 --> 00:25:04.540
And the opportunity
is quite literal.

00:25:04.540 --> 00:25:07.820
You can give your brand
a voice and personality.

00:25:07.820 --> 00:25:10.330
And considering that
your user's mood changes

00:25:10.330 --> 00:25:12.880
throughout the day, throughout
the week, throughout the year,

00:25:12.880 --> 00:25:15.010
your brand should adapt to that.

00:25:15.010 --> 00:25:17.140
And that's, for us,
the only way you

00:25:17.140 --> 00:25:21.160
can have a human, meaningful
conversation and also

00:25:21.160 --> 00:25:25.280
a long-lasting
relationship with people.

00:25:25.280 --> 00:25:28.300
FRANZ BLACH: So those
are just two examples

00:25:28.300 --> 00:25:32.560
of the set of 20 cards
you have in your hands.

00:25:32.560 --> 00:25:34.840
And we hope you take
these cards and some

00:25:34.840 --> 00:25:37.090
of the methods we
shared with you today

00:25:37.090 --> 00:25:40.930
and use them as a starting
point to imagining entirely

00:25:40.930 --> 00:25:43.960
new products, features,
and potentially even

00:25:43.960 --> 00:25:46.990
entirely new businesses
surrounding these technologies.

00:25:46.990 --> 00:25:50.050
Because getting started
with these technologies

00:25:50.050 --> 00:25:52.600
can be intimidating,
but we believe

00:25:52.600 --> 00:25:55.554
it doesn't have to be
complicated or expensive.

00:25:55.554 --> 00:25:56.470
FABIAN HERRMANN: Yeah.

00:25:56.470 --> 00:26:00.280
We just encourage you to
build those scrappy prototypes

00:26:00.280 --> 00:26:02.579
and go out and talk
to your customers.

00:26:02.579 --> 00:26:04.120
Because that's the
only way how we'll

00:26:04.120 --> 00:26:06.820
find out about their dreams.

00:26:06.820 --> 00:26:13.090
Dreams aren't made of specs
and features, SDKs, and APIs.

00:26:13.090 --> 00:26:14.950
Dreams are inherently human.

00:26:14.950 --> 00:26:19.635
And it's something that's
deep inside of all of us.

00:26:19.635 --> 00:26:22.010
FRANZ BLACH: So when building
with emerging technologies,

00:26:22.010 --> 00:26:23.250
start there.

00:26:23.250 --> 00:26:27.740
Start with the dreams of those
you're actually designing for.

00:26:27.740 --> 00:26:30.710
And also, sometimes,
don't forget

00:26:30.710 --> 00:26:33.080
to tap into your own dreams.

00:26:33.080 --> 00:26:36.920
We're very excited to
see what you come up with

00:26:36.920 --> 00:26:39.370
and what you create.

00:26:39.370 --> 00:26:41.190
FABIAN HERRMANN: Thank you.

