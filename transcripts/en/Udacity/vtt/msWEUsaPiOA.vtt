WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:02.500
Let's consider the following
decision problem.

00:00:02.500 --> 00:00:09.710
&gt;From an initial state, we have a choice
of three actions, a, b, and c.

00:00:09.710 --> 00:00:14.370
The immediate reward associated
with each of these actions is zero.

00:00:14.370 --> 00:00:16.980
But these three actions will
take us to different states with

00:00:16.980 --> 00:00:20.200
different possible rewards
available from these states.

00:00:20.200 --> 00:00:25.030
Action a takes us to state S1,
from which our only

00:00:25.030 --> 00:00:30.320
action is to loop at each
step back into state S1,

00:00:30.320 --> 00:00:36.530
accruing a reward of P1,
which is a parameter, each time.

00:00:36.530 --> 00:00:39.203
If we take action b
at the initial state,

00:00:39.203 --> 00:00:44.090
we will spend the rest of the game
alternating between states S2 and S4.

00:00:44.090 --> 00:00:50.830
We will gain a reward of P2 each
time we move from state S2 to S4.

00:00:50.830 --> 00:00:55.720
And we will receive a reward
of P3 on the return trip.

00:00:55.720 --> 00:01:00.190
And if we take action c initially,
we will move into state S3,

00:01:00.190 --> 00:01:05.920
from which our only next action is to
move into state S5, attaining no reward.

00:01:05.920 --> 00:01:06.460
After that,

00:01:06.460 --> 00:01:12.560
we repeatedly loop in state S5,
attaining a reward of P4 at each step.

00:01:12.560 --> 00:01:16.830
Suppose the game has an independent
probability, of ending after each step?

00:01:16.830 --> 00:01:19.760
And, let's call this probability,
1 minus gamma, so

00:01:19.760 --> 00:01:23.830
that the effective discount factor for
the scenario is gamma.

00:01:23.830 --> 00:01:30.423
Given the parameters P1, P2, P3 and
P4, our problem is to determine for

00:01:30.423 --> 00:01:34.988
which values of gamma we
prefer the initial action a,

00:01:34.988 --> 00:01:41.300
the initial action b, and for which
gamma we prefer the initial action c.

00:01:41.300 --> 00:01:46.205
We will solve this problem by setting up
a Markov decision process encapsulating

00:01:46.205 --> 00:01:48.090
this state diagram in Burlap.

00:01:48.090 --> 00:01:51.356
We will then run value iteration
procedures on the MDP for

00:01:51.356 --> 00:01:54.840
different values of gamma in
order to answer this question.

