WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.190
So we're going to talk about sort of an entry level

00:00:03.370 --> 00:00:10.380
Clustering approach called K-means now K-means comes up a lot in other fields so machine learning uses K-means quite a lot

00:00:10.389 --> 00:00:15.509
It's what we call an unsupervised clustering method often what you have is a situation where you have some training [data]

00:00:15.509 --> 00:00:19.769
But you already know what it is, and then you try and teach your network to find the same thing again

00:00:20.109 --> 00:00:26.669
So we've got labeled training Data in K-means what we've got is just some data and we say split that into three please

00:00:29.380 --> 00:00:32.279
I'll start by showing a very simple overview here of

00:00:32.380 --> 00:00:36.449
How caimans works if we imagine we've got some some data if it's grouped up

00:00:36.450 --> 00:00:42.059
So I'm going to do some x's here and some x's here, so if we wanted to split this data up

00:00:42.059 --> 00:00:43.980
We have no idea about this data to my eye

00:00:43.980 --> 00:00:48.570
It looks like there are two clusters here right partly because I cheated and drew two clusters, but you know

00:00:48.570 --> 00:00:54.419
So if we were giving this data, which is in two dimensions to a machine and said cluster this into two

00:00:54.489 --> 00:00:59.218
What would it do basically is a question there's lots of different approaches K-means is just one of these approaches

00:00:59.219 --> 00:00:59.910
I'm going to show you today

00:00:59.910 --> 00:01:03.869
It's [Cayley] like just a variable or yeah k is a variable we input at the beginning

00:01:03.870 --> 00:01:08.489
So if it's two we're going to split this into two if it's five we're going to split this into five which will kind of

00:01:08.490 --> 00:01:09.880
Be over splitting this

00:01:09.880 --> 00:01:17.009
arguably, but it depends when images come in then you might imagine splitting it into 256 so we can turn it into a

00:01:18.040 --> 00:01:23.879
256-Color Palette image as an example okay, so the number of k is very much dependent on the situation

00:01:23.880 --> 00:01:30.329
You're looking at so how do we do this? Well? What we do is. We have K averages for this data so K-means

00:01:30.329 --> 00:01:31.320
That's how it works

00:01:31.320 --> 00:01:36.089
So I've got myself a couple of squares of paper here, [but] I'm going to use with my mean position

00:01:36.090 --> 00:01:37.710
So I'm going to have this as mean position one

00:01:37.710 --> 00:01:43.110
and this is mean position two now if I was to calculate the mean position of all of this data this one is going to

00:01:43.110 --> 00:01:45.659
Be somewhere in the middle and what K-means is going to do is

00:01:46.390 --> 00:01:49.559
partition this into two and then calculate the means and

00:01:49.750 --> 00:01:53.909
then we partition it based on those means and try and iteratively work out where the

00:01:54.490 --> 00:01:58.979
Ideal means should be so let's start number one over here and let's start number two over here

00:01:58.979 --> 00:02:01.798
We want to partition this data into these groups

00:02:01.810 --> 00:02:06.329
It's probably going to put a partition somewhere around here, and maybe this is going to be in group two

00:02:06.329 --> 00:02:11.488
So these these will be decided you know depending on which their nearest to and so that's our initial segmentation

00:02:11.489 --> 00:02:16.059
Which is pretty poor because put a line straight through the middle of this data, and it's no it's not really any good

00:02:16.220 --> 00:02:20.080
But it's a start and so then what we do is. We say what we've got all of these in group one

00:02:20.150 --> 00:02:23.859
So what is the actual average position of these and maybe this one's in group one as well?

00:02:23.860 --> 00:02:27.910
So it remember moves just down there a little bit. Just just tweaks a little bit now this one

00:02:27.910 --> 00:02:30.939
It's got quite a lot of these in it, so this is going to come up a little bit

00:02:30.940 --> 00:02:32.350
So that's step one, right?

00:02:32.350 --> 00:02:34.350
so we partition them into these two means and

00:02:34.370 --> 00:02:39.040
Then we move the means a little bit based on how these new partitions. [have] formed for now. Let's assume

00:02:39.040 --> 00:02:44.379
We've picked one [and] two at [Random]. We might talk a bit about how you initialize them in a minute, but for step two

00:02:44.380 --> 00:02:45.610
We do the exactly same [thing] again

00:02:45.610 --> 00:02:49.480
So we say well now look the data has changed somewhat okay, so I'm gonna use [my] green pen now

00:02:49.480 --> 00:02:55.569
So maybe these ones are now closest to one and these ones are now closest to two

00:02:55.570 --> 00:02:57.020
So we're getting there, okay?

00:02:57.020 --> 00:02:58.010
so then we

00:02:58.010 --> 00:03:02.199
Reclassify them and we compute the means again and [to] comes up here and one comes a bit down here

00:03:02.200 --> 00:03:05.950
and then we do it again and two comes over here and one comes over here and

00:03:06.320 --> 00:03:11.139
Gradually we settle on the optimal mean position for our groups, okay?

00:03:11.140 --> 00:03:16.600
And then what that finally means is we put a big nice line between these two bits of Data, okay?

00:03:16.600 --> 00:03:21.369
which is exactly what we wanted is it possible they could get it completely wrong good question yes

00:03:22.340 --> 00:03:24.010
So absolutely right?

00:03:24.010 --> 00:03:28.539
So if I was if I was putting in one and two at Random [so] for example if I put one and two over here

00:03:28.880 --> 00:03:34.869
Okay, you might imagine a [situation] where if we're drawing a line down like this. They're kind of evenly distributed

00:03:34.870 --> 00:03:39.640
There's no real pull [right] away, and they just kind of get stuck there okay, so that could happen all right?

00:03:39.640 --> 00:03:46.209
So often what we might do is run K-means a few times with different starting positions, and then pick the best one okay?

00:03:46.430 --> 00:03:49.959
Pick the best one as in each of the ones in this cluster a nearer to one

00:03:50.090 --> 00:03:55.090
Than they would be in this situation what we sometimes do is instead of picking these at random because you know if I put over?

00:03:55.090 --> 00:03:58.000
Here that's not hugely helpful. It's just going to take longer to

00:03:58.520 --> 00:04:03.130
Converge on a solution what we sometimes do is pick two points as our starting positions

00:04:03.130 --> 00:04:07.989
So I could pick a point here and a point here [now]. [that's] not going to [necessarily] completely solve the problem

00:04:07.989 --> 00:04:11.859
You know [if] you pick really bad points that might be a problem, but on average

00:04:11.860 --> 00:04:13.869
It's going to work out okay, okay?

00:04:13.870 --> 00:04:15.260
There are other there are other

00:04:15.260 --> 00:04:19.959
Initialization methods like amy's plus plus and things like this you can read about that do slightly more complex things

00:04:21.320 --> 00:04:26.429
But the very general idea is we have an guess how to separate our data

00:04:26.920 --> 00:04:30.479
We separate it and then we calculate the centers of those regions

00:04:30.480 --> 00:04:36.569
And then we repeat that process to try and converge on a good separation and K-Means is very effective. You know

00:04:36.570 --> 00:04:43.109
It's simple really simple two steps basically move these points into one of the two classes and then we compute the means and just do

00:04:43.110 --> 00:04:44.370
That over and over again now

00:04:44.370 --> 00:04:49.829
This is [two-dimensional] data x and y, but there's no reason it couldn't be free or for five dimensional data

00:04:49.840 --> 00:04:51.840
Right which I can't draw a five dimensional

00:04:52.690 --> 00:04:55.950
Than what that's called, but you know a five dimensional object here on the paper

00:04:56.220 --> 00:05:02.580
I could barely draw a three dimensional one so but in in an image of course we've usually got three dimensions [RG] and B

00:05:02.830 --> 00:05:04.830
So what we have is we [have]

00:05:05.020 --> 00:05:10.500
One mean for the red position and one mean for the blue position and one mean for the green position and we're trying to move

00:05:10.500 --> 00:05:13.679
Around these in this color space trying to find

00:05:14.200 --> 00:05:18.569
What are the dominant colors so K-means on an image will not only tell you?

00:05:19.150 --> 00:05:23.549
Which pixels belong to which of the three classes or four classes or five classes?

00:05:23.590 --> 00:05:28.380
It'll also tell you what's the average color of those classes, so [then] we can simplify our image

00:05:28.600 --> 00:05:32.969
So if you wanted to compress an image for example and change it to say [sixteen] colors

00:05:33.220 --> 00:05:36.929
Right then you would [just] split it into K clusters. Where K is 16

00:05:36.930 --> 00:05:43.290
And then those dominant colors are what you're going to pick and it will look kind of like the original image not great

00:05:43.419 --> 00:05:48.059
But you know people are used to seeing compressed images like this you know on the internet

00:05:48.580 --> 00:05:52.799
So let's look at some moods and see what it does you could pick any initial image to do this to my eye

00:05:52.800 --> 00:05:59.370
There's maybe three or four dominant colors here. There's green obviously blue and black and to a lesser extent white

00:05:59.370 --> 00:06:03.540
I suppose because of these clouds or gray what we will do is we will pick three

00:06:05.350 --> 00:06:10.919
Pixels of random okay, and they will be the initial values for our means okay, so let's imagine

00:06:10.919 --> 00:06:14.129
I'm splitting this image into three because I think maybe there are three dominant colors

00:06:14.440 --> 00:06:17.429
So I pick I have three means instead of just number one

00:06:17.430 --> 00:06:22.680
I have [a] two and a three they get started at random with Random RGB values

00:06:22.680 --> 00:06:26.100
And I cluster the whole image into those regions one two or three

00:06:27.150 --> 00:06:31.830
Then I recompute these mean values and I cluster again, and I recompute [the] mean values [in] my cluster again

00:06:31.830 --> 00:06:34.830
And this is what happens on this image for a k of three

00:06:34.830 --> 00:06:40.149
So we've got the black or very dark green down here [like] Green Gray blue sky

00:06:40.150 --> 00:06:43.719
So that's done. Exactly what we hoped. It would do okay it split

00:06:43.719 --> 00:06:46.359
the image into three if we start to increase the amount of

00:06:46.759 --> 00:06:53.378
Classes, we can slowly start to improve the image and maybe start to get towards what the original image actually look like this is eight

00:06:53.990 --> 00:06:57.039
Classes you can see that now. We're starting to see what we were looking at before

00:06:57.039 --> 00:07:02.498
There's now a difference between the cloud in the sky and quite a lot of difference now on these bushes here, okay?

00:07:02.499 --> 00:07:06.159
And as we go up it gets better and better [now] on 256 colors

00:07:06.169 --> 00:07:09.549
We've had a problem here [with] some of these have [been] put into a weird cluster

00:07:09.550 --> 00:07:12.189
But that's just what happens sometimes with K-means do we initialize it?

00:07:12.259 --> 00:07:17.348
But you can see that actually the [sky] [is] now looking quite a lot like it did originally because we've got lots of different colors

00:07:17.349 --> 00:07:22.479
That we can represent it in terms of image processing we might segment this image to try and find the dominant objects

00:07:22.550 --> 00:07:25.210
In this image, it's not hugely helpful because even in

00:07:26.270 --> 00:07:29.020
Even with a few classes. We've got objects all over place

00:07:29.020 --> 00:07:32.799
We can't for example pick out the trees particularly well because the trees are the same color as a grass

00:07:32.959 --> 00:07:37.239
And the same [colors] [as] [brees] bushes here. So doesn't really help us, but it depends on the image

00:07:37.240 --> 00:07:40.779
You're using if there was a red bus and nothing else in the image was red

00:07:40.779 --> 00:07:44.349
We could pick that class out nicely so it depends on the situation

00:07:45.319 --> 00:07:50.979
Going forward. They're [a] much more complicated segmentation approach it. So things like super pixels that we can talk about another time

00:07:51.189 --> 00:07:57.609
They're trying group coherent regions of the image locally so they're bringing spatial information into it as well

00:07:57.610 --> 00:08:01.599
Which makes a lot more sense because our bus isn't going to be distributed in the red throughout?

00:08:01.599 --> 00:08:05.259
The image is going to be in a box so we can start to look for things like that. I

00:08:07.639 --> 00:08:12.239
Did particular implementation in Matlab because Matlab can do this in [about] five six lines of code?

00:08:12.450 --> 00:08:14.260
We can make that available in the comments

00:08:14.260 --> 00:08:19.709
So if you want to see the Matlab code that does this it uses the inbuilt K-means function of Matlab so I didn't have to

00:08:19.710 --> 00:08:24.570
Work too hard to get it to work, and if you haven't got a matlab license octaver also do this using the same code

00:08:24.570 --> 00:08:26.570
So you can have a go?

