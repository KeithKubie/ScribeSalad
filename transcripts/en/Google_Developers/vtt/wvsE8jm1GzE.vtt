WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.315
[MUSIC PLAYING]

00:00:05.854 --> 00:00:07.145
DANIEL SMILKOV: Hi, I'm Daniel.

00:00:07.145 --> 00:00:08.135
MARTIN WATTENBERG:
Hi, I'm Martin.

00:00:08.135 --> 00:00:09.551
FERNANDA VIEGAS:
Hi, I'm Fernanda.

00:00:12.400 --> 00:00:14.760
Machine learning
is pretty complex.

00:00:14.760 --> 00:00:16.670
So we've been
experimenting with ways

00:00:16.670 --> 00:00:18.960
to visualize what's happening.

00:00:18.960 --> 00:00:21.440
There's a core concept
in machine learning

00:00:21.440 --> 00:00:23.390
called high-dimensional space.

00:00:23.390 --> 00:00:26.570
Here's one way to wrap your
head around this concept.

00:00:26.570 --> 00:00:29.690
You can think about people
as being high-dimensional.

00:00:29.690 --> 00:00:32.330
For example, take
famous scientists.

00:00:32.330 --> 00:00:35.360
You can think about when they
were born, where they were

00:00:35.360 --> 00:00:37.700
born, their fields of study.

00:00:37.700 --> 00:00:40.760
Each of these is like a
dimension of that person.

00:00:40.760 --> 00:00:43.160
These dimensions become
difficult to untangle

00:00:43.160 --> 00:00:45.200
when you think about
different people,

00:00:45.200 --> 00:00:47.720
because someone might
be similar in some ways,

00:00:47.720 --> 00:00:49.261
but very different in others.

00:00:49.261 --> 00:00:51.260
MARTIN WATTENBERG: But
this is the kind of thing

00:00:51.260 --> 00:00:53.042
you can use machine
learning for.

00:00:53.042 --> 00:00:54.500
With machine
learning, the computer

00:00:54.500 --> 00:00:56.291
isn't told the meaning
of these dimensions.

00:00:56.291 --> 00:00:58.670
It just sees them as numbers.

00:00:58.670 --> 00:01:01.700
And it sees each set of
numbers as a data point.

00:01:01.700 --> 00:01:04.550
But by looking across all
of these dimensions at once,

00:01:04.550 --> 00:01:07.580
it's able to place related
points closer together

00:01:07.580 --> 00:01:09.172
in high-dimensional space.

00:01:09.172 --> 00:01:10.880
DANIEL SMILKOV: Here's
a concrete example

00:01:10.880 --> 00:01:14.120
where words are treated as
high-dimensional data points.

00:01:14.120 --> 00:01:15.710
The important thing
to remember is

00:01:15.710 --> 00:01:18.590
that we haven't told the
computer the meaning of words.

00:01:18.590 --> 00:01:21.470
Instead, we've shown it
millions of sentences

00:01:21.470 --> 00:01:23.630
as examples of how
words get used.

00:01:23.630 --> 00:01:26.420
Here is a visualization
of the results.

00:01:26.420 --> 00:01:28.070
We're looking at
a subset of words

00:01:28.070 --> 00:01:29.750
that the computer
has learned about.

00:01:29.750 --> 00:01:32.090
Each dot represents one word.

00:01:32.090 --> 00:01:35.540
Each word is a data point
with 200 dimensions.

00:01:35.540 --> 00:01:38.270
Using a technique called
t-SNE, the computer

00:01:38.270 --> 00:01:41.030
clusters words together
that it considers related.

00:01:41.030 --> 00:01:43.220
And clusters
form-base the meaning,

00:01:43.220 --> 00:01:46.250
even though we've never taught
it the meaning of words.

00:01:46.250 --> 00:01:49.700
Here is a cluster of
numbers, months of the year,

00:01:49.700 --> 00:01:54.892
words related to space, people's
names, cities, and so on.

00:01:54.892 --> 00:01:56.600
FERNANDA VIEGAS: We
can also look closely

00:01:56.600 --> 00:01:58.640
at smaller sets of words.

00:01:58.640 --> 00:02:02.030
If we search "piano,"
we can run t-SNE only

00:02:02.030 --> 00:02:03.770
on words related to "piano."

00:02:03.770 --> 00:02:08.600
We get clusters of composers,
genres, musical instruments,

00:02:08.600 --> 00:02:09.630
and more.

00:02:09.630 --> 00:02:11.130
MARTIN WATTENBERG:
And this approach

00:02:11.130 --> 00:02:12.500
doesn't just work from words.

00:02:12.500 --> 00:02:15.050
For example, you can
also treat an image

00:02:15.050 --> 00:02:16.700
as a high-dimensional
data point.

00:02:16.700 --> 00:02:18.650
Here's a dataset
where lots of people

00:02:18.650 --> 00:02:20.870
wrote digits between 0 and 9.

00:02:20.870 --> 00:02:22.920
People write in
all kinds of ways.

00:02:22.920 --> 00:02:26.450
So the question is, instead
of us needing to manually code

00:02:26.450 --> 00:02:28.640
rules for all the
ways people write,

00:02:28.640 --> 00:02:32.620
could a machine figure it out
itself using machine learning?

00:02:32.620 --> 00:02:35.180
Each image is 784 pixels.

00:02:35.180 --> 00:02:38.370
The computer treats each
pixel as a dimension.

00:02:38.370 --> 00:02:41.450
Again, using t-SNE, it
clusters these images

00:02:41.450 --> 00:02:43.430
in a high-dimensional space.

00:02:43.430 --> 00:02:46.010
We've color-coded them so
that it's easier for us

00:02:46.010 --> 00:02:47.600
to see what's going on.

00:02:47.600 --> 00:02:50.870
And you can see groups of
digits clustering together.

00:02:50.870 --> 00:02:54.240
It's learned something about
the meaning of these digits.

00:02:54.240 --> 00:02:56.240
FERNANDA VIEGAS: These
visualizations techniques

00:02:56.240 --> 00:03:00.540
we've been exploring can be
useful for all kinds of things.

00:03:00.540 --> 00:03:03.080
That's why we're working on
open sourcing all of this

00:03:03.080 --> 00:03:05.690
as part of TensorFlow
so that anyone

00:03:05.690 --> 00:03:07.790
can use these tools
to explore their data.

00:03:07.790 --> 00:03:10.840
[MUSIC PLAYING]

