WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.960
I'd like to talk about face detection

00:00:01.960 --> 00:00:06.899
All right. So this is the idea or if you've got a picture with one face in it or many faces in it

00:00:06.940 --> 00:00:08.940
how do we find those faces and

00:00:09.280 --> 00:00:12.059
The standard approaches is "Ah, we'll just use deep learning"

00:00:12.059 --> 00:00:13.679
Now you can use deep learning to find faces

00:00:13.680 --> 00:00:18.900
But actually the approach that everyone uses isn't deep learning and it was developed in the early 2000s

00:00:21.500 --> 00:00:23.680
So back before deep learning did everything

00:00:24.780 --> 00:00:29.220
You kind of had to come up with these algorithms yourself right machine learning was still a thing. So people still use machine learning

00:00:29.830 --> 00:00:36.299
But they used them with handcrafted features and small neural networks and other kinds of classifiers

00:00:36.790 --> 00:00:38.770
that they tried to use to do these things

00:00:38.770 --> 00:00:43.160
Now the face detection was you know ongoing research at this time

00:00:43.420 --> 00:00:47.040
In 2002 Paul viola Michael Jones came up with this paper here called

00:00:47.400 --> 00:00:52.040
"Rapid object detection using a boosted cascade of simple features", and this is a very very good paper.

00:00:52.520 --> 00:00:55.280
It's been cited some 17,000 times

00:00:55.280 --> 00:00:58.240
And despite the fact that deep learning has kind of taken over everything.

00:00:58.760 --> 00:01:01.080
In face detection, this still performs absolutely fine, right

00:01:01.400 --> 00:01:05.960
It's incredibly quick and if you've got any kind of camera that does some kind of face detection

00:01:05.960 --> 00:01:08.340
It's going to be using something very similar to this, right?

00:01:08.440 --> 00:01:10.400
So what does it do? Let's talk about that.

00:01:10.400 --> 00:01:11.340
The problem is, right,

00:01:11.340 --> 00:01:15.120
There's a few problems with face detection one is that we don't know how big the face is going to be

00:01:15.360 --> 00:01:18.780
So it could be very big could be very small, and another is, you know,

00:01:18.780 --> 00:01:22.920
Maybe you've got a very high-resolution image. We want to be doing this lots and lots of times a second

00:01:23.200 --> 00:01:27.390
So what are we going to do to? Look over every every tiny bit of image lots and lots of times?

00:01:28.210 --> 00:01:30.210
Complicated, um,

00:01:30.430 --> 00:01:33.360
Machine learning, that says, you know, is this a face? is this not a face?

00:01:34.150 --> 00:01:40.319
There's a trade-off between speed and accuracy and false-positives and false-negatives. It's a total mess

00:01:40.570 --> 00:01:46.500
It's very difficult to find faces quickly, right? This is also considering it, you know, we have different ethnic groups

00:01:47.110 --> 00:01:50.610
young, old people, people who've got glasses on, things like this

00:01:50.860 --> 00:01:54.839
So all of this adds up to quite a difficult problem, and yet it's not a problem

00:01:54.840 --> 00:01:58.120
we worry about anymore because we can do it and we can do it because of these guys

00:01:58.480 --> 00:02:05.080
They came up with a classifier that uses very very simple features, one bit of an image subtracted from another bit of an image and

00:02:05.700 --> 00:02:08.340
On its own and that's not very good, but if you have

00:02:08.500 --> 00:02:14.060
thousands and thousands of those, all giving you a clue that maybe this is a face, you could start to come up with proper decision

00:02:14.060 --> 00:02:19.080
[offscreen] Is this looking for facial features then is it as simple as looking for a nose and an eye and etc?

00:02:19.090 --> 00:02:22.450
So no, not really, right. So deep learning kind of does that right?

00:02:22.450 --> 00:02:26.379
It takes it takes edges and other features and it combines them together into objects

00:02:26.379 --> 00:02:32.529
you know, in a hierarchy and then maybe it finds faces. What this is doing is making very quick decisions about

00:02:32.720 --> 00:02:36.400
What it is to be a face, so in for example, if we're just looking at a grayscale image

00:02:36.400 --> 00:02:39.660
Right, my eye is arguably slightly darker than my forehead, right?

00:02:39.660 --> 00:02:42.440
In terms of shadowing and the pupils darker and things like this

00:02:42.740 --> 00:02:45.460
So if you just do this bit of image minus this bit of image

00:02:45.860 --> 00:02:50.600
My eye is going to produce a different response from this blackboard, right, most of the time

00:02:51.409 --> 00:02:56.048
Now, if you do that on its own, that's not a very good classifier, right? It'll get

00:02:56.989 --> 00:02:58.459
quite a lot of the faces

00:02:58.460 --> 00:03:03.280
But it'll also find a load of other stuff as well where something happens to be darker than something else that happens all the time

00:03:03.620 --> 00:03:10.140
so the question is "can we produce a lot of these things all at once and make a decision that way?"

00:03:10.140 --> 00:03:12.940
They proposed these very very simple rectangular features

00:03:12.940 --> 00:03:15.609
Which are just one part of an image subtracted from another part of an image

00:03:15.609 --> 00:03:19.600
So there are a few types of these features. One of them is a two rectangle features

00:03:19.600 --> 00:03:24.380
So we have a block of image where we subtract one side from the other side

00:03:24.380 --> 00:03:26.220
Their approaches are machine learning-based approach

00:03:26.230 --> 00:03:29.240
Normally, what you would do in machine learning is you would extract --

00:03:29.260 --> 00:03:32.420
You can't put the whole image in maybe there's five hundred faces in this image

00:03:32.600 --> 00:03:38.260
So we put in something we've calculated from the image some features and then we use all machine learning to try and classify

00:03:38.320 --> 00:03:43.300
bits of the image or the whole image or something like this. Their contribution was a very quick way to

00:03:43.840 --> 00:03:47.380
calculate these features and use them to make a face classification

00:03:47.480 --> 00:03:49.620
To say there is a face in this block of image or there isn't

00:03:49.620 --> 00:03:54.280
And the features they use a super simple, right? So they're just rectangular features like this

00:03:54.349 --> 00:03:59.138
So we've got two rectangles next to each other which, you know are some amount of pixels

00:03:59.139 --> 00:04:00.109
so maybe it's a

00:04:00.109 --> 00:04:05.340
It's nine pixels here and nine pixels here or just one pixel and one pixel or hundred pixels and a hundred pixels

00:04:05.340 --> 00:04:07.160
It's not really important.

00:04:07.440 --> 00:04:09.780
and we do one subtract the other right?

00:04:09.789 --> 00:04:13.720
So essentially we're looking for bits of an image where one bit is darker or brighter than another bit

00:04:13.720 --> 00:04:18.099
This is a two rectangle feature. It can also be oriented the other way so, you know like this

00:04:18.199 --> 00:04:24.848
We also have three rectangle features which are like this where you're doing sort of maybe the middle subtract the outside or vice versa

00:04:25.099 --> 00:04:30.249
And we have four rectangle feature which are going to be kind of finding diagonal sort of corner things

00:04:30.250 --> 00:04:31.570
So something like this

00:04:31.570 --> 00:04:37.659
Even if your image is small right you're going to have a lot of different possible features even of these four types

00:04:37.660 --> 00:04:43.570
So this four rectangle feature could just be one pixel each or each of these could be half the image it can scale

00:04:43.670 --> 00:04:45.670
You know or move and move around

00:04:46.220 --> 00:04:49.940
Brady : What determines that?
Mike : Um, so they do all of them, right?

00:04:50.040 --> 00:04:51.920
Or at least they look at all of them originally

00:04:51.920 --> 00:04:58.280
And they learn which ones are the most useful for finding a face this over a whole image of a face isn't hugely

00:04:58.480 --> 00:05:03.480
representative of what a face looks like right? No one's face. The corners are darker than the other two corners

00:05:03.480 --> 00:05:06.920
That doesn't make sense, right but maybe over their eye, maybe that makes more sense

00:05:07.240 --> 00:05:11.859
I don't know, that's the kind of the idea. So they have a training process at which was down

00:05:11.860 --> 00:05:15.759
Which of these features are useful, the other problem we've got is that on an image

00:05:16.340 --> 00:05:20.740
Calculating large groups of pixels and summing them up is quite a slow process

00:05:20.750 --> 00:05:25.390
So they come a really nifty idea called an integral image which makes this way way faster

00:05:25.610 --> 00:05:27.250
So let's imagine we have an image

00:05:27.250 --> 00:05:32.770
Right, and so think -- consider while we're talking about this that we want to kind of calculate these bits of image

00:05:32.770 --> 00:05:36.999
But minus some other bit of image, right? So let's imagine we have an image which is nice and small

00:05:37.520 --> 00:05:39.819
It's too small for me to write on but let's not worry about it

00:05:39.920 --> 00:05:46.020
Right and then let's draw in some pixel values. Sast forward. Look at the state of that. That's that's a total total shambles

00:05:46.640 --> 00:05:49.520
This is a rubbable-out pen, right? For goodness sake

00:05:51.040 --> 00:05:53.320
Right right okay okay so all right so

00:05:53.320 --> 00:05:56.240
Let's imagine this is our input image. We're trying to find a face in it

00:05:56.240 --> 00:05:57.320
Now I can't see one

00:05:57.320 --> 00:06:03.020
But obviously this could be a quite a lot bigger and we want to calculate let's say one of our two rectangle features

00:06:03.040 --> 00:06:05.560
So maybe we want to do these four pixels up in the top

00:06:05.720 --> 00:06:10.220
Minus the four pixels below it now that's only a few additions : 7 + 7 + 1 + 2

00:06:10.520 --> 00:06:12.520
minus 8 + 3 + 1 + 2

00:06:12.820 --> 00:06:18.320
But if you're doing this over large sections of image and thousands and thousands of times to try and find faces

00:06:19.040 --> 00:06:20.220
That's not gonna work

00:06:20.840 --> 00:06:26.620
So what Viola Jones came up with was this integral image where we pre-compute

00:06:26.900 --> 00:06:31.300
Some of this arithmetic for us, store it in an intermediate form, and then we can calculate

00:06:31.560 --> 00:06:34.300
rectangles minus of of rectangles really easily

00:06:34.300 --> 00:06:40.240
So we do one pass over the image, and every new pixel is the sum of all the pixels

00:06:40.490 --> 00:06:44.299
Above and to the left and it including it. right, so this will be something like this

00:06:44.300 --> 00:06:44.610
so

00:06:44.610 --> 00:06:51.470
1 and 1 + 7 is 8 so this pixel is the sum of these two pixels and this pixel is going to be all these three

00:06:51.470 --> 00:06:55.540
So that's going to be 12... 14... 23

00:06:55.540 --> 00:06:58.200
and now we fast forward while I do a bit of math in my head

00:06:58.200 --> 00:07:04.220
8...17 maybe I did somebody's earlier, 24... On a computer this is much much faster

00:07:04.830 --> 00:07:10.819
The sum of all the pixels is 113. For example, the sum of this 4x4 block is 68 now

00:07:10.819 --> 00:07:12.349
The reason this is useful, bear with me here

00:07:12.349 --> 00:07:17.149
But if we want to work out what, let's say, the sum of this region is what we do is we take this one

00:07:17.400 --> 00:07:21.019
113 we subtract this one, minus 64

00:07:21.180 --> 00:07:22.650
Alright, and this one?

00:07:22.650 --> 00:07:27.859
minus 71 and that's taken off all of that and all of that and then we have to add this bit in because we've been

00:07:27.860 --> 00:07:32.300
Taken off twice so plus 40. All right, so that's four reads. Now funnily enough this is a 4 by 4 block

00:07:32.300 --> 00:07:33.020
So I've achieved nothing

00:07:33.020 --> 00:07:37.549
But if this was a huge huge image, I've saved a huge amount of time and the answer to this is 18

00:07:37.680 --> 00:07:39.949
Which is 6 plus 6 plus 5 plus 1

00:07:39.949 --> 00:07:44.869
So the assumption is that I'm not just going to be looking at these pictures one time to do this, right?

00:07:45.060 --> 00:07:49.789
There's lots of places a face could be I've got to look at lots of combinations of pixels and different regions

00:07:49.789 --> 00:07:54.169
So I'm going to be doing huge amounts of pixel addition and subtraction

00:07:54.200 --> 00:07:59.800
So let's calculate this integral image once and then use that as a base to do really quick

00:08:01.260 --> 00:08:03.140
Adding and subtracting of regions, right?

00:08:03.300 --> 00:08:06.340
and so I think for example a 4 rectangle region

00:08:06.500 --> 00:08:10.660
is going to take something like nine reads or something like that and a little bit addition. It's very simple

00:08:10.669 --> 00:08:16.129
All right. So now how do we turn this into a working face detector? Let's imagine

00:08:16.130 --> 00:08:19.399
We have a picture of a face, which is going to be one of my good drawings again

00:08:19.680 --> 00:08:25.640
Now in this particular algorithm, they look 24 by 24 pixel regions, but they can also scale up and down a little bit

00:08:25.740 --> 00:08:32.640
So let's imagine there's a face here which has, you know eyes, a nose and a mouth right and some hair

00:08:33.260 --> 00:08:39.600
Okay, good. Now as I mentioned earlier, there are probably some features that don't make a lot of sense on this

00:08:39.620 --> 00:08:41.929
So subtracting, for example, if I take my red pen

00:08:42.690 --> 00:08:46.880
Subtracting this half of image from this half. It's not going to represent most faces

00:08:46.880 --> 00:08:51.799
It may be when there's a lot of lighting on one side, but it's not very good at distinguishing

00:08:52.460 --> 00:08:55.280
Images that have faces in and images that don't have faces in

00:08:55.280 --> 00:09:00.500
So what they do, is they calculate all of the features, right for a 24 by 24 image

00:09:00.500 --> 00:09:07.420
They calculate all 180,000 possible combinations of 2, 3, and 4 rectangle features and they work out which one

00:09:07.720 --> 00:09:14.399
For a given data set of faces and not faces, which one best separates the positives from the negatives, right?

00:09:14.399 --> 00:09:16.499
So let's say you have 10,000 pictures of faces

00:09:17.200 --> 00:09:21.600
10,000 pictures of background which one feature best

00:09:21.940 --> 00:09:24.900
says "this is a face, this is not a face" 
Right, bearing in mind

00:09:25.000 --> 00:09:27.209
Nothing is going to get it completely right with just one feature

00:09:27.370 --> 00:09:30.120
So the first one it looks it turns out is something like this

00:09:30.120 --> 00:09:36.260
It's a two rectangle region, but works out a difference between the area of the eyes and the air for cheeks

00:09:36.540 --> 00:09:41.580
So it's saying if on a normal face your cheeks are generally brighter or darker than your eyes

00:09:41.800 --> 00:09:44.380
So what they do is they say, okay

00:09:44.399 --> 00:09:48.268
Well, let's start a classifier with just that feature right and see how good it is

00:09:48.269 --> 00:09:52.469
This is our first feature feature number one, and we have a pretty relaxed threshold

00:09:52.510 --> 00:09:56.099
so if there's anything plausible in this region

00:09:56.100 --> 00:10:00.300
we'll let it through right which is going to let through all of the faces and a bunch of other stuff as well that we

00:10:00.300 --> 00:10:06.750
Don't want right. So this is yes. That's okay, right? That's okay if it's a no then we immediately

00:10:07.600 --> 00:10:13.920
Fail that region of image right? So we've done one test which is as we know about four additions

00:10:13.920 --> 00:10:18.630
So we've said for this region of image if this passes will let it through to the next stage

00:10:19.079 --> 00:10:21.629
Right and we'll say okay it definitely could be a face

00:10:22.390 --> 00:10:26.219
It's not not-a-face. Does that make sense? Yeah, okay

00:10:26.220 --> 00:10:27.660
So let's do look at the next feature

00:10:27.660 --> 00:10:28.740
The next feature is this one

00:10:28.740 --> 00:10:34.919
So it's a three region feature and it measures the difference between the nose and the bridge and the eyes, right?

00:10:34.920 --> 00:10:37.589
which may or may not be darker or lighter. All right, so there's a difference there

00:10:37.750 --> 00:10:41.309
So this is feature number two, so I'm going to draw that in here number two

00:10:41.310 --> 00:10:47.849
And if that passes we go to the next feature, so this is a sort of binary, they call it "degenerate decision tree"

00:10:47.850 --> 00:10:52.469
Right, well because the decision tree is a binary tree. This is not really because you immediately stop here

00:10:52.470 --> 00:10:54.470
you don't go any further.
The argument is that

00:10:54.580 --> 00:10:57.860
Every time we calculate one of these features it takes a little bit of time

00:10:57.860 --> 00:11:02.960
The quicker we can say "no definitely not a face in there", the better. And the only time we ever need to look at all the features

00:11:03.540 --> 00:11:07.649
Or all of the good ones is when we think, "okay, that actually could be a face here"

00:11:07.649 --> 00:11:12.868
So we have less and less general, more and more specific features going forward right up to about the number

00:11:12.869 --> 00:11:16.589
I think it's about six thousand they end up using. All right, so we we say just the first one pass

00:11:16.589 --> 00:11:18.100
Yes, just a second one pass

00:11:18.100 --> 00:11:23.369
Yes, and we keep going until we get a fail and if we get all the way to the end and nothing fails

00:11:23.860 --> 00:11:28.220
that's a face, right and the beauty of this, is that

00:11:29.440 --> 00:11:34.500
For the vast majority of the image, there's no computation at all. We just take one look at it, first feature fails

00:11:34.780 --> 00:11:39.140
"Nah, not a face". They designed a really good way of adding and subtracting different regions of the image

00:11:39.149 --> 00:11:45.178
And then they trained a classifier like this to find the best features and the best order to apply those features

00:11:45.300 --> 00:11:51.420
which was a nice compromise between always detecting the faces that are there and false positives and speed right?

00:11:51.420 --> 00:11:56.620
And at the time, this was running on, I think to give you some idea of what the computational Technology was like in 2002

00:11:56.860 --> 00:12:02.180
This was presented on a 700 megahertz Pentium 3 and ran at 15 frames a second

00:12:02.189 --> 00:12:09.149
which was totally unheard of back then. Face detection was the kind of offline, you know, it was okay at that time

00:12:09.880 --> 00:12:13.540
So this is a really, really cool algorithm and it's so effective

00:12:14.700 --> 00:12:17.460
that you still see it used in, you know, in your camera phone

00:12:17.520 --> 00:12:24.000
and in this camera and so on, when you just get a little bounding box around the face and this is still really useful

00:12:24.180 --> 00:12:29.040
because you might be doing deep learning on something like face recognition, face ID something like this

00:12:29.140 --> 00:12:35.920
But part of that process is firstly working out where the face is, and why reinvent the wheel when this technique works really really well

00:12:37.420 --> 00:12:41.699
You can't really get into the data center necessarily and take all the chips out that you've put in there

00:12:41.699 --> 00:12:48.149
So you probably will make the chips look like they're meant to be there like they're something else or hide them

00:12:48.149 --> 00:12:54.539
So the way a modern printed circuit board is constructed. It's a printed circuit board that's got several layers of fiberglass

