WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.690
for this final video for this week let's

00:00:02.690 --> 00:00:02.700
for this final video for this week let's
 

00:00:02.700 --> 00:00:05.360
for this final video for this week let's
talk a bit about why convolutions are so

00:00:05.360 --> 00:00:05.370
talk a bit about why convolutions are so
 

00:00:05.370 --> 00:00:07.970
talk a bit about why convolutions are so
useful when you include them in your new

00:00:07.970 --> 00:00:07.980
useful when you include them in your new
 

00:00:07.980 --> 00:00:10.669
useful when you include them in your new
networks and then finally let's briefly

00:00:10.669 --> 00:00:10.679
networks and then finally let's briefly
 

00:00:10.679 --> 00:00:13.070
networks and then finally let's briefly
talk about how to put this all together

00:00:13.070 --> 00:00:13.080
talk about how to put this all together
 

00:00:13.080 --> 00:00:16.039
talk about how to put this all together
and how you can train a convolutional

00:00:16.039 --> 00:00:16.049
and how you can train a convolutional
 

00:00:16.049 --> 00:00:18.439
and how you can train a convolutional
neural network when you have a labeled

00:00:18.439 --> 00:00:18.449
neural network when you have a labeled
 

00:00:18.449 --> 00:00:22.370
neural network when you have a labeled
training set I think there are two main

00:00:22.370 --> 00:00:22.380
training set I think there are two main
 

00:00:22.380 --> 00:00:26.349
training set I think there are two main
advantages of convolutional layers over

00:00:26.349 --> 00:00:26.359
advantages of convolutional layers over
 

00:00:26.359 --> 00:00:29.150
advantages of convolutional layers over
just using fully connected layers and

00:00:29.150 --> 00:00:29.160
just using fully connected layers and
 

00:00:29.160 --> 00:00:32.120
just using fully connected layers and
the advantages are parameter sharing and

00:00:32.120 --> 00:00:32.130
the advantages are parameter sharing and
 

00:00:32.130 --> 00:00:34.310
the advantages are parameter sharing and
sparsity of connections let me

00:00:34.310 --> 00:00:34.320
sparsity of connections let me
 

00:00:34.320 --> 00:00:36.950
sparsity of connections let me
illustrate to an example let's say you

00:00:36.950 --> 00:00:36.960
illustrate to an example let's say you
 

00:00:36.960 --> 00:00:42.260
illustrate to an example let's say you
have a 32 by 32 by 3 dimensional image

00:00:42.260 --> 00:00:42.270
have a 32 by 32 by 3 dimensional image
 

00:00:42.270 --> 00:00:47.840
have a 32 by 32 by 3 dimensional image
and this actually comes from the example

00:00:47.840 --> 00:00:47.850
and this actually comes from the example
 

00:00:47.850 --> 00:00:49.910
and this actually comes from the example
from the previous video but let's say

00:00:49.910 --> 00:00:49.920
from the previous video but let's say
 

00:00:49.920 --> 00:00:54.160
from the previous video but let's say
you use a 5 by 5 filter with 6 filters

00:00:54.160 --> 00:00:54.170
you use a 5 by 5 filter with 6 filters
 

00:00:54.170 --> 00:01:02.020
you use a 5 by 5 filter with 6 filters
and so this gives you a 28 by 28 by 6

00:01:02.020 --> 00:01:02.030
and so this gives you a 28 by 28 by 6
 

00:01:02.030 --> 00:01:08.440
and so this gives you a 28 by 28 by 6
dimensional output so 32 by 32 by 3 is

00:01:08.440 --> 00:01:08.450
dimensional output so 32 by 32 by 3 is
 

00:01:08.450 --> 00:01:09.679
dimensional output so 32 by 32 by 3 is
3072

00:01:09.679 --> 00:01:09.689
3072
 

00:01:09.689 --> 00:01:12.530
3072
and 20 by 20 by 60 we multiply all those

00:01:12.530 --> 00:01:12.540
and 20 by 20 by 60 we multiply all those
 

00:01:12.540 --> 00:01:18.800
and 20 by 20 by 60 we multiply all those
numbers in 4704 and so if you were to

00:01:18.800 --> 00:01:18.810
numbers in 4704 and so if you were to
 

00:01:18.810 --> 00:01:22.670
numbers in 4704 and so if you were to
create in your network with 3072 units

00:01:22.670 --> 00:01:22.680
create in your network with 3072 units
 

00:01:22.680 --> 00:01:27.050
create in your network with 3072 units
in one layer and you know 4704 units in

00:01:27.050 --> 00:01:27.060
in one layer and you know 4704 units in
 

00:01:27.060 --> 00:01:28.670
in one layer and you know 4704 units in
the next layer and if you were to

00:01:28.670 --> 00:01:28.680
the next layer and if you were to
 

00:01:28.680 --> 00:01:31.520
the next layer and if you were to
connect every one of these neurons then

00:01:31.520 --> 00:01:31.530
connect every one of these neurons then
 

00:01:31.530 --> 00:01:33.080
connect every one of these neurons then
the weight matrix the number of

00:01:33.080 --> 00:01:33.090
the weight matrix the number of
 

00:01:33.090 --> 00:01:34.670
the weight matrix the number of
parameters in the weight matrix would be

00:01:34.670 --> 00:01:34.680
parameters in the weight matrix would be
 

00:01:34.680 --> 00:01:37.130
parameters in the weight matrix would be
a 3072

00:01:37.130 --> 00:01:37.140
a 3072
 

00:01:37.140 --> 00:01:40.460
a 3072
times four thousand seven and four which

00:01:40.460 --> 00:01:40.470
times four thousand seven and four which
 

00:01:40.470 --> 00:01:43.190
times four thousand seven and four which
is about 14 million so that's just a lot

00:01:43.190 --> 00:01:43.200
is about 14 million so that's just a lot
 

00:01:43.200 --> 00:01:45.020
is about 14 million so that's just a lot
of parameters to train and you know

00:01:45.020 --> 00:01:45.030
of parameters to train and you know
 

00:01:45.030 --> 00:01:46.940
of parameters to train and you know
today you can train your networks with

00:01:46.940 --> 00:01:46.950
today you can train your networks with
 

00:01:46.950 --> 00:01:49.730
today you can train your networks with
even more parameters than 14 million but

00:01:49.730 --> 00:01:49.740
even more parameters than 14 million but
 

00:01:49.740 --> 00:01:51.710
even more parameters than 14 million but
considering that this is just a pretty

00:01:51.710 --> 00:01:51.720
considering that this is just a pretty
 

00:01:51.720 --> 00:01:53.539
considering that this is just a pretty
small image this is some other

00:01:53.539 --> 00:01:53.549
small image this is some other
 

00:01:53.549 --> 00:01:55.999
small image this is some other
parameters to train and of course if

00:01:55.999 --> 00:01:56.009
parameters to train and of course if
 

00:01:56.009 --> 00:01:59.630
parameters to train and of course if
this were to be a thousand by thousand

00:01:59.630 --> 00:01:59.640
this were to be a thousand by thousand
 

00:01:59.640 --> 00:02:01.609
this were to be a thousand by thousand
image then you know this weight matrix

00:02:01.609 --> 00:02:01.619
image then you know this weight matrix
 

00:02:01.619 --> 00:02:05.399
image then you know this weight matrix
will just become infeasible large

00:02:05.399 --> 00:02:05.409
will just become infeasible large
 

00:02:05.409 --> 00:02:08.010
will just become infeasible large
if you look at the number of parameters

00:02:08.010 --> 00:02:08.020
if you look at the number of parameters
 

00:02:08.020 --> 00:02:10.889
if you look at the number of parameters
in this convolutional layer each filter

00:02:10.889 --> 00:02:10.899
in this convolutional layer each filter
 

00:02:10.899 --> 00:02:14.430
in this convolutional layer each filter
is five by five so each filter has 25

00:02:14.430 --> 00:02:14.440
is five by five so each filter has 25
 

00:02:14.440 --> 00:02:17.009
is five by five so each filter has 25
parameters plus a bias parameter a means

00:02:17.009 --> 00:02:17.019
parameters plus a bias parameter a means
 

00:02:17.019 --> 00:02:19.350
parameters plus a bias parameter a means
you have 26 parameters per filter and

00:02:19.350 --> 00:02:19.360
you have 26 parameters per filter and
 

00:02:19.360 --> 00:02:22.140
you have 26 parameters per filter and
you have six filters so the total number

00:02:22.140 --> 00:02:22.150
you have six filters so the total number
 

00:02:22.150 --> 00:02:25.410
you have six filters so the total number
of parameters is that which is equal 256

00:02:25.410 --> 00:02:25.420
of parameters is that which is equal 256
 

00:02:25.420 --> 00:02:27.690
of parameters is that which is equal 256
parameters and so the number of

00:02:27.690 --> 00:02:27.700
parameters and so the number of
 

00:02:27.700 --> 00:02:30.420
parameters and so the number of
parameters in this complains quite small

00:02:30.420 --> 00:02:30.430
parameters in this complains quite small
 

00:02:30.430 --> 00:02:35.009
parameters in this complains quite small
and the reason that a confident has run

00:02:35.009 --> 00:02:35.019
and the reason that a confident has run
 

00:02:35.019 --> 00:02:36.780
and the reason that a confident has run
through these small parameters is really

00:02:36.780 --> 00:02:36.790
through these small parameters is really
 

00:02:36.790 --> 00:02:40.130
through these small parameters is really
two reasons one is parameter sharing and

00:02:40.130 --> 00:02:40.140
two reasons one is parameter sharing and
 

00:02:40.140 --> 00:02:42.750
two reasons one is parameter sharing and
then parameter sharing is motivated by

00:02:42.750 --> 00:02:42.760
then parameter sharing is motivated by
 

00:02:42.760 --> 00:02:45.509
then parameter sharing is motivated by
the observation that a feature detector

00:02:45.509 --> 00:02:45.519
the observation that a feature detector
 

00:02:45.519 --> 00:02:48.300
the observation that a feature detector
such as vertical edge detector let's use

00:02:48.300 --> 00:02:48.310
such as vertical edge detector let's use
 

00:02:48.310 --> 00:02:49.770
such as vertical edge detector let's use
when one how the image is produce for

00:02:49.770 --> 00:02:49.780
when one how the image is produce for
 

00:02:49.780 --> 00:02:51.600
when one how the image is produce for
another poly the image and what that

00:02:51.600 --> 00:02:51.610
another poly the image and what that
 

00:02:51.610 --> 00:02:53.940
another poly the image and what that
means is that if you think about say a

00:02:53.940 --> 00:02:53.950
means is that if you think about say a
 

00:02:53.950 --> 00:02:55.680
means is that if you think about say a
three by three filter for detecting

00:02:55.680 --> 00:02:55.690
three by three filter for detecting
 

00:02:55.690 --> 00:02:58.020
three by three filter for detecting
vertical edges you can then apply the

00:02:58.020 --> 00:02:58.030
vertical edges you can then apply the
 

00:02:58.030 --> 00:03:01.460
vertical edges you can then apply the
same three by three filter over here and

00:03:01.460 --> 00:03:01.470
same three by three filter over here and
 

00:03:01.470 --> 00:03:04.380
same three by three filter over here and
in the next position over and the next

00:03:04.380 --> 00:03:04.390
in the next position over and the next
 

00:03:04.390 --> 00:03:07.020
in the next position over and the next
position over and so on and so each of

00:03:07.020 --> 00:03:07.030
position over and so on and so each of
 

00:03:07.030 --> 00:03:09.300
position over and so on and so each of
these you know feature detectors each of

00:03:09.300 --> 00:03:09.310
these you know feature detectors each of
 

00:03:09.310 --> 00:03:11.729
these you know feature detectors each of
these outputs can use the same

00:03:11.729 --> 00:03:11.739
these outputs can use the same
 

00:03:11.739 --> 00:03:13.890
these outputs can use the same
parameters in lots of different

00:03:13.890 --> 00:03:13.900
parameters in lots of different
 

00:03:13.900 --> 00:03:16.800
parameters in lots of different
positions in your input image in order

00:03:16.800 --> 00:03:16.810
positions in your input image in order
 

00:03:16.810 --> 00:03:19.949
positions in your input image in order
to detect say a vertical edge or some

00:03:19.949 --> 00:03:19.959
to detect say a vertical edge or some
 

00:03:19.959 --> 00:03:23.580
to detect say a vertical edge or some
other feature and I think this is true

00:03:23.580 --> 00:03:23.590
other feature and I think this is true
 

00:03:23.590 --> 00:03:26.220
other feature and I think this is true
for low-level features like edges as

00:03:26.220 --> 00:03:26.230
for low-level features like edges as
 

00:03:26.230 --> 00:03:28.440
for low-level features like edges as
well as for higher-level features like

00:03:28.440 --> 00:03:28.450
well as for higher-level features like
 

00:03:28.450 --> 00:03:30.900
well as for higher-level features like
maybe detecting the I the indicates a

00:03:30.900 --> 00:03:30.910
maybe detecting the I the indicates a
 

00:03:30.910 --> 00:03:32.580
maybe detecting the I the indicates a
face where cats or something is there

00:03:32.580 --> 00:03:32.590
face where cats or something is there
 

00:03:32.590 --> 00:03:34.710
face where cats or something is there
but being with a share in this case the

00:03:34.710 --> 00:03:34.720
but being with a share in this case the
 

00:03:34.720 --> 00:03:38.160
but being with a share in this case the
same nine parameters to compute all 16

00:03:38.160 --> 00:03:38.170
same nine parameters to compute all 16
 

00:03:38.170 --> 00:03:40.920
same nine parameters to compute all 16
of these outputs is one of the ways the

00:03:40.920 --> 00:03:40.930
of these outputs is one of the ways the
 

00:03:40.930 --> 00:03:44.250
of these outputs is one of the ways the
number of parameters is reduced and it

00:03:44.250 --> 00:03:44.260
number of parameters is reduced and it
 

00:03:44.260 --> 00:03:46.680
number of parameters is reduced and it
also just seems intuitive that a feature

00:03:46.680 --> 00:03:46.690
also just seems intuitive that a feature
 

00:03:46.690 --> 00:03:49.020
also just seems intuitive that a feature
detector like a vertical edge detector

00:03:49.020 --> 00:03:49.030
detector like a vertical edge detector
 

00:03:49.030 --> 00:03:51.000
detector like a vertical edge detector
computed for the upper left-hand corner

00:03:51.000 --> 00:03:51.010
computed for the upper left-hand corner
 

00:03:51.010 --> 00:03:53.879
computed for the upper left-hand corner
of the image the same feature seems like

00:03:53.879 --> 00:03:53.889
of the image the same feature seems like
 

00:03:53.889 --> 00:03:55.890
of the image the same feature seems like
the world probably useful has a good

00:03:55.890 --> 00:03:55.900
the world probably useful has a good
 

00:03:55.900 --> 00:03:57.479
the world probably useful has a good
chance of being useful for the lower

00:03:57.479 --> 00:03:57.489
chance of being useful for the lower
 

00:03:57.489 --> 00:03:59.849
chance of being useful for the lower
right hand corner of the image so maybe

00:03:59.849 --> 00:03:59.859
right hand corner of the image so maybe
 

00:03:59.859 --> 00:04:01.500
right hand corner of the image so maybe
you don't need to learn separate feature

00:04:01.500 --> 00:04:01.510
you don't need to learn separate feature
 

00:04:01.510 --> 00:04:03.180
you don't need to learn separate feature
detectors for the upper left and the

00:04:03.180 --> 00:04:03.190
detectors for the upper left and the
 

00:04:03.190 --> 00:04:04.830
detectors for the upper left and the
lower right hand corners of the image

00:04:04.830 --> 00:04:04.840
lower right hand corners of the image
 

00:04:04.840 --> 00:04:06.900
lower right hand corners of the image
and maybe you do have a data set where

00:04:06.900 --> 00:04:06.910
and maybe you do have a data set where
 

00:04:06.910 --> 00:04:08.759
and maybe you do have a data set where
you know the upper left-hand corner and

00:04:08.759 --> 00:04:08.769
you know the upper left-hand corner and
 

00:04:08.769 --> 00:04:11.039
you know the upper left-hand corner and
in the right-hand corner have different

00:04:11.039 --> 00:04:11.049
in the right-hand corner have different
 

00:04:11.049 --> 00:04:12.900
in the right-hand corner have different
distributions so they maybe look a

00:04:12.900 --> 00:04:12.910
distributions so they maybe look a
 

00:04:12.910 --> 00:04:14.430
distributions so they maybe look a
little bit different but they might be

00:04:14.430 --> 00:04:14.440
little bit different but they might be
 

00:04:14.440 --> 00:04:16.439
little bit different but they might be
similar enough their share in future

00:04:16.439 --> 00:04:16.449
similar enough their share in future
 

00:04:16.449 --> 00:04:19.080
similar enough their share in future
detectors in all across the image

00:04:19.080 --> 00:04:19.090
detectors in all across the image
 

00:04:19.090 --> 00:04:21.360
detectors in all across the image
works just fine the second way that

00:04:21.360 --> 00:04:21.370
works just fine the second way that
 

00:04:21.370 --> 00:04:23.909
works just fine the second way that
confidence get away with having

00:04:23.909 --> 00:04:23.919
confidence get away with having
 

00:04:23.919 --> 00:04:26.220
confidence get away with having
relatively few parameters is by having

00:04:26.220 --> 00:04:26.230
relatively few parameters is by having
 

00:04:26.230 --> 00:04:28.230
relatively few parameters is by having
sparse connection so here's what I mean

00:04:28.230 --> 00:04:28.240
sparse connection so here's what I mean
 

00:04:28.240 --> 00:04:30.840
sparse connection so here's what I mean
if you look at the zero this was

00:04:30.840 --> 00:04:30.850
if you look at the zero this was
 

00:04:30.850 --> 00:04:33.690
if you look at the zero this was
computed by 3x3 convolution and so it

00:04:33.690 --> 00:04:33.700
computed by 3x3 convolution and so it
 

00:04:33.700 --> 00:04:37.200
computed by 3x3 convolution and so it
depends only on this V by V input grid

00:04:37.200 --> 00:04:37.210
depends only on this V by V input grid
 

00:04:37.210 --> 00:04:41.159
depends only on this V by V input grid
of cells so is as if this output unit on

00:04:41.159 --> 00:04:41.169
of cells so is as if this output unit on
 

00:04:41.169 --> 00:04:45.150
of cells so is as if this output unit on
the right is connected only to nine out

00:04:45.150 --> 00:04:45.160
the right is connected only to nine out
 

00:04:45.160 --> 00:04:49.379
the right is connected only to nine out
of these six by six 36 input features

00:04:49.379 --> 00:04:49.389
of these six by six 36 input features
 

00:04:49.389 --> 00:04:52.500
of these six by six 36 input features
and in particular the rest of these

00:04:52.500 --> 00:04:52.510
and in particular the rest of these
 

00:04:52.510 --> 00:04:54.990
and in particular the rest of these
pixel values you know only these pixel

00:04:54.990 --> 00:04:55.000
pixel values you know only these pixel
 

00:04:55.000 --> 00:04:57.330
pixel values you know only these pixel
values all of these pixel values do not

00:04:57.330 --> 00:04:57.340
values all of these pixel values do not
 

00:04:57.340 --> 00:05:00.330
values all of these pixel values do not
have any input on this do not have any

00:05:00.330 --> 00:05:00.340
have any input on this do not have any
 

00:05:00.340 --> 00:05:02.969
have any input on this do not have any
effect on that output so that's what I

00:05:02.969 --> 00:05:02.979
effect on that output so that's what I
 

00:05:02.979 --> 00:05:05.730
effect on that output so that's what I
mean by sponsee of connections as an

00:05:05.730 --> 00:05:05.740
mean by sponsee of connections as an
 

00:05:05.740 --> 00:05:10.230
mean by sponsee of connections as an
another example this output depends only

00:05:10.230 --> 00:05:10.240
another example this output depends only
 

00:05:10.240 --> 00:05:16.290
another example this output depends only
on these nine input features and so as

00:05:16.290 --> 00:05:16.300
on these nine input features and so as
 

00:05:16.300 --> 00:05:18.330
on these nine input features and so as
as if only those nine input features a

00:05:18.330 --> 00:05:18.340
as if only those nine input features a
 

00:05:18.340 --> 00:05:20.670
as if only those nine input features a
connector to this output and the other

00:05:20.670 --> 00:05:20.680
connector to this output and the other
 

00:05:20.680 --> 00:05:22.800
connector to this output and the other
pixels just don't affect this output at

00:05:22.800 --> 00:05:22.810
pixels just don't affect this output at
 

00:05:22.810 --> 00:05:23.130
pixels just don't affect this output at
all

00:05:23.130 --> 00:05:23.140
all
 

00:05:23.140 --> 00:05:25.860
all
and so through these two mechanisms a

00:05:25.860 --> 00:05:25.870
and so through these two mechanisms a
 

00:05:25.870 --> 00:05:29.159
and so through these two mechanisms a
new network has a lot fewer parameters

00:05:29.159 --> 00:05:29.169
new network has a lot fewer parameters
 

00:05:29.169 --> 00:05:31.110
new network has a lot fewer parameters
which allows it to be trained to have

00:05:31.110 --> 00:05:31.120
which allows it to be trained to have
 

00:05:31.120 --> 00:05:33.570
which allows it to be trained to have
smaller training sets and is less prone

00:05:33.570 --> 00:05:33.580
smaller training sets and is less prone
 

00:05:33.580 --> 00:05:36.510
smaller training sets and is less prone
to be overfitting and sometimes you also

00:05:36.510 --> 00:05:36.520
to be overfitting and sometimes you also
 

00:05:36.520 --> 00:05:38.940
to be overfitting and sometimes you also
hear about convolutional neural networks

00:05:38.940 --> 00:05:38.950
hear about convolutional neural networks
 

00:05:38.950 --> 00:05:40.950
hear about convolutional neural networks
being very good at capturing translation

00:05:40.950 --> 00:05:40.960
being very good at capturing translation
 

00:05:40.960 --> 00:05:43.710
being very good at capturing translation
invariance and that's the observation

00:05:43.710 --> 00:05:43.720
invariance and that's the observation
 

00:05:43.720 --> 00:05:46.950
invariance and that's the observation
that a picture of a cat shifted a couple

00:05:46.950 --> 00:05:46.960
that a picture of a cat shifted a couple
 

00:05:46.960 --> 00:05:48.930
that a picture of a cat shifted a couple
pixels to the right is still pretty

00:05:48.930 --> 00:05:48.940
pixels to the right is still pretty
 

00:05:48.940 --> 00:05:52.560
pixels to the right is still pretty
clearly a cat and convolutional

00:05:52.560 --> 00:05:52.570
clearly a cat and convolutional
 

00:05:52.570 --> 00:05:55.620
clearly a cat and convolutional
structure helps tune your network and

00:05:55.620 --> 00:05:55.630
structure helps tune your network and
 

00:05:55.630 --> 00:05:59.310
structure helps tune your network and
code the fact that an image shifted a

00:05:59.310 --> 00:05:59.320
code the fact that an image shifted a
 

00:05:59.320 --> 00:06:01.290
code the fact that an image shifted a
few pixels should result in pretty

00:06:01.290 --> 00:06:01.300
few pixels should result in pretty
 

00:06:01.300 --> 00:06:03.740
few pixels should result in pretty
similar features and should probably be

00:06:03.740 --> 00:06:03.750
similar features and should probably be
 

00:06:03.750 --> 00:06:08.400
similar features and should probably be
assigned the same other label and the

00:06:08.400 --> 00:06:08.410
assigned the same other label and the
 

00:06:08.410 --> 00:06:09.719
assigned the same other label and the
fact that you're applying the same

00:06:09.719 --> 00:06:09.729
fact that you're applying the same
 

00:06:09.729 --> 00:06:12.210
fact that you're applying the same
filter you knows all the positions of

00:06:12.210 --> 00:06:12.220
filter you knows all the positions of
 

00:06:12.220 --> 00:06:14.969
filter you knows all the positions of
the image both in the early layers and

00:06:14.969 --> 00:06:14.979
the image both in the early layers and
 

00:06:14.979 --> 00:06:17.520
the image both in the early layers and
in the later layers that hopes a neural

00:06:17.520 --> 00:06:17.530
in the later layers that hopes a neural
 

00:06:17.530 --> 00:06:19.800
in the later layers that hopes a neural
network automatically learn to be with a

00:06:19.800 --> 00:06:19.810
network automatically learn to be with a
 

00:06:19.810 --> 00:06:22.830
network automatically learn to be with a
more robust or to capture to better

00:06:22.830 --> 00:06:22.840
more robust or to capture to better
 

00:06:22.840 --> 00:06:24.990
more robust or to capture to better
capture this desirable property of

00:06:24.990 --> 00:06:25.000
capture this desirable property of
 

00:06:25.000 --> 00:06:28.749
capture this desirable property of
translation in the area

00:06:28.749 --> 00:06:28.759
 

00:06:28.759 --> 00:06:31.700
so these are maybe a couple of reasons

00:06:31.700 --> 00:06:31.710
so these are maybe a couple of reasons
 

00:06:31.710 --> 00:06:34.189
so these are maybe a couple of reasons
why convolutions or compositional net

00:06:34.189 --> 00:06:34.199
why convolutions or compositional net
 

00:06:34.199 --> 00:06:36.439
why convolutions or compositional net
neural networks work so well in computer

00:06:36.439 --> 00:06:36.449
neural networks work so well in computer
 

00:06:36.449 --> 00:06:39.439
neural networks work so well in computer
vision finally let's put it all together

00:06:39.439 --> 00:06:39.449
vision finally let's put it all together
 

00:06:39.449 --> 00:06:41.629
vision finally let's put it all together
and see how you can train one of these

00:06:41.629 --> 00:06:41.639
and see how you can train one of these
 

00:06:41.639 --> 00:06:44.420
and see how you can train one of these
networks let's say you want to build a

00:06:44.420 --> 00:06:44.430
networks let's say you want to build a
 

00:06:44.430 --> 00:06:46.850
networks let's say you want to build a
CAD detector and you have a neighbor

00:06:46.850 --> 00:06:46.860
CAD detector and you have a neighbor
 

00:06:46.860 --> 00:06:50.080
CAD detector and you have a neighbor
training set as follows where now X is a

00:06:50.080 --> 00:06:50.090
training set as follows where now X is a
 

00:06:50.090 --> 00:06:54.439
training set as follows where now X is a
image and the Y's can be binary labels

00:06:54.439 --> 00:06:54.449
image and the Y's can be binary labels
 

00:06:54.449 --> 00:06:59.360
image and the Y's can be binary labels
or one of K classes and let's say you've

00:06:59.360 --> 00:06:59.370
or one of K classes and let's say you've
 

00:06:59.370 --> 00:07:01.550
or one of K classes and let's say you've
chosen a convolutional neural network

00:07:01.550 --> 00:07:01.560
chosen a convolutional neural network
 

00:07:01.560 --> 00:07:04.610
chosen a convolutional neural network
structure maybe saute the image and then

00:07:04.610 --> 00:07:04.620
structure maybe saute the image and then
 

00:07:04.620 --> 00:07:06.499
structure maybe saute the image and then
having you know convolutional and

00:07:06.499 --> 00:07:06.509
having you know convolutional and
 

00:07:06.509 --> 00:07:08.240
having you know convolutional and
pooling layers and then some fully

00:07:08.240 --> 00:07:08.250
pooling layers and then some fully
 

00:07:08.250 --> 00:07:10.610
pooling layers and then some fully
connected layers followed by a soft max

00:07:10.610 --> 00:07:10.620
connected layers followed by a soft max
 

00:07:10.620 --> 00:07:14.779
connected layers followed by a soft max
output that then outputs Y hat the

00:07:14.779 --> 00:07:14.789
output that then outputs Y hat the
 

00:07:14.789 --> 00:07:17.809
output that then outputs Y hat the
conflation and the fully connected

00:07:17.809 --> 00:07:17.819
conflation and the fully connected
 

00:07:17.819 --> 00:07:21.649
conflation and the fully connected
layers will have various parameters W as

00:07:21.649 --> 00:07:21.659
layers will have various parameters W as
 

00:07:21.659 --> 00:07:25.369
layers will have various parameters W as
well as biases B and so any setting of

00:07:25.369 --> 00:07:25.379
well as biases B and so any setting of
 

00:07:25.379 --> 00:07:27.350
well as biases B and so any setting of
the parameters therefore lets you define

00:07:27.350 --> 00:07:27.360
the parameters therefore lets you define
 

00:07:27.360 --> 00:07:30.680
the parameters therefore lets you define
a cost function similar to what we have

00:07:30.680 --> 00:07:30.690
a cost function similar to what we have
 

00:07:30.690 --> 00:07:33.189
a cost function similar to what we have
seen in their previous courses where

00:07:33.189 --> 00:07:33.199
seen in their previous courses where
 

00:07:33.199 --> 00:07:36.409
seen in their previous courses where
would randomly initialize parameters W

00:07:36.409 --> 00:07:36.419
would randomly initialize parameters W
 

00:07:36.419 --> 00:07:41.019
would randomly initialize parameters W
and B you can compute the cost J as the

00:07:41.019 --> 00:07:41.029
and B you can compute the cost J as the
 

00:07:41.029 --> 00:07:43.550
and B you can compute the cost J as the
sum of losses of your neural networks

00:07:43.550 --> 00:07:43.560
sum of losses of your neural networks
 

00:07:43.560 --> 00:07:46.269
sum of losses of your neural networks
predictions on your entire training set

00:07:46.269 --> 00:07:46.279
predictions on your entire training set
 

00:07:46.279 --> 00:07:51.409
predictions on your entire training set
may be divided by M so to train this

00:07:51.409 --> 00:07:51.419
may be divided by M so to train this
 

00:07:51.419 --> 00:07:53.959
may be divided by M so to train this
neural network all you need to do is

00:07:53.959 --> 00:07:53.969
neural network all you need to do is
 

00:07:53.969 --> 00:07:56.240
neural network all you need to do is
then use gradient descents or some other

00:07:56.240 --> 00:07:56.250
then use gradient descents or some other
 

00:07:56.250 --> 00:07:58.999
then use gradient descents or some other
algorithm like gradient descent or

00:07:58.999 --> 00:07:59.009
algorithm like gradient descent or
 

00:07:59.009 --> 00:08:02.869
algorithm like gradient descent or
momentum or armless problem or something

00:08:02.869 --> 00:08:02.879
momentum or armless problem or something
 

00:08:02.879 --> 00:08:05.329
momentum or armless problem or something
else in order to optimize all the

00:08:05.329 --> 00:08:05.339
else in order to optimize all the
 

00:08:05.339 --> 00:08:07.369
else in order to optimize all the
parameters of the new network to try to

00:08:07.369 --> 00:08:07.379
parameters of the new network to try to
 

00:08:07.379 --> 00:08:10.100
parameters of the new network to try to
reduce the cost function J and you find

00:08:10.100 --> 00:08:10.110
reduce the cost function J and you find
 

00:08:10.110 --> 00:08:12.079
reduce the cost function J and you find
that if you do this you can build a very

00:08:12.079 --> 00:08:12.089
that if you do this you can build a very
 

00:08:12.089 --> 00:08:15.730
that if you do this you can build a very
effective detector or some other

00:08:15.730 --> 00:08:15.740
effective detector or some other
 

00:08:15.740 --> 00:08:19.550
effective detector or some other
detector so

00:08:19.550 --> 00:08:19.560
detector so
 

00:08:19.560 --> 00:08:21.170
detector so
graduations on finishing this week's

00:08:21.170 --> 00:08:21.180
graduations on finishing this week's
 

00:08:21.180 --> 00:08:23.240
graduations on finishing this week's
videos you've now seen all the basic

00:08:23.240 --> 00:08:23.250
videos you've now seen all the basic
 

00:08:23.250 --> 00:08:24.800
videos you've now seen all the basic
building blocks of a convolutional

00:08:24.800 --> 00:08:24.810
building blocks of a convolutional
 

00:08:24.810 --> 00:08:26.600
building blocks of a convolutional
neural network and how to put them

00:08:26.600 --> 00:08:26.610
neural network and how to put them
 

00:08:26.610 --> 00:08:28.730
neural network and how to put them
together into an effective image

00:08:28.730 --> 00:08:28.740
together into an effective image
 

00:08:28.740 --> 00:08:31.220
together into an effective image
recognition system in this week's four

00:08:31.220 --> 00:08:31.230
recognition system in this week's four
 

00:08:31.230 --> 00:08:33.050
recognition system in this week's four
exercises I think all of these things

00:08:33.050 --> 00:08:33.060
exercises I think all of these things
 

00:08:33.060 --> 00:08:34.670
exercises I think all of these things
will come more concrete and you get the

00:08:34.670 --> 00:08:34.680
will come more concrete and you get the
 

00:08:34.680 --> 00:08:36.740
will come more concrete and you get the
chance to practice implementing these

00:08:36.740 --> 00:08:36.750
chance to practice implementing these
 

00:08:36.750 --> 00:08:38.959
chance to practice implementing these
things yourself and seeing it work for

00:08:38.959 --> 00:08:38.969
things yourself and seeing it work for
 

00:08:38.969 --> 00:08:39.620
things yourself and seeing it work for
yourself

00:08:39.620 --> 00:08:39.630
yourself
 

00:08:39.630 --> 00:08:42.019
yourself
next week we'll continue to go deeper

00:08:42.019 --> 00:08:42.029
next week we'll continue to go deeper
 

00:08:42.029 --> 00:08:43.760
next week we'll continue to go deeper
into convolutional neural networks I

00:08:43.760 --> 00:08:43.770
into convolutional neural networks I
 

00:08:43.770 --> 00:08:45.530
into convolutional neural networks I
mentioned earlier that there's just a

00:08:45.530 --> 00:08:45.540
mentioned earlier that there's just a
 

00:08:45.540 --> 00:08:46.730
mentioned earlier that there's just a
lot of hyper parameters and

00:08:46.730 --> 00:08:46.740
lot of hyper parameters and
 

00:08:46.740 --> 00:08:48.380
lot of hyper parameters and
convolutional neural networks so what I

00:08:48.380 --> 00:08:48.390
convolutional neural networks so what I
 

00:08:48.390 --> 00:08:50.570
convolutional neural networks so what I
want to do next week is show you a few

00:08:50.570 --> 00:08:50.580
want to do next week is show you a few
 

00:08:50.580 --> 00:08:52.250
want to do next week is show you a few
concrete examples of some of the most

00:08:52.250 --> 00:08:52.260
concrete examples of some of the most
 

00:08:52.260 --> 00:08:54.530
concrete examples of some of the most
effective convolutional neural networks

00:08:54.530 --> 00:08:54.540
effective convolutional neural networks
 

00:08:54.540 --> 00:08:56.269
effective convolutional neural networks
so you can start to recognize the

00:08:56.269 --> 00:08:56.279
so you can start to recognize the
 

00:08:56.279 --> 00:08:58.280
so you can start to recognize the
patterns that what types of network

00:08:58.280 --> 00:08:58.290
patterns that what types of network
 

00:08:58.290 --> 00:09:01.190
patterns that what types of network
architectures are effective and one

00:09:01.190 --> 00:09:01.200
architectures are effective and one
 

00:09:01.200 --> 00:09:03.170
architectures are effective and one
thing that people often do is just take

00:09:03.170 --> 00:09:03.180
thing that people often do is just take
 

00:09:03.180 --> 00:09:05.060
thing that people often do is just take
the architecture that someone else has

00:09:05.060 --> 00:09:05.070
the architecture that someone else has
 

00:09:05.070 --> 00:09:06.290
the architecture that someone else has
found and published in the research

00:09:06.290 --> 00:09:06.300
found and published in the research
 

00:09:06.300 --> 00:09:08.090
found and published in the research
paper and just use that for your

00:09:08.090 --> 00:09:08.100
paper and just use that for your
 

00:09:08.100 --> 00:09:10.490
paper and just use that for your
application and so by seeing some more

00:09:10.490 --> 00:09:10.500
application and so by seeing some more
 

00:09:10.500 --> 00:09:12.530
application and so by seeing some more
concrete examples next week you also

00:09:12.530 --> 00:09:12.540
concrete examples next week you also
 

00:09:12.540 --> 00:09:15.980
concrete examples next week you also
learn how to do that better and beyond

00:09:15.980 --> 00:09:15.990
learn how to do that better and beyond
 

00:09:15.990 --> 00:09:17.900
learn how to do that better and beyond
that makes people also just get better

00:09:17.900 --> 00:09:17.910
that makes people also just get better
 

00:09:17.910 --> 00:09:20.360
that makes people also just get better
intuitions about what makes confidence

00:09:20.360 --> 00:09:20.370
intuitions about what makes confidence
 

00:09:20.370 --> 00:09:22.820
intuitions about what makes confidence
work well and then in the rest of the

00:09:22.820 --> 00:09:22.830
work well and then in the rest of the
 

00:09:22.830 --> 00:09:25.370
work well and then in the rest of the
course we'll also see a variety of other

00:09:25.370 --> 00:09:25.380
course we'll also see a variety of other
 

00:09:25.380 --> 00:09:27.440
course we'll also see a variety of other
computer vision applications such as

00:09:27.440 --> 00:09:27.450
computer vision applications such as
 

00:09:27.450 --> 00:09:29.630
computer vision applications such as
object detection and neuro style

00:09:29.630 --> 00:09:29.640
object detection and neuro style
 

00:09:29.640 --> 00:09:31.610
object detection and neuro style
transfer how to create new forms of

00:09:31.610 --> 00:09:31.620
transfer how to create new forms of
 

00:09:31.620 --> 00:09:33.530
transfer how to create new forms of
artwork using these types of algorithms

00:09:33.530 --> 00:09:33.540
artwork using these types of algorithms
 

00:09:33.540 --> 00:09:36.170
artwork using these types of algorithms
so that's it for this week best of luck

00:09:36.170 --> 00:09:36.180
so that's it for this week best of luck
 

00:09:36.180 --> 00:09:38.329
so that's it for this week best of luck
with the homeworks and I look forward to

00:09:38.329 --> 00:09:38.339
with the homeworks and I look forward to
 

00:09:38.339 --> 00:09:41.240
with the homeworks and I look forward to
seeing you next week

