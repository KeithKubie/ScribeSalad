WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.208
ALBERT REYNAUD: Hi, everyone.

00:00:01.208 --> 00:00:02.260
Thank you for being here.

00:00:02.260 --> 00:00:05.280
I hope you are all
comfortably seated.

00:00:05.280 --> 00:00:06.900
So my name is Albert Reynaud.

00:00:06.900 --> 00:00:09.870
I work in the Android and Play
Business Development team,

00:00:09.870 --> 00:00:12.696
looking after app
developers across Europe,

00:00:12.696 --> 00:00:13.695
and I'm based in London.

00:00:17.160 --> 00:00:19.860
So today, as you
heard this morning,

00:00:19.860 --> 00:00:21.990
we've been kind of
announcing a few things.

00:00:21.990 --> 00:00:27.540
And we're kind of excited of
do all these announcements.

00:00:27.540 --> 00:00:30.030
We've been working really
hard over the past few months

00:00:30.030 --> 00:00:31.080
of bring--

00:00:31.080 --> 00:00:33.010
keep on innovating
within the console,

00:00:33.010 --> 00:00:34.560
trying to bring
new tools, trying

00:00:34.560 --> 00:00:38.040
to bring new functionalities
so you can then come back home

00:00:38.040 --> 00:00:40.860
and also start innovating.

00:00:40.860 --> 00:00:44.049
So we are really excited
about having you here.

00:00:44.049 --> 00:00:45.840
I hope you're enjoying
your stay in Valene.

00:00:45.840 --> 00:00:48.690
I hope you're enjoying
your day so far.

00:00:48.690 --> 00:00:51.210
And as you can see in
this innovation track,

00:00:51.210 --> 00:00:52.890
got a pretty packed agenda.

00:00:52.890 --> 00:00:55.770
We're going to start talking
about machine learning

00:00:55.770 --> 00:00:57.690
slash assistance topics.

00:00:57.690 --> 00:01:01.500
And then we're going
to discuss VR and have

00:01:01.500 --> 00:01:03.450
some kind of panel discussions.

00:01:03.450 --> 00:01:06.210
And we're finished with
sharing insights and research

00:01:06.210 --> 00:01:09.510
findings about design.

00:01:09.510 --> 00:01:13.860
So let's start with
the first presentation

00:01:13.860 --> 00:01:17.190
focused on machine learning that
I will be presenting together

00:01:17.190 --> 00:01:21.930
with Daniel from Memrise
and Hashim from IM.

00:01:21.930 --> 00:01:24.559
So earlier this
morning, Harsim gave you

00:01:24.559 --> 00:01:26.600
a presentation about
machine learning, giving you

00:01:26.600 --> 00:01:29.820
an overview of the key
principles of machine learning,

00:01:29.820 --> 00:01:34.770
as well as why we believe at
Google that this is important.

00:01:34.770 --> 00:01:37.590
In this session we'll try to
have a slightly different angle

00:01:37.590 --> 00:01:40.780
and try to give you insight
on the how as a developer,

00:01:40.780 --> 00:01:43.110
you should be approaching
it and thinking about it

00:01:43.110 --> 00:01:46.990
and also how some of your
peers have been approaching it

00:01:46.990 --> 00:01:49.770
recently within the app.

00:01:49.770 --> 00:01:53.362
So I know that machine learning,
artificial intelligence, you

00:01:53.362 --> 00:01:54.570
probably hear a lot about it.

00:01:54.570 --> 00:01:56.280
A lot of people talk about it.

00:01:56.280 --> 00:01:59.880
It's probably one of the
top buzz word of 2017.

00:01:59.880 --> 00:02:03.530
Probably a lot less people
are actually really doing

00:02:03.530 --> 00:02:06.990
and I'm sure that many of you
are kind of excitingly confused

00:02:06.990 --> 00:02:08.009
about it.

00:02:08.009 --> 00:02:11.670
But if you're here at least that
means that you are interested.

00:02:11.670 --> 00:02:15.030
Who in the room
is actually doing

00:02:15.030 --> 00:02:19.220
some kind of machine learning
related project within the app?

00:02:19.220 --> 00:02:22.010
OK so we got like
maybe good 20%.

00:02:22.010 --> 00:02:27.160
And who is considering it
for the next six, 12 months?

00:02:27.160 --> 00:02:29.306
So we got up to 50%.

00:02:29.306 --> 00:02:30.930
I hope that the end
of this talk, we're

00:02:30.930 --> 00:02:32.490
going to have more than 50%.

00:02:32.490 --> 00:02:34.420
But that's great.

00:02:34.420 --> 00:02:37.680
So in any case, as
Harsim mentioned,

00:02:37.680 --> 00:02:40.440
machine learning has become the
number one priority for Google.

00:02:40.440 --> 00:02:44.670
We're moving from a mobile first
world towards a AI first world.

00:02:44.670 --> 00:02:47.220
And the way I think
about it is sometimes

00:02:47.220 --> 00:02:49.300
kind of thinking about
five 10 years ago,

00:02:49.300 --> 00:02:52.670
all these companies that were
not really considering mobile

00:02:52.670 --> 00:02:54.570
seriously in their strategy.

00:02:54.570 --> 00:02:55.350
Right?

00:02:55.350 --> 00:02:57.990
And actually, the
success of many of you

00:02:57.990 --> 00:03:01.710
is linked to the fact that all
traditional players were not

00:03:01.710 --> 00:03:04.650
taking into their
strategy mobile seriously.

00:03:04.650 --> 00:03:07.070
And we hope that
you're not going

00:03:07.070 --> 00:03:10.870
to do the same mistake with
machine learning today.

00:03:10.870 --> 00:03:14.280
So machine learning
already a reality as we

00:03:14.280 --> 00:03:17.150
saw this morning from
kind of image recognition

00:03:17.150 --> 00:03:20.890
in Google Photos, content
recommendation on YouTube.

00:03:20.890 --> 00:03:24.870
Over 100 production
ready projects

00:03:24.870 --> 00:03:29.400
are actually using neural
network technology at Google.

00:03:29.400 --> 00:03:32.490
But you probably thinking right
now, yes, right this is great.

00:03:32.490 --> 00:03:34.920
But how does that
apply to me, right?

00:03:34.920 --> 00:03:35.640
I'm not Google.

00:03:35.640 --> 00:03:36.880
I don't have the resources.

00:03:36.880 --> 00:03:39.510
I don't have the
skills to do it.

00:03:39.510 --> 00:03:41.220
How should I be
thinking about it?

00:03:41.220 --> 00:03:43.235
And how should I
even get started?

00:03:43.235 --> 00:03:44.610
So during this
presentation we're

00:03:44.610 --> 00:03:47.190
going to try to get look
at the key aspects you

00:03:47.190 --> 00:03:49.530
should be considering
when thinking

00:03:49.530 --> 00:03:50.850
about machine learning.

00:03:50.850 --> 00:03:56.730
And starting by thinking, OK,
are you machine learning ready?

00:03:56.730 --> 00:04:01.320
OK so what are the key initial
conditions before taking up

00:04:01.320 --> 00:04:04.180
a machine learning project?

00:04:04.180 --> 00:04:06.480
So first of all, do
you have a problem?

00:04:06.480 --> 00:04:08.110
Sounds a bit silly.

00:04:08.110 --> 00:04:10.290
But this is probably one
of the most common mistake

00:04:10.290 --> 00:04:11.550
we observe in industry.

00:04:11.550 --> 00:04:14.160
People are looking
at what ML can

00:04:14.160 --> 00:04:17.594
do and try to kind of randomly
apply that to their business.

00:04:17.594 --> 00:04:20.010
However, you should take the
problem the other way around.

00:04:20.010 --> 00:04:21.990
You should look
at your problems--

00:04:21.990 --> 00:04:25.530
and not simple problem like
mission critical problems--

00:04:25.530 --> 00:04:27.420
and try to see how
machine learning can

00:04:27.420 --> 00:04:29.170
help you solve these problems.

00:04:29.170 --> 00:04:31.560
This is important
because you might end up

00:04:31.560 --> 00:04:34.500
building a great model, super
successful machine learning

00:04:34.500 --> 00:04:35.260
feature.

00:04:35.260 --> 00:04:38.400
But it's useless because it's
not actually solving a problem

00:04:38.400 --> 00:04:40.690
within your company.

00:04:40.690 --> 00:04:42.910
Once you have a problem,
obviously, you need data.

00:04:42.910 --> 00:04:43.868
You need a lot of data.

00:04:43.868 --> 00:04:46.460
You need a lot of quality
data, large volume.

00:04:46.460 --> 00:04:50.750
And you need to be able to kind
of access it and process it

00:04:50.750 --> 00:04:51.290
at scale.

00:04:51.290 --> 00:04:52.665
So that means that
you might have

00:04:52.665 --> 00:04:54.630
to go through a
process of improvement

00:04:54.630 --> 00:04:56.160
of your infrastructure.

00:04:56.160 --> 00:04:57.990
You might have to
clean your data.

00:04:57.990 --> 00:05:01.200
And you have to either think
about collecting labels

00:05:01.200 --> 00:05:02.890
for your data.

00:05:02.890 --> 00:05:04.770
And finally, you
need to identify

00:05:04.770 --> 00:05:07.770
the people that are going
to execute this project

00:05:07.770 --> 00:05:09.232
within your companies.

00:05:09.232 --> 00:05:11.190
And if you don't have
anyone, please don't feel

00:05:11.190 --> 00:05:12.150
discouraged right away.

00:05:12.150 --> 00:05:14.730
They are a lot of
resources online

00:05:14.730 --> 00:05:17.420
that are available to
everyone to train your teams.

00:05:17.420 --> 00:05:21.210
Of course there are UDCity,
YouTube and all that kind of--

00:05:21.210 --> 00:05:22.470
GitHub et cetera, et cetera.

00:05:22.470 --> 00:05:26.000
There's a lot of resources out
there that you can leverage.

00:05:26.000 --> 00:05:29.150
But ideally, in an ideal world,
what tend to recommend it's

00:05:29.150 --> 00:05:32.160
to combine two types of skills.

00:05:32.160 --> 00:05:34.970
On one hand, what we
call data scientists.

00:05:34.970 --> 00:05:38.400
So people that are able to kind
of conceptualize mathematical

00:05:38.400 --> 00:05:41.250
model that kind of takes
into account your business

00:05:41.250 --> 00:05:42.510
requirements.

00:05:42.510 --> 00:05:46.350
And on the other side, what
we call data engineers that

00:05:46.350 --> 00:05:49.780
translate this into code,
are able to train the model,

00:05:49.780 --> 00:05:52.237
and to run it on production.

00:05:52.237 --> 00:05:53.820
So at the beginning,
obviously, you're

00:05:53.820 --> 00:05:56.760
going to be kind of tapping into
whatever resources you have.

00:05:56.760 --> 00:05:58.650
But the more you
grow, the more we

00:05:58.650 --> 00:06:00.840
encourage you to think
about structuring this team

00:06:00.840 --> 00:06:03.990
into centralized
team that is then

00:06:03.990 --> 00:06:06.990
going to diffuse their knowledge
into the different division

00:06:06.990 --> 00:06:10.640
and process of the organization.

00:06:10.640 --> 00:06:12.190
So now you have a clear problem.

00:06:12.190 --> 00:06:13.690
You have skills.

00:06:13.690 --> 00:06:15.300
You have data.

00:06:15.300 --> 00:06:17.800
You need to start thinking
about choosing your model.

00:06:17.800 --> 00:06:21.250
Harsim this morning mentioned,
kind of described a few of them

00:06:21.250 --> 00:06:25.060
from image classification
to reinforcement learning

00:06:25.060 --> 00:06:26.380
within self-driving cars.

00:06:26.380 --> 00:06:28.570
You need to choose your
model and even maybe

00:06:28.570 --> 00:06:30.240
a combination of several models.

00:06:30.240 --> 00:06:33.520
And it's often where
the magic happens.

00:06:33.520 --> 00:06:37.210
One key aspect of it
is the presence or not

00:06:37.210 --> 00:06:39.410
of labels within your data.

00:06:39.410 --> 00:06:41.387
So in the example of
image recognition,

00:06:41.387 --> 00:06:42.970
you might have data
that will tell you

00:06:42.970 --> 00:06:46.060
the object that is present
within your image, right?

00:06:46.060 --> 00:06:49.360
But unfortunately, often
this might not be the case.

00:06:49.360 --> 00:06:51.610
In this case, you
might have to consider

00:06:51.610 --> 00:06:54.910
starting to collect
these labels or even

00:06:54.910 --> 00:06:57.820
think about choosing
another model that will not

00:06:57.820 --> 00:06:58.720
require these labels.

00:07:01.860 --> 00:07:04.890
A lot of companies in the
machine learning field

00:07:04.890 --> 00:07:08.820
believe in what we
call open research.

00:07:08.820 --> 00:07:11.310
So including Google,
including DeepMind,

00:07:11.310 --> 00:07:12.900
we believe in open research.

00:07:12.900 --> 00:07:15.390
This means that a
lot of the research

00:07:15.390 --> 00:07:18.420
finding, a lot of the libraries,
a lot of the models being

00:07:18.420 --> 00:07:22.380
developed are being published
online, available open source

00:07:22.380 --> 00:07:23.970
to everyone.

00:07:23.970 --> 00:07:26.280
This means that as
a developer, you

00:07:26.280 --> 00:07:30.720
would have to choose between
to what extension you will rely

00:07:30.720 --> 00:07:32.700
on existing models
and to what extent

00:07:32.700 --> 00:07:35.640
you will actually
develop your own models.

00:07:35.640 --> 00:07:38.070
So obviously at the
beginning we encourage

00:07:38.070 --> 00:07:42.390
you to tap as much as you can
into our existing libraries

00:07:42.390 --> 00:07:43.840
that are built.

00:07:43.840 --> 00:07:46.380
But quickly, you might realize
that this doesn't really

00:07:46.380 --> 00:07:48.120
fit exactly your needs.

00:07:48.120 --> 00:07:52.110
And you might have to
either train your own model

00:07:52.110 --> 00:07:55.730
with your own data, or even
build your own custom model.

00:07:58.920 --> 00:08:04.050
As far as Google
is concerned, we

00:08:04.050 --> 00:08:06.240
have this trade off
between simplicity

00:08:06.240 --> 00:08:10.440
and flexibility will
also kind of determine

00:08:10.440 --> 00:08:12.600
what technological
kind of solution

00:08:12.600 --> 00:08:13.700
you're going to be using.

00:08:13.700 --> 00:08:17.060
So as Google is
concerned, we can help you

00:08:17.060 --> 00:08:20.880
along the whole spectrum
with under ready to use side

00:08:20.880 --> 00:08:22.680
of the spectrum,
we got solutions

00:08:22.680 --> 00:08:25.530
like Google Cloud Machine
Learning APIs, which gives you

00:08:25.530 --> 00:08:28.410
Cloud Vision, speech,
and translates,

00:08:28.410 --> 00:08:33.270
and natural language of APIs,
as well as Action on Google

00:08:33.270 --> 00:08:35.370
that we're going
to be discussing

00:08:35.370 --> 00:08:37.390
in the next presentation.

00:08:37.390 --> 00:08:43.860
But if this is not enough,
one of the most commonly used

00:08:43.860 --> 00:08:46.100
framework by developer
is TensorFlow.

00:08:46.100 --> 00:08:47.610
Harsim mentioned
it this morning.

00:08:47.610 --> 00:08:53.130
It has become the most common
use machine learning framework.

00:08:53.130 --> 00:08:56.040
You can use it to build
your own custom model.

00:08:56.040 --> 00:08:57.960
You can use it to
train your own model.

00:08:57.960 --> 00:09:00.750
You have a lot of libraries
available out there.

00:09:00.750 --> 00:09:03.800
You can kind of run it on
different processing units

00:09:03.800 --> 00:09:06.610
on different Cloud
platform etc, cetera.

00:09:06.610 --> 00:09:09.450
And as Harsim
mentioned this morning

00:09:09.450 --> 00:09:12.360
we're going to be launching
soon TensorFlow Lite, which

00:09:12.360 --> 00:09:17.010
will enable running machine
learning models directly

00:09:17.010 --> 00:09:18.360
on device.

00:09:18.360 --> 00:09:21.990
With this, I will pass it
over to Memorize and IM,

00:09:21.990 --> 00:09:25.420
to Daniel and Harsim who are
going to share with you how

00:09:25.420 --> 00:09:27.510
they are doing approaching
machine learning

00:09:27.510 --> 00:09:28.577
within their own app.

00:09:28.577 --> 00:09:29.410
Thank you very much.

00:09:35.327 --> 00:09:36.160
DANIEL ZOHAR: Hello.

00:09:36.160 --> 00:09:37.140
Hi.

00:09:37.140 --> 00:09:38.440
So thank you very much, Albert.

00:09:38.440 --> 00:09:39.814
And thank you for
having us here.

00:09:39.814 --> 00:09:41.767
I think it's an
amazing conference.

00:09:41.767 --> 00:09:42.600
Thank you very much.

00:09:42.600 --> 00:09:45.790
So right.

00:09:45.790 --> 00:09:48.380
So my name is Daniel,
I'm the CT of Memrise.

00:09:48.380 --> 00:09:51.820
And if you don't Memrise, we're
one of the leading language

00:09:51.820 --> 00:09:56.500
learning apps in the world, with
over 25 million users and 200

00:09:56.500 --> 00:09:58.600
language combinations
to learn from.

00:09:58.600 --> 00:10:00.100
We really strive
to make language

00:10:00.100 --> 00:10:03.040
learning as joyful and
effective as possible.

00:10:03.040 --> 00:10:06.220
And very recently we won
the best app on Google Play.

00:10:06.220 --> 00:10:08.980
We're very proud of
this achievement.

00:10:08.980 --> 00:10:10.390
And today I'd like
to talk to you

00:10:10.390 --> 00:10:14.050
about how we build product
feature using machine learning.

00:10:14.050 --> 00:10:16.910
So I think Albert asked you guys
how many people are interested

00:10:16.910 --> 00:10:19.429
or playing around
with using machine

00:10:19.429 --> 00:10:20.470
learning to be a product.

00:10:20.470 --> 00:10:23.440
But how many of you actually
have delivered a product

00:10:23.440 --> 00:10:25.690
using machine learning?

00:10:25.690 --> 00:10:26.810
Right, so not as many.

00:10:26.810 --> 00:10:27.880
So it's obvious
that everybody is

00:10:27.880 --> 00:10:29.921
really excited about the
possibilities of machine

00:10:29.921 --> 00:10:31.360
learning.

00:10:31.360 --> 00:10:35.030
But it's not as easy to get
from having ideas and using

00:10:35.030 --> 00:10:37.810
technology to get
something out there.

00:10:37.810 --> 00:10:42.070
So we doing hackathons
on a regular basis,

00:10:42.070 --> 00:10:43.300
like every six weeks.

00:10:43.300 --> 00:10:44.920
And we really want
to give people

00:10:44.920 --> 00:10:48.100
time to play around with ideas
and technologies they think

00:10:48.100 --> 00:10:49.940
might work well in the product.

00:10:49.940 --> 00:10:52.070
And this particular
feature started as a hack.

00:10:52.070 --> 00:10:54.040
So we try to think,
OK, so what can we

00:10:54.040 --> 00:10:55.960
do with object recognition?

00:10:55.960 --> 00:10:57.820
And after a couple of
days with developer

00:10:57.820 --> 00:11:00.490
playing around with
that, they came up

00:11:00.490 --> 00:11:03.970
with a very neat concept,
which is turning the world

00:11:03.970 --> 00:11:05.380
into its own dictionary.

00:11:05.380 --> 00:11:07.960
So imagine taking your
phone, looking around,

00:11:07.960 --> 00:11:10.600
and if you learn German,
then you look at the screen.

00:11:10.600 --> 00:11:14.080
You learn how to say
screen or TV in German.

00:11:14.080 --> 00:11:15.490
And that was the idea.

00:11:15.490 --> 00:11:19.210
So once we had that in
place, after the hack,

00:11:19.210 --> 00:11:20.860
we thought, OK,
this is really cool.

00:11:20.860 --> 00:11:23.440
How can we take this and
actually make this something

00:11:23.440 --> 00:11:25.550
that we can give to our users?

00:11:25.550 --> 00:11:29.170
So then we started
looking at the product

00:11:29.170 --> 00:11:31.090
and tried to define it better.

00:11:31.090 --> 00:11:33.770
And what we knew we
want to have-- we

00:11:33.770 --> 00:11:36.492
want to make sure that it
is very accurate, because we

00:11:36.492 --> 00:11:37.450
teach people languages.

00:11:37.450 --> 00:11:38.830
We can't the wrong thing.

00:11:38.830 --> 00:11:41.580
It has to be the right
difficulty level.

00:11:41.580 --> 00:11:44.230
And it has to be really
fast and give like, oh wow.

00:11:44.230 --> 00:11:45.320
This is amazing.

00:11:45.320 --> 00:11:49.210
Really bringing the
technology forward.

00:11:49.210 --> 00:11:52.180
The interesting thing
is that actually getting

00:11:52.180 --> 00:11:55.245
machine learning model in
this particular case object

00:11:55.245 --> 00:11:58.579
recognition was
really the easy part.

00:11:58.579 --> 00:12:00.120
The most difficult
part was to get it

00:12:00.120 --> 00:12:02.217
to recognize the right things.

00:12:02.217 --> 00:12:04.300
So if you guys look at
that picture, what you see?

00:12:07.380 --> 00:12:08.297
So a guy, a man.

00:12:08.297 --> 00:12:09.880
if I look at that
picture, actually, I

00:12:09.880 --> 00:12:11.860
see James, who's one
of the people that

00:12:11.860 --> 00:12:13.270
worked on this project.

00:12:13.270 --> 00:12:15.130
Now we took this
image and we gave it

00:12:15.130 --> 00:12:19.030
to Google Vision ARP, which is
an amazing piece of technology.

00:12:19.030 --> 00:12:20.800
And this is what
it came up with.

00:12:20.800 --> 00:12:23.740
So hair, facial hair, beard.

00:12:23.740 --> 00:12:25.930
Well, this picture is
definitely very much fun.

00:12:25.930 --> 00:12:28.660
But I think that's not the
first thing when we look

00:12:28.660 --> 00:12:30.070
at the picture, we think it.

00:12:30.070 --> 00:12:32.650
So I think context is
really, really important.

00:12:32.650 --> 00:12:34.390
It's not about
recognizing object,

00:12:34.390 --> 00:12:36.580
it's recognizing
the right objects.

00:12:36.580 --> 00:12:42.520
And we spend most of the
time really focusing on that.

00:12:42.520 --> 00:12:46.990
So once after playing
around with a lot of models,

00:12:46.990 --> 00:12:48.550
and there are quite
a few out there,

00:12:48.550 --> 00:12:50.690
we actually decide to
train our own model.

00:12:50.690 --> 00:12:53.271
So the base was
using Inception V3,

00:12:53.271 --> 00:12:54.520
which is a model which exists.

00:12:54.520 --> 00:12:56.780
On top of that, we
trained our model.

00:12:56.780 --> 00:13:02.090
So what we actually did
is we got product managers

00:13:02.090 --> 00:13:05.560
to collect a lot of images.

00:13:05.560 --> 00:13:07.610
We first defined the
images that we care about.

00:13:07.610 --> 00:13:09.700
So we do a lot of user surveys.

00:13:09.700 --> 00:13:12.730
We try to understand how
our users use the app.

00:13:12.730 --> 00:13:14.950
And we know that often
time, for example, they

00:13:14.950 --> 00:13:16.670
use it at their homes.

00:13:16.670 --> 00:13:17.860
So we thought, well, OK.

00:13:17.860 --> 00:13:19.420
So which objects
are available in

00:13:19.420 --> 00:13:21.050
their immediate surroundings?

00:13:21.050 --> 00:13:23.260
So we try to define
that list of objects,

00:13:23.260 --> 00:13:24.640
which were in the 100s.

00:13:24.640 --> 00:13:28.270
And then start
collecting the images.

00:13:28.270 --> 00:13:31.640
And actually, our
product manager

00:13:31.640 --> 00:13:36.892
spend out of time collecting
images from different sources.

00:13:36.892 --> 00:13:38.350
And we found out
that, actually, we

00:13:38.350 --> 00:13:41.710
need quite a few examples,
like some objects needed more

00:13:41.710 --> 00:13:42.530
than others.

00:13:42.530 --> 00:13:45.000
For example, people's
eyes you can see here,

00:13:45.000 --> 00:13:47.380
there is one example has
a suggestion here which

00:13:47.380 --> 00:13:49.210
is not quite the hairdryer.

00:13:49.210 --> 00:13:54.190
Maybe he needs one so this was
an example of something which

00:13:54.190 --> 00:13:55.400
was a bit difficult.

00:13:55.400 --> 00:13:58.270
And as you can see there,
there is a picture of a bicycle

00:13:58.270 --> 00:13:59.470
and the picture of glasses.

00:13:59.470 --> 00:14:01.840
And they're both recognized
as glasses, something

00:14:01.840 --> 00:14:04.810
that we wouldn't imagine
that-- you would never

00:14:04.810 --> 00:14:06.610
look at the bicycle
and say its glasses.

00:14:06.610 --> 00:14:08.520
But it's actually
problems that emerge.

00:14:08.520 --> 00:14:10.870
And we had to do a
lot of back and forth,

00:14:10.870 --> 00:14:13.330
collecting more and
more images, focusing

00:14:13.330 --> 00:14:17.590
on amateur photography,
and also different sizes

00:14:17.590 --> 00:14:22.189
and shapes of the objects
that we really cared about.

00:14:22.189 --> 00:14:23.980
So there are a lot of
interesting examples,

00:14:23.980 --> 00:14:27.370
as you can see in the slides,
where there were problems.

00:14:27.370 --> 00:14:29.170
But by iterating
and understanding

00:14:29.170 --> 00:14:33.580
what it is that we
want to build and what

00:14:33.580 --> 00:14:35.620
we care about being
the final result,

00:14:35.620 --> 00:14:38.050
we came up with a
really neat product.

00:14:38.050 --> 00:14:40.990
So these are just a few images
from the finished product that

00:14:40.990 --> 00:14:43.810
actually recognized really nice
things like airplanes and stuff

00:14:43.810 --> 00:14:44.570
like that.

00:14:44.570 --> 00:14:47.350
And now we're in the process of
finding out how to integrate it

00:14:47.350 --> 00:14:50.020
best with our product.

00:14:50.020 --> 00:14:54.820
So just a few lessons
learned, I think like I said,

00:14:54.820 --> 00:14:57.760
I think even with a
really good model,

00:14:57.760 --> 00:15:00.560
different data sets really
equal different products.

00:15:00.560 --> 00:15:03.460
So like we saw in the
Google Vision API,

00:15:03.460 --> 00:15:04.880
it's not that it was wrong.

00:15:04.880 --> 00:15:08.320
It just didn't give us
what we wanted it to be.

00:15:08.320 --> 00:15:10.210
We really cared in our product.

00:15:10.210 --> 00:15:12.550
We wanted people to look
around them and learn

00:15:12.550 --> 00:15:14.200
how objects are
called, so really

00:15:14.200 --> 00:15:20.420
cared about single objects, how
the user is experiencing it.

00:15:20.420 --> 00:15:22.120
And additionally to
that, I just want

00:15:22.120 --> 00:15:24.100
to say that I think,
machine learning--

00:15:24.100 --> 00:15:26.207
I think as Albert said
as well-- it's a tool.

00:15:26.207 --> 00:15:28.040
You want to educate
people on how to use it.

00:15:28.040 --> 00:15:29.860
There's a lot of
resources out there.

00:15:29.860 --> 00:15:34.060
Educate your teams and try
to encourage them to use it.

00:15:34.060 --> 00:15:37.330
And try to find
the right problems

00:15:37.330 --> 00:15:39.790
that machine learning can solve.

00:15:39.790 --> 00:15:40.790
Thank you very much.

00:15:40.790 --> 00:15:42.740
And I'll hand it over
to Harsim from IM.

00:15:49.249 --> 00:15:50.540
HARSIMRAT SANDHAWALIA: Morning.

00:15:57.260 --> 00:16:00.780
So we're going to talk about
how we use machine learning

00:16:00.780 --> 00:16:08.610
at IM to help improve our
workflow for the photographers.

00:16:08.610 --> 00:16:10.260
And what is IM?

00:16:10.260 --> 00:16:13.040
So IM is a combination
of our community.

00:16:13.040 --> 00:16:14.551
So these are our
photographers, we

00:16:14.551 --> 00:16:16.050
have around 20
million photographers

00:16:16.050 --> 00:16:18.781
who upload their content
onto our platform.

00:16:18.781 --> 00:16:20.280
And we also have a
marketplace where

00:16:20.280 --> 00:16:21.750
people can sell
their photographs

00:16:21.750 --> 00:16:23.760
for Live Think,
which can be used

00:16:23.760 --> 00:16:28.290
by brands for their PR
campaign or advertisement.

00:16:28.290 --> 00:16:31.200
And to connect the
right photographer

00:16:31.200 --> 00:16:35.400
with the right buyer and
we build the technology.

00:16:35.400 --> 00:16:37.800
And the technology we
build is called IM Vision.

00:16:37.800 --> 00:16:41.130
So the IM Vision focuses
on understanding everything

00:16:41.130 --> 00:16:42.240
about a photograph.

00:16:42.240 --> 00:16:44.060
So what's inside a photograph?

00:16:44.060 --> 00:16:47.940
There's a dog jumping,
a dog leaping, a stick,

00:16:47.940 --> 00:16:51.930
a frozen lake,
atmosphere, outdoors.

00:16:51.930 --> 00:16:54.810
But we also want to know
how good the photograph is

00:16:54.810 --> 00:16:55.770
composed.

00:16:55.770 --> 00:16:59.400
How did that photograph uploaded
by any person on the web

00:16:59.400 --> 00:17:03.400
compare to the photographs taken
by professional photographers?

00:17:03.400 --> 00:17:06.060
And that's what we captured
through aesthetics.

00:17:06.060 --> 00:17:08.250
So we have a deep learning
model, a machine learning

00:17:08.250 --> 00:17:11.910
model, which can rate a
photograph a score between 0

00:17:11.910 --> 00:17:12.682
and 100.

00:17:12.682 --> 00:17:15.750
100 means that it is as
good by a professional photo

00:17:15.750 --> 00:17:17.190
photographer.

00:17:17.190 --> 00:17:23.040
And so the core of training
any machine learning model

00:17:23.040 --> 00:17:24.250
is the problem.

00:17:24.250 --> 00:17:27.000
The problem is the
problem you want to solve.

00:17:27.000 --> 00:17:29.820
And a machine learning
model needs an objective.

00:17:29.820 --> 00:17:31.530
And objective, in
this case, would

00:17:31.530 --> 00:17:34.800
be given a collection of
images, give me the right answer

00:17:34.800 --> 00:17:35.730
that I expect.

00:17:35.730 --> 00:17:38.230
And when you don't give
me the right answer,

00:17:38.230 --> 00:17:39.640
go correct yourself.

00:17:39.640 --> 00:17:42.510
So this is the feedback that
the machine learning model gets.

00:17:42.510 --> 00:17:45.870
And as you can imagine, the
more complicated your problem,

00:17:45.870 --> 00:17:48.810
the more complex your
model needs to be.

00:17:48.810 --> 00:17:51.270
And that complexity
usually translates

00:17:51.270 --> 00:17:56.520
into the size of the model
in megabytes or gigabytes.

00:17:56.520 --> 00:17:59.310
And that's a concern when
you want to go mobile.

00:17:59.310 --> 00:18:02.310
So if you want to run machine
learning model on mobile,

00:18:02.310 --> 00:18:05.160
you are constrained on the
size of the machine learning

00:18:05.160 --> 00:18:08.590
model a phone can run
on a CPU or a GPU.

00:18:08.590 --> 00:18:10.050
So that's an
additional constraint

00:18:10.050 --> 00:18:14.370
that the model has
to take into account.

00:18:14.370 --> 00:18:17.480
You can actually take
an existing large scale,

00:18:17.480 --> 00:18:19.620
big complexity model
and then shrink it

00:18:19.620 --> 00:18:21.570
down to the size you want.

00:18:21.570 --> 00:18:23.750
There are many
methods out there.

00:18:23.750 --> 00:18:25.710
Quantization and
compression is one.

00:18:25.710 --> 00:18:30.000
An analogy would be changing
a PND image into a JPEG image,

00:18:30.000 --> 00:18:32.100
for all practical purposes.

00:18:32.100 --> 00:18:35.160
Their visual quality is
similar, but the more attention

00:18:35.160 --> 00:18:38.320
you pay to the detail, you
start to see the cracks.

00:18:38.320 --> 00:18:40.480
And this is all and well.

00:18:40.480 --> 00:18:43.180
Once you have a
machine learning model

00:18:43.180 --> 00:18:47.650
that can run on the phone, it
can produce all the information

00:18:47.650 --> 00:18:49.570
we need to know about an image.

00:18:49.570 --> 00:18:51.940
You can detect the
tags, you can detect

00:18:51.940 --> 00:18:54.550
what's inside the photograph,
but you can also get a score--

00:18:54.550 --> 00:18:56.740
a score how good the
photo the photograph

00:18:56.740 --> 00:19:02.080
is composed compared to
professional photographers.

00:19:02.080 --> 00:19:03.820
And once we have all
of the information,

00:19:03.820 --> 00:19:08.530
the question is you can send
all the photographs to a AWS

00:19:08.530 --> 00:19:13.960
machine or a Google Cloud and
get all the answers you want.

00:19:13.960 --> 00:19:18.930
Why bother your miniaturizing
your machine learning model?

00:19:18.930 --> 00:19:20.740
What's the advantage?

00:19:20.740 --> 00:19:23.636
Why spend so much effort
into something that

00:19:23.636 --> 00:19:24.760
is already working for you?

00:19:27.570 --> 00:19:29.730
One key aspect is privacy.

00:19:29.730 --> 00:19:33.060
So in our case, we are
working with people's

00:19:33.060 --> 00:19:33.900
personal collection.

00:19:33.900 --> 00:19:35.190
So it's your personal photos.

00:19:35.190 --> 00:19:37.560
It could be photos
of your partners.

00:19:37.560 --> 00:19:40.650
It could be pictures of your
kids or private moments.

00:19:40.650 --> 00:19:44.580
And it's very tedious to upload
the whole of your collection

00:19:44.580 --> 00:19:47.640
to Cloud and get it
analyzed by the algorithm.

00:19:47.640 --> 00:19:50.230
And the second key aspect
is that the current

00:19:50.230 --> 00:19:53.130
functionalities that multiple
people upload their photos

00:19:53.130 --> 00:19:55.590
and they go to a single server.

00:19:55.590 --> 00:19:58.550
But with mobile phones, we
have a perfect scenario.

00:19:58.550 --> 00:20:00.870
We have one user and
one computing machine--

00:20:00.870 --> 00:20:02.770
the handheld device.

00:20:02.770 --> 00:20:06.422
And the third reason is
it's available everywhere.

00:20:06.422 --> 00:20:08.380
You don't need to be
connected to the internet.

00:20:08.380 --> 00:20:10.510
You don't need to have Wi-Fi.

00:20:10.510 --> 00:20:13.990
And that makes sense, because
taking example of machine

00:20:13.990 --> 00:20:16.030
translation, you need
the translation the most

00:20:16.030 --> 00:20:18.490
when you're traveling abroad
when you don't have access

00:20:18.490 --> 00:20:20.836
to Instant or Wi-Fi.

00:20:20.836 --> 00:20:22.460
So you want your
machine learning model

00:20:22.460 --> 00:20:26.590
to be to be able
to run everywhere.

00:20:26.590 --> 00:20:30.330
So if you are a machine learning
engineer or a data scientist,

00:20:30.330 --> 00:20:32.160
that's your part of the problem.

00:20:32.160 --> 00:20:33.960
But this is a
problem half solved.

00:20:33.960 --> 00:20:37.230
Now it's the product
manager's turn

00:20:37.230 --> 00:20:39.180
to turn that into a feature.

00:20:39.180 --> 00:20:40.774
And that goes through
various cycles.

00:20:40.774 --> 00:20:43.440
Once you have a prototype-- that
could come through a hackathon,

00:20:43.440 --> 00:20:45.780
that could come through
an internal effort--

00:20:45.780 --> 00:20:47.130
you build the first prototype.

00:20:47.130 --> 00:20:48.870
And you let the
PMs play with it.

00:20:48.870 --> 00:20:50.490
And they can think
about how they

00:20:50.490 --> 00:20:54.870
can use this machine
learning model in a feature.

00:20:54.870 --> 00:20:57.300
And that's the place where
either your client's team

00:20:57.300 --> 00:20:59.490
Android iOS and the
designer come together

00:20:59.490 --> 00:21:01.710
to build a specific feature.

00:21:01.710 --> 00:21:03.810
The next step is actually
getting user feedback.

00:21:03.810 --> 00:21:08.430
So let real users of the app or
the feature play with the model

00:21:08.430 --> 00:21:10.050
and get their feedback.

00:21:10.050 --> 00:21:14.820
And this is the critical
part of actually retraining

00:21:14.820 --> 00:21:16.720
your machine learning model.

00:21:16.720 --> 00:21:18.780
And collect a new data set.

00:21:18.780 --> 00:21:20.970
That new data set should
reflect the feedback

00:21:20.970 --> 00:21:22.710
that you get from real users.

00:21:22.710 --> 00:21:25.380
And the next stage is actually
retraining your machine

00:21:25.380 --> 00:21:28.470
learning model to better fit.

00:21:28.470 --> 00:21:31.307
With that in mind, we launched
a feature a few months ago,

00:21:31.307 --> 00:21:33.390
called EyeEm selects, which
runs our deep learning

00:21:33.390 --> 00:21:35.310
models on the phone.

00:21:35.310 --> 00:21:36.990
It analyzes all your
photo collection.

00:21:36.990 --> 00:21:38.880
You could have
thousands of photos.

00:21:38.880 --> 00:21:41.460
And then it suggest what
the best pictures you

00:21:41.460 --> 00:21:43.860
should upload to the platform.

00:21:43.860 --> 00:21:44.730
This makes sense.

00:21:44.730 --> 00:21:46.950
You don't want to upload
your private photos.

00:21:46.950 --> 00:21:50.165
And also if you're
a new user to IM,

00:21:50.165 --> 00:21:52.290
you see all the good photos
and good photographers,

00:21:52.290 --> 00:21:53.340
and you get intimidated.

00:21:53.340 --> 00:21:54.300
What should I upload?

00:21:54.300 --> 00:21:55.740
Am I good enough?

00:21:55.740 --> 00:21:57.150
This machine
learning model helps

00:21:57.150 --> 00:22:00.120
us help them find
the best photos they

00:22:00.120 --> 00:22:01.830
can upload onto our platform.

00:22:01.830 --> 00:22:03.670
And this entirely
runs on TensorFlow.

00:22:03.670 --> 00:22:05.910
We haven't yet moved
to TensorFlow Lite.

00:22:05.910 --> 00:22:10.310
But it's going to
come very soon.

00:22:10.310 --> 00:22:11.810
If you have a machine
learning model

00:22:11.810 --> 00:22:14.570
you can assess its performance
by various metrics.

00:22:14.570 --> 00:22:17.420
There is precision
recall, toughen accuracy.

00:22:17.420 --> 00:22:20.330
But you also want to
measure the performance

00:22:20.330 --> 00:22:23.480
based on how well your
target feature is.

00:22:23.480 --> 00:22:26.210
And in our case, we
wanted the users to upload

00:22:26.210 --> 00:22:29.360
not just more photos,
but also better photos.

00:22:29.360 --> 00:22:32.159
And so when a user
uploads a photo that

00:22:32.159 --> 00:22:33.950
is recommended by a
machine learning model,

00:22:33.950 --> 00:22:37.640
we automatically add a hashtag
to it called #EyeEmselects.

00:22:37.640 --> 00:22:41.270
And then we assess
how does that photos

00:22:41.270 --> 00:22:43.370
with that hashtag
compared to everything

00:22:43.370 --> 00:22:44.574
else we how in our platform.

00:22:44.574 --> 00:22:46.490
And we saw that people
were actually uploading

00:22:46.490 --> 00:22:50.160
better content over time.

00:22:50.160 --> 00:22:51.070
I think that's it.

00:22:51.070 --> 00:22:53.310
If you have questions
for us, please feel

00:22:53.310 --> 00:22:54.860
free.

