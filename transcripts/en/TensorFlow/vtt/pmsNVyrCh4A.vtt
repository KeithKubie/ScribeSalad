WEBVTT
Kind: captions
Language: en

00:00:00.547 --> 00:00:04.085
♪ (music) ♪

00:00:04.085 --> 00:00:06.227
Hi, everybody, and welcome
to <i>TensorFlow Meets.</i>

00:00:06.227 --> 00:00:09.673
It's my honor to be chatting
with Karmel Allison, Engineering Manager

00:00:09.673 --> 00:00:11.869
on TensorFlow today.

00:00:11.869 --> 00:00:13.947
Now, Karmel, you do all
of this outreach stuff,

00:00:13.947 --> 00:00:15.313
as well as engineering management.

00:00:15.313 --> 00:00:17.039
You had these video series on YouTube,

00:00:17.039 --> 00:00:18.804
you've done talks at conferences,

00:00:18.804 --> 00:00:21.448
and I know you did a great talk
at the TensorFlow Developer Summit.

00:00:21.448 --> 00:00:23.524
Can you tell us a little bit
about you, what you do,

00:00:23.524 --> 00:00:24.885
as well as all this great stuff.

00:00:24.885 --> 00:00:27.575
Yes, so as you mentioned,
I'm an Engineering Manager for TensorFlow.

00:00:27.575 --> 00:00:31.178
My team works on high-level APIs,
so that's Estimator and Keras.

00:00:31.178 --> 00:00:35.045
<i>And my talk at the Dev Summit this year
was about what we're bringing in 2.0</i>

00:00:35.045 --> 00:00:38.123
<i>for high-level APIs,
and, specifically, about Keras,</i>

00:00:38.123 --> 00:00:40.492
<i>and how that's the primary high-level API</i>

00:00:40.492 --> 00:00:43.672
<i>that we're consolidating
a lot of the things we have under,</i>

00:00:43.672 --> 00:00:46.138
and bringing the scale
of Estimator into Keras,

00:00:46.138 --> 00:00:47.859
and how we're going
to be doing that in 2.0.

00:00:47.859 --> 00:00:50.655
That's really interesting-- bringing
the scale of Estimator into Keras.

00:00:50.655 --> 00:00:52.853
I know there's going to be
tons of questions about that.

00:00:52.853 --> 00:00:54.889
One of the things
I thought was really interesting,

00:00:54.889 --> 00:00:55.975
was that you had this slide

00:00:55.975 --> 00:00:57.655
where there was
this "spot the difference."

00:00:57.655 --> 00:01:01.503
You had like training a DNN,
I think it was in Fashion-MNIST in 1.13,

00:01:01.503 --> 00:01:04.422
<i>and then, in 2.0, and there was
no difference between them.</i>

00:01:04.422 --> 00:01:06.930
<i>So, what's the real message behind that?</i>

00:01:06.930 --> 00:01:09.701
Yes, so François Chollet,
the creator of Keras,

00:01:09.701 --> 00:01:14.166
is really, really one of the champions
of the user experience,

00:01:14.166 --> 00:01:17.725
and he's done a great job of that
with the Keras API thus far,

00:01:17.725 --> 00:01:20.843
and we wanted to be able to keep that--
minimize, first of all, the overhead

00:01:20.843 --> 00:01:23.815
in having to convert for people
who're already using Keras,

00:01:24.142 --> 00:01:28.057
but also just to retain that simple API
as we move into 2.0.

00:01:28.057 --> 00:01:29.061
At the same time,

00:01:29.061 --> 00:01:33.384
we were able to bring everything
we're bringing to the table in 2.0,

00:01:33.384 --> 00:01:35.525
into that same model in Keras.

00:01:35.803 --> 00:01:39.654
So, that same model works
in Eager Mode and in Graph Mode,

00:01:39.654 --> 00:01:42.074
so the same one in 1.13
would be Graph Mode,

00:01:42.074 --> 00:01:43.771
but in 2.0, it's going to be
in Eager Mode,

00:01:43.771 --> 00:01:47.486
which allows you to more easily debug,
prototype, and all of that.

00:01:47.986 --> 00:01:50.478
It also works
with Distribution Strategies,

00:01:50.478 --> 00:01:51.484
with Feature Columns.

00:01:51.484 --> 00:01:54.319
There's all these different tools
and pieces that we're bringing in 2.0,

00:01:54.319 --> 00:01:56.438
we wanted to make sure
that same Keras API worked,

00:01:56.438 --> 00:01:57.582
as it does now.

00:01:57.582 --> 00:01:58.850
I see, okay, cool.

00:01:58.850 --> 00:02:00.688
Now, you've mentioned
Distribution Strategy.

00:02:00.688 --> 00:02:02.851
So one of the things,
it's not just making it easier

00:02:02.851 --> 00:02:04.243
for the coding part of the cycle,

00:02:04.243 --> 00:02:06.974
but the training part of the cycle
and being able to go big.

00:02:06.974 --> 00:02:09.739
So could you tell us a little bit
about what Distribution Strategy

00:02:09.739 --> 00:02:11.395
is all about and how it works?

00:02:11.395 --> 00:02:14.388
Yes, so Distribution Strategies
is a set of strategies,

00:02:14.388 --> 00:02:17.396
a set of ways to distribute your model.

00:02:17.396 --> 00:02:20.462
There are a number of them,
including <i>MirroredStrategy,</i>

00:02:20.462 --> 00:02:25.284
which is distribution across multiple GPUs
on the same device or on the same machine.

00:02:25.696 --> 00:02:28.198
There is also
<i>MultiWorkerMirroredStrategy</i>

00:02:28.198 --> 00:02:30.181
where you're mirroring
across multiple machines,

00:02:30.181 --> 00:02:31.965
all with their own devices.

00:02:31.965 --> 00:02:34.760
And we've also got coming
in the future <i>ParameterServerStrategy</i>

00:02:34.760 --> 00:02:37.275
which is going
to be distributing asynchronously

00:02:37.275 --> 00:02:38.936
across hundreds of nodes,

00:02:38.936 --> 00:02:41.074
which is the kind of training
we also do at Google.

00:02:42.369 --> 00:02:46.397
It's really exciting to build that in
as a simple API, a flexible API

00:02:46.397 --> 00:02:49.645
that works for DeepMind,
for Google researchers,

00:02:49.645 --> 00:02:55.553
but also for the people who are outside
of the TensorFlow repository right now.

00:02:56.677 --> 00:02:59.216
To make it easy to use,
but also really performant.

00:02:59.216 --> 00:03:01.305
There's a lot of work
that's gone in under the hood

00:03:01.305 --> 00:03:03.762
to make sure
that the scaling efficiency is really high

00:03:03.762 --> 00:03:05.553
even though the code stays simple.

00:03:05.553 --> 00:03:07.342
Nice, nice.
And now this becomes available

00:03:07.342 --> 00:03:09.781
- to almost anybody who wants to use it.
- Yes, we hope.

00:03:09.781 --> 00:03:11.501
You don't have to be a Googler.

00:03:11.501 --> 00:03:13.623
So now, I'm going to put you
on the spot for a minute,

00:03:13.623 --> 00:03:16.090
because this all great new stuff
that we've been talking about

00:03:16.090 --> 00:03:18.200
in TensorFlow 2.0--
do you have a favorite?

00:03:19.060 --> 00:03:23.138
I think some of the things
I'm most excited about are <i>tf.functions.</i>

00:03:23.138 --> 00:03:27.938
So, this is some of the magic
we're bringing in in Eager Execution,

00:03:27.938 --> 00:03:31.442
where you can actually
continue to use graph style code

00:03:31.442 --> 00:03:33.316
and get the performance
of graph style code,

00:03:33.316 --> 00:03:35.484
even though you are in Eager Execution.

00:03:35.484 --> 00:03:36.484
That's one thing.

00:03:36.484 --> 00:03:39.583
Another is what I just mentioned
which is <i>ParameterServerStrategy.</i>

00:03:39.583 --> 00:03:41.788
That's the way that we're
going to be able to distribute

00:03:41.788 --> 00:03:45.585
some of the largest workloads
we have at Google, using Keras models.

00:03:45.585 --> 00:03:48.476
And I know that there are a lot
of researchers, internal to Google

00:03:48.476 --> 00:03:51.252
and externally, at some
of the largest companies we work with.

00:03:51.252 --> 00:03:54.581
We're excited to be able to take
the same model they prototype

00:03:55.185 --> 00:03:58.280
and take it all the way
to production, training, and serving,

00:03:58.423 --> 00:04:00.110
using Distribution Strategies.

00:04:00.110 --> 00:04:01.996
That's something
I'm really excited about.

00:04:01.996 --> 00:04:04.089
Nice. It's hard to pick
just one favorite, right?

00:04:04.949 --> 00:04:06.606
- Thank you so much, Karmel!
- Thank you!

00:04:06.606 --> 00:04:08.670
This has been,
as always, very informative,

00:04:08.670 --> 00:04:12.092
and if you've got any questions for me,
or if you've any questions for Karmel,

00:04:12.092 --> 00:04:13.896
please, just leave them
in the <i>Comments</i> below.

00:04:13.896 --> 00:04:16.376
And whatever you do, don't forget
to hit that <i>Subscribe</i> button,

00:04:16.376 --> 00:04:18.414
so you'll be able to see
the rest of Karmel's videos

00:04:18.414 --> 00:04:19.437
right here, on YouTube.

00:04:19.437 --> 00:04:20.438
Thank you.

00:04:20.438 --> 00:04:22.167
♪ (music) ♪

