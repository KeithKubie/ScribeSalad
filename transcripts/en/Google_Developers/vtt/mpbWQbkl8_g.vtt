WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.465
[MUSIC PLAYING]

00:00:26.730 --> 00:00:30.195
[APPLAUSE]

00:00:40.095 --> 00:00:42.450
MALE SPEAKER: Ladies and
gentlemen, Regina Dugan,

00:00:42.450 --> 00:00:44.830
Vice President of Engineering,
Advanced Technology,

00:00:44.830 --> 00:00:46.450
and Projects at Google.

00:00:46.450 --> 00:00:49.845
[APPLAUSE]

00:00:53.730 --> 00:00:59.150
REGINA DUGAN: One year
ago, on June 26, 2014,

00:00:59.150 --> 00:01:04.140
you met ATAP, a small
band of pirates trying

00:01:04.140 --> 00:01:11.050
to do epic shit by closing
the gap between what if

00:01:11.050 --> 00:01:13.310
and what is.

00:01:13.310 --> 00:01:16.590
A team that is mobile
first, lean and agile,

00:01:16.590 --> 00:01:19.770
open, optimized for speed.

00:01:19.770 --> 00:01:23.510
We wanted you to
know that about us,

00:01:23.510 --> 00:01:26.600
but what we wanted
you to remember

00:01:26.600 --> 00:01:34.410
about us is that ATAP is full
of doer-dreamers like you, who

00:01:34.410 --> 00:01:40.750
dare to try even when
it means we might fail,

00:01:40.750 --> 00:01:45.380
and that doing so is
terrifying and hard,

00:01:45.380 --> 00:01:51.320
because it is authentic and
human and scary to believe

00:01:51.320 --> 00:01:54.070
and dream and do.

00:01:54.070 --> 00:01:56.820
Now, we've spent a
year in that feeling.

00:01:56.820 --> 00:02:01.340
We are reminded every day that
we face a choice, play it safe

00:02:01.340 --> 00:02:02.840
or go for it.

00:02:02.840 --> 00:02:04.000
We push each other.

00:02:04.000 --> 00:02:05.900
We push ourselves.

00:02:05.900 --> 00:02:10.910
Because it's not easy,
but it is what matters.

00:02:10.910 --> 00:02:16.610
It's why I'm here, and I
suspect it's why you're back,

00:02:16.610 --> 00:02:19.270
why we all go back.

00:02:19.270 --> 00:02:25.230
And I don't mean to I/O. I
mean to that terrifying place

00:02:25.230 --> 00:02:30.740
where you take the risk
and you make something new.

00:02:30.740 --> 00:02:33.360
So we're going to go for it.

00:02:33.360 --> 00:02:35.010
No holding back.

00:02:35.010 --> 00:02:36.970
Welcome to ATAP.

00:02:36.970 --> 00:02:38.280
Game on.

00:02:38.280 --> 00:02:41.780
[APPLAUSE]

00:02:45.200 --> 00:02:45.700
All right.

00:02:45.700 --> 00:02:49.160
So what kind of trouble have
we made in the intervening 11

00:02:49.160 --> 00:02:50.700
months and three days?

00:02:50.700 --> 00:02:52.230
A lot.

00:02:52.230 --> 00:02:55.250
We've crashed more
than a few Aura phones,

00:02:55.250 --> 00:02:57.570
because that's what
happens when you're

00:02:57.570 --> 00:03:04.000
revving a new engine for a race
that is fast and worth winning.

00:03:04.000 --> 00:03:08.930
Add furious to fast, and you
get storytelling Justin Lin

00:03:08.930 --> 00:03:15.120
style, our first live action
360 degree Google's spotlight

00:03:15.120 --> 00:03:16.720
story.

00:03:16.720 --> 00:03:22.456
We're making a mobile movie
theater and it opens today.

00:03:22.456 --> 00:03:25.928
[APPLAUSE]

00:03:27.420 --> 00:03:30.560
Now we got a little impatient
with the false choice

00:03:30.560 --> 00:03:34.560
between the ever shrinking
screen size and rich user

00:03:34.560 --> 00:03:40.360
interactions, so we created
new materials for wearables.

00:03:40.360 --> 00:03:42.700
Now that would be
enough for today,

00:03:42.700 --> 00:03:45.860
but we're also going to
talk about our continuing

00:03:45.860 --> 00:03:48.810
efforts in
authentication, as we made

00:03:48.810 --> 00:03:51.200
the move from
tattoos to completely

00:03:51.200 --> 00:03:53.660
passive authentication.

00:03:53.660 --> 00:03:58.440
Our early results hint at a
time when passwords and PINs

00:03:58.440 --> 00:04:02.960
are considered the relics
of an inconvenient past.

00:04:02.960 --> 00:04:03.950
Yeah!

00:04:03.950 --> 00:04:06.346
Yeah.

00:04:06.346 --> 00:04:10.230
And we're going to show
you big mobile security

00:04:10.230 --> 00:04:15.510
in a very small micro package.

00:04:15.510 --> 00:04:20.350
Now to accomplish this, our
internal team of fewer than 100

00:04:20.350 --> 00:04:25.080
has built a global network
of partners measuring 1,000.

00:04:25.080 --> 00:04:27.750
In the last 11
months, the number

00:04:27.750 --> 00:04:34.190
of ATAP external partners
has grown from 305 to 514,

00:04:34.190 --> 00:04:40.510
from 22 countries to 27, from
three continents to five.

00:04:40.510 --> 00:04:47.880
That means every day in ATAP, on
average, we sign a new partner.

00:04:47.880 --> 00:04:53.460
That's innovation in
the open on steroids.

00:04:53.460 --> 00:04:56.500
We seek these
partnerships because we

00:04:56.500 --> 00:05:00.990
believe that the answer
is out there, somewhere,

00:05:00.990 --> 00:05:04.140
if we are humble
enough to find it.

00:05:04.140 --> 00:05:09.590
In every ATAP project we
see the inherent creativity

00:05:09.590 --> 00:05:12.760
of others at work, from
Oscar winning storytellers

00:05:12.760 --> 00:05:17.910
to system engineers,
musicians to mathematicians.

00:05:17.910 --> 00:05:21.510
Our lean internal
team gives us speed.

00:05:21.510 --> 00:05:24.090
Our external
partnerships give us

00:05:24.090 --> 00:05:29.700
scale and expertise not
available in our small team.

00:05:29.700 --> 00:05:35.090
Together we have the ability to
solve hard problems, problems

00:05:35.090 --> 00:05:38.690
you can't solve by yourself.

00:05:38.690 --> 00:05:42.550
You might say that
ATAP has the spirit

00:05:42.550 --> 00:05:46.230
of a startup, the
agility and scale

00:05:46.230 --> 00:05:51.810
that comes with a global network
of the best minds in the world,

00:05:51.810 --> 00:05:53.785
all with the daring of Google.

00:05:56.440 --> 00:05:57.520
OK.

00:05:57.520 --> 00:06:01.650
Now on the day that we released
the abstract for this breakout

00:06:01.650 --> 00:06:06.280
session, which as you
know, said jokingly

00:06:06.280 --> 00:06:08.030
we're going to introduce
wearables that we

00:06:08.030 --> 00:06:09.900
hope will blow your socks off.

00:06:09.900 --> 00:06:13.330
We mean this more literally
than you might think.

00:06:13.330 --> 00:06:18.890
That day the ATAP on reddit
went something like this,

00:06:18.890 --> 00:06:20.130
"Smart socks confirmed."

00:06:20.130 --> 00:06:23.090
[LAUGHTER]

00:06:23.090 --> 00:06:26.910
"What, is there a self
destruct feature?"

00:06:26.910 --> 00:06:35.160
"It just displays how smelly
your feet are on your watch..."

00:06:35.160 --> 00:06:39.110
Now, we've been talking about
wearables for two decades,

00:06:39.110 --> 00:06:40.570
maybe longer.

00:06:40.570 --> 00:06:44.590
And whenever I've seen a field
where many smart people have

00:06:44.590 --> 00:06:47.820
worked for a long time
and we've struggled

00:06:47.820 --> 00:06:50.840
for big breakthroughs,
it's been because there

00:06:50.840 --> 00:06:56.390
are some underlying scientific
principle that we're missing,

00:06:56.390 --> 00:07:01.330
and if we can find it, it
might unlock new strategies

00:07:01.330 --> 00:07:03.200
or opportunities.

00:07:03.200 --> 00:07:06.250
We asked this question
about wearables,

00:07:06.250 --> 00:07:10.900
and here's what we discovered,
a work from Paul Fitts.

00:07:10.900 --> 00:07:14.550
It was entitled "The Information
Capacity of the Human Motor

00:07:14.550 --> 00:07:15.810
System."

00:07:15.810 --> 00:07:19.070
It was written in June of 1954.

00:07:19.070 --> 00:07:22.910
That was six years after
Shannon's seminal work

00:07:22.910 --> 00:07:25.940
on information theory,
and many people

00:07:25.940 --> 00:07:28.870
were beginning to use
information theory

00:07:28.870 --> 00:07:33.570
to explain things that they
hadn't understood before.

00:07:33.570 --> 00:07:36.560
Now Fitts used
these basic concepts

00:07:36.560 --> 00:07:40.460
from Shannon's theory to
demonstrate that our brains

00:07:40.460 --> 00:07:44.340
and bodies combine to
create an information

00:07:44.340 --> 00:07:48.180
system with a certain capacity.

00:07:48.180 --> 00:07:50.820
Now, there were controversies
about this Fitts' work

00:07:50.820 --> 00:07:53.670
and nuances to it,
but that science

00:07:53.670 --> 00:07:57.460
taught us something
interesting about wearables.

00:07:57.460 --> 00:07:59.330
Let's look.

00:07:59.330 --> 00:08:03.640
If we look across the
x-axis as screen size,

00:08:03.640 --> 00:08:08.190
this is tablets,
smaller smartphones,

00:08:08.190 --> 00:08:12.280
against the y-axis-- this is the
load on the human motor cortex

00:08:12.280 --> 00:08:15.020
system, measured in
bits per second--

00:08:15.020 --> 00:08:18.210
and if we look at the dependency
between these two things

00:08:18.210 --> 00:08:20.870
for the human body, this
is what we discover.

00:08:20.870 --> 00:08:22.890
Now how did Fitts measure this?

00:08:22.890 --> 00:08:26.410
What he did is he took two
bars a certain thickness

00:08:26.410 --> 00:08:29.720
and a certain distance apart,
and he asked his subjects

00:08:29.720 --> 00:08:32.650
to tap between those two bars.

00:08:32.650 --> 00:08:35.919
Now, while they're thick and
far apart this tapping task

00:08:35.919 --> 00:08:36.830
is easy.

00:08:36.830 --> 00:08:38.770
And when they're thin
and close together,

00:08:38.770 --> 00:08:41.159
this tapping task is
hard, and that's what's

00:08:41.159 --> 00:08:44.280
represented by this red line.

00:08:44.280 --> 00:08:49.190
Now if we look at the limit that
is imposed by the system that

00:08:49.190 --> 00:08:52.100
goes from my shoulder to
the tip of my finger, which

00:08:52.100 --> 00:08:55.130
is the system that I use to
interact with most consumer

00:08:55.130 --> 00:08:58.400
electronics devices,
what I find is

00:08:58.400 --> 00:09:02.810
that it intersects this red
line in an interesting place.

00:09:02.810 --> 00:09:06.740
Now Ivan Poupyrev, he also
revisited this, and discovered

00:09:06.740 --> 00:09:08.850
something similar.

00:09:08.850 --> 00:09:11.580
Now what does this tell us?

00:09:11.580 --> 00:09:16.380
Right at that intersection,
we find the screen size

00:09:16.380 --> 00:09:18.720
of a smart watch.

00:09:18.720 --> 00:09:23.360
So what we learned from that is
that as the screen size shrinks

00:09:23.360 --> 00:09:25.870
to the point where we
can put it on our body,

00:09:25.870 --> 00:09:28.810
we are approaching the
limit of our ability

00:09:28.810 --> 00:09:31.230
to interact with it.

00:09:31.230 --> 00:09:34.690
Now, we have two projects that
Ivan will talk about today,

00:09:34.690 --> 00:09:37.210
Project Soli, which
seeks to break

00:09:37.210 --> 00:09:40.670
this tension by increasing
the bandwidth of the system

00:09:40.670 --> 00:09:44.200
that we use to interact,
and Project Jacquard,

00:09:44.200 --> 00:09:46.390
which seeks to create
a larger surface

00:09:46.390 --> 00:09:49.630
area in which we can interact.

00:09:49.630 --> 00:09:53.890
Now, Ivan has been working
on these technologies, ones

00:09:53.890 --> 00:09:56.940
that blends digital and
physical interactivity,

00:09:56.940 --> 00:09:59.990
for a good portion
of his career.

00:09:59.990 --> 00:10:03.210
And there are efforts to
ease the interaction burden

00:10:03.210 --> 00:10:05.050
through voice and
gesture, but Ivan

00:10:05.050 --> 00:10:08.340
is going to show you
something very different.

00:10:08.340 --> 00:10:12.090
Two projects, Project
Soli and Project Jacquard,

00:10:12.090 --> 00:10:14.860
which seek to break this
fundamental tension.

00:10:14.860 --> 00:10:15.360
Ivan.

00:10:15.360 --> 00:10:18.706
[APPLAUSE]

00:10:23.189 --> 00:10:24.230
IVAN POUPYREV: Thank you.

00:10:24.230 --> 00:10:26.860
Thank you.

00:10:26.860 --> 00:10:30.006
So let's talk
about Project Soli.

00:10:30.006 --> 00:10:32.180
Our hand is an
amazing instrument.

00:10:32.180 --> 00:10:34.950
It's very fast and
precise, particularly

00:10:34.950 --> 00:10:37.130
when we're using
tools that require

00:10:37.130 --> 00:10:39.920
full dexterity of our fingers.

00:10:39.920 --> 00:10:42.590
The sensitivity and accuracy
is very natural to us.

00:10:42.590 --> 00:10:44.060
We use it every day.

00:10:44.060 --> 00:10:45.376
We don't even notice it.

00:10:45.376 --> 00:10:47.000
But we're still are
not able to capture

00:10:47.000 --> 00:10:49.125
this sensitivity in
our user interfaces,

00:10:49.125 --> 00:10:51.790
which are still quite clunky.

00:10:51.790 --> 00:10:54.180
There are many reasons why
fingers and using fingers

00:10:54.180 --> 00:10:56.150
for manipulation is superior.

00:10:56.150 --> 00:10:57.890
For example, if you
measure the bandwidth

00:10:57.890 --> 00:11:00.730
from the cortex to the
tip of your fingers,

00:11:00.730 --> 00:11:03.560
it's 20 times the
bandwidth to the elbow.

00:11:06.090 --> 00:11:09.280
So what if we can capture
this power of fingers,

00:11:09.280 --> 00:11:11.550
these powerful capabilities
of hands and fingers,

00:11:11.550 --> 00:11:13.300
and use for user interaction?

00:11:13.300 --> 00:11:15.100
What kind of
interfaces can we build

00:11:15.100 --> 00:11:17.190
for wearables or other devices?

00:11:17.190 --> 00:11:20.370
I have been asking these
questions for a long time.

00:11:20.370 --> 00:11:23.050
Now, one approach is to
give everybody a tool.

00:11:23.050 --> 00:11:25.780
Give everybody a pen,
and go with that.

00:11:25.780 --> 00:11:27.000
Not scalable.

00:11:27.000 --> 00:11:30.670
What we propose instead is
that you use your hand motion

00:11:30.670 --> 00:11:35.255
vocabulary, familiar hand
motions you learn from tools

00:11:35.255 --> 00:11:39.592
you're using every day,
for the interaction.

00:11:39.592 --> 00:11:41.550
For example, we all
learned this motion, right?

00:11:41.550 --> 00:11:43.210
We use our mobile
phone all the time.

00:11:43.210 --> 00:11:45.930
We manipulate this every day.

00:11:45.930 --> 00:11:47.430
And we don't have
to learn it again.

00:11:47.430 --> 00:11:48.420
It's very intuitive.

00:11:48.420 --> 00:11:50.630
What if we remove
the mobile phone,

00:11:50.630 --> 00:11:54.450
and only leave the motion which
you already know, and then

00:11:54.450 --> 00:11:56.760
this motion-- decoupled
from the physical device,

00:11:56.760 --> 00:11:58.440
decoupled from
the mobile phone--

00:11:58.440 --> 00:12:00.430
can be used to
control other devices

00:12:00.430 --> 00:12:06.260
and becomes more generic input
modality for everything else?

00:12:06.260 --> 00:12:09.000
It doesn't have to be
only virtual touchpad.

00:12:09.000 --> 00:12:10.320
There's a multiple of motions.

00:12:10.320 --> 00:12:12.460
There's a broad vocabulary
of motions which

00:12:12.460 --> 00:12:14.480
can be created by your hand.

00:12:14.480 --> 00:12:17.510
Your hand can become
a variety of controls,

00:12:17.510 --> 00:12:22.680
such as a virtual dial, a
slider, or anything else.

00:12:22.680 --> 00:12:25.580
So note how haptic
feedback came naturally,

00:12:25.580 --> 00:12:30.600
because your hand provides you
haptic feedback while using it.

00:12:30.600 --> 00:12:33.330
So these are very powerful
physical metaphors

00:12:33.330 --> 00:12:35.320
which we're already
aware of, and they

00:12:35.320 --> 00:12:37.450
can form an interaction
vocabulary that

00:12:37.450 --> 00:12:40.900
can be applied to
multiple contexts of use

00:12:40.900 --> 00:12:42.470
for multiple devices.

00:12:42.470 --> 00:12:45.440
For example, you can use
your virtual touchpad

00:12:45.440 --> 00:12:49.710
to control the map on the watch,
or you can make a virtual dial

00:12:49.710 --> 00:12:53.140
to control your radio, volume on
the radio, go through stations.

00:12:53.140 --> 00:12:54.280
Multiple things you can do.

00:12:54.280 --> 00:12:57.160
So what we propose
is your hands can

00:12:57.160 --> 00:13:01.240
be complete self-contained
interface control, always

00:13:01.240 --> 00:13:04.715
with you, intuitive, easy to
use, and very, very ergonomic.

00:13:08.828 --> 00:13:12.125
[APPLAUSE]

00:13:13.080 --> 00:13:16.880
In fact, it can be the only
interface control and only

00:13:16.880 --> 00:13:20.510
interface device that you
would ever need for wearables.

00:13:20.510 --> 00:13:24.880
All physical controls
replaced by your hand.

00:13:24.880 --> 00:13:27.540
Now to accomplish
that we need a sensor,

00:13:27.540 --> 00:13:29.980
and not every sensor would work.

00:13:29.980 --> 00:13:31.980
What we need is a
sensor that can capture

00:13:31.980 --> 00:13:35.460
subtle little motions
of your fingers

00:13:35.460 --> 00:13:38.590
that are overlapped in 3D space.

00:13:38.590 --> 00:13:41.640
Because we want to put it
into the small devices,

00:13:41.640 --> 00:13:44.530
such as wearables, it has
to work through materials,

00:13:44.530 --> 00:13:46.990
it has to go through
materials, work day and night,

00:13:46.990 --> 00:13:49.830
and be small enough to
fit into the device.

00:13:49.830 --> 00:13:52.100
So we also don't want
to instrument the user.

00:13:52.100 --> 00:13:54.780
We don't want to put
things in your hand.

00:13:54.780 --> 00:13:57.650
So we have to go-- so we
looked at the electromagnetic

00:13:57.650 --> 00:14:00.470
spectrum, the entire one,
and we still couldn't

00:14:00.470 --> 00:14:01.760
find anything appropriate.

00:14:01.760 --> 00:14:03.540
You know, capacitive
sensing is very nice,

00:14:03.540 --> 00:14:05.760
but it cannot track 3D.

00:14:05.760 --> 00:14:08.690
Cameras would struggle
with overlapped fingers.

00:14:08.690 --> 00:14:10.830
However, in between
these two extremes,

00:14:10.830 --> 00:14:12.830
there's a sensor which
is almost perfect,

00:14:12.830 --> 00:14:17.960
would fit all our
requirements, and that's radar.

00:14:17.960 --> 00:14:21.030
The radar can do almost all
of that, all of the things

00:14:21.030 --> 00:14:24.020
I talked about,
fast, precise, can

00:14:24.020 --> 00:14:28.590
work through materials, all
of that, except for one thing.

00:14:28.590 --> 00:14:30.048
It doesn't fit in a watch.

00:14:30.048 --> 00:14:33.286
[LAUGHTER]

00:14:33.286 --> 00:14:35.160
And I have to make it
smaller, otherwise it's

00:14:35.160 --> 00:14:40.990
not going to be wearable,
and that's kind of hard.

00:14:40.990 --> 00:14:43.674
So we didn't have to start
with a dish, thankfully.

00:14:43.674 --> 00:14:44.840
This is our first prototype.

00:14:44.840 --> 00:14:47.682
It was about this
size, on a table.

00:14:47.682 --> 00:14:49.140
And then over the
course of time we

00:14:49.140 --> 00:14:51.770
worked with our partners
and industrial collaborators

00:14:51.770 --> 00:14:54.820
to go through many
prototypes like that.

00:14:54.820 --> 00:14:58.380
And today we have our
first gesture radar

00:14:58.380 --> 00:15:02.730
that is small enough to
fit into the wearable.

00:15:02.730 --> 00:15:03.330
Here it is.

00:15:03.330 --> 00:15:06.781
[APPLAUSE]

00:15:20.414 --> 00:15:21.330
A radar in the pocket.

00:15:24.070 --> 00:15:26.640
So this is a new category
of interaction sensors,

00:15:26.640 --> 00:15:29.390
running at 60 gigahertz,
that can capture

00:15:29.390 --> 00:15:34.420
the motion of your fingers and
hand in free space, touchless,

00:15:34.420 --> 00:15:39.080
at resolutions and speeds
not possible before.

00:15:39.080 --> 00:15:41.820
And you don't have to be
an RF engineer to use it.

00:15:41.820 --> 00:15:47.504
Everything is inside--
antennas, control electronics,

00:15:47.504 --> 00:15:48.670
and we can make it at scale.

00:15:51.636 --> 00:15:53.010
When we connect
it to a computer,

00:15:53.010 --> 00:16:01.217
we can run it at speeds up
to 10,000 frames per second.

00:16:01.217 --> 00:16:03.300
And because we have fast
and furious here at ATAP,

00:16:03.300 --> 00:16:06.530
as Regina mentioned, we went
from the first prototype

00:16:06.530 --> 00:16:09.050
to this chip I just
showed you in 10 months.

00:16:09.050 --> 00:16:12.396
[APPLAUSE]

00:16:17.180 --> 00:16:20.370
So it's not only
hardware that matters.

00:16:20.370 --> 00:16:23.320
The real essence of the
radar, the reasons of it,

00:16:23.320 --> 00:16:25.530
is in the signal.

00:16:25.530 --> 00:16:26.950
So originally we
think about radar

00:16:26.950 --> 00:16:28.360
as something like an echo.

00:16:28.360 --> 00:16:30.420
You know, you send
the signal, it

00:16:30.420 --> 00:16:33.190
bounces back from the object,
come give you a signal return.

00:16:33.190 --> 00:16:35.730
However, to capture the
complexity of the hand

00:16:35.730 --> 00:16:38.450
motion, the close range,
what you would have to do,

00:16:38.450 --> 00:16:42.230
you would have to have narrow
beams scanning the entire hand

00:16:42.230 --> 00:16:45.840
in real time, which is very
expensive both hardware

00:16:45.840 --> 00:16:47.620
wise and computationally.

00:16:47.620 --> 00:16:51.350
We cannot do wearable
radar this way.

00:16:51.350 --> 00:16:53.790
Instead, what we do, we
illuminate the entire hand

00:16:53.790 --> 00:16:56.730
with a broad beam,
and the chip receives

00:16:56.730 --> 00:16:59.570
signal of a complex
superposition of reflections

00:16:59.570 --> 00:17:01.170
from different
parts of your hand

00:17:01.170 --> 00:17:03.630
as it changes and
moves in space.

00:17:03.630 --> 00:17:05.800
And as the hand
moves, you can see

00:17:05.800 --> 00:17:08.290
that the shape of the
signal will change.

00:17:08.290 --> 00:17:10.589
So we track changes to
the signal, the change

00:17:10.589 --> 00:17:12.540
of the signal, and
estimate the shape

00:17:12.540 --> 00:17:16.400
of the hand from
the signal changes.

00:17:16.400 --> 00:17:17.859
And now, to explain
how it worked,

00:17:17.859 --> 00:17:19.190
I would like to
invite onto the stage

00:17:19.190 --> 00:17:21.670
Jaime Lien, our lead research
engineer and radar expert.

00:17:21.670 --> 00:17:25.072
[APPLAUSE]

00:17:27.990 --> 00:17:30.370
JAIME LIEN: Thank you Ivan.

00:17:30.370 --> 00:17:33.370
The radar signal contains a lot
of complexity and information

00:17:33.370 --> 00:17:36.080
about my hand when it's
in the field of view.

00:17:36.080 --> 00:17:37.740
We have a short
demonstration showing

00:17:37.740 --> 00:17:40.490
how we interpret and
extract this information

00:17:40.490 --> 00:17:42.970
for gesture sensing.

00:17:42.970 --> 00:17:46.030
Let's start with the raw radar
signal shown in this plot here.

00:17:48.920 --> 00:17:51.490
This one signal actually
contains a lot of information

00:17:51.490 --> 00:17:56.980
about my hand's size,
shape, pose, and dynamics.

00:17:56.980 --> 00:18:00.566
You can see how responsive
it is to any slight motion.

00:18:00.566 --> 00:18:02.440
So how do we capture
all of this information?

00:18:05.260 --> 00:18:08.410
We first transform the signal
into various representations

00:18:08.410 --> 00:18:11.290
which help us to visualize and
understand the radio waves'

00:18:11.290 --> 00:18:13.270
response to my hand.

00:18:13.270 --> 00:18:16.370
For example, on the left
in the range Doppler image,

00:18:16.370 --> 00:18:18.470
the specular reflections
off of my hand

00:18:18.470 --> 00:18:21.270
are mapped according to
velocity and distance.

00:18:21.270 --> 00:18:24.170
If I move my hand up and
down over the sensor,

00:18:24.170 --> 00:18:25.780
you can see this
little ball of energy

00:18:25.780 --> 00:18:28.530
tracking my motion very finely.

00:18:28.530 --> 00:18:31.060
And if I start
wiggling two fingers,

00:18:31.060 --> 00:18:33.200
suddenly we can resolve
two moving components

00:18:33.200 --> 00:18:35.540
instead of just one.

00:18:35.540 --> 00:18:37.450
Similarly, we have
other transformations

00:18:37.450 --> 00:18:40.210
which help us to interpret
immediate changes in the signal

00:18:40.210 --> 00:18:42.790
phase and amplitude,
as well as frequency

00:18:42.790 --> 00:18:45.280
dependent electromagnetic
phenomena which

00:18:45.280 --> 00:18:47.925
depend on my on my
hand's size and pose.

00:18:51.180 --> 00:18:52.730
From these signal
representations

00:18:52.730 --> 00:18:55.760
we can extract features which
directly measure my hand's

00:18:55.760 --> 00:18:57.215
characteristics and dynamics.

00:19:01.430 --> 00:19:02.930
These features are
fed into machine

00:19:02.930 --> 00:19:04.700
learning algorithms
which interpret them

00:19:04.700 --> 00:19:06.470
into gesture labels.

00:19:06.470 --> 00:19:11.030
And now, the sensor can tell
if I'm wiggling my fingers

00:19:11.030 --> 00:19:13.030
or holding still.

00:19:13.030 --> 00:19:18.920
[APPLAUSE]

00:19:18.920 --> 00:19:21.310
So you can see at each
stage of this pipeline,

00:19:21.310 --> 00:19:24.730
we abstract more and more from
the original radar signal as we

00:19:24.730 --> 00:19:27.460
extract more and more concrete
information about the gesture

00:19:27.460 --> 00:19:29.380
that I'm performing,
and we'll be making

00:19:29.380 --> 00:19:32.060
this entire pipeline available
to developers in the API

00:19:32.060 --> 00:19:33.201
that we're building.

00:19:33.201 --> 00:19:33.700
Thank you.

00:19:33.700 --> 00:19:34.760
[APPLAUSE]

00:19:34.760 --> 00:19:36.093
IVAN POUPYREV: Thank you, Jaime.

00:19:39.680 --> 00:19:42.600
So this is the world's
first radio frequency sensor

00:19:42.600 --> 00:19:45.650
for use for touch and
gesture interactions.

00:19:45.650 --> 00:19:48.040
So we talked about all
these small, tiny gestures.

00:19:48.040 --> 00:19:51.685
Let me try to show you
another demo where we actually

00:19:51.685 --> 00:19:52.310
try to do this.

00:19:52.310 --> 00:19:53.970
This is very early work.

00:19:53.970 --> 00:19:56.600
It's just off the-- Like,
we just finished a week ago,

00:19:56.600 --> 00:19:57.160
I guess, so--

00:20:00.430 --> 00:20:03.760
So first of all, there's the
detection of the hand, right?

00:20:03.760 --> 00:20:07.200
So the radar can detect the
presence, can lock in your hand

00:20:07.200 --> 00:20:10.110
or lock out from your hand,
can lock onto the hand.

00:20:10.110 --> 00:20:16.250
And now what I'm trying
to do is to control--

00:20:16.250 --> 00:20:20.365
directly map motion
of the hand--

00:20:20.365 --> 00:20:23.620
[APPLAUSE]

00:20:23.620 --> 00:20:25.630
See how precise it is.

00:20:25.630 --> 00:20:29.040
This is direct mapping,
where I map one to one.

00:20:29.040 --> 00:20:32.857
So even tiny motions like this
produce exact larger motions

00:20:32.857 --> 00:20:33.440
on the screen.

00:20:33.440 --> 00:20:35.380
So I can control this
little blob really,

00:20:35.380 --> 00:20:38.190
really precisely with just
tiny motions of my fingers.

00:20:41.530 --> 00:20:43.820
Now this was uninterpreted
motion of my hand, right,

00:20:43.820 --> 00:20:46.240
direct mapping from the
motion of the fingers

00:20:46.240 --> 00:20:47.602
to the control on the screen.

00:20:47.602 --> 00:20:49.310
So now we do some
simple interpretations,

00:20:49.310 --> 00:20:52.647
which allows you to do things,
controls, and gestures.

00:20:52.647 --> 00:20:53.980
I can do it really, really fast.

00:20:53.980 --> 00:20:57.180
[APPLAUSE]

00:20:59.610 --> 00:21:01.390
So this is on some of
the machine learning

00:21:01.390 --> 00:21:03.910
and intelligence we can build
into the user interfaces.

00:21:03.910 --> 00:21:05.890
What's exciting about
the radar is that we

00:21:05.890 --> 00:21:07.260
have multiple modalities.

00:21:07.260 --> 00:21:10.280
I can construct
gestures and distance.

00:21:10.280 --> 00:21:13.470
So in the next demo, I can
create multiple controls

00:21:13.470 --> 00:21:14.520
separated in space.

00:21:14.520 --> 00:21:17.170
For example in this
case, I can control

00:21:17.170 --> 00:21:22.105
hour-- what time is it-- I think
about 9:00 or something, no?

00:21:22.105 --> 00:21:23.960
OK, 10:00.

00:21:23.960 --> 00:21:27.342
And here we can control minutes.

00:21:27.342 --> 00:21:30.640
[APPLAUSE]

00:21:30.640 --> 00:21:33.413
And I could go back to hours
and control hours again,

00:21:33.413 --> 00:21:35.620
and I can control minutes again.

00:21:35.620 --> 00:21:38.680
I can do that all day.

00:21:38.680 --> 00:21:40.310
Now, let's not forget
this is not just

00:21:40.310 --> 00:21:43.450
a microsensor and micro
gesture sensor, right.

00:21:43.450 --> 00:21:45.940
It can do a lot of things.

00:21:45.940 --> 00:21:47.920
It can be a natural
gesture sensor.

00:21:47.920 --> 00:21:50.650
We made a small
game, a soccer game.

00:21:50.650 --> 00:21:54.162
I can push the ball.

00:21:54.162 --> 00:21:54.900
[APPLAUSE]

00:21:54.900 --> 00:21:55.400
Yay.

00:21:58.450 --> 00:22:01.630
I actually rigged this
game so I always win.

00:22:01.630 --> 00:22:02.980
I can't lose in this game.

00:22:05.550 --> 00:22:10.130
So, back to the project.

00:22:10.130 --> 00:22:14.380
So in Project Soli, our
what if became what is.

00:22:14.380 --> 00:22:16.550
We built a sensor
that's small enough

00:22:16.550 --> 00:22:18.860
to fit into the wearables,
a new sensor that

00:22:18.860 --> 00:22:21.330
would fit on the wearables,
but powerful enough

00:22:21.330 --> 00:22:23.090
to capture the
exquisite manipulation

00:22:23.090 --> 00:22:24.730
capabilities of your hand.

00:22:24.730 --> 00:22:28.247
It's a very powerful
and new sensor modality.

00:22:28.247 --> 00:22:29.830
We're working on
finalizing developing

00:22:29.830 --> 00:22:32.600
of the brand of the
board and software API.

00:22:32.600 --> 00:22:34.900
We'll then be applying to
release to developers later

00:22:34.900 --> 00:22:37.960
this year, so that you too
can begin to experiment

00:22:37.960 --> 00:22:39.650
and play with this
new sensor modality

00:22:39.650 --> 00:22:42.569
and create amazing things.

00:22:42.569 --> 00:22:46.020
[APPLAUSE]

00:22:48.000 --> 00:22:50.110
So let's move to
another project.

00:22:50.110 --> 00:22:52.720
As we you may remember from
the earlier slide which Regina

00:22:52.720 --> 00:22:55.070
showed with the graph,
there are two directions,

00:22:55.070 --> 00:22:57.710
one to increase the
capability of the sensors

00:22:57.710 --> 00:23:00.970
for the interfaces
through using faster

00:23:00.970 --> 00:23:03.902
and better manipulations,
interactions using our hand,

00:23:03.902 --> 00:23:05.610
and the second one,
to increase the space

00:23:05.610 --> 00:23:06.870
where we can interact.

00:23:06.870 --> 00:23:09.280
So let's talk about
Project Jacquard, which

00:23:09.280 --> 00:23:11.830
approaches this problem.

00:23:11.830 --> 00:23:13.465
So Project Jacquard
is about textiles.

00:23:16.330 --> 00:23:19.410
The idea for the project comes
from observing similarity

00:23:19.410 --> 00:23:21.015
between multitouch
panels that we use

00:23:21.015 --> 00:23:23.390
in mobile phones and textiles.

00:23:23.390 --> 00:23:25.850
Both are interlocking grids.

00:23:25.850 --> 00:23:27.480
Therefore, if we
can replace some

00:23:27.480 --> 00:23:32.000
of the yarns in the textile
with conductive yarns, what

00:23:32.000 --> 00:23:37.460
we can do is to weave
multitouch textile sensors.

00:23:37.460 --> 00:23:41.200
We can weave multitouch
panels, weave them.

00:23:41.200 --> 00:23:43.200
They are flexible,
colorful, tactile,

00:23:43.200 --> 00:23:45.460
made of silk, wool, cotton,
any other materials,

00:23:45.460 --> 00:23:47.280
like any other textile.

00:23:47.280 --> 00:23:51.590
You can weave interactive
deductive input devices.

00:23:51.590 --> 00:23:53.990
And if we make a garment
out of such textiles,

00:23:53.990 --> 00:23:56.760
it would be immediately
interactive and responsive,

00:23:56.760 --> 00:23:58.460
and you would not
call it a wearable.

00:23:58.460 --> 00:24:02.350
You would call it a jacket.

00:24:02.350 --> 00:24:05.020
So we have seen instances of
interactive garments before.

00:24:05.020 --> 00:24:06.050
People have done this.

00:24:06.050 --> 00:24:07.960
But we want to move
beyond novelty.

00:24:07.960 --> 00:24:11.550
We want to move beyond
the single case use cases.

00:24:11.550 --> 00:24:13.600
We want to make interactive
garments at scale,

00:24:13.600 --> 00:24:16.290
so everybody can make them
and everybody can buy them.

00:24:16.290 --> 00:24:17.950
And when you go
this direction, we

00:24:17.950 --> 00:24:19.710
have to think about
multiple clothes.

00:24:19.710 --> 00:24:23.020
We have to think about different
clothes from multiple brands.

00:24:23.020 --> 00:24:27.240
So we have to think about
making interactive textiles

00:24:27.240 --> 00:24:30.290
at the scale of the global
apparel fashion industry, which

00:24:30.290 --> 00:24:35.070
sells 19 billion garments a
year, which is 150 times more

00:24:35.070 --> 00:24:37.360
than mobile phones.

00:24:37.360 --> 00:24:40.776
We cannot expect the global
fashion industry to change just

00:24:40.776 --> 00:24:42.150
for us, even though
we're Google.

00:24:44.900 --> 00:24:47.780
We have to make interactive
garments possible

00:24:47.780 --> 00:24:51.140
using existing manufacturing
techniques and existing

00:24:51.140 --> 00:24:53.170
manufacturing supply chains.

00:24:53.170 --> 00:24:55.420
We have to adapt the
textile industry,

00:24:55.420 --> 00:24:57.670
so that every textile
mill in the world

00:24:57.670 --> 00:25:00.360
can weave interactive textiles.

00:25:00.360 --> 00:25:03.390
So can you really manufacture
interactive textiles--

00:25:03.390 --> 00:25:05.530
inductive garments, for
this reason-- at scale?

00:25:05.530 --> 00:25:06.510
So that's the question.

00:25:06.510 --> 00:25:07.740
We travelled the world.

00:25:07.740 --> 00:25:10.470
We went to multiple
countries, Japan, Europe.

00:25:10.470 --> 00:25:11.920
We learned about industry.

00:25:11.920 --> 00:25:13.760
We made friends.

00:25:13.760 --> 00:25:16.500
This is one of our
partner mills in Japan.

00:25:16.500 --> 00:25:19.630
It turned out that the very
basic fundamental technologies

00:25:19.630 --> 00:25:22.010
and materials that are
required to manufacture

00:25:22.010 --> 00:25:24.930
interactive textiles
simply are not available.

00:25:24.930 --> 00:25:26.580
You cannot buy
them off the shelf,

00:25:26.580 --> 00:25:30.430
so we had to invent them as we
were building the capability,

00:25:30.430 --> 00:25:32.750
starting with the
conductive yarns,

00:25:32.750 --> 00:25:35.260
conductive yarns that can
withstand the harsh industrial

00:25:35.260 --> 00:25:38.320
processes of textile
manufacturing, getting woven,

00:25:38.320 --> 00:25:42.230
burning textiles with open
fire, stretching, washing them,

00:25:42.230 --> 00:25:43.680
and pulling them
with metal claws.

00:25:43.680 --> 00:25:47.215
I said to myself, this is not
very friendly to electronics.

00:25:51.790 --> 00:25:53.620
So another problem was
the choice, a choice

00:25:53.620 --> 00:25:55.090
of colors of materials.

00:25:55.090 --> 00:25:57.630
This is an example of a
catalog of yarn swatches

00:25:57.630 --> 00:26:02.520
which textile designers
use when they make fabrics.

00:26:02.520 --> 00:26:05.810
This is the choice
of conductive yarns.

00:26:05.810 --> 00:26:09.174
Comes in one color, gray.

00:26:09.174 --> 00:26:10.590
And it's not even
that conductive.

00:26:14.560 --> 00:26:17.310
So we had to go and to
invent our own yarns, which

00:26:17.310 --> 00:26:19.240
you see in this
picture, not only that

00:26:19.240 --> 00:26:21.430
are hundreds of times
more conductive,

00:26:21.430 --> 00:26:25.960
they could withstand all
the burning and pulling

00:26:25.960 --> 00:26:29.090
forces of textile manufacturing,
all those conditions,

00:26:29.090 --> 00:26:31.240
but also look and
feel completely normal

00:26:31.240 --> 00:26:33.200
to a textile designer or to you.

00:26:33.200 --> 00:26:35.380
They look indistinguishable
from normal yarns.

00:26:35.380 --> 00:26:37.650
However, if you look at
them with a microscope,

00:26:37.650 --> 00:26:39.400
you will see that
in fact there are

00:26:39.400 --> 00:26:41.630
complex molecular
structures where

00:26:41.630 --> 00:26:44.880
highly conductive metallic
alloys are braided together

00:26:44.880 --> 00:26:48.990
with thin silk fibers to give
this yarn supreme strength

00:26:48.990 --> 00:26:51.080
and durability, and
at the same time

00:26:51.080 --> 00:26:54.020
we can make it in
multiple colors.

00:26:54.020 --> 00:26:56.920
So let me show a video of how
this textile-- how these yarns

00:26:56.920 --> 00:26:57.420
are made.

00:27:04.500 --> 00:27:06.355
So you can see from
the center, you

00:27:06.355 --> 00:27:09.730
can see the conductive core
comes in, and is braided around

00:27:09.730 --> 00:27:14.670
with a sleeve of additional
yarns, which gives it strength,

00:27:14.670 --> 00:27:17.842
but also can be of any color.

00:27:17.842 --> 00:27:19.175
It's a heavy industrial process.

00:27:19.175 --> 00:27:22.775
This is a very different
experience from programming.

00:27:26.200 --> 00:27:27.700
This is multiple
colors which we can

00:27:27.700 --> 00:27:30.370
produce with our
manufacturing approaches.

00:27:32.654 --> 00:27:34.820
Now, the challenge of
producing interactive textiles

00:27:34.820 --> 00:27:37.260
is also about connecting
them to the digital world.

00:27:37.260 --> 00:27:39.426
It's not just to make textile
and be happy about it,

00:27:39.426 --> 00:27:40.830
but you want to actually use it.

00:27:40.830 --> 00:27:43.580
So when we made the first
textile, we were very naive,

00:27:43.580 --> 00:27:45.540
and we just made this
whole thing interactive,

00:27:45.540 --> 00:27:48.280
all 20 meters of it.

00:27:48.280 --> 00:27:50.030
But this created a
connectivity problem.

00:27:50.030 --> 00:27:53.410
How do you take this textile
and connect it to electronics?

00:27:53.410 --> 00:28:00.780
So we tried brute force,
more brute force, then

00:28:00.780 --> 00:28:02.030
a little bit less brute force.

00:28:02.030 --> 00:28:03.571
But it still didn't
work, because you

00:28:03.571 --> 00:28:05.700
have to pull out each
of the yarns by hand,

00:28:05.700 --> 00:28:06.780
and it just doesn't work.

00:28:06.780 --> 00:28:09.582
So what we did, we went
back to the original idea,

00:28:09.582 --> 00:28:11.040
went back to the
craft, and thought

00:28:11.040 --> 00:28:15.300
how can you weave
interactive textiles in a way

00:28:15.300 --> 00:28:16.950
so it's easy to
connect electronics,

00:28:16.950 --> 00:28:18.920
not the other way around,
how does electronics

00:28:18.920 --> 00:28:20.820
attach to the textiles.

00:28:20.820 --> 00:28:25.200
So we went back to our partners
in the textile industry

00:28:25.200 --> 00:28:28.450
and figured out how can we can
weave our patches precisely

00:28:28.450 --> 00:28:32.410
where we want them to
be, to localize them,

00:28:32.410 --> 00:28:34.300
so the problem is
localized in one place

00:28:34.300 --> 00:28:37.057
not on 20 meters of textile.

00:28:37.057 --> 00:28:39.390
Or the [INAUDIBLE], which is
a three dimensional weaving

00:28:39.390 --> 00:28:41.565
technique, so we can change
directions of the yarn,

00:28:41.565 --> 00:28:44.430
going from the top surface
of the yarn to the bottom

00:28:44.430 --> 00:28:47.700
but then free float outside,
so that we can access them

00:28:47.700 --> 00:28:52.790
with tools and machines
required to make connections.

00:28:52.790 --> 00:28:56.230
At the same time, we're able to
keep the structure of textiles,

00:28:56.230 --> 00:28:59.420
the structure of
the yarns intact,

00:28:59.420 --> 00:29:02.270
so that we can connect the
yarns in the correct order.

00:29:02.270 --> 00:29:05.700
So the order of correct
connection is very important.

00:29:05.700 --> 00:29:07.962
So at the end we get
something like this,

00:29:07.962 --> 00:29:09.920
and that can be connected
to electronics really

00:29:09.920 --> 00:29:12.640
easily and without any effort.

00:29:12.640 --> 00:29:14.850
So let me show how interactive
textiles are woven.

00:29:14.850 --> 00:29:19.630
There are many,
many moving parts.

00:29:19.630 --> 00:29:21.980
This is one of our
partners, one of the experts

00:29:21.980 --> 00:29:23.860
in textile manufacturing
and textile design

00:29:23.860 --> 00:29:27.010
in Japan, one of the best ones.

00:29:27.010 --> 00:29:31.640
So you can see our yarn coming
in, our conductive yarn.

00:29:36.080 --> 00:29:39.410
And you see by weaving the
interactive panel coming out.

00:29:39.410 --> 00:29:41.010
This is our yarns inside.

00:29:41.010 --> 00:29:42.650
This is the woven
panel coming in.

00:29:42.650 --> 00:29:45.730
And we can place it anywhere
we want on a piece of textile,

00:29:45.730 --> 00:29:49.874
and we can do anything you like.

00:29:49.874 --> 00:29:51.290
So using this
established process,

00:29:51.290 --> 00:29:53.620
we can weave interactive
touch panels.

00:29:53.620 --> 00:29:54.860
They don't have to be gray.

00:29:54.860 --> 00:29:57.360
They can be any color and shape.

00:29:57.360 --> 00:30:00.530
Contemporary designs, there's
interactivity woven there.

00:30:00.530 --> 00:30:01.930
Classics.

00:30:01.930 --> 00:30:03.360
Transparent.

00:30:03.360 --> 00:30:04.610
Invisible.

00:30:04.610 --> 00:30:05.540
Stretchable.

00:30:05.540 --> 00:30:07.590
And of course we can
make it on any size.

00:30:07.590 --> 00:30:10.802
We can weave interactive
panels as large as you want.

00:30:10.802 --> 00:30:12.760
And now we can connect
the interactive textiles

00:30:12.760 --> 00:30:13.901
to the digital world.

00:30:13.901 --> 00:30:16.150
We can connect them and
control our devices with that.

00:30:16.150 --> 00:30:18.507
So let me show a
demo of how it works.

00:30:18.507 --> 00:30:20.090
First of all, let
me show the textile.

00:30:20.090 --> 00:30:22.360
This is a piece of textile
you so on the video.

00:30:22.360 --> 00:30:23.980
This is how it looks like.

00:30:23.980 --> 00:30:25.087
It's real.

00:30:25.087 --> 00:30:25.920
It's not-- you know.

00:30:25.920 --> 00:30:28.127
There you go.

00:30:28.127 --> 00:30:29.460
This is the back of the textile.

00:30:29.460 --> 00:30:33.260
You we can see we cut out
the yarns to separate them.

00:30:33.260 --> 00:30:34.910
And now I'll show how it works.

00:30:38.620 --> 00:30:40.850
You can see the green,
and as I approach it,

00:30:40.850 --> 00:30:43.400
you see the black square.

00:30:43.400 --> 00:30:44.300
Over here.

00:30:44.300 --> 00:30:46.020
Yeah, here you go.

00:30:46.020 --> 00:30:47.410
That is the interactive area.

00:30:47.410 --> 00:30:50.945
As I approach it in my
hand, you can see it moves.

00:30:50.945 --> 00:30:53.915
[APPLAUSE]

00:30:54.734 --> 00:30:56.150
So you actually
see the difference

00:30:56.150 --> 00:30:58.030
between our work
and a touch panel.

00:30:58.030 --> 00:31:00.980
Again, it's designed to
sense your entire hand,

00:31:00.980 --> 00:31:03.355
because you don't expect people
to use their fingers when

00:31:03.355 --> 00:31:05.050
they interact with
their clothes like this.

00:31:05.050 --> 00:31:06.716
But you also can use
fingers, of course.

00:31:06.716 --> 00:31:07.342
Here we go.

00:31:07.342 --> 00:31:09.330
[APPLAUSE]

00:31:09.330 --> 00:31:10.150
So you can draw.

00:31:10.150 --> 00:31:11.150
You can write something.

00:31:11.150 --> 00:31:16.730
A. You can do
multitouch like this.

00:31:16.730 --> 00:31:21.570
You can do the little waves
across the textile, like this.

00:31:21.570 --> 00:31:23.980
Different directions
like this, too.

00:31:23.980 --> 00:31:27.200
To wave to you-- wave at you.

00:31:27.200 --> 00:31:32.680
So we don't expect these
textiles to be replacement

00:31:32.680 --> 00:31:33.820
of the touchscreens.

00:31:33.820 --> 00:31:36.910
The material properties of the
cloth are completely different.

00:31:36.910 --> 00:31:39.470
It's something you can put on
your body, or on your couch,

00:31:39.470 --> 00:31:41.810
or on your pillow, or any
place you use textile.

00:31:41.810 --> 00:31:45.070
And then it becomes attractive,
not by precise manipulations,

00:31:45.070 --> 00:31:47.030
but using broad
gestures of your hand,

00:31:47.030 --> 00:31:49.387
when you just swipe across
and control anything

00:31:49.387 --> 00:31:50.470
you would like to control.

00:31:53.200 --> 00:31:56.250
So what we're doing right now--
switch back to the slides--

00:31:56.250 --> 00:31:58.330
we are building the
entire pipeline.

00:31:58.330 --> 00:32:00.000
We are going
through the textiles

00:32:00.000 --> 00:32:02.100
from the yarns to the
textile structures

00:32:02.100 --> 00:32:05.462
to connectors to wireless
connectivity, mobile systems,

00:32:05.462 --> 00:32:07.420
and then to applications
and services which you

00:32:07.420 --> 00:32:09.054
can control with the textiles.

00:32:09.054 --> 00:32:11.220
This is a website where you
can follow our progress.

00:32:11.220 --> 00:32:14.635
Please follow us
and let us know what

00:32:14.635 --> 00:32:16.970
you think, because what
we're trying to build

00:32:16.970 --> 00:32:19.500
is an ecosystem where people
can design applications

00:32:19.500 --> 00:32:21.880
for this technology and
build new services based

00:32:21.880 --> 00:32:27.160
on soft computing, soft,
flexible, textile computing.

00:32:27.160 --> 00:32:30.590
[APPLAUSE]

00:32:32.550 --> 00:32:35.410
Now, the story would not
be complete-- Oh, sorry,

00:32:35.410 --> 00:32:38.397
wrong clicker, here we go.

00:32:38.397 --> 00:32:40.480
So the story would not be
complete if you actually

00:32:40.480 --> 00:32:41.438
try to build a garment.

00:32:41.438 --> 00:32:43.140
How do we know that we succeed?

00:32:43.140 --> 00:32:45.872
And the only way to know
that, that you can succeed,

00:32:45.872 --> 00:32:48.080
is to actually make a
garment-- interactive garment--

00:32:48.080 --> 00:32:49.710
and we give it to
a tailor to do.

00:32:49.710 --> 00:32:50.670
Not yourself.

00:32:50.670 --> 00:32:52.850
Somebody else has to do it.

00:32:52.850 --> 00:32:56.840
So we went to
London, Savile Row.

00:32:56.840 --> 00:32:59.330
We had a long renowned
history of bespoke tailoring.

00:32:59.330 --> 00:33:02.500
We went to a tailor and gave
him interactive textile,

00:33:02.500 --> 00:33:05.540
rolls of interactive textiles,
and asked him to make a jacket.

00:33:05.540 --> 00:33:10.420
And that short movie
will show the experience.

00:33:10.420 --> 00:33:13.815
[MUSIC PLAYING]

00:33:22.070 --> 00:33:25.990
Creating jackets is a
200 year old tradition.

00:33:25.990 --> 00:33:28.950
It's a craft and art.

00:33:28.950 --> 00:33:32.030
People learn from
generation to generation.

00:33:32.030 --> 00:33:33.550
The tools and
materials, they don't

00:33:33.550 --> 00:33:38.120
change as much as we're used
to in our digital world.

00:33:38.120 --> 00:33:43.620
It's all about feeling
how you cut it,

00:33:43.620 --> 00:33:44.860
how it feels on your hands.

00:33:47.750 --> 00:33:49.220
So we gave them
the new material,

00:33:49.220 --> 00:33:50.230
our interactive textile.

00:33:50.230 --> 00:33:53.740
They were very excited,
because rarely in this industry

00:33:53.740 --> 00:33:57.726
something new and completely
different comes in.

00:33:57.726 --> 00:34:00.100
It's an industry built on
tradition and craft and respect

00:34:00.100 --> 00:34:01.940
for the craft and
respect for traditions.

00:34:01.940 --> 00:34:04.211
The brands we're working
with have been around

00:34:04.211 --> 00:34:05.960
for-- a lot of the
brands have been around

00:34:05.960 --> 00:34:09.859
for hundreds of years.

00:34:09.859 --> 00:34:11.900
This is connecting-- they
designed a little pouch

00:34:11.900 --> 00:34:12.858
to put the electronics.

00:34:15.090 --> 00:34:15.760
Close it in.

00:34:19.199 --> 00:34:21.570
It's a jacket come to life.

00:34:21.570 --> 00:34:26.325
Swipe across the sleeve
to make a phone call.

00:34:26.325 --> 00:34:28.579
[APPLAUSE]

00:34:28.579 --> 00:34:30.239
Your jacket has arrived.

00:34:30.239 --> 00:34:33.613
[APPLAUSE]

00:34:36.030 --> 00:34:39.190
And you can see this jacket
right here, me wearing it.

00:34:39.190 --> 00:34:42.424
[APPLAUSE]

00:34:44.739 --> 00:34:48.010
I actually quite like it.

00:34:48.010 --> 00:34:50.449
So it's about how to combine
technology and fashion,

00:34:50.449 --> 00:34:52.639
and making things
fashionable and beautiful.

00:34:52.639 --> 00:34:54.820
There's the answer.

00:34:54.820 --> 00:34:58.430
Now, we think about
Jacquard as a raw material

00:34:58.430 --> 00:35:03.050
that will make computation
part of the language which

00:35:03.050 --> 00:35:06.160
apparel designers and textile
designers and fashionistas

00:35:06.160 --> 00:35:06.730
speak.

00:35:06.730 --> 00:35:10.290
We want digital to be
just the same thing

00:35:10.290 --> 00:35:12.730
as quality of the yarns,
the color you use,

00:35:12.730 --> 00:35:15.070
how digital it is.

00:35:15.070 --> 00:35:16.480
And we cannot do
it by ourselves.

00:35:16.480 --> 00:35:20.390
We have to, and we wanted
to, work with creatives

00:35:20.390 --> 00:35:21.550
from the fashion industry.

00:35:21.550 --> 00:35:27.540
And today with us is our first
partner, a historic brand,

00:35:27.540 --> 00:35:31.560
sister San Francisco company.

00:35:31.560 --> 00:35:34.640
It was here long
before we arrived here.

00:35:34.640 --> 00:35:38.060
They came with the gold
rush and built a company

00:35:38.060 --> 00:35:42.310
by designing functional and
fashionable, highly innovative

00:35:42.310 --> 00:35:44.150
garments.

00:35:44.150 --> 00:35:48.560
Our partnership is a
continuation that tradition,

00:35:48.560 --> 00:35:49.420
and that's Levi's.

00:35:49.420 --> 00:35:52.864
[APPLAUSE]

00:35:56.320 --> 00:36:00.740
And I would like to introduce my
colleague, Paul Dillinger, head

00:36:00.740 --> 00:36:03.160
of global product innovation
from Levi Strauss company.

00:36:03.160 --> 00:36:04.306
[APPLAUSE]

00:36:04.306 --> 00:36:05.514
PAUL DILLINGER: Thanks, Ivan.

00:36:09.990 --> 00:36:10.550
Thank you.

00:36:10.550 --> 00:36:11.551
Thanks.

00:36:11.551 --> 00:36:12.050
Thanks.

00:36:12.050 --> 00:36:15.307
This is really, really exciting.

00:36:15.307 --> 00:36:17.515
As a kid, when I decided to
become a fashion designer

00:36:17.515 --> 00:36:21.200
at 12, this is not the company
I thought I would be keeping.

00:36:21.200 --> 00:36:24.500
I did not anticipate
playing in this sandbox

00:36:24.500 --> 00:36:25.390
with these pirates.

00:36:25.390 --> 00:36:26.790
This really-- this is great.

00:36:26.790 --> 00:36:29.170
And none of the future that
we're experiencing right now

00:36:29.170 --> 00:36:29.900
was imaginable.

00:36:29.900 --> 00:36:33.740
So science fiction,
not too long ago.

00:36:33.740 --> 00:36:36.480
This opportunity, this
extraordinary pioneering spirit

00:36:36.480 --> 00:36:40.625
that ATAP embodies, it makes
me think about our own history

00:36:40.625 --> 00:36:41.650
at Levi's.

00:36:41.650 --> 00:36:45.110
Levi Strauss was
a German immigrant

00:36:45.110 --> 00:36:47.140
who decided to go west
with the gold rush,

00:36:47.140 --> 00:36:50.520
like so many other people, to
find his fortune in California.

00:36:50.520 --> 00:36:53.880
And he was a dry goods
purveyor, selling the supplies

00:36:53.880 --> 00:36:57.490
to the miners going up into the
gold fields near Sutter's Mill.

00:36:57.490 --> 00:37:00.572
And the miners were
wearing cotton pants,

00:37:00.572 --> 00:37:02.030
right, and they
were falling apart.

00:37:02.030 --> 00:37:04.475
They were ripping at
these stress points.

00:37:04.475 --> 00:37:06.100
And there was this
point of innovation,

00:37:06.100 --> 00:37:08.520
where Levi Strauss and
his friend Jacob Davies

00:37:08.520 --> 00:37:11.110
discovered that if they could
use a copper rivet to create

00:37:11.110 --> 00:37:13.610
a point of strength where there
had been a point of weakness

00:37:13.610 --> 00:37:16.200
that they could
solve a real problem.

00:37:16.200 --> 00:37:18.140
And there's an
interesting symmetry here.

00:37:18.140 --> 00:37:20.220
The use of a metal
alloy, copper,

00:37:20.220 --> 00:37:23.540
from an unexpected place,
an unexpected technology,

00:37:23.540 --> 00:37:25.850
machine tools, creating
strengthened apparel.

00:37:25.850 --> 00:37:27.650
There's a nice
symmetry of innovation

00:37:27.650 --> 00:37:31.570
between what's happening here
at ATAP with Project Jacquard

00:37:31.570 --> 00:37:35.130
and what happened at Levi's
nearly 150 years ago.

00:37:35.130 --> 00:37:37.530
And I think if Levi Strauss
was here with us today,

00:37:37.530 --> 00:37:40.170
looking for the next
gold rush, there's

00:37:40.170 --> 00:37:44.070
a lot in common between Silicon
Valley and Sutter's Mill.

00:37:44.070 --> 00:37:46.760
We think about the optimism,
the creativity, the energy,

00:37:46.760 --> 00:37:50.380
the excitement around invention
that these two cultures share,

00:37:50.380 --> 00:37:53.480
and it's only appropriate that
these two great global brands

00:37:53.480 --> 00:37:55.440
rooted in San
Francisco come together

00:37:55.440 --> 00:37:57.150
for an exciting
opportunity like this.

00:37:57.150 --> 00:38:00.270
Now the question is why.

00:38:00.270 --> 00:38:03.570
You know, when you think
about the innovation,

00:38:03.570 --> 00:38:05.780
yes, the dazzling
opportunity that we

00:38:05.780 --> 00:38:07.580
see in this new technology.

00:38:07.580 --> 00:38:09.540
Yes, this great platform
that's been enabled.

00:38:09.540 --> 00:38:10.865
Yes, but why?

00:38:10.865 --> 00:38:12.240
I would think
about this, and all

00:38:12.240 --> 00:38:14.705
of us working on this project
would think about why.

00:38:14.705 --> 00:38:17.170
I mean, I'd be driving to work
in the morning thinking why,

00:38:17.170 --> 00:38:18.920
and some guy would cut
me off because he's

00:38:18.920 --> 00:38:20.040
texting while driving.

00:38:20.040 --> 00:38:23.420
I would think about why as
I'm biking around the city,

00:38:23.420 --> 00:38:26.450
struggling to get my navigation
function from my phone

00:38:26.450 --> 00:38:31.119
as I'm navigating the
grid of San Francisco.

00:38:31.119 --> 00:38:32.660
I'm sitting at dinner
and I'm looking

00:38:32.660 --> 00:38:35.140
at someone else at a sitting
across from their partner

00:38:35.140 --> 00:38:38.920
and their phone buried in
their-- up to their face.

00:38:38.920 --> 00:38:41.090
Phone to face, that's
a why right there.

00:38:41.090 --> 00:38:44.350
We live in a beautiful,
richly textured, real world,

00:38:44.350 --> 00:38:47.054
but at ever increasing
need and engagement

00:38:47.054 --> 00:38:48.720
with the digital
world, and these worlds

00:38:48.720 --> 00:38:50.780
exist with a certain tension.

00:38:50.780 --> 00:38:53.460
If there's a chance to enable
the clothes that we already

00:38:53.460 --> 00:38:57.870
love to help us facilitate
access to the best and most

00:38:57.870 --> 00:39:00.086
necessary of this digital
world while maintaining

00:39:00.086 --> 00:39:01.460
eye contact with
the person we're

00:39:01.460 --> 00:39:02.890
eating dinner with, right?

00:39:02.890 --> 00:39:03.990
This is a real value.

00:39:03.990 --> 00:39:07.974
[APPLAUSE]

00:39:08.970 --> 00:39:11.890
If we can deliver that value
in the form of the clothes

00:39:11.890 --> 00:39:15.190
that you as friends and fans
of this brand already love,

00:39:15.190 --> 00:39:17.390
that is a project worth doing.

00:39:17.390 --> 00:39:19.310
But as a fashion
designer, it's not

00:39:19.310 --> 00:39:22.560
really a project that I'm
entirely equipped to take on.

00:39:22.560 --> 00:39:26.140
We've got the genius pirates
at ATAP who can help us develop

00:39:26.140 --> 00:39:28.670
and deliver this platform,
and now we have all this great

00:39:28.670 --> 00:39:29.950
capability at Levi's.

00:39:29.950 --> 00:39:32.970
We've got experts in fabric
creation and supply chain.

00:39:32.970 --> 00:39:35.440
We've got designers who can
help us bring this form to life

00:39:35.440 --> 00:39:37.065
and the merchants
who can package it up

00:39:37.065 --> 00:39:39.630
and bring it to the consumer
in a really compelling way.

00:39:39.630 --> 00:39:41.400
But there's a third
creative constituency

00:39:41.400 --> 00:39:43.210
that we must activate.

00:39:43.210 --> 00:39:46.150
And so now, my friends, you
are all fashion designers

00:39:46.150 --> 00:39:47.220
along with us.

00:39:47.220 --> 00:39:47.750
[APPLAUSE]

00:39:47.750 --> 00:39:54.040
You have the-- We can tailor
a few specific applications

00:39:54.040 --> 00:39:56.010
for the exact
consumer that we know,

00:39:56.010 --> 00:39:58.410
but the real opportunity
is the creative unlock

00:39:58.410 --> 00:40:01.117
in this community to activate
this new platform in ways

00:40:01.117 --> 00:40:03.450
we have not had imagined, and
it's going to be iterative

00:40:03.450 --> 00:40:04.867
and it's going to
be fast and fun.

00:40:04.867 --> 00:40:07.366
And we've inviting you to come
along on this journey with us

00:40:07.366 --> 00:40:09.200
as the fashion
designers of the future

00:40:09.200 --> 00:40:12.180
to make something really special
happen with Project Jacquard.

00:40:12.180 --> 00:40:12.933
All right?

00:40:12.933 --> 00:40:13.433
[APPLAUSE]

00:40:13.433 --> 00:40:13.926
Yeah?

00:40:13.926 --> 00:40:14.419
Cool.

00:40:14.419 --> 00:40:14.919
Thank you.

00:40:17.731 --> 00:40:18.856
REGINA DUGAN: That's great.

00:40:22.320 --> 00:40:23.550
Thank you, Paul.

00:40:23.550 --> 00:40:28.610
And with us today is James
Curleigh, or JC as we know him,

00:40:28.610 --> 00:40:30.460
president of the Levi's brand.

00:40:30.460 --> 00:40:31.190
JC?

00:40:31.190 --> 00:40:34.536
[APPLAUSE]

00:40:36.930 --> 00:40:40.300
When I spoke to
JC this Wednesday,

00:40:40.300 --> 00:40:44.380
he told me that at Levi's they
were focused on two things,

00:40:44.380 --> 00:40:48.410
driving their iconic
brand and innovation.

00:40:48.410 --> 00:40:54.730
And last week, on the 142
year anniversary of the 501s,

00:40:54.730 --> 00:41:02.100
they found a 130-year-old
pair of Levi's from the 1880s.

00:41:02.100 --> 00:41:03.310
That's iconic.

00:41:03.310 --> 00:41:06.280
And this week, we
announce our partnership

00:41:06.280 --> 00:41:08.220
to work on new wearables.

00:41:08.220 --> 00:41:09.280
That's innovation.

00:41:09.280 --> 00:41:10.640
So congrats, JC.

00:41:10.640 --> 00:41:14.000
[APPLAUSE]

00:41:18.320 --> 00:41:21.910
Now, Ivan's project
makes it possible to have

00:41:21.910 --> 00:41:26.290
more intuitive interactions
with your mobile devices.

00:41:26.290 --> 00:41:29.720
But if you have to enter
a PIN or a password,

00:41:29.720 --> 00:41:35.730
it sort of spoils the mood,
because authentication sucks.

00:41:35.730 --> 00:41:38.140
Passwords suck.

00:41:38.140 --> 00:41:41.980
We forget them to
our frustration.

00:41:41.980 --> 00:41:45.370
We reuse them to our peril.

00:41:45.370 --> 00:41:48.990
We need better methods,
and squirrel noises

00:41:48.990 --> 00:41:50.362
are not scalable.

00:41:50.362 --> 00:41:53.100
[LAUGHTER]

00:41:53.100 --> 00:41:57.270
70% of users forget their
password once a month.

00:41:57.270 --> 00:42:00.470
We try, on average,
2.4 passwords

00:42:00.470 --> 00:42:02.400
before we have the right login.

00:42:02.400 --> 00:42:06.170
Humans are a bad
source of entropy,

00:42:06.170 --> 00:42:10.100
the entropy we need for
security, because we need

00:42:10.100 --> 00:42:13.540
patterns to remember things.

00:42:13.540 --> 00:42:15.960
In the last few years
we've seen the emergence

00:42:15.960 --> 00:42:18.980
of dedicated sensors
like fingerprint sensors.

00:42:18.980 --> 00:42:22.570
New phones have them, but
what if your phone doesn't?

00:42:22.570 --> 00:42:25.190
What if instead of
a single sensor,

00:42:25.190 --> 00:42:29.460
we could use a combination of
sensors that would allow you

00:42:29.460 --> 00:42:32.090
and your interactions
with the device

00:42:32.090 --> 00:42:35.460
to become your authentication?

00:42:35.460 --> 00:42:38.610
Your key stroke patterns--
not what you type,

00:42:38.610 --> 00:42:42.570
but how you type, your patterns
of speaking-- not what you say,

00:42:42.570 --> 00:42:45.500
but how you say it--
this combination,

00:42:45.500 --> 00:42:49.770
with local-only processing,
might provide not only stronger

00:42:49.770 --> 00:42:54.030
security guarantees, but
do so completely passively.

00:42:54.030 --> 00:42:57.940
And not as a binary
single, yes no score,

00:42:57.940 --> 00:43:00.960
but as a continuum of trust.

00:43:00.960 --> 00:43:03.580
This next frontier
of authentication

00:43:03.580 --> 00:43:06.730
moves the burdens of
PINs and passwords

00:43:06.730 --> 00:43:10.630
from the user to the
device itself, thereby

00:43:10.630 --> 00:43:15.030
trading human cycles
for machine cycles.

00:43:15.030 --> 00:43:17.810
Now, might we use advances
in machine learning

00:43:17.810 --> 00:43:21.110
to ensure that only you
can access your security

00:43:21.110 --> 00:43:23.230
sensitive information,
and do we have

00:43:23.230 --> 00:43:28.040
proof points that would lead us
to believe it's even possible?

00:43:28.040 --> 00:43:32.160
We saw promising results
from individual research labs

00:43:32.160 --> 00:43:33.350
across the globe.

00:43:33.350 --> 00:43:36.720
Single modalities, like
gait and keystroke patterns,

00:43:36.720 --> 00:43:40.210
but none even as secure
as a four digit PIN,

00:43:40.210 --> 00:43:44.170
and mostly demonstrated on
small, laboratory scale,

00:43:44.170 --> 00:43:45.480
data sets.

00:43:45.480 --> 00:43:49.420
We hypothesized, however,
that if they were sufficiently

00:43:49.420 --> 00:43:53.000
independent, they
might combine to offer

00:43:53.000 --> 00:43:57.110
authentication better than
fingerprints or even passwords.

00:43:57.110 --> 00:43:59.780
To solve for multimodal
authentication,

00:43:59.780 --> 00:44:02.470
though, we needed an
interdisciplinary research

00:44:02.470 --> 00:44:05.660
team, recruited from
13 universities,

00:44:05.660 --> 00:44:10.880
and a large comprehensive
data set for them to work on.

00:44:10.880 --> 00:44:15.110
Now, ATAP exists at the
intersection between a driving

00:44:15.110 --> 00:44:17.500
application and
ambitious science,

00:44:17.500 --> 00:44:20.580
and Deepak Chandra's
project, Project Abacus,

00:44:20.580 --> 00:44:23.370
has illustrated the
benefit of this commitment

00:44:23.370 --> 00:44:25.270
over the last year.

00:44:25.270 --> 00:44:29.790
We needed the ability to get
our partners in universities in

00:44:29.790 --> 00:44:34.320
to work with us faster than
the typical 9 to 12 months.

00:44:34.320 --> 00:44:39.170
So in June of 2013, we signed
a multi-university research

00:44:39.170 --> 00:44:42.790
agreement with eight of the
country's top universities.

00:44:42.790 --> 00:44:47.250
Last year at I/O, that
eight had turned into 16.

00:44:47.250 --> 00:44:52.180
This year, 16 is 33, including
international universities.

00:44:52.180 --> 00:44:57.260
We can now partner with any one
of them in less than 30 days,

00:44:57.260 --> 00:44:58.920
and we did.

00:44:58.920 --> 00:45:04.050
A team of 25 experts
from 16 institutions

00:45:04.050 --> 00:45:07.630
traveled from 10
countries to facilitate

00:45:07.630 --> 00:45:10.110
the cross-pollination of ideas.

00:45:10.110 --> 00:45:14.510
They joined us in Mountain View
for a 90 day intensive research

00:45:14.510 --> 00:45:15.550
sprint.

00:45:15.550 --> 00:45:19.350
Our data set was built
from 1,500 data donors

00:45:19.350 --> 00:45:22.470
who signed up to contribute
their smartphone sensor

00:45:22.470 --> 00:45:23.620
information.

00:45:23.620 --> 00:45:27.650
By the end of this study, we had
created a 40 terabyte research

00:45:27.650 --> 00:45:32.960
data set, as far as we know,
the largest of its kind.

00:45:32.960 --> 00:45:38.320
And we assembled 360 cores
across three clusters,

00:45:38.320 --> 00:45:40.910
pulled all of the power
from the first floor,

00:45:40.910 --> 00:45:44.880
and dropped power
from the second.

00:45:44.880 --> 00:45:46.960
The result?

00:45:46.960 --> 00:45:49.180
Proof of the hypothesis.

00:45:49.180 --> 00:45:52.440
A new method of
authentication that

00:45:52.440 --> 00:45:55.400
may prove to be
10-fold more secure

00:45:55.400 --> 00:45:59.130
than the best fingerprint
sensors, with only a software

00:45:59.130 --> 00:45:59.830
update.

00:45:59.830 --> 00:46:03.040
The hope is that we can
provide this level of security

00:46:03.040 --> 00:46:06.200
to millions of Android devices.

00:46:06.200 --> 00:46:09.360
And we want to move
beyond phone unlock

00:46:09.360 --> 00:46:12.310
to allow an application's
authentication

00:46:12.310 --> 00:46:17.900
needs to be individually
met using a system wide API.

00:46:17.900 --> 00:46:20.870
The result might look
something like this.

00:46:20.870 --> 00:46:24.800
Throughout your day, a
continuous trust score,

00:46:24.800 --> 00:46:29.340
running while you type, walk,
browse-- not what you do,

00:46:29.340 --> 00:46:32.540
but how you do it--
to allow access

00:46:32.540 --> 00:46:36.390
to a game, which might require
little or no authentication,

00:46:36.390 --> 00:46:39.970
or a banking app, which
might require much more,

00:46:39.970 --> 00:46:44.190
an authentication system
that accepts you and rejects

00:46:44.190 --> 00:46:48.470
impostors, in real
time, on device.

00:46:48.470 --> 00:46:50.280
Now on the right
side of the screen,

00:46:50.280 --> 00:46:52.890
you see two of our
researchers, Hung [? Tai ?]

00:46:52.890 --> 00:46:55.390
from Columbia
University and Sujeet,

00:46:55.390 --> 00:46:57.610
from the University of Illinois.

00:46:57.610 --> 00:47:00.710
They are using a
research debug interface

00:47:00.710 --> 00:47:03.790
to show you how this
system might detect

00:47:03.790 --> 00:47:06.910
an impostor through
differences in typing patterns

00:47:06.910 --> 00:47:09.180
and other signals.

00:47:09.180 --> 00:47:12.460
Now, these results are
hot off the sprint.

00:47:12.460 --> 00:47:16.480
So we're continuing development,
and hope that in the future,

00:47:16.480 --> 00:47:19.740
from high security
to low security,

00:47:19.740 --> 00:47:22.405
developers and
users will choose.

00:47:25.060 --> 00:47:27.740
Now, better
authentication is only

00:47:27.740 --> 00:47:31.280
part of the better
security story here.

00:47:31.280 --> 00:47:36.410
Project Vault is a hardware and
software isolated environment

00:47:36.410 --> 00:47:39.520
in the form of a microSD card.

00:47:39.520 --> 00:47:42.590
It can be used from
mobile to desktop

00:47:42.590 --> 00:47:45.230
to the internet of things.

00:47:45.230 --> 00:47:50.750
Mudge and his team have jammed
a security dedicated computer

00:47:50.750 --> 00:47:55.620
into a microSD card, with a
simple, driver free interface

00:47:55.620 --> 00:47:58.770
and a suite of
encryption primitives.

00:47:58.770 --> 00:48:04.230
Project Vault will enable secure
communications and storage,

00:48:04.230 --> 00:48:10.290
initially for enterprises,
eventually for individuals too.

00:48:10.290 --> 00:48:14.010
As our smartphones have
become more capable,

00:48:14.010 --> 00:48:17.310
the code that runs
them does too.

00:48:17.310 --> 00:48:22.410
Large code bases made
by humans have errors.

00:48:22.410 --> 00:48:25.440
Errors may be
exploited to place some

00:48:25.440 --> 00:48:27.750
of our most
important information

00:48:27.750 --> 00:48:31.770
at risk, like encryption
keys, sensitive documents,

00:48:31.770 --> 00:48:35.720
or the sensor parameters
that I just mentioned.

00:48:35.720 --> 00:48:39.840
There's an inherent
tension between the desire

00:48:39.840 --> 00:48:43.140
to create capability
and the ability

00:48:43.140 --> 00:48:48.350
to secure the very code that
drives those capabilities.

00:48:48.350 --> 00:48:50.390
Think of it like this.

00:48:50.390 --> 00:48:55.530
My home has windows and
doors, a porous boundary,

00:48:55.530 --> 00:49:00.470
which is necessary for people
and things to come and go.

00:49:00.470 --> 00:49:03.600
But those windows and
doors make it harder

00:49:03.600 --> 00:49:07.100
for me to protect
everything in the house.

00:49:07.100 --> 00:49:12.020
So I use a vault to store
the most sensitive documents.

00:49:12.020 --> 00:49:15.920
It cannot store all of
the contents of my house,

00:49:15.920 --> 00:49:21.200
but it can store my most
precious possessions.

00:49:21.200 --> 00:49:25.880
Project Vault is your
digital mobile safe.

00:49:25.880 --> 00:49:30.070
Big security, small package.

00:49:30.070 --> 00:49:33.680
Now, Mudge formerly
led the L0pht.

00:49:33.680 --> 00:49:36.880
That was the hacker group
that in 1998 famously

00:49:36.880 --> 00:49:39.080
testified to the Senate
that they could shut down

00:49:39.080 --> 00:49:41.580
the internet in 30 minutes.

00:49:41.580 --> 00:49:45.140
He was the original
author of L0phtCrack,

00:49:45.140 --> 00:49:49.150
the password cracking software
that drove operating system

00:49:49.150 --> 00:49:51.800
security for years thereafter.

00:49:51.800 --> 00:49:54.590
And project fault
is his program.

00:49:54.590 --> 00:49:55.240
Mudge?

00:49:55.240 --> 00:49:58.628
[APPLAUSE]

00:50:00.564 --> 00:50:03.952
PEITER "MUDGE" ZATKO: Thank you.

00:50:03.952 --> 00:50:06.390
Thanks.

00:50:06.390 --> 00:50:11.300
So Project Vault is a small
microSD form factor device.

00:50:11.300 --> 00:50:15.100
It's a separate
ultra-secure mini computer.

00:50:15.100 --> 00:50:17.280
You plug into any system
that has a microSD card

00:50:17.280 --> 00:50:19.820
slot or an SD card
slot, and make

00:50:19.820 --> 00:50:22.140
use of the suite of
cryptographic services

00:50:22.140 --> 00:50:25.395
to manage your data needs,
from encrypting data at rest

00:50:25.395 --> 00:50:27.960
to encrypting
streaming end to end

00:50:27.960 --> 00:50:32.290
communications, like
messaging, voice, and video.

00:50:32.290 --> 00:50:35.220
Only you can unlock it, and any
information and the algorithms

00:50:35.220 --> 00:50:38.670
inside Project Vault are
never exposed to the system

00:50:38.670 --> 00:50:40.670
that you plug it into.

00:50:40.670 --> 00:50:43.050
So the question
is, why build this,

00:50:43.050 --> 00:50:47.500
and why a microSD form factor?

00:50:47.500 --> 00:50:51.120
It turns out you already
have security elements

00:50:51.120 --> 00:50:55.010
in your phones and your
computers, SIM cards.

00:50:55.010 --> 00:50:57.590
They protect the things that
are important to the carriers,

00:50:57.590 --> 00:51:00.290
trusted platform
modules, or TPMs.

00:51:00.290 --> 00:51:02.750
They protect the things that
are important to the OEMs

00:51:02.750 --> 00:51:04.960
and the content providers.

00:51:04.960 --> 00:51:07.620
These are services with very
low bandwidth, a few bits

00:51:07.620 --> 00:51:10.900
per second, and with
minimal storage, measured

00:51:10.900 --> 00:51:12.520
on the order of kilobytes.

00:51:12.520 --> 00:51:15.900
So where's the
security element that

00:51:15.900 --> 00:51:18.390
protects the things that
are important to you,

00:51:18.390 --> 00:51:22.020
that you have
complete control over?

00:51:22.020 --> 00:51:24.050
So we made one.

00:51:24.050 --> 00:51:27.410
[APPLAUSE]

00:51:29.692 --> 00:51:31.150
We needed a little
more throughput,

00:51:31.150 --> 00:51:33.530
because we wanted to be able
to handle encrypting video.

00:51:33.530 --> 00:51:36.714
So at a bare minimum, one
megabyte a second streaming.

00:51:36.714 --> 00:51:38.880
We wanted it to be modular
so that you could take it

00:51:38.880 --> 00:51:41.060
with you from device to device.

00:51:41.060 --> 00:51:44.200
We also wanted gigabytes
worth of storage for use cases

00:51:44.200 --> 00:51:46.830
like immutable logging systems.

00:51:46.830 --> 00:51:48.940
Now, an immutable
logging system can

00:51:48.940 --> 00:51:51.457
be a really powerful
deterrent to an adversary,

00:51:51.457 --> 00:51:53.040
where the evidence
of their activities

00:51:53.040 --> 00:51:55.300
are forever captured
on a separate security

00:51:55.300 --> 00:52:00.990
computer in a way that can't
be tampered with or altered.

00:52:00.990 --> 00:52:04.020
Our first focus
is the enterprise,

00:52:04.020 --> 00:52:06.120
because if it works
for the enterprise,

00:52:06.120 --> 00:52:08.050
it'll work for the individual.

00:52:08.050 --> 00:52:11.740
What you're looking at here
are the actual first versions

00:52:11.740 --> 00:52:14.080
of Project Vault in
microSD form factor.

00:52:20.640 --> 00:52:22.940
We're deploying about 500
of these within Google

00:52:22.940 --> 00:52:25.410
for authentication
purposes, supporting things

00:52:25.410 --> 00:52:27.530
like Project Abacus,
that you just heard about

00:52:27.530 --> 00:52:30.050
and the aforementioned
immutable logs.

00:52:30.050 --> 00:52:34.490
Inside this little device
is an ARM processor

00:52:34.490 --> 00:52:37.190
that runs our security focused
real time operating system,

00:52:37.190 --> 00:52:38.400
or RTOS.

00:52:38.400 --> 00:52:40.800
It's got an NFC
chip and antenna,

00:52:40.800 --> 00:52:43.360
same thing that's in your
contactless payment systems.

00:52:43.360 --> 00:52:45.980
However, we're using it
so that you could actually

00:52:45.980 --> 00:52:48.940
prove to Project Vault that
you are in control of it

00:52:48.940 --> 00:52:52.560
and that it is authorized
perform sensitive processing

00:52:52.560 --> 00:52:53.980
on your behalf.

00:52:53.980 --> 00:52:57.400
We've loaded it up with a suite
of cryptographic services,

00:52:57.400 --> 00:53:00.000
hashing, signing, bulk
encryption, streaming

00:53:00.000 --> 00:53:02.470
encryption, a strong
hardware random number

00:53:02.470 --> 00:53:09.480
generator, and four gigabytes
of isolated sealed storage.

00:53:09.480 --> 00:53:10.140
To Vault--

00:53:10.140 --> 00:53:10.661
[APPLAUSE]

00:53:10.661 --> 00:53:11.160
Oh.

00:53:11.160 --> 00:53:11.660
Thank you.

00:53:15.240 --> 00:53:16.789
To Vault, users
can communicate end

00:53:16.789 --> 00:53:19.080
to end without exposing any
cryptographically sensitive

00:53:19.080 --> 00:53:21.020
data to the host
systems, and this

00:53:21.020 --> 00:53:23.560
provides a consistent
set of security

00:53:23.560 --> 00:53:26.800
features regardless of
how secure or insecure

00:53:26.800 --> 00:53:29.500
the host system
might be, and very

00:53:29.500 --> 00:53:32.530
importantly, in a way that's
easy enough for any novice

00:53:32.530 --> 00:53:35.020
to use.

00:53:35.020 --> 00:53:36.740
So what do developers
have to do to get

00:53:36.740 --> 00:53:39.620
their phones or their laptops
or internet of things devices

00:53:39.620 --> 00:53:42.750
ready to use Project Vault?

00:53:42.750 --> 00:53:43.900
Nothing.

00:53:43.900 --> 00:53:46.870
The host system just thinks this
is a regular storage device,

00:53:46.870 --> 00:53:48.370
but actually that's
just an illusion

00:53:48.370 --> 00:53:50.030
that we're creating on the fly.

00:53:50.030 --> 00:53:52.610
So to geek out for
just a moment, when

00:53:52.610 --> 00:53:55.210
we get the request, we gin
up an artificial disc label,

00:53:55.210 --> 00:53:57.470
a master boot record, the
file allocation table.

00:53:57.470 --> 00:54:00.220
We populate it with a read
file and a write file.

00:54:00.220 --> 00:54:02.820
We mark all of the
other blocks as bad,

00:54:02.820 --> 00:54:05.135
so that you can only interface
with these two files.

00:54:05.135 --> 00:54:07.560
You want to ask of a
service from Project Vault,

00:54:07.560 --> 00:54:09.070
you open up the write file.

00:54:09.070 --> 00:54:10.290
You send in your request.

00:54:10.290 --> 00:54:12.060
You want the cypher
text coming back out,

00:54:12.060 --> 00:54:13.430
you open up the read file.

00:54:13.430 --> 00:54:16.450
It's a procfile system
without any kernel drivers.

00:54:16.450 --> 00:54:19.880
[APPLAUSE]

00:54:24.300 --> 00:54:27.810
The fewer drivers that you have
to load up on the host system,

00:54:27.810 --> 00:54:30.740
the less of a security risk
you pose to the host system,

00:54:30.740 --> 00:54:35.450
and more importantly it makes
us operating system agnostic.

00:54:35.450 --> 00:54:38.650
It doesn't matter what version
of Android, iOS, Chromium,

00:54:38.650 --> 00:54:40.250
Linux, Windows, you have.

00:54:40.250 --> 00:54:43.190
You just plug it
in and it works.

00:54:43.190 --> 00:54:46.950
[APPLAUSE]

00:54:46.950 --> 00:54:49.390
So that's what we're
experimenting with inside ATAP

00:54:49.390 --> 00:54:51.973
right now, and it's still very
much in the experimental stage.

00:54:51.973 --> 00:54:54.740
But what we're releasing
today for everybody else

00:54:54.740 --> 00:54:59.240
is the full source code for our
FPGA-based developers platform.

00:54:59.240 --> 00:55:01.170
So it's all Apache 2.0.

00:55:01.170 --> 00:55:04.220
This includes the Verilog
and VHDL and all the code

00:55:04.220 --> 00:55:08.140
for the security based
RTOS, the SD controller

00:55:08.140 --> 00:55:11.410
firmware to allow communications
with the host systems, the NAND

00:55:11.410 --> 00:55:13.380
flash translation layer
so you can manipulate

00:55:13.380 --> 00:55:18.450
the sealed storage, my
personal favorite, the hardened

00:55:18.450 --> 00:55:21.430
and accelerated
hardware crypto cores,

00:55:21.430 --> 00:55:24.230
and the interface description
language so you can talk it.

00:55:24.230 --> 00:55:27.180
In fact, even the
processor on this

00:55:27.180 --> 00:55:29.870
is open source,
the OpenRISC1200.

00:55:29.870 --> 00:55:33.300
[APPLAUSE]

00:55:35.260 --> 00:55:38.260
We're doing this to be fully
transparent, because we want

00:55:38.260 --> 00:55:40.750
developers to be able
to see how it works,

00:55:40.750 --> 00:55:43.900
understand it, trust it,
and also then experiment

00:55:43.900 --> 00:55:47.030
with pulling certain
sensitive applications outside

00:55:47.030 --> 00:55:48.850
of the general purpose
operating systems

00:55:48.850 --> 00:55:51.980
that you're used to writing in,
because these devices might be

00:55:51.980 --> 00:55:56.260
untrusted or just too
complex to ever fully secure,

00:55:56.260 --> 00:55:59.430
and now you have an external
isolated execution environment

00:55:59.430 --> 00:56:00.410
to run them in.

00:56:00.410 --> 00:56:03.870
So with that, I'd to
invite Tim Carstens up,

00:56:03.870 --> 00:56:06.640
my colleague who's done a
lot of the Verilog VHDL work

00:56:06.640 --> 00:56:07.685
for these dev boards,

00:56:07.685 --> 00:56:08.185
[APPLAUSE]

00:56:08.185 --> 00:56:09.700
If I can get the
camera up, we're

00:56:09.700 --> 00:56:11.900
going to run a little demo.

00:56:11.900 --> 00:56:12.820
I'll log you in here.

00:56:12.820 --> 00:56:13.694
Oh, I hate passwords.

00:56:16.370 --> 00:56:18.430
Made a living off of
them for a while, too.

00:56:18.430 --> 00:56:20.890
Oof.

00:56:20.890 --> 00:56:25.040
So, on this side-- if the camera
can focus in on the laptop--

00:56:25.040 --> 00:56:27.010
we're looking at a chat server.

00:56:27.010 --> 00:56:28.550
So this is a chat
server running out

00:56:28.550 --> 00:56:30.591
of the East Coast,
essentially the Gods-eye view.

00:56:30.591 --> 00:56:32.630
There's nothing there
right now, because we're

00:56:32.630 --> 00:56:34.950
going to see the
communications as they come up.

00:56:34.950 --> 00:56:37.900
On the right we have, of
course, Bob and Alice.

00:56:37.900 --> 00:56:42.400
So Bob and Alice both have
a Project Vault device.

00:56:42.400 --> 00:56:44.830
So if we could have Alice plug
in the Project Vault here.

00:56:49.540 --> 00:56:51.970
There's the file system--
the illusionary file

00:56:51.970 --> 00:56:54.900
system-- with the read file
and write file there to see.

00:56:54.900 --> 00:56:58.130
So at this point, Alice would
launch a chat application,

00:56:58.130 --> 00:57:00.750
and the chat application
just opens those two files

00:57:00.750 --> 00:57:03.860
to make use of Project
Vault. And if we

00:57:03.860 --> 00:57:08.430
go back over to the laptop,
please, with the camera,

00:57:08.430 --> 00:57:11.490
if the demo gods are
happy with us today--

00:57:11.490 --> 00:57:13.650
and it appears that
they are cooperating--

00:57:13.650 --> 00:57:14.910
this is the cypher text.

00:57:14.910 --> 00:57:16.960
So all the cypher
text on the server.

00:57:16.960 --> 00:57:18.935
So what's happening
is Project Vault

00:57:18.935 --> 00:57:21.120
is ingesting this,
decrypting it, looking

00:57:21.120 --> 00:57:22.940
for the hello messages
from each other,

00:57:22.940 --> 00:57:25.920
from the contexts that are,
again, stored in Project Vault,

00:57:25.920 --> 00:57:28.750
engaging in key negotiation,
setting up a session key,

00:57:28.750 --> 00:57:31.580
and once that's done they
have an encrypted secure

00:57:31.580 --> 00:57:33.320
communications channel.

00:57:33.320 --> 00:57:34.920
So if we're back
over on the phones,

00:57:34.920 --> 00:57:37.623
we're going to send some
messages back and forth.

00:57:40.870 --> 00:57:43.690
The server, or any third party
only ever sees the cypher text.

00:57:43.690 --> 00:57:49.230
The phones display to the users
the decrypted communications,

00:57:49.230 --> 00:57:53.100
but none of the secrets,
none of private keys

00:57:53.100 --> 00:57:55.970
or the actual algorithms
that are operating with them

00:57:55.970 --> 00:57:58.330
are ever exposed to the
device it's plugged into.

00:57:58.330 --> 00:58:01.606
[APPLAUSE]

00:58:04.420 --> 00:58:07.050
So it shouldn't matter
how many doors or windows

00:58:07.050 --> 00:58:10.260
your house has, as long
as you have a vault in it.

00:58:10.260 --> 00:58:10.760
Thanks.

00:58:10.760 --> 00:58:14.218
[APPLAUSE]

00:58:17.182 --> 00:58:20.150
Thank you very much.

00:58:20.150 --> 00:58:21.910
REGINA DUGAN:
That's big security

00:58:21.910 --> 00:58:26.140
in a very small package,
but Spotlight Stories

00:58:26.140 --> 00:58:30.470
seeks to give you
big movie experiences

00:58:30.470 --> 00:58:33.960
through the mobile window
that used to feel like just

00:58:33.960 --> 00:58:36.130
a smaller screen.

00:58:36.130 --> 00:58:38.500
We combine traditional
storytelling

00:58:38.500 --> 00:58:40.880
with interactive
elements in a way that

00:58:40.880 --> 00:58:43.620
preserves the
emotional connection

00:58:43.620 --> 00:58:45.990
of a linear narrative.

00:58:45.990 --> 00:58:49.130
Now it's not often you
get to be present when

00:58:49.130 --> 00:58:51.920
a new creative format is made.

00:58:51.920 --> 00:58:57.050
Henry Jenkins, founder of the
MIT Comparative Media Studies

00:58:57.050 --> 00:59:00.030
program explained
that once we introduce

00:59:00.030 --> 00:59:05.890
a medium, a mode of human
expression, into the universe,

00:59:05.890 --> 00:59:08.400
it tends to persist.

00:59:08.400 --> 00:59:12.420
Live theater persists
in the face of cinema.

00:59:12.420 --> 00:59:17.230
Radio persists in the
face of television.

00:59:17.230 --> 00:59:22.810
That's why it feels special,
because a new format has

00:59:22.810 --> 00:59:26.170
a certain timelessness to it.

00:59:26.170 --> 00:59:29.390
Last year, Disney
legend Glen Keane

00:59:29.390 --> 00:59:33.160
completed 10,055
original drawings

00:59:33.160 --> 00:59:39.320
to create "Duet." "Duet" was
our third Spotlight Story,

00:59:39.320 --> 00:59:44.010
and a few months after I/O,
"Duet" shipped to millions

00:59:44.010 --> 00:59:47.670
of users on Motorola phones.

00:59:47.670 --> 00:59:50.150
The first wave of
press coverage was

00:59:50.150 --> 00:59:52.440
in the tech and Android blogs.

00:59:52.440 --> 00:59:54.990
Then "Duet" attracted
a bit of attention

00:59:54.990 --> 00:59:58.170
in the entertainment community,
and the artistic community

00:59:58.170 --> 01:00:00.230
recognized "Duet" as well.

01:00:00.230 --> 01:00:02.340
There was Oscar
buzz, and "Duet" at

01:00:02.340 --> 01:00:06.310
was nominated for an Annie,
the highest award in animation.

01:00:06.310 --> 01:00:11.240
It won the film industry's
award for best original score.

01:00:11.240 --> 01:00:16.180
And while millions saw "Duet"
through a small mobile window,

01:00:16.180 --> 01:00:22.000
lucky passers by saw it on
the largest screen in the US.

01:00:22.000 --> 01:00:27.310
We flooded times square with
Scot Stafford's original score,

01:00:27.310 --> 01:00:31.740
and for a few minutes,
in the rain and the cold

01:00:31.740 --> 01:00:35.290
on Christmas Eve,
people slowed down.

01:00:38.120 --> 01:00:41.580
In 2008, Jeremy Hsu
wrote an article

01:00:41.580 --> 01:00:46.270
in Scientific American entitled
"The Secrets of Storytelling--

01:00:46.270 --> 01:00:49.590
Why We Love a Good
Yarn," and in it

01:00:49.590 --> 01:00:55.770
he said that storytelling is
one of the few human traits

01:00:55.770 --> 01:01:03.640
that are truly universal across
culture and all known history.

01:01:03.640 --> 01:01:08.010
People in societies
of all types weave

01:01:08.010 --> 01:01:12.040
narratives, and when a
characteristic behavior

01:01:12.040 --> 01:01:15.790
shows up in so many
different societies,

01:01:15.790 --> 01:01:22.580
its roots may reveal something
about our evolutionary past.

01:01:22.580 --> 01:01:26.990
Simply put, we are
wired for stories.

01:01:26.990 --> 01:01:30.280
It's part of being human.

01:01:30.280 --> 01:01:34.220
We long for new ways to
experience and engage

01:01:34.220 --> 01:01:39.660
with stories, and storytellers
look for new outlets.

01:01:39.660 --> 01:01:43.830
In Spotlight Stories, we
found the answer right

01:01:43.830 --> 01:01:45.270
in front of us.

01:01:45.270 --> 01:01:48.940
Hundreds of millions of
powerful media devices,

01:01:48.940 --> 01:01:53.110
millions more shipped every
day, with ever more beautiful

01:01:53.110 --> 01:01:58.020
screens, powerful graphics,
and precise sensors.

01:01:58.020 --> 01:02:02.070
Please welcome Jan and Rachid,
quite the pair, creator

01:02:02.070 --> 01:02:05.140
and director of the original
spotlight story, "Windy Day,"

01:02:05.140 --> 01:02:08.460
Jan Pinkava, and with
him Rachid El Guerrab,

01:02:08.460 --> 01:02:11.640
the technical project lead
for Spotlight Stories.

01:02:11.640 --> 01:02:12.750
Their goal?

01:02:12.750 --> 01:02:17.890
More great stories, more happy
viewers, push the format.

01:02:17.890 --> 01:02:18.450
Gentlemen.

01:02:18.450 --> 01:02:20.314
[APPLAUSE]

01:02:20.314 --> 01:02:21.712
JAN PINKAVA: Thank you.

01:02:21.712 --> 01:02:23.912
How you doing?

01:02:23.912 --> 01:02:25.120
RACHID EL GUERRAB: Thank you.

01:02:25.120 --> 01:02:26.500
Thank you.

01:02:26.500 --> 01:02:31.330
So everybody wants more
stories, but we can't make

01:02:31.330 --> 01:02:33.080
them all ourselves, of course.

01:02:33.080 --> 01:02:35.840
So how do we enable
more creators

01:02:35.840 --> 01:02:38.730
to create these kind of stories?

01:02:38.730 --> 01:02:41.960
As developers, we of
course create an SDK.

01:02:41.960 --> 01:02:46.840
In our case, it's a
Story Development Kit.

01:02:46.840 --> 01:02:47.340
Now--

01:02:47.340 --> 01:02:48.134
[APPLAUSE]

01:02:48.134 --> 01:02:49.830
Thank you.

01:02:49.830 --> 01:02:54.420
For this to enable
filmmakers to create content

01:02:54.420 --> 01:02:57.420
for mobile, which is
a different space,

01:02:57.420 --> 01:03:01.310
this SDK has to fit within
their familiar film production

01:03:01.310 --> 01:03:02.470
pipeline.

01:03:02.470 --> 01:03:07.270
So for example, we integrate
with standard animation

01:03:07.270 --> 01:03:11.460
modeling tools like Maya, and
we support standard technologies

01:03:11.460 --> 01:03:14.840
like Pixar's opensubdiv surfaces
and the Alembic geometry

01:03:14.840 --> 01:03:19.280
format from Sony and Lucasfilm,
except these run normally

01:03:19.280 --> 01:03:22.520
on render farms and
big servers, but we

01:03:22.520 --> 01:03:26.530
have to run them in
real time, on mobile,

01:03:26.530 --> 01:03:28.010
and at 60 frames per second.

01:03:31.410 --> 01:03:34.440
JAN PINKAVA: Now for me as
an animator and a director,

01:03:34.440 --> 01:03:37.120
that all looks like
fairly familiar territory,

01:03:37.120 --> 01:03:39.350
but the SDK also
has to be a bridge

01:03:39.350 --> 01:03:43.560
to the unfamiliar landscape
of a new form of storytelling.

01:03:43.560 --> 01:03:47.680
Now the stories are
interactive and immersive.

01:03:47.680 --> 01:03:50.670
They're real time,
continuous, and they feel more

01:03:50.670 --> 01:03:53.430
like shooting a movie
than watching one.

01:03:53.430 --> 01:03:57.700
The flow is affected by the
attention of the audience.

01:03:57.700 --> 01:04:00.090
That means they have to
be structured differently

01:04:00.090 --> 01:04:03.380
in both time and space.

01:04:03.380 --> 01:04:05.210
You have to replace
the traditional film

01:04:05.210 --> 01:04:10.790
language of cuts and
shots with new techniques.

01:04:10.790 --> 01:04:13.130
For working with this
interactive story structure,

01:04:13.130 --> 01:04:15.534
this SDK has a Story Editor.

01:04:15.534 --> 01:04:16.950
Now, let's say I
want to make sure

01:04:16.950 --> 01:04:20.240
that the audience sees a
key action, like here, Pepe

01:04:20.240 --> 01:04:21.970
about to pick up his hat.

01:04:21.970 --> 01:04:25.610
One technique is to make
the story wait for you

01:04:25.610 --> 01:04:27.289
until you're watching.

01:04:27.289 --> 01:04:29.080
With the Story Editor
I can tell the action

01:04:29.080 --> 01:04:35.480
to pause, and until your
camera is pointing at Pepe,

01:04:35.480 --> 01:04:37.120
and then the action continues.

01:04:37.120 --> 01:04:37.990
Very simple.

01:04:37.990 --> 01:04:42.550
In this way, the story
is interacting with you.

01:04:42.550 --> 01:04:45.420
When we're planning a
story, we use storyboards.

01:04:45.420 --> 01:04:47.940
But it no longer
makes sense to have

01:04:47.940 --> 01:04:50.710
just a sequence of storyboards,
as if the action is playing out

01:04:50.710 --> 01:04:52.030
on the screen.

01:04:52.030 --> 01:04:55.670
In an immersive story, we
have a window onto a world

01:04:55.670 --> 01:05:00.490
all around us, and we have
to deal with that space.

01:05:00.490 --> 01:05:03.870
So our 360 storyboard tool
lets you place the boards

01:05:03.870 --> 01:05:07.760
all around you, so that you
can work out the story in space

01:05:07.760 --> 01:05:08.660
as well as time.

01:05:08.660 --> 01:05:12.020
[APPLAUSE]

01:05:14.430 --> 01:05:16.330
And we can't stop at
building these tools.

01:05:16.330 --> 01:05:19.120
We have to put them in
the hands of storytellers,

01:05:19.120 --> 01:05:22.910
making it real, making it
work as part of their process.

01:05:22.910 --> 01:05:25.660
And a growing number of
award winning filmmakers

01:05:25.660 --> 01:05:28.483
are exploring this
new territory.

01:05:28.483 --> 01:05:29.191
[VIDEO  PLAYBACK]

01:05:29.191 --> 01:05:32.460
[MUSIC PLAYING]

01:05:34.340 --> 01:05:36.820
-Working in a
virtual world where

01:05:36.820 --> 01:05:40.120
the audience is essentially the
camera changes things for you

01:05:40.120 --> 01:05:42.420
as a director.

01:05:42.420 --> 01:05:47.400
-We are trying to predict
the curiosity of the viewer

01:05:47.400 --> 01:05:49.762
and make it all
feel very seamless.

01:05:49.762 --> 01:05:51.595
-So I thought, well,
what if could structure

01:05:51.595 --> 01:05:54.350
it like a song with
chorus and verse?

01:05:54.350 --> 01:05:56.180
-You're kind of giving
your control back

01:05:56.180 --> 01:05:59.410
to the audience, which I thought
was a really interesting idea.

01:05:59.410 --> 01:06:01.740
-You can't just put a
traditional story on this.

01:06:01.740 --> 01:06:04.608
You're going to have to
think a lot about narrative

01:06:04.608 --> 01:06:06.520
in a different way.

01:06:06.520 --> 01:06:08.880
-Everything from the tools
that we use to the way

01:06:08.880 --> 01:06:10.910
we write stories and
the way we lay out

01:06:10.910 --> 01:06:13.720
narratives is going to
change and become something

01:06:13.720 --> 01:06:14.718
exciting and new again.

01:06:22.119 --> 01:06:22.702
[END PLAYBACK]

01:06:22.702 --> 01:06:26.195
[APPLAUSE]

01:06:28.117 --> 01:06:30.200
JAN PINKAVA: Now, they're
not just making stories,

01:06:30.200 --> 01:06:31.590
they're shaping the format.

01:06:31.590 --> 01:06:34.040
By using the tools,
they're making the tools,

01:06:34.040 --> 01:06:37.160
by telling us what
they need to do.

01:06:37.160 --> 01:06:41.786
And of course, great
storytellers need an audience.

01:06:41.786 --> 01:06:43.160
RACHID EL GUERRAB:
So now we have

01:06:43.160 --> 01:06:45.660
to scale the distribution
of these kind of stories

01:06:45.660 --> 01:06:48.480
and get them to more viewers.

01:06:48.480 --> 01:06:51.910
So this week, we launched
the Google Spotlight Stories

01:06:51.910 --> 01:06:57.570
app for Android, and very
soon after will be for iOS.

01:06:57.570 --> 01:07:01.035
[APPLAUSE]

01:07:02.030 --> 01:07:02.800
Thank you.

01:07:02.800 --> 01:07:06.659
Where you can find curated
stories by great storytellers,

01:07:06.659 --> 01:07:08.200
you can share them
with your friends,

01:07:08.200 --> 01:07:10.110
and look behind the scenes.

01:07:10.110 --> 01:07:12.680
And this summer,
we're on YouTube.

01:07:12.680 --> 01:07:17.152
Our interactive format supported
natively in YouTube mobile.

01:07:17.152 --> 01:07:18.520
[APPLAUSE]

01:07:18.520 --> 01:07:20.800
Thank you.

01:07:20.800 --> 01:07:24.600
So now filmmakers have the
means to make these stories,

01:07:24.600 --> 01:07:26.720
and we can put them at
the hands of hundreds

01:07:26.720 --> 01:07:28.410
of millions of viewers.

01:07:28.410 --> 01:07:29.100
Done.

01:07:29.100 --> 01:07:31.210
We planned our vacation.

01:07:31.210 --> 01:07:35.300
Then somebody had to ask,
what about live action?

01:07:35.300 --> 01:07:37.450
What are you doing there?

01:07:37.450 --> 01:07:40.645
And so, that somebody
was Justin Lin.

01:07:40.645 --> 01:07:43.950
[APPLAUSE]

01:07:44.450 --> 01:07:47.370
And when Justin saw "Windy
Day" the first time,

01:07:47.370 --> 01:07:49.400
our first story,
he was instantly

01:07:49.400 --> 01:07:51.450
intrigued by this
idea of telling

01:07:51.450 --> 01:07:53.690
stories that
surround you, but he

01:07:53.690 --> 01:07:56.400
wanted to do it in his own way.

01:07:56.400 --> 01:07:59.310
He wanted a full Hollywood
cinematic experience

01:07:59.310 --> 01:08:03.710
with high production
value, in 360, on mobile,

01:08:03.710 --> 01:08:05.570
and that, of course,
created new challenges,

01:08:05.570 --> 01:08:09.120
and goodbye vacation.

01:08:09.120 --> 01:08:11.230
So first, we had to
figure out the camera.

01:08:11.230 --> 01:08:14.020
For his films, Justin needs
professional grade cameras

01:08:14.020 --> 01:08:17.060
that can capture at high
resolution, in low light,

01:08:17.060 --> 01:08:20.550
at night, and with
fast moving action.

01:08:20.550 --> 01:08:23.100
Now we have to do it in 360.

01:08:23.100 --> 01:08:24.950
And with our partners
Bullitt and The Mill,

01:08:24.950 --> 01:08:27.450
we looked at every
360 camera system

01:08:27.450 --> 01:08:30.800
out there to find one
that could make the grade,

01:08:30.800 --> 01:08:32.330
and it just didn't exist.

01:08:32.330 --> 01:08:35.680
So we had to build it.

01:08:35.680 --> 01:08:38.569
Our rig uses four RED
Epic Dragon cameras

01:08:38.569 --> 01:08:41.720
with eight millimeter
fisheye lenses from Canon,

01:08:41.720 --> 01:08:44.939
capturing at 6K resolution each.

01:08:44.939 --> 01:08:47.240
So you can see there Angus,
the creative director

01:08:47.240 --> 01:08:50.270
from The Mill, looking a little
bit worried about all that data

01:08:50.270 --> 01:08:52.890
coming out of the cameras.

01:08:52.890 --> 01:08:56.939
We created a custom casing
that reduces the overall rig

01:08:56.939 --> 01:09:00.840
size and the offset between
the nodal points of the lenses,

01:09:00.840 --> 01:09:04.120
which is very important
for 360 video stitching,

01:09:04.120 --> 01:09:06.840
but also helps with
tasks in post production

01:09:06.840 --> 01:09:09.220
and visual effects
down the line.

01:09:09.220 --> 01:09:12.550
But of course, it's not
enough to just build the tech.

01:09:12.550 --> 01:09:15.000
We need to make sure
that Justin can direct

01:09:15.000 --> 01:09:18.700
with it on the set in 360.

01:09:18.700 --> 01:09:22.229
So we set up onset live
stitching and streaming

01:09:22.229 --> 01:09:26.910
to 360 monitors with real time
feedback on custom mobile rigs,

01:09:26.910 --> 01:09:31.290
so that Justin can see what the
camera sees at every moment,

01:09:31.290 --> 01:09:32.700
and what the viewer might see.

01:09:35.450 --> 01:09:37.270
Now we have to put it
all together for you

01:09:37.270 --> 01:09:39.170
and deliver it to your device.

01:09:39.170 --> 01:09:41.740
And to do that at
full resolution

01:09:41.740 --> 01:09:46.260
with cinematic field of view
means streaming, decoding,

01:09:46.260 --> 01:09:51.640
and rendering the equivalent
of three 4K videos at once.

01:09:51.640 --> 01:09:54.750
That's like three
ultra HDTV streams

01:09:54.750 --> 01:09:56.720
coming through your phone.

01:09:56.720 --> 01:10:00.630
Of course, few if any
devices can handle that.

01:10:00.630 --> 01:10:04.250
But it turns out
that only at most

01:10:04.250 --> 01:10:07.260
about 25% of that data
is actually needed

01:10:07.260 --> 01:10:08.890
at any one time,
because that's all

01:10:08.890 --> 01:10:11.160
you can see through your phone.

01:10:11.160 --> 01:10:14.380
And so we implemented a
dynamic spatial tiling system

01:10:14.380 --> 01:10:17.680
that would process only
what's visible and adapts

01:10:17.680 --> 01:10:20.000
to your device's
horsepower in real time.

01:10:20.000 --> 01:10:21.880
[APPLAUSE]

01:10:21.880 --> 01:10:22.380
Thank you.

01:10:25.980 --> 01:10:29.430
Those tiles are decoded
in multiple resolutions

01:10:29.430 --> 01:10:32.850
and then blended together to
adapt to your view in motion.

01:10:32.850 --> 01:10:36.100
So there's no blocking,
stuttering, or janking,

01:10:36.100 --> 01:10:38.950
whether you're turning
really fast or moving slow.

01:10:42.840 --> 01:10:44.970
JAN PINKAVA: So it's all
about what you're seeing.

01:10:44.970 --> 01:10:47.180
Now, for a filmmaker,
telling a story

01:10:47.180 --> 01:10:50.940
is about directing the
attention of the audience.

01:10:50.940 --> 01:10:52.360
You see this gesture
all the time.

01:10:52.360 --> 01:10:55.720
This is what I want
the audience to see.

01:10:55.720 --> 01:10:57.220
And some things are
important to see

01:10:57.220 --> 01:10:59.770
or to hear so that the
experience actually

01:10:59.770 --> 01:11:03.080
makes sense as a story, right?

01:11:03.080 --> 01:11:04.640
In a traditional
movie, the story

01:11:04.640 --> 01:11:06.389
has been completed
in the edit suite,

01:11:06.389 --> 01:11:07.930
and the audience
knows where to look.

01:11:07.930 --> 01:11:10.646
You just watch the screen.

01:11:10.646 --> 01:11:12.020
When watching an
immersive story,

01:11:12.020 --> 01:11:15.670
the audience is free to look
around just about anywhere,

01:11:15.670 --> 01:11:18.135
and sometimes it's
easy to get lost.

01:11:21.820 --> 01:11:23.860
So we developed camera
composition and tracking

01:11:23.860 --> 01:11:27.430
techniques that help
you stay with the action

01:11:27.430 --> 01:11:30.200
without ever dictating
where you should look,

01:11:30.200 --> 01:11:31.900
just as a gentle
guide that still

01:11:31.900 --> 01:11:35.450
leaves you free to point your
camera wherever you want.

01:11:35.450 --> 01:11:37.990
Whether you like to look
around or just sit and watch,

01:11:37.990 --> 01:11:42.210
we're there to help
you enjoy the ride.

01:11:42.210 --> 01:11:43.870
Now to complete the
picture, we need

01:11:43.870 --> 01:11:45.590
to complete the
sound experience.

01:11:45.590 --> 01:11:49.680
How can we bring the richness
of immersive theatrical sound

01:11:49.680 --> 01:11:51.960
to the mobile world?

01:11:51.960 --> 01:11:53.800
In a movie theater,
everyone looks

01:11:53.800 --> 01:11:55.810
in one direction--
at the screen--

01:11:55.810 --> 01:11:59.040
and the sound experience can
be created with a fixed speaker

01:11:59.040 --> 01:11:59.970
layout.

01:11:59.970 --> 01:12:03.610
In our format, you can
look in any direction,

01:12:03.610 --> 01:12:05.500
the story world
is all around you,

01:12:05.500 --> 01:12:08.600
and the speakers
are your headphones.

01:12:08.600 --> 01:12:10.840
The sound in your
ears now must change

01:12:10.840 --> 01:12:14.680
you turn, just like real life.

01:12:14.680 --> 01:12:17.650
To get a truly interactive
and immersive experience

01:12:17.650 --> 01:12:19.540
that responds to
you, we developed

01:12:19.540 --> 01:12:21.340
dynamic virtual surround.

01:12:21.340 --> 01:12:24.470
Using techniques like ambisonics
and binaural rendering

01:12:24.470 --> 01:12:27.460
and an end to end
pipeline, sound designers

01:12:27.460 --> 01:12:33.480
can now create subtle and rich
and realistic acoustic spaces

01:12:33.480 --> 01:12:36.240
of the sort they're used
to in feature films,

01:12:36.240 --> 01:12:39.794
but now in real
time, 360 on mobile.

01:12:39.794 --> 01:12:43.210
[APPLAUSE]

01:12:45.170 --> 01:12:47.170
And for Justin Lin's
story, we created

01:12:47.170 --> 01:12:50.680
a full sphere surround field for
interactive film from scratch.

01:12:50.680 --> 01:12:52.101
That's a first.

01:12:52.101 --> 01:12:54.350
And the soundscape of the
story is now all around you,

01:12:54.350 --> 01:12:58.246
and it comes to life only
when you watch the show.

01:12:58.246 --> 01:13:00.120
So we're not just putting
you in the picture,

01:13:00.120 --> 01:13:02.570
we're immersing
you in the sound,

01:13:02.570 --> 01:13:05.550
and all you need is an
ordinary pair of headphones.

01:13:05.550 --> 01:13:09.500
Now, we'd love to show you
this and share this with you

01:13:09.500 --> 01:13:11.200
right now.

01:13:11.200 --> 01:13:13.940
Unfortunately, the
screens in this room

01:13:13.940 --> 01:13:15.755
are only big enough
to give you about 15%

01:13:15.755 --> 01:13:17.130
of the whole
immersive experience

01:13:17.130 --> 01:13:18.880
that you can get with
a pair of earbuds

01:13:18.880 --> 01:13:20.990
and the phone in your pocket.

01:13:20.990 --> 01:13:25.543
So here's just a taste of it.

01:13:25.543 --> 01:13:29.036
[MUSIC PLAYING]

01:15:11.830 --> 01:15:15.323
[APPLAUSE]

01:15:22.350 --> 01:15:23.880
REGINA DUGAN: Ladies
and gentlemen,

01:15:23.880 --> 01:15:27.380
the writer, director,
and producer of films

01:15:27.380 --> 01:15:29.890
grossing over $2
billion, including

01:15:29.890 --> 01:15:33.130
the Fast and the Furious
franchise, and, upcoming,

01:15:33.130 --> 01:15:37.010
"Star Trek Three" for Paramount,
director of our latest

01:15:37.010 --> 01:15:39.520
Google Spotlight
Story, Justin Lin.

01:15:39.520 --> 01:15:42.908
[APPLAUSE]

01:15:48.716 --> 01:15:51.136
Awesome, Justin.

01:15:51.136 --> 01:15:55.170
And because it's taken some
serious storytelling partners

01:15:55.170 --> 01:15:57.600
to get us here, I
want you to meet

01:15:57.600 --> 01:15:59.880
some of the other
creative talent that

01:15:59.880 --> 01:16:02.190
helped make Google
Spotlight Stories,

01:16:02.190 --> 01:16:06.510
and continues to create
in this new mobile format.

01:16:06.510 --> 01:16:08.300
Let's welcome back Jan Pinkava.

01:16:08.300 --> 01:16:09.150
[APPLAUSE]

01:16:09.150 --> 01:16:11.780
Jan won the Oscar
for "Geri's Game"

01:16:11.780 --> 01:16:15.040
and was the co-director
for "Ratatouille."

01:16:15.040 --> 01:16:18.200
Jan is the creative director
for Google Spotlight Stories.

01:16:18.200 --> 01:16:22.450
And Karen Dufilho, double
Oscar winning producer,

01:16:22.450 --> 01:16:27.020
who along with Jan continues
to carry the Spotlight Stories

01:16:27.020 --> 01:16:28.170
creative frame.

01:16:28.170 --> 01:16:30.630
Now, Jan and Karen
have been here

01:16:30.630 --> 01:16:34.010
from the beginning, when
our makeshift studio in ATAP

01:16:34.010 --> 01:16:36.800
was a conference room
where we posted up

01:16:36.800 --> 01:16:39.810
artboards that had been
transported awkwardly

01:16:39.810 --> 01:16:42.170
in an engineer's car.

01:16:42.170 --> 01:16:46.810
And the man who challenged the
new with the old, hand drawn

01:16:46.810 --> 01:16:49.510
animation in mobile, is back.

01:16:49.510 --> 01:16:50.390
Glen Keane--

01:16:50.390 --> 01:16:53.440
[APPLAUSE]

01:16:53.440 --> 01:16:57.250
--animation legend and creator
of our third Spotlight Story,

01:16:57.250 --> 01:16:58.570
"Duet."

01:16:58.570 --> 01:17:02.520
Our Story Development Kit
guinea pig and resident nutcase,

01:17:02.520 --> 01:17:03.851
Shannon Tindle.

01:17:03.851 --> 01:17:04.350
[APPLAUSE]

01:17:04.350 --> 01:17:08.500
Shannon won a prime time Emmy
for individual achievement

01:17:08.500 --> 01:17:12.130
in animation, and he's working
on our fifth Spotlight Story.

01:17:12.130 --> 01:17:17.680
Think science fiction Icecapades
with an unsuspecting visitor.

01:17:17.680 --> 01:17:20.050
And finally, because
what else would

01:17:20.050 --> 01:17:24.510
you do after winning an Oscar
but a Google Spotlight Story,

01:17:24.510 --> 01:17:25.445
Patrick Osborne--

01:17:25.445 --> 01:17:26.300
[APPLAUSE]

01:17:26.300 --> 01:17:31.560
--head of animation on "Big Hero
6" and winner of the 2014 Oscar

01:17:31.560 --> 01:17:34.240
for the best animated short.

01:17:34.240 --> 01:17:37.890
Justin, Jan, Karen, Glen,
Shannon, and Patrick

01:17:37.890 --> 01:17:41.990
are here for a box talk right
across the hall, 11:00 AM,

01:17:41.990 --> 01:17:44.360
second floor, alcove three.

01:17:44.360 --> 01:17:45.070
Thank you.

01:17:45.070 --> 01:17:45.570
Awesome.

01:17:45.570 --> 01:17:48.714
[APPLAUSE]

01:17:54.890 --> 01:17:59.111
And, well, that's a wrap.

01:17:59.111 --> 01:17:59.610
Almost.

01:18:04.330 --> 01:18:07.690
[APPLAUSE]

01:18:10.110 --> 01:18:13.600
Creating the hardware equivalent
of the software ecosystem

01:18:13.600 --> 01:18:15.430
is hard.

01:18:15.430 --> 01:18:20.240
In the last months, we've moved
from the industrial design

01:18:20.240 --> 01:18:24.650
to functioning prototypes to
our first engineering spiral.

01:18:24.650 --> 01:18:27.700
We've moved from FPGAs
to ASICs, and we're

01:18:27.700 --> 01:18:30.000
starting our third spin.

01:18:30.000 --> 01:18:33.230
Rafa Camargo is our
lead system engineer,

01:18:33.230 --> 01:18:36.000
with responsibilities for
hardware and software.

01:18:36.000 --> 01:18:38.370
He's accustomed
to mobile firsts.

01:18:38.370 --> 01:18:41.780
He led the first Android
platform at Motorola.

01:18:41.780 --> 01:18:45.530
He's been at the forefront
of nearly every generation

01:18:45.530 --> 01:18:47.080
of mobile technology.

01:18:47.080 --> 01:18:49.250
And now, he's on Ara.

01:18:49.250 --> 01:18:50.247
Rafa.

01:18:50.247 --> 01:18:53.720
[APPLAUSE]

01:18:53.720 --> 01:18:54.720
RAFA CAMARGO: Thank you.

01:18:58.200 --> 01:19:02.510
Project Ara is all
about letting you decide

01:19:02.510 --> 01:19:06.150
what your device is, and does.

01:19:06.150 --> 01:19:07.518
So let's see how it works.

01:19:10.976 --> 01:19:11.964
Let's try this.

01:19:14.930 --> 01:19:17.360
This is the frame.

01:19:17.360 --> 01:19:19.850
We call it the endo.

01:19:19.850 --> 01:19:22.430
And these are modules.

01:19:22.430 --> 01:19:24.495
Let's just connect them.

01:19:24.495 --> 01:19:25.870
This is an
application processor.

01:19:29.532 --> 01:19:30.740
I just connected the battery.

01:19:35.190 --> 01:19:41.720
That's a speaker, and
this is another speaker.

01:19:41.720 --> 01:19:43.880
I want my ARA in stereo today.

01:19:46.980 --> 01:19:52.450
Enabling all of this is what we
believe to be the first UniPro

01:19:52.450 --> 01:19:57.940
switch network, and running
it all, is [? GreyBox ?].

01:19:57.940 --> 01:20:01.419
[APPLAUSE]

01:20:05.250 --> 01:20:05.750
Here you go.

01:20:05.750 --> 01:20:07.638
[APPLAUSE]

01:20:07.638 --> 01:20:12.775
Ara, running the
latest Android version.

01:20:15.730 --> 01:20:17.480
Let me show you something else.

01:20:17.480 --> 01:20:20.260
Let's launch the camera.

01:20:20.260 --> 01:20:22.250
Of course, I already
know that today I

01:20:22.250 --> 01:20:26.190
didn't configure a
camera, but let's see

01:20:26.190 --> 01:20:28.470
how easy it is to
add new hardware

01:20:28.470 --> 01:20:32.060
functionality to your device.

01:20:32.060 --> 01:20:35.180
This is a camera module.

01:20:35.180 --> 01:20:36.826
I connect it.

01:20:36.826 --> 01:20:37.700
And it's that simple.

01:20:40.680 --> 01:20:41.782
There you go.

01:20:41.782 --> 01:20:45.226
[APPLAUSE]

01:20:49.162 --> 01:20:50.640
All right.

01:20:50.640 --> 01:20:55.455
So why don't we take the
first public picture with Ara?

01:20:55.455 --> 01:20:57.235
[CHEERS]

01:20:57.235 --> 01:20:58.850
All right.

01:20:58.850 --> 01:21:01.640
All right, guys,
smile for the picture.

01:21:01.640 --> 01:21:04.070
[CHEERS]

01:21:04.570 --> 01:21:06.990
Let me see.

01:21:06.990 --> 01:21:10.790
Oh, you all look awesome.

01:21:10.790 --> 01:21:12.130
OK.

01:21:12.130 --> 01:21:12.960
Thank you.

01:21:12.960 --> 01:21:15.810
Follow us on our
Twitter account,

01:21:15.810 --> 01:21:19.940
Project ARA, where we'll have
updates on our next developer

01:21:19.940 --> 01:21:20.440
conference.

01:21:20.440 --> 01:21:23.728
[APPLAUSE]

01:21:28.710 --> 01:21:31.076
REGINA DUGAN: Can we have
just a moment, please?

01:21:31.076 --> 01:21:32.200
Because what just happened?

01:21:32.200 --> 01:21:36.670
We assembled a smartphone
on the fly, booted it,

01:21:36.670 --> 01:21:39.420
run time detected a camera,
and took your picture.

01:21:39.420 --> 01:21:42.815
[APPLAUSE]

01:21:43.785 --> 01:21:47.180
That's nuts.

01:21:47.180 --> 01:21:51.380
Artists and musicians,
scientists and engineers,

01:21:51.380 --> 01:21:55.710
we are more the same
than we are different.

01:21:55.710 --> 01:21:59.750
We share a deep
satisfaction that

01:21:59.750 --> 01:22:05.820
comes from creating something
that never existed before

01:22:05.820 --> 01:22:10.640
and a certain exhilaration
when that something connects

01:22:10.640 --> 01:22:18.210
us, makes us better, celebrates
the inherent curiosity,

01:22:18.210 --> 01:22:25.510
the vulnerability, the joy, and
the sorrow that makes us human.

01:22:25.510 --> 01:22:28.700
That kind of work,
it is inherently

01:22:28.700 --> 01:22:32.500
born of the human spirit.

01:22:32.500 --> 01:22:37.110
It is a little
badass and beautiful.

01:22:37.110 --> 01:22:42.060
It is tech infused
with our humanity.

01:22:42.060 --> 01:22:47.890
And it doesn't have love
sprinkled on at the finish.

01:22:47.890 --> 01:22:54.330
The work itself is an
expression of love.

01:22:54.330 --> 01:23:00.510
That's what it feels like
to us, in this fast boat,

01:23:00.510 --> 01:23:04.530
in this small band of
pirates, trying as best

01:23:04.530 --> 01:23:09.020
we can to do some epic shit.

01:23:09.020 --> 01:23:11.120
[APPLAUSE]

01:23:12.620 --> 01:23:13.220
Thank you.

01:23:17.420 --> 01:23:20.770
[MUSIC PLAYING]

