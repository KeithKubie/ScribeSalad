Speaker 1:          00:00          The Joe Rogan experience. Yeah, man, that is interesting about scientists, right? They're just concentrate on the task at hand. Yeah. I mean it wasn't that, that was like one of the big concerns about the Manhattan project, right? This is the task. The task is how to figure out how to do it. So they figured out how to do it, not the eventual in yes. Consequences. So when Robert Oppenheimer, who was the lead of the, of the Manhattan project, when that first bomb went off, I mean he has his, his famous quote. Yeah, exactly. I mean the, the, they, the English common translation was holy Shit, what have we done? And, and that's, and this science is real, but it's not going to be, it's not one person doing it. I mean, that's the whole like science has been diffused, at least with, with nuclear power, is a relatively small number of people.

Speaker 1:          00:51          And it was, uh, you know, one or two states that could do it. Now with with precision gene editing, I mean you get the Nobel prize for, for figuring out how to do, or you will get the Nobel prize for figuring out how to do CRISPR gene edits. But to apply it once the formula already exists, you get like an a minus in your high school biology class. So this technology is out there. It's cheap, it's accessible. Did you go to the 2045 conference in Manhattan a couple of years back? Now, do you know about all that? 2044 that's, that's part of the thing with these transhumanists folks. They believe that with their own calculations of the exponential increase of technology that somewhere around 2045 singularity. Yeah, yeah. Were at the very least, we're going to reach this point where you're going to be able to either download consciousness or have some sort of an artificially intelligent, sentient things hanging out with you.

Speaker 1:          01:49          Yeah. So as I'm involved, I'm on faculty for um, one of the programs of singularity university called exponential medicine. And so we're thinking a lot about that. Actually had an editorial in the New York Times a few weeks ago imagining a visit to a fertility clinic in the year 2045 and again because we are on this exponential change is it's really hard for people to to internalize, to kind of feel how fast these changes are coming. I do think though, a ray Kurzweil who's who's a really incredible genius, he thinks that we are soon going to get to a point now where our artificial intelligence is self learning because when you think about Ai, if it gets to the point where it can read something, read and comprehend, like in seconds it will read every book ever written in Cuban history and then it's says when you have all these doublings and all of this more knowledge, you can imagine how that would happen pretty quickly that the counter argument against, and I think that it will, but I don't think that we're, that our human brains are on one hand, they're incredibly complex and they're also kind of irrational.

Speaker 1:          02:54          I mean we have all these different layers of our lizard brain and every decision that we make, there's the rational decision, but then there's all the other stuff that our brains, that doesn't even rise to the level of our awareness that our, that our brains are processing. And right now we don't really have one really effective artificial intelligence algorithm, which is for pattern recognition. But I think if you think of pattern recognition as a core skill of what our brains do, our brain's probably have a thousand, 2000 different skills. Um, but the core thing is whether we reached this singularity moment or not, these technologies are going to become incredibly more powerful. They're going to become increasingly integrated into our lives and into our beings. And part of our evolutionary process there is no longer, oh, we just have our biological evolution and our technological evolution.

Speaker 1:          03:42          Those are separate things. They're connected. It's going to be the weird question of whether or not, if an artificial intelligence is going to be able to absorb all of the writing that human beings have ever done and really understand us, yeah. Will they really still be able to understand that just because they get all the writing. So right now you would say no. I'd say no. Yeah. But 20 years from now, 50 years from now, a hundred years from now, they could come up with a reasonable facsimile. I mean, yeah, they could figure out a way to get it close enough. Yeah, I know where it's like her, like the, yeah. Yeah. That's an essential point because I think when people imagine this AI future, they're imagining like some intimate relationship with some artificial intelligent, intelligent, that feels just like a human. I don't think that's going to happen because it's, it don't, well, no, but just because AI, it will be its own form of intelligence and it may not be, frankly, you wouldn't want ais with these brains like we have that have all these different impulses that are kind of imagining all this, this crazy stuff we're, we may want them to be more rational than, than we are.

Speaker 1:          04:43          So like chimpanzees or our close relatives, they don't think just like us, we're not know. We're not expecting them to think like they're their own thing. And I think AI's will be their own things. Will we be interacting with them? Will we be having sex with them? Yes. But if they're there, it's not going to be that. They're just like us. We're going to, they're going to be these things that live within us, live with us, and together we're going to evolve. Well, there's certainly already better at doing certain things like playing chess and it took a long time for an artificial intelligence to be able to compete against a real chess master. But now they swamp them. Yeah. So they learn quickly, like it's incredibly quickly they teach themselves. Yeah. So, so first we had chess in chess. People said, oh, that's what it means to be a human.

Speaker 1:          05:29          The computers will never beat humans at chess. Now it's like everyone says, well no human could ever compete. And then they said, well there's this Chinese game of go, which kind of when people here look at it, it looks kind of like checkers, but it's actually way more sophisticated. Way More complicated than chess. I heard that there are more moves in go more potential than there are stars in the universe. Yes. So so then they had Alphago that this this uh, company deep mind which was later by Google. They built this algorithm that in 2016 defeated the world champions of going people thought that was, we were decades away and then deep mind created this new program called Alpha Zero Alpha zero with Alphago. They gave it access to all of the digitized games of go. So it very quickly was able to learn from how everybody else had played go alpha zero.

Speaker 1:          06:22          They just said here are the basic rules of go and they let Alphago just play against itself with no other experience other than here are the rules and play against in four days Alpha zero destroyed Alphago and then Alpha and then Alpha zero destroyed the world champions of chess and destroyed every other computer program that had ever played chess. And this again, those computer programs had internalized all of the chess games of grandmasters. Alpha zero had not internalized any, it just played against itself for a few days. And then Shogi, which is a Japanese traditional game, kind of like chess. It destroyed the grandmasters of that. So that's what I'm saying is that these, the world is changing. It's changing so much faster than we anticipate and we have to be as ready for that as we can. I think we need to come to grips with the fact that we're way stupider than we think we are.

Speaker 1:          07:19          We what we think we're really intelligent and we are in comparison to everything else on this planet. Yeah. But in comparison to what is possible, we are really fucking dumb in comparison to what this computer can do and what the, the future of that computers and what maybe that computer's going to redesign another computer. Yeah. This is good, but I've got some, I've got some hiccups here. Yeah, no, it's true. But, and yet the technology is us, right? It's like this. Not like this technology is some alien force. We've, it's like this. It's like we create art. We create. We could, yeah. You use that. You mentioned cities in order, like we create these cities, which are these incredible places where dreams can happen to cities like here in Los Angeles or New York where, where, where I'm from. So this technology is us and the challenge is how can we make sure that this technology serves our needs rather than undermines our needs.

Speaker 1:          08:08          Yeah. And whether or not our needs supersede the needs of the human race or supersedes the needs of the planet. Yeah. It's, we're, we're almost too much chimp, right, to contemplate these. Yeah. Critical decisions in terms of like what, how it's going to unfold from here on out. We really might not we, but the people that are actually at the tip of the spear of this stuff, they really might be affecting the way the planet is shaped absolutely. From now. And we're doing that now. I mean we are, there is an article came out the other day. There's a million species that are on the verge of extinction. We are driving all these other species to extinction where warming the planet. So this is humans are that the determining factor in many ways for how this planet plays out. And that's why in my mind, everything comes back to values.

Speaker 1:          08:58          We, you're right, we have this, this lizard nature, this, this monkey nature. It's, it's who we are. And that's, I mean, you wouldn't want to take that away because that's the core of, of, of what we are. And yet we're also a species that has created philosophy. We've created a beautiful religions in traditions and art. And the question is, which version of us is going to lead us into the future? If it's this, you know, tribal primate with these urges, like that's really frightening. If we can say, you know, we've done better and worse in history and we had this terrible second world war and yet at the end of the Second World War with American leadership, the world came together. We established at United Nations, we establish these concepts of human rights. Like you can't just kill everybody in your own country and say, hey, it's, it's just my business. So we have this capability. But it's always a struggle. I mean, neither these forces are always at war with each other in many ways. It's just too much to think about. Yeah. Well, we have, I know

Speaker 2:          10:00          we do have to. Um, one of the things that's always been amusing to me is that we seem to have this insatiable desire to improve things. Yeah. And I've always wondered why I like it, but is that maybe because this is what human beings are here for? It's what we do. It's who we are. Right? Yeah. But this is a product. It's just, uh, uh, us being intelligent, trying to survive against nature and predators and weather and all the, all the different issues that we came up that we evolved growing up and dealing with. And then now we just want things to be better. We just want things to be more convenient, faster, but more data.