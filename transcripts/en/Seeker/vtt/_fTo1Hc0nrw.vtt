WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.291
TRACE DOMINGUEZ: Hey, everyone.

00:00:01.291 --> 00:00:02.880
Thanks for tuning
in to Seeker Plus.

00:00:02.880 --> 00:00:04.482
I know this is also on Seeker.

00:00:04.482 --> 00:00:05.940
This is a slightly
different format

00:00:05.940 --> 00:00:08.820
where we get really deep into
a topic for a little while.

00:00:08.820 --> 00:00:09.700
So stick with us.

00:00:09.700 --> 00:00:10.697
I'm Trace.

00:00:10.697 --> 00:00:12.030
This is going to be really cool.

00:00:12.030 --> 00:00:14.397
We're talking about
artificial intelligence today.

00:00:14.397 --> 00:00:16.980
And we didn't want to present
it as artificial intelligence is

00:00:16.980 --> 00:00:19.820
scary or artificial
intelligence is the best,

00:00:19.820 --> 00:00:22.980
but come down in the middle
and give you both perspectives

00:00:22.980 --> 00:00:26.010
because there are people on both
sides of pretty much every one

00:00:26.010 --> 00:00:27.180
of these debates.

00:00:27.180 --> 00:00:28.140
So let's kick into it.

00:00:28.140 --> 00:00:29.723
Artificial intelligence
is everywhere,

00:00:29.723 --> 00:00:32.910
and it's growing both in
scope and also in scale.

00:00:32.910 --> 00:00:35.580
It's just getting
to be in everything.

00:00:35.580 --> 00:00:37.410
And people have strong
opinions on this.

00:00:37.410 --> 00:00:39.180
One article called
"The Debate Itself--

00:00:39.180 --> 00:00:41.520
Singulatarians Versus
Skeptics," which

00:00:41.520 --> 00:00:42.810
we thought was kind of cool.

00:00:42.810 --> 00:00:44.850
And people do see
artificial intelligence

00:00:44.850 --> 00:00:46.560
as a possible threat--

00:00:46.560 --> 00:00:48.730
people like Elon
Musk, Stephen Hawking,

00:00:48.730 --> 00:00:52.470
Bill Gates kind of, and at
one point Steve Wozniak.

00:00:52.470 --> 00:00:55.260
On the other side, people
see artificial intelligence

00:00:55.260 --> 00:00:57.630
as the future and
inevitable-- people

00:00:57.630 --> 00:01:00.570
like Larry Page of Google-- and
said that in order for Google

00:01:00.570 --> 00:01:04.530
to achieve its mission,
that means achieving AI.

00:01:04.530 --> 00:01:06.930
Mark Zuckerberg uses
AI to run his home,

00:01:06.930 --> 00:01:10.020
and Facebook is moving
towards having AI assistants.

00:01:10.020 --> 00:01:12.060
Even Uber has an AI division.

00:01:12.060 --> 00:01:17.160
So it is like this old tech
new tech and with Elon Musk

00:01:17.160 --> 00:01:18.450
right in the middle.

00:01:18.450 --> 00:01:21.350
But chances are you all
probably know this stuff already

00:01:21.350 --> 00:01:23.430
because you follow
Science News likely

00:01:23.430 --> 00:01:24.870
if you're watching this show.

00:01:24.870 --> 00:01:29.580
But one way to think about this
is positives and negatives.

00:01:29.580 --> 00:01:33.390
Everyone has an opinion about
AI, and both of those opinions

00:01:33.390 --> 00:01:34.260
are usually valid.

00:01:34.260 --> 00:01:37.920
So we thought we'd see how
the debate is put together

00:01:37.920 --> 00:01:40.120
rather than coming down
on one side or the other.

00:01:40.120 --> 00:01:42.120
So let's quickly define
artificial intelligence.

00:01:42.120 --> 00:01:45.990
It's not just robots and
chat bots and assistants.

00:01:45.990 --> 00:01:48.420
It's being used across all
sorts of fields in industries,

00:01:48.420 --> 00:01:50.580
and it's computers
and it's machines

00:01:50.580 --> 00:01:52.240
imitating human intelligence.

00:01:52.240 --> 00:01:54.270
But it's not just that.

00:01:54.270 --> 00:01:56.070
It's more than just learning.

00:01:56.070 --> 00:01:59.370
It's more than just
replicating our intelligence.

00:01:59.370 --> 00:02:01.410
It's about learning new
things, and it's also

00:02:01.410 --> 00:02:04.200
about the machines
learning on their own.

00:02:04.200 --> 00:02:07.470
The big idea, the big
concept here could be great,

00:02:07.470 --> 00:02:10.030
but it also could
be kind of scary.

00:02:10.030 --> 00:02:12.000
So let's talk about
different ways

00:02:12.000 --> 00:02:14.280
that you could apply
artificial intelligence.

00:02:14.280 --> 00:02:15.870
A big one being
talked about right

00:02:15.870 --> 00:02:19.230
now is artificially intelligent
automobiles, trucks,

00:02:19.230 --> 00:02:22.570
and cars that drive themselves,
which, if you think about it,

00:02:22.570 --> 00:02:24.030
that is an intelligent task.

00:02:24.030 --> 00:02:26.400
It requires decision making
and learning and learning

00:02:26.400 --> 00:02:27.930
from your experiences.

00:02:27.930 --> 00:02:29.700
And a big thing would be safety.

00:02:29.700 --> 00:02:33.210
90 percent of car
accidents now, car crashes,

00:02:33.210 --> 00:02:36.540
are caused by
humans, human error.

00:02:36.540 --> 00:02:38.760
Smart cars,
intelligent cars, they

00:02:38.760 --> 00:02:41.280
would be able to take in
the environment around them.

00:02:41.280 --> 00:02:44.246
GPS could tell them what
roads they're on and also

00:02:44.246 --> 00:02:46.620
what buildings are nearby and
other monuments and things,

00:02:46.620 --> 00:02:47.220
of course.

00:02:47.220 --> 00:02:48.900
They have cameras and scanners.

00:02:48.900 --> 00:02:51.570
So they can see the trees and
the way the road actually moves

00:02:51.570 --> 00:02:53.470
versus what it's supposed to do.

00:02:53.470 --> 00:02:55.770
And you can see things
like other cars.

00:02:55.770 --> 00:02:57.390
Which what if they
were smart, too?

00:02:57.390 --> 00:02:59.130
Then they could interact
with each other.

00:02:59.130 --> 00:03:02.130
And then you have this network
that is moving everywhere.

00:03:02.130 --> 00:03:03.924
What if you have
smart traffic lights?

00:03:03.924 --> 00:03:05.340
Eventually this
whole system could

00:03:05.340 --> 00:03:07.830
be one giant AI system
where they're all

00:03:07.830 --> 00:03:09.190
talking to each other.

00:03:09.190 --> 00:03:13.260
And then we could virtually
eliminate 90% of crashes,

00:03:13.260 --> 00:03:14.040
right?

00:03:14.040 --> 00:03:17.130
Assuming we're eliminating
all of the human error ones.

00:03:17.130 --> 00:03:19.050
Of course, there are
moral issues here.

00:03:19.050 --> 00:03:21.180
The car might be designed
to cause the least

00:03:21.180 --> 00:03:23.940
damage to the owner of the car.

00:03:23.940 --> 00:03:27.320
It might not want the car
to be destroyed in a crash.

00:03:27.320 --> 00:03:30.270
And so that's a moral question.

00:03:30.270 --> 00:03:32.610
Can the owner of the
car, say, a taxi company

00:03:32.610 --> 00:03:36.060
decide not to protect
passengers or predestines

00:03:36.060 --> 00:03:38.770
over protecting their property?

00:03:38.770 --> 00:03:40.430
This is an ethical dilemma.

00:03:40.430 --> 00:03:42.430
What about a guy who owns a car?

00:03:42.430 --> 00:03:44.830
He would want to protect
his family at all costs.

00:03:44.830 --> 00:03:46.990
But what if in doing
so it sacrificed

00:03:46.990 --> 00:03:49.240
other people's
property or destroyed

00:03:49.240 --> 00:03:51.400
other intelligent cars?

00:03:51.400 --> 00:03:53.770
It gets complicated
because nothing

00:03:53.770 --> 00:03:57.040
is black and white when you
get it out into the real world.

00:03:57.040 --> 00:03:59.650
And that's part of the problem
with artificial intelligence

00:03:59.650 --> 00:04:01.120
across the board right now--

00:04:01.120 --> 00:04:03.910
is that the real world is messy.

00:04:03.910 --> 00:04:07.570
Is it worth it to have a
self-driving intelligent car

00:04:07.570 --> 00:04:10.810
that might not think some
humans are worth saving

00:04:10.810 --> 00:04:14.320
over other humans or that some
property isn't worth saving

00:04:14.320 --> 00:04:18.220
over other property even if
it can prevent more accidents,

00:04:18.220 --> 00:04:21.910
even if it knows the fastest
routes and could drive itself,

00:04:21.910 --> 00:04:24.190
so you wouldn't need to
worry about people under age

00:04:24.190 --> 00:04:27.010
or people over age
or people who were

00:04:27.010 --> 00:04:30.760
too intoxicated or inebriated
in any number of different ways?

00:04:30.760 --> 00:04:32.890
At the end of the day,
intelligent automobiles

00:04:32.890 --> 00:04:35.709
mean that, on the good side,
we don't have to go to the DMV.

00:04:35.709 --> 00:04:37.500
We don't have to worry
about drunk driving.

00:04:37.500 --> 00:04:41.020
But on the bad side, we're
taking our control away

00:04:41.020 --> 00:04:43.720
from something that happens
all the time all around us

00:04:43.720 --> 00:04:45.640
especially in urban areas.

00:04:45.640 --> 00:04:50.129
So if you're in a car and
it's raining and you slide,

00:04:50.129 --> 00:04:52.420
you go around a corner and
maybe something bad happens.

00:04:52.420 --> 00:04:53.530
The road's too wet.

00:04:53.530 --> 00:04:55.049
The car did something wrong.

00:04:55.049 --> 00:04:56.590
It's either going
to destroy the life

00:04:56.590 --> 00:05:00.220
of the person in the car or
a pedestrian on the sidewalk.

00:05:00.220 --> 00:05:04.930
That decision is made by
a machine not by a human

00:05:04.930 --> 00:05:06.670
and maybe by somebody
who programmed

00:05:06.670 --> 00:05:08.080
or owned that machine.

00:05:08.080 --> 00:05:09.850
We as a society have
to make a decision

00:05:09.850 --> 00:05:13.120
to give up that control and
hand it to an artificially

00:05:13.120 --> 00:05:15.020
intelligent machine.

00:05:15.020 --> 00:05:16.990
How do you feel about that?

00:05:16.990 --> 00:05:18.040
It's a debate.

00:05:18.040 --> 00:05:19.900
There's good and
bad on both sides.

00:05:19.900 --> 00:05:22.000
And this applies
across the board.

00:05:22.000 --> 00:05:23.500
Let's go to another example--

00:05:23.500 --> 00:05:24.800
marketing.

00:05:24.800 --> 00:05:26.590
Marketing is
pervasive, especially

00:05:26.590 --> 00:05:27.891
in the era of the internet.

00:05:27.891 --> 00:05:29.890
Marketers want to know
where you're going to be,

00:05:29.890 --> 00:05:31.960
what you're going to
buy, and what it takes

00:05:31.960 --> 00:05:33.790
to get you to buy something.

00:05:33.790 --> 00:05:37.150
You shop for shoes
that one time,

00:05:37.150 --> 00:05:39.550
and now there's an ad for
shoes on every website you

00:05:39.550 --> 00:05:41.680
visit and that shoe and a
couple of other different shoes

00:05:41.680 --> 00:05:42.820
in a variety of true colors.

00:05:42.820 --> 00:05:44.950
And they're all really nice, and
you kind of want all of them.

00:05:44.950 --> 00:05:46.325
But you kind of
want none of them

00:05:46.325 --> 00:05:48.460
because they're just everywhere.

00:05:48.460 --> 00:05:51.760
Or maybe you regularly visit
a site on your computer

00:05:51.760 --> 00:05:54.250
before you buy something.

00:05:54.250 --> 00:05:56.500
Maybe you visit it 20 times.

00:05:56.500 --> 00:05:59.470
Now right now all of that stuff
happens and all of that data

00:05:59.470 --> 00:06:01.270
is there, but no
one's really looking

00:06:01.270 --> 00:06:03.640
at all of that data
except artificially

00:06:03.640 --> 00:06:05.050
intelligent machines.

00:06:05.050 --> 00:06:07.780
Predictive shopping and
also recommendation engines

00:06:07.780 --> 00:06:09.490
on Netflix and on Amazon--

00:06:09.490 --> 00:06:12.670
those are basic
artificial intelligences.

00:06:12.670 --> 00:06:15.580
So imagine if they
got way better.

00:06:15.580 --> 00:06:18.490
When you shop for something,
do you just go and buy it

00:06:18.490 --> 00:06:21.040
or do you visit the same
site once or twice, then

00:06:21.040 --> 00:06:24.350
maybe look at some reviews, then
maybe ask your friends about it

00:06:24.350 --> 00:06:26.110
and then go back and buy it?

00:06:26.110 --> 00:06:28.270
An artificial
intelligence system

00:06:28.270 --> 00:06:30.820
might be able to get you to
buy that sooner because they

00:06:30.820 --> 00:06:31.840
know your behavior.

00:06:31.840 --> 00:06:34.120
So when you go there
the first time,

00:06:34.120 --> 00:06:36.040
what if an artificial
intelligent system

00:06:36.040 --> 00:06:39.610
just pulled in recommendations
from the sites that you already

00:06:39.610 --> 00:06:42.550
visit that it knows you visit
because of the cookies--

00:06:42.550 --> 00:06:44.650
little files-- that
all of those sites

00:06:44.650 --> 00:06:46.630
have stored on your computer?

00:06:46.630 --> 00:06:48.730
What if it knew
your social network

00:06:48.730 --> 00:06:50.710
and it went to your
friends who it knew

00:06:50.710 --> 00:06:52.810
had bought from this
web site and already

00:06:52.810 --> 00:06:54.940
bought these types
of items and said,

00:06:54.940 --> 00:06:58.720
oh, here we know that all of
your friends like this thing

00:06:58.720 --> 00:07:00.880
and we know where
you've shopped before.

00:07:00.880 --> 00:07:03.280
And the artificially
intelligent system

00:07:03.280 --> 00:07:05.800
could anticipate what you want.

00:07:05.800 --> 00:07:07.810
Is that scary or is that good?

00:07:07.810 --> 00:07:09.700
Because sometimes I
kind of like shoes,

00:07:09.700 --> 00:07:11.290
but I don't know what I want.

00:07:11.290 --> 00:07:13.480
And maybe the computer can
tell me you do want this,

00:07:13.480 --> 00:07:15.040
and I might love it.

00:07:15.040 --> 00:07:18.400
But also it's kind of creepy
to know that the computer knows

00:07:18.400 --> 00:07:21.460
my shopping habits and knows
what websites I've visited

00:07:21.460 --> 00:07:24.220
and knows what my friends
like and is anticipating

00:07:24.220 --> 00:07:26.470
what I might like.

00:07:26.470 --> 00:07:28.420
Good but also bad.

00:07:28.420 --> 00:07:31.780
The Trump campaign tapped
into a marketing AI

00:07:31.780 --> 00:07:35.140
to help determine how it wanted
to send out its messaging.

00:07:35.140 --> 00:07:39.190
And this marketing AI claims
to have 45,000 data points

00:07:39.190 --> 00:07:41.650
on 230 million Americans.

00:07:41.650 --> 00:07:44.100
They claim that they know
what makes us angry, happy,

00:07:44.100 --> 00:07:46.150
impassioned, or despondent.

00:07:46.150 --> 00:07:47.920
That's a lot of
power for somebody

00:07:47.920 --> 00:07:50.620
to have and be able
to then manipulate

00:07:50.620 --> 00:07:52.919
all sorts of different
people into doing

00:07:52.919 --> 00:07:55.210
what they want because that's
what marketing is about--

00:07:55.210 --> 00:07:57.984
is I want to market
something to you.

00:07:57.984 --> 00:07:59.650
I have to know how
to reach you in order

00:07:59.650 --> 00:08:03.560
to do that and push your buttons
and all sorts of other things.

00:08:03.560 --> 00:08:06.070
The idea is to get you to make
an emotional decision rather

00:08:06.070 --> 00:08:08.320
than a rational one
from time to time.

00:08:08.320 --> 00:08:10.870
Again, good or bad?

00:08:10.870 --> 00:08:11.890
What do you think?

00:08:11.890 --> 00:08:13.270
How about in medicine?

00:08:13.270 --> 00:08:16.490
Medicine is a field with
huge amounts of data.

00:08:16.490 --> 00:08:19.030
But most of that data
is protected and stored

00:08:19.030 --> 00:08:22.100
in very specific places,
sometimes never even digitally.

00:08:22.100 --> 00:08:26.440
It's just papers or it's just
file names and not so much

00:08:26.440 --> 00:08:28.990
all of the stuff in the file.

00:08:28.990 --> 00:08:31.210
AI machines could
potentially take

00:08:31.210 --> 00:08:33.789
in huge amounts of this
data, like medical records,

00:08:33.789 --> 00:08:36.789
doctor's notes, treatment
options, disease histories,

00:08:36.789 --> 00:08:39.490
family histories,
genetic information,

00:08:39.490 --> 00:08:42.370
and find patterns that
could help doctors diagnose

00:08:42.370 --> 00:08:45.040
diseases in people that
they didn't even know

00:08:45.040 --> 00:08:46.530
would have them.

00:08:46.530 --> 00:08:48.140
Let me give you an example.

00:08:48.140 --> 00:08:51.070
If I can analyze, as an
intelligent machine, all

00:08:51.070 --> 00:08:54.400
of your medical history and
also all of everyone else's

00:08:54.400 --> 00:08:57.760
medical history, who has all
of these genetic markers, what

00:08:57.760 --> 00:09:00.640
if I can find a pattern and
then use that to diagnose you

00:09:00.640 --> 00:09:02.500
and many other people?

00:09:02.500 --> 00:09:05.050
Would that offset
the fact that I now

00:09:05.050 --> 00:09:09.820
have your medical
information and I'm using it?

00:09:09.820 --> 00:09:10.330
Yeah, sure.

00:09:10.330 --> 00:09:12.280
I'm using it to
help other people.

00:09:12.280 --> 00:09:13.240
Great.

00:09:13.240 --> 00:09:16.510
But I also have your
private medical data.

00:09:16.510 --> 00:09:18.050
Maybe not great.

00:09:18.050 --> 00:09:20.560
The AI system
doesn't necessarily

00:09:20.560 --> 00:09:23.920
care whether it has all of your
data, but the more data it has,

00:09:23.920 --> 00:09:26.440
the better it's going
to be able to do.

00:09:26.440 --> 00:09:28.690
It does involve
us giving up some

00:09:28.690 --> 00:09:32.020
of this control to an
intelligent machine

00:09:32.020 --> 00:09:34.690
in order to get a benefit back.

00:09:34.690 --> 00:09:36.670
On top of that, is
it good to take away

00:09:36.670 --> 00:09:39.070
humans from healthcare?

00:09:39.070 --> 00:09:43.960
Will we rely someday 100%
on computers diagnosing us?

00:09:43.960 --> 00:09:45.820
They don't really have emotions.

00:09:45.820 --> 00:09:47.260
They don't have gut feelings.

00:09:47.260 --> 00:09:50.500
They can't read real patients'
experience in the same way

00:09:50.500 --> 00:09:53.020
that a well-trained doctor can.

00:09:53.020 --> 00:09:56.530
However, computers can
examine data and find patterns

00:09:56.530 --> 00:09:58.870
in our genetic codes and things.

00:09:58.870 --> 00:10:02.810
Lists of symptoms really
help with computers,

00:10:02.810 --> 00:10:05.980
but doctors don't always
get the whole list.

00:10:05.980 --> 00:10:07.579
I've watched a lot of "House."

00:10:07.579 --> 00:10:10.120
I know there's a lot of lying
that goes on in the examination

00:10:10.120 --> 00:10:10.760
room.

00:10:10.760 --> 00:10:12.040
I have lied to my doctor.

00:10:12.040 --> 00:10:13.310
I imagine you have, too.

00:10:13.310 --> 00:10:14.560
How often do you drink a week?

00:10:14.560 --> 00:10:16.570
Oh, a couple of times.

00:10:16.570 --> 00:10:18.312
Is it a couple of
times or is it more?

00:10:18.312 --> 00:10:20.000
Mm?

00:10:20.000 --> 00:10:22.340
However, how many times
have you googled something

00:10:22.340 --> 00:10:25.600
that you don't want
to tell anybody about?

00:10:25.600 --> 00:10:27.130
Probably lots of times.

00:10:27.130 --> 00:10:30.850
So maybe, in this case,
again, good and bad.

00:10:30.850 --> 00:10:32.890
Real people have all
of these gut feelings

00:10:32.890 --> 00:10:35.560
and can help you
understand what's going on,

00:10:35.560 --> 00:10:37.180
but you'll tell
machines something

00:10:37.180 --> 00:10:39.010
that you may not tell people.

00:10:39.010 --> 00:10:40.690
So an artificially
intelligent doctor

00:10:40.690 --> 00:10:42.980
might be able to help
you in that way in a way

00:10:42.980 --> 00:10:45.220
that a person can't
and vice versa.

00:10:45.220 --> 00:10:47.520
Really interesting discussion.

00:10:47.520 --> 00:10:48.960
We don't have the answer.

00:10:48.960 --> 00:10:50.160
Maybe you do.

00:10:50.160 --> 00:10:51.150
Let us know.

00:10:51.150 --> 00:10:51.720
So moving on.

00:10:51.720 --> 00:10:53.370
What about jobs?

00:10:53.370 --> 00:10:56.910
And specifically certain jobs.

00:10:56.910 --> 00:10:59.250
An Oxford study that
came out in 2013

00:10:59.250 --> 00:11:02.610
looked at 700 different jobs
and assessed their ability

00:11:02.610 --> 00:11:06.780
to be automated and their
probability that they would be.

00:11:06.780 --> 00:11:09.012
The jobs at the top of the
list, which is actually

00:11:09.012 --> 00:11:10.470
the bottom of the
list, were things

00:11:10.470 --> 00:11:15.870
like legal advising, marketing,
bank teller, tax prep, shipping

00:11:15.870 --> 00:11:18.630
and cargo control, in
fact, most everything

00:11:18.630 --> 00:11:21.900
you can think of for retail
and auditing and tax adjusting,

00:11:21.900 --> 00:11:23.070
even sports--

00:11:23.070 --> 00:11:24.900
things like umpires and refs.

00:11:24.900 --> 00:11:28.450
They were the number 15
most automatable job.

00:11:28.450 --> 00:11:31.530
Why do I need a referee if I
have an intelligent system that

00:11:31.530 --> 00:11:32.850
can do this job?

00:11:32.850 --> 00:11:35.520
It's just assessing the rules
and debating whether or not

00:11:35.520 --> 00:11:36.990
somebody had broken them.

00:11:36.990 --> 00:11:38.910
That is easy to
do for a computer.

00:11:38.910 --> 00:11:41.910
It's not as easy to do with
a referee or an umpire.

00:11:41.910 --> 00:11:43.770
Sports journalism,
even, has already

00:11:43.770 --> 00:11:47.070
been done in large part
much of it by robots.

00:11:47.070 --> 00:11:48.990
Humans are just
slower at this stuff.

00:11:48.990 --> 00:11:50.910
And calculating is
what computers do.

00:11:50.910 --> 00:11:54.060
So isn't this some place
where artificial intelligence

00:11:54.060 --> 00:11:55.156
is going to come in?

00:11:55.156 --> 00:11:57.030
Now many of you are
probably already thinking

00:11:57.030 --> 00:12:00.090
about how computers and
robots have taken some jobs.

00:12:00.090 --> 00:12:02.640
And the first things that
pop into people's heads are--

00:12:02.640 --> 00:12:04.530
at least people like
myself from Michigan--

00:12:04.530 --> 00:12:05.940
is the auto industry.

00:12:05.940 --> 00:12:08.580
It's already taken a lot
of jobs there-- automation.

00:12:08.580 --> 00:12:10.200
It's not people building cars.

00:12:10.200 --> 00:12:12.840
It's people managing
robots building cars.

00:12:12.840 --> 00:12:15.270
This has also happened
in cargo ships

00:12:15.270 --> 00:12:16.950
and in shipping in general.

00:12:16.950 --> 00:12:20.010
In fact, "99% Invisible"
and Alex Madrigal

00:12:20.010 --> 00:12:22.080
came out with this really
great audio documentary

00:12:22.080 --> 00:12:23.700
called "Containers."

00:12:23.700 --> 00:12:25.459
It was featured on
"99% Invisible."

00:12:25.459 --> 00:12:26.250
It was really good.

00:12:26.250 --> 00:12:27.420
So go check it out.

00:12:27.420 --> 00:12:29.130
And it talks all
about how docks used

00:12:29.130 --> 00:12:32.070
to be this really exciting place
filled with people and smells

00:12:32.070 --> 00:12:32.910
and sights.

00:12:32.910 --> 00:12:34.470
And now it's more automated.

00:12:34.470 --> 00:12:36.480
And one person with a
crane moves containers

00:12:36.480 --> 00:12:37.990
from one place to another.

00:12:37.990 --> 00:12:38.940
It's very different.

00:12:38.940 --> 00:12:41.310
All of that is
automation taking over.

00:12:41.310 --> 00:12:44.070
Now imagine why do we need
the person operating the crane

00:12:44.070 --> 00:12:46.620
if we have an artificial
intelligence that can do that

00:12:46.620 --> 00:12:49.800
and it can do it faster
and more precisely?

00:12:49.800 --> 00:12:50.640
Interesting.

00:12:50.640 --> 00:12:53.400
What about automation in
a variety of other things

00:12:53.400 --> 00:12:54.494
like when you buy coffee?

00:12:54.494 --> 00:12:56.160
Do I really need to
buy it from a person

00:12:56.160 --> 00:12:58.560
if I have an artificially
intelligent system that

00:12:58.560 --> 00:13:00.540
can bring me that coffee?

00:13:00.540 --> 00:13:03.090
Sidebar-- the vending
machine, where

00:13:03.090 --> 00:13:04.890
you get snacks or whatever.

00:13:04.890 --> 00:13:07.990
That's technically an
artificial intelligence system.

00:13:07.990 --> 00:13:09.450
It knows how much
money you put in.

00:13:09.450 --> 00:13:10.830
It knows what you want.

00:13:10.830 --> 00:13:12.780
And then you walk away.

00:13:12.780 --> 00:13:16.290
The first vending machines
showed up in 1070 in China.

00:13:16.290 --> 00:13:18.800
They were coin operated
pencil vending machines.

00:13:18.800 --> 00:13:21.780
In the 1970s, there were
machines that dispensed tobacco

00:13:21.780 --> 00:13:22.380
at taverns.

00:13:22.380 --> 00:13:25.290
And by the late 1800s, you
could get paper, envelopes,

00:13:25.290 --> 00:13:27.720
postcards, gum, and
things on train platforms

00:13:27.720 --> 00:13:28.950
and at post offices.

00:13:28.950 --> 00:13:30.952
And that was somebody's
livelihood before.

00:13:30.952 --> 00:13:32.910
That was somebody who
was selling you envelopes

00:13:32.910 --> 00:13:36.270
and gum or tobacco or pencils.

00:13:36.270 --> 00:13:38.730
So robots and automation
have been taking jobs

00:13:38.730 --> 00:13:40.570
for a long time-- end sidebar.

00:13:40.570 --> 00:13:42.360
Anyway, back to
this Oxford study

00:13:42.360 --> 00:13:44.460
because it's super interesting.

00:13:44.460 --> 00:13:46.590
Humans are slower
at calculating,

00:13:46.590 --> 00:13:47.910
like we were saying.

00:13:47.910 --> 00:13:52.830
But if you take tax prep jobs,
bank teller jobs, retail jobs

00:13:52.830 --> 00:13:54.990
and you give them to
intelligent machines,

00:13:54.990 --> 00:13:59.070
we are again giving up
control, giving up access

00:13:59.070 --> 00:14:01.800
to something that used
to be done by humans

00:14:01.800 --> 00:14:06.410
and was also a point of
contact of me with a stranger

00:14:06.410 --> 00:14:08.510
or you with a friend.

00:14:08.510 --> 00:14:11.780
We're giving that to a machine,
which some people come down

00:14:11.780 --> 00:14:12.740
on the good side of--

00:14:12.740 --> 00:14:15.281
I don't want to have to interact
with somebody to get coffee.

00:14:15.281 --> 00:14:16.370
I just want coffee--

00:14:16.370 --> 00:14:18.650
and some people come
down on the bad side of--

00:14:18.650 --> 00:14:23.870
I would rather have my
person than my coffee.

00:14:23.870 --> 00:14:25.850
It's part of my morning ritual.

00:14:25.850 --> 00:14:27.674
It's part of how I
go through my day.

00:14:27.674 --> 00:14:29.090
And if you take
that away from me,

00:14:29.090 --> 00:14:31.423
then that's one less person
that I get to interact with,

00:14:31.423 --> 00:14:33.980
and that makes me happy.

00:14:33.980 --> 00:14:36.750
Artificial intelligence can
do so many different things,

00:14:36.750 --> 00:14:39.480
and it will do so many
different things in the future.

00:14:39.480 --> 00:14:44.030
But for now, it's all
a matter of debate.

00:14:44.030 --> 00:14:46.250
On top of that, again,
another sidebar.

00:14:46.250 --> 00:14:49.700
If you take away retail and all
of these low level entry level

00:14:49.700 --> 00:14:53.190
jobs, what replaces them?

00:14:53.190 --> 00:14:54.440
What happens then?

00:14:54.440 --> 00:14:56.190
How does someone in
high school or college

00:14:56.190 --> 00:14:58.710
get into the workforce
or pay for college?

00:14:58.710 --> 00:15:01.020
How do they earn money if
an artificial intelligence

00:15:01.020 --> 00:15:02.460
is already doing that job?

00:15:02.460 --> 00:15:06.030
How do you get started at work
if all of the entry level jobs

00:15:06.030 --> 00:15:08.250
are done by machines?

00:15:08.250 --> 00:15:09.250
An interesting question.

00:15:09.250 --> 00:15:12.060
There's no real answer
to that at the moment.

00:15:12.060 --> 00:15:14.010
What about an education?

00:15:14.010 --> 00:15:16.920
Right now the education
system is in peril.

00:15:16.920 --> 00:15:18.390
We need more money for schools.

00:15:18.390 --> 00:15:19.776
We need less money for schools.

00:15:19.776 --> 00:15:21.150
It depends on who
you ask, and it

00:15:21.150 --> 00:15:24.330
depends on what outlook you have
on the future of our education

00:15:24.330 --> 00:15:25.380
system.

00:15:25.380 --> 00:15:28.500
But an obvious downfall
of artificial intelligence

00:15:28.500 --> 00:15:31.140
moving into education
is taking the roles

00:15:31.140 --> 00:15:33.840
of teachers, where
an obvious upside is

00:15:33.840 --> 00:15:36.660
that an artificial intelligence
will be able to do the best

00:15:36.660 --> 00:15:40.355
job at teaching in terms of
knowing what you need to learn

00:15:40.355 --> 00:15:42.480
and knowing how to present
that information to you,

00:15:42.480 --> 00:15:44.280
so that you learn at the best.

00:15:44.280 --> 00:15:45.570
When people say that they're--

00:15:45.570 --> 00:15:47.535
I'm a visual learner,
I'm a reading learner,

00:15:47.535 --> 00:15:48.882
or I'm an audio learner--

00:15:48.882 --> 00:15:50.340
an artificially
intelligent machine

00:15:50.340 --> 00:15:52.020
can do all of those
things equally well,

00:15:52.020 --> 00:15:53.394
whereas a teacher
might be better

00:15:53.394 --> 00:15:55.750
at some rather than others.

00:15:55.750 --> 00:15:56.610
It's a debate.

00:15:56.610 --> 00:15:59.370
And, again, we're relinquishing
this control over something

00:15:59.370 --> 00:16:02.040
that we have traditionally
had control over in order

00:16:02.040 --> 00:16:04.030
to potentially have an upside.

00:16:04.030 --> 00:16:06.810
But that upside might
also have a downside.

00:16:06.810 --> 00:16:09.690
Even assisting the teacher
would be really interesting

00:16:09.690 --> 00:16:13.500
because the AI maybe do tutor
stuff with individual students

00:16:13.500 --> 00:16:16.500
on an individual basis very
personalized for what they

00:16:16.500 --> 00:16:19.470
need, while the teacher is
there to give them social skills

00:16:19.470 --> 00:16:22.650
and interaction and make sure
that the classroom as a whole

00:16:22.650 --> 00:16:25.710
is progressing together.

00:16:25.710 --> 00:16:27.360
They can work together.

00:16:27.360 --> 00:16:30.300
This debate does often
feel black and white,

00:16:30.300 --> 00:16:33.075
but perhaps it's
less so because,

00:16:33.075 --> 00:16:35.215
if everyone is learning
from a computer

00:16:35.215 --> 00:16:36.840
but they're getting
their social skills

00:16:36.840 --> 00:16:40.639
from other humans, what does
that mean for how we think?

00:16:40.639 --> 00:16:42.180
Are we going to have
trouble thinking

00:16:42.180 --> 00:16:44.310
when interacting with humans?

00:16:44.310 --> 00:16:47.130
| posing more questions than
I'm answering in this episode,

00:16:47.130 --> 00:16:50.220
but I think the exciting thing
is that artificial intelligence

00:16:50.220 --> 00:16:53.760
holds so much promise in so many
different areas of our culture

00:16:53.760 --> 00:16:56.910
and our experience
and our abilities

00:16:56.910 --> 00:17:00.390
to do more in the future
that, when people say,

00:17:00.390 --> 00:17:02.940
I'm afraid of the
robot takeover,

00:17:02.940 --> 00:17:05.760
they're obviously only
looking at this bad column

00:17:05.760 --> 00:17:08.040
and not at this good column.

00:17:08.040 --> 00:17:10.349
Because we could learn
quicker and better and more

00:17:10.349 --> 00:17:10.890
personalized.

00:17:10.890 --> 00:17:12.630
We could have more
personalized medicine.

00:17:12.630 --> 00:17:16.680
We could have better automobiles
and automobile safety.

00:17:16.680 --> 00:17:19.710
But we'd also not
control those cars.

00:17:19.710 --> 00:17:23.010
We'd not control our
healthcare data as easily.

00:17:23.010 --> 00:17:25.400
We wouldn't have as
much social interaction.

00:17:25.400 --> 00:17:26.970
We bought coffee maybe.

00:17:26.970 --> 00:17:29.280
There are things
you have to give up.

00:17:29.280 --> 00:17:31.260
But we've given
up things before.

00:17:31.260 --> 00:17:32.641
And we're OK now.

00:17:32.641 --> 00:17:34.140
There are lots of
other applications

00:17:34.140 --> 00:17:36.723
that we don't have time to get
into, like in the entertainment

00:17:36.723 --> 00:17:38.850
industry, in the
security industry,

00:17:38.850 --> 00:17:43.350
in systems that make music or
make movies or write stories.

00:17:43.350 --> 00:17:46.590
AI can be good, but, like
everything, maybe it's

00:17:46.590 --> 00:17:48.690
AI in moderation.

00:17:48.690 --> 00:17:50.490
If every aspect of
our lives is being

00:17:50.490 --> 00:17:52.920
driven by intelligent
machines, does that

00:17:52.920 --> 00:17:56.950
take away our ability to
be intelligent ourselves?

00:17:56.950 --> 00:17:57.610
I don't know.

00:17:57.610 --> 00:17:58.780
Think about it.

00:17:58.780 --> 00:18:00.280
A lot of what humans
have been doing

00:18:00.280 --> 00:18:03.340
over the last few millennia
is just figuring out

00:18:03.340 --> 00:18:05.290
how to live our
lives on this planet

00:18:05.290 --> 00:18:09.100
and how to make the best of the
situation that we are all in.

00:18:09.100 --> 00:18:12.277
We're in a giant aquarium
floating in space,

00:18:12.277 --> 00:18:14.860
and we're all trying to figure
out the best way to live inside

00:18:14.860 --> 00:18:16.510
of this bubble.

00:18:16.510 --> 00:18:19.150
AI can help us with
that potentially,

00:18:19.150 --> 00:18:21.560
but it will change things.

00:18:21.560 --> 00:18:23.980
So where do you
come down on that?

00:18:23.980 --> 00:18:26.350
If AI can do all these
things that we used to have

00:18:26.350 --> 00:18:28.774
to do, then what do we do?

00:18:28.774 --> 00:18:29.440
All right, guys.

00:18:29.440 --> 00:18:30.910
Thanks so much for
watching this episode

00:18:30.910 --> 00:18:32.200
about artificial intelligence.

00:18:32.200 --> 00:18:34.200
Let us know what you think
down in the comments.

00:18:34.200 --> 00:18:36.910
Make sure that you watch last
week's episode on InfraRed

00:18:36.910 --> 00:18:37.870
right here.

00:18:37.870 --> 00:18:40.020
And one more favor to ask.

00:18:40.020 --> 00:18:42.700
Please go over to
vote.webbyawards.com

00:18:42.700 --> 00:18:45.160
because we got nominated for
a Webby in the people's choice

00:18:45.160 --> 00:18:46.710
category, and we need your vote.

00:18:46.710 --> 00:18:48.450
It's for the Edge
of Space video we

00:18:48.450 --> 00:18:50.976
did where we sent a camera
into the stratosphere.

00:18:50.976 --> 00:18:52.600
It's so cool if you
haven't watched it.

00:18:52.600 --> 00:18:54.600
Go watch it.

