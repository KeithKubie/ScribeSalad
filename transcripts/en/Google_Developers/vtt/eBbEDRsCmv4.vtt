WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.380
[MUSIC PLAYING]

00:00:03.437 --> 00:00:05.770
DANDELION MANE: I always wind
up doing these live demos,

00:00:05.770 --> 00:00:07.978
so I never get the privilege
of just jumping straight

00:00:07.978 --> 00:00:12.700
into slides, and so there's some
amount of computer wrangling.

00:00:12.700 --> 00:00:15.460
But [INAUDIBLE]?

00:00:15.460 --> 00:00:19.600
All right, so my
name is Dandelion.

00:00:19.600 --> 00:00:21.850
I'm the only person I know
who has an emoji signature.

00:00:21.850 --> 00:00:25.239
It's the dandelion emoji
and then the lion emoji,

00:00:25.239 --> 00:00:27.280
although I didn't actually
put this on the slide.

00:00:27.280 --> 00:00:29.980
And I'm here to talk
about TensorBoard.

00:00:29.980 --> 00:00:31.930
So TensorBoard is a
really exciting tool.

00:00:31.930 --> 00:00:34.570
It's been built by a number
of engineers at Google.

00:00:34.570 --> 00:00:36.160
And the basic idea
behind TensorBoard

00:00:36.160 --> 00:00:39.220
is everyone knows that
neural networks can sometimes

00:00:39.220 --> 00:00:41.065
be a bit of a black box.

00:00:41.065 --> 00:00:42.940
And so we want to
TensorBoard to be something

00:00:42.940 --> 00:00:44.530
of a flashlight,
something that will

00:00:44.530 --> 00:00:46.990
let you take the confusing
world of TensorFlow

00:00:46.990 --> 00:00:48.970
and start to dive into it.

00:00:48.970 --> 00:00:50.480
Now it's a pretty
complicated tool.

00:00:50.480 --> 00:00:52.184
It's got a lot of
bits and pieces.

00:00:52.184 --> 00:00:54.100
So the way that I'm going
to explain it to you

00:00:54.100 --> 00:00:56.150
is by going through an example.

00:00:56.150 --> 00:00:59.172
So we're going to take
a simple MNIST model.

00:00:59.172 --> 00:01:00.880
It's going to have a
couple convolutional

00:01:00.880 --> 00:01:02.489
and pooling layers at the top.

00:01:02.489 --> 00:01:04.780
And then it's going to have
two fully connected layers.

00:01:04.780 --> 00:01:06.820
And then it's going to
spit out our prediction.

00:01:06.820 --> 00:01:09.790
And we're going to just build
this model together and explore

00:01:09.790 --> 00:01:12.070
what can go wrong and how
we can use TensorBoard

00:01:12.070 --> 00:01:13.850
to better understand it.

00:01:13.850 --> 00:01:16.280
So I'm about to show
a bunch of code.

00:01:16.280 --> 00:01:18.080
I'm going to go through
it kind of quickly.

00:01:18.080 --> 00:01:20.163
You don't need to worry
about getting all the code

00:01:20.163 --> 00:01:23.140
right now because it's posted
on my GitHub as a gist,

00:01:23.140 --> 00:01:26.800
and we'll also tweet
out the link at the end.

00:01:26.800 --> 00:01:30.199
So to start, let's put together
some layers in TensorFlow.

00:01:30.199 --> 00:01:31.990
So we wanted to have
a convolutional layer.

00:01:31.990 --> 00:01:33.650
So we're going to
make two variables.

00:01:33.650 --> 00:01:35.922
These will have the
weights and the biases.

00:01:35.922 --> 00:01:37.880
We're going to then apply
the convolutional op,

00:01:37.880 --> 00:01:41.170
we're going to apply a
reLU to the convolution

00:01:41.170 --> 00:01:44.380
plus the biases, and
then we return that.

00:01:44.380 --> 00:01:46.600
Then we're going to make
a fully connected layer.

00:01:46.600 --> 00:01:48.040
This is even simpler.

00:01:48.040 --> 00:01:50.590
Once again, we have
weights and biases.

00:01:50.590 --> 00:01:54.310
We're going to do the reLU
of the matrix multiplication

00:01:54.310 --> 00:01:56.999
and addition, and
we return that.

00:01:56.999 --> 00:01:58.790
Now that we have some
layers, we can set up

00:01:58.790 --> 00:02:00.930
the feed-forward
part of our network.

00:02:00.930 --> 00:02:03.515
We have some input placeholders
which we'll just take

00:02:03.515 --> 00:02:05.960
in our images and our labels.

00:02:05.960 --> 00:02:08.870
We'll reshape the image so that
it actually looks like a 28

00:02:08.870 --> 00:02:11.796
by 28 pixels so we
can convolve on it.

00:02:11.796 --> 00:02:13.670
Then we'll start putting
together our layers.

00:02:13.670 --> 00:02:15.800
We've got the two
convolutional layers.

00:02:15.800 --> 00:02:18.560
We flatten it, we get the
two fully connected layers.

00:02:18.560 --> 00:02:20.750
And that's basically
our whole network.

00:02:20.750 --> 00:02:22.550
And finally, we need
to compute the loss

00:02:22.550 --> 00:02:24.560
and start to actually
train things.

00:02:24.560 --> 00:02:28.389
So we're going to use cross
entropy for our loss function.

00:02:28.389 --> 00:02:30.680
We're going to use an Adam
optimizer to do the training

00:02:30.680 --> 00:02:31.700
step.

00:02:31.700 --> 00:02:34.160
And just for convenience,
we'll record the accuracy

00:02:34.160 --> 00:02:36.965
so that we can print
that out to the console.

00:02:36.965 --> 00:02:39.090
So finally, we just need
to do a little bit of work

00:02:39.090 --> 00:02:40.877
to turn this model on.

00:02:40.877 --> 00:02:42.960
We're going to iterate--
we're going to initialize

00:02:42.960 --> 00:02:44.790
all of the variables.

00:02:44.790 --> 00:02:46.980
Then we're going to do
2,000 steps of training.

00:02:46.980 --> 00:02:49.021
For each step, we're going
to take an [INAUDIBLE]

00:02:49.021 --> 00:02:50.850
of the MNIST training data.

00:02:50.850 --> 00:02:52.960
Occasionally, we're going
to report the accuracy

00:02:52.960 --> 00:02:54.580
so we can see if it's working.

00:02:54.580 --> 00:02:57.860
And then finally, we'll
run the training step.

00:02:57.860 --> 00:02:59.120
So we have our model.

00:02:59.120 --> 00:03:00.900
Let's turn it on.

00:03:00.900 --> 00:03:03.470
At zero step, it
has 10% accuracy.

00:03:03.470 --> 00:03:04.960
That seems about right.

00:03:04.960 --> 00:03:08.300
At step 500, it
has 12% accuracy.

00:03:08.300 --> 00:03:10.310
Not exactly what
we were hoping for.

00:03:10.310 --> 00:03:11.720
And then it even goes down.

00:03:11.720 --> 00:03:14.720
And we can see really, this
model didn't learn anything.

00:03:14.720 --> 00:03:18.310
It's just getting baseline
10% by random guessing.

00:03:18.310 --> 00:03:21.226
So what are we going to do
about this broken model?

00:03:21.226 --> 00:03:22.850
Well, I just said we
have a flashlight,

00:03:22.850 --> 00:03:23.765
so let's turn it on.

00:03:23.765 --> 00:03:25.390
And the first thing
we might want to do

00:03:25.390 --> 00:03:28.180
is visualize the computational
structure of our TensorFlow

00:03:28.180 --> 00:03:29.110
graph.

00:03:29.110 --> 00:03:31.000
Because we spent all
this code setting it up,

00:03:31.000 --> 00:03:32.350
but what if it's miswired?

00:03:32.350 --> 00:03:34.690
What if somehow we just
didn't make the connections

00:03:34.690 --> 00:03:37.040
or the computation we expected?

00:03:37.040 --> 00:03:38.890
So we're going to need
something called--

00:03:38.890 --> 00:03:41.080
we're going to need a class
that lets us write data

00:03:41.080 --> 00:03:44.920
from TensorFlow to disk so that
we can read it TensorBoard.

00:03:44.920 --> 00:03:46.854
And that class is
called the FileWriter.

00:03:46.854 --> 00:03:48.520
It basically just
writes any information

00:03:48.520 --> 00:03:50.710
you're going to
visualize in TensorBoard.

00:03:50.710 --> 00:03:52.760
And to visualize the
graph, it's very simple.

00:03:52.760 --> 00:03:54.040
We set up the FileWriter.

00:03:54.040 --> 00:03:55.420
We give it a directory.

00:03:55.420 --> 00:03:59.370
And then we add to our
sessions graph to that writer.

00:03:59.370 --> 00:04:01.930
And now finally, we just
turn on TensorBoard.

00:04:01.930 --> 00:04:03.719
It comes pre-installed
in the PIP package,

00:04:03.719 --> 00:04:05.260
so you can just, at
the command line,

00:04:05.260 --> 00:04:08.290
write TensorBoard
and pass it a logdir.

00:04:08.290 --> 00:04:17.100
And that brings us to our
first demo, which is here.

00:04:17.100 --> 00:04:19.500
So it has no scale or
information, has no images.

00:04:19.500 --> 00:04:21.300
The only thing we
gave it is a graph.

00:04:21.300 --> 00:04:23.220
So we can go to the graph tab.

00:04:23.220 --> 00:04:27.242
And we get something that's
really quite confusing.

00:04:27.242 --> 00:04:28.950
So I can kind of see
how this corresponds

00:04:28.950 --> 00:04:29.850
to the graph we made.

00:04:29.850 --> 00:04:32.225
Because maybe we see on the
left we've got a convolution,

00:04:32.225 --> 00:04:35.400
we've got some addition, we've
got a reLU, we've got pooling.

00:04:35.400 --> 00:04:37.560
But it also has all of
these parts that I really

00:04:37.560 --> 00:04:40.080
don't have any idea where they
came from even though I just

00:04:40.080 --> 00:04:41.940
made the graph myself.

00:04:41.940 --> 00:04:44.160
So what we're seeing here
is that TensorFlow graphs

00:04:44.160 --> 00:04:45.600
are really complicated.

00:04:45.600 --> 00:04:48.310
And the way that we can get
this tool to actually give us

00:04:48.310 --> 00:04:50.640
useful insight, we need
to do a little bit of work

00:04:50.640 --> 00:04:52.170
to structure the graph.

00:04:52.170 --> 00:04:54.630
So essentially, we need
to clean the graph.

00:04:54.630 --> 00:04:58.350
Now you may know that every
TensorFlow graph is based

00:04:58.350 --> 00:05:01.320
on this naming system
where it has these ops

00:05:01.320 --> 00:05:03.300
and the ops have names.

00:05:03.300 --> 00:05:05.670
We can control the names
by giving individual nodes

00:05:05.670 --> 00:05:08.670
specific names and by setting
up names scopes, which

00:05:08.670 --> 00:05:11.610
cause all groups of related
ops to have the same naming

00:05:11.610 --> 00:05:12.940
structure.

00:05:12.940 --> 00:05:15.770
So let's go and apply that
to the model we just built.

00:05:15.770 --> 00:05:17.480
First, in our layer
definition, we're

00:05:17.480 --> 00:05:19.550
going to take a couple
ops that are important,

00:05:19.550 --> 00:05:22.100
like the variables, and
give them explicit names,

00:05:22.100 --> 00:05:24.860
like W for Weights
and B for Biases.

00:05:24.860 --> 00:05:26.570
And then we're going
to apply name scopes

00:05:26.570 --> 00:05:29.150
to the entire layers so that
all of our convolutional ops

00:05:29.150 --> 00:05:33.024
will stay grouped and likewise
in the fully connected layer.

00:05:33.024 --> 00:05:34.690
Then, when we actually
set up our graph,

00:05:34.690 --> 00:05:37.360
we pass a couple of more names,
like giving the placeholders

00:05:37.360 --> 00:05:38.110
names.

00:05:38.110 --> 00:05:42.067
And we use this function to
give name scopes to our layers.

00:05:42.067 --> 00:05:43.900
And finally, we add a
couple of names scopes

00:05:43.900 --> 00:05:47.380
to the training and the loss
computation and so forth.

00:05:47.380 --> 00:05:49.450
So now that we've
done that, we can

00:05:49.450 --> 00:05:51.970
construct another summary
FileWriter pointing

00:05:51.970 --> 00:05:53.170
at a different directory.

00:05:53.170 --> 00:05:55.003
You always want to use
a different directory

00:05:55.003 --> 00:05:56.890
with TensorBoard to
keep data separated.

00:05:56.890 --> 00:06:01.070
And we can turn on TensorBoard
pointing in that directory.

00:06:01.070 --> 00:06:03.117
And now we get a
much nicer graph.

00:06:03.117 --> 00:06:04.700
So you can see here
that this actually

00:06:04.700 --> 00:06:07.160
starts to correspond pretty
meaningfully to the graph

00:06:07.160 --> 00:06:08.594
that we had in mind.

00:06:08.594 --> 00:06:10.010
We have this
training block, which

00:06:10.010 --> 00:06:11.234
is connected to everything.

00:06:11.234 --> 00:06:13.400
That's because when you are
computing the gradients,

00:06:13.400 --> 00:06:15.839
you need to connect to
every variable in the graph.

00:06:15.839 --> 00:06:17.630
But maybe for now we'll
move it to the side

00:06:17.630 --> 00:06:19.554
because it's not as
interesting to us.

00:06:19.554 --> 00:06:21.470
And now we can kind of
explore and say, OK, we

00:06:21.470 --> 00:06:23.690
have our x placeholder.

00:06:23.690 --> 00:06:24.740
We reshaped the data.

00:06:24.740 --> 00:06:26.960
Then we go through each of
these convolutional layers

00:06:26.960 --> 00:06:28.490
where we have some variables.

00:06:28.490 --> 00:06:30.975
We have the convolution
and the addition.

00:06:30.975 --> 00:06:32.600
And we can kind of
scan through a graph

00:06:32.600 --> 00:06:36.194
and see that everything is wired
up the way that we expected.

00:06:36.194 --> 00:06:37.610
Now, I'll point
out a few features

00:06:37.610 --> 00:06:38.991
of the graph visualizer.

00:06:38.991 --> 00:06:40.490
One thing is, as
you've noticed, you

00:06:40.490 --> 00:06:43.880
can explore different layers
of levels of abstraction

00:06:43.880 --> 00:06:46.290
by diving into
individual pieces.

00:06:46.290 --> 00:06:48.099
And we can dive in further.

00:06:48.099 --> 00:06:49.640
And here, we're
getting the mechanics

00:06:49.640 --> 00:06:51.069
of computing cross entropy.

00:06:51.069 --> 00:06:52.610
It turns out all of
this sliced stuff

00:06:52.610 --> 00:06:55.084
was for computing cross entropy.

00:06:55.084 --> 00:06:56.750
Also, you'll notice
that different boxes

00:06:56.750 --> 00:06:58.310
have different colors.

00:06:58.310 --> 00:07:00.320
The way that the graph
visualizer works is it

00:07:00.320 --> 00:07:03.440
identifies repeated, similar
substructures of the graph

00:07:03.440 --> 00:07:04.970
and gives them the same color.

00:07:04.970 --> 00:07:07.730
So we can be sure that these
two fully connected layers have

00:07:07.730 --> 00:07:10.040
the exact same
structure as each other

00:07:10.040 --> 00:07:12.206
because they are
both colored green.

00:07:12.206 --> 00:07:13.580
Now this sounds
like it might not

00:07:13.580 --> 00:07:15.044
be such an important feature.

00:07:15.044 --> 00:07:16.460
But actually, when
we were porting

00:07:16.460 --> 00:07:18.980
the inception graph
over to TensorFlow

00:07:18.980 --> 00:07:20.360
back a year and a half ago--

00:07:20.360 --> 00:07:22.940
and this is a very complicated
graph with tens of thousands

00:07:22.940 --> 00:07:24.957
of nodes, we were
stuck for weeks.

00:07:24.957 --> 00:07:26.540
And we were getting
the wrong results.

00:07:26.540 --> 00:07:29.390
And we actually thought maybe
TensorFlow was just broken.

00:07:29.390 --> 00:07:31.880
Maybe we had spent like a year
developing this new software

00:07:31.880 --> 00:07:33.599
and it just wasn't
going to train.

00:07:33.599 --> 00:07:36.140
And it turned out the real issue
is that one of the inception

00:07:36.140 --> 00:07:37.989
submodules had a slight bug.

00:07:37.989 --> 00:07:39.530
So it was wired
slightly differently,

00:07:39.530 --> 00:07:42.020
and that was breaking
the training.

00:07:42.020 --> 00:07:44.580
There are a couple of other
settings you can use here.

00:07:44.580 --> 00:07:47.945
So, for example, we can
look at coloring by device.

00:07:47.945 --> 00:07:50.070
In this case, everything
was put on the same device

00:07:50.070 --> 00:07:50.880
so it's all gray.

00:07:50.880 --> 00:07:52.730
But if you were using
a mix of CPU and GPU,

00:07:52.730 --> 00:07:56.360
you can use that to get an idea
of where things were placed.

00:07:56.360 --> 00:08:02.420
We can also turn
on trace inputs,

00:08:02.420 --> 00:08:04.370
and then you can choose
any individual piece

00:08:04.370 --> 00:08:06.953
and kind of see what all of its
dependencies are in the graph.

00:08:06.953 --> 00:08:10.100
Everything else gets grayed out.

00:08:10.100 --> 00:08:10.700
So yeah.

00:08:10.700 --> 00:08:12.110
But from looking
at this, it does

00:08:12.110 --> 00:08:15.140
look like we have, more or
less, the graph we expected.

00:08:15.140 --> 00:08:17.104
But as we saw, it's
not training at all.

00:08:17.104 --> 00:08:19.520
So it's time to get a little
bit more information and time

00:08:19.520 --> 00:08:21.970
to start using these other tabs.

00:08:21.970 --> 00:08:24.020
Now to do that, we
need to actually write

00:08:24.020 --> 00:08:27.440
data, runtime data,
from TensorFlow to disk.

00:08:27.440 --> 00:08:29.210
And the way we do that
is through a system

00:08:29.210 --> 00:08:31.100
called summaries.

00:08:31.100 --> 00:08:34.130
A summary is basically a
special kind of TensorFlow op.

00:08:34.130 --> 00:08:37.280
It will take in a regular
tensor from your graph,

00:08:37.280 --> 00:08:39.350
and then it will
output protocol buffers

00:08:39.350 --> 00:08:41.000
that we can write to disk.

00:08:41.000 --> 00:08:43.370
Now, there are a couple of
different kinds of summaries.

00:08:43.370 --> 00:08:45.453
The simplest is the scalar
summary which will just

00:08:45.453 --> 00:08:47.110
write down a single
value, and you

00:08:47.110 --> 00:08:49.445
use it to create these
nice line charts.

00:08:49.445 --> 00:08:52.070
Then there are image summaries,
which we'll write out an image.

00:08:52.070 --> 00:08:53.944
And you can use it to
visualize, for example,

00:08:53.944 --> 00:08:55.850
if you have a generative
model of images,

00:08:55.850 --> 00:08:57.683
or if you just want to
check that your input

00:08:57.683 --> 00:08:59.550
data is formatted correctly.

00:08:59.550 --> 00:09:00.950
We have an audio summary.

00:09:00.950 --> 00:09:02.420
So, for example,
the magenta team,

00:09:02.420 --> 00:09:04.169
which we'll hear from
later and is working

00:09:04.169 --> 00:09:06.200
on a lot of music
generation actually

00:09:06.200 --> 00:09:08.820
added the audio
summary to TensorBoard.

00:09:08.820 --> 00:09:11.010
There are histogram
summaries, and these

00:09:11.010 --> 00:09:12.990
let you look at the
shape of distributions

00:09:12.990 --> 00:09:14.010
of different values.

00:09:14.010 --> 00:09:16.410
So it can be very nice to
be attach to your variables,

00:09:16.410 --> 00:09:17.910
like your weights.

00:09:17.910 --> 00:09:20.154
And finally, we have
the TensorSummary.

00:09:20.154 --> 00:09:21.820
The TensorSummary is
the newest summary.

00:09:21.820 --> 00:09:24.150
The idea is that it can
write out any kind of value

00:09:24.150 --> 00:09:26.820
because everything in
TensorFlow a Tensor.

00:09:26.820 --> 00:09:30.490
But we haven't quite added
support for it fully yet.

00:09:30.490 --> 00:09:32.340
And I'll discuss it a
little bit when we get

00:09:32.340 --> 00:09:34.915
to TensorBoard's future plans.

00:09:34.915 --> 00:09:36.540
So now we'll add a
couple of summaries.

00:09:36.540 --> 00:09:37.890
We had these two
scaler summaries,

00:09:37.890 --> 00:09:39.080
because it would be
nice to look at how

00:09:39.080 --> 00:09:40.560
the cross entropy
and the accuracy

00:09:40.560 --> 00:09:42.287
are changing over time.

00:09:42.287 --> 00:09:44.370
It would also be nice to
look at our input images,

00:09:44.370 --> 00:09:47.700
just make sure that they're
MNIST digits, like we expect.

00:09:47.700 --> 00:09:49.404
And then, finally,
in each of our layers

00:09:49.404 --> 00:09:50.820
we'll add a couple
histograms that

00:09:50.820 --> 00:09:55.160
will show us the weights, the
biases, and the activations.

00:09:55.160 --> 00:09:57.450
So with that all said,
we need to think, OK,

00:09:57.450 --> 00:09:59.750
how are we actually going
to run these summaries?

00:09:59.750 --> 00:10:02.450
And the answer is that
we run each summary op.

00:10:02.450 --> 00:10:04.190
It gives us the
protocol buffers,

00:10:04.190 --> 00:10:07.850
and then we can pass them to our
FileWriter to get them to disk.

00:10:07.850 --> 00:10:09.740
It would be really
tedious if we needed

00:10:09.740 --> 00:10:12.200
to keep track of those
six or seven summary ops

00:10:12.200 --> 00:10:14.492
and run them all individually,
especially if we'd

00:10:14.492 --> 00:10:16.700
go to a graph like Inception
that might have hundreds

00:10:16.700 --> 00:10:18.350
or thousands of summaries.

00:10:18.350 --> 00:10:20.660
So instead, we have
this Merge All summary

00:10:20.660 --> 00:10:22.220
that creates a single target.

00:10:22.220 --> 00:10:25.110
We run it, and we get every
summary in the whole graph.

00:10:25.110 --> 00:10:27.350
So we can go and create
another FileWriter.

00:10:27.350 --> 00:10:28.940
We can go and modify
our training code

00:10:28.940 --> 00:10:32.740
so that it will run the merged
summary and write it to disk.

00:10:32.740 --> 00:10:34.990
And then, finally, we just
need to turn on TensorBoard

00:10:34.990 --> 00:10:37.800
pointing out our new directory.

00:10:37.800 --> 00:10:39.630
So now we can start
to explore what's

00:10:39.630 --> 00:10:41.490
really happening in this model.

00:10:41.490 --> 00:10:45.900
So as we saw, the accuracy
bounces around 10%.

00:10:45.900 --> 00:10:50.940
In the backdrop, you can see
the original data is very noisy

00:10:50.940 --> 00:10:53.830
because it's just got random
sampling moving around.

00:10:53.830 --> 00:10:57.060
So we can smooth it to see
the trend line more clearly.

00:10:57.060 --> 00:10:58.860
And then we also have
the cross entropy.

00:10:58.860 --> 00:11:00.840
And this is pretty interesting
in that the cross entropy is

00:11:00.840 --> 00:11:03.450
staying exactly constant
throughout the entire training

00:11:03.450 --> 00:11:07.640
run, which is just something is
seriously wrong with the model.

00:11:07.640 --> 00:11:11.400
We can also take a
look at the Images tab.

00:11:11.400 --> 00:11:13.700
And here we find OK,
our images actually

00:11:13.700 --> 00:11:15.640
do look like fine MNIST images.

00:11:15.640 --> 00:11:17.630
And we can look at
a true pixel size

00:11:17.630 --> 00:11:20.240
and then be reminded that--

00:11:20.240 --> 00:11:21.580
something went wrong with that.

00:11:21.580 --> 00:11:23.580
But you also expand it.

00:11:23.580 --> 00:11:25.809
So we have a couple of
different capabilities here.

00:11:25.809 --> 00:11:27.350
And what we'll see
really interesting

00:11:27.350 --> 00:11:29.730
is when we look at the
distributions and histograms.

00:11:29.730 --> 00:11:31.340
So this is actually
two different ways

00:11:31.340 --> 00:11:34.070
of visualizing the same
histogram information.

00:11:34.070 --> 00:11:35.630
The distribution
chart is telling us

00:11:35.630 --> 00:11:38.390
that all of the values
were stuck at zero.

00:11:38.390 --> 00:11:40.760
And the histogram chart
is going to tell us

00:11:40.760 --> 00:11:41.930
the exact same thing.

00:11:41.930 --> 00:11:44.930
All of our activations were
one giant spike at zero.

00:11:44.930 --> 00:11:48.556
And also, all of our biases
and weights were stuck at zero.

00:11:48.556 --> 00:11:50.930
So this gives us an intuition
that something was probably

00:11:50.930 --> 00:11:53.030
wrong when we set up our layers.

00:11:53.030 --> 00:11:55.271
Because when the biases
and weights are all zero,

00:11:55.271 --> 00:11:57.020
we're going to have
zero gradients passing

00:11:57.020 --> 00:11:59.760
through the graph and
nothing will train at all.

00:11:59.760 --> 00:12:02.810
So let's take a look
at our code for where

00:12:02.810 --> 00:12:03.860
we set up these layers.

00:12:03.860 --> 00:12:05.735
I'm going to look at
the convolutional layer,

00:12:05.735 --> 00:12:06.590
for example.

00:12:06.590 --> 00:12:09.470
And you can see that we actually
set the biases and weights

00:12:09.470 --> 00:12:13.319
to initialize at zeros,
which was a mistake.

00:12:13.319 --> 00:12:15.860
So we can change that to have
a more sensible initialization,

00:12:15.860 --> 00:12:17.990
like a truncated
normal for the weights

00:12:17.990 --> 00:12:20.730
and a constant value
for the biases.

00:12:20.730 --> 00:12:22.390
And now we can just
rerun our model

00:12:22.390 --> 00:12:25.884
with the changed settings.

00:12:25.884 --> 00:12:27.550
And we start to get
much better results.

00:12:27.550 --> 00:12:30.250
We can see here that our
cross entropy rapidly

00:12:30.250 --> 00:12:31.960
decreases towards zero.

00:12:31.960 --> 00:12:34.720
And our accuracy rapidly
increases towards one,

00:12:34.720 --> 00:12:36.440
or perfect accuracy.

00:12:36.440 --> 00:12:38.770
If we want to see these two
charts at the same time,

00:12:38.770 --> 00:12:41.710
we have the ability to
create groups of charts

00:12:41.710 --> 00:12:43.360
using regular expressions.

00:12:43.360 --> 00:12:46.530
So we could put everything
in one chart, in one group.

00:12:46.530 --> 00:12:49.030
Similarly, we can now see that
if we look at the histograms,

00:12:49.030 --> 00:12:54.040
for example, we actually have
nice distributions over time.

00:12:54.040 --> 00:12:57.070
Sidebar about these
histogram visualizations.

00:12:57.070 --> 00:12:58.960
They were made by the
really talented Shawn

00:12:58.960 --> 00:13:01.204
Carter, who used to work
at the "New York Times."

00:13:01.204 --> 00:13:02.620
and he was inspired
if you've ever

00:13:02.620 --> 00:13:04.810
seen this album cover
called Joywave, where it's

00:13:04.810 --> 00:13:08.080
like an audio wave forms
spread out over time,

00:13:08.080 --> 00:13:10.630
he's the kind of guy who sees
an album cover and thinks,

00:13:10.630 --> 00:13:13.330
ah, that would make a
great visualization.

00:13:13.330 --> 00:13:14.830
So we can do a
couple of cool things

00:13:14.830 --> 00:13:17.990
here, like we can switch them
from the offset to overlay.

00:13:17.990 --> 00:13:20.350
So sort of if you want to
see how it evolved over time,

00:13:20.350 --> 00:13:21.794
the offset is useful.

00:13:21.794 --> 00:13:24.460
If you want to see how it looked
in absolute and relative terms,

00:13:24.460 --> 00:13:26.530
the overlay is quite useful.

00:13:26.530 --> 00:13:27.970
We have the exact
same information

00:13:27.970 --> 00:13:31.180
in the distribution
charts, where now it's

00:13:31.180 --> 00:13:33.590
showing us a different
view, where we can see,

00:13:33.590 --> 00:13:36.680
for example, this very pale
line is the maximum value.

00:13:36.680 --> 00:13:38.680
So we can see that there
was a very high maximum

00:13:38.680 --> 00:13:40.256
value for the activations.

00:13:40.256 --> 00:13:42.380
But here, we're looking at
like the 90th percentile

00:13:42.380 --> 00:13:43.910
and the 60th percentile.

00:13:43.910 --> 00:13:46.930
It was actually fairly
closely clustered.

00:13:46.930 --> 00:13:49.420
But the important thing here
is that our model is finally

00:13:49.420 --> 00:13:49.960
working.

00:13:49.960 --> 00:13:54.262
And we can see that it's
training a lot better.

00:13:54.262 --> 00:13:56.220
So now that we have a
good model, we might say,

00:13:56.220 --> 00:13:59.400
OK, well, we chose a learning
rate kind of arbitrarily,

00:13:59.400 --> 00:14:01.350
and we chose our model
architecture kind

00:14:01.350 --> 00:14:02.400
of arbitrarily.

00:14:02.400 --> 00:14:04.450
But what if we had done
things differently?

00:14:04.450 --> 00:14:06.030
What if we tried a couple
of different learning rates

00:14:06.030 --> 00:14:08.196
and what if we had tried a
couple of different model

00:14:08.196 --> 00:14:08.930
architectures?

00:14:08.930 --> 00:14:11.100
TensorBoard can be really
useful for this as well

00:14:11.100 --> 00:14:13.249
because it gives you
a good way to compare

00:14:13.249 --> 00:14:14.790
how different versions
of your models

00:14:14.790 --> 00:14:17.800
stack up on all of these
different variables.

00:14:17.800 --> 00:14:19.922
So we can make a couple
of changes to our code.

00:14:19.922 --> 00:14:22.380
We're going to iterate over
three different learning rates.

00:14:22.380 --> 00:14:24.030
And then we'll
iterate over using

00:14:24.030 --> 00:14:25.680
one or two fully
connected layers

00:14:25.680 --> 00:14:28.230
and one or two
convolutional layers.

00:14:28.230 --> 00:14:29.880
And we're going to
make a unique string

00:14:29.880 --> 00:14:32.430
for each of these hyperparameter
settings describing it.

00:14:32.430 --> 00:14:35.580
For example, learning rate,
underscore, 1e negative 3,

00:14:35.580 --> 00:14:37.860
then fully connected equals
2, and then convolutional

00:14:37.860 --> 00:14:39.420
equals 2.

00:14:39.420 --> 00:14:41.052
And we'll create a
new summary writer

00:14:41.052 --> 00:14:42.510
that's pointing to
a directory that

00:14:42.510 --> 00:14:44.460
has that string in the name.

00:14:44.460 --> 00:14:47.070
And now we can
actually run the model.

00:14:47.070 --> 00:14:49.680
And we're going to point
TensorBoard at the parent level

00:14:49.680 --> 00:14:50.412
directory.

00:14:50.412 --> 00:14:51.870
So in the past,
we've been pointing

00:14:51.870 --> 00:14:54.456
TensorBoard at the
directories for specific runs.

00:14:54.456 --> 00:14:56.330
And now we want to look
at the parent of runs

00:14:56.330 --> 00:15:00.340
so that it can find all of this
data and compare it for us.

00:15:00.340 --> 00:15:02.770
So now we can go
to our next demo.

00:15:02.770 --> 00:15:06.101
And here, we have this
run site on the left

00:15:06.101 --> 00:15:08.350
has got all of these different
hyperparameter settings

00:15:08.350 --> 00:15:10.020
that we experimented with.

00:15:10.020 --> 00:15:13.810
And now we can look at, for
example, our cross entropy

00:15:13.810 --> 00:15:15.610
and start to see
how they compare it

00:15:15.610 --> 00:15:17.530
across the different runs.

00:15:17.530 --> 00:15:19.972
Similarly, we have
accuracy up here.

00:15:19.972 --> 00:15:22.180
So we can see, actually,
there was a lot of variance.

00:15:22.180 --> 00:15:24.610
Some of our models barely
learned anything at all,

00:15:24.610 --> 00:15:27.400
and some of them were
extremely successful.

00:15:27.400 --> 00:15:28.960
If we look at cross
entropy, maybe we

00:15:28.960 --> 00:15:30.820
want to make things
a little bit clearer.

00:15:30.820 --> 00:15:32.850
Like the beginning
everything starts high,

00:15:32.850 --> 00:15:34.930
so it rescales the display.

00:15:34.930 --> 00:15:38.770
So we can zoom in, and we get
things a little bit clearer.

00:15:38.770 --> 00:15:42.190
We can also toggle on a
logarithmic scale, which

00:15:42.190 --> 00:15:44.320
makes the differences a
little bit more pronounced

00:15:44.320 --> 00:15:46.990
and sometimes very useful.

00:15:46.990 --> 00:15:49.150
And then we can start
exploring with our tool tips

00:15:49.150 --> 00:15:52.330
here and seeing, OK, this
run that was the worst

00:15:52.330 --> 00:15:55.540
was learning rate negative 3,
and then both convolutional

00:15:55.540 --> 00:15:56.739
and both fully connected.

00:15:56.739 --> 00:15:58.780
And this one that was the
best was the same thing

00:15:58.780 --> 00:16:01.130
but with a smaller
learning rate.

00:16:01.130 --> 00:16:04.180
And if we want to do a
more in-depth comparison,

00:16:04.180 --> 00:16:07.835
we can start to filter
by settings here.

00:16:07.835 --> 00:16:09.460
So if we want to look
at all the things

00:16:09.460 --> 00:16:11.600
that had only one
convolutional layer,

00:16:11.600 --> 00:16:13.369
we could type conv
equals 1, and now

00:16:13.369 --> 00:16:15.910
we can see just the ones that
had one convolutional layer, so

00:16:15.910 --> 00:16:18.430
that makes it a little
bit easier to dive it.

00:16:18.430 --> 00:16:20.740
Or similarly, we could search
for only the things that

00:16:20.740 --> 00:16:23.980
had the learning rate
of e to the negative 4,

00:16:23.980 --> 00:16:26.090
and that includes our best run.

00:16:26.090 --> 00:16:28.450
A couple other features
I'll point out.

00:16:28.450 --> 00:16:32.640
You can also just toggle one
run at of time by clicking here.

00:16:32.640 --> 00:16:35.040
And we can also
change the display

00:16:35.040 --> 00:16:38.820
to show us different
ways of visualizing time.

00:16:38.820 --> 00:16:41.550
Right now, we're orienting
the x-axis by step.

00:16:41.550 --> 00:16:43.980
But we could do it by,
for example, wall time.

00:16:43.980 --> 00:16:46.188
And then we can see, actually,
that while they're all

00:16:46.188 --> 00:16:48.577
aligned in steps, I ran
them at different times.

00:16:48.577 --> 00:16:50.160
We can also use
relative time, so this

00:16:50.160 --> 00:16:52.410
will show the number
of minutes from start.

00:16:52.410 --> 00:16:54.826
And then we can see, actually,
that some models took a lot

00:16:54.826 --> 00:16:56.110
longer to run than others.

00:16:56.110 --> 00:16:57.600
So even though they took
the same number of steps,

00:16:57.600 --> 00:16:59.160
the models with
more fully connected

00:16:59.160 --> 00:17:04.060
and more convolutional layers
ran about twice as slowly.

00:17:04.060 --> 00:17:06.740
And then we can also visualize--
all of our other displays

00:17:06.740 --> 00:17:08.490
also give us more information.

00:17:08.490 --> 00:17:11.480
So if we wanted to
look at all the biases,

00:17:11.480 --> 00:17:14.900
we could see how they
varied for different models.

00:17:14.900 --> 00:17:19.944
And let's see, conv
1, slash bias, maybe.

00:17:19.944 --> 00:17:21.319
And so that's kind
of interesting

00:17:21.319 --> 00:17:22.810
that we can see the
different models actually

00:17:22.810 --> 00:17:24.268
had very different
patterns for how

00:17:24.268 --> 00:17:26.170
the biases evolved over time.

00:17:26.170 --> 00:17:27.935
And probably by
digging into this,

00:17:27.935 --> 00:17:30.310
we could learn some ways in
which the models are actually

00:17:30.310 --> 00:17:32.590
structurally different.

00:17:32.590 --> 00:17:34.600
Similarly, in the
graph visualizer,

00:17:34.600 --> 00:17:36.790
we can explore the
different runs.

00:17:36.790 --> 00:17:38.290
So we can see here
that right now we

00:17:38.290 --> 00:17:39.956
have one of the models
that had only one

00:17:39.956 --> 00:17:42.340
convolutional layer and only
one fully connected layer.

00:17:42.340 --> 00:17:45.040
But we could go and compare it
to different models instead.

00:17:48.030 --> 00:17:48.866
So the final thing--

00:17:48.866 --> 00:17:51.240
major feature from TensorBoard
that I'm going to describe

00:17:51.240 --> 00:17:53.130
is the embedding visualizer.

00:17:53.130 --> 00:17:55.490
And it's maybe the coolest
piece of TensorBoard.

00:17:55.490 --> 00:17:57.990
What the embedding
visualizer basically does

00:17:57.990 --> 00:18:00.180
is it lets you take
high dimensional data

00:18:00.180 --> 00:18:02.222
and then project it down
into three dimensions.

00:18:02.222 --> 00:18:04.680
Now the way in which we might
be really interested in doing

00:18:04.680 --> 00:18:07.680
this is when we take
our input data set

00:18:07.680 --> 00:18:09.780
and we map it through the
neural network, to say,

00:18:09.780 --> 00:18:12.420
the final layer, that
embedding is actually

00:18:12.420 --> 00:18:15.240
the learned representation
of how our neural network is

00:18:15.240 --> 00:18:17.670
processing the information.

00:18:17.670 --> 00:18:20.160
So I'm going to throw a
bunch of code on the screen,

00:18:20.160 --> 00:18:22.029
and I'm not going to
explain in great depth.

00:18:22.029 --> 00:18:23.820
But I will say there's
a wonderful tutorial

00:18:23.820 --> 00:18:26.209
on the embedding
visualizer on the website.

00:18:26.209 --> 00:18:27.750
But basically, what
we're going to do

00:18:27.750 --> 00:18:29.400
is we're going to
make a variable that

00:18:29.400 --> 00:18:33.044
will hold the embedding of
each of our test set images.

00:18:33.044 --> 00:18:35.460
And then we're going to create
a configuration object that

00:18:35.460 --> 00:18:37.890
has a little bit of
information like, where can we

00:18:37.890 --> 00:18:40.440
find a sprite PNG of
all the MNIST images

00:18:40.440 --> 00:18:42.822
so we can display
thumbnails in the browser?

00:18:42.822 --> 00:18:44.280
And where are we
finding the labels

00:18:44.280 --> 00:18:46.230
so that we can
organize the examples

00:18:46.230 --> 00:18:48.520
by which label they are?

00:18:48.520 --> 00:18:51.250
And then we write this all
to disk using the FileWriter.

00:18:51.250 --> 00:18:53.500
And now, every 500
steps, we're going

00:18:53.500 --> 00:18:55.570
to save a model checkpoint.

00:18:55.570 --> 00:18:57.010
And this model
checkpoint contains

00:18:57.010 --> 00:18:58.540
all of the variables
in our model,

00:18:58.540 --> 00:19:00.830
including that
embedding variable.

00:19:00.830 --> 00:19:03.880
And then, finally, we turn
on TensorBoard once again,

00:19:03.880 --> 00:19:06.880
pointing to this directory.

00:19:06.880 --> 00:19:09.130
And here we have our embedding.

00:19:09.130 --> 00:19:13.300
This is 1,024 points
from MNIST that I decided

00:19:13.300 --> 00:19:14.722
to use from the test set.

00:19:14.722 --> 00:19:16.180
And what we're
looking at right now

00:19:16.180 --> 00:19:19.900
is the principal components
analysis of the embedding.

00:19:19.900 --> 00:19:22.180
So we've taken the top
three principal components

00:19:22.180 --> 00:19:25.390
and laid out these points in
three dimensional manifold.

00:19:25.390 --> 00:19:27.490
So if we color by
label, we can already

00:19:27.490 --> 00:19:30.439
see that it's learned a pretty
useful separation, like all

00:19:30.439 --> 00:19:32.230
of the ones that have
been separated on one

00:19:32.230 --> 00:19:33.396
of the principal components.

00:19:33.396 --> 00:19:35.470
And then there's kind of
one principal component

00:19:35.470 --> 00:19:37.210
has the 9s and the
7s, which makes sense

00:19:37.210 --> 00:19:38.680
since they're kind of similar.

00:19:38.680 --> 00:19:41.055
And then on the opposite end
of that principle component,

00:19:41.055 --> 00:19:44.260
you have more like
2s and 3s and 8s.

00:19:44.260 --> 00:19:46.180
But we can do even
better than this.

00:19:46.180 --> 00:19:48.550
We can use my personal
favorite feature here,

00:19:48.550 --> 00:19:49.900
which is [INAUDIBLE].

00:19:49.900 --> 00:19:51.550
So this is going to
go and reorganize

00:19:51.550 --> 00:19:54.790
the data set so that it
preserves local similarity.

00:19:54.790 --> 00:19:56.920
And then we get this
really cool visualization

00:19:56.920 --> 00:19:59.530
that shows us which
pieces of data

00:19:59.530 --> 00:20:03.717
were locally connected in the
manifold, in the embedding.

00:20:03.717 --> 00:20:05.800
So we can see, for example,
that the 1s got really

00:20:05.800 --> 00:20:07.841
nicely clustered on their
own, which makes sense,

00:20:07.841 --> 00:20:09.472
since 1s are very
distinct digit.

00:20:09.472 --> 00:20:11.680
And we can see that it has
a little bit more trouble,

00:20:11.680 --> 00:20:13.750
for example, with the 3s
and the 8s and the 5s,

00:20:13.750 --> 00:20:16.208
because those are a little bit
closer and a little bit more

00:20:16.208 --> 00:20:17.710
intermingled.

00:20:17.710 --> 00:20:20.140
And we can even start to
dive into individual examples

00:20:20.140 --> 00:20:22.210
where the model made
a bad prediction.

00:20:22.210 --> 00:20:24.190
So if we look, for
example, at the 7,

00:20:24.190 --> 00:20:26.440
it's clustered with the 1s,
so that's almost certainly

00:20:26.440 --> 00:20:28.840
a test error, whatever
it incorrectly

00:20:28.840 --> 00:20:30.940
labels the 7 as a 1.

00:20:30.940 --> 00:20:33.220
But as we zoom in on
this particular 7,

00:20:33.220 --> 00:20:34.990
it really does kind
of look like a 1.

00:20:34.990 --> 00:20:38.470
It's probably the
oneiest 7 that I've seen.

00:20:38.470 --> 00:20:41.050
So it makes sense that the
model's making that mistake.

00:20:41.050 --> 00:20:43.330
And similarly, if
we look at this 9,

00:20:43.330 --> 00:20:44.760
it really looks like a 1.

00:20:44.760 --> 00:20:46.580
This 4, I think, really is a 4.

00:20:46.580 --> 00:20:49.480
So maybe the model just
has an issue there.

00:20:49.480 --> 00:20:51.070
The embedding
visualizer can also

00:20:51.070 --> 00:20:53.200
be used for a lot
more than just images.

00:20:53.200 --> 00:20:56.830
So it's really useful for
visualizing vocabularies

00:20:56.830 --> 00:20:57.540
as well.

00:20:57.540 --> 00:21:01.270
And I'll actually just
show you an example.

00:21:01.270 --> 00:21:03.030
This is the smart
reply data set.

00:21:03.030 --> 00:21:05.940
So every time that's
your inbox app

00:21:05.940 --> 00:21:07.740
suggests saying
thank you to someone,

00:21:07.740 --> 00:21:10.080
it's using this dataset.

00:21:10.080 --> 00:21:13.580
And we can see here that we
have exclamatory statements

00:21:13.580 --> 00:21:14.370
are over here.

00:21:14.370 --> 00:21:17.310
Like please confirm now,
please confirm you got it.

00:21:17.310 --> 00:21:20.660
And then this access has
less exclamatory stuff.

00:21:20.660 --> 00:21:25.000
And we can even do stuff
like creating our own axes.

00:21:25.000 --> 00:21:26.610
So if you know the
king queen example,

00:21:26.610 --> 00:21:28.890
where you take a word to
[INAUDIBLE] embedding.

00:21:28.890 --> 00:21:31.117
And you set one axis
is king minus queen,

00:21:31.117 --> 00:21:32.700
and then you find
it has learned a lot

00:21:32.700 --> 00:21:35.910
of gender-related concepts,
you can interactively

00:21:35.910 --> 00:21:39.300
explore relationships like that
using the embedding visualizer

00:21:39.300 --> 00:21:41.670
by defining your axes
to be the differences

00:21:41.670 --> 00:21:42.870
between different words.

00:21:45.972 --> 00:21:47.430
So I'm almost out
of time, but I'll

00:21:47.430 --> 00:21:50.310
talk a little bit about
the future of TensorBoard.

00:21:50.310 --> 00:21:52.260
We're going to be, in
the next quarter or so,

00:21:52.260 --> 00:21:54.930
integrating the new TensorFlow
debugger into TensorBoard.

00:21:54.930 --> 00:21:57.180
So that means you'll start
to be able to use the graph

00:21:57.180 --> 00:22:00.260
visualizer to do things like
get an immediate view of where

00:22:00.260 --> 00:22:02.700
there are any NaNs or infinities
anywhere in your graph.

00:22:02.700 --> 00:22:04.354
And if so, when did they appear?

00:22:04.354 --> 00:22:05.770
Or you'll be able
to use the graph

00:22:05.770 --> 00:22:07.500
visualizer to click
on individual tensors

00:22:07.500 --> 00:22:09.180
and visualize them.

00:22:09.180 --> 00:22:11.287
We're also doing a bunch
of work on plug-ins.

00:22:11.287 --> 00:22:13.370
If you remember, I said
we're adding a new summary

00:22:13.370 --> 00:22:16.260
op that can write out any
kind of data in TensorFlow.

00:22:16.260 --> 00:22:17.910
And the idea there
is that we can

00:22:17.910 --> 00:22:20.790
start to have people
contribute visualizations.

00:22:20.790 --> 00:22:24.460
They'll be really specific to
a particular problem domains.

00:22:24.460 --> 00:22:26.160
So if you go to
distill.pub, you'll

00:22:26.160 --> 00:22:27.690
see that Chris Olah
and company have

00:22:27.690 --> 00:22:32.100
made amazing visualizations for
inspecting handwriting models

00:22:32.100 --> 00:22:34.607
or for inspecting
speech to text models.

00:22:34.607 --> 00:22:36.690
And we want to be able to
incorporate these really

00:22:36.690 --> 00:22:39.205
domain-specific visualizations
into TensorBoard,

00:22:39.205 --> 00:22:42.720
and we're going to do that by
making it easy to add plugins.

00:22:42.720 --> 00:22:44.500
And finally, we're
creating something

00:22:44.500 --> 00:22:46.974
I'll call organization
scale TensorBoard.

00:22:46.974 --> 00:22:48.390
Right now, as you
saw, TensorBoard

00:22:48.390 --> 00:22:50.130
is something that
one person locally

00:22:50.130 --> 00:22:52.320
turns on, on their own machine.

00:22:52.320 --> 00:22:54.970
And we're going to create a
scalable, production-sized

00:22:54.970 --> 00:22:57.240
instance so that your
entire organization

00:22:57.240 --> 00:22:59.040
or your entire
research group could

00:22:59.040 --> 00:23:01.110
share a single
TensorBoard and then

00:23:01.110 --> 00:23:05.060
share results easily and
keep a history over time.

00:23:05.060 --> 00:23:06.500
So that's it for my talk.

00:23:06.500 --> 00:23:09.470
The codes and slides
are on this link.

00:23:09.470 --> 00:23:11.600
It's also on my
GitHub, Dandelion Mane,

00:23:11.600 --> 00:23:13.820
and I think we'll
tweet this link out.

00:23:13.820 --> 00:23:16.760
And so next I'm going to
introduce Martin Wicke.

00:23:16.760 --> 00:23:19.700
Martin is undoubtedly the
most handsome, best dressed,

00:23:19.700 --> 00:23:21.890
and most intelligent
person on the team.

00:23:21.890 --> 00:23:22.820
And he's also my boss.

00:23:22.820 --> 00:23:24.760
[LAUGHTER]

00:23:24.760 --> 00:23:27.380
And he owns all of
TensorFlow open sourcing

00:23:27.380 --> 00:23:30.020
and he's going to tell
us a bit about new APIs

00:23:30.020 --> 00:23:33.230
that make doing all of this
MNIST code much easier and much

00:23:33.230 --> 00:23:35.937
less complicated
than in my example.

00:23:35.937 --> 00:23:36.770
Thank you very much.

00:23:36.770 --> 00:23:37.970
[APPLAUSE]

00:23:37.970 --> 00:23:41.920
[MUSIC PLAYING]

