Speaker 1:          00:00          This is more perfect. I'm Jad Abumrad today a little bit of a departure. Maybe it's more of an addendum, so we just released an episode about citizens United, which is one of the most argued about cases in recent history and this, this was a case really about the first amendment and whether we should limit the first amendment in any way. Now, in that case, you had this tension. You had justice Kennedy who saying, don't touch it, don't touch it, don't touch it. I don't care if all this money comes into our political system. Don't touch the first amendment, but you had just a suitor saying, I don't know, maybe we should touch it because sometimes your freedom impinges on my equality and shouldn't those two things be in balance? It's a fascinating and important conversation and it was one that we were having internally at the team while we were making that episode and at a certain point we decided let's actually take that conversation and make a live event around it.

Speaker 1:          01:02          This is something that we, we did a few times in the runup to season two. We would have these public debates in the WWE NYC green space. I don't want to play you, uh, some excerpts from that debate, um, that we had about free speech and we did it sort of classic debate format. One person took one side, one person took another, and our questions were, should the government do more in this day and age to limit free speech? Should Twitter do more? Should Facebook do more? Should all of us collectively be doing more to stop dangerous, hateful speech? Or is this precisely the moment when we have to stand up louder and prouder and protect that speech even if we hate it? So before we got into it, I took a poll of the audience. Everybody who thinks that your right to free speech, especially online, okay people say some bad things, fine, but your right to free speech should remain pretty much unlimited. Those of you who feel that way make some noise.

Speaker 2:          02:06          [inaudible]

Speaker 1:          02:06          all right, you guys are, you guys are thunders over here. Let's do it one. Let's just do one, one more time so I can just get a sort of more accurate. For those of you who don't think it should be limited, go.

Speaker 2:          02:14          Yeah.

Speaker 1:          02:16          Okay. Now those of you on the flip side, those of you think there should be some clear hard limits, easy, easy. Those of you think there should be some clear limits on what you can say online. Make some noise.

Speaker 2:          02:31          [inaudible]

Speaker 1:          02:32          all right. Okay. That gives us a good sense of where we're starting. All right, so let me introduce our debaters for round one. The question is, should the government limit online free speech? Taking one side of that question is Mr Ellie Mystil, our legal editor,

Speaker 2:          02:45          perfect. [inaudible] editor above La

Speaker 1:          02:50          site for legal news. He is on one side of the stage and have the question on the other. Mr Ken White, a First Amendment litigator criminal defense attorney Brown, white and Osborne in Los Angeles. He has joined us here from the left coast. He's a former federal prosecutor. He runs the free speech and criminal justice blog, [inaudible] dot com give it up for Ken.

Speaker 2:          03:13          All right,

Speaker 1:          03:16          let us begin. We'll start with you, Ellie. Uh, is there something wrong with the First Amendment, would you say?

Speaker 3:          03:21          Yeah. No, I don't have a problem with the first amendment. It was a beautiful thing written for white people who wanted to overthrow the government. It's fine. I have a problem with absolute absoluteness who wants to elevate threats, harassment and calls for genocide to the level of a secret. Right. I do not think that the first amendment prohibits us from preventing a Nazi from getting a permit to rally any more than I would think that the second amendment prevents us from having a sociopath not get a gun permit. Okay. Absolutism is absolutely wrong on this.

Speaker 2:          03:57          Okay. Let me smell strong beginning. Ken, what do you think?

Speaker 4:          04:01          Well, I don't know what Absolut is. Ellie is talking about, the last one I know was Hugo black and he died in 1971 we have well established narrow exceptions to the First Amendment and they are narrow for a reason. We got them narrowed on the backs of the powerless being suppressed by the powerful. All of the types of restrictions that Ellie would like are ones that have historically been used against communists, against Labor protestors, against war protestors, against minorities, and everyone else. The Nazis aren't the ones in danger from the types of restrictions that Ellie is suggesting. He'd like,

Speaker 1:          04:38          okay, there are the two basic positions. Let's get the debate started. All right, Ellie, start, start us off. Explain why you think that hateful speech, fake news shouldn't be protected by the first amendment.

Speaker 3:          04:55          Ken just admitted, just agreed that we already regulate speech at some level, so really all we're debating about tonight. The only thing that's even up for debate is where we want to draw that line. Ken would draw that line so it protects Nazis. I would draw that line so it protects us from the Nazis. Let's start with a pretty simple example. Fire kidding. There's no actual fire. I'm sure you've all heard that. The thing that you can say is that you can't shout fire on the crowded theater, but actually under our current laws I probably can because our current standard is that what is unprotected are things that lead to direct incitement of imminent lawless action. That's a very high bar, so I can probably say fire. What I probably can say is fire kill who you must to survive. That would probably get me in trouble.

Speaker 3:          05:51          But the fire analogy comes from an older standard older than the one that I just quoted. It comes Oliver Wendell Holmes, who some of you might've heard of and his standard when he used the, you can't falsely shout fire in a crowded theater analogy. His standard was false and dangerous speech that is false and dangerous is not protected by the constitution. I think that's where the line is. I think that's an eminently reasonable line. I think that we had 150 years of a free republic with that line. So I want the line where dangerous lies are not protected by the constitution.

Speaker 4:          06:27          I don't want the government deciding what's a line of what's true. May I remind you, we are currently led by a president who thinks that global warming is a Chinese hoax to corner the tungsten market and that's why I don't want the government deciding what to suppress based on its decision about what is true or not. Now, Ellie refers to the fire in the crowded theater just as home's famous quote. Let's remember what he was talking about. He was using that quote, you can't shout fire in a crowded theater to justify jailing a man who is protesting World War II by handing out flyers suggesting that people resist the draft. That was the clear danger that the government saw. Now, if you don't think that it's plausible that the government would be suppressing the same type of speech. Now, if you gave it the power, if you handed it to them out of fear of Nazis, then just look at what happened after the protest this last year, the outright and neo-nazis rose. There were massive protests in response and are largely Republican dominated. State legislatures leaped into action and in 17 places they proposed heavily punitive anti protest bills, including for charming examples, making it easier for you to get off if you run over a protestor in your car. That's what the government does with the power to suppress speech. When you let the government decide what's true,

Speaker 3:          07:49          I think you just proved that our current first amendment standard doesn't do bull to actually protect protesters. All it does is protect Nazis. You want to talk about the Oliver Wendell Holmes Skates? Let's talk about where our current standard comes from. It's relatively recent. In 1969 Brandenburg v Ohio. Now, what was that case? I said 1969 you probably thought, oh, it was probably like civil rights and, yeah, and they were making it. No, it was for clansmen. Brandenburg was a Klansman. He was all making clan statements. Somebody arrested his ass for being a Klansman. He got convicted for inciting violence and the court said, Eh, he's just the Klansman. We really need a new standard that protects the right of Klansmen to threatened black people in 1969

Speaker 4:          08:34          but you see Ellie, you know that that's not the right case. That's the one that's best for your argument. The right case is 12 years. That means the right case is 12 years earlier, Yates versus United States. People convicted for becoming members of the Communist Party under the theory that some ideas can be punished as clear and danger even when there is no imminent advocacy of wrongdoing. Yates built the wall that eventually Brandon Burke completed. Brandenburgs the outlier Yates is the one that shows how the power is consistently used by the governor.

Speaker 3:          09:08          Can you explain to me a standard that allows me to stop plantsman cause that's what I want. Like if you can explain to me how I could make Klansman not faint in a field, then I think we're going to agree more than we disagree. But it's a misnomer to suggest that the first amendment is here to protect minorities. Are you kidding me? The constitution to even think about black people until the 13th amendment. I think as we all know,

Speaker 1:          09:28          so, okay. You're saying that you would like to change the standards, so that will help me understand. So what would you do? The standards. Okay, so, so what was your, for people, how would you, how, what would the standard be?

Speaker 3:          09:39          I can give you an example. The president is a Kenyan that's false, but that's not particularly dangerous. And so we can let that kind of slide, right? Um, Hillary Clinton is running a pedophile ring out of a pizza shop. Do not pass. Go, do not collect $200. That is both false and demonstrably dangerous.

Speaker 1:          09:57          Wait, okay. But, but those, those are two very clear examples, but the, the idea of falseness and danger can get pretty squishy. I'm going to sugar camp. Can I call up an example? If you get, if you guys don't mind. So, uh, the daily stormer, which is a, a very popular new Nazi site, there was a situation where they basically took a, a Jewish woman, a real estate agent. Uh, that's, that's the image right there. You can see it on, on the screens and they superimpose it on image of Auschwitz. They published her name, they published her kids. Uh, they said hateful things like we will drive you to suicide. They call the phrase sort of troll off on her. Does that qualify for you and does it qualify for you? Can, I mean, would you limit that kind of speech?

Speaker 4:          10:38          I think a lot of the comments sent to her were true threats. That is a reasonable person would see them as statements of actual intent to do her harm. I think that some of the speech about her meets the incitement standard that it's intended to and likely cause imminent lawless action against her. But ideas, however hateful can't be true or false and it's not for the government to regulate whether ideas or opinions are true or false

Speaker 3:          11:06          ideas can be coupled. Nope. Nope, nope, nope. That is how we got here. Ideas can be true or false. Climate Change, real slow idea. Climate Change, not real false idea. We can make these distinctions and I don't think that we need to. Your standard requires, and I, and I have, unfortunately, because I am black on the Internet, I haven't unfortunately had to deal with some true threats, some not true threats, some trying to wrestle with this issue. When I go to the cops to try to ask for protection, I'm trying to wrestle with this issue of what's actually protected speech and what's actually not protected speech. And my problem with the current standard is that it basically waits until they start shooting at me before they stop them. I want to stop them before they start shooting. I want to stop them before they start driving their cars into crowded protesters because by then it's too late. I want them to stop

Speaker 4:          11:54          too. But here's the problem with the history of America being what it is with the power having been used in the past, being what it is. What possesses you to think that if you give this broader power to attack speech of the government, it's going to be used the way you want it to be.

Speaker 2:          12:13          [inaudible].

Speaker 4:          12:13          I'd rather have this, the Bain 2020. Okay. It's a date.

Speaker 1:          12:19          All right. Now you've heard, uh, Ellie and Ken's points. The question is, did you change your mind? Who thinks the government should limit what we say online? Let's hear some noise.

Speaker 2:          12:33          Okay,

Speaker 1:          12:34          let me get those of you who actually leaned farther in that direction over the course of this argument. Let me hear from you guys. Golf claps. You've got a few. You've got a few tips. Uh, those of you who do not think there should be limits place from the group

Speaker 2:          12:53          by US online.

Speaker 1:          12:59          Uh, I think we may have a winner for the first round. Uh, I'm going to declare that you can. White are the winner

Speaker 2:          13:07          for the first round. Give it up for Ken White Person Amendment Attorney, former federal prosecutor and founder of [inaudible] Dot Com. Thank you for joining us again.

Speaker 5:          13:24          Okay, so coming up, we're gonna shift the question a little bit. Instead of asking, what should the government do about free speech? You don't limit it or not. We're going to ask what your Twitter do. What should Facebook do? You know with all the fake news that's happening, all the hate speech that's coalescing online, should they limit free speech more than they are? That is coming up after the break. This is more perfect. I'm chat out. Boom, rod, stay with us.

Speaker 2:          13:59          [inaudible]

Speaker 5:          14:01          [inaudible]

Speaker 2:          14:04          [inaudible]

Speaker 1:          14:13          more perfect is supported by ZipRecruiter. The smartest way to hire quality talent fast with ZipRecruiter, you can post your job to 100 plus job boards with just one click. Then let ZipRecruiter's powerful technology match your job to the right candidates and use their simple dashboard to find your perfect hire. In fact, 80% of employers who post on ZipRecruiter get a quality candidate through the site within one day. Try It for free at ziprecruiter.com/more perfect. That zip recruiter.com/more perfect.

Speaker 2:          14:46          Hey, it's called Washington from snap, snap, duck live walks Nashville Wyman theater Friday, March 16th and I'm bringing the best and cause in the world last Friday. Laugh some more amazing night out and yes, she's coming. The funniest woman in the world, Jen Kober. I do my hung in the lady forest, Jen POBA rocks a brand new story. Get tickets at snap judgment. That'll watch it. I've never gotten applause for it before. If you guys could call my mom, that'd be awesome. She's still pissed.

Speaker 1:          15:19          [inaudible] this is more perfect. I'm Chad, I boom, rod, let's get back to our debate. Our free speech debate at the w NYC green space. Okay, so round two, we're going to take that same basic question that we asked in round one, but now we're going to transpose it. Whatever we think about the first amendment, it does place limits on the government, but not so much on Twitter or Facebook. So the question is, should Twitter and Facebook or other social media companies severely limit online speech or shouldn't they? I want to pull you guys for it just again, so we have a, a, a baseline to start from. Those of you people watching on Facebook, do you think the site of which you are on right now should aggressively limit this speech that you might type, uh, take, take the online poll, those of you in the audience, same question. Uh, should Facebook and Twitter be allowed to severely limit online speech? Define it as you will.

Speaker 2:          16:26          [inaudible].

Speaker 1:          16:27          Okay. Those of you who think Hell No.

Speaker 2:          16:29          Yeah.

Speaker 1:          16:33          All right. That's, I guess I get a kind of a sort of mixed sense of where we're at in the audience. Okay. So here to debate this topic with Elliot is Corrine McSherry legal director of the Electronic Frontier Foundation, which is committed to defending civil liberties in a digital world. Give it up for her.

Speaker 2:          16:51          All right. So

Speaker 1:          16:54          Karen, let's start with you. What, what do you think about the prospect of a Twitter or a Facebook stepping in to take down lies and take down hate speech?

Speaker 6:          17:03          So I think it's a very dangerous path that unfortunately we're already well along. I think in moments of crisis and I think we're in a moment of crisis right now. We look to simple solutions for very complex problems and we are often sorry. And I think that is where we are right now. The Internet grew up the way it did for mostly good, I would argue because the platforms and the intermediaries mostly stayed neutral. If we have a world in which Facebook, Twitter, Google, Instagram, put themselves in the position of a court and decide what speech should be up, what speed shouldn't, we're going to walk down a dangerous path because of those decisions. Those tactics will inevitably be used against speech that we would support for one thing. They will be inevitably used eventually by governments. Private censorship does not stay private. It becomes public censorship almost inevitably, and the third reason is really practical. They're already doing it and they're doing it badly. All kinds of losses,

Speaker 3:          18:08          which is being taken down every day. Google and Facebook can't save us from the Nazis. We have to do it. Okay, thank you Corrine. Ellie, what do you think? Yeah. The First Amendment does not apply to Twitter or Facebook. Anybody who tells you that they have a constitutional right to say what they want on Twitter is an idiot. The Twitter twirls want, they don't just want free speech, they want consequence free speech. They want to be able to say they're viral trash and still keep their jobs and still keep their homes. It's still get the girl, screw these people. All right, we should have Twitter at least at the level of a jets game. All right. Those are the basic sides. Let's start the debate. All right, Korean, kick us off. Okay, so the problems

Speaker 6:          19:04          you're are legion and almost start with the ones that I, that I just touched on briefly before. The reality is that we can all target people that we hate right now, but if we think that the rules that Twitter and Facebook and all those guys are going to come up with aren't going to be used against speech that we support, we are foolish. It's already happening. Community standards, complaints are used against valuable speech all the time. I know because I hear about it everyday in my job. Then the related problem to that is when you get your lawful speech taken down, you don't have any options. You don't know how to get your stuff put back up. So we have courts, but we don't have a right of appeal. We don't have any challenge. These platforms have the right to host any speech they want. They actually have the First Amendment right to host any speech they want, but I think as users, we want them to use that right wisely. That's not happening, right?

Speaker 3:          19:54          No. As a user, I want them to stop Nazis. Okay. That's really all I'm concerned about. I want them to find a Nazi and stop them from expressing, expressing their hate on Twitter. They can't. They can't. That's foolish. No, sorry. Yes. Goodbye. Here's one. You know what? I know the kid,

Speaker 6:          20:15          they're trying and they're failing over and over. They cannot tell the difference between hate speech and reporting on hate speech until the counts get taken down and suspended when they're doing perfectly lawful.

Speaker 3:          20:27          One of the reasons why this is so important that we demand a better from Facebook, from Twitter, from Reddit, is that the reason why we're seeing so many more Nazis now is because these platforms have allowed them to organize. There was a reason why the Klan was on the decline 20 years ago because you, because wearing hood and going out to meet your friends in the middle of a field like Brandenburg did wasn't really how the modern society was going. But then Twitter and Facebook and these fights and reddit came along and now they have a way to talk and talk to each other and realize that, no, I actually hate by people too. Oh, so do I? Yeah, let's hang out. No, screw these people. There's no, there's no constitutional reason why Twitter should allow them to exist or Facebook or whatever. There is no business reason why Twitter or Facebook or whatever should allow these people to exist. Get them the F out.

Speaker 1:          21:16          You know, one of the things I think about is one of the things we heard, uh, in the wake of Charlottesville was that a lot of these folks got radicalized online. So why would the prospect of them getting radicalized online? What would balance that out in terms of the failure that these sites are doing? I'm curious to hear you talk more about that.

Speaker 6:          21:31          Okay. So a couple things I do just want to respond to this real question. My view is if white supremacists and clansmen and Nazis are organizing, I way prefer they were doing it out in public where I can see them and I can challenge them and I can respond to them. And law enforcement will say the exact same thing. People who fight terrorism say it's much better for the, for the, you know, the people to speaking publicly for the radicals would be radicalizing where you can see them, they're going to organize anyway. Okay. So would you rather do what they stood in secret or in the open? Yeah,

Speaker 3:          22:01          I would rather, I would bet I would rather them do it in secret. I would actually rather them go and find a, make their own Nazi website. Right. Make their own Nazi thing. Right. So that when I, whenever I get Ken to agree with me, whenever the government is ready to stop these people, they will have all preregistered, they would've all said, hey, look@usallnotseemean.com boom and we can go get them.

Speaker 6:          22:23          And so great. So we can continue the silo conversations that we're having right now, which is a big part of where I ended up in this conversation from Nazis. I think that that sounds very nice and it's a good talking point, but in reality I think that's very, very dangerous for our society. We need people to be talking to each other when they only talk to people.

Speaker 2:          22:41          They never turned their minds. Now can you ask more

Speaker 3:          22:45          proven time and time again to me not true and again I hate, I feel like that is such a, a happy clappy white version of this story. Oh, if we just talked to these people, we can convince them that maybe black people shouldn't be sent off to prison camps once or twice and the rest of the time they're running cars and the people doesn't happen nearly not long.

Speaker 6:          23:05          Do you know why we have gay marriage equality now? Because people talk to each other.

Speaker 2:          23:11          It's not the only reason, but it helped. I'll put,

Speaker 6:          23:12          I want to answer John's question cause I think what you're asking is for an example of why I'm worried about how the moderation happened against Ellie's worry. Yeah. Okay. So the way that it works now and the way that it's likely to continue to work is this. So the social media companies employ a combination of humans and mostly algorithms to try to figure out what's bad speech and what's good speech and they mess it up. So they'll end up taking down this statement. All white people are racist as an example of hate speech, but they won't take down if you might show the one this from a congressman who said not a single radicalized Islamic suspect should be granted enter measure of quarter, et Cetera, et cetera. Nasty stuff, right? They can't tell the difference. And that's what happens. And there is an a hat tip to propublica. I hope you guys are all propublica supporters and fans because they're great. They did a detailed study to look at Facebook's policies and they found out that among other things, they're training their moderators to in some instances protect white men over black children. Yes. That's where we are right now. That's what we want to endorse. That's what we want to encourage. I don't think so.

Speaker 3:          24:19          I will stipulate that there are many examples of, of them getting it wrong. They get it wrong and they're not great at this job yet. But we live in a real world where the actual, now I'm talking about Twitter cops, but we live in a world where the actual cops get it wrong every fricking day. And in my most radical statements, I'm not saying let's get rid of the cops cause they don't know what they're doing. No, I'm saying let's get better cops and for Twitter I'm saying let's get better Twitter cops. So they don't get it wrong some so many times. But you want to talk about letting the perfect be the enemy of the good. Just because Twitter and Facebook have not gotten to the level yet where they're able to affectively police these people doesn't mean they should just stop trying.

Speaker 6:          25:02          Well, we have, where we are right now is thousands of accounts are being suspended every day. Let's just say a relatively small percentage of those are for per perfectly lawful speech. That's a lot of lawful speech. That's a lot that we have authorized Twitter and Facebook and everyone else to take on and encourage them to. And keep in mind. I want to say one more thing that I said before, but I want to emphasize it once we start down this path. If you think that this is gonna stay within the decision makers at Silicon Valley, you are dreaming. I mean, that's bad enough. I'm not actually sure why. We all want silicon valley to make decisions about what speech is okay for all the rest of us. But even that aside, it's not gonna stop there. Governments are gonna come in when they see that Google, Facebook, Twitter can easily take down accounts. They're going to say, okay, could you do that for us? This doesn't stop.

Speaker 3:          25:50          Somebody needs to stop these people. And I refuse to believe that we live in a country where that is impossible. Let's take a question. Take a question here in the back.

Speaker 5:          26:00          Ah, if Facebook emailed you and said you can be in charge of what's considered, you know, a speech that is either left up or is taken down, you could build, you know, whatever team of people, would you accept that? Would you think that that could create something that you would be satisfied with or not satisfied with? Oh, if I was queen of the world, Huh?

Speaker 6:          26:22          Hard to turn that down. But I think even I would have trouble in all instances being perfect about what was, um, lawful speech and what wasn't speech. But that actually isn't my main concern is that even I could then potentially be required by a government to then use that algorithm for other purposes. And that would be really dangerous. But here's the one thing that I would say, this is where I think we agree, is that if I was queen of the world and I was rule running any of these companies, one of the things I would absolutely do is put in much better processes for people to appeal, for people to challenge when things are taken down wrong. This isn't just a speech issue, it's a due process issue because let's face it, of course these aren't, you know, official government forums. We all understand that. But nonetheless, this is how we talk to each other. These are our public spaces. And in those public spaces, that's really important when your account gets suspended, when you get taken offline to be able to get back up, if what you're doing is perfectly legal. And right now the reality is, and I know this because I hear from people all the time, it's very confusing. You don't know who to appeal to. You don't know who to, you don't know why you're taking down half the time and you don't know what to do.

Speaker 7:          27:34          The question on the far right. Hi. Uh, I just wanted to get your opinions on, um, money because I hear a lot of talk about this being a speech issue or not. But I think for platforms, the social media platforms, I think it's really all about money and it's about followers and young kids that are getting rape threats and um, threats and that they eventually end in suicide. I think that this has to do with money. I think there's a bigger issue here and I just don't hear anyone talking about it and I just wanted to know what you both thought about that.

Speaker 6:          28:04          So I mean I think that that's, that's really a, a real pressure point cause I think a lot of these companies, and I think you actually genuinely so feel uncomfortable making money from, from hate. But unfortunately we still have a problem. And I'm going to give you an example from an article I just read yesterday. Um, that's a conversation. It's a solo piece about Google and how it runs advertising and search and so on from talking points, memo and talking points. Memo mentioned that you know, one of the problems that they have because these processes are so opaque, they survive because of Google advertising them to write and they're legitimate site trying to do good for the world. They survived because of Google advertising. They keep getting penalized for hate speech because they're reporting on hate speech, specifically Dylan, the Dylan roof situation. So we all easy to sort of disentangle,

Speaker 3:          28:51          but no, it is because we agree that the robots are bad, but I think that we can all agree that talking points memo is a decent site. Info wars. On the other hand, if Google and Facebook and whatever, slam them, Woo hoo, why would that, why would that be so hard? Here's, here's, here's the other thing. If you really don't think that we yet have the technology and the resources necessary in order to police these sites better, how about we go the other direction? How about we just asked people, how about you? Just if you, if you're going to, if you Twitter are going to tell me you can't tell who's threatening to kill me, just tell me where it is. Just tell me who it is and I will handle it myself. What's wrong with that?

Speaker 6:          29:33          See, now he's just trying to Piss me off. Okay,

Speaker 6:          29:38          so we're talking about is now step further. It's social media companies and intermediaries. By the way, all the different people that you interact with, they take it upon themselves to out you right to pierce your anonymity. That is profoundly, profoundly dangerous. Anonymity. Anonymous speech is the most, probably the most important form of political speech that we have. The ability to speak specially online without fear of retaliation means that you have the ability to speak your truth. If we out people, if we accept that social media companies should be judge and jury over, that should just expose people to the world without any choice, without any recourse because once you're out [inaudible]

Speaker 3:          30:19          yes, because they know that we used to have as a society to protect ourselves from these people, what's called shame. We could shame them into being part of the herd and if they didn't want to be part of the herd, we could know who they are and say, Hey, guess what? You're no longer part of the herd. Shame is a powerful weapon that we used to have and Twitter is taken away, taken away from us. And that is why these people are allowed to multiply.

Speaker 6:          30:44          That weapon was also used to persecute minorities all over the [inaudible]

Speaker 3:          30:48          and everything was always used to persecute minorities. At some point in mind, the fact that something has been used to persecute minorities doesn't mean that it can't also be used to stop Nazis. That's just the clocks were used to persecute minorities when they weren't paid by the hour we're calling me. Hello. Good thing. The one thing we have

Speaker 6:          31:06          always understood in this country, and this is before the first amendment, is the importance of anonymous speech.

Speaker 8:          31:13          Right. Let me just jump in for a second. We have a, we have a question here on the right. I just wanted to say that like, um, someone says something about is there a moral reason that Twitter or the government should, uh, lean towards free speech. And I personally am someone who used to have a port views and I was raised as fundamental Christian as you could get. And my views about gay people had I spoken them on the Internet probably would have put off some hate speech alarms and it was not shaming. That changed my mind. I encountered people who were engaging, who treated me like a person, even though I had back then there've been Twitter. I would have been a troll and it changed my mind and I don't know if you guys are familiar with the Westboro Baptist church. They fought a supreme court case in one.

Speaker 8:          31:58          They have really the worst views of anyone I any group that considers himself Christian that I can think of and their person who ran their Twitter is a friend of mine, Megan Phelps Roper. She has this great story about how using Twitter to essentially like spread terrible hate speech saying things like thank God for aids for killing gay people, but it was through Twitter and through the arguments she got in and then through the relationships that she got in that she found a way out of that bubble she lived in and now is out in the world doing amazing work. If, if what you want, Ellie happens that troll that you want to shut up that Klansman, you want to get rid, he doesn't go away. The, the, the mold grows in the shadow and it's, it's only in the sunshine. You know, it's only, it's only when you get it out in the open and we have these conversations and like as a former believer in some of this stuff like don't lose heart. Like we can have our minds changed and like we can, we can be convinced of the truth.

Speaker 2:          33:05          [inaudible]

Speaker 3:          33:05          [inaudible] story and I'm very glad that some that you were able to, to, to get to where you are. Um, however, turns out that I believed what you want me to believe for good. Oh, I don't know, 28, 29 years of my life, I am a 40 year old black man. I am sick of being the educational PBS afterschool special for racist white people. Gay people are sick of being the ABC after school special for white people. Women are sick of being the afterschool special, trying to teach the white man why they also should have rights. It is simply no longer acceptable for you to expect other people just trying to go about posting their dinner recipes on Facebook. It's ridiculous for you to think that we sit still have the burden of educating you. You should go get educated somewhere that can't be on us all the time and I'm willing to do it. I'm willing to do it here. I'm willing to, I'm willing to do it in, in, in, in public. I am actually, I'm leaving to go to a bar and have a drink with people that I can't stand, but at some point when I just want to like get on Facebook and see the met score, I shouldn't have to hear your bullshit. Okay. I don't actually think that was what he was saying at all. Entirely positive. Someone should say that with a microphone.

Speaker 3:          34:30          I think he was just saying silos bad, but that's what I'm saying. [inaudible] is what you're saying. Silos are bad. We should all be together and then then no, I think that, no, I think, I think we don't talk to each other. Nobody's mind ever changes.

Speaker 5:          34:48          All right. I'm going to jump in now. I think a, I think anyone, currently you've done all they can to persuade you guys, uh, who thinks that Twitter and Facebook and such should take a strong hand in severely limiting online speech. Those are you think so.

Speaker 2:          35:04          [inaudible]

Speaker 5:          35:05          those of you who disagree with the Asshole, clap into your left, make some noise.

Speaker 2:          35:15          [inaudible]

Speaker 5:          35:16          I believe that means that you are

Speaker 2:          35:29          [inaudible]

Speaker 5:          35:29          thank you to our debaters, Ellie [inaudible]. More perfect legal editor and executive editor at above the law. Thanks to Kerryn McSherry from the frontier foundation and Ken White from Pope pat.com. This episode was produced with Elaine Chin and the very excellent folks at wny C's green space. We had mixing help this week from Louie Mitchell Supreme Court. Audio is from OAA, a free law project in collaboration with the legal information institute at Cornell. Leadership support for more perfect is provided by the Joyce Foundation. Additional funding is provided by the Charles Evans Hughes Memorial Foundation. See you next week.