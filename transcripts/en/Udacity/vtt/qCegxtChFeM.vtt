WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:02.610
Alright, so, remember, Charles, we were talking about

00:00:02.610 --> 00:00:06.540
three different kinds of ways of choosing the

00:00:06.540 --> 00:00:08.840
inputs to the learner. Okay? So what were

00:00:08.840 --> 00:00:10.705
they again? We just looked at two of them.

00:00:10.705 --> 00:00:15.480
&gt;&gt; So the learner chooses examples. The teacher, hopefully a nice

00:00:15.480 --> 00:00:20.450
one, chooses examples, and then there was the case with the

00:00:20.450 --> 00:00:22.950
examples are given to us by nature. And I guess there

00:00:22.950 --> 00:00:25.267
was a fourth one, which is. That a mean teacher gives

00:00:25.267 --> 00:00:27.490
it to us but I, you know I don't think that's all

00:00:27.490 --> 00:00:30.283
that interesting. I tend to think of nature as a mean teacher.

00:00:30.283 --> 00:00:32.107
&gt;&gt; Well not only that but in the, at least in

00:00:32.107 --> 00:00:35.014
the mistake bound setting that we just looked at again the, the

00:00:35.014 --> 00:00:38.320
learner was robust against any choice of where the inputs were coming

00:00:38.320 --> 00:00:41.455
from. So mean teacher it would've it would've done just as well.

00:00:41.455 --> 00:00:42.424
&gt;&gt; That's a fine point.

00:00:42.424 --> 00:00:45.103
&gt;&gt; It doesn't matter when it makes its mistakes, it's only

00:00:45.103 --> 00:00:48.080
going to make a fixed number of them no matter what.

00:00:48.080 --> 00:00:48.260
&gt;&gt; Okay.

00:00:48.260 --> 00:00:50.270
&gt;&gt; So, we've kind of dealt with three

00:00:50.270 --> 00:00:52.880
of these but we haven't really talked about the, the

00:00:52.880 --> 00:00:56.000
nature chooses case yet. And that's in some ways the most

00:00:56.000 --> 00:00:59.850
interesting and relevant and in other ways the most complicated

00:00:59.850 --> 00:01:02.810
because you have to really take into consideration this space of

00:01:02.810 --> 00:01:05.760
possible distributions. I think now though we're in a pretty

00:01:05.760 --> 00:01:09.020
good situation in terms of being able to define some important

00:01:09.020 --> 00:01:11.430
terms and we're going to use those terms to get

00:01:11.430 --> 00:01:13.800
a handle on this question of what happens when nature chooses.

00:01:13.800 --> 00:01:15.090
&gt;&gt; Okay, that sounds reasonable.

00:01:16.190 --> 00:01:19.130
&gt;&gt; So computational complexity, we talked about. The, the, how much

00:01:19.130 --> 00:01:22.070
computational effort is going to be needed for a learner to convert

00:01:22.070 --> 00:01:25.830
to the answer. Sample complexity in the case of a batch,

00:01:25.830 --> 00:01:28.730
that is to say, we have a training set. Is how large

00:01:28.730 --> 00:01:31.270
is that training set need to be for the learner to

00:01:31.270 --> 00:01:35.090
be able to create successful hypothesis. And that's in the batch setting.

00:01:35.090 --> 00:01:37.740
In the online setting, we have this notion of a mistake

00:01:37.740 --> 00:01:41.180
bound. How many misclassifications can the learner make over an infinite run?

00:01:41.180 --> 00:01:41.870
&gt;&gt; Mind

00:01:41.870 --> 00:01:43.230
if I ask you a question? You said

00:01:43.230 --> 00:01:46.580
something I thought pretty interesting. How, for computational complexity,

00:01:46.580 --> 00:01:48.660
you said how much computational effort is needed

00:01:48.660 --> 00:01:51.210
for a learner to converge To the right answer.

00:01:51.210 --> 00:01:53.890
Is that the, is that a requirement when

00:01:53.890 --> 00:01:56.960
you talk about computational complexity? Or is just that

00:01:56.960 --> 00:01:58.350
you need to know how much computational effort

00:01:58.350 --> 00:02:01.110
is needed for a learner to converge to something?

00:02:01.110 --> 00:02:03.910
&gt;&gt; Well, so if it's converging to something and we don't care what

00:02:03.910 --> 00:02:06.960
it's converging to, then it's really easy to have an algorithm with low

00:02:06.960 --> 00:02:08.820
computational complexity, right? It's just like

00:02:08.820 --> 00:02:10.850
return garbage. It runs in constant time.

00:02:10.850 --> 00:02:11.260
&gt;&gt; Mm hm.

00:02:11.260 --> 00:02:14.160
&gt;&gt; So, yeah, it's in the context of actually

00:02:14.160 --> 00:02:17.310
solving the problem, that computational complexity is most interesting.

00:02:17.310 --> 00:02:18.610
&gt;&gt; Well, I was going to say, what if a set

00:02:18.610 --> 00:02:21.609
of hypothesis that I'm willing to entertain, doesn't include the true concept.

00:02:22.990 --> 00:02:25.330
&gt;&gt; good. Right. So in some sense maybe

00:02:25.330 --> 00:02:26.820
in that case what we're trying to find is

00:02:26.820 --> 00:02:29.900
the best hypothesis in the hypothesis class. But we

00:02:29.900 --> 00:02:32.520
can still ask about computational complexity in that case.

00:02:32.520 --> 00:02:35.550
So, I was saying successful hypothesis here. By that I

00:02:35.550 --> 00:02:38.780
meant, you know, whatever it is that the problem demands that

00:02:38.780 --> 00:02:41.230
we return and if it's a hypothesis class that's very

00:02:41.230 --> 00:02:43.970
limited we might just return the best thing in that class.

00:02:43.970 --> 00:02:45.090
&gt;&gt; Okay.

00:02:45.090 --> 00:02:47.120
&gt;&gt; But the important thing here is that we're not going

00:02:47.120 --> 00:02:48.880
to talk about computational [LAUGH] complexity,

00:02:48.880 --> 00:02:50.060
for the most part. We're going to

00:02:50.060 --> 00:02:54.070
focus on sample complexity for the time being. And that's really

00:02:54.070 --> 00:02:57.460
the relevant concept when we're talking about the idea of nature choosing.

00:02:57.460 --> 00:02:57.810
&gt;&gt; I believe you

