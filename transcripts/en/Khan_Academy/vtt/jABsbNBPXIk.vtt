WEBVTT
Kind: captions
Language: en

00:00:00.110 --> 00:00:01.430
- [Instructor] Let's
say there's some type of

00:00:01.430 --> 00:00:03.440
standardized exam where every question

00:00:03.440 --> 00:00:05.240
on the test has four choices,

00:00:05.240 --> 00:00:07.490
choice A, choice B,

00:00:07.490 --> 00:00:09.970
choice C, and choice D.

00:00:09.970 --> 00:00:13.520
And the test makers assure
folks that, over many years,

00:00:13.520 --> 00:00:15.990
there's an equal probability
that the correct answer

00:00:15.990 --> 00:00:19.070
for any one of the items is A, B, C, or D.

00:00:19.070 --> 00:00:22.280
It essentially is a 25%
chance of any of them.

00:00:22.280 --> 00:00:24.190
Now, let's say you have a hunch that,

00:00:24.190 --> 00:00:27.760
well, maybe it is skewed
towards one letter or another.

00:00:27.760 --> 00:00:29.650
How could you test this?

00:00:29.650 --> 00:00:31.060
Well, you could start with a null

00:00:31.060 --> 00:00:32.480
and alternative hypothesis,

00:00:32.480 --> 00:00:35.300
and then we can actually
do a hypothesis test.

00:00:35.300 --> 00:00:40.300
So let's say that our null
hypothesis is equal distribution,

00:00:40.340 --> 00:00:43.160
equal distribution

00:00:43.160 --> 00:00:45.080
of correct choices,

00:00:45.080 --> 00:00:47.750
correct choices.

00:00:47.750 --> 00:00:49.550
Or another way of thinking about it is

00:00:49.550 --> 00:00:52.150
A would be correct 25% of the time,

00:00:52.150 --> 00:00:54.930
B would be correct 25% of the time,

00:00:54.930 --> 00:00:57.300
C would be correct 25% of the time,

00:00:57.300 --> 00:01:00.460
and D would be correct 25% of the time.

00:01:00.460 --> 00:01:03.750
Now, what would be our
alternative hypothesis?

00:01:03.750 --> 00:01:05.870
Well, alternative hypothesis

00:01:05.870 --> 00:01:08.170
would be not equal distribution,

00:01:08.170 --> 00:01:09.360
not

00:01:09.360 --> 00:01:11.453
equal distribution.

00:01:12.350 --> 00:01:14.950
Now, how are we going
to actually test this?

00:01:14.950 --> 00:01:17.280
Well, we've seen this show before,

00:01:17.280 --> 00:01:19.200
at least the beginnings of the show.

00:01:19.200 --> 00:01:23.250
You have the population of all
of your potential items here,

00:01:23.250 --> 00:01:24.730
and you could take a sample.

00:01:24.730 --> 00:01:27.990
And so let's say we take
a sample of 100 items.

00:01:27.990 --> 00:01:31.250
So n is equal to 100.

00:01:31.250 --> 00:01:33.210
And let's write down the data that we get

00:01:33.210 --> 00:01:35.110
when we look at that sample.

00:01:35.110 --> 00:01:38.280
So this is the correct choice,

00:01:38.280 --> 00:01:40.083
correct choice.

00:01:41.020 --> 00:01:45.200
And then this would be the expected number

00:01:45.200 --> 00:01:47.050
that you would expect.

00:01:47.050 --> 00:01:49.710
And then this is the actual number.

00:01:49.710 --> 00:01:51.050
And if this doesn't make sense yet,

00:01:51.050 --> 00:01:51.883
we'll see it in a second.

00:01:51.883 --> 00:01:56.883
So there's four different
choices, A, B, C, D

00:01:57.377 --> 00:01:59.030
and a sample of 100.

00:01:59.030 --> 00:02:00.600
Remember, in any hypothesis test,

00:02:00.600 --> 00:02:03.580
we start assuming that the
null hypothesis is true.

00:02:03.580 --> 00:02:05.950
So the expected number
where A is a correct choice

00:02:05.950 --> 00:02:08.090
would be 25% of this 100.

00:02:08.090 --> 00:02:11.180
So you would expect 25 times
the A to be the correct choice,

00:02:11.180 --> 00:02:13.490
25 times B to be the correct choice,

00:02:13.490 --> 00:02:15.580
25 times C to be the correct choice,

00:02:15.580 --> 00:02:18.770
and 25 times D to be the correct choice.

00:02:18.770 --> 00:02:20.390
But let's say our actual results,

00:02:20.390 --> 00:02:21.990
when we look at these 100 items,

00:02:21.990 --> 00:02:24.480
we get that A is the
correct choice 20 times,

00:02:24.480 --> 00:02:26.580
B is the correct choice 20 times,

00:02:26.580 --> 00:02:28.710
C is the correct choice 25 times,

00:02:28.710 --> 00:02:32.220
and D is the correct choice 35 times.

00:02:32.220 --> 00:02:33.230
So if you just look at this,

00:02:33.230 --> 00:02:36.260
just look, hey, maybe there's
a higher frequency of D,

00:02:36.260 --> 00:02:38.110
but maybe you'd say, well,
this is just a sample.

00:02:38.110 --> 00:02:39.630
And just through random chance,

00:02:39.630 --> 00:02:42.260
it might have just
gotten more Ds than not.

00:02:42.260 --> 00:02:44.590
There's some probability
of getting this result,

00:02:44.590 --> 00:02:48.000
even assuming that the
null hypothesis is true.

00:02:48.000 --> 00:02:50.070
And that's the goal of
these hypothesis tests,

00:02:50.070 --> 00:02:52.020
is say what's the probability
of getting a result

00:02:52.020 --> 00:02:54.200
at least this extreme?

00:02:54.200 --> 00:02:57.660
And if that probability
is below some threshold,

00:02:57.660 --> 00:03:00.220
then we tend to reject the null hypothesis

00:03:00.220 --> 00:03:02.090
and accept an alternative.

00:03:02.090 --> 00:03:04.450
And those thresholds you have seen before.

00:03:04.450 --> 00:03:06.590
We've seen these significance levels.

00:03:06.590 --> 00:03:10.203
Let's say we set a
significance level of 5%, 0.05.

00:03:11.920 --> 00:03:14.010
So if the probability
of getting this result

00:03:14.010 --> 00:03:17.420
or something even more
different than what's expected

00:03:17.420 --> 00:03:19.370
is less than the significance level,

00:03:19.370 --> 00:03:21.740
then we'd reject the null hypothesis.

00:03:21.740 --> 00:03:24.700
But this all leads to one
really interesting question.

00:03:24.700 --> 00:03:26.650
How do we calculate a probability

00:03:26.650 --> 00:03:29.760
of getting a result this
extreme or more extreme?

00:03:29.760 --> 00:03:31.720
How do we even measure that?

00:03:31.720 --> 00:03:35.320
And this is where we're going
to introduce a new statistic

00:03:35.320 --> 00:03:37.970
and also, for many of
you, a new Greek letter,

00:03:37.970 --> 00:03:41.340
and that is the capital Greek letter chi,

00:03:41.340 --> 00:03:42.960
which might look like an X to you.

00:03:42.960 --> 00:03:44.510
But it's a little bit curvier,

00:03:44.510 --> 00:03:46.200
and you could look up more on that.

00:03:46.200 --> 00:03:48.300
You kind of curve that part of the X.

00:03:48.300 --> 00:03:50.220
But it's a chi, not an X.

00:03:50.220 --> 00:03:53.670
And the statistic is called chi-squared,

00:03:53.670 --> 00:03:55.390
and it's a way of taking the difference

00:03:55.390 --> 00:03:57.100
between the actual and the expected

00:03:57.100 --> 00:03:59.090
and translating that into a number.

00:03:59.090 --> 00:04:01.090
And the chi-squared distribution is,

00:04:01.090 --> 00:04:04.510
well, I really should say
distributions are well studied.

00:04:04.510 --> 00:04:07.420
And we can use that to figure
out what is the probability

00:04:07.420 --> 00:04:10.720
of getting a result this
extreme or more extreme?

00:04:10.720 --> 00:04:12.400
And if that's lower than
our significance level,

00:04:12.400 --> 00:04:14.010
we reject the null hypothesis,

00:04:14.010 --> 00:04:15.870
and it suggests the alternative.

00:04:15.870 --> 00:04:19.860
But how do we calculate the
chi-squared statistic here?

00:04:19.860 --> 00:04:22.050
Well, it's reasonably intuitive.

00:04:22.050 --> 00:04:24.980
What we do is, for each
of these categories,

00:04:24.980 --> 00:04:27.430
in this case, it's for
each of these choices,

00:04:27.430 --> 00:04:28.560
we look at the difference

00:04:28.560 --> 00:04:30.610
between the actual and the expected.

00:04:30.610 --> 00:04:31.730
So for choice A,

00:04:31.730 --> 00:04:35.720
we'd say 20 is the actual
minus the expected.

00:04:35.720 --> 00:04:38.060
And then we're going to square that.

00:04:38.060 --> 00:04:42.060
And then we're going to
divide by what was expected.

00:04:42.060 --> 00:04:44.600
And then we're going to
do that for choice B.

00:04:44.600 --> 00:04:48.000
So we're going to say the
actual was 20, expected is 25,

00:04:48.000 --> 00:04:50.320
so 20 minus 25

00:04:50.320 --> 00:04:52.540
squared, over the expected,

00:04:52.540 --> 00:04:54.180
over 25.

00:04:54.180 --> 00:04:56.030
Plus then we do that for choice C.

00:04:56.030 --> 00:04:58.400
25 minus 25,

00:04:58.400 --> 00:05:00.330
we know where that one will end up,

00:05:00.330 --> 00:05:03.690
squared, over the expected, over 25.

00:05:03.690 --> 00:05:06.020
And then finally, for choice D,

00:05:06.020 --> 00:05:09.240
which is going to get us 35

00:05:09.240 --> 00:05:10.650
minus 25

00:05:10.650 --> 00:05:11.690
squared,

00:05:11.690 --> 00:05:14.253
all of that over 25.

00:05:15.430 --> 00:05:18.750
And we are now, let's
see, if we calculate this,

00:05:18.750 --> 00:05:20.740
this is going to be negative five squared.

00:05:20.740 --> 00:05:22.860
So that's going to be 25.

00:05:22.860 --> 00:05:24.800
This is going to be 25.

00:05:24.800 --> 00:05:26.600
This is going to be zero.

00:05:26.600 --> 00:05:30.230
35 minus 25 is 10, squared, that is 100.

00:05:30.230 --> 00:05:31.870
So this is one

00:05:31.870 --> 00:05:33.510
plus one,

00:05:33.510 --> 00:05:34.950
plus zero,

00:05:34.950 --> 00:05:36.490
plus four.

00:05:36.490 --> 00:05:39.110
So our chi-squared
statistic, in this example,

00:05:39.110 --> 00:05:40.370
came out nice and clean,

00:05:40.370 --> 00:05:43.950
this won't always be the case, at six.

00:05:43.950 --> 00:05:45.580
So what do we make of this?

00:05:45.580 --> 00:05:47.350
Well, what we can do is then look

00:05:47.350 --> 00:05:49.850
at a chi-squared distribution

00:05:49.850 --> 00:05:51.670
for the appropriate degrees of freedom,

00:05:51.670 --> 00:05:53.240
and we'll talk about that in a second,

00:05:53.240 --> 00:05:55.480
and say what is the probability

00:05:55.480 --> 00:05:59.930
of getting a chi-squared
statistic six or larger?

00:05:59.930 --> 00:06:01.440
And to understand what a chi-squared

00:06:01.440 --> 00:06:03.200
distribution even looks like,

00:06:03.200 --> 00:06:05.210
these are multiple
chi-squared distributions

00:06:05.210 --> 00:06:08.900
for different values for
the degrees of freedom.

00:06:08.900 --> 00:06:10.770
And to calculate the degrees of freedom,

00:06:10.770 --> 00:06:12.490
you look at the number of categories.

00:06:12.490 --> 00:06:14.100
In this case, we have four categories,

00:06:14.100 --> 00:06:15.760
and you subtract one.

00:06:15.760 --> 00:06:16.980
Now, that makes a lot of sense

00:06:16.980 --> 00:06:20.740
because, if you knew how many
As, Bs, and Cs there are,

00:06:20.740 --> 00:06:23.530
if you knew the proportions,
even the assumed proportions,

00:06:23.530 --> 00:06:25.670
you can always calculate the fourth one.

00:06:25.670 --> 00:06:29.270
That's why it is four minus
one degrees of freedom.

00:06:29.270 --> 00:06:31.360
So in this case, our degrees of freedom

00:06:31.360 --> 00:06:32.870
are going to be equal to three.

00:06:32.870 --> 00:06:35.690
Over here, sometimes you'll
see it described as k,

00:06:35.690 --> 00:06:37.550
so k is equal to three.

00:06:37.550 --> 00:06:41.080
So if we look at, that's
that little light blue,

00:06:41.080 --> 00:06:43.890
so we're looking at this
chi-squared distribution

00:06:43.890 --> 00:06:46.920
where the degree of freedom is three.

00:06:46.920 --> 00:06:49.010
And we want to figure out
what is the probability

00:06:49.010 --> 00:06:52.930
of getting a chi-squared
statistic that is six or greater?

00:06:52.930 --> 00:06:57.070
So we would be looking at
this area right over here.

00:06:57.070 --> 00:06:59.300
And you could figure it
out using a calculator,

00:06:59.300 --> 00:07:00.930
or, if you're taking some type of a test,

00:07:00.930 --> 00:07:03.650
like an AP Statistics exam, for example,

00:07:03.650 --> 00:07:06.280
you could use their tables they give you.

00:07:06.280 --> 00:07:09.970
And so a table like this
could be quite useful.

00:07:09.970 --> 00:07:11.600
Remember, we're dealing with the situation

00:07:11.600 --> 00:07:13.470
where we have three degrees of freedom.

00:07:13.470 --> 00:07:16.290
We had four categories, so
four minus one is three.

00:07:16.290 --> 00:07:18.940
And we got a chi-squared value.

00:07:18.940 --> 00:07:22.000
Our chi-squared statistic was six.

00:07:22.000 --> 00:07:23.830
So this right over here tells us

00:07:23.830 --> 00:07:25.910
the probability of getting a 6.25

00:07:27.070 --> 00:07:31.660
or greater for our
chi-squared value is 10%.

00:07:31.660 --> 00:07:33.560
If we go back to this chart,

00:07:33.560 --> 00:07:38.250
we just learned that this
probability from 6.25 and up,

00:07:38.250 --> 00:07:40.180
when we have three degrees of freedom,

00:07:40.180 --> 00:07:43.130
that this right over here is 10%.

00:07:43.130 --> 00:07:44.840
Well, that's 10%.

00:07:44.840 --> 00:07:46.710
Then the probability,

00:07:46.710 --> 00:07:49.960
the probability of getting
a chi-squared value

00:07:49.960 --> 00:07:51.680
greater than or equal to six

00:07:51.680 --> 00:07:54.280
is going to be greater than 10%,

00:07:54.280 --> 00:07:55.550
greater than 10%.

00:07:55.550 --> 00:07:58.350
And we could also view
this as our P-value.

00:07:58.350 --> 00:08:01.540
And so for our probability,
assuming the null hypothesis

00:08:01.540 --> 00:08:04.090
is greater than 10%, well,
it's definitely going

00:08:04.090 --> 00:08:05.920
to be greater than our significance level.

00:08:05.920 --> 00:08:09.380
And because of that,
we will fail to reject,

00:08:09.380 --> 00:08:11.710
fail to reject.

00:08:11.710 --> 00:08:15.110
And so this is an example of,
even though in your sample,

00:08:15.110 --> 00:08:17.380
you just happened to get more Ds,

00:08:17.380 --> 00:08:20.240
the probability of getting
a result at least as extreme

00:08:20.240 --> 00:08:24.923
as what you saw is going to
be a little bit over 10%.

